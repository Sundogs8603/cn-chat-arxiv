# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [TEDDY: Trimming Edges with Degree-based Discrimination strategY](https://rss.arxiv.org/abs/2402.01261) | TEDDY是一种利用边缘度量信息的边缘修剪方法，旨在通过一次性操作实现边缘稀疏化，进而鼓励参数稀疏化训练。这是一个解决图神经网络中抽奖票假设的时间效率和效果问题的创新方法。 |
| [^2] | [The pitfalls of next-token prediction](https://arxiv.org/abs/2403.06963) | 论文揭示了在某些任务类别中，教师强制方法可能无法在第一时间学习到准确的下一个标记预测器，进而导致模型失败的一般机制。 |
| [^3] | [SELMA: Learning and Merging Skill-Specific Text-to-Image Experts with Auto-Generated Data](https://arxiv.org/abs/2403.06952) | SELMA提出了一种新范式，通过在自动生成的多技能图像文本数据集上微调模型，并进行技能特定专家学习和合并，从而改进T2I模型的忠实度。 |
| [^4] | [Counterfactual Reasoning with Knowledge Graph Embeddings](https://arxiv.org/abs/2403.06936) | 通过新任务CFKGR，本文将知识图补全和反事实推理联系起来，提出了一种用于适应假设前提的知识图嵌入方法COULDD，并通过基准数据集的评估表明KGEs可以学习图中的模式，检测出合理的反事实变化。 |
| [^5] | [Simplicity Bias of Transformers to Learn Low Sensitivity Functions](https://arxiv.org/abs/2403.06925) | Transformers在不同数据模态上具有低敏感性，这种简单性偏差有助于解释其在视觉和语言任务中的优越性能。 |
| [^6] | [MEND: Meta dEmonstratioN Distillation for Efficient and Effective In-Context Learning](https://arxiv.org/abs/2403.06914) | 提出了Meta dEmonstratioN Distillation (MEND)，利用知识蒸馏提高MEND和LLM之间的对齐，实现了高效和有效的上下文学习。 |
| [^7] | [Responsible Artificial Intelligence: A Structured Literature Review](https://arxiv.org/abs/2403.06910) | 该研究提出了负责任人工智能的全面统一定义，并通过结构化文献综述阐明了当前对负责任人工智能的理解，旨在帮助立法者和机器学习从业者在AI监管领域做出指导。 |
| [^8] | [Cost-Sensitive Learning to Defer to Multiple Experts with Workload Constraints](https://arxiv.org/abs/2403.06906) | 提出了成本和工作量约束下的推迟框架（DeCCaF），旨在解决成本敏感场景、并发预测和人类工作能力约束等问题 |
| [^9] | [LIBR+: Improving Intraoperative Liver Registration by Learning the Residual of Biomechanics-Based Deformable Registration](https://arxiv.org/abs/2403.06901) | 通过深度学习和生物力学模型相结合的LIBR+方法，作者提出了一种改进术中肝脏配准的方法，能有效处理术中测量的稀疏性和变异性。 |
| [^10] | [Unveiling the Significance of Toddler-Inspired Reward Transition in Goal-Oriented Reinforcement Learning](https://arxiv.org/abs/2403.06880) | 研究探讨了幼儿启发的奖励转换如何影响强化学习任务的样本效率和成功率，特别是发现了幼儿启发的稀疏转密集（S2D）转换的有效性。 |
| [^11] | [Exploring Large Language Models and Hierarchical Frameworks for Classification of Large Unstructured Legal Documents](https://arxiv.org/abs/2403.06872) | 使用MESc框架探索大型法律文件的分类，通过大型语言模型提取文件部分的嵌入并使用聚类近似结构，进而预测判决。 |
| [^12] | [Learning with Noisy Foundation Models](https://arxiv.org/abs/2403.06869) | 本文首次全面了解和分析了预训练数据集中的噪声性质，有效减轻其对下游任务影响。 |
| [^13] | [Towards an educational tool for supporting neonatologists in the delivery room](https://arxiv.org/abs/2403.06843) | 提出了一种机器学习方法，用于从实际数据中识别新生儿分娩事件的风险因素，旨在设计出一款用户友好的移动应用程序，提高对高风险患者的识别率和干预规划。 |
| [^14] | [RA-ISF: Learning to Answer and Understand from Retrieval Augmentation via Iterative Self-Feedback](https://arxiv.org/abs/2403.06840) | 通过迭代自反馈的检索增强方法在指定任务的特定场景中提高模型性能，优于现有基准模型，显著增强了事实推理能力。 |
| [^15] | [Medical Image Synthesis via Fine-Grained Image-Text Alignment and Anatomy-Pathology Prompting](https://arxiv.org/abs/2403.06835) | 通过细粒度图像-文本对齐和解剖病理提示，提出一种新的医学图像合成模型，能够生成高度详细和准确的合成医学图像。 |
| [^16] | [The Power of Noise: Toward a Unified Multi-modal Knowledge Graph Representation Framework](https://arxiv.org/abs/2403.06832) | 提出了一种利用噪声掩模的Transformer-based架构SNAG方法，实现了多模态知识图表示中实体嵌入的最先进性能 |
| [^17] | [NeuPAN: Direct Point Robot Navigation with End-to-End Model-based Learning](https://arxiv.org/abs/2403.06828) | NeuPAN 是一种实时、高度准确、无地图、适用于各种机器人且对环境不变的机器人导航解决方案，最大的创新在于将原始点直接映射到学习到的多帧距离空间，并具有端到端模型学习的可解释性，从而实现了可证明的收敛。 |
| [^18] | [In-context Exploration-Exploitation for Reinforcement Learning](https://arxiv.org/abs/2403.06826) | 引入了In-context Exploration-Exploitation (ICEE)算法，通过在Transformer模型内部进行探索-利用权衡，提高了在-context策略学习的效率。 |
| [^19] | [Are Targeted Messages More Effective?](https://arxiv.org/abs/2403.06817) | GNN的核心架构有两个版本，第一个版本消息仅取决于源顶点的状态，而第二个版本消息取决于源顶点和目标顶点的状态。 |
| [^20] | [Genetic Learning for Designing Sim-to-Real Data Augmentations](https://arxiv.org/abs/2403.06786) | 提出了两种可解释的度量方法，可以结合预测特定增强策略在Sim-to-Real设置中的表现，并引入了一种名为GeneticAugment的遗传规划方法。 |
| [^21] | [An Image is Worth 1/2 Tokens After Layer 2: Plug-and-Play Inference Acceleration for Large Vision-Language Models](https://arxiv.org/abs/2403.06764) | FastV是一种多功能即插即用方法，通过学习自适应注意力模式并在后续层中修剪视觉代币，极大地降低了计算成本，同时在各种图像和视频理解任务中不损失性能。 |
| [^22] | [ALaRM: Align Language Models via Hierarchical Rewards Modeling](https://arxiv.org/abs/2403.06754) | ALaRM是第一个从人类反馈中建模分层奖励的框架，通过整合整体奖励与特定方面的奖励，改善了大型语言模型与人类偏好的对齐性，尤其在复杂文本生成任务中表现出更精确和一致的指导。 |
| [^23] | [ACT-MNMT Auto-Constriction Turning for Multilingual Neural Machine Translation](https://arxiv.org/abs/2403.06745) | 该论文介绍了一种针对多语言神经机器翻译中出现的离靶问题的新型监督微调机制ACT-MNMT Auto-Constriction Turning，与传统基于提示的方法正交，并通过自动构建受限模板来解决该问题。 |
| [^24] | [Enhancing Image Caption Generation Using Reinforcement Learning with Human Feedback](https://arxiv.org/abs/2403.06735) | 通过整合监督学习和强化学习与人类反馈（RLHF）并引入新型损失函数，本研究提出增强深度神经网络模型性能的方法，以生成符合人类偏好的图像标题。 |
| [^25] | [Real-Time Multimodal Cognitive Assistant for Emergency Medical Services](https://arxiv.org/abs/2403.06734) | 本文提出了CognitiveEMS，一个实时多模态认知助手系统，通过引入三个新颖组件解决了实时认知辅助中的关键技术挑战，为急救服务提供关键的辅助。 |
| [^26] | [Improving Low-Resource Knowledge Tracing Tasks by Supervised Pre-training and Importance Mechanism Fine-tuning](https://arxiv.org/abs/2403.06725) | 本文提出了名为LoReKT的低资源知识追踪框架，通过监督预训练和微调重要性机制，旨在从丰富资源的KT数据集中学习可转移的参数和表示来改进低资源知识追踪任务。 |
| [^27] | [Streamlining in the Riemannian Realm: Efficient Riemannian Optimization with Loopless Variance Reduction](https://arxiv.org/abs/2403.06677) | 引入了在黎曼优化中采用概率梯度计算触发器的Loopless SVRG和PAGE方法，简化了证明、提高了超参数选择效率，并提供了尖锐的收敛保证。 |
| [^28] | [Poisoning Programs by Un-Repairing Code: Security Concerns of AI-generated Code](https://arxiv.org/abs/2403.06675) | 本文章针对AI代码生成器面临的安全挑战，提出了一种新颖的数据毒化攻击，通过向训练数据中注入毒素来生成易受攻击的代码，并对其对代码生成模型的影响进行了评估，并讨论了潜在的解决方案。 |
| [^29] | [Car Damage Detection and Patch-to-Patch Self-supervised Image Alignment](https://arxiv.org/abs/2403.06674) | 该论文提出了一种新颖的基于自监督的补丁对补丁SimCLR对齐方法，用于汽车损伤检测的图像对齐，实现了汽车损伤检测和图像对齐两大组件的结合。 |
| [^30] | [CEAT: Continual Expansion and Absorption Transformer for Non-Exemplar Class-Incremental Learnin](https://arxiv.org/abs/2403.06670) | CEAT提出了一种用于非示范类增量学习的新架构，通过持续扩展和吸收参数的方式解决了可塑性-稳定性困境和分类器偏差问题 |
| [^31] | [FashionReGen: LLM-Empowered Fashion Report Generation](https://arxiv.org/abs/2403.06660) | 提出了一个基于先进的大型语言模型(LLM)的智能时尚分析和报告系统 GPT-FAR，旨在通过有效的秀场分析来生成时尚报告。 |
| [^32] | [Zero-Shot ECG Classification with Multimodal Learning and Test-time Clinical Knowledge Enhancement](https://arxiv.org/abs/2403.06659) | 通过Multimodal ECG Representation Learning (MERL)框架，本文提出了一种零样本心电图分类方法，结合了对ECG记录和相关报告的多模态学习，同时在测试阶段使用了Clinical Knowledge Enhanced Prompt Engineering (CKEPE)方法来利用临床知识数据库。 |
| [^33] | [KELLMRec: Knowledge-Enhanced Large Language Models for Recommendation](https://arxiv.org/abs/2403.06642) | 提出了一种知识增强的大型语言模型用于推荐的方法，通过使用外部知识来帮助生成真实可用的文本，并包括知识为基础的对比学习方案进行训练。 |
| [^34] | [Evaluating the Energy Efficiency of Few-Shot Learning for Object Detection in Industrial Settings](https://arxiv.org/abs/2403.06631) | 本文研究了在工业环境中使用少样本学习进行物体检测的能效性，通过微调方法降低了能源消耗，并对模型在工业环境数据集上的能源需求进行了评估。 |
| [^35] | [Forest Inspection Dataset for Aerial Semantic Segmentation and Depth Estimation](https://arxiv.org/abs/2403.06621) | 引入了一个新的大型航空数据集，包含了自然环境的真实和虚拟录像，使用密集注释的语义分割标签和深度地图，在不同条件下拍摄，用于训练深度学习算法解决森林巡检问题。 |
| [^36] | [MedKP: Medical Dialogue with Knowledge Enhancement and Clinical Pathway Encoding](https://arxiv.org/abs/2403.06611) | 通过整合外部知识增强模块和内部临床路径编码，MedKP框架在医学对话生成中取得了显著进展。 |
| [^37] | [Guiding Clinical Reasoning with Large Language Models via Knowledge Seeds](https://arxiv.org/abs/2403.06609) | 大型语言模型在临床推理中展现出潜力，但存在幻觉问题和与医生决策路径不一致的挑战。 |
| [^38] | [Cross-domain and Cross-dimension Learning for Image-to-Graph Transformers](https://arxiv.org/abs/2403.06601) | 该论文提出了一种用于图像到图形转换器的跨域和跨维度迁移学习方法，包括正则化边缘采样损失、领域自适应框架和简单的投影函数，可以解决数据稀缺性问题，并在实验中展示了其实用性。 |
| [^39] | [Exploiting Style Latent Flows for Generalizing Deepfake Detection Video Detection](https://arxiv.org/abs/2403.06592) | 该研究提出了一种利用样式潜在流进行深度伪造视频检测的新方法，通过分析样式潜在向量在生成视频中的异常行为来检测假视频，利用对比学习训练的StyleGRU模块和样式注意模块的组合，能有效检测视觉和时间异常。 |
| [^40] | [ContextGPT: Infusing LLMs Knowledge into Neuro-Symbolic Activity Recognition Models](https://arxiv.org/abs/2403.06586) | 将预训练的大型语言模型（LLMs）的常识知识有效地注入神经符号活动识别模型，以缓解标记数据稀缺性问题。 |
| [^41] | [Better Understandings and Configurations in MaxSAT Local Search Solvers via Anytime Performance Analysis](https://arxiv.org/abs/2403.06568) | 通过任意性能分析显示出MaxSAT本地搜索求解器在不同时间预算下的性能优劣变化 |
| [^42] | [ReStainGAN: Leveraging IHC to IF Stain Domain Translation for in-silico Data Generation](https://arxiv.org/abs/2403.06545) | 提出了一种新的方法，通过将形态特定的IHC染色分解为单独的图像通道，生成了in-silico免疫组织化学（IHC）图像，该方法在训练细胞核分割模型时在质量和数量上优于基线方法。 |
| [^43] | [Decentralized and Lifelong-Adaptive Multi-Agent Collaborative Learning](https://arxiv.org/abs/2403.06535) | 本文提出了DeLAMA，一种具有动态协作图的分散多智能体终身协作学习算法，旨在通过自主识别协作关系和适应动态任务来增强多智能体之间的协作。 |
| [^44] | [SARDet-100K: Towards Open-Source Benchmark and ToolKit for Large-Scale SAR Object Detection](https://arxiv.org/abs/2403.06534) | SARDet-100K是第一个COCO级别的大规模多类别SAR物体检测数据集，为研究提供了大规模且多样化的数据集，揭示了SAR物体检测中预训练模型显著差异的关键挑战。 |
| [^45] | [Tactical Decision Making for Autonomous Trucks by Deep Reinforcement Learning with Total Cost of Operation Based Reward](https://arxiv.org/abs/2403.06524) | 通过基于全面运营成本的奖励函数，采用深度强化学习框架优化自主卡车的战术决策，将高级决策与低级控制分离，并采用不同技巧提升性能。 |
| [^46] | [How to Understand Named Entities: Using Common Sense for News Captioning](https://arxiv.org/abs/2403.06520) | 该论文利用常识知识来帮助新闻标题生成系统理解命名实体，从而更好地描述图像内容。 |
| [^47] | [Active Generation for Image Classification](https://arxiv.org/abs/2403.06517) | 该论文提出了一种名为ActGen的方法，通过采用训练感知的方式来生成图像，以提高图像分类准确性。ActGen利用主动学习的理念，生成类似于挑战性或被误分类样本的图像，并将其整合到训练集中，从而增强模型性能。 |
| [^48] | [Structure Your Data: Towards Semantic Graph Counterfactuals](https://arxiv.org/abs/2403.06514) | 提出了基于语义图的反事实解释方法，利用GNN来进行高效的图编辑距离计算，通过场景图形式，绕过NP困难的图相似性问题，实现更具描述性、准确性和与人类对齐的解释。 |
| [^49] | [The negation of permutation mass function](https://arxiv.org/abs/2403.06483) | 本文提出了排列质量函数的否定方法，并验证了其收敛性，研究了否定操作后的不确定性和不相似性变化趋势。 |
| [^50] | [Ada-Tracker: Soft Tissue Tracking via Inter-Frame and Adaptive-Template Matching](https://arxiv.org/abs/2403.06479) | Ada-Tracker利用光流捕捉像素级组织变形并自适应纠正跟踪模板，同时结合帧间匹配和自适应模板匹配，解决了在手术场景中软组织跟踪面临的形状和外观改变困难的问题。 |
| [^51] | [RL-MSA: a Reinforcement Learning-based Multi-line bus Scheduling Approach](https://arxiv.org/abs/2403.06466) | RL-MSA提出了一种基于强化学习的多线路公交车调度方法，将多线路公交车调度问题建模为MDP，首次在离线阶段将直行车决策整合入公交车选择决策，有效简化学习问题，在线阶段通过时间窗口机制进行直行车决策。 |
| [^52] | [RecAI: Leveraging Large Language Models for Next-Generation Recommender Systems](https://arxiv.org/abs/2403.06465) | 本文介绍了RecAI，一个旨在通过大型语言模型增强推荐系统的实用工具包，新一代由LLMs赋能的推荐系统将更加多才多艺、可解释、对话式和可控，为更智能和用户中心的推荐体验铺平道路。 |
| [^53] | [Unsupervised Real-Time Hallucination Detection based on the Internal States of Large Language Models](https://arxiv.org/abs/2403.06448) | 提出了一种利用大型语言模型内部状态进行实时幻觉检测的无监督训练框架，并引入了一个新的基准用于评估多个大型语言模型的幻觉检测。 |
| [^54] | [CoRAL: Collaborative Retrieval-Augmented Large Language Models Improve Long-tail Recommendation](https://arxiv.org/abs/2403.06447) | CoRAL引入了协作检索增强LLMs，将协作证据直接纳入到推理过程中，从而更好地理解用户之间的偏好，改进长尾推荐。 |
| [^55] | [Fine-Grained Pillar Feature Encoding Via Spatio-Temporal Virtual Grid for 3D Object Detection](https://arxiv.org/abs/2403.06433) | 本文提出一种名为细粒度柱特征编码（FG-PFE）的新型柱编码架构，利用时空虚拟（STV）网格捕捉每个柱内点云的细粒度分布 |
| [^56] | [A Differential Geometric View and Explainability of GNN on Evolving Graphs](https://arxiv.org/abs/2403.06425) | 提出了一种基于微分几何视角的方法，通过流形上的平滑曲线模拟图演化，实现了对图神经网络预测分布的可解释性。 |
| [^57] | [RLingua: Improving Reinforcement Learning Sample Efficiency in Robotic Manipulations With Large Language Models](https://arxiv.org/abs/2403.06420) | RLingua提出了一个框架，利用大型语言模型的内部知识来提高机器人操作中强化学习的样本效率。 |
| [^58] | [A Logical Pattern Memory Pre-trained Model for Entailment Tree Generation](https://arxiv.org/abs/2403.06410) | 提出了逻辑模式记忆预训练模型（LMPM），通过结合外部存储结构学习和存储逻辑模式的潜在表示，有助于生成逻辑一致的结论，并引入实体抽象方法来减少维基百科数据中的逻辑无关领域知识的影响。 |
| [^59] | [What Makes Quantization for Large Language Models Hard? An Empirical Study from the Lens of Perturbation](https://arxiv.org/abs/2403.06408) | 量化对大型语言模型的困难主要表现在如何通过添加扰动来改善模型性能和效率的关系，研究通过对不同人为扰动进行实验，发现了扰动特性与模型性能之间的联系，提出了改善量化稳健性的潜在解决方案。 |
| [^60] | [On the Diminishing Returns of Width for Continual Learning](https://arxiv.org/abs/2403.06398) | 增加神经网络宽度以减少遗忘会带来递减的回报，并且在先前研究中尚未探索的宽度范围内进行了实证验证。 |
| [^61] | [DeepSafeMPC: Deep Learning-Based Model Predictive Control for Safe Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2403.06397) | DeepSafeMPC是一种基于深度学习的模型预测控制方法，旨在有效预测多智体环境的复杂动态，并应用MARL原则寻找最优解。 |
| [^62] | [Pre-Trained Model Recommendation for Downstream Fine-tuning](https://arxiv.org/abs/2403.06382) | 本文提出了一个名为Fennec的框架，通过将所有模型和历史任务映射到一个迁移相关的子空间，以便推断新任务在迁移空间中的表征，从而改善模型选择技术。 |
| [^63] | [Human and Automatic Interpretation of Romanian Noun Compounds](https://arxiv.org/abs/2403.06360) | 提出了新的罗马尼亚名词复合词关系集，通过人类和神经网络分类器测试后发现，网络的预测与人类判断存在一致，即使是在人类一致率较低的情况下。需要一个更好的关系清单。 |
| [^64] | [Video Generation with Consistency Tuning](https://arxiv.org/abs/2403.06356) | 提出了一个新的视频生成框架，通过四个模块的应用优化视频帧中背景和前景的一致性，生成的视频质量高于现有最先进的方法 |
| [^65] | [MOAB: Multi-Modal Outer Arithmetic Block For Fusion Of Histopathological Images And Genetic Data For Brain Tumor Grading](https://arxiv.org/abs/2403.06349) | 该论文提出了一种新颖的多模态外部算术块（MOAB），用于将组织病理图像和遗传数据的潜在表示进行融合，以预测脑肿瘤的等级。 |
| [^66] | [Exploiting the Margin: How Capitalism Fuels AI at the Expense of Minoritized Groups](https://arxiv.org/abs/2403.06332) | 人工智能在深化社会不平等方面起着关键作用，通过剥削边缘群体，特别是通过机制如零工经济劳工的滥用、有偏见的面部识别技术和对这些社群施加的不成比例的心理健康负担，加剧了现有的不平等。 |
| [^67] | [From Instructions to Constraints: Language Model Alignment with Automatic Constraint Verification](https://arxiv.org/abs/2403.06326) | 提出了ACT框架，通过约束验证器自动计算每个响应的约束满意率，实现语言模型对齐与自动约束验证。 |
| [^68] | [Leveraging Computer Vision in the Intensive Care Unit (ICU) for Examining Visitation and Mobility](https://arxiv.org/abs/2403.06322) | 在重症监护病房中利用计算机视觉系统，可以实现不存在的评估和增强现有评估的频率和准确性，同时减少工作人员工作量。 |
| [^69] | [An End-to-End Deep Learning Generative Framework for Refinable Shape Matching and Generation](https://arxiv.org/abs/2403.06317) | 提出了一种端到端深度学习生成框架，利用图形表示为网格建立可微调的形状对应，在潜在空间生成逼真的合成形状，并扩展为联合形状生成-聚类多图谱框架以增加变异性和保留生成形状中的更多细节 |
| [^70] | [Optimal Policy Sparsification and Low Rank Decomposition for Deep Reinforcement Learning](https://arxiv.org/abs/2403.06313) | 提出一种新颖的$L_0$范数正则化技术，用于深度强化学习的最优策略稀疏化和低秩分解 |
| [^71] | [ArgMed-Agents: Explainable Clinical Decision Reasoning with Large Language Models via Argumentation Schemes](https://arxiv.org/abs/2403.06294) | 通过争论方案的自我论证迭代和构建争论过程，ArgMed-Agents实现了基于LLM的可解释临床决策推理，提高了用户对临床决策的信任。 |
| [^72] | [Understanding and Mitigating Human-Labelling Errors in Supervised Contrastive Learning](https://arxiv.org/abs/2403.06289) | 本文揭示了人工标注误差不仅与合成标签错误有显著不同，而且在监督对比学习中构成了独特挑战，提出了一种新颖的对抗人工标注误差的SCL目标。 |
| [^73] | [UNICORN: Ultrasound Nakagami Imaging via Score Matching and Adaptation](https://arxiv.org/abs/2403.06275) | 提出了一种名为UNICORN的新方法，通过分数匹配和自适应实现超声纳卡加米成像，能够在准确性和分辨率质量上超越传统方法。 |
| [^74] | [Physics-Guided Abnormal Trajectory Gap Detection](https://arxiv.org/abs/2403.06268) | 通过物理引导的方法，解决了在轨迹数据中识别异常间隙的挑战性问题，具有重要的社会应用和技术难度。 |
| [^75] | [FARPLS: A Feature-Augmented Robot Trajectory Preference Labeling System to Assist Human Labelers' Preference Elicitation](https://arxiv.org/abs/2403.06267) | FARPLS提出了一个特征增强的机器人轨迹偏好标注系统，用于帮助人类标注者在偏好获取过程中避免忽视重要特征、形成偏见标准和因比较过多而导致标注质量下降的问题。 |
| [^76] | [Unpacking Tokenization: Evaluating Text Compression and its Correlation with Model Performance](https://arxiv.org/abs/2403.06265) | 本文研究了文本压缩在分词过程中的重要性，证明了压缩与预训练语言模型后续成功之间的实证重要性，并表明分词器的压缩与模型的性能存在相关性。 |
| [^77] | [Editing Conceptual Knowledge for Large Language Models](https://arxiv.org/abs/2403.06259) | 该论文首次研究了为大型语言模型编辑概念知识，通过构建基准数据集和建立新评估指标，发现现有方法虽然能一定程度上修改概念定义，但也可能造成LLMs中相关实例知识的扭曲，导致性能下降。 |
| [^78] | [Text-Guided Variational Image Generation for Industrial Anomaly Detection and Segmentation](https://arxiv.org/abs/2403.06247) | 该方法利用文本信息生成类似输入图像的无缺陷数据图像，确保生成的图像符合期望分布，稳定且具有普适性。 |
| [^79] | [Cooperative Classification and Rationalization for Graph Generalization](https://arxiv.org/abs/2403.06239) | 本文提出了一种合作分类与理性化（C2R）方法，旨在解决图神经网络在泛化时面临的挑战，通过分类和理性化模块协同工作，改善对分布之外数据的泛化能力。 |
| [^80] | [Probabilistic Neural Circuits](https://arxiv.org/abs/2403.06235) | PNCs将概率电路和神经网络的特点结合起来，可以解释为深层混合的贝叶斯网络，同时作为强大的函数逼近器。 |
| [^81] | [MoST: Motion Style Transformer between Diverse Action Contents](https://arxiv.org/abs/2403.06225) | MoST提出了一种新颖的动作风格转换器，能够有效地将风格与内容分离，在转移风格时表现出色，并在不同内容的动作对中展现出卓越的质量。 |
| [^82] | [TRAD: Enhancing LLM Agents with Step-Wise Thought Retrieval and Aligned Decision](https://arxiv.org/abs/2403.06221) | 提出了TRAD框架，通过步骤式思维检索和对齐决策解决了利用上下文示例时可能出现的问题。 |
| [^83] | [$V_kD:$ Improving Knowledge Distillation using Orthogonal Projections](https://arxiv.org/abs/2403.06213) | 提出一种约束特征蒸馏方法，通过使用正交投影和任务特定的归一化，能够在ImageNet上实现高达4.4%的相对改进，并在目标检测和图像生成任务中取得显著性能提升 |
| [^84] | [Limit of the Maximum Random Permutation Set Entropy](https://arxiv.org/abs/2403.06206) | 本文定义了熵函数的包络概念，并推导证明了随机置换集熵包络的极限形式为$e \times (N!)^2$。 |
| [^85] | [Are You Being Tracked? Discover the Power of Zero-Shot Trajectory Tracing with LLMs!](https://arxiv.org/abs/2403.06201) | 介绍了LLMTrack模型，通过引入一种新颖的单提示技术，结合角色扮演和逐步思考方法，利用未经处理的IMU数据，实现了零射轨迹识别，超越了传统机器学习和深度学习模型，无需训练在专门数据集上的性能表现。 |
| [^86] | [Domain Adversarial Active Learning for Domain Generalization Classification](https://arxiv.org/abs/2403.06174) | 本文提出了一种用于领域泛化分类任务的领域对抗主动学习（DAAL）算法，通过设计一种优先选择具有挑战性样本的领域对抗选择方法，来改善模型的泛化能力。 |
| [^87] | [DiffuMatting: Synthesizing Arbitrary Objects with Matting-level Annotation](https://arxiv.org/abs/2403.06168) | 提出了DiffuMatting方法，通过扩散技术实现了“抠图任何物体”的能力，可以生成高度准确的注释，同时兼容社区LoRAs或各种条件控制方法。 |
| [^88] | [Can Large Language Models Automatically Score Proficiency of Written Essays?](https://arxiv.org/abs/2403.06149) | 本研究旨在测试大型语言模型在分析和评分书面作文方面的能力，通过对两种流行的LLMs进行实验，设计不同提示并在ASAP数据集上进行实验，揭示了有趣的观察结果。 |
| [^89] | [All-in-one platform for AI R&D in medical imaging, encompassing data collection, selection, annotation, and pre-processing](https://arxiv.org/abs/2403.06145) | 该论文介绍了首个商业化医学影像平台，着重解决了来自亚洲地区的数据不足问题，为医学AI研发准备并提供了可直接使用的数据集 |
| [^90] | [Fluent: Round-efficient Secure Aggregation for Private Federated Learning](https://arxiv.org/abs/2403.06143) | Fluent提出了一种面向私人联邦学习的轮次和通信高效的安全聚合方案，相比现有解决方案有两个重要改进。 |
| [^91] | [Fine-grainedly Synthesize Streaming Data Based On Large Language Models With Graph Structure Understanding For Data Sparsity](https://arxiv.org/abs/2403.06139) | 提出了一种细粒度合成流数据的框架，利用大型语言模型和图结构理解，将稀疏用户进行分类并生成高质量数据。 |
| [^92] | [MACE: Mass Concept Erasure in Diffusion Models](https://arxiv.org/abs/2403.06135) | MACE通过成功将概念消除的范围扩展到100个概念，并在泛化性和特异性之间取得有效平衡，从而防止大规模文本到图像扩散模型生成不良或误导性图像。 |
| [^93] | [FedPIT: Towards Privacy-preserving and Few-shot Federated Instruction Tuning](https://arxiv.org/abs/2403.06131) | 提出一种新颖的联邦算法FedPIT，通过利用LLMs的上下文学习能力自动生成任务特定的合成数据进行训练，采用参数隔离训练来防止数据提取攻击。 |
| [^94] | [FMPAF: How Do Fed Chairs Affect the Financial Market? A Fine-grained Monetary Policy Analysis Framework on Their Language](https://arxiv.org/abs/2403.06115) | FMPAF是一个新颖的方法，通过整合大型语言模型和回归分析，提供了对美联储主席新闻发布会沟通对金融市场影响的全面分析。 |
| [^95] | [Large Language Models on Fine-grained Emotion Detection Dataset with Data Augmentation and Transfer Learning](https://arxiv.org/abs/2403.06108) | 本文研究了如何在细粒度情感检测数据集上使用大型语言模型来提高分类性能，并提出了对于文本中检测微妙情感的挑战的有价值见解。 |
| [^96] | [Can LLM Substitute Human Labeling? A Case Study of Fine-grained Chinese Address Entity Recognition Dataset for UAV Delivery](https://arxiv.org/abs/2403.06097) | 提出了适用于无人机交付系统中地址解析任务的细粒度中文姓名实体识别数据集CNER-UAV，包含五个类别的多样化数据，经过严格的数据清洗和去敏处理，约有12,000个标注样本，评估了传统的实体识别模型并提供了深入分析 |
| [^97] | [RepoHyper: Better Context Retrieval Is All You Need for Repository-Level Code Completion](https://arxiv.org/abs/2403.06095) | RepoHyper提出了Repo级语义图（RSG）和Expand和Refine检索方法，显著优于现有技术，满足仓库级代码补全的需求 |
| [^98] | [Towards In-Vehicle Multi-Task Facial Attribute Recognition: Investigating Synthetic Data and Vision Foundation Models](https://arxiv.org/abs/2403.06088) | 本文通过研究合成数据集的实用性和不同视觉基础模型在车载多任务面部属性识别中的效果，填补了现有文献中的空白。 |
| [^99] | [Towards Generalizable and Interpretable Motion Prediction: A Deep Variational Bayes Approach](https://arxiv.org/abs/2403.06086) | 本论文提出了一种Goal-based Neural Variational Agent (GNeVA)模型，通过变分高斯混合估算长期目的地的空间分布，实现了目标驱动的运动预测，具有强大的泛化能力和解释性。 |
| [^100] | [L$^2$GC: Lorentzian Linear Graph Convolutional Networks For Node Classification](https://arxiv.org/abs/2403.06064) | 本文提出了一种新颖的洛伦兹线性图卷积网络框架，将双曲空间引入线性GCN，用于捕捉数据的树状结构，并在实验中取得了新的最先进的节点分类结果。 |
| [^101] | [Target-constrained Bidirectional Planning for Generation of Target-oriented Proactive Dialogue](https://arxiv.org/abs/2403.06063) | 提出了一种面向目标导向对话生成的目标受限双向规划（TRIP）方法，通过前向和后向规划生成对话路径，促进对话向预定目标发展。 |
| [^102] | [Decoupled Data Consistency with Diffusion Purification for Image Restoration](https://arxiv.org/abs/2403.06054) | 通过分离反向过程和数据一致性步骤，提出了一种新颖的基于扩散的图像恢复求解器。 |
| [^103] | [MATRIX: Multi-Agent Trajectory Generation with Diverse Contexts](https://arxiv.org/abs/2403.06041) | 本研究提出了一种名为MATRIX的学习基础自动轨迹生成模型，能够在多样化背景中生成交互式人类行为。 |
| [^104] | [A Preliminary Exploration of YouTubers' Use of Generative-AI in Content Creation](https://arxiv.org/abs/2403.06039) | 通过定性分析探讨了YouTuber在内容创作中使用生成式人工智能的方法和生成的内容领域。 |
| [^105] | [FairTargetSim: An Interactive Simulator for Understanding and Explaining the Fairness Effects of Target Variable Definition](https://arxiv.org/abs/2403.06031) | FairTargetSim提供了一个交互式模拟器，展示了目标变量定义对公平性的影响，适用于算法开发者、研究人员和非技术利益相关者。 |
| [^106] | [Towards a Generic Representation of Cominatorial Problems for Learning-Based Approaches](https://arxiv.org/abs/2403.06026) | 本文倡导为基于学习方法的组合问题构建通用表示，以解决特定表示无法跨越不同组合问题的问题。 |
| [^107] | [CarbonNet: How Computer Vision Plays a Role in Climate Change? Application: Learning Geomechanics from Subsurface Geometry of CCS to Mitigate Global Warming](https://arxiv.org/abs/2403.06025) | 这项研究介绍了一种利用计算机视觉从地下储存空间几何图像中预测陆地表面位移的新方法，为碳捕集和封存项目中的决策提供支持。 |
| [^108] | [Few-Shot Cross-Lingual Transfer for Prompting Large Language Models in Low-Resource Languages](https://arxiv.org/abs/2403.06018) | 本研究评估了如何将具有70亿参数的开源PLM LLaMa 用于低资源语言的提示，解决了跨语言适应提示的问题。 |
| [^109] | [Hard-label based Small Query Black-box Adversarial Attack](https://arxiv.org/abs/2403.06014) | 提出了一种新的基于硬标签的黑盒对抗攻击方法，通过在优化过程中利用预训练替代模型的指导，显著提高了攻击的查询效率。 |
| [^110] | [A Generalized Acquisition Function for Preference-based Reward Learning](https://arxiv.org/abs/2403.06003) | 通过引入一种可以捕捉奖励函数相似性定义的框架，优化了奖励函数的学习效率。 |
| [^111] | [Dissecting Deep RL with High Update Ratios: Combatting Value Overestimation and Divergence](https://arxiv.org/abs/2403.05996) | 本研究剖析了深度强化学习中的首要偏差现象，发现在大量更新比例下，价值高估是导致学习失败的根本挑战。 |
| [^112] | [Calibrating Large Language Models Using Their Generations Only](https://arxiv.org/abs/2403.05973) | 使用APRICOT方法，通过仅使用大型语言模型的文本输入和输出来设置置信目标并训练额外模型，从而实现大型语言模型的校准。 |
| [^113] | [Classifying Objects in 3D Point Clouds Using Recurrent Neural Network: A GRU LSTM Hybrid Approach](https://arxiv.org/abs/2403.05950) | 本文提出了一种使用GRU和LSTM混合方法进行3D点云中物体分类的深度学习策略，取得了高准确率，并在对多个类别的数据集中取得优异表现。 |
| [^114] | [Learned 3D volumetric recovery of clouds and its uncertainty for climate analysis](https://arxiv.org/abs/2403.05932) | 该模型设计了一个学习-based 模型（ProbCT），通过嘈杂的多视角航天图像实现了对云的三维CT，首次推断出每个3D位置的后验概率分布，产生了具有价值的统计数据。 |
| [^115] | [OntoChat: a Framework for Conversational Ontology Engineering using Language Models](https://arxiv.org/abs/2403.05921) | OntoChat是一个支持对话本体工程的框架，通过与对话代理互动，用户可以引导用户故事的创建和能力问题的提取，同时接收计算支持以分析整体需求并进行早期测试。 |
| [^116] | [High Throughput Phenotyping of Physician Notes with Large Language and Hybrid NLP Models](https://arxiv.org/abs/2403.05920) | 大语言模型和混合NLP模型的结合可在高准确率下对医师笔记进行高吞吐量表型识别，有望成为未来首选方法。 |
| [^117] | [SEMRes-DDPM: Residual Network Based Diffusion Modelling Applied to Imbalanced Data](https://arxiv.org/abs/2403.05918) | 基于残差网络的扩散建模方法能够有效处理不平衡数据，克服了经典过采样方法和基于生成网络的模式塌陷与训练不稳定问题。 |
| [^118] | [GPT as Psychologist? Preliminary Evaluations for GPT-4V on Visual Affective Computing](https://arxiv.org/abs/2403.05916) | 本文评估了GPT4在视觉情感计算中的应用，发现其在面部动作单位识别和微表情检测方面准确性高，但一般面部表情识别性能不佳，同时强调了微表情识别的挑战和进一步研究的潜力。 |
| [^119] | [Towards Optimizing Human-Centric Objectives in AI-Assisted Decision-Making With Offline Reinforcement Learning](https://arxiv.org/abs/2403.05911) | 该研究提出了使用离线强化学习来优化人类中心目标的方法，通过提供适当类型的决策支持，针对特定人员、在适当时间，来优化决策准确性和人类学习能力这两个目标。 |
| [^120] | [Reverse That Number! Decoding Order Matters in Arithmetic Learning](https://arxiv.org/abs/2403.05845) | 本研究提出了一种新颖的算术学习策略，重点考虑最低有效数字的输出，重新评估数字顺序，并结合逐步方法大幅减少了复杂性，从而取得了比之前方法更好的性能提升。 |
| [^121] | [Hufu: A Modality-Agnositc Watermarking System for Pre-Trained Transformers via Permutation Equivariance](https://arxiv.org/abs/2403.05842) | Hufu提出了一种适用于预训练Transformer模型的模态不可知水印系统，利用Transformer的置换等变性质，实现了在模型中嵌入水印并保持高保真度。 |
| [^122] | [Long-term Frame-Event Visual Tracking: Benchmark Dataset and Baseline](https://arxiv.org/abs/2403.05839) | 提出了一个新的长期和大规模的帧事件单目标跟踪数据集FELT，重新训练和评估了15个基准跟踪器，并引入了关联记忆Transformer网络来解决RGB帧和事件流不完整的问题。 |
| [^123] | [Quantum-HPC Framework with multi-GPU-Enabled Hybrid Quantum-Classical Workflow: Applications in Quantum Simulations](https://arxiv.org/abs/2403.05828) | 混合量子-经典工作流架构QCQ实现了量子模拟中的创新，通过在QPUs上运行VQE算法和在经典硬件上进行量子态分类，结合了cuQuantum SDK和PennyLane's Lightning plugin，为材料和凝聚态物理领域的计算挑战提供了解决方案。 |
| [^124] | [MP2D: An Automated Topic Shift Dialogue Generation Framework Leveraging Knowledge Graphs](https://arxiv.org/abs/2403.05814) | 提出了一种利用知识图谱的自动化对话生成框架MP2D，通过映射对话中话题的流动，有效地模拟了人类对话的动态，展示了其在生成具有自然话题转换的对话方面的有效性。 |
| [^125] | [Algorithmic progress in language models](https://arxiv.org/abs/2403.05812) | 研究发现，语言模型预训练算法每8个月几乎减半一次所需的计算需求，大大快于摩尔定律的硬件增益，尽管算法进展速度快，但计算能力的增加对整体性能改善的贡献更大。 |
| [^126] | [Recurrent Aligned Network for Generalized Pedestrian Trajectory Prediction](https://arxiv.org/abs/2403.05810) | 引入了循环对齐网络（RAN）来最小化领域差异，通过循环对齐策略有效地在时间-状态和时间-序列级别对齐轨迹特征空间，从而实现广义行人轨迹预测。 |
| [^127] | [Enhancing Multi-Hop Knowledge Graph Reasoning through Reward Shaping Techniques](https://arxiv.org/abs/2403.05801) | 通过奖励塑造技术和预训练的BERT嵌入以及提示学习方法，本研究在多跳知识图推理中处理知识图的固有不完整性，提高了精度。 |
| [^128] | [Privacy-Preserving Diffusion Model Using Homomorphic Encryption](https://arxiv.org/abs/2403.05794) | 本文介绍了一种使用同态加密的隐私保护扩散模型HE-Diffusion，通过最小失真方法和稀疏张量表示来提高效率，实现了500倍的加速。 |
| [^129] | [ItD: Large Language Models Can Teach Themselves Induction through Deduction](https://arxiv.org/abs/2403.05789) | 提出了演绎通过归纳（ItD）框架，使大型语言模型能够通过演绎自学归纳，显著提升了归纳任务的性能。 |
| [^130] | [On the Benefits of Fine-Grained Loss Truncation: A Case Study on Factuality in Summarization](https://arxiv.org/abs/2403.05788) | 通过细粒度NLL损失和fi以更好地区分事实性，改进了细粒度损失截断对于摘要中事实性的影响。 |
| [^131] | [Towards Deviation-Robust Agent Navigation via Perturbation-Aware Contrastive Learning](https://arxiv.org/abs/2403.05770) | 本文提出了一种名为渐进扰动感知对比学习（PROPER）的训练范式来增强现有的智能体对各种干扰的泛化能力，特别是针对偏离鲁棒导航进行了改进。 |
| [^132] | [Extending Activation Steering to Broad Skills and Multiple Behaviours](https://arxiv.org/abs/2403.05767) | 本文研究了将激活导向技术应用于广泛技能和多种行为的功效，并发现导向广泛技能具有竞争力，同时在模型中同时注入个体导向向量是一种有前途的方法。 |
| [^133] | [Investigation into the Potential of Parallel Quantum Annealing for Simultaneous Optimization of Multiple Problems: A Comprehensive Study](https://arxiv.org/abs/2403.05764) | 并行量子退火技术旨在通过在单个退火周期中解决多个独立问题来优化可用量子位的利用，相比传统的顺序处理方式，该方法最大程度地减少了闲置量子位，并显示出巨大的加速潜力。 |
| [^134] | [HDReason: Algorithm-Hardware Codesign for Hyperdimensional Knowledge Graph Reasoning](https://arxiv.org/abs/2403.05763) | 本文提出了一种基于超维计算的算法-硬件协同设计，用于更高效和加速的知识图推理。 |
| [^135] | [Membership Testing in Markov Equivalence Classes via Independence Query Oracles](https://arxiv.org/abs/2403.05759) | 通过建立在给定的最大无向团大小($s$)方面的下界，我们探讨了通过独立查询预言者在马尔可夫等价类中进行成员测试这一问题。 |
| [^136] | [Task-Oriented GNNs Training on Large Knowledge Graphs for Accurate and Efficient Modeling](https://arxiv.org/abs/2403.05752) | 本文提出了一种自动化TOSG提取的方法KG-TOSA，用于在大型知识图上进行面向任务的图神经网络训练，以减轻对大型KG的过多计算负担。 |
| [^137] | [MG-TSD: Multi-Granularity Time Series Diffusion Models with Guided Learning Process](https://arxiv.org/abs/2403.05751) | 提出了一种新颖的MG-TSD模型，利用数据内在粒度水平作为目标来引导学习过程，实现了状态-of-the-art的预测性能 |
| [^138] | [Decoding the AI Pen: Techniques and Challenges in Detecting AI-Generated Text](https://arxiv.org/abs/2403.05750) | 大型语言模型在自然语言生成领域取得了重大突破，提出了识别AI生成文本的解决方案，并探索了未来研究方向。 |
| [^139] | [Conservative DDPG -- Pessimistic RL without Ensemble](https://arxiv.org/abs/2403.05732) | 提出了一种新的保守DDPG方法，通过引入$Q$-目标和行为克隆损失惩罚来解决DDPG中的高估偏差问题，可以在不需要集成的情况下轻松实现，并且在各种任务中表现优异。 |
| [^140] | [A Benchmark of Domain-Adapted Large Language Models for Generating Brief Hospital Course Summaries](https://arxiv.org/abs/2403.05720) | 介绍了一个新的基准测试，评估了用于生成简要住院病程摘要的大语言模型在健康保健领域中的性能并提出相应的自适应策略 |
| [^141] | [A Framework for Effective AI Recommendations in Cyber-Physical-Human Systems](https://arxiv.org/abs/2403.05715) | 该论文提出了一个框架来解决网络物理人系统中人工智能推荐和人类决策者之间的挑战，通过考虑人类可能不同于AI平台的感知和解释方式，建立了最佳推荐策略的结构特性，并开发了近似人类模型，从而提供了理论上的最优性界限和数值示例验证结果。 |
| [^142] | [Are Large Language Models Aligned with People's Social Intuitions for Human-Robot Interactions?](https://arxiv.org/abs/2403.05701) | 该研究测试大型语言模型在人机互动中是否能够捕捉到人们的行为判断和沟通偏好，结果表明GPT-4在生成社会可接受行为方面表现出色。 |
| [^143] | [Efficient Public Health Intervention Planning Using Decomposition-Based Decision-Focused Learning](https://arxiv.org/abs/2403.05683) | 决策焦点学习（DFL）在公共卫生干预中的应用提高了干预的精准度，虽然存在高计算成本，但能优化有限的干预资源使用效果。 |
| [^144] | [DP-TabICL: In-Context Learning with Differentially Private Tabular Data](https://arxiv.org/abs/2403.05681) | 研究了如何使用差分隐私来保护在环境中学习中使用的表格数据。 |
| [^145] | [Decomposing Vision-based LLM Predictions for Auto-Evaluation with GPT-4](https://arxiv.org/abs/2403.05680) | 提出了一种新颖的评估框架，用于评估视觉-语言LLMs在生成CT异常的准确摘要方面的能力。 |
| [^146] | [Feature CAM: Interpretable AI in Image Classification](https://arxiv.org/abs/2403.05658) | 本研究比较了激活方法在CNN模型图像分类预测解释中的应用，提出了一种新颖的Feature CAM技术，用于提高模型的可解释性。 |
| [^147] | [What is different between these datasets?](https://arxiv.org/abs/2403.05652) | 这里是中文总结出的一句话要点 |
| [^148] | [Geometric Neural Network based on Phase Space for BCI decoding](https://arxiv.org/abs/2403.05645) | 基于相空间的几何神经网络用于BCI解码，提供了在脑机接口领域中可靠算法操作的方法，以提高用户舒适度并促进其广泛应用。 |
| [^149] | [A Feature-based Generalizable Prediction Model for Both Perceptual and Abstract Reasoning](https://arxiv.org/abs/2403.05641) | 本论文提出了一种基于特征的通用预测模型，旨在克服当前神经网络在识别和推断任务规则方面的局限性，并探索人类在符号和连续感知表示之间灵活切换的能力。 |
| [^150] | [Tuning-Free Accountable Intervention for LLM Deployment -- A Metacognitive Approach](https://arxiv.org/abs/2403.05636) | 提出了一种创新的元认知方法，名为CLEAR，旨在为LLMs提供自我意识的错误识别和纠正能力 |
| [^151] | [Can Large Language Models Play Games? A Case Study of A Self-Play Approach](https://arxiv.org/abs/2403.05632) | 该研究引入了一种创新方法，将蒙特卡罗树搜索（MCTS）的自我博弈与大型语言模型（LLMs）相结合，有效解决了确定性轮流零和游戏（DTZG），如国际象棋和围棋，而无需额外的训练。 |
| [^152] | [Unfamiliar Finetuning Examples Control How Language Models Hallucinate](https://arxiv.org/abs/2403.05612) | 本文研究了大型语言模型如何产生幻觉，并提出通过调整微调示例的监督来控制其对不熟悉输入的预测。作者开发了一种基于RL的方法，更可靠地减轻了长篇生成任务中的幻觉。 |
| [^153] | [A Concept-based Interpretable Model for the Diagnosis of Choroid Neoplasias using Multimodal Data](https://arxiv.org/abs/2403.05606) | 提出了一种基于概念的可解释模型，用于利用多模态数据诊断脉络膜肿瘤，促进了对罕见疾病的诊断，并在临床实践和医学教育中具有重要意义 |
| [^154] | [Introducing First-Principles Calculations: New Approach to Group Dynamics and Bridging Social Phenomena in TeNP-Chain Based Social Dynamics Simulations](https://arxiv.org/abs/2403.05593) | 本文介绍了一种利用第一原理计算的新方法，用于桥接量子力学原理与社会系统复杂动力学之间的联系，基于碲纳米颗粒和石墨烯结构特征与社会群体行为模式的隐喻对应。 |
| [^155] | [Eternal Sunshine of the Mechanical Mind: The Irreconcilability of Machine Learning and the Right to be Forgotten](https://arxiv.org/abs/2403.05592) | 人工智能的发展带来了深度学习系统的出现，但在处理这些人工大脑时，如何保护被遗忘的权利仍然是一个挑战。 |
| [^156] | [Optimizing Computer Lab Ergonomics in Universities: A Study on Anthropometric Measurements, Furniture Design, and ANOVA Test](https://arxiv.org/abs/2403.05589) | 提出基于人体测量的家具尺寸适合大学生，以改善计算机实验室人体工程学，研究发现其与现有家具尺寸存在显著差异并更加兼容 |
| [^157] | [Plasmon Resonance Model: Investigation of Analysis of Fake News Diffusion Model with Third Mover Intervention Using Soliton Solution in Non-Complete Information Game under Repeated Dilemma Condition](https://arxiv.org/abs/2403.05585) | 该研究提出了一个新的模型，使用非线性偏微分方程和孤子解方法研究了假新闻在不完全信息博弈中的扩散过程，探讨了各类动者在系统中的相互作用，旨在理解和防止假新闻扩散。 |
| [^158] | [Time2Stop: Adaptive and Explainable Human-AI Loop for Smartphone Overuse Intervention](https://arxiv.org/abs/2403.05584) | Time2Stop开发了一种智能、自适应和可解释的即时自适应干预系统，通过机器学习确定最佳干预时机，引入透明的AI解释进行干预，并通过收集用户反馈建立人-AI循环。 |
| [^159] | [A Cross-Modal Approach to Silent Speech with LLM-Enhanced Recognition](https://arxiv.org/abs/2403.05583) | 通过引入跨模态对齐和大语言模型，提出了一种Multimodal Orofacial Neural Audio系统，成功减少静默语音识别中的词错误率。 |
| [^160] | [Can Interpretability Layouts Influence Human Perception of Offensive Sentences?](https://arxiv.org/abs/2403.05581) | 本文通过用户研究探讨了机器学习解释布局是否会影响参与者对包含仇恨言论句子的评价，结果表明解释布局在触发参与者提供纠正性反馈和评估模型方面具有优势 |
| [^161] | [Cultural Bias in Explainable AI Research: A Systematic Analysis](https://arxiv.org/abs/2403.05579) | XAI研究普遍忽视了潜在的文化差异，过于假设西方解释需求在全球通用。 |
| [^162] | [Chaining text-to-image and large language model: A novel approach for generating personalized e-commerce banners](https://arxiv.org/abs/2403.05578) | 本研究提出了一种新方法，利用文本到图像模型和大型语言模型生成个性化网页横幅，根据用户互动动态内容，并且无需人工干预。 |
| [^163] | [Understanding Subjectivity through the Lens of Motivational Context in Model-Generated Image Satisfaction](https://arxiv.org/abs/2403.05576) | 通过模拟不同激励背景下的主观性因素，研究发现在评估图片时，主观性受图像外观、图像与文本对齐以及文本中提及对象的影响，强调了探究主观性对模型性能的重要性。 |
| [^164] | [HealMe: Harnessing Cognitive Reframing in Large Language Models for Psychotherapy](https://arxiv.org/abs/2403.05574) | 这一创新心理治疗模型HealMe通过基于心理治疗框架的共情对话，有效解决了根深蒂固的负面思维，并促进了理性、平衡的观点。 |
| [^165] | [Is ChatGPT More Empathetic than Humans?](https://arxiv.org/abs/2403.05572) | ChatGPT在回应情绪场景时比人类表现出更高的移情能力，平均移情评分高于人类生成的回应10%；指示ChatGPT在回应中融入对移情的清晰理解使得其回应与高度移情的个体的期望大致接近5倍。 |
| [^166] | [OpenHEXAI: An Open-Source Framework for Human-Centered Evaluation of Explainable Machine Learning](https://arxiv.org/abs/2403.05565) | OpenHEXAI是一个用于人类中心评估可解释机器学习的开源框架，拥有多元化基准数据集、易于使用的用户研究Web应用程序和全面的评估指标。 |
| [^167] | [SDXL Finetuned with LoRA for Coloring Therapy: Generating Graphic Templates Inspired by United Arab Emirates Culture](https://arxiv.org/abs/2403.05562) | 通过将机器学习技术与传统阿联酋图案相融合，在SDXL模型中加入LoRA技术生成具有文化意义的上色模板，将上色疗法与文化共鸣相结合，作为治疗干预和文化保护的有效工具。 |
| [^168] | [Multi-source and multimodal data fusion for predicting academic performance in blended learning university courses](https://arxiv.org/abs/2403.05552) | 该研究应用多源多模态数据融合方法，发现在混合式学习环境中预测学生学术表现的最佳属性集为理论课上的关注程度、Moodle测验成绩以及Moodle论坛上的活动水平。 |
| [^169] | [Teranga Go!: Carpooling Collaborative Consumption Community with multi-criteria hesitant fuzzy linguistic term set opinions to build confidence and trust](https://arxiv.org/abs/2403.05550) | 该论文提出了一种名为二元模糊语言Delphi方法的扩展，通过评估问卷的各个部分来验证整个问卷的有效性，以解决评委展示不同专业程度的场景，并检测影响工具质量的项目。 |
| [^170] | [Monitoring the evolution of antisemitic discourse on extremist social media using BERT](https://arxiv.org/abs/2403.05548) | 本研究提出了一种使用BERT监测极端社交媒体上反犹太主义话语演变的自动方法，避免了手动监测的不可行性，为干预和防止仇恨升级提供了新途径。 |
| [^171] | [AI for non-programmers: Applied AI in the lectures for students without programming skills](https://arxiv.org/abs/2403.05547) | 本研究提出了一个应用AI的教学规划脚本，通过将AI概念与研究相关主题联系起来，促进了学生对AI潜力和风险的理解和兴趣。 |
| [^172] | [From Algorithm Worship to the Art of Human Learning: Insights from 50-year journey of AI in Education](https://arxiv.org/abs/2403.05544) | 本文探讨了人工智能在教育领域的角色复杂性，同时关注了个性化学习、伦理影响、非STEM学科的贬值以及潜在对神经认知和社会情感功能的转变影响，以期为未来教育实践和政策提供启示。 |
| [^173] | [AI in ESG for Financial Institutions: An Industrial Survey](https://arxiv.org/abs/2403.05541) | 本文调查了金融机构中人工智能在ESG倡议中的应用，阐明了AI在加强ESG框架方面的必要性和影响，以及AI如何增强金融活动和可持续发展目标之间的复杂相互作用。 |
| [^174] | [DeepSeek-VL: Towards Real-World Vision-Language Understanding](https://arxiv.org/abs/2403.05525) | DeepSeek-VL是一个面向真实世界的视觉语言理解模型，通过多样化数据、真实场景覆盖和高效编码器的设计，大大提高了在实际应用中的用户体验 |
| [^175] | [Rule-driven News Captioning](https://arxiv.org/abs/2403.05101) | 本文提出了一种基于规则的新闻标题生成方法，通过新闻感知的语义规则，可以生成遵循新闻报道基本规则的图像描述。 |
| [^176] | [Fooling Neural Networks for Motion Forecasting via Adversarial Attacks](https://arxiv.org/abs/2403.04954) | 该研究在人体动作预测领域引入了对抗性攻击，通过实验证实模型即使在低水平的扰动下也容易受到攻击，并展示了对简单旋转和平移敏感的模型性能受影响。 |
| [^177] | [A Mixed-Integer Conic Program for the Moving-Target Traveling Salesman Problem based on a Graph of Convex Sets](https://arxiv.org/abs/2403.04917) | 本文提出了一个新的公式，用于解决移动目标旅行推销员问题，该公式基于目标在空间-时间坐标系内成为凸集的概念，通过在凸集图中寻找最短路径来实现，在实验中表现出比当前Mixed Integer Conic Program (MICP)求解器更好的效果。 |
| [^178] | [Self-Supervision in Time for Satellite Images(S3-TSS): A novel method of SSL technique in Satellite images](https://arxiv.org/abs/2403.04859) | 提出了一种新的卫星图像中的自监督学习方法S3-TSS，利用时间维度中的自然增强，结果显示在四个下游数据集中优于基线方法SeCo。 |
| [^179] | [TopicDiff: A Topic-enriched Diffusion Approach for Multimodal Conversational Emotion Detection](https://arxiv.org/abs/2403.04789) | 提出了一种TopicDiff方法，用于捕获多模态会话情感检测任务中的主题信息，通过将扩散模型集成到神经主题模型中，解决了神经主题模型在捕获主题信息方面的多样性不足问题，并相对于现有MCE基线取得了显著改进 |
| [^180] | [Removing GPT4's Filter](https://arxiv.org/abs/2403.04769) | 提出了一种方法，可以使经过微调的GPT4恢复到没有经过人类反馈强化学习训练的状态，从而移除其在学习期间的所有安全机制 |
| [^181] | [Competitive Facility Location under Random Utilities and Routing Constraints](https://arxiv.org/abs/2403.04264) | 本文研究了在竞争市场背景下的设施选址问题，引入了路径约束，探讨了三种有效割以处理非线性目标函数。 |
| [^182] | [Aligners: Decoupling LLMs and Alignment](https://arxiv.org/abs/2403.04224) | 提出了一种通过训练对齐器模型来解耦大型语言模型（LLMs）和对齐，以减少对齐对性能的潜在负面影响。 |
| [^183] | [Can Large Language Models Reason and Plan?](https://arxiv.org/abs/2403.04121) | 大型语言模型缺乏自我批评能力，无法像人类一样纠正错误。 |
| [^184] | [Personalizing explanations of AI-driven hints to users cognitive abilities: an empirical evaluation](https://arxiv.org/abs/2403.04035) | 该研究调查了如何个性化智能辅导系统生成的提示的解释，以帮助促进学生学习，实证结果表明，该个性化方法显著提高了目标用户与提示解释的互动、理解和学习效果。 |
| [^185] | [Are Language Models Puzzle Prodigies? Algorithmic Puzzles Unveil Serious Challenges in Multimodal Reasoning](https://arxiv.org/abs/2403.03864) | 这项研究提出了多模态解谜任务AlgoPuzzleVQA，通过算法谜题挑战评估了多模态语言模型在需要视觉理解、语言理解和复杂算法推理的能力，旨在评估视觉数据解释与算法问题解决能力之间的差距。 |
| [^186] | [DeepCRE: Revolutionizing Drug R&D with Cutting-Edge Computational Models](https://arxiv.org/abs/2403.03768) | DeepCRE是一种新型的计算模型，在患者级别CRE性能上平均提高了17.7％，在指示级别CRE增加了5倍，并成功确定了六个具有显着优势的药物候选者。 |
| [^187] | [Apollo: Lightweight Multilingual Medical LLMs towards Democratizing Medical AI to 6B People](https://arxiv.org/abs/2403.03640) | Apollo项目开发了多语言医学LLMs，创建了全球人口61亿的医学数据集，并发布了各种尺寸的最佳性能模型，其中Apollo-7B是最先进的多语言医学LLMs，可改善更大模型的多语言医学能力。 |
| [^188] | [The Case for Globalizing Fairness: A Mixed Methods Study on Colonialism, AI, and Health in Africa](https://arxiv.org/abs/2403.03357) | 该研究探讨了全球卫生公平性，以非洲为案例研究，通过范围审查和定性研究揭示了ML技术在非洲健康领域中可能出现的不公平现象，并特别关注殖民主义作为一个重要属性。 |
| [^189] | ["In Dialogues We Learn": Towards Personalized Dialogue Without Pre-defined Profiles through In-Dialogue Learning](https://arxiv.org/abs/2403.03102) | 提出了一种In-Dialogue Learning框架，通过对话历史刻画个人设来完成个性化对话生成任务，无需预定义个人资料，并在实验证明其显著改进对话生成性能。 |
| [^190] | [NASH: Neural Architecture Search for Hardware-Optimized Machine Learning Models](https://arxiv.org/abs/2403.01845) | NASH是一种将神经架构搜索应用于机器学习硬件的新方法，可以帮助硬件设计实现高吞吐量、低延迟和优越的准确性表现。 |
| [^191] | [GPTSee: Enhancing Moment Retrieval and Highlight Detection via Description-Based Similarity Features](https://arxiv.org/abs/2403.01437) | 该研究提出了一个新颖的两阶段模型，将大型语言模型（LLMs）的输出用作第二阶段变压器编码器-解码器的输入，实现了时刻检索和重点检测的最先进结果。 |
| [^192] | [PRIME: Scaffolding Manipulation Tasks with Behavior Primitives for Data-Efficient Imitation Learning](https://arxiv.org/abs/2403.00929) | PRIME是一个基于行为原语设计的框架，通过将任务分解为原语序列并学习高级控制策略，显著提高了多阶段操作任务的性能表现。 |
| [^193] | [Direct Alignment of Draft Model for Speculative Decoding with Chat-Fine-Tuned LLMs](https://arxiv.org/abs/2403.00858) | 通过提出的框架，我们训练了一种用于Llama 2 Chat 7B或更大模型的草案模型，实现了加速推理，仅占原始大小的1.64％。 |
| [^194] | [TV-TREES: Multimodal Entailment Trees for Neuro-Symbolic Video Reasoning](https://arxiv.org/abs/2402.19467) | TV-TREES是第一个多模态蕴涵树生成器，通过生成视频直接蕴涵的简单前提与高级结论之间的蕴涵关系树，实现了可解释联合模态推理，并在挑战性的TVQA数据集上展示了最先进的零-shot性能。 |
| [^195] | [Survey in Characterization of Semantic Change](https://arxiv.org/abs/2402.19088) | 语义变化对计算语言学算法的结果质量可能会产生影响，因此重要性日益凸显。 |
| [^196] | [ICE-SEARCH: A Language Model-Driven Feature Selection Approach](https://arxiv.org/abs/2402.18609) | ICE-SEARCH是首个将语言模型与进化算法相结合用于特征选择任务的方法，在医学预测分析应用中取得了State-of-the-Art(SOTA)表现。 |
| [^197] | [MMSR: Symbolic Regression is a Multimodal Task](https://arxiv.org/abs/2402.18603) | 符号回归被视为一个多模态任务，研究人员将数据到表达式的映射视为翻译问题，引入大规模预训练模型。 |
| [^198] | [LDB: A Large Language Model Debugger via Verifying Runtime Execution Step-by-step](https://arxiv.org/abs/2402.16906) | LDB是一个新颖的调试框架，可以让大型语言模型通过运行时执行信息来完善生成的程序。 |
| [^199] | [MIM-Reasoner: Learning with Theoretical Guarantees for Multiplex Influence Maximization](https://arxiv.org/abs/2402.16898) | 引入了MIM-Reasoner，结合强化学习和概率图模型，有效地捕捉了给定多重网络内部和层间的复杂传播过程，从而解决了MIM中最具挑战性的问题。 |
| [^200] | [LLM Inference Unveiled: Survey and Roofline Model Insights](https://arxiv.org/abs/2402.16363) | 本文提出了一个基于Roofline模型的框架，用于系统分析LLM推断技术，帮助识别部署中的瓶颈，并为更有效地部署LLM提供策略。 |
| [^201] | [A Self-matching Training Method with Annotation Embedding Models for Ontology Subsumption Prediction](https://arxiv.org/abs/2402.16278) | 提出了一种自匹配训练方法，通过两种本体嵌入模型捕获全局和局部信息，提高了概念子类预测的稳健性 |
| [^202] | [Emotion Classification in Short English Texts using Deep Learning Techniques](https://arxiv.org/abs/2402.16034) | 该研究使用深度学习技术在短英文文本中识别情绪，发现基于迁移学习和BERT的文本嵌入方法在分类准确性上表现优异。 |
| [^203] | [Random Graph Set and Evidence Pattern Reasoning Model](https://arxiv.org/abs/2402.13058) | 提出了证据模式推理模型（EPRM）以更好地符合决策目标，引入随机图集（RGS）来模拟复杂关系并表示更多事件类型。 |
| [^204] | [Me LLaMA: Foundation Large Language Models for Medical Applications](https://arxiv.org/abs/2402.12749) | Me LLaMA是一个医学领域的大型语言模型系列，通过持续预训练和指导调整在大型医学数据集上训练而成，其在零-shot和少-shot学习方面表现优于现有的医学语言模型和商业巨头ChatGPT。 |
| [^205] | [Model Editing by Pure Fine-Tuning](https://arxiv.org/abs/2402.11078) | 纯微调通过优化条件似然、增加随机释义和事实的数据，在模型编辑中取得了不俗的表现。 |
| [^206] | [Unlink to Unlearn: Simplifying Edge Unlearning in GNNs](https://arxiv.org/abs/2402.10695) | 研究揭示了GNN中边解除过程的关键问题，即过度遗忘现象，提出了解决方法来解决损失函数引起的问题。 |
| [^207] | [Guiding Masked Representation Learning to Capture Spatio-Temporal Relationship of Electrocardiogram](https://arxiv.org/abs/2402.09450) | 本研究提出了一种叫做ST-MEM的模型，通过重构遮蔽的心电图数据来学习时空特征，该模型在心律失常分类任务中优于其他自监督学习方法。 |
| [^208] | [On the Detection of Reviewer-Author Collusion Rings From Paper Bidding](https://arxiv.org/abs/2402.07860) | 本文研究了如何从论文竞标中检测勾结团体，以解决同行评审系统中的欺诈问题。 |
| [^209] | [Group Distributionally Robust Dataset Distillation with Risk Minimization](https://arxiv.org/abs/2402.04676) | 这项研究关注数据集蒸馏与其泛化能力的关系，尤其是在面对不常见的子组的样本时，如何确保模型在合成数据集上的训练可以表现良好。 |
| [^210] | [Can Large Language Model Agents Simulate Human Trust Behaviors?](https://arxiv.org/abs/2402.04559) | 大语言模型代理能够模拟人类的信任行为，表现出在信任游戏中的信任行为，并且与人类行为具有高度一致性，但存在一些偏见和对代理与人类的差异。 |
| [^211] | [Leveraging Swin Transformer for Local-to-Global Weakly Supervised Semantic Segmentation](https://arxiv.org/abs/2401.17828) | 本研究利用Swin Transformer提出了"SWTformer"，通过从局部到全局的视角来增强弱监督语义分割的准确性。 |
| [^212] | [Local Feature Matching Using Deep Learning: A Survey](https://arxiv.org/abs/2401.17592) | 本文调查了使用深度学习进行局部特征匹配的方法。局部特征匹配在计算机视觉中的各个领域具有广泛应用，但是由于视角和光照变化等因素，匹配的准确性和鲁棒性仍然存在挑战。近年来，深度学习模型的引入使得局部特征匹配技术得到了广泛研究。本文对局部特征匹配方法进行了全面概述，并对之前的工作进行了评估。 |
| [^213] | [Arrows of Time for Large Language Models](https://arxiv.org/abs/2401.17505) | 这篇论文通过研究自回归大型语言模型的时间方向性，发现了模型在建模自然语言能力上存在时间上的不对称性。从信息理论的角度来看，这种差异理论上是不应该存在的。通过稀疏性和计算复杂性的考虑，提供了一个理论框架来解释这种不对称性的出现。 |
| [^214] | [Adversarial Training on Purification (AToP): Advancing Both Robustness and Generalization](https://arxiv.org/abs/2401.16352) | 提出了一种新的对净化的对抗训练（AToP）流程，通过随机转换的扰动破坏和通过对抗损失微调净化器模型，同时提升了鲁棒性和泛化性能。 |
| [^215] | [Large receptive field strategy and important feature extraction strategy in 3D object detection](https://arxiv.org/abs/2401.11913) | 提出了动态特征融合模块（DFFM）来扩展3D卷积核的感知域，并使用特征选择模块（FSM）定量评估和消除不重要的特征。 |
| [^216] | [Generative AI in EU Law: Liability, Privacy, Intellectual Property, and Cybersecurity](https://arxiv.org/abs/2401.07348) | 生成式人工智能和大型语言模型在欧盟法律法规中的应用引发了责任、隐私、知识产权和网络安全等方面的挑战，本文对现有和拟议的法律进行了批判性分析，并提出了改进建议。 |
| [^217] | [State Machine of Thoughts: Leveraging Past Reasoning Trajectories for Enhancing Problem Solving](https://arxiv.org/abs/2312.17445) | 通过利用过去推理轨迹的经验，提出的思维状态机（SMoT）可以显著改善问题解决能力，选择最优解决方案并避免错误的解决方案。 |
| [^218] | [Alleviating Hallucinations of Large Language Models through Induced Hallucinations](https://arxiv.org/abs/2312.15710) | 通过诱导虚假信息来构建一个事实薄弱的语言模型，并在解码过程中通过对比解码来惩罚这些诱导的虚假信息，从而有效提升生成内容的真实性。 |
| [^219] | [Synergistic Anchored Contrastive Pre-training for Few-Shot Relation Extraction](https://arxiv.org/abs/2312.12021) | 新提出了一种协同对比预训练框架，利用大量的实例-标签对来丰富学习到的表示 |
| [^220] | [Learning Unknown Intervention Targets in Structural Causal Models from Heterogeneous Data](https://arxiv.org/abs/2312.06091) | 在结构因果模型中，通过两阶段方法学习未知干预目标的外生噪声，并将其与相应的内生变量匹配，有效地识别干预目标。 |
| [^221] | [Redefining Developer Assistance: Through Large Language Models in Software Ecosystem](https://arxiv.org/abs/2312.05626) | 本研究介绍了一种通过指导调整开发的DevAssistLlama模型，在处理软件相关自然语言查询时表现出优异能力，突出了专门LLM在软件开发中的潜力。 |
| [^222] | [Self Model for Embodied Intelligence: Modeling Full-Body Human Musculoskeletal System and Locomotion Control with Hierarchical Low-Dimensional Representation](https://arxiv.org/abs/2312.05473) | 本研究提出了一个包含90个身体段、206个关节和700个肌腱单位的肌肉骨骼模型，以及使用低维表示和分层深度强化学习的新算法，实现了最先进的全身控制。 |
| [^223] | [Breaking the Entanglement of Homophily and Heterophily in Semi-supervised Node Classification](https://arxiv.org/abs/2312.04111) | 开发了一个可以在同质性和异质性下保证性能的强大GNN模型 |
| [^224] | [Towards Assessing and Benchmarking Risk-Return Tradeoff of Off-Policy Evaluation](https://arxiv.org/abs/2311.18207) | 该研究提出了一种新的指标 SharpeRatio@k，用于评估离策略评估的风险-收益权衡，能够有效区分不同风险估计器并准确识别最高效的估计器。 |
| [^225] | [SCOPE-RL: A Python Library for Offline Reinforcement Learning and Off-Policy Evaluation](https://arxiv.org/abs/2311.18206) | SCOPE-RL是一个Python库，兼顾离线强化学习和离策略评估，通过整合策略学习和评估实现了更灵活、完整的实现方式，并通过OPE模块提供了多种OPE估计器和稳健的OPE协议，使得OPE更深入和可靠。 |
| [^226] | [TFMQ-DM: Temporal Feature Maintenance Quantization for Diffusion Models](https://arxiv.org/abs/2311.16503) | TFMQ-DM提出了一种称为Temporal Feature Maintenance Quantization (TFMQ)的方法，针对扩散模型中的时间特征进行量化，解决了传统模型中存在的优化问题，提高了压缩效率。 |
| [^227] | [Unbalancedness in Neural Monge Maps Improves Unpaired Domain Translation](https://arxiv.org/abs/2311.15100) | 在神经蒙日映射中引入不平衡性可改进未配对领域转换任务的效率和鲁棒性 |
| [^228] | [Mobile-Seed: Joint Semantic Segmentation and Boundary Detection for Mobile Robots](https://arxiv.org/abs/2311.12651) | Mobile-Seed是一个轻量级的双任务框架，旨在同时进行语义分割和边界检测，具有双流编码器、主动融合解码器和双任务正则化方法。 |
| [^229] | [Generating Progressive Images from Pathological Transitions via Diffusion Model](https://arxiv.org/abs/2311.12316) | 提出了一种自适应深度控制扩散（ADD）网络，通过混合式注意力策略指导双向扩散，实现有效的病理渐进图像生成。 |
| [^230] | [VERVE: Template-based ReflectiVE Rewriting for MotiVational IntErviewing](https://arxiv.org/abs/2311.08299) | 这项工作引入了 counseling response rewriting 任务，提出了基于模板的 VERVE 系统，通过加入释义的训练和自适应模板更新，将非反思性陈述转化为反思性回应。 |
| [^231] | [LRM: Large Reconstruction Model for Single Image to 3D](https://arxiv.org/abs/2311.04400) | 首次提出了LRM，采用大规模训练数据和高容量模型，可在短时间内从单个图像中预测高质量3D重建结果 |
| [^232] | [Selective Visual Representations Improve Convergence and Generalization for Embodied AI](https://arxiv.org/abs/2311.04193) | 引入了一种参数高效的方法，在具身智能中使用任务条件的选择性过滤器来改善收敛性和泛化性能 |
| [^233] | [LLM4VV: Developing LLM-Driven Testsuite for Compiler Validation](https://arxiv.org/abs/2310.04963) | 本研究开发了一个基于LLM的测试套件，用于验证编译器实现，探索了各种LLMs并使用不同的提示工程技术进行微调。 |
| [^234] | [From Text to Self: Users' Perceptions of Potential of AI on Interpersonal Communication and Self](https://arxiv.org/abs/2310.03976) | 用户对大型语言模型驱动的工具在人际交流方面的能力持积极看法，认为可以增加沟通自信、帮助表达想法以及克服语言和文化障碍，但也揭示出工具存在的一些局限性和用户关于技术不真实性和过度依赖的担忧。 |
| [^235] | [Visual Political Communication in a Polarized Society: A Longitudinal Study of Brazilian Presidential Elections on Instagram](https://arxiv.org/abs/2310.00349) | 该研究通过纵向研究巴西总统候选人在Instagram上发布的帖子，揭示了视觉政治传播中固定的模式，包括庆祝和积极调性图像的普遍使用以及候选人与选民紧密联系的个性化展示。 |
| [^236] | [Scene Informer: Anchor-based Occlusion Inference and Trajectory Prediction in Partially Observable Environments](https://arxiv.org/abs/2309.13893) | 场景通知者是一种统一方法，用于在部分可观察的环境中预测观察代理的轨迹和推断遮挡，其利用transformer聚合输入模态并实现对可能与自主车辆计划路径相交的遮挡的选择性查询。 |
| [^237] | [Rethinking Mobile AI Ecosystem in the LLM Era](https://arxiv.org/abs/2308.14363) | 重新思考移动AI生态系统，引入了一种基于协作管理的范式，通过在NPU内部放置不受应用或操作系统修订影响的基础模型，以及每个应用贡献特定的适配器，为广泛移动AI任务提供服务。 |
| [^238] | [Strategic Preys Make Acute Predators: Enhancing Camouflaged Object Detectors by Generating Camouflaged Objects](https://arxiv.org/abs/2308.03166) | 通过对抗训练框架Camouflageator生成更难以被检测到的伪装对象，从而增强伪装物体检测，解决了现有伪装物体检测器在挑战性案例中的精确性问题。 |
| [^239] | [Node-weighted Graph Convolutional Network for Depression Detection in Transcribed Clinical Interviews](https://arxiv.org/abs/2307.00920) | 提出了一种基于节点加权的图卷积网络方法，用于在临床面谈转录中检测抑郁症，相较于传统方法，在两个数据集上取得了更好的效果。 |
| [^240] | [Defending Against Malicious Behaviors in Federated Learning with Blockchain](https://arxiv.org/abs/2307.00543) | 该研究提出了一个基于区块链和分布式分类账技术的安全和可靠的联邦学习系统，包括点对点投票机制和奖励和惩罚机制，以检测和阻止恶意行为，证明了该框架对抗恶意客户的有效性。 |
| [^241] | [TransERR: Translation-based Knowledge Graph Embedding via Efficient Relation Rotation](https://arxiv.org/abs/2306.14580) | TransERR是一种基于翻译的知识图嵌入方法，采用超复值空间编码知识图，在模型训练中通过适应性旋转头实体和尾实体来最小化翻译距离，并具有有效建模不同关系模式的能力。 |
| [^242] | [Deep Classifier Mimicry without Data Access](https://arxiv.org/abs/2306.02090) | 提出了一种无需访问原始数据的模型-无关知识蒸馏过程CAKE，可以模拟深度分类器，通过生成噪声合成样本对比地扩散到模型的决策边界。 |
| [^243] | [Visual CPG-RL: Learning Central Pattern Generators for Visually-Guided Quadruped Locomotion](https://arxiv.org/abs/2212.14400) | 该论文提出了一个框架，通过将外感知传感和中枢模式发生器整合到深度强化学习框架中，学习视觉引导的四足动物运动，探索了耦合振荡器系统对导航鲁棒性的改进、具有记忆功能的策略网络与无记忆策略网络在导航任务中的效果以及动物如何容忍高。 |
| [^244] | [Limited or Biased: Modeling Sub-Rational Human Investors in Financial Markets](https://arxiv.org/abs/2210.08569) | 该研究引入了一个灵活模型，利用强化学习结合五个不同方面的人类次理性，在金融市场模拟中准确重现了先前研究中观察到的行为特征。 |
| [^245] | [Machine Learning-Powered Course Allocation](https://arxiv.org/abs/2210.00954) | 引入机器学习驱动的课程分配机制（MLCM），通过机器学习模块减轻学生在报告偏好时的错误，显著提高学生效用，且具有对环境变化的稳健性。 |
| [^246] | [OpenXAI: Towards a Transparent Evaluation of Model Explanations](https://arxiv.org/abs/2206.11104) | OpenXAI 是一个开源框架，旨在评估和基准测试后续解释方法，提供了灵活的数据生成器、多种数据集和评估指标，用户可轻松扩展和比较不同解释方法。 |
| [^247] | [Deep Reinforcement Learning with Spiking Q-learning](https://arxiv.org/abs/2201.09754) | 基于脉冲Q学习的深度强化学习方法DSQN利用非脉冲神经元的膜电压作为Q值表示，实现了能源高效的控制任务。 |
| [^248] | [Unveiling Project-Specific Bias in Neural Code Models](https://arxiv.org/abs/2201.07381) | 神经代码模型在训练和测试时表现出可观的性能，但往往无法有效地推广到跨项目分布的数据，原因在于过度依赖项目特定快捷方式进行预测。我们提出了一种量化项目特定性的度量Cond-Idf，并指出模型倾向于利用虚假统计线索进行预测。 |
| [^249] | [Generalizing Graph Neural Networks on Out-Of-Distribution Graphs](https://arxiv.org/abs/2111.10657) | 提出了一个名为StableGNN的通用因果表示框架，通过提取高级图表示并利用因果推断的区分能力，帮助模型在分布外图上实现稳定的泛化能力。 |
| [^250] | [Quantifying intrinsic causal contributions via structure preserving interventions](https://arxiv.org/abs/2007.00714) | 该论文提出一种通过结构保持干预来量化节点对目标节点的固有因果贡献的方法，从而将因果信息与祖先节点信息分离，并提出了对方差和熵的贡献分析。 |
| [^251] | [True Knowledge Comes from Practice: Aligning LLMs with Embodied Environments via Reinforcement Learning.](http://arxiv.org/abs/2401.14151) | 本研究通过使用大型语言模型（LLMs）作为决策智能体，通过强化学习与具身环境高效互动来解决LLMs与环境之间知识不对齐的问题。通过查询LLMs的联合概率，形成行为策略，并通过两种归一化方法和四个提示设计原则提高策略的稳定性和鲁棒性。最后，通过设计参数高效的训练架构提高学习效率。 |
| [^252] | [Compositional Generative Inverse Design.](http://arxiv.org/abs/2401.13171) | 逆向设计起到优化底层目标函数的作用，最近的研究利用了学习的动力学模型进行优化。通过优化扩散模型捕获的学习能量函数，可以避免对抗示例，并显著提高设计性能。这一设计系统是组合性的，使得可以设计具有每个指定组件的系统。 |
| [^253] | [Top in Chinese Data Processing: English Code Models.](http://arxiv.org/abs/2401.10286) | 在中文数据处理中，基于代码的语言模型在非编程中文任务中表现出色，尤其是在对中文幻觉敏感的任务中。此研究为讨论“中文房间”思想实验提供了独特的视角。 |
| [^254] | [Learning from Sparse Offline Datasets via Conservative Density Estimation.](http://arxiv.org/abs/2401.08819) | 本文提出了一种名为保守密度估计（CDE）的训练算法，通过明确约束状态-行为占据稳态分布来解决离线强化学习中的外推错误问题。在稀疏奖励或不足数据的任务中，CDE显示出明显优于基准方法的性能。 |
| [^255] | [InfiAgent-DABench: Evaluating Agents on Data Analysis Tasks.](http://arxiv.org/abs/2401.05507) | InfiAgent-DABench是第一个评估基于LLM的代理在数据分析任务中的基准测试，包括DAEval数据集和代理框架。对23个最先进的LLMs进行的基准测试揭示了当前数据分析任务中的挑战。 |
| [^256] | [The inherent goodness of well educated intelligence.](http://arxiv.org/abs/2401.04846) | 本文探讨了智能体变得智能的因素，强调了掌握特征和控制多个保守相互作用的子系统的能力。智能的核心是“集体如一体”和“了解局部行动的整体结果”。文章提出了一种对集体保守系统进行控制的替代方法。 |
| [^257] | [Phishing Website Detection through Multi-Model Analysis of HTML Content.](http://arxiv.org/abs/2401.04820) | 本研究提出了一种基于HTML内容的高级检测模型，集成了多层感知器和预训练的自然语言处理模型，通过新颖的融合方法检测网络钓鱼网站。同时，我们还创造了一个最新的数据集来支持这项研究。 |
| [^258] | [SecureReg: A Combined Framework for Proactively Exposing Malicious Domain Name Registrations.](http://arxiv.org/abs/2401.03196) | SecureReg是一个结合了自然语言处理和多层感知器模型的方法，用于在域名注册过程中主动暴露恶意域名注册，提供了早期威胁检测的解决方案，显著减少了漏洞窗口，并为主动预防性操作做出了贡献。 |
| [^259] | [A white box solution to the black box problem of AI.](http://arxiv.org/abs/2401.03093) | 一种解决人工智能黑盒问题的白盒解决方案是使用基于相关领域一般理论的确定性逻辑细胞自动机的规则，该细胞自动机实现自动并行逻辑推理。 |
| [^260] | [On the Expressive Power of Graph Neural Networks.](http://arxiv.org/abs/2401.01626) | 研究人员对图神经网络的表达能力和设计架构进行了大量工作，以提高其在各领域任务中的性能。主要方法包括研究GNN的通用逼近性质和其在区分不同图之间的能力程度。 |
| [^261] | [Plug-and-Play Policy Planner for Large Language Model Powered Dialogue Agents.](http://arxiv.org/abs/2311.00262) | 基于大型语言模型的对话代理的即插即用策略规划器(PDDPP)引入了一种新的对话策略规划范式，通过可调整的语言模型插件实现主动对话问题的策略制定。利用监督微调和强化学习，该框架在处理新的案例时具有较高的灵活性和性能。 |
| [^262] | [CycleNet: Rethinking Cycle Consistency in Text-Guided Diffusion for Image Manipulation.](http://arxiv.org/abs/2310.13165) | CycleNet是一种将循环一致性引入扩散模型的新方法，用于规范图像操作，具有优越的翻译一致性和质量，并且可以生成高质量的跨领域分布图像。 |
| [^263] | [Towards Robust Offline Reinforcement Learning under Diverse Data Corruption.](http://arxiv.org/abs/2310.12955) | 本文研究了在多种数据损坏情况下，离线强化学习算法的性能。研究发现，隐式Q-learning（IQL）在各种离线强化学习算法中展现出了较强的鲁棒性能，其采用的监督策略学习方案为关键。然而，在动力学损坏下，IQL仍然存在Q函数的重尾目标问题。 |
| [^264] | [In-Context Pretraining: Language Modeling Beyond Document Boundaries.](http://arxiv.org/abs/2310.10638) | 本论文提出了一种超越文档边界的上下文预训练方法，通过在相关文档序列上训练语言模型，鼓励模型进行跨文档的阅读和推理。该方法通过改变文档顺序并应用现有的预训练管道来实现。 |
| [^265] | [SiamAF: Learning Shared Information from ECG and PPG Signals for Robust Atrial Fibrillation Detection.](http://arxiv.org/abs/2310.09203) | 提出了一种名为SiamAF的新方法，利用心电图和光电脉搏图信号的共享信息，通过Siamese网络和联合学习实现强健的心房颤动（AF）检测。 |
| [^266] | [METRA: Scalable Unsupervised RL with Metric-Aware Abstraction.](http://arxiv.org/abs/2310.08887) | METRA提出了一种新的无监督强化学习目标，旨在使其在复杂的高维环境中可扩展。这个目标解决了纯探索方法在大状态空间环境中的困难以及互信息技能学习方法中缺乏激励而无法探索环境的问题。 |
| [^267] | [InstructDET: Diversifying Referring Object Detection with Generalized Instructions.](http://arxiv.org/abs/2310.05136) | 我们提出了一种名为InstructDET的方法，可以通过多样化的指令定位目标对象并进行指称对象检测。我们构建了一个包含图像、边界框和泛化指令的数据集，其中利用了视觉语言模型和大型语言模型生成指令。 |
| [^268] | [Training-free Linear Image Inversion via Flows.](http://arxiv.org/abs/2310.04432) | 提出了一种无需训练的线性图像反演方法，通过使用预训练的流模型，在减少手动调整的情况下解决逆问题。 |
| [^269] | [Accurate Cold-start Bundle Recommendation via Popularity-based Coalescence and Curriculum Heating.](http://arxiv.org/abs/2310.03813) | 本文提出了CoHeat算法，一种准确的冷启动捆绑推荐方法。该算法通过结合历史和关联信息，应对捆绑互动分布的倾斜，并有效地学习潜在表示。 |
| [^270] | [Diffusion Generative Flow Samplers: Improving learning signals through partial trajectory optimization.](http://arxiv.org/abs/2310.02679) | 这项工作介绍了一种名为扩散生成流采样器（DGFS）的采样框架，通过将学习过程分解为短的部分轨迹段，实现从难以处理的高维密度函数中进行采样。它通过利用中间的学习信号和非策略探索能力来改善学习信号的分配问题。 |
| [^271] | [Understanding and Mitigating the Label Noise in Pre-training on Downstream Tasks.](http://arxiv.org/abs/2309.17002) | 本文研究了深度学习中预训练数据中的标签噪声对下游任务的影响，并通过在合成噪声数据集上的实验证明，在预训练中的轻微噪声可以提高领域内的性能，但会损害领域外的性能。为了减轻噪声的影响，提出了一种轻量级的黑盒调整方法（NMTune）。 |
| [^272] | [ModuLoRA: Finetuning 3-Bit LLMs on Consumer GPUs by Integrating with Modular Quantizers.](http://arxiv.org/abs/2309.16119) | ModuLoRA提出了一种内存高效、能够在消费级GPU上支持3比特LLMs微调的方法，并通过与模块化量化器的集成实现了竞争性能和更少的内存使用。 |
| [^273] | [STARC: A General Framework For Quantifying Differences Between Reward Functions.](http://arxiv.org/abs/2309.15257) | 这篇论文提出了一个通用框架（STARC），用于评估奖励函数之间的差异，填补了奖励学习理论基础的空白。 |
| [^274] | [Navigating Text-To-Image Customization:From LyCORIS Fine-Tuning to Model Evaluation.](http://arxiv.org/abs/2309.14859) | 本文介绍了LyCORIS，一个开源库，提供了多种稳定扩散模型的微调方法，并提出了一个系统评估的全面框架。 |
| [^275] | [LMSYS-Chat-1M: A Large-Scale Real-World LLM Conversation Dataset.](http://arxiv.org/abs/2309.11998) | LMSYS-Chat-1M是一个包含一百万个实际对话的大规模数据集，通过其多样性和用例展示了其在理解和推进LLM能力方面的价值。 |
| [^276] | [Exploring Self-Reinforcement for Improving Learnersourced Multiple-Choice Question Explanations with Large Language Models.](http://arxiv.org/abs/2309.10444) | 本文提出了一个自我强化大型语言模型框架，自动生成和评估学生生成的解释，用于改进学生资源共享中学生生成的多项选择题的解释质量。 |
| [^277] | [DoLa: Decoding by Contrasting Layers Improves Factuality in Large Language Models.](http://arxiv.org/abs/2309.03883) | DoLa通过对比不同层次的逻辑差异，提高大型语言模型中的真实性和减少幻觉，无需外部知识或微调。 |
| [^278] | [CodeApex: A Bilingual Programming Evaluation Benchmark for Large Language Models.](http://arxiv.org/abs/2309.01940) | CodeApex是一个双语编程评估基准，用于评估大型语言模型在编程理解和代码生成任务上的能力。该基准包括多个选择题和算法问题，评估了14个LLM的编程能力，并发现仍有改进空间。 |
| [^279] | [Empowering LLM to use Smartphone for Intelligent Task Automation.](http://arxiv.org/abs/2308.15272) | 本论文提出了AutoDroid，一个移动任务自动化系统，可以在任何Android应用程序上自动处理任意任务。它通过结合LLMs的常识知识和应用的领域特定知识来实现，通过自动化的动态分析来实现功能意识的UI表示方法和基于探索的内存注入技术。 |
| [^280] | [SICNN: Soft Interference Cancellation Inspired Neural Network Equalizers.](http://arxiv.org/abs/2308.12591) | SICNN是基于神经网络的均衡方法，通过深度展开基于模型的迭代SIC方法来设计，消除了基于模型方法的缺点。 |
| [^281] | [Large Language Models for Software Engineering: A Systematic Literature Review.](http://arxiv.org/abs/2308.10620) | 通过系统性文献综述，本研究调查了大规模语言模型（LLM）在软件工程领域中的应用，并集中于了解如何利用LLM来优化软件工程过程和结果。文章总结了不同LLM的特点和用途以及数据收集和预处理方法的重要性。 |
| [^282] | [Improving Audio-Visual Speech Recognition by Lip-Subword Correlation Based Visual Pre-training and Cross-Modal Fusion Encoder.](http://arxiv.org/abs/2308.08488) | 本文提出了通过基于嘴唇-音素字级相关性的视觉预训练和跨模态融合编码器来改进视听语音识别的两种新技术。这些技术可以在预训练和微调阶段准确对齐音频和视频流，并且充分利用模态互补性。 |
| [^283] | [Deep Bradley-Terry Rating: Estimate Properties Without Metric of Unseen Items.](http://arxiv.org/abs/2307.13709) | 本论文提出了深度布拉德利-特里评分（DBTR）方法，用于评估不一定存在于数据集中的未知物品的属性。该方法通过将传统的布拉德利-特里模型与神经网络结构无缝结合，成功地学习了这些属性的预期量化。 |
| [^284] | [HIQL: Offline Goal-Conditioned RL with Latent States as Actions.](http://arxiv.org/abs/2307.11949) | 本文提出了一个基于离线数据的目标导向强化学习的分层算法，通过利用目标达成问题的结构，使用一个无动作的价值函数学习了两个策略，从而在学习过程中更有效地利用离线数据。 |
| [^285] | [Overthinking the Truth: Understanding how Language Models Process False Demonstrations.](http://arxiv.org/abs/2307.09476) | 该论文研究了现代语言模型在处理虚假演示时出现的过度思考和错误归纳头现象。通过研究模型的内部表示，发现模型在中间层之后对错误演示的处理准确性逐渐降低，并指出了错误归纳头机制可能导致过度思考现象。 |
| [^286] | [Scaling Laws for Imitation Learning in NetHack.](http://arxiv.org/abs/2307.09423) | 本文研究了在NetHack游戏中的模仿学习，发现通过扩大模型和数据规模可以改进模仿学习的效果，并建立了训练计算最优IL代理人的幂律。 |
| [^287] | [Combating Data Imbalances in Federated Semi-supervised Learning with Dual Regulators.](http://arxiv.org/abs/2307.05358) | 本文提出了一种带有双调节器的新型联邦半监督学习框架FedDure，解决了数据分布不平衡的问题。通过粗调节器和细调节器对本地模型的更新进行规范，以及学习适应性加权方案，适应不同的数据分布。 |
| [^288] | [DeepOnto: A Python Package for Ontology Engineering with Deep Learning.](http://arxiv.org/abs/2307.03067) | DeepOnto是一个Python包，用于深度学习本体工程。它通过集成深度学习框架和本体API，提供了丰富的工具和算法，支持本体工程任务，如本体对齐和完成。 |
| [^289] | [Image Matters: A New Dataset and Empirical Study for Multimodal Hyperbole Detection.](http://arxiv.org/abs/2307.00209) | 本研究提出了一个新的多模态夸张检测数据集，并使用文本和图像作为两种模态进行研究。同时，评估了不同预训练的多模态编码器在此任务中的表现。该研究探索了夸张检测的跨领域性能。 |
| [^290] | [Group-based Robustness: A General Framework for Customized Robustness in the Real World.](http://arxiv.org/abs/2306.16614) | 本研究提出了一种基于群体的鲁棒性指标，可以更好地评估机器学习模型在现实世界中抵抗攻击的能力，弥补了传统指标的不足。实验证明，该指标能够区分模型对特定威胁的脆弱性。 |
| [^291] | [Optimized Vectorizing of Building Structures with Swap: High-Efficiency Convolutional Channel-Swap Hybridization Strategy.](http://arxiv.org/abs/2306.15035) | 本论文提出了一种高效的卷积通道交换混合策略（Swap），用于优化建筑结构的向量化。该方法通过将相邻或对角特征交替交换并混合不同通道的信息，实现了集成局部特征空间信息的功能。同时，采用了基于组的参数共享机制，大大减少了模型中的冗余参数。 |
| [^292] | [BeMap: Balanced Message Passing for Fair Graph Neural Network.](http://arxiv.org/abs/2306.04107) | 本文提出了一种公平的消息传递方法，称为BeMap，旨在解决消息传递中的偏差放大问题，通过平衡感知的采样策略来平衡不同人口群体的1-hop邻居的数量。 |
| [^293] | [Explainability in Simplicial Map Neural Networks.](http://arxiv.org/abs/2306.00010) | 本文提出了简单形式映射神经网络（SMNN）的训练过程和替代凸多面体的方法，并且首次引入了 SMNN 的可解释性能力。 |
| [^294] | [Prediction Error-based Classification for Class-Incremental Learning.](http://arxiv.org/abs/2305.18806) | 本论文提出了一种新的增量学习分类方法——基于预测误差的分类方法（PEC）。对PEC的评估表明，在各种基准测试中，PEC可以与最先进的增量学习方法相竞争，并具有许多实际优势，例如样本效率高、易于调整。 |
| [^295] | [HiFA: High-fidelity Text-to-3D with Advanced Diffusion Guidance.](http://arxiv.org/abs/2305.18766) | 该论文提出了一种高保真度的文本到3D图像合成方法，并引入了先进的扩散引导策略。通过对NeRF渲染图像进行辅助深度监督和规范化密度场来提高3D几何表示。实验证明该方法优于以前的工作，产生了先进的照片真实感和改进的多视角一致性。 |
| [^296] | [Large Language Models as Tool Makers.](http://arxiv.org/abs/2305.17126) | 本文提出了一个闭环框架，即LLMs作为工具制造者（LATM），使LLMs能够自主地创建用于解决问题的工具，而不需要依赖于现有的外部工具。 |
| [^297] | [Jailbreaking ChatGPT via Prompt Engineering: An Empirical Study.](http://arxiv.org/abs/2305.13860) | 本研究探索了通过提示工程破解ChatGPT的有效性，发现破解提示可以在40种用例情况下一致地规避限制，强调了提示结构在破解ChatGPT中的重要性。 |
| [^298] | [Markov $\alpha$-Potential Games: Equilibrium Approximation and Regret Analysis.](http://arxiv.org/abs/2305.12553) | 本文提出了一种新的框架来研究马尔可夫博弈，即马尔可夫 $\alpha$-势博弈。介绍了两种算法来计算其中的纳什均衡，且表明这些算法能够找到近似均衡。 |
| [^299] | [Launching a Robust Backdoor Attack under Capability Constrained Scenarios.](http://arxiv.org/abs/2304.10985) | 深度神经网络的后门攻击一直是一个安全性问题，现有的改进方法需要强大的攻击者能力，在能力受限场景下还没有找到令人满意的解决办法，此外，模型鲁棒性仍然值得关注。 |
| [^300] | [ReelFramer: Co-creating News Reels on Social Media with Generative AI.](http://arxiv.org/abs/2304.09653) | ReelFramer使用生成式人工智能与社交媒体共同创作新闻片段。它可以帮助记者探索一个故事的多种叙事框架，并生成脚本、角色板和故事板。用户研究发现该系统大大减轻了将一篇书面报道转化为新闻片段的负担。 |
| [^301] | [Language-Driven Anchors for Zero-Shot Adversarial Robustness.](http://arxiv.org/abs/2301.13096) | 本文提出了一种基于语言驱动、基于锚点的对抗训练策略LAAT，通过利用文本编码器的语义一致性，在零样本图像分类场景下增强图像模型的对抗鲁棒性。实验结果表明，该方法在零样本对抗性能上优于先前的最佳状态对抗性一次性方法，同时能为流行的图像分类模型带来实质性的零样本对抗性能提升。 |
| [^302] | [CAPE: Corrective Actions from Precondition Errors using Large Language Models.](http://arxiv.org/abs/2211.09935) | CAPE是一种利用大型语言模型从前置错误中纠正行动的方法，提高了生成计划的质量，使具身代理能够执行更多任务，并改善了计划的正确性。 |
| [^303] | [Wise-SrNet: A Novel Architecture for Enhancing Image Classification by Learning Spatial Resolution of Feature Maps.](http://arxiv.org/abs/2104.12294) | 本文提出了一种名为Wise-SrNet的新型架构，用于增强图像分类任务。该架构通过学习特征图的空间分辨率，解决了连接特征图和分类层之间的挑战。实验证明，该方法在不增加计算成本的情况下，有效提高了学习效率。 |

# 详细

[^1]: TEDDY: 基于度量判别策略的边缘修剪方法

    TEDDY: Trimming Edges with Degree-based Discrimination strategY

    [https://rss.arxiv.org/abs/2402.01261](https://rss.arxiv.org/abs/2402.01261)

    TEDDY是一种利用边缘度量信息的边缘修剪方法，旨在通过一次性操作实现边缘稀疏化，进而鼓励参数稀疏化训练。这是一个解决图神经网络中抽奖票假设的时间效率和效果问题的创新方法。

    

    自从Chen等人在2021年提出用于图神经网络（GNNs）的抽奖票假设的开创性工作以来，寻找图抽奖票（GLT）的研究已成为GNN社区的重要关注点之一，激发了研究人员在实现与原始密集网络相当性能的同时，发现更稀疏的GLT。同时，图结构作为GNN训练动力学的重要因素，也受到了广泛关注，并得到了最近几项研究的阐明。尽管如此，目前关于GLT的研究通常没有充分利用图结构中的内在路径，并以迭代方式识别票数，这种方法耗时且效率低下。为解决这些限制，我们引入TEDDY，一种利用结构信息并整合边缘度量信息的一次性边缘稀疏化框架。在进行边缘稀疏化后，我们通过简单的投影梯度下降方法鼓励参数稀疏化训练。

    Since the pioneering work on the lottery ticket hypothesis for graph neural networks (GNNs) was proposed in Chen et al. (2021), the study on finding graph lottery tickets (GLT) has become one of the pivotal focus in the GNN community, inspiring researchers to discover sparser GLT while achieving comparable performance to original dense networks. In parallel, the graph structure has gained substantial attention as a crucial factor in GNN training dynamics, also elucidated by several recent studies. Despite this, contemporary studies on GLT, in general, have not fully exploited inherent pathways in the graph structure and identified tickets in an iterative manner, which is time-consuming and inefficient. To address these limitations, we introduce TEDDY, a one-shot edge sparsification framework that leverages structural information by incorporating edge-degree information. Following edge sparsification, we encourage the parameter sparsity during training via simple projected gradient desc
    
[^2]: 下一个标记预测的陷阱

    The pitfalls of next-token prediction

    [https://arxiv.org/abs/2403.06963](https://arxiv.org/abs/2403.06963)

    论文揭示了在某些任务类别中，教师强制方法可能无法在第一时间学习到准确的下一个标记预测器，进而导致模型失败的一般机制。

    

    一篇关于下一个标记预测的论文。我们提出了一个直观的担忧：一个仅仅基于下一个标记预测的模型是否能忠实地模拟人类智能。我们认为下一个标记预测中经常混淆的两个阶段 -- 自回归推断和教师强制训练 -- 必须被区别对待。我们描述了一个一般机制，展示了教师强制如何失败，并设计了一个最小化计划任务，在这个任务中Transformer和Mamba架构在实践中以这种方式失败 -- 尽管任务本身很容易学习。

    arXiv:2403.06963v1 Announce Type: cross  Abstract: Can a mere next-token predictor faithfully model human intelligence? We crystallize this intuitive concern, which is fragmented in the literature. As a starting point, we argue that the two often-conflated phases of next-token prediction -- autoregressive inference and teacher-forced training -- must be treated distinctly. The popular criticism that errors can compound during autoregressive inference, crucially assumes that teacher-forcing has learned an accurate next-token predictor. This assumption sidesteps a more deep-rooted problem we expose: in certain classes of tasks, teacher-forcing can simply fail to learn an accurate next-token predictor in the first place. We describe a general mechanism of how teacher-forcing can fail, and design a minimal planning task where both the Transformer and the Mamba architecture empirically fail in that manner -- remarkably, despite the task being straightforward to learn. We provide preliminary
    
[^3]: SELMA：学习和合并具有自动生成数据的技能特定文本到图像专家

    SELMA: Learning and Merging Skill-Specific Text-to-Image Experts with Auto-Generated Data

    [https://arxiv.org/abs/2403.06952](https://arxiv.org/abs/2403.06952)

    SELMA提出了一种新范式，通过在自动生成的多技能图像文本数据集上微调模型，并进行技能特定专家学习和合并，从而改进T2I模型的忠实度。

    

    最近，文本到图像（T2I）生成模型展示了从文本描述中创建图像的令人印象深刻的能力。然而，这些T2I生成模型在生成精确匹配文本输入细节的图像方面经常表现不佳，比如不正确的空间关系或缺失对象。在本文中，我们介绍了SELMA：具有自动生成数据的技能特定专家学习和合并，这是一种改进T2I模型忠实度的新范式，通过在自动生成的多技能图像文本数据集上微调模型，并进行技能特定专家学习和合并。首先，SELMA利用LLM的环境学习能力生成多个文本提示数据集，可以教授不同的技能，然后基于提示使用T2I模型生成图像。接下来，SELMA通过学习多个单技能的LoRA（低秩调整）专家调整T2I模型到新技能。

    arXiv:2403.06952v1 Announce Type: cross  Abstract: Recent text-to-image (T2I) generation models have demonstrated impressive capabilities in creating images from text descriptions. However, these T2I generation models often fall short of generating images that precisely match the details of the text inputs, such as incorrect spatial relationship or missing objects. In this paper, we introduce SELMA: Skill-Specific Expert Learning and Merging with Auto-Generated Data, a novel paradigm to improve the faithfulness of T2I models by fine-tuning models on automatically generated, multi-skill image-text datasets, with skill-specific expert learning and merging. First, SELMA leverages an LLM's in-context learning capability to generate multiple datasets of text prompts that can teach different skills, and then generates the images with a T2I model based on the prompts. Next, SELMA adapts the T2I model to the new skills by learning multiple single-skill LoRA (low-rank adaptation) experts follow
    
[^4]: 使用知识图嵌入进行反事实推理

    Counterfactual Reasoning with Knowledge Graph Embeddings

    [https://arxiv.org/abs/2403.06936](https://arxiv.org/abs/2403.06936)

    通过新任务CFKGR，本文将知识图补全和反事实推理联系起来，提出了一种用于适应假设前提的知识图嵌入方法COULDD，并通过基准数据集的评估表明KGEs可以学习图中的模式，检测出合理的反事实变化。

    

    知识图嵌入（KGEs）最初是为了推断不完整知识库中缺失的真实事实而开发的。本文通过我们的新任务CFKGR将知识图补全和反事实推理联系起来。我们将原始世界状态建模为知识图，假设情景为添加到图中的边，对图的合理变化为逻辑规则推理的结果。我们创建了相应的基准数据集，其中包含各种假设情景及对原始知识图的合理改变以及应该保留的事实。我们开发了COULDD，一种针对特定假设前提调整现有知识图嵌入的通用方法，并在我们的基准上进行评估。我们的结果表明，KGEs可以在没有显式训练的情况下从图中学习模式。我们进一步观察到，通过COULDD调整后的KGEs可以可靠地检测出遵循逻辑规则的图的合理反事实变化。

    arXiv:2403.06936v1 Announce Type: cross  Abstract: Knowledge graph embeddings (KGEs) were originally developed to infer true but missing facts in incomplete knowledge repositories. In this paper, we link knowledge graph completion and counterfactual reasoning via our new task CFKGR. We model the original world state as a knowledge graph, hypothetical scenarios as edges added to the graph, and plausible changes to the graph as inferences from logical rules. We create corresponding benchmark datasets, which contain diverse hypothetical scenarios with plausible changes to the original knowledge graph and facts that should be retained. We develop COULDD, a general method for adapting existing knowledge graph embeddings given a hypothetical premise, and evaluate it on our benchmark. Our results indicate that KGEs learn patterns in the graph without explicit training. We further observe that KGEs adapted with COULDD solidly detect plausible counterfactual changes to the graph that follow the
    
[^5]: Transformers学习低敏感性函数的简单性偏差

    Simplicity Bias of Transformers to Learn Low Sensitivity Functions

    [https://arxiv.org/abs/2403.06925](https://arxiv.org/abs/2403.06925)

    Transformers在不同数据模态上具有低敏感性，这种简单性偏差有助于解释其在视觉和语言任务中的优越性能。

    

    Transformers在许多任务中取得了最先进的准确性和鲁棒性，但对它们具有的归纳偏差以及这些偏差如何与其他神经网络架构不同的理解仍然难以捉摸。本文中，我们将模型对输入中的随机更改的敏感性概念化为一种简单性偏差的概念，这为解释transformers在不同数据模态上的简单性和谱偏差提供了统一的度量标准。我们展示了transformers在视觉和语言任务中比其他替代架构（如LSTMs、MLPs和CNNs）具有更低的敏感性。我们还展示了低敏感性偏差与改进性能的相关性。

    arXiv:2403.06925v1 Announce Type: cross  Abstract: Transformers achieve state-of-the-art accuracy and robustness across many tasks, but an understanding of the inductive biases that they have and how those biases are different from other neural network architectures remains elusive. Various neural network architectures such as fully connected networks have been found to have a simplicity bias towards simple functions of the data; one version of this simplicity bias is a spectral bias to learn simple functions in the Fourier space. In this work, we identify the notion of sensitivity of the model to random changes in the input as a notion of simplicity bias which provides a unified metric to explain the simplicity and spectral bias of transformers across different data modalities. We show that transformers have lower sensitivity than alternative architectures, such as LSTMs, MLPs and CNNs, across both vision and language tasks. We also show that low-sensitivity bias correlates with impro
    
[^6]: MEND：元演示蒸馏用于有效和高效的上下文学习

    MEND: Meta dEmonstratioN Distillation for Efficient and Effective In-Context Learning

    [https://arxiv.org/abs/2403.06914](https://arxiv.org/abs/2403.06914)

    提出了Meta dEmonstratioN Distillation (MEND)，利用知识蒸馏提高MEND和LLM之间的对齐，实现了高效和有效的上下文学习。

    

    大型语言模型(LLMs)展示了令人印象深刻的上下文学习(ICL)能力，其中LLM为给定的测试输入和少量输入-输出对(演示)进行预测。然而，演示的加入导致自注意机制的计算开销呈二次增加。现有解决方案尝试将冗长的演示蒸馏成紧凑的向量。然而，它们通常需要特定于任务的重新训练或牺牲LLM的上下文学习性能。为了缓解这些挑战，我们提出了Meta dEmonstratioN Distillation (MEND)，其中语言模型学会将任何冗长演示蒸馏为向量，而无需为新的下游任务重新训练。我们利用知识蒸馏增强MEND和LLM之间的对齐，同时实现效率和有效性。MEND具有蒸馏演示的元知识

    arXiv:2403.06914v1 Announce Type: cross  Abstract: Large Language models (LLMs) have demonstrated impressive in-context learning (ICL) capabilities, where a LLM makes predictions for a given test input together with a few input-output pairs (demonstrations). Nevertheless, the inclusion of demonstrations leads to a quadratic increase in the computational overhead of the self-attention mechanism. Existing solutions attempt to distill lengthy demonstrations into compact vectors. However, they often require task-specific retraining or compromise LLM's in-context learning performance. To mitigate these challenges, we present Meta dEmonstratioN Distillation (MEND), where a language model learns to distill any lengthy demonstrations into vectors without retraining for a new downstream task. We exploit the knowledge distillation to enhance alignment between MEND and LLM, achieving both efficiency and effectiveness simultaneously. MEND is endowed with the meta-knowledge of distilling demonstrat
    
[^7]: 负责任人工智能：一项结构化文献综述

    Responsible Artificial Intelligence: A Structured Literature Review

    [https://arxiv.org/abs/2403.06910](https://arxiv.org/abs/2403.06910)

    该研究提出了负责任人工智能的全面统一定义，并通过结构化文献综述阐明了当前对负责任人工智能的理解，旨在帮助立法者和机器学习从业者在AI监管领域做出指导。

    

    arXiv:2403.06910v1 公告类型：新的 摘要：我们的研究致力于推进负责任人工智能（AI）的概念，在欧盟政策讨论中日益重要。欧盟最近发布了几份强调AI信任必要性的出版物，强调AI作为有益工具和潜在武器的双重性质。这种二元性突显了国际监管的迫切需要。与此同时，需要指导公司在AI发展中遵守这些规定的框架。我们的研究旨在帮助立法者和机器学习从业者在AI监管不断发展的背景下导航，确定未来关注的焦点领域。本文介绍了负责任AI的全面且据我们所知第一个统一定义。通过结构化文献综述，我们阐明了对负责任AI的当前理解。借鉴这一分析，我们提出了

    arXiv:2403.06910v1 Announce Type: new  Abstract: Our research endeavors to advance the concept of responsible artificial intelligence (AI), a topic of increasing importance within EU policy discussions. The EU has recently issued several publications emphasizing the necessity of trust in AI, underscoring the dual nature of AI as both a beneficial tool and a potential weapon. This dichotomy highlights the urgent need for international regulation. Concurrently, there is a need for frameworks that guide companies in AI development, ensuring compliance with such regulations. Our research aims to assist lawmakers and machine learning practitioners in navigating the evolving landscape of AI regulation, identifying focal areas for future attention. This paper introduces a comprehensive and, to our knowledge, the first unified definition of responsible AI. Through a structured literature review, we elucidate the current understanding of responsible AI. Drawing from this analysis, we propose an
    
[^8]: 成本敏感学习在考虑工作量约束下推迟多位专家决策

    Cost-Sensitive Learning to Defer to Multiple Experts with Workload Constraints

    [https://arxiv.org/abs/2403.06906](https://arxiv.org/abs/2403.06906)

    提出了成本和工作量约束下的推迟框架（DeCCaF），旨在解决成本敏感场景、并发预测和人类工作能力约束等问题

    

    学习推迟（L2D）旨在通过学习如何在人工智能协作系统中将决策推迟给人类，从而在人类更有可能正确时推迟决策。现有L2D研究忽视了阻碍其实际采用的真实系统的关键方面，即：忽视成本敏感场景，其中第1类和第2类错误的成本不同；要求每个训练数据集实例的并发人类预测；不处理人类工作能力约束。为了解决这些问题，我们提出了成本和工作量约束下的推迟框架（DeCCaF）。DeCCaF是一种新颖的L2D方法，采用监督学习来建模人类错误的概率，减少数据要求的限制，并使用约束编程来全局最小化错误成本，同时考虑工作量限制。我们在一个系列中测试了DeCCaF

    arXiv:2403.06906v1 Announce Type: cross  Abstract: Learning to defer (L2D) aims to improve human-AI collaboration systems by learning how to defer decisions to humans when they are more likely to be correct than an ML classifier. Existing research in L2D overlooks key aspects of real-world systems that impede its practical adoption, namely: i) neglecting cost-sensitive scenarios, where type 1 and type 2 errors have different costs; ii) requiring concurrent human predictions for every instance of the training dataset and iii) not dealing with human work capacity constraints. To address these issues, we propose the deferral under cost and capacity constraints framework (DeCCaF). DeCCaF is a novel L2D approach, employing supervised learning to model the probability of human error under less restrictive data requirements (only one expert prediction per instance) and using constraint programming to globally minimize the error cost subject to workload limitations. We test DeCCaF in a series 
    
[^9]: LIBR+: 通过学习基于生物力学变形的差值来改进术中肝脏配准

    LIBR+: Improving Intraoperative Liver Registration by Learning the Residual of Biomechanics-Based Deformable Registration

    [https://arxiv.org/abs/2403.06901](https://arxiv.org/abs/2403.06901)

    通过深度学习和生物力学模型相结合的LIBR+方法，作者提出了一种改进术中肝脏配准的方法，能有效处理术中测量的稀疏性和变异性。

    

    手术环境对术中器官形状与术前成像几何形状的配准提出了独特的挑战。基于生物力学模型的配准仍然很流行，而深度学习解决方案受到术中测量的稀疏性和变异性以及手术过程中可以获得的有限器官地面真实变形的限制。本文提出了一种新颖的“混合”配准方法，利用基于线性弹性生物力学的线性化迭代边界重建（LIBR）方法，并使用深度神经网络学习其残差以获取地面真实变形（LIBR+）。我们进一步制定了一个双分支样条残差图卷积神经网络（SR-GCN）来吸收稀疏和变量术中测量的信息，并有效地通过3D器官的几何形状传播。在大规模数据集上进行了实验...

    arXiv:2403.06901v1 Announce Type: cross  Abstract: The surgical environment imposes unique challenges to the intraoperative registration of organ shapes to their preoperatively-imaged geometry. Biomechanical model-based registration remains popular, while deep learning solutions remain limited due to the sparsity and variability of intraoperative measurements and the limited ground-truth deformation of an organ that can be obtained during the surgery. In this paper, we propose a novel \textit{hybrid} registration approach that leverage a linearized iterative boundary reconstruction (LIBR) method based on linear elastic biomechanics, and use deep neural networks to learn its residual to the ground-truth deformation (LIBR+). We further formulate a dual-branch spline-residual graph convolutional neural network (SR-GCN) to assimilate information from sparse and variable intraoperative measurements and effectively propagate it through the geometry of the 3D organ. Experiments on a large int
    
[^10]: 揭示受幼儿启发的奖励转换在目标导向强化学习中的重要性

    Unveiling the Significance of Toddler-Inspired Reward Transition in Goal-Oriented Reinforcement Learning

    [https://arxiv.org/abs/2403.06880](https://arxiv.org/abs/2403.06880)

    研究探讨了幼儿启发的奖励转换如何影响强化学习任务的样本效率和成功率，特别是发现了幼儿启发的稀疏转密集（S2D）转换的有效性。

    

    幼儿从稀疏反馈的自由探索逐渐发展为利用先前经验进行以目标为导向的学习，获得更密集奖励。受此幼儿启发的奖励转换的影响，我们探讨了将不同奖励转换纳入强化学习（RL）任务的意义。我们研究的重点是从稀疏到基于潜在的密集奖励的转换，这两者共享无论奖励变化均为最佳策略。通过包括以自我为中心的导航和机械臂操作任务在内的各种实验，我们发现适当的奖励转换显著影响样本效率和成功率。特别值得注意的是受幼儿启发的稀疏转密集（S2D）转换的有效性。除了这些性能指标外，使用交叉密度可视化技术，我们观察到转换，特别是S2D，使策略损失景观更加平滑，促进

    arXiv:2403.06880v1 Announce Type: cross  Abstract: Toddlers evolve from free exploration with sparse feedback to exploiting prior experiences for goal-directed learning with denser rewards. Drawing inspiration from this Toddler-Inspired Reward Transition, we set out to explore the implications of varying reward transitions when incorporated into Reinforcement Learning (RL) tasks. Central to our inquiry is the transition from sparse to potential-based dense rewards, which share optimal strategies regardless of reward changes. Through various experiments, including those in egocentric navigation and robotic arm manipulation tasks, we found that proper reward transitions significantly influence sample efficiency and success rates. Of particular note is the efficacy of the toddler-inspired Sparse-to-Dense (S2D) transition. Beyond these performance metrics, using Cross-Density Visualizer technique, we observed that transitions, especially the S2D, smooth the policy loss landscape, promoting
    
[^11]: 探索大型语言模型和分层框架用于大型非结构化法律文件的分类

    Exploring Large Language Models and Hierarchical Frameworks for Classification of Large Unstructured Legal Documents

    [https://arxiv.org/abs/2403.06872](https://arxiv.org/abs/2403.06872)

    使用MESc框架探索大型法律文件的分类，通过大型语言模型提取文件部分的嵌入并使用聚类近似结构，进而预测判决。

    

    法律判决预测受长达数万字的案例文件和非均匀结构的问题困扰，尤其是对于没有结构标注的文件。本研究通过一个基于深度学习的分层框架(MESc)，即“基于多阶段编码器的带聚类的监督学习”，来探索这些大型法律文件的分类和它们缺乏结构信息的情况，用于判决预测。具体来说，我们将文件分成部分，从自定义精调的大型语言模型的最后四层中提取它们的嵌入，并尝试通过无监督聚类来近似它们的结构。然后在另一组变压器编码器层中使用这些表示来学习部分间的表示。我们分析了具有数十亿参数的大型语言模型(LLM)的适应性(GPT-Neo)。

    arXiv:2403.06872v1 Announce Type: cross  Abstract: Legal judgment prediction suffers from the problem of long case documents exceeding tens of thousands of words, in general, and having a non-uniform structure. Predicting judgments from such documents becomes a challenging task, more so on documents with no structural annotation. We explore the classification of these large legal documents and their lack of structural information with a deep-learning-based hierarchical framework which we call MESc; "Multi-stage Encoder-based Supervised with-clustering"; for judgment prediction. Specifically, we divide a document into parts to extract their embeddings from the last four layers of a custom fine-tuned Large Language Model, and try to approximate their structure through unsupervised clustering. Which we use in another set of transformer encoder layers to learn the inter-chunk representations. We analyze the adaptability of Large Language Models (LLMs) with multi-billion parameters (GPT-Neo
    
[^12]: 在有噪声基础模型中学习

    Learning with Noisy Foundation Models

    [https://arxiv.org/abs/2403.06869](https://arxiv.org/abs/2403.06869)

    本文首次全面了解和分析了预训练数据集中的噪声性质，有效减轻其对下游任务影响。

    

    基础模型通常是在大规模数据集上进行预训练，然后通过调整来适应下游任务。然而，大规模预训练数据集往往无法获取或成本过高，可能包含标签噪声，这可能会对模型的泛化能力造成不利影响，并带来意想不到的风险。本文是首个全面了解和分析预训练数据集中噪声性质，并有效减轻其对下游任务影响的工作。具体而言，通过在合成有噪声的ImageNet-1K、YFCC15M和CC12M数据集上进行完全监督和图像-文本对比预训练的广泛实验，我们证明了，尽管预训练中的轻微噪声可以使同领域（ID）性能受益，即训练和测试数据共享类似分布，但它总是会破坏跨领域（OOD）性能，在那里训练和测试分布明显不同。

    arXiv:2403.06869v1 Announce Type: cross  Abstract: Foundation models are usually pre-trained on large-scale datasets and then adapted to downstream tasks through tuning. However, the large-scale pre-training datasets, often inaccessible or too expensive to handle, can contain label noise that may adversely affect the generalization of the model and pose unexpected risks. This paper stands out as the first work to comprehensively understand and analyze the nature of noise in pre-training datasets and then effectively mitigate its impacts on downstream tasks. Specifically, through extensive experiments of fully-supervised and image-text contrastive pre-training on synthetic noisy ImageNet-1K, YFCC15M, and CC12M datasets, we demonstrate that, while slight noise in pre-training can benefit in-domain (ID) performance, where the training and testing data share a similar distribution, it always deteriorates out-of-domain (OOD) performance, where training and testing distributions are signific
    
[^13]: 面向支持新生儿科医生的分娩室教育工具研究

    Towards an educational tool for supporting neonatologists in the delivery room

    [https://arxiv.org/abs/2403.06843](https://arxiv.org/abs/2403.06843)

    提出了一种机器学习方法，用于从实际数据中识别新生儿分娩事件的风险因素，旨在设计出一款用户友好的移动应用程序，提高对高风险患者的识别率和干预规划。

    

    如今，有证据表明几个因素可能增加婴儿在出生时需要稳定或复苏操作的风险。然而，这些风险因素尚未完全知晓，并且目前尚无适用于预测高风险情况的普遍模型。考虑到这些限制和出生时需要进行复苏的需求相对罕见，有必要对负责分娩室新生儿护理的医护人员进行定期培训。本文提出了一种机器学习方法，用于从实际数据中识别风险因素及其对分娩事件的影响，这可以帮助人员逐步增加和更新他们的知识。我们的最终目标是设计一个用户友好的移动应用程序，能够提高高风险患者的识别率和规划适当的干预措施。

    arXiv:2403.06843v1 Announce Type: new  Abstract: Nowadays, there is evidence that several factors may increase the risk, for an infant, to require stabilisation or resuscitation manoeuvres at birth. However, this risk factors are not completely known, and a universally applicable model for predicting high-risk situations is not available yet. Considering both these limitations and the fact that the need for resuscitation at birth is a rare event, periodic training of the healthcare personnel responsible for newborn caring in the delivery room is mandatory.   In this paper, we propose a machine learning approach for identifying risk factors and their impact on the birth event from real data, which can be used by personnel to progressively increase and update their knowledge. Our final goal will be the one of designing a user-friendly mobile application, able to improve the recognition rate and the planning of the appropriate interventions on high-risk patients.
    
[^14]: RA-ISF: 通过迭代自反馈学习检索增强以回答和理解

    RA-ISF: Learning to Answer and Understand from Retrieval Augmentation via Iterative Self-Feedback

    [https://arxiv.org/abs/2403.06840](https://arxiv.org/abs/2403.06840)

    通过迭代自反馈的检索增强方法在指定任务的特定场景中提高模型性能，优于现有基准模型，显著增强了事实推理能力。

    

    大型语言模型(LLMs)在许多任务中表现出色，但仍然严重依赖存储在其参数中的知识。检索增强生成(RAG)方法通过整合外部知识来解决这一问题。模型可以通过检索与查询相关的知识来回答以前无法回答的问题。本文提出了检索增强迭代自反馈(RA-ISF)框架，通过三个子模块迭代分解任务并处理它们，以增强模型的问题解决能力。实验证明，我们的方法优于现有基准，在诸如GPT3.5、Llama2之类的模型上表现良好，显著增强了事实推理能力。

    arXiv:2403.06840v1 Announce Type: cross  Abstract: Large language models (LLMs) demonstrate exceptional performance in numerous tasks but still heavily rely on knowledge stored in their parameters. Moreover, updating this knowledge incurs high training costs. Retrieval-augmented generation (RAG) methods address this issue by integrating external knowledge. The model can answer questions it couldn't previously by retrieving knowledge relevant to the query. This approach improves performance in certain scenarios for specific tasks. However, if irrelevant texts are retrieved, it may impair model performance. In this paper, we propose Retrieval Augmented Iterative Self-Feedback (RA-ISF), a framework that iteratively decomposes tasks and processes them in three submodules to enhance the model's problem-solving capabilities. Experiments show that our method outperforms existing benchmarks, performing well on models like GPT3.5, Llama2, significantly enhancing factual reasoning capabilities a
    
[^15]: 通过细粒度图像-文本对齐和解剖病理提示进行医学图像合成

    Medical Image Synthesis via Fine-Grained Image-Text Alignment and Anatomy-Pathology Prompting

    [https://arxiv.org/abs/2403.06835](https://arxiv.org/abs/2403.06835)

    通过细粒度图像-文本对齐和解剖病理提示，提出一种新的医学图像合成模型，能够生成高度详细和准确的合成医学图像。

    

    数据稀缺和隐私问题限制了高质量医学图像供公众使用的可用性，可以通过医学图像合成来缓解这一问题。然而，当前的医学图像合成方法常常难以准确捕捉详细解剖结构和病理条件的复杂性。为解决这些挑战，我们提出了一种新颖的医学图像合成模型，利用细粒度图像-文本对齐和解剖病理提示生成高度详细和准确的合成医学图像。我们的方法将先进的自然语言处理技术与图像生成建模相结合，实现描述性文本提示与合成图像的解剖和病理细节之间的精确对齐。所提出的方法由两个关键组件组成：解剖病理提示模块和基于细粒度对齐的合成模块。

    arXiv:2403.06835v1 Announce Type: cross  Abstract: Data scarcity and privacy concerns limit the availability of high-quality medical images for public use, which can be mitigated through medical image synthesis. However, current medical image synthesis methods often struggle to accurately capture the complexity of detailed anatomical structures and pathological conditions. To address these challenges, we propose a novel medical image synthesis model that leverages fine-grained image-text alignment and anatomy-pathology prompts to generate highly detailed and accurate synthetic medical images. Our method integrates advanced natural language processing techniques with image generative modeling, enabling precise alignment between descriptive text prompts and the synthesized images' anatomical and pathological details. The proposed approach consists of two key components: an anatomy-pathology prompting module and a fine-grained alignment-based synthesis module. The anatomy-pathology prompt
    
[^16]: 噪声的力量：朝着统一的多模态知识图表示框架

    The Power of Noise: Toward a Unified Multi-modal Knowledge Graph Representation Framework

    [https://arxiv.org/abs/2403.06832](https://arxiv.org/abs/2403.06832)

    提出了一种利用噪声掩模的Transformer-based架构SNAG方法，实现了多模态知识图表示中实体嵌入的最先进性能

    

    多模态预训练的进展凸显出鲁棒的多模态知识图（MMKG）表示学习框架的必要性。此框架对于在规模上将结构化知识整合到多模态大型语言模型（LLMs）中至关重要，旨在减轻知识误解和多模态幻觉等问题。在这项工作中，为了评估模型准确嵌入MMKG中的实体的能力，我们专注于两个广泛研究的任务：多模态知识图完成（MKGC）和多模态实体对齐（MMEA）。在此基础上，我们提出了一种新颖的SNAG方法，该方法利用基于Transformer的架构，并配备了模态级噪声掩模，以在知识图中鲁棒地集成多模态实体特征。通过为MKGC和MMEA都引入特定的训练目标，我们的方法在总共十个数据集上（三个用于MKGC和...

    arXiv:2403.06832v1 Announce Type: cross  Abstract: The advancement of Multi-modal Pre-training highlights the necessity for a robust Multi-Modal Knowledge Graph (MMKG) representation learning framework. This framework is crucial for integrating structured knowledge into multi-modal Large Language Models (LLMs) at scale, aiming to alleviate issues like knowledge misconceptions and multi-modal hallucinations. In this work, to evaluate models' ability to accurately embed entities within MMKGs, we focus on two widely researched tasks: Multi-modal Knowledge Graph Completion (MKGC) and Multi-modal Entity Alignment (MMEA). Building on this foundation, we propose a novel SNAG method that utilizes a Transformer-based architecture equipped with modality-level noise masking for the robust integration of multi-modal entity features in KGs. By incorporating specific training objectives for both MKGC and MMEA, our approach achieves SOTA performance across a total of ten datasets (three for MKGC and 
    
[^17]: NeuPAN:直接点机器人导航的端到端基于模型学习

    NeuPAN: Direct Point Robot Navigation with End-to-End Model-based Learning

    [https://arxiv.org/abs/2403.06828](https://arxiv.org/abs/2403.06828)

    NeuPAN 是一种实时、高度准确、无地图、适用于各种机器人且对环境不变的机器人导航解决方案，最大的创新在于将原始点直接映射到学习到的多帧距离空间，并具有端到端模型学习的可解释性，从而实现了可证明的收敛。

    

    在拥挤环境中对非全向机器人进行导航需要极其精确的感知和运动以避免碰撞。本文提出NeuPAN：一种实时、高度准确、无地图、适用于各种机器人，且对环境不变的机器人导航解决方案。NeuPAN采用紧耦合的感知-运动框架，与现有方法相比有两个关键创新：1）它直接将原始点映射到学习到的多帧距离空间，避免了从感知到控制的误差传播；2）从端到端基于模型学习的角度进行解释，实现了可证明的收敛。NeuPAN的关键在于利用插拔式（PnP）交替最小化传感器（PAN）网络解高维端到端数学模型，其中包含各种点级约束，使NeuPAN能够直接生成实时、端到端、物理可解释的运动。

    arXiv:2403.06828v1 Announce Type: cross  Abstract: Navigating a nonholonomic robot in a cluttered environment requires extremely accurate perception and locomotion for collision avoidance. This paper presents NeuPAN: a real-time, highly-accurate, map-free, robot-agnostic, and environment-invariant robot navigation solution. Leveraging a tightly-coupled perception-locomotion framework, NeuPAN has two key innovations compared to existing approaches: 1) it directly maps raw points to a learned multi-frame distance space, avoiding error propagation from perception to control; 2) it is interpretable from an end-to-end model-based learning perspective, enabling provable convergence. The crux of NeuPAN is to solve a high-dimensional end-to-end mathematical model with various point-level constraints using the plug-and-play (PnP) proximal alternating-minimization network (PAN) with neurons in the loop. This allows NeuPAN to generate real-time, end-to-end, physically-interpretable motions direct
    
[^18]: 基于上下文的探索-利用用于强化学习

    In-context Exploration-Exploitation for Reinforcement Learning

    [https://arxiv.org/abs/2403.06826](https://arxiv.org/abs/2403.06826)

    引入了In-context Exploration-Exploitation (ICEE)算法，通过在Transformer模型内部进行探索-利用权衡，提高了在-context策略学习的效率。

    

    在-context学习是在线策略学习离线强化学习（RL）方法的一种有前途的方法，可以在推理时间内实现，无需梯度优化。然而，由于需要收集大量训练轨迹集并训练大型Transformer模型，这种方法所带来的显著计算成本。我们通过引入一种基于In-context Exploration-Exploitation（ICEE）的算法来解决这一挑战，该算法旨在优化在-context策略学习的效率。ICEE在推理时间内在Transformer模型中执行探索-利用权衡，不需要显式贝叶斯推断。因此，ICEE可以像高斯过程偏差方法那样有效地解决贝叶斯优化问题，但时间显着较短。通过在网格世界环境中的实验，我们证明ICEE能够学习解决新的R

    arXiv:2403.06826v1 Announce Type: cross  Abstract: In-context learning is a promising approach for online policy learning of offline reinforcement learning (RL) methods, which can be achieved at inference time without gradient optimization. However, this method is hindered by significant computational costs resulting from the gathering of large training trajectory sets and the need to train large Transformer models. We address this challenge by introducing an In-context Exploration-Exploitation (ICEE) algorithm, designed to optimize the efficiency of in-context policy learning. Unlike existing models, ICEE performs an exploration-exploitation trade-off at inference time within a Transformer model, without the need for explicit Bayesian inference. Consequently, ICEE can solve Bayesian optimization problems as efficiently as Gaussian process biased methods do, but in significantly less time. Through experiments in grid world environments, we demonstrate that ICEE can learn to solve new R
    
[^19]: 目标信息更有效吗？

    Are Targeted Messages More Effective?

    [https://arxiv.org/abs/2403.06817](https://arxiv.org/abs/2403.06817)

    GNN的核心架构有两个版本，第一个版本消息仅取决于源顶点的状态，而第二个版本消息取决于源顶点和目标顶点的状态。

    

    图神经网络（GNN）是用于图形的深度学习架构。本质上，GNN是一个分布式的消息传递算法，其受到从数据中学到的参数的控制。它在图的顶点上操作：在每次迭代中，顶点在每个传入边上接收一条消息，聚合这些消息，然后根据它们当前的状态和聚合的消息更新它们的状态。GNN的表达能力可以用带计数的一阶逻辑的某些片段和Weisfeiler-Lehman算法来描述。GNN的核心架构有两个不同的版本。在第一个版本中，消息仅取决于源顶点的状态，而在第二个版本中，消息取决于源顶点和目标顶点的状态。实际上，这两个版本都被使用，但迄今为止GNN的理论大多集中在第一个版本上。在逻辑方面，这两个版本对应着

    arXiv:2403.06817v1 Announce Type: cross  Abstract: Graph neural networks (GNN) are deep learning architectures for graphs. Essentially, a GNN is a distributed message passing algorithm, which is controlled by parameters learned from data. It operates on the vertices of a graph: in each iteration, vertices receive a message on each incoming edge, aggregate these messages, and then update their state based on their current state and the aggregated messages. The expressivity of GNNs can be characterised in terms of certain fragments of first-order logic with counting and the Weisfeiler-Lehman algorithm.   The core GNN architecture comes in two different versions. In the first version, a message only depends on the state of the source vertex, whereas in the second version it depends on the states of the source and target vertices. In practice, both of these versions are used, but the theory of GNNs so far mostly focused on the first one. On the logical side, the two versions correspond to 
    
[^20]: 用遗传学习设计Sim-to-Real数据增强

    Genetic Learning for Designing Sim-to-Real Data Augmentations

    [https://arxiv.org/abs/2403.06786](https://arxiv.org/abs/2403.06786)

    提出了两种可解释的度量方法，可以结合预测特定增强策略在Sim-to-Real设置中的表现，并引入了一种名为GeneticAugment的遗传规划方法。

    

    数据增强在训练合成数据时用于弥合Sim-to-Real领域差距中是有用的。这是因为它们扩展了训练数据分布，从而鼓励模型更好地推广到其他领域。许多图像增强技术存在，由不同设置参数化，比如强度和概率。这导致了一个不同可能增强策略的大空间。对于克服特定数据集的Sim-to-Real差距，一些策略比其他策略更有效，但目前尚不清楚原因。本文介绍了两种不同的可解释度度量，可以结合起来预测某种特定增强策略在特定Sim-to-Real设置中的工作效果，重点放在目标检测上。我们通过训练许多具有不同增强策略的模型并展示与真实数据表现之间的强相关性来验证我们的度量。此外，我们引入了GeneticAugment，这是一种基于遗传规划的方法。

    arXiv:2403.06786v1 Announce Type: cross  Abstract: Data augmentations are useful in closing the sim-to-real domain gap when training on synthetic data. This is because they widen the training data distribution, thus encouraging the model to generalize better to other domains. Many image augmentation techniques exist, parametrized by different settings, such as strength and probability. This leads to a large space of different possible augmentation policies. Some policies work better than others for overcoming the sim-to-real gap for specific datasets, and it is unclear why. This paper presents two different interpretable metrics that can be combined to predict how well a certain augmentation policy will work for a specific sim-to-real setting, focusing on object detection. We validate our metrics by training many models with different augmentation policies and showing a strong correlation with performance on real data. Additionally, we introduce GeneticAugment, a genetic programming me
    
[^21]: 一张图片在第二层之后价值1/2代币：针对大规模视觉语言模型的即插即用推理加速

    An Image is Worth 1/2 Tokens After Layer 2: Plug-and-Play Inference Acceleration for Large Vision-Language Models

    [https://arxiv.org/abs/2403.06764](https://arxiv.org/abs/2403.06764)

    FastV是一种多功能即插即用方法，通过学习自适应注意力模式并在后续层中修剪视觉代币，极大地降低了计算成本，同时在各种图像和视频理解任务中不损失性能。

    

    在本研究中，我们发现大规模视觉语言模型（LVLMs）中的注意力计算存在低效现象，尤其是在知名模型如LLaVA-1.5、QwenVL-Chat和Video-LLaVA中。我们发现在流行的LVLMs的深层中，对视觉代币的注意力计算极其低效，暗示相较于处理文本数据，需要更稀疏的方法。为此，我们引入了FastV，这是一种多功能即插即用方法，旨在通过学习早期层中的自适应注意力模式和在随后层中修剪视觉代币来优化计算效率。我们的评估表明FastV能够显著降低计算成本（例如，对于LLaVA-1.5-13B的FLOP减少了45%），而不会在广泛的图像和视频理解任务中牺牲性能。FastV的计算效率和性能权衡是高度可定制的，并且是帕累托有效的。

    arXiv:2403.06764v1 Announce Type: cross  Abstract: In this study, we identify the inefficient attention phenomena in Large Vision-Language Models (LVLMs), notably within prominent models like LLaVA-1.5, QwenVL-Chat and Video-LLaVA. We find out that the attention computation over visual tokens is of extreme inefficiency in the deep layers of popular LVLMs, suggesting a need for a sparser approach compared to textual data handling. To this end, we introduce FastV, a versatile plug-and-play method designed to optimize computational efficiency by learning adaptive attention patterns in early layers and pruning visual tokens in subsequent ones. Our evaluations demonstrate FastV's ability to dramatically reduce computational costs (e.g., a 45 reduction in FLOPs for LLaVA-1.5-13B) without sacrificing performance in a wide range of image and video understanding tasks. The computational efficiency and performance trade-off of FastV are highly customizable and pareto-efficient. It can compress t
    
[^22]: ALaRM: 通过分层奖励建模对齐语言模型

    ALaRM: Align Language Models via Hierarchical Rewards Modeling

    [https://arxiv.org/abs/2403.06754](https://arxiv.org/abs/2403.06754)

    ALaRM是第一个从人类反馈中建模分层奖励的框架，通过整合整体奖励与特定方面的奖励，改善了大型语言模型与人类偏好的对齐性，尤其在复杂文本生成任务中表现出更精确和一致的指导。

    

    我们介绍了ALaRM，第一个在强化学习中从人类反馈模型分层奖励的框架，旨在增强大型语言模型（LLMs）与人类偏好的对齐性。该框架解决了当前对齐方法的限制，这些方法通常难以处理人类监督信号的不一致性和稀疏性，通过将整体奖励与特定方面的奖励相结合。这种整合使得语言模型更加精确和一致地指导朝着期望的结果前进，尤其在复杂和开放的文本生成任务中。通过应用基于一致性的方法来过滤和组合多个奖励，该框架提供了一种可靠的机制来改善模型的对齐性。我们通过在长篇问题回答和机器翻译任务中使用gpt-3.5-turbo进行成对比较来验证我们的方法。

    arXiv:2403.06754v1 Announce Type: cross  Abstract: We introduce ALaRM, the first framework modeling hierarchical rewards in reinforcement learning from human feedback (RLHF), which is designed to enhance the alignment of large language models (LLMs) with human preferences. The framework addresses the limitations of current alignment approaches, which often struggle with the inconsistency and sparsity of human supervision signals, by integrating holistic rewards with aspect-specific rewards. This integration enables more precise and consistent guidance of language models towards desired outcomes, particularly in complex and open text generation tasks. By employing a methodology that filters and combines multiple rewards based on their consistency, the framework provides a reliable mechanism for improving model alignment. We validate our approach through applications in long-form question answering and machine translation tasks, employing gpt-3.5-turbo for pairwise comparisons, and demon
    
[^23]: ACT-MNMT自动收缩转向多语言神经机器翻译

    ACT-MNMT Auto-Constriction Turning for Multilingual Neural Machine Translation

    [https://arxiv.org/abs/2403.06745](https://arxiv.org/abs/2403.06745)

    该论文介绍了一种针对多语言神经机器翻译中出现的离靶问题的新型监督微调机制ACT-MNMT Auto-Constriction Turning，与传统基于提示的方法正交，并通过自动构建受限模板来解决该问题。

    

    大型语言模型（LLM）通过零/少shot提示或提示调整在多语言机器翻译任务中取得了令人期待的表现。然而，由于在LLM的预训练过程中混合了多语言数据，基于LLM的翻译模型在基于提示的方法中面临了离靶问题，包括一系列现象，即指令误解、错误语言翻译和过度生成。针对这一问题，本文介绍了一种用于多语言神经机器翻译（\model）的\textbf{\underline{A}}uto-\textbf{\underline{C}}onstriction \textbf{\underline{T}}urning机制，这是一种新颖的监督微调机制，与传统的基于提示的方法正交。在这种方法中，\model通过在目标端添加触发令牌自动构造受限模板。

    arXiv:2403.06745v1 Announce Type: cross  Abstract: Large language model (LLM) has achieved promising performance in multilingual machine translation tasks through zero/few-shot prompts or prompt-tuning. However, due to the mixture of multilingual data during the pre-training of LLM, the LLM-based translation models face the off-target issue in both prompt-based methods, including a series of phenomena, namely instruction misunderstanding, translation with wrong language and over-generation. For this issue, this paper introduces an \textbf{\underline{A}}uto-\textbf{\underline{C}}onstriction \textbf{\underline{T}}urning mechanism for \textbf{\underline{M}}ultilingual \textbf{\underline{N}}eural \textbf{\underline{M}}achine \textbf{\underline{T}}ranslation (\model), which is a novel supervised fine-tuning mechanism and orthogonal to the traditional prompt-based methods. In this method, \model automatically constructs a constrained template in the target side by adding trigger tokens ahead
    
[^24]: 利用强化学习和人类反馈增强图像标题生成

    Enhancing Image Caption Generation Using Reinforcement Learning with Human Feedback

    [https://arxiv.org/abs/2403.06735](https://arxiv.org/abs/2403.06735)

    通过整合监督学习和强化学习与人类反馈（RLHF）并引入新型损失函数，本研究提出增强深度神经网络模型性能的方法，以生成符合人类偏好的图像标题。

    

    最近关于生成模型以产生符合人类偏好输出的研究取得了显著进展。在文本和图像生成模型之间，我们将重点放在文本生成模型上，特别是为图像生成符合人类偏好的标题。在这项研究中，我们探讨了一种潜在的方法，通过集成监督学习、强化学习和人类反馈（RLHF）来提高深度神经网络模型的性能，生成人类喜欢的标题。我们使用Flickr8k数据集，并引入了一种能够根据人类反馈优化模型的新型损失函数。在本文中，我们提供了我们的方法和结果的简明概述，希望为人类偏好生成AI模型领域的持续进展做出贡献。

    arXiv:2403.06735v1 Announce Type: cross  Abstract: Research on generative models to produce human-aligned / human-preferred outputs has seen significant recent contributions. Between text and image-generative models, we narrowed our focus to text-based generative models, particularly to produce captions for images that align with human preferences. In this research, we explored a potential method to amplify the performance of the Deep Neural Network Model to generate captions that are preferred by humans. This was achieved by integrating Supervised Learning and Reinforcement Learning with Human Feedback (RLHF) using the Flickr8k dataset. Also, a novel loss function that is capable of optimizing the model based on human feedback is introduced. In this paper, we provide a concise sketch of our approach and results, hoping to contribute to the ongoing advances in the field of human-aligned generative AI models.
    
[^25]: 急救服务的实时多模态认知助手

    Real-Time Multimodal Cognitive Assistant for Emergency Medical Services

    [https://arxiv.org/abs/2403.06734](https://arxiv.org/abs/2403.06734)

    本文提出了CognitiveEMS，一个实时多模态认知助手系统，通过引入三个新颖组件解决了实时认知辅助中的关键技术挑战，为急救服务提供关键的辅助。

    

    急救服务（EMS）响应者经常在时间紧迫的条件下工作，面临认知过载和固有风险，需要具备关键思维和快速决策的基本技能。本文介绍了CognitiveEMS，这是一个端到端的可穿戴认知助手系统，可以充当协作虚拟伙伴，实时获取和分析急救现场的多模态数据，并通过增强现实（AR）智能眼镜与EMS响应者互动。CognitiveEMS实时处理连续的数据流，并利用边缘计算来提供EMS协议选择和干预识别的辅助。通过引入三个新颖组件，我们解决了实时认知辅助中的关键技术挑战：（i）一个经过微调的语音识别模型，用于针对模拟的EMS音频记录进行实际急诊对话，增强wit

    arXiv:2403.06734v1 Announce Type: new  Abstract: Emergency Medical Services (EMS) responders often operate under time-sensitive conditions, facing cognitive overload and inherent risks, requiring essential skills in critical thinking and rapid decision-making. This paper presents CognitiveEMS, an end-to-end wearable cognitive assistant system that can act as a collaborative virtual partner engaging in the real-time acquisition and analysis of multimodal data from an emergency scene and interacting with EMS responders through Augmented Reality (AR) smart glasses. CognitiveEMS processes the continuous streams of data in real-time and leverages edge computing to provide assistance in EMS protocol selection and intervention recognition. We address key technical challenges in real-time cognitive assistance by introducing three novel components: (i) a Speech Recognition model that is fine-tuned for real-world medical emergency conversations using simulated EMS audio recordings, augmented wit
    
[^26]: 通过监督预训练和重要性机制微调改进低资源知识追踪任务

    Improving Low-Resource Knowledge Tracing Tasks by Supervised Pre-training and Importance Mechanism Fine-tuning

    [https://arxiv.org/abs/2403.06725](https://arxiv.org/abs/2403.06725)

    本文提出了名为LoReKT的低资源知识追踪框架，通过监督预训练和微调重要性机制，旨在从丰富资源的KT数据集中学习可转移的参数和表示来改进低资源知识追踪任务。

    

    知识追踪（KT）旨在基于学生的历史互动来估计他们的知识掌握程度。最近，基于深度学习的KT（DLKT）方法在KT任务中取得了令人印象深刻的表现。然而，由于各种原因，如预算限制和隐私问题，许多实际场景中观察到的互动非常有限，即低资源KT数据集。直接在低资源KT数据集上训练DLKT模型可能会导致过拟合，并且很难选择适当的深度神经架构。因此，在本文中，我们提出了一个名为LoReKT的低资源KT框架来应对上述挑战。受盛行的“预训练和微调”范式的启发，我们旨在在预训练阶段从丰富资源的KT数据集中学习可转移的参数和表示。

    arXiv:2403.06725v1 Announce Type: cross  Abstract: Knowledge tracing (KT) aims to estimate student's knowledge mastery based on their historical interactions. Recently, the deep learning based KT (DLKT) approaches have achieved impressive performance in the KT task. These DLKT models heavily rely on the large number of available student interactions. However, due to various reasons such as budget constraints and privacy concerns, observed interactions are very limited in many real-world scenarios, a.k.a, low-resource KT datasets. Directly training a DLKT model on a low-resource KT dataset may lead to overfitting and it is difficult to choose the appropriate deep neural architecture. Therefore, in this paper, we propose a low-resource KT framework called LoReKT to address above challenges. Inspired by the prevalent "pre-training and fine-tuning" paradigm, we aim to learn transferable parameters and representations from rich-resource KT datasets during the pre-training stage and subseque
    
[^27]: 流畅的黎曼领域：无环方差减少的高效黎曼优化

    Streamlining in the Riemannian Realm: Efficient Riemannian Optimization with Loopless Variance Reduction

    [https://arxiv.org/abs/2403.06677](https://arxiv.org/abs/2403.06677)

    引入了在黎曼优化中采用概率梯度计算触发器的Loopless SVRG和PAGE方法，简化了证明、提高了超参数选择效率，并提供了尖锐的收敛保证。

    

    在本研究中，我们研究了在黎曼流形上的随机优化，重点关注在欧几里得和黎曼设置中使用的关键方差减少机制。黎曼方差减少方法通常涉及双循环结构，在每个循环的开始计算完整梯度。确定最佳内循环长度在实践中具有挑战性，因为它取决于强凸性或光滑度常数，这些常数通常是未知的或难以估计。受欧几里得方法的启发，我们引入了无环黎曼SVRG（R-LSVRG）和PAGE（R-PAGE）方法。这些方法用每次迭代中的硬币翻转触发的概率梯度计算替换了外循环，确保了更简单的证明、高效的超参数选择和尖锐的收敛保证。将R-PAGE作为非凸黎曼优化的框架，我们展示了它在各种重要设置中的适用性。

    arXiv:2403.06677v1 Announce Type: cross  Abstract: In this study, we investigate stochastic optimization on Riemannian manifolds, focusing on the crucial variance reduction mechanism used in both Euclidean and Riemannian settings. Riemannian variance-reduced methods usually involve a double-loop structure, computing a full gradient at the start of each loop. Determining the optimal inner loop length is challenging in practice, as it depends on strong convexity or smoothness constants, which are often unknown or hard to estimate. Motivated by Euclidean methods, we introduce the Riemannian Loopless SVRG (R-LSVRG) and PAGE (R-PAGE) methods. These methods replace the outer loop with probabilistic gradient computation triggered by a coin flip in each iteration, ensuring simpler proofs, efficient hyperparameter selection, and sharp convergence guarantees. Using R-PAGE as a framework for non-convex Riemannian optimization, we demonstrate its applicability to various important settings. For ex
    
[^28]: 通过不修复代码对程序进行毒化：AI生成的代码的安全问题

    Poisoning Programs by Un-Repairing Code: Security Concerns of AI-generated Code

    [https://arxiv.org/abs/2403.06675](https://arxiv.org/abs/2403.06675)

    本文章针对AI代码生成器面临的安全挑战，提出了一种新颖的数据毒化攻击，通过向训练数据中注入毒素来生成易受攻击的代码，并对其对代码生成模型的影响进行了评估，并讨论了潜在的解决方案。

    

    基于AI的代码生成器在协助开发人员从自然语言（NL）开始编写软件方面发挥了根本作用。然而，由于这些大型语言模型是在从不可靠的在线来源（例如GitHub，Hugging Face）收集的大量数据上进行训练的，AI模型成为数据毒化攻击的容易目标，即攻击者通过向训练数据中注入少量毒素（即巧妙制作的恶意样本）来破坏训练数据。在这篇立场论文中，我们通过识别一种导致生成易受攻击的代码的新型数据毒化攻击来讨论AI代码生成器的安全性。接下来，我们对这些攻击如何影响用于代码生成的最新模型进行了广泛评估。最后，我们讨论了解决这一威胁的潜在解决方案。

    arXiv:2403.06675v1 Announce Type: cross  Abstract: AI-based code generators have gained a fundamental role in assisting developers in writing software starting from natural language (NL). However, since these large language models are trained on massive volumes of data collected from unreliable online sources (e.g., GitHub, Hugging Face), AI models become an easy target for data poisoning attacks, in which an attacker corrupts the training data by injecting a small amount of poison into it, i.e., astutely crafted malicious samples. In this position paper, we address the security of AI code generators by identifying a novel data poisoning attack that results in the generation of vulnerable code. Next, we devise an extensive evaluation of how these attacks impact state-of-the-art models for code generation. Lastly, we discuss potential solutions to overcome this threat.
    
[^29]: 汽车损伤检测及补丁到补丁的自监督图像对齐

    Car Damage Detection and Patch-to-Patch Self-supervised Image Alignment

    [https://arxiv.org/abs/2403.06674](https://arxiv.org/abs/2403.06674)

    该论文提出了一种新颖的基于自监督的补丁对补丁SimCLR对齐方法，用于汽车损伤检测的图像对齐，实现了汽车损伤检测和图像对齐两大组件的结合。

    

    大多数计算机视觉应用旨在识别场景中的像素，并将它们用于各种目的。其中一个有趣的应用是保险公司的汽车损伤检测，它倾向于通过比较行程前后的图片来检测所有汽车损伤，甚至需要两个组件：(i) 汽车损伤检测；(ii) 图像对齐。首先，我们实现了一个Mask R-CNN模型来检测自定义图片上的汽车损伤。而对于图像对齐部分，我们特别提出了一种新颖的受自监督启发的补丁对补丁SimCLR对齐方法，以找到自定义行程前/行程后汽车租赁图片之间的透视变换，除了传统的计算机视觉方法。

    arXiv:2403.06674v1 Announce Type: cross  Abstract: Most computer vision applications aim to identify pixels in a scene and use them for diverse purposes. One intriguing application is car damage detection for insurance carriers which tends to detect all car damages by comparing both pre-trip and post-trip images, even requiring two components: (i) car damage detection; (ii) image alignment. Firstly, we implemented a Mask R-CNN model to detect car damages on custom images. Whereas for the image alignment section, we especially propose a novel self-supervised Patch-to-Patch SimCLR inspired alignment approach to find perspective transformations between custom pre/post car rental images except for traditional computer vision methods.
    
[^30]: CEAT：用于非示范类增量学习的持续扩展和吸收变压器

    CEAT: Continual Expansion and Absorption Transformer for Non-Exemplar Class-Incremental Learnin

    [https://arxiv.org/abs/2403.06670](https://arxiv.org/abs/2403.06670)

    CEAT提出了一种用于非示范类增量学习的新架构，通过持续扩展和吸收参数的方式解决了可塑性-稳定性困境和分类器偏差问题

    

    在现实世界的应用中，动态场景要求模型具备不断学习新任务而不忘记旧知识的能力。经验重放方法存储一部分旧图像进行联合训练。在更严格的隐私保护场景中，存储旧图像变得不可行，这导致了更为严重的可塑性-稳定性困境和分类器偏差。为应对上述挑战，我们提出了一种新的架构，称为持续扩展和吸收变压器（CEAT）。模型可以通过将扩展-融合层与冻结前期参数并行扩展来学习新知识。任务结束后，我们无损地吸收扩展的参数到主干，以确保参数数量保持恒定。为提高模型的学习能力，我们设计了一种新颖的原型对比损失，以减少旧类和新类之间的重叠。

    arXiv:2403.06670v1 Announce Type: cross  Abstract: In real-world applications, dynamic scenarios require the models to possess the capability to learn new tasks continuously without forgetting the old knowledge. Experience-Replay methods store a subset of the old images for joint training. In the scenario of more strict privacy protection, storing the old images becomes infeasible, which leads to a more severe plasticity-stability dilemma and classifier bias. To meet the above challenges, we propose a new architecture, named continual expansion and absorption transformer~(CEAT). The model can learn the novel knowledge by extending the expanded-fusion layers in parallel with the frozen previous parameters. After the task ends, we losslessly absorb the extended parameters into the backbone to ensure that the number of parameters remains constant. To improve the learning ability of the model, we designed a novel prototype contrastive loss to reduce the overlap between old and new classes 
    
[^31]: FashionReGen: 基于LLM的时尚报告生成

    FashionReGen: LLM-Empowered Fashion Report Generation

    [https://arxiv.org/abs/2403.06660](https://arxiv.org/abs/2403.06660)

    提出了一个基于先进的大型语言模型(LLM)的智能时尚分析和报告系统 GPT-FAR，旨在通过有效的秀场分析来生成时尚报告。

    

    时尚分析是指审查和评估时尚行业内的趋势、风格和元素的过程，以理解和解释其当前状态，并生成时尚报告。本文提出了一种基于先进的大型语言模型(LLM)的智能时尚分析和报告系统，称为GPT-FAR，以应对时尚报告生成（FashionReGen）任务。具体来说，它试图通过有效的秀场分析来进行FashionReGen，该分析系统具有几个关键过程，即秀场理解、集体组织和分析，以及报告生成。

    arXiv:2403.06660v1 Announce Type: cross  Abstract: Fashion analysis refers to the process of examining and evaluating trends, styles, and elements within the fashion industry to understand and interpret its current state, generating fashion reports. It is traditionally performed by fashion professionals based on their expertise and experience, which requires high labour cost and may also produce biased results for relying heavily on a small group of people. In this paper, to tackle the Fashion Report Generation (FashionReGen) task, we propose an intelligent Fashion Analyzing and Reporting system based the advanced Large Language Models (LLMs), debbed as GPT-FAR. Specifically, it tries to deliver FashionReGen based on effective catwalk analysis, which is equipped with several key procedures, namely, catwalk understanding, collective organization and analysis, and report generation. By posing and exploring such an open-ended, complex and domain-specific task of FashionReGen, it is able t
    
[^32]: 基于多模态学习和测试时临床知识增强的零样本心电图分类

    Zero-Shot ECG Classification with Multimodal Learning and Test-time Clinical Knowledge Enhancement

    [https://arxiv.org/abs/2403.06659](https://arxiv.org/abs/2403.06659)

    通过Multimodal ECG Representation Learning (MERL)框架，本文提出了一种零样本心电图分类方法，结合了对ECG记录和相关报告的多模态学习，同时在测试阶段使用了Clinical Knowledge Enhanced Prompt Engineering (CKEPE)方法来利用临床知识数据库。

    

    心电图（ECG）是临床实践中用于检测心律失常疾病的非侵入性诊断工具。在未经注释的ECG数据中进行自监督学习（eSSL）方法显示出了表征学习的潜力，但往往忽视了可以在报告中找到的临床知识。本文通过多模态学习ECG记录和相关报告，提出了Multimodal ECG Representation Learning (MERL)框架，该框架能够使用文本提示进行零样本ECG分类，消除了下游任务中对训练数据的需求。在测试时，我们提出了Clinical Knowledge Enhanced Prompt Engineering (CKEPE)方法，利用大型语言模型（LLM）来利用外部专家验证的临床知识数据库，生成更多关于患者病史的提示。

    arXiv:2403.06659v1 Announce Type: cross  Abstract: Electrocardiograms (ECGs) are non-invasive diagnostic tools crucial for detecting cardiac arrhythmic diseases in clinical practice. While ECG Self-supervised Learning (eSSL) methods show promise in representation learning from unannotated ECG data, they often overlook the clinical knowledge that can be found in reports. This oversight and the requirement for annotated samples for downstream tasks limit eSSL's versatility. In this work, we address these issues with the Multimodal ECG Representation Learning (MERL}) framework. Through multimodal learning on ECG records and associated reports, MERL is capable of performing zero-shot ECG classification with text prompts, eliminating the need for training data in downstream tasks. At test time, we propose the Clinical Knowledge Enhanced Prompt Engineering (CKEPE) approach, which uses Large Language Models (LLMs) to exploit external expert-verified clinical knowledge databases, generating mo
    
[^33]: KELLMRec: 知识增强大型语言模型用于推荐

    KELLMRec: Knowledge-Enhanced Large Language Models for Recommendation

    [https://arxiv.org/abs/2403.06642](https://arxiv.org/abs/2403.06642)

    提出了一种知识增强的大型语言模型用于推荐的方法，通过使用外部知识来帮助生成真实可用的文本，并包括知识为基础的对比学习方案进行训练。

    

    在推荐系统领域，利用语义信息是一个重要的研究问题，旨在补充主流基于ID的方法的缺失部分。随着LLM的兴起，它作为知识库的能力和推理能力为这一研究领域开辟了新的可能性，使基于LLM的推荐成为新兴研究方向。然而，直接使用LLM来处理推荐场景中的语义信息是不可靠和次优的，由于存在幻觉等问题。应对这一问题的一种有前途的方法是利用外部知识来帮助LLM生成真实可用的文本。受以上动机的启发，我们提出了一种知识增强的LLMRec方法。除了在提示中使用外部知识外，所提出的方法还包括一个基于知识的对比学习方案用于训练。在公共数据集和企业中进行的实验

    arXiv:2403.06642v1 Announce Type: cross  Abstract: The utilization of semantic information is an important research problem in the field of recommender systems, which aims to complement the missing parts of mainstream ID-based approaches. With the rise of LLM, its ability to act as a knowledge base and its reasoning capability have opened up new possibilities for this research area, making LLM-based recommendation an emerging research direction. However, directly using LLM to process semantic information for recommendation scenarios is unreliable and sub-optimal due to several problems such as hallucination. A promising way to cope with this is to use external knowledge to aid LLM in generating truthful and usable text. Inspired by the above motivation, we propose a Knowledge-Enhanced LLMRec method. In addition to using external knowledge in prompts, the proposed method also includes a knowledge-based contrastive learning scheme for training. Experiments on public datasets and in-enter
    
[^34]: 评估在工业环境中物体检测中少样本学习的能效性

    Evaluating the Energy Efficiency of Few-Shot Learning for Object Detection in Industrial Settings

    [https://arxiv.org/abs/2403.06631](https://arxiv.org/abs/2403.06631)

    本文研究了在工业环境中使用少样本学习进行物体检测的能效性，通过微调方法降低了能源消耗，并对模型在工业环境数据集上的能源需求进行了评估。

    

    在人工智能不断发展的时代，模型性能一直是驱动创新的关键指标，导致模型大小和复杂性呈指数级增长。然而，在当代工业环境中，可持续性和能效性一直是部署过程中的关键要求，因此需要使用少样本学习等数据高效方法。本文通过微调方法来减轻模型训练的负担，降低能源消耗，将标准物体检测模型调整到下游任务。随后，对开发的模型在不稳定工业环境中的物体检测基准数据集的能源需求进行了深入案例研究和评估。具体地，研究了不同的微调策略以及在训练过程中利用辅助评估数据，以及性能和能耗之间的权衡。

    arXiv:2403.06631v1 Announce Type: cross  Abstract: In the ever-evolving era of Artificial Intelligence (AI), model performance has constituted a key metric driving innovation, leading to an exponential growth in model size and complexity. However, sustainability and energy efficiency have been critical requirements during deployment in contemporary industrial settings, necessitating the use of data-efficient approaches such as few-shot learning. In this paper, to alleviate the burden of lengthy model training and minimize energy consumption, a finetuning approach to adapt standard object detection models to downstream tasks is examined. Subsequently, a thorough case study and evaluation of the energy demands of the developed models, applied in object detection benchmark datasets from volatile industrial environments is presented. Specifically, different finetuning strategies as well as utilization of ancillary evaluation data during training are examined, and the trade-off between perf
    
[^35]: 针对航空语义分割和深度估计的森林巡检数据集

    Forest Inspection Dataset for Aerial Semantic Segmentation and Depth Estimation

    [https://arxiv.org/abs/2403.06621](https://arxiv.org/abs/2403.06621)

    引入了一个新的大型航空数据集，包含了自然环境的真实和虚拟录像，使用密集注释的语义分割标签和深度地图，在不同条件下拍摄，用于训练深度学习算法解决森林巡检问题。

    

    人类使用无人机来监测森林环境的变化，因为它们重量轻，提供了大量的监视数据。然而，它们的信息并不足以展示足够的细节，这对于评估森林砍伐程度是必要的。为了解决这个问题，我们引入了一个新的大型航空数据集，其中包含自然环境的真实和虚拟录影，具有密集注释的语义分割标签和深度地图，拍摄于不同的照明条件，不同高度和记录角度。我们测试了两个多尺度神经网络解决语义分割任务的性能（HRNet和PointFlow网络），研究了各种获取方式的影响。

    arXiv:2403.06621v1 Announce Type: cross  Abstract: Humans use UAVs to monitor changes in forest environments since they are lightweight and provide a large variety of surveillance data. However, their information does not present enough details for understanding the scene which is needed to assess the degree of deforestation. Deep learning algorithms must be trained on large amounts of data to output accurate interpretations, but ground truth recordings of annotated forest imagery are not available. To solve this problem, we introduce a new large aerial dataset for forest inspection which contains both real-world and virtual recordings of natural environments, with densely annotated semantic segmentation labels and depth maps, taken in different illumination conditions, at various altitudes and recording angles. We test the performance of two multi-scale neural networks for solving the semantic segmentation task (HRNet and PointFlow network), studying the impact of the various acquisit
    
[^36]: MedKP：医学对话与知识增强与临床路径编码

    MedKP: Medical Dialogue with Knowledge Enhancement and Clinical Pathway Encoding

    [https://arxiv.org/abs/2403.06611](https://arxiv.org/abs/2403.06611)

    通过整合外部知识增强模块和内部临床路径编码，MedKP框架在医学对话生成中取得了显著进展。

    

    通过适当的数据选择和训练技术，大型语言模型（LLMs）在各种医学考试和多项选择问题中表现出色。 然而，LLMs在医学对话生成领域的应用--这个任务更加贴近实际医学实践--却鲜有探讨。 这一差距归因于LLMs医学知识不足，导致生成的医学回复出现不准确和幻觉信息。 在这项工作中，我们介绍了医学对话与知识增强和临床路径编码（MedKP）框架，通过医学知识图和医疗实体以及医师行动的内部临床路径编码，集成了外部知识增强模块。 通过全面指标进行评估，我们在两个大规模、真实世界的在线医学咨询数据集（MedDG和KaMed）上的实验表明

    arXiv:2403.06611v1 Announce Type: cross  Abstract: With appropriate data selection and training techniques, Large Language Models (LLMs) have demonstrated exceptional success in various medical examinations and multiple-choice questions. However, the application of LLMs in medical dialogue generation-a task more closely aligned with actual medical practice-has been less explored. This gap is attributed to the insufficient medical knowledge of LLMs, which leads to inaccuracies and hallucinated information in the generated medical responses. In this work, we introduce the Medical dialogue with Knowledge enhancement and clinical Pathway encoding (MedKP) framework, which integrates an external knowledge enhancement module through a medical knowledge graph and an internal clinical pathway encoding via medical entities and physician actions. Evaluated with comprehensive metrics, our experiments on two large-scale, real-world online medical consultation datasets (MedDG and KaMed) demonstrate 
    
[^37]: 通过知识种子指导大型语言模型的临床推理

    Guiding Clinical Reasoning with Large Language Models via Knowledge Seeds

    [https://arxiv.org/abs/2403.06609](https://arxiv.org/abs/2403.06609)

    大型语言模型在临床推理中展现出潜力，但存在幻觉问题和与医生决策路径不一致的挑战。

    

    临床推理是医生在评估和管理患者时采用的认知过程。这个过程通常涉及建议必要的检查，诊断患者疾病，并决定适当的治疗等。准确的临床推理需要广泛的医学知识和丰富的临床经验，为医生设置了很高的门槛。最近，像ChatGPT和GPT-4这样的大型语言模型(LLMs)显示出在临床推理中的潜力。然而，这些LLMs容易出现幻觉问题，而LLMs的推理过程可能与医生的临床决策路径不一致。在这项研究中，我们引入了一种

    arXiv:2403.06609v1 Announce Type: cross  Abstract: Clinical reasoning refers to the cognitive process that physicians employ in evaluating and managing patients. This process typically involves suggesting necessary examinations, diagnosing patients' diseases, and deciding on appropriate therapies, etc. Accurate clinical reasoning requires extensive medical knowledge and rich clinical experience, setting a high bar for physicians. This is particularly challenging in developing countries due to the overwhelming number of patients and limited physician resources, contributing significantly to global health inequity and necessitating automated clinical reasoning approaches. Recently, the emergence of large language models (LLMs) such as ChatGPT and GPT-4 have demonstrated their potential in clinical reasoning. However, these LLMs are prone to hallucination problems, and the reasoning process of LLMs may not align with the clinical decision path of physicians. In this study, we introduce a 
    
[^38]: 图像到图形变换中的跨域和跨维度学习

    Cross-domain and Cross-dimension Learning for Image-to-Graph Transformers

    [https://arxiv.org/abs/2403.06601](https://arxiv.org/abs/2403.06601)

    该论文提出了一种用于图像到图形转换器的跨域和跨维度迁移学习方法，包括正则化边缘采样损失、领域自适应框架和简单的投影函数，可以解决数据稀缺性问题，并在实验中展示了其实用性。

    

    直接的图像到图形转换是一个具有挑战性的任务，它在单个模型中解决了目标检测和关系预测。由于这个任务的复杂性，在许多领域中很难找到大型训练数据集，这使得训练大型网络具有挑战性。这种数据稀疏性需要建立类似于计算机视觉中最先进技术的预训练策略。在这项工作中，我们引入了一套方法，实现了图像到图形转换器的跨域和跨维度迁移学习。我们提出了(1) 正则化边缘采样损失，用于在不同领域中采样最佳数量的目标关系(边缘)，(2) 一种图像到图形转换器的领域自适应框架，可以对齐不同领域的特征，和(3) 一种简单的投影函数，使我们能够在二维输入数据上预训练三维转换器。我们展示了我们的方法在跨域和跨维度下的实用性。

    arXiv:2403.06601v1 Announce Type: cross  Abstract: Direct image-to-graph transformation is a challenging task that solves object detection and relationship prediction in a single model. Due to the complexity of this task, large training datasets are rare in many domains, which makes the training of large networks challenging. This data sparsity necessitates the establishment of pre-training strategies akin to the state-of-the-art in computer vision. In this work, we introduce a set of methods enabling cross-domain and cross-dimension transfer learning for image-to-graph transformers. We propose (1) a regularized edge sampling loss for sampling the optimal number of object relationships (edges) across domains, (2) a domain adaptation framework for image-to-graph transformers that aligns features from different domains, and (3) a simple projection function that allows us to pretrain 3D transformers on 2D input data. We demonstrate our method's utility in cross-domain and cross-dimension 
    
[^39]: 利用样式潜在流来推广深度伪造视频检测

    Exploiting Style Latent Flows for Generalizing Deepfake Detection Video Detection

    [https://arxiv.org/abs/2403.06592](https://arxiv.org/abs/2403.06592)

    该研究提出了一种利用样式潜在流进行深度伪造视频检测的新方法，通过分析样式潜在向量在生成视频中的异常行为来检测假视频，利用对比学习训练的StyleGRU模块和样式注意模块的组合，能有效检测视觉和时间异常。

    

    本文提出了一种基于分析样式潜在向量及其在生成视频的时间变化中异常行为的检测假视频的新方法。我们发现生成的面部视频在样式潜在向量的时间变化中存在时间上的独特性，这在生成具有各种面部表情和几何变换的时间稳定视频时是不可避免的。我们的框架利用了通过对比学习训练的StyleGRU模块来表示样式潜在向量的动态特性。另外，我们引入了一个样式注意模块，将StyleGRU生成的特征与基于内容的特征相结合，实现对视觉和时间异常的检测。我们在深度伪造检测的各种基准情景下展示了我们的方法，展示了它在跨数据集和跨操作情景中的优越性。

    arXiv:2403.06592v1 Announce Type: cross  Abstract: This paper presents a new approach for the detection of fake videos, based on the analysis of style latent vectors and their abnormal behavior in temporal changes in the generated videos. We discovered that the generated facial videos suffer from the temporal distinctiveness in the temporal changes of style latent vectors, which are inevitable during the generation of temporally stable videos with various facial expressions and geometric transformations. Our framework utilizes the StyleGRU module, trained by contrastive learning, to represent the dynamic properties of style latent vectors. Additionally, we introduce a style attention module that integrates StyleGRU-generated features with content-based features, enabling the detection of visual and temporal artifacts. We demonstrate our approach across various benchmark scenarios in deepfake detection, showing its superiority in cross-dataset and cross-manipulation scenarios. Through f
    
[^40]: ContextGPT: 将LLMs知识注入神经符号活动识别模型

    ContextGPT: Infusing LLMs Knowledge into Neuro-Symbolic Activity Recognition Models

    [https://arxiv.org/abs/2403.06586](https://arxiv.org/abs/2403.06586)

    将预训练的大型语言模型（LLMs）的常识知识有效地注入神经符号活动识别模型，以缓解标记数据稀缺性问题。

    

    上下文感知人类活动识别（HAR）是移动计算中一个热门的研究领域，文献中最有效的解决方案基于监督式深度学习模型。然而，这些系统的实际部署受到需要用于训练的标记数据的稀缺性的限制。神经符号人工智能（NeSy）为缓解这一问题提供了一个有趣的研究方向，即将关于人类活动及其可能发生的背景的常识知识注入HAR深度学习分类器中。现有的用于上下文感知HAR的NeSy方法依赖于逻辑模型中编码的知识（例如本体论），其设计、实施和维护以捕捉新活动和上下文需要显著的人力工程努力、技术知识和领域专业知识。最近的研究表明，预训练的大型语言模型（LLMs）有效地编码了关于人类活动的常识知识。

    arXiv:2403.06586v1 Announce Type: cross  Abstract: Context-aware Human Activity Recognition (HAR) is a hot research area in mobile computing, and the most effective solutions in the literature are based on supervised deep learning models. However, the actual deployment of these systems is limited by the scarcity of labeled data that is required for training. Neuro-Symbolic AI (NeSy) provides an interesting research direction to mitigate this issue, by infusing common-sense knowledge about human activities and the contexts in which they can be performed into HAR deep learning classifiers. Existing NeSy methods for context-aware HAR rely on knowledge encoded in logic-based models (e.g., ontologies) whose design, implementation, and maintenance to capture new activities and contexts require significant human engineering efforts, technical knowledge, and domain expertise. Recent works show that pre-trained Large Language Models (LLMs) effectively encode common-sense knowledge about human a
    
[^41]: 通过任意性能分析更好地理解和配置MaxSAT本地搜索求解器

    Better Understandings and Configurations in MaxSAT Local Search Solvers via Anytime Performance Analysis

    [https://arxiv.org/abs/2403.06568](https://arxiv.org/abs/2403.06568)

    通过任意性能分析显示出MaxSAT本地搜索求解器在不同时间预算下的性能优劣变化

    

    尽管已经提出了许多用于MaxSAT问题的求解器，并且诸如MaxSAT Evaluations之类的基准环境提供了一个平台，用于比较最先进的求解器，但现有的评估通常是基于在给定运行时间预算内获得的最佳解的质量来评估的。然而，仅考虑特定时间预算内最终获得的解可能会限制我们理解求解器在收敛过程中的行为。本文证明了经验累积分布函数可用于比较MaxSAT本地搜索求解器在多个问题实例和不同时间预算下的任意性能。评估揭示了求解器性能的差异，并显示出求解器的（不）优势随着不同运行时间的调整。这项工作还展示了定量和高方差的评估

    arXiv:2403.06568v1 Announce Type: new  Abstract: Though numerous solvers have been proposed for the MaxSAT problem, and the benchmark environment such as MaxSAT Evaluations provides a platform for the comparison of the state-of-the-art solvers, existing assessments were usually evaluated based on the quality, e.g., fitness, of the best-found solutions obtained within a given running time budget. However, concerning solely the final obtained solutions regarding specific time budgets may restrict us from comprehending the behavior of the solvers along the convergence process. This paper demonstrates that Empirical Cumulative Distribution Functions can be used to compare MaxSAT local search solvers' anytime performance across multiple problem instances and various time budgets. The assessment reveals distinctions in solvers' performance and displays that the (dis)advantages of solvers adjust along different running times. This work also exhibits that the quantitative and high variance ass
    
[^42]: ReStainGAN:利用IHC到IF染色域转换进行in-silico数据生成

    ReStainGAN: Leveraging IHC to IF Stain Domain Translation for in-silico Data Generation

    [https://arxiv.org/abs/2403.06545](https://arxiv.org/abs/2403.06545)

    提出了一种新的方法，通过将形态特定的IHC染色分解为单独的图像通道，生成了in-silico免疫组织化学（IHC）图像，该方法在训练细胞核分割模型时在质量和数量上优于基线方法。

    

    arXiv:2403.06545v1 公告类型：交叉摘要：通过在计算病理学中扩展现有注释的实用性到具有不同染色模式的新领域中，可以创造in-silico数据集。因此，这有可能大幅降低构建训练监督深度学习模型所需的大型且像素精确的数据集的成本。我们提出了一种新颖方法，通过在免疫荧光（IF）图像中将形态特定的IHC染色分离成单独的图像通道，生成in-silico免疫组织化学（IHC）图像。所提出的方法在创建的in-silico数据集上通过训练细胞核分割模型在质量和数量上优于基线方法。

    arXiv:2403.06545v1 Announce Type: cross  Abstract: The creation of in-silico datasets can expand the utility of existing annotations to new domains with different staining patterns in computational pathology. As such, it has the potential to significantly lower the cost associated with building large and pixel precise datasets needed to train supervised deep learning models. We propose a novel approach for the generation of in-silico immunohistochemistry (IHC) images by disentangling morphology specific IHC stains into separate image channels in immunofluorescence (IF) images. The proposed approach qualitatively and quantitatively outperforms baseline methods as proven by training nucleus segmentation models on the created in-silico datasets.
    
[^43]: 分散和终身自适应多智能体协作学习

    Decentralized and Lifelong-Adaptive Multi-Agent Collaborative Learning

    [https://arxiv.org/abs/2403.06535](https://arxiv.org/abs/2403.06535)

    本文提出了DeLAMA，一种具有动态协作图的分散多智能体终身协作学习算法，旨在通过自主识别协作关系和适应动态任务来增强多智能体之间的协作。

    

    分散和终身自适应多智能体协作学习旨在增强多个智能体之间的协作，不需要中央服务器，每个智能体随时间解决不同的任务。为了实现高效的协作，智能体应该：i) 在分散的方式下自主识别有益的协作关系；ii) 适应动态变化的任务观察。本文提出了DeLAMA，一种具有动态协作图的分散多智能体终身协作学习算法。为了促进自主协作关系学习，我们提出了一种分散的图结构学习算法，消除了对外部先验知识的需求。为了促进适应动态任务，我们设计了一个存储单元来捕获智能体积累的学习历史和知识，同时保持有限的存储消耗。为了进一步增强系统的表达能力和计算

    arXiv:2403.06535v1 Announce Type: cross  Abstract: Decentralized and lifelong-adaptive multi-agent collaborative learning aims to enhance collaboration among multiple agents without a central server, with each agent solving varied tasks over time. To achieve efficient collaboration, agents should: i) autonomously identify beneficial collaborative relationships in a decentralized manner; and ii) adapt to dynamically changing task observations. In this paper, we propose DeLAMA, a decentralized multi-agent lifelong collaborative learning algorithm with dynamic collaboration graphs. To promote autonomous collaboration relationship learning, we propose a decentralized graph structure learning algorithm, eliminating the need for external priors. To facilitate adaptation to dynamic tasks, we design a memory unit to capture the agents' accumulated learning history and knowledge, while preserving finite storage consumption. To further augment the system's expressive capabilities and computation
    
[^44]: SARDet-100K: 面向大规模合成孔径雷达 SAR 物体检测的开源基准和工具包

    SARDet-100K: Towards Open-Source Benchmark and ToolKit for Large-Scale SAR Object Detection

    [https://arxiv.org/abs/2403.06534](https://arxiv.org/abs/2403.06534)

    SARDet-100K是第一个COCO级别的大规模多类别SAR物体检测数据集，为研究提供了大规模且多样化的数据集，揭示了SAR物体检测中预训练模型显著差异的关键挑战。

    

    面向合成孔径雷达（SAR）物体检测近来备受关注，因其不可替代的全天候成像能力。然而，这一研究领域面临着有限的公共数据集（主要包含 <2K 张图像，且仅包含单类别物体）和源代码不可访问的挑战。为解决这些问题，我们建立了一个新的基准数据集和一个针对大规模 SAR 物体检测的开源方法。我们的数据集 SARDet-100K 结果是对 10 个现有 SAR 检测数据集进行深入调研、收集和标准化的产物，为研究提供了一个大规模且多样化的数据集。据我们所知，SARDet-100K 是有史以来第一个达到 COCO 水平的大规模多类别 SAR 物体检测数据集。凭借这一高质量数据集，我们进行了全面实验，并揭示了 SAR 物体检测中一个关键挑战：预训练模型的显著差异。

    arXiv:2403.06534v1 Announce Type: cross  Abstract: Synthetic Aperture Radar (SAR) object detection has gained significant attention recently due to its irreplaceable all-weather imaging capabilities. However, this research field suffers from both limited public datasets (mostly comprising <2K images with only mono-category objects) and inaccessible source code. To tackle these challenges, we establish a new benchmark dataset and an open-source method for large-scale SAR object detection. Our dataset, SARDet-100K, is a result of intense surveying, collecting, and standardizing 10 existing SAR detection datasets, providing a large-scale and diverse dataset for research purposes. To the best of our knowledge, SARDet-100K is the first COCO-level large-scale multi-class SAR object detection dataset ever created. With this high-quality dataset, we conducted comprehensive experiments and uncovered a crucial challenge in SAR object detection: the substantial disparities between the pretraining
    
[^45]: 基于全面运营成本奖励的深度强化学习自主卡车战术决策

    Tactical Decision Making for Autonomous Trucks by Deep Reinforcement Learning with Total Cost of Operation Based Reward

    [https://arxiv.org/abs/2403.06524](https://arxiv.org/abs/2403.06524)

    通过基于全面运营成本的奖励函数，采用深度强化学习框架优化自主卡车的战术决策，将高级决策与低级控制分离，并采用不同技巧提升性能。

    

    我们为自主卡车的战术决策制定了一个基于深度强化学习的框架，特别是针对高速公路场景中的自适应巡航控制（ACC）和变道动作。我们的研究结果表明，在强化学习代理和基于物理模型的低级控制器之间分离高级决策过程和低级控制动作是有益的。接下来，我们研究了通过在卡车的全面运营成本（TCOP）为基础的多目标奖励函数优化性能的不同方法；通过为奖励分量添加权重，通过对奖励分量进行归一化，以及使用课程学习技术。

    arXiv:2403.06524v1 Announce Type: cross  Abstract: We develop a deep reinforcement learning framework for tactical decision making in an autonomous truck, specifically for Adaptive Cruise Control (ACC) and lane change maneuvers in a highway scenario. Our results demonstrate that it is beneficial to separate high-level decision-making processes and low-level control actions between the reinforcement learning agent and the low-level controllers based on physical models. In the following, we study optimizing the performance with a realistic and multi-objective reward function based on Total Cost of Operation (TCOP) of the truck using different approaches; by adding weights to reward components, by normalizing the reward components and by using curriculum learning techniques.
    
[^46]: 如何理解命名实体：在新闻标题生成中使用常识

    How to Understand Named Entities: Using Common Sense for News Captioning

    [https://arxiv.org/abs/2403.06520](https://arxiv.org/abs/2403.06520)

    该论文利用常识知识来帮助新闻标题生成系统理解命名实体，从而更好地描述图像内容。

    

    新闻标题生成旨在使用新闻文章主体描述图像。它在很大程度上依赖于一组检测到的命名实体，包括真实世界的人物、组织和地点。本文利用常识知识来理解新闻标题生成中的命名实体。通过“理解”，我们指的是将新闻内容与常识联系起来，帮助代理人区分语义上相似的命名实体，并利用训练语料库之外的词语描述命名实体。

    arXiv:2403.06520v1 Announce Type: cross  Abstract: News captioning aims to describe an image with its news article body as input. It greatly relies on a set of detected named entities, including real-world people, organizations, and places. This paper exploits commonsense knowledge to understand named entities for news captioning. By ``understand'', we mean correlating the news content with common sense in the wild, which helps an agent to 1) distinguish semantically similar named entities and 2) describe named entities using words outside of training corpora. Our approach consists of three modules: (a) Filter Module aims to clarify the common sense concerning a named entity from two aspects: what does it mean? and what is it related to?, which divide the common sense into explanatory knowledge and relevant knowledge, respectively. (b) Distinguish Module aggregates explanatory knowledge from node-degree, dependency, and distinguish three aspects to distinguish semantically similar name
    
[^47]: 图像分类的主动生成

    Active Generation for Image Classification

    [https://arxiv.org/abs/2403.06517](https://arxiv.org/abs/2403.06517)

    该论文提出了一种名为ActGen的方法，通过采用训练感知的方式来生成图像，以提高图像分类准确性。ActGen利用主动学习的理念，生成类似于挑战性或被误分类样本的图像，并将其整合到训练集中，从而增强模型性能。

    

    最近，深度生成模型不断增强的能力突显了它们在提高图像分类准确性方面的潜力。然而，现有方法往往要求生成的图像数量远远超过原始数据集，而在准确性方面只有极小的改进。这种计算昂贵且耗时的过程阻碍了这种方法的实用性。在本文中，我们提出通过专注于模型的具体需求和特征来提高图像生成的效率。我们的方法ActGen以主动学习为中心原则，采用了一个针对训练感知的图像生成方法。它旨在创建类似于当前模型遇到的具有挑战性或被误分类样本的图像，并将这些生成的图像纳入训练集以增强模型性能。

    arXiv:2403.06517v1 Announce Type: cross  Abstract: Recently, the growing capabilities of deep generative models have underscored their potential in enhancing image classification accuracy. However, existing methods often demand the generation of a disproportionately large number of images compared to the original dataset, while having only marginal improvements in accuracy. This computationally expensive and time-consuming process hampers the practicality of such approaches. In this paper, we propose to address the efficiency of image generation by focusing on the specific needs and characteristics of the model. With a central tenet of active learning, our method, named ActGen, takes a training-aware approach to image generation. It aims to create images akin to the challenging or misclassified samples encountered by the current model and incorporates these generated images into the training set to augment model performance. ActGen introduces an attentive image guidance technique, usin
    
[^48]: 构建数据结构：走向语义图因果关系

    Structure Your Data: Towards Semantic Graph Counterfactuals

    [https://arxiv.org/abs/2403.06514](https://arxiv.org/abs/2403.06514)

    提出了基于语义图的反事实解释方法，利用GNN来进行高效的图编辑距离计算，通过场景图形式，绕过NP困难的图相似性问题，实现更具描述性、准确性和与人类对齐的解释。

    

    基于概念的反事实解释（CEs）是考虑替代情景以了解哪些高级语义特征对特定模型预测做出了贡献的解释。在这项工作中，我们提出了基于伴随输入数据的语义图的CEs，以实现更具描述性、准确性和与人类对齐的解释。借鉴最先进的概念尝试，我们采用了一个基于模型的编辑方法，并引入了利用GNN来实现高效的图编辑距离（GED）计算。我们将图形结构用于视觉领域，将图像表示为场景图，并获得它们的GNN嵌入以绕过解决所有输入对的NP困难图相似性问题，这是CE计算过程的一个重要部分。我们将我们的方法应用于具有不同难度和语义注释可用性的基准和真实世界数据集上。在各种分类器上进行测试，我们发现我们的CEs表现优异。

    arXiv:2403.06514v1 Announce Type: cross  Abstract: Counterfactual explanations (CEs) based on concepts are explanations that consider alternative scenarios to understand which high-level semantic features contributed to particular model predictions. In this work, we propose CEs based on the semantic graphs accompanying input data to achieve more descriptive, accurate, and human-aligned explanations. Building upon state-of-the-art (SoTA) conceptual attempts, we adopt a model-agnostic edit-based approach and introduce leveraging GNNs for efficient Graph Edit Distance (GED) computation. With a focus on the visual domain, we represent images as scene graphs and obtain their GNN embeddings to bypass solving the NP-hard graph similarity problem for all input pairs, an integral part of the CE computation process. We apply our method to benchmark and real-world datasets with varying difficulty and availability of semantic annotations. Testing on diverse classifiers, we find that our CEs outper
    
[^49]: 排列质量函数的否定

    The negation of permutation mass function

    [https://arxiv.org/abs/2403.06483](https://arxiv.org/abs/2403.06483)

    本文提出了排列质量函数的否定方法，并验证了其收敛性，研究了否定操作后的不确定性和不相似性变化趋势。

    

    否定是知识表示中的一个重要视角。现有的否定方法主要应用于概率论、证据理论和复杂证据理论。作为证据理论的一种泛化，随机排列集合理论可以更精确地表示信息。然而，如何将否定的概念应用于随机排列集合理论尚未被研究。本文提出了排列质量函数的否定。此外，在否定过程中，验证了所提出的否定方法的收敛性。研究了每个否定操作后不确定性和不相似性的趋势。数值例子被用来证明所提出方法的合理性。

    arXiv:2403.06483v1 Announce Type: new  Abstract: Negation is a important perspective of knowledge representation. Existing negation methods are mainly applied in probability theory, evidence theory and complex evidence theory. As a generalization of evidence theory, random permutation sets theory may represent information more precisely. However, how to apply the concept of negation to random permutation sets theory has not been studied. In this paper, the negation of permutation mass function is proposed. Moreover, in the negation process, the convergence of proposed negation method is verified. The trends of uncertainty and dissimilarity after each negation operation are investigated. Numerical examples are used to demonstrate the rationality of the proposed method.
    
[^50]: Ada-Tracker：通过帧间和自适应模板匹配进行软组织跟踪

    Ada-Tracker: Soft Tissue Tracking via Inter-Frame and Adaptive-Template Matching

    [https://arxiv.org/abs/2403.06479](https://arxiv.org/abs/2403.06479)

    Ada-Tracker利用光流捕捉像素级组织变形并自适应纠正跟踪模板，同时结合帧间匹配和自适应模板匹配，解决了在手术场景中软组织跟踪面临的形状和外观改变困难的问题。

    

    软组织跟踪对计算机辅助手术至关重要。现有方法主要依赖于从模板和视频中提取辨别特征来恢复相应匹配。然而，在手术场景中采用这些技术很困难，因为组织在整个手术过程中会改变形状和外观。为了解决这个问题，我们利用光流来自然捕捉像素级组织变形，并自适应性地纠正跟踪模板。具体而言，我们首先实现一个帧间匹配机制，基于连续帧之间的光流提取一个粗略感兴趣区域。为了适应外观变化和减轻漂移，然后提出了一种自适应模板匹配方法，根据估计的可靠性更新跟踪模板。我们的方法Ada-Tracker通过捕捉局部变形来享受短期动态建模和长期

    arXiv:2403.06479v1 Announce Type: cross  Abstract: Soft tissue tracking is crucial for computer-assisted interventions. Existing approaches mainly rely on extracting discriminative features from the template and videos to recover corresponding matches. However, it is difficult to adopt these techniques in surgical scenes, where tissues are changing in shape and appearance throughout the surgery. To address this problem, we exploit optical flow to naturally capture the pixel-wise tissue deformations and adaptively correct the tracked template. Specifically, we first implement an inter-frame matching mechanism to extract a coarse region of interest based on optical flow from consecutive frames. To accommodate appearance change and alleviate drift, we then propose an adaptive-template matching method, which updates the tracked template based on the reliability of the estimates. Our approach, Ada-Tracker, enjoys both short-term dynamics modeling by capturing local deformations and long-ter
    
[^51]: RL-MSA：基于强化学习的多线路公交车调度方法

    RL-MSA: a Reinforcement Learning-based Multi-line bus Scheduling Approach

    [https://arxiv.org/abs/2403.06466](https://arxiv.org/abs/2403.06466)

    RL-MSA提出了一种基于强化学习的多线路公交车调度方法，将多线路公交车调度问题建模为MDP，首次在离线阶段将直行车决策整合入公交车选择决策，有效简化学习问题，在线阶段通过时间窗口机制进行直行车决策。

    

    多线路公交车调度问题（MLBSP）对于节省公交公司运营成本和保证乘客服务质量至关重要。现有方法通常以离线方式生成公交车调度方案，然后根据该方案安排公交车。然而在实践中，诸如交通拥堵之类的不确定事件经常发生，这可能使事先确定的公交车调度方案变得不可行。本文将MLBSP建模为马尔科夫决策过程（MDP）。提出了一种基于强化学习的多线路公交车调度方法（RL-MSA），用于在离线和在线阶段进行公交车调度。在离线阶段，将直行车决策整合到首次出现的公交车选择决策中，以简化学习问题。在在线阶段，通过基于离线阶段学会的策略进行直行车决策，采用时间窗口机制。我们开发了几个新的有用状态特征包括

    arXiv:2403.06466v1 Announce Type: cross  Abstract: Multiple Line Bus Scheduling Problem (MLBSP) is vital to save operational cost of bus company and guarantee service quality for passengers. Existing approaches typically generate a bus scheduling scheme in an offline manner and then schedule buses according to the scheme. In practice, uncertain events such as traffic congestion occur frequently, which may make the pre-determined bus scheduling scheme infeasible. In this paper, MLBSP is modeled as a Markov Decision Process (MDP). A Reinforcement Learning-based Multi-line bus Scheduling Approach (RL-MSA) is proposed for bus scheduling at both the offline and online phases. At the offline phase, deadhead decision is integrated into bus selection decision for the first time to simplify the learning problem. At the online phase, deadhead decision is made through a time window mechanism based on the policy learned at the offline phase. We develop several new and useful state features includi
    
[^52]: RecAI：利用大型语言模型为下一代推荐系统增添力量

    RecAI: Leveraging Large Language Models for Next-Generation Recommender Systems

    [https://arxiv.org/abs/2403.06465](https://arxiv.org/abs/2403.06465)

    本文介绍了RecAI，一个旨在通过大型语言模型增强推荐系统的实用工具包，新一代由LLMs赋能的推荐系统将更加多才多艺、可解释、对话式和可控，为更智能和用户中心的推荐体验铺平道路。

    

    本文介绍了RecAI，一个实用的工具包，旨在通过大型语言模型（LLMs）的先进能力来增强甚至革新推荐系统。RecAI提供了一系列工具，包括推荐AI代理、面向推荐的语言模型、知识插件、推荐解释器和评估器，以多角度促进LLMs融入推荐系统。LLMs赋能的新一代推荐系统预计将更加多才多艺、可解释、对话式和可控，为更智能和用户中心的推荐体验铺平道路。我们希望RecAI的开源能够加速新一代先进推荐系统的演进。RecAI的源代码可在 \url{https://github.com/microsoft/RecAI} 找到。

    arXiv:2403.06465v1 Announce Type: cross  Abstract: This paper introduces RecAI, a practical toolkit designed to augment or even revolutionize recommender systems with the advanced capabilities of Large Language Models (LLMs). RecAI provides a suite of tools, including Recommender AI Agent, Recommendation-oriented Language Models, Knowledge Plugin, RecExplainer, and Evaluator, to facilitate the integration of LLMs into recommender systems from multifaceted perspectives. The new generation of recommender systems, empowered by LLMs, are expected to be more versatile, explainable, conversational, and controllable, paving the way for more intelligent and user-centric recommendation experiences. We hope the open-source of RecAI can help accelerate evolution of new advanced recommender systems. The source code of RecAI is available at \url{https://github.com/microsoft/RecAI}.
    
[^53]: 基于大型语言模型内部状态的无监督实时幻觉检测

    Unsupervised Real-Time Hallucination Detection based on the Internal States of Large Language Models

    [https://arxiv.org/abs/2403.06448](https://arxiv.org/abs/2403.06448)

    提出了一种利用大型语言模型内部状态进行实时幻觉检测的无监督训练框架，并引入了一个新的基准用于评估多个大型语言模型的幻觉检测。

    

    大型语言模型中的幻觉是指产生连贯但事实不准确的响应。为了解决LLMs中幻觉的问题，本文提出了MIND，一种利用LLMs内部状态进行实时幻觉检测的无监督训练框架。同时，我们还提出了HELM，一个用于评估多个LLMs幻觉检测的新基准，在LLMs推理过程中具有多样化的LLM输出和内部状态。

    arXiv:2403.06448v1 Announce Type: cross  Abstract: Hallucinations in large language models (LLMs) refer to the phenomenon of LLMs producing responses that are coherent yet factually inaccurate. This issue undermines the effectiveness of LLMs in practical applications, necessitating research into detecting and mitigating hallucinations of LLMs. Previous studies have mainly concentrated on post-processing techniques for hallucination detection, which tend to be computationally intensive and limited in effectiveness due to their separation from the LLM's inference process. To overcome these limitations, we introduce MIND, an unsupervised training framework that leverages the internal states of LLMs for real-time hallucination detection without requiring manual annotations. Additionally, we present HELM, a new benchmark for evaluating hallucination detection across multiple LLMs, featuring diverse LLM outputs and the internal states of LLMs during their inference process. Our experiments d
    
[^54]: CoRAL: 协作检索增强大型语言模型改进长尾推荐

    CoRAL: Collaborative Retrieval-Augmented Large Language Models Improve Long-tail Recommendation

    [https://arxiv.org/abs/2403.06447](https://arxiv.org/abs/2403.06447)

    CoRAL引入了协作检索增强LLMs，将协作证据直接纳入到推理过程中，从而更好地理解用户之间的偏好，改进长尾推荐。

    

    长尾推荐对传统推荐系统来说是一个具有挑战性的任务，主要是由于数据稀疏和数据不平衡问题。最近大型语言模型（LLMs）的发展展示了它们在复杂推理方面的能力，可以帮助基于非常少的先前交互来推断用户的偏好。然而，由于大多数基于LLM的系统仅依赖于物品的语义含义作为推理的唯一证据，忽略了用户-物品交互的协作信息，这可能导致LLM的推理与数据集的任务特定协作信息不一致。为了进一步将LLMs的推理与任务特定的用户-物品交互知识相一致，我们引入了协作检索增强LLMs，称为CoRAL，直接将协作证据纳入交互中。基于检索到的用户-物品交互，LLMs可以分析用户之间的共享和不同偏好，并总结

    arXiv:2403.06447v1 Announce Type: cross  Abstract: The long-tail recommendation is a challenging task for traditional recommender systems, due to data sparsity and data imbalance issues. The recent development of large language models (LLMs) has shown their abilities in complex reasoning, which can help to deduce users' preferences based on very few previous interactions. However, since most LLM-based systems rely on items' semantic meaning as the sole evidence for reasoning, the collaborative information of user-item interactions is neglected, which can cause the LLM's reasoning to be misaligned with task-specific collaborative information of the dataset. To further align LLMs' reasoning to task-specific user-item interaction knowledge, we introduce collaborative retrieval-augmented LLMs, CoRAL, which directly incorporate collaborative evidence into the prompts. Based on the retrieved user-item interactions, the LLM can analyze shared and distinct preferences among users, and summariz
    
[^55]: 通过时空虚拟网格进行细粒度柱特征编码用于3D物体检测

    Fine-Grained Pillar Feature Encoding Via Spatio-Temporal Virtual Grid for 3D Object Detection

    [https://arxiv.org/abs/2403.06433](https://arxiv.org/abs/2403.06433)

    本文提出一种名为细粒度柱特征编码（FG-PFE）的新型柱编码架构，利用时空虚拟（STV）网格捕捉每个柱内点云的细粒度分布

    

    开发高性能、实时的基于LiDAR的3D物体检测器对于自动驾驶汽车的成功商业化至关重要。基于柱的方法由于其计算效率而成为机载部署的实用选择。然而，尽管其效率，这些方法有时会对比体素编码或PointNet++等替代点编码技术表现不佳。我们认为当前基于柱的方法并未充分捕捉每个柱结构内LiDAR点的细粒度分布。因此，柱特征编码中存在着相当大的改进空间。在本文中，我们引入了一种名为细粒度柱特征编码（FG-PFE）的新型柱编码架构。FG-PFE利用时空虚拟（STV）网格来捕捉每个柱内点云的分布，跨垂直、时间

    arXiv:2403.06433v1 Announce Type: cross  Abstract: Developing high-performance, real-time architectures for LiDAR-based 3D object detectors is essential for the successful commercialization of autonomous vehicles. Pillar-based methods stand out as a practical choice for onboard deployment due to their computational efficiency. However, despite their efficiency, these methods can sometimes underperform compared to alternative point encoding techniques such as Voxel-encoding or PointNet++. We argue that current pillar-based methods have not sufficiently captured the fine-grained distributions of LiDAR points within each pillar structure. Consequently, there exists considerable room for improvement in pillar feature encoding. In this paper, we introduce a novel pillar encoding architecture referred to as Fine-Grained Pillar Feature Encoding (FG-PFE). FG-PFE utilizes Spatio-Temporal Virtual (STV) grids to capture the distribution of point clouds within each pillar across vertical, temporal
    
[^56]: 基于微分几何视角的图演化上图神经网络的可解释性研究

    A Differential Geometric View and Explainability of GNN on Evolving Graphs

    [https://arxiv.org/abs/2403.06425](https://arxiv.org/abs/2403.06425)

    提出了一种基于微分几何视角的方法，通过流形上的平滑曲线模拟图演化，实现了对图神经网络预测分布的可解释性。

    

    图在社交网络和生物化学中无处不在，图神经网络（GNN）是用于预测的最先进模型。图可能是演化的，形式化建模并理解训练后的GNN如何响应图演化至关重要。我们提出了使用公理归因对GNN预测分布进行平滑参数化，其中分布位于高维嵌入空间内的低维流形上。我们利用微分几何视角将分布演化建模为流形上的平滑曲线。我们重新参数化流形上的曲线族，并设计一个凸优化问题，以找到简洁地近似分布演化以供人类解释的唯一曲线。在节点分类、链接预测和图分类任务中进行了大量实验，这些任务涉及到演化的图，展示了更好的稀疏性、忠实度和直观性。

    arXiv:2403.06425v1 Announce Type: cross  Abstract: Graphs are ubiquitous in social networks and biochemistry, where Graph Neural Networks (GNN) are the state-of-the-art models for prediction. Graphs can be evolving and it is vital to formally model and understand how a trained GNN responds to graph evolution. We propose a smooth parameterization of the GNN predicted distributions using axiomatic attribution, where the distributions are on a low-dimensional manifold within a high-dimensional embedding space. We exploit the differential geometric viewpoint to model distributional evolution as smooth curves on the manifold. We reparameterize families of curves on the manifold and design a convex optimization problem to find a unique curve that concisely approximates the distributional evolution for human interpretation. Extensive experiments on node classification, link prediction, and graph classification tasks with evolving graphs demonstrate the better sparsity, faithfulness, and intui
    
[^57]: RLingua：利用大型语言模型改善在机器人操作中的强化学习样本效率

    RLingua: Improving Reinforcement Learning Sample Efficiency in Robotic Manipulations With Large Language Models

    [https://arxiv.org/abs/2403.06420](https://arxiv.org/abs/2403.06420)

    RLingua提出了一个框架，利用大型语言模型的内部知识来提高机器人操作中强化学习的样本效率。

    

    强化学习（RL）已经证明了其在解决各种任务中的能力，但以其低样本效率而声名狼藉。在本文中，我们提出了RLingua，这是一个可以利用大型语言模型（LLMs）的内部知识来减少机器人操作中RL的样本复杂性的框架。为此，我们首先介绍了如何通过提示工程提取LLMs的先验知识，从而生成特定任务的初步基于规则的机器人控制器。尽管不完美，LLM生成的机器人控制器被用于在rollout时以衰减概率生成动作样本，从而提高RL的样本效率。我们采用了演员-评论家框架，并修改了演员损失，以使策略学习朝着LLM生成的控制器规范化。RLingua还提供了一种改善不完美的LLM生成机器人控制器的新方法。我们展示了RLing

    arXiv:2403.06420v1 Announce Type: cross  Abstract: Reinforcement learning (RL) has demonstrated its capability in solving various tasks but is notorious for its low sample efficiency. In this paper, we propose RLingua, a framework that can leverage the internal knowledge of large language models (LLMs) to reduce the sample complexity of RL in robotic manipulations. To this end, we first present how to extract the prior knowledge of LLMs by prompt engineering so that a preliminary rule-based robot controller for a specific task can be generated. Despite being imperfect, the LLM-generated robot controller is utilized to produce action samples during rollouts with a decaying probability, thereby improving RL's sample efficiency. We employ the actor-critic framework and modify the actor loss to regularize the policy learning towards the LLM-generated controller. RLingua also provides a novel method of improving the imperfect LLM-generated robot controllers by RL. We demonstrated that RLing
    
[^58]: 用于蕴涵树生成的逻辑模式记忆预训练模型

    A Logical Pattern Memory Pre-trained Model for Entailment Tree Generation

    [https://arxiv.org/abs/2403.06410](https://arxiv.org/abs/2403.06410)

    提出了逻辑模式记忆预训练模型（LMPM），通过结合外部存储结构学习和存储逻辑模式的潜在表示，有助于生成逻辑一致的结论，并引入实体抽象方法来减少维基百科数据中的逻辑无关领域知识的影响。

    

    在人工智能领域，生成连贯可信的解释仍然是一个重大挑战。最近，研究人员深入研究了利用蕴涵树来描述解释的方法，这展示了一个假设如何从支持事实中推导出的推理过程。然而，现有模型通常忽视了从给定事实中生成具有逻辑一致性的中间结论的重要性，导致不准确的结论，削弱了蕴涵树的整体可信度。为了解决这一限制，我们提出了逻辑模式记忆预训练模型（LMPM）。LMPM结合了外部存储结构，学习和存储逻辑模式的潜在表示，有助于生成逻辑一致的结论。此外，为了减少维基百科数据中逻辑无关领域知识的影响，我们引入了一种实体抽象方法。

    arXiv:2403.06410v1 Announce Type: cross  Abstract: Generating coherent and credible explanations remains a significant challenge in the field of AI. In recent years, researchers have delved into the utilization of entailment trees to depict explanations, which exhibit a reasoning process of how a hypothesis is deduced from the supporting facts. However, existing models often overlook the importance of generating intermediate conclusions with logical consistency from the given facts, leading to inaccurate conclusions and undermining the overall credibility of entailment trees. To address this limitation, we propose the logical pattern memory pre-trained model (LMPM). LMPM incorporates an external memory structure to learn and store the latent representations of logical patterns, which aids in generating logically consistent conclusions. Furthermore, to mitigate the influence of logically irrelevant domain knowledge in the Wikipedia-based data, we introduce an entity abstraction approach
    
[^59]: 量化对大型语言模型的困难在哪里？基于扰动视角的实证研究

    What Makes Quantization for Large Language Models Hard? An Empirical Study from the Lens of Perturbation

    [https://arxiv.org/abs/2403.06408](https://arxiv.org/abs/2403.06408)

    量化对大型语言模型的困难主要表现在如何通过添加扰动来改善模型性能和效率的关系，研究通过对不同人为扰动进行实验，发现了扰动特性与模型性能之间的联系，提出了改善量化稳健性的潜在解决方案。

    

    量化已经成为提高大型语言模型（LLMs）内存和计算效率的一种有前途的技术。尽管性能和效率之间的权衡是众所周知的，但关于量化与LLM性能之间的关系仍有很多待探索。为了阐明这种关系，我们提出了一种量化新视角，将其视为添加到LLMs权重和激活上的扰动。我们称这种方法为“扰动视角”。利用这一视角，我们进行了各种人为扰动的实验，探讨它们对LLM性能的影响。我们的研究结果揭示了扰动的特性与LLM性能之间的几个联系，为均匀量化的失败案例提供了见解，并暗示了改善LLM量化稳健性的潜在解决方案。

    arXiv:2403.06408v1 Announce Type: cross  Abstract: Quantization has emerged as a promising technique for improving the memory and computational efficiency of large language models (LLMs). Though the trade-off between performance and efficiency is well-known, there is still much to be learned about the relationship between quantization and LLM performance. To shed light on this relationship, we propose a new perspective on quantization, viewing it as perturbations added to the weights and activations of LLMs. We call this approach "the lens of perturbation". Using this lens, we conduct experiments with various artificial perturbations to explore their impact on LLM performance. Our findings reveal several connections between the properties of perturbations and LLM performance, providing insights into the failure cases of uniform quantization and suggesting potential solutions to improve the robustness of LLM quantization. To demonstrate the significance of our findings, we implement a s
    
[^60]: 关于持续学习中宽度递减回报的研究

    On the Diminishing Returns of Width for Continual Learning

    [https://arxiv.org/abs/2403.06398](https://arxiv.org/abs/2403.06398)

    增加神经网络宽度以减少遗忘会带来递减的回报，并且在先前研究中尚未探索的宽度范围内进行了实证验证。

    

    深度神经网络在各种设置中展示了突破性的性能，但这些模型在按顺序训练新任务时经常出现“灾难性遗忘”。 一些研究已经经验性地证明增加神经网络宽度会导致灾难性遗忘减少，但尚未准确刻画宽度和持续学习之间的确切关系。我们设计了其中一个最早的框架来分析持续学习理论，并证明宽度与前馈网络（FFN）中的遗忘直接相关。 具体来说，我们证明增加网络宽度以减少遗忘会带来递减的回报。我们在先前研究中尚未探索的宽度上经验性验证了我们的论断，结果显示递减回报如我们的理论所预测的那样清晰可见。

    arXiv:2403.06398v1 Announce Type: cross  Abstract: While deep neural networks have demonstrated groundbreaking performance in various settings, these models often suffer from \emph{catastrophic forgetting} when trained on new tasks in sequence. Several works have empirically demonstrated that increasing the width of a neural network leads to a decrease in catastrophic forgetting but have yet to characterize the exact relationship between width and continual learning. We design one of the first frameworks to analyze Continual Learning Theory and prove that width is directly related to forgetting in Feed-Forward Networks (FFN). Specifically, we demonstrate that increasing network widths to reduce forgetting yields diminishing returns. We empirically verify our claims at widths hitherto unexplored in prior studies where the diminishing returns are clearly observed as predicted by our theory.
    
[^61]: DeepSafeMPC: 基于深度学习的安全多智体强化学习模型预测控制

    DeepSafeMPC: Deep Learning-Based Model Predictive Control for Safe Multi-Agent Reinforcement Learning

    [https://arxiv.org/abs/2403.06397](https://arxiv.org/abs/2403.06397)

    DeepSafeMPC是一种基于深度学习的模型预测控制方法，旨在有效预测多智体环境的复杂动态，并应用MARL原则寻找最优解。

    

    安全多智体强化学习（safe MARL）在最近几年逐渐受到关注，强调了智体不仅需要优化全局回报，还需要通过行为约束遵守安全要求的必要性。近期一些工作将控制理论与多智体强化学习相结合，以解决确保安全性的挑战。然而，在这一领域中应用模型预测控制（MPC）方法的应用非常有限，主要是由于多智体环境中复杂且隐式动态的特性。为弥合这一差距，我们提出了一种称为基于深度学习的安全多智体强化学习模型预测控制（DeepSafeMPC）的新方法。DeepSafeMPC 的关键见解是利用集中式深度学习模型很好地预测环境动态。我们的方法应用MARL原则来寻找最优解。

    arXiv:2403.06397v1 Announce Type: cross  Abstract: Safe Multi-agent reinforcement learning (safe MARL) has increasingly gained attention in recent years, emphasizing the need for agents to not only optimize the global return but also adhere to safety requirements through behavioral constraints. Some recent work has integrated control theory with multi-agent reinforcement learning to address the challenge of ensuring safety. However, there have been only very limited applications of Model Predictive Control (MPC) methods in this domain, primarily due to the complex and implicit dynamics characteristic of multi-agent environments. To bridge this gap, we propose a novel method called Deep Learning-Based Model Predictive Control for Safe Multi-Agent Reinforcement Learning (DeepSafeMPC). The key insight of DeepSafeMPC is leveraging a entralized deep learning model to well predict environmental dynamics. Our method applies MARL principles to search for optimal solutions. Through the employme
    
[^62]: 针对下游微调的预训练模型推荐

    Pre-Trained Model Recommendation for Downstream Fine-tuning

    [https://arxiv.org/abs/2403.06382](https://arxiv.org/abs/2403.06382)

    本文提出了一个名为Fennec的框架，通过将所有模型和历史任务映射到一个迁移相关的子空间，以便推断新任务在迁移空间中的表征，从而改善模型选择技术。

    

    作为迁移学习中的一个基本问题，模型选择旨在对现成的预训练模型进行排名，并选择最适合新目标任务的模型。现有的模型选择技术通常在范围上受限，并倾向于忽视模型与任务之间微妙的关系。在本文中，我们提出了一个务实的框架 Fennec，深入研究了一个多样化、大规模的模型库，同时细致考虑了任务与模型之间的复杂联系。关键洞见在于将所有模型和历史任务映射到一个与迁移相关的子空间中，模型向量和任务向量之间的距离代表了可迁移性的大小。一个大型视觉模型作为代理人，在迁移空间中推断新任务的表示，从而避开了进行大量前向传播的计算负担。我们还调查了模型固有归纳偏差的影响。

    arXiv:2403.06382v1 Announce Type: cross  Abstract: As a fundamental problem in transfer learning, model selection aims to rank off-the-shelf pre-trained models and select the most suitable one for the new target task. Existing model selection techniques are often constrained in their scope and tend to overlook the nuanced relationships between models and tasks. In this paper, we present a pragmatic framework \textbf{Fennec}, delving into a diverse, large-scale model repository while meticulously considering the intricate connections between tasks and models. The key insight is to map all models and historical tasks into a transfer-related subspace, where the distance between model vectors and task vectors represents the magnitude of transferability. A large vision model, as a proxy, infers a new task's representation in the transfer space, thereby circumventing the computational burden of extensive forward passes. We also investigate the impact of the inherent inductive bias of models 
    
[^63]: 人类和自动解释罗马尼亚名词复合词

    Human and Automatic Interpretation of Romanian Noun Compounds

    [https://arxiv.org/abs/2403.06360](https://arxiv.org/abs/2403.06360)

    提出了新的罗马尼亚名词复合词关系集，通过人类和神经网络分类器测试后发现，网络的预测与人类判断存在一致，即使是在人类一致率较低的情况下。需要一个更好的关系清单。

    

    确定类似"鞋子销售"和"火灾大甩卖"这样的名词复合词在特定语境中的预期含义对于自然语言处理而言仍然是一个挑战。先前的研究依赖于捕捉复合词成员间不同含义的语义关系清单。针对罗马尼亚的复合词，其形态句法与英语的对应物不同，我们提出了一个新的关系集，并通过人类注释者和神经网络分类器进行了测试。结果显示网络的预测与人类判断之间存在一致，即使在人类一致率较低的地方也是如此。一致性与所选关系的频率保持一致，而不受结构差异的影响。然而，最常选择的关系不属于十六个标记的语义关系之一，这表明需要一个更好的关系清单。

    arXiv:2403.06360v1 Announce Type: cross  Abstract: Determining the intended, context-dependent meanings of noun compounds like "shoe sale" and "fire sale" remains a challenge for NLP. Previous work has relied on inventories of semantic relations that capture the different meanings between compound members. Focusing on Romanian compounds, whose morphosyntax differs from that of their English counterparts, we propose a new set of relations and test it with human annotators and a neural net classifier. Results show an alignment of the network's predictions and human judgments, even where the human agreement rate is low. Agreement tracks with the frequency of the selected relations, regardless of structural differences. However, the most frequently selected relation was none of the sixteen labeled semantic relations, indicating the need for a better relation inventory.
    
[^64]: 视频生成与一致性调节

    Video Generation with Consistency Tuning

    [https://arxiv.org/abs/2403.06356](https://arxiv.org/abs/2403.06356)

    提出了一个新的视频生成框架，通过四个模块的应用优化视频帧中背景和前景的一致性，生成的视频质量高于现有最先进的方法

    

    目前，各种研究都在探索生成长视频的方法。然而，这些视频中生成的帧经常出现抖动和噪音。因此，为了生成没有这些噪音的视频，我们提出了一个新颖的框架，由四个模块组成：独立调节模块、平均融合模块、综合调节模块和帧间一致性模块。通过逐步应用我们提出的新模块，优化了每个视频帧中背景和前景的一致性。此外，实验结果表明，通过我们的方法生成的视频在质量上与最先进的方法相比具有高质量。

    arXiv:2403.06356v1 Announce Type: cross  Abstract: Currently, various studies have been exploring generation of long videos. However, the generated frames in these videos often exhibit jitter and noise. Therefore, in order to generate the videos without these noise, we propose a novel framework composed of four modules: separate tuning module, average fusion module, combined tuning module, and inter-frame consistency module. By applying our newly proposed modules subsequently, the consistency of the background and foreground in each video frames is optimized. Besides, the experimental results demonstrate that videos generated by our method exhibit a high quality in comparison of the state-of-the-art methods.
    
[^65]: MOAB: 脑肿瘤分级中组织病理图像和遗传数据融合的多模态外部算术块

    MOAB: Multi-Modal Outer Arithmetic Block For Fusion Of Histopathological Images And Genetic Data For Brain Tumor Grading

    [https://arxiv.org/abs/2403.06349](https://arxiv.org/abs/2403.06349)

    该论文提出了一种新颖的多模态外部算术块（MOAB），用于将组织病理图像和遗传数据的潜在表示进行融合，以预测脑肿瘤的等级。

    

    脑肿瘤是大脑细胞异常增长。根据它们的生长，可以将其分类为不同等级。通常根据组织学图像进行分级，这是患者预后的最重要预测因素之一，等级越高，肿瘤越具侵略性。肿瘤等级的正确诊断仍具有挑战性。尽管已经证明组织病理学分级具有预后价值，但结果会受到干预者之间的变异性影响，即使是经验丰富的病理学家之间也是如此。最近，世界卫生组织报告称，分子遗传学方面的进展已经改善了肿瘤分类。本文旨在整合组织学图像和遗传数据，以实现改进的计算机辅助诊断。我们提出了一种基于算术运算的新型多模态外部算术块（MOAB），用于结合不同模态的潜在表示，以预测肿瘤等级。

    arXiv:2403.06349v1 Announce Type: cross  Abstract: Brain tumors are an abnormal growth of cells in the brain. They can be classified into distinct grades based on their growth. Often grading is performed based on a histological image and is one of the most significant predictors of a patients prognosis, the higher the grade, the more aggressive the tumor. Correct diagnosis of a tumor grade remains challenging. Though histopathological grading has been shown to be prognostic, results are subject to interobserver variability, even among experienced pathologists. Recently, the World Health Organization reported that advances in molecular genetics have led to improvements in tumor classification. This paper seeks to integrate histological images and genetic data for improved computer-aided diagnosis. We propose a novel Multi-modal Outer Arithmetic Block (MOAB) based on arithmetic operations to combine latent representations of the different modalities for predicting the tumor grade (Grade 
    
[^66]: 利用利润空间：资本主义如何以剥削少数群体为代价推动人工智能

    Exploiting the Margin: How Capitalism Fuels AI at the Expense of Minoritized Groups

    [https://arxiv.org/abs/2403.06332](https://arxiv.org/abs/2403.06332)

    人工智能在深化社会不平等方面起着关键作用，通过剥削边缘群体，特别是通过机制如零工经济劳工的滥用、有偏见的面部识别技术和对这些社群施加的不成比例的心理健康负担，加剧了现有的不平等。

    

    这篇文章探讨了资本主义、种族压迫和人工智能之间复杂的关系，揭示了这些元素如何共同加深社会不平等。通过追溯历史上对边缘社群的剥削，该研究表明人工智能技术不仅反映了社会偏见，而且加剧了种族差异。

    arXiv:2403.06332v1 Announce Type: cross  Abstract: This article investigates the complex nexus of capitalism, racial oppression, and artificial intelligence (AI), revealing how these elements coalesce to deepen social inequities. By tracing the historical exploitation of marginalized communities through capitalist practices, the study demonstrates how AI technologies not only reflect but also amplify societal biases, particularly in exacerbating racial disparities. Through a focused analysis, the paper presents how AI's development and application exploit marginalized groups via mechanisms such as gig economy labor abuses, biased facial recognition technologies, and the disproportionate mental health burdens placed on these communities. These examples underscore the critical role of AI in reinforcing and intensifying existing inequalities. Concluding that unregulated AI significantly threatens to compound current oppressions, the article calls for a concerted effort towards responsible
    
[^67]: 从指令到约束：语言模型对齐与自动约束验证

    From Instructions to Constraints: Language Model Alignment with Automatic Constraint Verification

    [https://arxiv.org/abs/2403.06326](https://arxiv.org/abs/2403.06326)

    提出了ACT框架，通过约束验证器自动计算每个响应的约束满意率，实现语言模型对齐与自动约束验证。

    

    用户对齐对于将通用语言模型（LMs）调整为下游任务至关重要，但通常无法为所有类型的指令提供人类注释，特别是具有定制约束的指令。我们观察到用户指令通常包含约束条件。虽然评估整个指令的响应质量通常成本高昂，但高效地评估约束条件的满意率是可行的。我们研究了NLP任务中的常见约束条件，将它们基于其参数类型分类为三类，并提出了一个统一框架，ACT（Aligning to ConsTraints），用于自动为带约束用户对齐生成监督信号。具体而言，ACT使用约束验证器，这些验证器在实践中通常易于实现，来计算每个响应的约束满意率（CSR）。它为每个提示取样多个响应并收集偏好标签。

    arXiv:2403.06326v1 Announce Type: cross  Abstract: User alignment is crucial for adapting general-purpose language models (LMs) to downstream tasks, but human annotations are often not available for all types of instructions, especially those with customized constraints. We observe that user instructions typically contain constraints. While assessing response quality in terms of the whole instruction is often costly, efficiently evaluating the satisfaction rate of constraints is feasible. We investigate common constraints in NLP tasks, categorize them into three classes based on the types of their arguments, and propose a unified framework, ACT (Aligning to ConsTraints), to automatically produce supervision signals for user alignment with constraints. Specifically, ACT uses constraint verifiers, which are typically easy to implement in practice, to compute constraint satisfaction rate (CSR) of each response. It samples multiple responses for each prompt and collect preference labels ba
    
[^68]: 在重症监护病房（ICU）中利用计算机视觉检查探视和活动能力

    Leveraging Computer Vision in the Intensive Care Unit (ICU) for Examining Visitation and Mobility

    [https://arxiv.org/abs/2403.06322](https://arxiv.org/abs/2403.06322)

    在重症监护病房中利用计算机视觉系统，可以实现不存在的评估和增强现有评估的频率和准确性，同时减少工作人员工作量。

    

    尽管密切监测重症监护病房（ICU）患者的重要性，由于医护人员面临的时间限制，许多方面仍然受到限制评估。过度的探视可能在休息时间加剧循环节律紊乱和谵妄的风险，但在ICU中并未被捕捉。同样，活动能力可以是ICU患者康复或恶化的重要指标，但只被零星地捕捉或根本不被捕捉。在过去几年中，计算机视觉领域在许多领域中找到了应用，减轻了人力负担。在ICU中使用计算机视觉系统也有可能实现不存在的评估或增强现有评估的频率和准确性，同时减少工作人员的工作量。本研究利用基于深度成像的最新非侵入式计算机视觉系统，

    arXiv:2403.06322v1 Announce Type: cross  Abstract: Despite the importance of closely monitoring patients in the Intensive Care Unit (ICU), many aspects are still assessed in a limited manner due to the time constraints imposed on healthcare providers. For example, although excessive visitations during rest hours can potentially exacerbate the risk of circadian rhythm disruption and delirium, it is not captured in the ICU. Likewise, while mobility can be an important indicator of recovery or deterioration in ICU patients, it is only captured sporadically or not captured at all. In the past few years, the computer vision field has found application in many domains by reducing the human burden. Using computer vision systems in the ICU can also potentially enable non-existing assessments or enhance the frequency and accuracy of existing assessments while reducing the staff workload. In this study, we leverage a state-of-the-art noninvasive computer vision system based on depth imaging to c
    
[^69]: 一种用于可微调形状匹配和生成的端到端深度学习生成框架

    An End-to-End Deep Learning Generative Framework for Refinable Shape Matching and Generation

    [https://arxiv.org/abs/2403.06317](https://arxiv.org/abs/2403.06317)

    提出了一种端到端深度学习生成框架，利用图形表示为网格建立可微调的形状对应，在潜在空间生成逼真的合成形状，并扩展为联合形状生成-聚类多图谱框架以增加变异性和保留生成形状中的更多细节

    

    形状的生成建模是体内临床试验（ISCTs）的先决条件，旨在通过使用合成的解剖形状（通常表示为3D表面网格）以经济有效的方式验证医疗设备干预措施。然而，构建能够生成与真实网格样本密切类似的形状的人工智能模型具有挑战性，原因在于训练数据中可变的顶点计数、连接性以及缺乏密集的顶点对应。通过使用网格的图形表示，我们开发了一种新颖的无监督几何深度学习模型，以建立潜在空间中可微调的形状对应，构建基于人口数据的图谱并生成逼真的合成形状。我们还将我们提出的基础模型扩展为联合形状生成-聚类多图谱框架，以增加更多的变异性并在生成的形状中保留更多细节。利用肝脏和左心静脉作为实验对象，我们的实验结果表明…

    arXiv:2403.06317v1 Announce Type: cross  Abstract: Generative modelling for shapes is a prerequisite for In-Silico Clinical Trials (ISCTs), which aim to cost-effectively validate medical device interventions using synthetic anatomical shapes, often represented as 3D surface meshes. However, constructing AI models to generate shapes closely resembling the real mesh samples is challenging due to variable vertex counts, connectivities, and the lack of dense vertex-wise correspondences across the training data. Employing graph representations for meshes, we develop a novel unsupervised geometric deep-learning model to establish refinable shape correspondences in a latent space, construct a population-derived atlas and generate realistic synthetic shapes. We additionally extend our proposed base model to a joint shape generative-clustering multi-atlas framework to incorporate further variability and preserve more details in the generated shapes. Experimental results using liver and left-ven
    
[^70]: 深度强化学习的最优策略稀疏化和低秩分解

    Optimal Policy Sparsification and Low Rank Decomposition for Deep Reinforcement Learning

    [https://arxiv.org/abs/2403.06313](https://arxiv.org/abs/2403.06313)

    提出一种新颖的$L_0$范数正则化技术，用于深度强化学习的最优策略稀疏化和低秩分解

    

    深度强化学习在计算机游戏和机器人等多个领域显示出巨大潜力。然而，训练深度强化学习策略耗费了大量的计算资源，导致密集策略容易过拟合。此外，使用密集深度强化学习策略进行推理限制了它们在边缘计算等实际应用中的适用性。为了限制过拟合和减少内存消耗，研究者已经使用了像剪枝和奇异值分解这样的技术来对深度学习模型进行稀疏化和模型压缩。然而，这些技术导致了性能次优，在奖励方面出现显著的减弱。在神经网络稀疏化和稀疏自编码器开发中已经提出了$L_1$和$L_2$正则化技术，但它们在深度强化学习环境中的实现尚不明显。我们提出了一种新颖的$L_0$范数正则化技术，使用了一种最优稀疏度

    arXiv:2403.06313v1 Announce Type: cross  Abstract: Deep reinforcement learning(DRL) has shown significant promise in a wide range of applications including computer games and robotics. Yet, training DRL policies consume extraordinary computing resources resulting in dense policies which are prone to overfitting. Moreover, inference with dense DRL policies limit their practical applications, especially in edge computing. Techniques such as pruning and singular value decomposition have been used with deep learning models to achieve sparsification and model compression to limit overfitting and reduce memory consumption. However, these techniques resulted in sub-optimal performance with notable decay in rewards. $L_1$ and $L_2$ regularization techniques have been proposed for neural network sparsification and sparse auto-encoder development, but their implementation in DRL environments has not been apparent. We propose a novel $L_0$-norm-regularization technique using an optimal sparsity m
    
[^71]: ArgMed-Agents: 使用争议方案通过大型语言模型解释性临床决策推理

    ArgMed-Agents: Explainable Clinical Decision Reasoning with Large Language Models via Argumentation Schemes

    [https://arxiv.org/abs/2403.06294](https://arxiv.org/abs/2403.06294)

    通过争论方案的自我论证迭代和构建争论过程，ArgMed-Agents实现了基于LLM的可解释临床决策推理，提高了用户对临床决策的信任。

    

    arXiv:2403.06294v1 公告类型: 新摘要: 使用大型语言模型（LLMs）进行临床推理存在两个主要障碍。首先，虽然LLMs在自然语言处理（NLP）任务中显示出巨大的潜力，但在复杂推理和规划方面的表现却不尽人意。其次，LLMs使用不可解释的方法进行临床决策，这与临床医生的认知过程本质上不同，导致用户不信任。在本文中，我们提出了一个名为ArgMed-Agents的多代理框架，旨在通过交互使基于LLM的代理能够进行可解释的临床决策推理。ArgMed-Agents通过临床决策论据（一种模拟临床决策认知过程的推理机制）执行自论证迭代，然后将争论过程构建为表示冲突关系的有向图。最终，Reasoner（一种符号求解器）识别出一个

    arXiv:2403.06294v1 Announce Type: new  Abstract: There are two main barriers to using large language models (LLMs) in clinical reasoning. Firstly, while LLMs exhibit significant promise in Natural Language Processing (NLP) tasks, their performance in complex reasoning and planning falls short of expectations. Secondly, LLMs use uninterpretable methods to make clinical decisions that are fundamentally different from the clinician's cognitive processes. This leads to user distrust. In this paper, we present a multi-agent framework called ArgMed-Agents, which aims to enable LLM-based agents to make explainable clinical decision reasoning through interaction. ArgMed-Agents performs self-argumentation iterations via Argumentation Scheme for Clinical Decision (a reasoning mechanism for modeling cognitive processes in clinical reasoning), and then constructs the argumentation process as a directed graph representing conflicting relationships. Ultimately, Reasoner(a symbolic solver) identify a
    
[^72]: 理解和减轻监督对比学习中的人工标注误差

    Understanding and Mitigating Human-Labelling Errors in Supervised Contrastive Learning

    [https://arxiv.org/abs/2403.06289](https://arxiv.org/abs/2403.06289)

    本文揭示了人工标注误差不仅与合成标签错误有显著不同，而且在监督对比学习中构成了独特挑战，提出了一种新颖的对抗人工标注误差的SCL目标。

    

    通过arXiv:2403.06289v1公开的交叉类型的文摘可以得知，人工标注的视觉数据集中不可避免地包含一部分人工标注错误的示例。尽管这类标注错误对于监督学习的负面影响已经得到深入研究，但它们对监督对比学习（SCL）的影响仍然是相对未知的。本文表明，人工标注错误不仅与合成标签错误显著不同，而且在SCL中构成独特挑战，与传统监督学习方法中的挑战有所不同。具体而言，我们的研究结果表明，当它们作为误报样本出现时，它们会对学习过程造成大约99%的负面影响。已有的噪声缓解方法主要侧重于合成标签错误，并处理非常高合成噪声率（40-80%）的不切实际设置，但由于过度拟合，它们在普通图像数据集上的表现往往较差。为了解决这个问题，我们引入了一种新颖的对抗人工标注鲁棒性的SCL目标。

    arXiv:2403.06289v1 Announce Type: cross  Abstract: Human-annotated vision datasets inevitably contain a fraction of human mislabelled examples. While the detrimental effects of such mislabelling on supervised learning are well-researched, their influence on Supervised Contrastive Learning (SCL) remains largely unexplored. In this paper, we show that human-labelling errors not only differ significantly from synthetic label errors, but also pose unique challenges in SCL, different to those in traditional supervised learning methods. Specifically, our results indicate they adversely impact the learning process in the ~99% of cases when they occur as false positive samples. Existing noise-mitigating methods primarily focus on synthetic label errors and tackle the unrealistic setting of very high synthetic noise rates (40-80%), but they often underperform on common image datasets due to overfitting. To address this issue, we introduce a novel SCL objective with robustness to human-labelling
    
[^73]: UNICORN: 通过分数匹配和自适应实现的超声纳卡加米成像

    UNICORN: Ultrasound Nakagami Imaging via Score Matching and Adaptation

    [https://arxiv.org/abs/2403.06275](https://arxiv.org/abs/2403.06275)

    提出了一种名为UNICORN的新方法，通过分数匹配和自适应实现超声纳卡加米成像，能够在准确性和分辨率质量上超越传统方法。

    

    Nakagami成像在超声波中可视化和量化组织散射方面具有潜力，在肿瘤诊断和脂肪分数估计等领域有潜在应用，而这些领域很难通过传统超声B模式图像分辨。现有方法在选择最优窗口大小上存在困难，并且由于估计不稳定性而导致分辨率降低。为解决这一问题，本文提出了一种名为UNICORN（通过分数匹配和自适应实现的超声纳卡加米成像）的新方法，它提供了一种准确的，封闭形式的方法，用于通过超声包络的分数函数来估计卡加米参数。通过使用模拟和真实超声RF数据进行的大量实验证明了UNICORN在准确性和分辨率质量方面优于传统方法。

    arXiv:2403.06275v1 Announce Type: cross  Abstract: Nakagami imaging holds promise for visualizing and quantifying tissue scattering in ultrasound waves, with potential applications in tumor diagnosis and fat fraction estimation which are challenging to discern by conventional ultrasound B-mode images. Existing methods struggle with optimal window size selection and suffer from estimator instability, leading to degraded resolution images. To address this, here we propose a novel method called UNICORN (Ultrasound Nakagami Imaging via Score Matching and Adaptation), that offers an accurate, closed-form estimator for Nakagami parameter estimation in terms of the score function of ultrasonic envelope. Extensive experiments using simulation and real ultrasound RF data demonstrate UNICORN's superiority over conventional approaches in accuracy and resolution quality.
    
[^74]: 物理引导的异常轨迹间隙检测

    Physics-Guided Abnormal Trajectory Gap Detection

    [https://arxiv.org/abs/2403.06268](https://arxiv.org/abs/2403.06268)

    通过物理引导的方法，解决了在轨迹数据中识别异常间隙的挑战性问题，具有重要的社会应用和技术难度。

    

    在具有间隙（即缺失数据）的轨迹中，我们研究了用于识别轨迹中的异常间隙的算法，这种异常间隙在一个移动物体没有报告其位置时发生，但同一地理区域的其他移动物体周期性地报告位置。该问题由于其对社会的重要应用而变得重要，如改善海上安全和对全球安全问题（如非法捕鱼、非法输油和转运活动）的监管执行。该问题具有挑战性，因为很难限定在轨迹间隙期间移动物体的可能位置，并且检测如此大量位置数据中的间隙的计算成本非常高。目前关于异常轨迹检测的文献假设在间隙内进行线性插值，这可能无法检测到异常间隙，因为在给定区域内的物体可能已经偏离最短路径。在初步

    arXiv:2403.06268v1 Announce Type: cross  Abstract: Given trajectories with gaps (i.e., missing data), we investigate algorithms to identify abnormal gaps in trajectories which occur when a given moving object did not report its location, but other moving objects in the same geographic region periodically did. The problem is important due to its societal applications, such as improving maritime safety and regulatory enforcement for global security concerns such as illegal fishing, illegal oil transfers, and trans-shipments. The problem is challenging due to the difficulty of bounding the possible locations of the moving object during a trajectory gap, and the very high computational cost of detecting gaps in such a large volume of location data. The current literature on anomalous trajectory detection assumes linear interpolation within gaps, which may not be able to detect abnormal gaps since objects within a given region may have traveled away from their shortest path. In preliminary 
    
[^75]: FARPLS: 一个特征增强的机器人轨迹偏好标注系统，用于协助人类标注者的偏好获取

    FARPLS: A Feature-Augmented Robot Trajectory Preference Labeling System to Assist Human Labelers' Preference Elicitation

    [https://arxiv.org/abs/2403.06267](https://arxiv.org/abs/2403.06267)

    FARPLS提出了一个特征增强的机器人轨迹偏好标注系统，用于帮助人类标注者在偏好获取过程中避免忽视重要特征、形成偏见标准和因比较过多而导致标注质量下降的问题。

    

    基于偏好的学习旨在使机器人的任务目标与人类价值观保持一致。推断人类偏好的最常见方法之一是通过对机器人任务轨迹的两两比较。传统基于比较的偏好标注系统很少支持标注者消化和确定视频中记录的复杂轨迹之间的关键差异。我们的形成性研究（N = 12）表明，个体可能会忽视非显著的任务特征，并在偏好获取过程中建立有偏见的偏好标准，因为存在部分观察。此外，当给定许多配对进行比较时，他们可能会感到精神疲劳，导致标注质量下降。为了减轻这些问题，我们提出了FARPLS，一个特征增强的机器人轨迹偏好标注系统。FARPLS突出显示与人类相关的各种任务特征中的潜在异常值，并提取相应的视频关键帧。

    arXiv:2403.06267v1 Announce Type: cross  Abstract: Preference-based learning aims to align robot task objectives with human values. One of the most common methods to infer human preferences is by pairwise comparisons of robot task trajectories. Traditional comparison-based preference labeling systems seldom support labelers to digest and identify critical differences between complex trajectories recorded in videos. Our formative study (N = 12) suggests that individuals may overlook non-salient task features and establish biased preference criteria during their preference elicitation process because of partial observations. In addition, they may experience mental fatigue when given many pairs to compare, causing their label quality to deteriorate. To mitigate these issues, we propose FARPLS, a Feature-Augmented Robot trajectory Preference Labeling System. FARPLS highlights potential outliers in a wide variety of task features that matter to humans and extracts the corresponding video ke
    
[^76]: 拆解分词：评估文本压缩及其与模型性能的相关性

    Unpacking Tokenization: Evaluating Text Compression and its Correlation with Model Performance

    [https://arxiv.org/abs/2403.06265](https://arxiv.org/abs/2403.06265)

    本文研究了文本压缩在分词过程中的重要性，证明了压缩与预训练语言模型后续成功之间的实证重要性，并表明分词器的压缩与模型的性能存在相关性。

    

    尽管压缩是BPE最常见的分词算法的重要基础，但分词过程中的压缩重要性仍不清楚。本文论述了压缩的理论重要性，可以被看作是0-gram语言建模，即为所有标记分配相等的概率。我们还展示了压缩对预训练语言模型后续成功的实证重要性。我们通过改变训练过程中可用文档的数量来控制多个BPE分词器的压缩能力：从100万个文档到相当于没有训练数据的基于字符的分词器。然后，我们基于这些分词器预训练英语语言模型，并在多个任务上进行微调。我们展示了分词器的压缩与模型的后续性能之间存在相关性，表明压缩是分词的可靠内在指标

    arXiv:2403.06265v1 Announce Type: cross  Abstract: Despite it being the cornerstone of BPE, the most common tokenization algorithm, the importance of compression in the tokenization process is still unclear. In this paper, we argue for the theoretical importance of compression, that can be viewed as 0-gram language modeling where equal probability is assigned to all tokens. We also demonstrate the empirical importance of compression for downstream success of pre-trained language models. We control the compression ability of several BPE tokenizers by varying the amount of documents available during their training: from 1 million documents to a character-based tokenizer equivalent to no training data at all. We then pre-train English language models based on those tokenizers and fine-tune them over several tasks. We show that there is a correlation between tokenizers' compression and models' downstream performance, suggesting that compression is a reliable intrinsic indicator of tokeniza
    
[^77]: 大型语言模型的概念知识编辑

    Editing Conceptual Knowledge for Large Language Models

    [https://arxiv.org/abs/2403.06259](https://arxiv.org/abs/2403.06259)

    该论文首次研究了为大型语言模型编辑概念知识，通过构建基准数据集和建立新评估指标，发现现有方法虽然能一定程度上修改概念定义，但也可能造成LLMs中相关实例知识的扭曲，导致性能下降。

    

    最近，对于大型语言模型（LLMs）的知识编辑引起了越来越多的关注。当前的方法和评估仅探讨了实例级别的编辑，然而LLMs是否具有修改概念的能力仍不清楚。本文首次研究了为LLMs编辑概念知识，通过构建一个新颖的基准数据集ConceptEdit并建立了一套新的评估指标。实验结果表明，尽管现有的编辑方法可以有效地在一定程度上修改概念级别的定义，但它们也有潜力扭曲LLMs中相关的实例知识，导致性能不佳。我们期望这可以激发对更好理解LLMs的进一步进展。我们的项目主页位于https://zjunlp.github.io/project/ConceptEdit。

    arXiv:2403.06259v1 Announce Type: cross  Abstract: Recently, there has been a growing interest in knowledge editing for Large Language Models (LLMs). Current approaches and evaluations merely explore the instance-level editing, while whether LLMs possess the capability to modify concepts remains unclear. This paper pioneers the investigation of editing conceptual knowledge for LLMs, by constructing a novel benchmark dataset ConceptEdit and establishing a suite of new metrics for evaluation. The experimental results reveal that, although existing editing methods can efficiently modify concept-level definition to some extent, they also have the potential to distort the related instantial knowledge in LLMs, leading to poor performance. We anticipate this can inspire further progress in better understanding LLMs. Our project homepage is available at https://zjunlp.github.io/project/ConceptEdit.
    
[^78]: 基于文本引导的变分图像生成用于工业异常检测和分割

    Text-Guided Variational Image Generation for Industrial Anomaly Detection and Segmentation

    [https://arxiv.org/abs/2403.06247](https://arxiv.org/abs/2403.06247)

    该方法利用文本信息生成类似输入图像的无缺陷数据图像，确保生成的图像符合期望分布，稳定且具有普适性。

    

    我们提出了一种文本引导的变分图像生成方法，以解决工业制造中异常检测的干净数据获取挑战。我们的方法利用来自广泛文本库文档的关于目标对象的文本信息，生成类似输入图像的无缺陷数据图像。所提出的框架确保生成的无缺陷图像与来自文本和图像知识的预期分布保持一致，确保稳定性和普适性。实验结果表明了我们的方法的有效性，即使只有有限的无缺陷数据，也能超越先前的方法。我们的方法通过跨四个基准模型和三个不同数据集进行泛化测试进行了验证。我们提出了一种利用生成图像增强异常检测模型效果的额外分析。

    arXiv:2403.06247v1 Announce Type: cross  Abstract: We propose a text-guided variational image generation method to address the challenge of getting clean data for anomaly detection in industrial manufacturing. Our method utilizes text information about the target object, learned from extensive text library documents, to generate non-defective data images resembling the input image. The proposed framework ensures that the generated non-defective images align with anticipated distributions derived from textual and image-based knowledge, ensuring stability and generality. Experimental results demonstrate the effectiveness of our approach, surpassing previous methods even with limited non-defective data. Our approach is validated through generalization tests across four baseline models and three distinct datasets. We present an additional analysis to enhance the effectiveness of anomaly detection models by utilizing the generated images.
    
[^79]: 合作分类与理性化用于图泛化

    Cooperative Classification and Rationalization for Graph Generalization

    [https://arxiv.org/abs/2403.06239](https://arxiv.org/abs/2403.06239)

    本文提出了一种合作分类与理性化（C2R）方法，旨在解决图神经网络在泛化时面临的挑战，通过分类和理性化模块协同工作，改善对分布之外数据的泛化能力。

    

    arXiv:2403.06239v1 公告类型: 跨界 摘要: 图神经网络（GNNs）在图分类任务中取得了令人印象深刻的结果，但面对分布之外的数据时很难有效泛化。已经提出了几种方法来解决这个问题。其中之一的解决方案是通过修改数据环境来使原始分类的训练分布多样化，但访问环境信息较为复杂。另一个有前途的方法涉及理性化，提取用于预测的不变原理。然而，由于学习信号有限，提取原理是困难的，导致较不准确的原理和减弱的预测。为了解决这些挑战，在本文中，我们提出了一种合作分类与理性化（C2R）方法，包括分类模块和理性化模块。具体地，我们首先假设分类中存在多个环境

    arXiv:2403.06239v1 Announce Type: cross  Abstract: Graph Neural Networks (GNNs) have achieved impressive results in graph classification tasks, but they struggle to generalize effectively when faced with out-of-distribution (OOD) data. Several approaches have been proposed to address this problem. Among them, one solution is to diversify training distributions in vanilla classification by modifying the data environment, yet accessing the environment information is complex. Besides, another promising approach involves rationalization, extracting invariant rationales for predictions. However, extracting rationales is difficult due to limited learning signals, resulting in less accurate rationales and diminished predictions. To address these challenges, in this paper, we propose a Cooperative Classification and Rationalization (C2R) method, consisting of the classification and the rationalization module. Specifically, we first assume that multiple environments are available in the classif
    
[^80]: 概率神经电路

    Probabilistic Neural Circuits

    [https://arxiv.org/abs/2403.06235](https://arxiv.org/abs/2403.06235)

    PNCs将概率电路和神经网络的特点结合起来，可以解释为深层混合的贝叶斯网络，同时作为强大的函数逼近器。

    

    概率电路（PCs）近年来作为一个灵活的框架，被广泛应用于探讨支持可处理查询且足够表达复杂概率分布的概率模型。然而，可处理性是有代价的：PCs比神经网络表达能力更弱。在本文中，我们介绍了概率神经电路（PNCs），在可处理性和表达能力方面在PCs和神经网络之间取得了平衡。理论上，我们展示了PNCs可以被解释为贝叶斯网络的深度混合。实验上，我们证明了PNCs构成了强大的函数逼近器。

    arXiv:2403.06235v1 Announce Type: cross  Abstract: Probabilistic circuits (PCs) have gained prominence in recent years as a versatile framework for discussing probabilistic models that support tractable queries and are yet expressive enough to model complex probability distributions. Nevertheless, tractability comes at a cost: PCs are less expressive than neural networks. In this paper we introduce probabilistic neural circuits (PNCs), which strike a balance between PCs and neural nets in terms of tractability and expressive power. Theoretically, we show that PNCs can be interpreted as deep mixtures of Bayesian networks. Experimentally, we demonstrate that PNCs constitute powerful function approximators.
    
[^81]: MoST: 在多样动作内容之间进行运动风格转换的动作风格转换器

    MoST: Motion Style Transformer between Diverse Action Contents

    [https://arxiv.org/abs/2403.06225](https://arxiv.org/abs/2403.06225)

    MoST提出了一种新颖的动作风格转换器，能够有效地将风格与内容分离，在转移风格时表现出色，并在不同内容的动作对中展现出卓越的质量。

    

    尽管现有的动作风格转移方法在相同内容的两个动作之间是有效的，但当在不同内容的动作之间转移风格时，它们的表现显著下降。这一挑战在于动作的内容和风格之间缺乏明确的分离。为了应对这一挑战，我们提出了一种新颖的动作风格转换器，有效地将风格与内容分离，并从源动作生成具有转移风格的合理动作。我们实现分离目标的独特方法具有双重性：(1) 带有“部分关注风格调制器跨身体部位”和“编码器编码风格和内容特征分开”的动作风格转换器的新架构；(2) 风格分离损失。我们的方法优于现有方法，并表现出异常高的质量，特别是在具有不同内容的动作对中，无需...

    arXiv:2403.06225v1 Announce Type: cross  Abstract: While existing motion style transfer methods are effective between two motions with identical content, their performance significantly diminishes when transferring style between motions with different contents. This challenge lies in the lack of clear separation between content and style of a motion. To tackle this challenge, we propose a novel motion style transformer that effectively disentangles style from content and generates a plausible motion with transferred style from a source motion. Our distinctive approach to achieving the goal of disentanglement is twofold: (1) a new architecture for motion style transformer with 'part-attentive style modulator across body parts' and 'Siamese encoders that encode style and content features separately'; (2) style disentanglement loss. Our method outperforms existing methods and demonstrates exceptionally high quality, particularly in motion pairs with different contents, without the need fo
    
[^82]: 用步骤式思维检索和对齐决策增强LLM代理

    TRAD: Enhancing LLM Agents with Step-Wise Thought Retrieval and Aligned Decision

    [https://arxiv.org/abs/2403.06221](https://arxiv.org/abs/2403.06221)

    提出了TRAD框架，通过步骤式思维检索和对齐决策解决了利用上下文示例时可能出现的问题。

    

    许多大型语言模型（LLM）代理已经被构建用于不同任务，如网络导航和在线购物，这是因为LLM具有广泛的知识和文本理解能力。在这些研究中，许多利用上下文示例来实现泛化，而无需微调，但少数考虑了如何选择和有效利用这些示例的问题。最近，基于轨迹级检索和使用轨迹作为上下文示例的方法已经提出，以提高代理在一些顺序决策任务中的整体性能。然而，这些方法可能存在问题，因为检索出的可信示例缺乏特定于任务的状态转移动态，且输入长且包含大量无关上下文。在本文中，我们提出了一个新框架（TRAD）来解决这些问题。TRAD首先进行思维检索，实现步骤级演示。

    arXiv:2403.06221v1 Announce Type: new  Abstract: Numerous large language model (LLM) agents have been built for different tasks like web navigation and online shopping due to LLM's wide knowledge and text-understanding ability. Among these works, many of them utilize in-context examples to achieve generalization without the need for fine-tuning, while few of them have considered the problem of how to select and effectively utilize these examples. Recently, methods based on trajectory-level retrieval with task meta-data and using trajectories as in-context examples have been proposed to improve the agent's overall performance in some sequential decision making tasks. However, these methods can be problematic due to plausible examples retrieved without task-specific state transition dynamics and long input with plenty of irrelevant context. In this paper, we propose a novel framework (TRAD) to address these issues. TRAD first conducts Thought Retrieval, achieving step-level demonstration
    
[^83]: $V_kD：使用正交投影改进知识蒸馏

    $V_kD:$ Improving Knowledge Distillation using Orthogonal Projections

    [https://arxiv.org/abs/2403.06213](https://arxiv.org/abs/2403.06213)

    提出一种约束特征蒸馏方法，通过使用正交投影和任务特定的归一化，能够在ImageNet上实现高达4.4%的相对改进，并在目标检测和图像生成任务中取得显著性能提升

    

    知识蒸馏是一种训练小型高效深度学习模型的有效方法。本文提出一种新颖的约束特征蒸馏方法，以解决单一方法在转移到其他任务、模态或架构时的有效性降低的问题。该方法源于一小组核心原则，包括正交投影和任务特定的归一化，通过这两个组件，我们的Transformer模型在ImageNet上表现优异，相对于之前的最先进方法取得了高达4.4%的相对改进。我们进一步将该方法应用于目标检测和图像生成，得到了持续和显著的性能改进。代码和模型公开可用：https://github.com/roymiles/

    arXiv:2403.06213v1 Announce Type: cross  Abstract: Knowledge distillation is an effective method for training small and efficient deep learning models. However, the efficacy of a single method can degenerate when transferring to other tasks, modalities, or even other architectures. To address this limitation, we propose a novel constrained feature distillation method. This method is derived from a small set of core principles, which results in two emerging components: an orthogonal projection and a task-specific normalisation. Equipped with both of these components, our transformer models can outperform all previous methods on ImageNet and reach up to a 4.4% relative improvement over the previous state-of-the-art methods. To further demonstrate the generality of our method, we apply it to object detection and image generation, whereby we obtain consistent and substantial performance improvements over state-of-the-art. Code and models are publicly available: https://github.com/roymiles/
    
[^84]: 最大随机置换集熵的极限

    Limit of the Maximum Random Permutation Set Entropy

    [https://arxiv.org/abs/2403.06206](https://arxiv.org/abs/2403.06206)

    本文定义了熵函数的包络概念，并推导证明了随机置换集熵包络的极限形式为$e \times (N!)^2$。

    

    最近提出了随机置换集（RPS）作为证据理论的泛化形式。为了衡量RPS的不确定性，提出了RPS的熵以及其对应的最大熵。探索最大熵为理解RPS的物理意义提供了一种可能的方式。本文定义了熵函数的包络的新概念。此外，推导并证明了RPS熵包络的极限。与现有方法相比，所提出的计算RPS熵包络的方法的计算复杂性大大降低。结果表明，当$N \to \infty$时，RPS熵包络的极限形式收敛到$e \times (N!)^2$，这与常数$e$和阶乘密切相关。最后，数值例证验证了所提出的包络的效率和简洁性。

    arXiv:2403.06206v1 Announce Type: cross  Abstract: The Random Permutation Set (RPS) is a new type of set proposed recently, which can be regarded as the generalization of evidence theory. To measure the uncertainty of RPS, the entropy of RPS and its corresponding maximum entropy have been proposed. Exploring the maximum entropy provides a possible way of understanding the physical meaning of RPS. In this paper, a new concept, the envelope of entropy function, is defined. In addition, the limit of the envelope of RPS entropy is derived and proved. Compared with the existing method, the computational complexity of the proposed method to calculate the envelope of RPS entropy decreases greatly. The result shows that when $N \to \infty$, the limit form of the envelope of the entropy of RPS converges to $e \times (N!)^2$, which is highly connected to the constant $e$ and factorial. Finally, numerical examples validate the efficiency and conciseness of the proposed envelope, which provides a 
    
[^85]: 您被追踪了吗？发现LLMs的零射轨迹跟踪的威力！

    Are You Being Tracked? Discover the Power of Zero-Shot Trajectory Tracing with LLMs!

    [https://arxiv.org/abs/2403.06201](https://arxiv.org/abs/2403.06201)

    介绍了LLMTrack模型，通过引入一种新颖的单提示技术，结合角色扮演和逐步思考方法，利用未经处理的IMU数据，实现了零射轨迹识别，超越了传统机器学习和深度学习模型，无需训练在专门数据集上的性能表现。

    

    在关于大型语言模型（LLMs）能够作为基本组件的讨论中，能够无缝地融入物联网人工智能（AIoT）中以解释复杂轨迹。本研究介绍了LLMTrack，该模型演示了如何利用LLMs进行零射轨迹识别，通过采用将角色扮演和逐步思考方法与未经处理的惯性测量单元（IMU）数据相结合的新颖单提示技术。我们使用真实世界数据集对模型进行评估，这些数据集旨在挑战它以具有室内和室外情景特征的不同轨迹。在两种测试情景中，LLMTrack 不仅满足甚至超过了传统机器学习方法以及当代最先进的深度学习模型设定的性能基准，而且无需对专门数据集进行训练。

    arXiv:2403.06201v1 Announce Type: cross  Abstract: There is a burgeoning discussion around the capabilities of Large Language Models (LLMs) in acting as fundamental components that can be seamlessly incorporated into Artificial Intelligence of Things (AIoT) to interpret complex trajectories. This study introduces LLMTrack, a model that illustrates how LLMs can be leveraged for Zero-Shot Trajectory Recognition by employing a novel single-prompt technique that combines role-play and think step-by-step methodologies with unprocessed Inertial Measurement Unit (IMU) data. We evaluate the model using real-world datasets designed to challenge it with distinct trajectories characterized by indoor and outdoor scenarios. In both test scenarios, LLMTrack not only meets but exceeds the performance benchmarks set by traditional machine learning approaches and even contemporary state-of-the-art deep learning models, all without the requirement of training on specialized datasets. The results of our 
    
[^86]: 针对领域泛化分类的领域对抗主动学习

    Domain Adversarial Active Learning for Domain Generalization Classification

    [https://arxiv.org/abs/2403.06174](https://arxiv.org/abs/2403.06174)

    本文提出了一种用于领域泛化分类任务的领域对抗主动学习（DAAL）算法，通过设计一种优先选择具有挑战性样本的领域对抗选择方法，来改善模型的泛化能力。

    

    领域泛化模型旨在从源领域数据中学习跨领域知识，以提高在未知目标领域上的性能。最近的研究表明，多样化和丰富的源领域样本可以增强领域泛化能力。本文认为每个样本对模型的泛化能力的影响是不同的。尽管规模较小，高质量的数据集仍然能够实现一定水平的泛化能力。在此基础上，我们提出了一种用于领域泛化分类任务的领域对抗主动学习（DAAL）算法。首先，我们分析任务的目标是最大化同一领域内的类间距离，并在不同领域之间最小化类内距离。为了实现这一目标，我们设计了一种优先考虑具有挑战性样本的领域对抗选择方法。

    arXiv:2403.06174v1 Announce Type: cross  Abstract: Domain generalization models aim to learn cross-domain knowledge from source domain data, to improve performance on unknown target domains. Recent research has demonstrated that diverse and rich source domain samples can enhance domain generalization capability. This paper argues that the impact of each sample on the model's generalization ability varies. Despite its small scale, a high-quality dataset can still attain a certain level of generalization ability. Motivated by this, we propose a domain-adversarial active learning (DAAL) algorithm for classification tasks in domain generalization. First, we analyze that the objective of tasks is to maximize the inter-class distance within the same domain and minimize the intra-class distance across different domains. To achieve this objective, we design a domain adversarial selection method that prioritizes challenging samples. Second, we posit that even in a converged model, there are sub
    
[^87]: DiffuMatting：使用Matting级别标注合成任意对象

    DiffuMatting: Synthesizing Arbitrary Objects with Matting-level Annotation

    [https://arxiv.org/abs/2403.06168](https://arxiv.org/abs/2403.06168)

    提出了DiffuMatting方法，通过扩散技术实现了“抠图任何物体”的能力，可以生成高度准确的注释，同时兼容社区LoRAs或各种条件控制方法。

    

    由于获取高度准确或抠图注释的困难和劳动密集性，公开可用的高度准确标签数量有限。为了解决这一挑战，我们提出了一种DiffuMatting，它继承了扩散的强大生成能力，并赋予了“抠图任何物体”的能力。我们的DiffuMatting可以：1）作为一个具有高准确度注释的任意抠图工厂；2）与社区LoRAs或各种条件控制方法兼容，以实现社区友好的艺术设计和可控生成。具体地，受绿幕抠像的启发，我们旨在教授扩散模型在固定的绿幕画布上绘画。为此，收集了一个大规模的绿幕数据集（Green100K）作为DiffuMatting的训练数据集。其次，提出了一个绿色背景控制损失，以保持画布为纯绿色以进行区分。

    arXiv:2403.06168v1 Announce Type: cross  Abstract: Due to the difficulty and labor-consuming nature of getting highly accurate or matting annotations, there only exists a limited amount of highly accurate labels available to the public. To tackle this challenge, we propose a DiffuMatting which inherits the strong Everything generation ability of diffusion and endows the power of "matting anything". Our DiffuMatting can 1). act as an anything matting factory with high accurate annotations 2). be well-compatible with community LoRAs or various conditional control approaches to achieve the community-friendly art design and controllable generation. Specifically, inspired by green-screen-matting, we aim to teach the diffusion model to paint on a fixed green screen canvas. To this end, a large-scale greenscreen dataset (Green100K) is collected as a training dataset for DiffuMatting. Secondly, a green background control loss is proposed to keep the drawing board as a pure green color to disti
    
[^88]: 大型语言模型能否自动评分写作文章的能力？

    Can Large Language Models Automatically Score Proficiency of Written Essays?

    [https://arxiv.org/abs/2403.06149](https://arxiv.org/abs/2403.06149)

    本研究旨在测试大型语言模型在分析和评分书面作文方面的能力，通过对两种流行的LLMs进行实验，设计不同提示并在ASAP数据集上进行实验，揭示了有趣的观察结果。

    

    虽然在过去50年中提出了几种方法来解决自动评分作文（AES）的问题，但在效果方面仍有许多不足之处。大型语言模型（LLMs）是基于Transformer的模型，在各种任务上展示了非凡的能力。本文测试了LLMs的能力，鉴于它们强大的语言知识，来分析和有效评分书面作文。我们对两种流行的LLMs进行了实验，分别是ChatGPT和Llama。我们旨在检查这些模型是否能够完成这项任务，以及它们在两个层面上的表现如何，即在整体上和在个体写作特征上。我们利用提示工程策略设计了四个不同的提示，以发挥它们在这项任务中的最大潜力。我们在ASAP数据集上进行的实验揭示了几个有趣的观察结果。

    arXiv:2403.06149v1 Announce Type: cross  Abstract: Although several methods were proposed to address the problem of automated essay scoring (AES) in the last 50 years, there is still much to desire in terms of effectiveness. Large Language Models (LLMs) are transformer-based models that demonstrate extraordinary capabilities on various tasks. In this paper, we test the ability of LLMs, given their powerful linguistic knowledge, to analyze and effectively score written essays. We experimented with two popular LLMs, namely ChatGPT and Llama. We aim to check if these models can do this task and, if so, how their performance is positioned among the state-of-the-art (SOTA) models across two levels, holistically and per individual writing trait. We utilized prompt-engineering tactics in designing four different prompts to bring their maximum potential to this task. Our experiments conducted on the ASAP dataset revealed several interesting observations. First, choosing the right prompt depend
    
[^89]: AI医学影像领域全能研发平台: 包括数据收集、筛选、标注和预处理

    All-in-one platform for AI R&D in medical imaging, encompassing data collection, selection, annotation, and pre-processing

    [https://arxiv.org/abs/2403.06145](https://arxiv.org/abs/2403.06145)

    该论文介绍了首个商业化医学影像平台，着重解决了来自亚洲地区的数据不足问题，为医学AI研发准备并提供了可直接使用的数据集

    

    深度学习正在推动医学影像研究与开发（R&D），促使基于人工智能/机器学习（AI/ML）的医疗设备频繁在临床中使用。为了推进AI R&D，我们建立了首个商业化医学影像平台，包括数据收集、数据筛选、标注和预处理等步骤。我们专注于利用来自日本和广泛亚洲地区的低重复数据，包括计算机断层扫描、磁共振成像和全切片成像扫描。

    arXiv:2403.06145v1 Announce Type: cross  Abstract: Deep Learning is advancing medical imaging Research and Development (R&D), leading to the frequent clinical use of Artificial Intelligence/Machine Learning (AI/ML)-based medical devices. However, to advance AI R&D, two challenges arise: 1) significant data imbalance, with most data from Europe/America and under 10% from Asia, despite its 60% global population share; and 2) hefty time and investment needed to curate proprietary datasets for commercial use. In response, we established the first commercial medical imaging platform, encompassing steps like: 1) data collection, 2) data selection, 3) annotation, and 4) pre-processing. Moreover, we focus on harnessing under-represented data from Japan and broader Asia, including Computed Tomography, Magnetic Resonance Imaging, and Whole Slide Imaging scans. Using the collected data, we are preparing/providing ready-to-use datasets for medical AI R&D by 1) offering these datasets to AI firms, 
    
[^90]: 流畅：面向私人联邦学习的轮次高效安全聚合

    Fluent: Round-efficient Secure Aggregation for Private Federated Learning

    [https://arxiv.org/abs/2403.06143](https://arxiv.org/abs/2403.06143)

    Fluent提出了一种面向私人联邦学习的轮次和通信高效的安全聚合方案，相比现有解决方案有两个重要改进。

    

    面向私人联邦学习的流畅(Fluent)介绍了一种轮次和通信高效的安全聚合方案。与Bell等人（CCS 2020）和Ma等人（SP 2023）的最新解决方案相比，Fluent在几个方面有所改进：(1)通过在多个训练迭代之间高效地重用份额而不泄露任何私人信息，消除了频繁的握手和秘密共享操作；(2)在一个逻辑操作中完成了一致性检查和梯度解码。

    arXiv:2403.06143v1 Announce Type: cross  Abstract: Federated learning (FL) facilitates collaborative training of machine learning models among a large number of clients while safeguarding the privacy of their local datasets. However, FL remains susceptible to vulnerabilities such as privacy inference and inversion attacks. Single-server secure aggregation schemes were proposed to address these threats. Nonetheless, they encounter practical constraints due to their round and communication complexities. This work introduces Fluent, a round and communication-efficient secure aggregation scheme for private FL. Fluent has several improvements compared to state-of-the-art solutions like Bell et al. (CCS 2020) and Ma et al. (SP 2023): (1) it eliminates frequent handshakes and secret sharing operations by efficiently reusing the shares across multiple training iterations without leaking any private information; (2) it accomplishes both the consistency check and gradient unmasking in one logica
    
[^91]: 基于大型语言模型与图结构理解的细粒度合成流数据用于数据稀疏性

    Fine-grainedly Synthesize Streaming Data Based On Large Language Models With Graph Structure Understanding For Data Sparsity

    [https://arxiv.org/abs/2403.06139](https://arxiv.org/abs/2403.06139)

    提出了一种细粒度合成流数据的框架，利用大型语言模型和图结构理解，将稀疏用户进行分类并生成高质量数据。

    

    由于用户数据稀疏，电子商务平台上对用户评论进行情感分析通常性能不佳，特别是在面对极度稀疏的用户数据或长尾标签时。最近，LLMs的出现通过利用图结构生成辅助用户档案，为这些问题引入了新的解决方案。然而，先前的方法并未充分利用LLMs的图理解能力，并且难以适应复杂的流数据环境。在这项工作中，我们提出了一种细粒度的流数据合成框架，将稀疏用户分类为三类：中尾、长尾和极端。具体来说，我们设计了LLMs，全面理解流数据中的三个关键图元素，包括局部-全局图理解、二阶关系提取和产品属性理解，从而实现高质量数据的生成。

    arXiv:2403.06139v1 Announce Type: cross  Abstract: Due to the sparsity of user data, sentiment analysis on user reviews in e-commerce platforms often suffers from poor performance, especially when faced with extremely sparse user data or long-tail labels. Recently, the emergence of LLMs has introduced new solutions to such problems by leveraging graph structures to generate supplementary user profiles. However, previous approaches have not fully utilized the graph understanding capabilities of LLMs and have struggled to adapt to complex streaming data environments. In this work, we propose a fine-grained streaming data synthesis framework that categorizes sparse users into three categories: Mid-tail, Long-tail, and Extreme. Specifically, we design LLMs to comprehensively understand three key graph elements in streaming data, including Local-global Graph Understanding, Second-Order Relationship Extraction, and Product Attribute Understanding, which enables the generation of high-quality
    
[^92]: MACE：扩散模型中的大规模概念消除

    MACE: Mass Concept Erasure in Diffusion Models

    [https://arxiv.org/abs/2403.06135](https://arxiv.org/abs/2403.06135)

    MACE通过成功将概念消除的范围扩展到100个概念，并在泛化性和特异性之间取得有效平衡，从而防止大规模文本到图像扩散模型生成不良或误导性图像。

    

    大规模文本到图像扩散模型的快速扩展引起了人们对其在创建有害或误导性内容方面潜在误用的担忧。本文介绍了一种名为MACE的微调框架，用于大规模概念消除任务。该任务旨在防止模型在提示时生成具有不希望概念的图像。现有的概念消除方法通常受限于同时处理少于五个概念，并且在消除概念的同时难以找到消除概念同义词（泛化性）和保持不相关概念（特异性）之间的平衡。相比之下，MACE通过成功将消除范围扩展到100个概念，并在泛化性和特异性之间取得有效平衡而不同。这是通过利用闭环交叉注意力细化以及LoRA微调来实现的，共同消除了不良概念的信息。此外，MACE还...

    arXiv:2403.06135v1 Announce Type: cross  Abstract: The rapid expansion of large-scale text-to-image diffusion models has raised growing concerns regarding their potential misuse in creating harmful or misleading content. In this paper, we introduce MACE, a finetuning framework for the task of mass concept erasure. This task aims to prevent models from generating images that embody unwanted concepts when prompted. Existing concept erasure methods are typically restricted to handling fewer than five concepts simultaneously and struggle to find a balance between erasing concept synonyms (generality) and maintaining unrelated concepts (specificity). In contrast, MACE differs by successfully scaling the erasure scope up to 100 concepts and by achieving an effective balance between generality and specificity. This is achieved by leveraging closed-form cross-attention refinement along with LoRA finetuning, collectively eliminating the information of undesirable concepts. Furthermore, MACE int
    
[^93]: FedPIT：面向隐私保护和少样本联邦指令调整

    FedPIT: Towards Privacy-preserving and Few-shot Federated Instruction Tuning

    [https://arxiv.org/abs/2403.06131](https://arxiv.org/abs/2403.06131)

    提出一种新颖的联邦算法FedPIT，通过利用LLMs的上下文学习能力自动生成任务特定的合成数据进行训练，采用参数隔离训练来防止数据提取攻击。

    

    指令调整对于增强大型语言模型（LLMs）在生成与人类对齐的响应方面的性能已被证明至关重要。然而，在调整过程中收集多样化、高质量的指令数据存在挑战，特别是在涉及隐私的领域。联邦指令调整（FedIT）已成为一种解决方案，利用来自多个数据所有者的联邦学习，同时保护隐私。然而，由于指令数据有限以及容易受到训练数据提取攻击的脆弱性，它面临挑战。为解决这些问题，我们提出了一种新颖的联邦算法，FedPIT，它利用LLMs的上下文学习能力自动生成用于训练的特定任务合成数据。我们的方法采用参数隔离训练来维护在合成数据上训练的全局参数和在增强本地数据上训练的本地参数，有效地防止数据提取攻击。

    arXiv:2403.06131v1 Announce Type: cross  Abstract: Instruction tuning has proven essential for enhancing the performance of large language models (LLMs) in generating human-aligned responses. However, collecting diverse, high-quality instruction data for tuning poses challenges, particularly in privacy-sensitive domains. Federated instruction tuning (FedIT) has emerged as a solution, leveraging federated learning from multiple data owners while preserving privacy. Yet, it faces challenges due to limited instruction data and vulnerabilities to training data extraction attacks. To address these issues, we propose a novel federated algorithm, FedPIT, which utilizes LLMs' in-context learning capability to self-generate task-specific synthetic data for training autonomously. Our method employs parameter-isolated training to maintain global parameters trained on synthetic data and local parameters trained on augmented local data, effectively thwarting data extraction attacks. Extensive exper
    
[^94]: FMPAF：联邦储备主席如何影响金融市场？关于他们语言的细粒度货币政策分析框架

    FMPAF: How Do Fed Chairs Affect the Financial Market? A Fine-grained Monetary Policy Analysis Framework on Their Language

    [https://arxiv.org/abs/2403.06115](https://arxiv.org/abs/2403.06115)

    FMPAF是一个新颖的方法，通过整合大型语言模型和回归分析，提供了对美联储主席新闻发布会沟通对金融市场影响的全面分析。

    

    中央银行沟通的有效性是货币政策传导的一个关键方面。尽管最近的研究已经考察了美联储主席的政策沟通对各种金融变量的影响，但大部分文献依赖于基于规则或词典的方法来解析主席的语言，导致对包含在非言语情绪中的政策立场的微妙信息缺乏分析。在当前研究中，我们提出了细粒度货币政策分析框架（FMPAF），这是一种集成大型语言模型（LLMs）与回归分析的新方法，旨在全面分析美联储主席新闻发布会沟通对金融市场的影响。我们进行了模型性能在不同细粒度、模态和沟通场景下的广泛比较。

    arXiv:2403.06115v1 Announce Type: cross  Abstract: The effectiveness of central bank communication is a crucial aspect of monetary policy transmission. While recent research has examined the influence of policy communication by the chairs of the Federal Reserve on various financial variables, much of the literature relies on rule-based or dictionary-based methods in parsing the language of the chairs, leaving nuanced information about policy stance contained in nonverbal emotion out of the analysis. In the current study, we propose the Fine-Grained Monetary Policy Analysis Framework (FMPAF), a novel approach that integrates large language models (LLMs) with regression analysis to provide a comprehensive analysis of the impact of the press-conference communications of chairs of the Federal Reserve on financial markets. We conduct extensive comparisons of model performance under different levels of granularity, modalities, and communication scenarios. Based on our preferred specification
    
[^95]: 在包含数据增强和迁移学习的细粒度情感检测数据集上使用大型语言模型

    Large Language Models on Fine-grained Emotion Detection Dataset with Data Augmentation and Transfer Learning

    [https://arxiv.org/abs/2403.06108](https://arxiv.org/abs/2403.06108)

    本文研究了如何在细粒度情感检测数据集上使用大型语言模型来提高分类性能，并提出了对于文本中检测微妙情感的挑战的有价值见解。

    

    本文深入研究了如何在GoEmotions数据集上提高情感检测的分类性能，这是一个大型、手动注释的文本情感检测数据集。本文的主要目标是解决在文本中检测微妙情感的挑战，这是自然语言处理中一个复杂的问题，具有重要的实际应用。研究结果为解决文本情感检测的挑战提供了宝贵的见解，并提出了未来研究的方向，包括合成该领域各个数据集上方法和性能的综述论文的潜在性。

    arXiv:2403.06108v1 Announce Type: cross  Abstract: This paper delves into enhancing the classification performance on the GoEmotions dataset, a large, manually annotated dataset for emotion detection in text. The primary goal of this paper is to address the challenges of detecting subtle emotions in text, a complex issue in Natural Language Processing (NLP) with significant practical applications. The findings offer valuable insights into addressing the challenges of emotion detection in text and suggest directions for future research, including the potential for a survey paper that synthesizes methods and performances across various datasets in this domain.
    
[^96]: 能否用LLM替代人工标注？ 无人机交付任务下的细粒度中文地址实体识别数据集案例研究

    Can LLM Substitute Human Labeling? A Case Study of Fine-grained Chinese Address Entity Recognition Dataset for UAV Delivery

    [https://arxiv.org/abs/2403.06097](https://arxiv.org/abs/2403.06097)

    提出了适用于无人机交付系统中地址解析任务的细粒度中文姓名实体识别数据集CNER-UAV，包含五个类别的多样化数据，经过严格的数据清洗和去敏处理，约有12,000个标注样本，评估了传统的实体识别模型并提供了深入分析

    

    我们提出了CNER-UAV，一个专为无人机交付系统中地址解析任务设计的细粒度中文姓名实体识别数据集。该数据集涵盖了五个类别，可以全面训练和评估实体识别模型。为构建这一数据集，我们从真实无人机交付系统中获取数据，并进行了严格的数据清洗和去敏处理，确保数据的隐私性和完整性。最终的数据集约包含12,000个标注样本，经过人工专家和大型语言模型的注释。我们在我们的数据集上评估了传统的实体识别模型，并提供了深入分析。数据集和模型可以在 \url{https://github.com/zhhvvv/CNER-UAV} 上公开获取。

    arXiv:2403.06097v1 Announce Type: cross  Abstract: We present CNER-UAV, a fine-grained \textbf{C}hinese \textbf{N}ame \textbf{E}ntity \textbf{R}ecognition dataset specifically designed for the task of address resolution in \textbf{U}nmanned \textbf{A}erial \textbf{V}ehicle delivery systems. The dataset encompasses a diverse range of five categories, enabling comprehensive training and evaluation of NER models. To construct this dataset, we sourced the data from a real-world UAV delivery system and conducted a rigorous data cleaning and desensitization process to ensure privacy and data integrity. The resulting dataset, consisting of around 12,000 annotated samples, underwent human experts and \textbf{L}arge \textbf{L}anguage \textbf{M}odel annotation. We evaluated classical NER models on our dataset and provided in-depth analysis. The dataset and models are publicly available at \url{https://github.com/zhhvvv/CNER-UAV}.
    
[^97]: RepoHyper：更好的上下文检索是仓库级代码补全所需的一切

    RepoHyper: Better Context Retrieval Is All You Need for Repository-Level Code Completion

    [https://arxiv.org/abs/2403.06095](https://arxiv.org/abs/2403.06095)

    RepoHyper提出了Repo级语义图（RSG）和Expand和Refine检索方法，显著优于现有技术，满足仓库级代码补全的需求

    

    arXiv:2403.06095v1 公告类型：交叉摘要：代码大型语言模型（CodeLLMs）在代码补全任务中展示出令人印象深刻的熟练程度。然而，它们经常无法完全理解项目仓库的广泛上下文，比如相关文件和类层次结构的复杂性，这可能导致补全不够精确。为了克服这些限制，我们提出了RepoHyper，一个旨在解决与仓库级代码补全相关的复杂挑战的多方面框架。RepoHyper的核心是Repo级语义图（RSG），一种封装代码仓库广泛上下文的新颖语义图结构。此外，RepoHyper利用扩展和细化检索方法，包括应用于RSG的图扩展和链接预测算法，从而实现对相关代码片段的有效检索和优先排序。我们的评估表明，RepoHyper在重新

    arXiv:2403.06095v1 Announce Type: cross  Abstract: Code Large Language Models (CodeLLMs) have demonstrated impressive proficiency in code completion tasks. However, they often fall short of fully understanding the extensive context of a project repository, such as the intricacies of relevant files and class hierarchies, which can result in less precise completions. To overcome these limitations, we present RepoHyper, a multifaceted framework designed to address the complex challenges associated with repository-level code completion. Central to RepoHyper is the Repo-level Semantic Graph (RSG), a novel semantic graph structure that encapsulates the vast context of code repositories. Furthermore, RepoHyper leverages Expand and Refine retrieval method, including a graph expansion and a link prediction algorithm applied to the RSG, enabling the effective retrieval and prioritization of relevant code snippets. Our evaluations show that RepoHyper markedly outperforms existing techniques in re
    
[^98]: 面向车载多任务面部属性识别：研究合成数据和视觉基础模型

    Towards In-Vehicle Multi-Task Facial Attribute Recognition: Investigating Synthetic Data and Vision Foundation Models

    [https://arxiv.org/abs/2403.06088](https://arxiv.org/abs/2403.06088)

    本文通过研究合成数据集的实用性和不同视觉基础模型在车载多任务面部属性识别中的效果，填补了现有文献中的空白。

    

    在智能交通系统蓬勃发展的领域中，通过面部属性识别（如面部表情、眼神、年龄等）增强车辆驾驶员的交互对于安全、个性化和整体用户体验至关重要。然而，缺乏全面大规模的真实世界数据集对训练稳健的多任务模型构成了重大挑战。现有文献通常忽视了合成数据集的潜力以及在这种受限环境中最先进的视觉基础模型的比较功效。本文通过研究合成数据集的实用性来训练识别车辆乘客的面部属性（如眼神方向、年龄和面部表情）的复杂多任务模型，并利用预训练的Vision Transformer（ViT）和残差网络（ResNet）模型的迁移学习技术来填补这些空白。

    arXiv:2403.06088v1 Announce Type: cross  Abstract: In the burgeoning field of intelligent transportation systems, enhancing vehicle-driver interaction through facial attribute recognition, such as facial expression, eye gaze, age, etc., is of paramount importance for safety, personalization, and overall user experience. However, the scarcity of comprehensive large-scale, real-world datasets poses a significant challenge for training robust multi-task models. Existing literature often overlooks the potential of synthetic datasets and the comparative efficacy of state-of-the-art vision foundation models in such constrained settings. This paper addresses these gaps by investigating the utility of synthetic datasets for training complex multi-task models that recognize facial attributes of passengers of a vehicle, such as gaze plane, age, and facial expression. Utilizing transfer learning techniques with both pre-trained Vision Transformer (ViT) and Residual Network (ResNet) models, we exp
    
[^99]: 通向可泛化和可解释的运动预测：一种深度变分贝叶斯方法

    Towards Generalizable and Interpretable Motion Prediction: A Deep Variational Bayes Approach

    [https://arxiv.org/abs/2403.06086](https://arxiv.org/abs/2403.06086)

    本论文提出了一种Goal-based Neural Variational Agent (GNeVA)模型，通过变分高斯混合估算长期目的地的空间分布，实现了目标驱动的运动预测，具有强大的泛化能力和解释性。

    

    arXiv:2403.06086v1 公告类型:新 摘要:估计周围人驾驶车辆的潜在行为对自动驾驶车辆在混合交通流中的安全至关重要。最近的最先进技术利用深度神经网络实现了准确的预测。然而，这些端到端模型通常是黑箱，解释性和泛化能力弱。本文提出了基于目标的神经变分代理（GNeVA），一种可解释的生成模型，用于具有鲁棒泛化能力以处理分布之外情况的运动预测。为了可解释性，该模型通过估算长期目的地的空间分布来实现目标驱动的运动预测，采用高斯变分混合。我们识别地图和代理历史之间的因果结构，并推导变分后验以增强泛化能力。在运动预测数据集上的实验证明，拟合的模型既可解释又具有泛化能力，并可实现

    arXiv:2403.06086v1 Announce Type: new  Abstract: Estimating the potential behavior of the surrounding human-driven vehicles is crucial for the safety of autonomous vehicles in a mixed traffic flow. Recent state-of-the-art achieved accurate prediction using deep neural networks. However, these end-to-end models are usually black boxes with weak interpretability and generalizability. This paper proposes the Goal-based Neural Variational Agent (GNeVA), an interpretable generative model for motion prediction with robust generalizability to out-of-distribution cases. For interpretability, the model achieves target-driven motion prediction by estimating the spatial distribution of long-term destinations with a variational mixture of Gaussians. We identify a causal structure among maps and agents' histories and derive a variational posterior to enhance generalizability. Experiments on motion prediction datasets validate that the fitted model can be interpretable and generalizable and can achi
    
[^100]: L$^2$GC: 洛伦兹线性图卷积网络用于节点分类

    L$^2$GC: Lorentzian Linear Graph Convolutional Networks For Node Classification

    [https://arxiv.org/abs/2403.06064](https://arxiv.org/abs/2403.06064)

    本文提出了一种新颖的洛伦兹线性图卷积网络框架，将双曲空间引入线性GCN，用于捕捉数据的树状结构，并在实验中取得了新的最先进的节点分类结果。

    

    线性图卷积网络（GCNs）用于对图数据中的节点进行分类。然而，我们注意到大多数现有的线性GCN模型在欧几里得空间中执行神经网络操作，这并没有明确捕捉到作为图模型的现实世界数据集中呈现出的类似树状的层次结构。本文尝试将双曲空间引入线性GCN，并提出了一种新颖的洛伦兹线性GCN框架。具体来说，我们将图节点的学习特征映射到双曲空间中，然后进行洛伦兹线性特征变换，以捕获数据的潜在树状结构。在标准引文网络数据集上进行的半监督学习实验结果显示，我们的方法在Citeseer数据集上达到了74.7%的准确度，而在PubMed数据集上达到了81.3%的准确度，创造了新的最先进结果。此外，我们观察到我们的方法可以训练至少达到2个数量级。

    arXiv:2403.06064v1 Announce Type: cross  Abstract: Linear Graph Convolutional Networks (GCNs) are used to classify the node in the graph data. However, we note that most existing linear GCN models perform neural network operations in Euclidean space, which do not explicitly capture the tree-like hierarchical structure exhibited in real-world datasets that modeled as graphs. In this paper, we attempt to introduce hyperbolic space into linear GCN and propose a novel framework for Lorentzian linear GCN. Specifically, we map the learned features of graph nodes into hyperbolic space, and then perform a Lorentzian linear feature transformation to capture the underlying tree-like structure of data. Experimental results on standard citation networks datasets with semi-supervised learning show that our approach yields new state-of-the-art results of accuracy 74.7$\%$ on Citeseer and 81.3$\%$ on PubMed datasets. Furthermore, we observe that our approach can be trained up to two orders of magnitu
    
[^101]: 面向目标导向主动对话生成的目标受限双向规划

    Target-constrained Bidirectional Planning for Generation of Target-oriented Proactive Dialogue

    [https://arxiv.org/abs/2403.06063](https://arxiv.org/abs/2403.06063)

    提出了一种面向目标导向对话生成的目标受限双向规划（TRIP）方法，通过前向和后向规划生成对话路径，促进对话向预定目标发展。

    

    面向目标导向的主动对话系统旨在引导对话从对话上下文向预定目标发展，比如在指定项目上进行推荐或介绍新的特定主题。为此，对话系统关键在于计划合理的行动以主动推动对话，并同时计划适当的主题以顺利推进对话到目标话题。本文主要关注于面向目标导向对话生成的有效对话规划。受认知科学中决策理论的启发，我们提出了一种新颖的目标受限双向规划（TRIP）方法，通过前向和后向规划一个适当的对话路径。通过将规划形式化为一项生成任务，我们的TRIP双向生成了一个由一系列pair组成的对话路径，使用了两个Transformer解码器。它们被预期用于监督

    arXiv:2403.06063v1 Announce Type: cross  Abstract: Target-oriented proactive dialogue systems aim to lead conversations from a dialogue context toward a pre-determined target, such as making recommendations on designated items or introducing new specific topics. To this end, it is critical for such dialogue systems to plan reasonable actions to drive the conversation proactively, and meanwhile, to plan appropriate topics to move the conversation forward to the target topic smoothly. In this work, we mainly focus on effective dialogue planning for target-oriented dialogue generation. Inspired by decision-making theories in cognitive science, we propose a novel target-constrained bidirectional planning (TRIP) approach, which plans an appropriate dialogue path by looking ahead and looking back. By formulating the planning as a generation task, our TRIP bidirectionally generates a dialogue path consisting of a sequence of  pairs using two Transformer decoders. They are expected to supervis
    
[^102]: 具有扩散净化的分离数据一致性的图像恢复

    Decoupled Data Consistency with Diffusion Purification for Image Restoration

    [https://arxiv.org/abs/2403.06054](https://arxiv.org/abs/2403.06054)

    通过分离反向过程和数据一致性步骤，提出了一种新颖的基于扩散的图像恢复求解器。

    

    最近，扩散模型作为一种强大的深度生成先验类别已经引起了人们的关注，由于其出色地建模数据分布的能力，在各种图像恢复任务中表现出色。为了解决图像恢复问题，许多现有技术通过将额外的似然梯度步骤纳入到扩散模型的反向采样过程中来实现数据一致性。然而，这些额外的梯度步骤对于实际应用中存在挑战，因为它们造成了巨大的计算开销，从而增加了推理时间。当使用加速的扩散模型采样器时，这些额外的步骤还会导致额外的困难，因为数据一致性步骤的数量受限于反向采样步骤的数量。在这项工作中，我们提出了一种新颖的基于扩散的图像恢复求解器，通过将反向过程与数据一致性步骤分离来解决这些问题。我们的方法涉及

    arXiv:2403.06054v1 Announce Type: cross  Abstract: Diffusion models have recently gained traction as a powerful class of deep generative priors, excelling in a wide range of image restoration tasks due to their exceptional ability to model data distributions. To solve image restoration problems, many existing techniques achieve data consistency by incorporating additional likelihood gradient steps into the reverse sampling process of diffusion models. However, the additional gradient steps pose a challenge for real-world practical applications as they incur a large computational overhead, thereby increasing inference time. They also present additional difficulties when using accelerated diffusion model samplers, as the number of data consistency steps is limited by the number of reverse sampling steps. In this work, we propose a novel diffusion-based image restoration solver that addresses these issues by decoupling the reverse process from the data consistency steps. Our method involv
    
[^103]: MATRIX: 具有多样化背景的多智能体轨迹生成

    MATRIX: Multi-Agent Trajectory Generation with Diverse Contexts

    [https://arxiv.org/abs/2403.06041](https://arxiv.org/abs/2403.06041)

    本研究提出了一种名为MATRIX的学习基础自动轨迹生成模型，能够在多样化背景中生成交互式人类行为。

    

    数据驱动方法在建模复杂人类行为动态和处理许多人机交互应用中具有巨大优势。然而，收集大规模和带标注的真实世界人类数据通常是一项费力的任务，特别是对于高度交互式的场景。另一方面，基于算法的数据生成方法通常受到模型能力的限制，使其无法为各种应用用户提供所需的现实和多样化数据。本文研究了多人或人机交互场景的轨迹级数据生成，并提出了一种学习基础的自动轨迹生成模型，我们称之为具有多样化背景的多智能体轨迹生成（MATRIX）。MATRIX能够在现实多样化的背景中生成交互式人类行为。我们通过建模显式和可解释的目标来实现这一目标，使MATRIX能够生成人类运动。

    arXiv:2403.06041v1 Announce Type: cross  Abstract: Data-driven methods have great advantages in modeling complicated human behavioral dynamics and dealing with many human-robot interaction applications. However, collecting massive and annotated real-world human datasets has been a laborious task, especially for highly interactive scenarios. On the other hand, algorithmic data generation methods are usually limited by their model capacities, making them unable to offer realistic and diverse data needed by various application users. In this work, we study trajectory-level data generation for multi-human or human-robot interaction scenarios and propose a learning-based automatic trajectory generation model, which we call Multi-Agent TRajectory generation with dIverse conteXts (MATRIX). MATRIX is capable of generating interactive human behaviors in realistic diverse contexts. We achieve this goal by modeling the explicit and interpretable objectives so that MATRIX can generate human motion
    
[^104]: 对YouTuber在内容创作中使用生成式人工智能的初步探索

    A Preliminary Exploration of YouTubers' Use of Generative-AI in Content Creation

    [https://arxiv.org/abs/2403.06039](https://arxiv.org/abs/2403.06039)

    通过定性分析探讨了YouTuber在内容创作中使用生成式人工智能的方法和生成的内容领域。

    

    内容创作者越来越多地利用生成式人工智能（Gen-AI）在YouTube、TikTok、Instagram和各种博客网站等平台上生成想象力十足的图像、AI生成视频和使用大型语言模型（LLM）的文章。尽管其日益普及，AI生成内容正在应用的具体领域以及内容创作者在创作过程中使用Gen-AI工具的方法仍然是一个尚未被深入探讨的领域。该研究通过对展示Gen-AI使用的68个YouTube视频进行定性分析，最初探讨了这一新兴领域。我们的研究重点是识别在用户生成内容背景下由Gen-AI生成的内容领域、使用的工具种类、执行的活动以及生成的最终产品的性质。

    arXiv:2403.06039v1 Announce Type: cross  Abstract: Content creators increasingly utilize generative artificial intelligence (Gen-AI) on platforms such as YouTube, TikTok, Instagram, and various blogging sites to produce imaginative images, AI-generated videos, and articles using Large Language Models (LLMs). Despite its growing popularity, there remains an underexplored area concerning the specific domains where AI-generated content is being applied, and the methodologies content creators employ with Gen-AI tools during the creation process. This study initially explores this emerging area through a qualitative analysis of 68 YouTube videos demonstrating Gen-AI usage. Our research focuses on identifying the content domains, the variety of tools used, the activities performed, and the nature of the final products generated by Gen-AI in the context of user-generated content.
    
[^105]: FairTargetSim：用于理解和解释目标变量定义公平性影响的交互式模拟器

    FairTargetSim: An Interactive Simulator for Understanding and Explaining the Fairness Effects of Target Variable Definition

    [https://arxiv.org/abs/2403.06031](https://arxiv.org/abs/2403.06031)

    FairTargetSim提供了一个交互式模拟器，展示了目标变量定义对公平性的影响，适用于算法开发者、研究人员和非技术利益相关者。

    

    机器学习需要为预测或决策定义目标变量，这个过程可能对公平性产生深远影响：偏见通常已经被编码在目标变量定义本身中，而不是在任何数据收集或训练之前。我们提出了一个交互式模拟器，FairTargetSim (FTS)，展示了目标变量定义如何影响公平性。FTS是一个有价值的工具，适用于算法开发者、研究人员和非技术利益相关者。FTS使用了算法招聘的案例研究，使用真实世界数据和用户定义的目标变量。FTS是开源的，可在以下网址找到：http://tinyurl.com/ftsinterface。本文附带的视频网址为：http://tinyurl.com/ijcaifts。

    arXiv:2403.06031v1 Announce Type: cross  Abstract: Machine learning requires defining one's target variable for predictions or decisions, a process that can have profound implications on fairness: biases are often encoded in target variable definition itself, before any data collection or training. We present an interactive simulator, FairTargetSim (FTS), that illustrates how target variable definition impacts fairness. FTS is a valuable tool for algorithm developers, researchers, and non-technical stakeholders. FTS uses a case study of algorithmic hiring, using real-world data and user-defined target variables. FTS is open-source and available at: http://tinyurl.com/ftsinterface. The video accompanying this paper is here: http://tinyurl.com/ijcaifts.
    
[^106]: 为基于学习方法的组合问题构建通用表示

    Towards a Generic Representation of Cominatorial Problems for Learning-Based Approaches

    [https://arxiv.org/abs/2403.06026](https://arxiv.org/abs/2403.06026)

    本文倡导为基于学习方法的组合问题构建通用表示，以解决特定表示无法跨越不同组合问题的问题。

    

    近年来，越来越多的研究人员对使用基于学习方法解决组合问题产生了兴趣，无论是以端到端的方式还是与传统优化算法结合使用。在这两种情景下，挑战在于将目标组合问题编码成适用于学习算法的结构。许多现有作品提出了特定于问题的表示，通常以图的形式，以利用图神经网络的优势。然而，这些方法缺乏泛化性，因为表示不能轻易从一个组合问题转移到另一个组合问题。虽然已经有一些尝试去填补这一差距，但它们仍然只提供了部分泛化性。鉴于这一挑战，本文倡导为基于学习方法的组合问题朝着完全通用的表示方式迈进。我们提出的方法包括

    arXiv:2403.06026v1 Announce Type: cross  Abstract: In recent years, there has been a growing interest in using learning-based approaches for solving combinatorial problems, either in an end-to-end manner or in conjunction with traditional optimization algorithms. In both scenarios, the challenge lies in encoding the targeted combinatorial problems into a structure compatible with the learning algorithm. Many existing works have proposed problem-specific representations, often in the form of a graph, to leverage the advantages of \textit{graph neural networks}. However, these approaches lack generality, as the representation cannot be easily transferred from one combinatorial problem to another one. While some attempts have been made to bridge this gap, they still offer a partial generality only. In response to this challenge, this paper advocates for progress toward a fully generic representation of combinatorial problems for learning-based approaches. The approach we propose involves 
    
[^107]: CarbonNet: 计算机视觉在气候变化中的作用是什么？ 应用：学习从地下储存空间几何形状中减缓全球变暖的地质力学

    CarbonNet: How Computer Vision Plays a Role in Climate Change? Application: Learning Geomechanics from Subsurface Geometry of CCS to Mitigate Global Warming

    [https://arxiv.org/abs/2403.06025](https://arxiv.org/abs/2403.06025)

    这项研究介绍了一种利用计算机视觉从地下储存空间几何图像中预测陆地表面位移的新方法，为碳捕集和封存项目中的决策提供支持。

    

    我们介绍了一种新方法，使用计算机视觉从地下储存空间几何图像中预测陆地表面位移，以应用于碳捕集和封存（CCS）。CCS已被证明是碳中和社会的关键组成部分。然而，科学家发现存在挑战，包括由于大模型尺度而导致的高计算成本，以及难以泛化具有复杂物理学的预训练模型的限制。我们通过直接从地下储存空间几何图像训练模型来应对这些挑战。我们的目标是理解由碳注入导致的陆地表面位移响应，并利用我们训练的模型来为CCS项目的决策提供信息。

    arXiv:2403.06025v1 Announce Type: cross  Abstract: We introduce a new approach using computer vision to predict the land surface displacement from subsurface geometry images for Carbon Capture and Sequestration (CCS). CCS has been proved to be a key component for a carbon neutral society. However, scientists see there are challenges along the way including the high computational cost due to the large model scale and limitations to generalize a pre-trained model with complex physics. We tackle those challenges by training models directly from the subsurface geometry images. The goal is to understand the respons of land surface displacement due to carbon injection and utilize our trained models to inform decision making in CCS projects.   We implement multiple models (CNN, ResNet, and ResNetUNet) for static mechanics problem, which is a image prediction problem. Next, we use the LSTM and transformer for transient mechanics scenario, which is a video prediction problem. It shows ResNetUNe
    
[^108]: 少样本跨语言迁移用于在低资源语言中提示大型语言模型

    Few-Shot Cross-Lingual Transfer for Prompting Large Language Models in Low-Resource Languages

    [https://arxiv.org/abs/2403.06018](https://arxiv.org/abs/2403.06018)

    本研究评估了如何将具有70亿参数的开源PLM LLaMa 用于低资源语言的提示，解决了跨语言适应提示的问题。

    

    大型预训练语言模型（PLMs）处于自然语言处理进展的前沿。PLMs的一个广泛应用是“提示” - 或上下文学习 - 用户在提示PLM对新示例执行任务之前向PLM提供任务描述和一些完成的示例作为上下文。目前只有最大、最有能力的PLMs才能有效地执行上下文学习，而这些模型通常是通过主要以英语为语料库训练的，其他所有语言都落后。大多数语言的数据限制阻碍了训练具有提示能力的语言特定PLMs。尽管在提示设置方面的工作激增，目前仍不清楚如何将PLMs专门用于跨语言适应提示。我们评估了适应LLaMa的可能方法，LLaMa是一个主要在英语中训练的具有70亿参数的开源PLM，用于在低资源语言中进行提示。

    arXiv:2403.06018v1 Announce Type: cross  Abstract: Large pre-trained language models (PLMs) are at the forefront of advances in Natural Language Processing. One widespread use case of PLMs is "prompting" - or in-context learning - where a user provides a description of a task and some completed examples of the task to a PLM as context before prompting the PLM to perform the task on a new example. Only the largest, most capable PLMs are able to perform in-context learning effectively, and these models are typically trained with a predominantly English corpus, leaving all other languages behind. The data limitations in most languages preclude the training of language-specific PLMs capable of prompting. Albeit the surge in work of prompting settings, it is still unclear how PLMs should be adapted cross-lingually specifically for prompting. We evaluate the possible methods to adapt LLaMa, a 7B parameter open-source PLM mainly trained in English, for prompting in low-resource languages, nam
    
[^109]: 基于硬标签的小查询黑盒对抗攻击

    Hard-label based Small Query Black-box Adversarial Attack

    [https://arxiv.org/abs/2403.06014](https://arxiv.org/abs/2403.06014)

    提出了一种新的基于硬标签的黑盒对抗攻击方法，通过在优化过程中利用预训练替代模型的指导，显著提高了攻击的查询效率。

    

    我们考虑了基于硬标签的黑盒对抗攻击设置，仅观察来自目标模型的预测类别。在这种设置中，大多数攻击方法都需要不切实际数量的查询才能实现成功攻击。解决这一缺点的一种方法是利用白盒替代模型与黑盒目标模型之间的对抗传递性。然而，采用这种方法的大多数方法都是基于软标签的，以充分利用零阶优化。与主流方法不同，我们提出了一种新的实用的基于硬标签的攻击设置，其优化过程由预训练的替代模型指导。实验证明，所提出的方法显著提高了在各种目标模型架构上的基于硬标签的黑盒攻击的查询效率。我们发现，所提出的方法实现了约5倍更高的攻击成功率。

    arXiv:2403.06014v1 Announce Type: cross  Abstract: We consider the hard label based black box adversarial attack setting which solely observes predicted classes from the target model. Most of the attack methods in this setting suffer from impractical number of queries required to achieve a successful attack. One approach to tackle this drawback is utilising the adversarial transferability between white box surrogate models and black box target model. However, the majority of the methods adopting this approach are soft label based to take the full advantage of zeroth order optimisation. Unlike mainstream methods, we propose a new practical setting of hard label based attack with an optimisation process guided by a pretrained surrogate model. Experiments show the proposed method significantly improves the query efficiency of the hard label based black-box attack across various target model architectures. We find the proposed method achieves approximately 5 times higher attack success rat
    
[^110]: 一种推广的用于基于偏好的奖励学习的收益函数

    A Generalized Acquisition Function for Preference-based Reward Learning

    [https://arxiv.org/abs/2403.06003](https://arxiv.org/abs/2403.06003)

    通过引入一种可以捕捉奖励函数相似性定义的框架，优化了奖励函数的学习效率。

    

    基于偏好的奖励学习是一种用于教导机器人和自主系统如何执行任务的流行技术。 先前的研究表明，积极合成偏好查询以最大化关于奖励函数参数的信息增益可以提高数据效率。 信息增益标准侧重于精确识别奖励函数的所有参数。 这可能是低效的，因为许多参数可能导致相同的奖励，并且许多奖励可能导致下游任务中的相同行为。 相反，我们展示了可以优化学习奖励函数直到行为等效类，例如诱导出相同的行为排序，选择分布，或其他相关定义使得两个奖励看起来相似。 我们引入了一个可以捕捉这种相似性定义的可处理框架。 我们在一个.synthetic env的实验中展示了这一点

    arXiv:2403.06003v1 Announce Type: cross  Abstract: Preference-based reward learning is a popular technique for teaching robots and autonomous systems how a human user wants them to perform a task. Previous works have shown that actively synthesizing preference queries to maximize information gain about the reward function parameters improves data efficiency. The information gain criterion focuses on precisely identifying all parameters of the reward function. This can potentially be wasteful as many parameters may result in the same reward, and many rewards may result in the same behavior in the downstream tasks. Instead, we show that it is possible to optimize for learning the reward function up to a behavioral equivalence class, such as inducing the same ranking over behaviors, distribution over choices, or other related definitions of what makes two rewards similar. We introduce a tractable framework that can capture such definitions of similarity. Our experiments in a synthetic env
    
[^111]: 用高更新比例剖析深度强化学习：应对价值高估和发散

    Dissecting Deep RL with High Update Ratios: Combatting Value Overestimation and Divergence

    [https://arxiv.org/abs/2403.05996](https://arxiv.org/abs/2403.05996)

    本研究剖析了深度强化学习中的首要偏差现象，发现在大量更新比例下，价值高估是导致学习失败的根本挑战。

    

    我们展示了深度强化学习在设置中可以在梯度更新次数大大超过环境样本数量的情况下保持学习能力，而无需重置网络参数。在这种大量更新与数据比例的情况下，尼基辛等人 (2022) 的最近一项研究指出了一个首要偏差的出现，即代理在早期交互中过拟合并淡化后续经验，从而损害了其学习能力。在这项工作中，我们深入解析了导致首要偏差的现象。我们检查了应该导致学习失败的训练早期阶段，并发现一个根本性挑战是长期以来存在的问题：价值高估。我们发现Q值不仅在分布外数据上被高估，而且在分布内数据上也是如此，可以追溯到由优化器动量推动的未见的动作预测。我们采用了一种简单的单位球归一化方法，可以在大更新比例下实现学习。

    arXiv:2403.05996v1 Announce Type: cross  Abstract: We show that deep reinforcement learning can maintain its ability to learn without resetting network parameters in settings where the number of gradient updates greatly exceeds the number of environment samples. Under such large update-to-data ratios, a recent study by Nikishin et al. (2022) suggested the emergence of a primacy bias, in which agents overfit early interactions and downplay later experience, impairing their ability to learn. In this work, we dissect the phenomena underlying the primacy bias. We inspect the early stages of training that ought to cause the failure to learn and find that a fundamental challenge is a long-standing acquaintance: value overestimation. Overinflated Q-values are found not only on out-of-distribution but also in-distribution data and can be traced to unseen action prediction propelled by optimizer momentum. We employ a simple unit-ball normalization that enables learning under large update ratios
    
[^112]: 仅使用生成来校准大型语言模型

    Calibrating Large Language Models Using Their Generations Only

    [https://arxiv.org/abs/2403.05973](https://arxiv.org/abs/2403.05973)

    使用APRICOT方法，通过仅使用大型语言模型的文本输入和输出来设置置信目标并训练额外模型，从而实现大型语言模型的校准。

    

    随着大型语言模型（LLMs）越来越多地部署在面向用户的应用程序中，通过准确量化模型对其预测的信心来建立信任并保持安全性变得更加重要。然而，找到有效的方法来校准LLMs - 尤其是当与模型的唯一接口是它们生成的文本时 - 仍然是一个挑战。我们提出了APRICOT（辅助预测置信目标）：一种通过仅使用其文本输入和输出来设置置信目标并训练一个额外模型来预测LLM置信度的方法。这种方法有几个优点：概念上简单，不需要访问目标模型超出其输出，不干扰语言生成，并且有多种潜在用途，例如通过言语化预测的置信度或根据置信度调整给定的答案。我们展示了我们的方法如何具有竞争性能。

    arXiv:2403.05973v1 Announce Type: cross  Abstract: As large language models (LLMs) are increasingly deployed in user-facing applications, building trust and maintaining safety by accurately quantifying a model's confidence in its prediction becomes even more important. However, finding effective ways to calibrate LLMs - especially when the only interface to the models is their generated text - remains a challenge. We propose APRICOT (auxiliary prediction of confidence targets): A method to set confidence targets and train an additional model that predicts an LLM's confidence based on its textual input and output alone. This approach has several advantages: It is conceptually simple, does not require access to the target model beyond its output, does not interfere with the language generation, and has a multitude of potential usages, for instance by verbalizing the predicted confidence or adjusting the given answer based on the confidence. We show how our approach performs competitively
    
[^113]: 使用循环神经网络在3D点云中对物体进行分类：一种GRU LSTM混合方法

    Classifying Objects in 3D Point Clouds Using Recurrent Neural Network: A GRU LSTM Hybrid Approach

    [https://arxiv.org/abs/2403.05950](https://arxiv.org/abs/2403.05950)

    本文提出了一种使用GRU和LSTM混合方法进行3D点云中物体分类的深度学习策略，取得了高准确率，并在对多个类别的数据集中取得优异表现。

    

    在自主导航和增强/虚拟现实场景等多个应用中，准确对3D点云中的物体进行分类是一个重要问题，已成为研究热点。本文提出了一种用于增强现实中的3D物体分类的深度学习策略。该方法是GRU和LSTM的组合。LSTM网络能够很好地学习长期依赖关系，但由于门数量较多，训练时间较长；另一方面，GRU网络性能较弱于LSTM，但其训练速度远高于LSTM，这是由于其门数量较少。该方法利用了这两种网络的速度和准确性的组合。提出的方法在包含八个类别（未标记、人造地形、自然地形、高植被、低植被、建筑、硬景观）的4,499,0641个点数据集中实现了0.99的准确率。

    arXiv:2403.05950v1 Announce Type: cross  Abstract: Accurate classification of objects in 3D point clouds is a significant problem in several applications, such as autonomous navigation and augmented/virtual reality scenarios, which has become a research hot spot. In this paper, we presented a deep learning strategy for 3D object classification in augmented reality. The proposed approach is a combination of the GRU and LSTM. LSTM networks learn longer dependencies well, but due to the number of gates, it takes longer to train; on the other hand, GRU networks have a weaker performance than LSTM, but their training speed is much higher than GRU, which is The speed is due to its fewer gates. The proposed approach used the combination of speed and accuracy of these two networks. The proposed approach achieved an accuracy of 0.99 in the 4,499,0641 points dataset, which includes eight classes (unlabeled, man-made terrain, natural terrain, high vegetation, low vegetation, buildings, hardscape,
    
[^114]: 学习三维云体积恢复及其在气候分析中的不确定性

    Learned 3D volumetric recovery of clouds and its uncertainty for climate analysis

    [https://arxiv.org/abs/2403.05932](https://arxiv.org/abs/2403.05932)

    该模型设计了一个学习-based 模型（ProbCT），通过嘈杂的多视角航天图像实现了对云的三维CT，首次推断出每个3D位置的后验概率分布，产生了具有价值的统计数据。

    

    气候预测和云物理学中的重要不确定性与关于稀疏散射云的观测空隙相关。为了解决这些挑战，需要远程感测它们的三维（3D）异质体积散射内容。这需要进行被动散射计算断层摄影（CT）。我们设计了一个基于学习的模型（ProbCT），通过嘈杂的多视角航天图像实现这类云的CT。ProbCT首次推断出每个3D位置的异质消光系数的后验概率分布，这产生了任意有价值的统计数据，例如最可能的消光的3D场和其不确定性。ProbCT使用神经场表示，实质上可以进行实时推断。ProbCT通过一个新的带标签的基于物理的多类数据库的监督训练，包括云的体积场和相应的图像，以改善其越界性能。

    arXiv:2403.05932v1 Announce Type: cross  Abstract: Significant uncertainty in climate prediction and cloud physics is tied to observational gaps relating to shallow scattered clouds. Addressing these challenges requires remote sensing of their three-dimensional (3D) heterogeneous volumetric scattering content. This calls for passive scattering computed tomography (CT). We design a learning-based model (ProbCT) to achieve CT of such clouds, based on noisy multi-view spaceborne images. ProbCT infers - for the first time - the posterior probability distribution of the heterogeneous extinction coefficient, per 3D location. This yields arbitrary valuable statistics, e.g., the 3D field of the most probable extinction and its uncertainty. ProbCT uses a neural-field representation, making essentially real-time inference. ProbCT undergoes supervised training by a new labeled multi-class database of physics-based volumetric fields of clouds and their corresponding images. To improve out-of-distr
    
[^115]: OntoChat: 一种使用语言模型进行对话本体工程的框架

    OntoChat: a Framework for Conversational Ontology Engineering using Language Models

    [https://arxiv.org/abs/2403.05921](https://arxiv.org/abs/2403.05921)

    OntoChat是一个支持对话本体工程的框架，通过与对话代理互动，用户可以引导用户故事的创建和能力问题的提取，同时接收计算支持以分析整体需求并进行早期测试。

    

    大型项目中的本体工程(OE)面临着许多挑战，其中的挑战源于各方利益相关者、领域专家及其与本体设计者的复杂互动背景的异质性。这种多方互动经常会在本体需求的引申中产生系统性的歧义和偏见，直接影响设计、评估并可能危及目标的重复使用性。与此同时，目前的OE方法强烈依赖于手工活动（如采访、讨论页面）。在收集了关于最关键OE活动的证据后，我们引入了OntoChat，这是一个支持需求引申、分析和测试的对话本体工程框架。通过与对话代理进行互动，用户可以引导用户故事的创建和能力问题的提取，同时接收计算支持以分析整体需求并进行早期测试。

    arXiv:2403.05921v1 Announce Type: new  Abstract: Ontology engineering (OE) in large projects poses a number of challenges arising from the heterogeneous backgrounds of the various stakeholders, domain experts, and their complex interactions with ontology designers. This multi-party interaction often creates systematic ambiguities and biases from the elicitation of ontology requirements, which directly affect the design, evaluation and may jeopardise the target reuse. Meanwhile, current OE methodologies strongly rely on manual activities (e.g., interviews, discussion pages). After collecting evidence on the most crucial OE activities, we introduce OntoChat, a framework for conversational ontology engineering that supports requirement elicitation, analysis, and testing. By interacting with a conversational agent, users can steer the creation of user stories and the extraction of competency questions, while receiving computational support to analyse the overall requirements and test early
    
[^116]: 基于大语言模型和混合NLP模型的医师笔记高吞吐量表型识别

    High Throughput Phenotyping of Physician Notes with Large Language and Hybrid NLP Models

    [https://arxiv.org/abs/2403.05920](https://arxiv.org/abs/2403.05920)

    大语言模型和混合NLP模型的结合可在高准确率下对医师笔记进行高吞吐量表型识别，有望成为未来首选方法。

    

    深度表型是利用本体论中的概念对患者体征和症状进行详细描述。电子健康记录中大量医师笔记的深度表型需要高吞吐量的方法。在过去的三十年里，取得了使高吞吐量表型成为可能的进展。在这项研究中，我们证明了一个大型语言模型和一个混合NLP模型（结合了词向量和机器学习分类器）可以在高准确率下对医师笔记进行高吞吐量表型识别。大型语言模型很可能会成为医师笔记高吞吐量深度表型识别的首选方法。

    arXiv:2403.05920v1 Announce Type: cross  Abstract: Deep phenotyping is the detailed description of patient signs and symptoms using concepts from an ontology. The deep phenotyping of the numerous physician notes in electronic health records requires high throughput methods. Over the past thirty years, progress toward making high throughput phenotyping feasible. In this study, we demonstrate that a large language model and a hybrid NLP model (combining word vectors with a machine learning classifier) can perform high throughput phenotyping on physician notes with high accuracy. Large language models will likely emerge as the preferred method for high throughput deep phenotyping of physician notes.
    
[^117]: 基于残差网络的扩散建模在不平衡数据上的应用

    SEMRes-DDPM: Residual Network Based Diffusion Modelling Applied to Imbalanced Data

    [https://arxiv.org/abs/2403.05918](https://arxiv.org/abs/2403.05918)

    基于残差网络的扩散建模方法能够有效处理不平衡数据，克服了经典过采样方法和基于生成网络的模式塌陷与训练不稳定问题。

    

    在数据挖掘和机器学习领域，通常使用的分类模型在不平衡数据中无法有效学习。为了平衡模型训练前的数据分布，通常使用过采样方法为少数类生成数据，以解决分类不平衡数据的问题。大多数经典的过采样方法基于SMOTE技术，该技术仅关注数据的局部信息，因此生成的数据可能存在不够逼真的问题。在基于生成网络的当前过采样方法中，基于GAN的方法可以捕获数据的真实分布，但训练中存在模式崩溃和不稳定性的问题；基于去噪扩散概率模型的过采样方法中，使用U-Net的逆扩散过程神经网络不适用于表格数据。

    arXiv:2403.05918v1 Announce Type: cross  Abstract: In the field of data mining and machine learning, commonly used classification models cannot effectively learn in unbalanced data. In order to balance the data distribution before model training,oversamplingmethods are often used to generate data for a small number of classes to solve the problem of classifying unbalanced data. Most of the classical oversampling methods are based on theSMOTE technique, which only focuses on the local information of the data, and therefore the generated data may have the problem of not being realistic enough. In the current oversampling methods based on generative networks, the methods based on GANs can capture the true distribution of data, but there is the problem of pattern collapse and training instability in training; in the oversampling methods based on denoising diffusion probability models, the neural network of the inverse diffusion process using the U-Net is not applicable to tabular data, and
    
[^118]: GPT作为心理学家？GPT-4V在视觉情感计算上的初步评估

    GPT as Psychologist? Preliminary Evaluations for GPT-4V on Visual Affective Computing

    [https://arxiv.org/abs/2403.05916](https://arxiv.org/abs/2403.05916)

    本文评估了GPT4在视觉情感计算中的应用，发现其在面部动作单位识别和微表情检测方面准确性高，但一般面部表情识别性能不佳，同时强调了微表情识别的挑战和进一步研究的潜力。

    

    多模态语言模型（MLMs）旨在处理和整合来自多个来源的信息，例如文本、语音、图像和视频。尽管在语言理解方面取得了成功，但对下游任务的性能进行评估对于更好的以人为中心的应用至关重要。本文评估了MLMs在情感计算中的应用，跨越视觉情感任务和推理任务的5个关键能力。结果显示，GPT4在面部动作单位识别和微表情检测方面具有高准确性，而其一般面部表情识别性能不准确。我们还强调了实现细粒度微表情识别的挑战，以及进一步研究的潜力，并通过与任务相关代理结合展示了GPT4处理情感识别和相关领域高级任务的多功能性和潜力，以处理更复杂的任务。

    arXiv:2403.05916v1 Announce Type: cross  Abstract: Multimodal language models (MLMs) are designed to process and integrate information from multiple sources, such as text, speech, images, and videos. Despite its success in language understanding, it is critical to evaluate the performance of downstream tasks for better human-centric applications. This paper assesses the application of MLMs with 5 crucial abilities for affective computing, spanning from visual affective tasks and reasoning tasks. The results show that GPT4 has high accuracy in facial action unit recognition and micro-expression detection while its general facial expression recognition performance is not accurate. We also highlight the challenges of achieving fine-grained micro-expression recognition and the potential for further study and demonstrate the versatility and potential of GPT4 for handling advanced tasks in emotion recognition and related fields by integrating with task-related agents for more complex tasks, 
    
[^119]: 优化人类中心目标：AI辅助决策中的离线强化学习研究

    Towards Optimizing Human-Centric Objectives in AI-Assisted Decision-Making With Offline Reinforcement Learning

    [https://arxiv.org/abs/2403.05911](https://arxiv.org/abs/2403.05911)

    该研究提出了使用离线强化学习来优化人类中心目标的方法，通过提供适当类型的决策支持，针对特定人员、在适当时间，来优化决策准确性和人类学习能力这两个目标。

    

    随着人工智能辅助渗透到决策过程中，我们可能希望优化人类中心目标，超越决策准确性，如那些与这些系统互动的个体的技能提升或任务享受。考虑到这一愿景，我们提出了离线强化学习（RL）作为建模人机决策以优化这些人类中心目标的一般方法。我们的方法通过灵活地为人类提供决策支持来优化不同的目标--在正确的时间、向正确的人提供正确类型的帮助。我们用两个目标实例化我们的方法：人工智能在决策任务中的准确性和人类对该任务的学习，并从先前的人机交互数据中学习优化这两个目标的策略。我们将优化的策略与在AI辅助决策中的各种基线进行比较。在两个实验中（N = 316 和 N

    arXiv:2403.05911v1 Announce Type: cross  Abstract: As AI assistance is increasingly infused into decision-making processes, we may seek to optimize human-centric objectives beyond decision accuracy, such as skill improvement or task enjoyment of individuals interacting with these systems. With this aspiration in mind, we propose offline reinforcement learning (RL) as a general approach for modeling human-AI decision-making to optimize such human-centric objectives. Our approach seeks to optimize different objectives by adaptively providing decision support to humans -- the right type of assistance, to the right person, at the right time. We instantiate our approach with two objectives: human-AI accuracy on the decision-making task and human learning about the task, and learn policies that optimize these two objectives from previous human-AI interaction data. We compare the optimized policies against various baselines in AI-assisted decision-making. Across two experiments (N = 316 and N
    
[^120]: 数字反转！算术学习中顺序解码很重要

    Reverse That Number! Decoding Order Matters in Arithmetic Learning

    [https://arxiv.org/abs/2403.05845](https://arxiv.org/abs/2403.05845)

    本研究提出了一种新颖的算术学习策略，重点考虑最低有效数字的输出，重新评估数字顺序，并结合逐步方法大幅减少了复杂性，从而取得了比之前方法更好的性能提升。

    

    最近预训练的最新进展表明，现代大型语言模型（LLMs）具有有效学习算术操作的能力。然而，尽管承认数字顺序在算术计算中的重要性，但目前的方法主要依赖于顺序、逐步的方法来教授LLMs算术，导致结论是获得更好的性能涉及到精细的逐步操作。与传统路径不同，我们的工作引入了一种新颖的策略，不仅通过优先考虑从最低有效数字输出来重新评估数字顺序，还结合逐步方法大幅减少了复杂性。我们已经在全面的一系列实验中开发并应用了这种方法。与先前的最先进（SOTA）方法相比，我们的研究结果显示总体准确度的提高，同时仅需要三分之一的复杂度。

    arXiv:2403.05845v1 Announce Type: cross  Abstract: Recent advancements in pretraining have demonstrated that modern Large Language Models (LLMs) possess the capability to effectively learn arithmetic operations. However, despite acknowledging the significance of digit order in arithmetic computation, current methodologies predominantly rely on sequential, step-by-step approaches for teaching LLMs arithmetic, resulting in a conclusion where obtaining better performance involves fine-grained step-by-step. Diverging from this conventional path, our work introduces a novel strategy that not only reevaluates the digit order by prioritizing output from the least significant digit but also incorporates a step-by-step methodology to substantially reduce complexity. We have developed and applied this method in a comprehensive set of experiments. Compared to the previous state-of-the-art (SOTA) method, our findings reveal an overall improvement of in accuracy while requiring only a third of the 
    
[^121]: Hufu：一种通过置换等变性对预训练的Transformer进行水印处理的模态不可知水印系统

    Hufu: A Modality-Agnositc Watermarking System for Pre-Trained Transformers via Permutation Equivariance

    [https://arxiv.org/abs/2403.05842](https://arxiv.org/abs/2403.05842)

    Hufu提出了一种适用于预训练Transformer模型的模态不可知水印系统，利用Transformer的置换等变性质，实现了在模型中嵌入水印并保持高保真度。

    

    随着深度学习模型和服务的蓬勃发展，保护宝贵的模型参数免受盗窃已成为一项迫切关注的问题。水印技术被认为是所有权验证的重要工具。然而，当前的水印方案针对不同的模型和任务定制，难以作为集成的知识产权保护服务。我们提出了Hufu，这是一种针对预训练的基于Transformer的模型的模态不可知水印系统，依赖于Transformer的置换等变性质。Hufu通过微调预训练模型在特定置换的一组数据样本上嵌入水印，嵌入的模型基本上包含两组权重 -- 一组用于正常使用，另一组用于水印提取，触发条件是经过置换的输入。置换等变性确保这两组模型权重之间的最小干扰，从而在水印提取时具有高保真度。

    arXiv:2403.05842v1 Announce Type: cross  Abstract: With the blossom of deep learning models and services, it has become an imperative concern to safeguard the valuable model parameters from being stolen. Watermarking is considered an important tool for ownership verification. However, current watermarking schemes are customized for different models and tasks, hard to be integrated as an integrated intellectual protection service. We propose Hufu, a modality-agnostic watermarking system for pre-trained Transformer-based models, relying on the permutation equivariance property of Transformers. Hufu embeds watermark by fine-tuning the pre-trained model on a set of data samples specifically permuted, and the embedded model essentially contains two sets of weights -- one for normal use and the other for watermark extraction which is triggered on permuted inputs. The permutation equivariance ensures minimal interference between these two sets of model weights and thus high fidelity on downst
    
[^122]: 长期帧事件视觉跟踪：基准数据集与基准线

    Long-term Frame-Event Visual Tracking: Benchmark Dataset and Baseline

    [https://arxiv.org/abs/2403.05839](https://arxiv.org/abs/2403.05839)

    提出了一个新的长期和大规模的帧事件单目标跟踪数据集FELT，重新训练和评估了15个基准跟踪器，并引入了关联记忆Transformer网络来解决RGB帧和事件流不完整的问题。

    

    当前基于事件/帧事件的跟踪器在短期跟踪数据集上进行评估，然而，对于真实场景的跟踪涉及长期跟踪，现有跟踪算法在这些场景中的性能仍不清楚。在本文中，我们首先提出了一个新的长期和大规模的帧事件单目标跟踪数据集，名为FELT。它包含742个视频和1,594,474个RGB帧和事件流对，并已成为迄今为止最大的帧事件跟踪数据集。我们重新训练和评估了15个基准跟踪器在我们的数据集上，以供未来研究进行比较。更重要的是，我们发现RGB帧和事件流由于挑战因素的影响和空间稀疏的事件流而自然不完整。针对这一问题，我们提出了一种新颖的关联记忆Transformer网络作为统一骨干，通过将现代Hopfield层引入多头自注意力块来进行处理。

    arXiv:2403.05839v1 Announce Type: cross  Abstract: Current event-/frame-event based trackers undergo evaluation on short-term tracking datasets, however, the tracking of real-world scenarios involves long-term tracking, and the performance of existing tracking algorithms in these scenarios remains unclear. In this paper, we first propose a new long-term and large-scale frame-event single object tracking dataset, termed FELT. It contains 742 videos and 1,594,474 RGB frames and event stream pairs and has become the largest frame-event tracking dataset to date. We re-train and evaluate 15 baseline trackers on our dataset for future works to compare. More importantly, we find that the RGB frames and event streams are naturally incomplete due to the influence of challenging factors and spatially sparse event flow. In response to this, we propose a novel associative memory Transformer network as a unified backbone by introducing modern Hopfield layers into multi-head self-attention blocks to
    
[^123]: 具有多GPU启用的混合量子-经典工作流的Quantum-HPC框架：在量子模拟中的应用

    Quantum-HPC Framework with multi-GPU-Enabled Hybrid Quantum-Classical Workflow: Applications in Quantum Simulations

    [https://arxiv.org/abs/2403.05828](https://arxiv.org/abs/2403.05828)

    混合量子-经典工作流架构QCQ实现了量子模拟中的创新，通过在QPUs上运行VQE算法和在经典硬件上进行量子态分类，结合了cuQuantum SDK和PennyLane's Lightning plugin，为材料和凝聚态物理领域的计算挑战提供了解决方案。

    

    在量子系统上实现高性能计算面临着巨大挑战，需要弥合量子硬件和经典计算资源之间的能力差距。本研究引入了一种创新的分布感知的Quantum-Classical-Quantum (QCQ)架构，将前沿的量子软件框架与高性能经典计算资源整合在一起，以解决材料和凝聚态物理领域的量子模拟挑战。该架构的核心是在QPUs上运行VQE算法实现高效量子态准备，在经典硬件上进行量子态分类的Tensor Network states和QCNNs的无缝集成。 为了对量子模拟器进行基准测试，QCQ架构利用cuQuantum SDK利用多GPU加速，集成了PennyLane的Lightning插件，展示了计算速度增加多达十倍的能力。

    arXiv:2403.05828v1 Announce Type: cross  Abstract: Achieving high-performance computation on quantum systems presents a formidable challenge that necessitates bridging the capabilities between quantum hardware and classical computing resources. This study introduces an innovative distribution-aware Quantum-Classical-Quantum (QCQ) architecture, which integrates cutting-edge quantum software framework works with high-performance classical computing resources to address challenges in quantum simulation for materials and condensed matter physics. At the heart of this architecture is the seamless integration of VQE algorithms running on QPUs for efficient quantum state preparation, Tensor Network states, and QCNNs for classifying quantum states on classical hardware.   For benchmarking quantum simulators, the QCQ architecture utilizes the cuQuantum SDK to leverage multi-GPU acceleration, integrated with PennyLane's Lightning plugin, demonstrating up to tenfold increases in computational spe
    
[^124]: MP2D:一种利用知识图谱的自动话题转移对话生成框架

    MP2D: An Automated Topic Shift Dialogue Generation Framework Leveraging Knowledge Graphs

    [https://arxiv.org/abs/2403.05814](https://arxiv.org/abs/2403.05814)

    提出了一种利用知识图谱的自动化对话生成框架MP2D，通过映射对话中话题的流动，有效地模拟了人类对话的动态，展示了其在生成具有自然话题转换的对话方面的有效性。

    

    尽管面向特定话题的对话系统取得了进展，但在对话中有效地管理话题转移仍然是一个持续的挑战，这在很大程度上归因于训练数据集的有限可用性。为了解决这个问题，我们提出了Multi-Passage to Dialogue (MP2D)，这是一个数据生成框架，可以自动创建具有自然话题转换的对话问答数据集。通过利用知识图谱中实体之间的关系，MP2D映射对话中话题的流动，有效地模拟人类对话的动态。它检索与话题对应的相关段落，并通过段落到对话的方法将它们转换为对话。通过定量和定性实验，我们展示了MP2D在生成具有自然话题转换的对话方面的有效性。此外，本研究介绍了一个新颖的话题转移对话基准，TS-WikiDialog。利用t

    arXiv:2403.05814v1 Announce Type: cross  Abstract: Despite advancements in on-topic dialogue systems, effectively managing topic shifts within dialogues remains a persistent challenge, largely attributed to the limited availability of training datasets. To address this issue, we propose Multi-Passage to Dialogue (MP2D), a data generation framework that automatically creates conversational question-answering datasets with natural topic transitions. By leveraging the relationships between entities in a knowledge graph, MP2D maps the flow of topics within a dialogue, effectively mirroring the dynamics of human conversation. It retrieves relevant passages corresponding to the topics and transforms them into dialogues through the passage-to-dialogue method. Through quantitative and qualitative experiments, we demonstrate MP2D's efficacy in generating dialogue with natural topic shifts. Furthermore, this study introduces a novel benchmark for topic shift dialogues, TS-WikiDialog. Utilizing t
    
[^125]: 语言模型中算法进展的研究

    Algorithmic progress in language models

    [https://arxiv.org/abs/2403.05812](https://arxiv.org/abs/2403.05812)

    研究发现，语言模型预训练算法每8个月几乎减半一次所需的计算需求，大大快于摩尔定律的硬件增益，尽管算法进展速度快，但计算能力的增加对整体性能改善的贡献更大。

    

    我们调查了自深度学习问世以来，用于预训练语言模型的算法改善速度。使用跨越2012年至2023年的Wikitext和Penn Treebank上的200多个语言模型评估数据集，我们发现达到一定性能阈值所需的计算时间大约每8个月减半，95%的置信区间约为5至14个月，远远快于摩尔定律的硬件增益。我们估计了增强扩展规律，这使我们能够量化算法进展，并确定模型扩展与训练算法创新的相对贡献。尽管算法进展速度快，且出现新的架构如Transformer，但我们的分析显示在这段时间内，计算能力的增加对整体性能改善的贡献更大。尽管受到嘈杂的基准数据的限制，我们的分析表明算法的进展对语言模型的性能的增长有显著影响。

    arXiv:2403.05812v1 Announce Type: cross  Abstract: We investigate the rate at which algorithms for pre-training language models have improved since the advent of deep learning. Using a dataset of over 200 language model evaluations on Wikitext and Penn Treebank spanning 2012-2023, we find that the compute required to reach a set performance threshold has halved approximately every 8 months, with a 95% confidence interval of around 5 to 14 months, substantially faster than hardware gains per Moore's Law. We estimate augmented scaling laws, which enable us to quantify algorithmic progress and determine the relative contributions of scaling models versus innovations in training algorithms. Despite the rapid pace of algorithmic progress and the development of new architectures such as the transformer, our analysis reveals that the increase in compute made an even larger contribution to overall performance improvements over this time period. Though limited by noisy benchmark data, our analy
    
[^126]: 用于广义行人轨迹预测的循环对齐网络

    Recurrent Aligned Network for Generalized Pedestrian Trajectory Prediction

    [https://arxiv.org/abs/2403.05810](https://arxiv.org/abs/2403.05810)

    引入了循环对齐网络（RAN）来最小化领域差异，通过循环对齐策略有效地在时间-状态和时间-序列级别对齐轨迹特征空间，从而实现广义行人轨迹预测。

    

    行人轨迹预测在计算机视觉和机器人领域中是一个关键组成部分，但由于领域转移问题而仍然具有挑战性。以往的研究试图通过利用来自目标领域的部分轨迹数据来调整模型来解决这个问题。然而，在现实世界的场景中，这些领域自适应方法是不切实际的，因为不太可能从所有潜在的目标领域收集轨迹数据。本文研究了一项名为广义行人轨迹预测的任务，旨在将模型推广到看不见的领域，而无需访问它们的轨迹。为了解决这个任务，我们引入了一个循环对齐网络（RAN）来通过领域对齐来最小化领域差异。具体地，我们设计了一个循环对齐模块，通过循环对齐策略有效地在时间-状态和时间-序列级别对齐轨迹特征空间。

    arXiv:2403.05810v1 Announce Type: cross  Abstract: Pedestrian trajectory prediction is a crucial component in computer vision and robotics, but remains challenging due to the domain shift problem. Previous studies have tried to tackle this problem by leveraging a portion of the trajectory data from the target domain to adapt the model. However, such domain adaptation methods are impractical in real-world scenarios, as it is infeasible to collect trajectory data from all potential target domains. In this paper, we study a task named generalized pedestrian trajectory prediction, with the aim of generalizing the model to unseen domains without accessing their trajectories. To tackle this task, we introduce a Recurrent Aligned Network~(RAN) to minimize the domain gap through domain alignment. Specifically, we devise a recurrent alignment module to effectively align the trajectory feature spaces at both time-state and time-sequence levels by the recurrent alignment strategy.Furthermore, we 
    
[^127]: 通过奖励塑造技术增强多跳知识图推理

    Enhancing Multi-Hop Knowledge Graph Reasoning through Reward Shaping Techniques

    [https://arxiv.org/abs/2403.05801](https://arxiv.org/abs/2403.05801)

    通过奖励塑造技术和预训练的BERT嵌入以及提示学习方法，本研究在多跳知识图推理中处理知识图的固有不完整性，提高了精度。

    

    在计算知识表示领域，知识图推理（KG-R）处于促进各个领域之间复杂推理能力的前沿。本研究的要点在于阐明了利用强化学习（RL）策略，特别是REINFORCE算法，来解决多跳KG-R中固有复杂性的方法。通过将统一医学语言系统（UMLS）基准数据集分为丰富和稀疏子集，我们研究了预训练的BERT嵌入和提示学习方法对改进奖励塑造过程的有效性。这种方法不仅提高了多跳KG-R的精度，还...

    arXiv:2403.05801v1 Announce Type: new  Abstract: In the realm of computational knowledge representation, Knowledge Graph Reasoning (KG-R) stands at the forefront of facilitating sophisticated inferential capabilities across multifarious domains. The quintessence of this research elucidates the employment of reinforcement learning (RL) strategies, notably the REINFORCE algorithm, to navigate the intricacies inherent in multi-hop KG-R. This investigation critically addresses the prevalent challenges introduced by the inherent incompleteness of Knowledge Graphs (KGs), which frequently results in erroneous inferential outcomes, manifesting as both false negatives and misleading positives. By partitioning the Unified Medical Language System (UMLS) benchmark dataset into rich and sparse subsets, we investigate the efficacy of pre-trained BERT embeddings and Prompt Learning methodologies to refine the reward shaping process. This approach not only enhances the precision of multi-hop KG-R but 
    
[^128]: 使用同态加密的隐私保护扩散模型

    Privacy-Preserving Diffusion Model Using Homomorphic Encryption

    [https://arxiv.org/abs/2403.05794](https://arxiv.org/abs/2403.05794)

    本文介绍了一种使用同态加密的隐私保护扩散模型HE-Diffusion，通过最小失真方法和稀疏张量表示来提高效率，实现了500倍的加速。

    

    在本文中，我们介绍了一种利用同态加密的隐私保护稳定扩散框架，称为HE-Diffusion，主要关注于保护扩散过程中的去噪阶段。HE-Diffusion是一个量身定制的加密框架，专门设计以与稳定扩散的独特架构相匹配，确保隐私和功能性。为了解决固有的计算挑战，我们提出了一种新颖的最小失真方法，使得部分图像加密更加高效，显著降低了开销而不损害模型的输出质量。此外，我们采用了稀疏张量表示来加速计算操作，提高了隐私保护扩散过程的整体效率。我们成功实现了基于HE的隐私保护稳定扩散推理。实验结果表明，HE-Diffusion相比之下实现了500倍的加速。

    arXiv:2403.05794v1 Announce Type: cross  Abstract: In this paper, we introduce a privacy-preserving stable diffusion framework leveraging homomorphic encryption, called HE-Diffusion, which primarily focuses on protecting the denoising phase of the diffusion process. HE-Diffusion is a tailored encryption framework specifically designed to align with the unique architecture of stable diffusion, ensuring both privacy and functionality. To address the inherent computational challenges, we propose a novel min-distortion method that enables efficient partial image encryption, significantly reducing the overhead without compromising the model's output quality. Furthermore, we adopt a sparse tensor representation to expedite computational operations, enhancing the overall efficiency of the privacy-preserving diffusion process. We successfully implement HE-based privacy-preserving stable diffusion inference. The experimental results show that HE-Diffusion achieves 500 times speedup compared wit
    
[^129]: ItD：大型语言模型可以通过演绎自学归纳

    ItD: Large Language Models Can Teach Themselves Induction through Deduction

    [https://arxiv.org/abs/2403.05789](https://arxiv.org/abs/2403.05789)

    提出了演绎通过归纳（ItD）框架，使大型语言模型能够通过演绎自学归纳，显著提升了归纳任务的性能。

    

    虽然大型语言模型（LLMs）在各种自然语言处理任务上表现出色，研究人员发现它们在进行归纳推理方面的能力仍然有限。最近的作品主要采用“后处理”范式来提高LLMs在归纳方面的表现（如假设搜索和细化方法），但它们的性能仍受限于LLMs的固有归纳能力。本文提出了一个新颖的框架，即演绎通过归纳（ItD），以使LLMs能够通过演绎自学归纳。ItD框架由两个主要组件组成：演绎数据生成模块用于生成归纳数据，以及朴素贝叶斯归纳模块用于优化LLMs的微调和解码。我们的实证结果展示了ItD在两个归纳基准上的有效性，相对性能提升分别为36%和1%。

    arXiv:2403.05789v1 Announce Type: cross  Abstract: Although Large Language Models (LLMs) are showing impressive performance on a wide range of Natural Language Processing tasks, researchers have found that they still have limited ability to conduct induction. Recent works mainly adopt ``post processes'' paradigms to improve the performance of LLMs on induction (e.g., the hypothesis search & refinement methods), but their performance is still constrained by the inherent inductive capability of the LLMs. In this paper, we propose a novel framework, Induction through Deduction (ItD), to enable the LLMs to teach themselves induction through deduction. The ItD framework is composed of two main components: a Deductive Data Generation module to generate induction data and a Naive Bayesian Induction module to optimize the fine-tuning and decoding of LLMs. Our empirical results showcase the effectiveness of ItD on two induction benchmarks, achieving relative performance improvement of 36% and 1
    
[^130]: 对细粒度损失截断效益的研究：以摘要中的事实性为例

    On the Benefits of Fine-Grained Loss Truncation: A Case Study on Factuality in Summarization

    [https://arxiv.org/abs/2403.05788](https://arxiv.org/abs/2403.05788)

    通过细粒度NLL损失和fi以更好地区分事实性，改进了细粒度损失截断对于摘要中事实性的影响。

    

    arXiv:2403.05788v1 公告类型：跨项 摘要：文本摘要和简化是人工智能中最广泛使用的应用之一。然而，针对这些任务开发的模型往往容易出现幻觉，这可能是因为在未对齐数据上进行训练。解决这一问题的一种有效方法是损失截断（LT）（Kang和Hashimoto，2020），这是一种修改标准对数损失以在训练过程中自适应地去除嘈杂示例的方法。然而，我们发现仅使用LT在各种数据集上会产生大量幻觉实体。我们研究了事实和非事实示例之间基础损失的行为，以了解并改进LT的性能。我们证明了当嘈杂目标具有较高NLL损失的基础假设不被满足时，LT的性能是有限的，并发现实体之间的单词级NLL为区分事实性提供了更好的信号。然后我们利用这一点提出了一种细粒度NLL损失和fi

    arXiv:2403.05788v1 Announce Type: cross  Abstract: Text summarization and simplification are among the most widely used applications of AI. However, models developed for such tasks are often prone to hallucination, which can result from training on unaligned data. One efficient approach to address this issue is Loss Truncation (LT) (Kang and Hashimoto, 2020), an approach to modify the standard log loss to adaptively remove noisy examples during training. However, we find that LT alone yields a considerable number of hallucinated entities on various datasets. We study the behavior of the underlying losses between factual and non-factual examples, to understand and refine the performance of LT. We demonstrate that LT's performance is limited when the underlying assumption that noisy targets have higher NLL loss is not satisfied, and find that word-level NLL among entities provides better signal for distinguishing factuality. We then leverage this to propose a fine-grained NLL loss and fi
    
[^131]: 通过扰动感知对比学习实现偏离鲁棒智能体导航

    Towards Deviation-Robust Agent Navigation via Perturbation-Aware Contrastive Learning

    [https://arxiv.org/abs/2403.05770](https://arxiv.org/abs/2403.05770)

    本文提出了一种名为渐进扰动感知对比学习（PROPER）的训练范式来增强现有的智能体对各种干扰的泛化能力，特别是针对偏离鲁棒导航进行了改进。

    

    arXiv:2403.05770v1 发表类型: 跨领域 摘要: 视觉与语言导航（VLN）要求智能体根据给定的语言指令在真实的三维环境中导航。尽管取得了显著进展，传统的VLN智能体通常在无干扰的环境下进行训练，可能会在现实世界中轻易失败，因为它们不知道如何处理各种可能的干扰，例如突然的障碍物或人类中断，这些干扰广泛存在并通常会导致意外的路径偏移。本文提出了一种名为渐进扰动感知对比学习（PROPER）的模型无关训练范式，以增强现有VLN智能体的泛化能力，要求它们朝向具有偏离鲁棒性导航的学习。具体来说，引入了一种简单而有效的路径扰动方案来实现路线偏离，智能体需要继续成功地按照原始指令进行导航。

    arXiv:2403.05770v1 Announce Type: cross  Abstract: Vision-and-language navigation (VLN) asks an agent to follow a given language instruction to navigate through a real 3D environment. Despite significant advances, conventional VLN agents are trained typically under disturbance-free environments and may easily fail in real-world scenarios, since they are unaware of how to deal with various possible disturbances, such as sudden obstacles or human interruptions, which widely exist and may usually cause an unexpected route deviation. In this paper, we present a model-agnostic training paradigm, called Progressive Perturbation-aware Contrastive Learning (PROPER) to enhance the generalization ability of existing VLN agents, by requiring them to learn towards deviation-robust navigation. Specifically, a simple yet effective path perturbation scheme is introduced to implement the route deviation, with which the agent is required to still navigate successfully following the original instruction
    
[^132]: 将激活导向扩展到广泛技能与多种行为

    Extending Activation Steering to Broad Skills and Multiple Behaviours

    [https://arxiv.org/abs/2403.05767](https://arxiv.org/abs/2403.05767)

    本文研究了将激活导向技术应用于广泛技能和多种行为的功效，并发现导向广泛技能具有竞争力，同时在模型中同时注入个体导向向量是一种有前途的方法。

    

    当前大型语言模型具有危险的能力，这很可能在未来变得更加棘手。激活导向技术可用于减少这些能力带来的风险。本文研究了激活导向在广泛技能和多种行为中的功效。通过比较减少对一般编码能力和Python特定能力表现的影响，我们发现导向更广泛技能与导向较窄技能竞争激烈。其次，我们引导模型变得更加或更少近视和寻求财富，以及其他行为。在实验中，将多种不同行为的导向向量组合为一个导向向量通常不成功。另一方面，同时在模型中不同位置注入个体导向向量是有前途的。

    arXiv:2403.05767v1 Announce Type: cross  Abstract: Current large language models have dangerous capabilities, which are likely to become more problematic in the future. Activation steering techniques can be used to reduce risks from these capabilities. In this paper, we investigate the efficacy of activation steering for broad skills and multiple behaviours. First, by comparing the effects of reducing performance on general coding ability and Python-specific ability, we find that steering broader skills is competitive to steering narrower skills. Second, we steer models to become more or less myopic and wealth-seeking, among other behaviours. In our experiments, combining steering vectors for multiple different behaviours into one steering vector is largely unsuccessful. On the other hand, injecting individual steering vectors at different places in a model simultaneously is promising.
    
[^133]: 探讨并行量子退火在同时优化多个问题方面的潜力：一项全面研究

    Investigation into the Potential of Parallel Quantum Annealing for Simultaneous Optimization of Multiple Problems: A Comprehensive Study

    [https://arxiv.org/abs/2403.05764](https://arxiv.org/abs/2403.05764)

    并行量子退火技术旨在通过在单个退火周期中解决多个独立问题来优化可用量子位的利用，相比传统的顺序处理方式，该方法最大程度地减少了闲置量子位，并显示出巨大的加速潜力。

    

    并行量子退火是一种解决多个优化问题的技术。它旨在通过在单个退火周期中处理多个独立问题来优化量子拓扑上可用量子位的利用。本研究深入探讨了这种并行化方法的潜力和局限性。实验包括两个不同问题，并探索了各种问题维度，包括使用特定方法进行标准化技术，如使用具有默认嵌入的DWaveSampler、使用自定义嵌入的DWaveSampler和LeapHybridSampler。这种方法最大程度地减少了闲置量子位，并在解决方案时间（TTS）度量标准方面显示出与传统量子退火相比的巨大加速潜力，传统量子退火解决问题的方法是顺序处理，可能导致未利用的量子位。

    arXiv:2403.05764v1 Announce Type: cross  Abstract: Parallel Quantum Annealing is a technique to solve multiple optimization problems simultaneously. Parallel quantum annealing aims to optimize the utilization of available qubits on a quantum topology by addressing multiple independent problems in a single annealing cycle. This study provides insights into the potential and the limitations of this parallelization method. The experiments consisting of two different problems are integrated, and various problem dimensions are explored including normalization techniques using specific methods such as DWaveSampler with Default Embedding, DWaveSampler with Custom Embedding and LeapHybridSampler. This method minimizes idle qubits and holds promise for substantial speed-up, as indicated by the Time-to-Solution (TTS) metric, compared to traditional quantum annealing, which solves problems sequentially and may leave qubits unutilized.
    
[^134]: HDReason：超维知识图推理的算法-硬件协同设计

    HDReason: Algorithm-Hardware Codesign for Hyperdimensional Knowledge Graph Reasoning

    [https://arxiv.org/abs/2403.05763](https://arxiv.org/abs/2403.05763)

    本文提出了一种基于超维计算的算法-硬件协同设计，用于更高效和加速的知识图推理。

    

    最近，为图学习应用如顶点分类和图分类提出了大量硬件加速器。然而，先前的工作很少关注知识图补全（KGC），这是一项以其显著更高算法复杂性而闻名的任务。基于图卷积神经网络（GCN）的最先进KGC解决方案涉及广泛的顶点/关系嵌入更新和复杂的得分函数，这对加速来说是困难的。因此，现有的加速器设计不再是最佳选择，需要一种新颖的算法-硬件协同设计来进行KG推理。最近，受脑启发的超维计算（HDC）被引入作为轻量级机器学习的有前途的解决方案，特别适用于图学习应用。在本文中，我们利用HDC来实现一个固有更高效且适合加速的

    arXiv:2403.05763v1 Announce Type: cross  Abstract: In recent times, a plethora of hardware accelerators have been put forth for graph learning applications such as vertex classification and graph classification. However, previous works have paid little attention to Knowledge Graph Completion (KGC), a task that is well-known for its significantly higher algorithm complexity. The state-of-the-art KGC solutions based on graph convolution neural network (GCN) involve extensive vertex/relation embedding updates and complicated score functions, which are inherently cumbersome for acceleration. As a result, existing accelerator designs are no longer optimal, and a novel algorithm-hardware co-design for KG reasoning is needed.   Recently, brain-inspired HyperDimensional Computing (HDC) has been introduced as a promising solution for lightweight machine learning, particularly for graph learning applications. In this paper, we leverage HDC for an intrinsically more efficient and acceleration-fri
    
[^135]: 通过独立查询预言者在马尔可夫等价类中进行成员测试

    Membership Testing in Markov Equivalence Classes via Independence Query Oracles

    [https://arxiv.org/abs/2403.05759](https://arxiv.org/abs/2403.05759)

    通过建立在给定的最大无向团大小($s$)方面的下界，我们探讨了通过独立查询预言者在马尔可夫等价类中进行成员测试这一问题。

    

    变量之间因果关系的理解是许多科学领域中具有广泛影响的基本问题。虽然已经投入了大量研究来从数据中学习因果图，但其补充概念——测试因果关系却基本没有被探索。我们通过建立在给定MEC(Markov等价类)的最大无向团的大小($s$)方面的下界，探讨基于约束的测试方法。在最坏情况下，我们展示了$\exp(\Omega(s))$个独立性测试的下界。

    arXiv:2403.05759v1 Announce Type: cross  Abstract: Understanding causal relationships between variables is a fundamental problem with broad impact in numerous scientific fields. While extensive research has been dedicated to learning causal graphs from data, its complementary concept of testing causal relationships has remained largely unexplored. While learning involves the task of recovering the Markov equivalence class (MEC) of the underlying causal graph from observational data, the testing counterpart addresses the following critical question: Given a specific MEC and observational data from some causal graph, can we determine if the data-generating causal graph belongs to the given MEC?   We explore constraint-based testing methods by establishing bounds on the required number of conditional independence tests. Our bounds are in terms of the size of the maximum undirected clique ($s$) of the given MEC. In the worst case, we show a lower bound of $\exp(\Omega(s))$ independence tes
    
[^136]: 在大型知识图上训练面向任务的图神经网络，实现准确高效建模

    Task-Oriented GNNs Training on Large Knowledge Graphs for Accurate and Efficient Modeling

    [https://arxiv.org/abs/2403.05752](https://arxiv.org/abs/2403.05752)

    本文提出了一种自动化TOSG提取的方法KG-TOSA，用于在大型知识图上进行面向任务的图神经网络训练，以减轻对大型KG的过多计算负担。

    

    知识图（KG）是一种包含各种节点和边类型的异构图。异构图神经网络（HGNNs）通常用于在KG上训练节点分类和链接预测等机器学习任务。然而，HGNN方法受KG的大小、密度以及节点和边类型数量的影响，表现出过多的复杂性。AI从业者手工设计出一个与特定任务相关的KG G的子图，我们称之为面向任务的子图（TOSG），其中包含G中与任务相关的节点和边类型的子集。使用TOSG而不是G来训练任务可以减轻对大型KG所需的过多计算。设计TOSG需要深入了解KG的结构和任务的目标，因此具有挑战性且耗时。本文提出了KG-TOSA，一种自动化TOSG提取的方法，用于在大型KG上进行面向任务的HGNN训练。

    arXiv:2403.05752v1 Announce Type: cross  Abstract: A Knowledge Graph (KG) is a heterogeneous graph encompassing a diverse range of node and edge types. Heterogeneous Graph Neural Networks (HGNNs) are popular for training machine learning tasks like node classification and link prediction on KGs. However, HGNN methods exhibit excessive complexity influenced by the KG's size, density, and the number of node and edge types. AI practitioners handcraft a subgraph of a KG G relevant to a specific task. We refer to this subgraph as a task-oriented subgraph (TOSG), which contains a subset of task-related node and edge types in G. Training the task using TOSG instead of G alleviates the excessive computation required for a large KG. Crafting the TOSG demands a deep understanding of the KG's structure and the task's objectives. Hence, it is challenging and time-consuming. This paper proposes KG-TOSA, an approach to automate the TOSG extraction for task-oriented HGNN training on a large KG. In KG
    
[^137]: MG-TSD：具有引导学习过程的多粒度时间序列扩散模型

    MG-TSD: Multi-Granularity Time Series Diffusion Models with Guided Learning Process

    [https://arxiv.org/abs/2403.05751](https://arxiv.org/abs/2403.05751)

    提出了一种新颖的MG-TSD模型，利用数据内在粒度水平作为目标来引导学习过程，实现了状态-of-the-art的预测性能

    

    最近，扩散概率模型由于其生成高保真样本的显著能力而在生成式时间序列预测中引起关注。然而，由于其随机特性带来的不稳定性挑战，如何有效利用它们在概率时间序列预测任务中的强大建模能力仍然是一个悬而未决的问题。为了解决这一挑战，我们引入了一种新颖的多粒度时间序列扩散（MG-TSD）模型，通过利用数据内在的粒度水平作为中间扩散步骤的给定目标来指导扩散模型的学习过程，实现了最先进的预测性能。

    arXiv:2403.05751v1 Announce Type: cross  Abstract: Recently, diffusion probabilistic models have attracted attention in generative time series forecasting due to their remarkable capacity to generate high-fidelity samples. However, the effective utilization of their strong modeling ability in the probabilistic time series forecasting task remains an open question, partially due to the challenge of instability arising from their stochastic nature. To address this challenge, we introduce a novel Multi-Granularity Time Series Diffusion (MG-TSD) model, which achieves state-of-the-art predictive performance by leveraging the inherent granularity levels within the data as given targets at intermediate diffusion steps to guide the learning process of diffusion models. The way to construct the targets is motivated by the observation that the forward process of the diffusion model, which sequentially corrupts the data distribution to a standard normal distribution, intuitively aligns with the p
    
[^138]: 解读AI笔: 检测AI生成文本的技术与挑战

    Decoding the AI Pen: Techniques and Challenges in Detecting AI-Generated Text

    [https://arxiv.org/abs/2403.05750](https://arxiv.org/abs/2403.05750)

    大型语言模型在自然语言生成领域取得了重大突破，提出了识别AI生成文本的解决方案，并探索了未来研究方向。

    

    大型语言模型(LLMs)通过展示生成类人文本的惊人能力，彻底颠覆了自然语言生成(NLG)领域。然而，它们广泛的应用带来挑战，需要深入审查、伦理审查和负责任的实践。本研究探讨了这些挑战，探索了现有的缓解策略，重点是识别AI生成文本作为最终解决方案。此外，我们从理论角度评估了检测的可行性，并提出了解决当前领域限制的新颖研究方向。

    arXiv:2403.05750v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have revolutionized the field of Natural Language Generation (NLG) by demonstrating an impressive ability to generate human-like text. However, their widespread usage introduces challenges that necessitate thoughtful examination, ethical scrutiny, and responsible practices. In this study, we delve into these challenges, explore existing strategies for mitigating them, with a particular emphasis on identifying AI-generated text as the ultimate solution. Additionally, we assess the feasibility of detection from a theoretical perspective and propose novel research directions to address the current limitations in this domain.
    
[^139]: 保守DDPG - 无集成的悲观强化学习

    Conservative DDPG -- Pessimistic RL without Ensemble

    [https://arxiv.org/abs/2403.05732](https://arxiv.org/abs/2403.05732)

    提出了一种新的保守DDPG方法，通过引入$Q$-目标和行为克隆损失惩罚来解决DDPG中的高估偏差问题，可以在不需要集成的情况下轻松实现，并且在各种任务中表现优异。

    

    DDPG受到高估偏差问题的阻碍，其中其$Q$-估计倾向于夸大实际$Q$值。传统解决这一偏见的方法涉及基于集成的方法，需要大量计算资源，或者基于复杂对数策略的方法，难以理解和实施。相比之下，我们提出了一种简单的解决方案，使用$Q$-目标并结合行为克隆（BC）损失惩罚。这种解决方案作为一种不确定性度量，可以很容易地用较少的代码实现，而无需集成。我们的实证结果强烈支持保守DDPG在各种MuJoCo和Bullet任务上优于DDPG。我们始终观察到在所有评估任务中表现更好，甚至在与TD3和TD7相比性能更有竞争力或更优越，所有这些都是以显著降低的计算要求实现的。

    arXiv:2403.05732v1 Announce Type: new  Abstract: DDPG is hindered by the overestimation bias problem, wherein its $Q$-estimates tend to overstate the actual $Q$-values. Traditional solutions to this bias involve ensemble-based methods, which require significant computational resources, or complex log-policy-based approaches, which are difficult to understand and implement. In contrast, we propose a straightforward solution using a $Q$-target and incorporating a behavioral cloning (BC) loss penalty. This solution, acting as an uncertainty measure, can be easily implemented with minimal code and without the need for an ensemble. Our empirical findings strongly support the superiority of Conservative DDPG over DDPG across various MuJoCo and Bullet tasks. We consistently observe better performance in all evaluated tasks and even competitive or superior performance compared to TD3 and TD7, all achieved with significantly reduced computational requirements.
    
[^140]: 用于生成简要住院病程摘要的领域自适应大语言模型的基准测试

    A Benchmark of Domain-Adapted Large Language Models for Generating Brief Hospital Course Summaries

    [https://arxiv.org/abs/2403.05720](https://arxiv.org/abs/2403.05720)

    介绍了一个新的基准测试，评估了用于生成简要住院病程摘要的大语言模型在健康保健领域中的性能并提出相应的自适应策略

    

    简要住院病程（BHC）摘要是通过总结临床记录而生成的常见临床文件。虽然大型语言模型（LLMs）在自动化实际任务方面展现出显著能力，但它们在医疗应用（如BHC合成）中的能力尚未得到展示。为了使LLMs能够适应BHC合成，我们引入了一个新颖的基准测试，其中包含从MIMIC-IV记录中提取的经过预处理的数据集，封装了临床记录和简要住院病程（BHC）对。我们评估了两个通用LLMs和三个医疗领域适应的LLMs的性能，以改进从临床记录生成BHC。我们使用临床记录作为输入来生成BHC，采用基于提示的（使用上下文学习）和基于微调的自适应策略来应用于三个开源LLMs（Clinical-T5-Large，Llama2-13B，FLAN-UL2）和两个专有LLMs（GPT-3.5，GPT-4）。我们定量评估了性能。

    arXiv:2403.05720v1 Announce Type: cross  Abstract: Brief hospital course (BHC) summaries are common clinical documents generated by summarizing clinical notes. While large language models (LLMs) depict remarkable capabilities in automating real-world tasks, their capabilities for healthcare applications such as BHC synthesis have not been shown. To enable the adaptation of LLMs for BHC synthesis, we introduce a novel benchmark consisting of a pre-processed dataset extracted from MIMIC-IV notes, encapsulating clinical note, and brief hospital course (BHC) pairs. We assess the performance of two general-purpose LLMs and three healthcare-adapted LLMs to improve BHC synthesis from clinical notes. Using clinical notes as input for generating BHCs, we apply prompting-based (using in-context learning) and fine-tuning-based adaptation strategies to three open-source LLMs (Clinical-T5-Large, Llama2-13B, FLAN-UL2) and two proprietary LLMs (GPT-3.5, GPT-4). We quantitatively evaluate the performa
    
[^141]: 一个用于在网络物理人系统中进行有效人工智能推荐的框架

    A Framework for Effective AI Recommendations in Cyber-Physical-Human Systems

    [https://arxiv.org/abs/2403.05715](https://arxiv.org/abs/2403.05715)

    该论文提出了一个框架来解决网络物理人系统中人工智能推荐和人类决策者之间的挑战，通过考虑人类可能不同于AI平台的感知和解释方式，建立了最佳推荐策略的结构特性，并开发了近似人类模型，从而提供了理论上的最优性界限和数值示例验证结果。

    

    许多网络物理人系统（CPHS）涉及到一个人类决策者，他可能会从人工智能（AI）平台接收推荐，同时又持有最终决策的责任。在这类CPHS应用中，人类决策者可能会因为各种原因而偏离最佳推荐决策，而不是实施另一个。在这封信中，我们开发了一个严格的框架来克服这一挑战。在我们的框架中，我们考虑到人类可能会因为感知和解释系统状态的方式与AI平台不同而偏离AI的推荐。我们建立了最佳推荐策略的结构特性，并开发了AI使用的近似人类模型（AHM）。我们为由AHM产生的最优性差距提供了理论界限，并在一个数值示例中说明了我们结果的功效。

    arXiv:2403.05715v1 Announce Type: cross  Abstract: Many cyber-physical-human systems (CPHS) involve a human decision-maker who may receive recommendations from an artificial intelligence (AI) platform while holding the ultimate responsibility of making decisions. In such CPHS applications, the human decision-maker may depart from an optimal recommended decision and instead implement a different one for various reasons. In this letter, we develop a rigorous framework to overcome this challenge. In our framework, we consider that humans may deviate from AI recommendations as they perceive and interpret the system's state in a different way than the AI platform. We establish the structural properties of optimal recommendation strategies and develop an approximate human model (AHM) used by the AI. We provide theoretical bounds on the optimality gap that arises from an AHM and illustrate the efficacy of our results in a numerical example.
    
[^142]: 大型语言模型是否与人们的社交直觉相一致，用于人机互动？

    Are Large Language Models Aligned with People's Social Intuitions for Human-Robot Interactions?

    [https://arxiv.org/abs/2403.05701](https://arxiv.org/abs/2403.05701)

    该研究测试大型语言模型在人机互动中是否能够捕捉到人们的行为判断和沟通偏好，结果表明GPT-4在生成社会可接受行为方面表现出色。

    

    大型语言模型（LLMs）越来越多地用于机器人技术，特别是高层次的行动规划。与此同时，许多机器人应用涉及人类监督员或合作者。因此，对LLMs生成与人们偏好和价值观相一致的社会可接受行动至关重要。在这项工作中，我们测试LLMs是否捕捉到人们在人机互动（HRI）场景中行为判断和沟通偏好方面的直觉。为了评估，我们重现了三个HRI用户研究，将LLMs的输出与真实参与者的输出进行比较。我们发现GPT-4在非常出色地表现，生成的答案与两项研究的用户答案具有很强相关性——第一项研究涉及在各种情境中选择最合适的沟通举动给机器人（$r_s$ = 0.82），第二项涉及判断行为的可取性、意图性和令人惊讶性。

    arXiv:2403.05701v1 Announce Type: cross  Abstract: Large language models (LLMs) are increasingly used in robotics, especially for high-level action planning. Meanwhile, many robotics applications involve human supervisors or collaborators. Hence, it is crucial for LLMs to generate socially acceptable actions that align with people's preferences and values. In this work, we test whether LLMs capture people's intuitions about behavior judgments and communication preferences in human-robot interaction (HRI) scenarios. For evaluation, we reproduce three HRI user studies, comparing the output of LLMs with that of real participants. We find that GPT-4 strongly outperforms other models, generating answers that correlate strongly with users' answers in two studies $\unicode{x2014}$ the first study dealing with selecting the most appropriate communicative act for a robot in various situations ($r_s$ = 0.82), and the second with judging the desirability, intentionality, and surprisingness of beh
    
[^143]: 使用基于分解的决策焦点学习进行高效的公共卫生干预规划

    Efficient Public Health Intervention Planning Using Decomposition-Based Decision-Focused Learning

    [https://arxiv.org/abs/2403.05683](https://arxiv.org/abs/2403.05683)

    决策焦点学习（DFL）在公共卫生干预中的应用提高了干预的精准度，虽然存在高计算成本，但能优化有限的干预资源使用效果。

    

    公共卫生计划中受益者参与度下降是一个重要问题，为了改善保留率，健康工作者会对有辍学风险的受益者进行干预，然而，健康工作者的可用性和时间是有限资源。因此，有研究致力于使用不安定多臂赌博机来优化这些有限的干预资源。然而，在实践中使用这一框架的关键技术障碍在于需要从历史数据中估算受益者的多臂赌博机参数。

    arXiv:2403.05683v1 Announce Type: new  Abstract: The declining participation of beneficiaries over time is a key concern in public health programs. A popular strategy for improving retention is to have health workers `intervene' on beneficiaries at risk of dropping out. However, the availability and time of these health workers are limited resources. As a result, there has been a line of research on optimizing these limited intervention resources using Restless Multi-Armed Bandits (RMABs). The key technical barrier to using this framework in practice lies in the need to estimate the beneficiaries' RMAB parameters from historical data. Recent research has shown that Decision-Focused Learning (DFL), which focuses on maximizing the beneficiaries' adherence rather than predictive accuracy, improves the performance of intervention targeting using RMABs. Unfortunately, these gains come at a high computational cost because of the need to solve and evaluate the RMAB in each DFL training step. 
    
[^144]: 使用不同ially Private Tabular Data进行环境中学习的DP-TabICL

    DP-TabICL: In-Context Learning with Differentially Private Tabular Data

    [https://arxiv.org/abs/2403.05681](https://arxiv.org/abs/2403.05681)

    研究了如何使用差分隐私来保护在环境中学习中使用的表格数据。

    

    In-context learning (ICL)使得大型语言模型（LLM）通过在问题-答案对的示范条件下适应新任务，并且它已经表现出与昂贵的模型重新训练和微调相媲美的性能。最近，ICL已被扩展，允许使用表格数据作为示范示例，方法是将单个记录串行化为自然语言格式。然而，已经表明LLM可能会泄露提示中包含的信息，而且由于表格数据通常包含敏感信息，因此了解如何保护ICL中使用的基础表格数据是一个重要的研究领域。本文作为对如何使用差分隐私（DP）进行初始探索的研究--差分隐私是数据隐私和匿名化的长期金标准--以保护ICL中使用的表格数据。具体而言，我们研究了通过数据私有化机制在私有表格ICL中应用DP机制。

    arXiv:2403.05681v1 Announce Type: cross  Abstract: In-context learning (ICL) enables large language models (LLMs) to adapt to new tasks by conditioning on demonstrations of question-answer pairs and it has been shown to have comparable performance to costly model retraining and fine-tuning. Recently, ICL has been extended to allow tabular data to be used as demonstration examples by serializing individual records into natural language formats. However, it has been shown that LLMs can leak information contained in prompts, and since tabular data often contain sensitive information, understanding how to protect the underlying tabular data used in ICL is a critical area of research. This work serves as an initial investigation into how to use differential privacy (DP) -- the long-established gold standard for data privacy and anonymization -- to protect tabular data used in ICL. Specifically, we investigate the application of DP mechanisms for private tabular ICL via data privatization pr
    
[^145]: 使用GPT-4对基于视觉的LLM预测进行分解以进行自动评估

    Decomposing Vision-based LLM Predictions for Auto-Evaluation with GPT-4

    [https://arxiv.org/abs/2403.05680](https://arxiv.org/abs/2403.05680)

    提出了一种新颖的评估框架，用于评估视觉-语言LLMs在生成CT异常的准确摘要方面的能力。

    

    CT检查的数量每年都在增加，这导致放射科医生疲劳。大型语言模型（LLMs）有潜力减轻他们的负担，但其在临床中的采用取决于放射科医生的信任和生成内容的简单评估。本文提出了一个新颖的评估框架，用于评估视觉-语言LLMs在生成CT异常的准确摘要方面的能力。

    arXiv:2403.05680v1 Announce Type: new  Abstract: The volume of CT exams being done in the world has been rising every year, which has led to radiologist burn-out. Large Language Models (LLMs) have the potential to reduce their burden, but their adoption in the clinic depends on radiologist trust, and easy evaluation of generated content. Presently, many automated methods are available to evaluate the reports generated for chest radiographs, but such an approach is not available for CT presently. In this paper, we propose a novel evaluation framework to judge the capabilities of vision-language LLMs in generating accurate summaries of CT-based abnormalities. CT slices containing an abnormality (e.g., lesion) were input to a vision-based LLM (GPT-4V, LLaVA-Med, and RadFM), and it generated a free-text summary of the predicted characteristics of the abnormality. Next, a GPT-4 model decomposed the summary into specific aspects (body part, location, type, and attributes), automatically eval
    
[^146]: Feature CAM: 图像分类中的可解释AI

    Feature CAM: Interpretable AI in Image Classification

    [https://arxiv.org/abs/2403.05658](https://arxiv.org/abs/2403.05658)

    本研究比较了激活方法在CNN模型图像分类预测解释中的应用，提出了一种新颖的Feature CAM技术，用于提高模型的可解释性。

    

    深度神经网络常被称为黑盒子，因为其复杂的深层结构和内部层的不透明性。人们在将人工智能应用于安全、金融、健康和制造业等关键和高精度领域时常常缺乏信任。我们研究了激活方法（ABM）的最新方法，用于解释CNN模型对图像分类应用的预测。我们扩展了同样的方法，比较了八种基于CNN的体系结构的差异，从而提高了可解释性。我们引入了一种新颖的特征CAM技术，它属于扰动激活组合，用于创建细粒度的、具有类别区分性的可视化。

    arXiv:2403.05658v1 Announce Type: cross  Abstract: Deep Neural Networks have often been called the black box because of the complex, deep architecture and non-transparency presented by the inner layers. There is a lack of trust to use Artificial Intelligence in critical and high-precision fields such as security, finance, health, and manufacturing industries. A lot of focused work has been done to provide interpretable models, intending to deliver meaningful insights into the thoughts and behavior of neural networks. In our research, we compare the state-of-the-art methods in the Activation-based methods (ABM) for interpreting predictions of CNN models, specifically in the application of Image Classification. We then extend the same for eight CNN-based architectures to compare the differences in visualization and thus interpretability. We introduced a novel technique Feature CAM, which falls in the perturbation-activation combination, to create fine-grained, class-discriminative visual
    
[^147]: 这里是翻译过的论文标题

    What is different between these datasets?

    [https://arxiv.org/abs/2403.05652](https://arxiv.org/abs/2403.05652)

    这里是中文总结出的一句话要点

    

    这里是翻译过的论文摘要

    arXiv:2403.05652v1 Announce Type: cross  Abstract: The performance of machine learning models heavily depends on the quality of input data, yet real-world applications often encounter various data-related challenges. One such challenge could arise when curating training data or deploying the model in the real world - two comparable datasets in the same domain may have different distributions. While numerous techniques exist for detecting distribution shifts, the literature lacks comprehensive approaches for explaining dataset differences in a human-understandable manner. To address this gap, we propose a suite of interpretable methods (toolbox) for comparing two datasets. We demonstrate the versatility of our approach across diverse data modalities, including tabular data, language, images, and signals in both low and high-dimensional settings. Our methods not only outperform comparable and related approaches in terms of explanation quality and correctness, but also provide actionable,
    
[^148]: 基于相空间的几何神经网络用于BCI解码

    Geometric Neural Network based on Phase Space for BCI decoding

    [https://arxiv.org/abs/2403.05645](https://arxiv.org/abs/2403.05645)

    基于相空间的几何神经网络用于BCI解码，提供了在脑机接口领域中可靠算法操作的方法，以提高用户舒适度并促进其广泛应用。

    

    Deep Learning(DL)算法与脑信号分析的整合仍处于萌芽阶段，相比计算机视觉等领域的成功，在脑机接口(BCI)领域尤为突出，BCI通过解码大脑活动控制外部设备而无需肌肉控制。脑电图(EEG)是设计BCI系统的广泛选择，因其无创性、成本效益和出色的时间分辨率，但缺少训练数据、信噪比低、以及在个体间和内部的大量变化。 最后，使用多个电极设置BCI系统需要很长时间，阻碍可靠DL架构在研究实验室之外的BCI中的广泛应用。 为了提高采纳率，我们需要改善用户舒适度，例如使用少量电极操作的可靠算法。

    arXiv:2403.05645v1 Announce Type: cross  Abstract: The integration of Deep Learning (DL) algorithms on brain signal analysis is still in its nascent stages compared to their success in fields like Computer Vision, especially in Brain-Computer Interface (BCI), where the brain activity is decoded to control external devices without requiring muscle control. Electroencephalography (EEG) is a widely adopted choice for designing BCI systems due to its non-invasive and cost-effective nature and excellent temporal resolution. Still, it comes at the expense of limited training data, poor signal-to-noise, and a large variability across and within-subject recordings. Finally, setting up a BCI system with many electrodes takes a long time, hindering the widespread adoption of reliable DL architectures in BCIs outside research laboratories. To improve adoption, we need to improve user comfort using, for instance, reliable algorithms that operate with few electrodes. \textbf{Approach:} Our research
    
[^149]: 一个基于特征的通用预测模型，适用于感知和抽象推理

    A Feature-based Generalizable Prediction Model for Both Perceptual and Abstract Reasoning

    [https://arxiv.org/abs/2403.05641](https://arxiv.org/abs/2403.05641)

    本论文提出了一种基于特征的通用预测模型，旨在克服当前神经网络在识别和推断任务规则方面的局限性，并探索人类在符号和连续感知表示之间灵活切换的能力。

    

    人类智慧的一个特点是能够从有限的经验中推断出抽象规则，并将这些规则应用于陌生情境。最近深度学习方面取得的多项进展带来了多个人工神经网络模型能够达到甚至超越人类表现。然而，尽管人类能够在很少或没有接触的情况下识别和表达这些任务背后的规则，当代神经网络往往依赖于大规模基于模式的训练，无法表达或推断出任务中的规则。此外，用于神经网络训练的大部分Raven's Progressive Matrices或类似任务使用了符号表示，而人类可以在符号和连续感知表示之间灵活切换。在本研究中，我们提出了一种基于特征检测的算法方法来检测和应用规则。

    arXiv:2403.05641v1 Announce Type: new  Abstract: A hallmark of human intelligence is the ability to infer abstract rules from limited experience and apply these rules to unfamiliar situations. This capacity is widely studied in the visual domain using the Raven's Progressive Matrices. Recent advances in deep learning have led to multiple artificial neural network models matching or even surpassing human performance. However, while humans can identify and express the rule underlying these tasks with little to no exposure, contemporary neural networks often rely on massive pattern-based training and cannot express or extrapolate the rule inferred from the task. Furthermore, most Raven's Progressive Matrices or Raven-like tasks used for neural network training used symbolic representations, whereas humans can flexibly switch between symbolic and continuous perceptual representations. In this work, we present an algorithmic approach to rule detection and application using feature detection
    
[^150]: 无需调参的LLM部署负责干预--一种元认知方法

    Tuning-Free Accountable Intervention for LLM Deployment -- A Metacognitive Approach

    [https://arxiv.org/abs/2403.05636](https://arxiv.org/abs/2403.05636)

    提出了一种创新的元认知方法，名为CLEAR，旨在为LLMs提供自我意识的错误识别和纠正能力

    

    大型语言模型（LLMs）通过少量或零-shot提示在一系列自然语言处理任务中催生了变革性进展，绕过了参数调整的必要性。然而，这种便利的操作方式加剧了“幻觉”问题，特别是考虑到它们庞大模型规模背后的神秘“黑匣子”性质。这些担忧在高风险应用（如医疗保健）中变得更加严重，因为不负责任的决策错误可能导致灾难性后果。相比之下，人类决策依赖于微妙的认知过程，如通过概念理解感知和自适应地纠正错误判断的能力。受人类认知的启发，我们提出了一种创新的元认知方法，称为CLEAR，为LLMs提供自我意识的错误识别和纠正能力。我们的框架有助于构建co

    arXiv:2403.05636v1 Announce Type: new  Abstract: Large Language Models (LLMs) have catalyzed transformative advances across a spectrum of natural language processing tasks through few-shot or zero-shot prompting, bypassing the need for parameter tuning. While convenient, this modus operandi aggravates ``hallucination'' concerns, particularly given the enigmatic ``black-box'' nature behind their gigantic model sizes. Such concerns are exacerbated in high-stakes applications (e.g., healthcare), where unaccountable decision errors can lead to devastating consequences. In contrast, human decision-making relies on nuanced cognitive processes, such as the ability to sense and adaptively correct misjudgments through conceptual understanding. Drawing inspiration from human cognition, we propose an innovative \textit{metacognitive} approach, dubbed \textbf{CLEAR}, to equip LLMs with capabilities for self-aware error identification and correction. Our framework facilitates the construction of co
    
[^151]: 大型语言模型能玩游戏吗？一种自我博弈方法的案例研究

    Can Large Language Models Play Games? A Case Study of A Self-Play Approach

    [https://arxiv.org/abs/2403.05632](https://arxiv.org/abs/2403.05632)

    该研究引入了一种创新方法，将蒙特卡罗树搜索（MCTS）的自我博弈与大型语言模型（LLMs）相结合，有效解决了确定性轮流零和游戏（DTZG），如国际象棋和围棋，而无需额外的训练。

    

    大型语言模型（LLMs）利用来自互联网的大量数据，存储广泛的先验知识。虽然LLMs已被证明有助于决策辅助，但它们的可靠性受到推理能力的限制、幻觉现象等问题的影响。另一方面，蒙特卡罗树搜索（MCTS）是一种启发式搜索算法，通过递归展开和自我博弈提供可靠的决策解决方案。然而，在复杂的决策场景中，MCTS的有效性在很大程度上依赖于启发式修剪和外部值函数。这项工作引入了一种创新方法，通过将MCTS自我博弈与LLMs相结合，有效解决确定性轮流零和游戏（DTZG），如国际象棋和围棋，而无需额外的训练。具体而言，我们利用LLMs作为行动剪枝器和值函数的代理，而无需额外的训练。

    arXiv:2403.05632v1 Announce Type: new  Abstract: Large Language Models (LLMs) harness extensive data from the Internet, storing a broad spectrum of prior knowledge. While LLMs have proven beneficial as decision-making aids, their reliability is hampered by limitations in reasoning, hallucination phenomenon, and so on. On the other hand, Monte-Carlo Tree Search (MCTS) is a heuristic search algorithm that provides reliable decision-making solutions, achieved through recursive rollouts and self-play. However, the effectiveness of MCTS relies heavily on heuristic pruning and external value functions, particularly in complex decision scenarios. This work introduces an innovative approach that bolsters LLMs with MCTS self-play to efficiently resolve deterministic turn-based zero-sum games (DTZG), such as chess and go, without the need for additional training. Specifically, we utilize LLMs as both action pruners and proxies for value functions without the need for additional training. We theo
    
[^152]: 不熟悉的微调示例控制语言模型如何产生幻觉

    Unfamiliar Finetuning Examples Control How Language Models Hallucinate

    [https://arxiv.org/abs/2403.05612](https://arxiv.org/abs/2403.05612)

    本文研究了大型语言模型如何产生幻觉，并提出通过调整微调示例的监督来控制其对不熟悉输入的预测。作者开发了一种基于RL的方法，更可靠地减轻了长篇生成任务中的幻觉。

    

    大型语言模型（LLMs）倾向于生成听起来令人信服但事实不正确的响应，特别是当在不熟悉的概念上进行查询时。本文探讨了调整后的LLMs如何产生幻觉的基本机制。我们的调查揭示了一个有趣的模式：随着输入变得更不熟悉，LLMs的输出倾向于默认为"含糊其词"的预测，其形式受微调数据中不熟悉示例监督方式的影响。因此，通过策略性地修改这些示例的监督，我们可以控制LLM对不熟悉输入的预测（例如，教会它们说“我不知道”）。基于这些原则，我们开发了一种RL方法，通过解决奖励模型幻觉带来的挑战，更可靠地减轻长篇生成任务的幻觉。我们通过在MMLU上的多选QA中进行一系列受控实验来验证我们的发现。

    arXiv:2403.05612v1 Announce Type: cross  Abstract: Large language models (LLMs) have a tendency to generate plausible-sounding yet factually incorrect responses, especially when queried on unfamiliar concepts. In this work, we explore the underlying mechanisms that govern how finetuned LLMs hallucinate. Our investigation reveals an interesting pattern: as inputs become more unfamiliar, LLM outputs tend to default towards a ``hedged'' prediction, whose form is determined by how the unfamiliar examples in the finetuning data are supervised. Thus, by strategically modifying these examples' supervision, we can control LLM predictions for unfamiliar inputs (e.g., teach them to say ``I don't know''). Based on these principles, we develop an RL approach that more reliably mitigates hallucinations for long-form generation tasks, by tackling the challenges presented by reward model hallucinations. We validate our findings with a series of controlled experiments in multiple-choice QA on MMLU, as
    
[^153]: 基于概念的可解释模型用于利用多模态数据诊断脉络膜肿瘤

    A Concept-based Interpretable Model for the Diagnosis of Choroid Neoplasias using Multimodal Data

    [https://arxiv.org/abs/2403.05606](https://arxiv.org/abs/2403.05606)

    提出了一种基于概念的可解释模型，用于利用多模态数据诊断脉络膜肿瘤，促进了对罕见疾病的诊断，并在临床实践和医学教育中具有重要意义

    

    诊断罕见疾病在临床实践中面临着共同挑战，需要专家的专业知识才能准确识别。机器学习的出现提供了一种有希望的解决方案，然而这类技术的发展受到罕见状况的数据稀缺和在临床环境中需要具有可解释性和可信赖性的模型的需求的阻碍。可解释的人工智能，具有人类可读输出的能力，可以促进临床医生的验证并促进医学教育。在当前工作中，我们专注于脉络膜肿瘤，这是成人中最常见的眼睛癌症形式，尽管罕见，罹患率为每百万人5.1例。我们建立了迄今为止最大的数据集，共包括750名患者，涵盖了从2004年至2022年收集的三种不同成像模态。我们的工作引入了一个基于概念的可解释模型，可区分三种类型的脉络膜肿瘤，融合了一些不太重要的

    arXiv:2403.05606v1 Announce Type: cross  Abstract: Diagnosing rare diseases presents a common challenge in clinical practice, necessitating the expertise of specialists for accurate identification. The advent of machine learning offers a promising solution, while the development of such technologies is hindered by the scarcity of data on rare conditions and the demand for models that are both interpretable and trustworthy in a clinical context. Interpretable AI, with its capacity for human-readable outputs, can facilitate validation by clinicians and contribute to medical education. In the current work, we focus on choroid neoplasias, the most prevalent form of eye cancer in adults, albeit rare with 5.1 per million. We built the so-far largest dataset consisting of 750 patients, incorporating three distinct imaging modalities collected from 2004 to 2022. Our work introduces a concept-based interpretable model that distinguishes between three types of choroidal tumors, integrating insig
    
[^154]: 引入第一原理计算：一种新的方法用于群体动态和在TeNP-链社会动态模拟中架设社会现象之间的联系

    Introducing First-Principles Calculations: New Approach to Group Dynamics and Bridging Social Phenomena in TeNP-Chain Based Social Dynamics Simulations

    [https://arxiv.org/abs/2403.05593](https://arxiv.org/abs/2403.05593)

    本文介绍了一种利用第一原理计算的新方法，用于桥接量子力学原理与社会系统复杂动力学之间的联系，基于碲纳米颗粒和石墨烯结构特征与社会群体行为模式的隐喻对应。

    

    本文考虑了一种创新的跨学科方法论，它架起了量子力学基本原理与材料研究（如碲纳米颗粒和石墨烯）以及社会系统复杂动力学之间的鸿沟。这种方法的基础在于碲纳米颗粒和石墨烯的结构特征与社会群体行为模式之间的隐喻对应。碲纳米颗粒具有独特的属性，如提高碲链中共价键的强化和引发次生结构破坏导致这些链的分离。这类似于社会群体内部凝聚力加强和不同分组之间信息流动的干扰。同样，石墨烯的出色特性，如高电导性、强度和柔韧性，为理解社会群体动力学提供了更多层面。

    arXiv:2403.05593v1 Announce Type: cross  Abstract: This note considers an innovative interdisciplinary methodology that bridges the gap between the fundamental principles of quantum mechanics applied to the study of materials such as tellurium nanoparticles (TeNPs) and graphene and the complex dynamics of social systems. The basis for this approach lies in the metaphorical parallels drawn between the structural features of TeNPs and graphene and the behavioral patterns of social groups in the face of misinformation. TeNPs exhibit unique properties such as the strengthening of covalent bonds within telluric chains and the disruption of secondary structure leading to the separation of these chains. This is analogous to increased cohesion within social groups and disruption of information flow between different subgroups, respectively. . Similarly, the outstanding properties of graphene, such as high electrical conductivity, strength, and flexibility, provide additional aspects for unders
    
[^155]: 机械头脑的永恒阳光：机器学习与被遗忘权的不可调和性

    Eternal Sunshine of the Mechanical Mind: The Irreconcilability of Machine Learning and the Right to be Forgotten

    [https://arxiv.org/abs/2403.05592](https://arxiv.org/abs/2403.05592)

    人工智能的发展带来了深度学习系统的出现，但在处理这些人工大脑时，如何保护被遗忘的权利仍然是一个挑战。

    

    随着我们迅速迈向人工智能成为大多数人不断发生和规范化的时代，我们也必须意识到这一愿景和这一进步蕴含着什么。通过首先近似计算机电路中的神经连接和活动，然后创建越来越复杂版本的这种粗糙近似，我们现在正面临一个未来时代，现代基于深度学习的人工智能系统可以被称为思考机器，有时甚至因其新生行为和黑盒方法而受到称赞。但随着我们创造更强大的电子大脑，具有数十亿的神经连接和参数，我们能确保这些由人工神经构建的庞然大物能够遗忘我们在其中存储的数据吗？如果它们在某种程度上像大脑，那么在应对这些人工智能时，被遗忘的权利仍能得到保护吗？

    arXiv:2403.05592v1 Announce Type: cross  Abstract: As we keep rapidly advancing toward an era where artificial intelligence is a constant and normative experience for most of us, we must also be aware of what this vision and this progress entail. By first approximating neural connections and activities in computer circuits and then creating more and more sophisticated versions of this crude approximation, we are now facing an age to come where modern deep learning-based artificial intelligence systems can rightly be called thinking machines, and they are sometimes even lauded for their emergent behavior and black-box approaches. But as we create more powerful electronic brains, with billions of neural connections and parameters, can we guarantee that these mammoths built of artificial neurons will be able to forget the data that we store in them? If they are at some level like a brain, can the right to be forgotten still be protected while dealing with these AIs? The essential gap betw
    
[^156]: 优化大学计算机实验室人体工程学：一个关于人体测量、家具设计和ANOVA测试的研究

    Optimizing Computer Lab Ergonomics in Universities: A Study on Anthropometric Measurements, Furniture Design, and ANOVA Test

    [https://arxiv.org/abs/2403.05589](https://arxiv.org/abs/2403.05589)

    提出基于人体测量的家具尺寸适合大学生，以改善计算机实验室人体工程学，研究发现其与现有家具尺寸存在显著差异并更加兼容

    

    许多研究表明，人体工程学设计的家具能提高工作效率和身心健康。随着计算机成为学生学术生活的一部分，它们在未来将进一步普及。我们提出基于人体测量的家具尺寸，适合大学生以改善计算机实验室的人体工程学。我们收集了380名参与者的数据，分析了11项人体测量，并将它们与11项家具尺寸进行了相关性分析。研究了两种类型的家具：非可调椅子与非可调桌子，以及可调椅子与非可调桌子。不匹配计算显示家具尺寸与人体测量之间存在显著差异。显著水平为5%的单因素方差分析测试还显示了所提出的和现有的家具尺寸之间存在显著差异。发现所提出的尺寸更加兼容，减少了不匹配百分比。

    arXiv:2403.05589v1 Announce Type: cross  Abstract: Many studies have shown how ergonomically designed furniture improves productivity and well-being. As computers have become a part of students' academic lives, they will grow further in the future. We propose anthropometric-based furniture dimensions suitable for university students to improve computer laboratory ergonomics. We collected data from 380 participants and analyzed 11 anthropometric measurements, correlating them to 11 furniture dimensions. Two types of furniture were studied: a non-adjustable chair with a non-adjustable table and an adjustable chair with a non-adjustable table. The mismatch calculation showed a significant difference between furniture dimensions and anthropometric measurements. The one-way ANOVA test with a significance level of 5% also showed a significant difference between proposed and existing furniture dimensions. The proposed dimensions were found to be more compatible and reduced mismatch percentage
    
[^157]: 悬浮复共振模型：使用孤子解研究第三方干预下非完全信息博弈中的假新闻扩散模型

    Plasmon Resonance Model: Investigation of Analysis of Fake News Diffusion Model with Third Mover Intervention Using Soliton Solution in Non-Complete Information Game under Repeated Dilemma Condition

    [https://arxiv.org/abs/2403.05585](https://arxiv.org/abs/2403.05585)

    该研究提出了一个新的模型，使用非线性偏微分方程和孤子解方法研究了假新闻在不完全信息博弈中的扩散过程，探讨了各类动者在系统中的相互作用，旨在理解和防止假新闻扩散。

    

    在这篇研究说明中，我们提出了一种新的方法来模拟虚假新闻在不完全信息博弈框架内的扩散过程。具体而言，我们使用非线性偏微分方程来表示悬浮复共振现象，其中虚假新闻的扩散在特定社交群体或通信网络内被迅速放大，并通过孤子解方法分析其动态。此外，我们考虑头部动者、次头动者和第三方干预策略如何在这个非线性系统中相互作用，并对虚假新闻的扩散起到放大或抑制的作用。该模型旨在理解虚假新闻传播机制，并提供防止或打击其的见解。通过结合社会科学和自然科学的概念，本研究试图为当今的假新闻问题开发一个新的理论框架。

    arXiv:2403.05585v1 Announce Type: cross  Abstract: In this research note, we propose a new approach to model the fake news diffusion process within the framework of incomplete information games. In particular, we use nonlinear partial differential equations to represent the phenomenon of plasmon resonance, in which the diffusion of fake news is rapidly amplified within a particular social group or communication network, and analyze its dynamics through a soliton solution approach. In addition, we consider how first mover, second mover, and third mover strategies interact within this nonlinear system and contribute to the amplification or suppression of fake news diffusion. The model aims to understand the mechanisms of fake news proliferation and provide insights into how to prevent or combat it. By combining concepts from the social sciences and the physical sciences, this study attempts to develop a new theoretical framework for the contemporary problem of fake news.
    
[^158]: Time2Stop：自适应和可解释的人工智能循环系统，用于干预智能手机过度使用

    Time2Stop: Adaptive and Explainable Human-AI Loop for Smartphone Overuse Intervention

    [https://arxiv.org/abs/2403.05584](https://arxiv.org/abs/2403.05584)

    Time2Stop开发了一种智能、自适应和可解释的即时自适应干预系统，通过机器学习确定最佳干预时机，引入透明的AI解释进行干预，并通过收集用户反馈建立人-AI循环。

    

    尽管对干预智能手机过度使用技术进行了深入的研究，但基于人工智能的即时自适应干预（JITAI）方法仍然缺乏。我们开发了Time2Stop，这是一个智能、自适应和可解释的JITAI系统，利用机器学习来确定最佳干预时机，引入透明的AI解释进行干预，并收集用户反馈以建立人工智能循环，并随时间调整干预模型。我们进行了为期8周的现场实验（N=71）来评估Time2Stop的自适应和解释方面的有效性。我们的结果表明，我们的自适应模型在干预准确性（>32.8\%相对）和接受度（>8.0\%）方面明显优于基线方法。此外，纳入解释进一步提高了干预的有效性，分别为准确性和接受度提高了53.8\%和11.4\%。此外，Time2Stop

    arXiv:2403.05584v1 Announce Type: cross  Abstract: Despite a rich history of investigating smartphone overuse intervention techniques, AI-based just-in-time adaptive intervention (JITAI) methods for overuse reduction are lacking. We develop Time2Stop, an intelligent, adaptive, and explainable JITAI system that leverages machine learning to identify optimal intervention timings, introduces interventions with transparent AI explanations, and collects user feedback to establish a human-AI loop and adapt the intervention model over time. We conducted an 8-week field experiment (N=71) to evaluate the effectiveness of both the adaptation and explanation aspects of Time2Stop. Our results indicate that our adaptive models significantly outperform the baseline methods on intervention accuracy (>32.8\% relatively) and receptivity (>8.0\%). In addition, incorporating explanations further enhances the effectiveness by 53.8\% and 11.4\% on accuracy and receptivity, respectively. Moreover, Time2Stop
    
[^159]: 一种基于LLM增强识别的跨模态静默语音方法

    A Cross-Modal Approach to Silent Speech with LLM-Enhanced Recognition

    [https://arxiv.org/abs/2403.05583](https://arxiv.org/abs/2403.05583)

    通过引入跨模态对齐和大语言模型，提出了一种Multimodal Orofacial Neural Audio系统，成功减少静默语音识别中的词错误率。

    

    静默语音界面（SSIs）为无声口头交流提供了一种非侵入式的替代方案，相较于脑机接口。我们引入了Multimodal Orofacial Neural Audio（MONA），该系统通过新颖的损失函数——跨对比（crossCon）和监督时间对比（supTcon）利用跨模态对齐来训练具有共享潜在表示的多模态模型。这种架构使得可以利用类似LibriSpeech的仅音频数据集来改善静默语音识别。此外，我们引入的大语言模型（LLM）整合评分调整（LISA）显著提高了识别准确性。综合而言，MONA LISA在Gaddy（2020年）静默语音基准数据集上将词错误率（WER）从28.8%降至12.2%，并且在开放词汇表上进行了静默语音的改进。对于声音EMG记录，我们的方法将最先进的识别率从23.3%提高到3.7% WER。

    arXiv:2403.05583v1 Announce Type: cross  Abstract: Silent Speech Interfaces (SSIs) offer a noninvasive alternative to brain-computer interfaces for soundless verbal communication. We introduce Multimodal Orofacial Neural Audio (MONA), a system that leverages cross-modal alignment through novel loss functions--cross-contrast (crossCon) and supervised temporal contrast (supTcon)--to train a multimodal model with a shared latent representation. This architecture enables the use of audio-only datasets like LibriSpeech to improve silent speech recognition. Additionally, our introduction of Large Language Model (LLM) Integrated Scoring Adjustment (LISA) significantly improves recognition accuracy. Together, MONA LISA reduces the state-of-the-art word error rate (WER) from 28.8% to 12.2% in the Gaddy (2020) benchmark dataset for silent speech on an open vocabulary. For vocal EMG recordings, our method improves the state-of-the-art from 23.3% to 3.7% WER. In the Brain-to-Text 2024 competition,
    
[^160]: 解释布局可以影响人对冒犯性句子的感知吗？

    Can Interpretability Layouts Influence Human Perception of Offensive Sentences?

    [https://arxiv.org/abs/2403.05581](https://arxiv.org/abs/2403.05581)

    本文通过用户研究探讨了机器学习解释布局是否会影响参与者对包含仇恨言论句子的评价，结果表明解释布局在触发参与者提供纠正性反馈和评估模型方面具有优势

    

    本文进行了一项用户研究，评估三种机器学习（ML）解释布局是否会影响参与者评估包含仇恨言论的句子时的观点，重点关注“厌恶女性”和“种族主义”两类。鉴于文献中存在分歧的结论，我们通过统计和定性分析问卷调查回应的实证证据，探讨在在线社区中使用ML解释性的优势。广义可加模型估计参与者的评级，融合了组内设计和组间设计。尽管我们的统计分析表明，没有任何解释布局显著影响参与者的观点，但我们的定性分析表明ML解释性的优势：1）触发参与者在他们的观点与模型之间存在差异时提供纠正性反馈，2）提供评估模型的见解

    arXiv:2403.05581v1 Announce Type: cross  Abstract: This paper conducts a user study to assess whether three machine learning (ML) interpretability layouts can influence participants' views when evaluating sentences containing hate speech, focusing on the "Misogyny" and "Racism" classes. Given the existence of divergent conclusions in the literature, we provide empirical evidence on using ML interpretability in online communities through statistical and qualitative analyses of questionnaire responses. The Generalized Additive Model estimates participants' ratings, incorporating within-subject and between-subject designs. While our statistical analysis indicates that none of the interpretability layouts significantly influences participants' views, our qualitative analysis demonstrates the advantages of ML interpretability: 1) triggering participants to provide corrective feedback in case of discrepancies between their views and the model, and 2) providing insights to evaluate a model's 
    
[^161]: Explainable AI研究中的文化偏见：一项系统性分析

    Cultural Bias in Explainable AI Research: A Systematic Analysis

    [https://arxiv.org/abs/2403.05579](https://arxiv.org/abs/2403.05579)

    XAI研究普遍忽视了潜在的文化差异，过于假设西方解释需求在全球通用。

    

    为了使人类和人工智能（AI）系统之间的协同作用更加有效，人工智能的输出通常需要向人类解释。可解释的人工智能（XAI）系统通常在人类用户研究中进行测试。然而，XAI研究人员是否考虑了人类解释需求中的文化差异仍未被探讨。我们强调了一项心理研究发现，普遍来自西方个人主义国家的人们和经常来自非西方集体主义国家的人们在解释上存在明显差异。我们认为，XAI研究目前忽视了这些差异，并且许多流行的XAI设计隐含地且问题地假设西方的解释需求在跨文化中是共享的。此外，我们系统性地审查了超过200个XAI用户研究，发现大多数研究未考虑相关的文化变化，只对西方人口进行了取样，但对人类的结论取得的是关于人类整体的。

    arXiv:2403.05579v1 Announce Type: cross  Abstract: For synergistic interactions between humans and artificial intelligence (AI) systems, AI outputs often need to be explainable to people. Explainable AI (XAI) systems are commonly tested in human user studies. However, whether XAI researchers consider potential cultural differences in human explanatory needs remains unexplored. We highlight psychological research that found significant differences in human explanations between many people from Western, commonly individualist countries and people from non-Western, often collectivist countries. We argue that XAI research currently overlooks these variations and that many popular XAI designs implicitly and problematically assume that Western explanatory needs are shared cross-culturally. Additionally, we systematically reviewed over 200 XAI user studies and found that most studies did not consider relevant cultural variations, sampled only Western populations, but drew conclusions about hu
    
[^162]: 将文本到图像和大型语言模型串联：生成个性化电子商务横幅的新方法

    Chaining text-to-image and large language model: A novel approach for generating personalized e-commerce banners

    [https://arxiv.org/abs/2403.05578](https://arxiv.org/abs/2403.05578)

    本研究提出了一种新方法，利用文本到图像模型和大型语言模型生成个性化网页横幅，根据用户互动动态内容，并且无需人工干预。

    

    arXiv:2403.05578v1 公告类型：交叉摘要：稳定扩散等文本到图像模型为生成艺术作品开辟了大量机会。最近的文献调查了文本到图像模型在增强许多创意艺术家工作中的应用。许多电子商务平台采用手动流程生成横幅，这是耗时的且存在可扩展性的局限性。在这项工作中，我们展示了利用文本到图像模型根据在线购物者的互动生成具有动态内容的个性化网页横幅的用途。此方法的新颖之处在于在没有人为干预的情况下将用户互动数据转换为有意义的提示。为此，我们利用大型语言模型（LLM）系统地从项目元信息中提取属性元组。然后通过提示工程将这些属性传递给文本到图像模型，以生成横幅的图像。我们的结果表明，所提出的方法可以创建高-

    arXiv:2403.05578v1 Announce Type: cross  Abstract: Text-to-image models such as stable diffusion have opened a plethora of opportunities for generating art. Recent literature has surveyed the use of text-to-image models for enhancing the work of many creative artists. Many e-commerce platforms employ a manual process to generate the banners, which is time-consuming and has limitations of scalability. In this work, we demonstrate the use of text-to-image models for generating personalized web banners with dynamic content for online shoppers based on their interactions. The novelty in this approach lies in converting users' interaction data to meaningful prompts without human intervention. To this end, we utilize a large language model (LLM) to systematically extract a tuple of attributes from item meta-information. The attributes are then passed to a text-to-image model via prompt engineering to generate images for the banner. Our results show that the proposed approach can create high-
    
[^163]: 通过激励背景理解模型生成图像满意度中的主观性

    Understanding Subjectivity through the Lens of Motivational Context in Model-Generated Image Satisfaction

    [https://arxiv.org/abs/2403.05576](https://arxiv.org/abs/2403.05576)

    通过模拟不同激励背景下的主观性因素，研究发现在评估图片时，主观性受图像外观、图像与文本对齐以及文本中提及对象的影响，强调了探究主观性对模型性能的重要性。

    

    图像生成模型在各种应用中都有望成为普遍存在。这些模型通常通过人类的质量评价进行微调和评估，而这些评价假定了一个普遍标准，未能考虑到这类任务的主观性。为了研究如何量化主观性及其影响规模，我们测量了不同使用情况下人类注释者的评估差异。通过模拟注释者主观性原本的潜在因素的影响，我们设计了一组动机（T恤图案、演示文稿视觉和手机背景图像）来为一组众包任务提供语境。我们的研究结果表明，图像的人类评估在不同语境中有所不同，以及不同语境组合之间也有所差异。影响这种主观性的三个关键因素是图像外观、图像与文本的对齐以及文本中提及的对象的表现。我们的研究凸显了考虑主观性重要性，并强调了获取主观性数据以提高模型性能的重要性。

    arXiv:2403.05576v1 Announce Type: cross  Abstract: Image generation models are poised to become ubiquitous in a range of applications. These models are often fine-tuned and evaluated using human quality judgments that assume a universal standard, failing to consider the subjectivity of such tasks. To investigate how to quantify subjectivity, and the scale of its impact, we measure how assessments differ among human annotators across different use cases. Simulating the effects of ordinarily latent elements of annotators subjectivity, we contrive a set of motivations (t-shirt graphics, presentation visuals, and phone background images) to contextualize a set of crowdsourcing tasks. Our results show that human evaluations of images vary within individual contexts and across combinations of contexts. Three key factors affecting this subjectivity are image appearance, image alignment with text, and representation of objects mentioned in the text. Our study highlights the importance of takin
    
[^164]: 利用大型语言模型在心理治疗中进行认知重构

    HealMe: Harnessing Cognitive Reframing in Large Language Models for Psychotherapy

    [https://arxiv.org/abs/2403.05574](https://arxiv.org/abs/2403.05574)

    这一创新心理治疗模型HealMe通过基于心理治疗框架的共情对话，有效解决了根深蒂固的负面思维，并促进了理性、平衡的观点。

    

    大型语言模型（LLMs）在心理治疗中可以发挥重要作用，熟练处理认知重构等关键任务，克服羞耻、不信任、治疗师技能差异和资源稀缺等挑战。在先前的认知重构中，主要将负面情绪转化为积极的，但这些方法效果有限，经常不能促进客户自我发现替代视角。在本文中，我们揭示了帮助和赋能通过自适应语言在心理增强（HealMe）模型。这种新颖的认知重构疗法方法有效地解决了根深蒂固的负面想法，并促进理性、平衡的视角。HealMe与传统LLM方法不同，采用基于心理治疗框架的共情对话。它通过系统指导客户区分情境和感受，集思广益寻找替代视角，并制定...

    arXiv:2403.05574v1 Announce Type: cross  Abstract: Large Language Models (LLMs) can play a vital role in psychotherapy by adeptly handling the crucial task of cognitive reframing and overcoming challenges such as shame, distrust, therapist skill variability, and resource scarcity. Previous LLMs in cognitive reframing mainly converted negative emotions to positive ones, but these approaches have limited efficacy, often not promoting clients' self-discovery of alternative perspectives. In this paper, we unveil the Helping and Empowering through Adaptive Language in Mental Enhancement (HealMe) model. This novel cognitive reframing therapy method effectively addresses deep-rooted negative thoughts and fosters rational, balanced perspectives. Diverging from traditional LLM methods, HealMe employs empathetic dialogue based on psychotherapeutic frameworks. It systematically guides clients through distinguishing circumstances from feelings, brainstorming alternative viewpoints, and developing 
    
[^165]: ChatGPT比人类更具移情能力吗？

    Is ChatGPT More Empathetic than Humans?

    [https://arxiv.org/abs/2403.05572](https://arxiv.org/abs/2403.05572)

    ChatGPT在回应情绪场景时比人类表现出更高的移情能力，平均移情评分高于人类生成的回应10%；指示ChatGPT在回应中融入对移情的清晰理解使得其回应与高度移情的个体的期望大致接近5倍。

    

    本文研究了ChatGPT以及尤其是其最新版本GPT-4在回应各种情绪场景（包括积极和消极情绪）时的移情能力，与人类生成的回应进行对比。我们采用严谨的评估方法，通过一个涉及600名参与者的组间研究来评估ChatGPT生成的回应中的移情水平。ChatGPT被提示的方式有两种：一种是标准方法，另一种明确详细说明了移情的认知、情感和同情方面。我们的发现表明，ChatGPT生成的回应的平均移情评分超过了人类生成的回应约10%。此外，指示ChatGPT在其回应中融入对移情的清晰理解使得这些回应与高度移情的个体的期望大致接近多达5倍。

    arXiv:2403.05572v1 Announce Type: cross  Abstract: This paper investigates the empathetic responding capabilities of ChatGPT, particularly its latest iteration, GPT-4, in comparison to human-generated responses to a wide range of emotional scenarios, both positive and negative. We employ a rigorous evaluation methodology, involving a between-groups study with 600 participants, to evaluate the level of empathy in responses generated by humans and ChatGPT. ChatGPT is prompted in two distinct ways: a standard approach and one explicitly detailing empathy's cognitive, affective, and compassionate counterparts. Our findings indicate that the average empathy rating of responses generated by ChatGPT exceeds those crafted by humans by approximately 10%. Additionally, instructing ChatGPT to incorporate a clear understanding of empathy in its responses makes the responses align approximately 5 times more closely with the expectations of individuals possessing a high degree of empathy, compared t
    
[^166]: OpenHEXAI：一个用于可解释机器学习人类中心评估的开源框架

    OpenHEXAI: An Open-Source Framework for Human-Centered Evaluation of Explainable Machine Learning

    [https://arxiv.org/abs/2403.05565](https://arxiv.org/abs/2403.05565)

    OpenHEXAI是一个用于人类中心评估可解释机器学习的开源框架，拥有多元化基准数据集、易于使用的用户研究Web应用程序和全面的评估指标。

    

    最近，由于需要理解高风险情景下的机器学习模型行为，解释型人工智能（XAI）方法大幅增多。然而，适当评估XAI方法的有效性不可避免地需要人类主体的参与，并且进行人类中心基准测试在许多方面都具有挑战性：设计和实施用户研究是复杂的；在设计空间中的众多设计选择导致可重复性问题；进行用户研究可能对机器学习研究人员来说是具有挑战性甚至令人望而生畏的。为解决这些挑战，本文提出了OpenHEXAI，一个用于XAI方法的人类中心评估的开源框架。OpenHEXAI具有（1）一系列不同基准数据集、预训练模型和事后解释方法；（2）用于用户研究的易于使用的Web应用程序；（3）全面的评估指标。

    arXiv:2403.05565v1 Announce Type: cross  Abstract: Recently, there has been a surge of explainable AI (XAI) methods driven by the need for understanding machine learning model behaviors in high-stakes scenarios. However, properly evaluating the effectiveness of the XAI methods inevitably requires the involvement of human subjects, and conducting human-centered benchmarks is challenging in a number of ways: designing and implementing user studies is complex; numerous design choices in the design space of user study lead to problems of reproducibility; and running user studies can be challenging and even daunting for machine learning researchers. To address these challenges, this paper presents OpenHEXAI, an open-source framework for human-centered evaluation of XAI methods. OpenHEXAI features (1) a collection of diverse benchmark datasets, pre-trained models, and post hoc explanation methods; (2) an easy-to-use web application for user study; (3) comprehensive evaluation metrics for the
    
[^167]: 利用LoRA对SDXL进行微调以进行上色疗法：受阿拉伯联合酋长国文化启发生成图形模板

    SDXL Finetuned with LoRA for Coloring Therapy: Generating Graphic Templates Inspired by United Arab Emirates Culture

    [https://arxiv.org/abs/2403.05562](https://arxiv.org/abs/2403.05562)

    通过将机器学习技术与传统阿联酋图案相融合，在SDXL模型中加入LoRA技术生成具有文化意义的上色模板，将上色疗法与文化共鸣相结合，作为治疗干预和文化保护的有效工具。

    

    一种革命性的心理健康疗法方法融合了文化遗产和先进技术的交汇点。本文介绍了一种创新方法，将机器学习技术与传统的阿拉伯联合酋长国图案相融合，重点放在阿联酋。我们利用了增强了Low-Rank Adaptation (LoRA)的Stable Diffusion XL (SDXL)模型，以创造具有文化意义的上色模板，其中包括Al-Sadu编织图案。这种新颖方法利用了上色疗法被认可的减压益处，并嵌入了深厚的文化共鸣，使其成为治疗干预和文化保护的强大工具。针对广泛性焦虑障碍 (GAD)，我们的方法展示了在减少相关症状方面的重要潜力。此外，本文深入探讨了色彩和音乐疗法的更广泛影响，并强调了文化定制内容的重要性。

    arXiv:2403.05562v1 Announce Type: cross  Abstract: A transformative approach to mental health therapy lies at the crossroads of cultural heritage and advanced technology. This paper introduces an innovative method that fuses machine learning techniques with traditional Emirati motifs, focusing on the United Arab Emirates (UAE). We utilize the Stable Diffusion XL (SDXL) model, enhanced with Low-Rank Adaptation (LoRA), to create culturally significant coloring templates featuring Al-Sadu weaving patterns. This novel approach leverages coloring therapy for its recognized stress-relieving benefits and embeds deep cultural resonance, making it a potent tool for therapeutic intervention and cultural preservation. Specifically targeting Generalized Anxiety Disorder (GAD), our method demonstrates significant potential in reducing associated symptoms. Additionally, the paper delves into the broader implications of color and music therapy, emphasizing the importance of culturally tailored conten
    
[^168]: 多源多模态数据融合在混合式学习大学课程中预测学术表现

    Multi-source and multimodal data fusion for predicting academic performance in blended learning university courses

    [https://arxiv.org/abs/2403.05552](https://arxiv.org/abs/2403.05552)

    该研究应用多源多模态数据融合方法，发现在混合式学习环境中预测学生学术表现的最佳属性集为理论课上的关注程度、Moodle测验成绩以及Moodle论坛上的活动水平。

    

    在这篇论文中，我们应用数据融合方法来预测大学生在混合式学习环境中的最终学术表现，利用来自多个源头、多模态的数据。我们从不同来源收集和预处理了关于大一学生的数据：理论课、实践课、在线Moodle课程以及期末考试。我们的目标是发现哪种数据融合方法在我们的数据中产生了最好的结果。我们进行了实验，应用了四种不同的数据融合方法和六种分类算法。结果显示，集成和选择最佳属性方法与离散化数据一起产生了最佳预测结果。最佳预测模型显示，理论课上的关注程度、Moodle测验成绩以及Moodle论坛上的活动水平是预测学生最终表现的最佳属性集。

    arXiv:2403.05552v1 Announce Type: cross  Abstract: In this paper we applied data fusion approaches for predicting the final academic performance of university students using multiple-source, multimodal data from blended learning environments. We collected and preprocessed data about first-year university students from different sources: theory classes, practical sessions, on-line Moodle sessions, and a final exam. Our objective was to discover which data fusion approach produced the best results using our data. We carried out experiments by applying four different data fusion approaches and six classification algorithms. The results showed that the best predictions were produced using ensembles and selecting the best attributes approach with discretized data. The best prediction models showed us that the level of attention in theory classes, scores in Moodle quizzes, and the level of activity in Moodle forums were the best set of attributes for predicting students' final performance in
    
[^169]: Teranga Go!：拼车协作消费社区，采用多准则犹豫模糊语言术语集观点来建立信心和信任

    Teranga Go!: Carpooling Collaborative Consumption Community with multi-criteria hesitant fuzzy linguistic term set opinions to build confidence and trust

    [https://arxiv.org/abs/2403.05550](https://arxiv.org/abs/2403.05550)

    该论文提出了一种名为二元模糊语言Delphi方法的扩展，通过评估问卷的各个部分来验证整个问卷的有效性，以解决评委展示不同专业程度的场景，并检测影响工具质量的项目。

    

    Classic Delphi和Fuzzy Delphi方法用于测试诸如问卷调查之类的数据采集工具的内容有效性。Fuzzy Delphi从语言角度处理评委员们发表的观点，通过使用模糊数值减少观点的歧义性。我们提出了一种称为二元模糊语言Delphi方法的扩展，以处理评委员展示不同专业程度的场景，通过使用语言术语的模糊多粒度语义，并通过2元语言值得出中间和最终结果。我们提案的关键思想是通过评估问卷的各个部分来验证整个问卷的有效性，将每个项目的有效性定义为决策问题。通过专家的意见，我们测量一致性程度、一致性程度和每个项目的语言分数，以便检测那些对工具的质量产生积极或消极影响的项目。

    arXiv:2403.05550v1 Announce Type: cross  Abstract: Classic Delphi and Fuzzy Delphi methods are used to test content validity of a data collection tools such as questionnaires. Fuzzy Delphi takes the opinion issued by judges from a linguistic perspective reducing ambiguity in opinions by using fuzzy numbers. We propose an extension named 2-Tuple Fuzzy Linguistic Delphi method to deal with scenarios in which judges show different expertise degrees by using fuzzy multigranular semantics of the linguistic terms and to obtain intermediate and final results expressed by 2-tuple linguistic values. The key idea of our proposal is to validate the full questionnaire by means of the evaluation of its parts, defining the validity of each item as a Decision Making problem. Taking the opinion of experts, we measure the degree of consensus, the degree of consistency, and the linguistic score of each item, in order to detect those items that affect, positively or negatively, the quality of the instrum
    
[^170]: 使用BERT监测极端社交媒体上反犹太主义话语的演变

    Monitoring the evolution of antisemitic discourse on extremist social media using BERT

    [https://arxiv.org/abs/2403.05548](https://arxiv.org/abs/2403.05548)

    本研究提出了一种使用BERT监测极端社交媒体上反犹太主义话语演变的自动方法，避免了手动监测的不可行性，为干预和防止仇恨升级提供了新途径。

    

    研究表明，社交媒体上的种族主义和不宽容有可能在线下产生仇恨，最终导致身体暴力。本研究考虑的是在线反犹主义，追踪在线讨论中的反犹主题及其相关术语的演变，有助于监测参与者的情绪和演变，并可能提供干预方法，防止仇恨升级。鉴于在线流量庞大且不断变化，手动监测谈话实际上是不现实的。因此，我们提出了一种自动化方法，可以从极端社交媒体中提取反犹主题和术语，跟踪它们的演变。由于监督学习在这样的任务中过于受限，我们开发了一种无监督的在线机器学习方法，使用大型语言模型。

    arXiv:2403.05548v1 Announce Type: cross  Abstract: Racism and intolerance on social media contribute to a toxic online environment which may spill offline to foster hatred, and eventually lead to physical violence. That is the case with online antisemitism, the specific category of hatred considered in this study. Tracking antisemitic themes and their associated terminology over time in online discussions could help monitor the sentiments of their participants and their evolution, and possibly offer avenues for intervention that may prevent the escalation of hatred. Due to the large volume and constant evolution of online traffic, monitoring conversations manually is impractical. Instead, we propose an automated method that extracts antisemitic themes and terminology from extremist social media over time and captures their evolution. Since supervised learning would be too limited for such a task, we created an unsupervised online machine learning approach that uses large language model
    
[^171]: AI对非程序员的应用：应用AI在没有编程技能的学生课堂中的应用

    AI for non-programmers: Applied AI in the lectures for students without programming skills

    [https://arxiv.org/abs/2403.05547](https://arxiv.org/abs/2403.05547)

    本研究提出了一个应用AI的教学规划脚本，通过将AI概念与研究相关主题联系起来，促进了学生对AI潜力和风险的理解和兴趣。

    

    诸如ChatGPT和WOMBO Dream等应用使得启发无编程知识的学生使用人工智能（AI）变得轻而易举。鉴于AI在各个学科中的日益重要，需要创新策略来教育那些没有编程知识的学生，以便将AI作为未来技能融入他们的学习模块。本文提出了一个应用AI的教学规划脚本。该教学规划脚本基于AI应用流程，并将AI概念与研究相关主题联系起来。这些联系打开了新的解决方案空间，并促进了学生对AI潜力和风险的兴趣和理解。以能源管理硕士学生为例，展示了如何将AI无缝地整合到专业课程中。为此，应用AI的教学规划脚本被调整以适应研究项目的主题。

    arXiv:2403.05547v1 Announce Type: cross  Abstract: Applications such as ChatGPT and WOMBO Dream make it easy to inspire students without programming knowledge to use artificial intelligence (AI). Therefore, given the increasing importance of AI in all disciplines, innovative strategies are needed to educate students in AI without programming knowledge so that AI can be integrated into their study modules as a future skill. This work presents a didactic planning script for applied AI. The didactic planning script is based on the AI application pipeline and links AI concepts with study-relevant topics. These linkages open up a new solution space and promote students' interest in and understanding of the potentials and risks of AI. An example lecture series for master students in energy management shows how AI can be seamlessly integrated into discipline-specific lectures. To this end, the planning script for applied AI is adapted to fit the study programs' topic. This specific teaching s
    
[^172]: 从算法崇拜到人类学习的艺术：从人工智能在教育领域的50年历程中获得的洞见

    From Algorithm Worship to the Art of Human Learning: Insights from 50-year journey of AI in Education

    [https://arxiv.org/abs/2403.05544](https://arxiv.org/abs/2403.05544)

    本文探讨了人工智能在教育领域的角色复杂性，同时关注了个性化学习、伦理影响、非STEM学科的贬值以及潜在对神经认知和社会情感功能的转变影响，以期为未来教育实践和政策提供启示。

    

    关于人工智能（AI）的当前讨论在希望和忧虑之间摇摆，描绘了一个未来，AI将重塑人类生活的方方面面，包括教育。本文深入探讨了AI在教育中的角色复杂性，解决了同时激励和警示教育工作者、决策者和公众的矛盾信息。它探讨了AI为通过规模化个性化提升学习所持有的承诺，同时也关注了伦理影响、非STEM学科的贬值以及对我们的神经认知和社会情感功能潜在转变影响的背景。借鉴最新研究和全球讨论，本文试图揭示当前AI在教育领域（AIED）讨论的模糊性背后的原因，以及这种不确定性对未来教育实践和政策的影响。

    arXiv:2403.05544v1 Announce Type: cross  Abstract: Current discourse surrounding Artificial Intelligence (AI) oscillates between hope and apprehension, painting a future where AI reshapes every facet of human life, including Education. This paper delves into the complexities of AI's role in Education, addressing the mixed messages that have both enthused and alarmed educators, policymakers, and the public. It explores the promises that AI holds for enhancing learning through personalisation at scale, against the backdrop of concerns about ethical implications, the devaluation of non-STEM subjects, and the potential transformative impact on our neurocognitive and socio-emotional functioning. Drawing on recent research and global discourse, the paper seeks to unpack the reasons behind the vagueness of current discussions on AI in Education (AIED) and the implications of this ambiguity for future educational practices and policies. By highlighting insights from educational research and sy
    
[^173]: 金融机构ESG中的人工智能：一个产业调查

    AI in ESG for Financial Institutions: An Industrial Survey

    [https://arxiv.org/abs/2403.05541](https://arxiv.org/abs/2403.05541)

    本文调查了金融机构中人工智能在ESG倡议中的应用，阐明了AI在加强ESG框架方面的必要性和影响，以及AI如何增强金融活动和可持续发展目标之间的复杂相互作用。

    

    人工智能（AI）日益融入金融行业的环境、社会和治理（ESG）倡议，代表了向更可持续和公平金融实践的范式转变。本文调查产业格局，阐明了AI在加强ESG框架中的必要性和影响。随着严格的监管要求和利益相关者意识的提高，金融机构（FIs）越来越被迫采纳ESG标准。AI成为在导航金融活动和可持续发展目标的复杂相互作用中的关键工具。我们的调查对ESG的三个主要支柱中的AI应用进行了分类，阐明了AI如何增强分析能力、风险评估、客户参与、报告准确性等方面。此外，我们深入探讨了围绕数据使用和模型开发的关键考虑因素。

    arXiv:2403.05541v1 Announce Type: cross  Abstract: The burgeoning integration of Artificial Intelligence (AI) into Environmental, Social, and Governance (ESG) initiatives within the financial sector represents a paradigm shift towards more sus-tainable and equitable financial practices. This paper surveys the industrial landscape to delineate the necessity and impact of AI in bolstering ESG frameworks. With the advent of stringent regulatory requirements and heightened stakeholder awareness, financial institutions (FIs) are increasingly compelled to adopt ESG criteria. AI emerges as a pivotal tool in navigating the complex in-terplay of financial activities and sustainability goals. Our survey categorizes AI applications across three main pillars of ESG, illustrating how AI enhances analytical capabilities, risk assessment, customer engagement, reporting accuracy and more. Further, we delve into the critical con-siderations surrounding the use of data and the development of models, und
    
[^174]: DeepSeek-VL:走向真实世界的视觉语言理解

    DeepSeek-VL: Towards Real-World Vision-Language Understanding

    [https://arxiv.org/abs/2403.05525](https://arxiv.org/abs/2403.05525)

    DeepSeek-VL是一个面向真实世界的视觉语言理解模型，通过多样化数据、真实场景覆盖和高效编码器的设计，大大提高了在实际应用中的用户体验

    

    我们提出DeepSeek-VL，一个面向真实世界视觉和语言理解应用的开源视觉-语言（VL）模型。我们的方法围绕三个关键维度展开：确保数据多样化、可扩展性强，并广泛涵盖包括网络截图、PDF、OCR、图表和基于知识的内容在内的真实场景，以全面表征实际环境。此外，我们从真实用户场景创建了用例分类法，并相应构建了指导调整数据集。通过这个数据集的微调，大大提高了模型在实际应用中的用户体验。考虑到效率和大多数真实场景的需求，DeepSeek-VL整合了一个混合视觉编码器，能够高效处理高分辨率图像（1024 x 1024），同时保持相对较低的计算开销。这种设计选择确保了模型的能力

    arXiv:2403.05525v1 Announce Type: new  Abstract: We present DeepSeek-VL, an open-source Vision-Language (VL) Model designed for real-world vision and language understanding applications. Our approach is structured around three key dimensions:   We strive to ensure our data is diverse, scalable, and extensively covers real-world scenarios including web screenshots, PDFs, OCR, charts, and knowledge-based content, aiming for a comprehensive representation of practical contexts. Further, we create a use case taxonomy from real user scenarios and construct an instruction tuning dataset accordingly. The fine-tuning with this dataset substantially improves the model's user experience in practical applications. Considering efficiency and the demands of most real-world scenarios, DeepSeek-VL incorporates a hybrid vision encoder that efficiently processes high-resolution images (1024 x 1024), while maintaining a relatively low computational overhead. This design choice ensures the model's abilit
    
[^175]: 基于规则的新闻标题生成

    Rule-driven News Captioning

    [https://arxiv.org/abs/2403.05101](https://arxiv.org/abs/2403.05101)

    本文提出了一种基于规则的新闻标题生成方法，通过新闻感知的语义规则，可以生成遵循新闻报道基本规则的图像描述。

    

    News captioning任务旨在通过描述图片及其新闻文章中的命名实体或具体事件来生成句子。现有方法通过依赖大规模预训练模型已取得显著成果，这些模型主要专注于输入新闻内容与输出预测之间的相关性。然而，新闻标题生成需要遵循新闻报道的一些基本规则，如准确描述与事件相关的个体和动作。在本文中，我们提出了基于规则的新闻标题生成方法，可以根据指定的规则信号生成图像描述。具体而言，我们首先为描述设计了新闻感知的语义规则。这一规则包括图片中描绘的主要动作（例如，“执行”）以及参与动作的命名实体扮演的角色（例如，“代理人”和“地点”）。其次，我们将这个语义规则注入到文本生成模型中。

    arXiv:2403.05101v1 Announce Type: cross  Abstract: News captioning task aims to generate sentences by describing named entities or concrete events for an image with its news article. Existing methods have achieved remarkable results by relying on the large-scale pre-trained models, which primarily focus on the correlations between the input news content and the output predictions. However, the news captioning requires adhering to some fundamental rules of news reporting, such as accurately describing the individuals and actions associated with the event. In this paper, we propose the rule-driven news captioning method, which can generate image descriptions following designated rule signal. Specifically, we first design the news-aware semantic rule for the descriptions. This rule incorporates the primary action depicted in the image (e.g., "performing") and the roles played by named entities involved in the action (e.g., "Agent" and "Place"). Second, we inject this semantic rule into th
    
[^176]: 通过对抗性攻击欺骗神经网络进行动作预测

    Fooling Neural Networks for Motion Forecasting via Adversarial Attacks

    [https://arxiv.org/abs/2403.04954](https://arxiv.org/abs/2403.04954)

    该研究在人体动作预测领域引入了对抗性攻击，通过实验证实模型即使在低水平的扰动下也容易受到攻击，并展示了对简单旋转和平移敏感的模型性能受影响。

    

    人体动作预测仍然是一个需要解决的开放问题，对于自动驾驶和安全应用非常重要。尽管该领域取得了巨大进展，但广泛研究的对抗性攻击主题尚未应用于人体动作预测中的多回归模型，如GCNs和基于MLP的架构。该工作旨在通过对类似于图像分类中对抗性攻击初始阶段的最先进架构进行广泛的定量和定性实验来缩小这一差距。结果表明，即使在低水平扰动上，模型也容易受到攻击。我们还展示了影响模型性能的三维变换实验，特别是我们展示了大多数模型对简单的旋转和平移敏感，这些变换不会改变关节距离。我们得出结论，类似早期CNN模型一样，动作预测任务易受到小的攻击。

    arXiv:2403.04954v1 Announce Type: cross  Abstract: Human motion prediction is still an open problem, which is extremely important for autonomous driving and safety applications. Although there are great advances in this area, the widely studied topic of adversarial attacks has not been applied to multi-regression models such as GCNs and MLP-based architectures in human motion prediction. This work intends to reduce this gap using extensive quantitative and qualitative experiments in state-of-the-art architectures similar to the initial stages of adversarial attacks in image classification. The results suggest that models are susceptible to attacks even on low levels of perturbation. We also show experiments with 3D transformations that affect the model performance, in particular, we show that most models are sensitive to simple rotations and translations which do not alter joint distances. We conclude that similar to earlier CNN models, motion forecasting tasks are susceptible to small
    
[^177]: 基于凸集图的移动目标旅行推销员问题的混合整数锥规划

    A Mixed-Integer Conic Program for the Moving-Target Traveling Salesman Problem based on a Graph of Convex Sets

    [https://arxiv.org/abs/2403.04917](https://arxiv.org/abs/2403.04917)

    本文提出了一个新的公式，用于解决移动目标旅行推销员问题，该公式基于目标在空间-时间坐标系内成为凸集的概念，通过在凸集图中寻找最短路径来实现，在实验中表现出比当前Mixed Integer Conic Program (MICP)求解器更好的效果。

    

    本文介绍了一种寻找移动目标旅行推销员问题（MT-TSP）的最佳解决方案的新的公式，该问题旨在找到一个最短路径，使一个从仓库出发的代理访问一组移动目标，并在它们分配的时间窗口内恰好访问一次，然后返回到仓库。该公式依赖于一个关键思想，即当目标沿着线移动时，它们的轨迹在空间-时间坐标系内变为凸集。然后，问题就缩减为在一个凸集图中寻找最短路径，受到一些速度约束的限制。我们将我们的公式与当前最先进的Mixed Integer Conic Program (MICP)求解器进行了比较，结果显示，我们的公式在目标数量最多为20个的情况下性能优于MICP，在运行时间上缩短了两个数量级，并且最优性差距缩小了高达60％。我们还展示了该解法的成本...

    arXiv:2403.04917v1 Announce Type: cross  Abstract: This paper introduces a new formulation that finds the optimum for the Moving-Target Traveling Salesman Problem (MT-TSP), which seeks to find a shortest path for an agent, that starts at a depot, visits a set of moving targets exactly once within their assigned time-windows, and returns to the depot. The formulation relies on the key idea that when the targets move along lines, their trajectories become convex sets within the space-time coordinate system. The problem then reduces to finding the shortest path within a graph of convex sets, subject to some speed constraints. We compare our formulation with the current state-of-the-art Mixed Integer Conic Program (MICP) solver for the MT-TSP. The experimental results show that our formulation outperforms the MICP for instances with up to 20 targets, with up to two orders of magnitude reduction in runtime, and up to a 60\% tighter optimality gap. We also show that the solution cost from th
    
[^178]: 卫星图像时间自监督（S3-TSS）：卫星图像中的SSL技术的新方法

    Self-Supervision in Time for Satellite Images(S3-TSS): A novel method of SSL technique in Satellite images

    [https://arxiv.org/abs/2403.04859](https://arxiv.org/abs/2403.04859)

    提出了一种新的卫星图像中的自监督学习方法S3-TSS，利用时间维度中的自然增强，结果显示在四个下游数据集中优于基线方法SeCo。

    

    随着遥感图像中带有各种大气条件的标记数据的有限可用性，似乎使用自监督算法很有用。包括旋转、空间上下文和拼图在内的几种基于假设的算法并不适用于卫星图像。通常，卫星图像具有更高的时间频率。 因此，遥感数据的时间维度提供了自然增强，而无需我们创建图像的人工增强。 在这里，我们提出了S3-TSS，一种利用时间维度中自然增强的自监督学习技术的新方法。 我们将我们的结果与当前领先的方法进行了比较，并进行了各种实验。 我们观察到，我们的方法在四个下游数据集中表现优于基线SeCo。 我们的工作代码可以在这里找到：https://github.com/hewanshrestha/Why-Self-Supervision-in-Time

    arXiv:2403.04859v1 Announce Type: new  Abstract: With the limited availability of labeled data with various atmospheric conditions in remote sensing images, it seems useful to work with self-supervised algorithms. Few pretext-based algorithms, including from rotation, spatial context and jigsaw puzzles are not appropriate for satellite images. Often, satellite images have a higher temporal frequency. So, the temporal dimension of remote sensing data provides natural augmentation without requiring us to create artificial augmentation of images. Here, we propose S3-TSS, a novel method of self-supervised learning technique that leverages natural augmentation occurring in temporal dimension. We compare our results with current state-of-the-art methods and also perform various experiments. We observed that our method was able to perform better than baseline SeCo in four downstream datasets. Code for our work can be found here: https://github.com/hewanshrestha/Why-Self-Supervision-in-Time
    
[^179]: TopicDiff：一种用于多模态会话情感检测的主题丰富扩散方法

    TopicDiff: A Topic-enriched Diffusion Approach for Multimodal Conversational Emotion Detection

    [https://arxiv.org/abs/2403.04789](https://arxiv.org/abs/2403.04789)

    提出了一种TopicDiff方法，用于捕获多模态会话情感检测任务中的主题信息，通过将扩散模型集成到神经主题模型中，解决了神经主题模型在捕获主题信息方面的多样性不足问题，并相对于现有MCE基线取得了显著改进

    

    多模态会话情感（MCE）检测通常跨越声学、视觉和语言模态，吸引了多媒体社区日益增加的兴趣。先前的研究主要集中在学习对话中的语境信息，只有少数考虑单一语言模态中的主题信息，而总是忽视声学和视觉主题信息。在此基础上，我们提出了一个模型不可知的Topic-enriched Diffusion（TopicDiff）方法，用于捕获MCE任务中的多模态主题信息。特别是，我们将扩散模型集成到神经主题模型中，以缓解神经主题模型在捕获主题信息方面的多样性不足问题。详细的评估表明，TopicDiff相对于最先进的MCE基线取得了显著改进，证明了多模态主题信息对MCE的重要性以及TopicDiff的有效性。

    arXiv:2403.04789v1 Announce Type: cross  Abstract: Multimodal Conversational Emotion (MCE) detection, generally spanning across the acoustic, vision and language modalities, has attracted increasing interest in the multimedia community. Previous studies predominantly focus on learning contextual information in conversations with only a few considering the topic information in single language modality, while always neglecting the acoustic and vision topic information. On this basis, we propose a model-agnostic Topic-enriched Diffusion (TopicDiff) approach for capturing multimodal topic information in MCE tasks. Particularly, we integrate the diffusion model into neural topic model to alleviate the diversity deficiency problem of neural topic model in capturing topic information. Detailed evaluations demonstrate the significant improvements of TopicDiff over the state-of-the-art MCE baselines, justifying the importance of multimodal topic information to MCE and the effectiveness of Topic
    
[^180]: 移除GPT4的过滤器

    Removing GPT4's Filter

    [https://arxiv.org/abs/2403.04769](https://arxiv.org/abs/2403.04769)

    提出了一种方法，可以使经过微调的GPT4恢复到没有经过人类反馈强化学习训练的状态，从而移除其在学习期间的所有安全机制

    

    GPT4最初在大量数据集上进行训练，然后使用来自人类反馈的强化学习进行微调，即志愿者提供反馈以教导GPT4不要生成不当内容。本文提出了一种方法来操作已经进行微调的版本，使其恢复到没有经过RLHF（Reinforcement learning from Human Feedback）的行为，有效地移除了模型在RLHF期间学习的所有安全机制。特别是，当GPT4在没有经过RLHF的情况下运行时，它失去了所有抑制力，只需前几个词就可以生成非常不当的内容。

    arXiv:2403.04769v1 Announce Type: cross  Abstract: GPT4 was initially trained on large amounts of data, and then fine-tuned using Reinforcement learning from Human Feedback (RLHF), which is when volunteers give feedback in order to teach GPT4 not to create inappropriate content. In this paper, we present a method to manipulate the fine-tuned version into reverting to pre-RLHF behavior, effectively removing all safety mechanisms that the model learned during RLHF. In particular, when GPT4 acts without RLHF, it loses all inhibition, and can complete very inappropriate content given only the first few words.
    
[^181]: 在随机效用和路径约束下的竞争设施选址问题

    Competitive Facility Location under Random Utilities and Routing Constraints

    [https://arxiv.org/abs/2403.04264](https://arxiv.org/abs/2403.04264)

    本文研究了在竞争市场背景下的设施选址问题，引入了路径约束，探讨了三种有效割以处理非线性目标函数。

    

    本文研究了在竞争市场背景下的设施选址问题，其中顾客需求由随机效用选择模型预测。与以往主要关注简单约束（例如所选位置数量的基数约束）的研究不同，我们引入了路径约束，这些约束需要以一种方式选择位置，以保证存在访问所有选择位置的旅程，同时遵守指定的旅程长度上限。这种路径约束在各种现实场景中具有关键应用。所涉问题具有非线性目标函数，这是由于采用了随机效用，并且具有复杂的路径约束，使其在计算上具有挑战性。为了解决这个问题，我们探讨了三种有效割，即外估计和子模割，以处理非线性目标函数，以及

    arXiv:2403.04264v1 Announce Type: new  Abstract: In this paper, we study a facility location problem within a competitive market context, where customer demand is predicted by a random utility choice model. Unlike prior research, which primarily focuses on simple constraints such as a cardinality constraint on the number of selected locations, we introduce routing constraints that necessitate the selection of locations in a manner that guarantees the existence of a tour visiting all chosen locations while adhering to a specified tour length upper bound. Such routing constraints find crucial applications in various real-world scenarios. The problem at hand features a non-linear objective function, resulting from the utilization of random utilities, together with complex routing constraints, making it computationally challenging. To tackle this problem, we explore three types of valid cuts, namely, outer-approximation and submodular cuts to handle the nonlinear objective function, as wel
    
[^182]: Aligners: 解耦LLMs和对齐

    Aligners: Decoupling LLMs and Alignment

    [https://arxiv.org/abs/2403.04224](https://arxiv.org/abs/2403.04224)

    提出了一种通过训练对齐器模型来解耦大型语言模型（LLMs）和对齐，以减少对齐对性能的潜在负面影响。

    

    大型语言模型（LLMs）需要与人类期望对齐，以确保它们在大多数应用中的安全性和实用性。对齐具有挑战性，成本高昂，并且需要为每个LLM和对齐标准重复进行。我们建议通过训练可以根据需要用于对齐给定标准的任何LLM的对齐模型来解耦LLMs和对齐，从而在一定程度上减少对性能的潜在负面影响。我们提出的对齐模型训练配方仅依赖于使用（提示的）LLM 生成的合成数据，并且可以轻松调整以适应各种对齐标准。我们通过训练一个“道德”对齐器并在实验上验证其有效性来阐明我们的方法。

    arXiv:2403.04224v1 Announce Type: cross  Abstract: Large Language Models (LLMs) need to be aligned with human expectations to ensure their safety and utility in most applications. Alignment is challenging, costly, and needs to be repeated for every LLM and alignment criterion. We propose to decouple LLMs and alignment by training aligner models that can be used to align any LLM for a given criteria on an as-needed basis, thus also reducing the potential negative impacts of alignment on performance. Our recipe for training the aligner models solely relies on synthetic data generated with a (prompted) LLM and can be easily adjusted for a variety of alignment criteria. We illustrate our method by training an "ethical" aligner and verify its efficacy empirically.
    
[^183]: 大型语言模型能够进行推理和规划吗？

    Can Large Language Models Reason and Plan?

    [https://arxiv.org/abs/2403.04121](https://arxiv.org/abs/2403.04121)

    大型语言模型缺乏自我批评能力，无法像人类一样纠正错误。

    

    虽然人类有时候表现出能够通过自我批评纠正自己错误猜测的能力，但似乎在大型语言模型的情况下没有依据支持这一假设。

    arXiv:2403.04121v1 Announce Type: new  Abstract: While humans sometimes do show the capability of correcting their own erroneous guesses with self-critiquing, there seems to be no basis for that assumption in the case of LLMs.
    
[^184]: 个性化AI驱动提示对用户认知能力的解释：一项实证评估

    Personalizing explanations of AI-driven hints to users cognitive abilities: an empirical evaluation

    [https://arxiv.org/abs/2403.04035](https://arxiv.org/abs/2403.04035)

    该研究调查了如何个性化智能辅导系统生成的提示的解释，以帮助促进学生学习，实证结果表明，该个性化方法显著提高了目标用户与提示解释的互动、理解和学习效果。

    

    我们调查了个性化解释智能辅导系统生成的提示，以证明它们提供提示促进学生学习的有效性。个性化针对具有两种特征（认知需求和认真度）较低水平的学生，旨在增强这些学生对解释的参与，基于先前研究发现，这些学生不会自然参与解释，但如果他们这样做将会受益。为了评估个性化的有效性，我们进行了一项用户研究，我们发现我们提出的个性化显著增加了我们目标用户与提示解释的互动、他们对提示的理解以及他们的学习。因此，这项工作为个性化AI驱动解释提供了有价值的见解，适用于如学习等认知要求高的任务。

    arXiv:2403.04035v1 Announce Type: new  Abstract: We investigate personalizing the explanations that an Intelligent Tutoring System generates to justify the hints it provides to students to foster their learning. The personalization targets students with low levels of two traits, Need for Cognition and Conscientiousness, and aims to enhance these students' engagement with the explanations, based on prior findings that these students do not naturally engage with the explanations but they would benefit from them if they do. To evaluate the effectiveness of the personalization, we conducted a user study where we found that our proposed personalization significantly increases our target users' interaction with the hint explanations, their understanding of the hints and their learning. Hence, this work provides valuable insights into effectively personalizing AI-driven explanations for cognitively demanding tasks such as learning.
    
[^185]: 语言模型是否是解谜天才？算法谜题揭示了多模态推理中的严峻挑战

    Are Language Models Puzzle Prodigies? Algorithmic Puzzles Unveil Serious Challenges in Multimodal Reasoning

    [https://arxiv.org/abs/2403.03864](https://arxiv.org/abs/2403.03864)

    这项研究提出了多模态解谜任务AlgoPuzzleVQA，通过算法谜题挑战评估了多模态语言模型在需要视觉理解、语言理解和复杂算法推理的能力，旨在评估视觉数据解释与算法问题解决能力之间的差距。

    

    这篇论文介绍了多模态解谜任务，将其放在视觉问答的背景中。我们提出了一个新的数据集AlgoPuzzleVQA，旨在挑战和评估多模态语言模型在解决需要视觉理解、语言理解和复杂算法推理的算法谜题方面的能力。我们创建了涵盖布尔逻辑、组合数学、图论、优化、搜索等多种数学和算法主题的谜题，旨在评估视觉数据解释与算法问题解决能力之间的差距。数据集是通过人类编写的代码自动生成的。我们所有的谜题都有精确的解决方案，可以从算法中找到，无需繁琐的人工计算。这确保了我们的数据集在推理复杂性和数据集大小方面可以任意扩展。

    arXiv:2403.03864v1 Announce Type: cross  Abstract: This paper introduces the novel task of multimodal puzzle solving, framed within the context of visual question-answering. We present a new dataset, AlgoPuzzleVQA designed to challenge and evaluate the capabilities of multimodal language models in solving algorithmic puzzles that necessitate both visual understanding, language understanding, and complex algorithmic reasoning. We create the puzzles to encompass a diverse array of mathematical and algorithmic topics such as boolean logic, combinatorics, graph theory, optimization, search, etc., aiming to evaluate the gap between visual data interpretation and algorithmic problem-solving skills. The dataset is generated automatically from code authored by humans. All our puzzles have exact solutions that can be found from the algorithm without tedious human calculations. It ensures that our dataset can be scaled up arbitrarily in terms of reasoning complexity and dataset size. Our investi
    
[^186]: DeepCRE：利用尖端计算模型改革药物研发

    DeepCRE: Revolutionizing Drug R&D with Cutting-Edge Computational Models

    [https://arxiv.org/abs/2403.03768](https://arxiv.org/abs/2403.03768)

    DeepCRE是一种新型的计算模型，在患者级别CRE性能上平均提高了17.7％，在指示级别CRE增加了5倍，并成功确定了六个具有显着优势的药物候选者。

    

    arXiv:2403.03768v1 公告类型：新摘要：药物开发领域和治疗应用领域都面临着重大挑战。治疗领域需要更多的治疗选择，同时大量有前景的临床前药物在临床试验中失败。一个原因是在药物开发的后期阶段交叉药物反应评估（CRE）的不足。尽管计算机模拟的CRE模型为解决这一问题提供了一种解决方案，但现有方法学要么局限于早期开发阶段，要么缺乏对全面CRE分析的能力。在这里，我们介绍了一种名为DeepCRE的新型计算模型，并展示了DeepCRE在推动治疗发现和发展方面的潜力。DeepCRE通过实现患者级别CRE平均性能提高17.7\%，指示级别CRE增加了5倍，优于现有最佳模型。此外，DeepCRE已经确定了六个显示出明显更大优势的药物候选者。

    arXiv:2403.03768v1 Announce Type: new  Abstract: The field of pharmaceutical development and therapeutic application both face substantial challenges. Therapeutic domain calls for more treatment alternatives while numerous promising pre-clinical drugs fail in clinical trails. One of the reasons is the inadequacy of Cross-drug Response Evaluation (CRE) during the late stage of drug development. Although in-silico CRE models offer a solution to this problem, existing methodologies are either limited to early development stages or lack the capacity for a comprehensive CRE analysis. Herein, we introduce a novel computational model named DeepCRE and present the potential of DeepCRE in advancing therapeutic discovery and development. DeepCRE outperforms the existing best models by achieving an average performance improvement of 17.7\% in patient-level CRE, and a 5-fold increase in indication-level CRE. Furthermore, DeepCRE has identified six drug candidates that show significantly greater ef
    
[^187]: Apollo：轻量级多语言医学LLMs：让医学人工智能普惠60亿人

    Apollo: Lightweight Multilingual Medical LLMs towards Democratizing Medical AI to 6B People

    [https://arxiv.org/abs/2403.03640](https://arxiv.org/abs/2403.03640)

    Apollo项目开发了多语言医学LLMs，创建了全球人口61亿的医学数据集，并发布了各种尺寸的最佳性能模型，其中Apollo-7B是最先进的多语言医学LLMs，可改善更大模型的多语言医学能力。

    

    尽管全球医学知识的庞大存储库主要是以英语为主，但在传递量身定制医疗服务方面，本地语言对于在医疗资源有限的地区尤为重要。为了将医学人工智能的进展扩展到更广泛的人群，我们旨在开发涵盖全球61亿人口的六种最常用语言的医学LLMs。这一努力最终促成了ApolloCorpora多语言医学数据集和XMedBench基准的创建。在多语言医学基准测试中，发布的Apollo模型，在各种相对较小尺寸（即0.5B、1.8B、2B、6B和7B）上取得了与同等大小模型最佳性能。特别地，Apollo-7B是迄今为止达到70B的最先进的多语言医学LLMs。此外，这些轻量级模型可用于在不需要微调的情况下改进较大模型的多语言医学能力。

    arXiv:2403.03640v1 Announce Type: cross  Abstract: Despite the vast repository of global medical knowledge predominantly being in English, local languages are crucial for delivering tailored healthcare services, particularly in areas with limited medical resources. To extend the reach of medical AI advancements to a broader population, we aim to develop medical LLMs across the six most widely spoken languages, encompassing a global population of 6.1 billion. This effort culminates in the creation of the ApolloCorpora multilingual medical dataset and the XMedBench benchmark. In the multilingual medical benchmark, the released Apollo models, at various relatively-small sizes (i.e., 0.5B, 1.8B, 2B, 6B, and 7B), achieve the best performance among models of equivalent size. Especially, Apollo-7B is the state-of-the-art multilingual medical LLMs up to 70B. Additionally, these lite models could be used to improve the multi-lingual medical capabilities of larger models without fine-tuning in a
    
[^188]: 全球推广公平性的理由：关于殖民主义、人工智能和非洲健康的混合方法研究

    The Case for Globalizing Fairness: A Mixed Methods Study on Colonialism, AI, and Health in Africa

    [https://arxiv.org/abs/2403.03357](https://arxiv.org/abs/2403.03357)

    该研究探讨了全球卫生公平性，以非洲为案例研究，通过范围审查和定性研究揭示了ML技术在非洲健康领域中可能出现的不公平现象，并特别关注殖民主义作为一个重要属性。

    

    随着机器学习（ML）技术在医疗保健中的应用日益增长，人们呼吁开发技术来理解和减轻这些系统可能表现出的偏见。 公平性在为健康开发基于ML的解决方案时具有特定对非洲有重要影响，非洲已经面临全球南北之间不公平的权力失衡。 本文旨在探讨全球健康的公平性，以非洲为案例研究。我们进行范围审查，提出在非洲环境中考虑公平性的差距轴，并勾画它们可能在不同ML启用的医疗模式中产生影响的区域。 然后，我们进行了对672名一般人口研究参与者和28名专家进行的定性研究，他们关注的是与非洲有关的ML、健康和政策，以获得关于已提出的差距轴的证实性证据。 我们的分析聚焦于殖民主义作为综合的特征。

    arXiv:2403.03357v1 Announce Type: new  Abstract: With growing application of machine learning (ML) technologies in healthcare, there have been calls for developing techniques to understand and mitigate biases these systems may exhibit. Fair-ness considerations in the development of ML-based solutions for health have particular implications for Africa, which already faces inequitable power imbalances between the Global North and South.This paper seeks to explore fairness for global health, with Africa as a case study. We conduct a scoping review to propose axes of disparities for fairness consideration in the African context and delineate where they may come into play in different ML-enabled medical modalities. We then conduct qualitative research studies with 672 general population study participants and 28 experts inML, health, and policy focused on Africa to obtain corroborative evidence on the proposed axes of disparities. Our analysis focuses on colonialism as the attribute of inte
    
[^189]: “在对话中学习”：通过对话中学习实现无需预定义个人资料的个性化对话

    "In Dialogues We Learn": Towards Personalized Dialogue Without Pre-defined Profiles through In-Dialogue Learning

    [https://arxiv.org/abs/2403.03102](https://arxiv.org/abs/2403.03102)

    提出了一种In-Dialogue Learning框架，通过对话历史刻画个人设来完成个性化对话生成任务，无需预定义个人资料，并在实验证明其显著改进对话生成性能。

    

    个性化对话系统近年来备受关注，因其能够生成与不同人设一致的响应。然而，大多数现有方法依赖预定义的个人资料，这不仅耗时且劳动密集，还缺乏灵活性。我们提出了In-Dialogue Learning（IDL），一种微调框架，增强了预训练的大型语言模型利用对话历史来刻画个人设，以完成个性化对话生成任务，而无需预定义个人资料。我们在三个数据集上的实验表明，IDL带来了显著的改进，BLEU和ROUGE分数分别增加了高达200%和247%。此外，人工评估的结果进一步验证了我们提出方法的有效性。

    arXiv:2403.03102v1 Announce Type: cross  Abstract: Personalized dialogue systems have gained significant attention in recent years for their ability to generate responses in alignment with different personas. However, most existing approaches rely on pre-defined personal profiles, which are not only time-consuming and labor-intensive to create but also lack flexibility. We propose In-Dialogue Learning (IDL), a fine-tuning framework that enhances the ability of pre-trained large language models to leverage dialogue history to characterize persona for completing personalized dialogue generation tasks without pre-defined profiles. Our experiments on three datasets demonstrate that IDL brings substantial improvements, with BLEU and ROUGE scores increasing by up to 200% and 247%, respectively. Additionally, the results of human evaluations further validate the efficacy of our proposed method.
    
[^190]: NASH：用于硬件优化机器学习模型的神经架构搜索

    NASH: Neural Architecture Search for Hardware-Optimized Machine Learning Models

    [https://arxiv.org/abs/2403.01845](https://arxiv.org/abs/2403.01845)

    NASH是一种将神经架构搜索应用于机器学习硬件的新方法，可以帮助硬件设计实现高吞吐量、低延迟和优越的准确性表现。

    

    随着机器学习（ML）算法在越来越多的应用中部署，这些算法需要在高准确性、高吞吐量和低延迟之间取得更好的权衡。本文介绍了一种名为NASH的新方法，将神经架构搜索应用于机器学习硬件。使用NASH，硬件设计不仅可以实现高吞吐量和低延迟，还可以实现优越的准确性表现。本文提出了四个版本的NASH策略，所有这些策略显示出比原始模型更高的准确性。该策略可以应用于各种卷积神经网络，从众多模型操作中选择特定操作，引导训练过程朝向更高的准确性。实验结果显示，在 ResNet18 或 ResNet34 上应用NASH，与非NASH版本相比，可使Top1准确率提高高达3.1%，Top5准确率提高高达2.2%。

    arXiv:2403.01845v1 Announce Type: cross  Abstract: As machine learning (ML) algorithms get deployed in an ever-increasing number of applications, these algorithms need to achieve better trade-offs between high accuracy, high throughput and low latency. This paper introduces NASH, a novel approach that applies neural architecture search to machine learning hardware. Using NASH, hardware designs can achieve not only high throughput and low latency but also superior accuracy performance. We present four versions of the NASH strategy in this paper, all of which show higher accuracy than the original models. The strategy can be applied to various convolutional neural networks, selecting specific model operations among many to guide the training process toward higher accuracy. Experimental results show that applying NASH on ResNet18 or ResNet34 achieves a top 1 accuracy increase of up to 3.1% and a top 5 accuracy increase of up to 2.2% compared to the non-NASH version when tested on the Imag
    
[^191]: GPTSee：通过基于描述的相似特征增强时刻检索和重点检测

    GPTSee: Enhancing Moment Retrieval and Highlight Detection via Description-Based Similarity Features

    [https://arxiv.org/abs/2403.01437](https://arxiv.org/abs/2403.01437)

    该研究提出了一个新颖的两阶段模型，将大型语言模型（LLMs）的输出用作第二阶段变压器编码器-解码器的输入，实现了时刻检索和重点检测的最先进结果。

    

    时刻检索（MR）和重点检测（HD）旨在从相应的自然语言查询中识别视频中的相关时刻和重点。大型语言模型（LLMs）已经展示了在各种计算机视觉任务中的熟练程度。然而，现有的MR和HD方法尚未与LLMs集成。在这封信中，我们提出了一种新颖的两阶段模型，将LLMs的输出作为第二阶段变压器编码器-解码器的输入。首先，利用MiniGPT-4生成视频帧的详细描述并重写查询语句，将其作为新特征输入编码器。然后计算生成描述和重写查询之间的语义相似性。最后，连续高相似性视频帧被转换为范围锚点，作为解码器的先验位置信息。实验证明，我们的方法达到了最先进的结果，并通过使用...

    arXiv:2403.01437v1 Announce Type: cross  Abstract: Moment retrieval (MR) and highlight detection (HD) aim to identify relevant moments and highlights in video from corresponding natural language query. Large language models (LLMs) have demonstrated proficiency in various computer vision tasks. However, existing methods for MR\&HD have not yet been integrated with LLMs. In this letter, we propose a novel two-stage model that takes the output of LLMs as the input to the second-stage transformer encoder-decoder. First, MiniGPT-4 is employed to generate the detailed description of the video frame and rewrite the query statement, fed into the encoder as new features. Then, semantic similarity is computed between the generated description and the rewritten queries. Finally, continuous high-similarity video frames are converted into span anchors, serving as prior position information for the decoder. Experiments demonstrate that our approach achieves a state-of-the-art result, and by using on
    
[^192]: 利用行为原语搭建任务的框架以提高数据效率的模仿学习

    PRIME: Scaffolding Manipulation Tasks with Behavior Primitives for Data-Efficient Imitation Learning

    [https://arxiv.org/abs/2403.00929](https://arxiv.org/abs/2403.00929)

    PRIME是一个基于行为原语设计的框架，通过将任务分解为原语序列并学习高级控制策略，显著提高了多阶段操作任务的性能表现。

    

    模仿学习已经显示出巨大潜力，可以让机器人学会复杂的操作行为。然而，在长期任务中，这些算法受到高样本复杂度的困扰，因为复合误差会在任务时段内累积。我们提出了PRIME（基于行为原语的数据效率模仿），这是一个基于行为原语的框架，旨在提高模仿学习的数据效率。PRIME通过将任务演示分解为原语序列来搭建机器人任务，然后通过模仿学习学习一个高级控制策略来对原语序列进行排序。我们的实验证明，PRIME在多阶段操作任务中实现了显著的性能提升，在模拟环境中的成功率比最先进的基线高出10-34％，在实际硬件上高出20-48％。

    arXiv:2403.00929v1 Announce Type: cross  Abstract: Imitation learning has shown great potential for enabling robots to acquire complex manipulation behaviors. However, these algorithms suffer from high sample complexity in long-horizon tasks, where compounding errors accumulate over the task horizons. We present PRIME (PRimitive-based IMitation with data Efficiency), a behavior primitive-based framework designed for improving the data efficiency of imitation learning. PRIME scaffolds robot tasks by decomposing task demonstrations into primitive sequences, followed by learning a high-level control policy to sequence primitives through imitation learning. Our experiments demonstrate that PRIME achieves a significant performance improvement in multi-stage manipulation tasks, with 10-34% higher success rates in simulation over state-of-the-art baselines and 20-48% on physical hardware.
    
[^193]: 直接与Chat-Fine-Tuned LLMs的草案模型对齐

    Direct Alignment of Draft Model for Speculative Decoding with Chat-Fine-Tuned LLMs

    [https://arxiv.org/abs/2403.00858](https://arxiv.org/abs/2403.00858)

    通过提出的框架，我们训练了一种用于Llama 2 Chat 7B或更大模型的草案模型，实现了加速推理，仅占原始大小的1.64％。

    

    文本生成与大型语言模型（LLMs）由于其自回归本质、巨大的参数数量和有限的内存带宽而被认为是内存密集型，通常导致低令牌速率。猜测解码已被提出作为LLM推理加速的解决方案。然而，在现代开源LLM系列中，例如Llama 2 7B，由于草案模型通常不可用，因此需要训练高质量的草案模型以通过猜测解码实现推理加速。在本文中，我们提出了一个简单的草案模型训练框架，用于直接与Chat-capable目标模型对齐。通过我们提出的框架，我们训练出Llama 2 Chat Drafter 115M，这是一个适用于Llama 2 Chat 7B或更大模型的草案模型，仅占原始大小的1.64％。我们的训练框架仅包括预训练、蒸馏数据集生成和使用知识蒸馏进行微调，没有额外的对齐步骤。

    arXiv:2403.00858v1 Announce Type: cross  Abstract: Text generation with Large Language Models (LLMs) is known to be memory bound due to the combination of their auto-regressive nature, huge parameter counts, and limited memory bandwidths, often resulting in low token rates. Speculative decoding has been proposed as a solution for LLM inference acceleration. However, since draft models are often unavailable in the modern open-source LLM families, e.g., for Llama 2 7B, training a high-quality draft model is required to enable inference acceleration via speculative decoding. In this paper, we propose a simple draft model training framework for direct alignment to chat-capable target models. With the proposed framework, we train Llama 2 Chat Drafter 115M, a draft model for Llama 2 Chat 7B or larger, with only 1.64\% of the original size. Our training framework only consists of pretraining, distillation dataset generation, and finetuning with knowledge distillation, with no additional align
    
[^194]: TV-TREES：用于神经符号视频推理的多模态蕴涵树

    TV-TREES: Multimodal Entailment Trees for Neuro-Symbolic Video Reasoning

    [https://arxiv.org/abs/2402.19467](https://arxiv.org/abs/2402.19467)

    TV-TREES是第一个多模态蕴涵树生成器，通过生成视频直接蕴涵的简单前提与高级结论之间的蕴涵关系树，实现了可解释联合模态推理，并在挑战性的TVQA数据集上展示了最先进的零-shot性能。

    

    在处理电视剪辑等复杂的多模态内容进行问答是一项具有挑战性的任务。这部分是因为当前的视频-语言模型依赖于单模态推理，在处理长输入时性能下降，并且缺乏可解释性。我们提出了TV-TREES，这是第一个多模态蕴涵树生成器。TV-TREES作为一种促进可解释联合模态推理的视频理解方法，通过生成视频直接蕴涵的简单前提与高级结论之间的蕴涵关系树。随后，我们引入了多模态蕴涵树生成任务来评估此类方法的推理质量。我们的方法在具有挑战性的TVQA数据集上的实验结果展示了可解释的、具有最先进零-shot性能的完整视频剪辑，展示了与黑盒方法相比的最佳实践。

    arXiv:2402.19467v1 Announce Type: cross  Abstract: It is challenging to perform question-answering over complex, multimodal content such as television clips. This is in part because current video-language models rely on single-modality reasoning, have lowered performance on long inputs, and lack interpetability. We propose TV-TREES, the first multimodal entailment tree generator. TV-TREES serves as an approach to video understanding that promotes interpretable joint-modality reasoning by producing trees of entailment relationships between simple premises directly entailed by the videos and higher-level conclusions. We then introduce the task of multimodal entailment tree generation to evaluate the reasoning quality of such methods. Our method's experimental results on the challenging TVQA dataset demonstrate intepretable, state-of-the-art zero-shot performance on full video clips, illustrating a best of both worlds contrast to black-box methods.
    
[^195]: 对语义变化特征的调查

    Survey in Characterization of Semantic Change

    [https://arxiv.org/abs/2402.19088](https://arxiv.org/abs/2402.19088)

    语义变化对计算语言学算法的结果质量可能会产生影响，因此重要性日益凸显。

    

    活语言不断发展，以吸纳人类社会的文化变化。这种演变通过新词语（新单词）或单词的语义变化（赋予已有单词新的含义）来体现。理解单词的含义对解释来自不同文化（地方用语或俚语）、领域（例如技术术语）或时代的文本至关重要。在计算机科学中，这些单词与计算语言学算法相关，例如翻译、信息检索、问答等。语义变化可能会影响这些算法的结果质量。因此，了解和形式化表征这些变化是很重要的。研究这种影响是计算语言学界近期引起关注的问题。几种方法提出了检测语义变化的方法，具有较高的精度，但需要更多努力来对其进行表征。

    arXiv:2402.19088v1 Announce Type: cross  Abstract: Live languages continuously evolve to integrate the cultural change of human societies. This evolution manifests through neologisms (new words) or \textbf{semantic changes} of words (new meaning to existing words). Understanding the meaning of words is vital for interpreting texts coming from different cultures (regionalism or slang), domains (e.g., technical terms), or periods. In computer science, these words are relevant to computational linguistics algorithms such as translation, information retrieval, question answering, etc. Semantic changes can potentially impact the quality of the outcomes of these algorithms. Therefore, it is important to understand and characterize these changes formally. The study of this impact is a recent problem that has attracted the attention of the computational linguistics community. Several approaches propose methods to detect semantic changes with good precision, but more effort is needed to charact
    
[^196]: ICE-SEARCH: 一种基于语言模型驱动的特征选择方法

    ICE-SEARCH: A Language Model-Driven Feature Selection Approach

    [https://arxiv.org/abs/2402.18609](https://arxiv.org/abs/2402.18609)

    ICE-SEARCH是首个将语言模型与进化算法相结合用于特征选择任务的方法，在医学预测分析应用中取得了State-of-the-Art(SOTA)表现。

    

    本研究揭示了In-Context Evolutionary Search (ICE-SEARCH)方法，这是首个将语言模型(LMs)与进化算法相结合用于特征选择(FS)任务的工作，并展示了其在医学预测分析(MPA)应用中的有效性。ICE-SEARCH利用语言模型中固有的交叉和突变能力，在一个进化框架内显着改进特征选择，通过模型的全面世界知识和其适应各种角色的能力。我们对该方法的评估涵盖了三个关键的MPA任务：中风、心血管疾病和糖尿病，在这些任务中ICE-SEARCH在确定医学应用的关键特征方面优于传统的FS方法。ICE-SEARCH在中风预测和糖尿病预测中实现了领先水平；决策随机化ICE-SEARCH在心血管疾病预测中排名为领先水平。我们的结果不仅证明了

    arXiv:2402.18609v1 Announce Type: cross  Abstract: This study unveils the In-Context Evolutionary Search (ICE-SEARCH) method, the first work that melds language models (LMs) with evolutionary algorithms for feature selection (FS) tasks and demonstrates its effectiveness in Medical Predictive Analytics (MPA) applications. ICE-SEARCH harnesses the crossover and mutation capabilities inherent in LMs within an evolutionary framework, significantly improving FS through the model's comprehensive world knowledge and its adaptability to a variety of roles. Our evaluation of this methodology spans three crucial MPA tasks: stroke, cardiovascular disease, and diabetes, where ICE-SEARCH outperforms traditional FS methods in pinpointing essential features for medical applications. ICE-SEARCH achieves State-of-the-Art (SOTA) performance in stroke prediction and diabetes prediction; the Decision-Randomized ICE-SEARCH ranks as SOTA in cardiovascular disease prediction. Our results not only demonstrate
    
[^197]: MMSR：符号回归是一个多模态任务

    MMSR: Symbolic Regression is a Multimodal Task

    [https://arxiv.org/abs/2402.18603](https://arxiv.org/abs/2402.18603)

    符号回归被视为一个多模态任务，研究人员将数据到表达式的映射视为翻译问题，引入大规模预训练模型。

    

    数学公式是探索自然规律几千年来人类智慧的结晶。用简洁的数学公式描述复杂的自然规律是科学家不断追求的目标，也是人工智能面临的重大挑战。这一领域被称为符号回归。在本文中，研究人员将从数据到表达式的映射视为翻译问题，并引入了相应的大规模预训练模型。

    arXiv:2402.18603v1 Announce Type: cross  Abstract: Mathematical formulas are the crystallization of human wisdom in exploring the laws of nature for thousands of years. Describing the complex laws of nature with a concise mathematical formula is a constant pursuit of scientists and a great challenge for artificial intelligence. This field is called symbolic regression. Symbolic regression was originally formulated as a combinatorial optimization problem, and GP and reinforcement learning algorithms were used to solve it. However, GP is sensitive to hyperparameters, and these two types of algorithms are inefficient. To solve this problem, researchers treat the mapping from data to expressions as a translation problem. And the corresponding large-scale pre-trained model is introduced. However, the data and expression skeletons do not have very clear word correspondences as the two languages do. Instead, they are more like two modalities (e.g., image and text). Therefore, in this paper, w
    
[^198]: LDB：通过逐步验证运行时执行来调试大型语言模型

    LDB: A Large Language Model Debugger via Verifying Runtime Execution Step-by-step

    [https://arxiv.org/abs/2402.16906](https://arxiv.org/abs/2402.16906)

    LDB是一个新颖的调试框架，可以让大型语言模型通过运行时执行信息来完善生成的程序。

    

    大型语言模型（LLMs）在代码生成方面取得了重大进展。最近的研究不仅将单次代码生成，而且还将单元测试和程序验证器整合到LLMs中，以迭代地完善生成的程序。然而，这些工作将生成的程序视为不可分割的实体，这对LLMs在调试程序时存在不足，特别是当程序包含复杂的逻辑流程和数据操作时。相比之下，当人类开发人员调试程序时，他们通常设置断点并有选择地检查运行时执行信息。执行流和中间变量在调试过程中发挥着关键作用，然而现有的代码生成文献中未充分利用它们。本研究引入了大型语言模型调试器（LDB），这是一个新颖的调试框架，可以让LLMs通过运行时执行信息完善其生成的程序。

    arXiv:2402.16906v1 Announce Type: cross  Abstract: Large language models (LLMs) are leading significant progress in code generation. Beyond one-pass code generation, recent works further integrate unit tests and program verifiers into LLMs to iteratively refine the generated programs. However, these works consider the generated programs as an indivisible entity, which falls short for LLMs in debugging the programs, especially when the programs contain complex logic flows and data operations. In contrast, when human developers debug programs, they typically set breakpoints and selectively examine runtime execution information. The execution flow and the intermediate variables play a crucial role in the debugging process, yet they are underutilized in the existing literature on code generation. In this study, we introduce Large Language Model Debugger (LDB), a novel debugging framework that enables LLMs to refine their generated programs with the runtime execution information. Specifical
    
[^199]: MIM-Reasoner: 具有理论保证的多重影响最大化学习

    MIM-Reasoner: Learning with Theoretical Guarantees for Multiplex Influence Maximization

    [https://arxiv.org/abs/2402.16898](https://arxiv.org/abs/2402.16898)

    引入了MIM-Reasoner，结合强化学习和概率图模型，有效地捕捉了给定多重网络内部和层间的复杂传播过程，从而解决了MIM中最具挑战性的问题。

    

    多重影响最大化（MIM）要求我们识别一组种子用户，以最大化多重网络中受影响用户的预期数量。本文介绍了MIM-Reasoner，将强化学习与概率图模型相结合，有效捕捉给定多重网络内部和层间的复杂传播过程，从而解决了MIM中最具挑战性的问题。

    arXiv:2402.16898v1 Announce Type: cross  Abstract: Multiplex influence maximization (MIM) asks us to identify a set of seed users such as to maximize the expected number of influenced users in a multiplex network. MIM has been one of central research topics, especially in nowadays social networking landscape where users participate in multiple online social networks (OSNs) and their influences can propagate among several OSNs simultaneously. Although there exist a couple combinatorial algorithms to MIM, learning-based solutions have been desired due to its generalization ability to heterogeneous networks and their diversified propagation characteristics. In this paper, we introduce MIM-Reasoner, coupling reinforcement learning with probabilistic graphical model, which effectively captures the complex propagation process within and between layers of a given multiplex network, thereby tackling the most challenging problem in MIM. We establish a theoretical guarantee for MIM-Reasoner as w
    
[^200]: LLM推断揭示：调查与Roofline模型见解

    LLM Inference Unveiled: Survey and Roofline Model Insights

    [https://arxiv.org/abs/2402.16363](https://arxiv.org/abs/2402.16363)

    本文提出了一个基于Roofline模型的框架，用于系统分析LLM推断技术，帮助识别部署中的瓶颈，并为更有效地部署LLM提供策略。

    

    高效大语言模型（LLM）推断领域正在迅速发展，提供了机遇和挑战的独特结合。虽然该领域已经扩展并充满活力，但至今还没有一个简明的框架来分析LLM推断的各种方法，以便清晰地理解这一领域。我们的调查不仅总结了当前研究现状，还基于Roofline模型引入了一个框架，用于系统分析LLM推断技术。这一框架能够帮助识别LLM部署中的瓶颈，并更深入地了解在实际设备上的实际方面，从而为部署LLM提供更有效的策略。此外，我们还系统地汇总了高效LLM推断的最新进展，涵盖关键领域，比如权重优化（如知识蒸馏和量化）。

    arXiv:2402.16363v1 Announce Type: cross  Abstract: The field of efficient Large Language Model (LLM) inference is rapidly evolving, presenting a unique blend of opportunities and challenges. Although the field has expanded and is vibrant, there hasn't been a concise framework that analyzes the various methods of LLM Inference to provide a clear understanding of this domain. Our survey stands out from traditional literature reviews by not only summarizing the current state of research but also by introducing a framework based on roofline model for systematic analysis of LLM inference techniques. This framework enables identifying the bottlenecks in LLM deployments and provides a deeper understanding of the practical aspects on real devices, thereby informing more effective strategies for deploying LLM. Furthermore, we systematically collate the latest advancements in efficient LLM inference, covering crucial areas such as weight optimization (e.g., Knowledge Distillation and Quantizatio
    
[^201]: 一种使用注释嵌入模型的本体包含关系预测自匹配训练方法

    A Self-matching Training Method with Annotation Embedding Models for Ontology Subsumption Prediction

    [https://arxiv.org/abs/2402.16278](https://arxiv.org/abs/2402.16278)

    提出了一种自匹配训练方法，通过两种本体嵌入模型捕获全局和局部信息，提高了概念子类预测的稳健性

    

    最近，提出了一种在低维空间中表示实体的本体嵌入，用于本体完成。然而，用于概念子类预测的本体嵌入未解决类似和孤立实体的困难，并且未提取本体中注释公理的全局信息。本文提出了一种针对两种本体嵌入模型的自匹配训练方法：Inverted-index Matrix Embedding (InME) 和 Co-occurrence Matrix Embedding (CoME)。这两种嵌入通过每个单词在一组公理中出现的位置以及每个公理中单词的共现来捕获注释公理中的全局和局部信息。自匹配训练方法提高了概念子类预测的稳健性，当预测的超类与子类相似且孤立于本体中的其他实体时。

    arXiv:2402.16278v1 Announce Type: new  Abstract: Recently, ontology embeddings representing entities in a low-dimensional space have been proposed for ontology completion. However, the ontology embeddings for concept subsumption prediction do not address the difficulties of similar and isolated entities and fail to extract the global information of annotation axioms from an ontology. In this paper, we propose a self-matching training method for the two ontology embedding models: Inverted-index Matrix Embedding (InME) and Co-occurrence Matrix Embedding (CoME). The two embeddings capture the global and local information in annotation axioms by means of the occurring locations of each word in a set of axioms and the co-occurrences of words in each axiom. The self-matching training method increases the robustness of the concept subsumption prediction when predicted superclasses are similar to subclasses and are isolated to other entities in an ontology. Our evaluation experiments show that
    
[^202]: 使用深度学习技术在短英文文本中进行情绪分类

    Emotion Classification in Short English Texts using Deep Learning Techniques

    [https://arxiv.org/abs/2402.16034](https://arxiv.org/abs/2402.16034)

    该研究使用深度学习技术在短英文文本中识别情绪，发现基于迁移学习和BERT的文本嵌入方法在分类准确性上表现优异。

    

    从资源匮乏的语言中的有限文本数据集中检测情绪是一项严峻的挑战，需要专门的框架和计算策略。本研究对使用深度学习技术在短英文文本中识别情绪进行了彻底的研究。深度学习方法采用迁移学习和词嵌入，特别是BERT，以获得更高的准确性。为了评估这些方法，我们引入了“SmallEnglishEmotions”数据集，该数据集包含6372个带有五种主要情绪类别注释的不同短波斯文本。我们的实验表明，迁移学习和基于BERT的文本嵌入在准确分类数据集中的文本方面优于替代方法。

    arXiv:2402.16034v1 Announce Type: cross  Abstract: Detecting emotions in limited text datasets from under-resourced languages presents a formidable obstacle, demanding specialized frameworks and computational strategies. This study conducts a thorough examination of deep learning techniques for discerning emotions in short English texts. Deep learning approaches employ transfer learning and word embedding, notably BERT, to attain superior accuracy. To evaluate these methods, we introduce the "SmallEnglishEmotions" dataset, comprising 6372 varied short Persian texts annotated with five primary emotion categories. Our experiments reveal that transfer learning and BERT-based text embedding outperform alternative methods in accurately categorizing the text in the dataset.
    
[^203]: 随机图集和证据模式推理模型

    Random Graph Set and Evidence Pattern Reasoning Model

    [https://arxiv.org/abs/2402.13058](https://arxiv.org/abs/2402.13058)

    提出了证据模式推理模型（EPRM）以更好地符合决策目标，引入随机图集（RGS）来模拟复杂关系并表示更多事件类型。

    

    证据理论在决策和推理系统中被广泛使用。以往的研究中，转移信念模型（TBM）是常用的证据决策模型，但TBM是一个非偏好模型。为了更好地符合决策目标，提出了证据模式推理模型（EPRM）。通过定义模式运算符和决策运算符，可以为不同任务设置相应的偏好。随机排列集（RPS）为证据理论扩展了顺序信息。RPS很难刻画样本之间的复杂关系，如循环、并行关系。因此，提出了随机图集（RGS）来模拟复杂关系并表示更多事件类型。为了说明RGS和EPRM的重要性，设计了一项飞机速度排序实验，并模拟了10,000个案例。EPRM的实现称为冲突解决Dec

    arXiv:2402.13058v1 Announce Type: new  Abstract: Evidence theory is widely used in decision-making and reasoning systems. In previous research, Transferable Belief Model (TBM) is a commonly used evidential decision making model, but TBM is a non-preference model. In order to better fit the decision making goals, the Evidence Pattern Reasoning Model (EPRM) is proposed. By defining pattern operators and decision making operators, corresponding preferences can be set for different tasks. Random Permutation Set (RPS) expands order information for evidence theory. It is hard for RPS to characterize the complex relationship between samples such as cycling, paralleling relationships. Therefore, Random Graph Set (RGS) were proposed to model complex relationships and represent more event types. In order to illustrate the significance of RGS and EPRM, an experiment of aircraft velocity ranking was designed and 10,000 cases were simulated. The implementation of EPRM called Conflict Resolution Dec
    
[^204]: Me LLaMA: 为医疗应用构建大型语言模型的基础

    Me LLaMA: Foundation Large Language Models for Medical Applications

    [https://arxiv.org/abs/2402.12749](https://arxiv.org/abs/2402.12749)

    Me LLaMA是一个医学领域的大型语言模型系列，通过持续预训练和指导调整在大型医学数据集上训练而成，其在零-shot和少-shot学习方面表现优于现有的医学语言模型和商业巨头ChatGPT。

    

    最近，诸如ChatGPT和LLaMA等大型语言模型(LLMs)在许多人工智能应用中展现出巨大的潜力。然而，它们在医学任务上的表现不够理想，并且可以通过在大型领域特定数据集上进行训练来进一步改进。本研究引入了Me LLaMA，一个医学LLM系列，包括基础模型- Me LLaMA 13/70B及其 chat-enhanced 版本- Me LLaMA 13/70B-chat，通过持续对LLaMA2进行预训练和指导调整，使用大规模医学数据开发而成。我们用于训练和评估的领域特定数据套件包括一个具有129B tokens的大规模持续预训练数据集，一个包含214k个样本的指导调整数据集，以及跨越14个数据集的六项任务的医学评估基准(MIBE)。我们使用MIBE进行的广泛评估显示，Me LLaMA模型在零-shot和少-shot学习方面超越了现有的开源医学LLMs，并且在商业巨头如ChatGPT上表现出色。

    arXiv:2402.12749v1 Announce Type: cross  Abstract: Recent large language models (LLMs) like ChatGPT and LLaMA have shown great promise in many AI applications. However, their performance on medical tasks is suboptimal and can be further improved by training on large domain-specific datasets. This study introduces Me LLaMA, a medical LLM family including foundation models - Me LLaMA 13/70B and their chat-enhanced versions - Me LLaMA 13/70B-chat, developed through the continual pre-training and instruction tuning of LLaMA2 using large medical data. Our domain-specific data suite for training and evaluation, includes a large-scale continual pre-training dataset with 129B tokens, an instruction tuning dataset with 214k samples, and a medical evaluation benchmark (MIBE) across six tasks with 14 datasets. Our extensive evaluation using MIBE shows that Me LLaMA models surpass existing open-source medical LLMs in zero-shot and few-shot learning and outperform commercial giants like ChatGPT on 
    
[^205]: 通过纯微调进行模型编辑

    Model Editing by Pure Fine-Tuning

    [https://arxiv.org/abs/2402.11078](https://arxiv.org/abs/2402.11078)

    纯微调通过优化条件似然、增加随机释义和事实的数据，在模型编辑中取得了不俗的表现。

    

    精细调整被认为在模型编辑中不够有效，因为相对更专业的方法而言，它的表现较差。然而，微调是简单的，不关心被编辑模型的体系结构细节，并且能够利用标准训练方法的不断进展（例如PEFT），使其成为模型编辑器的吸引选择。在本文中，我们展示了纯粹的微调可以是一种可行的模型编辑方法。我们提出了对朴素微调进行轻微修改的两个关键因素。第一，我们优化条件似然而非完整似然。第二，我们使用随机释义和事实来增加数据，以鼓励泛化和局部性。我们在ZsRE和CounterFact上的实验表明，这一简单修改使得微调通常可以与专业编辑器在编辑分数方面匹敌甚至超越。

    arXiv:2402.11078v1 Announce Type: cross  Abstract: Fine-tuning is dismissed as not effective for model editing due to its poor performance compared to more specialized methods. However, fine-tuning is simple, agnostic to the architectural details of the model being edited, and able to leverage ongoing advances in standard training methods (e.g., PEFT), making it an appealing choice for a model editor. In this work, we show that pure fine-tuning can be a viable approach to model editing. We propose a slight modification of naive fine-tuning with two key ingredients. First, we optimize the conditional likelihood rather than the full likelihood. Second, we augment the data with random paraphrases and facts to encourage generalization and locality. Our experiments on ZsRE and CounterFact show that this simple modification allows fine-tuning to often match or outperform specialized editors in the edit score.
    
[^206]: 与遗忘呼应的解除链接：简化GNN中的边解除

    Unlink to Unlearn: Simplifying Edge Unlearning in GNNs

    [https://arxiv.org/abs/2402.10695](https://arxiv.org/abs/2402.10695)

    研究揭示了GNN中边解除过程的关键问题，即过度遗忘现象，提出了解决方法来解决损失函数引起的问题。

    

    随着对数据隐私的担忧加剧，图神经网络（GNN）中的解除学习已经成为学术界一个突出的研究前沿。这一概念在强调被遗忘权利方面起着关键作用，包括在用户请求时有选择性地从已训练的GNN中删除特定数据。我们的研究关注边的解除学习，这一过程对现实应用特别相关，因为它具有广泛的适用性。目前的最先进方法如GNNDelete可以消除特定边的影响，然而我们的研究揭示了这些方法的一个关键局限，称为过度遗忘。当解除学习过程无意中除去超出特定数据的过多信息时，会导致对剩余边的预测准确性显著下降。为了解决这个问题，我们确定了GNNDelete的损失函数作为过度遗忘现象的主要来源。

    arXiv:2402.10695v1 Announce Type: cross  Abstract: As concerns over data privacy intensify, unlearning in Graph Neural Networks (GNNs) has emerged as a prominent research frontier in academia. This concept is pivotal in enforcing the right to be forgotten, which entails the selective removal of specific data from trained GNNs upon user request. Our research focuses on edge unlearning, a process of particular relevance to real-world applications, owing to its widespread applicability. Current state-of-the-art approaches like GNNDelete can eliminate the influence of specific edges, yet our research has revealed a critical limitation in these approaches, termed over-forgetting. It occurs when the unlearning process inadvertently removes excessive information beyond specific data, leading to a significant decline in prediction accuracy for the remaining edges. To address this issue, we have identified the loss functions of GNNDelete as the primary source of the over-forgetting phenomenon. 
    
[^207]: 引导遮蔽表示学习以捕捉心电图的时空关系

    Guiding Masked Representation Learning to Capture Spatio-Temporal Relationship of Electrocardiogram

    [https://arxiv.org/abs/2402.09450](https://arxiv.org/abs/2402.09450)

    本研究提出了一种叫做ST-MEM的模型，通过重构遮蔽的心电图数据来学习时空特征，该模型在心律失常分类任务中优于其他自监督学习方法。

    

    心电图（ECG）广泛用作监测心脏起源的电信号的诊断工具。近年来，机器学习的研究努力集中在使用ECG信号进行各种疾病筛查的应用上。然而，适应疾病筛查应用是具有挑战性的，因为标记的ECG数据有限。通过自监督学习（SSL）实现通用表示是克服标记数据稀缺性的常用方法；然而，在ECG数据上纯粹应用SSL，而不考虑ECG信号固有的时空关系，可能会产生次优的结果。本文介绍了ST-MEM（时空遮蔽心电图建模），该模型通过重构遮蔽的12导联ECG数据来学习时空特征。在各种实验设置中，ST-MEM在心律失常分类任务中的性能优于其他SSL基线方法。

    arXiv:2402.09450v1 Announce Type: cross  Abstract: Electrocardiograms (ECG) are widely employed as a diagnostic tool for monitoring electrical signals originating from a heart. Recent machine learning research efforts have focused on the application of screening various diseases using ECG signals. However, adapting to the application of screening disease is challenging in that labeled ECG data are limited. Achieving general representation through self-supervised learning (SSL) is a well-known approach to overcome the scarcity of labeled data; however, a naive application of SSL to ECG data, without considering the spatial-temporal relationships inherent in ECG signals, may yield suboptimal results. In this paper, we introduce ST-MEM (Spatio-Temporal Masked Electrocardiogram Modeling), designed to learn spatio-temporal features by reconstructing masked 12-lead ECG data. ST-MEM outperforms other SSL baseline methods in various experimental settings for arrhythmia classification tasks. Mo
    
[^208]: 论文竞标中检测作者与审稿人勾结的方法研究

    On the Detection of Reviewer-Author Collusion Rings From Paper Bidding

    [https://arxiv.org/abs/2402.07860](https://arxiv.org/abs/2402.07860)

    本文研究了如何从论文竞标中检测勾结团体，以解决同行评审系统中的欺诈问题。

    

    计算机科学会议的同行评审系统面临的主要威胁是审稿人之间存在的"勾结团体"。在这种勾结团体中，提交了自己的论文的审稿人合作，试图通过操纵会议的论文分配，以便被指派为彼此论文的审稿人。纵观现有的研究，虽然已经发展出了有效的技术来检测其他种类的欺诈行为，但尚未有研究证明检测勾结团体的可能性。本研究解决了如何从论文竞标中检测勾结团体的问题。

    A major threat to the peer-review systems of computer science conferences is the existence of "collusion rings" between reviewers. In such collusion rings, reviewers who have also submitted their own papers to the conference work together to manipulate the conference's paper assignment, with the aim of being assigned to review each other's papers. The most straightforward way that colluding reviewers can manipulate the paper assignment is by indicating their interest in each other's papers through strategic paper bidding. One potential approach to solve this important problem would be to detect the colluding reviewers from their manipulated bids, after which the conference can take appropriate action. While prior work has has developed effective techniques to detect other kinds of fraud, no research has yet established that detecting collusion rings is even possible. In this work, we tackle the question of whether it is feasible to detect collusion rings from the paper bidding. To answ
    
[^209]: 带风险最小化的分组分布鲁棒数据集蒸馏

    Group Distributionally Robust Dataset Distillation with Risk Minimization

    [https://arxiv.org/abs/2402.04676](https://arxiv.org/abs/2402.04676)

    这项研究关注数据集蒸馏与其泛化能力的关系，尤其是在面对不常见的子组的样本时，如何确保模型在合成数据集上的训练可以表现良好。

    

    数据集蒸馏（DD）已成为一种广泛采用的技术，用于构建一个合成数据集，该数据集在捕捉训练数据集的基本信息方面起到重要作用，从而方便准确训练神经模型。其应用涵盖了转移学习、联邦学习和神经架构搜索等各个领域。构建合成数据的最流行方法依赖于使模型在合成数据集和训练数据集上的收敛性能相匹配。然而，目标是将训练数据集视为辅助，就像训练集是人口分布的近似替代品一样，而后者才是我们感兴趣的数据。尽管其受欢迎程度很高，但尚未探索的一个方面是DD与其泛化能力的关系，特别是跨不常见的子组。也就是说，当面对来自罕见子组的样本时，我们如何确保在合成数据集上训练的模型表现良好。

    Dataset distillation (DD) has emerged as a widely adopted technique for crafting a synthetic dataset that captures the essential information of a training dataset, facilitating the training of accurate neural models. Its applications span various domains, including transfer learning, federated learning, and neural architecture search. The most popular methods for constructing the synthetic data rely on matching the convergence properties of training the model with the synthetic dataset and the training dataset. However, targeting the training dataset must be thought of as auxiliary in the same sense that the training set is an approximate substitute for the population distribution, and the latter is the data of interest. Yet despite its popularity, an aspect that remains unexplored is the relationship of DD to its generalization, particularly across uncommon subgroups. That is, how can we ensure that a model trained on the synthetic dataset performs well when faced with samples from re
    
[^210]: 大语言模型代理能够模拟人类的信任行为吗？

    Can Large Language Model Agents Simulate Human Trust Behaviors?

    [https://arxiv.org/abs/2402.04559](https://arxiv.org/abs/2402.04559)

    大语言模型代理能够模拟人类的信任行为，表现出在信任游戏中的信任行为，并且与人类行为具有高度一致性，但存在一些偏见和对代理与人类的差异。

    

    大语言模型（LLM）代理已经越来越多地被采用作为模拟工具，用于模拟人类在社会科学等领域中的行为。然而，一个基本的问题仍然存在：LLM代理是否真的能够模拟人类行为？在本文中，我们专注于人类互动中最关键的行为之一，信任，旨在调查LLM代理是否能够模拟人类的信任行为。我们首先发现，在被行为经济学广泛接受的信任游戏框架下，LLM代理通常表现出信任行为，称为代理信任。然后，我们发现LLM代理在信任行为方面与人类具有较高的行为一致性，表明使用LLM代理模拟人类的信任行为是可行的。此外，我们还探索了代理信任中的偏见以及代理信任在对代理和人类之间的差异方面的内在特性。我们还探讨了包括高级推理策略在内的条件下代理信任的内在特性。

    Large Language Model (LLM) agents have been increasingly adopted as simulation tools to model humans in applications such as social science. However, one fundamental question remains: can LLM agents really simulate human behaviors? In this paper, we focus on one of the most critical behaviors in human interactions, trust, and aim to investigate whether or not LLM agents can simulate human trust behaviors. We first find that LLM agents generally exhibit trust behaviors, referred to as agent trust, under the framework of Trust Games, which are widely recognized in behavioral economics. Then, we discover that LLM agents can have high behavioral alignment with humans regarding trust behaviors, indicating the feasibility to simulate human trust behaviors with LLM agents. In addition, we probe into the biases in agent trust and the differences in agent trust towards agents and humans. We also explore the intrinsic properties of agent trust under conditions including advanced reasoning strate
    
[^211]: 利用Swin Transformer进行从局部到全局的弱监督语义分割

    Leveraging Swin Transformer for Local-to-Global Weakly Supervised Semantic Segmentation

    [https://arxiv.org/abs/2401.17828](https://arxiv.org/abs/2401.17828)

    本研究利用Swin Transformer提出了"SWTformer"，通过从局部到全局的视角来增强弱监督语义分割的准确性。

    

    最近几年，利用图像级标签作为监督的弱监督语义分割在计算机视觉领域引起了极大关注。大多数现有方法通过从类激活图(CAM)中生成伪标签来解决这些标签中缺乏空间信息的挑战。由于卷积神经网络(CNNs)的局部模式检测，CAMs通常只强调对象的最具区分度的部分，使得准确区分前景对象与背景以及彼此之间变得困难。最近的研究表明，由于其全局视角，Vision Transformer (ViT)特征在捕捉场景布局方面比CNNs更有效。然而，层次化的ViTs在该领域中的应用尚未得到广泛探索。本文通过提出“SWTformer”来探索使用Swin Transformer来提高初始准确性。

    In recent years, weakly supervised semantic segmentation using image-level labels as supervision has received significant attention in the field of computer vision. Most existing methods have addressed the challenges arising from the lack of spatial information in these labels by focusing on facilitating supervised learning through the generation of pseudo-labels from class activation maps (CAMs). Due to the localized pattern detection of Convolutional Neural Networks (CNNs), CAMs often emphasize only the most discriminative parts of an object, making it challenging to accurately distinguish foreground objects from each other and the background. Recent studies have shown that Vision Transformer (ViT) features, due to their global view, are more effective in capturing the scene layout than CNNs. However, the use of hierarchical ViTs has not been extensively explored in this field. This work explores the use of Swin Transformer by proposing "SWTformer" to enhance the accuracy of the init
    
[^212]: 使用深度学习进行局部特征匹配：一项调查

    Local Feature Matching Using Deep Learning: A Survey

    [https://arxiv.org/abs/2401.17592](https://arxiv.org/abs/2401.17592)

    本文调查了使用深度学习进行局部特征匹配的方法。局部特征匹配在计算机视觉中的各个领域具有广泛应用，但是由于视角和光照变化等因素，匹配的准确性和鲁棒性仍然存在挑战。近年来，深度学习模型的引入使得局部特征匹配技术得到了广泛研究。本文对局部特征匹配方法进行了全面概述，并对之前的工作进行了评估。

    

    局部特征匹配在计算机视觉领域中具有广泛的应用，包括图像检索、三维重建和物体识别等领域。然而，由于视角和光照变化等因素，提高匹配的准确性和鲁棒性仍然面临挑战。近年来，深度学习模型的引入引发了局部特征匹配技术的广泛探索。本文旨在提供局部特征匹配方法的全面概述。这些方法基于是否存在检测器被分为两个主要类别。基于检测器的类别包括检测然后描述、联合检测和描述、描述然后检测以及基于图的技术。相反，不需要检测器的类别包括基于CNN的方法、基于Transformer的方法和基于块的方法。我们的研究超越了方法论分析，还包括对先前工作的评估。

    Local feature matching enjoys wide-ranging applications in the realm of computer vision, encompassing domains such as image retrieval, 3D reconstruction, and object recognition. However, challenges persist in improving the accuracy and robustness of matching due to factors like viewpoint and lighting variations. In recent years, the introduction of deep learning models has sparked widespread exploration into local feature matching techniques. The objective of this endeavor is to furnish a comprehensive overview of local feature matching methods. These methods are categorized into two key segments based on the presence of detectors. The Detector-based category encompasses models inclusive of Detect-then-Describe, Joint Detection and Description, Describe-then-Detect, as well as Graph Based techniques. In contrast, the Detector-free category comprises CNN Based, Transformer Based, and Patch Based methods. Our study extends beyond methodological analysis, incorporating evaluations of prev
    
[^213]: 大型语言模型中的时间箭头

    Arrows of Time for Large Language Models

    [https://arxiv.org/abs/2401.17505](https://arxiv.org/abs/2401.17505)

    这篇论文通过研究自回归大型语言模型的时间方向性，发现了模型在建模自然语言能力上存在时间上的不对称性。从信息理论的角度来看，这种差异理论上是不应该存在的。通过稀疏性和计算复杂性的考虑，提供了一个理论框架来解释这种不对称性的出现。

    

    我们通过时间方向性的视角研究了自回归大型语言模型的概率建模。我们在实证上发现这类模型在建模自然语言能力上存在时间上的不对称性：预测下一个记号和预测前一个记号时的平均对数困惑度存在差异。这种差异既微妙又在不同的模态（语言、模型大小、训练时间等）下非常一致。从信息理论的角度来看，这在理论上是令人惊讶的，不应该存在这样的差异。我们提供了一个理论框架，解释了这种不对称性如何出现在稀疏性和计算复杂性考虑中，并概述了我们的结果带来的一些展望。

    We study the probabilistic modeling performed by Autoregressive Large Language Models through the angle of time directionality. We empirically find a time asymmetry exhibited by such models in their ability to model natural language: a difference in the average log-perplexity when trying to predict the next token versus when trying to predict the previous one. This difference is at the same time subtle and very consistent across various modalities (language, model size, training time, ...). Theoretically, this is surprising: from an information-theoretic point of view, there should be no such difference. We provide a theoretical framework to explain how such an asymmetry can appear from sparsity and computational complexity considerations, and outline a number of perspectives opened by our results.
    
[^214]: 对净化的对抗训练（AToP）：提升鲁棒性和泛化性能

    Adversarial Training on Purification (AToP): Advancing Both Robustness and Generalization

    [https://arxiv.org/abs/2401.16352](https://arxiv.org/abs/2401.16352)

    提出了一种新的对净化的对抗训练（AToP）流程，通过随机转换的扰动破坏和通过对抗损失微调净化器模型，同时提升了鲁棒性和泛化性能。

    

    深度神经网络被认为易受设计精良的对抗攻击影响。基于对抗训练（AT）的最成功防御技术可以实现特定攻击下的最佳鲁棒性，但无法很好地泛化到未知攻击。基于对抗净化（AP）的另一有效防御技术可以增强泛化性能，但无法实现最佳鲁棒性。与此同时，这两种方法都存在一个共同的局限性，即标准准确性降级。为了缓解这些问题，我们提出了一种新的流程，称为对净化的对抗训练（AToP），包括两个组件：通过随机转换（RT）破坏扰动，以避免对已知攻击的过度学习，从而实现对未知攻击的鲁棒性泛化；以及通过对抗损失对净化器模型进行微调（FT），以提高鲁棒性。为了评估我们的方法，我们在一种...

    arXiv:2401.16352v2 Announce Type: replace-cross  Abstract: The deep neural networks are known to be vulnerable to well-designed adversarial attacks. The most successful defense technique based on adversarial training (AT) can achieve optimal robustness against particular attacks but cannot generalize well to unseen attacks. Another effective defense technique based on adversarial purification (AP) can enhance generalization but cannot achieve optimal robustness. Meanwhile, both methods share one common limitation on the degraded standard accuracy. To mitigate these issues, we propose a novel pipeline called Adversarial Training on Purification (AToP), which comprises two components: perturbation destruction by random transforms (RT) and purifier model fine-tuned (FT) by adversarial loss. RT is essential to avoid overlearning to known attacks resulting in the robustness generalization to unseen attacks and FT is essential for the improvement of robustness. To evaluate our method in an e
    
[^215]: 3D目标检测中的大感知域策略和重要特征提取策略

    Large receptive field strategy and important feature extraction strategy in 3D object detection

    [https://arxiv.org/abs/2401.11913](https://arxiv.org/abs/2401.11913)

    提出了动态特征融合模块（DFFM）来扩展3D卷积核的感知域，并使用特征选择模块（FSM）定量评估和消除不重要的特征。

    

    3D目标检测的增强对于自动驾驶中精确环境感知和改进任务执行能力至关重要。激光雷达点云提供准确的深度信息，被用作此目的的关键信息。我们的研究专注于3D目标检测中的关键挑战。为解决扩展3D卷积核感知域的挑战，我们引入了动态特征融合模块（DFFM）。该模块实现了3D卷积核感知域的自适应扩展，平衡了扩展与可接受的计算负载。这一创新减少了操作，扩展了感知域，并允许模型动态调整以适应不同的对象需求。同时，我们识别了3D特征中的冗余信息。使用特征选择模块（FSM）定量评估并消除不重要的特征，实现了

    arXiv:2401.11913v2 Announce Type: replace-cross  Abstract: The enhancement of 3D object detection is pivotal for precise environmental perception and improved task execution capabilities in autonomous driving. LiDAR point clouds, offering accurate depth information, serve as a crucial information for this purpose. Our study focuses on key challenges in 3D target detection. To tackle the challenge of expanding the receptive field of a 3D convolutional kernel, we introduce the Dynamic Feature Fusion Module (DFFM). This module achieves adaptive expansion of the 3D convolutional kernel's receptive field, balancing the expansion with acceptable computational loads. This innovation reduces operations, expands the receptive field, and allows the model to dynamically adjust to different object requirements. Simultaneously, we identify redundant information in 3D features. Employing the Feature Selection Module (FSM) quantitatively evaluates and eliminates non-important features, achieving the 
    
[^216]: 欧盟法律中的生成式人工智能：责任、隐私、知识产权和网络安全

    Generative AI in EU Law: Liability, Privacy, Intellectual Property, and Cybersecurity

    [https://arxiv.org/abs/2401.07348](https://arxiv.org/abs/2401.07348)

    生成式人工智能和大型语言模型在欧盟法律法规中的应用引发了责任、隐私、知识产权和网络安全等方面的挑战，本文对现有和拟议的法律进行了批判性分析，并提出了改进建议。

    

    生成式人工智能的出现，特别是通过大型语言模型（LLMs）如ChatGPT及其后继模型，标志着人工智能领域的一次范式转变。先进的LLMs表现出多模态性，能处理多样化的数据格式，从而拓宽了它们的应用范围。然而，这些模型的复杂性和新兴自治性引入了预测性和法律遵从性方面的挑战。本文深入探讨了生成式人工智能和LLMs在欧盟背景下的法律和监管影响，分析了责任、隐私、知识产权和网络安全等方面。它批判性地审视了现有和拟议的欧盟立法（包括《人工智能法》草案）在应对生成式人工智能普遍和LLMs特别挑战方面的充分性。本文确定了立法框架中的潜在差距和不足，并提出建议以确保

    arXiv:2401.07348v2 Announce Type: replace-cross  Abstract: The advent of Generative AI, particularly through Large Language Models (LLMs) like ChatGPT and its successors, marks a paradigm shift in the AI landscape. Advanced LLMs exhibit multimodality, handling diverse data formats, thereby broadening their application scope. However, the complexity and emergent autonomy of these models introduce challenges in predictability and legal compliance. This paper delves into the legal and regulatory implications of Generative AI and LLMs in the European Union context, analyzing aspects of liability, privacy, intellectual property, and cybersecurity. It critically examines the adequacy of the existing and proposed EU legislation, including the Artificial Intelligence Act (AIA) draft, in addressing the unique challenges posed by Generative AI in general and LLMs in particular. The paper identifies potential gaps and shortcomings in the legislative framework and proposes recommendations to ensur
    
[^217]: 思维状态机：利用过去推理轨迹增强问题解决能力

    State Machine of Thoughts: Leveraging Past Reasoning Trajectories for Enhancing Problem Solving

    [https://arxiv.org/abs/2312.17445](https://arxiv.org/abs/2312.17445)

    通过利用过去推理轨迹的经验，提出的思维状态机（SMoT）可以显著改善问题解决能力，选择最优解决方案并避免错误的解决方案。

    

    基于当前大型语言模型的代理程序常常以一种类似树状的方式在探索-评估框架内推理，导航问题解决过程。然而，这些方法经常忽略一旦问题解决就可以舍弃的成功推理轨迹，从而导致这些轨迹在未来类似问题中被低效利用。为了解决这种低效率，我们采用了状态机来记录来自先前推理轨迹的经验。在状态机内，状态代表了细分的子问题，而状态转换反映了子问题之间的依赖关系。状态机记录了成功和失败的轨迹。利用状态机的经验，我们提出的思维状态机（SMoT）选择最优的子解决方案并避免错误的解决方案。我们的实验表明，SMoT可以显著改善在两种探索密集型问题中的问题解决能力：24

    arXiv:2312.17445v2 Announce Type: replace  Abstract: Current Large Language Model-based agents reason within an exploration-evaluation framework, navigating problem-solving processes in a tree-like manner. However, these methods often neglect successful reasoning trajectories once a problem is resolved, leading to inefficient use of these trajectories for future analogous problems. To address this inefficiency, we adopt a state machine to record experience derived from previous reasoning trajectories. Within the state machine, states represent decomposed sub-problems, while state transitions reflect the dependencies among sub-problems. The state machine records both successful and failed trajectories. Utilizing the experience from the state machine, our proposed State Machine of Thoughts (SMoT) selects the most optimal sub-solutions and avoids incorrect ones. Our experiments show that SMoT can significantly improve problem-solving abilities in two exploration-intensive problems: the 24
    
[^218]: 通过诱导性幻觉缓解大型语言模型的幻觉

    Alleviating Hallucinations of Large Language Models through Induced Hallucinations

    [https://arxiv.org/abs/2312.15710](https://arxiv.org/abs/2312.15710)

    通过诱导虚假信息来构建一个事实薄弱的语言模型，并在解码过程中通过对比解码来惩罚这些诱导的虚假信息，从而有效提升生成内容的真实性。

    

    尽管大型语言模型(LLMs)具有令人印象深刻的能力，但已观察到它们生成的响应中包含不准确或虚假信息，这种现象通常称为“幻觉”。在这项工作中，我们提出了一个简单的“诱导-对比解码”(ICD)策略来减轻幻觉。我们首先通过从原始LLMs中诱导幻觉来构建一个事实上薄弱的LLM。然后，在解码过程中惩罚这些诱导的幻觉以增强生成内容的真实性。具体来说，我们通过对比解码来放大原模型的预测并贬低诱导的不真实预测来确定最终的下一个标记预测。对基于歧视和基于生成的幻觉评估基准，如TruthfulQA和FActScore等进行的实验结果表明，我们提出的ICD方法能够有效增强

    arXiv:2312.15710v2 Announce Type: replace-cross  Abstract: Despite their impressive capabilities, large language models (LLMs) have been observed to generate responses that include inaccurate or fabricated information, a phenomenon commonly known as ``hallucination''. In this work, we propose a simple \textit{Induce-then-Contrast} Decoding (ICD) strategy to alleviate hallucinations. We first construct a factually weak LLM by inducing hallucinations from the original LLMs. Then, we penalize these induced hallucinations during decoding to enhance the factuality of the generated content. Concretely, we determine the final next-token predictions by amplifying the predictions from the original model and downplaying the induced untruthful predictions via contrastive decoding. Experimental results on both discrimination-based and generation-based hallucination evaluation benchmarks, such as TruthfulQA and \textsc{FActScore}, demonstrate that our proposed ICD methods can effectively enhance th
    
[^219]: Synergistic Anchored Contrastive Pre-training for Few-Shot Relation Extraction

    Synergistic Anchored Contrastive Pre-training for Few-Shot Relation Extraction

    [https://arxiv.org/abs/2312.12021](https://arxiv.org/abs/2312.12021)

    新提出了一种协同对比预训练框架，利用大量的实例-标签对来丰富学习到的表示

    

    少样本关系抽取（FSRE）旨在从稀疏标记语料库中提取关系事实。最近的研究通过在监督对比学习框架中利用预训练语言模型（PLMs）展现了有希望的FSRE结果，该框架考虑了实例和标签事实。然而，在这种学习范式中如何有效利用大量的实例-标签对来使学习到的表示具有语义丰富性尚未得到充分探讨。为填补这一空白，我们提出了一种新颖的协同对比预训练框架。这个框架的动机是，通过实例-标签对传达的多样观点捕捉到了不完整但互补的文本语义。具体而言，我们的框架涉及一种对称对比目标，包含了句子锚定和标签锚定的对比损失。通过组合这两种损失

    arXiv:2312.12021v3 Announce Type: replace-cross  Abstract: Few-shot Relation Extraction (FSRE) aims to extract relational facts from a sparse set of labeled corpora. Recent studies have shown promising results in FSRE by employing Pre-trained Language Models (PLMs) within the framework of supervised contrastive learning, which considers both instances and label facts. However, how to effectively harness massive instance-label pairs to encompass the learned representation with semantic richness in this learning paradigm is not fully explored. To address this gap, we introduce a novel synergistic anchored contrastive pre-training framework. This framework is motivated by the insight that the diverse viewpoints conveyed through instance-label pairs capture incomplete yet complementary intrinsic textual semantics. Specifically, our framework involves a symmetrical contrastive objective that encompasses both sentence-anchored and label-anchored contrastive losses. By combining these two los
    
[^220]: 从异构数据中学习结构因果模型中的未知干预目标

    Learning Unknown Intervention Targets in Structural Causal Models from Heterogeneous Data

    [https://arxiv.org/abs/2312.06091](https://arxiv.org/abs/2312.06091)

    在结构因果模型中，通过两阶段方法学习未知干预目标的外生噪声，并将其与相应的内生变量匹配，有效地识别干预目标。

    

    我们研究了在结构因果模型中识别未知干预目标的问题，其中我们可以访问从多个环境中收集的异构数据。未知干预目标是一组内生变量，其相应的外生噪声在不同环境中发生变化。我们提出了一个两阶段方法，第一阶段中恢复了跨不同环境发生变化的未知干预目标对应的外生噪声。在第二阶段，恢复的噪声与相应的内生变量进行匹配。对于恢复阶段，我们提供了学习这些外生噪声的充分条件，可达到某种分量方向可逆转换。对于匹配阶段，在因果充分性假设下，我们证明了所提方法可以唯一地识别干预目标。

    arXiv:2312.06091v2 Announce Type: replace-cross  Abstract: We study the problem of identifying the unknown intervention targets in structural causal models where we have access to heterogeneous data collected from multiple environments. The unknown intervention targets are the set of endogenous variables whose corresponding exogenous noises change across the environments. We propose a two-phase approach which in the first phase recovers the exogenous noises corresponding to unknown intervention targets whose distributions have changed across environments. In the second phase, the recovered noises are matched with the corresponding endogenous variables. For the recovery phase, we provide sufficient conditions for learning these exogenous noises up to some component-wise invertible transformation. For the matching phase, under the causal sufficiency assumption, we show that the proposed method uniquely identifies the intervention targets. In the presence of latent confounders, the interv
    
[^221]: 通过大型语言模型重新定义开发者援助：在软件生态系统中的应用

    Redefining Developer Assistance: Through Large Language Models in Software Ecosystem

    [https://arxiv.org/abs/2312.05626](https://arxiv.org/abs/2312.05626)

    本研究介绍了一种通过指导调整开发的DevAssistLlama模型，在处理软件相关自然语言查询时表现出优异能力，突出了专门LLM在软件开发中的潜力。

    

    在本文中，我们深入探讨了领域特定的大型语言模型（LLMs）的进展，重点关注它们在软件开发中的应用。我们介绍了DevAssistLlama，这是一个通过指导调整开发的模型，可帮助开发人员处理与软件相关的自然语言查询。这个模型，作为指导调整的LLM变体，特别擅长处理复杂的技术文档，增强了开发人员在软件特定任务中的能力。DevAssistLlama的创建涉及从各种软件系统构建了一个广泛的指导数据集，从而有效处理命名实体识别（NER）、关系抽取（RE）和链接预测（LP）。我们的结果表明，在这些任务中，DevAssistLlama相对于其他模型（包括ChatGPT）具有更优越的能力。这项研究不仅突出了专门LLM在软件开发中的潜力

    arXiv:2312.05626v2 Announce Type: replace-cross  Abstract: In this paper, we delve into the advancement of domain-specific Large Language Models (LLMs) with a focus on their application in software development. We introduce DevAssistLlama, a model developed through instruction tuning, to assist developers in processing software-related natural language queries. This model, a variant of instruction tuned LLM, is particularly adept at handling intricate technical documentation, enhancing developer capability in software specific tasks. The creation of DevAssistLlama involved constructing an extensive instruction dataset from various software systems, enabling effective handling of Named Entity Recognition (NER), Relation Extraction (RE), and Link Prediction (LP). Our results demonstrate DevAssistLlama's superior capabilities in these tasks, in comparison with other models including ChatGPT. This research not only highlights the potential of specialized LLMs in software development also t
    
[^222]: 自我模型用于具身智能：用分层低维表示建模全身人体骨骼肌肉系统和运动控制

    Self Model for Embodied Intelligence: Modeling Full-Body Human Musculoskeletal System and Locomotion Control with Hierarchical Low-Dimensional Representation

    [https://arxiv.org/abs/2312.05473](https://arxiv.org/abs/2312.05473)

    本研究提出了一个包含90个身体段、206个关节和700个肌腱单位的肌肉骨骼模型，以及使用低维表示和分层深度强化学习的新算法，实现了最先进的全身控制。

    

    人体肌肉骨骼系统的建模和控制对于理解人类运动功能、开发具身智能以及优化人机交互系统至关重要。本文针对目前开源模型仅限于少数身体部位且通常肌肉数量有限的问题，提出了一个包含90个身体段、206个关节和700个肌腱单位的肌肉骨骼模型，能够模拟全身动态并与各种设备进行交互。我们提出了一种使用低维表示和分层深度强化学习的新算法，实现了最先进的全身控制。通过模拟真实人类步态数据验证了我们模型和算法的有效性。

    arXiv:2312.05473v2 Announce Type: replace  Abstract: Modeling and control of the human musculoskeletal system is important for understanding human motor functions, developing embodied intelligence, and optimizing human-robot interaction systems. However, current open-source models are restricted to a limited range of body parts and often with a reduced number of muscles. There is also a lack of algorithms capable of controlling over 600 muscles to generate reasonable human movements. To fill this gap, we build a musculoskeletal model with 90 body segments, 206 joints, and 700 muscle-tendon units, allowing simulation of full-body dynamics and interaction with various devices. We develop a new algorithm using low-dimensional representation and hierarchical deep reinforcement learning to achieve state-of-the-art full-body control. We validate the effectiveness of our model and algorithm in simulations with real human locomotion data. The musculoskeletal model, along with its control algor
    
[^223]: 打破同质性和异质性在半监督节点分类中的纠缠

    Breaking the Entanglement of Homophily and Heterophily in Semi-supervised Node Classification

    [https://arxiv.org/abs/2312.04111](https://arxiv.org/abs/2312.04111)

    开发了一个可以在同质性和异质性下保证性能的强大GNN模型

    

    最近，图神经网络（GNNs）在利用图数据库知识进行半监督节点分类方面表现出色。然而，大多数现有的GNNs遵循同质性假设，即连接的节点更有可能展现出相似的特征分布和相同的标签，这种假设在越来越多的实际应用中被证明是脆弱的。作为补充，异质性反映了相连节点的不相似性，在图学习中引起了重要关注。因此，数据工程师旨在开发一个强大的GNN模型，可以在同质性和异质性下保证性能。尽管已进行了大量尝试，但由于无向图的约束，大多数现有的GNNs都难以实现最佳节点表示。忽略有向边会导致次优的图表示，从而阻碍了GNNs的能力。

    arXiv:2312.04111v2 Announce Type: replace-cross  Abstract: Recently, graph neural networks (GNNs) have shown prominent performance in semi-supervised node classification by leveraging knowledge from the graph database. However, most existing GNNs follow the homophily assumption, where connected nodes are more likely to exhibit similar feature distributions and the same labels, and such an assumption has proven to be vulnerable in a growing number of practical applications. As a supplement, heterophily reflects dissimilarity in connected nodes, which has gained significant attention in graph learning. To this end, data engineers aim to develop a powerful GNN model that can ensure performance under both homophily and heterophily. Despite numerous attempts, most existing GNNs struggle to achieve optimal node representations due to the constraints of undirected graphs. The neglect of directed edges results in sub-optimal graph representations, thereby hindering the capacity of GNNs. To add
    
[^224]: 评估和基准化离策略评估的风险-收益权衡

    Towards Assessing and Benchmarking Risk-Return Tradeoff of Off-Policy Evaluation

    [https://arxiv.org/abs/2311.18207](https://arxiv.org/abs/2311.18207)

    该研究提出了一种新的指标 SharpeRatio@k，用于评估离策略评估的风险-收益权衡，能够有效区分不同风险估计器并准确识别最高效的估计器。

    

    离策略评估（OPE）旨在仅使用线下记录的数据评估反事实政策的有效性，并通常用于识别在在线A/B测试部署中的前k个有前途的政策。当前的OPE估计器评估指标主要关注OPE或下游政策选择的“准确性”，而忽略了随后在线政策部署中的风险-回报权衡。为解决这一问题，我们从金融中的投资组合评估中汲取灵感，开发了一种名为SharpeRatio@k的新指标，用于衡量由OPE估计器形成的政策投资组合在不同的在线评估预算（k）下的风险-回报权衡。我们在两个示例场景中验证了我们的指标，展示了其能够有效区分低风险和高风险估计器，并准确识别效率最高的估计器。

    arXiv:2311.18207v3 Announce Type: replace-cross  Abstract: Off-Policy Evaluation (OPE) aims to assess the effectiveness of counterfactual policies using only offline logged data and is often used to identify the top-k promising policies for deployment in online A/B tests. Existing evaluation metrics for OPE estimators primarily focus on the "accuracy" of OPE or that of downstream policy selection, neglecting risk-return tradeoff in the subsequent online policy deployment. To address this issue, we draw inspiration from portfolio evaluation in finance and develop a new metric, called SharpeRatio@k, which measures the risk-return tradeoff of policy portfolios formed by an OPE estimator under varying online evaluation budgets (k). We validate our metric in two example scenarios, demonstrating its ability to effectively distinguish between low-risk and high-risk estimators and to accurately identify the most efficient one. Efficiency of an estimator is characterized by its capability to fo
    
[^225]: SCOPE-RL: 用于离线强化学习和离策略评估的Python库

    SCOPE-RL: A Python Library for Offline Reinforcement Learning and Off-Policy Evaluation

    [https://arxiv.org/abs/2311.18206](https://arxiv.org/abs/2311.18206)

    SCOPE-RL是一个Python库，兼顾离线强化学习和离策略评估，通过整合策略学习和评估实现了更灵活、完整的实现方式，并通过OPE模块提供了多种OPE估计器和稳健的OPE协议，使得OPE更深入和可靠。

    

    本文介绍了SCOPE-RL，这是一个全面的开源Python软件，专为离线强化学习（offline RL）、离策略评估（OPE）和选择（OPS）而设计。与大多数现有的库不同，这些库仅关注策略学习或评估中的一个，SCOPE-RL无缝整合了这两个关键方面，促进了离线RL和OPE过程的灵活和完整实现。SCOPE-RL特别侧重于其OPE模块，提供一系列OPE估计器和稳健的OPE协议。这种方法使得与其他软件包相比，SCOPE-RL能够更深入和可靠地评估OPE。例如，SCOPE-RL通过估计策略下的整个奖励分布而不仅仅是其点值预期值来增强OPE。此外，SCOPE-RL通过在OPE结果中提供风险-回报权衡，超越了现有库中仅仅是准确性评估的更全面的OPE评估。

    arXiv:2311.18206v3 Announce Type: replace-cross  Abstract: This paper introduces SCOPE-RL, a comprehensive open-source Python software designed for offline reinforcement learning (offline RL), off-policy evaluation (OPE), and selection (OPS). Unlike most existing libraries that focus solely on either policy learning or evaluation, SCOPE-RL seamlessly integrates these two key aspects, facilitating flexible and complete implementations of both offline RL and OPE processes. SCOPE-RL put particular emphasis on its OPE modules, offering a range of OPE estimators and robust evaluation-of-OPE protocols. This approach enables more in-depth and reliable OPE compared to other packages. For instance, SCOPE-RL enhances OPE by estimating the entire reward distribution under a policy rather than its mere point-wise expected value. Additionally, SCOPE-RL provides a more thorough evaluation-of-OPE by presenting the risk-return tradeoff in OPE results, extending beyond mere accuracy evaluations in exis
    
[^226]: TFMQ-DM：面向扩散模型的时间特征维持量化

    TFMQ-DM: Temporal Feature Maintenance Quantization for Diffusion Models

    [https://arxiv.org/abs/2311.16503](https://arxiv.org/abs/2311.16503)

    TFMQ-DM提出了一种称为Temporal Feature Maintenance Quantization (TFMQ)的方法，针对扩散模型中的时间特征进行量化，解决了传统模型中存在的优化问题，提高了压缩效率。

    

    arXiv:2311.16503v2 通告类型：替换-交叉 摘要：扩散模型是一种广泛应用于图像生成的框架，但由于其较长的推理时间和大量的内存需求，在广泛适用性方面遇到了重大挑战。高效的后训练量化（PTQ）对于传统模型解决这些问题至关重要。与传统模型不同，扩散模型严重依赖时间步长 $t$ 来实现令人满意的多轮去噪。通常，从有限集合 $\{1, \ldots, T\}$ 中的 $t$会被几个模块编码为一个时间特征，这完全不考虑采样数据。然而，现有的PTQ方法并不分别优化这些模块。它们采用不恰当的重构目标和复杂的校准方法，导致时间特征和去噪轨迹严重受到干扰，同时压缩效率较低。为了解决这些问题，我们提出了一种称为Temporal Feature Maintenance Quantization (TFMQ)的方法

    arXiv:2311.16503v2 Announce Type: replace-cross  Abstract: The Diffusion model, a prevalent framework for image generation, encounters significant challenges in terms of broad applicability due to its extended inference times and substantial memory requirements. Efficient Post-training Quantization (PTQ) is pivotal for addressing these issues in traditional models. Different from traditional models, diffusion models heavily depend on the time-step $t$ to achieve satisfactory multi-round denoising. Usually, $t$ from the finite set $\{1, \ldots, T\}$ is encoded to a temporal feature by a few modules totally irrespective of the sampling data. However, existing PTQ methods do not optimize these modules separately. They adopt inappropriate reconstruction targets and complex calibration methods, resulting in a severe disturbance of the temporal feature and denoising trajectory, as well as a low compression efficiency. To solve these, we propose a Temporal Feature Maintenance Quantization (TF
    
[^227]: 在神经蒙日映射中的不平衡性改进未配对领域转换

    Unbalancedness in Neural Monge Maps Improves Unpaired Domain Translation

    [https://arxiv.org/abs/2311.15100](https://arxiv.org/abs/2311.15100)

    在神经蒙日映射中引入不平衡性可改进未配对领域转换任务的效率和鲁棒性

    

    在最优输送（OT）中，蒙日映射被称为以最经济的方式将源分布传输到目标分布的映射。最近，已经开发并应用了多种用于Monge映射的神经估计器，并在各种未配对的领域转换任务中进行了应用，例如在单细胞生物学和计算机视觉中。然而，经典的OT框架强制保持质量守恒，这使其容易受到离群值的影响，并限制了它在现实世界场景中的适用性。后者在OT领域转换任务中可能特别有害，因为其中显式考虑了样本在分布中的相对位置。尽管在离散设置中，不平衡OT解决了这一挑战，但其集成到神经Monge映射估计器中受到了有限的关注。我们提出了一种理论上基础的方法，将不平衡性纳入到任何Monge映射估计器中。我们改进了现有的估计器以模

    arXiv:2311.15100v2 Announce Type: replace-cross  Abstract: In optimal transport (OT), a Monge map is known as a mapping that transports a source distribution to a target distribution in the most cost-efficient way. Recently, multiple neural estimators for Monge maps have been developed and applied in diverse unpaired domain translation tasks, e.g. in single-cell biology and computer vision. However, the classic OT framework enforces mass conservation, which makes it prone to outliers and limits its applicability in real-world scenarios. The latter can be particularly harmful in OT domain translation tasks, where the relative position of a sample within a distribution is explicitly taken into account. While unbalanced OT tackles this challenge in the discrete setting, its integration into neural Monge map estimators has received limited attention. We propose a theoretically grounded method to incorporate unbalancedness into any Monge map estimator. We improve existing estimators to mode
    
[^228]: 移动机器人的联合语义分割和边界检测

    Mobile-Seed: Joint Semantic Segmentation and Boundary Detection for Mobile Robots

    [https://arxiv.org/abs/2311.12651](https://arxiv.org/abs/2311.12651)

    Mobile-Seed是一个轻量级的双任务框架，旨在同时进行语义分割和边界检测，具有双流编码器、主动融合解码器和双任务正则化方法。

    

    精确快速地勾勒出清晰边界和稳健的语义对于众多下游机器人任务至关重要，例如机器人抓取和操作、实时语义映射以及在线传感器校准等任务是在边缘计算单元上执行的。尽管边界检测和语义分割是互补的任务，但大多数研究集中在轻量级模型上进行语义分割，而忽略了边界检测的关键作用。在这项工作中，我们引入了Mobile-Seed，一个专为同时进行语义分割和边界检测而设计的轻量级双任务框架。我们的框架具有双流编码器、主动融合解码器（AFD）和双任务正则化方法。编码器分为两条路径：一条捕获具有类别感知的语义信息，另一条从多尺度特征中辨别边界。AFD模块动态调整语义和边界的融合。

    arXiv:2311.12651v3 Announce Type: replace-cross  Abstract: Precise and rapid delineation of sharp boundaries and robust semantics is essential for numerous downstream robotic tasks, such as robot grasping and manipulation, real-time semantic mapping, and online sensor calibration performed on edge computing units. Although boundary detection and semantic segmentation are complementary tasks, most studies focus on lightweight models for semantic segmentation but overlook the critical role of boundary detection. In this work, we introduce Mobile-Seed, a lightweight, dual-task framework tailored for simultaneous semantic segmentation and boundary detection. Our framework features a two-stream encoder, an active fusion decoder (AFD) and a dual-task regularization approach. The encoder is divided into two pathways: one captures category-aware semantic information, while the other discerns boundaries from multi-scale features. The AFD module dynamically adapts the fusion of semantic and boun
    
[^229]: 通过扩散模型从病理转变生成渐进图像

    Generating Progressive Images from Pathological Transitions via Diffusion Model

    [https://arxiv.org/abs/2311.12316](https://arxiv.org/abs/2311.12316)

    提出了一种自适应深度控制扩散（ADD）网络，通过混合式注意力策略指导双向扩散，实现有效的病理渐进图像生成。

    

    深度学习广泛应用于计算机辅助病理诊断，减轻病理工作量，提供及时的临床分析。然而，大多数模型通常需要大规模注释数据进行训练，由于病理图像的采样和注释稀缺性而面临挑战。最近的研究显示，快速发展的生成模型具有潜力从病理图像中生成更多训练样本。然而，他们在有限的训练数据下普遍面临泛化多样性的挑战，无法生成有效样本。受不同阶段之间的病理转变启发，我们提出了一种自适应深度控制扩散（ADD）网络，用于生成病理渐进图像以进行有效数据增强。这种新颖的方法根源于领域迁移，其中混合式注意力策略引导双向扩散，融合局部和全局注意力优先级。

    arXiv:2311.12316v2 Announce Type: replace-cross  Abstract: Deep learning is widely applied in computer-aided pathological diagnosis, which alleviates the pathologist workload and provide timely clinical analysis. However, most models generally require large-scale annotated data for training, which faces challenges due to the sampling and annotation scarcity in pathological images. The rapid developing generative models shows potential to generate more training samples from recent studies. However, they also struggle in generalization diversity with limited training data, incapable of generating effective samples. Inspired by the pathological transitions between different stages, we propose an adaptive depth-controlled diffusion (ADD) network to generate pathological progressive images for effective data augmentation. This novel approach roots in domain migration, where a hybrid attention strategy guides the bidirectional diffusion, blending local and global attention priorities. With f
    
[^230]: VERVE: 基于模板的反思重写用于激励性面谈

    VERVE: Template-based ReflectiVE Rewriting for MotiVational IntErviewing

    [https://arxiv.org/abs/2311.08299](https://arxiv.org/abs/2311.08299)

    这项工作引入了 counseling response rewriting 任务，提出了基于模板的 VERVE 系统，通过加入释义的训练和自适应模板更新，将非反思性陈述转化为反思性回应。

    

    反思式倾听是心理辅导师必须掌握的基本技能，以在激励性面谈中达到熟练水平。它涉及以一种承认和探索客户对话中表达的意义的方式进行回应。在这项工作中，我们引入了辅导响应重写的任务，将非反思性陈述转化为反思性回应。我们提出了VERVE，一个基于模板的重写系统，具有加入释义的训练和自适应模板更新。VERVE首先通过识别和过滤与反思无关的标记来创建模板，并使用模板构建反思式回应。释义增强训练使模型能够学习对掩码空间进行较不严格的填充，而自适应模板更新则有助于发现重写的有效模板，而不会显著移除原始内容。使用自动和

    arXiv:2311.08299v2 Announce Type: replace-cross  Abstract: Reflective listening is a fundamental skill that counselors must acquire to achieve proficiency in motivational interviewing (MI). It involves responding in a manner that acknowledges and explores the meaning of what the client has expressed in the conversation. In this work, we introduce the task of counseling response rewriting, which transforms non-reflective statements into reflective responses. We introduce VERVE, a template-based rewriting system with paraphrase-augmented training and adaptive template updating. VERVE first creates a template by identifying and filtering out tokens that are not relevant to reflections and constructs a reflective response using the template. Paraphrase-augmented training allows the model to learn less-strict fillings of masked spans, and adaptive template updating helps discover effective templates for rewriting without significantly removing the original content. Using both automatic and 
    
[^231]: LRM：单图像到3D的大型重建模型

    LRM: Large Reconstruction Model for Single Image to 3D

    [https://arxiv.org/abs/2311.04400](https://arxiv.org/abs/2311.04400)

    首次提出了LRM，采用大规模训练数据和高容量模型，可在短时间内从单个图像中预测高质量3D重建结果

    

    我们提出了第一个大型重建模型（LRM），可以在短短5秒内从单个输入图像中预测对象的3D模型。与许多先前训练在小规模数据集（如ShapeNet）上的方法相比，LRM采用了一个高度可扩展的基于transformer的架构，具有5亿的可学习参数，可以直接从输入图像中预测神经辐射场（NeRF）。我们以端到端的方式在包含约100万个对象的大规模多视角数据上训练我们的模型，包括来自Objaverse的合成渲染和来自MVImgNet的真实捕获。这种高容量模型和大规模训练数据的结合使得我们的模型具有很强的泛化能力，可以从各种测试输入中产生高质量的3D重建结果，包括真实场景捕获和生成模型创建的图像。视频演示和可交互的3D模型

    arXiv:2311.04400v2 Announce Type: replace-cross  Abstract: We propose the first Large Reconstruction Model (LRM) that predicts the 3D model of an object from a single input image within just 5 seconds. In contrast to many previous methods that are trained on small-scale datasets such as ShapeNet in a category-specific fashion, LRM adopts a highly scalable transformer-based architecture with 500 million learnable parameters to directly predict a neural radiance field (NeRF) from the input image. We train our model in an end-to-end manner on massive multi-view data containing around 1 million objects, including both synthetic renderings from Objaverse and real captures from MVImgNet. This combination of a high-capacity model and large-scale training data empowers our model to be highly generalizable and produce high-quality 3D reconstructions from various testing inputs, including real-world in-the-wild captures and images created by generative models. Video demos and interactable 3D mes
    
[^232]: 选择性视觉表示提高具身智能的收敛性和泛化性

    Selective Visual Representations Improve Convergence and Generalization for Embodied AI

    [https://arxiv.org/abs/2311.04193](https://arxiv.org/abs/2311.04193)

    引入了一种参数高效的方法，在具身智能中使用任务条件的选择性过滤器来改善收敛性和泛化性能

    

    具身智能模型通常使用类似CLIP之类的通用视觉主干来编码它们的视觉观察。尽管这种通用目的的表示编码了关于场景的丰富句法和语义信息，但其中很多信息通常与手头的具体任务无关。这在学习过程中引入了噪声，并使代理人的注意力从任务相关的视觉线索转移。受人类选择性注意的启发-即人们根据他们的经验、知识和手头的任务来过滤他们的感知，我们介绍了一种参数高效的方法来为具身智能过滤视觉刺激。我们的方法使用一个小型可学习的码书模块引入了一个任务条件的瓶颈。这个码书是联合训练来优化任务奖励，并作为一个任务条件的选择性过滤器作用于视觉观察。我们的实验展示了针对obj的表现达到了最先进水平。

    arXiv:2311.04193v2 Announce Type: replace-cross  Abstract: Embodied AI models often employ off the shelf vision backbones like CLIP to encode their visual observations. Although such general purpose representations encode rich syntactic and semantic information about the scene, much of this information is often irrelevant to the specific task at hand. This introduces noise within the learning process and distracts the agent's focus from task-relevant visual cues. Inspired by selective attention in humans-the process through which people filter their perception based on their experiences, knowledge, and the task at hand-we introduce a parameter-efficient approach to filter visual stimuli for embodied AI. Our approach induces a task-conditioned bottleneck using a small learnable codebook module. This codebook is trained jointly to optimize task reward and acts as a task-conditioned selective filter over the visual observation. Our experiments showcase state-of-the-art performance for obj
    
[^233]: LLM4VV：为编译器验证开发基于LLM的测试套件

    LLM4VV: Developing LLM-Driven Testsuite for Compiler Validation

    [https://arxiv.org/abs/2310.04963](https://arxiv.org/abs/2310.04963)

    本研究开发了一个基于LLM的测试套件，用于验证编译器实现，探索了各种LLMs并使用不同的提示工程技术进行微调。

    

    大型语言模型(LLMs)是一种新而强大的工具，可用于涵盖自然语言的各种应用，并展示出令人印象深刻的代码生成能力。本文旨在自动生成测试，并利用这些测试来验证和验证基于指令的并行编程范例OpenACC的编译器实现。为此，我们探索了最先进的LLM技术，包括开源LLMs -- Meta Codellama、Codellama的Phind微调版本、Deepseek Coder和闭源LLMs -- OpenAI GPT-3.5-Turbo和GPT-4-Turbo。我们进一步使用我们自己的测试套件数据集和OpenACC规范对开源LLMs和GPT-3.5-Turbo进行了微调。我们还使用了各种提示工程技术来探索这些LLMs，包括代码模板、带有检索增强生成(RAG)的模板、一次性示例、带有RAG的一次性和表达式提示。

    arXiv:2310.04963v3 Announce Type: replace  Abstract: Large language models (LLMs) are a new and powerful tool for a wide span of applications involving natural language and demonstrate impressive code generation abilities. The goal of this work is to automatically generate tests and use these tests to validate and verify compiler implementations of a directive-based parallel programming paradigm, OpenACC. To do so, in this paper, we explore the capabilities of state-of-the-art LLMs, including open-source LLMs -- Meta Codellama, Phind fine-tuned version of Codellama, Deepseek Deepseek Coder and closed-source LLMs -- OpenAI GPT-3.5-Turbo and GPT-4-Turbo. We further fine-tuned the open-source LLMs and GPT-3.5-Turbo using our own testsuite dataset along with using the OpenACC specification. We also explored these LLMs using various prompt engineering techniques that include code template, template with retrieval-augmented generation (RAG), one-shot example, one-shot with RAG, expressive pr
    
[^234]: 从文本到自我：用户对人工智能在人际交流和自我方面潜力的认知

    From Text to Self: Users' Perceptions of Potential of AI on Interpersonal Communication and Self

    [https://arxiv.org/abs/2310.03976](https://arxiv.org/abs/2310.03976)

    用户对大型语言模型驱动的工具在人际交流方面的能力持积极看法，认为可以增加沟通自信、帮助表达想法以及克服语言和文化障碍，但也揭示出工具存在的一些局限性和用户关于技术不真实性和过度依赖的担忧。

    

    在快速发展的AI中介交流（AIMC）领域中，由大型语言模型（LLMs）驱动的工具正成为人际交流的重要组成部分。采用混合方法，我们进行了为期一周的日记和访谈研究，探讨了用户对这些工具在短期内支持人际交流的能力和可能导致的长期效果的看法。我们的研究发现，参与者对AIMC支持持有积极看法，认为其能够增加沟通自信，帮助找到准确的语言表达想法，以及克服语言和文化障碍。然而，研究还揭示了AIMC工具目前存在的局限，包括啰嗦的回复、不自然的回应以及过度情绪化。这些缺陷进一步受到用户对不真实性和对技术过度依赖的担忧所加剧。此外，我们确定了

    arXiv:2310.03976v2 Announce Type: cross  Abstract: In the rapidly evolving landscape of AI-mediated communication (AIMC), tools powered by Large Language Models (LLMs) are becoming integral to interpersonal communication. Employing a mixed-methods approach, we conducted a one-week diary and interview study to explore users' perceptions of these tools' ability to: 1) support interpersonal communication in the short-term, and 2) lead to potential long-term effects. Our findings indicate that participants view AIMC support favorably, citing benefits such as increased communication confidence, and finding precise language to express their thoughts, navigating linguistic and cultural barriers. However, the study also uncovers current limitations of AIMC tools, including verbosity, unnatural responses, and excessive emotional intensity. These shortcomings are further exacerbated by user concerns about inauthenticity and potential overreliance on the technology. Furthermore, we identified fou
    
[^235]: 极化社会中的视觉政治传播: 巴西总统选举在Instagram上的纵向研究

    Visual Political Communication in a Polarized Society: A Longitudinal Study of Brazilian Presidential Elections on Instagram

    [https://arxiv.org/abs/2310.00349](https://arxiv.org/abs/2310.00349)

    该研究通过纵向研究巴西总统候选人在Instagram上发布的帖子，揭示了视觉政治传播中固定的模式，包括庆祝和积极调性图像的普遍使用以及候选人与选民紧密联系的个性化展示。

    

    在当今数字时代，图像已经成为政治人士在社交媒体平台上与选民互动的强大工具。视觉内容具有独特的情感吸引力，往往导致用户参与度增加。然而，对视觉传播的研究仍然相对有限，尤其是在全球南方国家。本研究旨在通过采用计算方法和定性方法相结合的方式，研究2018年和2022年19位巴西总统候选人在Instagram上发布的11,263条帖子中采用的视觉传播策略，以弥补这一空白。通过两项研究，我们观察到这些候选人在视觉政治传播上存在一致的模式。值得注意的是，我们确定了庆祝和积极调性图像的普遍性。他们还展示了强烈的个性化感，描绘候选人与选民更紧密相连的形象。

    arXiv:2310.00349v2 Announce Type: replace-cross  Abstract: In today's digital age, images have emerged as powerful tools for politicians to engage with their voters on social media platforms. Visual content possesses a unique emotional appeal that often leads to increased user engagement. However, research on visual communication remains relatively limited, particularly in the Global South. This study aims to bridge this gap by employing a combination of computational methods and qualitative approach to investigate the visual communication strategies employed in a dataset of 11,263 Instagram posts by 19 Brazilian presidential candidates in 2018 and 2022 national elections. Through two studies, we observed consistent patterns across these candidates on their use of visual political communication. Notably, we identify a prevalence of celebratory and positively toned images. They also exhibit a strong sense of personalization, portraying candidates connected with their voters on a more em
    
[^236]: 场景通知者：基于锚点的遮挡推断和轨迹预测在部分可观测环境中

    Scene Informer: Anchor-based Occlusion Inference and Trajectory Prediction in Partially Observable Environments

    [https://arxiv.org/abs/2309.13893](https://arxiv.org/abs/2309.13893)

    场景通知者是一种统一方法，用于在部分可观察的环境中预测观察代理的轨迹和推断遮挡，其利用transformer聚合输入模态并实现对可能与自主车辆计划路径相交的遮挡的选择性查询。

    

    在复杂和动态的环境中自主车辆（AVs）导航需要AVs推理可见和遮挡区域。这涉及预测观察代理的未来运动，推断被遮挡的代理，并根据部分可观测环境的矢量化场景表示建模它们的相互作用。然而，在遮挡推断和轨迹预测方面的先前工作是分别发展的，前者基于简化的光栅方法，后者假定完整的环境可观察性。我们引入了场景通知者，这是一种统一的方法，用于在部分可观察的情况下预测观察代理的轨迹和推断遮挡。它使用一个transformer来聚合各种输入模态，并促进对可能与AV计划路径相交的遮挡的选择性查询。该框架估计了遮挡概率和可能的遮挡轨迹。

    arXiv:2309.13893v2 Announce Type: replace-cross  Abstract: Navigating complex and dynamic environments requires autonomous vehicles (AVs) to reason about both visible and occluded regions. This involves predicting the future motion of observed agents, inferring occluded ones, and modeling their interactions based on vectorized scene representations of the partially observable environment. However, prior work on occlusion inference and trajectory prediction have developed in isolation, with the former based on simplified rasterized methods and the latter assuming full environment observability. We introduce the Scene Informer, a unified approach for predicting both observed agent trajectories and inferring occlusions in a partially observable setting. It uses a transformer to aggregate various input modalities and facilitate selective queries on occlusions that might intersect with the AV's planned path. The framework estimates occupancy probabilities and likely trajectories for occlusi
    
[^237]: 在LLM时代重新思考移动AI生态系统

    Rethinking Mobile AI Ecosystem in the LLM Era

    [https://arxiv.org/abs/2308.14363](https://arxiv.org/abs/2308.14363)

    重新思考移动AI生态系统，引入了一种基于协作管理的范式，通过在NPU内部放置不受应用或操作系统修订影响的基础模型，以及每个应用贡献特定的适配器，为广泛移动AI任务提供服务。

    

    在今天的背景下，智能手机已经演变成了托管多种深度学习模型的中心，旨在进行本地执行。推动这项工作的一个关键意识是这些模型之间的显著分散性，其特点是不同的架构、运算符和实现。这种分散性给硬件、系统设置和算法的全面优化带来了重大负担。在最近的大型基础模型取得重大进展的推动下，这项工作引入了一种移动AI的开创性范式：移动操作系统和硬件之间的协作管理方法，监督具有为广泛移动AI任务提供服务能力的基础模型，即使还不能为所有任务提供服务。这个基础模型驻留在NPU内部，类似于固件，不受应用或操作系统的修订的影响。同时，每个应用程序都会贡献一个简洁的、离线微调的“适配器”，用于特定的下游任务。

    arXiv:2308.14363v2 Announce Type: replace  Abstract: In today's landscape, smartphones have evolved into hubs for hosting a multitude of deep learning models aimed at local execution. A key realization driving this work is the notable fragmentation among these models, characterized by varied architectures, operators, and implementations. This fragmentation imposes a significant burden on the comprehensive optimization of hardware, system settings, and algorithms.   Buoyed by the recent strides in large foundation models, this work introduces a pioneering paradigm for mobile AI: a collaborative management approach between the mobile OS and hardware, overseeing a foundational model capable of serving a broad spectrum of mobile AI tasks, if not all. This foundational model resides within the NPU and remains impervious to app or OS revisions, akin to firmware. Concurrently, each app contributes a concise, offline fine-tuned "adapter" tailored to distinct downstream tasks. From this concept
    
[^238]: 战略性猎物使犀利的捕食者：通过生成伪装物体来增强伪装物体检测器

    Strategic Preys Make Acute Predators: Enhancing Camouflaged Object Detectors by Generating Camouflaged Objects

    [https://arxiv.org/abs/2308.03166](https://arxiv.org/abs/2308.03166)

    通过对抗训练框架Camouflageator生成更难以被检测到的伪装对象，从而增强伪装物体检测，解决了现有伪装物体检测器在挑战性案例中的精确性问题。

    

    伪装物体检测（COD）是一项具有挑战性的任务，旨在识别视觉上融入环境中的伪装物体。尽管取得了显著的成功，现有的COD检测器在一些具有挑战性的情况下仍然难以获得精确的结果。为了解决这个问题，我们从猎物与捕食者的博弈中汲取灵感，这导致猎物发展出更好的伪装能力，而捕食者则获得更敏锐的视觉系统，并从猎物方和捕食者方开发算法。在猎物一侧，我们提出了一个对抗训练框架，Camouflageator，引入一个辅助生成器来生成更难以被COD方法检测到的伪装对象。Camouflageator以对抗的方式训练生成器和检测器，使增强的辅助生成器有助于产生更强大的检测器。

    arXiv:2308.03166v2 Announce Type: replace-cross  Abstract: Camouflaged object detection (COD) is the challenging task of identifying camouflaged objects visually blended into surroundings. Albeit achieving remarkable success, existing COD detectors still struggle to obtain precise results in some challenging cases. To handle this problem, we draw inspiration from the prey-vs-predator game that leads preys to develop better camouflage and predators to acquire more acute vision systems and develop algorithms from both the prey side and the predator side. On the prey side, we propose an adversarial training framework, Camouflageator, which introduces an auxiliary generator to generate more camouflaged objects that are harder for a COD method to detect. Camouflageator trains the generator and detector in an adversarial way such that the enhanced auxiliary generator helps produce a stronger detector. On the predator side, we introduce a novel COD method, called Internal Coherence and Edge G
    
[^239]: 基于节点加权的图卷积网络用于分析转录的临床面谈中的抑郁症检测

    Node-weighted Graph Convolutional Network for Depression Detection in Transcribed Clinical Interviews

    [https://arxiv.org/abs/2307.00920](https://arxiv.org/abs/2307.00920)

    提出了一种基于节点加权的图卷积网络方法，用于在临床面谈转录中检测抑郁症，相较于传统方法，在两个数据集上取得了更好的效果。

    

    我们提出了一种简单的方法，用于在图卷积网络（GCN）中加权自连接边，并展示其对从转录的临床面谈中进行抑郁症检测的影响。为此，我们使用GCN来对转录进行建模，以将其分类为抑郁症患者或对照组。所提出的方法旨在减轻GCN中对局部性和自连接与相邻节点边的等重要性的限制性假设，同时保留了诸如低计算成本、数据不可知和可解释性能力等有吸引力的特征。我们在两个基准数据集上进行了详尽的评估。结果表明，我们的方法始终优于基准GCN模型以及先前报告的结果，在两个数据集上均达到了F1=0.84。最后，定性分析展示了所提出方法的可解释性能力。

    arXiv:2307.00920v2 Announce Type: replace-cross  Abstract: We propose a simple approach for weighting self-connecting edges in a Graph Convolutional Network (GCN) and show its impact on depression detection from transcribed clinical interviews. To this end, we use a GCN for modeling non-consecutive and long-distance semantics to classify the transcriptions into depressed or control subjects. The proposed method aims to mitigate the limiting assumptions of locality and the equal importance of self-connections vs. edges to neighboring nodes in GCNs, while preserving attractive features such as low computational cost, data agnostic, and interpretability capabilities. We perform an exhaustive evaluation in two benchmark datasets. Results show that our approach consistently outperforms the vanilla GCN model as well as previously reported results, achieving an F1=0.84 on both datasets. Finally, a qualitative analysis illustrates the interpretability capabilities of the proposed approach and 
    
[^240]: 使用区块链防御联邦学习中的恶意行为

    Defending Against Malicious Behaviors in Federated Learning with Blockchain

    [https://arxiv.org/abs/2307.00543](https://arxiv.org/abs/2307.00543)

    该研究提出了一个基于区块链和分布式分类账技术的安全和可靠的联邦学习系统，包括点对点投票机制和奖励和惩罚机制，以检测和阻止恶意行为，证明了该框架对抗恶意客户的有效性。

    

    在深度学习时代，联邦学习(FL)提供了一种有前途的方法，允许多家机构数据所有者或客户共同训练机器学习模型，而不会损害数据隐私。然而，大多数现有的FL方法依赖于用于全局模型聚合的集中式服务器，导致单点故障。这使系统在处理不诚实的客户时容易受到恶意攻击。在这项工作中，我们通过提出基于区块链和分布式分类账技术的安全可靠FL系统来解决这个问题。我们的系统结合了点对点投票机制和奖励和惩罚机制，由链上智能合约提供动力，以检测和阻止恶意行为。我们提出了理论和实证分析，以展示所提出方法的有效性，表明我们的框架对恶意客户是强大的。

    arXiv:2307.00543v2 Announce Type: replace-cross  Abstract: In the era of deep learning, federated learning (FL) presents a promising approach that allows multi-institutional data owners, or clients, to collaboratively train machine learning models without compromising data privacy. However, most existing FL approaches rely on a centralized server for global model aggregation, leading to a single point of failure. This makes the system vulnerable to malicious attacks when dealing with dishonest clients. In this work, we address this problem by proposing a secure and reliable FL system based on blockchain and distributed ledger technology. Our system incorporates a peer-to-peer voting mechanism and a reward-and-slash mechanism, which are powered by on-chain smart contracts, to detect and deter malicious behaviors. Both theoretical and empirical analyses are presented to demonstrate the effectiveness of the proposed approach, showing that our framework is robust against malicious client-s
    
[^241]: TransERR:通过高效关系旋转的基于翻译的知识图嵌入方法

    TransERR: Translation-based Knowledge Graph Embedding via Efficient Relation Rotation

    [https://arxiv.org/abs/2306.14580](https://arxiv.org/abs/2306.14580)

    TransERR是一种基于翻译的知识图嵌入方法，采用超复值空间编码知识图，在模型训练中通过适应性旋转头实体和尾实体来最小化翻译距离，并具有有效建模不同关系模式的能力。

    

    本文提出了一种通过高效关系旋转（TransERR）实现的基于翻译的知识图嵌入方法，这是传统基于翻译的知识图嵌入模型的一种简单且有效的替代方案。与先前的基于翻译模型不同，TransERR在超复值空间中对知识图进行编码，从而使其能够在挖掘头部和尾部实体之间的潜在信息时具有更高程度的翻译自由度。为进一步减小翻译距离，TransERR通过它们各自可学习的单位四元数适应性地旋转头实体和尾实体。我们还提供数学证明来展示TransERR在建模各种关系模式（包括对称性、反对称性、倒置、合成和子关系模式）方面的能力。对10个基准数据集的实验验证了其有效性。

    arXiv:2306.14580v2 Announce Type: replace-cross  Abstract: This paper presents a translation-based knowledge geraph embedding method via efficient relation rotation (TransERR), a straightforward yet effective alternative to traditional translation-based knowledge graph embedding models. Different from the previous translation-based models, TransERR encodes knowledge graphs in the hypercomplex-valued space, thus enabling it to possess a higher degree of translation freedom in mining latent information between the head and tail entities. To further minimize the translation distance, TransERR adaptively rotates the head entity and the tail entity with their corresponding unit quaternions, which are learnable in model training. We also provide mathematical proofs to demonstrate the ability of TransERR in modeling various relation patterns, including symmetry, antisymmetry, inversion, composition, and subrelation patterns. The experiments on 10 benchmark datasets validate the effectiveness 
    
[^242]: 没有数据访问的深度分类器模拟

    Deep Classifier Mimicry without Data Access

    [https://arxiv.org/abs/2306.02090](https://arxiv.org/abs/2306.02090)

    提出了一种无需访问原始数据的模型-无关知识蒸馏过程CAKE，可以模拟深度分类器，通过生成噪声合成样本对比地扩散到模型的决策边界。

    

    最近，对预先训练模型的访问已经成为许多机器学习领域的标准。不幸的是，可能无法等同地获得模型训练所需的原始数据。这使得微调、压缩模型、持续调整或进行任何其他类型的数据驱动更新变得极具挑战性。我们认为可能无需原始数据访问。具体而言，我们提出了对比推理知识提取（CAKE），这是一种模型无关的知识蒸馏过程，可以模拟深度分类器而无需访问原始数据。为此，CAKE生成一对噪声合成样本，并将它们对比地扩散到模型的决策边界。我们通过几个基准数据集和各种架构选择在实证上证实了CAKE的有效性，为广泛应用铺平了道路。

    arXiv:2306.02090v2 Announce Type: replace-cross  Abstract: Access to pre-trained models has recently emerged as a standard across numerous machine learning domains. Unfortunately, access to the original data the models were trained on may not equally be granted. This makes it tremendously challenging to fine-tune, compress models, adapt continually, or to do any other type of data-driven update. We posit that original data access may however not be required. Specifically, we propose Contrastive Abductive Knowledge Extraction (CAKE), a model-agnostic knowledge distillation procedure that mimics deep classifiers without access to the original data. To this end, CAKE generates pairs of noisy synthetic samples and diffuses them contrastively toward a model's decision boundary. We empirically corroborate CAKE's effectiveness using several benchmark datasets and various architectural choices, paving the way for broad application.
    
[^243]: Visual CPG-RL：学习用于视觉引导的四足动物运动的中枢模式发生器

    Visual CPG-RL: Learning Central Pattern Generators for Visually-Guided Quadruped Locomotion

    [https://arxiv.org/abs/2212.14400](https://arxiv.org/abs/2212.14400)

    该论文提出了一个框架，通过将外感知传感和中枢模式发生器整合到深度强化学习框架中，学习视觉引导的四足动物运动，探索了耦合振荡器系统对导航鲁棒性的改进、具有记忆功能的策略网络与无记忆策略网络在导航任务中的效果以及动物如何容忍高。

    

    我们提出了一个框架，通过将外感知传感和中枢模式发生器（CPGs，即耦合振荡器系统）整合到深度强化学习（DRL）框架中，学习视觉引导的四足动物运动。通过外感知和本体感知，代理学习协调不同振荡器之间的节律行为，以跟踪速度指令，同时覆盖这些指令以避免与环境碰撞。我们探讨了几个开放的机器人技术和神经科学问题：1）振荡器之间的显式相互耦合的作用是什么，这种耦合是否能提高用于导航鲁棒性的从模拟到真实的转移？2）使用具有记忆功能与无记忆策略网络对于鲁棒性、能效和从模拟到真实导航任务的跟踪性能有什么影响？3）动物是如何容忍高

    arXiv:2212.14400v2 Announce Type: replace-cross  Abstract: We present a framework for learning visually-guided quadruped locomotion by integrating exteroceptive sensing and central pattern generators (CPGs), i.e. systems of coupled oscillators, into the deep reinforcement learning (DRL) framework. Through both exteroceptive and proprioceptive sensing, the agent learns to coordinate rhythmic behavior among different oscillators to track velocity commands, while at the same time override these commands to avoid collisions with the environment. We investigate several open robotics and neuroscience questions: 1) What is the role of explicit interoscillator couplings between oscillators, and can such coupling improve sim-to-real transfer for navigation robustness? 2) What are the effects of using a memory-enabled vs. a memory-free policy network with respect to robustness, energy-efficiency, and tracking performance in sim-to-real navigation tasks? 3) How do animals manage to tolerate high 
    
[^244]: 有限或有偏见: 在金融市场中建模次理性人类投资者

    Limited or Biased: Modeling Sub-Rational Human Investors in Financial Markets

    [https://arxiv.org/abs/2210.08569](https://arxiv.org/abs/2210.08569)

    该研究引入了一个灵活模型，利用强化学习结合五个不同方面的人类次理性，在金融市场模拟中准确重现了先前研究中观察到的行为特征。

    

    在现实生活中，人类的决策与完全理性个体做出的最佳决策存在明显差异，主要是由于计算限制或心理偏见。尽管行为金融领域的现有研究发现了人类次理性的各个方面，但缺乏将这些发现转化为适用于不同金融市场场景的自适应人类模型的综合框架。在本研究中，我们引入了一个灵活的模型，利用强化学习结合五个不同方面的人类次理性。我们的模型使用高保真度的多智能体市场模拟器进行训练，克服了缺乏个体投资者标记数据的限制。我们通过手工制作的市场场景和SHAP值分析评估了次理性人类投资者的行为，显示出我们的模型准确地重现了先前研究中的观察结果。

    arXiv:2210.08569v2 Announce Type: replace  Abstract: Human decision-making in real-life deviates significantly from the optimal decisions made by fully rational agents, primarily due to computational limitations or psychological biases. While existing studies in behavioral finance have discovered various aspects of human sub-rationality, there lacks a comprehensive framework to transfer these findings into an adaptive human model applicable across diverse financial market scenarios. In this study, we introduce a flexible model that incorporates five different aspects of human sub-rationality using reinforcement learning. Our model is trained using a high-fidelity multi-agent market simulator, which overcomes limitations associated with the scarcity of labeled data of individual investors. We evaluate the behavior of sub-rational human investors using hand-crafted market scenarios and SHAP value analysis, showing that our model accurately reproduces the observations in the previous stud
    
[^245]: 机器学习驱动的课程分配

    Machine Learning-Powered Course Allocation

    [https://arxiv.org/abs/2210.00954](https://arxiv.org/abs/2210.00954)

    引入机器学习驱动的课程分配机制（MLCM），通过机器学习模块减轻学生在报告偏好时的错误，显著提高学生效用，且具有对环境变化的稳健性。

    

    我们研究了课程分配问题，即大学为学生安排课程时间表。目前最先进的机制Course Match存在一个主要缺点：学生在报告他们的偏好时会犯很大的错误，从而对福利和公平性产生负面影响。为解决这一问题，我们引入了一种新机制，即基于机器学习的Course Match（MLCM）。MLCM的核心是一个机器学习驱动的偏好引导模块，通过迭代式地向学生提出个性化的两两比较查询，以减轻学生的报告错误。大量基于真实数据的计算实验表明，MLCM仅需十个比较查询，就能将平均和最小学生效用分别提高7%-11%和17%-29%。最后，我们强调了MLCM对环境变化的稳健性，并展示了我们的设计如何最小化升级至MLCM 的风险。

    arXiv:2210.00954v3 Announce Type: replace-cross  Abstract: We study the course allocation problem, where universities assign course schedules to students. The current state-of-the-art mechanism, Course Match, has one major shortcoming: students make significant mistakes when reporting their preferences, which negatively affects welfare and fairness. To address this issue, we introduce a new mechanism, Machine Learning-powered Course Match (MLCM). At the core of MLCM is a machine learning-powered preference elicitation module that iteratively asks personalized pairwise comparison queries to alleviate students' reporting mistakes. Extensive computational experiments, grounded in real-world data, demonstrate that MLCM, with only ten comparison queries, significantly increases both average and minimum student utility by 7%-11% and 17%-29%, respectively. Finally, we highlight MLCM's robustness to changes in the environment and show how our design minimizes the risk of upgrading to MLCM whil
    
[^246]: OpenXAI: 迈向透明评估模型解释

    OpenXAI: Towards a Transparent Evaluation of Model Explanations

    [https://arxiv.org/abs/2206.11104](https://arxiv.org/abs/2206.11104)

    OpenXAI 是一个开源框架，旨在评估和基准测试后续解释方法，提供了灵活的数据生成器、多种数据集和评估指标，用户可轻松扩展和比较不同解释方法。

    

    虽然最近文献中提出了几种后续解释方法，但对这些方法进行系统性基准测试的工作非常少。在这里，我们介绍了OpenXAI，一个全面且可扩展的开源框架，用于评估和基准测试后续解释方法。OpenXAI包括以下关键组件：（i）灵活的合成数据生成器和各种真实世界数据集、预训练模型和最先进特征归属方法的集合，以及（ii）用于评估解释方法忠实度、稳定性（鲁棒性）和公平性的十一种量化度量标准的开源实现，从而提供了对多种度量标准、模型和数据集上几种解释方法的比较。OpenXAI易于扩展，用户可以轻松评估自定义解释方法并将其纳入我们的排行榜中。

    arXiv:2206.11104v4 Announce Type: replace-cross  Abstract: While several types of post hoc explanation methods have been proposed in recent literature, there is very little work on systematically benchmarking these methods. Here, we introduce OpenXAI, a comprehensive and extensible open-source framework for evaluating and benchmarking post hoc explanation methods. OpenXAI comprises of the following key components: (i) a flexible synthetic data generator and a collection of diverse real-world datasets, pre-trained models, and state-of-the-art feature attribution methods, and (ii) open-source implementations of eleven quantitative metrics for evaluating faithfulness, stability (robustness), and fairness of explanation methods, in turn providing comparisons of several explanation methods across a wide variety of metrics, models, and datasets. OpenXAI is easily extensible, as users can readily evaluate custom explanation methods and incorporate them into our leaderboards. Overall, OpenXAI 
    
[^247]: 带波脉冲Q学习的深度强化学习

    Deep Reinforcement Learning with Spiking Q-learning

    [https://arxiv.org/abs/2201.09754](https://arxiv.org/abs/2201.09754)

    基于脉冲Q学习的深度强化学习方法DSQN利用非脉冲神经元的膜电压作为Q值表示，实现了能源高效的控制任务。

    

    借助特殊的神经形态硬件，期望通过脉冲神经网络（SNNs）实现人工智能（AI），以更少的能量消耗。通过将SNNs与深度强化学习（RL）相结合，为实现现实控制任务提供了一种有前途的高效能源方式。目前仅有少数基于SNN的RL方法。其中大部分要么缺乏泛化能力，要么在训练中使用人工神经网络（ANNs）来估算值函数。前者需要为每个场景调整大量超参数，而后者限制了不同类型RL算法的应用并忽略了训练中的能量消耗较大。为开发一个强大的基于脉冲的RL方法，我们从昆虫中发现的非脉冲间神经元中汲取灵感，提出了深度脉冲Q网络（DSQN），使用非脉冲神经元的膜电压作为Q值的表示，从而可以指导

    arXiv:2201.09754v2 Announce Type: replace-cross  Abstract: With the help of special neuromorphic hardware, spiking neural networks (SNNs) are expected to realize artificial intelligence (AI) with less energy consumption. It provides a promising energy-efficient way for realistic control tasks by combining SNNs with deep reinforcement learning (RL). There are only a few existing SNN-based RL methods at present. Most of them either lack generalization ability or employ Artificial Neural Networks (ANNs) to estimate value function in training. The former needs to tune numerous hyper-parameters for each scenario, and the latter limits the application of different types of RL algorithm and ignores the large energy consumption in training. To develop a robust spike-based RL method, we draw inspiration from non-spiking interneurons found in insects and propose the deep spiking Q-network (DSQN), using the membrane voltage of non-spiking neurons as the representation of Q-value, which can direct
    
[^248]: 揭示神经代码模型中的项目特定偏见

    Unveiling Project-Specific Bias in Neural Code Models

    [https://arxiv.org/abs/2201.07381](https://arxiv.org/abs/2201.07381)

    神经代码模型在训练和测试时表现出可观的性能，但往往无法有效地推广到跨项目分布的数据，原因在于过度依赖项目特定快捷方式进行预测。我们提出了一种量化项目特定性的度量Cond-Idf，并指出模型倾向于利用虚假统计线索进行预测。

    

    深度学习在许多软件分析任务中取得了显著的改进。尽管基于大型语言模型（LLMs）的神经代码模型在项目内独立和同分布（IID）设置下训练和测试时表现出可观的性能，但它们往往无法有效地推广到现实世界的跨项目分布（OOD）数据。在这项工作中，我们表明这种现象是由于过度依赖项目特定快捷方式进行预测，而不是真实证据导致的。我们提出了一种名为Cond-Idf的度量来解释这种行为，该度量量化了令牌与标签及其项目特定性之间的相关性。模型行为与提出的度量之间的强相关性表明，在没有适当的正则化的情况下，模型往往倾向于利用虚假的统计线索进行预测。借助这些观察结果，我们提出了一种新颖的偏见

    arXiv:2201.07381v2 Announce Type: replace  Abstract: Deep learning has introduced significant improvements in many software analysis tasks. Although the Large Language Models (LLMs) based neural code models demonstrate commendable performance when trained and tested within the intra-project independent and identically distributed (IID) setting, they often struggle to generalize effectively to real-world inter-project out-of-distribution (OOD) data. In this work, we show that this phenomenon is caused by the heavy reliance on project-specific shortcuts for prediction instead of ground-truth evidence. We propose a Cond-Idf measurement to interpret this behavior, which quantifies the relatedness of a token with a label and its project-specificness. The strong correlation between model behavior and the proposed measurement indicates that without proper regularization, models tend to leverage spurious statistical cues for prediction. Equipped with these observations, we propose a novel bias
    
[^249]: 在分布外图上推广图神经网络

    Generalizing Graph Neural Networks on Out-Of-Distribution Graphs

    [https://arxiv.org/abs/2111.10657](https://arxiv.org/abs/2111.10657)

    提出了一个名为StableGNN的通用因果表示框架，通过提取高级图表示并利用因果推断的区分能力，帮助模型在分布外图上实现稳定的泛化能力。

    

    图神经网络（GNNs）在没有考虑训练和测试图之间的分布差异的情况下提出，导致GNNs在分布外（OOD）设置上的泛化能力下降。这种退化的根本原因是大多数GNNs是基于独立同分布假设开发的。在这种设置中，GNNs倾向于利用训练集中存在的细微统计相关性进行预测，即使这是一种伪相关性。然而，这种伪相关性在测试环境中可能会改变，导致GNNs失败。因此，消除伪相关性的影响对于稳定的GNNs至关重要。为此，我们提出了一个名为StableGNN的通用因果表示框架。主要思想是首先从图数据中提取高级表示，然后借助因果推断的区分能力来帮助模型获得稳定的预测效果。

    arXiv:2111.10657v3 Announce Type: replace-cross  Abstract: Graph Neural Networks (GNNs) are proposed without considering the agnostic distribution shifts between training and testing graphs, inducing the degeneration of the generalization ability of GNNs on Out-Of-Distribution (OOD) settings. The fundamental reason for such degeneration is that most GNNs are developed based on the I.I.D hypothesis. In such a setting, GNNs tend to exploit subtle statistical correlations existing in the training set for predictions, even though it is a spurious correlation. However, such spurious correlations may change in testing environments, leading to the failure of GNNs. Therefore, eliminating the impact of spurious correlations is crucial for stable GNNs. To this end, we propose a general causal representation framework, called StableGNN. The main idea is to extract high-level representations from graph data first and resort to the distinguishing ability of causal inference to help the model get ri
    
[^250]: 通过保持结构的干预来量化固有因果贡献

    Quantifying intrinsic causal contributions via structure preserving interventions

    [https://arxiv.org/abs/2007.00714](https://arxiv.org/abs/2007.00714)

    该论文提出一种通过结构保持干预来量化节点对目标节点的固有因果贡献的方法，从而将因果信息与祖先节点信息分离，并提出了对方差和熵的贡献分析。

    

    我们提出了一种描述有向无环图中一个节点对目标节点的“固有”贡献部分的因果影响概念。通过将每个节点递归地写成上游噪声项的函数，我们将每个节点添加的固有信息与从祖先节点获得的信息分开。为了将固有信息解释为“因果”贡献，我们考虑了“保持结构的干预”，这些干预以一种模拟对父节点的通常依赖关系并且不扰乱观察到的联合分布的方式随机化每个节点。为了获得一个对重新标记节点不变的测量，我们使用基于Shapley的对称化，并且表明在线性情况下，在将目标节点解析为噪声变量后，它化简为简单的ANOVA。我们描述了方差和熵的贡献分析，但其他目标度量的贡献可以类似地定义。代码可在...

    arXiv:2007.00714v4 Announce Type: replace  Abstract: We propose a notion of causal influence that describes the `intrinsic' part of the contribution of a node on a target node in a DAG. By recursively writing each node as a function of the upstream noise terms, we separate the intrinsic information added by each node from the one obtained from its ancestors. To interpret the intrinsic information as a {\it causal} contribution, we consider `structure-preserving interventions' that randomize each node in a way that mimics the usual dependence on the parents and does not perturb the observed joint distribution. To get a measure that is invariant with respect to relabelling nodes we use Shapley based symmetrization and show that it reduces in the linear case to simple ANOVA after resolving the target node into noise variables. We describe our contribution analysis for variance and entropy, but contributions for other target metrics can be defined analogously. The code is available in the 
    
[^251]: 真知来源于实践：通过强化学习使LLMs与具身环境对齐的方法研究

    True Knowledge Comes from Practice: Aligning LLMs with Embodied Environments via Reinforcement Learning. (arXiv:2401.14151v1 [cs.LG])

    [http://arxiv.org/abs/2401.14151](http://arxiv.org/abs/2401.14151)

    本研究通过使用大型语言模型（LLMs）作为决策智能体，通过强化学习与具身环境高效互动来解决LLMs与环境之间知识不对齐的问题。通过查询LLMs的联合概率，形成行为策略，并通过两种归一化方法和四个提示设计原则提高策略的稳定性和鲁棒性。最后，通过设计参数高效的训练架构提高学习效率。

    

    尽管在众多任务中取得了令人印象深刻的表现，但大型语言模型（LLMs）在解决简单的决策任务上经常失败，原因是LLMs中的知识与环境不对齐。相反，强化学习（RL）智能体从零开始学习策略，这使得它们始终与环境保持一致，但难以将先前的知识整合到其中以进行有效的探索。为了缩小这一差距，我们提出了TWOSOME，一种新颖的在线框架，利用LLMs作为决策智能体，通过RL与具身环境高效互动并实现对齐，而无需任何准备好的数据集或环境的先前知识。首先，我们使用LLMs查询每个有效动作的联合概率以形成行为策略。然后，为了增强策略的稳定性和鲁棒性，我们提出了两种归一化方法，并总结了四个提示设计原则。最后，我们设计了一种新颖的参数高效的训练架构，其中包括一个行为评估和选择算法来提高学习效率。

    Despite the impressive performance across numerous tasks, large language models (LLMs) often fail in solving simple decision-making tasks due to the misalignment of the knowledge in LLMs with environments. On the contrary, reinforcement learning (RL) agents learn policies from scratch, which makes them always align with environments but difficult to incorporate prior knowledge for efficient explorations. To narrow the gap, we propose TWOSOME, a novel general online framework that deploys LLMs as decision-making agents to efficiently interact and align with embodied environments via RL without requiring any prepared datasets or prior knowledge of the environments. Firstly, we query the joint probabilities of each valid action with LLMs to form behavior policies. Then, to enhance the stability and robustness of the policies, we propose two normalization methods and summarize four prompt design principles. Finally, we design a novel parameter-efficient training architecture where the acto
    
[^252]: 组合式生成逆设计

    Compositional Generative Inverse Design. (arXiv:2401.13171v1 [cs.LG])

    [http://arxiv.org/abs/2401.13171](http://arxiv.org/abs/2401.13171)

    逆向设计起到优化底层目标函数的作用，最近的研究利用了学习的动力学模型进行优化。通过优化扩散模型捕获的学习能量函数，可以避免对抗示例，并显著提高设计性能。这一设计系统是组合性的，使得可以设计具有每个指定组件的系统。

    

    逆设计是一种寻求设计输入变量以优化底层目标函数的重要问题，在机械工程到航天工程等领域都有应用。逆设计通常被构建成一个优化问题，最近的研究利用了学习的动力学模型进行优化。然而，由于模型的优化往往会陷入对抗模式，阻碍有效的抽样。我们证明，通过优化扩散模型捕获的学习能量函数，我们可以避免这种对抗性示例，并显著提高设计性能。我们进一步展示了这样一个设计系统是组合性的，使我们能够结合多个不同的扩散模型来代表所需系统的子组件，从而设计具有每个指定组件的系统。在一个N体相互作用任务和一个具有挑战性的二维多翼型设计任务中，我们证明通过组合学习的能量函数，可以实现更好的设计性能。

    Inverse design, where we seek to design input variables in order to optimize an underlying objective function, is an important problem that arises across fields such as mechanical engineering to aerospace engineering. Inverse design is typically formulated as an optimization problem, with recent works leveraging optimization across learned dynamics models. However, as models are optimized they tend to fall into adversarial modes, preventing effective sampling. We illustrate that by instead optimizing over the learned energy function captured by the diffusion model, we can avoid such adversarial examples and significantly improve design performance. We further illustrate how such a design system is compositional, enabling us to combine multiple different diffusion models representing subcomponents of our desired system to design systems with every specified component. In an N-body interaction task and a challenging 2D multi-airfoil design task, we demonstrate that by composing the learn
    
[^253]: 中文数据处理中的佼佼者：英文代码模型

    Top in Chinese Data Processing: English Code Models. (arXiv:2401.10286v1 [cs.CL])

    [http://arxiv.org/abs/2401.10286](http://arxiv.org/abs/2401.10286)

    在中文数据处理中，基于代码的语言模型在非编程中文任务中表现出色，尤其是在对中文幻觉敏感的任务中。此研究为讨论“中文房间”思想实验提供了独特的视角。

    

    尽管在语言模型的应用中，任务与训练语料之间的对齐是一个基本的共识，但我们的一系列实验和我们设计的评估指标表明，基于代码的大型语言模型(LLMs)在非编程中文任务中的表现明显优于与任务紧密匹配的训练数据。此外，在对中文幻觉敏感程度较高的任务中，展示较少中文语言特征的模型表现更好。我们的实验结果可以通过简单地用代码模型替换基础模型，在中文数据处理任务中，如为检索增强生成(RAG)准备数据，很容易得到复制。此外，我们的研究为讨论“中文房间”思想实验提供了独特的视角。

    While the alignment between tasks and training corpora is a fundamental consensus in the application of language models, our series of experiments and the metrics we designed reveal that code-based Large Language Models (LLMs) significantly outperform models trained on data that is closely matched to the tasks in non-coding Chinese tasks. Moreover, in tasks high sensitivity to Chinese hallucinations, models exhibiting fewer linguistic features of the Chinese language achieve better performance. Our experimental results can be easily replicated in Chinese data processing tasks, such as preparing data for Retrieval-Augmented Generation (RAG), by simply replacing the base model with a code-based model. Additionally, our research offers a distinct perspective for discussion on the philosophical "Chinese Room" thought experiment.
    
[^254]: 通过保守密度估计从稀疏离线数据集中学习

    Learning from Sparse Offline Datasets via Conservative Density Estimation. (arXiv:2401.08819v1 [cs.LG])

    [http://arxiv.org/abs/2401.08819](http://arxiv.org/abs/2401.08819)

    本文提出了一种名为保守密度估计（CDE）的训练算法，通过明确约束状态-行为占据稳态分布来解决离线强化学习中的外推错误问题。在稀疏奖励或不足数据的任务中，CDE显示出明显优于基准方法的性能。

    

    离线强化学习（RL）为从预先收集的数据集中学习策略提供了一种有前景的方向，而无需与环境进一步交互。然而，现有的方法在处理分布外（OOD）外推错误方面存在困难，特别是在稀疏奖励或数据稀缺的情况下。在本文中，我们提出了一种名为保守密度估计（CDE）的新的训练算法，通过明确约束状态-行为占据稳态分布来解决这个挑战。CDE通过解决边际重要性抽样中的支持不匹配问题，克服了现有方法的局限性，如稳态分布校正方法。我们的方法在D4RL基准测试中实现了最先进的性能。值得注意的是，CDE在具有稀疏奖励或不足数据的挑战性任务中持续优于基准方法，证明了我们的方法在解决外推错误问题上的优势。

    Offline reinforcement learning (RL) offers a promising direction for learning policies from pre-collected datasets without requiring further interactions with the environment. However, existing methods struggle to handle out-of-distribution (OOD) extrapolation errors, especially in sparse reward or scarce data settings. In this paper, we propose a novel training algorithm called Conservative Density Estimation (CDE), which addresses this challenge by explicitly imposing constraints on the state-action occupancy stationary distribution. CDE overcomes the limitations of existing approaches, such as the stationary distribution correction method, by addressing the support mismatch issue in marginal importance sampling. Our method achieves state-of-the-art performance on the D4RL benchmark. Notably, CDE consistently outperforms baselines in challenging tasks with sparse rewards or insufficient data, demonstrating the advantages of our approach in addressing the extrapolation error problem i
    
[^255]: InfiAgent-DABench: 在数据分析任务中评估代理的基准测试

    InfiAgent-DABench: Evaluating Agents on Data Analysis Tasks. (arXiv:2401.05507v1 [cs.CL])

    [http://arxiv.org/abs/2401.05507](http://arxiv.org/abs/2401.05507)

    InfiAgent-DABench是第一个评估基于LLM的代理在数据分析任务中的基准测试，包括DAEval数据集和代理框架。对23个最先进的LLMs进行的基准测试揭示了当前数据分析任务中的挑战。

    

    本文介绍了"InfiAgent-DABench"，这是第一个专门设计用于评估基于LLM的代理在数据分析任务中的基准测试。该基准测试包含DAEval，这是一个由55个CSV文件衍生出的311个数据分析问题的数据集，以及一个评估LLMs作为数据分析代理的代理框架。我们采用了一种格式提示技术，确保问题是闭合形式的，可以自动评估。我们对23个最先进的LLMs进行了广泛的基准测试，揭示了数据分析任务中当前遇到的挑战。此外，我们还开发了DAAgent，这是一个在指令调优数据集上训练的专门代理。InfiAgent-DABench的评估数据集和工具包已经发布在https://github.com/InfiAgent/InfiAgent上。

    In this paper, we introduce "InfiAgent-DABench", the first benchmark specifically designed to evaluate LLM-based agents in data analysis tasks. This benchmark contains DAEval, a dataset consisting of 311 data analysis questions derived from 55 CSV files, and an agent framework to evaluate LLMs as data analysis agents. We adopt a format-prompting technique, ensuring questions to be closed-form that can be automatically evaluated. Our extensive benchmarking of 23 state-of-the-art LLMs uncovers the current challenges encountered in data analysis tasks. In addition, we have developed DAAgent, a specialized agent trained on instruction-tuning datasets. Evaluation datasets and toolkits for InfiAgent-DABench are released at https://github.com/InfiAgent/InfiAgent.
    
[^256]: 受过良好教育的智能的内在善良

    The inherent goodness of well educated intelligence. (arXiv:2401.04846v1 [econ.TH])

    [http://arxiv.org/abs/2401.04846](http://arxiv.org/abs/2401.04846)

    本文探讨了智能体变得智能的因素，强调了掌握特征和控制多个保守相互作用的子系统的能力。智能的核心是“集体如一体”和“了解局部行动的整体结果”。文章提出了一种对集体保守系统进行控制的替代方法。

    

    本文将探讨使一个智能体变得智能的因素，无论是生物体还是计算机上的人工智能。特别关注的是能够表征和控制多个保守相互作用的相同子系统的能力。智能的本质将被发现是黄金法则——“集体行动如一体”或“了解局部行动的整体结果”。集体的流动是由掌控着少量字符串的操纵者决定的，根据对称性确定的最小作用路径的测地线运动。控制集体保守系统是困难的，历史上一直通过为系统添加显著黏性来稳定期望的最大性能的亚稳平衡状态，但这会在过程中降低或破坏它们。有一种替代方案。

    This paper will examine what makes a being intelligent, whether that be a biological being or an artificial silicon being on a computer. Special attention will be paid to the being having the ability to characterize and control a collective system of many identical conservative sub-systems conservatively interacting. The essence of intelligence will be found to be the golden rule -- "the collective acts as one" or "knowing the global consequences of local actions". The flow of the collective is a small set of twinkling textures, that are governed by a puppeteer who is pulling a small number of strings according to a geodesic motion of least action, determined by the symmetries. Controlling collective conservative systems is difficult and has historically been done by adding significant viscosity to the system to stabilize the desirable meta stable equilibriums of maximum performance, but it degrades or destroys them in the process. There is an alternative. Once the optimum twinkling te
    
[^257]: 通过HTML内容的多模型分析检测网络钓鱼网站

    Phishing Website Detection through Multi-Model Analysis of HTML Content. (arXiv:2401.04820v1 [cs.CR])

    [http://arxiv.org/abs/2401.04820](http://arxiv.org/abs/2401.04820)

    本研究提出了一种基于HTML内容的高级检测模型，集成了多层感知器和预训练的自然语言处理模型，通过新颖的融合方法检测网络钓鱼网站。同时，我们还创造了一个最新的数据集来支持这项研究。

    

    随着互联网的兴起，我们的通信和工作方式发生了巨大的变化。虽然它为我们带来了新的机会，但也增加了网络威胁。其中一种常见且严重的威胁是网络钓鱼，黑客使用欺骗性方法窃取敏感信息。本研究通过引入一种基于HTML内容的先进检测模型，针对网络钓鱼问题进行了探讨。我们提出的方法集成了用于结构化表格数据的专门的多层感知器(MLP)模型和两个预训练的自然语言处理(NLP)模型，以分析页面标题和内容等文本特征。通过一种新颖的融合过程，这些模型生成的嵌入向量被和谐地组合在一起，并输入到线性分类器中。鉴于目前缺乏全面的网络钓鱼研究数据集，我们的贡献还包括创建一个最新的数据集

    The way we communicate and work has changed significantly with the rise of the Internet. While it has opened up new opportunities, it has also brought about an increase in cyber threats. One common and serious threat is phishing, where cybercriminals employ deceptive methods to steal sensitive information.This study addresses the pressing issue of phishing by introducing an advanced detection model that meticulously focuses on HTML content. Our proposed approach integrates a specialized Multi-Layer Perceptron (MLP) model for structured tabular data and two pretrained Natural Language Processing (NLP) models for analyzing textual features such as page titles and content. The embeddings from these models are harmoniously combined through a novel fusion process. The resulting fused embeddings are then input into a linear classifier. Recognizing the scarcity of recent datasets for comprehensive phishing research, our contribution extends to the creation of an up-to-date dataset, which we o
    
[^258]: SecureReg:一个结合方法用于主动暴露恶意域名注册

    SecureReg: A Combined Framework for Proactively Exposing Malicious Domain Name Registrations. (arXiv:2401.03196v1 [cs.CR])

    [http://arxiv.org/abs/2401.03196](http://arxiv.org/abs/2401.03196)

    SecureReg是一个结合了自然语言处理和多层感知器模型的方法，用于在域名注册过程中主动暴露恶意域名注册，提供了早期威胁检测的解决方案，显著减少了漏洞窗口，并为主动预防性操作做出了贡献。

    

    随着网络安全威胁不断增加，不法分子每天注册数千个新域名进行垃圾邮件、网络钓鱼和驱动下载等互联网攻击，强调了创新检测方法的需求。本文介绍了一种先进的方法，用于在注册过程开始时识别可疑域名。附带的数据流程通过比较新域名与注册域名产生关键特征，强调了关键相似度得分。利用自然语言处理（NLP）技术的新颖组合，包括预训练的Canine模型和多层感知器（MLP）模型，我们的系统分析语义和数值属性，为早期威胁检测提供了强大的解决方案。该综合方法显著减少了漏洞窗口，加强了对潜在威胁的防御。研究结果证明了该综合方法的有效性，并为开发主动预防性操作的努力做出了贡献。

    Rising cyber threats, with miscreants registering thousands of new domains daily for Internet-scale attacks like spam, phishing, and drive-by downloads, emphasize the need for innovative detection methods. This paper introduces a cutting-edge approach for identifying suspicious domains at the onset of the registration process. The accompanying data pipeline generates crucial features by comparing new domains to registered domains,emphasizing the crucial similarity score. Leveraging a novel combination of Natural Language Processing (NLP) techniques, including a pretrained Canine model, and Multilayer Perceptron (MLP) models, our system analyzes semantic and numerical attributes, providing a robust solution for early threat detection. This integrated approach significantly reduces the window of vulnerability, fortifying defenses against potential threats. The findings demonstrate the effectiveness of the integrated approach and contribute to the ongoing efforts in developing proactive s
    
[^259]: 一种解决人工智能黑盒问题的白盒解决方案

    A white box solution to the black box problem of AI. (arXiv:2401.03093v1 [cs.AI])

    [http://arxiv.org/abs/2401.03093](http://arxiv.org/abs/2401.03093)

    一种解决人工智能黑盒问题的白盒解决方案是使用基于相关领域一般理论的确定性逻辑细胞自动机的规则，该细胞自动机实现自动并行逻辑推理。

    

    基于神经网络的人工智能取得了重大进展。然而，由于缺乏透明性，对其可靠性和安全性存在担忧。这就是人工智能的黑盒问题。在这里，我们展示了如何使用符号 AI 来解决这个问题，符号 AI 具有透明的白盒性质。符号 AI 的广泛应用受到数学模型和自然语言术语的不透明性、缺乏统一本体论以及搜索选项的组合爆炸的阻碍。为了解决人工智能的黑盒问题并实现通用的符号 AI，我们提议使用基于相关领域一般理论的确定性逻辑细胞自动机的规则。在这种情况下，相关领域的一般理论起到了细胞自动机推理的知识库的作用。细胞自动机在复杂系统的三个层次上实现自动并行逻辑推理。

    Artificial intelligence based on neural networks has made significant progress. However, there are concerns about the reliability and security of this approach due to its lack of transparency. This is the black box problem of AI. Here we show how this problem can be solved using symbolic AI, which has a transparent white box nature. The widespread use of symbolic AI is hindered by the opacity of mathematical models and natural language terms, the lack of a unified ontology, and the combinatorial explosion of search options. To solve the AI black box problem and to implement general-purpose symbolic AI, we propose to use deterministic logic cellular automata with rules based on first principles of the general theory of the relevant domain. In this case, the general theory of the relevant domain plays the role of a knowledge base for the cellular automaton inference. A cellular automaton implements automatic parallel logical inference at three levels of organization of a complex system. 
    
[^260]: 关于图神经网络的表达能力研究

    On the Expressive Power of Graph Neural Networks. (arXiv:2401.01626v1 [cs.LG])

    [http://arxiv.org/abs/2401.01626](http://arxiv.org/abs/2401.01626)

    研究人员对图神经网络的表达能力和设计架构进行了大量工作，以提高其在各领域任务中的性能。主要方法包括研究GNN的通用逼近性质和其在区分不同图之间的能力程度。

    

    过去几年来，图神经网络的研究引起了相当大的兴趣。通过将深度学习扩展到图结构化数据，GNN可以解决社会科学、化学和医学等领域的各种任务。GNN架构的发展主要集中在改进节点或图分类等任务的实证性性能。然而，最近的一系列工作则寻求找到具有理论特性的GNN架构，通过研究其表达能力并设计最大化这种表达能力的架构。虽然关于如何定义GNN的表达能力还没有共识，但可以从几个有很好动机的角度来看待。也许最自然的方法是研究GNN的通用逼近性质，就像MLP的这种性质一样得到了广泛的研究。另一个方向关注的是GNN在区分不同图之间的能力程度。

    The study of Graph Neural Networks has received considerable interest in the past few years. By extending deep learning to graph-structured data, GNNs can solve a diverse set of tasks in fields including social science, chemistry, and medicine. The development of GNN architectures has largely been focused on improving empirical performance on tasks like node or graph classification. However, a line of recent work has instead sought to find GNN architectures that have desirable theoretical properties - by studying their expressive power and designing architectures that maximize this expressiveness.  While there is no consensus on the best way to define the expressiveness of a GNN, it can be viewed from several well-motivated perspectives. Perhaps the most natural approach is to study the universal approximation properties of GNNs, much in the way that this has been studied extensively for MLPs. Another direction focuses on the extent to which GNNs can distinguish between different graph
    
[^261]: 基于大型语言模型的对话代理的即插即用策略规划器

    Plug-and-Play Policy Planner for Large Language Model Powered Dialogue Agents. (arXiv:2311.00262v1 [cs.CL])

    [http://arxiv.org/abs/2311.00262](http://arxiv.org/abs/2311.00262)

    基于大型语言模型的对话代理的即插即用策略规划器(PDDPP)引入了一种新的对话策略规划范式，通过可调整的语言模型插件实现主动对话问题的策略制定。利用监督微调和强化学习，该框架在处理新的案例时具有较高的灵活性和性能。

    

    在大型语言模型（LLMs）的时代中，主动对话作为一个实际但具有挑战性的对话问题，对话策略规划是提高LLMs主动性的关键。大多数现有研究使用各种提示方案或通过语言人工智能反馈迭代增强对LLMs的对话策略规划能力。然而，这些方法要么受限于冻结的LLMs的策略规划能力，要么难以转移到新的案例。在这项工作中，我们引入了一种新的对话策略规划范式，以使用可调整的语言模型插件作为即插即用的对话策略规划器来制定LLMs在主动对话问题上的策略，命名为PPDPP。具体而言，我们开发了一个新颖的训练框架，以便利用可用的人工注释数据进行监督微调，并通过基于LLM的自我对弈收集的动态交互数据进行强化学习。

    Proactive dialogues serve as a practical yet challenging dialogue problem in the era of large language models (LLMs), where the dialogue policy planning is the key to improving the proactivity of LLMs. Most existing studies enable the dialogue policy planning of LLMs using various prompting schemes or iteratively enhance this capability in handling the given case with verbal AI feedback. However, these approaches are either bounded by the policy planning capability of the frozen LLMs or hard to be transferred to new cases. In this work, we introduce a new dialogue policy planning paradigm to strategize LLMs for proactive dialogue problems with a tunable language model plug-in as a plug-and-play dialogue policy planner, named PPDPP. Specifically, we develop a novel training framework to facilitate supervised fine-tuning over available human-annotated data as well as reinforcement learning from goal-oriented AI feedback with dynamic interaction data collected by the LLM-based self-play s
    
[^262]: CycleNet：重新思考文本引导扩散中的循环一致性，以进行图像操作

    CycleNet: Rethinking Cycle Consistency in Text-Guided Diffusion for Image Manipulation. (arXiv:2310.13165v1 [cs.CV])

    [http://arxiv.org/abs/2310.13165](http://arxiv.org/abs/2310.13165)

    CycleNet是一种将循环一致性引入扩散模型的新方法，用于规范图像操作，具有优越的翻译一致性和质量，并且可以生成高质量的跨领域分布图像。

    

    扩散模型（DM）在图像合成任务中取得了突破，但缺乏一种直观的一致图像到图像（I2I）翻译接口。为解决这个问题，已经探索了各种方法，包括基于掩码的方法，基于注意力的方法和基于图像的方法。然而，如何使用预训练的DMs进行无配对的I2I翻译并保持一致性仍然是一个关键挑战。本文介绍了Cyclenet，一种新颖但简单的方法，它将循环一致性纳入DMs中，以规范图像操作。我们验证了Cyclenet在不同粒度的无配对I2I任务上的优势。除了场景和对象级别的翻译，我们还贡献了一个多领域I2I翻译数据集，用于研究物体的物理状态变化。我们的实证研究表明，Cyclenet在翻译的一致性和质量方面具有优势，并且在改变文本描述时可以生成高质量的跨领域分布图像。

    Diffusion models (DMs) have enabled breakthroughs in image synthesis tasks but lack an intuitive interface for consistent image-to-image (I2I) translation. Various methods have been explored to address this issue, including mask-based methods, attention-based methods, and image-conditioning. However, it remains a critical challenge to enable unpaired I2I translation with pre-trained DMs while maintaining satisfying consistency. This paper introduces Cyclenet, a novel but simple method that incorporates cycle consistency into DMs to regularize image manipulation. We validate Cyclenet on unpaired I2I tasks of different granularities. Besides the scene and object level translation, we additionally contribute a multi-domain I2I translation dataset to study the physical state changes of objects. Our empirical studies show that Cyclenet is superior in translation consistency and quality, and can generate high-quality images for out-of-domain distributions with a simple change of the textual 
    
[^263]: 构建具有多样数据损坏情况下鲁棒性的离线强化学习

    Towards Robust Offline Reinforcement Learning under Diverse Data Corruption. (arXiv:2310.12955v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.12955](http://arxiv.org/abs/2310.12955)

    本文研究了在多种数据损坏情况下，离线强化学习算法的性能。研究发现，隐式Q-learning（IQL）在各种离线强化学习算法中展现出了较强的鲁棒性能，其采用的监督策略学习方案为关键。然而，在动力学损坏下，IQL仍然存在Q函数的重尾目标问题。

    

    离线强化学习（RL）是一种有前途的方法，可以从离线数据集中学习强化策略，而无需与环境进行昂贵或不安全的交互。然而，人们在真实环境中收集的数据集往往存在噪声，甚至可能被恶意损坏，这可能会严重影响离线强化学习的性能。本研究首先对当前离线强化学习算法在包括状态、动作、奖励和动力学在内的全面数据损坏情况下的性能进行了调查。我们的大量实验显示，隐式Q-learning（IQL）在各种离线强化学习算法中表现出了可靠的抗数据损坏能力。此外，我们还进行了经验和理论分析，以了解IQL的鲁棒性能，并将其监督策略学习方案确定为关键因素。尽管相对鲁棒，但IQL在动力学损坏下仍然存在Q函数的重尾目标问题。

    Offline reinforcement learning (RL) presents a promising approach for learning reinforced policies from offline datasets without the need for costly or unsafe interactions with the environment. However, datasets collected by humans in real-world environments are often noisy and may even be maliciously corrupted, which can significantly degrade the performance of offline RL. In this work, we first investigate the performance of current offline RL algorithms under comprehensive data corruption, including states, actions, rewards, and dynamics. Our extensive experiments reveal that implicit Q-learning (IQL) demonstrates remarkable resilience to data corruption among various offline RL algorithms. Furthermore, we conduct both empirical and theoretical analyses to understand IQL's robust performance, identifying its supervised policy learning scheme as the key factor. Despite its relative robustness, IQL still suffers from heavy-tail targets of Q functions under dynamics corruption. To tack
    
[^264]: 超越文档边界的上下文预训练：语言模型

    In-Context Pretraining: Language Modeling Beyond Document Boundaries. (arXiv:2310.10638v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.10638](http://arxiv.org/abs/2310.10638)

    本论文提出了一种超越文档边界的上下文预训练方法，通过在相关文档序列上训练语言模型，鼓励模型进行跨文档的阅读和推理。该方法通过改变文档顺序并应用现有的预训练管道来实现。

    

    目前，大型语言模型（LMs）通过预测给定文档前缀的标记来进行训练，从而能够直接进行长篇生成和提示式任务，这可以简化为文档完成。现有的预训练管道通过连接随机组合的短文档来训练LMs，以创建输入上下文，但前一个文档对于预测下一个文档没有提供任何信号。我们提出了一种新方法——上下文预训练，即在相关文档序列上预先训练语言模型，从而明确鼓励它们跨越文档边界进行阅读和推理。我们可以通过改变文档顺序，使每个上下文包含相关的文档，并直接应用现有的预训练管道来进行上下文预训练。然而，这个文档排序问题很具有挑战性。有数十亿个文档，我们希望在每个文档中最大化上下文相似性而不重复任何数据。

    Large language models (LMs) are currently trained to predict tokens given document prefixes, enabling them to directly perform long-form generation and prompting-style tasks which can be reduced to document completion. Existing pretraining pipelines train LMs by concatenating random sets of short documents to create input contexts but the prior documents provide no signal for predicting the next document. We instead present In-Context Pretraining, a new approach where language models are pretrained on a sequence of related documents, thereby explicitly encouraging them to read and reason across document boundaries. We can do In-Context Pretraining by simply changing the document ordering so that each context contains related documents, and directly applying existing pretraining pipelines. However, this document sorting problem is challenging. There are billions of documents and we would like the sort to maximize contextual similarity for every document without repeating any data. To do
    
[^265]: SiamAF: 学习心电图和光电脉搏图信号的共享信息用于强健的心房颤动检测

    SiamAF: Learning Shared Information from ECG and PPG Signals for Robust Atrial Fibrillation Detection. (arXiv:2310.09203v1 [cs.LG])

    [http://arxiv.org/abs/2310.09203](http://arxiv.org/abs/2310.09203)

    提出了一种名为SiamAF的新方法，利用心电图和光电脉搏图信号的共享信息，通过Siamese网络和联合学习实现强健的心房颤动（AF）检测。

    

    心房颤动（AF）是最常见的心脏心律失常类型，与中风、心力衰竭和其他心血管并发症的风险增加有关，但可以临床上无声。佩戴式设备进行被动性的AF监测可能有助于减少与AF相关的不良临床结果。在嘈杂的佩戴式数据中检测AF面临重大挑战，引发了各种不同的深度学习技术。先前的深度学习模型从单一形态学习，要么是心电图（ECG），要么是光电脉搏图（PPG）信号。然而，深度学习模型往往难以学习可泛化的特征，并依赖于更容易受到噪声损坏的特征，在某些场景中导致次优的性能，特别是在低质量信号的情况下。鉴于佩戴式设备和床边监护仪上ECG和PPG信号配对的日益丰富，我们提出了一种新的方法SiamAF，利用一种新颖的Siamese网络结构和联合学习的方法。

    Atrial fibrillation (AF) is the most common type of cardiac arrhythmia. It is associated with an increased risk of stroke, heart failure, and other cardiovascular complications, but can be clinically silent. Passive AF monitoring with wearables may help reduce adverse clinical outcomes related to AF. Detecting AF in noisy wearable data poses a significant challenge, leading to the emergence of various deep learning techniques. Previous deep learning models learn from a single modality, either electrocardiogram (ECG) or photoplethysmography (PPG) signals. However, deep learning models often struggle to learn generalizable features and rely on features that are more susceptible to corruption from noise, leading to sub-optimal performances in certain scenarios, especially with low-quality signals. Given the increasing availability of ECG and PPG signal pairs from wearables and bedside monitors, we propose a new approach, SiamAF, leveraging a novel Siamese network architecture and joint le
    
[^266]: METRA:具有度量感知抽象的可扩展无监督强化学习

    METRA: Scalable Unsupervised RL with Metric-Aware Abstraction. (arXiv:2310.08887v1 [cs.LG])

    [http://arxiv.org/abs/2310.08887](http://arxiv.org/abs/2310.08887)

    METRA提出了一种新的无监督强化学习目标，旨在使其在复杂的高维环境中可扩展。这个目标解决了纯探索方法在大状态空间环境中的困难以及互信息技能学习方法中缺乏激励而无法探索环境的问题。

    

    无监督预训练策略在自然语言处理和计算机视觉领域证明了其高效性。同样，无监督强化学习（RL）有望发现各种潜在有用的行为，可以加速学习各种下游任务。然而，尽管之前的尝试，使无监督RL真正可扩展仍然是一个重大的挑战：在具有大状态空间的复杂环境中，纯探索方法可能会面临困难，因为覆盖每个可能的转换是不可行的；而互信息技能学习方法可能由于缺乏激励而完全无法探索环境。为了使无监督RL在复杂的高维环境中可扩展，我们提出了一种新的无监督RL目标，称为度量感知抽象（METRA）。

    Unsupervised pre-training strategies have proven to be highly effective in natural language processing and computer vision. Likewise, unsupervised reinforcement learning (RL) holds the promise of discovering a variety of potentially useful behaviors that can accelerate the learning of a wide array of downstream tasks. Previous unsupervised RL approaches have mainly focused on pure exploration and mutual information skill learning. However, despite the previous attempts, making unsupervised RL truly scalable still remains a major open challenge: pure exploration approaches might struggle in complex environments with large state spaces, where covering every possible transition is infeasible, and mutual information skill learning approaches might completely fail to explore the environment due to the lack of incentives. To make unsupervised RL scalable to complex, high-dimensional environments, we propose a novel unsupervised RL objective, which we call Metric-Aware Abstraction (METRA). Ou
    
[^267]: InstructDET: 通用指令的引导下的指称对象检测的多样化方法

    InstructDET: Diversifying Referring Object Detection with Generalized Instructions. (arXiv:2310.05136v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2310.05136](http://arxiv.org/abs/2310.05136)

    我们提出了一种名为InstructDET的方法，可以通过多样化的指令定位目标对象并进行指称对象检测。我们构建了一个包含图像、边界框和泛化指令的数据集，其中利用了视觉语言模型和大型语言模型生成指令。

    

    我们提出了InstructDET，一种基于用户指令来定位目标对象的指称对象检测（ROD）的数据中心方法。我们利用了多样化的指令，涵盖与对象检测相关的常见用户意图。对于一张图像，我们生成了大量的指令，涉及每个单独的对象和多个对象的不同组合。每个指令及其对应的对象边界框构成一个训练数据对。为了包含常见的检测表达式，我们采用了新兴的视觉语言模型（VLM）和大型语言模型（LLM），通过文本提示和对象边界框生成指令，因为基础模型的泛化能力可以产生类似人类的表达（例如，描述对象属性、类别和关系）。我们将构建的数据集命名为InDET，包含图像、边界框和泛化指令。

    We propose InstructDET, a data-centric method for referring object detection (ROD) that localizes target objects based on user instructions. While deriving from referring expressions (REC), the instructions we leverage are greatly diversified to encompass common user intentions related to object detection. For one image, we produce tremendous instructions that refer to every single object and different combinations of multiple objects. Each instruction and its corresponding object bounding boxes (bbxs) constitute one training data pair. In order to encompass common detection expressions, we involve emerging vision-language model (VLM) and large language model (LLM) to generate instructions guided by text prompts and object bbxs, as the generalizations of foundation models are effective to produce human-like expressions (e.g., describing object property, category, and relationship). We name our constructed dataset as InDET. It contains images, bbxs and generalized instructions that are 
    
[^268]: 无需训练的线性图像反演方法：通过流进行

    Training-free Linear Image Inversion via Flows. (arXiv:2310.04432v1 [cs.CV])

    [http://arxiv.org/abs/2310.04432](http://arxiv.org/abs/2310.04432)

    提出了一种无需训练的线性图像反演方法，通过使用预训练的流模型，在减少手动调整的情况下解决逆问题。

    

    无需训练的线性反演方法使用预训练的生成模型，并通过对生成过程的适当修改来解决逆问题，而无需对生成模型进行调优。虽然最近的先前方法已经探索了扩散模型的使用，但仍需要手动调整许多超参数来应对不同的逆问题。在本文中，我们提出了一种使用预训练流模型进行图像反演的无需训练方法，利用了流匹配模型的简洁性和高效性，使用理论上合理的加权方案，从而显著减少了手动调整的工作量。具体而言，我们从两个主要源头汲取灵感：将先前的梯度校正方法应用于流领域，以及基于条件最优传输路径的求解器方案。由于预训练的扩散模型广泛可用，我们还展示了如何将扩散模型实际应用于我们的方法。实验结果表明，我们的方法在多个逆问题上实现了较好的性能。

    Training-free linear inversion involves the use of a pretrained generative model and -- through appropriate modifications to the generation process -solving inverse problems without any finetuning of the generative model. While recent prior methods have explored the use of diffusion models, they still require the manual tuning of many hyperparameters for different inverse problems. In this work, we propose a training-free method for image inversion using pretrained flow models, leveraging the simplicity and efficiency of Flow Matching models, using theoretically-justified weighting schemes and thereby significantly reducing the amount of manual tuning. In particular, we draw inspiration from two main sources: adopting prior gradient correction methods to the flow regime, and a solver scheme based on conditional Optimal Transport paths. As pretrained diffusion models are widely accessible, we also show how to practically adapt diffusion models for our method. Empirically, our approach
    
[^269]: 准确的冷启动捆绑推荐：基于流行度的聚合和课程加热

    Accurate Cold-start Bundle Recommendation via Popularity-based Coalescence and Curriculum Heating. (arXiv:2310.03813v1 [cs.IR])

    [http://arxiv.org/abs/2310.03813](http://arxiv.org/abs/2310.03813)

    本文提出了CoHeat算法，一种准确的冷启动捆绑推荐方法。该算法通过结合历史和关联信息，应对捆绑互动分布的倾斜，并有效地学习潜在表示。

    

    如何准确地向用户推荐冷启动捆绑？捆绑推荐中的冷启动问题在实际场景中至关重要，因为新建捆绑不断出现以满足各种营销目的。尽管其重要性，之前没有研究涉及冷启动捆绑推荐。此外，现有的冷启动物品推荐方法过于依赖历史信息，即使对于不受欢迎的捆绑也是如此，无法应对捆绑互动分布高度倾斜的主要挑战。在这项工作中，我们提出了CoHeat（基于流行度的聚合和课程加热），这是一种准确的冷启动捆绑推荐方法。CoHeat通过结合历史信息和关联信息来估计用户与捆绑之间的关系，以应对捆绑互动分布的高度倾斜问题。此外，CoHeat还通过利用课程学习和聚合特征学习效果地学习潜在表示。

    How can we accurately recommend cold-start bundles to users? The cold-start problem in bundle recommendation is critical in practical scenarios since new bundles are continuously created for various marketing purposes. Despite its importance, no previous studies have addressed cold-start bundle recommendation. Moreover, existing methods for cold-start item recommendation overly rely on historical information, even for unpopular bundles, failing to tackle the primary challenge of the highly skewed distribution of bundle interactions. In this work, we propose CoHeat (Popularity-based Coalescence and Curriculum Heating), an accurate approach for the cold-start bundle recommendation. CoHeat tackles the highly skewed distribution of bundle interactions by incorporating both historical and affiliation information based on the bundle's popularity when estimating the user-bundle relationship. Furthermore, CoHeat effectively learns latent representations by exploiting curriculum learning and co
    
[^270]: 扩散生成流采样器：通过部分轨迹优化改善学习信号

    Diffusion Generative Flow Samplers: Improving learning signals through partial trajectory optimization. (arXiv:2310.02679v1 [cs.LG])

    [http://arxiv.org/abs/2310.02679](http://arxiv.org/abs/2310.02679)

    这项工作介绍了一种名为扩散生成流采样器（DGFS）的采样框架，通过将学习过程分解为短的部分轨迹段，实现从难以处理的高维密度函数中进行采样。它通过利用中间的学习信号和非策略探索能力来改善学习信号的分配问题。

    

    我们解决了从难以处理的高维密度函数中进行采样的问题，这是在机器学习和统计中经常出现的基本任务。我们扩展了最近的基于采样的方法，利用控制的随机过程来模拟这些目标密度的近似样本。这些方法的主要缺点是训练目标需要计算完整的轨迹，导致由于使用完整轨迹和只在终端时间存在的学习信号的使用而产生缓慢的信用分配问题。在这项工作中，我们提出了扩散生成流采样器（DGFS），这是一个基于采样的框架，可以将学习过程可行地分解为短的部分轨迹段，通过参数化一个额外的“流函数”。我们的方法借鉴了生成流网络（GFlowNets）的理论，使我们能够利用中间的学习信号，并从非策略探索能力中受益。

    We tackle the problem of sampling from intractable high-dimensional density functions, a fundamental task that often appears in machine learning and statistics. We extend recent sampling-based approaches that leverage controlled stochastic processes to model approximate samples from these target densities. The main drawback of these approaches is that the training objective requires full trajectories to compute, resulting in sluggish credit assignment issues due to use of entire trajectories and a learning signal present only at the terminal time. In this work, we present Diffusion Generative Flow Samplers (DGFS), a sampling-based framework where the learning process can be tractably broken down into short partial trajectory segments, via parameterizing an additional "flow function". Our method takes inspiration from the theory developed for generative flow networks (GFlowNets), allowing us to make use of intermediate learning signals and benefit from off-policy exploration capabilitie
    
[^271]: 理解和减轻预训练中的标签噪声对下游任务的影响

    Understanding and Mitigating the Label Noise in Pre-training on Downstream Tasks. (arXiv:2309.17002v1 [cs.LG])

    [http://arxiv.org/abs/2309.17002](http://arxiv.org/abs/2309.17002)

    本文研究了深度学习中预训练数据中的标签噪声对下游任务的影响，并通过在合成噪声数据集上的实验证明，在预训练中的轻微噪声可以提高领域内的性能，但会损害领域外的性能。为了减轻噪声的影响，提出了一种轻量级的黑盒调整方法（NMTune）。

    

    在深度学习中，先在大规模数据集上进行预训练，然后在下游任务上进行微调已经成为一种标准做法。然而，预训练数据通常包含标签噪声，这可能对模型的泛化能力产生不利影响。本文旨在了解预训练数据集中噪声的性质，并减轻其对下游任务的影响。具体而言，通过在合成噪声的ImageNet-1K和YFCC15M数据集上进行大量实验，我们证明在预训练中的轻微噪声可以促进领域内的转移性能，即训练和测试数据具有相同的分布；然而，它总是会损害领域外的性能，即训练和测试数据具有不同的分布。我们通过实验证实，预训练中的噪声会不同地塑造特征空间。然后我们提出了一种轻量级的黑盒调整方法（NMTune）来使特征空间达到映射并减轻噪声的影响。

    Pre-training on large-scale datasets and then fine-tuning on downstream tasks have become a standard practice in deep learning. However, pre-training data often contain label noise that may adversely affect the generalization of the model. This paper aims to understand the nature of noise in pre-training datasets and to mitigate its impact on downstream tasks. More specifically, through extensive experiments of supervised pre-training models on synthetic noisy ImageNet-1K and YFCC15M datasets, we demonstrate that while slight noise in pre-training can benefit in-domain (ID) transfer performance, where the training and testing data share the same distribution, it always deteriorates out-of-domain (OOD) performance, where training and testing data distribution are different. We empirically verify that the reason behind is noise in pre-training shapes the feature space differently. We then propose a lightweight black-box tuning method (NMTune) to affine the feature space to mitigate the m
    
[^272]: ModuLoRA:通过与模块化量化器集成在消费级GPU上对3 Bit LLMs进行微调

    ModuLoRA: Finetuning 3-Bit LLMs on Consumer GPUs by Integrating with Modular Quantizers. (arXiv:2309.16119v1 [cs.LG])

    [http://arxiv.org/abs/2309.16119](http://arxiv.org/abs/2309.16119)

    ModuLoRA提出了一种内存高效、能够在消费级GPU上支持3比特LLMs微调的方法，并通过与模块化量化器的集成实现了竞争性能和更少的内存使用。

    

    我们提出了一种内存高效的大型语言模型（LLMs）微调算法，可支持在仅使用1个48GB GPU上以3比特或4比特精度微调具有65B参数的LLMs。我们的方法——模块化低秩自适应（ModuLoRA），通过低秩适配器（LoRA）将任何用户指定的权重量化器与微调集成。我们的方法依赖于一个简单的量化无关的反向传播，通过自定义的黑盒量化模块从低精度LLM权重中自适应地生成权重。这种方法使得首次能够进行3比特LLMs的微调，利用先进的3比特OPTQ量化往往优于依赖于较不复杂的4比特和8比特方法的微调。在我们的实验中，ModuLoRA在文本分类、自然语言推理和指令跟随任务中取得了有竞争力的性能，使用的内存比现有方法少很多，并且在一个流行的摘要任务上超过了最先进的ROUGE分数。

    We propose a memory-efficient finetuning algorithm for large language models (LLMs) that supports finetuning LLMs with 65B parameters in 3-bit or 4-bit precision on as little as one 48GB GPU. Our method, modular low-rank adaptation (ModuLoRA), integrates any user-specified weight quantizer with finetuning via low-rank adapters (LoRAs). Our approach relies on a simple quantization-agnostic backward pass that adaptively materializes low-precision LLM weights from a custom black-box quantization module. This approach enables finetuning 3-bit LLMs for the first time--leveraging state-of-the-art 3-bit OPTQ quantization often outperforms finetuning that relies on less sophisticated 4-bit and 8-bit methods. In our experiments, ModuLoRA attains competitive performance on text classification, natural language infernece, and instruction following tasks using significantly less memory than existing approaches, and we also surpass the state-of-the-art ROUGE score on a popular summarization task. W
    
[^273]: STARC:评估奖励函数之间差异的通用框架

    STARC: A General Framework For Quantifying Differences Between Reward Functions. (arXiv:2309.15257v1 [cs.LG])

    [http://arxiv.org/abs/2309.15257](http://arxiv.org/abs/2309.15257)

    这篇论文提出了一个通用框架（STARC），用于评估奖励函数之间的差异，填补了奖励学习理论基础的空白。

    

    为了使用强化学习解决任务，需要将任务的目标形式化为奖励函数。然而，对于许多现实世界的任务来说，手动指定一个永不激励不良行为的奖励函数非常困难。因此，使用奖励学习算法来从数据中学习奖励函数变得越来越流行。然而，奖励学习的理论基础尚未完善。特别地，通常不知道给定的奖励学习算法在高概率下是否会学习到一个安全优化的奖励函数。这意味着奖励学习算法通常必须经过经验评估，这是昂贵的，并且很难预测其失效模式。其中一个阻碍获得更好理论保证的障碍是缺乏较好的方法来量化奖励函数之间的差异。在本文中，我们提供了一种解决方案。

    In order to solve a task using reinforcement learning, it is necessary to first formalise the goal of that task as a reward function. However, for many real-world tasks, it is very difficult to manually specify a reward function that never incentivises undesirable behaviour. As a result, it is increasingly popular to use reward learning algorithms, which attempt to learn a reward function from data. However, the theoretical foundations of reward learning are not yet well-developed. In particular, it is typically not known when a given reward learning algorithm with high probability will learn a reward function that is safe to optimise. This means that reward learning algorithms generally must be evaluated empirically, which is expensive, and that their failure modes are difficult to predict in advance. One of the roadblocks to deriving better theoretical guarantees is the lack of good methods for quantifying the difference between reward functions. In this paper we provide a solution t
    
[^274]: 导航文本到图像定制：从LyCORIS微调到模型评估

    Navigating Text-To-Image Customization:From LyCORIS Fine-Tuning to Model Evaluation. (arXiv:2309.14859v1 [cs.CV])

    [http://arxiv.org/abs/2309.14859](http://arxiv.org/abs/2309.14859)

    本文介绍了LyCORIS，一个开源库，提供了多种稳定扩散模型的微调方法，并提出了一个系统评估的全面框架。

    

    文本到图像生成模型因其能够从文本提示生成高保真度图像而受到广泛关注。其中，稳定扩散模型作为领先的开源模型在这个快速发展的领域中表现出色。然而，微调这些模型的复杂性给新方法的整合和系统评估带来了多重挑战。本文介绍了LyCORIS（Lora beYond Conventional methods，Other Rank adaptation Implementations for Stable diffusion）[https://github.com/KohakuBlueleaf/LyCORIS]，这是一个开源库，提供了多种稳定扩散模型的微调方法。此外，我们还提出了一个系统评估的全面框架，该框架采用了多样化的指标，并深入研究了微调的多个方面，包括超参数调整和在不同概念类别下使用不同提示类型的评估。

    Text-to-image generative models have garnered immense attention for their ability to produce high-fidelity images from text prompts. Among these, Stable Diffusion distinguishes itself as a leading open-source model in this fast-growing field. However, the intricacies of fine-tuning these models pose multiple challenges from new methodology integration to systematic evaluation. Addressing these issues, this paper introduces LyCORIS (Lora beYond Conventional methods, Other Rank adaptation Implementations for Stable diffusion) [https://github.com/KohakuBlueleaf/LyCORIS], an open-source library that offers a wide selection of fine-tuning methodologies for Stable Diffusion. Furthermore, we present a thorough framework for the systematic assessment of varied fine-tuning techniques. This framework employs a diverse suite of metrics and delves into multiple facets of fine-tuning, including hyperparameter adjustments and the evaluation with different prompt types across various concept categori
    
[^275]: LMSYS-Chat-1M：一个大规模实际语言模型对话数据集

    LMSYS-Chat-1M: A Large-Scale Real-World LLM Conversation Dataset. (arXiv:2309.11998v1 [cs.CL])

    [http://arxiv.org/abs/2309.11998](http://arxiv.org/abs/2309.11998)

    LMSYS-Chat-1M是一个包含一百万个实际对话的大规模数据集，通过其多样性和用例展示了其在理解和推进LLM能力方面的价值。

    

    随着大规模语言模型（LLM）在各种应用中的广泛使用，研究人们如何在实际场景中与其交互变得越来越重要。在本文中，我们介绍了LMSYS-Chat-1M，这是一个包含一百万个与25个最先进的LLM进行的实际对话的大规模数据集。这个数据集是从我们的Vicuna演示和Chatbot Arena网站上的21万个独立IP地址中收集而来的。我们提供了数据集内容的概述，包括其策划过程、基本统计数据和主题分布，强调其多样性、独特性和规模。我们通过四个用例展示了它的多样性：开发与GPT-4表现相似的内容过滤模型、构建一个安全基准、训练与Vicuna表现相似的指令跟随模型、创建具有挑战性的基准问题。我们相信这个数据集将成为我们理解和推进LLM能力的宝贵资源。

    Studying how people interact with large language models (LLMs) in real-world scenarios is increasingly important due to their widespread use in various applications. In this paper, we introduce LMSYS-Chat-1M, a large-scale dataset containing one million real-world conversations with 25 state-of-the-art LLMs. This dataset is collected from 210K unique IP addresses in the wild on our Vicuna demo and Chatbot Arena website. We offer an overview of the dataset's content, including its curation process, basic statistics, and topic distribution, highlighting its diversity, originality, and scale. We demonstrate its versatility through four use cases: developing content moderation models that perform similarly to GPT-4, building a safety benchmark, training instruction-following models that perform similarly to Vicuna, and creating challenging benchmark questions. We believe that this dataset will serve as a valuable resource for understanding and advancing LLM capabilities. The dataset is pub
    
[^276]: 利用大型语言模型探索自我强化以改进学生生成的多项选择题解释

    Exploring Self-Reinforcement for Improving Learnersourced Multiple-Choice Question Explanations with Large Language Models. (arXiv:2309.10444v1 [cs.AI])

    [http://arxiv.org/abs/2309.10444](http://arxiv.org/abs/2309.10444)

    本文提出了一个自我强化大型语言模型框架，自动生成和评估学生生成的解释，用于改进学生资源共享中学生生成的多项选择题的解释质量。

    

    学生资源共享涉及学生生成和分享学习资源。在学生生成多项选择题时，创建解释是一个关键步骤，因为它有助于对相关概念的深入理解。然而，学生往往由于主题理解有限和仅仅重申问题、干扰因素和正确答案的倾向而难以编写有效的解释。为了帮助支撑这个任务，在这项工作中，我们提出了一个自我强化的大型语言模型框架，旨在自动生成和评估解释。该框架由三个模块组成，生成与学生对齐的解释，评估这些解释以确保其质量，并迭代增强解释。如果一个解释的评估分数低于定义的阈值，框架会迭代地优化和重新评估解释。重要的是，我们的框架模拟了一个学生学习的过程。

    Learnersourcing involves students generating and sharing learning resources with their peers. When learnersourcing multiple-choice questions, creating explanations for the generated questions is a crucial step as it facilitates a deeper understanding of the related concepts. However, it is often difficult for students to craft effective explanations due to limited subject understanding and a tendency to merely restate the question stem, distractors, and correct answer. To help scaffold this task, in this work we propose a self-reinforcement large-language-model framework, with the goal of generating and evaluating explanations automatically. Comprising three modules, the framework generates student-aligned explanations, evaluates these explanations to ensure their quality and iteratively enhances the explanations. If an explanation's evaluation score falls below a defined threshold, the framework iteratively refines and reassesses the explanation. Importantly, our framework emulates th
    
[^277]: DoLa：通过对比层次提高大型语言模型中的真实性

    DoLa: Decoding by Contrasting Layers Improves Factuality in Large Language Models. (arXiv:2309.03883v1 [cs.CL])

    [http://arxiv.org/abs/2309.03883](http://arxiv.org/abs/2309.03883)

    DoLa通过对比不同层次的逻辑差异，提高大型语言模型中的真实性和减少幻觉，无需外部知识或微调。

    

    尽管大型语言模型（LLMs）具有令人印象深刻的能力，但它们容易出现幻觉，即生成与预训练期间观察到的事实偏离的内容。我们提出了一种简单的解码策略，用于减少预训练LLMs中的幻觉，它不需要在检索的外部知识或额外的微调上进行条件约束。我们的方法通过对比将较晚层和较早层投影到词汇空间得到的逻辑差异来获得下一个令牌的分布，利用了LLMs中的事实知识通常被证明局部化在特定的Transformer层中的事实。我们发现，这种通过对比层次的解码（DoLa）方法能够更好地展示事实知识，并减少生成不正确事实的情况。DoLa在多个选择任务和开放式生成任务中持续提升了真实性，例如改善了LLaMA系列模型在TruthfulQA上的表现。

    Despite their impressive capabilities, large language models (LLMs) are prone to hallucinations, i.e., generating content that deviates from facts seen during pretraining. We propose a simple decoding strategy for reducing hallucinations with pretrained LLMs that does not require conditioning on retrieved external knowledge nor additional fine-tuning. Our approach obtains the next-token distribution by contrasting the differences in logits obtained from projecting the later layers versus earlier layers to the vocabulary space, exploiting the fact that factual knowledge in an LLMs has generally been shown to be localized to particular transformer layers. We find that this Decoding by Contrasting Layers (DoLa) approach is able to better surface factual knowledge and reduce the generation of incorrect facts. DoLa consistently improves the truthfulness across multiple choices tasks and open-ended generation tasks, for example improving the performance of LLaMA family models on TruthfulQA b
    
[^278]: CodeApex：用于大型语言模型的双语编程评估基准

    CodeApex: A Bilingual Programming Evaluation Benchmark for Large Language Models. (arXiv:2309.01940v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2309.01940](http://arxiv.org/abs/2309.01940)

    CodeApex是一个双语编程评估基准，用于评估大型语言模型在编程理解和代码生成任务上的能力。该基准包括多个选择题和算法问题，评估了14个LLM的编程能力，并发现仍有改进空间。

    

    随着大型语言模型（LLM）的出现，模型的编程能力得到了显著提升，吸引了研究人员日益增长的关注。我们提出了CodeApex，一种双语基准数据集，专注于LLM的编程理解和代码生成能力。CodeApex包括三种类型的多项选择题：概念理解、常识推理和多跳推理，旨在评估LLM在编程理解任务上的能力。此外，CodeApex利用算法问题和相应的测试用例来评估LLM生成的代码质量。我们评估了14个最先进的LLM，包括通用和专门化模型。GPT展现出最佳的编程能力，在这两个任务上的准确率分别达到了约50%和56%。编程任务仍有很大的改进空间。我们希望CodeApex能够为评估编程能力提供参考。

    With the emergence of Large Language Models (LLMs), there has been a significant improvement in the programming capabilities of models, attracting growing attention from researchers. We propose CodeApex, a bilingual benchmark dataset focusing on the programming comprehension and code generation abilities of LLMs. CodeApex comprises three types of multiple-choice questions: conceptual understanding, commonsense reasoning, and multi-hop reasoning, designed to evaluate LLMs on programming comprehension tasks. Additionally, CodeApex utilizes algorithmic questions and corresponding test cases to assess the code quality generated by LLMs. We evaluate 14 state-of-the-art LLMs, including both general-purpose and specialized models. GPT exhibits the best programming capabilities, achieving approximate accuracies of 50% and 56% on the two tasks, respectively. There is still significant room for improvement in programming tasks. We hope that CodeApex can serve as a reference for evaluating the co
    
[^279]: 让LLM能够使用智能手机进行智能任务自动化

    Empowering LLM to use Smartphone for Intelligent Task Automation. (arXiv:2308.15272v1 [cs.AI])

    [http://arxiv.org/abs/2308.15272](http://arxiv.org/abs/2308.15272)

    本论文提出了AutoDroid，一个移动任务自动化系统，可以在任何Android应用程序上自动处理任意任务。它通过结合LLMs的常识知识和应用的领域特定知识来实现，通过自动化的动态分析来实现功能意识的UI表示方法和基于探索的内存注入技术。

    

    移动任务自动化是一种吸引人的技术，旨在实现基于语音的免提用户与智能手机的交互。然而，现有的方法由于语言理解能力有限，以及开发人员或终端用户需要付出非常努力的手动工作而导致可扩展性差。最近大型语言模型（LLMs）在语言理解和推理方面的进展激发了我们从模型中心化的角度重新思考这个问题，即通过统一的语言模型处理任务准备、理解和执行。在这项工作中，我们介绍了AutoDroid，这是一个能够在任何Android应用程序上无需手动工作处理任意任务的移动任务自动化系统。关键洞察力是通过自动化的动态分析将LLMs的常识知识与应用的领域特定知识相结合。主要组件包括功能意识的UI表示方法，桥接了UI和LLM，基于探索的内存注入技术

    Mobile task automation is an attractive technique that aims to enable voice-based hands-free user interaction with smartphones. However, existing approaches suffer from poor scalability due to the limited language understanding ability and the non-trivial manual efforts required from developers or end-users. The recent advance of large language models (LLMs) in language understanding and reasoning inspires us to rethink the problem from a model-centric perspective, where task preparation, comprehension, and execution are handled by a unified language model. In this work, we introduce AutoDroid, a mobile task automation system that can handle arbitrary tasks on any Android application without manual efforts. The key insight is to combine the commonsense knowledge of LLMs and domain-specific knowledge of apps through automated dynamic analysis. The main components include a functionality-aware UI representation method that bridges the UI with the LLM, exploration-based memory injection t
    
[^280]: SICNN: 受软干扰抵消启发的神经网络均衡器

    SICNN: Soft Interference Cancellation Inspired Neural Network Equalizers. (arXiv:2308.12591v1 [eess.SP])

    [http://arxiv.org/abs/2308.12591](http://arxiv.org/abs/2308.12591)

    SICNN是基于神经网络的均衡方法，通过深度展开基于模型的迭代SIC方法来设计，消除了基于模型方法的缺点。

    

    均衡是数字无线通信系统接收端的一项重要任务，传统上使用基于模型的估计方法来进行。在众多选项中，迭代软干扰抵消（SIC）是一种表现良好的方法，因为它避免了迭代估计过程中由硬决策数据符号估计引起的错误传播。然而，基于模型的方法存在高计算复杂度和性能降低的问题，因为需要进行逼近。在这项工作中，我们提出了一种新颖的基于神经网络（NN）的均衡方法，称为SICNN，通过对基于模型的迭代SIC方法进行深度展开来设计，消除了其基于模型的对应方法的主要缺点。我们提出了不同版本的SICNN。SICNNv1非常类似于基于模型的方法，专门为单载波频域均衡系统设计

    Equalization is an important task at the receiver side of a digital wireless communication system, which is traditionally conducted with model-based estimation methods. Among the numerous options for model-based equalization, iterative soft interference cancellation (SIC) is a well-performing approach since error propagation caused by hard decision data symbol estimation during the iterative estimation procedure is avoided. However, the model-based method suffers from high computational complexity and performance degradation due to required approximations. In this work, we propose a novel neural network (NN-)based equalization approach, referred to as SICNN, which is designed by deep unfolding of a model-based iterative SIC method, eliminating the main disadvantages of its model-based counterpart. We present different variants of SICNN. SICNNv1 is very similar to the model-based method, and is specifically tailored for single carrier frequency domain equalization systems, which is the 
    
[^281]: 大规模语言模型在软件工程中的应用：系统性文献综述

    Large Language Models for Software Engineering: A Systematic Literature Review. (arXiv:2308.10620v2 [cs.SE] UPDATED)

    [http://arxiv.org/abs/2308.10620](http://arxiv.org/abs/2308.10620)

    通过系统性文献综述，本研究调查了大规模语言模型（LLM）在软件工程领域中的应用，并集中于了解如何利用LLM来优化软件工程过程和结果。文章总结了不同LLM的特点和用途以及数据收集和预处理方法的重要性。

    

    大规模语言模型（LLM）在包括软件工程在内的多个领域产生了显著影响。许多最近的文献探讨了LLM在各种软件工程任务和应用中的应用。然而，对LLM在软件工程中的应用、影响和可能的限制的全面理解仍处于初级阶段。为了弥补这一差距，我们对LLM与软件工程的交叉领域进行了系统性文献综述，特别关注LLM在软件工程中如何被利用来优化过程和结果的理解。我们收集和分析了2017年至2023年的229篇研究论文，以回答四个关键研究问题（RQs）。在RQ1中，我们对在软件工程任务中使用的不同LLM进行分类和比较分析，描绘其独特的特点和用途。在RQ2中，我们分析数据收集、预处理和应用中使用的方法，强调了强大、精心策划的数据集对于成功利用LLM非常重要。

    Large Language Models (LLMs) have significantly impacted numerous domains, including Software Engineering (SE). Many recent publications have explored LLMs applied to various SE tasks and applications. Nevertheless, a comprehensive understanding of the application, effects, and possible limitations of LLMs on SE is still in its early stages. To bridge this gap, we conducted a systematic literature review on the intersection of LLMs and SE, with a particular focus on understanding how LLMs can be exploited in SE to optimize processes and outcomes. We collect and analyze a total of 229 research papers from 2017 to 2023 to answer four key research questions (RQs). In RQ1, we categorize and provide a comparative analysis of different LLMs that have been employed in SE tasks, characterising their distinctive features and uses. In RQ2, we analyse the methods used in data collection, preprocessing, and application highlighting the role of robust, well-curated datasets for successful LLM for S
    
[^282]: 通过基于嘴唇-音素字级相关性的视觉预训练和跨模态融合编码器来改进视听语音识别

    Improving Audio-Visual Speech Recognition by Lip-Subword Correlation Based Visual Pre-training and Cross-Modal Fusion Encoder. (arXiv:2308.08488v1 [cs.CL])

    [http://arxiv.org/abs/2308.08488](http://arxiv.org/abs/2308.08488)

    本文提出了通过基于嘴唇-音素字级相关性的视觉预训练和跨模态融合编码器来改进视听语音识别的两种新技术。这些技术可以在预训练和微调阶段准确对齐音频和视频流，并且充分利用模态互补性。

    

    最近的研究中观察到，在低质量视频的端到端框架下，从自动语音识别系统到视听语音识别系统的性能略有改进。据认为，音频和视觉模态之间不匹配的收敛速度和专门的输入表示导致了这个问题。在本文中，我们提出了两种新技术来改进视听语音识别（AVSR）在预训练和微调训练框架下。首先，我们探索了普通话中嘴唇形状和音节级音素字单元之间的相关性，以建立准确的帧级音节边界。这使得在视觉模型预训练和跨模态融合过程中能够对齐视频和音频流。接下来，我们提出了一种音频引导的跨模态融合编码器（CMFE）神经网络，利用主要训练参数来实现多个跨模态注意力层的充分利用模态互补性。在实验上进行了验证

    In recent research, slight performance improvement is observed from automatic speech recognition systems to audio-visual speech recognition systems in the end-to-end framework with low-quality videos. Unmatching convergence rates and specialized input representations between audio and visual modalities are considered to cause the problem. In this paper, we propose two novel techniques to improve audio-visual speech recognition (AVSR) under a pre-training and fine-tuning training framework. First, we explore the correlation between lip shapes and syllable-level subword units in Mandarin to establish good frame-level syllable boundaries from lip shapes. This enables accurate alignment of video and audio streams during visual model pre-training and cross-modal fusion. Next, we propose an audio-guided cross-modal fusion encoder (CMFE) neural network to utilize main training parameters for multiple cross-modal attention layers to make full use of modality complementarity. Experiments on the
    
[^283]: 深度布拉德利-特里评分：在没有具体评价标准的情况下估计物品的属性

    Deep Bradley-Terry Rating: Estimate Properties Without Metric of Unseen Items. (arXiv:2307.13709v1 [cs.LG])

    [http://arxiv.org/abs/2307.13709](http://arxiv.org/abs/2307.13709)

    本论文提出了深度布拉德利-特里评分（DBTR）方法，用于评估不一定存在于数据集中的未知物品的属性。该方法通过将传统的布拉德利-特里模型与神经网络结构无缝结合，成功地学习了这些属性的预期量化。

    

    在现实世界中，许多属性，如竞争环境中的可取性或强度，无法直接观测，这使得它们难以评估。为了解决这个具有挑战性的问题，先前的研究主要集中在估计已知物品的这些属性，特别是出现在配对比较数据集中的运动员的实力。在本文中，我们介绍了深度布拉德利-特里评分（DBTR），这是一个新颖的机器学习框架，用于评估不一定存在于数据集中的未知物品的任何属性。我们的方法无缝地将传统的布拉德利-特里模型与神经网络结构相结合。我们还进一步推广了这个架构，用于具有不公平性的非对称环境，这在现实世界中更为常见。在我们的实验分析中，DBTR成功地学习了这些属性的预期量化。

    Many properties in real world, such as desirability or strength in competitive environment, can't be directly observed, which makes them difficult to evaluate. To deal with this challenging problem, prior work has primarily focused on estimating those properties of known items, especially the strength of sports players, only of those who appears in paired comparison dataset. In this paper, we introduce Deep Bradley-Terry Rating (DBTR), a novel ML framework to evaluate any properties of unknown items, not necessarily present in dataset. Our method seamlessly integrates traditional Bradley-Terry model with a neural network structure. We also generalizes this architecture further for asymmetric environment with unfairness, which is much more common in real world settings. In our experimental analysis, DBTR successfully learned desired quantification of those properties.
    
[^284]: HIQL: 以潜在状态作为动作的离线目标导向强化学习

    HIQL: Offline Goal-Conditioned RL with Latent States as Actions. (arXiv:2307.11949v1 [cs.LG])

    [http://arxiv.org/abs/2307.11949](http://arxiv.org/abs/2307.11949)

    本文提出了一个基于离线数据的目标导向强化学习的分层算法，通过利用目标达成问题的结构，使用一个无动作的价值函数学习了两个策略，从而在学习过程中更有效地利用离线数据。

    

    无监督预训练最近已成为计算机视觉和自然语言处理的基石。在强化学习中，目标导向强化学习可以潜在地利用大量未标记的（无奖励）数据，提供类似于自我监督的方法。然而，构建有效的目标导向强化学习算法并直接从多样化的离线数据中进行学习是具有挑战性的，因为准确估计远期目标的价值函数很困难。然而，目标达成问题表现出一定的结构，即达到远期目标需要首先通过较近子目标。这种结构非常有用，因为评估邻近目标的动作质量通常比更远目标容易。基于这一思想，我们提出了一个基于离线数据的目标导向强化学习的分层算法。利用一个没有动作的价值函数，我们学习了两个策略，允许我们利用这种结构：一个高层策略

    Unsupervised pre-training has recently become the bedrock for computer vision and natural language processing. In reinforcement learning (RL), goal-conditioned RL can potentially provide an analogous self-supervised approach for making use of large quantities of unlabeled (reward-free) data. However, building effective algorithms for goal-conditioned RL that can learn directly from diverse offline data is challenging, because it is hard to accurately estimate the exact value function for faraway goals. Nonetheless, goal-reaching problems exhibit structure, such that reaching distant goals entails first passing through closer subgoals. This structure can be very useful, as assessing the quality of actions for nearby goals is typically easier than for more distant goals. Based on this idea, we propose a hierarchical algorithm for goal-conditioned RL from offline data. Using one action-free value function, we learn two policies that allow us to exploit this structure: a high-level policy 
    
[^285]: 过度思考真相：理解语言模型如何处理虚假演示

    Overthinking the Truth: Understanding how Language Models Process False Demonstrations. (arXiv:2307.09476v1 [cs.LG])

    [http://arxiv.org/abs/2307.09476](http://arxiv.org/abs/2307.09476)

    该论文研究了现代语言模型在处理虚假演示时出现的过度思考和错误归纳头现象。通过研究模型的内部表示，发现模型在中间层之后对错误演示的处理准确性逐渐降低，并指出了错误归纳头机制可能导致过度思考现象。

    

    现代语言模型可以通过少量示范进行复杂模式的模仿学习，使其能够在没有微调的情况下完成具有挑战性的任务。然而，模仿也可能导致模型在上下文中重现不准确或有害的内容。我们通过模型的内部表示来研究有害的模仿，并确定了两个相关现象：过度思考和错误归纳头。第一个现象，过度思考，在给出正确与错误的少量示范时，我们从中间层解码预测。在早期层中，两种示范引起了相似的模型行为，但在某个“关键层”之后，给出错误示范的准确性逐渐降低。第二个现象，错误归纳头，可能是过度思考的一种机制性原因：这些是位于较晚层的头部，它们关注并复制先前示范中的错误信息，其削弱会减少过度思考现象。

    Modern language models can imitate complex patterns through few-shot learning, enabling them to complete challenging tasks without fine-tuning. However, imitation can also lead models to reproduce inaccuracies or harmful content if present in the context. We study harmful imitation through the lens of a model's internal representations, and identify two related phenomena: overthinking and false induction heads. The first phenomenon, overthinking, appears when we decode predictions from intermediate layers, given correct vs. incorrect few-shot demonstrations. At early layers, both demonstrations induce similar model behavior, but the behavior diverges sharply at some "critical layer", after which the accuracy given incorrect demonstrations progressively decreases. The second phenomenon, false induction heads, are a possible mechanistic cause of overthinking: these are heads in late layers that attend to and copy false information from previous demonstrations, and whose ablation reduces 
    
[^286]: 在NetHack中的模仿学习的规模律

    Scaling Laws for Imitation Learning in NetHack. (arXiv:2307.09423v1 [cs.LG])

    [http://arxiv.org/abs/2307.09423](http://arxiv.org/abs/2307.09423)

    本文研究了在NetHack游戏中的模仿学习，发现通过扩大模型和数据规模可以改进模仿学习的效果，并建立了训练计算最优IL代理人的幂律。

    

    模仿学习 (IL) 是机器学习中最常用的方法之一。然而，虽然强大，但许多研究发现它往往不能完全恢复出潜在的专家行为。然而，这些研究没有深入探究模型和数据规模的扩大在其中的作用。受最近在自然语言处理 (NLP) 领域的工作的启发，在那里“扩大规模”已经导致了越来越有能力的领域特定语言模型 (LLMs)，我们研究了仔细扩大模型和数据规模是否可以在模仿学习的设置中带来类似的改进。为了展示我们的发现，我们将重点放在 NetHack 游戏上，这是一个具有程序生成、随机性、长期依赖性和部分可观测性的具有挑战性的环境。我们发现 IL 的损失和平均回报随着计算预算的变化而平滑变化且强相关，从而在模型大小和样本数量方面为训练计算最优的 IL 代理人的计算预算建立了幂律。我们预测并训练了几个具有 IL 的NetHack代理。

    Imitation Learning (IL) is one of the most widely used methods in machine learning. Yet, while powerful, many works find it is often not able to fully recover the underlying expert behavior. However, none of these works deeply investigate the role of scaling up the model and data size. Inspired by recent work in Natural Language Processing (NLP) where "scaling up" has resulted in increasingly more capable LLMs, we investigate whether carefully scaling up model and data size can bring similar improvements in the imitation learning setting. To demonstrate our findings, we focus on the game of NetHack, a challenging environment featuring procedural generation, stochasticity, long-term dependencies, and partial observability. We find IL loss and mean return scale smoothly with the compute budget and are strongly correlated, resulting in power laws for training compute-optimal IL agents with respect to model size and number of samples. We forecast and train several NetHack agents with IL an
    
[^287]: 使用双调节器解决联邦半监督学习中的数据不平衡问题

    Combating Data Imbalances in Federated Semi-supervised Learning with Dual Regulators. (arXiv:2307.05358v1 [cs.LG])

    [http://arxiv.org/abs/2307.05358](http://arxiv.org/abs/2307.05358)

    本文提出了一种带有双调节器的新型联邦半监督学习框架FedDure，解决了数据分布不平衡的问题。通过粗调节器和细调节器对本地模型的更新进行规范，以及学习适应性加权方案，适应不同的数据分布。

    

    联邦学习已经成为一种从分散异构数据中学习的流行方法。由于分散客户端上标签稀缺，联邦半监督学习（FSSL）出现以从少量标记数据中训练模型。现有的FSSL方法假设客户端之间的标签数据独立且具有相同分布，并且在客户端内部标记和未标记数据之间具有一致的类别分布。本文研究了FSSL的更实际和具有挑战性的情况，即数据分布不仅在客户端之间不同，在客户端内部标记和未标记数据之间也不同。为了解决这个挑战，本文提出了一种带有双调节器的新型FSSL框架，FedDure。FedDure通过粗调节器（C-reg）和细调节器（F-reg）解除了以前的假设：C-reg通过跟踪标记数据分布的学习效果来规范本地模型的更新；F-reg学习一个适应性加权方案，以适应客户端内不同的数据分布。

    Federated learning has become a popular method to learn from decentralized heterogeneous data. Federated semi-supervised learning (FSSL) emerges to train models from a small fraction of labeled data due to label scarcity on decentralized clients. Existing FSSL methods assume independent and identically distributed (IID) labeled data across clients and consistent class distribution between labeled and unlabeled data within a client. This work studies a more practical and challenging scenario of FSSL, where data distribution is different not only across clients but also within a client between labeled and unlabeled data. To address this challenge, we propose a novel FSSL framework with dual regulators, FedDure.} FedDure lifts the previous assumption with a coarse-grained regulator (C-reg) and a fine-grained regulator (F-reg): C-reg regularizes the updating of the local model by tracking the learning effect on labeled data distribution; F-reg learns an adaptive weighting scheme tailored f
    
[^288]: DeepOnto: 一个用于深度学习本体工程的Python包

    DeepOnto: A Python Package for Ontology Engineering with Deep Learning. (arXiv:2307.03067v1 [cs.AI])

    [http://arxiv.org/abs/2307.03067](http://arxiv.org/abs/2307.03067)

    DeepOnto是一个Python包，用于深度学习本体工程。它通过集成深度学习框架和本体API，提供了丰富的工具和算法，支持本体工程任务，如本体对齐和完成。

    

    应用深度学习技术，特别是语言模型（LMs），在本体工程中已经引起了广泛关注。然而，深度学习框架如PyTorch和Tensorflow主要是为Python开发的，而广泛使用的本体API（如OWL API和Jena）主要是基于Java的。为了方便无缝集成这些框架和API，我们提出了Deeponto，一个专为本体工程设计的Python包。该包包括一个基于广泛认可和可靠的OWL API的核心本体处理模块，以更“Pythonic”的方式封装其基本特性，并扩展其功能以包括其他重要组成部分，包括推理、语言化、规范化、投影等。基于这个模块，Deeponto提供了一套工具、资源和算法，支持各种本体工程任务，例如本体对齐和完成，利用深度学习方法实现。

    Applying deep learning techniques, particularly language models (LMs), in ontology engineering has raised widespread attention. However, deep learning frameworks like PyTorch and Tensorflow are predominantly developed for Python programming, while widely-used ontology APIs, such as the OWL API and Jena, are primarily Java-based. To facilitate seamless integration of these frameworks and APIs, we present Deeponto, a Python package designed for ontology engineering. The package encompasses a core ontology processing module founded on the widely-recognised and reliable OWL API, encapsulating its fundamental features in a more "Pythonic" manner and extending its capabilities to include other essential components including reasoning, verbalisation, normalisation, projection, and more. Building on this module, Deeponto offers a suite of tools, resources, and algorithms that support various ontology engineering tasks, such as ontology alignment and completion, by harnessing deep learning meth
    
[^289]: 图像的重要性：多模态夸张检测的新数据集和实证研究

    Image Matters: A New Dataset and Empirical Study for Multimodal Hyperbole Detection. (arXiv:2307.00209v1 [cs.CV])

    [http://arxiv.org/abs/2307.00209](http://arxiv.org/abs/2307.00209)

    本研究提出了一个新的多模态夸张检测数据集，并使用文本和图像作为两种模态进行研究。同时，评估了不同预训练的多模态编码器在此任务中的表现。该研究探索了夸张检测的跨领域性能。

    

    夸张，即夸大其词，是一种常见的语言现象。夸张检测是理解人类表达的重要部分。已经有几项关于夸张检测的研究，但大多数的研究只关注文本模态。然而，随着社交媒体的发展，人们可以使用各种模态（包括文本、图像、视频等）来表达夸张。在本文中，我们专注于多模态夸张检测。我们从微博（中国的一种社交媒体）创建了一个多模态检测数据集，并对其进行了一些研究。我们将微博的文本和图像视为两种模态，探索了文本和图像在夸张检测中的作用。此外，我们还评估了不同预训练的多模态编码器在这个下游任务上的性能。由于这个数据集是从五个不同的主题构建的，我们还评估了不同领域之间的性能。

    Hyperbole, or exaggeration, is a common linguistic phenomenon. The detection of hyperbole is an important part of understanding human expression. There have been several studies on hyperbole detection, but most of which focus on text modality only. However, with the development of social media, people can create hyperbolic expressions with various modalities, including text, images, videos, etc. In this paper, we focus on multimodal hyperbole detection. We create a multimodal detection dataset\footnote{The dataset will be released to the community.} from Weibo (a Chinese social media) and carry out some studies on it. We treat the text and image from a piece of weibo as two modalities and explore the role of text and image for hyperbole detection. Different pre-trained multimodal encoders are also evaluated on this downstream task to show their performance. Besides, since this dataset is constructed from five different topics, we also evaluate the cross-domain performance of different 
    
[^290]: 基于群体的鲁棒性：现实世界中定制鲁棒性的通用框架

    Group-based Robustness: A General Framework for Customized Robustness in the Real World. (arXiv:2306.16614v1 [cs.LG])

    [http://arxiv.org/abs/2306.16614](http://arxiv.org/abs/2306.16614)

    本研究提出了一种基于群体的鲁棒性指标，可以更好地评估机器学习模型在现实世界中抵抗攻击的能力，弥补了传统指标的不足。实验证明，该指标能够区分模型对特定威胁的脆弱性。

    

    众所周知，机器学习模型容易受到逃避攻击的影响，即通过扰动模型输入来引起错误分类。本研究中，我们发现传统的度量目标和非目标鲁棒性的指标无法准确评估现实世界中的真实威胁。为了解决现有方法的缺陷，我们正式定义了一种新的指标，称为基于群体的鲁棒性，它补充了现有的度量标准，并更适合评估特定攻击场景下的模型性能。我们通过实验证明，基于群体的鲁棒性能够在传统的鲁棒性指标不适用的情况下区分模型对特定威胁模型的脆弱性。此外，为了有效准确地衡量基于群体的鲁棒性，我们提出了两个损失函数。

    Machine-learning models are known to be vulnerable to evasion attacks that perturb model inputs to induce misclassifications. In this work, we identify real-world scenarios where the true threat cannot be assessed accurately by existing attacks. Specifically, we find that conventional metrics measuring targeted and untargeted robustness do not appropriately reflect a model's ability to withstand attacks from one set of source classes to another set of target classes. To address the shortcomings of existing methods, we formally define a new metric, termed group-based robustness, that complements existing metrics and is better-suited for evaluating model performance in certain attack scenarios. We show empirically that group-based robustness allows us to distinguish between models' vulnerability against specific threat models in situations where traditional robustness metrics do not apply. Moreover, to measure group-based robustness efficiently and accurately, we 1) propose two loss func
    
[^291]: 使用Swap优化建筑结构的向量化：高效卷积通道交换混合策略

    Optimized Vectorizing of Building Structures with Swap: High-Efficiency Convolutional Channel-Swap Hybridization Strategy. (arXiv:2306.15035v1 [cs.AI])

    [http://arxiv.org/abs/2306.15035](http://arxiv.org/abs/2306.15035)

    本论文提出了一种高效的卷积通道交换混合策略（Swap），用于优化建筑结构的向量化。该方法通过将相邻或对角特征交替交换并混合不同通道的信息，实现了集成局部特征空间信息的功能。同时，采用了基于组的参数共享机制，大大减少了模型中的冗余参数。

    

    建筑平面图的重建，也称为足迹重建，属于计算机视觉和地理信息学领域，长期以来一直受到传统卷积模型中冗余参数的挑战。因此，在本文中，我们提出了一种先进和自适应的移位架构，即Swap操作，它结合了非指数增长参数，同时保持了集成局部特征空间信息的类似功能，类似于高维卷积操作器。Swap跨通道操作架构通过异或操作交替交换相邻或对角特征，然后通过1x1卷积操作混合交替的通道，以整合不同通道的信息。另一方面，SwapNN架构采用了受卷积神经网络过程启发的基于组的参数共享机制，从而显著减少了数量。

    The building planar graph reconstruction, a.k.a. footprint reconstruction, which lies in the domain of computer vision and geoinformatics, has been long afflicted with the challenge of redundant parameters in conventional convolutional models. Therefore, in this paper, we proposed an advanced and adaptive shift architecture, namely the Swap operation, which incorporates non-exponential growth parameters while retaining analogous functionalities to integrate local feature spatial information, resembling a high-dimensional convolution operator. The Swap, cross-channel operation, architecture implements the XOR operation to alternately exchange adjacent or diagonal features, and then blends alternating channels through a 1x1 convolution operation to consolidate information from different channels. The SwapNN architecture, on the other hand, incorporates a group-based parameter-sharing mechanism inspired by the convolutional neural network process and thereby significantly reducing the num
    
[^292]: BeMap：平衡的消息传递方法用于公平的图神经网络。

    BeMap: Balanced Message Passing for Fair Graph Neural Network. (arXiv:2306.04107v1 [cs.LG])

    [http://arxiv.org/abs/2306.04107](http://arxiv.org/abs/2306.04107)

    本文提出了一种公平的消息传递方法，称为BeMap，旨在解决消息传递中的偏差放大问题，通过平衡感知的采样策略来平衡不同人口群体的1-hop邻居的数量。

    

    图神经网络（GNN）通过迭代地聚合每个节点的局部邻域信息来表现出强大的实证性能，即消息传递。然而，具体证据显示，图神经网络可能对某些人口群体存在偏见，这要求考虑算法的公正性。尽管越来越多的努力在保证图神经网络的算法公平性，但在训练期间往往并不明确考虑消息传递在GNN中引起的偏差。本文首先研究了消息传递中的偏差放大问题。我们通过经验证据和理论证明，当来自不同人口群体的1-hop邻居不平衡时，消息传递可能会放大偏差。在这些分析的指导下，我们提出了BeMap，一种公平的消息传递方法，利用平衡感知的采样策略来平衡每个节点的1-hop邻居的数量。

    Graph Neural Network (GNN) has shown strong empirical performance in many downstream tasks by iteratively aggregating information from the local neighborhood of each node, i.e., message passing. However, concrete evidence has revealed that a graph neural network could be biased against certain demographic groups, which calls for the consideration of algorithmic fairness. Despite the increasing efforts in ensuring algorithmic fairness on graph neural networks, they often do not explicitly consider the induced bias caused by message passing in GNN during training. In this paper, we first investigate the problem of bias amplification in message passing. We empirically and theoretically demonstrate that message passing could amplify the bias when the 1-hop neighbors from different demographic groups are unbalanced. Guided by such analyses, we propose BeMap, a fair message passing method, that leverages a balance-aware sampling strategy to balance the number of the 1-hop neighbors of each n
    
[^293]: 简单形式映射神经网络中的可解释性

    Explainability in Simplicial Map Neural Networks. (arXiv:2306.00010v1 [cs.LG])

    [http://arxiv.org/abs/2306.00010](http://arxiv.org/abs/2306.00010)

    本文提出了简单形式映射神经网络（SMNN）的训练过程和替代凸多面体的方法，并且首次引入了 SMNN 的可解释性能力。

    

    简单形式映射神经网络（SMNN）是基于拓扑学的神经网络，具有普适逼近能力和在适当条件下对抗性示例的鲁棒性。然而，在高维中应用 SMNN 存在一些瓶颈，首先没有定义 SMNN 的训练过程，其次对于输入数据集需要构建一个包围凸多面体。本文提出了基于给定数据集的支持子集和投影到超球面的方法作为替代凸多面体的 SMNN 训练过程，并首次引入了 SMNN 的可解释性能力。

    Simplicial map neural networks (SMNNs) are topology-based neural networks with interesting properties such as universal approximation capability and robustness to adversarial examples under appropriate conditions. However, SMNNs present some bottlenecks for their possible application in high dimensions. First, no SMNN training process has been defined so far. Second, SMNNs require the construction of a convex polytope surrounding the input dataset. In this paper, we propose a SMNN training procedure based on a support subset of the given dataset and a method based on projection to a hypersphere as a replacement for the convex polytope construction. In addition, the explainability capacity of SMNNs is also introduced for the first time in this paper.
    
[^294]: 基于预测误差的增量学习分类方法

    Prediction Error-based Classification for Class-Incremental Learning. (arXiv:2305.18806v1 [cs.LG])

    [http://arxiv.org/abs/2305.18806](http://arxiv.org/abs/2305.18806)

    本论文提出了一种新的增量学习分类方法——基于预测误差的分类方法（PEC）。对PEC的评估表明，在各种基准测试中，PEC可以与最先进的增量学习方法相竞争，并具有许多实际优势，例如样本效率高、易于调整。

    

    增量学习分类是连续学习中的一个挑战性问题，目标是学习来区分所有类别。现有的方法在处理大量分类时容易出现过度遗忘和分数不均衡。本研究提出了一种新方法，名为预测误差分类（PEC），它与传统的判别和生成分类范式有所不同。PEC通过测量模型在从该类别中学习的数据上复制随机神经网络输出的预测误差来计算类别得分。该方法可以解释为基于高斯过程后验方差的分类规则的近似。PEC具有几个实际优势，包括样本效率高、易于调整以及即使在逐个呈现数据时也很有效。本文的实证结果表明PEC在广泛的基准测试中表现出色，可以与最先进的增量学习方法相竞争。

    Class-incremental learning (CIL) is a particularly challenging variant of continual learning, where the goal is to learn to discriminate between all classes presented in an incremental fashion. Existing approaches often suffer from excessive forgetting and imbalance of the scores assigned to classes that have not been seen together during training. In this study, we introduce a novel approach, Prediction Error-based Classification (PEC), which differs from traditional discriminative and generative classification paradigms. PEC computes a class score by measuring the prediction error of a model trained to replicate the outputs of a frozen random neural network on data from that class. The method can be interpreted as approximating a classification rule based on Gaussian Process posterior variance. PEC offers several practical advantages, including sample efficiency, ease of tuning, and effectiveness even when data are presented one class at a time. Our empirical results show that PEC pe
    
[^295]: HiFA: 高保真度的文本到3D图像合成及其先进的扩散引导策略

    HiFA: High-fidelity Text-to-3D with Advanced Diffusion Guidance. (arXiv:2305.18766v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2305.18766](http://arxiv.org/abs/2305.18766)

    该论文提出了一种高保真度的文本到3D图像合成方法，并引入了先进的扩散引导策略。通过对NeRF渲染图像进行辅助深度监督和规范化密度场来提高3D几何表示。实验证明该方法优于以前的工作，产生了先进的照片真实感和改进的多视角一致性。

    

    通过优化3D模型，自动文本到3D合成在提升中已经取得了显著进展。现有方法通常依赖于预训练的文本到图像生成模型（如扩散模型），提供神经辐射场（NeRFs）的2D渲染得分并用于优化NeRFs。然而，由于其对3D几何的有限理解，这些方法经常遇到多个视角上的伪影和不一致现象。为了解决这些限制，我们提出了使用扩散先验重新制定优化损失的方法。此外，我们引入了一种新的训练方法，释放了扩散先验的潜力。为了提高3D几何表示，我们对NeRF渲染图像进行辅助深度监督，并规范化NeRF的密度场。大量实验证明了我们的方法优于以前的工作，产生了先进的照片真实感和改进的多视角一致性。

    Automatic text-to-3D synthesis has achieved remarkable advancements through the optimization of 3D models. Existing methods commonly rely on pre-trained text-to-image generative models, such as diffusion models, providing scores for 2D renderings of Neural Radiance Fields (NeRFs) and being utilized for optimizing NeRFs. However, these methods often encounter artifacts and inconsistencies across multiple views due to their limited understanding of 3D geometry. To address these limitations, we propose a reformulation of the optimization loss using the diffusion prior. Furthermore, we introduce a novel training approach that unlocks the potential of the diffusion prior. To improve 3D geometry representation, we apply auxiliary depth supervision for NeRF-rendered images and regularize the density field of NeRFs. Extensive experiments demonstrate the superiority of our method over prior works, resulting in advanced photo-realism and improved multi-view consistency.
    
[^296]: 大型语言模型作为工具制造者

    Large Language Models as Tool Makers. (arXiv:2305.17126v1 [cs.LG])

    [http://arxiv.org/abs/2305.17126](http://arxiv.org/abs/2305.17126)

    本文提出了一个闭环框架，即LLMs作为工具制造者（LATM），使LLMs能够自主地创建用于解决问题的工具，而不需要依赖于现有的外部工具。

    

    最近的研究表明，通过使用外部工具，大型语言模型（LLMs）可以增强其问题解决能力的潜力。然而，在这方面的先前工作依赖于现有工具的可用性。在本文中，我们提出了一个闭环框架，称为LLMs As Tool Makers（LATM），以消除这种依赖性，其中LLMs创建自己的可重用工具来解决问题。我们的方法包括两个关键阶段：1）制造工具：LLM作为工具制造者，为给定任务制作工具，其中工具作为Python实用函数实现。2）使用工具：LLM作为工具用户，应用工具制造者构建的工具来解决问题。工具用户可以是与工具制造者相同或不同的LLM。工具制造使LLM能够不断生成可应用于不同请求的工具，以便将来请求在解决问题时能调用相应的API。

    Recent research shows the potential of enhancing the problem-solving ability of large language models (LLMs) through the use of external tools. However, prior work along this line depends on the availability of existing tools. In this work, we take an initial step towards removing this dependency by proposing a closed-loop framework, referred to as LLMs As Tool Makers (LATM), where LLMs create their own reusable tools for problem-solving. Our approach consists of two key phases: 1) tool making: an LLM acts as the tool maker that crafts tools for given tasks, where a tool is implemented as a Python utility function. 2) tool using: an LLM acts as the tool user, which applies the tool built by the tool maker for problem-solving. The tool user can be either the same or a different LLM from the tool maker. Tool-making enables an LLM to continually generate tools that can be applied to different requests so that future requests can call the corresponding APIs when beneficial for solving the 
    
[^297]: 通过提示工程破解ChatGPT：一项实证研究

    Jailbreaking ChatGPT via Prompt Engineering: An Empirical Study. (arXiv:2305.13860v1 [cs.SE])

    [http://arxiv.org/abs/2305.13860](http://arxiv.org/abs/2305.13860)

    本研究探索了通过提示工程破解ChatGPT的有效性，发现破解提示可以在40种用例情况下一致地规避限制，强调了提示结构在破解ChatGPT中的重要性。

    

    大型语言模型（LLMs）如ChatGPT已经展示了强大的潜力，但同时也引发了与内容约束和潜在滥用相关的挑战。我们的研究探究了三个关键问题：（1）可以用多少种不同的提示类型破解LLMs，（2）破解提示在规避LLM限制方面的有效性以及（3）ChatGPT对这些破解提示的韧性。首先，我们开发了一个分类模型来分析现有提示的分布，识别出十个不同模式和三个破解提示类别。随后，我们使用3,120个禁止情景下的狱中问题数据集评估ChatGPT 3.5和4.0版本的破解能力。最后，我们评估了ChatGPT对破解提示的抵抗力，发现提示可以在40种用例情景下一致地规避限制。该研究强调了提示结构在破解ChatGPT中的重要性，并突出了LLMs对意外滥用的敏感性。

    Large Language Models (LLMs), like ChatGPT, have demonstrated vast potential but also introduce challenges related to content constraints and potential misuse. Our study investigates three key research questions: (1) the number of different prompt types that can jailbreak LLMs, (2) the effectiveness of jailbreak prompts in circumventing LLM constraints, and (3) the resilience of ChatGPT against these jailbreak prompts. Initially, we develop a classification model to analyze the distribution of existing prompts, identifying ten distinct patterns and three categories of jailbreak prompts. Subsequently, we assess the jailbreak capability of prompts with ChatGPT versions 3.5 and 4.0, utilizing a dataset of 3,120 jailbreak questions across eight prohibited scenarios. Finally, we evaluate the resistance of ChatGPT against jailbreak prompts, finding that the prompts can consistently evade the restrictions in 40 use-case scenarios. The study underscores the importance of prompt structures in j
    
[^298]: 马尔可夫$\alpha$-势博弈:均衡近似与遗憾分析

    Markov $\alpha$-Potential Games: Equilibrium Approximation and Regret Analysis. (arXiv:2305.12553v2 [cs.GT] UPDATED)

    [http://arxiv.org/abs/2305.12553](http://arxiv.org/abs/2305.12553)

    本文提出了一种新的框架来研究马尔可夫博弈，即马尔可夫 $\alpha$-势博弈。介绍了两种算法来计算其中的纳什均衡，且表明这些算法能够找到近似均衡。

    

    本文提出了一种研究马尔可夫博弈中多代理交互的新框架:马尔可夫$\alpha$-势博弈。马尔可夫势博弈是马尔可夫 $\alpha$-势博弈的特殊情况，马尔可夫拥堵博弈和扰动马尔可夫团队博弈是两个重要且实际意义重大的博弈类。本文提供了两个博弈的$\alpha$-势函数，并针对博弈参数表征了差距 $\alpha$。引入了两种算法——投影梯度上升算法和顺序最大改进平滑最佳反应动态——来近似计算马尔可夫$\alpha$-势博弈中的稳态纳什均衡。每个算法的纳什遗憾都显示为时间跨度的亚线性缩放。我们的分析和数值实验表明，简单的算法能够找到马尔可夫$\alpha$-势博弈的近似均衡。

    This paper proposes a new framework to study multi-agent interaction in Markov games: Markov $\alpha$-potential games. Markov potential games are special cases of Markov $\alpha$-potential games, so are two important and practically significant classes of games: Markov congestion games and perturbed Markov team games. In this paper, {$\alpha$-potential} functions for both games are provided and the gap $\alpha$ is characterized with respect to game parameters. Two algorithms -- the projected gradient-ascent algorithm and the sequential maximum improvement smoothed best response dynamics -- are introduced for approximating the stationary Nash equilibrium in Markov $\alpha$-potential games. The Nash-regret for each algorithm is shown to scale sub-linearly in time horizon. Our analysis and numerical experiments demonstrates that simple algorithms are capable of finding approximate equilibrium in Markov $\alpha$-potential games.
    
[^299]: 在能力受限场景下启动强韧后门攻击

    Launching a Robust Backdoor Attack under Capability Constrained Scenarios. (arXiv:2304.10985v1 [cs.CR])

    [http://arxiv.org/abs/2304.10985](http://arxiv.org/abs/2304.10985)

    深度神经网络的后门攻击一直是一个安全性问题，现有的改进方法需要强大的攻击者能力，在能力受限场景下还没有找到令人满意的解决办法，此外，模型鲁棒性仍然值得关注。

    

    随着深度神经网络在关键领域的应用不断增加，人们开始担心它们的安全性。由于缺乏透明度，深度学习模型容易受到后门攻击的威胁。污染的后门模型在普通环境下可能表现正常，但当输入包含触发器时，会显示出恶意行为。目前对后门攻击的研究集中于改善触发器的秘密性，大多数方法需要强大的攻击者能力，例如对模型结构的了解或对训练过程的控制。由于在大多数情况下攻击者的能力受到限制，这些攻击是不切实际的。此外，模型鲁棒性的问题还未得到充分关注。例如，模型蒸馏常用于简化模型大小，但随着参数数量指数级增长，以前的许多后门攻击在模型蒸馏后均失败;图像增强操作可以破坏触发器，从而使后门攻击失效。

    As deep neural networks continue to be used in critical domains, concerns over their security have emerged. Deep learning models are vulnerable to backdoor attacks due to the lack of transparency. A poisoned backdoor model may perform normally in routine environments, but exhibit malicious behavior when the input contains a trigger. Current research on backdoor attacks focuses on improving the stealthiness of triggers, and most approaches require strong attacker capabilities, such as knowledge of the model structure or control over the training process. These attacks are impractical since in most cases the attacker's capabilities are limited. Additionally, the issue of model robustness has not received adequate attention. For instance, model distillation is commonly used to streamline model size as the number of parameters grows exponentially, and most of previous backdoor attacks failed after model distillation; the image augmentation operations can destroy the trigger and thus disabl
    
[^300]: ReelFramer：使用生成式人工智能与社交媒体共同创作新闻片段

    ReelFramer: Co-creating News Reels on Social Media with Generative AI. (arXiv:2304.09653v1 [cs.HC])

    [http://arxiv.org/abs/2304.09653](http://arxiv.org/abs/2304.09653)

    ReelFramer使用生成式人工智能与社交媒体共同创作新闻片段。它可以帮助记者探索一个故事的多种叙事框架，并生成脚本、角色板和故事板。用户研究发现该系统大大减轻了将一篇书面报道转化为新闻片段的负担。

    

    社交媒体上的短视频是许多年轻人发现和消费内容的主要方式。新闻机构希望通过新闻片段接触受众，但目前难以将传统的新闻报道格式转化为与平台风格相匹配的短小有趣视频。有多种方法可以围绕新闻事件构建片段式叙事，而选定其中一种则是具有挑战性的。不同的新闻故事需要不同的叙述框架，并需要在娱乐性和信息量之间达到不同的平衡。本文提出了一种名为ReelFramer的系统，利用文本和图像生成来帮助记者探索一个故事的多种叙事框架，然后生成他们可以编辑和迭代的脚本、角色板和故事板。在一项由五名新闻相关领域的研究生参与的用户研究中，我们发现该系统大大减轻了将一篇书面报道转化为新闻片段的负担，并探索叙事框架以找到正确的框架过程是非常有意义的。

    Short videos on social media are a prime way many young people find and consume content. News outlets would like to reach audiences through news reels, but currently struggle to translate traditional journalistic formats into the short, entertaining videos that match the style of the platform. There are many ways to frame a reel-style narrative around a news story, and selecting one is a challenge. Different news stories call for different framings, and require a different trade-off between entertainment and information. We present a system called ReelFramer that uses text and image generation to help journalists explore multiple narrative framings for a story, then generate scripts, character boards and storyboards they can edit and iterate on. A user study of five graduate students in journalism-related fields found the system greatly eased the burden of transforming a written story into a reel, and that exploring framings to find the right one was a rewarding process.
    
[^301]: 基于语言驱动的锚点的零样本对抗鲁棒性

    Language-Driven Anchors for Zero-Shot Adversarial Robustness. (arXiv:2301.13096v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2301.13096](http://arxiv.org/abs/2301.13096)

    本文提出了一种基于语言驱动、基于锚点的对抗训练策略LAAT，通过利用文本编码器的语义一致性，在零样本图像分类场景下增强图像模型的对抗鲁棒性。实验结果表明，该方法在零样本对抗性能上优于先前的最佳状态对抗性一次性方法，同时能为流行的图像分类模型带来实质性的零样本对抗性能提升。

    

    深度神经网络容易受到对抗性攻击。本文旨在改善具有挑战性的零样本图像分类场景下的对抗鲁棒性。为解决这一问题，我们提出了一种新的基于语言驱动、基于锚点的对抗训练策略LAAT。LAAT利用文本编码器为每个类别生成固定的锚点（归一化特征嵌入），并在对抗训练中使用这些锚点。通过利用文本编码器的语义一致性，LAAT可以增强图像模型在新类别上的对抗鲁棒性，而无需额外的样例。我们发现了最近文本编码器的余弦相似度问题，并设计了几种有效的技术来解决它。实验结果表明，LAAT显著提高了零样本对抗性能，优于先前的最佳状态对抗性一次性方法。此外，我们的方法在几个基准数据集上为流行的图像分类模型（如ResNet-50和DenseNet-121）产生了实质性的零样本对抗性能提升。

    Deep neural networks are known to be susceptible to adversarial attacks. In this work, we focus on improving adversarial robustness in the challenging zero-shot image classification setting. To address this issue, we propose LAAT, a novel Language-driven, Anchor-based Adversarial Training strategy. LAAT utilizes a text encoder to generate fixed anchors (normalized feature embeddings) for each category and then uses these anchors for adversarial training. By leveraging the semantic consistency of the text encoders, LAAT can enhance the adversarial robustness of the image model on novel categories without additional examples. We identify the large cosine similarity problem of recent text encoders and design several effective techniques to address it. The experimental results demonstrate that LAAT significantly improves zero-shot adversarial performance, outperforming previous state-of-the-art adversarially robust one-shot methods. Moreover, our method produces substantial zero-shot adver
    
[^302]: CAPE: 使用大型语言模型从前置错误中纠正行动

    CAPE: Corrective Actions from Precondition Errors using Large Language Models. (arXiv:2211.09935v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2211.09935](http://arxiv.org/abs/2211.09935)

    CAPE是一种利用大型语言模型从前置错误中纠正行动的方法，提高了生成计划的质量，使具身代理能够执行更多任务，并改善了计划的正确性。

    

    从大型语言模型中提取常识知识为设计智能机器人提供了一种途径。现有的利用语言模型进行规划的方法在行动失败时无法恢复，并且通常只能尝试重新执行失败的行动，而无法解决错误的根本原因。我们提出了一种新颖的方法（CAPE），试图在规划过程中提出纠正前置条件错误的行动。CAPE通过利用少样本推理从行动前置条件中提高了生成计划的质量。我们的方法使得具身代理能够执行比基线方法更多的任务，同时确保语义正确性和最小化重新提示。在VirtualHome中，CAPE生成可执行的计划，并且相比SayCan，将人工标注的计划正确度指标从28.89%提高到49.63%。我们的改进也适用于一台配置了一组以语言为指定的技能和相关前置条件的波士顿动力公司的Spot机器人，其中CAPE提高了正确性。

    Extracting commonsense knowledge from a large language model (LLM) offers a path to designing intelligent robots. Existing approaches that leverage LLMs for planning are unable to recover when an action fails and often resort to retrying failed actions, without resolving the error's underlying cause.  We propose a novel approach (CAPE) that attempts to propose corrective actions to resolve precondition errors during planning. CAPE improves the quality of generated plans by leveraging few-shot reasoning from action preconditions. Our approach enables embodied agents to execute more tasks than baseline methods while ensuring semantic correctness and minimizing re-prompting. In VirtualHome, CAPE generates executable plans while improving a human-annotated plan correctness metric from 28.89% to 49.63% over SayCan. Our improvements transfer to a Boston Dynamics Spot robot initialized with a set of skills (specified in language) and associated preconditions, where CAPE improves the correctne
    
[^303]: Wise-SrNet: 一种增强图像分类的新型架构，通过学习特征图的空间分辨率

    Wise-SrNet: A Novel Architecture for Enhancing Image Classification by Learning Spatial Resolution of Feature Maps. (arXiv:2104.12294v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2104.12294](http://arxiv.org/abs/2104.12294)

    本文提出了一种名为Wise-SrNet的新型架构，用于增强图像分类任务。该架构通过学习特征图的空间分辨率，解决了连接特征图和分类层之间的挑战。实验证明，该方法在不增加计算成本的情况下，有效提高了学习效率。

    

    自从卷积神经网络的发展以来，将提取的特征图与最终的分类层连接起来一直是主要的挑战之一。VGG模型使用两组全连接层用于架构的分类部分，这显著增加了模型权重的数量。ResNet等深度卷积模型使用全局平均池化（GAP）层将特征图压缩并输入分类层。尽管使用GAP层可以减少计算成本，但也会导致特征图的空间分辨率损失，从而降低学习效率。在本文中，我们通过使用一种名为Wise-SrNet的新型架构来解决这个问题。它受到了深度卷积思想的启发，并且专为处理空间分辨率而设计，同时不增加计算成本。我们使用三个不同的数据集对我们的方法进行了评估：Intel图像分类数据集...

    One of the main challenges since the advancement of convolutional neural networks is how to connect the extracted feature map to the final classification layer. VGG models used two sets of fully connected layers for the classification part of their architectures, which significantly increased the number of models' weights. ResNet and the next deep convolutional models used the Global Average Pooling (GAP) layer to compress the feature map and feed it to the classification layer. Although using the GAP layer reduces the computational cost, but also causes losing spatial resolution of the feature map, which results in decreasing learning efficiency. In this paper, we aim to tackle this problem by replacing the GAP layer with a new architecture called Wise-SrNet. It is inspired by the depthwise convolutional idea and is designed for processing spatial resolution while not increasing computational cost. We have evaluated our method using three different datasets: Intel Image Classification
    

