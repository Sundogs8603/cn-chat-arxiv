# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Few-Shot Learning on Graphs: from Meta-learning to Pre-training and Prompting](https://rss.arxiv.org/abs/2402.01440) | 本文综述了图上的小样本学习的最新发展，将现有的研究方法划分为元学习、预训练和混合方法三大类别，并对它们的优缺点进行了比较。还提出了未来的研究方向。 |
| [^2] | [Arithmetic Control of LLMs for Diverse User Preferences: Directional Preference Alignment with Multi-Objective Rewards](https://arxiv.org/abs/2402.18571) | 提出了方向偏好对齐（DPA）框架，通过多目标奖励模拟不同偏好配置，以实现用户相关的偏好控制。 |
| [^3] | [Approaching Human-Level Forecasting with Language Models](https://arxiv.org/abs/2402.18563) | 该研究探讨了使用语言模型（LMs）进行预测未来事件的能力，开发了一种检索增强型LM系统，通过在竞争性预测平台收集数据集，并在知识截止日期后评估系统性能，发现该系统能够准确预测未来事件并在某些情况下超越人类预测者。 |
| [^4] | [Keeping LLMs Aligned After Fine-tuning: The Crucial Role of Prompt Templates](https://arxiv.org/abs/2402.18540) | 提出了“纯粹调优，安全测试”（PTST）原则，即在微调时不包含安全提示，但在测试时加入，可以显著减少LLMs中不安全行为的出现。 |
| [^5] | [Language Models Represent Beliefs of Self and Others](https://arxiv.org/abs/2402.18496) | 通过神经激活线性解析语言模型中代理人观点下的信念状态，揭示了大型语言模型内部表述自我和他人信念，这对社会推理过程至关重要，并在多样社会推理任务中具有潜在的泛化能力。 |
| [^6] | [Human-Centric Aware UAV Trajectory Planning in Search and Rescue Missions Employing Multi-Objective Reinforcement Learning with AHP and Similarity-Based Experience Replay](https://arxiv.org/abs/2402.18487) | 该论文探讨了人本关注因素在搜索和救援任务中无人机轨迹规划中的作用，引入了基于强化学习、AHP和基于相似性经验回放的新方法优化无人机轨迹，平衡了运营目标与人类舒适和安全考虑。 |
| [^7] | [FinAgent: A Multimodal Foundation Agent for Financial Trading: Tool-Augmented, Diversified, and Generalist](https://arxiv.org/abs/2402.18485) | FinAgent是一个多模态基础代理，通过工具增强用于金融交易，具有独特的双重反射模块，可以处理多样化的数据并快速适应市场动态。 |
| [^8] | [Signature Kernel Conditional Independence Tests in Causal Discovery for Stochastic Processes](https://arxiv.org/abs/2402.18477) | 本文在随机过程中开发了一种基于签名核的条件独立性测试，实现了对因果关系的推断，以及开发了约束条件的因果发现算法用于恢复整个有向图。 |
| [^9] | [HOP to the Next Tasks and Domains for Continual Learning in NLP](https://arxiv.org/abs/2402.18449) | 该方法HOP在连续学习中引入了三个方向以在自然语言处理中跨任务和领域进行学习。 |
| [^10] | [LeMo-NADe: Multi-Parameter Neural Architecture Discovery with LLMs](https://arxiv.org/abs/2402.18443) | LeMo-NADe是一种基于LLM的框架，旨在根据用户定义的参数、专家系统和大量开放领域知识，自动发现新的神经网络架构，适用于非AI专家，无需预设的搜索空间，并考虑了大量边缘设备特定的参数。 |
| [^11] | [Beyond Natural Language: LLMs Leveraging Alternative Formats for Enhanced Reasoning and Communication](https://arxiv.org/abs/2402.18439) | 挑战了默认使用自然语言的做法，通过探索LLMs在推理和沟通中使用替代格式的实用性，实现了推理效率的提升和多智能体通信时标记使用量的显著减少。 |
| [^12] | [A Relational Inductive Bias for Dimensional Abstraction in Neural Networks](https://arxiv.org/abs/2402.18426) | 研究了神经网络中关系归纳偏好对维度抽象的影响，并证明关系瓶颈机制能够提高泛化和学习效率，使网络表现与人类行为偏好一致。 - 关系瓶颈改善神经网络处理抽象任务的能力，促进网络在维度上进行组合编码，提高处理灵活性。 |
| [^13] | [Emotion Classification in Low and Moderate Resource Languages](https://arxiv.org/abs/2402.18424) | 通过跨语言情感分类器，在低和中等资源语言中实现情感分类，展示了两种迁移学习方法的有效性。 |
| [^14] | [Can GPT Improve the State of Prior Authorization via Guideline Based Automated Question Answering?](https://arxiv.org/abs/2402.18419) | 通过问答任务，GPT能够验证医疗领域患者的PA请求，帮助卫生计划更快地做出决策。 |
| [^15] | [A Cognitive Evaluation Benchmark of Image Reasoning and Description for Large Vision Language Models](https://arxiv.org/abs/2402.18409) | 提出了一个新颖的评估基准，用于评估大型视觉语言模型的认知能力，发现LVLMs与人类之间存在较大的认知能力差距。 |
| [^16] | [Evaluating Decision Optimality of Autonomous Driving via Metamorphic Testing](https://arxiv.org/abs/2402.18393) | 本文着重于评估自动驾驶系统的决策质量，提出了检测非最佳决策场景的方法，通过新颖的变形关系暴露最佳决策违规。 |
| [^17] | [Unveiling the Potential of Robustness in Evaluating Causal Inference Models](https://arxiv.org/abs/2402.18392) | 介绍了一种新颖的分布式健壮度量（DRM）方法，以解决选择理想因果推断模型中健壮估计器的挑战。 |
| [^18] | [Neuromorphic Event-Driven Semantic Communication in Microgrids](https://arxiv.org/abs/2402.18390) | 通过在微网中使用脉冲神经网络(SNNs)在每个节点上协同在线训练的神经形态学习，本论文提出了新的内在方式以优化系统的控制性能。 |
| [^19] | [Large Language Models As Evolution Strategies](https://arxiv.org/abs/2402.18381) | 探索大型语言模型是否能够在处理黑盒优化任务中实现进化优化算法，并引入了一种新的提示策略来提高均值统计，从而实现黑盒重组操作。 |
| [^20] | [Tokenization Is More Than Compression](https://arxiv.org/abs/2402.18376) | 通过引入新的分词器PathPiece，研究者发现少量标记并不能导致更好的下游性能，这一结果对于 Tokenization 的有效性理解提出了质疑。 |
| [^21] | [FedUV: Uniformity and Variance for Heterogeneous Federated Learning](https://arxiv.org/abs/2402.18372) | 提出了FedUV框架，通过引入两种正则化项，促使局部模型在异构分布数据中表现得更均匀和稳定 |
| [^22] | [Objective and Interpretable Breast Cosmesis Evaluation with Attention Guided Denoising Diffusion Anomaly Detection Model](https://arxiv.org/abs/2402.18362) | 本研究提出一种新的自动化方法AG-DDAD，旨在通过注意力机制和扩散模型评估乳腺整容，从而克服传统监督学习和现有异常检测模型的局限性。 |
| [^23] | [Similarity-based analogical proportions](https://arxiv.org/abs/2402.18360) | 通过将类比比例规定为相似性，建立了从相似性到类比比例的桥梁，使得将来的相似性结果可以直接应用于类比比例。 |
| [^24] | [When Should Algorithms Resign?](https://arxiv.org/abs/2402.18326) | 论文讨论了算法辞职作为管理组织内使用AI系统的战略方法，提出通过在AI系统中嵌入治理机制，有意识和明智地在某些情况下脱离AI辅助，以指导何时以及如何使用或避免这些系统，从而获得多方面的利益。 |
| [^25] | [Location-guided Head Pose Estimation for Fisheye Image](https://arxiv.org/abs/2402.18320) | 通过利用头部位置信息，本文提出了一种使用鱼眼图像进行头部姿态估计的新方法，采用端到端卷积神经网络，在头部姿态和头部位置的多任务学习下，直接从鱼眼图像中估计头部姿态。 |
| [^26] | [Enhancing Roadway Safety: LiDAR-based Tree Clearance Analysis](https://arxiv.org/abs/2402.18309) | 本文提出了一种新的点云算法，利用LiDAR技术自动检测树木生长在街道上需要修剪的部分，这有助于增强道路安全。 |
| [^27] | [FSL Model can Score Higher as It Is](https://arxiv.org/abs/2402.18292) | 为了增加测试期间正确预测的机会，研究旨在通过图像到图像的转换纠正FSL模型的测试输入，生成被测试类别的新样本。 |
| [^28] | [Self-Supervised Learning in Electron Microscopy: Towards a Foundation Model for Advanced Image Analysis](https://arxiv.org/abs/2402.18286) | 本文探讨了在电子显微镜中进行自监督学习的潜力，展示自监督预训练如何促进有效的微调，同时指出较低复杂度的模型在微调过程中始终优于更复杂的随机初始化模型。 |
| [^29] | [PiShield: A NeSy Framework for Learning with Requirements](https://arxiv.org/abs/2402.18285) | PiShield是第一个允许将需求集成到神经网络拓扑结构中的框架，无论输入如何都能确保满足这些需求，并可根据从业者需求在推断和/或训练时集成需求。 |
| [^30] | [Is Crowdsourcing Breaking Your Bank? Cost-Effective Fine-Tuning of Pre-trained Language Models with Proximal Policy Optimization](https://arxiv.org/abs/2402.18284) | 提出了一种自监督文本排序方法，利用近端策略优化对语言模型进行微调，消除了对人工注释员的需求，实验结果表明该方法训练的模型在各项得分方面明显优于基线 |
| [^31] | [Rethinking the Bounds of LLM Reasoning: Are Multi-Agent Discussions the Key?](https://arxiv.org/abs/2402.18272) | 多智能体讨论提升了LLM的推理能力，但在有演示的情况下，单智能体LLM通过强提示几乎能达到与最佳讨论方法相同的性能。 |
| [^32] | [A Survey on Neural Question Generation: Methods, Applications, and Prospects](https://arxiv.org/abs/2402.18267) | 这项调查系统研究了神经问答生成（NQG）领域的进展，包括了背景概述、不同类别的方法、以及未来展望 |
| [^33] | [Towards Generalist Prompting for Large Language Models by Mental Models](https://arxiv.org/abs/2402.18252) | 通过提出通用提示概念和创新的MeMo（心智模型）方法，实现大型语言模型在广泛任务范围内实现最佳性能，消除了手动选择和定制提示的需求。 |
| [^34] | [CogBench: a large language model walks into a psychology lab](https://arxiv.org/abs/2402.18225) | CogBench提出了一个从七个认知心理学实验中衍生出十个行为指标的基准测试，为评估大型语言模型的行为提供了工具，研究发现模型大小和从人类反馈中学习的强化学习对性能改善和与人类行为一致具有重要作用。 |
| [^35] | [HearHere: Mitigating Echo Chambers in News Consumption through an AI-based Web System](https://arxiv.org/abs/2402.18222) | HearHere是一个基于人工智能的网络系统，旨在帮助用户从不同视角融合信息和观点，以减轻新闻消费中“回声室”现象。 |
| [^36] | [Lemur: Log Parsing with Entropy Sampling and Chain-of-Thought Merging](https://arxiv.org/abs/2402.18205) | Lemur提出了一种先进的日志解析框架，采用熵抽样和思维链合并，解决了日志解析中存在的人工规则依赖和语义信息忽略等问题。 |
| [^37] | [Autoencoder-based General Purpose Representation Learning for Customer Embedding](https://arxiv.org/abs/2402.18164) | 设计了基于自动编码器的框架用于构建通用嵌入，展示简单模型在嵌入复杂表格数据时优于复杂模型，并将框架应用于生成表示AWS客户的嵌入，显著节省开发时间并观察到下游模型的改进。 |
| [^38] | [Evaluating Quantized Large Language Models](https://arxiv.org/abs/2402.18158) | 该论文通过全面评估后训练量化对权重、激活和KV缓存的影响，以指导选择量化方法，并对11种模型系列进行了评估，覆盖了多种任务类型。 |
| [^39] | [From Summary to Action: Enhancing Large Language Models for Complex Tasks with Open World APIs](https://arxiv.org/abs/2402.18157) | 本研究引入了一个新颖的工具调用管道，旨在控制大规模现实世界API，从而增强大型语言模型在复杂任务中的应用能力。 |
| [^40] | [Cutting Off the Head Ends the Conflict: A Mechanism for Interpreting and Mitigating Knowledge Conflicts in Language Models](https://arxiv.org/abs/2402.18154) | 通过信息流的视角解释并干预语言模型中的知识冲突，提出了一种名为Pruning Head via PatH的方法来缓解冲突 |
| [^41] | [Diffusion-based Neural Network Weights Generation](https://arxiv.org/abs/2402.18153) | 提出了一种基于扩散模型和变分自动编码器的数据集条件的预训练权重采样策略，用于改善迁移学习的性能。 |
| [^42] | [Unsupervised Information Refinement Training of Large Language Models for Retrieval-Augmented Generation](https://arxiv.org/abs/2402.18150) | 本文提出了一种名为InFO-RAG的无监督信息细化训练方法，将大型语言模型在检索增强生成中的角色定义为“信息细化者”，帮助模型更好地整合检索信息以生成更加简洁、准确和完整的文本。 |
| [^43] | [Random Silicon Sampling: Simulating Human Sub-Population Opinion Using a Large Language Model Based on Group-Level Demographic Information](https://arxiv.org/abs/2402.18144) | 通过随机硅抽样方法，可以模拟人类种群亚组的意见，并发现语言模型可以生成回应分布与实际美国公共舆论调查非常相似。 |
| [^44] | [Cause and Effect: Can Large Language Models Truly Understand Causality?](https://arxiv.org/abs/2402.18139) | 本研究提出了一种名为CARE CA的新型架构，通过结合显式因果检测模块和反事实陈述、以及隐含因果检测模块，旨在增强大型语言模型对因果关系的理解能力。 |
| [^45] | [DecisionNCE: Embodied Multimodal Representations via Implicit Preference Learning](https://arxiv.org/abs/2402.18137) | 本文提出了 DecisionNCE 框架，通过隐式偏好学习实体多模态表示，实现了提取任务进展信息和与语言指令对齐的有效方法 |
| [^46] | [On the Inductive Biases of Demographic Parity-based Fair Learning Algorithms](https://arxiv.org/abs/2402.18129) | 分析了标准 DP 基础正则化方法对给定敏感属性的预测标签条件分布的影响，并提出了一种基于敏感属性的分布稳健优化方法来控制归纳偏差。 |
| [^47] | [Saving the legacy of Hero Ibash: Evaluating Four Language Models for Aminoacian](https://arxiv.org/abs/2402.18121) | 本研究评估了四种语言模型在未被充分探索的氨基酸语言中的适应性、有效性和局限性，并为未来自然语言处理的进展奠定了基础。 |
| [^48] | [Small But Funny: A Feedback-Driven Approach to Humor Distillation](https://arxiv.org/abs/2402.18113) | 通过将大型语言模型分配为“教师”生成数据和“评论家”评估学生表现的双重角色，研究表明这种基于反馈的方法在幽默生成任务中取得了更高的性能。 |
| [^49] | [Making Them Ask and Answer: Jailbreaking Large Language Models in Few Queries via Disguise and Reconstruction](https://arxiv.org/abs/2402.18104) | 通过伪装和重构攻击方法，我们提出了一种在大型语言模型中越狱的方法，通过成功隐藏有害指令并引导模型重构原指令，取得了90%的攻击成功率。 |
| [^50] | [Editing Factual Knowledge and Explanatory Ability of Medical Large Language Models](https://arxiv.org/abs/2402.18099) | 提出了一种新型的Layer-wise Scalable Adapter策略MedLaSA，用于编辑医学大型语言模型，能精确修改医学知识并解释事实，解决了当前方法在医学知识特殊化和复杂性方面的困难。 |
| [^51] | [No Token Left Behind: Reliable KV Cache Compression via Importance-Aware Mixed Precision Quantization](https://arxiv.org/abs/2402.18096) | 通过重要性感知混合精度量化，本论文研究了KV缓存压缩中不丢弃令牌的方法，并发现保留被驱逐KV对中的一小部分信息可以避免安全漏洞、幻觉和上下文丢失。 |
| [^52] | [Polos: Multimodal Metric Learning from Human Feedback for Image Captioning](https://arxiv.org/abs/2402.18091) | 提出了一种使用多模态输入和基于人类反馈的框架训练的自动评估指标Polos，旨在有效开发图像字幕生成模型。 |
| [^53] | [Generative AI for Unmanned Vehicle Swarms: Challenges, Applications and Opportunities](https://arxiv.org/abs/2402.18062) | 生成式人工智能在解决无人车群体挑战方面具有巨大潜力，本文对其在应用、挑战和机遇方面进行了全面调查。 |
| [^54] | [On the use of Silver Standard Data for Zero-shot Classification Tasks in Information Extraction](https://arxiv.org/abs/2402.18061) | 本研究提出了一个新框架Clean-LaVe，旨在利用银标准数据来增强零样本分类性能。 |
| [^55] | [Datasets for Large Language Models: A Comprehensive Survey](https://arxiv.org/abs/2402.18041) | 本文全面探讨了大型语言模型数据集的不同类型、挑战和未来发展方向。 |
| [^56] | [Automated Discovery of Integral with Deep Learning](https://arxiv.org/abs/2402.18040) | 本研究探讨了利用深度学习重新发现基本数学概念：积分的潜力。 |
| [^57] | [ResLoRA: Identity Residual Mapping in Low-Rank Adaption](https://arxiv.org/abs/2402.18039) | ResLoRA提出了在训练中添加残余路径并在推断过程中消除这些额外路径的方法，实现了更好的结果，比LoRA更加高效。 |
| [^58] | [Do Large Language Models Mirror Cognitive Language Processing?](https://arxiv.org/abs/2402.18023) | 本文提出了一种新颖方法，通过将大型语言模型（LLMs）的表示与人类认知信号联系起来，评估LLMs模拟认知语言处理的效果。 |
| [^59] | [Dynamic Explanation Selection Towards Successful User-Decision Support with Explainable AI](https://arxiv.org/abs/2402.18016) | 该论文提出了一种名为X-Selector的方法，通过动态选择解释，预测不同解释组合对用户决策的影响，从而引导用户做出更好的决策。 |
| [^60] | [A Survey on Recent Advances in LLM-Based Multi-turn Dialogue Systems](https://arxiv.org/abs/2402.18013) | 这项调查综述了基于LLM的多轮对话系统的研究，并重点介绍了LLMs的应用和最新进展，对开放领域对话和任务导向对话系统进行了涵盖，并讨论了相关数据集和评估指标，以及未来研究方向和问题。 |
| [^61] | [Diffusion Models as Constrained Samplers for Optimization with Unknown Constraints](https://arxiv.org/abs/2402.18012) | 使用扩散模型在数据流形内进行优化，通过在目标函数定义的Boltzmann分布和扩散模型学习的数据分布的乘积上进行抽样来解决具有未知约束的优化问题。 |
| [^62] | [Mixer is more than just a model](https://arxiv.org/abs/2402.18007) | Mixer的创新之处在于将通道和令牌信息融合，代表了信息提取范式，还可以根据不同需求创建更适合特定任务的混合器。 |
| [^63] | [Exploring Multi-Document Information Consolidation for Scientific Sentiment Summarization](https://arxiv.org/abs/2402.18005) | 通过人类元审阅者的情感整合框架，提出评估指标并在实验中验证，指导LLMs生成科学元审阅的逻辑被验证可行。 |
| [^64] | [Symmetry-aware Reinforcement Learning for Robotic Assembly under Partial Observability with a Soft Wrist](https://arxiv.org/abs/2402.18002) | 本研究利用部分可观测性和深度强化学习处理机器人装配中的零件装配任务，通过利用领域对称性提高样本效率，成功构建了一种基于记忆的代理模型。 |
| [^65] | [FlattenQuant: Breaking Through the Inference Compute-bound for Large Language Models with Per-tensor Quantization](https://arxiv.org/abs/2402.17985) | FlattenQuant方法通过展平张量中的大通道，实现了低比特每张量量化，降低了准确性损失 |
| [^66] | [Ensemble Methodology:Innovations in Credit Default Prediction Using LightGBM, XGBoost, and LocalEnsemble](https://arxiv.org/abs/2402.17979) | 本研究提出了一个集成方法框架，包括LightGBM、XGBoost和LocalEnsemble模块，旨在重新定义信用违约预测的准确性标准。 |
| [^67] | [Imagine, Initialize, and Explore: An Effective Exploration Method in Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2402.17978) | 提出了一种名为Imagine, Initialize, and Explore (IIE)的新方法，利用变压器模型在复杂场景中实现多智能体的有效探索。 |
| [^68] | [Sample-Efficient Preference-based Reinforcement Learning with Dynamics Aware Rewards](https://arxiv.org/abs/2402.17975) | 动态感知奖励函数显著提高了基于偏好的强化学习的样本效率，实验证明只需50个偏好标签即可达到与传统方法500个偏好标签相同的性能，并且能更好地恢复地面真值奖励策略性能。 |
| [^69] | [All in a Single Image: Large Multimodal Models are In-Image Learners](https://arxiv.org/abs/2402.17971) | 这项研究引入了一种名为图片内学习（I$^2$L）的新型上下文学习机制，将演示示例、视觉线索和指令合并到一个图片中，以提升GPT-4V的能力，并通过整合图像处理、理解和推理的能力来取得多个优点 |
| [^70] | [Vision Language Model-based Caption Evaluation Method Leveraging Visual Context Extraction](https://arxiv.org/abs/2402.17969) | 该论文提出了一种基于视觉语言模型的图像标题评估方法，通过提取和组织视觉上下文来替代人工参考文献，从而提升图像标题的评估性能。 |
| [^71] | [Multitask Multilingual Model Adaptation with Featurized Low-Rank Mixtures](https://arxiv.org/abs/2402.17934) | 提出了一种名为FLix的新型参数高效微调方法，适用于多任务多语言调整，通过关联每个独特数据集特征与其低秩权重更新参数，实现了更好的泛化能力和性能表现。 |
| [^72] | [Pragmatic Instruction Following and Goal Assistance via Cooperative Language-Guided Inverse Planning](https://arxiv.org/abs/2402.17930) | 本文介绍了一种名为合作语言引导逆向计划搜索（CLIPS）的贝叶斯代理架构，用于实现实用指令跟随和目标辅助，能够通过多模态贝叶斯推断，利用大型语言模型评估指令的可能性以实现实用目标达成成本最小化。 |
| [^73] | [LLM-Resistant Math Word Problem Generation via Adversarial Attacks](https://arxiv.org/abs/2402.17916) | 本研究提出了一种新方法，通过生成保留原问题结构难度但针对LLMs无解的对抗性示例，有效地降低了LLMs的数学问题解决能力。 |
| [^74] | [Extracting Lexical Features from Dialects via Interpretable Dialect Classifiers](https://arxiv.org/abs/2402.17914) | 通过可解释的方言分类器提取方言的词汇特征，成功识别了有助于方言变化的关键语言特定词汇特征。 |
| [^75] | [Using AI libraries for Incompressible Computational Fluid Dynamics](https://arxiv.org/abs/2402.17913) | 本文提出了一种将AI软件和硬件应用于数值建模领域的新方法，通过重新利用AI方法，如CNN，来解决偏微分方程的标准操作，带来高性能、架构不可知性和易用性。 |
| [^76] | [Researchy Questions: A Dataset of Multi-Perspective, Decompositional Questions for LLM Web Agents](https://arxiv.org/abs/2402.17896) | 提出了一个研究性问题数据集，其中包含非事实型、多透视的问题，能够挑战目前大型语言模型的表现。 |
| [^77] | [ConjNorm: Tractable Density Estimation for Out-of-Distribution Detection](https://arxiv.org/abs/2402.17888) | 提出了一种新颖的理论框架，基于Bregman散度，通过引入共轭约束，提出了一种\textsc{ConjNorm}方法，以在给定数据集中搜索最佳规范系数$p$来重新构想密度函数设计。 |
| [^78] | [REPrune: Channel Pruning via Kernel Representative Selection](https://arxiv.org/abs/2402.17862) | REPrune是一种新颖的通道修剪技术，通过模拟核修剪，并结合聚类和滤波器选择，实现了更精细但结构化的修剪粒度，促进了在训练CNNs期间的高效、渐进式修剪。 |
| [^79] | [Latent Neural PDE Solver: a reduced-order modelling framework for partial differential equations](https://arxiv.org/abs/2402.17853) | 提出了一种名为潜在神经PDE求解器（LNS）的框架，通过在潜在空间学习系统动态并使用较粗糙的离散化，可以大大简化神经PDE求解器的训练过程，降低计算成本。 |
| [^80] | [Follow My Instruction and Spill the Beans: Scalable Data Extraction from Retrieval-Augmented Generation Systems](https://arxiv.org/abs/2402.17840) | 研究揭示了检索增强生成系统中的数据泄露风险，指出对手可以利用LMs的指示遵循能力轻松地从数据存储中直接提取文本数据，并设计了攻击对生产RAG模型GPTs造成数据存储泄漏。 |
| [^81] | [Prediction-Powered Ranking of Large Language Models](https://arxiv.org/abs/2402.17826) | 该研究提出了一种统计框架，可以衡量人类与模型偏好之间的不确定性，从而进行大型语言模型的预测排名。 |
| [^82] | [TruthX: Alleviating Hallucinations by Editing Large Language Models in Truthful Space](https://arxiv.org/abs/2402.17811) | 本文提出了一种名为TruthX的方法，通过在真实空间中编辑大型语言模型的内部表示，有效提高了语言模型的真实性，实验证明在TruthfulQA基准测试中，TruthX平均提高了13种先进语言模型的真实性。 |
| [^83] | [BioT5+: Towards Generalized Biological Understanding with IUPAC Integration and Multi-task Tuning](https://arxiv.org/abs/2402.17810) | BioT5+是BioT5框架的扩展，通过整合IUPAC名称、包含广泛生物文本和分子数据、多任务指令调整以及新颖的数值标记技术，实现了分子表示与文本之间的联系。 |
| [^84] | [Graph Neural Networks and Arithmetic Circuits](https://arxiv.org/abs/2402.17805) | 研究者在本文中建立了图神经网络与算术电路之间的表达能力对应关系，结果表明不同激活函数的GNN在表达能力上等价于实数上的算术电路。 |
| [^85] | [Generative AI and Copyright: A Dynamic Perspective](https://arxiv.org/abs/2402.17801) | 本文研究了生成人工智能对创意产业带来的版权问题，探讨了公平使用标准和AI-版权性对AI发展和公司利润的影响 |
| [^86] | [A Surprising Failure? Multimodal LLMs and the NLVR Challenge](https://arxiv.org/abs/2402.17793) | 这项研究评估了多模LLMs在自然语言视觉推理任务NLVR上的性能表现，发现它们在需要组合和空间推理、对语义和系统性偏见具有鲁棒性的任务上表现不佳。 |
| [^87] | [EGNN-C+: Interpretable Evolving Granular Neural Network and Application in Classification of Weakly-Supervised EEG Data Streams](https://arxiv.org/abs/2402.17792) | 该研究介绍了一种改进的增量学习算法，用于演化颗粒神经网络分类器，能够在分类弱监督EEG数据流时提高鲁棒性和灵活性，同时结合了对情绪相关模式的分类应用。 |
| [^88] | [Label Informed Contrastive Pretraining for Node Importance Estimation on Knowledge Graphs](https://arxiv.org/abs/2402.17791) | 引入标签信息对知识图谱中节点重要性估计问题的对比预训练（LICAP），利用连续标签生成对比样本来更好地了解高重要性节点。 |
| [^89] | [Stepwise Self-Consistent Mathematical Reasoning with Large Language Models](https://arxiv.org/abs/2402.17786) | 提出了一种名为SSC-CoT的算法，通过选择中间步骤的策略和查询知识图来解决大型语言模型进行复杂数学推理时面临的挑战 |
| [^90] | [ByteComposer: a Human-like Melody Composition Method based on Language Model Agent](https://arxiv.org/abs/2402.17785) | 提出了ByteComposer代理框架，在模拟人类创作流程的基础上，将大型语言模型与符号音乐生成模型结合，实现了可与人类创作者相提并论的旋律创作代理。 |
| [^91] | [BagStacking: An Integrated Ensemble Learning Approach for Freezing of Gait Detection in Parkinson's Disease](https://arxiv.org/abs/2402.17783) | BagStacking是一种集成学习方法，通过在训练数据的自举样本上训练一组基础模型，然后在基础模型输出和真实标签上训练元学习器，以找到最佳的聚合方案，实现了对帕金森病患者步态冻结检测的显着改进 |
| [^92] | [Dynamic Anchor Selection and Real-Time Pose Prediction for Ultra-wideband Tagless Gate](https://arxiv.org/abs/2402.17778) | 本文提出了针对超宽带无标签门的动态锚点选择和DS-TWR的实时姿态预测方法，解决了MD准确位置需求，实现了高精度的定位和姿态预测。 |
| [^93] | [Wavelet Scattering Transform for Bioacustics: Application to Watkins Marine Mammal Sound Database](https://arxiv.org/abs/2402.17775) | 本研究提出了在Watkins海洋哺乳动物声音数据库上应用Wavelet散射变换（WST）和Mel频谱图预处理的方法，在分类任务中取得了较高的准确率。 |
| [^94] | [Autonomous Vehicles: Evolution of Artificial Intelligence and Learning Algorithms](https://arxiv.org/abs/2402.17690) | 本文全面探讨了自动驾驶车辆中AI的演进轨迹，从基础原理追溯到最新进展，并阐明了AI在塑造车辆自主决策能力中的基础作用。 |
| [^95] | [Navigator: A Decentralized Scheduler for Latency-Sensitive ML Workflows](https://arxiv.org/abs/2402.17652) | 提出了一种名为Navigator的新型框架，通过统一GPU内存管理和任务放置功能，以减少作业延迟，同时高效利用资源，比其他最先进的调度器表现出更显著的完成时间缩短。 |
| [^96] | [DAGnosis: Localized Identification of Data Inconsistencies using Structures](https://arxiv.org/abs/2402.17599) | DAGnosis使用有向无环图(DAGs)来解决数据一致性检测中的两个关键限制，并能够准确定位为何样本会被标记为不一致。 |
| [^97] | [OmniACT: A Dataset and Benchmark for Enabling Multimodal Generalist Autonomous Agents for Desktop and Web](https://arxiv.org/abs/2402.17553) | OmniACT是一个针对代理生成可执行程序完成计算机任务能力的数据集和基准，超越了传统Web自动化，涵盖了各种桌面应用。 |
| [^98] | [Sora: A Review on Background, Technology, Limitations, and Opportunities of Large Vision Models](https://arxiv.org/abs/2402.17177) | Sora是一种文本到视频生成的人工智能模型，展示出在模拟物理世界方面的潜力，具有广泛的应用前景和挑战，未来发展具有重要意义。 |
| [^99] | [Reliable Conflictive Multi-View Learning](https://arxiv.org/abs/2402.16897) | 提出了可靠的冲突多视角学习（RCML）问题，开发了一种Evidential Conflictive Multi-view Learning (ECML)方法来处理具有冲突信息的多视角数据。 |
| [^100] | [If in a Crowdsourced Data Annotation Pipeline, a GPT-4](https://arxiv.org/abs/2402.16795) | 本文比较了 GPT-4 和 MTurk 管道的数据标注准确性，发现尽管 MTurk 采用了最佳实践，但 GPT-4 的准确率更高，并且结合 GPT-4 和众包标签使用聚合算法可以提高准确率。 |
| [^101] | [Aligning Large Language Models to a Domain-specific Graph Database](https://arxiv.org/abs/2402.16567) | 该论文提出了一种将大型语言模型对齐到特定领域的图数据库的方法，通过利用ChatGPT生成NL-GQL数据对并微调LLMs，实现了两者之间的对齐。 |
| [^102] | [Memory GAPS: Would LLM pass the Tulving Test?](https://arxiv.org/abs/2402.16505) | 本文旨在探讨四十多年前的图尔文测试框架是否对LLM的记忆行为有所帮助。 |
| [^103] | [LLM Inference Unveiled: Survey and Roofline Model Insights](https://arxiv.org/abs/2402.16363) | 本文提出了一个基于Roofline模型的框架，用于系统分析LLM推断技术，帮助识别部署中的瓶颈，并为更有效地部署LLM提供策略。 |
| [^104] | [A Self-matching Training Method with Annotation Embedding Models for Ontology Subsumption Prediction](https://arxiv.org/abs/2402.16278) | 提出了一种自匹配训练方法，通过两种本体嵌入模型捕获全局和局部信息，提高了概念子类预测的稳健性 |
| [^105] | [An Empirical Study of Challenges in Machine Learning Asset Management](https://arxiv.org/abs/2402.15990) | 通过分析开发者论坛和平台上的帖子，研究揭示了与机器学习资产管理挑战相关的133个主题，其中最重要的包括软件依赖、模型部署和模型训练。 |
| [^106] | [Attention-GAN for Anomaly Detection: A Cutting-Edge Approach to Cybersecurity Threat Management](https://arxiv.org/abs/2402.15945) | 该研究提出了一种基于注意力机制的 GAN 框架，用于增强网络安全性，重点关注异常检测，通过生成多样且逼真的合成攻击场景来改进威胁识别和解决数据稀缺性问题。 |
| [^107] | [Optimal Zero-Shot Detector for Multi-Armed Attacks](https://arxiv.org/abs/2402.15808) | 本文提出了一种创新的信息论防御方法，通过最优地汇总现有探测器做出的决策，消除了对训练数据的需求。 |
| [^108] | [Large Scale Generative AI Text Applied to Sports and Music](https://arxiv.org/abs/2402.15514) | 这项工作利用生成式人工智能模型将大规模多模数据转化为连贯流畅文本，首次推出了用于体育和音乐领域的AI评论系统，并取得了显著性能提升。 |
| [^109] | [Text2Pic Swift: Enhancing Long-Text to Image Retrieval for Large-Scale Libraries](https://arxiv.org/abs/2402.15276) | Text2Pic Swift框架针对大规模库中文本描述到图像的检索提出了一种高效且强大的方法，通过两阶段策略解决了长文本查询中的歧义问题 |
| [^110] | [Fine-Tuning of Continuous-Time Diffusion Models as Entropy-Regularized Control](https://arxiv.org/abs/2402.15194) | 扩散模型的微调方法可以通过最大化奖励函数的价值来以目标导向方式进行微调，但可能会面临奖励崩溃的挑战。 |
| [^111] | [Spatially-Aware Transformer Memory for Embodied Agents](https://arxiv.org/abs/2402.15160) | 本文探讨了利用包含空间信息的面向空间感知变压器模型，以改善记忆利用效率。 |
| [^112] | [Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education](https://arxiv.org/abs/2402.15027) | 本研究从多利益相关者视角探讨了教育中不同人工智能应用的可接受性，关注数据隐私、AI代理、透明度、可解释性和道德部署等问题。 |
| [^113] | [Enhancing Systematic Decompositional Natural Language Inference Using Informal Logic](https://arxiv.org/abs/2402.14798) | 本文提出了一种一致且在理论上有根据的方法来注释分解蕴涵数据集，形成RDTE数据集，该数据集在解决何为有效的组合蕴涵的问题上有显著进展。 |
| [^114] | [OpenCodeInterpreter: Integrating Code Generation with Execution and Refinement](https://arxiv.org/abs/2402.14658) | OpenCodeInterpreter是一种开源代码系统，集成了执行、人类反馈和动态代码细化的功能，并在关键基准测试中表现出色，甚至与GPT-4相媲美。 |
| [^115] | [Zero-shot generalization across architectures for visual classification](https://arxiv.org/abs/2402.14095) | 不同神经网络在跨架构和层间泛化到未知类别的能力存在差异，准确性并不是泛化能力的良好预测因子，泛化能力随着层深度呈非单调变化。 |
| [^116] | [Reinforcement learning-assisted quantum architecture search for variational quantum algorithms](https://arxiv.org/abs/2402.13754) | 通过强化学习自动搜索变分电路的最佳结构，改善了VQAs的性能。 |
| [^117] | [ToDo: Token Downsampling for Efficient Generation of High-Resolution Images](https://arxiv.org/abs/2402.13573) | 提出了一种新的训练-free 方法 ToDo，通过令牌下采样加速 Stable Diffusion 推理，以实现高分辨率图像的高效生成。 |
| [^118] | [Structure-informed Positional Encoding for Music Generation](https://arxiv.org/abs/2402.13301) | 提出了一种针对音乐生成的结构感知位置编码框架，通过绝对、相对和非平稳位置信息，显著改善了生成作品的旋律和结构一致性。 |
| [^119] | [A Dynamical View of the Question of Why](https://arxiv.org/abs/2402.10240) | 提出了一种在时间过程中直接建立事件之间因果关系的学习范式，并提出了用于计算因果贡献的两个关键引理，可以揭示和量化扩散过程中的因果关系。 |
| [^120] | [HyperAgent: A Simple, Scalable, Efficient and Provable Reinforcement Learning Framework for Complex Environments](https://arxiv.org/abs/2402.10228) | HyperAgent提出了一种简单、高效、可扩展的强化学习框架，在复杂环境下能够实现高效的计算和数据选择，是首个达到可证明可扩展的每步计算复杂度以及次线性后悔的方法。 |
| [^121] | [GraphTranslator: Aligning Graph Model to Large Language Model for Open-ended Tasks](https://arxiv.org/abs/2402.07197) | "GraphTranslator"是一个旨在将预训练的图模型和大型语言模型对齐的翻译器，可以同时处理预定义任务和开放式任务。通过将这两种模型结合起来，能够有效地处理各种任务，并实现更具创新性和灵活性的应用。 |
| [^122] | [A Closer Look at the Limitations of Instruction Tuning](https://arxiv.org/abs/2402.05119) | 本文通过实验和分析揭示了指令调整的多个局限性，包括无法增强LLM的知识和技能、从具有知识来源的数据集复制回应模式导致质量下降、全参数微调增加了错误生成的情况。 |
| [^123] | [Large-Scale Multi-Robot Coverage Path Planning via Local Search](https://arxiv.org/abs/2312.10797) | 该论文提出了一种新的算法框架LS-MCPP，通过局部搜索直接在分解图上操作，以探索如何系统地搜索地形图上的良好覆盖路径。 |
| [^124] | [Consistency Models for Scalable and Fast Simulation-Based Inference](https://arxiv.org/abs/2312.05440) | 提出了一种新的神经后验估计的一致性模型，结合了标准化流和流匹配方法的优点，用于可扩展、快速和摊销推断，在多个实验中展示出优越性能。 |
| [^125] | [ChatGPT as a Math Questioner? Evaluating ChatGPT on Generating Pre-university Math Questions](https://arxiv.org/abs/2312.01661) | ChatGPT在生成预大学数学问题上的表现进行了评估，为填补现有教育问题生成模型的不足提供了新思路。 |
| [^126] | [TFMQ-DM: Temporal Feature Maintenance Quantization for Diffusion Models](https://arxiv.org/abs/2311.16503) | TFMQ-DM提出了一种称为Temporal Feature Maintenance Quantization (TFMQ)的方法，针对扩散模型中的时间特征进行量化，解决了传统模型中存在的优化问题，提高了压缩效率。 |
| [^127] | [Toward Robust Imperceptible Perturbation against Unauthorized Text-to-image Diffusion-based Synthesis](https://arxiv.org/abs/2311.13127) | MetaCloak提出了一种基于元学习框架的解决方案，通过额外转换抽样过程来制造可转移和鲁棒的扰动，以解决现有防御方法的局限性。 |
| [^128] | [BLT: Can Large Language Models Handle Basic Legal Text?](https://arxiv.org/abs/2311.09693) | 大型语言模型在处理基础法律文本方面表现不佳，但通过针对性微调，甚至较小的模型也能在测试中表现出色，提升了相关法律任务的表现。 |
| [^129] | [Identification and Estimation for Nonignorable Missing Data: A Data Fusion Approach](https://arxiv.org/abs/2311.09015) | 该论文提出了一种数据融合方法，通过将缺失不是随机的数据集与随机缺失的辅助数据集信息相结合，实现对感兴趣参数的识别和估计。 |
| [^130] | [In Search of the Long-Tail: Systematic Generation of Long-Tail Inferential Knowledge via Logical Rule Guided Search](https://arxiv.org/abs/2311.07237) | 该研究提出了一个名为LINK的框架，能够系统性地生成长尾推理知识，从而更有效地评估LLMs在推理空间中的表现。 |
| [^131] | [Large Trajectory Models are Scalable Motion Predictors and Planners](https://arxiv.org/abs/2310.19620) | 大规模轨迹模型（LTMs）采用State Transformer (STR)模型，将运动预测和规划问题统一建模，有效应对自动驾驶中的挑战。 |
| [^132] | [UWB Based Static Gesture Classification](https://arxiv.org/abs/2310.15036) | 该论文提出了基于UWB的静态手势识别的稳健框架，经过数据集收集和处理，训练模型达到96.78%准确率，并开发了用户友好的GUI框架，为将UWB技术应用于静态手势识别带来了重要进展。 |
| [^133] | [Ask Again, Then Fail: Large Language Models' Vacillations in Judgement](https://arxiv.org/abs/2310.02174) | 目前的语言模型在面对后续问题时常常摇摆不定，研究者提出了一个后续问题机制和两个度量标准来量化这种不一致性，并开发出Unwavering-FQ框架来教导模型保持最初的正确判断，实验证明其有效性。 |
| [^134] | [Errors are Robustly Tamed in Cumulative Knowledge Processes](https://arxiv.org/abs/2309.05638) | 该研究考虑了更一般的累积知识过程家族，探讨了在社会知识积累过程中如何确保一定比例的知识有效性。 |
| [^135] | [Towards Video Anomaly Retrieval from Video Anomaly Detection: New Benchmarks and Model](https://arxiv.org/abs/2307.12545) | 提出了视频异常检索(VAR)任务，旨在通过跨模态检索相关异常视频。 |
| [^136] | [Understanding Certified Training with Interval Bound Propagation](https://arxiv.org/abs/2306.10426) | 本研究通过引入一种新颖指标，深入探讨了区间传播边界（IBP）训练成功的机制。理论上表明，对于深度线性模型，IBP训练能够在足够宽度的条件下改善边界紧密度。 |
| [^137] | [MiniLLM: Knowledge Distillation of Large Language Models](https://arxiv.org/abs/2306.08543) | 本文提出了一种将大型语言模型的知识蒸馏到更小模型的方法，通过使用反向KLD替换标准KD方法中的前向KLD目标，有效避免了学生模型高估教师分布的低概率区域。 |
| [^138] | [Interruption-Aware Cooperative Perception for V2X Communication-Aided Autonomous Driving](https://arxiv.org/abs/2304.11821) | V2X-INCOP是一个针对V2X通信辅助自动驾驶的合作感知系统，利用历史合作信息来恢复由中断引起的丢失信息，并缓解安全风险。 |
| [^139] | [Mutual Information Regularized Offline Reinforcement Learning](https://arxiv.org/abs/2210.07484) | 该论文提出了一种互信息正则化的离线强化学习方法，通过直接约束策略改进方向，从而有效解决了离线强化学习中出现的分布偏移问题。 |
| [^140] | [Emergent Dominance Hierarchies in Reinforcement Learning Agents.](http://arxiv.org/abs/2401.12258) | 本研究在强化学习中探讨了一种新的支配等级现象，并证明了在没有明确编程和内在奖励的情况下，强化学习代理能够自主发明、学习、实施和传递支配等级给新的群体。 |
| [^141] | [Efficient local linearity regularization to overcome catastrophic overfitting.](http://arxiv.org/abs/2401.11618) | 本研究引入了一种名为ELLE的正则化项，用于高效地减轻单步对抗性训练中的灾难性过拟合。它能够保持损失函数在输入上的局部线性性，与传统的正则化方法相比，ELLE更加高效，能够有效应对大对抗性扰动和长训练计划等困难情况。 |
| [^142] | [BIBench: Benchmarking Data Analysis Knowledge of Large Language Models.](http://arxiv.org/abs/2401.02982) | BIBench是一个旨在评估大型语言模型（LLMs）在商业智能（BI）数据分析领域中能力的综合基准测试，其通过测试模型在BI基础知识、应用知识和技术技能三个维度上的表现来进行评估。 |
| [^143] | [Improving Low-resource Prompt-based Relation Representation with Multi-view Decoupling Learning.](http://arxiv.org/abs/2312.17267) | 提出了一种名为MVRE的新方法，通过将关系解耦为不同的视角，生成多视角关系表示，并利用预训练语言模型（PLMs）的能力来提高低资源关系抽取任务的性能。 |
| [^144] | [Federated Heterogeneous Graph Neural Network for Privacy-preserving Recommendation.](http://arxiv.org/abs/2310.11730) | 本文提出了一种联邦异构图神经网络（FedHGNN）的框架，能够在分布式的异构信息网络上协同训练推荐模型，同时保护用户隐私。 |
| [^145] | [Physics-aware Machine Learning Revolutionizes Scientific Paradigm for Machine Learning and Process-based Hydrology.](http://arxiv.org/abs/2310.05227) | 物理感知机器学习是一种革命性方法，它将物理知识和机器学习相结合，提供了准确的水文学理解和水循环预测，对于管理水资源以应对气候变化等挑战具有重要意义。 |
| [^146] | [MindShift: Leveraging Large Language Models for Mental-States-Based Problematic Smartphone Use Intervention.](http://arxiv.org/abs/2309.16639) | MindShift利用大型语言模型实现了基于心态的问题性智能手机使用干预，通过动态生成适应用户环境和心理状态的高质量说服内容来帮助用户解决问题性智能手机使用的困扰。 |
| [^147] | [Cure the headache of Transformers via Collinear Constrained Attention.](http://arxiv.org/abs/2309.08646) | 通过引入共线约束注意力（CoCA）结构，解决Transformer模型中的头痛问题，实现了出色的外推性能和提高的计算效率。 |
| [^148] | [CL-MAE: Curriculum-Learned Masked Autoencoders.](http://arxiv.org/abs/2308.16572) | 本文提出了一种课程学习的遮罩自编码器（CL-MAE）。我们引入了一种可学习的遮罩模块，通过更新遮罩策略来增加自监督重构任务的复杂性。通过逐渐增加任务复杂性，模型可以学习更复杂和可迁移的表示。 |
| [^149] | [FedSoL: Bridging Global Alignment and Local Generality in Federated Learning.](http://arxiv.org/abs/2308.12532) | FedSoL提出了一种联邦学习的方法，该方法旨在解决数据分布不均匀导致性能下降的问题。它通过平衡全局对齐和本地一般性来改善FL的学习效果。 |
| [^150] | [One for Multiple: Physics-informed Synthetic Data Boosts Generalizable Deep Learning for Fast MRI Reconstruction.](http://arxiv.org/abs/2307.13220) | 提出了一种名为PISF的物理信息合成数据学习框架，该框架使得快速MRI重建中的多场景可推广深度学习成为可能。 |
| [^151] | [Hyperbolic Active Learning for Semantic Segmentation under Domain Shift.](http://arxiv.org/abs/2306.11180) | 这项研究首次在Poincaré双曲球模型中运用超bolic活跃学习方法，利用区域内像素嵌入的半径变化作为新的数据获取策略，以提升域转移下语义分割的性能。 |
| [^152] | [Efficient Recruitment Strategy for Collaborative Mobile Crowd Sensing Based on GCN Trustworthiness Prediction.](http://arxiv.org/abs/2306.04366) | 本文提出了一种基于GCN可信度预测的协同移动群感知的高效招募策略，通过捕获工人之间的非对称信任关系和工人能力来实现有效的任务分配，优于现有方法。 |
| [^153] | [A Meta-learning Framework for Tuning Parameters of Protection Mechanisms in Trustworthy Federated Learning.](http://arxiv.org/abs/2305.18400) | 提出了一个元学习框架，用于调整可信联邦学习保护机制的参数，以在隐私泄露、效用损失和效率降低之间进行权衡。 |
| [^154] | [Tune-Mode ConvBN Blocks For Efficient Transfer Learning.](http://arxiv.org/abs/2305.11624) | 本文研究了ConvBN块中稳定性和效率之间的权衡问题，提出了一种新的Tune模式，以便在迁移学习中既能保持稳定性又能提高效率。 |
| [^155] | [False Claims against Model Ownership Resolution.](http://arxiv.org/abs/2304.06607) | 该论文研究了模型所有权解决方案中对抗恶意原告的鲁棒性问题，展示了常见的MOR方案可以被恶意原告针对未被盗用的独立模型提出虚假指控。 |
| [^156] | [A Game-theoretic Framework for Federated Learning.](http://arxiv.org/abs/2304.05836) | 本文提出了一个名为联邦学习安全博弈（FLSG）的博弈论框架，该框架同时考虑到联邦学习的保护者和攻击者的收益，包括计算成本、FL模型效用和隐私泄漏风险，并提出了一个实用算法来近似oracle并保持隐私。研究表明该算法对于预防和检测现实世界中的联邦学习攻击具有有效性。 |
| [^157] | [A Comprehensive Survey on Deep Graph Representation Learning.](http://arxiv.org/abs/2304.05055) | 本文综述了深度图表示学习的研究现状和存在的问题，并指出利用深度学习已经显示出巨大的优势和潜力。 |
| [^158] | [On the Robustness of Bayesian Neural Networks to Adversarial Attacks.](http://arxiv.org/abs/2207.06154) | 本文研究了贝叶斯神经网络在对抗攻击下的鲁棒性问题，证明了在大数据、超参数化极限下，BNN的后验具有梯度攻击的鲁棒性，这对于解决深度学习在安全关键应用中的脆弱性问题具有重要意义。 |
| [^159] | [Multimodal Fusion of EMG and Vision for Human Grasp Intent Inference in Prosthetic Hand Control.](http://arxiv.org/abs/2104.03893) | 本文提出了一种使用眼睛视图视频、注视眼动和肌电进行握持意图推理的贝叶斯证据融合框架，在人工智能假肢手控制中具有重要应用价值。 |

# 详细

[^1]: 在图上的小样本学习：从元学习到预训练和提示

    Few-Shot Learning on Graphs: from Meta-learning to Pre-training and Prompting

    [https://rss.arxiv.org/abs/2402.01440](https://rss.arxiv.org/abs/2402.01440)

    本文综述了图上的小样本学习的最新发展，将现有的研究方法划分为元学习、预训练和混合方法三大类别，并对它们的优缺点进行了比较。还提出了未来的研究方向。

    

    图表示学习是图中心任务中的关键步骤，在这方面已经取得了重大进展。早期的技术通常在端到端的设置中运行，性能严重依赖于充足的标记数据的可用性。这个限制引发了图上的小样本学习的出现，其中每个任务只有少量的任务特定标签可用。鉴于这个领域的广泛文献，本综述试图综合最近的发展，提供比较性的见解，并确定未来的方向。我们将现有的研究系统地分为三个主要类别：元学习方法、预训练方法和混合方法，并在每个类别中进行细粒度的分类，以帮助读者进行方法选择。在每个类别中，我们分析这些方法之间的关系并比较它们的优缺点。最后，我们概述了图上的小样本学习未来的方向。

    Graph representation learning, a critical step in graph-centric tasks, has seen significant advancements. Earlier techniques often operate in an end-to-end setting, where performance heavily relies on the availability of ample labeled data. This constraint has spurred the emergence of few-shot learning on graphs, where only a few task-specific labels are available for each task. Given the extensive literature in this field, this survey endeavors to synthesize recent developments, provide comparative insights, and identify future directions. We systematically categorize existing studies into three major families: meta-learning approaches, pre-training approaches, and hybrid approaches, with a finer-grained classification in each family to aid readers in their method selection process. Within each category, we analyze the relationships among these methods and compare their strengths and limitations. Finally, we outline prospective future directions for few-shot learning on graphs to cata
    
[^2]: 用于满足多样用户偏好的算术控制LLMs：具有多目标奖励的方向偏好对齐

    Arithmetic Control of LLMs for Diverse User Preferences: Directional Preference Alignment with Multi-Objective Rewards

    [https://arxiv.org/abs/2402.18571](https://arxiv.org/abs/2402.18571)

    提出了方向偏好对齐（DPA）框架，通过多目标奖励模拟不同偏好配置，以实现用户相关的偏好控制。

    

    针对大型语言模型（LLMs）的精细控制仍然是一个重要挑战，阻碍了它们适应各种用户需求。本文提出了方向偏好对齐（DPA）框架，通过多目标奖励建模来表示多样化的偏好配置，将用户偏好建模为奖励空间中的方向（即单位向量）以实现用户相关的偏好控制。

    arXiv:2402.18571v1 Announce Type: cross  Abstract: Fine-grained control over large language models (LLMs) remains a significant challenge, hindering their adaptability to diverse user needs. While Reinforcement Learning from Human Feedback (RLHF) shows promise in aligning LLMs, its reliance on scalar rewards often limits its ability to capture diverse user preferences in real-world applications. To address this limitation, we introduce the Directional Preference Alignment (DPA) framework. Unlike the scalar-reward RLHF, DPA incorporates multi-objective reward modeling to represent diverse preference profiles. Additionally, DPA models user preferences as directions (i.e., unit vectors) in the reward space to achieve user-dependent preference control. Our method involves training a multi-objective reward model and then fine-tuning the LLM with a preference-conditioned variant of Rejection Sampling Finetuning (RSF), an RLHF method adopted by Llama 2. This method enjoys a better performance
    
[^3]: 用语言模型接近人类水平的预测能力

    Approaching Human-Level Forecasting with Language Models

    [https://arxiv.org/abs/2402.18563](https://arxiv.org/abs/2402.18563)

    该研究探讨了使用语言模型（LMs）进行预测未来事件的能力，开发了一种检索增强型LM系统，通过在竞争性预测平台收集数据集，并在知识截止日期后评估系统性能，发现该系统能够准确预测未来事件并在某些情况下超越人类预测者。

    

    预测未来事件对政策和决策制定至关重要。本研究探讨了语言模型(LMs)是否能够在竞争性人类预测者的水平上进行预测。为实现这一目标，我们开发了一种检索增强型LM系统，旨在自动搜索相关信息、生成预测和聚合预测。为了促进研究，我们收集了来自竞争性预测平台的大量问题数据集。在LM的知识截止日期之后发布的测试集下，我们评估了我们系统的端到端性能与人类预测的聚合之间的比较。平均而言，该系统接近于竞争预测者的聚合，并在某些情况下超越了它。我们的工作表明，利用LM来预测未来可能会提供准确的大规模预测，并有助于为机构决策提供信息。

    arXiv:2402.18563v1 Announce Type: cross  Abstract: Forecasting future events is important for policy and decision making. In this work, we study whether language models (LMs) can forecast at the level of competitive human forecasters. Towards this goal, we develop a retrieval-augmented LM system designed to automatically search for relevant information, generate forecasts, and aggregate predictions. To facilitate our study, we collect a large dataset of questions from competitive forecasting platforms. Under a test set published after the knowledge cut-offs of our LMs, we evaluate the end-to-end performance of our system against the aggregates of human forecasts. On average, the system nears the crowd aggregate of competitive forecasters, and in some settings surpasses it. Our work suggests that using LMs to forecast the future could provide accurate predictions at scale and help to inform institutional decision making.
    
[^4]: 在微调后保持LLMs的对齐性:提示模板的关键作用

    Keeping LLMs Aligned After Fine-tuning: The Crucial Role of Prompt Templates

    [https://arxiv.org/abs/2402.18540](https://arxiv.org/abs/2402.18540)

    提出了“纯粹调优，安全测试”（PTST）原则，即在微调时不包含安全提示，但在测试时加入，可以显著减少LLMs中不安全行为的出现。

    

    公共LLMs，如Llama 2-Chat，推动了LLM研究的巨大活动。这些模型经历了对齐性训练，被认为是安全的。最近，齐等人（2023年）报告称，即使是良性的微调（例如，在看似安全的数据集上）也可能导致模型产生不安全的行为。本文介绍了减轻这种对齐性丢失的方法和最佳实践。通过对几个聊天模型（Meta的Llama 2-Chat，Mistral AI的Mistral 7B Instruct v0.2和OpenAI的GPT-3.5 Turbo）进行广泛实验，本文发现微调和推理过程中使用的提示模板在保持安全对齐性方面起着至关重要的作用，并提出了“纯粹调优，安全测试”（PTST）原则 - 在测试时不使用安全提示进行模型微调，但在测试时包含它。对GSM8K，ChatDoctor和OpenOrca进行的微调实验表明，PTST显着减少了不安全行为的增加，甚至几乎消除了它们。

    arXiv:2402.18540v1 Announce Type: cross  Abstract: Public LLMs such as the Llama 2-Chat have driven huge activity in LLM research. These models underwent alignment training and were considered safe. Recently Qi et al. (2023) reported that even benign fine-tuning (e.g., on seemingly safe datasets) can give rise to unsafe behaviors in the models. The current paper is about methods and best practices to mitigate such loss of alignment. Through extensive experiments on several chat models (Meta's Llama 2-Chat, Mistral AI's Mistral 7B Instruct v0.2, and OpenAI's GPT-3.5 Turbo), this paper uncovers that the prompt templates used during fine-tuning and inference play a crucial role in preserving safety alignment, and proposes the "Pure Tuning, Safe Testing" (PTST) principle -- fine-tune models without a safety prompt, but include it at test time. Fine-tuning experiments on GSM8K, ChatDoctor, and OpenOrca show that PTST significantly reduces the rise of unsafe behaviors, and even almost elimin
    
[^5]: 语言模型表达自我和他人信念

    Language Models Represent Beliefs of Self and Others

    [https://arxiv.org/abs/2402.18496](https://arxiv.org/abs/2402.18496)

    通过神经激活线性解析语言模型中代理人观点下的信念状态，揭示了大型语言模型内部表述自我和他人信念，这对社会推理过程至关重要，并在多样社会推理任务中具有潜在的泛化能力。

    

    理解和归因心理状态，即心灵理论（ToM），被视为人类社会推理的基本能力。虽然大型语言模型（LLMs）似乎具有某些ToM能力，但这些能力背后的机制仍然令人费解。在本研究中，我们发现通过语言模型的神经激活线性解码各个代理人观点下的信念状态是可能的，这表明存在自我的内部表述和他人信念的表示。通过操纵这些表征，我们观察到模型的ToM性能发生显著变化，突显了其在社会推理过程中的关键作用。此外，我们的发现还延伸到涉及不同因果推理模式的多样社会推理任务，暗示了这些表征的潜在泛化能力。

    arXiv:2402.18496v1 Announce Type: new  Abstract: Understanding and attributing mental states, known as Theory of Mind (ToM), emerges as a fundamental capability for human social reasoning. While Large Language Models (LLMs) appear to possess certain ToM abilities, the mechanisms underlying these capabilities remain elusive. In this study, we discover that it is possible to linearly decode the belief status from the perspectives of various agents through neural activations of language models, indicating the existence of internal representations of self and others' beliefs. By manipulating these representations, we observe dramatic changes in the models' ToM performance, underscoring their pivotal role in the social reasoning process. Additionally, our findings extend to diverse social reasoning tasks that involve different causal inference patterns, suggesting the potential generalizability of these representations.
    
[^6]: 人本关注的多目标强化学习与AHP及基于相似性经验回放的无人机轨迹规划在搜索和救援任务中的应用

    Human-Centric Aware UAV Trajectory Planning in Search and Rescue Missions Employing Multi-Objective Reinforcement Learning with AHP and Similarity-Based Experience Replay

    [https://arxiv.org/abs/2402.18487](https://arxiv.org/abs/2402.18487)

    该论文探讨了人本关注因素在搜索和救援任务中无人机轨迹规划中的作用，引入了基于强化学习、AHP和基于相似性经验回放的新方法优化无人机轨迹，平衡了运营目标与人类舒适和安全考虑。

    

    集成无人机（UAVs）到搜索和救援（SAR）任务中为提高操作效率和效果提供了一个有前景的途径。然而，这些任务的成功不仅仅取决于无人机的技术能力，也取决于它们与地面人员的接受和互动。本文探讨了人本因素在SAR任务中无人机轨迹规划中的作用。我们引入了一种基于强化学习的新方法，该方法使用层次分析过程和新的基于相似性的经验回放优化无人机轨迹，平衡操作目标与人类舒适性和安全考虑。此外，通过一项全面的调查，我们研究了在无人机设计中性别暗示和拟人化对公众接受和信任的影响，揭示了对SAR中无人机互动策略具有重要意义的重要影响。

    arXiv:2402.18487v1 Announce Type: cross  Abstract: The integration of Unmanned Aerial Vehicles (UAVs) into Search and Rescue (SAR) missions presents a promising avenue for enhancing operational efficiency and effectiveness. However, the success of these missions is not solely dependent on the technical capabilities of the drones but also on their acceptance and interaction with humans on the ground. This paper explores the effect of human-centric factor in UAV trajectory planning for SAR missions. We introduce a novel approach based on the reinforcement learning augmented with Analytic Hierarchy Process and novel similarity-based experience replay to optimize UAV trajectories, balancing operational objectives with human comfort and safety considerations. Additionally, through a comprehensive survey, we investigate the impact of gender cues and anthropomorphism in UAV design on public acceptance and trust, revealing significant implications for drone interaction strategies in SAR. Our c
    
[^7]: FinAgent: 用于金融交易的多模态基础代理：工具增强、多样化和通用

    FinAgent: A Multimodal Foundation Agent for Financial Trading: Tool-Augmented, Diversified, and Generalist

    [https://arxiv.org/abs/2402.18485](https://arxiv.org/abs/2402.18485)

    FinAgent是一个多模态基础代理，通过工具增强用于金融交易，具有独特的双重反射模块，可以处理多样化的数据并快速适应市场动态。

    

    金融交易是市场的重要组成部分，受到新闻、价格和K线图等多模态信息构成的信息景观的影响，涵盖了诸如量化交易和不同资产的高频交易等多样化任务。尽管深度学习和强化学习等先进AI技术在金融领域得到广泛应用，但它们在金融交易任务中的应用往往面临着多模态数据处理不足和跨不同任务有限泛化能力的挑战。为了解决这些挑战，我们提出了FinAgent，一个具有工具增强功能的多模态基础代理，用于金融交易。FinAgent的市场智能模块处理各种数据-数值、文本和图像-以准确分析金融市场。其独特的双重反射模块不仅能够快速适应市场动态，还融合了多样化的记忆检索。

    arXiv:2402.18485v1 Announce Type: cross  Abstract: Financial trading is a crucial component of the markets, informed by a multimodal information landscape encompassing news, prices, and Kline charts, and encompasses diverse tasks such as quantitative trading and high-frequency trading with various assets. While advanced AI techniques like deep learning and reinforcement learning are extensively utilized in finance, their application in financial trading tasks often faces challenges due to inadequate handling of multimodal data and limited generalizability across various tasks. To address these challenges, we present FinAgent, a multimodal foundational agent with tool augmentation for financial trading. FinAgent's market intelligence module processes a diverse range of data-numerical, textual, and visual-to accurately analyze the financial market. Its unique dual-level reflection module not only enables rapid adaptation to market dynamics but also incorporates a diversified memory retri
    
[^8]: 在因果发现中的签名核条件独立性测试用于随机过程

    Signature Kernel Conditional Independence Tests in Causal Discovery for Stochastic Processes

    [https://arxiv.org/abs/2402.18477](https://arxiv.org/abs/2402.18477)

    本文在随机过程中开发了一种基于签名核的条件独立性测试，实现了对因果关系的推断，以及开发了约束条件的因果发现算法用于恢复整个有向图。

    

    从观测数据中推断随机动力系统背后的因果结构在科学、健康和金融等领域具有巨大潜力。本文通过利用最近签名核技术的进展，开发了一种基于内核的“路径空间”上条件独立性（CI）测试，用于随机微分方程的解。我们展示了相较于现有方法，在路径空间上，我们提出的CI测试表现出严格更好的性能。此外，我们还为非循环随机动力系统开发了基于约束的因果发现算法，利用时间信息来恢复整个有向图。在假设忠实性和CI预言机的情况下，我们的算法是完备且正确的。

    arXiv:2402.18477v1 Announce Type: cross  Abstract: Inferring the causal structure underlying stochastic dynamical systems from observational data holds great promise in domains ranging from science and health to finance. Such processes can often be accurately modeled via stochastic differential equations (SDEs), which naturally imply causal relationships via "which variables enter the differential of which other variables". In this paper, we develop a kernel-based test of conditional independence (CI) on "path-space" -- solutions to SDEs -- by leveraging recent advances in signature kernels. We demonstrate strictly superior performance of our proposed CI test compared to existing approaches on path-space. Then, we develop constraint-based causal discovery algorithms for acyclic stochastic dynamical systems (allowing for loops) that leverage temporal information to recover the entire directed graph. Assuming faithfulness and a CI oracle, our algorithm is sound and complete. We empirical
    
[^9]: HOP到自然语言处理中连续学习的下一个任务和领域

    HOP to the Next Tasks and Domains for Continual Learning in NLP

    [https://arxiv.org/abs/2402.18449](https://arxiv.org/abs/2402.18449)

    该方法HOP在连续学习中引入了三个方向以在自然语言处理中跨任务和领域进行学习。

    

    连续学习（CL）旨在通过转移先前问题中获得的知识来学习一系列问题（即任务和领域），同时避免遗忘过去的问题。与先前专注于特定用例中一个NLP任务或领域的CL方法不同，本文针对一个更通用的CL设置，从一个唯一的框架中学习一系列问题。我们的方法HOP通过沿三个方向解决CL问题来允许在任务和领域之间跳跃：（i）我们使用一组适配器将大型预训练模型推广到未见问题，（ii）我们计算嵌入表示分布上的高阶矩以区分不同任务和领域之间的独立和相关统计数据，（iii）我们通过为每个最终问题专门设计的辅助头处理这些丰富信息。我们在4个NLP应用程序，5个基准测试和...

    arXiv:2402.18449v1 Announce Type: cross  Abstract: Continual Learning (CL) aims to learn a sequence of problems (i.e., tasks and domains) by transferring knowledge acquired on previous problems, whilst avoiding forgetting of past ones. Different from previous approaches which focused on CL for one NLP task or domain in a specific use-case, in this paper, we address a more general CL setting to learn from a sequence of problems in a unique framework. Our method, HOP, permits to hop across tasks and domains by addressing the CL problem along three directions: (i) we employ a set of adapters to generalize a large pre-trained model to unseen problems, (ii) we compute high-order moments over the distribution of embedded representations to distinguish independent and correlated statistics across different tasks and domains, (iii) we process this enriched information with auxiliary heads specialized for each end problem. Extensive experimental campaign on 4 NLP applications, 5 benchmarks and 
    
[^10]: LeMo-NADe: 基于LLMs的多参数神经架构发现

    LeMo-NADe: Multi-Parameter Neural Architecture Discovery with LLMs

    [https://arxiv.org/abs/2402.18443](https://arxiv.org/abs/2402.18443)

    LeMo-NADe是一种基于LLM的框架，旨在根据用户定义的参数、专家系统和大量开放领域知识，自动发现新的神经网络架构，适用于非AI专家，无需预设的搜索空间，并考虑了大量边缘设备特定的参数。

    

    建立高效的神经网络架构可能是一项耗时且需要广泛专业知识的任务。对于边缘设备来说，这项任务变得尤为具有挑战性，因为人们必须考虑推理过程中的功耗、模型大小、推理速度和CO2排放量等参数。在本文中，我们介绍了一种新颖的框架，旨在根据用户定义的参数、专家系统和在大量开放领域知识上训练的LLM，自动发现新的神经网络架构。引入的框架（LeMo-NADe）旨在供非人工智能专家使用，不需要预先确定的神经架构搜索空间，并考虑了大量边缘设备特定的参数。我们利用GPT-4 Turbo和Gemini作为LLM组件，在CIFAR-10、CIFAR-100和ImageNet16-120数据集上实施和验证了这一提出的神经架构发现框架。

    arXiv:2402.18443v1 Announce Type: cross  Abstract: Building efficient neural network architectures can be a time-consuming task requiring extensive expert knowledge. This task becomes particularly challenging for edge devices because one has to consider parameters such as power consumption during inferencing, model size, inferencing speed, and CO2 emissions. In this article, we introduce a novel framework designed to automatically discover new neural network architectures based on user-defined parameters, an expert system, and an LLM trained on a large amount of open-domain knowledge. The introduced framework (LeMo-NADe) is tailored to be used by non-AI experts, does not require a predetermined neural architecture search space, and considers a large set of edge device-specific parameters. We implement and validate this proposed neural architecture discovery framework using CIFAR-10, CIFAR-100, and ImageNet16-120 datasets while using GPT-4 Turbo and Gemini as the LLM component. We obser
    
[^11]: 超越自然语言：LLM利用替代格式进行增强推理和沟通

    Beyond Natural Language: LLMs Leveraging Alternative Formats for Enhanced Reasoning and Communication

    [https://arxiv.org/abs/2402.18439](https://arxiv.org/abs/2402.18439)

    挑战了默认使用自然语言的做法，通过探索LLMs在推理和沟通中使用替代格式的实用性，实现了推理效率的提升和多智能体通信时标记使用量的显著减少。

    

    自然语言（NL）长期以来一直是人类认知和沟通的主要格式，因此，在大型语言模型（LLMs）的发展和应用中同样至关重要。然而，除了NL之外，LLMs在预训练过程中看到了各种非NL格式，如代码和逻辑表达式。NL作为LLMs的最佳格式，在单一LLM推理和多智能体通信中的地位尚未得到彻底审查。在这项工作中，我们挑战了默认使用NL，通过探索在这些上下文中使用非NL格式的效用。我们展示，允许LLMs在推理或沟通之前自主选择最合适的格式，可导致不同LLMs推理效率提高3.3至5.7％，并且在多智能体通信中最多可减少72.7％的标记使用，同时保持沟通效果。我们的综合分析进一步揭示了LLMs可以......

    arXiv:2402.18439v1 Announce Type: cross  Abstract: Natural language (NL) has long been the predominant format for human cognition and communication, and by extension, has been similarly pivotal in the development and application of Large Language Models (LLMs). Yet, besides NL, LLMs have seen various non-NL formats during pre-training, such as code and logical expression. NL's status as the optimal format for LLMs, particularly in single-LLM reasoning and multi-agent communication, has not been thoroughly examined. In this work, we challenge the default use of NL by exploring the utility of non-NL formats in these contexts. We show that allowing LLMs to autonomously select the most suitable format before reasoning or communicating leads to a 3.3 to 5.7\% improvement in reasoning efficiency for different LLMs, and up to a 72.7\% reduction in token usage in multi-agent communication, all while maintaining communicative effectiveness. Our comprehensive analysis further reveals that LLMs c
    
[^12]: 神经网络中关系归纳偏好对维度抽象的影响

    A Relational Inductive Bias for Dimensional Abstraction in Neural Networks

    [https://arxiv.org/abs/2402.18426](https://arxiv.org/abs/2402.18426)

    研究了神经网络中关系归纳偏好对维度抽象的影响，并证明关系瓶颈机制能够提高泛化和学习效率，使网络表现与人类行为偏好一致。 - 关系瓶颈改善神经网络处理抽象任务的能力，促进网络在维度上进行组合编码，提高处理灵活性。

    

    人类认知系统表现出卓越的灵活性和泛化能力，部分原因在于其能够形成环境的低维、组合表示。相比之下，标准神经网络架构常常在抽象推理任务、过拟合和需要大量数据进行训练时遇到困难。本文研究了关系瓶颈的影响 - 这是一种将处理集中在输入之间关系上的机制 - 对学习有利于组成编码和相应处理灵活性的分解表示的影响。我们证明这种瓶颈不仅提高了泛化和学习效率，还使网络表现与类似人类的行为偏好一致。经过关系瓶颈训练的网络发展出了在数据集中潜在的特征维度上正交的表示，反映了被认为存在的分解结构。

    arXiv:2402.18426v1 Announce Type: new  Abstract: The human cognitive system exhibits remarkable flexibility and generalization capabilities, partly due to its ability to form low-dimensional, compositional representations of the environment. In contrast, standard neural network architectures often struggle with abstract reasoning tasks, overfitting, and requiring extensive data for training. This paper investigates the impact of the relational bottleneck -- a mechanism that focuses processing on relations among inputs -- on the learning of factorized representations conducive to compositional coding and the attendant flexibility of processing. We demonstrate that such a bottleneck not only improves generalization and learning efficiency, but also aligns network performance with human-like behavioral biases. Networks trained with the relational bottleneck developed orthogonal representations of feature dimensions latent in the dataset, reflecting the factorized structure thought to unde
    
[^13]: 低资源和中等资源语言中的情感分类

    Emotion Classification in Low and Moderate Resource Languages

    [https://arxiv.org/abs/2402.18424](https://arxiv.org/abs/2402.18424)

    通过跨语言情感分类器，在低和中等资源语言中实现情感分类，展示了两种迁移学习方法的有效性。

    

    能够分析全球范围内人们情绪状态是很重要的。全球有7100多种活跃语言，为每种语言构建情感分类是一项劳动密集型工作。特别是对于低资源和濒危语言，建立情感分类可能非常具有挑战性。我们提出了一种跨语言情感分类器，我们在资源丰富的语言（例如我们的工作中的英语）上训练情感分类器，并将学习迁移到低资源和中等资源的语言。我们比较并对比了从高资源语言到低资源或中等资源语言的两种迁移学习方法。一种方法将高资源语言的标注投影到低资源和中等资源语言的平行语料库中，另一种方法直接将高资源语言的学习迁移到其他语言。我们展示了我们的方法在6种语言上的有效性：Fa

    arXiv:2402.18424v1 Announce Type: cross  Abstract: It is important to be able to analyze the emotional state of people around the globe. There are 7100+ active languages spoken around the world and building emotion classification for each language is labor intensive. Particularly for low-resource and endangered languages, building emotion classification can be quite challenging. We present a cross-lingual emotion classifier, where we train an emotion classifier with resource-rich languages (i.e. \textit{English} in our work) and transfer the learning to low and moderate resource languages. We compare and contrast two approaches of transfer learning from a high-resource language to a low or moderate-resource language. One approach projects the annotation from a high-resource language to low and moderate-resource language in parallel corpora and the other one uses direct transfer from high-resource language to the other languages. We show the efficacy of our approaches on 6 languages: Fa
    
[^14]: 能否通过基于指南的自动问答来改善GPT的先前授权状态？

    Can GPT Improve the State of Prior Authorization via Guideline Based Automated Question Answering?

    [https://arxiv.org/abs/2402.18419](https://arxiv.org/abs/2402.18419)

    通过问答任务，GPT能够验证医疗领域患者的PA请求，帮助卫生计划更快地做出决策。

    

    卫生保险公司有一个被称为先前授权（PA）的流程，这是一种卫生计划成本控制流程，要求医生和其他医疗专业人员在对患者执行特定程序之前必须事先获得卫生计划的批准，以便有资格获得支付覆盖。对卫生保险公司来说，批准医疗领域患者的PA请求是一项耗时且具有挑战性的任务。其中的一项关键挑战是验证请求是否符合某些标准，如年龄、性别等。在这项工作中，我们评估了GPT是否能验证大量关键因素，从而帮助卫生计划更快地做出决策。我们将其构建为一个问答任务，促使GPT从患者的电子健康记录中回答问题。我们尝试了不同的传统提示技术，同时还引入了我们自己的新颖提示技术。

    arXiv:2402.18419v1 Announce Type: cross  Abstract: Health insurance companies have a defined process called prior authorization (PA) which is a health plan cost-control process that requires doctors and other healthcare professionals to get clearance in advance from a health plan before performing a particular procedure on a patient in order to be eligible for payment coverage. For health insurance companies, approving PA requests for patients in the medical domain is a time-consuming and challenging task. One of those key challenges is validating if a request matches up to certain criteria such as age, gender, etc. In this work, we evaluate whether GPT can validate numerous key factors, in turn helping health plans reach a decision drastically faster. We frame it as a question answering task, prompting GPT to answer a question from patient electronic health record. We experiment with different conventional prompting techniques as well as introduce our own novel prompting technique. Mo
    
[^15]: 一个针对大型视觉语言模型图像推理和描述的认知评估基准

    A Cognitive Evaluation Benchmark of Image Reasoning and Description for Large Vision Language Models

    [https://arxiv.org/abs/2402.18409](https://arxiv.org/abs/2402.18409)

    提出了一个新颖的评估基准，用于评估大型视觉语言模型的认知能力，发现LVLMs与人类之间存在较大的认知能力差距。

    

    尽管大型视觉语言模型(LVLMs)近年来取得了成功，但它们很少受到全面的认知能力测试。受到人类认知测试中广泛使用的“偷饼干”任务的启发，我们提出了一个新颖的评估基准，利用具有丰富语义的图像评估LVLMs的高级认知能力。它定义了八种推理能力，并包括图像描述任务和视觉问答任务。我们对知名LVLMs进行的评估表明，在LVLMs和人类之间仍存在较大的认知能力差距。

    arXiv:2402.18409v1 Announce Type: new  Abstract: Large Vision Language Models (LVLMs), despite their recent success, are hardly comprehensively tested for their cognitive abilities. Inspired by the prevalent use of the "Cookie Theft" task in human cognition test, we propose a novel evaluation benchmark to evaluate high-level cognitive ability of LVLMs using images with rich semantics. It defines eight reasoning capabilities and consists of an image description task and a visual question answering task. Our evaluation on well-known LVLMs shows that there is still a large gap in cognitive ability between LVLMs and humans.
    
[^16]: 通过变形测试评估自动驾驶的决策最佳性

    Evaluating Decision Optimality of Autonomous Driving via Metamorphic Testing

    [https://arxiv.org/abs/2402.18393](https://arxiv.org/abs/2402.18393)

    本文着重于评估自动驾驶系统的决策质量，提出了检测非最佳决策场景的方法，通过新颖的变形关系暴露最佳决策违规。

    

    arXiv:2402.18393v1 公告类型：新摘要：自动驾驶系统（ADS）的测试在ADS开发中至关重要，目前主要关注的是安全性。然而，评估非安全关键性能，特别是ADS制定最佳决策并为自动车辆（AV）生成最佳路径的能力同样重要，以确保AV的智能性并降低风险。目前，鲜有工作致力于评估ADS的最佳决策性能，因为缺乏相应的预言和生成有非最佳决策的场景难度较大。本文侧重于评估ADS的决策质量，并提出首个用于检测非最佳决策场景（NoDSs）的方法，即ADS未计算AV的最佳路径的情况。首先，为解决预言问题，我们提出了一种旨在暴露最佳决策违规情况的新颖变形关系（MR）。这个MR确定了性能最佳决策的违规。

    arXiv:2402.18393v1 Announce Type: new  Abstract: Autonomous Driving System (ADS) testing is crucial in ADS development, with the current primary focus being on safety. However, the evaluation of non-safety-critical performance, particularly the ADS's ability to make optimal decisions and produce optimal paths for autonomous vehicles (AVs), is equally vital to ensure the intelligence and reduce risks of AVs. Currently, there is little work dedicated to assessing ADSs' optimal decision-making performance due to the lack of corresponding oracles and the difficulty in generating scenarios with non-optimal decisions. In this paper, we focus on evaluating the decision-making quality of an ADS and propose the first method for detecting non-optimal decision scenarios (NoDSs), where the ADS does not compute optimal paths for AVs. Firstly, to deal with the oracle problem, we propose a novel metamorphic relation (MR) aimed at exposing violations of optimal decisions. The MR identifies the propert
    
[^17]: 揭示健壮性在评估因果推断模型中的潜力

    Unveiling the Potential of Robustness in Evaluating Causal Inference Models

    [https://arxiv.org/abs/2402.18392](https://arxiv.org/abs/2402.18392)

    介绍了一种新颖的分布式健壮度量（DRM）方法，以解决选择理想因果推断模型中健壮估计器的挑战。

    

    越来越多对个性化决策制定的需求导致人们对估计条件平均处理效应（CATE）产生了兴趣。机器学习和因果推断的交叉领域已经产生了各种有效的CATE估计器。然而，在实践中使用这些估计器通常受制于缺乏反事实标签，因此使用传统的交叉验证等模型选择程序来选择理想的CATE估计器变得具有挑战性。现有的CATE估计器选择方法，如插值和伪结果度量，面临着两个固有挑战。首先，它们需要确定度量形式和拟合干扰参数或插件学习者的基础机器学习模型。其次，它们缺乏针对选择健壮估计器的特定重点。为解决这些挑战，本文引入了一种新颖的方法，分布式健壮度量（DRM）。

    arXiv:2402.18392v1 Announce Type: cross  Abstract: The growing demand for personalized decision-making has led to a surge of interest in estimating the Conditional Average Treatment Effect (CATE). The intersection of machine learning and causal inference has yielded various effective CATE estimators. However, deploying these estimators in practice is often hindered by the absence of counterfactual labels, making it challenging to select the desirable CATE estimator using conventional model selection procedures like cross-validation. Existing approaches for CATE estimator selection, such as plug-in and pseudo-outcome metrics, face two inherent challenges. Firstly, they are required to determine the metric form and the underlying machine learning models for fitting nuisance parameters or plug-in learners. Secondly, they lack a specific focus on selecting a robust estimator. To address these challenges, this paper introduces a novel approach, the Distributionally Robust Metric (DRM), for 
    
[^18]: 微网中神经形态事件驱动的语义通信

    Neuromorphic Event-Driven Semantic Communication in Microgrids

    [https://arxiv.org/abs/2402.18390](https://arxiv.org/abs/2402.18390)

    通过在微网中使用脉冲神经网络(SNNs)在每个节点上协同在线训练的神经形态学习，本论文提出了新的内在方式以优化系统的控制性能。

    

    先进通信、计算和人工智能之间的协同作用正在揭示微网协调运行和韧性的新方向。一方面，通过在多个位置进行分布式、注重隐私的处理，实现了源之间的协调，而另一方面，这也为对手创造了外生数据到达路径，可能导致通信层中的网络物理攻击等可靠性问题。这一长期存在的问题需要新的内在方式，在功率线之间交换信息，以优化系统的控制性能。超越现有的受效率和可扩展性问题限制的功率和数据共转移技术，本文提出了使用脉冲神经网络(SNNs)在每个节点上协同在线训练的神经形态学习，来植入交流特性。

    arXiv:2402.18390v1 Announce Type: cross  Abstract: Synergies between advanced communications, computing and artificial intelligence are unraveling new directions of coordinated operation and resiliency in microgrids. On one hand, coordination among sources is facilitated by distributed, privacy-minded processing at multiple locations, whereas on the other hand, it also creates exogenous data arrival paths for adversaries that can lead to cyber-physical attacks amongst other reliability issues in the communication layer. This long-standing problem necessitates new intrinsic ways of exchanging information between converters through power lines to optimize the system's control performance. Going beyond the existing power and data co-transfer technologies that are limited by efficiency and scalability concerns, this paper proposes neuromorphic learning to implant communicative features using spiking neural networks (SNNs) at each node, which is trained collaboratively in an online manner s
    
[^19]: 大型语言模型作为进化策略

    Large Language Models As Evolution Strategies

    [https://arxiv.org/abs/2402.18381](https://arxiv.org/abs/2402.18381)

    探索大型语言模型是否能够在处理黑盒优化任务中实现进化优化算法，并引入了一种新的提示策略来提高均值统计，从而实现黑盒重组操作。

    

    大型Transformer模型能够实现各种所谓的上下文学习算法，包括梯度下降、分类、序列完成、转换和改进。在这项工作中，我们探讨了从未明确遇到过黑盒优化任务的大型语言模型（LLMs）是否基本上能够实现进化优化算法。我们介绍了一种新的提示策略，通过对离散化的种群成员进行从少到多的排序，并询问LLM提出对均值统计的改进，执行一种黑盒重组操作。实证上，我们发现我们的设置允许用户获得基于LLM的进化策略，我们称之为`EvoLL`。

    arXiv:2402.18381v1 Announce Type: new  Abstract: Large Transformer models are capable of implementing a plethora of so-called in-context learning algorithms. These include gradient descent, classification, sequence completion, transformation, and improvement. In this work, we investigate whether large language models (LLMs), which never explicitly encountered the task of black-box optimization, are in principle capable of implementing evolutionary optimization algorithms. While previous works have solely focused on language-based task specification, we move forward and focus on the zero-shot application of LLMs to black-box optimization. We introduce a novel prompting strategy, consisting of least-to-most sorting of discretized population members and querying the LLM to propose an improvement to the mean statistic, i.e. perform a type of black-box recombination operation. Empirically, we find that our setup allows the user to obtain an LLM-based evolution strategy, which we call `EvoLL
    
[^20]: Tokenization超越了压缩

    Tokenization Is More Than Compression

    [https://arxiv.org/abs/2402.18376](https://arxiv.org/abs/2402.18376)

    通过引入新的分词器PathPiece，研究者发现少量标记并不能导致更好的下游性能，这一结果对于 Tokenization 的有效性理解提出了质疑。

    

    Tokenization是自然语言处理（NLP）任务中的基础步骤，它连接了原始文本和语言模型。现有的Tokenization方法，如字节对编码（Byte-Pair Encoding，BPE），源自数据压缩领域，并有人认为BPE的有效性源于其将文本压缩为相对较少的标记的能力。我们通过引入PathPiece来测试“更少的标记是否会导致更好的下游性能”这一假设，PathPiece是一种新的分词器，根据给定词汇将文档文本划分为最少数量的标记。通过广泛实验，我们发现这一假设并非成立，对有效Tokenization原因的理解产生了疑问。为了检查哪些其他因素起到作用，我们评估了Tokenization的所有三个阶段（预分词、词汇构造和分割）的设计决策，提供了关于设计的新见解。

    arXiv:2402.18376v1 Announce Type: cross  Abstract: Tokenization is a foundational step in Natural Language Processing (NLP) tasks, bridging raw text and language models. Existing tokenization approaches like Byte-Pair Encoding (BPE) originate from the field of data compression, and it has been suggested that the effectiveness of BPE stems from its ability to condense text into a relatively small number of tokens. We test the hypothesis that fewer tokens lead to better downstream performance by introducing PathPiece, a new tokenizer that segments a document's text into the minimum number of tokens for a given vocabulary. Through extensive experimentation we find this hypothesis not to be the case, casting doubt on the understanding of the reasons for effective tokenization. To examine which other factors play a role, we evaluate design decisions across all three phases of tokenization: pre-tokenization, vocabulary construction, and segmentation, offering new insights into the design of 
    
[^21]: FedUV: 异构联邦学习的均匀性和方差

    FedUV: Uniformity and Variance for Heterogeneous Federated Learning

    [https://arxiv.org/abs/2402.18372](https://arxiv.org/abs/2402.18372)

    提出了FedUV框架，通过引入两种正则化项，促使局部模型在异构分布数据中表现得更均匀和稳定

    

    联邦学习是一种训练神经网络的有希望的框架，能够处理广泛分布的数据。然而，性能很大程度上会随着异构分布的数据而下降。最近的研究表明，这是由于网络的最终层最容易出现局部偏差，一些研究发现通过将最终层冻结为正交分类器可以取得成功。我们通过对权重应用奇异值分解来研究分类器的训练动态，这是受到冻结权重导致奇异值恒定的观察启发的。我们发现在IID和非IID设置下训练时存在差异。基于这一发现，我们引入两种局部训练的正则化项，以持续模拟IID设置：（1）分类器的维度概率分布方差和（2）编码器表示的超球均匀性。这些正则化促使局部模型表现得好像在IID设置中一样。

    arXiv:2402.18372v1 Announce Type: cross  Abstract: Federated learning is a promising framework to train neural networks with widely distributed data. However, performance degrades heavily with heterogeneously distributed data. Recent work has shown this is due to the final layer of the network being most prone to local bias, some finding success freezing the final layer as an orthogonal classifier. We investigate the training dynamics of the classifier by applying SVD to the weights motivated by the observation that freezing weights results in constant singular values. We find that there are differences when training in IID and non-IID settings. Based on this finding, we introduce two regularization terms for local training to continuously emulate IID settings: (1) variance in the dimension-wise probability distribution of the classifier and (2) hyperspherical uniformity of representations of the encoder. These regularizations promote local models to act as if it were in an IID setting
    
[^22]: 使用注意力引导去噪扩散异常检测模型进行客观且可解释的乳腺整容评估

    Objective and Interpretable Breast Cosmesis Evaluation with Attention Guided Denoising Diffusion Anomaly Detection Model

    [https://arxiv.org/abs/2402.18362](https://arxiv.org/abs/2402.18362)

    本研究提出一种新的自动化方法AG-DDAD，旨在通过注意力机制和扩散模型评估乳腺整容，从而克服传统监督学习和现有异常检测模型的局限性。

    

    随着乳腺癌治疗领域的不断发展，术后整容效果的评估因其对患者生活质量的重大影响而日益重要。然而，由于专家标注的固有主观性，评估乳腺整容存在挑战。在本研究中，我们提出了一种新颖的自动化方法，Attention-Guided Denoising Diffusion Anomaly Detection (AG-DDAD)，旨在评估手术后的乳腺整容，并解决传统监督学习和现有异常检测模型的局限性。我们的方法利用无标签蒸馏（DINO）自监督视觉Transformer（ViT）的注意力机制，结合扩散模型，实现高质量图像重建和辨别性区域精确变换。通过主要使用无标签数据训练扩散模型，

    arXiv:2402.18362v1 Announce Type: cross  Abstract: As advancements in the field of breast cancer treatment continue to progress, the assessment of post-surgical cosmetic outcomes has gained increasing significance due to its substantial impact on patients' quality of life. However, evaluating breast cosmesis presents challenges due to the inherently subjective nature of expert labeling. In this study, we present a novel automated approach, Attention-Guided Denoising Diffusion Anomaly Detection (AG-DDAD), designed to assess breast cosmesis following surgery, addressing the limitations of conventional supervised learning and existing anomaly detection models. Our approach leverages the attention mechanism of the distillation with no label (DINO) self-supervised Vision Transformer (ViT) in combination with a diffusion model to achieve high-quality image reconstruction and precise transformation of discriminative regions. By training the diffusion model on unlabeled data predominantly with
    
[^23]: 基于相似性的类比比例

    Similarity-based analogical proportions

    [https://arxiv.org/abs/2402.18360](https://arxiv.org/abs/2402.18360)

    通过将类比比例规定为相似性，建立了从相似性到类比比例的桥梁，使得将来的相似性结果可以直接应用于类比比例。

    

    作者最近在通用代数的一般设置内引入了类比比例和相似性的抽象代数框架。本文的目的是通过用相似性来规定类比比例，从而建立从相似性到类比比例的桥梁。这种基于相似性的方法的好处在于，比例和相似性的联系被构建到框架中，因此显而易见，这一点很吸引人，因为比例和相似性都处于类比的中心；此外，对相似性的未来结果可以直接应用于类比比例。

    arXiv:2402.18360v1 Announce Type: cross  Abstract: The author has recently introduced abstract algebraic frameworks of analogical proportions and similarity within the general setting of universal algebra. The purpose of this paper is to build a bridge from similarity to analogical proportions by formulating the latter in terms of the former. The benefit of this similarity-based approach is that the connection between proportions and similarity is built into the framework and therefore evident which is appealing since proportions and similarity are both at the center of analogy; moreover, future results on similarity can directly be applied to analogical proportions.
    
[^24]: 算法何时该辞职？

    When Should Algorithms Resign?

    [https://arxiv.org/abs/2402.18326](https://arxiv.org/abs/2402.18326)

    论文讨论了算法辞职作为管理组织内使用AI系统的战略方法，提出通过在AI系统中嵌入治理机制，有意识和明智地在某些情况下脱离AI辅助，以指导何时以及如何使用或避免这些系统，从而获得多方面的利益。

    

    这篇论文讨论了算法辞职，这是一种管理组织内使用AI系统的战略方法。算法辞职涉及在某些情况下有意识和明智地脱离AI辅助，通过直接将治理机制嵌入到AI系统中。我们的提议不仅仅是关于不使用AI，还包括指导何时以及如何使用或避免这些系统。我们讨论了算法辞职的多方面利益，涵盖经济效率、声誉增益和法律合规性。此外，我们概述了通过积极和消极助推、利益相关者激励对齐以及审慎考虑AI参与程度等各种方法来实现辞职。通过诸如有选择地阻止访问AI输出或对系统性能明确声明免责等技术手段，算法辞职不仅能降低与之相关的风险。

    arXiv:2402.18326v1 Announce Type: cross  Abstract: This paper discusses algorithmic resignation, a strategic approach for managing the use of AI systems within organizations. Algorithmic resignation involves the deliberate and informed disengagement from AI assistance in certain scenarios, by embedding governance mechanisms directly into AI systems. Our proposal is not merely about disuse of AI but includes guiding when and how these systems should be used or avoided. We discuss the multifaceted benefits of algorithmic resignation, spanning economic efficiency, reputational gains, and legal compliance. Further, we outline the operationalization of resignation through various methods such as positive and negative nudges, stakeholder incentive alignment, and careful consideration of the level of AI engagement. Using techniques like barring access to AI outputs selectively or providing explicit disclaimers on system performance, algorithmic resignation not only mitigates risks associated 
    
[^25]: 基于位置引导的鱼眼图像头部姿态估计

    Location-guided Head Pose Estimation for Fisheye Image

    [https://arxiv.org/abs/2402.18320](https://arxiv.org/abs/2402.18320)

    通过利用头部位置信息，本文提出了一种使用鱼眼图像进行头部姿态估计的新方法，采用端到端卷积神经网络，在头部姿态和头部位置的多任务学习下，直接从鱼眼图像中估计头部姿态。

    

    拥有鱼眼或超广角镜头的相机覆盖的视场广阔，无法通过透视投影来建模。图像边缘处严重的鱼眼镜头畸变导致了在非畸变图像上训练的现有头部姿态估计模型性能下降。本文提出了一种新的头部姿态估计方法，利用图像中头部位置的知识来减少鱼眼畸变的负面影响。我们开发了一个端到端的卷积神经网络，通过头部姿态和头部位置的多任务学习来估计头部姿态。我们提出的网络可以直接从鱼眼图像中估计头部姿态，无需校正或标定操作。我们还为BIWI、300W-LP和AFLW2000这三个热门头部姿态估计数据集创建了鱼眼畸变版本进行实验。

    arXiv:2402.18320v1 Announce Type: cross  Abstract: Camera with a fisheye or ultra-wide lens covers a wide field of view that cannot be modeled by the perspective projection. Serious fisheye \textcolor{blue}{lens} distortion in the peripheral region of the image leads to degraded performance of the \textcolor{blue}{existing} head pose estimation models trained on undistorted images. This paper presents a new approach for head pose estimation that uses the knowledge of head location in the image to reduce the negative effect of fisheye distortion. We develop an end-to-end convolutional neural network to estimate the head pose with the multi-task learning of head pose and head location. Our proposed network estimates the head pose directly from the fisheye image without the operation of rectification or calibration. We also created \textcolor{blue}{a} fisheye-\textcolor{blue}{distorted} version of the three popular head pose estimation datasets, BIWI, 300W-LP, and AFLW2000 for our experim
    
[^26]: 增强道路安全：基于LiDAR的树木间隙分析

    Enhancing Roadway Safety: LiDAR-based Tree Clearance Analysis

    [https://arxiv.org/abs/2402.18309](https://arxiv.org/abs/2402.18309)

    本文提出了一种新的点云算法，利用LiDAR技术自动检测树木生长在街道上需要修剪的部分，这有助于增强道路安全。

    

    在致力于更安全道路的努力中，确保道路上方有足够的垂直间隙非常重要。经常情况下，树木或其他植被会生长在道路上方，遮挡了交通标志和灯光的视线，并对交通参与者构成危险。利用简单的图像准确估计这个空间由于缺乏深度信息而变得具有挑战性。这就是LiDAR技术发挥作用的地方，这是一种激光扫描传感器，可以显示三维视角。迄今为止，街道水平上的LiDAR点云主要被用于自动驾驶领域的应用。然而，这些扫描还打开了城市管理领域的可能性。在本文中，我们提出了一种新的点云算法，可以自动检测那些生长在街道上方需要修剪的树木部分。我们的系统利用语义分割来过滤相关点，然后进行下游处理步骤来创建...

    arXiv:2402.18309v1 Announce Type: cross  Abstract: In the efforts for safer roads, ensuring adequate vertical clearance above roadways is of great importance. Frequently, trees or other vegetation is growing above the roads, blocking the sight of traffic signs and lights and posing danger to traffic participants. Accurately estimating this space from simple images proves challenging due to a lack of depth information. This is where LiDAR technology comes into play, a laser scanning sensor that reveals a three-dimensional perspective. Thus far, LiDAR point clouds at the street level have mainly been used for applications in the field of autonomous driving. These scans, however, also open up possibilities in urban management. In this paper, we present a new point cloud algorithm that can automatically detect those parts of the trees that grow over the street and need to be trimmed. Our system uses semantic segmentation to filter relevant points and downstream processing steps to create t
    
[^27]: FSL模型可以因为其优越性得分更高

    FSL Model can Score Higher as It Is

    [https://arxiv.org/abs/2402.18292](https://arxiv.org/abs/2402.18292)

    为了增加测试期间正确预测的机会，研究旨在通过图像到图像的转换纠正FSL模型的测试输入，生成被测试类别的新样本。

    

    在日常生活中，为了增加被正确识别的机会，我们倾向于面对面地直视面部识别机，而不是侧着面对。少样本学习（FSL）分类本身就具有挑战性，因为模型必须识别属于训练时未见的类别的图像。因此，在测试期间对扭曲和非典型的查询或支持图像会让模型更难正确预测。在我们的研究中，为了增加测试期间正确预测的机会，我们旨在通过图像到图像的转换纠正训练过的FSL模型的测试输入，生成被测试类别的新样本。FSL模型通常是在具有足够样本的类别上进行训练，然后在具有少样本样本的类别上进行测试。我们提出的方法首先捕捉测试图像的风格或形状，然后识别一个适当的训

    arXiv:2402.18292v1 Announce Type: cross  Abstract: In daily life, we tend to present the front of our faces by staring squarely at a facial recognition machine, instead of facing it sideways, in order to increase the chance of being correctly recognised. Few-shot-learning (FSL) classification is challenging in itself because a model has to identify images that belong to classes previously unseen during training. Therefore, a warped and non-typical query or support image during testing can make it even more challenging for a model to predict correctly. In our work, to increase the chance of correct prediction during testing, we aim to rectify the test input of a trained FSL model by generating new samples of the tested classes through image-to-image translation. An FSL model is usually trained on classes with sufficient samples, and then tested on classes with few-shot samples. Our proposed method first captures the style or shape of the test image, and then identifies a suitable traine
    
[^28]: 电子显微镜中的自监督学习：迈向高级图像分析基础模型

    Self-Supervised Learning in Electron Microscopy: Towards a Foundation Model for Advanced Image Analysis

    [https://arxiv.org/abs/2402.18286](https://arxiv.org/abs/2402.18286)

    本文探讨了在电子显微镜中进行自监督学习的潜力，展示自监督预训练如何促进有效的微调，同时指出较低复杂度的模型在微调过程中始终优于更复杂的随机初始化模型。

    

    在这项工作中，我们探讨了从无标签的电子显微镜数据集中进行自监督学习的潜力，迈出了构建该领域基础模型的一步。我们展示了自监督预训练如何促进有效的微调，以应用于一系列下游任务，包括语义分割、去噪、噪声与背景去除以及超分辨率。通过实验不同模型复杂度和感受野大小的变化，我们发现一个显著的现象，即微调过的较低复杂度模型始终胜过具有随机权重初始化的更复杂模型。我们展示了自监督预训练在电子显微镜背景下在各种下游任务中的多才多艺，使得快速收敛和更好的性能成为可能。我们得出结论，自监督预训练是一种强大的催化剂，特别在有限的注释数据可用时和 ef

    arXiv:2402.18286v1 Announce Type: cross  Abstract: In this work, we explore the potential of self-supervised learning from unlabeled electron microscopy datasets, taking a step toward building a foundation model in this field. We show how self-supervised pretraining facilitates efficient fine-tuning for a spectrum of downstream tasks, including semantic segmentation, denoising, noise & background removal, and super-resolution. Experimentation with varying model complexities and receptive field sizes reveals the remarkable phenomenon that fine-tuned models of lower complexity consistently outperform more complex models with random weight initialization. We demonstrate the versatility of self-supervised pretraining across various downstream tasks in the context of electron microscopy, allowing faster convergence and better performance. We conclude that self-supervised pretraining serves as a powerful catalyst, being especially advantageous when limited annotated data are available and ef
    
[^29]: PiShield：一种适用于以需求为基础学习的NeSy框架

    PiShield: A NeSy Framework for Learning with Requirements

    [https://arxiv.org/abs/2402.18285](https://arxiv.org/abs/2402.18285)

    PiShield是第一个允许将需求集成到神经网络拓扑结构中的框架，无论输入如何都能确保满足这些需求，并可根据从业者需求在推断和/或训练时集成需求。

    

    深度学习模型在各种应用领域展现出了其优势，然而，它们往往难以满足其输出的安全需求。本文介绍了PiShield，这是第一个允许将需求集成到神经网络拓扑结构中的框架。PiShield确保满足这些需求，无论输入如何。此外，它允许根据从业者的需求在推断和/或训练时集成需求。鉴于深度学习的广泛应用，迫切需要允许在各个领域集成需求的框架。这里，我们探讨了三个应用场景：功能基因组学、自动驾驶和表格数据生成。

    arXiv:2402.18285v1 Announce Type: cross  Abstract: Deep learning models have shown their strengths in various application domains, however, they often struggle to meet safety requirements for their outputs. In this paper, we introduce PiShield, the first framework ever allowing for the integration of the requirements into the neural networks' topology. PiShield guarantees compliance with these requirements, regardless of input. Additionally, it allows for integrating requirements both at inference and/or training time, depending on the practitioners' needs. Given the widespread application of deep learning, there is a growing need for frameworks allowing for the integration of the requirements across various domains. Here, we explore three application scenarios: functional genomics, autonomous driving, and tabular data generation.
    
[^30]: 众包是否让您破产了？使用近端策略优化对预训练语言模型进行成本效益微调

    Is Crowdsourcing Breaking Your Bank? Cost-Effective Fine-Tuning of Pre-trained Language Models with Proximal Policy Optimization

    [https://arxiv.org/abs/2402.18284](https://arxiv.org/abs/2402.18284)

    提出了一种自监督文本排序方法，利用近端策略优化对语言模型进行微调，消除了对人工注释员的需求，实验结果表明该方法训练的模型在各项得分方面明显优于基线

    

    ChatGPT的广泛使用凸显了从人类反馈中进行强化学习的潜力。然而，其训练流程依赖于人工排序，这是一个资源密集型的过程。为了降低劳动成本，我们提出了一种自监督文本排序方法，用于应用近端策略优化来对语言模型进行微调，同时消除了对人工注释员的需求。我们的方法从概率抽样开始，鼓励语言模型为每个输入生成多样化的响应。然后，我们使用TextRank和ISODATA算法，基于语义对这些响应进行排序和聚类。随后，我们构建了一个奖励模型来学习排名并优化我们的生成策略。我们在三个任务上使用两个语言模型进行的实验结果表明，我们的方法训练的模型在BLEU、GLEU和METEOR得分方面明显优于基线。此外，我们的手动评估显示

    arXiv:2402.18284v1 Announce Type: cross  Abstract: Wide usage of ChatGPT has highlighted the potential of reinforcement learning from human feedback. However, its training pipeline relies on manual ranking, a resource-intensive process. To reduce labor costs, we propose a self-supervised text ranking approach for applying Proximal-Policy-Optimization to fine-tune language models while eliminating the need for human annotators. Our method begins with probabilistic sampling to encourage a language model to generate diverse responses for each input. We then employ TextRank and ISODATA algorithms to rank and cluster these responses based on their semantics. Subsequently, we construct a reward model to learn the rank and optimize our generative policy. Our experimental results, conducted using two language models on three tasks, demonstrate that the models trained by our method considerably outperform baselines regarding BLEU, GLEU, and METEOR scores. Furthermore, our manual evaluation show
    
[^31]: 重新思考LLM推理的界限：多智能体讨论是关键吗？

    Rethinking the Bounds of LLM Reasoning: Are Multi-Agent Discussions the Key?

    [https://arxiv.org/abs/2402.18272](https://arxiv.org/abs/2402.18272)

    多智能体讨论提升了LLM的推理能力，但在有演示的情况下，单智能体LLM通过强提示几乎能达到与最佳讨论方法相同的性能。

    

    LLM讨论领域的最新进展表明，多智能体讨论提升了LLM的推理能力。在这项工作中，我们通过系统实验对这一说法进行重新评估，我们提出了一个新颖的小组讨论框架，丰富了讨论机制集合。有趣的是，我们的结果显示，一个带有强提示的单智能体LLM在广泛的推理任务和基本LLM中几乎可以达到与最佳现有讨论方法相同的性能。我们观察到，多智能体讨论仅在提示中没有演示时才优于单个智能体。进一步研究揭示了LLM在讨论过程中的常见交互机制。

    arXiv:2402.18272v1 Announce Type: cross  Abstract: Recent progress in LLMs discussion suggests that multi-agent discussion improves the reasoning abilities of LLMs. In this work, we reevaluate this claim through systematic experiments, where we propose a novel group discussion framework to enrich the set of discussion mechanisms. Interestingly, our results show that a single-agent LLM with strong prompts can achieve almost the same performance as the best existing discussion approach on a wide range of reasoning tasks and backbone LLMs. We observe that the multi-agent discussion performs better than a single agent only when there is no demonstration in the prompt. Further study reveals the common interaction mechanisms of LLMs during the discussion.
    
[^32]: 关于神经问答生成的调查：方法、应用和前景

    A Survey on Neural Question Generation: Methods, Applications, and Prospects

    [https://arxiv.org/abs/2402.18267](https://arxiv.org/abs/2402.18267)

    这项调查系统研究了神经问答生成（NQG）领域的进展，包括了背景概述、不同类别的方法、以及未来展望

    

    在这项调查中，我们对神经问答生成（NQG）领域的进展进行了详细检查，这一领域利用神经网络技术从各种来源，如知识库、文本和图像中生成相关问题。调查从NQG背景概述开始，包括任务的问题制定、流行的基准数据集、已建立的评估指标和显著应用。然后，系统地将NQG方法分为三个主要类别：结构化NQG，利用有组织的数据源，非结构化NQG，专注于更松散结构的输入，如文本或视觉内容，以及混合NQG，利用多样的输入模式。这一分类后是对为每个类别量身定制的不同神经网络模型的深入分析，讨论它们固有的优势和潜在局限性。调查以展望未来结束。

    arXiv:2402.18267v1 Announce Type: cross  Abstract: In this survey, we present a detailed examination of the advancements in Neural Question Generation (NQG), a field leveraging neural network techniques to generate relevant questions from diverse inputs like knowledge bases, texts, and images. The survey begins with an overview of NQG's background, encompassing the task's problem formulation, prevalent benchmark datasets, established evaluation metrics, and notable applications. It then methodically classifies NQG approaches into three predominant categories: structured NQG, which utilizes organized data sources, unstructured NQG, focusing on more loosely structured inputs like texts or visual content, and hybrid NQG, drawing on diverse input modalities. This classification is followed by an in-depth analysis of the distinct neural network models tailored for each category, discussing their inherent strengths and potential limitations. The survey culminates with a forward-looking persp
    
[^33]: 通过心智模型实现大型语言模型的通用提示方法

    Towards Generalist Prompting for Large Language Models by Mental Models

    [https://arxiv.org/abs/2402.18252](https://arxiv.org/abs/2402.18252)

    通过提出通用提示概念和创新的MeMo（心智模型）方法，实现大型语言模型在广泛任务范围内实现最佳性能，消除了手动选择和定制提示的需求。

    

    大型语言模型（LLMs）在许多任务上展示出令人印象深刻的性能。然而，为了达到最佳性能，仍然需要特别设计的提示方法。这些方法要么依赖于需要一定领域知识的特定任务少量示例，要么被设计为简单，但只对少数类型任务表现良好。在这项工作中，我们尝试引入通用提示的概念，它的设计原则是在广泛任务范围内实现最佳或接近最佳的性能，同时消除了需要针对特定问题手动选择和定制提示的需求。此外，我们提出了MeMo（心智模型），这是一种简单设计的创新提示方法，能有效地实现通用提示的标准。MeMo将各种提示方法的核心精髓提炼为单个心智模型，并允许LLM自主选择。

    arXiv:2402.18252v1 Announce Type: cross  Abstract: Large language models (LLMs) have demonstrated impressive performance on many tasks. However, to achieve optimal performance, specially designed prompting methods are still needed. These methods either rely on task-specific few-shot examples that require a certain level of domain knowledge, or are designed to be simple but only perform well on a few types of tasks. In this work, we attempt to introduce the concept of generalist prompting, which operates on the design principle of achieving optimal or near-optimal performance on a wide range of tasks while eliminating the need for manual selection and customization of prompts tailored to specific problems. Furthermore, we propose MeMo (Mental Models), an innovative prompting method that is simple-designed yet effectively fulfills the criteria of generalist prompting. MeMo distills the cores of various prompting methods into individual mental models and allows LLMs to autonomously select
    
[^34]: CogBench: 一个大型语言模型步入心理实验室

    CogBench: a large language model walks into a psychology lab

    [https://arxiv.org/abs/2402.18225](https://arxiv.org/abs/2402.18225)

    CogBench提出了一个从七个认知心理学实验中衍生出十个行为指标的基准测试，为评估大型语言模型的行为提供了工具，研究发现模型大小和从人类反馈中学习的强化学习对性能改善和与人类行为一致具有重要作用。

    

    大型语言模型（LLMs）显著推动了人工智能领域的发展。然而，对它们进行全面评估仍然具有挑战性。我们认为，这部分是由于大多数基准测试中对性能指标的主要关注。本文介绍了CogBench，这是一个基准测试，包括从七个认知心理学实验中衍生的十个行为指标。这种新颖方法为表型化LLMs的行为提供了一个工具包。我们将CogBench应用于35个LLMs，得到丰富多样的数据集。我们使用统计多层建模技术分析这些数据，考虑到特定LLMs的微调版本之间的嵌套依赖关系。我们的研究突出了模型大小和从人类反馈中学习的强化学习在改善性能并与人类行为保持一致方面的关键作用。有趣的是，我们发现开源模型比专有模型更少风险，并且精细调

    arXiv:2402.18225v1 Announce Type: cross  Abstract: Large language models (LLMs) have significantly advanced the field of artificial intelligence. Yet, evaluating them comprehensively remains challenging. We argue that this is partly due to the predominant focus on performance metrics in most benchmarks. This paper introduces CogBench, a benchmark that includes ten behavioral metrics derived from seven cognitive psychology experiments. This novel approach offers a toolkit for phenotyping LLMs' behavior. We apply CogBench to 35 LLMs, yielding a rich and diverse dataset. We analyze this data using statistical multilevel modeling techniques, accounting for the nested dependencies among fine-tuned versions of specific LLMs. Our study highlights the crucial role of model size and reinforcement learning from human feedback (RLHF) in improving performance and aligning with human behavior. Interestingly, we find that open-source models are less risk-prone than proprietary models and that fine-t
    
[^35]: HearHere: 通过基于人工智能的网络系统缓解新闻消费中的“回声室”现象

    HearHere: Mitigating Echo Chambers in News Consumption through an AI-based Web System

    [https://arxiv.org/abs/2402.18222](https://arxiv.org/abs/2402.18222)

    HearHere是一个基于人工智能的网络系统，旨在帮助用户从不同视角融合信息和观点，以减轻新闻消费中“回声室”现象。

    

    目前正在大力努力减轻“回声室”所带来的负面影响，包括更容易受到虚假新闻的影响以及对接受科学证据的抗拒。本文提出了HearHere，这是一个基于人工智能的网络系统，旨在帮助用户从不同视角融合信息和观点。HearHere通过两种可视化方式促进了新闻信息消费的关键流程。

    arXiv:2402.18222v1 Announce Type: cross  Abstract: Considerable efforts are currently underway to mitigate the negative impacts of echo chambers, such as increased susceptibility to fake news and resistance towards accepting scientific evidence. Prior research has presented the development of computer systems that support the consumption of news information from diverse political perspectives to mitigate the echo chamber effect. However, existing studies still lack the ability to effectively support the key processes of news information consumption and quantitatively identify a political stance towards the information. In this paper, we present HearHere, an AI-based web system designed to help users accommodate information and opinions from diverse perspectives. HearHere facilitates the key processes of news information consumption through two visualizations. Visualization 1 provides political news with quantitative political stance information, derived from our graph-based political c
    
[^36]: Lemur: 使用熵抽样和思维链合并进行日志解析

    Lemur: Log Parsing with Entropy Sampling and Chain-of-Thought Merging

    [https://arxiv.org/abs/2402.18205](https://arxiv.org/abs/2402.18205)

    Lemur提出了一种先进的日志解析框架，采用熵抽样和思维链合并，解决了日志解析中存在的人工规则依赖和语义信息忽略等问题。

    

    大型软件系统产生的日志对监视系统行为至关重要。先进的日志分析有助于检测、报警和诊断系统故障。日志解析是日志分析自动化的关键阶段，它涉及将原始日志消息转换为结构化模板。现有的日志解析器由于依赖于人工制定的规则而无法识别正确的模板。此外，这些方法侧重于统计特征，而忽略了日志消息中的语义信息。为了解决这些挑战，我们提出了一种先进的日志解析框架，采用熵抽样和思维链合并（Lemur）。具体而言，为了摆脱繁琐的手动规则，我们提出了一种受信息熵启发的新型抽样方法，能够有效地对典型日志进行聚类。此外，为了增强日志模板的合并，我们设计了一种思维链方法。

    arXiv:2402.18205v1 Announce Type: cross  Abstract: Logs produced by extensive software systems are integral to monitoring system behaviors. Advanced log analysis facilitates the detection, alerting, and diagnosis of system faults. Log parsing, which entails transforming raw log messages into structured templates, constitutes a critical phase in the automation of log analytics. Existing log parsers fail to identify the correct templates due to reliance on human-made rules. Besides, These methods focus on statistical features while ignoring semantic information in log messages. To address these challenges, we introduce a cutting-edge \textbf{L}og parsing framework with \textbf{E}ntropy sampling and Chain-of-Thought \textbf{M}erging (Lemur). Specifically, to discard the tedious manual rules. We propose a novel sampling method inspired by information entropy, which efficiently clusters typical logs. Furthermore, to enhance the merging of log templates, we design a chain-of-thought method f
    
[^37]: 基于自动编码器的通用表示学习用于客户嵌入

    Autoencoder-based General Purpose Representation Learning for Customer Embedding

    [https://arxiv.org/abs/2402.18164](https://arxiv.org/abs/2402.18164)

    设计了基于自动编码器的框架用于构建通用嵌入，展示简单模型在嵌入复杂表格数据时优于复杂模型，并将框架应用于生成表示AWS客户的嵌入，显著节省开发时间并观察到下游模型的改进。

    

    最近几年，利用数据的领域特定基础结构及其生成因素进行表示学习，在各种用例无关应用中取得成功。然而，表格数据的多样性和复杂性使得通过多维向量在潜在空间中表示这些结构具有挑战性。我们设计了一个基于自动编码器的框架用于构建通用嵌入，评估了不同自动编码器架构的性能，并展示了简单模型在嵌入高度复杂表格数据时优于复杂模型。我们将我们的框架应用于生成插拔式、丰富和匿名化的表示AWS客户的嵌入，可用于任何模型，节省开发时间高达45％，并观察到下游模型的显著改进。此外，我们提出了一种对于多层收缩自动编码器重构损失计算的重要改进。

    arXiv:2402.18164v1 Announce Type: cross  Abstract: In recent years, exploiting the domain-specific underlying structure of data and its generative factors for representation learning has shown success in various use-case agnostic applications. However, the diversity and complexity of tabular data have made it challenging to represent these structures in a latent space through multi-dimensional vectors. We design an autoencoder-based framework for building general purpose embeddings, we assess the performance of different autoencoder architectures, and show simpler models outperform complex ones in embedding highly complex tabular data. We apply our framework to produce plug-and-play, rich, and anonymized embeddings representing AWS customers for usage in any model, saving up to 45% of development time, and observe significant improvements in downstream models. Moreover, we propose a significant improvement to the calculation of reconstruction loss for multi-layer contractive autoencode
    
[^38]: 评估量化大型语言模型

    Evaluating Quantized Large Language Models

    [https://arxiv.org/abs/2402.18158](https://arxiv.org/abs/2402.18158)

    该论文通过全面评估后训练量化对权重、激活和KV缓存的影响，以指导选择量化方法，并对11种模型系列进行了评估，覆盖了多种任务类型。

    

    后训练量化（PTQ）已经成为减少大型语言模型（LLMs）成本的一种有前景的技术，具体地，PTQ可以有效地减轻LLMs中的内存消耗并降低计算开销。为了满足各种场景下高效率和性能的要求，对量化LLMs进行全面评估是必要的，以指导量化方法的选择。本文通过评估PTQ对11个模型系列（包括OPT、LLaMA2、Falcon、Bloomz、Mistral、ChatGLM、Vicuna、LongChat、StableLM、Gemma和Mamba）的权重、激活和KV缓存的影响，范围从125M到180B，全面评估了这些因素。评估涵盖了五种类型的任务：基础NLP、突然出现的能力、可靠性、对话和长上下文任务。此外，我们还评估了最先进的量化方法，以展示它们的应用。

    arXiv:2402.18158v1 Announce Type: cross  Abstract: Post-training quantization (PTQ) has emerged as a promising technique to reduce the cost of large language models (LLMs). Specifically, PTQ can effectively mitigate memory consumption and reduce computational overhead in LLMs. To meet the requirements of both high efficiency and performance across diverse scenarios, a comprehensive evaluation of quantized LLMs is essential to guide the selection of quantization methods. This paper presents a thorough evaluation of these factors by evaluating the effect of PTQ on Weight, Activation, and KV Cache on 11 model families, including OPT, LLaMA2, Falcon, Bloomz, Mistral, ChatGLM, Vicuna, LongChat, StableLM, Gemma, and Mamba, with parameters ranging from 125M to 180B. The evaluation encompasses five types of tasks: basic NLP, emergent ability, trustworthiness, dialogue, and long-context tasks. Moreover, we also evaluate the state-of-the-art (SOTA) quantization methods to demonstrate their appli
    
[^39]: 从总结到行动：利用开放世界API增强复杂任务的大型语言模型

    From Summary to Action: Enhancing Large Language Models for Complex Tasks with Open World APIs

    [https://arxiv.org/abs/2402.18157](https://arxiv.org/abs/2402.18157)

    本研究引入了一个新颖的工具调用管道，旨在控制大规模现实世界API，从而增强大型语言模型在复杂任务中的应用能力。

    

    人类与动物之间的区别在于人类具有使用和创造工具的独特能力。工具使人类能够克服生理限制，促进了宏伟文明的创造。类似地，将像大型语言模型（LLMs）这样的基础模型赋予学习外部工具使用能力可能是实现人工智能的关键一步。本领域先前的研究主要追求两种不同的方法来增强LLMs的工具调用能力。第一种方法强调构建用于模型微调的相关数据集。相反，第二种方法旨在通过上下文学习策略充分利用LLMs固有的推理能力。在这项工作中，我们介绍了一个旨在控制大型现实世界API的创新工具调用管道。这一管道反映了人类解决任务的过程，解决了c

    arXiv:2402.18157v1 Announce Type: new  Abstract: The distinction between humans and animals lies in the unique ability of humans to use and create tools. Tools empower humans to overcome physiological limitations, fostering the creation of magnificent civilizations. Similarly, enabling foundational models like Large Language Models (LLMs) with the capacity to learn external tool usage may serve as a pivotal step toward realizing artificial general intelligence. Previous studies in this field have predominantly pursued two distinct approaches to augment the tool invocation capabilities of LLMs. The first approach emphasizes the construction of relevant datasets for model fine-tuning. The second approach, in contrast, aims to fully exploit the inherent reasoning abilities of LLMs through in-context learning strategies. In this work, we introduce a novel tool invocation pipeline designed to control massive real-world APIs. This pipeline mirrors the human task-solving process, addressing c
    
[^40]: 切断头部终结冲突：解释和缓解语言模型中的知识冲突的机制

    Cutting Off the Head Ends the Conflict: A Mechanism for Interpreting and Mitigating Knowledge Conflicts in Language Models

    [https://arxiv.org/abs/2402.18154](https://arxiv.org/abs/2402.18154)

    通过信息流的视角解释并干预语言模型中的知识冲突，提出了一种名为Pruning Head via PatH的方法来缓解冲突

    

    最近，检索增强和工具增强展示了通过提供外部上下文来扩展语言模型（LMs）的内部记忆边界的显著能力。然而，内部记忆和外部上下文不可避免地发生冲突，导致LMs内部出现知识冲突。本文旨在通过信息流的视角解释知识冲突的机制，然后通过在关键点进行精确干预来缓解冲突。我们发现在后续层中有一些具有相反效果的注意力头，其中内存头可以从内部记忆中召回知识，而上下文头可以从外部上下文中检索知识。此外，我们揭示了LMs中知识冲突发生的关键点是内存头和上下文头整合不一致信息流的地方。受到这些见解的启发，我们提出了一种名为Pruning Head via PatH的新方法。

    arXiv:2402.18154v1 Announce Type: cross  Abstract: Recently, retrieval augmentation and tool augmentation have demonstrated a remarkable capability to expand the internal memory boundaries of language models (LMs) by providing external context. However, internal memory and external context inevitably clash, leading to knowledge conflicts within LMs. In this paper, we aim to interpret the mechanism of knowledge conflicts through the lens of information flow, and then mitigate conflicts by precise interventions at the pivotal point. We find there are some attention heads with opposite effects in the later layers, where memory heads can recall knowledge from internal memory, and context heads can retrieve knowledge from external context. Moreover, we reveal that the pivotal point at which knowledge conflicts emerge in LMs is the integration of inconsistent information flows by memory heads and context heads. Inspired by the insights, we propose a novel method called Pruning Head via PatH 
    
[^41]: 基于扩散的神经网络权重生成

    Diffusion-based Neural Network Weights Generation

    [https://arxiv.org/abs/2402.18153](https://arxiv.org/abs/2402.18153)

    提出了一种基于扩散模型和变分自动编码器的数据集条件的预训练权重采样策略，用于改善迁移学习的性能。

    

    迁移学习是近期深度学习研究中具有显著兴趣的话题，因为它可以实现更快的收敛速度并在新任务上改善性能。然而，迁移学习的性能取决于源数据与目标数据的相似性，但在大量数据集上训练模型成本高昂。因此，预训练模型通常是盲目选择，并希望它们能在给定任务上表现良好。为了解决预训练模型的次优性，我们提出了一种通过数据集条件的预训练权重采样实现高效自适应迁移学习方案。具体而言，我们使用潜在扩散模型结合变分自动编码器，可以重建神经网络权重，以学习每个数据集条件下一组预训练权重的分布，从而在未见数据集上进行迁移学习。通过学习神经网络在不同数据集上的分布，

    arXiv:2402.18153v1 Announce Type: cross  Abstract: Transfer learning is a topic of significant interest in recent deep learning research because it enables faster convergence and improved performance on new tasks. While the performance of transfer learning depends on the similarity of the source data to the target data, it is costly to train a model on a large number of datasets. Therefore, pretrained models are generally blindly selected with the hope that they will achieve good performance on the given task. To tackle such suboptimality of the pretrained models, we propose an efficient and adaptive transfer learning scheme through dataset-conditioned pretrained weights sampling. Specifically, we use a latent diffusion model with a variational autoencoder that can reconstruct the neural network weights, to learn the distribution of a set of pretrained weights conditioned on each dataset for transfer learning on unseen datasets. By learning the distribution of a neural network on a var
    
[^42]: 大型语言模型的无监督信息细化训练用于检索增强生成

    Unsupervised Information Refinement Training of Large Language Models for Retrieval-Augmented Generation

    [https://arxiv.org/abs/2402.18150](https://arxiv.org/abs/2402.18150)

    本文提出了一种名为InFO-RAG的无监督信息细化训练方法，将大型语言模型在检索增强生成中的角色定义为“信息细化者”，帮助模型更好地整合检索信息以生成更加简洁、准确和完整的文本。

    

    检索增强生成（RAG）通过将来自检索的额外信息整合到大型语言模型（LLMs）中，从而增强其性能。然而，研究表明，LLMs在有效利用检索信息方面仍然面临挑战，有时会忽视或被错误引导。其关键原因在于LLMs的训练没有清晰地让LLMs学会如何利用具有不同质量的检索文本输入。本文提出了一个新颖的视角，将LLMs在RAG中的角色视为“信息细化者”，这意味着无论检索文本的正确性、完整性或有用性如何，LLMs都能一致地整合检索文本中的知识和模型参数，生成比检索文本更简洁、准确和完整的文本。为此，我们提出了一种名为InFO-RAG的信息细化训练方法，以无监督的方式优化LLMs用于RAG。

    arXiv:2402.18150v1 Announce Type: cross  Abstract: Retrieval-augmented generation (RAG) enhances large language models (LLMs) by incorporating additional information from retrieval. However, studies have shown that LLMs still face challenges in effectively using the retrieved information, even ignoring it or being misled by it. The key reason is that the training of LLMs does not clearly make LLMs learn how to utilize input retrieved texts with varied quality. In this paper, we propose a novel perspective that considers the role of LLMs in RAG as ``Information Refiner'', which means that regardless of correctness, completeness, or usefulness of retrieved texts, LLMs can consistently integrate knowledge within the retrieved texts and model parameters to generate the texts that are more concise, accurate, and complete than the retrieved texts. To this end, we propose an information refinement training method named InFO-RAG that optimizes LLMs for RAG in an unsupervised manner. InFO-RAG i
    
[^43]: 随机硅抽样：基于群体级别人口统计信息的大型语言模型模拟人类亚人口意见

    Random Silicon Sampling: Simulating Human Sub-Population Opinion Using a Large Language Model Based on Group-Level Demographic Information

    [https://arxiv.org/abs/2402.18144](https://arxiv.org/abs/2402.18144)

    通过随机硅抽样方法，可以模拟人类种群亚组的意见，并发现语言模型可以生成回应分布与实际美国公共舆论调查非常相似。

    

    大型语言模型表现出与人口统计信息相关的社会偏见，包括种族、性别等。为这些语言模型赋予基于人口数据的个性可以实现生成与人类观点一致的意见。基于这一想法，我们提出了“随机硅抽样”，一种方法来模拟人类种群亚组的观点。我们的研究分析了：1）仅基于其人口分布生成与人类群体对应的调查回应的语言模型；2）我们的方法在不同人口子群和主题问题中的适用性。通过随机硅抽样并仅使用群体级别的人口信息，我们发现语言模型可以生成与实际美国公共舆论调查非常相似的回应分布。此外，我们发现语言模型的可复制性取决于不同因

    arXiv:2402.18144v1 Announce Type: new  Abstract: Large language models exhibit societal biases associated with demographic information, including race, gender, and others. Endowing such language models with personalities based on demographic data can enable generating opinions that align with those of humans. Building on this idea, we propose "random silicon sampling," a method to emulate the opinions of the human population sub-group. Our study analyzed 1) a language model that generates the survey responses that correspond with a human group based solely on its demographic distribution and 2) the applicability of our methodology across various demographic subgroups and thematic questions. Through random silicon sampling and using only group-level demographic information, we discovered that language models can generate response distributions that are remarkably similar to the actual U.S. public opinion polls. Moreover, we found that the replicability of language models varies dependin
    
[^44]: 因果关系：大型语言模型真正理解因果关系吗？

    Cause and Effect: Can Large Language Models Truly Understand Causality?

    [https://arxiv.org/abs/2402.18139](https://arxiv.org/abs/2402.18139)

    本研究提出了一种名为CARE CA的新型架构，通过结合显式因果检测模块和反事实陈述、以及隐含因果检测模块，旨在增强大型语言模型对因果关系的理解能力。

    

    随着大型语言模型（LLMs）的兴起，理解它们在解读和解释语言所涉及的复杂因果关系的能力和局限性变得至关重要。目前的方法使用明确或隐含的因果推理，然而迫切需要一种统一的方法，将两者结合起来更有效地处理各种因果关系。本研究提出了一种新颖的架构，称为具有反事实分析的上下文感知推理增强（CARE CA）框架，以增强因果推理和可解释性。所提出的框架将 ConceptNet 和反事实陈述中的明确因果检测模块以及通过LLMs进行的隐含因果检测相结合。我们的框架通过一层反事实解释进一步突出LLMs对因果关系的理解。ConceptNet 中的知识提高了多

    arXiv:2402.18139v1 Announce Type: cross  Abstract: With the rise of Large Language Models(LLMs), it has become crucial to understand their capabilities and limitations in deciphering and explaining the complex web of causal relationships that language entails. Current methods use either explicit or implicit causal reasoning, yet there is a strong need for a unified approach combining both to tackle a wide array of causal relationships more effectively. This research proposes a novel architecture called Context Aware Reasoning Enhancement with Counterfactual Analysis(CARE CA) framework to enhance causal reasoning and explainability. The proposed framework incorporates an explicit causal detection module with ConceptNet and counterfactual statements, as well as implicit causal detection through LLMs. Our framework goes one step further with a layer of counterfactual explanations to accentuate LLMs understanding of causality. The knowledge from ConceptNet enhances the performance of multi
    
[^45]: DecisionNCE: 通过隐式偏好学习实体多模态表示

    DecisionNCE: Embodied Multimodal Representations via Implicit Preference Learning

    [https://arxiv.org/abs/2402.18137](https://arxiv.org/abs/2402.18137)

    本文提出了 DecisionNCE 框架，通过隐式偏好学习实体多模态表示，实现了提取任务进展信息和与语言指令对齐的有效方法

    

    多模态预训练已被证明是自主机器人中表示学习的三大目标：1）提取局部和全局任务进展信息；2）强化视觉表示的时间一致性；3）捕获轨迹级语言基础的有效策略。大部分已有方法通过不同的目标来处理这些问题，往往导致次优解。本文提出了一个通用统一目标，可以同时从图像序列中提取有意义的任务进展信息，并将它们与语言指令无缝对齐。我们发现，通过隐式偏好，在视觉轨迹与其对应的语言指令相比不匹配对更好地对齐时，流行的 Bradley-Terry 模型可以通过适当的奖励重新参数化而变为表示学习。结果产生的 DecisionNCE 框架，类似于 InfoNC

    arXiv:2402.18137v1 Announce Type: cross  Abstract: Multimodal pretraining has emerged as an effective strategy for the trinity of goals of representation learning in autonomous robots: 1) extracting both local and global task progression information; 2) enforcing temporal consistency of visual representation; 3) capturing trajectory-level language grounding. Most existing methods approach these via separate objectives, which often reach sub-optimal solutions. In this paper, we propose a universal unified objective that can simultaneously extract meaningful task progression information from image sequences and seamlessly align them with language instructions. We discover that via implicit preferences, where a visual trajectory inherently aligns better with its corresponding language instruction than mismatched pairs, the popular Bradley-Terry model can transform into representation learning through proper reward reparameterizations. The resulted framework, DecisionNCE, mirrors an InfoNC
    
[^46]: 关于基于人口统计学平等的公平学习算法的归纳偏差

    On the Inductive Biases of Demographic Parity-based Fair Learning Algorithms

    [https://arxiv.org/abs/2402.18129](https://arxiv.org/abs/2402.18129)

    分析了标准 DP 基础正则化方法对给定敏感属性的预测标签条件分布的影响，并提出了一种基于敏感属性的分布稳健优化方法来控制归纳偏差。

    

    公平的监督式学习算法在机器学习领域备受关注，这些算法在分配标签时很少依赖敏感属性。本文分析了标准DP（人口统计学平等）基础正则化方法对给定敏感属性的预测标签条件分布的影响。我们的分析表明，在具有非均匀分布敏感属性的训练数据集中，可能会导致分类规则偏向占据大多数训练数据的敏感属性结果。为了控制DP-based公平学习中的这种归纳偏差，我们提出了基于敏感属性的分布稳健优化（SA）

    arXiv:2402.18129v1 Announce Type: cross  Abstract: Fair supervised learning algorithms assigning labels with little dependence on a sensitive attribute have attracted great attention in the machine learning community. While the demographic parity (DP) notion has been frequently used to measure a model's fairness in training fair classifiers, several studies in the literature suggest potential impacts of enforcing DP in fair learning algorithms. In this work, we analytically study the effect of standard DP-based regularization methods on the conditional distribution of the predicted label given the sensitive attribute. Our analysis shows that an imbalanced training dataset with a non-uniform distribution of the sensitive attribute could lead to a classification rule biased toward the sensitive attribute outcome holding the majority of training data. To control such inductive biases in DP-based fair learning, we propose a sensitive attribute-based distributionally robust optimization (SA
    
[^47]: 拯救英雄伊巴什的遗产：评估四种语言模型在氨基酸语言中的表现

    Saving the legacy of Hero Ibash: Evaluating Four Language Models for Aminoacian

    [https://arxiv.org/abs/2402.18121](https://arxiv.org/abs/2402.18121)

    本研究评估了四种语言模型在未被充分探索的氨基酸语言中的适应性、有效性和局限性，并为未来自然语言处理的进展奠定了基础。

    

    本研究评估了四种前沿语言模型在未开发的氨基酸语言中的表现。通过评估，本研究审查了它们在文本生成、语义连贯性和上下文理解方面的适应性，有效性和局限性。揭示这些模型在低资源语言中的表现，为弥合语言差距开辟了道路。通过提供基准和理解挑战，为未来自然语言处理的进展奠定了基础，旨在提升语言模型在类似语言环境中的适用性，标志着语言技术包容性和进步的重要一步。

    arXiv:2402.18121v1 Announce Type: cross  Abstract: This study assesses four cutting-edge language models in the underexplored Aminoacian language. Through evaluation, it scrutinizes their adaptability, effectiveness, and limitations in text generation, semantic coherence, and contextual understanding. Uncovering insights into these models' performance in a low-resourced language, this research pioneers pathways to bridge linguistic gaps. By offering benchmarks and understanding challenges, it lays groundwork for future advancements in natural language processing, aiming to elevate the applicability of language models in similar linguistic landscapes, marking a significant step toward inclusivity and progress in language technology.
    
[^48]: 小而有趣：一种基于反馈的幽默精馏方法

    Small But Funny: A Feedback-Driven Approach to Humor Distillation

    [https://arxiv.org/abs/2402.18113](https://arxiv.org/abs/2402.18113)

    通过将大型语言模型分配为“教师”生成数据和“评论家”评估学生表现的双重角色，研究表明这种基于反馈的方法在幽默生成任务中取得了更高的性能。

    

    大型语言模型（LLMs）的出现揭示了有潜力的语言生成能力，特别是在执行诸如复杂推理和创意写作之类的任务方面。因此，通过模仿教师回答的方式进行精馏已经成为一种流行的技术，用于将LLMs中的知识转移到更易访问的小型语言模型（SLMs）中。虽然这对于简单任务效果很好，但在需要复杂语言理解和创造力的任务上存在实质性的表现差距，比如幽默生成。我们假设这种差距可能源自于创造性任务可能单凭模仿学习是很难的，并探讨一种涉及到教师额外指导的方法，能否产生更高的性能。为了解决这个问题，我们研究了将LLM分配双重角色的效果-作为生成数据的“教师”，以及作为评估学生表现的“评论家”。我们的实验结果表明，这种方法在幽默生成任务上确实产生了更高的性能。

    arXiv:2402.18113v1 Announce Type: cross  Abstract: The emergence of Large Language Models (LLMs) has brought to light promising language generation capabilities, particularly in performing tasks like complex reasoning and creative writing. Consequently, distillation through imitation of teacher responses has emerged as a popular technique to transfer knowledge from LLMs to more accessible, Small Language Models (SLMs). While this works well for simpler tasks, there is a substantial performance gap on tasks requiring intricate language comprehension and creativity, such as humor generation. We hypothesize that this gap may stem from the fact that creative tasks might be hard to learn by imitation alone and explore whether an approach, involving supplementary guidance from the teacher, could yield higher performance. To address this, we study the effect of assigning a dual role to the LLM - as a "teacher" generating data, as well as a "critic" evaluating the student's performance. Our ex
    
[^49]: 通过伪装和重构在少量查询中越狱大型语言模型

    Making Them Ask and Answer: Jailbreaking Large Language Models in Few Queries via Disguise and Reconstruction

    [https://arxiv.org/abs/2402.18104](https://arxiv.org/abs/2402.18104)

    通过伪装和重构攻击方法，我们提出了一种在大型语言模型中越狱的方法，通过成功隐藏有害指令并引导模型重构原指令，取得了90%的攻击成功率。

    

    近年来，大型语言模型（LLMs）在各种任务中取得显著成功，但LLMs的可信度仍然是一个未解之谜。其中一个特定的威胁是可能生成有毒或有害的回应。攻击者可以制作有针对性的提示，诱使LLMs生成有害的回应。在这项工作中，我们通过识别在安全微调中的偏见漏洞，开创了LLMs安全领域的理论基础，并设计了一种名为DRA（伪装和重构攻击）的黑盒越狱方法，通过伪装来隐藏有害指令，并提示模型在完成过程中重构原始有害指令。我们评估了DRA在各种开源和闭源模型上的表现，展示了最先进的越狱成功率和攻击效率。值得注意的是，DRA在LLM聊天机器人GPT-4上拥有90\%的攻击成功率。

    arXiv:2402.18104v1 Announce Type: cross  Abstract: In recent years, large language models (LLMs) have demonstrated notable success across various tasks, but the trustworthiness of LLMs is still an open problem. One specific threat is the potential to generate toxic or harmful responses. Attackers can craft adversarial prompts that induce harmful responses from LLMs. In this work, we pioneer a theoretical foundation in LLMs security by identifying bias vulnerabilities within the safety fine-tuning and design a black-box jailbreak method named DRA (Disguise and Reconstruction Attack), which conceals harmful instructions through disguise and prompts the model to reconstruct the original harmful instruction within its completion. We evaluate DRA across various open-source and close-source models, showcasing state-of-the-art jailbreak success rates and attack efficiency. Notably, DRA boasts a 90\% attack success rate on LLM chatbots GPT-4.
    
[^50]: 编辑医学大型语言模型的事实知识和解释能力

    Editing Factual Knowledge and Explanatory Ability of Medical Large Language Models

    [https://arxiv.org/abs/2402.18099](https://arxiv.org/abs/2402.18099)

    提出了一种新型的Layer-wise Scalable Adapter策略MedLaSA，用于编辑医学大型语言模型，能精确修改医学知识并解释事实，解决了当前方法在医学知识特殊化和复杂性方面的困难。

    

    模型编辑旨在精确修改大型语言模型（LLMs）对特定知识的行为，同时保持不相关的知识不变。已经证明，这种方法在解决LLMs中的幻觉和过时问题方面是有效的。因此，它可以提高LLMs在许多关键领域（例如医学领域）中的应用，其中幻觉是不可容忍的。本文提出两项模型编辑研究，并在医学领域验证它们：（1）直接编辑医学事实知识和（2）编辑对事实的解释。同时，我们观察到当前的模型编辑方法在医学知识的特殊化和复杂性方面存在困难。因此，我们提出了MedLaSA，一种新型的适用于医学模型编辑的分层可扩展适配器策略。它采用因果追踪来识别神经元中知识的精确位置，然后将可扩展适配器引入到LLMs的密集层中。

    arXiv:2402.18099v1 Announce Type: cross  Abstract: Model editing aims to precisely modify the behaviours of large language models (LLMs) on specific knowledge while keeping irrelevant knowledge unchanged. It has been proven effective in resolving hallucination and out-of-date issues in LLMs. As a result, it can boost the application of LLMs in many critical domains (e.g., medical domain), where the hallucination is not tolerable. In this paper, we propose two model editing studies and validate them in the medical domain: (1) directly editing the factual medical knowledge and (2) editing the explanations to facts. Meanwhile, we observed that current model editing methods struggle with the specialization and complexity of medical knowledge. Therefore, we propose MedLaSA, a novel Layer-wise Scalable Adapter strategy for medical model editing. It employs causal tracing to identify the precise location of knowledge in neurons and then introduces scalable adapters into the dense layers of LL
    
[^51]: 不丢弃任何令牌: 通过重要性感知混合精度量化实现可靠的KV缓存压缩

    No Token Left Behind: Reliable KV Cache Compression via Importance-Aware Mixed Precision Quantization

    [https://arxiv.org/abs/2402.18096](https://arxiv.org/abs/2402.18096)

    通过重要性感知混合精度量化，本论文研究了KV缓存压缩中不丢弃令牌的方法，并发现保留被驱逐KV对中的一小部分信息可以避免安全漏洞、幻觉和上下文丢失。

    

    键值（KV）缓存已成为加速生成大型语言模型（LLMs）推理速度和吞吐量的基本技术。然而，随着批量大小和序列长度的增长，KV缓存的内存占用成为LLM部署中的关键瓶颈，常常超过模型本身的大小。尽管最近提出了一些方法来选择和驱逐缓存中的不重要KV对以减少内存消耗，但驱逐对生成过程的潜在影响尚未得到彻底检验。在本文中，我们检查了缓存驱逐的有害影响，并观察到由于KV对中包含的信息被彻底丢弃而导致安全漏洞、幻觉和上下文丢失的不良后果。令人惊讶的是，我们发现即使通过降低精度保留被驱逐KV对中包含的一小部分信息，

    arXiv:2402.18096v1 Announce Type: cross  Abstract: Key-Value (KV) Caching has become an essential technique for accelerating the inference speed and throughput of generative Large Language Models~(LLMs). However, the memory footprint of the KV cache poses a critical bottleneck in LLM deployment as the cache size grows with batch size and sequence length, often surpassing even the size of the model itself. Although recent methods were proposed to select and evict unimportant KV pairs from the cache to reduce memory consumption, the potential ramifications of eviction on the generative process are yet to be thoroughly examined. In this paper, we examine the detrimental impact of cache eviction and observe that unforeseen risks arise as the information contained in the KV pairs is exhaustively discarded, resulting in safety breaches, hallucinations, and context loss. Surprisingly, we find that preserving even a small amount of information contained in the evicted KV pairs via reduced prec
    
[^52]: Polos：从人类反馈学习的多模式度量用于图像字幕生成

    Polos: Multimodal Metric Learning from Human Feedback for Image Captioning

    [https://arxiv.org/abs/2402.18091](https://arxiv.org/abs/2402.18091)

    提出了一种使用多模态输入和基于人类反馈的框架训练的自动评估指标Polos，旨在有效开发图像字幕生成模型。

    

    建立一个与人类判断紧密对齐的自动评估指标对于有效开发图像字幕生成模型至关重要。最近的数据驱动指标表现出比传统指标如CIDEr更强的与人类判断相关性；然而，它们缺乏足够的能力来处理幻觉，并且跨各种图像和文本泛化部分是因为它们仅仅使用从与图像字幕生成评估无关的任务学习的嵌入计算标量相似性。在这项研究中，我们提出了Polos，一种用于图像字幕生成模型的监督自动评估指标。Polos从多模式输入中计算得分，使用一个并行特征提取机制，利用通过大规模对比学习训练的嵌入。为了训练Polos，我们引入了基于人类反馈的多模态度量学习（M$^2$LHF）框架，用于开发度量方法。

    arXiv:2402.18091v1 Announce Type: cross  Abstract: Establishing an automatic evaluation metric that closely aligns with human judgments is essential for effectively developing image captioning models. Recent data-driven metrics have demonstrated a stronger correlation with human judgments than classic metrics such as CIDEr; however they lack sufficient capabilities to handle hallucinations and generalize across diverse images and texts partially because they compute scalar similarities merely using embeddings learned from tasks unrelated to image captioning evaluation. In this study, we propose Polos, a supervised automatic evaluation metric for image captioning models. Polos computes scores from multimodal inputs, using a parallel feature extraction mechanism that leverages embeddings trained through large-scale contrastive learning. To train Polos, we introduce Multimodal Metric Learning from Human Feedback (M$^2$LHF), a framework for developing metrics based on human feedback. We co
    
[^53]: 无人车群体的生成式人工智能：挑战、应用和机遇

    Generative AI for Unmanned Vehicle Swarms: Challenges, Applications and Opportunities

    [https://arxiv.org/abs/2402.18062](https://arxiv.org/abs/2402.18062)

    生成式人工智能在解决无人车群体挑战方面具有巨大潜力，本文对其在应用、挑战和机遇方面进行了全面调查。

    

    随着人工智能（AI）和机器人技术的不断进步，无人车群体因其潜在提供人类难以完成和危险的任务的能力，从学术界和工业界获得了极大关注。然而，在复杂和动态环境中学习和协调大量无人车的移动和行动，给传统人工智能方法引入了重大挑战。生成式人工智能（GAI）以其在复杂数据特征提取、转换和增强方面的能力，为解决无人车群体这些挑战提供了巨大潜力。因此，本文旨在对生成式人工智能在无人车群体中的应用、挑战和机遇进行全面调查。具体而言，我们首先概述了无人车和无人车群体以及它们的用例和现有问题。

    arXiv:2402.18062v1 Announce Type: cross  Abstract: With recent advances in artificial intelligence (AI) and robotics, unmanned vehicle swarms have received great attention from both academia and industry due to their potential to provide services that are difficult and dangerous to perform by humans. However, learning and coordinating movements and actions for a large number of unmanned vehicles in complex and dynamic environments introduce significant challenges to conventional AI methods. Generative AI (GAI), with its capabilities in complex data feature extraction, transformation, and enhancement, offers great potential in solving these challenges of unmanned vehicle swarms. For that, this paper aims to provide a comprehensive survey on applications, challenges, and opportunities of GAI in unmanned vehicle swarms. Specifically, we first present an overview of unmanned vehicles and unmanned vehicle swarms as well as their use cases and existing issues. Then, an in-depth background of
    
[^54]: 关于在信息提取中利用银标准数据进行零样本分类任务的研究

    On the use of Silver Standard Data for Zero-shot Classification Tasks in Information Extraction

    [https://arxiv.org/abs/2402.18061](https://arxiv.org/abs/2402.18061)

    本研究提出了一个新框架Clean-LaVe，旨在利用银标准数据来增强零样本分类性能。

    

    在信息提取（IE）领域，监督分类方法的卓越性能严重依赖于大量的黄金标准数据。最近的零样本分类方法将任务转化为其他NLP任务（例如，文本蕴涵），并使用这些NLP任务的现成模型直接对测试数据进行推理，而无需使用大量的IE注释数据。这些方法的一个潜在有价值的副产品是大规模的银标准数据，即其他NLP任务的现成模型生成的伪标记数据。然而，对于这些数据的利用并没有进一步的研究。本文提出了一个新框架Clean-LaVe，旨在利用银标准数据来增强零样本分类性能。Clean-LaVe包括四个阶段：（1）获取银标准数据；（2）从银标准数据中识别相对干净的数据；（3）使用干净数据微调现成模型；

    arXiv:2402.18061v1 Announce Type: cross  Abstract: The superior performance of supervised classification methods in the information extraction (IE) area heavily relies on a large amount of gold standard data. Recent zero-shot classification methods converted the task to other NLP tasks (e.g., textual entailment) and used off-the-shelf models of these NLP tasks to directly perform inference on the test data without using a large amount of IE annotation data. A potentially valuable by-product of these methods is the large-scale silver standard data, i.e., pseudo-labeled data by the off-the-shelf models of other NLP tasks. However, there is no further investigation into the use of these data. In this paper, we propose a new framework, Clean-LaVe, which aims to utilize silver standard data to enhance the zero-shot performance. Clean-LaVe includes four phases: (1) Obtaining silver data; (2) Identifying relatively clean data from silver data; (3) Finetuning the off-the-shelf model using clea
    
[^55]: 大型语言模型数据集：一项全面调查

    Datasets for Large Language Models: A Comprehensive Survey

    [https://arxiv.org/abs/2402.18041](https://arxiv.org/abs/2402.18041)

    本文全面探讨了大型语言模型数据集的不同类型、挑战和未来发展方向。

    

    本文对大型语言模型（LLM）数据集进行了探索，这些数据集在LLMs的显着进展中起着至关重要的作用。数据集类似于维持和培育LLMs发展的根系基础架构。因此，检查这些数据集成为研究中的一个关键主题。为了解决当前缺乏对LLM数据集全面概述和彻底分析的问题，并获得有关它们当前状态和未来趋势的见解，本调查从五个角度整合和分类LLM数据集的基本方面：（1）预训练语料库；（2）指导微调数据集；（3）偏好数据集；（4）评估数据集；（5）传统自然语言处理（NLP）数据集。调查阐明了当前存在的挑战，并指出了未来研究的潜在途径。

    arXiv:2402.18041v1 Announce Type: cross  Abstract: This paper embarks on an exploration into the Large Language Model (LLM) datasets, which play a crucial role in the remarkable advancements of LLMs. The datasets serve as the foundational infrastructure analogous to a root system that sustains and nurtures the development of LLMs. Consequently, examination of these datasets emerges as a critical topic in research. In order to address the current lack of a comprehensive overview and thorough analysis of LLM datasets, and to gain insights into their current status and future trends, this survey consolidates and categorizes the fundamental aspects of LLM datasets from five perspectives: (1) Pre-training Corpora; (2) Instruction Fine-tuning Datasets; (3) Preference Datasets; (4) Evaluation Datasets; (5) Traditional Natural Language Processing (NLP) Datasets. The survey sheds light on the prevailing challenges and points out potential avenues for future investigation. Additionally, a compre
    
[^56]: 利用深度学习自动发现积分

    Automated Discovery of Integral with Deep Learning

    [https://arxiv.org/abs/2402.18040](https://arxiv.org/abs/2402.18040)

    本研究探讨了利用深度学习重新发现基本数学概念：积分的潜力。

    

    深度学习领域的新进展，尤其是大型语言模型（LLMs）的发展，展示了人工智能解决复杂数学问题或解决编程挑战的能力。然而，根据大量训练数据解决明确定义问题的能力与进行科学发现的微妙过程有着显著差异。本研究探讨了利用深度学习重新发现基本数学概念：积分 的潜力。通过将积分定义为曲线下的面积，我们阐明了人工智能如何推导给定函数的积分。

    arXiv:2402.18040v1 Announce Type: new  Abstract: Recent advancements in the realm of deep learning, particularly in the development of large language models (LLMs), have demonstrated AI's ability to tackle complex mathematical problems or solving programming challenges. However, the capability to solve well-defined problems based on extensive training data differs significantly from the nuanced process of making scientific discoveries. Trained on almost all human knowledge available, today's sophisticated LLMs basically learn to predict sequences of tokens. They generate mathematical derivations and write code in a similar way as writing an essay, and do not have the ability to pioneer scientific discoveries in the manner a human scientist would do.   In this study we delve into the potential of using deep learning to rediscover a fundamental mathematical concept: integrals. By defining integrals as area under the curve, we illustrate how AI can deduce the integral of a given function,
    
[^57]: ResLoRA：低秩适应中的身份残差映射

    ResLoRA: Identity Residual Mapping in Low-Rank Adaption

    [https://arxiv.org/abs/2402.18039](https://arxiv.org/abs/2402.18039)

    ResLoRA提出了在训练中添加残余路径并在推断过程中消除这些额外路径的方法，实现了更好的结果，比LoRA更加高效。

    

    作为最流行的参数高效微调（PEFT）方法之一，低秩适应（LoRA）通常应用于微调大型语言模型（LLMs）。然而，在原始模型中由于长计算路径，在有效而迅速地更新LoRA块的权重方面存在挑战。为了解决这个问题，我们提出了ResLoRA，这是LoRA的改进框架。通过在训练过程中添加残余路径，并使用合并方法在推断过程中消除这些额外路径，我们的方法可以在较少的训练步骤内取得更好的结果，而与LoRA相比，不需要额外的可训练参数或推断成本。对 NLG、NLU 和文本到图像任务上的实验表明了我们方法的有效性。据我们所知，ResLoRA是首个将残余路径与LoRA结合的工作。我们方法的代码可在 https://github.com/microsoft/LMOps/tree/main/reslora 上获取。

    arXiv:2402.18039v1 Announce Type: cross  Abstract: As one of the most popular parameter-efficient fine-tuning (PEFT) methods, low-rank adaptation (LoRA) is commonly applied to fine-tune large language models (LLMs). However, updating the weights of LoRA blocks effectively and expeditiously is challenging due to the long calculation path in the original model. To address this, we propose ResLoRA, an improved framework of LoRA. By adding residual paths during training and using merging approaches to eliminate these extra paths during inference, our method can achieve better results in fewer training steps without any extra trainable parameters or inference cost compared to LoRA. The experiments on NLG, NLU, and text-to-image tasks demonstrate the effectiveness of our method. To the best of our knowledge, ResLoRA is the first work that combines the residual path with LoRA. The code of our method is available at https://github.com/microsoft/LMOps/tree/main/reslora .
    
[^58]: 大型语言模型是否反映认知语言处理？

    Do Large Language Models Mirror Cognitive Language Processing?

    [https://arxiv.org/abs/2402.18023](https://arxiv.org/abs/2402.18023)

    本文提出了一种新颖方法，通过将大型语言模型（LLMs）的表示与人类认知信号联系起来，评估LLMs模拟认知语言处理的效果。

    

    大型语言模型（LLMs）在文本理解和逻辑推理方面展现出卓越能力，甚至在许多认知任务中实现甚至超越人类水平的表现。由于LLMs是从人类语言认知的大量文本产出中训练出来的，自然而然地会问LLMs是否反映认知语言处理，或LLMs在多大程度上类似于认知语言处理。本文提出了一种新颖的方法，用于连接LLMs表征和人类认知信号，以评估LLMs如何有效地模拟认知语言处理。我们采用表征相似性分析（RSA）来衡量16种主流LLMs与大脑fMRI信号之间的对齐程度。我们在实验中探讨了各种因素（例如模型规模、对齐训练、指导附加）对LLM-大脑对齐的影响。实验结果表明，模型规模与正相关

    arXiv:2402.18023v1 Announce Type: new  Abstract: Large language models (LLMs) have demonstrated remarkable capabilities in text comprehension and logical reasoning, achiving or even surpassing human-level performance in numerous cognition tasks. As LLMs are trained from massive textual outputs of human language cognition, it is natural to ask whether LLMs mirror cognitive language processing. Or to what extend LLMs resemble cognitive language processing? In this paper, we propose a novel method that bridge between LLM representations and human cognition signals to evaluate how effectively LLMs simulate cognitive language processing. We employ Representational Similarity Analysis (RSA) to mearsure the alignment between 16 mainstream LLMs and fMRI signals of the brain. We empirically investigate the impact of a variety of factors (e.g., model scaling, alignment training, instruction appending) on such LLM-brain alignment. Experimental results indicate that model scaling is positively cor
    
[^59]: 动态解释选择：实现可解释AI的成功用户决策支持

    Dynamic Explanation Selection Towards Successful User-Decision Support with Explainable AI

    [https://arxiv.org/abs/2402.18016](https://arxiv.org/abs/2402.18016)

    该论文提出了一种名为X-Selector的方法，通过动态选择解释，预测不同解释组合对用户决策的影响，从而引导用户做出更好的决策。

    

    本文解决了如何为基于可解释AI的智能决策支持系统(IDSSs)选择解释的问题。IDSSs通过可解释AI生成的解释以及AI预测展示了提高用户决策的潜力。由于可解释AI的发展提供了各种解释，我们认为如果能够有策略地选择指导用户做出更好决策的解释，IDSSs 的性能将得到极大提升。本文提出了X-Selector，一种动态选择解释的方法。X-Selector的目标是通过预测不同解释组合对用户决策的影响，引导用户做出更好的决策。我们将X-Selector的性能与两种朴素策略（所有可能的解释和仅针对最可能预测的解释）、以及两种基线方法（无解释和无AI支持）进行了比较。结果表明X-Selector有潜力引导用户做出推荐的决策。

    arXiv:2402.18016v1 Announce Type: cross  Abstract: This paper addresses the problem of how to select explanations for XAI (Explainable AI)-based Intelligent Decision Support Systems (IDSSs). IDSSs have shown promise in improving user decisions through XAI-generated explanations along with AI predictions. As the development of XAI made various explanations available, we believe that IDSSs can be greatly improved if they can strategically select explanations that guide users to better decisions. This paper proposes X-Selector, a method for dynamically selecting explanations. X-Selector aims to guide users to better decisions by predicting the impact of different combinations of explanations on user decisions. We compared X-Selector's performance with two naive strategies (all possible explanations and explanations only for the most likely prediction) and two baselines (no explanation and no AI support). The results suggest the potential of X-Selector to guide users to recommended decisio
    
[^60]: 基于LLM的多轮对话系统最新进展综述

    A Survey on Recent Advances in LLM-Based Multi-turn Dialogue Systems

    [https://arxiv.org/abs/2402.18013](https://arxiv.org/abs/2402.18013)

    这项调查综述了基于LLM的多轮对话系统的研究，并重点介绍了LLMs的应用和最新进展，对开放领域对话和任务导向对话系统进行了涵盖，并讨论了相关数据集和评估指标，以及未来研究方向和问题。

    

    这项调查全面回顾了关于多轮对话系统的研究，特别侧重于基于大型语言模型（LLMs）的多轮对话系统。本文旨在（a）总结现有的LLMs和适应LLMs进行下游任务的方法；（b）详细阐述多轮对话系统的最新进展，涵盖基于LLM的开放领域对话（ODD）和任务导向对话（TOD）系统，以及数据集和评估指标；（c）讨论由于LLMs的发展和对多轮对话系统不断增加的需求而产生的未来重点和最新研究问题。

    arXiv:2402.18013v1 Announce Type: cross  Abstract: This survey provides a comprehensive review of research on multi-turn dialogue systems, with a particular focus on multi-turn dialogue systems based on large language models (LLMs). This paper aims to (a) give a summary of existing LLMs and approaches for adapting LLMs to downstream tasks; (b) elaborate recent advances in multi-turn dialogue systems, covering both LLM-based open-domain dialogue (ODD) and task-oriented dialogue (TOD) systems, along with datasets and evaluation metrics; (c) discuss some future emphasis and recent research problems arising from the development of LLMs and the increasing demands on multi-turn dialogue systems.
    
[^61]: 扩散模型作为具有未知约束的优化约束抽样器

    Diffusion Models as Constrained Samplers for Optimization with Unknown Constraints

    [https://arxiv.org/abs/2402.18012](https://arxiv.org/abs/2402.18012)

    使用扩散模型在数据流形内进行优化，通过在目标函数定义的Boltzmann分布和扩散模型学习的数据分布的乘积上进行抽样来解决具有未知约束的优化问题。

    

    处理现实世界的优化问题在分析客观函数或约束不可用时变得尤为具有挑战性。虽然许多研究已经解决了未知目标的问题，但有限研究关注了约束条件未明确给出的情况。忽略这些约束可能导致在实践中不现实的虚假解决方案。为了处理这种未知约束，我们建议使用扩散模型在数据流形内进行优化。为了将优化过程限制在数据流形内，我们将原始优化问题重新构造为通过客观函数定义的Boltzmann分布和扩散模型学习的数据分布的乘积的抽样问题。为了增强抽样效率，我们提出了一个两阶段框架，以引导扩散过程进行预热，然后是Langevin动态。

    arXiv:2402.18012v1 Announce Type: cross  Abstract: Addressing real-world optimization problems becomes particularly challenging when analytic objective functions or constraints are unavailable. While numerous studies have addressed the issue of unknown objectives, limited research has focused on scenarios where feasibility constraints are not given explicitly. Overlooking these constraints can lead to spurious solutions that are unrealistic in practice. To deal with such unknown constraints, we propose to perform optimization within the data manifold using diffusion models. To constrain the optimization process to the data manifold, we reformulate the original optimization problem as a sampling problem from the product of the Boltzmann distribution defined by the objective function and the data distribution learned by the diffusion model. To enhance sampling efficiency, we propose a two-stage framework that begins with a guided diffusion process for warm-up, followed by a Langevin dyna
    
[^62]: Mixer不仅仅是一个模型

    Mixer is more than just a model

    [https://arxiv.org/abs/2402.18007](https://arxiv.org/abs/2402.18007)

    Mixer的创新之处在于将通道和令牌信息融合，代表了信息提取范式，还可以根据不同需求创建更适合特定任务的混合器。

    

    最近，MLP结构重新受到关注，其中MLP-Mixer以其突出的表现脱颖而出。在计算机视觉领域，MLP-Mixer以从通道和令牌两个角度提取数据信息的能力而闻名，有效地作为通道信息和令牌信息的融合。事实上，Mixer代表了一种信息提取范式，将通道和令牌信息融合在一起。Mixer的精髓在于它能够从多元视角融合信息，典型地体现了在神经网络架构领域的“混合”真正概念。除了考虑通道和令牌以外，可以从各种角度创造更贴合特定任务需求的混合器。本研究专注于音频识别领域，引入一种名为带Roll-Time和Hermit FFT的音频频谱混合器(ASM-RH)的创新模型，该模型结合了对时间和频率的洞察。

    arXiv:2402.18007v1 Announce Type: cross  Abstract: Recently, MLP structures have regained popularity, with MLP-Mixer standing out as a prominent example. In the field of computer vision, MLP-Mixer is noted for its ability to extract data information from both channel and token perspectives, effectively acting as a fusion of channel and token information. Indeed, Mixer represents a paradigm for information extraction that amalgamates channel and token information. The essence of Mixer lies in its ability to blend information from diverse perspectives, epitomizing the true concept of "mixing" in the realm of neural network architectures. Beyond channel and token considerations, it is possible to create more tailored mixers from various perspectives to better suit specific task requirements. This study focuses on the domain of audio recognition, introducing a novel model named Audio Spectrogram Mixer with Roll-Time and Hermit FFT (ASM-RH) that incorporates insights from both time and freq
    
[^63]: 探索科学情感总结的多文档信息整合

    Exploring Multi-Document Information Consolidation for Scientific Sentiment Summarization

    [https://arxiv.org/abs/2402.18005](https://arxiv.org/abs/2402.18005)

    通过人类元审阅者的情感整合框架，提出评估指标并在实验中验证，指导LLMs生成科学元审阅的逻辑被验证可行。

    

    现代自然语言生成系统具有生成多个文档的合理摘要的能力；然而，现在尚不确定模型是否真正具有整合信息的能力来生成总结，尤其是对那些包含个人意见信息的源文档。为了使科学情感总结更加扎实，我们假设在同行评审中，人类元审阅者遵循情感整合的三层框架来撰写元审阅，并且这代表了在元审阅生成过程中总结科学情感的逻辑。通过人类注释，验证了这一框架。基于该框架，我们提出了评估指标来评估生成的元审阅的质量，并且在广泛实验中发现，当我们将其作为LLMs生成元审阅的提示时，情感整合框架的假设在经验上是行得通的。

    arXiv:2402.18005v1 Announce Type: cross  Abstract: Modern natural language generation systems with LLMs exhibit the capability to generate a plausible summary of multiple documents; however, it is uncertain if models truly possess the ability of information consolidation to generate summaries, especially on those source documents with opinionated information. To make scientific sentiment summarization more grounded, we hypothesize that in peer review human meta-reviewers follow a three-layer framework of sentiment consolidation to write meta-reviews and it represents the logic of summarizing scientific sentiments in meta-review generation. The framework is validated via human annotation. Based on the framework, we propose evaluation metrics to assess the quality of generated meta-reviews, and we find that the hypothesis of the sentiment consolidation framework works out empirically when we incorporate it as prompts for LLMs to generate meta-reviews in extensive experiments.
    
[^64]: 考虑对称性的软腕部分可观测性下机器人装配的强化学习

    Symmetry-aware Reinforcement Learning for Robotic Assembly under Partial Observability with a Soft Wrist

    [https://arxiv.org/abs/2402.18002](https://arxiv.org/abs/2402.18002)

    本研究利用部分可观测性和深度强化学习处理机器人装配中的零件装配任务，通过利用领域对称性提高样本效率，成功构建了一种基于记忆的代理模型。

    

    本研究运用软腕来解决机器人装配中的代表性但具有挑战性的富接触PEG-IN-HOLE任务，该软腕可以比刚性腕部更安全地操作并容忍较低频率的控制信号。与以往研究通常使用完全可观测公式不同，该公式需要外部设置或估计器来获取PEG-TO-HOLE姿态。相反，我们使用部分可观测公式和基于深度强化学习的示范来学习一种基于记忆的代理，该代理完全基于触觉和本体感知信号行动。此外，以前的研究未融合潜在领域对称性，因此必须在更大的空间中搜索解决方案。相反，我们建议利用对称性来提高样本效率，通过增加训练数据并构建辅助损失来强迫代理遵守对称性。在模拟实验中，使用五种不同对称PEG形状显示，我们提出的代理可以与

    arXiv:2402.18002v1 Announce Type: cross  Abstract: This study tackles the representative yet challenging contact-rich peg-in-hole task of robotic assembly, using a soft wrist that can operate more safely and tolerate lower-frequency control signals than a rigid one. Previous studies often use a fully observable formulation, requiring external setups or estimators for the peg-to-hole pose. In contrast, we use a partially observable formulation and deep reinforcement learning from demonstrations to learn a memory-based agent that acts purely on haptic and proprioceptive signals. Moreover, previous works do not incorporate potential domain symmetry and thus must search for solutions in a bigger space. Instead, we propose to leverage the symmetry for sample efficiency by augmenting the training data and constructing auxiliary losses to force the agent to adhere to the symmetry. Results in simulation with five different symmetric peg shapes show that our proposed agent can be comparable to 
    
[^65]: FlattenQuant: 使用分张量量化打破大型语言模型推断计算限制

    FlattenQuant: Breaking Through the Inference Compute-bound for Large Language Models with Per-tensor Quantization

    [https://arxiv.org/abs/2402.17985](https://arxiv.org/abs/2402.17985)

    FlattenQuant方法通过展平张量中的大通道，实现了低比特每张量量化，降低了准确性损失

    

    大型语言模型(LLMs)在各种任务中展现出领先的性能，然而，推断的延迟和LLMs的大GPU内存消耗限制了它们的部署性能。本文提出了一种名为FlattenQuant的方法，通过对张量中的大通道进行展平来显著降低张量的最大值，实现了低比特每张量量化，减小了准确性损失。

    arXiv:2402.17985v1 Announce Type: cross  Abstract: Large language models (LLMs) have demonstrated state-of-the-art performance across various tasks. However, the latency of inference and the large GPU memory consumption of LLMs restrict their deployment performance. Recently, there have been some efficient attempts to quantize LLMs, yet inference with large batch size or long sequence still has the issue of being compute-bound. Fine-grained quantization methods have showcased their proficiency in achieving low-bit quantization for LLMs, while requiring FP16 data type for linear layer computations, which is time-consuming when dealing with large batch size or long sequence. In this paper, we introduce a method called FlattenQuant, which significantly reduces the maximum value of the tensor by flattening the large channels in the tensor, to achieve low bit per-tensor quantization with minimal accuracy loss. Our experiments show that FlattenQuant can directly use 4 bits to achieve 48.29% 
    
[^66]: 集成方法论：使用LightGBM、XGBoost和LocalEnsemble进行信用违约预测的创新

    Ensemble Methodology:Innovations in Credit Default Prediction Using LightGBM, XGBoost, and LocalEnsemble

    [https://arxiv.org/abs/2402.17979](https://arxiv.org/abs/2402.17979)

    本研究提出了一个集成方法框架，包括LightGBM、XGBoost和LocalEnsemble模块，旨在重新定义信用违约预测的准确性标准。

    

    在消费信贷领域，准确的信用违约预测是风险缓解和贷款决策优化的关键要素。本研究针对信用违约预测领域的不断演变，挑战传统模型，引入创新方法。通过积累基础研究和最新创新，我们的工作旨在重新定义信用违约预测准确性标准，为该行业设立新的基准。为了克服这些挑战，我们提出了一个包含LightGBM、XGBoost和LocalEnsemble模块的集成方法框架，每个模块都提供独特的贡献，以增强多样性和改善泛化能力。通过利用不同的特征集，我们的方法直接解决了局限性。

    arXiv:2402.17979v1 Announce Type: cross  Abstract: In the realm of consumer lending, accurate credit default prediction stands as a critical element in risk mitigation and lending decision optimization. Extensive research has sought continuous improvement in existing models to enhance customer experiences and ensure the sound economic functioning of lending institutions. This study responds to the evolving landscape of credit default prediction, challenging conventional models and introducing innovative approaches. By building upon foundational research and recent innovations, our work aims to redefine the standards of accuracy in credit default prediction, setting a new benchmark for the industry. To overcome these challenges, we present an Ensemble Methods framework comprising LightGBM, XGBoost, and LocalEnsemble modules, each making unique contributions to amplify diversity and improve generalization. By utilizing distinct feature sets, our methodology directly tackles limitations i
    
[^67]: 想象、初始化和探索：多智能体强化学习中的有效探索方法

    Imagine, Initialize, and Explore: An Effective Exploration Method in Multi-Agent Reinforcement Learning

    [https://arxiv.org/abs/2402.17978](https://arxiv.org/abs/2402.17978)

    提出了一种名为Imagine, Initialize, and Explore (IIE)的新方法，利用变压器模型在复杂场景中实现多智能体的有效探索。

    

    有效的探索对于在复杂协调任务中发现多智能体强化学习（MARL）的最佳策略至关重要。现有方法主要利用内在奖励来实现承诺的探索，或者使用基于角色的学习来分解联合动作空间，而不是直接在整个动作-观察空间中进行集体搜索。然而，在长时间跨度任务中，他们往往面临获取特定联合动作序列以达到成功状态的挑战。为解决这一局限性，我们提出了一种称为Imagine, Initialize, and Explore (IIE)的新方法，为复杂场景中的高效多智能体探索提供了一个有前途的解决方案。IIE利用一个变压器模型来想象智能体如何达到可以影响彼此转移函数的关键状态。然后，在探索阶段之前，我们通过模拟器在这个状态下初始化环境。我们制定了实现这种想象的方法。

    arXiv:2402.17978v1 Announce Type: cross  Abstract: Effective exploration is crucial to discovering optimal strategies for multi-agent reinforcement learning (MARL) in complex coordination tasks. Existing methods mainly utilize intrinsic rewards to enable committed exploration or use role-based learning for decomposing joint action spaces instead of directly conducting a collective search in the entire action-observation space. However, they often face challenges obtaining specific joint action sequences to reach successful states in long-horizon tasks. To address this limitation, we propose Imagine, Initialize, and Explore (IIE), a novel method that offers a promising solution for efficient multi-agent exploration in complex scenarios. IIE employs a transformer model to imagine how the agents reach a critical state that can influence each other's transition functions. Then, we initialize the environment at this state using a simulator before the exploration phase. We formulate the imag
    
[^68]: 基于偏好的强化学习中的样本有效性及动态感知奖励

    Sample-Efficient Preference-based Reinforcement Learning with Dynamics Aware Rewards

    [https://arxiv.org/abs/2402.17975](https://arxiv.org/abs/2402.17975)

    动态感知奖励函数显著提高了基于偏好的强化学习的样本效率，实验证明只需50个偏好标签即可达到与传统方法500个偏好标签相同的性能，并且能更好地恢复地面真值奖励策略性能。

    

    基于偏好的强化学习（PbRL）通过从对代理行为的二进制反馈中学习的奖励函数将机器人行为与人类偏好对齐。我们展示了动态感知奖励函数可以将PbRL的样本效率提高一个数量级。在我们的实验中，我们在学习动态感知状态-动作表示（z^{sa））和基于偏好的奖励函数之间迭代，结果表明这可以加快策略学习并提高最终策略性能。例如，在四足行走、步行和猎豹奔跑等领域，使用50个偏好标签的性能与使用500个偏好标签的现有方法相同，并且我们恢复了83\%和66\%的地面真值奖励策略性能，而其他方法只有38\%和21\%。这些性能提升展示了明确学习动态感知奖励模型的好处。

    arXiv:2402.17975v1 Announce Type: new  Abstract: Preference-based reinforcement learning (PbRL) aligns a robot behavior with human preferences via a reward function learned from binary feedback over agent behaviors. We show that dynamics-aware reward functions improve the sample efficiency of PbRL by an order of magnitude. In our experiments we iterate between: (1) learning a dynamics-aware state-action representation (z^{sa}) via a self-supervised temporal consistency task, and (2) bootstrapping the preference-based reward function from (z^{sa}), which results in faster policy learning and better final policy performance. For example, on quadruped-walk, walker-walk, and cheetah-run, with 50 preference labels we achieve the same performance as existing approaches with 500 preference labels, and we recover 83\% and 66\% of ground truth reward policy performance versus only 38\% and 21\%. The performance gains demonstrate the benefits of explicitly learning a dynamics-aware reward model.
    
[^69]: 一张图片搞定：大型多模态模型是图片内学习者

    All in a Single Image: Large Multimodal Models are In-Image Learners

    [https://arxiv.org/abs/2402.17971](https://arxiv.org/abs/2402.17971)

    这项研究引入了一种名为图片内学习（I$^2$L）的新型上下文学习机制，将演示示例、视觉线索和指令合并到一个图片中，以提升GPT-4V的能力，并通过整合图像处理、理解和推理的能力来取得多个优点

    

    本文介绍了一种名为图片内学习（I$^2$L）的新型上下文学习（ICL）机制，将演示示例、视觉线索和指令合并到一张图片中，以增强GPT-4V的能力。与以往依赖将图像转换为文本或将视觉输入融入语言模型的方法不同，I$^2$L将所有信息整合到一张图片中，主要利用图像处理、理解和推理能力。这有几个优点：避免了对复杂图像的不准确文本描述，提供了在定位演示示例时的灵活性，减少了输入负担，并通过消除对多个图片和冗长文本的需求来避免超过输入限制。为了进一步结合不同ICL方法的优势，我们引入了一种自动策略，用于选择给定任务中数据示例的适当ICL方法。我们在MathVi上进行了实验

    arXiv:2402.17971v1 Announce Type: cross  Abstract: This paper introduces a new in-context learning (ICL) mechanism called In-Image Learning (I$^2$L) that combines demonstration examples, visual cues, and instructions into a single image to enhance the capabilities of GPT-4V. Unlike previous approaches that rely on converting images to text or incorporating visual input into language models, I$^2$L consolidates all information into one image and primarily leverages image processing, understanding, and reasoning abilities. This has several advantages: it avoids inaccurate textual descriptions of complex images, provides flexibility in positioning demonstration examples, reduces the input burden, and avoids exceeding input limits by eliminating the need for multiple images and lengthy text. To further combine the strengths of different ICL methods, we introduce an automatic strategy to select the appropriate ICL method for a data example in a given task. We conducted experiments on MathVi
    
[^70]: 基于视觉语言模型的图像标题评估方法，利用视觉上下文提取

    Vision Language Model-based Caption Evaluation Method Leveraging Visual Context Extraction

    [https://arxiv.org/abs/2402.17969](https://arxiv.org/abs/2402.17969)

    该论文提出了一种基于视觉语言模型的图像标题评估方法，通过提取和组织视觉上下文来替代人工参考文献，从而提升图像标题的评估性能。

    

    鉴于视觉和语言建模的加速进展，准确评估机器生成的图像标题仍然至关重要。为了更贴近人类偏好地评估标题，度量标准需要区分不同质量和内容的标题。然而，传统度量标准仅限于比较单词或嵌入相似性的表面匹配，因此仍有改进的空间。本文提出了基于视觉语言模型的标题评估方法VisCE$^2$。我们的方法侧重于视觉上下文，即图像的详细内容，包括对象、属性和关系。通过提取并组织成结构化格式，我们用视觉上下文替换人工编写的参考文献，帮助视觉语言模型更好地理解图像，提升评估性能。通过在多个数据集上的元评估，我们验证了VisCE$^2$优于传統方法。

    arXiv:2402.17969v1 Announce Type: cross  Abstract: Given the accelerating progress of vision and language modeling, accurate evaluation of machine-generated image captions remains critical. In order to evaluate captions more closely to human preferences, metrics need to discriminate between captions of varying quality and content. However, conventional metrics fail short of comparing beyond superficial matches of words or embedding similarities; thus, they still need improvement. This paper presents VisCE$^2$, a vision language model-based caption evaluation method. Our method focuses on visual context, which refers to the detailed content of images, including objects, attributes, and relationships. By extracting and organizing them into a structured format, we replace the human-written references with visual contexts and help VLMs better understand the image, enhancing evaluation performance. Through meta-evaluation on multiple datasets, we validated that VisCE$^2$ outperforms the con
    
[^71]: 用特征化低秩混合进行多任务多语言模型适应

    Multitask Multilingual Model Adaptation with Featurized Low-Rank Mixtures

    [https://arxiv.org/abs/2402.17934](https://arxiv.org/abs/2402.17934)

    提出了一种名为FLix的新型参数高效微调方法，适用于多任务多语言调整，通过关联每个独特数据集特征与其低秩权重更新参数，实现了更好的泛化能力和性能表现。

    

    预训练大型语言模型（LLMs）适应数十甚至数百种人类语言的各种下游任务在计算上是昂贵的。参数高效微调（PEFT）通过只调整少量参数显著减少了适应成本。然而，直接将像 LoRA（Hu 等人，2022）这样的 PEFT 方法应用于不同数据集混合可能导致性能次优，原因在于有限的参数容量和不同数据集之间的负面互相影响。在这项工作中，我们提出了特征化低秩混合（FLix），这是一种针对有效的多任务多语言调整的新型 PEFT 方法。FLix将每个独特数据集特征（例如数据集的语言或任务）与其自己的低秩权重更新参数相关联。通过为每个数据集组合特定于特征的参数，FLix能够适应多种数据集混合，并更好地泛化到未见数据集。我们的实验表明，FLix 可以在提供更好性能的同时显著减少适应成本。

    arXiv:2402.17934v1 Announce Type: cross  Abstract: Adapting pretrained large language models (LLMs) to various downstream tasks in tens or hundreds of human languages is computationally expensive. Parameter-efficient fine-tuning (PEFT) significantly reduces the adaptation cost, by tuning only a small amount of parameters. However, directly applying PEFT methods such as LoRA (Hu et al., 2022) on diverse dataset mixtures could lead to suboptimal performance due to limited parameter capacity and negative interference among different datasets. In this work, we propose Featurized Low-rank Mixtures (FLix), a novel PEFT method designed for effective multitask multilingual tuning. FLix associates each unique dataset feature, such as the dataset's language or task, with its own low-rank weight update parameters. By composing feature-specific parameters for each dataset, FLix can accommodate diverse dataset mixtures and generalize better to unseen datasets. Our experiments show that FLix leads t
    
[^72]: 通过合作语言引导逆向规划实现实用指令跟随和目标辅助

    Pragmatic Instruction Following and Goal Assistance via Cooperative Language-Guided Inverse Planning

    [https://arxiv.org/abs/2402.17930](https://arxiv.org/abs/2402.17930)

    本文介绍了一种名为合作语言引导逆向计划搜索（CLIPS）的贝叶斯代理架构，用于实现实用指令跟随和目标辅助，能够通过多模态贝叶斯推断，利用大型语言模型评估指令的可能性以实现实用目标达成成本最小化。

    

    人们经常给出在缺乏进一步上下文的情况下意义模糊的指令，期望他们的行动或目标能消除不明确的意图。我们如何构建能够以灵活、与上下文相关的方式遵循这类指令的辅助代理呢？本文介绍了一种名为合作语言引导逆向计划搜索（CLIPS）的贝叶斯代理架构，用于实现实用指令跟随和目标辅助。我们的代理通过将人类建模为一个合作规划者，将共同计划与助手进行通信，然后通过动作和语言执行多模态贝叶斯推断，利用大型语言模型（LLMs）评估在假设计划下给出的指令的可能性。在获得这一后验分布后，我们的助手通过行动来最小化期望目标实现成本，使其能够实用地遵循含糊的指令，并即使在对指令不确定时也能提供有效的辅助。

    arXiv:2402.17930v1 Announce Type: new  Abstract: People often give instructions whose meaning is ambiguous without further context, expecting that their actions or goals will disambiguate their intentions. How can we build assistive agents that follow such instructions in a flexible, context-sensitive manner? This paper introduces cooperative language-guided inverse plan search (CLIPS), a Bayesian agent architecture for pragmatic instruction following and goal assistance. Our agent assists a human by modeling them as a cooperative planner who communicates joint plans to the assistant, then performs multimodal Bayesian inference over the human's goal from actions and language, using large language models (LLMs) to evaluate the likelihood of an instruction given a hypothesized plan. Given this posterior, our assistant acts to minimize expected goal achievement cost, enabling it to pragmatically follow ambiguous instructions and provide effective assistance even when uncertain about the g
    
[^73]: 通过对抗攻击实现抗LLM的数学问题生成

    LLM-Resistant Math Word Problem Generation via Adversarial Attacks

    [https://arxiv.org/abs/2402.17916](https://arxiv.org/abs/2402.17916)

    本研究提出了一种新方法，通过生成保留原问题结构难度但针对LLMs无解的对抗性示例，有效地降低了LLMs的数学问题解决能力。

    

    大型语言模型（LLMs）显著改变了教育领域。本文探讨了一种新的范例，生成对抗性示例，以确保公平评估，这些示例保留了原始问题的结构和难度，但LLMs无法解决。我们专注于数学应用领域的词问题，利用抽象语法树结构生成对抗示例，通过简单编辑问题中的数字值，导致LLMs产生错误答案。我们对各种开源和闭源LLMs进行实验，定量和定性地证明我们的方法显著降低了它们的数学问题解决能力。

    arXiv:2402.17916v1 Announce Type: cross  Abstract: Large language models (LLMs) have significantly transformed the educational landscape. As current plagiarism detection tools struggle to keep pace with LLMs' rapid advancements, the educational community faces the challenge of assessing students' true problem-solving abilities in the presence of LLMs. In this work, we explore a new paradigm for ensuring fair evaluation -- generating adversarial examples which preserve the structure and difficulty of the original questions aimed for assessment, but are unsolvable by LLMs. Focusing on the domain of math word problems, we leverage abstract syntax trees to structurally generate adversarial examples that cause LLMs to produce incorrect answers by simply editing the numeric values in the problems. We conduct experiments on various open- and closed-source LLMs, quantitatively and qualitatively demonstrating that our method significantly degrades their math problem-solving ability. We identify
    
[^74]: 通过可解释的方言分类器提取方言的词汇特征

    Extracting Lexical Features from Dialects via Interpretable Dialect Classifiers

    [https://arxiv.org/abs/2402.17914](https://arxiv.org/abs/2402.17914)

    通过可解释的方言分类器提取方言的词汇特征，成功识别了有助于方言变化的关键语言特定词汇特征。

    

    识别一种语言的方言之间的语言差异通常需要专业知识和细致的人类分析。这主要是因为研究各种方言涉及到复杂性和微妙之处。我们提出了一种新颖的方法，通过利用可解释的方言分类器提取方言的区分性词汇特征，即使在没有人类专家的情况下。我们探索了事后和内在的解释性方法，对普通话、意大利语和低地萨克森语进行实验，并实验证明我们的方法成功地识别了有助于方言变化的关键语言特定词汇特征。

    arXiv:2402.17914v1 Announce Type: cross  Abstract: Identifying linguistic differences between dialects of a language often requires expert knowledge and meticulous human analysis. This is largely due to the complexity and nuance involved in studying various dialects. We present a novel approach to extract distinguishing lexical features of dialects by utilizing interpretable dialect classifiers, even in the absence of human experts. We explore both post-hoc and intrinsic approaches to interpretability, conduct experiments on Mandarin, Italian, and Low Saxon, and experimentally demonstrate that our method successfully identifies key language-specific lexical features that contribute to dialectal variations.
    
[^75]: 使用AI库进行不可压缩计算流体动力学

    Using AI libraries for Incompressible Computational Fluid Dynamics

    [https://arxiv.org/abs/2402.17913](https://arxiv.org/abs/2402.17913)

    本文提出了一种将AI软件和硬件应用于数值建模领域的新方法，通过重新利用AI方法，如CNN，来解决偏微分方程的标准操作，带来高性能、架构不可知性和易用性。

    

    最近，人们致力于开发高效开源库，以在不同的计算机架构（例如CPU、GPU和新的AI处理器）上执行人工智能（AI）相关的计算。这不仅使基于这些库的算法高效而且在不同架构之间可移植，还大大简化了使用AI开发方法的门槛。本文提出了一种新颖的方法论，将AI软件和硬件的强大功能带入数值建模领域，将AI方法（如卷积神经网络CNN）重新用于数值偏微分方程的标准操作。本工作的目标是将高性能、架构不可知性和易用性引入数值偏微分方程的解决领域。

    arXiv:2402.17913v1 Announce Type: cross  Abstract: Recently, there has been a huge effort focused on developing highly efficient open source libraries to perform Artificial Intelligence (AI) related computations on different computer architectures (for example, CPUs, GPUs and new AI processors). This has not only made the algorithms based on these libraries highly efficient and portable between different architectures, but also has substantially simplified the entry barrier to develop methods using AI. Here, we present a novel methodology to bring the power of both AI software and hardware into the field of numerical modelling by repurposing AI methods, such as Convolutional Neural Networks (CNNs), for the standard operations required in the field of the numerical solution of Partial Differential Equations (PDEs). The aim of this work is to bring the high performance, architecture agnosticism and ease of use into the field of the numerical solution of PDEs. We use the proposed methodol
    
[^76]: 研究性问题：LLM网络特工的多透视、分解问题数据集

    Researchy Questions: A Dataset of Multi-Perspective, Decompositional Questions for LLM Web Agents

    [https://arxiv.org/abs/2402.17896](https://arxiv.org/abs/2402.17896)

    提出了一个研究性问题数据集，其中包含非事实型、多透视的问题，能够挑战目前大型语言模型的表现。

    

    现有的问答（QA）数据集对于大多数强大的大型语言模型（LLMs）来说不再具有挑战性。传统的QA基准如TriviaQA、NaturalQuestions、ELI5和HotpotQA主要研究明确指示了缺少哪些信息以及如何找到这些信息来回答问题的“已知未知s”。因此，对这些基准的优秀表现提供了一种虚假的安全感。自然语言处理（NLP）社区尚未满足的需求是一个非事实型、多透视问题的银行，涉及大量不明确的信息需求，即“未知的未知s”。我们声称可以在搜索引擎日志中找到这样的问题，这令人惊讶，因为大多数问答意图查询实际上是事实型的。我们展示了Researchy Questions，一个经过繁琐过滤以变为非事实型、“分解式”和多透视的搜索引擎查询数据集。我们展示了用户在这些问题上投入了大量“努力”，这种努力表现为信号

    arXiv:2402.17896v1 Announce Type: cross  Abstract: Existing question answering (QA) datasets are no longer challenging to most powerful Large Language Models (LLMs). Traditional QA benchmarks like TriviaQA, NaturalQuestions, ELI5 and HotpotQA mainly study ``known unknowns'' with clear indications of both what information is missing, and how to find it to answer the question. Hence, good performance on these benchmarks provides a false sense of security. A yet unmet need of the NLP community is a bank of non-factoid, multi-perspective questions involving a great deal of unclear information needs, i.e. ``unknown uknowns''. We claim we can find such questions in search engine logs, which is surprising because most question-intent queries are indeed factoid. We present Researchy Questions, a dataset of search engine queries tediously filtered to be non-factoid, ``decompositional'' and multi-perspective. We show that users spend a lot of ``effort'' on these questions in terms of signals lik
    
[^77]: ConjNorm：用于异常分布检测的可处理密度估计

    ConjNorm: Tractable Density Estimation for Out-of-Distribution Detection

    [https://arxiv.org/abs/2402.17888](https://arxiv.org/abs/2402.17888)

    提出了一种新颖的理论框架，基于Bregman散度，通过引入共轭约束，提出了一种\textsc{ConjNorm}方法，以在给定数据集中搜索最佳规范系数$p$来重新构想密度函数设计。

    

    后续异常分布（OOD）检测在可靠机器学习中受到密切关注。许多工作致力于推导基于logits、距离或严格数据分布假设的评分函数，以识别得分低的OOD样本。然而，这些估计得分可能无法准确反映真实数据密度或施加不切实际的约束。为了在基于密度得分设计方面提供一个统一的视角，我们提出了一个以Bregman散度为基础的新颖理论框架，该框架将分布考虑扩展到涵盖一系列指数族分布。利用我们定理中揭示的共轭约束，我们引入了一种\textsc{ConjNorm}方法，将密度函数设计重新构想为针对给定数据集搜索最佳规范系数$p$的过程。鉴于归一化的计算挑战，我们设计了一种无偏和解析可追踪的方法

    arXiv:2402.17888v1 Announce Type: cross  Abstract: Post-hoc out-of-distribution (OOD) detection has garnered intensive attention in reliable machine learning. Many efforts have been dedicated to deriving score functions based on logits, distances, or rigorous data distribution assumptions to identify low-scoring OOD samples. Nevertheless, these estimate scores may fail to accurately reflect the true data density or impose impractical constraints. To provide a unified perspective on density-based score design, we propose a novel theoretical framework grounded in Bregman divergence, which extends distribution considerations to encompass an exponential family of distributions. Leveraging the conjugation constraint revealed in our theorem, we introduce a \textsc{ConjNorm} method, reframing density function design as a search for the optimal norm coefficient $p$ against the given dataset. In light of the computational challenges of normalization, we devise an unbiased and analytically tract
    
[^78]: REPrune：通过核代表选择进行通道修剪

    REPrune: Channel Pruning via Kernel Representative Selection

    [https://arxiv.org/abs/2402.17862](https://arxiv.org/abs/2402.17862)

    REPrune是一种新颖的通道修剪技术，通过模拟核修剪，并结合聚类和滤波器选择，实现了更精细但结构化的修剪粒度，促进了在训练CNNs期间的高效、渐进式修剪。

    

    通道修剪被广泛认可为加速现代卷积神经网络（CNNs）的方法。所得到的修剪模型可以立即部署在通用软件和硬件资源上。然而，由于在卷积滤波器这个单元上的大修剪粒度，通常会导致不希望的准确性下降，这是由于在CNNs中决定如何以及在何处引入稀疏性的灵活性不足。在本文中，我们提出了REPrune，一种新颖的通道修剪技术，模拟了核修剪，充分利用了更细但有结构的粒度。REPrune使用凝聚聚类识别每个通道内的相似核。然后，它选择最大化包含核代表的滤波器，同时优化最大聚类覆盖问题。通过与同时训练-修剪范式相结合，REPrune促进了在训练CNNs期间的高效、渐进式修剪，避免了在训练期间的误差传播。

    arXiv:2402.17862v1 Announce Type: cross  Abstract: Channel pruning is widely accepted to accelerate modern convolutional neural networks (CNNs). The resulting pruned model benefits from its immediate deployment on general-purpose software and hardware resources. However, its large pruning granularity, specifically at the unit of a convolution filter, often leads to undesirable accuracy drops due to the inflexibility of deciding how and where to introduce sparsity to the CNNs. In this paper, we propose REPrune, a novel channel pruning technique that emulates kernel pruning, fully exploiting the finer but structured granularity. REPrune identifies similar kernels within each channel using agglomerative clustering. Then, it selects filters that maximize the incorporation of kernel representatives while optimizing the maximum cluster coverage problem. By integrating with a simultaneous training-pruning paradigm, REPrune promotes efficient, progressive pruning throughout training CNNs, avoi
    
[^79]: 潜在神经PDE求解器：用于偏微分方程的降阶建模框架

    Latent Neural PDE Solver: a reduced-order modelling framework for partial differential equations

    [https://arxiv.org/abs/2402.17853](https://arxiv.org/abs/2402.17853)

    提出了一种名为潜在神经PDE求解器（LNS）的框架，通过在潜在空间学习系统动态并使用较粗糙的离散化，可以大大简化神经PDE求解器的训练过程，降低计算成本。

    

    神经网络在加速由偏微分方程（PDEs）控制的系统的数值模拟方面显示出了巨大潜力。与许多现有的在高维离散化场上操作的神经网络代理不同，我们提议在潜在空间学习系统的动态，使用更粗糙的离散化。在我们提出的框架 - 潜在神经PDE求解器（LNS）中，首先训练一个非线性自动编码器，将系统的全阶表示投影到网格减少的空间中，接着训练一个时间模型来预测这个网格减少的空间中的未来状态。这种降阶过程通过大大减少伴随细粒度离散化的计算成本，简化了时间模型的训练。我们研究了提出的框架以及几种其他流行的神经PDE求解器在各种类型的系统上的能力，包括单相和多相流体系统。

    arXiv:2402.17853v1 Announce Type: cross  Abstract: Neural networks have shown promising potential in accelerating the numerical simulation of systems governed by partial differential equations (PDEs). Different from many existing neural network surrogates operating on high-dimensional discretized fields, we propose to learn the dynamics of the system in the latent space with much coarser discretizations. In our proposed framework - Latent Neural PDE Solver (LNS), a non-linear autoencoder is first trained to project the full-order representation of the system onto the mesh-reduced space, then a temporal model is trained to predict the future state in this mesh-reduced space. This reduction process simplifies the training of the temporal model by greatly reducing the computational cost accompanying a fine discretization. We study the capability of the proposed framework and several other popular neural PDE solvers on various types of systems including single-phase and multi-phase flows a
    
[^80]: 遵循我的指示并说出真相：来自检索增强生成系统的可扩展数据提取

    Follow My Instruction and Spill the Beans: Scalable Data Extraction from Retrieval-Augmented Generation Systems

    [https://arxiv.org/abs/2402.17840](https://arxiv.org/abs/2402.17840)

    研究揭示了检索增强生成系统中的数据泄露风险，指出对手可以利用LMs的指示遵循能力轻松地从数据存储中直接提取文本数据，并设计了攻击对生产RAG模型GPTs造成数据存储泄漏。

    

    检索增强生成（RAG）通过在测试时将外部知识纳入预训练模型，从而实现定制适应，提升了模型性能。本研究探讨了Retrieval-In-Context RAG语言模型（LMs）中的数据泄露风险。我们展示了当对使用指令调整的LMs构建的RAG系统进行提示注入时，对手可以利用LMs的指示遵循能力轻松地从数据存储中直接提取文本数据。这种漏洞存在于覆盖Llama2、Mistral/Mixtral、Vicuna、SOLAR、WizardLM、Qwen1.5和Platypus2等多种现代LMs的广泛范围内，并且随着模型规模的扩大，利用能力加剧。将研究扩展到生产RAG模型GPTs，我们设计了一种攻击，可以在对25个随机选择的定制GPTs施加最多2个查询时以100%成功率导致数据存储泄漏，并且我们能够以77,000字的书籍中的文本数据的提取率为41%，以及在含有1,569,00词的语料库中的文本数据的提取率为3%。

    arXiv:2402.17840v1 Announce Type: cross  Abstract: Retrieval-Augmented Generation (RAG) improves pre-trained models by incorporating external knowledge at test time to enable customized adaptation. We study the risk of datastore leakage in Retrieval-In-Context RAG Language Models (LMs). We show that an adversary can exploit LMs' instruction-following capabilities to easily extract text data verbatim from the datastore of RAG systems built with instruction-tuned LMs via prompt injection. The vulnerability exists for a wide range of modern LMs that span Llama2, Mistral/Mixtral, Vicuna, SOLAR, WizardLM, Qwen1.5, and Platypus2, and the exploitability exacerbates as the model size scales up. Extending our study to production RAG models GPTs, we design an attack that can cause datastore leakage with a 100% success rate on 25 randomly selected customized GPTs with at most 2 queries, and we extract text data verbatim at a rate of 41% from a book of 77,000 words and 3% from a corpus of 1,569,00
    
[^81]: 大型语言模型的预测排名

    Prediction-Powered Ranking of Large Language Models

    [https://arxiv.org/abs/2402.17826](https://arxiv.org/abs/2402.17826)

    该研究提出了一种统计框架，可以衡量人类与模型偏好之间的不确定性，从而进行大型语言模型的预测排名。

    

    大型语言模型通常根据其与人类偏好的一致性水平进行排名--如果一个模型的输出更受人类偏好，那么它就比其他模型更好。本文提出了一种统计框架来弥合人类与模型偏好之间可能引入的不一致性。

    arXiv:2402.17826v1 Announce Type: cross  Abstract: Large language models are often ranked according to their level of alignment with human preferences -- a model is better than other models if its outputs are more frequently preferred by humans. One of the most popular ways to elicit human preferences utilizes pairwise comparisons between the outputs provided by different models to the same inputs. However, since gathering pairwise comparisons by humans is costly and time-consuming, it has become a very common practice to gather pairwise comparisons by a strong large language model -- a model strongly aligned with human preferences. Surprisingly, practitioners cannot currently measure the uncertainty that any mismatch between human and model preferences may introduce in the constructed rankings. In this work, we develop a statistical framework to bridge this gap. Given a small set of pairwise comparisons by humans and a large set of pairwise comparisons by a model, our framework provid
    
[^82]: TruthX: 通过在真实空间中编辑大型语言模型来减轻幻觉

    TruthX: Alleviating Hallucinations by Editing Large Language Models in Truthful Space

    [https://arxiv.org/abs/2402.17811](https://arxiv.org/abs/2402.17811)

    本文提出了一种名为TruthX的方法，通过在真实空间中编辑大型语言模型的内部表示，有效提高了语言模型的真实性，实验证明在TruthfulQA基准测试中，TruthX平均提高了13种先进语言模型的真实性。

    

    大型语言模型(LLMs)在各种任务中展现出了显著的能力。然而，它们有时会产生幻觉，特别是在它们可能生成不真实的回应，尽管拥有正确的知识的情况下。在本文中，我们提出了TruthX，一种用于在真实空间中编辑LLMs内部表示以获取其真实性的推断时间方法。TruthX利用自动编码器将LLM的表示分别映射到语义和真实潜在空间，并应用对比学习在真实空间中识别真实的编辑方向。在推断过程中，通过在真实空间中编辑LLM的内部表示，TruthX有效地增强了LLMs的真实性。实验证明，TruthX通过20%的平均值提高了13种先进LLMs在TruthfulQA基准测试中的真实性。进一步的分析表明，真实空间

    arXiv:2402.17811v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across various tasks. However, they sometimes suffer from producing hallucinations, particularly in cases where they may generate untruthful responses despite possessing the correct knowledge. In this paper, we propose TruthX, an inference-time method to elicit the truthfulness of LLMs by editing their internal representations in truthful space. TruthX employs an auto-encoder to map LLM's representations into semantic and truthful latent spaces respectively, and applies contrastive learning to identify a truthful editing direction within the truthful space. During inference, by editing LLM's internal representations in truthful space, TruthX effectively enhances the truthfulness of LLMs. Experiments show that TruthX effectively improves the truthfulness of 13 advanced LLMs by an average of 20% on TruthfulQA benchmark. Further analyses suggest that the truthful space
    
[^83]: BioT5+: 通过IUPAC集成和多任务调整实现广义生物理解

    BioT5+: Towards Generalized Biological Understanding with IUPAC Integration and Multi-task Tuning

    [https://arxiv.org/abs/2402.17810](https://arxiv.org/abs/2402.17810)

    BioT5+是BioT5框架的扩展，通过整合IUPAC名称、包含广泛生物文本和分子数据、多任务指令调整以及新颖的数值标记技术，实现了分子表示与文本之间的联系。

    

    最近计算生物学的研究趋势越来越集中于整合文本和生物实体建模，特别是在分子和蛋白质的背景下。然而，类似于BioT5的先前工作在跨越多样化任务和缺乏对分子结构的细致理解方面面临挑战，特别是在它们的文本表示（例如IUPAC）方面。本文介绍了BioT5+，这是BioT5框架的一个扩展，旨在增强生物研究和药物发现。 BioT5+包含几个新颖的特性：整合IUPAC名称以加深对分子的理解，包括来自bioRxiv和PubChem等源的广泛生物文本和分子数据，多任务指令调整以跨越多个任务，以及一种用于改进数字数据处理的新颖数值标记技术。 这些增强功能使BioT5+能够弥合分子表示和它们的文本之间的差距。

    arXiv:2402.17810v1 Announce Type: cross  Abstract: Recent research trends in computational biology have increasingly focused on integrating text and bio-entity modeling, especially in the context of molecules and proteins. However, previous efforts like BioT5 faced challenges in generalizing across diverse tasks and lacked a nuanced understanding of molecular structures, particularly in their textual representations (e.g., IUPAC). This paper introduces BioT5+, an extension of the BioT5 framework, tailored to enhance biological research and drug discovery. BioT5+ incorporates several novel features: integration of IUPAC names for molecular understanding, inclusion of extensive bio-text and molecule data from sources like bioRxiv and PubChem, the multi-task instruction tuning for generality across tasks, and a novel numerical tokenization technique for improved processing of numerical data. These enhancements allow BioT5+ to bridge the gap between molecular representations and their text
    
[^84]: 图神经网络与算术电路

    Graph Neural Networks and Arithmetic Circuits

    [https://arxiv.org/abs/2402.17805](https://arxiv.org/abs/2402.17805)

    研究者在本文中建立了图神经网络与算术电路之间的表达能力对应关系，结果表明不同激活函数的GNN在表达能力上等价于实数上的算术电路。

    

    我们表征了遵循图神经网络（GNN）架构的神经网络的计算能力，不限于聚合-组合GNN或其他特定类型。我们建立了使用不同激活函数的GNN的表达能力与实数上的算术电路之间的准确对应关系。在我们的结果中，网络的激活函数成为电路中的门类型。我们的结果对于常数深度电路和网络家族均成立，无论是在一致还是非一致的情况下，对于所有常见激活函数。

    arXiv:2402.17805v1 Announce Type: cross  Abstract: We characterize the computational power of neural networks that follow the graph neural network (GNN) architecture, not restricted to aggregate-combine GNNs or other particular types. We establish an exact correspondence between the expressivity of GNNs using diverse activation functions and arithmetic circuits over real numbers. In our results the activation function of the network becomes a gate type in the circuit. Our result holds for families of constant depth circuits and networks, both uniformly and non-uniformly, for all common activation functions.
    
[^85]: 生成人工智能与版权：一个动态视角

    Generative AI and Copyright: A Dynamic Perspective

    [https://arxiv.org/abs/2402.17801](https://arxiv.org/abs/2402.17801)

    本文研究了生成人工智能对创意产业带来的版权问题，探讨了公平使用标准和AI-版权性对AI发展和公司利润的影响

    

    生成人工智能的快速发展即将颠覆创意产业。在对这项新技术的巨大兴奋中，其在创意产业中的未来发展和应用至关重要的两个版权问题是：1) 补偿那些用于训练生成人工智能模型的创作者（公平使用标准）；和2) AI生成的内容是否有资格获得版权保护（AI-版权性）。虽然这两个问题引发了学术界和实践者之间激烈的争论，但大多数分析都集中在它们对现有版权原则所带来的挑战上。在本文中，我们旨在更好地理解这两个监管问题及其互动对经济的影响。通过建立一个具有内生内容创作和AI模型发展的动态模型，我们揭示了公平使用标准和AI-版权性对AI发展、AI公司利润、cr的影响

    arXiv:2402.17801v1 Announce Type: cross  Abstract: The rapid advancement of generative AI is poised to disrupt the creative industry. Amidst the immense excitement for this new technology, its future development and applications in the creative industry hinge crucially upon two copyright issues: 1) the compensation to creators whose content has been used to train generative AI models (the fair use standard); and 2) the eligibility of AI-generated content for copyright protection (AI-copyrightability). While both issues have ignited heated debates among academics and practitioners, most analysis has focused on their challenges posed to existing copyright doctrines. In this paper, we aim to better understand the economic implications of these two regulatory issues and their interactions. By constructing a dynamic model with endogenous content creation and AI model development, we unravel the impacts of the fair use standard and AI-copyrightability on AI development, AI company profit, cr
    
[^86]: 一个令人惊讶的失败？多模LLMs和NLVR挑战

    A Surprising Failure? Multimodal LLMs and the NLVR Challenge

    [https://arxiv.org/abs/2402.17793](https://arxiv.org/abs/2402.17793)

    这项研究评估了多模LLMs在自然语言视觉推理任务NLVR上的性能表现，发现它们在需要组合和空间推理、对语义和系统性偏见具有鲁棒性的任务上表现不佳。

    

    这项研究评估了三种最先进的MLLMs——GPT-4V、Gemini Pro和开源模型IDEFICS——对于组合自然语言视觉推理任务NLVR的表现。NLVR要求模型根据一个人类书写的句子和一个合成图像来确定句子相对于图像的真假。尽管这些模型表现出强大的性能，我们观察到它们在NLVR上表现不佳，该任务旨在需要组合和空间推理，并且对语义和系统性偏见具有鲁棒性。

    arXiv:2402.17793v1 Announce Type: new  Abstract: This study evaluates three state-of-the-art MLLMs -- GPT-4V, Gemini Pro, and the open-source model IDEFICS -- on the compositional natural language vision reasoning task NLVR. Given a human-written sentence paired with a synthetic image, this task requires the model to determine the truth value of the sentence with respect to the image. Despite the strong performance demonstrated by these models, we observe they perform poorly on NLVR, which was constructed to require compositional and spatial reasoning, and to be robust for semantic and systematic biases.
    
[^87]: EGNN-C+: 可解释的演化颗粒神经网络及其在弱监督EEG数据流分类中的应用

    EGNN-C+: Interpretable Evolving Granular Neural Network and Application in Classification of Weakly-Supervised EEG Data Streams

    [https://arxiv.org/abs/2402.17792](https://arxiv.org/abs/2402.17792)

    该研究介绍了一种改进的增量学习算法，用于演化颗粒神经网络分类器，能够在分类弱监督EEG数据流时提高鲁棒性和灵活性，同时结合了对情绪相关模式的分类应用。

    

    我们引入了一种改进的增量学习算法，用于演化颗粒神经网络分类器（eGNN-C+）。我们使用双边界超立方体来表示颗粒，并定制了适应性过程，以增强外部盒子对数据覆盖和噪声抑制的鲁棒性，同时确保内部盒子保持灵活以捕获漂移。分类器从零开始演化，在运行过程中结合新的类别，并执行局部增量特征加权。作为一个应用，我们集中在对脑电图（EEG）信号中与情绪相关的模式进行分类。情绪识别对于增强计算机系统的逼真性和互动性至关重要。我们从28名参与电脑游戏的个体获得的EEG信号的傅立叶谱中提取特征 -- 这是一个公共数据集。每个游戏引发不同的主导情绪：无聊、平静、恐怖或快乐。我们分析了个体间不同的情绪模式。

    arXiv:2402.17792v1 Announce Type: cross  Abstract: We introduce a modified incremental learning algorithm for evolving Granular Neural Network Classifiers (eGNN-C+). We use double-boundary hyper-boxes to represent granules, and customize the adaptation procedures to enhance the robustness of outer boxes for data coverage and noise suppression, while ensuring that inner boxes remain flexible to capture drifts. The classifier evolves from scratch, incorporates new classes on the fly, and performs local incremental feature weighting. As an application, we focus on the classification of emotion-related patterns within electroencephalogram (EEG) signals. Emotion recognition is crucial for enhancing the realism and interactivity of computer systems. We extract features from the Fourier spectrum of EEG signals obtained from 28 individuals engaged in playing computer games -- a public dataset. Each game elicits a different predominant emotion: boredom, calmness, horror, or joy. We analyze indi
    
[^88]: 标签信息对知识图谱中节点重要性估计的对比预训练的影响

    Label Informed Contrastive Pretraining for Node Importance Estimation on Knowledge Graphs

    [https://arxiv.org/abs/2402.17791](https://arxiv.org/abs/2402.17791)

    引入标签信息对知识图谱中节点重要性估计问题的对比预训练（LICAP），利用连续标签生成对比样本来更好地了解高重要性节点。

    

    节点重要性估计（NIE）是推断图中节点重要性分数的任务。最近的研究兴趣已经转向知识图谱，用于预测未来或缺失的节点重要性分数，由于数据和知识更为丰富。现有最先进的NIE方法通过可用标签训练模型，并在训练之前平等地考虑每个感兴趣的节点。然而，在现实场景中，更重要的节点通常需要或会得到更多关注，例如，人们可能更关心具有更高重要性的电影或网页。为此，我们引入了标签信息对知识图谱中节点重要性估计问题的对比预训练（LICAP），以更好地了解具有高重要性分数的节点。具体而言，LICAP是一种新颖的对比学习框架，旨在充分利用连续标签生成预训练嵌入的对比样本。

    arXiv:2402.17791v1 Announce Type: new  Abstract: Node Importance Estimation (NIE) is a task of inferring importance scores of the nodes in a graph. Due to the availability of richer data and knowledge, recent research interests of NIE have been dedicating to knowledge graphs for predicting future or missing node importance scores. Existing state-of-the-art NIE methods train the model by available labels, and they consider every interested node equally before training. However, the nodes with higher importance often require or receive more attention in real-world scenarios, e.g., people may care more about the movies or webpages with higher importance. To this end, we introduce Label Informed ContrAstive Pretraining (LICAP) to the NIE problem for being better aware of the nodes with high importance scores. Specifically, LICAP is a novel type of contrastive learning framework that aims to fully utilize the continuous labels to generate contrastive samples for pretraining embeddings. Cons
    
[^89]: 使用大型语言模型进行逐步自洽的数学推理

    Stepwise Self-Consistent Mathematical Reasoning with Large Language Models

    [https://arxiv.org/abs/2402.17786](https://arxiv.org/abs/2402.17786)

    提出了一种名为SSC-CoT的算法，通过选择中间步骤的策略和查询知识图来解决大型语言模型进行复杂数学推理时面临的挑战

    

    使用大型语言模型进行复杂数学推理是困难的，主要是由于多步推理过程的复杂性。该论文介绍了一种新的算法，名为Stepwise Self-Consistent Chain-of-Thought（SSC-CoT），用于解决这些问题。SSC-CoT利用选择基于不同推理链交集的中间步骤的策略，并通过查询包含相关领域知识的知识图来发现关键的中间步骤。

    arXiv:2402.17786v1 Announce Type: new  Abstract: Using Large Language Models for complex mathematical reasoning is difficult, primarily due to the complexity of multi-step reasoning. The main challenges of this process include (1) selecting critical intermediate results to advance the procedure, and (2) limited exploration of potential solutions. To address these issues, we introduce a novel algorithm, namely Stepwise Self-Consistent Chain-of-Thought (SSC-CoT). SSC-CoT employs a strategy of selecting intermediate steps based on the intersection of various reasoning chains. Additionally, SSC-CoT enables the model to discover critical intermediate steps by querying a knowledge graph comprising relevant domain knowledge. To validate SSC-CoT, we present a new dataset, TriMaster100, tailored for complex trigonometry problems. This dataset contains 100 questions, with each solution broken down into scored intermediate steps, facilitating a comprehensive evaluation of the mathematical reasoni
    
[^90]: ByteComposer：基于语言模型代理的类人旋律创作方法

    ByteComposer: a Human-like Melody Composition Method based on Language Model Agent

    [https://arxiv.org/abs/2402.17785](https://arxiv.org/abs/2402.17785)

    提出了ByteComposer代理框架，在模拟人类创作流程的基础上，将大型语言模型与符号音乐生成模型结合，实现了可与人类创作者相提并论的旋律创作代理。

    

    大型语言模型（Large Language Models，LLM）在多模态理解和生成任务中取得了令人鼓舞的进展。然而，如何设计一个人类对齐且可解释的旋律创作系统仍未得到充分探讨。为了解决这一问题，我们提出了ByteComposer，一个代理框架，模拟人类创作的四个独立步骤：“概念分析 - 起草作品 - 自我评估和修改 - 美学选择”。该框架将LLM的交互和知识理解特性与现有的符号音乐生成模型无缝融合，从而实现了一个可与人类创作者媲美的旋律创作代理。我们在GPT4和几个开源大型语言模型上进行了大量实验，证实了我们框架的有效性。此外，专业音乐作曲家参与了多维度评估，最终结果表明，在各个方面

    arXiv:2402.17785v1 Announce Type: cross  Abstract: Large Language Models (LLM) have shown encouraging progress in multimodal understanding and generation tasks. However, how to design a human-aligned and interpretable melody composition system is still under-explored. To solve this problem, we propose ByteComposer, an agent framework emulating a human's creative pipeline in four separate steps : "Conception Analysis - Draft Composition - Self-Evaluation and Modification - Aesthetic Selection". This framework seamlessly blends the interactive and knowledge-understanding features of LLMs with existing symbolic music generation models, thereby achieving a melody composition agent comparable to human creators. We conduct extensive experiments on GPT4 and several open-source large language models, which substantiate our framework's effectiveness. Furthermore, professional music composers were engaged in multi-dimensional evaluations, the final results demonstrated that across various facets
    
[^91]: BagStacking：一种集成学习方法，用于帕金森病患者的步态冻结检测

    BagStacking: An Integrated Ensemble Learning Approach for Freezing of Gait Detection in Parkinson's Disease

    [https://arxiv.org/abs/2402.17783](https://arxiv.org/abs/2402.17783)

    BagStacking是一种集成学习方法，通过在训练数据的自举样本上训练一组基础模型，然后在基础模型输出和真实标签上训练元学习器，以找到最佳的聚合方案，实现了对帕金森病患者步态冻结检测的显着改进

    

    本文介绍了BagStacking，一种新颖的集成学习方法，旨在通过使用下背传感器跟踪加速度来增强对帕金森病患者步态冻结（FOG）的检测。BagStacking建立在装袋和堆叠的原则之上，旨在实现装袋的自举采样的方差减少好处，同时通过堆叠学习复杂的混合。

    arXiv:2402.17783v1 Announce Type: cross  Abstract: This paper introduces BagStacking, a novel ensemble learning method designed to enhance the detection of Freezing of Gait (FOG) in Parkinson's Disease (PD) by using a lower-back sensor to track acceleration. Building on the principles of bagging and stacking, BagStacking aims to achieve the variance reduction benefit of bagging's bootstrap sampling while also learning sophisticated blending through stacking. The method involves training a set of base models on bootstrap samples from the training data, followed by a meta-learner trained on the base model outputs and true labels to find an optimal aggregation scheme. The experimental evaluation demonstrates significant improvements over other state-of-the-art machine learning methods on the validation set. Specifically, BagStacking achieved a MAP score of 0.306, outperforming LightGBM (0.234) and classic Stacking (0.286). Additionally, the run-time of BagStacking was measured at 3828 sec
    
[^92]: 为超宽带无标签门实时姿态预测提出动态锚点选择方法

    Dynamic Anchor Selection and Real-Time Pose Prediction for Ultra-wideband Tagless Gate

    [https://arxiv.org/abs/2402.17778](https://arxiv.org/abs/2402.17778)

    本文提出了针对超宽带无标签门的动态锚点选择和DS-TWR的实时姿态预测方法，解决了MD准确位置需求，实现了高精度的定位和姿态预测。

    

    超宽带（Ultra-wideband，UWB）作为一种有望实现接触性服务的解决方案，如UWB无标签门（UTG），得益于基于下行到达时间差（DL-TDoA）和双边双向测距（DS-TWR）等两种不同测距方法提供的厘米级定位精度，正在崛起。UTG是一种基于UWB的接触性服务，提供无需实时移动设备（MD）敲击即可实现的无缝门禁系统。MD的位置通过DL-TDoA计算，并通过DS-TWR与最近的UTG通信以打开大门。因此，MD的准确位置是UTG面临的主要挑战，因此我们提供了针对DL-TDoA和DS-TWR的解决方案。在本文中，我们提出了极其准确的DL-TDoA定位的动态锚点选择方法和DS-TWR的姿态预测，称为DynaPose。姿态定义为MD在人体上的实际位置，影响着...

    arXiv:2402.17778v1 Announce Type: cross  Abstract: Ultra-wideband (UWB) is emerging as a promising solution that can realize proximity services, such as UWB tagless gate (UTG), thanks to centimeter-level localization accuracy based on two different ranging methods such as downlink time-difference of arrival (DL-TDoA) and double-sided two-way ranging (DS-TWR). The UTG is a UWB-based proximity service that provides a seamless gate pass system without requiring real-time mobile device (MD) tapping. The location of MD is calculated using DL-TDoA, and the MD communicates with the nearest UTG using DS-TWR to open the gate. Therefore, the knowledge about the exact location of MD is the main challenge of UTG, and hence we provide the solutions for both DL-TDoA and DS-TWR. In this paper, we propose dynamic anchor selection for extremely accurate DL-TDoA localization and pose prediction for DS-TWR, called DynaPose. The pose is defined as the actual location of MD on the human body, which affects
    
[^93]: Wavelet散射变换在生物声学中的应用：以Watkins海洋哺乳动物声音数据库为例

    Wavelet Scattering Transform for Bioacustics: Application to Watkins Marine Mammal Sound Database

    [https://arxiv.org/abs/2402.17775](https://arxiv.org/abs/2402.17775)

    本研究提出了在Watkins海洋哺乳动物声音数据库上应用Wavelet散射变换（WST）和Mel频谱图预处理的方法，在分类任务中取得了较高的准确率。

    

    海洋哺乳动物的交流是一个复杂的领域，受到鸣叫的多样性和环境因素的影响。Watkins海洋哺乳动物声音数据库（WMMD）是一个广泛应用于机器学习中的标记数据集。本研究首先重点介绍了该数据集上最新的基准记录，着重澄清数据准备和预处理方法。随后，我们提出了在STFT基础上应用Wavelet散射变换（WST）的方法。研究还探讨了使用自适应深层架构和残差层进行分类任务。我们在准确率上使用WST比现有分类架构提高了6％，使用Mel频谱图预处理提高了8％，从而有效地减少了

    arXiv:2402.17775v1 Announce Type: cross  Abstract: Marine mammal communication is a complex field, hindered by the diversity of vocalizations and environmental factors. The Watkins Marine Mammal Sound Database (WMMD) is an extensive labeled dataset used in machine learning applications. However, the methods for data preparation, preprocessing, and classification found in the literature are quite disparate. This study first focuses on a brief review of the state-of-the-art benchmarks on the dataset, with an emphasis on clarifying data preparation and preprocessing methods. Subsequently, we propose the application of the Wavelet Scattering Transform (WST) in place of standard methods based on the Short-Time Fourier Transform (STFT). The study also tackles a classification task using an ad-hoc deep architecture with residual layers. We outperform the existing classification architecture by $6\%$ in accuracy using WST and $8\%$ using Mel spectrogram preprocessing, effectively reducing by h
    
[^94]: 自动驾驶车辆：人工智能和学习算法的演进

    Autonomous Vehicles: Evolution of Artificial Intelligence and Learning Algorithms

    [https://arxiv.org/abs/2402.17690](https://arxiv.org/abs/2402.17690)

    本文全面探讨了自动驾驶车辆中AI的演进轨迹，从基础原理追溯到最新进展，并阐明了AI在塑造车辆自主决策能力中的基础作用。

    

    自动驾驶车辆的出现标志着交通运输领域迎来了一个变革时代，通过尖端技术重塑了移动性的格局。人工智能（AI）和学习算法的整合是这一进化的核心，将车辆推向前所未有的自主领域。本文全面探讨了自动驾驶车辆中AI的演进轨迹，从基础原理追溯到最新进展。从当前景观概述开始，本文深入探讨了AI在塑造车辆自主决策能力中的基础作用。阐明了AI驱动的车辆开发生命周期中涉及的步骤，解决了自动驾驶车辆中AI驱动软件开发中的伦理考虑和偏见问题。该研究提供了关于AI/学习的使用和类型的统计洞见。

    arXiv:2402.17690v1 Announce Type: cross  Abstract: The advent of autonomous vehicles has heralded a transformative era in transportation, reshaping the landscape of mobility through cutting-edge technologies. Central to this evolu- tion is the integration of Artificial Intelligence (AI) and learning algorithms, propelling vehicles into realms of unprecedented autonomy. This paper provides a comprehensive exploration of the evolutionary trajectory of AI within autonomous vehicles, tracing the journey from foundational principles to the most recent advancements. Commencing with a current landscape overview, the paper delves into the fundamental role of AI in shaping the autonomous decision-making capabilities of vehicles. It elucidates the steps involved in the AI-powered development life cycle in vehicles, addressing ethical considerations and bias in AI-driven software development for autonomous vehicles. The study presents statis- tical insights into the usage and types of AI/learning
    
[^95]: 导航器：面向延迟敏感ML工作流的分散式调度器

    Navigator: A Decentralized Scheduler for Latency-Sensitive ML Workflows

    [https://arxiv.org/abs/2402.17652](https://arxiv.org/abs/2402.17652)

    提出了一种名为Navigator的新型框架，通过统一GPU内存管理和任务放置功能，以减少作业延迟，同时高效利用资源，比其他最先进的调度器表现出更显著的完成时间缩短。

    

    我们考虑在分布式系统中进行ML查询处理，其中启用GPU的工作人员协调执行复杂查询：这种计算风格经常出现在与用户互动支持图像处理和自然语言处理的应用程序中。在这种系统中，GPU内存管理和任务放置的协同调度代表着一个有前途的机会。我们提出了Navigator，一个新颖的框架，统一了这些功能，以减少作业延迟，同时高效利用资源，将任务放置在数据依赖关系将得到满足的地方，将来自同一作业的任务放在一起（当这不会使主机或其GPU超载时），并高效地管理GPU内存。与其他最先进的调度器比较显示，在需要相同量甚至更少资源的情况下，完成时间显著减少。在一个案例中，仅需要一半的服务器来处理相同的工作负载。

    arXiv:2402.17652v1 Announce Type: cross  Abstract: We consider ML query processing in distributed systems where GPU-enabled workers coordinate to execute complex queries: a computing style often seen in applications that interact with users in support of image processing and natural language processing. In such systems, coscheduling of GPU memory management and task placement represents a promising opportunity. We propose Navigator, a novel framework that unifies these functions to reduce job latency while using resources efficiently, placing tasks where data dependencies will be satisfied, collocating tasks from the same job (when this will not overload the host or its GPU), and efficiently managing GPU memory. Comparison with other state of the art schedulers shows a significant reduction in completion times while requiring the same amount or even fewer resources. In one case, just half the servers were needed for processing the same workload.
    
[^96]: DAGnosis：使用结构进行数据不一致性的局部识别

    DAGnosis: Localized Identification of Data Inconsistencies using Structures

    [https://arxiv.org/abs/2402.17599](https://arxiv.org/abs/2402.17599)

    DAGnosis使用有向无环图(DAGs)来解决数据一致性检测中的两个关键限制，并能够准确定位为何样本会被标记为不一致。

    

    在部署时识别和适当处理数据中的不一致性对可靠地使用机器学习模型至关重要。近期的数据中心方法能够识别与训练集相关的这种不一致性，但存在两个关键限制：（1）在特征展现统计独立性的情况下表现不佳，因为它们使用压缩表示；（2）缺乏局部化，无法准确定位样本为何被标记为不一致，这对指导未来数据收集至关重要。我们使用有向无环图（DAGs）来编码训练集的特征概率分布和独立性作为结构，从而解决了这两个基本限制。我们的方法被称为DAGnosis，利用这些结构交互带来有价值的、深刻的数据中心结论。DAGnosis解锁了在DAG上定位不一致性原因的能力，

    arXiv:2402.17599v1 Announce Type: cross  Abstract: Identification and appropriate handling of inconsistencies in data at deployment time is crucial to reliably use machine learning models. While recent data-centric methods are able to identify such inconsistencies with respect to the training set, they suffer from two key limitations: (1) suboptimality in settings where features exhibit statistical independencies, due to their usage of compressive representations and (2) lack of localization to pin-point why a sample might be flagged as inconsistent, which is important to guide future data collection. We solve these two fundamental limitations using directed acyclic graphs (DAGs) to encode the training set's features probability distribution and independencies as a structure. Our method, called DAGnosis, leverages these structural interactions to bring valuable and insightful data-centric conclusions. DAGnosis unlocks the localization of the causes of inconsistencies on a DAG, an aspec
    
[^97]: OmniACT：用于启用桌面和Web多模式通用主动智能体的数据集和基准

    OmniACT: A Dataset and Benchmark for Enabling Multimodal Generalist Autonomous Agents for Desktop and Web

    [https://arxiv.org/abs/2402.17553](https://arxiv.org/abs/2402.17553)

    OmniACT是一个针对代理生成可执行程序完成计算机任务能力的数据集和基准，超越了传统Web自动化，涵盖了各种桌面应用。

    

    几十年来，人机交互从根本上一直是手动的。即使在今天，几乎所有在计算机上进行的高效工作都需要人类在每一步都提供输入。虚拟主动智能代表了自动化许多这些琐碎任务的一个激动人心的步骤。虚拟代理将使技术能力有限的用户能够充分利用计算机系统的各种可能性。它们还可以实现高效地简化许多计算机任务，从日历管理到复杂的旅行预订，减少人类干预。在这篇论文中，我们介绍了 OmniACT，这是一个用于评估代理生成可执行程序来完成计算机任务能力的首个数据集和基准。我们的范围超越了传统的Web自动化，涵盖了各种桌面应用。该数据集包含诸如"播放下一首歌"之类的基本任务，以及更为长期的任务

    arXiv:2402.17553v1 Announce Type: new  Abstract: For decades, human-computer interaction has fundamentally been manual. Even today, almost all productive work done on the computer necessitates human input at every step. Autonomous virtual agents represent an exciting step in automating many of these menial tasks. Virtual agents would empower users with limited technical proficiency to harness the full possibilities of computer systems. They could also enable the efficient streamlining of numerous computer tasks, ranging from calendar management to complex travel bookings, with minimal human intervention. In this paper, we introduce OmniACT, the first-of-a-kind dataset and benchmark for assessing an agent's capability to generate executable programs to accomplish computer tasks. Our scope extends beyond traditional web automation, covering a diverse range of desktop applications. The dataset consists of fundamental tasks such as "Play the next song", as well as longer horizon tasks such
    
[^98]: Sora: 大型视觉模型背景、技术、局限性和机遇的综述

    Sora: A Review on Background, Technology, Limitations, and Opportunities of Large Vision Models

    [https://arxiv.org/abs/2402.17177](https://arxiv.org/abs/2402.17177)

    Sora是一种文本到视频生成的人工智能模型，展示出在模拟物理世界方面的潜力，具有广泛的应用前景和挑战，未来发展具有重要意义。

    

    Sora是由OpenAI于2024年2月发布的一种文本到视频生成的人工智能模型。这个模型经过训练，可以根据文本指令生成逼真或想象的场景视频，并在模拟物理世界方面显示出潜力。本文基于公开的技术报告和逆向工程，对这个模型的背景、相关技术、应用、尚存的挑战以及文本到视频人工智能模型的未来方向进行了全面回顾。首先我们追溯了Sora的发展历程，并调查了用于构建这个"世界模拟器"的基础技术。然后，我们详细描述了Sora在从电影制作和教育到营销等多个行业中的应用和潜在影响。我们讨论了需要解决的主要挑战和局限性，以便广泛部署Sora，如确保安全和无偏见的视频生成。最后，我们讨论了Sora以及视频生成技术未来的发展。

    arXiv:2402.17177v1 Announce Type: cross  Abstract: Sora is a text-to-video generative AI model, released by OpenAI in February 2024. The model is trained to generate videos of realistic or imaginative scenes from text instructions and show potential in simulating the physical world. Based on public technical reports and reverse engineering, this paper presents a comprehensive review of the model's background, related technologies, applications, remaining challenges, and future directions of text-to-video AI models. We first trace Sora's development and investigate the underlying technologies used to build this "world simulator". Then, we describe in detail the applications and potential impact of Sora in multiple industries ranging from film-making and education to marketing. We discuss the main challenges and limitations that need to be addressed to widely deploy Sora, such as ensuring safe and unbiased video generation. Lastly, we discuss the future development of Sora and video gene
    
[^99]: 可靠的冲突多视角学习

    Reliable Conflictive Multi-View Learning

    [https://arxiv.org/abs/2402.16897](https://arxiv.org/abs/2402.16897)

    提出了可靠的冲突多视角学习（RCML）问题，开发了一种Evidential Conflictive Multi-view Learning (ECML)方法来处理具有冲突信息的多视角数据。

    

    多视角学习旨在结合多个特征，以实现对数据的更全面描述。之前的大部分工作都假设多个视图是严格对齐的。然而，现实世界中的多视角数据可能包含低质量的冲突实例，即在不同视图中显示冲突信息。为了解决这个问题，我们提出了一个新的可靠的冲突多视角学习（RCML）问题，要求模型为冲突的多视角数据提供决策结果和附加的可靠性。我们为这个问题开发了一种Evidential Conflictive Multi-view Learning (ECML)方法。

    arXiv:2402.16897v1 Announce Type: cross  Abstract: Multi-view learning aims to combine multiple features to achieve more comprehensive descriptions of data. Most previous works assume that multiple views are strictly aligned. However, real-world multi-view data may contain low-quality conflictive instances, which show conflictive information in different views. Previous methods for this problem mainly focus on eliminating the conflictive data instances by removing them or replacing conflictive views. Nevertheless, real-world applications usually require making decisions for conflictive instances rather than only eliminating them. To solve this, we point out a new Reliable Conflictive Multi-view Learning (RCML) problem, which requires the model to provide decision results and attached reliabilities for conflictive multi-view data. We develop an Evidential Conflictive Multi-view Learning (ECML) method for this problem. ECML first learns view-specific evidence, which could be termed as th
    
[^100]: 如果在一个众包数据标注管道中，GPT-4

    If in a Crowdsourced Data Annotation Pipeline, a GPT-4

    [https://arxiv.org/abs/2402.16795](https://arxiv.org/abs/2402.16795)

    本文比较了 GPT-4 和 MTurk 管道的数据标注准确性，发现尽管 MTurk 采用了最佳实践，但 GPT-4 的准确率更高，并且结合 GPT-4 和众包标签使用聚合算法可以提高准确率。

    

    最近的研究表明GPT-4在数据标注准确性方面优于在线众包工作者，尤其是来自亚马逊机械土耳其（MTurk）的工作者。然而，这些研究因偏离标准众包实践并强调个别工作者的表现而受到批评，而不是整个数据标注过程。本文比较了GPT-4和一个道德且执行良好的MTurk管道，使用415名工作者标注了来自200篇学术文章的3,177个句段，使用了CODA-19方案。两个工作者界面产生了127,080个标签，然后通过八种标签聚合算法推断出最终的标签。我们的评估结果显示，尽管采用了最佳实践，MTurk管道的最高准确率为81.5%，而GPT-4达到了83.6%。有趣的是，当将GPT-4的标签与通过先进工作者界面收集的众包标签结合起来进行聚合时，8种算法中有2种实现了更高的准确率。

    arXiv:2402.16795v1 Announce Type: cross  Abstract: Recent studies indicated GPT-4 outperforms online crowd workers in data labeling accuracy, notably workers from Amazon Mechanical Turk (MTurk). However, these studies were criticized for deviating from standard crowdsourcing practices and emphasizing individual workers' performances over the whole data-annotation process. This paper compared GPT-4 and an ethical and well-executed MTurk pipeline, with 415 workers labeling 3,177 sentence segments from 200 scholarly articles using the CODA-19 scheme. Two worker interfaces yielded 127,080 labels, which were then used to infer the final labels through eight label-aggregation algorithms. Our evaluation showed that despite best practices, MTurk pipeline's highest accuracy was 81.5%, whereas GPT-4 achieved 83.6%. Interestingly, when combining GPT-4's labels with crowd labels collected via an advanced worker interface for aggregation, 2 out of the 8 algorithms achieved an even higher accuracy (
    
[^101]: 将大型语言模型对齐到特定领域的图数据库

    Aligning Large Language Models to a Domain-specific Graph Database

    [https://arxiv.org/abs/2402.16567](https://arxiv.org/abs/2402.16567)

    该论文提出了一种将大型语言模型对齐到特定领域的图数据库的方法，通过利用ChatGPT生成NL-GQL数据对并微调LLMs，实现了两者之间的对齐。

    

    图数据库（Graph DB）被广泛应用于金融、社交网络和医药等各个领域。然而，将自然语言（NL）转换为图查询语言（GQL），通常称为NL2GQL，由于其固有复杂性和专业化特性而变得具有挑战性。一些方法试图利用大型语言模型（LLMs）来解决类似的任务，如文本转SQL。然而，在特定领域的NL2GQL任务中，缺乏特定领域的NL-GQL数据对使得难以建立LLMs和图数据库之间的对齐。为了解决这一挑战，我们提出了一个明确定义的流水线。具体地，我们利用ChatGPT基于给定的图数据库自我生成NL-GQL数据对。然后，我们使用创建的数据来对LLMs进行微调，从而实现LLMs与图数据库之间的对齐。此外，在推断过程中，我们提出了一种提取相关信息的方法。

    arXiv:2402.16567v1 Announce Type: new  Abstract: Graph Databases (Graph DB) are widely applied in various fields, including finance, social networks, and medicine. However, translating Natural Language (NL) into the Graph Query Language (GQL), commonly known as NL2GQL, proves to be challenging due to its inherent complexity and specialized nature. Some approaches have sought to utilize Large Language Models (LLMs) to address analogous tasks like text2SQL. Nevertheless, when it comes to NL2GQL taskson a particular domain, the absence of domain-specific NL-GQL data pairs makes it difficult to establish alignment between LLMs and the graph DB. To address this challenge, we propose a well-defined pipeline. Specifically, we utilize ChatGPT to create NL-GQL data pairs based on the given graph DB with self-instruct. Then, we use the created data to fine-tune LLMs, thereby achieving alignment between LLMs and the graph DB. Additionally, during inference, we propose a method that extracts relev
    
[^102]: 记忆差距：LLM 是否能通过图尔文测试？

    Memory GAPS: Would LLM pass the Tulving Test?

    [https://arxiv.org/abs/2402.16505](https://arxiv.org/abs/2402.16505)

    本文旨在探讨四十多年前的图尔文测试框架是否对LLM的记忆行为有所帮助。

    

    arXiv:2402.16505v1 公告类型：新摘要：图尔文测试旨在研究认知和回忆任务中的记忆表现。其结果有助于评估记忆的“协同引导模型”及类似RK范例在人类表现中的相关性。本文着手研究这个已有四十多年历史的框架是否能为LLM的记忆行为带来一些启示。

    arXiv:2402.16505v1 Announce Type: new  Abstract: The Tulving Test was designed to investigate memory performance in recognition and recall tasks. Its results help assess the relevance of the "Synergistic Ecphory Model" of memory and similar RK paradigms in human performance. This paper starts investigating whether the more than forty-year-old framework sheds some light on LLMs' acts of remembering.
    
[^103]: LLM推断揭示：调查与Roofline模型见解

    LLM Inference Unveiled: Survey and Roofline Model Insights

    [https://arxiv.org/abs/2402.16363](https://arxiv.org/abs/2402.16363)

    本文提出了一个基于Roofline模型的框架，用于系统分析LLM推断技术，帮助识别部署中的瓶颈，并为更有效地部署LLM提供策略。

    

    高效大语言模型（LLM）推断领域正在迅速发展，提供了机遇和挑战的独特结合。虽然该领域已经扩展并充满活力，但至今还没有一个简明的框架来分析LLM推断的各种方法，以便清晰地理解这一领域。我们的调查不仅总结了当前研究现状，还基于Roofline模型引入了一个框架，用于系统分析LLM推断技术。这一框架能够帮助识别LLM部署中的瓶颈，并更深入地了解在实际设备上的实际方面，从而为部署LLM提供更有效的策略。此外，我们还系统地汇总了高效LLM推断的最新进展，涵盖关键领域，比如权重优化（如知识蒸馏和量化）。

    arXiv:2402.16363v1 Announce Type: cross  Abstract: The field of efficient Large Language Model (LLM) inference is rapidly evolving, presenting a unique blend of opportunities and challenges. Although the field has expanded and is vibrant, there hasn't been a concise framework that analyzes the various methods of LLM Inference to provide a clear understanding of this domain. Our survey stands out from traditional literature reviews by not only summarizing the current state of research but also by introducing a framework based on roofline model for systematic analysis of LLM inference techniques. This framework enables identifying the bottlenecks in LLM deployments and provides a deeper understanding of the practical aspects on real devices, thereby informing more effective strategies for deploying LLM. Furthermore, we systematically collate the latest advancements in efficient LLM inference, covering crucial areas such as weight optimization (e.g., Knowledge Distillation and Quantizatio
    
[^104]: 一种使用注释嵌入模型的本体包含关系预测自匹配训练方法

    A Self-matching Training Method with Annotation Embedding Models for Ontology Subsumption Prediction

    [https://arxiv.org/abs/2402.16278](https://arxiv.org/abs/2402.16278)

    提出了一种自匹配训练方法，通过两种本体嵌入模型捕获全局和局部信息，提高了概念子类预测的稳健性

    

    最近，提出了一种在低维空间中表示实体的本体嵌入，用于本体完成。然而，用于概念子类预测的本体嵌入未解决类似和孤立实体的困难，并且未提取本体中注释公理的全局信息。本文提出了一种针对两种本体嵌入模型的自匹配训练方法：Inverted-index Matrix Embedding (InME) 和 Co-occurrence Matrix Embedding (CoME)。这两种嵌入通过每个单词在一组公理中出现的位置以及每个公理中单词的共现来捕获注释公理中的全局和局部信息。自匹配训练方法提高了概念子类预测的稳健性，当预测的超类与子类相似且孤立于本体中的其他实体时。

    arXiv:2402.16278v1 Announce Type: new  Abstract: Recently, ontology embeddings representing entities in a low-dimensional space have been proposed for ontology completion. However, the ontology embeddings for concept subsumption prediction do not address the difficulties of similar and isolated entities and fail to extract the global information of annotation axioms from an ontology. In this paper, we propose a self-matching training method for the two ontology embedding models: Inverted-index Matrix Embedding (InME) and Co-occurrence Matrix Embedding (CoME). The two embeddings capture the global and local information in annotation axioms by means of the occurring locations of each word in a set of axioms and the co-occurrences of words in each axiom. The self-matching training method increases the robustness of the concept subsumption prediction when predicted superclasses are similar to subclasses and are isolated to other entities in an ontology. Our evaluation experiments show that
    
[^105]: 机器学习资产管理挑战的实证研究

    An Empirical Study of Challenges in Machine Learning Asset Management

    [https://arxiv.org/abs/2402.15990](https://arxiv.org/abs/2402.15990)

    通过分析开发者论坛和平台上的帖子，研究揭示了与机器学习资产管理挑战相关的133个主题，其中最重要的包括软件依赖、模型部署和模型训练。

    

    在机器学习（ML）中，高效的资产管理，包括ML模型、数据集、算法和工具，对于资源优化、持续性能和简化的开发生命周期至关重要。这使得快速迭代、适应性、减少开发到部署时间以及可靠的输出成为可能。尽管存在研究，但在诸如模型版本控制、数据可追溯性和协作等操作挑战方面仍存在重要的知识差距，这对ML项目的成功至关重要。我们的研究旨在通过分析来自开发者论坛和平台的15,065个帖子，采用混合方法来分类查询，利用BERTopic提取挑战，并通过开放式卡片排序和BERTopic聚类识别解决方案。我们发现了133个与资产管理挑战相关的主题，分成16个宏主题，其中软件依赖、模型部署和模型训练是最重要的。

    arXiv:2402.15990v1 Announce Type: cross  Abstract: In machine learning (ML), efficient asset management, including ML models, datasets, algorithms, and tools, is vital for resource optimization, consistent performance, and a streamlined development lifecycle. This enables quicker iterations, adaptability, reduced development-to-deployment time, and reliable outputs. Despite existing research, a significant knowledge gap remains in operational challenges like model versioning, data traceability, and collaboration, which are crucial for the success of ML projects. Our study aims to address this gap by analyzing 15,065 posts from developer forums and platforms, employing a mixed-method approach to classify inquiries, extract challenges using BERTopic, and identify solutions through open card sorting and BERTopic clustering. We uncover 133 topics related to asset management challenges, grouped into 16 macro-topics, with software dependency, model deployment, and model training being the mo
    
[^106]: 基于注意力机制的 GAN 在异常检测中的应用：网络安全威胁管理的前沿方法

    Attention-GAN for Anomaly Detection: A Cutting-Edge Approach to Cybersecurity Threat Management

    [https://arxiv.org/abs/2402.15945](https://arxiv.org/abs/2402.15945)

    该研究提出了一种基于注意力机制的 GAN 框架，用于增强网络安全性，重点关注异常检测，通过生成多样且逼真的合成攻击场景来改进威胁识别和解决数据稀缺性问题。

    

    本文提出了一种创新的基于注意力机制的 GAN 框架，用于增强网络安全性，重点关注异常检测。针对网络威胁不断演变带来的挑战，所提出的方法旨在生成多样且逼真的合成攻击场景，从而丰富数据集并改进威胁识别。将注意力机制与生成对抗网络（GANs）相结合是该方法的关键特点。注意力机制增强了模型聚焦于相关特征的能力，对于检测微妙和复杂的攻击模式至关重要。此外，GANs通过生成额外多样的攻击数据，涵盖已知和新兴的威胁，解决了数据稀缺性问题。这种双重方法确保系统能够应对不断演变的网络攻击保持相关性和有效性。KDD Cup 和 CICIDS2017 数据集用于验证该方法。

    arXiv:2402.15945v1 Announce Type: cross  Abstract: This paper proposes an innovative Attention-GAN framework for enhancing cybersecurity, focusing on anomaly detection. In response to the challenges posed by the constantly evolving nature of cyber threats, the proposed approach aims to generate diverse and realistic synthetic attack scenarios, thereby enriching the dataset and improving threat identification. Integrating attention mechanisms with Generative Adversarial Networks (GANs) is a key feature of the proposed method. The attention mechanism enhances the model's ability to focus on relevant features, essential for detecting subtle and complex attack patterns. In addition, GANs address the issue of data scarcity by generating additional varied attack data, encompassing known and emerging threats. This dual approach ensures that the system remains relevant and effective against the continuously evolving cyberattacks. The KDD Cup and CICIDS2017 datasets were used to validate this m
    
[^107]: 多臂攻击的最佳零射击探测器

    Optimal Zero-Shot Detector for Multi-Armed Attacks

    [https://arxiv.org/abs/2402.15808](https://arxiv.org/abs/2402.15808)

    本文提出了一种创新的信息论防御方法，通过最优地汇总现有探测器做出的决策，消除了对训练数据的需求。

    

    本文探讨了恶意参与者采用多臂攻击策略操纵数据样本的情况，为其提供了各种方式向数据集中引入噪音。我们的主要目标是通过检测任何对输入的更改来保护数据。我们在防御策略中极度谨慎，操作在防守者拥有信息明显少于攻击者的环境中。具体而言，防守者无法利用任何数据样本来训练防御模型或验证信道的完整性。相反，防守者完全依赖一组现成的“即插即用”探测器。为了解决这一挑战，我们提出了一种创新的信息论防御方法，通过最优地汇总这些探测器做出的决策，从而消除了对任何训练数据的需求。我们进一步探讨了一个实际的使用案例场景。

    arXiv:2402.15808v1 Announce Type: cross  Abstract: This paper explores a scenario in which a malicious actor employs a multi-armed attack strategy to manipulate data samples, offering them various avenues to introduce noise into the dataset. Our central objective is to protect the data by detecting any alterations to the input. We approach this defensive strategy with utmost caution, operating in an environment where the defender possesses significantly less information compared to the attacker. Specifically, the defender is unable to utilize any data samples for training a defense model or verifying the integrity of the channel. Instead, the defender relies exclusively on a set of pre-existing detectors readily available ``off the shelf''. To tackle this challenge, we derive an innovative information-theoretic defense approach that optimally aggregates the decisions made by these detectors, eliminating the need for any training data. We further explore a practical use-case scenario fo
    
[^108]: 大规模生成式人工智能文本在体育和音乐领域的应用

    Large Scale Generative AI Text Applied to Sports and Music

    [https://arxiv.org/abs/2402.15514](https://arxiv.org/abs/2402.15514)

    这项工作利用生成式人工智能模型将大规模多模数据转化为连贯流畅文本，首次推出了用于体育和音乐领域的AI评论系统，并取得了显著性能提升。

    

    我们解决了将媒体内容（包括评论和个性化新闻报道）扩展到全球大型体育和音乐活动的生产问题。我们的方法依赖生成式人工智能模型，将大量多模数据（例如视频、文章、实时比分、统计数据和资料）转换为连贯流畅的文本。基于这一方法，我们首次推出了一款人工智能评论系统，该系统被部署用于为2023年美国公开赛、温布尔登公开赛和大师赛的精彩片段制作自动化叙述。我们的解决方案还被扩展用于为ESPN梦幻橄榄球和格莱美奖音乐艺术家故事创造个性化内容。这些应用程序采用了相同的软件架构，实现了15倍的速度提升，平均Rouge-L为82.00，困惑度为6.6。

    arXiv:2402.15514v1 Announce Type: cross  Abstract: We address the problem of scaling up the production of media content, including commentary and personalized news stories, for large-scale sports and music events worldwide. Our approach relies on generative AI models to transform a large volume of multimodal data (e.g., videos, articles, real-time scoring feeds, statistics, and fact sheets) into coherent and fluent text. Based on this approach, we introduce, for the first time, an AI commentary system, which was deployed to produce automated narrations for highlight packages at the 2023 US Open, Wimbledon, and Masters tournaments. In the same vein, our solution was extended to create personalized content for ESPN Fantasy Football and stories about music artists for the Grammy awards. These applications were built using a common software architecture achieved a 15x speed improvement with an average Rouge-L of 82.00 and perplexity of 6.6. Our work was successfully deployed at the aforeme
    
[^109]: Text2Pic Swift：增强大规模库中长文本到图像的检索

    Text2Pic Swift: Enhancing Long-Text to Image Retrieval for Large-Scale Libraries

    [https://arxiv.org/abs/2402.15276](https://arxiv.org/abs/2402.15276)

    Text2Pic Swift框架针对大规模库中文本描述到图像的检索提出了一种高效且强大的方法，通过两阶段策略解决了长文本查询中的歧义问题

    

    arXiv:2402.15276v1 公告类型：跨领域 摘要：文本到图像检索在各种应用中起着至关重要的作用，包括数字图书馆、电子商务平台和多媒体数据库，通过使用文本查询来搜索图像。尽管多模态大语言模型（MLLMs）取得了先进的性能，但它们在大规模、多样化和模糊的检索场景中的适用性受到显着的计算需求和生成可注入的嵌入所限制。本文介绍了Text2Pic Swift框架，专为在庞大的数据集中有效和稳健地检索与广泛文本描述对应的图像而设计。该框架采用了两阶段方法：初始基于实体的排序（ER）阶段通过多查询对多目标的策略来解决长文本查询中固有的歧义，从而有效地缩小了可能的候选项，以便进行后续分析。接下来

    arXiv:2402.15276v1 Announce Type: cross  Abstract: Text-to-image retrieval plays a crucial role across various applications, including digital libraries, e-commerce platforms, and multimedia databases, by enabling the search for images using text queries. Despite the advancements in Multimodal Large Language Models (MLLMs), which offer leading-edge performance, their applicability in large-scale, varied, and ambiguous retrieval scenarios is constrained by significant computational demands and the generation of injective embeddings. This paper introduces the Text2Pic Swift framework, tailored for efficient and robust retrieval of images corresponding to extensive textual descriptions in sizable datasets. The framework employs a two-tier approach: the initial Entity-based Ranking (ER) stage addresses the ambiguity inherent in lengthy text queries through a multiple-queries-to-multiple-targets strategy, effectively narrowing down potential candidates for subsequent analysis. Following thi
    
[^110]: 连续时间扩散模型的微调作为熵正则化控制

    Fine-Tuning of Continuous-Time Diffusion Models as Entropy-Regularized Control

    [https://arxiv.org/abs/2402.15194](https://arxiv.org/abs/2402.15194)

    扩散模型的微调方法可以通过最大化奖励函数的价值来以目标导向方式进行微调，但可能会面临奖励崩溃的挑战。

    

    扩散模型在捕捉复杂数据分布方面表现出色，例如自然图像和蛋白质的分布。虽然扩散模型经过训练可代表训练数据集中的分布，但我们通常更关注其他属性，例如生成图像的美学质量或生成蛋白质的功能属性。扩散模型可以通过最大化某些奖励函数的价值（例如图像的美学质量）以目标导向的方式进行微调。然而，这些方法可能会导致样本多样性减少，与训练数据分布出现显著偏差，甚至由于利用不完美的奖励函数而导致样本质量较差。在许多实际应用中奖励函数是用于近似真实“真实”奖励的学习模型时，最后一个问题经常会产生。这些挑战总称为“奖励崩溃”。

    arXiv:2402.15194v1 Announce Type: cross  Abstract: Diffusion models excel at capturing complex data distributions, such as those of natural images and proteins. While diffusion models are trained to represent the distribution in the training dataset, we often are more concerned with other properties, such as the aesthetic quality of the generated images or the functional properties of generated proteins. Diffusion models can be finetuned in a goal-directed way by maximizing the value of some reward function (e.g., the aesthetic quality of an image). However, these approaches may lead to reduced sample diversity, significant deviations from the training data distribution, and even poor sample quality due to the exploitation of an imperfect reward function. The last issue often occurs when the reward function is a learned model meant to approximate a ground-truth "genuine" reward, as is the case in many practical applications. These challenges, collectively termed "reward collapse," pose
    
[^111]: 面向空间感知的变压器记忆体用于体验代理

    Spatially-Aware Transformer Memory for Embodied Agents

    [https://arxiv.org/abs/2402.15160](https://arxiv.org/abs/2402.15160)

    本文探讨了利用包含空间信息的面向空间感知变压器模型，以改善记忆利用效率。

    

    情节记忆在各种认知过程中起着至关重要的作用，比如能够在头脑中回忆过去事件的能力。虽然认知科学强调空间上下文在情节记忆的形成和检索中的重要性，但当前实现人工智能系统中情节记忆的主要方法是通过存储时间顺序体验的变压器，这忽略了空间维度。因此，目前尚不清楚如何将基础结构扩展到除了仅有时间顺序之外的空间轴，并由此能够获得哪些好处。为了解决这个问题，本文探讨了利用包含空间信息的面向空间感知变压器模型。这些模型使得可以创建考虑时间和空间维度的场所中心情节记忆。采用这种方法，我们证明记忆利用效率可以得到提高，导致增强

    arXiv:2402.15160v1 Announce Type: cross  Abstract: Episodic memory plays a crucial role in various cognitive processes, such as the ability to mentally recall past events. While cognitive science emphasizes the significance of spatial context in the formation and retrieval of episodic memory, the current primary approach to implementing episodic memory in AI systems is through transformers that store temporally ordered experiences, which overlooks the spatial dimension. As a result, it is unclear how the underlying structure could be extended to incorporate the spatial axis beyond temporal order alone and thereby what benefits can be obtained. To address this, this paper explores the use of Spatially-Aware Transformer models that incorporate spatial information. These models enable the creation of place-centric episodic memory that considers both temporal and spatial dimensions. Adopting this approach, we demonstrate that memory utilization efficiency can be improved, leading to enhanc
    
[^112]: 多利益相关者视角下的负责任人工智能与教育可接受性研究

    Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education

    [https://arxiv.org/abs/2402.15027](https://arxiv.org/abs/2402.15027)

    本研究从多利益相关者视角探讨了教育中不同人工智能应用的可接受性，关注数据隐私、AI代理、透明度、可解释性和道德部署等问题。

    

    本研究从多利益相关者的视角，包括学生、教师和家长，调查了教育中不同人工智能（AI）应用的可接受性。认识到人工智能在教育中的变革潜力，它关注了与数据隐私、AI代理、透明度、可解释性以及道德部署有关的问题。通过创景方法，参与者被呈现了四个场景，其中AI的代理、透明度、可解释性和隐私遭到操纵。在每个场景后，参与者完成了一个调查问卷，其中捕捉了他们对AI的全球效用、个人实用性、公正性、信心、风险以及若每个场景的AI可用话，他们打算使用的意图。数据收集涵盖了最终样本量为1198名多利益相关者参与者，通过一个合作机构和社交媒体活动分发，并重点关注了对四个场景的个体回应。

    arXiv:2402.15027v1 Announce Type: cross  Abstract: This study investigates the acceptability of different artificial intelligence (AI) applications in education from a multi-stakeholder perspective, including students, teachers, and parents. Acknowledging the transformative potential of AI in education, it addresses concerns related to data privacy, AI agency, transparency, explainability and the ethical deployment of AI. Through a vignette methodology, participants were presented with four scenarios where AI's agency, transparency, explainability, and privacy were manipulated. After each scenario, participants completed a survey that captured their perceptions of AI's global utility, individual usefulness, justice, confidence, risk, and intention to use each scenario's AI if available. The data collection comprising a final sample of 1198 multi-stakeholder participants was distributed through a partner institution and social media campaigns and focused on individual responses to four 
    
[^113]: 利用非正式逻辑增强系统化分解的自然语言推理

    Enhancing Systematic Decompositional Natural Language Inference Using Informal Logic

    [https://arxiv.org/abs/2402.14798](https://arxiv.org/abs/2402.14798)

    本文提出了一种一致且在理论上有根据的方法来注释分解蕴涵数据集，形成RDTE数据集，该数据集在解决何为有效的组合蕴涵的问题上有显著进展。

    

    当代语言模型为使用文本进行结构化推理提供了新的机会，例如在不依赖脆弱的形式逻辑的情况下构建和评估直观的、类似证明的文本蕴涵树。然而，沿着这个方向的进展受到一个长期以来缺乏明确的确定何为有效的组合蕴涵的清晰协议的阻碍。本文提出了一个一致且在理论上有根据的方法来注释分解蕴涵数据集，并评估其对基于LLM的文本推理的影响。我们发现，我们的结果数据集RDTE (Recognizing Decompositional Textual Entailment) 的内部一致性比先前的分解蕴涵数据集高得多（+9%），表明RDTE在长期存在的关于何为有效的组合蕴涵的问题上是一个重要的进步。

    arXiv:2402.14798v1 Announce Type: cross  Abstract: Contemporary language models enable new opportunities for structured reasoning with text, such as the construction and evaluation of intuitive, proof-like textual entailment trees without relying on brittle formal logic. However, progress in this direction has been hampered by a long-standing lack of a clear protocol for determining what valid compositional entailment is. This absence causes noisy datasets and limited performance gains by modern neuro-symbolic engines. To address these problems, we formulate a consistent and theoretically grounded approach to annotating decompositional entailment datasets, and evaluate its impact on LLM-based textual inference. We find that our resulting dataset, RDTE (Recognizing Decompositional Textual Entailment), has a substantially higher internal consistency (+9%) than prior decompositional entailment datasets, suggesting that RDTE is a significant step forward in the long-standing problem of for
    
[^114]: OpenCodeInterpreter：集成代码生成、执行和细化

    OpenCodeInterpreter: Integrating Code Generation with Execution and Refinement

    [https://arxiv.org/abs/2402.14658](https://arxiv.org/abs/2402.14658)

    OpenCodeInterpreter是一种开源代码系统，集成了执行、人类反馈和动态代码细化的功能，并在关键基准测试中表现出色，甚至与GPT-4相媲美。

    

    大型语言模型的引入显著推动了代码生成的发展。然而，开源模型通常缺乏类似GPT-4 Code Interpreter这样的高级系统的执行能力和迭代细化能力。为了解决这一问题，我们介绍了OpenCodeInterpreter，这是一族旨在生成、执行和迭代细化代码的开源代码系统。通过Code-Feedback支持，该系统集成了执行和人类反馈，用于动态代码细化。我们对OpenCodeInterpreter在诸如HumanEval、MBPP以及它们来自EvalPlus的增强版本等关键基准上进行了全面评估，证实了其出色的性能。值得注意的是，OpenCodeInterpreter-33B在HumanEval和MBPP的平均值（以及其增强版本）上取得了83.2（76.4）的准确率，与GPT-4的84.2（76.2）紧密匹敌，并且通过合成hum

    arXiv:2402.14658v1 Announce Type: cross  Abstract: The introduction of large language models has significantly advanced code generation. However, open-source models often lack the execution capabilities and iterative refinement of advanced systems like the GPT-4 Code Interpreter. To address this, we introduce OpenCodeInterpreter, a family of open-source code systems designed for generating, executing, and iteratively refining code. Supported by Code-Feedback, a dataset featuring 68K multi-turn interactions, OpenCodeInterpreter integrates execution and human feedback for dynamic code refinement. Our comprehensive evaluation of OpenCodeInterpreter across key benchmarks such as HumanEval, MBPP, and their enhanced versions from EvalPlus reveals its exceptional performance. Notably, OpenCodeInterpreter-33B achieves an accuracy of 83.2 (76.4) on the average (and plus versions) of HumanEval and MBPP, closely rivaling GPT-4's 84.2 (76.2) and further elevates to 91.6 (84.6) with synthesized hum
    
[^115]: 跨架构零样本泛化的视觉分类

    Zero-shot generalization across architectures for visual classification

    [https://arxiv.org/abs/2402.14095](https://arxiv.org/abs/2402.14095)

    不同神经网络在跨架构和层间泛化到未知类别的能力存在差异，准确性并不是泛化能力的良好预测因子，泛化能力随着层深度呈非单调变化。

    

    深度网络的一个关键优势是对未见数据的泛化能力，但其与分类准确性的关系尚不清楚。我们利用一种极简的视觉数据集和一种泛化度量，展示了从深度卷积网络（CNNs）到transformers的流行网络在通过层和架构泛化到未见类别方面的能力存在差异。准确性并不是泛化能力的良好预测因子，并且泛化能力随着层深度呈非单调变化。代码可在https://github.com/dyballa/zero-shot-generalization 找到。

    arXiv:2402.14095v1 Announce Type: cross  Abstract: Generalization to unseen data is a key desideratum for deep networks, but its relation to classification accuracy is unclear. Using a minimalist vision dataset and a measure of generalizability, we show that popular networks, from deep convolutional networks (CNNs) to transformers, vary in their power to extrapolate to unseen classes both across layers and across architectures. Accuracy is not a good predictor of generalizability, and generalization varies non-monotonically with layer depth. Code is available at https://github.com/dyballa/zero-shot-generalization.
    
[^116]: 强化学习辅助的变分量子算法量子架构搜索

    Reinforcement learning-assisted quantum architecture search for variational quantum algorithms

    [https://arxiv.org/abs/2402.13754](https://arxiv.org/abs/2402.13754)

    通过强化学习自动搜索变分电路的最佳结构，改善了VQAs的性能。

    

    在嘈杂中等规模量子（NISQ）时代，一个重要障碍是确定功能性量子电路。这些电路必须同时符合当前量子硬件限制所施加的约束。变分量子算法（VQA）是一类量子-经典优化算法，旨在解决当前可用量子设备中的这些挑战。本论文侧重于电路结构，通过使用强化学习（RL）自动搜索变分电路的最优结构，改善了VQAs的性能。论文内通过评估电路的深度、门和参数的总数以及准确性来确定电路的优越性。

    arXiv:2402.13754v1 Announce Type: cross  Abstract: A significant hurdle in the noisy intermediate-scale quantum (NISQ) era is identifying functional quantum circuits. These circuits must also adhere to the constraints imposed by current quantum hardware limitations. Variational quantum algorithms (VQAs), a class of quantum-classical optimization algorithms, were developed to address these challenges in the currently available quantum devices. However, the overall performance of VQAs depends on the initialization strategy of the variational circuit, the structure of the circuit (also known as ansatz), and the configuration of the cost function. Focusing on the structure of the circuit, in this thesis, we improve the performance of VQAs by automating the search for an optimal structure for the variational circuits using reinforcement learning (RL). Within the thesis, the optimality of a circuit is determined by evaluating its depth, the overall count of gates and parameters, and its accu
    
[^117]: 任务待办：用于高分辨率图像高效生成的令牌下采样

    ToDo: Token Downsampling for Efficient Generation of High-Resolution Images

    [https://arxiv.org/abs/2402.13573](https://arxiv.org/abs/2402.13573)

    提出了一种新的训练-free 方法 ToDo，通过令牌下采样加速 Stable Diffusion 推理，以实现高分辨率图像的高效生成。

    

    注意力机制对于图像扩散模型至关重要，然而，它们的二次计算复杂性限制了我们可以在合理时间和内存限制内处理的图像大小。本文研究了在生成图像模型中密集注意力的重要性，这些模型通常包含冗余特征，使它们适合稀疏注意力机制。我们提出了一种新颖的无需训练的方法 ToDo，该方法依赖于关键和值令牌的令牌下采样，可将常见大小的 Stable Diffusion 推理加速至多达2倍，对于2048x2048等高分辨率，加速比可达4.5倍或更高。我们证明了我们的方法在平衡高效吞吐量和保真度方面优于先前的方法。

    arXiv:2402.13573v1 Announce Type: cross  Abstract: Attention mechanism has been crucial for image diffusion models, however, their quadratic computational complexity limits the sizes of images we can process within reasonable time and memory constraints. This paper investigates the importance of dense attention in generative image models, which often contain redundant features, making them suitable for sparser attention mechanisms. We propose a novel training-free method ToDo that relies on token downsampling of key and value tokens to accelerate Stable Diffusion inference by up to 2x for common sizes and up to 4.5x or more for high resolutions like 2048x2048. We demonstrate that our approach outperforms previous methods in balancing efficient throughput and fidelity.
    
[^118]: 针对音乐生成的结构感知位置编码

    Structure-informed Positional Encoding for Music Generation

    [https://arxiv.org/abs/2402.13301](https://arxiv.org/abs/2402.13301)

    提出了一种针对音乐生成的结构感知位置编码框架，通过绝对、相对和非平稳位置信息，显著改善了生成作品的旋律和结构一致性。

    

    由深度学习方法生成的音乐往往缺乏连贯性和长期组织，而多尺度层次结构是音乐信号的显著特征。为了利用这一信息，我们提出了一种针对Transformer音乐生成的结构感知位置编码框架。我们设计了三种变体，涉及绝对、相对和非平稳位置信息。我们在两个符号音乐生成任务上对它们进行了全面测试：下一个时间步预测和伴奏生成。作为对比，我们选择了文献中的多个基线，使用几个以音乐为动机的评估指标展示了我们方法的优点。特别是，我们的方法改善了生成作品的旋律和结构一致性。

    arXiv:2402.13301v1 Announce Type: cross  Abstract: Music generated by deep learning methods often suffers from a lack of coherence and long-term organization. Yet, multi-scale hierarchical structure is a distinctive feature of music signals. To leverage this information, we propose a structure-informed positional encoding framework for music generation with Transformers. We design three variants in terms of absolute, relative and non-stationary positional information. We comprehensively test them on two symbolic music generation tasks: next-timestep prediction and accompaniment generation. As a comparison, we choose multiple baselines from the literature and demonstrate the merits of our methods using several musically-motivated evaluation metrics. In particular, our methods improve the melodic and structural consistency of the generated pieces.
    
[^119]: 为什么问题的动态视角

    A Dynamical View of the Question of Why

    [https://arxiv.org/abs/2402.10240](https://arxiv.org/abs/2402.10240)

    提出了一种在时间过程中直接建立事件之间因果关系的学习范式，并提出了用于计算因果贡献的两个关键引理，可以揭示和量化扩散过程中的因果关系。

    

    我们研究由随机过程生成的多元时间序列数据中的因果推理。现有方法主要局限于静态设置，忽略了时间上的连续性和变化的发射。相比之下，我们提出了一个学习范式，直接在时间过程中建立事件之间的因果关系。我们提出了两个关键引理来计算因果贡献，并将其构造为强化学习问题。我们的方法提供了揭示和量化扩散过程中因果关系的形式化和计算工具，包括各种重要设置，如离散时间马尔可夫决策过程。最后，通过相当复杂的实验和通过纯学习，我们的框架揭示和量化了因果联系，否则看似莫名其妙。

    arXiv:2402.10240v1 Announce Type: cross  Abstract: We address causal reasoning in multivariate time series data generated by stochastic processes. Existing approaches are largely restricted to static settings, ignoring the continuity and emission of variations across time. In contrast, we propose a learning paradigm that directly establishes causation between events in the course of time. We present two key lemmas to compute causal contributions and frame them as reinforcement learning problems. Our approach offers formal and computational tools for uncovering and quantifying causal relationships in diffusion processes, subsuming various important settings such as discrete-time Markov decision processes. Finally, in fairly intricate experiments and through sheer learning, our framework reveals and quantifies causal links, which otherwise seem inexplicable.
    
[^120]: HyperAgent：一种简单、可扩展、高效且可证明用于复杂环境的强化学习框架

    HyperAgent: A Simple, Scalable, Efficient and Provable Reinforcement Learning Framework for Complex Environments

    [https://arxiv.org/abs/2402.10228](https://arxiv.org/abs/2402.10228)

    HyperAgent提出了一种简单、高效、可扩展的强化学习框架，在复杂环境下能够实现高效的计算和数据选择，是首个达到可证明可扩展的每步计算复杂度以及次线性后悔的方法。

    

    为了在资源约束下解决复杂任务，强化学习（RL）代理需要简单、高效、可扩展、具有大状态空间和不断积累的交互数据。我们提出了HyperAgent，这是一个具有超模型、索引抽样方案和增量更新机制的RL框架，可以在一般价值函数逼近中进行计算高效的顺序后验逼近和数据高效的动作选择，超越了共轭性。HyperAgent的实现简单，只需要在DDQN中添加一个模块和一行额外代码。在实践中，HyperAgent在大规模深度RL基准测试中表现出稳健的性能，无论是在数据还是计算方面都获得了显着的效率提升。在理论上，在实际可扩展的算法中，HyperAgent是第一个能够实现可证明可扩展的每步计算复杂度以及次线性后悔的方法。

    arXiv:2402.10228v1 Announce Type: cross  Abstract: To solve complex tasks under resource constraints, reinforcement learning (RL) agents need to be simple, efficient, and scalable with (1) large state space and (2) increasingly accumulated data of interactions. We propose the HyperAgent, a RL framework with hypermodel, index sampling schemes and incremental update mechanism, enabling computation-efficient sequential posterior approximation and data-efficient action selection under general value function approximation beyond conjugacy. The implementation of \HyperAgent is simple as it only adds one module and one line of code additional to DDQN. Practically, HyperAgent demonstrates its robust performance in large-scale deep RL benchmarks with significant efficiency gain in terms of both data and computation. Theoretically, among the practically scalable algorithms, HyperAgent is the first method to achieve provably scalable per-step computational complexity as well as sublinear regret u
    
[^121]: GraphTranslator：将图模型与大型语言模型对齐用于开放式任务

    GraphTranslator: Aligning Graph Model to Large Language Model for Open-ended Tasks

    [https://arxiv.org/abs/2402.07197](https://arxiv.org/abs/2402.07197)

    "GraphTranslator"是一个旨在将预训练的图模型和大型语言模型对齐的翻译器，可以同时处理预定义任务和开放式任务。通过将这两种模型结合起来，能够有效地处理各种任务，并实现更具创新性和灵活性的应用。

    

    大型语言模型（LLMs）如ChatGPT，展示了强大的零样本和遵循指令的能力，在人工智能的各个研究领域中引发了一场革命性的转变，尤其是对于开放式任务。尽管在图领域中这个想法较少被探索，尽管有许多强大的图模型（GMs）可用，但它们被限制在预定义形式的任务中。虽然已经提出了几种将LLMs应用于图的方法，但它们未能同时处理预定义任务和开放式任务，无论是将LLMs作为节点特征增强器还是作为独立预测器。为了打破这个困境，我们提出了一个名为GraphTranslator的翻译器，旨在通过预训练的GM和LLMs之间的桥梁，有效地处理预定义任务，并利用LLMs的扩展接口为GM提供各种开放式任务。为了训练这样的翻译器，我们提出了一个称为Producer的构建图文对齐数据的工具。

    Large language models (LLMs) like ChatGPT, exhibit powerful zero-shot and instruction-following capabilities, have catalyzed a revolutionary transformation across diverse research fields of artificial intelligence, especially for open-ended tasks. While the idea is less explored in the graph domain, despite the availability of numerous powerful graph models (GMs), they are restricted to tasks in a pre-defined form. Although several methods applying LLMs to graphs have been proposed, they fail to simultaneously handle the pre-defined and open-ended tasks, with LLM as a node feature enhancer or as a standalone predictor. To break this dilemma, we propose to bridge the pretrained GM and LLM by a Translator, named GraphTranslator, aiming to leverage GM to handle the pre-defined tasks effectively and utilize the extended interface of LLMs to offer various open-ended tasks for GM. To train such Translator, we propose a Producer capable of constructing the graph-text alignment data along node
    
[^122]: 研究指令调整的局限性

    A Closer Look at the Limitations of Instruction Tuning

    [https://arxiv.org/abs/2402.05119](https://arxiv.org/abs/2402.05119)

    本文通过实验和分析揭示了指令调整的多个局限性，包括无法增强LLM的知识和技能、从具有知识来源的数据集复制回应模式导致质量下降、全参数微调增加了错误生成的情况。

    

    指令调整（IT）是使用指令-回应对来训练大型语言模型（LLM）的过程，已成为将基础预训练LLM转化为开放领域对话代理的主要方法。虽然IT取得了显著的成功并广泛应用，但其局限性和不足仍未得到充分探讨。本文通过严格的实验和对LLM通过IT发生的变化的深入分析，揭示了IT的多种局限性。特别是，我们发现：（1）IT无法增强LLM的知识或技能。LoRA微调仅限于学习回应的启动和样式令牌，而全参数微调会导致知识退化。（2）从具有知识来源的IT数据集复制回应模式会导致回应质量下降。（3）全参数微调通过不准确地从IT数据集中获取概念上相似实例的标记，增加了错误生成的情况。

    Instruction Tuning (IT), the process of training large language models (LLMs) using instruction-response pairs, has emerged as the predominant method for transforming base pre-trained LLMs into open-domain conversational agents. While IT has achieved notable success and widespread adoption, its limitations and shortcomings remain underexplored. In this paper, through rigorous experiments and an in-depth analysis of the changes LLMs undergo through IT, we reveal various limitations of IT. In particular, we show that (1) IT fails to enhance knowledge or skills in LLMs. LoRA fine-tuning is limited to learning response initiation and style tokens, and full-parameter fine-tuning leads to knowledge degradation. (2) Copying response patterns from IT datasets derived from knowledgeable sources leads to a decline in response quality. (3) Full-parameter fine-tuning increases hallucination by inaccurately borrowing tokens from conceptually similar instances in the IT dataset for generating respon
    
[^123]: 大规模多机器人覆盖路径规划的局部搜索方法

    Large-Scale Multi-Robot Coverage Path Planning via Local Search

    [https://arxiv.org/abs/2312.10797](https://arxiv.org/abs/2312.10797)

    该论文提出了一种新的算法框架LS-MCPP，通过局部搜索直接在分解图上操作，以探索如何系统地搜索地形图上的良好覆盖路径。

    

    我们研究了基于图的多机器人覆盖路径规划（MCPP），旨在为多个机器人计算覆盖给定2D网格地形图$G$的所有顶点的覆盖路径。现有的基于图的MCPP算法首先在$G$上计算树覆盖，即覆盖所有顶点的多棵树，然后采用生成覆盖路径的跨越树覆盖（STC）范式，通过绕行计算树的边在地形图$G$的分解图$D$上生成覆盖路径，旨在优化最大覆盖路径成本（即所有机器人中的最大覆盖路径成本）。

    arXiv:2312.10797v2 Announce Type: replace-cross  Abstract: We study graph-based Multi-Robot Coverage Path Planning (MCPP) that aims to compute coverage paths for multiple robots to cover all vertices of a given 2D grid terrain graph $G$. Existing graph-based MCPP algorithms first compute a tree cover on $G$ -- a forest of multiple trees that cover all vertices -- and then employ the Spanning Tree Coverage (STC) paradigm to generate coverage paths on the decomposed graph $D$ of the terrain graph $G$ by circumnavigating the edges of the computed trees, aiming to optimize the makespan (i.e., the maximum coverage path cost among all robots). In this paper, we take a different approach by exploring how to systematically search for good coverage paths directly on $D$. We introduce a new algorithmic framework, called LS-MCPP, which leverages a local search to operate directly on $D$. We propose a novel standalone paradigm, Extended-STC (ESTC), that extends STC to achieve complete coverage for
    
[^124]: 可扩展和快速模拟推断的一致性模型

    Consistency Models for Scalable and Fast Simulation-Based Inference

    [https://arxiv.org/abs/2312.05440](https://arxiv.org/abs/2312.05440)

    提出了一种新的神经后验估计的一致性模型，结合了标准化流和流匹配方法的优点，用于可扩展、快速和摊销推断，在多个实验中展示出优越性能。

    

    仿真推断（SBI）不断寻找更具表现力的算法，以准确推断复杂模型的参数从嘈杂数据中。我们提出了神经后验估计的一致性模型（CMPE），这是一个用于可扩展、快速和摊销推断的新自由形式条件采样器，利用生成性神经网络。CMPE将标准化流和流匹配方法的优点结合到单个生成架构中：它本质上提炼了连续概率流，并能够利用无约束的结构快速进行少射推断，该结构可以定制到估计问题的结构。我们的实证评估表明，CMPE不仅在三个困难的低维问题上优于当前的最先进算法，而且在高维贝叶斯去噪实验和估计计算密集型多尺度中表现出有竞争力的性能。

    arXiv:2312.05440v2 Announce Type: replace-cross  Abstract: Simulation-based inference (SBI) is constantly in search of more expressive algorithms for accurately inferring the parameters of complex models from noisy data. We present consistency models for neural posterior estimation (CMPE), a new free-form conditional sampler for scalable, fast, and amortized SBI with generative neural networks. CMPE combines the advantages of normalizing flows and flow matching methods into a single generative architecture: It essentially distills a continuous probability flow and enables rapid few-shot inference with an unconstrained architecture that can be tailored to the structure of the estimation problem. Our empirical evaluation demonstrates that CMPE not only outperforms current state-of-the-art algorithms on three hard low-dimensional problems but also achieves competitive performance in a high-dimensional Bayesian denoising experiment and in estimating a computationally demanding multi-scale 
    
[^125]: ChatGPT作为数学提问者？评估ChatGPT在生成预大学数学问题上的表现

    ChatGPT as a Math Questioner? Evaluating ChatGPT on Generating Pre-university Math Questions

    [https://arxiv.org/abs/2312.01661](https://arxiv.org/abs/2312.01661)

    ChatGPT在生成预大学数学问题上的表现进行了评估，为填补现有教育问题生成模型的不足提供了新思路。

    

    数学提问对于评估学生的解决问题能力至关重要。由于手动创建这样的问题需要大量工作，因此人们已经探索了自动方法。现有的最先进模型依赖于微调策略，并且在生成涉及多步逻辑和算术推理的问题时很难。与此同时，诸如ChatGPT之类的大型语言模型(LLMs)在许多涉及逻辑和算术推理的NLP任务中表现出色。然而，它们在生成教育问题方面的应用尚未充分利用，特别是在数学领域。为了弥补这一差距，我们迈出了第一步，对ChatGPT在生成预大学数学问题方面进行了深入分析。我们的分析分为两个主要设置：基于上下文感知和不基于上下文感知。

    arXiv:2312.01661v2 Announce Type: replace-cross  Abstract: Mathematical questioning is crucial for assessing students problem-solving skills. Since manually creating such questions requires substantial effort, automatic methods have been explored. Existing state-of-the-art models rely on fine-tuning strategies and struggle to generate questions that heavily involve multiple steps of logical and arithmetic reasoning. Meanwhile, large language models(LLMs) such as ChatGPT have excelled in many NLP tasks involving logical and arithmetic reasoning. Nonetheless, their applications in generating educational questions are underutilized, especially in the field of mathematics. To bridge this gap, we take the first step to conduct an in-depth analysis of ChatGPT in generating pre-university math questions. Our analysis is categorized into two main settings: context-aware and context-unaware. In the context-aware setting, we evaluate ChatGPT on existing math question-answering benchmarks coverin
    
[^126]: TFMQ-DM：面向扩散模型的时间特征维持量化

    TFMQ-DM: Temporal Feature Maintenance Quantization for Diffusion Models

    [https://arxiv.org/abs/2311.16503](https://arxiv.org/abs/2311.16503)

    TFMQ-DM提出了一种称为Temporal Feature Maintenance Quantization (TFMQ)的方法，针对扩散模型中的时间特征进行量化，解决了传统模型中存在的优化问题，提高了压缩效率。

    

    arXiv:2311.16503v2 通告类型：替换-交叉 摘要：扩散模型是一种广泛应用于图像生成的框架，但由于其较长的推理时间和大量的内存需求，在广泛适用性方面遇到了重大挑战。高效的后训练量化（PTQ）对于传统模型解决这些问题至关重要。与传统模型不同，扩散模型严重依赖时间步长 $t$ 来实现令人满意的多轮去噪。通常，从有限集合 $\{1, \ldots, T\}$ 中的 $t$会被几个模块编码为一个时间特征，这完全不考虑采样数据。然而，现有的PTQ方法并不分别优化这些模块。它们采用不恰当的重构目标和复杂的校准方法，导致时间特征和去噪轨迹严重受到干扰，同时压缩效率较低。为了解决这些问题，我们提出了一种称为Temporal Feature Maintenance Quantization (TFMQ)的方法

    arXiv:2311.16503v2 Announce Type: replace-cross  Abstract: The Diffusion model, a prevalent framework for image generation, encounters significant challenges in terms of broad applicability due to its extended inference times and substantial memory requirements. Efficient Post-training Quantization (PTQ) is pivotal for addressing these issues in traditional models. Different from traditional models, diffusion models heavily depend on the time-step $t$ to achieve satisfactory multi-round denoising. Usually, $t$ from the finite set $\{1, \ldots, T\}$ is encoded to a temporal feature by a few modules totally irrespective of the sampling data. However, existing PTQ methods do not optimize these modules separately. They adopt inappropriate reconstruction targets and complex calibration methods, resulting in a severe disturbance of the temporal feature and denoising trajectory, as well as a low compression efficiency. To solve these, we propose a Temporal Feature Maintenance Quantization (TF
    
[^127]: 针对未经授权的文本到图像扩散合成的鲁棒性不可察觉扰动

    Toward Robust Imperceptible Perturbation against Unauthorized Text-to-image Diffusion-based Synthesis

    [https://arxiv.org/abs/2311.13127](https://arxiv.org/abs/2311.13127)

    MetaCloak提出了一种基于元学习框架的解决方案，通过额外转换抽样过程来制造可转移和鲁棒的扰动，以解决现有防御方法的局限性。

    

    arXiv:2311.13127v2 公告类型: 替代交叉 摘要: 文本到图像扩散模型允许从少量参考照片无缝生成个性化图像。然而，这些工具如果落入错误的手中，可能制造误导性或有害内容，危害个人。为解决此问题，现有的基于投毒的方法以一种不可察觉的方式扰动用户图像，以使其无法被恶意使用者学习。我们确定这些防御方法存在两个限制：i) 由于手工启发式解决难解双层优化而导致次优；ii) 缺乏对简单数据转换（如高斯滤波）的鲁棒性。为解决这些挑战，我们提出了MetaCloak，它通过元学习框架解决双级投毒问题，并采用额外的转换抽样过程来制造可转移和鲁棒的扰动。具体而言，我们利用一组替代扩散模型来制造可转移和与模型无关的扰动。

    arXiv:2311.13127v2 Announce Type: replace-cross  Abstract: Text-to-image diffusion models allow seamless generation of personalized images from scant reference photos. Yet, these tools, in the wrong hands, can fabricate misleading or harmful content, endangering individuals. To address this problem, existing poisoning-based approaches perturb user images in an imperceptible way to render them "unlearnable" from malicious uses. We identify two limitations of these defending approaches: i) sub-optimal due to the hand-crafted heuristics for solving the intractable bilevel optimization and ii) lack of robustness against simple data transformations like Gaussian filtering. To solve these challenges, we propose MetaCloak, which solves the bi-level poisoning problem with a meta-learning framework with an additional transformation sampling process to craft transferable and robust perturbation. Specifically, we employ a pool of surrogate diffusion models to craft transferable and model-agnostic
    
[^128]: BLT: 大型语言模型能处理基础法律文本吗？

    BLT: Can Large Language Models Handle Basic Legal Text?

    [https://arxiv.org/abs/2311.09693](https://arxiv.org/abs/2311.09693)

    大型语言模型在处理基础法律文本方面表现不佳，但通过针对性微调，甚至较小的模型也能在测试中表现出色，提升了相关法律任务的表现。

    

    我们发现像GPT-4、Claude和{PaLM 2}这样的最好的公开可用的LLM在处理基础法律文本方面表现不佳。我们引入了一个基准，其中包含律师和法律助理期望LLM零-shot处理的任务，比如查找证词文件的某一行或合同的某个子部分的文本。LLM在这个基准上的差劲表现对它们在法律实践中的可靠性提出了质疑。然而，针对这些任务进行微调甚至使一个较小的模型在我们的测试集上表现接近完美，并且还提升了相关法律任务的表现。这些结果表明，许多领域所需的简单行为在基础LLM中可能不存在，除非有领域专家的额外参与。

    arXiv:2311.09693v2 Announce Type: replace-cross  Abstract: We find that the best publicly available LLMs like GPT-4, Claude, and {PaLM 2} currently perform poorly at basic legal text handling. We introduce a benchmark consisting of tasks that lawyers and paralegals would expect LLMs to handle zero-shot, such as looking up the text at a line of a witness deposition or at a subsection of a contract. LLMs' poor performance on this benchmark casts into doubt their reliability as-is for legal practice. However, fine-tuning for these tasks brings even a smaller model to near-perfect performance on our test set and also raises performance on a related legal task. These results suggest that many simple behaviors needed for a domain may not be present in foundational LLMs, without additional engagement from subject matter experts.
    
[^129]: 针对非随机缺失数据的识别和估计：一种数据融合方法

    Identification and Estimation for Nonignorable Missing Data: A Data Fusion Approach

    [https://arxiv.org/abs/2311.09015](https://arxiv.org/abs/2311.09015)

    该论文提出了一种数据融合方法，通过将缺失不是随机的数据集与随机缺失的辅助数据集信息相结合，实现对感兴趣参数的识别和估计。

    

    我们考虑在数据缺失不是随机的情况下识别和估计感兴趣参数的任务。一般来说，这种参数在没有对缺失数据模型做出强烈假设的情况下是不可识别的。本文采用一种受数据融合启发的替代方法，引入了一种方法，即在缺失不是随机的数据集中增加由随机缺失的辅助数据集中的信息。我们展示了即使在单独的数据集中无法识别感兴趣的参数，通过汇集数据，在两组互补的假设下可以识别参数。我们为已确定的参数推导了一种反向概率加权（IPW）估计量，并通过模拟研究和数据应用评估了我们估计策略的性能。

    arXiv:2311.09015v2 Announce Type: replace-cross  Abstract: We consider the task of identifying and estimating a parameter of interest in settings where data is missing not at random (MNAR). In general, such parameters are not identified without strong assumptions on the missing data model. In this paper, we take an alternative approach and introduce a method inspired by data fusion, where information in an MNAR dataset is augmented by information in an auxiliary dataset subject to missingness at random (MAR). We show that even if the parameter of interest cannot be identified given either dataset alone, it can be identified given pooled data, under two complementary sets of assumptions. We derive an inverse probability weighted (IPW) estimator for identified parameters, and evaluate the performance of our estimation strategies via simulation studies, and a data application.
    
[^130]: 在搜索长尾中：通过逻辑规则引导搜索系统性生成长尾推理知识

    In Search of the Long-Tail: Systematic Generation of Long-Tail Inferential Knowledge via Logical Rule Guided Search

    [https://arxiv.org/abs/2311.07237](https://arxiv.org/abs/2311.07237)

    该研究提出了一个名为LINK的框架，能够系统性地生成长尾推理知识，从而更有效地评估LLMs在推理空间中的表现。

    

    最先进的LLMs在诸如自然语言推理等推理任务上胜过人类。最近评估LLMs的研究指出，在来自低概率分布——即长尾的输入数据上表现大幅下降。因此，我们专注于系统生成涉及长尾推理知识的语句，以更有效地评估LLMs在推理空间中的表现。我们首先提出了一个新颖的框架Logic-Induced-Knowledge-Search（LINK），该框架生成基于符号规则模板的事实正确且长尾知识语句；LINK有效地生成长尾分布数据，零-shot提示的LLMs无法到达，并且在事实正确性方面优于零-shot GPT4达到5%。我们进一步使用LINK生成的数据构建了一个名为Logic-Induced-Long-Tail（LINT）的数据集，可用于评估长尾分布上的下游模型；LINT包含108K个知识条目。

    arXiv:2311.07237v2 Announce Type: replace-cross  Abstract: State-of-the-art LLMs outperform humans on reasoning tasks such as Natural Language Inference. Recent works evaluating LLMs note a marked performance drop on input data from the low-probability distribution, i.e., the longtail. Therefore, we focus on systematically generating statements involving long-tail inferential knowledge for more effective evaluation of LLMs in the reasoning space. We first propose a novel framework Logic-Induced- Knowledge-Search (LINK) that generates factually correct and long-tail knowledge statements grounded on symbolic rule templates; LINK effectively generates data in the longtail distribution that zero-shot prompted LLMs are unable to reach, and outperforms zero-shot GPT4 on factual correctness by 5%. We further use the data generated by LINK to construct a dataset Logic-Induced-Long-Tail (LINT) that can be used to evaluate downstream models on the long-tail distribution; LINT contains 108K knowl
    
[^131]: 大规模轨迹模型是可扩展的运动预测和规划器

    Large Trajectory Models are Scalable Motion Predictors and Planners

    [https://arxiv.org/abs/2310.19620](https://arxiv.org/abs/2310.19620)

    大规模轨迹模型（LTMs）采用State Transformer (STR)模型，将运动预测和规划问题统一建模，有效应对自动驾驶中的挑战。

    

    运动预测和规划是自动驾驶中的重要任务，最近的研究工作已经转向基于机器学习的方法。面临的挑战包括理解多样化的道路拓扑，推理长时间范围内的交通动态，解释异质行为，并在大规模连续状态空间生成策略。受到大型语言模型在通过模型扩展解决类似复杂性方面的成功启发，我们引入一种可扩展的轨迹模型 State Transformer (STR)。STR通过将观察、状态和动作排列成一个统一的序列建模任务来重新定义运动预测和运动规划问题。我们的方法将轨迹生成问题与其他序列建模问题结合起来，借助领域间的突破性进展（如语言建模），实现快速迭代。引人注目的是，实验结果表明，大规模轨迹模型（如STR）遵循扩展定律，展示了

    Motion prediction and planning are vital tasks in autonomous driving, and recent efforts have shifted to machine learning-based approaches. The challenges include understanding diverse road topologies, reasoning traffic dynamics over a long time horizon, interpreting heterogeneous behaviors, and generating policies in a large continuous state space. Inspired by the success of large language models in addressing similar complexities through model scaling, we introduce a scalable trajectory model called State Transformer (STR). STR reformulates the motion prediction and motion planning problems by arranging observations, states, and actions into one unified sequence modeling task. Our approach unites trajectory generation problems with other sequence modeling problems, powering rapid iterations with breakthroughs in neighbor domains such as language modeling. Remarkably, experimental results reveal that large trajectory models (LTMs), such as STR, adhere to the scaling laws by presenting
    
[^132]: 基于UWB的静态手势分类

    UWB Based Static Gesture Classification

    [https://arxiv.org/abs/2310.15036](https://arxiv.org/abs/2310.15036)

    该论文提出了基于UWB的静态手势识别的稳健框架，经过数据集收集和处理，训练模型达到96.78%准确率，并开发了用户友好的GUI框架，为将UWB技术应用于静态手势识别带来了重要进展。

    

    我们的论文提出了一个稳健的框架，用于基于UWB的静态手势识别，利用专有的UWB雷达传感器技术。进行了大量数据收集工作，编制了包含五种常用手势的数据集。我们的方法涉及全面的数据预处理流程，包括异常值处理、保持长宽比的调整大小和伪彩色图像转换。我们对处理后的图像训练了CNN和MobileNet模型。值得注意的是，我们表现最佳的模型达到了96.78%的准确率。此外，我们开发了一个用户友好的GUI框架，用于评估模型的系统资源使用情况和处理时间，显示出低内存利用和在不到一秒的实时任务完成。这项研究是在使用UWB技术增强静态手势识别方面迈出的重要一步，具有在各个领域中应用的潜力。

    arXiv:2310.15036v2 Announce Type: replace-cross  Abstract: Our paper presents a robust framework for UWB-based static gesture recognition, leveraging proprietary UWB radar sensor technology. Extensive data collection efforts were undertaken to compile datasets containing five commonly used gestures. Our approach involves a comprehensive data pre-processing pipeline that encompasses outlier handling, aspect ratio-preserving resizing, and false-color image transformation. Both CNN and MobileNet models were trained on the processed images. Remarkably, our best-performing model achieved an accuracy of 96.78%. Additionally, we developed a user-friendly GUI framework to assess the model's system resource usage and processing times, which revealed low memory utilization and real-time task completion in under one second. This research marks a significant step towards enhancing static gesture recognition using UWB technology, promising practical applications in various domains.
    
[^133]: 让循环的询问: 大型语言模型在判断中的摇摆

    Ask Again, Then Fail: Large Language Models' Vacillations in Judgement

    [https://arxiv.org/abs/2310.02174](https://arxiv.org/abs/2310.02174)

    目前的语言模型在面对后续问题时常常摇摆不定，研究者提出了一个后续问题机制和两个度量标准来量化这种不一致性，并开发出Unwavering-FQ框架来教导模型保持最初的正确判断，实验证明其有效性。

    

    我们观察到目前的会话式语言模型在面对后续问题时往往在其判断上摇摆不定，即使原始判断是正确的。这种摇摆对于生成可靠回复和建立用户信任构成了重要挑战。为了全面评估这一问题，我们引入了一个后续问题机制以及两个度量标准来量化这种不一致性，确认了当前语言模型普遍存在这种情况。为了缓解这一问题，我们探讨了各种提示策略用于闭源模型；此外，我们开发了一个基于训练的框架Unwavering-FQ，通过合成高质量的偏好数据来教导语言模型保持其最初的正确判断。我们的实验结果验证了我们框架的有效性以及其增强模型通用能力的能力。

    arXiv:2310.02174v2 Announce Type: replace-cross  Abstract: We observe that current conversational language models often waver in their judgements when faced with follow-up questions, even if the original judgement was correct. This wavering presents a significant challenge for generating reliable responses and building user trust. To comprehensively assess this issue, we introduce a Follow-up Questioning Mechanism along with two metrics to quantify this inconsistency, confirming its widespread presence in current language models. To mitigate this issue, we explore various prompting strategies for closed-source models; moreover, we develop a training-based framework Unwavering-FQ that teaches language models to maintain their originally correct judgements through synthesized high-quality preference data. Our experimental results confirm the effectiveness of our framework and its ability to enhance the general capabilities of models (https://github.com/NUSTM/LLMs-Waver-In-Judgements).
    
[^134]: 错误在累积知识过程中被有效地驯服了

    Errors are Robustly Tamed in Cumulative Knowledge Processes

    [https://arxiv.org/abs/2309.05638](https://arxiv.org/abs/2309.05638)

    该研究考虑了更一般的累积知识过程家族，探讨了在社会知识积累过程中如何确保一定比例的知识有效性。

    

    我们研究了社会知识积累过程，其中新知识单元的有效性既取决于其推导的正确性，又取决于它所依赖的单元的有效性。在这种情境中的一个基本问题是：如果新推导的恒定比例是错误的，那么投入一个恒定比例并远离一的努力是否能确保社会中的知识的一个恒定比例是有效的？Ben-Eliezer, Mikulincer, Mossel和Sudan (ITCS 2023)引入了一个具体的概率模型来分析这类问题，并对这个问题作出了肯定的回答。然而，他们的研究集中于一个简单情况，即每个新单元只依赖于一个现有单元，并且单元根据$\textit{优先附加规则}$附加。在这项工作中，我们考虑了更一般的累积知识过程家族，其中新单元可能根据不同的附加机制进行附加。

    arXiv:2309.05638v2 Announce Type: replace  Abstract: We study processes of societal knowledge accumulation, where the validity of a new unit of knowledge depends both on the correctness of its derivation and on the validity of the units it depends on. A fundamental question in this setting is: If a constant fraction of the new derivations is wrong, can investing a constant fraction, bounded away from one, of effort ensure that a constant fraction of knowledge in society is valid? Ben-Eliezer, Mikulincer, Mossel, and Sudan (ITCS 2023) introduced a concrete probabilistic model to analyze such questions and showed an affirmative answer to this question. Their study, however, focuses on the simple case where each new unit depends on just one existing unit, and units attach according to a $\textit{preferential attachment rule}$.   In this work, we consider much more general families of cumulative knowledge processes, where new units may attach according to varied attachment mechanisms and d
    
[^135]: 从视频异常检测走向视频异常检索：新的基准和模型

    Towards Video Anomaly Retrieval from Video Anomaly Detection: New Benchmarks and Model

    [https://arxiv.org/abs/2307.12545](https://arxiv.org/abs/2307.12545)

    提出了视频异常检索(VAR)任务，旨在通过跨模态检索相关异常视频。

    

    视频异常检测(VAD)因其潜在应用而受到越来越多的关注，目前的主要任务集中在在线检测帧级别的异常，这可以粗略地解释为二进制或多类事件分类。与此类似，我们提出了一个称为视频异常检索(VAR)的新任务，旨在通过跨模态，例如语言描述和同步音频，实现实用的检索相关异常视频。

    arXiv:2307.12545v2 Announce Type: replace-cross  Abstract: Video anomaly detection (VAD) has been paid increasing attention due to its potential applications, its current dominant tasks focus on online detecting anomalies% at the frame level, which can be roughly interpreted as the binary or multiple event classification. However, such a setup that builds relationships between complicated anomalous events and single labels, e.g., ``vandalism'', is superficial, since single labels are deficient to characterize anomalous events. In reality, users tend to search a specific video rather than a series of approximate videos. Therefore, retrieving anomalous events using detailed descriptions is practical and positive but few researches focus on this. In this context, we propose a novel task called Video Anomaly Retrieval (VAR), which aims to pragmatically retrieve relevant anomalous videos by cross-modalities, e.g., language descriptions and synchronous audios. Unlike the current video retrie
    
[^136]: 了解使用区间传播边界进行认证训练

    Understanding Certified Training with Interval Bound Propagation

    [https://arxiv.org/abs/2306.10426](https://arxiv.org/abs/2306.10426)

    本研究通过引入一种新颖指标，深入探讨了区间传播边界（IBP）训练成功的机制。理论上表明，对于深度线性模型，IBP训练能够在足够宽度的条件下改善边界紧密度。

    

    随着鲁棒性验证方法变得更加精确，对训练具有认证鲁棒性的神经网络变得越来越重要。认证训练方法计算并优化了对鲁棒性规范下最坏情况损失的上界。有趣的是，基于不精确的区间传播边界（IBP）的训练方法一直表现出色，优于利用更精确边界方法的方法。然而，我们仍然缺乏对使IBP如此成功的机制的理解。在这项工作中，我们通过利用一种衡量IBP边界紧密度的新颖指标，彻底研究了这些机制。我们首先在理论上表明，对于深度线性模型，在初始化时，紧密度随着宽度和深度减小，但在给定足够网络宽度的情况下，通过IBP训练会得到改进。然后，我们推导了使IBP边界变得精确的权重矩阵的充分和必要条件，并证明了t

    arXiv:2306.10426v2 Announce Type: replace-cross  Abstract: As robustness verification methods are becoming more precise, training certifiably robust neural networks is becoming ever more relevant. To this end, certified training methods compute and then optimize an upper bound on the worst-case loss over a robustness specification. Curiously, training methods based on the imprecise interval bound propagation (IBP) consistently outperform those leveraging more precise bounding methods. Still, we lack an understanding of the mechanisms making IBP so successful.   In this work, we thoroughly investigate these mechanisms by leveraging a novel metric measuring the tightness of IBP bounds. We first show theoretically that, for deep linear models, tightness decreases with width and depth at initialization, but improves with IBP training, given sufficient network width. We, then, derive sufficient and necessary conditions on weight matrices for IBP bounds to become exact and demonstrate that t
    
[^137]: MiniLLM：大型语言模型的知识蒸馏

    MiniLLM: Knowledge Distillation of Large Language Models

    [https://arxiv.org/abs/2306.08543](https://arxiv.org/abs/2306.08543)

    本文提出了一种将大型语言模型的知识蒸馏到更小模型的方法，通过使用反向KLD替换标准KD方法中的前向KLD目标，有效避免了学生模型高估教师分布的低概率区域。

    

    知识蒸馏（KD）是一种减少大型语言模型（LLMs）高计算需求的有前途的技术。然而，先前的KD方法主要应用于白盒分类模型或训练小模型来模仿如ChatGPT之类的黑盒模型API。如何有效地将白盒LLMs的知识蒸馏到小模型中仍未得到充分探讨，随着开源LLMs的蓬勃发展，这变得更为重要。在这项工作中，我们提出一种KD方法，将LLMs蒸馏到更小的语言模型。

    arXiv:2306.08543v2 Announce Type: replace-cross  Abstract: Knowledge Distillation (KD) is a promising technique for reducing the high computational demand of large language models (LLMs). However, previous KD methods are primarily applied to white-box classification models or training small models to imitate black-box model APIs like ChatGPT. How to effectively distill the knowledge of white-box LLMs into small models is still under-explored, which becomes more important with the prosperity of open-source LLMs. In this work, we propose a KD approach that distills LLMs into smaller language models. We first replace the forward Kullback-Leibler divergence (KLD) objective in the standard KD approaches with reverse KLD, which is more suitable for KD on generative language models, to prevent the student model from overestimating the low-probability regions of the teacher distribution. Then, we derive an effective optimization approach to learn this objective. The student models are named Mi
    
[^138]: 基于中断感知的V2X通信辅助自动驾驶的合作感知

    Interruption-Aware Cooperative Perception for V2X Communication-Aided Autonomous Driving

    [https://arxiv.org/abs/2304.11821](https://arxiv.org/abs/2304.11821)

    V2X-INCOP是一个针对V2X通信辅助自动驾驶的合作感知系统，利用历史合作信息来恢复由中断引起的丢失信息，并缓解安全风险。

    

    合作感知通过V2X通信与邻近车辆交换信息，可以显著提升自动车辆的感知性能，超越个体车辆的有限感知能力。然而，大多数现有研究假设各车辆之间通信理想，忽视了V2X通信不完善带来的显著的常见\textit{中断问题}，导致合作车辆无法成功接收合作信息，从而无法实现合作感知，带来安全风险。为了在实践中充分利用合作感知的优势，我们提出了 V2X通信中断感知的合作感知 (V2X-INCOP)，一个针对V2X通信辅助自动驾驶的鲁棒性合作感知系统，利用历史合作信息来恢复由中断导致的丢失信息，并缓解...

    arXiv:2304.11821v2 Announce Type: replace-cross  Abstract: Cooperative perception can significantly improve the perception performance of autonomous vehicles beyond the limited perception ability of individual vehicles by exchanging information with neighbor agents through V2X communication. However, most existing work assume ideal communication among agents, ignoring the significant and common \textit{interruption issues} caused by imperfect V2X communication, where cooperation agents can not receive cooperative messages successfully and thus fail to achieve cooperative perception, leading to safety risks. To fully reap the benefits of cooperative perception in practice, we propose V2X communication INterruption-aware COoperative Perception (V2X-INCOP), a cooperative perception system robust to communication interruption for V2X communication-aided autonomous driving, which leverages historical cooperation information to recover missing information due to the interruptions and allevia
    
[^139]: 互信息正则化的离线强化学习

    Mutual Information Regularized Offline Reinforcement Learning

    [https://arxiv.org/abs/2210.07484](https://arxiv.org/abs/2210.07484)

    该论文提出了一种互信息正则化的离线强化学习方法，通过直接约束策略改进方向，从而有效解决了离线强化学习中出现的分布偏移问题。

    

    离线强化学习的主要挑战是当超出分布的动作被查询时出现的分布偏移，这使得策略改进方向受到外推误差的偏置。大多数现有方法通过惩罚在策略改进或评估过程中偏离行为策略的策略或价值来解决这个问题。在这项工作中，我们提出了一个新颖的MISA框架，从数据集中状态和行为之间的互信息的角度直接约束策略改进方向，以应对离线强化学习。

    arXiv:2210.07484v3 Announce Type: replace-cross  Abstract: The major challenge of offline RL is the distribution shift that appears when out-of-distribution actions are queried, which makes the policy improvement direction biased by extrapolation errors. Most existing methods address this problem by penalizing the policy or value for deviating from the behavior policy during policy improvement or evaluation. In this work, we propose a novel MISA framework to approach offline RL from the perspective of Mutual Information between States and Actions in the dataset by directly constraining the policy improvement direction. MISA constructs lower bounds of mutual information parameterized by the policy and Q-values. We show that optimizing this lower bound is equivalent to maximizing the likelihood of a one-step improved policy on the offline dataset. Hence, we constrain the policy improvement direction to lie in the data manifold. The resulting algorithm simultaneously augments the policy e
    
[^140]: 强化学习代理中的新兴支配等级

    Emergent Dominance Hierarchies in Reinforcement Learning Agents. (arXiv:2401.12258v1 [cs.MA])

    [http://arxiv.org/abs/2401.12258](http://arxiv.org/abs/2401.12258)

    本研究在强化学习中探讨了一种新的支配等级现象，并证明了在没有明确编程和内在奖励的情况下，强化学习代理能够自主发明、学习、实施和传递支配等级给新的群体。

    

    现代强化学习算法在各种任务中能够胜过人类。多智能体强化学习(MARL)设置提出了额外的挑战，成功的混合动机代理协作取决于个体和群体目标之间的微妙平衡。社会习惯和规范，往往受到人类机构的启发，被用作实现这种平衡的工具。在本文中，我们研究了一种基本且经过深入研究的社会习惯，即支配等级，它在动物和人类社会中都存在。我们将支配等级的行为理论应用于人工智能代理，并尽可能少地修改现有的术语和定义。我们证明，在没有明确编程或内在奖励的情况下，强化学习代理的群体能够发明、学习、实施和传递支配等级给新的群体。所产生的支配等级有一个

    Modern Reinforcement Learning (RL) algorithms are able to outperform humans in a wide variety of tasks. Multi-agent reinforcement learning (MARL) settings present additional challenges, and successful cooperation in mixed-motive groups of agents depends on a delicate balancing act between individual and group objectives. Social conventions and norms, often inspired by human institutions, are used as tools for striking this balance.  In this paper, we examine a fundamental, well-studied social convention that underlies cooperation in both animal and human societies: Dominance hierarchies.  We adapt the ethological theory of dominance hierarchies to artificial agents, borrowing the established terminology and definitions with as few amendments as possible. We demonstrate that populations of RL agents, operating without explicit programming or intrinsic rewards, can invent, learn, enforce, and transmit a dominance hierarchy to new populations. The dominance hierarchies that emerge have a 
    
[^141]: 用于克服灾难性过拟合的高效本地线性正则化

    Efficient local linearity regularization to overcome catastrophic overfitting. (arXiv:2401.11618v1 [cs.LG])

    [http://arxiv.org/abs/2401.11618](http://arxiv.org/abs/2401.11618)

    本研究引入了一种名为ELLE的正则化项，用于高效地减轻单步对抗性训练中的灾难性过拟合。它能够保持损失函数在输入上的局部线性性，与传统的正则化方法相比，ELLE更加高效，能够有效应对大对抗性扰动和长训练计划等困难情况。

    

    单步对抗性训练中的灾难性过拟合 (CO) 导致对抗性测试准确率突然下降（甚至降至0%）。对于使用多步对抗性训练训练的模型，已观察到损失函数在输入上具有局部线性性，但这种特性在单步对抗性训练中丢失。为了解决单步对抗性训练中的CO问题，提出了几种通过正则化来强制损失函数局部线性性的方法。然而，由于双重反向传播，这些正则化项会显著减慢训练速度。与之相反，在本研究中，我们引入一种称为ELLE的正则化项，以在经典对抗性训练评估中有效且高效地减轻CO问题，在一些更困难的情况下也能起作用，例如大对抗性扰动和长训练计划。我们的正则化项在理论上与损失函数的曲率有联系，并且通过避免双重反向传播而具有比先前方法更低的计算成本。通过彻底的实验研究...

    Catastrophic overfitting (CO) in single-step adversarial training (AT) results in abrupt drops in the adversarial test accuracy (even down to 0%). For models trained with multi-step AT, it has been observed that the loss function behaves locally linearly with respect to the input, this is however lost in single-step AT. To address CO in single-step AT, several methods have been proposed to enforce local linearity of the loss via regularization. However, these regularization terms considerably slow down training due to Double Backpropagation. Instead, in this work, we introduce a regularization term, called ELLE, to mitigate CO effectively and efficiently in classical AT evaluations, as well as some more difficult regimes, e.g., large adversarial perturbations and long training schedules. Our regularization term can be theoretically linked to curvature of the loss function and is computationally cheaper than previous methods by avoiding Double Backpropagation. Our thorough experimental 
    
[^142]: BIBench: 大型语言模型数据分析知识基准测试

    BIBench: Benchmarking Data Analysis Knowledge of Large Language Models. (arXiv:2401.02982v1 [cs.CL])

    [http://arxiv.org/abs/2401.02982](http://arxiv.org/abs/2401.02982)

    BIBench是一个旨在评估大型语言模型（LLMs）在商业智能（BI）数据分析领域中能力的综合基准测试，其通过测试模型在BI基础知识、应用知识和技术技能三个维度上的表现来进行评估。

    

    大型语言模型（LLMs）在各种任务中展示了令人印象深刻的能力。然而，它们在数据分析的专业领域中的熟练度和可靠性，特别是在以数据驱动思维为重点的领域中，仍然存在不确定性。为了填补这一差距，我们介绍了BIBench，这是一个全面的基准测试，旨在评估LLMs在商业智能（BI）的背景下的数据分析能力。BIBench通过三个维度评估LLMs：1）BI基础知识，评估模型的数值推理能力和对金融概念的熟悉程度；2）BI知识应用，确定模型快速理解文本信息并从多个视角生成分析问题的能力；3）BI技术技能，检查模型使用技术知识解决现实数据分析挑战的能力。BIBench包括11个子任务，涵盖分类、提取和生成三种任务类型。

    Large Language Models (LLMs) have demonstrated impressive capabilities across a wide range of tasks. However, their proficiency and reliability in the specialized domain of Data Analysis, particularly with a focus on data-driven thinking, remain uncertain. To bridge this gap, we introduce BIBench, a comprehensive benchmark designed to evaluate the data analysis capabilities of LLMs within the context of Business Intelligence (BI). BIBench assesses LLMs across three dimensions: 1) BI foundational knowledge, evaluating the models' numerical reasoning and familiarity with financial concepts; 2) BI knowledge application, determining the models' ability to quickly comprehend textual information and generate analysis questions from multiple views; and 3) BI technical skills, examining the models' use of technical knowledge to address real-world data analysis challenges. BIBench comprises 11 sub-tasks, spanning three categories of task types: classification, extraction, and generation. Additi
    
[^143]: 通过多视角解耦学习改进低资源的基于提示的关系表示

    Improving Low-resource Prompt-based Relation Representation with Multi-view Decoupling Learning. (arXiv:2312.17267v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.17267](http://arxiv.org/abs/2312.17267)

    提出了一种名为MVRE的新方法，通过将关系解耦为不同的视角，生成多视角关系表示，并利用预训练语言模型（PLMs）的能力来提高低资源关系抽取任务的性能。

    

    最近，使用预训练语言模型（PLMs）进行提示调整已经展示出了显著的关系抽取（RE）任务的增强能力。然而，在低资源场景中，即训练数据有限的情况下，由于对关系的表层理解，先前基于提示的方法可能仍然表现不佳，用于表示学习。为此，我们强调在低资源场景中学习高质量关系表示对于RE的重要性，并提出了一种新的基于提示的关系表示方法，名为MVRE（多视角关系抽取），以更好地利用PLMs的能力来改善低资源提示调整范式下的RE性能。具体而言，MVRE将每个关系解耦为不同的视角，以包含多视角的关系表示，以最大化关系推断过程中的似然性。此外，我们还设计了一个全局性的低领域任务学习策略，以进一步提高关系表示的质量。

    Recently, prompt-tuning with pre-trained language models (PLMs) has demonstrated the significantly enhancing ability of relation extraction (RE) tasks. However, in low-resource scenarios, where the available training data is scarce, previous prompt-based methods may still perform poorly for prompt-based representation learning due to a superficial understanding of the relation. To this end, we highlight the importance of learning high-quality relation representation in low-resource scenarios for RE, and propose a novel prompt-based relation representation method, named MVRE (\underline{M}ulti-\underline{V}iew \underline{R}elation \underline{E}xtraction), to better leverage the capacity of PLMs to improve the performance of RE within the low-resource prompt-tuning paradigm. Specifically, MVRE decouples each relation into different perspectives to encompass multi-view relation representations for maximizing the likelihood during relation inference. Furthermore, we also design a Global-Lo
    
[^144]: 面向隐私保护推荐的联邦异构图神经网络

    Federated Heterogeneous Graph Neural Network for Privacy-preserving Recommendation. (arXiv:2310.11730v1 [cs.LG])

    [http://arxiv.org/abs/2310.11730](http://arxiv.org/abs/2310.11730)

    本文提出了一种联邦异构图神经网络（FedHGNN）的框架，能够在分布式的异构信息网络上协同训练推荐模型，同时保护用户隐私。

    

    异构信息网络（HIN）通过元路径描述丰富的语义，已成为缓解推荐系统数据稀疏性的强大工具。现有的基于HIN的推荐系统持有数据的集中存储假设，并进行集中式模型训练。然而，由于隐私问题，现实世界的数据往往以分布式方式存储，导致集中式HIN推荐无法实现。本文提出将HIN分为客户端存储的私有HIN和服务器端的共享HIN。在此设置下，我们提出了一种基于联邦异构图神经网络（FedHGNN）的框架，可以在分布式HIN上协作训练推荐模型，同时不泄露用户隐私。具体而言，我们首先针对基于HIN的联合推荐，基于差分隐私的光下确定了隐私定义，旨在保护私有HIN的用户-商品交互，以及用户的隐私信息。

    Heterogeneous information network (HIN), which contains rich semantics depicted by meta-paths, has become a powerful tool to alleviate data sparsity in recommender systems. Existing HIN-based recommendations hold the data centralized storage assumption and conduct centralized model training. However, the real-world data is often stored in a distributed manner for privacy concerns, resulting in the failure of centralized HIN-based recommendations. In this paper, we suggest the HIN is partitioned into private HINs stored in the client side and shared HINs in the server. Following this setting, we propose a federated heterogeneous graph neural network (FedHGNN) based framework, which can collaboratively train a recommendation model on distributed HINs without leaking user privacy. Specifically, we first formalize the privacy definition in the light of differential privacy for HIN-based federated recommendation, which aims to protect user-item interactions of private HIN as well as user's 
    
[^145]: 物理感知机器学习革命科学范式对于机器学习和基于过程的水文学的影响

    Physics-aware Machine Learning Revolutionizes Scientific Paradigm for Machine Learning and Process-based Hydrology. (arXiv:2310.05227v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.05227](http://arxiv.org/abs/2310.05227)

    物理感知机器学习是一种革命性方法，它将物理知识和机器学习相结合，提供了准确的水文学理解和水循环预测，对于管理水资源以应对气候变化等挑战具有重要意义。

    

    准确的水文学理解和水循环预测对于解决水资源管理中的科学和社会挑战至关重要，特别是在人为气候变化的动态影响下。现有的评论主要关注机器学习在这个领域的发展，然而水文学和机器学习作为独立的范式存在明显的区别。在这里，我们介绍了以物理感知机器学习作为一种变革性方法，克服了这种认知障碍，并革新了这两个领域。具体来说，我们提出了一个综合的物理感知机器学习方法的评论，构建了一个结构化社区（PaML），将先前的物理知识或基于物理的建模与机器学习相结合。我们系统地从物理数据引导的机器学习、物理信息处理的机器学习、物理嵌入式机器学习和物理感知混合学习四个方面分析了这些PaML方法。PaML促进了机器学习辅助的假设推导。

    Accurate hydrological understanding and water cycle prediction are crucial for addressing scientific and societal challenges associated with the management of water resources, particularly under the dynamic influence of anthropogenic climate change. Existing reviews predominantly concentrate on the development of machine learning (ML) in this field, yet there is a clear distinction between hydrology and ML as separate paradigms. Here, we introduce physics-aware ML as a transformative approach to overcome the perceived barrier and revolutionize both fields. Specifically, we present a comprehensive review of the physics-aware ML methods, building a structured community (PaML) of existing methodologies that integrate prior physical knowledge or physics-based modeling into ML. We systematically analyze these PaML methodologies with respect to four aspects: physical data-guided ML, physics-informed ML, physics-embedded ML, and physics-aware hybrid learning. PaML facilitates ML-aided hypothe
    
[^146]: MindShift: 利用大型语言模型进行基于心态的问题性智能手机使用干预

    MindShift: Leveraging Large Language Models for Mental-States-Based Problematic Smartphone Use Intervention. (arXiv:2309.16639v1 [cs.CL])

    [http://arxiv.org/abs/2309.16639](http://arxiv.org/abs/2309.16639)

    MindShift利用大型语言模型实现了基于心态的问题性智能手机使用干预，通过动态生成适应用户环境和心理状态的高质量说服内容来帮助用户解决问题性智能手机使用的困扰。

    

    问题性智能手机使用对身体和心理健康有负面影响。尽管有大量的先前研究，现有的说服技巧不足以根据用户的身体环境和心理状态提供动态说服内容。我们首先进行了一项人为操作研究（N = 12）和一项访谈研究（N = 10），总结了问题性智能手机使用背后的心态：无聊、压力和惯性。这为我们设计了四种说服策略：理解、安抚、唤起和支持习惯。我们利用大型语言模型（LLMs）实现了有效说服内容的自动和动态生成。我们开发了一种新颖的LLM技术驱动的问题性智能手机使用干预技术MindShift。MindShift根据用户当下的身体环境、心态、应用使用行为、用户的目标与习惯作为输入，并生成具有适当说服策略的高质量和灵活的说服内容。我们进行了一项5-

    Problematic smartphone use negatively affects physical and mental health. Despite the wide range of prior research, existing persuasive techniques are not flexible enough to provide dynamic persuasion content based on users' physical contexts and mental states. We first conduct a Wizard-of-Oz study (N=12) and an interview study (N=10) to summarize the mental states behind problematic smartphone use: boredom, stress, and inertia. This informs our design of four persuasion strategies: understanding, comforting, evoking, and scaffolding habits. We leverage large language models (LLMs) to enable the automatic and dynamic generation of effective persuasion content. We develop MindShift, a novel LLM-powered problematic smartphone use intervention technique. MindShift takes users' in-the-moment physical contexts, mental states, app usage behaviors, users' goals & habits as input, and generates high-quality and flexible persuasive content with appropriate persuasion strategies. We conduct a 5-
    
[^147]: 通过共线约束注意力解决Transformer的头痛问题

    Cure the headache of Transformers via Collinear Constrained Attention. (arXiv:2309.08646v1 [cs.LG])

    [http://arxiv.org/abs/2309.08646](http://arxiv.org/abs/2309.08646)

    通过引入共线约束注意力（CoCA）结构，解决Transformer模型中的头痛问题，实现了出色的外推性能和提高的计算效率。

    

    随着基于大型语言模型的实际应用的快速进展，推断性能的外推变得在研究领域中变得越来越重要。在我们的研究中，我们发现了Transformer模型中的一个被之前忽视的异常行为，导致了最接近的标记之间的混乱，这些标记携带了最重要的信息。我们将这一发现称为“Transformer的头痛问题”。为了从根本上解决这个问题，我们引入了一种新的自注意结构，命名为Collinear Constrained Attention（CoCA）。这个结构可以无缝地与现有的推断、插值方法和其他针对传统Transformer模型设计的优化策略集成。我们在推断过程中实现了优秀的外推性能，即使是16到24倍的序列长度，而且没有对我们的模型进行任何微调。我们还增强了CoCA的计算和空间效率，以确保其实用性。我们计划...

    As the rapid progression of practical applications based on Large Language Models continues, the importance of extrapolating performance has grown exponentially in the research domain. In our study, we identified an anomalous behavior in Transformer models that had been previously overlooked, leading to a chaos around closest tokens which carried the most important information. We've coined this discovery the "headache of Transformers". To address this at its core, we introduced a novel self-attention structure named Collinear Constrained Attention (CoCA). This structure can be seamlessly integrated with existing extrapolation, interpolation methods, and other optimization strategies designed for traditional Transformer models. We have achieved excellent extrapolating performance even for 16 times to 24 times of sequence lengths during inference without any fine-tuning on our model. We have also enhanced CoCA's computational and spatial efficiency to ensure its practicality. We plan to
    
[^148]: CL-MAE: 课程学习的遮罩自编码器

    CL-MAE: Curriculum-Learned Masked Autoencoders. (arXiv:2308.16572v1 [cs.CV])

    [http://arxiv.org/abs/2308.16572](http://arxiv.org/abs/2308.16572)

    本文提出了一种课程学习的遮罩自编码器（CL-MAE）。我们引入了一种可学习的遮罩模块，通过更新遮罩策略来增加自监督重构任务的复杂性。通过逐渐增加任务复杂性，模型可以学习更复杂和可迁移的表示。

    

    遮罩图像建模已被证明是一种强大的预文本任务，用于生成能够有效泛化到多个下游任务的鲁棒表示。通常，这种方法涉及在输入图像中随机遮罩补丁（标记），并且遮罩策略在训练过程中保持不变。本文提出了一种课程学习方法，通过更新遮罩策略以持续增加自监督重构任务的复杂性。我们推测，通过逐渐增加任务复杂性，模型可以学习更复杂和可迁移的表示。为了实现这一点，我们引入了一种新颖的可学习遮罩模块，具有生成不同复杂度遮罩的能力，并将该模块与遮罩自编码器（MAE）集成。我们的模块与MAE一同训练，同时调整其行为，在训练过程中从MAE的参与者过渡到MAE（优化相同的重构目标）。

    Masked image modeling has been demonstrated as a powerful pretext task for generating robust representations that can be effectively generalized across multiple downstream tasks. Typically, this approach involves randomly masking patches (tokens) in input images, with the masking strategy remaining unchanged during training. In this paper, we propose a curriculum learning approach that updates the masking strategy to continually increase the complexity of the self-supervised reconstruction task. We conjecture that, by gradually increasing the task complexity, the model can learn more sophisticated and transferable representations. To facilitate this, we introduce a novel learnable masking module that possesses the capability to generate masks of different complexities, and integrate the proposed module into masked autoencoders (MAE). Our module is jointly trained with the MAE, while adjusting its behavior during training, transitioning from a partner to the MAE (optimizing the same rec
    
[^149]: FedSoL: 在联邦学习中解决全局对齐和本地一般性的问题

    FedSoL: Bridging Global Alignment and Local Generality in Federated Learning. (arXiv:2308.12532v1 [cs.LG])

    [http://arxiv.org/abs/2308.12532](http://arxiv.org/abs/2308.12532)

    FedSoL提出了一种联邦学习的方法，该方法旨在解决数据分布不均匀导致性能下降的问题。它通过平衡全局对齐和本地一般性来改善FL的学习效果。

    

    联邦学习(Federated Learning, FL)通过聚合来自个体客户端的本地训练模型来构建全局模型。虽然FL可以在保护数据隐私的情况下学习模型，但当客户端数据分布不均匀时，常常导致性能下降。许多先前的FL算法通过引入各种近似约束来解决这个问题。这些约束旨在通过限制局部学习与全局目标的偏离来促进全局对齐。然而，它们本质上通过干扰原始的局部目标而限制了局部学习。最近，出现了一种替代方法来改善本地学习的一般性。通过在平滑的损失空间中获得本地模型，这种方法减轻了客户端不同本地目标之间的冲突。然而，它不能确保稳定的全局对齐，因为本地学习不考虑全局目标。在本研究中，我们提出了联邦学习的稳定性(FedSoL)方法来在FL中解决全局对齐和本地一般性的问题。

    Federated Learning (FL) aggregates locally trained models from individual clients to construct a global model. While FL enables learning a model with data privacy, it often suffers from significant performance degradation when client data distributions are heterogeneous. Many previous FL algorithms have addressed this issue by introducing various proximal restrictions. These restrictions aim to encourage global alignment by constraining the deviation of local learning from the global objective. However, they inherently limit local learning by interfering with the original local objectives. Recently, an alternative approach has emerged to improve local learning generality. By obtaining local models within a smooth loss landscape, this approach mitigates conflicts among different local objectives of the clients. Yet, it does not ensure stable global alignment, as local learning does not take the global objective into account. In this study, we propose Federated Stability on Learning (Fed
    
[^150]: 一次多用：物理信息合成数据增强了快速MRI重建中的可推广深度学习

    One for Multiple: Physics-informed Synthetic Data Boosts Generalizable Deep Learning for Fast MRI Reconstruction. (arXiv:2307.13220v1 [eess.IV])

    [http://arxiv.org/abs/2307.13220](http://arxiv.org/abs/2307.13220)

    提出了一种名为PISF的物理信息合成数据学习框架，该框架使得快速MRI重建中的多场景可推广深度学习成为可能。

    

    磁共振成像（MRI）是一种提供无辐射、丰富和多样化有关整个人体医学诊断信息的主要放射学方法，但其扫描时间较长。通过k空间欠采样可以显著减少扫描时间，但需要在图像重建中去除引入的伪影。虽然深度学习（DL）已经成为快速MRI图像重建的有力工具，但其在多种成像场景中的潜力尚未充分利用。这是因为不仅收集大规模和多样化的真实训练数据通常昂贵且受限于隐私，现有的DL方法还难以处理训练数据和目标数据之间实际上不可避免的不匹配。在这里，我们提出了一种物理信息合成数据学习框架（PISF）用于快速MRI，它是第一个仅使用一个训练模型实现可推广的多场景MRI重建的方法。

    Magnetic resonance imaging (MRI) is a principal radiological modality that provides radiation-free, abundant, and diverse information about the whole human body for medical diagnosis, but suffers from prolonged scan time. The scan time can be significantly reduced through k-space undersampling but the introduced artifacts need to be removed in image reconstruction. Although deep learning (DL) has emerged as a powerful tool for image reconstruction in fast MRI, its potential in multiple imaging scenarios remains largely untapped. This is because not only collecting large-scale and diverse realistic training data is generally costly and privacy-restricted, but also existing DL methods are hard to handle the practically inevitable mismatch between training and target data. Here, we present a Physics-Informed Synthetic data learning framework for Fast MRI, called PISF, which is the first to enable generalizable DL for multi-scenario MRI reconstruction using solely one trained model. For a 
    
[^151]: 超bolic活跃学习在域转移下的语义分割中的应用

    Hyperbolic Active Learning for Semantic Segmentation under Domain Shift. (arXiv:2306.11180v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2306.11180](http://arxiv.org/abs/2306.11180)

    这项研究首次在Poincaré双曲球模型中运用超bolic活跃学习方法，利用区域内像素嵌入的半径变化作为新的数据获取策略，以提升域转移下语义分割的性能。

    

    对于域转移下的语义分割任务，基于图像区域和伪标签的主动学习获取策略是最先进的。在区域内存在不同类别的伪标签可以识别出不同类别之间的像素，这是一种高效的主动学习数据获取策略。然而，由于设计限制，伪标签的变化仅限于选择类别的轮廓，限制了最终的主动学习性能。我们首次在Poincaré双曲球模型中使用超bolic方法来进行语义分割的主动学习，并利用区域内像素嵌入的半径变化作为一种新的数据获取策略。这源于一种无层次约束训练的超bolic空间的新颖几何特性，我们通过实验证明了这一点。也就是说，类别被映射到具有相当内类半径方差的紧凑超bolic区域，因为模型将难以解释的类别放置在更密集的超bolic区域内。

    For the task of semantic segmentation (SS) under domain shift, active learning (AL) acquisition strategies based on image regions and pseudo labels are state-of-the-art (SoA). The presence of diverse pseudo-labels within a region identifies pixels between different classes, which is a labeling efficient active learning data acquisition strategy. However, by design, pseudo-label variations are limited to only select the contours of classes, limiting the final AL performance. We approach AL for SS in the Poincar\'e hyperbolic ball model for the first time and leverage the variations of the radii of pixel embeddings within regions as a novel data acquisition strategy. This stems from a novel geometric property of a hyperbolic space trained without enforced hierarchies, which we experimentally prove. Namely, classes are mapped into compact hyperbolic areas with a comparable intra-class radii variance, as the model places classes of increasing explainable difficulty at denser hyperbolic are
    
[^152]: 基于GCN可信度预测的协同移动群感知的高效招募策略

    Efficient Recruitment Strategy for Collaborative Mobile Crowd Sensing Based on GCN Trustworthiness Prediction. (arXiv:2306.04366v1 [cs.SI])

    [http://arxiv.org/abs/2306.04366](http://arxiv.org/abs/2306.04366)

    本文提出了一种基于GCN可信度预测的协同移动群感知的高效招募策略，通过捕获工人之间的非对称信任关系和工人能力来实现有效的任务分配，优于现有方法。

    

    协同移动群感知可以通过促进任务感知的团队合作来提高数据质量和覆盖范围，而工人招募则代表着一个复杂的多目标优化问题。现有策略主要关注工人本身的特征，忽略了工人之间的非对称信任关系，从而影响了任务效用评估的合理性。为解决这个问题，本文首先使用Mini-Batch K-Means聚类算法和边缘服务器来实现高效的分布式工人招募。利用历史数据和任务要求获得工人的能力类型和距离。使用工人社交网络中的信任导向图输入至图卷积网络（GCN）框架进行训练，捕获工人之间的非对称信任关系。通过工人之间的高信任值，防止CMCS场景下的隐私泄露。最终，利用预测的信任和工人能力构建了一个无向招募图，以实现有效的任务分配。实验结果表明，与现有方法相比，这种招募方法在招募准确度、任务完成时间和能量消耗方面表现优异。

    Collaborative Mobile Crowd Sensing (CMCS) enhances data quality and coverage by promoting teamwork in task sensing, with worker recruitment representing a complex multi-objective optimization problem. Existing strategies mainly focus on the characteristics of workers themselves, neglecting the asymmetric trust relationships between them, which affects the rationality of task utility evaluation. To address this, this paper first employs the Mini-Batch K-Means clustering algorithm and deploys edge servers to enable efficient distributed worker recruitment. Historical data and task requirements are utilized to obtain workers' ability types and distances. A trust-directed graph in the worker's social network is input into the Graph Convolutional Network (GCN) framework for training, capturing asymmetric trustworthiness between worker pairs. Privacy leakage is prevented in CMCS scenarios through high trust values between workers. Ultimately, an undirected recruitment graph is constructed us
    
[^153]: 一种元学习框架用于调整可信联邦学习保护机制的参数

    A Meta-learning Framework for Tuning Parameters of Protection Mechanisms in Trustworthy Federated Learning. (arXiv:2305.18400v1 [cs.LG])

    [http://arxiv.org/abs/2305.18400](http://arxiv.org/abs/2305.18400)

    提出了一个元学习框架，用于调整可信联邦学习保护机制的参数，以在隐私泄露、效用损失和效率降低之间进行权衡。

    

    可信联邦学习（TFL）通常利用保护机制来保证隐私安全。然而，保护机制不可避免地会引入效用损失或效率降低，同时保护数据隐私。因此，保护机制及其参数应该仔细选择，以在保护隐私泄露、效用损失和效率降低之间取得最佳平衡。为此，联邦学习从业者需要工具来衡量这三个因素，并优化它们之间的权衡，选择最适合手头应用的保护机制。基于这个要求，我们提出了一个框架，它(1)将TFL定义为找到保护机制来优化隐私泄露、效用损失和效率降低三者之间的权衡的问题；(2)正式定义了这三个因素的有界测量。然后，我们提出了一个元学习算法来近似解决此优化问题。

    Trustworthy Federated Learning (TFL) typically leverages protection mechanisms to guarantee privacy. However, protection mechanisms inevitably introduce utility loss or efficiency reduction while protecting data privacy. Therefore, protection mechanisms and their parameters should be carefully chosen to strike an optimal tradeoff between \textit{privacy leakage}, \textit{utility loss}, and \textit{efficiency reduction}. To this end, federated learning practitioners need tools to measure the three factors and optimize the tradeoff between them to choose the protection mechanism that is most appropriate to the application at hand. Motivated by this requirement, we propose a framework that (1) formulates TFL as a problem of finding a protection mechanism to optimize the tradeoff between privacy leakage, utility loss, and efficiency reduction and (2) formally defines bounded measurements of the three factors. We then propose a meta-learning algorithm to approximate this optimization proble
    
[^154]: 为了有效的迁移学习而调整模式的ConvBN块

    Tune-Mode ConvBN Blocks For Efficient Transfer Learning. (arXiv:2305.11624v1 [cs.AI])

    [http://arxiv.org/abs/2305.11624](http://arxiv.org/abs/2305.11624)

    本文研究了ConvBN块中稳定性和效率之间的权衡问题，提出了一种新的Tune模式，以便在迁移学习中既能保持稳定性又能提高效率。

    

    卷积-批归一化（ConvBN）块是各种计算机视觉任务和其他领域的重要组成部分。ConvBN块可以在三种模式下运行：Train、Eval和Deploy。虽然Train模式对于从头开始训练模型是必不可少的，但Eval模式适用于迁移学习和模型验证，而Deploy模式则适用于模型部署。本文重点研究了ConvBN块中稳定性和效率之间的权衡：Deploy模式效率高但训练不稳定；Eval模式在迁移学习中应用广泛，但缺乏效率。为了解决这个难题，我们在理论上揭示了Deploy模式下稳定性下降的原因。随后，我们提出了一种新的Tune模式，以弥合Eval模式和Deploy模式之间的差距。所提出的Tune模式与Eval模式一样稳定，适用于迁移学习，而其计算效率与Deploy模式非常接近。通过大量实验，我们证明了Tune模式的有效性和优越性。

    Convolution-BatchNorm (ConvBN) blocks are integral components in various computer vision tasks and other domains. A ConvBN block can operate in three modes: Train, Eval, and Deploy. While the Train mode is indispensable for training models from scratch, the Eval mode is suitable for transfer learning and model validation, and the Deploy mode is designed for the deployment of models. This paper focuses on the trade-off between stability and efficiency in ConvBN blocks: Deploy mode is efficient but suffers from training instability; Eval mode is widely used in transfer learning but lacks efficiency. To solve the dilemma, we theoretically reveal the reason behind the diminished training stability observed in the Deploy mode. Subsequently, we propose a novel Tune mode to bridge the gap between Eval mode and Deploy mode. The proposed Tune mode is as stable as Eval mode for transfer learning, and its computational efficiency closely matches that of the Deploy mode. Through extensive experime
    
[^155]: 模型所有权争议中的虚假指控

    False Claims against Model Ownership Resolution. (arXiv:2304.06607v1 [cs.CR])

    [http://arxiv.org/abs/2304.06607](http://arxiv.org/abs/2304.06607)

    该论文研究了模型所有权解决方案中对抗恶意原告的鲁棒性问题，展示了常见的MOR方案可以被恶意原告针对未被盗用的独立模型提出虚假指控。

    

    深度神经网络模型是模型所有者的有价值知识产权，构成了竞争优势。因此，开发保护模型不被盗用的技术至关重要。模型所有权解决方案（MOR）是一类可以防止模型被盗的技术。MOR方案使得原告方可以通过提供证据（如水印或指纹）来断言对涉嫌盗用模型的被告方声称所有权，证明涉嫌模型是被盗或者源自于原告方拥有的源模型。现有的大多数 MOR 方案重点放在防范恶意涉嫌方方面，确保如果涉嫌模型确实是被盗版，则原告方将获胜。但是在本文中，我们揭示了现有文献中的常见 MOR 方案存在着另一个同等重要但尚未被充分探讨的鲁棒性问题：恶意原告。我们展示了如何成功地针对未被盗用的独立模型提出虚假指控。

    Deep neural network (DNN) models are valuable intellectual property of model owners, constituting a competitive advantage. Therefore, it is crucial to develop techniques to protect against model theft. Model ownership resolution (MOR) is a class of techniques that can deter model theft. A MOR scheme enables an accuser to assert an ownership claim for a suspect model by presenting evidence, such as a watermark or fingerprint, to show that the suspect model was stolen or derived from a source model owned by the accuser. Most of the existing MOR schemes prioritize robustness against malicious suspects, ensuring that the accuser will win if the suspect model is indeed a stolen model.  In this paper, we show that common MOR schemes in the literature are vulnerable to a different, equally important but insufficiently explored, robustness concern: a malicious accuser. We show how malicious accusers can successfully make false claims against independent suspect models that were not stolen. Our
    
[^156]: 一种联邦学习的博弈论框架

    A Game-theoretic Framework for Federated Learning. (arXiv:2304.05836v1 [cs.LG])

    [http://arxiv.org/abs/2304.05836](http://arxiv.org/abs/2304.05836)

    本文提出了一个名为联邦学习安全博弈（FLSG）的博弈论框架，该框架同时考虑到联邦学习的保护者和攻击者的收益，包括计算成本、FL模型效用和隐私泄漏风险，并提出了一个实用算法来近似oracle并保持隐私。研究表明该算法对于预防和检测现实世界中的联邦学习攻击具有有效性。

    

    在联邦学习中，良性参与者旨在协同优化全局模型。然而，在存在半诚实的对手时，\textit{隐私泄漏}的风险是不可忽视的。现有研究要么专注于设计保护机制，要么专注于发明攻击机制。虽然保护者与攻击者之间的斗争似乎永无止境，但我们关心一个关键问题：是否可能事先预防潜在的攻击？为了解决这个问题，我们提出了一个博弈论框架，同时考虑FL保护者和攻击者的相应收益，其中包括计算成本、FL模型效用和隐私泄漏风险。我们将此游戏称为联邦学习安全博弈（FLSG），在其中保护者和攻击者都不知道所有参与者的收益。为了处理这种情况固有的\textit{不完全信息}，我们建议将FLSG与一个\textit{oracle}相关联，该oracle具有所有参与者的收益知识。我们分析了在各种效用函数和攻击模型组合下FLSG的纳什均衡存在性和唯一性。此外，我们提出了一个实用算法来近似oracle并保持隐私。实验结果说明了我们的算法在预防和检测现实世界中的FL场景中的攻击方面的有效性。

    In federated learning, benign participants aim to optimize a global model collaboratively. However, the risk of \textit{privacy leakage} cannot be ignored in the presence of \textit{semi-honest} adversaries. Existing research has focused either on designing protection mechanisms or on inventing attacking mechanisms. While the battle between defenders and attackers seems never-ending, we are concerned with one critical question: is it possible to prevent potential attacks in advance? To address this, we propose the first game-theoretic framework that considers both FL defenders and attackers in terms of their respective payoffs, which include computational costs, FL model utilities, and privacy leakage risks. We name this game the Federated Learning Security Game (FLSG), in which neither defenders nor attackers are aware of all participants' payoffs.  To handle the \textit{incomplete information} inherent in this situation, we propose associating the FLSG with an \textit{oracle} that ha
    
[^157]: 深度图表示学习综述

    A Comprehensive Survey on Deep Graph Representation Learning. (arXiv:2304.05055v1 [cs.LG])

    [http://arxiv.org/abs/2304.05055](http://arxiv.org/abs/2304.05055)

    本文综述了深度图表示学习的研究现状和存在的问题，并指出利用深度学习已经显示出巨大的优势和潜力。

    

    图表示学习旨在将高维稀疏的图结构数据有效地编码成低维密集向量，这是一个基本任务，在包括机器学习和数据挖掘在内的一系列领域都得到了广泛的研究。传统图嵌入方法遵循这样一种基本思想，即图中相互连接的节点的嵌入矢量仍然能够保持相对接近的距离，从而保留了图中节点之间的结构信息。然而，这种方法存在以下问题：（i）传统方法的模型容量受限，限制了学习性能; （ii）现有技术通常依赖于无监督学习策略，无法与最新的学习范式相结合；（iii）表示学习和下游任务相互依存，应共同加强。随着深度学习的显着成功，深度图表示学习已经显示出巨大的潜力和优势。

    Graph representation learning aims to effectively encode high-dimensional sparse graph-structured data into low-dimensional dense vectors, which is a fundamental task that has been widely studied in a range of fields, including machine learning and data mining. Classic graph embedding methods follow the basic idea that the embedding vectors of interconnected nodes in the graph can still maintain a relatively close distance, thereby preserving the structural information between the nodes in the graph. However, this is sub-optimal due to: (i) traditional methods have limited model capacity which limits the learning performance; (ii) existing techniques typically rely on unsupervised learning strategies and fail to couple with the latest learning paradigms; (iii) representation learning and downstream tasks are dependent on each other which should be jointly enhanced. With the remarkable success of deep learning, deep graph representation learning has shown great potential and advantages 
    
[^158]: 对贝叶斯神经网络在对抗攻击下的鲁棒性的研究

    On the Robustness of Bayesian Neural Networks to Adversarial Attacks. (arXiv:2207.06154v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2207.06154](http://arxiv.org/abs/2207.06154)

    本文研究了贝叶斯神经网络在对抗攻击下的鲁棒性问题，证明了在大数据、超参数化极限下，BNN的后验具有梯度攻击的鲁棒性，这对于解决深度学习在安全关键应用中的脆弱性问题具有重要意义。

    

    在安全关键应用中，对抗攻击的脆弱性是深度学习广泛应用的主要障碍之一。尽管在实践和理论方面已经进行了大量努力，但训练出对抗攻击具有鲁棒性的深度学习模型仍然是一个未解决的问题。本文分析了大数据、超参数化极限下贝叶斯神经网络（BNNs）对抗攻击的几何性质。我们证明，在这个极限下，梯度攻击的脆弱性是由于数据分布的退化导致的，也就是当数据位于环境空间的一个低维子流形上时。作为直接结果，我们证明在这个极限下，BNN的后验对梯度攻击具有鲁棒性。关键是，我们证明了即使从后验中采样的每个神经网络对梯度攻击都具有脆弱性，损失函数对BNN后验分布的期望梯度仍然趋于零。在t上的实验结果表明了我们的发现。

    Vulnerability to adversarial attacks is one of the principal hurdles to the adoption of deep learning in safety-critical applications. Despite significant efforts, both practical and theoretical, training deep learning models robust to adversarial attacks is still an open problem. In this paper, we analyse the geometry of adversarial attacks in the large-data, overparameterized limit for Bayesian Neural Networks (BNNs). We show that, in the limit, vulnerability to gradient-based attacks arises as a result of degeneracy in the data distribution, i.e., when the data lies on a lower-dimensional submanifold of the ambient space. As a direct consequence, we demonstrate that in this limit BNN posteriors are robust to gradient-based adversarial attacks. Crucially, we prove that the expected gradient of the loss with respect to the BNN posterior distribution is vanishing, even when each neural network sampled from the posterior is vulnerable to gradient-based attacks. Experimental results on t
    
[^159]: 人工智能假肢手控制中的肌电和视觉多模态融合

    Multimodal Fusion of EMG and Vision for Human Grasp Intent Inference in Prosthetic Hand Control. (arXiv:2104.03893v4 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2104.03893](http://arxiv.org/abs/2104.03893)

    本文提出了一种使用眼睛视图视频、注视眼动和肌电进行握持意图推理的贝叶斯证据融合框架，在人工智能假肢手控制中具有重要应用价值。

    

    目标：对于下肢截肢者，使用机器人假肢手可以恢复进行日常生活活动的能力。目前基于生理信号（如肌电）的控制方法容易因为运动伪迹、肌肉疲劳等原因导致推理结果不佳。视觉传感器是关于环境状态的重要信息来源，可以在推断可行和预期手势方面发挥重要作用。然而，视觉证据也容易受到自身伪迹的影响，最常见的原因是物体遮挡、光照变化等。使用生理和视觉传感器测量的多模态证据融合是一种自然的方法，因为这些模态具有互补的优势。方法：在本文中，我们提出了一个贝叶斯证据融合框架，用于使用眼睛视图视频、注视眼动和肌电从前臂进行握持意图推理。我们分析了个体和融合性能与某些因素的关系。

    Objective: For lower arm amputees, robotic prosthetic hands promise to regain the capability to perform daily living activities. Current control methods based on physiological signals such as electromyography (EMG) are prone to yielding poor inference outcomes due to motion artifacts, muscle fatigue, and many more. Vision sensors are a major source of information about the environment state and can play a vital role in inferring feasible and intended gestures. However, visual evidence is also susceptible to its own artifacts, most often due to object occlusion, lighting changes, etc. Multimodal evidence fusion using physiological and vision sensor measurements is a natural approach due to the complementary strengths of these modalities. Methods: In this paper, we present a Bayesian evidence fusion framework for grasp intent inference using eye-view video, eye-gaze, and EMG from the forearm processed by neural network models. We analyze individual and fused performance as a function of 
    

