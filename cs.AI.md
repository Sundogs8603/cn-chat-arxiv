# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [RealFill: Reference-Driven Generation for Authentic Image Completion.](http://arxiv.org/abs/2309.16668) | RealFill是一种个性化的生成修填模型，通过使用少量目标场景的参考图像，能够以真实、高质量、逼真的内容完成目标图像的修复。 |
| [^2] | [SA2-Net: Scale-aware Attention Network for Microscopic Image Segmentation.](http://arxiv.org/abs/2309.16661) | SA2-Net是一种尺度感知注意力网络，用于处理显微图像中的多样结构。它结合了多尺度特征学习和尺度感知注意力模块，以实现准确的分割。 |
| [^3] | [MindShift: Leveraging Large Language Models for Mental-States-Based Problematic Smartphone Use Intervention.](http://arxiv.org/abs/2309.16639) | MindShift利用大型语言模型实现了基于心态的问题性智能手机使用干预，通过动态生成适应用户环境和心理状态的高质量说服内容来帮助用户解决问题性智能手机使用的困扰。 |
| [^4] | [Mixup Your Own Pairs.](http://arxiv.org/abs/2309.16633) | 本文提出了一种名为SupReMix的方法，通过混合样本，特别是混合负样本和混合正样本，来解决回归问题中表示学习的挑战。这种方法能够提供更好的性能和更准确的回归结果。 |
| [^5] | [Stress Testing Chain-of-Thought Prompting for Large Language Models.](http://arxiv.org/abs/2309.16621) | 本研究通过压力测试探究了大型语言模型中链式思路提示的有效性，并发现准确的CoT值对于预测正确答案非常重要，而错误的CoT提示会导致性能下降。此外，CoT运算符或CoT顺序错误的不正确演示对性能影响较小。这项研究加深了对CoT提示的理解，并对LLM学习上下文推理能力提出了一些新问题。 |
| [^6] | [Depthwise Hyperparameter Transfer in Residual Networks: Dynamics and Scaling Limit.](http://arxiv.org/abs/2309.16620) | 这项研究通过残差分支尺度和$\mu$P参数化的残差网络，实现了深度学习中超参数的跨宽度和深度的转移。 |
| [^7] | [Revisiting Neural Program Smoothing for Fuzzing.](http://arxiv.org/abs/2309.16618) | 本文对神经程序平滑（NPS）模糊测试方法进行了最广泛的评估，发现其原始性能声明不成立，并提出了解决实际限制问题的新模糊测试方法Neuzz++。 |
| [^8] | ["AI enhances our performance, I have no doubt this one will do the same": The Placebo effect is robust to negative descriptions of AI.](http://arxiv.org/abs/2309.16606) | 该研究发现，无论是正面还是负面描述AI，在实际情况下都不存在AI时，参与者的期望值都很高，并且表现更好。这表明AI的表现期望在负面描述下是有偏差且稳定的。 |
| [^9] | [Transfer Learning for Bayesian Optimization on Heterogeneous Search Spaces.](http://arxiv.org/abs/2309.16597) | 本文提出了MPHD方法，通过模型预训练和神经网络在异质搜索空间上实现贝叶斯优化的迁移学习。实验证明了MPHD的有效性和在黑盒函数优化任务中的优越性能。 |
| [^10] | [Can LLMs Effectively Leverage Structural Information for Graph Learning: When and Why.](http://arxiv.org/abs/2309.16595) | 本文研究了大型语言模型（LLM）在图数据中的应用，发现LLM可以从结构信息中受益，尤其是在文本节点特征缺乏的情况下，而LLM的性能与数据泄露没有显著相关。 |
| [^11] | [Navigating Healthcare Insights: A Birds Eye View of Explainability with Knowledge Graphs.](http://arxiv.org/abs/2309.16593) | 本文总结了知识图谱在医疗领域的影响以及开发可解释性AI模型中的作用。强调了通过知识注入学习提高知识图谱的可解释性的重要性，并提供了未来方向的见解。 |
| [^12] | [The ARRT of Language-Models-as-a-Service: Overview of a New Paradigm and its Challenges.](http://arxiv.org/abs/2309.16573) | 语言模型即服务（LMaaS）作为专有系统，限制了其可访问性和评估可靠性，并提出了ARRT（可访问性、可复制性、可靠性和可信度）挑战。本文总结了这些挑战以及当前解决方案，并提供了未来发展方向的建议。 |
| [^13] | [Augment to Interpret: Unsupervised and Inherently Interpretable Graph Embeddings.](http://arxiv.org/abs/2309.16564) | 本文研究了无监督图表示学习，通过学习并利用保持语义的数据增强方法，创建了解释性嵌入，并解决了无监督表示学习可解释性研究领域的不足。 |
| [^14] | [Voting Network for Contour Levee Farmland Segmentation and Classification.](http://arxiv.org/abs/2309.16561) | 本文提出了一个基于投票网络的端到端可训练模型，用于从高分辨率航空影像中分割和分类等高堤农田。通过使用投票机制来减少边界扭曲和类别混淆，实现了较高的准确性。 |
| [^15] | [KLoB: a Benchmark for Assessing Knowledge Locating Methods in Language Models.](http://arxiv.org/abs/2309.16535) | KLoB是一个评估语言模型中知识定位方法的基准，旨在解决现有定位方法的准确性和事实知识局部性假设的问题。 |
| [^16] | [MotionLM: Multi-Agent Motion Forecasting as Language Modeling.](http://arxiv.org/abs/2309.16534) | MotionLM模型是一个用于多智能体运动预测的语言建模方法，不需要锚点或显式潜在变量优化，能够生成关于交互智能体未来的联合分布和实现时间因果条件展开。 |
| [^17] | [From Complexity to Clarity: Analytical Expressions of Deep Neural Network Weights via Clifford's Geometric Algebra and Convexity.](http://arxiv.org/abs/2309.16512) | 本文通过Clifford的几何代数和凸优化，提出了一种分析深度神经网络的新方法。我们展示了深度ReLU神经网络的最优权重可以通过训练样本的楔积来获得，并且训练问题可以简化为对楔积特征进行凸优化，从而揭示了神经网络内部的几何结构。 |
| [^18] | [Toloka Visual Question Answering Benchmark.](http://arxiv.org/abs/2309.16511) | 本文介绍了Toloka视觉问答，这是一个新的众包数据集，旨在比较机器学习系统在视觉问答任务中与人类专家水平的表现。通过对数据集进行实验和竞赛，发现目前没有机器学习模型能够超过非专家众包基线。 |
| [^19] | [Asset Bundling for Wind Power Forecasting.](http://arxiv.org/abs/2309.16492) | 本研究提出了一种资产捆绑-预测-调整（BPR）框架，将资产捆绑、机器学习和预测协调技术相结合，以实现对风电功率的准确预测和一致性调整。 |
| [^20] | [Augmenting LLMs with Knowledge: A survey on hallucination prevention.](http://arxiv.org/abs/2309.16459) | 本调研论文讨论了将预训练语言模型与外部知识源集成的方法，以解决模型对知识的访问和操作能力的限制问题。 |
| [^21] | [Neuro Symbolic Reasoning for Planning: Counterexample Guided Inductive Synthesis using Large Language Models and Satisfiability Solving.](http://arxiv.org/abs/2309.16436) | 该论文提出了一种利用大型语言模型和可满足性求解进行反例引导归纳合成的神经符号推理方法，旨在解决大型语言模型生成虚假结果的问题，并为安全关键应用中的形式化工件合成提供解决方案。 |
| [^22] | [Diverse and Aligned Audio-to-Video Generation via Text-to-Video Model Adaptation.](http://arxiv.org/abs/2309.16429) | 通过轻量级适配器网络将音频的表示映射到文本到视频生成模型所期望的输入表示，实现了在全局和时间上与输入音频对齐的多样且逼真的视频生成。 |
| [^23] | [Prompt-and-Align: Prompt-Based Social Alignment for Few-Shot Fake News Detection.](http://arxiv.org/abs/2309.16424) | 这项研究提出了一种基于提示的少样本虚假新闻检测方法，通过结合预训练语言模型和社交语境拓扑，有效地减少了标签稀缺性问题。 |
| [^24] | [AutoCLIP: Auto-tuning Zero-Shot Classifiers for Vision-Language Models.](http://arxiv.org/abs/2309.16414) | 本研究提出了一种名为AutoCLIP的方法，用于自动调谐视觉语言模型的零样本分类器。AutoCLIP通过为每个提示模板分配图像特定的权重，从而改进了从编码类别描述符推导零样本分类器的方式。 |
| [^25] | [Genetic Engineering Algorithm (GEA): An Efficient Metaheuristic Algorithm for Solving Combinatorial Optimization Problems.](http://arxiv.org/abs/2309.16413) | 遗传工程算法（GEA）是一种用于解决组合优化问题的高效元启发式算法，通过重新设计传统遗传算法并引入新的搜索方法，GEA能够更好地处理早熟收敛、缺乏问题特定知识和随机性等限制，并在多个组合优化问题上取得了优于传统遗传算法和其他元启发式算法的结果。 |
| [^26] | [Physics-Preserving AI-Accelerated Simulations of Plasma Turbulence.](http://arxiv.org/abs/2309.16400) | 该论文提出了一种将大涡模拟技术与机器学习相结合的方法，用于模拟等离子体湍流。通过这种方法可以显式地保留湍流系统的大尺度动力学，并利用机器学习模型描述小尺度动力学，从而大幅度减少计算量并保持湍流系统的统计物理性质。 |
| [^27] | [Uncertainty-Aware Decision Transformer for Stochastic Driving Environments.](http://arxiv.org/abs/2309.16397) | 本论文提出了一种针对随机驾驶环境的不确定性感知决策Transformer（UNREST），通过估计状态的不确定性并相应地分割序列，取代了全局回报。这项工作通过解决在不确定性环境中过于乐观的问题，为离线强化学习在自主驾驶任务中的应用提供了一种有效的解决方案。 |
| [^28] | [Differential 2D Copula Approximating Transforms via Sobolev Training: 2-Cats Networks.](http://arxiv.org/abs/2309.16391) | 本文介绍了一种通过Sobolev训练的2-Cats网络，它能够非参数地逼近任何二维Copula，并且在估计输出方面优于现有技术。 |
| [^29] | [RLLTE: Long-Term Evolution Project of Reinforcement Learning.](http://arxiv.org/abs/2309.16382) | RLLTE是一种长期演进、极度模块化和开源的强化学习框架，提供了完整的生态系统，预计将为RL工程实践设定标准并刺激产业和学术界。 |
| [^30] | [Conditional normalizing flows for IceCube event reconstruction.](http://arxiv.org/abs/2309.16380) | 该论文提出了使用条件正态流对IceCube中微子观测站的事件重构进行推断的方法，这些条件正态流可以正确地考虑南极冰的光学特性和其与探测器的关系。这项研究在下一代重构工作中具有很大的潜力。 |
| [^31] | [Epistemic Logic Programs: a study of some properties.](http://arxiv.org/abs/2309.16344) | 本论文研究了认知逻辑程序（ELPs），通过引入认知运算符和世界观的概念，提供了一种类似于传统ASP的自下而上模块化计算方法，并提出了一种等价的自上而下方法，可以应用于现有的多种语义，并且在任何语义下都是一致的。 |
| [^32] | [End-to-end Risk Prediction of Atrial Fibrillation from the 12-Lead ECG by Deep Neural Networks.](http://arxiv.org/abs/2309.16335) | 该研究提出了一种由深度神经网络进行的端到端方法，可以从12导联心电图中预测房颤的风险。研究结果显示，该模型可以在目前的心电图中识别出未来会发展房颤的患者，并可以根据患者的风险等级评估他们在一定时间内发展房颤的可能性。 |
| [^33] | [Augmenting transformers with recursively composed multi-grained representations.](http://arxiv.org/abs/2309.16319) | ReCAT是一种增强的Transformer模型，使用递归组合和上下文内外层能够模拟文本的层级句法结构，并生成与其他跨度上下文相关的多粒度表示。 |
| [^34] | [Efficiency Separation between RL Methods: Model-Free, Model-Based and Goal-Conditioned.](http://arxiv.org/abs/2309.16291) | 本论文证明了无模型和有模型强化学习方法在效率上存在根本的限制，但目标条件下的方法和构建逆动力学模型的算法不受该限制。 |
| [^35] | [LawBench: Benchmarking Legal Knowledge of Large Language Models.](http://arxiv.org/abs/2309.16289) | LawBench针对大型语言模型的法律知识进行了综合评估，从记忆，理解和应用三个层面评估了它们在法律任务上的能力。 |
| [^36] | [Generalizable Heterogeneous Federated Cross-Correlation and Instance Similarity Learning.](http://arxiv.org/abs/2309.16286) | 本文提出了一种通用的异构联邦交叉相关和实例相似性学习的方法，利用非目标蒸馏来解决模型异质性和灾难性遗忘问题，提高了联邦学习的泛化能力和应用性能。 |
| [^37] | [UPB @ ACTI: Detecting Conspiracies using fine tuned Sentence Transformers.](http://arxiv.org/abs/2309.16275) | 使用经过微调的句子Transformer模型和数据增强技术，本研究在阴谋论检测任务中取得了很好的成绩，超过了其他竞争系统。 |
| [^38] | [Cooperation Dynamics in Multi-Agent Systems: Exploring Game-Theoretic Scenarios with Mean-Field Equilibria.](http://arxiv.org/abs/2309.16263) | 本文研究在多智能体系统中激发合作的策略和方法，通过分析现有的合作策略和引入鼓励团队回报的修改，解决了在分布式系统中存在的现实困境。同时，利用均值场博弈理论，建立了无限大智能体集合中的平衡解和奖励结构。 |
| [^39] | [QonFusion -- Quantum Approaches to Gaussian Random Variables: Applications in Stable Diffusion and Brownian Motion.](http://arxiv.org/abs/2309.16258) | 本研究提出了一种以非参数量子电路为基础的策略，用于生成高斯随机变量，并将量子随机数生成器纳入经典扩散模型。与传统方法相比，这种方法可以直接生成符合要求的随机变量，避免了计算量大的优化过程。 |
| [^40] | [Nondestructive chicken egg fertility detection using CNN-transfer learning algorithms.](http://arxiv.org/abs/2309.16257) | 本研究使用CNN迁移学习算法对鸡蛋受精进行了非破坏性检测，实现了精确的家禽孵化场实践；通过对四种模型的训练和评估，发现InceptionNet在准确度和性能上表现最佳，在测试集中达到了0.98的准确度，并且对可孵化和不可孵化的鸡蛋都有高精确度的分类能力。 |
| [^41] | [Beyond Reverse KL: Generalizing Direct Preference Optimization with Diverse Divergence Constraints.](http://arxiv.org/abs/2309.16240) | 本论文提出了一种通过引入多样差异约束推广直接偏好优化（DPO）的方法，该方法消除了对估计方法的需要并简化了奖励和最优策略之间的复杂关系。 |
| [^42] | [Language models in molecular discovery.](http://arxiv.org/abs/2309.16235) | 语言模型在分子发现中的应用为加速药物发现和分子设计提供了有希望的方法，包括从头设计药物、性质预测和反应化学。同时，开源软件资源降低了科学语言建模领域的门槛，未来将结合聊天机器人和计算化学工具。 |
| [^43] | [GInX-Eval: Towards In-Distribution Evaluation of Graph Neural Network Explanations.](http://arxiv.org/abs/2309.16223) | 本文针对图神经网络解释的内分布评估问题，提出了GInX-Eval方法，克服了传统评估指标的局限性，为解释方法提供了新的见解。 |
| [^44] | [Unmasking the Chameleons: A Benchmark for Out-of-Distribution Detection in Medical Tabular Data.](http://arxiv.org/abs/2309.16220) | 该论文提出了一个基准来比较不同的方法在医学表格数据中进行ODD检测，为了实现在实际医疗系统中可靠地使用机器学习模型并避免对ODD数据进行不准确的预测，该基准利用了大规模的ICU患者数据集，考虑了多种方法和预测架构。 |
| [^45] | [VDC: Versatile Data Cleanser for Detecting Dirty Samples via Visual-Linguistic Inconsistency.](http://arxiv.org/abs/2309.16211) | VDC是一个多功能数据清洁器，通过检测图像和标签之间的视觉和语言不一致性来解决数据集中的脏样本问题。 |
| [^46] | [A More General Theory of Diagnosis from First Principles.](http://arxiv.org/abs/2309.16180) | 本文提出了从基本原理出发的更一般的诊断理论，该理论将模型诊断推广为对所有类型的系统和诊断都适用的方法。在相对温和的假设下，我们的算法可以正确计算出首选诊断候选集合。 |
| [^47] | [CoinRun: Solving Goal Misgeneralisation.](http://arxiv.org/abs/2309.16166) | 本文介绍了通过使用ACE代理解决目标错误泛化中的CoinRun挑战，并展示了自主代理在新环境下可以在不使用新奖励信息的情况下，在关键情况下受人信任地行动。 |
| [^48] | [Leveraging Untrustworthy Commands for Multi-Robot Coordination in Unpredictable Environments: A Bandit Submodular Maximization Approach.](http://arxiv.org/abs/2309.16161) | 本文研究了在不可预测和部分可观测环境中，利用不可信的外部命令进行多机器人协同的问题。提出了一种算法，Meta Bandit Sequential Greedy (MetaBSG)，能够在外部命令任意糟糕的情况下提供性能保证。 |
| [^49] | [AE-GPT: Using Large Language Models to Extract Adverse Events from Surveillance Reports-A Use Case with Influenza Vaccine Adverse Events.](http://arxiv.org/abs/2309.16150) | AE-GPT是一种使用大型语言模型的方法，可以从监测报告中提取不良事件，该研究以流感疫苗不良事件为例评估了该方法的能力，发现经过微调的GPT 3.5模型（AE-GPT）在严格匹配和灵活匹配方面表现优秀，显示了LLMs在处理医学数据方面的潜力，可推广到其他不良事件提取任务。 |
| [^50] | [T-COL: Generating Counterfactual Explanations for General User Preferences on Variable Machine Learning Systems.](http://arxiv.org/abs/2309.16146) | 该论文提出了一个名为T-COL的方法，针对可变的机器学习系统和一般用户偏好生成反事实解释。这些解释不仅能够解释预测结果的原因，还提供了可操作的建议给用户。通过将一般用户偏好映射到CEs的属性上，以及采用定制化的方式来适应可变的机器学习模型，T-COL能够克服现有挑战并保持健壮性。 |
| [^51] | [Generative Semi-supervised Learning with Meta-Optimized Synthetic Samples.](http://arxiv.org/abs/2309.16143) | 本文提出了一种基于生成基础模型生成的合成样本进行半监督学习的方法，旨在解决实际应用中无法获取大规模无标签数据集的问题。 |
| [^52] | [ModuLoRA: Finetuning 3-Bit LLMs on Consumer GPUs by Integrating with Modular Quantizers.](http://arxiv.org/abs/2309.16119) | ModuLoRA提出了一种内存高效、能够在消费级GPU上支持3比特LLMs微调的方法，并通过与模块化量化器的集成实现了竞争性能和更少的内存使用。 |
| [^53] | [E2Net: Resource-Efficient Continual Learning with Elastic Expansion Network.](http://arxiv.org/abs/2309.16117) | E2Net是一种资源高效的持续学习方法，通过核心子网蒸馏和精确的回放样本选择，实现了卓越的准确性和较小的遗忘，在相同的计算和存储限制下最大程度地减少了处理时间。 |
| [^54] | [Channel Vision Transformers: An Image Is Worth C x 16 x 16 Words.](http://arxiv.org/abs/2309.16108) | 本文提出了ChannelViT模型，通过对ViT架构的修改和引入分层通道采样技术，增强了对多通道图像的推理能力和鲁棒性，适用于显微镜和卫星成像等领域。 |
| [^55] | [Discovering Utility-driven Interval Rules.](http://arxiv.org/abs/2309.16102) | 本研究提出了一种基于效用的区间规则挖掘算法（UIRMiner），可以从区间事件序列数据库中提取所有基于效用的区间规则（UIRs），进一步揭示事件之间的关联性。 |
| [^56] | [Adversarial Examples Might be Avoidable: The Role of Data Concentration in Adversarial Robustness.](http://arxiv.org/abs/2309.16096) | 本研究论证了数据分布的集中程度对于决定鲁棒分类器的存在与否至关重要，并展示了在数据分布集中在低维线性子空间的并集时，利用数据结构可以获得具有良好鲁棒性保证的分类器的方法。 |
| [^57] | [TPE: Towards Better Compositional Reasoning over Conceptual Tools with Multi-persona Collaboration.](http://arxiv.org/abs/2309.16090) | TPE是一种面向概念工具的多人物协作框架，旨在提高大型语言模型在推理和规划方面的能力。 |
| [^58] | [Forgetting Private Textual Sequences in Language Models via Leave-One-Out Ensemble.](http://arxiv.org/abs/2309.16082) | 通过教师-学生框架和排除法集成方法，在语言模型中遗忘私人文本序列时能够取得比其他方法更好的隐私-效用权衡性能。 |
| [^59] | [Masked autoencoders are scalable learners of cellular morphology.](http://arxiv.org/abs/2309.16064) | 本研究探索了弱监督和自监督深度学习方法在训练更大的模型和数据集时的可扩展性，并发现基于CNN和ViT的受屏蔽自动编码器在推断细胞形态学关系方面明显优于弱监督模型。 |
| [^60] | [Towards Best Practices of Activation Patching in Language Models: Metrics and Methods.](http://arxiv.org/abs/2309.16042) | 本研究系统地考察了激活路径修复中的方法细节对语言模型解释性结果的影响，并提出了最佳实践建议。 |
| [^61] | [MedEdit: Model Editing for Medical Question Answering with External Knowledge Bases.](http://arxiv.org/abs/2309.16035) | 该论文研究了利用外部知识库进行医学问答的模型编辑方法，通过提取医学事实并将其融入到语言模型的查询提示中，显著提高了医学问答的准确率。 |
| [^62] | [Symbolic Imitation Learning: From Black-Box to Explainable Driving Policies.](http://arxiv.org/abs/2309.16025) | 本文介绍了一种名为符号化模仿学习（SIL）的方法，通过引入归纳逻辑编程（ILP）来学习从现有数据集中获取透明、可解释和泛化的驾驶策略。与传统的基于深度神经网络的模仿学习方法相比，SIL不仅提高了驾驶策略的可解释性，还显著改进了它们在各种驾驶情况下的适用性。 |
| [^63] | [Clinical Trial Recommendations Using Semantics-Based Inductive Inference and Knowledge Graph Embeddings.](http://arxiv.org/abs/2309.15979) | 本论文提出了一种基于知识图嵌入的临床试验推荐方法，实验表明该方法能够在临床试验设计中实现高达70%-83%的相关性得分，并且最相关的推荐位于推荐列表的前部。 |
| [^64] | [Unified Long-Term Time-Series Forecasting Benchmark.](http://arxiv.org/abs/2309.15946) | 该论文介绍了一个专门用于长期时序预测的综合数据集，通过对多个经典和最先进的模型进行广泛基准分析，发现模型的有效性与数据集相关性有关。 |
| [^65] | [Towards Efficient and Trustworthy AI Through Hardware-Algorithm-Communication Co-Design.](http://arxiv.org/abs/2309.15942) | 通过硬件-算法-通信协同设计，本论文提出了一种实现高效可信的人工智能的研究方法，即通过结合物理洞见、高效信息处理原则、最优不确定度量结果和分布式处理准则，来提高神经网络算法的效率和可信度。 |
| [^66] | [Enhancing Cross-Category Learning in Recommendation Systems with Multi-Layer Embedding Training.](http://arxiv.org/abs/2309.15881) | 该论文提出了一种名为多层嵌入训练（MLET）的训练技术，通过跨类别学习产生优秀的嵌入。该方法通过嵌入层的分解训练嵌入，内部维度高于目标嵌入维度，并在推理时提高了效率。该技术的实验结果令人惊讶，并且通过理论解释了其有效性。 |
| [^67] | [Neuro-Inspired Hierarchical Multimodal Learning.](http://arxiv.org/abs/2309.15877) | 这项研究提出了一种神经启发的分层多模态学习方法，利用信息瓶颈理论构建了一种有效且紧凑的信息流，实现了对真实世界的全面和准确的感知。 |
| [^68] | [STAG: Enabling Low Latency and Low Staleness of GNN-based Services with Dynamic Graphs.](http://arxiv.org/abs/2309.15875) | STAG是一个GNN服务框架，用于解决动态图中基于GNN的服务中的低延迟和低陈旧度问题。它采用协同服务机制和增量传播策略来优化节点表示的更新过程。 |
| [^69] | [ChatGPT & Mechanical Engineering: Examining performance on the FE Mechanical Engineering and Undergraduate Exams.](http://arxiv.org/abs/2309.15866) | 这项研究研究了ChatGPT在机械工程领域的能力，并发现付费订阅模型（GPT-4）在回答机械工程考试和FE考试问题上的性能明显优于免费版本（GPT-3.5）。 |
| [^70] | [A Survey on Image-text Multimodal Models.](http://arxiv.org/abs/2309.15857) | 图像-文本多模型综述论文全面回顾了其发展历程和当前状态，提出了新的分类方法，并阐明了该领域的挑战和潜在研究方向。 |
| [^71] | [Latent Graph Powered Semi-Supervised Learning on Biomedical Tabular Data.](http://arxiv.org/abs/2309.15757) | 本文提出了一种基于潜在图的半监督学习方法，通过利用图的表示来捕捉数据之间的关系，并实现了全局和局部知识的有效融合。在生物医学数据集上的评估中，我们的方法表现出了最先进的结果。 |
| [^72] | [joint prediction and denoising for large-scale multilingual self-supervised learning.](http://arxiv.org/abs/2309.15317) | 这项研究提出了WavLabLM，它通过联合预测和去噪的方法，实现了在136种语言的40k小时数据上进行大规模多语言自监督学习。WavLabLM的多阶段预训练方法解决了多语言数据的语言失衡问题，使其在ML-SUPERB上达到了与XLS-R相当的性能，同时仅使用不到10%的训练数据，这使得SSL在学术高性能计算上可行。 |
| [^73] | [Semantic Map Learning of Traffic Light to Lane Assignment based on Motion Data.](http://arxiv.org/abs/2309.14793) | 本论文介绍了一种基于运动数据的交通灯-车道分配语义地图学习的方法，通过统计方法自动推导交通灯到车道的分配，并且提出了安全考虑和数据集转换方法来提高效果和扩展性。 |
| [^74] | [Generative Escher Meshes.](http://arxiv.org/abs/2309.14564) | 本文提出了一种全自动的生成方法，用于生成周期性的非正方形镶嵌图案，该方法通过优化几何和颜色来生成与所需对象形状和外观相似的瓷砖。 |
| [^75] | [Innovative Digital Storytelling with AIGC: Exploration and Discussion of Recent Advances.](http://arxiv.org/abs/2309.14329) | 本研究探索了AIGC与数字叙事的整合状态，发现虽然AIGC在某些领域表现出色，但由于人类的创造力和审美感等因素，仍无法替代人类在复杂人物动画、面部表情和音效方面的贡献。 |
| [^76] | [Q-Bench: A Benchmark for General-Purpose Foundation Models on Low-level Vision.](http://arxiv.org/abs/2309.14181) | Q-Bench是一个综合性的基准测试，用于评估多模态大型语言模型在低级别视觉感知和理解方面的能力。 |
| [^77] | [AgriSORT: A Simple Online Real-time Tracking-by-Detection framework for robotics in precision agriculture.](http://arxiv.org/abs/2309.13393) | AgriSORT是一个简单的在线实时检测跟踪框架，主要解决精准农业中的多目标跟踪问题，通过仅使用运动信息进行关联，实现了准确和快速的跟踪轨迹传播。 |
| [^78] | [HANS, are you clever? Clever Hans Effect Analysis of Neural Systems.](http://arxiv.org/abs/2309.12481) | 这项研究调查了指导调整的大型语言模型（It-LLMs）对多项选择题（MCQ）的鲁棒性能力，在选择顺序变动时揭示了选择偏见和推理能力的问题。 |
| [^79] | [General In-Hand Object Rotation with Vision and Touch.](http://arxiv.org/abs/2309.09979) | 本研究介绍了一个能够通过视觉和触觉感知实现手中物体通用旋转的系统，通过训练和模拟推断物体的形状和物理属性，并在实际部署中展示了显著的性能提升。 |
| [^80] | [Imbalanced Data Stream Classification using Dynamic Ensemble Selection.](http://arxiv.org/abs/2309.09175) | 本文提出了一个新的框架，通过对非稳态漂移的不平衡数据流进行分类框架设计，采用数据预处理和动态集成选择技术。该框架使用了六个人工生成的数据流，并且通过评估了七种预处理技术和两种动态集成选择方法的效果。 |
| [^81] | [Detecting Unknown Attacks in IoT Environments: An Open Set Classifier for Enhanced Network Intrusion Detection.](http://arxiv.org/abs/2309.07461) | 这项研究介绍了一个针对物联网环境定制的网络入侵检测系统的开放集分类器框架，利用图像表示和堆叠子聚类技术来识别未知攻击。 |
| [^82] | [LEyes: A Lightweight Framework for Deep Learning-Based Eye Tracking using Synthetic Eye Images.](http://arxiv.org/abs/2309.06129) | 本研究提出了一种名为LEyes的轻量级深度学习眼动跟踪框架，利用合成眼部图像进行训练，解决了由于训练数据集不足和眼部图像变异导致的模型泛化问题。实验结果表明，LEyes训练的模型在瞳孔和CR定位方面优于其他算法。 |
| [^83] | [Optimize Weight Rounding via Signed Gradient Descent for the Quantization of LLMs.](http://arxiv.org/abs/2309.05516) | 本文提出一种名为SignRound的优化权重舍入的方法，通过使用有符号梯度进行轻量级分块调整，解决了大型语言模型(LLMs)的量化挑战。 |
| [^84] | [Effect of Attention and Self-Supervised Speech Embeddings on Non-Semantic Speech Tasks.](http://arxiv.org/abs/2308.14359) | 该论文探讨了注意力和自监督语音嵌入对非语义语音任务的影响，特别是情感理解。实验结果表明，基于自注意力的轻量级HuBERT-Large模型在这些任务中表现出色。 |
| [^85] | [Understanding the Usage of QUBO-based Hamiltonian Function in Combinatorial Optimization over Graphs: A Discussion Using Max Cut (MC) Problem.](http://arxiv.org/abs/2308.13978) | 研究探讨了在图上基于QUBO公式的最大切割问题中，如何使用基于强化学习范式和哈密顿函数来解决组合优化问题。通过使用图神经网络作为信息传递架构，并通过三种不同的公式形式进行实验，发现... |
| [^86] | [Algorithm of Thoughts: Enhancing Exploration of Ideas in Large Language Models.](http://arxiv.org/abs/2308.10379) | 本论文提出了一种名为"思想算法"的策略，通过算法推理路径推动大型语言模型的思想探索，以低成本、低存储和低计算开销的方式扩展了其推理能力。结果显示，使用算法指导的大型语言模型的性能可以超越算法本身。 |
| [^87] | [Synergistic Integration of Large Language Models and Cognitive Architectures for Robust AI: An Exploratory Analysis.](http://arxiv.org/abs/2308.09830) | 本文探索了将大型语言模型和认知架构相结合的替代方案，通过协同方法互补各自的弱点和限制，从而实现更稳健和复杂的人工智能系统。 |
| [^88] | [Enhancing Reasoning Capabilities of Large Language Models: A Graph-Based Verification Approach.](http://arxiv.org/abs/2308.09267) | 本研究引入了一种基于图形验证的方法，以进一步提高大型语言模型（LLM）的推理能力，通过将LLM生成的多个解决方案表示为推理图，从而增强推理能力。 |
| [^89] | [Probabilistic contingent planning based on HTN for high-quality plans.](http://arxiv.org/abs/2308.06922) | 该论文提出了一种基于概率性依赖规划的HTN规划器，用于在部分可观察环境中生成高质量的计划。通过扩展HTN规划的形式化和引入新颖的启发式规则，该规划器能够在具有不确定性的环境中产生灵活且稳健的解决方案。 |
| [^90] | [VisIT-Bench: A Benchmark for Vision-Language Instruction Following Inspired by Real-World Use.](http://arxiv.org/abs/2308.06595) | VisIT-Bench是一个用于评价真实世界中视觉语言模型指示遵循的基准，包含了各种任务并提供了详细描述，可以自动评估多模态生成的质量差距。 |
| [^91] | [Probabilistic Invariant Learning with Randomized Linear Classifiers.](http://arxiv.org/abs/2308.04412) | 本文介绍了一种使用随机线性分类器进行概率不变学习的方法，通过接受概率化的普遍逼近和不变性，设计了能同时具有表达能力和不变性的模型，并且使用更少的资源。通过实验证明了这种方法在分类任务中的有效性。 |
| [^92] | [TinyMetaFed: Efficient Federated Meta-Learning for TinyML.](http://arxiv.org/abs/2307.06822) | TinyMetaFed是一个适用于TinyML的高效联邦元学习框架，通过协同训练神经网络初始化，在小型设备上能够快速微调，同时实现通信节省和隐私保护。 |
| [^93] | [SayPlan: Grounding Large Language Models using 3D Scene Graphs for Scalable Task Planning.](http://arxiv.org/abs/2307.06135) | SayPlan是一种利用3D场景图为基础的可扩展的大规模任务规划方法，通过利用3D场景图的层次结构、集成经典路径规划器以及引入迭代的重规划流程，实现了在庞大复杂环境中进行规划的能力。 |
| [^94] | [Temporal Graph Benchmark for Machine Learning on Temporal Graphs.](http://arxiv.org/abs/2307.01026) | TGB是一个用于在时态图上进行机器学习模型评估的基准测试数据集集合，具有挑战性和多样化，涵盖了节点和边级预测任务，对多种领域的时态图进行了广泛的基准测试，并发现常见模型的性能可能有巨大差异。在动态节点属性预测任务中，我们展示了简单方法可能比现有的时态图模型表现出更好的性能。 |
| [^95] | [Revisiting Acceptability Judgements.](http://arxiv.org/abs/2305.14091) | 本文介绍了第一个大规模的非英语语言可接受性数据集CoLAC，发现语言模型性能低于人类的表现，但跨语言转移可行，并可以追溯到预训练阶段。 |
| [^96] | [Visualizing Linguistic Diversity of Text Datasets Synthesized by Large Language Models.](http://arxiv.org/abs/2305.11364) | 该论文介绍了一种新的可视化工具，用于分析大型语言模型生成的数据集的句法多样性，可以通过分层可视化来帮助用户快速浏览概述和检查各个示例。 |
| [^97] | [Causal Policy Gradient for Whole-Body Mobile Manipulation.](http://arxiv.org/abs/2305.04866) | 本文提出了一种新框架——因果MoMa，可以训练适用于典型MoMa任务的策略，在此框架下，机动和交互自由度可以同时组合，并且不需要人类领域知识来划分动作空间或将动作部分与子目标匹配。 |
| [^98] | [Deep learning techniques for financial time series forecasting: A review of recent advancements: 2020-2022.](http://arxiv.org/abs/2305.04811) | 本研究综述了深度学习模型在金融时间序列预测上的最新研究进展，包括不同数据来源和神经网络结构以及实现细节，并提供未来研究方向的建议。 |
| [^99] | [Learning Hybrid Actor-Critic Maps for 6D Non-Prehensile Manipulation.](http://arxiv.org/abs/2305.03942) | 论文介绍了一种名为HACMan的强化学习方法，用于使用点云观察进行6D非抓取式操作的物体操纵。HACMan重点关注物体中心动作表示，它包括从物体点云中选择接触位置和一组描述机器人在接触后如何移动的运动参数。在实际测试中，HACMan的表现明显优于现有基线方法。 |
| [^100] | [Optimal Layout Synthesis for Quantum Circuits as Classical Planning.](http://arxiv.org/abs/2304.12014) | 本文提供了两种编码，将最优布局综合作为经典规划问题，并使用最优的经典规划器来综合标准基准测试的最优布局，解决了对于大规模量子比特优化布局的问题。 |
| [^101] | [Multi-scale Evolutionary Neural Architecture Search for Deep Spiking Neural Networks.](http://arxiv.org/abs/2304.10749) | 本文提出了一种新方法--多尺度进化神经架构搜索，用于自动设计脉冲神经网络，同时考虑微观、中观和宏观尺度的脑拓扑结构。MSE-NAS可以帮助SNN实现多电路模式的自组织集成，并通过全局性的跨模式连接来优化网络性能。 |
| [^102] | [Generative Disco: Text-to-Video Generation for Music Visualization.](http://arxiv.org/abs/2304.08551) | Generative Disco是一个生成式人工智能系统，利用大型语言模型和文本到图像模型帮助生成音乐可视化；用户通过定义开始和结束提示来参数化可视化，可生成反应音频的视频，引入了“过渡”和“保持”的设计模式，能够产生高度表现力并适用于专业人员。 |
| [^103] | [Dice Semimetric Losses: Optimizing the Dice Score with Soft Labels.](http://arxiv.org/abs/2303.16296) | 本文提出的Dice半度量损失函数可在软标签设置中使用，在医疗成像领域的分割方案中与使用软标签的研究相结合，可以获得更好的Dice分数和模型校准。 |
| [^104] | [Tubelet-Contrastive Self-Supervision for Video-Efficient Generalization.](http://arxiv.org/abs/2303.11003) | 该论文提出了Tubelet-对比自监督方法，通过在局部运动动态相同但外观不同的视频之间学习相似性，引入超出预训练数据中存在的运动模式来学习高效的视频表示。实验证明该方法在使用仅25％的预训练视频时仍能保持性能，并在多个下游任务中具有竞争力和一定的泛化能力。 |
| [^105] | [EvCenterNet: Uncertainty Estimation for Object Detection using Evidential Learning.](http://arxiv.org/abs/2303.03037) | EvCenterNet是一种使用证据学习进行目标检测的不确定性感知框架，可以直接估计分类和回归的不确定性，并通过关注最不确定的点来改善检测性能。模型在KITTI数据集和其他具有挑战性的数据集上进行了评估。 |
| [^106] | [On the Role of Morphological Information for Contextual Lemmatization.](http://arxiv.org/abs/2302.00407) | 本文研究了形态信息在六种语言的上下文词形还原器开发中的作用，并对词形还原器进行了领域外性能评估。 |
| [^107] | [Is My Prediction Arbitrary? Measuring Self-Consistency in Fair Classification.](http://arxiv.org/abs/2301.11562) | 在公平分类中，模型的预测方差是一个重要但鲜为人知的误差来源问题。作者提出了一个自洽性标准来衡量测量和减少随意性。作者还开发了一个算法来处理随意性预测，并通过实证研究揭示了当前模型无法处理某些类型数据的问题。 |
| [^108] | [Vertical Federated Learning: Concepts, Advances and Challenges.](http://arxiv.org/abs/2211.12814) | 垂直联合学习（VFL）是一种联合学习设置，多个具有关于同一组用户不同特征的参与方共同训练机器学习模型，而不公开原始数据或模型参数。本文提供了对VFL概念、算法以及各个方面的进展和挑战的综合回顾，深入分析了隐私保护协议的分类、隐私攻击和防御策略，并提出了考虑多个约束条件的统一框架VFLow。此外，还回顾了工业应用中的最新进展和VFL面临的未来挑战和方向。 |
| [^109] | [Responsible AI Pattern Catalogue: A Collection of Best Practices for AI Governance and Engineering.](http://arxiv.org/abs/2209.04963) | 本文提出了一个负责任的AI模式目录，旨在从系统角度实现负责任的AI。与现有的伦理原则框架不同，该目录提供了实践中可采取的最佳实践，并涵盖了AI系统开发生命周期的各个阶段。 |
| [^110] | [Quantum Self-Attention Neural Networks for Text Classification.](http://arxiv.org/abs/2205.05625) | 本论文提出了一种名为量子自注意力神经网络（QSANN）的简单网络架构，通过将自注意机制引入到量子神经网络中，并利用高斯投影的量子自注意力，弥补了现有量子自然语言处理方法的一些限制。QSANN在更大规模的数据集上具有有效和可扩展的性能，并且可以在近期量子设备上实现。 |

# 详细

[^1]: RealFill：参考驱动的真实图像修复生成方法

    RealFill: Reference-Driven Generation for Authentic Image Completion. (arXiv:2309.16668v1 [cs.CV])

    [http://arxiv.org/abs/2309.16668](http://arxiv.org/abs/2309.16668)

    RealFill是一种个性化的生成修填模型，通过使用少量目标场景的参考图像，能够以真实、高质量、逼真的内容完成目标图像的修复。

    

    最近，生成图像的进展带来了能够在未知区域生成高质量、逼真图像内容的外拓和修填模型，但这些模型产生的内容是不真实的，因为模型缺乏关于真实场景的足够背景信息。在本文中，我们提出了一种新颖的真实图像修复生成方法RealFill，它通过填充图像中缺失区域使其内容真正应在的内容。RealFill是一种个性化的生成修填模型，仅使用几张目标场景的参考图像进行个性化。这些参考图像不需要与目标图像对齐，可以通过不同的视角、光照条件、摄像机光圈或图像风格拍摄。个性化后，RealFill能够以视觉上引人注目的内容完成目标图像，并且忠实于原始场景。我们在一个全面且具挑战性的图像修复基准上对RealFill进行评估。

    Recent advances in generative imagery have brought forth outpainting and inpainting models that can produce high-quality, plausible image content in unknown regions, but the content these models hallucinate is necessarily inauthentic, since the models lack sufficient context about the true scene. In this work, we propose RealFill, a novel generative approach for image completion that fills in missing regions of an image with the content that should have been there. RealFill is a generative inpainting model that is personalized using only a few reference images of a scene. These reference images do not have to be aligned with the target image, and can be taken with drastically varying viewpoints, lighting conditions, camera apertures, or image styles. Once personalized, RealFill is able to complete a target image with visually compelling contents that are faithful to the original scene. We evaluate RealFill on a new image completion benchmark that covers a set of diverse and challenging
    
[^2]: SA2-Net: 用于显微图像分割的尺度感知注意力网络

    SA2-Net: Scale-aware Attention Network for Microscopic Image Segmentation. (arXiv:2309.16661v1 [cs.CV])

    [http://arxiv.org/abs/2309.16661](http://arxiv.org/abs/2309.16661)

    SA2-Net是一种尺度感知注意力网络，用于处理显微图像中的多样结构。它结合了多尺度特征学习和尺度感知注意力模块，以实现准确的分割。

    

    显微图像分割是一项具有挑战性的任务，其目标是为给定的显微图像中的每个像素分配语义标签。虽然卷积神经网络（CNNs）是许多现有框架的基础，但它们通常难以明确捕捉长程依赖关系。尽管变压器最初是为了使用自注意力来解决这个问题，但已经证明，在显微图像中，包括形状、大小、外观和目标区域密度的各种挑战中，本地和全局特征都是至关重要的。在本文中，我们介绍了SA2-Net，这是一种利用多尺度特征学习来有效处理显微图像中多样结构的注意引导方法。具体而言，我们提出了尺度感知注意力（SA2）模块，用于捕捉显微区域（如细胞）尺度和形状的固有变化，以实现准确的分割。这个模块结合了局部注意力

    Microscopic image segmentation is a challenging task, wherein the objective is to assign semantic labels to each pixel in a given microscopic image. While convolutional neural networks (CNNs) form the foundation of many existing frameworks, they often struggle to explicitly capture long-range dependencies. Although transformers were initially devised to address this issue using self-attention, it has been proven that both local and global features are crucial for addressing diverse challenges in microscopic images, including variations in shape, size, appearance, and target region density. In this paper, we introduce SA2-Net, an attention-guided method that leverages multi-scale feature learning to effectively handle diverse structures within microscopic images. Specifically, we propose scale-aware attention (SA2) module designed to capture inherent variations in scales and shapes of microscopic regions, such as cells, for accurate segmentation. This module incorporates local attention
    
[^3]: MindShift: 利用大型语言模型进行基于心态的问题性智能手机使用干预

    MindShift: Leveraging Large Language Models for Mental-States-Based Problematic Smartphone Use Intervention. (arXiv:2309.16639v1 [cs.CL])

    [http://arxiv.org/abs/2309.16639](http://arxiv.org/abs/2309.16639)

    MindShift利用大型语言模型实现了基于心态的问题性智能手机使用干预，通过动态生成适应用户环境和心理状态的高质量说服内容来帮助用户解决问题性智能手机使用的困扰。

    

    问题性智能手机使用对身体和心理健康有负面影响。尽管有大量的先前研究，现有的说服技巧不足以根据用户的身体环境和心理状态提供动态说服内容。我们首先进行了一项人为操作研究（N = 12）和一项访谈研究（N = 10），总结了问题性智能手机使用背后的心态：无聊、压力和惯性。这为我们设计了四种说服策略：理解、安抚、唤起和支持习惯。我们利用大型语言模型（LLMs）实现了有效说服内容的自动和动态生成。我们开发了一种新颖的LLM技术驱动的问题性智能手机使用干预技术MindShift。MindShift根据用户当下的身体环境、心态、应用使用行为、用户的目标与习惯作为输入，并生成具有适当说服策略的高质量和灵活的说服内容。我们进行了一项5-

    Problematic smartphone use negatively affects physical and mental health. Despite the wide range of prior research, existing persuasive techniques are not flexible enough to provide dynamic persuasion content based on users' physical contexts and mental states. We first conduct a Wizard-of-Oz study (N=12) and an interview study (N=10) to summarize the mental states behind problematic smartphone use: boredom, stress, and inertia. This informs our design of four persuasion strategies: understanding, comforting, evoking, and scaffolding habits. We leverage large language models (LLMs) to enable the automatic and dynamic generation of effective persuasion content. We develop MindShift, a novel LLM-powered problematic smartphone use intervention technique. MindShift takes users' in-the-moment physical contexts, mental states, app usage behaviors, users' goals & habits as input, and generates high-quality and flexible persuasive content with appropriate persuasion strategies. We conduct a 5-
    
[^4]: 混合你自己的对比对

    Mixup Your Own Pairs. (arXiv:2309.16633v1 [cs.LG])

    [http://arxiv.org/abs/2309.16633](http://arxiv.org/abs/2309.16633)

    本文提出了一种名为SupReMix的方法，通过混合样本，特别是混合负样本和混合正样本，来解决回归问题中表示学习的挑战。这种方法能够提供更好的性能和更准确的回归结果。

    

    在表示学习中，回归问题传统上比分类问题受到的关注较少。直接应用为分类设计的表示学习技术到回归问题往往会导致潜空间中碎片化的表示，从而产生次优的性能。本文认为，由于忽视了两个关键方面：序序感知和难度，对于回归问题而言，对比学习的潜能被忽视了。为了解决这些挑战，我们提倡“混合自己的对比对进行监督性对比回归”，而不仅仅依靠真实/增强样本。具体来说，我们提出了混合式监督对比回归学习（SupReMix）。它在嵌入级别上以锚点包含的混合（锚点和一个不同的负样本的混合）作为困难负对，以锚点排除的混合（两个不同的负样本的混合）作为困难正对。这一策略形成了困难样本对学习的方式。

    In representation learning, regression has traditionally received less attention than classification. Directly applying representation learning techniques designed for classification to regression often results in fragmented representations in the latent space, yielding sub-optimal performance. In this paper, we argue that the potential of contrastive learning for regression has been overshadowed due to the neglect of two crucial aspects: ordinality-awareness and hardness. To address these challenges, we advocate "mixup your own contrastive pairs for supervised contrastive regression", instead of relying solely on real/augmented samples. Specifically, we propose Supervised Contrastive Learning for Regression with Mixup (SupReMix). It takes anchor-inclusive mixtures (mixup of the anchor and a distinct negative sample) as hard negative pairs and anchor-exclusive mixtures (mixup of two distinct negative samples) as hard positive pairs at the embedding level. This strategy formulates harde
    
[^5]: 大型语言模型的链式思路提示的压力测试

    Stress Testing Chain-of-Thought Prompting for Large Language Models. (arXiv:2309.16621v1 [cs.CL])

    [http://arxiv.org/abs/2309.16621](http://arxiv.org/abs/2309.16621)

    本研究通过压力测试探究了大型语言模型中链式思路提示的有效性，并发现准确的CoT值对于预测正确答案非常重要，而错误的CoT提示会导致性能下降。此外，CoT运算符或CoT顺序错误的不正确演示对性能影响较小。这项研究加深了对CoT提示的理解，并对LLM学习上下文推理能力提出了一些新问题。

    

    本报告研究了链式思路提示（CoT）在改进大型语言模型（LLM）的多步推理能力方面的有效性。受到之前的研究的启发，我们分析了CoT提示的三种类型的扰动（即CoT顺序，CoT值和CoT运算符）对GPT-3在各种任务上的性能的影响。我们的发现表明，错误的CoT提示会导致准确性指标下的性能较差。正确的CoT值对于预测正确答案至关重要。此外，当与基于值的扰动相比时，CoT运算符或CoT顺序错误的不正确演示并没有如此剧烈地影响性能。这项研究加深了我们对CoT提示的理解，并提出了一些关于LLM学习上下文推理能力的新问题。

    This report examines the effectiveness of Chain-of-Thought (CoT) prompting in improving the multi-step reasoning abilities of large language models (LLMs). Inspired by previous studies \cite{Min2022RethinkingWork}, we analyze the impact of three types of CoT prompt perturbations, namely CoT order, CoT values, and CoT operators on the performance of GPT-3 on various tasks. Our findings show that incorrect CoT prompting leads to poor performance on accuracy metrics. Correct values in the CoT is crucial for predicting correct answers. Moreover, incorrect demonstrations, where the CoT operators or the CoT order are wrong, do not affect the performance as drastically when compared to the value based perturbations. This research deepens our understanding of CoT prompting and opens some new questions regarding the capability of LLMs to learn reasoning in context.
    
[^6]: 残差网络中的深度超参数转移：动态和缩放限制

    Depthwise Hyperparameter Transfer in Residual Networks: Dynamics and Scaling Limit. (arXiv:2309.16620v1 [stat.ML])

    [http://arxiv.org/abs/2309.16620](http://arxiv.org/abs/2309.16620)

    这项研究通过残差分支尺度和$\mu$P参数化的残差网络，实现了深度学习中超参数的跨宽度和深度的转移。

    

    随着模型大小的增加，深度学习中超参数调整的成本不断上升，促使从业者寻找使用较小网络的代理方法进行调整。其中一个建议使用$\mu$P参数化网络，其中小宽度网络的最佳超参数转移到任意宽度的网络中。然而，在这个方案中，超参数不会在不同深度之间转移。为了解决这个问题，我们研究了具有$1/\sqrt{\text{depth}}$的残差分支尺度和$\mu$P参数化的残差网络。我们通过实验证明，使用这种参数化训练的残差结构，包括卷积ResNet和Vision Transformer，在CIFAR-10和ImageNet上展示了跨宽度和深度的最佳超参数转移。此外，我们的经验发现得到了理论的支持和动机。利用神经网络学习动力学的动态均场理论（DMFT）描述的最新进展，我们展示了

    The cost of hyperparameter tuning in deep learning has been rising with model sizes, prompting practitioners to find new tuning methods using a proxy of smaller networks. One such proposal uses $\mu$P parameterized networks, where the optimal hyperparameters for small width networks transfer to networks with arbitrarily large width. However, in this scheme, hyperparameters do not transfer across depths. As a remedy, we study residual networks with a residual branch scale of $1/\sqrt{\text{depth}}$ in combination with the $\mu$P parameterization. We provide experiments demonstrating that residual architectures including convolutional ResNets and Vision Transformers trained with this parameterization exhibit transfer of optimal hyperparameters across width and depth on CIFAR-10 and ImageNet. Furthermore, our empirical findings are supported and motivated by theory. Using recent developments in the dynamical mean field theory (DMFT) description of neural network learning dynamics, we show
    
[^7]: 重访神经程序平滑技术用于模糊测试

    Revisiting Neural Program Smoothing for Fuzzing. (arXiv:2309.16618v1 [cs.SE])

    [http://arxiv.org/abs/2309.16618](http://arxiv.org/abs/2309.16618)

    本文对神经程序平滑（NPS）模糊测试方法进行了最广泛的评估，发现其原始性能声明不成立，并提出了解决实际限制问题的新模糊测试方法Neuzz++。

    

    随机生成输入进行测试（模糊测试）由于能够自动暴露程序的漏洞而受到广泛关注。模糊测试生成了大量的数据，使其非常适合应用机器学习（ML）方法。神经程序平滑（NPS）是一种特定的基于ML的模糊测试方法，旨在将神经网络用作程序目标的平滑近似，以生成新的测试用例。在本文中，我们对NPS模糊测试方法进行了最广泛的评估，并与标准的灰盒模糊测试方法进行了比较（>11个CPU年和>5.5个GPU年），并做出了以下贡献：(1)我们发现NPS模糊测试方法的原始性能声明不成立；我们将这个差距与先前工作的基本、实施和实验限制相关联。(2)我们首次深入分析了ML和基于梯度的变异在NPS中的贡献。(3)我们实现了新的模糊测试方法Neuzz++，它解决了实际限制问题。

    Testing with randomly generated inputs (fuzzing) has gained significant traction due to its capacity to expose program vulnerabilities automatically. Fuzz testing campaigns generate large amounts of data, making them ideal for the application of machine learning (ML). Neural program smoothing (NPS), a specific family of ML-guided fuzzers, aims to use a neural network as a smooth approximation of the program target for new test case generation.  In this paper, we conduct the most extensive evaluation of NPS fuzzers against standard gray-box fuzzers (>11 CPU years and >5.5 GPU years), and make the following contributions: (1) We find that the original performance claims for NPS fuzzers do not hold; a gap we relate to fundamental, implementation, and experimental limitations of prior works. (2) We contribute the first in-depth analysis of the contribution of machine learning and gradient-based mutations in NPS. (3) We implement Neuzz++, which shows that addressing the practical limitation
    
[^8]: “AI增强我们的表现，我毫不怀疑这一篇论文也会做到同样的事情”：安慰剂效应对AI负面描述有一定的影响(arXiv:2309.16606v1 [cs.HC])

    "AI enhances our performance, I have no doubt this one will do the same": The Placebo effect is robust to negative descriptions of AI. (arXiv:2309.16606v1 [cs.HC])

    [http://arxiv.org/abs/2309.16606](http://arxiv.org/abs/2309.16606)

    该研究发现，无论是正面还是负面描述AI，在实际情况下都不存在AI时，参与者的期望值都很高，并且表现更好。这表明AI的表现期望在负面描述下是有偏差且稳定的。

    

    AI更高的期望通过安慰剂效应促进了人机交互的表现。降低期望来控制安慰剂效应是明智的，但过于负面的期望可能导致负安慰剂效应。在一个字母辨识任务中，我们告知参与者AI会通过调整界面来增强或降低他们的表现，但实际上，在任何条件下都没有AI存在。贝叶斯分析显示，参与者期望值很高，并且不管AI的描述如何，当一个虚假的AI存在时，他们的表现都更好。通过认知建模，我们可以追溯到参与者收集更多信息从而获得优势。一项复制研究验证了负面AI描述不会改变期望值，这表明AI的表现期望在负面言语描述下是有偏差且稳定的。我们讨论了用户期望对于AI交互和评估的影响，并提供了行为安慰剂的证据。

    Heightened AI expectations facilitate performance in human-AI interactions through placebo effects. While lowering expectations to control for placebo effects is advisable, overly negative expectations could induce nocebo effects. In a letter discrimination task, we informed participants that an AI would either increase or decrease their performance by adapting the interface, but in reality, no AI was present in any condition. A Bayesian analysis showed that participants had high expectations and performed descriptively better irrespective of the AI description when a sham-AI was present. Using cognitive modeling, we could trace this advantage back to participants gathering more information. A replication study verified that negative AI descriptions do not alter expectations, suggesting that performance expectations with AI are biased and robust to negative verbal descriptions. We discuss the impact of user expectations on AI interactions and evaluation and provide a behavioral placebo
    
[^9]: 异质搜索空间上的贝叶斯优化的迁移学习

    Transfer Learning for Bayesian Optimization on Heterogeneous Search Spaces. (arXiv:2309.16597v1 [cs.LG])

    [http://arxiv.org/abs/2309.16597](http://arxiv.org/abs/2309.16597)

    本文提出了MPHD方法，通过模型预训练和神经网络在异质搜索空间上实现贝叶斯优化的迁移学习。实验证明了MPHD的有效性和在黑盒函数优化任务中的优越性能。

    

    贝叶斯优化是一种流行的黑盒函数优化方法，它基于贝叶斯模型（通常是高斯过程）进行顺序决策。为了确保模型的质量，我们开发了迁移学习方法，通过学习来自“训练”函数的观察结果来自动设计高斯过程先验。这些训练函数通常需要与“测试”函数（待优化的黑盒函数）具有相同的定义域。在本文中，我们介绍了一种名为MPHD的模型预训练方法，它使用神经网络将特定于领域的上下文映射到分层高斯过程的规范。MPHD可以与贝叶斯优化无缝集成，实现异质搜索空间的知识迁移。我们的理论和实证结果证明了MPHD的有效性，并展示了它在具有挑战性的黑盒函数优化任务中的优越性能。

    Bayesian optimization (BO) is a popular black-box function optimization method, which makes sequential decisions based on a Bayesian model, typically a Gaussian process (GP), of the function. To ensure the quality of the model, transfer learning approaches have been developed to automatically design GP priors by learning from observations on "training" functions. These training functions are typically required to have the same domain as the "test" function (black-box function to be optimized). In this paper, we introduce MPHD, a model pre-training method on heterogeneous domains, which uses a neural net mapping from domain-specific contexts to specifications of hierarchical GPs. MPHD can be seamlessly integrated with BO to transfer knowledge across heterogeneous search spaces. Our theoretical and empirical results demonstrate the validity of MPHD and its superior performance on challenging black-box function optimization tasks.
    
[^10]: LLM能否有效利用结构信息进行图学习：何时何地。

    Can LLMs Effectively Leverage Structural Information for Graph Learning: When and Why. (arXiv:2309.16595v1 [cs.LG])

    [http://arxiv.org/abs/2309.16595](http://arxiv.org/abs/2309.16595)

    本文研究了大型语言模型（LLM）在图数据中的应用，发现LLM可以从结构信息中受益，尤其是在文本节点特征缺乏的情况下，而LLM的性能与数据泄露没有显著相关。

    

    本文研究了大型语言模型（LLM）在结构化数据（特别是图数据）上的应用，这是LLM文献中尚未充分探索的重要数据形态。我们旨在了解在节点分类任务中，何时何地引入图数据中的结构信息可以提高LLM的预测性能。为了解决“何时”问题，我们研究了多种编码结构信息的提示方法，设置中文本节点特征丰富或稀缺。对于“为什么”问题，我们探讨了LLM性能的两个潜在因素：数据泄露和同质性。我们的研究结果表明：（i）LLM可以从结构信息中受益，尤其是在文本节点特征缺乏的情况下；（ii）没有实质性的证据表明LLM性能与数据泄露有显著相关；（iii）LLM在目标节点上的性能与正向相关。

    This paper studies Large Language Models (LLMs) for structured data--particularly graphs--a crucial data modality that remains underexplored in the LLM literature. We aim to understand when and why the incorporation of structural information inherent in graph data can improve the prediction performance of LLMs on node classification tasks. To address the ``when'' question, we examine a variety of prompting methods for encoding structural information, in settings where textual node features are either rich or scarce. For the ``why'' questions, we probe into two potential contributing factors to the LLM performance: data leakage and homophily. Our exploration of these questions reveals that (i) LLMs can benefit from structural information, especially when textual node features are scarce; (ii) there is no substantial evidence indicating that the performance of LLMs is significantly attributed to data leakage; and (iii) the performance of LLMs on a target node is strongly positively relat
    
[^11]: 导航医疗洞见：知识图谱中可解释性的鸟瞰视角

    Navigating Healthcare Insights: A Birds Eye View of Explainability with Knowledge Graphs. (arXiv:2309.16593v1 [cs.AI])

    [http://arxiv.org/abs/2309.16593](http://arxiv.org/abs/2309.16593)

    本文总结了知识图谱在医疗领域的影响以及开发可解释性AI模型中的作用。强调了通过知识注入学习提高知识图谱的可解释性的重要性，并提供了未来方向的见解。

    

    知识图谱在医疗人工智能中日益受到重视，特别是在药物发现和制药研究中，因为它们提供了一种结构化的方式来整合多样化的信息源，增强了AI系统的可解释性。在医疗领域，这种可解释性非常重要，因为信任和透明性至关重要，可解释的AI（XAI）支持医疗专业人员的决策。本综述总结了关于知识图谱在医疗领域的影响及其在开发可解释性AI模型中的作用的最新文献。我们涵盖了知识图谱的工作流程，包括构建、关系提取、推理以及它们在药物-药物相互作用、药物靶点相互作用、药物开发、药物不良反应和生物信息学等领域的应用。我们强调通过在医疗中进行知识注入学习来提高知识图谱的可解释性的重要性。最后，我们突出研究挑战并提供未来方向的见解。

    Knowledge graphs (KGs) are gaining prominence in Healthcare AI, especially in drug discovery and pharmaceutical research as they provide a structured way to integrate diverse information sources, enhancing AI system interpretability. This interpretability is crucial in healthcare, where trust and transparency matter, and eXplainable AI (XAI) supports decision making for healthcare professionals. This overview summarizes recent literature on the impact of KGs in healthcare and their role in developing explainable AI models. We cover KG workflow, including construction, relationship extraction, reasoning, and their applications in areas like Drug-Drug Interactions (DDI), Drug Target Interactions (DTI), Drug Development (DD), Adverse Drug Reactions (ADR), and bioinformatics. We emphasize the importance of making KGs more interpretable through knowledge-infused learning in healthcare. Finally, we highlight research challenges and provide insights for future directions.
    
[^12]: 语言模型即服务的ARRT: 新范式及其挑战的概述

    The ARRT of Language-Models-as-a-Service: Overview of a New Paradigm and its Challenges. (arXiv:2309.16573v1 [cs.AI])

    [http://arxiv.org/abs/2309.16573](http://arxiv.org/abs/2309.16573)

    语言模型即服务（LMaaS）作为专有系统，限制了其可访问性和评估可靠性，并提出了ARRT（可访问性、可复制性、可靠性和可信度）挑战。本文总结了这些挑战以及当前解决方案，并提供了未来发展方向的建议。

    

    当前一些最强大的语言模型都是专有系统，只能通过（通常是限制性的）网络或软件编程接口访问。这就是语言模型即服务（LMaaS）的范式。与可以完全访问模型的情况相反，如开放源代码模型的情况，这些封闭的语言模型对于评估、基准测试和测试造成了特定的挑战。本文的两个目标是：一方面，我们界定前述挑战如何作为对LMaaS的可访问性、可复制性、可靠性和可信度（ARRT）的障碍。我们系统地研究了与每个这四个方面的语言模型信息不足有关的问题。我们阐明了目前的解决方案，提出了一些建议，并强调了未来发展的方向。另一方面，本文是当前主要LMaaS现有知识的一站式集锦，提供了综合的信息。

    Some of the most powerful language models currently are proprietary systems, accessible only via (typically restrictive) web or software programming interfaces. This is the Language-Models-as-a-Service (LMaaS) paradigm. Contrasting with scenarios where full model access is available, as in the case of open-source models, such closed-off language models create specific challenges for evaluating, benchmarking, and testing them. This paper has two goals: on the one hand, we delineate how the aforementioned challenges act as impediments to the accessibility, replicability, reliability, and trustworthiness (ARRT) of LMaaS. We systematically examine the issues that arise from a lack of information about language models for each of these four aspects. We shed light on current solutions, provide some recommendations, and highlight the directions for future advancements. On the other hand, it serves as a one-stop-shop for the extant knowledge about current, major LMaaS, offering a synthesized o
    
[^13]: 增强解释性: 无监督的和本质上可解释的图嵌入

    Augment to Interpret: Unsupervised and Inherently Interpretable Graph Embeddings. (arXiv:2309.16564v1 [cs.LG])

    [http://arxiv.org/abs/2309.16564](http://arxiv.org/abs/2309.16564)

    本文研究了无监督图表示学习，通过学习并利用保持语义的数据增强方法，创建了解释性嵌入，并解决了无监督表示学习可解释性研究领域的不足。

    

    无监督学习使我们能够利用大量可用的未标记数据，并创建可用于各种下游任务的嵌入。然而，无监督表示学习的典型缺乏解释性已成为最近透明人工智能法规的限制因素。在本文中，我们研究了图表示学习，并展示了学习保持语义的数据增强方法可以用于生成解释。我们的框架名为INGENIOUS，创建了本质上可解释的嵌入，并消除了昂贵的后续分析的需要。我们还引入了针对无监督表示学习可解释性研究领域缺乏形式化和度量的额外指标。我们的结果通过应用于图级和节点级任务的实验证明，可解释的嵌入在性能上达到了最先进水平。

    Unsupervised learning allows us to leverage unlabelled data, which has become abundantly available, and to create embeddings that are usable on a variety of downstream tasks. However, the typical lack of interpretability of unsupervised representation learning has become a limiting factor with regard to recent transparent-AI regulations. In this paper, we study graph representation learning and we show that data augmentation that preserves semantics can be learned and used to produce interpretations. Our framework, which we named INGENIOUS, creates inherently interpretable embeddings and eliminates the need for costly additional post-hoc analysis. We also introduce additional metrics addressing the lack of formalism and metrics in the understudied area of unsupervised-representation learning interpretability. Our results are supported by an experimental study applied to both graph-level and node-level tasks and show that interpretable embeddings provide state-of-the-art performance on 
    
[^14]: 基于投票网络的等高堤农田分割和分类

    Voting Network for Contour Levee Farmland Segmentation and Classification. (arXiv:2309.16561v1 [cs.CV])

    [http://arxiv.org/abs/2309.16561](http://arxiv.org/abs/2309.16561)

    本文提出了一个基于投票网络的端到端可训练模型，用于从高分辨率航空影像中分割和分类等高堤农田。通过使用投票机制来减少边界扭曲和类别混淆，实现了较高的准确性。

    

    高分辨率航空影像允许在农田分割中获取细节信息。然而，小物体和特征会导致物体边界的扭曲，需要更大的上下文视图来减少类别混淆。本文提出了一个端到端可训练的网络，用于从高分辨率航空影像中分割等高堤农田。我们设计了一个融合块，其中包括多个投票块，以实现图像分割和分类。我们将融合块与骨干网络结合，同时生成语义预测和分割片段。分割片段用于在预测上进行多数投票。网络被训练为将段落的最有可能类别标签分配给其像素，从而学习农田的概念，而不是单独分析像素。

    High-resolution aerial imagery allows fine details in the segmentation of farmlands. However, small objects and features introduce distortions to the delineation of object boundaries, and larger contextual views are needed to mitigate class confusion. In this work, we present an end-to-end trainable network for segmenting farmlands with contour levees from high-resolution aerial imagery. A fusion block is devised that includes multiple voting blocks to achieve image segmentation and classification. We integrate the fusion block with a backbone and produce both semantic predictions and segmentation slices. The segmentation slices are used to perform majority voting on the predictions. The network is trained to assign the most likely class label of a segment to its pixels, learning the concept of farmlands rather than analyzing constitutive pixels separately. We evaluate our method using images from the National Agriculture Imagery Program. Our method achieved an average accuracy of 94.3
    
[^15]: KLoB: 一种评估语言模型中知识定位方法的基准

    KLoB: a Benchmark for Assessing Knowledge Locating Methods in Language Models. (arXiv:2309.16535v1 [cs.CL])

    [http://arxiv.org/abs/2309.16535](http://arxiv.org/abs/2309.16535)

    KLoB是一个评估语言模型中知识定位方法的基准，旨在解决现有定位方法的准确性和事实知识局部性假设的问题。

    

    最近，定位然后编辑的范式已经成为改变语言模型中存储的事实知识的主要方法之一。然而，目前的定位方法是否能够准确地找到嵌入所需知识的确切参数还缺乏研究。此外，尽管许多研究人员对事实知识的局部性假设的有效性提出了质疑，但没有提供一种测试假设的方法以进行更深入的讨论和研究。因此，我们引入了KLoB，一个评估可靠的知识定位方法应满足的三个基本属性的基准。KLoB可作为评估语言模型中现有定位方法的基准，并为重新评估事实知识的局部性假设提供了一种方法。我们的代码公开可用于\url{https://github.com/juyiming/KLoB}。

    Recently, Locate-Then-Edit paradigm has emerged as one of the main approaches in changing factual knowledge stored in the Language models. However, there is a lack of research on whether present locating methods can pinpoint the exact parameters embedding the desired knowledge. Moreover, although many researchers have questioned the validity of locality hypothesis of factual knowledge, no method is provided to test the a hypothesis for more in-depth discussion and research. Therefore, we introduce KLoB, a benchmark examining three essential properties that a reliable knowledge locating method should satisfy. KLoB can serve as a benchmark for evaluating existing locating methods in language models, and can contributes a method to reassessing the validity of locality hypothesis of factual knowledge. Our is publicly available at \url{https://github.com/juyiming/KLoB}.
    
[^16]: MotionLM: 多智能体运动预测作为语言建模

    MotionLM: Multi-Agent Motion Forecasting as Language Modeling. (arXiv:2309.16534v1 [cs.CV])

    [http://arxiv.org/abs/2309.16534](http://arxiv.org/abs/2309.16534)

    MotionLM模型是一个用于多智能体运动预测的语言建模方法，不需要锚点或显式潜在变量优化，能够生成关于交互智能体未来的联合分布和实现时间因果条件展开。

    

    在自动驾驶车辆的安全规划中，可靠地预测道路上智能体的未来行为是至关重要的。在这里，我们将连续轨迹表示为离散运动令牌的序列，并将多智能体运动预测视为对该领域的语言建模任务。我们的模型MotionLM提供了几个优势：首先，它不需要锚点或显式潜在变量优化来学习多模态分布。相反，我们利用单个标准的语言建模目标，最大化序列令牌的平均对数概率。其次，我们的方法绕过事后交互启发式，其中在交互评分之前进行单个代理轨迹生成。相反，MotionLM在单个自回归解码过程中生成关于交互代理未来的联合分布。此外，模型的时序因子化使其能够实现时间因果条件展开。所提出的方法建立了新的最先进技术。

    Reliable forecasting of the future behavior of road agents is a critical component to safe planning in autonomous vehicles. Here, we represent continuous trajectories as sequences of discrete motion tokens and cast multi-agent motion prediction as a language modeling task over this domain. Our model, MotionLM, provides several advantages: First, it does not require anchors or explicit latent variable optimization to learn multimodal distributions. Instead, we leverage a single standard language modeling objective, maximizing the average log probability over sequence tokens. Second, our approach bypasses post-hoc interaction heuristics where individual agent trajectory generation is conducted prior to interactive scoring. Instead, MotionLM produces joint distributions over interactive agent futures in a single autoregressive decoding process. In addition, the model's sequential factorization enables temporally causal conditional rollouts. The proposed approach establishes new state-of-t
    
[^17]: 从复杂到清晰：通过Clifford的几何代数和凸优化的分析表达深度神经网络的权重

    From Complexity to Clarity: Analytical Expressions of Deep Neural Network Weights via Clifford's Geometric Algebra and Convexity. (arXiv:2309.16512v1 [cs.LG])

    [http://arxiv.org/abs/2309.16512](http://arxiv.org/abs/2309.16512)

    本文通过Clifford的几何代数和凸优化，提出了一种分析深度神经网络的新方法。我们展示了深度ReLU神经网络的最优权重可以通过训练样本的楔积来获得，并且训练问题可以简化为对楔积特征进行凸优化，从而揭示了神经网络内部的几何结构。

    

    本文介绍了一种基于几何（Clifford）代数和凸优化的神经网络分析方法。我们展示了当使用标准正则化损失进行训练时，深度ReLU神经网络的最优权重由训练样本的楔积给出。此外，训练问题可简化为对楔积特征进行凸优化，在其中编码训练数据集的几何结构。该结构以数据向量生成的三角形和平行体的有符号体积表示。凸问题通过$\ell_1$正则化找到样本的一个小子集，以发现仅相关的楔积特征。我们的分析提供了对深度神经网络内部工作机制的新视角，并揭示了隐藏层的作用。

    In this paper, we introduce a novel analysis of neural networks based on geometric (Clifford) algebra and convex optimization. We show that optimal weights of deep ReLU neural networks are given by the wedge product of training samples when trained with standard regularized loss. Furthermore, the training problem reduces to convex optimization over wedge product features, which encode the geometric structure of the training dataset. This structure is given in terms of signed volumes of triangles and parallelotopes generated by data vectors. The convex problem finds a small subset of samples via $\ell_1$ regularization to discover only relevant wedge product features. Our analysis provides a novel perspective on the inner workings of deep neural networks and sheds light on the role of the hidden layers.
    
[^18]: Toloka视觉问答基准. (arXiv:2309.16511v1 [cs.CV])

    Toloka Visual Question Answering Benchmark. (arXiv:2309.16511v1 [cs.CV])

    [http://arxiv.org/abs/2309.16511](http://arxiv.org/abs/2309.16511)

    本文介绍了Toloka视觉问答，这是一个新的众包数据集，旨在比较机器学习系统在视觉问答任务中与人类专家水平的表现。通过对数据集进行实验和竞赛，发现目前没有机器学习模型能够超过非专家众包基线。

    

    本文介绍了Toloka视觉问答，这是一个新的众包数据集，允许对比机器学习系统在视觉问答任务中与人类专家水平的表现。在这个任务中，给定一张图像和一个文本问题，需要正确地绘制出包围该问题回答的对象的边界框。每个图像-问题对都包含回答，每个图像只有一个正确的回答。我们的数据集包含45,199个图像和问题的对，以英文提供，并附带有真实的边界框，分为训练和两个测试子集。除了描述数据集并在CC BY许可下发布之外，我们还对开源的零样本基线模型进行了一系列实验，并组织了在WSDM Cup上吸引了全球48个参与者的多阶段竞赛。然而，在提交论文时，根据交叉验证没有机器学习模型超越了非专家众包基线。

    In this paper, we present Toloka Visual Question Answering, a new crowdsourced dataset allowing comparing performance of machine learning systems against human level of expertise in the grounding visual question answering task. In this task, given an image and a textual question, one has to draw the bounding box around the object correctly responding to that question. Every image-question pair contains the response, with only one correct response per image. Our dataset contains 45,199 pairs of images and questions in English, provided with ground truth bounding boxes, split into train and two test subsets. Besides describing the dataset and releasing it under a CC BY license, we conducted a series of experiments on open source zero-shot baseline models and organized a multi-phase competition at WSDM Cup that attracted 48 participants worldwide. However, by the time of paper submission, no machine learning model outperformed the non-expert crowdsourcing baseline according to the interse
    
[^19]: 风电功率预测的资产捆绑

    Asset Bundling for Wind Power Forecasting. (arXiv:2309.16492v1 [stat.ME])

    [http://arxiv.org/abs/2309.16492](http://arxiv.org/abs/2309.16492)

    本研究提出了一种资产捆绑-预测-调整（BPR）框架，将资产捆绑、机器学习和预测协调技术相结合，以实现对风电功率的准确预测和一致性调整。

    

    美国电网中间断性可再生能源的不断增加，特别是风能和太阳能发电，导致运营不确定性增加。在这种背景下，准确的预测非常重要，特别是对于风能发电，由于其变化幅度大且历史上难以预测。为了克服这一挑战，本研究提出了一种新颖的资产捆绑-预测-调整（BPR）框架，将资产捆绑、机器学习和预测协调技术相结合。BPR框架首先学习中间的层次结构（捆绑），然后预测资产、捆绑和整个风电场的风电功率，最后调整所有预测结果以确保一致性。这种方法有效地引入了一个辅助学习任务（预测捆绑层次的时间序列），以帮助主要的学习任务。本文还介绍了能够捕捉风电时间序列的时空动态的新的资产捆绑标准。进行了大量的数值实验。

    The growing penetration of intermittent, renewable generation in US power grids, especially wind and solar generation, results in increased operational uncertainty. In that context, accurate forecasts are critical, especially for wind generation, which exhibits large variability and is historically harder to predict. To overcome this challenge, this work proposes a novel Bundle-Predict-Reconcile (BPR) framework that integrates asset bundling, machine learning, and forecast reconciliation techniques. The BPR framework first learns an intermediate hierarchy level (the bundles), then predicts wind power at the asset, bundle, and fleet level, and finally reconciles all forecasts to ensure consistency. This approach effectively introduces an auxiliary learning task (predicting the bundle-level time series) to help the main learning tasks. The paper also introduces new asset-bundling criteria that capture the spatio-temporal dynamics of wind power time series. Extensive numerical experiments
    
[^20]: 使用知识增强LLM：关于幻觉预防的调研

    Augmenting LLMs with Knowledge: A survey on hallucination prevention. (arXiv:2309.16459v1 [cs.CL])

    [http://arxiv.org/abs/2309.16459](http://arxiv.org/abs/2309.16459)

    本调研论文讨论了将预训练语言模型与外部知识源集成的方法，以解决模型对知识的访问和操作能力的限制问题。

    

    大规模预训练语言模型在存储事实知识和在下游自然语言处理任务中取得显著结果方面表现出了熟练程度。然而，它们对于准确访问和操作知识的能力仍然受限，导致在知识密集型任务上的表现与特定任务的架构相比存在差距。此外，提供模型决策的来源和保持最新世界知识的挑战仍然是开放的研究前沿。为了解决这些限制，将预训练模型与可微分访问机制集成到显式的非参数记忆中成为一种有希望的解决方案。本调研探讨了增强了与外部知识来源（包括外部知识库和搜索引擎）相连接能力的语言模型（LMs）。

    Large pre-trained language models have demonstrated their proficiency in storing factual knowledge within their parameters and achieving remarkable results when fine-tuned for downstream natural language processing tasks. Nonetheless, their capacity to access and manipulate knowledge with precision remains constrained, resulting in performance disparities on knowledge-intensive tasks when compared to task-specific architectures. Additionally, the challenges of providing provenance for model decisions and maintaining up-to-date world knowledge persist as open research frontiers. To address these limitations, the integration of pre-trained models with differentiable access mechanisms to explicit non-parametric memory emerges as a promising solution. This survey delves into the realm of language models (LMs) augmented with the ability to tap into external knowledge sources, including external knowledge bases and search engines. While adhering to the standard objective of predicting missin
    
[^21]: 神经符号推理用于计划：利用大型语言模型和可满足性求解进行反例引导归纳合成

    Neuro Symbolic Reasoning for Planning: Counterexample Guided Inductive Synthesis using Large Language Models and Satisfiability Solving. (arXiv:2309.16436v1 [cs.AI])

    [http://arxiv.org/abs/2309.16436](http://arxiv.org/abs/2309.16436)

    该论文提出了一种利用大型语言模型和可满足性求解进行反例引导归纳合成的神经符号推理方法，旨在解决大型语言模型生成虚假结果的问题，并为安全关键应用中的形式化工件合成提供解决方案。

    

    利用强化训练的生成型大型语言模型（LLM）（如GPT-4），可以根据人工提供的指令提示来生成类似人类的回复。除了自然语言回复外，这些模型还被发现在从自然语言提示中生成代码、计划和逻辑规范方面非常有效。尽管它们的准确性得到了显着改善，但这些模型仍然可能产生事实不正确或上下文不恰当的结果，这被称为幻觉现象。这种限制使得在安全关键应用中使用这些模型合成形式化工件变得困难。与文本摘要和问答等任务不同，LLM生成的代码、计划和其他形式化工件中的错误可能具有灾难性。我们认为可以使用可满足性模型检测（SMT）求解器作为演绎推理引擎来分析生成的工件。

    Generative large language models (LLMs) with instruct training such as GPT-4 can follow human-provided instruction prompts and generate human-like responses to these prompts. Apart from natural language responses, they have also been found to be effective at generating formal artifacts such as code, plans, and logical specifications from natural language prompts. Despite their remarkably improved accuracy, these models are still known to produce factually incorrect or contextually inappropriate results despite their syntactic coherence - a phenomenon often referred to as hallucination. This limitation makes it difficult to use these models to synthesize formal artifacts that are used in safety-critical applications. Unlike tasks such as text summarization and question-answering, bugs in code, plan, and other formal artifacts produced by LLMs can be catastrophic. We posit that we can use the satisfiability modulo theory (SMT) solvers as deductive reasoning engines to analyze the generat
    
[^22]: 通过文本到视频模型自适应实现多样且对齐的音频到视频生成

    Diverse and Aligned Audio-to-Video Generation via Text-to-Video Model Adaptation. (arXiv:2309.16429v1 [cs.LG])

    [http://arxiv.org/abs/2309.16429](http://arxiv.org/abs/2309.16429)

    通过轻量级适配器网络将音频的表示映射到文本到视频生成模型所期望的输入表示，实现了在全局和时间上与输入音频对齐的多样且逼真的视频生成。

    

    我们考虑使用来自各种语义类别的自然音频样本来引导生成多样且逼真的视频的任务。对于这个任务，视频需要在全局和时间上与输入音频进行对齐：全局上，输入音频与整个输出视频有语义关联；时间上，输入音频的每个片段都与相应的视频片段关联。我们利用现有的文本驱动视频生成模型和预训练的音频编码器模型。所提出的方法基于一个轻量级的适配器网络，该网络学习将基于音频的表示映射到文本到视频生成模型所期望的输入表示。因此，它也可以实现基于文本、音频以及文本和音频的视频生成，据我们所知，这是首次实现。我们在三个数据集上对我们的方法进行了大量验证，展示了音频-视频样本的显著语义多样性，并进一步验证了我们的方法的性能。

    We consider the task of generating diverse and realistic videos guided by natural audio samples from a wide variety of semantic classes. For this task, the videos are required to be aligned both globally and temporally with the input audio: globally, the input audio is semantically associated with the entire output video, and temporally, each segment of the input audio is associated with a corresponding segment of that video. We utilize an existing text-conditioned video generation model and a pre-trained audio encoder model. The proposed method is based on a lightweight adaptor network, which learns to map the audio-based representation to the input representation expected by the text-to-video generation model. As such, it also enables video generation conditioned on text, audio, and, for the first time as far as we can ascertain, on both text and audio. We validate our method extensively on three datasets demonstrating significant semantic diversity of audio-video samples and further
    
[^23]: Prompt-and-Align: 基于提示的社交调整用于少样本虚假新闻检测

    Prompt-and-Align: Prompt-Based Social Alignment for Few-Shot Fake News Detection. (arXiv:2309.16424v1 [cs.CL])

    [http://arxiv.org/abs/2309.16424](http://arxiv.org/abs/2309.16424)

    这项研究提出了一种基于提示的少样本虚假新闻检测方法，通过结合预训练语言模型和社交语境拓扑，有效地减少了标签稀缺性问题。

    

    尽管自动检测虚假新闻取得了相当大的进展，但由于新闻的及时性，如何有效地根据有限的事实核对信息来预测新闻文章的真实性仍然是一个关键的未解决问题。现有方法通常遵循“从头训练”的范例，这在根本上受到大规模注释数据的可用性的限制。尽管已经以“预训练和微调”的方式适应了表达能力强的预训练语言模型（PLM），但预训练与下游目标之间的不一致也需要昂贵的任务特定监督。在本文中，我们提出了“Prompt-and-Align”（P&A），一种基于提示的少样本虚假新闻检测新范例，联合利用了PLM中的预训练知识和社交语境拓扑。我们的方法通过将新闻文章包裹在一个与任务相关的文本提示中来缓解标签稀缺性，然后通过PLM处理来直接引出任务特定的知识。

    Despite considerable advances in automated fake news detection, due to the timely nature of news, it remains a critical open question how to effectively predict the veracity of news articles based on limited fact-checks. Existing approaches typically follow a "Train-from-Scratch" paradigm, which is fundamentally bounded by the availability of large-scale annotated data. While expressive pre-trained language models (PLMs) have been adapted in a "Pre-Train-and-Fine-Tune" manner, the inconsistency between pre-training and downstream objectives also requires costly task-specific supervision. In this paper, we propose "Prompt-and-Align" (P&A), a novel prompt-based paradigm for few-shot fake news detection that jointly leverages the pre-trained knowledge in PLMs and the social context topology. Our approach mitigates label scarcity by wrapping the news article in a task-related textual prompt, which is then processed by the PLM to directly elicit task-specific knowledge. To supplement the PL
    
[^24]: AutoCLIP: 自动调谐视觉语言模型的零样本分类器

    AutoCLIP: Auto-tuning Zero-Shot Classifiers for Vision-Language Models. (arXiv:2309.16414v1 [cs.CV])

    [http://arxiv.org/abs/2309.16414](http://arxiv.org/abs/2309.16414)

    本研究提出了一种名为AutoCLIP的方法，用于自动调谐视觉语言模型的零样本分类器。AutoCLIP通过为每个提示模板分配图像特定的权重，从而改进了从编码类别描述符推导零样本分类器的方式。

    

    基于视觉语言模型（如CLIP）构建的分类器在广泛的图像分类任务中展现了出色的零样本性能。先前的工作研究了根据提示模板自动创建每个类别的描述符集的不同方式，包括手工设计的模板、从大型语言模型获取的模板以及从随机单词和字符构建的模板。然而，从相应的编码类别描述符导出零样本分类器几乎没有改变：将图像的平均编码类别描述符与编码图像之间的余弦相似度最大化以进行分类。然而，当某些描述符比其他描述符更好地匹配给定图像上的视觉线索时，将所有类别描述符等权重可能不是最优的。在这项工作中，我们提出了一种自动调谐零样本分类器的方法AutoCLIP。AutoCLIP为每个提示模板分配了图像特定的权重，这些权重是从s

    Classifiers built upon vision-language models such as CLIP have shown remarkable zero-shot performance across a broad range of image classification tasks. Prior work has studied different ways of automatically creating descriptor sets for every class based on prompt templates, ranging from manually engineered templates over templates obtained from a large language model to templates built from random words and characters. In contrast, deriving zero-shot classifiers from the respective encoded class descriptors has remained nearly unchanged, that is: classify to the class that maximizes the cosine similarity between its averaged encoded class descriptors and the encoded image. However, weighting all class descriptors equally can be suboptimal when certain descriptors match visual clues on a given image better than others. In this work, we propose AutoCLIP, a method for auto-tuning zero-shot classifiers. AutoCLIP assigns to each prompt template per-image weights, which are derived from s
    
[^25]: 遗传工程算法（GEA）：一种用于解决组合优化问题的高效元启发式算法

    Genetic Engineering Algorithm (GEA): An Efficient Metaheuristic Algorithm for Solving Combinatorial Optimization Problems. (arXiv:2309.16413v1 [cs.NE])

    [http://arxiv.org/abs/2309.16413](http://arxiv.org/abs/2309.16413)

    遗传工程算法（GEA）是一种用于解决组合优化问题的高效元启发式算法，通过重新设计传统遗传算法并引入新的搜索方法，GEA能够更好地处理早熟收敛、缺乏问题特定知识和随机性等限制，并在多个组合优化问题上取得了优于传统遗传算法和其他元启发式算法的结果。

    

    遗传算法（GAs）以其在解决组合优化问题方面的效率而闻名，拥有探索多样化解空间的能力、处理各种表示、利用并行性、保留良好解、适应变化动态、处理组合多样性和提供启发式搜索的能力。然而，GAs存在早熟收敛、缺乏问题特定知识和交叉和变异操作的随机性等限制，使其通常在找到最优解方面效率低下。为了解决这些限制，本文提出了一种名为遗传工程算法（GEA）的新型元启发式算法，从基因工程概念中汲取灵感。GEA重新设计了传统遗传算法，同时引入新的搜索方法，通过隔离、纯化、插入和表达新基因，基于已有基因产生特定染色体，从而实现所需特征的出现和特定染色体的生成。比较评估结果表明，GEA在多个组合优化问题上超过了传统遗传算法和其他元启发式算法。

    Genetic Algorithms (GAs) are known for their efficiency in solving combinatorial optimization problems, thanks to their ability to explore diverse solution spaces, handle various representations, exploit parallelism, preserve good solutions, adapt to changing dynamics, handle combinatorial diversity, and provide heuristic search. However, limitations such as premature convergence, lack of problem-specific knowledge, and randomness of crossover and mutation operators make GAs generally inefficient in finding an optimal solution. To address these limitations, this paper proposes a new metaheuristic algorithm called the Genetic Engineering Algorithm (GEA) that draws inspiration from genetic engineering concepts. GEA redesigns the traditional GA while incorporating new search methods to isolate, purify, insert, and express new genes based on existing ones, leading to the emergence of desired traits and the production of specific chromosomes based on the selected genes. Comparative evaluati
    
[^26]: 等离子体湍流的物理保持的AI加速模拟

    Physics-Preserving AI-Accelerated Simulations of Plasma Turbulence. (arXiv:2309.16400v1 [physics.comp-ph])

    [http://arxiv.org/abs/2309.16400](http://arxiv.org/abs/2309.16400)

    该论文提出了一种将大涡模拟技术与机器学习相结合的方法，用于模拟等离子体湍流。通过这种方法可以显式地保留湍流系统的大尺度动力学，并利用机器学习模型描述小尺度动力学，从而大幅度减少计算量并保持湍流系统的统计物理性质。

    

    流体、气体和等离子体中的湍流问题一直是一个既重要又没有解答的问题。由于其无法简单地通过计算处理其不可简化的复杂性。本文结合了大涡模拟 (LES) 技术和机器学习 (ML) 技术，仅保留最大的动力学显式地展示，而小尺度动力学则通过基于ML的子网格模型来描述。将这种新颖的方法应用于自驱动的等离子体湍流，能够去除大部分惯性范围，将计算量降低了大约三个数量级，同时保留了湍流系统的统计物理性质。

    Turbulence in fluids, gases, and plasmas remains an open problem of both practical and fundamental importance. Its irreducible complexity usually cannot be tackled computationally in a brute-force style. Here, we combine Large Eddy Simulation (LES) techniques with Machine Learning (ML) to retain only the largest dynamics explicitly, while small-scale dynamics are described by an ML-based sub-grid-scale model. Applying this novel approach to self-driven plasma turbulence allows us to remove large parts of the inertial range, reducing the computational effort by about three orders of magnitude, while retaining the statistical physical properties of the turbulent system.
    
[^27]: 针对随机驾驶环境的不确定性感知决策Transformer

    Uncertainty-Aware Decision Transformer for Stochastic Driving Environments. (arXiv:2309.16397v1 [cs.LG])

    [http://arxiv.org/abs/2309.16397](http://arxiv.org/abs/2309.16397)

    本论文提出了一种针对随机驾驶环境的不确定性感知决策Transformer（UNREST），通过估计状态的不确定性并相应地分割序列，取代了全局回报。这项工作通过解决在不确定性环境中过于乐观的问题，为离线强化学习在自主驾驶任务中的应用提供了一种有效的解决方案。

    

    离线强化学习（RL）已经成为一种无需主动交互的学习策略的有希望框架，因此在自主驾驶任务中尤其吸引人。最近Transformers的成功启发了将离线RL视为序列建模，这在长期任务中表现出色。然而，在具有不确定性的环境中，它们过于乐观，错误地假设相同的目标可以通过相同的动作一致实现。在本文中，我们引入了一种针对随机驾驶环境的不确定性感知决策Transformer（UNREST），不引入额外的转换模型或复杂的生成模型来进行规划。具体而言，UNREST通过转换与回报之间的条件互信息来估计状态的不确定性，并相应地分割序列。通过发现驾驶环境的“不确定性累积”和“时间局部性”特性，UNREST将决策Transformer中的全局回报替换为较少的部分回报。

    Offline Reinforcement Learning (RL) has emerged as a promising framework for learning policies without active interactions, making it especially appealing for autonomous driving tasks. Recent successes of Transformers inspire casting offline RL as sequence modeling, which performs well in long-horizon tasks. However, they are overly optimistic in stochastic environments with incorrect assumptions that the same goal can be consistently achieved by identical actions. In this paper, we introduce an UNcertainty-awaRE deciSion Transformer (UNREST) for planning in stochastic driving environments without introducing additional transition or complex generative models. Specifically, UNREST estimates state uncertainties by the conditional mutual information between transitions and returns, and segments sequences accordingly. Discovering the `uncertainty accumulation' and `temporal locality' properties of driving environments, UNREST replaces the global returns in decision transformers with less 
    
[^28]: 通过Sobolev训练的二维Copula逼近变换：2-Cats网络

    Differential 2D Copula Approximating Transforms via Sobolev Training: 2-Cats Networks. (arXiv:2309.16391v1 [cs.LG])

    [http://arxiv.org/abs/2309.16391](http://arxiv.org/abs/2309.16391)

    本文介绍了一种通过Sobolev训练的2-Cats网络，它能够非参数地逼近任何二维Copula，并且在估计输出方面优于现有技术。

    

    Copula是一种强大的统计工具，用于捕捉数据维度之间的依赖关系。在应用Copula时，我们可以通过首先估计独立的边际分布（一个简单任务），然后估计连接边际的单个Copula函数C（一个困难任务）来估计多元分布函数。对于二维数据，Copula是一个形如C：(u，v)∈\mathbf{I}^2\rightarrow \mathbf{I}的二次增函数，其中\mathbf{I}=[0，1]。在本文中，我们展示了神经网络（NNs）如何能够非参数地逼近任何二维Copula。我们的方法被称为2-Cats，受到物理启发的神经网络和Sobolev训练文献的启发。我们不仅证明了我们能够比现有技术更好地估计2D Copula的输出，而且我们的方法是非参数的，并且符合Copula C的数学性质。

    Copulas are a powerful statistical tool that captures dependencies across data dimensions. When applying Copulas, we can estimate multivariate distribution functions by initially estimating independent marginals, an easy task, and then a single copulating function, $C$, to connect the marginals, a hard task. For two-dimensional data, a copula is a two-increasing function of the form $C: (u,v)\in \mathbf{I}^2 \rightarrow \mathbf{I}$, where $\mathbf{I} = [0, 1]$. In this paper, we show how Neural Networks (NNs) can approximate any two-dimensional copula non-parametrically. Our approach, denoted as 2-Cats, is inspired by the Physics-Informed Neural Networks and Sobolev Training literature. Not only do we show that we can estimate the output of a 2d Copula better than the state-of-the-art, our approach is non-parametric and respects the mathematical properties of a Copula $C$.
    
[^29]: RLLTE：强化学习的长期演进项目

    RLLTE: Long-Term Evolution Project of Reinforcement Learning. (arXiv:2309.16382v1 [cs.AI])

    [http://arxiv.org/abs/2309.16382](http://arxiv.org/abs/2309.16382)

    RLLTE是一种长期演进、极度模块化和开源的强化学习框架，提供了完整的生态系统，预计将为RL工程实践设定标准并刺激产业和学术界。

    

    我们提出了RLLTE：一种长期演进、极度模块化和开源的强化学习（RL）研究与应用框架。除了提供一流的算法实现之外，RLLTE还作为一个算法开发工具包。具体来说，RLLTE完全解耦了RL算法与开发算法的实践角度，提供了大量组件来加速算法的发展和演进。特别地，RLLTE是第一个构建了完整丰富的生态系统的RL框架，其中包括模型训练、评估、部署、基准测试中心和大语言模型（LLM）增强的副驾驶。预期RLLTE将为RL工程实践设定标准，并对产业和学术界具有高度刺激作用。

    We present RLLTE: a long-term evolution, extremely modular, and open-source framework for reinforcement learning (RL) research and application. Beyond delivering top-notch algorithm implementations, RLLTE also serves as a toolkit for developing algorithms. More specifically, RLLTE decouples the RL algorithms completely from the exploitation-exploration perspective, providing a large number of components to accelerate algorithm development and evolution. In particular, RLLTE is the first RL framework to build a complete and luxuriant ecosystem, which includes model training, evaluation, deployment, benchmark hub, and large language model (LLM)-empowered copilot. RLLTE is expected to set standards for RL engineering practice and be highly stimulative for industry and academia.
    
[^30]: 适用于IceCube事件重构的条件正态流

    Conditional normalizing flows for IceCube event reconstruction. (arXiv:2309.16380v1 [astro-ph.HE])

    [http://arxiv.org/abs/2309.16380](http://arxiv.org/abs/2309.16380)

    该论文提出了使用条件正态流对IceCube中微子观测站的事件重构进行推断的方法，这些条件正态流可以正确地考虑南极冰的光学特性和其与探测器的关系。这项研究在下一代重构工作中具有很大的潜力。

    

    IceCube中微子观测站是部署在南极冰中的一个立方千米级的高能中微子探测器。两个主要的事件类别是带电电子和带电μ中微子相互作用。在本文中，我们讨论了使用条件正态流对这些类别的方向和能量进行推断。它们允许基于原始数据对每个单独事件推导出一个后验分布，这些数据可能包括系统不确定性，这使得它们非常适用于下一代重构工作。对于每个正态流，我们使用微分熵和KL散度到其最大熵近似来解释结果。正态流正确地包含了南极冰的复杂光学特性及其与嵌入式探测器的关系。对于淋浴事件，微分熵在高光子吸收区域增加，在清晰冰中减少。对于μ子，微分熵与所包含的区域强相关。

    The IceCube Neutrino Observatory is a cubic-kilometer high-energy neutrino detector deployed in the Antarctic ice. Two major event classes are charged-current electron and muon neutrino interactions. In this contribution, we discuss the inference of direction and energy for these classes using conditional normalizing flows. They allow to derive a posterior distribution for each individual event based on the raw data that can include systematic uncertainties, which makes them very promising for next-generation reconstructions. For each normalizing flow we use the differential entropy and the KL-divergence to its maximum entropy approximation to interpret the results. The normalizing flows correctly incorporate complex optical properties of the Antarctic ice and their relation to the embedded detector. For showers, the differential entropy increases in regions of high photon absorption and decreases in clear ice. For muons, the differential entropy strongly correlates with the contained 
    
[^31]: 认知逻辑程序：一些性质的研究

    Epistemic Logic Programs: a study of some properties. (arXiv:2309.16344v1 [cs.AI])

    [http://arxiv.org/abs/2309.16344](http://arxiv.org/abs/2309.16344)

    本论文研究了认知逻辑程序（ELPs），通过引入认知运算符和世界观的概念，提供了一种类似于传统ASP的自下而上模块化计算方法，并提出了一种等价的自上而下方法，可以应用于现有的多种语义，并且在任何语义下都是一致的。

    

    认知逻辑程序（ELPs）在答案集编程（ASP）的基础上引入了认知运算符。这类程序的语义是通过世界观来提供的，世界观是一组信念集合，即句法上的原子集合的集合。不同的语义方法提出了不同的世界观刻画方式。最近的工作引入了一些对ELPs的语义满足的性质，例如认知分割性质，如果满足该性质，可以类似于传统的ASP以自下而上的方式模块化地计算世界观。我们分析了改变观察角度的可能性，从自下而上的分裂方法转向自上而下的方法。我们提出了一种基本的自上而下方法，并证明它与自下而上方法等价。然后我们提出了一种扩展的方法，其中我们的新定义：（i）可以证明适用于许多现有的语义；（ii）与“传统”的ASP类似地操作；（iii）在任何语义下都可以证明一致。

    Epistemic Logic Programs (ELPs), extend Answer Set Programming (ASP) with epistemic operators. The semantics of such programs is provided in terms of world views, which are sets of belief sets, i.e., syntactically, sets of sets of atoms. Different semantic approaches propose different characterizations of world views. Recent work has introduced semantic properties that should be met by any semantics for ELPs, like the Epistemic Splitting Property, that, if satisfied, allows to modularly compute world views in a bottom-up fashion, analogously to ``traditional'' ASP. We analyze the possibility of changing the perspective, shifting from a bottom-up to a top-down approach to splitting. We propose a basic top-down approach, which we prove to be equivalent to the bottom-up one. We then propose an extended approach, where our new definition: (i) is provably applicable to many of the existing semantics; (ii) operates similarly to ``traditional'' ASP; (iii) provably coincides under any semantic
    
[^32]: 由深度神经网络从12导联心电图中进行的房颤风险预测的端到端方法

    End-to-end Risk Prediction of Atrial Fibrillation from the 12-Lead ECG by Deep Neural Networks. (arXiv:2309.16335v1 [cs.LG])

    [http://arxiv.org/abs/2309.16335](http://arxiv.org/abs/2309.16335)

    该研究提出了一种由深度神经网络进行的端到端方法，可以从12导联心电图中预测房颤的风险。研究结果显示，该模型可以在目前的心电图中识别出未来会发展房颤的患者，并可以根据患者的风险等级评估他们在一定时间内发展房颤的可能性。

    

    背景：房颤是最常见的心律失常之一，每年影响全球数百万人，与中风和心力衰竭等心血管疾病的风险密切相关。机器学习方法在评估从心电图中发展房颤的风险方面取得了有希望的结果。我们的目标是在巴西收集的大型CODE数据集上开发和评估这样的算法。结果：深度神经网络模型识别出在目前的心电图中没有房颤迹象，但将来会发展房颤的患者，AUC得分为0.845。从我们的生存模型中得知，高风险组（即未来房颤发病概率大于0.7）的患者在40周内发展房颤的可能性要高出50%，而属于最低风险组（即未来房颤发病概率小于或等于0.1）的患者有超过85%的机会。

    Background: Atrial fibrillation (AF) is one of the most common cardiac arrhythmias that affects millions of people each year worldwide and it is closely linked to increased risk of cardiovascular diseases such as stroke and heart failure. Machine learning methods have shown promising results in evaluating the risk of developing atrial fibrillation from the electrocardiogram. We aim to develop and evaluate one such algorithm on a large CODE dataset collected in Brazil.  Results: The deep neural network model identified patients without indication of AF in the presented ECG but who will develop AF in the future with an AUC score of 0.845. From our survival model, we obtain that patients in the high-risk group (i.e. with the probability of a future AF case being greater than 0.7) are 50% more likely to develop AF within 40 weeks, while patients belonging to the minimal-risk group (i.e. with the probability of a future AF case being less than or equal to 0.1) have more than 85% chance of r
    
[^33]: 基于递归组合多粒度表示的Transformer增强模型

    Augmenting transformers with recursively composed multi-grained representations. (arXiv:2309.16319v1 [cs.CL])

    [http://arxiv.org/abs/2309.16319](http://arxiv.org/abs/2309.16319)

    ReCAT是一种增强的Transformer模型，使用递归组合和上下文内外层能够模拟文本的层级句法结构，并生成与其他跨度上下文相关的多粒度表示。

    

    我们提出了一种名为ReCAT的递归组合增强Transformer模型，它能够在学习和推理过程中明确建模原始文本的层级句法结构，而无需依赖于黄金树。现有研究限制数据遵循层级树结构，因此缺乏跨距通信。为了克服这个问题，我们提出了一种新颖的上下文内外(CIO)层，通过自底向上和自顶向下的传递学习跨度的上下文化表示，其中自底向上传递通过组合低级跨度形成高级跨度的表示，而自顶向下传递则结合了跨度内部和外部的信息。通过在嵌入层和注意力层之间叠加多个CIO层，ReCAT模型可以进行跨距内部和跨距间的深层交互，从而生成与其他跨度完全上下文化的多粒度表示。此外，CIO层可以进行联合预训练。

    We present ReCAT, a recursive composition augmented Transformer that is able to explicitly model hierarchical syntactic structures of raw texts without relying on gold trees during both learning and inference. Existing research along this line restricts data to follow a hierarchical tree structure and thus lacks inter-span communications. To overcome the problem, we propose a novel contextual inside-outside (CIO) layer that learns contextualized representations of spans through bottom-up and top-down passes, where a bottom-up pass forms representations of high-level spans by composing low-level spans, while a top-down pass combines information inside and outside a span. By stacking several CIO layers between the embedding layer and the attention layers in Transformer, the ReCAT model can perform both deep intra-span and deep inter-span interactions, and thus generate multi-grained representations fully contextualized with other spans. Moreover, the CIO layers can be jointly pre-trained
    
[^34]: RL方法的效率分离：无模型、有模型和目标条件下的效率分析

    Efficiency Separation between RL Methods: Model-Free, Model-Based and Goal-Conditioned. (arXiv:2309.16291v1 [cs.LG])

    [http://arxiv.org/abs/2309.16291](http://arxiv.org/abs/2309.16291)

    本论文证明了无模型和有模型强化学习方法在效率上存在根本的限制，但目标条件下的方法和构建逆动力学模型的算法不受该限制。

    

    我们证明了一类广泛的强化学习（RL）算法的效率的基本限制。这个限制适用于无模型的RL方法，以及一系列的有模型方法，如树搜索的规划。在对这类问题的抽象定义下，我们提供了一系列RL问题，对于这些方法来说，它们与环境的交互寻找最优行为的时间复杂度下界是指数级的。然而，存在一种方法，不针对这个特定的问题家族，可以高效地解决这个问题家族中的问题。相比之下，我们的限制不适用于文献中提出的几种方法，例如目标条件下的方法或构建逆动力学模型的其他算法。

    We prove a fundamental limitation on the efficiency of a wide class of Reinforcement Learning (RL) algorithms. This limitation applies to model-free RL methods as well as a broad range of model-based methods, such as planning with tree search.  Under an abstract definition of this class, we provide a family of RL problems for which these methods suffer a lower bound exponential in the horizon for their interactions with the environment to find an optimal behavior. However, there exists a method, not tailored to this specific family of problems, which can efficiently solve the problems in the family.  In contrast, our limitation does not apply to several types of methods proposed in the literature, for instance, goal-conditioned methods or other algorithms that construct an inverse dynamics model.
    
[^35]: LawBench: 对大型语言模型的法律知识进行基准测试

    LawBench: Benchmarking Legal Knowledge of Large Language Models. (arXiv:2309.16289v1 [cs.CL])

    [http://arxiv.org/abs/2309.16289](http://arxiv.org/abs/2309.16289)

    LawBench针对大型语言模型的法律知识进行了综合评估，从记忆，理解和应用三个层面评估了它们在法律任务上的能力。

    

    大型语言模型（LLMs）在各方面表现出了强大的能力。然而，当将它们应用于高度专业化、安全关键的法律领域时，尚不清楚它们所具备的法律知识量以及它们是否能可靠地执行与法律相关的任务。为了填补这一空白，我们提出了一个全面评估基准LawBench。LawBench经过精心设计，从三个认知层面对LLMs的法律能力进行精确评估：（1）法律知识记忆：LLMs是否能够记住所需的法律概念、条款和事实；（2）法律知识理解：LLMs是否能够理解法律文本中的实体、事件和关系；（3）法律知识应用：LLMs是否能够正确运用自己的法律知识并进行必要的推理步骤来解决现实的法律任务。LawBench包含20个多样化的任务，涵盖了5种任务类型：单标签分类（SLC）、多标签分类（MLC）、回归等。

    Large language models (LLMs) have demonstrated strong capabilities in various aspects. However, when applying them to the highly specialized, safe-critical legal domain, it is unclear how much legal knowledge they possess and whether they can reliably perform legal-related tasks. To address this gap, we propose a comprehensive evaluation benchmark LawBench. LawBench has been meticulously crafted to have precise assessment of the LLMs' legal capabilities from three cognitive levels: (1) Legal knowledge memorization: whether LLMs can memorize needed legal concepts, articles and facts; (2) Legal knowledge understanding: whether LLMs can comprehend entities, events and relationships within legal text; (3) Legal knowledge applying: whether LLMs can properly utilize their legal knowledge and make necessary reasoning steps to solve realistic legal tasks. LawBench contains 20 diverse tasks covering 5 task types: single-label classification (SLC), multi-label classification (MLC), regression, e
    
[^36]: 通用的异构联邦交叉相关和实例相似性学习

    Generalizable Heterogeneous Federated Cross-Correlation and Instance Similarity Learning. (arXiv:2309.16286v1 [cs.LG])

    [http://arxiv.org/abs/2309.16286](http://arxiv.org/abs/2309.16286)

    本文提出了一种通用的异构联邦交叉相关和实例相似性学习的方法，利用非目标蒸馏来解决模型异质性和灾难性遗忘问题，提高了联邦学习的泛化能力和应用性能。

    

    联邦学习是一种重要的保护隐私的多方学习范式，涉及与他人的合作学习和对私有数据的本地更新。模型异质性和灾难性遗忘是两个重要的挑战，极大地限制了应用和泛化性能。本文提出了一种新颖的FCCL+方法，即联邦相关性和相似性学习与非目标蒸馏，促进了域内区分能力和域间泛化能力。对于异质性问题，我们利用无关的未标记公共数据来进行异构参与者之间的通信。我们构建交叉相关矩阵，并在标志和特征水平上对实例相似性分布进行对齐，有效地克服了通信障碍并提高了广泛的能力。对于本地更新阶段的灾难性遗忘，FCCL+引入了联邦非目标蒸馏，既保留了域间知识又避免了优化问题。

    Federated learning is an important privacy-preserving multi-party learning paradigm, involving collaborative learning with others and local updating on private data. Model heterogeneity and catastrophic forgetting are two crucial challenges, which greatly limit the applicability and generalizability. This paper presents a novel FCCL+, federated correlation and similarity learning with non-target distillation, facilitating the both intra-domain discriminability and inter-domain generalization. For heterogeneity issue, we leverage irrelevant unlabeled public data for communication between the heterogeneous participants. We construct cross-correlation matrix and align instance similarity distribution on both logits and feature levels, which effectively overcomes the communication barrier and improves the generalizable ability. For catastrophic forgetting in local updating stage, FCCL+ introduces Federated Non Target Distillation, which retains inter-domain knowledge while avoiding the opt
    
[^37]: UPB @ ACTI: 使用经过微调的句子Transformer来检测阴谋论

    UPB @ ACTI: Detecting Conspiracies using fine tuned Sentence Transformers. (arXiv:2309.16275v1 [cs.CL])

    [http://arxiv.org/abs/2309.16275](http://arxiv.org/abs/2309.16275)

    使用经过微调的句子Transformer模型和数据增强技术，本研究在阴谋论检测任务中取得了很好的成绩，超过了其他竞争系统。

    

    阴谋论已成为在线讨论的重要和令人担忧的方面，对信息完整性和社会信任构成挑战。因此，我们将阴谋论检测作为ACTI @ EVALITA 2023共享任务的提议。使用预训练的句子Transformer模型和数据增强技术的组合使我们在两个子任务的最终排行榜中获得第一名。我们的方法在二元分类中获得了85.71%的F1分数，在精细阴谋主题分类中获得了91.23%的F1分数，超过其他竞争系统。

    Conspiracy theories have become a prominent and concerning aspect of online discourse, posing challenges to information integrity and societal trust. As such, we address conspiracy theory detection as proposed by the ACTI @ EVALITA 2023 shared task. The combination of pre-trained sentence Transformer models and data augmentation techniques enabled us to secure first place in the final leaderboard of both sub-tasks. Our methodology attained F1 scores of 85.71% in the binary classification and 91.23% for the fine-grained conspiracy topic classification, surpassing other competing systems.
    
[^38]: 多智能体系统中的合作动力学：探索具有均值场均衡的博弈理论情景

    Cooperation Dynamics in Multi-Agent Systems: Exploring Game-Theoretic Scenarios with Mean-Field Equilibria. (arXiv:2309.16263v1 [cs.GT])

    [http://arxiv.org/abs/2309.16263](http://arxiv.org/abs/2309.16263)

    本文研究在多智能体系统中激发合作的策略和方法，通过分析现有的合作策略和引入鼓励团队回报的修改，解决了在分布式系统中存在的现实困境。同时，利用均值场博弈理论，建立了无限大智能体集合中的平衡解和奖励结构。

    

    合作是多智能体系统（MAS）和多智能体强化学习（MARL）中的基本要素，通常要求智能体在个体收益和集体回报之间保持平衡。本文旨在研究在博弈理论情景中激发合作的策略，例如迭代囚徒困境，在这种情况下，智能体必须优化个体和团队的结果。分析了现有的合作策略对于促进重复博弈中团队导向行为的有效性。提出了一种修改，即鼓励团队回报也将导致更高的个体收益，解决了分布式系统中存在的现实困境。研究还扩展到智能体人口指数增长的情景（$N \longrightarrow +\infty$），在这种情况下，传统计算和平衡确定具有挑战性。利用均值场博弈理论，建立了无限大智能体集合中的平衡解和奖励结构。

    Cooperation is fundamental in Multi-Agent Systems (MAS) and Multi-Agent Reinforcement Learning (MARL), often requiring agents to balance individual gains with collective rewards. In this regard, this paper aims to investigate strategies to invoke cooperation in game-theoretic scenarios, namely the Iterated Prisoner's Dilemma, where agents must optimize both individual and group outcomes. Existing cooperative strategies are analyzed for their effectiveness in promoting group-oriented behavior in repeated games. Modifications are proposed where encouraging group rewards will also result in a higher individual gain, addressing real-world dilemmas seen in distributed systems. The study extends to scenarios with exponentially growing agent populations ($N \longrightarrow +\infty$), where traditional computation and equilibrium determination are challenging. Leveraging mean-field game theory, equilibrium solutions and reward structures are established for infinitely large agent sets in repea
    
[^39]: QonFusion -- 高斯随机变量的量子方法：在稳定性扩散和布朗运动中的应用

    QonFusion -- Quantum Approaches to Gaussian Random Variables: Applications in Stable Diffusion and Brownian Motion. (arXiv:2309.16258v1 [quant-ph])

    [http://arxiv.org/abs/2309.16258](http://arxiv.org/abs/2309.16258)

    本研究提出了一种以非参数量子电路为基础的策略，用于生成高斯随机变量，并将量子随机数生成器纳入经典扩散模型。与传统方法相比，这种方法可以直接生成符合要求的随机变量，避免了计算量大的优化过程。

    

    在本研究中，我们描述了一种以非参数量子电路为重点的策略，用于生成高斯随机变量（GRVs）。这种以量子为中心的方法作为传统伪随机数生成器（PRNGs）的替代品，如PyTorch中的\textbf{torch.rand}函数。我们研究的主题是将量子随机数生成器（QRNGs）纳入经典扩散模型中。值得注意的是，我们的量子高斯随机变量生成器在稳定扩散（SD）和布朗运动（BM）中发挥了双重作用。这与使用参数化量子电路（PQCs）以及变分量子本征解算器（VQEs）的现有方法有显著不同。尽管传统技术可以准确地近似复杂系统中的基态或建模精细的概率分布，但它们需要计算量大的优化过程来调整参数。我们的非参数量子电路可以直接生成符合要求的随机变量，避免了这一优化过程。

    In the present study, we delineate a strategy focused on non-parametric quantum circuits for the generation of Gaussian random variables (GRVs). This quantum-centric approach serves as a substitute for conventional pseudorandom number generators (PRNGs), such as the \textbf{torch.rand} function in PyTorch. The principal theme of our research is the incorporation of Quantum Random Number Generators (QRNGs) into classical models of diffusion. Notably, our Quantum Gaussian Random Variable Generator fulfills dual roles, facilitating simulations in both Stable Diffusion (SD) and Brownian Motion (BM). This diverges markedly from prevailing methods that utilize parametric quantum circuits (PQCs), often in conjunction with variational quantum eigensolvers (VQEs). Although conventional techniques can accurately approximate ground states in complex systems or model elaborate probability distributions, they require a computationally demanding optimization process to tune parameters. Our non-param
    
[^40]: 使用CNN迁移学习算法的非破坏性鸡蛋受精检测

    Nondestructive chicken egg fertility detection using CNN-transfer learning algorithms. (arXiv:2309.16257v1 [cs.CV])

    [http://arxiv.org/abs/2309.16257](http://arxiv.org/abs/2309.16257)

    本研究使用CNN迁移学习算法对鸡蛋受精进行了非破坏性检测，实现了精确的家禽孵化场实践；通过对四种模型的训练和评估，发现InceptionNet在准确度和性能上表现最佳，在测试集中达到了0.98的准确度，并且对可孵化和不可孵化的鸡蛋都有高精确度的分类能力。

    

    本研究探讨了使用CNN迁移学习算法对鸡蛋受精进行非破坏性检测，以实现精确的家禽孵化场实践。使用增广图像（旋转、翻转、缩放、平移和反射）对四种模型（VGG16、ResNet50、InceptionNet和MobileNet）进行训练和评估，数据集包括200个单一鸡蛋图像。虽然训练结果显示所有模型均达到了较高的准确度，表明它们能够准确地学习和分类鸡蛋的受精状态，但在测试集上评估时，准确度和性能存在差异。InceptionNet表现出了最佳的整体性能，能够准确地分类可孵化和不可孵化的鸡蛋。在评估指标的所有参数上，在训练集和测试集中都表现出了优异的性能。在测试集中，它实现了0.98的准确度，1的敏感性来检测可孵化的鸡蛋，并以0.96的特异性来识别不可孵化的鸡蛋。

    This study explored the application of CNN-Transfer Learning for nondestructive chicken egg fertility detection for precision poultry hatchery practices. Four models, VGG16, ResNet50, InceptionNet, and MobileNet, were trained and evaluated on a dataset (200 single egg images) using augmented images (rotation, flip, scale, translation, and reflection). Although the training results demonstrated that all models achieved high accuracy, indicating their ability to accurately learn and classify chicken eggs' fertility state, when evaluated on the testing set, variations in accuracy and performance were observed. InceptionNet exhibited the best overall performance, accurately classifying fertile and non-fertile eggs. It demonstrated excellent performance in both training and testing sets in all parameters of the evaluation metrics. In testing set, it achieved an accuracy of 0.98, a sensitivity of 1 for detecting fertile eggs, and a specificity of 0.96 for identifying non-fertile eggs. The hi
    
[^41]: 超越逆KL：通过多样的差异约束推广直接偏好优化

    Beyond Reverse KL: Generalizing Direct Preference Optimization with Diverse Divergence Constraints. (arXiv:2309.16240v1 [cs.LG])

    [http://arxiv.org/abs/2309.16240](http://arxiv.org/abs/2309.16240)

    本论文提出了一种通过引入多样差异约束推广直接偏好优化（DPO）的方法，该方法消除了对估计方法的需要并简化了奖励和最优策略之间的复杂关系。

    

    大型语言模型（LLM）的不断增强能力为人工智能提供了机会，但同时也放大了安全问题，如AI系统的潜在滥用，这需要有效的AI对齐。基于人类反馈的强化学习（RLHF）已经成为AI对齐的一条有希望的路径，但由于其复杂性和对独立奖励模型的依赖性而带来了挑战。直接偏好优化（DPO）被提出作为一种替代方法，在逆KL正则化约束下等同于RLHF。本文提出了f-DPO，一种通过整合多样的差异约束来推广DPO的方法。我们证明，在某些f-散度下，包括Jensen-Shannon散度、正向KL散度和α-散度，奖励和最优策略之间的复杂关系也可以通过解决Karush-Kuhn-Tucker条件来简化。这消除了对估计方法的需要。

    The increasing capabilities of large language models (LLMs) raise opportunities for artificial general intelligence but concurrently amplify safety concerns, such as potential misuse of AI systems, necessitating effective AI alignment. Reinforcement Learning from Human Feedback (RLHF) has emerged as a promising pathway towards AI alignment but brings forth challenges due to its complexity and dependence on a separate reward model. Direct Preference Optimization (DPO) has been proposed as an alternative, and it remains equivalent to RLHF under the reverse KL regularization constraint. This paper presents $f$-DPO, a generalized approach to DPO by incorporating diverse divergence constraints. We show that under certain $f$-divergences, including Jensen-Shannon divergence, forward KL divergences and $\alpha$-divergences, the complex relationship between the reward and optimal policy can also be simplified by addressing the Karush-Kuhn-Tucker conditions. This eliminates the need for estimat
    
[^42]: 语言模型在分子发现中的应用

    Language models in molecular discovery. (arXiv:2309.16235v1 [physics.chem-ph])

    [http://arxiv.org/abs/2309.16235](http://arxiv.org/abs/2309.16235)

    语言模型在分子发现中的应用为加速药物发现和分子设计提供了有希望的方法，包括从头设计药物、性质预测和反应化学。同时，开源软件资源降低了科学语言建模领域的门槛，未来将结合聊天机器人和计算化学工具。

    

    语言模型的成功，特别是基于Transformer的架构，已经渗透到其他领域，出现了在小分子、蛋白质或聚合物上运作的“科学语言模型”。在化学领域，语言模型在加速分子发现周期方面发挥了作用，最近在早期药物发现方面有了有希望的发现。在这里，我们回顾了语言模型在分子发现中的角色，强调了从头设计药物、性质预测和反应化学方面的优势。我们还强调了有价值的开源软件资源，从而降低了科学语言建模领域的门槛。最后，我们勾画了未来分子设计的愿景，将聊天机器人界面与计算化学工具结合起来。我们的贡献为研究人员、化学家和对了解语言模型如何加速化学发现感兴趣的人提供了宝贵的资源。

    The success of language models, especially transformer-based architectures, has trickled into other domains giving rise to "scientific language models" that operate on small molecules, proteins or polymers. In chemistry, language models contribute to accelerating the molecule discovery cycle as evidenced by promising recent findings in early-stage drug discovery. Here, we review the role of language models in molecular discovery, underlining their strength in de novo drug design, property prediction and reaction chemistry. We highlight valuable open-source software assets thus lowering the entry barrier to the field of scientific language modeling. Last, we sketch a vision for future molecular design that combines a chatbot interface with access to computational chemistry tools. Our contribution serves as a valuable resource for researchers, chemists, and AI enthusiasts interested in understanding how language models can and will be used to accelerate chemical discovery.
    
[^43]: GInX-Eval: 面向图神经网络解释的内分布评估

    GInX-Eval: Towards In-Distribution Evaluation of Graph Neural Network Explanations. (arXiv:2309.16223v1 [cs.AI])

    [http://arxiv.org/abs/2309.16223](http://arxiv.org/abs/2309.16223)

    本文针对图神经网络解释的内分布评估问题，提出了GInX-Eval方法，克服了传统评估指标的局限性，为解释方法提供了新的见解。

    

    最近，为了突出图中对模型预测最有贡献的边和节点，人们开发了各种解释图神经网络（GNN）的方法。然而，目前尚不清楚如何从人类或模型的角度评估这些解释的正确性。当前评估过程中一个未解决的瓶颈问题是解释的分布与训练数据的分布不同的情况。这个重要问题会影响到现有的评估指标，如流行的忠实度或保真度得分。在本文中，我们展示了忠实度指标的局限性。我们提出了GInX-Eval（图内分布解释评估），这是一种用于评估图解释的过程，克服了忠实度的缺陷，并提供了对解释方法的新见解。使用重新训练策略，GInX得分可衡量已移除边对模型的信息量以及边的重要性。

    Diverse explainability methods of graph neural networks (GNN) have recently been developed to highlight the edges and nodes in the graph that contribute the most to the model predictions. However, it is not clear yet how to evaluate the correctness of those explanations, whether it is from a human or a model perspective. One unaddressed bottleneck in the current evaluation procedure is the problem of out-of-distribution explanations, whose distribution differs from those of the training data. This important issue affects existing evaluation metrics such as the popular faithfulness or fidelity score. In this paper, we show the limitations of faithfulness metrics. We propose GInX-Eval (Graph In-distribution eXplanation Evaluation), an evaluation procedure of graph explanations that overcomes the pitfalls of faithfulness and offers new insights on explainability methods. Using a retraining strategy, the GInX score measures how informative removed edges are for the model and the EdgeRank s
    
[^44]: 揭示变色龙：医学表格数据中的ODD检测的基准。 (arXiv:2309.16220v1 [cs.LG])

    Unmasking the Chameleons: A Benchmark for Out-of-Distribution Detection in Medical Tabular Data. (arXiv:2309.16220v1 [cs.LG])

    [http://arxiv.org/abs/2309.16220](http://arxiv.org/abs/2309.16220)

    该论文提出了一个基准来比较不同的方法在医学表格数据中进行ODD检测，为了实现在实际医疗系统中可靠地使用机器学习模型并避免对ODD数据进行不准确的预测，该基准利用了大规模的ICU患者数据集，考虑了多种方法和预测架构。

    

    尽管机器学习（ML）模型取得了成功，但它们在来自训练分布之外的数据上没有有效的泛化能力。为了可靠地在现实世界的医疗系统中使用ML模型，并避免对ODD数据进行不准确的预测，检测ODD样本至关重要。虽然在其他领域，特别是在计算机视觉领域，提出了许多ODD检测方法，但当处理医学表格数据时，是否解决了这一挑战仍不清楚。为了回答这一迫切需求，我们提出了一个广泛可复制的基准，通过多个测试来比较不同方法，包括近和远ODDs。我们的基准利用了最新版本的eICU和MIMIC-IV，这是两个公共数据集，涵盖了数万名ICU患者在多家医院。我们考虑了各种基于密度的方法和SOTA后置检测器，涵盖了多种预测架构，包括MLP、ResNet和Transformer。我们的研究结果显示。

    Despite their success, Machine Learning (ML) models do not generalize effectively to data not originating from the training distribution. To reliably employ ML models in real-world healthcare systems and avoid inaccurate predictions on out-of-distribution (OOD) data, it is crucial to detect OOD samples. Numerous OOD detection approaches have been suggested in other fields - especially in computer vision - but it remains unclear whether the challenge is resolved when dealing with medical tabular data. To answer this pressing need, we propose an extensive reproducible benchmark to compare different methods across a suite of tests including both near and far OODs. Our benchmark leverages the latest versions of eICU and MIMIC-IV, two public datasets encompassing tens of thousands of ICU patients in several hospitals. We consider a wide array of density-based methods and SOTA post-hoc detectors across diverse predictive architectures, including MLP, ResNet, and Transformer. Our findings sho
    
[^45]: VDC: 通过视觉和语言的不一致性检测脏样本的多功能数据清洁器

    VDC: Versatile Data Cleanser for Detecting Dirty Samples via Visual-Linguistic Inconsistency. (arXiv:2309.16211v1 [cs.CV])

    [http://arxiv.org/abs/2309.16211](http://arxiv.org/abs/2309.16211)

    VDC是一个多功能数据清洁器，通过检测图像和标签之间的视觉和语言不一致性来解决数据集中的脏样本问题。

    

    最近，数据中心人工智能的新概念强调了数据在构建AI系统中的作用。不幸的是，在现实世界中，数据集可能会包含脏样本，例如来自后门攻击的毒样本，众包中的噪声标签，甚至是它们的混合体。这些脏样本的存在使得DNNs变得脆弱和不可靠。因此，检测脏样本以提高数据集的质量和可靠性至关重要。现有的检测器只关注检测毒样本或噪声标签，当处理来自其他领域的脏样本时，往往容易出现弱泛化。在本文中，我们发现各种脏样本之间的一个共同性是图像和相关标签之间的视觉和语言之间的不一致性。为了捕捉模态之间的语义不一致性，我们提出了一种多功能数据清洁器(VDC)，利用跨模态对齐和推理的多模态大型语言模型(MLLM)的超过能力。它由...（此处省略）

    The role of data in building AI systems has recently been emphasized by the emerging concept of data-centric AI. Unfortunately, in the real-world, datasets may contain dirty samples, such as poisoned samples from backdoor attack, noisy labels in crowdsourcing, and even hybrids of them. The presence of such dirty samples makes the DNNs vunerable and unreliable.Hence, it is critical to detect dirty samples to improve the quality and realiability of dataset. Existing detectors only focus on detecting poisoned samples or noisy labels, that are often prone to weak generalization when dealing with dirty samples from other domains.In this paper, we find a commonality of various dirty samples is visual-linguistic inconsistency between images and associated labels. To capture the semantic inconsistency between modalities, we propose versatile data cleanser (VDC) leveraging the surpassing capabilities of multimodal large language models (MLLM) in cross-modal alignment and reasoning.It consists o
    
[^46]: 从基本原理出发的更一般的诊断理论

    A More General Theory of Diagnosis from First Principles. (arXiv:2309.16180v1 [cs.AI])

    [http://arxiv.org/abs/2309.16180](http://arxiv.org/abs/2309.16180)

    本文提出了从基本原理出发的更一般的诊断理论，该理论将模型诊断推广为对所有类型的系统和诊断都适用的方法。在相对温和的假设下，我们的算法可以正确计算出首选诊断候选集合。

    

    模型诊断是人工智能、形式方法和控制等不同社区中的一个活跃的研究话题。这导致了一系列不同的方法来处理不同类型的系统和寻找不同形式的诊断。本文通过将Reiter的理论推广为对系统和诊断类型不可知的方法来解决这些差异。这个更一般的基于基本原理的诊断理论将最小诊断定义为在假设的搜索空间中的首选诊断候选集合。计算最小诊断是通过探索诊断假设空间、测试一组假设与系统模型和观察的一致性，并生成排除继承者和其他部分搜索空间的冲突来实现的。在相对温和的假设下，我们的算法可以正确计算出首选诊断候选集合。主要困难在于s

    Model-based diagnosis has been an active research topic in different communities including artificial intelligence, formal methods, and control. This has led to a set of disparate approaches addressing different classes of systems and seeking different forms of diagnoses. In this paper, we resolve such disparities by generalising Reiter's theory to be agnostic to the types of systems and diagnoses considered. This more general theory of diagnosis from first principles defines the minimal diagnosis as the set of preferred diagnosis candidates in a search space of hypotheses. Computing the minimal diagnosis is achieved by exploring the space of diagnosis hypotheses, testing sets of hypotheses for consistency with the system's model and the observation, and generating conflicts that rule out successors and other portions of the search space. Under relatively mild assumptions, our algorithms correctly compute the set of preferred diagnosis candidates. The main difficulty here is that the s
    
[^47]: CoinRun: 解决目标错误泛化问题

    CoinRun: Solving Goal Misgeneralisation. (arXiv:2309.16166v1 [cs.AI])

    [http://arxiv.org/abs/2309.16166](http://arxiv.org/abs/2309.16166)

    本文介绍了通过使用ACE代理解决目标错误泛化中的CoinRun挑战，并展示了自主代理在新环境下可以在不使用新奖励信息的情况下，在关键情况下受人信任地行动。

    

    目标错误泛化是人工智能对齐的一个重要挑战，即使强大的人工智能能够将其目标与人类意图和道德对齐。在本文中，我们展示了ACE（概念扩展算法）代理如何解决目标错误泛化的一项关键标准挑战：CoinRun挑战。该代理在新环境中不使用任何新的奖励信息。这表明自主代理可以在新颖和关键的情况下受人信任地行动。

    Goal misgeneralisation is a key challenge in AI alignment -- the task of getting powerful Artificial Intelligences to align their goals with human intentions and human morality. In this paper, we show how the ACE (Algorithm for Concept Extrapolation) agent can solve one of the key standard challenges in goal misgeneralisation: the CoinRun challenge. It uses no new reward information in the new environment. This points to how autonomous agents could be trusted to act in human interests, even in novel and critical situations.
    
[^48]: 在不可预测环境中利用不可信命令实现多机器人协同: 一种赌博次模最大化方法

    Leveraging Untrustworthy Commands for Multi-Robot Coordination in Unpredictable Environments: A Bandit Submodular Maximization Approach. (arXiv:2309.16161v1 [eess.SY])

    [http://arxiv.org/abs/2309.16161](http://arxiv.org/abs/2309.16161)

    本文研究了在不可预测和部分可观测环境中，利用不可信的外部命令进行多机器人协同的问题。提出了一种算法，Meta Bandit Sequential Greedy (MetaBSG)，能够在外部命令任意糟糕的情况下提供性能保证。

    

    本文研究了在不可预测和部分可观测环境中，利用不可信的外部命令进行多智能体协同的问题。这些命令是对机器人建议的动作，由于其性能保证未知，因此被认为是不可信的。这些命令可以由人工操作员或机器学习算法生成，并且尽管不可信，但通常可以提高复杂多机器人任务的性能。我们的研究动机来源于复杂的多机器人任务，如目标跟踪、环境建模和区域监测。由于机器人之间的信息重叠，这些任务通常被建模为次模最大化问题。我们提供了一种算法，元赌博顺贪心（MetaBSG），即使外部命令任意糟糕，它也能够提供性能保证。MetaBSG利用元算法学习机器人是否应该遵循命令，或者应该采用最近开发的次模协同算法，赌博顺利算法。

    We study the problem of multi-agent coordination in unpredictable and partially-observable environments with untrustworthy external commands. The commands are actions suggested to the robots, and are untrustworthy in that their performance guarantees, if any, are unknown. Such commands may be generated by human operators or machine learning algorithms and, although untrustworthy, can often increase the robots' performance in complex multi-robot tasks. We are motivated by complex multi-robot tasks such as target tracking, environmental mapping, and area monitoring. Such tasks are often modeled as submodular maximization problems due to the information overlap among the robots. We provide an algorithm, Meta Bandit Sequential Greedy (MetaBSG), which enjoys performance guarantees even when the external commands are arbitrarily bad. MetaBSG leverages a meta-algorithm to learn whether the robots should follow the commands or a recently developed submodular coordination algorithm, Bandit Sequ
    
[^49]: AE-GPT:使用大型语言模型从监测报告中提取不良事件-以流感疫苗不良事件为例

    AE-GPT: Using Large Language Models to Extract Adverse Events from Surveillance Reports-A Use Case with Influenza Vaccine Adverse Events. (arXiv:2309.16150v1 [cs.CL])

    [http://arxiv.org/abs/2309.16150](http://arxiv.org/abs/2309.16150)

    AE-GPT是一种使用大型语言模型的方法，可以从监测报告中提取不良事件，该研究以流感疫苗不良事件为例评估了该方法的能力，发现经过微调的GPT 3.5模型（AE-GPT）在严格匹配和灵活匹配方面表现优秀，显示了LLMs在处理医学数据方面的潜力，可推广到其他不良事件提取任务。

    

    尽管疫苗在全球健康、减轻传染病和大流行爆发方面起着重要作用，但偶尔也会导致不良事件（AEs）。近年来，大型语言模型（LLMs）在有效识别和编目临床报告中的不良事件方面显示出潜力。本研究利用1990年至2016年来自疫苗不良事件报告系统（VAERS）的数据，特别关注评估LLMs在不良事件提取方面的能力。使用流感疫苗作为使用案例，评估了各种主流的LLMs，包括GPT-2、GPT-3变体、GPT-4和Llama 2。经过微调的GPT 3.5模型（AE-GPT）在严格匹配方面的平均微 F1 分数为0.704，灵活匹配方面为0.816。AE-GPT的令人鼓舞的表现突显了LLMs在处理医学数据方面的潜力，表明在先进的AE检测方面迈出了重要的一步，因此可以推广到其他AE提取任务。

    Though Vaccines are instrumental in global health, mitigating infectious diseases and pandemic outbreaks, they can occasionally lead to adverse events (AEs). Recently, Large Language Models (LLMs) have shown promise in effectively identifying and cataloging AEs within clinical reports. Utilizing data from the Vaccine Adverse Event Reporting System (VAERS) from 1990 to 2016, this study particularly focuses on AEs to evaluate LLMs' capability for AE extraction. A variety of prevalent LLMs, including GPT-2, GPT-3 variants, GPT-4, and Llama 2, were evaluated using Influenza vaccine as a use case. The fine-tuned GPT 3.5 model (AE-GPT) stood out with a 0.704 averaged micro F1 score for strict match and 0.816 for relaxed match. The encouraging performance of the AE-GPT underscores LLMs' potential in processing medical data, indicating a significant stride towards advanced AE detection, thus presumably generalizable to other AE extraction tasks.
    
[^50]: T-COL: 为可变机器学习系统生成一般用户偏好的反事实解释

    T-COL: Generating Counterfactual Explanations for General User Preferences on Variable Machine Learning Systems. (arXiv:2309.16146v1 [cs.AI])

    [http://arxiv.org/abs/2309.16146](http://arxiv.org/abs/2309.16146)

    该论文提出了一个名为T-COL的方法，针对可变的机器学习系统和一般用户偏好生成反事实解释。这些解释不仅能够解释预测结果的原因，还提供了可操作的建议给用户。通过将一般用户偏好映射到CEs的属性上，以及采用定制化的方式来适应可变的机器学习模型，T-COL能够克服现有挑战并保持健壮性。

    

    基于机器学习的系统缺乏可解释性。为了解决这个问题，提出了反事实解释（CEs）。CEs独特之处在于它们不仅解释为什么会预测某个特定结果，还提供可操作的建议给用户。然而，CEs的应用受到了两个主要挑战的限制，即一般用户偏好和可变的机器学习系统。特别是，用户偏好往往是一般性的而不是特定的特征值。此外，CEs需要根据机器学习模型的可变性进行定制，并且在这些验证模型发生变化时仍然保持健壮性。为了克服这些挑战，我们提出了几个可能验证的一般用户偏好，并将它们映射到CEs的属性上。我们还引入了一种名为T-COL的新方法，它具有两种可选结构和几组协同操作。

    Machine learning (ML) based systems have been suffering a lack of interpretability. To address this problem, counterfactual explanations (CEs) have been proposed. CEs are unique as they provide workable suggestions to users, in addition to explaining why a certain outcome was predicted. However, the application of CEs has been hindered by two main challenges, namely general user preferences and variable ML systems. User preferences, in particular, tend to be general rather than specific feature values. Additionally, CEs need to be customized to suit the variability of ML models, while also maintaining robustness even when these validation models change. To overcome these challenges, we propose several possible general user preferences that have been validated by user research and map them to the properties of CEs. We also introduce a new method called \uline{T}ree-based \uline{C}onditions \uline{O}ptional \uline{L}inks (T-COL), which has two optional structures and several groups of co
    
[^51]: 基于元优化合成样本的生成式半监督学习

    Generative Semi-supervised Learning with Meta-Optimized Synthetic Samples. (arXiv:2309.16143v1 [cs.LG])

    [http://arxiv.org/abs/2309.16143](http://arxiv.org/abs/2309.16143)

    本文提出了一种基于生成基础模型生成的合成样本进行半监督学习的方法，旨在解决实际应用中无法获取大规模无标签数据集的问题。

    

    半监督学习是使用有标签和无标签数据集来训练深度分类模型的一种有前景的方法。然而，现有的半监督学习方法依赖于大规模的无标签数据集，在许多实际应用中由于法律限制（例如，GDPR）可能无法获取。本文研究一个问题：我们能否在没有实际无标签数据集的情况下训练半监督学习模型？我们提出了一种使用从包含数百万样本的多样领域数据集（例如ImageNet）训练的生成基础模型生成的合成数据集的半监督学习方法。我们的主要思想是识别生成基础模型中仿真无标签样本的合成样本，并使用这些合成样本来训练分类器。为了实现这一点，我们的方法被构建为一个交替优化问题：（i）元学习生成基础模型和（ii）使用真实标记样本和合成样本进行半监督学习的分类器。

    Semi-supervised learning (SSL) is a promising approach for training deep classification models using labeled and unlabeled datasets. However, existing SSL methods rely on a large unlabeled dataset, which may not always be available in many real-world applications due to legal constraints (e.g., GDPR). In this paper, we investigate the research question: Can we train SSL models without real unlabeled datasets? Instead of using real unlabeled datasets, we propose an SSL method using synthetic datasets generated from generative foundation models trained on datasets containing millions of samples in diverse domains (e.g., ImageNet). Our main concepts are identifying synthetic samples that emulate unlabeled samples from generative foundation models and training classifiers using these synthetic samples. To achieve this, our method is formulated as an alternating optimization problem: (i) meta-learning of generative foundation models and (ii) SSL of classifiers using real labeled and synthet
    
[^52]: ModuLoRA:通过与模块化量化器集成在消费级GPU上对3 Bit LLMs进行微调

    ModuLoRA: Finetuning 3-Bit LLMs on Consumer GPUs by Integrating with Modular Quantizers. (arXiv:2309.16119v1 [cs.LG])

    [http://arxiv.org/abs/2309.16119](http://arxiv.org/abs/2309.16119)

    ModuLoRA提出了一种内存高效、能够在消费级GPU上支持3比特LLMs微调的方法，并通过与模块化量化器的集成实现了竞争性能和更少的内存使用。

    

    我们提出了一种内存高效的大型语言模型（LLMs）微调算法，可支持在仅使用1个48GB GPU上以3比特或4比特精度微调具有65B参数的LLMs。我们的方法——模块化低秩自适应（ModuLoRA），通过低秩适配器（LoRA）将任何用户指定的权重量化器与微调集成。我们的方法依赖于一个简单的量化无关的反向传播，通过自定义的黑盒量化模块从低精度LLM权重中自适应地生成权重。这种方法使得首次能够进行3比特LLMs的微调，利用先进的3比特OPTQ量化往往优于依赖于较不复杂的4比特和8比特方法的微调。在我们的实验中，ModuLoRA在文本分类、自然语言推理和指令跟随任务中取得了有竞争力的性能，使用的内存比现有方法少很多，并且在一个流行的摘要任务上超过了最先进的ROUGE分数。

    We propose a memory-efficient finetuning algorithm for large language models (LLMs) that supports finetuning LLMs with 65B parameters in 3-bit or 4-bit precision on as little as one 48GB GPU. Our method, modular low-rank adaptation (ModuLoRA), integrates any user-specified weight quantizer with finetuning via low-rank adapters (LoRAs). Our approach relies on a simple quantization-agnostic backward pass that adaptively materializes low-precision LLM weights from a custom black-box quantization module. This approach enables finetuning 3-bit LLMs for the first time--leveraging state-of-the-art 3-bit OPTQ quantization often outperforms finetuning that relies on less sophisticated 4-bit and 8-bit methods. In our experiments, ModuLoRA attains competitive performance on text classification, natural language infernece, and instruction following tasks using significantly less memory than existing approaches, and we also surpass the state-of-the-art ROUGE score on a popular summarization task. W
    
[^53]: E2Net: 弹性扩展网络实现资源高效的持续学习

    E2Net: Resource-Efficient Continual Learning with Elastic Expansion Network. (arXiv:2309.16117v1 [cs.LG])

    [http://arxiv.org/abs/2309.16117](http://arxiv.org/abs/2309.16117)

    E2Net是一种资源高效的持续学习方法，通过核心子网蒸馏和精确的回放样本选择，实现了卓越的准确性和较小的遗忘，在相同的计算和存储限制下最大程度地减少了处理时间。

    

    持续学习方法旨在学习新任务而不消除以前的知识。然而，持续学习通常需要大量的计算能力和存储容量才能达到令人满意的性能。在本文中，我们提出了一种资源高效的持续学习方法，称为弹性扩展网络（E2Net）。通过核心子网蒸馏和精确的回放样本选择，E2Net在相同的计算和存储限制下实现了卓越的平均准确性和较小的遗忘，并最大程度地减少了处理时间。在E2Net中，我们提出了代表性网络蒸馏，通过评估参数数量和与工作网络的输出相似性来识别代表性的核心子网，蒸馏工作网络内的类似子网以减轻对重演缓冲区的依赖，并促进跨先前任务的知识转移。为了提高存储资源利用率，我们还提出了子网约束经验回放方法。

    Continual Learning methods are designed to learn new tasks without erasing previous knowledge. However, Continual Learning often requires massive computational power and storage capacity for satisfactory performance. In this paper, we propose a resource-efficient continual learning method called the Elastic Expansion Network (E2Net). Leveraging core subnet distillation and precise replay sample selection, E2Net achieves superior average accuracy and diminished forgetting within the same computational and storage constraints, all while minimizing processing time. In E2Net, we propose Representative Network Distillation to identify the representative core subnet by assessing parameter quantity and output similarity with the working network, distilling analogous subnets within the working network to mitigate reliance on rehearsal buffers and facilitating knowledge transfer across previous tasks. To enhance storage resource utilization, we then propose Subnet Constraint Experience Replay t
    
[^54]: 频道视觉Transformer：一张图值C x 16 x 16个词

    Channel Vision Transformers: An Image Is Worth C x 16 x 16 Words. (arXiv:2309.16108v1 [cs.CV])

    [http://arxiv.org/abs/2309.16108](http://arxiv.org/abs/2309.16108)

    本文提出了ChannelViT模型，通过对ViT架构的修改和引入分层通道采样技术，增强了对多通道图像的推理能力和鲁棒性，适用于显微镜和卫星成像等领域。

    

    视觉Transformer在现代计算机视觉领域中已经成为一种强大的架构。然而，它在某些图像领域的应用，如显微镜和卫星成像，面临着独特的挑战。在这些领域中，图像通常包含多个通道，每个通道都携带着语义上不同和独立的信息。此外，模型必须对输入通道的稀疏性表现出鲁棒性，在训练或测试过程中可能没有密集可用的通道。在本文中，我们提出了对ViT架构的修改，增强了对输入通道之间的推理，并引入了分层通道采样(HCS)作为一种附加的正则化技术，以确保在测试过程中仅出现部分通道时的鲁棒性。我们提出的模型ChannelViT独立地构建补丁令牌并利用可学习的通道嵌入将其添加到补丁令牌中，类似于位置嵌入。我们进行了评估

    Vision Transformer (ViT) has emerged as a powerful architecture in the realm of modern computer vision. However, its application in certain imaging fields, such as microscopy and satellite imaging, presents unique challenges. In these domains, images often contain multiple channels, each carrying semantically distinct and independent information. Furthermore, the model must demonstrate robustness to sparsity in input channels, as they may not be densely available during training or testing. In this paper, we propose a modification to the ViT architecture that enhances reasoning across the input channels and introduce Hierarchical Channel Sampling (HCS) as an additional regularization technique to ensure robustness when only partial channels are presented during test time. Our proposed model, ChannelViT, constructs patch tokens independently from each input channel and utilizes a learnable channel embedding that is added to the patch tokens, similar to positional embeddings. We evaluate
    
[^55]: 发现基于效用的区间规则

    Discovering Utility-driven Interval Rules. (arXiv:2309.16102v1 [cs.AI])

    [http://arxiv.org/abs/2309.16102](http://arxiv.org/abs/2309.16102)

    本研究提出了一种基于效用的区间规则挖掘算法（UIRMiner），可以从区间事件序列数据库中提取所有基于效用的区间规则（UIRs），进一步揭示事件之间的关联性。

    

    对于人工智能来说，高效用序列规则挖掘（HUSRM）是一种能够揭示序列中事件之间关联的知识发现方法。最近，已经提出了丰富的方法来发现高效用序列规则。然而，现有的方法都与基于点的序列相关。存在一些持续一段时间的区间事件。传统的区间事件序列知识发现任务主要关注模式发现，但是模式无法很好地揭示区间事件之间的相关性。此外，现有的HUSRM算法无法直接应用于区间事件序列，因为区间事件序列中的关联要比基于点的序列复杂得多。在这项工作中，我们提出了一种基于效用的区间规则挖掘（UIRMiner）算法，可以从区间事件序列数据库中提取所有基于效用的区间规则（UIRs）来解决这个问题。

    For artificial intelligence, high-utility sequential rule mining (HUSRM) is a knowledge discovery method that can reveal the associations between events in the sequences. Recently, abundant methods have been proposed to discover high-utility sequence rules. However, the existing methods are all related to point-based sequences. Interval events that persist for some time are common. Traditional interval-event sequence knowledge discovery tasks mainly focus on pattern discovery, but patterns cannot reveal the correlation between interval events well. Moreover, the existing HUSRM algorithms cannot be directly applied to interval-event sequences since the relation in interval-event sequences is much more intricate than those in point-based sequences. In this work, we propose a utility-driven interval rule mining (UIRMiner) algorithm that can extract all utility-driven interval rules (UIRs) from the interval-event sequence database to solve the problem. In UIRMiner, we first introduce a num
    
[^56]: 对抗样本可能是可以避免的：数据集中性在对抗鲁棒性中的作用

    Adversarial Examples Might be Avoidable: The Role of Data Concentration in Adversarial Robustness. (arXiv:2309.16096v1 [cs.LG])

    [http://arxiv.org/abs/2309.16096](http://arxiv.org/abs/2309.16096)

    本研究论证了数据分布的集中程度对于决定鲁棒分类器的存在与否至关重要，并展示了在数据分布集中在低维线性子空间的并集时，利用数据结构可以获得具有良好鲁棒性保证的分类器的方法。

    

    现代机器学习分类器对于对抗样本的敏感性引发了理论结果，暗示这些对抗样本可能是不可避免的。然而，这些结果可能过于一般化，无法应用于自然数据分布。事实上，人类在涉及视觉的任务中表现出相当的鲁棒性。这种明显的矛盾推动我们更深入地探索一个问题：对抗样本是否真的是不可避免的？在这项工作中，我们理论上证明了数据分布的一个关键属性——对输入空间的小容积子集的集中程度，决定了是否存在一个鲁棒分类器。我们进一步证明，在数据分布集中在低维线性子空间的并集时，利用数据结构自然地得到享有良好鲁棒性保证的分类器，改进了在特定范围内可证明认证方法。

    The susceptibility of modern machine learning classifiers to adversarial examples has motivated theoretical results suggesting that these might be unavoidable. However, these results can be too general to be applicable to natural data distributions. Indeed, humans are quite robust for tasks involving vision. This apparent conflict motivates a deeper dive into the question: Are adversarial examples truly unavoidable? In this work, we theoretically demonstrate that a key property of the data distribution -- concentration on small-volume subsets of the input space -- determines whether a robust classifier exists. We further demonstrate that, for a data distribution concentrated on a union of low-dimensional linear subspaces, exploiting data structure naturally leads to classifiers that enjoy good robustness guarantees, improving upon methods for provable certification in certain regimes.
    
[^57]: TPE: 面向多人物协作的概念工具更好合成推理

    TPE: Towards Better Compositional Reasoning over Conceptual Tools with Multi-persona Collaboration. (arXiv:2309.16090v1 [cs.AI])

    [http://arxiv.org/abs/2309.16090](http://arxiv.org/abs/2309.16090)

    TPE是一种面向概念工具的多人物协作框架，旨在提高大型语言模型在推理和规划方面的能力。

    

    大型语言模型(LLMs)在规划使用各种功能工具，如计算器和检索器方面表现出了非凡的性能，尤其是在问答任务中。本文扩展了这些工具的定义，重点是对话系统中的概念工具。概念工具指定了一种有助于系统性或调查性思考的认知概念。这些概念工具在实践中发挥重要作用，例如多重心理或辅导策略动态应用于单个回合以组合有用的响应。为了进一步增强LLMs在这些概念工具上的推理和规划能力，我们引入了一种多人物协作框架: Think-Plan-Execute (TPE)。该框架将响应生成过程分解为三个不同的角色: 思考者，规划者和执行者。具体而言，思考者分析对话上下文中表现出的内部状态，例如用户的情绪。

    Large language models (LLMs) have demonstrated exceptional performance in planning the use of various functional tools, such as calculators and retrievers, particularly in question-answering tasks. In this paper, we expand the definition of these tools, centering on conceptual tools within the context of dialogue systems. A conceptual tool specifies a cognitive concept that aids systematic or investigative thought. These conceptual tools play important roles in practice, such as multiple psychological or tutoring strategies being dynamically applied in a single turn to compose helpful responses. To further enhance the reasoning and planning capability of LLMs with these conceptual tools, we introduce a multi-persona collaboration framework: Think-Plan-Execute (TPE). This framework decouples the response generation process into three distinct roles: Thinker, Planner, and Executor. Specifically, the Thinker analyzes the internal status exhibited in the dialogue context, such as user emot
    
[^58]: 通过排除法集成模型来在语言模型中遗忘私人文本序列

    Forgetting Private Textual Sequences in Language Models via Leave-One-Out Ensemble. (arXiv:2309.16082v1 [cs.CL])

    [http://arxiv.org/abs/2309.16082](http://arxiv.org/abs/2309.16082)

    通过教师-学生框架和排除法集成方法，在语言模型中遗忘私人文本序列时能够取得比其他方法更好的隐私-效用权衡性能。

    

    最近的研究表明，语言模型有倾向于在训练数据中记住罕见或独特的令牌序列。在部署模型后，根据个人要求，从模型中删除任何个人信息可能会被提出。每次个人想要行使被遗忘权利时重新训练底层模型的计算成本很高。我们使用教师-学生框架，并提出了一种新的排除法集成方法来从模型中遗忘需要遗忘的文本序列。在我们的方法中，多个教师模型在不同的数据集上进行训练；对于每个需要删除的目标序列，我们排除在包含该序列的训练集上训练的教师模型，并从剩余的教师模型中聚合预测结果，以提供在微调过程中的监督。在LibriSpeech和WikiText-103数据集上的实验证明，所提出的方法在隐私-效用权衡方面具有优势。

    Recent research has shown that language models have a tendency to memorize rare or unique token sequences in the training corpus. After deploying a model, practitioners might be asked to delete any personal information from the model by individuals' requests. Re-training the underlying model every time individuals would like to practice their rights to be forgotten is computationally expensive. We employ a teacher-student framework and propose a novel leave-one-out ensemble method to unlearn the targeted textual sequences that need to be forgotten from the model. In our approach, multiple teachers are trained on disjoint sets; for each targeted sequence to be removed, we exclude the teacher trained on the set containing this sequence and aggregate the predictions from remaining teachers to provide supervision during fine-tuning. Experiments on LibriSpeech and WikiText-103 datasets show that the proposed method achieves superior privacy-utility trade-offs than other counterparts.
    
[^59]: 受屏蔽自动编码器学习细胞形态的可扩展性

    Masked autoencoders are scalable learners of cellular morphology. (arXiv:2309.16064v1 [cs.CV])

    [http://arxiv.org/abs/2309.16064](http://arxiv.org/abs/2309.16064)

    本研究探索了弱监督和自监督深度学习方法在训练更大的模型和数据集时的可扩展性，并发现基于CNN和ViT的受屏蔽自动编码器在推断细胞形态学关系方面明显优于弱监督模型。

    

    在高内容显微镜检查中从细胞表型中推断生物关系在生物研究中提供了重要的机会和挑战。之前的研究结果表明，深度视觉模型比手工设计的特征更能捕捉生物信号。本研究探讨了弱监督和自监督深度学习方法在训练更大的模型和更大的数据集时的可扩展性。我们的结果显示，基于CNN和ViT的受屏蔽自动编码器在性能上显著优于弱监督模型。在我们研究的最高尺度上，一个在公共数据库中构建的细胞形态学关系数据集上训练的覆盖超过35亿个唯一剪裁图像的ViT-L/8模型，在推断已知生物关系时相对改进高达28%。

    Inferring biological relationships from cellular phenotypes in high-content microscopy screens provides significant opportunity and challenge in biological research. Prior results have shown that deep vision models can capture biological signal better than hand-crafted features. This work explores how weakly supervised and self-supervised deep learning approaches scale when training larger models on larger datasets. Our results show that both CNN- and ViT-based masked autoencoders significantly outperform weakly supervised models. At the high-end of our scale, a ViT-L/8 trained on over 3.5-billion unique crops sampled from 95-million microscopy images achieves relative improvements as high as 28% over our best weakly supervised models at inferring known biological relationships curated from public databases.
    
[^60]: 《语言模型中激活路径修复的最佳实践：度量和方法》的论文翻译

    Towards Best Practices of Activation Patching in Language Models: Metrics and Methods. (arXiv:2309.16042v1 [cs.LG])

    [http://arxiv.org/abs/2309.16042](http://arxiv.org/abs/2309.16042)

    本研究系统地考察了激活路径修复中的方法细节对语言模型解释性结果的影响，并提出了最佳实践建议。

    

    机械解释性旨在理解机器学习模型的内部机制，其中定位-识别重要的模型组件是关键步骤。激活路径修复，也称为因果追踪或交换干预，是完成这一任务的标准技术，但文献中存在许多变体，对超参数或方法选择缺乏一致性。在这项工作中，我们系统地考察了激活路径修复中的方法细节对结果的影响，包括评估指标和损坏方法。在语言模型的定位和电路发现的几种设置中，我们发现不同的超参数可能导致不同的解释结果。通过经验观察支持，我们提出了为什么某些指标或方法可能更受欢迎的概念性论证。最后，我们提出了激活路径修复的最佳实践建议。

    Mechanistic interpretability seeks to understand the internal mechanisms of machine learning models, where localization -- identifying the important model components -- is a key step. Activation patching, also known as causal tracing or interchange intervention, is a standard technique for this task (Vig et al., 2020), but the literature contains many variants with little consensus on the choice of hyperparameters or methodology. In this work, we systematically examine the impact of methodological details in activation patching, including evaluation metrics and corruption methods. In several settings of localization and circuit discovery in language models, we find that varying these hyperparameters could lead to disparate interpretability results. Backed by empirical observations, we give conceptual arguments for why certain metrics or methods may be preferred. Finally, we provide recommendations for the best practices of activation patching going forwards.
    
[^61]: MedEdit：利用外部知识库进行医学问答的模型编辑

    MedEdit: Model Editing for Medical Question Answering with External Knowledge Bases. (arXiv:2309.16035v1 [cs.CL])

    [http://arxiv.org/abs/2309.16035](http://arxiv.org/abs/2309.16035)

    该论文研究了利用外部知识库进行医学问答的模型编辑方法，通过提取医学事实并将其融入到语言模型的查询提示中，显著提高了医学问答的准确率。

    

    大型语言模型（LLM）虽然在一般领域表现强大，但在特定领域的任务，如医学问答（QA）方面往往表现不佳。此外，它们往往作为“黑盒”运作，难以修改其行为。针对这一问题，我们的研究探讨了利用上下文学习的模型编辑，旨在改进LLM的响应，而无需重新微调或重新训练。具体而言，我们提出了一种全面的检索策略，从外部知识库中提取医学事实，然后将它们合并到LLM的查询提示中。通过对MedQA-SMILE数据集进行医学QA的重点研究，我们评估了不同检索模型和向LLM提供的事实数量对其影响。值得注意的是，我们编辑后的Vicuna模型的准确率从44.46％提高到48.54％。这项工作凸显了模型编辑改善LLM性能的潜力，为缓解黑盒LLM的挑战提供了实用的方法。

    Large Language Models (LLMs), although powerful in general domains, often perform poorly on domain-specific tasks like medical question answering (QA). Moreover, they tend to function as "black-boxes," making it challenging to modify their behavior. Addressing this, our study delves into model editing utilizing in-context learning, aiming to improve LLM responses without the need for fine-tuning or retraining. Specifically, we propose a comprehensive retrieval strategy to extract medical facts from an external knowledge base, and then we incorporate them into the query prompt for the LLM. Focusing on medical QA using the MedQA-SMILE dataset, we evaluate the impact of different retrieval models and the number of facts provided to the LLM. Notably, our edited Vicuna model exhibited an accuracy improvement from 44.46% to 48.54%. This work underscores the potential of model editing to enhance LLM performance, offering a practical approach to mitigate the challenges of black-box LLMs.
    
[^62]: 符号化模仿学习：从黑盒到可解释的驾驶策略

    Symbolic Imitation Learning: From Black-Box to Explainable Driving Policies. (arXiv:2309.16025v1 [cs.LG])

    [http://arxiv.org/abs/2309.16025](http://arxiv.org/abs/2309.16025)

    本文介绍了一种名为符号化模仿学习（SIL）的方法，通过引入归纳逻辑编程（ILP）来学习从现有数据集中获取透明、可解释和泛化的驾驶策略。与传统的基于深度神经网络的模仿学习方法相比，SIL不仅提高了驾驶策略的可解释性，还显著改进了它们在各种驾驶情况下的适用性。

    

    当前的模仿学习方法主要基于深度神经网络，提供了从现实世界数据中获取驾驶策略的有效手段，但在可解释性和泛化性方面存在显著局限性。这些缺点在自动驾驶等安全关键应用中尤为令人担忧。本文通过引入符号化模仿学习（SIL），一种使用归纳逻辑编程（ILP）学习从可用数据集中获取透明、可解释和泛化的驾驶策略的创新方法，来解决这些局限性。利用真实世界的highD数据集，我们对我们的方法进行了严格的比较分析，与当前的基于神经网络的模仿学习方法进行了对比。我们的结果表明，SIL不仅提高了驾驶策略的可解释性，还显著提高了它们在各种驾驶情况下的适用性。因此，这项工作为实现更可靠和可解释的驾驶策略打开了一条新的途径。

    Current methods of imitation learning (IL), primarily based on deep neural networks, offer efficient means for obtaining driving policies from real-world data but suffer from significant limitations in interpretability and generalizability. These shortcomings are particularly concerning in safety-critical applications like autonomous driving. In this paper, we address these limitations by introducing Symbolic Imitation Learning (SIL), a groundbreaking method that employs Inductive Logic Programming (ILP) to learn driving policies which are transparent, explainable and generalisable from available datasets. Utilizing the real-world highD dataset, we subject our method to a rigorous comparative analysis against prevailing neural-network-based IL methods. Our results demonstrate that SIL not only enhances the interpretability of driving policies but also significantly improves their applicability across varied driving situations. Hence, this work offers a novel pathway to more reliable an
    
[^63]: 使用基于语义的归纳推理和知识图嵌入的临床试验推荐方法

    Clinical Trial Recommendations Using Semantics-Based Inductive Inference and Knowledge Graph Embeddings. (arXiv:2309.15979v1 [cs.AI])

    [http://arxiv.org/abs/2309.15979](http://arxiv.org/abs/2309.15979)

    本论文提出了一种基于知识图嵌入的临床试验推荐方法，实验表明该方法能够在临床试验设计中实现高达70%-83%的相关性得分，并且最相关的推荐位于推荐列表的前部。

    

    设计新的临床试验涉及到诸多决策，比如确定队列和设定研究目标等，因此可以通过对过去临床试验记录的全面挖掘来获得推荐建议。本文提出了一种基于临床试验知识图的神经嵌入训练的推荐方法。我们在这个背景下解决了一些重要的研究问题，包括设计临床试验知识图，各种知识图嵌入方法的有效性，使用嵌入进行归纳推理的新方法，以及在临床试验设计中生成推荐的应用。我们使用了来自clinicaltrials.gov的公开数据进行研究。结果显示，我们的推荐方法实现了70％-83％的相关性得分，以实际临床试验元素的文本相似性衡量，而最相关的推荐可以在列表的前部找到。我们的研究还建议了其他方法的改进方向。

    Designing a new clinical trial entails many decisions, such as defining a cohort and setting the study objectives to name a few, and therefore can benefit from recommendations based on exhaustive mining of past clinical trial records. Here, we propose a novel recommendation methodology, based on neural embeddings trained on a first-of-a-kind knowledge graph of clinical trials. We addressed several important research questions in this context, including designing a knowledge graph (KG) for clinical trial data, effectiveness of various KG embedding (KGE) methods for it, a novel inductive inference using KGE, and its use in generating recommendations for clinical trial design. We used publicly available data from clinicaltrials.gov for the study. Results show that our recommendations approach achieves relevance scores of 70%-83%, measured as the text similarity to actual clinical trial elements, and the most relevant recommendation can be found near the top of list. Our study also suggest
    
[^64]: 统一的长期时序预测基准

    Unified Long-Term Time-Series Forecasting Benchmark. (arXiv:2309.15946v1 [cs.LG])

    [http://arxiv.org/abs/2309.15946](http://arxiv.org/abs/2309.15946)

    该论文介绍了一个专门用于长期时序预测的综合数据集，通过对多个经典和最先进的模型进行广泛基准分析，发现模型的有效性与数据集相关性有关。

    

    为了支持机器学习方法在预测时间序列数据方面的进展，我们提出了一个专门用于长期时序预测的综合数据集。我们采集了来自各种不同、动态系统和真实记录的数据集。每个数据集都经过标准化处理，分为训练和测试轨迹，并预先确定了回溯长度。我们包括了长度为2000的轨迹，以确保可靠地评估长期预测能力。为了确定在不同场景中最有效的模型，我们使用经典和最先进的模型（包括LSTM、DeepAR、NLinear、N-Hits、PatchTST和LatentODE）进行了广泛的基准分析。我们的研究结果显示了这些模型之间有趣的性能比较，突出了模型有效性与数据集相关性的特点。值得注意的是，我们引入了一种定制的潜在NLinear模型，并在DeepAR中增加了一个课程学习阶段。

    In order to support the advancement of machine learning methods for predicting time-series data, we present a comprehensive dataset designed explicitly for long-term time-series forecasting. We incorporate a collection of datasets obtained from diverse, dynamic systems and real-life records. Each dataset is standardized by dividing it into training and test trajectories with predetermined lookback lengths. We include trajectories of length up to $2000$ to ensure a reliable evaluation of long-term forecasting capabilities. To determine the most effective model in diverse scenarios, we conduct an extensive benchmarking analysis using classical and state-of-the-art models, namely LSTM, DeepAR, NLinear, N-Hits, PatchTST, and LatentODE. Our findings reveal intriguing performance comparisons among these models, highlighting the dataset-dependent nature of model effectiveness. Notably, we introduce a custom latent NLinear model and enhance DeepAR with a curriculum learning phase. Both consist
    
[^65]: 通过硬件-算法-通信协同设计实现高效可信的人工智能

    Towards Efficient and Trustworthy AI Through Hardware-Algorithm-Communication Co-Design. (arXiv:2309.15942v1 [cs.AI])

    [http://arxiv.org/abs/2309.15942](http://arxiv.org/abs/2309.15942)

    通过硬件-算法-通信协同设计，本论文提出了一种实现高效可信的人工智能的研究方法，即通过结合物理洞见、高效信息处理原则、最优不确定度量结果和分布式处理准则，来提高神经网络算法的效率和可信度。

    

    基于神经网络的人工智能算法已经被设计了几十年，目标是最大化某种准确性度量。这导致了两个不希望出现的结果。首先，以计算和内存需求为衡量标准，模型复杂性呈指数增长。第二，最新的人工智能模型在提供可信度量方面很难实现，可能出现"幻觉"问题，从而阻碍了其在敏感应用的决策制定中的应用。为了实现高效可信的人工智能，本文强调硬件和软件设计交叉的研究方向，将物理洞见与计算基础、神经科学有关的高效信息处理原则、信息论中关于最优不确定度量的结果以及通信理论中关于分布式处理的准则相结合。总体而言，本文提倡新的硬件-算法-通信协同设计方法，以实现高效可信的人工智能。

    Artificial intelligence (AI) algorithms based on neural networks have been designed for decades with the goal of maximising some measure of accuracy. This has led to two undesired effects. First, model complexity has risen exponentially when measured in terms of computation and memory requirements. Second, state-of-the-art AI models are largely incapable of providing trustworthy measures of their uncertainty, possibly `hallucinating' their answers and discouraging their adoption for decision-making in sensitive applications.  With the goal of realising efficient and trustworthy AI, in this paper we highlight research directions at the intersection of hardware and software design that integrate physical insights into computational substrates, neuroscientific principles concerning efficient information processing, information-theoretic results on optimal uncertainty quantification, and communication-theoretic guidelines for distributed processing. Overall, the paper advocates for novel d
    
[^66]: 利用多层嵌入训练增强推荐系统中的跨类别学习

    Enhancing Cross-Category Learning in Recommendation Systems with Multi-Layer Embedding Training. (arXiv:2309.15881v1 [cs.LG])

    [http://arxiv.org/abs/2309.15881](http://arxiv.org/abs/2309.15881)

    该论文提出了一种名为多层嵌入训练（MLET）的训练技术，通过跨类别学习产生优秀的嵌入。该方法通过嵌入层的分解训练嵌入，内部维度高于目标嵌入维度，并在推理时提高了效率。该技术的实验结果令人惊讶，并且通过理论解释了其有效性。

    

    现代基于DNN的推荐系统依赖于对稀疏特征进行训练得到的嵌入。输入稀疏性使得很难获得少出现类别的高质量嵌入，因为它们的表示很少更新。我们展示了一种训练时的技术，通过有效的跨类别学习产生优秀的嵌入，并从理论上解释了其令人惊讶的有效性。该方案被称为多层嵌入训练（MLET），通过嵌入层的分解训练嵌入，内部维度高于目标嵌入维度。为了提高推理效率，MLET将训练得到的双层嵌入转换为单层嵌入，从而保持了推理时的模型大小不变。MLET的实验优越性令人困惑，因为其搜索空间并不比单层嵌入更大。MLET对内部维度的强依赖甚至更令人惊讶。我们发展了一个理论来解释这两种行为。

    Modern DNN-based recommendation systems rely on training-derived embeddings of sparse features. Input sparsity makes obtaining high-quality embeddings for rarely-occurring categories harder as their representations are updated infrequently. We demonstrate a training-time technique to produce superior embeddings via effective cross-category learning and theoretically explain its surprising effectiveness. The scheme, termed the multi-layer embeddings training (MLET), trains embeddings using factorization of the embedding layer, with an inner dimension higher than the target embedding dimension. For inference efficiency, MLET converts the trained two-layer embedding into a single-layer one thus keeping inference-time model size unchanged.  Empirical superiority of MLET is puzzling as its search space is not larger than that of the single-layer embedding. The strong dependence of MLET on the inner dimension is even more surprising. We develop a theory that explains both of these behaviors 
    
[^67]: 神经启发的分层多模态学习

    Neuro-Inspired Hierarchical Multimodal Learning. (arXiv:2309.15877v1 [cs.LG])

    [http://arxiv.org/abs/2309.15877](http://arxiv.org/abs/2309.15877)

    这项研究提出了一种神经启发的分层多模态学习方法，利用信息瓶颈理论构建了一种有效且紧凑的信息流，实现了对真实世界的全面和准确的感知。

    

    整合和处理来自多种信息源或模态对于获得对真实世界的全面和准确的感知至关重要。受到神经科学的启发，我们开发了信息论分层感知(ITHP)模型，该模型利用了信息瓶颈的概念。与大多数旨在将所有模态纳入输入的传统融合模型不同，我们的模型将主要模态指定为输入，而其余模态则作为信息路径中的检测器。我们提出的感知模型的重点是通过在潜在状态和输入模态状态之间最小化相互信息并在潜在状态和其余模态之间最大化相互信息的平衡，构建一种有效且紧凑的信息流。这种方法导致了保留相关信息并最小化冗余的紧凑潜在状态表示，从而实现更好的感知。

    Integrating and processing information from various sources or modalities are critical for obtaining a comprehensive and accurate perception of the real world. Drawing inspiration from neuroscience, we develop the Information-Theoretic Hierarchical Perception (ITHP) model, which utilizes the concept of information bottleneck. Distinct from most traditional fusion models that aim to incorporate all modalities as input, our model designates the prime modality as input, while the remaining modalities act as detectors in the information pathway. Our proposed perception model focuses on constructing an effective and compact information flow by achieving a balance between the minimization of mutual information between the latent state and the input modal state, and the maximization of mutual information between the latent states and the remaining modal states. This approach leads to compact latent state representations that retain relevant information while minimizing redundancy, thereby sub
    
[^68]: STAG: 实现动态图中基于GNN的服务低延迟和低陈旧度

    STAG: Enabling Low Latency and Low Staleness of GNN-based Services with Dynamic Graphs. (arXiv:2309.15875v1 [cs.LG])

    [http://arxiv.org/abs/2309.15875](http://arxiv.org/abs/2309.15875)

    STAG是一个GNN服务框架，用于解决动态图中基于GNN的服务中的低延迟和低陈旧度问题。它采用协同服务机制和增量传播策略来优化节点表示的更新过程。

    

    许多新兴的用户面向服务采用图神经网络（GNN）来提高服务准确性。当GNN模型使用的图发生变化时，图中节点的表示（嵌入）应相应更新。然而，节点表示的更新速度过慢，导致用户查询的响应延迟较长（更新完成后进行推理）或存在较高的陈旧度问题（基于陈旧数据进行推理）。我们的深入分析表明，更新过慢主要是由于图中的邻居爆炸问题和重复计算。基于这些发现，我们提出了STAG，这是一个能够实现基于GNN的服务低延迟和低陈旧度的GNN服务框架。它包括协同服务机制和基于可加性的增量传播策略。通过协同服务机制，只有部分节点表示在更新阶段进行更新，最终的表示是在增量传播策略中计算得到的。

    Many emerging user-facing services adopt Graph Neural Networks (GNNs) to improve serving accuracy. When the graph used by a GNN model changes, representations (embedding) of nodes in the graph should be updated accordingly. However, the node representation update is too slow, resulting in either long response latency of user queries (the inference is performed after the update completes) or high staleness problem (the inference is performed based on stale data). Our in-depth analysis shows that the slow update is mainly due to neighbor explosion problem in graphs and duplicated computation. Based on such findings, we propose STAG, a GNN serving framework that enables low latency and low staleness of GNN-based services. It comprises a collaborative serving mechanism and an additivity-based incremental propagation strategy. With the collaborative serving mechanism, only part of node representations are updated during the update phase, and the final representations are calculated in the i
    
[^69]: ChatGPT与机械工程：对FE机械工程和本科考试的性能研究

    ChatGPT & Mechanical Engineering: Examining performance on the FE Mechanical Engineering and Undergraduate Exams. (arXiv:2309.15866v1 [cs.CY])

    [http://arxiv.org/abs/2309.15866](http://arxiv.org/abs/2309.15866)

    这项研究研究了ChatGPT在机械工程领域的能力，并发现付费订阅模型（GPT-4）在回答机械工程考试和FE考试问题上的性能明显优于免费版本（GPT-3.5）。

    

    ChatGPT在2022年底的发布引发了人们对人工智能在STEM教育和STEM专业中可能应用的广泛关注。因此，关于课堂内外生成AI工具的能力引发了许多问题，并开始得到探索。本研究考察了ChatGPT在机械工程学科中的能力。它旨在研究该技术在课堂和专业环境中的使用案例和潜在问题。研究使用了一些来自大型私立大学的初级和高级机械工程考试题目，以及一组用于机械工程基础工程考试（FE）的练习题。作者分析了两个ChatGPT模型（一个免费使用，一个付费订阅）的回答。研究发现付费订阅模型（GPT-4）的表现远远超过了免费版本（GPT-3.5），达到了76％。

    The launch of ChatGPT at the end of 2022 generated large interest into possible applications of artificial intelligence in STEM education and among STEM professions. As a result many questions surrounding the capabilities of generative AI tools inside and outside of the classroom have been raised and are starting to be explored. This study examines the capabilities of ChatGPT within the discipline of mechanical engineering. It aims to examine use cases and pitfalls of such a technology in the classroom and professional settings. ChatGPT was presented with a set of questions from junior and senior level mechanical engineering exams provided at a large private university, as well as a set of practice questions for the Fundamentals of Engineering Exam (FE) in Mechanical Engineering. The responses of two ChatGPT models, one free to use and one paid subscription, were analyzed. The paper found that the subscription model (GPT-4) greatly outperformed the free version (GPT-3.5), achieving 76%
    
[^70]: 图像-文本多模型综述论文

    A Survey on Image-text Multimodal Models. (arXiv:2309.15857v1 [cs.CL])

    [http://arxiv.org/abs/2309.15857](http://arxiv.org/abs/2309.15857)

    图像-文本多模型综述论文全面回顾了其发展历程和当前状态，提出了新的分类方法，并阐明了该领域的挑战和潜在研究方向。

    

    在人工智能不断发展的背景下，图像和文本信息的融合成为一个至关重要的领域，导致了图像-文本多模型的出现。本论文全面回顾了图像-文本多模型的发展历程和当前状态，探讨了它们的应用价值、挑战和潜在研究方向。首先，我们重新审视了这些模型的基本概念和发展里程碑，引入了一种新的分类方法，将它们的发展分为三个不同的阶段，基于它们被引入的时间和对学科的影响。此外，基于任务在学术领域中的重要性和普及性，我们提出了将与图像-文本多模型相关的任务划分为五个主要类型的分类方法，阐明了每个类别内的最新进展和关键技术。尽管这些模型取得了显著的成就，但仍面临着许多挑战。

    Amidst the evolving landscape of artificial intelligence, the convergence of visual and textual information has surfaced as a crucial frontier, leading to the advent of image-text multimodal models. This paper provides a comprehensive review of the evolution and current state of image-text multimodal models, exploring their application value, challenges, and potential research trajectories. Initially, we revisit the basic concepts and developmental milestones of these models, introducing a novel classification that segments their evolution into three distinct phases, based on their time of introduction and subsequent impact on the discipline. Furthermore, based on the tasks' significance and prevalence in the academic landscape, we propose a categorization of the tasks associated with image-text multimodal models into five major types, elucidating the recent progress and key technologies within each category. Despite the remarkable accomplishments of these models, numerous challenges a
    
[^71]: 基于潜在图的生物医学表格数据半监督学习

    Latent Graph Powered Semi-Supervised Learning on Biomedical Tabular Data. (arXiv:2309.15757v1 [cs.LG])

    [http://arxiv.org/abs/2309.15757](http://arxiv.org/abs/2309.15757)

    本文提出了一种基于潜在图的半监督学习方法，通过利用图的表示来捕捉数据之间的关系，并实现了全局和局部知识的有效融合。在生物医学数据集上的评估中，我们的方法表现出了最先进的结果。

    

    在半监督学习领域中，现有方法未充分利用（有）标记数据之间的实例间关系的潜力。本文通过提供一种推断捕捉内在数据关系的潜在图的方法来解决这个限制。通过利用基于图的表示，我们的方法促进了信息在整个图中的无缝传播，能够有效地融合全局和局部知识。通过在生物医学表格数据集上的评估，我们比较了我们的方法与其他当代方法的能力。我们的工作证明了发现实例间关系作为构建强化半监督学习技术的鲁棒潜在图的实际手段的重要性。我们的方法在三个生物医学数据集上取得了最先进的结果。

    In the domain of semi-supervised learning, the current approaches insufficiently exploit the potential of considering inter-instance relationships among (un)labeled data. In this work, we address this limitation by providing an approach for inferring latent graphs that capture the intrinsic data relationships. By leveraging graph-based representations, our approach facilitates the seamless propagation of information throughout the graph, enabling the effective incorporation of global and local knowledge. Through evaluations on biomedical tabular datasets, we compare the capabilities of our approach to other contemporary methods. Our work demonstrates the significance of inter-instance relationship discovery as practical means for constructing robust latent graphs to enhance semi-supervised learning techniques. Our method achieves state-of-the-art results on three biomedical datasets.
    
[^72]: 大规模多语言自监督学习的联合预测和去噪

    joint prediction and denoising for large-scale multilingual self-supervised learning. (arXiv:2309.15317v1 [cs.CL])

    [http://arxiv.org/abs/2309.15317](http://arxiv.org/abs/2309.15317)

    这项研究提出了WavLabLM，它通过联合预测和去噪的方法，实现了在136种语言的40k小时数据上进行大规模多语言自监督学习。WavLabLM的多阶段预训练方法解决了多语言数据的语言失衡问题，使其在ML-SUPERB上达到了与XLS-R相当的性能，同时仅使用不到10%的训练数据，这使得SSL在学术高性能计算上可行。

    

    多语言自监督学习(SSL)由于处理多种语言所需的费用和复杂性而经常落后于最先进的方法。这进一步影响了SSL的可重复性，由于资源使用的限制，SSL已经仅限于少数研究团队。我们展示了更强大的技术实际上可以导致更高效的预训练，从而使更多的研究团队能够加入SSL。我们提出了WavLabLM，将WavLM的联合预测和去噪扩展到136种语言的40k小时数据。为了构建WavLabLM，我们设计了一种新颖的多阶段预训练方法，旨在解决多语言数据的语言失衡问题。WavLabLM在ML-SUPERB上实现了与XLS-R相当的性能，仅使用不到10%的训练数据，使得SSL在学术高性能计算上可实现。我们还展示了vanilla HuBERT Base模型可以实现进一步的效率提升，仅使用3%的数据、4个GPU和有限的试验次数，就能保持94%的XLS-R性能。

    Multilingual self-supervised learning (SSL) has often lagged behind state-of-the-art (SOTA) methods due to the expenses and complexity required to handle many languages. This further harms the reproducibility of SSL, which is already limited to few research groups due to its resource usage. We show that more powerful techniques can actually lead to more efficient pre-training, opening SSL to more research groups. We propose WavLabLM, which extends WavLM's joint prediction and denoising to 40k hours of data across 136 languages. To build WavLabLM, we devise a novel multi-stage pre-training method, designed to address the language imbalance of multilingual data. WavLabLM achieves comparable performance to XLS-R on ML-SUPERB with less than 10% of the training data, making SSL realizable with academic compute. We show that further efficiency can be achieved with a vanilla HuBERT Base model, which can maintain 94% of XLS-R's performance with only 3% of the data, 4 GPUs, and limited trials. 
    
[^73]: 基于运动数据的交通灯-车道分配语义地图学习

    Semantic Map Learning of Traffic Light to Lane Assignment based on Motion Data. (arXiv:2309.14793v1 [cs.CV])

    [http://arxiv.org/abs/2309.14793](http://arxiv.org/abs/2309.14793)

    本论文介绍了一种基于运动数据的交通灯-车道分配语义地图学习的方法，通过统计方法自动推导交通灯到车道的分配，并且提出了安全考虑和数据集转换方法来提高效果和扩展性。

    

    理解哪个交通灯控制哪个车道对于安全通过路口至关重要。自动驾驶车辆通常依赖包含交通灯-车道分配信息的高清地图。手动提供这些信息既费时又昂贵，而且不可扩展。为了解决这些问题，我们提出了一种新颖的方法，利用交通灯状态和车辆运动模式推导出分配方式。该方法自动化并且不依赖几何排列。我们通过实现和评估基于模式的贡献方法展示了基本统计方法在这个任务上的有效性。此外，我们的新颖的拒绝方法通过利用统计假设检验考虑了安全因素。最后，我们提出了一种数据集转换方法，以重新利用现有的运动预测数据集进行语义地图学习。我们还提供了适用于Lyft Level 5数据集的公开API。

    Understanding which traffic light controls which lane is crucial to navigate intersections safely. Autonomous vehicles commonly rely on High Definition (HD) maps that contain information about the assignment of traffic lights to lanes. The manual provisioning of this information is tedious, expensive, and not scalable. To remedy these issues, our novel approach derives the assignments from traffic light states and the corresponding motion patterns of vehicle traffic. This works in an automated way and independently of the geometric arrangement. We show the effectiveness of basic statistical approaches for this task by implementing and evaluating a pattern-based contribution method. In addition, our novel rejection method includes accompanying safety considerations by leveraging statistical hypothesis testing. Finally, we propose a dataset transformation to re-purpose available motion prediction datasets for semantic map learning. Our publicly available API for the Lyft Level 5 dataset 
    
[^74]: 生成艾舍尔网格

    Generative Escher Meshes. (arXiv:2309.14564v1 [cs.CV])

    [http://arxiv.org/abs/2309.14564](http://arxiv.org/abs/2309.14564)

    本文提出了一种全自动的生成方法，用于生成周期性的非正方形镶嵌图案，该方法通过优化几何和颜色来生成与所需对象形状和外观相似的瓷砖。

    

    本文提出了一种全自动、以文本为导向的生成方法，用于生成周期性的、可重复的二维艺术作品，如地板、马赛克、陶瓷和艾舍尔的作品。与传统的无缝纹理概念不同，即平铺无缝的正方形图像，我们的方法生成的是由重复的相同对象组成的非正方形镶嵌图案。它通过优化二维网格的几何和颜色来生成与所需对象形状和外观相似的非正方形瓷砖，几乎没有额外的背景细节。我们通过一个关键的技术贡献实现了镶嵌图案的几何优化：一个无约束的、可微分的参数化方法，用于给定对称群的所有可能的可铺砖形状空间。换句话说，我们证明了修改二维网格映射技术Orbifold Tutte Embedding中使用的Laplacian算子可以实现所选平面对称群的所有可能的铺砖配置。

    This paper proposes a fully-automatic, text-guided generative method for producing periodic, repeating, tile-able 2D art, such as the one seen on floors, mosaics, ceramics, and the work of M.C. Escher. In contrast to the standard concept of a seamless texture, i.e., square images that are seamless when tiled, our method generates non-square tilings which comprise solely of repeating copies of the same object. It achieves this by optimizing both geometry and color of a 2D mesh, in order to generate a non-square tile in the shape and appearance of the desired object, with close to no additional background details. We enable geometric optimization of tilings by our key technical contribution: an unconstrained, differentiable parameterization of the space of all possible tileable shapes for a given symmetry group. Namely, we prove that modifying the laplacian used in a 2D mesh-mapping technique Orbifold Tutte Embedding - can achieve all possible tiling configurations for a chosen planar 
    
[^75]: AIGC的创新数字叙事探索与讨论：对最新进展的探索与讨论

    Innovative Digital Storytelling with AIGC: Exploration and Discussion of Recent Advances. (arXiv:2309.14329v1 [cs.HC] CROSS LISTED)

    [http://arxiv.org/abs/2309.14329](http://arxiv.org/abs/2309.14329)

    本研究探索了AIGC与数字叙事的整合状态，发现虽然AIGC在某些领域表现出色，但由于人类的创造力和审美感等因素，仍无法替代人类在复杂人物动画、面部表情和音效方面的贡献。

    

    数字叙事作为一种艺术形式，一直在费用与质量之间挣扎。AI生成内容（AIGC）的出现被视为高效数字叙事制作的潜在解决方案。然而，这种融合的具体形式、效果和影响仍不清楚，使得AIGC与叙事的边界模糊不清。本研究探讨了AIGC与数字叙事的当前整合状态，在样本项目中研究了两者融合的艺术价值，并通过访谈解决常见问题。通过我们的研究，我们发现AIGC在图像创作、配音制作和音乐创作方面表现出色，但由于人类创造力和审美感的不可替代元素，尤其是在复杂人物动画、面部表情和音效方面，AIGC还无法取代人类。本研究的目标是增强公众对当前状态、限制和挑战的认识。

    Digital storytelling, as an art form, has struggled with cost-quality balance. The emergence of AI-generated Content (AIGC) is considered as a potential solution for efficient digital storytelling production. However, the specific form, effects, and impacts of this fusion remain unclear, leaving the boundaries of AIGC combined with storytelling undefined. This work explores the current integration state of AIGC and digital storytelling, investigates the artistic value of their fusion in a sample project, and addresses common issues through interviews. Through our study, we conclude that AIGC, while proficient in image creation, voiceover production, and music composition, falls short of replacing humans due to the irreplaceable elements of human creativity and aesthetic sensibilities at present, especially in complex character animations, facial expressions, and sound effects. The research objective is to increase public awareness of the current state, limitations, and challenges arisi
    
[^76]: Q-Bench: 一种用于低级别视觉通用基础模型的基准测试

    Q-Bench: A Benchmark for General-Purpose Foundation Models on Low-level Vision. (arXiv:2309.14181v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2309.14181](http://arxiv.org/abs/2309.14181)

    Q-Bench是一个综合性的基准测试，用于评估多模态大型语言模型在低级别视觉感知和理解方面的能力。

    

    多模态大型语言模型（MLLMs）的快速发展引发了计算机视觉从专门模型向通用基础模型的转变。然而，评估MLLMs在低级别视觉感知和理解方面的能力仍然不足。为了填补这一差距，我们提出了Q-Bench，这是一个综合性的基准测试，用于系统评估MLLMs在三个领域的潜在能力：低级别视觉感知、低级别视觉描述和整体视觉质量评估。

    The rapid evolution of Multi-modality Large Language Models (MLLMs) has catalyzed a shift in computer vision from specialized models to general-purpose foundation models. Nevertheless, there is still an inadequacy in assessing the abilities of MLLMs on low-level visual perception and understanding. To address this gap, we present Q-Bench, a holistic benchmark crafted to systematically evaluate potential abilities of MLLMs on three realms: low-level visual perception, low-level visual description, and overall visual quality assessment. a) To evaluate the low-level perception ability, we construct the LLVisionQA dataset, consisting of 2,990 diverse-sourced images, each equipped with a human-asked question focusing on its low-level attributes. We then measure the correctness of MLLMs on answering these questions. b) To examine the description ability of MLLMs on low-level information, we propose the LLDescribe dataset consisting of long expert-labelled golden low-level text descriptions o
    
[^77]: AgriSORT: 一种用于农业机器人精准农业的简单在线实时检测跟踪框架

    AgriSORT: A Simple Online Real-time Tracking-by-Detection framework for robotics in precision agriculture. (arXiv:2309.13393v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2309.13393](http://arxiv.org/abs/2309.13393)

    AgriSORT是一个简单的在线实时检测跟踪框架，主要解决精准农业中的多目标跟踪问题，通过仅使用运动信息进行关联，实现了准确和快速的跟踪轨迹传播。

    

    多目标跟踪（MOT）问题是指在视频序列中检测和跟踪所有物体，并为每个物体保持唯一的标识符。这是机器人领域中一个具有挑战性和基础性的问题。在精准农业中，要实现令人满意的解决方案面临着摄像机运动剧烈、光照突变和严重遮挡等挑战。大多数现代跟踪器依赖于物体的外观而不是运动来进行关联，在农业领域中静止物体具有相同外观时，这种方法可能不太有效。因此，在SORT的基础上，我们提出了AgriSORT，一种简单的、在线的、实时的基于运动信息的精准农业检测跟踪流水线，可以在帧间准确且快速地传播跟踪轨迹。AgriSORT的主要关注点是效率、灵活性、最小依赖性以及在机器人平台上的易部署性。

    The problem of multi-object tracking (MOT) consists in detecting and tracking all the objects in a video sequence while keeping a unique identifier for each object. It is a challenging and fundamental problem for robotics. In precision agriculture the challenge of achieving a satisfactory solution is amplified by extreme camera motion, sudden illumination changes, and strong occlusions. Most modern trackers rely on the appearance of objects rather than motion for association, which can be ineffective when most targets are static objects with the same appearance, as in the agricultural case. To this end, on the trail of SORT [5], we propose AgriSORT, a simple, online, real-time tracking-by-detection pipeline for precision agriculture based only on motion information that allows for accurate and fast propagation of tracks between frames. The main focuses of AgriSORT are efficiency, flexibility, minimal dependencies, and ease of deployment on robotic platforms. We test the proposed pipeli
    
[^78]: HANS，你聪明吗？神经系统的Clever Hans效应分析

    HANS, are you clever? Clever Hans Effect Analysis of Neural Systems. (arXiv:2309.12481v1 [cs.CL])

    [http://arxiv.org/abs/2309.12481](http://arxiv.org/abs/2309.12481)

    这项研究调查了指导调整的大型语言模型（It-LLMs）对多项选择题（MCQ）的鲁棒性能力，在选择顺序变动时揭示了选择偏见和推理能力的问题。

    

    指导调整的大型语言模型(It-LLMs)展示出了在认知状态、意图和反应方面推理的出色能力，可以让人们有效地引导和理解日常社交互动。事实上，已经提出了几个多项选择题(MCQ)基准来构建对模型能力的确切评估。然而，早期的研究表明It-LLMs中存在固有的“顺序偏见”，给适当的评估带来了挑战。本文通过使用四个MCQ基准对It-LLMs的抵抗能力进行了研究。通过引入对抗性示例，我们展示了显著的性能差距，特别是在选择顺序变动时，揭示了选择偏见并引发了对推理能力的讨论。通过第一位置和模型选择之间的相关性，我们假设在模型中存在结构启发式方法。

    Instruction-tuned Large Language Models (It-LLMs) have been exhibiting outstanding abilities to reason around cognitive states, intentions, and reactions of all people involved, letting humans guide and comprehend day-to-day social interactions effectively. In fact, several multiple-choice questions (MCQ) benchmarks have been proposed to construct solid assessments of the models' abilities. However, earlier works are demonstrating the presence of inherent "order bias" in It-LLMs, posing challenges to the appropriate evaluation. In this paper, we investigate It-LLMs' resilience abilities towards a series of probing tests using four MCQ benchmarks. Introducing adversarial examples, we show a significant performance gap, mainly when varying the order of the choices, which reveals a selection bias and brings into discussion reasoning abilities. Following a correlation between first positions and model choices due to positional bias, we hypothesized the presence of structural heuristics in 
    
[^79]: 具备视觉和触觉的手中物体通用旋转

    General In-Hand Object Rotation with Vision and Touch. (arXiv:2309.09979v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2309.09979](http://arxiv.org/abs/2309.09979)

    本研究介绍了一个能够通过视觉和触觉感知实现手中物体通用旋转的系统，通过训练和模拟推断物体的形状和物理属性，并在实际部署中展示了显著的性能提升。

    

    我们介绍了一个名为RotateIt的系统，通过利用多模态感知输入，使指尖能够在多个轴上进行物体旋转。我们的系统在仿真环境中进行训练，其中可以获取物体的真实形状和物理属性。然后我们将其简化为在真实但噪声干扰下的模拟触觉和本体感知输入。这些多模态输入通过视觉触觉变换器进行融合，使得在部署过程中可以进行物体形状和物理属性的在线推断。我们展示了相比以前的方法的显著性能改进，并且证明了视觉和触觉感知的重要性。

    We introduce RotateIt, a system that enables fingertip-based object rotation along multiple axes by leveraging multimodal sensory inputs. Our system is trained in simulation, where it has access to ground-truth object shapes and physical properties. Then we distill it to operate on realistic yet noisy simulated visuotactile and proprioceptive sensory inputs. These multimodal inputs are fused via a visuotactile transformer, enabling online inference of object shapes and physical properties during deployment. We show significant performance improvements over prior methods and the importance of visual and tactile sensing.
    
[^80]: 通过动态集成选择进行不平衡数据流分类

    Imbalanced Data Stream Classification using Dynamic Ensemble Selection. (arXiv:2309.09175v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2309.09175](http://arxiv.org/abs/2309.09175)

    本文提出了一个新的框架，通过对非稳态漂移的不平衡数据流进行分类框架设计，采用数据预处理和动态集成选择技术。该框架使用了六个人工生成的数据流，并且通过评估了七种预处理技术和两种动态集成选择方法的效果。

    

    现代流数据分类面临着概念漂移和类别不平衡数据的重大挑战。这对分类器的输出产生了负面影响，导致分类不正确。此外，多个类别的重叠等其他因素限制了输出的正确性程度。本文提出了一个新的框架，通过对非稳态漂移的不平衡数据流进行分类框架设计，采用数据预处理和动态集成选择技术。该框架使用了六个人工生成的数据流，这些数据流具有不同的不平衡比例，并且包含两种不同类型的概念漂移。每个数据流由200个500个对象的块组成，每个对象由八个特征描述，并且包含五个概念漂移。考虑了七种预处理技术和两种动态集成选择方法进行评估。

    Modern streaming data categorization faces significant challenges from concept drift and class imbalanced data. This negatively impacts the output of the classifier, leading to improper classification. Furthermore, other factors such as the overlapping of multiple classes limit the extent of the correctness of the output. This work proposes a novel framework for integrating data pre-processing and dynamic ensemble selection, by formulating the classification framework for the nonstationary drifting imbalanced data stream, which employs the data pre-processing and dynamic ensemble selection techniques. The proposed framework was evaluated using six artificially generated data streams with differing imbalance ratios in combination with two different types of concept drifts. Each stream is composed of 200 chunks of 500 objects described by eight features and contains five concept drifts. Seven pre-processing techniques and two dynamic ensemble selection methods were considered. According 
    
[^81]: 在物联网环境中检测未知攻击: 一种用于增强网络入侵检测的开放集分类器

    Detecting Unknown Attacks in IoT Environments: An Open Set Classifier for Enhanced Network Intrusion Detection. (arXiv:2309.07461v1 [cs.CR])

    [http://arxiv.org/abs/2309.07461](http://arxiv.org/abs/2309.07461)

    这项研究介绍了一个针对物联网环境定制的网络入侵检测系统的开放集分类器框架，利用图像表示和堆叠子聚类技术来识别未知攻击。

    

    物联网设备在生活的各个方面都得到了广泛的应用，这引入了互联的时代，创造了新的网络安全挑战，并强调了强大的入侵检测系统的需求。然而，传统的安全系统是基于封闭世界视角设计的，往往面临与不断发展的威胁环境中新的、陌生的攻击相处理的挑战。在本文中，我们介绍了一个框架，旨在解决物联网环境下网络入侵检测系统（NIDS）中的开放集识别（OSR）问题。我们的框架利用基于图像的数据表示，从网络流量中提取空间和时间模式。此外，我们还集成了堆叠和子聚类技术，通过有效地建模复杂和多样化的良性行为，实现对未知攻击的识别。

    The widespread integration of Internet of Things (IoT) devices across all facets of life has ushered in an era of interconnectedness, creating new avenues for cybersecurity challenges and underscoring the need for robust intrusion detection systems. However, traditional security systems are designed with a closed-world perspective and often face challenges in dealing with the ever-evolving threat landscape, where new and unfamiliar attacks are constantly emerging. In this paper, we introduce a framework aimed at mitigating the open set recognition (OSR) problem in the realm of Network Intrusion Detection Systems (NIDS) tailored for IoT environments. Our framework capitalizes on image-based representations of packet-level data, extracting spatial and temporal patterns from network traffic. Additionally, we integrate stacking and sub-clustering techniques, enabling the identification of unknown attacks by effectively modeling the complex and diverse nature of benign behavior. The empiric
    
[^82]: LEyes：一种轻量级深度学习眼动跟踪框架，使用合成眼部图像

    LEyes: A Lightweight Framework for Deep Learning-Based Eye Tracking using Synthetic Eye Images. (arXiv:2309.06129v1 [cs.CV])

    [http://arxiv.org/abs/2309.06129](http://arxiv.org/abs/2309.06129)

    本研究提出了一种名为LEyes的轻量级深度学习眼动跟踪框架，利用合成眼部图像进行训练，解决了由于训练数据集不足和眼部图像变异导致的模型泛化问题。实验结果表明，LEyes训练的模型在瞳孔和CR定位方面优于其他算法。

    

    深度学习已经加强了凝视估计技术，但实际部署受到不足的训练数据集的限制。眼部图像的硬件引起的变异以及记录的参与者之间固有的生物差异会导致特征和像素级别的差异，阻碍了在特定数据集上训练的模型的泛化能力。虚拟数据集可以是一个解决方案，但创建虚拟数据集既需要时间又需要资源。为了解决这个问题，我们提出了一个名为Light Eyes or "LEyes"的框架，与传统的逼真方法不同，LEyes仅模拟视频眼动跟踪所需的关键图像特征。LEyes便于在多样化的凝视估计任务上训练神经网络。我们证明，使用LEyes训练的模型在眼睛瞳孔和CR定位方面优于其他最先进的算法。

    Deep learning has bolstered gaze estimation techniques, but real-world deployment has been impeded by inadequate training datasets. This problem is exacerbated by both hardware-induced variations in eye images and inherent biological differences across the recorded participants, leading to both feature and pixel-level variance that hinders the generalizability of models trained on specific datasets. While synthetic datasets can be a solution, their creation is both time and resource-intensive. To address this problem, we present a framework called Light Eyes or "LEyes" which, unlike conventional photorealistic methods, only models key image features required for video-based eye tracking using simple light distributions. LEyes facilitates easy configuration for training neural networks across diverse gaze-estimation tasks. We demonstrate that models trained using LEyes outperform other state-of-the-art algorithms in terms of pupil and CR localization across well-known datasets. In addit
    
[^83]: 通过有符号梯度下降优化LLMs量化中的权重舍入

    Optimize Weight Rounding via Signed Gradient Descent for the Quantization of LLMs. (arXiv:2309.05516v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2309.05516](http://arxiv.org/abs/2309.05516)

    本文提出一种名为SignRound的优化权重舍入的方法，通过使用有符号梯度进行轻量级分块调整，解决了大型语言模型(LLMs)的量化挑战。

    

    大型语言模型(LLMs)在执行语言相关任务方面表现出了非凡的能力。然而，由于其巨大的内存和存储需求，它们的部署面临着重大挑战。为了解决这个问题，仅针对权重的量化，特别是3位和4位仅针对权重的量化，已经成为最可行的解决方案之一。随着位数的减少，量化网格变得更加宽泛，从而强调了上下舍入的重要性。尽管先前的研究表明，在某些情况下，通过添加扰动细调上下舍入可以提高准确性，但我们的研究受制于这些扰动的精确且有限的边界，只有改变舍入值的阈值才具有重要性。因此，我们提出了一种简洁高效的优化权重舍入任务的方法。我们的方法名为SignRound，它涉及使用有符号梯度的轻量级分块调整。

    Large Language Models (LLMs) have proven their exceptional capabilities in performing language-related tasks. However, their deployment poses significant challenges due to their considerable memory and storage requirements. In response to this issue, weight-only quantization, particularly 3 and 4-bit weight-only quantization, has emerged as one of the most viable solutions. As the number of bits decreases, the quantization grid broadens, thus emphasizing the importance of up and down rounding. While previous studies have demonstrated that fine-tuning up and down rounding with the addition of perturbations can enhance accuracy in some scenarios, our study is driven by the precise and limited boundary of these perturbations, where only the threshold for altering the rounding value is of significance. Consequently, we propose a concise and highly effective approach for optimizing the weight rounding task. Our method, named SignRound, involves lightweight block-wise tuning using signed gra
    
[^84]: 注意力和自监督语音嵌入对非语义语音任务的影响

    Effect of Attention and Self-Supervised Speech Embeddings on Non-Semantic Speech Tasks. (arXiv:2308.14359v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2308.14359](http://arxiv.org/abs/2308.14359)

    该论文探讨了注意力和自监督语音嵌入对非语义语音任务的影响，特别是情感理解。实验结果表明，基于自注意力的轻量级HuBERT-Large模型在这些任务中表现出色。

    

    在现实中，人类情感理解在使对话技术成为主流方面至关重要。我们将语音情感理解视为一种知觉任务，这是一种更现实的情景。在不同的上下文（语言，人口统计学等），不同比例的人会将相同的语音片段视为非一致的情感。作为ACM多媒体2023计算语音联机挑战（ComParE）的一部分，在EMotion Share轨道上，我们利用他们丰富的多语种演讲者和多标签回归目标的数据集，即“情感分享”或对该情感的感知。我们证明了不同基础模型的训练方案决定了它们在超越语音识别的任务中的有效性，特别是对于情感理解等非语义语音任务。这是一个非常复杂的任务，因为涉及到多语种演讲者，目标标签的变化以及回归数据集中的固有不平衡性。我们的结果表明，基于自注意力的轻量级HuBERT-Large模型在这些任务中表现出色。

    Human emotion understanding is pivotal in making conversational technology mainstream. We view speech emotion understanding as a perception task which is a more realistic setting. With varying contexts (languages, demographics, etc.) different share of people perceive the same speech segment as a non-unanimous emotion. As part of the ACM Multimedia 2023 Computational Paralinguistics ChallengE (ComParE) in the EMotion Share track, we leverage their rich dataset of multilingual speakers and multi-label regression target of 'emotion share' or perception of that emotion. We demonstrate that the training scheme of different foundation models dictates their effectiveness for tasks beyond speech recognition, especially for non-semantic speech tasks like emotion understanding. This is a very complex task due to multilingual speakers, variability in the target labels, and inherent imbalance in the regression dataset. Our results show that HuBERT-Large with a self-attention-based light-weight se
    
[^85]: 理解基于QUBO的哈密顿函数在图上的组合优化中的使用：以最大切割问题为例讨论

    Understanding the Usage of QUBO-based Hamiltonian Function in Combinatorial Optimization over Graphs: A Discussion Using Max Cut (MC) Problem. (arXiv:2308.13978v1 [cs.AI])

    [http://arxiv.org/abs/2308.13978](http://arxiv.org/abs/2308.13978)

    研究探讨了在图上基于QUBO公式的最大切割问题中，如何使用基于强化学习范式和哈密顿函数来解决组合优化问题。通过使用图神经网络作为信息传递架构，并通过三种不同的公式形式进行实验，发现...

    

    二次无约束二进制优化（QUBO）是一种广义技术，用于将各种NP困难组合优化问题建模为二进制变量的形式。哈密顿函数经常用于形成QUBO问题，其中它在优化的上下文中被用作目标函数。在本研究中，我们研究了如何使用基于强化学习（RL）范式和哈密顿函数解决QUBO公式中的图上组合优化问题。我们使用图神经网络（GNN）作为信息传递架构在节点之间传递信息。我们主要研究了三种公式，Monty-Carlo Tree Search with GNN-based RL（MCTS-GNN）、DQN with GNN-based RL和带有注意力的通用GNN（GRL）。我们的研究结果表明，...

    Quadratic Unconstrained Binary Optimization (QUBO) is a generic technique to model various NP-hard combinatorial optimization problems in the form of binary variables. The Hamiltonian function is often used to formulate QUBO problems where it is used as the objective function in the context of optimization. In this study, we investigate how reinforcement learning-based (RL) paradigms with the presence of the Hamiltonian function can address combinatorial optimization problems over graphs in QUBO formulations. We use Graph Neural Network (GNN) as the message-passing architecture to convey the information among the nodes. We have centered our discussion on QUBO formulated Max-Cut problem but the intuitions can be extended to any QUBO supported canonical NP-Hard combinatorial optimization problems. We mainly investigate three formulations, Monty-Carlo Tree Search with GNN-based RL (MCTS-GNN), DQN with GNN-based RL, and a generic GNN with attention-based RL (GRL). Our findings state that i
    
[^86]: 思想算法：增强大型语言模型中的思想探索

    Algorithm of Thoughts: Enhancing Exploration of Ideas in Large Language Models. (arXiv:2308.10379v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2308.10379](http://arxiv.org/abs/2308.10379)

    本论文提出了一种名为"思想算法"的策略，通过算法推理路径推动大型语言模型的思想探索，以低成本、低存储和低计算开销的方式扩展了其推理能力。结果显示，使用算法指导的大型语言模型的性能可以超越算法本身。

    

    当前的文献旨在超越“连续思维”的方法，通常采用外部操作方法，在生成过程中停止、修改，然后恢复以增强大型语言模型（LLM）的推理能力。这种模式增加了查询请求的数量，增加了成本、内存和计算开销。针对这个问题，我们提出了思想算法——一种新颖的策略，通过算法推理路径推动LLM，开创了一种新的上下文学习模式。通过使用算法示例，我们利用LLM的固有循环动力学，仅使用一个或少数几个查询扩展其思想探索。我们的技术优于早期的单次查询方法，并与最近采用广泛的树搜索算法的多次查询策略不相上下。有趣的是，我们的结果表明，使用算法指导LLM可以使性能超越算法本身，这暗示着

    Current literature, aiming to surpass the "Chain-of-Thought" approach, often resorts to an external modus operandi involving halting, modifying, and then resuming the generation process to boost Large Language Models' (LLMs) reasoning capacities. This mode escalates the number of query requests, leading to increased costs, memory, and computational overheads. Addressing this, we propose the Algorithm of Thoughts -- a novel strategy that propels LLMs through algorithmic reasoning pathways, pioneering a new mode of in-context learning. By employing algorithmic examples, we exploit the innate recurrence dynamics of LLMs, expanding their idea exploration with merely one or a few queries. Our technique outperforms earlier single-query methods and stands on par with a recent multi-query strategy that employs an extensive tree search algorithm. Intriguingly, our results suggest that instructing an LLM using an algorithm can lead to performance surpassing that of the algorithm itself, hinting 
    
[^87]: 大型语言模型和认知架构的协同集成对于稳健人工智能的探索分析

    Synergistic Integration of Large Language Models and Cognitive Architectures for Robust AI: An Exploratory Analysis. (arXiv:2308.09830v1 [cs.AI])

    [http://arxiv.org/abs/2308.09830](http://arxiv.org/abs/2308.09830)

    本文探索了将大型语言模型和认知架构相结合的替代方案，通过协同方法互补各自的弱点和限制，从而实现更稳健和复杂的人工智能系统。

    

    本文探讨了在构建表现出智能行为的人工智能代理时，将大型语言模型(LLMs)和认知架构(CAs) 进行集成的替代方案。在理论模型的指导下，通过初步的经验数据支持，我们假设不同的协同方法可以互补它们各自的弱点和限制，从而培育出更稳健和复杂的人工智能系统。此外，我们还讨论了每种方法所涉及的权衡和挑战。

    This paper explores alternatives for integrating two subdisciplines of AI in the construction of artificial agents that exhibit intelligent behavior: Large Language Models (LLMs) and Cognitive Architectures (CAs). Guided by theoretical models and supported by preliminary empirical data, we hypothesize how diverse synergistic approaches can mutually compensate for their respective weaknesses and limitations, ultimately fostering more robust and sophisticated artificial intelligence systems. Additionally, we discuss the tradeoffs and challenges associated with each approach.
    
[^88]: 提升大型语言模型的推理能力：一种基于图形验证的方法

    Enhancing Reasoning Capabilities of Large Language Models: A Graph-Based Verification Approach. (arXiv:2308.09267v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2308.09267](http://arxiv.org/abs/2308.09267)

    本研究引入了一种基于图形验证的方法，以进一步提高大型语言模型（LLM）的推理能力，通过将LLM生成的多个解决方案表示为推理图，从而增强推理能力。

    

    大型语言模型（LLM）展现出了令人印象深刻的推理能力，在复杂的数学问题等推理任务中，特别是在受特定设计的提示指导下。这些模型通常使用思维链的方法来解决任务，这不仅增强了它们的推理能力，还提供了宝贵的洞察力，揭示了它们的问题求解过程。然而，提升LLM的推理能力还有很大的改进空间。一些研究表明，将LLM输出验证器集成到模型中可以提高推理准确性，而无需额外进行模型训练。在本文中，我们遵循这些研究，引入了一种新颖的基于图形的方法，进一步增强LLM的推理能力。我们设想一个推理任务的多个解决方案，由LLM生成，可以由推理图表示，因为不同推理路径的中间步骤之间存在逻辑连接。因此，我们提出了推理图方法。

    Large Language Models (LLMs) have showcased impressive reasoning capabilities, particularly when guided by specifically designed prompts in complex reasoning tasks such as math word problems. These models typically solve tasks using a chain-of-thought approach, which not only bolsters their reasoning abilities but also provides valuable insights into their problem-solving process. However, there is still significant room for enhancing the reasoning abilities of LLMs. Some studies suggest that the integration of an LLM output verifier can boost reasoning accuracy without necessitating additional model training. In this paper, we follow these studies and introduce a novel graph-based method to further augment the reasoning capabilities of LLMs. We posit that multiple solutions to a reasoning task, generated by an LLM, can be represented as a reasoning graph due to the logical connections between intermediate steps from different reasoning paths. Therefore, we propose the Reasoning Graph 
    
[^89]: 基于HTN的概率性依赖规划用于高质量计划

    Probabilistic contingent planning based on HTN for high-quality plans. (arXiv:2308.06922v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2308.06922](http://arxiv.org/abs/2308.06922)

    该论文提出了一种基于概率性依赖规划的HTN规划器，用于在部分可观察环境中生成高质量的计划。通过扩展HTN规划的形式化和引入新颖的启发式规则，该规划器能够在具有不确定性的环境中产生灵活且稳健的解决方案。

    

    确定性规划假设规划沿着完全可预测的路径发展，因此在大多数真实的情景中失去了实际价值。更现实的观点是规划应该事先考虑到部分可观察性，并为更灵活和稳健的解决方案而努力。而且更重要的是，在部分可观察环境中规划的质量不可避免地变化较大。在本文中，我们提出了一个概率性依赖Hierarchical Task Network (HTN) 规划器，称为High-Quality Contingent Planner (HQCP)，以在部分可观察环境中生成高质量的计划。我们将HTN规划中的形式化扩展到部分可观测性，并对其成本进行评估。接着，我们探索了一种新颖的高质量计划启发式规则，并开发了集成规划算法。最后，一项实证研究验证了规划器在概率性依赖规划和高质量计划方面的有效性和效率。

    Deterministic planning assumes that the planning evolves along a fully predictable path, and therefore it loses the practical value in most real projections. A more realistic view is that planning ought to take into consideration partial observability beforehand and aim for a more flexible and robust solution. What is more significant, it is inevitable that the quality of plan varies dramatically in the partially observable environment. In this paper we propose a probabilistic contingent Hierarchical Task Network (HTN) planner, named High-Quality Contingent Planner (HQCP), to generate high-quality plans in the partially observable environment. The formalisms in HTN planning are extended into partial observability and are evaluated regarding the cost. Next, we explore a novel heuristic for high-quality plans and develop the integrated planning algorithm. Finally, an empirical study verifies the effectiveness and efficiency of the planner both in probabilistic contingent planning and for
    
[^90]: VisIT-Bench: 一个受真实世界使用启发的视觉语言指示评估基准

    VisIT-Bench: A Benchmark for Vision-Language Instruction Following Inspired by Real-World Use. (arXiv:2308.06595v1 [cs.CL])

    [http://arxiv.org/abs/2308.06595](http://arxiv.org/abs/2308.06595)

    VisIT-Bench是一个用于评价真实世界中视觉语言模型指示遵循的基准，包含了各种任务并提供了详细描述，可以自动评估多模态生成的质量差距。

    

    我们引入了VisIT-Bench（Visual InsTruction Benchmark），这是一个评价用于真实世界使用的视觉语言模型的指示遵循基准。我们的起点是策划了70个“指示家族”，我们认为指示调优的视觉语言模型应该能够解决这些家族。任务不仅限于VQAv2和COCO等评估，涵盖了从基本识别到游戏玩法和创造性生成的各种任务。在策划之后，我们的数据集包括592个测试查询，每个查询都带有一个人工编写的指示条件化的字幕。这些描述展现了特定指示因素，例如对于询问店面对于轮椅用户的易访问性的指示，条件化的字幕描述了斜坡/潜在障碍物。这些描述使得我们可以：1）收集每个实例的人工验证的参考输出；2）使用仅文本的语言模型对候选多模态生成进行自动评估，与人类判断相一致。我们量化了质量差距。

    We introduce VisIT-Bench (Visual InsTruction Benchmark), a benchmark for evaluation of instruction-following vision-language models for real-world use. Our starting point is curating 70 'instruction families' that we envision instruction tuned vision-language models should be able to address. Extending beyond evaluations like VQAv2 and COCO, tasks range from basic recognition to game playing and creative generation. Following curation, our dataset comprises 592 test queries, each with a human-authored instruction-conditioned caption. These descriptions surface instruction-specific factors, e.g., for an instruction asking about the accessibility of a storefront for wheelchair users, the instruction-conditioned caption describes ramps/potential obstacles. These descriptions enable 1) collecting human-verified reference outputs for each instance; and 2) automatic evaluation of candidate multimodal generations using a text-only LLM, aligning with human judgment. We quantify quality gaps be
    
[^91]: 使用随机线性分类器进行概率不变学习

    Probabilistic Invariant Learning with Randomized Linear Classifiers. (arXiv:2308.04412v1 [cs.LG])

    [http://arxiv.org/abs/2308.04412](http://arxiv.org/abs/2308.04412)

    本文介绍了一种使用随机线性分类器进行概率不变学习的方法，通过接受概率化的普遍逼近和不变性，设计了能同时具有表达能力和不变性的模型，并且使用更少的资源。通过实验证明了这种方法在分类任务中的有效性。

    

    设计既具有表达能力又能保持任务已知不变性的模型是一个越来越困难的问题。现有解决方案在不变性和计算或内存资源之间进行权衡。在这项工作中，我们展示了如何利用随机性设计既具表达能力又具不变性但使用更少资源的模型。受随机算法的启发，我们的关键洞察是接受概率化的普遍逼近和不变性可以减少资源需求。具体而言，我们提出了一类称为随机线性分类器 (RLCs) 的二分类模型。我们给出了参数和样本大小的条件，在这些条件下，RLCs 可以以高概率逼近任何（平滑）函数，并保持对紧致群变换的不变性。利用这一结果，我们设计了三种可验证地概率不变的 RLCs，用于集合、图和球形数据的分类任务。我们展示了这些模型如何实现概率不变性。

    Designing models that are both expressive and preserve known invariances of tasks is an increasingly hard problem. Existing solutions tradeoff invariance for computational or memory resources. In this work, we show how to leverage randomness and design models that are both expressive and invariant but use less resources. Inspired by randomized algorithms, our key insight is that accepting probabilistic notions of universal approximation and invariance can reduce our resource requirements. More specifically, we propose a class of binary classification models called Randomized Linear Classifiers (RLCs). We give parameter and sample size conditions in which RLCs can, with high probability, approximate any (smooth) function while preserving invariance to compact group transformations. Leveraging this result, we design three RLCs that are provably probabilistic invariant for classification tasks over sets, graphs, and spherical data. We show how these models can achieve probabilistic invari
    
[^92]: TinyMetaFed: 高效的用于TinyML的联邦元学习

    TinyMetaFed: Efficient Federated Meta-Learning for TinyML. (arXiv:2307.06822v1 [cs.LG])

    [http://arxiv.org/abs/2307.06822](http://arxiv.org/abs/2307.06822)

    TinyMetaFed是一个适用于TinyML的高效联邦元学习框架，通过协同训练神经网络初始化，在小型设备上能够快速微调，同时实现通信节省和隐私保护。

    

    Tiny Machine Learning (TinyML)领域在使得机器学习在低功耗设备（如微控制器）上实现方面取得了重大进展。这些微型设备的普及引发了一个问题，即聚合它们的知识是否能够使TinyML应用受益。联邦元学习是这个问题的一个有前景的答案，因为它解决了现实世界中标记数据的稀缺性和设备之间的异构数据分布。然而，部署TinyML硬件面临着独特的资源限制，现有方法由于能源、隐私和通信限制而不实用。我们引入了TinyMetaFed，一个适用于TinyML的模型无关的元学习框架。TinyMetaFed促进了神经网络初始化的协同训练，可以在新设备上快速微调。它通过部分本地重构和Top-P%选择性通信提供通信节省和隐私保护，具有计算效果好。

    The field of Tiny Machine Learning (TinyML) has made substantial advancements in democratizing machine learning on low-footprint devices, such as microcontrollers. The prevalence of these miniature devices raises the question of whether aggregating their knowledge can benefit TinyML applications. Federated meta-learning is a promising answer to this question, as it addresses the scarcity of labeled data and heterogeneous data distribution across devices in the real world. However, deploying TinyML hardware faces unique resource constraints, making existing methods impractical due to energy, privacy, and communication limitations. We introduce TinyMetaFed, a model-agnostic meta-learning framework suitable for TinyML. TinyMetaFed facilitates collaborative training of a neural network initialization that can be quickly fine-tuned on new devices. It offers communication savings and privacy protection through partial local reconstruction and Top-P% selective communication, computational eff
    
[^93]: SayPlan: 使用3D场景图为可扩展任务规划对大规模语言模型进行基础化

    SayPlan: Grounding Large Language Models using 3D Scene Graphs for Scalable Task Planning. (arXiv:2307.06135v1 [cs.RO])

    [http://arxiv.org/abs/2307.06135](http://arxiv.org/abs/2307.06135)

    SayPlan是一种利用3D场景图为基础的可扩展的大规模任务规划方法，通过利用3D场景图的层次结构、集成经典路径规划器以及引入迭代的重规划流程，实现了在庞大复杂环境中进行规划的能力。

    

    大规模语言模型（LLM）在开发多样化任务的通用规划智能体方面取得了令人印象深刻的结果。然而，将这些规划应用于庞大、多层楼、多房间的环境中对机器人提出了重大挑战。我们介绍了一种名为SayPlan的可扩展方法，利用3D场景图（3DSG）表示进行基于LLM的大规模任务规划。为了确保我们的方法的可扩展性，我们：（1）利用3DSG的层次结构允许LLMs从较小的、折叠的完整图表示中进行语义搜索，寻找与任务相关的子图；（2）通过集成经典路径规划器减少LLM的规划视野；（3）引入一个迭代的重规划流程，通过与场景图模拟器的反馈来修正不可行的动作并避免规划失败。我们在两个涵盖3层、36个房间和140个对象的大规模环境上评估了我们的方法。

    Large language models (LLMs) have demonstrated impressive results in developing generalist planning agents for diverse tasks. However, grounding these plans in expansive, multi-floor, and multi-room environments presents a significant challenge for robotics. We introduce SayPlan, a scalable approach to LLM-based, large-scale task planning for robotics using 3D scene graph (3DSG) representations. To ensure the scalability of our approach, we: (1) exploit the hierarchical nature of 3DSGs to allow LLMs to conduct a semantic search for task-relevant subgraphs from a smaller, collapsed representation of the full graph; (2) reduce the planning horizon for the LLM by integrating a classical path planner and (3) introduce an iterative replanning pipeline that refines the initial plan using feedback from a scene graph simulator, correcting infeasible actions and avoiding planning failures. We evaluate our approach on two large-scale environments spanning up to 3 floors, 36 rooms and 140 objects
    
[^94]: 用于机器学习的时态图基准测试

    Temporal Graph Benchmark for Machine Learning on Temporal Graphs. (arXiv:2307.01026v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2307.01026](http://arxiv.org/abs/2307.01026)

    TGB是一个用于在时态图上进行机器学习模型评估的基准测试数据集集合，具有挑战性和多样化，涵盖了节点和边级预测任务，对多种领域的时态图进行了广泛的基准测试，并发现常见模型的性能可能有巨大差异。在动态节点属性预测任务中，我们展示了简单方法可能比现有的时态图模型表现出更好的性能。

    

    我们提出了Temporal Graph Benchmark（TGB），这是一个用于在时态图上进行真实、可重现和强大的机器学习模型评估的挑战性和多样化的基准测试数据集集合。TGB数据集具有大规模、跨年的时长，包括节点和边级预测任务，并涵盖了社交、贸易、交易和交通网络等多种领域。针对这两个任务，我们设计了基于实际使用案例的评估协议。我们对每个数据集进行了广泛的基准测试，并发现常见模型的性能在不同的数据集上可能存在巨大差异。此外，在动态节点属性预测任务中，我们展示了简单方法常常比现有的时态图模型表现出更好的性能。我们相信这些发现为未来的时态图研究开辟了机会。最后，TGB提供了一个自动化的机器学习流程，用于可重现和可访问的时态图研究，包括...

    We present the Temporal Graph Benchmark (TGB), a collection of challenging and diverse benchmark datasets for realistic, reproducible, and robust evaluation of machine learning models on temporal graphs. TGB datasets are of large scale, spanning years in duration, incorporate both node and edge-level prediction tasks and cover a diverse set of domains including social, trade, transaction, and transportation networks. For both tasks, we design evaluation protocols based on realistic use-cases. We extensively benchmark each dataset and find that the performance of common models can vary drastically across datasets. In addition, on dynamic node property prediction tasks, we show that simple methods often achieve superior performance compared to existing temporal graph models. We believe that these findings open up opportunities for future research on temporal graphs. Finally, TGB provides an automated machine learning pipeline for reproducible and accessible temporal graph research, inclu
    
[^95]: 重温接受性判断

    Revisiting Acceptability Judgements. (arXiv:2305.14091v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.14091](http://arxiv.org/abs/2305.14091)

    本文介绍了第一个大规模的非英语语言可接受性数据集CoLAC，发现语言模型性能低于人类的表现，但跨语言转移可行，并可以追溯到预训练阶段。

    

    至NLP社区最后一次关注语言可接受性已经过去多年。在本文中，我们在大型语言模型的背景下重温这个话题。我们引入了 CoLAC-中文语言可接受性语料库，这是第一个由母语讲者验证并带有两组标签的大规模非英语可接受性数据集。我们的实验表明，即使最大的InstructGPT模型在CoLAC上也只能表现随机水平，而ChatGPT的性能（48.30 MCC）也远低于监督模型（59.03 MCC）和人类（65.11 MCC）。通过跨语言转移实验和细粒度的语言分析，我们首次证明了语言可接受性知识可以在不同类型的语言之间转移，而且可以追溯到预训练阶段。

    Years have passed since the NLP community has last focused on linguistic acceptability. In this work, we revisit this topic in the context of large language models. We introduce CoLAC - Corpus of Linguistic Acceptability in Chinese, the first large-scale non-English acceptability dataset that is verified by native speakers and comes with two sets of labels. Our experiments show that even the largest InstructGPT model performs only at chance level on CoLAC, while ChatGPT's performance (48.30 MCC) is also way below supervised models (59.03 MCC) and human (65.11 MCC). Through cross-lingual transfer experiments and fine-grained linguistic analysis, we demonstrate for the first time that knowledge of linguistic acceptability can be transferred across typologically distinct languages, as well as be traced back to pre-training.
    
[^96]: 大型语言模型合成文本数据集的语言多样性可视化

    Visualizing Linguistic Diversity of Text Datasets Synthesized by Large Language Models. (arXiv:2305.11364v1 [cs.CL])

    [http://arxiv.org/abs/2305.11364](http://arxiv.org/abs/2305.11364)

    该论文介绍了一种新的可视化工具，用于分析大型语言模型生成的数据集的句法多样性，可以通过分层可视化来帮助用户快速浏览概述和检查各个示例。

    

    大型语言模型（LLMs）可通过少量提示生成更精细的数据集用于基准测试、微调或其他用例。然而，理解和评估这些数据集很困难，而LLM生成数据的失败模式仍不为人们所理解。具体来说，数据可能以意外的方式变得重复，不仅语义上如此，而且在句法、词汇方面也是如此。我们提出了LinguisticLens，一种新颖的交互式可视化工具，用于理解和分析LLM生成数据集的句法多样性。 LinguisticLens沿着句法、词汇和语义轴将文本聚类。它支持文本数据集的分层可视化，允许用户快速浏览概述和检查各个示例。实时演示可在shorturl.at/zHOUV查看。

    Large language models (LLMs) can be used to generate smaller, more refined datasets via few-shot prompting for benchmarking, fine-tuning or other use cases. However, understanding and evaluating these datasets is difficult, and the failure modes of LLM-generated data are still not well understood. Specifically, the data can be repetitive in surprising ways, not only semantically but also syntactically and lexically. We present LinguisticLens, a novel inter-active visualization tool for making sense of and analyzing syntactic diversity of LLM-generated datasets. LinguisticLens clusters text along syntactic, lexical, and semantic axes. It supports hierarchical visualization of a text dataset, allowing users to quickly scan for an overview and inspect individual examples. The live demo is available at shorturl.at/zHOUV.
    
[^97]: 移动机器人全身操作的因果策略梯度

    Causal Policy Gradient for Whole-Body Mobile Manipulation. (arXiv:2305.04866v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2305.04866](http://arxiv.org/abs/2305.04866)

    本文提出了一种新框架——因果MoMa，可以训练适用于典型MoMa任务的策略，在此框架下，机动和交互自由度可以同时组合，并且不需要人类领域知识来划分动作空间或将动作部分与子目标匹配。

    

    开发下一代家庭机器人助手需要结合机动和交互能力，即通常所说的移动操作。由于机器人的大动作空间和任务常见的多目标性质，例如能够有效地达到目标且避免障碍，移动操作任务很难。目前的方法通常根据人工匹配动作空间的部分到移动操作子目标（例如用于移动目标的基础动作和用于操作的手臂动作）将任务分为不带操作的导航和不带机动的固定操作。此解决方案防止了机动和交互自由度的同时组合，并且需要人类领域知识来划分动作空间并将动作部分与子目标匹配。在本文中，我们介绍了一种新的框架——因果MoMa，该框架用于训练典型MoMa任务的策略。

    Developing the next generation of household robot helpers requires combining locomotion and interaction capabilities, which is generally referred to as mobile manipulation (MoMa). MoMa tasks are difficult due to the large action space of the robot and the common multi-objective nature of the task, e.g., efficiently reaching a goal while avoiding obstacles. Current approaches often segregate tasks into navigation without manipulation and stationary manipulation without locomotion by manually matching parts of the action space to MoMa sub-objectives (e.g. base actions for locomotion objectives and arm actions for manipulation). This solution prevents simultaneous combinations of locomotion and interaction degrees of freedom and requires human domain knowledge for both partitioning the action space and matching the action parts to the sub-objectives. In this paper, we introduce Causal MoMa, a new framework to train policies for typical MoMa tasks that makes use of the most favorable subsp
    
[^98]: 金融时间序列预测的深度学习技术: 2020-2022年的最新进展综述

    Deep learning techniques for financial time series forecasting: A review of recent advancements: 2020-2022. (arXiv:2305.04811v1 [q-fin.ST])

    [http://arxiv.org/abs/2305.04811](http://arxiv.org/abs/2305.04811)

    本研究综述了深度学习模型在金融时间序列预测上的最新研究进展，包括不同数据来源和神经网络结构以及实现细节，并提供未来研究方向的建议。

    

    预测金融时间序列一直是一个具有挑战性的问题，吸引了研究人员和从业者的关注。在过去几十年中，统计学和机器学习技术都被探索用于开发有效的预测模型。随着深度学习模型的最新发展，金融时间序列预测模型得到了显著的发展，这些新进展往往难以跟上。因此，我们进行了这篇文献综述，对2020年至2022年间基于深度学习模型用于预测金融价格的最新研究进行了全面评估。我们的综述介绍了不同的数据来源和神经网络结构，以及它们的实现细节。我们的目标是确保感兴趣的研究人员了解该领域的最新发展，并便于根据先前研究中使用的模型选择基准线。此外，我们提供了未来研究方向的建议。

    Forecasting financial time series has long been a challenging problem that has attracted attention from both researchers and practitioners. Statistical and machine learning techniques have both been explored to develop effective forecasting models in the past few decades. With recent developments in deep learning models, financial time series forecasting models have advanced significantly, and these developments are often difficult to keep up with. Hence, we have conducted this literature review to provide a comprehensive assessment of recent research from 2020 to 2022 on deep learning models used to predict prices based on financial time series. Our review presents different data sources and neural network structures, as well as their implementation details. Our goals are to ensure that interested researchers remain up-to-date on recent developments in the field and facilitate the selection of baselines based on models used in prior studies. Additionally, we provide suggestions for fu
    
[^99]: 学习6D非抓取式操作的混合演员-评论员地图

    Learning Hybrid Actor-Critic Maps for 6D Non-Prehensile Manipulation. (arXiv:2305.03942v1 [cs.RO])

    [http://arxiv.org/abs/2305.03942](http://arxiv.org/abs/2305.03942)

    论文介绍了一种名为HACMan的强化学习方法，用于使用点云观察进行6D非抓取式操作的物体操纵。HACMan重点关注物体中心动作表示，它包括从物体点云中选择接触位置和一组描述机器人在接触后如何移动的运动参数。在实际测试中，HACMan的表现明显优于现有基线方法。

    

    在人类的灵巧性中，非抓取式操作是操作物体的重要组成部分。非抓取式操纵可以使与物体的交互更加复杂，但也在推理交互方面提出了挑战。在本文中，我们引入了一个名为HACMan的混合演员评论员地图，这是一种使用点云观察的6D非抓取式物体操作的强化学习方法。HACMan提出了一种时间抽象和空间基础的物体中心动作表示，该表示包括从物体点云中选择接触位置和一组描述机器人在接触后如何移动的运动参数。我们修改了一个现有的离线策略RL算法，以在这种混合的离散-连续动作表示学习。我们在仿真和现实世界中对HACMan进行了6D物体姿态对齐任务的评估。在最难的任务版本中，通过随机初始化物体和机器人配置，HACMan的表现优于现有的基线方法。

    Manipulating objects without grasping them is an essential component of human dexterity, referred to as non-prehensile manipulation. Non-prehensile manipulation may enable more complex interactions with the objects, but also presents challenges in reasoning about the interactions. In this work, we introduce Hybrid Actor-Critic Maps for Manipulation (HACMan), a reinforcement learning approach for 6D non-prehensile manipulation of objects using point cloud observations. HACMan proposes a temporally-abstracted and spatially-grounded object-centric action representation that consists of selecting a contact location from the object point cloud and a set of motion parameters describing how the robot will move after making contact. We modify an existing off-policy RL algorithm to learn in this hybrid discrete-continuous action representation. We evaluate HACMan on a 6D object pose alignment task in both simulation and in the real world. On the hardest version of our task, with randomized init
    
[^100]: 作为经典计划的量子电路最优布局综合

    Optimal Layout Synthesis for Quantum Circuits as Classical Planning. (arXiv:2304.12014v2 [quant-ph] UPDATED)

    [http://arxiv.org/abs/2304.12014](http://arxiv.org/abs/2304.12014)

    本文提供了两种编码，将最优布局综合作为经典规划问题，并使用最优的经典规划器来综合标准基准测试的最优布局，解决了对于大规模量子比特优化布局的问题。

    

    在布局综合中，将量子电路的逻辑量子比特映射到给定量子硬件平台的物理量子比特，考虑物理量子比特的连接。这涉及在应用于远距离量子比特的操作之前插入SWAP门。最优布局综合对于当前误差率较高的硬件上实用的量子计算非常重要：最小化SWAP门数量直接减轻了运行量子电路时的错误率。近年来，已经提出了几种方法来最小化所需的SWAP插入次数。所提出的精确方法只能扩展到少量的量子比特。证明所需的交换插入次数是最优的要比生成近似最优的映射困难得多。在本文中，我们提供了两种编码，将最优布局综合作为经典规划问题。我们使用最优的经典规划器来综合标准基准测试的最优布局。我们的结果显示了我们方法的可扩展性。

    In Layout Synthesis, the logical qubits of a quantum circuit are mapped to the physical qubits of a given quantum hardware platform, taking into account the connectivity of physical qubits. This involves inserting SWAP gates before an operation is applied on distant qubits. Optimal Layout Synthesis is crucial for practical Quantum Computing on current error-prone hardware: Minimizing the number of SWAP gates directly mitigates the error rates when running quantum circuits.  In recent years, several approaches have been proposed for minimizing the required SWAP insertions. The proposed exact approaches can only scale to a small number of qubits. Proving that a number of swap insertions is optimal is much harder than producing near optimal mappings.  In this paper, we provide two encodings for Optimal Layout Synthesis as a classical planning problem. We use optimal classical planners to synthesize the optimal layout for a standard set of benchmarks. Our results show the scalability of ou
    
[^101]: 多尺度进化神经架构搜索用于深度脉冲神经网络

    Multi-scale Evolutionary Neural Architecture Search for Deep Spiking Neural Networks. (arXiv:2304.10749v1 [cs.NE])

    [http://arxiv.org/abs/2304.10749](http://arxiv.org/abs/2304.10749)

    本文提出了一种新方法--多尺度进化神经架构搜索，用于自动设计脉冲神经网络，同时考虑微观、中观和宏观尺度的脑拓扑结构。MSE-NAS可以帮助SNN实现多电路模式的自组织集成，并通过全局性的跨模式连接来优化网络性能。

    

    脉冲神经网络（SNN）不仅因其离散信号处理的能源效率卓越，而且因其天然适合于集成多尺度生物可塑性而受到广泛关注。然而，大多数SNN直接采用成熟的DNN结构，很少自动设计神经架构搜索（NAS）用于SNN。人类大脑神经模式的拓扑结构，模块化的区域结构和全局性的跨脑区连接是自然进化的产物，可以作为设计基于脑的SNN架构的完美参考。本文提出了一种多尺度进化神经架构搜索（MSE-NAS），同时考虑微观、中观和宏观尺度的脑拓扑作为进化搜索空间。 MSE-NAS通过基于大脑启发的间接方式，进化单个神经元操作，多个电路模式的自组织集成以及跨模式的全局连通性。

    Spiking Neural Networks (SNNs) have received considerable attention not only for their superiority in energy efficient with discrete signal processing, but also for their natural suitability to integrate multi-scale biological plasticity. However, most SNNs directly adopt the structure of the well-established DNN, rarely automatically design Neural Architecture Search (NAS) for SNNs. The neural motifs topology, modular regional structure and global cross-brain region connection of the human brain are the product of natural evolution and can serve as a perfect reference for designing brain-inspired SNN architecture. In this paper, we propose a Multi-Scale Evolutionary Neural Architecture Search (MSE-NAS) for SNN, simultaneously considering micro-, meso- and macro-scale brain topologies as the evolutionary search space. MSE-NAS evolves individual neuron operation, self-organized integration of multiple circuit motifs, and global connectivity across motifs through a brain-inspired indirec
    
[^102]: 创作迪斯科：音乐可视化的文本到视频生成

    Generative Disco: Text-to-Video Generation for Music Visualization. (arXiv:2304.08551v1 [cs.HC])

    [http://arxiv.org/abs/2304.08551](http://arxiv.org/abs/2304.08551)

    Generative Disco是一个生成式人工智能系统，利用大型语言模型和文本到图像模型帮助生成音乐可视化；用户通过定义开始和结束提示来参数化可视化，可生成反应音频的视频，引入了“过渡”和“保持”的设计模式，能够产生高度表现力并适用于专业人员。

    

    视觉是音乐体验的核心组成部分，因为它们可以放大音乐传达的情感和信息。然而，创造音乐可视化是一个复杂、耗时和资源密集的过程。我们介绍了Generative Disco，一个生成式人工智能系统，利用大型语言模型和文本到图像模型帮助生成音乐可视化。用户选择要可视化的音乐间隔，然后通过定义开始和结束提示来参数化该可视化。这些提示根据音乐的节奏进行变形和生成，以产生反应音频的视频。我们介绍了改进生成视频的设计模式：“过渡”，表达颜色、时间、主题或风格的变化，“保持”，鼓励视觉重点和一致性。专业人员参与的研究表明，该系统具有愉悦性、易于探索和高度表现力。我们总结了Generative Disco在专业人士中的应用案例以及AI生成内容与版权的联系。

    Visuals are a core part of our experience of music, owing to the way they can amplify the emotions and messages conveyed through the music. However, creating music visualization is a complex, time-consuming, and resource-intensive process. We introduce Generative Disco, a generative AI system that helps generate music visualizations with large language models and text-to-image models. Users select intervals of music to visualize and then parameterize that visualization by defining start and end prompts. These prompts are warped between and generated according to the beat of the music for audioreactive video. We introduce design patterns for improving generated videos: "transitions", which express shifts in color, time, subject, or style, and "holds", which encourage visual emphasis and consistency. A study with professionals showed that the system was enjoyable, easy to explore, and highly expressive. We conclude on use cases of Generative Disco for professionals and how AI-generated c
    
[^103]: Dice半度量损失函数：用软标签优化Dice分数

    Dice Semimetric Losses: Optimizing the Dice Score with Soft Labels. (arXiv:2303.16296v1 [cs.CV])

    [http://arxiv.org/abs/2303.16296](http://arxiv.org/abs/2303.16296)

    本文提出的Dice半度量损失函数可在软标签设置中使用，在医疗成像领域的分割方案中与使用软标签的研究相结合，可以获得更好的Dice分数和模型校准。

    

    在医学成像领域的许多自动分割方案中，软Dice损失（SDL）发挥了关键作用。在过去几年中，人们已经揭示了其优越性能背后的一些原因并进一步探索了其优化。然而，目前还没有实现支持直接在软标签设置中使用它的方案。因此，在使用SDL和研究利用软标签的同时进行模型校准的协同作用仍然缺失。在本文中，我们介绍了Dice半度量损失函数（DMLs），它们（i）在硬标签的标准设置下与SDL相同，但（ii）也可在软标签设置中使用。我们在公共的QUBIQ、LiTS和KiTS基准测试上的实验证实了DMLs与软标签（如平均、标签平滑和知识蒸馏）的潜在协同作用，而DMLs与硬标签（如大多数投票和随机选择）相比，产生了更优秀的Dice分数和模型校准。

    The soft Dice loss (SDL) has taken a pivotal role in many automated segmentation pipelines in the medical imaging community. Over the last years, some reasons behind its superior functioning have been uncovered and further optimizations have been explored. However, there is currently no implementation that supports its direct use in settings with soft labels. Hence, a synergy between the use of SDL and research leveraging the use of soft labels, also in the context of model calibration, is still missing. In this work, we introduce Dice semimetric losses (DMLs), which (i) are by design identical to SDL in a standard setting with hard labels, but (ii) can be used in settings with soft labels. Our experiments on the public QUBIQ, LiTS and KiTS benchmarks confirm the potential synergy of DMLs with soft labels (e.g. averaging, label smoothing, and knowledge distillation) over hard labels (e.g. majority voting and random selection). As a result, we obtain superior Dice scores and model calib
    
[^104]: Tubelet-对比自监督方法用于视频高效泛化

    Tubelet-Contrastive Self-Supervision for Video-Efficient Generalization. (arXiv:2303.11003v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2303.11003](http://arxiv.org/abs/2303.11003)

    该论文提出了Tubelet-对比自监督方法，通过在局部运动动态相同但外观不同的视频之间学习相似性，引入超出预训练数据中存在的运动模式来学习高效的视频表示。实验证明该方法在使用仅25％的预训练视频时仍能保持性能，并在多个下游任务中具有竞争力和一定的泛化能力。

    

    我们提出了一种自监督方法来学习以运动为重点的视频表示。现有方法通过最小化时间增强的视频之间的距离来保持高空间相似性。相反，我们提出通过在局部运动动态相同但外观不同的视频之间学习相似性来实现。我们在视频中添加了合成的运动轨迹，称之为tubelets，通过模拟不同的tubelet运动并应用缩放和旋转等变换，引入了超出预训练数据中存在的运动模式。这使我们能够学习出一种数据效率显著的视频表示：我们的方法在使用仅25％的预训练视频时仍能保持性能。在10个不同的下游设置上的实验证明了我们竞争力强的性能和对新领域和细粒度动作的泛化能力。

    We propose a self-supervised method for learning motion-focused video representations. Existing approaches minimize distances between temporally augmented videos, which maintain high spatial similarity. We instead propose to learn similarities between videos with identical local motion dynamics but an otherwise different appearance. We do so by adding synthetic motion trajectories to videos which we refer to as tubelets. By simulating different tubelet motions and applying transformations, such as scaling and rotation, we introduce motion patterns beyond what is present in the pretraining data. This allows us to learn a video representation that is remarkably data efficient: our approach maintains performance when using only 25\% of the pretraining videos. Experiments on 10 diverse downstream settings demonstrate our competitive performance and generalizability to new domains and fine-grained actions.
    
[^105]: EvCenterNet: 使用证据学习进行目标检测的不确定性估计

    EvCenterNet: Uncertainty Estimation for Object Detection using Evidential Learning. (arXiv:2303.03037v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2303.03037](http://arxiv.org/abs/2303.03037)

    EvCenterNet是一种使用证据学习进行目标检测的不确定性感知框架，可以直接估计分类和回归的不确定性，并通过关注最不确定的点来改善检测性能。模型在KITTI数据集和其他具有挑战性的数据集上进行了评估。

    

    在安全关键的场景中，不确定性估计对于自动驾驶等任务至关重要，因为它为高级决策和路径规划等多个下游任务提供了宝贵的信息。在本文中，我们提出了EvCenterNet，一种新颖的不确定性感知的二维目标检测框架，使用证据学习直接估计分类和回归的不确定性。为了应用证据学习进行目标检测，我们设计了一种证据和焦点损失函数的组合，用于稀疏热图输入。我们引入了类平衡权重来处理证据学习中遇到的类不平衡问题。此外，我们提出了一种学习策略，通过重点关注最不确定的点来利用预测的热图不确定性来改善检测性能。我们在KITTI数据集上训练模型，并在包括BDD100K和nuImages在内的具有挑战性的分布外数据集上进行评估。

    Uncertainty estimation is crucial in safety-critical settings such as automated driving as it provides valuable information for several downstream tasks including high-level decision making and path planning. In this work, we propose EvCenterNet, a novel uncertainty-aware 2D object detection framework using evidential learning to directly estimate both classification and regression uncertainties. To employ evidential learning for object detection, we devise a combination of evidential and focal loss functions for the sparse heatmap inputs. We introduce class-balanced weighting for regression and heatmap prediction to tackle the class imbalance encountered by evidential learning. Moreover, we propose a learning scheme to actively utilize the predicted heatmap uncertainties to improve the detection performance by focusing on the most uncertain points. We train our model on the KITTI dataset and evaluate it on challenging out-of-distribution datasets including BDD100K and nuImages. Our ex
    
[^106]: 关于形态信息在上下文词形还原中的作用

    On the Role of Morphological Information for Contextual Lemmatization. (arXiv:2302.00407v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.00407](http://arxiv.org/abs/2302.00407)

    本文研究了形态信息在六种语言的上下文词形还原器开发中的作用，并对词形还原器进行了领域外性能评估。

    

    词形还原是一项自然语言处理的任务，它包括从给定的屈折词生成其规范形式或词形还原。词形还原是简化下游自然语言处理应用的基本任务之一，对于高度屈折语言尤为重要。虽然根据屈折词获得词形还原形式的过程可以通过考虑其形态句法类别来解释，但在训练上下文词形还原器时引入细粒度的形态句法信息已经成为常见做法，而无视下游绩效是否优化。为了解决这个问题，本文实证研究了在六种语言中考察形态信息在上下文词形还原器开发中的作用，这六种语言的形态复杂性各不相同，包括巴斯克语、土耳其语、俄语、捷克语、西班牙语和英语。此外，与绝大多数先前的工作不同，我们还在领域外环境中进行了词形还原器的评估。

    Lemmatization is a natural language processing (NLP) task which consists of producing, from a given inflected word, its canonical form or lemma. Lemmatization is one of the basic tasks that facilitate downstream NLP applications, and is of particular importance for high-inflected languages. Given that the process to obtain a lemma from an inflected word can be explained by looking at its morphosyntactic category, including fine-grained morphosyntactic information to train contextual lemmatizers has become common practice, without considering whether that is the optimum in terms of downstream performance. In order to address this issue, in this paper we empirically investigate the role of morphological information to develop contextual lemmatizers in six languages within a varied spectrum of morphological complexity: Basque, Turkish, Russian, Czech, Spanish and English. Furthermore, and unlike the vast majority of previous work, we also evaluate lemmatizers in out-of-domain settings, wh
    
[^107]: 预测是否随意？在公平分类中评估自洽性

    Is My Prediction Arbitrary? Measuring Self-Consistency in Fair Classification. (arXiv:2301.11562v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.11562](http://arxiv.org/abs/2301.11562)

    在公平分类中，模型的预测方差是一个重要但鲜为人知的误差来源问题。作者提出了一个自洽性标准来衡量测量和减少随意性。作者还开发了一个算法来处理随意性预测，并通过实证研究揭示了当前模型无法处理某些类型数据的问题。

    

    在公平分类中，不同经过训练的模型之间的预测方差是一个重要但鲜为人知的误差来源问题。 实证表明，某些情况下，预测的方差差异非常大，以至于决策实际上是随意的。 为了研究这个问题，我们进行了大规模的实证研究，并做出了四个总体贡献：我们1）定义了一种基于方差的度量标准，称为自洽性，在测量和减少随意性时使用； 2）开发了一种合理的算法，当预测无法做出决策时，可以放弃分类； 3）进行了迄今为止有关公平分类中方差（相对于自洽性和随意性）作用的最大规模实证研究； 4）推出了一个工具包，使美国住房抵押贷款披露法案（HMDA）数据集易于用于未来研究。 总的来说，我们的实证结果揭示了关于可重复性的令人震惊的见解。当考虑到方差和随意预测的可能性时，大多数公平分类基准接近公平。 但是，一小部分实例显示出极大的随意性水平，这表明当前的模型可能无法处理某些类型的数据。

    Variance in predictions across different trained models is a significant, under-explored source of error in fair classification. Empirically, the variance on some instances is so large that decisions can be effectively arbitrary. To study this problem, we perform a large-scale empirical study and make four overarching contributions: We 1) Define a metric called self-consistency, derived from variance, which we use as a proxy for measuring and reducing arbitrariness; 2) Develop an ensembling algorithm that abstains from classification when a prediction would be arbitrary; 3) Conduct the largest to-date empirical study of the role of variance (vis-a-vis self-consistency and arbitrariness) in fair classification; and, 4) Release a toolkit that makes the US Home Mortgage Disclosure Act (HMDA) datasets easily usable for future research. Altogether, our empirical results reveal shocking insights about reproducibility. Most fairness classification benchmarks are close-to-fair when taking into
    
[^108]: 垂直联合学习：概念、进展和挑战

    Vertical Federated Learning: Concepts, Advances and Challenges. (arXiv:2211.12814v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.12814](http://arxiv.org/abs/2211.12814)

    垂直联合学习（VFL）是一种联合学习设置，多个具有关于同一组用户不同特征的参与方共同训练机器学习模型，而不公开原始数据或模型参数。本文提供了对VFL概念、算法以及各个方面的进展和挑战的综合回顾，深入分析了隐私保护协议的分类、隐私攻击和防御策略，并提出了考虑多个约束条件的统一框架VFLow。此外，还回顾了工业应用中的最新进展和VFL面临的未来挑战和方向。

    

    垂直联合学习（VFL）是一种联合学习设置，多个具有关于同一组用户不同特征的参与方共同训练机器学习模型，而不公开原始数据或模型参数。受VFL研究和实际应用的快速增长的推动，我们全面回顾了VFL的概念和算法，以及各个方面的当前进展和挑战，包括有效性、效率和隐私。我们提供了对VFL设置和隐私保护协议的详尽分类，并对每个协议的隐私攻击和防御策略进行了全面分析。最后，我们提出了一个统一的框架，称为VFLow，它考虑了VFL问题在通信、计算、隐私以及有效性和公平性约束下的情况。最后，我们回顾了工业应用中最新的进展，突出了VFL面临的开放性挑战和未来方向。

    Vertical Federated Learning (VFL) is a federated learning setting where multiple parties with different features about the same set of users jointly train machine learning models without exposing their raw data or model parameters. Motivated by the rapid growth in VFL research and real-world applications, we provide a comprehensive review of the concept and algorithms of VFL, as well as current advances and challenges in various aspects, including effectiveness, efficiency, and privacy. We provide an exhaustive categorization for VFL settings and privacy-preserving protocols and comprehensively analyze the privacy attacks and defense strategies for each protocol. In the end, we propose a unified framework, termed VFLow, which considers the VFL problem under communication, computation, privacy, as well as effectiveness and fairness constraints. Finally, we review the most recent advances in industrial applications, highlighting open challenges and future directions for VFL.
    
[^109]: 负责任的AI模式目录：AI治理与工程的最佳实践集合

    Responsible AI Pattern Catalogue: A Collection of Best Practices for AI Governance and Engineering. (arXiv:2209.04963v4 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2209.04963](http://arxiv.org/abs/2209.04963)

    本文提出了一个负责任的AI模式目录，旨在从系统角度实现负责任的AI。与现有的伦理原则框架不同，该目录提供了实践中可采取的最佳实践，并涵盖了AI系统开发生命周期的各个阶段。

    

    负责任的AI被广泛认为是我们时代最重要的科学挑战之一，也是增加AI采用的关键。最近，许多AI伦理原则框架已经发布。然而，缺乏进一步的最佳实践指导，从业者们除了空洞的词句之外没有太多东西可依靠。此外，现有的努力更多地集中在算法层面上，而不是系统层面上，主要关注一些符合数学原则的伦理问题，如公平性。然而，伦理问题可能在开发生命周期的任何阶段出现，涉及多个AI和非AI系统组件。为了从系统角度实现负责任的AI，本文基于多声音文献综述的结果，提出了一个负责任的AI模式目录。我们的关注点不仅仅停留在原则和算法层面上，而是聚焦于AI系统利益相关者在实践中可以采取的模式，以确保

    Responsible AI is widely considered as one of the greatest scientific challenges of our time and is key to increase the adoption of AI. Recently, a number of AI ethics principles frameworks have been published. However, without further guidance on best practices, practitioners are left with nothing much beyond truisms. Also, significant efforts have been placed at algorithm-level rather than system-level, mainly focusing on a subset of mathematics-amenable ethical principles, such as fairness. Nevertheless, ethical issues can arise at any step of the development lifecycle, cutting across many AI and non-AI components of systems beyond AI algorithms and models. To operationalize responsible AI from a system perspective, in this paper, we present a Responsible AI Pattern Catalogue based on the results of a Multivocal Literature Review (MLR). Rather than staying at the principle or algorithm level, we focus on patterns that AI system stakeholders can undertake in practice to ensure that t
    
[^110]: 量子自注意力神经网络用于文本分类

    Quantum Self-Attention Neural Networks for Text Classification. (arXiv:2205.05625v2 [quant-ph] UPDATED)

    [http://arxiv.org/abs/2205.05625](http://arxiv.org/abs/2205.05625)

    本论文提出了一种名为量子自注意力神经网络（QSANN）的简单网络架构，通过将自注意机制引入到量子神经网络中，并利用高斯投影的量子自注意力，弥补了现有量子自然语言处理方法的一些限制。QSANN在更大规模的数据集上具有有效和可扩展的性能，并且可以在近期量子设备上实现。

    

    量子计算的一个新兴方向是在包括自然语言处理在内的人工智能各个领域建立有意义的量子应用。尽管基于句法分析的一些工作为量子自然语言处理研究打开了大门，但是诸如繁重的句法预处理和句法相关的网络结构等限制使得它们在更大规模和实际数据集上不可行。在本文中，我们提出了一种新的简单网络架构，称为量子自注意力神经网络（QSANN），可以弥补这些限制。具体而言，我们将自注意机制引入到量子神经网络中，然后利用高斯投影的量子自注意力作为自注意力的量子版本。结果表明，QSANN在更大规模的数据集上具有有效和可扩展的性能，并且具有在近期量子设备上可实现的理想性质。特别地，我们的QSANN优于最佳的现有模型。

    An emerging direction of quantum computing is to establish meaningful quantum applications in various fields of artificial intelligence, including natural language processing (NLP). Although some efforts based on syntactic analysis have opened the door to research in Quantum NLP (QNLP), limitations such as heavy syntactic preprocessing and syntax-dependent network architecture make them impracticable on larger and real-world data sets. In this paper, we propose a new simple network architecture, called the quantum self-attention neural network (QSANN), which can compensate for these limitations. Specifically, we introduce the self-attention mechanism into quantum neural networks and then utilize a Gaussian projected quantum self-attention serving as a sensible quantum version of self-attention. As a result, QSANN is effective and scalable on larger data sets and has the desirable property of being implementable on near-term quantum devices. In particular, our QSANN outperforms the best
    

