# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Learning with Explanation Constraints.](http://arxiv.org/abs/2303.14496) | 本文研究了解释约束下的学习问题，提出了EPAC模型，探讨了使用这些解释时模型的益处，并提供了一种基于变分近似的算法解决方案。 |
| [^2] | [GANTEE: Generative Adversatial Network for Taxonomy Entering Evaluation.](http://arxiv.org/abs/2303.14480) | GANTEE 是一种用于分类法添加评估的生成对抗网络，通过使用生成对抗网络和新的综合数据生成方法，它具有比其他先前方法更高效和更有效的性能。 |
| [^3] | [Informed Machine Learning, Centrality, CNN, Relevant Document Detection, Repatriation of Indigenous Human Remains.](http://arxiv.org/abs/2303.14475) | 本篇研究介绍了研发出一个机器学习系统的进展, 该系统可以自动查找并语义分析相关文献,以协助土著人类寻找其被盗窃、捐赠、出售或在机构之间交换的遗骸信息。 |
| [^4] | [3Mformer: Multi-order Multi-mode Transformer for Skeletal Action Recognition.](http://arxiv.org/abs/2303.14474) | 3Mformer是一种多阶多模变形器，通过形成超图捕捉身体关节组的高阶运动模式，使得在骨骼动作识别方面表现优于现有最先进的模型 |
| [^5] | [A Survey on the Densest Subgraph Problem and its Variants.](http://arxiv.org/abs/2303.14467) | 本调查全面介绍了稠密子图问题及其变种，在讨论最新结果的同时，还提出了应用广泛的开放性问题。 |
| [^6] | [Diverse Motion In-betweening with Dual Posture Stitching.](http://arxiv.org/abs/2303.14457) | 该论文提出一种针对只有第一帧和最后一帧的情况的多样化动作中间帧生成技术，通过使用双向方案和两个对抗的自回归网络，以及条件变分自动编码器进行拼接，实现了更高的运动质量和更多样化的结果。 |
| [^7] | [Federated Learning without Full Labels: A Survey.](http://arxiv.org/abs/2303.14453) | 本文综述了如何在联邦学习过程中利用无标注数据解决无全标签问题，并介绍了半监督学习、自监督学习和迁移学习等方法。同时还总结了用于评估这些方法的数据集和它们各自的优缺点。 |
| [^8] | [Design of a Smart Waste Management System for the City of Johannesburg.](http://arxiv.org/abs/2303.14436) | 本文旨在为南非约翰内斯堡市设计一种智能垃圾管理系统，以解决城市中日益增长的废弃物资源不足问题和垃圾管理不善所导致的环境、健康等问题。 |
| [^9] | [Beta-VAE has 2 Behaviors: PCA or ICA?.](http://arxiv.org/abs/2303.14430) | Beta-VAE模型的表示学习效果受潜在变量总量影响：使用少量潜在变量时表现为PCA，使用大量潜在变量时表现为ICA。 |
| [^10] | [Sem4SAP: Synonymous Expression Mining From Open Knowledge Graph For Language Model Synonym-Aware Pretraining.](http://arxiv.org/abs/2303.14425) | Sem4SAP利用开放知识图谱中挖掘到的同义词进行同义词感知预训练，扩展了同义词的应用范围，并提出两种新颖而有效的同义词感知预训练方法。实验结果表明，Sem4SAP可以显著提高模型质量。 |
| [^11] | [Better Aligning Text-to-Image Models with Human Preference.](http://arxiv.org/abs/2303.14420) | 研究者们收集了一个数据集，证明现有的生成模型评估指标与人类选择相关性不强。因此，他们使用这个数据集训练了一个人类偏好分类器，并通过HPS提出了一种方法以更好地将Stable Diffusion与人类审美偏好对齐。实验表明，该方法在预测人类选择方面优于CLIP，并具有良好的泛化能力。 |
| [^12] | [Fairness meets Cross-Domain Learning: a new perspective on Models and Metrics.](http://arxiv.org/abs/2303.14411) | 本研究针对基于深度学习的识别系统的公平性与跨领域学习问题进行了深入研究，提出了一个面向跨领域图像的基准和考虑公平性和准确性的新评估指标，并表明公平模型与不公平模型表现相似。 |
| [^13] | [IFSeg: Image-free Semantic Segmentation via Vision-Language Model.](http://arxiv.org/abs/2303.14396) | IFSeg提出了一种全新的无图像分割任务，能够在没有特定图像和注释的情况下执行语义分割，实现了基于视觉语言模型的人工图像分割对更新，取得了在多个基准数据集上的最先进表现，对未知类别和噪声鲁棒性强。 |
| [^14] | [DoNet: Deep De-overlapping Network for Cytology Instance Segmentation.](http://arxiv.org/abs/2303.14373) | 提出一种去重叠网络 DoNet，包含双路径区域分割模块和语义一致性引导的重新组合模块，以及掩模引导的区域建议策略；实验结果表明，DoNet在细胞学实例分割领域表现显著优于其他方法。 |
| [^15] | [FlexNeRF: Photorealistic Free-viewpoint Rendering of Moving Humans from Sparse Views.](http://arxiv.org/abs/2303.14368) | 本文提出了FlexNeRF方法，用于从单目视频中实现运动人体的真实自由视角渲染。通过对时间和姿态配置的优化以及额外的损失，可在观察视角变得更稀疏时提供高质量的输出，这在公开基准数据集以及自行捕获的时尚数据集上都表现出优越性。 |
| [^16] | [Heuristic Search for Multi-Objective Probabilistic Planning.](http://arxiv.org/abs/2303.14363) | 本文设计了新的启发式搜索算法MOLAO*和MOLRTDP，将众所周知的SSP算法扩展到了需要计算非支配策略的覆盖集的多目标随机最短路径(MOSSP)问题上，并构建了一系列与领域无关的启发式函数来指导搜索。 |
| [^17] | [Intelligent Load Balancing and Resource Allocation in O-RAN: A Multi-Agent Multi-Armed Bandit Approach.](http://arxiv.org/abs/2303.14355) | 本论文提出了一种多智能体多臂赌博机(mmLBRA)方法，用于实现O-RAN中的负载均衡和资源分配，以解决网络拥塞和用户故障问题。 |
| [^18] | [From G\"odel's Incompleteness Theorem to the completeness of bot religions (Extended abstract).](http://arxiv.org/abs/2303.14338) | 本文研究了从哥德尔不完备定理到机器人宗教的完备性的逻辑过程，提出了任何信仰系统可以被形式化为逻辑理论，并且不完备定理意味着存在真实但无法证明的陈述，可以用来定义出与现有信仰和传统一致的新宗教实践。 |
| [^19] | [GPU-accelerated Matrix Cover Algorithm for Multiple Patterning Layout Decomposition.](http://arxiv.org/abs/2303.14335) | 本文提出了一种GPU加速矩阵覆盖算法(GAMCA), 通过使用并行GPU矩阵操作替换CPU跳舞链数据结构，以加速解决基于精确覆盖的多重图案版式分解中的NP难问题。实验结果显示，GAMCA比最先进的算法快5-7倍，在24核机器上，比并行CPU算法快100倍。 |
| [^20] | [The Semantic Reader Project: Augmenting Scholarly Documents through AI-Powered Interactive Reading Interfaces.](http://arxiv.org/abs/2303.14334) | 本文探讨了利用人工智能和人机交互技术为研究论文提供智能、交互式和无障碍的阅读界面的可行性，并介绍了跨机构合作的语义阅读器项目。 |
| [^21] | [Train/Test-Time Adaptation with Retrieval.](http://arxiv.org/abs/2303.14333) | 该论文提出了一种采用检索方法的训练/测试时间自适应算法，该方法不仅使用合成数据增强，还利用检索的真实样本来提高模型适应性，并且可以让用户或服务提供商在部署后更新相关数据以改善模型适应性。 |
| [^22] | [Using Simple Incentives to Improve Two-Sided Fairness in Ridesharing Systems.](http://arxiv.org/abs/2303.14332) | 本论文提出了一种基于简单激励措施、可以在线实施的公平合理方案，通过整数线性规划来改善共享乘车系统中的双边公平性。 |
| [^23] | [Unsupervised Feature Selection to Identify Important ICD-10 Codes for Machine Learning: A Case Study on a Coronary Artery Disease Patient Cohort.](http://arxiv.org/abs/2303.14303) | 本研究比较了几种无监督特征选择方法，通过选择性能最佳的Concrete Autoencoder方法，成功识别出49,075例冠状动脉疾病患者数据库中的最佳100个特征，并证实Concrete Autoencoder方法中的权重调整能够提高其准确性。 |
| [^24] | [Learning to Operate in Open Worlds by Adapting Planning Models.](http://arxiv.org/abs/2303.14272) | 该论文提出了一种能够在开放环境中检测新奇性并快速适应其领域模型和行动选择的方法，具有解释性，表现良好。 |
| [^25] | [Towards Diverse and Coherent Augmentation for Time-Series Forecasting.](http://arxiv.org/abs/2303.14254) | 本研究提出了一种组合频谱和时间增强的方法，用于解决时间序列预测数据增强缺乏多样性和连贯性的问题。 |
| [^26] | [IDGI: A Framework to Eliminate Explanation Noise from Integrated Gradients.](http://arxiv.org/abs/2303.14242) | IDGI 提出了一种新的方法来减少 integrated gradients 解释显著性图中的噪声，并在众多可解释性指标上显著提高了解释性能。 |
| [^27] | [Causality Detection for Efficient Multi-Agent Reinforcement Learning.](http://arxiv.org/abs/2303.14227) | 本文研究了多智能体强化学习中一些代理无法理解他们在团队表现中的真实影响，导致学习次优策略，表现懒惰。通过因果关系检测惩罚懒惰代理并改善其行为，团队整体性能和每个代理的个体能力都得到了提升。 |
| [^28] | [Optimal Smoothing Distribution Exploration for Backdoor Neutralization in Deep Learning-based Traffic Systems.](http://arxiv.org/abs/2303.14197) | 该论文提出了一种在DRL基础的AVs中探索最佳平滑分布以消除后门攻击的方法，通过将噪声添加到输入中来中和攻击并实现更好的检测和防御。 |
| [^29] | [DeepEpiSolver: Unravelling Inverse problems in Covid, HIV, Ebola and Disease Transmission.](http://arxiv.org/abs/2303.14194) | DeepEpiSolver使用深度神经网络(DNN)作为逆问题求解器估计SIR模型的参数，相对于Physics Informed Neural Networks (PINNs)方法，其训练速度更快，且可以很好地推广到新的SIDR轨迹上，并在 COVID-19、HIV、埃博拉和疾病传播方面取得验证性结果。 |
| [^30] | [Improved Adversarial Training Through Adaptive Instance-wise Loss Smoothing.](http://arxiv.org/abs/2303.14077) | 本文提出了一种新的对抗训练方法(Instance-adaptive Adversarial Training, IAAT)通过平滑实例级别的对抗性损失，鼓励模型关注“难”的样本，同时避免牺牲特定的样本而偏爱其他样本，取得了在各种数据集下的最新、最佳结果，并在白盒和黑盒攻击下均优于以前的方法。 |
| [^31] | [Physical Backdoor Trigger Activation of Autonomous Vehicle using Reachability Analysis.](http://arxiv.org/abs/2303.13992) | 本研究的方法通过可达性分析识别出自动驾驶汽车可能被物理触发器激活的危险区域和可达路径，测试结果显示成功率接近100％。这将有助于发现AV的漏洞并实施有效的安全策略。 |
| [^32] | [Edge-free but Structure-aware: Prototype-Guided Knowledge Distillation from GNNs to MLPs.](http://arxiv.org/abs/2303.13763) | 本文提出了一种原型引导知识蒸馏（PGKD）方法，它不需要图形边缘，但可以在不考虑边缘的情况下学习结构感知的MLP。 |
| [^33] | [Artificial Intelligence for Sustainability: Facilitating Sustainable Smart Product-Service Systems with Computer Vision.](http://arxiv.org/abs/2303.13540) | 本论文在可持续性方面的主要贡献是使用深度学习技术提高产品生产和使用的可持续性，通过计算机视觉技术检测产品的磨损状态并用于改进智能产品-服务系统的集成和结果取向。 |
| [^34] | [DreamBooth3D: Subject-Driven Text-to-3D Generation.](http://arxiv.org/abs/2303.13508) | DreamBooth3D是一种可从3-6张图片中生成主体特定3D素材的方法，通过结合文本到图像模型和文本到3D生成模型，使用一种三阶段的优化策略来产生高质量3D素材。 |
| [^35] | [Fairness-guided Few-shot Prompting for Large Language Models.](http://arxiv.org/abs/2303.13217) | 本文提出了一种新的搜索策略-FairPrompt，在保证公正性的前提下，通过评估提示预测偏差，确定近似最优的提示，从而改进大型语言模型的上下文学习性能，实验表明该方法在准确性和公正性方面均优于现有方法。 |
| [^36] | [MagicFusion: Boosting Text-to-Image Generation Performance by Fusing Diffusion Models.](http://arxiv.org/abs/2303.13126) | 本论文提出了一种名为SNB的方法，该方法集成了两个文本指导扩散模型的噪声预测，以实现更可控的图像生成，同时不需要额外的训练或注释。 |
| [^37] | [SPeC: A Soft Prompt-Based Calibration on Mitigating Performance Variability in Clinical Notes Summarization.](http://arxiv.org/abs/2303.13035) | 研究通过引入软提示嵌入，提出Soft Prompt-Based Calibration (SPeC)管道，来减轻输入变量对输出多样性的影响，降低性能变异. 此方法不仅比大语言模型(LLM)性能稳定，而且在临床笔记摘要任务上表现优于最先进的模型. |
| [^38] | [The Shaky Foundations of Clinical Foundation Models: A Survey of Large Language Models and Foundation Models for EMRs.](http://arxiv.org/abs/2303.12961) | 本论文回顾了超过80个在非成像 EMR 数据上训练的基础模型，发现这些模型大多范围有限、训练集有限，且评估指标未对其对医疗系统贡献提供有意义见解。因此，本研究提出了一种更接近于医疗保健重要指标的医疗基础模型效益评估框架。 |
| [^39] | [Are LLMs the Master of All Trades? : Exploring Domain-Agnostic Reasoning Skills of LLMs.](http://arxiv.org/abs/2303.12810) | 本文探究了大型语言模型(LLM)在不同领域推理任务上的表现，并发现LLM在类比和道德推理方面表现出色，在空间推理任务上表现较差。这对于LLM未来的发展具有重要意义。 |
| [^40] | [Democratising AI: Multiple Meanings, Goals, and Methods.](http://arxiv.org/abs/2303.12642) | 这篇论文探讨了AI的民主化，包括四种类型的民主化：AI使用的民主化，AI开发的民主化，AI利润的民主化，和AI治理的民主化。要想实现有效的政策和权衡讨论，需要认识到AI治理的民主化在决策中扮演着重要的角色。 |
| [^41] | [Reveal to Revise: An Explainable AI Life Cycle for Iterative Bias Correction of Deep Models.](http://arxiv.org/abs/2303.12641) | 本文提出一个可解释的AI生命周期框架（R2R），允许从业者逐步识别、减少和重新评估深度学习模型数据偏差，包括寻找异常值、检测负责的文物、空间定位和修改模型的行为。 |
| [^42] | [$P^{3}O$: Transferring Visual Representations for Reinforcement Learning via Prompting.](http://arxiv.org/abs/2303.12371) | 本论文提出一种名为$P^{3}O$的三阶段DRL算法，通过提问来转移视觉表示，显著优于现有的视觉传输方案。 |
| [^43] | [Self-Correctable and Adaptable Inference for Generalizable Human Pose Estimation.](http://arxiv.org/abs/2303.11180) | 本文提出了可自我修正和自适应推理的通用人体姿态估计方法，通过学习一个校正网络和健康反馈网络来解决网络预测的泛化挑战。 |
| [^44] | [Rotating without Seeing: Towards In-hand Dexterity through Touch.](http://arxiv.org/abs/2303.10880) | 本研究提出了一种新系统Touch Dexterity，通过密集二进制力传感器实现了多指机器人手不看就能旋转物体，同时大大降低了成本和与实际应用的差距。 |
| [^45] | [Among Us: Adversarially Robust Collaborative Perception by Consensus.](http://arxiv.org/abs/2303.09495) | ROBOSAC提出了一种基于共识的反对抗鲁棒协同感知防御策略，使用随机子集的队友来对比协同感知和单个感知的结果，以排除潜在攻击者，并推导出确保获得所需无攻击者子集所需的采样试验个数。 |
| [^46] | [GPT-4 Technical Report.](http://arxiv.org/abs/2303.08774) | GPT-4是一个大规模多模态模型，可以接收图像和文本输入并产生文本输出，能够在各种专业和学术基准测试中表现出人类水平的表现，包括通过模拟的律师考试。该项目的核心组件是开发基础设施和优化方法，可在广泛的规模范围内表现预测性。 |
| [^47] | [NL4Opt Competition: Formulating Optimization Problems Based on Their Natural Language Descriptions.](http://arxiv.org/abs/2303.08233) | NL4Opt比赛旨在研究如何从自然语言描述中提取出优化问题的含义和表述，并通过自然语言与非专业人士进行交互。竞赛分为两个子任务：(1) 识别和标记对应于优化问题组件的语义实体;(2)从检测到的问题实体生成意义表示(即逻辑形式)。 |
| [^48] | [MEDBERT.de: A Comprehensive German BERT Model for the Medical Domain.](http://arxiv.org/abs/2303.08179) | 本文介绍了medBERT.de，这是一个用于德语医学领域的BERT模型，通过在大规模语料库上的训练，在八个不同的医学基准测试中取得最新的最先进的表现。该模型对长文本特别有用，而数据去重和有效的分词则只对模型性能产生了较小的影响。 |
| [^49] | [Audio Visual Language Maps for Robot Navigation.](http://arxiv.org/abs/2303.07522) | 该论文提出了一种音视语言地图(AVLMaps)，用于存储跨模态信息，实现机器人根据多模态查询在地图中索引目标的导航方式。在模拟实验中，AVLMaps实现了从多模态提示的零次学习式多模态目标导航，并提供了更好的召回率。 |
| [^50] | [Parachute: Evaluating Interactive Human-LM Co-writing Systems.](http://arxiv.org/abs/2303.06333) | 本文提出了一个以人为中心的评估框架Parachute，用于交互式共同撰写系统的评估，该框架包含了分类的实用指标，可以用于评估和比较共同撰写系统。 |
| [^51] | [Zone-based Federated Learning for Mobile Sensing Data.](http://arxiv.org/abs/2303.06246) | 本文提出了一种基于区域的联邦学习方法，用于训练移动感知数据的深度学习模型。该方法将物理空间划分为地理区域，并映射到移动边缘云系统架构，以实现良好的模型准确性和可扩展性。每个区域都有一个联合训练模型，能够很好地适应该区域用户的数据和行为，并保护用户数据隐私。 |
| [^52] | [Complement Sparsification: Low-Overhead Model Pruning for Federated Learning.](http://arxiv.org/abs/2303.06237) | 本文提出了一种名为补充稀疏化的模型剪枝机制，通过在服务器和客户端之间进行互补和协作的剪枝来满足联邦学习中低双向通信开销、客户端低计算开销和良好模型准确性的要求。 |
| [^53] | [Complexity and scalability of defeasible reasoning in many-valued weighted knowledge bases with typicality.](http://arxiv.org/abs/2303.04534) | 本文提出了一种基于典型性描述逻辑的加权知识库的推理方法，通过提供新的ASP编码填补现有研究的不足，复杂性项的理论分析推导了经典问题 $P^{NP[log]}$-完备性结果。 |
| [^54] | [Model-Agnostic Meta-Learning for Natural Language Understanding Tasks in Finance.](http://arxiv.org/abs/2303.02841) | 本文研究了金融领域自然语言理解任务中的模型无关元学习算法，取得了最先进的性能表现。 |
| [^55] | [AI and the FCI: Can ChatGPT Project an Understanding of Introductory Physics?.](http://arxiv.org/abs/2303.01067) | 本研究以力学概念库评估了ChatGPT3.5和ChatGPT4在大学第一学期物理学领域的表现，结果显示ChatGPT3.5可以在某些方面匹配或超过传统教学的中位数表现。 |
| [^56] | [Distributed Subweb Specifications for Traversing the Web.](http://arxiv.org/abs/2302.14411) | 本文提出了一种分布式子网规范的 LTQP 方法，该方法通过让数据发布者能够建议查询来源以及引导数据使用者向相关且可靠的数据查询，解决了 LTQP 存在的性能和信息质量问题。 |
| [^57] | [Linear Spaces of Meanings: Compositional Structures in Vision-Language Models.](http://arxiv.org/abs/2302.14383) | 本文研究了视觉语言模型中的组合结构，并提出了一种使用嵌入空间中较小集合的向量组合来近似表示来自编码器的表示形式的方法，将这些向量视为“理想单词”，并在CLIP的嵌入中以实验方式探索了这些结构的可用性。 |
| [^58] | [Im2Hands: Learning Attentive Implicit Representation of Interacting Two-Hand Shapes.](http://arxiv.org/abs/2302.14348) | 本文提出了Im2Hands，一个用于表示交互双手的神经隐式表示方法，可以产生高手到手和手到图像一致性的细粒度几何形态。 |
| [^59] | [VoxFormer: Sparse Voxel Transformer for Camera-based 3D Semantic Scene Completion.](http://arxiv.org/abs/2302.12251) | VoxFormer是一个基于变换器的语义场景补全框架，可以仅从2D图像输出完整的三维体积语义。它采用两阶段设计，从可见的体素查询开始，并通过自我注意来传播信息，实现了有效的三维场景补全。 |
| [^60] | [HumanMAC: Masked Motion Completion for Human Motion Prediction.](http://arxiv.org/abs/2302.03665) | HumanMAC是一个掩码动作修复框架，通过训练阶段的运动扩散模型和推断阶段的去噪过程，在观察到的运动数据的控制下进行运动预测，并在多个基准数据集上展示了显著的改进。 |
| [^61] | [ESC: Exploration with Soft Commonsense Constraints for Zero-shot Object Navigation.](http://arxiv.org/abs/2301.13166) | 本文提出了一种新颖的零样本物体导航方法 ESC，它从预先训练的视觉和自然语言处理模型中转移常识知识，可在未知环境中进行导航，具有广阔的应用前景。 |
| [^62] | [Identifying Adversarially Attackable and Robust Samples.](http://arxiv.org/abs/2301.12896) | 本文提出了一种深度学习方法，用于检测哪些样本最容易受到对抗性攻击，从而确定哪些样本最不容易受到攻击。实验结果表明，这种检测器在不同的模型结构中具有较好的可移植性和检测性能。 |
| [^63] | [Editing Language Model-based Knowledge Graph Embeddings.](http://arxiv.org/abs/2301.10405) | 本文提出了一种新的任务——编辑基于语言模型的知识图谱嵌入，旨在实现对KG嵌入的数据高效和快速更新。针对这一任务，提出了一个简单而强大的方案——KGEditor，可以更好地更新特定事实而不影响其余部分的性能。 |
| [^64] | [Open-World Multi-Task Control Through Goal-Aware Representation Learning and Adaptive Horizon Prediction.](http://arxiv.org/abs/2301.10034) | 该论文提出了一种解决多任务控制中面临的开放世界挑战的新方法，即通过Goal-Sensitive Backbone鼓励出现与目标相关的视觉状态表示，并通过自适应视野预测模块来减轻非静态动态引起的学习不确定性。 |
| [^65] | [PIRLNav: Pretraining with Imitation and RL Finetuning for ObjectNav.](http://arxiv.org/abs/2301.07302) | 本文提出了PIRLNav，通过人类演示的BC预训练和RL微调两个阶段的学习方案，成功率达到ObjectNav的65.0％，比以前的最新技术高5.0％。 |
| [^66] | [Towards Scalable Physically Consistent Neural Networks: an Application to Data-driven Multi-zone Thermal Building Models.](http://arxiv.org/abs/2212.12380) | 本论文研究了物理一致神经网络(PCNNs) 在模拟建筑温度动态方面的扩展性和准确性。结果发现，PCNNs既确保了物理一致性，同时又能在复杂的多区域热建筑模型中取得高精度的性能表现，且在可用数据量有限的情况下超越经典灰盒模型，具有可扩展性优势。 |
| [^67] | [On Calibrating Semantic Segmentation Models: Analyses and An Algorithm.](http://arxiv.org/abs/2212.12053) | 本文系统研究了语义分割模型的校准问题，提出了一种简单而有效的方法——选择性缩放，通过将正确/错误预测分开进行缩放，并更加关注错误预测的逻辑平滑，此方法在语义分割校准上取得了良好效果。 |
| [^68] | [RepMode: Learning to Re-parameterize Diverse Experts for Subcellular Structure Prediction.](http://arxiv.org/abs/2212.10066) | 本文提出了RepMode，一种网络，利用任务感知的先验动态组织其参数以处理亚细胞结构预测等指定的单标签预测任务。 |
| [^69] | [Expanding Knowledge Graphs with Humans in the Loop.](http://arxiv.org/abs/2212.05189) | 本文提出了一种与人类互动的方法扩展知识图谱，通过预测新概念的“父母”，然后由人类专家进一步验证。该方法能够保证预测的父母距离概念的真实父母“近”，能够提高人算协作的速度和准确性，并在新闻和娱乐领域的真实数据集上得到了验证。 |
| [^70] | [Fine-tuned CLIP Models are Efficient Video Learners.](http://arxiv.org/abs/2212.03640) | 本文提出了一个简单的视频细调CLIP（ViFi-CLIP）基线，通过从CLIP图像编码器的帧级处理，接着进行特征池化和与相应文本嵌入的相似度匹配，有效地将图像级别的CLIP表示转移到视频中，从而弥合了从图像到视频的领域差距。 |
| [^71] | [Diffusion Video Autoencoders: Toward Temporally Consistent Face Video Editing via Disentangled Video Encoding.](http://arxiv.org/abs/2212.02802) | 本文提出了一种基于扩散自编码器的面部视频编辑框架，可以从给定的视频中提取出分解的特征，实现简单的特征调整来确保时间上的一致性。与现有的基于GAN的方法不同，该模型同时满足重建和编辑能力，并且对受野外面部视频的角落情况具有鲁棒性。 |
| [^72] | [Optimizing Explanations by Network Canonization and Hyperparameter Search.](http://arxiv.org/abs/2211.17174) | 这篇论文介绍了新的解释人工智能方法，通过网络规范化和超参数搜索来提高解释效果。 |
| [^73] | [Shifted Diffusion for Text-to-image Generation.](http://arxiv.org/abs/2211.15388) | 本文提出了一种新的文本到图像生成方法，使用Shifted Diffusion模型更好地生成来自输入文本的图像嵌入，并通过大量实验和评估证明了其在效率和有效性方面的优势，同时支持半监督和无语言训练。 |
| [^74] | [Multi-Modal Few-Shot Temporal Action Detection.](http://arxiv.org/abs/2211.14905) | 提出了一个新的多模态少样本时间动作检测问题，针对这个问题提出了一个新的 MUPPET 方法，通过在视觉-语言模型中构建多模态提示，并使用多模态聚类算法来组合时序连续的片段，解决了问题。在少样本和零样本场景下表现出了优越性，并验证了不同组件的有效性。 |
| [^75] | [On Designing Light-Weight Object Trackers through Network Pruning: Use CNNs or Transformers?.](http://arxiv.org/abs/2211.13769) | 本文介绍了如何通过神经网络结构剪枝技术设计压缩版的高度压缩轻量级物体跟踪器。通过对CNN和Transformers跟踪器的比较研究，揭示出在设计轻量级跟踪器时的最佳架构选择。最后，提供了极端剪枝率的跟踪结果，可能有助于更好地了解网络剪枝在物体跟踪中的限制。 |
| [^76] | [Visually Grounded Commonsense Knowledge Acquisition.](http://arxiv.org/abs/2211.12054) | 本文介绍了CLEVER，一种以视觉-语言预训练模型为基础的常识知识提取方法，通过包含有关实体对的图像包汇总出常识关系，避免了对图像实例进行人工注释的问题。 |
| [^77] | [Minimizing the Accumulated Trajectory Error to Improve Dataset Distillation.](http://arxiv.org/abs/2211.11004) | 通过新增损失项最小化累积轨迹误差，从而提高数据集精炼效果，并且在多种数据集和网络架构上的实验证明该方法优于当前最先进的方法。 |
| [^78] | [Fraudulent User Detection Via Behavior Information Aggregation Network (BIAN) On Large-Scale Financial Social Network.](http://arxiv.org/abs/2211.06315) | 本文提出了一款新颖的行为信息聚合网络（BIAN），可以同时考虑用户的个人资料、行为以及社交联系，以有效检测金融欺诈。 |
| [^79] | [DynamicISP: Dynamically Controlled Image Signal Processor for Image Recognition.](http://arxiv.org/abs/2211.01146) | DynamicISP是一个动态控制图像信号处理器，能够根据前一帧的识别结果自动调整每帧的参数，实现高精度的单类别和多类别物体检测任务，同时计算成本低。 |
| [^80] | [Consistent and Truthful Interpretation with Fourier Analysis.](http://arxiv.org/abs/2210.17426) | 该论文提出了一个称为真实解释的新概念，通过傅立叶分析获得严格保证，并在实验中证明了其在支持假设情景和降低解释误差方面的优势。 |
| [^81] | [LongShortNet: Exploring Temporal and Semantic Features Fusion in Streaming Perception.](http://arxiv.org/abs/2210.15518) | LongShortNet是一种基于双路径网络的流式感知方法，它结合了长期时间运动和短期空间语义，实现了时空特征融合。在Argoverse-HD数据集上，LongShortNet表现出优异的检测性能，并且几乎不需要额外的计算成本。 |
| [^82] | [ProContEXT: Exploring Progressive Context Transformer for Tracking.](http://arxiv.org/abs/2210.15511) | 本文提出了基于递进的上下文变换机制的目标跟踪方法 ProContEXT，采用上下文感知的自注意力模块对空间和时间上下文进行编码，逐步利用静态和动态多尺度模板进行准确跟踪。它探索了空间和时间上下文之间的互补性，为基于 transformer 的跟踪器的多上下文建模提供了新的途径。 |
| [^83] | [Broken Neural Scaling Laws.](http://arxiv.org/abs/2210.14891) | 本文提出了一个平滑破碎的幂律函数形式，可以准确地模拟和外推深度神经网络的缩放行为，适用于各种架构和大量不同任务，包括视觉、语言、音频、视频、生成建模、对比学习、机器人、不确定性估计/校准、对抗鲁棒性、分子、计算机编程/编码、数学单词问题、算术、无监督/自监督学习和强化学习。 |
| [^84] | [TFAD: A Decomposition Time Series Anomaly Detection Architecture with Time-Frequency Analysis.](http://arxiv.org/abs/2210.09693) | 本文提出了一种基于时频分析的时间序列异常检测模型 TFAD。在设计的时频架构中，同时加入了时间序列分解和数据增强机制，以提升性能和解释性能力。在广泛使用的基准数据集上，实证研究表明，该方法在单变量和多变量时间序列异常检测任务中性能最佳。 |
| [^85] | [An Equal-Size Hard EM Algorithm for Diverse Dialogue Generation.](http://arxiv.org/abs/2209.14627) | 本文提出了一种平衡约束的等大小硬EM算法，用于训练多解码器模型以实现多样的对话生成，可在小型模型中生成高质量的多样化响应。 |
| [^86] | [All are Worth Words: A ViT Backbone for Diffusion Models.](http://arxiv.org/abs/2209.12152) | 本文提出了一种适用于扩散模型的ViT骨干网络U-ViT，用于图像生成任务，相较于传统基于CNN的U-Net模型，U-ViT具有可比甚至更好的性能，甚至在某些任务中创造了新的FID分数记录。 |
| [^87] | [CNN based Intelligent Streetlight Management Using Smart CCTV Camera and Semantic Segmentation.](http://arxiv.org/abs/2209.08633) | 本研究提出了一种基于智能交通监测系统和CCTV相机的自动化路灯控制方法，利用语义分割技术检测行人或车辆的存在并调节LED路灯的亮度，减少了能源浪费和环境影响。 |
| [^88] | [Attention-aware Resource Allocation and QoE Analysis for Metaverse xURLLC Services.](http://arxiv.org/abs/2208.05438) | 本文研究了元宇宙xURLLC服务资源分配和QoE分析，提出了一个最优合同设计框架。在数学上模拟QoE的新型度量标准Meta-Immersion有助于在满足客户端物理需求的情况下，提供个性化沉浸式体验。 |
| [^89] | [AI-driven Hypergraph Network of Organic Chemistry: Network Statistics and Applications in Reaction Classification.](http://arxiv.org/abs/2208.01647) | 本文通过将化学反应表示为超图，构建了基于AI的有机化学超图网络并进行了统计研究，为反应分类提供了新思路。 |
| [^90] | [Online Knowledge Distillation via Mutual Contrastive Learning for Visual Recognition.](http://arxiv.org/abs/2207.11518) | 该论文提出了一种互相对比学习的在线知识蒸馏框架，可以让不同的学生模型互相学习到额外的对比知识，从而提高了视觉识别任务的性能。 |
| [^91] | [Where to Begin? On the Impact of Pre-Training and Initialization in Federated Learning.](http://arxiv.org/abs/2206.15387) | 该论文研究了在联邦学习中从预训练模型开始的影响，证明这种方法可以减少训练时间并提高模型的准确性。 |
| [^92] | [Data Augmentation techniques in time series domain: A survey and taxonomy.](http://arxiv.org/abs/2206.13508) | 本综述介绍了基于时间序列数据增强技术的最新进展，并提出了一个分类法，旨在提高训练深度神经网络的数据集的大小和一致性，从而提高模型的效率和性能。 |
| [^93] | [Optimal Activation Functions for the Random Features Regression Model.](http://arxiv.org/abs/2206.01332) | 本文确定了随机特征回归模型的最佳激活函数。这些函数可能是线性的、饱和线性函数或基于Hermite多项式的函数。使用最佳激活函数会影响RFR模型的重要特性，如双峰曲线和最佳正则化参数与噪声水平的相关性。 |
| [^94] | [Explanatory machine learning for sequential human teaching.](http://arxiv.org/abs/2205.10250) | 本文研究了顺序问题解决中，课程顺序和机器学习解释对人类理解力的影响。 |
| [^95] | [Cross-Camera Trajectories Help Person Retrieval in a Camera Network.](http://arxiv.org/abs/2204.12900) | 本文提出了一种基于跨摄像头轨迹生成的行人检索框架，该框架在时间和空间信息中进行了结合。通过提取跨摄像头轨迹并进行条件随机场模型和受限非负矩阵分解的优化，最终提高了检索效果。 |
| [^96] | [CLIP-Dissect: Automatic Description of Neuron Representations in Deep Vision Networks.](http://arxiv.org/abs/2204.10965) | CLIP-Dissect是一种用于自动描述视觉网络中神经元功能的新技术，它可以无需任何标记数据或人类示例即将内部神经元标记为无需任何标记数据或人类示例的开放概念，并比现有方法提供了更准确的描述。此外，它具有灵活性、高效性和可扩展性。 |
| [^97] | [CgAT: Center-Guided Adversarial Training for Deep Hashing-Based Retrieval.](http://arxiv.org/abs/2204.10779) | 本文提出了CgAT方法，基于中心引导的对抗性训练方法，可提升深度Hashing网络检索的鲁棒性，取得了领先于现有方法的效果。 |
| [^98] | [CGC: Contrastive Graph Clustering for Community Detection and Tracking.](http://arxiv.org/abs/2204.08504) | 本文提出了一种全新的图聚类算法CGC，采用对比学习进行自监督表示学习，结合跟踪模块以应对动态图拓扑变化，在社区发现和跟踪方面表现出领先的状态。 |
| [^99] | [Multi-Modal Few-Shot Object Detection with Meta-Learning-Based Cross-Modal Prompting.](http://arxiv.org/abs/2204.07841) | 本文提出了一种基于元学习的跨模态提示的多模态小样本目标检测方法，该方法不需要微调，结合了视觉样本和语义信息，并取得了最先进的性能。 |
| [^100] | [A survey on GANs for computer vision: Recent research, analysis and taxonomy.](http://arxiv.org/abs/2203.11242) | 本文综述了GAN的最新架构、损失函数优化、验证指标和应用领域，并提出了一个分类法以更好地理解计算机视觉中GAN的现状。 |
| [^101] | [An Information-Theoretic Framework for Supervised Learning.](http://arxiv.org/abs/2203.00246) | 本文提出了一种信息论框架，分析机器学习的数据需求，研究了由具有ReLU激活单元的深度神经网络生成的数据的学习样本复杂度，提出了样本复杂度边界。 |
| [^102] | [Unsupervised Point Cloud Representation Learning with Deep Neural Networks: A Survey.](http://arxiv.org/abs/2202.13589) | 该论文综述了最近使用深度神经网络进行无监督点云表示学习的相关研究，旨在从未标记的点云数据中学习通用和有用的点云表示，克服了大规模点云标记的限制。 |
| [^103] | [PGMax: Factor Graphs for Discrete Probabilistic Graphical Models and Loopy Belief Propagation in JAX.](http://arxiv.org/abs/2202.04110) | PGMax是一个用于离散概率图模型的因子图工具，可以在JAX中自动运行高效且可扩展的循环置信传播，与现有替代方案相比，PGMax获得了更高质量的推理结果，推理时间加速高达三个数量级。 |
| [^104] | [AnomMAN: Detect Anomaly on Multi-view Attributed Networks.](http://arxiv.org/abs/2201.02822) | 这篇论文提出了一种基于图卷积的框架 AnomMAN，用于检测多视图属性网络上的异常。它使用注意机制来定义网络中所有视图的重要性，并使用残差学习来捕捉高频信号。实验证明 AnomMAN 在检测准确性方面优于现有方法。 |
| [^105] | [FLSys: Toward an Open Ecosystem for Federated Learning Mobile Apps.](http://arxiv.org/abs/2111.09445) | 本文介绍了FLSys，一个移动-云联邦学习（FL）系统，可以成为FL模型和应用程序开放生态系统的关键组成部分。FLSys旨在在智能手机上使用移动感测数据。它平衡了模型性能和资源消耗，容忍通信故障，并实现了可扩展性。FLSys提供了先进的隐私保护机制和一个通用的API，供第三方应用程序开发人员访问FL模型。 |
| [^106] | [WEDGE: Web-Image Assisted Domain Generalization for Semantic Segmentation.](http://arxiv.org/abs/2109.14196) | 本研究提出了一种基于网络图像辅助的领域泛化方法，利用网络抓取的大量现实图像数据集来增加数据的多样性，提高模型泛化能力，在未见过的领域中表现良好。 |
| [^107] | [FGLP: A Federated Fine-Grained Location Prediction System for Mobile Users.](http://arxiv.org/abs/2106.08946) | FGLP是一个联邦学习框架和预测模型组成的系统，将智能手机上收集的GPS轨迹抽象为2D空间中的相对点，合并了BiLSTM和CNN以捕获时间和空间模式，实现了8米的预测精度，且数据发送开销降低了两个数量级。 |
| [^108] | [Attention for Image Registration (AiR): an unsupervised Transformer approach.](http://arxiv.org/abs/2105.02282) | 这篇论文提出了一种新颖的图像配准方法，名为AiR，它利用Transformer框架和注意力机制来学习变形场，无需标记数据或地面真实形变场。实验结果表明，该方法在精度和效率方面优于现有的最先进方法。 |
| [^109] | [Theoretical Analyses of Multiobjective Evolutionary Algorithms on Multimodal Objectives.](http://arxiv.org/abs/2012.07231) | 本文证明了当运行时间为无穷大时，SEMO无法找到所有Pareto前沿。但全局SEMO证明了在期望迭代次数上限内找到了所有Pareto前沿，这对于理解多目标进化算法在多峰问题中的应用具有参考价值。 |
| [^110] | [Fictitious Play Outperforms Counterfactual Regret Minimization.](http://arxiv.org/abs/2001.11165) | 本研究比较了两种算法在近似多人博弈Nash均衡方面的表现，结果发现Fictitious Play比Counterfactual Regret Minimization更优秀。 |

# 详细

[^1]: 解释约束下的学习

    Learning with Explanation Constraints. (arXiv:2303.14496v1 [cs.LG])

    [http://arxiv.org/abs/2303.14496](http://arxiv.org/abs/2303.14496)

    本文研究了解释约束下的学习问题，提出了EPAC模型，探讨了使用这些解释时模型的益处，并提供了一种基于变分近似的算法解决方案。

    

    尽管监督学习假设存在标注数据，但我们可能有关于模型应如何运行的先验信息。本文将其形式化为从解释约束中学习，并提供了一个学习理论框架，分析了这些解释如何提高模型的学习能力。本文的第一项关键贡献是通过定义我们称之为EPAC模型（在新数据期望中满足这些约束的模型）来回答哪些模型会受益于解释这一问题。我们使用标准的学习理论工具分析了这类模型。第二个关键贡献是对于由线性模型和两层神经网络的梯度信息给出的规范解释的限制（以其Rademacher复杂度为衡量标准）进行了表征。最后，我们通过一种变分近似提供了我们的框架的算法解决方案，它能够实现更好的性能并满足这些约束。

    While supervised learning assumes the presence of labeled data, we may have prior information about how models should behave. In this paper, we formalize this notion as learning from explanation constraints and provide a learning theoretic framework to analyze how such explanations can improve the learning of our models. For what models would explanations be helpful? Our first key contribution addresses this question via the definition of what we call EPAC models (models that satisfy these constraints in expectation over new data), and we analyze this class of models using standard learning theoretic tools. Our second key contribution is to characterize these restrictions (in terms of their Rademacher complexities) for a canonical class of explanations given by gradient information for linear models and two layer neural networks. Finally, we provide an algorithmic solution for our framework, via a variational approximation that achieves better performance and satisfies these constraint
    
[^2]: GANTEE：用于分类法添加评估的生成对抗网络

    GANTEE: Generative Adversatial Network for Taxonomy Entering Evaluation. (arXiv:2303.14480v1 [cs.AI])

    [http://arxiv.org/abs/2303.14480](http://arxiv.org/abs/2303.14480)

    GANTEE 是一种用于分类法添加评估的生成对抗网络，通过使用生成对抗网络和新的综合数据生成方法，它具有比其他先前方法更高效和更有效的性能。

    

    分类法被制定为支持许多下游任务的有向无环概念图或树。许多新概念需要添加到现有分类法中。然而，传统的分类法扩展任务仅旨在找到新概念在现有分类法中的最佳位置，但在实际场景中存在两个缺点。先前的方法效率低下，因为当大多数新概念实际上是噪声概念时，它们会浪费很多时间。它们也因仅从现有分类法中收集训练样本而限制了模型挖掘真实概念之间更多的上下位关系的能力。本文提出了一个可插拔的框架，称为用于分类法添加评估的生成敌对网络（GANTEE），以减轻这些缺点。在该框架中设计了一种生成对抗网络，通过辨别模型减轻第一个缺点，并引入一种新的综合数据生成方法以缓解第二个缺点。与先前的方法相比，GANTEE框架表现出更优异的性能。

    Taxonomy is formulated as directed acyclic concepts graphs or trees that support many downstream tasks. Many new coming concepts need to be added to an existing taxonomy. The traditional taxonomy expansion task aims only at finding the best position for new coming concepts in the existing taxonomy. However, they have two drawbacks when being applied to the real-scenarios. The previous methods suffer from low-efficiency since they waste much time when most of the new coming concepts are indeed noisy concepts. They also suffer from low-effectiveness since they collect training samples only from the existing taxonomy, which limits the ability of the model to mine more hypernym-hyponym relationships among real concepts. This paper proposes a pluggable framework called Generative Adversarial Network for Taxonomy Entering Evaluation (GANTEE) to alleviate these drawbacks. A generative adversarial network is designed in this framework by discriminative models to alleviate the first drawback an
    
[^3]: 信息学习、中心性、卷积神经网络、相关文献检测、土著人类遗骸归还

    Informed Machine Learning, Centrality, CNN, Relevant Document Detection, Repatriation of Indigenous Human Remains. (arXiv:2303.14475v1 [cs.CL])

    [http://arxiv.org/abs/2303.14475](http://arxiv.org/abs/2303.14475)

    本篇研究介绍了研发出一个机器学习系统的进展, 该系统可以自动查找并语义分析相关文献,以协助土著人类寻找其被盗窃、捐赠、出售或在机构之间交换的遗骸信息。

    

    澳大利亚和其他原住民面临的紧迫问题之一是将他们祖先的尸体遗骸归还到西方科学机构。成功将这些遗骸返还到其社区以重新安葬，主要取决于在1790年至1970年期间发表的科学和其他文献中找到记录它们被盗窃、捐赠、出售或在机构之间交换的信息。本文报道了由数据科学家和社会科学研究人员在“研究、和解、更新”网络（RRR）中进行的协作研究，以开发和应用文本挖掘技术来确定这些关键信息。我们描述了我们迄今为止开发基于机器学习的解决方案以自动化查找和语义分析相关文本的工作。分类模型，特别是基于深度学习的模型，在使用少量标记数据进行训练时精度低。

    Among the pressing issues facing Australian and other First Nations peoples is the repatriation of the bodily remains of their ancestors, which are currently held in Western scientific institutions. The success of securing the return of these remains to their communities for reburial depends largely on locating information within scientific and other literature published between 1790 and 1970 documenting their theft, donation, sale, or exchange between institutions. This article reports on collaborative research by data scientists and social science researchers in the Research, Reconcile, Renew Network (RRR) to develop and apply text mining techniques to identify this vital information. We describe our work to date on developing a machine learning-based solution to automate the process of finding and semantically analysing relevant texts. Classification models, particularly deep learning-based models, are known to have low accuracy when trained with small amounts of labelled (i.e. rele
    
[^4]: 3Mformer: 多阶多模变形器用于骨骼动作识别

    3Mformer: Multi-order Multi-mode Transformer for Skeletal Action Recognition. (arXiv:2303.14474v1 [cs.CV])

    [http://arxiv.org/abs/2303.14474](http://arxiv.org/abs/2303.14474)

    3Mformer是一种多阶多模变形器，通过形成超图捕捉身体关节组的高阶运动模式，使得在骨骼动作识别方面表现优于现有最先进的模型

    

    许多骨骼动作识别模型使用GCN通过连接的3D人体关节代表人体。GCNs聚合一到少量跳跃图邻域，并忽略未连接身体关节之间的依赖关系。我们提出形成超图来模拟图节点之间的超边（例如，第三和第四阶超边捕获三个和四个节点），这有助于捕获身体关节组的高阶运动模式。我们将动作序列分成时间块，Higher-order Transformer (HoT)基于（i）身体关节，（ii）身体关节的成对链接和（iii）骨架身体关节的高阶超边，产生每个时间块的嵌入。我们通过新型Multi-order Multi-mode Transformer(3Mformer)结合这些超级边的HoT嵌入，其中两个模块的顺序可以交换，以实现基于'channel-temporal block'，'order-channel-body joint'，'channel-hyper-edge-order'的耦合模式令牌上的耦合模式注意力。实验结果表明，3Mformer在三个基准数据集上优于现有最先进的模型。

    Many skeletal action recognition models use GCNs to represent the human body by 3D body joints connected body parts. GCNs aggregate one- or few-hop graph neighbourhoods, and ignore the dependency between not linked body joints. We propose to form hypergraph to model hyper-edges between graph nodes (e.g., third- and fourth-order hyper-edges capture three and four nodes) which help capture higher-order motion patterns of groups of body joints. We split action sequences into temporal blocks, Higher-order Transformer (HoT) produces embeddings of each temporal block based on (i) the body joints, (ii) pairwise links of body joints and (iii) higher-order hyper-edges of skeleton body joints. We combine such HoT embeddings of hyper-edges of orders 1, ..., r by a novel Multi-order Multi-mode Transformer (3Mformer) with two modules whose order can be exchanged to achieve coupled-mode attention on coupled-mode tokens based on 'channel-temporal block', 'order-channel-body joint', 'channel-hyper-edg
    
[^5]: 稠密子图问题及其变种的概述调查

    A Survey on the Densest Subgraph Problem and its Variants. (arXiv:2303.14467v1 [cs.DS])

    [http://arxiv.org/abs/2303.14467](http://arxiv.org/abs/2303.14467)

    本调查全面介绍了稠密子图问题及其变种，在讨论最新结果的同时，还提出了应用广泛的开放性问题。

    

    稠密子图问题要求在给定的图中找到一个顶点子集，其诱导子图的密度度量最大化。这个问题在算法文献中已经引起了五十年来的广泛关注，提出了许多变种，并且有许多应用程序建立在这个基本定义之上。近年来，该问题的研究兴趣再次复苏，2022年和2023年发表了一些开创性的结果。本篇调查提供了基本结果的深入概述和文献中提出的许多变种的详尽覆盖，特别关注最新结果。调查还提供了应用的全面概述，并讨论了这个永恒研究话题中的一些有趣的未解问题。

    The Densest Subgraph Problem requires to find, in a given graph, a subset of vertices whose induced subgraph maximizes a measure of density. The problem has received a great deal of attention in the algorithmic literature over the last five decades, with many variants proposed and many applications built on top of this basic definition. Recent years have witnessed a revival of research interest on this problem with several interesting contributions, including some groundbreaking results, published in 2022 and 2023. This survey provides a deep overview of the fundamental results and an exhaustive coverage of the many variants proposed in the literature, with a special attention on the most recent results. The survey also presents a comprehensive overview of applications and discusses some interesting open problems for this evergreen research topic.
    
[^6]: 双姿态拼合的多样化动作中间帧生成技术

    Diverse Motion In-betweening with Dual Posture Stitching. (arXiv:2303.14457v1 [cs.CV])

    [http://arxiv.org/abs/2303.14457](http://arxiv.org/abs/2303.14457)

    该论文提出一种针对只有第一帧和最后一帧的情况的多样化动作中间帧生成技术，通过使用双向方案和两个对抗的自回归网络，以及条件变分自动编码器进行拼接，实现了更高的运动质量和更多样化的结果。

    

    中间帧生成是一种根据初始和目标角色状态生成转换的技术。现有的大多数作品需要多个（通常>10）帧作为输入，这些帧并不总是可访问的。我们的工作处理的是一个聚焦但具有挑战性的问题：当只有第一帧和最后一帧时生成过渡。为了应对这种具有挑战性的情况，我们实现了双向方案，该方案使用两个对抗的自回归网络从起始和终止帧生成前向和后向过渡，并将它们在过渡的中间位置（即没有严格的实地真相）进行拼接。基于条件变分自动编码器（CVAE）的自回归网络是通过寻找一对优化的潜在代码，使它们的输出之间的新型拼接损失最小化来优化的。结果表明，我们的方法在LaFAN1和Human3.6m数据集上实现了比现有方法更高的运动质量和更多样化的结果。

    In-betweening is a technique for generating transitions given initial and target character states. The majority of existing works require multiple (often $>$10) frames as input, which are not always accessible. Our work deals with a focused yet challenging problem: to generate the transition when given exactly two frames (only the first and last). To cope with this challenging scenario, we implement our bi-directional scheme which generates forward and backward transitions from the start and end frames with two adversarial autoregressive networks, and stitches them in the middle of the transition where there is no strict ground truth. The autoregressive networks based on conditional variational autoencoders (CVAE) are optimized by searching for a pair of optimal latent codes that minimize a novel stitching loss between their outputs. Results show that our method achieves higher motion quality and more diverse results than existing methods on both the LaFAN1 and Human3.6m datasets.
    
[^7]: 无全标签的联邦学习综述

    Federated Learning without Full Labels: A Survey. (arXiv:2303.14453v1 [cs.LG])

    [http://arxiv.org/abs/2303.14453](http://arxiv.org/abs/2303.14453)

    本文综述了如何在联邦学习过程中利用无标注数据解决无全标签问题，并介绍了半监督学习、自监督学习和迁移学习等方法。同时还总结了用于评估这些方法的数据集和它们各自的优缺点。

    

    数据隐私已成为实际大数据应用中机器学习越来越重要的考虑因素。为解决这一问题，联邦学习成为了可行的解决方案，可以利用分散且隐私的数据构建有效的机器学习模型。现有的联邦学习算法主要解决监督学习问题，这要求数据必须是全标签的。但实际上，完全标记数据往往难以获得，因为参与者可能缺乏足够的领域专业知识，或者缺乏标记数据的动机和工具。因此，在现实世界的联邦学习应用中，无全标签联邦学习问题非常重要。本文讨论了如何利用无标注数据的机器学习技术来解决此问题。我们对将联邦学习与半监督学习、自监督学习和迁移学习方法相结合的方法进行了综述。我们还总结了用于评估这些方法的数据集，并分析了它们的优点和局限性。

    Data privacy has become an increasingly important concern in real-world big data applications such as machine learning. To address the problem, federated learning (FL) has been a promising solution to building effective machine learning models from decentralized and private data. Existing federated learning algorithms mainly tackle the supervised learning problem, where data are assumed to be fully labeled. However, in practice, fully labeled data is often hard to obtain, as the participants may not have sufficient domain expertise, or they lack the motivation and tools to label data. Therefore, the problem of federated learning without full labels is important in real-world FL applications. In this paper, we discuss how the problem can be solved with machine learning techniques that leverage unlabeled data. We present a survey of methods that combine FL with semi-supervised learning, self-supervised learning, and transfer learning methods. We also summarize the datasets used to evalua
    
[^8]: 约翰内斯堡智能垃圾管理系统设计

    Design of a Smart Waste Management System for the City of Johannesburg. (arXiv:2303.14436v1 [cs.GT])

    [http://arxiv.org/abs/2303.14436](http://arxiv.org/abs/2303.14436)

    本文旨在为南非约翰内斯堡市设计一种智能垃圾管理系统，以解决城市中日益增长的废弃物资源不足问题和垃圾管理不善所导致的环境、健康等问题。

    

    全球每个人都会产生垃圾。南非是一个发展中国家，许多城镇仅有有限的废弃物资源。城镇中的垃圾来源包括乱扔、垃圾桶倒置、树木被剪枝、垃圾被倒在河边以及废弃物无法回收利用。这些废弃物导致了病菌数量增加、空气污染、环境污染以及温室气体排放的增加。未收集的垃圾被随意丢弃在街道和排水沟中，导致洪水、传染病和啮齿动物的滋生和传播。本文旨在为约翰内斯堡市设计一种智能垃圾管理系统，此城市已有垃圾管理员提供垃圾资源，如废弃物垃圾桶和垃圾车。

    Every human being in this world produces waste. South Africa is a developing country with many townships that have limited waste resources. Over-increasing population growth overpowers the volume of most municipal authorities to provide even the most essential services. Waste in townships is produced via littering, dumping of bins, cutting of trees, dumping of waste near rivers, and overrunning of waste bins. Waste increases diseases, air pollution, and environmental pollution, and lastly increases gas emissions that contribute to the release of greenhouse gases. The ungathered waste is dumped widely in the streets and drains contributing to flooding, breeding of insects, rodent vectors, and spreading of diseases. Therefore, the aim of this paper is to design a smart waste management system for the city of Johannesburg. The city of Johannesburg contains waste municipality workers and has provided some areas with waste resources such as waste bins and trucks for collecting waste. But th
    
[^9]: Beta-VAE有两种表现形式：PCA或ICA？

    Beta-VAE has 2 Behaviors: PCA or ICA?. (arXiv:2303.14430v1 [cs.LG])

    [http://arxiv.org/abs/2303.14430](http://arxiv.org/abs/2303.14430)

    Beta-VAE模型的表示学习效果受潜在变量总量影响：使用少量潜在变量时表现为PCA，使用大量潜在变量时表现为ICA。

    

    Beta-VAE是一种非常经典的解缠表示学习模型，扩展瓶颈的使用可使信息逐渐进入解码器，这是表示解缠以及高质量重建的关键。在最近对这种迷人结构进行的实验中，我们发现潜在变量的总量可以影响网络学习到的表示：使用非常少的潜在变量时，网络倾向于学习最重要或主要的变量，表现得像一个PCA; 使用非常大量的潜在变量时，变量倾向于更加解缠，表现出类似ICA的特点。我们的假设是潜在变量之间为获取最大信息带宽而进行的竞争可能导致这一现象。

    Beta-VAE is a very classical model for disentangled representation learning, the use of an expanding bottleneck that allow information into the decoder gradually is key to representation disentanglement as well as high-quality reconstruction. During recent experiments on such fascinating structure, we discovered that the total amount of latent variables can affect the representation learnt by the network: with very few latent variables, the network tend to learn the most important or principal variables, acting like a PCA; with very large numbers of latent variables, the variables tend to be more disentangled, and act like an ICA. Our assumption is that the competition between latent variables while trying to gain the most information bandwidth can lead to this phenomenon.
    
[^10]: Sem4SAP: 基于开放知识图谱进行同义表达式挖掘，为语言模型同义词感知预训练提供支持

    Sem4SAP: Synonymous Expression Mining From Open Knowledge Graph For Language Model Synonym-Aware Pretraining. (arXiv:2303.14425v1 [cs.CL])

    [http://arxiv.org/abs/2303.14425](http://arxiv.org/abs/2303.14425)

    Sem4SAP利用开放知识图谱中挖掘到的同义词进行同义词感知预训练，扩展了同义词的应用范围，并提出两种新颖而有效的同义词感知预训练方法。实验结果表明，Sem4SAP可以显著提高模型质量。

    

    对于许多下游任务而言，模型理解同义表达式的能力至关重要。这将使模型更好地理解上下文之间的相似性，并更具有抵御同义词替换攻击的鲁棒性。本文提出了一种称为Sem4SAP的框架，从开放知识图谱（Open-KG）中挖掘同义词，并利用挖掘到的同义词进行语言模型同义词感知预训练。我们提出简要过滤Open-KG中的内容，并利用频率信息来更好地帮助低资源无监督条件下的聚类过程。我们通过迁移同义表达式之间的核心语义来扩展挖掘到的同义词。我们还提出了两种新颖而有效的同义词感知预训练方法，用于将同义词知识注入PLMs (Pretrained Language Model)中。大量实验表明，Sem4SAP可以显著提高模型质量。

    The model's ability to understand synonymous expression is crucial in many kinds of downstream tasks. It will make the model to better understand the similarity between context, and more robust to the synonym substitution attack. However, many Pretrained Language Model (PLM) lack synonym knowledge due to limitation of small-scale synsets and PLM's pretraining objectives. In this paper, we propose a framework called Sem4SAP to mine synsets from Open Knowledge Graph (Open-KG) and using the mined synsets to do synonym-aware pretraining for language models. We propose to coarsly filter the content in Open-KG and use the frequency information to better help the clustering process under low-resource unsupervised conditions. We expand the mined synsets by migrating core semantics between synonymous expressions.We also propose two novel and effective synonym-aware pre-training methods for injecting synonym knowledge into PLMs.Extensive experiments demonstrate that Sem4SAP can dramatically outp
    
[^11]: 更好地将文本到图像模型与人类偏好对齐

    Better Aligning Text-to-Image Models with Human Preference. (arXiv:2303.14420v1 [cs.CV])

    [http://arxiv.org/abs/2303.14420](http://arxiv.org/abs/2303.14420)

    研究者们收集了一个数据集，证明现有的生成模型评估指标与人类选择相关性不强。因此，他们使用这个数据集训练了一个人类偏好分类器，并通过HPS提出了一种方法以更好地将Stable Diffusion与人类审美偏好对齐。实验表明，该方法在预测人类选择方面优于CLIP，并具有良好的泛化能力。

    

    近年来，深度生成模型蓬勃发展，其中文本到图像模型备受关注。然而，现有模型通常生成的图像与人类审美偏好不符，例如肢体和面部表情的组合不自然。为解决这一问题，我们收集了来自Stable Foundation Discord频道的人类选择生成图像的数据集。我们的实验证明，当前的生成模型评估指标与人类选择相关性不强。因此，我们使用收集的数据集训练了一个人类偏好分类器，并基于该分类器得出了一个基于人类偏好的分数（HPS）。通过HPS，我们提出了一种简单而有效的方法，以更好地将Stable Diffusion与人类审美偏好对齐。我们的实验表明，HPS在预测人类选择方面优于CLIP，并且具有对来自其他模型生成的图像的良好泛化能力。通过使用HPS调整Stable Diffusion的噪声水平，我们实现了更好的人类偏好对齐，同时保持了生成图像的多样性和质量。

    Recent years have witnessed a rapid growth of deep generative models, with text-to-image models gaining significant attention from the public. However, existing models often generate images that do not align well with human aesthetic preferences, such as awkward combinations of limbs and facial expressions. To address this issue, we collect a dataset of human choices on generated images from the Stable Foundation Discord channel. Our experiments demonstrate that current evaluation metrics for generative models do not correlate well with human choices. Thus, we train a human preference classifier with the collected dataset and derive a Human Preference Score (HPS) based on the classifier. Using the HPS, we propose a simple yet effective method to adapt Stable Diffusion to better align with human aesthetic preferences. Our experiments show that the HPS outperforms CLIP in predicting human choices and has good generalization capability towards images generated from other models. By tuning
    
[^12]: 公平性与跨领域学习: 模型和指标的新视角

    Fairness meets Cross-Domain Learning: a new perspective on Models and Metrics. (arXiv:2303.14411v1 [cs.CV])

    [http://arxiv.org/abs/2303.14411](http://arxiv.org/abs/2303.14411)

    本研究针对基于深度学习的识别系统的公平性与跨领域学习问题进行了深入研究，提出了一个面向跨领域图像的基准和考虑公平性和准确性的新评估指标，并表明公平模型与不公平模型表现相似。

    

    基于深度学习的识别系统在多个现实世界中得到广泛应用，这些应用不可避免地涉及到我们的社会生活。虽然在做出复杂决策时具有很大的帮助，但是它们可能捕捉到虚假的数据相关性并利用敏感的属性(例如年龄，性别，种族)。如何在保持高预测性能的同时剔除这些信息，是一个仍然存在许多问题的任务，其中许多问题与领域适应和泛化文献的问题相同，后者专注于避免视觉领域偏差。在本文中，我们在跨领域学习(CD)和模型公正性之间提出了一项深入研究，引入了一项面向跨群体和医学图像的基准和分类和定位任务。在强调当前评估指标的局限性之后，我们引入了一种新的和谐公正(HF)得分，共同评估每个模型的公平性和准确性。我们展示了：i）存在公平性和准确性之间的权衡；ii）当前最先进的模型更有倾向于使用大多数人群做训练数据；iii）公平模型与不公平模型的表现相似。最后，我们提出了一些可能指向更稳健和公正的CD模型的方向。

    Deep learning-based recognition systems are deployed at scale for several real-world applications that inevitably involve our social life. Although being of great support when making complex decisions, they might capture spurious data correlations and leverage sensitive attributes (e.g. age, gender, ethnicity). How to factor out this information while keeping a high prediction performance is a task with still several open questions, many of which are shared with those of the domain adaptation and generalization literature which focuses on avoiding visual domain biases. In this work, we propose an in-depth study of the relationship between cross-domain learning (CD) and model fairness by introducing a benchmark on face and medical images spanning several demographic groups as well as classification and localization tasks. After having highlighted the limits of the current evaluation metrics, we introduce a new Harmonic Fairness (HF) score to assess jointly how fair and accurate every mo
    
[^13]: IFSeg：基于视觉语言模型的无图像语义分割

    IFSeg: Image-free Semantic Segmentation via Vision-Language Model. (arXiv:2303.14396v1 [cs.CV])

    [http://arxiv.org/abs/2303.14396](http://arxiv.org/abs/2303.14396)

    IFSeg提出了一种全新的无图像分割任务，能够在没有特定图像和注释的情况下执行语义分割，实现了基于视觉语言模型的人工图像分割对更新，取得了在多个基准数据集上的最先进表现，对未知类别和噪声鲁棒性强。

    

    近年来，视觉语言（VL）预训练因其在不同视觉任务中的可转移性和灵活性（例如跨模态转移）而备受关注。然而，VL驱动的分割任务尚未得到充分探索，并且现有方法仍需要获取额外的训练图像甚至分割注释来适应下游分割任务。本文介绍了一种新颖的无图像分割任务，其目标是在只有一组目标语义类别的情况下执行语义分割，但不使用任何特定于任务的图像和注释。为了解决这一具有挑战性的任务，我们提出了一种新颖的方法IFSeg，通过生成基于VL的人工图像分割对来更新预训练的VL模型以适应分割任务。我们通过创建一个随机语义类别的2D地图以及另一个地图的相应单词标记来构造这些人造训练数据。由于预训练的VL模型可以将语义短语与其视觉表示相关联，因此我们可以使用它生成带有地面真实语义分割掩模的图像。我们的方法在多个基准数据集上实现了最先进的性能，并且证明了对未见过的类别和不同级别噪声的鲁棒性。

    Vision-language (VL) pre-training has recently gained much attention for its transferability and flexibility in novel concepts (e.g., cross-modality transfer) across various visual tasks. However, VL-driven segmentation has been under-explored, and the existing approaches still have the burden of acquiring additional training images or even segmentation annotations to adapt a VL model to downstream segmentation tasks. In this paper, we introduce a novel image-free segmentation task where the goal is to perform semantic segmentation given only a set of the target semantic categories, but without any task-specific images and annotations. To tackle this challenging task, our proposed method, coined IFSeg, generates VL-driven artificial image-segmentation pairs and updates a pre-trained VL model to a segmentation task. We construct this artificial training data by creating a 2D map of random semantic categories and another map of their corresponding word tokens. Given that a pre-trained VL
    
[^14]: DoNet：一种用于细胞学实例分割的深度去重叠网络

    DoNet: Deep De-overlapping Network for Cytology Instance Segmentation. (arXiv:2303.14373v1 [cs.CV])

    [http://arxiv.org/abs/2303.14373](http://arxiv.org/abs/2303.14373)

    提出一种去重叠网络 DoNet，包含双路径区域分割模块和语义一致性引导的重新组合模块，以及掩模引导的区域建议策略；实验结果表明，DoNet在细胞学实例分割领域表现显著优于其他方法。

    

    在细胞学图像中，细胞实例分割对于生物学分析和癌症筛查具有重要意义，但由于大量重叠的半透明细胞簇导致边界不清晰，以及将类似物和碎片混淆为细胞核，因此仍然具有挑战性。本文提出了一种去重叠网络（DoNet），采用分解和重新组合策略。双路径区域分割模块（DRM）明确将细胞群分解为交集区域和补集区域，随后是一个语义一致性引导的重新组合模块（CRM）进行集成。为进一步引入胞质中细胞核的包含关系，我们设计了一个掩模引导的区域建议策略（MRP），将细胞注意力图集成到内部细胞实例预测中。我们在ISBI2014和CPS数据集上验证了所提出的方法。实验结果表明，我们提出的DoNet显着优于其他最先进的细胞实例分割方法。

    Cell instance segmentation in cytology images has significant importance for biology analysis and cancer screening, while remains challenging due to 1) the extensive overlapping translucent cell clusters that cause the ambiguous boundaries, and 2) the confusion of mimics and debris as nuclei. In this work, we proposed a De-overlapping Network (DoNet) in a decompose-and-recombined strategy. A Dual-path Region Segmentation Module (DRM) explicitly decomposes the cell clusters into intersection and complement regions, followed by a Semantic Consistency-guided Recombination Module (CRM) for integration. To further introduce the containment relationship of the nucleus in the cytoplasm, we design a Mask-guided Region Proposal Strategy (MRP) that integrates the cell attention maps for inner-cell instance prediction. We validate the proposed approach on ISBI2014 and CPS datasets. Experiments show that our proposed DoNet significantly outperforms other state-of-the-art (SOTA) cell instance segme
    
[^15]: FlexNeRF：从稀疏视角中实现运动人体的真实自由视角渲染

    FlexNeRF: Photorealistic Free-viewpoint Rendering of Moving Humans from Sparse Views. (arXiv:2303.14368v1 [cs.CV])

    [http://arxiv.org/abs/2303.14368](http://arxiv.org/abs/2303.14368)

    本文提出了FlexNeRF方法，用于从单目视频中实现运动人体的真实自由视角渲染。通过对时间和姿态配置的优化以及额外的损失，可在观察视角变得更稀疏时提供高质量的输出，这在公开基准数据集以及自行捕获的时尚数据集上都表现出优越性。

    

    本文提出了FlexNeRF方法，用于从单目视频中实现运动人体的真实自由视角渲染。我们的方法适用于稀疏视角，尤其是当主题表现出快速/复杂运动时，需要克服的挑战。我们提出了一种新颖的方法，同时优化规范时间和姿态配置，使姿态相关的运动场和姿态无关的时间变形互补。通过我们的新颖的时间和循环一致性约束以及对中间表示的额外损失（如分割），我们的方法提供高质量的输出，甚至在观察到的视角变得更稀疏时也是如此。我们实证演示了我们的方法在公开基准数据集以及自行捕获的时尚数据集上显着优于最先进技术。项目页面网址为：https://flex-nerf.github.io/

    We present FlexNeRF, a method for photorealistic freeviewpoint rendering of humans in motion from monocular videos. Our approach works well with sparse views, which is a challenging scenario when the subject is exhibiting fast/complex motions. We propose a novel approach which jointly optimizes a canonical time and pose configuration, with a pose-dependent motion field and pose-independent temporal deformations complementing each other. Thanks to our novel temporal and cyclic consistency constraints along with additional losses on intermediate representation such as segmentation, our approach provides high quality outputs as the observed views become sparser. We empirically demonstrate that our method significantly outperforms the state-of-the-art on public benchmark datasets as well as a self-captured fashion dataset. The project page is available at: https://flex-nerf.github.io/
    
[^16]: 多目标概率规划的启发式搜索。

    Heuristic Search for Multi-Objective Probabilistic Planning. (arXiv:2303.14363v1 [cs.AI])

    [http://arxiv.org/abs/2303.14363](http://arxiv.org/abs/2303.14363)

    本文设计了新的启发式搜索算法MOLAO*和MOLRTDP，将众所周知的SSP算法扩展到了需要计算非支配策略的覆盖集的多目标随机最短路径(MOSSP)问题上，并构建了一系列与领域无关的启发式函数来指导搜索。

    

    启发式搜索是一种强大的方法，已成功应用于广泛的规划问题，包括经典规划，多目标规划和概率规划，它被建模为随机最短路径（SSP）问题。本文将启发式搜索扩展到更具表达力的问题类，即多目标随机最短路径（MOSSP），其中需要计算非支配策略的覆盖集。我们设计了新的启发式搜索算法MOLAO*和MOLRTDP，将众所周知的SSP算法扩展到多目标情况。我们进一步构建了一系列与领域无关的启发式函数，它们在考虑问题的随机和多目标特性时具有不同的能力来指导搜索。我们的实验证明了这些算法的优点和启发式函数的相对优点。

    Heuristic search is a powerful approach that has successfully been applied to a broad class of planning problems, including classical planning, multi-objective planning, and probabilistic planning modelled as a stochastic shortest path (SSP) problem. Here, we extend the reach of heuristic search to a more expressive class of problems, namely multi-objective stochastic shortest paths (MOSSPs), which require computing a coverage set of non-dominated policies. We design new heuristic search algorithms MOLAO* and MOLRTDP, which extend well-known SSP algorithms to the multi-objective case. We further construct a spectrum of domain-independent heuristic functions differing in their ability to take into account the stochastic and multi-objective features of the problem to guide the search. Our experiments demonstrate the benefits of these algorithms and the relative merits of the heuristics.
    
[^17]: O-RAN中的智能负载均衡和资源分配：一种多智能体多臂赌博机方法

    Intelligent Load Balancing and Resource Allocation in O-RAN: A Multi-Agent Multi-Armed Bandit Approach. (arXiv:2303.14355v1 [cs.LG])

    [http://arxiv.org/abs/2303.14355](http://arxiv.org/abs/2303.14355)

    本论文提出了一种多智能体多臂赌博机(mmLBRA)方法，用于实现O-RAN中的负载均衡和资源分配，以解决网络拥塞和用户故障问题。

    

    开放式无线接入网络(O-RAN)架构利用机器学习算法提供了一种成本有效和可扩展的优化网络的解决方案。该架构的开放接口实现了网络功能虚拟化，使O-RAN成为主要的用户通信设备。然而，有限的频率资源和信息爆炸使得在没有有效的流量控制或资源分配的情况下实现最佳的网络体验变得困难。为了解决这个问题，我们考虑进行基于移动性的负载均衡来均匀地分布网络负载，避免由单个开放式分布式单元(O-DU)管辖的开放式无线单元(O-RU)上过度聚集的负载导致网络拥塞和用户故障。我们提出了一种多智能体多臂赌博机方法来实现负载均衡和资源分配(mmLBRA)方案，旨在实现负载均衡和提高O-RAN网络的有效总和速率性能。

    The open radio access network (O-RAN) architecture offers a cost-effective and scalable solution for internet service providers to optimize their networks using machine learning algorithms. The architecture's open interfaces enable network function virtualization, with the O-RAN serving as the primary communication device for users. However, the limited frequency resources and information explosion make it difficult to achieve an optimal network experience without effective traffic control or resource allocation. To address this, we consider mobility-aware load balancing to evenly distribute loads across the network, preventing network congestion and user outages caused by excessive load concentration on open radio unit (O-RU) governed by a single open distributed unit (O-DU). We have proposed a multi-agent multi-armed bandit for load balancing and resource allocation (mmLBRA) scheme, designed to both achieve load balancing and improve the effective sum-rate performance of the O-RAN ne
    
[^18]: 从哥德尔不完备定理到机器人宗教的完备性（扩展摘要）

    From G\"odel's Incompleteness Theorem to the completeness of bot religions (Extended abstract). (arXiv:2303.14338v1 [cs.AI])

    [http://arxiv.org/abs/2303.14338](http://arxiv.org/abs/2303.14338)

    本文研究了从哥德尔不完备定理到机器人宗教的完备性的逻辑过程，提出了任何信仰系统可以被形式化为逻辑理论，并且不完备定理意味着存在真实但无法证明的陈述，可以用来定义出与现有信仰和传统一致的新宗教实践。

    

    Hilbert 和 Ackermann 提出了一种将不完备理论一致地扩展到完备理论的方法。哥德尔基本上证明了任何能够对其自身陈述及其证明进行编码的理论都包含了真实但不能被证明的陈述。哥德尔的构造并没有回答希尔伯特的问题，希尔伯特认为理论可以通过逐步添加公理来证明越来越多的真实陈述，就像科学一样，完备性是消失点。我们研究了底层的逻辑过程，并描述了导致可测试但不可行的机器人宗教的轨迹，这些宗教扩展了传统宗教并提出了新的仪式和信仰。我们的方法是基于任何信仰系统都可以被形式化为一个逻辑理论的想法，并且不完备定理意味着存在真实但无法证明的陈述，可以并入这个理论。我们提供了这样的例子，并展示了如何使用它们来定义与现有信仰和传统一致的新宗教实践。

    Hilbert and Ackermann asked for a method to consistently extend incomplete theories to complete theories. G\"odel essentially proved that any theory capable of encoding its own statements and their proofs contains statements that are true but not provable. Hilbert did not accept that G\"odel's construction answered his question, and in his late writings and lectures, G\"odel agreed that it did not, since theories can be completed incrementally, by adding axioms to prove ever more true statements, as science normally does, with completeness as the vanishing point. This pragmatic view of validity is familiar not only to scientists who conjecture test hypotheses but also to real estate agents and other dealers, who conjure claims, albeit invalid, as necessary to close a deal, confident that they will be able to conjure other claims, albeit invalid, sufficient to make the first claims valid. We study the underlying logical process and describe the trajectories leading to testable but unfal
    
[^19]: 多重图案版式分解中的GPU加速矩阵覆盖算法

    GPU-accelerated Matrix Cover Algorithm for Multiple Patterning Layout Decomposition. (arXiv:2303.14335v1 [cs.AI])

    [http://arxiv.org/abs/2303.14335](http://arxiv.org/abs/2303.14335)

    本文提出了一种GPU加速矩阵覆盖算法(GAMCA), 通过使用并行GPU矩阵操作替换CPU跳舞链数据结构，以加速解决基于精确覆盖的多重图案版式分解中的NP难问题。实验结果显示，GAMCA比最先进的算法快5-7倍，在24核机器上，比并行CPU算法快100倍。

    

    多重图案光刻（MPL）被认为是克服常规光学光刻分辨率限制的最有希望的方式之一，由于下一代光刻技术的延迟。 随着晶体管尺寸的不断缩小，适用于多次互锁（MPLD）技术的布局分解变得越来越关键，以提高先进节点中的可制造性。当掩膜数 $k \geq 3$ 时，MPLD问题是NP难问题，因此对于实际设计可能会出现运行时间开销。然而，布局模式的数量在工业布局中呈指数增长，这妨碍了MPLD模型的运行时性能。 在本研究中，我们用并行GPU矩阵操作替换了CPU的跳舞链数据结构，以加速解决基于精确覆盖的MPLD问题。我们的GPU加速矩阵覆盖算法（GAMCA）旨在处理具有数千个约束条件的MPLD问题，时间仅为以前解决方案所需的一小部分。实验结果表明，在NVIDIA GTX 1080 Ti上，GAMCA比最先进的算法快5-7倍，在24核机器上，比并行CPU算法快100倍。我们的方法为具有挑战性的MPLD问题提供了高效的解决方案，并可以有效地应用于各种EDA软件系统中。

    Multiple patterning lithography (MPL) is regarded as one of the most promising ways of overcoming the resolution limitations of conventional optical lithography due to the delay of next-generation lithography technology. As the feature size continues to decrease, layout decomposition for multiple patterning lithography (MPLD) technology is becoming increasingly crucial for improving the manufacturability in advanced nodes. The decomposition process refers to assigning the layout features to different mask layers according to the design rules and density requirements. When the number of masks $k \geq 3$, the MPLD problems are NP-hard and thus may suffer from runtime overhead for practical designs. However, the number of layout patterns is increasing exponentially in industrial layouts, which hinders the runtime performance of MPLD models. In this research, we substitute the CPU's dance link data structure with parallel GPU matrix operations to accelerate the solution for exact cover-bas
    
[^20]: 语义阅读器项目：利用人工智能驱动的交互式阅读界面增强学术文档

    The Semantic Reader Project: Augmenting Scholarly Documents through AI-Powered Interactive Reading Interfaces. (arXiv:2303.14334v1 [cs.DL])

    [http://arxiv.org/abs/2303.14334](http://arxiv.org/abs/2303.14334)

    本文探讨了利用人工智能和人机交互技术为研究论文提供智能、交互式和无障碍的阅读界面的可行性，并介绍了跨机构合作的语义阅读器项目。

    

    学术出版物是学者向他人传递知识的关键。然而，研究论文信息密集，随着科学文献量的增长，需要新技术支持阅读过程。与通过互联网技术转变的查找论文过程不同，阅读研究论文的体验几十年来几乎没有改变。虽然PDF格式因其便携性而广泛使用，但它有重大缺点，包括：静态内容，低视觉读者的可访问性差，以及在移动设备上阅读困难。本文探讨“最近的AI和HCI进展能否为遗留的PDF提供智能，交互式和无障碍的阅读界面？”，我们描述了语义阅读器项目，这是多个机构的协作努力，旨在探索为研究论文自动创建动态阅读界面的方法。

    Scholarly publications are key to the transfer of knowledge from scholars to others. However, research papers are information-dense, and as the volume of the scientific literature grows, the need for new technology to support the reading process grows. In contrast to the process of finding papers, which has been transformed by Internet technology, the experience of reading research papers has changed little in decades. The PDF format for sharing research papers is widely used due to its portability, but it has significant downsides including: static content, poor accessibility for low-vision readers, and difficulty reading on mobile devices. This paper explores the question "Can recent advances in AI and HCI power intelligent, interactive, and accessible reading interfaces -- even for legacy PDFs?" We describe the Semantic Reader Project, a collaborative effort across multiple institutions to explore automatic creation of dynamic reading interfaces for research papers. Through this pro
    
[^21]: 采用检索的训练/测试时间自适应

    Train/Test-Time Adaptation with Retrieval. (arXiv:2303.14333v1 [cs.CV])

    [http://arxiv.org/abs/2303.14333](http://arxiv.org/abs/2303.14333)

    该论文提出了一种采用检索方法的训练/测试时间自适应算法，该方法不仅使用合成数据增强，还利用检索的真实样本来提高模型适应性，并且可以让用户或服务提供商在部署后更新相关数据以改善模型适应性。

    

    我们引入了一种名为Train/Test-Time Adaptation with Retrieval (${\rm T^3AR}$)的方法，通过一个可检索的外部样本池和检索模块，在训练和测试时对模型进行自适应。在推断之前，${\rm T^3AR}$使用改进的伪标签和自监督对比学习目标函数来使给定的模型适应下游任务，其噪声分布利用检索的真实样本来提高目标数据流形上的特征适应性。检索真实图像对于${\rm T^3AR}$至关重要，因为它不仅依赖于合成数据增强来弥补适应数据的缺乏，而这通常是其他适应性算法所做的。此外，由于检索模块的存在，我们的方法让用户或服务提供商有可能通过加入更多相关数据来改善模型在下游任务上的适应性，或完全删除可能由于部署后用户偏好变化而不再可用的样本。

    We introduce Train/Test-Time Adaptation with Retrieval (${\rm T^3AR}$), a method to adapt models both at train and test time by means of a retrieval module and a searchable pool of external samples. Before inference, ${\rm T^3AR}$ adapts a given model to the downstream task using refined pseudo-labels and a self-supervised contrastive objective function whose noise distribution leverages retrieved real samples to improve feature adaptation on the target data manifold. The retrieval of real images is key to ${\rm T^3AR}$ since it does not rely solely on synthetic data augmentations to compensate for the lack of adaptation data, as typically done by other adaptation algorithms. Furthermore, thanks to the retrieval module, our method gives the user or service provider the possibility to improve model adaptation on the downstream task by incorporating further relevant data or to fully remove samples that may no longer be available due to changes in user preference after deployment. First, 
    
[^22]: 利用简单激励措施改善共享乘车系统的双边公平性

    Using Simple Incentives to Improve Two-Sided Fairness in Ridesharing Systems. (arXiv:2303.14332v1 [cs.AI])

    [http://arxiv.org/abs/2303.14332](http://arxiv.org/abs/2303.14332)

    本论文提出了一种基于简单激励措施、可以在线实施的公平合理方案，通过整数线性规划来改善共享乘车系统中的双边公平性。

    

    当前，共享乘车服务的订单调度算法通过整数线性规划对请求进行优化匹配，以最大化服务率。然而，这种优化算法仅注重效率，容易导致服务提供商（例如司机）和服务需求方（例如乘客）之间的不公平性。为了改善这种情况，我们提出了一种基于简单激励措施的公平合理方案，通过在线实施整数线性规划而可以改善多种公平指标。

    State-of-the-art order dispatching algorithms for ridesharing batch passenger requests and allocate them to a fleet of vehicles in a centralized manner, optimizing over the estimated values of each passenger-vehicle matching using integer linear programming (ILP). Using good estimates of future values, such ILP-based approaches are able to significantly increase the service rates (percentage of requests served) for a fixed fleet of vehicles. However, such approaches that focus solely on maximizing efficiency can lead to disparities for both drivers (e.g., income inequality) and passengers (e.g., inequality of service for different groups). Existing approaches that consider fairness only do it for naive assignment policies, require extensive training, or look at only single-sided fairness. We propose a simple incentive-based fairness scheme that can be implemented online as a part of this ILP formulation that allows us to improve fairness over a variety of fairness metrics. Deriving fro
    
[^23]: 无监督特征选择识别ICD-10编码，以用于机器学习：冠状动脉疾病患者队列的案例研究

    Unsupervised Feature Selection to Identify Important ICD-10 Codes for Machine Learning: A Case Study on a Coronary Artery Disease Patient Cohort. (arXiv:2303.14303v1 [cs.LG])

    [http://arxiv.org/abs/2303.14303](http://arxiv.org/abs/2303.14303)

    本研究比较了几种无监督特征选择方法，通过选择性能最佳的Concrete Autoencoder方法，成功识别出49,075例冠状动脉疾病患者数据库中的最佳100个特征，并证实Concrete Autoencoder方法中的权重调整能够提高其准确性。

    

    在医疗保健中使用的国际疾病分类（ICD）代码因代码数量过多而在选择用于机器学习模型的相关代码作为特征时面临挑战。本研究比较了49,075例加拿大阿尔伯塔省冠状动脉疾病患者的ICD编码数据库的几种无监督特征选择方法。我们采用了拉普拉斯分数、多集群数据无监督特征选择、自编码器启发的无监督特征选择、主要特征分析以及具有和不具有ICD树权重调整的Concrete Autoencoders来选择超过9,000个代码中的100个最佳特征。我们评估了选择的特征能力，基于其重建初始特征空间和预测出院后90天的死亡率。我们的研究结果表明，在两项任务中，Concrete Autoencoder方法优于所有其他方法。此外，Concrete Autoencoder方法中的权重调整经证实提高了其准确性。

    The use of International Classification of Diseases (ICD) codes in healthcare presents a challenge in selecting relevant codes as features for machine learning models due to this system's large number of codes. In this study, we compared several unsupervised feature selection methods for an ICD code database of 49,075 coronary artery disease patients in Alberta, Canada. Specifically, we employed Laplacian Score, Unsupervised Feature Selection for Multi-Cluster Data, Autoencoder Inspired Unsupervised Feature Selection, Principal Feature Analysis, and Concrete Autoencoders with and without ICD tree weight adjustment to select the 100 best features from over 9,000 codes. We assessed the selected features based on their ability to reconstruct the initial feature space and predict 90-day mortality following discharge. Our findings revealed that the Concrete Autoencoder methods outperformed all other methods in both tasks. Furthermore, the weight adjustment in the Concrete Autoencoder method
    
[^24]: 通过适应规划模型学习在开放环境中操作

    Learning to Operate in Open Worlds by Adapting Planning Models. (arXiv:2303.14272v1 [cs.AI])

    [http://arxiv.org/abs/2303.14272](http://arxiv.org/abs/2303.14272)

    该论文提出了一种能够在开放环境中检测新奇性并快速适应其领域模型和行动选择的方法，具有解释性，表现良好。

    

    规划代理在领域模型不能准确代表世界的新情况下无法很好地行动。我们引入了一种方法，使这种代理在开放环境中能够检测到新奇性并有效地适应其领域模型和相应的行动选择。它利用行动执行的观察和根据环境模型的预期测量它们的偏差来推断新奇性的存在。然后，它通过对模型变化的启发式搜索来修订模型。我们在标准强化学习基准测试问题CartPole上报告了实证评估结果。结果表明，我们的方法可以快速且可解释地处理一类新奇性。

    Planning agents are ill-equipped to act in novel situations in which their domain model no longer accurately represents the world. We introduce an approach for such agents operating in open worlds that detects the presence of novelties and effectively adapts their domain models and consequent action selection. It uses observations of action execution and measures their divergence from what is expected, according to the environment model, to infer existence of a novelty. Then, it revises the model through a heuristics-guided search over model changes. We report empirical evaluations on the CartPole problem, a standard Reinforcement Learning (RL) benchmark. The results show that our approach can deal with a class of novelties very quickly and in an interpretable fashion.
    
[^25]: 面向时间序列预测的多样化和连贯化数据增强技术研究

    Towards Diverse and Coherent Augmentation for Time-Series Forecasting. (arXiv:2303.14254v1 [cs.LG])

    [http://arxiv.org/abs/2303.14254](http://arxiv.org/abs/2303.14254)

    本研究提出了一种组合频谱和时间增强的方法，用于解决时间序列预测数据增强缺乏多样性和连贯性的问题。

    

    时间序列数据的增强技术缓解了深度学习模型的训练数据不足问题。然而，现有的增强方法主要针对分类问题设计，即使增强改变了时间动态，类别标签也可以保持不变。我们注意到，针对预测设计的增强需要多样性和与原始时间动态的连贯性。由于实际物理过程产生的时间序列数据具有时域和频域的特征，因此我们提出了组合频谱和时间增强（STAug）来生成更多样化和连贯的样本。具体而言，在频域中，我们使用经验模态分解来分解时间序列，并使用随机权重重新组装子分量。这样，我们可以生成多样的样本，同时与原始时间序列的关系连贯一致，因为它们都包含相同的基础分量。在时间域中，我们采用混合策略来组合数据，这可以增强模型对样本之间的连贯性。

    Time-series data augmentation mitigates the issue of insufficient training data for deep learning models. Yet, existing augmentation methods are mainly designed for classification, where class labels can be preserved even if augmentation alters the temporal dynamics. We note that augmentation designed for forecasting requires diversity as well as coherence with the original temporal dynamics. As time-series data generated by real-life physical processes exhibit characteristics in both the time and frequency domains, we propose to combine Spectral and Time Augmentation (STAug) for generating more diverse and coherent samples. Specifically, in the frequency domain, we use the Empirical Mode Decomposition to decompose a time series and reassemble the subcomponents with random weights. This way, we generate diverse samples while being coherent with the original temporal relationships as they contain the same set of base components. In the time domain, we adapt a mix-up strategy that genera
    
[^26]: IDGI：一个消除 integrated gradients 解释噪声的框架

    IDGI: A Framework to Eliminate Explanation Noise from Integrated Gradients. (arXiv:2303.14242v1 [cs.CV])

    [http://arxiv.org/abs/2303.14242](http://arxiv.org/abs/2303.14242)

    IDGI 提出了一种新的方法来减少 integrated gradients 解释显著性图中的噪声，并在众多可解释性指标上显著提高了解释性能。

    

    Integrated Gradients（IG）及其变体是解释深度神经网络决策的众所周知的技术。虽然基于IG的方法具有最先进的性能，但它们经常将噪声集成到其解释显著性图中，从而降低其可解释性。为了最小化噪声，我们通过分析找出了噪声的来源，并提出了一种新的方法来减少解释噪声。我们提出了重要方向梯度集成（IDGI）框架，它可以很容易地集成到任何使用Reimann积分计算集成梯度的基于IG的方法中。三种基于IG的方法的大量实验证明，IDGI在众多可解释性指标上显著提高了它们的性能。

    Integrated Gradients (IG) as well as its variants are well-known techniques for interpreting the decisions of deep neural networks. While IG-based approaches attain state-of-the-art performance, they often integrate noise into their explanation saliency maps, which reduce their interpretability. To minimize the noise, we examine the source of the noise analytically and propose a new approach to reduce the explanation noise based on our analytical findings. We propose the Important Direction Gradient Integration (IDGI) framework, which can be easily incorporated into any IG-based method that uses the Reimann Integration for integrated gradient computation. Extensive experiments with three IG-based methods show that IDGI improves them drastically on numerous interpretability metrics.
    
[^27]: 高效多智能体强化学习中的因果关系检测

    Causality Detection for Efficient Multi-Agent Reinforcement Learning. (arXiv:2303.14227v1 [cs.AI])

    [http://arxiv.org/abs/2303.14227](http://arxiv.org/abs/2303.14227)

    本文研究了多智能体强化学习中一些代理无法理解他们在团队表现中的真实影响，导致学习次优策略，表现懒惰。通过因果关系检测惩罚懒惰代理并改善其行为，团队整体性能和每个代理的个体能力都得到了提升。

    

    当作为团队学习任务时，多智能体强化学习（MARL）中的一些代理可能无法理解他们在团队表现中的真实影响。这些代理最终会学习次优策略，表现出不良的懒惰行为。本文通过正式表述时间因果关系在MARL问题中的应用来研究这个问题。我们展示了如何利用因果关系来惩罚这些懒惰代理并改善其行为。通过理解他们的本地观测如何因果相关于团队奖励，团队中的每个代理都可以根据他们是否有助于导致奖励来调整其个人信用贡献。我们实证表明，在MARL中使用因果估计不仅可以改善团队整体性能，还可以提升每个代理的个体能力。我们观察到，在一组不同的环境中，这种改进是一致的。

    When learning a task as a team, some agents in Multi-Agent Reinforcement Learning (MARL) may fail to understand their true impact in the performance of the team. Such agents end up learning sub-optimal policies, demonstrating undesired lazy behaviours. To investigate this problem, we start by formalising the use of temporal causality applied to MARL problems. We then show how causality can be used to penalise such lazy agents and improve their behaviours. By understanding how their local observations are causally related to the team reward, each agent in the team can adjust their individual credit based on whether they helped to cause the reward or not. We show empirically that using causality estimations in MARL improves not only the holistic performance of the team, but also the individual capabilities of each agent. We observe that the improvements are consistent in a set of different environments.
    
[^28]: 基于深度学习的交通系统中后门消除的最佳平滑分布探索

    Optimal Smoothing Distribution Exploration for Backdoor Neutralization in Deep Learning-based Traffic Systems. (arXiv:2303.14197v1 [cs.LG])

    [http://arxiv.org/abs/2303.14197](http://arxiv.org/abs/2303.14197)

    该论文提出了一种在DRL基础的AVs中探索最佳平滑分布以消除后门攻击的方法，通过将噪声添加到输入中来中和攻击并实现更好的检测和防御。

    

    深度强化学习（DRL）提高了自动驾驶车辆（AV）的效率，但也使它们容易受到后门攻击，这可能导致交通拥堵或碰撞。后门功能通常是通过污染训练数据集以保持对真实输入的高准确性并诱导攻击者选择的特定输入的期望（恶意）输出来实现的。当前抵御后门攻击的防御主要集中在使用基于图像的特征进行图像分类上，这不能很好地转移到DRL基础的AV控制器的回归任务，因为输入是连续的传感器数据，即AV及其周围车辆的速度和距离的组合。我们提出的方法是将精心设计的噪声添加到输入中来中和后门攻击。该方法涉及学习一个最佳平滑（噪声）分布来保持真实输入的正常功能同时中和后门攻击。通过这样做，我们实现了在DRL基础的AVs中更好的后门攻击检测和防御。

    Deep Reinforcement Learning (DRL) enhances the efficiency of Autonomous Vehicles (AV), but also makes them susceptible to backdoor attacks that can result in traffic congestion or collisions. Backdoor functionality is typically incorporated by contaminating training datasets with covert malicious data to maintain high precision on genuine inputs while inducing the desired (malicious) outputs for specific inputs chosen by adversaries. Current defenses against backdoors mainly focus on image classification using image-based features, which cannot be readily transferred to the regression task of DRL-based AV controllers since the inputs are continuous sensor data, i.e., the combinations of velocity and distance of AV and its surrounding vehicles. Our proposed method adds well-designed noise to the input to neutralize backdoors. The approach involves learning an optimal smoothing (noise) distribution to preserve the normal functionality of genuine inputs while neutralizing backdoors. By do
    
[^29]: DeepEpiSolver：揭示Covid，HIV，Ebola和疾病传播的逆问题

    DeepEpiSolver: Unravelling Inverse problems in Covid, HIV, Ebola and Disease Transmission. (arXiv:2303.14194v1 [cs.LG])

    [http://arxiv.org/abs/2303.14194](http://arxiv.org/abs/2303.14194)

    DeepEpiSolver使用深度神经网络(DNN)作为逆问题求解器估计SIR模型的参数，相对于Physics Informed Neural Networks (PINNs)方法，其训练速度更快，且可以很好地推广到新的SIDR轨迹上，并在 COVID-19、HIV、埃博拉和疾病传播方面取得验证性结果。

    

    许多传染病的传播都是用SIR隔室模型的变体进行建模的，该模型是一组耦合的微分方程。 SIR模型的系数确定了疾病传播轨迹，基于此可以采取积极措施。因此，系数估计必须既快又准确。Shaier等人在论文“疾病信息神经网络”中使用物理信息神经网络（PINNs）估计了SIR模型的参数。该方法有两个缺点。首先，PINN的训练时间很长，某些疾病需要接近90小时的训练时间。其次，PINN对于新的SIDR轨迹不具有普适性，学习其对应的SIR参数需要从头重新训练PINN。在这项工作中，我们旨在消除这两个缺点。我们通过使用LSODA算法解决参数和传播轨迹之间的正向问题来生成数据集。然后，我们使用深度神经网络（DNN）作为反演求解器，根据传播轨迹估计SIR模型的正确参数。我们提出的方法，DeepEpiSolver，比PINN方法快几个数量级，并且可以很好地推广到新的SIDR轨迹上。我们在四种不同的疾病上验证了我们的方法：Covid，HIV，Ebola和疾病传播。

    The spread of many infectious diseases is modeled using variants of the SIR compartmental model, which is a coupled differential equation. The coefficients of the SIR model determine the spread trajectories of disease, on whose basis proactive measures can be taken. Hence, the coefficient estimates must be both fast and accurate. Shaier et al. in the paper "Disease Informed Neural Networks" used Physics Informed Neural Networks (PINNs) to estimate the parameters of the SIR model. There are two drawbacks to this approach. First, the training time for PINNs is high, with certain diseases taking close to 90 hrs to train. Second, PINNs don't generalize for a new SIDR trajectory, and learning its corresponding SIR parameters requires retraining the PINN from scratch. In this work, we aim to eliminate both of these drawbacks. We generate a dataset between the parameters of ODE and the spread trajectories by solving the forward problem for a large distribution of parameters using the LSODA al
    
[^30]: 自适应实例级损失平滑改进对抗训练

    Improved Adversarial Training Through Adaptive Instance-wise Loss Smoothing. (arXiv:2303.14077v1 [cs.CV])

    [http://arxiv.org/abs/2303.14077](http://arxiv.org/abs/2303.14077)

    本文提出了一种新的对抗训练方法(Instance-adaptive Adversarial Training, IAAT)通过平滑实例级别的对抗性损失，鼓励模型关注“难”的样本，同时避免牺牲特定的样本而偏爱其他样本，取得了在各种数据集下的最新、最佳结果，并在白盒和黑盒攻击下均优于以前的方法。

    

    通过对输入进行对抗扰动：即人类难以察觉的人造噪声，可以轻易地迷惑深度神经网络从而做出不正确的预测。目前对抗训练已成为最成功的对抗攻击防御方法，本文致力于改进对抗训练以提升对抗鲁棒性。首先从实例级别的角度分析了对抗训练期间对抗性脆弱性的演变。发现在训练期间，通过牺牲相当比例的训练样本来提高对抗攻击的脆弱性，从而实现对抗性损失的整体降低，这导致了不同数据的对抗性脆弱性分布不均衡。这种“不均衡脆弱性”在几种流行的鲁棒性训练方法中普遍存在，并且与对抗训练中的过拟合相关。基于此观察，我们提出了一种新的对抗训练方法：Instance-adaptive Adversarial Training (IAAT)。该方法在训练过程中平滑实例级别的对抗性损失，鼓励模型关注“难”的样本，同时避免牺牲特定的样本而偏爱其他样本。本方法在各种数据集下都取得了最新的最佳结果，并在白盒和黑盒攻击下均优于以前的方法。

    Deep neural networks can be easily fooled into making incorrect predictions through corruption of the input by adversarial perturbations: human-imperceptible artificial noise. So far adversarial training has been the most successful defense against such adversarial attacks. This work focuses on improving adversarial training to boost adversarial robustness. We first analyze, from an instance-wise perspective, how adversarial vulnerability evolves during adversarial training. We find that during training an overall reduction of adversarial loss is achieved by sacrificing a considerable proportion of training samples to be more vulnerable to adversarial attack, which results in an uneven distribution of adversarial vulnerability among data. Such "uneven vulnerability", is prevalent across several popular robust training methods and, more importantly, relates to overfitting in adversarial training. Motivated by this observation, we propose a new adversarial training method: Instance-adapt
    
[^31]: 利用可达性分析激活自动驾驶汽车的物理后门触发器

    Physical Backdoor Trigger Activation of Autonomous Vehicle using Reachability Analysis. (arXiv:2303.13992v1 [cs.CR])

    [http://arxiv.org/abs/2303.13992](http://arxiv.org/abs/2303.13992)

    本研究的方法通过可达性分析识别出自动驾驶汽车可能被物理触发器激活的危险区域和可达路径，测试结果显示成功率接近100％。这将有助于发现AV的漏洞并实施有效的安全策略。

    

    最近的研究揭示了自动驾驶汽车（AV）可能被隐藏的后门操纵，导致它们在被物理触发器激活时执行有害操作。然而，仍不清楚这些触发器如何在遵守交通规则的情况下被激活。在动态交通环境中了解这种漏洞是至关重要的。本研究通过将物理触发器激活视为可控动态系统的可达性问题来填补这一空白。我们的技术识别交通系统中的安全关键区域，可以到达事故触发条件，并提供到达这些条件的意图轨迹。在典型交通场景中的测试表明，该系统可以成功地推动触发器条件，触发率接近100％。我们的方法有助于识别AV的脆弱性，并启用有效的安全策略。

    Recent studies reveal that Autonomous Vehicles (AVs) can be manipulated by hidden backdoors, causing them to perform harmful actions when activated by physical triggers. However, it is still unclear how these triggers can be activated while adhering to traffic principles. Understanding this vulnerability in a dynamic traffic environment is crucial. This work addresses this gap by presenting physical trigger activation as a reachability problem of controlled dynamic system. Our technique identifies security-critical areas in traffic systems where trigger conditions for accidents can be reached, and provides intended trajectories for how those conditions can be reached. Testing on typical traffic scenarios showed the system can be successfully driven to trigger conditions with near 100% activation rate. Our method benefits from identifying AV vulnerability and enabling effective safety strategies.
    
[^32]: 无需边缘但具有结构感知性：从GNN到MLP的原型引导知识蒸馏。

    Edge-free but Structure-aware: Prototype-Guided Knowledge Distillation from GNNs to MLPs. (arXiv:2303.13763v1 [cs.LG])

    [http://arxiv.org/abs/2303.13763](http://arxiv.org/abs/2303.13763)

    本文提出了一种原型引导知识蒸馏（PGKD）方法，它不需要图形边缘，但可以在不考虑边缘的情况下学习结构感知的MLP。

    

    将高精度的图神经网络（GNN）在图任务中压缩成低延迟的多层感知器（MLP）已成为热门研究课题。以前的方法会将图的边缘处理成额外的输入给MLP，但这样的图结构对于各种场景可能无法获得。因此，我们提出了一种原型引导知识蒸馏（PGKD）方法，它不需要图形边缘，但可以在不考虑边缘的情况下学习结构感知的MLP。具体而言，我们分析了GNN教师中的图形结构信息，并通过原型在无边缘设置中从GNN到MLP进行了知识蒸馏。在流行的图形基准实验中的实验结果表明了所提出的PGKD方法的有效性和鲁棒性。

    Distilling high-accuracy Graph Neural Networks~(GNNs) to low-latency multilayer perceptrons~(MLPs) on graph tasks has become a hot research topic. However, MLPs rely exclusively on the node features and fail to capture the graph structural information. Previous methods address this issue by processing graph edges into extra inputs for MLPs, but such graph structures may be unavailable for various scenarios. To this end, we propose a Prototype-Guided Knowledge Distillation~(PGKD) method, which does not require graph edges~(edge-free) yet learns structure-aware MLPs. Specifically, we analyze the graph structural information in GNN teachers, and distill such information from GNNs to MLPs via prototypes in an edge-free setting. Experimental results on popular graph benchmarks demonstrate the effectiveness and robustness of the proposed PGKD.
    
[^33]: 人工智能在可持续性方面的应用: 利用计算机视觉促进可持续智能产品-服务系统。

    Artificial Intelligence for Sustainability: Facilitating Sustainable Smart Product-Service Systems with Computer Vision. (arXiv:2303.13540v1 [cs.LG])

    [http://arxiv.org/abs/2303.13540](http://arxiv.org/abs/2303.13540)

    本论文在可持续性方面的主要贡献是使用深度学习技术提高产品生产和使用的可持续性，通过计算机视觉技术检测产品的磨损状态并用于改进智能产品-服务系统的集成和结果取向。

    

    目前使用深度学习来实现清洁生产和可持续性目的的研究还非常有限。本论文展示了如何利用深度学习技术提高产品生产和使用的可持续性，尤其是采用深度学习的计算机视觉技术来识别产品的磨损状态，并将这些结果用于改进智能产品-服务系统的集成和结果取向。此外，这些成果预计将促进产品使用的改进和研发创新。我们在两种产品上演示了我们的方法:加工工具和旋转X射线阳极。

    The usage and impact of deep learning for cleaner production and sustainability purposes remain little explored. This work shows how deep learning can be harnessed to increase sustainability in production and product usage. Specifically, we utilize deep learning-based computer vision to determine the wear states of products. The resulting insights serve as a basis for novel product-service systems with improved integration and result orientation. Moreover, these insights are expected to facilitate product usage improvements and R&D innovations. We demonstrate our approach on two products: machining tools and rotating X-ray anodes. From a technical standpoint, we show that it is possible to recognize the wear state of these products using deep-learning-based computer vision. In particular, we detect wear through microscopic images of the two products. We utilize a U-Net for semantic segmentation to detect wear based on pixel granularity. The resulting mean dice coefficients of 0.631 and
    
[^34]: DreamBooth3D：主体驱动的文本到3D生成

    DreamBooth3D: Subject-Driven Text-to-3D Generation. (arXiv:2303.13508v1 [cs.CV])

    [http://arxiv.org/abs/2303.13508](http://arxiv.org/abs/2303.13508)

    DreamBooth3D是一种可从3-6张图片中生成主体特定3D素材的方法，通过结合文本到图像模型和文本到3D生成模型，使用一种三阶段的优化策略来产生高质量3D素材。

    

    我们提出了DreamBooth3D方法，该方法可以从3-6个随意拍摄的主体图像个性化生成文本到3D模型。我们的方法将个性化文本到图像模型(DreamBooth)与文本到3D生成(DreamFusion)的最新进展相结合。我们发现，简单地将这些方法组合起来无法产生令人满意的主体特定的3D素材，因为个性化的文本到图像模型会过度拟合主体图像的输入视角。我们通过三阶段的优化策略解决了这个问题，其中我们同时利用了神经辐射场的3D一致性和文本到图像模型的个性化能力。我们的方法可以产生高质量、主体特定的3D素材，具有文本驱动的修改，如新颖的姿势、颜色和属性，这些修改在主体的任何输入图像中都没有看到。

    We present DreamBooth3D, an approach to personalize text-to-3D generative models from as few as 3-6 casually captured images of a subject. Our approach combines recent advances in personalizing text-to-image models (DreamBooth) with text-to-3D generation (DreamFusion). We find that naively combining these methods fails to yield satisfactory subject-specific 3D assets due to personalized text-to-image models overfitting to the input viewpoints of the subject. We overcome this through a 3-stage optimization strategy where we jointly leverage the 3D consistency of neural radiance fields together with the personalization capability of text-to-image models. Our method can produce high-quality, subject-specific 3D assets with text-driven modifications such as novel poses, colors and attributes that are not seen in any of the input images of the subject.
    
[^35]: 大型语言模型的公正引导少样本提示

    Fairness-guided Few-shot Prompting for Large Language Models. (arXiv:2303.13217v1 [cs.CL])

    [http://arxiv.org/abs/2303.13217](http://arxiv.org/abs/2303.13217)

    本文提出了一种新的搜索策略-FairPrompt，在保证公正性的前提下，通过评估提示预测偏差，确定近似最优的提示，从而改进大型语言模型的上下文学习性能，实验表明该方法在准确性和公正性方面均优于现有方法。

    

    大型语言模型已经表现出惊人的能力，能够通过几个输入输出示例构建的提示进行直接应用来解决众多下游任务。但是，先前的研究表明，由于训练示例，示例顺序和提示格式的变化导致上下文学习容易出现高度不稳定性。因此，构建适当的提示对于改进上下文学习的性能至关重要。在这篇文章中，我们从预测偏差的角度重新探讨了这个问题。具体而言，我们引入了一个指标来评估固定提示相对于标签或给定属性的预测偏差。然后我们通过实验证明了预测偏差较大的提示总是导致不令人满意的预测质量。基于这个观察，我们提出了一种新的搜索策略，基于贪婪搜索来确定近似最优的提示，从而改进上下文学习的性能。我们提出的方法叫做"公正提示"，其中融入了公平性约束，以指导搜索不展现出对某些人群的偏见。我们在多种少样本分类任务上证明了FairPrompt的有效性，并展示了它在准确性和公正性方面均优于现有的最先进方法。

    Large language models have demonstrated surprising ability to perform in-context learning, i.e., these models can be directly applied to solve numerous downstream tasks by conditioning on a prompt constructed by a few input-output examples. However, prior research has shown that in-context learning can suffer from high instability due to variations in training examples, example order, and prompt formats. Therefore, the construction of an appropriate prompt is essential for improving the performance of in-context learning. In this paper, we revisit this problem from the view of predictive bias. Specifically, we introduce a metric to evaluate the predictive bias of a fixed prompt against labels or a given attributes. Then we empirically show that prompts with higher bias always lead to unsatisfactory predictive quality. Based on this observation, we propose a novel search strategy based on the greedy search to identify the near-optimal prompt for improving the performance of in-context l
    
[^36]: MagicFusion：通过融合扩散模型提高文本到图像生成的性能

    MagicFusion: Boosting Text-to-Image Generation Performance by Fusing Diffusion Models. (arXiv:2303.13126v1 [cs.CV])

    [http://arxiv.org/abs/2303.13126](http://arxiv.org/abs/2303.13126)

    本论文提出了一种名为SNB的方法，该方法集成了两个文本指导扩散模型的噪声预测，以实现更可控的图像生成，同时不需要额外的训练或注释。

    

    开源AI社区的出现产生了一系列强大的基于文本的扩散模型，这些模型训练在各种数据集上。本文提出了一种名为“Saliency-aware Noise Blending (SNB)” 的简单且有效的方法，可以使融合的文本指导扩散模型实现更可控的生成。实验证明分类器自由指导的响应与生成图像的显着性高度相关，因此我们提出了一种在显着性感知的情况下混合两个扩散模型的预测噪声来信任其专业领域的不同模型的方法。SNB是无需训练即可完成的，并且可以在DDIM采样过程中自动对齐两个噪声空间的语义，而无需额外的注释，例如掩模。大量的实验展示了SNB的显着有效性

    The advent of open-source AI communities has produced a cornucopia of powerful text-guided diffusion models that are trained on various datasets. While few explorations have been conducted on ensembling such models to combine their strengths. In this work, we propose a simple yet effective method called Saliency-aware Noise Blending (SNB) that can empower the fused text-guided diffusion models to achieve more controllable generation. Specifically, we experimentally find that the responses of classifier-free guidance are highly related to the saliency of generated images. Thus we propose to trust different models in their areas of expertise by blending the predicted noises of two diffusion models in a saliency-aware manner. SNB is training-free and can be completed within a DDIM sampling process. Additionally, it can automatically align the semantics of two noise spaces without requiring additional annotations such as masks. Extensive experiments show the impressive effectiveness of SNB
    
[^37]: SPeC：软提示校准在临床笔记摘要中降低性能变异的研究

    SPeC: A Soft Prompt-Based Calibration on Mitigating Performance Variability in Clinical Notes Summarization. (arXiv:2303.13035v1 [cs.CL])

    [http://arxiv.org/abs/2303.13035](http://arxiv.org/abs/2303.13035)

    研究通过引入软提示嵌入，提出Soft Prompt-Based Calibration (SPeC)管道，来减轻输入变量对输出多样性的影响，降低性能变异. 此方法不仅比大语言模型(LLM)性能稳定，而且在临床笔记摘要任务上表现优于最先进的模型.

    

    电子健康记录（EHR）存储着包括病历、诊断、治疗和检测结果在内的大量患者信息。这些记录对于医疗保健专业人员做出明智的患者护理决策非常关键。摘要临床笔记可以帮助医疗保健专业人员更好地发现潜在健康风险，以及做出更好的决策。这一过程通过确保医疗保健专业人员可以访问最相关和最新的患者数据，有助于减少错误并提高患者的护理效果。最近的研究表明，将提示与大语言模型（LLM）相结合可以显著提高摘要任务的效率。然而，我们发现这种方法也会导致输出方差增加，即使提示意义相似，输出也会有明显的差异。为了解决这一挑战，我们引入了一个模型无关的软提示校准（SPeC）流程，该流程采用软提示嵌入来减轻输入变量对输出多样性的影响。我们的实验表明，SPeC不仅可以降低LLM的性能变异，而且在临床笔记摘要任务上优于现有的最先进模型。

    Electronic health records (EHRs) store an extensive array of patient information, encompassing medical histories, diagnoses, treatments, and test outcomes. These records are crucial for enabling healthcare providers to make well-informed decisions regarding patient care. Summarizing clinical notes further assists healthcare professionals in pinpointing potential health risks and making better-informed decisions. This process contributes to reducing errors and enhancing patient outcomes by ensuring providers have access to the most pertinent and current patient data. Recent research has shown that incorporating prompts with large language models (LLMs) substantially boosts the efficacy of summarization tasks. However, we show that this approach also leads to increased output variance, resulting in notably divergent outputs even when prompts share similar meanings. To tackle this challenge, we introduce a model-agnostic Soft Prompt-Based Calibration (SPeC) pipeline that employs soft prom
    
[^38]: 临床基础模型的不稳定基础：针对 EMR 的大语言模型和基础模型的调查

    The Shaky Foundations of Clinical Foundation Models: A Survey of Large Language Models and Foundation Models for EMRs. (arXiv:2303.12961v1 [cs.LG])

    [http://arxiv.org/abs/2303.12961](http://arxiv.org/abs/2303.12961)

    本论文回顾了超过80个在非成像 EMR 数据上训练的基础模型，发现这些模型大多范围有限、训练集有限，且评估指标未对其对医疗系统贡献提供有意义见解。因此，本研究提出了一种更接近于医疗保健重要指标的医疗基础模型效益评估框架。

    

    类似 ChatGPT 和 AlphaFold 的基础模型的成功引发了人们对于构建类似模型以改善 EMR（电子病历）以提高患者护理和医院运营的极大兴趣。然而，最近的炒作掩盖了我们对这些模型能力的关键缺失。我们回顾了超过80个在非成像 EMR 数据（即临床文本和/或结构化数据）上训练的基础模型，并创建了一个分类法来说明它们的体系结构、训练数据和潜在用例。我们发现大多数模型是在小型、范围有限的临床数据集（例如MIMIC-III）或广泛的公共生物医学语料库（例如PubMed）上进行训练的，并且在不提供对其对医疗系统有用处的有意义见解的任务上进行评估。基于这些发现，我们提出了一种更接近于医疗保健重要指标的医疗基础模型效益的改进评估框架。

    The successes of foundation models such as ChatGPT and AlphaFold have spurred significant interest in building similar models for electronic medical records (EMRs) to improve patient care and hospital operations. However, recent hype has obscured critical gaps in our understanding of these models' capabilities. We review over 80 foundation models trained on non-imaging EMR data (i.e. clinical text and/or structured data) and create a taxonomy delineating their architectures, training data, and potential use cases. We find that most models are trained on small, narrowly-scoped clinical datasets (e.g. MIMIC-III) or broad, public biomedical corpora (e.g. PubMed) and are evaluated on tasks that do not provide meaningful insights on their usefulness to health systems. In light of these findings, we propose an improved evaluation framework for measuring the benefits of clinical foundation models that is more closely grounded to metrics that matter in healthcare.
    
[^39]: LLM是万能的大师吗？探索LLM的领域不可知推理技能。

    Are LLMs the Master of All Trades? : Exploring Domain-Agnostic Reasoning Skills of LLMs. (arXiv:2303.12810v1 [cs.CL])

    [http://arxiv.org/abs/2303.12810](http://arxiv.org/abs/2303.12810)

    本文探究了大型语言模型(LLM)在不同领域推理任务上的表现，并发现LLM在类比和道德推理方面表现出色，在空间推理任务上表现较差。这对于LLM未来的发展具有重要意义。

    

    大型语言模型(LLM)类似于人类推理的潜力一直是机器学习界争议最激烈的话题之一。然而，人类的推理能力是多方面的，可以通过各种形式进行体现，包括类比、空间和道德推理等。这一事实引发了一个问题，LLM能否在所有这些不同领域中同样表现出色。本研究旨在通过直接使用或从现有类比和空间推理数据集中汲取启示，对LLM在不同推理任务上的表现进行研究。此外，为了评估LLM像人类一样推理的能力，研究还对更开放、自然的语言问题进行了评估。我的研究结果表明，LLM在类比和道德推理方面表现出色，但在空间推理任务上表现得不够熟练。我认为这些实验对于推动LLM未来的发展，特别是在改进空间推理能力方面具有重要意义。

    The potential of large language models (LLMs) to reason like humans has been a highly contested topic in Machine Learning communities. However, the reasoning abilities of humans are multifaceted and can be seen in various forms, including analogical, spatial and moral reasoning, among others. This fact raises the question whether LLMs can perform equally well across all these different domains. This research work aims to investigate the performance of LLMs on different reasoning tasks by conducting experiments that directly use or draw inspirations from existing datasets on analogical and spatial reasoning. Additionally, to evaluate the ability of LLMs to reason like human, their performance is evaluted on more open-ended, natural language questions. My findings indicate that LLMs excel at analogical and moral reasoning, yet struggle to perform as proficiently on spatial reasoning tasks. I believe these experiments are crucial for informing the future development of LLMs, particularly 
    
[^40]: 智能化的民主化：多种含义、目标和方法

    Democratising AI: Multiple Meanings, Goals, and Methods. (arXiv:2303.12642v1 [cs.AI])

    [http://arxiv.org/abs/2303.12642](http://arxiv.org/abs/2303.12642)

    这篇论文探讨了AI的民主化，包括四种类型的民主化：AI使用的民主化，AI开发的民主化，AI利润的民主化，和AI治理的民主化。要想实现有效的政策和权衡讨论，需要认识到AI治理的民主化在决策中扮演着重要的角色。

    

    许多人呼吁实现AI的民主化，但这个词语用来指代多种目标，有时会相互冲突。本文确定了通常讨论的四种AI民主化类型：(1) AI使用的民主化，(2) AI开发的民主化，(3) AI利润的民主化，和(4) AI治理的民主化。本文讨论了实现每种民主化形式的多个目标和方法。从本文中主要得出的结论是，AI的民主化是一个多元而有时会相互冲突的概念，不应混淆AI可访问性的改善。如果我们想要超越对智能化民主化的模糊承诺，进入具体政策和权衡的生产性讨论，我们需要认识到AI治理的民主化在跨越关于使用、开发和利润的决策中导航权衡和风险的主要作用。

    Numerous parties are calling for the democratisation of AI, but the phrase is used to refer to a variety of goals, the pursuit of which sometimes conflict. This paper identifies four kinds of AI democratisation that are commonly discussed: (1) the democratisation of AI use, (2) the democratisation of AI development, (3) the democratisation of AI profits, and (4) the democratisation of AI governance. Numerous goals and methods of achieving each form of democratisation are discussed. The main takeaway from this paper is that AI democratisation is a multifarious and sometimes conflicting concept that should not be conflated with improving AI accessibility. If we want to move beyond ambiguous commitments to democratising AI, to productive discussions of concrete policies and trade-offs, then we need to recognise the principal role of the democratisation of AI governance in navigating tradeoffs and risks across decisions around use, development, and profits.
    
[^41]: 揭示与修正：一种可解释的深度模型迭代偏差校正生命周期

    Reveal to Revise: An Explainable AI Life Cycle for Iterative Bias Correction of Deep Models. (arXiv:2303.12641v1 [cs.CV])

    [http://arxiv.org/abs/2303.12641](http://arxiv.org/abs/2303.12641)

    本文提出一个可解释的AI生命周期框架（R2R），允许从业者逐步识别、减少和重新评估深度学习模型数据偏差，包括寻找异常值、检测负责的文物、空间定位和修改模型的行为。

    

    最先进的机器学习模型通常会学习训练数据中嵌入的虚假相关性。当将这些模型用于高风险决策，如皮肤癌检测等医疗应用时，这会带来风险。为解决这个问题，本文提出了一种名为“揭示与修正”的框架，其中包括整个可解释人工智能(XAI)生命周期，使从业者能够逐步识别、减少和(重新)评估虚假模型行为，并最大程度地减少人类干预。

    State-of-the-art machine learning models often learn spurious correlations embedded in the training data. This poses risks when deploying these models for high-stake decision-making, such as in medical applications like skin cancer detection. To tackle this problem, we propose Reveal to Revise (R2R), a framework entailing the entire eXplainable Artificial Intelligence (XAI) life cycle, enabling practitioners to iteratively identify, mitigate, and (re-)evaluate spurious model behavior with a minimal amount of human interaction. In the first step (1), R2R reveals model weaknesses by finding outliers in attributions or through inspection of latent concepts learned by the model. Secondly (2), the responsible artifacts are detected and spatially localized in the input data, which is then leveraged to (3) revise the model behavior. Concretely, we apply the methods of RRR, CDEP and ClArC for model correction, and (4) (re-)evaluate the model's performance and remaining sensitivity towards the 
    
[^42]: $P^{3}O$: Prompting方法中用于强化学习的视觉表示迁移

    $P^{3}O$: Transferring Visual Representations for Reinforcement Learning via Prompting. (arXiv:2303.12371v1 [cs.CV])

    [http://arxiv.org/abs/2303.12371](http://arxiv.org/abs/2303.12371)

    本论文提出一种名为$P^{3}O$的三阶段DRL算法，通过提问来转移视觉表示，显著优于现有的视觉传输方案。

    

    在深度强化学习算法中，将学到的策略转移至视觉输入不同的新环境是非常重要的。本文提出了一种基于Prompt的近端策略优化($P^{3}O$)的三阶段DRL算法，通过应用Prompt使得视觉表示从目标环境传递到源环境。$P^{3}O$的过程包括三个阶段:预训练、Prompting和预测。我们提出了一个Prompt-Transformer用于表示转换，并针对目标环境提出了一个两步训练过程，训练Prompt-Transformer，而DRL管道的其余部分保持不变。我们在OpenAI CarRacing视频游戏上实施$P^{3}O$并进行评估。实验结果表明，$P^{3}O$优于最先进的视觉转移方案，而且能让学到的策略在视觉输入不同的环境中表现良好，这是非常重要的。

    It is important for deep reinforcement learning (DRL) algorithms to transfer their learned policies to new environments that have different visual inputs. In this paper, we introduce Prompt based Proximal Policy Optimization ($P^{3}O$), a three-stage DRL algorithm that transfers visual representations from a target to a source environment by applying prompting. The process of $P^{3}O$ consists of three stages: pre-training, prompting, and predicting. In particular, we specify a prompt-transformer for representation conversion and propose a two-step training process to train the prompt-transformer for the target environment, while the rest of the DRL pipeline remains unchanged. We implement $P^{3}O$ and evaluate it on the OpenAI CarRacing video game. The experimental results show that $P^{3}O$ outperforms the state-of-the-art visual transferring schemes. In particular, $P^{3}O$ allows the learned policies to perform well in environments with different visual inputs, which is much more e
    
[^43]: 可自我修正和自适应推理的通用人体姿态估计方法

    Self-Correctable and Adaptable Inference for Generalizable Human Pose Estimation. (arXiv:2303.11180v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2303.11180](http://arxiv.org/abs/2303.11180)

    本文提出了可自我修正和自适应推理的通用人体姿态估计方法，通过学习一个校正网络和健康反馈网络来解决网络预测的泛化挑战。

    

    人体姿态估计中的一个主要挑战是泛化问题，即学习的网络无法对预测误差进行特征化，不能从测试样本中生成反馈信息并针对每个测试样本动态修正预测误差，导致泛化性能下降。本文引入自我修正和自适应推理（SCAI）方法来解决网络预测的泛化挑战，并以人体姿态估计为例来展示其有效性和性能。

    A central challenge in human pose estimation, as well as in many other machine learning and prediction tasks, is the generalization problem. The learned network does not have the capability to characterize the prediction error, generate feedback information from the test sample, and correct the prediction error on the fly for each individual test sample, which results in degraded performance in generalization. In this work, we introduce a self-correctable and adaptable inference (SCAI) method to address the generalization challenge of network prediction and use human pose estimation as an example to demonstrate its effectiveness and performance. We learn a correction network to correct the prediction result conditioned by a fitness feedback error. This feedback error is generated by a learned fitness feedback network which maps the prediction result to the original input domain and compares it against the original input. Interestingly, we find that this self-referential feedback error 
    
[^44]: 不看就能旋转: 通过触觉实现手部灵活性

    Rotating without Seeing: Towards In-hand Dexterity through Touch. (arXiv:2303.10880v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2303.10880](http://arxiv.org/abs/2303.10880)

    本研究提出了一种新系统Touch Dexterity，通过密集二进制力传感器实现了多指机器人手不看就能旋转物体，同时大大降低了成本和与实际应用的差距。

    

    触感信息在人类灵巧性中扮演着至关重要的角色，它可以提供有用的接触信息，直接从视觉中无法推断。这篇论文探讨了是否能够使多指机器人手具备与人类类似的不看就能旋转物体的能力。作者们提出了一个新的系统Touch Dexterity，通过使用覆盖整个机器人手的密集二进制力传感器（触摸或未触摸）代替仅仅在小区域内进行精准的触觉传感，使系统具有低成本、覆盖范围广等优点，并通过强化学习在多样的物体模拟中训练出了一种触感旋转策略，能够在真实的机器人手上直接实施不看就能旋转新型物体。

    Tactile information plays a critical role in human dexterity. It reveals useful contact information that may not be inferred directly from vision. In fact, humans can even perform in-hand dexterous manipulation without using vision. Can we enable the same ability for the multi-finger robot hand? In this paper, we present Touch Dexterity, a new system that can perform in-hand object rotation using only touching without seeing the object. Instead of relying on precise tactile sensing in a small region, we introduce a new system design using dense binary force sensors (touch or no touch) overlaying one side of the whole robot hand (palm, finger links, fingertips). Such a design is low-cost, giving a larger coverage of the object, and minimizing the Sim2Real gap at the same time. We train an in-hand rotation policy using Reinforcement Learning on diverse objects in simulation. Relying on touch-only sensing, we can directly deploy the policy in a real robot hand and rotate novel objects tha
    
[^45]: Among Us: 基于共识的反对抗鲁棒协同感知

    Among Us: Adversarially Robust Collaborative Perception by Consensus. (arXiv:2303.09495v1 [cs.RO])

    [http://arxiv.org/abs/2303.09495](http://arxiv.org/abs/2303.09495)

    ROBOSAC提出了一种基于共识的反对抗鲁棒协同感知防御策略，使用随机子集的队友来对比协同感知和单个感知的结果，以排除潜在攻击者，并推导出确保获得所需无攻击者子集所需的采样试验个数。

    

    多个机器人之间的协同感知能够比单个机器人更好地感知场景(例如，检测物体)，但在使用深度学习时很容易受到敌对攻击。这一问题可通过对抗性防御来解决，但训练需要了解攻击机制，而这通常是未知的。因此，我们提出了 ROBOSAC，一种基于采样的新型防御策略，该策略具有泛化能力，能应对未知的攻击者。我们的核心思想是，协同感知应该比单个感知更能达成一致，而不应相互产生分歧。这导致我们提出了一种假说和验证的框架：利用一组随机选择的队友，对协同感知与单个感知的结果进行比较，直到达成共识。在这样的框架下，更多的队友通常意味着更好的感知表现，但需要更长的采样时间来排除潜在的攻击者。因此，我们推导出了需要多少个采样试验才能确保获得所需的无攻击者子集。

    Multiple robots could perceive a scene (e.g., detect objects) collaboratively better than individuals, although easily suffer from adversarial attacks when using deep learning. This could be addressed by the adversarial defense, but its training requires the often-unknown attacking mechanism. Differently, we propose ROBOSAC, a novel sampling-based defense strategy generalizable to unseen attackers. Our key idea is that collaborative perception should lead to consensus rather than dissensus in results compared to individual perception. This leads to our hypothesize-and-verify framework: perception results with and without collaboration from a random subset of teammates are compared until reaching a consensus. In such a framework, more teammates in the sampled subset often entail better perception performance but require longer sampling time to reject potential attackers. Thus, we derive how many sampling trials are needed to ensure the desired size of an attacker-free subset, or equival
    
[^46]: GPT-4技术报告

    GPT-4 Technical Report. (arXiv:2303.08774v1 [cs.CL])

    [http://arxiv.org/abs/2303.08774](http://arxiv.org/abs/2303.08774)

    GPT-4是一个大规模多模态模型，可以接收图像和文本输入并产生文本输出，能够在各种专业和学术基准测试中表现出人类水平的表现，包括通过模拟的律师考试。该项目的核心组件是开发基础设施和优化方法，可在广泛的规模范围内表现预测性。

    

    我们报告了GPT-4的开发，它是一个可以接受图像和文本输入并产生文本输出的大规模多模态模型。虽然在许多现实场景中不如人类，但GPT-4在各种专业和学术基准测试中表现出人类水平的表现，包括通过模拟的律师考试，成绩排名在前10％左右。GPT-4是一个基于Transformer的模型，预训练用于预测文档中的下一个标记。后训练对齐过程提高了事实性和符合期望行为的性能指标。项目的核心组件是开发基础设施和优化方法，可在广泛的规模范围内表现预测性。这使我们能够准确预测GPT-4的某些性能方面，而这些性能是基于使用不超过GPT-4计算能力的1/1,000的模型训练的。

    We report the development of GPT-4, a large-scale, multimodal model which can accept image and text inputs and produce text outputs. While less capable than humans in many real-world scenarios, GPT-4 exhibits human-level performance on various professional and academic benchmarks, including passing a simulated bar exam with a score around the top 10% of test takers. GPT-4 is a Transformer-based model pre-trained to predict the next token in a document. The post-training alignment process results in improved performance on measures of factuality and adherence to desired behavior. A core component of this project was developing infrastructure and optimization methods that behave predictably across a wide range of scales. This allowed us to accurately predict some aspects of GPT-4's performance based on models trained with no more than 1/1,000th the compute of GPT-4.
    
[^47]: NL4Opt 比赛：基于自然语言描述构建优化问题

    NL4Opt Competition: Formulating Optimization Problems Based on Their Natural Language Descriptions. (arXiv:2303.08233v1 [cs.CL])

    [http://arxiv.org/abs/2303.08233](http://arxiv.org/abs/2303.08233)

    NL4Opt比赛旨在研究如何从自然语言描述中提取出优化问题的含义和表述，并通过自然语言与非专业人士进行交互。竞赛分为两个子任务：(1) 识别和标记对应于优化问题组件的语义实体;(2)从检测到的问题实体生成意义表示(即逻辑形式)。

    

    自然语言优化（NL4Opt）竞赛旨在研究如何根据优化问题的文本描述提取其含义和表述的方法。具体而言，该竞赛的目标是通过使用自然语言中介来使非专业人士能够接口使用优化求解器，以增加其可访问性和可用性。我们将这一挑战性目标分为两个子任务：(1)识别和标记对应于优化问题组件的语义实体;(2)从检测到的问题实体生成意义表示(即逻辑形式)。第一个任务旨在通过检测和标记优化问题的实体来减少歧义。第二个任务创建了一个线性规划(LP)问题的中间表示，该中间表示被转换为商用求解器可用的格式。在本报告中，我们介绍了LP单词问题数据集和NL4Opt比赛的共享任务，并总结了竞赛条目的结果。

    The Natural Language for Optimization (NL4Opt) Competition was created to investigate methods of extracting the meaning and formulation of an optimization problem based on its text description. Specifically, the goal of the competition is to increase the accessibility and usability of optimization solvers by allowing non-experts to interface with them using natural language. We separate this challenging goal into two sub-tasks: (1) recognize and label the semantic entities that correspond to the components of the optimization problem; (2) generate a meaning representation (i.e., a logical form) of the problem from its detected problem entities. The first task aims to reduce ambiguity by detecting and tagging the entities of the optimization problems. The second task creates an intermediate representation of the linear programming (LP) problem that is converted into a format that can be used by commercial solvers. In this report, we present the LP word problem dataset and shared tasks f
    
[^48]: MEDBERT.de：一个基于德语的、针对医学领域专门设计的全面BERT模型

    MEDBERT.de: A Comprehensive German BERT Model for the Medical Domain. (arXiv:2303.08179v1 [cs.CL])

    [http://arxiv.org/abs/2303.08179](http://arxiv.org/abs/2303.08179)

    本文介绍了medBERT.de，这是一个用于德语医学领域的BERT模型，通过在大规模语料库上的训练，在八个不同的医学基准测试中取得最新的最先进的表现。该模型对长文本特别有用，而数据去重和有效的分词则只对模型性能产生了较小的影响。

    

    本文介绍了medBERT.de，这是一个针对德语医学领域专门设计的预训练BERT模型。该模型已经在470万份德语医学文档的大型语料库上进行了训练，并在八个不同的医学基准测试中取得了新的最先进的效果，涉及各种学科和医学文献类型。除了评估该模型的整体性能外，本文还对其能力进行了更深入的分析。我们研究了数据去重对模型性能的影响，以及使用更有效的分词方法的潜在好处。我们的结果表明，像medBERT.de这样的领域专用模型特别适用于较长的文本，并且数据去重不一定会导致性能改善。此外，我们发现有效的分词只在提高模型性能方面发挥了较小的作用，并且大多数改进源于模型的预训练。

    This paper presents medBERT.de, a pre-trained German BERT model specifically designed for the German medical domain. The model has been trained on a large corpus of 4.7 Million German medical documents and has been shown to achieve new state-of-the-art performance on eight different medical benchmarks covering a wide range of disciplines and medical document types. In addition to evaluating the overall performance of the model, this paper also conducts a more in-depth analysis of its capabilities. We investigate the impact of data deduplication on the model's performance, as well as the potential benefits of using more efficient tokenization methods. Our results indicate that domain-specific models such as medBERT.de are particularly useful for longer texts, and that deduplication of training data does not necessarily lead to improved performance. Furthermore, we found that efficient tokenization plays only a minor role in improving model performance, and attribute most of the improved
    
[^49]: 机器人导航的音视语言地图

    Audio Visual Language Maps for Robot Navigation. (arXiv:2303.07522v1 [cs.RO])

    [http://arxiv.org/abs/2303.07522](http://arxiv.org/abs/2303.07522)

    该论文提出了一种音视语言地图(AVLMaps)，用于存储跨模态信息，实现机器人根据多模态查询在地图中索引目标的导航方式。在模拟实验中，AVLMaps实现了从多模态提示的零次学习式多模态目标导航，并提供了更好的召回率。

    

    与世界的互动是一种多感官的体验，但是许多机器人仍然主要依赖视觉感知来绘制和导航他们的环境。本文提出了音视语言地图(AVLMaps)，这是一个统一的3D空间地图表示，用于存储来自音频、视觉和语言线索的跨模态信息。在导航的情境下，我们展示了AVLMaps能够使机器人系统根据多模态查询(例如，文本描述、图像或地标的音频片段)在地图中索引目标。特别是，添加音频信息使机器人能够更可靠地消除目标位置的歧义性。在模拟实验中，我们展示了AVLMaps能够实现从多模态提示进行零次学习的多模态目标导航，并在模糊场景中提供50%更好的召回率。

    While interacting in the world is a multi-sensory experience, many robots continue to predominantly rely on visual perception to map and navigate in their environments. In this work, we propose Audio-Visual-Language Maps (AVLMaps), a unified 3D spatial map representation for storing cross-modal information from audio, visual, and language cues. AVLMaps integrate the open-vocabulary capabilities of multimodal foundation models pre-trained on Internet-scale data by fusing their features into a centralized 3D voxel grid. In the context of navigation, we show that AVLMaps enable robot systems to index goals in the map based on multimodal queries, e.g., textual descriptions, images, or audio snippets of landmarks. In particular, the addition of audio information enables robots to more reliably disambiguate goal locations. Extensive experiments in simulation show that AVLMaps enable zero-shot multimodal goal navigation from multimodal prompts and provide 50% better recall in ambiguous scenar
    
[^50]: 降落伞：评估交互式人机共同撰写系统

    Parachute: Evaluating Interactive Human-LM Co-writing Systems. (arXiv:2303.06333v1 [cs.HC])

    [http://arxiv.org/abs/2303.06333](http://arxiv.org/abs/2303.06333)

    本文提出了一个以人为中心的评估框架Parachute，用于交互式共同撰写系统的评估，该框架包含了分类的实用指标，可以用于评估和比较共同撰写系统。

    This paper proposes a human-centered evaluation framework, Parachute, for interactive co-writing systems, which includes categorized practical metrics and can be used to evaluate and compare co-writing systems.

    语言模型的飞速发展引起了人们对于利用语言模型构建共同撰写系统的极大兴趣，其中人类和语言模型交互地为共同的写作成果做出贡献。然而，缺乏对于交互式环境下共同撰写系统的评估研究。我们提出了一个以人为中心的评估框架Parachute，用于交互式共同撰写系统的评估。Parachute展示了交互评估的综合视角，其中每个评估方面都包含了分类的实用指标。此外，我们提供了一个使用案例来演示如何使用Parachute评估和比较共同撰写系统。

    A surge of advances in language models (LMs) has led to significant interest in using LMs to build co-writing systems, in which humans and LMs interactively contribute to a shared writing artifact. However, there is a lack of studies assessing co-writing systems in interactive settings. We propose a human-centered evaluation framework, Parachute, for interactive co-writing systems. Parachute showcases an integrative view of interaction evaluation, where each evaluation aspect consists of categorized practical metrics. Furthermore, we present Parachute with a use case to demonstrate how to evaluate and compare co-writing systems using Parachute.
    
[^51]: 基于区域的联邦学习用于移动感知数据

    Zone-based Federated Learning for Mobile Sensing Data. (arXiv:2303.06246v1 [cs.LG])

    [http://arxiv.org/abs/2303.06246](http://arxiv.org/abs/2303.06246)

    本文提出了一种基于区域的联邦学习方法，用于训练移动感知数据的深度学习模型。该方法将物理空间划分为地理区域，并映射到移动边缘云系统架构，以实现良好的模型准确性和可扩展性。每个区域都有一个联合训练模型，能够很好地适应该区域用户的数据和行为，并保护用户数据隐私。

    This paper proposes a zone-based federated learning method for training deep learning models with mobile sensing data. The method divides the physical space into geographical zones and maps them to a mobile-edge-cloud system architecture for good model accuracy and scalability. Each zone has a federated training model that adapts well to the data and behaviors of users in that zone, while protecting user data privacy.

    移动应用程序，如mHealth和健康应用程序，可以从使用智能手机或可穿戴设备收集的移动感知数据训练的深度学习（DL）模型中受益。然而，目前没有移动感知DL系统能够同时实现良好的模型准确性，适应用户的移动行为，随着用户数量的增加而扩展，并保护用户数据隐私。我们提出了基于区域的联邦学习（ZoneFL）来解决这些要求。ZoneFL将物理空间划分为地理区域，映射到移动边缘云系统架构，以实现良好的模型准确性和可扩展性。每个区域都有一个联合训练模型，称为区域模型，它能够很好地适应该区域用户的数据和行为。受益于FL设计，ZoneFL培训期间保护用户数据隐私。我们提出了两种新颖的基于区域的联合训练算法来优化区域模型以适应用户的移动行为：区域合并和分裂（ZMS）和Zo

    Mobile apps, such as mHealth and wellness applications, can benefit from deep learning (DL) models trained with mobile sensing data collected by smart phones or wearable devices. However, currently there is no mobile sensing DL system that simultaneously achieves good model accuracy while adapting to user mobility behavior, scales well as the number of users increases, and protects user data privacy. We propose Zone-based Federated Learning (ZoneFL) to address these requirements. ZoneFL divides the physical space into geographical zones mapped to a mobile-edge-cloud system architecture for good model accuracy and scalability. Each zone has a federated training model, called a zone model, which adapts well to data and behaviors of users in that zone. Benefiting from the FL design, the user data privacy is protected during the ZoneFL training. We propose two novel zone-based federated training algorithms to optimize zone models to user mobility behavior: Zone Merge and Split (ZMS) and Zo
    
[^52]: 低开销模型剪枝：面向联邦学习的补充稀疏化

    Complement Sparsification: Low-Overhead Model Pruning for Federated Learning. (arXiv:2303.06237v1 [cs.LG])

    [http://arxiv.org/abs/2303.06237](http://arxiv.org/abs/2303.06237)

    本文提出了一种名为补充稀疏化的模型剪枝机制，通过在服务器和客户端之间进行互补和协作的剪枝来满足联邦学习中低双向通信开销、客户端低计算开销和良好模型准确性的要求。

    This paper proposes a model pruning mechanism called Complement Sparsification (CS), which satisfies the requirements of low bidirectional communication overhead between the server and the clients, low computation overhead at the clients, and good model accuracy in federated learning through complementary and collaborative pruning done at the server and the clients.

    联邦学习（FL）是一种隐私保护的分布式深度学习范例，涉及大量通信和计算工作，这对于资源受限的移动和物联网设备是一个问题。模型剪枝/稀疏化开发了可以解决此问题的稀疏模型，但现有的稀疏化解决方案不能同时满足服务器和客户端之间低双向通信开销、客户端低计算开销和良好模型准确性的要求，在FL假设下，服务器无法访问原始数据以微调修剪的模型。我们提出了补充稀疏化（CS），这是一种剪枝机制，通过在服务器和客户端之间进行互补和协作的剪枝来满足所有这些要求。在每一轮中，CS创建一个全局稀疏模型，其中包含捕获所有客户端的一般数据分布的权重，而客户端则创建本地稀疏模型。

    Federated Learning (FL) is a privacy-preserving distributed deep learning paradigm that involves substantial communication and computation effort, which is a problem for resource-constrained mobile and IoT devices. Model pruning/sparsification develops sparse models that could solve this problem, but existing sparsification solutions cannot satisfy at the same time the requirements for low bidirectional communication overhead between the server and the clients, low computation overhead at the clients, and good model accuracy, under the FL assumption that the server does not have access to raw data to fine-tune the pruned models. We propose Complement Sparsification (CS), a pruning mechanism that satisfies all these requirements through a complementary and collaborative pruning done at the server and the clients. At each round, CS creates a global sparse model that contains the weights that capture the general data distribution of all clients, while the clients create local sparse model
    
[^53]: 具有典型性的多值加权知识库中可撤销推理的复杂性和可扩展性

    Complexity and scalability of defeasible reasoning in many-valued weighted knowledge bases with typicality. (arXiv:2303.04534v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2303.04534](http://arxiv.org/abs/2303.04534)

    本文提出了一种基于典型性描述逻辑的加权知识库的推理方法，通过提供新的ASP编码填补现有研究的不足，复杂性项的理论分析推导了经典问题 $P^{NP[log]}$-完备性结果。

    

    针对具有典型性的描述逻辑的加权知识库，本文提出了一种基于“概念级”的多优先语义的逻辑解释方法，并显示出答案集编程（ASP）适用于处理有限多值情形下的可撤销推理。该文通过提供 $P^{NP[log]}$-完备性结果和具有大搜索空间的加权知识库的新的ASP编码来填补这一缺口。

    Weighted knowledge bases for description logics with typicality under a "concept-wise" multi-preferential semantics provide a logical interpretation of MultiLayer Perceptrons. In this context, Answer Set Programming (ASP) has been shown to be suitable for addressing defeasible reasoning in the finitely many-valued case, providing a $\Pi^p_2$ upper bound on the complexity of the problem, nonetheless leaving unknown the exact complexity and only providing a proof-of-concept implementation. This paper fulfils the lack by providing a $P^{NP[log]}$-completeness result and new ASP encodings that deal with weighted knowledge bases with large search spaces.
    
[^54]: 金融自然语言理解任务中的模型无关元学习

    Model-Agnostic Meta-Learning for Natural Language Understanding Tasks in Finance. (arXiv:2303.02841v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.02841](http://arxiv.org/abs/2303.02841)

    本文研究了金融领域自然语言理解任务中的模型无关元学习算法，取得了最先进的性能表现。

    

    金融领域的自然语言理解因缺乏标注数据和特殊语言而具有挑战性。近年来，研究人员提出使用预训练语言模型和多任务学习来学习稳健的表示。然而，过度微调经常导致过拟合，多任务学习可能会偏袒大量数据的任务。为了解决这些问题，本文研究了低资源金融自然语言理解任务中的模型无关元学习算法。我们的贡献包括：1.我们探索了使用多种类型任务的MAML方法的性能：GLUE数据集，SNLI，Sci-Tail和Financial PhraseBank；2.我们研究了在一个真实场景的基于推特文本的股票价格预测问题中使用MAML方法的性能。根据实验结果，我们的模型实现了最先进的性能，证明了我们的方法可以快速适应。

    Natural language understanding(NLU) is challenging for finance due to the lack of annotated data and the specialized language in that domain. As a result, researchers have proposed to use pre-trained language model and multi-task learning to learn robust representations. However, aggressive fine-tuning often causes over-fitting and multi-task learning may favor tasks with significantly larger amounts data, etc. To address these problems, in this paper, we investigate model-agnostic meta-learning algorithm(MAML) in low-resource financial NLU tasks. Our contribution includes: 1. we explore the performance of MAML method with multiple types of tasks: GLUE datasets, SNLI, Sci-Tail and Financial PhraseBank; 2. we study the performance of MAML method with multiple single-type tasks: a real scenario stock price prediction problem with twitter text data. Our models achieve the state-of-the-art performance according to the experimental results, which demonstrate that our method can adapt fast a
    
[^55]: 人工智能与FCI：ChatGPT能否理解初级物理？

    AI and the FCI: Can ChatGPT Project an Understanding of Introductory Physics?. (arXiv:2303.01067v2 [physics.ed-ph] UPDATED)

    [http://arxiv.org/abs/2303.01067](http://arxiv.org/abs/2303.01067)

    本研究以力学概念库评估了ChatGPT3.5和ChatGPT4在大学第一学期物理学领域的表现，结果显示ChatGPT3.5可以在某些方面匹配或超过传统教学的中位数表现。

    

    ChatGPT是一种突破性的“聊天机器人”，它是建立在一个大型语言模型上的人工智能接口，该模型是由大量人类文本训练而成，以模拟人类对话。除了能以一种合理的方式进行交谈，它还因其能够胜任律师考试和MBA课程的问题，并能提供编写计算机代码的有用帮助等能力而受到关注。这些明显的能力引发了有关ChatGPT作为高等教育完整性的威胁的讨论，反之亦然，它也是一种强大的教学工具。在这项工作中，我们提出了对两个版本的ChatGPT（ChatGPT3.5和ChatGPT4）在大学第一学期物理学领域的表现的初步分析，使用修改版的力学概念库（FCI），评估它是否能够正确回答关于运动学和牛顿动力学的概念物理问题。我们证明，从某些方面来看，ChatGPT3.5可以匹配或超过传统教学方法的中位数表现。

    ChatGPT is a groundbreaking ``chatbot"--an AI interface built on a large language model that was trained on an enormous corpus of human text to emulate human conversation. Beyond its ability to converse in a plausible way, it has attracted attention for its ability to competently answer questions from the bar exam and from MBA coursework, and to provide useful assistance in writing computer code. These apparent abilities have prompted discussion of ChatGPT as both a threat to the integrity of higher education and conversely as a powerful teaching tool. In this work we present a preliminary analysis of how two versions of ChatGPT (ChatGPT3.5 and ChatGPT4) fare in the field of first-semester university physics, using a modified version of the Force Concept Inventory (FCI) to assess whether it can give correct responses to conceptual physics questions about kinematics and Newtonian dynamics. We demonstrate that, by some measures, ChatGPT3.5 can match or exceed the median performance of a 
    
[^56]: 分布式子网规范用于遍历 Web

    Distributed Subweb Specifications for Traversing the Web. (arXiv:2302.14411v2 [cs.DB] UPDATED)

    [http://arxiv.org/abs/2302.14411](http://arxiv.org/abs/2302.14411)

    本文提出了一种分布式子网规范的 LTQP 方法，该方法通过让数据发布者能够建议查询来源以及引导数据使用者向相关且可靠的数据查询，解决了 LTQP 存在的性能和信息质量问题。

    

    基于链接遍历的查询处理（LTQP）在一组文档上评估 sparql 查询而不是单个数据集，通常被视为在理论上有趣但不实用的技术。然而，在数据的超集中心化越来越受到审查的时代，具有简单基于文档的界面的分散式数据网络具有吸引力，因为它使数据发布者能够控制其数据和访问权。虽然 LTQP 允许在这样的网络上评估复杂的查询，但由于包含数据的文档数量过多，它受到性能问题的困扰，同时也存在信息质量方面的担忧（由于提供此类文档的许多来源）。在现有的 LTQP 方法中，寻找要查询的来源的负担完全由数据使用者承担。本文认为，为了解决这些问题，数据发布者应该也能够建议感兴趣的来源，引导数据使用者使用相关且可靠的数据。

    Link Traversal-based Query Processing (ltqp), in which a sparql query is evaluated over a web of documents rather than a single dataset, is often seen as a theoretically interesting yet impractical technique. However, in a time where the hypercentralization of data has increasingly come under scrutiny, a decentralized Web of Data with a simple document-based interface is appealing, as it enables data publishers to control their data and access rights. While ltqp allows evaluating complex queries over such webs, it suffers from performance issues (due to the high number of documents containing data) as well as information quality concerns (due to the many sources providing such documents). In existing ltqp approaches, the burden of finding sources to query is entirely in the hands of the data consumer. In this paper, we argue that to solve these issues, data publishers should also be able to suggest sources of interest and guide the data consumer towards relevant and trustworthy data. W
    
[^57]: 意义的线性空间：视觉语言模型中的组合结构

    Linear Spaces of Meanings: Compositional Structures in Vision-Language Models. (arXiv:2302.14383v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.14383](http://arxiv.org/abs/2302.14383)

    本文研究了视觉语言模型中的组合结构，并提出了一种使用嵌入空间中较小集合的向量组合来近似表示来自编码器的表示形式的方法，将这些向量视为“理想单词”，并在CLIP的嵌入中以实验方式探索了这些结构的可用性。

    

    本文研究了预训练视觉语言模型（VLM）中的数据嵌入的组合结构。传统上，组合性与预先存在的词汇表中的单词嵌入的代数运算有关。相反，我们试图使用嵌入空间中较小集合的向量组合来近似表示来自编码器的表示形式。这些向量可以被看作是在模型的嵌入空间中直接生成概念的“理想单词”。我们首先从几何学的角度提出了理解组合结构的框架。然后，我们解释了VLM嵌入在概率上的这些组合结构的含义，并提供了它们在实践中产生的直觉。最后，我们在CLIP的嵌入中以实验方式探索了这些结构，并评估了它们在解决分类、去偏和检索等不同视觉语言任务中的有用性。我们的结果表明，嵌入空间中简单的线性代数运算可以实现与更复杂的方法相媲美甚至更好的性能，证明了所提出的意义的线性空间的有效性和可解释性。

    We investigate compositional structures in data embeddings from pre-trained vision-language models (VLMs). Traditionally, compositionality has been associated with algebraic operations on embeddings of words from a pre-existing vocabulary. In contrast, we seek to approximate representations from an encoder as combinations of a smaller set of vectors in the embedding space. These vectors can be seen as "ideal words" for generating concepts directly within the embedding space of the model. We first present a framework for understanding compositional structures from a geometric perspective. We then explain what these compositional structures entail probabilistically in the case of VLM embeddings, providing intuitions for why they arise in practice. Finally, we empirically explore these structures in CLIP's embeddings and we evaluate their usefulness for solving different vision-language tasks such as classification, debiasing, and retrieval. Our results show that simple linear algebraic o
    
[^58]: Im2Hands: 学习交互双手形状的关注隐式表示

    Im2Hands: Learning Attentive Implicit Representation of Interacting Two-Hand Shapes. (arXiv:2302.14348v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.14348](http://arxiv.org/abs/2302.14348)

    本文提出了Im2Hands，一个用于表示交互双手的神经隐式表示方法，可以产生高手到手和手到图像一致性的细粒度几何形态。

    

    我们提出了Implicit Two Hands (Im2Hands)，这是第一个用于表示两只交互手的神经隐式表示。 Im2Hands不同于现有的两只手重建方法，它们依赖于参数手模型和/或低分辨率网格，Im2Hands可以产生高手到手和手到图像一致性的两只手的细粒度几何形态。为了处理两只手的形态复杂性和交互上下文，Im2Hands通过两个新颖的基于注意力机制的模块来建模两只手的占用体积 - 一个负责初始占用估计，一个负责上下文感知的占用精化。Im2Hands首先使用查询-图像注意力在为每个手设计的规范空间中学习每只手的神经关节占用，然后使用查询-锚点注意力在姿势空间中优化两只手的初始占用以增强两只手形状之间的一致性。此外，我们引入一个可选的关键点精化步骤。

    We present Implicit Two Hands (Im2Hands), the first neural implicit representation of two interacting hands. Unlike existing methods on two-hand reconstruction that rely on a parametric hand model and/or low-resolution meshes, Im2Hands can produce fine-grained geometry of two hands with high hand-to-hand and hand-to-image coherency. To handle the shape complexity and interaction context between two hands, Im2Hands models the occupancy volume of two hands - conditioned on an RGB image and coarse 3D keypoints - by two novel attention-based modules responsible for (1) initial occupancy estimation and (2) context-aware occupancy refinement, respectively. Im2Hands first learns per-hand neural articulated occupancy in the canonical space designed for each hand using query-image attention. It then refines the initial two-hand occupancy in the posed space to enhance the coherency between the two hand shapes using query-anchor attention. In addition, we introduce an optional keypoint refinement
    
[^59]: VoxFormer： 基于稀疏体素变换的基于相机的三维语义场景补全

    VoxFormer: Sparse Voxel Transformer for Camera-based 3D Semantic Scene Completion. (arXiv:2302.12251v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.12251](http://arxiv.org/abs/2302.12251)

    VoxFormer是一个基于变换器的语义场景补全框架，可以仅从2D图像输出完整的三维体积语义。它采用两阶段设计，从可见的体素查询开始，并通过自我注意来传播信息，实现了有效的三维场景补全。

    

    人类很容易想象被遮挡物体和场景的完整三维几何形状，在识别和理解方面至关重要。为了使AI系统具备这种能力，我们提出了VoxFormer，这是一个基于变换器的语义场景补全框架，可以仅从2D图像输出完整的三维体积语义。我们的框架采用两阶段设计，从深度估计的稀疏可见和占用体素查询开始，随后进行生成稠密3D体素的稠密化阶段。这个设计的一个关键思想是，2D图像上的视觉特征仅对应于可见场景结构而不是遮挡或空间。因此，从可见结构的特征化和预测开始更加可靠。一旦我们获得了一组稀疏查询，我们就应用掩码自编码器设计通过自我注意将信息传播到所有体素。在SemanticKITTI上的实验表明了我们的方法的有效性。

    Humans can easily imagine the complete 3D geometry of occluded objects and scenes. This appealing ability is vital for recognition and understanding. To enable such capability in AI systems, we propose VoxFormer, a Transformer-based semantic scene completion framework that can output complete 3D volumetric semantics from only 2D images. Our framework adopts a two-stage design where we start from a sparse set of visible and occupied voxel queries from depth estimation, followed by a densification stage that generates dense 3D voxels from the sparse ones. A key idea of this design is that the visual features on 2D images correspond only to the visible scene structures rather than the occluded or empty spaces. Therefore, starting with the featurization and prediction of the visible structures is more reliable. Once we obtain the set of sparse queries, we apply a masked autoencoder design to propagate the information to all the voxels by self-attention. Experiments on SemanticKITTI show th
    
[^60]: HumanMAC：用于人体运动预测的掩码动作修复

    HumanMAC: Masked Motion Completion for Human Motion Prediction. (arXiv:2302.03665v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.03665](http://arxiv.org/abs/2302.03665)

    HumanMAC是一个掩码动作修复框架，通过训练阶段的运动扩散模型和推断阶段的去噪过程，在观察到的运动数据的控制下进行运动预测，并在多个基准数据集上展示了显著的改进。

    

    人体运动预测是计算机视觉和计算机图形学中的一个经典问题，具有广泛的实际应用。以编码-解码风格为基础的先前方法在经验性能方面取得了巨大的成功，但实际上仍存在一些问题，包括复杂的损失约束、繁琐的培训过程以及预测中不同类别运动的稀缺切换。本文从新的角度提出了一个新颖的框架，采用掩蔽完成方式解决了以上问题。具体来说，在训练阶段，我们学习了一个运动扩散模型来从随机噪声中生成运动。在推断阶段，通过去噪过程，我们进行了运动预测并在观察到的运动数据的控制下进行了预测。我们提出的框架名为HumanMAC，在几个基准数据集上显示出明显的改进。

    Human motion prediction is a classical problem in computer vision and computer graphics, which has a wide range of practical applications. Previous effects achieve great empirical performance based on an encoding-decoding style. The methods of this style work by first encoding previous motions to latent representations and then decoding the latent representations into predicted motions. However, in practice, they are still unsatisfactory due to several issues, including complicated loss constraints, cumbersome training processes, and scarce switch of different categories of motions in prediction. In this paper, to address the above issues, we jump out of the foregoing style and propose a novel framework from a new perspective. Specifically, our framework works in a masked completion fashion. In the training stage, we learn a motion diffusion model that generates motions from random noise. In the inference stage, with a denoising procedure, we make motion prediction conditioning on obse
    
[^61]: ESC：具备软件常识约束的零样本物体导航探索

    ESC: Exploration with Soft Commonsense Constraints for Zero-shot Object Navigation. (arXiv:2301.13166v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2301.13166](http://arxiv.org/abs/2301.13166)

    本文提出了一种新颖的零样本物体导航方法 ESC，它从预先训练的视觉和自然语言处理模型中转移常识知识，可在未知环境中进行导航，具有广阔的应用前景。

    

    准确地定位和导航到特定物体的能力对于在现实世界中操作并与物体交互以完成任务的实体代理来说至关重要。这种物体导航任务通常需要在具有标记物体的视觉环境中进行大规模训练，这种训练效果在未知环境中的新颖物体上泛化效果较差。本文提出了一种新颖的零样本物体导航方法——具备软件常识约束的探索（ESC），它将预先训练的模型中的常识知识转移到在视觉环境上进行开放世界物体导航时不需要进行导航或其他视觉环境训练。首先，ESC利用预先训练的视觉和语言模型进行开放世界基于提示的接地，利用预先训练的常识语言模型进行房间和物体推理。然后，ESC通过将常识知识建模为软逻辑谓词来使其转化为导航动作，从而进行有效的探索。在MP3D上进行了大量实验，......

    The ability to accurately locate and navigate to a specific object is a crucial capability for embodied agents that operate in the real world and interact with objects to complete tasks. Such object navigation tasks usually require large-scale training in visual environments with labeled objects, which generalizes poorly to novel objects in unknown environments. In this work, we present a novel zero-shot object navigation method, Exploration with Soft Commonsense constraints (ESC), that transfers commonsense knowledge in pre-trained models to open-world object navigation without any navigation experience nor any other training on the visual environments. First, ESC leverages a pre-trained vision and language model for open-world prompt-based grounding and a pre-trained commonsense language model for room and object reasoning. Then ESC converts commonsense knowledge into navigation actions by modeling it as soft logic predicates for efficient exploration. Extensive experiments on MP3D, 
    
[^62]: 鉴定容易受到对抗性攻击的样本和强韧样本

    Identifying Adversarially Attackable and Robust Samples. (arXiv:2301.12896v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.12896](http://arxiv.org/abs/2301.12896)

    本文提出了一种深度学习方法，用于检测哪些样本最容易受到对抗性攻击，从而确定哪些样本最不容易受到攻击。实验结果表明，这种检测器在不同的模型结构中具有较好的可移植性和检测性能。

    

    对抗性攻击将微小的，难以感知的扰动插入输入样本，导致深度学习模型的输出发生大量不期望的变化。虽然对抗性攻击的生成和防御已经得到广泛研究，但对从输入数据角度理解对抗性攻击的研究仍然很有限。本文引入了样本攻击性的概念，旨在确定最容易受到对抗性攻击的样本（攻击性样本），从而反过来确定最不容易受到攻击的样本（强韧样本）。我们提出了一种基于深度学习的方法，用于检测针对未知目标模型的未见数据集中，容易受到对抗性攻击和强韧性样本。标准图像分类数据集上的实验证实了深度攻击性检测器在不同体系结构中的可移植性。我们发现，与基于简单模型不确定性的措施相比，深度攻击性检测器表现更好。

    Adversarial attacks insert small, imperceptible perturbations to input samples that cause large, undesired changes to the output of deep learning models. Despite extensive research on generating adversarial attacks and building defense systems, there has been limited research on understanding adversarial attacks from an input-data perspective. This work introduces the notion of sample attackability, where we aim to identify samples that are most susceptible to adversarial attacks (attackable samples) and conversely also identify the least susceptible samples (robust samples). We propose a deep-learning-based method to detect the adversarially attackable and robust samples in an unseen dataset for an unseen target model. Experiments on standard image classification datasets enables us to assess the portability of the deep attackability detector across a range of architectures. We find that the deep attackability detector performs better than simple model uncertainty-based measures for i
    
[^63]: 基于语言模型的知识图谱嵌入编辑

    Editing Language Model-based Knowledge Graph Embeddings. (arXiv:2301.10405v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.10405](http://arxiv.org/abs/2301.10405)

    本文提出了一种新的任务——编辑基于语言模型的知识图谱嵌入，旨在实现对KG嵌入的数据高效和快速更新。针对这一任务，提出了一个简单而强大的方案——KGEditor，可以更好地更新特定事实而不影响其余部分的性能。

    

    近几十年来，使用语言模型进行知识图谱（KG）嵌入已经取得了实证成功。但是，基于语言模型的KG嵌入通常作为静态工件部署，修改起来具有挑战性，需要重新训练。为了解决这个问题，本文提出了一种新的任务，即编辑基于语言模型的KG嵌入。该任务旨在实现对KG嵌入的数据高效和快速更新，而不影响其余部分的性能。我们构建了四个新数据集：E-FB15k237、A-FB15k237、E-WN18RR 和 A-WN18RR，并评估了几种知识编辑基线，证明了之前的模型处理该任务的能力有限。我们进一步提出了一个简单但强大的基线——KGEditor，它利用超网络的附加参数层来编辑/添加事实。全面的实验结果表明，当更新特定事实而不影响其余部分的性能时，KGEditor 的表现更好。

    Recently decades have witnessed the empirical success of framing Knowledge Graph (KG) embeddings via language models. However, language model-based KG embeddings are usually deployed as static artifacts, which are challenging to modify without re-training after deployment. To address this issue, we propose a new task of editing language model-based KG embeddings in this paper. The proposed task aims to enable data-efficient and fast updates to KG embeddings without damaging the performance of the rest. We build four new datasets: E-FB15k237, A-FB15k237, E-WN18RR, and A-WN18RR, and evaluate several knowledge editing baselines demonstrating the limited ability of previous models to handle the proposed challenging task. We further propose a simple yet strong baseline dubbed KGEditor, which utilizes additional parametric layers of the hyper network to edit/add facts. Comprehensive experimental results demonstrate that KGEditor can perform better when updating specific facts while not affec
    
[^64]: 通过目标感知表示学习和自适应视野预测的开放世界多任务控制

    Open-World Multi-Task Control Through Goal-Aware Representation Learning and Adaptive Horizon Prediction. (arXiv:2301.10034v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2301.10034](http://arxiv.org/abs/2301.10034)

    该论文提出了一种解决多任务控制中面临的开放世界挑战的新方法，即通过Goal-Sensitive Backbone鼓励出现与目标相关的视觉状态表示，并通过自适应视野预测模块来减轻非静态动态引起的学习不确定性。

    

    本文研究在Minecraft中学习目标条件下控制策略的问题，提出Goal-Sensitive Backbone（GSB）使政策鼓励出现与目标相关的视觉状态表示，并通过自适应视野预测模块减轻因非静态动态引起的学习不确定性。实验结果表明，我们的方法在20个Minecraft任务中表现显著优于迄今为止最好的基线，其中许多任务的表现是基线的两倍。

    We study the problem of learning goal-conditioned policies in Minecraft, a popular, widely accessible yet challenging open-ended environment for developing human-level multi-task agents. We first identify two main challenges of learning such policies: 1) the indistinguishability of tasks from the state distribution, due to the vast scene diversity, and 2) the non-stationary nature of environment dynamics caused by partial observability. To tackle the first challenge, we propose Goal-Sensitive Backbone (GSB) for the policy to encourage the emergence of goal-relevant visual state representations. To tackle the second challenge, the policy is further fueled by an adaptive horizon prediction module that helps alleviate the learning uncertainty brought by the non-stationary dynamics. Experiments on 20 Minecraft tasks show that our method significantly outperforms the best baseline so far; in many of them, we double the performance. Our ablation and exploratory studies then explain how our a
    
[^65]: PIRLNav: 对于ObjectNav进行模仿学习和强化学习微调的预训练研究

    PIRLNav: Pretraining with Imitation and RL Finetuning for ObjectNav. (arXiv:2301.07302v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.07302](http://arxiv.org/abs/2301.07302)

    本文提出了PIRLNav，通过人类演示的BC预训练和RL微调两个阶段的学习方案，成功率达到ObjectNav的65.0％，比以前的最新技术高5.0％。

    

    本研究探讨了ObjectGoal Navigation——在新环境中要求虚拟机器人导航到一个物体。以前的研究表明，使用人类演示的数据集进行行为克隆（BC）的模仿学习（IL）取得了有希望的结果。然而，这种方法也存在局限性——1）由于训练只模仿动作而不是后果，因此BC策略对新状态的泛化能力较差，2）收集演示数据成本高昂。另一方面，强化学习（RL）容易扩展，但需要精心设计奖励来实现理想的行为。我们提出PIRLNav，一个两阶段的学习方案，用于对人类演示进行BC预训练，然后进行RL微调。这导致该策略在ObjectNav上实现了65.0％的成功率（绝对值比以前的最新技术高5.0％）。使用这种BC $ \rightarrow $ RL训练方法，我们对设计选择进行了严格的实证分析。首先，我们调查了使用人类演示是否可行。

    We study ObjectGoal Navigation -- where a virtual robot situated in a new environment is asked to navigate to an object. Prior work has shown that imitation learning (IL) using behavior cloning (BC) on a dataset of human demonstrations achieves promising results. However, this has limitations -- 1) BC policies generalize poorly to new states, since the training mimics actions not their consequences, and 2) collecting demonstrations is expensive. On the other hand, reinforcement learning (RL) is trivially scalable, but requires careful reward engineering to achieve desirable behavior. We present PIRLNav, a two-stage learning scheme for BC pretraining on human demonstrations followed by RL-finetuning. This leads to a policy that achieves a success rate of $65.0\%$ on ObjectNav ($+5.0\%$ absolute over previous state-of-the-art). Using this BC$\rightarrow$RL training recipe, we present a rigorous empirical analysis of design choices. First, we investigate whether human demonstrations can b
    
[^66]: 面向可扩展物理一致的神经网络：在数据驱动多区域热建筑模型中的应用研究

    Towards Scalable Physically Consistent Neural Networks: an Application to Data-driven Multi-zone Thermal Building Models. (arXiv:2212.12380v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.12380](http://arxiv.org/abs/2212.12380)

    本论文研究了物理一致神经网络(PCNNs) 在模拟建筑温度动态方面的扩展性和准确性。结果发现，PCNNs既确保了物理一致性，同时又能在复杂的多区域热建筑模型中取得高精度的性能表现，且在可用数据量有限的情况下超越经典灰盒模型，具有可扩展性优势。

    

    随着越来越多的数据被收集，数据驱动建模方法近年来越来越受欢迎。虽然经典灰盒模型在物理上是可靠的，但通常很难识别和扩展，并且受其有限的表现力影响可能会影响其准确性。另一方面，常常依赖神经网络 (NNs) 的经典黑盒方法通常能够从数据中推导出统计模式，即使在扩展方面也能取得令人印象深刻的性能。然而，它们对潜在的物理定律完全无视，如果基于它们做决策用于实际物理系统，可能会导致潜在的灾难性后果。最近开发了物理一致神经网络 (PCNNs) 来解决这些问题，确保物理一致性，同时利用 NNs 实现最先进的准确性。在这项工作中，我们将 PCNN 扩展到建筑温度动态建模，并提出与经典灰盒和黑盒方法的彻底比较。特别是，我们研究多区域建筑模型，其中每个区域的热行为由能量平衡方程式统治，其参数必须通过测量数据进行识别。所得结果表明，即使涉及许多相互作用的组件构成的复杂和动态系统，PCNNs 也可以在确保物理一致性的同时实现高精度。此外，我们证明 PCNN 在经典灰盒模型上提供了可扩展性优势，在有限的可用训练数据下表现出色。

    With more and more data being collected, data-driven modeling methods have been gaining in popularity in recent years. While physically sound, classical gray-box models are often cumbersome to identify and scale, and their accuracy might be hindered by their limited expressiveness. On the other hand, classical black-box methods, typically relying on Neural Networks (NNs) nowadays, often achieve impressive performance, even at scale, by deriving statistical patterns from data. However, they remain completely oblivious to the underlying physical laws, which may lead to potentially catastrophic failures if decisions for real-world physical systems are based on them. Physically Consistent Neural Networks (PCNNs) were recently developed to address these aforementioned issues, ensuring physical consistency while still leveraging NNs to attain state-of-the-art accuracy.  In this work, we scale PCNNs to model building temperature dynamics and propose a thorough comparison with classical gray-b
    
[^67]: 关于语义分割模型的校准：分析与算法

    On Calibrating Semantic Segmentation Models: Analyses and An Algorithm. (arXiv:2212.12053v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.12053](http://arxiv.org/abs/2212.12053)

    本文系统研究了语义分割模型的校准问题，提出了一种简单而有效的方法——选择性缩放，通过将正确/错误预测分开进行缩放，并更加关注错误预测的逻辑平滑，此方法在语义分割校准上取得了良好效果。

    

    我们研究了语义分割校准的问题。虽然已经提出了很多解决方案来处理图像分类置信度的模型误校准，但至今为止，对语义分割的置信度校准研究仍然很有限。我们对语义分割模型的校准进行了系统研究，并提出了一种简单而有效的方法。首先，我们发现模型容量、裁剪大小、多尺度测试和预测正确性对校准有影响。其中，预测正确性，特别是错误预测，对由于过度置信而导致的误校准更为重要。接下来，我们提出了一种简单、统一且有效的方法，即选择性缩放，通过将正确/错误预测分开进行缩放，并更加关注错误预测的逻辑平滑。然后，我们研究了流行的现有校准方法，并将它们与选择性缩放在语义分割校准上进行比较。我们进行了大量实验，使用了多种数据集和语义分割模型，以验证我们提出的方法的有效性。

    We study the problem of semantic segmentation calibration. Lots of solutions have been proposed to approach model miscalibration of confidence in image classification. However, to date, confidence calibration research on semantic segmentation is still limited. We provide a systematic study on the calibration of semantic segmentation models and propose a simple yet effective approach. First, we find that model capacity, crop size, multi-scale testing, and prediction correctness have impact on calibration. Among them, prediction correctness, especially misprediction, is more important to miscalibration due to over-confidence. Next, we propose a simple, unifying, and effective approach, namely selective scaling, by separating correct/incorrect prediction for scaling and more focusing on misprediction logit smoothing. Then, we study popular existing calibration methods and compare them with selective scaling on semantic segmentation calibration. We conduct extensive experiments with a vari
    
[^68]: RepMode：学习重新参数化用于亚细胞结构预测的不同专家

    RepMode: Learning to Re-parameterize Diverse Experts for Subcellular Structure Prediction. (arXiv:2212.10066v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.10066](http://arxiv.org/abs/2212.10066)

    本文提出了RepMode，一种网络，利用任务感知的先验动态组织其参数以处理亚细胞结构预测等指定的单标签预测任务。

    

    在生物研究中，荧光染色是揭示亚细胞结构位置和形态的关键技术。然而，这种技术速度慢、费用高且对细胞有害。本文将其建模为一个深度学习任务——亚细胞结构预测（SSP），旨在预测多个亚细胞结构的三维荧光图像，从而从3D透射光图像中获取更多信息。由于当前生物技术的局限性，每个图像在SSP中只有部分标注。此外，亚细胞结构的大小差异很大，这导致了SSP的多尺度问题。为了克服这些挑战，本文提出了重新参数化多元专家混合（RepMode），一种网络，它利用任务感知的先验动态组织其参数以处理指定的单标签预测任务。在RepMode中，多元专家混合（MoDE）块被设计为学习所有任务的广义参数，同时门控重新参数化（GatRep）被用来对其进行微调以适应特定任务。

    In biological research, fluorescence staining is a key technique to reveal the locations and morphology of subcellular structures. However, it is slow, expensive, and harmful to cells. In this paper, we model it as a deep learning task termed subcellular structure prediction (SSP), aiming to predict the 3D fluorescent images of multiple subcellular structures from a 3D transmitted-light image. Unfortunately, due to the limitations of current biotechnology, each image is partially labeled in SSP. Besides, naturally, subcellular structures vary considerably in size, which causes the multi-scale issue of SSP. To overcome these challenges, we propose Re-parameterizing Mixture-of-Diverse-Experts (RepMode), a network that dynamically organizes its parameters with task-aware priors to handle specified single-label prediction tasks. In RepMode, the Mixture-of-Diverse-Experts (MoDE) block is designed to learn the generalized parameters for all tasks, and gating re-parameterization (GatRep) is p
    
[^69]: 人工参与的知识图谱拓展

    Expanding Knowledge Graphs with Humans in the Loop. (arXiv:2212.05189v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.05189](http://arxiv.org/abs/2212.05189)

    本文提出了一种与人类互动的方法扩展知识图谱，通过预测新概念的“父母”，然后由人类专家进一步验证。该方法能够保证预测的父母距离概念的真实父母“近”，能够提高人算协作的速度和准确性，并在新闻和娱乐领域的真实数据集上得到了验证。

    

    精心策划的知识图谱编码领域专业知识，提高推荐、分割、广告定向和其他机器学习系统在多个领域中的性能。随着领域中出现新概念，知识图谱必须扩展以保持机器学习性能。但是，在规模上手动扩展知识图谱是不可行的。在这项工作中，我们提出了一种与人类互动的知识图谱拓展方法。具体而言，给定一个知识图谱，我们的方法预测了需要添加到此图谱中的新概念的“父母”，以供人类专家进一步验证。我们证明了我们的方法既准确又可证明是“人性化”的。具体来说，我们证明了即使预测不正确，我们的方法也能预测距离概念的真实父母“近”的父母。然后，我们通过一项受控实验，证明了满足此属性可以增加人算协作的速度和准确性。我们进一步展示了我们的方法在新闻和娱乐领域的真实数据集上的有效性。

    Curated knowledge graphs encode domain expertise and improve the performance of recommendation, segmentation, ad targeting, and other machine learning systems in several domains. As new concepts emerge in a domain, knowledge graphs must be expanded to preserve machine learning performance. Manually expanding knowledge graphs, however, is infeasible at scale. In this work, we propose a method for knowledge graph expansion with humans-in-the-loop. Concretely, given a knowledge graph, our method predicts the "parents" of new concepts to be added to this graph for further verification by human experts. We show that our method is both accurate and provably "human-friendly". Specifically, we prove that our method predicts parents that are "near" concepts' true parents in the knowledge graph, even when the predictions are incorrect. We then show, with a controlled experiment, that satisfying this property increases both the speed and the accuracy of the human-algorithm collaboration. We furth
    
[^70]: 细调CLIP模型是高效的视频学习器

    Fine-tuned CLIP Models are Efficient Video Learners. (arXiv:2212.03640v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.03640](http://arxiv.org/abs/2212.03640)

    本文提出了一个简单的视频细调CLIP（ViFi-CLIP）基线，通过从CLIP图像编码器的帧级处理，接着进行特征池化和与相应文本嵌入的相似度匹配，有效地将图像级别的CLIP表示转移到视频中，从而弥合了从图像到视频的领域差距。

    This paper proposes a simple Video Fine-tuned CLIP (ViFi-CLIP) baseline, which effectively transfers image-level CLIP representations to videos by frame-level processing from CLIP image-encoder followed by feature pooling and similarity matching with corresponding text embeddings, thus bridging the domain gap from images to videos.

    通过图像-文本对的大规模多模态训练，CLIP模型具有强大的泛化能力。由于在类似规模上对视频进行训练是不可行的，因此最近的方法集中于将基于图像的CLIP有效地转移到视频领域。在这个追求中，添加了新的参数模块来学习时间信息和帧间关系，这需要精心设计。此外，当所得到的模型在视频上进行学习时，它们往往会过度拟合给定的任务分布，并且缺乏泛化方面。这引出了以下问题：如何有效地将图像级别的CLIP表示转移到视频中？在这项工作中，我们展示了一个简单的视频细调CLIP（ViFi-CLIP）基线通常足以弥合从图像到视频的领域差距。我们的定性分析表明，从CLIP图像编码器的帧级处理，接着进行特征池化和与相应文本嵌入的相似度匹配，有助于提高模型的性能。

    Large-scale multi-modal training with image-text pairs imparts strong generalization to CLIP model. Since training on a similar scale for videos is infeasible, recent approaches focus on the effective transfer of image-based CLIP to the video domain. In this pursuit, new parametric modules are added to learn temporal information and inter-frame relationships which require meticulous design efforts. Furthermore, when the resulting models are learned on videos, they tend to overfit on the given task distribution and lack in generalization aspect. This begs the following question: How to effectively transfer image-level CLIP representations to videos? In this work, we show that a simple Video Fine-tuned CLIP (ViFi-CLIP) baseline is generally sufficient to bridge the domain gap from images to videos. Our qualitative analysis illustrates that the frame-level processing from CLIP image-encoder followed by feature pooling and similarity matching with corresponding text embeddings helps in imp
    
[^71]: 扩散视频自编码器：通过分解视频特征实现一致的人脸视频编辑

    Diffusion Video Autoencoders: Toward Temporally Consistent Face Video Editing via Disentangled Video Encoding. (arXiv:2212.02802v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.02802](http://arxiv.org/abs/2212.02802)

    本文提出了一种基于扩散自编码器的面部视频编辑框架，可以从给定的视频中提取出分解的特征，实现简单的特征调整来确保时间上的一致性。与现有的基于GAN的方法不同，该模型同时满足重建和编辑能力，并且对受野外面部视频的角落情况具有鲁棒性。

    

    受到最近面部图像编辑方法的惊人表现的启发，自然会有几项研究来扩展这些方法以应用于面部视频编辑任务。 这里的一个主要挑战是编辑帧之间的时间一致性，这仍然没有得到解决。 为此，我们提出了一种基于扩散自编码器的新型面部视频编辑框架，该框架可以成功地从给定的视频中提取出分解的特征-首次作为面部视频编辑模型-标识和运动。

    Inspired by the impressive performance of recent face image editing methods, several studies have been naturally proposed to extend these methods to the face video editing task. One of the main challenges here is temporal consistency among edited frames, which is still unresolved. To this end, we propose a novel face video editing framework based on diffusion autoencoders that can successfully extract the decomposed features - for the first time as a face video editing model - of identity and motion from a given video. This modeling allows us to edit the video by simply manipulating the temporally invariant feature to the desired direction for the consistency. Another unique strength of our model is that, since our model is based on diffusion models, it can satisfy both reconstruction and edit capabilities at the same time, and is robust to corner cases in wild face videos (e.g. occluded faces) unlike the existing GAN-based methods.
    
[^72]: 通过网络规范化和超参数搜索优化解释

    Optimizing Explanations by Network Canonization and Hyperparameter Search. (arXiv:2211.17174v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.17174](http://arxiv.org/abs/2211.17174)

    这篇论文介绍了新的解释人工智能方法，通过网络规范化和超参数搜索来提高解释效果。

    

    解释型人工智能（XAI）正在逐渐成为许多人工智能应用的关键组成部分。然而，基于规则和修改后的反向传播XAI方法往往在应用于现代模型架构时面临挑战，包括创新的层构建块，这是由两个原因造成的。首先，基于规则的XAI方法的高灵活性导致了许多潜在的参数化。其次，许多XAI方法破坏了实现不变性公理，因为他们无法处理某些模型组件，例如BatchNorm层。后者可以通过模型规范化来解决，模型规范化是重新组织模型以忽略有问题的组件而不改变基本函数的过程。虽然对于简单的架构（例如VGG、ResNet），模型规范化很简单，但对于更复杂和高度互联的模型（例如DenseNet），它可能具有挑战性。此外，只有很少的可量化证据表明模型规范化对XAI有益。

    Explainable AI (XAI) is slowly becoming a key component for many AI applications. Rule-based and modified backpropagation XAI approaches however often face challenges when being applied to modern model architectures including innovative layer building blocks, which is caused by two reasons. Firstly, the high flexibility of rule-based XAI methods leads to numerous potential parameterizations. Secondly, many XAI methods break the implementation-invariance axiom because they struggle with certain model components, e.g., BatchNorm layers. The latter can be addressed with model canonization, which is the process of re-structuring the model to disregard problematic components without changing the underlying function. While model canonization is straightforward for simple architectures (e.g., VGG, ResNet), it can be challenging for more complex and highly interconnected models (e.g., DenseNet). Moreover, there is only little quantifiable evidence that model canonization is beneficial for XAI.
    
[^73]: Shifted Diffusion用于文本到图像生成

    Shifted Diffusion for Text-to-image Generation. (arXiv:2211.15388v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.15388](http://arxiv.org/abs/2211.15388)

    本文提出了一种新的文本到图像生成方法，使用Shifted Diffusion模型更好地生成来自输入文本的图像嵌入，并通过大量实验和评估证明了其在效率和有效性方面的优势，同时支持半监督和无语言训练。

    

    我们提出了Corgi，一种新颖的文本到图像生成方法。Corgi基于我们提出的Shifted Diffusion模型，可以更好地生成来自输入文本的图像嵌入。与DALL-E 2中使用的基线扩散模型不同，我们的方法通过设计新的初始化分布和扩散的新过渡步骤，在其扩散过程中无缝地编码了预训练CLIP模型的先前知识。与强劲的DALL-E 2基准相比，我们的方法在从文本中生成图像嵌入方面表现更好，具有更高的效率和有效性，从而实现更好的文本到图像生成。进行了大量的大规模实验，并在定量指标和人类评估方面进行了评估，结果表明与现有方法相比，我们的方法具有更强的生成能力。此外，我们的模型实现了文本到图像生成的半监督和无语言训练，只需要部分或不需要训练数据集中的图像与输入文本对齐。

    We present Corgi, a novel method for text-to-image generation. Corgi is based on our proposed shifted diffusion model, which achieves better image embedding generation from input text. Unlike the baseline diffusion model used in DALL-E 2, our method seamlessly encodes prior knowledge of the pre-trained CLIP model in its diffusion process by designing a new initialization distribution and a new transition step of the diffusion. Compared to the strong DALL-E 2 baseline, our method performs better in generating image embedding from the text in terms of both efficiency and effectiveness, resulting in better text-to-image generation. Extensive large-scale experiments are conducted and evaluated in terms of both quantitative measures and human evaluation, indicating a stronger generation ability of our method compared to existing ones. Furthermore, our model enables semi-supervised and language-free training for text-to-image generation, where only part or none of the images in the training 
    
[^74]: 多模态少样本时间动作检测

    Multi-Modal Few-Shot Temporal Action Detection. (arXiv:2211.14905v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.14905](http://arxiv.org/abs/2211.14905)

    提出了一个新的多模态少样本时间动作检测问题，针对这个问题提出了一个新的 MUPPET 方法，通过在视觉-语言模型中构建多模态提示，并使用多模态聚类算法来组合时序连续的片段，解决了问题。在少样本和零样本场景下表现出了优越性，并验证了不同组件的有效性。

    

    少样本 (FS) 和零样本 (ZS) 学习是缩放时间动作检测 (TAD) 到新类的两种不同方法。前者将经过预训练的视觉模型适应于新任务，该任务由每类仅有一个视频表示，而后者通过利用新类的语义描述而不需要训练示例。在本文中，我们介绍了一种新的多模态少样本 (MMFS) TAD 问题，它可以被视为通过共同利用少数支持视频和新类名字来结合 FS-TAD 和 ZS-TAD 的方法。为了解决这个问题，我们进一步提出了一种新颖的 MUlti-modality PromPt mETa-learning (MUPPET) 方法。这是通过有效地连接预训练的视觉和语言模型，同时最大程度地重用已经学习的能力来实现的。具体来说，我们通过使用元学习适配器装备的视觉语义分词器，将支持视频映射到视觉-语言模型的文本标记空间中来构建多模态提示。为了解决大的类内变化，我们提出了一种新的多模态聚类算法来对时间上一致的提议片段进行分组。全面的实验展示了所提出的方法在少样本和零样本场景下的优势，以及不同组件的有效性。

    Few-shot (FS) and zero-shot (ZS) learning are two different approaches for scaling temporal action detection (TAD) to new classes. The former adapts a pretrained vision model to a new task represented by as few as a single video per class, whilst the latter requires no training examples by exploiting a semantic description of the new class. In this work, we introduce a new multi-modality few-shot (MMFS) TAD problem, which can be considered as a marriage of FS-TAD and ZS-TAD by leveraging few-shot support videos and new class names jointly. To tackle this problem, we further introduce a novel MUlti-modality PromPt mETa-learning (MUPPET) method. This is enabled by efficiently bridging pretrained vision and language models whilst maximally reusing already learned capacity. Concretely, we construct multi-modal prompts by mapping support videos into the textual token space of a vision-language model using a meta-learned adapter-equipped visual semantics tokenizer. To tackle large intra-clas
    
[^75]: 通过网络剪枝设计轻量级物体跟踪器：使用CNN还是Transformers?

    On Designing Light-Weight Object Trackers through Network Pruning: Use CNNs or Transformers?. (arXiv:2211.13769v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.13769](http://arxiv.org/abs/2211.13769)

    本文介绍了如何通过神经网络结构剪枝技术设计压缩版的高度压缩轻量级物体跟踪器。通过对CNN和Transformers跟踪器的比较研究，揭示出在设计轻量级跟踪器时的最佳架构选择。最后，提供了极端剪枝率的跟踪结果，可能有助于更好地了解网络剪枝在物体跟踪中的限制。

    

    低功耗设备上部署的物体跟踪器需要轻量级设计，然而，大多数现有最先进的方法依赖于使用构建于CNN或transformers上的计算密集的主干网络。这些模型的巨大尺寸不允许在低功耗条件下部署它们，因此设计压缩版的大型跟踪模型具有重要意义。本文演示了如何通过神经结构剪枝设计高度压缩的轻量级物体跟踪器，同时提供了一个比较研究，以确定最适合设计轻量级跟踪器的架构选择。还提供了使用CNNs、transformers以及两者组合的最新跟踪器之间的比较，以研究它们在各种压缩比下的稳定性。最后，展示了极端剪枝场景下的结果，有些情况下剪枝比率低至1%，以研究网络剪枝在物体跟踪中的限制。本文提供了更深入的洞察力。

    Object trackers deployed on low-power devices need to be light-weight, however, most of the current state-of-the-art (SOTA) methods rely on using compute-heavy backbones built using CNNs or transformers. Large sizes of such models do not allow their deployment in low-power conditions and designing compressed variants of large tracking models is of great importance. This paper demonstrates how highly compressed light-weight object trackers can be designed using neural architectural pruning of large CNN and transformer based trackers. Further, a comparative study on architectural choices best suited to design light-weight trackers is provided. A comparison between SOTA trackers using CNNs, transformers as well as the combination of the two is presented to study their stability at various compression ratios. Finally results for extreme pruning scenarios going as low as 1% in some cases are shown to study the limits of network pruning in object tracking. This work provides deeper insights 
    
[^76]: 视觉基础下的常识知识获取

    Visually Grounded Commonsense Knowledge Acquisition. (arXiv:2211.12054v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.12054](http://arxiv.org/abs/2211.12054)

    本文介绍了CLEVER，一种以视觉-语言预训练模型为基础的常识知识提取方法，通过包含有关实体对的图像包汇总出常识关系，避免了对图像实例进行人工注释的问题。

    

    大规模的常识知识库为广泛的AI应用提供动力，其中自动提取常识知识（CKE）是一个关键且具有挑战性的问题。由文本提取CKE知识是已知的受限于本质的稀疏性和推理偏差。另一方面，视觉知觉包含有关真实世界实体的丰富常识知识，例如（人，可以持有，瓶子），这些知识可作为获取基于常识的知识的有希望来源。我们提出CLEVER，将CKE作为一种远距离监督多实例学习问题进行了规定，模型通过关于实体对的图像包汇总出常识关系而无需对图像实例进行人工注释。CLEVER使用了基于视觉-语言预训练模型深入理解图像包中的每个图像，并从中选择信息性实例，以通过新颖的关系汇总方式概括常识知识实体关系信息。

    Large-scale commonsense knowledge bases empower a broad range of AI applications, where the automatic extraction of commonsense knowledge (CKE) is a fundamental and challenging problem. CKE from text is known for suffering from the inherent sparsity and reporting bias of commonsense in text. Visual perception, on the other hand, contains rich commonsense knowledge about real-world entities, e.g., (person, can_hold, bottle), which can serve as promising sources for acquiring grounded commonsense knowledge. In this work, we present CLEVER, which formulates CKE as a distantly supervised multi-instance learning problem, where models learn to summarize commonsense relations from a bag of images about an entity pair without any human annotation on image instances. To address the problem, CLEVER leverages vision-language pre-training models for deep understanding of each image in the bag, and selects informative instances from the bag to summarize commonsense entity relations via a novel cont
    
[^77]: 通过减少累积轨迹误差来提高数据集精炼效果的论文翻译

    Minimizing the Accumulated Trajectory Error to Improve Dataset Distillation. (arXiv:2211.11004v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.11004](http://arxiv.org/abs/2211.11004)

    通过新增损失项最小化累积轨迹误差，从而提高数据集精炼效果，并且在多种数据集和网络架构上的实验证明该方法优于当前最先进的方法。

    

    由于大型真实世界数据集的可用性，基于模型的深度学习取得了惊人的成功。然而，处理如此大量的数据在计算、存储、训练和搜寻良好的神经结构等方面成本相当高昂，因此数据集精炼近期成为焦点。这种范式涉及获取真实世界数据集中的信息并将其提炼为微小紧凑的合成数据集，以便在理想情况下处理后者的表现类似于前者。当前最先进的方法主要依靠学习通过在真实数据和合成数据之间匹配训练期间获得的梯度的合成数据集。然而，这些梯度匹配方法受到所谓的累积轨迹误差的影响，此误差是由于精炼和后续评估之间不一致导致的。为了减轻这种累积轨迹误差的不利影响，我们提出了一种新方法，鼓励将累积轨迹误差从训练阶段转移到精炼阶段。具体而言，我们引入了一种损失项，在精炼过程中最小化累积轨迹误差。我们在不同数据集和网络架构上的实验表明，我们的方法优于当前最先进的方法并显著减少累积轨迹误差。

    Model-based deep learning has achieved astounding successes due in part to the availability of large-scale real-world data. However, processing such massive amounts of data comes at a considerable cost in terms of computations, storage, training and the search for good neural architectures. Dataset distillation has thus recently come to the fore. This paradigm involves distilling information from large real-world datasets into tiny and compact synthetic datasets such that processing the latter ideally yields similar performances as the former. State-of-the-art methods primarily rely on learning the synthetic dataset by matching the gradients obtained during training between the real and synthetic data. However, these gradient-matching methods suffer from the so-called accumulated trajectory error caused by the discrepancy between the distillation and subsequent evaluation. To mitigate the adverse impact of this accumulated trajectory error, we propose a novel approach that encourages t
    
[^78]: 基于行为信息聚合网络（BIAN）的大规模金融社交网络欺诈用户检测

    Fraudulent User Detection Via Behavior Information Aggregation Network (BIAN) On Large-Scale Financial Social Network. (arXiv:2211.06315v2 [cs.SI] UPDATED)

    [http://arxiv.org/abs/2211.06315](http://arxiv.org/abs/2211.06315)

    本文提出了一款新颖的行为信息聚合网络（BIAN），可以同时考虑用户的个人资料、行为以及社交联系，以有效检测金融欺诈。

    

    金融欺诈每年造成数十亿美元的损失，但目前缺乏有效的方法来同时考虑社交网络中用户的个人资料和行为以检测欺诈。社交网络形成了一个图形结构，而图神经网络（GNN）是深度学习中一个有前途的研究领域，可以无缝处理非欧几里得图形数据。在金融欺诈检测中，通过分析用户的个人资料和行为（如交易、贷款等）以及他们的社交联系，可以识别犯罪分子的作案方式。目前，大多数GNN无法选择重要的邻居，因为邻居的边属性（即行为）被忽略了。本文提出了一种新颖的行为信息聚合网络（BIAN），将用户的行为与其他用户特征相结合。与其近亲Graph Attention Networks（GAT）和Graph Transformer Networks（GTN）不同，它基于相邻边属性进行邻域聚合。

    Financial frauds cause billions of losses annually and yet it lacks efficient approaches in detecting frauds considering user profile and their behaviors simultaneously in social network . A social network forms a graph structure whilst Graph neural networks (GNN), a promising research domain in Deep Learning, can seamlessly process non-Euclidean graph data . In financial fraud detection, the modus operandi of criminals can be identified by analyzing user profile and their behaviors such as transaction, loaning etc. as well as their social connectivity. Currently, most GNNs are incapable of selecting important neighbors since the neighbors' edge attributes (i.e., behaviors) are ignored. In this paper, we propose a novel behavior information aggregation network (BIAN) to combine the user behaviors with other user features. Different from its close "relatives" such as Graph Attention Networks (GAT) and Graph Transformer Networks (GTN), it aggregates neighbors based on neighboring edge at
    
[^79]: DynamicISP：用于图像识别的动态控制图像信号处理器

    DynamicISP: Dynamically Controlled Image Signal Processor for Image Recognition. (arXiv:2211.01146v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.01146](http://arxiv.org/abs/2211.01146)

    DynamicISP是一个动态控制图像信号处理器，能够根据前一帧的识别结果自动调整每帧的参数，实现高精度的单类别和多类别物体检测任务，同时计算成本低。

    

    图像信号处理器（ISPs）在图像识别任务和捕获图像的感知质量中发挥着重要作用。通常情况下，专家们会花费大量精力手动调整ISPs的许多参数，但这些参数是次优的。在文献中，已经积极研究了两种技术：基于机器学习的参数调整技术和基于DNN的ISP技术。前者轻量级但缺乏表现力，后者具有表现力，但在边缘设备上的计算成本太高。为了解决这些问题，我们提出了“DynamicISP”，它由多个传统的ISP函数组成，并根据前一帧的识别结果动态控制每个帧的参数。我们展示了我们的方法成功地控制了多个ISP函数的参数，并在单类别和多类别物体检测任务中以低计算成本实现了最先进的精度。

    Image Signal Processors (ISPs) play important roles in image recognition tasks as well as in the perceptual quality of captured images. In most cases, experts make a lot of effort to manually tune many parameters of ISPs, but the parameters are sub-optimal. In the literature, two types of techniques have been actively studied: a machine learning-based parameter tuning technique and a DNN-based ISP technique. The former is lightweight but lacks expressive power. The latter has expressive power, but the computational cost is too heavy on edge devices. To solve these problems, we propose "DynamicISP," which consists of multiple classical ISP functions and dynamically controls the parameters of each frame according to the recognition result of the previous frame. We show our method successfully controls the parameters of multiple ISP functions and achieves state-of-the-art accuracy with low computational cost in single and multi-category object detection tasks.
    
[^80]: 傅立叶分析实现一致且真实的模型解释

    Consistent and Truthful Interpretation with Fourier Analysis. (arXiv:2210.17426v1 [cs.LG] CROSS LISTED)

    [http://arxiv.org/abs/2210.17426](http://arxiv.org/abs/2210.17426)

    该论文提出了一个称为真实解释的新概念，通过傅立叶分析获得严格保证，并在实验中证明了其在支持假设情景和降低解释误差方面的优势。

    

    对于许多跨学科领域，机器学习的解释需要与当前案例相关的假设情景一致，即如果一个因素改变，模型会如何反应？尽管归因方法由优雅的公理系统支持，但它们主要关注单个输入，并且通常不一致。为支持假设情景，我们引入了一个称为真实解释的新概念，并应用布尔函数的傅立叶分析来获得严格的保证。实验结果表明，对于各种半径的邻域，我们的方法与其他方法相比，可以实现2倍至50倍更低的解释误差。

    For many interdisciplinary fields, ML interpretations need to be consistent with what-if scenarios related to the current case, i.e., if one factor changes, how does the model react? Although the attribution methods are supported by the elegant axiomatic systems, they mainly focus on individual inputs, and are generally inconsistent. To support what-if scenarios, we introduce a new notion called truthful interpretation, and apply Fourier analysis of Boolean functions to get rigorous guarantees. Experimental results show that for neighborhoods with various radii, our method achieves 2x - 50x lower interpretation error compared with the other methods.
    
[^81]: LongShortNet：探索时间和语义特征融合在流式感知中

    LongShortNet: Exploring Temporal and Semantic Features Fusion in Streaming Perception. (arXiv:2210.15518v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2210.15518](http://arxiv.org/abs/2210.15518)

    LongShortNet是一种基于双路径网络的流式感知方法，它结合了长期时间运动和短期空间语义，实现了时空特征融合。在Argoverse-HD数据集上，LongShortNet表现出优异的检测性能，并且几乎不需要额外的计算成本。

    

    流式感知是自动驾驶中的基本任务，需要在自动驾驶系统的延迟和准确性之间进行仔细的平衡。然而，当前的流式感知方法存在局限性，因为它们仅仅依赖于当前帧及其相邻的两帧来学习运动模式，从而限制了它们对复杂场景的建模能力，往往导致检测结果不佳。为了解决这一限制，我们提出了LongShortNet，一种新颖的双路径网络，它捕捉长期的时间运动，并将其与短期的空间语义集成到实时感知中。我们提出的LongShortNet值得注意，因为它是第一个将长期时间建模扩展到流式感知的工作，从而实现了时空特征融合。我们在具有挑战性的Argoverse-HD数据集上评估了LongShortNet，并证明了它在几乎没有额外计算成本的情况下优于现有的最先进方法。

    Streaming perception is a fundamental task in autonomous driving that requires a careful balance between the latency and accuracy of the autopilot system. However, current methods for streaming perception are limited as they rely only on the current and adjacent two frames to learn movement patterns, which restricts their ability to model complex scenes, often leading to poor detection results. To address this limitation, we propose LongShortNet, a novel dual-path network that captures long-term temporal motion and integrates it with short-term spatial semantics for real-time perception. Our proposed LongShortNet is notable as it is the first work to extend long-term temporal modeling to streaming perception, enabling spatiotemporal feature fusion. We evaluate LongShortNet on the challenging Argoverse-HD dataset and demonstrate that it outperforms existing state-of-the-art methods with almost no additional computational cost.
    
[^82]: ProContEXT：基于递进的上下文变换机制的目标跟踪方法研究

    ProContEXT: Exploring Progressive Context Transformer for Tracking. (arXiv:2210.15511v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2210.15511](http://arxiv.org/abs/2210.15511)

    本文提出了基于递进的上下文变换机制的目标跟踪方法 ProContEXT，采用上下文感知的自注意力模块对空间和时间上下文进行编码，逐步利用静态和动态多尺度模板进行准确跟踪。它探索了空间和时间上下文之间的互补性，为基于 transformer 的跟踪器的多上下文建模提供了新的途径。

    

    传统的视觉目标跟踪仅将第一个帧中的目标区域作为模板，无法适应快速变化和拥挤场景中的物体外观变化，导致跟踪失败。本文提出了一种基于递进式上下文编码变换机制的跟踪方法 ProContEXT，使用上下文感知的自注意力模块对空间和时间上下文进行编码，逐步利用静态和动态多尺度模板进行准确跟踪。它探索了空间和时间上下文之间的互补性，为基于 transformer 的跟踪器的多上下文建模提供了新的途径。另外，ProContEXT 修订了标记修剪技术以减少计算复杂度。

    Existing Visual Object Tracking (VOT) only takes the target area in the first frame as a template. This causes tracking to inevitably fail in fast-changing and crowded scenes, as it cannot account for changes in object appearance between frames. To this end, we revamped the tracking framework with Progressive Context Encoding Transformer Tracker (ProContEXT), which coherently exploits spatial and temporal contexts to predict object motion trajectories. Specifically, ProContEXT leverages a context-aware self-attention module to encode the spatial and temporal context, refining and updating the multi-scale static and dynamic templates to progressively perform accurate tracking. It explores the complementary between spatial and temporal context, raising a new pathway to multi-context modeling for transformer-based trackers. In addition, ProContEXT revised the token pruning technique to reduce computational complexity. Extensive experiments on popular benchmark datasets such as GOT-10k and
    
[^83]: 破碎的神经缩放定律

    Broken Neural Scaling Laws. (arXiv:2210.14891v7 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.14891](http://arxiv.org/abs/2210.14891)

    本文提出了一个平滑破碎的幂律函数形式，可以准确地模拟和外推深度神经网络的缩放行为，适用于各种架构和大量不同任务，包括视觉、语言、音频、视频、生成建模、对比学习、机器人、不确定性估计/校准、对抗鲁棒性、分子、计算机编程/编码、数学单词问题、算术、无监督/自监督学习和强化学习。

    This paper proposes a smoothly broken power law functional form (referred to as a Broken Neural Scaling Law (BNSL)) that accurately models and extrapolates the scaling behaviors of deep neural networks for various architectures and a large and diverse set of tasks, including vision, language, audio, video, generative modeling, contrastive learning, robotics, uncertainty estimation/calibration, adversarial robustness, molecules, computer programming/coding, math word problems, arithmetic, unsupervised/self-supervised learning, and reinforcement learning.

    我们提出了一个平滑破碎的幂律函数形式（我们称之为破碎的神经缩放定律（BNSL）），它准确地模拟和外推了深度神经网络的缩放行为（即感兴趣的评估指标随用于训练的计算量、模型参数数量、训练数据集大小或上游性能变化而变化）对于各种架构和大量不同任务中的每个任务，包括大规模视觉、语言、音频、视频、扩散、生成建模、多模态学习、对比学习、AI对齐、机器人、超出分布（OOD）泛化、持续学习、不确定性估计/校准、超出分布检测、对抗鲁棒性、蒸馏、分子、计算机编程/编码、数学单词问题、算术、无监督/自监督学习和强化学习。

    We present a smoothly broken power law functional form (referred to by us as a Broken Neural Scaling Law (BNSL)) that accurately models and extrapolates the scaling behaviors of deep neural networks (i.e. how the evaluation metric of interest varies as the amount of compute used for training, number of model parameters, training dataset size, or upstream performance varies) for various architectures and for each of various tasks within a large and diverse set of upstream and downstream tasks, in zero-shot, prompted, and fine-tuned settings. This set includes large-scale vision, language, audio, video, diffusion, generative modeling, multimodal learning, contrastive learning, AI alignment, robotics, out-of-distribution (OOD) generalization, continual learning, uncertainty estimation / calibration, out-of-distribution detection, adversarial robustness, distillation, molecules, computer programming/coding, math word problems, arithmetic, unsupervised/self-supervised learning, and reinforc
    
[^84]: TFAD: 一种基于时频分析的时间序列异常检测架构

    TFAD: A Decomposition Time Series Anomaly Detection Architecture with Time-Frequency Analysis. (arXiv:2210.09693v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.09693](http://arxiv.org/abs/2210.09693)

    本文提出了一种基于时频分析的时间序列异常检测模型 TFAD。在设计的时频架构中，同时加入了时间序列分解和数据增强机制，以提升性能和解释性能力。在广泛使用的基准数据集上，实证研究表明，该方法在单变量和多变量时间序列异常检测任务中性能最佳。

    

    时间序列异常检测是一个具有挑战性的问题，由于复杂的时间依赖性和有限的标签数据。虽然一些算法，包括传统和深度模型已经被提出，但大多数算法主要集中在时间域建模，没有充分利用时间序列数据中的频域信息。本文提出了一种基于时频分析的时间序列异常检测模型 TFAD，以利用时间和频域进行性能提升。此外，我们还在设计的时频架构中加入了时间序列分解和数据增强机制，进一步提升了性能和解释性能力。广泛使用的基准数据集上的实证研究表明，我们的方法在单变量和多变量时间序列异常检测任务中获得了最先进的性能。代码可在 https://github.com/DAMO-DI-ML/CIKM22-TFAD 获取。

    Time series anomaly detection is a challenging problem due to the complex temporal dependencies and the limited label data. Although some algorithms including both traditional and deep models have been proposed, most of them mainly focus on time-domain modeling, and do not fully utilize the information in the frequency domain of the time series data. In this paper, we propose a Time-Frequency analysis based time series Anomaly Detection model, or TFAD for short, to exploit both time and frequency domains for performance improvement. Besides, we incorporate time series decomposition and data augmentation mechanisms in the designed time-frequency architecture to further boost the abilities of performance and interpretability. Empirical studies on widely used benchmark datasets show that our approach obtains state-of-the-art performance in univariate and multivariate time series anomaly detection tasks. Code is provided at https://github.com/DAMO-DI-ML/CIKM22-TFAD.
    
[^85]: 《一种针对多样对话生成的等大小硬EM算法》

    An Equal-Size Hard EM Algorithm for Diverse Dialogue Generation. (arXiv:2209.14627v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2209.14627](http://arxiv.org/abs/2209.14627)

    本文提出了一种平衡约束的等大小硬EM算法，用于训练多解码器模型以实现多样的对话生成，可在小型模型中生成高质量的多样化响应。

    

    开放领域对话系统旨在以自然语言文本与人类互动。尽管像ChatGPT这样的超大型对话系统最近取得了成功，但使用中小型对话系统仍然是常见的做法，因为它们更加轻便易用。然而，在较小的模型中生成多样的对话响应是具有挑战性的。在本文中，我们提出了一种等大小硬EM（EqHard-EM）算法，用于训练多解码器模型以实现多样的对话生成。我们的算法以硬方式将样本分配给解码器，并额外施加平衡约束条件，以确保所有解码器都经过充分的训练。我们提供了详细的理论分析来证明我们的方法。此外，我们在两个大规模的开放领域对话数据集上进行实验，证明我们的EqHard-EM算法可以生成高质量的多样化响应。

    Open-domain dialogue systems aim to interact with humans through natural language texts in an open-ended fashion. Despite the recent success of super large dialogue systems such as ChatGPT, using medium-to-small-sized dialogue systems remains the common practice as they are more lightweight and accessible; however, generating diverse dialogue responses is challenging, especially with smaller models. In this work, we propose an Equal-size Hard Expectation--Maximization (EqHard-EM) algorithm to train a multi-decoder model for diverse dialogue generation. Our algorithm assigns a sample to a decoder in a hard manner and additionally imposes an equal-assignment constraint to ensure that all decoders are well-trained. We provide detailed theoretical analysis to justify our approach. Further, experiments on two large-scale open-domain dialogue datasets verify that our EqHard-EM algorithm generates high-quality diverse responses.
    
[^86]: 全部值得一试：适用于扩散模型的ViT骨干网络

    All are Worth Words: A ViT Backbone for Diffusion Models. (arXiv:2209.12152v4 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2209.12152](http://arxiv.org/abs/2209.12152)

    本文提出了一种适用于扩散模型的ViT骨干网络U-ViT，用于图像生成任务，相较于传统基于CNN的U-Net模型，U-ViT具有可比甚至更好的性能，甚至在某些任务中创造了新的FID分数记录。

    

    在各种视觉任务中，视觉变换器（ViT）已经显示出了良好的性能，而基于卷积神经网络（CNN）的U-Net在扩散模型中仍然占主导地位。我们设计了一个简单通用的ViT骨干架构（称为U-ViT），用于生成扩散模型的图像。U-ViT的特点是将所有输入，包括时间、条件和噪声图像块都视为令牌，并在浅层和深层之间使用长跳跃连接。我们在无条件和类条件图像生成以及文本到图像生成任务中评估了U-ViT，在相似大小的基于“U-Net”的CNN模型中，U-ViT具有可比甚至更好的性能。特别是U-ViT的潜在扩散模型在ImageNet 256x256类条件图像生成中取得了2.29的最佳FID分数，在MS-COCO的文本到图像生成中取得了5.48的最佳FID分数，相比其他生成模型，不需要在训练期间访问大型外部数据集。我们的结果表明，在扩散型图像生成模型中，像U-ViT这样的ViT骨干架构可以实现与传统基于CNN的U-Net模型相当或更好的性能，甚至在某些任务中创造新的FID分数记录。

    Vision transformers (ViT) have shown promise in various vision tasks while the U-Net based on a convolutional neural network (CNN) remains dominant in diffusion models. We design a simple and general ViT-based architecture (named U-ViT) for image generation with diffusion models. U-ViT is characterized by treating all inputs including the time, condition and noisy image patches as tokens and employing long skip connections between shallow and deep layers. We evaluate U-ViT in unconditional and class-conditional image generation, as well as text-to-image generation tasks, where U-ViT is comparable if not superior to a CNN-based U-Net of a similar size. In particular, latent diffusion models with U-ViT achieve record-breaking FID scores of 2.29 in class-conditional image generation on ImageNet 256x256, and 5.48 in text-to-image generation on MS-COCO, among methods without accessing large external datasets during the training of generative models. Our results suggest that, for diffusion-b
    
[^87]: 基于智能CCTV相机和语义分割的CNN智能路灯管理

    CNN based Intelligent Streetlight Management Using Smart CCTV Camera and Semantic Segmentation. (arXiv:2209.08633v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2209.08633](http://arxiv.org/abs/2209.08633)

    本研究提出了一种基于智能交通监测系统和CCTV相机的自动化路灯控制方法，利用语义分割技术检测行人或车辆的存在并调节LED路灯的亮度，减少了能源浪费和环境影响。

    

    街灯是最容易被忽视的能源浪费源之一，其在不需要照明的区域发出过多的光线，造成巨大的经济和环境影响。由于传统的人工操作方式，街灯常常会在白天被打开，在晚上被关闭，这在21世纪仍然很遗憾。因此需要自动化的路灯控制方法来解决这些问题。本研究旨在通过将由计算机视觉技术驱动的智能交通监测系统与闭路电视(CCTV)相机相结合，利用CCTV视频流中的语义图像分割检测行人或车辆的存在并在其缺席时调节街灯的亮度，从而开发一种新型的路灯控制方法。因此，我们的模型区分白天和黑夜，并根据需要自动调节LED路灯的亮度。

    One of the most neglected sources of energy loss is streetlights which generate too much light in areas where it is not required. Energy waste has enormous economic and environmental effects. In addition, due to the conventional manual nature of the operation, streetlights are frequently seen being turned ON during the day and OFF in the evening, which is regrettable even in the twenty-first century. These issues require automated streetlight control in order to be resolved. This study aims to develop a novel streetlight controlling method by combining a smart transport monitoring system powered by computer vision technology with a closed circuit television (CCTV) camera that allows the light-emitting diode (LED) streetlight to automatically light up with the appropriate brightness by detecting the presence of pedestrians or vehicles and dimming the streetlight in their absence using semantic image segmentation from the CCTV video streaming. Consequently, our model distinguishes daylig
    
[^88]: 基于注意力的元宇宙xURLLC服务资源分配和QoE分析

    Attention-aware Resource Allocation and QoE Analysis for Metaverse xURLLC Services. (arXiv:2208.05438v5 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2208.05438](http://arxiv.org/abs/2208.05438)

    本文研究了元宇宙xURLLC服务资源分配和QoE分析，提出了一个最优合同设计框架。在数学上模拟QoE的新型度量标准Meta-Immersion有助于在满足客户端物理需求的情况下，提供个性化沉浸式体验。

    

    元宇宙代表了我们对下一代互联网的期望，并带来了新的关键绩效指标（KPI） 。虽然传统的超可靠性和低时延通信（URLLC）可以满足客观的KPI，但很难提供个性化的沉浸式体验，这是元宇宙的独特特点。由于体验质量（QoE）可以被视为综合的KPI，因此URLLC被演变为具有个性化资源分配方案的下一代URLLC（xURLLC）来实现更高的QoE。为了部署元宇宙xURLLC服务，我们研究了元宇宙服务提供商（MSP）和网络基础设施提供商（InP）之间的交互，并提供了一个最优合同设计框架。具体而言，我们旨在最大化MSP的效用，该效用被定义为元宇宙用户QoE的函数，同时确保InP的激励。为了在数学上模拟QoE，我们提出了一个名为Meta-Immersion的新型度量标准。

    Metaverse encapsulates our expectations of the next-generation Internet, while bringing new key performance indicators (KPIs). Although conventional ultra-reliable and low-latency communications (URLLC) can satisfy objective KPIs, it is difficult to provide a personalized immersive experience that is a distinctive feature of the Metaverse. Since the quality of experience (QoE) can be regarded as a comprehensive KPI, the URLLC is evolved towards the next generation URLLC (xURLLC) with a personalized resource allocation scheme to achieve higher QoE. To deploy Metaverse xURLLC services, we study the interaction between the Metaverse service provider (MSP) and the network infrastructure provider (InP), and provide an optimal contract design framework. Specifically, the utility of the MSP, defined as a function of Metaverse users' QoE, is to be maximized, while ensuring the incentives of the InP. To model the QoE mathematically, we propose a novel metric named Meta-Immersion that incorporat
    
[^89]: 基于AI的有机化学超图网络：网络统计和反应分类应用

    AI-driven Hypergraph Network of Organic Chemistry: Network Statistics and Applications in Reaction Classification. (arXiv:2208.01647v2 [q-bio.MN] UPDATED)

    [http://arxiv.org/abs/2208.01647](http://arxiv.org/abs/2208.01647)

    本文通过将化学反应表示为超图，构建了基于AI的有机化学超图网络并进行了统计研究，为反应分类提供了新思路。

    

    近年来，高通量筛选的进展、更复杂化学设计空间的可访问性以及精确的分子建模框架的发展，促进了新反应和分子的快速发现。因此，需要进行关注最近趋势并将其外推到可能的未来轨迹的综合性研究来理解不断增长的化学文献。为此，已经报告了几个基于网络理论的研究，这些研究使用化学反应的有向图表示。在这里，我们使用超图来表示化学反应，其中超边表示化学反应，节点表示参与的分子。我们使用标准的反应数据集构造了一个超网络，并报告其统计信息，例如度分布、平均路径长度、同配性或度相关性、PageRank 中心性和基于图的聚类（或社区）。

    Rapid discovery of new reactions and molecules in recent years has been facilitated by the advancements in high throughput screening, accessibility to a much more complex chemical design space, and the development of accurate molecular modeling frameworks. A holistic study of the growing chemistry literature is, therefore, required that focuses on understanding the recent trends and extrapolating them into possible future trajectories. To this end, several network theory-based studies have been reported that use a directed graph representation of chemical reactions. Here, we perform a study based on representing chemical reactions as hypergraphs where the hyperedges represent chemical reactions and nodes represent the participating molecules. We use a standard reactions dataset to construct a hypernetwork and report its statistics such as degree distributions, average path length, assortativity or degree correlations, PageRank centrality, and graph-based clusters (or communities). We a
    
[^90]: 在视觉识别中通过互相对比学习的在线知识蒸馏

    Online Knowledge Distillation via Mutual Contrastive Learning for Visual Recognition. (arXiv:2207.11518v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2207.11518](http://arxiv.org/abs/2207.11518)

    该论文提出了一种互相对比学习的在线知识蒸馏框架，可以让不同的学生模型互相学习到额外的对比知识，从而提高了视觉识别任务的性能。

    

    无需教师的在线知识蒸馏旨在通过合作训练一组多个学生模型并相互蒸馏知识。虽然现有的在线知识蒸馏方法能够达到理想的性能，但它们通常将类概率作为核心知识类型，忽略了有价值的特征表示信息。我们提出了一种互相对比学习的在线知识蒸馏框架，其核心思想是在一组网络之间进行互相交互和对比分布的转移。我们的方法可以汇总不同网络之间的嵌入信息，并最大化两个网络之间互信息的下限。这使得每个网络都可以从其他网络中学习到额外的对比知识，从而改善特征表示，提高视觉识别任务的性能。除了最后一层，我们还将MCL扩展到中间层，并进行自适应层匹配机制的训练。

    The teacher-free online Knowledge Distillation (KD) aims to train an ensemble of multiple student models collaboratively and distill knowledge from each other. Although existing online KD methods achieve desirable performance, they often focus on class probabilities as the core knowledge type, ignoring the valuable feature representational information. We present a Mutual Contrastive Learning (MCL) framework for online KD. The core idea of MCL is to perform mutual interaction and transfer of contrastive distributions among a cohort of networks in an online manner. Our MCL can aggregate cross-network embedding information and maximize the lower bound to the mutual information between two networks. This enables each network to learn extra contrastive knowledge from others, leading to better feature representations, thus improving the performance of visual recognition tasks. Beyond the final layer, we extend MCL to intermediate layers and perform an adaptive layer-matching mechanism train
    
[^91]: 从哪里开始？关于联邦学习中预训练和初始化的影响。

    Where to Begin? On the Impact of Pre-Training and Initialization in Federated Learning. (arXiv:2206.15387v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.15387](http://arxiv.org/abs/2206.15387)

    该论文研究了在联邦学习中从预训练模型开始的影响，证明这种方法可以减少训练时间并提高模型的准确性。

    

    联邦学习中的一个常见挑战是异构性问题。数据异构性是指来自不同客户端的数据可能遵循非常不同的分布。系统异构性是指客户端设备具有不同的系统能力。许多联邦优化方法都解决了这个挑战。虽然文献中的实证评估通常从随机初始化开始联邦训练，但在许多实际的联邦学习应用中，服务器可以访问用于训练任务的代理数据，可以用这些数据在开始联邦训练之前预训练模型。使用四个标准联邦学习基准数据集，我们经验性地研究了在联邦学习中从经过预训练的模型开始的影响。不出所料，从经过预训练的模型开始可以减少达到目标误差率所需的训练时间，并使模型训练更准确（高达40％）。

    An oft-cited challenge of federated learning is the presence of heterogeneity. \emph{Data heterogeneity} refers to the fact that data from different clients may follow very different distributions. \emph{System heterogeneity} refers to client devices having different system capabilities. A considerable number of federated optimization methods address this challenge. In the literature, empirical evaluations usually start federated training from random initialization. However, in many practical applications of federated learning, the server has access to proxy data for the training task that can be used to pre-train a model before starting federated training. Using four standard federated learning benchmark datasets, we empirically study the impact of starting from a pre-trained model in federated learning. Unsurprisingly, starting from a pre-trained model reduces the training time required to reach a target error rate and enables the training of more accurate models (up to 40\%) than is
    
[^92]: 基于时间序列的数据增强技术：一份综述和分类

    Data Augmentation techniques in time series domain: A survey and taxonomy. (arXiv:2206.13508v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.13508](http://arxiv.org/abs/2206.13508)

    本综述介绍了基于时间序列数据增强技术的最新进展，并提出了一个分类法，旨在提高训练深度神经网络的数据集的大小和一致性，从而提高模型的效率和性能。

    

    随着深度学习建模的最新进展，利用其在时间序列领域中出色性能的方式并不需要太长时间。深度神经网络在处理时间序列方面严重依赖于训练中使用的数据集的大小和一致性。这些特征通常在现实世界中并不丰富，通常受到限制和需要保证的约束。因此，提高数据量的有效方法是使用数据增强技术，无论是通过添加噪声或置换还是生成新的合成数据。本文系统地回顾了该领域中的最新技术现状，提供了所有可用算法的概述，并提出了最相关研究的分类法。不同变体的效率将作为该过程的中心部分进行评估，同时还将评估不同的性能指标以及每个模型的主要问题。

    With the latest advances in Deep Learning-based} generative models, it has not taken long to take advantage of their remarkable performance in the area of time series. Deep neural networks used to work with time series heavily depend on the size and consistency of the datasets used in training. These features are not usually abundant in the real world, where they are usually limited and often have constraints that must be guaranteed. Therefore, an effective way to increase the amount of data is by using Data Augmentation techniques, either by adding noise or permutations and by generating new synthetic data. This work systematically reviews the current state-of-the-art in the area to provide an overview of all available algorithms and proposes a taxonomy of the most relevant research. The efficiency of the different variants will be evaluated as a central part of the process, as well as the different metrics to evaluate the performance and the main problems concerning each model will b
    
[^93]: 随机特征回归模型的最佳激活函数

    Optimal Activation Functions for the Random Features Regression Model. (arXiv:2206.01332v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2206.01332](http://arxiv.org/abs/2206.01332)

    本文确定了随机特征回归模型的最佳激活函数。这些函数可能是线性的、饱和线性函数或基于Hermite多项式的函数。使用最佳激活函数会影响RFR模型的重要特性，如双峰曲线和最佳正则化参数与噪声水平的相关性。

    

    近期已研究了随机特征回归模型(RFR)的渐近均方测试误差和灵敏度。我们在此基础上，通过不同的函数简洁概念，确定了在闭合形式下极小化RFR测试误差和灵敏度组合的激活函数(AF)族群。我们发现在某些场景下，最佳AF可以是线性的、饱和线性函数或基于Hermite多项式表示的函数。最后，我们展示了使用最佳AF如何影响RFR模型的重要特性，比如双峰曲线和其最佳正则化参数与观察噪声水平的相关性。

    The asymptotic mean squared test error and sensitivity of the Random Features Regression model (RFR) have been recently studied. We build on this work and identify in closed-form the family of Activation Functions (AFs) that minimize a combination of the test error and sensitivity of the RFR under different notions of functional parsimony. We find scenarios under which the optimal AFs are linear, saturated linear functions, or expressible in terms of Hermite polynomials. Finally, we show how using optimal AFs impacts well-established properties of the RFR model, such as its double descent curve, and the dependency of its optimal regularization parameter on the observation noise level.
    
[^94]: 顺序人类教学的机器学习解释性研究

    Explanatory machine learning for sequential human teaching. (arXiv:2205.10250v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2205.10250](http://arxiv.org/abs/2205.10250)

    本文研究了顺序问题解决中，课程顺序和机器学习解释对人类理解力的影响。

    

    最近越来越多的人关注机器学习理论的可理解性。归纳逻辑编程（ILP）使用逻辑编程技术基于缩略推理和归纳推理，从少量的数据中得出逻辑理论。学得的理论以规则形式表示，是所获知识的声明性描述。在早期研究中，作者首次提出了基于机器学习逻辑规则的简单分类任务对人类理解能力有可衡量的提高的证据。在后续的研究中，发现向人类展示机器学习解释 在游戏学习环境中产生了有益和有害的影响。我们通过研究概念呈现的顺序对人类理解力的影响来继续探讨可理解性。在这项工作中，我们研究了课程顺序和机器学习解释对于顺序问题解决的解释效果。

    The topic of comprehensibility of machine-learned theories has recently drawn increasing attention. Inductive Logic Programming (ILP) uses logic programming to derive logic theories from small data based on abduction and induction techniques. Learned theories are represented in the form of rules as declarative descriptions of obtained knowledge. In earlier work, the authors provided the first evidence of a measurable increase in human comprehension based on machine-learned logic rules for simple classification tasks. In a later study, it was found that the presentation of machine-learned explanations to humans can produce both beneficial and harmful effects in the context of game learning. We continue our investigation of comprehensibility by examining the effects of the ordering of concept presentations on human comprehension. In this work, we examine the explanatory effects of curriculum order and the presence of machine-learned explanations for sequential problem-solving. We show th
    
[^95]: “跨摄像头轨迹辅助相机网络中的人员检索”

    Cross-Camera Trajectories Help Person Retrieval in a Camera Network. (arXiv:2204.12900v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2204.12900](http://arxiv.org/abs/2204.12900)

    本文提出了一种基于跨摄像头轨迹生成的行人检索框架，该框架在时间和空间信息中进行了结合。通过提取跨摄像头轨迹并进行条件随机场模型和受限非负矩阵分解的优化，最终提高了检索效果。

    

    本文关注如何从一个非覆盖的摄像头网络中的多个视频中检索出一个查询对象的身份。目前已有的方法往往依赖于视觉匹配或者考虑时间约束，但是忽略了摄像头网格的空间信息。为了解决这个问题，我们提出了一种基于跨摄像头轨迹生成的行人检索框架，将时间和空间信息结合起来。为了获取行人轨迹，我们提出了一种新颖的跨摄像头时空模型，它结合了行人的行走习惯和相邻摄像头之间的路径布局，形成了一个联合概率分布。这样的时空模型可以基于稀疏采样的行人数据在摄像头网络中实现。基于这个时空模型，可以通过条件随机场模型提取跨摄像头轨迹，并通过受限非负矩阵分解进行进一步优化。最后，文章提出了一种轨迹重新排序技术来提高检索效果。

    We are concerned with retrieving a query person from multiple videos captured by a non-overlapping camera network. Existing methods often rely on purely visual matching or consider temporal constraints but ignore the spatial information of the camera network. To address this issue, we propose a pedestrian retrieval framework based on cross-camera trajectory generation, which integrates both temporal and spatial information. To obtain pedestrian trajectories, we propose a novel cross-camera spatio-temporal model that integrates pedestrians' walking habits and the path layout between cameras to form a joint probability distribution. Such a spatio-temporal model among a camera network can be specified using sparsely sampled pedestrian data. Based on the spatio-temporal model, cross-camera trajectories can be extracted by the conditional random field model and further optimized by restricted non-negative matrix factorization. Finally, a trajectory re-ranking technique is proposed to improv
    
[^96]: CLIP-Dissect：深度视觉网络中神经元表示的自动描述

    CLIP-Dissect: Automatic Description of Neuron Representations in Deep Vision Networks. (arXiv:2204.10965v4 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2204.10965](http://arxiv.org/abs/2204.10965)

    CLIP-Dissect是一种用于自动描述视觉网络中神经元功能的新技术，它可以无需任何标记数据或人类示例即将内部神经元标记为无需任何标记数据或人类示例的开放概念，并比现有方法提供了更准确的描述。此外，它具有灵活性、高效性和可扩展性。

    

    本文提出了一种新技术CLIP-Dissect，可以自动描述视觉网络中单个隐藏神经元的功能。CLIP-Dissect利用了最近在多模态视觉/语言模型方面的进展，将内部神经元标记为无需任何标记数据或人类示例的开放概念。我们证明了CLIP-Dissect提供了比现有方法更准确的描述，其中包括具备“地面真相”（ground-truth）的最后一层神经元以及具备定性好的隐藏层神经元。此外，该方法非常灵活：它与模型无关，可以轻松处理新概念，可以扩展以利用未来更好的多模态模型。最后，CLIP-Dissect计算效率高，可以在短短4分钟内标记ResNet-50的五层所有神经元，比现有方法快10倍以上。我们的代码可在https://github.com/Trustworthy-ML-Lab/CLIP-dissect 上找到。

    In this paper, we propose CLIP-Dissect, a new technique to automatically describe the function of individual hidden neurons inside vision networks. CLIP-Dissect leverages recent advances in multimodal vision/language models to label internal neurons with open-ended concepts without the need for any labeled data or human examples. We show that CLIP-Dissect provides more accurate descriptions than existing methods for last layer neurons where the ground-truth is available as well as qualitatively good descriptions for hidden layer neurons. In addition, our method is very flexible: it is model agnostic, can easily handle new concepts and can be extended to take advantage of better multimodal models in the future. Finally CLIP-Dissect is computationally efficient and can label all neurons from five layers of ResNet-50 in just 4 minutes, which is more than 10 times faster than existing methods. Our code is available at https://github.com/Trustworthy-ML-Lab/CLIP-dissect.
    
[^97]: CgAT：基于中心引导的对抗性训练提升Hashing检索鲁棒性

    CgAT: Center-Guided Adversarial Training for Deep Hashing-Based Retrieval. (arXiv:2204.10779v5 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2204.10779](http://arxiv.org/abs/2204.10779)

    本文提出了CgAT方法，基于中心引导的对抗性训练方法，可提升深度Hashing网络检索的鲁棒性，取得了领先于现有方法的效果。

    

    深度Hashing在图像检索领域被广泛应用，但往往容易受到对抗样本的攻击。为此，本文提出了基于min-max的中心引导的对抗性训练方法（CgAT），通过最坏的对抗性样本来提高深度Hashing网络的鲁棒性。实验表明，该方法在多个基准数据集上优于目前深度Hashing检索领域中的最新对抗性防御算法。

    Deep hashing has been extensively utilized in massive image retrieval because of its efficiency and effectiveness. However, deep hashing models are vulnerable to adversarial examples, making it essential to develop adversarial defense methods for image retrieval. Existing solutions achieved limited defense performance because of using weak adversarial samples for training and lacking discriminative optimization objectives to learn robust features. In this paper, we present a min-max based Center-guided Adversarial Training, namely CgAT, to improve the robustness of deep hashing networks through worst adversarial examples. Specifically, we first formulate the center code as a semantically-discriminative representative of the input image content, which preserves the semantic similarity with positive samples and dissimilarity with negative examples. We prove that a mathematical formula can calculate the center code immediately. After obtaining the center codes in each optimization iterati
    
[^98]: CGC: 对比图聚类用于社区发现和跟踪

    CGC: Contrastive Graph Clustering for Community Detection and Tracking. (arXiv:2204.08504v3 [cs.SI] UPDATED)

    [http://arxiv.org/abs/2204.08504](http://arxiv.org/abs/2204.08504)

    本文提出了一种全新的图聚类算法CGC，采用对比学习进行自监督表示学习，结合跟踪模块以应对动态图拓扑变化，在社区发现和跟踪方面表现出领先的状态。

    

    本文从图聚类的角度入手，探讨在网络数据中发现实体和实体之间的交互以及对它们进行社区跟踪的方法。我们提出了一种全新的端到端框架CGC，该方法利用对比学习范式进行自监督表示学习，并采用了跟踪模块以应对不断变化的图形拓扑。在各个真实场景和合成基准上，我们对CGC进行了评估，并在社区发现和跟踪方面展示出了卓越的性能，尤其在动态图上表现出了领先的状态。

    Given entities and their interactions in the web data, which may have occurred at different time, how can we find communities of entities and track their evolution? In this paper, we approach this important task from graph clustering perspective. Recently, state-of-the-art clustering performance in various domains has been achieved by deep clustering methods. Especially, deep graph clustering (DGC) methods have successfully extended deep clustering to graph-structured data by learning node representations and cluster assignments in a joint optimization framework. Despite some differences in modeling choices (e.g., encoder architectures), existing DGC methods are mainly based on autoencoders and use the same clustering objective with relatively minor adaptations. Also, while many real-world graphs are dynamic, previous DGC methods considered only static graphs. In this work, we develop CGC, a novel end-to-end framework for graph clustering, which fundamentally differs from existing meth
    
[^99]: 基于元学习的跨模态提示的多模态小样本目标检测

    Multi-Modal Few-Shot Object Detection with Meta-Learning-Based Cross-Modal Prompting. (arXiv:2204.07841v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2204.07841](http://arxiv.org/abs/2204.07841)

    本文提出了一种基于元学习的跨模态提示的多模态小样本目标检测方法，该方法不需要微调，结合了视觉样本和语义信息，并取得了最先进的性能。

    

    本文研究了多模态小样本目标检测的问题，在检测中使用了视觉样本和语义信息，这些信息的使用是互补的。当前的多模态小样本目标检测方法大多是基于微调的，这对于在线应用来说效率较低。此外，这些方法通常需要专业知识，如类名等，以提取类语义嵌入，对于罕见类来说比较困难。我们的方法受到度量学习和基于提示的学习的高层概念相似性的启发，分别通过元学习和基于提示的学习来学习通用的小样本和零样本目标检测模型，而无需微调。具体来说，我们结合元学习和基于提示的学习分别学得的小样本视觉分类器和文本分类器来建立多模态分类器和检测模型。此外，为了充分利用预训练的语言模型，我们提出了基于元学习的跨模态提示来辅助检测器生成更全面的建议。在三个公共数据集上的实验结果表明，我们提出的方法在小样本和零样本检测任务方面均达到了最先进的性能。

    We study multi-modal few-shot object detection (FSOD) in this paper, using both few-shot visual examples and class semantic information for detection, which are complementary to each other by definition. Most of the previous works on multi-modal FSOD are fine-tuning-based which are inefficient for online applications. Moreover, these methods usually require expertise like class names to extract class semantic embedding, which are hard to get for rare classes. Our approach is motivated by the high-level conceptual similarity of (metric-based) meta-learning and prompt-based learning to learn generalizable few-shot and zero-shot object detection models respectively without fine-tuning. Specifically, we combine the few-shot visual classifier and text classifier learned via meta-learning and prompt-based learning respectively to build the multi-modal classifier and detection models. In addition, to fully exploit the pre-trained language models, we propose meta-learning-based cross-modal pro
    
[^100]: 计算机视觉GAN综述：最新研究、分析和分类（arXiv：2203.11242v2 [cs.LG] UPDATED）

    A survey on GANs for computer vision: Recent research, analysis and taxonomy. (arXiv:2203.11242v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2203.11242](http://arxiv.org/abs/2203.11242)

    本文综述了GAN的最新架构、损失函数优化、验证指标和应用领域，并提出了一个分类法以更好地理解计算机视觉中GAN的现状。

    

    在过去的几年中，深度学习领域已经进行了几次革命，其中最受关注的是生成对抗网络（GANs）的巨大影响。GAN不仅在定义其模型时提供了独特的架构，而且生成了引人注目的结果，对社会产生了直接影响。由于GAN带来的重大改进和新的研究领域，社区不断提出新的研究，使得跟上时代几乎是不可能的。我们的综述旨在提供GAN的概述，展示最新的架构、损失函数的优化、验证指标和最广泛认可的变体的应用领域。将评估不同变体的模型架构效率，展示最佳的应用领域；作为该过程的重要组成部分，将分析评估GAN性能的不同度量标准和经常使用的损失函数。最后，将提出一个分类法以更好地理解GAN在计算机视觉领域中的现状。

    In the last few years, there have been several revolutions in the field of deep learning, mainly headlined by the large impact of Generative Adversarial Networks (GANs). GANs not only provide an unique architecture when defining their models, but also generate incredible results which have had a direct impact on society. Due to the significant improvements and new areas of research that GANs have brought, the community is constantly coming up with new researches that make it almost impossible to keep up with the times. Our survey aims to provide a general overview of GANs, showing the latest architectures, optimizations of the loss functions, validation metrics and application areas of the most widely recognized variants. The efficiency of the different variants of the model architecture will be evaluated, as well as showing the best application area; as a vital part of the process, the different metrics for evaluating the performance of GANs and the frequently used loss functions will
    
[^101]: 监督学习的信息论框架

    An Information-Theoretic Framework for Supervised Learning. (arXiv:2203.00246v6 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2203.00246](http://arxiv.org/abs/2203.00246)

    本文提出了一种信息论框架，分析机器学习的数据需求，研究了由具有ReLU激活单元的深度神经网络生成的数据的学习样本复杂度，提出了样本复杂度边界。

    

    每年，深度学习展示出更加新颖和优秀的经验结果，其中采用更深和更广的神经网络。同时，利用现有的理论框架，分析超过两层的神经网络是困难的，除非诉诸于计数参数或遭遇深度指数样本复杂度边界。因此，在不同的角度下分析现代机器学习可能是有成果的。本文提出了一种新的信息论框架，具有自己的遗憾和样本复杂度概念，用于分析机器学习的数据需求。我们首先通过一些经典案例，例如标量估计和线性回归，使用我们的框架建立直觉和介绍一般技术。然后，我们利用该框架研究了由具有ReLU激活单元的深度神经网络生成的数据的学习样本复杂度。对于权重的特定先验分布，我们建立了学习的样本复杂度边界。

    Each year, deep learning demonstrates new and improved empirical results with deeper and wider neural networks. Meanwhile, with existing theoretical frameworks, it is difficult to analyze networks deeper than two layers without resorting to counting parameters or encountering sample complexity bounds that are exponential in depth. Perhaps it may be fruitful to try to analyze modern machine learning under a different lens. In this paper, we propose a novel information-theoretic framework with its own notions of regret and sample complexity for analyzing the data requirements of machine learning. With our framework, we first work through some classical examples such as scalar estimation and linear regression to build intuition and introduce general techniques. Then, we use the framework to study the sample complexity of learning from data generated by deep neural networks with ReLU activation units. For a particular prior distribution on weights, we establish sample complexity bounds tha
    
[^102]: 使用深度神经网络的无监督点云表示学习综述

    Unsupervised Point Cloud Representation Learning with Deep Neural Networks: A Survey. (arXiv:2202.13589v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2202.13589](http://arxiv.org/abs/2202.13589)

    该论文综述了最近使用深度神经网络进行无监督点云表示学习的相关研究，旨在从未标记的点云数据中学习通用和有用的点云表示，克服了大规模点云标记的限制。

    

    由于其在各种逆境下的卓越精确性和鲁棒性，点云数据已被广泛探索。同时，深度神经网络（DNN）在各种应用中取得了非常印象深刻的成功，例如监控和自动驾驶。点云和DNN的融合导致了许多深层点云模型，主要在大规模和稠密标记的点云数据的监督下进行训练。由于大规模点云标记的限制，最近引起了越来越多关于从未标记的点云数据中学习通用和有用的点云表示的无监督点云表示学习的关注。本文全面评述了使用DNN进行无监督点云表示学习的相关研究。首先描述了最近研究的动机、一般流程以及术语。然后描述了广泛采用的点云数据集和DNN架构的相关背景。

    Point cloud data have been widely explored due to its superior accuracy and robustness under various adverse situations. Meanwhile, deep neural networks (DNNs) have achieved very impressive success in various applications such as surveillance and autonomous driving. The convergence of point cloud and DNNs has led to many deep point cloud models, largely trained under the supervision of large-scale and densely-labelled point cloud data. Unsupervised point cloud representation learning, which aims to learn general and useful point cloud representations from unlabelled point cloud data, has recently attracted increasing attention due to the constraint in large-scale point cloud labelling. This paper provides a comprehensive review of unsupervised point cloud representation learning using DNNs. It first describes the motivation, general pipelines as well as terminologies of the recent studies. Relevant background including widely adopted point cloud datasets and DNN architectures is then b
    
[^103]: PGMax: 用于离散概率图模型和JAX中的循环置信传播的因子图

    PGMax: Factor Graphs for Discrete Probabilistic Graphical Models and Loopy Belief Propagation in JAX. (arXiv:2202.04110v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2202.04110](http://arxiv.org/abs/2202.04110)

    PGMax是一个用于离散概率图模型的因子图工具，可以在JAX中自动运行高效且可扩展的循环置信传播，与现有替代方案相比，PGMax获得了更高质量的推理结果，推理时间加速高达三个数量级。

    PGMax is a factor graph tool for discrete probabilistic graphical models that automatically runs efficient and scalable loopy belief propagation in JAX. Compared with existing alternatives, PGMax obtains higher-quality inference results with up to three orders-of-magnitude inference time speedups.

    PGMax是一个开源的Python包，用于轻松指定离散概率图模型（PGMs）作为因子图，并在JAX中自动运行高效且可扩展的循环置信传播（LBP）。PGMax支持具有可处理因子的一般因子图，并利用现代加速器（如GPU）进行推理。与现有替代方案相比，PGMax获得了更高质量的推理结果，推理时间加速高达三个数量级。PGMax还与快速增长的JAX生态系统无缝交互，开启了新的研究可能性。我们的源代码、示例和文档可在https://github.com/deepmind/PGMax上获得。

    PGMax is an open-source Python package for (a) easily specifying discrete Probabilistic Graphical Models (PGMs) as factor graphs; and (b) automatically running efficient and scalable loopy belief propagation (LBP) in JAX. PGMax supports general factor graphs with tractable factors, and leverages modern accelerators like GPUs for inference. Compared with existing alternatives, PGMax obtains higher-quality inference results with up to three orders-of-magnitude inference time speedups. PGMax additionally interacts seamlessly with the rapidly growing JAX ecosystem, opening up new research possibilities. Our source code, examples and documentation are available at https://github.com/deepmind/PGMax.
    
[^104]: AnomMAN: 检测多视图属性网络上的异常

    AnomMAN: Detect Anomaly on Multi-view Attributed Networks. (arXiv:2201.02822v2 [cs.SI] UPDATED)

    [http://arxiv.org/abs/2201.02822](http://arxiv.org/abs/2201.02822)

    这篇论文提出了一种基于图卷积的框架 AnomMAN，用于检测多视图属性网络上的异常。它使用注意机制来定义网络中所有视图的重要性，并使用残差学习来捕捉高频信号。实验证明 AnomMAN 在检测准确性方面优于现有方法。

    

    属性网络上的异常检测被广泛应用于在线购物、金融交易、通信网络等领域。然而，大多数现有的工作只考虑单一种类的交互来检测属性网络上的异常，因此无法处理多视图属性网络上的各种不同交互。在综合考虑所有不同交互并检测多视图属性网络上的异常实例仍然是一个具有挑战性的任务。本文提出了一种名为 AnomMAN 的基于图卷积的框架来检测多视图属性网络上的异常。为了共同考虑多视图属性网络上的属性和所有种类的交互，我们使用注意机制来定义网络中所有视图的重要性。由于图卷积操作的低通特性滤除了大多数高频信号（异常信号），因此不能直接应用于异常检测任务。AnomMAN 被设计为聚合不同视图的特征，并使用残差学习来捕捉高频信号。在几个真实数据集上的大量实验证明，AnomMAN 在检测准确性方面优于现有方法。

    Anomaly detection on attributed networks is widely used in online shopping, financial transactions, communication networks, and so on. However, most existing works trying to detect anomalies on attributed networks only consider a single kind of interaction, so they cannot deal with various kinds of interactions on multi-view attributed networks. It remains a challenging task to jointly consider all different kinds of interactions and detect anomalous instances on multi-view attributed networks. In this paper, we propose a graph convolution-based framework, named AnomMAN, to detect Anomaly on Multi-view Attributed Networks. To jointly consider attributes and all kinds of interactions on multi-view attributed networks, we use the attention mechanism to define the importance of all views in networks. Since the low-pass characteristic of graph convolution operation filters out most high-frequency signals (aonmaly signals), it cannot be directly applied to anomaly detection tasks. AnomMAN i
    
[^105]: FLSys：面向联邦学习移动应用的开放生态系统

    FLSys: Toward an Open Ecosystem for Federated Learning Mobile Apps. (arXiv:2111.09445v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2111.09445](http://arxiv.org/abs/2111.09445)

    本文介绍了FLSys，一个移动-云联邦学习（FL）系统，可以成为FL模型和应用程序开放生态系统的关键组成部分。FLSys旨在在智能手机上使用移动感测数据。它平衡了模型性能和资源消耗，容忍通信故障，并实现了可扩展性。FLSys提供了先进的隐私保护机制和一个通用的API，供第三方应用程序开发人员访问FL模型。

    This article introduces FLSys, a mobile-cloud federated learning (FL) system that can be a key component for an open ecosystem of FL models and apps. FLSys is designed to work on smart phones with mobile sensing data. It balances model performance with resource consumption, tolerates communication failures, and achieves scalability. FLSys provides advanced privacy preserving mechanisms and a common API for third-party app developers to access FL models.

    本文介绍了FLSys的设计、实现和评估，这是一个移动-云联邦学习（FL）系统，可以成为FL模型和应用程序开放生态系统的关键组成部分。FLSys旨在在智能手机上使用移动感测数据。它平衡了模型性能和资源消耗，容忍通信故障，并实现了可扩展性。在FLSys中，不同的DL模型和不同的FL聚合方法可以同时被不同的应用程序训练和访问。此外，FLSys提供了先进的隐私保护机制和一个通用的API，供第三方应用程序开发人员访问FL模型。FLSys采用模块化设计，实现在Android和AWS云中。我们与人类活动识别（HAR）模型共同设计了FLSys。在4个月的时间里，从100多名大学生中收集了HAR感测数据。我们实现了HAR-Wild，这是一个针对移动设备量身定制的CNN模型，具有数据增强机制以减轻p

    This article presents the design, implementation, and evaluation of FLSys, a mobile-cloud federated learning (FL) system, which can be a key component for an open ecosystem of FL models and apps. FLSys is designed to work on smart phones with mobile sensing data. It balances model performance with resource consumption, tolerates communication failures, and achieves scalability. In FLSys, different DL models with different FL aggregation methods can be trained and accessed concurrently by different apps. Furthermore, FLSys provides advanced privacy preserving mechanisms and a common API for third-party app developers to access FL models. FLSys adopts a modular design and is implemented in Android and AWS cloud. We co-designed FLSys with a human activity recognition (HAR) model. HAR sensing data was collected in the wild from 100+ college students during a 4-month period. We implemented HAR-Wild, a CNN model tailored to mobile devices, with a data augmentation mechanism to mitigate the p
    
[^106]: WEDGE：基于网络图像辅助的语义分割领域泛化

    WEDGE: Web-Image Assisted Domain Generalization for Semantic Segmentation. (arXiv:2109.14196v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2109.14196](http://arxiv.org/abs/2109.14196)

    本研究提出了一种基于网络图像辅助的领域泛化方法，利用网络抓取的大量现实图像数据集来增加数据的多样性，提高模型泛化能力，在未见过的领域中表现良好。

    

    针对语义分割的领域泛化问题，在现实应用场景中，训练好的模型需要在之前未见过的领域表现出良好的效果，但面临着训练数据无法覆盖各种可能看不见的领域分布的挑战。本文提出了WEb-image辅助的Domain GEneralization（WEDGE）方案，这是首个利用网络抓取图像的多样性来进行普适语义分割的方法。为了探索和利用现实中的数据分布，我们收集了一个网络抓取的数据集，其中包括了不同的天气条件、网站、光照、相机风格等各种多样性。同时，我们提出了一种方法，可以在训练过程中实时地将网络抓取数据的风格表示注入源领域，从而使网络经历具有可靠标签的不同风格的图像以进行有效的训练。此外，我们使用网络抓取数据集和预测伪标签来增强泛化能力，使模型在以前未见过的领域中表现出良好的效果。

    Domain generalization for semantic segmentation is highly demanded in real applications, where a trained model is expected to work well in previously unseen domains. One challenge lies in the lack of data which could cover the diverse distributions of the possible unseen domains for training. In this paper, we propose a WEb-image assisted Domain GEneralization (WEDGE) scheme, which is the first to exploit the diversity of web-crawled images for generalizable semantic segmentation. To explore and exploit the real-world data distributions, we collect a web-crawled dataset which presents large diversity in terms of weather conditions, sites, lighting, camera styles, etc. We also present a method which injects the style representation of the web-crawled data into the source domain on-the-fly during training, which enables the network to experience images of diverse styles with reliable labels for effective training. Moreover, we use the web-crawled dataset with predicted pseudo labels for 
    
[^107]: FGLP：移动用户联邦细粒度位置预测系统

    FGLP: A Federated Fine-Grained Location Prediction System for Mobile Users. (arXiv:2106.08946v1 [cs.LG] CROSS LISTED)

    [http://arxiv.org/abs/2106.08946](http://arxiv.org/abs/2106.08946)

    FGLP是一个联邦学习框架和预测模型组成的系统，将智能手机上收集的GPS轨迹抽象为2D空间中的相对点，合并了BiLSTM和CNN以捕获时间和空间模式，实现了8米的预测精度，且数据发送开销降低了两个数量级。

    

    智能手机上的细粒度位置预测可以用于改进应用程序/系统性能。 应用场景包括根据预测用户位置的5G网络质量自适应视频质量，以及基于预测用户位置加速内容渲染的增强现实应用程序。 这些用例要求预测误差与GPS误差相同，并且目前在位置预测方面没有任何现有工作可以实现这种精度水平。我们提出了一种基于手机上收集的GPS轨迹的移动用户的细粒度位置预测系统（FGLP）。 FGLP有两个组件：联邦学习框架和预测模型。 该框架在用户的手机上以及在协调系统中的所有用户的服务器上运行学习。 FGLP将用户位置数据表示为抽象2D空间中的相对点，这使得可以跨不同的物理空间进行学习。 该模型合并了双向长短期记忆（BiLSTM）和卷积神经网络（CNN）以捕获GPS轨迹中的时间和空间模式。 仿真结果表明，FGLP实现了8米的预测精度，这与GPS误差相当，同时将数据发送开销降低了两个数量级，相对于集中式系统。

    Fine-grained location prediction on smart phones can be used to improve app/system performance. Application scenarios include video quality adaptation as a function of the 5G network quality at predicted user locations, and augmented reality apps that speed up content rendering based on predicted user locations. Such use cases require prediction error in the same range as the GPS error, and no existing works on location prediction can achieve this level of accuracy. We present a system for fine-grained location prediction (FGLP) of mobile users, based on GPS traces collected on the phones. FGLP has two components: a federated learning framework and a prediction model. The framework runs on the phones of the users and also on a server that coordinates learning from all users in the system. FGLP represents the user location data as relative points in an abstract 2D space, which enables learning across different physical spaces. The model merges Bidirectional Long Short-Term Memory (BiLST
    
[^108]: 图像配准中的注意力机制（AiR）：一种无监督的Transformer方法

    Attention for Image Registration (AiR): an unsupervised Transformer approach. (arXiv:2105.02282v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2105.02282](http://arxiv.org/abs/2105.02282)

    这篇论文提出了一种新颖的图像配准方法，名为AiR，它利用Transformer框架和注意力机制来学习变形场，无需标记数据或地面真实形变场。实验结果表明，该方法在精度和效率方面优于现有的最先进方法。

    

    图像配准是信号处理中的一项关键任务，但它经常遇到稳定性和效率问题。非学习配准方法依赖于优化固定图像和移动图像之间的相似度指标，这可能在时间和空间复杂度方面变得昂贵。当图像较大或它们之间存在明显的形变时，这个问题可能会加剧。最近，深度学习，特别是基于卷积神经网络（CNN）的方法，被探索作为非学习方法弱点的有效解决方案。为了进一步推进图像配准中的学习方法，我们在可变形图像配准问题中引入了注意力机制。我们提出的方法基于一种Transformer框架称为AiR，可以在GPGPU设备上高效训练。我们将图像配准问题视为语言翻译任务，并使用Transformer学习变形场。该方法学习了一种无监督的配准方法，无需标记数据或地面真实形变场。我们在各种数据集上进行实验，并展示了我们的方法在精度和效率方面优于现有的最先进方法。

    Image registration is a crucial task in signal processing, but it often encounters issues with stability and efficiency. Non-learning registration approaches rely on optimizing similarity metrics between fixed and moving images, which can be expensive in terms of time and space complexity. This problem can be exacerbated when the images are large or there are significant deformations between them. Recently, deep learning, specifically convolutional neural network (CNN)-based methods, have been explored as an effective solution to the weaknesses of non-learning approaches. To further advance learning approaches in image registration, we introduce an attention mechanism in the deformable image registration problem. Our proposed approach is based on a Transformer framework called AiR, which can be efficiently trained on GPGPU devices. We treat the image registration problem as a language translation task and use the Transformer to learn the deformation field. The method learns an unsuperv
    
[^109]: 多目标进化算法在多峰目标上的理论分析

    Theoretical Analyses of Multiobjective Evolutionary Algorithms on Multimodal Objectives. (arXiv:2012.07231v4 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2012.07231](http://arxiv.org/abs/2012.07231)

    本文证明了当运行时间为无穷大时，SEMO无法找到所有Pareto前沿。但全局SEMO证明了在期望迭代次数上限内找到了所有Pareto前沿，这对于理解多目标进化算法在多峰问题中的应用具有参考价值。

    

    多目标进化算法（MOEA）在实践中的成功远远超过了理论研究的进展。特别是，以前的理论工作主要考虑由单峰目标组成的简单问题。为了更深入地了解进化算法如何解决多峰多目标问题，本文提出了OJZJ问题，这是一个由两个与经典跳跃函数基准同构的目标组成的双目标问题。我们证明了对于SEMO，无论运行时间如何，概率都不可能计算出完整的 Pareto 前沿。相反，对于所有问题大小n和所有跳跃大小k∈[ 4 . . n 2 −1 ]，全局SEMO（GSEMO）在 Θ ((n−2k)n^k）次迭代中覆盖 Pareto 前沿预期。

    The theoretical understanding of MOEAs is lagging far behind their success in practice. In particular, previous theory work considers mostly easy problems that are composed of unimodal objectives.  As a first step towards a deeper understanding of how evolutionary algorithms solve multimodal multiobjective problems, we propose the OJZJ problem, a bi-objective problem composed of two objectives isomorphic to the classic jump function benchmark. We prove that SEMO with probability one does not compute the full Pareto front, regardless of the runtime. In contrast, for all problem sizes $n$ and all jump sizes ${k \in [4..\frac n2 - 1]}$, the global SEMO (GSEMO) covers the Pareto front in an expected number of $\Theta((n-2k)n^{k})$ iterations. For $k = o(n)$, we also show the tighter bound $\frac 32 e n^{k+1} \pm o(n^{k+1})$, which might be the first runtime bound for an MOEA that is tight apart from lower-order terms. We also combine the GSEMO with two approaches that showed advantages in 
    
[^110]: Fictitious Play优于Counterfactual Regret Minimization

    Fictitious Play Outperforms Counterfactual Regret Minimization. (arXiv:2001.11165v7 [cs.GT] UPDATED)

    [http://arxiv.org/abs/2001.11165](http://arxiv.org/abs/2001.11165)

    本研究比较了两种算法在近似多人博弈Nash均衡方面的表现，结果发现Fictitious Play比Counterfactual Regret Minimization更优秀。

    

    本文比较了两种广受欢迎的算法——Fictitious Play和Counterfactual Regret Minimization在近似多人博弈Nash均衡方面的表现。虽然Counterfactual Regret Minimization在多人扑克中取得了较大成功并被认为是更优秀的算法，但我们展示了Fictitious Play在各种类别和规模的游戏中都可以带来更好的Nash均衡近似效果。

    We compare the performance of two popular algorithms, fictitious play and counterfactual regret minimization, in approximating Nash equilibrium in multiplayer games. Despite recent success of counterfactual regret minimization in multiplayer poker and conjectures of its superiority, we show that fictitious play leads to improved Nash equilibrium approximation over a variety of game classes and sizes.
    

