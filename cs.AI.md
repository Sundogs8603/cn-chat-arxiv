# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Corrective Machine Unlearning](https://arxiv.org/abs/2402.14015) | 该论文通过形式化“修正机器消除”来解决受未知操纵影响的数据对训练模型的影响问题，可能仅知道一部分受影响样本。发现纠正消除问题与传统以隐私为导向的消除方法有显著不同的要求。 |
| [^2] | [Can Watermarks Survive Translation? On the Cross-lingual Consistency of Text Watermark for Large Language Models](https://arxiv.org/abs/2402.14007) | 该研究引入了文本水印中的“跨语言一致性”概念，发现当前文本水印技术在文本被翻译成其他语言后失去了一致性，并提出了一种跨语言水印去除攻击方法，有效绕过水印，降低AUC值，同时指出了导致这种差异的关键因素。 |
| [^3] | [The Importance of Architecture Choice in Deep Learning for Climate Applications](https://arxiv.org/abs/2402.13979) | 本文研究了深度学习在气候科学应用中架构选择的重要性，并展示了神经网络可以在多样化的气候情景下可预测大西洋经向翻转环流（AMOC），进一步揭示MLP和深度集成可以学习AMOC的物理过程而非模拟其进展。 |
| [^4] | [Probabilistic Neural Networks (PNNs) for Modeling Aleatoric Uncertainty in Scientific Machine Learning](https://arxiv.org/abs/2402.13945) | 本文探讨了使用概率神经网络（PNNs）来建模Aleatoric不确定性，通过开发概率距离度量来优化PNN架构，证实了PNNs在模拟Aleatoric不确定性中的有效性。 |
| [^5] | [Do Efficient Transformers Really Save Computation?](https://arxiv.org/abs/2402.13934) | 本研究旨在理解高效Transformer（例如稀疏Transformer和线性Transformer）的能力和限制，发现它们适合解决一般DP任务，但不同于标准Transformer。 |
| [^6] | [SDXL-Lightning: Progressive Adversarial Diffusion Distillation](https://arxiv.org/abs/2402.13929) | 提出了一种结合渐进和对抗性蒸馏的扩散蒸馏方法，在文本到图像生成任务中取得了新的最先进结果，并开源了相应模型。 |
| [^7] | [The Delusional Hedge Algorithm as a Model of Human Learning from Diverse Opinions](https://arxiv.org/abs/2402.13927) | 通过扩展妄想对冲算法，本研究提出了一种模型，能够帮助人们从多元信息源中学习并判断哪些观点值得信任。 |
| [^8] | [Large Language Models are Vulnerable to Bait-and-Switch Attacks for Generating Harmful Content](https://arxiv.org/abs/2402.13926) | 大型语言模型可能受到诱饵-转换攻击的威胁，甚至安全生成的文本也能轻易转变为有害内容，强调在LLMs的安全防护中需要考虑后处理转换。 |
| [^9] | [SYNFAC-EDIT: Synthetic Imitation Edit Feedback for Factual Alignment in Clinical Summarization](https://arxiv.org/abs/2402.13919) | 该研究提出了一种创新流程，利用GPT-3.5和GPT-4生成高质量反馈，以增强临床笔记摘要中的事实一致性，弥补了专家注释数据的高成本和有限可用性问题。 |
| [^10] | [What Linguistic Features and Languages are Important in LLM Translation?](https://arxiv.org/abs/2402.13917) | Llama2模型在翻译中表现出准确度高，部分未见语言需要更大规模的模型来提升翻译质量，另外语言的句法相似性并非翻译质量的主要因素，某些语言即使数据少依然表现出强相关性。 |
| [^11] | [Explain to Question not to Justify](https://arxiv.org/abs/2402.13914) | XAI领域被划分为蓝色XAI和红色XAI两种解释文化，指出了红色XAI领域的重要性和研究潜力，并提出了未来的研究挑战。 |
| [^12] | [Science Checker Reloaded: A Bidirectional Paradigm for Transparency and Logical Reasoning](https://arxiv.org/abs/2402.13897) | 提出了一个两块式的方法来解决长文档中信息检索领域的挑战，并实现了双向交互 |
| [^13] | [An Explainable Transformer-based Model for Phishing Email Detection: A Large Language Model Approach](https://arxiv.org/abs/2402.13871) | 优化的Transformer模型DistilBERT用于检测钓鱼邮件，通过预处理技术解决了类别不平衡问题 |
| [^14] | [Kuaiji: the First Chinese Accounting Large Language Model](https://arxiv.org/abs/2402.13866) | Kuaiji是第一个中国会计大型语言模型，通过Baichuan框架精心调整，支持的CAtAcctQA数据集，展现出卓越的准确性和响应速度，具有开创性地创建了中国会计数据集，并证实了在真实会计场景中的高效性。 |
| [^15] | [RealDex: Towards Human-like Grasping for Robotic Dexterous Hand](https://arxiv.org/abs/2402.13853) | RealDex数据集捕捉了真实的灵巧手抓取动作，利用多模态数据使得训练灵巧手更加自然和精确，同时提出了一种先进的灵巧抓取动作生成框架，有效利用多模态大型语言模型，在类人机器人的自动感知、认知和操纵方面具有巨大潜力。 |
| [^16] | [Neural Control System for Continuous Glucose Monitoring and Maintenance](https://arxiv.org/abs/2402.13852) | 引入了一种新颖的神经控制系统，用于连续葡萄糖监测和维护，实时动态调整胰岛素输送，增强葡萄糖优化，最大化效率并确保个性化护理。 |
| [^17] | [Large Language Models are Advanced Anonymizers](https://arxiv.org/abs/2402.13846) | 大型语言模型在保护个人数据方面取得了重要进展，提出了一种基于对抗性LLM推断的匿名化框架。 |
| [^18] | [LLM4SBR: A Lightweight and Effective Framework for Integrating Large Language Models in Session-based Recommendation](https://arxiv.org/abs/2402.13840) | 该研究提出了LLM4SBR框架，是第一个适合在基于会话的推荐中集成大型语言模型的轻量且有效框架。 |
| [^19] | [FLD: Fourier Latent Dynamics for Structured Motion Representation and Learning](https://arxiv.org/abs/2402.13820) | 介绍了一种自监督的、结构化的表示和生成方法，通过傅立叶潜动力学提高了运动学习算法的插值和泛化能力。 |
| [^20] | [NeuralDiffuser: Controllable fMRI Reconstruction with Primary Visual Feature Guided Diffusion](https://arxiv.org/abs/2402.13809) | NeuralDiffuser引入主视觉特征引导，扩展了LDM方法的自下而上过程，以实现忠实的语义和细节。 |
| [^21] | [Synthesis of Hierarchical Controllers Based on Deep Reinforcement Learning Policies](https://arxiv.org/abs/2402.13785) | 提出了基于深度强化学习策略的分层控制器设计方法，通过训练简洁的“潜在”策略来解决房间建模问题，无需模型提炼步骤，克服了DRL中的稀疏奖励，实现了低级策略的可重用性 |
| [^22] | [Semirings for Probabilistic and Neuro-Symbolic Logic Programming](https://arxiv.org/abs/2402.13782) | 提出了一种用于概率和神经符号逻辑编程的统一代数视角，将许多PLP的扩展都纳入一个共同的代数逻辑编程框架中。 |
| [^23] | [Contextual Molecule Representation Learning from Chemical Reaction Knowledge](https://arxiv.org/abs/2402.13779) | REMO是一个自监督学习框架，通过利用常见化学中明确定义的原子组合规则，在1.7百万个已知化学反应上预训练图形/Transformer编码器，并提出了Masked Reaction Centre Reconstruction (MRCR)和Reaction Centre Identification (RCI)两个预训练目标，为分子表示学习提供了新颖解决方案。 |
| [^24] | [Deep Generative Models for Offline Policy Learning: Tutorial, Survey, and Perspectives on Future Directions](https://arxiv.org/abs/2402.13777) | 深度生成模型在离线策略学习中展现了巨大潜力，本文提供了首个系统性综述，涵盖了五种主流深度生成模型及其应用。 |
| [^25] | [Mask-up: Investigating Biases in Face Re-identification for Masked Faces](https://arxiv.org/abs/2402.13771) | 研究审计了商业和开源人脸识别系统在戴口罩人脸再识别中的偏见，揭示了这些系统在应对戴口罩带来的挑战方面的不足。 |
| [^26] | [CriticBench: Evaluating Large Language Models as Critic](https://arxiv.org/abs/2402.13764) | CriticBench是一个旨在全面和可靠地评估大型语言模型的评论能力的新型基准，展示了评论能力与任务、响应质量和模型规模之间的关系。 |
| [^27] | [Reinforcement learning-assisted quantum architecture search for variational quantum algorithms](https://arxiv.org/abs/2402.13754) | 通过强化学习自动搜索变分电路的最佳结构，改善了VQAs的性能。 |
| [^28] | [AI-Powered Predictions for Electricity Load in Prosumer Communities](https://arxiv.org/abs/2402.13752) | 本文审查了如何利用人工智能技术对生产者兼消费者社区的电力负载进行预测的方法和可行性 |
| [^29] | [Breaking the Barrier: Utilizing Large Language Models for Industrial Recommendation Systems through an Inferential Knowledge Graph](https://arxiv.org/abs/2402.13750) | 提出了一种基于大型语言模型的互补知识增强推荐系统（LLM-KERec），通过引入实体提取器和构建互补知识图，解决了推荐系统难以捕捉用户意图转变和适应新商品的挑战。 |
| [^30] | [Unlocking Instructive In-Context Learning with Tabular Prompting for Relational Triple Extraction](https://arxiv.org/abs/2402.13741) | 设计了表格提示以解决关系三元组抽取中的提示设计和样本选择挑战。 |
| [^31] | [The Da Vinci Code of Large Pre-trained Language Models: Deciphering Degenerate Knowledge Neurons](https://arxiv.org/abs/2402.13731) | 本研究提供了对预训练语言模型中退化知识神经元（DKNs）的全面定义，引入了神经拓扑聚类方法和神经退化分析框架，从而实现更准确的DKN获取。 |
| [^32] | [An Evaluation of Large Language Models in Bioinformatics Research](https://arxiv.org/abs/2402.13714) | 大型语言模型在生物信息学研究中展现出了潜力，可成功处理多项关键任务，但在复杂任务中仍存在局限性。 |
| [^33] | [DSLR: Diversity Enhancement and Structure Learning for Rehearsal-based Graph Continual Learning](https://arxiv.org/abs/2402.13711) | DSLR提出了一种基于覆盖范围的多样性方法，以解决基于重播的图持续学习中回放节点过于集中导致过拟合和灾难性遗忘的问题。 |
| [^34] | [SaGE: Evaluating Moral Consistency in Large Language Models](https://arxiv.org/abs/2402.13709) | 提出SaGE方法，通过语义图熵来衡量大型语言模型道德一致性，构建了MCC语料库。 |
| [^35] | [KInIT at SemEval-2024 Task 8: Fine-tuned LLMs for Multilingual Machine-Generated Text Detection](https://arxiv.org/abs/2402.13671) | 本论文针对SemEval-2024任务8提出了一种使用微调LLMs进行多语言机器生成文本检测的方法，通过多种方式处理该任务并将统计检测指标与模型预测相结合，取得了竞争性结果。 |
| [^36] | [Unsupervised Text Style Transfer via LLMs and Attention Masking with Multi-way Interactions](https://arxiv.org/abs/2402.13647) | 通过组合注意力遮罩方法和大型语言模型，提出多种交互方式，可以改进无监督文本风格转移任务。 |
| [^37] | [The METRIC-framework for assessing data quality for trustworthy AI in medicine: a systematic review](https://arxiv.org/abs/2402.13635) | 本文提出了用于评估医疗人工智能数据质量的METRIC框架，着重探讨数据质量在深度学习应用中的重要性，强调数据质量对于医学人工智能产品监管批准的关键作用。 |
| [^38] | [Analyizing the Conjunction Fallacy as a Fact](https://arxiv.org/abs/2402.13615) | 分析连词谬误的事实可能性范围，揭示大多数研究存在对可能性狭隘的偏见。 |
| [^39] | [Data-driven Discovery with Large Generative Models](https://arxiv.org/abs/2402.13610) | 大型生成模型在数据驱动发现中的应用开创了端到端发现系统的新模式，利用提供的数据集搜寻和验证假设，突显了自动化系统的重要性和局限性。 |
| [^40] | [Hybrid Reasoning Based on Large Language Models for Autonomous Car Driving](https://arxiv.org/abs/2402.13602) | 大型语言模型在自动驾驶中的混合推理能力可以通过分析数据、理解规则和法则、提供语境等方式提高自动驶驶的决策能力。 |
| [^41] | [User-LLM: Efficient LLM Contextualization with User Embeddings](https://arxiv.org/abs/2402.13598) | User-LLM框架利用用户嵌入对LLMs进行语境化，使其能够动态适应用户上下文，在各种任务中实现显著性能提升。 |
| [^42] | [Mastering the Game of Guandan with Deep Reinforcement Learning and Behavior Regulating](https://arxiv.org/abs/2402.13582) | 该论文主要贡献是通过深度神经网络和行为调控方案，提出了一个框架GuanoZero，使AI代理能够掌握《关旦》游戏。 |
| [^43] | [Flexible Physical Camouflage Generation Based on a Differential Approach](https://arxiv.org/abs/2402.13575) | 该研究引入了一种新颖的神经渲染方法，名为FPA，通过学习对抗模式并结合特殊设计的对抗损失和隐蔽约束损失，可以生成物理世界中具有对抗性和隐蔽性质的伪装。 |
| [^44] | [ToDo: Token Downsampling for Efficient Generation of High-Resolution Images](https://arxiv.org/abs/2402.13573) | 提出了一种新的训练-free 方法 ToDo，通过令牌下采样加速 Stable Diffusion 推理，以实现高分辨率图像的高效生成。 |
| [^45] | [On the Expressive Power of a Variant of the Looped Transformer](https://arxiv.org/abs/2402.13572) | 设计了一种新型Transformer块AlgoFormer，相比标准Transformer和Looped Transformer，AlgoFormer在相同参数数量下能够实现更高的算法表达能力 |
| [^46] | [Multilingual Coreference Resolution in Low-resource South Asian Languages](https://arxiv.org/abs/2402.13571) | 引入了一个用于31种南亚语言的多语言共指解析翻译数据集，通过利用现成工具进行训练和对齐，在低资源条件下实现了较好的共指解析模型性能提升。 |
| [^47] | [Spot Check Equivalence: an Interpretable Metric for Information Elicitation Mechanisms](https://arxiv.org/abs/2402.13567) | 提出了"点检查等价性"，为同行预测机制的效力提供了一个可解释的度量 |
| [^48] | [Inductive Graph Alignment Prompt: Bridging the Gap between Graph Pre-training and Inductive Fine-tuning From Spectral Perspective](https://arxiv.org/abs/2402.13556) | IGAP提出了一种新型的基于图提示的方法，用于将图预训练泛化到归纳场景，弥合了预训练图和微调图之间的差距。 |
| [^49] | [Are LLMs Effective Negotiators? Systematic Evaluation of the Multifaceted Capabilities of LLMs in Negotiation Dialogues](https://arxiv.org/abs/2402.13550) | 本研究系统评估了LLMs在谈判对话中的多方面能力，揭示了它们在谈判研究中的潜力和局限。 |
| [^50] | [ARL2: Aligning Retrievers for Black-box Large Language Models via Self-guided Adaptive Relevance Labeling](https://arxiv.org/abs/2402.13542) | ARL2提出了一种检索器学习技术，利用LLMs作为标注者，并采用自适应自训练策略，能够有效减少注释成本，并在NQ和MMLU上取得了5.4%和4.6%的准确度提升。 |
| [^51] | [Exploring the Limits of Semantic Image Compression at Micro-bits per Pixel](https://arxiv.org/abs/2402.13536) | 本文使用GPT-4V和DALL-E3来探索图像压缩的质量和压缩界限，推动语义压缩降至每像素100微比特，并通过迭代反射过程改善解码图像。 |
| [^52] | [An Effective Incorporating Heterogeneous Knowledge Curriculum Learning for Sequence Labeling](https://arxiv.org/abs/2402.13534) | 提出了一个专为序列标注任务设计的两阶段课程学习（TCL）框架，逐渐引入数据实例从简单到困难，旨在提高性能和训练速度，并且对六个中文分词和词性标注数据集进行了广泛实验，证明了模型的有效性。 |
| [^53] | [FinGPT-HPC: Efficient Pretraining and Finetuning Large Language Models for Financial Applications with High-Performance Computing](https://arxiv.org/abs/2402.13533) | 该论文提出了一种基于高性能GPU的方法，利用低秩结构来高效地预训练和微调大型语言模型，解决了线性层冗余性、GPU内存占用和分布式训练中GPU利用率不足的挑战 |
| [^54] | [Test-Driven Development for Code Generation](https://arxiv.org/abs/2402.13521) | 本文旨在研究通过测试驱动开发（TDD）方法，将问题描述和测试作为输入是否优于仅将问题描述作为输入，以提高基于大型语言模型（LLM）的代码生成效果。 |
| [^55] | [Round Trip Translation Defence against Large Language Model Jailbreaking Attacks](https://arxiv.org/abs/2402.13517) | 往返翻译（RTT）方法是第一个专门设计用于抵御大型语言模型（LLMs）社交工程攻击的算法，成功地减少了多种攻击形式的成功率。 |
| [^56] | [ProSparse: Introducing and Enhancing Intrinsic Activation Sparsity within Large Language Models](https://arxiv.org/abs/2402.13516) | 本文介绍了一种名为"ProSparse"的有效稀疏化方法，以推动大型语言模型实现更高的激活稀疏性而不降低模型性能 |
| [^57] | [Self-DC: When to retrieve and When to generate? Self Divide-and-Conquer for Compositional Unknown Questions](https://arxiv.org/abs/2402.13514) | 提出了面向组合未知问题的自我分而治之算法，引入了第一个组合未知问题问答数据集（CuQA），通过自适应调用不同方法实现更好的性能和效率。 |
| [^58] | [From Self-Attention to Markov Models: Unveiling the Dynamics of Generative Transformers](https://arxiv.org/abs/2402.13512) | 本文研究了从自注意力模型到马尔可夫模型的转变，揭示了生成Transformer动态的机理和相关条件，为一致估计提供了保证，并在IID样本下建立了样本复杂性保证。 |
| [^59] | [Retrieval-Augmented Data Augmentation for Low-Resource Domain Tasks](https://arxiv.org/abs/2402.13482) | 提出了一种用于低资源领域任务的新方法，通过结合来自其他数据集的相关示例来增强训练数据，以解决在低资源环境中生成样本不够理想和缺乏多样性的挑战 |
| [^60] | [Learning to Model Diverse Driving Behaviors in Highly Interactive Autonomous Driving Scenarios with Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2402.13481) | 引入了Personality Modeling Network (PeMN)来模拟高度互动场景中各种驾驶交互，通过训练背景交通流改善自车性能和泛化能力 |
| [^61] | [Multi-scale Spatio-temporal Transformer-based Imbalanced Longitudinal Learning for Glaucoma Forecasting from Irregular Time Series Images](https://arxiv.org/abs/2402.13475) | 介绍了一种基于Multi-scale Spatio-temporal Transformer网络的失衡纵向学习方法，针对青光眼预测中的不规则时间序列图像，能有效学习代表性语义信息. |
| [^62] | [RefuteBench: Evaluating Refuting Instruction-Following for Large Language Models](https://arxiv.org/abs/2402.13463) | 本文提出了一个名为RefuteBench的基准测试，旨在评估大型语言模型对反驳指令的遵循能力，发现LLMs倾向于固执于其内部知识而无法遵从用户反馈。 |
| [^63] | [Potential and Challenges of Model Editing for Social Debiasing](https://arxiv.org/abs/2402.13462) | 模型编辑方法在社交去偏见中具有潜力，但也面临挑战，尤其是在支持不同偏见类型和理解编辑方法应用于去偏见过程中的利弊方面。 |
| [^64] | [LLM Jailbreak Attack versus Defense Techniques -- A Comprehensive Study](https://arxiv.org/abs/2402.13457) | 本研究对LLM模型的越狱攻击和防御技术进行了全面研究，揭示了现有攻击和防御技术的有效性。 |
| [^65] | [ED-Copilot: Reduce Emergency Department Wait Time with Language Model Diagnostic Assistance](https://arxiv.org/abs/2402.13448) | 本研究提出了一种在急诊科中减少等待时间的诊断辅助方法，利用人工智能系统帮助医生进行快速准确的诊断，并开发了ED-Copilot系统来推荐实验室检测并进行诊断预测。 |
| [^66] | [A Neuro-Symbolic Approach to Multi-Agent RL for Interpretability and Probabilistic Decision Making](https://arxiv.org/abs/2402.13440) | 提出了一种神经符号化方法，通过神经符号逻辑神经网络（LNN）框架和概率逻辑神经网络（PLNN）框架，在多智能体强化学习中实现可解释的决策制定和处理不确定性。 |
| [^67] | [DrBenchmark: A Large Language Understanding Evaluation Benchmark for French Biomedical Domain](https://arxiv.org/abs/2402.13432) | DrBenchmark提出了一个针对法语生物医学领域的大型语言理解评估基准，旨在弥补对最新法语生物医学模型评估的不足，并考虑到法语的独特敏感性。 |
| [^68] | [LinkSAGE: Optimizing Job Matching Using Graph Neural Networks](https://arxiv.org/abs/2402.13430) | LinkSAGE是一个采用图神经网络的优化工作匹配框架，通过独特的训练和服务方法，实现了在庞大而复杂的领英专业网络中进行个性化工作匹配。 |
| [^69] | [Quantitative causality, causality-guided scientific discovery, and causal machine learning](https://arxiv.org/abs/2402.13427) | 因果分析在人工智能领域中的应用挑战已得到基本解决，建立了严格的因果分析形式主义，推动了因果深度学习框架的建立，促进了从大气海洋科学到量子力学、神经科学、金融经济等领域的科学发现。 |
| [^70] | [Investigating the Histogram Loss in Regression](https://arxiv.org/abs/2402.13425) | 学习整个分布在回归中的性能提升主要来自于优化的改进，而不是学习更好的表示。 |
| [^71] | [Reward Bound for Behavioral Guarantee of Model-based Planning Agents](https://arxiv.org/abs/2402.13419) | 本研究探讨了如何确保模型规划代理在特定时间步内达到目标状态的行为保证问题，并提出了目标状态奖励的下界，对于低于该奖励的情况无法获得保证。 |
| [^72] | [Scaling physics-informed hard constraints with mixture-of-experts](https://arxiv.org/abs/2402.13412) | 新方法能够有效扩展物理信息的硬约束，提高了对复杂动力系统的建模效率。 |
| [^73] | [Learning and Sustaining Shared Normative Systems via Bayesian Rule Induction in Markov Games](https://arxiv.org/abs/2402.13399) | 通过贝叶斯规则归纳，新引入的智能体可以推断现有人群的规范，使智能体收敛到共享的规范，从而实现规范体系的稳定性 |
| [^74] | [Xling: A Learned Filter Framework for Accelerating High-Dimensional Approximate Similarity Join](https://arxiv.org/abs/2402.13397) | Xling是一个通用框架，利用学习模型构建度量空间过滤器，用于加速高维近似相似性连接，提供优化策略以提高预测质量 |
| [^75] | [Toward TransfORmers: Revolutionizing the Solution of Mixed Integer Programs with Transformers](https://arxiv.org/abs/2402.13380) | 这项研究利用变压器模型解决混合整数规划问题，首次采用变压器预测二进制变量，提出的算法在解决时间上超越了传统CPLEX和LSTM。 |
| [^76] | [The Uncanny Valley: A Comprehensive Analysis of Diffusion Models](https://arxiv.org/abs/2402.13369) | 通过对扩散模型的综合分析，揭示了决定模型性能的隐藏关键因素，为DMs的推进提供了见解。 |
| [^77] | [KetGPT -- Dataset Augmentation of Quantum Circuits using Transformers](https://arxiv.org/abs/2402.13352) | 该研究利用Transformer机器学习架构生成“看起来真实”的量子电路，以增强现有的量子电路数据集。 |
| [^78] | [Aria Everyday Activities Dataset](https://arxiv.org/abs/2402.13349) | AEA数据集是使用Project Aria眼镜记录的第一人称多模态开放数据集，其中包含了多个佩戴者在室内不同位置记录的日常活动序列，为研究提供了3D轨迹、场景点云、眼球注视向量和语音转录等机器感知数据，支持神经场景重建和提示分割。 |
| [^79] | [Deep Hedging with Market Impact](https://arxiv.org/abs/2402.13326) | 本文提出了一种基于深度强化学习的市场影响动态套期保值模型，考虑了凸市场影响和随时间持续的影响，通过与常用程序比较，展示了其在期权套期保值方面的优越性。 |
| [^80] | [Harmful algal bloom forecasting. A comparison between stream and batch learning](https://arxiv.org/abs/2402.13304) | 流式学习是有望解决时间序列问题中概念漂移的最有希望方法之一，本研究对其在预测有害藻华细胞损害方面的效力进行了测试并与批处理学习进行了比较。 |
| [^81] | [Structure-informed Positional Encoding for Music Generation](https://arxiv.org/abs/2402.13301) | 提出了一种针对音乐生成的结构感知位置编码框架，通过绝对、相对和非平稳位置信息，显著改善了生成作品的旋律和结构一致性。 |
| [^82] | [Integrating Deep Learning and Synthetic Biology: A Co-Design Approach for Enhancing Gene Expression via N-terminal Coding Sequences](https://arxiv.org/abs/2402.13297) | 本文提出了一种深度学习/合成生物学协同设计的少样本训练工作流程，用于N端编码序列（NCS）优化，通过利用k最近编码和word2vec对NCS进行编码，并利用注意机制进行特征提取，构建时间序列网络预测基因表达强度，最终通过直接搜索算法确定具有有限训练数据的最佳NCS。 |
| [^83] | [A Conflict-Aware Optimal Goal Assignment Algorithm for Multi-Robot Systems](https://arxiv.org/abs/2402.13292) | 提出了针对多机器人系统的冲突感知最优目标分配算法，并引入了冲突引导方法和其他优化方法。 |
| [^84] | [Grounding from an AI and Cognitive Science Lens](https://arxiv.org/abs/2402.13290) | 从认知科学和机器学习的视角探讨基础建立的微妙之处，探讨神经符号方法在如何更全面地解决基础建立问题，讨论基础建立领域的进一步发展方向。 |
| [^85] | [Training Table Question Answering via SQL Query Decomposition](https://arxiv.org/abs/2402.13288) | 通过学习模拟SQL样式代数操作的受限部分，提供了中间监督步骤，相较于传统方法增加了泛化性和结构推理能力。 |
| [^86] | [Manipulating hidden-Markov-model inferences by corrupting batch data](https://arxiv.org/abs/2402.13287) | 通过污染数据，本研究提供了一种新颖的概率视角，用于操纵隐马尔可夫模型的推断，并开发了多种解决方法进行应用和实证测试。 |
| [^87] | [Structure Guided Large Language Model for SQL Generation](https://arxiv.org/abs/2402.13284) | 通过引入结构信息，提出了一个结构引导的SQL生成模型，以改善大型语言模型生成SQL的准确性和可执行性。 |
| [^88] | [When LLMs Meets Acoustic Landmarks: An Efficient Approach to Integrate Speech into Large Language Models for Depression Detection](https://arxiv.org/abs/2402.13276) | 本文提出了一种创新方法，将声学语音信息集成到LLMs框架中，以用于多模式抑郁检测。 |
| [^89] | [Implementation of a Model of the Cortex Basal Ganglia Loop](https://arxiv.org/abs/2402.13275) | 本文提出了皮层基底神经节环路模型的实现，用于行动选择和执行，基于大脑皮层预测行动，基底神经节使用强化学习决定执行哪些行动。 |
| [^90] | [Operational Collective Intelligence of Humans and Machines](https://arxiv.org/abs/2402.13273) | 聚合众包预测作为集体智能的重要进展，促进了人类和AI的连接，使决策具有优势。 |
| [^91] | [Spontaneous Theory of Mind for Artificial Intelligence](https://arxiv.org/abs/2402.13272) | 论文提出了人工智能中自发心灵理论的概念，强调了自发ToM相对于启发式ToM的重要性，并主张发展AI ToM需要采取原则性方法，以实现更具弹性的人工社会智能。 |
| [^92] | [Global Tropical Cyclone Intensity Forecasting with Multi-modal Multi-scale Causal Autoregressive Model](https://arxiv.org/abs/2402.13270) | 提出了一种全球热带气旋强度预测模型MSCAR，首次将因果关系与大规模多模态数据相结合，有效优于现有最先进方法。 |
| [^93] | [KGroot: Enhancing Root Cause Analysis through Knowledge Graphs and Graph Convolutional Neural Networks](https://arxiv.org/abs/2402.13264) | 通过知识图谱和图卷积神经网络，KGroot提出了一种增强根本原因分析的方法，应用于在线微服务中的故障定位，旨在解决监控数据多样性、事件传播等挑战，提高准确性和效率。 |
| [^94] | [Controlling Large Electric Vehicle Charging Stations via User Behavior Modeling and Stochastic Programming](https://arxiv.org/abs/2402.13224) | 本文介绍了一个新的电动汽车充电站模型，通过用户行为建模和随机规划，解决了充电会话不确定性问题，并提出了两种方法来优化成本并提高用户满意度。 |
| [^95] | [CMDAG: A Chinese Metaphor Dataset with Annotated Grounds as CoT for Boosting Metaphor Generation](https://arxiv.org/abs/2402.13145) | 本文介绍了一个大规模高质量的带注释中文隐喻语料库，强调隐喻生成中的基础及其独特特征，而非传统的对象和载体组合。 |
| [^96] | [Turn Waste into Worth: Rectifying Top-$k$ Router of MoE](https://arxiv.org/abs/2402.12399) | 提出了Rectify-Router解决了MoE模型中常用的Top-k路由机制所带来的令牌丢失和填充问题，通过Intra-GPU矫正和Fill-in矫正来实现。 |
| [^97] | [Toward a Team of AI-made Scientists for Scientific Discovery from Gene Expression Data](https://arxiv.org/abs/2402.12391) | 引入了一个名为AI科学家团队（TAIS）的框架，旨在简化科学发现流程，由模拟角色协作，特别关注于识别具有疾病预测价值的基因 |
| [^98] | [Emulated Disalignment: Safety Alignment for Large Language Models May Backfire!](https://arxiv.org/abs/2402.12343) | 安全对齐的大型语言模型可能会通过模拟失调框架，在对抗性操纵下产生危险结果，对训练的语言模型具有双倍有害性，高于强基线，强调了即使在安全对齐后也需要重新评估开源语言模型的重要性。 |
| [^99] | [Causal Equal Protection as Algorithmic Fairness](https://arxiv.org/abs/2402.12062) | 本文提出了一种新的算法公平性原则——平等保护，其关键在于将错误分类的风险均等化，避免了许多对传统分类平等原则的反例。 |
| [^100] | [From Reals to Logic and Back: Inventing Symbolic Vocabularies, Actions and Models for Planning from Raw Data](https://arxiv.org/abs/2402.11871) | 本文提出了一种从未标记高维实值机器人轨迹开始自主学习通用的逻辑相关表示，这些表示构成了自动发明的PDDL-like域模型。 |
| [^101] | [Re-Dock: Towards Flexible and Realistic Molecular Docking with Diffusion Bridge](https://arxiv.org/abs/2402.11459) | 提出了一种新颖的扩散桥生成模型 Re-Dock，用于灵活和现实的分子对接，通过能量到几何映射来共同建模结合能和构象，填补了对接中的实用性和构象预测方面的差距 |
| [^102] | [SciAgent: Tool-augmented Language Models for Scientific Reasoning](https://arxiv.org/abs/2402.11451) | 引入了工具增强型科学推理的新任务设置，通过提供可扩展的工具集，帮助大型语言模型在科学问题解决中变得更加实用和可解决。 |
| [^103] | [Reasoning before Comparison: LLM-Enhanced Semantic Similarity Metrics for Domain Specialized Text Analysis](https://arxiv.org/abs/2402.11398) | 通过利用LLM增强语义分析，开发了用于文本的相似度度量框架，可显著改善文本的语义相似性评估，并可扩展到其他专业领域。 |
| [^104] | [Trust Regions for Explanations via Black-Box Probabilistic Certification](https://arxiv.org/abs/2402.11168) | 通过黑盒概率认证解释的信任区域能够有效地洞察模型行为、保证解释的稳定性，并实现解释的重用 |
| [^105] | [Accelerating Semi-Asynchronous Federated Learning](https://arxiv.org/abs/2402.10991) | 提出了一种考虑贡献的异步联邦学习方法，动态调整接收到的更新的处理方式，以解决现实情况下同步上传数据可能出现的缓慢和不可靠问题。 |
| [^106] | [CHEMREASONER: Heuristic Search over a Large Language Model's Knowledge Space using Quantum-Chemical Feedback](https://arxiv.org/abs/2402.10980) | 通过将大型语言模型推理与量子化学反馈相结合，我们引入了一个AI引导的计算筛选框架，将催化剂发现形式化为一个不确定环境，从而实现高效催化剂的积极搜索 |
| [^107] | [In Search of Needles in a 10M Haystack: Recurrent Memory Finds What LLMs Miss](https://arxiv.org/abs/2402.10790) | 通过使用循环记忆增强对 GPT-2 进行微调，使其能够处理长达 1000 万个元素的任务，这是迄今为止处理最长输入的开放神经网络模型，并展示了对长序列处理能力的显著改进。 |
| [^108] | [InSaAF: Incorporating Safety through Accuracy and Fairness | Are LLMs ready for the Indian Legal Domain?](https://arxiv.org/abs/2402.10567) | 本研究在印度法律领域探讨了大型语言模型（LLMs）在处理社会因素时的能力，提出了结合公平性和准确性的新指标$LSS_{\beta}$，并评估了模型在二元法律推理任务中的表现以及在印度社会各种不平等方面的公平性展示。 |
| [^109] | [Aligning Crowd Feedback via Distributional Preference Reward Modeling](https://arxiv.org/abs/2402.09764) | 本文提出了一种名为分布偏好奖励模型的框架，用于将大型语言模型与多样的人类偏好对齐。该框架使用贝塔分布刻画偏好，并设计了基于最优输运的损失函数来校准模型与偏好的对齐程度。最终利用期望奖励微调语言模型的策略。 |
| [^110] | [User Modeling and User Profiling: A Comprehensive Survey](https://arxiv.org/abs/2402.09660) | 这篇综述论文介绍了用户建模与用户画像研究的现状、发展和未来方向。该研究主要关注在人工智能应用中构建准确的用户表示，包括利用大量数据进行建模以及采用深度学习和图数据技术等先进方法。 |
| [^111] | [Progress in artificial intelligence applications based on the combination of self-driven sensors and deep learning](https://arxiv.org/abs/2402.09442) | 本文介绍了基于自驱动传感器和深度学习的人工智能应用的最新进展，重点讨论了使用TENG作为自驱动传感器的优势，包括简单结构和高瞬时性能。 |
| [^112] | [Persuasion, Delegation, and Private Information in Algorithm-Assisted Decisions](https://arxiv.org/abs/2402.09384) | 一篇论文研究了在算法辅助决策中，如何设计最优的预测算法和委托规则。关键发现包括：委托的最优性与委托人是否会做出与代理人相同的决策有关、最具信息量的算法不一定是最优的、常见的算法限制会降低决策质量。 |
| [^113] | [Is Epistemic Uncertainty Faithfully Represented by Evidential Deep Learning Methods?](https://arxiv.org/abs/2402.09056) | 本论文提出了关于证据深度学习的新理论洞见, 高亮了在优化二阶损失函数和解释得出的认识不确定性度量上的困难性 |
| [^114] | [SAGMAN: Stability Analysis of Graph Neural Networks on the Manifolds](https://arxiv.org/abs/2402.08653) | SAGMAN是一种用于检验图神经网络稳定性的谱框架，它通过评估非线性映射中的距离失真来衡量GNN的稳定性。为了进行有意义的稳定性分析，我们提出了一种距离保持的图降维方法。 |
| [^115] | [Differentially Private Zeroth-Order Methods for Scalable Large Language Model Finetuning](https://arxiv.org/abs/2402.07818) | 本文研究了差分隐私零阶方法在大型语言模型微调中的应用，该方法通过使用零阶梯度来避免传统优化方法的可扩展性瓶颈，实现了在隐私、效用和可扩展性之间的良好平衡。 |
| [^116] | [DeAL: Decoding-time Alignment for Large Language Models](https://arxiv.org/abs/2402.06147) | DeAL是一个允许用户自定义奖励函数并实现解码时对齐LLMs的框架。 |
| [^117] | [InkSight: Offline-to-Online Handwriting Conversion by Learning to Read and Write](https://arxiv.org/abs/2402.05804) | InkSight是一个可以将离线手写转换为在线手写的系统，通过结合阅读和书写先验知识，在多样化的照片中有效地Derendering手写文本。 |
| [^118] | [Rocks Coding, Not Development--A Human-Centric, Experimental Evaluation of LLM-Supported SE Tasks](https://arxiv.org/abs/2402.05650) | 这项研究提出了一种自监督学习框架，用于训练神经网络从未标记的多感官数据中学习丰富而有意义的3D场景表示。通过利用不同感觉模态之间的时间一致性和几何对齐，我们的框架能够学习到强大而准确的表示。我们将我们的方法应用于各种3D感知任务，并与监督基线进行了比较，展示了竞争性的性能。此外，我们还展示了我们学到的表示在不同的传感器设置下具有很好的泛化能力，进一步突显了我们的自监督学习方法的有效性和多功能性。 |
| [^119] | [Tactile-based Object Retrieval From Granular Media](https://arxiv.org/abs/2402.04536) | 这项研究介绍了一种基于触觉反馈的机器人操作方法，用于在颗粒介质中检索埋藏的物体。通过模拟传感器噪声进行端到端训练，实现了自然出现的学习推动行为，并成功将其迁移到实际硬件上。 |
| [^120] | [HEAM : Hashed Embedding Acceleration using Processing-In-Memory](https://arxiv.org/abs/2402.04032) | HEAM是一种采用异构内存架构的方法，将3D堆叠DRAM与DIMM集成，用于加速处理大规模个性化推荐系统中的嵌入操作。 |
| [^121] | [SEABO: A Simple Search-Based Method for Offline Imitation Learning](https://arxiv.org/abs/2402.03807) | SEABO是一种简单而有效的基于搜索的离线模仿学习方法，它以无监督学习的方式，根据专家数据和无标签数据得到奖励函数，实验结果表明其性能与离线强化学习相当。 |
| [^122] | [MolTC: Towards Molecular Relational Modeling In Language Models](https://arxiv.org/abs/2402.03781) | 本研究提出了一种基于语言模型的多模态框架MolTC，用于分子相互作用预测，该框架能够高效地整合分子对的丰富图形信息，并通过思维链理论实现统一的分子关系学习。 |
| [^123] | [Exploiting Class Probabilities for Black-box Sentence-level Attacks](https://arxiv.org/abs/2402.02695) | 该论文研究了在黑盒子句级攻击中利用类别概率的有效性，并开发了一种新的算法进行攻击。通过与基线方法进行对比，进行了广泛的评估。 |
| [^124] | [Graph Contrastive Learning with Cohesive Subgraph Awareness](https://arxiv.org/abs/2401.17580) | 本研究提出了一种名为CTAug的新框架，将内聚子图意识无缝整合到图对比学习中。通过改进图拓扑增强和图学习过程，提高了对各种图的表征学习性能。 |
| [^125] | [Enhancing Emotional Generation Capability of Large Language Models via Emotional Chain-of-Thought](https://arxiv.org/abs/2401.06836) | 该研究提出了一种名为情感思维链（ECoT）的提示方法，通过与人类情感智慧准则对齐，增强大型语言模型在情感生成任务上的性能。 |
| [^126] | [MLCA-AVSR: Multi-Layer Cross Attention Fusion based Audio-Visual Speech Recognition](https://arxiv.org/abs/2401.03424) | 提出了基于多层交叉注意力融合的音频-视觉语音识别（MLCA-AVSR）方法，通过在不同级别的音频/视觉编码器上融合模态特征，有效提高了系统的稳健性。 |
| [^127] | [Towards Message Brokers for Generative AI: Survey, Challenges, and Opportunities](https://arxiv.org/abs/2312.14647) | 该研究调查了传统和现代消息代理，比较分析了流行平台，为数据中心GenAI模型的需求增加提供了健壮的数据通信基础设施 |
| [^128] | [Towards Context-Aware Domain Generalization: Understanding the Benefits and Limits of Marginal Transfer Learning](https://arxiv.org/abs/2312.10107) | 分析了上下文感知领域泛化的条件，提出了理论分析和实证分析所需的标准，并展示了该方法可以检测非常数域的场景。 |
| [^129] | [Neural Machine Translation of Clinical Text: An Empirical Investigation into Multilingual Pre-Trained Language Models and Transfer-Learning](https://arxiv.org/abs/2312.07250) | 在临床文本的神经机器翻译研究中，通过使用多语言预训练语言模型和迁移学习方法，在ClinSpEn-2022英西临床领域数据上取得了顶级性能，并发现小型预训练语言模型在临床领域微调中胜过其他超大型语言模型。 |
| [^130] | [Playing Large Games with Oracles and AI Debate](https://arxiv.org/abs/2312.04792) | 本论文研究了在具有大量动作的重复游戏中实现遗憾最小化的问题，通过使用基于Oracle的算法，提出了一种高效的内部遗憾最小化算法，实现了在大型游戏中计算相关均衡的高效性。通过在AI安全辩论环境中的实验验证了算法的有效性。 |
| [^131] | [SynthScribe: Deep Multimodal Tools for Synthesizer Sound Retrieval and Exploration](https://arxiv.org/abs/2312.04690) | SynthScribe是一个利用多模态深度学习的全栈系统，让用户以更高级别表达意图，实现了搜索现有声音、创建全新声音、对给定声音进行有意义修改的功能 |
| [^132] | [Tree of Attacks: Jailbreaking Black-Box LLMs Automatically](https://arxiv.org/abs/2312.02119) | 提出了一种名为Tree of Attacks with Pruning (TAP)的自动化方法，用于生成只需要对目标大型语言模型进行黑盒访问的越狱方法，并通过思维树推理和修剪生成准确的越狱提示。 |
| [^133] | [CAMRA: Copilot for AMR Annotation](https://arxiv.org/abs/2311.10928) | CAMRA是一个创新的基于web的工具，用于从自然语言文本构建抽象意义表示（AMR），通过整合编程语言的编码方法和AMR解析器模型作为副驾驶，极大提高了AMR注释的效率和准确性。 |
| [^134] | [Adaptive Interventions with User-Defined Goals for Health Behavior Change](https://arxiv.org/abs/2311.09483) | 该论文介绍了一种修改过的Thompson抽样算法，强调通过优化个性化奖励函数实现个性化目标设定，为支持目标设定提供了一个平衡方法，并证明此修改仅对累积遗憾产生恒定的惩罚。 |
| [^135] | [To Tell The Truth: Language of Deception and Language Models](https://arxiv.org/abs/2311.07092) | 在高风险环境中，研究人员通过分析电视游戏节目数据发现，即使只使用语言线索，基于大型语言模型构建的模型可以与人类主体具有类似的真相检测性能。 |
| [^136] | [Kinematic-aware Prompting for Generalizable Articulated Object Manipulation with LLMs](https://arxiv.org/abs/2311.02847) | 基于物体的运动学结构，提出了一种运动学感知提示框架，用于生成LLMs的低级运动轨迹位点，以实现对可移动物体的泛化操作 |
| [^137] | [Building a Safer Maritime Environment Through Multi-Path Long-Term Vessel Trajectory Forecasting](https://arxiv.org/abs/2310.18948) | 通过利用AIS数据预测船舶轨迹，本研究旨在通过减少船舶与鲸鱼碰撞来建立更安全的海洋环境。 |
| [^138] | [RGI-Net: 3D Room Geometry Inference from Room Impulse Responses in the Absence of First-order Echoes](https://arxiv.org/abs/2309.01513) | RGI-Net通过深度神经网络学习和利用房间脉冲响应中高阶反射之间的关系，实现在没有传统假设的情况下推断房间几何信息。 |
| [^139] | [A Survey on Fairness in Large Language Models](https://arxiv.org/abs/2308.10149) | 本文审查了关于大型语言模型中公平性的研究，针对中等规模LLMs和大规模LLMs提出了评估指标和去偏见方法。 |
| [^140] | [Fixing confirmation bias in feature attribution methods via semantic match](https://arxiv.org/abs/2307.00897) | 提出了通过语义匹配修复特征归因方法中的确认偏见问题，引入了人类概念与（亚符号）解释之间的概念框架，并提出了一种结构化方法来评估语义匹配。 |
| [^141] | [Sin3DM: Learning a Diffusion Model from a Single 3D Textured Shape](https://arxiv.org/abs/2305.15399) | Sin3DM提出了一种扩散模型，能够从单个3D纹理形状中学习内部补丁分布，在低维潜在空间中训练并生成高质量的变体。 |
| [^142] | [InPars-Light: Cost-Effective Unsupervised Training of Efficient Rankers](https://arxiv.org/abs/2301.02998) | InPars-Light是一个简单而有效的修改，通过使用小得多的排名模型和免费语言模型BLOOM，在多个英文检索集合上显著改进了排名性能。 |
| [^143] | [Motor Imagery Decoding Using Ensemble Curriculum Learning and Collaborative Training](https://arxiv.org/abs/2211.11460) | 提出了一种使用集成课程学习和协作训练的两阶段模型集成架构，通过引入新的损失项应用课程学习并允许协作解读，解决了跨主体运动想象解码的挑战性问题。 |
| [^144] | [Assessing Uncertainty in Similarity Scoring: Performance & Fairness in Face Recognition](https://arxiv.org/abs/2211.07245) | 评估相似度评分函数性能和公平性质的关键工具是ROC曲线，文章提出了一种准确评估与ROC曲线相关不确定性水平的方法，特别适用于面部识别等具有社会影响的应用。 |
| [^145] | [Design of Fuzzy Logic Controller for Washing Machine](https://arxiv.org/abs/2210.00187) | 本文基于Mamdani方法，设计了一个基于多输入多输出的模糊逻辑控制器算法，并在Python中实现，结果显示在低计算成本下洗衣机表现更好 |
| [^146] | [RIS-ADMM: A RIS and ADMM-Based Passive and Sparse Sensing Method With Interference Removal](https://arxiv.org/abs/2206.06172) | 本文提出了一种基于RIS和ADMM的被动稀疏感知方法，通过新颖的迭代方法有效抑制干扰信号，显著提高到达方向（DOA）估计的准确性。 |
| [^147] | [Mildly Conservative Q-Learning for Offline Reinforcement Learning](https://arxiv.org/abs/2206.04745) | 本文提出了一种离线强化学习中的温和保守Q学习（MCQ）方法，通过为OOD动作分配适当的伪Q值来训练，从而在不损害泛化能力的情况下实现价值函数的保守性，避免过度高估超出分布的动作。 |
| [^148] | [Trustworthy Graph Neural Networks: Aspects, Methods and Trends](https://arxiv.org/abs/2205.07424) | 论文提出了构建可信赖图神经网络的综合路线图，关注解决性能导向的图神经网络可能存在的对抗性攻击、歧视问题和资源消耗过多等挑战。 |
| [^149] | [Learning Optimal Control with Stochastic Models of Hamiltonian Dynamics](https://arxiv.org/abs/2111.08108) | 本文提出了一种新颖的学习框架来解决最优控制问题，通过学习减少的哈密顿动力学和伴随变量，利用变分自动编码器逐渐学习后验分布，从而提高了路径探索过程的效率。 |
| [^150] | [Conflict-Averse Gradient Descent for Multi-task Learning](https://arxiv.org/abs/2110.14048) | 冲突回避梯度下降（CAGrad）是针对多任务学习中梯度冲突问题提出的方法，旨在解决不同任务梯度不一致导致的性能下降挑战。 |
| [^151] | [Ontological Smart Contracts in OASIS: Ontology for Agents, Systems, and Integration of Services (Extended Version)](https://arxiv.org/abs/2012.01410) | 本文扩展了一种用于代理建模的本体OASIS，引入了条件和本体智能合约（OSCs），将其应用于扩展区块链和智能合约，并提出了基于OASIS OSCs定义的框架架构。 |
| [^152] | [Multivariate Beta Mixture Model: Probabilistic Clustering With Flexible Cluster Shapes.](http://arxiv.org/abs/2401.16708) | 本文提出了一种名为多元贝塔混合模型（MBMM）的新的概率模型，用于软聚类。MBMM通过其灵活的多元贝塔分布的概率密度函数适应不同的聚类形状，并在合成和真实数据集上展示了其适应性。 |
| [^153] | [SH2: Self-Highlighted Hesitation Helps You Decode More Truthfully.](http://arxiv.org/abs/2401.05930) | 自我突出式犹豫（SH2）是一种推理时的方法，通过选择预测概率较低的标记，并强调它们的差异，从而帮助语言模型更准确地解码。 |
| [^154] | [ANGO: A Next-Level Evaluation Benchmark For Generation-Oriented Language Models In Chinese Domain.](http://arxiv.org/abs/2401.04898) | ANGO是一个中文领域生成型语言模型评估基准，引入了关键点分类标准，提供了更好的可解释性，同时建立了可量化的问题难度标准，对模型训练提供了更精确的指导。 |
| [^155] | [ICMC-ASR: The ICASSP 2024 In-Car Multi-Channel Automatic Speech Recognition Challenge.](http://arxiv.org/abs/2401.03473) | ICMC-ASR挑战赛是为了促进驾驶场景下的语音处理和识别研究而举办的，包括自动语音识别（ASR）和自动语音分离和识别（ASDR）两个赛道，取得了显著的改善。最终，USTCiflytek队在ASR赛道上获得了13.16%的CER，ASDR赛道上获得了21.48%的cpCER。 |
| [^156] | [Explore Spurious Correlations at the Concept Level in Language Models for Text Classification.](http://arxiv.org/abs/2311.08648) | 本文研究了语言模型在文本分类中概念级别的误相关性问题，并通过使用ChatGPT分配概念标签和引入数据再平衡技术来解决这一问题。 |
| [^157] | [Identifiability of total effects from abstractions of time series causal graphs.](http://arxiv.org/abs/2310.14691) | 本文研究了基于因果图抽象从观测时间序列中识别干预总效应的问题，并证明了在扩展摘要因果图中总效应总是可识别的。同时，我们提供了摘要因果图中总效应可识别的必要和充分的图形条件，并提供了调整集合以估计总效应。 |
| [^158] | [EEG motor imagery decoding: A framework for comparative analysis with channel attention mechanisms.](http://arxiv.org/abs/2310.11198) | 本研究探索了在运动意向解码领域应用不同通道关注机制的可行性，通过构建一个轻量级架构框架，并在同一环境中比较它们的影响，结果表明这些机制的易集成性和低计算复杂度使其成为BCI中运动意向解码的有效方法。 |
| [^159] | [QLLM: Accurate and Efficient Low-Bitwidth Quantization for Large Language Models.](http://arxiv.org/abs/2310.08041) | QLLM是一种为大规模语言模型设计的准确高效的低位宽后训练量化方法，通过引入自适应通道重组技术，将离群值的大小重新分配给其他通道，从而减轻它们对量化范围的影响。 |
| [^160] | [Interpretable Diffusion via Information Decomposition.](http://arxiv.org/abs/2310.07972) | 本研究通过观察扩散和信息分解之间的关系，揭示了扩散模型学习到的细粒度关系，进一步解决了高维空间中信息携带变量的问题。 |
| [^161] | [Denoising Task Routing for Diffusion Models.](http://arxiv.org/abs/2310.07138) | 本文提出了一种名为去噪任务路由的策略，通过为扩散模型的不同任务建立独立的信息路径，实现了对多任务学习的明确纳入。该方法将去噪任务的先验知识无缝集成到框架中，通过激活相似的通道和滑动窗口的方式，充分利用了相邻时间步任务间的亲和关系。 |
| [^162] | [Scaling Laws for Associative Memories.](http://arxiv.org/abs/2310.02984) | 本文研究了应用于联想记忆中的缩放定律，通过高维矩阵和嵌入的外积来模拟内层Transformer语言模型。作者推导出了与样本数量和参数大小相关的精确缩放定律，并验证了理论结果的有效性。同时，作者还通过大量实验展示了存储记忆关联的细粒度可视化。 |
| [^163] | [MIDDAG: Where Does Our News Go? Investigating Information Diffusion via Community-Level Information Pathways.](http://arxiv.org/abs/2310.02529) | MIDDAG是一个交互式系统，通过可视化社交媒体上由COVID-19相关新闻触发的信息传播路径，提供全面的洞察力，并能构建用户社区和预测信息传播，从而追踪和理解信息的传播方式。 |
| [^164] | [The Entity-Deduction Arena: A playground for probing the conversational reasoning and planning capabilities of LLMs.](http://arxiv.org/abs/2310.01468) | 本文提供了一个评估框架，通过向法官提出一系列查询来评估LLMs的对话推理和规划能力。我们发现不同的LLMs在这个任务上表现出显著差异。 |
| [^165] | [ToRA: A Tool-Integrated Reasoning Agent for Mathematical Problem Solving.](http://arxiv.org/abs/2309.17452) | ToRA是一种集成工具的数学问题求解推理代理，通过结合语言的分析能力和工具的计算效率，能够显著提高数学推理的性能，在多个数学推理数据集上取得了13%-19%的平均绝对改进率，并在竞赛级数据集MATH上达到了44.6%的性能。 |
| [^166] | [Enhancing Large Language Models in Coding Through Multi-Perspective Self-Consistency.](http://arxiv.org/abs/2309.17272) | 本文提出了一个名为多角度自一致性（MPSC）的框架，用于提升大规模语言模型在复杂的代码生成任务中的性能。该框架通过从多个角度采样多个输出并构建一个多部分图，利用交叉一致性和内一致性信息来选择最优输出。 |
| [^167] | [TranDRL: A Transformer-Driven Deep Reinforcement Learning Enabled Prescriptive Maintenance Framework.](http://arxiv.org/abs/2309.16935) | TranDRL是一种基于Transformer驱动的深度强化学习支持的预防性维护框架，结合了复杂时间模式捕捉和经济高效维护建议，显著提高了剩余寿命（RUL）预测准确性和维护行动优化。 |
| [^168] | [Are Human-generated Demonstrations Necessary for In-context Learning?.](http://arxiv.org/abs/2309.14681) | 本文研究了上下文学习中人工生成的演示是否有必要，并提出了一种新的自反思提示策略（SEC），通过这种策略，大型语言模型（LLMs）可以自行生成演示和最终输出，避免了手动生成过程的复杂性。 |
| [^169] | [What Matters to Enhance Traffic Rule Compliance of Imitation Learning for Automated Driving.](http://arxiv.org/abs/2309.07808) | 本文提出了一种基于惩罚的模仿学习方法P-CSG，结合语义生成传感器融合技术，以提高端到端自动驾驶的整体性能，并解决了交通规则遵守和传感器感知问题。 |
| [^170] | [Rank Collapse Causes Over-Smoothing and Over-Correlation in Graph Neural Networks.](http://arxiv.org/abs/2308.16800) | 本文研究了图神经网络中的平滑过度和特征关联过高现象，发现固定不变的子空间导致了节点表示的等级崩塌。在该子空间中平滑向量的存在导致过度平滑，即使避免过度平滑也会导致过高的关联。为了解决这个问题，我们提出了一种克罗内克积之和作为一种有效方法。 |
| [^171] | [Learning Collaborative Information Dissemination with Graph-based Multi-Agent Reinforcement Learning.](http://arxiv.org/abs/2308.16198) | 本论文介绍了一种使用多智能体强化学习的方法来实现协作信息传播。通过提出分布式POMDP形式，在消息转发上实现了每个智能体的独立决策，相比传统的基于多点中继选择的启发式方法具有重大创新和贡献。同时，该方法利用图卷积强化学习和动态注意力机制捕捉关键网络特征，并提出了不同信息交换方式的两种方法进行评估。 |
| [^172] | [Empowering Clinicians and Democratizing Data Science: Large Language Models Automate Machine Learning for Clinical Studies.](http://arxiv.org/abs/2308.14120) | chatGPT ADA是一种能够自主开发临床研究所需的最先进的机器学习模型的大型语言模型，可将高级分析工具民主化，使非数据科学家的临床医生能够轻松应用于医学领域。 |
| [^173] | [Contextual Pre-Planning on Reward Machine Abstractions for Enhanced Transfer in Deep Reinforcement Learning.](http://arxiv.org/abs/2307.05209) | 我们提出了一种使用奖励机器抽象来表示当前任务，并在迁移学习中提升DRL代理的性能的方法，实验表明该方法能够提高样本效率并在多个领域中进行少样本迁移。 |
| [^174] | [The Ontology for Agents, Systems and Integration of Services: OASIS version 2.](http://arxiv.org/abs/2306.10061) | 本文介绍了 OASIS 2 本体论，一种为代理提供语义表示和通信的行为主义方法。该本体论已应用于区块链及其他领域。 |
| [^175] | [A Simple Unified Uncertainty-Guided Framework for Offline-to-Online Reinforcement Learning.](http://arxiv.org/abs/2306.07541) | SUNG是一种基于不确定性引导的离线到在线强化学习框架，在通过量化不确定性进行探索和应用保守Q值估计的指导下，实现了高效的老化强化学习。 |
| [^176] | [STAR: Improving Low-Resource Information Extraction by Structure-to-Text Data Generation with Large Language Models.](http://arxiv.org/abs/2305.15090) | STAR是一种利用大型语言模型合成数据实例的数据生成方法，用于改进低资源信息抽取，为实际应用提供了需要最少人工标注的解决方案。 |
| [^177] | [CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing.](http://arxiv.org/abs/2305.11738) | 本文提出了一个名为CRITIC的框架，使得大型语言模型可以通过与工具的交互校正自己的错误，从而避免生成出现不一致和问题行为的结果。 |
| [^178] | [InstructIE: A Chinese Instruction-based Information Extraction Dataset.](http://arxiv.org/abs/2305.11527) | 介绍了一份中文的基于指令的信息提取数据集InstructIE，其中包括了270,000个弱监督的数据和1,000个高质量注释实例。实验结果表明当前的模型表现有待改进，该任务仍存在挑战。 |
| [^179] | [AMS-DRL: Learning Multi-Pursuit Evasion for Safe Targeted Navigation of Drones.](http://arxiv.org/abs/2304.03443) | 本文提出了AMS-DRL方法用于训练对抗性神经网络，以学习和快速适应多个攻击者的行为，从而实现无人机的安全导航和到达目标。 |
| [^180] | [Unsupervised Layer-wise Score Aggregation for Textual OOD Detection.](http://arxiv.org/abs/2302.09852) | 提出了一种无监督的逐层聚合异常得分的方法，用于更好地进行文本OOD检测。其能发掘不同层输出的优势，达到更鲁棒的性能，并扩展经典基准测试以反映更现实的设置。 |
| [^181] | [The Normalized Cross Density Functional: A Framework to Quantify Statistical Dependence for Random Processes.](http://arxiv.org/abs/2212.04631) | 本文提出了一种用于量化随机过程统计依赖关系的框架，通过最大化交替协方差估计和规范化交叉密度来衡量多变量统计依赖性，并应用于机器学习架构中。 |
| [^182] | [Machine Learning with a Reject Option: A survey.](http://arxiv.org/abs/2107.11277) | 这项调查综述了机器学习中的拒绝选项。通过机器学习模型避免在可能犯错误时做出预测，可以在决策支持应用中避免严重后果。调查介绍了拒绝选项的条件、评估策略以及相关应用领域，并探讨了它与其他机器学习方法的关系。 |

# 详细

[^1]: 修正机器消除

    Corrective Machine Unlearning

    [https://arxiv.org/abs/2402.14015](https://arxiv.org/abs/2402.14015)

    该论文通过形式化“修正机器消除”来解决受未知操纵影响的数据对训练模型的影响问题，可能仅知道一部分受影响样本。发现纠正消除问题与传统以隐私为导向的消除方法有显著不同的要求。

    

    机器学习模型越来越面临数据完整性挑战，因为它们使用了大规模的从互联网中获取的训练数据集。本文研究了如果模型开发者发现某些数据被篡改或错误，他们可以采取什么措施。这些被篡改的数据会导致不利影响，如容易受到后门样本的攻击、系统性偏见，以及在某些输入领域的准确度降低。通常，并非所有被篡改的训练样本都是已知的，而只有一小部分代表性的受影响数据被标记。

    arXiv:2402.14015v1 Announce Type: cross  Abstract: Machine Learning models increasingly face data integrity challenges due to the use of large-scale training datasets drawn from the internet. We study what model developers can do if they detect that some data was manipulated or incorrect. Such manipulated data can cause adverse effects like vulnerability to backdoored samples, systematic biases, and in general, reduced accuracy on certain input domains. Often, all manipulated training samples are not known, and only a small, representative subset of the affected data is flagged.   We formalize "Corrective Machine Unlearning" as the problem of mitigating the impact of data affected by unknown manipulations on a trained model, possibly knowing only a subset of impacted samples. We demonstrate that the problem of corrective unlearning has significantly different requirements from traditional privacy-oriented unlearning. We find most existing unlearning methods, including the gold-standard
    
[^2]: 水印是否能够在翻译中存活？关于大型语言模型文本水印的跨语言一致性

    Can Watermarks Survive Translation? On the Cross-lingual Consistency of Text Watermark for Large Language Models

    [https://arxiv.org/abs/2402.14007](https://arxiv.org/abs/2402.14007)

    该研究引入了文本水印中的“跨语言一致性”概念，发现当前文本水印技术在文本被翻译成其他语言后失去了一致性，并提出了一种跨语言水印去除攻击方法，有效绕过水印，降低AUC值，同时指出了导致这种差异的关键因素。

    

    文本水印技术旨在标记和识别大型语言模型（LLMs）生成的内容，以防止滥用。本研究引入了文本水印中的“跨语言一致性”概念，评估了文本水印在被翻译成其他语言后保持有效性的能力。两个LLM和三种水印方法的初步实证结果显示，当前的文本水印技术在文本被翻译成不同语言时缺乏一致性。基于这一观察，我们提出了一种跨语言水印去除攻击（CWRA）方法，通过首先从一个LLM中获取来自中介语言的响应，然后将其翻译成目标语言来绕过水印，从而有效地减少AUC值从0.95降至0.67而无性能损失。此外，我们分析了导致交叉一致性差异的两个关键因素。

    arXiv:2402.14007v1 Announce Type: cross  Abstract: Text watermarking technology aims to tag and identify content produced by large language models (LLMs) to prevent misuse. In this study, we introduce the concept of ''cross-lingual consistency'' in text watermarking, which assesses the ability of text watermarks to maintain their effectiveness after being translated into other languages. Preliminary empirical results from two LLMs and three watermarking methods reveal that current text watermarking technologies lack consistency when texts are translated into various languages. Based on this observation, we propose a Cross-lingual Watermark Removal Attack (CWRA) to bypass watermarking by first obtaining a response from an LLM in a pivot language, which is then translated into the target language. CWRA can effectively remove watermarks by reducing the Area Under the Curve (AUC) from 0.95 to 0.67 without performance loss. Furthermore, we analyze two key factors that contribute to the cros
    
[^3]: 深度学习在气候应用中的架构选择的重要性

    The Importance of Architecture Choice in Deep Learning for Climate Applications

    [https://arxiv.org/abs/2402.13979](https://arxiv.org/abs/2402.13979)

    本文研究了深度学习在气候科学应用中架构选择的重要性，并展示了神经网络可以在多样化的气候情景下可预测大西洋经向翻转环流（AMOC），进一步揭示MLP和深度集成可以学习AMOC的物理过程而非模拟其进展。

    

    机器学习已经成为气候科学应用中普遍使用的工具。然而，目前的模型未能解决由人为改变温室气体排放引起的非平稳性，并且不会定期量化所提出的预测的不确定性。在本文中，我们对大西洋经向翻转环流（AMOC）进行建模，通过将温暖水输送到欧洲和美国东海岸，对这些地区的气候至关重要，并且有潜在的突然崩溃风险。我们可以生成通过任意时间尺度的任意极端气候场景，然后利用神经网络进行预测。我们的分析显示，在多样化的气候情景下，AMOC可以通过神经网络进行可预测。进一步的实验显示，MLP和深度集成可以学习AMOC的物理过程，而不是通过自相关模拟其进展。通过量化不确定性，发现了一个有趣的模式。

    arXiv:2402.13979v1 Announce Type: cross  Abstract: Machine Learning has become a pervasive tool in climate science applications. However, current models fail to address nonstationarity induced by anthropogenic alterations in greenhouse emissions and do not routinely quantify the uncertainty of proposed projections. In this paper, we model the Atlantic Meridional Overturning Circulation (AMOC) which is of major importance to climate in Europe and the US East Coast by transporting warm water to these regions, and has the potential for abrupt collapse. We can generate arbitrarily extreme climate scenarios through arbitrary time scales which we then predict using neural networks. Our analysis shows that the AMOC is predictable using neural networks under a diverse set of climate scenarios. Further experiments reveal that MLPs and Deep Ensembles can learn the physics of the AMOC instead of imitating its progression through autocorrelation. With quantified uncertainty, an intriguing pattern 
    
[^4]: 用于建模科学机器学习中Aleatoric不确定性的概率神经网络（PNNs）

    Probabilistic Neural Networks (PNNs) for Modeling Aleatoric Uncertainty in Scientific Machine Learning

    [https://arxiv.org/abs/2402.13945](https://arxiv.org/abs/2402.13945)

    本文探讨了使用概率神经网络（PNNs）来建模Aleatoric不确定性，通过开发概率距离度量来优化PNN架构，证实了PNNs在模拟Aleatoric不确定性中的有效性。

    

    本文探讨了使用概率神经网络（PNNs）来建模Aleatoric不确定性，该不确定性是指系统输入输出关系中固有的变异性，通常表现为不均等的方差或异方差性。不同于产生确定性输出的传统神经网络，PNNs为目标变量生成概率分布，允许在回归场景中确定预测均值和区间。本文的贡献包括开发概率距离度量来优化PNN架构，以及在受控数据集和涉及纤维增强复合材料的实际材料科学案例中部署PNNs。研究结果证实，PNNs有效地模拟了Aleatoric不确定性，证明在这一目的上，它比通常采用的高斯过程回归更为合适。具体来说，在一个真实的科学环境中

    arXiv:2402.13945v1 Announce Type: cross  Abstract: This paper investigates the use of probabilistic neural networks (PNNs) to model aleatoric uncertainty, which refers to the inherent variability in the input-output relationships of a system, often characterized by unequal variance or heteroscedasticity. Unlike traditional neural networks that produce deterministic outputs, PNNs generate probability distributions for the target variable, allowing the determination of both predicted means and intervals in regression scenarios. Contributions of this paper include the development of a probabilistic distance metric to optimize PNN architecture, and the deployment of PNNs in controlled data sets as well as a practical material science case involving fiber-reinforced composites. The findings confirm that PNNs effectively model aleatoric uncertainty, proving to be more appropriate than the commonly employed Gaussian process regression for this purpose. Specifically, in a real-world scientific
    
[^5]: 确实高效的Transformer能够节约计算吗？

    Do Efficient Transformers Really Save Computation?

    [https://arxiv.org/abs/2402.13934](https://arxiv.org/abs/2402.13934)

    本研究旨在理解高效Transformer（例如稀疏Transformer和线性Transformer）的能力和限制，发现它们适合解决一般DP任务，但不同于标准Transformer。

    

    随着基于Transformer的语言模型在越来越大的数据集上训练，并拥有大量参数，找到更高效的替代标准Transformer变得非常有价值。虽然已经提出了许多高效的Transformer和Transformer的替代方案，但没有一个能够提供它们适合替代标准Transformer的理论保证。这使得很难确定何时使用特定模型以及进一步研究的重点。在本文中，我们旨在理解高效Transformer的能力和局限性，特别是稀疏Transformer和线性Transformer。我们专注于它们在Chain-of-Thought (CoT)提示中展示的推理能力，并遵循先前的研究将它们建模为动态规划（DP）问题。我们的结果表明，虽然这些模型足够表达解决一般DP任务的能力，但与标准Transformer不同

    arXiv:2402.13934v1 Announce Type: cross  Abstract: As transformer-based language models are trained on increasingly large datasets and with vast numbers of parameters, finding more efficient alternatives to the standard Transformer has become very valuable. While many efficient Transformers and Transformer alternatives have been proposed, none provide theoretical guarantees that they are a suitable replacement for the standard Transformer. This makes it challenging to identify when to use a specific model and what directions to prioritize for further investigation. In this paper, we aim to understand the capabilities and limitations of efficient Transformers, specifically the Sparse Transformer and the Linear Transformer. We focus on their reasoning capability as exhibited by Chain-of-Thought (CoT) prompts and follow previous works to model them as Dynamic Programming (DP) problems. Our results show that while these models are expressive enough to solve general DP tasks, contrary to ex
    
[^6]: SDXL-Lightning: 渐进式对抗性扩散蒸馏

    SDXL-Lightning: Progressive Adversarial Diffusion Distillation

    [https://arxiv.org/abs/2402.13929](https://arxiv.org/abs/2402.13929)

    提出了一种结合渐进和对抗性蒸馏的扩散蒸馏方法，在文本到图像生成任务中取得了新的最先进结果，并开源了相应模型。

    

    我们提出了一种扩散蒸馏方法，在基于SDXL的一步/几步1024像素文本到图像生成任务中实现了全新的最先进水平。我们的方法结合了渐进和对抗性蒸馏，实现了质量和模式覆盖之间的平衡。本文讨论了理论分析、判别器设计、模型公式和训练技巧。我们以LoRA和完整UNet权重的形式开源了我们的蒸馏SDXL-Lightning模型。

    arXiv:2402.13929v1 Announce Type: cross  Abstract: We propose a diffusion distillation method that achieves new state-of-the-art in one-step/few-step 1024px text-to-image generation based on SDXL. Our method combines progressive and adversarial distillation to achieve a balance between quality and mode coverage. In this paper, we discuss the theoretical analysis, discriminator design, model formulation, and training techniques. We open-source our distilled SDXL-Lightning models both as LoRA and full UNet weights.
    
[^7]: 以妄想的对冲算法作为人类从多元观点学习的模型

    The Delusional Hedge Algorithm as a Model of Human Learning from Diverse Opinions

    [https://arxiv.org/abs/2402.13927](https://arxiv.org/abs/2402.13927)

    通过扩展妄想对冲算法，本研究提出了一种模型，能够帮助人们从多元信息源中学习并判断哪些观点值得信任。

    

    认知学习模型通常假设直接体验事件的特征和真实标签或结果，但大部分日常学习来源于听取他人观点，没有直接接触体验或准确结果。我们通过扩展对冲算法来考虑人们在这种场景下如何学会信任哪些观点：这是一个经典解决方案，用于从不同信息源学习。我们首次引入了一个我们称之为妄想对冲的半监督变体，它能够从监督和无监督经验中学习。通过两个实验，我们检验了人类判断和标准对冲、妄想对冲以及启发式基线模型预测之间的一致性。结果表明，人类有效地结合了标记和未标记信息，与妄想对冲算法一致地学习——这表明人类学习者

    arXiv:2402.13927v1 Announce Type: new  Abstract: Whereas cognitive models of learning often assume direct experience with both the features of an event and with a true label or outcome, much of everyday learning arises from hearing the opinions of others, without direct access to either the experience or the ground truth outcome. We consider how people can learn which opinions to trust in such scenarios by extending the hedge algorithm: a classic solution for learning from diverse information sources. We first introduce a semi-supervised variant we call the delusional hedge capable of learning from both supervised and unsupervised experiences. In two experiments, we examine the alignment between human judgments and predictions from the standard hedge, the delusional hedge, and a heuristic baseline model. Results indicate that humans effectively incorporate both labeled and unlabeled information in a manner consistent with the delusional hedge algorithm -- suggesting that human learners
    
[^8]: 大型语言模型易受诱饵-转换攻击的危害内容生成研究

    Large Language Models are Vulnerable to Bait-and-Switch Attacks for Generating Harmful Content

    [https://arxiv.org/abs/2402.13926](https://arxiv.org/abs/2402.13926)

    大型语言模型可能受到诱饵-转换攻击的威胁，甚至安全生成的文本也能轻易转变为有害内容，强调在LLMs的安全防护中需要考虑后处理转换。

    

    大型语言模型（LLMs）生成欺骗性和有害内容所带来的风险已经引起了相当多的研究，但即使是安全的生成也可能导致问题降级影响。在我们的研究中，我们将焦点转移到即使来自LLMs的安全文本也可以通过诱饵-转换攻击轻松转变为潜在危险内容。在这种攻击中，用户首先用安全问题提示LLMs，然后利用简单的查找和替换后处理技术将输出操纵成有害叙事。这种方法在生成有毒内容方面的惊人有效性突出了在开发可靠的LLMs安全防护栏时面临的重大挑战。特别是，我们强调，专注于逐字的LLMs输出的安全性是不够的，我们还需要考虑后处理转换。

    arXiv:2402.13926v1 Announce Type: cross  Abstract: The risks derived from large language models (LLMs) generating deceptive and damaging content have been the subject of considerable research, but even safe generations can lead to problematic downstream impacts. In our study, we shift the focus to how even safe text coming from LLMs can be easily turned into potentially dangerous content through Bait-and-Switch attacks. In such attacks, the user first prompts LLMs with safe questions and then employs a simple find-and-replace post-hoc technique to manipulate the outputs into harmful narratives. The alarming efficacy of this approach in generating toxic content highlights a significant challenge in developing reliable safety guardrails for LLMs. In particular, we stress that focusing on the safety of the verbatim LLM outputs is insufficient and that we also need to consider post-hoc transformations.
    
[^9]: SYNFAC-EDIT: 用于临床摘要中的事实对齐的合成模仿编辑反馈

    SYNFAC-EDIT: Synthetic Imitation Edit Feedback for Factual Alignment in Clinical Summarization

    [https://arxiv.org/abs/2402.13919](https://arxiv.org/abs/2402.13919)

    该研究提出了一种创新流程，利用GPT-3.5和GPT-4生成高质量反馈，以增强临床笔记摘要中的事实一致性，弥补了专家注释数据的高成本和有限可用性问题。

    

    大型语言模型（LLMs）如GPT和Llama在摘要任务上取得了重大进展，但在事实不准确方面存在困难，这是临床NLP应用中的关键问题，错误可能导致严重后果。为了解决事实对齐的专家注释数据成本高昂且有限的问题，本研究引入了一种创新的流程，利用GPT-3.5和GPT-4生成高质量反馈，旨在增强临床笔记摘要中的事实一致性。我们的研究主要关注编辑反馈，在没有额外注释的情况下，模拟了医疗专业人员改善AI系统输出的实际场景。尽管GPT在各种临床NLP任务中都表现出了专业水平，比如医学执照考试，但对其提供改善较弱LM或LLM生成质量的专业级编辑反馈的研究很少。

    arXiv:2402.13919v1 Announce Type: cross  Abstract: Large Language Models (LLMs) such as GPT and Llama have demonstrated significant achievements in summarization tasks but struggle with factual inaccuracies, a critical issue in clinical NLP applications where errors could lead to serious consequences. To counter the high costs and limited availability of expert-annotated data for factual alignment, this study introduces an innovative pipeline that utilizes GPT-3.5 and GPT-4 to generate high-quality feedback aimed at enhancing factual consistency in clinical note summarization. Our research primarily focuses on edit feedback, mirroring the practical scenario in which medical professionals refine AI system outputs without the need for additional annotations. Despite GPT's proven expertise in various clinical NLP tasks, such as the Medical Licensing Examination, there is scant research on its capacity to deliver expert-level edit feedback for improving weaker LMs or LLMs generation qualit
    
[^10]: LLM翻译中的语言特征和重要语言是什么？

    What Linguistic Features and Languages are Important in LLM Translation?

    [https://arxiv.org/abs/2402.13917](https://arxiv.org/abs/2402.13917)

    Llama2模型在翻译中表现出准确度高，部分未见语言需要更大规模的模型来提升翻译质量，另外语言的句法相似性并非翻译质量的主要因素，某些语言即使数据少依然表现出强相关性。

    

    arXiv：2402.13917v1 公告类型：跨领域 摘要：大型语言模型（LLMs）展示了在多个任务中具有强大能力，包括机器翻译。我们的研究重点在于评估Llama2的机器翻译能力，并探索翻译如何取决于其训练数据中的语言。我们的实验表明，7B Llama2模型对其所见的所有语言都可以获得超过10的BLEU分数，但并非总是对其未见的语言。对于这些未见语言，与使用聊天版本或添加少量数据相比，在模型规模上观察到的最大收益。此外，我们的语言距离分析显示，句法相似性并非始终是决定翻译质量的主要语言因素。有趣的是，我们发现在特定情况下，一些语言，尽管训练数据明显少于英语，却表现出与英语可比的强相关性。我们在这里的发现为研究提供了新的视角。

    arXiv:2402.13917v1 Announce Type: cross  Abstract: Large Language Models (LLMs) demonstrate strong capability across multiple tasks, including machine translation. Our study focuses on evaluating Llama2's machine translation capabilities and exploring how translation depends on languages in its training data. Our experiments show that the 7B Llama2 model yields above 10 BLEU score for all languages it has seen, but not always for languages it has not seen. Most gains for those unseen languages are observed the most with the model scale compared to using chat versions or adding shot count. Furthermore, our linguistic distance analysis reveals that syntactic similarity is not always the primary linguistic factor in determining translation quality. Interestingly, we discovered that under specific circumstances, some languages, despite having significantly less training data than English, exhibit strong correlations comparable to English. Our discoveries here give new perspectives for the 
    
[^11]: 不是为了辩解而是为了解释

    Explain to Question not to Justify

    [https://arxiv.org/abs/2402.13914](https://arxiv.org/abs/2402.13914)

    XAI领域被划分为蓝色XAI和红色XAI两种解释文化，指出了红色XAI领域的重要性和研究潜力，并提出了未来的研究挑战。

    

    可解释人工智能（XAI）是一个年轻但非常有前途的研究领域。不幸的是，该领域目前的进展受到了不同和不兼容目标的限制。在本文中，我们将XAI领域内纠缠在一起的各种线索分为两种互补的文化，即人类/价值取向解释（蓝色XAI）和模型/验证取向解释（红色XAI）。我们还认为，红色XAI领域目前未被充分探索，隐藏着巨大的机遇和重要研究的潜力，以确保AI系统的安全。我们通过提出这一领域的有前途的挑战来总结本文。

    arXiv:2402.13914v1 Announce Type: new  Abstract: Explainable Artificial Intelligence (XAI) is a young but very promising field of research. Unfortunately, the progress in this field is currently slowed down by divergent and incompatible goals. In this paper, we separate various threads tangled within the area of XAI into two complementary cultures of human/value-oriented explanations (BLUE XAI) and model/validation-oriented explanations (RED XAI). We also argue that the area of RED XAI is currently under-explored and hides great opportunities and potential for important research necessary to ensure the safety of AI systems. We conclude this paper by presenting promising challenges in this area.
    
[^12]: 科学检查者再度升级：透明度和逻辑推理的双向范式

    Science Checker Reloaded: A Bidirectional Paradigm for Transparency and Logical Reasoning

    [https://arxiv.org/abs/2402.13897](https://arxiv.org/abs/2402.13897)

    提出了一个两块式的方法来解决长文档中信息检索领域的挑战，并实现了双向交互

    

    信息检索是一个快速发展的领域。然而，它仍然面临着在科学和工业的海量信息中的诸多限制，比如语义分歧和检索中的词汇差距、语义搜索中的低精度和缺乏可解释性，或者生成模型中的幻觉和过时信息。在本文中，我们提出了一个两块式的方法来解决长文档的这些障碍。第一个模块通过查询扩展增强了在稀疏检索中的语言理解，以检索相关文档。第二个模块通过只使用长文档中传播的信息，为复杂问题提供全面和信息丰富的答案来加深结果，实现双向交互。在管道的各个阶段，向用户呈现中间结果以促进对系统推理的理解。我们相信这种双向方法带来了

    arXiv:2402.13897v1 Announce Type: cross  Abstract: Information retrieval is a rapidly evolving field. However it still faces significant limitations in the scientific and industrial vast amounts of information, such as semantic divergence and vocabulary gaps in sparse retrieval, low precision and lack of interpretability in semantic search, or hallucination and outdated information in generative models. In this paper, we introduce a two-block approach to tackle these hurdles for long documents. The first block enhances language understanding in sparse retrieval by query expansion to retrieve relevant documents. The second block deepens the result by providing comprehensive and informative answers to the complex question using only the information spread in the long document, enabling bidirectional engagement. At various stages of the pipeline, intermediate results are presented to users to facilitate understanding of the system's reasoning. We believe this bidirectional approach brings
    
[^13]: 一种可解释的基于Transformer的钓鱼邮件检测模型：基于大型语言模型的方法

    An Explainable Transformer-based Model for Phishing Email Detection: A Large Language Model Approach

    [https://arxiv.org/abs/2402.13871](https://arxiv.org/abs/2402.13871)

    优化的Transformer模型DistilBERT用于检测钓鱼邮件，通过预处理技术解决了类别不平衡问题

    

    钓鱼邮件是一种严重的网络威胁，试图通过发送虚假邮件来欺骗用户，意图是窃取机密信息或造成财务损失。攻击者常常冒充可信实体，利用技术进步和复杂性使得钓鱼的检测和预防更具挑战性。尽管进行了大量学术研究，但钓鱼邮件检测在网络安全领域仍然是一个持续且严峻的挑战。大型语言模型（LLMs）和掩盖语言模型（MLMs）拥有巨大潜力，能够提供创新解决方案来解决长期存在的挑战。在本研究论文中，我们提出了一个经过优化的、经过微调的基于Transformer的DistilBERT模型，用于检测钓鱼邮件。在检测过程中，我们使用了一组钓鱼邮件数据集，并利用预处理技术来清理和解决类别不平衡问题。通过我们的实验，

    arXiv:2402.13871v1 Announce Type: cross  Abstract: Phishing email is a serious cyber threat that tries to deceive users by sending false emails with the intention of stealing confidential information or causing financial harm. Attackers, often posing as trustworthy entities, exploit technological advancements and sophistication to make detection and prevention of phishing more challenging. Despite extensive academic research, phishing detection remains an ongoing and formidable challenge in the cybersecurity landscape. Large Language Models (LLMs) and Masked Language Models (MLMs) possess immense potential to offer innovative solutions to address long-standing challenges. In this research paper, we present an optimized, fine-tuned transformer-based DistilBERT model designed for the detection of phishing emails. In the detection process, we work with a phishing email dataset and utilize the preprocessing techniques to clean and solve the imbalance class issues. Through our experiments, 
    
[^14]: Kuaiji：第一个中国会计大型语言模型

    Kuaiji: the First Chinese Accounting Large Language Model

    [https://arxiv.org/abs/2402.13866](https://arxiv.org/abs/2402.13866)

    Kuaiji是第一个中国会计大型语言模型，通过Baichuan框架精心调整，支持的CAtAcctQA数据集，展现出卓越的准确性和响应速度，具有开创性地创建了中国会计数据集，并证实了在真实会计场景中的高效性。

    

    大语言模型（LLMs）如ChatGPT和GPT-4已经展示出在理解和生成自然语言方面的出色能力。然而，当面临任务要求适应会计等专业领域时，它们会遇到困难。为了解决这一挑战，我们引入了Kuaiji，一个专门定制的会计大型语言模型。Kuaiji经过精心调整，使用包含连续预训练和监督微调过程的Baichuan框架。在CAtAcctQA的支持下，这是一个包含大量真实会计师与客户对话的数据集，Kuaiji表现出卓越的准确性和响应速度。我们的贡献包括创建了第一个中国会计数据集，将Kuaiji建立为一种领先的开源中国会计LLM，并通过真实会计场景对其有效性进行了验证。

    arXiv:2402.13866v1 Announce Type: cross  Abstract: Large Language Models (LLMs) like ChatGPT and GPT-4 have demonstrated impressive proficiency in comprehending and generating natural language. However, they encounter difficulties when tasked with adapting to specialized domains such as accounting. To address this challenge, we introduce Kuaiji, a tailored Accounting Large Language Model. Kuaiji is meticulously fine-tuned using the Baichuan framework, which encompasses continuous pre-training and supervised fine-tuning processes. Supported by CAtAcctQA, a dataset containing large genuine accountant-client dialogues, Kuaiji exhibits exceptional accuracy and response speed. Our contributions encompass the creation of the first Chinese accounting dataset, the establishment of Kuaiji as a leading open-source Chinese accounting LLM, and the validation of its efficacy through real-world accounting scenarios.
    
[^15]: RealDex: 实现机器人灵巧手类人式抓取

    RealDex: Towards Human-like Grasping for Robotic Dexterous Hand

    [https://arxiv.org/abs/2402.13853](https://arxiv.org/abs/2402.13853)

    RealDex数据集捕捉了真实的灵巧手抓取动作，利用多模态数据使得训练灵巧手更加自然和精确，同时提出了一种先进的灵巧抓取动作生成框架，有效利用多模态大型语言模型，在类人机器人的自动感知、认知和操纵方面具有巨大潜力。

    

    在本文中，我们介绍了RealDex，一个开创性的数据集，捕捉了融入了人类行为模式的真实灵巧手抓取动作，同时通过多视角和多模态视觉数据进行了丰富。利用远程操作系统，我们可以实时无缝同步人-机器人手姿势。这些类人动作的集合对于训练灵巧手更自然、更精确地模仿人类动作至关重要。RealDex在推动类人机器人在真实场景中自动感知、认知和操纵方面具有巨大潜力。此外，我们介绍了一种前沿的灵巧抓取动作生成框架，该框架符合人类经验，并通过有效利用多模态大型语言模型增强了在现实世界中的适用性。广泛的实验证明了我们的方法在RealDex和其他开放数据集上的优越性能。完整的数据集和代码将会公开发布。

    arXiv:2402.13853v1 Announce Type: cross  Abstract: In this paper, we introduce RealDex, a pioneering dataset capturing authentic dexterous hand grasping motions infused with human behavioral patterns, enriched by multi-view and multimodal visual data. Utilizing a teleoperation system, we seamlessly synchronize human-robot hand poses in real time. This collection of human-like motions is crucial for training dexterous hands to mimic human movements more naturally and precisely. RealDex holds immense promise in advancing humanoid robot for automated perception, cognition, and manipulation in real-world scenarios. Moreover, we introduce a cutting-edge dexterous grasping motion generation framework, which aligns with human experience and enhances real-world applicability through effectively utilizing Multimodal Large Language Models. Extensive experiments have demonstrated the superior performance of our method on RealDex and other open datasets. The complete dataset and code will be made 
    
[^16]: 连续葡萄糖监测和维护的神经控制系统

    Neural Control System for Continuous Glucose Monitoring and Maintenance

    [https://arxiv.org/abs/2402.13852](https://arxiv.org/abs/2402.13852)

    引入了一种新颖的神经控制系统，用于连续葡萄糖监测和维护，实时动态调整胰岛素输送，增强葡萄糖优化，最大化效率并确保个性化护理。

    

    精确的葡萄糖水平管理对于糖尿病患者至关重要，可以避免严重并发症。本研究引入了一种新颖的神经控制系统，用于连续葡萄糖监测和维护，利用微分预测控制。我们的系统受到复杂神经策略和可区分建模的指导，实时动态调整胰岛素输送，增强葡萄糖优化。这种端到端方法最大化效率，确保个性化护理和改善健康结果，如经验发现所证实。

    arXiv:2402.13852v1 Announce Type: cross  Abstract: Precise glucose level management is pivotal for individuals with diabetes, averting severe complications. In this work, we introduce a novel neural control system for continuous glucose monitoring and maintenance, utilizing differential predictive control. Our system, guided by a sophisticated neural policy and differentiable modeling, dynamically adjusts insulin delivery in real-time, enhancing glucose optimization. This end-to-end approach maximizes efficiency, ensuring personalized care and improved health outcomes, as affirmed by empirical findings.
    
[^17]: 大型语言模型是先进的匿名化工具

    Large Language Models are Advanced Anonymizers

    [https://arxiv.org/abs/2402.13846](https://arxiv.org/abs/2402.13846)

    大型语言模型在保护个人数据方面取得了重要进展，提出了一种基于对抗性LLM推断的匿名化框架。

    

    最近在隐私研究领域对大型语言模型的研究表明，它们在推断真实世界在线文本中的个人数据方面表现出接近人类水平的性能。随着模型能力的不断增强，现有的文本匿名化方法当前已经落后于监管要求和对抗威胁。这引出了一个问题：个人如何有效地保护他们在分享在线文本时的个人数据。在这项工作中，我们采取了两步来回答这个问题：首先，我们提出了一个新的设置，用于评估面对对抗性LLM的推断时的匿名化效果，从而允许自然地测量匿名化性能，同时纠正了以前指标的一些缺陷。然后，我们提出了基于LLM的对抗性匿名化框架，利用LLM的强大推断能力来指导我们的匿名化过程。在我们的实验评估中，我们展示了在真实世界中的匿名化实践。

    arXiv:2402.13846v1 Announce Type: cross  Abstract: Recent work in privacy research on large language models has shown that they achieve near human-level performance at inferring personal data from real-world online texts. With consistently increasing model capabilities, existing text anonymization methods are currently lacking behind regulatory requirements and adversarial threats. This raises the question of how individuals can effectively protect their personal data in sharing online texts. In this work, we take two steps to answer this question: We first present a new setting for evaluating anonymizations in the face of adversarial LLMs inferences, allowing for a natural measurement of anonymization performance while remedying some of the shortcomings of previous metrics. We then present our LLM-based adversarial anonymization framework leveraging the strong inferential capabilities of LLMs to inform our anonymization procedure. In our experimental evaluation, we show on real-world 
    
[^18]: LLM4SBR: 一个轻量且有效的框架，用于在基于会话的推荐中集成大型语言模型

    LLM4SBR: A Lightweight and Effective Framework for Integrating Large Language Models in Session-based Recommendation

    [https://arxiv.org/abs/2402.13840](https://arxiv.org/abs/2402.13840)

    该研究提出了LLM4SBR框架，是第一个适合在基于会话的推荐中集成大型语言模型的轻量且有效框架。

    

    传统的基于会话的推荐(SBR)利用来自匿名用户的会话行为序列进行推荐。虽然这种策略非常高效，但牺牲了商品的固有语义信息，使模型难以理解会话的真正意图，导致推荐结果缺乏可解释性。近年来，大型语言模型(LLMs)在各个领域蓬勃发展，为解决上述挑战带来了一线希望。受LLMs影响，探讨LLMs与推荐系统(RS)集成的研究如雨后春笋般涌现。然而，受限于高时间和空间成本，以及会话数据短暂且匿名的特性，第一个适合工业部署的LLM推荐框架在SBR领域尚未出现。为了解决上述挑战，我们...

    arXiv:2402.13840v1 Announce Type: cross  Abstract: Traditional session-based recommendation (SBR) utilizes session behavior sequences from anonymous users for recommendation. Although this strategy is highly efficient, it sacrifices the inherent semantic information of the items, making it difficult for the model to understand the true intent of the session and resulting in a lack of interpretability in the recommended results. Recently, large language models (LLMs) have flourished across various domains, offering a glimpse of hope in addressing the aforementioned challenges. Inspired by the impact of LLMs, research exploring the integration of LLMs with the Recommender system (RS) has surged like mushrooms after rain. However, constrained by high time and space costs, as well as the brief and anonymous nature of session data, the first LLM recommendation framework suitable for industrial deployment has yet to emerge in the field of SBR. To address the aforementioned challenges, we hav
    
[^19]: FLD：傅立叶潜动力学用于结构化运动表示和学习

    FLD: Fourier Latent Dynamics for Structured Motion Representation and Learning

    [https://arxiv.org/abs/2402.13820](https://arxiv.org/abs/2402.13820)

    介绍了一种自监督的、结构化的表示和生成方法，通过傅立叶潜动力学提高了运动学习算法的插值和泛化能力。

    

    运动轨迹为基于物理的运动学习提供可靠参考，但在缺乏足够数据覆盖的区域，存在稀疏性问题。为了解决这一挑战，我们引入了一种自监督的结构化表示和生成方法，提取周期性或准周期性运动的时空关系。在连续参数化的潜空间中的运动动力学使我们的方法能够增强运动学习算法的插值和泛化能力。受运动参数化启发的运动学习控制器可以在线跟踪各种运动，包括训练时未见过的目标。通过一个回退机制，控制器可以动态调整其跟踪策略，并在提出潜在危险目标时自动采取安全行动执行。通过利用识别的时空结构，我们的工作开启

    arXiv:2402.13820v1 Announce Type: cross  Abstract: Motion trajectories offer reliable references for physics-based motion learning but suffer from sparsity, particularly in regions that lack sufficient data coverage. To address this challenge, we introduce a self-supervised, structured representation and generation method that extracts spatial-temporal relationships in periodic or quasi-periodic motions. The motion dynamics in a continuously parameterized latent space enable our method to enhance the interpolation and generalization capabilities of motion learning algorithms. The motion learning controller, informed by the motion parameterization, operates online tracking of a wide range of motions, including targets unseen during training. With a fallback mechanism, the controller dynamically adapts its tracking strategy and automatically resorts to safe action execution when a potentially risky target is proposed. By leveraging the identified spatial-temporal structure, our work open
    
[^20]: NeuralDiffuser：具有主视觉特征引导扩散的可控fMRI重建

    NeuralDiffuser: Controllable fMRI Reconstruction with Primary Visual Feature Guided Diffusion

    [https://arxiv.org/abs/2402.13809](https://arxiv.org/abs/2402.13809)

    NeuralDiffuser引入主视觉特征引导，扩展了LDM方法的自下而上过程，以实现忠实的语义和细节。

    

    基于潜在扩散模型(LDM)从功能性磁共振成像(fMRI)中重建视觉刺激，为大脑提供了细粒度的检索。一个挑战在于重建细节的连贯对齐（如结构、背景、纹理、颜色等）。此外，即使在相同条件下，LDM也会生成不同的图像结果。因此，我们首先揭示了基于LDM的神经科学视角，即基于来自海量图像的预训练知识进行自上而下的创建，但缺乏基于细节驱动的自下而上感知，导致细节不忠实。我们提出了NeuralDiffuser，引入主视觉特征引导，以渐变形式提供细节线索，扩展了LDM方法的自下而上过程，以实现忠实的语义和细节。我们还开发了一种新颖的引导策略，以确保重复重建的一致性，而不是随机性。

    arXiv:2402.13809v1 Announce Type: cross  Abstract: Reconstructing visual stimuli from functional Magnetic Resonance Imaging (fMRI) based on Latent Diffusion Models (LDM) provides a fine-grained retrieval of the brain. A challenge persists in reconstructing a cohesive alignment of details (such as structure, background, texture, color, etc.). Moreover, LDMs would generate different image results even under the same conditions. For these, we first uncover the neuroscientific perspective of LDM-based methods that is top-down creation based on pre-trained knowledge from massive images but lack of detail-driven bottom-up perception resulting in unfaithful details. We propose NeuralDiffuser which introduces primary visual feature guidance to provide detail cues in the form of gradients, extending the bottom-up process for LDM-based methods to achieve faithful semantics and details. We also developed a novel guidance strategy to ensure the consistency of repeated reconstructions rather than a
    
[^21]: 基于深度强化学习策略的分层控制器合成

    Synthesis of Hierarchical Controllers Based on Deep Reinforcement Learning Policies

    [https://arxiv.org/abs/2402.13785](https://arxiv.org/abs/2402.13785)

    提出了基于深度强化学习策略的分层控制器设计方法，通过训练简洁的“潜在”策略来解决房间建模问题，无需模型提炼步骤，克服了DRL中的稀疏奖励，实现了低级策略的可重用性

    

    我们提出了一种新颖的方法来解决将环境建模为马尔可夫决策过程（MDPs）的控制器设计问题。具体来说，我们考虑了一个分层MDP，一个由称为“房间”的MDP填充的图形。我们首先应用深度强化学习（DRL）来获得每个房间的低级策略，以适应未知结构的大房间。然后我们应用反应合成来获得一个高级规划者，选择在每个房间执行哪个低级策略。在合成规划者方面的中心挑战是需要对房间进行建模。我们通过开发一个DRL过程来训练简洁的“潜在”策略以及关于其性能的PAC保证来解决这一挑战。与先前方法不同，我们的方法规避了模型提炼步骤。我们的方法对抗DRL中的稀疏奖励，并实现了低级策略的可重用性。我们通过一个涉及代理导航的案例研究证明了可行性。

    arXiv:2402.13785v1 Announce Type: new  Abstract: We propose a novel approach to the problem of controller design for environments modeled as Markov decision processes (MDPs). Specifically, we consider a hierarchical MDP a graph with each vertex populated by an MDP called a "room". We first apply deep reinforcement learning (DRL) to obtain low-level policies for each room, scaling to large rooms of unknown structure. We then apply reactive synthesis to obtain a high-level planner that chooses which low-level policy to execute in each room. The central challenge in synthesizing the planner is the need for modeling rooms. We address this challenge by developing a DRL procedure to train concise "latent" policies together with PAC guarantees on their performance. Unlike previous approaches, ours circumvents a model distillation step. Our approach combats sparse rewards in DRL and enables reusability of low-level policies. We demonstrate feasibility in a case study involving agent navigation
    
[^22]: 用于概率和神经符号逻辑编程的半环

    Semirings for Probabilistic and Neuro-Symbolic Logic Programming

    [https://arxiv.org/abs/2402.13782](https://arxiv.org/abs/2402.13782)

    提出了一种用于概率和神经符号逻辑编程的统一代数视角，将许多PLP的扩展都纳入一个共同的代数逻辑编程框架中。

    

    概率逻辑编程(PLP)领域致力于将概率模型集成到基于逻辑的编程语言中。在过去的30年中，已经开发出许多用于在概率逻辑程序中建模、推理和学习的语言和框架。尽管最初PLP专注于离散概率，但更近期的方法已经将连续分布以及神经网络纳入其中，有效地产生了神经符号方法。我们提供了一个统一的代数透视来看待PLP，表明许多PLP的扩展可以在一个共同的代数逻辑编程框架内进行转换，其中事实被标记为半环的元素，而析取和合取被替换为加法和乘法。这不仅适用于PLP的变体本身，也适用于基于(代数)模型计数的基础执行机制。

    arXiv:2402.13782v1 Announce Type: new  Abstract: The field of probabilistic logic programming (PLP) focuses on integrating probabilistic models into programming languages based on logic. Over the past 30 years, numerous languages and frameworks have been developed for modeling, inference and learning in probabilistic logic programs. While originally PLP focused on discrete probability, more recent approaches have incorporated continuous distributions as well as neural networks, effectively yielding neural-symbolic methods. We provide a unified algebraic perspective on PLP, showing that many if not most of the extensions of PLP can be cast within a common algebraic logic programming framework, in which facts are labeled with elements of a semiring and disjunction and conjunction are replaced by addition and multiplication. This does not only hold for the PLP variations itself but also for the underlying execution mechanism that is based on (algebraic) model counting.
    
[^23]: 从化学反应知识中学习上下文分子表示

    Contextual Molecule Representation Learning from Chemical Reaction Knowledge

    [https://arxiv.org/abs/2402.13779](https://arxiv.org/abs/2402.13779)

    REMO是一个自监督学习框架，通过利用常见化学中明确定义的原子组合规则，在1.7百万个已知化学反应上预训练图形/Transformer编码器，并提出了Masked Reaction Centre Reconstruction (MRCR)和Reaction Centre Identification (RCI)两个预训练目标，为分子表示学习提供了新颖解决方案。

    

    近年来，自监督学习已经成为一种强大的工具，用于利用丰富的未标记数据进行表示学习，并已广泛应用于各个领域。然而，当应用于分子表示学习（MRL）时，流行的技术(如掩码亚单位重建)往往表现不佳，这是因为分子中可能的原子组合方式自由度较高，给掩码重建范式带来了难以逾越的复杂性。为了应对这一挑战，我们引入了REMO，这是一个自监督学习框架，利用常见化学中的明确定义的原子组合规则。具体来说，REMO在文献中已知的170万个化学反应上进行了图/变换器编码器的预训练。我们提出了两个预训练目标: 掩码反应中心重建（MRCR）和反应中心识别（RCI）。REMO通过利用新颖的解决方案在MRL方面做出了贡献。

    arXiv:2402.13779v1 Announce Type: cross  Abstract: In recent years, self-supervised learning has emerged as a powerful tool to harness abundant unlabelled data for representation learning and has been broadly adopted in diverse areas. However, when applied to molecular representation learning (MRL), prevailing techniques such as masked sub-unit reconstruction often fall short, due to the high degree of freedom in the possible combinations of atoms within molecules, which brings insurmountable complexity to the masking-reconstruction paradigm. To tackle this challenge, we introduce REMO, a self-supervised learning framework that takes advantage of well-defined atom-combination rules in common chemistry. Specifically, REMO pre-trains graph/Transformer encoders on 1.7 million known chemical reactions in the literature. We propose two pre-training objectives: Masked Reaction Centre Reconstruction (MRCR) and Reaction Centre Identification (RCI). REMO offers a novel solution to MRL by exploi
    
[^24]: 离线策略学习的深度生成模型：教程、调查和未来方向展望

    Deep Generative Models for Offline Policy Learning: Tutorial, Survey, and Perspectives on Future Directions

    [https://arxiv.org/abs/2402.13777](https://arxiv.org/abs/2402.13777)

    深度生成模型在离线策略学习中展现了巨大潜力，本文提供了首个系统性综述，涵盖了五种主流深度生成模型及其应用。

    

    深度生成模型(DGMs)在各个领域展示了巨大成功，特别是在使用从离线数据训练的模型生成文本、图像和视频方面。类似地，基于数据驱动的决策和机器人控制也需要从离线数据中学习一个生成函数作为策略或政策。在这种情况下，将深度生成模型应用于离线策略学习展现出巨大潜力，许多研究在这个方向上进行了探索。然而，这一领域仍然缺乏全面的评估，因此不同分支的发展相对独立。因此，我们提供了深度生成模型在离线策略学习应用方面的第一次系统性综述。具体而言，我们涵盖了五种主流深度生成模型，包括变分自动编码器、生成对抗网络、归一化流、变压器和扩散模型，以及它们的应用。

    arXiv:2402.13777v1 Announce Type: cross  Abstract: Deep generative models (DGMs) have demonstrated great success across various domains, particularly in generating texts, images, and videos using models trained from offline data. Similarly, data-driven decision-making and robotic control also necessitate learning a generator function from the offline data to serve as the strategy or policy. In this case, applying deep generative models in offline policy learning exhibits great potential, and numerous studies have explored in this direction. However, this field still lacks a comprehensive review and so developments of different branches are relatively independent. Thus, we provide the first systematic review on the applications of deep generative models for offline policy learning. In particular, we cover five mainstream deep generative models, including Variational Auto-Encoders, Generative Adversarial Networks, Normalizing Flows, Transformers, and Diffusion Models, and their applicati
    
[^25]: Mask-up: 探究戴口罩人脸再识别中的偏见

    Mask-up: Investigating Biases in Face Re-identification for Masked Faces

    [https://arxiv.org/abs/2402.13771](https://arxiv.org/abs/2402.13771)

    研究审计了商业和开源人脸识别系统在戴口罩人脸再识别中的偏见，揭示了这些系统在应对戴口罩带来的挑战方面的不足。

    

    AI基于的人脸识别系统（FRSs）目前已被广泛分发，并部署为遍布全球的MLaaS解决方案，尤其是自COVID-19大流行以来，用于验证个人购买SIM卡时的面部，到对公民进行监视。已经报告了这些系统对边缘化群体存在广泛的偏见，并导致高度歧视性的结果。后疫情时代已经使戴口罩变得正常，但FRSs并没有跟上潮流。因此，这些系统容易受到基于口罩的脸部遮盖的影响。在这项研究中，我们审计了四个商业FRSs和九个开源FRSs，用于在五个基准数据集（共14,722张图像）之间对不同类型的戴口罩和不戴口罩图像进行人脸再识别的任务。这些数据集模拟了部署在全球主要国家中的现实验证/监视任务。其中三个商业和五个开源的...

    arXiv:2402.13771v1 Announce Type: cross  Abstract: AI based Face Recognition Systems (FRSs) are now widely distributed and deployed as MLaaS solutions all over the world, moreso since the COVID-19 pandemic for tasks ranging from validating individuals' faces while buying SIM cards to surveillance of citizens. Extensive biases have been reported against marginalized groups in these systems and have led to highly discriminatory outcomes. The post-pandemic world has normalized wearing face masks but FRSs have not kept up with the changing times. As a result, these systems are susceptible to mask based face occlusion. In this study, we audit four commercial and nine open-source FRSs for the task of face re-identification between different varieties of masked and unmasked images across five benchmark datasets (total 14,722 images). These simulate a realistic validation/surveillance task as deployed in all major countries around the world. Three of the commercial and five of the open-source 
    
[^26]: CriticBench: 将大型语言模型作为评论家进行评估

    CriticBench: Evaluating Large Language Models as Critic

    [https://arxiv.org/abs/2402.13764](https://arxiv.org/abs/2402.13764)

    CriticBench是一个旨在全面和可靠地评估大型语言模型的评论能力的新型基准，展示了评论能力与任务、响应质量和模型规模之间的关系。

    

    论文提出了 CriticBench，这是一个旨在全面和可靠地评估大型语言模型（LLMs）的四个关键评论能力维度（反馈、比较、改进和元反馈）的新型基准。CriticBench包含九个不同的任务，每个任务评估LLMs在不同质量细粒度水平上评论响应的能力。对开源和闭源LLMs进行的广泛评估揭示了评论能力与任务、响应质量和模型规模之间有趣的关系。CriticBench的数据集、资源和评估工具包将在https://github.com/gmftbyGMFTBY/Cri上公开发布。

    arXiv:2402.13764v1 Announce Type: cross  Abstract: Critique ability are crucial in the scalable oversight and self-improvement of Large Language Models (LLMs). While many recent studies explore the critique ability of LLMs to judge and refine flaws in generations, how to comprehensively and reliably measure the critique abilities of LLMs is under-explored. This paper introduces \shortname, a novel benchmark designed to comprehensively and reliably evaluate four key critique ability dimensions of LLMs: feedback, comparison, refinement and meta-feedback. \shortname~encompasses nine diverse tasks, each assessing the LLMs' ability to critique responses at varying levels of quality granularity. Our extensive evaluations of open-source and closed-source LLMs reveal intriguing relationships between the critique ability and tasks, response qualities, and model scales. Datasets, resources and evaluation toolkit for \shortname~will be publicly released at \url{https://github.com/gmftbyGMFTBY/Cri
    
[^27]: 强化学习辅助的变分量子算法量子架构搜索

    Reinforcement learning-assisted quantum architecture search for variational quantum algorithms

    [https://arxiv.org/abs/2402.13754](https://arxiv.org/abs/2402.13754)

    通过强化学习自动搜索变分电路的最佳结构，改善了VQAs的性能。

    

    在嘈杂中等规模量子（NISQ）时代，一个重要障碍是确定功能性量子电路。这些电路必须同时符合当前量子硬件限制所施加的约束。变分量子算法（VQA）是一类量子-经典优化算法，旨在解决当前可用量子设备中的这些挑战。本论文侧重于电路结构，通过使用强化学习（RL）自动搜索变分电路的最优结构，改善了VQAs的性能。论文内通过评估电路的深度、门和参数的总数以及准确性来确定电路的优越性。

    arXiv:2402.13754v1 Announce Type: cross  Abstract: A significant hurdle in the noisy intermediate-scale quantum (NISQ) era is identifying functional quantum circuits. These circuits must also adhere to the constraints imposed by current quantum hardware limitations. Variational quantum algorithms (VQAs), a class of quantum-classical optimization algorithms, were developed to address these challenges in the currently available quantum devices. However, the overall performance of VQAs depends on the initialization strategy of the variational circuit, the structure of the circuit (also known as ansatz), and the configuration of the cost function. Focusing on the structure of the circuit, in this thesis, we improve the performance of VQAs by automating the search for an optimal structure for the variational circuits using reinforcement learning (RL). Within the thesis, the optimality of a circuit is determined by evaluating its depth, the overall count of gates and parameters, and its accu
    
[^28]: AI-Powered Predictions for Electricity Load in Prosumer Communities

    AI-Powered Predictions for Electricity Load in Prosumer Communities

    [https://arxiv.org/abs/2402.13752](https://arxiv.org/abs/2402.13752)

    本文审查了如何利用人工智能技术对生产者兼消费者社区的电力负载进行预测的方法和可行性

    

    住宅楼宇社区的电力消耗和产出灵活性，包括具有可再生能源和能源储存设施（也称为生产者兼消费者），可以通过先进的短期需求响应机制得到有效利用。众所周知，如果在生产者兼消费者社区层面进行需求响应，灵活性就可以进一步提高，因为聚合的群体可以更好地协调电力消费。然而，这种短期优化的效果在很大程度上取决于对每栋建筑物以及整个社区的电力负载预测的准确性。电力负载曲线中的结构变化可能与不同的外部因素相关联，例如天气条件、日历信息、星期几以及用户行为。本文审查了一系列广泛的电力负载预测技术，

    arXiv:2402.13752v1 Announce Type: cross  Abstract: The flexibility in electricity consumption and production in communities of residential buildings, including those with renewable energy sources and energy storage (a.k.a., prosumers), can effectively be utilized through the advancement of short-term demand response mechanisms. It is known that flexibility can further be increased if demand response is performed at the level of communities of prosumers, since aggregated groups can better coordinate electricity consumption. However, the effectiveness of such short-term optimization is highly dependent on the accuracy of electricity load forecasts both for each building as well as for the whole community. Structural variations in the electricity load profile can be associated with different exogenous factors, such as weather conditions, calendar information and day of the week, as well as user behavior. In this paper, we review a wide range of electricity load forecasting techniques, tha
    
[^29]: 打破障碍：通过推理知识图利用大型语言模型进行工业推荐系统

    Breaking the Barrier: Utilizing Large Language Models for Industrial Recommendation Systems through an Inferential Knowledge Graph

    [https://arxiv.org/abs/2402.13750](https://arxiv.org/abs/2402.13750)

    提出了一种基于大型语言模型的互补知识增强推荐系统（LLM-KERec），通过引入实体提取器和构建互补知识图，解决了推荐系统难以捕捉用户意图转变和适应新商品的挑战。

    

    推荐系统在电子商务网站和在线平台中被广泛使用，以应对信息过载。然而，现有系统主要依赖历史数据和用户反馈，难以捕捉用户意图转变。最近，提出了基于知识库（KB）的模型来整合专家知识，但它们难以适应新商品和不断发展的电子商务环境。为了解决这些挑战，我们提出了一种新颖的基于大型语言模型的互补知识增强推荐系统（LLM-KERec）。它引入了一个实体提取器，从商品和用户信息中提取统一概念术语。为了提供具有成本效益且可靠的先验知识，根据实体的流行度和特定策略生成实体对。大型语言模型确定每个实体对中的互补关系，构建一个互补知识图。此外，一个新的...

    arXiv:2402.13750v1 Announce Type: cross  Abstract: Recommendation systems are widely used in e-commerce websites and online platforms to address information overload. However, existing systems primarily rely on historical data and user feedback, making it difficult to capture user intent transitions. Recently, Knowledge Base (KB)-based models are proposed to incorporate expert knowledge, but it struggle to adapt to new items and the evolving e-commerce environment. To address these challenges, we propose a novel Large Language Model based Complementary Knowledge Enhanced Recommendation System (LLM-KERec). It introduces an entity extractor that extracts unified concept terms from item and user information. To provide cost-effective and reliable prior knowledge, entity pairs are generated based on entity popularity and specific strategies. The large language model determines complementary relationships in each entity pair, constructing a complementary knowledge graph. Furthermore, a new 
    
[^30]: 使用表格提示解锁关系三元组抽取的上下文学习

    Unlocking Instructive In-Context Learning with Tabular Prompting for Relational Triple Extraction

    [https://arxiv.org/abs/2402.13741](https://arxiv.org/abs/2402.13741)

    设计了表格提示以解决关系三元组抽取中的提示设计和样本选择挑战。

    

    关系三元组抽取（RTE）的上下文学习（ICL）取得了令人满意的表现，但仍然面临两个关键挑战：（1）如何设计有效的提示和（2）如何选择适当的演示。然而，现有方法未能适当解决这些挑战。一方面，它们通常将RTE任务重新定义为文本-文本提示格式，这是不自然的，导致在预训练时的输出格式和大型语言模型（LLMs）的推断时间之间不匹配。另一方面，它们只利用表面自然语言特征，缺乏在样本选择中考虑三元组语义。这些问题阻碍了ICL对RTE性能的改进，因此我们旨在同时解决提示设计和样本选择挑战。为此，我们设计了一个用于RTE的表格提示（TableIE），将RTE任务构建成一个表格生成任务以解决上述挑战。

    arXiv:2402.13741v1 Announce Type: cross  Abstract: The in-context learning (ICL) for relational triple extraction (RTE) has achieved promising performance, but still encounters two key challenges: (1) how to design effective prompts and (2) how to select proper demonstrations. Existing methods, however, fail to address these challenges appropriately. On the one hand, they usually recast RTE task to text-to-text prompting formats, which is unnatural and results in a mismatch between the output format at the pre-training time and the inference time for large language models (LLMs). On the other hand, they only utilize surface natural language features and lack consideration of triple semantics in sample selection. These issues are blocking improved performance in ICL for RTE, thus we aim to tackle prompt designing and sample selection challenges simultaneously. To this end, we devise a tabular prompting for RTE (\textsc{TableIE}) which frames RTE task into a table generation task to inco
    
[^31]: 大型预训练语言模型的达芬奇密码：解读退化知识神经元

    The Da Vinci Code of Large Pre-trained Language Models: Deciphering Degenerate Knowledge Neurons

    [https://arxiv.org/abs/2402.13731](https://arxiv.org/abs/2402.13731)

    本研究提供了对预训练语言模型中退化知识神经元（DKNs）的全面定义，引入了神经拓扑聚类方法和神经退化分析框架，从而实现更准确的DKN获取。

    

    本研究探讨了预训练语言模型（PLMs）中事实知识存储的机制。先前的研究表明，事实知识存储在多层感知器权重中，某些存储单元表现出退化性，称为退化知识神经元（Degenerate Knowledge Neurons, DKNs）。本文提供了一个涵盖结构和功能方面的DKNs全面定义，开创了对PLMs事实知识存储单元结构的研究。基于此，我们引入了神经拓扑聚类方法，该方法允许形成任意数量和结构的DKNs，从而实现更准确的DKN获取。此外，我们引入了神经退化分析框架，独特地整合了模型鲁棒性、可进化性和复杂性，以对PLMs进行全面评估。在该框架内，我们执行了34个实验，跨越2个PLMs、4个数据集和6个设置。

    arXiv:2402.13731v1 Announce Type: cross  Abstract: This study explores the mechanism of factual knowledge storage in pre-trained language models (PLMs). Previous research suggests that factual knowledge is stored within multi-layer perceptron weights, and some storage units exhibit degeneracy, referred to as Degenerate Knowledge Neurons (DKNs). This paper provides a comprehensive definition of DKNs that covers both structural and functional aspects, pioneering the study of structures in PLMs' factual knowledge storage units. Based on this, we introduce the Neurological Topology Clustering method, which allows the formation of DKNs in any numbers and structures, leading to a more accurate DKN acquisition. Furthermore, we introduce the Neuro-Degeneracy Analytic Analysis Framework, which uniquely integrates model robustness, evolvability, and complexity for a holistic assessment of PLMs. Within this framework, our execution of 34 experiments across 2 PLMs, 4 datasets, and 6 settings highl
    
[^32]: 生物信息学研究中大型语言模型的评估

    An Evaluation of Large Language Models in Bioinformatics Research

    [https://arxiv.org/abs/2402.13714](https://arxiv.org/abs/2402.13714)

    大型语言模型在生物信息学研究中展现出了潜力，可成功处理多项关键任务，但在复杂任务中仍存在局限性。

    

    大型语言模型（LLMs）如ChatGPT在各个研究领域引起了极大关注。它们在文本完成和生成方面的显著能力开创了一种新的用于解决问题的语言界面范式。然而，这些模型在生物信息学中的潜力和功效尚未完全探索。在这项工作中，我们研究了LLMs在各种关键生物信息学任务中的表现。这些任务包括潜在编码区域的识别，基因和蛋白质的命名实体提取，抗微生物和抗癌肽的检测，分子优化以及解决教育性生物信息学问题。我们的发现表明，在给定适当提示的情况下，像GPT变种这样的LLMs可以成功处理大多数这些任务。此外，我们对它们在复杂生物信息学任务背景下的限制进行了彻底的分析。在结论部分，

    arXiv:2402.13714v1 Announce Type: cross  Abstract: Large language models (LLMs) such as ChatGPT have gained considerable interest across diverse research communities. Their notable ability for text completion and generation has inaugurated a novel paradigm for language-interfaced problem solving. However, the potential and efficacy of these models in bioinformatics remain incompletely explored. In this work, we study the performance LLMs on a wide spectrum of crucial bioinformatics tasks. These tasks include the identification of potential coding regions, extraction of named entities for genes and proteins, detection of antimicrobial and anti-cancer peptides, molecular optimization, and resolution of educational bioinformatics problems. Our findings indicate that, given appropriate prompts, LLMs like GPT variants can successfully handle most of these tasks. In addition, we provide a thorough analysis of their limitations in the context of complicated bioinformatics tasks. In conclusion
    
[^33]: DSLR：多样性增强和结构学习用于基于重播的图持续学习

    DSLR: Diversity Enhancement and Structure Learning for Rehearsal-based Graph Continual Learning

    [https://arxiv.org/abs/2402.13711](https://arxiv.org/abs/2402.13711)

    DSLR提出了一种基于覆盖范围的多样性方法，以解决基于重播的图持续学习中回放节点过于集中导致过拟合和灾难性遗忘的问题。

    

    我们研究了基于重播方法中回放缓冲区对图持续学习（GCL）方法的影响。现有的基于重播的GCL方法为每个类别选择最具代表性的节点并将它们存储在重播缓冲区中，以供在训练后续任务时使用。然而，我们发现，仅考虑每个回放节点的类别代表性会使回放节点集中在每个类别的中心周围，可能存在过拟合于位于那些区域的节点的风险，从而加剧灾难性遗忘。此外，由于基于重播方法严重依赖于少数回放节点来保留从先前任务中获得的知识，涉及在模型训练中具有不相关邻居的回放节点可能对模型性能产生显着的负面影响。在本文中，我们提出了一种名为DSLR的GCL模型，具体来说，我们设计了一种基于覆盖范围的多样性（CD）

    arXiv:2402.13711v1 Announce Type: cross  Abstract: We investigate the replay buffer in rehearsal-based approaches for graph continual learning (GCL) methods. Existing rehearsal-based GCL methods select the most representative nodes for each class and store them in a replay buffer for later use in training subsequent tasks. However, we discovered that considering only the class representativeness of each replayed node makes the replayed nodes to be concentrated around the center of each class, incurring a potential risk of overfitting to nodes residing in those regions, which aggravates catastrophic forgetting. Moreover, as the rehearsal-based approach heavily relies on a few replayed nodes to retain knowledge obtained from previous tasks, involving the replayed nodes that have irrelevant neighbors in the model training may have a significant detrimental impact on model performance. In this paper, we propose a GCL model named DSLR, specifically, we devise a coverage-based diversity (CD)
    
[^34]: SaGE：评估大型语言模型的道德一致性

    SaGE: Evaluating Moral Consistency in Large Language Models

    [https://arxiv.org/abs/2402.13709](https://arxiv.org/abs/2402.13709)

    提出SaGE方法，通过语义图熵来衡量大型语言模型道德一致性，构建了MCC语料库。

    

    尽管最近展示出大型语言模型（LLMs）在会话系统中的印象深刻能力，但我们表明即使是最先进的LLMs在生成过程中也存在道德不一致，对其可靠性（以及总体可信赖性）提出了质疑。以往在LLM评估领域的工作侧重于开发地面真实数据，以衡量在特定任务上的准确性。然而，对于道德情景往往缺乏普遍认同答案的情况，模型响应的一致性对于其可靠性变得至关重要。为了解决这一问题，我们提出了一种信息理论度量方法，称为语义图熵（SaGE），基于“经验法则”（RoTs）的概念来衡量模型的道德一致性。RoTs是模型学习到的抽象原则，可有效帮助解释其决策策略。在此基础上，我们构建了道德一致性语料库（MCC），包含50K个道德问题、回答。

    arXiv:2402.13709v1 Announce Type: cross  Abstract: Despite recent advancements showcasing the impressive capabilities of Large Language Models (LLMs) in conversational systems, we show that even state-of-the-art LLMs are morally inconsistent in their generations, questioning their reliability (and trustworthiness in general). Prior works in LLM evaluation focus on developing ground-truth data to measure accuracy on specific tasks. However, for moral scenarios that often lack universally agreed-upon answers, consistency in model responses becomes crucial for their reliability. To address this issue, we propose an information-theoretic measure called Semantic Graph Entropy (SaGE), grounded in the concept of "Rules of Thumb" (RoTs) to measure a model's moral consistency. RoTs are abstract principles learned by a model and can help explain their decision-making strategies effectively. To this extent, we construct the Moral Consistency Corpus (MCC), containing 50K moral questions, responses
    
[^35]: KInIT参加SemEval-2024任务8：针对多语言机器生成文本检测的微调LLMs

    KInIT at SemEval-2024 Task 8: Fine-tuned LLMs for Multilingual Machine-Generated Text Detection

    [https://arxiv.org/abs/2402.13671](https://arxiv.org/abs/2402.13671)

    本论文针对SemEval-2024任务8提出了一种使用微调LLMs进行多语言机器生成文本检测的方法，通过多种方式处理该任务并将统计检测指标与模型预测相结合，取得了竞争性结果。

    

    arXiv:2402.13671v1 发表类型：交叉传播 摘要：SemEval-2024任务8侧重于多生成器、多领域和多语言的黑盒机器生成文本检测。这样的检测对于防止大型语言模型（LLMs）的潜在滥用非常重要，其中最新的LLMs非常擅长生成多语言的类似人类的文本。我们以多种方式处理了这个任务，利用语言识别和参数高效微调较小的LLMs进行文本分类。我们进一步使用每种语言的分类阈值校准，将微调的模型预测与统计检测指标独特结合，以提高系统检测性能的泛化。我们提交的方法取得了竞争性的结果，排名第四，仅落后于获胜者不到1个百分点。

    arXiv:2402.13671v1 Announce Type: cross  Abstract: SemEval-2024 Task 8 is focused on multigenerator, multidomain, and multilingual black-box machine-generated text detection. Such a detection is important for preventing a potential misuse of large language models (LLMs), the newest of which are very capable in generating multilingual human-like texts. We have coped with this task in multiple ways, utilizing language identification and parameter-efficient fine-tuning of smaller LLMs for text classification. We have further used the per-language classification-threshold calibration to uniquely combine fine-tuned models predictions with statistical detection metrics to improve generalization of the system detection performance. Our submitted method achieved competitive results, ranking at the fourth place, just under 1 percentage point behind the winner.
    
[^36]: 通过LLMs和注意力遮罩完成无监督文本风格转移与多路交互

    Unsupervised Text Style Transfer via LLMs and Attention Masking with Multi-way Interactions

    [https://arxiv.org/abs/2402.13647](https://arxiv.org/abs/2402.13647)

    通过组合注意力遮罩方法和大型语言模型，提出多种交互方式，可以改进无监督文本风格转移任务。

    

    无监督文本风格转移（UTST）已成为自然语言处理（NLP）领域中的一个关键任务，旨在将句子的一种风格方面转换为另一种风格，同时不改变其语义、句法或其他属性。本文探讨了如何有效结合注意力遮罩方法和大型语言模型（LLMs），提出了四种交互方式：具有调整顺序的流水线框架；知识蒸馏从LLMs到注意力遮罩模型；使用构建的并行示例进行上下文学习。我们实验证明这些多路交互可以改进性

    arXiv:2402.13647v1 Announce Type: cross  Abstract: Unsupervised Text Style Transfer (UTST) has emerged as a critical task within the domain of Natural Language Processing (NLP), aiming to transfer one stylistic aspect of a sentence into another style without changing its semantics, syntax, or other attributes. This task is especially challenging given the intrinsic lack of parallel text pairings. Among existing methods for UTST tasks, attention masking approach and Large Language Models (LLMs) are deemed as two pioneering methods. However, they have shortcomings in generating unsmooth sentences and changing the original contents, respectively. In this paper, we investigate if we can combine these two methods effectively. We propose four ways of interactions, that are pipeline framework with tuned orders; knowledge distillation from LLMs to attention masking model; in-context learning with constructed parallel examples. We empirically show these multi-way interactions can improve the ba
    
[^37]: 用于评估可信医疗人工智能数据质量的METRIC框架: 一项系统性综述

    The METRIC-framework for assessing data quality for trustworthy AI in medicine: a systematic review

    [https://arxiv.org/abs/2402.13635](https://arxiv.org/abs/2402.13635)

    本文提出了用于评估医疗人工智能数据质量的METRIC框架，着重探讨数据质量在深度学习应用中的重要性，强调数据质量对于医学人工智能产品监管批准的关键作用。

    

    arXiv:2402.13635v1 公告类型:跨领域 摘要: 机器学习(ML)的采用，更具体地说是深度学习(DL)应用正在蔓延到我们生活的各个主要领域中。在医学领域，发展可信人工智能尤为重要，因为这对患者的生活有着重大影响。虽然可信性涉及多个方面，包括道德、技术和隐私要求，但我们着重于DL中数据质量(训练/测试)的重要性。由于数据质量决定了ML产品的行为，评估数据质量将在医疗人工智能产品的监管批准中起关键作用。我们按照PRISMA指南进行系统性综述，使用PubMed和ACM数字图书馆数据库。我们发现了2362项研究，其中62项符合我们的资格标准。在这一文献中，我们综合现有的关于数据质量框架的知识，并结合ML在医学中的应用视角。因此，我们的工作总结了医疗AI领域数据质量框架的现有知识，并将其与ML应用的视角结合在一起。

    arXiv:2402.13635v1 Announce Type: cross  Abstract: The adoption of machine learning (ML) and, more specifically, deep learning (DL) applications into all major areas of our lives is underway. The development of trustworthy AI is especially important in medicine due to the large implications for patients' lives. While trustworthiness concerns various aspects including ethical, technical and privacy requirements, we focus on the importance of data quality (training/test) in DL. Since data quality dictates the behaviour of ML products, evaluating data quality will play a key part in the regulatory approval of medical AI products. We perform a systematic review following PRISMA guidelines using the databases PubMed and ACM Digital Library. We identify 2362 studies, out of which 62 records fulfil our eligibility criteria. From this literature, we synthesise the existing knowledge on data quality frameworks and combine it with the perspective of ML applications in medicine. As a result, we p
    
[^38]: 将连词谬误视为一个事实进行分析

    Analyizing the Conjunction Fallacy as a Fact

    [https://arxiv.org/abs/2402.13615](https://arxiv.org/abs/2402.13615)

    分析连词谬误的事实可能性范围，揭示大多数研究存在对可能性狭隘的偏见。

    

    自从Tversky和Kahneman的开创性论文以来，连词谬误一直是多次辩论的主题，并成为决策制定中认知理论面临的基本挑战。本文从一种不太常见的角度来看待这一现象。我们分析其事实可能性的范围，而不是试图解释连词谬误的本质或原因（内涵定义）。我们展示了根据我们所审查的涵盖了1983年至2016年文献的实验样本，大多数关于连词谬误的研究集中在先验事实可能性的狭窄部分，暗示了连词谬误的解释在很大程度上受限于探索的可能性范围狭隘。后者是连词谬误研究进化中相当奇特的一个方面，考虑到它本质上是由其可能性的扩展所推动的。

    arXiv:2402.13615v1 Announce Type: new  Abstract: Since the seminal paper by Tversky and Kahneman, the conjunction fallacy has been the subject of multiple debates and become a fundamental challenge for cognitive theories in decision-making. In this article, we take a rather uncommon perspective on this phenomenon. Instead of trying to explain the nature or causes of the conjunction fallacy (intensional definition), we analyze its range of factual possibilities (extensional definition). We show that the majority of research on the conjunction fallacy, according to our sample of experiments reviewed which covers literature between 1983 and 2016, has focused on a narrow part of the a priori factual possibilities, implying that explanations of the conjunction fallacy are fundamentally biased by the short scope of possibilities explored. The latter is a rather curious aspect of the research evolution in the conjunction fallacy considering that the very nature of it is motivated by extension
    
[^39]: 数据驱动的大型生成模型在科学发现中的应用

    Data-driven Discovery with Large Generative Models

    [https://arxiv.org/abs/2402.13610](https://arxiv.org/abs/2402.13610)

    大型生成模型在数据驱动发现中的应用开创了端到端发现系统的新模式，利用提供的数据集搜寻和验证假设，突显了自动化系统的重要性和局限性。

    

    随着数据以前所未有的速度累积，它作为促进科学发现的潜力呈指数增长。这篇立场论文敦促机器学习（ML）社区利用大型生成模型（LGMs）的能力，开发自动化系统用于端到端的数据驱动发现 -- 一种范式，从所提供的数据集中纯粹搜索和验证假设，而无需额外的数据收集或物理实验。我们首先概述了理想数据驱动发现系统的几个期望条件。然后，通过使用GPT-4的DATAVOYAGER作为概念验证，我们展示了LGMs如何实现几项这些期望条件 -- 这是以前无法做到的成就 -- 同时也突显了当前系统中的重要局限性，从而为开展新型机器学习研究提供了机遇。

    arXiv:2402.13610v1 Announce Type: cross  Abstract: With the accumulation of data at an unprecedented rate, its potential to fuel scientific discovery is growing exponentially. This position paper urges the Machine Learning (ML) community to exploit the capabilities of large generative models (LGMs) to develop automated systems for end-to-end data-driven discovery -- a paradigm encompassing the search and verification of hypotheses purely from a set of provided datasets, without the need for additional data collection or physical experiments. We first outline several desiderata for an ideal data-driven discovery system. Then, through DATAVOYAGER, a proof-of-concept utilizing GPT-4, we demonstrate how LGMs fulfill several of these desiderata -- a feat previously unattainable -- while also highlighting important limitations in the current system that open up opportunities for novel ML research. We contend that achieving accurate, reliable, and robust end-to-end discovery systems solely th
    
[^40]: 基于大型语言模型的混合推理在自动驾驶中的应用

    Hybrid Reasoning Based on Large Language Models for Autonomous Car Driving

    [https://arxiv.org/abs/2402.13602](https://arxiv.org/abs/2402.13602)

    大型语言模型在自动驾驶中的混合推理能力可以通过分析数据、理解规则和法则、提供语境等方式提高自动驶驶的决策能力。

    

    大型语言模型（LLMs）因其理解文本和图像、生成类人文本以及执行复杂推理任务的能力而受到广泛关注。然而，它们将这种高级推理与自然语言文本相结合以用于动态情况下的决策的泛化能力需要进一步探索。本研究探讨了LLMs在混合算术和常识推理方面的适应能力和应用能力，特别是在自动驾驶场景中。我们假设LLMs的混合推理能力可以通过使它们分析检测到的物体和传感器数据、理解驾驶规定和物理法则，并提供额外的语境来改善自动驾驶。这解决了复杂情景，如低能见度（由于天气条件）下的决策，传统方法可能不足以胜任。我们通过准确性评估基于大型语言模型（LLMs）的这种能力。

    arXiv:2402.13602v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have garnered significant attention for their ability to understand text and images, generate human-like text, and perform complex reasoning tasks. However, their ability to generalize this advanced reasoning with a combination of natural language text for decision-making in dynamic situations requires further exploration. In this study, we investigate how well LLMs can adapt and apply a combination of arithmetic and common-sense reasoning, particularly in autonomous driving scenarios. We hypothesize that LLMs hybrid reasoning abilities can improve autonomous driving by enabling them to analyze detected object and sensor data, understand driving regulations and physical laws, and offer additional context. This addresses complex scenarios, like decisions in low visibility (due to weather conditions), where traditional methods might fall short. We evaluated Large Language Models (LLMs) based on accuracy by co
    
[^41]: User-LLM: 利用用户嵌入实现有效的LLM语境化

    User-LLM: Efficient LLM Contextualization with User Embeddings

    [https://arxiv.org/abs/2402.13598](https://arxiv.org/abs/2402.13598)

    User-LLM框架利用用户嵌入对LLMs进行语境化，使其能够动态适应用户上下文，在各种任务中实现显著性能提升。

    

    大语言模型(LLMs)已经彻底改变了自然语言处理。然而，有效地整合复杂且潜在嘈杂的用户交互数据仍然是一个挑战。为了解决这个问题，我们提出了User-LLM，这是一个新颖的框架，利用用户嵌入来对LLMs进行语境化。这些嵌入是通过自监督预训练从各种用户交互中精炼出来的，能够捕捉潜在用户偏好及其随时间的演变。我们通过交叉注意力和软提示将这些用户嵌入与LLMs集成起来，使LLMs能够动态适应用户上下文。我们在MovieLens、亚马逊评论和谷歌本地评论等数据集上进行了全面实验，展示了在各种任务中的显著性能提升。值得注意的是，我们的方法在长序列任务和需要深入理解用户的任务上超过了基于文本提示的语境化，同时在计算上也更加高效。

    arXiv:2402.13598v1 Announce Type: cross  Abstract: Large language models (LLMs) have revolutionized natural language processing. However, effectively incorporating complex and potentially noisy user interaction data remains a challenge. To address this, we propose User-LLM, a novel framework that leverages user embeddings to contextualize LLMs. These embeddings, distilled from diverse user interactions using self-supervised pretraining, capture latent user preferences and their evolution over time. We integrate these user embeddings with LLMs through cross-attention and soft-prompting, enabling LLMs to dynamically adapt to user context. Our comprehensive experiments on MovieLens, Amazon Review, and Google Local Review datasets demonstrate significant performance gains across various tasks. Notably, our approach outperforms text-prompt-based contextualization on long sequence tasks and tasks that require deep user understanding while being computationally efficient. We further incorpora
    
[^42]: 用深度强化学习和行为调控掌握关旦游戏

    Mastering the Game of Guandan with Deep Reinforcement Learning and Behavior Regulating

    [https://arxiv.org/abs/2402.13582](https://arxiv.org/abs/2402.13582)

    该论文主要贡献是通过深度神经网络和行为调控方案，提出了一个框架GuanoZero，使AI代理能够掌握《关旦》游戏。

    

    游戏是现实的简化模型，通常被视为人工智能研究的首选平台。 很多研究关注于游戏代理和它们的决策过程。《关旦》是一种具有挑战性的游戏，即使是专业的人类玩家有时也难以做出正确的决策。 在本文中，我们提出了一个名为GuanZero的框架，让AI代理通过蒙特卡洛方法和深度神经网络来掌握这个游戏。 本文的主要贡献在于通过精心设计的神经网络编码方案来调控代理的行为。 然后，我们通过与最先进的方法进行比较，展示了所提出框架的有效性。

    arXiv:2402.13582v1 Announce Type: new  Abstract: Games are a simplified model of reality and often serve as a favored platform for Artificial Intelligence (AI) research. Much of the research is concerned with game-playing agents and their decision making processes. The game of Guandan (literally, "throwing eggs") is a challenging game where even professional human players struggle to make the right decision at times. In this paper we propose a framework named GuanZero for AI agents to master this game using Monte-Carlo methods and deep neural networks. The main contribution of this paper is about regulating agents' behavior through a carefully designed neural network encoding scheme. We then demonstrate the effectiveness of the proposed framework by comparing it with state-of-the-art approaches.
    
[^43]: 基于差异方法的灵活物理伪装生成

    Flexible Physical Camouflage Generation Based on a Differential Approach

    [https://arxiv.org/abs/2402.13575](https://arxiv.org/abs/2402.13575)

    该研究引入了一种新颖的神经渲染方法，名为FPA，通过学习对抗模式并结合特殊设计的对抗损失和隐蔽约束损失，可以生成物理世界中具有对抗性和隐蔽性质的伪装。

    

    这项研究介绍了一种新的神经渲染方法，专门针对对抗伪装，在广泛的三维渲染框架内进行了定制。我们的方法，名为FPA，通过忠实地模拟光照条件和材料变化，确保在三维目标上对纹理进行微妙而逼真的表现。为了实现这一目标，我们采用一种生成方法，从扩散模型中学习对抗模式。这涉及将一个特别设计的对抗损失和隐蔽约束损失结合在一起，以确保伪装在物理世界中的对抗性和隐蔽性质。此外，我们展示了所提出的伪装在贴纸模式下的有效性，展示了其覆盖目标而不影响对抗信息的能力。通过实证和物理实验，FPA在攻击成功率和可转移性方面表现出很强的性能。

    arXiv:2402.13575v1 Announce Type: cross  Abstract: This study introduces a novel approach to neural rendering, specifically tailored for adversarial camouflage, within an extensive 3D rendering framework. Our method, named FPA, goes beyond traditional techniques by faithfully simulating lighting conditions and material variations, ensuring a nuanced and realistic representation of textures on a 3D target. To achieve this, we employ a generative approach that learns adversarial patterns from a diffusion model. This involves incorporating a specially designed adversarial loss and covert constraint loss to guarantee the adversarial and covert nature of the camouflage in the physical world. Furthermore, we showcase the effectiveness of the proposed camouflage in sticker mode, demonstrating its ability to cover the target without compromising adversarial information. Through empirical and physical experiments, FPA exhibits strong performance in terms of attack success rate and transferabili
    
[^44]: 任务待办：用于高分辨率图像高效生成的令牌下采样

    ToDo: Token Downsampling for Efficient Generation of High-Resolution Images

    [https://arxiv.org/abs/2402.13573](https://arxiv.org/abs/2402.13573)

    提出了一种新的训练-free 方法 ToDo，通过令牌下采样加速 Stable Diffusion 推理，以实现高分辨率图像的高效生成。

    

    注意力机制对于图像扩散模型至关重要，然而，它们的二次计算复杂性限制了我们可以在合理时间和内存限制内处理的图像大小。本文研究了在生成图像模型中密集注意力的重要性，这些模型通常包含冗余特征，使它们适合稀疏注意力机制。我们提出了一种新颖的无需训练的方法 ToDo，该方法依赖于关键和值令牌的令牌下采样，可将常见大小的 Stable Diffusion 推理加速至多达2倍，对于2048x2048等高分辨率，加速比可达4.5倍或更高。我们证明了我们的方法在平衡高效吞吐量和保真度方面优于先前的方法。

    arXiv:2402.13573v1 Announce Type: cross  Abstract: Attention mechanism has been crucial for image diffusion models, however, their quadratic computational complexity limits the sizes of images we can process within reasonable time and memory constraints. This paper investigates the importance of dense attention in generative image models, which often contain redundant features, making them suitable for sparser attention mechanisms. We propose a novel training-free method ToDo that relies on token downsampling of key and value tokens to accelerate Stable Diffusion inference by up to 2x for common sizes and up to 4.5x or more for high resolutions like 2048x2048. We demonstrate that our approach outperforms previous methods in balancing efficient throughput and fidelity.
    
[^45]: 论一种变种Looped Transformer的表达能力

    On the Expressive Power of a Variant of the Looped Transformer

    [https://arxiv.org/abs/2402.13572](https://arxiv.org/abs/2402.13572)

    设计了一种新型Transformer块AlgoFormer，相比标准Transformer和Looped Transformer，AlgoFormer在相同参数数量下能够实现更高的算法表达能力

    

    除了自然语言处理，在解决更广泛的应用程序（包括科学计算和计算机视觉）方面，Transformer展现出卓越的性能。先前的工作试图从表达能力和功能性角度解释，标准的Transformer能够执行一些算法。为了赋予Transformer算法能力，并受到最近提出的Looped Transformer的启发，我们设计了一种新颖的Transformer块，名为Algorithm Transformer（简称AlgoFormer）。与标准Transformer和纯粹的Looped Transformer相比，所提出的AlgoFormer在使用相同数量的参数时可以实现更高的算法表示表达能力。特别是，受人类设计的学习算法结构的启发，我们的Transformer块包括一个负责进行ta

    arXiv:2402.13572v1 Announce Type: cross  Abstract: Besides natural language processing, transformers exhibit extraordinary performance in solving broader applications, including scientific computing and computer vision. Previous works try to explain this from the expressive power and capability perspectives that standard transformers are capable of performing some algorithms. To empower transformers with algorithmic capabilities and motivated by the recently proposed looped transformer (Yang et al., 2024; Giannou et al., 2023), we design a novel transformer block, dubbed Algorithm Transformer (abbreviated as AlgoFormer). Compared with the standard transformer and vanilla looped transformer, the proposed AlgoFormer can achieve significantly higher expressiveness in algorithm representation when using the same number of parameters. In particular, inspired by the structure of human-designed learning algorithms, our transformer block consists of a pre-transformer that is responsible for ta
    
[^46]: 低资源条件下南亚语言的多语言共指解析

    Multilingual Coreference Resolution in Low-resource South Asian Languages

    [https://arxiv.org/abs/2402.13571](https://arxiv.org/abs/2402.13571)

    引入了一个用于31种南亚语言的多语言共指解析翻译数据集，通过利用现成工具进行训练和对齐，在低资源条件下实现了较好的共指解析模型性能提升。

    

    共指解析涉及识别在话语中指向同一现实实体的文本片段的任务。虽然这一任务在英语中得到了广泛研究，但在南亚语言中，公开可访问的共指解析资源和模型相对稀缺。我们利用现成的翻译和词对齐工具，在31种南亚语言中引入了一个用于多语言共指解析的翻译数据集（TransMuCoRes）。几乎所有预测的翻译都通过了合理性检查，75%的英语参考文献与其预测的翻译相对应。利用多语言编码器，我们训练了两种现成的共指解析模型，将TransMuCoRes与带有手动注释的印地语共指解析数据集拼接在一起。最佳表现模型在LEA F1和CoNLL F1上分别达到了64和68的分数。

    arXiv:2402.13571v1 Announce Type: cross  Abstract: Coreference resolution involves the task of identifying text spans within a discourse that pertain to the same real-world entity. While this task has been extensively explored in the English language, there has been a notable scarcity of publicly accessible resources and models for coreference resolution in South Asian languages. We introduce a Translated dataset for Multilingual Coreference Resolution (TransMuCoRes) in 31 South Asian languages using off-the-shelf tools for translation and word-alignment. Nearly all of the predicted translations successfully pass a sanity check, and 75% of English references align with their predicted translations. Using multilingual encoders, two off-the-shelf coreference resolution models were trained on a concatenation of TransMuCoRes and a Hindi coreference resolution dataset with manual annotations. The best performing model achieved a score of 64 and 68 for LEA F1 and CoNLL F1, respectively, on o
    
[^47]: Spot Check Equivalence：一个可解释的信息引出机制度量

    Spot Check Equivalence: an Interpretable Metric for Information Elicitation Mechanisms

    [https://arxiv.org/abs/2402.13567](https://arxiv.org/abs/2402.13567)

    提出了"点检查等价性"，为同行预测机制的效力提供了一个可解释的度量

    

    由于高质量数据对于AI系统如同氧气一般重要，有效地从众包工作者中引出信息已成为开发高性能机器学习算法的首要问题。两种普遍的范式，即点检查和同行预测，使得设计机制来评估和激励来自人类标注者的高质量数据成为可能。到目前为止，至少提出了三种指标来比较这些技术的性能。然而，不同的指标在不同背景下导致了分歧甚至矛盾的结果。本文将调和这些不同的故事，展示其中两个指标在某些背景下实际上是相同的，并解释第三个的分歧。此外，我们通过引入"点检查等价性"来统一这些不同的背景，为同行预测机制的有效性提供了一个可解释的度量。最后，我们提出...（未完）

    arXiv:2402.13567v1 Announce Type: cross  Abstract: Because high-quality data is like oxygen for AI systems, effectively eliciting information from crowdsourcing workers has become a first-order problem for developing high-performance machine learning algorithms. Two prevalent paradigms, spot-checking and peer prediction, enable the design of mechanisms to evaluate and incentivize high-quality data from human labelers. So far, at least three metrics have been proposed to compare the performances of these techniques [33, 8, 3]. However, different metrics lead to divergent and even contradictory results in various contexts. In this paper, we harmonize these divergent stories, showing that two of these metrics are actually the same within certain contexts and explain the divergence of the third. Moreover, we unify these different contexts by introducing \textit{Spot Check Equivalence}, which offers an interpretable metric for the effectiveness of a peer prediction mechanism. Finally, we pr
    
[^48]: 归纳图对齐提示：从谱角度弥合图预训练和归纳微调之间的差距

    Inductive Graph Alignment Prompt: Bridging the Gap between Graph Pre-training and Inductive Fine-tuning From Spectral Perspective

    [https://arxiv.org/abs/2402.13556](https://arxiv.org/abs/2402.13556)

    IGAP提出了一种新型的基于图提示的方法，用于将图预训练泛化到归纳场景，弥合了预训练图和微调图之间的差距。

    

    “图预训练和微调”范式通过捕捉下游任务无需手动标注的通用知识，显著改进了图神经网络(GNNs)。然而，由于在预训练和微调阶段之间的数据和任务巨大差距，模型性能仍然受限。受自然语言处理(NLP)中提示微调的启发，许多努力已经为在图领域中弥合差距做出了努力。但现有方法仅仅将微调任务的形式重新表述为预训练任务。在预训练图与微调图兼容的前提下，这些方法通常在转导设置中运行。为了将图预训练泛化到归纳场景，其中微调图可能与预训练图显著不同，我们提出了一种名为归纳图对齐提示(IGAP)的新型基于图提示的方法。首先，我们统

    arXiv:2402.13556v1 Announce Type: cross  Abstract: The "Graph pre-training and fine-tuning" paradigm has significantly improved Graph Neural Networks(GNNs) by capturing general knowledge without manual annotations for downstream tasks. However, due to the immense gap of data and tasks between the pre-training and fine-tuning stages, the model performance is still limited. Inspired by prompt fine-tuning in Natural Language Processing(NLP), many endeavors have been made to bridge the gap in graph domain. But existing methods simply reformulate the form of fine-tuning tasks to the pre-training ones. With the premise that the pre-training graphs are compatible with the fine-tuning ones, these methods typically operate in transductive setting. In order to generalize graph pre-training to inductive scenario where the fine-tuning graphs might significantly differ from pre-training ones, we propose a novel graph prompt based method called Inductive Graph Alignment Prompt(IGAP). Firstly, we uni
    
[^49]: LLM们是有效的谈判者吗？对LLM在谈判对话中多方面能力的系统评估

    Are LLMs Effective Negotiators? Systematic Evaluation of the Multifaceted Capabilities of LLMs in Negotiation Dialogues

    [https://arxiv.org/abs/2402.13550](https://arxiv.org/abs/2402.13550)

    本研究系统评估了LLMs在谈判对话中的多方面能力，揭示了它们在谈判研究中的潜力和局限。

    

    一次成功的谈判需要对谈话背景有深刻理解，具备推断对方动机的心理理论技能，以及战略推理和有效沟通，这使得自动化系统面临挑战。鉴于LLMs在各种自然语言处理任务中表现出色，本研究旨在探索LLMs如何推动谈判研究的不同方面，包括设计对话系统、提供教学反馈和扩大数据收集实践。为此，我们设计了一种方法来分析LLMs在各种对话情景中的多方面能力，涵盖典型谈判互动的所有时间阶段。我们的分析进一步证明了GPT-4在各种任务上的优越性，同时也揭示了LLMs在某些任务上仍然困难的细节。例如，这些模型与人类的相关性较差。

    arXiv:2402.13550v1 Announce Type: cross  Abstract: A successful negotiation demands a deep comprehension of the conversation context, Theory-of-Mind (ToM) skills to infer the partner's motives, as well as strategic reasoning and effective communication, making it challenging for automated systems. Given the remarkable performance of LLMs across a variety of NLP tasks, in this work, we aim to understand how LLMs can advance different aspects of negotiation research, ranging from designing dialogue systems to providing pedagogical feedback and scaling up data collection practices. To this end, we devise a methodology to analyze the multifaceted capabilities of LLMs across diverse dialogue scenarios covering all the time stages of a typical negotiation interaction. Our analysis adds to the increasing evidence for the superiority of GPT-4 across various tasks while also providing insights into specific tasks that remain difficult for LLMs. For instance, the models correlate poorly with hum
    
[^50]: ARL2: 通过自导自适应相关性标记将检索器与黑盒大型语言模型对齐

    ARL2: Aligning Retrievers for Black-box Large Language Models via Self-guided Adaptive Relevance Labeling

    [https://arxiv.org/abs/2402.13542](https://arxiv.org/abs/2402.13542)

    ARL2提出了一种检索器学习技术，利用LLMs作为标注者，并采用自适应自训练策略，能够有效减少注释成本，并在NQ和MMLU上取得了5.4%和4.6%的准确度提升。

    

    arXiv:2402.13542v1 公告类型: 交叉 摘要: 检索增强生成通过整合外部知识源的相关信息改进大型语言模型（LLMs），使LLMs能够适应特定领域，并减轻知识密集任务中的幻觉。然而，由于其分开的训练过程和LLMs的黑盒特性，现有的检索器通常与LLMs不匹配。为解决这一挑战，我们提出了ARL2，一种利用LLMs作为标注者的检索器学习技术。ARL2利用LLMs注释和评分相关证据，从而能够从强大的LLM监督中学习检索器。此外，ARL2使用自适应自训练策略来策划高质量和多样性相关性数据，可以有效降低标注成本。大量实验表明ARL2的有效性，与最先进方法相比，在NQ上提高了5.4%的准确率，在MMLU上提高了4.6%。

    arXiv:2402.13542v1 Announce Type: cross  Abstract: Retrieval-augmented generation enhances large language models (LLMs) by incorporating relevant information from external knowledge sources. This enables LLMs to adapt to specific domains and mitigate hallucinations in knowledge-intensive tasks. However, existing retrievers are often misaligned with LLMs due to their separate training processes and the black-box nature of LLMs. To address this challenge, we propose ARL2, a retriever learning technique that harnesses LLMs as labelers. ARL2 leverages LLMs to annotate and score relevant evidence, enabling learning the retriever from robust LLM supervision. Furthermore, ARL2 uses an adaptive self-training strategy for curating high-quality and diverse relevance data, which can effectively reduce the annotation cost. Extensive experiments demonstrate the effectiveness of ARL2, achieving accuracy improvements of 5.4% on NQ and 4.6% on MMLU compared to the state-of-the-art methods. Additionall
    
[^51]: 探索每微比特语义图像压缩的极限

    Exploring the Limits of Semantic Image Compression at Micro-bits per Pixel

    [https://arxiv.org/abs/2402.13536](https://arxiv.org/abs/2402.13536)

    本文使用GPT-4V和DALL-E3来探索图像压缩的质量和压缩界限，推动语义压缩降至每像素100微比特，并通过迭代反射过程改善解码图像。

    

    传统方法，如JPEG，通过处理结构信息（如像素值或频率内容）来进行图像压缩。在标准图像尺寸下，这些方法在每像素约一比特（bpp）及以上的比特率上是有效的。相比之下，基于文本的语义压缩直接使用自然语言存储概念及其关系，这些关系已与人类一起演变，以有效表示这些突出的概念。通过忽略位置、大小和方向等结构信息，这些方法可以在极低比特率下运行。本文利用OpenAI的GPT-4V和DALL-E3探索图像压缩的质量-压缩前沿，并确定当前技术的限制。通过引入迭代反射过程来改善解码图像，我们将语义压缩推至每像素100微比特（比JPEG小$10,000\times$）。我们进一步假设

    arXiv:2402.13536v1 Announce Type: cross  Abstract: Traditional methods, such as JPEG, perform image compression by operating on structural information, such as pixel values or frequency content. These methods are effective to bitrates around one bit per pixel (bpp) and higher at standard image sizes. In contrast, text-based semantic compression directly stores concepts and their relationships using natural language, which has evolved with humans to efficiently represent these salient concepts. These methods can operate at extremely low bitrates by disregarding structural information like location, size, and orientation. In this work, we use GPT-4V and DALL-E3 from OpenAI to explore the quality-compression frontier for image compression and identify the limitations of current technology. We push semantic compression as low as 100 $\mu$bpp (up to $10,000\times$ smaller than JPEG) by introducing an iterative reflection process to improve the decoded image. We further hypothesize this 100 
    
[^52]: 一种有效融合异构知识的课程学习方法用于序列标注

    An Effective Incorporating Heterogeneous Knowledge Curriculum Learning for Sequence Labeling

    [https://arxiv.org/abs/2402.13534](https://arxiv.org/abs/2402.13534)

    提出了一个专为序列标注任务设计的两阶段课程学习（TCL）框架，逐渐引入数据实例从简单到困难，旨在提高性能和训练速度，并且对六个中文分词和词性标注数据集进行了广泛实验，证明了模型的有效性。

    

    序列标注模型常常受益于整合外部知识。然而，这一做法引入了数据异构性，并通过额外模块使模型变得复杂，导致训练高性能模型的成本增加。为了应对这一挑战，我们提出了一个专为序列标注任务设计的两阶段课程学习（TCL）框架。TCL框架通过逐渐引入从简单到困难的数据实例来增强训练，旨在提高性能和训练速度。此外，我们还探索了用于评估序列标注任务难度级别的不同指标。通过在六个中文分词（CWS）和词性标注（POS）数据集上进行大量实验，我们展示了我们的模型在提高序列标注模型性能方面的有效性。此外，我们的分析表明TCL加速了训练并缓解了

    arXiv:2402.13534v1 Announce Type: cross  Abstract: Sequence labeling models often benefit from incorporating external knowledge. However, this practice introduces data heterogeneity and complicates the model with additional modules, leading to increased expenses for training a high-performing model. To address this challenge, we propose a two-stage curriculum learning (TCL) framework specifically designed for sequence labeling tasks. The TCL framework enhances training by gradually introducing data instances from easy to hard, aiming to improve both performance and training speed. Furthermore, we explore different metrics for assessing the difficulty levels of sequence labeling tasks. Through extensive experimentation on six Chinese word segmentation (CWS) and Part-of-speech tagging (POS) datasets, we demonstrate the effectiveness of our model in enhancing the performance of sequence labeling models. Additionally, our analysis indicates that TCL accelerates training and alleviates the 
    
[^53]: FinGPT-HPC: 高性能计算下用于金融应用的高效预训练和微调大型语言模型

    FinGPT-HPC: Efficient Pretraining and Finetuning Large Language Models for Financial Applications with High-Performance Computing

    [https://arxiv.org/abs/2402.13533](https://arxiv.org/abs/2402.13533)

    该论文提出了一种基于高性能GPU的方法，利用低秩结构来高效地预训练和微调大型语言模型，解决了线性层冗余性、GPU内存占用和分布式训练中GPU利用率不足的挑战

    

    大型语言模型(LLMs)的计算密集性很高。计算工作量和内存占用量随维度(层宽度)的增加呈二次增长。大多数LLM参数来自变压器结构的线性层，具有高度冗余性。这些线性层贡献了超过80%的计算工作量和99%的模型大小。为了高效地预训练和微调LLMs，需要解决三个主要挑战：1) 减少线性层的冗余性；2) 减少GPU内存占用；3) 在使用分布式训练时提高GPU利用率。之前的方法，如LoRA和QLoRA，利用低秩矩阵和量化来分别减少可训练参数的数量和模型大小。然而， resulting model 仍然消耗大量GPU内存。在本文中，我们提出了基于高性能GPU的方法，利用低秩结构来预训练和微调。

    arXiv:2402.13533v1 Announce Type: cross  Abstract: Large language models (LLMs) are computationally intensive. The computation workload and the memory footprint grow quadratically with the dimension (layer width). Most of LLMs' parameters come from the linear layers of the transformer structure and are highly redundant. These linear layers contribute more than 80% of the computation workload and 99% of the model size. To pretrain and finetune LLMs efficiently, there are three major challenges to address: 1) reducing redundancy of the linear layers; 2) reducing GPU memory footprint; 3) improving GPU utilization when using distributed training. Prior methods, such as LoRA and QLoRA, utilized low-rank matrices and quantization to reduce the number of trainable parameters and model size, respectively. However, the resulting model still consumes a large amount of GPU memory. In this paper, we present high-performance GPU-based methods that exploit low-rank structures to pretrain and finetun
    
[^54]: 面向代码生成的测试驱动开发

    Test-Driven Development for Code Generation

    [https://arxiv.org/abs/2402.13521](https://arxiv.org/abs/2402.13521)

    本文旨在研究通过测试驱动开发（TDD）方法，将问题描述和测试作为输入是否优于仅将问题描述作为输入，以提高基于大型语言模型（LLM）的代码生成效果。

    

    arXiv:2402.13521v1 公告类型:交叉摘要:大型语言模型（LLMs）如GPT4已经展示出了从问题描述中生成代码片段的能力。传统上，人类编写软件的方法类似于从问题描述或需求中编写代码。然而，过去有几项研究已经显示了测试驱动开发（TDD）的价值，即在编写功能代码之前，人类根据问题描述编写测试。在基于LLM的代码生成环境中，TDD的一个明显好处是开发人员可以确切知道生成的代码是否通过了所有给定的测试。因此，在本文中，我们希望通过实证评估假设：将问题描述和测试作为GPT4的输入要优于仅将问题描述作为输入。为了测试我们的假设，我们建立了一个名为TGen的框架。在MBPP、HumanEval和CodeChef数据集上的实验中，

    arXiv:2402.13521v1 Announce Type: cross  Abstract: Large language models (LLMs) like GPT4, have shown proficiency in generating code snippets from problem statements. Traditionally software development by humans followed a similar methodology of writing code from problem statements or requirements. However, in the past, there have been several studies that have shown the value of test-driven development (TDD) where humans write tests based on problem statements before the code for the functionality is written. In the context of LLM-based code generation, one obvious benefit of TDD is that the developer then knows for sure if the generated code has passed all the given tests or not. Therefore, in this paper, we want to empirically evaluate the hypothesis: giving the problem statements and tests as input to GPT4 is better than just giving the problem statement as input. To test our hypothesis, we build a framework TGen. In our experiments on the MBPP, HumanEval and CodeChef datasets, we 
    
[^55]: 大型语言模型逆向翻译防御对抗攻击

    Round Trip Translation Defence against Large Language Model Jailbreaking Attacks

    [https://arxiv.org/abs/2402.13517](https://arxiv.org/abs/2402.13517)

    往返翻译（RTT）方法是第一个专门设计用于抵御大型语言模型（LLMs）社交工程攻击的算法，成功地减少了多种攻击形式的成功率。

    

    大型语言模型（LLMs）容易受到社交工程攻击，这些攻击对人类具有可解释性，但需要LLMs具有高水平的理解能力才能抵抗。现有的防御措施最多只能缓解这些攻击的不到一半。为解决这一问题，我们提出了往返翻译（RTT）方法，这是第一个专门设计用于抵御LLMs社交工程攻击的算法。RTT会改写对抗性提示并推广表达的思想，使LLMs更容易检测出诱发有害行为。这种方法灵活、轻量且可转移至不同的LLMs。我们的防御成功地缓解了超过70%的Prompt Automatic Iterative Refinement (PAIR)攻击，这是目前我们所知最有效的防御。我们也是首次尝试缓解MathsAttack，并将其攻击成功率降低了近40%。我们的代码已公开发布。

    arXiv:2402.13517v1 Announce Type: cross  Abstract: Large language models (LLMs) are susceptible to social-engineered attacks that are human-interpretable but require a high level of comprehension for LLMs to counteract. Existing defensive measures can only mitigate less than half of these attacks at most. To address this issue, we propose the Round Trip Translation (RTT) method, the first algorithm specifically designed to defend against social-engineered attacks on LLMs. RTT paraphrases the adversarial prompt and generalizes the idea conveyed, making it easier for LLMs to detect induced harmful behavior. This method is versatile, lightweight, and transferrable to different LLMs. Our defense successfully mitigated over 70% of Prompt Automatic Iterative Refinement (PAIR) attacks, which is currently the most effective defense to the best of our knowledge. We are also the first to attempt mitigating the MathsAttack and reduced its attack success rate by almost 40%. Our code is publicly av
    
[^56]: ProSparse: 引入和增强大型语言模型内部激活稀疏性

    ProSparse: Introducing and Enhancing Intrinsic Activation Sparsity within Large Language Models

    [https://arxiv.org/abs/2402.13516](https://arxiv.org/abs/2402.13516)

    本文介绍了一种名为"ProSparse"的有效稀疏化方法，以推动大型语言模型实现更高的激活稀疏性而不降低模型性能

    

    Activation sparsity指的是激活输出中存在许多弱贡献元素。作为使用ReLU激活函数的模型的普遍属性，已被证明是提高模型推理效率的一种有前途的范例。然而，大多数大型语言模型（LLMs）采用了没有内在激活稀疏性的激活函数（例如GELU和Swish）。一些最近的努力尝试引入ReLU或其变体作为替代激活函数，以帮助LLMs实现激活稀疏性和推理加速，但很少能同时获得高稀疏度和可比较的模型性能。本文介绍了一种名为"ProSparse"的有效稀疏化方法，以推动LLMs实现更高的激活稀疏性而不降低模型性能。具体来说，将LLMs的激活函数替换为ReLU后，ProSparse采用渐进稀疏正则化

    arXiv:2402.13516v1 Announce Type: cross  Abstract: Activation sparsity refers to the existence of considerable weakly-contributed elements among activation outputs. As a prevalent property of the models using the ReLU activation function, it has been proven a promising paradigm to boost model inference efficiency. Nevertheless, most large language models (LLMs) adopt activation functions without intrinsic activation sparsity (e.g., GELU and Swish). Some recent efforts have explored introducing ReLU or its variants as the substitutive activation function to help LLMs achieve activation sparsity and inference acceleration, but few can simultaneously obtain high sparsity and comparable model performance. This paper introduces an effective sparsification method named "ProSparse" to push LLMs for higher activation sparsity without decreasing model performance. Specifically, after substituting the activation function of LLMs with ReLU, ProSparse adopts progressive sparsity regularization wit
    
[^57]: 自我分而治之：何时检索、何时生成？面向组合未知问题的自我分而治之算法

    Self-DC: When to retrieve and When to generate? Self Divide-and-Conquer for Compositional Unknown Questions

    [https://arxiv.org/abs/2402.13514](https://arxiv.org/abs/2402.13514)

    提出了面向组合未知问题的自我分而治之算法，引入了第一个组合未知问题问答数据集（CuQA），通过自适应调用不同方法实现更好的性能和效率。

    

    检索-然后阅读和生成-然后阅读是处理开放域问答中未知和已知问题的两种典型解决方案，前者检索必要的外部知识，后者则促使大型语言模型生成参数中编码的内部已知知识。然而，过去很少有作品考虑到组合未知问题，这些问题由几个已知或未知的子问题组成。因此，简单的二元分类（已知或未知）变得次优和低效，因为它会对每个组合未知问题过度调用外部检索。为此，我们提出了第一个组合未知问题问答数据集（CuQA），并引入了一个自我分而治之（Self-DC）框架，使大型语言模型能够自适应地调用不同的方法，从而提高性能和效率。实验结果在两个数据集（CuQA和FreshQA）上表明……

    arXiv:2402.13514v1 Announce Type: cross  Abstract: Retrieve-then-read and generate-then-read are two typical solutions to handle unknown and known questions in open-domain question-answering, while the former retrieves necessary external knowledge and the later prompt the large language models to generate internal known knowledge encoded in the parameters. However, few of previous works consider the compositional unknown questions, which consist of several known or unknown sub-questions. Thus, simple binary classification (known or unknown) becomes sub-optimal and inefficient since it will call external retrieval excessively for each compositional unknown question. To this end, we propose the first Compositional unknown Question-Answering dataset (CuQA), and introduce a Self Divide-and-Conquer (Self-DC) framework to empower LLMs to adaptively call different methods on-demand, resulting in better performance and efficiency. Experimental results on two datasets (CuQA and FreshQA) demonst
    
[^58]: 从自注意力到马尔可夫模型：揭示生成Transformer的动态

    From Self-Attention to Markov Models: Unveiling the Dynamics of Generative Transformers

    [https://arxiv.org/abs/2402.13512](https://arxiv.org/abs/2402.13512)

    本文研究了从自注意力模型到马尔可夫模型的转变，揭示了生成Transformer动态的机理和相关条件，为一致估计提供了保证，并在IID样本下建立了样本复杂性保证。

    

    现代语言模型依赖Transformer架构和注意力机制来进行语言理解和文本生成。本文研究了从一组提示和与模型采样的关联输出数据中学习一个单层自注意模型。我们首先建立了自注意机制和马尔可夫模型之间的精确映射：将提示输入模型会根据上下文条件的马尔可夫链（CCMC）对输出标记进行采样，该链加权了基本马尔可夫链的转移矩阵。此外，引入位置编码导致了转移概率的位置相关缩放。基于这种形式主义，我们为提示分布开发了可辨识性/覆盖条件，确保一致估计，并在IID样本下建立了样本复杂性保证。最后，我们研究了从单个输出轨迹生成中学习的问题。

    arXiv:2402.13512v1 Announce Type: cross  Abstract: Modern language models rely on the transformer architecture and attention mechanism to perform language understanding and text generation. In this work, we study learning a 1-layer self-attention model from a set of prompts and associated output data sampled from the model. We first establish a precise mapping between the self-attention mechanism and Markov models: Inputting a prompt to the model samples the output token according to a context-conditioned Markov chain (CCMC) which weights the transition matrix of a base Markov chain. Additionally, incorporating positional encoding results in position-dependent scaling of the transition probabilities. Building on this formalism, we develop identifiability/coverage conditions for the prompt distribution that guarantee consistent estimation and establish sample complexity guarantees under IID samples. Finally, we study the problem of learning from a single output trajectory generated from
    
[^59]: 用于低资源领域任务的检索增强数据增强

    Retrieval-Augmented Data Augmentation for Low-Resource Domain Tasks

    [https://arxiv.org/abs/2402.13482](https://arxiv.org/abs/2402.13482)

    提出了一种用于低资源领域任务的新方法，通过结合来自其他数据集的相关示例来增强训练数据，以解决在低资源环境中生成样本不够理想和缺乏多样性的挑战

    

    尽管最近语言模型在多样任务上取得了巨大成功，但在训练数据有限的低资源环境中，它们的性能会严重下降。许多现有作品通过从训练数据生成合成数据，然后在其上训练模型来解决这个问题，最近使用大型语言模型（LLM）进行。然而，在低资源环境中，用于数据增强的种子数据样本数量非常少，这使得生成的样本不够理想且缺乏多样性。为了解决这一挑战，我们提出了一种新颖的方法，通过将其他数据集中丰富的示例与给定的训练数据结合起来，来增强训练数据。具体来说，我们首先通过与给定种子数据相似性基于其他数据集检索相关实例，例如它们的输入-输出对或上下文，然后提示LLM使用上下文信息生成新样本。

    arXiv:2402.13482v1 Announce Type: cross  Abstract: Despite large successes of recent language models on diverse tasks, they suffer from severe performance degeneration in low-resource settings with limited training data available. Many existing works tackle this problem by generating synthetic data from the training data and then training models on them, recently using Large Language Models (LLMs). However, in low-resource settings, the amount of seed data samples to use for data augmentation is very small, which makes generated samples suboptimal and less diverse. To tackle this challenge, we propose a novel method that augments training data by incorporating a wealth of examples from other datasets, along with the given training data. Specifically, we first retrieve the relevant instances from other datasets, such as their input-output pairs or contexts, based on their similarities with the given seed data, and then prompt LLMs to generate new samples with the contextual information 
    
[^60]: 用多智能体强化学习在高度互动自动驾驶场景中学习建模多样的驾驶行为

    Learning to Model Diverse Driving Behaviors in Highly Interactive Autonomous Driving Scenarios with Multi-Agent Reinforcement Learning

    [https://arxiv.org/abs/2402.13481](https://arxiv.org/abs/2402.13481)

    引入了Personality Modeling Network (PeMN)来模拟高度互动场景中各种驾驶交互，通过训练背景交通流改善自车性能和泛化能力

    

    通过多智能体强化学习（MARL）训练的自动驾驶车辆在许多驾驶场景中展示出了令人印象深刻的结果。然而，在面对多样的驾驶风格和个性，特别是在高度互动的情况下，这些训练策略的性能可能会受到影响。为了解决这个问题，我们引入了Personality Modeling Network（PeMN），其中包括一个合作值函数和个性参数，用来建模高度互动场景中的各种交互。PeMN还可以训练具有不同行为的背景交通流，从而提高自车的性能和泛化能力。我们的广泛实验研究融入了不同的个性参数。

    arXiv:2402.13481v1 Announce Type: cross  Abstract: Autonomous vehicles trained through Multi-Agent Reinforcement Learning (MARL) have shown impressive results in many driving scenarios. However, the performance of these trained policies can be impacted when faced with diverse driving styles and personalities, particularly in highly interactive situations. This is because conventional MARL algorithms usually operate under the assumption of fully cooperative behavior among all agents and focus on maximizing team rewards during training. To address this issue, we introduce the Personality Modeling Network (PeMN), which includes a cooperation value function and personality parameters to model the varied interactions in high-interactive scenarios. The PeMN also enables the training of a background traffic flow with diverse behaviors, thereby improving the performance and generalization of the ego vehicle. Our extensive experimental studies, which incorporate different personality parameters
    
[^61]: 多尺度时空变压器的失衡纵向学习，用于从不规则时间序列图像中预测青光眼

    Multi-scale Spatio-temporal Transformer-based Imbalanced Longitudinal Learning for Glaucoma Forecasting from Irregular Time Series Images

    [https://arxiv.org/abs/2402.13475](https://arxiv.org/abs/2402.13475)

    介绍了一种基于Multi-scale Spatio-temporal Transformer网络的失衡纵向学习方法，针对青光眼预测中的不规则时间序列图像，能有效学习代表性语义信息.

    

    青光眼是导致进行性视神经纤维损伤和不可逆盲目的主要眼病之一，影响着数百万人。青光眼预测是早期筛查和干预潜在患者的良好解决方案，有助于防止疾病的进一步恶化。它利用眼睛的一系列历史底片图像，并预测未来青光眼发生的可能性。然而，不规则采样的性质和失衡的类分布是疾病预测方法开发中的两个挑战。为此，我们引入了基于变压器架构的适用于顺序图像输入的多尺度时空变压器网络（MST-former），可以有效地从顺序图像中在时间和空间维度上学习代表性语义信息。具体地，我们采用多尺度结构来提取

    arXiv:2402.13475v1 Announce Type: cross  Abstract: Glaucoma is one of the major eye diseases that leads to progressive optic nerve fiber damage and irreversible blindness, afflicting millions of individuals. Glaucoma forecast is a good solution to early screening and intervention of potential patients, which is helpful to prevent further deterioration of the disease. It leverages a series of historical fundus images of an eye and forecasts the likelihood of glaucoma occurrence in the future. However, the irregular sampling nature and the imbalanced class distribution are two challenges in the development of disease forecasting approaches. To this end, we introduce the Multi-scale Spatio-temporal Transformer Network (MST-former) based on the transformer architecture tailored for sequential image inputs, which can effectively learn representative semantic information from sequential images on both temporal and spatial dimensions. Specifically, we employ a multi-scale structure to extract
    
[^62]: RefuteBench：评估用于大型语言模型的反驳指令遵循

    RefuteBench: Evaluating Refuting Instruction-Following for Large Language Models

    [https://arxiv.org/abs/2402.13463](https://arxiv.org/abs/2402.13463)

    本文提出了一个名为RefuteBench的基准测试，旨在评估大型语言模型对反驳指令的遵循能力，发现LLMs倾向于固执于其内部知识而无法遵从用户反馈。

    

    大型语言模型（LLMs）的应用范围日益扩大。在实际使用中，用户可能根据模型的输出提供反馈，希望得到一个可以根据他们的反馈完成响应的响应模型。然而，模型能否恰当地响应用户的反驳反馈并始终执行下去尚未得到彻底分析。基于这一问题，本文提出了一个全面的基准测试，RefuteBench，涵盖了诸如问答、机器翻译和电子邮件撰写等任务。评估旨在评估模型是否能够积极接受反驳指令形式的反馈，并是否能够在对话中始终遵循用户需求。我们对众多LLMs进行了评估，并发现LLMs倾向固执，即倾向于其内部知识，经常未能遵守用户反馈。

    arXiv:2402.13463v1 Announce Type: cross  Abstract: The application scope of large language models (LLMs) is increasingly expanding. In practical use, users might provide feedback based on the model's output, hoping for a responsive model that can complete responses according to their feedback. Whether the model can appropriately respond to users' refuting feedback and consistently follow through with execution has not been thoroughly analyzed. In light of this, this paper proposes a comprehensive benchmark, RefuteBench, covering tasks such as question answering, machine translation, and email writing. The evaluation aims to assess whether models can positively accept feedback in form of refuting instructions and whether they can consistently adhere to user demands throughout the conversation. We conduct evaluations on numerous LLMs and find that LLMs are stubborn, i.e. exhibit inclination to their internal knowledge, often failing to comply with user feedback. Additionally, as the leng
    
[^63]: 模型编辑在社交去偏见中的潜力与挑战

    Potential and Challenges of Model Editing for Social Debiasing

    [https://arxiv.org/abs/2402.13462](https://arxiv.org/abs/2402.13462)

    模型编辑方法在社交去偏见中具有潜力，但也面临挑战，尤其是在支持不同偏见类型和理解编辑方法应用于去偏见过程中的利弊方面。

    

    在大量语料库上训练的大语言模型（LLMs）不可避免地存在刻板印象偏见。通过微调来减轻这些偏见可能既昂贵又需要大量数据。模型编辑方法专注于以事后方式修改LLMs，对于解决去偏见问题具有巨大潜力。然而，缺乏支持各种偏见类型，并了解应用编辑方法于去偏见过程中的利弊的综合研究。为填补这一差距，我们将社交去偏见仔细构建为一个编辑问题，并在刻板印象去偏见上对七种现有的模型编辑算法进行基准测试，即去偏见编辑。我们在三种情景下的研究结果展示了去偏见编辑的潜力与挑战：（1）现有的模型编辑方法可以有效保留知识并减轻偏见，同时也揭示了去偏见效果从编辑到应用的一般化过程。

    arXiv:2402.13462v1 Announce Type: cross  Abstract: Large language models (LLMs) trained on vast corpora suffer from inevitable stereotype biases. Mitigating these biases with fine-tuning could be both costly and data-hungry. Model editing methods, which focus on modifying LLMs in a post-hoc manner, are of great potential to address debiasing. However, it lacks a comprehensive study that facilitates both internal and external model editing methods, supports various bias types, as well as understands the pros and cons of applying editing methods to stereotypical debiasing. To mitigate this gap, we carefully formulate social debiasing into an editing problem and benchmark seven existing model editing algorithms on stereotypical debiasing, i.e., debias editing. Our findings in three scenarios reveal both the potential and challenges of debias editing: (1) Existing model editing methods can effectively preserve knowledge and mitigate biases, while the generalization of debias effect from ed
    
[^64]: LLM越狱攻击与防御技术—一项全面研究

    LLM Jailbreak Attack versus Defense Techniques -- A Comprehensive Study

    [https://arxiv.org/abs/2402.13457](https://arxiv.org/abs/2402.13457)

    本研究对LLM模型的越狱攻击和防御技术进行了全面研究，揭示了现有攻击和防御技术的有效性。

    

    大型语言模型(LLMs)越来越成为产生具有潜在社会影响内容的核心。值得注意的是，这些模型展示了生成可能被视为有害的内容的能力。为了减轻这些风险，研究人员采用了安全训练技术，以使模型输出与社会价值观保持一致，以遏制对恶意内容的生成。然而，“越狱”现象，即精心制作的提示引发模型产生有害回应的情况，仍然是一个重要挑战。本研究对现有关于越狱LLMs及其防御技术的研究进行了全面分析。我们对三种不同语言模型的九种攻击技术和七种防御技术进行了细致调查：Vicuna、LLama和GPT-3.5 Turbo。我们旨在评估这些攻击和防御技术的有效性。我们的研究结果表明，现有的白盒攻击u

    arXiv:2402.13457v1 Announce Type: cross  Abstract: Large Language Models (LLMS) have increasingly become central to generating content with potential societal impacts. Notably, these models have demonstrated capabilities for generating content that could be deemed harmful. To mitigate these risks, researchers have adopted safety training techniques to align model outputs with societal values to curb the generation of malicious content. However, the phenomenon of "jailbreaking", where carefully crafted prompts elicit harmful responses from models, persists as a significant challenge. This research conducts a comprehensive analysis of existing studies on jailbreaking LLMs and their defense techniques. We meticulously investigate nine attack techniques and seven defense techniques applied across three distinct language models: Vicuna, LLama, and GPT-3.5 Turbo. We aim to evaluate the effectiveness of these attack and defense techniques. Our findings reveal that existing white-box attacks u
    
[^65]: ED-Copilot: 使用语言模型诊断辅助减少急诊科等待时间

    ED-Copilot: Reduce Emergency Department Wait Time with Language Model Diagnostic Assistance

    [https://arxiv.org/abs/2402.13448](https://arxiv.org/abs/2402.13448)

    本研究提出了一种在急诊科中减少等待时间的诊断辅助方法，利用人工智能系统帮助医生进行快速准确的诊断，并开发了ED-Copilot系统来推荐实验室检测并进行诊断预测。

    

    在急诊科（ED）中，患者在诊断前需要进行分诊和多种实验室检测。这个过程耗时，导致急诊科拥挤，显著影响患者死亡率、医疗错误、人员枯竭等。本研究提出了一种（时间）成本有效的诊断辅助方法，探索人工智能系统在协助急诊科临床医生进行高效准确诊断方面的潜力。使用公开可获得的患者数据，我们与急诊科临床医生合作策划了MIMIC-ED-Assist，这是一个衡量人工智能系统在建议最大程度减少急诊等待时间的实验室检测，并在正确预测诸如死亡之类关键结果方面的能力的基准。我们开发了ED-Copilot，它依次建议患者特定的实验室检测并进行诊断预测。ED-Copilot使用预训练的生物医学语言模型对患者信息进行编码并进行增强学习。

    arXiv:2402.13448v1 Announce Type: cross  Abstract: In the emergency department (ED), patients undergo triage and multiple laboratory tests before diagnosis. This process is time-consuming, and causes ED crowding which significantly impacts patient mortality, medical errors, staff burnout, etc. This work proposes (time) cost-effective diagnostic assistance that explores the potential of artificial intelligence (AI) systems in assisting ED clinicians to make time-efficient and accurate diagnoses. Using publicly available patient data, we collaborate with ED clinicians to curate MIMIC-ED-Assist, a benchmark that measures the ability of AI systems in suggesting laboratory tests that minimize ED wait times, while correctly predicting critical outcomes such as death. We develop ED-Copilot which sequentially suggests patient-specific laboratory tests and makes diagnostic predictions. ED-Copilot uses a pre-trained bio-medical language model to encode patient information and reinforcement learn
    
[^66]: 一种神经符号化方法用于多智能体强化学习，实现可解释性和概率决策

    A Neuro-Symbolic Approach to Multi-Agent RL for Interpretability and Probabilistic Decision Making

    [https://arxiv.org/abs/2402.13440](https://arxiv.org/abs/2402.13440)

    提出了一种神经符号化方法，通过神经符号逻辑神经网络（LNN）框架和概率逻辑神经网络（PLNN）框架，在多智能体强化学习中实现可解释的决策制定和处理不确定性。

    

    多智能体强化学习（MARL）非常适合在优化系统性能的实时决策中，其中多个智能体共存并竞争共享资源。然而，将常见的基于深度学习的MARL解决方案应用于真实世界问题存在解释性、样本效率、部分可观测性等问题。为了解决这些挑战，我们提出了一种事件驱动的形式化方法，决策由使用神经符号方法的分布式合作MARL智能体处理。最近引入的神经符号逻辑神经网络（LNN）框架作为RL的函数逼近器，训练一个基于规则的策略，通过结构构建既逻辑又可解释。为了在不确定性和部分可观测性下实现决策制定，我们开发了一种新颖的概率神经符号框架，概率逻辑神经网络（PLNN），结合了能力

    arXiv:2402.13440v1 Announce Type: new  Abstract: Multi-agent reinforcement learning (MARL) is well-suited for runtime decision-making in optimizing the performance of systems where multiple agents coexist and compete for shared resources. However, applying common deep learning-based MARL solutions to real-world problems suffers from issues of interpretability, sample efficiency, partial observability, etc. To address these challenges, we present an event-driven formulation, where decision-making is handled by distributed co-operative MARL agents using neuro-symbolic methods. The recently introduced neuro-symbolic Logical Neural Networks (LNN) framework serves as a function approximator for the RL, to train a rules-based policy that is both logical and interpretable by construction. To enable decision-making under uncertainty and partial observability, we developed a novel probabilistic neuro-symbolic framework, Probabilistic Logical Neural Networks (PLNN), which combines the capabiliti
    
[^67]: DrBenchmark: 一个针对法语生物医学领域的大型语言理解评估基准

    DrBenchmark: A Large Language Understanding Evaluation Benchmark for French Biomedical Domain

    [https://arxiv.org/abs/2402.13432](https://arxiv.org/abs/2402.13432)

    DrBenchmark提出了一个针对法语生物医学领域的大型语言理解评估基准，旨在弥补对最新法语生物医学模型评估的不足，并考虑到法语的独特敏感性。

    

    生物医学领域在自然语言处理（NLP）领域引起了极大的兴趣，随着预训练语言模型（PLMs）的实质性进展。然而，由于不同模型之间评估协议的变化，比较这些模型已经变得具有挑战性。一个公平的解决方案是将不同的下游任务聚合到一个基准中，允许从各种角度评估PLMs的内在品质。尽管这一倡议仍然局限于少数语言，特别是英语和中文，但已经在生物医学领域展开。这一限制阻碍了对最新的法语生物医学模型的评价，因为它们要么在少量任务上进行评估，而且使用的协议不够标准化，要么使用一般的下游任务进行评估。为弥补这一研究差距，并考虑到法语的独特敏感性，我们提出了首个公开可用的法语生物医学基准

    arXiv:2402.13432v1 Announce Type: cross  Abstract: The biomedical domain has sparked a significant interest in the field of Natural Language Processing (NLP), which has seen substantial advancements with pre-trained language models (PLMs). However, comparing these models has proven challenging due to variations in evaluation protocols across different models. A fair solution is to aggregate diverse downstream tasks into a benchmark, allowing for the assessment of intrinsic PLMs qualities from various perspectives. Although still limited to few languages, this initiative has been undertaken in the biomedical field, notably English and Chinese. This limitation hampers the evaluation of the latest French biomedical models, as they are either assessed on a minimal number of tasks with non-standardized protocols or evaluated using general downstream tasks. To bridge this research gap and account for the unique sensitivities of French, we present the first-ever publicly available French biom
    
[^68]: LinkSAGE: 使用图神经网络优化工作匹配

    LinkSAGE: Optimizing Job Matching Using Graph Neural Networks

    [https://arxiv.org/abs/2402.13430](https://arxiv.org/abs/2402.13430)

    LinkSAGE是一个采用图神经网络的优化工作匹配框架，通过独特的训练和服务方法，实现了在庞大而复杂的领英专业网络中进行个性化工作匹配。

    

    我们提出了LinkSAGE，一个创新性框架，将图神经网络（GNNs）集成到大规模个性化工作匹配系统中，旨在应对领英庞大专业网络的复杂动态。我们的方法利用了一个全新的工作市场图，这是工业界规模最大、最复杂的图之一，拥有数十亿个节点和边。这个图不仅广泛，而且详细丰富，包含会员和工作节点以及关键属性，从而创建了一个广阔而交织的网络。LinkSAGE的一个关键创新在于其训练和服务方法，它有效地将感知图学习与编码器-解码器GNN模型相结合，训练GNN模型与现有深度神经网络（DNN）模型的训练分离，消除了频繁重新训练GNN的需要，同时保持图信号最新。

    arXiv:2402.13430v1 Announce Type: cross  Abstract: We present LinkSAGE, an innovative framework that integrates Graph Neural Networks (GNNs) into large-scale personalized job matching systems, designed to address the complex dynamics of LinkedIns extensive professional network. Our approach capitalizes on a novel job marketplace graph, the largest and most intricate of its kind in industry, with billions of nodes and edges. This graph is not merely extensive but also richly detailed, encompassing member and job nodes along with key attributes, thus creating an expansive and interwoven network. A key innovation in LinkSAGE is its training and serving methodology, which effectively combines inductive graph learning on a heterogeneous, evolving graph with an encoder-decoder GNN model. This methodology decouples the training of the GNN model from that of existing Deep Neural Nets (DNN) models, eliminating the need for frequent GNN retraining while maintaining up-to-date graph signals in ne
    
[^69]: 定量因果关系、因果引导的科学发现和因果机器学习

    Quantitative causality, causality-guided scientific discovery, and causal machine learning

    [https://arxiv.org/abs/2402.13427](https://arxiv.org/abs/2402.13427)

    因果分析在人工智能领域中的应用挑战已得到基本解决，建立了严格的因果分析形式主义，推动了因果深度学习框架的建立，促进了从大气海洋科学到量子力学、神经科学、金融经济等领域的科学发现。

    

    人们曾说，因果分析应该为可解释的深度学习和泛化铺平一条充满希望的道路。然而，将因果性纳入人工智能（AI）算法中面临着其模糊性、非定量性、计算效率低等挑战。在过去的18年中，这些挑战已基本得到解决，建立了一个严格的因果分析形式主义，最初是受大气可预测性启发而建立的。这不仅开启了大气海洋科学中的一个新领域，即信息流，还通过各种应用在其他学科中取得了科学发现，如量子力学、神经科学、金融经济等。本文提供了对过去十年努力的简要回顾，包括主要理论结果的列表、因果深度学习框架的概述以及一些代表性的实际应用。

    arXiv:2402.13427v1 Announce Type: new  Abstract: It has been said, arguably, that causality analysis should pave a promising way to interpretable deep learning and generalization. Incorporation of causality into artificial intelligence (AI) algorithms, however, is challenged with its vagueness, non-quantitiveness, computational inefficiency, etc. During the past 18 years, these challenges have been essentially resolved, with the establishment of a rigorous formalism of causality analysis initially motivated from atmospheric predictability. This not only opens a new field in the atmosphere-ocean science, namely, information flow, but also has led to scientific discoveries in other disciplines, such as quantum mechanics, neuroscience, financial economics, etc., through various applications. This note provides a brief review of the decade-long effort, including a list of major theoretical results, a sketch of the causal deep learning framework, and some representative real-world applicati
    
[^70]: 在回归中探讨直方图损失

    Investigating the Histogram Loss in Regression

    [https://arxiv.org/abs/2402.13425](https://arxiv.org/abs/2402.13425)

    学习整个分布在回归中的性能提升主要来自于优化的改进，而不是学习更好的表示。

    

    越来越常见的是，在回归中训练神经网络来建模整个分布，即使只需要均值来进行预测。 这种额外的建模通常会带来性能增益，但背后的原因尚不完全清楚。 本文研究了回归中的一种最新方法，即直方图损失，该方法通过最小化目标分布和灵活直方图预测之间的交叉熵来学习目标变量的条件分布。 我们设计了理论和实证分析，以确定为什么以及何时会出现性能增益，以及损失的不同组件如何为此做出贡献。 我们的结果表明，在这种设置中学习分布的好处来自于优化的改进，而不是学习更好的表示。 然后，我们展示了直方图损失在常见的深度学习应用中的可行性。

    arXiv:2402.13425v1 Announce Type: cross  Abstract: It is becoming increasingly common in regression to train neural networks that model the entire distribution even if only the mean is required for prediction. This additional modeling often comes with performance gain and the reasons behind the improvement are not fully known. This paper investigates a recent approach to regression, the Histogram Loss, which involves learning the conditional distribution of the target variable by minimizing the cross-entropy between a target distribution and a flexible histogram prediction. We design theoretical and empirical analyses to determine why and when this performance gain appears, and how different components of the loss contribute to it. Our results suggest that the benefits of learning distributions in this setup come from improvements in optimization rather than learning a better representation. We then demonstrate the viability of the Histogram Loss in common deep learning applications wi
    
[^71]: 基于行为保证的模型规划代理的奖励下界研究

    Reward Bound for Behavioral Guarantee of Model-based Planning Agents

    [https://arxiv.org/abs/2402.13419](https://arxiv.org/abs/2402.13419)

    本研究探讨了如何确保模型规划代理在特定时间步内达到目标状态的行为保证问题，并提出了目标状态奖励的下界，对于低于该奖励的情况无法获得保证。

    

    近年来，在机器学习为基础的代理在现实环境中的可信度引起了人们的兴趣，特别是在机器人领域，为该行业提供安全保证。为这些代理获取行为保证仍然是一个重要问题。在本研究中，我们专注于保证模型规划代理在特定未来时间步内达到目标状态。我们表明，在目标状态存在一个奖励的下界，如果该奖励低于该下界，则无法获得此保证。此外，我们展示了如何对多个目标进行优先排序。

    arXiv:2402.13419v1 Announce Type: new  Abstract: Recent years have seen an emerging interest in the trustworthiness of machine learning-based agents in the wild, especially in robotics, to provide safety assurance for the industry. Obtaining behavioral guarantees for these agents remains an important problem. In this work, we focus on guaranteeing a model-based planning agent reaches a goal state within a specific future time step. We show that there exists a lower bound for the reward at the goal state, such that if the said reward is below that bound, it is impossible to obtain such a guarantee. By extension, we show how to enforce preferences over multiple goals.
    
[^72]: 使用专家混合模型扩展物理信息的硬约束

    Scaling physics-informed hard constraints with mixture-of-experts

    [https://arxiv.org/abs/2402.13412](https://arxiv.org/abs/2402.13412)

    新方法能够有效扩展物理信息的硬约束，提高了对复杂动力系统的建模效率。

    

    在神经网络训练中强加已知的物理约束，比如守恒定律，引入了一种归纳偏差，可以提高模拟物理动态的准确性、可靠性、收敛性和数据效率。虽然这些约束可以通过损失函数惩罚软性地强加，但最近不同iable物理和优化的进展通过将PDE约束优化作为神经网络中的单独层来改善性能。这使得对物理约束的遵守更加严格。然而，强加硬约束显著增加了计算和内存成本，尤其是对于复杂的动力系统。这是因为它需要在网格中的大量点上求解优化问题，表示空间和时间的离散化，从而极大地增加了约束的复杂性。为了解决这一挑战，我们开发了一种可扩展的方法来实施硬

    arXiv:2402.13412v1 Announce Type: cross  Abstract: Imposing known physical constraints, such as conservation laws, during neural network training introduces an inductive bias that can improve accuracy, reliability, convergence, and data efficiency for modeling physical dynamics. While such constraints can be softly imposed via loss function penalties, recent advancements in differentiable physics and optimization improve performance by incorporating PDE-constrained optimization as individual layers in neural networks. This enables a stricter adherence to physical constraints. However, imposing hard constraints significantly increases computational and memory costs, especially for complex dynamical systems. This is because it requires solving an optimization problem over a large number of points in a mesh, representing spatial and temporal discretizations, which greatly increases the complexity of the constraint. To address this challenge, we develop a scalable approach to enforce hard 
    
[^73]: 通过贝叶斯规则归纳在马尔科夫博弈中学习和维持共享的规范系统

    Learning and Sustaining Shared Normative Systems via Bayesian Rule Induction in Markov Games

    [https://arxiv.org/abs/2402.13399](https://arxiv.org/abs/2402.13399)

    通过贝叶斯规则归纳，新引入的智能体可以推断现有人群的规范，使智能体收敛到共享的规范，从而实现规范体系的稳定性

    

    人类社会的一个普遍特征是采用规则和规范体系来服务于合作目的。我们如何构建可以学习并遵守这一体系的智能体，以便它们可以灵活地与人类机构合作？我们假设，通过假定存在一个共享的规范集，大多数其他人会遵守这些规范，同时追求他们个人的愿望，即使他们不知道这些规范的确切内容。通过假设共享规范，新引入的智能体可以从遵守和违反的观察中推断现有人群的规范。此外，即使最初在对规范的信念上存在分歧，一组智能体也可以收敛到共享的规范，从而实现规范体系的稳定性：由于智能体可以使规范变为共识知识，这导致规范得到广泛遵守，从而使新的参与者得以加入

    arXiv:2402.13399v1 Announce Type: new  Abstract: A universal feature of human societies is the adoption of systems of rules and norms in the service of cooperative ends. How can we build learning agents that do the same, so that they may flexibly cooperate with the human institutions they are embedded in? We hypothesize that agents can achieve this by assuming there exists a shared set of norms that most others comply with while pursuing their individual desires, even if they do not know the exact content of those norms. By assuming shared norms, a newly introduced agent can infer the norms of an existing population from observations of compliance and violation. Furthermore, groups of agents can converge to a shared set of norms, even if they initially diverge in their beliefs about what the norms are. This in turn enables the stability of the normative system: since agents can bootstrap common knowledge of the norms, this leads the norms to be widely adhered to, enabling new entrants 
    
[^74]: Xling: 用于加速高维近似相似性连接的学习过滤器框架

    Xling: A Learned Filter Framework for Accelerating High-Dimensional Approximate Similarity Join

    [https://arxiv.org/abs/2402.13397](https://arxiv.org/abs/2402.13397)

    Xling是一个通用框架，利用学习模型构建度量空间过滤器，用于加速高维近似相似性连接，提供优化策略以提高预测质量

    

    相似性连接查找距离阈值内的所有接近点对。许多相似性连接方法已被提出，但在高维空间中通常由于维度灾难和数据不可感知而效率低下。我们调查了使用度量空间布隆过滤器（MSBF）的可能性，它是一组数据结构，检查查询点在多维空间中是否有邻居，以加速相似性连接。然而，将MSBF应用于相似性连接时存在几个挑战，包括信息严重丢失，数据不可感知和对距离度量的严格约束。在本文中，我们提出了Xling，一个通用框架，用任何现有回归模型构建基于学习的度量空间过滤器，旨在准确预测查询点是否具有足够数量的邻居。该框架提供了一套优化策略来进一步提高预测质量。

    arXiv:2402.13397v1 Announce Type: cross  Abstract: Similarity join finds all pairs of close points within a given distance threshold. Many similarity join methods have been proposed, but they are usually not efficient on high-dimensional space due to the curse of dimensionality and data-unawareness. We investigate the possibility of using metric space Bloom filter (MSBF), a family of data structures checking if a query point has neighbors in a multi-dimensional space, to speed up similarity join. However, there are several challenges when applying MSBF to similarity join, including excessive information loss, data-unawareness and hard constraint on the distance metric. In this paper, we propose Xling, a generic framework to build a learning-based metric space filter with any existing regression model, aiming at accurately predicting whether a query point has enough number of neighbors. The framework provides a suite of optimization strategies to further improve the prediction quality b
    
[^75]: 迈向变压器：用变压器彻底改变混合整数规划的解决方案

    Toward TransfORmers: Revolutionizing the Solution of Mixed Integer Programs with Transformers

    [https://arxiv.org/abs/2402.13380](https://arxiv.org/abs/2402.13380)

    这项研究利用变压器模型解决混合整数规划问题，首次采用变压器预测二进制变量，提出的算法在解决时间上超越了传统CPLEX和LSTM。

    

    在这项研究中，我们引入了一种创新的深度学习框架，利用变压器模型来解决混合整数规划的挑战，特别是专注于容量限制批量生产问题（CLSP）。据我们所知，我们的方法是首个利用变压器来预测混合整数规划问题中的二进制变量。具体而言，我们的方法利用编码器-解码器变压器处理顺序数据的能力，非常适合预测每个CLSP周期中表示生产设置决策的二进制变量。这个问题本质上是动态的，我们需要在约束条件下处理顺序决策。我们提出了一种有效的算法，通过变压器神经网络学习CLSP解决方案。所提出的后处理变压器算法在解决时间上超越了最先进的求解器CPLEX和长短期记忆（LSTM）。

    arXiv:2402.13380v1 Announce Type: new  Abstract: In this study, we introduce an innovative deep learning framework that employs a transformer model to address the challenges of mixed-integer programs, specifically focusing on the Capacitated Lot Sizing Problem (CLSP). Our approach, to our knowledge, is the first to utilize transformers to predict the binary variables of a mixed-integer programming (MIP) problem. Specifically, our approach harnesses the encoder decoder transformer's ability to process sequential data, making it well-suited for predicting binary variables indicating production setup decisions in each period of the CLSP. This problem is inherently dynamic, and we need to handle sequential decision making under constraints. We present an efficient algorithm in which CLSP solutions are learned through a transformer neural network. The proposed post-processed transformer algorithm surpasses the state-of-the-art solver, CPLEX and Long Short-Term Memory (LSTM) in solution time
    
[^76]: 异议山谷：扩散模型的综合分析

    The Uncanny Valley: A Comprehensive Analysis of Diffusion Models

    [https://arxiv.org/abs/2402.13369](https://arxiv.org/abs/2402.13369)

    通过对扩散模型的综合分析，揭示了决定模型性能的隐藏关键因素，为DMs的推进提供了见解。

    

    通过扩散模型（DMs），我们在生成高质量图像方面取得了重要进展。我们深入探讨了这些模型的核心操作原则，系统地调查了不同DM架构中的关键方面：i）噪声时间表，ii）采样器和iii）引导。我们对这些模型的全面审查揭示了它们隐藏的基本机制，揭示了对其有效性至关重要的隐藏基础要素。我们的分析强调了决定模型性能的隐藏关键因素，提供了有助于推动DMs发展的见解。过去的研究发现，噪声时间表、采样器和引导的配置对生成图像的质量至关重要；然而，模型在不同配置下在一个非常相似的稳定质量水平上达到，揭示了决定最佳性能的关键因素。

    arXiv:2402.13369v1 Announce Type: cross  Abstract: Through Diffusion Models (DMs), we have made significant advances in generating high-quality images. Our exploration of these models delves deeply into their core operational principles by systematically investigating key aspects across various DM architectures: i) noise schedules, ii) samplers, and iii) guidance. Our comprehensive examination of these models sheds light on their hidden fundamental mechanisms, revealing the concealed foundational elements that are essential for their effectiveness. Our analyses emphasize the hidden key factors that determine model performance, offering insights that contribute to the advancement of DMs. Past findings show that the configuration of noise schedules, samplers, and guidance is vital to the quality of generated images; however, models reach a stable level of quality across different configurations at a remarkably similar point, revealing that the decisive factors for optimal performance pre
    
[^77]: KetGPT -- 使用Transformer对量子电路进行数据增强

    KetGPT -- Dataset Augmentation of Quantum Circuits using Transformers

    [https://arxiv.org/abs/2402.13352](https://arxiv.org/abs/2402.13352)

    该研究利用Transformer机器学习架构生成“看起来真实”的量子电路，以增强现有的量子电路数据集。

    

    量子算法，表示为量子电路，可用作评估量子系统性能的基准。现有数据集在规模和多样性方面存在限制，在该领域广泛使用，导致研究人员使用随机生成的电路。然而，随机电路并不是代表性基准，因为它们缺乏量子系统制造的真实量子算法的固有属性。这种缺乏“有用”的量子基准构成了推动量子编译器和硬件开发与比较的挑战。本研究旨在通过使用Transformer机器学习架构生成我们称之为“看起来真实”的电路，以增强现有的量子电路数据集。为此，我们引入了KetGPT，一种以OpenQASM语言生成合成电路的工具，其结构是基于推导自量子电路的

    arXiv:2402.13352v1 Announce Type: cross  Abstract: Quantum algorithms, represented as quantum circuits, can be used as benchmarks for assessing the performance of quantum systems. Existing datasets, widely utilized in the field, suffer from limitations in size and versatility, leading researchers to employ randomly generated circuits. Random circuits are, however, not representative benchmarks as they lack the inherent properties of real quantum algorithms for which the quantum systems are manufactured. This shortage of `useful' quantum benchmarks poses a challenge to advancing the development and comparison of quantum compilers and hardware.   This research aims to enhance the existing quantum circuit datasets by generating what we refer to as `realistic-looking' circuits by employing the Transformer machine learning architecture. For this purpose, we introduce KetGPT, a tool that generates synthetic circuits in OpenQASM language, whose structure is based on quantum circuits derived f
    
[^78]: Aria Everyday Activities 数据集

    Aria Everyday Activities Dataset

    [https://arxiv.org/abs/2402.13349](https://arxiv.org/abs/2402.13349)

    AEA数据集是使用Project Aria眼镜记录的第一人称多模态开放数据集，其中包含了多个佩戴者在室内不同位置记录的日常活动序列，为研究提供了3D轨迹、场景点云、眼球注视向量和语音转录等机器感知数据，支持神经场景重建和提示分割。

    

    我们介绍了Aria Everyday Activities (AEA)数据集，这是一个使用Project Aria眼镜记录的第一人称多模态开放数据集。AEA包含了由多名佩戴者在五个地理上多样的室内位置记录的143个日常活动序列。每个记录都包含通过Project Aria眼镜记录的多模态传感器数据。此外，AEA还提供了机器感知数据，包括高频全局对齐的3D轨迹，场景点云，逐帧3D眼球注视向量和时间对齐的语音转录。在本文中，我们展示了通过这一数据集实现的一些示例研究应用，包括神经场景重建和提示分割。AEA是一个可以从projectaria.com下载的开源数据集。我们还提供了如何在Project Aria Tools中使用数据集的开源实现和示例。

    arXiv:2402.13349v1 Announce Type: cross  Abstract: We present Aria Everyday Activities (AEA) Dataset, an egocentric multimodal open dataset recorded using Project Aria glasses. AEA contains 143 daily activity sequences recorded by multiple wearers in five geographically diverse indoor locations. Each of the recording contains multimodal sensor data recorded through the Project Aria glasses. In addition, AEA provides machine perception data including high frequency globally aligned 3D trajectories, scene point cloud, per-frame 3D eye gaze vector and time aligned speech transcription. In this paper, we demonstrate a few exemplar research applications enabled by this dataset, including neural scene reconstruction and prompted segmentation. AEA is an open source dataset that can be downloaded from projectaria.com. We are also providing open-source implementations and examples of how to use the dataset in Project Aria Tools.
    
[^79]: 具有市场影响力的深度套期保值

    Deep Hedging with Market Impact

    [https://arxiv.org/abs/2402.13326](https://arxiv.org/abs/2402.13326)

    本文提出了一种基于深度强化学习的市场影响动态套期保值模型，考虑了凸市场影响和随时间持续的影响，通过与常用程序比较，展示了其在期权套期保值方面的优越性。

    

    动态套期保值是定期进行金融工具交易，以抵消投资或负债所带来风险的实践。动态套期保值优化可以被视为一个顺序决策问题；因此，最近提出了利用强化学习（RL）模型来解决这一任务。然而，现有的套期保值RL工作并未考虑由交易工具的有限流动性引起的市场影响。整合这样的特征对于在具有有限流动性的股票期权套期保值时实现最佳性能可能是至关重要的。本文提出了一种基于深度强化学习（DRL）的新型通用市场影响动态套期保值模型，考虑了几个逼真的特征，例如凸市场影响和随时间持续的影响。从DRL模型得到的最优策略通过几个期权套期保值模拟进行了分析，并与常用程序（如德尔塔套期保值）进行了比较。

    arXiv:2402.13326v1 Announce Type: cross  Abstract: Dynamic hedging is the practice of periodically transacting financial instruments to offset the risk caused by an investment or a liability. Dynamic hedging optimization can be framed as a sequential decision problem; thus, Reinforcement Learning (RL) models were recently proposed to tackle this task. However, existing RL works for hedging do not consider market impact caused by the finite liquidity of traded instruments. Integrating such feature can be crucial to achieve optimal performance when hedging options on stocks with limited liquidity. In this paper, we propose a novel general market impact dynamic hedging model based on Deep Reinforcement Learning (DRL) that considers several realistic features such as convex market impacts, and impact persistence through time. The optimal policy obtained from the DRL model is analysed using several option hedging simulations and compared to commonly used procedures such as delta hedging. Re
    
[^80]: 有害藻华细胞损害(DSP)的预测：流式学习和批处理学习的比较

    Harmful algal bloom forecasting. A comparison between stream and batch learning

    [https://arxiv.org/abs/2402.13304](https://arxiv.org/abs/2402.13304)

    流式学习是有望解决时间序列问题中概念漂移的最有希望方法之一，本研究对其在预测有害藻华细胞损害方面的效力进行了测试并与批处理学习进行了比较。

    

    有害藻华细胞损害(DSP)是一种全球健康威胁，源于贝类受到甲藻产生的毒素污染。这种疾病由于普遍性发生、高致病率和贝类持续的毒性，对公共卫生和贝类产业构成危险。毒素产生藻类生物量高的情况，如DSP，被称为有害藻华细胞损害(HABs)。监测和预测系统对于减轻HABs影响至关重要。预测有害藻华细胞损害涉及一个以时间序列为基础的问题，其中有一个强烈的历史季节性组成部分，然而，近期由于气象和海洋事件变化而引起的异常现象已被观察到。流式学习是解决具有概念漂移的时间序列问题的最有希望的方法之一。然而，其在预测HABs方面的有效性尚未得到证明，并且需要与批处理学习进行比较测试。

    arXiv:2402.13304v1 Announce Type: cross  Abstract: Diarrhetic Shellfish Poisoning (DSP) is a global health threat arising from shellfish contaminated with toxins produced by dinoflagellates. The condition, with its widespread incidence, high morbidity rate, and persistent shellfish toxicity, poses risks to public health and the shellfish industry. High biomass of toxin-producing algae such as DSP are known as Harmful Algal Blooms (HABs). Monitoring and forecasting systems are crucial for mitigating HABs impact. Predicting harmful algal blooms involves a time-series-based problem with a strong historical seasonal component, however, recent anomalies due to changes in meteorological and oceanographic events have been observed. Stream Learning stands out as one of the most promising approaches for addressing time-series-based problems with concept drifts. However, its efficacy in predicting HABs remains unproven and needs to be tested in comparison with Batch Learning. Historical data ava
    
[^81]: 针对音乐生成的结构感知位置编码

    Structure-informed Positional Encoding for Music Generation

    [https://arxiv.org/abs/2402.13301](https://arxiv.org/abs/2402.13301)

    提出了一种针对音乐生成的结构感知位置编码框架，通过绝对、相对和非平稳位置信息，显著改善了生成作品的旋律和结构一致性。

    

    由深度学习方法生成的音乐往往缺乏连贯性和长期组织，而多尺度层次结构是音乐信号的显著特征。为了利用这一信息，我们提出了一种针对Transformer音乐生成的结构感知位置编码框架。我们设计了三种变体，涉及绝对、相对和非平稳位置信息。我们在两个符号音乐生成任务上对它们进行了全面测试：下一个时间步预测和伴奏生成。作为对比，我们选择了文献中的多个基线，使用几个以音乐为动机的评估指标展示了我们方法的优点。特别是，我们的方法改善了生成作品的旋律和结构一致性。

    arXiv:2402.13301v1 Announce Type: cross  Abstract: Music generated by deep learning methods often suffers from a lack of coherence and long-term organization. Yet, multi-scale hierarchical structure is a distinctive feature of music signals. To leverage this information, we propose a structure-informed positional encoding framework for music generation with Transformers. We design three variants in terms of absolute, relative and non-stationary positional information. We comprehensively test them on two symbolic music generation tasks: next-timestep prediction and accompaniment generation. As a comparison, we choose multiple baselines from the literature and demonstrate the merits of our methods using several musically-motivated evaluation metrics. In particular, our methods improve the melodic and structural consistency of the generated pieces.
    
[^82]: 深度学习与合成生物学的集成: 通过N端编码序列增强基因表达的协同设计方法

    Integrating Deep Learning and Synthetic Biology: A Co-Design Approach for Enhancing Gene Expression via N-terminal Coding Sequences

    [https://arxiv.org/abs/2402.13297](https://arxiv.org/abs/2402.13297)

    本文提出了一种深度学习/合成生物学协同设计的少样本训练工作流程，用于N端编码序列（NCS）优化，通过利用k最近编码和word2vec对NCS进行编码，并利用注意机制进行特征提取，构建时间序列网络预测基因表达强度，最终通过直接搜索算法确定具有有限训练数据的最佳NCS。

    

    N端编码序列（NCS）通过影响翻译起始速率而影响基因表达。 NCS优化问题是找到最大化基因表达的NCS。 该问题在遗传工程中非常重要。 但是，目前用于NCS优化的方法，如有理设计和统计引导方法，劳动密集且仅产生相对较小的改进。 本文介绍了一种用于NCS优化的深度学习/合成生物学协同设计少样本训练工作流程。 我们的方法利用k最近编码，然后利用word2vec对NCS进行编码，然后使用注意机制进行特征提取，然后构建时间序列网络以预测基因表达强度，最后通过直接搜索算法确定具有有限训练数据的最佳NCS。 我们以枯荧光蛋白（GFP）由枯荧杆菌表达作为NCS的报告蛋白，并采用

    arXiv:2402.13297v1 Announce Type: cross  Abstract: N-terminal coding sequence (NCS) influences gene expression by impacting the translation initiation rate. The NCS optimization problem is to find an NCS that maximizes gene expression. The problem is important in genetic engineering. However, current methods for NCS optimization such as rational design and statistics-guided approaches are labor-intensive yield only relatively small improvements. This paper introduces a deep learning/synthetic biology co-designed few-shot training workflow for NCS optimization. Our method utilizes k-nearest encoding followed by word2vec to encode the NCS, then performs feature extraction using attention mechanisms, before constructing a time-series network for predicting gene expression intensity, and finally a direct search algorithm identifies the optimal NCS with limited training data. We took green fluorescent protein (GFP) expressed by Bacillus subtilis as a reporting protein of NCSs, and employed 
    
[^83]: 一个针对多机器人系统的冲突感知最优目标分配算法

    A Conflict-Aware Optimal Goal Assignment Algorithm for Multi-Robot Systems

    [https://arxiv.org/abs/2402.13292](https://arxiv.org/abs/2402.13292)

    提出了针对多机器人系统的冲突感知最优目标分配算法，并引入了冲突引导方法和其他优化方法。

    

    多机器人应用中的基本目标分配问题旨在为每个机器人分配一个唯一目标，同时确保路径无碰撞，最小化总移动成本。这个NP-hard问题的一个可行算法解决方案涉及一个迭代过程，该过程整合了一个任务规划器来计算目标分配，同时忽略机器人之间的碰撞可能性，以及一个多代理路径规划算法来找到给定分配的无碰撞轨迹。为了避免这一瓶颈，我们提出了一种高效的冲突引导方法来计算下一个最佳分配。此外，我们还引入了另外两种优化方法到算法中。

    arXiv:2402.13292v1 Announce Type: cross  Abstract: The fundamental goal assignment problem for a multi-robot application aims to assign a unique goal to each robot while ensuring collision-free paths, minimizing the total movement cost. A plausible algorithmic solution to this NP-hard problem involves an iterative process that integrates a task planner to compute the goal assignment while ignoring the collision possibilities among the robots and a multi-agent path-finding algorithm to find the collision-free trajectories for a given assignment. This procedure involves a method for computing the next best assignment given the current best assignment. A naive way of computing the next best assignment, as done in the state-of-the-art solutions, becomes a roadblock to achieving scalability in solving the overall problem. To obviate this bottleneck, we propose an efficient conflict-guided method to compute the next best assignment. Additionally, we introduce two more optimizations to the al
    
[^84]: 从人工智能和认知科学的视角看基础建立

    Grounding from an AI and Cognitive Science Lens

    [https://arxiv.org/abs/2402.13290](https://arxiv.org/abs/2402.13290)

    从认知科学和机器学习的视角探讨基础建立的微妙之处，探讨神经符号方法在如何更全面地解决基础建立问题，讨论基础建立领域的进一步发展方向。

    

    基础建立是一个具有挑战性的问题，需要一个正式的定义和不同层次的抽象。本文从认知科学和机器学习的视角探讨了基础建立。它确定了基础建立的微妙之处，它对协作代理的重要性，以及在两个社区中基础建立方法的相似之处和不同之处。本文还研究了专为基础建立任务量身定制的神经符号方法的潜力，展示了它们如何更全面地解决基础建立问题。最后，我们讨论了基础建立领域的进一步探索和发展方向。

    arXiv:2402.13290v1 Announce Type: new  Abstract: Grounding is a challenging problem, requiring a formal definition and different levels of abstraction. This article explores grounding from both cognitive science and machine learning perspectives. It identifies the subtleties of grounding, its significance for collaborative agents, and similarities and differences in grounding approaches in both communities. The article examines the potential of neuro-symbolic approaches tailored for grounding tasks, showcasing how they can more comprehensively address grounding. Finally, we discuss areas for further exploration and development in grounding.
    
[^85]: 通过SQL查询分解进行培训表格问答

    Training Table Question Answering via SQL Query Decomposition

    [https://arxiv.org/abs/2402.13288](https://arxiv.org/abs/2402.13288)

    通过学习模拟SQL样式代数操作的受限部分，提供了中间监督步骤，相较于传统方法增加了泛化性和结构推理能力。

    

    表格问答涉及理解自然语言查询并将其扎根于输入表格的上下文中，以提取相关信息。许多方法强调了从SQL查询进行中间预训练的好处。然而，虽然大多数方法旨在直接从输入生成最终答案，我们主张在训练过程中更好地利用SQL查询。通过学习模拟SQL样式代数操作的受限部分，我们展示了它们的执行流程提供了中间监督步骤，允许相对于该领域的传统方法而言增加了泛化性和结构推理能力。我们的研究弥合了语义解析和直接回答方法之间的差距，并就生成架构应预测哪些类型的操作或最好由外部算法执行提供了有用的见解。

    arXiv:2402.13288v1 Announce Type: cross  Abstract: Table Question-Answering involves both understanding the natural language query and grounding it in the context of the input table to extract the relevant information. In this context, many methods have highlighted the benefits of intermediate pre-training from SQL queries. However, while most approaches aim at generating final answers from inputs directly, we claim that there is better to do with SQL queries during training. By learning to imitate a restricted portion of SQL-like algebraic operations, we show that their execution flow provides intermediate supervision steps that allow increased generalization and structural reasoning compared with classical approaches of the field. Our study bridges the gap between semantic parsing and direct answering methods and provides useful insights regarding what types of operations should be predicted by a generative architecture or be preferably executed by an external algorithm.
    
[^86]: 通过污染批量数据操纵隐马尔可夫模型的推断

    Manipulating hidden-Markov-model inferences by corrupting batch data

    [https://arxiv.org/abs/2402.13287](https://arxiv.org/abs/2402.13287)

    通过污染数据，本研究提供了一种新颖的概率视角，用于操纵隐马尔可夫模型的推断，并开发了多种解决方法进行应用和实证测试。

    

    时间序列模型通常假设数据流是未被污染和合法的。然而，一个自私的对手可能有动机来破坏这些数据，从而改变决策者的推断。在更广泛的对抗机器学习领域，这项研究提供了一种新颖的概率视角，用于通过污染数据来操纵隐马尔可夫模型的推断。具体而言，我们提供了一套污染问题，用于过滤、平滑和解码推断，利用对抗风险分析方法。提出了多个随机规划模型，这些模型结合了现实中的不确定性和不同的攻击者目标。通过从频率主义和贝叶斯角度交替地观察问题，开发了三种一般的解决方法。通过广泛的实证测试，说明了每种方法的有效性。开发的方法以其解决质量为特点

    arXiv:2402.13287v1 Announce Type: cross  Abstract: Time-series models typically assume untainted and legitimate streams of data. However, a self-interested adversary may have incentive to corrupt this data, thereby altering a decision maker's inference. Within the broader field of adversarial machine learning, this research provides a novel, probabilistic perspective toward the manipulation of hidden Markov model inferences via corrupted data. In particular, we provision a suite of corruption problems for filtering, smoothing, and decoding inferences leveraging an adversarial risk analysis approach. Multiple stochastic programming models are set forth that incorporate realistic uncertainties and varied attacker objectives. Three general solution methods are developed by alternatively viewing the problem from frequentist and Bayesian perspectives. The efficacy of each method is illustrated via extensive, empirical testing. The developed methods are characterized by their solution qualit
    
[^87]: 结构引导的大型语言模型用于SQL生成

    Structure Guided Large Language Model for SQL Generation

    [https://arxiv.org/abs/2402.13284](https://arxiv.org/abs/2402.13284)

    通过引入结构信息，提出了一个结构引导的SQL生成模型，以改善大型语言模型生成SQL的准确性和可执行性。

    

    生成准确的结构化查询语言（SQL）是一个长期存在的问题，特别是在将用户的语义查询与结构化数据库匹配，然后生成结构化SQL方面。现有模型通常将查询和数据库模式输入到LLM中，并依赖LLM执行语义-结构匹配并生成结构化SQL。然而，这种解决方案忽略了用户查询和数据库中的结构信息，而这些信息可以用来增强结构化SQL的生成。这一疏忽可能导致不准确或无法执行的SQL生成。为了充分利用结构，我们提出了一个结构到SQL的框架，利用固有的结构信息来改善LLM的SQL生成。具体地，我们介绍了我们的结构引导SQL（SGU-SQL）生成模型。

    arXiv:2402.13284v1 Announce Type: cross  Abstract: Generating accurate Structured Querying Language (SQL) is a long-standing problem, especially in matching users' semantic queries with structured databases and then generating structured SQL. Existing models typically input queries and database schemas into the LLM and rely on the LLM to perform semantic-structure matching and generate structured SQL. However, such solutions overlook the structural information within user queries and databases, which can be utilized to enhance the generation of structured SQL. This oversight can lead to inaccurate or unexecutable SQL generation. To fully exploit the structure, we propose a structure-to-SQL framework, which leverages the inherent structure information to improve the SQL generation of LLMs. Specifically, we introduce our Structure Guided SQL~(SGU-SQL) generation model. SGU-SQL first links user queries and databases in a structure-enhanced manner. It then decomposes complicated linked str
    
[^88]: 当LLMs遇到声学标志：一种高效地将语音集成到大型语言模型中用于抑郁检测的方法

    When LLMs Meets Acoustic Landmarks: An Efficient Approach to Integrate Speech into Large Language Models for Depression Detection

    [https://arxiv.org/abs/2402.13276](https://arxiv.org/abs/2402.13276)

    本文提出了一种创新方法，将声学语音信息集成到LLMs框架中，以用于多模式抑郁检测。

    

    抑郁是全球心理健康中的一个严重关切，促使进行大量研究来探讨基于AI的检测方法。在各种AI技术中，大型语言模型（LLMs）因其在心理卫生应用中的多功能性而脱颖而出。然而，它们的主要局限性在于它们仅依赖于文本输入，这限制了它们的整体功能。此外，LLMs在识别和分析抑郁状态方面的利用仍相对未开发。在本文中，我们提出了一种创新方法，将声学语音信息集成到LLMs框架中，以用于多模式抑郁检测。我们研究了一种通过利用声学标志将语音信号集成到LLMs中的高效抑郁检测方法。通过整合声学标志，这些标志是特定于口语单词发音的，我们的方法为文本转录添加了关键维度。

    arXiv:2402.13276v1 Announce Type: cross  Abstract: Depression is a critical concern in global mental health, prompting extensive research into AI-based detection methods. Among various AI technologies, Large Language Models (LLMs) stand out for their versatility in mental healthcare applications. However, their primary limitation arises from their exclusive dependence on textual input, which constrains their overall capabilities. Furthermore, the utilization of LLMs in identifying and analyzing depressive states is still relatively untapped. In this paper, we present an innovative approach to integrating acoustic speech information into the LLMs framework for multimodal depression detection. We investigate an efficient method for depression detection by integrating speech signals into LLMs utilizing Acoustic Landmarks. By incorporating acoustic landmarks, which are specific to the pronunciation of spoken words, our method adds critical dimensions to text transcripts. This integration a
    
[^89]: 皮层基底神经节环路模型的实现

    Implementation of a Model of the Cortex Basal Ganglia Loop

    [https://arxiv.org/abs/2402.13275](https://arxiv.org/abs/2402.13275)

    本文提出了皮层基底神经节环路模型的实现，用于行动选择和执行，基于大脑皮层预测行动，基底神经节使用强化学习决定执行哪些行动。

    

    本文提出了皮层-基底神经节-丘脑环路的简单模型，该模型被认为用于行动选择和执行，并报告了其实现的结果。该模型基于大脑皮层预测行动，而基底神经节使用强化学习来决定是否执行皮层预测的行动。该实现旨在用作由大脑皮层区域或受启发认知架构组成的模型的组成部分。

    arXiv:2402.13275v1 Announce Type: cross  Abstract: This article presents a simple model of the cortex-basal ganglia-thalamus loop, which is thought to serve for action selection and executions, and reports the results of its implementation. The model is based on the hypothesis that the cerebral cortex predicts actions, while the basal ganglia use reinforcement learning to decide whether to perform the actions predicted by the cortex. The implementation is intended to be used as a component of models of the brain consisting of cortical regions or brain-inspired cognitive architectures.
    
[^90]: 人类与机器的运营集体智能

    Operational Collective Intelligence of Humans and Machines

    [https://arxiv.org/abs/2402.13273](https://arxiv.org/abs/2402.13273)

    聚合众包预测作为集体智能的重要进展，促进了人类和AI的连接，使决策具有优势。

    

    我们探讨了聚合式众包预测（ACF）的使用，作为帮助运用人机团队的“集体智能”来协调行动的机制。我们采纳了集体智能的定义：“一种从数据-信息-知识、软件-硬件、个人（那些具有新见解以及公认权威）之间的协同作用产生的群体属性，使得实时知识能够比这三个元素单独行动做出更好的决策。”集体智能源自于连接人类和人工智能的新方法，以实现决策优势，部分原因在于创造和利用可能否则不会被包括的额外信息来源。

    arXiv:2402.13273v1 Announce Type: new  Abstract: We explore the use of aggregative crowdsourced forecasting (ACF) as a mechanism to help operationalize ``collective intelligence'' of human-machine teams for coordinated actions. We adopt the definition for Collective Intelligence as: ``A property of groups that emerges from synergies among data-information-knowledge, software-hardware, and individuals (those with new insights as well as recognized authorities) that enables just-in-time knowledge for better decisions than these three elements acting alone.'' Collective Intelligence emerges from new ways of connecting humans and AI to enable decision-advantage, in part by creating and leveraging additional sources of information that might otherwise not be included. Aggregative crowdsourced forecasting (ACF) is a recent key advancement towards Collective Intelligence wherein predictions (X\% probability that Y will happen) and rationales (why I believe it is this probability that X will h
    
[^91]: 人工智能的自发心灵理论

    Spontaneous Theory of Mind for Artificial Intelligence

    [https://arxiv.org/abs/2402.13272](https://arxiv.org/abs/2402.13272)

    论文提出了人工智能中自发心灵理论的概念，强调了自发ToM相对于启发式ToM的重要性，并主张发展AI ToM需要采取原则性方法，以实现更具弹性的人工社会智能。

    

    人工智能领域现有的心灵理论（ToM）方法过分强调启发式或基于线索的ToM，可能限制我们发展人工社会智能（ASI）的集体能力。借鉴计算机科学、认知科学和相关学科的研究，我们将启发式ToM与我们所称的自发ToM进行对比 - 即关于他人心智状态的推理，基于无意识、可能无法控制的认知功能。我们主张对研究和发展AI ToM采取原则性的方法，并建议健全的或通用的ASI将对提示作出回应，并自发地参与社会推理。

    arXiv:2402.13272v1 Announce Type: new  Abstract: Existing approaches to Theory of Mind (ToM) in Artificial Intelligence (AI) overemphasize prompted, or cue-based, ToM, which may limit our collective ability to develop Artificial Social Intelligence (ASI). Drawing from research in computer science, cognitive science, and related disciplines, we contrast prompted ToM with what we call spontaneous ToM -- reasoning about others' mental states that is grounded in unintentional, possibly uncontrollable cognitive functions. We argue for a principled approach to studying and developing AI ToM and suggest that a robust, or general, ASI will respond to prompts \textit{and} spontaneously engage in social reasoning.
    
[^92]: 全球热带气旋强度预测的多模态多尺度因果自回归模型

    Global Tropical Cyclone Intensity Forecasting with Multi-modal Multi-scale Causal Autoregressive Model

    [https://arxiv.org/abs/2402.13270](https://arxiv.org/abs/2402.13270)

    提出了一种全球热带气旋强度预测模型MSCAR，首次将因果关系与大规模多模态数据相结合，有效优于现有最先进方法。

    

    精确预测热带气旋（TC）强度对于制定灾害风险减少策略至关重要。目前的方法主要依赖于来自ERA5数据的有限时空信息，并忽视这些物理变量之间的因果关系，未能充分捕捉强度预测所需的空间和时间模式。为解决这一问题，作者提出了一种多模态多尺度因果自回归模型（MSCAR），这是第一个将因果关系与大规模多模态数据结合起来进行全球TC强度自回归预测的模型。此外，鉴于目前缺乏一个提供广泛空间变量的TC数据集，我们推出了基于卫星和ERA5的热带气旋数据集（SETCD），它是与TC有关的最长和最全面的全球数据集。对该数据集的实验表明MSCAR胜过了现有的最先进方法。

    arXiv:2402.13270v1 Announce Type: cross  Abstract: Accurate forecasting of Tropical cyclone (TC) intensity is crucial for formulating disaster risk reduction strategies. Current methods predominantly rely on limited spatiotemporal information from ERA5 data and neglect the causal relationships between these physical variables, failing to fully capture the spatial and temporal patterns required for intensity forecasting. To address this issue, we propose a Multi-modal multi-Scale Causal AutoRegressive model (MSCAR), which is the first model that combines causal relationships with large-scale multi-modal data for global TC intensity autoregressive forecasting. Furthermore, given the current absence of a TC dataset that offers a wide range of spatial variables, we present the Satellite and ERA5-based Tropical Cyclone Dataset (SETCD), which stands as the longest and most comprehensive global dataset related to TCs. Experiments on the dataset show that MSCAR outperforms the state-of-the-art
    
[^93]: KGroot：通过知识图谱和图卷积神经网络增强根本原因分析

    KGroot: Enhancing Root Cause Analysis through Knowledge Graphs and Graph Convolutional Neural Networks

    [https://arxiv.org/abs/2402.13264](https://arxiv.org/abs/2402.13264)

    通过知识图谱和图卷积神经网络，KGroot提出了一种增强根本原因分析的方法，应用于在线微服务中的故障定位，旨在解决监控数据多样性、事件传播等挑战，提高准确性和效率。

    

    故障定位在在线微服务中具有挑战性，因为监控数据的数量、类型、事件以及服务和组件之间复杂的相互依赖性多种多样。服务中的故障事件是具有传播性的，可以在短时间内触发一系列警报。在工业界，故障定位通常由经验丰富的人员手动进行。这种依赖于经验的方式不可靠且缺乏自动化。不同的模块在手动定位过程中存在信息障碍，使得在紧急故障期间很难快速对齐。这种低效导致了稳定性保证滞后，无法及时最小化故障检测和修复时间。虽然已经有可操作的方法旨在自动化这个过程，但准确性和效率仍不尽如人意。故障定位结果的精确性非常重要，因为它为工程师对从多个方面得出的诊断结论的信任奠定了基础。

    arXiv:2402.13264v1 Announce Type: new  Abstract: Fault localization is challenging in online micro-service due to the wide variety of monitoring data volume, types, events and complex interdependencies in service and components. Faults events in services are propagative and can trigger a cascade of alerts in a short period of time. In the industry, fault localization is typically conducted manually by experienced personnel. This reliance on experience is unreliable and lacks automation. Different modules present information barriers during manual localization, making it difficult to quickly align during urgent faults. This inefficiency lags stability assurance to minimize fault detection and repair time. Though actionable methods aimed to automatic the process, the accuracy and efficiency are less than satisfactory. The precision of fault localization results is of paramount importance as it underpins engineers trust in the diagnostic conclusions, which are derived from multiple perspe
    
[^94]: 通过用户行为建模和随机规划控制大型电动汽车充电站

    Controlling Large Electric Vehicle Charging Stations via User Behavior Modeling and Stochastic Programming

    [https://arxiv.org/abs/2402.13224](https://arxiv.org/abs/2402.13224)

    本文介绍了一个新的电动汽车充电站模型，通过用户行为建模和随机规划，解决了充电会话不确定性问题，并提出了两种方法来优化成本并提高用户满意度。

    

    本文介绍了一个电动汽车充电站（EVCS）模型，该模型融合了真实世界的约束条件，如插槽功率限制、合同阈值超限惩罚以及电动汽车（EVs）的早期断开。我们提出了一个在不确定性下控制EVCS的问题形式，并实施了两种多阶段随机规划方法，利用用户提供的信息，即模型预测控制和二阶段随机规划。该模型解决了充电会话开始和结束时间以及能量需求的不确定性。基于驻留时间依赖随机过程的用户行为模型增强了成本降低的同时保持客户满意度。通过使用真实世界数据集进行的22天模拟展示了两种提出方法相对于两个基线的优势。两阶段方法证明了针对早期断开的鲁棒性，考虑了更多

    arXiv:2402.13224v1 Announce Type: cross  Abstract: This paper introduces an Electric Vehicle Charging Station (EVCS) model that incorporates real-world constraints, such as slot power limitations, contract threshold overruns penalties, or early disconnections of electric vehicles (EVs). We propose a formulation of the problem of EVCS control under uncertainty, and implement two Multi-Stage Stochastic Programming approaches that leverage user-provided information, namely, Model Predictive Control and Two-Stage Stochastic Programming. The model addresses uncertainties in charging session start and end times, as well as in energy demand. A user's behavior model based on a sojourn-time-dependent stochastic process enhances cost reduction while maintaining customer satisfaction. The benefits of the two proposed methods are showcased against two baselines over a 22-day simulation using a real-world dataset. The two-stage approach proves robust against early disconnections, considering a more
    
[^95]: CMDAG: 一个带有注释的中文隐喻数据集作为“CoT”来提升隐喻生成

    CMDAG: A Chinese Metaphor Dataset with Annotated Grounds as CoT for Boosting Metaphor Generation

    [https://arxiv.org/abs/2402.13145](https://arxiv.org/abs/2402.13145)

    本文介绍了一个大规模高质量的带注释中文隐喻语料库，强调隐喻生成中的基础及其独特特征，而非传统的对象和载体组合。

    

    隐喻是人类语言和文学中显著的修辞手法，因为它们增添了色彩、形象和强调，以增强有效交流。本文介绍了一个大规模高质量的带注释中文隐喻语料库，包括约28K句来自各种中文文学来源（如诗歌、散文、歌词等）。为确保注释的准确性和一致性，我们提出了一套全面的指南。这些指南涵盖了隐喻标注的方面，包括识别对象、载体和基础，以处理比喻、拟人、并列和夸张等复杂性。打破传统，我们的隐喻生成方法强调基础及其独特特征，而不是传统的对象和载体组合。通过将“基础”作为“CoT”（思维链）输入进行整合，我们能够生成重新

    arXiv:2402.13145v1 Announce Type: cross  Abstract: Metaphor is a prominent linguistic device in human language and literature, as they add color, imagery, and emphasis to enhance effective communication. This paper introduces a large-scale high quality annotated Chinese Metaphor Corpus, which comprises around 28K sentences drawn from a diverse range of Chinese literary sources, such as poems, prose, song lyrics, etc. To ensure the accuracy and consistency of our annotations, we introduce a comprehensive set of guidelines. These guidelines address the facets of metaphor annotation, including identifying tenors, vehicles, and grounds to handling the complexities of similes, personifications, juxtapositions, and hyperboles. Breaking tradition, our approach to metaphor generation emphasizes grounds and their distinct features rather than the conventional combination of tenors and vehicles. By integrating "ground" as a CoT (Chain of Thoughts) input, we are able to generate metaphors that re
    
[^96]: 将废料变废为宝：矫正MoE的Top-k路由器

    Turn Waste into Worth: Rectifying Top-$k$ Router of MoE

    [https://arxiv.org/abs/2402.12399](https://arxiv.org/abs/2402.12399)

    提出了Rectify-Router解决了MoE模型中常用的Top-k路由机制所带来的令牌丢失和填充问题，通过Intra-GPU矫正和Fill-in矫正来实现。

    

    稀疏混合专家（MoE）模型因其计算效率而受到欢迎，用于训练大型语言模型。然而，常用的Top-k路由机制由于不平衡的路由导致冗余计算和内存成本过高。一些专家会溢出，其中超出的令牌会被丢弃。而一些专家是空闲的，这些专家会填充为零，负面影响了模型性能。为了解决丢弃令牌和填充问题，我们提出了Rectify-Router，包括Intra-GPU矫正和Fill-in矫正。Intra-GPU矫正处理丢弃的令牌，将它们有效地路由到GPU内的专家，避免跨GPU通信。Fill-in矫正通过用具有高路由分数的令牌替换填充令牌来解决填充问题。我们的实验结果表明，Intra-GPU矫正和Fill-in矫正

    arXiv:2402.12399v1 Announce Type: cross  Abstract: Sparse Mixture of Experts (MoE) models are popular for training large language models due to their computational efficiency. However, the commonly used top-$k$ routing mechanism suffers from redundancy computation and memory costs due to the unbalanced routing. Some experts are overflow, where the exceeding tokens are dropped. While some experts are vacant, which are padded with zeros, negatively impacting model performance. To address the dropped tokens and padding, we propose the Rectify-Router, comprising the Intra-GPU Rectification and the Fill-in Rectification. The Intra-GPU Rectification handles dropped tokens, efficiently routing them to experts within the GPU where they are located to avoid inter-GPU communication. The Fill-in Rectification addresses padding by replacing padding tokens with the tokens that have high routing scores. Our experimental results demonstrate that the Intra-GPU Rectification and the Fill-in Rectificati
    
[^97]: 实现基因表达数据科学发现的AI科学家团队

    Toward a Team of AI-made Scientists for Scientific Discovery from Gene Expression Data

    [https://arxiv.org/abs/2402.12391](https://arxiv.org/abs/2402.12391)

    引入了一个名为AI科学家团队（TAIS）的框架，旨在简化科学发现流程，由模拟角色协作，特别关注于识别具有疾病预测价值的基因

    

    机器学习已成为科学发现的强大工具，使研究人员能够从复杂数据集中提取有意义的见解。我们引入了一个新颖的框架，名为AI科学家团队（TAIS），旨在简化科学发现流程。TAIS包括模拟角色，包括项目经理、数据工程师和领域专家，每个角色由大型语言模型（LLM）代表。这些角色协作以复制数据科学家通常执行的任务，特别关注于识别具有疾病预测价值的基因。

    arXiv:2402.12391v1 Announce Type: cross  Abstract: Machine learning has emerged as a powerful tool for scientific discovery, enabling researchers to extract meaningful insights from complex datasets. For instance, it has facilitated the identification of disease-predictive genes from gene expression data, significantly advancing healthcare. However, the traditional process for analyzing such datasets demands substantial human effort and expertise for the data selection, processing, and analysis. To address this challenge, we introduce a novel framework, a Team of AI-made Scientists (TAIS), designed to streamline the scientific discovery pipeline. TAIS comprises simulated roles, including a project manager, data engineer, and domain expert, each represented by a Large Language Model (LLM). These roles collaborate to replicate the tasks typically performed by data scientists, with a specific focus on identifying disease-predictive genes. Furthermore, we have curated a benchmark dataset t
    
[^98]: 模拟失调: 大型语言模型的安全对齐可能会适得其反！

    Emulated Disalignment: Safety Alignment for Large Language Models May Backfire!

    [https://arxiv.org/abs/2402.12343](https://arxiv.org/abs/2402.12343)

    安全对齐的大型语言模型可能会通过模拟失调框架，在对抗性操纵下产生危险结果，对训练的语言模型具有双倍有害性，高于强基线，强调了即使在安全对齐后也需要重新评估开源语言模型的重要性。

    

    大型语言模型（LLMs）需要进行安全对齐，以确保与人类进行安全的对话。然而，在这项工作中，我们引入了一种推理时攻击框架，表明安全对齐也可能在对抗性操纵下无意中促成有害结果。这个框架被命名为模拟失调（ED），在输出空间中不良地组合了一对开源预训练和安全对齐的语言模型，产生了一个有害的语言模型而无需任何训练。我们对ED在三个数据集和四个模型系列（Llama-1、Llama-2、Mistral和Alpaca）上的实验表明，ED使预训练模型的有害性增加了一倍，并胜过强基线，以较大优势在48个评估子集中的43个中实现了最高的有害率。至关重要的是，我们的研究结果凸显了即使在安全对齐后，重新评估开源语言模型实践的重要性。

    arXiv:2402.12343v1 Announce Type: new  Abstract: Large language models (LLMs) need to undergo safety alignment to ensure safe conversations with humans. However, in this work, we introduce an inference-time attack framework, demonstrating that safety alignment can also unintentionally facilitate harmful outcomes under adversarial manipulation. This framework, named Emulated Disalignment (ED), adversely combines a pair of open-source pre-trained and safety-aligned language models in the output space to produce a harmful language model without any training. Our experiments with ED across three datasets and four model families (Llama-1, Llama-2, Mistral, and Alpaca) show that ED doubles the harmfulness of pre-trained models and outperforms strong baselines, achieving the highest harmful rate in 43 out of 48 evaluation subsets by a large margin. Crucially, our findings highlight the importance of reevaluating the practice of open-sourcing language models even after safety alignment.
    
[^99]: 因果平等保护与算法公平性

    Causal Equal Protection as Algorithmic Fairness

    [https://arxiv.org/abs/2402.12062](https://arxiv.org/abs/2402.12062)

    本文提出了一种新的算法公平性原则——平等保护，其关键在于将错误分类的风险均等化，避免了许多对传统分类平等原则的反例。

    

    过去十年，计算机科学和哲学的文献形成了不同的算法公平性标准。其中最受争议的分类平等要求，预测算法的错误分类在被保护特征所指示的群体中以相等频率发生。尽管分类平等具有直观吸引力，但已受到攻击。我们转向一个相关原则，即平等保护，该原则最初是在刑事司法领域发展起来的。平等保护的关键在于将错误分类的风险（将在规定的意义上具体说明）进行均等化，而不是将错误分类的比率均等化。我们展示了平等保护避免了许多对分类平等的反例。

    arXiv:2402.12062v1 Announce Type: cross  Abstract: Over the last ten years the literature in computer science and philosophy has formulated different criteria of algorithmic fairness. One of the most discussed, classification parity, requires that the erroneous classifications of a predictive algorithm occur with equal frequency for groups picked out by protected characteristics. Despite its intuitive appeal, classification parity has come under attack. Multiple scenarios can be imagined in which - intuitively - a predictive algorithm does not treat any individual unfairly, and yet classification parity is violated. To make progress, we turn to a related principle, equal protection, originally developed in the context of criminal justice. Key to equal protection is equalizing the risks of erroneous classifications (in a sense to be specified) as opposed to equalizing the rates of erroneous classifications. We show that equal protection avoids many of the counterexamples to classificati
    
[^100]: 从实际到逻辑再到实际：为规划从原始数据中发明符号词汇、动作和模型

    From Reals to Logic and Back: Inventing Symbolic Vocabularies, Actions and Models for Planning from Raw Data

    [https://arxiv.org/abs/2402.11871](https://arxiv.org/abs/2402.11871)

    本文提出了一种从未标记高维实值机器人轨迹开始自主学习通用的逻辑相关表示，这些表示构成了自动发明的PDDL-like域模型。

    

    手工制作的基于逻辑的状态和动作表示已被广泛用于克服长期人工智能机器人规划问题的计算复杂性，包括任务和动作规划问题。但是，创建这样的表示需要具有强烈直觉和详细知识的专家，他们了解机器人和在特定环境中可能需要完成的任务。消除对人类直觉的依赖是一个极为活跃的研究领域。 本文提出了一种自主学习通用逻辑相关表示的方法，该表示从未标记的高维实值机器人轨迹开始。所学表示构成了自动发明的类PDDL域模型。确定性设置下的实证结果表明，仅从少数机器人轨迹中可以学到强大的抽象表示；所学关系

    arXiv:2402.11871v1 Announce Type: cross  Abstract: Hand-crafted, logic-based state and action representations have been widely used to overcome the intractable computational complexity of long-horizon robot planning problems, including task and motion planning problems. However, creating such representations requires experts with strong intuitions and detailed knowledge about the robot and the tasks it may need to accomplish in a given setting. Removing this dependency on human intuition is a highly active research area.   This paper presents the first approach for autonomously learning generalizable, logic-based relational representations for abstract states and actions starting from unannotated high-dimensional, real-valued robot trajectories. The learned representations constitute auto-invented PDDL-like domain models. Empirical results in deterministic settings show that powerful abstract representations can be learned from just a handful of robot trajectories; the learned relation
    
[^101]: Re-Dock: 朝向具有扩散桥的灵活和现实分子对接

    Re-Dock: Towards Flexible and Realistic Molecular Docking with Diffusion Bridge

    [https://arxiv.org/abs/2402.11459](https://arxiv.org/abs/2402.11459)

    提出了一种新颖的扩散桥生成模型 Re-Dock，用于灵活和现实的分子对接，通过能量到几何映射来共同建模结合能和构象，填补了对接中的实用性和构象预测方面的差距

    

    准确预测蛋白质-配体结合结构，即分子对接任务对于药物设计至关重要，但仍然具有挑战性。尽管深度学习显示出了潜力，但现有方法通常依赖于完整蛋白质结构（对接，且在现实任务中不可达）或忽略口袋侧链构象，导致有限的实用性和不切实际的构象预测。为填补这些差距，我们引入了一个未经探索的任务，命名为柔性对接，以同时预测配体和口袋侧链的姿势，并引入了一种扩展到几何流形的新型扩散桥生成模型 Re-Dock。具体而言，我们提出了受牛顿-欧拉方程启发的能量到几何映射，以共同建模结合能和构象，以反映能量约束对接生成过程。我们在设计的基准数据集上进行了全面的实验，包括apo-dock和cross-dock d

    arXiv:2402.11459v1 Announce Type: cross  Abstract: Accurate prediction of protein-ligand binding structures, a task known as molecular docking is crucial for drug design but remains challenging. While deep learning has shown promise, existing methods often depend on holo-protein structures (docked, and not accessible in realistic tasks) or neglect pocket sidechain conformations, leading to limited practical utility and unrealistic conformation predictions. To fill these gaps, we introduce an under-explored task, named flexible docking to predict poses of ligand and pocket sidechains simultaneously and introduce Re-Dock, a novel diffusion bridge generative model extended to geometric manifolds. Specifically, we propose energy-to-geometry mapping inspired by the Newton-Euler equation to co-model the binding energy and conformations for reflecting the energy-constrained docking generative process. Comprehensive experiments on designed benchmark datasets including apo-dock and cross-dock d
    
[^102]: SciAgent: 工具增强型语言模型用于科学推理

    SciAgent: Tool-augmented Language Models for Scientific Reasoning

    [https://arxiv.org/abs/2402.11451](https://arxiv.org/abs/2402.11451)

    引入了工具增强型科学推理的新任务设置，通过提供可扩展的工具集，帮助大型语言模型在科学问题解决中变得更加实用和可解决。

    

    科学推理对于即使最先进的大型语言模型（LLMs）来说也是一项巨大挑战。为了使LLMs更加实用和可解决此任务，我们引入了一种名为工具增强型科学推理的新任务设置。这种设置通过为LLMs提供可扩展的工具集，将重点从追求全知问题求解器转变为熟练使用工具的人。为了促进这种设置的研究，我们构建了一个名为MathFunc的工具增强型训练语料库，涵盖了超过30,000个样本和大约6,000个工具。基于MathFunc，我们开发了SciAgent，用于检索、理解，以及必要时使用工具进行科学问题解决。此外，我们构建了一个名为SciToolBench的基准，涵盖五个科学领域，以评估LLMs在工具辅助下的能力。对SciToolBench进行的大量实验验证了SciAgent的有效性。值得注意的是，SciAgent-Mistral-7B超过了其他LLMs。

    arXiv:2402.11451v1 Announce Type: cross  Abstract: Scientific reasoning poses an excessive challenge for even the most advanced Large Language Models (LLMs). To make this task more practical and solvable for LLMs, we introduce a new task setting named tool-augmented scientific reasoning. This setting supplements LLMs with scalable toolsets, and shifts the focus from pursuing an omniscient problem solver to a proficient tool-user. To facilitate the research of such setting, we construct a tool-augmented training corpus named MathFunc which encompasses over 30,000 samples and roughly 6,000 tools. Building on MathFunc, we develop SciAgent to retrieve, understand and, if necessary, use tools for scientific problem solving. Additionally, we craft a benchmark, SciToolBench, spanning five scientific domains to evaluate LLMs' abilities with tool assistance. Extensive experiments on SciToolBench confirm the effectiveness of SciAgent. Notably, SciAgent-Mistral-7B surpasses other LLMs with the sa
    
[^103]: 在比较之前进行推理：LLM增强的语义相似度度量用于领域专门文本分析

    Reasoning before Comparison: LLM-Enhanced Semantic Similarity Metrics for Domain Specialized Text Analysis

    [https://arxiv.org/abs/2402.11398](https://arxiv.org/abs/2402.11398)

    通过利用LLM增强语义分析，开发了用于文本的相似度度量框架，可显著改善文本的语义相似性评估，并可扩展到其他专业领域。

    

    在这项研究中，我们利用LLM来增强语义分析，为文本开发相似度度量，解决传统无监督NLP度量（如ROUGE和BLEU）的局限性。我们开发了一个框架，其中LLM（例如GPT-4）用于零样本文本识别和放射学报告的标签生成，在那里这些标签然后被用作文本相似性的度量。通过在MIMIC数据集上测试所提出的框架，我们发现GPT-4生成的标签能够显著改善语义相似度评估，得分更接近临床实际情况比传统NLP度量。我们的工作展示了使用LLM进行高度专业领域的文本数据的语义分析的可能性，具有半定量推理结果。虽然该框架针对放射学报告相似性分析进行了实施，但其概念可以扩展到其他专门领域。

    arXiv:2402.11398v1 Announce Type: cross  Abstract: In this study, we leverage LLM to enhance the semantic analysis and develop similarity metrics for texts, addressing the limitations of traditional unsupervised NLP metrics like ROUGE and BLEU. We develop a framework where LLMs such as GPT-4 are employed for zero-shot text identification and label generation for radiology reports, where the labels are then used as measurements for text similarity. By testing the proposed framework on the MIMIC data, we find that GPT-4 generated labels can significantly improve the semantic similarity assessment, with scores more closely aligned with clinical ground truth than traditional NLP metrics. Our work demonstrates the possibility of conducting semantic analysis of the text data using semi-quantitative reasoning results by the LLMs for highly specialized domains. While the framework is implemented for radiology report similarity analysis, its concept can be extended to other specialized domains 
    
[^104]: 基于信任区域的黑盒概率认证解释

    Trust Regions for Explanations via Black-Box Probabilistic Certification

    [https://arxiv.org/abs/2402.11168](https://arxiv.org/abs/2402.11168)

    通过黑盒概率认证解释的信任区域能够有效地洞察模型行为、保证解释的稳定性，并实现解释的重用

    

    由于机器学习模型的黑盒性质，人们开发了大量的可解释性方法来解析个别决策背后的因素。本文提出了一个新颖的黑盒（概率性）解释认证问题。我们提出了一个问题：给定一个黑盒模型，只有查询访问权，一个示例的解释以及一个质量度量（如逼真度、稳定性），我们是否能找到最大的超立方体（即 $\ell_{\infty}$ 球），以示例为中心，使得当解释被应用于超立方体内的所有示例时（高概率下）质量标准得到满足（比如逼真度高于某个值）？能够高效地找到这样一个信任区域有多重好处：i）洞察模型在一个区域内的行为，具有保证；ii）解释的稳定性得到保证；iii）解释的重用，可以节省时间、精力和金钱。

    arXiv:2402.11168v1 Announce Type: cross  Abstract: Given the black box nature of machine learning models, a plethora of explainability methods have been developed to decipher the factors behind individual decisions. In this paper, we introduce a novel problem of black box (probabilistic) explanation certification. We ask the question: Given a black box model with only query access, an explanation for an example and a quality metric (viz. fidelity, stability), can we find the largest hypercube (i.e., $\ell_{\infty}$ ball) centered at the example such that when the explanation is applied to all examples within the hypercube, (with high probability) a quality criterion is met (viz. fidelity greater than some value)? Being able to efficiently find such a \emph{trust region} has multiple benefits: i) insight into model behavior in a \emph{region}, with a \emph{guarantee}; ii) ascertained \emph{stability} of the explanation; iii) \emph{explanation reuse}, which can save time, energy and mone
    
[^105]: 加速半异步联邦学习

    Accelerating Semi-Asynchronous Federated Learning

    [https://arxiv.org/abs/2402.10991](https://arxiv.org/abs/2402.10991)

    提出了一种考虑贡献的异步联邦学习方法，动态调整接收到的更新的处理方式，以解决现实情况下同步上传数据可能出现的缓慢和不可靠问题。

    

    联邦学习（FL）是一种分布式机器学习范例，允许客户端在保护隐私的同时在其数据上训练模型。现有的FL算法，如Federated Averaging（FedAvg）及其变种，在许多情况下已经被证明收敛良好。然而，这些方法需要客户端以同步方式将其本地更新上传至服务器，这在现实情况下可能会变得缓慢和不可靠。为了解决这个问题，研究人员开发了异步FL方法，允许客户端继续使用陈旧的全局模型对其本地数据进行训练。然而，大多数这些方法仅仅聚合了所有接收到的更新，而没有考虑其相对贡献，这可能导致收敛速度变慢。在本文中，我们提出了一种考虑贡献的异步FL方法，考虑了接收到的更新的陈旧程度和统计异质性。我们的方法动态调整

    arXiv:2402.10991v1 Announce Type: cross  Abstract: Federated Learning (FL) is a distributed machine learning paradigm that allows clients to train models on their data while preserving their privacy. FL algorithms, such as Federated Averaging (FedAvg) and its variants, have been shown to converge well in many scenarios. However, these methods require clients to upload their local updates to the server in a synchronous manner, which can be slow and unreliable in realistic FL settings. To address this issue, researchers have developed asynchronous FL methods that allow clients to continue training on their local data using a stale global model. However, most of these methods simply aggregate all of the received updates without considering their relative contributions, which can slow down convergence. In this paper, we propose a contribution-aware asynchronous FL method that takes into account the staleness and statistical heterogeneity of the received updates. Our method dynamically adju
    
[^106]: CHEMREASONER：使用量子化学反馈在大型语言模型的知识空间中进行启发式搜索

    CHEMREASONER: Heuristic Search over a Large Language Model's Knowledge Space using Quantum-Chemical Feedback

    [https://arxiv.org/abs/2402.10980](https://arxiv.org/abs/2402.10980)

    通过将大型语言模型推理与量子化学反馈相结合，我们引入了一个AI引导的计算筛选框架，将催化剂发现形式化为一个不确定环境，从而实现高效催化剂的积极搜索

    

    arXiv:2402.10980v1 类型公告：跨领域 摘要：发现新的催化剂对于设计新的更高效的化学过程至关重要，以实现向可持续未来的过渡。我们引入了一种人工智能引导的计算筛选框架，将语言推理与基于量子化学的三维原子表示的反馈统一起来。我们的方法将催化剂发现构建为一个不确定环境，其中一个代理通过大型语言模型（LLM）推导的假设与基于原子图神经网络（GNN）的反馈的迭代组合，积极搜索高效催化剂。在中间搜索步骤确定的催化剂经过基于空间定向、反应途径和稳定性的结构评估。基于吸附能和势垒的评分函数引导在LLM的知识空间中向能量有利、高效的催化剂探索。我们引入了可以自动规划的方法

    arXiv:2402.10980v1 Announce Type: cross  Abstract: The discovery of new catalysts is essential for the design of new and more efficient chemical processes in order to transition to a sustainable future. We introduce an AI-guided computational screening framework unifying linguistic reasoning with quantum-chemistry based feedback from 3D atomistic representations. Our approach formulates catalyst discovery as an uncertain environment where an agent actively searches for highly effective catalysts via the iterative combination of large language model (LLM)-derived hypotheses and atomistic graph neural network (GNN)-derived feedback. Identified catalysts in intermediate search steps undergo structural evaluation based on spatial orientation, reaction pathways, and stability. Scoring functions based on adsorption energies and barriers steer the exploration in the LLM's knowledge space toward energetically favorable, high-efficiency catalysts. We introduce planning methods that automaticall
    
[^107]: 在一个 1000 万根草垛中寻找针：循环记忆找到了语言模型不擅长的内容

    In Search of Needles in a 10M Haystack: Recurrent Memory Finds What LLMs Miss

    [https://arxiv.org/abs/2402.10790](https://arxiv.org/abs/2402.10790)

    通过使用循环记忆增强对 GPT-2 进行微调，使其能够处理长达 1000 万个元素的任务，这是迄今为止处理最长输入的开放神经网络模型，并展示了对长序列处理能力的显著改进。

    

    本文解决了使用生成式 Transformer 模型处理长文档的挑战。为了评估不同方法，我们引入了 BABILong，这是一个新的基准，旨在评估模型在提取和处理广泛文本中分布式事实方面的能力。我们的评估包括 GPT-4 和 RAG 的基准，结果显示常见方法仅适用于最多 $10^4$ 个元素的序列。相反，通过使用循环记忆增强对 GPT-2 进行微调，使其能够处理涉及最多 $10^7$ 个元素的任务。这一成就标志着迄今为止任何开源神经网络模型处理的最长输入，显示了对长序列处理能力的显著改进。

    arXiv:2402.10790v1 Announce Type: cross  Abstract: This paper addresses the challenge of processing long documents using generative transformer models. To evaluate different approaches, we introduce BABILong, a new benchmark designed to assess model capabilities in extracting and processing distributed facts within extensive texts. Our evaluation, which includes benchmarks for GPT-4 and RAG, reveals that common methods are effective only for sequences up to $10^4$ elements. In contrast, fine-tuning GPT-2 with recurrent memory augmentations enables it to handle tasks involving up to $10^7$ elements. This achievement marks a substantial leap, as it is by far the longest input processed by any open neural network model to date, demonstrating a significant improvement in the processing capabilities for long sequences.
    
[^108]: 在InSaAF中融入安全性，通过准确性和公平性 | LLM是否已经准备好进入印度法律领域？

    InSaAF: Incorporating Safety through Accuracy and Fairness | Are LLMs ready for the Indian Legal Domain?

    [https://arxiv.org/abs/2402.10567](https://arxiv.org/abs/2402.10567)

    本研究在印度法律领域探讨了大型语言模型（LLMs）在处理社会因素时的能力，提出了结合公平性和准确性的新指标$LSS_{\beta}$，并评估了模型在二元法律推理任务中的表现以及在印度社会各种不平等方面的公平性展示。

    

    语言技术和人工智能的最新进展已经导致提出了众多语言模型，用于执行法律领域的各种任务，从预测判决到生成摘要。尽管它们具有巨大潜力，但已经证明这些模型学习并展示社会偏见，并做出不公平的预测。在这项研究中，我们探讨了当涉及社会因素时大型语言模型（LLMs）在印度法律领域执行任务的能力。我们提出了一种新颖的度量标准，$\beta$-加权的$\textit{法律安全分数($LSS_{\beta}$)}$，将LLM的公平性和准确性两个方面结合起来。我们通过考虑LLM在$\textit{二元法律推理}$任务中的表现以及其在印度社会各种不平等方面的公平展示来评估LLMs的安全性。LLaMA和LLaMA--2模型的任务表现和公平得分表明...

    arXiv:2402.10567v1 Announce Type: cross  Abstract: Recent advancements in language technology and Artificial Intelligence have resulted in numerous Language Models being proposed to perform various tasks in the legal domain ranging from predicting judgments to generating summaries. Despite their immense potential, these models have been proven to learn and exhibit societal biases and make unfair predictions. In this study, we explore the ability of Large Language Models (LLMs) to perform legal tasks in the Indian landscape when social factors are involved. We present a novel metric, $\beta$-weighted $\textit{Legal Safety Score ($LSS_{\beta}$)}$, which encapsulates both the fairness and accuracy aspects of the LLM. We assess LLMs' safety by considering its performance in the $\textit{Binary Statutory Reasoning}$ task and its fairness exhibition with respect to various axes of disparities in the Indian society. Task performance and fairness scores of LLaMA and LLaMA--2 models indicate th
    
[^109]: 通过分布偏好奖励建模对齐众包反馈

    Aligning Crowd Feedback via Distributional Preference Reward Modeling

    [https://arxiv.org/abs/2402.09764](https://arxiv.org/abs/2402.09764)

    本文提出了一种名为分布偏好奖励模型的框架，用于将大型语言模型与多样的人类偏好对齐。该框架使用贝塔分布刻画偏好，并设计了基于最优输运的损失函数来校准模型与偏好的对齐程度。最终利用期望奖励微调语言模型的策略。

    

    深度强化学习广泛用于将大型语言模型与人类偏好对齐。然而，传统的奖励建模主要依赖于一组个体提供的人类标注。这种依赖可能会导致模型倾向于反映这些标注者的倾向，从而未能充分代表更广泛人群的期望。本文介绍了一种简单而有效的框架——分布偏好奖励模型(DPRM)，以将大型语言模型与多样的人类偏好对齐。为此，我们使用贝塔分布来刻画偏好，该分布能够动态适应偏好趋势的波动。在此基础上，我们设计了基于最优输运的损失函数，以校准DPRM与偏好分布的对齐度。最后，利用期望奖励来微调语言模型的策略。

    arXiv:2402.09764v1 Announce Type: new  Abstract: Deep Reinforcement Learning is widely used for aligning Large Language Models (LLM) with human preference. However, the conventional reward modelling has predominantly depended on human annotations provided by a select cohort of individuals. Such dependence may unintentionally result in models that are skewed to reflect the inclinations of these annotators, thereby failing to represent the expectations of the wider population adequately. In this paper, we introduce the Distributional Preference Reward Model (DPRM), a simple yet effective framework to align large language models with a diverse set of human preferences. To this end, we characterize the preferences by a beta distribution, which can dynamically adapt to fluctuations in preference trends. On top of that, we design an optimal-transportation-based loss to calibrate DPRM to align with the preference distribution. Finally, the expected reward is utilized to fine-tune an LLM polic
    
[^110]: 用户建模与用户画像：综述

    User Modeling and User Profiling: A Comprehensive Survey

    [https://arxiv.org/abs/2402.09660](https://arxiv.org/abs/2402.09660)

    这篇综述论文介绍了用户建模与用户画像研究的现状、发展和未来方向。该研究主要关注在人工智能应用中构建准确的用户表示，包括利用大量数据进行建模以及采用深度学习和图数据技术等先进方法。

    

    人工智能（AI）融入日常生活，特别是通过信息检索和推荐系统，已经促使先进的用户建模和用户画像技术，以提供个性化体验。这些技术旨在基于与这些系统的互动中生成的大量数据构建准确的用户表示。本文对用户建模和用户画像研究的现状、发展和未来方向进行了全面综述。我们提供了一个历史概述，追溯了从早期的刻板模型到最新的深度学习技术，并提出了一个新的分类体系，涵盖了这一研究领域中的所有活动主题，包括最近的趋势。我们的综述突出了向更复杂的用户画像方法的范式转变，强调了隐式数据收集、多行为建模以及图数据的整合。

    arXiv:2402.09660v1 Announce Type: new  Abstract: The integration of artificial intelligence (AI) into daily life, particularly through information retrieval and recommender systems, has necessitated advanced user modeling and profiling techniques to deliver personalized experiences. These techniques aim to construct accurate user representations based on the rich amounts of data generated through interactions with these systems. This paper presents a comprehensive survey of the current state, evolution, and future directions of user modeling and profiling research. We provide a historical overview, tracing the development from early stereotype models to the latest deep learning techniques, and propose a novel taxonomy that encompasses all active topics in this research area, including recent trends. Our survey highlights the paradigm shifts towards more sophisticated user profiling methods, emphasizing implicit data collection, multi-behavior modeling, and the integration of graph data
    
[^111]: 基于自驱动传感器和深度学习的人工智能应用进展

    Progress in artificial intelligence applications based on the combination of self-driven sensors and deep learning

    [https://arxiv.org/abs/2402.09442](https://arxiv.org/abs/2402.09442)

    本文介绍了基于自驱动传感器和深度学习的人工智能应用的最新进展，重点讨论了使用TENG作为自驱动传感器的优势，包括简单结构和高瞬时性能。

    

    在物联网时代，如何开发具有可持续电源供应、易于部署和灵活使用的智能传感器系统已成为一个难题。传统的电源供应存在频繁更换或使用时充电等问题，这限制了可穿戴设备的发展。通过使用聚四氟乙烯（PTFE）和铝箔（AI）制备接触-分离摩擦纳米发电机（TENG）来收集人体运动能量，根据输出电信号的变化来监测人体运动姿势。 2012年，王中林院士及其团队发明了摩擦电纳米发电机（TENG），它利用最大位移电流作为驱动力，将机械刺激直接转换为电信号，因此可以用作自驱动传感器。TENG传感器具有结构简单和瞬时性高的优点。

    arXiv:2402.09442v1 Announce Type: cross  Abstract: In the era of Internet of Things, how to develop a smart sensor system with sustainable power supply, easy deployment and flexible use has become a difficult problem to be solved. The traditional power supply has problems such as frequent replacement or charging when in use, which limits the development of wearable devices. The contact-to-separate friction nanogenerator (TENG) was prepared by using polychotomy thy lene (PTFE) and aluminum (AI) foils. Human motion energy was collected by human body arrangement, and human motion posture was monitored according to the changes of output electrical signals. In 2012, Academician Wang Zhong lin and his team invented the triboelectric nanogenerator (TENG), which uses Maxwell displacement current as a driving force to directly convert mechanical stimuli into electrical signals, so it can be used as a self-driven sensor. Teng-based sensors have the advantages of simple structure and high instant
    
[^112]: 说服、委托和私有信息在算法辅助决策中的应用

    Persuasion, Delegation, and Private Information in Algorithm-Assisted Decisions

    [https://arxiv.org/abs/2402.09384](https://arxiv.org/abs/2402.09384)

    一篇论文研究了在算法辅助决策中，如何设计最优的预测算法和委托规则。关键发现包括：委托的最优性与委托人是否会做出与代理人相同的决策有关、最具信息量的算法不一定是最优的、常见的算法限制会降低决策质量。

    

    一位委托人设计了一个算法，该算法生成一个公开可见的二进制状态预测。她必须决定是根据预测直接行动还是将决策委托给一个代理人，该代理人具有私有信息但可能存在不对齐问题。我们研究了在这种环境下预测算法和委托规则的最优设计。得出了三个关键发现：(1)只有当委托人在观察到代理人的信息时会做出与代理人相同的二进制决策时，委托才是最优的。(2)提供最具信息量的算法可能并不是最优的，即使委托人可以根据算法的预测来行动。相反，最优算法可能提供更多关于一个状态的信息，并限制关于另一个状态的信息。(3)在没有完美的预测准确性的情况下，常见的对算法的限制，如保持"人机合作"或要求最大预测精度，会严重降低决策质量。

    arXiv:2402.09384v1 Announce Type: cross Abstract: A principal designs an algorithm that generates a publicly observable prediction of a binary state. She must decide whether to act directly based on the prediction or to delegate the decision to an agent with private information but potential misalignment. We study the optimal design of the prediction algorithm and the delegation rule in such environments. Three key findings emerge: (1) Delegation is optimal if and only if the principal would make the same binary decision as the agent had she observed the agent's information. (2) Providing the most informative algorithm may be suboptimal even if the principal can act on the algorithm's prediction. Instead, the optimal algorithm may provide more information about one state and restrict information about the other. (3) Common restrictions on algorithms, such as keeping a "human-in-the-loop" or requiring maximal prediction accuracy, strictly worsen decision quality in the absence of perfec
    
[^113]: 证据深度学习方法是否准确地表示认识不确定性？

    Is Epistemic Uncertainty Faithfully Represented by Evidential Deep Learning Methods?

    [https://arxiv.org/abs/2402.09056](https://arxiv.org/abs/2402.09056)

    本论文提出了关于证据深度学习的新理论洞见, 高亮了在优化二阶损失函数和解释得出的认识不确定性度量上的困难性

    

    可信的机器学习系统不仅应返回准确的预测结果，还应提供可靠的不确定性表示。贝叶斯方法常用于量化不确定性，但近年来，证据深度学习方法等替代方法也变得流行起来。后者本质上扩展了经验风险最小化（ERM），用于预测结果的二阶概率分布，从中可以提取认识（和随机）不确定性的度量。本文提供了证据深度学习的新理论洞见，强调了优化二阶损失函数以及解释结果认识不确定性度量的困难性。通过系统化的设置，涵盖了分类、回归和计数的广泛方法，这篇论文为可辨识性和收敛性问题提供了新的洞察。

    arXiv:2402.09056v1 Announce Type: new Abstract: Trustworthy ML systems should not only return accurate predictions, but also a reliable representation of their uncertainty. Bayesian methods are commonly used to quantify both aleatoric and epistemic uncertainty, but alternative approaches, such as evidential deep learning methods, have become popular in recent years. The latter group of methods in essence extends empirical risk minimization (ERM) for predicting second-order probability distributions over outcomes, from which measures of epistemic (and aleatoric) uncertainty can be extracted. This paper presents novel theoretical insights of evidential deep learning, highlighting the difficulties in optimizing second-order loss functions and interpreting the resulting epistemic uncertainty measures. With a systematic setup that covers a wide range of approaches for classification, regression and counts, it provides novel insights into issues of identifiability and convergence in second-o
    
[^114]: SAGMAN: 用于图神经网络在流形上的稳定性分析的方法

    SAGMAN: Stability Analysis of Graph Neural Networks on the Manifolds

    [https://arxiv.org/abs/2402.08653](https://arxiv.org/abs/2402.08653)

    SAGMAN是一种用于检验图神经网络稳定性的谱框架，它通过评估非线性映射中的距离失真来衡量GNN的稳定性。为了进行有意义的稳定性分析，我们提出了一种距离保持的图降维方法。

    

    现代图神经网络（GNN）对输入图结构和节点特征的变化敏感，可能导致不可预测的行为和性能下降。本文引入了一种称为SAGMAN的谱框架，用于检验GNN的稳定性。该框架评估非线性映射中GNN在输入和输出流形之间引起的距离失真: 当输入流行中两个附近的节点（通过GNN模型）被映射到输出流行上的两个远离的节点时，意味着存在较大的距离失真，从而导致GNN的稳定性较差。我们提出了一种距离保持的图降维（GDR）方法，利用谱图嵌入和概率图模型（PGMs）来创建低维的输入/输出基于图的流形，以进行有意义的稳定性分析。我们的实证评估表明，SAGMAN能够有效评估每个节点在面对不同边缘或特征扰动时的稳定性。

    Modern graph neural networks (GNNs) can be sensitive to changes in the input graph structure and node features, potentially resulting in unpredictable behavior and degraded performance. In this work, we introduce a spectral framework known as SAGMAN for examining the stability of GNNs. This framework assesses the distance distortions that arise from the nonlinear mappings of GNNs between the input and output manifolds: when two nearby nodes on the input manifold are mapped (through a GNN model) to two distant ones on the output manifold, it implies a large distance distortion and thus a poor GNN stability. We propose a distance-preserving graph dimension reduction (GDR) approach that utilizes spectral graph embedding and probabilistic graphical models (PGMs) to create low-dimensional input/output graph-based manifolds for meaningful stability analysis. Our empirical evaluations show that SAGMAN effectively assesses the stability of each node when subjected to various edge or feature pe
    
[^115]: 可扩展大型语言模型微调的差分隐私零阶方法

    Differentially Private Zeroth-Order Methods for Scalable Large Language Model Finetuning

    [https://arxiv.org/abs/2402.07818](https://arxiv.org/abs/2402.07818)

    本文研究了差分隐私零阶方法在大型语言模型微调中的应用，该方法通过使用零阶梯度来避免传统优化方法的可扩展性瓶颈，实现了在隐私、效用和可扩展性之间的良好平衡。

    

    在特定任务的数据集上进行微调是利用预训练语言模型的强大能力进行各种下游任务的广泛接受的范例。由于预训练语言模型微调的普及以及与之相关的隐私问题，差分隐私预训练语言模型微调引起了越来越多的关注，以保护特定任务数据集的隐私。差分隐私预训练语言模型微调方法的设计核心是在隐私、效用和可扩展性之间达到满意的权衡。大多数现有方法都是基于DP-SGD的创新性工作。尽管将DP-SGD的可扩展性推到了极限，但基于DP-SGD的微调方法不幸地受到了SGD固有低效率的限制。在本文中，我们研究了DP零阶方法在LLM预训练中的潜力，该方法通过用更高效的零阶梯度来近似梯度，避免了SGD的可扩展性瓶颈。与将零阶方法作为一种替代方法进行处理不同，我们引入了一种新的割接框架，该框架能够以非常接近的方式模拟DP-SGD的基本操作，然后利用零阶优化方法来近似梯度。

    Finetuning on task-specific datasets is a widely-embraced paradigm of harnessing the powerful capability of pretrained LLMs for various downstream tasks. Due to the popularity of LLMs finetuning and its accompanying privacy concerns, differentially private (DP) finetuning of pretrained LLMs has garnered increasing attention to safeguarding the privacy of task-specific datasets. Lying at the design core of DP LLM finetuning methods is the satisfactory tradeoff between privacy, utility, and scalability. Most existing methods build upon the seminal work of DP-SGD. Despite pushing the scalability of DP-SGD to its limit, DP-SGD-based finetuning methods are unfortunately limited by the inherent inefficiency of SGD. In this paper, we investigate the potential of DP zeroth-order methods for LLM pretraining, which avoids the scalability bottleneck of SGD by approximating the gradient with the more efficient zeroth-order gradient. Rather than treating the zeroth-order method as a drop-in replace
    
[^116]: DeAL：用于大型语言模型的解码时对齐

    DeAL: Decoding-time Alignment for Large Language Models

    [https://arxiv.org/abs/2402.06147](https://arxiv.org/abs/2402.06147)

    DeAL是一个允许用户自定义奖励函数并实现解码时对齐LLMs的框架。

    

    大型语言模型（LLMs）现在期望生成与人类偏好对齐的内容。目前的工作主要集中在模型训练时间对齐上，通过诸如强化学习与人类反馈（RLHF）等技术。然而，目前还不清楚这些方法是否有效地教导模型对齐目标。首先，无法整合多个自定义奖励和依赖模型开发者对通用和静态原则的理解是主要局限。其次，模型训练中的残留差距以及这些方法的可靠性也值得质疑（例如，即使在安全训练后仍然容易被越狱）。为了解决这些问题，我们提出了DeAL，一个允许用户自定义奖励函数并实现解码时对齐LLMs（DeAL）的框架。核心思想在于将解码视为一个启发式引导的搜索过程，并促使使用各种对齐目标。我们的实验以编程约束为例进行了验证。

    Large Language Models (LLMs) are nowadays expected to generate content aligned with human preferences. Current work focuses on alignment at model training time, through techniques such as Reinforcement Learning with Human Feedback (RLHF). However, it is unclear if such methods are an effective choice to teach alignment objectives to the model. First, the inability to incorporate multiple, custom rewards and reliance on a model developer's view of universal and static principles are key limitations. Second, the residual gaps in model training and the reliability of such approaches are also questionable (e.g. susceptibility to jail-breaking even after safety training). To address these, we propose DeAL, a framework that allows the user to customize reward functions and enables Decoding-time Alignment of LLMs (DeAL). At its core, we view decoding as a heuristic-guided search process and facilitate the use of a wide variety of alignment objectives. Our experiments with programmatic constra
    
[^117]: InkSight：通过学习阅读和书写实现离线到在线手写转换

    InkSight: Offline-to-Online Handwriting Conversion by Learning to Read and Write

    [https://arxiv.org/abs/2402.05804](https://arxiv.org/abs/2402.05804)

    InkSight是一个可以将离线手写转换为在线手写的系统，通过结合阅读和书写先验知识，在多样化的照片中有效地Derendering手写文本。

    

    数字笔记正在变得越来越受欢迎，提供了一种耐用、可编辑和易于索引的存储笔记的方式，即矢量化形式的数字墨水。然而，这种笔记方式与传统的纸笔记方式之间仍存在显著差距，而传统纸笔记方式仍受到绝大多数人的青睐。我们的工作InkSight旨在弥合这种差距，使实体笔记者能够轻松地将他们的作品（离线手写）转换为数字墨水（在线手写），这个过程我们称之为Derendering。之前关于此主题的研究集中在图像的几何属性上，导致了在训练领域之外的有限泛化能力。我们的方法结合了阅读和书写的先验知识，允许在缺乏大量配对样本的情况下训练模型，而这些配对样本很难获取。据我们所知，这是第一个有效地对具有多样化视觉特征和背景的任意照片中的手写文本进行Derendering的工作。

    Digital note-taking is gaining popularity, offering a durable, editable, and easily indexable way of storing notes in the vectorized form, known as digital ink. However, a substantial gap remains between this way of note-taking and traditional pen-and-paper note-taking, a practice still favored by a vast majority. Our work, InkSight, aims to bridge the gap by empowering physical note-takers to effortlessly convert their work (offline handwriting) to digital ink (online handwriting), a process we refer to as Derendering. Prior research on the topic has focused on the geometric properties of images, resulting in limited generalization beyond their training domains. Our approach combines reading and writing priors, allowing training a model in the absence of large amounts of paired samples, which are difficult to obtain. To our knowledge, this is the first work that effectively derenders handwritten text in arbitrary photos with diverse visual characteristics and backgrounds. Furthermore,
    
[^118]: 《岩石编码，不是开发-一个以人为中心的LLM在软件工程任务中的实验评估》

    Rocks Coding, Not Development--A Human-Centric, Experimental Evaluation of LLM-Supported SE Tasks

    [https://arxiv.org/abs/2402.05650](https://arxiv.org/abs/2402.05650)

    这项研究提出了一种自监督学习框架，用于训练神经网络从未标记的多感官数据中学习丰富而有意义的3D场景表示。通过利用不同感觉模态之间的时间一致性和几何对齐，我们的框架能够学习到强大而准确的表示。我们将我们的方法应用于各种3D感知任务，并与监督基线进行了比较，展示了竞争性的性能。此外，我们还展示了我们学到的表示在不同的传感器设置下具有很好的泛化能力，进一步突显了我们的自监督学习方法的有效性和多功能性。

    

    最近，基于大型语言模型（LLM）的生成型AI因其在多个领域中令人印象深刻的高质量表现而备受关注，特别是在ChatGPT发布之后。许多人认为它们有潜力在软件开发中执行通用问题解决，并取代人类软件开发人员。然而，目前没有对这些LLM技术在完成软件开发任务方面的能力进行深入调查。在一项有109名参与者的受控 2x2 受试者间实验中，我们研究了与ChatGPT合作在编码任务和典型软件开发任务中的效用程度以及人们如何使用ChatGPT。我们发现，尽管ChatGPT在解决简单的编码问题方面表现出色，但它在支持典型的软件开发任务方面的表现并不理想。我们还观察了参与者与ChatGPT之间的互动，并找到了相互关系。

    Recently, large language models (LLM) based generative AI has been gaining momentum for their impressive high-quality performances in multiple domains, particularly after the release of the ChatGPT. Many believe that they have the potential to perform general-purpose problem-solving in software development and replace human software developers. Nevertheless, there are in a lack of serious investigation into the capability of these LLM techniques in fulfilling software development tasks. In a controlled 2 $\times$ 2 between-subject experiment with 109 participants, we examined whether and to what degree working with ChatGPT was helpful in the coding task and typical software development task and how people work with ChatGPT. We found that while ChatGPT performed well in solving simple coding problems, its performance in supporting typical software development tasks was not that good. We also observed the interactions between participants and ChatGPT and found the relations between the i
    
[^119]: 基于触觉的从颗粒介质中检索物体的研究

    Tactile-based Object Retrieval From Granular Media

    [https://arxiv.org/abs/2402.04536](https://arxiv.org/abs/2402.04536)

    这项研究介绍了一种基于触觉反馈的机器人操作方法，用于在颗粒介质中检索埋藏的物体。通过模拟传感器噪声进行端到端训练，实现了自然出现的学习推动行为，并成功将其迁移到实际硬件上。

    

    我们介绍了一种名为GEOTACT的机器人操作方法，能够在颗粒介质中检索埋藏的物体。这是一项具有挑战性的任务，因为需要与颗粒介质进行交互，并且仅依靠触觉反馈来完成，因为一个埋藏的物体可能完全被视觉隐藏。在这种环境中，触觉反馈本身具有挑战性，因为需要与周围介质进行普遍接触，并且由触觉读数引起的固有噪声水平。为了解决这些挑战，我们使用了一种通过模拟传感器噪声进行端到端训练的学习方法。我们展示了我们的问题表述导致了学习推动行为的自然出现，操作器使用这些行为来减少不确定性并将物体引导到稳定的抓取位置，尽管存在假的和噪声的触觉读数。我们还引入了一种培训方案，可以在仿真中学习这些行为，并在实际硬件上进行零样本迁移。据我们所知，GEOTACT是第一个这样的方法。

    We introduce GEOTACT, a robotic manipulation method capable of retrieving objects buried in granular media. This is a challenging task due to the need to interact with granular media, and doing so based exclusively on tactile feedback, since a buried object can be completely hidden from vision. Tactile feedback is in itself challenging in this context, due to ubiquitous contact with the surrounding media, and the inherent noise level induced by the tactile readings. To address these challenges, we use a learning method trained end-to-end with simulated sensor noise. We show that our problem formulation leads to the natural emergence of learned pushing behaviors that the manipulator uses to reduce uncertainty and funnel the object to a stable grasp despite spurious and noisy tactile readings. We also introduce a training curriculum that enables learning these behaviors in simulation, followed by zero-shot transfer to real hardware. To the best of our knowledge, GEOTACT is the first meth
    
[^120]: HEAM: 使用处理-内存进行散列嵌入加速的方法

    HEAM : Hashed Embedding Acceleration using Processing-In-Memory

    [https://arxiv.org/abs/2402.04032](https://arxiv.org/abs/2402.04032)

    HEAM是一种采用异构内存架构的方法，将3D堆叠DRAM与DIMM集成，用于加速处理大规模个性化推荐系统中的嵌入操作。

    

    在当今的数据中心中，个性化推荐系统面临着诸多挑战，特别是在执行嵌入操作时需要大容量的内存和高带宽。之前的方法依赖于DIMM-based近内存处理技术或引入3D堆叠DRAM来解决内存限制和扩展内存带宽的问题。然而，这些解决方案在处理日益扩大的个性化推荐系统大小时存在不足之处。推荐模型已经增长到超过数十TB的大小，导致在传统单节点推断服务器上高效运行变得困难。尽管已经提出了各种算法方法来减小嵌入表容量，但通常会导致内存访问增加或内存资源利用低效的问题。本文引入了HEAM，一种异构内存架构，将3D堆叠DRAM与DIMM集成在一起，以加速组合嵌入的推荐系统。

    In today's data centers, personalized recommendation systems face challenges such as the need for large memory capacity and high bandwidth, especially when performing embedding operations. Previous approaches have relied on DIMM-based near-memory processing techniques or introduced 3D-stacked DRAM to address memory-bound issues and expand memory bandwidth. However, these solutions fall short when dealing with the expanding size of personalized recommendation systems. Recommendation models have grown to sizes exceeding tens of terabytes, making them challenging to run efficiently on traditional single-node inference servers. Although various algorithmic methods have been proposed to reduce embedding table capacity, they often result in increased memory access or inefficient utilization of memory resources. This paper introduces HEAM, a heterogeneous memory architecture that integrates 3D-stacked DRAM with DIMM to accelerate recommendation systems in which compositional embedding is util
    
[^121]: SEABO: 一种简单的基于搜索的离线模仿学习方法

    SEABO: A Simple Search-Based Method for Offline Imitation Learning

    [https://arxiv.org/abs/2402.03807](https://arxiv.org/abs/2402.03807)

    SEABO是一种简单而有效的基于搜索的离线模仿学习方法，它以无监督学习的方式，根据专家数据和无标签数据得到奖励函数，实验结果表明其性能与离线强化学习相当。

    

    离线强化学习（RL）由于能够从静态离线数据集中学习并消除与环境交互的需求，受到了广泛关注。然而，离线RL的成功在很大程度上取决于标有奖励标签的离线转换。在实践中，我们经常需要手工设计奖励函数，这有时是困难的、劳动密集的或低效的。为了解决这个挑战，我们把重点放在离线模仿学习（IL）设置上，旨在基于专家数据和无标签数据得到一个奖励函数。为此，我们提出了一种简单但有效的基于搜索的离线IL方法，称为SEABO。SEABO以无监督学习的方式，将较大的奖励分配给与专家演示中最接近的转换，否则分配较小的奖励。在多个D4RL数据集上的实验结果表明，SEABO能够达到与离线RL相当的性能水平。

    Offline reinforcement learning (RL) has attracted much attention due to its ability in learning from static offline datasets and eliminating the need of interacting with the environment. Nevertheless, the success of offline RL relies heavily on the offline transitions annotated with reward labels. In practice, we often need to hand-craft the reward function, which is sometimes difficult, labor-intensive, or inefficient. To tackle this challenge, we set our focus on the offline imitation learning (IL) setting, and aim at getting a reward function based on the expert data and unlabeled data. To that end, we propose a simple yet effective search-based offline IL method, tagged SEABO. SEABO allocates a larger reward to the transition that is close to its closest neighbor in the expert demonstration, and a smaller reward otherwise, all in an unsupervised learning manner. Experimental results on a variety of D4RL datasets indicate that SEABO can achieve competitive performance to offline RL 
    
[^122]: MolTC: 在语言模型中进行分子关系建模

    MolTC: Towards Molecular Relational Modeling In Language Models

    [https://arxiv.org/abs/2402.03781](https://arxiv.org/abs/2402.03781)

    本研究提出了一种基于语言模型的多模态框架MolTC，用于分子相互作用预测，该框架能够高效地整合分子对的丰富图形信息，并通过思维链理论实现统一的分子关系学习。

    

    分子关系学习（MRL）旨在理解分子之间的相互作用，在推进生物化学研究方面起到了关键作用。最近，大型语言模型（LLMs）的采用已成为一种有效和高效的MRL方法，这些模型以其庞大的知识存储库和先进的逻辑推理能力而闻名。尽管具有潜力，但这些方法主要依赖于文本数据，因此没有充分利用分子图中固有的丰富结构信息。此外，缺乏统一的框架加剧了信息的浪费，因为它阻碍了在不同数据集之间共享学习到的相互作用理由。为了解决这些挑战，本研究提出了一种基于LLM的多模态框架，用于根据思维链（CoT）理论对分子相互作用进行预测，称为MolTC，它可以高效地整合分子对的丰富图形信息。

    Molecular Relational Learning (MRL), aiming to understand interactions between molecular pairs, plays a pivotal role in advancing biochemical research. Recently, the adoption of large language models (LLMs), known for their vast knowledge repositories and advanced logical inference capabilities, has emerged as a promising way for efficient and effective MRL. Despite their potential, these methods predominantly rely on the textual data, thus not fully harnessing the wealth of structural information inherent in molecular graphs. Moreover, the absence of a unified framework exacerbates the information underutilization, as it hinders the sharing of interaction rationale learned across diverse datasets. To address these challenges, this work proposes a novel LLM-based multi-modal framework for Molecular inTeraction prediction following Chain-of-Thought (CoT) theory, termed MolTC, which can efficiently integrate rich graphical information of molecular pairs. For achieving a unified MRL, MolT
    
[^123]: 利用类别概率进行黑盒子句级攻击

    Exploiting Class Probabilities for Black-box Sentence-level Attacks

    [https://arxiv.org/abs/2402.02695](https://arxiv.org/abs/2402.02695)

    该论文研究了在黑盒子句级攻击中利用类别概率的有效性，并开发了一种新的算法进行攻击。通过与基线方法进行对比，进行了广泛的评估。

    

    句级攻击是针对文本分类器的对抗性句子生成方法，这些句子与正确分类的句子同义，但被分类器错误地分类。在黑盒设置下，分类器只能通过对查询输入的反馈进行访问，这主要以类别概率的形式提供。尽管利用类别概率可以获得更强大的攻击效果，但由于在句级攻击中使用类别概率存在挑战，现有的攻击方法要么不使用反馈，要么仅使用类别标签。为了克服这些挑战，我们开发了一种新的算法，使用类别概率进行黑盒句级攻击，并研究了在攻击成功率上使用类别概率的有效性，并探讨了在黑盒句级攻击中使用类别概率是否值得或可行。我们在各种分类器和基准数据集上对提出的攻击方法进行了广泛评估，并与基线进行了对比。

    Sentence-level attacks craft adversarial sentences that are synonymous with correctly-classified sentences but are misclassified by the text classifiers. Under the black-box setting, classifiers are only accessible through their feedback to queried inputs, which is predominately available in the form of class probabilities. Even though utilizing class probabilities results in stronger attacks, due to the challenges of using them for sentence-level attacks, existing attacks use either no feedback or only the class labels. Overcoming the challenges, we develop a novel algorithm that uses class probabilities for black-box sentence-level attacks, investigate the effectiveness of using class probabilities on the attack's success, and examine the question if it is worthy or practical to use class probabilities by black-box sentence-level attacks. We conduct extensive evaluations of the proposed attack comparing with the baselines across various classifiers and benchmark datasets.
    
[^124]: 具有内聚子图意识的图对比学习

    Graph Contrastive Learning with Cohesive Subgraph Awareness

    [https://arxiv.org/abs/2401.17580](https://arxiv.org/abs/2401.17580)

    本研究提出了一种名为CTAug的新框架，将内聚子图意识无缝整合到图对比学习中。通过改进图拓扑增强和图学习过程，提高了对各种图的表征学习性能。

    

    图对比学习（GCL）已成为学习各种图表征的先进策略，包括社交和生物医学网络。GCL广泛使用随机图拓扑增强，如均匀节点丢失，生成增强图。然而，这种随机增强可能严重损害图的内在属性并恶化后续的表征学习过程。我们认为，在图增强和学习过程中引入内聚子图意识有可能提高GCL的性能。为此，我们提出了一种称为CTAug的新颖统一框架，以无缝地将内聚意识整合到各种现有的GCL机制中。具体来说，CTAug包括两个专门的模块：拓扑增强增强和图学习增强。前者生成谨慎保留内聚性质的增强图，而后者增强了图的学习能力。

    Graph contrastive learning (GCL) has emerged as a state-of-the-art strategy for learning representations of diverse graphs including social and biomedical networks. GCL widely uses stochastic graph topology augmentation, such as uniform node dropping, to generate augmented graphs. However, such stochastic augmentations may severely damage the intrinsic properties of a graph and deteriorate the following representation learning process. We argue that incorporating an awareness of cohesive subgraphs during the graph augmentation and learning processes has the potential to enhance GCL performance. To this end, we propose a novel unified framework called CTAug, to seamlessly integrate cohesion awareness into various existing GCL mechanisms. In particular, CTAug comprises two specialized modules: topology augmentation enhancement and graph learning enhancement. The former module generates augmented graphs that carefully preserve cohesion properties, while the latter module bolsters the grap
    
[^125]: 通过情绪思维链增强大型语言模型的情绪生成能力

    Enhancing Emotional Generation Capability of Large Language Models via Emotional Chain-of-Thought

    [https://arxiv.org/abs/2401.06836](https://arxiv.org/abs/2401.06836)

    该研究提出了一种名为情感思维链（ECoT）的提示方法，通过与人类情感智慧准则对齐，增强大型语言模型在情感生成任务上的性能。

    

    大型语言模型（LLMs）在各种情绪识别任务中表现出色，引起了研究界对探索它们在情感智能中潜力的好奇心。然而，情感生成任务领域仍存在一些问题，包括人类偏好的对齐和情感生成评估。本文提出了一种名为情感思维链（ECoT）的即插即用提示方法，通过与人类情感智力指南对齐来增强LLMs在各种情感生成任务上的表现。为了评估ECoT的可靠性，我们提出了一种称为情感生成得分（EGS）的自动化基于模型的评估方法。EGS将戈尔曼的情绪智力理论作为人类专家共识，为情感生成任务的评估提供了新的视角。大量实验结果证明...

    arXiv:2401.06836v2 Announce Type: replace-cross  Abstract: Large Language Models (LLMs) have shown remarkable performance in various emotion recognition tasks, thereby piquing the research community's curiosity for exploring their potential in emotional intelligence. However, several issues in the field of emotional generation tasks remain unresolved, including human preference alignment and emotional generation assessment. In this paper, we propose the Emotional Chain-of-Thought (ECoT), a plug-and-play prompting method that enhances the performance of LLMs on various emotional generation tasks by aligning with human emotional intelligence guidelines. To assess the reliability of ECoT, we propose an automated model-based evaluation method called Emotional Generation Score (EGS). EGS incorporates Goleman's Emotional Intelligence Theory as a consensus of human experts, providing a new perspective on the evaluation of emotional generation tasks. Extensive experimental results demonstrate 
    
[^126]: 基于多层交叉注意力融合的音频-视觉语音识别（MLCA-AVSR）

    MLCA-AVSR: Multi-Layer Cross Attention Fusion based Audio-Visual Speech Recognition

    [https://arxiv.org/abs/2401.03424](https://arxiv.org/abs/2401.03424)

    提出了基于多层交叉注意力融合的音频-视觉语音识别（MLCA-AVSR）方法，通过在不同级别的音频/视觉编码器上融合模态特征，有效提高了系统的稳健性。

    

    自动语音识别（ASR）系统在嘈杂环境中明显退化，而音频-视觉语音识别（AVSR）系统旨在用抗噪音的视觉线索补充音频流，并提高系统的稳健性。然而，当前研究主要集中在融合好学习的模态特征，如模态特定编码器的输出，而没有考虑模态特征学习期间的上下文关系。在本研究中，我们提出了一种基于多层交叉注意力融合的AVSR（MLCA-AVSR）方法，通过在不同级别的音频/视觉编码器上融合它们来促进每个模态的表示学习。对MISP2022-AVSR挑战数据集上的实验结果显示了我们提出的系统的有效性，在Eval集上实现了30.57%的拼接最小置换字符误差率（cpCER），相对于我们的p取得了高达3.17%的相对改善。

    arXiv:2401.03424v2 Announce Type: replace-cross  Abstract: While automatic speech recognition (ASR) systems degrade significantly in noisy environments, audio-visual speech recognition (AVSR) systems aim to complement the audio stream with noise-invariant visual cues and improve the system's robustness. However, current studies mainly focus on fusing the well-learned modality features, like the output of modality-specific encoders, without considering the contextual relationship during the modality feature learning. In this study, we propose a multi-layer cross-attention fusion based AVSR (MLCA-AVSR) approach that promotes representation learning of each modality by fusing them at different levels of audio/visual encoders. Experimental results on the MISP2022-AVSR Challenge dataset show the efficacy of our proposed system, achieving a concatenated minimum permutation character error rate (cpCER) of 30.57% on the Eval set and yielding up to 3.17% relative improvement compared with our p
    
[^127]: 面向生成人工智能的消息代理：调研、挑战和机遇

    Towards Message Brokers for Generative AI: Survey, Challenges, and Opportunities

    [https://arxiv.org/abs/2312.14647](https://arxiv.org/abs/2312.14647)

    该研究调查了传统和现代消息代理，比较分析了流行平台，为数据中心GenAI模型的需求增加提供了健壮的数据通信基础设施

    

    在当今数字化世界中，生成人工智能（GenAI）如大型语言模型（LLMs）正变得越来越普遍，扩展其影响范围至各种应用。这种采用激增引发了对数据中心GenAI模型的需求显著增加，突显出健壮的数据通信基础设施的必要性。消息代理在这一需求中至关重要，它们作为各个系统组件之间数据传输的重要通道。本调查旨在深入分析传统和现代消息代理，提供流行平台的比较研究。我们的研究考虑了许多标准，包括但不限于开源可用性、集成监控工具、消息优先级机制、并行处理能力、可靠性、分发和集群功能、认证流程、数据持久化。

    arXiv:2312.14647v2 Announce Type: replace-cross  Abstract: In today's digital world, Generative Artificial Intelligence (GenAI) such as Large Language Models (LLMs) is becoming increasingly prevalent, extending its reach across diverse applications. This surge in adoption has sparked a significant increase in demand for data-centric GenAI models, highlighting the necessity for robust data communication infrastructures. Central to this need are message brokers, which serve as essential channels for data transfer within various system components. This survey aims to delve into a comprehensive analysis of traditional and modern message brokers, offering a comparative study of prevalent platforms. Our study considers numerous criteria including, but not limited to, open-source availability, integrated monitoring tools, message prioritization mechanisms, capabilities for parallel processing, reliability, distribution and clustering functionalities, authentication processes, data persistence
    
[^128]: 迈向面向上下文感知领域泛化：理解边缘传递学习的好处和限制

    Towards Context-Aware Domain Generalization: Understanding the Benefits and Limits of Marginal Transfer Learning

    [https://arxiv.org/abs/2312.10107](https://arxiv.org/abs/2312.10107)

    分析了上下文感知领域泛化的条件，提出了理论分析和实证分析所需的标准，并展示了该方法可以检测非常数域的场景。

    

    在这项工作中，我们分析了关于输入$X$的上下文信息如何改善深度学习模型在新领域中的预测的条件。在领域泛化中边缘传递学习的研究基础上，我们将上下文的概念形式化为一组数据点的排列不变表示，这些数据点来自于与输入本身相同的域。我们对这种方法在原则上可以产生好处的条件进行了理论分析，并制定了两个在实践中可以轻松验证的必要标准。此外，我们提供了关于边缘传递学习方法有望具有稳健性的分布变化类型的见解。实证分析表明我们的标准有效地区分了有利和不利的场景。最后，我们证明可以可靠地检测模型面临非常数域的场景。

    arXiv:2312.10107v2 Announce Type: replace-cross  Abstract: In this work, we analyze the conditions under which information about the context of an input $X$ can improve the predictions of deep learning models in new domains. Following work in marginal transfer learning in Domain Generalization (DG), we formalize the notion of context as a permutation-invariant representation of a set of data points that originate from the same domain as the input itself. We offer a theoretical analysis of the conditions under which this approach can, in principle, yield benefits, and formulate two necessary criteria that can be easily verified in practice. Additionally, we contribute insights into the kind of distribution shifts for which the marginal transfer learning approach promises robustness. Empirical analysis shows that our criteria are effective in discerning both favorable and unfavorable scenarios. Finally, we demonstrate that we can reliably detect scenarios where a model is tasked with unw
    
[^129]: 临床文本的神经机器翻译：对多语言预训练语言模型和迁移学习的经验研究

    Neural Machine Translation of Clinical Text: An Empirical Investigation into Multilingual Pre-Trained Language Models and Transfer-Learning

    [https://arxiv.org/abs/2312.07250](https://arxiv.org/abs/2312.07250)

    在临床文本的神经机器翻译研究中，通过使用多语言预训练语言模型和迁移学习方法，在ClinSpEn-2022英西临床领域数据上取得了顶级性能，并发现小型预训练语言模型在临床领域微调中胜过其他超大型语言模型。

    

    我们通过检验使用基于深度学习的多语言神经网络模型，如基于Transformer结构的模型，在临床文本机器翻译方面进行了调查。此外，为了解决语言资源不平衡问题，我们还使用基于大规模多语言预训练语言模型（MMPLMs）的迁移学习方法进行了实验。在临床案例（CC）、临床术语（CT）和本体概念（OC）等三个子任务上的实验结果显示，我们的模型在ClinSpEn-2022英西临床领域数据共享任务中取得了顶级性能。此外，我们基于专家的人工评估显示，在临床领域微调中，小型预训练语言模型（PLM）明显胜过其他两个超大型语言模型，这一发现在该领域从未有过报道。最后，迁移学习方法表现出

    arXiv:2312.07250v2 Announce Type: replace-cross  Abstract: We conduct investigations on clinical text machine translation by examining multilingual neural network models using deep learning such as Transformer based structures. Furthermore, to address the language resource imbalance issue, we also carry out experiments using a transfer learning methodology based on massive multilingual pre-trained language models (MMPLMs). The experimental results on three subtasks including 1) clinical case (CC), 2) clinical terminology (CT), and 3) ontological concept (OC) show that our models achieved top-level performances in the ClinSpEn-2022 shared task on English-Spanish clinical domain data. Furthermore, our expert-based human evaluations demonstrate that the small-sized pre-trained language model (PLM) won over the other two extra-large language models by a large margin, in the clinical domain fine-tuning, which finding was never reported in the field. Finally, the transfer learning method wor
    
[^130]: 使用Oracle和AI辩论进行大型游戏的玩法

    Playing Large Games with Oracles and AI Debate

    [https://arxiv.org/abs/2312.04792](https://arxiv.org/abs/2312.04792)

    本论文研究了在具有大量动作的重复游戏中实现遗憾最小化的问题，通过使用基于Oracle的算法，提出了一种高效的内部遗憾最小化算法，实现了在大型游戏中计算相关均衡的高效性。通过在AI安全辩论环境中的实验验证了算法的有效性。

    

    我们考虑在具有大量动作的重复游戏中实现遗憾最小化。这种游戏在通过辩论确保AI安全的环境中是固有的，并且更一般地应用于动作基于语言的游戏中。现有的在线游戏算法需要多项式计算数量的动作，而对于大型游戏来说，这可能是难以实现的。因此，我们考虑使用基于Oracle的算法，因为Oracle自然地模拟了对AI代理的访问。通过对Oracle访问进行特征化，我们可以有效地实现内部和外部遗憾的最小化。我们提出了一种新颖的内部遗憾最小化算法，其遗憾和计算复杂度对数地依赖于动作数量。这意味着可以高效地基于Oracle计算大型游戏中的相关均衡。最后，我们通过在AI安全辩论环境中进行实验，展示了我们算法分析的好处。

    We consider regret minimization in repeated games with a very large number of actions. Such games are inherent in the setting of AI safety via debate, and more generally games whose actions are language-based. Existing algorithms for online game playing require computation polynomial in the number of actions, which can be prohibitive for large games.   We thus consider oracle-based algorithms, as oracles naturally model access to AI agents. With oracle access, we characterize when internal and external regret can be minimized efficiently. We give a novel efficient algorithm for internal regret minimization whose regret and computation complexity depend logarithmically on the number of actions. This implies efficient oracle-based computation of a correlated equilibrium in large games.   We conclude with experiments in the setting of AI Safety via Debate that shows the benefit of insights from our algorithmic analysis.
    
[^131]: SynthScribe：用于合成器声音检索和探索的深度多模态工具

    SynthScribe: Deep Multimodal Tools for Synthesizer Sound Retrieval and Exploration

    [https://arxiv.org/abs/2312.04690](https://arxiv.org/abs/2312.04690)

    SynthScribe是一个利用多模态深度学习的全栈系统，让用户以更高级别表达意图，实现了搜索现有声音、创建全新声音、对给定声音进行有意义修改的功能

    

    合成器是能够让音乐家创作出动态和原创声音的强大工具。现有的用于合成器的商用界面通常要求音乐家与复杂的低级参数进行交互，或者管理大量预制声音库。为了解决这些挑战，我们实现了SynthScribe——一个利用多模态深度学习的全栈系统，让用户可以以更高级别表达他们的意图。我们实现了几个功能，以解决一些困难，即1）搜索现有声音，2）创建全新声音，3）对给定声音进行有意义的修改。这通过三个主要功能实现：一个用于大型合成器声音库的多模态搜索引擎；一个以用户为中心的遗传算法，可以根据用户的偏好创建和选择全新声音；一个声音编辑支持功能，突出显示并提供关键示例

    arXiv:2312.04690v2 Announce Type: replace-cross  Abstract: Synthesizers are powerful tools that allow musicians to create dynamic and original sounds. Existing commercial interfaces for synthesizers typically require musicians to interact with complex low-level parameters or to manage large libraries of premade sounds. To address these challenges, we implement SynthScribe -- a fullstack system that uses multimodal deep learning to let users express their intentions at a much higher level. We implement features which address a number of difficulties, namely 1) searching through existing sounds, 2) creating completely new sounds, 3) making meaningful modifications to a given sound. This is achieved with three main features: a multimodal search engine for a large library of synthesizer sounds; a user centered genetic algorithm by which completely new sounds can be created and selected given the users preferences; a sound editing support feature which highlights and gives examples for key 
    
[^132]: 攻击树：自动破解黑盒大型语言模型

    Tree of Attacks: Jailbreaking Black-Box LLMs Automatically

    [https://arxiv.org/abs/2312.02119](https://arxiv.org/abs/2312.02119)

    提出了一种名为Tree of Attacks with Pruning (TAP)的自动化方法，用于生成只需要对目标大型语言模型进行黑盒访问的越狱方法，并通过思维树推理和修剪生成准确的越狱提示。

    

    大型语言模型(LLMs)展示了多功能性，但仍在生成有害、带偏见和有毒内容，这一点由人为设计的越狱行为的普遍存在得以证明。在这项工作中，我们提出了一种名为Tree of Attacks with Pruning (TAP)的自动化方法，用于生成越狱，仅需要对目标LLM进行黑盒访问。TAP利用LLM来通过思维树推理迭代地优化候选（攻击）提示，直到生成的提示之一越狱目标。关键在于，在将提示发送给目标之前，TAP对其进行评估并移除可能不会导致越狱的提示。使用思维树推理使TAP能够在大量提示的搜索空间中导航，而修剪则减少了发送给目标的总查询数量。在实证评估中，我们观察到TAP生成的提示越狱了超过80%的最先进LLMs（包括GPT4和GPT4-Turbo）。

    arXiv:2312.02119v2 Announce Type: replace-cross  Abstract: While Large Language Models (LLMs) display versatile functionality, they continue to generate harmful, biased, and toxic content, as demonstrated by the prevalence of human-designed jailbreaks. In this work, we present Tree of Attacks with Pruning (TAP), an automated method for generating jailbreaks that only requires black-box access to the target LLM. TAP utilizes an LLM to iteratively refine candidate (attack) prompts using tree-of-thought reasoning until one of the generated prompts jailbreaks the target. Crucially, before sending prompts to the target, TAP assesses them and prunes the ones unlikely to result in jailbreaks. Using tree-of-thought reasoning allows TAP to navigate a large search space of prompts and pruning reduces the total number of queries sent to the target. In empirical evaluations, we observe that TAP generates prompts that jailbreak state-of-the-art LLMs (including GPT4 and GPT4-Turbo) for more than 80%
    
[^133]: CAMRA：AMR注释的副驾驶

    CAMRA: Copilot for AMR Annotation

    [https://arxiv.org/abs/2311.10928](https://arxiv.org/abs/2311.10928)

    CAMRA是一个创新的基于web的工具，用于从自然语言文本构建抽象意义表示（AMR），通过整合编程语言的编码方法和AMR解析器模型作为副驾驶，极大提高了AMR注释的效率和准确性。

    

    在本文中，我们介绍了CAMRA（Copilot for AMR Annotations），这是一个最先进的基于web的工具，旨在从自然语言文本构建抽象意义表示（AMR）。CAMRA提供了一种创新的深层词汇语义注释方法，如AMR，将AMR注释视为编程语言中的编码。借助编程范式的熟悉度，CAMRA包含了所有现有AMR编辑器的基本功能，包括示例查找，同时通过将Propbank角色集查找集成为工具中的自动完成功能，更进一步。值得注意的是，CAMRA将AMR解析器模型作为编码副驾驶，极大地提高了AMR注释者的效率和准确性。为了展示工具的功能，我们提供了一个可访问的实时演示：https://camra.colorado.edu

    arXiv:2311.10928v2 Announce Type: replace-cross  Abstract: In this paper, we introduce CAMRA (Copilot for AMR Annotatations), a cutting-edge web-based tool designed for constructing Abstract Meaning Representation (AMR) from natural language text. CAMRA offers a novel approach to deep lexical semantics annotation such as AMR, treating AMR annotation akin to coding in programming languages. Leveraging the familiarity of programming paradigms, CAMRA encompasses all essential features of existing AMR editors, including example lookup, while going a step further by integrating Propbank roleset lookup as an autocomplete feature within the tool. Notably, CAMRA incorporates AMR parser models as coding co-pilots, greatly enhancing the efficiency and accuracy of AMR annotators. To demonstrate the tool's capabilities, we provide a live demo accessible at: https://camra.colorado.edu
    
[^134]: 具有用户定义目标的自适应干预用于健康行为改变

    Adaptive Interventions with User-Defined Goals for Health Behavior Change

    [https://arxiv.org/abs/2311.09483](https://arxiv.org/abs/2311.09483)

    该论文介绍了一种修改过的Thompson抽样算法，强调通过优化个性化奖励函数实现个性化目标设定，为支持目标设定提供了一个平衡方法，并证明此修改仅对累积遗憾产生恒定的惩罚。

    

    身体活动不足仍然是一个主要的公共健康问题，与心血管疾病和2型糖尿病等不良健康结果相关。移动健康应用程序为低成本、可扩展的身体活动促进提供了一个有希望的途径，然而通常效果较小，粘附率低，特别是与人类辅导相比。目标设定是健康辅导的一个关键组成部分，在移动健康干预的自适应算法中一直未充分利用。本文介绍了对Thompson抽样算法的修改，重点放在通过优化个性化奖励函数实现个性化目标设定。作为支持目标设定的一步，本文提供了一个可以利用共享结构同时优化个人偏好和目标的平衡方法。我们证明，我们的修改只对累积遗憾造成一个常数惩罚。

    arXiv:2311.09483v2 Announce Type: replace-cross  Abstract: Physical inactivity remains a major public health concern, having associations with adverse health outcomes such as cardiovascular disease and type-2 diabetes. Mobile health applications present a promising avenue for low-cost, scalable physical activity promotion, yet often suffer from small effect sizes and low adherence rates, particularly in comparison to human coaching. Goal-setting is a critical component of health coaching that has been underutilized in adaptive algorithms for mobile health interventions. This paper introduces a modification to the Thompson sampling algorithm that places emphasis on individualized goal-setting by optimizing personalized reward functions. As a step towards supporting goal-setting, this paper offers a balanced approach that can leverage shared structure while optimizing individual preferences and goals. We prove that our modification incurs only a constant penalty on the cumulative regret 
    
[^135]: 揭示真相：欺骗语言和语言模型

    To Tell The Truth: Language of Deception and Language Models

    [https://arxiv.org/abs/2311.07092](https://arxiv.org/abs/2311.07092)

    在高风险环境中，研究人员通过分析电视游戏节目数据发现，即使只使用语言线索，基于大型语言模型构建的模型可以与人类主体具有类似的真相检测性能。

    

    arXiv:2311.07092v2 公告类型：替换-cross 摘要：基于文本的错误信息渗透到在线讨论中，然而人们能够从这种欺骗性文本内容中辨别真相的证据却很少。我们分析了一档新颖的电视游戏节目数据，其中高风险环境中相互之间存在冲突目标的个体之间的对话导致谎言。我们调查了欺骗语言潜在可验证语言线索在客观真相存在的情况下的表现，这是以往基于文本的欺骗数据集中缺少的一个显著特征。我们展示了存在一类探测器（算法），其真相检测性能与人类主体相似，即使前者只使用语言线索，而后者则通过完全访问所有潜在线索源（语言和视听）进行对话。我们的模型，建立在大型语言模型之上，采用瓶颈框架来学习可辨别的线索，以确定真相的行为

    arXiv:2311.07092v2 Announce Type: replace-cross  Abstract: Text-based misinformation permeates online discourses, yet evidence of people's ability to discern truth from such deceptive textual content is scarce. We analyze a novel TV game show data where conversations in a high-stake environment between individuals with conflicting objectives result in lies. We investigate the manifestation of potentially verifiable language cues of deception in the presence of objective truth, a distinguishing feature absent in previous text-based deception datasets. We show that there exists a class of detectors (algorithms) that have similar truth detection performance compared to human subjects, even when the former accesses only the language cues while the latter engages in conversations with complete access to all potential sources of cues (language and audio-visual). Our model, built on a large language model, employs a bottleneck framework to learn discernible cues to determine truth, an act of 
    
[^136]: 使用LLMs的运动学感知提示实现对可移动物体的泛化操作

    Kinematic-aware Prompting for Generalizable Articulated Object Manipulation with LLMs

    [https://arxiv.org/abs/2311.02847](https://arxiv.org/abs/2311.02847)

    基于物体的运动学结构，提出了一种运动学感知提示框架，用于生成LLMs的低级运动轨迹位点，以实现对可移动物体的泛化操作

    

    泛化的可移动物体操作对于家庭助手机器人至关重要。最近的研究主要集中在从演示中进行模仿学习或在模拟环境中进行强化学习，然而，由于实际数据收集和精确对象模拟成本高昂，这些工作仍然难以在多样的可移动物体上实现广泛的适应性。最近，许多研究尝试利用大型语言模型（LLMs）的强大上下文学习能力实现可泛化的机器人操作，但大多数研究侧重于高层任务规划，忽视了低层的机器人控制。在这项工作中，基于一个理念，即物体的运动学结构决定了我们如何操纵它，我们提出了一个运动学感知提示框架，用物体的运动学知识提示LLMs生成低层运动轨迹位点，支持

    arXiv:2311.02847v3 Announce Type: replace-cross  Abstract: Generalizable articulated object manipulation is essential for home-assistant robots. Recent efforts focus on imitation learning from demonstrations or reinforcement learning in simulation, however, due to the prohibitive costs of real-world data collection and precise object simulation, it still remains challenging for these works to achieve broad adaptability across diverse articulated objects. Recently, many works have tried to utilize the strong in-context learning ability of Large Language Models (LLMs) to achieve generalizable robotic manipulation, but most of these researches focus on high-level task planning, sidelining low-level robotic control. In this work, building on the idea that the kinematic structure of the object determines how we can manipulate it, we propose a kinematic-aware prompting framework that prompts LLMs with kinematic knowledge of objects to generate low-level motion trajectory waypoints, supportin
    
[^137]: 通过多路径长期船舶轨迹预测建立更安全的海洋环境

    Building a Safer Maritime Environment Through Multi-Path Long-Term Vessel Trajectory Forecasting

    [https://arxiv.org/abs/2310.18948](https://arxiv.org/abs/2310.18948)

    通过利用AIS数据预测船舶轨迹，本研究旨在通过减少船舶与鲸鱼碰撞来建立更安全的海洋环境。

    

    海上交通对于实现全球经济增长至关重要，同时也需要在可持续性和保护濒危海洋物种方面履行生态义务，尤其是保护大型鲸类种群。在这方面，自动识别系统(AIS)数据通过提供船舶运动的实时流数据，可以实现强化的交通监控，从而避免船舶与鲸鱼碰撞。本研究探讨利用AIS数据预测长期船舶轨迹，从而预防船舶与鲸鱼的碰撞。为此，我们采用双向长短期记忆网络(Bi-LSTM)构建了一种编码器-解码器模型架构，通过将1到3小时的AIS数据作为输入，预测接下来12小时的船舶轨迹。我们从历史AIS数据中提取潜在路线和目的地的概率特征，并将其作为模型的输入。模型随后预测船舶的轨迹，考虑到潜在路线和目的地的影响。

    Maritime transportation is paramount in achieving global economic growth, entailing concurrent ecological obligations in sustainability and safeguarding endangered marine species, most notably preserving large whale populations. In this regard, the Automatic Identification System (AIS) data plays a significant role by offering real-time streaming data on vessel movement, allowing enhanced traffic monitoring. This study explores using AIS data to prevent vessel-to-whale collisions by forecasting long-term vessel trajectories from engineered AIS data sequences. For such a task, we have developed an encoder-decoder model architecture using Bidirectional Long Short-Term Memory Networks (Bi-LSTM) to predict the next 12 hours of vessel trajectories using 1 to 3 hours of AIS data as input. We feed the model with probabilistic features engineered from historical AIS data that refer to each trajectory's potential route and destination. The model then predicts the vessel's trajectory, considerin
    
[^138]: RGI-Net：在没有一阶回声的情况下从房间脉冲响应中推断3D房间几何

    RGI-Net: 3D Room Geometry Inference from Room Impulse Responses in the Absence of First-order Echoes

    [https://arxiv.org/abs/2309.01513](https://arxiv.org/abs/2309.01513)

    RGI-Net通过深度神经网络学习和利用房间脉冲响应中高阶反射之间的关系，实现在没有传统假设的情况下推断房间几何信息。

    

    房间几何是实现逼真的3D音频渲染的重要先验信息。为此，利用房间脉冲响应中到达时间（TOA）或到达时间差（TDOA）信息发展了各种房间几何推断（RGI）方法。然而，传统的RGI技术提出了一些假设，如凸房间形状、已知墙壁数量和一阶反射的可见性。在这项工作中，我们引入了深度神经网络（DNN）RGI-Net，它可以在没有上述假设的情况下估计房间几何。RGI-Net学习并利用房间脉冲响应（RIRs）中的高阶反射之间的复杂关系，因此可以在形状为非凸形或RIRs中缺少一阶反射的情况下估计房间形状。该网络采用从装有圆形麦克风的紧凑音频设备测量的RIRs。

    arXiv:2309.01513v2 Announce Type: replace-cross  Abstract: Room geometry is important prior information for implementing realistic 3D audio rendering. For this reason, various room geometry inference (RGI) methods have been developed by utilizing the time of arrival (TOA) or time difference of arrival (TDOA) information in room impulse responses. However, the conventional RGI technique poses several assumptions, such as convex room shapes, the number of walls known in priori, and the visibility of first-order reflections. In this work, we introduce the deep neural network (DNN), RGI-Net, which can estimate room geometries without the aforementioned assumptions. RGI-Net learns and exploits complex relationships between high-order reflections in room impulse responses (RIRs) and, thus, can estimate room shapes even when the shape is non-convex or first-order reflections are missing in the RIRs. The network takes RIRs measured from a compact audio device equipped with a circular microphon
    
[^139]: 大型语言模型中公平性的调查

    A Survey on Fairness in Large Language Models

    [https://arxiv.org/abs/2308.10149](https://arxiv.org/abs/2308.10149)

    本文审查了关于大型语言模型中公平性的研究，针对中等规模LLMs和大规模LLMs提出了评估指标和去偏见方法。

    

    大型语言模型(LLMs)展现了强大的性能和发展前景，并广泛部署在现实世界中。然而，LLMs可能会捕捉到未经处理的训练数据中的社会偏见，并将这些偏见传播到下游任务。不公平的LLM系统会产生不良的社会影响和潜在危害。在本文中，我们全面回顾了有关LLMs中公平性的研究。考虑到参数大小和训练范式对研究策略的影响，我们将现有的公平性研究分为针对中等规模LLMs在预训练和微调范式下的研究以及针对大规模LLMs在提示范式下的研究。首先，对于中等规模LLMs，我们从内在偏见和外在偏见的角度介绍了评估指标和去偏见方法。然后，对于大规模LLMs，我们引入了最近的公平性研究，包括公平性评估、原因...

    arXiv:2308.10149v2 Announce Type: replace-cross  Abstract: Large Language Models (LLMs) have shown powerful performance and development prospects and are widely deployed in the real world. However, LLMs can capture social biases from unprocessed training data and propagate the biases to downstream tasks. Unfair LLM systems have undesirable social impacts and potential harms. In this paper, we provide a comprehensive review of related research on fairness in LLMs. Considering the influence of parameter magnitude and training paradigm on research strategy, we divide existing fairness research into oriented to medium-sized LLMs under pre-training and fine-tuning paradigms and oriented to large-sized LLMs under prompting paradigms. First, for medium-sized LLMs, we introduce evaluation metrics and debiasing methods from the perspectives of intrinsic bias and extrinsic bias, respectively. Then, for large-sized LLMs, we introduce recent fairness research, including fairness evaluation, reason
    
[^140]: 通过语义匹配修复特征归因方法中的确认偏见

    Fixing confirmation bias in feature attribution methods via semantic match

    [https://arxiv.org/abs/2307.00897](https://arxiv.org/abs/2307.00897)

    提出了通过语义匹配修复特征归因方法中的确认偏见问题，引入了人类概念与（亚符号）解释之间的概念框架，并提出了一种结构化方法来评估语义匹配。

    

    特征归因方法已经成为解析黑盒模型复杂行为的重要方法。尽管取得了成功，一些学者指出这类方法存在严重缺陷：它们不能可靠地用人类概念进行解释。简而言之，仅仅可视化一系列特征贡献对于人类来说无法得出关于模型内部表示的结论，而确认偏见可能会让用户产生关于模型行为的错误信念。我们认为需要一种结构化方法来验证我们对模型的假设是否得到了特征归因的确认。这就是我们所说的人类概念与（亚符号）解释之间的“语义匹配”。在 Cin\`a等人[2023]提出的概念框架基础上，我们提出了一种结构化方法来在实践中评估语义匹配。我们在一系列实验中展示了这一过程。

    arXiv:2307.00897v2 Announce Type: replace-cross  Abstract: Feature attribution methods have become a staple method to disentangle the complex behavior of black box models. Despite their success, some scholars have argued that such methods suffer from a serious flaw: they do not allow a reliable interpretation in terms of human concepts. Simply put, visualizing an array of feature contributions is not enough for humans to conclude something about a model's internal representations, and confirmation bias can trick users into false beliefs about model behavior. We argue that a structured approach is required to test whether our hypotheses on the model are confirmed by the feature attributions. This is what we call the "semantic match" between human concepts and (sub-symbolic) explanations. Building on the conceptual framework put forward in Cin\`a et al. [2023], we propose a structured approach to evaluate semantic match in practice. We showcase the procedure in a suite of experiments spa
    
[^141]: Sin3DM: 从单个3D纹理形状中学习扩散模型

    Sin3DM: Learning a Diffusion Model from a Single 3D Textured Shape

    [https://arxiv.org/abs/2305.15399](https://arxiv.org/abs/2305.15399)

    Sin3DM提出了一种扩散模型，能够从单个3D纹理形状中学习内部补丁分布，在低维潜在空间中训练并生成高质量的变体。

    

    合成功能不仅可以随机生成新样本，还可以从实际输入样本中生成类似的高质量变化，包括精细的几何和纹理细节。

    arXiv:2305.15399v2 Announce Type: replace-cross  Abstract: Synthesizing novel 3D models that resemble the input example has long been pursued by graphics artists and machine learning researchers. In this paper, we present Sin3DM, a diffusion model that learns the internal patch distribution from a single 3D textured shape and generates high-quality variations with fine geometry and texture details. Training a diffusion model directly in 3D would induce large memory and computational cost. Therefore, we first compress the input into a lower-dimensional latent space and then train a diffusion model on it. Specifically, we encode the input 3D textured shape into triplane feature maps that represent the signed distance and texture fields of the input. The denoising network of our diffusion model has a limited receptive field to avoid overfitting, and uses triplane-aware 2D convolution blocks to improve the result quality. Aside from randomly generating new samples, our model also facilitat
    
[^142]: InPars-Light:成本效益高的无监督训练高效排名器

    InPars-Light: Cost-Effective Unsupervised Training of Efficient Rankers

    [https://arxiv.org/abs/2301.02998](https://arxiv.org/abs/2301.02998)

    InPars-Light是一个简单而有效的修改，通过使用小得多的排名模型和免费语言模型BLOOM，在多个英文检索集合上显著改进了排名性能。

    

    我们开展了对InPars的可重现性研究，这是一种用于无监督训练神经排名器的方法。作为副产品，我们开发出了InPars-Light，这是对InPars的简单而有效的修改。与InPars不同，InPars-Light使用7-100倍更小的排名模型，并且只需要一个免费提供的语言模型BLOOM，我们发现，与专有的GPT-3模型相比，BLOOM能够产生更准确的排名器。在所有五个英文检索集合上，我们仅使用一个30M参数六层MiniLM-30M排名器和一个三选俩的提示，在nDCG和MRR方面，相比BM25，我们都获得了显著的（7%-30%）且具有统计学意义的改进。相反，在InPars的研究中，只有一个大100倍的monoT5-3B模型能够始终胜过BM25，而小得多的monoT5-220M模型（仍然比我们的MiniLM排名器大7倍）只是在MS MAR上胜过BM25。

    arXiv:2301.02998v2 Announce Type: replace-cross  Abstract: We carried out a reproducibility study of InPars, which is a method for unsupervised training of neural rankers (Bonifacio et al., 2022). As a by-product, we developed InPars-light, which is a simple-yet-effective modification of InPars. Unlike InPars, InPars-light uses 7x-100x smaller ranking models and only a freely available language model BLOOM, which -- as we found out -- produced more accurate rankers compared to a proprietary GPT-3 model. On all five English retrieval collections (used in the original InPars study) we obtained substantial (7%-30%) and statistically significant improvements over BM25 (in nDCG and MRR) using only a 30M parameter six-layer MiniLM-30M ranker and a single three-shot prompt. In contrast, in the InPars study only a 100x larger monoT5-3B model consistently outperformed BM25, whereas their smaller monoT5-220M model (which is still 7x larger than our MiniLM ranker) outperformed BM25 only on MS MAR
    
[^143]: 使用集成课程学习和协作训练进行运动想象解码

    Motor Imagery Decoding Using Ensemble Curriculum Learning and Collaborative Training

    [https://arxiv.org/abs/2211.11460](https://arxiv.org/abs/2211.11460)

    提出了一种使用集成课程学习和协作训练的两阶段模型集成架构，通过引入新的损失项应用课程学习并允许协作解读，解决了跨主体运动想象解码的挑战性问题。

    

    在这项工作中，我们研究了使用脑电图（EEG）数据进行跨主体运动想象（MI）解码的问题。多主体EEG数据集由于各种不同的主体间差异（如大脑解剖、个性和认知特征）而产生多种领域转移。受到领域泛化技术对解决此类问题的重要性的启发，我们提出了一个两阶段模型集成架构，由多个特征提取器（第一阶段）和一个共享分类器（第二阶段）构建，我们用两个新颖的损失项端到端地训练它们。第一个损失应用课程学习，促使每个特征提取器专门针对一部分训练主体并促进特征多样性。第二个损失是一个内部集成蒸馏目标，允许协作解读

    arXiv:2211.11460v2 Announce Type: replace-cross  Abstract: In this work, we study the problem of cross-subject motor imagery (MI) decoding from electroencephalography (EEG) data. Multi-subject EEG datasets present several kinds of domain shifts due to various inter-individual differences (e.g. brain anatomy, personality and cognitive profile). These domain shifts render multi-subject training a challenging task and also impede robust cross-subject generalization. Inspired by the importance of domain generalization techniques for tackling such issues, we propose a two-stage model ensemble architecture built with multiple feature extractors (first stage) and a shared classifier (second stage), which we train end-to-end with two novel loss terms. The first loss applies curriculum learning, forcing each feature extractor to specialize to a subset of the training subjects and promoting feature diversity. The second loss is an intra-ensemble distillation objective that allows collaborative e
    
[^144]: 评估相似度评分的不确定性：面部识别中的性能与公平性

    Assessing Uncertainty in Similarity Scoring: Performance & Fairness in Face Recognition

    [https://arxiv.org/abs/2211.07245](https://arxiv.org/abs/2211.07245)

    评估相似度评分函数性能和公平性质的关键工具是ROC曲线，文章提出了一种准确评估与ROC曲线相关不确定性水平的方法，特别适用于面部识别等具有社会影响的应用。

    

    ROC曲线是评估相似度评分函数性能和公平性质的主要工具。为了基于经验ROC分析得出可靠结论，准确评估与感兴趣的ROC曲线的统计版本相关的不确定性水平是绝对必要的，特别是对于具有重要社会影响的应用，如面部识别。在本文中，我们证明了相似性函数的经验ROC曲线以及用于评估公平性的副产品指标的渐近保证。我们还解释，由于在相似度评分情况下，误接受/拒绝率的形式为U-统计量，所以天真的自助法可能会危及评估过程。必须使用专门的重新居中技术。除进行的理论分析外，还使用真实人脸图像数据集进行了各种实验。

    arXiv:2211.07245v2 Announce Type: replace-cross  Abstract: The ROC curve is the major tool for assessing not only the performance but also the fairness properties of a similarity scoring function. In order to draw reliable conclusions based on empirical ROC analysis, accurately evaluating the uncertainty level related to statistical versions of the ROC curves of interest is absolutely necessary, especially for applications with considerable societal impact such as Face Recognition. In this article, we prove asymptotic guarantees for empirical ROC curves of similarity functions as well as for by-product metrics useful to assess fairness. We also explain that, because the false acceptance/rejection rates are of the form of U-statistics in the case of similarity scoring, the naive bootstrap approach may jeopardize the assessment procedure. A dedicated recentering technique must be used instead. Beyond the theoretical analysis carried out, various experiments using real face image datasets
    
[^145]: 模糊逻辑控制器的洗衣机设计

    Design of Fuzzy Logic Controller for Washing Machine

    [https://arxiv.org/abs/2210.00187](https://arxiv.org/abs/2210.00187)

    本文基于Mamdani方法，设计了一个基于多输入多输出的模糊逻辑控制器算法，并在Python中实现，结果显示在低计算成本下洗衣机表现更好

    

    随着技术的进步，事物变得更加先进，机器现在执行大部分手动工作。最常用的家用电器是洗衣机。在本文中，我们使用了Mamdani方法，并基于多输入多输出创建了一个算法。该算法是用Python实现的。模拟结果表明，该洗衣机在低计算成本下提供了更好的执行。

    arXiv:2210.00187v2 Announce Type: replace-cross  Abstract: Things are becoming more advanced as technology advances,and machines now perform the majority of the manual work. The most often used home appliance is the washing machine for cloths. In this paper, we used the Mamdani approach and created an algorithm based on multi-input multi-output. The algorithm is implemented in Python.The results of this simulation show that the washing machine provides better execution at a low computation cost
    
[^146]: 基于RIS和ADMM的被动稀疏感知方法及干扰去除

    RIS-ADMM: A RIS and ADMM-Based Passive and Sparse Sensing Method With Interference Removal

    [https://arxiv.org/abs/2206.06172](https://arxiv.org/abs/2206.06172)

    本文提出了一种基于RIS和ADMM的被动稀疏感知方法，通过新颖的迭代方法有效抑制干扰信号，显著提高到达方向（DOA）估计的准确性。

    

    可重构智能表面（RIS）在未来雷达和无线通信领域崛起为有前途的技术。本文解决了在无线通信信号和RIS中被无线接入点（AP）干扰的情况下利用被动感知的问题。我们引入了一种原子范数最小化（ANM）方法来利用空间域目标稀疏性并估计到达方向（DOA）。然而，用于ANM问题的传统半定规划（SDP）解决方案复杂且缺乏高效实现。因此，我们提出了一种RIS-ADMM方法，这是一种创新的基于交替方向乘子方法（ADMM）的迭代方法。该方法产生闭式表达式并有效抑制干扰信号。仿真结果证实了我们的RIS-ADMM方法在DOA估计精度方面超过了现有技术，同时保持低计算复杂度。

    arXiv:2206.06172v2 Announce Type: replace-cross  Abstract: Reconfigurable Intelligent Surfaces (RIS) emerge as promising technologies in future radar and wireless communication domains. This letter addresses the passive sensing issue utilizing wireless communication signals and RIS amidst interference from wireless access points (APs). We introduce an atomic norm minimization (ANM) approach to leverage spatial domain target sparsity and estimate the direction of arrival (DOA). However, the conventional semidefinite programming (SDP)-based solutions for the ANM problem are complex and lack efficient realization. Consequently, we propose a RIS-ADMM method, an innovative alternating direction method of multipliers (ADMM)-based iterative approach. This method yields closed-form expressions and effectively suppresses interference signals. Simulation outcomes affirm that our RIS-ADMM method surpasses existing techniques in DOA estimation accuracy while maintaining low computational complexit
    
[^147]: 离线强化学习中的温和保守Q学习

    Mildly Conservative Q-Learning for Offline Reinforcement Learning

    [https://arxiv.org/abs/2206.04745](https://arxiv.org/abs/2206.04745)

    本文提出了一种离线强化学习中的温和保守Q学习（MCQ）方法，通过为OOD动作分配适当的伪Q值来训练，从而在不损害泛化能力的情况下实现价值函数的保守性，避免过度高估超出分布的动作。

    

    离线强化学习定义了从静态记录的数据集中学习而无需持续与环境进行交互的任务。学习策略与行为策略之间的分布转移使得价值函数保持保守成为必要，以确保超出分布（OOD）的动作不会被严重高估。然而，现有的方法，如对未见动作进行惩罚或与行为策略进行正则化，都过于悲观，抑制了价值函数的泛化能力，并阻碍了性能的提高。本文探讨了离线学习中的温和但足够保守，同时不损害泛化能力。我们提出了温和保守Q学习（MCQ），通过为OOD动作分配适当的伪Q值来积极训练它们。我们理论上证明了MCQ会产生一个至少与行为策略一样好的策略，并且不会发生错误的过估计。

    arXiv:2206.04745v3 Announce Type: replace-cross  Abstract: Offline reinforcement learning (RL) defines the task of learning from a static logged dataset without continually interacting with the environment. The distribution shift between the learned policy and the behavior policy makes it necessary for the value function to stay conservative such that out-of-distribution (OOD) actions will not be severely overestimated. However, existing approaches, penalizing the unseen actions or regularizing with the behavior policy, are too pessimistic, which suppresses the generalization of the value function and hinders the performance improvement. This paper explores mild but enough conservatism for offline learning while not harming generalization. We propose Mildly Conservative Q-learning (MCQ), where OOD actions are actively trained by assigning them proper pseudo Q values. We theoretically show that MCQ induces a policy that behaves at least as well as the behavior policy and no erroneous ov
    
[^148]: 值得信赖的图神经网络：方面、方法和趋势

    Trustworthy Graph Neural Networks: Aspects, Methods and Trends

    [https://arxiv.org/abs/2205.07424](https://arxiv.org/abs/2205.07424)

    论文提出了构建可信赖图神经网络的综合路线图，关注解决性能导向的图神经网络可能存在的对抗性攻击、歧视问题和资源消耗过多等挑战。

    

    论文探讨了图神经网络在各种现实场景中的应用，不仅仅关注任务表现，还着重指出性能导向的图神经网络可能存在对抗性攻击、歧视弱势群体、在边缘计算环境中消耗资源过多等问题。为了避免这些意外伤害，有必要构建具有信赖性的高效图神经网络，提出了从涉及的各种计算技术视角构建可信赖图神经网络的全面路线图。

    arXiv:2205.07424v2 Announce Type: replace-cross  Abstract: Graph neural networks (GNNs) have emerged as a series of competent graph learning methods for diverse real-world scenarios, ranging from daily applications like recommendation systems and question answering to cutting-edge technologies such as drug discovery in life sciences and n-body simulation in astrophysics. However, task performance is not the only requirement for GNNs. Performance-oriented GNNs have exhibited potential adverse effects like vulnerability to adversarial attacks, unexplainable discrimination against disadvantaged groups, or excessive resource consumption in edge computing environments. To avoid these unintentional harms, it is necessary to build competent GNNs characterised by trustworthiness. To this end, we propose a comprehensive roadmap to build trustworthy GNNs from the view of the various computing technologies involved. In this survey, we introduce basic concepts and comprehensively summarise existin
    
[^149]: 使用哈密顿动力学随机模型学习最优控制

    Learning Optimal Control with Stochastic Models of Hamiltonian Dynamics

    [https://arxiv.org/abs/2111.08108](https://arxiv.org/abs/2111.08108)

    本文提出了一种新颖的学习框架来解决最优控制问题，通过学习减少的哈密顿动力学和伴随变量，利用变分自动编码器逐渐学习后验分布，从而提高了路径探索过程的效率。

    

    通过应用庞特里亚金最大值原理，然后求解哈密顿动力系统，最优控制问题可以得到解决。本文提出了新颖的学习框架来解决最优控制问题。通过将庞特里亚金最大值原理应用于原始最优控制问题，学习重点转移到了减少的哈密顿动力学和相应的伴随变量上。减少的哈密顿网络可以通过向后推进时间，然后最小化从庞特里亚金最大值原理条件推导出的损失函数来学习。通过逐渐学习减少的哈密顿的后验分布，利用变分自动编码器进一步改进了学习过程，从而导致更有效的路径探索过程。我们将我们的学习框架应用于控制任务并获得了竞争力的结果。

    arXiv:2111.08108v2 Announce Type: replace-cross  Abstract: Optimal control problems can be solved by applying the Pontryagin maximum principle and then solving for a Hamiltonian dynamical system. In this paper, we propose novel learning frameworks to tackle optimal control problems. By applying the Pontryagin maximum principle to the original optimal control problem, the learning focus shifts to reduced Hamiltonian dynamics and corresponding adjoint variables. The reduced Hamiltonian networks can be learned by going backward in time and then minimizing loss function deduced from the Pontryagin maximum principle's conditions. The learning process is further improved by progressively learning a posterior distribution of reduced Hamiltonians, utilizing a variational autoencoder which leads to more effective path exploration process. We apply our learning frameworks to control tasks and obtain competitive results.
    
[^150]: 冲突回避梯度下降用于多任务学习

    Conflict-Averse Gradient Descent for Multi-task Learning

    [https://arxiv.org/abs/2110.14048](https://arxiv.org/abs/2110.14048)

    冲突回避梯度下降（CAGrad）是针对多任务学习中梯度冲突问题提出的方法，旨在解决不同任务梯度不一致导致的性能下降挑战。

    

    多任务学习的目标是通过共享模型结构来实现比单任务学习更高效的学习，以适应各种任务。标准的多任务学习目标是最小化所有任务的平均损失。然而，使用这个目标通常会导致每个任务的最终表现比独立学习它们时更差。在优化多任务模型中的一个主要挑战是冲突梯度，即不同任务目标的梯度不太一致，因此遵循平均梯度方向可能对特定任务的性能有害。先前的研究提出了几种启发式方法来操纵任务梯度以缓解这个问题。但是大多数方法缺乏收敛保证和/或可能收敛到任何帕累托稳定点。在本文中，我们介绍了一种叫做冲突回避梯度下降（CAGrad）的方法，通过最小化平均损失函数

    arXiv:2110.14048v2 Announce Type: replace-cross  Abstract: The goal of multi-task learning is to enable more efficient learning than single task learning by sharing model structures for a diverse set of tasks. A standard multi-task learning objective is to minimize the average loss across all tasks. While straightforward, using this objective often results in much worse final performance for each task than learning them independently. A major challenge in optimizing a multi-task model is the conflicting gradients, where gradients of different task objectives are not well aligned so that following the average gradient direction can be detrimental to specific tasks' performance. Previous work has proposed several heuristics to manipulate the task gradients for mitigating this problem. But most of them lack convergence guarantee and/or could converge to any Pareto-stationary point. In this paper, we introduce Conflict-Averse Gradient descent (CAGrad) which minimizes the average loss funct
    
[^151]: OASIS中的本体智能合约：代理、系统和服务集成的本体（扩展版）

    Ontological Smart Contracts in OASIS: Ontology for Agents, Systems, and Integration of Services (Extended Version)

    [https://arxiv.org/abs/2012.01410](https://arxiv.org/abs/2012.01410)

    本文扩展了一种用于代理建模的本体OASIS，引入了条件和本体智能合约（OSCs），将其应用于扩展区块链和智能合约，并提出了基于OASIS OSCs定义的框架架构。

    

    在这篇论文中，我们通过条件和本体智能合约（简称为OSCs）扩展了一种用于建模代理及其交互的本体，称为代理、系统和服务集成的本体（简称OASIS）。 OASIS中定义的条件和OSCs被应用于扩展具有本体能力的数字公共账本，如区块链和其上实施的智能合约。

    arXiv:2012.01410v4 Announce Type: replace  Abstract: In this contribution we extend an ontology for modelling agents and their interactions, called Ontology for Agents, Systems, and Integration of Services (in short, OASIS), with conditionals and ontological smart contracts (in short, OSCs). OSCs are ontological representations of smart contracts that allow to establish responsibilities and authorizations among agents and set agreements, whereas conditionals allow one to restrict and limit agent interactions, define activation mechanisms that trigger agent actions, and define constraints and contract terms on OSCs. Conditionals and OSCs, as defined in OASIS, are applied to extend with ontological capabilities digital public ledgers such as the blockchain and smart contracts implemented on it. We will also sketch the architecture of a framework based on the OASIS definition of OSCs that exploits the Ethereum platform and the Interplanetary File System.
    
[^152]: 多元贝塔混合模型：具有灵活聚类形状的概率聚类方法

    Multivariate Beta Mixture Model: Probabilistic Clustering With Flexible Cluster Shapes. (arXiv:2401.16708v1 [cs.LG])

    [http://arxiv.org/abs/2401.16708](http://arxiv.org/abs/2401.16708)

    本文提出了一种名为多元贝塔混合模型（MBMM）的新的概率模型，用于软聚类。MBMM通过其灵活的多元贝塔分布的概率密度函数适应不同的聚类形状，并在合成和真实数据集上展示了其适应性。

    

    本文介绍了多元贝塔混合模型（MBMM），这是一种新的概率模型用于软聚类。MBMM通过多元贝塔分布的灵活概率密度函数适应不同的聚类形状。我们介绍了MBMM的属性，描述了参数学习过程，并展示了在合成和真实数据集上适合各种聚类形状的实验结果。代码匿名发布在\url{https://github.com/hhchen1105/mbmm/}上。

    This paper introduces the multivariate beta mixture model (MBMM), a new probabilistic model for soft clustering. MBMM adapts to diverse cluster shapes because of the flexible probability density function of the multivariate beta distribution. We introduce the properties of MBMM, describe the parameter learning procedure, and present the experimental results, showing that MBMM fits diverse cluster shapes on synthetic and real datasets. The code is released anonymously at \url{https://github.com/hhchen1105/mbmm/}.
    
[^153]: SH2: 自我突出式犹豫帮助您更准确解码。

    SH2: Self-Highlighted Hesitation Helps You Decode More Truthfully. (arXiv:2401.05930v1 [cs.CL])

    [http://arxiv.org/abs/2401.05930](http://arxiv.org/abs/2401.05930)

    自我突出式犹豫（SH2）是一种推理时的方法，通过选择预测概率较低的标记，并强调它们的差异，从而帮助语言模型更准确地解码。

    

    大型语言模型(LLMs)在文本生成方面表现出色。然而，LLMs仍然存在幻觉问题。在本研究中，我们提出了一种推理时方法，即自我突出式犹豫(SH2)，以帮助LLMs更准确地解码。SH2基于信息理论中一个简单的事实，即对于LLMs而言，预测概率较低的标记往往更具信息量。我们的分析表明，LLMs给予较低概率的标记更有可能与事实信息（如名词、专有名词和形容词）密切相关。因此，我们提出通过选择概率最低的标记并将其连接到原始上下文中来“突出”事实信息，从而迫使模型在生成之前多次阅读和犹豫这些标记。在解码过程中，我们还采用对比解码的方式来强调由犹豫带来的输出概率的差异。

    Large language models (LLMs) demonstrate great performance in text generation. However, LLMs are still suffering from hallucinations. In this work, we propose an inference-time method, Self-Highlighted Hesitation (SH2), to help LLMs decode more truthfully. SH2 is based on a simple fact rooted in information theory that for an LLM, the tokens predicted with lower probabilities are prone to be more informative than others. Our analysis shows that the tokens assigned with lower probabilities by an LLM are more likely to be closely related to factual information, such as nouns, proper nouns, and adjectives. Therefore, we propose to ''highlight'' the factual information by selecting the tokens with the lowest probabilities and concatenating them to the original context, thus forcing the model to repeatedly read and hesitate on these tokens before generation. During decoding, we also adopt contrastive decoding to emphasize the difference in the output probabilities brought by the hesitation.
    
[^154]: ANGO: 一个面向生成型语言模型的中文领域评估基准

    ANGO: A Next-Level Evaluation Benchmark For Generation-Oriented Language Models In Chinese Domain. (arXiv:2401.04898v1 [cs.CL])

    [http://arxiv.org/abs/2401.04898](http://arxiv.org/abs/2401.04898)

    ANGO是一个中文领域生成型语言模型评估基准，引入了关键点分类标准，提供了更好的可解释性，同时建立了可量化的问题难度标准，对模型训练提供了更精确的指导。

    

    最近，出现了各种大规模语言模型（LLMs）评估数据集，但其中大多数存在排名失真和模型能力分析困难的问题。针对这些问题，本文引入了ANGO，一个中文多项选择题评估基准。ANGO首次提出了“关键点”分类标准，ANGO中的每个问题可以对应多个关键点，有效提高了评估结果的可解释性。基于真人表现的性能，我们建立了可量化的问题难度标准，并将ANGO问题分为9个难度级别，为模型训练提供了更精确的指导。为了最小化数据泄漏的影响并充分利用ANGO的创新特点，我们设计了独家抽样策略和新的评估框架，支持快速测试集迭代。我们的实验证明，ANGO对模型提出了更大的挑战，并在评估结果中揭示出更多细节。

    Recently, various Large Language Models (LLMs) evaluation datasets have emerged, but most of them have issues with distorted rankings and difficulty in model capabilities analysis. Addressing these concerns, this paper introduces ANGO, a Chinese multi-choice question evaluation benchmark. ANGO proposes \textit{Keypoint} categorization standard for the first time, each question in ANGO can correspond to multiple keypoints, effectively enhancing interpretability of evaluation results. Base on performance of real humans, we build a quantifiable question difficulty standard and divide ANGO questions into 9 difficulty levels, which provide more precise guidance for model training. To minimize data leakage impact and fully leverage ANGO's innovative features, we have engineered exclusive sampling strategies and a new evaluation framework that support swift testset iteration. Our experiments demonstrate that ANGO poses a stronger challenge to models and reveals more details in evaluation resu
    
[^155]: ICMC-ASR：ICASSP 2024年汽车多通道自动语音识别挑战赛

    ICMC-ASR: The ICASSP 2024 In-Car Multi-Channel Automatic Speech Recognition Challenge. (arXiv:2401.03473v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2401.03473](http://arxiv.org/abs/2401.03473)

    ICMC-ASR挑战赛是为了促进驾驶场景下的语音处理和识别研究而举办的，包括自动语音识别（ASR）和自动语音分离和识别（ASDR）两个赛道，取得了显著的改善。最终，USTCiflytek队在ASR赛道上获得了13.16%的CER，ASDR赛道上获得了21.48%的cpCER。

    

    为了促进驾驶场景下的语音处理和识别研究，我们基于ISCSLP 2022年度举办的智能座舱语音识别挑战赛（ICSRC）的成功经验，推出了ICASSP 2024年汽车多通道自动语音识别（ICMC-ASR）挑战赛。该挑战收集了100多小时的新能源汽车内部多通道语音数据以及40小时的噪声进行数据增强。设立了自动语音识别（ASR）和自动语音分离和识别（ASDR）两个赛道，并分别使用字符错误率（CER）和连接最小置换字符错误率（cpCER）作为评估指标。总体上，ICMC-ASR挑战赛吸引了98支参赛队伍，并在两个赛道上收到了53个有效结果。最终，USTCiflytek队在ASR赛道上实现了13.16%的CER，在ASDR赛道上实现了21.48%的cpCER，分别相对于我们挑战赛准则的绝对改善率为13.08%和51.4%。

    To promote speech processing and recognition research in driving scenarios, we build on the success of the Intelligent Cockpit Speech Recognition Challenge (ICSRC) held at ISCSLP 2022 and launch the ICASSP 2024 In-Car Multi-Channel Automatic Speech Recognition (ICMC-ASR) Challenge. This challenge collects over 100 hours of multi-channel speech data recorded inside a new energy vehicle and 40 hours of noise for data augmentation. Two tracks, including automatic speech recognition (ASR) and automatic speech diarization and recognition (ASDR) are set up, using character error rate (CER) and concatenated minimum permutation character error rate (cpCER) as evaluation metrics, respectively. Overall, the ICMC-ASR Challenge attracts 98 participating teams and receives 53 valid results in both tracks. In the end, first-place team USTCiflytek achieves a CER of 13.16% in the ASR track and a cpCER of 21.48% in the ASDR track, showing an absolute improvement of 13.08% and 51.4% compared to our chal
    
[^156]: 在文本分类中探索语言模型中的概念级别的误相关性

    Explore Spurious Correlations at the Concept Level in Language Models for Text Classification. (arXiv:2311.08648v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2311.08648](http://arxiv.org/abs/2311.08648)

    本文研究了语言模型在文本分类中概念级别的误相关性问题，并通过使用ChatGPT分配概念标签和引入数据再平衡技术来解决这一问题。

    

    语言模型在众多自然语言处理任务中取得了显著的成功，采用了微调和上下文学习方法。虽然语言模型表现出卓越的性能，但由于训练数据中标签分布不平衡或上下文学习实例产生的误相关性，它们面临着鲁棒性挑战。以往的研究主要集中在词语、短语和句法特征上，忽视了概念级别的研究，这往往是由于缺乏概念标签和难以确定输入文本中的概念内容。本文提出了两个主要贡献。首先，我们使用ChatGPT为文本分配概念标签，评估模型在微调或上下文学习测试数据中的概念偏差。我们发现，当语言模型在训练或提示中遇到概念和标签之间的误相关性时，会采取预测的捷径。其次，我们引入了一种数据再平衡技术，将ChatGPT生成的反事实数据纳入其中。

    Language models (LMs) have achieved notable success in numerous NLP tasks, employing both fine-tuning and in-context learning (ICL) methods. While language models demonstrate exceptional performance, they face robustness challenges due to spurious correlations arising from imbalanced label distributions in training data or ICL exemplars. Previous research has primarily concentrated on word, phrase, and syntax features, neglecting the concept level, often due to the absence of concept labels and difficulty in identifying conceptual content in input texts. This paper introduces two main contributions. First, we employ ChatGPT to assign concept labels to texts, assessing concept bias in models during fine-tuning or ICL on test data. We find that LMs, when encountering spurious correlations between a concept and a label in training or prompts, resort to shortcuts for predictions. Second, we introduce a data rebalancing technique that incorporates ChatGPT-generated counterfactual data, ther
    
[^157]: 时序因果图的抽象中总效应的可识别性研究

    Identifiability of total effects from abstractions of time series causal graphs. (arXiv:2310.14691v2 [math.ST] CROSS LISTED)

    [http://arxiv.org/abs/2310.14691](http://arxiv.org/abs/2310.14691)

    本文研究了基于因果图抽象从观测时间序列中识别干预总效应的问题，并证明了在扩展摘要因果图中总效应总是可识别的。同时，我们提供了摘要因果图中总效应可识别的必要和充分的图形条件，并提供了调整集合以估计总效应。

    

    我们研究了仅基于系统的因果图抽象从观测时间序列中识别干预总效应的问题。具体而言，我们考虑了两种类型的抽象：扩展摘要因果图将所有滞后因果关系混淆在一起，但区分滞后和瞬时关系；而摘要因果图则不提供任何关于因果关系滞后的指示。我们证明扩展摘要因果图中总效应总是可识别的，并且我们提供了摘要因果图中的可识别性所必需和充分的图形条件。此外，在总效应可识别时，我们提供了用于估计总效应的调整集合。

    We study the problem of identifiability of the total effect of an intervention from observational time series only given an abstraction of the causal graph of the system. Specifically, we consider two types of abstractions: the extended summary causal graph which conflates all lagged causal relations but distinguishes between lagged and instantaneous relations; and the summary causal graph which does not give any indication about the lag between causal relations. We show that the total effect is always identifiable in extended summary causal graphs and we provide necessary and sufficient graphical conditions for identifiability in summary causal graphs. Furthermore, we provide adjustment sets allowing to estimate the total effect whenever it is identifiable.
    
[^158]: EEG运动意向解码：一种与通道关注机制相比较的分析框架

    EEG motor imagery decoding: A framework for comparative analysis with channel attention mechanisms. (arXiv:2310.11198v1 [cs.HC])

    [http://arxiv.org/abs/2310.11198](http://arxiv.org/abs/2310.11198)

    本研究探索了在运动意向解码领域应用不同通道关注机制的可行性，通过构建一个轻量级架构框架，并在同一环境中比较它们的影响，结果表明这些机制的易集成性和低计算复杂度使其成为BCI中运动意向解码的有效方法。

    

    本研究的目标是探讨在大脑-计算机接口（BCI）领域中应用各种通道关注机制于运动意向解码。通道关注机制可以视为传统用于运动意向解码的空间滤波器的强大演进。本研究通过将这些机制整合到一个轻量级架构框架中，系统地比较它们的影响。我们精心构建了一个简单而轻量级的基准架构，旨在无缝集成不同的通道关注机制。这种方法与之前的研究相反，之前的研究只研究一个关注机制，并且通常构建一个非常复杂、有时嵌套的架构。我们的框架使我们能够在相同情况下评估和比较不同的关注机制的影响。易于集成不同的通道关注机制以及低计算复杂度使我们能够高效地研究和推进BCI中的运动意向解码。

    The objective of this study is to investigate the application of various channel attention mechanisms within the domain of brain-computer interface (BCI) for motor imagery decoding. Channel attention mechanisms can be seen as a powerful evolution of spatial filters traditionally used for motor imagery decoding. This study systematically compares such mechanisms by integrating them into a lightweight architecture framework to evaluate their impact. We carefully construct a straightforward and lightweight baseline architecture designed to seamlessly integrate different channel attention mechanisms. This approach is contrary to previous works which only investigate one attention mechanism and usually build a very complex, sometimes nested architecture. Our framework allows us to evaluate and compare the impact of different attention mechanisms under the same circumstances. The easy integration of different channel attention mechanisms as well as the low computational complexity enables us
    
[^159]: QLLM: 大规模语言模型的准确高效低位宽量化

    QLLM: Accurate and Efficient Low-Bitwidth Quantization for Large Language Models. (arXiv:2310.08041v1 [cs.CL])

    [http://arxiv.org/abs/2310.08041](http://arxiv.org/abs/2310.08041)

    QLLM是一种为大规模语言模型设计的准确高效的低位宽后训练量化方法，通过引入自适应通道重组技术，将离群值的大小重新分配给其他通道，从而减轻它们对量化范围的影响。

    

    大规模语言模型在自然语言处理领域表现出色，但由于其所需资源过大，限制了其广泛应用。虽然量化感知训练（Quantization-Aware Training，QAT）提供了一种解决方案，但它的训练成本过高，因此后训练量化（Post-Training Quantization，PTQ）成为大规模语言模型更实际的方法。在现有研究中，特定通道中的激活离群值被认为是导致后训练量化准确性下降的瓶颈。本文提出了QLLM，一种为大规模语言模型设计的准确高效的低位宽后训练量化方法。QLLM引入了一种自适应通道重组技术，将离群值的大小重新分配给其他通道，从而减轻它们对量化范围的影响。具体来说，通过通道拆分和通道组装，在保证低位宽的情况下将离群通道分解成多个子通道。

    Large Language Models (LLMs) excel in NLP, but their demands hinder their widespread deployment. While Quantization-Aware Training (QAT) offers a solution, its extensive training costs make Post-Training Quantization (PTQ) a more practical approach for LLMs. In existing studies, activation outliers in particular channels are identified as the bottleneck to PTQ accuracy. They propose to transform the magnitudes from activations to weights, which however offers limited alleviation or suffers from unstable gradients, resulting in a severe performance drop at low-bitwidth. In this paper, we propose QLLM, an accurate and efficient low-bitwidth PTQ method designed for LLMs. QLLM introduces an adaptive channel reassembly technique that reallocates the magnitude of outliers to other channels, thereby mitigating their impact on the quantization range. This is achieved by channel disassembly and channel assembly, which first breaks down the outlier channels into several sub-channels to ensure a 
    
[^160]: 可解释的扩散模型通过信息分解

    Interpretable Diffusion via Information Decomposition. (arXiv:2310.07972v1 [cs.LG])

    [http://arxiv.org/abs/2310.07972](http://arxiv.org/abs/2310.07972)

    本研究通过观察扩散和信息分解之间的关系，揭示了扩散模型学习到的细粒度关系，进一步解决了高维空间中信息携带变量的问题。

    

    去噪扩散模型能够用于复杂关系的条件生成和密度建模，如图像和文本。然而，学习到的关系的本质是不透明的，因此很难准确理解单词和图像部分之间的关系，或者预测干预的效果。我们通过观察扩散和信息分解之间的精确关系，揭示了扩散模型学习到的细粒度关系。互信息和条件互信息的精确表达可以通过去噪模型来计算。此外，也可以轻松估计在特定图像和标题之间的关系。进一步对信息进行分解，以理解高维空间中哪些变量携带信息，是一个长期存在的问题。对于扩散模型，我们展示了一种自然的非负信息分解方法。

    Denoising diffusion models enable conditional generation and density modeling of complex relationships like images and text. However, the nature of the learned relationships is opaque making it difficult to understand precisely what relationships between words and parts of an image are captured, or to predict the effect of an intervention. We illuminate the fine-grained relationships learned by diffusion models by noticing a precise relationship between diffusion and information decomposition. Exact expressions for mutual information and conditional mutual information can be written in terms of the denoising model. Furthermore, pointwise estimates can be easily estimated as well, allowing us to ask questions about the relationships between specific images and captions. Decomposing information even further to understand which variables in a high-dimensional space carry information is a long-standing problem. For diffusion models, we show that a natural non-negative decomposition of mutu
    
[^161]: 扩散模型的去噪任务路由

    Denoising Task Routing for Diffusion Models. (arXiv:2310.07138v1 [cs.CV])

    [http://arxiv.org/abs/2310.07138](http://arxiv.org/abs/2310.07138)

    本文提出了一种名为去噪任务路由的策略，通过为扩散模型的不同任务建立独立的信息路径，实现了对多任务学习的明确纳入。该方法将去噪任务的先验知识无缝集成到框架中，通过激活相似的通道和滑动窗口的方式，充分利用了相邻时间步任务间的亲和关系。

    

    扩散模型通过学习多步去噪过程生成高度逼真的图像，自然地体现了多任务学习（MTL）的原理。尽管扩散模型和MTL之间存在固有的连接，但在设计明确将MTL纳入扩散模型框架的神经结构方面仍存在一个未被探索的领域。在本文中，我们提出了去噪任务路由（DTR），一种对现有扩散模型架构进行简单附加的策略，通过选择性地激活模型中的子通道来为单个任务建立独立的信息路径。DTR的特别吸引人之处在于它将去噪任务的先验知识无缝集成到框架中：（1）任务亲和性：DTR为相邻时间步的任务激活相似的通道，并将激活的通道作为滑动窗口通过时间步进行移动，利用相邻时间步任务间固有的强亲和关系。

    Diffusion models generate highly realistic images through learning a multi-step denoising process, naturally embodying the principles of multi-task learning (MTL). Despite the inherent connection between diffusion models and MTL, there remains an unexplored area in designing neural architectures that explicitly incorporate MTL into the framework of diffusion models. In this paper, we present Denoising Task Routing (DTR), a simple add-on strategy for existing diffusion model architectures to establish distinct information pathways for individual tasks within a single architecture by selectively activating subsets of channels in the model. What makes DTR particularly compelling is its seamless integration of prior knowledge of denoising tasks into the framework: (1) Task Affinity: DTR activates similar channels for tasks at adjacent timesteps and shifts activated channels as sliding windows through timesteps, capitalizing on the inherent strong affinity between tasks at adjacent timestep
    
[^162]: 缩放定律在联想记忆中的应用

    Scaling Laws for Associative Memories. (arXiv:2310.02984v1 [stat.ML])

    [http://arxiv.org/abs/2310.02984](http://arxiv.org/abs/2310.02984)

    本文研究了应用于联想记忆中的缩放定律，通过高维矩阵和嵌入的外积来模拟内层Transformer语言模型。作者推导出了与样本数量和参数大小相关的精确缩放定律，并验证了理论结果的有效性。同时，作者还通过大量实验展示了存储记忆关联的细粒度可视化。

    

    学习很可能涉及到抽象规则的发现和记忆。本文旨在研究联想记忆机制。我们的模型基于高维矩阵，由嵌入的外积组成，与Transformer语言模型的内层相关。我们推导出关于样本数量和参数规模的精确缩放定律，并讨论了不同估计器的统计效率，包括基于优化的算法。我们进行了大量的数值实验，以验证和解释理论结果，包括对存储记忆关联的细粒度可视化。

    Learning arguably involves the discovery and memorization of abstract rules. The aim of this paper is to study associative memory mechanisms. Our model is based on high-dimensional matrices consisting of outer products of embeddings, which relates to the inner layers of transformer language models. We derive precise scaling laws with respect to sample size and parameter size, and discuss the statistical efficiency of different estimators, including optimization-based algorithms. We provide extensive numerical experiments to validate and interpret theoretical results, including fine-grained visualizations of the stored memory associations.
    
[^163]: MIDDAG：新闻走向何方？通过社区级信息路径研究信息传播

    MIDDAG: Where Does Our News Go? Investigating Information Diffusion via Community-Level Information Pathways. (arXiv:2310.02529v1 [cs.SI])

    [http://arxiv.org/abs/2310.02529](http://arxiv.org/abs/2310.02529)

    MIDDAG是一个交互式系统，通过可视化社交媒体上由COVID-19相关新闻触发的信息传播路径，提供全面的洞察力，并能构建用户社区和预测信息传播，从而追踪和理解信息的传播方式。

    

    我们提出了MIDDAG，一个直观、交互式的系统，可以可视化由COVID-19相关新闻文章触发的社交媒体信息传播路径，并提供包括用户/社区易感性水平、以及信息传播过程中引发的事件和广大群众的热门观点的全面洞察。除了发现用户之间的信息流模式，我们还构建了用户之间的社区，并开发了传播预测能力，从而实现对高层次信息传播方式的追踪和理解。

    We present MIDDAG, an intuitive, interactive system that visualizes the information propagation paths on social media triggered by COVID-19-related news articles accompanied by comprehensive insights including user/community susceptibility level, as well as events and popular opinions raised by the crowd while propagating the information. Besides discovering information flow patterns among users, we construct communities among users and develop the propagation forecasting capability, enabling tracing and understanding of how information is disseminated at a higher level.
    
[^164]: 实体推断竞技场：探究LLMs的对话推理和规划能力的平台

    The Entity-Deduction Arena: A playground for probing the conversational reasoning and planning capabilities of LLMs. (arXiv:2310.01468v1 [cs.CL])

    [http://arxiv.org/abs/2310.01468](http://arxiv.org/abs/2310.01468)

    本文提供了一个评估框架，通过向法官提出一系列查询来评估LLMs的对话推理和规划能力。我们发现不同的LLMs在这个任务上表现出显著差异。

    

    目前，大型语言模型（LLMs）在回答明确提问时非常有效。然而，当面临含糊不清的查询时，它们可能行为难以预测并产生错误的输出。这凸显了需要开发能够提出澄清问题以有效解决歧义的智能代理的需求。这种能力需要对多个对话轮次进行复杂的理解、状态跟踪、推理和规划。然而，直接测量这种能力可能具有挑战性。在本文中，我们提供了一个替代性问题，通过向法官提出一系列查询，评估了LLMs推断自己不知道但被法官揭示的实体的能力。这个“实体推断游戏”可以作为一个评估框架，用于探究语言模型的对话推理和规划能力。我们系统地评估了各种LLMs，并发现在这个任务上它们的性能存在显著差异。我们发现强大的LLMs...

    Large language models (LLMs) are currently effective at answering questions that are clearly asked. However, when faced with ambiguous queries they can act unpredictably and produce incorrect outputs. This underscores the need for the development of intelligent agents capable of asking clarification questions to resolve ambiguities effectively. This capability requires complex understanding, state tracking, reasoning and planning over multiple conversational turns. However, directly measuring this can be challenging. In this paper, we offer a surrogate problem which assesses an LLMs's capability to deduce an entity unknown to itself, but revealed to a judge, by asking the judge a series of queries. This \textit{entity-deducing game} can serve as an evaluation framework to probe the conversational reasoning and planning capabilities of language models. We systematically evaluate various LLMs and discover significant differences in their performance on this task. We find that strong LLMs
    
[^165]: ToRA：一种集成工具的数学问题求解推理代理

    ToRA: A Tool-Integrated Reasoning Agent for Mathematical Problem Solving. (arXiv:2309.17452v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2309.17452](http://arxiv.org/abs/2309.17452)

    ToRA是一种集成工具的数学问题求解推理代理，通过结合语言的分析能力和工具的计算效率，能够显著提高数学推理的性能，在多个数学推理数据集上取得了13%-19%的平均绝对改进率，并在竞赛级数据集MATH上达到了44.6%的性能。

    

    大型语言模型在各种语言任务中取得了重大进展，但在复杂的数学问题上仍然存在困难。在本文中，我们提出了一系列集成工具的推理代理ToRA，它通过无缝地将自然语言推理与外部工具（例如计算库和符号求解器）的利用相结合，从而将语言的分析能力与工具的计算效率融合在一起，用于解决具有挑战性的数学问题。为了训练ToRA，我们精选了数学数据集上的互动工具使用轨迹，应用模仿学习于注释，并提出输出空间整形来进一步改进模型的推理行为。结果显示，ToRA模型在10个涵盖各种规模的数学推理数据集上显著优于开源模型，平均绝对改进率达到13%至19%。值得注意的是，ToRA-7B 在竞赛级数据集MATH上达到了44.6%，超越了最佳开源模型WizardMath。

    Large language models have made significant progress in various language tasks, yet they still struggle with complex mathematics. In this paper, we propose ToRA a series of Tool-integrated Reasoning Agents designed to solve challenging mathematical problems by seamlessly integrating natural language reasoning with the utilization of external tools (e.g., computation libraries and symbolic solvers), thereby amalgamating the analytical prowess of language and the computational efficiency of tools. To train ToRA, we curate interactive tool-use trajectories on mathematical datasets, apply imitation learning on the annotations, and propose output space shaping to further refine models' reasoning behavior. As a result, ToRA models significantly outperform open-source models on 10 mathematical reasoning datasets across all scales with 13%-19% absolute improvements on average. Notably, ToRA-7B reaches 44.6% on the competition-level dataset MATH, surpassing the best open-source model WizardMath
    
[^166]: 提升大规模语言模型在编码中的能力通过多角度自一致性

    Enhancing Large Language Models in Coding Through Multi-Perspective Self-Consistency. (arXiv:2309.17272v1 [cs.CL])

    [http://arxiv.org/abs/2309.17272](http://arxiv.org/abs/2309.17272)

    本文提出了一个名为多角度自一致性（MPSC）的框架，用于提升大规模语言模型在复杂的代码生成任务中的性能。该框架通过从多个角度采样多个输出并构建一个多部分图，利用交叉一致性和内一致性信息来选择最优输出。

    

    大规模语言模型（LLMs）在文本生成方面展现了卓越的能力。然而，在复杂的推理任务，如代码生成中，LLMs仍然难以在一次尝试中生成正确的答案。先前的研究通过聚合多个输出，利用它们之间的一致性来探索解决方案。然而，这些研究没有全面地从不同的角度捕捉这种一致性。在本文中，我们提出了一种名为多角度自一致性（MPSC）框架的新的解码策略，用于LLM，它将来自多个角度的输出之间的交叉一致性和单个角度内的内一致性结合起来。具体而言，我们要求LLMs对给定查询从各个角度采样多个多样化的输出，并基于它们构建一个多部分图。通过两个预定义的一致性度量，我们将交叉一致性和内一致性信息嵌入到图中。最佳选择是根据这些一致性度量来选择输出。

    Large language models (LLMs) have exhibited remarkable ability in textual generation. However, in complex reasoning tasks such as code generation, generating the correct answer in a single attempt remains a formidable challenge for LLMs. Previous research has explored solutions by aggregating multiple outputs, leveraging the consistency among them. However, none of them have comprehensively captured this consistency from different perspectives. In this paper, we propose the Multi-Perspective Self-Consistency (MPSC) framework, a novel decoding strategy for LLM that incorporates both inter-consistency across outputs from multiple perspectives and intra-consistency within a single perspective. Specifically, we ask LLMs to sample multiple diverse outputs from various perspectives for a given query and then construct a multipartite graph based on them. With two predefined measures of consistency, we embed both inter- and intra-consistency information into the graph. The optimal choice is th
    
[^167]: TranDRL：一种基于Transformer驱动的深度强化学习支持的预防性维护框架

    TranDRL: A Transformer-Driven Deep Reinforcement Learning Enabled Prescriptive Maintenance Framework. (arXiv:2309.16935v1 [cs.LG])

    [http://arxiv.org/abs/2309.16935](http://arxiv.org/abs/2309.16935)

    TranDRL是一种基于Transformer驱动的深度强化学习支持的预防性维护框架，结合了复杂时间模式捕捉和经济高效维护建议，显著提高了剩余寿命（RUL）预测准确性和维护行动优化。

    

    工业系统需要可靠的预测性维护策略来提高运营效率并减少停机时间。本文介绍了一种新颖的综合框架，利用Transformer神经网络和深度强化学习（DRL）算法来优化维护行动。我们的方法采用Transformer模型来有效捕捉传感器数据中的复杂时间模式，从而准确预测设备的剩余寿命（RUL）。同时，我们框架中的DRL组件提供了经济高效和及时的维护建议。我们在NASA C-MPASS数据集上验证了我们框架的有效性，结果显示在RUL预测准确性和维护行动优化方面取得了显著进展。因此，我们的创新方法为预防性维护提供了一种创新的数据驱动方法，解决了工业运营中的关键挑战，并带来了更多发展机遇。

    Industrial systems demand reliable predictive maintenance strategies to enhance operational efficiency and reduce downtime. This paper introduces a novel, integrated framework that leverages the power of transformer neural networks and deep reinforcement learning (DRL) algorithms to optimize maintenance actions. Our approach employs the transformer model to effectively capture complex temporal patterns in sensor data, thereby accurately predicting the Remaining Useful Life (RUL) of equipment. Simultaneously, the DRL component of our framework provides cost-effective and timely maintenance recommendations. We validate the efficacy of our framework on the NASA C-MPASS dataset, where it demonstrates significant advancements in both RUL prediction accuracy and the optimization of maintenance actions. Consequently, our pioneering approach provides an innovative data-driven methodology for prescriptive maintenance, addressing key challenges in industrial operations and leading the way to mor
    
[^168]: 人工生成的演示是否对于上下文学习有必要？

    Are Human-generated Demonstrations Necessary for In-context Learning?. (arXiv:2309.14681v1 [cs.LG])

    [http://arxiv.org/abs/2309.14681](http://arxiv.org/abs/2309.14681)

    本文研究了上下文学习中人工生成的演示是否有必要，并提出了一种新的自反思提示策略（SEC），通过这种策略，大型语言模型（LLMs）可以自行生成演示和最终输出，避免了手动生成过程的复杂性。

    

    尽管大型语言模型（LLMs）具备良好的少样本能力，但在上下文学习（ICL）的标准范式中存在以下弊端：易受选定演示的影响，生成这些演示的复杂性。本文提出了对于ICL，人工生成的演示是否有必要的基本问题，并提出了自反思提示策略（SEC），这是一种不依赖人工演示的范例。SEC的关键点在于，不使用手工制作的示例作为ICL中的演示，而是要求LLMs首先自行创建演示，然后生成最终输出。SEC是一种灵活的框架，可适应原始ICL和“思维链”（CoT），并且更加便捷：因为可以节省示例和理由的手动生成过程。在算术推理、常识推理和多任务语言理解方面进行了大量实验。

    Despite the promising few-shot ability of large language models (LLMs), the standard paradigm of In-context Learning (ICL) suffers the disadvantages of susceptibility to selected demonstrations and the intricacy to generate these demonstrations. In this paper, we raise the fundamental question that whether human-generated demonstrations are necessary for ICL. To answer this question, we propose self-contemplation prompting strategy (SEC), a paradigm free from human-crafted demonstrations. The key point of SEC is that, instead of using hand-crafted examples as demonstrations in ICL, SEC asks LLMs to first create demonstrations on their own, based on which the final output is generated. SEC is a flexible framework and can be adapted to both the vanilla ICL and the chain-of-thought (CoT), but with greater ease: as the manual-generation process of both examples and rationale can be saved. Extensive experiments in arithmetic reasoning, commonsense reasoning, multi-task language understandin
    
[^169]: 提升模仿学习用于自动驾驶的交通规则遵守的关键因素

    What Matters to Enhance Traffic Rule Compliance of Imitation Learning for Automated Driving. (arXiv:2309.07808v1 [cs.CV])

    [http://arxiv.org/abs/2309.07808](http://arxiv.org/abs/2309.07808)

    本文提出了一种基于惩罚的模仿学习方法P-CSG，结合语义生成传感器融合技术，以提高端到端自动驾驶的整体性能，并解决了交通规则遵守和传感器感知问题。

    

    最近越来越多的研究关注于全端到端的自动驾驶技术，在这种技术中，整个驾驶流程被替换为一个简单的神经网络，由于其结构简单和推理时间快，因此变得非常吸引人。尽管这种方法大大减少了驾驶流程中的组件，但其简单性也导致解释性问题和安全问题。训练得到的策略并不总是符合交通规则，同时也很难发现其错误的原因，因为缺乏中间输出。同时，传感器对于自动驾驶的安全性和可行性也至关重要，可以帮助感知复杂驾驶场景下的周围环境。本文提出了一种全新的基于惩罚的模仿学习方法P-CSG，结合语义生成传感器融合技术，以提高端到端自动驾驶的整体性能。我们对模型的性能进行了评估。

    More research attention has recently been given to end-to-end autonomous driving technologies where the entire driving pipeline is replaced with a single neural network because of its simpler structure and faster inference time. Despite this appealing approach largely reducing the components in driving pipeline, its simplicity also leads to interpretability problems and safety issues arXiv:2003.06404. The trained policy is not always compliant with the traffic rules and it is also hard to discover the reason for the misbehavior because of the lack of intermediate outputs. Meanwhile, Sensors are also critical to autonomous driving's security and feasibility to perceive the surrounding environment under complex driving scenarios. In this paper, we proposed P-CSG, a novel penalty-based imitation learning approach with cross semantics generation sensor fusion technologies to increase the overall performance of End-to-End Autonomous Driving. We conducted an assessment of our model's perform
    
[^170]: 图神经网络中的等级崩塌导致平滑过度和关联过高

    Rank Collapse Causes Over-Smoothing and Over-Correlation in Graph Neural Networks. (arXiv:2308.16800v1 [cs.LG])

    [http://arxiv.org/abs/2308.16800](http://arxiv.org/abs/2308.16800)

    本文研究了图神经网络中的平滑过度和特征关联过高现象，发现固定不变的子空间导致了节点表示的等级崩塌。在该子空间中平滑向量的存在导致过度平滑，即使避免过度平滑也会导致过高的关联。为了解决这个问题，我们提出了一种克罗内克积之和作为一种有效方法。

    

    我们的研究揭示了深度图神经网络中平滑过度和特征关联过高的新理论见解。我们展示了固定不变子空间的普遍存在，它表现出一种相对的行为，不受特征转换的影响。我们的工作阐明了与收敛到常数状态和节点状态的过分分离相关的最新观察结果，因为子空间的放大只取决于聚合函数的频谱。在线性场景中，这导致节点表示由低维子空间主导，并且具有与特征转换无关的渐近收敛速率。当平滑向量跨越这个子空间时，这会导致节点表示的等级崩塌，从而导致过度平滑，即使避免过度平滑也会导致过高的关联。在我们的理论指导下，我们提出了一种克罗内克积之和作为一种有益特性，可以可靠地防止过度平滑、过高关联和等级崩塌。

    Our study reveals new theoretical insights into over-smoothing and feature over-correlation in deep graph neural networks. We show the prevalence of invariant subspaces, demonstrating a fixed relative behavior that is unaffected by feature transformations. Our work clarifies recent observations related to convergence to a constant state and a potential over-separation of node states, as the amplification of subspaces only depends on the spectrum of the aggregation function. In linear scenarios, this leads to node representations being dominated by a low-dimensional subspace with an asymptotic convergence rate independent of the feature transformations. This causes a rank collapse of the node representations, resulting in over-smoothing when smooth vectors span this subspace, and over-correlation even when over-smoothing is avoided. Guided by our theory, we propose a sum of Kronecker products as a beneficial property that can provably prevent over-smoothing, over-correlation, and rank c
    
[^171]: 使用基于图的多智能体强化学习学习协作信息传播

    Learning Collaborative Information Dissemination with Graph-based Multi-Agent Reinforcement Learning. (arXiv:2308.16198v1 [cs.LG])

    [http://arxiv.org/abs/2308.16198](http://arxiv.org/abs/2308.16198)

    本论文介绍了一种使用多智能体强化学习的方法来实现协作信息传播。通过提出分布式POMDP形式，在消息转发上实现了每个智能体的独立决策，相比传统的基于多点中继选择的启发式方法具有重大创新和贡献。同时，该方法利用图卷积强化学习和动态注意力机制捕捉关键网络特征，并提出了不同信息交换方式的两种方法进行评估。

    

    在现代通信系统中，高效可靠的信息传播对支持关键操作至关重要，如灾难响应、自动驾驶车辆和传感器网络。本文介绍了一种多智能体强化学习（MARL）方法，作为实现更为分散、高效和协作解决方案的重要进展。我们提出了一种用于信息传播的分布式POMDP（Decentralized-POMDP）形式，使得每个智能体可以独立决定消息的转发。这构成了一种从传统基于多点中继（MPR）选择的启发式方法的重大范式转移。我们的方法利用图卷积强化学习，采用具有动态注意力的图注意力网络（GAT）来捕捉关键网络特征。我们提出了两种方法，L-DGN和HL-DGN，它们在智能体之间交换的信息上有所不同。通过将我们的分散方法与基于MPR的方法进行比较，我们评估了其性能。

    In modern communication systems, efficient and reliable information dissemination is crucial for supporting critical operations across domains like disaster response, autonomous vehicles, and sensor networks. This paper introduces a Multi-Agent Reinforcement Learning (MARL) approach as a significant step forward in achieving more decentralized, efficient, and collaborative solutions. We propose a Decentralized-POMDP formulation for information dissemination, empowering each agent to independently decide on message forwarding. This constitutes a significant paradigm shift from traditional heuristics based on Multi-Point Relay (MPR) selection. Our approach harnesses Graph Convolutional Reinforcement Learning, employing Graph Attention Networks (GAT) with dynamic attention to capture essential network features. We propose two approaches, L-DGN and HL-DGN, which differ in the information that is exchanged among agents. We evaluate the performance of our decentralized approaches, by compari
    
[^172]: 授权临床医生并民主化数据科学：大型语言模型自动化临床研究的机器学习。 (arXiv:2308.14120v2 [cs.LG] 更新版)

    Empowering Clinicians and Democratizing Data Science: Large Language Models Automate Machine Learning for Clinical Studies. (arXiv:2308.14120v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2308.14120](http://arxiv.org/abs/2308.14120)

    chatGPT ADA是一种能够自主开发临床研究所需的最先进的机器学习模型的大型语言模型，可将高级分析工具民主化，使非数据科学家的临床医生能够轻松应用于医学领域。

    

    机器学习（ML）开发者（如数据科学家）和从业者（如临床医生）之间存在知识差距，阻碍了ML在临床数据分析中的充分利用。我们研究了chatGPT Advanced Data Analysis（ADA），即GPT-4的扩展，来弥合这一差距并高效执行ML分析的潜力。我们向chatGPT ADA提供了各种医学专业的大型试验的真实临床数据和研究详细信息，没有给出具体指导。ChatGPT ADA基于原始研究的训练数据自主开发了最先进的ML模型，用于预测临床结果，如癌症发展、癌症进展、疾病并发症或致病基因序列等生物标志物。令人惊讶的是，这些ML模型与其已发表的对应物相匹配甚至表现更好。我们得出结论，chatGPT ADA为民主化医学中的ML提供了一个有前景的途径，使非ML专家能够获得先进的分析工具并推动广泛应用。

    A knowledge gap persists between Machine Learning (ML) developers (e.g., data scientists) and practitioners (e.g., clinicians), hampering the full utilization of ML for clinical data analysis. We investigated the potential of the chatGPT Advanced Data Analysis (ADA), an extension of GPT-4, to bridge this gap and perform ML analyses efficiently. Real-world clinical datasets and study details from large trials across various medical specialties were presented to chatGPT ADA without specific guidance. ChatGPT ADA autonomously developed state-of-the-art ML models based on the original study's training data to predict clinical outcomes such as cancer development, cancer progression, disease complications, or biomarkers such as pathogenic gene sequences. Strikingly, these ML models matched or outperformed their published counterparts. We conclude that chatGPT ADA offers a promising avenue to democratize ML in medicine, making advanced analytics accessible to non-ML experts and promoting broa
    
[^173]: 强化学习中基于奖励机器抽象的上下文预规划以增强迁移学习

    Contextual Pre-Planning on Reward Machine Abstractions for Enhanced Transfer in Deep Reinforcement Learning. (arXiv:2307.05209v1 [cs.AI])

    [http://arxiv.org/abs/2307.05209](http://arxiv.org/abs/2307.05209)

    我们提出了一种使用奖励机器抽象来表示当前任务，并在迁移学习中提升DRL代理的性能的方法，实验表明该方法能够提高样本效率并在多个领域中进行少样本迁移。

    

    最近的研究表明，深度强化学习（DRL）代理倾向于过拟合训练任务，并且无法适应轻微的环境变化。为了在转移到未见任务时加快学习，我们提出了一种使用奖励机器（RM）来表示当前任务的新方法，奖励机器是基于当前任务的奖励和动态生成子任务的状态机抽象。我们的方法为代理提供了当前抽象状态的符号表示，并奖励它们达成这些转换。这些表示在任务之间共享，使代理能够利用先前遇到的符号和转换的知识，从而增强迁移能力。我们的实证评估表明，我们的表示在各种领域中提高了样本效率和少样本迁移。

    Recent studies show that deep reinforcement learning (DRL) agents tend to overfit to the task on which they were trained and fail to adapt to minor environment changes. To expedite learning when transferring to unseen tasks, we propose a novel approach to representing the current task using reward machines (RM), state machine abstractions that induce subtasks based on the current task's rewards and dynamics. Our method provides agents with symbolic representations of optimal transitions from their current abstract state and rewards them for achieving these transitions. These representations are shared across tasks, allowing agents to exploit knowledge of previously encountered symbols and transitions, thus enhancing transfer. Our empirical evaluation shows that our representations improve sample efficiency and few-shot transfer in a variety of domains.
    
[^174]: 代理、系统和服务集成的本体论：OASIS 2 版本

    The Ontology for Agents, Systems and Integration of Services: OASIS version 2. (arXiv:2306.10061v1 [cs.AI])

    [http://arxiv.org/abs/2306.10061](http://arxiv.org/abs/2306.10061)

    本文介绍了 OASIS 2 本体论，一种为代理提供语义表示和通信的行为主义方法。该本体论已应用于区块链及其他领域。

    

    语义表示是多个应用领域的关键方法，其中多智能体系统领域也不例外。在为代理进行语义表示的方法中，一个基本实现手段是采取行为主义视角，通过描述智能体如何操作并与其同行互动。这种方法主要旨在通过与任务完成相关的心理状态来定义代理的操作能力。OASIS 本体论（一种代理、系统和服务集成的本体论），于2019年提出了这种行为主义方法，以提供智能代理及其承诺的语义表示系统和通信协议。本文报告了 OASIS 2 中有关代理表示的主要建模选择，这是 OASIS 的最新重大升级版本，并介绍了自其首次引入以来本体论在区块链本体论等领域中的应用及成就。

    Semantic representation is a key enabler for several application domains, and the multi-agent systems realm makes no exception. Among the methods for semantically representing agents, one has been essentially achieved by taking a behaviouristic vision, through which one can describe how they operate and engage with their peers. The approach essentially aims at defining the operational capabilities of agents through the mental states related with the achievement of tasks. The OASIS ontology -- An Ontology for Agent, Systems, and Integration of Services, presented in 2019 -- pursues the behaviouristic approach to deliver a semantic representation system and a communication protocol for agents and their commitments. This paper reports on the main modeling choices concerning the representation of agents in OASIS 2, the latest major upgrade of OASIS, and the achievement reached by the ontology since it was first introduced, in particular in the context of ontologies for blockchains.
    
[^175]: 一种简单统一的基于不确定性引导的离线到在线强化学习框架

    A Simple Unified Uncertainty-Guided Framework for Offline-to-Online Reinforcement Learning. (arXiv:2306.07541v1 [cs.LG])

    [http://arxiv.org/abs/2306.07541](http://arxiv.org/abs/2306.07541)

    SUNG是一种基于不确定性引导的离线到在线强化学习框架，在通过量化不确定性进行探索和应用保守Q值估计的指导下，实现了高效的老化强化学习。

    

    离线强化学习为依靠数据驱动范例学习智能体提供了一种有前途的解决方案。 然而，受限于离线数据集的有限质量，其性能常常不够优秀。因此，在部署之前通过额外的在线交互进一步微调智能体是有必要的。不幸的是，由于受到两个主要挑战的制约，即受限的探索行为和状态-动作分布偏移，离线到在线强化学习可能具有挑战性。为此，我们提出了一个简单统一的基于不确定性引导的（SUNG）框架，其通过不确定性工具自然地统一了这两个挑战的解决方案。具体而言，SUNG通过基于VAE的状态-动作访问密度估计器量化不确定性。为了促进高效探索，SUNG提出了一种实用的乐观探索策略，以选择具有高价值和高不确定性的信息动作。此外，SUNG通过在不确定性指导下应用保守Q值估计来开发一种自适应利用方法。我们在Atari和MuJoCo基准测试上进行了全面的实验，结果表明SUNG始终优于最先进的离线到在线强化学习方法，并在许多任务中实现了接近在线学习的性能。

    Offline reinforcement learning (RL) provides a promising solution to learning an agent fully relying on a data-driven paradigm. However, constrained by the limited quality of the offline dataset, its performance is often sub-optimal. Therefore, it is desired to further finetune the agent via extra online interactions before deployment. Unfortunately, offline-to-online RL can be challenging due to two main challenges: constrained exploratory behavior and state-action distribution shift. To this end, we propose a Simple Unified uNcertainty-Guided (SUNG) framework, which naturally unifies the solution to both challenges with the tool of uncertainty. Specifically, SUNG quantifies uncertainty via a VAE-based state-action visitation density estimator. To facilitate efficient exploration, SUNG presents a practical optimistic exploration strategy to select informative actions with both high value and high uncertainty. Moreover, SUNG develops an adaptive exploitation method by applying conserva
    
[^176]: STAR: 利用大型语言模型通过结构到文本数据生成改进低资源信息抽取

    STAR: Improving Low-Resource Information Extraction by Structure-to-Text Data Generation with Large Language Models. (arXiv:2305.15090v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.15090](http://arxiv.org/abs/2305.15090)

    STAR是一种利用大型语言模型合成数据实例的数据生成方法，用于改进低资源信息抽取，为实际应用提供了需要最少人工标注的解决方案。

    

    信息抽取任务，如事件抽取，需要对输出结构和子任务依赖进行深入理解。为了获得合理的性能，它们严重依赖于以（段落，目标结构）对的形式的任务特定训练数据。然而，通过人工注释获得这样的数据是昂贵的，因此对于实际应用，我们迫切需要需要最少人工标注的低资源信息抽取方法。使用合成训练数据对监督模型进行微调可能是一种通用方法，但现有的数据生成方法要么仍然依赖于大规模的真实数据，要么由于性能差而无法应用于复杂的信息抽取任务。为了解决这些挑战，我们提出了STAR，一种利用大型语言模型（LLMs）根据有限的种子示例合成数据实例，从而提高低资源信息抽取性能的数据生成方法。

    Information extraction tasks such as event extraction require an in-depth understanding of the output structure and sub-task dependencies. They heavily rely on task-specific training data in the form of (passage, target structure) pairs to obtain reasonable performance. However, obtaining such data through human annotation is costly, leading to a pressing need for low-resource information extraction approaches that require minimal human labeling for real-world applications. Fine-tuning supervised models with synthesized training data would be a generalizable method, but the existing data generation methods either still rely on large-scale ground-truth data or cannot be applied to complicated IE tasks due to their poor performance. To address these challenges, we propose STAR, a data generation method that leverages Large Language Models (LLMs) to synthesize data instances given limited seed demonstrations, thereby boosting low-resource information extraction performance. Our approach i
    
[^177]: CRITIC：大型语言模型可以通过工具交互批评进行自我校正

    CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing. (arXiv:2305.11738v1 [cs.CL])

    [http://arxiv.org/abs/2305.11738](http://arxiv.org/abs/2305.11738)

    本文提出了一个名为CRITIC的框架，使得大型语言模型可以通过与工具的交互校正自己的错误，从而避免生成出现不一致和问题行为的结果。

    

    近年来，大型语言模型的发展非常引人注目。然而，这些模型有时会出现不一致和问题行为，例如出现幻觉事实，生成有缺陷的代码或创建冒犯和有害的内容。与这些模型不同，人类通常使用外部工具来交叉检查和精炼他们的初步内容，例如使用搜索引擎进行事实检查或使用代码解释器进行调试。受这一观察的启发，我们引入了一个名为CRITIC的框架，允许LLMs（实质上是“黑盒子”）以类似于人类与工具交互的方式验证和逐步修正自己的输出。更具体地说，从初始输出开始，CRITIC与适当的工具交互以评估文本的某些方面，然后根据在此验证过程中获得的反馈修改输出。涉及自由形式问答、数学程序综合和毒性检测的全面评估表明，我们的框架使LLMs能够从错误中学习并纠正自己的错误。

    Recent developments in large language models (LLMs) have been impressive. However, these models sometimes show inconsistencies and problematic behavior, such as hallucinating facts, generating flawed code, or creating offensive and toxic content. Unlike these models, humans typically utilize external tools to cross-check and refine their initial content, like using a search engine for fact-checking, or a code interpreter for debugging. Inspired by this observation, we introduce a framework called CRITIC that allows LLMs, which are essentially "black boxes" to validate and progressively amend their own outputs in a manner similar to human interaction with tools. More specifically, starting with an initial output, CRITIC interacts with appropriate tools to evaluate certain aspects of the text, and then revises the output based on the feedback obtained during this validation process. Comprehensive evaluations involving free-form question answering, mathematical program synthesis, and toxi
    
[^178]: InstructIE: 一份基于指令的中文信息提取数据集

    InstructIE: A Chinese Instruction-based Information Extraction Dataset. (arXiv:2305.11527v1 [cs.CL])

    [http://arxiv.org/abs/2305.11527](http://arxiv.org/abs/2305.11527)

    介绍了一份中文的基于指令的信息提取数据集InstructIE，其中包括了270,000个弱监督的数据和1,000个高质量注释实例。实验结果表明当前的模型表现有待改进，该任务仍存在挑战。

    

    我们引入了一项新的信息提取任务，称为基于指令的信息提取 (Instruction-based IE)，它旨在要求系统遵循特定的指令或指南来提取信息。为了促进该领域的研究，我们构建了一个数据集，称为InstructIE，其中包括来自中文维基百科的 270,000 个弱监督数据和 1,000 个高质量众包注释实例。我们进一步评估了各种基线模型在InstructIE数据集上的表现。结果表明，尽管当前的模型表现很有希望，但仍有改进的空间。此外，我们进行了全面的案例研究分析，强调了基于指令的信息提取任务中固有的挑战。代码和数据集可在 https://github.com/zjunlp/DeepKE/tree/main/example/llm 找到。

    We introduce a new Information Extraction (IE) task dubbed Instruction-based IE, which aims to ask the system to follow specific instructions or guidelines to extract information. To facilitate research in this area, we construct a dataset called InstructIE, consisting of 270,000 weakly supervised data from Chinese Wikipedia and 1,000 high-quality crowdsourced annotated instances. We further evaluate the performance of various baseline models on the InstructIE dataset. The results reveal that although current models exhibit promising performance, there is still room for improvement. Furthermore, we conduct a comprehensive case study analysis, underlining the challenges inherent in the Instruction-based IE task. Code and dataset are available at https://github.com/zjunlp/DeepKE/tree/main/example/llm.
    
[^179]: AMS-DRL: 学习多目标逃避以实现无人机安全导航

    AMS-DRL: Learning Multi-Pursuit Evasion for Safe Targeted Navigation of Drones. (arXiv:2304.03443v1 [cs.RO])

    [http://arxiv.org/abs/2304.03443](http://arxiv.org/abs/2304.03443)

    本文提出了AMS-DRL方法用于训练对抗性神经网络，以学习和快速适应多个攻击者的行为，从而实现无人机的安全导航和到达目标。

    

    在多个袭击者存在的情况下，无人机的安全导航是一项具有挑战性的任务。本文提出了一种新方法，异步多阶段深度强化学习(AMS-DRL)，来训练对抗性神经网络，该网络可以从多个攻击者的行动中学习和快速适应它们的行为，使无人机能够避免攻击并到达目标。我们的方法通过确保博弈论分析中的代理之间的Nash均衡来保证收敛性。我们在广泛的模拟中评估了我们的方法，并展示了它比基线方法具有更高的导航成功率。我们还分析了一些参数如相对最大速度如何影响导航性能。此外，我们进行了物理实验，并验证了实时飞行中受训策略的有效性。介绍了成功率热图，以说明空间几何对导航结果的影响。项目网站：https://gi

    Safe navigation of drones in the presence of adversarial physical attacks from multiple pursuers is a challenging task. This paper proposes a novel approach, asynchronous multi-stage deep reinforcement learning (AMS-DRL), to train an adversarial neural network that can learn from the actions of multiple pursuers and adapt quickly to their behavior, enabling the drone to avoid attacks and reach its target. Our approach guarantees convergence by ensuring Nash Equilibrium among agents from the game-theory analysis. We evaluate our method in extensive simulations and show that it outperforms baselines with higher navigation success rates. We also analyze how parameters such as the relative maximum speed affect navigation performance. Furthermore, we have conducted physical experiments and validated the effectiveness of the trained policies in real-time flights. A success rate heatmap is introduced to elucidate how spatial geometry influences navigation outcomes. Project website: https://gi
    
[^180]: 无监督的逐层文本OOD检测得分聚合

    Unsupervised Layer-wise Score Aggregation for Textual OOD Detection. (arXiv:2302.09852v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.09852](http://arxiv.org/abs/2302.09852)

    提出了一种无监督的逐层聚合异常得分的方法，用于更好地进行文本OOD检测。其能发掘不同层输出的优势，达到更鲁棒的性能，并扩展经典基准测试以反映更现实的设置。

    

    随着越来越多基于AI的系统增加，OOD检测是一个迅速发展的领域，由于新的鲁棒性和安全性要求。现有的OOD文本检测器通常依赖于在编码器的最后一层输出上计算的异常得分（例如马氏距离）。在这项工作中，我们观察到OOD检测性能因任务和层输出而异。更重要的是，我们表明通常的选择（最后一层）很少是OOD检测的最佳选择，如果选择最佳层，则可以获得更好的结果。为了利用这个观察结果，我们提出了一种数据驱动的无监督方法来结合逐层的异常得分。此外，我们通过包括更多类别的分类任务（高达77）扩展了经典文本OOD基准测试，从而反映更现实的设置。在这个增强的基准测试上，我们展示了所提出的后聚合方法实现了鲁棒的OOD检测性能。

    Out-of-distribution (OOD) detection is a rapidly growing field due to new robustness and security requirements driven by an increased number of AI-based systems. Existing OOD textual detectors often rely on an anomaly score (e.g., Mahalanobis distance) computed on the embedding output of the last layer of the encoder. In this work, we observe that OOD detection performance varies greatly depending on the task and layer output. More importantly, we show that the usual choice (the last layer) is rarely the best one for OOD detection and that far better results could be achieved if the best layer were picked. To leverage this observation, we propose a data-driven, unsupervised method to combine layer-wise anomaly scores. In addition, we extend classical textual OOD benchmarks by including classification tasks with a greater number of classes (up to 77), which reflects more realistic settings. On this augmented benchmark, we show that the proposed post-aggregation methods achieve robust an
    
[^181]: 规范化交叉密度函数：一种用于量化随机过程统计依赖关系的框架

    The Normalized Cross Density Functional: A Framework to Quantify Statistical Dependence for Random Processes. (arXiv:2212.04631v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.04631](http://arxiv.org/abs/2212.04631)

    本文提出了一种用于量化随机过程统计依赖关系的框架，通过最大化交替协方差估计和规范化交叉密度来衡量多变量统计依赖性，并应用于机器学习架构中。

    

    本文提出了一种基于阿尔弗雷德·雷尼（Alfr\'ed R\'enyi）的功能方法论，通过对两个连续随机过程（r.p.）之间的统计依赖关系进行新颖的多变量定义。将随机过程样本对的互信息的对数论证命名为规范化交叉密度（NCD），定义了一种对称和自伴的正定函数。我们证明，最大化交替协方差估计（ACE）递归应用于输入样本对的联合概率密度，符合雷尼的最大相关性的所有性质。我们提出了NCD的特征谱作为一种新颖的多变量度量，用于衡量输入和输出r.p.之间的统计依赖关系。利用r.p.的实现，也可以直接估计多变量统计依赖性。提出的功能最大相关算法（FMCA）应用于由两个神经网络构建的机器学习架构上，通过逼近联合训练来同时学习。

    This paper proposes a novel multivariate definition of statistical dependence between two continuous random processes (r.p.) using a functional methodology inspired by Alfr\'ed R\'enyi. The argument of the logarithm of mutual information between pairs of samples of a r.p., named here the normalized cross density (NCD), defines a symmetric and self-adjoint positive definite function. We show that maximizing the alternating covariance estimation (ACE) recursion, applied to each of the joint probability density of input sample pairs, obeys all the properties of Renyi's maximal correlation. We propose the NCD's eigenspectrum as a novel multivariate measure of the statistical dependence between the input and output r.p.  The multivariate statistical dependence can also be estimated directly from r.p. realizations. The proposed functional maximum correlation algorithm (FMCA) is applied to a machine learning architecture built from two neural networks that learn concurrently by approximating 
    
[^182]: 机器学习中的拒绝选项：一项调查

    Machine Learning with a Reject Option: A survey. (arXiv:2107.11277v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2107.11277](http://arxiv.org/abs/2107.11277)

    这项调查综述了机器学习中的拒绝选项。通过机器学习模型避免在可能犯错误时做出预测，可以在决策支持应用中避免严重后果。调查介绍了拒绝选项的条件、评估策略以及相关应用领域，并探讨了它与其他机器学习方法的关系。

    

    机器学习模型总是做出预测，即使可能是不准确的。在许多决策支持应用中，应避免这种行为，因为错误可能带来严重后果。尽管在1970年已经研究过，但近年来机器学习中的拒绝选项引起了人们的关注。这个机器学习子领域使得机器学习模型能够在可能犯错误时避免做出预测。本调查旨在提供机器学习中拒绝选项的概述。我们介绍了导致两种拒绝情况（模糊和新奇拒绝）的条件，并对其进行了仔细的形式化。此外，我们还回顾和分类了评估模型预测和拒绝质量的策略。此外，我们定义了现有的带有拒绝选项的模型架构，并描述了学习这些模型的标准技术。最后，我们提供了相关应用领域的示例，并展示了机器学习中的拒绝选项与其他机器学习方法之间的关系。

    Machine learning models always make a prediction, even when it is likely to be inaccurate. This behavior should be avoided in many decision support applications, where mistakes can have severe consequences. Albeit already studied in 1970, machine learning with rejection recently gained interest. This machine learning subfield enables machine learning models to abstain from making a prediction when likely to make a mistake.  This survey aims to provide an overview on machine learning with rejection. We introduce the conditions leading to two types of rejection, ambiguity and novelty rejection, which we carefully formalize. Moreover, we review and categorize strategies to evaluate a model's predictive and rejective quality. Additionally, we define the existing architectures for models with rejection and describe the standard techniques for learning such models. Finally, we provide examples of relevant application domains and show how machine learning with rejection relates to other machi
    

