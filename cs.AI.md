# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Theory of Mind abilities of Large Language Models in Human-Robot Interaction : An Illusion?.](http://arxiv.org/abs/2401.05302) | 大型语言模型在人机交互中的应用具有较高的风险和潜在的不可逆后果。这项研究探索了大型语言模型的心智理论能力，特别关注机器人感知行为识别任务。 |
| [^2] | [I am a Strange Dataset: Metalinguistic Tests for Language Models.](http://arxiv.org/abs/2401.05300) | 本研究提出了一个新的数据集，名为“我是一个奇怪的数据集”，用来测试大型语言模型（LLMs）是否能够处理元语言自指的陈述。实验证明，各种开源和闭源LLMs在生成和验证任务中的表现都接近随机猜测。 |
| [^3] | [INACIA: Integrating Large Language Models in Brazilian Audit Courts: Opportunities and Challenges.](http://arxiv.org/abs/2401.05273) | 本文介绍了INACIA系统，这是一个将大型语言模型整合到巴西审计法院中的系统，可以自动化案件分析的各个阶段，并展示了其在从案件文件中提取信息、评估合法性和生成司法建议方面的潜力。 |
| [^4] | [AUTOACT: Automatic Agent Learning from Scratch via Self-Planning.](http://arxiv.org/abs/2401.05268) | AUTOACT是一个自动代理学习框架，通过自主规划合成轨迹，不依赖于大规模数据和闭源模型，能够实现更好或类似的性能。 |
| [^5] | [ReACT: Reinforcement Learning for Controller Parametrization using B-Spline Geometries.](http://arxiv.org/abs/2401.05251) | 本研究提出了一种使用深度强化学习和N维B样条几何进行控制器参数化的方法。通过自主决定控制器参数的调整，该方法可以简化对于复杂和非线性系统的控制器参数化过程。 |
| [^6] | [Do Vision and Language Encoders Represent the World Similarly?.](http://arxiv.org/abs/2401.05224) | 通过分析视觉和语言模型的潜在空间结构，发现未对齐和对齐的编码器的表示空间在语义上是相似的。我们提出了两种方法来匹配未对齐编码器，无需训练即可实现匹配。 |
| [^7] | [Distributed Monitoring for Data Distribution Shifts in Edge-ML Fraud Detection.](http://arxiv.org/abs/2401.05219) | 本研究提出了一个用于边缘机器学习欺诈检测的分布式数据分布变化监测框架，包括了创新的Kolmogorov-Smirnov (KS)检验计算方法，能够高效准确地监测用户行为变化。 |
| [^8] | [Pre-trained Large Language Models for Financial Sentiment Analysis.](http://arxiv.org/abs/2401.05215) | 本文提出了一种使用预训练大型语言模型进行金融情绪分析的方法，通过领域特定的适应和监督微调技术，即使在有限的训练样本下，也能显著提升分类性能。 |
| [^9] | [A Novel Prompt-tuning Method: Incorporating Scenario-specific Concepts into a Verbalizer.](http://arxiv.org/abs/2401.05204) | 本文提出了一种新颖的提示调整方法，通过将情景特定概念纳入到话语生成器中，提高了标签词空间的覆盖度和减小了偏见。 |
| [^10] | [Knowledge Sharing in Manufacturing using Large Language Models: User Evaluation and Model Benchmarking.](http://arxiv.org/abs/2401.05200) | 使用大型语言模型在制造业中进行知识共享，通过评估实证了该系统的效益，提高了操作员的信息检索速度和问题解决效率，同时强调在有人工专家选项时的偏好。GPT-4是最优秀的模型。 |
| [^11] | [Monte Carlo Tree Search for Recipe Generation using GPT-2.](http://arxiv.org/abs/2401.05199) | 本研究提出了一种利用GPT-2和蒙特卡洛树搜索的方法来生成食谱，通过定义奖励函数对文本生成进行限制，提高了生成食谱的可信度。 |
| [^12] | [Modelling, Positioning, and Deep Reinforcement Learning Path Tracking Control of Scaled Robotic Vehicles: Design and Experimental Validation.](http://arxiv.org/abs/2401.05194) | 本文提出了一种缩放机器人车辆建模和控制的解决方案，包括联邦式扩展卡尔曼滤波器和通过专家演示器训练的深度强化学习路径跟踪控制器。这些方法可以加快学习阶段并增加对模拟与现实之间差距的鲁棒性。 |
| [^13] | [Experiment Planning with Function Approximation.](http://arxiv.org/abs/2401.05193) | 本研究探讨了在上下文关联赌博问题中使用函数逼近进行实验规划的问题，并提出了两种与函数逼近兼容的实验规划策略。 |
| [^14] | [Can ChatGPT Rival Neural Machine Translation? A Comparative Study.](http://arxiv.org/abs/2401.05176) | 本文比较了对话式语言模型ChatGPT和神经机器翻译引擎在将中文外交文本翻译为英文方面的能力，发现自动评价指标和人工评估方法之间存在差异。 |
| [^15] | [MISS: A Generative Pretraining and Finetuning Approach for Med-VQA.](http://arxiv.org/abs/2401.05163) | MISS是一种适用于医学视觉问答的生成式预训练与微调方法。相比于现有方法，我们把医学视觉问答作为一个生成式任务处理，通过多任务学习使图像和文本特征对齐，并通过使用大型语言模型扩展单模态图像数据集的转换和字幕方法实现特征空间的扩展。 |
| [^16] | [Derm-T2IM: Harnessing Synthetic Skin Lesion Data via Stable Diffusion Models for Enhanced Skin Disease Classification using ViT and CNN.](http://arxiv.org/abs/2401.05159) | 本研究利用稳定扩散模型生成合成皮肤镜数据，增强机器学习模型训练的鲁棒性，并在皮肤疾病分类中探索了其有效性。 |
| [^17] | [Yes, this is what I was looking for! Towards Multi-modal Medical Consultation Concern Summary Generation.](http://arxiv.org/abs/2401.05134) | 本文提出了一个新的任务：多模态医疗关注摘要生成，通过结合患者的非语言线索和个人信息，生成简短精确的咨询关注摘要。 |
| [^18] | [Neural Population Learning beyond Symmetric Zero-sum Games.](http://arxiv.org/abs/2401.05133) | 本研究研究了在n个玩家 general-sum 游戏中寻找均衡的计算方法。提出了一种神经群体学习算法 NeuPL-JPSRO，通过技能的迁移学习，收敛到游戏的粗略相关均衡。验证了算法的实证收敛性，并在复杂领域中展示了应用的可行性。该研究为解决现实世界中异质玩家、具有混合动机的游戏提供了新的路径。 |
| [^19] | [Unpacking Human-AI interactions: From interaction primitives to a design space.](http://arxiv.org/abs/2401.05115) | 本文开发了一个半正式的设计空间，利用一组交互原则，为人机交互提供抽象规范，支持目的性交互，并简洁概括了现有实践的相似性和差异性。它还为新系统的创建提供了可能性空间。 |
| [^20] | [Any-Way Meta Learning.](http://arxiv.org/abs/2401.05097) | 本文通过引入“任意方式”学习范式解决了元学习中固定基数的限制，并通过利用从标签分配中出现的“标签等价性”来提高模型的性能和稳定性。同时提出了一个新的方法来弥补标签等价性带来的语义信息差距。 |
| [^21] | [Generating Diverse and High-Quality Texts by Minimum Bayes Risk Decoding.](http://arxiv.org/abs/2401.05054) | 本研究提出了基于最小贝叶斯风险解码的多样性生成算法，通过在解码过程中加入多样性目标，能够生成高质量且多样化的文本输出。 |
| [^22] | [CreINNs: Credal-Set Interval Neural Networks for Uncertainty Estimation in Classification Tasks.](http://arxiv.org/abs/2401.05043) | CreINNs是一种用于分类任务的Credal-Set Interval Neural Networks，通过保留传统的区间神经网络结构，捕捉权重不确定性，并使用概率区间的数学框架预测可信区间。实验结果表明，CreINNs在不确定性估计方面优于变分贝叶斯神经网络和深度集成，并且具有较低的计算复杂度和模型大小。 |
| [^23] | [Bootstrapping LLM-based Task-Oriented Dialogue Agents via Self-Talk.](http://arxiv.org/abs/2401.05033) | 本论文提出了一种通过LLM的自我对话收集数据的方法，用于指导基于LLM的任务导向对话代理。通过引入自我对话度量来衡量对话的成功，我们可以选择质量较高的样本进行训练和优化。 |
| [^24] | [Source-Free Cross-Modal Knowledge Transfer by Unleashing the Potential of Task-Irrelevant Data.](http://arxiv.org/abs/2401.05014) | 本论文提出了一种无源跨模态知识转移方法，通过解锁无用任务数据的潜力，利用成对的任务无关数据来估计源数据分布并促进知识转移。该方法采用了Task-irrelevant data-Guided Modality Bridging (TGMB)模块来更好地估计源数据分布。 |
| [^25] | [Less is More : A Closer Look at Multi-Modal Few-Shot Learning.](http://arxiv.org/abs/2401.05010) | 该论文提出了一个简单但有效的框架，利用文本信息和语言模型来进行少样本学习任务，充分发挥了预训练语言模型的零样本能力，并直接将视觉特征和文本特征进行推理。 |
| [^26] | [AdaFed: Fair Federated Learning via Adaptive Common Descent Direction.](http://arxiv.org/abs/2401.04993) | AdaFed是一种通过自适应公共下降方向实现公平的联邦学习方法，通过调整服务器的更新方向来确保所有客户端的损失函数减小，并且更大值的客户端的减小速率更高。 |
| [^27] | [Autonomous Navigation of Tractor-Trailer Vehicles through Roundabout Intersections.](http://arxiv.org/abs/2401.04980) | 该论文通过开发拖车和卡车模型，使用高保真度模拟软件CARLA，并建立了基准数据集，以研究拖车车辆在环岛交叉口的自主导航。研究使用双Q软件演员评论算法训练了一个准端到端的自动驾驶模型，在不同环岛上取得了73%的成功率。 |
| [^28] | [Invertible Solution of Neural Differential Equations for Analysis of Irregularly-Sampled Time Series.](http://arxiv.org/abs/2401.04979) | 我们提出了一种可逆解决非规则采样时间序列的神经微分方程分析方法，通过引入神经流的概念，我们的方法既保证了可逆性又降低了计算负担，并且在分类和插值任务中表现出了优异的性能。 |
| [^29] | [Closed-Form Interpretation of Neural Network Classifiers with Symbolic Regression Gradients.](http://arxiv.org/abs/2401.04978) | 本文提出了一种解释神经网络分类器的闭式表示的方法，使其适用于自动化科学发现。这种方法通过将神经网络嵌入到一组基于相同量的等价类中，并通过找到该等价类与符号回归搜索空间中的方程的交集来解释神经网络。 |
| [^30] | [Information Flow Rate for Cross-Correlated Stochastic Processes.](http://arxiv.org/abs/2401.04950) | 该论文探讨了耦合随机过程中基于数据驱动的信息流速率的统计特性，通过推导信息流速率统计量与自相关和互相关函数属性之间的关系，揭示了信息流速率与相关函数特征的依赖性。 |
| [^31] | [Fully Decentralized Cooperative Multi-Agent Reinforcement Learning: A Survey.](http://arxiv.org/abs/2401.04934) | 本文系统地回顾了完全分散的合作多智能体强化学习方法，并讨论了两种不同设置下的算法以及未来的研究方向。 |
| [^32] | [Learning-Based Difficulty Calibration for Enhanced Membership Inference Attacks.](http://arxiv.org/abs/2401.04929) | 本文介绍了一种基于学习的难度校准的成员推理攻击方法，旨在显著提高低FPR下的TPR，以验证训练模型是否保护隐私。 |
| [^33] | [The Impact of Reasoning Step Length on Large Language Models.](http://arxiv.org/abs/2401.04925) | 本研究探讨了推理步长对大型语言模型的影响，并发现在提示中增加推理步骤能显著提高模型的推理能力，而减少推理步骤则会降低模型的推理能力。 |
| [^34] | [ANGO: A Next-Level Evaluation Benchmark For Generation-Oriented Language Models In Chinese Domain.](http://arxiv.org/abs/2401.04898) | ANGO是一个中文领域生成型语言模型评估基准，引入了关键点分类标准，提供了更好的可解释性，同时建立了可量化的问题难度标准，对模型训练提供了更精确的指导。 |
| [^35] | [An Analysis of User Behaviours for Objectively Evaluating Spoken Dialogue Systems.](http://arxiv.org/abs/2401.04867) | 本文研究了用户行为与主观评估在口语对话系统中的关系，提出了一种间接但客观评估系统的框架，并发现在不同类型的对话任务中，不同的用户行为指标对评估起到重要作用。 |
| [^36] | [User Embedding Model for Personalized Language Prompting.](http://arxiv.org/abs/2401.04858) | 本研究提出了一种新的用户嵌入模块，可以更有效地处理长时间的用户历史记录，并在推荐系统中取得了显著的改进。 |
| [^37] | [Graph Learning-based Fleet Scheduling for Urban Air Mobility under Operational Constraints, Varying Demand & Uncertainties.](http://arxiv.org/abs/2401.04851) | 本文提出了一种基于图学习的方法，用于在线规划城市空中移动机队的时间表和目的地，考虑到操作限制、需求变化和不确定性等问题。通过构建新的策略架构和使用图胶囊转换网络、转换器层和Multi-head Attention-based解码器等组件，该方法能够解决现有机队规划实施中存在的复杂性，具有更高的现实性和逼真度。 |
| [^38] | [A Deep Learning Representation of Spatial Interaction Model for Resilient Spatial Planning of Community Business Clusters.](http://arxiv.org/abs/2401.04849) | 本研究提出了一个SIM-GAT模型，可以捕捉商业集群与贸易区之间复杂的互动关系。我们使用连通图表示综合系统，并利用Graph AttenTion network模型进行深度学习，从而提高了传统SIM的预测和分析能力。 |
| [^39] | [The inherent goodness of well educated intelligence.](http://arxiv.org/abs/2401.04846) | 本文探讨了智能体变得智能的因素，强调了掌握特征和控制多个保守相互作用的子系统的能力。智能的核心是“集体如一体”和“了解局部行动的整体结果”。文章提出了一种对集体保守系统进行控制的替代方法。 |
| [^40] | [MoSECroT: Model Stitching with Static Word Embeddings for Crosslingual Zero-shot Transfer.](http://arxiv.org/abs/2401.04821) | MoSECroT是一个结合静态词向量的模型拼接框架，用于跨语言零样例迁移。它利用相对表示构建了源语言预训练语言模型和目标语言静态词向量的共享空间，从而实现了通过简单交换嵌入从源语言训练数据中进行训练，并在目标语言上进行零样例迁移。 |
| [^41] | [Phishing Website Detection through Multi-Model Analysis of HTML Content.](http://arxiv.org/abs/2401.04820) | 本研究提出了一种基于HTML内容的高级检测模型，集成了多层感知器和预训练的自然语言处理模型，通过新颖的融合方法检测网络钓鱼网站。同时，我们还创造了一个最新的数据集来支持这项研究。 |
| [^42] | [Sample-and-Bound for Non-Convex Optimization.](http://arxiv.org/abs/2401.04812) | 本论文提出了一种基于采样的非凸优化方法，采用Monte Carlo Tree Search (MCTS)来提高效率，并利用数值上估计的不确定度指标和采样估计的一阶和二阶信息，避免固定组合模式的树生长，积极缩小到有希望的区域，同时平衡探索和开发。 |
| [^43] | [How predictable is language model benchmark performance?.](http://arxiv.org/abs/2401.04757) | 本研究通过对十一个最近的模型架构在五个数量级的计算规模上进行了大规模的语言模型性能研究，发现将许多个体任务和评估聚合在一起的平均基准性能可以合理预测，但在个别任务中的预测性能仍存在挑战。 |
| [^44] | [LogFormer: A Pre-train and Tuning Pipeline for Log Anomaly Detection.](http://arxiv.org/abs/2401.04749) | LogFormer是一种预训练和调优流程，能够提高日志异常检测在不同领域之间的泛化能力。它通过在源领域上进行预训练并利用共享参数将知识转移到目标领域，同时引入Log-Attention模块来补充被日志配对忽略的信息。 |
| [^45] | [Convolutional Neural Network Ensemble Learning for Hyperspectral Imaging-based Blackberry Fruit Ripeness Detection in Uncontrolled Farm Environment.](http://arxiv.org/abs/2401.04748) | 本文提出了一种基于卷积神经网络集成学习的方法，用于在无控制农场环境下检测黑莓果实的细微成熟特征。最近的研究已经开始使用深度学习技术来提取黑莓果实图像的特征，以判断其成熟度。本研究通过使用预训练的VGG16模型，构建了一个多输入CNN进行集成分类，以解决黑莓果实成熟度检测中的困难。 |
| [^46] | [DiffSHEG: A Diffusion-Based Approach for Real-Time Speech-driven Holistic 3D Expression and Gesture Generation.](http://arxiv.org/abs/2401.04747) | DiffSHEG是一种基于扩散的实时语音驱动的整体三维表情和手势生成方法，通过联合生成同步表情和手势，并引入基于扩散模型的任意长序列生成策略，实现了高质量的同步表情和手势生成。 |
| [^47] | [Content-Conditioned Generation of Stylized Free hand Sketches.](http://arxiv.org/abs/2401.04739) | 本文提出了一种根据内容生成风格化自由手绘草图的新方法，该方法能够准确生成具有各种风格的逼真自由手绘草图。通过在生成过程中使用先验正态分布中随机采样的风格或从已知草图中解开画家风格，该方法能够生成具有特定风格的图像，同时还能生成未知类别的图像。 |
| [^48] | [Music Genre Classification: A Comparative Analysis of CNN and XGBoost Approaches with Mel-frequency cepstral coefficients and Mel Spectrograms.](http://arxiv.org/abs/2401.04737) | 本研究比较了使用CNN、VGG16和XGBoost模型以及不同特征的音乐类型分类性能。结果表明，CNN在处理30秒的梅尔频谱图时表现最好，XGBoost在处理3秒的梅尔频率倒谱系数时表现最好。 |
| [^49] | [Exploring Attack Resilience in Distributed Platoon Controllers with Model Predictive Control.](http://arxiv.org/abs/2401.04736) | 这项研究通过模拟各种攻击技术，分析了分布式车队控制器的漏洞，提出了加强通信协议和使用机器学习技术进行恶意攻击检测的对策。 |
| [^50] | [A case study of Generative AI in MSX Sales Copilot: Improving seller productivity with a real-time question-answering system for content recommendation.](http://arxiv.org/abs/2401.04732) | 本论文设计了一个实时问答系统，通过LLM嵌入与销售材料进行匹配，提供给销售人员实时推荐，从而提高销售人员的工作效率。这一解决方案可以在几秒钟内返回最相关的内容推荐，即使对于大规模数据集也是如此。这一推荐系统已成功集成到微软销售人员每日使用的Dynamics CRM的生产版本中。 |
| [^51] | [RoSA: Accurate Parameter-Efficient Fine-Tuning via Robust Adaptation.](http://arxiv.org/abs/2401.04679) | RoSA是一种新的PEFT方法，通过在预训练权重上训练低秩和高度稀疏的组件，以高效近似完全微调的性能，来实现准确的参数高效微调。在多个生成任务中，RoSA表现出优于其他方法的性能。 |
| [^52] | [Agent Alignment in Evolving Social Norms.](http://arxiv.org/abs/2401.04620) | 本论文提出了一个名为EvolutionaryAgent的进化框架，将Agent对齐转化为适者生存的演化和选择过程，在不断演化的社会规范中，与当前社会规范更好适应的Agent将具有更高的生存和传播概率。 |
| [^53] | [Deep Efficient Private Neighbor Generation for Subgraph Federated Learning.](http://arxiv.org/abs/2401.04336) | 本文提出了FedDEP，用于解决子图联邦学习中的信息传播不完整的问题，并提出了一系列新颖的技术设计，包括深度邻居生成和高效的私密领域生成。 |
| [^54] | [Unsupervised Test-Time Adaptation via Plug-and-Play Transformer Modules.](http://arxiv.org/abs/2401.04130) | 这项工作介绍了PLUTO:一种插拔式模块化的测试时领域适应策略，通过预先训练一系列针对不同源领域的模块，有效地创建了一个"模块存储库"。采用无监督的测试时自适应方法，从存储库中选择稀疏的相关模块的子集，并创建选中模块的加权组合，实现了对新领域的自适应。 |
| [^55] | [Advancing Spatial Reasoning in Large Language Models: An In-Depth Evaluation and Enhancement Using the StepGame Benchmark.](http://arxiv.org/abs/2401.03991) | 本研究通过改进StepGame基准，提供了更准确的数据集用于评估语言模型在空间推理方面的能力。研究发现，当前的大型语言模型在将自然语言文本映射到空间关系方面表现优秀，但在多跳推理方面存在限制。 |
| [^56] | [Contextual Fixed-Budget Best Arm Identification: Adaptive Experimental Design with Policy Learning.](http://arxiv.org/abs/2401.03756) | 该论文研究了个性化治疗推荐的问题，提出了一个上下文固定预算的最佳臂识别模型，通过自适应实验设计和策略学习来推荐最佳治疗方案，并通过最坏情况下的期望简单遗憾来衡量推荐的有效性。 |
| [^57] | [Predicting the Skies: A Novel Model for Flight-Level Passenger Traffic Forecasting.](http://arxiv.org/abs/2401.03397) | 本研究提出了一种新颖的多模态深度学习方法用于预测航班层次的乘客流量，相比传统模型取得了显著的准确性提升。该模型有效整合了循环神经网络和卷积神经网络，利用数据内部的时间模式和空间关系来增强预测性能。 |
| [^58] | [A Survey on Verification and Validation, Testing and Evaluations of Neurosymbolic Artificial Intelligence.](http://arxiv.org/abs/2401.03188) | 神经符号人工智能的验证和验证、测试和评估是一项具有挑战性的任务，因为亚符号人工智能的黑盒特性使得预测难以解释。本调查研究了神经符号人工智能如何简化V&V过程，并提供了关于当前应用的算法和技术的概述。 |
| [^59] | [Human as AI Mentor: Enhanced Human-in-the-loop Reinforcement Learning for Safe and Efficient Autonomous Driving.](http://arxiv.org/abs/2401.03160) | 本文提出了一种增强的人机协作强化学习方法，通过将人类智能注入到AI中实现混合交通编队中的安全高效自动驾驶。该方法将人类专家作为导师，允许代理在不确定环境中进行探索，同时在危险情况下接管控制以避免事故，并指导代理减小交通流干扰，优化交通流效果。 |
| [^60] | [Decentralized Multi-Agent Active Search and Tracking when Targets Outnumber Agents.](http://arxiv.org/abs/2401.03154) | 该论文介绍了一种处理多目标跟踪的分散式多智能体算法，该算法能在智能体数量少于目标数量时实现主动搜索和跟踪，并使用异步智能体通信来协调动作。 |
| [^61] | [Has Your Pretrained Model Improved? A Multi-head Posterior Based Approach.](http://arxiv.org/abs/2401.02987) | 本研究提出一种基于多头后验的方法，通过利用实体的元特征和模型的表示之间的一致性作为度量标准，有效评估预训练模型在各个领域的表现。 |
| [^62] | [XUAT-Copilot: Multi-Agent Collaborative System for Automated User Acceptance Testing with Large Language Model.](http://arxiv.org/abs/2401.02705) | XUAT-Copilot是一个使用大型语言模型的多智能体协作系统，旨在提高自动用户验收测试的自动化水平和测试脚本生成阶段的效率。 |
| [^63] | [IdentiFace : A VGG Based Multimodal Facial Biometric System.](http://arxiv.org/abs/2401.01227) | 本文介绍了一种基于VGG的多模态人脸生物特征系统"IdentiFace"，通过将人脸识别与性别、脸型和情感等软生物特征相结合，实现了高效、有意义的结合。通过使用统一的架构和对学到的特征进行解释，该系统在高内类别变异下取得了99.2%的测试精确度。 |
| [^64] | [Accurate Leukocyte Detection Based on Deformable-DETR and Multi-Level Feature Fusion for Aiding Diagnosis of Blood Diseases.](http://arxiv.org/abs/2401.00926) | 本文提出了一种创新的白细胞检测方法，使用多级特征融合和变形自注意DETR，通过解决白细胞尺度差异问题和提高检测精度，以改善传统血液检测的效率和准确性。 |
| [^65] | [Comparative study of clustering models for multivariate time series from connected medical devices.](http://arxiv.org/abs/2312.17286) | 这项研究比较了两种针对多变量时间序列的聚类模型，通过预测未来值并形成聚类空间来创建患者资料，其中一种模型可以处理动态群组归属。 |
| [^66] | [DarkShot: Lighting Dark Images with Low-Compute and High-Quality.](http://arxiv.org/abs/2312.16805) | 本文提出了一种用低计算量和高质量照亮暗图像的轻量级网络，该网络采用Siamese自注意块和Skip-Channel注意力模块，可以在低光增强任务中超越现有最先进的方法，并提出了一个两阶段框架来实现更好的结果。 |
| [^67] | [TAPE: Leveraging Agent Topology for Cooperative Multi-Agent Policy Gradient.](http://arxiv.org/abs/2312.15667) | TAPE提出了一种代理拓扑框架，用于解决多智能体策略梯度方法中的集中-分散不匹配（CDM）问题，通过平衡合作和减轻CDM的影响。 |
| [^68] | [I-CEE: Tailoring Explanations of Image Classification Models to User Expertise.](http://arxiv.org/abs/2312.12102) | I-CEE是一个人为中心的框架，为用户专业知识定制了图像分类模型的解释，通过提供信息丰富的示例图像、局部解释和模型决策来帮助用户理解模型的决策。 |
| [^69] | [Non-Euclidean Spatial Graph Neural Network.](http://arxiv.org/abs/2312.10808) | 本文提出了一种新的通用框架，用于学习嵌入在非欧几里德流形空间中的空间网络的表示，通过提取边上的消息将图拓扑和空间几何结合起来。 |
| [^70] | [Human-computer Interaction for Brain-inspired Computing Based on Machine Learning And Deep Learning:A Review.](http://arxiv.org/abs/2312.07213) | 该论文综述了机器学习和深度学习在脑启发计算的人机交互研究中的应用，介绍了其演化、挑战和潜在研究轨迹。 |
| [^71] | [KwaiAgents: Generalized Information-seeking Agent System with Large Language Models.](http://arxiv.org/abs/2312.04889) | 本文介绍了 KwaiAgents，这是一个基于大型语言模型的通用信息搜索智能体系统。该系统能够利用语言模型作为认知核心，理解用户的查询，行为准则并参考外部文档，以提供高质量的知识和信息。 |
| [^72] | [Sample-based Dynamic Hierarchical Transformer with Layer and Head Flexibility via Contextual Bandit.](http://arxiv.org/abs/2312.03038) | 我们提出了一种基于样本的动态分层Transformer模型(DHT)，通过解决上下文Bandit问题动态配置层和头的数量。与之前的工作不同，DHT不仅在训练中能够自适应优化网络架构，而且具有灵活的网络架构，用于高效的推断。 |
| [^73] | [FedEmb: A Vertical and Hybrid Federated Learning Algorithm using Network And Feature Embedding Aggregation.](http://arxiv.org/abs/2312.00102) | 本论文提出了一种名为FedEmb的通用算法，用于进行垂直和混合的基于DNN的联邦学习，具有更高的推理准确率、隐私保护性能更强以及较低的通信带宽需求。实验证明，FedEmb是一种有效的方法来解决分布式问题，并在有限的隐私泄露下提高推理准确度。 |
| [^74] | [A density estimation perspective on learning from pairwise human preferences.](http://arxiv.org/abs/2311.14115) | 研究提出了一个从密度估计的角度解释学习成对人类偏好的方法，并证明通过这种方法训练奖励函数可以有效地模拟注释者的隐含偏好分布。 |
| [^75] | [Speak Like a Native: Prompting Large Language Models in a Native Style.](http://arxiv.org/abs/2311.13538) | 本文提出了一种名为AlignedCoT的新颖有效方法，通过将上下文示例与大型语言模型（LLMs）的母语风格对齐，提高了LLMs的推理能力和性能。 |
| [^76] | [Attributes Grouping and Mining Hashing for Fine-Grained Image Retrieval.](http://arxiv.org/abs/2311.06067) | 该论文提出了一种属性分组和挖掘哈希（AGMH）方法，通过将卷积描述符替代注意力引导特征，在细粒度图像检索中生成了多样的特征表示，以捕捉细微的差异和局部特征。这种方法可以有效地提高图像检索的准确性和效率。 |
| [^77] | [Pre-training LLMs using human-like development data corpus.](http://arxiv.org/abs/2311.04666) | 本论文使用类似人类发展数据语料库对LLMs进行预训练，通过与儿童观看的令牌数量相似的方式，评估了LLMs学习上下文词表示的能力。同时提供强大的基准和对任务组织者提供的RoBERTa基准的复制尝试。 |
| [^78] | [KirchhoffNet: A Circuit Bridging Message Passing and Continuous-Depth Models.](http://arxiv.org/abs/2310.15872) | 本文提出了一种称为基赫霍夫网络的神经网络模型，利用基赫霍夫电流定律与消息传递神经网络和连续深度网络建立连接。在MNIST数据集上，基赫霍夫网络可以实现接近98.86%的测试准确度，且具有在硬件上实现的潜力。无论网络参数数量如何，其正向计算都可以在1/f秒内完成，具有快速计算的硬件特性。 |
| [^79] | [Molecular De Novo Design through Transformer-based Reinforcement Learning.](http://arxiv.org/abs/2310.05365) | 本文提出了一种基于Transformer的强化学习方法，通过精细调整生成模型，能够在分子的全新设计中生成具有所需性质的分子结构，展现出优越的性能。 |
| [^80] | [Improving Automatic VQA Evaluation Using Large Language Models.](http://arxiv.org/abs/2310.02567) | 提出使用大型语言模型改进自动视觉问答（VQA）评估的方法，将VQA评估格式化为回答评分任务，通过指令调整大型语言模型在准确度上评分候选答案，证明该方法与人类判断相关性优于现有度量方法。 |
| [^81] | [Enhancing Student Performance Prediction on Learnersourced Questions with SGNN-LLM Synergy.](http://arxiv.org/abs/2309.13500) | 这项研究介绍了一种创新的策略，将有符号图神经网络（SGNNs）和大型语言模型（LLM）的潜力协同起来，用于预测学生在学习者提供的问题上的表现。该方法利用有符号二分图全面建模学生回答，并采用对比学习框架增强了噪声的鲁棒性。 |
| [^82] | [Evaluating large language models' ability to understand metaphor and sarcasm using a screening test for Asperger syndrome.](http://arxiv.org/abs/2309.10744) | 该研究使用一个评分测试来评估大型语言模型（LLMs）理解人类微妙交流的能力。研究结果发现，随着模型参数数量的增加，LLMs对隐喻理解能力有所改善，但对讽刺理解能力的改进并未观察到。 |
| [^83] | [Analysis of the Memorization and Generalization Capabilities of AI Agents: Are Continual Learners Robust?.](http://arxiv.org/abs/2309.10149) | 本文提出了一种新的连续学习框架，旨在在动态环境下实现鲁棒的泛化能力并保留过去的知识。通过使用有限容量的内存来保存先前观察到的环境信息，并从内存中采样数据点来获得对未知变化鲁棒的预测器。该分析展示了记忆和泛化之间的权衡，而实验证明了所提出的算法的优越性。 |
| [^84] | [RaTrack: Moving Object Detection and Tracking with 4D Radar Point Cloud.](http://arxiv.org/abs/2309.09737) | RaTrack是一种针对雷达跟踪的创新解决方案，通过运动分割和聚类以及运动估计模块，实现了对移动物体的精确跟踪，优于最先进性能。 |
| [^85] | [Nonlinearity, Feedback and Uniform Consistency in Causal Structural Learning.](http://arxiv.org/abs/2308.07520) | 这篇论文研究了非线性、反馈和因果结构学习中的一致性问题，并提出了一个弱于强可靠性的k-Triangle Faithfulness的替代定义。 |
| [^86] | [MSQNet: Actor-agnostic Action Recognition with Multi-modal Query.](http://arxiv.org/abs/2307.10763) | MSQNet是一种无关演员的多模态多标签动作识别方法，通过使用视觉和文本模态来更好地表示动作类别，克服了现有方法中针对特定演员的限制。 |
| [^87] | [TrustGuard: GNN-based Robust and Explainable Trust Evaluation with Dynamicity Support.](http://arxiv.org/abs/2306.13339) | TrustGuard是一种基于GNN的信任评估模型，支持信任动态性，抗击鲁棒并提供解释能力，它的实验结果在准确性、鲁棒性和可解释性方面都优于其他方法。 |
| [^88] | [HomeRobot: Open-Vocabulary Mobile Manipulation.](http://arxiv.org/abs/2306.11565) | HomeRobot是一种开放词汇移动操作的顺应力机器人，可在家庭环境中导航并操纵各种物体，以完成日常任务。它引入了HomeRobot OVMM基准测试，通过仿真和实际机器人两个组件进行测试和验证。 |
| [^89] | [Tensorized Hypergraph Neural Networks.](http://arxiv.org/abs/2306.02560) | 本文提出了一种基于张量化和高阶特征传递的超图神经网络（THNN），用于从均匀超图中提取高阶信息。同时采用部分对称的CP分解来处理高阶特征传递的复杂度。 |
| [^90] | [BiomedGPT: A Unified and Generalist Biomedical Generative Pre-trained Transformer for Vision, Language, and Multimodal Tasks.](http://arxiv.org/abs/2305.17100) | BiomedGPT是一种面向视觉、语言和多模态任务的通用生物医学生成预训练Transformer，在多个临床任务中取得了16个最新的最优结果，包括超过了OpenAI的GPT-4V和Google的Med-PaLM M（12B）。同时，BiomedGPT还支持零-shot迁移学习。 |
| [^91] | [SLaDe: A Portable Small Language Model Decompiler for Optimized Assembly.](http://arxiv.org/abs/2305.12520) | SLaDe是一种基于小型语言模型的反编译器，通过训练真实代码的序列到序列变换器，使用了新颖的分词器、无丢弃训练和类型推断等方法，能够生成更易读和更准确的程序。 |
| [^92] | [Protein Complex Invariant Embedding with Cross-Gate MLP is A One-Shot Antibody Designer.](http://arxiv.org/abs/2305.09480) | 本文提出了一种深度生成模型，可以一次性地共同设计抗体CDR的1D序列和3D结构，解决几何建模和低效推断的问题。 |
| [^93] | [SemPPL: Predicting pseudo-labels for better contrastive representations.](http://arxiv.org/abs/2301.05158) | 该论文提出了一种新的半监督学习方法SemPPL，通过预测伪标签来改善对比表示，从而解决了计算机视觉中学习大量无监督数据和少量监督数据的问题。 |
| [^94] | [t-SMILES: A Scalable Fragment-based Molecular Representation Framework for De Novo Molecule Generation.](http://arxiv.org/abs/2301.01829) | 本研究提出了一种可扩展的基于碎片的分子表示框架 t-SMILES，通过引入 t-SMILES 可以显著改善分子的表示效果，并在多种任务中表现出色，优于其他经典模型。 |
| [^95] | [Failed Goal Aware Hindsight Experience Replay.](http://arxiv.org/abs/2208.14741) | 本文提出了一种称为Failed goal Aware HER (FAHER)的新方法来增强多目标强化学习中的采样效率。该方法利用实现目标与未实现目标之间的关系，并通过聚类模型对序列进行聚类和采样。 |
| [^96] | [Improving generalization by mimicking the human visual diet.](http://arxiv.org/abs/2206.07802) | 本文提出了一个新的视角，通过模仿人类视觉经验的方法来缩小生物和计算机视觉之间的泛化差距。结果显示，将人类的视觉经验中的变化和上下文信息纳入模型中，显著改善了模型对真实世界变换的泛化能力，并在从合成到真实数据的过程中取得了较大的优势。 |

# 详细

[^1]: 大型语言模型在人机交互中的心智理论能力:一个幻觉?

    Theory of Mind abilities of Large Language Models in Human-Robot Interaction : An Illusion?. (arXiv:2401.05302v1 [cs.RO])

    [http://arxiv.org/abs/2401.05302](http://arxiv.org/abs/2401.05302)

    大型语言模型在人机交互中的应用具有较高的风险和潜在的不可逆后果。这项研究探索了大型语言模型的心智理论能力，特别关注机器人感知行为识别任务。

    

    大型语言模型在各种自然语言和生成任务中展示了异常的生成能力。然而，可能出现人形化和对失败案例的宽容性引发了关于大型语言模型中出现的心智理论（ToM）能力的讨论。虽然存在几种假信念测试来验证推断和维护另一个实体的心智模型的能力，我们研究了ToM能力的一个特殊应用，这具有更高的风险和可能是不可逆的后果：人机交互。在这项工作中，我们探讨了感知行为识别的任务，其中机器人使用大型语言模型（LLM）评估机器人生成的行为，类似于人类观察者的方式。我们关注四种行为类型，即可以解释的、可读的、可预测的和混淆的行为，这些行为已被广泛用于合成可解释的机器人行为。因此，LLM的目标是...

    Large Language Models have shown exceptional generative abilities in various natural language and generation tasks. However, possible anthropomorphization and leniency towards failure cases have propelled discussions on emergent abilities of Large Language Models especially on Theory of Mind (ToM) abilities in Large Language Models. While several false-belief tests exists to verify the ability to infer and maintain mental models of another entity, we study a special application of ToM abilities that has higher stakes and possibly irreversible consequences : Human Robot Interaction. In this work, we explore the task of Perceived Behavior Recognition, where a robot employs a Large Language Model (LLM) to assess the robot's generated behavior in a manner similar to human observer. We focus on four behavior types, namely explicable, legible, predictable, and obfuscatory behavior which have been extensively used to synthesize interpretable robot behaviors. The LLMs goal is, therefore to b
    
[^2]: 我是一个奇怪的数据集：用于语言模型的元语言测试

    I am a Strange Dataset: Metalinguistic Tests for Language Models. (arXiv:2401.05300v1 [cs.CL])

    [http://arxiv.org/abs/2401.05300](http://arxiv.org/abs/2401.05300)

    本研究提出了一个新的数据集，名为“我是一个奇怪的数据集”，用来测试大型语言模型（LLMs）是否能够处理元语言自指的陈述。实验证明，各种开源和闭源LLMs在生成和验证任务中的表现都接近随机猜测。

    

    在许多领域中，涉及元语言自指的陈述（“本论文有六个部分。”）是普遍存在的。大型语言模型（LLMs）能否处理这样的语言？在本文中，我们提出了一个新的数据集“我是一个奇怪的数据集”，用来解决这个问题。它包含两个子任务：生成和验证。在生成任务中，模型会继续类似于“这个句子中倒数第二个词是”的陈述（正确的继续应该是“是”）。在验证任务中，模型会判断类似于“这个句子中倒数第二个词是句子。”的陈述的真实性（是假的）。我们还提供了最小差异的非自指元语言示例，来补充主数据集，以测试模型是否能够处理元语言语言。数据集由专家手工制作，非专家标注员进行验证。我们测试了各种开源LLMs（从7B到70B的参数）以及通过API进行测试的闭源LLMs。所有模型在两个子任务上的表现都接近随机猜测。

    Statements involving metalinguistic self-reference ("This paper has six sections.") are prevalent in many domains. Can large language models (LLMs) handle such language? In this paper, we present "I am a Strange Dataset", a new dataset for addressing this question. There are two subtasks: generation and verification. In generation, models continue statements like "The penultimate word in this sentence is" (where a correct continuation is "is"). In verification, models judge the truth of statements like "The penultimate word in this sentence is sentence." (false). We also provide minimally different metalinguistic non-self-reference examples to complement the main dataset by probing for whether models can handle metalinguistic language at all. The dataset is hand-crafted by experts and validated by non-expert annotators. We test a variety of open-source LLMs (7B to 70B parameters) as well as closed-source LLMs through APIs. All models perform close to chance across both subtasks and eve
    
[^3]: INACIA：将大型语言模型整合到巴西审计法院中的机会和挑战

    INACIA: Integrating Large Language Models in Brazilian Audit Courts: Opportunities and Challenges. (arXiv:2401.05273v1 [cs.CL])

    [http://arxiv.org/abs/2401.05273](http://arxiv.org/abs/2401.05273)

    本文介绍了INACIA系统，这是一个将大型语言模型整合到巴西审计法院中的系统，可以自动化案件分析的各个阶段，并展示了其在从案件文件中提取信息、评估合法性和生成司法建议方面的潜力。

    

    本文介绍了INACIA（基于人工智能的辅助指令系统），这是一个开创性的系统，旨在将大型语言模型（LLMs）整合到巴西联邦审计法院（TCU）的运营框架中。该系统自动化了案件分析的各个阶段，包括基本信息提取、可受理性审查、Periculum in mora和Fumus boni iuris分析以及建议生成。通过一系列实验，我们展示了INACIA从案件文件中提取相关信息、评估其合法性并生成司法建议的潜力。利用验证数据集和LLMs，我们的评估方法提供了一种创新的方法来评估系统性能，与人类判断高度相关。结果突显了INACIA处理复杂法律任务的能力，表明其适用于增加法律系统的效率和司法公正性。

    This paper introduces INACIA (Instru\c{c}\~ao Assistida com Intelig\^encia Artificial), a groundbreaking system designed to integrate Large Language Models (LLMs) into the operational framework of Brazilian Federal Court of Accounts (TCU). The system automates various stages of case analysis, including basic information extraction, admissibility examination, Periculum in mora and Fumus boni iuris analyses, and recommendations generation. Through a series of experiments, we demonstrate INACIA's potential in extracting relevant information from case documents, evaluating its legal plausibility, and generating judicial recommendations. Utilizing a validation dataset alongside LLMs, our evaluation methodology presents an innovative approach to assessing system performance, correlating highly with human judgment. The results highlight INACIA's proficiency in handling complex legal tasks, indicating its suitability for augmenting efficiency and judicial fairness within legal systems. The pap
    
[^4]: AUTOACT：通过自主规划实现的自动代理学习

    AUTOACT: Automatic Agent Learning from Scratch via Self-Planning. (arXiv:2401.05268v1 [cs.CL])

    [http://arxiv.org/abs/2401.05268](http://arxiv.org/abs/2401.05268)

    AUTOACT是一个自动代理学习框架，通过自主规划合成轨迹，不依赖于大规模数据和闭源模型，能够实现更好或类似的性能。

    

    语言代理在各种复杂任务上取得了相当的性能。尽管在这个领域进行了不断的探索，但现有的语言代理系统仍然面临昂贵、不可重复的数据依赖问题，并且面临将单一模型应用于多个功能的挑战。为此，我们介绍了AutoAct，这是一个自动代理学习框架，不依赖于大规模带注释的数据和来自闭源模型（如GPT-4）的合成轨迹。给定有限的数据和工具库，AutoAct首先自动合成规划轨迹，不需要人类或强闭源模型的任何辅助。然后，AutoAct利用分工策略，根据目标任务信息和合成轨迹自动区分，产生一个子代理组来完成任务。我们进行了多种LLMs的广泛实验，结果显示AutoAct在性能上优于或与其相当。

    Language agents have achieved considerable performance on various complex tasks. Despite the incessant exploration in this field, existing language agent systems still struggle with costly, non-reproducible data reliance and face the challenge of compelling a single model for multiple functions. To this end, we introduce AutoAct, an automatic agent learning framework that does not rely on large-scale annotated data and synthetic trajectories from closed-source models (e.g., GPT-4). Given limited data with a tool library, AutoAct first automatically synthesizes planning trajectories without any assistance from humans or strong closed-source models. Then, AutoAct leverages a division-of-labor strategy to automatically differentiate based on the target task information and synthesized trajectories, producing a sub-agent group to complete the task. We conduct comprehensive experiments with different LLMs, which demonstrates that AutoAct yields better or parallel performance compared to var
    
[^5]: ReACT: 使用B样条几何的强化学习在控制器参数化中的应用

    ReACT: Reinforcement Learning for Controller Parametrization using B-Spline Geometries. (arXiv:2401.05251v1 [cs.LG])

    [http://arxiv.org/abs/2401.05251](http://arxiv.org/abs/2401.05251)

    本研究提出了一种使用深度强化学习和N维B样条几何进行控制器参数化的方法。通过自主决定控制器参数的调整，该方法可以简化对于复杂和非线性系统的控制器参数化过程。

    

    强大且高效的控制器对于工业应用至关重要。然而，对于复杂和非线性系统导出控制器参数是具有挑战性且耗时的。为了便于自动控制器参数化，本研究提出了一种新的方法，使用深度强化学习（DRL）和N维B样条几何（BSG）。我们关注参数变化系统的控制，这是一类行为复杂且取决于运行条件的系统。对于这一系统类别，由于其已知的设计原理，增益调度控制结构被广泛应用于各个行业的应用中。为了简化对于这些控制结构的控制器参数化任务，我们部署了一个DRL代理。基于控制系统观测，代理自主决定如何调整控制器参数。通过引入BSG来映射可能依赖于多个变量的控制器参数，我们使得适应过程更加高效。

    Robust and performant controllers are essential for industrial applications. However, deriving controller parameters for complex and nonlinear systems is challenging and time-consuming. To facilitate automatic controller parametrization, this work presents a novel approach using deep reinforcement learning (DRL) with N-dimensional B-spline geometries (BSGs). We focus on the control of parameter-variant systems, a class of systems with complex behavior which depends on the operating conditions. For this system class, gain-scheduling control structures are widely used in applications across industries due to well-known design principles. Facilitating the expensive controller parametrization task regarding these control structures, we deploy an DRL agent. Based on control system observations, the agent autonomously decides how to adapt the controller parameters. We make the adaptation process more efficient by introducing BSGs to map the controller parameters which may depend on numerous 
    
[^6]: 视觉和语言编码器是否以相似方式表示世界？

    Do Vision and Language Encoders Represent the World Similarly?. (arXiv:2401.05224v1 [cs.CV])

    [http://arxiv.org/abs/2401.05224](http://arxiv.org/abs/2401.05224)

    通过分析视觉和语言模型的潜在空间结构，发现未对齐和对齐的编码器的表示空间在语义上是相似的。我们提出了两种方法来匹配未对齐编码器，无需训练即可实现匹配。

    

    已经成为视觉语言任务中事实上的模型的对齐的文本-图像编码器（如CLIP）已经取得了令人印象深刻的表现。此外，模态特定的编码器在各自领域中也取得了令人印象深刻的表现。这引出了一个核心问题：由于它们基本上表示同一个物理世界，单模态的视觉和语言编码器之间是否存在对齐？通过使用中心核对齐（CKA）分析图像-标题基准上视觉和语言模型的潜在空间结构，我们发现未对齐和对齐的编码器的表示空间在语义上是相似的。在像CLIP这样的对齐编码器中缺乏统计相似性的情况下，我们显示了可能存在无需任何训练的未对齐编码器的匹配。我们将这视为利用图之间的语义相似性的有种子图匹配问题，并提出了两种方法 - 快速二次分配问题优化和一种基于新颖的局部CKA度量的匹配/检索方法。

    Aligned text-image encoders such as CLIP have become the de facto model for vision-language tasks. Furthermore, modality-specific encoders achieve impressive performances in their respective domains. This raises a central question: does an alignment exist between uni-modal vision and language encoders since they fundamentally represent the same physical world? Analyzing the latent spaces structure of vision and language models on image-caption benchmarks using the Centered Kernel Alignment (CKA), we find that the representation spaces of unaligned and aligned encoders are semantically similar. In the absence of statistical similarity in aligned encoders like CLIP, we show that a possible matching of unaligned encoders exists without any training. We frame this as a seeded graph-matching problem exploiting the semantic similarity between graphs and propose two methods - a Fast Quadratic Assignment Problem optimization, and a novel localized CKA metric-based matching/retrieval. We demons
    
[^7]: 边缘机器学习欺诈检测中的分布式数据分布变化监测

    Distributed Monitoring for Data Distribution Shifts in Edge-ML Fraud Detection. (arXiv:2401.05219v1 [cs.CE])

    [http://arxiv.org/abs/2401.05219](http://arxiv.org/abs/2401.05219)

    本研究提出了一个用于边缘机器学习欺诈检测的分布式数据分布变化监测框架，包括了创新的Kolmogorov-Smirnov (KS)检验计算方法，能够高效准确地监测用户行为变化。

    

    在数字时代，金融欺诈案件明显增加。边缘机器学习是一种有望解决智能手机支付服务欺诈检测问题的方法，可以直接在边缘设备上部署机器学习模型。这种方法可以实现更个性化的实时欺诈检测。然而，目前的研究中存在一个显著的空白，即缺乏一个强大的系统来监测这些分布式边缘机器学习应用中的数据分布变化。我们的工作填补了这一空白，提出了一个新颖的开源框架，用于对边缘设备网络上的数据分布变化进行连续监测。我们的系统包括一种创新的分布式边缘设备上的Kolmogorov-Smirnov (KS)检验计算方法，能够高效准确地监测用户行为变化。我们对提出的框架进行了全面的评估，使用了真实世界和合成金融交易数据集，并展示了该框架的有效性。

    The digital era has seen a marked increase in financial fraud. edge ML emerged as a promising solution for smartphone payment services fraud detection, enabling the deployment of ML models directly on edge devices. This approach enables a more personalized real-time fraud detection. However, a significant gap in current research is the lack of a robust system for monitoring data distribution shifts in these distributed edge ML applications. Our work bridges this gap by introducing a novel open-source framework designed for continuous monitoring of data distribution shifts on a network of edge devices. Our system includes an innovative calculation of the Kolmogorov-Smirnov (KS) test over a distributed network of edge devices, enabling efficient and accurate monitoring of users behavior shifts. We comprehensively evaluate the proposed framework employing both real-world and synthetic financial transaction datasets and demonstrate the framework's effectiveness.
    
[^8]: 金融情绪分析的预训练大型语言模型

    Pre-trained Large Language Models for Financial Sentiment Analysis. (arXiv:2401.05215v1 [cs.CL])

    [http://arxiv.org/abs/2401.05215](http://arxiv.org/abs/2401.05215)

    本文提出了一种使用预训练大型语言模型进行金融情绪分析的方法，通过领域特定的适应和监督微调技术，即使在有限的训练样本下，也能显著提升分类性能。

    

    金融情绪分析是将金融文本内容分类为情绪类别（如积极、消极和中性）。本文关注金融新闻标题的分类，这是一个具有挑战性的任务，因为缺乏大量的训练样本。为了克服这个困难，我们提出了将预训练的大型语言模型（LLMs）[1, 2, 3] 进行领域特定任务的有效适应。LLMs是从大量的文本语料库中训练得到的，具有文本理解的优势，并且可以在需要很少训练样本的情况下进行有效适应。具体而言，我们采用了开源的Llama2-7B模型（2023年）和监督微调（SFT）技术[4]。实验评估结果表明，即使对于LLMs来说较小的7B模型，我们的方法在性能上显著优于先前的最先进算法。

    Financial sentiment analysis refers to classifying financial text contents into sentiment categories (e.g. positive, negative, and neutral). In this paper, we focus on the classification of financial news title, which is a challenging task due to a lack of large amount of training samples. To overcome this difficulty, we propose to adapt the pretrained large language models (LLMs) [1, 2, 3] to solve this problem. The LLMs, which are trained from huge amount of text corpora,have an advantage in text understanding and can be effectively adapted to domain-specific task while requiring very few amount of training samples. In particular, we adapt the open-source Llama2-7B model (2023) with the supervised fine-tuning (SFT) technique [4]. Experimental evaluation shows that even with the 7B model (which is relatively small for LLMs), our approach significantly outperforms the previous state-of-the-art algorithms.
    
[^9]: 一种新颖的提示调整方法：将情景特定概念纳入到话语生成器中

    A Novel Prompt-tuning Method: Incorporating Scenario-specific Concepts into a Verbalizer. (arXiv:2401.05204v1 [cs.CL])

    [http://arxiv.org/abs/2401.05204](http://arxiv.org/abs/2401.05204)

    本文提出了一种新颖的提示调整方法，通过将情景特定概念纳入到话语生成器中，提高了标签词空间的覆盖度和减小了偏见。

    

    话语生成器是提示调整的关键组件，用于将标签词映射到类别标签。本文提出了一种构建话语生成器的新方法。与现有方法主要依赖于对类别名称的同义词或相关词集进行增强和精炼不同，我们的方法通过从特定任务场景中提取丰富的概念作为标签词候选，并开发了一种新颖的级联校准模块来将候选词精炼为每个类别的一组标签词，从而解决了现有方法在标签词空间中覆盖度有限和偏见较高的问题。

    The verbalizer, which serves to map label words to class labels, is an essential component of prompt-tuning. In this paper, we present a novel approach to constructing verbalizers. While existing methods for verbalizer construction mainly rely on augmenting and refining sets of synonyms or related words based on class names, this paradigm suffers from a narrow perspective and lack of abstraction, resulting in limited coverage and high bias in the label-word space. To address this issue, we propose a label-word construction process that incorporates scenario-specific concepts. Specifically, we extract rich concepts from task-specific scenarios as label-word candidates and then develop a novel cascade calibration module to refine the candidates into a set of label words for each class. We evaluate the effectiveness of our proposed approach through extensive experiments on {five} widely used datasets for zero-shot text classification. The results demonstrate that our method outperforms ex
    
[^10]: 使用大型语言模型在制造业中进行知识共享：用户评估和模型基准测试

    Knowledge Sharing in Manufacturing using Large Language Models: User Evaluation and Model Benchmarking. (arXiv:2401.05200v1 [cs.HC])

    [http://arxiv.org/abs/2401.05200](http://arxiv.org/abs/2401.05200)

    使用大型语言模型在制造业中进行知识共享，通过评估实证了该系统的效益，提高了操作员的信息检索速度和问题解决效率，同时强调在有人工专家选项时的偏好。GPT-4是最优秀的模型。

    

    高效管理知识对组织的成功至关重要。在制造业中，操作工厂变得越来越依赖知识，这给工厂培训和支持新操作员的能力带来了压力。本文介绍了一个基于大型语言模型（LLM）的系统，旨在利用工厂文档中包含的广泛知识，高效回答操作员的查询并促进新知识的共享。为了评估其有效性，我们在一个工厂环境中进行了评估。评估结果表明该系统的好处，即能够更快地检索信息和更高效地解决问题。然而，研究也强调了在有人工专家选项时更倾向于向人工专家学习。此外，我们还对该系统进行了几种闭源和开源语言模型的基准测试。GPT-4表现始终优于其他模型，像StableBe

    Managing knowledge efficiently is crucial for organizational success. In manufacturing, operating factories has become increasing knowledge-intensive putting strain on the factory's capacity to train and support new operators. In this paper, we introduce a Large Language Model (LLM)-based system designed to use the extensive knowledge contained in factory documentation. The system aims to efficiently answer queries from operators and facilitate the sharing of new knowledge. To assess its effectiveness, we conducted an evaluation in a factory setting. The results of this evaluation demonstrated the system's benefits; namely, in enabling quicker information retrieval and more efficient resolution of issues. However, the study also highlighted a preference for learning from a human expert when such an option is available. Furthermore, we benchmarked several closed and open-sourced LLMs for this system. GPT-4 consistently outperformed its counterparts, with open-source models like StableBe
    
[^11]: 使用GPT-2的蒙特卡洛树搜索进行食谱生成

    Monte Carlo Tree Search for Recipe Generation using GPT-2. (arXiv:2401.05199v1 [cs.CL])

    [http://arxiv.org/abs/2401.05199](http://arxiv.org/abs/2401.05199)

    本研究提出了一种利用GPT-2和蒙特卡洛树搜索的方法来生成食谱，通过定义奖励函数对文本生成进行限制，提高了生成食谱的可信度。

    

    自动食谱生成方法为厨师提供了一种创造性工具，可以探索和创造新的有趣的烹饪美食。考虑到大型语言模型（LLMs）的最近成功，它们有潜力创造出可以满足个人偏好、膳食限制以及适应您冰箱内食材的新食谱。现有的通过LLMs生成食谱的研究表明，LLMs可以通过微调来生成听起来真实的食谱。然而，仔细检查后发现，这些生成的食谱往往无法满足基本要求，比如在鸡肉菜肴中包含鸡肉。在本文中，我们提出了一种名为RecipeMC的文本生成方法，它使用GPT-2并依赖于蒙特卡洛树搜索（MCTS）。RecipeMC允许我们定义奖励函数以对文本生成进行软限制，从而提高生成食谱的可信度。我们的结果表明，人类评估者更喜欢使用RecipeMC生成的食谱。

    Automatic food recipe generation methods provide a creative tool for chefs to explore and to create new, and interesting culinary delights. Given the recent success of large language models (LLMs), they have the potential to create new recipes that can meet individual preferences, dietary constraints, and adapt to what is in your refrigerator. Existing research on using LLMs to generate recipes has shown that LLMs can be finetuned to generate realistic-sounding recipes. However, on close examination, these generated recipes often fail to meet basic requirements like including chicken as an ingredient in chicken dishes. In this paper, we propose RecipeMC, a text generation method using GPT-2 that relies on Monte Carlo Tree Search (MCTS). RecipeMC allows us to define reward functions to put soft constraints on text generation and thus improve the credibility of the generated recipes. Our results show that human evaluators prefer recipes generated with RecipeMC more often than recipes gen
    
[^12]: 缩放机器人车辆的建模、定位和深度强化学习路径跟踪控制：设计和实验验证

    Modelling, Positioning, and Deep Reinforcement Learning Path Tracking Control of Scaled Robotic Vehicles: Design and Experimental Validation. (arXiv:2401.05194v1 [cs.RO])

    [http://arxiv.org/abs/2401.05194](http://arxiv.org/abs/2401.05194)

    本文提出了一种缩放机器人车辆建模和控制的解决方案，包括联邦式扩展卡尔曼滤波器和通过专家演示器训练的深度强化学习路径跟踪控制器。这些方法可以加快学习阶段并增加对模拟与现实之间差距的鲁棒性。

    

    移动机器人系统越来越受欢迎。这些系统用于各种室内应用，从仓储和制造到用于评估先进控制策略（如基于人工智能的控制解决方案）的测试台，仅举几例。缩放机器人车辆通常配备一种分层控制体系结构，包括用于车辆状态估计和控制的任务。本文提出了两个方面的解决方案：（i）联邦式扩展卡尔曼滤波器（FEKF），和（ii）一种新颖的通过专家演示器训练的深度强化学习（DRL）路径跟踪控制器，以加快学习阶段并增加对模拟与现实之间差距的鲁棒性。本文还介绍了车辆模型的制定以及一种有效而简单的参数辨识过程。通过实验验证的模型用于（i）支持FEKF的设计和（ii）作为数字孪生。

    Mobile robotic systems are becoming increasingly popular. These systems are used in various indoor applications, raging from warehousing and manufacturing to test benches for assessment of advanced control strategies, such as artificial intelligence (AI)-based control solutions, just to name a few. Scaled robotic cars are commonly equipped with a hierarchical control acthiecture that includes tasks dedicated to vehicle state estimation and control. This paper covers both aspects by proposing (i) a federeted extended Kalman filter (FEKF), and (ii) a novel deep reinforcement learning (DRL) path tracking controller trained via an expert demonstrator to expedite the learning phase and increase robustess to the simulation-to-reality gap. The paper also presents the formulation of a vehicle model along with an effective yet simple procedure for identifying tis paramters. The experimentally validated model is used for (i) supporting the design of the FEKF and (ii) serving as a digital twin fo
    
[^13]: 使用函数逼近进行实验规划

    Experiment Planning with Function Approximation. (arXiv:2401.05193v1 [cs.LG])

    [http://arxiv.org/abs/2401.05193](http://arxiv.org/abs/2401.05193)

    本研究探讨了在上下文关联赌博问题中使用函数逼近进行实验规划的问题，并提出了两种与函数逼近兼容的实验规划策略。

    

    我们研究了在上下文关联赌博问题中使用函数逼近进行实验规划的问题。在存在部署自适应算法的显著开销的情况下，例如当执行数据收集策略需要分布式或需要人工参与时，提前生成一组数据收集策略是至关重要的。我们研究了一个大型上下文数据集可用但奖励数据不可用的情景，学习者可以利用该数据集设计一个有效的数据收集策略。虽然当奖励是线性的时候，这个问题已经被广泛研究，但对于更复杂的奖励模型，仍然缺乏结果。在这项工作中，我们提出了两种与函数逼近兼容的实验规划策略。第一种是逃避者规划和采样过程，可以根据逃避者维度的奖励函数类获得最优性保证。对于第二种策略，我们证明了一个...

    We study the problem of experiment planning with function approximation in contextual bandit problems. In settings where there is a significant overhead to deploying adaptive algorithms -- for example, when the execution of the data collection policies is required to be distributed, or a human in the loop is needed to implement these policies -- producing in advance a set of policies for data collection is paramount. We study the setting where a large dataset of contexts but not rewards is available and may be used by the learner to design an effective data collection strategy. Although when rewards are linear this problem has been well studied, results are still missing for more complex reward models. In this work we propose two experiment planning strategies compatible with function approximation. The first is an eluder planning and sampling procedure that can recover optimality guarantees depending on the eluder dimension of the reward function class. For the second, we show that a 
    
[^14]: 对话式语言模型ChatGPT与神经机器翻译在翻译中的竞争性研究

    Can ChatGPT Rival Neural Machine Translation? A Comparative Study. (arXiv:2401.05176v1 [cs.CL])

    [http://arxiv.org/abs/2401.05176](http://arxiv.org/abs/2401.05176)

    本文比较了对话式语言模型ChatGPT和神经机器翻译引擎在将中文外交文本翻译为英文方面的能力，发现自动评价指标和人工评估方法之间存在差异。

    

    在对越来越多地利用大型语言模型进行翻译的兴趣不断增加的背景下，本文评估了ChatGPT等大型语言模型（LLM）与主流神经机器翻译（NMT）引擎在将中文外交文本翻译为英文方面的能力。具体而言，我们通过四个自动评价指标和基于错误类型和六个分析细则的人工评估，考察了ChatGPT和NMT引擎的翻译质量。研究结果表明，自动评价指标对于ChatGPT在不同提示和NMT系统下的表现得出了类似的结果，而当ChatGPT提供示例或翻译任务的上下文信息时，人工评估者往往会给予明显较高的评分。自动评价指标与人工评估维度之间的两两相关性结果较弱且不显著，这表明了两种翻译质量评估方法之间的差异。

    Inspired by the increasing interest in leveraging large language models for translation, this paper evaluates the capabilities of large language models (LLMs) represented by ChatGPT in comparison to the mainstream neural machine translation (NMT) engines in translating Chinese diplomatic texts into English. Specifically, we examine the translation quality of ChatGPT and NMT engines as measured by four automated metrics and human evaluation based on an error-typology and six analytic rubrics. Our findings show that automated metrics yield similar results for ChatGPT under different prompts and NMT systems, while human annotators tend to assign noticeably higher scores to ChatGPT when it is provided an example or contextual information about the translation task. Pairwise correlation between automated metrics and dimensions of human evaluation produces weak and non-significant results, suggesting the divergence between the two methods of translation quality assessment. These findings pro
    
[^15]: MISS：一种适用于医学视觉问答的生成式预训练与微调方法

    MISS: A Generative Pretraining and Finetuning Approach for Med-VQA. (arXiv:2401.05163v1 [cs.CV])

    [http://arxiv.org/abs/2401.05163](http://arxiv.org/abs/2401.05163)

    MISS是一种适用于医学视觉问答的生成式预训练与微调方法。相比于现有方法，我们把医学视觉问答作为一个生成式任务处理，通过多任务学习使图像和文本特征对齐，并通过使用大型语言模型扩展单模态图像数据集的转换和字幕方法实现特征空间的扩展。

    

    医学视觉问答是一项具有挑战性的多模态任务，视觉语言预训练模型能够有效提高其泛化性能。然而，当前多数方法将医学视觉问答视为一个难以转移到实际应用场景的答案分类任务。另外，由于医学图像的隐私性和昂贵的注释过程，用于预训练的大规模医学图文对数据集严重缺乏。本文中，我们提出了一种基于多任务自监督学习的大规模医学视觉问答（MISS）框架。与现有方法不同，我们将医学视觉问答视为一项生成式任务。我们将文本编码器和多模态编码器统一起来，并通过多任务学习使图像和文本特征对齐。此外，我们提出了一种通过使用大型语言模型（LLMs）扩展单模态图像数据集的转换和字幕方法，从而实现了特征空间的扩展。

    Medical visual question answering (VQA) is a challenging multimodal task, where Vision-Language Pre-training (VLP) models can effectively improve the generalization performance. However, most methods in the medical field treat VQA as an answer classification task which is difficult to transfer to practical application scenarios. Additionally, due to the privacy of medical images and the expensive annotation process, large-scale medical image-text pairs datasets for pretraining are severely lacking. In this paper, we propose a large-scale MultI-task Self-Supervised learning based framework (MISS) for medical VQA tasks. Unlike existing methods, we treat medical VQA as a generative task. We unify the text encoder and multimodal encoder and align image-text features through multi-task learning. Furthermore, we propose a Transfer-and-Caption method that extends the feature space of single-modal image datasets using large language models (LLMs), enabling those traditional medical vision fiel
    
[^16]: Derm-T2IM：利用稳定扩散模型的合成皮损数据，通过ViT和CNN增强皮肤疾病分类

    Derm-T2IM: Harnessing Synthetic Skin Lesion Data via Stable Diffusion Models for Enhanced Skin Disease Classification using ViT and CNN. (arXiv:2401.05159v1 [cs.CV])

    [http://arxiv.org/abs/2401.05159](http://arxiv.org/abs/2401.05159)

    本研究利用稳定扩散模型生成合成皮肤镜数据，增强机器学习模型训练的鲁棒性，并在皮肤疾病分类中探索了其有效性。

    

    本研究探索了利用通过稳定扩散模型生成的皮肤镜合成数据作为增强机器学习模型训练鲁棒性的策略。合成数据生成在缓解有限标记数据集所带来的挑战方面发挥着关键作用，从而促进更有效的模型训练。在这个背景下，我们通过扩展最近在文本到图像潜在扩散模型中的少样本学习和少量数据表示的成功，目标是将增强的数据转换技术纳入其中。经过优化调整的模型进一步用于生成具有多样性和逼真特征的高质量皮损合成数据，为现有训练数据提供了有价值的补充和多样性。我们研究了将新生成的合成数据纳入最先进的机器学习模型的训练流程对模型性能和泛化能力的影响。

    This study explores the utilization of Dermatoscopic synthetic data generated through stable diffusion models as a strategy for enhancing the robustness of machine learning model training. Synthetic data generation plays a pivotal role in mitigating challenges associated with limited labeled datasets, thereby facilitating more effective model training. In this context, we aim to incorporate enhanced data transformation techniques by extending the recent success of few-shot learning and a small amount of data representation in text-to-image latent diffusion models. The optimally tuned model is further used for rendering high-quality skin lesion synthetic data with diverse and realistic characteristics, providing a valuable supplement and diversity to the existing training data. We investigate the impact of incorporating newly generated synthetic data into the training pipeline of state-of-art machine learning models, assessing its effectiveness in enhancing model performance and general
    
[^17]: 是的，这就是我想要的！向多模态医疗咨询关注摘要生成迈进

    Yes, this is what I was looking for! Towards Multi-modal Medical Consultation Concern Summary Generation. (arXiv:2401.05134v1 [cs.AI])

    [http://arxiv.org/abs/2401.05134](http://arxiv.org/abs/2401.05134)

    本文提出了一个新的任务：多模态医疗关注摘要生成，通过结合患者的非语言线索和个人信息，生成简短精确的咨询关注摘要。

    

    在过去几年中，互联网在医疗保健相关任务中的使用增长迅猛，有效管理和处理信息以确保其高效利用面临挑战。在情绪困扰和心理挑战时刻，我们经常转向互联网作为我们最初的支持源，选择它而不是与他人讨论我们的感受，因为这涉及社会的污名。在本文中，我们提出了一个新的多模态医疗关注摘要生成（MMCS）任务，它提供了关于患者在咨询过程中提出的主要关注的简短和精确摘要。非语言线索，例如患者的手势和面部表情，有助于准确识别患者的关注点。医生还考虑患者的个人信息，例如年龄和性别，以便适当地描述医疗状况。受患者个人上下文和视觉手势的潜在疗效的启发，我们提出了一个新的方法

    Over the past few years, the use of the Internet for healthcare-related tasks has grown by leaps and bounds, posing a challenge in effectively managing and processing information to ensure its efficient utilization. During moments of emotional turmoil and psychological challenges, we frequently turn to the internet as our initial source of support, choosing this over discussing our feelings with others due to the associated social stigma. In this paper, we propose a new task of multi-modal medical concern summary (MMCS) generation, which provides a short and precise summary of patients' major concerns brought up during the consultation. Nonverbal cues, such as patients' gestures and facial expressions, aid in accurately identifying patients' concerns. Doctors also consider patients' personal information, such as age and gender, in order to describe the medical condition appropriately. Motivated by the potential efficacy of patients' personal context and visual gestures, we propose a tr
    
[^18]: 超出对称零和博弈的神经群体学习

    Neural Population Learning beyond Symmetric Zero-sum Games. (arXiv:2401.05133v1 [cs.AI])

    [http://arxiv.org/abs/2401.05133](http://arxiv.org/abs/2401.05133)

    本研究研究了在n个玩家 general-sum 游戏中寻找均衡的计算方法。提出了一种神经群体学习算法 NeuPL-JPSRO，通过技能的迁移学习，收敛到游戏的粗略相关均衡。验证了算法的实证收敛性，并在复杂领域中展示了应用的可行性。该研究为解决现实世界中异质玩家、具有混合动机的游戏提供了新的路径。

    

    我们研究了在n个玩家 general-sum 游戏中寻找均衡的计算方法，特别是那些涉及复杂的视觉运动技能。我们展示了现有方法在这种情况下要么在计算上困难，要么在理论上面临困难。然后，我们引入了 NeuPL-JPSRO，一种神经群体学习算法，该算法通过技能的迁移学习，收敛到游戏的粗略相关均衡 (Coarse Correlated Equilibrium)。我们在一系列的 OpenSpiel 游戏中展示了实证收敛性，并由精确的游戏求解器进行了严格验证。然后，我们将 NeuPL-JPSRO 应用于复杂的领域，在 MuJoCo 控制领域实现了自适应协调和 capture-the-flag 中的技能迁移。我们的工作表明，可以在规模和普遍性上实现收敛于均衡的群体学习，为解决异质玩家、具有混合动机的现实世界游戏铺平了道路。

    We study computationally efficient methods for finding equilibria in n-player general-sum games, specifically ones that afford complex visuomotor skills. We show how existing methods would struggle in this setting, either computationally or in theory. We then introduce NeuPL-JPSRO, a neural population learning algorithm that benefits from transfer learning of skills and converges to a Coarse Correlated Equilibrium (CCE) of the game. We show empirical convergence in a suite of OpenSpiel games, validated rigorously by exact game solvers. We then deploy NeuPL-JPSRO to complex domains, where our approach enables adaptive coordination in a MuJoCo control domain and skill transfer in capture-the-flag. Our work shows that equilibrium convergent population learning can be implemented at scale and in generality, paving the way towards solving real-world games between heterogeneous players with mixed motives.
    
[^19]: 揭示人机交互：从交互原则到设计空间

    Unpacking Human-AI interactions: From interaction primitives to a design space. (arXiv:2401.05115v1 [cs.HC])

    [http://arxiv.org/abs/2401.05115](http://arxiv.org/abs/2401.05115)

    本文开发了一个半正式的设计空间，利用一组交互原则，为人机交互提供抽象规范，支持目的性交互，并简洁概括了现有实践的相似性和差异性。它还为新系统的创建提供了可能性空间。

    

    本文旨在通过构建一组交互原则，为人机交互开发一个半正式的设计空间，以指定用户与AI系统在交互过程中的通信方式。我们展示了这些原则如何组合成一组交互模式，为人类和AI/ML模型之间的信息交换提供抽象规范，以进行有目的的交互。这样做的动机有两个方面：首先，提供对现有实践的简洁概括，突出了系统在交互行为方面的相似性和差异性；其次，支持新系统的创建，特别是通过为与模型的交互打开可能性空间。我们对与HAI交互设计和实施相关的框架，指南和分类方法进行了简要的文献回顾，包括人机协同，可解释的AI以及混合智能。

    This paper aims to develop a semi-formal design space for Human-AI interactions, by building a set of interaction primitives which specify the communication between users and AI systems during their interaction. We show how these primitives can be combined into a set of interaction patterns which can provide an abstract specification for exchanging messages between humans and AI/ML models to carry out purposeful interactions. The motivation behind this is twofold: firstly, to provide a compact generalisation of existing practices, that highlights the similarities and differences between systems in terms of their interaction behaviours; and secondly, to support the creation of new systems, in particular by opening the space of possibilities for interactions with models. We present a short literature review on frameworks, guidelines and taxonomies related to the design and implementation of HAI interactions, including human-in-the-loop, explainable AI, as well as hybrid intelligence and 
    
[^20]: 任意方式元学习

    Any-Way Meta Learning. (arXiv:2401.05097v1 [cs.LG])

    [http://arxiv.org/abs/2401.05097](http://arxiv.org/abs/2401.05097)

    本文通过引入“任意方式”学习范式解决了元学习中固定基数的限制，并通过利用从标签分配中出现的“标签等价性”来提高模型的性能和稳定性。同时提出了一个新的方法来弥补标签等价性带来的语义信息差距。

    

    尽管元学习在快速适应性方面表现出了很大的潜力，但它受到固定基数的限制。当面临训练过程中未见过的基数不同的任务时，模型就无法胜任。本文通过利用从随机数值标签分配中出现的“标签等价性”来解决这一挑战。质疑“真正的”元学习的定义，我们引入了“任意方式”学习范式，这是一种创新的模型训练方法，使模型摆脱了固定基数的限制。令人惊讶的是，这个模型不仅在性能、收敛速度和稳定性方面与传统的固定方式模型相匹配，而且通常表现得更好。这颠覆了关于领域泛化的已有观念。此外，我们认为固有的标签等价性自然地缺乏语义信息。为了弥补标签等价性带来的这种语义信息差距，我们进一步提出了一个新的方法。

    Although meta-learning seems promising performance in the realm of rapid adaptability, it is constrained by fixed cardinality. When faced with tasks of varying cardinalities that were unseen during training, the model lacks its ability. In this paper, we address and resolve this challenge by harnessing `label equivalence' emerged from stochastic numeric label assignments during episodic task sampling. Questioning what defines ``true" meta-learning, we introduce the ``any-way" learning paradigm, an innovative model training approach that liberates model from fixed cardinality constraints. Surprisingly, this model not only matches but often outperforms traditional fixed-way models in terms of performance, convergence speed, and stability. This disrupts established notions about domain generalization. Furthermore, we argue that the inherent label equivalence naturally lacks semantic information. To bridge this semantic information gap arising from label equivalence, we further propose a m
    
[^21]: 通过最小贝叶斯风险解码生成多样性和高质量的文本

    Generating Diverse and High-Quality Texts by Minimum Bayes Risk Decoding. (arXiv:2401.05054v1 [cs.CL])

    [http://arxiv.org/abs/2401.05054](http://arxiv.org/abs/2401.05054)

    本研究提出了基于最小贝叶斯风险解码的多样性生成算法，通过在解码过程中加入多样性目标，能够生成高质量且多样化的文本输出。

    

    文本生成系统中最重要的挑战之一是产生不仅正确而且多样化的输出。最近，最小贝叶斯风险（MBR）解码在生成算法中得到了广泛应用，可以产生最高质量的句子。然而，目前为生成多样化输出而提出的现有算法主要基于波束搜索或随机抽样，因此其输出质量受限于这些基本方法。在本文中，我们探索了一种替代方法--通过将多样性目标强加到MBR解码中来开发促进多样性的解码算法。我们提出了两种MBR的变体，即多样性MBR（DMBR）和k-medoids MBR（KMBR），用于生成一组高质量和多样性的句子。我们使用编码器-解码器模型和大型语言模型进行了各种定向文本生成任务的DMBR和KMBR评估。实验结果表明，所提出的方法实现了更好的传统

    One of the most important challenges in text generation systems is to produce outputs that are not only correct but also diverse. Recently, Minimum Bayes-Risk (MBR) decoding has gained prominence for generating sentences of the highest quality among the decoding algorithms. However, existing algorithms proposed for generating diverse outputs are predominantly based on beam search or random sampling, thus their output quality is capped by these underlying methods. In this paper, we investigate an alternative approach -- we develop diversity-promoting decoding algorithms by enforcing diversity objectives to MBR decoding. We propose two variants of MBR, Diverse MBR (DMBR) and $k$-medoids MBR (KMBR), methods to generate a set of sentences with high quality and diversity. We evaluate DMBR and KMBR on a variety of directed text generation tasks using encoder-decoder models and a large language model with prompting. The experimental results show that the proposed method achieves a better trad
    
[^22]: CreINNs: Credal-Set Interval Neural Networks用于分类任务中的不确定性估计

    CreINNs: Credal-Set Interval Neural Networks for Uncertainty Estimation in Classification Tasks. (arXiv:2401.05043v1 [cs.LG])

    [http://arxiv.org/abs/2401.05043](http://arxiv.org/abs/2401.05043)

    CreINNs是一种用于分类任务的Credal-Set Interval Neural Networks，通过保留传统的区间神经网络结构，捕捉权重不确定性，并使用概率区间的数学框架预测可信区间。实验结果表明，CreINNs在不确定性估计方面优于变分贝叶斯神经网络和深度集成，并且具有较低的计算复杂度和模型大小。

    

    不确定性估计对于提高神经网络的可靠性越来越有吸引力。在这项工作中，我们提出了新颖的Credal-Set Interval Neural Networks（CreINNs），用于分类任务。CreINNs保留了传统的区间神经网络结构，通过确定性区间捕捉权重的不确定性，同时使用概率区间的数学框架预测可信区间。在一个超出分发检测基准（CIFAR10 vs SVHN）上的实验验证中，CreINNs相比于变分贝叶斯神经网络（BNNs）和深度集成（DEs），在认知不确定性估计方面表现出色。此外，与变分BNNs相比，CreINNs的计算复杂度显著降低，并且比DEs具有较小的模型大小。

    Uncertainty estimation is increasingly attractive for improving the reliability of neural networks. In this work, we present novel credal-set interval neural networks (CreINNs) designed for classification tasks. CreINNs preserve the traditional interval neural network structure, capturing weight uncertainty through deterministic intervals, while forecasting credal sets using the mathematical framework of probability intervals. Experimental validations on an out-of-distribution detection benchmark (CIFAR10 vs SVHN) showcase that CreINNs outperform epistemic uncertainty estimation when compared to variational Bayesian neural networks (BNNs) and deep ensembles (DEs). Furthermore, CreINNs exhibit a notable reduction in computational complexity compared to variational BNNs and demonstrate smaller model sizes than DEs.
    
[^23]: 通过自我对话引导基于LLM的任务导向对话代理的引导

    Bootstrapping LLM-based Task-Oriented Dialogue Agents via Self-Talk. (arXiv:2401.05033v1 [cs.CL])

    [http://arxiv.org/abs/2401.05033](http://arxiv.org/abs/2401.05033)

    本论文提出了一种通过LLM的自我对话收集数据的方法，用于指导基于LLM的任务导向对话代理。通过引入自我对话度量来衡量对话的成功，我们可以选择质量较高的样本进行训练和优化。

    

    大型语言模型（LLM）是强大的对话代理，但特化它们以实现特定功能可能具有挑战性。指示调谐，即在人类生成的指令和示例响应上调谐模型（Ouyang等人，2022），已被证明是一种有效的方法，但需要一定数量的数据样本，这些样本可能不可用或生成成本高昂。此外，当目标是使LLM遵循对话中的特定工作流程而不仅仅是单个指令时，这种成本会增加。受到强化学习中自我博弈技术和使用LLM模拟人类代理的启发，我们提出了一种更有效的通过LLM扮演不同角色进行对话的数据收集方法。这种方法通过LLM的“自我对话”生成训练数据，可以进行精细调谐和利用。我们引入了一种自动化的方法来衡量对话的（部分）成功。该度量用于过滤基于LLM的自我对话生成的训练数据，以选择质量较高的样本进行进一步的训练和优化。

    Large language models (LLMs) are powerful dialogue agents, but specializing them towards fulfilling a specific function can be challenging. Instructing tuning, i.e. tuning models on instruction and sample responses generated by humans (Ouyang et al., 2022), has proven as an effective method to do so, yet requires a number of data samples that a) might not be available or b) costly to generate. Furthermore, this cost increases when the goal is to make the LLM follow a specific workflow within a dialogue instead of single instructions. Inspired by the self-play technique in reinforcement learning and the use of LLMs to simulate human agents, we propose a more effective method for data collection through LLMs engaging in a conversation in various roles. This approach generates a training data via "self-talk" of LLMs that can be refined and utilized for supervised fine-tuning. We introduce an automated way to measure the (partial) success of a dialogue. This metric is used to filter the ge
    
[^24]: 无源跨模态知识转移方法：释放无用任务数据的潜力

    Source-Free Cross-Modal Knowledge Transfer by Unleashing the Potential of Task-Irrelevant Data. (arXiv:2401.05014v1 [cs.CV])

    [http://arxiv.org/abs/2401.05014](http://arxiv.org/abs/2401.05014)

    本论文提出了一种无源跨模态知识转移方法，通过解锁无用任务数据的潜力，利用成对的任务无关数据来估计源数据分布并促进知识转移。该方法采用了Task-irrelevant data-Guided Modality Bridging (TGMB)模块来更好地估计源数据分布。

    

    无源跨模态知识转移是一项重要且具有挑战性的任务，它旨在在没有任务相关源数据的情况下将知识从一个源模态（例如，RGB）转移到目标模态（例如，深度或红外）中，原因是由于内存和隐私问题。最近的一项尝试利用成对的任务无关性（TI）数据，并直接匹配它们的特征来消除模态差异。然而，它忽略了一个关键线索，即成对的TI数据可以用于有效估计源数据分布并更好地促进向目标模态的知识转移。为此，我们提出了一种新颖而简洁的框架，来发挥成对的TI数据在增强无源跨模态知识转移方面的潜力。我们的工作得到了两个关键技术组成部分的支持。首先，为了更好地估计源数据分布，我们引入了一个任务无关数据引导的模态桥接（TGMB）模块。它将目标模态数据翻译为与源模态特征匹配的形式。

    Source-free cross-modal knowledge transfer is a crucial yet challenging task, which aims to transfer knowledge from one source modality (e.g., RGB) to the target modality (e.g., depth or infrared) with no access to the task-relevant (TR) source data due to memory and privacy concerns. A recent attempt leverages the paired task-irrelevant (TI) data and directly matches the features from them to eliminate the modality gap. However, it ignores a pivotal clue that the paired TI data could be utilized to effectively estimate the source data distribution and better facilitate knowledge transfer to the target modality. To this end, we propose a novel yet concise framework to unlock the potential of paired TI data for enhancing source-free cross-modal knowledge transfer. Our work is buttressed by two key technical components. Firstly, to better estimate the source data distribution, we introduce a Task-irrelevant data-Guided Modality Bridging (TGMB) module. It translates the target modality da
    
[^25]: 简约即大道：对多模态少样本学习的深入研究

    Less is More : A Closer Look at Multi-Modal Few-Shot Learning. (arXiv:2401.05010v1 [cs.CV])

    [http://arxiv.org/abs/2401.05010](http://arxiv.org/abs/2401.05010)

    该论文提出了一个简单但有效的框架，利用文本信息和语言模型来进行少样本学习任务，充分发挥了预训练语言模型的零样本能力，并直接将视觉特征和文本特征进行推理。

    

    少样本学习旨在通过极少量的可用图像来学习和区分新的类别，这在深度学习领域中构成了一个重大挑战。最近的研究者们试图利用这些稀有类别的附加文本或语言信息和预训练的语言模型来促进学习，从而在一定程度上缓解不足的监督信号问题。然而，至今对于文本信息和预训练语言模型的充分潜力在少样本学习中被低估了，导致性能的提升有限。为了解决这个问题，我们提出了一个简单但有效的少样本学习任务框架，专门设计用于利用文本信息和语言模型。更详细地说，我们明确地利用可学习的提示来充分发挥预训练语言模型的零样本能力。我们直接将视觉特征和文本特征进行推理，而不是简单地添加它们。

    Few-shot Learning aims to learn and distinguish new categories with a very limited number of available images, presenting a significant challenge in the realm of deep learning. Recent researchers have sought to leverage the additional textual or linguistic information of these rare categories with a pre-trained language model to facilitate learning, thus partially alleviating the problem of insufficient supervision signals. However, the full potential of the textual information and pre-trained language model have been underestimated in the few-shot learning till now, resulting in limited performance enhancements. To address this, we propose a simple but effective framework for few-shot learning tasks, specifically designed to exploit the textual information and language model. In more detail, we explicitly exploit the zero-shot capability of the pre-trained language model with the learnable prompt. And we just add the visual feature with the textual feature for inference directly witho
    
[^26]: AdaFed：通过自适应公共下降方向实现公平的联邦学习

    AdaFed: Fair Federated Learning via Adaptive Common Descent Direction. (arXiv:2401.04993v1 [cs.LG])

    [http://arxiv.org/abs/2401.04993](http://arxiv.org/abs/2401.04993)

    AdaFed是一种通过自适应公共下降方向实现公平的联邦学习方法，通过调整服务器的更新方向来确保所有客户端的损失函数减小，并且更大值的客户端的减小速率更高。

    

    联邦学习是一种有前途的技术，通过该技术，一些边缘设备/客户端在服务器的协调下共同训练一个机器学习模型。不公平的模型学习是联邦学习中的一个关键问题，训练的模型可能对某些设备产生不公平的优势或劣势。为了解决这个问题，本文提出了AdaFed。AdaFed的目标是找到服务器更新方向，在这个方向上，所有客户端的损失函数都在减小，并且更重要的是，损失函数值较大的客户端的减小速率更高。AdaFed根据本地梯度和损失函数的值自适应地调整这个公共方向。我们通过一系列联邦数据集验证了AdaFed的有效性，并证明AdaFed优于最先进的公平联邦学习方法。

    Federated learning (FL) is a promising technology via which some edge devices/clients collaboratively train a machine learning model orchestrated by a server. Learning an unfair model is known as a critical problem in federated learning, where the trained model may unfairly advantage or disadvantage some of the devices. To tackle this problem, in this work, we propose AdaFed. The goal of AdaFed is to find an updating direction for the server along which (i) all the clients' loss functions are decreasing; and (ii) more importantly, the loss functions for the clients with larger values decrease with a higher rate. AdaFed adaptively tunes this common direction based on the values of local gradients and loss functions. We validate the effectiveness of AdaFed on a suite of federated datasets, and demonstrate that AdaFed outperforms state-of-the-art fair FL methods.
    
[^27]: 拖车车辆在环岛交叉口的自主导航

    Autonomous Navigation of Tractor-Trailer Vehicles through Roundabout Intersections. (arXiv:2401.04980v1 [cs.RO])

    [http://arxiv.org/abs/2401.04980](http://arxiv.org/abs/2401.04980)

    该论文通过开发拖车和卡车模型，使用高保真度模拟软件CARLA，并建立了基准数据集，以研究拖车车辆在环岛交叉口的自主导航。研究使用双Q软件演员评论算法训练了一个准端到端的自动驾驶模型，在不同环岛上取得了73%的成功率。

    

    近年来，自动驾驶领域取得了显著进展，旨在提高安全性和效率。然而，对于拖车车辆的研究相对较少。由于其物理特性和铰接关节，这种车辆需要定制模型。在转弯时，拖车的后轮以更小的半径转动，卡车经常需要偏离车道中心来适应这种情况。由于缺乏公开可用的模型，本研究利用高保真度模拟软件CARLA开发了卡车和拖车模型，并使用几个环岛场景建立了基准数据集。使用双Q软件演员评论算法，我们训练了一个准端到端的自动驾驶模型，在不同环岛上实现了73%的成功率。

    In recent years, significant advancements have been made in the field of autonomous driving with the aim of increasing safety and efficiency. However, research that focuses on tractor-trailer vehicles is relatively sparse. Due to the physical characteristics and articulated joints, such vehicles require tailored models. While turning, the back wheels of the trailer turn at a tighter radius and the truck often has to deviate from the centre of the lane to accommodate this. Due to the lack of publicly available models, this work develops truck and trailer models using the high-fidelity simulation software CARLA, together with several roundabout scenarios, to establish a baseline dataset for benchmarks. Using a twin-q soft actor-critic algorithm, we train a quasi-end-to-end autonomous driving model which is able to achieve a 73% success rate on different roundabouts.
    
[^28]: 可逆解决非规则采样时间序列的神经微分方程分析方法

    Invertible Solution of Neural Differential Equations for Analysis of Irregularly-Sampled Time Series. (arXiv:2401.04979v1 [cs.LG])

    [http://arxiv.org/abs/2401.04979](http://arxiv.org/abs/2401.04979)

    我们提出了一种可逆解决非规则采样时间序列的神经微分方程分析方法，通过引入神经流的概念，我们的方法既保证了可逆性又降低了计算负担，并且在分类和插值任务中表现出了优异的性能。

    

    为了处理非规则和不完整的时间序列数据的复杂性，我们提出了一种基于神经微分方程（NDE）的可逆解决方案。虽然基于NDE的方法是分析非规则采样时间序列的一种强大方法，但它们通常不能保证在其标准形式下进行可逆变换。我们的方法建议使用具有神经流的神经控制微分方程（Neural CDEs）的变种，该方法在保持较低的计算负担的同时确保了可逆性。此外，它还可以训练双重潜在空间，增强了对动态时间动力学的建模能力。我们的研究提出了一个先进的框架，在分类和插值任务中都表现出色。我们方法的核心是一个经过精心设计的增强型双重潜在状态架构，用于在各种时间序列任务中提高精度。实证分析表明，我们的方法明显优于现有模型。

    To handle the complexities of irregular and incomplete time series data, we propose an invertible solution of Neural Differential Equations (NDE)-based method. While NDE-based methods are a powerful method for analyzing irregularly-sampled time series, they typically do not guarantee reversible transformations in their standard form. Our method suggests the variation of Neural Controlled Differential Equations (Neural CDEs) with Neural Flow, which ensures invertibility while maintaining a lower computational burden. Additionally, it enables the training of a dual latent space, enhancing the modeling of dynamic temporal dynamics. Our research presents an advanced framework that excels in both classification and interpolation tasks. At the core of our approach is an enhanced dual latent states architecture, carefully designed for high precision across various time series tasks. Empirical analysis demonstrates that our method significantly outperforms existing models. This work significan
    
[^29]: 用符号回归梯度解释神经网络分类器的闭式表示

    Closed-Form Interpretation of Neural Network Classifiers with Symbolic Regression Gradients. (arXiv:2401.04978v1 [cs.LG])

    [http://arxiv.org/abs/2401.04978](http://arxiv.org/abs/2401.04978)

    本文提出了一种解释神经网络分类器的闭式表示的方法，使其适用于自动化科学发现。这种方法通过将神经网络嵌入到一组基于相同量的等价类中，并通过找到该等价类与符号回归搜索空间中的方程的交集来解释神经网络。

    

    我提出了一个统一的框架来解释神经网络分类器，以实现自动科学发现。与基于神经网络的回归不同，对于分类而言，即使神经网络本身的分类基于可以表示为闭式方程的量，也一般无法找到从神经网络到符号方程的一对一映射。在本文中，我将训练好的神经网络嵌入到一个等价类中，这个等价类的分类函数的决策都基于相同的量。我通过找到这个等价类与由符号回归搜索空间定义的可读的方程的交集来解释神经网络。这种方法不限于分类器或完整的神经网络，还可以应用于隐藏层或潜在空间中的任意神经元，或简化解释神经网络回归器的过程。

    I introduce a unified framework for interpreting neural network classifiers tailored toward automated scientific discovery. In contrast to neural network-based regression, for classification, it is in general impossible to find a one-to-one mapping from the neural network to a symbolic equation even if the neural network itself bases its classification on a quantity that can be written as a closed-form equation. In this paper, I embed a trained neural network into an equivalence class of classifying functions that base their decisions on the same quantity. I interpret neural networks by finding an intersection between this equivalence class and human-readable equations defined by the search space of symbolic regression. The approach is not limited to classifiers or full neural networks and can be applied to arbitrary neurons in hidden layers or latent spaces or to simplify the process of interpreting neural network regressors.
    
[^30]: 跨相关随机过程的信息流速率

    Information Flow Rate for Cross-Correlated Stochastic Processes. (arXiv:2401.04950v1 [physics.data-an])

    [http://arxiv.org/abs/2401.04950](http://arxiv.org/abs/2401.04950)

    该论文探讨了耦合随机过程中基于数据驱动的信息流速率的统计特性，通过推导信息流速率统计量与自相关和互相关函数属性之间的关系，揭示了信息流速率与相关函数特征的依赖性。

    

    因果推断旨在识别耦合系统中的因果关系。Liang最近提出的一种方法通过量化时间序列之间的信息流的方向和大小来检测因果关系。随机动力系统的信息流的理论表述提供了一个总体表达式和一个数据驱动的统计量，用于衡量不同系统单元之间的熵传输速率。为了推进对信息流速率的理解，以直观概念和物理上有意义的参数为基础，我们研究了耦合随机过程之间的数据驱动信息流速率的统计特性。我们推导出了信息流速率统计量的期望与自相关和互相关函数的属性之间的关系。因此，我们阐明了信息流速率对相关函数的分析性质和特征时间的依赖性。我们的分析提供了对信息流与耦合随机过程之间关系的洞察。

    Causal inference seeks to identify cause-and-effect interactions in coupled systems. A recently proposed method by Liang detects causal relations by quantifying the direction and magnitude of information flow between time series. The theoretical formulation of information flow for stochastic dynamical systems provides a general expression and a data-driven statistic for the rate of entropy transfer between different system units. To advance understanding of information flow rate in terms of intuitive concepts and physically meaningful parameters, we investigate statistical properties of the data-driven information flow rate between coupled stochastic processes. We derive relations between the expectation of the information flow rate statistic and properties of the auto- and cross-correlation functions. Thus, we elucidate the dependence of the information flow rate on the analytical properties and characteristic times of the correlation functions. Our analysis provides insight into the 
    
[^31]: 完全分散的合作多智能体强化学习：一项调查

    Fully Decentralized Cooperative Multi-Agent Reinforcement Learning: A Survey. (arXiv:2401.04934v1 [cs.MA])

    [http://arxiv.org/abs/2401.04934](http://arxiv.org/abs/2401.04934)

    本文系统地回顾了完全分散的合作多智能体强化学习方法，并讨论了两种不同设置下的算法以及未来的研究方向。

    

    合作多智能体强化学习是解决许多实际合作任务的强大工具，但现实应用的限制可能要求以完全分散的方式训练智能体。由于缺乏其他智能体的信息，要在完全分散的情况下得出可以收敛到最优联合策略的算法是具有挑战性的。因此，这个研究领域还没有得到深入的研究。在本文中，我们系统地回顾了两种设置的完全分散方法：最大化所有智能体的共享奖励和最大化所有智能体的个体奖励的总和，并讨论了开放问题和未来的研究方向。

    Cooperative multi-agent reinforcement learning is a powerful tool to solve many real-world cooperative tasks, but restrictions of real-world applications may require training the agents in a fully decentralized manner. Due to the lack of information about other agents, it is challenging to derive algorithms that can converge to the optimal joint policy in a fully decentralized setting. Thus, this research area has not been thoroughly studied. In this paper, we seek to systematically review the fully decentralized methods in two settings: maximizing a shared reward of all agents and maximizing the sum of individual rewards of all agents, and discuss open questions and future research directions.
    
[^32]: 基于学习的难度校准提升成员推理攻击的能力

    Learning-Based Difficulty Calibration for Enhanced Membership Inference Attacks. (arXiv:2401.04929v1 [cs.CR])

    [http://arxiv.org/abs/2401.04929](http://arxiv.org/abs/2401.04929)

    本文介绍了一种基于学习的难度校准的成员推理攻击方法，旨在显著提高低FPR下的TPR，以验证训练模型是否保护隐私。

    

    机器学习模型，特别是深度神经网络，目前是各种应用的重要组成部分，从医疗保健到金融。然而，使用敏感数据来训练这些模型引发了对隐私和安全的担忧。一种验证训练模型是否保护隐私的方法是成员推理攻击（MIA），它允许对手确定特定数据点是否是模型的训练数据集的一部分。虽然已经在文献中提出了一系列的MIA，但只有少数能够在低假阳性率（FPR）区域（0.01%~1%）实现较高的真阳性率（TPR）。这是实际应用于实际场景中的MIA必须考虑的关键因素。在本文中，我们提出了一种新颖的MIA方法，旨在显著提高低FPR的TPR。我们的方法名为基于学习的难度校准（LDC-MIA），通过使用神经网络分类器将数据记录以其难度级别进行表征。

    Machine learning models, in particular deep neural networks, are currently an integral part of various applications, from healthcare to finance. However, using sensitive data to train these models raises concerns about privacy and security. One method that has emerged to verify if the trained models are privacy-preserving is Membership Inference Attacks (MIA), which allows adversaries to determine whether a specific data point was part of a model's training dataset. While a series of MIAs have been proposed in the literature, only a few can achieve high True Positive Rates (TPR) in the low False Positive Rate (FPR) region (0.01%~1%). This is a crucial factor to consider for an MIA to be practically useful in real-world settings. In this paper, we present a novel approach to MIA that is aimed at significantly improving TPR at low FPRs. Our method, named learning-based difficulty calibration for MIA(LDC-MIA), characterizes data records by their hardness levels using a neural network clas
    
[^33]: 推理步长对大型语言模型的影响

    The Impact of Reasoning Step Length on Large Language Models. (arXiv:2401.04925v1 [cs.CL])

    [http://arxiv.org/abs/2401.04925](http://arxiv.org/abs/2401.04925)

    本研究探讨了推理步长对大型语言模型的影响，并发现在提示中增加推理步骤能显著提高模型的推理能力，而减少推理步骤则会降低模型的推理能力。

    

    思维链条（CoT）对于提高大型语言模型（LLM）的推理能力具有重要作用。然而，CoT的有效性与提示中推理步骤的长度之间的关系仍然不为人所知。为了揭示这一点，我们进行了几个实证实验来探索这些关系。具体而言，我们设计了一些实验，扩展和压缩CoT演示中的合理推理步骤，同时保持其他因素不变。我们得出了以下主要发现。首先，结果表明，在提示中延长推理步骤，即使没有向提示中添加新信息，也会显著提高LLM在多个数据集上的推理能力。相反，缩短推理步骤，即使保留关键信息，也会显著降低模型的推理能力。这一发现突显了CoT提示中步骤数量的重要性，并提供了实际指导。

    Chain of Thought (CoT) is significant in improving the reasoning abilities of large language models (LLMs). However, the correlation between the effectiveness of CoT and the length of reasoning steps in prompts remains largely unknown. To shed light on this, we have conducted several empirical experiments to explore the relations. Specifically, we design experiments that expand and compress the rationale reasoning steps within CoT demonstrations, while keeping all other factors constant. We have the following key findings. First, the results indicate that lengthening the reasoning steps in prompts, even without adding new information into the prompt, considerably enhances LLMs' reasoning abilities across multiple datasets. Alternatively, shortening the reasoning steps, even while preserving the key information, significantly diminishes the reasoning abilities of models. This finding highlights the importance of the number of steps in CoT prompts and provides practical guidance to make 
    
[^34]: ANGO: 一个面向生成型语言模型的中文领域评估基准

    ANGO: A Next-Level Evaluation Benchmark For Generation-Oriented Language Models In Chinese Domain. (arXiv:2401.04898v1 [cs.CL])

    [http://arxiv.org/abs/2401.04898](http://arxiv.org/abs/2401.04898)

    ANGO是一个中文领域生成型语言模型评估基准，引入了关键点分类标准，提供了更好的可解释性，同时建立了可量化的问题难度标准，对模型训练提供了更精确的指导。

    

    最近，出现了各种大规模语言模型（LLMs）评估数据集，但其中大多数存在排名失真和模型能力分析困难的问题。针对这些问题，本文引入了ANGO，一个中文多项选择题评估基准。ANGO首次提出了“关键点”分类标准，ANGO中的每个问题可以对应多个关键点，有效提高了评估结果的可解释性。基于真人表现的性能，我们建立了可量化的问题难度标准，并将ANGO问题分为9个难度级别，为模型训练提供了更精确的指导。为了最小化数据泄漏的影响并充分利用ANGO的创新特点，我们设计了独家抽样策略和新的评估框架，支持快速测试集迭代。我们的实验证明，ANGO对模型提出了更大的挑战，并在评估结果中揭示出更多细节。

    Recently, various Large Language Models (LLMs) evaluation datasets have emerged, but most of them have issues with distorted rankings and difficulty in model capabilities analysis. Addressing these concerns, this paper introduces ANGO, a Chinese multi-choice question evaluation benchmark. ANGO proposes \textit{Keypoint} categorization standard for the first time, each question in ANGO can correspond to multiple keypoints, effectively enhancing interpretability of evaluation results. Base on performance of real humans, we build a quantifiable question difficulty standard and divide ANGO questions into 9 difficulty levels, which provide more precise guidance for model training. To minimize data leakage impact and fully leverage ANGO's innovative features, we have engineered exclusive sampling strategies and a new evaluation framework that support swift testset iteration. Our experiments demonstrate that ANGO poses a stronger challenge to models and reveals more details in evaluation resu
    
[^35]: 对用户行为进行分析以客观评估口语对话系统

    An Analysis of User Behaviours for Objectively Evaluating Spoken Dialogue Systems. (arXiv:2401.04867v1 [cs.CL])

    [http://arxiv.org/abs/2401.04867](http://arxiv.org/abs/2401.04867)

    本文研究了用户行为与主观评估在口语对话系统中的关系，提出了一种间接但客观评估系统的框架，并发现在不同类型的对话任务中，不同的用户行为指标对评估起到重要作用。

    

    建立口语对话系统的评估方案很重要，但也具有挑战性。虽然主观评估在用户实验中常用，但客观评估对于研究比较和可复制性是必要的。为解决这个问题，我们提出了一个框架，通过用户行为间接但客观地评估系统。为此，我们调查了社交对话任务中用户行为与主观评估分数之间的关系：专注倾听、面试和首次会议对话。结果显示，在用户话语是主要因素的对话任务中，如专注倾听和面试，话语数量和单词数量等指标在评估中起到重要作用。观察语调不流畅等也可以指示正式任务的有效性，例如面试。另一方面，在高互动性的对话任务中，如首次会议对话，用户情绪和参与程度更重要。

    Establishing evaluation schemes for spoken dialogue systems is important, but it can also be challenging. While subjective evaluations are commonly used in user experiments, objective evaluations are necessary for research comparison and reproducibility. To address this issue, we propose a framework for indirectly but objectively evaluating systems based on users' behaviours. In this paper, to this end, we investigate the relationship between user behaviours and subjective evaluation scores in social dialogue tasks: attentive listening, job interview, and first-meeting conversation. The results reveal that in dialogue tasks where user utterances are primary, such as attentive listening and job interview, indicators like the number of utterances and words play a significant role in evaluation. Observing disfluency also can indicate the effectiveness of formal tasks, such as job interview. On the other hand, in dialogue tasks with high interactivity, such as first-meeting conversation, b
    
[^36]: 个性化语言提示的用户嵌入模型

    User Embedding Model for Personalized Language Prompting. (arXiv:2401.04858v1 [cs.CL])

    [http://arxiv.org/abs/2401.04858](http://arxiv.org/abs/2401.04858)

    本研究提出了一种新的用户嵌入模块，可以更有效地处理长时间的用户历史记录，并在推荐系统中取得了显著的改进。

    

    对于提升推荐系统的模型，建模长时间的历史记录起到了关键作用，能够捕捉用户不断演变的偏好，从而得到更准确和个性化的推荐。本研究致力于解决自然语言偏好理解中建模长用户历史记录的挑战。具体地，我们引入了一种新的用户嵌入模块(UEM)，通过将用户历史记录以嵌入形式压缩和表示，将其作为对语言模型的软提示。我们的实验表明，与传统的基于文本的提示方法相比，这种方法在处理显著更长的历史记录方面具有卓越的能力，并在预测性能方面取得了实质性的改进。该研究的主要贡献在于展示了使用表示为嵌入的用户信号来偏置语言模型的能力。

    Modeling long histories plays a pivotal role in enhancing recommendation systems, allowing to capture user's evolving preferences, resulting in more precise and personalized recommendations. In this study we tackle the challenges of modeling long user histories for preference understanding in natural language. Specifically, we introduce a new User Embedding Module (UEM) that efficiently processes user history in free-form text by compressing and representing them as embeddings, to use them as soft prompts to a LM. Our experiments demonstrate the superior capability of this approach in handling significantly longer histories compared to conventional text based prompting methods, yielding substantial improvements in predictive performance. The main contribution of this research is to demonstrate the ability to bias language models with user signals represented as embeddings.
    
[^37]: 基于图学习的城市空中移动机队调度在操作限制、需求变化和不确定性下的研究

    Graph Learning-based Fleet Scheduling for Urban Air Mobility under Operational Constraints, Varying Demand & Uncertainties. (arXiv:2401.04851v1 [cs.MA])

    [http://arxiv.org/abs/2401.04851](http://arxiv.org/abs/2401.04851)

    本文提出了一种基于图学习的方法，用于在线规划城市空中移动机队的时间表和目的地，考虑到操作限制、需求变化和不确定性等问题。通过构建新的策略架构和使用图胶囊转换网络、转换器层和Multi-head Attention-based解码器等组件，该方法能够解决现有机队规划实施中存在的复杂性，具有更高的现实性和逼真度。

    

    本文提出了一种基于图强化学习的方法,用于在线规划电动飞行器的时间表和目的地,该飞行器组成了一个跨多个垂直港口运营的城市空中移动（UAM）机队。这个机队调度问题的制定考虑了时间变化的需求、垂直港口容量、飞行器容量和空域安全准则的约束，以及起飞延误、天气引起的路线关闭和情况未知的飞行器停机时间的不确定性。这样的制定方式比现有的UAM机队规划实施更加复杂，可能增加了更多的现实性。为了解决这些复杂性，构建了一个新的策略架构，主要组成部分包括：作为图的抽象，用于编码垂直港口和飞行器机队状态的图胶囊转换网络；编码需求和乘客票价的时间序列信息的转换器层；以及使用编码器的Multi-head Attention-based解码器。

    This paper develops a graph reinforcement learning approach to online planning of the schedule and destinations of electric aircraft that comprise an urban air mobility (UAM) fleet operating across multiple vertiports. This fleet scheduling problem is formulated to consider time-varying demand, constraints related to vertiport capacity, aircraft capacity and airspace safety guidelines, uncertainties related to take-off delay, weather-induced route closures, and unanticipated aircraft downtime. Collectively, such a formulation presents greater complexity, and potentially increased realism, than in existing UAM fleet planning implementations. To address these complexities, a new policy architecture is constructed, primary components of which include: graph capsule conv-nets for encoding vertiport and aircraft-fleet states both abstracted as graphs; transformer layers encoding time series information on demand and passenger fare; and a Multi-head Attention-based decoder that uses the enco
    
[^38]: 深度学习表示空间交互模型以实现社区商业集群的弹性空间规划

    A Deep Learning Representation of Spatial Interaction Model for Resilient Spatial Planning of Community Business Clusters. (arXiv:2401.04849v1 [econ.EM])

    [http://arxiv.org/abs/2401.04849](http://arxiv.org/abs/2401.04849)

    本研究提出了一个SIM-GAT模型，可以捕捉商业集群与贸易区之间复杂的互动关系。我们使用连通图表示综合系统，并利用Graph AttenTion network模型进行深度学习，从而提高了传统SIM的预测和分析能力。

    

    现有的空间交互模型（SIM）在捕捉商业集群与贸易区之间复杂的、与环境相关的互动方面存在局限性。为了解决这个问题，我们提出了一个SIM-GAT模型，用于预测社区商业集群与其贸易区之间的时空访问流量。该模型创新地使用连通图表示城市地区内的商业集群、贸易区和交通基础设施的综合系统。然后，使用基于图的深度学习模型，即Graph AttenTion network (GAT)，来捕捉商业集群的复杂性和相互依赖关系。我们使用佛罗里达州迈阿密都市区收集的数据开发了这个模型。然后，我们使用可解释的AI方法证明了其在捕捉不同居民社区对商业集群的吸引力以及不同情景下的有效性。我们对预测和分析传统SIM的新方法进行了贡献。

    Existing Spatial Interaction Models (SIMs) are limited in capturing the complex and context-aware interactions between business clusters and trade areas. To address the limitation, we propose a SIM-GAT model to predict spatiotemporal visitation flows between community business clusters and their trade areas. The model innovatively represents the integrated system of business clusters, trade areas, and transportation infrastructure within an urban region using a connected graph. Then, a graph-based deep learning model, i.e., Graph AttenTion network (GAT), is used to capture the complexity and interdependencies of business clusters. We developed this model with data collected from the Miami metropolitan area in Florida. We then demonstrated its effectiveness in capturing varying attractiveness of business clusters to different residential neighborhoods and across scenarios with an eXplainable AI approach. We contribute a novel method supplementing conventional SIMs to predict and analyze
    
[^39]: 受过良好教育的智能的内在善良

    The inherent goodness of well educated intelligence. (arXiv:2401.04846v1 [econ.TH])

    [http://arxiv.org/abs/2401.04846](http://arxiv.org/abs/2401.04846)

    本文探讨了智能体变得智能的因素，强调了掌握特征和控制多个保守相互作用的子系统的能力。智能的核心是“集体如一体”和“了解局部行动的整体结果”。文章提出了一种对集体保守系统进行控制的替代方法。

    

    本文将探讨使一个智能体变得智能的因素，无论是生物体还是计算机上的人工智能。特别关注的是能够表征和控制多个保守相互作用的相同子系统的能力。智能的本质将被发现是黄金法则——“集体行动如一体”或“了解局部行动的整体结果”。集体的流动是由掌控着少量字符串的操纵者决定的，根据对称性确定的最小作用路径的测地线运动。控制集体保守系统是困难的，历史上一直通过为系统添加显著黏性来稳定期望的最大性能的亚稳平衡状态，但这会在过程中降低或破坏它们。有一种替代方案。

    This paper will examine what makes a being intelligent, whether that be a biological being or an artificial silicon being on a computer. Special attention will be paid to the being having the ability to characterize and control a collective system of many identical conservative sub-systems conservatively interacting. The essence of intelligence will be found to be the golden rule -- "the collective acts as one" or "knowing the global consequences of local actions". The flow of the collective is a small set of twinkling textures, that are governed by a puppeteer who is pulling a small number of strings according to a geodesic motion of least action, determined by the symmetries. Controlling collective conservative systems is difficult and has historically been done by adding significant viscosity to the system to stabilize the desirable meta stable equilibriums of maximum performance, but it degrades or destroys them in the process. There is an alternative. Once the optimum twinkling te
    
[^40]: MoSECroT: 使用静态词向量进行模型拼接实现跨语言零样例迁移

    MoSECroT: Model Stitching with Static Word Embeddings for Crosslingual Zero-shot Transfer. (arXiv:2401.04821v1 [cs.CL])

    [http://arxiv.org/abs/2401.04821](http://arxiv.org/abs/2401.04821)

    MoSECroT是一个结合静态词向量的模型拼接框架，用于跨语言零样例迁移。它利用相对表示构建了源语言预训练语言模型和目标语言静态词向量的共享空间，从而实现了通过简单交换嵌入从源语言训练数据中进行训练，并在目标语言上进行零样例迁移。

    

    基于Transformer的预训练语言模型（PLMs）在各种自然语言处理（NLP）任务中取得了显著的性能。然而，这种模型的预训练需要大量资源，而这些资源几乎只有高资源语言才能获得。相反，静态词向量的训练更容易，可以更节省计算资源和数据量。本文介绍了MoSECroT（Model Stitching with Static Word Embeddings for Crosslingual Zero-shot Transfer）模型拼接与静态词向量结合的新颖且具有挑战性的任务，特别适用于存在静态词向量的低资源语言。为了解决这个任务，我们提出了第一个利用相对表示构建源语言PLM嵌入和目标语言静态词向量之间的共享空间的框架。通过这种方式，我们可以使用源语言训练数据训练PLM，并通过简单地交换嵌入完成从源语言到目标语言的零样例迁移。

    Transformer-based pre-trained language models (PLMs) have achieved remarkable performance in various natural language processing (NLP) tasks. However, pre-training such models can take considerable resources that are almost only available to high-resource languages. On the contrary, static word embeddings are easier to train in terms of computing resources and the amount of data required. In this paper, we introduce MoSECroT Model Stitching with Static Word Embeddings for Crosslingual Zero-shot Transfer), a novel and challenging task that is especially relevant to low-resource languages for which static word embeddings are available. To tackle the task, we present the first framework that leverages relative representations to construct a common space for the embeddings of a source language PLM and the static word embeddings of a target language. In this way, we can train the PLM on source-language training data and perform zero-shot transfer to the target language by simply swapping th
    
[^41]: 通过HTML内容的多模型分析检测网络钓鱼网站

    Phishing Website Detection through Multi-Model Analysis of HTML Content. (arXiv:2401.04820v1 [cs.CR])

    [http://arxiv.org/abs/2401.04820](http://arxiv.org/abs/2401.04820)

    本研究提出了一种基于HTML内容的高级检测模型，集成了多层感知器和预训练的自然语言处理模型，通过新颖的融合方法检测网络钓鱼网站。同时，我们还创造了一个最新的数据集来支持这项研究。

    

    随着互联网的兴起，我们的通信和工作方式发生了巨大的变化。虽然它为我们带来了新的机会，但也增加了网络威胁。其中一种常见且严重的威胁是网络钓鱼，黑客使用欺骗性方法窃取敏感信息。本研究通过引入一种基于HTML内容的先进检测模型，针对网络钓鱼问题进行了探讨。我们提出的方法集成了用于结构化表格数据的专门的多层感知器(MLP)模型和两个预训练的自然语言处理(NLP)模型，以分析页面标题和内容等文本特征。通过一种新颖的融合过程，这些模型生成的嵌入向量被和谐地组合在一起，并输入到线性分类器中。鉴于目前缺乏全面的网络钓鱼研究数据集，我们的贡献还包括创建一个最新的数据集

    The way we communicate and work has changed significantly with the rise of the Internet. While it has opened up new opportunities, it has also brought about an increase in cyber threats. One common and serious threat is phishing, where cybercriminals employ deceptive methods to steal sensitive information.This study addresses the pressing issue of phishing by introducing an advanced detection model that meticulously focuses on HTML content. Our proposed approach integrates a specialized Multi-Layer Perceptron (MLP) model for structured tabular data and two pretrained Natural Language Processing (NLP) models for analyzing textual features such as page titles and content. The embeddings from these models are harmoniously combined through a novel fusion process. The resulting fused embeddings are then input into a linear classifier. Recognizing the scarcity of recent datasets for comprehensive phishing research, our contribution extends to the creation of an up-to-date dataset, which we o
    
[^42]: 采样与束缚用于非凸优化

    Sample-and-Bound for Non-Convex Optimization. (arXiv:2401.04812v1 [cs.AI])

    [http://arxiv.org/abs/2401.04812](http://arxiv.org/abs/2401.04812)

    本论文提出了一种基于采样的非凸优化方法，采用Monte Carlo Tree Search (MCTS)来提高效率，并利用数值上估计的不确定度指标和采样估计的一阶和二阶信息，避免固定组合模式的树生长，积极缩小到有希望的区域，同时平衡探索和开发。

    

    针对非凸函数的全局优化标准方法，如分支和束缚，维护可用于系统剪枝的分区树。树的大小随维度的增加而呈指数增长。我们提出了一种新的基于采样的非凸优化方法，它改进了蒙特卡罗树搜索(MCTS)的效率。我们不再使用标准的访问计数来作为不确定度指标，而是利用目标的数值上估计作为不确定度指标，并考虑采样估计的一阶和二阶信息。我们的方法中的蒙特卡罗树避免了通常固定组合模式的树生长，并积极地缩小到有希望的区域，同时平衡探索和开发。我们将提出的算法与竞争基线在高维非凸优化基准上进行评估，并分析超参数的影响。

    Standard approaches for global optimization of non-convex functions, such as branch-and-bound, maintain partition trees to systematically prune the domain. The tree size grows exponentially in the number of dimensions. We propose new sampling-based methods for non-convex optimization that adapts Monte Carlo Tree Search (MCTS) to improve efficiency. Instead of the standard use of visitation count in Upper Confidence Bounds, we utilize numerical overapproximations of the objective as an uncertainty metric, and also take into account of sampled estimates of first-order and second-order information. The Monte Carlo tree in our approach avoids the usual fixed combinatorial patterns in growing the tree, and aggressively zooms into the promising regions, while still balancing exploration and exploitation. We evaluate the proposed algorithms on high-dimensional non-convex optimization benchmarks against competitive baselines and analyze the effects of the hyper parameters.
    
[^43]: 语言模型基准性能有多可预测？

    How predictable is language model benchmark performance?. (arXiv:2401.04757v1 [cs.LG])

    [http://arxiv.org/abs/2401.04757](http://arxiv.org/abs/2401.04757)

    本研究通过对十一个最近的模型架构在五个数量级的计算规模上进行了大规模的语言模型性能研究，发现将许多个体任务和评估聚合在一起的平均基准性能可以合理预测，但在个别任务中的预测性能仍存在挑战。

    

    我们对十一个最近的模型架构在五个数量级的计算规模上进行了大规模的语言模型性能研究。我们发现，将许多个体任务和评估聚合在一起，就像常用的BIG-Bench数据集一样，平均基准性能在训练计算规模的函数下是可以合理预测的。具体来说，当在计算中扩大一个数量级时，我们观察到BIG-Bench Hard的平均绝对误差为6个百分点（pp）。相比之下，在计算中扩大一个数量级的个别BIG-Bench任务的外推平均误差为18pp。不过，个别任务的性能仍然比随机结果更可预测。总之，我们的研究表明，计算规模提供了一种有前景的方法来预测多样化基准中的AI能力，但在特定任务中预测性能仍然存在挑战。

    We investigate large language model performance across five orders of magnitude of compute scaling in eleven recent model architectures. We show that average benchmark performance, aggregating over many individual tasks and evaluations as in the commonly-used BIG-Bench dataset, is decently predictable as a function of training compute scale. Specifically, when extrapolating BIG-Bench Hard performance across one order of magnitude in compute, we observe average absolute errors of 6 percentage points (pp). By contrast, extrapolation for individual BIG-Bench tasks across an order of magnitude in compute yields higher average errors of 18pp. Nonetheless, individual task performance remains significantly more predictable than chance. Overall, our work suggests compute scaling provides a promising basis to forecast AI capabilities in diverse benchmarks, though predicting performance in specific tasks poses challenges.
    
[^44]: LogFormer：一种适用于日志异常检测的预训练和调优流程

    LogFormer: A Pre-train and Tuning Pipeline for Log Anomaly Detection. (arXiv:2401.04749v1 [cs.LG])

    [http://arxiv.org/abs/2401.04749](http://arxiv.org/abs/2401.04749)

    LogFormer是一种预训练和调优流程，能够提高日志异常检测在不同领域之间的泛化能力。它通过在源领域上进行预训练并利用共享参数将知识转移到目标领域，同时引入Log-Attention模块来补充被日志配对忽略的信息。

    

    日志异常检测是人工智能运维（AIOps）领域的关键组成部分。考虑到不同领域的日志数据，在实际工业场景中重新训练整个网络以适应未知领域是低效的。然而，先前的深度模型仅关注于在同一领域中提取日志序列的语义信息，导致在多领域日志上的泛化能力较差。为了解决这个问题，我们提出了一种基于Transformer的Log异常检测统一框架(LogFormer)，以改善在不同领域之间的泛化能力，并建立了包括预训练和基于adapter的调优阶段的两阶段流程。具体而言，我们的模型首先在源领域上进行预训练，以获取日志数据的共享语义知识。然后，通过共享参数将这种知识转移到目标领域。此外，我们提出了Log-Attention模块，用于补充被日志配对忽略的信息。该方法是经过实验证明的。

    Log anomaly detection is a key component in the field of artificial intelligence for IT operations (AIOps). Considering log data of variant domains, retraining the whole network for unknown domains is inefficient in real industrial scenarios. However, previous deep models merely focused on extracting the semantics of log sequences in the same domain, leading to poor generalization on multi-domain logs. To alleviate this issue, we propose a unified Transformer-based framework for Log anomaly detection (LogFormer) to improve the generalization ability across different domains, where we establish a two-stage process including the pre-training and adapter-based tuning stage. Specifically, our model is first pre-trained on the source domain to obtain shared semantic knowledge of log data. Then, we transfer such knowledge to the target domain via shared parameters. Besides, the Log-Attention module is proposed to supplement the information ignored by the log-paring. The proposed method is ev
    
[^45]: 基于卷积神经网络集成学习的无控制农场环境下的高光谱图像黑莓果实成熟度检测

    Convolutional Neural Network Ensemble Learning for Hyperspectral Imaging-based Blackberry Fruit Ripeness Detection in Uncontrolled Farm Environment. (arXiv:2401.04748v1 [cs.CV])

    [http://arxiv.org/abs/2401.04748](http://arxiv.org/abs/2401.04748)

    本文提出了一种基于卷积神经网络集成学习的方法，用于在无控制农场环境下检测黑莓果实的细微成熟特征。最近的研究已经开始使用深度学习技术来提取黑莓果实图像的特征，以判断其成熟度。本研究通过使用预训练的VGG16模型，构建了一个多输入CNN进行集成分类，以解决黑莓果实成熟度检测中的困难。

    

    多年来，果实成熟度估计模型一直依赖于光谱指数特征或基于颜色的特征，如均值、标准差、偏度、颜色矩和/或直方图。最近，一些研究开始探索使用深度学习技术从黑莓果实的图像中提取特征来判断其成熟度。然而，黑莓果实在成熟时没有明显可靠的可见性特征，因此对采摘者来说具有很大的困难。为了解决这个工程应用挑战，本文提出了一种新颖的多输入卷积神经网络（CNN）集成分类器，用于检测黑莓果实成熟度的细微特征。多输入CNN是由在ImageNet数据集上训练的预训练视觉几何组16层深度卷积网络（VGG16）模型创建的。

    Fruit ripeness estimation models have for decades depended on spectral index features or colour-based features, such as mean, standard deviation, skewness, colour moments, and/or histograms for learning traits of fruit ripeness. Recently, few studies have explored the use of deep learning techniques to extract features from images of fruits with visible ripeness cues. However, the blackberry (Rubus fruticosus) fruit does not show obvious and reliable visible traits of ripeness when mature and therefore poses great difficulty to fruit pickers. The mature blackberry, to the human eye, is black before, during, and post-ripening. To address this engineering application challenge, this paper proposes a novel multi-input convolutional neural network (CNN) ensemble classifier for detecting subtle traits of ripeness in blackberry fruits. The multi-input CNN was created from a pre-trained visual geometry group 16-layer deep convolutional network (VGG16) model trained on the ImageNet dataset. Th
    
[^46]: DiffSHEG:一种基于扩散的实时语音驱动的整体三维表情和手势生成方法

    DiffSHEG: A Diffusion-Based Approach for Real-Time Speech-driven Holistic 3D Expression and Gesture Generation. (arXiv:2401.04747v1 [cs.SD])

    [http://arxiv.org/abs/2401.04747](http://arxiv.org/abs/2401.04747)

    DiffSHEG是一种基于扩散的实时语音驱动的整体三维表情和手势生成方法，通过联合生成同步表情和手势，并引入基于扩散模型的任意长序列生成策略，实现了高质量的同步表情和手势生成。

    

    我们提出了DiffSHEG，一种基于扩散的方法，用于实时语音驱动的整体三维表情和手势生成，适用于任意长度的语音输入。与以往的研究不同，我们专注于联合生成同步表情和手势，而不是分别生成。为了解决这个问题，我们提出了基于扩散的联动生成变换器，使得从表情到手势的单向信息流更加顺畅，有利于匹配联合的表情和手势分布。此外，我们引入了一种基于扩散模型的任意长序列生成策略，提供了灵活性和计算效率。我们的方法能够实现由语音驱动的高质量同步表情和手势生成的实际解决方案。通过在两个公共数据集上进行评估，我们的方法在定量和定性方面均取得了最先进的性能。此外，用户研究证实了我们方法的有效性。

    We propose DiffSHEG, a Diffusion-based approach for Speech-driven Holistic 3D Expression and Gesture generation with arbitrary length. While previous works focused on co-speech gesture or expression generation individually, the joint generation of synchronized expressions and gestures remains barely explored. To address this, our diffusion-based co-speech motion generation transformer enables uni-directional information flow from expression to gesture, facilitating improved matching of joint expression-gesture distributions. Furthermore, we introduce an outpainting-based sampling strategy for arbitrary long sequence generation in diffusion models, offering flexibility and computational efficiency. Our method provides a practical solution that produces high-quality synchronized expression and gesture generation driven by speech. Evaluated on two public datasets, our approach achieves state-of-the-art performance both quantitatively and qualitatively. Additionally, a user study confirms 
    
[^47]: 根据内容生成风格化自由手绘草图

    Content-Conditioned Generation of Stylized Free hand Sketches. (arXiv:2401.04739v1 [cs.CV])

    [http://arxiv.org/abs/2401.04739](http://arxiv.org/abs/2401.04739)

    本文提出了一种根据内容生成风格化自由手绘草图的新方法，该方法能够准确生成具有各种风格的逼真自由手绘草图。通过在生成过程中使用先验正态分布中随机采样的风格或从已知草图中解开画家风格，该方法能够生成具有特定风格的图像，同时还能生成未知类别的图像。

    

    最近几年，自由手绘草图的识别一直是一个热门任务。然而，在一些特殊领域如军事领域，很难大规模采样自由手绘草图。常见的数据增强和图像生成技术很难产生具有各种自由手绘风格的图像。因此，相关领域中的识别和分割任务受到限制。在本文中，我们提出了一种新的对抗生成网络，可以准确地生成具有各种风格的逼真自由手绘草图。我们探索了模型的性能，包括使用从先验正态分布中随机采样的风格来生成具有各种自由手绘风格的图像，从已知的自由手绘草图中解开画家的风格，以生成具有特定风格的图像，以及生成不在训练集中的未知类别的图像。我们进一步通过定性和定量评估证明我们的优势。

    In recent years, the recognition of free-hand sketches has remained a popular task. However, in some special fields such as the military field, free-hand sketches are difficult to sample on a large scale. Common data augmentation and image generation techniques are difficult to produce images with various free-hand sketching styles. Therefore, the recognition and segmentation tasks in related fields are limited. In this paper, we propose a novel adversarial generative network that can accurately generate realistic free-hand sketches with various styles. We explore the performance of the model, including using styles randomly sampled from a prior normal distribution to generate images with various free-hand sketching styles, disentangling the painters' styles from known free-hand sketches to generate images with specific styles, and generating images of unknown classes that are not in the training set. We further demonstrate with qualitative and quantitative evaluations our advantages i
    
[^48]: 音乐类型分类：使用梅尔频率倒谱系数和梅尔频谱图的CNN和XGBoost方法的比较分析

    Music Genre Classification: A Comparative Analysis of CNN and XGBoost Approaches with Mel-frequency cepstral coefficients and Mel Spectrograms. (arXiv:2401.04737v1 [cs.SD])

    [http://arxiv.org/abs/2401.04737](http://arxiv.org/abs/2401.04737)

    本研究比较了使用CNN、VGG16和XGBoost模型以及不同特征的音乐类型分类性能。结果表明，CNN在处理30秒的梅尔频谱图时表现最好，XGBoost在处理3秒的梅尔频率倒谱系数时表现最好。

    

    最近几年，各种精心设计的算法使得音乐平台能够根据用户的喜好提供内容。音乐类型通过包括声学特征和文化考虑在内的各个方面来定义。音乐类型分类在基于内容的过滤中非常有效，它基于音乐的相似性向用户推荐内容。在给定大规模数据集的情况下，一种假设是使用机器学习或深度学习方法进行自动注释，能够有效分类音频文件。系统的有效性在很大程度上取决于特征和模型的选择，因为不同的体系结构和特征可以相互促进并产生不同的结果。在本研究中，我们进行了一项比较研究，研究了三个模型的性能：提出的卷积神经网络（CNN），带有全连接层（FC）的VGG16模型和极限梯度提升（XGBoost）方法在不同特征上的表现：30秒的梅尔频谱图和3秒的梅尔频率倒谱系数。

    In recent years, various well-designed algorithms have empowered music platforms to provide content based on one's preferences. Music genres are defined through various aspects, including acoustic features and cultural considerations. Music genre classification works well with content-based filtering, which recommends content based on music similarity to users. Given a considerable dataset, one premise is automatic annotation using machine learning or deep learning methods that can effectively classify audio files. The effectiveness of systems largely depends on feature and model selection, as different architectures and features can facilitate each other and yield different results. In this study, we conduct a comparative study investigating the performances of three models: a proposed convolutional neural network (CNN), the VGG16 with fully connected layers (FC), and an eXtreme Gradient Boosting (XGBoost) approach on different features: 30-second Mel spectrogram and 3-second Mel-freq
    
[^49]: 对使用模型预测控制的分布式车队控制器的攻击韧性的研究

    Exploring Attack Resilience in Distributed Platoon Controllers with Model Predictive Control. (arXiv:2401.04736v1 [eess.SY])

    [http://arxiv.org/abs/2401.04736](http://arxiv.org/abs/2401.04736)

    这项研究通过模拟各种攻击技术，分析了分布式车队控制器的漏洞，提出了加强通信协议和使用机器学习技术进行恶意攻击检测的对策。

    

    分布式车队控制器的广泛应用为交通系统带来了诸多好处，如增加了交通流量、燃油效率提高以及减少了污染。然而，与此同时，对互连系统和通信网络的日益依赖也使得这些控制器面临潜在的网络攻击，这可能危及其安全性和功能性。该论文旨在通过研究攻击场景并评估其对系统性能的影响，提高分布式车队控制器的安全性。使用模型预测控制器模拟了包括中间人攻击和假数据注入在内的各种攻击技术，以识别车队控制器的漏洞和弱点。提供并测试了包括攻击分析和使用机器学习技术进行检测的，加强了通信协议的应对措施。研究结果强调了集成安全性设计和恶意攻击检测的重要性。

    The extensive use of distributed vehicle platoon controllers has resulted in several benefits for transportation systems, such as increased traffic flow, fuel efficiency, and decreased pollution. The rising reliance on interconnected systems and communication networks, on the other hand, exposes these controllers to potential cyber-attacks, which may compromise their safety and functionality. This thesis aims to improve the security of distributed vehicle platoon controllers by investigating attack scenarios and assessing their influence on system performance. Various attack techniques, including man-in-the-middle (MITM) and false data injection (FDI), are simulated using Model Predictive Control (MPC) controller to identify vulnerabilities and weaknesses of the platoon controller. Countermeasures are offered and tested, that includes attack analysis and reinforced communication protocols using Machine Learning techniques for detection. The findings emphasize the significance of integr
    
[^50]: MSX销售协同助手中生成式人工智能的案例研究: 通过实时问答系统改善销售人员的工作效率以实现内容推荐

    A case study of Generative AI in MSX Sales Copilot: Improving seller productivity with a real-time question-answering system for content recommendation. (arXiv:2401.04732v1 [cs.IR])

    [http://arxiv.org/abs/2401.04732](http://arxiv.org/abs/2401.04732)

    本论文设计了一个实时问答系统，通过LLM嵌入与销售材料进行匹配，提供给销售人员实时推荐，从而提高销售人员的工作效率。这一解决方案可以在几秒钟内返回最相关的内容推荐，即使对于大规模数据集也是如此。这一推荐系统已成功集成到微软销售人员每日使用的Dynamics CRM的生产版本中。

    

    本文设计了一个实时问答系统，专门为销售人员提供有关材料/文档的实时推荐，以便与客户分享或在电话中参考。通过使用Seismic销售资料的相对较大规模的多样化数据集，我们展示了如何使用卖方查询的LLM嵌入与相关内容相匹配。我们通过以详细的方式设计提示语，并利用可用的丰富的文档和销售者元特征集，实现了这一目标。通过使用具有交叉编码器重排序器架构的双编码器，我们展示了该解决方案在仅几秒钟内即可返回最相关的内容推荐，即使对于大规模数据集也是如此。我们的推荐系统已部署为用于实时推理的AML端点，并已集成到Copilot界面中，该界面现已部署在每日由微软销售人员使用的Dynamics CRM的生产版本中(MSX）。

    In this paper, we design a real-time question-answering system specifically targeted for helping sellers get relevant material/documentation they can share live with their customers or refer to during a call. Taking the Seismic content repository as a relatively large scale example of a diverse dataset of sales material, we demonstrate how LLM embeddings of sellers' queries can be matched with the relevant content. We achieve this by engineering prompts in an elaborate fashion that makes use of the rich set of meta-features available for documents and sellers. Using a bi-encoder with cross-encoder re-ranker architecture, we show how the solution returns the most relevant content recommendations in just a few seconds even for large datasets. Our recommender system is deployed as an AML endpoint for real-time inferencing and has been integrated into a Copilot interface that is now deployed in the production version of the Dynamics CRM, known as MSX, used daily by Microsoft sellers.
    
[^51]: RoSA: 通过鲁棒适应实现准确的参数高效微调

    RoSA: Accurate Parameter-Efficient Fine-Tuning via Robust Adaptation. (arXiv:2401.04679v1 [cs.CL])

    [http://arxiv.org/abs/2401.04679](http://arxiv.org/abs/2401.04679)

    RoSA是一种新的PEFT方法，通过在预训练权重上训练低秩和高度稀疏的组件，以高效近似完全微调的性能，来实现准确的参数高效微调。在多个生成任务中，RoSA表现出优于其他方法的性能。

    

    我们研究了在大语言模型 (LLMs) 的背景下，能够在有限的计算和内存预算下提供良好准确性的参数高效微调 (PEFT) 方法。我们提出了一种新的PEFT方法，称为RoSA，受鲁棒主成分分析 (PCA) 的启发，它在一组固定的预训练权重上共同训练$\textit{低秩}$和$\textit{高度稀疏}$的组件，以高效近似完全微调（FFT）解决方案的性能。我们展示了RoSA在一系列具有挑战性的生成任务上的性能，例如小学数学和SQL查询生成，这些任务需要进行微调以获得良好性能，我们证明了在相同的参数预算下，RoSA优于LoRA和纯粹的稀疏微调。我们通过稀疏GPU内核为RoSA提供系统支持，以补充训练算法，从而实现内存和计算效率的训练。我们的代码将在https://github.com/IST-DASLab上提供。

    We investigate parameter-efficient fine-tuning (PEFT) methods that can provide good accuracy under limited computational and memory budgets in the context of large language models (LLMs). We present a new PEFT method called Robust Adaptation (RoSA) inspired by robust principal component analysis (PCA) that jointly trains $\textit{low-rank}$ and $\textit{highly-sparse}$ components on top of a set of fixed pretrained weights to efficiently approximate the performance of a full-fine-tuning (FFT) solution. Across a series of challenging generative tasks such as grade-school math and SQL query generation, which require fine-tuning for good performance, we show that RoSA outperforms both LoRA and pure sparse fine-tuning, at the same parameter budget. We provide system support for RoSA to complement the training algorithm, specifically in the form of sparse GPU kernels which enable memoryand computationally-efficient training. Our code will be made available at https://github.com/IST-DASLab
    
[^52]: 在不断演化的社会规范中的Agent对齐

    Agent Alignment in Evolving Social Norms. (arXiv:2401.04620v1 [cs.CL])

    [http://arxiv.org/abs/2401.04620](http://arxiv.org/abs/2401.04620)

    本论文提出了一个名为EvolutionaryAgent的进化框架，将Agent对齐转化为适者生存的演化和选择过程，在不断演化的社会规范中，与当前社会规范更好适应的Agent将具有更高的生存和传播概率。

    

    基于大型语言模型（LLM）的Agent越来越多地渗透到人类生产和生活的各个领域，凸显了将其与人类价值观对齐的重要性。目前AI系统的对齐主要集中在通过人为干预对LLM进行被动对齐。然而，Agent具有接受环境反馈和自我进化等特性，使得LLM对齐方法变得不足够。为此，我们提出了一个名为EvolutionaryAgent的Agent进化和对齐的进化框架，将Agent对齐转化为适者生存的演化和选择过程。在社会规范不断演化的环境中，与当前社会规范更好适应的Agent将具有更高的生存和传播概率，而对齐不足的Agent则逐渐减少。通过多个角度对与社会规范相对齐的Agent进行的实验结果进行评估。

    Agents based on Large Language Models (LLMs) are increasingly permeating various domains of human production and life, highlighting the importance of aligning them with human values. The current alignment of AI systems primarily focuses on passively aligning LLMs through human intervention. However, agents possess characteristics like receiving environmental feedback and self-evolution, rendering the LLM alignment methods inadequate. In response, we propose an evolutionary framework for agent evolution and alignment, named EvolutionaryAgent, which transforms agent alignment into a process of evolution and selection under the principle of survival of the fittest. In an environment where social norms continuously evolve, agents better adapted to the current social norms will have a higher probability of survival and proliferation, while those inadequately aligned dwindle over time. Experimental results assessing the agents from multiple perspectives in aligning with social norms demonstr
    
[^53]: 深度高效的私密领域生成用于子图联邦学习

    Deep Efficient Private Neighbor Generation for Subgraph Federated Learning. (arXiv:2401.04336v1 [cs.LG])

    [http://arxiv.org/abs/2401.04336](http://arxiv.org/abs/2401.04336)

    本文提出了FedDEP，用于解决子图联邦学习中的信息传播不完整的问题，并提出了一系列新颖的技术设计，包括深度邻居生成和高效的私密领域生成。

    

    在现实应用中，巨大图通常以非中心化子图的形式由多个数据所有者分散存储。为了保护数据隐私，在不损害数据隐私的前提下，考虑到子图联邦学习（subgraph FL）场景是很自然的，其中每个本地客户端持有整个全局图的子图，以获取全局一般化的图挖掘模型。为了解决由于缺少跨子图邻居而导致的局部子图上的信息传播不完整的独特挑战，以前的工作通过缺失邻居生成器和GNN的联合FL来增加本地邻域。然而，它们在FL的效用性、效率性和隐私目标方面存在深层次的限制。在这项工作中，我们提出了FedDEP来全面解决子图FL中的这些挑战。FedDEP包括一系列新颖的技术设计：(1) 利用潜在缺失邻居的GNN嵌入进行深度邻居生成；(2) Effic...

    Behemoth graphs are often fragmented and separately stored by multiple data owners as distributed subgraphs in many realistic applications. Without harming data privacy, it is natural to consider the subgraph federated learning (subgraph FL) scenario, where each local client holds a subgraph of the entire global graph, to obtain globally generalized graph mining models. To overcome the unique challenge of incomplete information propagation on local subgraphs due to missing cross-subgraph neighbors, previous works resort to the augmentation of local neighborhoods through the joint FL of missing neighbor generators and GNNs. Yet their technical designs have profound limitations regarding the utility, efficiency, and privacy goals of FL. In this work, we propose FedDEP to comprehensively tackle these challenges in subgraph FL. FedDEP consists of a series of novel technical designs: (1) Deep neighbor generation through leveraging the GNN embeddings of potential missing neighbors; (2) Effic
    
[^54]: 无监督的测试时自适应：通过插入和播放变换器模块

    Unsupervised Test-Time Adaptation via Plug-and-Play Transformer Modules. (arXiv:2401.04130v1 [cs.LG])

    [http://arxiv.org/abs/2401.04130](http://arxiv.org/abs/2401.04130)

    这项工作介绍了PLUTO:一种插拔式模块化的测试时领域适应策略，通过预先训练一系列针对不同源领域的模块，有效地创建了一个"模块存储库"。采用无监督的测试时自适应方法，从存储库中选择稀疏的相关模块的子集，并创建选中模块的加权组合，实现了对新领域的自适应。

    

    参数高效调优(PET)方法，如LoRA、Adapter和Visual Prompt Tuning(VPT)，通过调整变换器模型中的小模块，在使适应新领域方面取得了成功。然而，在测试过程中遇到的领域数量可能非常大，数据通常是无标签的。因此，适应新领域是具有挑战性的，也不现实为每个这样的领域生成定制的调整模块。为了应对这些挑战，本文引入了PLUTO：一种插拔模块化的测试时领域适应策略。我们预训练了一系列模块，每个模块专为不同的源领域进行了专门设计，有效地创建了一个"模块存储库"。给定一个带有少样本无标签数据的目标域，我们引入了一种无监督的测试时自适应(TTA)方法，来(1)从库中选择出稀疏的相关模块的子集，并且(2)在不调整权重的情况下创建选中模块的加权组合。这种插拔式的特性使得它可===

    Parameter-efficient tuning (PET) methods such as LoRA, Adapter, and Visual Prompt Tuning (VPT) have found success in enabling adaptation to new domains by tuning small modules within a transformer model. However, the number of domains encountered during test time can be very large, and the data is usually unlabeled. Thus, adaptation to new domains is challenging; it is also impractical to generate customized tuned modules for each such domain. Toward addressing these challenges, this work introduces PLUTO: a Plug-and-pLay modUlar Test-time domain adaptatiOn strategy. We pre-train a large set of modules, each specialized for different source domains, effectively creating a ``module store''. Given a target domain with few-shot unlabeled data, we introduce an unsupervised test-time adaptation (TTA) method to (1) select a sparse subset of relevant modules from this store and (2) create a weighted combination of selected modules without tuning their weights. This plug-and-play nature enable
    
[^55]: 提升大型语言模型中的空间推理能力：通过StepGame基准的深入评估和增强

    Advancing Spatial Reasoning in Large Language Models: An In-Depth Evaluation and Enhancement Using the StepGame Benchmark. (arXiv:2401.03991v1 [cs.AI] CROSS LISTED)

    [http://arxiv.org/abs/2401.03991](http://arxiv.org/abs/2401.03991)

    本研究通过改进StepGame基准，提供了更准确的数据集用于评估语言模型在空间推理方面的能力。研究发现，当前的大型语言模型在将自然语言文本映射到空间关系方面表现优秀，但在多跳推理方面存在限制。

    

    人工智能在各个领域取得了显著进展，例如ChatGPT等大型语言模型因其类似人类的文本生成能力而受到了广泛关注。然而，这些模型在空间推理方面仍然存在一定挑战。StepGame等基准评估了人工智能的空间推理能力，ChatGPT在其中表现出了不尽人意的性能。然而，基准中存在的模板错误对评估结果有影响。因此，如果解决了这些模板错误，ChatGPT有潜力表现更好，从而获得对其空间推理能力更准确的评估。在本研究中，我们完善了StepGame基准，提供了更准确的数据集用于模型评估。我们分析了GPT在经过修正的基准上的空间推理性能，在将自然语言文本映射到空间关系方面表现优秀，但在多跳推理方面存在限制。我们提供了一个无缺陷的解决方案

    Artificial intelligence (AI) has made remarkable progress across various domains, with large language models like ChatGPT gaining substantial attention for their human-like text-generation capabilities. Despite these achievements, spatial reasoning remains a significant challenge for these models. Benchmarks like StepGame evaluate AI spatial reasoning, where ChatGPT has shown unsatisfactory performance. However, the presence of template errors in the benchmark has an impact on the evaluation results. Thus there is potential for ChatGPT to perform better if these template errors are addressed, leading to more accurate assessments of its spatial reasoning capabilities. In this study, we refine the StepGame benchmark, providing a more accurate dataset for model evaluation. We analyze GPT's spatial reasoning performance on the rectified benchmark, identifying proficiency in mapping natural language text to spatial relations but limitations in multi-hop reasoning. We provide a flawless solu
    
[^56]: 上下文固定预算的最佳臂识别：适应性实验设计与策略学习

    Contextual Fixed-Budget Best Arm Identification: Adaptive Experimental Design with Policy Learning. (arXiv:2401.03756v1 [cs.LG])

    [http://arxiv.org/abs/2401.03756](http://arxiv.org/abs/2401.03756)

    该论文研究了个性化治疗推荐的问题，提出了一个上下文固定预算的最佳臂识别模型，通过自适应实验设计和策略学习来推荐最佳治疗方案，并通过最坏情况下的期望简单遗憾来衡量推荐的有效性。

    

    个性化治疗推荐是基于证据的决策中的关键任务。在这项研究中，我们将这个任务作为一个带有上下文信息的固定预算最佳臂识别（Best Arm Identification, BAI）问题来进行建模。在这个设置中，我们考虑了一个给定多个治疗臂的自适应试验。在每一轮中，决策者观察一个刻画实验单位的上下文（协变量），并将该单位分配给其中一个治疗臂。在实验结束时，决策者推荐一个在给定上下文条件下预计产生最高期望结果的治疗臂（最佳治疗臂）。该决策的有效性通过最坏情况下的期望简单遗憾（策略遗憾）来衡量，该遗憾表示在给定上下文条件下，最佳治疗臂和推荐治疗臂的条件期望结果之间的最大差异。我们的初始步骤是推导最坏情况下期望简单遗憾的渐近下界，该下界还暗示着解决该问题的一些思路。

    Individualized treatment recommendation is a crucial task in evidence-based decision-making. In this study, we formulate this task as a fixed-budget best arm identification (BAI) problem with contextual information. In this setting, we consider an adaptive experiment given multiple treatment arms. At each round, a decision-maker observes a context (covariate) that characterizes an experimental unit and assigns the unit to one of the treatment arms. At the end of the experiment, the decision-maker recommends a treatment arm estimated to yield the highest expected outcome conditioned on a context (best treatment arm). The effectiveness of this decision is measured in terms of the worst-case expected simple regret (policy regret), which represents the largest difference between the conditional expected outcomes of the best and recommended treatment arms given a context. Our initial step is to derive asymptotic lower bounds for the worst-case expected simple regret, which also implies idea
    
[^57]: 预测天空：一种用于航班层次的乘客流量预测的新模型

    Predicting the Skies: A Novel Model for Flight-Level Passenger Traffic Forecasting. (arXiv:2401.03397v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2401.03397](http://arxiv.org/abs/2401.03397)

    本研究提出了一种新颖的多模态深度学习方法用于预测航班层次的乘客流量，相比传统模型取得了显著的准确性提升。该模型有效整合了循环神经网络和卷积神经网络，利用数据内部的时间模式和空间关系来增强预测性能。

    

    准确预测航班层次的乘客流量在航空公司运营中至关重要，影响从定价到路线优化等关键决策。本研究引入了一种新颖的多模态深度学习方法来解决航班层次乘客流量预测的挑战，相比传统模型，取得了显著的准确性提升。利用美国航空公司的大量数据集，我们的模型吸收了历史流量数据、票价关闭信息和每个航班特定的季节性属性。我们提出的神经网络将循环神经网络（RNN）和卷积神经网络（CNN）的优势进行了整合，利用数据内部的时间模式和空间关系来增强预测性能。我们成功的一个关键因素是全面的数据处理策略。我们构建了3D张量来表示数据，应用了精细的掩蔽策略来模拟真实世界的动态，并采用数据增强方法。

    Accurate prediction of flight-level passenger traffic is of paramount importance in airline operations, influencing key decisions from pricing to route optimization. This study introduces a novel, multimodal deep learning approach to the challenge of predicting flight-level passenger traffic, yielding substantial accuracy improvements compared to traditional models. Leveraging an extensive dataset from American Airlines, our model ingests historical traffic data, fare closure information, and seasonality attributes specific to each flight. Our proposed neural network integrates the strengths of Recurrent Neural Networks (RNN) and Convolutional Neural Networks (CNN), exploiting the temporal patterns and spatial relationships within the data to enhance prediction performance. Crucial to the success of our model is a comprehensive data processing strategy. We construct 3D tensors to represent data, apply careful masking strategies to mirror real-world dynamics, and employ data augmentatio
    
[^58]: 对神经符号人工智能的验证和验证、测试和评估的调查

    A Survey on Verification and Validation, Testing and Evaluations of Neurosymbolic Artificial Intelligence. (arXiv:2401.03188v1 [cs.AI])

    [http://arxiv.org/abs/2401.03188](http://arxiv.org/abs/2401.03188)

    神经符号人工智能的验证和验证、测试和评估是一项具有挑战性的任务，因为亚符号人工智能的黑盒特性使得预测难以解释。本调查研究了神经符号人工智能如何简化V&V过程，并提供了关于当前应用的算法和技术的概述。

    

    神经符号人工智能是一种新兴的人工智能分支，将符号人工智能和亚符号人工智能的优势相结合。亚符号人工智能的一个主要缺点是它表现为“黑盒”，意味着预测很难解释，使得使用亚符号人工智能系统的测试和评估（T&E）以及验证和验证（V&V）过程成为一项挑战。由于神经符号人工智能结合了符号和亚符号人工智能的优点，本调查探讨了神经符号应用如何简化V&V过程。本调查考虑了两种神经符号人工智能的分类法，并评估了它们，并分析了当前应用中作为符号和亚符号组成部分的常用算法。此外，还提供了关于这些组件的T&E和V&V过程的当前技术概述。此外，还调查了符号部分在当前神经符号应用中如何用于T&E和V&V目的。我们的研究表明

    Neurosymbolic artificial intelligence (AI) is an emerging branch of AI that combines the strengths of symbolic AI and sub-symbolic AI. A major drawback of sub-symbolic AI is that it acts as a "black box", meaning that predictions are difficult to explain, making the testing & evaluation (T&E) and validation & verification (V&V) processes of a system that uses sub-symbolic AI a challenge. Since neurosymbolic AI combines the advantages of both symbolic and sub-symbolic AI, this survey explores how neurosymbolic applications can ease the V&V process. This survey considers two taxonomies of neurosymbolic AI, evaluates them, and analyzes which algorithms are commonly used as the symbolic and sub-symbolic components in current applications. Additionally, an overview of current techniques for the T&E and V&V processes of these components is provided. Furthermore, it is investigated how the symbolic part is used for T&E and V&V purposes in current neurosymbolic applications. Our research shows
    
[^59]: 人作为AI导师：增强人机协作强化学习以实现安全高效的自动驾驶

    Human as AI Mentor: Enhanced Human-in-the-loop Reinforcement Learning for Safe and Efficient Autonomous Driving. (arXiv:2401.03160v1 [cs.LG])

    [http://arxiv.org/abs/2401.03160](http://arxiv.org/abs/2401.03160)

    本文提出了一种增强的人机协作强化学习方法，通过将人类智能注入到AI中实现混合交通编队中的安全高效自动驾驶。该方法将人类专家作为导师，允许代理在不确定环境中进行探索，同时在危险情况下接管控制以避免事故，并指导代理减小交通流干扰，优化交通流效果。

    

    尽管自动驾驶车辆（AVs）取得了重大进展，但确保AVs的安全性和交通流效率的驾驶策略的发展尚未得到充分探索。在本文中，我们提出了一种增强的人机协作强化学习方法，称为基于人作为AI导师的深度强化学习（HAIM-DRL）框架，以在混合交通编队中实现安全高效的自动驾驶。从人类学习过程中汲取灵感，我们首先引入了一种创新的学习范式，有效地将人类智能注入到AI中，称为人作为AI导师（HAIM）。在这个范式中，人类专家作为导师为AI代理提供帮助。在允许代理在不确定环境中进行充分探索的同时，人类专家可以在危险情况下接管控制，并展示正确的行动以避免潜在事故。另一方面，可以指导代理减小交通流干扰，从而优化交通流效果。

    Despite significant progress in autonomous vehicles (AVs), the development of driving policies that ensure both the safety of AVs and traffic flow efficiency has not yet been fully explored. In this paper, we propose an enhanced human-in-the-loop reinforcement learning method, termed the Human as AI mentor-based deep reinforcement learning (HAIM-DRL) framework, which facilitates safe and efficient autonomous driving in mixed traffic platoon. Drawing inspiration from the human learning process, we first introduce an innovative learning paradigm that effectively injects human intelligence into AI, termed Human as AI mentor (HAIM). In this paradigm, the human expert serves as a mentor to the AI agent. While allowing the agent to sufficiently explore uncertain environments, the human expert can take control in dangerous situations and demonstrate correct actions to avoid potential accidents. On the other hand, the agent could be guided to minimize traffic flow disturbance, thereby optimizi
    
[^60]: 分散式多智能体主动搜索和跟踪当目标超过智能体数量时

    Decentralized Multi-Agent Active Search and Tracking when Targets Outnumber Agents. (arXiv:2401.03154v1 [cs.RO])

    [http://arxiv.org/abs/2401.03154](http://arxiv.org/abs/2401.03154)

    该论文介绍了一种处理多目标跟踪的分散式多智能体算法，该算法能在智能体数量少于目标数量时实现主动搜索和跟踪，并使用异步智能体通信来协调动作。

    

    多智能体多目标跟踪在野生动物巡逻、安全监控或环境监测等领域有广泛应用。现有算法常常做出一些限制性假设：目标数量和初始位置已知，或者智能体已被预分配到监控环境的不重叠分区，减轻了探索的负担。然而，当智能体数量少于目标数量时，这种假设会限制算法的适用性，因为智能体无法持续跟踪其视野中的目标。此外，多智能体跟踪算法还假设智能体间观测的同步，或者需要一个中央控制器来协调联合动作。相反，我们关注于分散式多智能体、多目标、同时主动搜索和跟踪的设置，其中智能体间通信是异步的。我们提出的算法DecSTER使用了一种基于概率假设密度滤波器的顺序蒙特卡洛实现。

    Multi-agent multi-target tracking has a wide range of applications, including wildlife patrolling, security surveillance or environment monitoring. Such algorithms often make restrictive assumptions: the number of targets and/or their initial locations may be assumed known, or agents may be pre-assigned to monitor disjoint partitions of the environment, reducing the burden of exploration. This also limits applicability when there are fewer agents than targets, since agents are unable to continuously follow the targets in their fields of view. Multi-agent tracking algorithms additionally assume inter-agent synchronization of observations, or the presence of a central controller to coordinate joint actions. Instead, we focus on the setting of decentralized multi-agent, multi-target, simultaneous active search-and-tracking with asynchronous inter-agent communication. Our proposed algorithm DecSTER uses a sequential monte carlo implementation of the probability hypothesis density filter fo
    
[^61]: 你的预训练模型有改进吗？一种基于多头后验的方法

    Has Your Pretrained Model Improved? A Multi-head Posterior Based Approach. (arXiv:2401.02987v1 [cs.CL])

    [http://arxiv.org/abs/2401.02987](http://arxiv.org/abs/2401.02987)

    本研究提出一种基于多头后验的方法，通过利用实体的元特征和模型的表示之间的一致性作为度量标准，有效评估预训练模型在各个领域的表现。

    

    预训练模型的出现对自然语言处理（NLP）、计算机视觉和关系型数据集等领域产生了显著影响。传统上，这些模型通过下游任务进行评估。然而，这引发了如何更高效、更有效地评估这些模型的问题。在本研究中，我们探索了一种新颖的方法，即利用与每个实体相关的元特征作为世界知识的来源，并利用模型的实体表示。我们提出使用这些表示和元特征之间的一致性作为评估预训练模型的度量标准。我们的方法在各个领域表现出了有效性，包括具有关系型数据集、大型语言模型和图像模型的模型。

    The emergence of pretrained models has significantly impacted from Natural Language Processing (NLP) and Computer Vision to relational datasets. Traditionally, these models are assessed through fine-tuned downstream tasks. However, this raises the question of how to evaluate these models more efficiently and more effectively. In this study, we explore a novel approach where we leverage the meta features associated with each entity as a source of worldly knowledge and employ entity representations from the models. We propose using the consistency between these representations and the meta features as a metric for evaluating pretrained models. Our method's effectiveness is demonstrated across various domains, including models with relational datasets, large language models and images models.
    
[^62]: XUAT-Copilot: 多智能体协作系统用于使用大型语言模型进行自动用户验收测试

    XUAT-Copilot: Multi-Agent Collaborative System for Automated User Acceptance Testing with Large Language Model. (arXiv:2401.02705v1 [cs.AI])

    [http://arxiv.org/abs/2401.02705](http://arxiv.org/abs/2401.02705)

    XUAT-Copilot是一个使用大型语言模型的多智能体协作系统，旨在提高自动用户验收测试的自动化水平和测试脚本生成阶段的效率。

    

    过去几年，我们致力于自动化微信支付的用户验收测试（UAT）过程，这是中国最具影响力的移动支付应用之一。我们开发了一个名为XUAT的系统用于这个目的。然而，在当前系统中仍然存在一个人力密集阶段，即测试脚本的生成。因此，在本文中，我们集中研究提高当前系统自动化水平的方法，特别是测试脚本生成阶段。近年来，大型语言模型（LLMs）取得了显著的成功，展示了获取人类智能的潜力，并且已经形成了一个不断增长的研究领域，使用LLMs作为自主智能体来获得类似人类的决策能力。受到这些工作的启发，我们提出了一个基于LLM的多智能体协作系统，名为XUAT-Copilot，用于自动UAT。该系统主要由三个以LLM为基础的智能体组成，负责动作规划、状态检测和...

    In past years, we have been dedicated to automating user acceptance testing (UAT) process of WeChat Pay, one of the most influential mobile payment applications in China. A system titled XUAT has been developed for this purpose. However, there is still a human-labor-intensive stage, i.e, test scripts generation, in the current system. Therefore, in this paper, we concentrate on methods of boosting the automation level of the current system, particularly the stage of test scripts generation. With recent notable successes, large language models (LLMs) demonstrate significant potential in attaining human-like intelligence and there has been a growing research area that employs LLMs as autonomous agents to obtain human-like decision-making capabilities. Inspired by these works, we propose an LLM-powered multi-agent collaborative system, named XUAT-Copilot, for automated UAT. The proposed system mainly consists of three LLM-based agents responsible for action planning, state checking and pa
    
[^63]: IdentiFace：基于VGG的多模态人脸生物特征系统

    IdentiFace : A VGG Based Multimodal Facial Biometric System. (arXiv:2401.01227v1 [cs.CV])

    [http://arxiv.org/abs/2401.01227](http://arxiv.org/abs/2401.01227)

    本文介绍了一种基于VGG的多模态人脸生物特征系统"IdentiFace"，通过将人脸识别与性别、脸型和情感等软生物特征相结合，实现了高效、有意义的结合。通过使用统一的架构和对学到的特征进行解释，该系统在高内类别变异下取得了99.2%的测试精确度。

    

    人脸生物特征系统的发展为计算机视觉领域的发展做出了巨大贡献。现今，需要开发一种多模态系统，以高效、有意义的方式结合多种生物特征。本文介绍了“IdentiFace”，这是一种多模态人脸生物特征系统，将人脸识别的核心与性别、脸型和情感等一些重要的软生物特征相结合。我们还着重使用只有VGG-16受到启发的架构，在不同子系统中进行了一些细微的更改。这种统一性使得跨模态的集成更加简单。它更容易解释不同任务之间学到的特征，从而对于决策过程和人脸模态之间的潜在关系给出了很好的指示。对于识别问题，我们使用收集的数据，在五个类别的高内类别变异下获得了99.2%的测试精确度。

    The development of facial biometric systems has contributed greatly to the development of the computer vision field. Nowadays, there's always a need to develop a multimodal system that combines multiple biometric traits in an efficient, meaningful way. In this paper, we introduce "IdentiFace" which is a multimodal facial biometric system that combines the core of facial recognition with some of the most important soft biometric traits such as gender, face shape, and emotion. We also focused on developing the system using only VGG-16 inspired architecture with minor changes across different subsystems. This unification allows for simpler integration across modalities. It makes it easier to interpret the learned features between the tasks which gives a good indication about the decision-making process across the facial modalities and potential connection. For the recognition problem, we acquired a 99.2% test accuracy for five classes with high intra-class variations using data collected 
    
[^64]: 准确的变形DETR和多级特征融合用于辅助血液疾病诊断的白细胞检测

    Accurate Leukocyte Detection Based on Deformable-DETR and Multi-Level Feature Fusion for Aiding Diagnosis of Blood Diseases. (arXiv:2401.00926v1 [cs.CV])

    [http://arxiv.org/abs/2401.00926](http://arxiv.org/abs/2401.00926)

    本文提出了一种创新的白细胞检测方法，使用多级特征融合和变形自注意DETR，通过解决白细胞尺度差异问题和提高检测精度，以改善传统血液检测的效率和准确性。

    

    在标准医院血液检测中，传统的方法需要医生使用显微镜从患者的血液显微图像中手动分离白细胞。然后通过自动白细胞分类器对这些分离的白细胞进行分类，以确定血样中不同类型白细胞的比例和体积，从而协助疾病诊断。这种方法不仅耗时、耗力，而且容易出现错误，因为图像质量和环境条件等因素，可能导致后续分类错误和误诊。为了解决这些问题，本文提出了一种创新的白细胞检测方法：多级特征融合和变形自注意DETR（MFDS-DETR）。为了解决白细胞尺度差异的问题，我们设计了高级筛选特征融合金字塔（HS-FPN），实现了多级融合。该模型使用高级特征作为特征融合的输入，同时采用变形自注意DETR实现精确的白细胞检测。

    In standard hospital blood tests, the traditional process requires doctors to manually isolate leukocytes from microscopic images of patients' blood using microscopes. These isolated leukocytes are then categorized via automatic leukocyte classifiers to determine the proportion and volume of different types of leukocytes present in the blood samples, aiding disease diagnosis. This methodology is not only time-consuming and labor-intensive, but it also has a high propensity for errors due to factors such as image quality and environmental conditions, which could potentially lead to incorrect subsequent classifications and misdiagnosis. To address these issues, this paper proposes an innovative method of leukocyte detection: the Multi-level Feature Fusion and Deformable Self-attention DETR (MFDS-DETR). To tackle the issue of leukocyte scale disparity, we designed the High-level Screening-feature Fusion Pyramid (HS-FPN), enabling multi-level fusion. This model uses high-level features as 
    
[^65]: 连接医疗设备的多变量时间序列的聚类模型的比较研究

    Comparative study of clustering models for multivariate time series from connected medical devices. (arXiv:2312.17286v2 [cs.LG] CROSS LISTED)

    [http://arxiv.org/abs/2312.17286](http://arxiv.org/abs/2312.17286)

    这项研究比较了两种针对多变量时间序列的聚类模型，通过预测未来值并形成聚类空间来创建患者资料，其中一种模型可以处理动态群组归属。

    

    在医疗保健领域，患者数据通常以多变量时间序列的形式收集，可以全面地反映患者随时间变化的健康状况。虽然这些数据可能是稀疏的，但连接的设备可以增加数据频率。目标是从这些时间序列中创建患者资料。在没有标签的情况下，可以使用预测模型来预测未来值，同时形成一个潜在的聚类空间，并以预测性能为评价指标。我们在Withing的数据集上比较了两个模型，M AGMAC LUST可以对整个时间序列进行聚类，而DGM${}^2$允许个体的群组归属随时间变化（动态聚类）。

    In healthcare, patient data is often collected as multivariate time series, providing a comprehensive view of a patient's health status over time. While this data can be sparse, connected devices may enhance its frequency. The goal is to create patient profiles from these time series. In the absence of labels, a predictive model can be used to predict future values while forming a latent cluster space, evaluated based on predictive performance. We compare two models on Withing's datasets, M AGMAC LUST which clusters entire time series and DGM${}^2$ which allows the group affiliation of an individual to change over time (dynamic clustering).
    
[^66]: DarkShot: 用低计算量和高质量照亮暗图像

    DarkShot: Lighting Dark Images with Low-Compute and High-Quality. (arXiv:2312.16805v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2312.16805](http://arxiv.org/abs/2312.16805)

    本文提出了一种用低计算量和高质量照亮暗图像的轻量级网络，该网络采用Siamese自注意块和Skip-Channel注意力模块，可以在低光增强任务中超越现有最先进的方法，并提出了一个两阶段框架来实现更好的结果。

    

    夜间摄影在极低光条件下遇到越来越多的挑战，主要是由于超低的信噪比。对于实际部署，实用解决方案不仅必须产生视觉上吸引人的结果，还必须要求最小计算量。然而，大多数现有方法要么专注于提高恢复性能，要么采用轻量级模型却牺牲了质量。本文提出了一个轻量级网络，它在低光增强任务中优于现有最先进的方法，同时最小化计算量。所提出的网络结合了Siamese自注意块(SSAB)和Skip-Channel注意力(SCA)模块，增强了模型聚合全局信息的能力，并且非常适用于高分辨率图像。此外，基于我们对低光图像恢复过程的分析，我们提出了一个两阶段框架，可以实现更好的结果。我们的模型可以恢复UHD 4K分辨率的图像。

    Nighttime photography encounters escalating challenges in extremely low-light conditions, primarily attributable to the ultra-low signal-to-noise ratio. For real-world deployment, a practical solution must not only produce visually appealing results but also require minimal computation. However, most existing methods are either focused on improving restoration performance or employ lightweight models at the cost of quality. This paper proposes a lightweight network that outperforms existing state-of-the-art (SOTA) methods in low-light enhancement tasks while minimizing computation. The proposed network incorporates Siamese Self-Attention Block (SSAB) and Skip-Channel Attention (SCA) modules, which enhance the model's capacity to aggregate global information and are well-suited for high-resolution images. Additionally, based on our analysis of the low-light image restoration process, we propose a Two-Stage Framework that achieves superior results. Our model can restore a UHD 4K resoluti
    
[^67]: TAPE: 利用代理拓扑进行协作多智能体策略梯度

    TAPE: Leveraging Agent Topology for Cooperative Multi-Agent Policy Gradient. (arXiv:2312.15667v2 [cs.MA] UPDATED)

    [http://arxiv.org/abs/2312.15667](http://arxiv.org/abs/2312.15667)

    TAPE提出了一种代理拓扑框架，用于解决多智能体策略梯度方法中的集中-分散不匹配（CDM）问题，通过平衡合作和减轻CDM的影响。

    

    多智能体策略梯度（MAPG）在近年取得了显著进展。然而，最先进的MAPG方法中的集中式评论器仍然面临集中-分散不匹配（CDM）问题，这意味着一些智能体的次优行动会影响其他智能体的策略学习。虽然使用单独的评论器可以避免这个问题，但它们严重限制了智能体之间的协作。为了解决这个问题，我们提出了一个代理拓扑框架，该框架决定了在策略梯度中是否应考虑其他代理，并在促进合作和减轻CDM问题之间取得平衡。代理拓扑允许代理使用合作效用作为学习目标，而不是由集中式评论器确定的全局效用或者由个体评论器确定的局部效用。为了构建代理拓扑，我们研究了多种模型。我们提出了基于拓扑的多智能体策略梯度（TAPE），适用于随机和确定性的MAPG方法。

    Multi-Agent Policy Gradient (MAPG) has made significant progress in recent years. However, centralized critics in state-of-the-art MAPG methods still face the centralized-decentralized mismatch (CDM) issue, which means sub-optimal actions by some agents will affect other agent's policy learning. While using individual critics for policy updates can avoid this issue, they severely limit cooperation among agents. To address this issue, we propose an agent topology framework, which decides whether other agents should be considered in policy gradient and achieves compromise between facilitating cooperation and alleviating the CDM issue. The agent topology allows agents to use coalition utility as learning objective instead of global utility by centralized critics or local utility by individual critics. To constitute the agent topology, various models are studied. We propose Topology-based multi-Agent Policy gradiEnt (TAPE) for both stochastic and deterministic MAPG methods. We prove the po
    
[^68]: I-CEE: 将图像分类模型的解释定制为用户专业知识

    I-CEE: Tailoring Explanations of Image Classification Models to User Expertise. (arXiv:2312.12102v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2312.12102](http://arxiv.org/abs/2312.12102)

    I-CEE是一个人为中心的框架，为用户专业知识定制了图像分类模型的解释，通过提供信息丰富的示例图像、局部解释和模型决策来帮助用户理解模型的决策。

    

    有效解释黑盒机器学习模型的决策对于依赖它们的人工智能系统的负责任部署至关重要。识别到其重要性，可以生成这些解释的可解释人工智能（XAI）领域提供了几种技术。然而，在这一不断发展的工作中，对用户（解释对象）的关注相对较少，大多数XAI技术产生的是“一刀切”的解释。为了弥合这一差距，实现更加以人为中心的XAI，我们提出了I-CEE，这是一个为用户专业知识定制图像分类解释的框架。受到现有工作的启发，I-CEE通过为用户提供信息丰富的训练数据子集（即示例图像）、相应的局部解释和模型决策来解释图像分类模型的决策。然而，与此前的工作不同的是，I-CEE模拟了示例图像的信息量依赖于用户专业知识的情况，从而为不同的用户提供不同的示例。

    Effectively explaining decisions of black-box machine learning models is critical to responsible deployment of AI systems that rely on them. Recognizing their importance, the field of explainable AI (XAI) provides several techniques to generate these explanations. Yet, there is relatively little emphasis on the user (the explainee) in this growing body of work and most XAI techniques generate "one-size-fits-all" explanations. To bridge this gap and achieve a step closer towards human-centered XAI, we present I-CEE, a framework that provides Image Classification Explanations tailored to User Expertise. Informed by existing work, I-CEE explains the decisions of image classification models by providing the user with an informative subset of training data (i.e., example images), corresponding local explanations, and model decisions. However, unlike prior work, I-CEE models the informativeness of the example images to depend on user expertise, resulting in different examples for different u
    
[^69]: 非欧几里德空间图神经网络

    Non-Euclidean Spatial Graph Neural Network. (arXiv:2312.10808v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2312.10808](http://arxiv.org/abs/2312.10808)

    本文提出了一种新的通用框架，用于学习嵌入在非欧几里德流形空间中的空间网络的表示，通过提取边上的消息将图拓扑和空间几何结合起来。

    

    空间网络是其图拓扑受嵌入空间约束的网络。理解耦合的空间图属性对于从空间网络中提取强大表示非常重要。因此，仅仅结合个别的空间和网络表示无法揭示空间网络的潜在交互机制。此外，现有的空间网络表示学习方法只能考虑嵌入在欧几里德空间中的网络，无法很好地利用不规则和非均匀的非欧几里德空间中所携带的丰富几何信息。为了解决这个问题，本文提出了一个新的通用框架来学习嵌入在非欧几里德流形空间中的空间网络的表示。具体而言，我们提出了一种基于消息传递的神经网络来结合图拓扑和空间几何，其中空间几何被提取为边上的消息。我们在理论上保证了...

    Spatial networks are networks whose graph topology is constrained by their embedded spatial space. Understanding the coupled spatial-graph properties is crucial for extracting powerful representations from spatial networks. Therefore, merely combining individual spatial and network representations cannot reveal the underlying interaction mechanism of spatial networks. Besides, existing spatial network representation learning methods can only consider networks embedded in Euclidean space, and can not well exploit the rich geometric information carried by irregular and non-uniform non-Euclidean space. In order to address this issue, in this paper we propose a novel generic framework to learn the representation of spatial networks that are embedded in non-Euclidean manifold space. Specifically, a novel message-passing-based neural network is proposed to combine graph topology and spatial geometry, where spatial geometry is extracted as messages on the edges. We theoretically guarantee tha
    
[^70]: 基于机器学习和深度学习的人机交互研究：对脑启发计算的综述

    Human-computer Interaction for Brain-inspired Computing Based on Machine Learning And Deep Learning:A Review. (arXiv:2312.07213v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2312.07213](http://arxiv.org/abs/2312.07213)

    该论文综述了机器学习和深度学习在脑启发计算的人机交互研究中的应用，介绍了其演化、挑战和潜在研究轨迹。

    

    人工智能的持续发展对生物医学研究和其他领域产生了深远影响。脑启发计算是多模态技术和生物医学领域的重要交叉点。本文综述了机器学习（ML）和深度学习（DL）模型在人机交互研究中应用于脑启发计算的演化、应用价值、挑战和潜在研究轨迹。首先回顾了基本概念和发展历史，并将其演化划分为近期的机器学习和当前的深度学习，强调了每个阶段在人机交互研究中对脑启发计算的重要性。另外，从六个角度介绍了深度学习在不同任务的人机交互脑启发计算中的最新进展和关键技术。尽管取得了显著进展，但在人机交互脑启发计算中仍面临挑战。

    The continuous development of artificial intelligence has a profound impact on biomedical research and other fields.Brain-inspired computing is an important intersection of multimodal technology and biomedical field. This paper presents a comprehensive review of machine learning (ML) and deep learning (DL) models applied in human-computer interaction for brain-inspired computing, tracking their evolution, application value, challenges, and potential research trajectories. First, the basic concepts and development history are reviewed, and their evolution is divided into two stages: recent machine learning and current deep learning, emphasizing the importance of each stage in the research state of human-computer interaction for brain-inspired computing. In addition, the latest progress and key techniques of deep learning in different tasks of human-computer interaction for brain-inspired computing are introduced from six perspectives. Despite significant progress, challenges remain in m
    
[^71]: KwaiAgents：基于大型语言模型的通用信息搜索智能体系统

    KwaiAgents: Generalized Information-seeking Agent System with Large Language Models. (arXiv:2312.04889v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2312.04889](http://arxiv.org/abs/2312.04889)

    本文介绍了 KwaiAgents，这是一个基于大型语言模型的通用信息搜索智能体系统。该系统能够利用语言模型作为认知核心，理解用户的查询，行为准则并参考外部文档，以提供高质量的知识和信息。

    

    人类由于好奇心的驱使，不断探索和理解周围的世界，从而发明了各种工具来满足这种好奇心。尽管人类无法在大脑中处理和记忆大量信息，但在批判思维、规划、反思以及利用现有工具与世界进行交互和解释方面卓越出色，使其能够高效地寻找答案。最近大型语言模型（LLM）的进步表明，机器可能也具备类似于人类的能力，即使参数数量受限，也能展示强大的能力。在本文中，我们介绍了 KwaiAgents，这是一个基于LLM的通用信息搜索智能体系统。在 KwaiAgents 中，我们提出了一种利用LLM作为认知核心的智能体系统，它能够理解用户的查询、行为准则和参考外部文档。智能体还可以更新查询结果，与用户进行互动，并提供高质量的知识和信息。

    Driven by curiosity, humans have continually sought to explore and understand the world around them, leading to the invention of various tools to satiate this inquisitiveness. Despite not having the capacity to process and memorize vast amounts of information in their brains, humans excel in critical thinking, planning, reflection, and harnessing available tools to interact with and interpret the world, enabling them to find answers efficiently. The recent advancements in large language models (LLMs) suggest that machines might also possess the aforementioned human-like capabilities, allowing them to exhibit powerful abilities even with a constrained parameter count. In this paper, we introduce KwaiAgents, a generalized information-seeking agent system based on LLMs. Within KwaiAgents, we propose an agent system that employs LLMs as its cognitive core, which is capable of understanding a user's query, behavior guidelines, and referencing external documents. The agent can also update an
    
[^72]: 基于样本的动态分层Transformer通过上下文Bandit实现层和头的灵活性

    Sample-based Dynamic Hierarchical Transformer with Layer and Head Flexibility via Contextual Bandit. (arXiv:2312.03038v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2312.03038](http://arxiv.org/abs/2312.03038)

    我们提出了一种基于样本的动态分层Transformer模型(DHT)，通过解决上下文Bandit问题动态配置层和头的数量。与之前的工作不同，DHT不仅在训练中能够自适应优化网络架构，而且具有灵活的网络架构，用于高效的推断。

    

    Transformer模型需要固定数量的层和头，这使得它们对单个样本的复杂性不灵活，并且在训练和推断中都很昂贵。为了解决这个问题，我们提出了一种基于样本的动态分层Transformer（DHT）模型，它的层和头可以通过解决上下文Bandit问题动态配置。为了确定层数和头数，我们使用了均匀置信上界，而在给定头数量的情况下，我们采用组合Thompson抽样来选择特定的头组合。与之前只关注压缩训练网络以用于推断的工作不同，DHT不仅在训练期间能够自适应优化底层网络架构，而且还具有灵活的网络架构，以实现高效的推断。据我们所知，这是第一个全面的、没有任何额外辅助神经网络实现动态系统的数据驱动动态transformer模型。

    Transformer requires a fixed number of layers and heads which makes them inflexible to the complexity of individual samples and expensive in training and inference. To address this, we propose a sample-based Dynamic Hierarchical Transformer (DHT) model whose layers and heads can be dynamically configured with single data samples via solving contextual bandit problems. To determine the number of layers and heads, we use the Uniform Confidence Bound while we deploy combinatorial Thompson Sampling in order to select specific head combinations given their number. Different from previous work that focuses on compressing trained networks for inference only, DHT is not only advantageous for adaptively optimizing the underlying network architecture during training but also has a flexible network for efficient inference. To the best of our knowledge, this is the first comprehensive data-driven dynamic transformer without any additional auxiliary neural networks that implement the dynamic system
    
[^73]: FedEmb:一种使用网络和特征嵌入聚合的垂直和混合联邦学习算法

    FedEmb: A Vertical and Hybrid Federated Learning Algorithm using Network And Feature Embedding Aggregation. (arXiv:2312.00102v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2312.00102](http://arxiv.org/abs/2312.00102)

    本论文提出了一种名为FedEmb的通用算法，用于进行垂直和混合的基于DNN的联邦学习，具有更高的推理准确率、隐私保护性能更强以及较低的通信带宽需求。实验证明，FedEmb是一种有效的方法来解决分布式问题，并在有限的隐私泄露下提高推理准确度。

    

    联邦学习(FL)是一种新兴的去中心化训练机器学习模型的范例，它在分布式客户端上进行，而不将数据传输给中央服务器。学习方案可以是水平的、垂直的或混合的(垂直和水平都有)。大部分现有的基于深度神经网络(DNN)建模的研究工作都集中在水平数据分布上，而垂直和混合方案研究较少。本文提出了一种通用算法FedEmb,用于建模垂直和混合的基于DNN的学习。我们算法的思想具有更高的推理准确率、更强的隐私保护性能和更低的客户端-服务器通信带宽需求，与现有工作相比。实验结果表明，FedEmb是一种有效的方法来解决分割特征和主题空间分散问题，在有限的隐私暴露下，显示了0.3%到4.2%的推理准确度提高，适用于存储在本地客户端的数据集。

    Federated learning (FL) is an emerging paradigm for decentralized training of machine learning models on distributed clients, without revealing the data to the central server. The learning scheme may be horizontal, vertical or hybrid (both vertical and horizontal). Most existing research work with deep neural network (DNN) modelling is focused on horizontal data distributions, while vertical and hybrid schemes are much less studied. In this paper, we propose a generalized algorithm FedEmb, for modelling vertical and hybrid DNN-based learning. The idea of our algorithm is characterised by higher inference accuracy, stronger privacy-preserving properties, and lower client-server communication bandwidth demands as compared with existing work. The experimental results show that FedEmb is an effective method to tackle both split feature & subject space decentralized problems, shows 0.3% to 4.2% inference accuracy improvement with limited privacy revealing for datasets stored in local client
    
[^74]: 从成对人类偏好学习的密度估计视角

    A density estimation perspective on learning from pairwise human preferences. (arXiv:2311.14115v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2311.14115](http://arxiv.org/abs/2311.14115)

    研究提出了一个从密度估计的角度解释学习成对人类偏好的方法，并证明通过这种方法训练奖励函数可以有效地模拟注释者的隐含偏好分布。

    

    从人类反馈中学习（LHF）--尤其是从成对偏好学习--最近在训练大型语言模型（LLM）中变得至关重要，并成为许多研究的主题。最近的工作大多将其框架为一种强化学习问题，通过成对偏好数据学习奖励函数，并将LLM视为一个策略，并在额外的正则化约束下进行调整以最大化奖励。我们提出了一种替代解释，它以成对偏好的生成过程为中心，并将LHF视为一个密度估计问题。我们提供了理论和实证结果，表明对于通过偏好行为分布方程定义的一类生成过程，通过成对偏好训练奖励函数有效地模拟了注释者的隐含偏好分布。最后，我们讨论并提出了关于“标注者错误”的研究结果--即错误的情况。

    Learning from human feedback (LHF) -- and in particular learning from pairwise preferences -- has recently become a crucial ingredient in training large language models (LLMs), and has been the subject of much research. Most recent works frame it as a reinforcement learning problem, where a reward function is learned from pairwise preference data and the LLM is treated as a policy which is adapted to maximize the rewards, often under additional regularization constraints. We propose an alternative interpretation which centers on the generative process for pairwise preferences and treats LHF as a density estimation problem. We provide theoretical and empirical results showing that for a family of generative processes defined via preference behavior distribution equations, training a reward function on pairwise preferences effectively models an annotator's implicit preference distribution. Finally, we discuss and present findings on "annotator misspecification" -failure cases where wro
    
[^75]: 学会说母语：以母语风格激发大型语言模型的能力

    Speak Like a Native: Prompting Large Language Models in a Native Style. (arXiv:2311.13538v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2311.13538](http://arxiv.org/abs/2311.13538)

    本文提出了一种名为AlignedCoT的新颖有效方法，通过将上下文示例与大型语言模型（LLMs）的母语风格对齐，提高了LLMs的推理能力和性能。

    

    大型语言模型（LLMs）与上下文学习（ICL）已成为许多自然语言处理任务的现代工具选择。然而，上下文示例的文本风格如何影响LLMs的性能仍然不足。本文提出了一种名为AlignedCoT的新颖有效的方法，通过将上下文示例与LLMs的母语风格对齐来提高LLMs的推理能力。 "母语"是指LLMs的固有特征，可以通过零-shot场景探测。 AlignedCoT广泛适用于ICL方法，可以轻松与最先进的技术结合，进一步提高LLMs的性能。我们在数学问答、常识推理和文本理解等多个基准测试上进行了广泛而全面的实验。实证结果表明，我们的AlignedCoT相比精心手工制作的演示文稿显著提高了性能。

    In-context learning (ICL) with large language models (LLMs) has become the modern tools of choice for many natural language processing tasks. However, how the text style of in-context examples influences the performance of LLMs still remains under-explored. This paper presents a novel and effective approach, named \textbf{AlignedCoT}, to improve the reasoning capability of LLMs by aligning the in-context examples with the native style of LLMs.''Native'' refers to the inherent characteristic of LLMs which can be probed by zero-shot scenarios.AlignedCoT is widely applicable to ICL methods, making it easy to combine with state-of-the-art techniques to further improve the LLMs' performance. We conduct extensive and comprehensive experiments on several benchmarks on mathematical question-answering, common-sense reasoning, and text understanding. The empirical results demonstrate that our AlignedCoT significantly improves performance over the carefully handcrafted demonstrations. Specificall
    
[^76]: 属性分组和挖掘哈希在细粒度图像检索中的应用

    Attributes Grouping and Mining Hashing for Fine-Grained Image Retrieval. (arXiv:2311.06067v1 [cs.IR] CROSS LISTED)

    [http://arxiv.org/abs/2311.06067](http://arxiv.org/abs/2311.06067)

    该论文提出了一种属性分组和挖掘哈希（AGMH）方法，通过将卷积描述符替代注意力引导特征，在细粒度图像检索中生成了多样的特征表示，以捕捉细微的差异和局部特征。这种方法可以有效地提高图像检索的准确性和效率。

    

    近年来，哈希方法在大规模媒体搜索中因其低存储和强大的表示能力而受到广泛关注。为了描述具有相似整体外观但细微差异的对象，越来越多的研究聚焦于基于哈希的细粒度图像检索。现有的哈希网络通常通过对相同的深层激活张量进行注意力引导来生成局部和全局特征，这限制了特征表示的多样性。为了解决这个限制，我们将卷积描述符替代注意力引导特征，并提出了一种属性分组和挖掘哈希（AGMH）方法，该方法可以在多个描述符中对类别特定的视觉属性进行分组和嵌入，以生成用于有效细粒度图像检索的综合特征表示。具体来说，我们设计了一种注意力分散损失（ADL）来强制描述符关注各种局部区域，并捕捉多样的细微细节。

    In recent years, hashing methods have been popular in the large-scale media search for low storage and strong representation capabilities. To describe objects with similar overall appearance but subtle differences, more and more studies focus on hashing-based fine-grained image retrieval. Existing hashing networks usually generate both local and global features through attention guidance on the same deep activation tensor, which limits the diversity of feature representations. To handle this limitation, we substitute convolutional descriptors for attention-guided features and propose an Attributes Grouping and Mining Hashing (AGMH), which groups and embeds the category-specific visual attributes in multiple descriptors to generate a comprehensive feature representation for efficient fine-grained image retrieval. Specifically, an Attention Dispersion Loss (ADL) is designed to force the descriptors to attend to various local regions and capture diverse subtle details. Moreover, we propos
    
[^77]: 使用类似人类发展数据语料库进行预训练的LLMs

    Pre-training LLMs using human-like development data corpus. (arXiv:2311.04666v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2311.04666](http://arxiv.org/abs/2311.04666)

    本论文使用类似人类发展数据语料库对LLMs进行预训练，通过与儿童观看的令牌数量相似的方式，评估了LLMs学习上下文词表示的能力。同时提供强大的基准和对任务组织者提供的RoBERTa基准的复制尝试。

    

    预训练的大型语言模型（LLMs）在各种语言推理和理解任务中取得了成功。LLMs的预训练阶段会查看大量的原始文本数据。BabyLM共享任务将LLM的预训练与人类语言习得进行比较，13岁孩子看到的令牌数量比LLMs看到的数量要小得多。在这项工作中，我们在LLMs能够学习上下文词表示方面进行预训练和评估，使用的令牌数量与儿童看到的差不多。我们提供了一组强大的基准；不同的架构、评估不同时期性能变化和报告的预训练指标，以及尝试松散复制任务组织者提供的RoBERTa基准以观察超参数选择和复现性对训练稳健性的影响。我们提供了对严格和严格小规模路径的提交细节。

    Pre-trained Large Language Models (LLMs) have shown success in a diverse set of language inference and understanding tasks. The pre-training stage of LLMs looks at a large corpus of raw textual data. The BabyLM shared task compares LLM pre-training to human language acquisition, where the number of tokens seen by 13-year-old kids is magnitudes smaller than the number of tokens seen by LLMs. In this work, we pre-train and evaluate LLMs on their ability to learn contextual word representations using roughly the same number of tokens as seen by children. We provide a strong set of baselines; with different architectures, evaluation of changes in performance across epochs, and reported pre-training metrics for the strict small and strict tracks of the task. We also try to loosely replicate the RoBERTa baseline given by the task organizers to observe the training robustness to hyperparameter selection and replicability. We provide the submission details to the strict and strict-small tracks
    
[^78]: KirchhoffNet：一种连接消息传递和连续深度模型的电路桥接神经网络

    KirchhoffNet: A Circuit Bridging Message Passing and Continuous-Depth Models. (arXiv:2310.15872v1 [cs.LG])

    [http://arxiv.org/abs/2310.15872](http://arxiv.org/abs/2310.15872)

    本文提出了一种称为基赫霍夫网络的神经网络模型，利用基赫霍夫电流定律与消息传递神经网络和连续深度网络建立连接。在MNIST数据集上，基赫霍夫网络可以实现接近98.86%的测试准确度，且具有在硬件上实现的潜力。无论网络参数数量如何，其正向计算都可以在1/f秒内完成，具有快速计算的硬件特性。

    

    在本文中，我们利用了模拟电路的基本原理基赫霍夫电流定律，引入了一类独特的神经网络模型，称为基赫霍夫网络。基赫霍夫网络与消息传递神经网络和连续深度网络建立了密切联系。我们证明，即使在没有任何传统层（如卷积、池化或线性层）的情况下，基赫霍夫网络在MNIST数据集上取得了98.86%的测试准确度，与最先进的结果相当。让基赫霍夫网络更加有趣的是其在硬件领域的潜力。当代深度神经网络通常部署在GPU上。相反，基赫霍夫网络可以通过模拟电路来实现。此外，我们证明了无论在基赫霍夫网络内有多少参数，其正向计算都可以在1/f秒内完成，其中f表示硬件的时钟频率。这种特性表明，基赫霍夫网络具有潜力实现快速计算的硬件。

    In this paper, we exploit a fundamental principle of analog electronic circuitry, Kirchhoff's current law, to introduce a unique class of neural network models that we refer to as KirchhoffNet. KirchhoffNet establishes close connections with message passing neural networks and continuous-depth networks. We demonstrate that even in the absence of any traditional layers (such as convolution, pooling, or linear layers), KirchhoffNet attains 98.86% test accuracy on the MNIST dataset, comparable with state of the art (SOTA) results. What makes KirchhoffNet more intriguing is its potential in the realm of hardware. Contemporary deep neural networks are conventionally deployed on GPUs. In contrast, KirchhoffNet can be physically realized by an analog electronic circuit. Moreover, we justify that irrespective of the number of parameters within a KirchhoffNet, its forward calculation can always be completed within 1/f seconds, with f representing the hardware's clock frequency. This characteris
    
[^79]: 通过基于Transformer的强化学习进行分子的全新设计

    Molecular De Novo Design through Transformer-based Reinforcement Learning. (arXiv:2310.05365v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.05365](http://arxiv.org/abs/2310.05365)

    本文提出了一种基于Transformer的强化学习方法，通过精细调整生成模型，能够在分子的全新设计中生成具有所需性质的分子结构，展现出优越的性能。

    

    本文介绍了一种通过精细调整基于Transformer的生成模型用于分子的全新设计的方法。利用Transformer相对于循环神经网络（RNN）的优越序列学习能力，我们的模型可以有效地生成具有所需性质的分子结构。与传统的基于RNN的模型相比，我们提出的方法在生成预测对多种生物靶点具有活性的化合物方面表现出卓越性能，捕捉了分子结构序列的长期依赖性。该模型的有效性在许多任务中得到了证明，包括生成与查询结构类似的分子和生成具有特定属性的化合物，在性能上优于基线的基于RNN的方法。我们的方法可以用于桥接化学、从单个分子开始扩展库，并生成具有高预测活性的化合物。

    In this work, we introduce a method to fine-tune a Transformer-based generative model for molecular de novo design. Leveraging the superior sequence learning capacity of Transformers over Recurrent Neural Networks (RNNs), our model can generate molecular structures with desired properties effectively. In contrast to the traditional RNN-based models, our proposed method exhibits superior performance in generating compounds predicted to be active against various biological targets, capturing long-term dependencies in the molecular structure sequence. The model's efficacy is demonstrated across numerous tasks, including generating analogues to a query structure and producing compounds with particular attributes, outperforming the baseline RNN-based methods. Our approach can be used for scaffold hopping, library expansion starting from a single molecule, and generating compounds with high predicted activity against biological targets.
    
[^80]: 使用大型语言模型改进自动VQA评估

    Improving Automatic VQA Evaluation Using Large Language Models. (arXiv:2310.02567v1 [cs.CV])

    [http://arxiv.org/abs/2310.02567](http://arxiv.org/abs/2310.02567)

    提出使用大型语言模型改进自动视觉问答（VQA）评估的方法，将VQA评估格式化为回答评分任务，通过指令调整大型语言模型在准确度上评分候选答案，证明该方法与人类判断相关性优于现有度量方法。

    

    在提出视觉问答（VQA）任务8年后，准确率仍然是自动评估的主要指标。在IID评估设置中，VQA准确度一直很有效。然而，我们的社区正在转向开放式生成模型和OOD评估。在这种新的范式中，现有的VQA准确度指标过于严格，低估了VQA系统的性能。因此，有必要开发更强大的自动VQA度量，作为人类判断的代理。在这项工作中，我们提出利用指令调整大型语言模型（LLM）的上下文学习能力来构建更好的VQA度量。我们将VQA评估格式化为一个回答评分任务，即指令调整的大型语言模型被指示根据一组参考答案评分候选答案的准确性。我们证明所提出的度量与人类判断相关性优于现有度量在几个VQA模型和基准测试中。

    8 years after the visual question answering (VQA) task was proposed, accuracy remains the primary metric for automatic evaluation. VQA Accuracy has been effective so far in the IID evaluation setting. However, our community is undergoing a shift towards open-ended generative models and OOD evaluation. In this new paradigm, the existing VQA Accuracy metric is overly stringent and underestimates the performance of VQA systems. Thus, there is a need to develop more robust automatic VQA metrics that serve as a proxy for human judgment. In this work, we propose to leverage the in-context learning capabilities of instruction-tuned large language models (LLMs) to build a better VQA metric. We formulate VQA evaluation as an answer-rating task where the LLM is instructed to score the accuracy of a candidate answer given a set of reference answers. We demonstrate the proposed metric better correlates with human judgment compared to existing metrics across several VQA models and benchmarks. We ho
    
[^81]: 在学习者提供的问题上增强学生表现预测的SGNN-LLM协同

    Enhancing Student Performance Prediction on Learnersourced Questions with SGNN-LLM Synergy. (arXiv:2309.13500v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2309.13500](http://arxiv.org/abs/2309.13500)

    这项研究介绍了一种创新的策略，将有符号图神经网络（SGNNs）和大型语言模型（LLM）的潜力协同起来，用于预测学生在学习者提供的问题上的表现。该方法利用有符号二分图全面建模学生回答，并采用对比学习框架增强了噪声的鲁棒性。

    

    通过学生内容创作，学习者合作具有可扩展教育的巨大潜力。然而，预测学生在学习者提供的问题上的表现，对于个性化学习体验至关重要，由于学生生成的数据中固有的噪声，这是具有挑战性的。此外，传统的基于图的方法可以捕获学生和问题交互的复杂网络，但在冷启动条件下，其中学生对问题的有限参与导致数据稀疏，这些方法往往表现不佳。为了解决这两个挑战，我们引入了一种创新策略，将整合有符号图神经网络（SGNNs）和大型语言模型（LLM）的潜力协同起来。我们的方法利用有符号二分图全面建模学生回答，并采用对比学习框架增强了噪声的鲁棒性。此外，LLM的贡献在于生成基础问题嵌入，特别是证明了其优势。

    Learnersourcing offers great potential for scalable education through student content creation. However, predicting student performance on learnersourced questions, which is essential for personalizing the learning experience, is challenging due to the inherent noise in student-generated data. Moreover, while conventional graph-based methods can capture the complex network of student and question interactions, they often fall short under cold start conditions where limited student engagement with questions yields sparse data. To address both challenges, we introduce an innovative strategy that synergizes the potential of integrating Signed Graph Neural Networks (SGNNs) and Large Language Model (LLM) embeddings. Our methodology employs a signed bipartite graph to comprehensively model student answers, complemented by a contrastive learning framework that enhances noise resilience. Furthermore, LLM's contribution lies in generating foundational question embeddings, proving especially adv
    
[^82]: 评估大型语言模型利用亚斯伯格综合征筛选测试理解隐喻和讽刺的能力

    Evaluating large language models' ability to understand metaphor and sarcasm using a screening test for Asperger syndrome. (arXiv:2309.10744v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2309.10744](http://arxiv.org/abs/2309.10744)

    该研究使用一个评分测试来评估大型语言模型（LLMs）理解人类微妙交流的能力。研究结果发现，随着模型参数数量的增加，LLMs对隐喻理解能力有所改善，但对讽刺理解能力的改进并未观察到。

    

    隐喻和讽刺是我们高度进化的社交沟通技巧的珍贵成果。然而，亚斯伯格综合征的儿童众所周知在理解讽刺方面存在困难，即使他们具有足够理解隐喻的口语智商水平。鉴于此，已经使用了一个评分测试来评估理解隐喻和讽刺的能力，以区分亚斯伯格综合征和其他表现相似外部行为的症状（例如注意力缺陷/多动障碍）。本研究使用标准化测试来研究最近大型语言模型（LLMs）理解人类微妙交流的能力。结果显示，随着模型参数数量的增加，它们理解隐喻的能力得到了改善，但并没有观察到对讽刺理解的改进。这意味着有必要采取其他方法来使LLMs具备理解讽刺的能力，这已与亚斯伯格综合征相关。

    Metaphors and sarcasm are precious fruits of our highly-evolved social communication skills. However, children with Asperger syndrome are known to have difficulties in comprehending sarcasm, even if they possess a certain level of verbal IQ sufficient for understanding metaphors. Given that, a screening test that scores the ability to understand metaphor and sarcasm has been used to differentiate Asperger syndrome from other symptoms exhibiting akin external behaviors (e.g., attention-deficit/hyperactivity disorder). This study uses the standardized test to examine the capability of recent large language models (LLMs) in understanding human nuanced communication. The results divulged that, whereas their ability to comprehend metaphors has been improved with the increase of the number of model parameters, the improvement in sarcasm understanding was not observed. This implies that an alternative approach is imperative to imbue LLMs with the capacity to grasp sarcasm, which has been asso
    
[^83]: AI代理的记忆和泛化能力分析：连续学习者是否具有鲁棒性？

    Analysis of the Memorization and Generalization Capabilities of AI Agents: Are Continual Learners Robust?. (arXiv:2309.10149v1 [cs.LG])

    [http://arxiv.org/abs/2309.10149](http://arxiv.org/abs/2309.10149)

    本文提出了一种新的连续学习框架，旨在在动态环境下实现鲁棒的泛化能力并保留过去的知识。通过使用有限容量的内存来保存先前观察到的环境信息，并从内存中采样数据点来获得对未知变化鲁棒的预测器。该分析展示了记忆和泛化之间的权衡，而实验证明了所提出的算法的优越性。

    

    在连续学习中，AI代理（例如自动驾驶车辆或机器人）在动态环境下从非稳态数据流中学习。对于这类应用的实际部署，保证对未知环境的鲁棒性以及保留过去的经验是非常重要的。本文提出了一种新的连续学习框架，旨在在动态环境下实现鲁棒的泛化能力并保留过去的知识。考虑到连续学习代理使用有限容量的内存来保存先前观察到的环境信息，以减轻遗忘问题。然后，从内存中采样数据点，以估计环境变化的风险分布，从而得到对未知变化具有鲁棒性的预测器。对所提出的框架的泛化和记忆性能进行了理论分析。该分析展示了随内存大小的记忆和泛化之间的权衡。实验证明了所提出的算法的优越性。

    In continual learning (CL), an AI agent (e.g., autonomous vehicles or robotics) learns from non-stationary data streams under dynamic environments. For the practical deployment of such applications, it is important to guarantee robustness to unseen environments while maintaining past experiences. In this paper, a novel CL framework is proposed to achieve robust generalization to dynamic environments while retaining past knowledge. The considered CL agent uses a capacity-limited memory to save previously observed environmental information to mitigate forgetting issues. Then, data points are sampled from the memory to estimate the distribution of risks over environmental change so as to obtain predictors that are robust with unseen changes. The generalization and memorization performance of the proposed framework are theoretically analyzed. This analysis showcases the tradeoff between memorization and generalization with the memory size. Experiments show that the proposed algorithm outpe
    
[^84]: RaTrack: 带有4D雷达点云的运动物体检测与跟踪

    RaTrack: Moving Object Detection and Tracking with 4D Radar Point Cloud. (arXiv:2309.09737v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2309.09737](http://arxiv.org/abs/2309.09737)

    RaTrack是一种针对雷达跟踪的创新解决方案，通过运动分割和聚类以及运动估计模块，实现了对移动物体的精确跟踪，优于最先进性能。

    

    移动自主性依赖于对动态环境的精确感知。在3D世界中稳定地跟踪移动物体因此对于轨迹预测、避障和路径规划等应用起着关键作用。虽然大多数现有方法利用LiDAR或相机进行多目标跟踪（MOT），但4D成像雷达的能力仍然很少被探索。认识到4D雷达数据中的雷达噪声和点稀疏性所带来的挑战，我们介绍了RaTrack，这是一种专门针对基于雷达的跟踪的创新解决方案。我们的方法摒弃了对特定对象类型和3D边界框的依赖，而是专注于运动分割和聚类，并配以运动估计模块。在View-of-Delft数据集上进行评估时，RaTrack展示出了优于最先进性能的运动物体跟踪精度。

    Mobile autonomy relies on the precise perception of dynamic environments. Robustly tracking moving objects in 3D world thus plays a pivotal role for applications like trajectory prediction, obstacle avoidance, and path planning. While most current methods utilize LiDARs or cameras for Multiple Object Tracking (MOT), the capabilities of 4D imaging radars remain largely unexplored. Recognizing the challenges posed by radar noise and point sparsity in 4D radar data, we introduce RaTrack, an innovative solution tailored for radar-based tracking. Bypassing the typical reliance on specific object types and 3D bounding boxes, our method focuses on motion segmentation and clustering, enriched by a motion estimation module. Evaluated on the View-of-Delft dataset, RaTrack showcases superior tracking precision of moving objects, largely surpassing the performance of the state of the art.
    
[^85]: 非线性、反馈和因果结构学习中的一致性问题研究

    Nonlinearity, Feedback and Uniform Consistency in Causal Structural Learning. (arXiv:2308.07520v1 [stat.ML])

    [http://arxiv.org/abs/2308.07520](http://arxiv.org/abs/2308.07520)

    这篇论文研究了非线性、反馈和因果结构学习中的一致性问题，并提出了一个弱于强可靠性的k-Triangle Faithfulness的替代定义。

    

    因果发现的目标是从观测数据中找到学习因果结构的自动化搜索方法。有些情况下，感兴趣的因果机制的所有变量都已经被测量，任务是预测一个变量对另一个变量的影响。相反，有时主要关注的变量并非直接可观察，而是通过它们在数据中的表现来推理出来的。这些被称为潜在变量。一个广泛被知道的例子是心理构造的智商，因为无法直接测量，所以研究人员尝试通过各种指标如智商测试来评估。在这种情况下，因果发现算法可以揭示潜在变量之间和潜在变量与观察变量之间的因果连接，从而发现潜在的模式和结构。这篇论文主要研究因果发现中的两个问题：提供了一个弱于强可靠性的k-Triangle Faithfulness的替代定义，并提出了对统计一致性的新要求。

    The goal of Causal Discovery is to find automated search methods for learning causal structures from observational data. In some cases all variables of the interested causal mechanism are measured, and the task is to predict the effects one measured variable has on another. In contrast, sometimes the variables of primary interest are not directly observable but instead inferred from their manifestations in the data. These are referred to as latent variables. One commonly known example is the psychological construct of intelligence, which cannot directly measured so researchers try to assess through various indicators such as IQ tests. In this case, casual discovery algorithms can uncover underlying patterns and structures to reveal the causal connections between the latent variables and between the latent and observed variables. This thesis focuses on two questions in causal discovery: providing an alternative definition of k-Triangle Faithfulness that (i) is weaker than strong faithfu
    
[^86]: MSQNet: 无关演员的多模态动作识别

    MSQNet: Actor-agnostic Action Recognition with Multi-modal Query. (arXiv:2307.10763v1 [cs.CV])

    [http://arxiv.org/abs/2307.10763](http://arxiv.org/abs/2307.10763)

    MSQNet是一种无关演员的多模态多标签动作识别方法，通过使用视觉和文本模态来更好地表示动作类别，克服了现有方法中针对特定演员的限制。

    

    现有的动作识别方法通常是针对特定演员的，因为演员之间具有固有的拓扑和显着差异。这就需要特定演员的姿态估计（例如人类与动物），导致模型设计复杂性和高维护成本。此外，它们通常只关注学习视觉模态和单标签分类，忽视了其他可用信息源（例如类名文本）和多个动作的同时发生。为了克服这些限制，我们提出了一种新的方法，称为“无关演员的多模态多标签动作识别”，为包括人类和动物在内的各种类型的演员提供了统一的解决方案。我们进一步在基于Transformer的目标检测框架（例如DETR）中提出了一种新颖的多模态语义查询网络（MSQNet）模型，通过利用视觉和文本模态更好地表示动作类别。消除了演员特定性的限制。

    Existing action recognition methods are typically actor-specific due to the intrinsic topological and apparent differences among the actors. This requires actor-specific pose estimation (e.g., humans vs. animals), leading to cumbersome model design complexity and high maintenance costs. Moreover, they often focus on learning the visual modality alone and single-label classification whilst neglecting other available information sources (e.g., class name text) and the concurrent occurrence of multiple actions. To overcome these limitations, we propose a new approach called 'actor-agnostic multi-modal multi-label action recognition,' which offers a unified solution for various types of actors, including humans and animals. We further formulate a novel Multi-modal Semantic Query Network (MSQNet) model in a transformer-based object detection framework (e.g., DETR), characterized by leveraging visual and textual modalities to represent the action classes better. The elimination of actor-spec
    
[^87]: TrustGuard: 基于GNN的动态支持鲁棒且可解释的信任评估

    TrustGuard: GNN-based Robust and Explainable Trust Evaluation with Dynamicity Support. (arXiv:2306.13339v1 [cs.LG])

    [http://arxiv.org/abs/2306.13339](http://arxiv.org/abs/2306.13339)

    TrustGuard是一种基于GNN的信任评估模型，支持信任动态性，抗击鲁棒并提供解释能力，它的实验结果在准确性、鲁棒性和可解释性方面都优于其他方法。

    

    信任评估评估实体之间的信任关系并促进决策。机器学习由于其学习能力而表现出巨大的潜力，因此对信任评估具有重要意义。近年来，作为一种新的机器学习范 paradigm，图神经网络（GNN）在处理图形数据方面表现出优越性。这激发了研究人员探索将其用于信任评估，因为实体之间的信任关系可以建模为图形。但是，使用GNN的当前信任评估方法未能完全满足信任的动态性，忽略了攻击对信任评估的不利影响，并且无法提供令人信服的评估结果解释。为解决这些问题，在本文中，我们提出了TrustGuard ：一种支持信任动态性、抗击鲁棒且通过可视化提供解释的精确信任评估模型。具体而言，TrustGuard 设计了一个由动态感知节点嵌入层、图卷积层、注意机制层和信任预测层组成的分层架构。为了评估提出的模型的有效性，我们对真实数据集进行了实验，并将TrustGuard与其他最先进的方法进行了比较。实验结果表明，TrustGuard 在准确性、鲁棒性和可解释性方面均优于其他方法。

    Trust evaluation assesses trust relationships between entities and facilitates decision-making. Machine Learning (ML) shows great potential for trust evaluation owing to its learning capabilities. In recent years, Graph Neural Networks (GNNs), as a new ML paradigm, have demonstrated superiority in dealing with graph data. This has motivated researchers to explore their use in trust evaluation, as trust relationships among entities can be modeled as a graph. However, current trust evaluation methods that employ GNNs fail to fully satisfy the dynamicity nature of trust, overlook the adverse effects of attacks on trust evaluation, and cannot provide convincing explanations on evaluation results. To address these problems, in this paper, we propose TrustGuard, a GNN-based accurate trust evaluation model that supports trust dynamicity, is robust against typical attacks, and provides explanations through visualization. Specifically, TrustGuard is designed with a layered architecture that con
    
[^88]: HomeRobot: 开放词汇移动操作

    HomeRobot: Open-Vocabulary Mobile Manipulation. (arXiv:2306.11565v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2306.11565](http://arxiv.org/abs/2306.11565)

    HomeRobot是一种开放词汇移动操作的顺应力机器人，可在家庭环境中导航并操纵各种物体，以完成日常任务。它引入了HomeRobot OVMM基准测试，通过仿真和实际机器人两个组件进行测试和验证。

    

    HomeRobot(noun): 一种价格合理的顺应力机器人，可在家庭中导航并操纵各种物体，以完成日常任务。开放词汇移动操作（OVMM）是在任何未知环境中捡起任何物体并放置在指定位置的问题。对于机器人要成为人类环境中有用的助手，这是一个基础性的挑战，因为它涉及到机器人学中的各个子问题：感知、语言理解、导航和操纵都是OVMM的关键。此外，将这些子问题的解决方案集成起来也面临着自己的巨大挑战。为推动这一领域的研究，我们推出了HomeRobot OVMM基准测试，其中一个智能体在家庭环境中导航，以捡起新奇物体并放置在目标容器上。HomeRobot具有两个组件：一个仿真组件，使用新的高质量多房间家庭环境中的大量和多样化的物体集合; 和一个实际的物理机器人组件，用于在真实世界中进行测试和验证。

    HomeRobot (noun): An affordable compliant robot that navigates homes and manipulates a wide range of objects in order to complete everyday tasks. Open-Vocabulary Mobile Manipulation (OVMM) is the problem of picking any object in any unseen environment, and placing it in a commanded location. This is a foundational challenge for robots to be useful assistants in human environments, because it involves tackling sub-problems from across robotics: perception, language understanding, navigation, and manipulation are all essential to OVMM. In addition, integration of the solutions to these sub-problems poses its own substantial challenges. To drive research in this area, we introduce the HomeRobot OVMM benchmark, where an agent navigates household environments to grasp novel objects and place them on target receptacles. HomeRobot has two components: a simulation component, which uses a large and diverse curated object set in new, high-quality multi-room home environments; and a real-world co
    
[^89]: Tensorized Hypergraph Neural Networks（张量化超图神经网络）

    Tensorized Hypergraph Neural Networks. (arXiv:2306.02560v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2306.02560](http://arxiv.org/abs/2306.02560)

    本文提出了一种基于张量化和高阶特征传递的超图神经网络（THNN），用于从均匀超图中提取高阶信息。同时采用部分对称的CP分解来处理高阶特征传递的复杂度。

    

    最近，由于在各个领域表现优秀，超图神经网络（HGNN）变得越来越受关注。然而，大多数现有的HGNN都依赖于对超图连接模式的一阶近似，忽略了重要的高阶信息。为了解决这个问题，我们提出了一种新颖的基于邻接张量的张量化超图神经网络（THNN）。THNN是一个通过高阶外积特征传递实现忠实超图建模的框架，是邻接矩阵为基础的图神经网络的自然张量扩展。提出的THNN等效于一个高阶多项式回归方案，使得THNN能够有效地从均匀超图中提取高阶信息。此外，考虑到直接处理高阶外积特征的指数复杂度，我们提出使用部分对称的CP分解。

    Hypergraph neural networks (HGNN) have recently become attractive and received significant attention due to their excellent performance in various domains. However, most existing HGNNs rely on first-order approximations of hypergraph connectivity patterns, which ignores important high-order information. To address this issue, we propose a novel adjacency-tensor-based \textbf{T}ensorized \textbf{H}ypergraph \textbf{N}eural \textbf{N}etwork (THNN). THNN is a faithful hypergraph modeling framework through high-order outer product feature message passing and is a natural tensor extension of the adjacency-matrix-based graph neural networks. The proposed THNN is equivalent to a high-order polynomial regression scheme, which enables THNN with the ability to efficiently extract high-order information from uniform hypergraphs. Moreover, in consideration of the exponential complexity of directly processing high-order outer product features, we propose using a partially symmetric CP decomposition
    
[^90]: BiomedGPT：一种面向视觉、语言和多模态任务的统一且通用的生物医学生成预训练Transformer

    BiomedGPT: A Unified and Generalist Biomedical Generative Pre-trained Transformer for Vision, Language, and Multimodal Tasks. (arXiv:2305.17100v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.17100](http://arxiv.org/abs/2305.17100)

    BiomedGPT是一种面向视觉、语言和多模态任务的通用生物医学生成预训练Transformer，在多个临床任务中取得了16个最新的最优结果，包括超过了OpenAI的GPT-4V和Google的Med-PaLM M（12B）。同时，BiomedGPT还支持零-shot迁移学习。

    

    传统的任务和模态特定的人工智能模型在生物医学领域的实际应用和维护中不够灵活。与此同时，生物医学数据的不断增加，结合现代多模态多任务人工智能技术的进展，为通用的生物医学人工智能解决方案的出现铺平了道路。这些解决方案有潜力解释不同的医疗模态，并产生如自由文本报告或疾病诊断等表达性输出。本文提出了BiomedGPT，这是第一个面向多样化生物医学任务的开源通用视觉语言人工智能模型。BiomedGPT在26个数据集的五个临床重要任务中实现了16个最新的结果。值得注意的是，在放射学人员评估中，它超越了OpenAI的GPT-4 with vision（GPT-4V），并在乳腺癌诊断和医学视觉问题回答方面超过了Google的Med-PaLM M（12B）。此外，BiomedGPT还支持零-shot迁移学习。

    Conventional task- and modality-specific artificial intelligence (AI) models are inflexible in real-world deployment and maintenance for biomedicine. At the same time, the growing availability of biomedical data, coupled with the advancements in modern multi-modal multi-task AI techniques, has paved the way for the emergence of generalist biomedical AI solutions. These solutions hold the potential to interpret different medical modalities and produce expressive outputs such as free-text reports or disease diagnosis. Here, we propose BiomedGPT, the first open-source and generalist visual language AI for diverse biomedical tasks. BiomedGPT achieved 16 state-of-the-art results across five clinically significant tasks on 26 datasets. Notably, it outperformed OpenAI's GPT-4 with vision (GPT-4V) in radiology human evaluation and surpassed Google's Med-PaLM M (12B) in breast cancer diagnosis and medical visual question answering. Moreover, BiomedGPT facilitates zero-shot transfer learning, gr
    
[^91]: SLaDe: 一种用于优化汇编代码的可移植小型语言模型反编译器

    SLaDe: A Portable Small Language Model Decompiler for Optimized Assembly. (arXiv:2305.12520v2 [cs.PL] UPDATED)

    [http://arxiv.org/abs/2305.12520](http://arxiv.org/abs/2305.12520)

    SLaDe是一种基于小型语言模型的反编译器，通过训练真实代码的序列到序列变换器，使用了新颖的分词器、无丢弃训练和类型推断等方法，能够生成更易读和更准确的程序。

    

    反编译是一个研究较为广泛的领域，有许多高质量的工具可供使用。这些工具通常用于安全任务和移植遗留代码。然而，它们经常生成难以阅读的程序，并且需要大量的工程工作来支持新的编程语言和指令集架构。最近关注神经方法产生了能生成可读代码的可移植工具。然而，迄今为止，这些技术通常只适用于没有优化的合成程序，并且没有模型评估它们的可移植性。此外，虽然生成的代码可能更易读，但通常是不正确的。本文介绍了SLaDe，一种基于序列到序列变换器训练的小型语言模型反编译器，该变换器是使用实际代码进行训练的。我们开发了一种新颖的分词器，并利用无丢弃训练来产生高质量的代码。我们利用类型推断生成比标准分析方法和最近的神经方法更易读和更准确的程序。

    Decompilation is a well-studied area with numerous high-quality tools available. These are frequently used for security tasks and to port legacy code. However, they regularly generate difficult-to-read programs and require a large amount of engineering effort to support new programming languages and ISAs. Recent interest in neural approaches has produced portable tools that generate readable code. However, to-date such techniques are usually restricted to synthetic programs without optimization, and no models have evaluated their portability. Furthermore, while the code generated may be more readable, it is usually incorrect. This paper presents SLaDe, a Small Language model Decompiler based on a sequence-to-sequence transformer trained over real-world code. We develop a novel tokenizer and exploit no-dropout training to produce high-quality code. We utilize type-inference to generate programs that are more readable and accurate than standard analytic and recent neural approaches. Unli
    
[^92]: 交叉门控多层感知机下的蛋白质复合物不变嵌入是一种一次性抗体设计器

    Protein Complex Invariant Embedding with Cross-Gate MLP is A One-Shot Antibody Designer. (arXiv:2305.09480v1 [q-bio.BM])

    [http://arxiv.org/abs/2305.09480](http://arxiv.org/abs/2305.09480)

    本文提出了一种深度生成模型，可以一次性地共同设计抗体CDR的1D序列和3D结构，解决几何建模和低效推断的问题。

    

    抗体是由免疫系统产生的针对外来物质或抗原的重要蛋白质。抗体的特异性由其互补决定区（CDR）决定，CDR位于抗体链的可变区域中，形成与抗原结合的位点。以往的研究利用复杂的技术生成CDR，但它们遭受了几何建模不足的问题。此外，常见的迭代精化策略导致了低效的推断。本文提出了一种深度生成模型，可以一次性地共同设计CDR的1D序列和3D结构。为了实现这一目标，我们将抗体CDR设计分为两个阶段：（i）蛋白质结构的几何建模和（ii）序列结构共学习。我们开发了一种蛋白质复合物不变嵌入，可捕捉蛋白质骨架原子（包括Cα、N、C和O原子）之间的内部和外部组分相互作用，以实现全面的几何建模。

    Antibodies are crucial proteins produced by the immune system in response to foreign substances or antigens. The specificity of an antibody is determined by its complementarity-determining regions (CDRs), which are located in the variable domains of the antibody chains and form the antigen-binding site. Previous studies have utilized complex techniques to generate CDRs, but they suffer from inadequate geometric modeling. Moreover, the common iterative refinement strategies lead to an inefficient inference. In this paper, we propose a deep generative model that can co-design 1D sequences and 3D structures of CDRs in a one-shot manner. To achieve this, we decouple the antibody CDR design into two stages: (i) geometric modeling of protein structures and (ii) sequence-structure co-learning. We develop a protein complex invariant embedding that captures both intra- and inter-component interactions among the backbone atoms including C$\alpha$, N, C, and O atoms to achieve comprehensive geome
    
[^93]: SemPPL: 预测伪标签以改善对比表示

    SemPPL: Predicting pseudo-labels for better contrastive representations. (arXiv:2301.05158v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2301.05158](http://arxiv.org/abs/2301.05158)

    该论文提出了一种新的半监督学习方法SemPPL，通过预测伪标签来改善对比表示，从而解决了计算机视觉中学习大量无监督数据和少量监督数据的问题。

    

    从大量无监督数据和少量监督数据中学习是计算机视觉中一个重要的开放问题。我们提出了一种新的半监督学习方法，Semantic Positives via Pseudo-Labels (SemPPL)，它结合了有标签和无标签的数据来学习信息丰富的表示。我们的方法扩展了自监督对比学习，通过选择正样本的新方法，来区分两个样本是否代表相同的基础数据。为了丰富正样本集，我们利用少量已有的真实标签通过学习到的有标签数据的嵌入来预测缺失的标签，通过k最近邻分类器实现。我们将具有相同伪标签的数据点扩展为正样本，并称之为语义正样本。我们同时学习表示和预测自动增强的伪标签，形成一个循环。

    Learning from large amounts of unsupervised data and a small amount of supervision is an important open problem in computer vision. We propose a new semi-supervised learning method, Semantic Positives via Pseudo-Labels (SemPPL), that combines labelled and unlabelled data to learn informative representations. Our method extends self-supervised contrastive learning -where representations are shaped by distinguishing whether two samples represent the same underlying datum (positives) or not (negatives) -- with a novel approach to selecting positives. To enrich the set of positives, we leverage the few existing ground-truth labels to predict the missing ones through a $k$-nearest neighbours classifier by using the learned embeddings of the labelled data. We thus extend the set of positives with datapoints having the same pseudo-label and call these semantic positives. We jointly learn the representation and predict bootstrapped pseudo-labels. This creates a reinforcing cycle. Strong init
    
[^94]: t-SMILES：用于全新分子生成的可扩展基于碎片的分子表示框架

    t-SMILES: A Scalable Fragment-based Molecular Representation Framework for De Novo Molecule Generation. (arXiv:2301.01829v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.01829](http://arxiv.org/abs/2301.01829)

    本研究提出了一种可扩展的基于碎片的分子表示框架 t-SMILES，通过引入 t-SMILES 可以显著改善分子的表示效果，并在多种任务中表现出色，优于其他经典模型。

    

    分子的有效表示是影响人工智能模型性能的关键因素。本研究引入了一种灵活的、基于碎片的多尺度分子表示框架 t-SMILES（基于树的SMILES），该框架包含三种代码算法：TSSA（带有共享原子的t-SMILES）、TSDY（带有虚拟原子的t-SMILES）和TSID（带有ID的t-SMILES）。它使用从分子图的碎片形成的全二叉树上进行广度优先搜索得到的SMILES类型字符串来描述分子。通过使用JTVAE、BRICS、MMPA和Scaffold进行系统评估，显示了构建多代码分子描述系统的可行性，各种描述相互补充，提高整体性能。此外，在资源有限的数据集上表现出色，无论模型是原始的、数据增强的还是预训练微调的。它在goa等任务中明显优于经典的SMILES、DeepSMILES、SELFIES和基准模型。

    Effective representation of molecules is a crucial factor affecting the performance of artificial intelligence models. This study introduces a flexible, fragment-based, multiscale molecular representation framework called t-SMILES (tree-based SMILES) with three code algorithms: TSSA (t-SMILES with Shared Atom), TSDY (t-SMILES with Dummy Atom) and TSID (t-SMILES with ID). It describes molecules using SMILES-type strings obtained by performing a breadth-first search on a full binary tree formed from a fragmented molecular graph. Systematic evaluations using JTVAE, BRICS, MMPA, and Scaffold show the feasibility to construct a multi-code molecular description system, where various descriptions complement each other, enhancing the overall performance. Additionally, it exhibits impressive performance on low-resource datasets, whether the model is original, data augmented, or pre-training fine-tuned. It significantly outperforms classical SMILES, DeepSMILES, SELFIES and baseline models in goa
    
[^95]: 失败目标感知的事后经验重播

    Failed Goal Aware Hindsight Experience Replay. (arXiv:2208.14741v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2208.14741](http://arxiv.org/abs/2208.14741)

    本文提出了一种称为Failed goal Aware HER (FAHER)的新方法来增强多目标强化学习中的采样效率。该方法利用实现目标与未实现目标之间的关系，并通过聚类模型对序列进行聚类和采样。

    

    在给定环境中的多目标强化学习中，代理通过与环境的交互获得的经验来学习实现多个目标的策略。在这种情况下，一个关键挑战是使用稀疏二元奖励训练代理，由于缺乏成功的经验，这可能会很困难。为了解决这个挑战，事后经验重播（HER）从不成功的经验中生成成功的经验。然而，从均匀抽样的经验中生成成功的经验的过程可能效率低下。本文提出了一种名为Failed goal Aware HER (FAHER)的新方法来增强采样效率。该方法利用了实现目标与未实现目标之间的关系，并使用聚类模型对具有不同实现目标的序列进行聚类，并在HER的方式下对经验进行采样。

    In multi-goal reinforcement learning for a given environment, agents learn policies to achieve multiple goals by using experiences gained from interactions with the environment. One of the key challenges in this setting is training agents using sparse binary rewards, which can be difficult due to a lack of successful experiences. To address this challenge, hindsight experience replay (HER) generates successful experiences from unsuccessful experiences. However, the process of generating successful experiences from uniformly sampled ones can be inefficient. In this paper, a novel approach called Failed goal Aware HER (FAHER) is proposed to enhance the sampling efficiency. The approach exploits the property of achieved goals in relation to failed goals that are defined as the original goals not achieved. The proposed method involves clustering episodes with different achieved goals using a cluster model and subsequently sampling experiences in the manner of HER. The cluster model is gene
    
[^96]: 通过模仿人类视觉经验改善泛化能力

    Improving generalization by mimicking the human visual diet. (arXiv:2206.07802v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2206.07802](http://arxiv.org/abs/2206.07802)

    本文提出了一个新的视角，通过模仿人类视觉经验的方法来缩小生物和计算机视觉之间的泛化差距。结果显示，将人类的视觉经验中的变化和上下文信息纳入模型中，显著改善了模型对真实世界变换的泛化能力，并在从合成到真实数据的过程中取得了较大的优势。

    

    我们提出了一个新的视角，用于弥合生物和计算机视觉之间的泛化差距 - 模仿人类的视觉经验。尽管计算机视觉模型依赖于互联网网站上获取的数据集，但人类是通过在自然环境中的有限3D场景中学习，并且接触到各种真实世界的变化，其中包括自然环境中的对象。我们的结果表明，将人类视觉训练数据（视觉经验）中普遍存在的变化和上下文线索纳入模型中，显著改善了对真实世界变换（如光照、视角和材料变化）的泛化能力。这种改进还扩展到从合成数据到真实世界数据的泛化 - 所有经过人类视觉经验训练的模型在自然图像数据上的测试中，均表现优于专门的架构。这些实验得益于我们的两个关键贡献：一个新颖的数据集，捕捉了场景上下文和各种真实世界的变换，以模拟人类的视觉经验，以及一个针对该数据集定制的转换模型，用于利用上下文和变换信息。

    We present a new perspective on bridging the generalization gap between biological and computer vision -- mimicking the human visual diet. While computer vision models rely on internet-scraped datasets, humans learn from limited 3D scenes under diverse real-world transformations with objects in natural context. Our results demonstrate that incorporating variations and contextual cues ubiquitous in the human visual training data (visual diet) significantly improves generalization to real-world transformations such as lighting, viewpoint, and material changes. This improvement also extends to generalizing from synthetic to real-world data -- all models trained with a human-like visual diet outperform specialized architectures by large margins when tested on natural image data. These experiments are enabled by our two key contributions: a novel dataset capturing scene context and diverse real-world transformations to mimic the human visual diet, and a transformer model tailored to leverag
    

