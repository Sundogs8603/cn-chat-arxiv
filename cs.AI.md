# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [ODIN: A Single Model for 2D and 3D Perception.](http://arxiv.org/abs/2401.02416) | ODIN是一个模型，可以同时对2D RGB图像和3D点云进行分割和标记，使用变压器架构进行2D和3D视图间的信息融合。 |
| [^2] | [LLM Augmented LLMs: Expanding Capabilities through Composition.](http://arxiv.org/abs/2401.02412) | 本文提出了CALM方法，通过组合现有的基础模型和更具体的模型，使用交叉注意力来增强模型的表示并实现新的能力。CALM可以通过“重用”现有模型和一些额外的参数和数据来扩展新任务上的模型规模，并且保留现有模型的功能。 |
| [^3] | [What You See is What You GAN: Rendering Every Pixel for High-Fidelity Geometry in 3D GANs.](http://arxiv.org/abs/2401.02411) | 本文提出了将神经体积渲染扩展到本地2D图像更高分辨率的技术，以解决3D GANs无法解决2D图像中丰富的3D几何图形的问题。 |
| [^4] | [Real-Time 2D Temperature Field Prediction in Metal Additive Manufacturing Using Physics-Informed Neural Networks.](http://arxiv.org/abs/2401.02403) | 本论文介绍了一种基于物理信息的神经网络框架，用于实时预测金属增材制造中的二维温度场。该框架结合了基于物理信息的输入、损失函数和卷积长短期记忆架构，通过使用实时温度数据，可以预测未来时间戳下不同几何形状、沉积模式和工艺的温度场。 |
| [^5] | [TinyLlama: An Open-Source Small Language Model.](http://arxiv.org/abs/2401.02385) | TinyLlama是一个开源的小型语言模型，基于Llama 2的架构和分词器，利用各种先进技术实现了更好的计算效率。尽管规模较小，但在下游任务中表现出色，明显优于其他类似规模的开源语言模型。 |
| [^6] | [Survey of 3D Human Body Pose and Shape Estimation Methods for Contemporary Dance Applications.](http://arxiv.org/abs/2401.02383) | 这项研究调查了现代舞和表演艺术中的三维人体形状和姿势估计方法，发现多帧方法在现代舞蹈表演中的姿势估计方面比单帧方法效果更好。 |
| [^7] | [A Survey Analyzing Generalization in Deep Reinforcement Learning.](http://arxiv.org/abs/2401.02349) | 本文调查了深度强化学习中的泛化性能。深度强化学习策略存在过拟合问题，限制了它们的鲁棒性和泛化能力。研究形式化和统一了提高泛化性和克服过拟合的不同解决方案。 |
| [^8] | [Mining Fine-Grained Image-Text Alignment for Zero-Shot Captioning via Text-Only Training.](http://arxiv.org/abs/2401.02347) | 通过分析CLIP潜在空间，我们发现CLIP的视觉特征可以更接近于配对的字幕，而图像-文本之间的模态差距可以经验性地建模为一个零均值的高斯分布。 |
| [^9] | [Path-based Explanation for Knowledge Graph Completion.](http://arxiv.org/abs/2401.02290) | 基于路径的KGC解释器Power-Link通过引入图加权技术，实现了可解释的知识图谱补全，推动了模型透明度和可靠性的提升。 |
| [^10] | [Uncertainty-Aware Deep Attention Recurrent Neural Network for Heterogeneous Time Series Imputation.](http://arxiv.org/abs/2401.02258) | 该论文提出了鉴于复杂数据中出现的问题，能够同时估计异质多变量时间序列中缺失值及其相关不确定性的深度关注循环神经网络插补方法。 |
| [^11] | [Policy-regularized Offline Multi-objective Reinforcement Learning.](http://arxiv.org/abs/2401.02244) | 本文将离线规范化方法扩展到多目标强化学习中，以利用离线轨迹数据训练多目标政策。在面对偏好不一致的演示问题时，提出了过滤方法和正则化技术。通过将偏好条件化标量化更新与政策规范化相结合，可以同时学习一组策略，从而降低计算成本。 |
| [^12] | [Joint Multi-Facts Reasoning Network For Complex Temporal Question Answering Over Knowledge Graph.](http://arxiv.org/abs/2401.02212) | 本研究提出了联合多事实推理网络（JMFRN）用于复杂时态问题在知识图上的问答，通过聚合实体和时间戳信息来准确回答复杂时态问题。 |
| [^13] | [LADRI: LeArning-based Dynamic Risk Indicator in Automated Driving System.](http://arxiv.org/abs/2401.02199) | 本研究提出了一种基于学习的动态风险评估框架，利用人工神经网络分析和分类实时的车载传感器数据，以提升自动驾驶系统的安全水平和情境意识。 |
| [^14] | [FairGridSearch: A Framework to Compare Fairness-Enhancing Models.](http://arxiv.org/abs/2401.02183) | 本文提出了一种比较公平性增强模型的框架FairGridSearch，通过实验不同模型参数组合并推荐最佳组合。研究结果表明，选择适当的准确度和公平性度量对模型评估非常重要。 |
| [^15] | [Shayona@SMM4H23: COVID-19 Self diagnosis classification using BERT and LightGBM models.](http://arxiv.org/abs/2401.02158) | Shayona团队在SMMH4-23中使用了BERT和LightGBM模型进行COVID-19自我诊断分类，并在任务1中取得了最高的F1分数0.94。 |
| [^16] | [Disentangle Estimation of Causal Effects from Cross-Silo Data.](http://arxiv.org/abs/2401.02154) | 引入一种新颖的解耦架构来解决跨平台数据中因果效应估计的问题，并通过引入全局约束条件来提高准确性。 |
| [^17] | [Unit Testing in ASP Revisited: Language and Test-Driven Development Environment.](http://arxiv.org/abs/2401.02153) | 本文重新审视了ASP中的单元测试语言和工具，提出了一种新的内联测试规范语言，并确定了相应任务的计算复杂度。 |
| [^18] | [Graph Neural Networks for Tabular Data Learning: A Survey with Taxonomy and Directions.](http://arxiv.org/abs/2401.02143) | 这项综述研究了使用图神经网络（GNN）进行表格数据学习（TDL）的领域。研究发现，深度学习方法在分类和回归任务方面表现出优越性能，但目前对数据实例和特征值之间潜在相关性的表达不足。GNN以其能力模拟复杂关系和相互作用，并在TDL领域得到了广泛应用。本综述对GNN4TDL方法进行了系统回顾，提供了对其演化领域的洞见，并提出了一个全面的分类。 |
| [^19] | [SyCoCa: Symmetrizing Contrastive Captioners with Attentive Masking for Multimodal Alignment.](http://arxiv.org/abs/2401.02137) | 本文提出了SyCoCa方法，通过引入全局和本地表示层面上图像和文本的双向交互，实现了多模态对齐。这种方法可以更好地理解图像和文本之间的细粒度关联。 |
| [^20] | [DCR-Consistency: Divide-Conquer-Reasoning for Consistency Evaluation and Improvement of Large Language Models.](http://arxiv.org/abs/2401.02132) | DCR-Consistency提出了一个基于划分-征服-推理方法的自动化框架，用于评估和改进大型语言模型生成文本的一致性。与传统的评估方法不同，该方法通过将段落对段落比较划分为句子对段落的比较，并根据预定义标准进行评估。 |
| [^21] | [ACP-ESM: A novel framework for classification of anticancer peptides using protein-oriented transformer approach.](http://arxiv.org/abs/2401.02124) | ACP-ESM是一个使用以蛋白质为导向的Transformer方法的新框架，用于分类抗癌肽。这种方法可以优化抗癌肽的稳定性，改善选择性，并提高对癌细胞的传递性。 |
| [^22] | [Mobile ALOHA: Learning Bimanual Mobile Manipulation with Low-Cost Whole-Body Teleoperation.](http://arxiv.org/abs/2401.02117) | 该论文介绍了一个移动ALOHA系统，用于学习双手移动操作。通过低成本的远程操作和整体身体控制，系统能够完成复杂的移动操作任务，并通过联合训练提高成功率达到90%。 |
| [^23] | [k-Winners-Take-All Ensemble Neural Network.](http://arxiv.org/abs/2401.02092) | 本论文提出了k-Winners-Take-All集合神经网络（kWTA-ENN），通过同时训练子网络来改进以往的集合方法，使用kWTA激活函数作为输出的组合方法，从而实现神经网络性能的提升。 |
| [^24] | [An Example of Evolutionary Computation + Large Language Model Beating Human: Design of Efficient Guided Local Search.](http://arxiv.org/abs/2401.02051) | 使用进化计算和大语言模型的算法进化框架，自动设计了高效的引导局部搜索算法来解决旅行商问题，在实验中表现优于人工设计的算法，标志着自动算法设计的新时代出现。 |
| [^25] | [Self-Contrast: Better Reflection Through Inconsistent Solving Perspectives.](http://arxiv.org/abs/2401.02009) | 自我对比是一种通过对比不同求解视角和总结差异，提高大型语言模型（LLM）的反思能力的方法。 |
| [^26] | [On Time-Indexing as Inductive Bias in Deep RL for Sequential Manipulation Tasks.](http://arxiv.org/abs/2401.01993) | 本论文提出一种简单的策略架构，通过按固定持续时间依次执行不同的行动头，使得深度强化学习在解决顺序操控任务时能够学习到更多的基本技能，实证评估结果显示这种结构优于标准方法。 |
| [^27] | [GPS-SSL: Guided Positive Sampling to Inject Prior Into Self-Supervised Learning.](http://arxiv.org/abs/2401.01990) | GPS-SSL是一种将先验知识注入到自监督学习中的通用方法，通过设计度量空间并利用最近邻采样生成正样本。它可以减少对强数据增强的依赖，因此在Cifar10上达到了更好的效果。 |
| [^28] | [Revisiting Zero-Shot Abstractive Summarization in the Era of Large Language Models from the Perspective of Position Bias.](http://arxiv.org/abs/2401.01989) | 这项研究通过测量位置偏见，重访了大语言模型中的零-shot 抽象摘要。研究结果揭示了模型不公平地优先考虑某些部分的信息，从而导致不可取的行为。对多个LLM模型和预训练抽象摘要模型进行的实验提供了关于零-shot 总结任务的模型性能和位置偏见的新见解和讨论。 |
| [^29] | [Towards Truly Zero-shot Compositional Visual Reasoning with LLMs as Programmers.](http://arxiv.org/abs/2401.01974) | 本文提出了一种框架来实现零样本组合视觉推理，通过引入抽象的空间和时间例程以及利用少量的nun |
| [^30] | [FMGS: Foundation Model Embedded 3D Gaussian Splatting for Holistic 3D Scene Understanding.](http://arxiv.org/abs/2401.01970) | 提出了一种新颖的方法，将视觉语言嵌入基础模型到3D高斯分割中，实现了高质量的3D场景理解。 |
| [^31] | [A Mechanistic Understanding of Alignment Algorithms: A Case Study on DPO and Toxicity.](http://arxiv.org/abs/2401.01967) | 通过研究对齐算法和预训练语言模型，本论文揭示了对齐模型的机制，并提出了一种简单的方法来取消模型的对齐，从而使其恢复有害行为。 |
| [^32] | [Instruct-Imagen: Image Generation with Multi-modal Instruction.](http://arxiv.org/abs/2401.01952) | Instruct-Imagen是一种处理异构图像生成任务并进行泛化的模型，引入了多模式指令以实现各种生成意图的统一标准化。通过微调预训练的文本到图像扩散模型，并使用检索增强的训练提升模型在外部多模态环境下的生成能力。对多样化图像生成任务的人工评估表明，该模型取得了良好的效果。 |
| [^33] | [Can We Generate Realistic Hands Only Using Convolution?.](http://arxiv.org/abs/2401.01951) | 本文展示了通过为卷积层提供具有相对$n$维笛卡尔坐标系的单一输入通道，可以缓解图像生成模型无法重现复杂几何特征的问题，显著提高了GAN和VAE生成的手部和面部图像质量。 |
| [^34] | [Generalist embedding models are better at short-context clinical semantic search than specialized embedding models.](http://arxiv.org/abs/2401.01943) | 本研究发现，在临床语义搜索方面，通用嵌入模型比专业嵌入模型表现更好，这表明现有的临床专业化模型对输入的微小变化更敏感。 |
| [^35] | [Vietnamese Poem Generation & The Prospect Of Cross-Language Poem-To-Poem Translation.](http://arxiv.org/abs/2401.01078) | 本文通过使用大型语言模型，成功提出了一种生成越南诗歌的方法，并探索了将诗歌翻译成不同语言的可能性，同时保持对生成内容的完全控制。 |
| [^36] | [Accurate Leukocyte Detection Based on Deformable-DETR and Multi-Level Feature Fusion for Aiding Diagnosis of Blood Diseases.](http://arxiv.org/abs/2401.00926) | 本文提出了一种创新的白细胞检测方法，使用多级特征融合和变形自注意DETR，通过解决白细胞尺度差异问题和提高检测精度，以改善传统血液检测的效率和准确性。 |
| [^37] | [Knowledge Enhanced Conditional Imputation for Healthcare Time-series.](http://arxiv.org/abs/2312.16713) | 本研究提出了一种知识增强的条件插补方法，针对医疗时间序列数据中的缺失数据问题。通过整合先进的知识嵌入和非均匀掩蔽策略，该方法能够灵活适应不同模式的电子健康记录中的缺失数据分布不平衡问题。 |
| [^38] | [Lookahead: An Inference Acceleration Framework for Large Language Model with Lossless Generation Accuracy.](http://arxiv.org/abs/2312.12728) | 本研究介绍了一种通用的推理加速框架，用于提高大型语言模型（LLMs）的推理速度，并在保持生成准确性的同时降低成本。该框架在支付宝的检索增强生成（RAG）系统中得到了应用。 |
| [^39] | [Continual Learning: Forget-free Winning Subnetworks for Video Representations.](http://arxiv.org/abs/2312.11973) | 本研究基于"彩票票据假设"，提出了一种连续学习方法，通过利用稀疏子网络和FSO进行任务增量学习、少样本类增量学习和视频增量学习，实现高效学习和有效的权重重用。 |
| [^40] | [Evaluating Language-Model Agents on Realistic Autonomous Tasks.](http://arxiv.org/abs/2312.11671) | 这篇论文评估了语言模型代理在现实自主任务中的表现，发现这些代理只能完成最简单的任务，对于更具挑战性的任务有一定进展。 |
| [^41] | [Perceptual Musical Features for Interpretable Audio Tagging.](http://arxiv.org/abs/2312.11234) | 本研究在自动音乐标记中探索了解释性的重要性，并构建了一个工作流来提取音频文件中的感知特征，从而训练出可解释的机器学习模型。 |
| [^42] | [One Shot Learning as Instruction Data Prospector for Large Language Models.](http://arxiv.org/abs/2312.10302) | 本研究提出了一种名为Nuggets的新颖有效方法，利用单次学习从庞大的数据集中选择高质量的指导数据，通过评估示例对多样锚定集的困惑度影响，选择对指导调优最有益的数据 |
| [^43] | [Entropy and the Kullback-Leibler Divergence for Bayesian Networks: Computational Complexity and Efficient Implementation.](http://arxiv.org/abs/2312.01520) | 本文提出了一种计算贝叶斯网络中Shannon熵和Kullback-Leibler散度的高效算法，并通过一系列数值示例进行了演示。此外，还展示了如何将高斯贝叶斯网络中KL的计算复杂度从立方降低到二次。 |
| [^44] | [DiffAttack: Evasion Attacks Against Diffusion-Based Adversarial Purification.](http://arxiv.org/abs/2311.16124) | 这篇论文介绍了DiffAttack，一个针对基于扩散的对抗净化的有效和高效攻击框架，通过引入偏差重构损失和分段式前向后向算法解决了梯度消失/爆炸的问题，验证了其攻击效果。 |
| [^45] | [TEAL: Tokenize and Embed ALL for Multi-modal Large Language Models.](http://arxiv.org/abs/2311.04589) | TEAL是一种用于多模态大语言模型的方法，将不同模态的输入视为令牌序列，并学习它们的联合嵌入空间。这使得模型能够有效地建模多模态输入之间的相互作用，并生成非文本模态的输出。 |
| [^46] | [Pre-trained Recommender Systems: A Causal Debiasing Perspective.](http://arxiv.org/abs/2310.19251) | 本文探讨了将预训练模型的范式应用于推荐系统的可能性和挑战，提出开发一种通用推荐系统，可以用于少样本学习，并在未知新领域中快速适应，以提高性能。 |
| [^47] | [DHOT-GM: Robust Graph Matching Using A Differentiable Hierarchical Optimal Transport Framework.](http://arxiv.org/abs/2310.12081) | 本研究提出了一种名为DHOT-GM的图匹配方法，使用可微分的分层最优传输框架，充分利用了图中隐藏的多模态信息，通过对匹配结果进行加权平均来推断节点对应关系。 |
| [^48] | [FactoFormer: Factorized Hyperspectral Transformers with Self-Supervised Pretraining.](http://arxiv.org/abs/2309.09431) | 该论文提出了一种Factorized Hyperspectral Transformer，结合了分解的自监督预训练流程，显著提高了性能。 |
| [^49] | [MLN-net: A multi-source medical image segmentation method for clustered microcalcifications using multiple layer normalization.](http://arxiv.org/abs/2309.02742) | 提出了一种名为MLN-net的新型框架，用于集群微钙化的准确分割。该方法能够使用单一源图像来准确地分割多源图像，通过多层归一化层结构来处理不同领域的图像分割，进而提高了泛化性能。 |
| [^50] | [Let There Be Sound: Reconstructing High Quality Speech from Silent Videos.](http://arxiv.org/abs/2308.15256) | 本文介绍了一个重建高质量语音的唇语转语音系统，通过解决一对多映射问题和细节精炼来显著改进生成质量。 |
| [^51] | [Not Only Rewards But Also Constraints: Applications on Legged Robot Locomotion.](http://arxiv.org/abs/2308.12517) | 本文提出了一种新的强化学习框架，为复杂机器人系统训练神经网络控制器。该框架引入了奖励和约束的概念，通过设计高效的策略优化算法来处理约束，以减少计算开销。通过应用于不同腿式机器人的运动控制器训练中，展示了该框架的有效性。 |
| [^52] | [Unleashing Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration.](http://arxiv.org/abs/2307.05300) | 本论文提出了单人表现提示（SPP）的概念，通过与多个角色进行多轮自我协作，将单个语言模型转化为认知协同者，从而增强其在复杂任务中的问题解决能力和整体性能。 |
| [^53] | [Provably Powerful Graph Neural Networks for Directed Multigraphs.](http://arxiv.org/abs/2306.11586) | 本文分析了一组简单的改进方法，将标准的消息传递图神经网络（GNN）转化为可证明强大的有向多图神经网络，能够检测任何有向子图模式。实验结果展示了这些改进方法在合成子图检测任务和金融犯罪分析任务上的出色性能。 |
| [^54] | [Simplifying and Empowering Transformers for Large-Graph Representations.](http://arxiv.org/abs/2306.10759) | 本文通过实验证明，在大型图上使用一层注意力即可获得令人惊讶的竞争性能，挑战了在语言和视觉任务中复杂模型的应用。这促使我们重新思考在大型图上设计Transformer的理念，以提高可扩展性。 |
| [^55] | [Learning with Noisy Labels by Adaptive Gradient-Based Outlier Removal.](http://arxiv.org/abs/2306.04502) | 本文提出了一种名为AGRA的自适应梯度异常值去除方法，能够在模型训练过程中动态调整数据集从而有效提高模型学习效果。 |
| [^56] | [Quantifying Deep Learning Model Uncertainty in Conformal Prediction.](http://arxiv.org/abs/2306.00876) | 本文针对深度学习模型的不确定性进行了量化，采用了符合性预测框架来计算模型的置信水平，并与其他不确定性量化方法进行了比较。 |
| [^57] | [STAS: Spatial-Temporal Return Decomposition for Multi-agent Reinforcement Learning.](http://arxiv.org/abs/2304.07520) | 提出了一种名为STAS的新方法，用于多智能体强化学习中时空回报分解，可以对代理进行信用分配。该方法引入了Shapley值和空间-时间注意机制来解决先前方法中延迟全局回报的复杂关系问题。在各种基准环境下，该方法表现良好。 |
| [^58] | [Learning to Generalize towards Unseen Domains via a Content-Aware Style Invariant Model for Disease Detection from Chest X-rays.](http://arxiv.org/abs/2302.13991) | 通过内容感知的风格不变模型，我们提出了一种解决深度学习医学图像分析中源领域不匹配挑战的方法。我们采用了风格随机化模块来提取既是风格不变又是内容偏好的领域不变特征，在胸部X射线疾病检测中取得了良好的性能。 |
| [^59] | [Anatomy-aware and acquisition-agnostic joint registration with SynthMorph.](http://arxiv.org/abs/2301.11329) | SynthMorph是一个易于使用的DL工具，用于无需预处理即可直接从MRI扫描仪上对任何脑图像进行联合仿射-可变形配准，采用了从标签图生成具有极大差异图像的策略，实现了更准确和鲁棒的图像配准。 |
| [^60] | [A First Runtime Analysis of the NSGA-II on a Multimodal Problem.](http://arxiv.org/abs/2204.13750) | 本论文对多目标进化优化器NSGA-II在多模式问题上的运行时间进行了第一次分析，证明了当种群大小足够大时，NSGA-II能够在时间复杂度为O(N n^k)内优化OneJumpZeroJump基准问题，且使用快速突变算子可以提高优化效果。 |
| [^61] | [Data Valuation for Vertical Federated Learning: A Model-free and Privacy-preserving Method.](http://arxiv.org/abs/2112.08364) | 提出了一种垂直联合学习中的数据价值评估方法FedValue，该方法是隐私保护、针对任务而无需模型的。它包括数据价值度量MShapley-CMI和联合计算方法，有助于解决垂直联合学习中评估数据方数据价值的问题。 |
| [^62] | [Handling Noisy Labels via One-Step Abductive Multi-Target Learning and Its Application to Helicobacter Pylori Segmentation.](http://arxiv.org/abs/2011.14956) | 本文研究了处理噪声标签的新方法，特别针对医学组织病理学图像分析中的困难情况。通过一步式绳索多目标学习，该方法克服了标签中存在的复杂噪声和评估策略不明确的问题。 |
| [^63] | [Sample-efficient Reinforcement Learning in Robotic Table Tennis.](http://arxiv.org/abs/2011.03275) | 这篇论文研究了机器人乒乓球中的高效样本增强学习算法，通过嵌入到机器人系统中，在少数尝试中实现了高效学习。 |

# 详细

[^1]: ODIN: 一个用于2D和3D感知的单一模型

    ODIN: A Single Model for 2D and 3D Perception. (arXiv:2401.02416v1 [cs.CV])

    [http://arxiv.org/abs/2401.02416](http://arxiv.org/abs/2401.02416)

    ODIN是一个模型，可以同时对2D RGB图像和3D点云进行分割和标记，使用变压器架构进行2D和3D视图间的信息融合。

    

    目前的先进模型在像ScanNet这样的当代3D感知基准上使用并标记依赖于数据集提供的3D点云，该点云是通过对感知到的多视角RGB-D图像进行后处理获得的。它们通常在领域内进行训练，放弃了大规模的2D预训练，并且胜过将姿态RGB-D多视角图像进行特征化的替代方案。消耗姿态图像和后处理的3D点云之间的性能差距，加剧了2D和3D感知需要不同模型架构的观点。在本文中，我们挑战这个观点，并提出ODIN（Omni-Dimensional INstance segmentation），一种能够使用变压器架构对2D RGB图像和3D点云进行分割和标记的模型，该模型通过交替的2D视图内和3D视图间信息融合来区分2D和3D特征操作，利用涉及的令牌的位置编码来捕捉2D补丁令牌和3D坐标的像素坐标。

    State-of-the-art models on contemporary 3D perception benchmarks like ScanNet consume and label dataset-provided 3D point clouds, obtained through post processing of sensed multiview RGB-D images. They are typically trained in-domain, forego large-scale 2D pre-training and outperform alternatives that featurize the posed RGB-D multiview images instead. The gap in performance between methods that consume posed images versus post-processed 3D point clouds has fueled the belief that 2D and 3D perception require distinct model architectures. In this paper, we challenge this view and propose ODIN (Omni-Dimensional INstance segmentation), a model that can segment and label both 2D RGB images and 3D point clouds, using a transformer architecture that alternates between 2D within-view and 3D cross-view information fusion. Our model differentiates 2D and 3D feature operations through the positional encodings of the tokens involved, which capture pixel coordinates for 2D patch tokens and 3D coor
    
[^2]: LLM增强的LLMs：通过组合扩展功能

    LLM Augmented LLMs: Expanding Capabilities through Composition. (arXiv:2401.02412v1 [cs.LG])

    [http://arxiv.org/abs/2401.02412](http://arxiv.org/abs/2401.02412)

    本文提出了CALM方法，通过组合现有的基础模型和更具体的模型，使用交叉注意力来增强模型的表示并实现新的能力。CALM可以通过“重用”现有模型和一些额外的参数和数据来扩展新任务上的模型规模，并且保留现有模型的功能。

    

    在大型数据集上训练的具有数十亿个参数的基础模型已经展现出在各个领域具有非平凡技能。然而，由于它们的整体结构，对它们进行增强或赋予新的技能是具有挑战性和成本高昂的。另一方面，由于其适应能力，正在训练多个新领域和任务的模型实例。在这项工作中，我们研究了利用现有的基础模型与更具体模型进行高效实用的组合，以实现新的功能。为此，我们提出了CALM -用于增强语言模型的组合模型-，它引入了模型之间的交叉注意力，以组合它们的表示并实现新的能力。CALM的显著特点包括：(i)通过“重用”现有LLMs和一些额外的参数和数据来扩展新任务上的LLMs的规模，(ii)保持现有模型权重不变，从而保留现有功能，(iii)应用新功能只需要对增加的模型进行微调。

    Foundational models with billions of parameters which have been trained on large corpora of data have demonstrated non-trivial skills in a variety of domains. However, due to their monolithic structure, it is challenging and expensive to augment them or impart new skills. On the other hand, due to their adaptation abilities, several new instances of these models are being trained towards new domains and tasks. In this work, we study the problem of efficient and practical composition of existing foundation models with more specific models to enable newer capabilities. To this end, we propose CALM -Composition to Augment Language Models -- which introduces cross-attention between models to compose their representations and enable new capabilities. Salient features of CALM are: (i) Scales up LLMs on new tasks by 're-using' existing LLMs along with a few additional parameters and data, (ii) Existing model weights are kept intact, and hence preserves existing capabilities, and (iii) Appli
    
[^3]: 你所见即所GAN: 在3D GAN中为高保真度几何图形渲染每个像素

    What You See is What You GAN: Rendering Every Pixel for High-Fidelity Geometry in 3D GANs. (arXiv:2401.02411v1 [cs.CV])

    [http://arxiv.org/abs/2401.02411](http://arxiv.org/abs/2401.02411)

    本文提出了将神经体积渲染扩展到本地2D图像更高分辨率的技术，以解决3D GANs无法解决2D图像中丰富的3D几何图形的问题。

    

    3D感知生成对抗网络(GANs)在通过神经体积渲染从2D图像集合中学习生成多视角一致的图像和场景3D几何图形方面取得了显著进展。然而，体积渲染中密集采样导致的显著内存和计算开销迫使3D GANs采用基于块的训练或采用低分辨率渲染与后处理的2D超分辨率，这损害了多视角一致性和解决几何图形的质量。因此，3D GANs尚不能完全解决2D图像中丰富的3D几何图形。在本文中，我们提出了将神经体积渲染扩展到本地2D图像更高分辨率的技术，因此能以前所未有的细节解决细粒度的3D几何图形。我们的方法使用基于学习的采样器来加速3D GAN训练中的神经渲染，使用更少的深度采样次数高达5倍。这使我们能够明确地“渲染每个像素”。

    3D-aware Generative Adversarial Networks (GANs) have shown remarkable progress in learning to generate multi-view-consistent images and 3D geometries of scenes from collections of 2D images via neural volume rendering. Yet, the significant memory and computational costs of dense sampling in volume rendering have forced 3D GANs to adopt patch-based training or employ low-resolution rendering with post-processing 2D super resolution, which sacrifices multiview consistency and the quality of resolved geometry. Consequently, 3D GANs have not yet been able to fully resolve the rich 3D geometry present in 2D images. In this work, we propose techniques to scale neural volume rendering to the much higher resolution of native 2D images, thereby resolving fine-grained 3D geometry with unprecedented detail. Our approach employs learning-based samplers for accelerating neural rendering for 3D GAN training using up to 5 times fewer depth samples. This enables us to explicitly "render every pixel" o
    
[^4]: 金属增材制造中基于物理信息的神经网络实时二维温度场预测

    Real-Time 2D Temperature Field Prediction in Metal Additive Manufacturing Using Physics-Informed Neural Networks. (arXiv:2401.02403v1 [cs.LG])

    [http://arxiv.org/abs/2401.02403](http://arxiv.org/abs/2401.02403)

    本论文介绍了一种基于物理信息的神经网络框架，用于实时预测金属增材制造中的二维温度场。该框架结合了基于物理信息的输入、损失函数和卷积长短期记忆架构，通过使用实时温度数据，可以预测未来时间戳下不同几何形状、沉积模式和工艺的温度场。

    

    准确预测金属增材制造过程中的温度场对于防止过热、调整工艺参数和确保工艺稳定性至关重要。虽然基于物理的计算模型提供了精确性，但往往耗时且不适用于迭代设计场景中的实时预测和在线控制。相反，机器学习模型严重依赖高质量数据集，而在金属增材制造领域内获得这样的数据集往往成本高且具有挑战性。我们的工作通过引入一种专门针对金属增材制造中温度场预测的基于物理信息的神经网络框架来解决这个问题。该框架包括基于物理信息的输入、基于物理信息的损失函数和卷积长短期记忆(ConvLSTM)架构。利用工艺过程中的实时温度数据，我们的模型预测未来时间戳下各种几何形状、沉积模式和工艺的二维温度场。

    Accurately predicting the temperature field in metal additive manufacturing (AM) processes is critical to preventing overheating, adjusting process parameters, and ensuring process stability. While physics-based computational models offer precision, they are often time-consuming and unsuitable for real-time predictions and online control in iterative design scenarios. Conversely, machine learning models rely heavily on high-quality datasets, which can be costly and challenging to obtain within the metal AM domain. Our work addresses this by introducing a physics-informed neural network framework specifically designed for temperature field prediction in metal AM. This framework incorporates a physics-informed input, physics-informed loss function, and a Convolutional Long Short-Term Memory (ConvLSTM) architecture. Utilizing real-time temperature data from the process, our model predicts 2D temperature fields for future timestamps across diverse geometries, deposition patterns, and proce
    
[^5]: TinyLlama：一个开源的小型语言模型

    TinyLlama: An Open-Source Small Language Model. (arXiv:2401.02385v1 [cs.CL])

    [http://arxiv.org/abs/2401.02385](http://arxiv.org/abs/2401.02385)

    TinyLlama是一个开源的小型语言模型，基于Llama 2的架构和分词器，利用各种先进技术实现了更好的计算效率。尽管规模较小，但在下游任务中表现出色，明显优于其他类似规模的开源语言模型。

    

    我们介绍了TinyLlama，一个有限的1.1B语言模型，大约预训练了1万亿个标记，训练轮数约为3轮。TinyLlama基于Llama 2的架构和分词器，在开源社区的贡献基础上（例如FlashAttention），利用各种先进技术实现了更好的计算效率。尽管规模相对较小，TinyLlama在一系列下游任务中展示了出色的性能。它明显优于具有类似规模的现有开源语言模型。我们的模型检查点和代码可在GitHub上公开获取，网址为https://github.com/jzhang38/TinyLlama。

    We present TinyLlama, a compact 1.1B language model pretrained on around 1 trillion tokens for approximately 3 epochs. Building on the architecture and tokenizer of Llama 2, TinyLlama leverages various advances contributed by the open-source community (e.g., FlashAttention), achieving better computational efficiency. Despite its relatively small size, TinyLlama demonstrates remarkable performance in a series of downstream tasks. It significantly outperforms existing open-source language models with comparable sizes. Our model checkpoints and code are publicly available on GitHub at https://github.com/jzhang38/TinyLlama.
    
[^6]: 现代舞应用中三维人体姿势和形状估计方法调查

    Survey of 3D Human Body Pose and Shape Estimation Methods for Contemporary Dance Applications. (arXiv:2401.02383v1 [cs.CV])

    [http://arxiv.org/abs/2401.02383](http://arxiv.org/abs/2401.02383)

    这项研究调查了现代舞和表演艺术中的三维人体形状和姿势估计方法，发现多帧方法在现代舞蹈表演中的姿势估计方面比单帧方法效果更好。

    

    从RGB图像中估计三维人体形状和姿势是一个具有挑战性的问题，具有增强/虚拟现实、医疗保健和健身技术以及虚拟零售等潜在应用。最近的解决方案主要关注三种类型的输入：i）单个图像，ii）多视图图像和iii）视频。在这项研究中，我们调查并比较了现代舞和表演艺术中的三维人体形状和姿势估计方法，特别关注人体姿势和穿着、摄像机视角、照明条件和背景条件。我们证明了对于现代舞蹈表演中的姿势估计，如PHALP这样的多帧方法比单帧方法提供更好的结果。

    3D human body shape and pose estimation from RGB images is a challenging problem with potential applications in augmented/virtual reality, healthcare and fitness technology and virtual retail. Recent solutions have focused on three types of inputs: i) single images, ii) multi-view images and iii) videos. In this study, we surveyed and compared 3D body shape and pose estimation methods for contemporary dance and performing arts, with a special focus on human body pose and dressing, camera viewpoint, illumination conditions and background conditions. We demonstrated that multi-frame methods, such as PHALP, provide better results than single-frame method for pose estimation when dancers are performing contemporary dances.
    
[^7]: 分析深度强化学习中泛化性能的调查

    A Survey Analyzing Generalization in Deep Reinforcement Learning. (arXiv:2401.02349v1 [cs.LG])

    [http://arxiv.org/abs/2401.02349](http://arxiv.org/abs/2401.02349)

    本文调查了深度强化学习中的泛化性能。深度强化学习策略存在过拟合问题，限制了它们的鲁棒性和泛化能力。研究形式化和统一了提高泛化性和克服过拟合的不同解决方案。

    

    利用深度神经网络解决高维状态或动作空间中的问题，强化学习研究在实践中取得了重要的成功和关注。尽管深度强化学习策略目前在许多领域中正在被应用，从医疗应用到自动驾驶车辆，但关于深度强化学习策略的泛化能力仍有许多待解答的问题。在本文中，我们将概述深度强化学习策略遇到过拟合问题的根本原因，限制了它们的鲁棒性和泛化能力。此外，我们将对提高泛化性和克服状态-动作值函数中的过拟合的不同解决方案进行形式化和统一。我们相信我们的研究可以为当前深度强化学习的进展提供一个简洁系统的统一分析，并有助于构建健壮的深度神经网络策略。

    Reinforcement learning research obtained significant success and attention with the utilization of deep neural networks to solve problems in high dimensional state or action spaces. While deep reinforcement learning policies are currently being deployed in many different fields from medical applications to self driving vehicles, there are still ongoing questions the field is trying to answer on the generalization capabilities of deep reinforcement learning policies. In this paper, we will outline the fundamental reasons why deep reinforcement learning policies encounter overfitting problems that limit their robustness and generalization capabilities. Furthermore, we will formalize and unify the diverse solution approaches to increase generalization, and overcome overfitting in state-action value functions. We believe our study can provide a compact systematic unified analysis for the current advancements in deep reinforcement learning, and help to construct robust deep neural policies 
    
[^8]: 通过纯文本训练挖掘细粒度图像-文本对齐进行零样本字幕生成

    Mining Fine-Grained Image-Text Alignment for Zero-Shot Captioning via Text-Only Training. (arXiv:2401.02347v1 [cs.CV])

    [http://arxiv.org/abs/2401.02347](http://arxiv.org/abs/2401.02347)

    通过分析CLIP潜在空间，我们发现CLIP的视觉特征可以更接近于配对的字幕，而图像-文本之间的模态差距可以经验性地建模为一个零均值的高斯分布。

    

    图像字幕的目标是生成对图像进行描述的有意义的文本描述，从而实现广泛的视觉-语言应用。先前的研究表明，利用对比图像语言预训练（CLIP）的力量可以有望实现零样本字幕生成，消除了昂贵的字幕注释的需求。然而，CLIP潜在空间中普遍存在的模态差距破坏了图像-文本特征之间的对齐，从而影响了零样本字幕生成的性能。为了解决这个问题，我们对CLIP潜在空间进行了分析，得出了两个发现。首先，我们观察到，由于文本描述中固有的信息损失，CLIP图像子区域的视觉特征可以更接近于配对的字幕。另外，我们展示了配对的图像-文本之间的模态差距可以经验性地建模为一个零均值的高斯分布。受到这些发现的启发，我们...

    Image captioning aims at generating descriptive and meaningful textual descriptions of images, enabling a broad range of vision-language applications. Prior works have demonstrated that harnessing the power of Contrastive Image Language Pre-training (CLIP) offers a promising approach to achieving zero-shot captioning, eliminating the need for expensive caption annotations. However, the widely observed modality gap in the latent space of CLIP harms the performance of zero-shot captioning by breaking the alignment between paired image-text features. To address this issue, we conduct an analysis on the CLIP latent space which leads to two findings. Firstly, we observe that the CLIP's visual feature of image subregions can achieve closer proximity to the paired caption due to the inherent information loss in text descriptions. In addition, we show that the modality gap between a paired image-text can be empirically modeled as a zero-mean Gaussian distribution. Motivated by the findings, we
    
[^9]: 基于路径的知识图谱补全的解释方法

    Path-based Explanation for Knowledge Graph Completion. (arXiv:2401.02290v1 [cs.LG])

    [http://arxiv.org/abs/2401.02290](http://arxiv.org/abs/2401.02290)

    基于路径的KGC解释器Power-Link通过引入图加权技术，实现了可解释的知识图谱补全，推动了模型透明度和可靠性的提升。

    

    近年来，图神经网络（GNNs）通过建模实体和关系的交互在知识图谱补全（KGC）任务中取得了巨大成功。然而，对预测结果的解释却没有得到必要的关注。对基于GNN的KGC模型结果进行适当解释，可以增加模型的透明度，并帮助研究人员开发更可靠的模型。现有的KGC解释方法主要依赖于实例/子图的方法，而在某些场景下，路径可以提供更友好和可解释的解释。然而，还没有对生成基于路径的知识图谱解释方法进行充分探索。为了填补这一空白，我们提出了Power-Link，这是第一个探索基于路径的KGC解释器。我们设计了一种新颖的图加权技术，使得可以以完全可并行化和内存高效的训练方案生成基于路径的解释。我们还引入了三个新的度量指标，用于评估解释的质量和有效性。

    Graph Neural Networks (GNNs) have achieved great success in Knowledge Graph Completion (KGC) by modelling how entities and relations interact in recent years. However, the explanation of the predicted facts has not caught the necessary attention. Proper explanations for the results of GNN-based KGC models increase model transparency and help researchers develop more reliable models. Existing practices for explaining KGC tasks rely on instance/subgraph-based approaches, while in some scenarios, paths can provide more user-friendly and interpretable explanations. Nonetheless, the methods for generating path-based explanations for KGs have not been well-explored. To address this gap, we propose Power-Link, the first path-based KGC explainer that explores GNN-based models. We design a novel simplified graph-powering technique, which enables the generation of path-based explanations with a fully parallelisable and memory-efficient training scheme. We further introduce three new metrics for 
    
[^10]: 不确定性感知的深度关注循环神经网络用于异质时间序列插补

    Uncertainty-Aware Deep Attention Recurrent Neural Network for Heterogeneous Time Series Imputation. (arXiv:2401.02258v1 [cs.LG])

    [http://arxiv.org/abs/2401.02258](http://arxiv.org/abs/2401.02258)

    该论文提出了鉴于复杂数据中出现的问题，能够同时估计异质多变量时间序列中缺失值及其相关不确定性的深度关注循环神经网络插补方法。

    

    多变量时间序列中普遍存在缺失，给可靠的下游分析带来了障碍。尽管递归网络插补达到了最先进的水平，但现有模型不能扩展到可以缓解复杂数据中出现的问题的深度结构。此外，插补还存在估计地面真值偏差的风险。然而，对插补值的置信度始终是未被测量的或从模型输出后计算的。我们提出了DEep Attention Recurrent Imputation (DEARI)，它在异质多变量时间序列中同时估计缺失值及其相关的不确定性。通过联合表示特征相关性和时序动态，我们采用了自注意机制和有效的残差组件，实现了一个具有良好插补性能和稳定收敛性的深度循环神经网络。我们还利用自监督度量学习来通过优化样本相似性来提高性能。

    Missingness is ubiquitous in multivariate time series and poses an obstacle to reliable downstream analysis. Although recurrent network imputation achieved the SOTA, existing models do not scale to deep architectures that can potentially alleviate issues arising in complex data. Moreover, imputation carries the risk of biased estimations of the ground truth. Yet, confidence in the imputed values is always unmeasured or computed post hoc from model output. We propose DEep Attention Recurrent Imputation (DEARI), which jointly estimates missing values and their associated uncertainty in heterogeneous multivariate time series. By jointly representing feature-wise correlations and temporal dynamics, we adopt a self attention mechanism, along with an effective residual component, to achieve a deep recurrent neural network with good imputation performance and stable convergence. We also leverage self-supervised metric learning to boost performance by optimizing sample similarity. Finally, we 
    
[^11]: 政策规范化的离线多目标强化学习

    Policy-regularized Offline Multi-objective Reinforcement Learning. (arXiv:2401.02244v1 [cs.LG])

    [http://arxiv.org/abs/2401.02244](http://arxiv.org/abs/2401.02244)

    本文将离线规范化方法扩展到多目标强化学习中，以利用离线轨迹数据训练多目标政策。在面对偏好不一致的演示问题时，提出了过滤方法和正则化技术。通过将偏好条件化标量化更新与政策规范化相结合，可以同时学习一组策略，从而降低计算成本。

    

    本文旨在利用仅使用离线轨迹数据来训练多目标强化学习的政策。我们将广泛采用的用于单目标离线强化学习问题的离线规范化方法扩展到多目标设置，以实现上述目标。然而，在离线多目标强化学习中，这样的方法面临新的挑战，即偏好不一致的演示问题。我们提出了两种解决这个问题的方法：1）通过近似行为偏好来过滤出偏好不一致的演示，和2）采用具有高策略表达能力的正则化技术。此外，我们将偏好条件化标量化更新方法融入到政策规范化的离线强化学习中，以使用单个策略网络同时学习一组策略，从而减少为各种偏好训练大量个体策略所产生的计算成本。最后，我们引入了正则化权重调整方法...

    In this paper, we aim to utilize only offline trajectory data to train a policy for multi-objective RL. We extend the offline policy-regularized method, a widely-adopted approach for single-objective offline RL problems, into the multi-objective setting in order to achieve the above goal. However, such methods face a new challenge in offline MORL settings, namely the preference-inconsistent demonstration problem. We propose two solutions to this problem: 1) filtering out preference-inconsistent demonstrations via approximating behavior preferences, and 2) adopting regularization techniques with high policy expressiveness. Moreover, we integrate the preference-conditioned scalarized update method into policy-regularized offline RL, in order to simultaneously learn a set of policies using a single policy network, thus reducing the computational cost induced by the training of a large number of individual policies for various preferences. Finally, we introduce Regularization Weight Adapta
    
[^12]: 联合多事实推理网络用于复杂时态问题在知识图上的问答

    Joint Multi-Facts Reasoning Network For Complex Temporal Question Answering Over Knowledge Graph. (arXiv:2401.02212v1 [cs.CL])

    [http://arxiv.org/abs/2401.02212](http://arxiv.org/abs/2401.02212)

    本研究提出了联合多事实推理网络（JMFRN）用于复杂时态问题在知识图上的问答，通过聚合实体和时间戳信息来准确回答复杂时态问题。

    

    时间知识图（TKG）是在常规知识图的基础上加入时间范围的扩展。现有的时间知识图问答（TKGQA）模型仅处理简单问题，因为它们先前假设每个问题只包含一个具有显式/隐式时间约束的时间事实。因此，它们对于具有多个时间事实的问题表现较差。在本文中，我们提出了联合多事实推理网络（JMFRN），用于准确回答复杂时态问题。具体地，JMFRN首先从TKG中检索与给定复杂问题的每个实体相关的时间事实。为了进行联合推理，我们设计了两个不同的注意力模块（即实体感知和时间感知），适用于通用设置，以聚合实体和时间戳信息。

    Temporal Knowledge Graph (TKG) is an extension of regular knowledge graph by attaching the time scope. Existing temporal knowledge graph question answering (TKGQA) models solely approach simple questions, owing to the prior assumption that each question only contains a single temporal fact with explicit/implicit temporal constraints. Hence, they perform poorly on questions which own multiple temporal facts. In this paper, we propose \textbf{\underline{J}}oint \textbf{\underline{M}}ulti \textbf{\underline{F}}acts \textbf{\underline{R}}easoning \textbf{\underline{N}}etwork (JMFRN), to jointly reasoning multiple temporal facts for accurately answering \emph{complex} temporal questions. Specifically, JMFRN first retrieves question-related temporal facts from TKG for each entity of the given complex question. For joint reasoning, we design two different attention (\ie entity-aware and time-aware) modules, which are suitable for universal settings, to aggregate entities and timestamps inform
    
[^13]: LADRI: 基于学习的自动驾驶系统中的动态风险指标

    LADRI: LeArning-based Dynamic Risk Indicator in Automated Driving System. (arXiv:2401.02199v1 [eess.SY])

    [http://arxiv.org/abs/2401.02199](http://arxiv.org/abs/2401.02199)

    本研究提出了一种基于学习的动态风险评估框架，利用人工神经网络分析和分类实时的车载传感器数据，以提升自动驾驶系统的安全水平和情境意识。

    

    随着自动驾驶系统（ADS）的演进，智能交通的视野不断扩大，确保极其安全变得比以往任何时候都更为迫切。传统的风险评估方法主要用于人工驾驶的车辆，无法充分适应ADS多方面、不断演变的环境。本文引入了一种基于人工神经网络（ANN）的实时动态风险评估（DRA）框架。我们提出的解决方案突破了这些限制，利用深度学习的核心部分——ANN，通过分析和分类实时的车载传感器（OBS）数据来细致地分析和分类风险维度。这种以学习为中心的方法不仅提升了ADS的情境意识，还丰富了其对即时运行环境的理解。通过分析OBS数据，系统能够准确定位其当前的风险配置文件，从而提高了乘客和更广泛旅途中的安全前景。

    As the horizon of intelligent transportation expands with the evolution of Automated Driving Systems (ADS), ensuring paramount safety becomes more imperative than ever. Traditional risk assessment methodologies, primarily crafted for human-driven vehicles, grapple to adequately adapt to the multifaceted, evolving environments of ADS. This paper introduces a framework for real-time Dynamic Risk Assessment (DRA) in ADS, harnessing the potency of Artificial Neural Networks (ANNs).  Our proposed solution transcends these limitations, drawing upon ANNs, a cornerstone of deep learning, to meticulously analyze and categorize risk dimensions using real-time On-board Sensor (OBS) data. This learning-centric approach not only elevates the ADS's situational awareness but also enriches its understanding of immediate operational contexts. By dissecting OBS data, the system is empowered to pinpoint its current risk profile, thereby enhancing safety prospects for onboard passengers and the broader tr
    
[^14]: 公平性增强模型比较的框架: FairGridSearch

    FairGridSearch: A Framework to Compare Fairness-Enhancing Models. (arXiv:2401.02183v1 [cs.LG])

    [http://arxiv.org/abs/2401.02183](http://arxiv.org/abs/2401.02183)

    本文提出了一种比较公平性增强模型的框架FairGridSearch，通过实验不同模型参数组合并推荐最佳组合。研究结果表明，选择适当的准确度和公平性度量对模型评估非常重要。

    

    机器学习模型在关键决策应用中的使用越来越多。然而，这些模型容易复制或甚至放大现实世界数据中的偏见。尽管文献中存在各种偏见缓解方法和基本估计器，但选择特定应用的最佳模型仍然具有挑战性。本文针对二元分类，提出了一种新颖的比较公平性增强模型的框架FairGridSearch。FairGridSearch通过实验不同模型参数组合，并推荐最佳组合。本研究将FairGridSearch应用于三个流行数据集(成年人、COMPAS和德国信用)，并分析度量选择、基本估计器选择和分类阈值对模型公平性的影响。结果突出了选择合适的准确度和公平性度量对模型评估的重要性。此外，不同的基本估计器和分类阈值也会对模型的公平性产生影响。

    Machine learning models are increasingly used in critical decision-making applications. However, these models are susceptible to replicating or even amplifying bias present in real-world data. While there are various bias mitigation methods and base estimators in the literature, selecting the optimal model for a specific application remains challenging.  This paper focuses on binary classification and proposes FairGridSearch, a novel framework for comparing fairness-enhancing models. FairGridSearch enables experimentation with different model parameter combinations and recommends the best one. The study applies FairGridSearch to three popular datasets (Adult, COMPAS, and German Credit) and analyzes the impacts of metric selection, base estimator choice, and classification threshold on model fairness.  The results highlight the significance of selecting appropriate accuracy and fairness metrics for model evaluation. Additionally, different base estimators and classification threshold va
    
[^15]: Shayona@SMM4H23：使用BERT和LightGBM模型进行COVID-19自我诊断分类

    Shayona@SMM4H23: COVID-19 Self diagnosis classification using BERT and LightGBM models. (arXiv:2401.02158v1 [cs.CL])

    [http://arxiv.org/abs/2401.02158](http://arxiv.org/abs/2401.02158)

    Shayona团队在SMMH4-23中使用了BERT和LightGBM模型进行COVID-19自我诊断分类，并在任务1中取得了最高的F1分数0.94。

    

    本文描述了Shayona团队在SMMH4-23的共享任务1和4中的方法和结果。共享任务1是对自报COVID-19诊断的英文推文进行二分类，共享任务4是对自报社交焦虑障碍诊断的英文Reddit帖子进行二分类。我们的团队在任务1中取得了所有参与者中最高的F1分数0.94。我们在两个任务中都使用了Transformer模型（BERT）和LightGBM模型进行处理。

    This paper describes approaches and results for shared Task 1 and 4 of SMMH4-23 by Team Shayona. Shared Task-1 was binary classification of english tweets self-reporting a COVID-19 diagnosis, and Shared Task-4 was Binary classification of English Reddit posts self-reporting a social anxiety disorder diagnosis. Our team has achieved the highest f1-score 0.94 in Task-1 among all participants. We have leveraged the Transformer model (BERT) in combination with the LightGBM model for both tasks.
    
[^16]: 跨平台数据中的因果效应估计方法

    Disentangle Estimation of Causal Effects from Cross-Silo Data. (arXiv:2401.02154v1 [cs.LG])

    [http://arxiv.org/abs/2401.02154](http://arxiv.org/abs/2401.02154)

    引入一种新颖的解耦架构来解决跨平台数据中因果效应估计的问题，并通过引入全局约束条件来提高准确性。

    

    在诸如药物研发等关键领域，估计不同事件之间的因果效应非常重要。然而，与事件相关的数据特征可能分布在不同的平台上，并且在各方之间保持私密，阻碍了它们之间的直接信息交流。这反过来可能导致局部因果效应的估计存在偏差，依赖于仅子集协变量的特征。为了解决这个挑战，我们引入了一种创新的解耦架构，旨在通过共享和私有分支的组合促进模型参数的无缝跨平台传递，丰富因果机制。此外，我们引入了全局约束条件来有效减轻各个缺失域内的偏差，从而提高了我们因果效应估计的准确性。在新的半合成数据集上进行的大量实验证明，我们的方法优于最先进的方法。

    Estimating causal effects among different events is of great importance to critical fields such as drug development. Nevertheless, the data features associated with events may be distributed across various silos and remain private within respective parties, impeding direct information exchange between them. This, in turn, can result in biased estimations of local causal effects, which rely on the characteristics of only a subset of the covariates. To tackle this challenge, we introduce an innovative disentangle architecture designed to facilitate the seamless cross-silo transmission of model parameters, enriched with causal mechanisms, through a combination of shared and private branches. Besides, we introduce global constraints into the equation to effectively mitigate bias within the various missing domains, thereby elevating the accuracy of our causal effect estimation. Extensive experiments conducted on new semi-synthetic datasets show that our method outperforms state-of-the-art b
    
[^17]: ASP中的单元测试重新审视：语言和测试驱动开发环境

    Unit Testing in ASP Revisited: Language and Test-Driven Development Environment. (arXiv:2401.02153v1 [cs.SE])

    [http://arxiv.org/abs/2401.02153](http://arxiv.org/abs/2401.02153)

    本文重新审视了ASP中的单元测试语言和工具，提出了一种新的内联测试规范语言，并确定了相应任务的计算复杂度。

    

    单元测试框架现如今被视为一种最佳实践，几乎包含在所有现代软件开发过程中，以实现快速开发正确的规范。Answer Set Programming（ASP）等知识表示和推理范例在工业级应用中也不例外。事实上，ASPIDE开发环境的首个ASP单元测试规范语言是在2011年提出的。随后，在LANA注释语言中包含了更加可移植的单元测试语言。本文重新审视了ASP中的两种语言和工具以进行单元测试。我们提出了一种新的单元测试规范语言，可以在ASP程序内联测试，并确定与检查各种程序正确性断言相关的任务的计算复杂度。用例规范对传统评估来说是透明的，但可以由特定的测试工具解释。

    Unit testing frameworks are nowadays considered a best practice, included in almost all modern software development processes, to achieve rapid development of correct specifications. Knowledge representation and reasoning paradigms such as Answer Set Programming (ASP), that have been used in industry-level applications, are not an exception. Indeed, the first unit testing specification language for ASP was proposed in 2011 as a feature of the ASPIDE development environment. Later, a more portable unit testing language was included in the LANA annotation language. In this paper we revisit both languages and tools for unit testing in ASP. We propose a new unit test specification language that allows one to inline tests within ASP programs, and we identify the computational complexity of the tasks associated with checking the various program-correctness assertions. Test-case specifications are transparent to the traditional evaluation, but can be interpreted by a specific testing tool. Th
    
[^18]: 图神经网络在表格数据学习中的应用：一项带有分类和方向的综述

    Graph Neural Networks for Tabular Data Learning: A Survey with Taxonomy and Directions. (arXiv:2401.02143v1 [cs.LG])

    [http://arxiv.org/abs/2401.02143](http://arxiv.org/abs/2401.02143)

    这项综述研究了使用图神经网络（GNN）进行表格数据学习（TDL）的领域。研究发现，深度学习方法在分类和回归任务方面表现出优越性能，但目前对数据实例和特征值之间潜在相关性的表达不足。GNN以其能力模拟复杂关系和相互作用，并在TDL领域得到了广泛应用。本综述对GNN4TDL方法进行了系统回顾，提供了对其演化领域的洞见，并提出了一个全面的分类。

    

    在这项综述中，我们深入研究了使用图神经网络（GNN）进行表格数据学习（TDL）的领域，与传统方法相比，基于深度学习的方法在分类和回归任务中显示出优越的性能。该综述突出了深度神经TDL方法中的一个关键差距：数据实例和特征值之间的潜在相关性的表述不足。GNN以其天然能力来模拟表格数据的复杂关系和相互作用，在各种TDL领域中引起了重要的兴趣和应用。我们的综述对设计和实现GNN用于TDL（GNN4TDL）的方法进行了系统回顾。它包括对基础问题的详细研究和基于GNN的TDL方法的概述，为其不断发展的领域提供了深入见解。我们提出了一个关注构建图结构和表示学习的全面分类。

    In this survey, we dive into Tabular Data Learning (TDL) using Graph Neural Networks (GNNs), a domain where deep learning-based approaches have increasingly shown superior performance in both classification and regression tasks compared to traditional methods. The survey highlights a critical gap in deep neural TDL methods: the underrepresentation of latent correlations among data instances and feature values. GNNs, with their innate capability to model intricate relationships and interactions between diverse elements of tabular data, have garnered significant interest and application across various TDL domains. Our survey provides a systematic review of the methods involved in designing and implementing GNNs for TDL (GNN4TDL). It encompasses a detailed investigation into the foundational aspects and an overview of GNN-based TDL methods, offering insights into their evolving landscape. We present a comprehensive taxonomy focused on constructing graph structures and representation learn
    
[^19]: SyCoCa: 用关注掩码对多模态对齐进行对称化的对比式字幕生成器

    SyCoCa: Symmetrizing Contrastive Captioners with Attentive Masking for Multimodal Alignment. (arXiv:2401.02137v1 [cs.CV])

    [http://arxiv.org/abs/2401.02137](http://arxiv.org/abs/2401.02137)

    本文提出了SyCoCa方法，通过引入全局和本地表示层面上图像和文本的双向交互，实现了多模态对齐。这种方法可以更好地理解图像和文本之间的细粒度关联。

    

    语言和视觉之间的多模态对齐是当前视觉-语言模型研究中的基本主题。对比式字幕生成器（CoCa）作为一种代表性方法，将对比式语言-图像预训练（CLIP）和图像字幕（IC）整合到统一的框架中，取得了令人瞩目的结果。虽然IC在本地表示上进行了单向的图像到文本生成，但它缺乏对本地文本到图像重构的任何约束，在与文本对齐时限制了对图像的细粒度理解能力。为了从全局和本地两个角度实现多模态对齐，本文提出了对称化对比式字幕生成器（SyCoCa），它在全局和本地表示层面上引入了图像和文本的双向交互。具体而言，我们在基于ITC的文本引导掩码图像建模（TG-MIM）头上进行了扩展。

    Multimodal alignment between language and vision is the fundamental topic in current vision-language model research. Contrastive Captioners (CoCa), as a representative method, integrates Contrastive Language-Image Pretraining (CLIP) and Image Caption (IC) into a unified framework, resulting in impressive results. CLIP imposes a bidirectional constraints on global representation of entire images and sentences. Although IC conducts an unidirectional image-to-text generation on local representation, it lacks any constraint on local text-to-image reconstruction, which limits the ability to understand images at a fine-grained level when aligned with texts. To achieve multimodal alignment from both global and local perspectives, this paper proposes Symmetrizing Contrastive Captioners (SyCoCa), which introduces bidirectional interactions on images and texts across the global and local representation levels. Specifically, we expand a Text-Guided Masked Image Modeling (TG-MIM) head based on ITC
    
[^20]: DCR-Consistency: 大型语言模型一致性评估和改进的划分-征服-推理方法

    DCR-Consistency: Divide-Conquer-Reasoning for Consistency Evaluation and Improvement of Large Language Models. (arXiv:2401.02132v1 [cs.CL])

    [http://arxiv.org/abs/2401.02132](http://arxiv.org/abs/2401.02132)

    DCR-Consistency提出了一个基于划分-征服-推理方法的自动化框架，用于评估和改进大型语言模型生成文本的一致性。与传统的评估方法不同，该方法通过将段落对段落比较划分为句子对段落的比较，并根据预定义标准进行评估。

    

    评估大型语言模型（LLMs）生成的文本的质量和变异性是一个重要而尚未解决的研究难题。传统的评估方法，如ROUGE和BERTScore，通常无法捕捉到整体语义的等价性。这导致与人类判断和直觉的相关性较低，尤其在医疗和金融等高风险应用中，可靠性、安全性和强大的决策能力尤为重要。本研究提出了DCR框架，一种使用划分-征服-推理方法评估和改进LLM生成文本一致性的自动化框架。与现有的基于LLM的评估器不同，本方法采用了划分和征服评估器（DCE），将两个生成的回答之间的段落对段落比较分解为根据预定义标准评估的每个句子对段落的比较。

    Evaluating the quality and variability of text generated by Large Language Models (LLMs) poses a significant, yet unresolved research challenge. Traditional evaluation methods, such as ROUGE and BERTScore, which measure token similarity, often fail to capture the holistic semantic equivalence. This results in a low correlation with human judgments and intuition, which is especially problematic in high-stakes applications like healthcare and finance where reliability, safety, and robust decision-making are highly critical. This work proposes DCR, an automated framework for evaluating and improving the consistency of LLM-generated texts using a divide-conquer-reasoning approach. Unlike existing LLM-based evaluators that operate at the paragraph level, our method employs a divide-and-conquer evaluator (DCE) that breaks down the paragraph-to-paragraph comparison between two generated responses into individual sentence-to-paragraph comparisons, each evaluated based on predefined criteria. T
    
[^21]: ACP-ESM:一种使用以蛋白质为导向的Transformer方法进行抗癌肽分类的新框架

    ACP-ESM: A novel framework for classification of anticancer peptides using protein-oriented transformer approach. (arXiv:2401.02124v1 [q-bio.BM])

    [http://arxiv.org/abs/2401.02124](http://arxiv.org/abs/2401.02124)

    ACP-ESM是一个使用以蛋白质为导向的Transformer方法的新框架，用于分类抗癌肽。这种方法可以优化抗癌肽的稳定性，改善选择性，并提高对癌细胞的传递性。

    

    抗癌肽(ACPs)是一类在癌症研究和治疗领域引起重视的分子。 ACPs是由氨基酸构成的短链，是蛋白质的构建基块，并具有选择性靶向和杀死癌细胞的能力。 ACPs之所以具有针对癌细胞的选择性，往往归因于癌细胞表面特性与正常细胞的差异。因此，ACP被认为是癌症治疗的潜在候选药物。ACPs可以单独使用或与化疗和放疗等治疗方式联合使用。虽然ACP作为一种新型癌症治疗方法具有潜力，但仍需克服一些挑战，包括优化其稳定性，改善选择性，提高对癌细胞的传递性，并且应对肽序列数量的不断增加。

    Anticancer peptides (ACPs) are a class of molecules that have gained significant attention in the field of cancer research and therapy. ACPs are short chains of amino acids, the building blocks of proteins, and they possess the ability to selectively target and kill cancer cells. One of the key advantages of ACPs is their ability to selectively target cancer cells while sparing healthy cells to a greater extent. This selectivity is often attributed to differences in the surface properties of cancer cells compared to normal cells. That is why ACPs are being investigated as potential candidates for cancer therapy. ACPs may be used alone or in combination with other treatment modalities like chemotherapy and radiation therapy. While ACPs hold promise as a novel approach to cancer treatment, there are challenges to overcome, including optimizing their stability, improving selectivity, and enhancing their delivery to cancer cells, continuous increasing in number of peptide sequences, develo
    
[^22]: 移动ALOHA：低成本全身远程操作学习双手移动操作

    Mobile ALOHA: Learning Bimanual Mobile Manipulation with Low-Cost Whole-Body Teleoperation. (arXiv:2401.02117v1 [cs.RO])

    [http://arxiv.org/abs/2401.02117](http://arxiv.org/abs/2401.02117)

    该论文介绍了一个移动ALOHA系统，用于学习双手移动操作。通过低成本的远程操作和整体身体控制，系统能够完成复杂的移动操作任务，并通过联合训练提高成功率达到90%。

    

    仿真学习来自人类演示在机器人学中已经展现出令人印象深刻的性能。然而，大多数的结果集中在桌面操作上，缺乏对于通常有用任务所需要的移动性和灵活性。在这项工作中，我们开发了一个系统，用于模仿移动操作任务，该任务是双手操作且需要全身控制的。我们首先介绍了移动ALOHA，这是一个低成本和全身远程操作数据收集系统。它通过增加一个移动底盘和一个全身远程操作接口来增强ALOHA系统。然后，使用通过移动ALOHA收集的数据，我们进行监督式行为克隆，并发现与现有的静态ALOHA数据集进行联合训练可以提高移动操作任务的性能。对于每个任务进行50次演示，联合训练可以将成功率提高90%，使得移动ALOHA能够自主完成复杂的移动操作任务，如炒虾和上菜，并打开一个双门壁柜存放重型烹饪设备。

    Imitation learning from human demonstrations has shown impressive performance in robotics. However, most results focus on table-top manipulation, lacking the mobility and dexterity necessary for generally useful tasks. In this work, we develop a system for imitating mobile manipulation tasks that are bimanual and require whole-body control. We first present Mobile ALOHA, a low-cost and whole-body teleoperation system for data collection. It augments the ALOHA system with a mobile base, and a whole-body teleoperation interface. Using data collected with Mobile ALOHA, we then perform supervised behavior cloning and find that co-training with existing static ALOHA datasets boosts performance on mobile manipulation tasks. With 50 demonstrations for each task, co-training can increase success rates by up to 90%, allowing Mobile ALOHA to autonomously complete complex mobile manipulation tasks such as sauteing and serving a piece of shrimp, opening a two-door wall cabinet to store heavy cooki
    
[^23]: k-Winners-Take-All集合神经网络

    k-Winners-Take-All Ensemble Neural Network. (arXiv:2401.02092v1 [cs.NE])

    [http://arxiv.org/abs/2401.02092](http://arxiv.org/abs/2401.02092)

    本论文提出了k-Winners-Take-All集合神经网络（kWTA-ENN），通过同时训练子网络来改进以往的集合方法，使用kWTA激活函数作为输出的组合方法，从而实现神经网络性能的提升。

    

    集合是通过组合多个独立的神经网络来提高神经网络性能的一种方法，通常通过对它们的单独输出进行平均或求和来实现。我们改进了这种集合方法，通过同时训练子网络而不是独立训练它们。这种并发训练使子网络相互合作，我们称之为“合作集合”。同时，专家组合方法通过将给定数据集划分为子网络来改善神经网络性能。然后使用一个门控网络，给它的子网络分配一个称为“专家”的专业化角色。我们改进了上述结合神经网络的方法，使用了一种称为k-Winners-Take-All（kWTA）的激活函数，它作为集合中每个子网络输出的组合方法。我们将这个提出的模型称为“kWTA集合神经网络”（kWTA-ENN）。

    Ensembling is one approach that improves the performance of a neural network by combining a number of independent neural networks, usually by either averaging or summing up their individual outputs. We modify this ensembling approach by training the sub-networks concurrently instead of independently. This concurrent training of sub-networks leads them to cooperate with each other, and we refer to them as "cooperative ensemble". Meanwhile, the mixture-of-experts approach improves a neural network performance by dividing up a given dataset to its sub-networks. It then uses a gating network that assigns a specialization to each of its sub-networks called "experts". We improve on these aforementioned ways for combining a group of neural networks by using a k-Winners-Take-All (kWTA) activation function, that acts as the combination method for the outputs of each sub-network in the ensemble. We refer to this proposed model as "kWTA ensemble neural networks" (kWTA-ENN). With the kWTA activati
    
[^24]: 进化计算与大语言模型击败人类：高效引导局部搜索设计的例子

    An Example of Evolutionary Computation + Large Language Model Beating Human: Design of Efficient Guided Local Search. (arXiv:2401.02051v1 [cs.NE])

    [http://arxiv.org/abs/2401.02051](http://arxiv.org/abs/2401.02051)

    使用进化计算和大语言模型的算法进化框架，自动设计了高效的引导局部搜索算法来解决旅行商问题，在实验中表现优于人工设计的算法，标志着自动算法设计的新时代出现。

    

    对人类专家来说，设计高效算法通常非常繁琐。最近，我们提出了一种新颖的算法进化与大语言模型（AEL）框架，用于自动算法设计。AEL将大语言模型的能力与进化计算的范式相结合，实现自动设计、组合和修改算法。在本文中，我们使用AEL来设计引导局部搜索（GLS）的引导算法，以解决著名的旅行商问题（TSP）。AEL自动演化出优秀的GLS算法，在两天内实现，只需要极少的人力投入和无需模型训练。在1,000个TSP20-TSP100实例和TSPLib实例上的实验结果表明，AEL设计的GLS算法在相同的迭代预算下优于最先进的人工设计的GLS算法。在1,000次迭代中，它在TSP20和TSP50上达到0%间隙，在TSP100上达到0.032%间隙。我们的发现标志着自动算法设计的新时代的出现。

    It is often very tedious for human experts to design efficient algorithms. Recently, we have proposed a novel Algorithm Evolution using Large Language Model (AEL) framework for automatic algorithm design. AEL combines the power of a large language model and the paradigm of evolutionary computation to design, combine, and modify algorithms automatically. In this paper, we use AEL to design the guide algorithm for guided local search (GLS) to solve the well-known traveling salesman problem (TSP). AEL automatically evolves elite GLS algorithms in two days, with minimal human effort and no model training. Experimental results on 1,000 TSP20-TSP100 instances and TSPLib instances show that AEL-designed GLS outperforms state-of-the-art human-designed GLS with the same iteration budget. It achieves a 0% gap on TSP20 and TSP50 and a 0.032% gap on TSP100 in 1,000 iterations. Our findings mark the emergence of a new era in automatic algorithm design.
    
[^25]: 自我对比：通过不一致的求解视角获得更好的反思能力

    Self-Contrast: Better Reflection Through Inconsistent Solving Perspectives. (arXiv:2401.02009v1 [cs.CL])

    [http://arxiv.org/abs/2401.02009](http://arxiv.org/abs/2401.02009)

    自我对比是一种通过对比不同求解视角和总结差异，提高大型语言模型（LLM）的反思能力的方法。

    

    大型语言模型（LLM）的反思能力引起了广泛关注。一种事后提示策略，例如反思和自我改进，根据自我评估或外部反馈来改善LLM的响应。然而，最近的研究表明，在没有外部反馈的情况下，LLM的内在反思是不稳定的。我们的调查揭示了自我评估反馈质量是关键瓶颈。我们发现LLM在自我评估时常常表现出过度自信或高度随机性，提供固执或不一致的反馈，导致反思能力不佳。为了解决这个问题，我们提出了自我对比的方法：它根据请求自适应地探索多样的求解视角，对比差异，并将这些差异总结为一个检查表，用于重新审视和消除差异。我们的方法赋予LLM多样的视角以减轻固执偏见。此外，差异指示了潜在的错误或固有的不确定性。

    The reflection capacity of Large Language Model (LLM) has garnered extensive attention. A post-hoc prompting strategy, e.g., reflexion and self-refine, refines LLM's response based on self-evaluated or external feedback. However, recent research indicates without external feedback, LLM's intrinsic reflection is unstable. Our investigation unveils that the key bottleneck is the quality of the self-evaluated feedback. We find LLMs often exhibit overconfidence or high randomness when self-evaluate, offering stubborn or inconsistent feedback, which causes poor reflection. To remedy this, we advocate Self-Contrast: It adaptively explores diverse solving perspectives tailored to the request, contrasts the differences, and summarizes these discrepancies into a checklist which could be used to re-examine and eliminate discrepancies. Our method endows LLM with diverse perspectives to alleviate stubborn biases. Moreover, their discrepancies indicate potential errors or inherent uncertainties tha
    
[^26]: 关于用时间索引作为深度强化学习中的归纳偏好处理顺序操控任务

    On Time-Indexing as Inductive Bias in Deep RL for Sequential Manipulation Tasks. (arXiv:2401.01993v1 [cs.RO])

    [http://arxiv.org/abs/2401.01993](http://arxiv.org/abs/2401.01993)

    本论文提出一种简单的策略架构，通过按固定持续时间依次执行不同的行动头，使得深度强化学习在解决顺序操控任务时能够学习到更多的基本技能，实证评估结果显示这种结构优于标准方法。

    

    在解决复杂的操控任务时，操控策略通常需要学习一组多样化的技能来完成这些任务。这组技能通常是多模态的，每个技能可能具有相当不同的行动和状态分布。标准的深度策略学习算法通常将策略建模为具有单个输出头的深度神经网络（确定性或随机性）。这种结构要求网络在内部学习在不同模式之间切换，这可能导致样本利用效率低和性能差。在本文中，我们探索了一种简单的结构，有助于学习许多操控任务所需的技能。具体而言，我们提出了一种策略架构，其按固定持续时间依次执行不同的行动头，从而实现了诸如到达和抓取等基本技能的学习。我们对Metaworld任务进行了实证评估，结果表明这种简单的结构优于标准的策略学习方法，凸显出其创新之处。

    While solving complex manipulation tasks, manipulation policies often need to learn a set of diverse skills to accomplish these tasks. The set of skills is often quite multimodal - each one may have a quite distinct distribution of actions and states. Standard deep policy-learning algorithms often model policies as deep neural networks with a single output head (deterministic or stochastic). This structure requires the network to learn to switch between modes internally, which can lead to lower sample efficiency and poor performance. In this paper we explore a simple structure which is conducive to skill learning required for so many of the manipulation tasks. Specifically, we propose a policy architecture that sequentially executes different action heads for fixed durations, enabling the learning of primitive skills such as reaching and grasping. Our empirical evaluation on the Metaworld tasks reveals that this simple structure outperforms standard policy learning methods, highlightin
    
[^27]: GPS-SSL: 引导正样本采样将先验知识注入到自监督学习中

    GPS-SSL: Guided Positive Sampling to Inject Prior Into Self-Supervised Learning. (arXiv:2401.01990v1 [cs.CV])

    [http://arxiv.org/abs/2401.01990](http://arxiv.org/abs/2401.01990)

    GPS-SSL是一种将先验知识注入到自监督学习中的通用方法，通过设计度量空间并利用最近邻采样生成正样本。它可以减少对强数据增强的依赖，因此在Cifar10上达到了更好的效果。

    

    我们提出了引导正样本采样自监督学习（GPS-SSL），这是一种将先验知识注入到自监督学习（SSL）正样本选择的通用方法。当前的SSL方法利用数据增强（DA）生成正样本，并将先验知识结合进去，但是错误或者过弱的DA会严重降低所学到的表示的质量。GPS-SSL则提出设计一个度量空间，使得欧氏距离成为语义关系的有意义的替代。在这个空间中，可以通过最近邻采样生成正样本。任何先验知识都可以独立地嵌入到这个度量空间中，而不受所使用的DA影响。由于其简单性，GPS-SSL适用于任何SSL方法，如SimCLR或BYOL。GPS-SSL的一个关键好处是减少了定制强DA的压力。例如，GPS-SSL在Cifar10上使用弱DA达到了85.58％，而基准值只达到了37.51％。

    We propose Guided Positive Sampling Self-Supervised Learning (GPS-SSL), a general method to inject a priori knowledge into Self-Supervised Learning (SSL) positive samples selection. Current SSL methods leverage Data-Augmentations (DA) for generating positive samples and incorporate prior knowledge - an incorrect, or too weak DA will drastically reduce the quality of the learned representation. GPS-SSL proposes instead to design a metric space where Euclidean distances become a meaningful proxy for semantic relationship. In that space, it is now possible to generate positive samples from nearest neighbor sampling. Any prior knowledge can now be embedded into that metric space independently from the employed DA. From its simplicity, GPS-SSL is applicable to any SSL method, e.g. SimCLR or BYOL. A key benefit of GPS-SSL is in reducing the pressure in tailoring strong DAs. For example GPS-SSL reaches 85.58% on Cifar10 with weak DA while the baseline only reaches 37.51%. We therefore move a 
    
[^28]: 重访大语言模型时代下的零-shot 抽象摘要，从位置偏见的角度出发

    Revisiting Zero-Shot Abstractive Summarization in the Era of Large Language Models from the Perspective of Position Bias. (arXiv:2401.01989v1 [cs.CL])

    [http://arxiv.org/abs/2401.01989](http://arxiv.org/abs/2401.01989)

    这项研究通过测量位置偏见，重访了大语言模型中的零-shot 抽象摘要。研究结果揭示了模型不公平地优先考虑某些部分的信息，从而导致不可取的行为。对多个LLM模型和预训练抽象摘要模型进行的实验提供了关于零-shot 总结任务的模型性能和位置偏见的新见解和讨论。

    

    我们通过测量位置偏见来表征和研究大型语言模型（LLMs）中的零-shot 抽象摘要，我们将其视为先前文献中研究过的更为限制性的引导偏见现象的一般表述。位置偏见捕捉到模型在输入文本的某些部分上不公平地优先考虑信息，导致不可取的行为。通过对四个不同的真实数据集进行大量实验，我们研究了多个LLM模型如GPT 3.5-Turbo，Llama-2和Dolly-v2中的位置偏见，以及当前最先进的预训练编码器-解码器抽象摘要模型如Pegasus和BART。我们的发现为零-shot 总结任务的模型性能和位置偏见提供了新的见解和讨论。

    We characterize and study zero-shot abstractive summarization in Large Language Models (LLMs) by measuring position bias, which we propose as a general formulation of the more restrictive lead bias phenomenon studied previously in the literature. Position bias captures the tendency of a model unfairly prioritizing information from certain parts of the input text over others, leading to undesirable behavior. Through numerous experiments on four diverse real-world datasets, we study position bias in multiple LLM models such as GPT 3.5-Turbo, Llama-2, and Dolly-v2, as well as state-of-the-art pretrained encoder-decoder abstractive summarization models such as Pegasus and BART. Our findings lead to novel insights and discussion on performance and position bias of models for zero-shot summarization tasks.
    
[^29]: 实现真正的零样本组合视觉推理：以LLMs为程序员

    Towards Truly Zero-shot Compositional Visual Reasoning with LLMs as Programmers. (arXiv:2401.01974v1 [cs.CV])

    [http://arxiv.org/abs/2401.01974](http://arxiv.org/abs/2401.01974)

    本文提出了一种框架来实现零样本组合视觉推理，通过引入抽象的空间和时间例程以及利用少量的nun

    

    视觉推理主要采用端到端神经网络，拥有数十亿个模型参数和训练样本。然而，即使是最大的模型在组合推理、泛化、细粒度空间和时间推理以及计数方面也存在困难。在理论上，使用大型语言模型(LLMs)作为控制器进行视觉推理可以解决这些限制，通过将任务分解为子任务，并通过调度一组(视觉)工具来解决子任务。最近，这些模型在组合视觉问答、视觉 grounding 和视频的时间推理等任务上取得了很好的性能。然而，现有模型在当前形式下严重依赖于在提示中针对具体数据集和任务进行人工设计的上下文示例，这需要高技能程序员投入大量的劳动力。在这项工作中，我们提出了一个框架来缓解这些问题，通过引入具有空间和时间抽象的例程，并利用少量的nu

    Visual reasoning is dominated by end-to-end neural networks scaled to billions of model parameters and training examples. However, even the largest models struggle with compositional reasoning, generalization, fine-grained spatial and temporal reasoning, and counting. Visual reasoning with large language models (LLMs) as controllers can, in principle, address these limitations by decomposing the task and solving subtasks by orchestrating a set of (visual) tools. Recently, these models achieved great performance on tasks such as compositional visual question answering, visual grounding, and video temporal reasoning. Nevertheless, in their current form, these models heavily rely on human engineering of in-context examples in the prompt, which are often dataset- and task-specific and require significant labor by highly skilled programmers. In this work, we present a framework that mitigates these issues by introducing spatially and temporally abstract routines and by leveraging a small nu
    
[^30]: FMGS：基于嵌入式3D高斯分割的全面3D场景理解

    FMGS: Foundation Model Embedded 3D Gaussian Splatting for Holistic 3D Scene Understanding. (arXiv:2401.01970v1 [cs.CV])

    [http://arxiv.org/abs/2401.01970](http://arxiv.org/abs/2401.01970)

    提出了一种新颖的方法，将视觉语言嵌入基础模型到3D高斯分割中，实现了高质量的3D场景理解。

    

    准确地感知现实世界3D物体的几何和语义特性对于增强现实和机器人应用的持续进化至关重要。为此，我们提出了FMGS（Foundation Model Embedded 3D Gaussian Splatting），将视觉语言嵌入基础模型到3D高斯分割中。本工作的主要贡献是一种高效的方法，用于重建和表示3D视觉语言模型。这是通过将基于图像的基础模型生成的特征图融合到我们的3D模型中渲染实现的。为了确保高质量的渲染和快速训练，我们引入了一种新颖的场景表示方法，将GS和多分辨率哈希编码（MHE）的优势结合起来。我们的有效训练过程还引入了像素对齐损失，使相同语义实体的渲染特征距离接近，遵循像素级语义边界。我们的结果展示了显著的多视图语义一致性。

    Precisely perceiving the geometric and semantic properties of real-world 3D objects is crucial for the continued evolution of augmented reality and robotic applications. To this end, we present \algfull{} (\algname{}), which incorporates vision-language embeddings of foundation models into 3D Gaussian Splatting (GS). The key contribution of this work is an efficient method to reconstruct and represent 3D vision-language models. This is achieved by distilling feature maps generated from image-based foundation models into those rendered from our 3D model. To ensure high-quality rendering and fast training, we introduce a novel scene representation by integrating strengths from both GS and multi-resolution hash encodings (MHE). Our effective training procedure also introduces a pixel alignment loss that makes the rendered feature distance of same semantic entities close, following the pixel-level semantic boundaries. Our results demonstrate remarkable multi-view semantic consistency, faci
    
[^31]: 对齐算法的机制理解：基于DPO和毒性的案例研究

    A Mechanistic Understanding of Alignment Algorithms: A Case Study on DPO and Toxicity. (arXiv:2401.01967v1 [cs.CL])

    [http://arxiv.org/abs/2401.01967](http://arxiv.org/abs/2401.01967)

    通过研究对齐算法和预训练语言模型，本论文揭示了对齐模型的机制，并提出了一种简单的方法来取消模型的对齐，从而使其恢复有害行为。

    

    虽然对齐算法现在常用于调整预训练语言模型以适应用户喜好，但我们缺乏解释模型如何“对齐”的基本机制，因此难以解释诸如越狱等现象。本研究中，我们研究了一种常见的算法——直接偏好优化（DPO），以及它如何降低毒性的机制。具体而言，我们首先研究了毒性在预训练语言模型GPT2-medium中的表示和唤起方式。然后，我们使用精心设计的成对数据集应用DPO来降低毒性。我们检查了生成模型是如何避免输出有害结果的，并发现预训练学到的能力并没有被移除，而是被绕过。我们利用这一观察结果展示了一种简单的方法来取消模型的对齐，将其恢复为有害行为。

    While alignment algorithms are now commonly used to tune pre-trained language models towards a user's preferences, we lack explanations for the underlying mechanisms in which models become ``aligned'', thus making it difficult to explain phenomena like jailbreaks. In this work we study a popular algorithm, direct preference optimization (DPO), and the mechanisms by which it reduces toxicity. Namely, we first study how toxicity is represented and elicited in a pre-trained language model, GPT2-medium. We then apply DPO with a carefully crafted pairwise dataset to reduce toxicity. We examine how the resulting model averts toxic outputs, and find that capabilities learned from pre-training are not removed, but rather bypassed. We use this insight to demonstrate a simple method to un-align the model, reverting it back to its toxic behavior.
    
[^32]: Instruct-Imagen: 带有多模式指令的图像生成

    Instruct-Imagen: Image Generation with Multi-modal Instruction. (arXiv:2401.01952v1 [cs.CV])

    [http://arxiv.org/abs/2401.01952](http://arxiv.org/abs/2401.01952)

    Instruct-Imagen是一种处理异构图像生成任务并进行泛化的模型，引入了多模式指令以实现各种生成意图的统一标准化。通过微调预训练的文本到图像扩散模型，并使用检索增强的训练提升模型在外部多模态环境下的生成能力。对多样化图像生成任务的人工评估表明，该模型取得了良好的效果。

    

    本文提出了Instruct-Imagen，这是一种处理异构图像生成任务并在未见任务中进行泛化的模型。我们引入了多模式指令用于图像生成，这是一种任务表示方法，可以精确地表达各种生成意图。它使用自然语言来整合不同的模态（例如文本、边缘、风格、主题等），使得丰富的生成意图能够以统一的格式标准化。然后，我们通过微调预训练的文本到图像扩散模型构建了Instruct-Imagen的两阶段框架。首先，我们使用检索增强的训练来使模型能够在外部多模态环境下基于其生成。然后，我们在需要视觉-语言理解的多样化图像生成任务中对这个调整后的模型进行微调，每个任务都配对一个包含任务本质的多模式指令。对各种图像生成任务的人工评估表明，

    This paper presents instruct-imagen, a model that tackles heterogeneous image generation tasks and generalizes across unseen tasks. We introduce *multi-modal instruction* for image generation, a task representation articulating a range of generation intents with precision. It uses natural language to amalgamate disparate modalities (e.g., text, edge, style, subject, etc.), such that abundant generation intents can be standardized in a uniform format.  We then build instruct-imagen by fine-tuning a pre-trained text-to-image diffusion model with a two-stage framework. First, we adapt the model using the retrieval-augmented training, to enhance model's capabilities to ground its generation on external multimodal context. Subsequently, we fine-tune the adapted model on diverse image generation tasks that requires vision-language understanding (e.g., subject-driven generation, etc.), each paired with a multi-modal instruction encapsulating the task's essence. Human evaluation on various ima
    
[^33]: 使用卷积能否仅生成逼真的手部图像？

    Can We Generate Realistic Hands Only Using Convolution?. (arXiv:2401.01951v1 [cs.CV])

    [http://arxiv.org/abs/2401.01951](http://arxiv.org/abs/2401.01951)

    本文展示了通过为卷积层提供具有相对$n$维笛卡尔坐标系的单一输入通道，可以缓解图像生成模型无法重现复杂几何特征的问题，显著提高了GAN和VAE生成的手部和面部图像质量。

    

    长达十年之久，图像生成模型一直无法重现复杂的几何特征，例如人手和手指中所存在的特征，这一问题在图像生成领域一直存在。虽然通过增加模型大小和多样化训练数据集已经取得了一定进展，但这个问题在各种模型中仍然普遍存在，从去噪扩散模型到生成对抗网络（GAN），这指向了底层结构的根本缺陷。在本文中，我们通过为卷积层提供一个单一输入通道，其中包含相对$n$维笛卡尔坐标系，来展示如何缓解这个问题。我们展示了这种方法极大地改善了GAN和变分自动编码器（VAE）生成的手部和面部图像的质量。

    The enduring inability of image generative models to recreate intricate geometric features, such as those present in human hands and fingers has been an ongoing problem in image generation for nearly a decade. While strides have been made by increasing model sizes and diversifying training datasets, this issue remains prevalent across all models, from denoising diffusion models to Generative Adversarial Networks (GAN), pointing to a fundamental shortcoming in the underlying architectures. In this paper, we demonstrate how this problem can be mitigated by augmenting convolution layers geometric capabilities through providing them with a single input channel incorporating the relative $n$-dimensional Cartesian coordinate system. We show that this drastically improves quality of hand and face images generated by GANs and Variational AutoEncoders (VAE).
    
[^34]: 通用嵌入模型在短语境临床语义搜索方面表现比专业嵌入模型更好

    Generalist embedding models are better at short-context clinical semantic search than specialized embedding models. (arXiv:2401.01943v1 [cs.CL])

    [http://arxiv.org/abs/2401.01943](http://arxiv.org/abs/2401.01943)

    本研究发现，在临床语义搜索方面，通用嵌入模型比专业嵌入模型表现更好，这表明现有的临床专业化模型对输入的微小变化更敏感。

    

    基于大型语言模型（LLM）的工具和解决方案在医疗领域的应用日益增多，这已成为一个重要趋势。然而，在这个高度关键和敏感的领域中使用它们对其稳健性产生了重要的问题，特别是对输入变化和生成的输出的可靠性。本研究通过构建基于ICD-10-CM代码描述的文本数据集来解决这些问题，该数据集广泛应用于美国医院，包含许多临床术语及其易于复制的改写。然后，我们在语义搜索任务中对现有的通用或临床专业化的嵌入模型进行了基准测试，目标是正确匹配改写的文本与原始描述。我们的结果表明，通用模型比临床模型表现更好，这表明现有的临床专业化模型对输入的微小变化更敏感，从而使其困惑。

    The increasing use of tools and solutions based on Large Language Models (LLMs) for various tasks in the medical domain has become a prominent trend. Their use in this highly critical and sensitive domain has thus raised important questions about their robustness, especially in response to variations in input, and the reliability of the generated outputs. This study addresses these questions by constructing a textual dataset based on the ICD-10-CM code descriptions, widely used in US hospitals and containing many clinical terms, and their easily reproducible rephrasing. We then benchmarked existing embedding models, either generalist or specialized in the clinical domain, in a semantic search task where the goal was to correctly match the rephrased text to the original description. Our results showed that generalist models performed better than clinical models, suggesting that existing clinical specialized models are more sensitive to small changes in input that confuse them. The highl
    
[^35]: 越南诗歌生成与跨语言诗歌翻译的前景

    Vietnamese Poem Generation & The Prospect Of Cross-Language Poem-To-Poem Translation. (arXiv:2401.01078v1 [cs.CL])

    [http://arxiv.org/abs/2401.01078](http://arxiv.org/abs/2401.01078)

    本文通过使用大型语言模型，成功提出了一种生成越南诗歌的方法，并探索了将诗歌翻译成不同语言的可能性，同时保持对生成内容的完全控制。

    

    诗歌生成一直是自然语言处理领域的一项挑战任务，因为它要求模型理解语言、情感和风格的细微差别。在本文中，我们提出使用大型语言模型从自然语言提示中生成越南诗歌，从而实现直观的过程和增强的内容控制。我们最有效的模型，GPT-3 Babbage变种，在越南诗歌的“六八词”类型中实现了0.8的自定义评分。此外，我们还探索了将诗歌改写成正常文本提示的想法，并在“六八词”类型中获得了相对较高的0.718分数。这个实验展示了以翻译后的诗歌作为输入进行跨语言诗歌翻译的潜力，并同时保持对生成内容的完全控制。

    Poetry generation has been a challenging task in the field of Natural Language Processing, as it requires the model to understand the nuances of language, sentiment, and style. In this paper, we propose using Large Language Models to generate Vietnamese poems from natural language prompts, thereby facilitating an intuitive process with enhanced content control. Our most efficacious model, the GPT-3 Babbage variant, achieves a custom evaluation score of 0.8, specifically tailored to the "luc bat" genre of Vietnamese poetry. Furthermore, we also explore the idea of paraphrasing poems into normal text prompts and yield a relatively high score of 0.718 in the "luc bat" genre. This experiment presents the potential for cross-Language poem-to-poem translation with translated poems as the inputs while concurrently maintaining complete control over the generated content.
    
[^36]: 准确的变形DETR和多级特征融合用于辅助血液疾病诊断的白细胞检测

    Accurate Leukocyte Detection Based on Deformable-DETR and Multi-Level Feature Fusion for Aiding Diagnosis of Blood Diseases. (arXiv:2401.00926v1 [cs.CV])

    [http://arxiv.org/abs/2401.00926](http://arxiv.org/abs/2401.00926)

    本文提出了一种创新的白细胞检测方法，使用多级特征融合和变形自注意DETR，通过解决白细胞尺度差异问题和提高检测精度，以改善传统血液检测的效率和准确性。

    

    在标准医院血液检测中，传统的方法需要医生使用显微镜从患者的血液显微图像中手动分离白细胞。然后通过自动白细胞分类器对这些分离的白细胞进行分类，以确定血样中不同类型白细胞的比例和体积，从而协助疾病诊断。这种方法不仅耗时、耗力，而且容易出现错误，因为图像质量和环境条件等因素，可能导致后续分类错误和误诊。为了解决这些问题，本文提出了一种创新的白细胞检测方法：多级特征融合和变形自注意DETR（MFDS-DETR）。为了解决白细胞尺度差异的问题，我们设计了高级筛选特征融合金字塔（HS-FPN），实现了多级融合。该模型使用高级特征作为特征融合的输入，同时采用变形自注意DETR实现精确的白细胞检测。

    In standard hospital blood tests, the traditional process requires doctors to manually isolate leukocytes from microscopic images of patients' blood using microscopes. These isolated leukocytes are then categorized via automatic leukocyte classifiers to determine the proportion and volume of different types of leukocytes present in the blood samples, aiding disease diagnosis. This methodology is not only time-consuming and labor-intensive, but it also has a high propensity for errors due to factors such as image quality and environmental conditions, which could potentially lead to incorrect subsequent classifications and misdiagnosis. To address these issues, this paper proposes an innovative method of leukocyte detection: the Multi-level Feature Fusion and Deformable Self-attention DETR (MFDS-DETR). To tackle the issue of leukocyte scale disparity, we designed the High-level Screening-feature Fusion Pyramid (HS-FPN), enabling multi-level fusion. This model uses high-level features as 
    
[^37]: 知识增强的医疗时间序列条件插补方法

    Knowledge Enhanced Conditional Imputation for Healthcare Time-series. (arXiv:2312.16713v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2312.16713](http://arxiv.org/abs/2312.16713)

    本研究提出了一种知识增强的条件插补方法，针对医疗时间序列数据中的缺失数据问题。通过整合先进的知识嵌入和非均匀掩蔽策略，该方法能够灵活适应不同模式的电子健康记录中的缺失数据分布不平衡问题。

    

    本研究提出了一种新颖的方法来解决多变量时间序列中的缺失数据问题，特别关注医疗数据的复杂性。我们的条件自注意力插补（CSAI）模型以基于Transformer的框架为基础，引入了一种针对医疗时间序列数据细节的条件隐藏状态初始化方式。该方法与传统的插补技术不同，它特别针对医疗数据集中缺失数据分布的不平衡问题，这一关键问题常常被忽视。通过整合先进的知识嵌入和非均匀掩蔽策略，CSAI能够灵活适应电子健康记录（EHR）中缺失数据的不同模式。

    This study presents a novel approach to addressing the challenge of missing data in multivariate time series, with a particular focus on the complexities of healthcare data. Our Conditional Self-Attention Imputation (CSAI) model, grounded in a transformer-based framework, introduces a conditional hidden state initialization tailored to the intricacies of medical time series data. This methodology diverges from traditional imputation techniques by specifically targeting the imbalance in missing data distribution, a crucial aspect often overlooked in healthcare datasets. By integrating advanced knowledge embedding and a non-uniform masking strategy, CSAI adeptly adjusts to the distinct patterns of missing data in Electronic Health Records (EHRs).
    
[^38]: Lookahead:一种用于具有无损生成准确性的大型语言模型的推理加速框架

    Lookahead: An Inference Acceleration Framework for Large Language Model with Lossless Generation Accuracy. (arXiv:2312.12728v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2312.12728](http://arxiv.org/abs/2312.12728)

    本研究介绍了一种通用的推理加速框架，用于提高大型语言模型（LLMs）的推理速度，并在保持生成准确性的同时降低成本。该框架在支付宝的检索增强生成（RAG）系统中得到了应用。

    

    随着大型语言模型（LLMs）在各种任务中取得了重大进展，如问答、翻译、文本摘要和对话系统，尤其是对于像支付宝这样为数十亿用户提供重要金融产品的需要准确信息的情况，信息的准确性变得至关重要。为了解决这个问题，支付宝开发了一种称为检索增强生成（RAG）系统的方法，该系统将LLMs与最准确和最新的信息相结合。然而，对于为数百万用户提供服务的真实产品来说，LLMs的推理速度成为一个关键因素，而不仅仅是一个实验性的模型。因此，本文提出了一种通用的推理加速框架，通过加速推理过程，实现了我们的RAG系统的速度大幅提升和成本降低，同时保持着无损的生成准确性。在传统的推理过程中，每个令牌都由LLMs按顺序生成，导致的时间消耗与生成的令牌数成正比。

    As Large Language Models (LLMs) have made significant advancements across various tasks, such as question answering, translation, text summarization, and dialogue systems, the need for accuracy in information becomes crucial, especially for serious financial products serving billions of users like Alipay. To address this, Alipay has developed a Retrieval-Augmented Generation (RAG) system that grounds LLMs on the most accurate and up-to-date information. However, for a real-world product serving millions of users, the inference speed of LLMs becomes a critical factor compared to a mere experimental model.  Hence, this paper presents a generic framework for accelerating the inference process, resulting in a substantial increase in speed and cost reduction for our RAG system, with lossless generation accuracy. In the traditional inference process, each token is generated sequentially by the LLM, leading to a time consumption proportional to the number of generated tokens. To enhance this 
    
[^39]: 连续学习: 面向视频表示的免遗忘优胜子网络

    Continual Learning: Forget-free Winning Subnetworks for Video Representations. (arXiv:2312.11973v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2312.11973](http://arxiv.org/abs/2312.11973)

    本研究基于"彩票票据假设"，提出了一种连续学习方法，通过利用稀疏子网络和FSO进行任务增量学习、少样本类增量学习和视频增量学习，实现高效学习和有效的权重重用。

    

    受到"彩票票据假设"（LTH）的启发，该假设强调在较大的密集网络中存在高效子网络，研究了在适当的稀疏条件下表现优秀的优胜子网络（WSN）在各种连续学习任务中的应用。它利用来自密集网络的预先存在的权重，在任务增量学习（TIL）场景中实现高效学习。在少样本类增量学习（FSCIL）中，设计了一种称为软子网络（SoftNet）的WSN变体，以防止数据样本稀缺时的过拟合。此外，考虑了WSN权重的稀疏重用，用于视频增量学习（VIL）。考虑了在WSN中使用傅立叶子神经运算器（FSO），它能够对视频进行紧凑编码，并在不同带宽下识别可重用的子网络。我们将FSO集成到不同的连续学习架构中，包括VIL、TIL和FSCIL。

    Inspired by the Lottery Ticket Hypothesis (LTH), which highlights the existence of efficient subnetworks within larger, dense networks, a high-performing Winning Subnetwork (WSN) in terms of task performance under appropriate sparsity conditions is considered for various continual learning tasks. It leverages pre-existing weights from dense networks to achieve efficient learning in Task Incremental Learning (TIL) scenarios. In Few-Shot Class Incremental Learning (FSCIL), a variation of WSN referred to as the Soft subnetwork (SoftNet) is designed to prevent overfitting when the data samples are scarce. Furthermore, the sparse reuse of WSN weights is considered for Video Incremental Learning (VIL). The use of Fourier Subneural Operator (FSO) within WSN is considered. It enables compact encoding of videos and identifies reusable subnetworks across varying bandwidths. We have integrated FSO into different architectural frameworks for continual learning, including VIL, TIL, and FSCIL. Our c
    
[^40]: 评估语言模型代理在现实自主任务中的表现

    Evaluating Language-Model Agents on Realistic Autonomous Tasks. (arXiv:2312.11671v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.11671](http://arxiv.org/abs/2312.11671)

    这篇论文评估了语言模型代理在现实自主任务中的表现，发现这些代理只能完成最简单的任务，对于更具挑战性的任务有一定进展。

    

    在这篇报告中，我们探索了语言模型代理在野外获取资源、复制自身和适应新挑战的能力。我们称这些能力为"自主复制和适应"或者ARA。我们认为具备ARA能力的系统可能具有广泛而难以预测的后果，并且对于衡量和预测ARA能力可能有助于制定相关的安全、监测和对齐措施。此外，一旦系统具备ARA能力，对系统能力的限制可能变得更加困难。我们构建了四个简单的示例代理，将语言模型与允许其在世界中采取行动的工具相结合。然后，我们对这些代理在与ARA相关的12个任务上进行评估。我们发现这些语言模型代理只能完成任务列表中最简单的任务，尽管对于更具挑战性的任务也有一定的进展。不幸的是，这些评估还没有完成。

    In this report, we explore the ability of language model agents to acquire resources, create copies of themselves, and adapt to novel challenges they encounter in the wild. We refer to this cluster of capabilities as "autonomous replication and adaptation" or ARA. We believe that systems capable of ARA could have wide-reaching and hard-to-anticipate consequences, and that measuring and forecasting ARA may be useful for informing measures around security, monitoring, and alignment. Additionally, once a system is capable of ARA, placing bounds on a system's capabilities may become significantly more difficult.  We construct four simple example agents that combine language models with tools that allow them to take actions in the world. We then evaluate these agents on 12 tasks relevant to ARA. We find that these language model agents can only complete the easiest tasks from this list, although they make some progress on the more challenging tasks. Unfortunately, these evaluations are not 
    
[^41]: 可解释的音频标记的感知音乐特征

    Perceptual Musical Features for Interpretable Audio Tagging. (arXiv:2312.11234v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2312.11234](http://arxiv.org/abs/2312.11234)

    本研究在自动音乐标记中探索了解释性的重要性，并构建了一个工作流来提取音频文件中的感知特征，从而训练出可解释的机器学习模型。

    

    在音乐流媒体平台的时代，自动标记音乐音频的任务引起了重要关注，推动研究人员设计旨在提高标准数据集上性能指标的方法。最近的方法大多依赖于深度神经网络，尽管其表现出色，但也具有不透明性，使得难以解释其对给定输入的输出。然而，解释性问题在其他领域如医学中备受强调，但在音乐相关任务中并未得到关注。本研究中，我们探索了在自动音乐标记的背景下解释性的相关性。我们构建了一个工作流，结合了三种不同的信息提取技术：a）利用符号知识，b）利用辅助深度神经网络，c）利用信号处理从音频文件中提取感知特征。

    In the age of music streaming platforms, the task of automatically tagging music audio has garnered significant attention, driving researchers to devise methods aimed at enhancing performance metrics on standard datasets. Most recent approaches rely on deep neural networks, which, despite their impressive performance, possess opacity, making it challenging to elucidate their output for a given input. While the issue of interpretability has been emphasized in other fields like medicine, it has not received attention in music-related tasks. In this study, we explored the relevance of interpretability in the context of automatic music tagging. We constructed a workflow that incorporates three different information extraction techniques: a) leveraging symbolic knowledge, b) utilizing auxiliary deep neural networks, and c) employing signal processing to extract perceptual features from audio files. These features were subsequently used to train an interpretable machine-learning model for ta
    
[^42]: 作为大型语言模型的指导数据探索者的单次学习方法

    One Shot Learning as Instruction Data Prospector for Large Language Models. (arXiv:2312.10302v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.10302](http://arxiv.org/abs/2312.10302)

    本研究提出了一种名为Nuggets的新颖有效方法，利用单次学习从庞大的数据集中选择高质量的指导数据，通过评估示例对多样锚定集的困惑度影响，选择对指导调优最有益的数据

    

    将大型语言模型与人类对齐是有效利用其预训练能力的关键步骤。当前的指导调优方法通常依赖于扩展数据集大小，但缺乏确保数据质量的明确策略，这可能无意中引入噪声并降低模型性能。为了应对这一挑战，我们引入了一种新颖高效的方法Nuggets，该方法利用单次学习从庞大的数据集中选择高质量的指导数据。Nuggets评估单个指导示例作为有效单次示例的潜力，从而识别可以显著提升各种任务性能的示例。Nuggets利用基于候选示例对多样锚定集的困惑度影响的评分系统，有助于选择对指导调优最有益的数据。通过在两个基准测试集MT-Bench和Alpaca-Ev上进行严格测试

    Aligning large language models(LLMs) with human is a critical step in effectively utilizing their pre-trained capabilities across a wide array of language tasks. Current instruction tuning practices often rely on expanding dataset size without a clear strategy for ensuring data quality, which can inadvertently introduce noise and degrade model performance. To address this challenge, we introduce Nuggets, a novel and efficient methodology that employs one shot learning to select high-quality instruction data from expansive datasets. Nuggets assesses the potential of individual instruction examples to act as effective one shot examples, thereby identifying those that can significantly enhance diverse task performance. Nuggets utilizes a scoring system based on the impact of candidate examples on the perplexity of a diverse anchor set, facilitating the selection of the most beneficial data for instruction tuning. Through rigorous testing on two benchmarks, including MT-Bench and Alpaca-Ev
    
[^43]: Bayesian网络的熵和Kullback-Leibler散度：计算复杂度和高效实现

    Entropy and the Kullback-Leibler Divergence for Bayesian Networks: Computational Complexity and Efficient Implementation. (arXiv:2312.01520v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2312.01520](http://arxiv.org/abs/2312.01520)

    本文提出了一种计算贝叶斯网络中Shannon熵和Kullback-Leibler散度的高效算法，并通过一系列数值示例进行了演示。此外，还展示了如何将高斯贝叶斯网络中KL的计算复杂度从立方降低到二次。

    

    贝叶斯网络（BNs）是机器学习和因果推断中的基础模型。它们的图结构可以处理高维问题，并将其分为稀疏的一系列较小问题，这是Judea Pearl的因果性的基础，也决定了它们的可解释性和可理解性。尽管它们很受欢迎，但在文献中几乎没有关于如何在最常见的分布假设下计算BNs的Shannon熵和Kullback-Leibler（KL）散度的资源。在本文中，我们利用BNs的图结构提供了计算效率高的算法，并用一整套数值示例说明了它们。在此过程中，我们展示了可以将高斯BNs的KL计算复杂度从立方降低到二次的可能性。

    Bayesian networks (BNs) are a foundational model in machine learning and causal inference. Their graphical structure can handle high-dimensional problems, divide them into a sparse collection of smaller ones, underlies Judea Pearl's causality, and determines their explainability and interpretability. Despite their popularity, there are almost no resources in the literature on how to compute Shannon's entropy and the Kullback-Leibler (KL) divergence for BNs under their most common distributional assumptions. In this paper, we provide computationally efficient algorithms for both by leveraging BNs' graphical structure, and we illustrate them with a complete set of numerical examples. In the process, we show it is possible to reduce the computational complexity of KL from cubic to quadratic for Gaussian BNs.
    
[^44]: DiffAttack：针对基于扩散的对抗净化的规避攻击

    DiffAttack: Evasion Attacks Against Diffusion-Based Adversarial Purification. (arXiv:2311.16124v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2311.16124](http://arxiv.org/abs/2311.16124)

    这篇论文介绍了DiffAttack，一个针对基于扩散的对抗净化的有效和高效攻击框架，通过引入偏差重构损失和分段式前向后向算法解决了梯度消失/爆炸的问题，验证了其攻击效果。

    

    基于扩散的净化防御利用扩散模型消除对抗示例的制造扰动，并实现了最先进的鲁棒性。最近的研究表明，即使是先进的攻击也无法有效地破坏这种防御，因为净化过程引发了一个极其深层的计算图，可能导致梯度模糊、高内存消耗和无限的随机性问题。在本文中，我们提出了一个统一的框架DiffAttack来对基于扩散的净化防御执行有效和高效的攻击，包括DDPM和基于分数的方法。具体来说，我们在中间的扩散步骤中提出了一个偏差重构损失，以引起不准确的密度梯度估计，以解决梯度消失/爆炸的问题。我们还提供了一种分段式前向后向算法，可以实现高效的梯度反向传播。我们通过与其他攻击方法进行比较验证了DiffAttack的攻击效果。

    Diffusion-based purification defenses leverage diffusion models to remove crafted perturbations of adversarial examples and achieve state-of-the-art robustness. Recent studies show that even advanced attacks cannot break such defenses effectively, since the purification process induces an extremely deep computational graph which poses the potential problem of gradient obfuscation, high memory cost, and unbounded randomness. In this paper, we propose a unified framework DiffAttack to perform effective and efficient attacks against diffusion-based purification defenses, including both DDPM and score-based approaches. In particular, we propose a deviated-reconstruction loss at intermediate diffusion steps to induce inaccurate density gradient estimation to tackle the problem of vanishing/exploding gradients. We also provide a segment-wise forwarding-backwarding algorithm, which leads to memory-efficient gradient backpropagation. We validate the attack effectiveness of DiffAttack compared 
    
[^45]: TEAL: 对于多模态大语言模型的一种将所有模态进行分词和嵌入的方法

    TEAL: Tokenize and Embed ALL for Multi-modal Large Language Models. (arXiv:2311.04589v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2311.04589](http://arxiv.org/abs/2311.04589)

    TEAL是一种用于多模态大语言模型的方法，将不同模态的输入视为令牌序列，并学习它们的联合嵌入空间。这使得模型能够有效地建模多模态输入之间的相互作用，并生成非文本模态的输出。

    

    尽管多模态大语言模型（MM-LLMs）最近取得了令人兴奋的进展，但它们仍然在有效地建模多模态输入之间的相互作用和非文本模态的生成方面面临困难。在这项工作中，我们提出了一种名为TEAL（Tokenize and Embed ALL）的方法，将任何模态的输入视为令牌序列，并学习所有模态的联合嵌入空间。具体而言，对于任何模态的输入，TEAL首先使用现成的分词器将其离散化为令牌序列，然后使用可学习的嵌入矩阵将令牌序列嵌入到联合嵌入空间中。MM-LLMs只需要像文本LLMs那样自回归地预测多模态令牌。最后，根据预测的令牌序列，应用相应的去分词器生成每个模态的输出。通过联合嵌入空间，TEAL使冻结的LLMs能够执行涉及非文本模态的理解和生成任务，如理解和生成图像或音频。

    Despite Multi-modal Large Language Models (MM-LLMs) have made exciting strides recently, they are still struggling to efficiently model the interactions among multi-modal inputs and the generation in non-textual modalities. In this work, we propose TEAL (Tokenize and Embed ALl)}, an approach to treat the input from any modality as a token sequence and learn a joint embedding space for all modalities. Specifically, for the input from any modality, TEAL first discretizes it into a token sequence with the off-the-shelf tokenizer and embeds the token sequence into a joint embedding space with a learnable embedding matrix. MM-LLMs just need to predict the multi-modal tokens autoregressively as the textual LLMs do. Finally, the corresponding de-tokenizer is applied to generate the output in each modality based on the predicted token sequence. With the joint embedding space, TEAL enables the frozen LLMs to perform both understanding and generation tasks involving non-textual modalities, such 
    
[^46]: 预训练推荐系统：一种因果去偏见的视角

    Pre-trained Recommender Systems: A Causal Debiasing Perspective. (arXiv:2310.19251v3 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2310.19251](http://arxiv.org/abs/2310.19251)

    本文探讨了将预训练模型的范式应用于推荐系统的可能性和挑战，提出开发一种通用推荐系统，可以用于少样本学习，并在未知新领域中快速适应，以提高性能。

    

    最近对于预训练的视觉/语言模型的研究表明了一种新的、有前景的解决方案建立范式在人工智能领域，其中模型可以在广泛描述通用任务空间的数据上进行预训练，然后成功地适应解决各种下游任务，即使训练数据非常有限（如在零样本学习或少样本学习场景中）。受到这样的进展的启发，我们在本文中研究了将这种范式调整到推荐系统领域的可能性和挑战，这一领域在预训练模型的视角下较少被调查。特别是，我们提出开发一种通用推荐系统，通过对从不同领域中提取的通用用户-物品交互数据进行训练，捕捉到通用的交互模式，然后可以快速适应提升少样本学习性能，在未知新领域（数据有限）中发挥作用。

    Recent studies on pre-trained vision/language models have demonstrated the practical benefit of a new, promising solution-building paradigm in AI where models can be pre-trained on broad data describing a generic task space and then adapted successfully to solve a wide range of downstream tasks, even when training data is severely limited (e.g., in zero- or few-shot learning scenarios). Inspired by such progress, we investigate in this paper the possibilities and challenges of adapting such a paradigm to the context of recommender systems, which is less investigated from the perspective of pre-trained model. In particular, we propose to develop a generic recommender that captures universal interaction patterns by training on generic user-item interaction data extracted from different domains, which can then be fast adapted to improve few-shot learning performance in unseen new domains (with limited data).  However, unlike vision/language data which share strong conformity in the semant
    
[^47]: DHOT-GM：使用可微分的分层最优传输框架实现鲁棒图匹配

    DHOT-GM: Robust Graph Matching Using A Differentiable Hierarchical Optimal Transport Framework. (arXiv:2310.12081v1 [cs.AI])

    [http://arxiv.org/abs/2310.12081](http://arxiv.org/abs/2310.12081)

    本研究提出了一种名为DHOT-GM的图匹配方法，使用可微分的分层最优传输框架，充分利用了图中隐藏的多模态信息，通过对匹配结果进行加权平均来推断节点对应关系。

    

    在实践中，图匹配是最重要的图分析任务之一，其目标是找到不同图之间的节点对应关系。大多数现有方法在匹配图时依赖于邻接矩阵或节点嵌入，其性能常常不够优越，因为没有充分利用图中隐藏的多模态信息，如节点属性、子图结构等。在本研究中，我们提出了一种基于可微分的分层最优传输（HOT）框架的新颖有效的图匹配方法，称为DHOT-GM。实质上，我们的方法将每个图表示为与不同模态信息对应的一组关系矩阵。给定两个图，我们枚举所有关系矩阵对，并获取它们的匹配结果，然后通过对匹配结果进行加权平均来推断节点对应关系。该方法可以实现为计算两个图之间的HOT距离，每个图都是由关系矩阵表示的。

    Graph matching is one of the most significant graph analytic tasks in practice, which aims to find the node correspondence across different graphs. Most existing approaches rely on adjacency matrices or node embeddings when matching graphs, whose performances are often sub-optimal because of not fully leveraging the multi-modal information hidden in graphs, such as node attributes, subgraph structures, etc. In this study, we propose a novel and effective graph matching method based on a differentiable hierarchical optimal transport (HOT) framework, called DHOT-GM. Essentially, our method represents each graph as a set of relational matrices corresponding to the information of different modalities. Given two graphs, we enumerate all relational matrix pairs and obtain their matching results, and accordingly, infer the node correspondence by the weighted averaging of the matching results. This method can be implemented as computing the HOT distance between the two graphs -- each matching 
    
[^48]: FactoFormer: 通过自监督预训练的分解高光谱变压器

    FactoFormer: Factorized Hyperspectral Transformers with Self-Supervised Pretraining. (arXiv:2309.09431v4 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2309.09431](http://arxiv.org/abs/2309.09431)

    该论文提出了一种Factorized Hyperspectral Transformer，结合了分解的自监督预训练流程，显著提高了性能。

    

    高光谱图像（HSIs）包含丰富的光谱和空间信息。在自然语言处理和计算机视觉领域，变压器在学习输入数据中的长程依赖性方面取得了成功，因此近期的研究集中在将变压器用于HSIs上。然而，当前最先进的高光谱变压器只在光谱维度上对输入的HSI样本进行标记，导致空间信息的利用不足。此外，已知变压器对数据需求量大，并且它们的性能严重依赖于大规模的预训练，而由于有限的标注高光谱数据，这在实践中存在挑战。因此，高光谱变压器的全部潜力尚未完全发挥出来。为了克服这些限制，我们提出了一种新颖的分解光谱-空间变压器，它融合了分解的自监督预训练流程，从而显著提高了性能。

    Hyperspectral images (HSIs) contain rich spectral and spatial information. Motivated by the success of transformers in the field of natural language processing and computer vision where they have shown the ability to learn long range dependencies within input data, recent research has focused on using transformers for HSIs. However, current state-of-the-art hyperspectral transformers only tokenize the input HSI sample along the spectral dimension, resulting in the under-utilization of spatial information. Moreover, transformers are known to be data-hungry and their performance relies heavily on large-scale pretraining, which is challenging due to limited annotated hyperspectral data. Therefore, the full potential of HSI transformers has not been fully realized. To overcome these limitations, we propose a novel factorized spectral-spatial transformer that incorporates factorized self-supervised pretraining procedures, leading to significant improvements in performance. The factorization
    
[^49]: MLN-net：一种利用多层归一化进行集群微钙化的多源医学图像分割方法

    MLN-net: A multi-source medical image segmentation method for clustered microcalcifications using multiple layer normalization. (arXiv:2309.02742v1 [cs.CV])

    [http://arxiv.org/abs/2309.02742](http://arxiv.org/abs/2309.02742)

    提出了一种名为MLN-net的新型框架，用于集群微钙化的准确分割。该方法能够使用单一源图像来准确地分割多源图像，通过多层归一化层结构来处理不同领域的图像分割，进而提高了泛化性能。

    

    针对乳腺X线摄影中集群微钙化的准确分割对于乳腺癌的诊断和治疗至关重要。尽管近期深度学习在医学图像分割方面取得了专家级准确性，但由于患者体位、个体腺体密度和乳腺X线摄影成像模式等方面的差异造成了领域转移，导致在实际应用中贡献有限。本文提出了一种名为MLN-net的新型框架，仅使用单一源图像即可准确地分割多源图像，用于集群微钙化分割。首先，我们提出了一种源域图像增强方法来生成多源图像，从而提高泛化性能。其次，采用了多层归一化（LN）层的结构来构建分割网络，在不同领域中对于集群微钙化分割具有良好效果。此外，还提出了一种支路选择策略来优化分割性能。

    Accurate segmentation of clustered microcalcifications in mammography is crucial for the diagnosis and treatment of breast cancer. Despite exhibiting expert-level accuracy, recent deep learning advancements in medical image segmentation provide insufficient contribution to practical applications, due to the domain shift resulting from differences in patient postures, individual gland density, and imaging modalities of mammography etc. In this paper, a novel framework named MLN-net, which can accurately segment multi-source images using only single source images, is proposed for clustered microcalcification segmentation. We first propose a source domain image augmentation method to generate multi-source images, leading to improved generalization. And a structure of multiple layer normalization (LN) layers is used to construct the segmentation network, which can be found efficient for clustered microcalcification segmentation in different domains. Additionally, a branch selection strateg
    
[^50]: 让声音存在：从无声视频中重建高质量语音

    Let There Be Sound: Reconstructing High Quality Speech from Silent Videos. (arXiv:2308.15256v1 [eess.AS])

    [http://arxiv.org/abs/2308.15256](http://arxiv.org/abs/2308.15256)

    本文介绍了一个重建高质量语音的唇语转语音系统，通过解决一对多映射问题和细节精炼来显著改进生成质量。

    

    本研究的目标是仅通过唇运动重建高质量的语音，也被称为唇语转语音。唇语转语音系统的一个关键挑战是由于同形异音和多样化语音变化而造成的一对多映射，导致发音错误和过度平滑的语音。在本文中，我们提出了一种新颖的唇语转语音系统，通过从多个角度缓解一对多映射问题，显著改进了生成质量。具体来说，我们结合了（1）自我监督的语音表示来消除同形异音，和（2）声学变异信息来建模多样化的语音风格。此外，为了更好地解决上述问题，我们采用了基于流的后处理网络，捕捉和精炼所生成语音的细节。我们进行了大量实验，并证明我们的方法实现了接近真实人类语音的生成质量，超过了现有方法。

    The goal of this work is to reconstruct high quality speech from lip motions alone, a task also known as lip-to-speech. A key challenge of lip-to-speech systems is the one-to-many mapping caused by (1) the existence of homophenes and (2) multiple speech variations, resulting in a mispronounced and over-smoothed speech. In this paper, we propose a novel lip-to-speech system that significantly improves the generation quality by alleviating the one-to-many mapping problem from multiple perspectives. Specifically, we incorporate (1) self-supervised speech representations to disambiguate homophenes, and (2) acoustic variance information to model diverse speech styles. Additionally, to better solve the aforementioned problem, we employ a flow based post-net which captures and refines the details of the generated speech. We perform extensive experiments and demonstrate that our method achieves the generation quality close to that of real human utterance, outperforming existing methods in term
    
[^51]: 不仅仅奖励，还有约束：用于腿式机器人运动的应用

    Not Only Rewards But Also Constraints: Applications on Legged Robot Locomotion. (arXiv:2308.12517v1 [cs.RO])

    [http://arxiv.org/abs/2308.12517](http://arxiv.org/abs/2308.12517)

    本文提出了一种新的强化学习框架，为复杂机器人系统训练神经网络控制器。该框架引入了奖励和约束的概念，通过设计高效的策略优化算法来处理约束，以减少计算开销。通过应用于不同腿式机器人的运动控制器训练中，展示了该框架的有效性。

    

    早期的一些研究通过设计神经网络控制器并使用无模型强化学习来训练，展示了复杂机器人系统中令人印象深刻的控制性能。然而，这些具有自然动作风格和高任务性能的出色控制器是通过进行大量奖励工程而开发的，该过程非常费时费力，需要设计大量奖励项并确定合适的奖励系数。在这项工作中，我们提出了一种新的强化学习框架，用于训练同时包含奖励和约束的神经网络控制器。为了让工程师能够适当地反映他们对约束的意图并以最小的计算开销处理它们，我们提出了两种约束类型和一种高效的策略优化算法。该学习框架被应用于训练不同形态和物理属性的几个腿式机器人的运动控制器。

    Several earlier studies have shown impressive control performance in complex robotic systems by designing the controller using a neural network and training it with model-free reinforcement learning. However, these outstanding controllers with natural motion style and high task performance are developed through extensive reward engineering, which is a highly laborious and time-consuming process of designing numerous reward terms and determining suitable reward coefficients. In this work, we propose a novel reinforcement learning framework for training neural network controllers for complex robotic systems consisting of both rewards and constraints. To let the engineers appropriately reflect their intent to constraints and handle them with minimal computation overhead, two constraint types and an efficient policy optimization algorithm are suggested. The learning framework is applied to train locomotion controllers for several legged robots with different morphology and physical attribu
    
[^52]: 在大型语言模型中释放认知协同：通过多人格自我协作实现任务解决代理

    Unleashing Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration. (arXiv:2307.05300v1 [cs.AI])

    [http://arxiv.org/abs/2307.05300](http://arxiv.org/abs/2307.05300)

    本论文提出了单人表现提示（SPP）的概念，通过与多个角色进行多轮自我协作，将单个语言模型转化为认知协同者，从而增强其在复杂任务中的问题解决能力和整体性能。

    

    人类智慧依赖于认知协同的概念，即在不同认知过程之间进行协作和信息整合，以获得比个体认知过程更出色的结果。尽管大型语言模型（LLM）作为通用任务解决代理表现出了令人期待的性能，但它们在需要丰富领域知识和复杂推理的任务上仍然面临困难。在这项工作中，我们提出了单人表现提示（SPP）的概念，通过与多个角色进行多轮自我协作，将单个LLM转化为认知协同者。认知协同者指的是一个智能代理，与多个智慧合作，结合他们的个体优势和知识，从而增强复杂任务的问题解决能力和整体性能。通过根据任务输入动态识别和模拟不同的角色，SPP释放了LLM中认知协同的潜力。

    Human intelligence thrives on the concept of cognitive synergy, where collaboration and information integration among different cognitive processes yield superior outcomes compared to individual cognitive processes in isolation. Although Large Language Models (LLMs) have demonstrated promising performance as general task-solving agents, they still struggle with tasks that require intensive domain knowledge and complex reasoning. In this work, we propose Solo Performance Prompting (SPP), which transforms a single LLM into a cognitive synergist by engaging in multi-turn self-collaboration with multiple personas. A cognitive synergist refers to an intelligent agent that collaborates with multiple minds, combining their individual strengths and knowledge, to enhance problem-solving and overall performance in complex tasks. By dynamically identifying and simulating different personas based on task inputs, SPP unleashes the potential of cognitive synergy in LLMs. We have discovered that assi
    
[^53]: 可证明强大的有向多图神经网络

    Provably Powerful Graph Neural Networks for Directed Multigraphs. (arXiv:2306.11586v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.11586](http://arxiv.org/abs/2306.11586)

    本文分析了一组简单的改进方法，将标准的消息传递图神经网络（GNN）转化为可证明强大的有向多图神经网络，能够检测任何有向子图模式。实验结果展示了这些改进方法在合成子图检测任务和金融犯罪分析任务上的出色性能。

    

    本文分析了一组简单的改进方法，将标准的消息传递图神经网络（GNN）转化为可证明强大的有向多图神经网络。改进方法包括多图端口编号、个体ID和反向消息传递。我们证明这些方法的组合在理论上能够检测任何有向子图模式。为了验证我们提出的改进方法在实践中的有效性，我们在合成子图检测任务上进行了实验，结果表明其具有出色的性能，几乎可以得到完美的结果。此外，我们将提出的改进方法应用于两个金融犯罪分析任务。我们观察到在检测洗钱交易方面有显著的改善，将标准的消息传递GNN的少数类F1分数提高了高达30%，并且与基于树和GNN的基准相媲美或超越。在一个实际的网络钓鱼检测数据集上也观察到了类似令人印象深刻的结果，提升了三个标准方法的性能。

    This paper analyses a set of simple adaptations that transform standard message-passing Graph Neural Networks (GNN) into provably powerful directed multigraph neural networks. The adaptations include multigraph port numbering, ego IDs, and reverse message passing. We prove that the combination of these theoretically enables the detection of any directed subgraph pattern. To validate the effectiveness of our proposed adaptations in practice, we conduct experiments on synthetic subgraph detection tasks, which demonstrate outstanding performance with almost perfect results. Moreover, we apply our proposed adaptations to two financial crime analysis tasks. We observe dramatic improvements in detecting money laundering transactions, improving the minority-class F1 score of a standard message-passing GNN by up to 30%, and closely matching or outperforming tree-based and GNN baselines. Similarly impressive results are observed on a real-world phishing detection dataset, boosting three standar
    
[^54]: 为大型图表示简化和增强Transformer

    Simplifying and Empowering Transformers for Large-Graph Representations. (arXiv:2306.10759v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.10759](http://arxiv.org/abs/2306.10759)

    本文通过实验证明，在大型图上使用一层注意力即可获得令人惊讶的竞争性能，挑战了在语言和视觉任务中复杂模型的应用。这促使我们重新思考在大型图上设计Transformer的理念，以提高可扩展性。

    

    在大型图上学习表示是一个长期存在的挑战，因为其中涉及了大量数据点之间的相互依赖关系。Transformer作为一种新兴的用于图结构数据的基本编码器类别，由于其全局注意力可以捕捉到邻节点之外的所有对影响，因此在小型图上表现出了有希望的性能。尽管如此，现有方法往往继承了Transformer在语言和视觉任务中的思想，并通过堆叠深层多头注意力来采用复杂的模型。本文通过关于节点属性预测基准的实验证明，即使只使用一层注意力也能在节点数量从千级到十亿级的范围内带来令人惊讶的竞争性能。这鼓励我们重新思考在大型图上设计Transformer的理念，其中全局注意力是一个阻碍可扩展性的计算开销。我们将提出的方案称为简化图Transformer。

    Learning representations on large-sized graphs is a long-standing challenge due to the inter-dependence nature involved in massive data points. Transformers, as an emerging class of foundation encoders for graph-structured data, have shown promising performance on small graphs due to its global attention capable of capturing all-pair influence beyond neighboring nodes. Even so, existing approaches tend to inherit the spirit of Transformers in language and vision tasks, and embrace complicated models by stacking deep multi-head attentions. In this paper, we critically demonstrate that even using a one-layer attention can bring up surprisingly competitive performance across node property prediction benchmarks where node numbers range from thousand-level to billion-level. This encourages us to rethink the design philosophy for Transformers on large graphs, where the global attention is a computation overhead hindering the scalability. We frame the proposed scheme as Simplified Graph Trans
    
[^55]: 自适应基于梯度的异常值去除的嘈杂标签学习方法

    Learning with Noisy Labels by Adaptive Gradient-Based Outlier Removal. (arXiv:2306.04502v1 [cs.LG])

    [http://arxiv.org/abs/2306.04502](http://arxiv.org/abs/2306.04502)

    本文提出了一种名为AGRA的自适应梯度异常值去除方法，能够在模型训练过程中动态调整数据集从而有效提高模型学习效果。

    

    训练可靠和高性能模型需要准确和丰富的数据集，但即便是人工标注的数据集也会包含错误，更不用说自动标注的数据集了。现有的一些数据去噪方法主要集中于检测异常值并进行永久性去除，但这种方法很容易过度或者欠度过滤数据集。在本论文中，我们提出了一种新的自适应梯度异常值去除方法（AGRA），不同于在模型训练之前清洗数据集，我们的方法在训练过程中动态调整数据集。通过比较一组样本的累积梯度和单个样本的梯度，我们的方法可以决定是否在当前更新时保留对应的样本，以此来确定它是否有助于模型的学习效果。在多个数据集上进行的广泛评估表明，AGRA方法的有效性，并且全面的结果分析证实了我们方法的理论和实践收益。

    An accurate and substantial dataset is necessary to train a reliable and well-performing model. However, even manually labeled datasets contain errors, not to mention automatically labeled ones. The problem of data denoising was addressed in different existing research, most of which focuses on the detection of outliers and their permanent removal - a process that is likely to over- or underfilter the dataset. In this work, we propose AGRA: a new method for Adaptive GRAdient-based outlier removal. Instead of cleaning the dataset prior to model training, the dataset is adjusted during the training process. By comparing the aggregated gradient of a batch of samples and an individual example gradient, our method dynamically decides whether a corresponding example is helpful for the model at this point or is counter-productive and should be left out for the current update. Extensive evaluation on several datasets demonstrates the AGRA effectiveness, while comprehensive results analysis sup
    
[^56]: 在符合性预测中量化深度学习模型的不确定性

    Quantifying Deep Learning Model Uncertainty in Conformal Prediction. (arXiv:2306.00876v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.00876](http://arxiv.org/abs/2306.00876)

    本文针对深度学习模型的不确定性进行了量化，采用了符合性预测框架来计算模型的置信水平，并与其他不确定性量化方法进行了比较。

    

    在机器学习和统计建模中，精确估计深度神经网络的预测不确定性对于可靠的决策至关重要，尤其在医疗人工智能的背景下。符合性预测（CP）已经成为一个有希望的框架，通过提供良好校准的置信水平来表示模型的不确定性以进行单个预测。然而，对于在符合性预测中量化模型不确定性的研究仍然是一个活跃的领域，还没有完全解决。在本文中，我们探讨了最先进的符合性预测方法及其理论基础。我们提出了一个概率方法来量化符合性预测中产生的预测集的模型不确定性，并为计算得到的不确定性提供了认证边界。通过这样做，我们可以将通过CP测量的模型不确定性与其他不确定性量化方法（如贝叶斯方法、MC-Dropout和DeepEnsemble）进行比较.

    Precise estimation of predictive uncertainty in deep neural networks is a critical requirement for reliable decision-making in machine learning and statistical modeling, particularly in the context of medical AI. Conformal Prediction (CP) has emerged as a promising framework for representing the model uncertainty by providing well-calibrated confidence levels for individual predictions. However, the quantification of model uncertainty in conformal prediction remains an active research area, yet to be fully addressed. In this paper, we explore state-of-the-art CP methodologies and their theoretical foundations. We propose a probabilistic approach in quantifying the model uncertainty derived from the produced prediction sets in conformal prediction and provide certified boundaries for the computed uncertainty. By doing so, we allow model uncertainty measured by CP to be compared by other uncertainty quantification methods such as Bayesian (e.g., MC-Dropout and DeepEnsemble) and Evidentia
    
[^57]: STAS: 多智能体强化学习的时空回报分解

    STAS: Spatial-Temporal Return Decomposition for Multi-agent Reinforcement Learning. (arXiv:2304.07520v1 [cs.AI])

    [http://arxiv.org/abs/2304.07520](http://arxiv.org/abs/2304.07520)

    提出了一种名为STAS的新方法，用于多智能体强化学习中时空回报分解，可以对代理进行信用分配。该方法引入了Shapley值和空间-时间注意机制来解决先前方法中延迟全局回报的复杂关系问题。在各种基准环境下，该方法表现良好。

    

    集中式训练和分散式执行（CTDE）已被证明是合作多智能体强化学习（MARL）中有效的范例。其中一个主要的挑战是赋信用值，即通过代理的贡献来给代理赋信用值。先前的研究集中于隐式地分解联合价值函数或显式地计算所有代理的支付分配。然而，在只有在周期性强化学习设置中，全局奖励只能在周期结束时显示。现有的方法通常不起作用。它们缺乏对延迟全局奖励在时间维度中复杂关系的建模功能，并且受偏差和方差的影响较大。我们提出了一种名为空间时间关注与 Shapley（STAS）的新方法，用于回报分解；STAS 在时间和空间维度上学习信用分配。它首先将全局回报分解回到每个时间步，然后使用Shapley值来评估协作MARL中每个代理的贡献。 STAS 还引入了一种空间 - 时间关注机制，以捕获延迟全局奖励的复杂关系。我们的实验表明，在各种基准环境中，STAS 能够胜过最先进的方法。

    Centralized Training with Decentralized Execution (CTDE) has been proven to be an effective paradigm in cooperative multi-agent reinforcement learning (MARL). One of the major challenges is yet credit assignment, which aims to credit agents by their contributions. Prior studies focus on either implicitly decomposing the joint value function or explicitly computing the payoff distribution of all agents. However, in episodic reinforcement learning settings where global rewards can only be revealed at the end of the episode, existing methods usually fail to work. They lack the functionality of modeling complicated relations of the delayed global reward in the temporal dimension and suffer from large variance and bias. We propose a novel method named Spatial-Temporal Attention with Shapley (STAS) for return decomposition; STAS learns credit assignment in both the temporal and the spatial dimension. It first decomposes the global return back to each time step, then utilizes Shapley Value to
    
[^58]: 通过内容感知的风格不变模型学习对未知领域进行泛化：用于胸部X射线疾病检测的翻译摘要

    Learning to Generalize towards Unseen Domains via a Content-Aware Style Invariant Model for Disease Detection from Chest X-rays. (arXiv:2302.13991v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.13991](http://arxiv.org/abs/2302.13991)

    通过内容感知的风格不变模型，我们提出了一种解决深度学习医学图像分析中源领域不匹配挑战的方法。我们采用了风格随机化模块来提取既是风格不变又是内容偏好的领域不变特征，在胸部X射线疾病检测中取得了良好的性能。

    

    在基于深度学习的医学图像分析中，由于源领域不匹配而导致性能降低一直是一个长期存在的挑战，特别是在胸部X射线（CXR）领域。为了解决这种领域转移问题，已经提出了一些方法（如对抗训练，多领域混合），用于提取领域不变的高级特征。然而，这些方法并没有明确规范提取的领域不变特征的内容和风格特征。最近的研究表明，CNN模型对风格（例如，无信息的纹理）有很强的偏好，而不是对内容（例如，形状）的偏好，这与人类视觉系统形成鲜明对比。放射科医师倾向于从CXR图像中学习视觉线索，并因此在多个领域中表现良好。因此，在从CXR图像进行病理诊断的医学成像中，模型应该提取既是风格不变又是内容偏好的领域不变特征。受此启发，我们在实验中使用了新颖的风格随机化模块（SRMs）。

    Performance degradation due to source domain mismatch is a longstanding challenge in deep learning-based medical image analysis, particularly for chest X-rays (CXRs). Several methods (e.g., adversarial training, multi-domain mixups) have been proposed to extract domain-invariant high-level features to address this domain shift. However, these methods do not explicitly regularize the content and style characteristics of the extracted domain-invariant features. Recent studies have demonstrated that CNN models exhibit a strong bias toward styles (e.g., uninformative textures) rather than content (e.g., shape), in stark contrast to the human-vision system. Radiologists tend to learn visual cues from CXRs and thus perform well across multiple domains. Therefore, in medical imaging for pathology diagnosis from CXR images, models should extract domain-invariant features that are style-invariant and content-biased. Motivated by this, we employ the novel style randomization modules (SRMs) at bo
    
[^59]: SynthMorph实现的考虑解剖结构和无关采集方法的联合配准

    Anatomy-aware and acquisition-agnostic joint registration with SynthMorph. (arXiv:2301.11329v2 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2301.11329](http://arxiv.org/abs/2301.11329)

    SynthMorph是一个易于使用的DL工具，用于无需预处理即可直接从MRI扫描仪上对任何脑图像进行联合仿射-可变形配准，采用了从标签图生成具有极大差异图像的策略，实现了更准确和鲁棒的图像配准。

    

    仿射图像配准是医学图像分析的基石。虽然传统算法可以实现优秀的准确性，但它们需要为每一对图像进行耗时的优化。深度学习方法通过学习一个将图像对映射到输出变换的函数来解决这个问题。评估这个函数是快速的，但捕捉大的变换可能是具有挑战性的，而且如果测试图像的特征从训练领域变化，如分辨率，网络往往会出现困难。大多数仿射方法是对解剖结构无知的，意味着如果算法考虑图像中的所有结构，配准会不准确。我们通过SynthMorph解决了这些缺点，它是一个易于使用的DL工具，用于对任何脑图像进行联合仿射-可变形配准，无需预处理即可直接从MRI扫描仪进行操作。首先，我们利用从标签图生成的具有极大差异的图像来训练网络的策略，从而实现对训练过程中未见的多样化采集规范的鲁棒性能。其次，我们优化网络的损失函数，使其能够考虑不同的解剖特征和学习抵制采集特定限制的变换。通过这些创新，我们实现了更准确和鲁棒的图像配准。

    Affine image registration is a cornerstone of medical-image analysis. While classical algorithms can achieve excellent accuracy, they solve a time-consuming optimization for every image pair. Deep-learning (DL) methods learn a function that maps an image pair to an output transform. Evaluating the function is fast, but capturing large transforms can be challenging, and networks tend to struggle if a test-image characteristic shifts from the training domain, such as resolution. Most affine methods are agnostic to anatomy, meaning the registration will be inaccurate if algorithms consider all structures in the image.  We address these shortcomings with SynthMorph, an easy-to-use DL tool for joint affine-deformable registration of any brain image without preprocessing, right off the MRI scanner. First, we leverage a strategy to train networks with wildly varying images synthesized from label maps, yielding robust performance across acquisition specifics unseen at training. Second, we opti
    
[^60]: NSGA-II在多模式问题上的第一次运行时间分析

    A First Runtime Analysis of the NSGA-II on a Multimodal Problem. (arXiv:2204.13750v5 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2204.13750](http://arxiv.org/abs/2204.13750)

    本论文对多目标进化优化器NSGA-II在多模式问题上的运行时间进行了第一次分析，证明了当种群大小足够大时，NSGA-II能够在时间复杂度为O(N n^k)内优化OneJumpZeroJump基准问题，且使用快速突变算子可以提高优化效果。

    

    最近，对多目标进化优化器NSGA-II进行了第一次数学运行时间分析。我们继续这项研究，在一个包含两个多模式目标的基准问题上进行了该算法的第一个运行时间分析。我们证明，如果种群大小N至少是帕累托前沿大小的四倍，则带有四种不同选择父代和位突变的NSGA-II能够在时间复杂度为O(N n^k)内优化OneJumpZeroJump基准问题，其中2≤k≤n/4。当使用快速突变时，最近提出的重尾突变算子可以将这一保证提高至k^Ω(k)倍。总体而言，这项工作表明，NSGA-II至少与全局SEMO算法一样能够处理OneJumpZeroJump问题的局部最优解。

    Very recently, the first mathematical runtime analyses of the multi-objective evolutionary optimizer NSGA-II have been conducted. We continue this line of research with a first runtime analysis of this algorithm on a benchmark problem consisting of two multimodal objectives. We prove that if the population size $N$ is at least four times the size of the Pareto front, then the NSGA-II with four different ways to select parents and bit-wise mutation optimizes the OneJumpZeroJump benchmark with jump size~$2 \le k \le n/4$ in time $O(N n^k)$. When using fast mutation, a recently proposed heavy-tailed mutation operator, this guarantee improves by a factor of $k^{\Omega(k)}$. Overall, this work shows that the NSGA-II copes with the local optima of the OneJumpZeroJump problem at least as well as the global SEMO algorithm.
    
[^61]: 垂直联合学习的数据价值评估：一种无模型且保护隐私的方法

    Data Valuation for Vertical Federated Learning: A Model-free and Privacy-preserving Method. (arXiv:2112.08364v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2112.08364](http://arxiv.org/abs/2112.08364)

    提出了一种垂直联合学习中的数据价值评估方法FedValue，该方法是隐私保护、针对任务而无需模型的。它包括数据价值度量MShapley-CMI和联合计算方法，有助于解决垂直联合学习中评估数据方数据价值的问题。

    

    垂直联合学习（VFL）是一种有前景的预测分析范式，通过与多个数据提供方（即数据方）的合作，在分散和保护隐私的方式下，赋予一个组织（即任务方）提高其预测模型的能力。尽管对VFL的兴趣不断增长，但缺乏有效且安全的工具来评估数据方拥有的数据价值，制约了VFL在商业环境中的应用。为解决这个问题，我们提出了FedValue，一种针对VFL的保护隐私且针对任务的无模型数据价值评估方法，它由数据价值度量和联合计算方法组成。具体来说，我们首先引入一种新颖的数据价值度量，即MShapley-CMI。该度量评估数据方对预测分析任务的贡献，而无需执行机器学习模型，使其非常适合于VFL的实际应用。接下来，我们开发了一种创新的联合计算方法。

    Vertical Federated learning (VFL) is a promising paradigm for predictive analytics, empowering an organization (i.e., task party) to enhance its predictive models through collaborations with multiple data suppliers (i.e., data parties) in a decentralized and privacy-preserving way. Despite the fast-growing interest in VFL, the lack of effective and secure tools for assessing the value of data owned by data parties hinders the application of VFL in business contexts. In response, we propose FedValue, a privacy-preserving, task-specific but model-free data valuation method for VFL, which consists of a data valuation metric and a federated computation method. Specifically, we first introduce a novel data valuation metric, namely MShapley-CMI. The metric evaluates a data party's contribution to a predictive analytics task without the need of executing a machine learning model, making it well-suited for real-world applications of VFL. Next, we develop an innovative federated computation met
    
[^62]: 通过一步式绳索多目标学习处理噪声标签及其在幽门螺杆菌分割中的应用

    Handling Noisy Labels via One-Step Abductive Multi-Target Learning and Its Application to Helicobacter Pylori Segmentation. (arXiv:2011.14956v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2011.14956](http://arxiv.org/abs/2011.14956)

    本文研究了处理噪声标签的新方法，特别针对医学组织病理学图像分析中的困难情况。通过一步式绳索多目标学习，该方法克服了标签中存在的复杂噪声和评估策略不明确的问题。

    

    由于在许多现实场景中缺乏准确的地面实况标签，因此从噪声标签中学习是一个重要问题。在实践中，针对这个问题的不同方法首先对可能有噪声标签的实例进行一些纠正，然后用纠正信息更新预测模型。然而，在医学组织病理学全切片图像分析（MHWSIA）等特定领域中，专家往往难以或甚至无法手动实现无噪声的地面实况标签，导致标签存在复杂噪声。这种情况引发了两个更加困难的问题：1）由于标签中存在复杂噪声，先前方法纠正可能有噪声标签的实例的方法学存在局限性；2）由于收集无噪声地面实况标签非常困难，验证/测试的适当评估策略不明确。本文重点研究了缓解以上问题的方法。

    Learning from noisy labels is an important concern because of the lack of accurate ground-truth labels in plenty of real-world scenarios. In practice, various approaches for this concern first make some corrections corresponding to potentially noisy-labeled instances, and then update predictive model with information of the made corrections. However, in specific areas, such as medical histopathology whole slide image analysis (MHWSIA), it is often difficult or even impossible for experts to manually achieve the noisy-free ground-truth labels which leads to labels with complex noise. This situation raises two more difficult problems: 1) the methodology of approaches making corrections corresponding to potentially noisy-labeled instances has limitations due to the complex noise existing in labels; and 2) the appropriate evaluation strategy for validation/testing is unclear because of the great difficulty in collecting the noisy-free ground-truth labels. In this paper, we focus on allevia
    
[^63]: 机器人乒乓球中的高效样本增强学习

    Sample-efficient Reinforcement Learning in Robotic Table Tennis. (arXiv:2011.03275v4 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2011.03275](http://arxiv.org/abs/2011.03275)

    这篇论文研究了机器人乒乓球中的高效样本增强学习算法，通过嵌入到机器人系统中，在少数尝试中实现了高效学习。

    

    强化学习在各种计算机游戏和模拟中取得了一些令人印象深刻的成就。然而，大多数成功案例都是基于大量试验次数的学习。而在典型的机器人应用中，可行尝试次数非常有限。本文提出了一种适用于乒乓球机器人的高效样本增强学习算法。在乒乓球中，每个击球都是不同的，具有不同的位置、速度和旋转。因此，必须根据高维连续状态空间找到准确的回球方式。为了在少数尝试中实现学习，该方法被嵌入到我们的机器人系统中，使用一步环境。状态空间取决于击球时球的位置、速度和旋转，动作是击球时球拍的状态（方向、速度）。我们开发了基于演员-评论家的确定性策略梯度算法来加速学习。我们的方法可以以较少的样本次数实现高效学习。

    Reinforcement learning (RL) has achieved some impressive recent successes in various computer games and simulations. Most of these successes are based on having large numbers of episodes from which the agent can learn. In typical robotic applications, however, the number of feasible attempts is very limited. In this paper we present a sample-efficient RL algorithm applied to the example of a table tennis robot. In table tennis every stroke is different, with varying placement, speed and spin. An accurate return therefore has to be found depending on a high-dimensional continuous state space. To make learning in few trials possible the method is embedded into our robot system. In this way we can use a one-step environment. The state space depends on the ball at hitting time (position, velocity, spin) and the action is the racket state (orientation, velocity) at hitting. An actor-critic based deterministic policy gradient algorithm was developed for accelerated learning. Our approach per
    

