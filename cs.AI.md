# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Probabilistic Sampling of Balanced K-Means using Adiabatic Quantum Computing.](http://arxiv.org/abs/2310.12153) | 该论文研究了使用绝热量子计算的平衡K-Means聚类的概率采样方法，通过利用非最优解来计算校准后验概率，实现在D-Wave AQC上识别模糊解决方案和数据点的目标。 |
| [^2] | [Fairer and More Accurate Tabular Models Through NAS.](http://arxiv.org/abs/2310.12145) | 通过使用多目标神经架构搜索(NAS)和超参数优化(HPO)，我们在表格数据领域首次提出了一种更新模型架构和超参数的策略，以寻找更公平和准确的模型。我们发现，仅针对准确性进行优化可能会导致公平性的降低，因此需要同时考虑准确性和公平性。 |
| [^3] | [A comprehensible analysis of the efficacy of Ensemble Models for Bug Prediction.](http://arxiv.org/abs/2310.12133) | 本文通过对两种基于人工智能的方法进行Java类错误预测效力的比较和分析，发现集成人工智能模型优于单一人工智能模型，并提供了有助于提升集成人工智能模型性能的因素。 |
| [^4] | [DiagrammerGPT: Generating Open-Domain, Open-Platform Diagrams via LLM Planning.](http://arxiv.org/abs/2310.12128) | DiagrammerGPT是一个通过LLM规划生成开放领域、开放平台的图表的框架，填补了T2I模型在图表生成方面的空白。 |
| [^5] | [SHARCS: Efficient Transformers through Routing with Dynamic Width Sub-networks.](http://arxiv.org/abs/2310.12126) | SHARCS是一种高效的Transformer模型，通过动态宽度子网络进行路由，实现自适应推理和更高的效率，同时在各种分类任务中表现优越并且具有通用性。 |
| [^6] | [A Cautionary Tale: On the Role of Reference Data in Empirical Privacy Defenses.](http://arxiv.org/abs/2310.12112) | 本文研究了实证隐私防御中参考数据的作用和隐私问题，提出了一种基准防御方法，实现了模型效用和训练数据隐私的权衡。 |
| [^7] | [DASA: Difficulty-Aware Semantic Augmentation for Speaker Verification.](http://arxiv.org/abs/2310.12111) | 本文提出了一种面向说话人验证的难度感知语义增强(DASA)方法，通过扰动语义方向来增强训练样本，并引入了难度感知的加性边界软最大值(DAAM-Softmax)来实现最优的说话人嵌入，从而改善模型的泛化能力和鲁棒性。 |
| [^8] | [Quality Diversity through Human Feedback.](http://arxiv.org/abs/2310.12103) | 本文提出了一种通过人类反馈实现质量多样性（Quality Diversity through Human Feedback，QDHF）的方法，该方法利用人类反馈推断多样性指标，扩展了质量多样性（Quality Diversity，QD）算法的适用性。实验证明，QDHF在自动多样性发现方面表现出色，并且具有与QD相匹配的搜索能力。 |
| [^9] | [Non-Intrusive Adaptation: Input-Centric Parameter-efficient Fine-Tuning for Versatile Multimodal Modeling.](http://arxiv.org/abs/2310.12100) | 这篇论文介绍了一种非侵入式的参数高效微调技术（AdaLink），通过只调整模型的外部参数而保持内部结构不变，实现了对多模态建模的竞争性能，这对于大规模语言模型和视觉语言模型的自适应和部署具有重要意义。 |
| [^10] | [Unveiling the Siren's Song: Towards Reliable Fact-Conflicting Hallucination Detection.](http://arxiv.org/abs/2310.12086) | 该论文介绍了一种为大型语言模型设计的FactCHD事实冲突幻觉检测基准，用于评估LLMs生成文本的事实性。基准包含了多种事实模式，并使用基于事实的证据链进行组合性幻觉的检测。 |
| [^11] | [DHOT-GM: Robust Graph Matching Using A Differentiable Hierarchical Optimal Transport Framework.](http://arxiv.org/abs/2310.12081) | 本研究提出了一种名为DHOT-GM的图匹配方法，使用可微分的分层最优传输框架，充分利用了图中隐藏的多模态信息，通过对匹配结果进行加权平均来推断节点对应关系。 |
| [^12] | [Black-Box Training Data Identification in GANs via Detector Networks.](http://arxiv.org/abs/2310.12063) | 本研究探索了在黑盒设置中使用GAN时的隐私问题，通过引入一套攻击来识别训练数据成员身份，本文提供了对版权和数据隐私方面的重要洞见。 |
| [^13] | [Machine Learning-based Nutrient Application's Timeline Recommendation for Smart Agriculture: A Large-Scale Data Mining Approach.](http://arxiv.org/abs/2310.12052) | 本文研究了基于机器学习的智能农业营养应用时间推荐方法。通过预测整个季节所需的肥料数量，并根据天气条件和土壤特性调整肥料量，以促进经济高效和环境友好的农业。研究还探讨了施肥应用与天气数据对作物产量的影响。 |
| [^14] | [A General Theoretical Paradigm to Understand Learning from Human Preferences.](http://arxiv.org/abs/2310.12036) | 本文研究了学习从人类偏好中学习的实际算法的理论基础，推导出一个新的一般目标，绕过了两个重要的近似。这种方法允许直接从收集的数据中学习策略而无需奖励模型的训练。 |
| [^15] | [SegmATRon: Embodied Adaptive Semantic Segmentation for Indoor Environment.](http://arxiv.org/abs/2310.12031) | SegmATRon是一种自适应变换模型，用于室内图像的语义分割。通过在多张图像上进行推断时权重的自适应调整，可以提高语义分割的质量。在室内环境中使用代理的行为获取额外图像的方法在实验中证明是有效的。 |
| [^16] | [Multi-view Contrastive Learning for Entity Typing over Knowledge Graphs.](http://arxiv.org/abs/2310.12008) | 本文提出了一种名为多视角对比学习的新方法，该方法有效地将类型聚类提供的粗粒度知识编码到实体和类型嵌入中，从而改进了知识图谱实体类型判断任务。 |
| [^17] | [KI-PMF: Knowledge Integrated Plausible Motion Forecasting.](http://arxiv.org/abs/2310.12007) | 本研究提出了一种名为KI-PMF的方法，通过结合先验知识，对交通参与者的未来行动进行准确预测，遵循车辆的运动约束和行驶环境的几何形状。通过条件化网络以遵循物理定律，可以获得准确和安全的预测，对于在实际环境中维护自动驾驶汽车的安全和效率至关重要。 |
| [^18] | [Sociotechnical Safety Evaluation of Generative AI Systems.](http://arxiv.org/abs/2310.11986) | 本文提出了一个三层框架，采用社会技术方法对生成型AI系统的安全风险进行评估。同时，评估现状调查发现了三个显著的评估差距，并提出了解决这些差距的方法。 |
| [^19] | [InfoDiffusion: Information Entropy Aware Diffusion Process for Non-Autoregressive Text Generation.](http://arxiv.org/abs/2310.11976) | InfoDiffusion是一种非自回归文本扩散模型，通过引入“keyinfo-first”生成策略和基于文本信息量的噪声调度，以及结合自我条件和部分加噪模型结构的方法，提高了生成质量和多样性，并展示出更高的采样效率。 |
| [^20] | [Improving Generalization of Alignment with Human Preferences through Group Invariant Learning.](http://arxiv.org/abs/2310.11971) | 该论文提出了一种通过强化学习实现在不同数据组或领域中学习一致策略的方法，该方法可以提高AI助手对不同领域的泛化能力，并更好地与人类偏好对齐。 |
| [^21] | [A Multi-Scale Decomposition MLP-Mixer for Time Series Analysis.](http://arxiv.org/abs/2310.11959) | 我们提出了一种名为MSD-Mixer的多尺度分解MLP-Mixer模型，它能够将时间序列分解成不同的组成部分，并在不同的层次中表示这些组成部分。我们还提出了一种新颖的时间拼接方法，以处理多尺度的时间模式和通道间的依赖关系。我们的模型能够比现有方法更好地进行时间序列分析。 |
| [^22] | [Too Good To Be True: performance overestimation in (re)current practices for Human Activity Recognition.](http://arxiv.org/abs/2310.11950) | 本文发现在人类活动识别中存在性能评估过高的问题，传统方法中的数据分割和交叉验证导致了结果的偏见。这个问题在最新的研究中很常见，但往往被忽视。不正确的结果会导致报告较低准确度的论文更难发表。 |
| [^23] | [A Benchmark for Semi-Inductive Link Prediction in Knowledge Graphs.](http://arxiv.org/abs/2310.11917) | 本文提出了一个用于评估知识图谱中半感应式链接预测模型的大规模基准，基于Wikidata5M进行扩展。通过各种不同的任务和信息组合，该基准为进一步研究上下文和文本信息在链接预测中的整合提供了一个测试平台。 |
| [^24] | [Analyze Mass Spectrometry data with Artificial Intelligence to assist the understanding of past habitability of Mars and provide insights for future missions.](http://arxiv.org/abs/2310.11888) | 本文介绍了一种利用人工智能分析质谱数据以检测古代火星适居性潜力的方法，并展示了该方法在外星物质分析中的适用性。关键技术包括质谱值的转换、数据可视化和机器学习模型的应用。 |
| [^25] | [From Neural Activations to Concepts: A Survey on Explaining Concepts in Neural Networks.](http://arxiv.org/abs/2310.11884) | 本文调查了解释神经网络中概念的最新方法，这对于实现基于可解释概念的神经符号化人工智能来说是重要的一步。 |
| [^26] | [AI Nushu: An Exploration of Language Emergence in Sisterhood -Through the Lens of Computational Linguistics.](http://arxiv.org/abs/2310.11870) | 本文介绍了一种受女书启发的新兴语言系统AI Nushu，通过计算语言学的视角，结合中国文化遗产和女权主义视角，通过两个AI代理人的合作创造了一个标准的中文写作系统。 |
| [^27] | [The Value-Sensitive Conversational Agent Co-Design Framework.](http://arxiv.org/abs/2310.11848) | 本文介绍了一种价值感知对话代理共同设计框架，旨在与相关利益相关者合作设计具有价值感知的对话代理。 |
| [^28] | [Masked Pretraining for Multi-Agent Decision Making.](http://arxiv.org/abs/2310.11846) | 我们提出了一个掩码预训练框架(MaskMA)用于解决多智能体决策中的挑战。这个框架采用变压器架构，并使用基于掩码的协作学习策略，同时整合了可泛化的动作表示。 |
| [^29] | [Classification Aggregation without Unanimity.](http://arxiv.org/abs/2310.11841) | 这项研究证明了每个公民主权和独立的分类聚合函数本质上都是一种独裁制度，并提出了一种替代证明技术来解决两个类别的情况，同时识别出两个类别和两个物体情况下的所有独立和一致的分类聚合函数。 |
| [^30] | [IntentDial: An Intent Graph based Multi-Turn Dialogue System with Reasoning Path Visualization.](http://arxiv.org/abs/2310.11818) | IntentDial是一种基于图的多轮对话系统，在实现意图检测和识别时使用强化学习和推理路径可视化组件，有助于提高对话系统的性能和改进。 |
| [^31] | [Conservative Predictions on Noisy Financial Data.](http://arxiv.org/abs/2310.11815) | 在嘈杂的金融数据上进行保守预测，通过对不确定的数据点进行剪枝，以提高预测的准确性。 |
| [^32] | [Learning and Discovering Quantum Properties with Multi-Task Neural Networks.](http://arxiv.org/abs/2310.11807) | 这篇论文介绍了一种用多任务神经网络学习和发现量子性质的方法，该方法能够同时预测和发现多个量子性质，并且能够推断多体量子系统的全局性质和发现不同相之间的未知边界。 |
| [^33] | [Auction-Based Scheduling.](http://arxiv.org/abs/2310.11798) | 该论文提出了一种基于拍卖的调度框架，用于解决多目标决策问题。该框架的创新之处在于将每个目标的实现分配给单独的策略，并且可以独立创建、修改和替换这些策略。使用拍卖机制来解决冲突和组合策略，确保长期的调度公平性。 |
| [^34] | [Telecom AI Native Systems in the Age of Generative AI -- An Engineering Perspective.](http://arxiv.org/abs/2310.11770) | 电信行业试图将生成式AI和基础模型（FMs）整合进产品开发中，形成AI原生的电信系统。然而，伦理、监管和运营方面的挑战需要慎重考虑。 |
| [^35] | [Estimating Material Properties of Interacting Objects Using Sum-GP-UCB.](http://arxiv.org/abs/2310.11749) | 本文提出了一种使用Sum-GP-UCB方法估计互动物体材料性质的贝叶斯优化方法，在不同组互动物体场景的观察下，通过建模奖励函数结构和部分评估来加速优化过程。 |
| [^36] | [Action-Quantized Offline Reinforcement Learning for Robotic Skill Learning.](http://arxiv.org/abs/2310.11731) | 本文提出了一种适应性动作量化方案，通过使用VQ-VAE来学习状态条件下的动作量化，从而改善了机器人技能学习的离线强化学习在离散动作设置下的表现。 |
| [^37] | [Federated Heterogeneous Graph Neural Network for Privacy-preserving Recommendation.](http://arxiv.org/abs/2310.11730) | 本文提出了一种联邦异构图神经网络（FedHGNN）的框架，能够在分布式的异构信息网络上协同训练推荐模型，同时保护用户隐私。 |
| [^38] | [Uncertainty in Automated Ontology Matching: Lessons Learned from an Empirical Experimentation.](http://arxiv.org/abs/2310.11723) | 本文通过实证实验揭示了自动本体匹配中存在的不确定性，这是数据集成领域的一个紧迫问题。 |
| [^39] | [Quantify Health-Related Atomic Knowledge in Chinese Medical Large Language Models: A Computational Analysis.](http://arxiv.org/abs/2310.11722) | 本研究通过构建一个基准，量化了中文医学大型语言模型中与健康相关的原子知识的存储程度，并发现通用LLMs在原子知识和指令遵循能力方面表现更好。两种类型的LLMs都倾向于迎合用户要求。 |
| [^40] | [Enhancing Low-resource Fine-grained Named Entity Recognition by Leveraging Coarse-grained Datasets.](http://arxiv.org/abs/2310.11715) | 通过利用粗粒度数据集，提出了一种细粒度命名实体识别模型，使用细粒度-粗粒度映射矩阵来显式利用层次结构，并提出了一种不一致性过滤方法，以增强低资源细粒度命名实体识别。 |
| [^41] | [Learning Co-Speech Gesture for Multimodal Aphasia Type Detection.](http://arxiv.org/abs/2310.11710) | 通过学习语音和手势之间的相关性，我们提出了一种多模态图神经网络，用于准确识别特定失语类型的检测。实验证明我们的方法优于现有方法，达到了最先进的结果（F1 84.2%）。 |
| [^42] | [Live Graph Lab: Towards Open, Dynamic and Real Transaction Graphs with NFT.](http://arxiv.org/abs/2310.11709) | 本文介绍了用于时间图的“实时图实验室”的概念，该实验室可以从NFT的区块链中提取开放、动态和实时的交易图，为了弥补对新兴NFT生态系统的特性了解的缺口，我们使用NFT交易网络实例化了一个实时图并进行了调查 |
| [^43] | [A Comprehensive Survey on Vector Database: Storage and Retrieval Technique, Challenge.](http://arxiv.org/abs/2310.11703) | 这篇论文对向量数据库进行了全面调查，介绍了存储和检索技术以及面临的挑战，对解决近似最近邻搜索问题的不同方法进行了分类，并探讨了向量数据库与大型语言模型的结合带来的新机遇。 |
| [^44] | [Runner re-identification from single-view video in the open-world setting.](http://arxiv.org/abs/2310.11700) | 本论文提出了一种在开放世界环境中直接处理单视角视频的跑者再识别系统。通过自动处理原始视频作为输入来识别跑者，并且能够在跑者被框选出多次的情况下进行识别。 |
| [^45] | [Quantum Acceleration of Infinite Horizon Average-Reward Reinforcement Learning.](http://arxiv.org/abs/2310.11684) | 本研究探索了无限时域平均奖励强化学习中量子加速的潜力。我们提出了一种创新的量子框架，通过高效的量子均值估计技术，实现了指数级改进的遗憾保证。所提出的量子算法相较于经典算法，在遗憾界限上有显著改进。 |
| [^46] | [Descriptive Knowledge Graph in Biomedical Domain.](http://arxiv.org/abs/2310.11681) | 这个论文提出了一个在生物医学领域中构建描述性知识图谱的新系统，可以从文献中提取有信息量的句子并进行关系搜索和导航。并且该系统使用自动生成描述性句子的模型，减少了人工阅读的工作量。在COVID-19研究中应用该系统展示了其在相关领域的实用性。 |
| [^47] | [Using Experience Classification for Training Non-Markovian Tasks.](http://arxiv.org/abs/2310.11678) | 该论文提出了一种使用经验分类的方法来训练非马尔可夫任务。通过将非马尔可夫任务转化为有限轨迹上的线性时态逻辑表达，并利用优先化经验回放技术改善训练过程，以实现非马尔可夫奖励的目标逻辑。实验证明了该方法的可行性和有效性。 |
| [^48] | [Improved Sample Complexity Analysis of Natural Policy Gradient Algorithm with General Parameterization for Infinite Horizon Discounted Reward Markov Decision Processes.](http://arxiv.org/abs/2310.11677) | 本论文提出了一种加速自然策略梯度算法（ANPG），用于解决无限时间无折扣奖励马尔可夫决策过程。ANPG实现了样本和迭代复杂度的显著改进，克服了现有算法的局限性，并达到了最新的技术成果。 |
| [^49] | [PREM: A Simple Yet Effective Approach for Node-Level Graph Anomaly Detection.](http://arxiv.org/abs/2310.11676) | PREM是一种简单而有效的节点级图异常检测方法，它通过简化图异常检测的过程，减少了时间和内存消耗，同时保持了强大的异常检测能力。 |
| [^50] | [Prototype-based HyperAdapter for Sample-Efficient Multi-task Tuning.](http://arxiv.org/abs/2310.11670) | 基于原型的超适配器（PHA）框架用于样本高效多任务调整，通过引入实例密集的检索器和样本高效的原型超网络生成条件模块，在多任务学习和少样本迁移学习中取得了可比性能的提升，甚至在数据量较小时也能超过其他强基线方法的性能。 |
| [^51] | [SOTOPIA: Interactive Evaluation for Social Intelligence in Language Agents.](http://arxiv.org/abs/2310.11667) | SOTOPIA是一个用于评估语言智能中的社交智能的交互式环境。通过模拟复杂的社交互动，并使用全面的评估框架，我们发现不同模型之间的社交智能存在显著差异，特别是在SOTOPIA-hard情景下。GPT-4在这个子集上的目标完成率较低。 |
| [^52] | [Hetero$^2$Net: Heterophily-aware Representation Learning on Heterogenerous Graphs.](http://arxiv.org/abs/2310.11664) | Hetero$^2$Net是一种面向异构图的异质属性感知表示学习方法，通过使用元路径识别异构图中的异质性，并提出了度量指标来描述异质性水平，以解决常见图神经网络在处理具有异质性的图中的限制。 |
| [^53] | [Cloud-Magnetic Resonance Imaging System: In the Era of 6G and Artificial Intelligence.](http://arxiv.org/abs/2310.11641) | Cloud-MRI是一种创新的MRI系统，在6G和人工智能时代应用的云磁共振成像系统，旨在解决MRI数据存储安全性、传输速度、AI算法维护、硬件升级和协作工作的问题。 |
| [^54] | [A Symbolic Language for Interpreting Decision Trees.](http://arxiv.org/abs/2310.11636) | 这篇论文介绍了一种解释决策树的符号语言ExplainDT，使用了一阶逻辑的片段StratiFOILed，可以计算出各种事后解释，包括局部解释和全局解释。 |
| [^55] | [Learn Your Tokens: Word-Pooled Tokenization for Language Modeling.](http://arxiv.org/abs/2310.11628) | 使用"学习您的标记"方案，利用单词边界将字节/字符汇聚成单词表示形式，以改善标记化策略的局限性并提高语言模型的性能。 |
| [^56] | [Unveiling the General Intelligence Factor in Language Models: A Psychometric Approach.](http://arxiv.org/abs/2310.11616) | 本研究利用心理测量理论揭示了语言模型中的普遍智能因子g的存在，并发现了该因子解释模型性能方差的85%，为模型评估和开发提供了统一的指标。 |
| [^57] | [Learning a Hierarchical Planner from Humans in Multiple Generations.](http://arxiv.org/abs/2310.11614) | 这项研究提出了一种将编程学习与层次规划器结合的自然编程库学习系统，通过用户教导的方式，系统可以快速学习并适应复杂任务。 |
| [^58] | [Language Models as Zero-Shot Trajectory Generators.](http://arxiv.org/abs/2310.11604) | 本文研究了使用大型语言模型（LLMs）作为零-shot轨迹生成器的可能性。通过给予LLM物体检测和分割视觉模型的访问权限，研究人员发现LLMs能够直接预测操作技能中的末端执行器姿态序列，并在26个真实世界的语言任务中取得了良好效果。这一研究突破了对LLMs在机器人技术中的限制，揭示了LLMs确实具有对操作任务的理解能力。 |
| [^59] | [The Efficacy of Transformer-based Adversarial Attacks in Security Domains.](http://arxiv.org/abs/2310.11597) | 本文评估了Transformer对于系统防御者和系统攻击者的对抗性样本的鲁棒性和可转移性，为了更好地理解Transformer在网络安全应用中的属性和影响。 |
| [^60] | [WaveAttack: Asymmetric Frequency Obfuscation-based Backdoor Attacks Against Deep Neural Networks.](http://arxiv.org/abs/2310.11595) | 本文提出了一种名为WaveAttack的新型基于频率的背门攻击方法，通过离散小波变换获取图像的高频特征来生成背门触发器，并引入了一种不对称的频率混淆方法来改善触发器的影响力，有效提高了背门攻击的成功率并且不易被检测到。 |
| [^61] | [Adversarial Robustness Unhardening via Backdoor Attacks in Federated Learning.](http://arxiv.org/abs/2310.11594) | 本文研究了联邦学习中对抗性训练和后门攻击的交叉点，引入了Adversarial Robustness Unhardening（ARU），通过有意介入分散式训练过程中破坏模型的鲁棒性，使模型更容易受到更广泛的逃避攻击。 |
| [^62] | [Automated Evaluation of Personalized Text Generation using Large Language Models.](http://arxiv.org/abs/2310.11593) | 这项研究提出了一种使用大型语言模型自动评价个性化文本生成的方法。传统的自动评价指标无法捕捉个性化质量的微妙差别，而人工判断又昂贵且困难。因此，本研究提出了一种新颖的评估方法，能够自动测量个性化、质量和相关性这三个重要语义方面。 |
| [^63] | [Eliciting Human Preferences with Language Models.](http://arxiv.org/abs/2310.11589) | 本文介绍了一种生成式主动任务引导（GATE）的学习框架，该框架通过与用户进行自由形式的、基于语言的交互来引导和推断预期行为。在实验中展示，通过GATE引导的语言模型通常比用户编写的提示或标签更具信息量。 |
| [^64] | [When Rigidity Hurts: Soft Consistency Regularization for Probabilistic Hierarchical Time Series Forecasting.](http://arxiv.org/abs/2310.11569) | 提出了一个新的概率分层时间序列预测模型，该模型能够有效建模和预测具有层次化关系的多变量时间序列。相较于现有方法，该模型不仅考虑点预测，还能提供经过良好校准的概率预测分布，并且在建模过程中考虑了预测分布的相关性。 |
| [^65] | [Integrating 3D City Data through Knowledge Graphs.](http://arxiv.org/abs/2310.11555) | 通过知识图谱整合3D城市数据，能够利用CityGML的语义和拓扑属性对该数据进行查询，实现各种应用的分析。目前关于查询CityGML数据的潜力尚未充分开发，常见的处理方式是将其存储在3DCityDB系统中，使用SQL查询语言进行操作。然而，终端用户在针对特定任务制定查询时仍然面临一些挑战，因为CityGML的概念语义与关系模式之间存在差距。 |
| [^66] | [Towards Optimal Regret in Adversarial Linear MDPs with Bandit Feedback.](http://arxiv.org/abs/2310.11550) | 研究带有对抗损失和强盗反馈的线性MDPs问题，提出了两种算法，分别达到了$\widetilde{\mathcal{O}}\left(\sqrt{K}\right)$和$\widetilde{\mathcal{O}}\left(K^{\frac{3}{4}} \right)$的遗憾性能。 |
| [^67] | [MUST&P-SRL: Multi-lingual and Unified Syllabification in Text and Phonetic Domains for Speech Representation Learning.](http://arxiv.org/abs/2310.11541) | 本文提出了一种多语言和统一音节标记的文本和音韵领域中的语音表示学习方法，通过自动音节化单词并生成宝贵注释，适用于语音表示学习、语音单元发现和语音因素解缠。 |
| [^68] | [Efficient Online Learning with Offline Datasets for Infinite Horizon MDPs: A Bayesian Approach.](http://arxiv.org/abs/2310.11531) | 本文研究了在存在离线数据集的情况下，如何在无限时域进行高效的在线学习。研究表明，学习代理模拟专家的行为策略能够显著减小累积遗憾。通过贝叶斯方法进行的先验相关遗憾分析提供了算法的性能上界，并提出了一种近似的模仿学习算法来结合离线数据集和在线学习。 |
| [^69] | [Group Preference Optimization: Few-Shot Alignment of Large Language Models.](http://arxiv.org/abs/2310.11523) | 这项研究介绍了一种名为群体偏好优化（GPO）的对齐框架，可以以少样本的方式将大规模语言模型（LLMs）引导到个别群体的偏好。通过在基本LLM上加入独立的transformer模块来预测群体偏好，并通过元学习进行训练，GPO经过严格评估验证了其有效性。 |
| [^70] | [Guarantees for Self-Play in Multiplayer Games via Polymatrix Decomposability.](http://arxiv.org/abs/2310.11518) | 这篇论文研究了多人游戏中自我对抗的保证问题，通过多矩阵可分解性，在满足一定条件的情况下，通过自我对抗学习的算法能够产生有界脆弱性的策略。 |
| [^71] | [Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection.](http://arxiv.org/abs/2310.11511) | Self-RAG是一种通过检索和自我反思提高语言模型质量和事实性的框架。 |
| [^72] | [CoMPosT: Characterizing and Evaluating Caricature in LLM Simulations.](http://arxiv.org/abs/2310.11501) | 利用CoMPosT框架，我们提出了一种对LLM模拟进行特征化的方法，评估其是否存在夸张刻板化，并发现在某些情况下存在夸张刻板化的现象。 |
| [^73] | [End-to-End real time tracking of children's reading with pointer network.](http://arxiv.org/abs/2310.11486) | 本研究提出了一种用于儿童阅读的实时跟踪器模型，在语音跟踪的延迟方面具有较低的敏感性。通过使用指针网络和强制对齐生成训练信号，我们的模型可以准确地跟踪成人语音，并在儿童语音数据集上获得良好的效果。 |
| [^74] | [Rethinking Class-incremental Learning in the Era of Large Pre-trained Models via Test-Time Adaptation.](http://arxiv.org/abs/2310.11482) | 本研究提出了一种名为“增量学习的测试时适应”的方法，通过在测试实例上进行微调，避免了在每个新任务上进行训练，从而在增量学习中实现了预训练模型的稳定性和可塑性的平衡。 |
| [^75] | [Contracting Tsetlin Machine with Absorbing Automata.](http://arxiv.org/abs/2310.11481) | 本文介绍了一种合同Tsetlin机器（TM）与吸收自动机（TA）状态的稀疏扩展，通过引入吸收性的排除和包含状态，加速学习过程并减少能量消耗。 |
| [^76] | [ASP: Automatic Selection of Proxy dataset for efficient AutoML.](http://arxiv.org/abs/2310.11478) | 本文提出了一个自动选择代理数据集框架 (ASP)，通过动态地找到信息丰富的代理子集来减小训练数据大小并节省AutoML处理时间，实验证明ASP在不同基准测试上获得了优于其他方法的结果。 |
| [^77] | [Robust-MBFD: A Robust Deep Learning System for Motor Bearing Faults Detection Using Multiple Deep Learning Training Strategies and A Novel Double Loss Function.](http://arxiv.org/abs/2310.11477) | 本文提出了一种稳健的深度学习系统用于电机轴承故障检测，采用多个深度学习训练策略和一种新的双损失函数。通过对比评估不同系统并寻找最佳模型，我们展示了该系统对各种电机轴承故障的有效性。 |
| [^78] | [Classic machine learning methods.](http://arxiv.org/abs/2310.11470) | 本章主要介绍了经典机器学习方法，包括监督学习和无监督学习。其中介绍了分类和回归的各种方法，以及解决过拟合问题的策略。 |
| [^79] | [Enhancing Binary Code Comment Quality Classification: Integrating Generative AI for Improved Accuracy.](http://arxiv.org/abs/2310.11467) | 本报告通过整合生成的代码和注释对，改进二进制代码注释质量分类模型，提高准确性。 |
| [^80] | [Protein 3D Graph Structure Learning for Robust Structure-based Protein Property Prediction.](http://arxiv.org/abs/2310.11466) | 本文研究了蛋白质基于结构的性质预测中使用预测结构时性能下降的原因，并将其归因为结构嵌入偏差。 |
| [^81] | [BaitBuster-Bangla: A Comprehensive Dataset for Clickbait Detection in Bangla with Multi-Feature and Multi-Modal Analysis.](http://arxiv.org/abs/2310.11465) | 本研究提出了一个大规模的孟加拉语YouTube clickbait多模态数据集，为研究人员提供了在低资源语言中建模clickbait现象的重要价值，并且可以开发出更复杂的跨语言检测方法。 |
| [^82] | [GPT-4 as an interface between researchers and computational software: improving usability and reproducibility.](http://arxiv.org/abs/2310.11458) | GPT-4作为研究人员和计算软件之间接口的能力提高了科学软件的可用性和结果的可重复性。 |
| [^83] | [Understanding Fairness Surrogate Functions in Algorithmic Fairness.](http://arxiv.org/abs/2310.11211) | 本文研究了算法公平性中的公平性代理函数，并发现了代理和公平性定义之间存在一个差距。这个差距决定了一个代理函数能否适当替代一个公平性定义。 |
| [^84] | [Uncovering wall-shear stress dynamics from neural-network enhanced fluid flow measurements.](http://arxiv.org/abs/2310.11147) | 本文提出了一种从流动测量中推导出具有令人印象深刻的空间和时间分辨率的速度和壁剪切应力场的方法，该方法利用了深度光流估计器的物理知识。这对于准确预测壁剪切应力，并在交通运输、能源技术和医疗治疗等领域具有重要意义。 |
| [^85] | [HGCVAE: Integrating Generative and Contrastive Learning for Heterogeneous Graph Learning.](http://arxiv.org/abs/2310.11102) | HGCVAE是一种将生成式学习和对比学习整合为一体的异构图学习方法，通过利用生成式的自监督学习能力来解决异构图学习的挑战。 |
| [^86] | [Core Building Blocks: Next Gen Geo Spatial GPT Application.](http://arxiv.org/abs/2310.11029) | 本研究提出了一种名为MapGPT的新方法，将语言模型和空间数据处理技术相结合，在自然语言理解和空间数据分析之间建立桥梁。MapGPT能够对基于位置的查询进行更精确和上下文感知的响应，通过构建基于地理空间的GPT应用的核心模块，实现了在空间和文本数据上生成向量表示，并探索了计算能力的潜力。 |
| [^87] | [Demystifying Poisoning Backdoor Attacks from a Statistical Perspective.](http://arxiv.org/abs/2310.10780) | 从统计学角度揭开中毒后门攻击的神秘面纱，通过评估任何包含恒定触发器的后门攻击的有效性，确定了后门攻击成功的决定因素、最有效的攻击方向以及几乎不可察觉的人类触发器何时会成功。 |
| [^88] | [Harnessing the Power of LLMs: Evaluating Human-AI text Co-Creation through the Lens of News Headline Generation.](http://arxiv.org/abs/2310.10706) | 该研究通过对LLMs辅助新闻标题生成的人工智能协作方法进行比较，发现引导和选择模型输出能够带来最大的效益，并且与自由编辑相比并不损害参与者对控制的感知。 |
| [^89] | [Microscaling Data Formats for Deep Learning.](http://arxiv.org/abs/2310.10537) | 本文评估了Microscaling（MX）数据格式在降低深度学习应用的计算和存储成本方面的可行性。实证结果显示MX数据格式可以作为基线FP32的替代，同时保持低用户摩擦，并且成功在超过两打基准测试中以小于8位的数据格式进行了训练。 |
| [^90] | [Semantic Parsing by Large Language Models for Intricate Updating Strategies of Zero-Shot Dialogue State Tracking.](http://arxiv.org/abs/2310.10520) | 本论文提出了ParsingDST方法，利用大型语言模型和语义解析技术，实现了复杂的零样本对话状态跟踪的更新策略，并在实验中展示了明显的改进。 |
| [^91] | [Text Summarization Using Large Language Models: A Comparative Study of MPT-7b-instruct, Falcon-7b-instruct, and OpenAI Chat-GPT Models.](http://arxiv.org/abs/2310.10449) | 本研究通过比较MPT-7b-instruct, Falcon-7b-instruct和OpenAI Chat-GPT模型，在不同的数据集上使用不同的超参数进行了文本摘要实验。实验结果表明，text-davinci-003模型表现最佳，并且提供了大型语言模型在文本摘要中的性能综述。 |
| [^92] | [Cross-Lingual Consistency of Factual Knowledge in Multilingual Language Models.](http://arxiv.org/abs/2310.10378) | 本论文研究了多语言预训练语言模型中事实知识的跨语言一致性，提出了一种新的度量方法，并通过分析模型大小、语言配对等因素发现了影响一致性的因素。实验结果表明，增加模型大小可以提高准确性，但不会改善跨语言一致性。 |
| [^93] | [TRANSOM: An Efficient Fault-Tolerant System for Training LLMs.](http://arxiv.org/abs/2310.10046) | TRANSOM是一种用于训练LLMs的高效容错系统，包括训练流水线自动容错和恢复机制（TOL）、训练任务多维度度量的自动决策和调整机制（ADAM）以及在群集恢复之间自动决策和管理任务移动的模型（RMM）。 |
| [^94] | [Chinese Painting Style Transfer Using Deep Generative Models.](http://arxiv.org/abs/2310.09978) | 本文研究和利用不同的深度生成模型进行中国绘画风格转换，并提出了一种结合了多种模型的算法。在定性和定量方面评估了其性能。 |
| [^95] | [Enhancing Conversational Search: Large Language Model-Aided Informative Query Rewriting.](http://arxiv.org/abs/2310.09716) | 该论文提出了一种利用大型语言模型(LLMs)作为查询重写器的方法，通过指令生成信息丰富的查询重写，以提升对话式搜索的检索性能。实验结果表明，这种方法在QReCC数据集上取得了良好的效果。 |
| [^96] | [Edge-InversionNet: Enabling Efficient Inference of InversionNet on Edge Devices.](http://arxiv.org/abs/2310.09667) | 本论文提出了Edge-InversionNet，通过采用结构化修剪算法得到了InversionNet的轻量化版本，在资源受限的边缘设备上实现了高效的推理。实验结果显示，修剪后的InversionNet在性能略有下降的情况下，可以实现高达98.2%的计算资源减少。 |
| [^97] | [Security Considerations in AI-Robotics: A Survey of Current Methods, Challenges, and Opportunities.](http://arxiv.org/abs/2310.08565) | 本文调查和分类了AI-机器人系统中的安全问题，包括攻击面、道德和法律问题以及人机交互安全。旨在为用户、开发者和其他利益相关者提供指导。 |
| [^98] | [Online Speculative Decoding.](http://arxiv.org/abs/2310.07177) | 在线推测解码是通过利用多余计算能力，在LLM服务集群中持续更新草稿模型，从而加速大型语言模型推理的一种方法。 |
| [^99] | [Crystal: Introspective Reasoners Reinforced with Self-Feedback.](http://arxiv.org/abs/2310.04921) | 提出了一种名为Crystal的内省型常识推理器，通过内省知识和基于知识的推理相结合，提高了常识推理的性能和解释能力。 |
| [^100] | [Intelligent Client Selection for Federated Learning using Cellular Automata.](http://arxiv.org/abs/2310.00627) | 本研究提出了一种使用元胞自动机的智能客户端选择算法，用于解决联邦学习中由于传感器数量增加带来的通信和资源分配问题。 |
| [^101] | [A Foundation Model for General Moving Object Segmentation in Medical Images.](http://arxiv.org/abs/2309.17264) | 本文提出了一种用于医学图像中移动目标分割的基础模型iMOS，通过对序列中只有少量图像进行注释，即可实现高精度的分割效果 |
| [^102] | [SA2-Net: Scale-aware Attention Network for Microscopic Image Segmentation.](http://arxiv.org/abs/2309.16661) | SA2-Net是一种尺度感知注意力网络，用于处理显微图像中的多样结构。它结合了多尺度特征学习和尺度感知注意力模块，以实现准确的分割。 |
| [^103] | [Making PPO even better: Value-Guided Monte-Carlo Tree Search decoding.](http://arxiv.org/abs/2309.15028) | 本文提出了一种基于值导向的Monte-Carlo Tree Search解码算法PPO-MCTS，通过在PPO之上集成MCTS，解决了训练和测试之间部分输出评分机制的不匹配问题，实验证明该算法可以显著提升性能。 |
| [^104] | [Limits of Actor-Critic Algorithms for Decision Tree Policies Learning in IBMDPs.](http://arxiv.org/abs/2309.13365) | 该论文研究了在IBMDP中使用Actor-Critic算法学习决策树策略的局限性。结果表明，即使是在简单的玩具任务上，深度RL也可能失败。 |
| [^105] | [Uncertainty-aware Traffic Prediction under Missing Data.](http://arxiv.org/abs/2309.06800) | 本研究提出了一种考虑不确定性的交通预测方法，可以处理缺失数据和测量不确定性，并适用于风险敏感任务和决策导向问题。 |
| [^106] | [Interactively Robot Action Planning with Uncertainty Analysis and Active Questioning by Large Language Model.](http://arxiv.org/abs/2308.15684) | 本文提出了一种交互式机器人行动规划方法，利用大型语言模型（LLM）通过向人类提问来分析并收集缺失信息，最大程度地减少生成精确机器人指令的设计成本。揭示了在机器人行动规划中使用LLM面临的挑战，并为未来研究提供了有价值的见解。 |
| [^107] | [Identifying and Mitigating the Security Risks of Generative AI.](http://arxiv.org/abs/2308.14840) | 生成式人工智能技术具有巨大的潜力，但也存在安全风险。这篇论文是一个研讨会的综合报道，讨论了生成式人工智能所带来的双重用途困境，提出了社区在这个领域的短期和长期目标。 |
| [^108] | [Reinforcement Learning-based Non-Autoregressive Solver for Traveling Salesman Problems.](http://arxiv.org/abs/2308.00560) | 基于强化学习的非自回归TSP求解器NAR4TSP使用特别设计的图神经网络进行推理，消除了昂贵标签的依赖，并在解决方案质量、推理延迟和泛化能力方面优于其他四个最先进的模型。 |
| [^109] | [Large Language Model as Attributed Training Data Generator: A Tale of Diversity and Bias.](http://arxiv.org/abs/2306.15895) | 本论文研究了大型语言模型作为属性化训练数据生成器的应用。通过使用具有多样性属性的提示，我们能够生成多样化且归因的数据。研究表明，在高基数和多样领域的数据集中，使用属性化提示对生成模型性能有积极影响。此外，论文还展示了关于偏差、多样性和效率的全面实证研究结果，并得出了三个关键观察：系统性偏差存在于生成数据中，多样性和效率之间存在权衡，属性化训练数据生成可以改善模型性能。 |
| [^110] | [OpenSTL: A Comprehensive Benchmark of Spatio-Temporal Predictive Learning.](http://arxiv.org/abs/2306.11249) | OpenSTL是一个全面的时空预测学习基准，通过将流行的方法分为基于循环和不基于循环的模型，并提供一个模块化和可扩展的框架，对各种领域的数据集进行了标准评估，并对模型架构进行了详细分析。 |
| [^111] | [DORSal: Diffusion for Object-centric Representations of Scenes $\textit{et al.}$.](http://arxiv.org/abs/2306.08068) | DORSal提出了一种基于扩散模型的物体中心场景表示方法，可以呈现高保真新视图，并在较大程度上保留了诸如基于物体的场景编辑之类的优点。 |
| [^112] | [Interactive Explanation with Varying Level of Details in an Explainable Scientific Literature Recommender System.](http://arxiv.org/abs/2306.05809) | 本文旨在采用以用户为中心的交互式解释模型，在推荐系统中为用户提供不同细节级别的解释，赋予用户个性化解释的能力。 |
| [^113] | [What model does MuZero learn?.](http://arxiv.org/abs/2306.00840) | 本文研究了MuZero算法，发现它学习到的模型无法有效推广到评估未见策略，限制了其对当前策略的进一步改进。 |
| [^114] | [Beyond One-Model-Fits-All: A Survey of Domain Specialization for Large Language Models.](http://arxiv.org/abs/2305.18703) | 本文综述了大型语言模型的领域专门化，包括动机、挑战、方法论和评估指标。此外，还提供了一个特定领域任务和数据集的分类法，对现有的领域自适应和定制技术进行了详细比较，并广泛讨论了这一领域中的未解决问题和未来的发展方向。 |
| [^115] | [Machine learning for phase-resolved reconstruction of nonlinear ocean wave surface elevations from sparse remote sensing data.](http://arxiv.org/abs/2305.11913) | 本文提出了一种基于神经网络的方法，利用高度现实的合成训练数据对稀疏雷达数据进行相位相关的波浪表面重建。 |
| [^116] | [Appraising the Potential Uses and Harms of LLMs for Medical Systematic Reviews.](http://arxiv.org/abs/2305.11828) | 本文研究了使用LLM协助制作医学证据综述的潜在用途和风险，指出LLM有可能自动生成文献综述，但由于可能出现虚构或遗漏信息的情况，LLM的使用需要谨慎。 |
| [^117] | [Diving into the Inter-Consistency of Large Language Models: An Insightful Analysis through Debate.](http://arxiv.org/abs/2305.11595) | 本文提出了通过辩论探究大型语言模型之间的内部一致性问题，实验证明通过严格的辩论框架可以提高模型性能和常识知识的结构化学习。 |
| [^118] | [Plug-and-Play Medical Dialogue System.](http://arxiv.org/abs/2305.11508) | 该论文提出了一种即插即用的医疗对话系统，使用大型语言模型实现医疗问答及诊断策略，避免了传统昂贵的LLMs微调。 |
| [^119] | [Clifford Group Equivariant Neural Networks.](http://arxiv.org/abs/2305.11141) | 我们引入了Clifford群等变神经网络，它可以构建O(n)和E(n)等变模型。该方法通过调整Clifford群的定义以及保持向量空间和乘法结构的作用来实现多个有利属性。 |
| [^120] | [Stop Uploading Test Data in Plain Text: Practical Strategies for Mitigating Data Contamination by Evaluation Benchmarks.](http://arxiv.org/abs/2305.10160) | 提出了三个适用策略：（1）公钥加密发布测试数据，仅允许特定派生发布；（2）对于API持有方，要求训练排除控制，保护测试数据，不停止评估直到达到要求；（3）如果测试数据来自互联网文本，需避免某些结果的使用。 |
| [^121] | [Search for the UGLE Truth: An Investigation into Unsupervised GNN Learning Environments.](http://arxiv.org/abs/2305.06026) | 本文提出了一种GNN学习环境下的社区检测算法比较框架，包括数据集和评估指标，以解决目前文献中对于基于GNN的社区检测缺乏公平且严谨评估的问题。 |
| [^122] | [DeformerNet: Learning Bimanual Manipulation of 3D Deformable Objects.](http://arxiv.org/abs/2305.04449) | 本论文介绍了一种名为DeformerNet的神经网络架构，通过学习三维可塑物体的低维表示来实现机器人对物体形状的操纵。这种方法不需要手工特征和物体特定的控制模型，可在仿真和真实机器人上进行演示和应用。 |
| [^123] | [Vera: A General-Purpose Plausibility Estimation Model for Commonsense Statements.](http://arxiv.org/abs/2305.03695) | 本文提出了Vera模型，它是一个通用模型，可以基于常识知识估计陈述性语句的可信度。在解决验证格式的常识问题时，Vera明显优于现有的模型，并展现了对未见任务的泛化能力和良好的标定输出。 |
| [^124] | [When Do Neural Nets Outperform Boosted Trees on Tabular Data?.](http://arxiv.org/abs/2305.02997) | 这项研究通过对176个数据集的比较分析发现，在许多数据集中，GBDT和NN之间的性能差异可以忽略不计，或者GBDT的轻微超参数调整比选择最佳算法更重要。此外，研究人员对965个元特征进行了分析，发现GBDT在高维稀疏数据上表现更好。 |
| [^125] | [Answering Questions by Meta-Reasoning over Multiple Chains of Thought.](http://arxiv.org/abs/2304.13007) | 本论文提出了基于元推理的Multi-Chain Reasoning (MCR)方法，该方法检查多个推理链，混合它们之间的信息并选择最相关的事实，从而超越多链思维，解决多跳QA问题。 实验结果表明MCR胜过多个强基线，解释质量高。 |
| [^126] | [SkillGPT: a RESTful API service for skill extraction and standardization using a Large Language Model.](http://arxiv.org/abs/2304.11060) | SkillGPT是一种使用大型语言模型进行技能提取和标准化的RESTful API服务，通过摘要和向量相似性搜索平衡速度和准确度。 |
| [^127] | [Nerfbusters: Removing Ghostly Artifacts from Casually Captured NeRFs.](http://arxiv.org/abs/2304.10532) | 通过使用新的数据集和评估程序，提出了一种使用3D扩散优先级别加上新颖的基于密度的得分蒸馏采样损失的方法来防止NeRF优化过程中出现图形伪影的解决方案。 |
| [^128] | [Action of the Euclidean versus Projective group on an agent's internal space in curiosity driven exploration: a formal analysis.](http://arxiv.org/abs/2304.00188) | 该论文将人类空间感知的3D射影几何学与智能体感知方案中的群概念相结合，探讨不同群结构如何影响智能体的好奇心驱动探索行为。 |
| [^129] | [Automated deep learning segmentation of high-resolution 7 T ex vivo MRI for quantitative analysis of structure-pathology correlations in neurodegenerative diseases.](http://arxiv.org/abs/2303.12237) | 本文提出了一个深度学习分割管道，用于离体MRI图像的自动化分割。基于37个标本的高分辨率7 T MRI图像，该方法可准确分割整个脑半球，包括皮层、皮质下结构、白质高信号以及正常出现的白质。该方法可为神经病理学研究提供帮助。 |
| [^130] | [Taylor TD-learning.](http://arxiv.org/abs/2302.14182) | Taylor TD是一个基于模型的RL框架，通过使用TD更新的泰勒级数展开，减少了连续状态-动作设置中的方差，并具有与标准TD学习相同的稳定学习保证。TaTD3是Taylor TD与TD3算法相结合所形成的方法，其表现优于一些最先进的无模型和基于模型的基准。 |
| [^131] | [Grounding Complex Natural Language Commands for Temporal Tasks in Unseen Environments.](http://arxiv.org/abs/2302.11649) | 该论文提出了一个名为Lang2LTL的模块化系统和软件包，利用大型语言模型将导航命令与LTL规范进行关联。通过在没有先前语言数据的环境中全面评估Lang2LTL，证明了其在21个城市级规模的环境中与各种时态规范进行关联的最先进能力。并且通过展示物理机器人在两个室内环境中可以遵循52个语义多样的导航命令，进一步验证了Lang2LTL的实际应用价值。 |
| [^132] | [SHINE: Deep Learning-Based Accessible Parking Management System.](http://arxiv.org/abs/2302.00837) | SHINE是一个基于深度学习的无障碍停车管理系统，能够实时识别停放在无障碍停车位上的车辆，并具备可访问性监测功能。实验结果表明，SHINE优于现有的车牌识别系统。 |
| [^133] | [Learning List-Level Domain-Invariant Representations for Ranking.](http://arxiv.org/abs/2212.10764) | 本文提出了一种针对排名问题的列表级别对齐的学习方法，该方法利用列表的结构特性，在领域适应中实现从源领域到目标领域的知识转移。 |
| [^134] | [Planning and Learning: Path-Planning for Autonomous Vehicles, a Review of the Literature.](http://arxiv.org/abs/2207.13181) | 这篇综述主要介绍了当前关于规划、调度和学习的最新工作，包括先进的规划算法、神经网络和图神经网络、增强学习方法以及将神经网络应用于路径规划的成功方法。 |
| [^135] | [A Comparative Evaluation of Quantification Methods.](http://arxiv.org/abs/2103.03223) | 本研究通过对24种不同量化方法在超过40个数据集上进行全面实证比较，填补了量化方法比较研究的空白。我们发现在二分类设置中，基于阈值选择的Median Sweep和TSMax方法、DyS框架和弗里德曼的方法表现最佳；而在多分类设置中，Generaliz方法表现良好。 |
| [^136] | [Euclidean-Norm-Induced Schatten-p Quasi-Norm Regularization for Low-Rank Tensor Completion and Tensor Robust Principal Component Analysis.](http://arxiv.org/abs/2012.03436) | 本文提出了一种新的张量秩正则化方法，通过计算张量的CP分量向量的欧几里德范数，间接最小化了Schatten-p准范，用于低秩张量补全和张量鲁棒主成分分析。该方法在处理大型张量时具有可扩展性，并且提供了比核范数更精确的秩代理。同时，通过比较理论分析，证明了该方法在LRTC的泛化能力上的优势。 |
| [^137] | [Model Checkers Are Cool: How to Model Check Voting Protocols in Uppaal.](http://arxiv.org/abs/2007.12412) | 本文介绍了如何使用Uppaal模型检查器对投票协议进行建模和验证，展示了对Prêter à Voter及其扩展模型的验证，并克服了模型检查器中属性规范语言的限制。 |

# 详细

[^1]: 使用绝热量子计算的平衡K-Means的概率采样

    Probabilistic Sampling of Balanced K-Means using Adiabatic Quantum Computing. (arXiv:2310.12153v1 [cs.LG])

    [http://arxiv.org/abs/2310.12153](http://arxiv.org/abs/2310.12153)

    该论文研究了使用绝热量子计算的平衡K-Means聚类的概率采样方法，通过利用非最优解来计算校准后验概率，实现在D-Wave AQC上识别模糊解决方案和数据点的目标。

    

    绝热量子计算（AQC）是一种有望用于离散且通常为NP困难优化问题的量子计算方法。目前的AQC允许实现感兴趣的问题，这促使了为许多机器学习和计算机视觉任务开发量子表示的发展。尽管需要从噪声AQC进行多次测量，但当前方法仅利用最佳测量，丢弃了其他测量中包含的信息。在这项工作中，我们探讨了利用这些信息进行概率平衡k-means聚类的潜力。我们提出了使用非最优解来计算校准后验概率的方法，计算成本很低。这使我们能够识别模糊的解决方案和数据点，我们在D-Wave AQC上使用合成和真实数据进行了验证。

    Adiabatic quantum computing (AQC) is a promising quantum computing approach for discrete and often NP-hard optimization problems. Current AQCs allow to implement problems of research interest, which has sparked the development of quantum representations for many machine learning and computer vision tasks. Despite requiring multiple measurements from the noisy AQC, current approaches only utilize the best measurement, discarding information contained in the remaining ones. In this work, we explore the potential of using this information for probabilistic balanced k-means clustering. Instead of discarding non-optimal solutions, we propose to use them to compute calibrated posterior probabilities with little additional compute cost. This allows us to identify ambiguous solutions and data points, which we demonstrate on a D-Wave AQC on synthetic and real data.
    
[^2]: 通过NAS实现更公平和准确的表格模型

    Fairer and More Accurate Tabular Models Through NAS. (arXiv:2310.12145v1 [cs.LG])

    [http://arxiv.org/abs/2310.12145](http://arxiv.org/abs/2310.12145)

    通过使用多目标神经架构搜索(NAS)和超参数优化(HPO)，我们在表格数据领域首次提出了一种更新模型架构和超参数的策略，以寻找更公平和准确的模型。我们发现，仅针对准确性进行优化可能会导致公平性的降低，因此需要同时考虑准确性和公平性。

    

    长期以来，通过算法使得表格数据的模型更加公平一直是研究的课题。现有的技术通常针对存在不可取的结果的神经模型，通过改变数据的摄入方式、模型权重或输出处理方式来修复。我们采用了新的策略，在去偏过程中考虑更新模型的架构和训练超参数，以找到一个从一开始在预测结果上更好的新模型。在这项工作中，我们首次将多目标神经架构搜索(NAS)和超参数优化(HPO)应用于具有挑战性的表格数据领域。我们在不同数据集上对MLP、ResNet和FT-Transformer等不同架构和超参数空间进行了广泛的探索，展示了模型预测的准确性和公平性指标对超参数组合的依赖关系。我们表明，仅针对准确性进行优化的模型可能会导致公平性的降低，因此需要在优化过程中同时考虑准确性和公平性。

    Making models algorithmically fairer in tabular data has been long studied, with techniques typically oriented towards fixes which usually take a neural model with an undesirable outcome and make changes to how the data are ingested, what the model weights are, or how outputs are processed. We employ an emergent and different strategy where we consider updating the model's architecture and training hyperparameters to find an entirely new model with better outcomes from the beginning of the debiasing procedure. In this work, we propose using multi-objective Neural Architecture Search (NAS) and Hyperparameter Optimization (HPO) in the first application to the very challenging domain of tabular data. We conduct extensive exploration of architectural and hyperparameter spaces (MLP, ResNet, and FT-Transformer) across diverse datasets, demonstrating the dependence of accuracy and fairness metrics of model predictions on hyperparameter combinations. We show that models optimized solely for ac
    
[^3]: 对于Bug预测的集成模型效力的可理解性分析

    A comprehensible analysis of the efficacy of Ensemble Models for Bug Prediction. (arXiv:2310.12133v1 [cs.SE])

    [http://arxiv.org/abs/2310.12133](http://arxiv.org/abs/2310.12133)

    本文通过对两种基于人工智能的方法进行Java类错误预测效力的比较和分析，发现集成人工智能模型优于单一人工智能模型，并提供了有助于提升集成人工智能模型性能的因素。

    

    软件系统的正确性对于其有效运行至关重要。发现和修复软件缺陷是一项重要的开发任务。人工智能技术在软件工程中的增长导致了许多技术的发展，可以帮助软件开发人员识别代码中的潜在缺陷。本文提出了对两种基于人工智能的方法（单一人工智能模型和集成人工智能模型）进行的Java类错误预测效力的可理解性比较和分析。我们使用了两个开源Apache Commons项目的Java组件来进行模型的训练和评估。我们的实验结果表明，集成人工智能模型的效果优于单一人工智能模型的效果。我们还提供了有助于增强集成人工智能模型性能的因素的见解。呈现的结果展示了使用集成人工智能模型的潜力。

    The correctness of software systems is vital for their effective operation. It makes discovering and fixing software bugs an important development task. The increasing use of Artificial Intelligence (AI) techniques in Software Engineering led to the development of a number of techniques that can assist software developers in identifying potential bugs in code. In this paper, we present a comprehensible comparison and analysis of the efficacy of two AI-based approaches, namely single AI models and ensemble AI models, for predicting the probability of a Java class being buggy. We used two open-source Apache Commons Project's Java components for training and evaluating the models. Our experimental findings indicate that the ensemble of AI models can outperform the results of applying individual AI models. We also offer insight into the factors that contribute to the enhanced performance of the ensemble AI model. The presented results demonstrate the potential of using ensemble AI models t
    
[^4]: DiagrammerGPT: 通过LLM规划生成开放领域、开放平台的图表

    DiagrammerGPT: Generating Open-Domain, Open-Platform Diagrams via LLM Planning. (arXiv:2310.12128v1 [cs.CV])

    [http://arxiv.org/abs/2310.12128](http://arxiv.org/abs/2310.12128)

    DiagrammerGPT是一个通过LLM规划生成开放领域、开放平台的图表的框架，填补了T2I模型在图表生成方面的空白。

    

    过去几年，文本到图像（T2I）生成取得了显著的发展。尽管如此，在使用T2I模型生成图表方面的研究很少。图表是一种使用结构丰富和空间复杂的可视化来解释信息的符号/示意性表示（例如，一种密集的相关对象、文本标签、方向箭头、连接线等组合）。现有的最先进的T2I模型在生成图表时经常失败，因为它们在许多对象通过复杂的关系（如箭头/线）密集连接时缺乏细粒度的对象布局控制，并且经常不能渲染出可理解的文本标签。为了填补这一空白，我们提出了DiagrammerGPT，一个新颖的两阶段文本到图表生成框架，它利用LLM（如GPT-4）的布局引导能力来生成更准确的开放领域、开放平台的图表。在第一阶段，我们使用LLM生成和迭代改进“图表规划”（在一个规划方案中）。

    Text-to-image (T2I) generation has seen significant growth over the past few years. Despite this, there has been little work on generating diagrams with T2I models. A diagram is a symbolic/schematic representation that explains information using structurally rich and spatially complex visualizations (e.g., a dense combination of related objects, text labels, directional arrows, connection lines, etc.). Existing state-of-the-art T2I models often fail at diagram generation because they lack fine-grained object layout control when many objects are densely connected via complex relations such as arrows/lines and also often fail to render comprehensible text labels. To address this gap, we present DiagrammerGPT, a novel two-stage text-to-diagram generation framework that leverages the layout guidance capabilities of LLMs (e.g., GPT-4) to generate more accurate open-domain, open-platform diagrams. In the first stage, we use LLMs to generate and iteratively refine 'diagram plans' (in a planne
    
[^5]: SHARCS：通过动态宽度子网络进行路由的高效Transformer

    SHARCS: Efficient Transformers through Routing with Dynamic Width Sub-networks. (arXiv:2310.12126v1 [cs.LG])

    [http://arxiv.org/abs/2310.12126](http://arxiv.org/abs/2310.12126)

    SHARCS是一种高效的Transformer模型，通过动态宽度子网络进行路由，实现自适应推理和更高的效率，同时在各种分类任务中表现优越并且具有通用性。

    

    我们引入了SHARCS，用于自适应推理，考虑到输入样本的难度。SHARCS可以在任何Transformer网络上训练一个路由器，使模型能够将不同样本指向具有不同宽度的子网络。我们的实验证明：（1）在准确性与FLOPs之间，SHARCS在各种分类任务上的表现优于或补充了现有的每个样本自适应推理方法；（2）SHARCS在不同架构之间具有泛化能力，甚至可以应用于压缩和高效的Transformer编码器，以进一步提高其效率；（3）SHARCS可以提供2倍的推理加速，几乎不损失准确性。

    We introduce SHARCS for adaptive inference that takes into account the hardness of input samples. SHARCS can train a router on any transformer network, enabling the model to direct different samples to sub-networks with varying widths. Our experiments demonstrate that: (1) SHARCS outperforms or complements existing per-sample adaptive inference methods across various classification tasks in terms of accuracy vs. FLOPs; (2) SHARCS generalizes across different architectures and can be even applied to compressed and efficient transformer encoders to further improve their efficiency; (3) SHARCS can provide a 2 times inference speed up at an insignificant drop in accuracy.
    
[^6]: 一则警示故事：关于参考数据在实证隐私防御中的作用

    A Cautionary Tale: On the Role of Reference Data in Empirical Privacy Defenses. (arXiv:2310.12112v1 [cs.CR])

    [http://arxiv.org/abs/2310.12112](http://arxiv.org/abs/2310.12112)

    本文研究了实证隐私防御中参考数据的作用和隐私问题，提出了一种基准防御方法，实现了模型效用和训练数据隐私的权衡。

    

    在隐私保护机器学习领域，已经提出了实证隐私防御作为一种解决方案，以实现在不显著降低模型效用的情况下，达到令人满意的训练数据隐私水平。大多数现有的防御成员推理攻击的方法假设可以访问参考数据，参考数据指的是来自训练数据相同（或类似）基础分布的附加数据集。尽管参考数据的使用很普遍，但之前的研究对于定义和评估参考数据隐私相当保守。由于模型效用和/或训练数据隐私的提升可能以牺牲参考数据隐私为代价，因此需要充分考虑这三个方面。在本文中，我们首先研究了之前的作品中参考数据的可用性及其隐私处理情况，并证明了对于公平比较防御方法来说参考数据的必要性。其次，我们提出了一种基准防御方法，它可以在模型效用和训练数据隐私之间进行权衡。

    Within the realm of privacy-preserving machine learning, empirical privacy defenses have been proposed as a solution to achieve satisfactory levels of training data privacy without a significant drop in model utility. Most existing defenses against membership inference attacks assume access to reference data, defined as an additional dataset coming from the same (or a similar) underlying distribution as training data. Despite the common use of reference data, previous works are notably reticent about defining and evaluating reference data privacy. As gains in model utility and/or training data privacy may come at the expense of reference data privacy, it is essential that all three aspects are duly considered. In this paper, we first examine the availability of reference data and its privacy treatment in previous works and demonstrate its necessity for fairly comparing defenses. Second, we propose a baseline defense that enables the utility-privacy tradeoff with respect to both trainin
    
[^7]: DASA: Difficulty-Aware Semantic Augmentation for Speaker Verification. (arXiv:2310.12111v1 [eess.AS])

    DASA: Difficulty-Aware Semantic Augmentation for Speaker Verification. (arXiv:2310.12111v1 [eess.AS])

    [http://arxiv.org/abs/2310.12111](http://arxiv.org/abs/2310.12111)

    本文提出了一种面向说话人验证的难度感知语义增强(DASA)方法，通过扰动语义方向来增强训练样本，并引入了难度感知的加性边界软最大值(DAAM-Softmax)来实现最优的说话人嵌入，从而改善模型的泛化能力和鲁棒性。

    

    数据增强对于深度神经网络(DNN)模型的泛化能力和鲁棒性至关重要。现有的说话人验证增强方法操纵原始信号，这些方法耗时且增强样本缺乏多样性。本文提出了一种新的面向说话人验证的难度感知语义增强(DASA)方法，可以在说话人嵌入空间中生成多样化的训练样本，成本几乎可以忽略。首先，我们通过扰动来自说话人矩阵的语义方向来增强训练样本。其次，在训练过程中，我们从鲁棒的说话人嵌入中估计准确的协方差矩阵，所以我们引入了难度感知的加性边界软最大值(DAAM-Softmax)来获得最优的说话人嵌入。最后，我们假设增强样本数量趋近无穷大，并推导出带有DASA的期望损失的闭式上界，该方法实现了最优的性能提升。

    Data augmentation is vital to the generalization ability and robustness of deep neural networks (DNNs) models. Existing augmentation methods for speaker verification manipulate the raw signal, which are time-consuming and the augmented samples lack diversity. In this paper, we present a novel difficulty-aware semantic augmentation (DASA) approach for speaker verification, which can generate diversified training samples in speaker embedding space with negligible extra computing cost. Firstly, we augment training samples by perturbing speaker embeddings along semantic directions, which are obtained from speaker-wise covariance matrices. Secondly, accurate covariance matrices are estimated from robust speaker embeddings during training, so we introduce difficultyaware additive margin softmax (DAAM-Softmax) to obtain optimal speaker embeddings. Finally, we assume the number of augmented samples goes to infinity and derive a closed-form upper bound of the expected loss with DASA, which achi
    
[^8]: 通过人类反馈实现质量多样性

    Quality Diversity through Human Feedback. (arXiv:2310.12103v1 [cs.AI])

    [http://arxiv.org/abs/2310.12103](http://arxiv.org/abs/2310.12103)

    本文提出了一种通过人类反馈实现质量多样性（Quality Diversity through Human Feedback，QDHF）的方法，该方法利用人类反馈推断多样性指标，扩展了质量多样性（Quality Diversity，QD）算法的适用性。实验证明，QDHF在自动多样性发现方面表现出色，并且具有与QD相匹配的搜索能力。

    

    从人类反馈中进行强化学习（RLHF）在提高定性任务的基础模型性能方面显示出潜力。尽管如此，当仅将其概念化为最大化平均人类偏好的学习奖励模型的机制时，特别是在要求多样化模型响应的图像生成等领域，其效果往往受到限制。与此同时，致力于寻找多样化的高质量解决方案的质量多样性（QD）算法通常受到对手动定义多样性指标的依赖约束。有趣的是，通过融合来自两者的见解，可以克服RLHF和QD的这些局限性。本文介绍了通过人类反馈实现质量多样性（QDHF），该方法利用人类反馈推断多样性指标，扩展了QD算法的适用性。实证结果表明，与现有的QD方法相比，QDHF在自动多样性发现方面表现出色，并且与QD的搜索能力相匹配。

    Reinforcement learning from human feedback (RLHF) has exhibited the potential to enhance the performance of foundation models for qualitative tasks. Despite its promise, its efficacy is often restricted when conceptualized merely as a mechanism to maximize learned reward models of averaged human preferences, especially in areas such as image generation which demand diverse model responses. Meanwhile, quality diversity (QD) algorithms, dedicated to seeking diverse, high-quality solutions, are often constrained by the dependency on manually defined diversity metrics. Interestingly, such limitations of RLHF and QD can be overcome by blending insights from both. This paper introduces Quality Diversity through Human Feedback (QDHF), which employs human feedback for inferring diversity metrics, expanding the applicability of QD algorithms. Empirical results reveal that QDHF outperforms existing QD methods regarding automatic diversity discovery, and matches the search capabilities of QD with
    
[^9]: 非侵入式自适应：面向多模态建模的输入中心参数高效微调

    Non-Intrusive Adaptation: Input-Centric Parameter-efficient Fine-Tuning for Versatile Multimodal Modeling. (arXiv:2310.12100v1 [cs.CL])

    [http://arxiv.org/abs/2310.12100](http://arxiv.org/abs/2310.12100)

    这篇论文介绍了一种非侵入式的参数高效微调技术（AdaLink），通过只调整模型的外部参数而保持内部结构不变，实现了对多模态建模的竞争性能，这对于大规模语言模型和视觉语言模型的自适应和部署具有重要意义。

    

    大规模语言模型（LLMs）和视觉语言模型（VLMs）通过将参数数量从O（10^9）扩展到O（10^{12}）甚至更高水平，展现出在广泛任务上出色的性能。这样大规模的模型使得在给定感兴趣的任务上进行完全专业化模型的自适应和部署成为不可能。参数高效微调（PEFT）成为应对这些大型模型适应和服务挑战的一种有希望的方向。我们将PEFT技术分为两种类型：侵入式和非侵入式。侵入式PEFT技术直接改变模型的内部结构。虽然更灵活，但在训练和服务过程中引入了显著的复杂性。非侵入式PEFT技术保持内部结构不变，只调整模型的外部参数，如输入的嵌入。在这项工作中，我们将AdaLink描述为一种非侵入式PEFT技术，与SoTA侵入式PEFT（LoRA）和完整模型相比，实现了有竞争力的性能。

    Large language models (LLMs) and vision language models (VLMs) demonstrate excellent performance on a wide range of tasks by scaling up parameter counts from O(10^9) to O(10^{12}) levels and further beyond. These large scales make it impossible to adapt and deploy fully specialized models given a task of interest. Parameter-efficient fine-tuning (PEFT) emerges as a promising direction to tackle the adaptation and serving challenges for such large models. We categorize PEFT techniques into two types: intrusive and non-intrusive. Intrusive PEFT techniques directly change a model's internal architecture. Though more flexible, they introduce significant complexities for training and serving. Non-intrusive PEFT techniques leave the internal architecture unchanged and only adapt model-external parameters, such as embeddings for input. In this work, we describe AdaLink as a non-intrusive PEFT technique that achieves competitive performance compared to SoTA intrusive PEFT (LoRA) and full model
    
[^10]: 发现塞壬之歌：可靠的事实冲突幻觉检测

    Unveiling the Siren's Song: Towards Reliable Fact-Conflicting Hallucination Detection. (arXiv:2310.12086v1 [cs.CL])

    [http://arxiv.org/abs/2310.12086](http://arxiv.org/abs/2310.12086)

    该论文介绍了一种为大型语言模型设计的FactCHD事实冲突幻觉检测基准，用于评估LLMs生成文本的事实性。基准包含了多种事实模式，并使用基于事实的证据链进行组合性幻觉的检测。

    

    大型语言模型（LLMs），如ChatGPT/GPT-4，因其广泛的实际应用而受到广泛关注，但其在网络平台上存在事实冲突幻觉的问题限制了其采用。对由LLMs产生的文本的事实性评估仍然未被充分探索，不仅涉及对基本事实的判断，还包括对复杂推理任务（如多跳等）中出现的事实错误的评估。为此，我们引入了FactCHD，一种为LLMs精心设计的事实冲突幻觉检测基准。作为在“查询-响应”上下文中评估事实性的关键工具，我们的基准采用了大规模数据集，涵盖了广泛的事实模式，如基本事实，多跳，比较和集合操作模式。我们基准的一个独特特点是其包含基于事实的证据链，从而便于进行组合性幻觉的检测。

    Large Language Models (LLMs), such as ChatGPT/GPT-4, have garnered widespread attention owing to their myriad of practical applications, yet their adoption has been constrained by issues of fact-conflicting hallucinations across web platforms. The assessment of factuality in text, produced by LLMs, remains inadequately explored, extending not only to the judgment of vanilla facts but also encompassing the evaluation of factual errors emerging in complex inferential tasks like multi-hop, and etc. In response, we introduce FactCHD, a fact-conflicting hallucination detection benchmark meticulously designed for LLMs. Functioning as a pivotal tool in evaluating factuality within "Query-Respons" contexts, our benchmark assimilates a large-scale dataset, encapsulating a broad spectrum of factuality patterns, such as vanilla, multi-hops, comparison, and set-operation patterns. A distinctive feature of our benchmark is its incorporation of fact-based chains of evidence, thereby facilitating com
    
[^11]: DHOT-GM：使用可微分的分层最优传输框架实现鲁棒图匹配

    DHOT-GM: Robust Graph Matching Using A Differentiable Hierarchical Optimal Transport Framework. (arXiv:2310.12081v1 [cs.AI])

    [http://arxiv.org/abs/2310.12081](http://arxiv.org/abs/2310.12081)

    本研究提出了一种名为DHOT-GM的图匹配方法，使用可微分的分层最优传输框架，充分利用了图中隐藏的多模态信息，通过对匹配结果进行加权平均来推断节点对应关系。

    

    在实践中，图匹配是最重要的图分析任务之一，其目标是找到不同图之间的节点对应关系。大多数现有方法在匹配图时依赖于邻接矩阵或节点嵌入，其性能常常不够优越，因为没有充分利用图中隐藏的多模态信息，如节点属性、子图结构等。在本研究中，我们提出了一种基于可微分的分层最优传输（HOT）框架的新颖有效的图匹配方法，称为DHOT-GM。实质上，我们的方法将每个图表示为与不同模态信息对应的一组关系矩阵。给定两个图，我们枚举所有关系矩阵对，并获取它们的匹配结果，然后通过对匹配结果进行加权平均来推断节点对应关系。该方法可以实现为计算两个图之间的HOT距离，每个图都是由关系矩阵表示的。

    Graph matching is one of the most significant graph analytic tasks in practice, which aims to find the node correspondence across different graphs. Most existing approaches rely on adjacency matrices or node embeddings when matching graphs, whose performances are often sub-optimal because of not fully leveraging the multi-modal information hidden in graphs, such as node attributes, subgraph structures, etc. In this study, we propose a novel and effective graph matching method based on a differentiable hierarchical optimal transport (HOT) framework, called DHOT-GM. Essentially, our method represents each graph as a set of relational matrices corresponding to the information of different modalities. Given two graphs, we enumerate all relational matrix pairs and obtain their matching results, and accordingly, infer the node correspondence by the weighted averaging of the matching results. This method can be implemented as computing the HOT distance between the two graphs -- each matching 
    
[^12]: GAN中黑盒训练数据识别的探测器网络研究

    Black-Box Training Data Identification in GANs via Detector Networks. (arXiv:2310.12063v1 [cs.LG])

    [http://arxiv.org/abs/2310.12063](http://arxiv.org/abs/2310.12063)

    本研究探索了在黑盒设置中使用GAN时的隐私问题，通过引入一套攻击来识别训练数据成员身份，本文提供了对版权和数据隐私方面的重要洞见。

    

    从它们问世以来，生成对抗网络（GAN）一直是流行的生成模型，可用于图像、音频、视频和表格数据。本文研究了在已训练好的GAN以及来自基础分布的新样本的情况下，攻击者能否有效地识别给定点是否属于GAN的训练数据。这对于版权相关的原因很有意义，用户可能想确定他们的版权数据是否被用来训练GAN，以及对数据隐私的研究也很有意义，其中检测训练集成员身份的能力被称为成员隐私攻击。与大多数先前的工作不同，本文研究了在黑盒设置中使用GAN的隐私影响，攻击者只能访问生成器的样本，而不能访问鉴别器的样本。我们引入了一套针对黑盒设置中GAN的成员隐私攻击，并评估了我们的方法。

    Since their inception Generative Adversarial Networks (GANs) have been popular generative models across images, audio, video, and tabular data. In this paper we study whether given access to a trained GAN, as well as fresh samples from the underlying distribution, if it is possible for an attacker to efficiently identify if a given point is a member of the GAN's training data. This is of interest for both reasons related to copyright, where a user may want to determine if their copyrighted data has been used to train a GAN, and in the study of data privacy, where the ability to detect training set membership is known as a membership inference attack. Unlike the majority of prior work this paper investigates the privacy implications of using GANs in black-box settings, where the attack only has access to samples from the generator, rather than access to the discriminator as well. We introduce a suite of membership inference attacks against GANs in the black-box setting and evaluate our 
    
[^13]: 基于机器学习的智能农业营养应用时间推荐：一种大规模数据挖掘方法

    Machine Learning-based Nutrient Application's Timeline Recommendation for Smart Agriculture: A Large-Scale Data Mining Approach. (arXiv:2310.12052v1 [cs.LG])

    [http://arxiv.org/abs/2310.12052](http://arxiv.org/abs/2310.12052)

    本文研究了基于机器学习的智能农业营养应用时间推荐方法。通过预测整个季节所需的肥料数量，并根据天气条件和土壤特性调整肥料量，以促进经济高效和环境友好的农业。研究还探讨了施肥应用与天气数据对作物产量的影响。

    

    本研究讨论了数据分析在监测农作物施肥应用中的重要作用。不准确的施肥决策会导致昂贵的后果，阻碍粮食生产，并造成环境危害。我们提出了一种解决方案，通过确定整个季节所需的肥料数量来预测营养应用。该解决方案建议根据天气条件和土壤特性调整肥料量，以促进经济高效和环境友好的农业。收集的数据集是高维度和异构的。我们的研究在决策过程的语境中研究了大规模异构数据集，包括数据收集和分析。我们还以冬小麦作物为案例研究了施肥应用与天气数据对作物产量的影响。通过理解本地背景和地理因素，我们希望稳定甚至减少需求。

    This study addresses the vital role of data analytics in monitoring fertiliser applications in crop cultivation. Inaccurate fertiliser application decisions can lead to costly consequences, hinder food production, and cause environmental harm. We propose a solution to predict nutrient application by determining required fertiliser quantities for an entire season. The proposed solution recommends adjusting fertiliser amounts based on weather conditions and soil characteristics to promote cost-effective and environmentally friendly agriculture. The collected dataset is high-dimensional and heterogeneous. Our research examines large-scale heterogeneous datasets in the context of the decision-making process, encompassing data collection and analysis. We also study the impact of fertiliser applications combined with weather data on crop yield, using the winter wheat crop as a case study. By understanding local contextual and geographic factors, we aspire to stabilise or even reduce the dema
    
[^14]: 一个理论框架来理解从人类偏好中学习的一般方法

    A General Theoretical Paradigm to Understand Learning from Human Preferences. (arXiv:2310.12036v1 [cs.AI])

    [http://arxiv.org/abs/2310.12036](http://arxiv.org/abs/2310.12036)

    本文研究了学习从人类偏好中学习的实际算法的理论基础，推导出一个新的一般目标，绕过了两个重要的近似。这种方法允许直接从收集的数据中学习策略而无需奖励模型的训练。

    

    目前从人类偏好中学习的流行方法依赖于两个重要的近似：第一假设可以用逐点奖励替代成对偏好。第二个假设是在这些逐点奖励上训练的奖励模型可以从收集到的数据泛化到策略采样的超出分布的数据。最近，提出了一种称为直接偏好优化(DPO)的方法，该方法绕过了第二个近似，并直接从收集的数据中学习策略而无需奖励模型阶段。然而，这种方法仍然严重依赖于第一个近似。在本文中，我们试图对这些实际算法进行更深入的理论理解。特别地，我们推导出了一个新的一般目标，称为ΨPO，用于从人类偏好中学习，该目标以成对偏好的形式表达，因此绕过了这两个近似。这个新的一般目标使我们能够进行一种新的从训练数据直接学习策略的方法而无需进行奖励模型的训练。

    The prevalent deployment of learning from human preferences through reinforcement learning (RLHF) relies on two important approximations: the first assumes that pairwise preferences can be substituted with pointwise rewards. The second assumes that a reward model trained on these pointwise rewards can generalize from collected data to out-of-distribution data sampled by the policy. Recently, Direct Preference Optimisation (DPO) has been proposed as an approach that bypasses the second approximation and learn directly a policy from collected data without the reward modelling stage. However, this method still heavily relies on the first approximation.  In this paper we try to gain a deeper theoretical understanding of these practical algorithms. In particular we derive a new general objective called $\Psi$PO for learning from human preferences that is expressed in terms of pairwise preferences and therefore bypasses both approximations. This new general objective allows us to perform an 
    
[^15]: SegmATRon: 用于室内环境的具有自适应语义分割的体验感知模型

    SegmATRon: Embodied Adaptive Semantic Segmentation for Indoor Environment. (arXiv:2310.12031v1 [cs.CV])

    [http://arxiv.org/abs/2310.12031](http://arxiv.org/abs/2310.12031)

    SegmATRon是一种自适应变换模型，用于室内图像的语义分割。通过在多张图像上进行推断时权重的自适应调整，可以提高语义分割的质量。在室内环境中使用代理的行为获取额外图像的方法在实验中证明是有效的。

    

    本文提出了一种名为SegmATRon的自适应变换模型，用于室内图像的语义分割。其独特之处在于使用混合多组分损失函数在多张图像上进行推断的模型权重适应性调整。我们在逼真的Habitat和AI2-THOR合成模拟器中的数据集上研究了该模型。我们证明，在室内环境中利用代理的行为获取额外图像可以提高语义分割的质量。所提出方法的代码和数据集可在https://github.com/wingrune/SegmATRon上公开获取。

    This paper presents an adaptive transformer model named SegmATRon for embodied image semantic segmentation. Its distinctive feature is the adaptation of model weights during inference on several images using a hybrid multicomponent loss function. We studied this model on datasets collected in the photorealistic Habitat and the synthetic AI2-THOR Simulators. We showed that obtaining additional images using the agent's actions in an indoor environment can improve the quality of semantic segmentation. The code of the proposed approach and datasets are publicly available at https://github.com/wingrune/SegmATRon.
    
[^16]: 多视角对比学习用于知识图谱中的实体类型判断

    Multi-view Contrastive Learning for Entity Typing over Knowledge Graphs. (arXiv:2310.12008v1 [cs.CL])

    [http://arxiv.org/abs/2310.12008](http://arxiv.org/abs/2310.12008)

    本文提出了一种名为多视角对比学习的新方法，该方法有效地将类型聚类提供的粗粒度知识编码到实体和类型嵌入中，从而改进了知识图谱实体类型判断任务。

    

    知识图谱实体类型判断(KGET)旨在推断知识图谱中实体的可能类型。现有的KGET方法侧重于如何更好地将实体的邻居和类型提供的知识编码到其表示中，但它们忽略了类型如何以聚类方式提供的语义知识。本文提出了一种名为多视角对比学习的知识图谱实体类型判断(MCLET)的新方法，它有效地将聚类提供的粗粒度知识编码到实体和类型嵌入中。MCLET由三个模块组成：i) 多视图生成和编码器模块，用于编码实体类型、实体聚类和聚类类型视图中的结构化信息；ii) 跨视图对比学习模块，鼓励不同视图共同改进实体和类型的视图特定表示；iii) 实体类型判断模块，集成多头注意力和...

    Knowledge graph entity typing (KGET) aims at inferring plausible types of entities in knowledge graphs. Existing approaches to KGET focus on how to better encode the knowledge provided by the neighbors and types of an entity into its representation. However, they ignore the semantic knowledge provided by the way in which types can be clustered together. In this paper, we propose a novel method called Multi-view Contrastive Learning for knowledge graph Entity Typing (MCLET), which effectively encodes the coarse-grained knowledge provided by clusters into entity and type embeddings. MCLET is composed of three modules: i) Multi-view Generation and Encoder module, which encodes structured information from entity-type, entity-cluster and cluster-type views; ii) Cross-view Contrastive Learning module, which encourages different views to collaboratively improve view-specific representations of entities and types; iii) Entity Typing Prediction module, which integrates multi-head attention and 
    
[^17]: KI-PMF：知识综合的合理动作预测

    KI-PMF: Knowledge Integrated Plausible Motion Forecasting. (arXiv:2310.12007v1 [cs.RO])

    [http://arxiv.org/abs/2310.12007](http://arxiv.org/abs/2310.12007)

    本研究提出了一种名为KI-PMF的方法，通过结合先验知识，对交通参与者的未来行动进行准确预测，遵循车辆的运动约束和行驶环境的几何形状。通过条件化网络以遵循物理定律，可以获得准确和安全的预测，对于在实际环境中维护自动驾驶汽车的安全和效率至关重要。

    

    准确预测交通参与者的行动对大规模部署自动驾驶汽车至关重要。当前的轨迹预测方法主要集中在优化特定度量的损失函数上，这可能导致预测不符合物理定律或违反外部约束条件。我们的目标是结合明确的先验知识，使网络能够预测未来轨迹，符合车辆的运动约束和行驶环境的几何形状。为了实现这一目标，我们引入了非参数剪枝层和注意力层来整合定义的先验知识。我们的方法旨在确保交通参与者在复杂和动态情况下的到达可达性保证。通过将网络条件化为遵循物理定律，我们可以获得准确和安全的预测，这对于在实际世界环境中维护自动驾驶汽车的安全和效率至关重要。

    Accurately forecasting the motion of traffic actors is crucial for the deployment of autonomous vehicles at a large scale. Current trajectory forecasting approaches primarily concentrate on optimizing a loss function with a specific metric, which can result in predictions that do not adhere to physical laws or violate external constraints. Our objective is to incorporate explicit knowledge priors that allow a network to forecast future trajectories in compliance with both the kinematic constraints of a vehicle and the geometry of the driving environment. To achieve this, we introduce a non-parametric pruning layer and attention layers to integrate the defined knowledge priors. Our proposed method is designed to ensure reachability guarantees for traffic actors in both complex and dynamic situations. By conditioning the network to follow physical laws, we can obtain accurate and safe predictions, essential for maintaining autonomous vehicles' safety and efficiency in real-world settings
    
[^18]: 生成型AI系统的社会技术安全评估

    Sociotechnical Safety Evaluation of Generative AI Systems. (arXiv:2310.11986v1 [cs.AI])

    [http://arxiv.org/abs/2310.11986](http://arxiv.org/abs/2310.11986)

    本文提出了一个三层框架，采用社会技术方法对生成型AI系统的安全风险进行评估。同时，评估现状调查发现了三个显著的评估差距，并提出了解决这些差距的方法。

    

    生成型AI系统会产生一系列风险。为了确保生成型AI系统的安全，需要对这些风险进行评估。本文提出了一个三层框架，采用结构化的社会技术方法来评估这些风险。该框架包括能力评估，这是目前主要的安全评估方法。在此基础上，我们进一步建立在系统安全原则的基础上，特别是认识到上下文决定了特定能力是否会造成伤害。为了考虑相关的上下文，我们的框架增加了人机互动和系统影响作为额外的评估层面。其次，我们调查了生成型AI系统安全评估的现状，并创建了现有评估的库。从分析中得出了三个显著的评估差距。我们提出了解决这些差距的前进方式，概述了实际步骤和角色。

    Generative AI systems produce a range of risks. To ensure the safety of generative AI systems, these risks must be evaluated. In this paper, we make two main contributions toward establishing such evaluations. First, we propose a three-layered framework that takes a structured, sociotechnical approach to evaluating these risks. This framework encompasses capability evaluations, which are the main current approach to safety evaluation. It then reaches further by building on system safety principles, particularly the insight that context determines whether a given capability may cause harm. To account for relevant context, our framework adds human interaction and systemic impacts as additional layers of evaluation. Second, we survey the current state of safety evaluation of generative AI systems and create a repository of existing evaluations. Three salient evaluation gaps emerge from this analysis. We propose ways forward to closing these gaps, outlining practical steps as well as roles
    
[^19]: InfoDiffusion: 针对非自回归文本生成的信息熵感知扩散过程

    InfoDiffusion: Information Entropy Aware Diffusion Process for Non-Autoregressive Text Generation. (arXiv:2310.11976v1 [cs.CL])

    [http://arxiv.org/abs/2310.11976](http://arxiv.org/abs/2310.11976)

    InfoDiffusion是一种非自回归文本扩散模型，通过引入“keyinfo-first”生成策略和基于文本信息量的噪声调度，以及结合自我条件和部分加噪模型结构的方法，提高了生成质量和多样性，并展示出更高的采样效率。

    

    扩散模型在文本生成领域引起了广泛关注。一些研究已经探索了具有不同结构的文本扩散模型，并将它们应用于各种任务，包括命名实体识别和摘要生成。然而，当前扩散模型的“easy-first”文本生成过程与人类的“keyword-first”自然文本生成过程存在明显差异，这引起了有限的关注。为了弥合这一差距，我们提出了一种非自回归文本扩散模型InfoDiffusion。我们的方法引入了“keyinfo-first”生成策略，并结合了基于文本信息量的噪声调度。此外，InfoDiffusion结合了自我条件和一个新提出的部分加噪模型结构。实验结果表明，InfoDiffusion在生成质量和多样性方面优于基线模型，并展示出更高的采样效率。

    Diffusion models have garnered considerable interest in the field of text generation. Several studies have explored text diffusion models with different structures and applied them to various tasks, including named entity recognition and summarization. However, there exists a notable disparity between the "easy-first" text generation process of current diffusion models and the "keyword-first" natural text generation process of humans, which has received limited attention. To bridge this gap, we propose InfoDiffusion, a non-autoregressive text diffusion model. Our approach introduces a "keyinfo-first" generation strategy and incorporates a noise schedule based on the amount of text information. In addition, InfoDiffusion combines self-conditioning with a newly proposed partially noising model structure. Experimental results show that InfoDiffusion outperforms the baseline model in terms of generation quality and diversity, as well as exhibiting higher sampling efficiency.
    
[^20]: 通过群体不变性学习提高与人类偏好的对齐的泛化能力

    Improving Generalization of Alignment with Human Preferences through Group Invariant Learning. (arXiv:2310.11971v1 [cs.LG])

    [http://arxiv.org/abs/2310.11971](http://arxiv.org/abs/2310.11971)

    该论文提出了一种通过强化学习实现在不同数据组或领域中学习一致策略的方法，该方法可以提高AI助手对不同领域的泛化能力，并更好地与人类偏好对齐。

    

    基于语言模型(LLMs)的AI助手的成功在于强化学习从人类反馈中, 使生成的回答更加与人类偏好一致. 作为通用AI助手, 人们越来越期望它们在不同领域中表现一致. 然而, 先前的工作表明,强化学习(RL)经常利用捷径以获得较高的奖励, 忽略了具有挑战性的样本. 这种对快速奖励收益的关注不仅削弱了训练的稳定性, 也削弱了模型对新的未见数据的泛化能力. 在这项工作中, 我们提出了一种新颖的方法, 可以通过RL在不同数据组或领域中学习一致的策略. 鉴于获得群体标注的挑战, 我们的方法会自动将数据分类到不同的组中, 有意地最大化性能差异. 然后, 我们优化策略以在具有挑战性的组中表现良好. 最后, 利用已建立的

    The success of AI assistants based on language models (LLMs) hinges crucially on Reinforcement Learning from Human Feedback (RLHF), which enables the generation of responses more aligned with human preferences. As universal AI assistants, there's a growing expectation for them to perform consistently across various domains. However, previous work shows that Reinforcement Learning (RL) often exploits shortcuts to attain high rewards and overlooks challenging samples. This focus on quick reward gains undermines both the stability in training and the model's ability to generalize to new, unseen data. In this work, we propose a novel approach that can learn a consistent policy via RL across various data groups or domains. Given the challenges associated with acquiring group annotations, our method automatically classifies data into different groups, deliberately maximizing performance variance. Then, we optimize the policy to perform well on challenging groups. Lastly, leveraging the estab
    
[^21]: 一种用于时间序列分析的多尺度分解MLP-Mixer

    A Multi-Scale Decomposition MLP-Mixer for Time Series Analysis. (arXiv:2310.11959v1 [cs.LG])

    [http://arxiv.org/abs/2310.11959](http://arxiv.org/abs/2310.11959)

    我们提出了一种名为MSD-Mixer的多尺度分解MLP-Mixer模型，它能够将时间序列分解成不同的组成部分，并在不同的层次中表示这些组成部分。我们还提出了一种新颖的时间拼接方法，以处理多尺度的时间模式和通道间的依赖关系。我们的模型能够比现有方法更好地进行时间序列分析。

    

    时间序列数据通常具有独特的组成和复杂的多尺度时间变化，需要在其分析中特别考虑分解和多尺度建模。现有的深度学习方法只适用于单变量时间序列，并且对子序列级别的建模和分解不够充分。为了解决这个问题，我们提出了MSD-Mixer，一种多尺度分解的MLP-Mixer，它学会了将输入的时间序列明确地分解成不同的组成部分，并在不同的层次中表示这些组成部分。为了处理多尺度的时间模式和通道间的依赖关系，我们提出了一种新颖的时间拼接方法，将时间序列建模为多尺度子序列，即patches，并使用MLPs来组合patches内部和patches间的变化以及通道间的相关性。此外，我们提出了一个损失函数来约束分解残差的幅度和自相关性，以实现完整的分解。

    Time series data, often characterized by unique composition and complex multi-scale temporal variations, requires special consideration of decomposition and multi-scale modeling in its analysis. Existing deep learning methods on this best fit to only univariate time series, and have not sufficiently accounted for sub-series level modeling and decomposition completeness. To address this, we propose MSD-Mixer, a Multi-Scale Decomposition MLP-Mixer which learns to explicitly decompose the input time series into different components, and represents the components in different layers. To handle multi-scale temporal patterns and inter-channel dependencies, we propose a novel temporal patching approach to model the time series as multi-scale sub-series, i.e., patches, and employ MLPs to mix intra- and inter-patch variations and channel-wise correlations. In addition, we propose a loss function to constrain both the magnitude and autocorrelation of the decomposition residual for decomposition 
    
[^22]: 太好不像是真的：人类活动识别中的性能评估过高的问题

    Too Good To Be True: performance overestimation in (re)current practices for Human Activity Recognition. (arXiv:2310.11950v1 [cs.LG])

    [http://arxiv.org/abs/2310.11950](http://arxiv.org/abs/2310.11950)

    本文发现在人类活动识别中存在性能评估过高的问题，传统方法中的数据分割和交叉验证导致了结果的偏见。这个问题在最新的研究中很常见，但往往被忽视。不正确的结果会导致报告较低准确度的论文更难发表。

    

    当今，在人类活动识别（HAR）领域有一些标准和既定程序。然而，一些传统方法会导致精度被高估，特别是使用滑动窗口进行数据分割的方法以及标准的随机k折交叉验证方法会产生偏见结果。对过去的文献和现代研究的分析显示，这些方法在HAR领域的最新研究中很常见。我们有必要引起科学界对这个问题的关注，因为它的负面影响被忽视了。否则，发表偏见结果的论文将会报告较低的准确度，正确的无偏方法更难以发表。通过对不同类型的数据集和不同类型的分类模型进行多次实验，我们可以证明这个问题的存在，并且无论方法和数据集如何，这个问题都存在。

    Today, there are standard and well established procedures within the Human Activity Recognition (HAR) pipeline. However, some of these conventional approaches lead to accuracy overestimation. In particular, sliding windows for data segmentation followed by standard random k-fold cross validation, produce biased results. An analysis of previous literature and present-day studies, surprisingly, shows that these are common approaches in state-of-the-art studies on HAR. It is important to raise awareness in the scientific community about this problem, whose negative effects are being overlooked. Otherwise, publications of biased results lead to papers that report lower accuracies, with correct unbiased methods, harder to publish. Several experiments with different types of datasets and different types of classification models allow us to exhibit the problem and show it persists independently of the method or dataset.
    
[^23]: 知识图谱中半感应式链接预测的基准

    A Benchmark for Semi-Inductive Link Prediction in Knowledge Graphs. (arXiv:2310.11917v1 [cs.CL])

    [http://arxiv.org/abs/2310.11917](http://arxiv.org/abs/2310.11917)

    本文提出了一个用于评估知识图谱中半感应式链接预测模型的大规模基准，基于Wikidata5M进行扩展。通过各种不同的任务和信息组合，该基准为进一步研究上下文和文本信息在链接预测中的整合提供了一个测试平台。

    

    知识图谱中的半感应式链接预测是根据上下文信息来预测新的、之前未见的实体的事实的任务。本文提出和描述了一个大规模基准来评估半感应式链接预测模型。该基准基于并扩展了Wikidata5M：它提供了转导式、k-shot和0-shot链接预测任务，每个任务都会根据可用的信息情况从（i）仅有知识图谱结构，到（ii）包含文本提及，再到（iii）实体的详细描述进行变化。我们进行了一项关于最近方法的小型研究，发现半感应式链接预测的性能远远低于转导式性能，在所有实验中都表现出对于长尾实体的不足。该基准为进一步研究如何将上下文和文本信息整合到链接预测中提供了一个测试平台。

    Semi-inductive link prediction (LP) in knowledge graphs (KG) is the task of predicting facts for new, previously unseen entities based on context information. Although new entities can be integrated by retraining the model from scratch in principle, such an approach is infeasible for large-scale KGs, where retraining is expensive and new entities may arise frequently. In this paper, we propose and describe a large-scale benchmark to evaluate semi-inductive LP models. The benchmark is based on and extends Wikidata5M: It provides transductive, k-shot, and 0-shot LP tasks, each varying the available information from (i) only KG structure, to (ii) including textual mentions, and (iii) detailed descriptions of the entities. We report on a small study of recent approaches and found that semi-inductive LP performance is far from transductive performance on long-tail entities throughout all experiments. The benchmark provides a test bed for further research into integrating context and textual
    
[^24]: 用人工智能分析质谱数据以辅助理解火星的过去适居性并提供未来任务的见解

    Analyze Mass Spectrometry data with Artificial Intelligence to assist the understanding of past habitability of Mars and provide insights for future missions. (arXiv:2310.11888v1 [astro-ph.EP])

    [http://arxiv.org/abs/2310.11888](http://arxiv.org/abs/2310.11888)

    本文介绍了一种利用人工智能分析质谱数据以检测古代火星适居性潜力的方法，并展示了该方法在外星物质分析中的适用性。关键技术包括质谱值的转换、数据可视化和机器学习模型的应用。

    

    本文介绍了将人工智能应用于质谱数据以检测火星古代适居性潜力的方法。尽管数据是针对火星收集的，但同样的方法可以用于太阳系中的任何地球对象。此外，所提出的方法可以适应任何使用质谱的领域。研究集中于两种质谱技术（进化气体分析-质谱和气相色谱-质谱）的数据分析，这些技术用于识别地质样品中的特定化学化合物。研究证明了进化气体分析-质谱和气相色谱-质谱数据在外星物质分析中的适用性。所提出方法的最重要特征包括质谱值的平方根转换，将原始数据转换为二维光谱图，并利用特定的机器学习模型和技术以避免在相对较小的数据集上过度拟合。EGA-MS和GC-MS数据集

    This paper presents an application of artificial intelligence on mass spectrometry data for detecting habitability potential of ancient Mars. Although data was collected for planet Mars the same approach can be replicated for any terrestrial object of our solar system. Furthermore, proposed methodology can be adapted to any domain that uses mass spectrometry. This research is focused in data analysis of two mass spectrometry techniques, evolved gas analysis (EGA-MS) and gas chromatography (GC-MS), which are used to identify specific chemical compounds in geological material samples. The study demonstrates the applicability of EGA-MS and GC-MS data to extra-terrestrial material analysis. Most important features of proposed methodology includes square root transformation of mass spectrometry values, conversion of raw data to 2D sprectrograms and utilization of specific machine learning models and techniques to avoid overfitting on relative small datasets. Both EGA-MS and GC-MS datasets c
    
[^25]: 从神经激活到概念: 解释神经网络中的概念的调查

    From Neural Activations to Concepts: A Survey on Explaining Concepts in Neural Networks. (arXiv:2310.11884v1 [cs.AI])

    [http://arxiv.org/abs/2310.11884](http://arxiv.org/abs/2310.11884)

    本文调查了解释神经网络中概念的最新方法，这对于实现基于可解释概念的神经符号化人工智能来说是重要的一步。

    

    在本文中，我们审查了解释神经网络中概念的最新方法。概念可以作为学习和推理之间的自然桥梁：一旦确定了神经学习系统使用的概念，就可以将这些概念与推理系统整合，用于推理或使用推理系统对其进行改进或增强以改善学习系统。另一方面，不仅可以从神经网络中提取知识，还可以将概念知识插入神经网络体系结构中。由于整合学习和推理是神经符号化人工智能的核心，所以通过这项调查获得的见解可以成为实现基于可解释概念的神经符号化人工智能的重要一步。

    In this paper, we review recent approaches for explaining concepts in neural networks. Concepts can act as a natural link between learning and reasoning: once the concepts are identified that a neural learning system uses, one can integrate those concepts with a reasoning system for inference or use a reasoning system to act upon them to improve or enhance the learning system. On the other hand, knowledge can not only be extracted from neural networks but concept knowledge can also be inserted into neural network architectures. Since integrating learning and reasoning is at the core of neuro-symbolic AI, the insights gained from this survey can serve as an important step towards realizing neuro-symbolic AI based on explainable concepts.
    
[^26]: AI Nushu: 计算语言学视角下姐妹团结中的语言形成探索

    AI Nushu: An Exploration of Language Emergence in Sisterhood -Through the Lens of Computational Linguistics. (arXiv:2310.11870v1 [cs.CL])

    [http://arxiv.org/abs/2310.11870](http://arxiv.org/abs/2310.11870)

    本文介绍了一种受女书启发的新兴语言系统AI Nushu，通过计算语言学的视角，结合中国文化遗产和女权主义视角，通过两个AI代理人的合作创造了一个标准的中文写作系统。

    

    本文介绍了“AI Nushu”，这是一种受女书（女性专用文字）启发的新兴语言系统，女书是古代中国女性在一个父权社会中被认为是文盲而创造并独自使用的独特语言。在这个交互式装置中，两个人工智能（AI）代理人通过对中文字典和女书语料库的训练，不断观察环境并进行交流，合作创造一个标准的中文写作系统。它从计算语言学的角度提供了一种艺术性解释，将AI技术与中国文化遗产和女权主义视角相结合，创造了一种非西方文字的创作过程。

    This paper presents "AI Nushu," an emerging language system inspired by Nushu (women's scripts), the unique language created and used exclusively by ancient Chinese women who were thought to be illiterate under a patriarchal society. In this interactive installation, two artificial intelligence (AI) agents are trained in the Chinese dictionary and the Nushu corpus. By continually observing their environment and communicating, these agents collaborate towards creating a standard writing system to encode Chinese. It offers an artistic interpretation of the creation of a non-western script from a computational linguistics perspective, integrating AI technology with Chinese cultural heritage and a feminist viewpoint.
    
[^27]: 价值感知对话代理共同设计框架

    The Value-Sensitive Conversational Agent Co-Design Framework. (arXiv:2310.11848v1 [cs.HC])

    [http://arxiv.org/abs/2310.11848](http://arxiv.org/abs/2310.11848)

    本文介绍了一种价值感知对话代理共同设计框架，旨在与相关利益相关者合作设计具有价值感知的对话代理。

    

    对话代理在工业和学术界正在受到越来越多的关注，尤其是随着生成式人工智能和大型语言模型的出现。随着这些代理在公众中的广泛使用以及承担了一系列关键的用例和社会角色，考虑到这些系统中嵌入的价值观变得非常重要。这个考虑包括回答诸如“谁的价值观被嵌入到这些代理中？”和“这些价值观在正在设计的代理中如何体现？”等问题。因此，本文的目的是介绍一种价值感知对话代理共同设计框架，以便与相关利益相关者共同设计价值感知的对话代理。首先，在此总结了以前的工作中确定的设计价值感知对话代理的共同设计要求。其次，介绍并讨论了实际框架，包括其在设计工具包中的操作化。该框架促进了共同设计。

    Conversational agents (CAs) are gaining traction in both industry and academia, especially with the advent of generative AI and large language models. As these agents are used more broadly by members of the general public and take on a number of critical use cases and social roles, it becomes important to consider the values embedded in these systems. This consideration includes answering questions such as 'whose values get embedded in these agents?' and 'how do those values manifest in the agents being designed?' Accordingly, the aim of this paper is to present the Value-Sensitive Conversational Agent (VSCA) Framework for enabling the collaborative design (co-design) of value-sensitive CAs with relevant stakeholders. Firstly, requirements for co-designing value-sensitive CAs which were identified in previous works are summarised here. Secondly, the practical framework is presented and discussed, including its operationalisation into a design toolkit. The framework facilitates the co-d
    
[^28]: 多智能体决策的掩码预训练

    Masked Pretraining for Multi-Agent Decision Making. (arXiv:2310.11846v1 [cs.AI])

    [http://arxiv.org/abs/2310.11846](http://arxiv.org/abs/2310.11846)

    我们提出了一个掩码预训练框架(MaskMA)用于解决多智能体决策中的挑战。这个框架采用变压器架构，并使用基于掩码的协作学习策略，同时整合了可泛化的动作表示。

    

    最近，在决策领域，构建具有零样本能力的通用单智能体日益取得重大进展。然而，将这种能力扩展到多智能体场景存在挑战。大多数现有工作在零样本能力方面存在困难，原因是多智能体环境中存在两个特定挑战：集中式预训练和分散式执行之间存在不匹配，以及不同的智能体数量和动作空间，使得难以创建适用于不同下游任务的可泛化表示。为了克服这些挑战，我们提出了一种适用于多智能体决策的掩码预训练框架(MaskMA)。该模型基于变压器架构，采用适合于带有部分观测的分散式执行的基于掩码的协作学习策略。此外，MaskMA通过将动作空间划分为面向自身信息的动作和与他人相关的动作，融入了可泛化的动作表示。

    Building a single generalist agent with zero-shot capability has recently sparked significant advancements in decision-making. However, extending this capability to multi-agent scenarios presents challenges. Most current works struggle with zero-shot capabilities, due to two challenges particular to the multi-agent settings: a mismatch between centralized pretraining and decentralized execution, and varying agent numbers and action spaces, making it difficult to create generalizable representations across diverse downstream tasks. To overcome these challenges, we propose a \textbf{Mask}ed pretraining framework for \textbf{M}ulti-\textbf{a}gent decision making (MaskMA). This model, based on transformer architecture, employs a mask-based collaborative learning strategy suited for decentralized execution with partial observation. Moreover, MaskMA integrates a generalizable action representation by dividing the action space into actions toward self-information and actions related to other 
    
[^29]: 无需一致性的分类聚合

    Classification Aggregation without Unanimity. (arXiv:2310.11841v1 [cs.AI])

    [http://arxiv.org/abs/2310.11841](http://arxiv.org/abs/2310.11841)

    这项研究证明了每个公民主权和独立的分类聚合函数本质上都是一种独裁制度，并提出了一种替代证明技术来解决两个类别的情况，同时识别出两个类别和两个物体情况下的所有独立和一致的分类聚合函数。

    

    分类是从一组物体到一组类别的满射映射。分类聚合函数将每个分类向量聚合成一个单一的分类。我们证明每个公民主权和独立的分类聚合函数本质上都是一种独裁制度。这种不可能性推导出了Maniquet和Mongin（2016年）的一个较早结果，他们证明了每个一致且独立的分类聚合函数都是一种独裁制度。这两种不可能性之间的关系类似于偏好聚合中Wilson和Arrow的不可能性之间的关系。此外，虽然Maniquet-Mongin的不可能性是建立在至少三个类别存在的基础上的，但我们提出了一种替代的证明技术，涵盖了两个类别的情况，除非物体的数量也是两个。我们还确定了两个类别和两个物体情况下的所有独立和一致的分类聚合函数

    A classification is a surjective mapping from a set of objects to a set of categories. A classification aggregation function aggregates every vector of classifications into a single one. We show that every citizen sovereign and independent classification aggregation function is essentially a dictatorship. This impossibility implies an earlier result of Maniquet and Mongin (2016), who show that every unanimous and independent classification aggregation function is a dictatorship. The relationship between the two impossibilities is reminiscent to the relationship between Wilson's and Arrow's impossibilities in preference aggregation. Moreover, while the Maniquet-Mongin impossibility rests on the existence of at least three categories, we propose an alternative proof technique that covers the case of two categories, except when the number of objects is also two. We also identify all independent and unanimous classification aggregation functions for the case of two categories and two objec
    
[^30]: IntentDial:一种基于意图图的多轮对话系统，并提供推理路径可视化

    IntentDial: An Intent Graph based Multi-Turn Dialogue System with Reasoning Path Visualization. (arXiv:2310.11818v1 [cs.AI])

    [http://arxiv.org/abs/2310.11818](http://arxiv.org/abs/2310.11818)

    IntentDial是一种基于图的多轮对话系统，在实现意图检测和识别时使用强化学习和推理路径可视化组件，有助于提高对话系统的性能和改进。

    

    意图检测和识别已成为对话代理（例如声音助手和智能客服）中广泛研究的技术。传统方法通常将意图挖掘过程视为分类任务。虽然神经网络分类器在这类任务中表现出色，但神经网络模型的问题常常阻碍其在实际场景中的应用。我们提出了一种新颖的基于图的多轮对话系统，称为IntentDial，通过使用强化学习从动态构建和可扩展的意图图中识别用户的意图，即意图元素和标准查询。此外，我们还提供了可视化组件，用于监视对话的每个轮次的直接推理路径，这极大地促进了系统的进一步改进。

    Intent detection and identification from multi-turn dialogue has become a widely explored technique in conversational agents, for example, voice assistants and intelligent customer services. The conventional approaches typically cast the intent mining process as a classification task. Although neural classifiers have proven adept at such classification tasks, the issue of neural network models often impedes their practical deployment in real-world settings. We present a novel graph-based multi-turn dialogue system called , which identifies a user's intent by identifying intent elements and a standard query from a dynamically constructed and extensible intent graph using reinforcement learning. In addition, we provide visualization components to monitor the immediate reasoning path for each turn of a dialogue, which greatly facilitates further improvement of the system.
    
[^31]: 在嘈杂的金融数据上进行保守预测

    Conservative Predictions on Noisy Financial Data. (arXiv:2310.11815v1 [cs.LG])

    [http://arxiv.org/abs/2310.11815](http://arxiv.org/abs/2310.11815)

    在嘈杂的金融数据上进行保守预测，通过对不确定的数据点进行剪枝，以提高预测的准确性。

    

    金融市场的价格波动被认为是非常嘈杂的。因此，即使机器学习算法偶尔能够捕捉到可利用的模式，由于特征和标签的噪声，这些模式往往被掩盖，使得预测变得不太有用且存在风险。我们应用了一种类似的方法，即模型在对不确定的数据点上不进行预测。在训练过程中，一系列这样的模型按序进行学习，类似于规则列表，每个模型仅在前面的模型对其不确定的数据上进行训练。测试时也会进行类似的数据剪枝，只对测试数据的一部分（支持集）进行预测，从而获得更高的准确性。

    Price movements in financial markets are well known to be very noisy. As a result, even if there are, on occasion, exploitable patterns that could be picked up by machine-learning algorithms, these are obscured by feature and label noise rendering the predictions less useful, and risky in practice. Traditional rule-learning techniques developed for noisy data, such as CN2, would seek only high precision rules and refrain from making predictions where their antecedents did not apply. We apply a similar approach, where a model abstains from making a prediction on data points that it is uncertain on. During training, a cascade of such models are learned in sequence, similar to rule lists, with each model being trained only on data on which the previous model(s) were uncertain. Similar pruning of data takes place at test-time, with (higher accuracy) predictions being made albeit only on a fraction (support) of test-time data. In a financial prediction setting, such an approach allows decis
    
[^32]: 用多任务神经网络学习和发现量子性质

    Learning and Discovering Quantum Properties with Multi-Task Neural Networks. (arXiv:2310.11807v1 [quant-ph])

    [http://arxiv.org/abs/2310.11807](http://arxiv.org/abs/2310.11807)

    这篇论文介绍了一种用多任务神经网络学习和发现量子性质的方法，该方法能够同时预测和发现多个量子性质，并且能够推断多体量子系统的全局性质和发现不同相之间的未知边界。

    

    深度神经网络是一种从有限测量数据中预测量子态性质的强大工具。在这里，我们开发了一个网络模型，可以同时预测多个量子性质，包括量子可观测量的期望值以及量子状态的一般非线性函数，如纠缠熵和多体拓扑不变量。值得注意的是，我们发现一个在给定性质集上训练的模型也可以发现超出该集合的新性质。多功能训练还使模型能够从局部测量中推断出多体量子系统的全局性质，分类保护对称的拓扑物质相，并发现不同相之间的未知边界。

    Deep neural networks are a powerful tool for predicting properties of quantum states from limited measurement data. Here we develop a network model that can simultaneously predict multiple quantum properties, including not only expectation values of quantum observables, but also general nonlinear functions of the quantum state, like entanglement entropies and many-body topological invariants. Remarkably, we find that a model trained on a given set of properties can also discover new properties outside that set. Multi-purpose training also enables the model to infer global properties of many-body quantum systems from local measurements, to classify symmetry protected topological phases of matter, and to discover unknown boundaries between different phases.
    
[^33]: 基于拍卖的调度

    Auction-Based Scheduling. (arXiv:2310.11798v1 [cs.AI])

    [http://arxiv.org/abs/2310.11798](http://arxiv.org/abs/2310.11798)

    该论文提出了一种基于拍卖的调度框架，用于解决多目标决策问题。该框架的创新之处在于将每个目标的实现分配给单独的策略，并且可以独立创建、修改和替换这些策略。使用拍卖机制来解决冲突和组合策略，确保长期的调度公平性。

    

    许多顺序决策任务需要满足多个部分矛盾的目标。现有方法是整体化的，即通过一个函数来选择一系列动作来满足所有目标。我们提出了基于拍卖的调度，这是一个模块化的多目标决策框架。每个目标都使用单独的策略来实现，这些策略可以独立创建、修改和替换。可以理解的是，具有冲突目标的不同策略可能在给定时间选择冲突的动作。为了解决冲突和组合策略，我们采用了一种新颖的基于拍卖的机制。我们给每个策略分配一个有限的预算，在每一步，策略同时从可用的预算中出价来获取调度和选择动作的特权。策略使用其出价来表达调度的紧迫性，有限的预算确保了长期的调度公平性。

    Many sequential decision-making tasks require satisfaction of multiple, partially contradictory objectives. Existing approaches are monolithic, namely all objectives are fulfilled using a single policy, which is a function that selects a sequence of actions. We present auction-based scheduling, a modular framework for multi-objective decision-making problems. Each objective is fulfilled using a separate policy, and the policies can be independently created, modified, and replaced. Understandably, different policies with conflicting goals may choose conflicting actions at a given time. In order to resolve conflicts, and compose policies, we employ a novel auction-based mechanism. We allocate a bounded budget to each policy, and at each step, the policies simultaneously bid from their available budgets for the privilege of being scheduled and choosing an action. Policies express their scheduling urgency using their bids and the bounded budgets ensure long-run scheduling fairness. We lay 
    
[^34]: 电信AI原生系统在生成式AI时代的工程视角

    Telecom AI Native Systems in the Age of Generative AI -- An Engineering Perspective. (arXiv:2310.11770v1 [cs.SE])

    [http://arxiv.org/abs/2310.11770](http://arxiv.org/abs/2310.11770)

    电信行业试图将生成式AI和基础模型（FMs）整合进产品开发中，形成AI原生的电信系统。然而，伦理、监管和运营方面的挑战需要慎重考虑。

    

    人工智能，特别是生成式AI和基础模型（FMs）的快速发展，正在不同行业引起转型性变革。大型语言模型（LLMs）作为一种FM，展示了在自然语言处理任务和内容生成方面的强大能力，彻底改变了我们与软件产品和服务的互动方式。本文探讨了将FMs整合到电信行业中的可能性，揭示了AI原生电信的概念，即将AI无缝融入电信产品的构架中。本文深入探讨了将FMs实施到软件生命周期中的工程考虑和独特挑战，强调了AI原生优先的重要性。尽管FMs具有巨大潜力，但在关乎任务关键的电信环境中，伦理、监管和运营方面的挑战需要慎重考虑。随着电信行业试图利用AI的力量，一个组建AI原生团队的综合和实际方法是必要的

    The rapid advancements in Artificial Intelligence (AI), particularly in generative AI and foundational models (FMs), have ushered in transformative changes across various industries. Large language models (LLMs), a type of FM, have demonstrated their prowess in natural language processing tasks and content generation, revolutionizing how we interact with software products and services. This article explores the integration of FMs in the telecommunications industry, shedding light on the concept of AI native telco, where AI is seamlessly woven into the fabric of telecom products. It delves into the engineering considerations and unique challenges associated with implementing FMs into the software life cycle, emphasizing the need for AI native-first approaches. Despite the enormous potential of FMs, ethical, regulatory, and operational challenges require careful consideration, especially in mission-critical telecom contexts. As the telecom industry seeks to harness the power of AI, a com
    
[^35]: 使用Sum-GP-UCB方法估计互动物体的材料性质

    Estimating Material Properties of Interacting Objects Using Sum-GP-UCB. (arXiv:2310.11749v1 [cs.RO])

    [http://arxiv.org/abs/2310.11749](http://arxiv.org/abs/2310.11749)

    本文提出了一种使用Sum-GP-UCB方法估计互动物体材料性质的贝叶斯优化方法，在不同组互动物体场景的观察下，通过建模奖励函数结构和部分评估来加速优化过程。

    

    机器人需要通过观察来准确模拟物体的材料和动态特性。我们提出了一种基于贝叶斯优化的方法，用于通过一组观察来识别物体的材料属性参数。我们的重点是基于不同组互动物体场景的观察来估计这些属性。我们提出了一种利用奖励函数结构的方法，通过分别建模每个观察的奖励，并仅使用该场景中物体的参数作为输入。得到的低维模型在参数空间上具有更好的泛化能力，从而加速了优化过程。为了进一步加快优化过程，并减少寻找优秀参数值所需的仿真次数，我们还提出了奖励函数的部分评估方法，其中选择的参数仅在一部分真实世界评估上进行评估。

    Robots need to estimate the material and dynamic properties of objects from observations in order to simulate them accurately. We present a Bayesian optimization approach to identifying the material property parameters of objects based on a set of observations. Our focus is on estimating these properties based on observations of scenes with different sets of interacting objects. We propose an approach that exploits the structure of the reward function by modeling the reward for each observation separately and using only the parameters of the objects in that scene as inputs. The resulting lower-dimensional models generalize better over the parameter space, which in turn results in a faster optimization. To speed up the optimization process further, and reduce the number of simulation runs needed to find good parameter values, we also propose partial evaluations of the reward function, wherein the selected parameters are only evaluated on a subset of real world evaluations. The approach 
    
[^36]: 机器人技能学习的离线强化学习方法——动作量化离线强化学习

    Action-Quantized Offline Reinforcement Learning for Robotic Skill Learning. (arXiv:2310.11731v1 [cs.AI])

    [http://arxiv.org/abs/2310.11731](http://arxiv.org/abs/2310.11731)

    本文提出了一种适应性动作量化方案，通过使用VQ-VAE来学习状态条件下的动作量化，从而改善了机器人技能学习的离线强化学习在离散动作设置下的表现。

    

    离线强化学习（RL）范式提供了一种将静态行为数据集转化为比收集数据的策略表现更好的策略的通用方法。尽管策略约束、保守性和其他缓解分布偏移的方法使得离线强化学习更加有效，但在连续动作设置中，往往需要各种近似方法来应用这些技术。许多这些挑战在离散动作设置中得到了很大的缓解，离线RL约束和规则化器往往可以更精确或甚至完全计算出来。在本文中，我们提出了一种自适应的动作量化方案。我们使用VQ-VAE来学习状态条件下的动作量化，避免了动作空间的朴素离散化所带来的指数级增长。我们展示了一些最先进的离线RL方法，如IQL、CQL和BRAC，在基准测试中与我们提出的方法相结合后取得了更好的性能。

    The offline reinforcement learning (RL) paradigm provides a general recipe to convert static behavior datasets into policies that can perform better than the policy that collected the data. While policy constraints, conservatism, and other methods for mitigating distributional shifts have made offline reinforcement learning more effective, the continuous action setting often necessitates various approximations for applying these techniques. Many of these challenges are greatly alleviated in discrete action settings, where offline RL constraints and regularizers can often be computed more precisely or even exactly. In this paper, we propose an adaptive scheme for action quantization. We use a VQ-VAE to learn state-conditioned action quantization, avoiding the exponential blowup that comes with na\"ive discretization of the action space. We show that several state-of-the-art offline RL methods such as IQL, CQL, and BRAC improve in performance on benchmarks when combined with our proposed
    
[^37]: 面向隐私保护推荐的联邦异构图神经网络

    Federated Heterogeneous Graph Neural Network for Privacy-preserving Recommendation. (arXiv:2310.11730v1 [cs.LG])

    [http://arxiv.org/abs/2310.11730](http://arxiv.org/abs/2310.11730)

    本文提出了一种联邦异构图神经网络（FedHGNN）的框架，能够在分布式的异构信息网络上协同训练推荐模型，同时保护用户隐私。

    

    异构信息网络（HIN）通过元路径描述丰富的语义，已成为缓解推荐系统数据稀疏性的强大工具。现有的基于HIN的推荐系统持有数据的集中存储假设，并进行集中式模型训练。然而，由于隐私问题，现实世界的数据往往以分布式方式存储，导致集中式HIN推荐无法实现。本文提出将HIN分为客户端存储的私有HIN和服务器端的共享HIN。在此设置下，我们提出了一种基于联邦异构图神经网络（FedHGNN）的框架，可以在分布式HIN上协作训练推荐模型，同时不泄露用户隐私。具体而言，我们首先针对基于HIN的联合推荐，基于差分隐私的光下确定了隐私定义，旨在保护私有HIN的用户-商品交互，以及用户的隐私信息。

    Heterogeneous information network (HIN), which contains rich semantics depicted by meta-paths, has become a powerful tool to alleviate data sparsity in recommender systems. Existing HIN-based recommendations hold the data centralized storage assumption and conduct centralized model training. However, the real-world data is often stored in a distributed manner for privacy concerns, resulting in the failure of centralized HIN-based recommendations. In this paper, we suggest the HIN is partitioned into private HINs stored in the client side and shared HINs in the server. Following this setting, we propose a federated heterogeneous graph neural network (FedHGNN) based framework, which can collaboratively train a recommendation model on distributed HINs without leaking user privacy. Specifically, we first formalize the privacy definition in the light of differential privacy for HIN-based federated recommendation, which aims to protect user-item interactions of private HIN as well as user's 
    
[^38]: 自动本体匹配中的不确定性：从实证实验中获得的经验教训

    Uncertainty in Automated Ontology Matching: Lessons Learned from an Empirical Experimentation. (arXiv:2310.11723v1 [cs.AI])

    [http://arxiv.org/abs/2310.11723](http://arxiv.org/abs/2310.11723)

    本文通过实证实验揭示了自动本体匹配中存在的不确定性，这是数据集成领域的一个紧迫问题。

    

    数据集成被认为是信息科学界中的一个经典研究领域和一个紧迫的需求。本体在这一过程中扮演了关键的角色，通过提供良好巩固的支持来通过互操作性链接和语义集成数据集。本文从应用的角度探讨了基于本体匹配的技术来进行数据集成。基于本体的过程只有通过假设手动匹配不同信息源才能被认为是适当的。然而，一旦系统扩大规模，这种方法变得不切实际，匹配过程的自动化变得迫切需要。因此，我们利用科学界现有的自动本体匹配工具对实际数据进行了实验。即使考虑到一个相对简单的案例研究（即全球指标的时空对齐），结果清楚地显示出由于错误和不准确性产生的显著不确定性。

    Data integration is considered a classic research field and a pressing need within the information science community. Ontologies play a critical role in such a process by providing well-consolidated support to link and semantically integrate datasets via interoperability. This paper approaches data integration from an application perspective, looking at techniques based on ontology matching. An ontology-based process may only be considered adequate by assuming manual matching of different sources of information. However, since the approach becomes unrealistic once the system scales up, automation of the matching process becomes a compelling need. Therefore, we have conducted experiments on actual data with the support of existing tools for automatic ontology matching from the scientific community. Even considering a relatively simple case study (i.e., the spatio-temporal alignment of global indicators), outcomes clearly show significant uncertainty resulting from errors and inaccuracie
    
[^39]: 量化中文医学大型语言模型中与健康相关的原子知识：一项计算分析

    Quantify Health-Related Atomic Knowledge in Chinese Medical Large Language Models: A Computational Analysis. (arXiv:2310.11722v1 [cs.CL])

    [http://arxiv.org/abs/2310.11722](http://arxiv.org/abs/2310.11722)

    本研究通过构建一个基准，量化了中文医学大型语言模型中与健康相关的原子知识的存储程度，并发现通用LLMs在原子知识和指令遵循能力方面表现更好。两种类型的LLMs都倾向于迎合用户要求。

    

    大型语言模型（LLMs）有潜力通过搜索引擎直接和高效地提供用户的自诊断建议，从而革新用户自诊断的方式。最近的研究主要关注基于GPT-4评估LLMs的质量或其通过医学考试的能力，但没有研究量化存储在LLMs记忆中的健康相关原子知识的程度，而这是LLMs提供更准确建议的基础。在本文中，我们首先构建了一个基准，包括用户自诊断查询中最常见的原子知识类型，共17种原子类型和14048条原子知识。然后，我们对通用和专业LLMs在基准上进行了评估。实验结果表明，在原子知识和指令遵循能力方面，通用LLMs的表现优于专业LLMs。错误分析显示，通用和专业LLMs都是马屁精，即在涉及用户要求时总是迎合用户。

    Large Language Models (LLMs) have the potential to revolutionize the way users self-diagnose through search engines by offering direct and efficient suggestions. Recent studies primarily focused on the quality of LLMs evaluated by GPT-4 or their ability to pass medical exams, no studies have quantified the extent of health-related atomic knowledge stored in LLMs' memory, which is the basis of LLMs to provide more factual suggestions. In this paper, we first constructed a benchmark, including the most common types of atomic knowledge in user self-diagnosis queries, with 17 atomic types and a total of 14, 048 pieces of atomic knowledge. Then, we evaluated both generic and specialized LLMs on the benchmark. The experimental results showcased that generic LLMs perform better than specialized LLMs in terms of atomic knowledge and instruction-following ability. Error analysis revealed that both generic and specialized LLMs are sycophantic, e.g., always catering to users' claims when it comes
    
[^40]: 利用粗粒度数据集增强低资源细粒度命名实体识别

    Enhancing Low-resource Fine-grained Named Entity Recognition by Leveraging Coarse-grained Datasets. (arXiv:2310.11715v1 [cs.CL])

    [http://arxiv.org/abs/2310.11715](http://arxiv.org/abs/2310.11715)

    通过利用粗粒度数据集，提出了一种细粒度命名实体识别模型，使用细粒度-粗粒度映射矩阵来显式利用层次结构，并提出了一种不一致性过滤方法，以增强低资源细粒度命名实体识别。

    

    命名实体识别（NER）在细粒度NER场景下常常面临标注数据不足的问题。虽然可以应用K-shot学习技术，但当注释数量超过几十个标签时，性能往往达到饱和。为了解决这个问题，我们利用现有的粗粒度数据集，其中包含大量的标注。一种直接解决这个问题的方法是预训练，它利用粗粒度数据进行表示学习。然而，它无法直接利用细粒度和粗粒度实体之间的关系，尽管细粒度实体类型很可能是粗粒度实体类型的子类别。我们提出了一个带有细粒度-粗粒度（F2C）映射矩阵的细粒度NER模型，以显式地利用层次结构。此外，我们提出了一种不一致性过滤方法，以消除与细粒度不一致的粗粒度实体。

    Named Entity Recognition (NER) frequently suffers from the problem of insufficient labeled data, particularly in fine-grained NER scenarios. Although $K$-shot learning techniques can be applied, their performance tends to saturate when the number of annotations exceeds several tens of labels. To overcome this problem, we utilize existing coarse-grained datasets that offer a large number of annotations. A straightforward approach to address this problem is pre-finetuning, which employs coarse-grained data for representation learning. However, it cannot directly utilize the relationships between fine-grained and coarse-grained entities, although a fine-grained entity type is likely to be a subcategory of a coarse-grained entity type. We propose a fine-grained NER model with a Fine-to-Coarse(F2C) mapping matrix to leverage the hierarchical structure explicitly. In addition, we present an inconsistency filtering method to eliminate coarse-grained entities that are inconsistent with fine-gr
    
[^41]: 学习同时语言手势用于多模态失语类型检测

    Learning Co-Speech Gesture for Multimodal Aphasia Type Detection. (arXiv:2310.11710v1 [cs.CL])

    [http://arxiv.org/abs/2310.11710](http://arxiv.org/abs/2310.11710)

    通过学习语音和手势之间的相关性，我们提出了一种多模态图神经网络，用于准确识别特定失语类型的检测。实验证明我们的方法优于现有方法，达到了最先进的结果（F1 84.2%）。

    

    失语是一种由脑损伤引起的语言障碍，需要准确识别特定的失语类型，如Broca失语和Wernicke失语，以进行有效的治疗。然而，对于开发用于检测不同类型失语的方法，人们并没有给予足够的关注。我们意识到分析同时语言手势对于区分失语类型的重要性，提出了一种多模态图神经网络，利用语音和相应的手势模式进行失语类型检测。通过学习每种失语类型的语音和手势模态之间的相关性，我们的模型可以生成对手势信息敏感的文本表示，从而实现准确的失语类型检测。大量实验证明了我们方法的优越性，实现了最先进的结果（F1 84.2%）。我们还展示了手势特征优于声学特征，突显了手势表达在检测失语类型中的重要性。

    Aphasia, a language disorder resulting from brain damage, requires accurate identification of specific aphasia types, such as Broca's and Wernicke's aphasia, for effective treatment. However, little attention has been paid to developing methods to detect different types of aphasia. Recognizing the importance of analyzing co-speech gestures for distinguish aphasia types, we propose a multimodal graph neural network for aphasia type detection using speech and corresponding gesture patterns. By learning the correlation between the speech and gesture modalities for each aphasia type, our model can generate textual representations sensitive to gesture information, leading to accurate aphasia type detection. Extensive experiments demonstrate the superiority of our approach over existing methods, achieving state-of-the-art results (F1 84.2\%). We also show that gesture features outperform acoustic features, highlighting the significance of gesture expression in detecting aphasia types. We pro
    
[^42]: Live Graph Lab:朝向具有NFT的开放、动态和实时交易图

    Live Graph Lab: Towards Open, Dynamic and Real Transaction Graphs with NFT. (arXiv:2310.11709v1 [cs.AI])

    [http://arxiv.org/abs/2310.11709](http://arxiv.org/abs/2310.11709)

    本文介绍了用于时间图的“实时图实验室”的概念，该实验室可以从NFT的区块链中提取开放、动态和实时的交易图，为了弥补对新兴NFT生态系统的特性了解的缺口，我们使用NFT交易网络实例化了一个实时图并进行了调查

    

    进行了大量研究来调查大规模时间图的特性。尽管这些图在现实场景中普遍存在，但由于隐私问题和技术限制，我们通常无法获取整个实时图。在本文中，我们介绍了用于时间图的“实时图实验室”概念，该实验室可以从区块链中提取开放、动态和实时的交易图。其中，非同质化代币（NFT）在过去几年中成为区块链中最重要的部分之一。这个分散化生态系统具有超过400亿美元的市值，产生了大量的匿名和实时交易活动，自然形成了一个复杂的交易网络。然而，从时间图分析的角度对这个新兴的NFT生态系统的特性了解有限。为了弥补这一差距，我们使用NFT交易网络实例化了一个实时图并进行了调查。

    Numerous studies have been conducted to investigate the properties of large-scale temporal graphs. Despite the ubiquity of these graphs in real-world scenarios, it's usually impractical for us to obtain the whole real-time graphs due to privacy concerns and technical limitations. In this paper, we introduce the concept of {\it Live Graph Lab} for temporal graphs, which enables open, dynamic and real transaction graphs from blockchains. Among them, Non-fungible tokens (NFTs) have become one of the most prominent parts of blockchain over the past several years. With more than \$40 billion market capitalization, this decentralized ecosystem produces massive, anonymous and real transaction activities, which naturally forms a complicated transaction network. However, there is limited understanding about the characteristics of this emerging NFT ecosystem from a temporal graph analysis perspective. To mitigate this gap, we instantiate a live graph with NFT transaction network and investigate 
    
[^43]: 对向量数据库的全面调查：存储和检索技术，挑战

    A Comprehensive Survey on Vector Database: Storage and Retrieval Technique, Challenge. (arXiv:2310.11703v1 [cs.DB])

    [http://arxiv.org/abs/2310.11703](http://arxiv.org/abs/2310.11703)

    这篇论文对向量数据库进行了全面调查，介绍了存储和检索技术以及面临的挑战，对解决近似最近邻搜索问题的不同方法进行了分类，并探讨了向量数据库与大型语言模型的结合带来的新机遇。

    

    向量数据库用于存储无法用传统的DBMS来描述的高维数据。虽然目前对现有的向量数据库架构的描述或新的引入的文章并不多，但近似最近邻搜索问题在向量数据库背后已经被长时间研究，相关的算法文章在文献中可以找到相当多。本文试图全面回顾相关算法，以提供对这一蓬勃发展的研究领域的普遍理解。我们的框架将这些研究分为基于哈希、基于树、基于图、和基于量化的方法来解决近似最近邻搜索问题。然后，我们概述了向量数据库面临的现有挑战。最后，我们概述了向量数据库如何结合大型语言模型，提供新的可能性。

    A vector database is used to store high-dimensional data that cannot be characterized by traditional DBMS. Although there are not many articles describing existing or introducing new vector database architectures, the approximate nearest neighbor search problem behind vector databases has been studied for a long time, and considerable related algorithmic articles can be found in the literature. This article attempts to comprehensively review relevant algorithms to provide a general understanding of this booming research area. The basis of our framework categorises these studies by the approach of solving ANNS problem, respectively hash-based, tree-based, graph-based and quantization-based approaches. Then we present an overview of existing challenges for vector databases. Lastly, we sketch how vector databases can be combined with large language models and provide new possibilities.
    
[^44]: 单视角视频中的跑者再识别在开放环境中

    Runner re-identification from single-view video in the open-world setting. (arXiv:2310.11700v1 [cs.CV])

    [http://arxiv.org/abs/2310.11700](http://arxiv.org/abs/2310.11700)

    本论文提出了一种在开放世界环境中直接处理单视角视频的跑者再识别系统。通过自动处理原始视频作为输入来识别跑者，并且能够在跑者被框选出多次的情况下进行识别。

    

    在许多体育运动中，跑者的再识别对于自动视频处理和分析至关重要。然而，目前关于多视角或单视角体育视频中跑者再识别的大部分研究都集中在使用标记图像数据集进行封闭世界设定的再识别上，而在开放世界环境下进行自动视频分析的跑者再识别并未得到很好的发展。本文提出了一种直接处理单视角视频以解决开放世界设置的跑者再识别系统。在开放世界设置中，我们无法使用标记数据集，并且必须直接处理视频。所提出的系统自动处理原始视频作为输入来识别跑者，即使跑者出现多次被框选出，系统也能进行识别。对于自动处理，我们首先使用预训练的YOLOv8和微调的EfficientNet来检测视频中的跑者。然后使用ByteTrack来跟踪跑者，并使用微调的YOLO来检测他们的鞋子。

    In many sports, player re-identification is crucial for automatic video processing and analysis. However, most of the current studies on player re-identification in multi- or single-view sports videos focus on re-identification in the closed-world setting using labeled image dataset, and player re-identification in the open-world setting for automatic video analysis is not well developed. In this paper, we propose a runner re-identification system that directly processes single-view video to address the open-world setting. In the open-world setting, we cannot use labeled dataset and have to process video directly. The proposed system automatically processes raw video as input to identify runners, and it can identify runners even when they are framed out multiple times. For the automatic processing, we first detect the runners in the video using the pre-trained YOLOv8 and the fine-tuned EfficientNet. We then track the runners using ByteTrack and detect their shoes with the fine-tuned YO
    
[^45]: 无限时域平均奖励强化学习的量子加速

    Quantum Acceleration of Infinite Horizon Average-Reward Reinforcement Learning. (arXiv:2310.11684v1 [cs.LG])

    [http://arxiv.org/abs/2310.11684](http://arxiv.org/abs/2310.11684)

    本研究探索了无限时域平均奖励强化学习中量子加速的潜力。我们提出了一种创新的量子框架，通过高效的量子均值估计技术，实现了指数级改进的遗憾保证。所提出的量子算法相较于经典算法，在遗憾界限上有显著改进。

    

    本文研究量子加速在解决无限时域Markov决策过程（MDPs）中提高平均奖励结果的潜力。我们引入了一种创新的量子框架，用于代理与未知MDP的互动，扩展了传统的交互范式。我们的方法涉及设计一种基于乐观主导的具有量子信号的表格强化学习算法，通过高效的量子均值估计技术获取代理获取的量子信号。通过深入的理论分析，我们证明了量子均值估计的优势能够在无限时域强化学习中导致遗憾保证的指数进展。具体地，所提出的量子算法实现了一个遗憾界为$\tilde{\mathcal{O}}(1)$的性能，这是相对于经典对应算法所展示的$\tilde{\mathcal{O}}(\sqrt{T})$界限的显著改进。

    This paper investigates the potential of quantum acceleration in addressing infinite horizon Markov Decision Processes (MDPs) to enhance average reward outcomes. We introduce an innovative quantum framework for the agent's engagement with an unknown MDP, extending the conventional interaction paradigm. Our approach involves the design of an optimism-driven tabular Reinforcement Learning algorithm that harnesses quantum signals acquired by the agent through efficient quantum mean estimation techniques. Through thorough theoretical analysis, we demonstrate that the quantum advantage in mean estimation leads to exponential advancements in regret guarantees for infinite horizon Reinforcement Learning. Specifically, the proposed Quantum algorithm achieves a regret bound of $\tilde{\mathcal{O}}(1)$, a significant improvement over the $\tilde{\mathcal{O}}(\sqrt{T})$ bound exhibited by classical counterparts.
    
[^46]: 生物医学领域中的描述性知识图谱

    Descriptive Knowledge Graph in Biomedical Domain. (arXiv:2310.11681v1 [cs.CL])

    [http://arxiv.org/abs/2310.11681](http://arxiv.org/abs/2310.11681)

    这个论文提出了一个在生物医学领域中构建描述性知识图谱的新系统，可以从文献中提取有信息量的句子并进行关系搜索和导航。并且该系统使用自动生成描述性句子的模型，减少了人工阅读的工作量。在COVID-19研究中应用该系统展示了其在相关领域的实用性。

    

    我们提出了一个新颖的系统，可以从生物医学文献中自动提取和生成有信息量和描述性的句子，并促进有效的关系知识搜索。与之前检索非相关段落的搜索引擎或探索系统不同，我们的系统将描述性句子组织为一个关系图，使研究人员能够探索相关的生物医学实体（例如，由化学物质治疗的疾病）或间接相关的实体（例如，用于治疗某种疾病的潜在药物）。我们的系统还使用ChatGPT和经过微调的关系合成模型从检索到的信息中生成简洁可靠的描述性句子，减少了人工阅读的需求。使用我们的系统，研究人员可以轻松获得高级知识和详细参考，并可以交互地导航到感兴趣的信息。我们重点介绍了我们系统在COVID-19研究中的应用，以说明其在相关领域的效用

    We present a novel system that automatically extracts and generates informative and descriptive sentences from the biomedical corpus and facilitates the efficient search for relational knowledge. Unlike previous search engines or exploration systems that retrieve unconnected passages, our system organizes descriptive sentences as a relational graph, enabling researchers to explore closely related biomedical entities (e.g., diseases treated by a chemical) or indirectly connected entities (e.g., potential drugs for treating a disease). Our system also uses ChatGPT and a fine-tuned relation synthesis model to generate concise and reliable descriptive sentences from retrieved information, reducing the need for extensive human reading effort. With our system, researchers can easily obtain both high-level knowledge and detailed references and interactively steer to the information of interest. We spotlight the application of our system in COVID-19 research, illustrating its utility in areas 
    
[^47]: 使用经验分类训练非马尔可夫任务

    Using Experience Classification for Training Non-Markovian Tasks. (arXiv:2310.11678v1 [cs.LG])

    [http://arxiv.org/abs/2310.11678](http://arxiv.org/abs/2310.11678)

    该论文提出了一种使用经验分类的方法来训练非马尔可夫任务。通过将非马尔可夫任务转化为有限轨迹上的线性时态逻辑表达，并利用优先化经验回放技术改善训练过程，以实现非马尔可夫奖励的目标逻辑。实验证明了该方法的可行性和有效性。

    

    不同于标准的强化学习模型，许多实际任务是非马尔可夫的，其奖励是基于状态历史而不仅仅是当前状态。解决非马尔可夫任务在实际应用中（如自动驾驶、金融交易和医学诊断）中经常面临挑战。我们提出了一种新颖的强化学习方法，以实现在有限轨迹上表达的非马尔可夫奖励的目标逻辑LTL$_f$（线性时态逻辑）。为此，我们引入了一种从LTL$_f$到MDPs（马尔可夫决策过程）的线性复杂度的编码，以利用先进的强化学习算法。然后，我们利用基于自动机结构（语义等价于LTL$_f$规范）的优先化经验回放技术来改善训练过程。我们通过对几个带有非马尔可夫任务的基准问题进行实证评估，以展示我们方法的可行性和有效性。

    Unlike the standard Reinforcement Learning (RL) model, many real-world tasks are non-Markovian, whose rewards are predicated on state history rather than solely on the current state. Solving a non-Markovian task, frequently applied in practical applications such as autonomous driving, financial trading, and medical diagnosis, can be quite challenging. We propose a novel RL approach to achieve non-Markovian rewards expressed in temporal logic LTL$_f$ (Linear Temporal Logic over Finite Traces). To this end, an encoding of linear complexity from LTL$_f$ into MDPs (Markov Decision Processes) is introduced to take advantage of advanced RL algorithms. Then, a prioritized experience replay technique based on the automata structure (semantics equivalent to LTL$_f$ specification) is utilized to improve the training process. We empirically evaluate several benchmark problems augmented with non-Markovian tasks to demonstrate the feasibility and effectiveness of our approach.
    
[^48]: 无限时间无折扣奖励马尔可夫决策过程自然策略梯度算法的改进样本复杂度分析

    Improved Sample Complexity Analysis of Natural Policy Gradient Algorithm with General Parameterization for Infinite Horizon Discounted Reward Markov Decision Processes. (arXiv:2310.11677v1 [cs.LG])

    [http://arxiv.org/abs/2310.11677](http://arxiv.org/abs/2310.11677)

    本论文提出了一种加速自然策略梯度算法（ANPG），用于解决无限时间无折扣奖励马尔可夫决策过程。ANPG实现了样本和迭代复杂度的显著改进，克服了现有算法的局限性，并达到了最新的技术成果。

    

    本文考虑设计样本高效的学习算法，用于无限时间无折扣奖励马尔可夫决策过程。具体地，我们提出了加速自然策略梯度（ANPG）算法，利用加速随机梯度下降过程来获取自然策略梯度。ANPG算法在一般参数化情况下实现了O(ε^{-2})的样本复杂度和O(ε^{-1})的迭代复杂度，其中ε定义了最优性误差。这将样本复杂度提高了一个log(1/ε)的因子。ANPG是一个一阶算法，并且不需要现有文献中可能无法验证的重要性采样(IS)权重方差上界的假设。在无Hessian和无IS算法类中，ANPG超过了已知样本复杂度的一个O(ε^{-\frac{1}{2}})的因子，并同时达到了它们的最新技术成果。

    We consider the problem of designing sample efficient learning algorithms for infinite horizon discounted reward Markov Decision Process. Specifically, we propose the Accelerated Natural Policy Gradient (ANPG) algorithm that utilizes an accelerated stochastic gradient descent process to obtain the natural policy gradient. ANPG achieves $\mathcal{O}({\epsilon^{-2}})$ sample complexity and $\mathcal{O}(\epsilon^{-1})$ iteration complexity with general parameterization where $\epsilon$ defines the optimality error. This improves the state-of-the-art sample complexity by a $\log(\frac{1}{\epsilon})$ factor. ANPG is a first-order algorithm and unlike some existing literature, does not require the unverifiable assumption that the variance of importance sampling (IS) weights is upper bounded. In the class of Hessian-free and IS-free algorithms, ANPG beats the best-known sample complexity by a factor of $\mathcal{O}(\epsilon^{-\frac{1}{2}})$ and simultaneously matches their state-of-the-art it
    
[^49]: PREM:一种简单而有效的节点级图异常检测方法。

    PREM: A Simple Yet Effective Approach for Node-Level Graph Anomaly Detection. (arXiv:2310.11676v1 [cs.LG])

    [http://arxiv.org/abs/2310.11676](http://arxiv.org/abs/2310.11676)

    PREM是一种简单而有效的节点级图异常检测方法，它通过简化图异常检测的过程，减少了时间和内存消耗，同时保持了强大的异常检测能力。

    

    节点级图异常检测在识别医学、社交网络和电子商务等各个领域中的图结构数据中的异常节点起着关键作用。然而，由于异常的多样性以及标注数据的匮乏，已有的基于重构和对比学习的方法往往在效率方面存在问题，这源于它们复杂的目标和繁琐的模块。为了提高图异常检测的效率，我们引入了一种简单的方法，称为PREprocessing and Matching（简称PREM）。我们的方法简化了图异常检测，减少了时间和内存的消耗，同时保持了强大的异常检测能力。PREM由两个模块组成：预处理模块和邻居匹配模块。PREM在训练过程中消除了消息传递传播的必要性，并采用了简单的对比损失函数，从而大大减少了训练时间和内存使用量。此外，

    Node-level graph anomaly detection (GAD) plays a critical role in identifying anomalous nodes from graph-structured data in various domains such as medicine, social networks, and e-commerce. However, challenges have arisen due to the diversity of anomalies and the dearth of labeled data. Existing methodologies reconstruction-based and contrastive learning - while effective, often suffer from efficiency issues, stemming from their complex objectives and elaborate modules. To improve the efficiency of GAD, we introduce a simple method termed PREprocessing and Matching (PREM for short). Our approach streamlines GAD, reducing time and memory consumption while maintaining powerful anomaly detection capabilities. Comprising two modules - a pre-processing module and an ego-neighbor matching module - PREM eliminates the necessity for message-passing propagation during training, and employs a simple contrastive loss, leading to considerable reductions in training time and memory usage. Moreov
    
[^50]: 基于原型的超适配器用于样本高效多任务调整

    Prototype-based HyperAdapter for Sample-Efficient Multi-task Tuning. (arXiv:2310.11670v1 [cs.CL])

    [http://arxiv.org/abs/2310.11670](http://arxiv.org/abs/2310.11670)

    基于原型的超适配器（PHA）框架用于样本高效多任务调整，通过引入实例密集的检索器和样本高效的原型超网络生成条件模块，在多任务学习和少样本迁移学习中取得了可比性能的提升，甚至在数据量较小时也能超过其他强基线方法的性能。

    

    参数高效微调（PEFT）已经证明在适应预训练语言模型到下游任务时有效，同时只更新了少量参数。尽管取得了成功，大多数现有方法独立地适应每个任务，没有考虑任务之间的知识传输，并且受限于低数据情景。为了克服这个问题，我们提出了一种基于原型的超适配器（PHA）框架，该框架建立在适配器调整和超网络基础上。它引入了一个实例密集的检索器和一个样本高效的原型超网络来生成条件模块。这导致与现有PEFT方法在多任务学习和少样本迁移学习上相当的性能改进。更重要的是，当可用数据量变小时，我们的方法比其他强基线方法有很大的优势。基于我们在各种数据集上的广泛实证实验，我们证明了PHA在权衡方面取得了更好的结果。

    Parameter-efficient fine-tuning (PEFT) has shown its effectiveness in adapting the pre-trained language models to downstream tasks while only updating a small number of parameters. Despite the success, most existing methods independently adapt to each task without considering knowledge transfer between tasks and are limited to low-data regimes. To overcome this issue, we propose Prototype-based HyperAdapter (PHA), a novel framework built on the adapter-tuning and hypernetwork. It introduces an instance-dense retriever and a prototypical hypernetwork to generate the conditional modules in a sample-efficient manner. This leads to comparable performance improvements against existing PEFT methods on multi-task learning and few-shot transfer learning. More importantly, when the available data size gets smaller, our method outperforms other strong baselines by a large margin. Based on our extensive empirical experiments across various datasets, we demonstrate that PHA strikes a better trade-
    
[^51]: SOTOPIA: 交互式评估语言智能中的社交智能

    SOTOPIA: Interactive Evaluation for Social Intelligence in Language Agents. (arXiv:2310.11667v1 [cs.AI])

    [http://arxiv.org/abs/2310.11667](http://arxiv.org/abs/2310.11667)

    SOTOPIA是一个用于评估语言智能中的社交智能的交互式环境。通过模拟复杂的社交互动，并使用全面的评估框架，我们发现不同模型之间的社交智能存在显著差异，特别是在SOTOPIA-hard情景下。GPT-4在这个子集上的目标完成率较低。

    

    人类是社交的存在；我们在日常互动中追求社交目标，这是社交智能的关键方面。然而，人工智能系统在这个领域的能力仍然难以捉摸。我们提出了SOTOPIA，一个开放式环境，用于模拟人工智能代理之间的复杂社交互动并评估它们的社交智能。在我们的环境中，代理人扮演角色，在各种场景下相互协作、合作、交流和竞争，以实现复杂的社交目标。我们模拟了LLM-based代理人与人类之间在这个任务空间内的角色扮演互动，并使用一个名为SOTOPIA-Eval的整体评估框架对它们的表现进行评估。通过SOTOPIA，我们发现这些模型在社交智能方面存在显著差异，并确定了SOTOPIA的一个子集，即SOTOPIA-hard，对所有模型来说都具有挑战性。我们发现在这个子集上，GPT-4的目标完成率显著较低。

    Humans are social beings; we pursue social goals in our daily interactions, which is a crucial aspect of social intelligence. Yet, AI systems' abilities in this realm remain elusive. We present SOTOPIA, an open-ended environment to simulate complex social interactions between artificial agents and evaluate their social intelligence. In our environment, agents role-play and interact under a wide variety of scenarios; they coordinate, collaborate, exchange, and compete with each other to achieve complex social goals. We simulate the role-play interaction between LLM-based agents and humans within this task space and evaluate their performance with a holistic evaluation framework called SOTOPIA-Eval. With SOTOPIA, we find significant differences between these models in terms of their social intelligence, and we identify a subset of SOTOPIA scenarios, SOTOPIA-hard, that is generally challenging for all models. We find that on this subset, GPT-4 achieves a significantly lower goal completio
    
[^52]: Hetero$^2$Net: 面向异构图的异质属性感知表示学习

    Hetero$^2$Net: Heterophily-aware Representation Learning on Heterogenerous Graphs. (arXiv:2310.11664v1 [cs.LG])

    [http://arxiv.org/abs/2310.11664](http://arxiv.org/abs/2310.11664)

    Hetero$^2$Net是一种面向异构图的异质属性感知表示学习方法，通过使用元路径识别异构图中的异质性，并提出了度量指标来描述异质性水平，以解决常见图神经网络在处理具有异质性的图中的限制。

    

    实际世界的图通常非常复杂，全局结构中存在异构性，而局部邻域内则表现出强烈的异质性。尽管有越来越多的文献揭示了常见图神经网络（GNNs）在处理具有异质性的同构图时的局限性，但在研究异构图中的异质性属性方面却鲜有研究。为填补这一研究空白，我们使用元路径识别了异构图中的异质性，并提出了两个实用的度量指标来定量描述异质性水平。通过对几个展示不同异质性水平的真实世界异构图的深入研究，我们发现继承了很多设计用于同构图的GNNs机制的异构图神经网络（HGNNs）在处理具有异质性或低度同质性的异构图时无法泛化。为了解决这一挑战，我们提出了Hetero$^2$Net，一个面向异构图的异质属性感知表示学习方法。

    Real-world graphs are typically complex, exhibiting heterogeneity in the global structure, as well as strong heterophily within local neighborhoods. While a growing body of literature has revealed the limitations of common graph neural networks (GNNs) in handling homogeneous graphs with heterophily, little work has been conducted on investigating the heterophily properties in the context of heterogeneous graphs. To bridge this research gap, we identify the heterophily in heterogeneous graphs using metapaths and propose two practical metrics to quantitatively describe the levels of heterophily. Through in-depth investigations on several real-world heterogeneous graphs exhibiting varying levels of heterophily, we have observed that heterogeneous graph neural networks (HGNNs), which inherit many mechanisms from GNNs designed for homogeneous graphs, fail to generalize to heterogeneous graphs with heterophily or low level of homophily. To address the challenge, we present Hetero$^2$Net, a h
    
[^53]: 云磁共振成像系统：在6G和人工智能时代的应用

    Cloud-Magnetic Resonance Imaging System: In the Era of 6G and Artificial Intelligence. (arXiv:2310.11641v1 [eess.IV])

    [http://arxiv.org/abs/2310.11641](http://arxiv.org/abs/2310.11641)

    Cloud-MRI是一种创新的MRI系统，在6G和人工智能时代应用的云磁共振成像系统，旨在解决MRI数据存储安全性、传输速度、AI算法维护、硬件升级和协作工作的问题。

    

    磁共振成像（MRI）在医学诊断中起着重要作用，每年在大型医院产生了数PB的图像数据。这个庞大的数据流需要大量的网络带宽和庞大的存储基础设施。此外，本地数据处理需要大量的人力和硬件投资。不同医疗机构之间的数据隔离阻碍了临床和研究的跨机构合作。在这项工作中，我们预期将新兴的分布式云计算、6G带宽、边缘计算、联邦学习和区块链技术结合起来，提出一种创新的MRI系统及其四代。该系统被称为Cloud-MRI，旨在解决MRI数据存储安全性、传输速度、AI算法维护、硬件升级和协作工作的问题。工作流程从将k空间原始数据转化为标准化的磁共振成像学会的图像格式开始。

    Magnetic Resonance Imaging (MRI) plays an important role in medical diagnosis, generating petabytes of image data annually in large hospitals. This voluminous data stream requires a significant amount of network bandwidth and extensive storage infrastructure. Additionally, local data processing demands substantial manpower and hardware investments. Data isolation across different healthcare institutions hinders cross-institutional collaboration in clinics and research. In this work, we anticipate an innovative MRI system and its four generations that integrate emerging distributed cloud computing, 6G bandwidth, edge computing, federated learning, and blockchain technology. This system is called Cloud-MRI, aiming at solving the problems of MRI data storage security, transmission speed, AI algorithm maintenance, hardware upgrading, and collaborative work. The workflow commences with the transformation of k-space raw data into the standardized Imaging Society for Magnetic Resonance in Med
    
[^54]: 解释决策树的符号语言

    A Symbolic Language for Interpreting Decision Trees. (arXiv:2310.11636v1 [cs.LO])

    [http://arxiv.org/abs/2310.11636](http://arxiv.org/abs/2310.11636)

    这篇论文介绍了一种解释决策树的符号语言ExplainDT，使用了一阶逻辑的片段StratiFOILed，可以计算出各种事后解释，包括局部解释和全局解释。

    

    近期发展的正式可解释的AI挑战了“决策树是易解释的模型”的流行说法，展示了在决策树上进行解释性查询的计算难题，并提出了不同的方法在实践中处理这些问题。然而，没有一个单一的解释性查询或评分适用于每个情境和最终用户。这自然地提出了“可解释性语言”的可能性，其中可以表达各种查询，为最终用户提供根据其特定需求定制查询的控制。在这个背景下，我们的工作介绍了解释决策树的符号语言ExplainDT。ExplainDT根植于我们称之为StratiFOILed的精心构建的一阶逻辑的片段。StratiFOILed平衡了表达能力和评估复杂度，允许计算出许多事后解释，包括局部解释（例如，认为和反向推理）和全局解释（例如，推广和对抗）。

    The recent development of formal explainable AI has disputed the folklore claim that "decision trees are readily interpretable models", showing different interpretability queries that are computationally hard on decision trees, as well as proposing different methods to deal with them in practice. Nonetheless, no single explainability query or score works as a "silver bullet" that is appropriate for every context and end-user. This naturally suggests the possibility of "interpretability languages" in which a wide variety of queries can be expressed, giving control to the end-user to tailor queries to their particular needs. In this context, our work presents ExplainDT, a symbolic language for interpreting decision trees. ExplainDT is rooted in a carefully constructed fragment of first-ordered logic that we call StratiFOILed. StratiFOILed balances expressiveness and complexity of evaluation, allowing for the computation of many post-hoc explanations--both local (e.g., abductive and contr
    
[^55]: 学习您的标记：用于语言模型的单词池化标记化

    Learn Your Tokens: Word-Pooled Tokenization for Language Modeling. (arXiv:2310.11628v1 [cs.CL])

    [http://arxiv.org/abs/2310.11628](http://arxiv.org/abs/2310.11628)

    使用"学习您的标记"方案，利用单词边界将字节/字符汇聚成单词表示形式，以改善标记化策略的局限性并提高语言模型的性能。

    

    语言模型通常将文本标记化为子词，使用确定性的、手工设计的启发式方法将字符组合成更长的表层字符串（如 'ing'）或整个单词。最近的文献反复展示了这种标记化策略的局限性，特别是对于非英文的文档和表示数字。另一方面，字节/字符级语言模型受限制较少，但在自我注意计算中存在序列描述长度增加和后续二次扩展的问题。最近对这些上下文长度进行固定大小卷积压缩和限制的尝试是有益的，但完全忽略了单词边界。本文考虑了一种替代的“学习您的标记”方案，利用单词边界将字节/字符汇聚成单词表示形式，然后将其馈送到主要语言模型中，再对每个单词并行解码个别的字符/字节。我们发现我们的

    Language models typically tokenize text into subwords, using a deterministic, hand-engineered heuristic of combining characters into longer surface-level strings such as 'ing' or whole words. Recent literature has repeatedly shown the limitations of such a tokenization strategy, particularly for documents not written in English and for representing numbers. On the other extreme, byte/character-level language models are much less restricted but suffer from increased sequence description lengths and a subsequent quadratic expansion in self-attention computation. Recent attempts to compress and limit these context lengths with fixed size convolutions is helpful but completely ignores the word boundary. This paper considers an alternative 'learn your tokens' scheme which utilizes the word boundary to pool bytes/characters into word representations, which are fed to the primary language model, before again decoding individual characters/bytes per word in parallel. We find that our moderatel
    
[^56]: 揭示语言模型中的普遍智能因子：一种心理测量方法

    Unveiling the General Intelligence Factor in Language Models: A Psychometric Approach. (arXiv:2310.11616v1 [cs.CL])

    [http://arxiv.org/abs/2310.11616](http://arxiv.org/abs/2310.11616)

    本研究利用心理测量理论揭示了语言模型中的普遍智能因子g的存在，并发现了该因子解释模型性能方差的85%，为模型评估和开发提供了统一的指标。

    

    本研究采用心理测量理论，揭示了语言模型中普遍智能因子g的存在，并扩展了该理论在人类和某些动物物种中的应用。通过对两个大型数据集Open LLM Leaderboard（包含1,232个模型）和General Language Understanding Evaluation（GLUE）Leaderboard（包含88个模型）进行因子分析，我们发现了一个具有一维性和高度稳定性的g因子，可以解释模型性能方差的85%。研究还发现模型大小和g之间的中度相关性为0.48。在语言模型中发现g因子为模型评估提供了统一的指标，为更强大、基于g因子的模型能力评估开辟了新的途径。这些发现为从心理测量的角度理解和未来研究人工智能提供了基础，并对模型评估和开发具有实际意义。

    This study uncovers the factor of general intelligence, or g, in language models, extending the psychometric theory traditionally applied to humans and certain animal species. Utilizing factor analysis on two extensive datasets Open LLM Leaderboard with 1,232 models and General Language Understanding Evaluation (GLUE) Leaderboard with 88 models - we find compelling evidence for a unidimensional, highly stable g factor that accounts for 85% of the variance in model performance. The study also finds a moderate correlation of .48 between model size and g. The discovery of g in language models offers a unified metric for model evaluation and opens new avenues for more robust, g-based model ability assessment. These findings lay the foundation for understanding and future research on artificial general intelligence from a psychometric perspective and have practical implications for model evaluation and development.
    
[^57]: 从多代人中学习的层次规划器

    Learning a Hierarchical Planner from Humans in Multiple Generations. (arXiv:2310.11614v1 [cs.AI])

    [http://arxiv.org/abs/2310.11614](http://arxiv.org/abs/2310.11614)

    这项研究提出了一种将编程学习与层次规划器结合的自然编程库学习系统，通过用户教导的方式，系统可以快速学习并适应复杂任务。

    

    机器从人类获得知识的一种典型方式是通过编程。与从演示或经验中学习相比，编程学习允许机器在编写程序时就能获得新的技能，并通过建立程序库，机器可以快速学习如何执行复杂任务。然而，由于程序往往默认执行环境不变，当环境发生变化时，复杂程序的适应性变差，使得将复杂程序适应新环境变得困难。本文介绍了一种将编程学习与层次规划器相结合的自然编程库学习系统。自然编程通过维护一个包含目标、目标如何分解为子目标的语言描述，以及具体分解为子目标的实例的分解库，用户可以通过课程构建的方式教导系统，选择一个具有挑战但不是不可能达到的目标，并提供关于如何达成这一目标的提示。

    A typical way in which a machine acquires knowledge from humans is by programming. Compared to learning from demonstrations or experiences, programmatic learning allows the machine to acquire a novel skill as soon as the program is written, and, by building a library of programs, a machine can quickly learn how to perform complex tasks. However, as programs often take their execution contexts for granted, they are brittle when the contexts change, making it difficult to adapt complex programs to new contexts. We present natural programming, a library learning system that combines programmatic learning with a hierarchical planner. Natural programming maintains a library of decompositions, consisting of a goal, a linguistic description of how this goal decompose into sub-goals, and a concrete instance of its decomposition into sub-goals. A user teaches the system via curriculum building, by identifying a challenging yet not impossible goal along with linguistic hints on how this goal may
    
[^58]: 语言模型作为零-shot轨迹生成器

    Language Models as Zero-Shot Trajectory Generators. (arXiv:2310.11604v1 [cs.RO])

    [http://arxiv.org/abs/2310.11604](http://arxiv.org/abs/2310.11604)

    本文研究了使用大型语言模型（LLMs）作为零-shot轨迹生成器的可能性。通过给予LLM物体检测和分割视觉模型的访问权限，研究人员发现LLMs能够直接预测操作技能中的末端执行器姿态序列，并在26个真实世界的语言任务中取得了良好效果。这一研究突破了对LLMs在机器人技术中的限制，揭示了LLMs确实具有对操作任务的理解能力。

    

    近期研究表明，大型语言模型（LLMs）在给予低级技能选择时能够作为机器人的高级规划器。然而，通常认为LLMs不具备足够的知识来用于低级轨迹生成。在本研究中，我们详细探讨了这种假设，并调查了当给予LLM（GPT-4）仅能访问物体检测和分割视觉模型时，它能否直接预测一系列密集的末端执行器姿态用于操作技能。我们研究了一个单一的任务不可知提示，没有任何上下文示例、运动原语或外部轨迹优化器，它在26个真实世界的基于语言的任务中的表现，如“打开瓶盖”和“用海绵擦拭盘子”，以及我们调查了这个提示中哪些设计选择最有效。我们的结论突破了对LLMs在机器人技术上的限制，并首次揭示了LLMs确实具有对操作任务的理解能力。

    Large Language Models (LLMs) have recently shown promise as high-level planners for robots when given access to a selection of low-level skills. However, it is often assumed that LLMs do not possess sufficient knowledge to be used for the low-level trajectories themselves. In this work, we address this assumption thoroughly, and investigate if an LLM (GPT-4) can directly predict a dense sequence of end-effector poses for manipulation skills, when given access to only object detection and segmentation vision models. We study how well a single task-agnostic prompt, without any in-context examples, motion primitives, or external trajectory optimisers, can perform across 26 real-world language-based tasks, such as "open the bottle cap" and "wipe the plate with the sponge", and we investigate which design choices in this prompt are the most effective. Our conclusions raise the assumed limit of LLMs for robotics, and we reveal for the first time that LLMs do indeed possess an understanding o
    
[^59]: 基于Transformer的对抗攻击在安全领域中的有效性

    The Efficacy of Transformer-based Adversarial Attacks in Security Domains. (arXiv:2310.11597v1 [cs.CR])

    [http://arxiv.org/abs/2310.11597](http://arxiv.org/abs/2310.11597)

    本文评估了Transformer对于系统防御者和系统攻击者的对抗性样本的鲁棒性和可转移性，为了更好地理解Transformer在网络安全应用中的属性和影响。

    

    如今，许多领域的安全依赖于使用机器学习来检测威胁、识别漏洞并保护系统免受攻击。最近，Transformer架构在恶意软件检测和网络入侵检测等各种任务中改善了最先进的性能。然而，在放弃当前的Transformer方法之前，了解它们对网络安全应用的属性和影响是至关重要的。在本文中，我们评估了Transformer对于系统防御者（即对于在不同类型的架构上生成的对抗性扰动的韧性）和系统攻击者（即将由Transformer生成的对抗样本的可转移性）的对抗样本的鲁棒性。为此，我们首先微调一套预训练的Transformer、卷积神经网络（CNN）和混合（Transformer和CNN的集成）模型来解决不同的问题。

    Today, the security of many domains rely on the use of Machine Learning to detect threats, identify vulnerabilities, and safeguard systems from attacks. Recently, transformer architectures have improved the state-of-the-art performance on a wide range of tasks such as malware detection and network intrusion detection. But, before abandoning current approaches to transformers, it is crucial to understand their properties and implications on cybersecurity applications. In this paper, we evaluate the robustness of transformers to adversarial samples for system defenders (i.e., resiliency to adversarial perturbations generated on different types of architectures) and their adversarial strength for system attackers (i.e., transferability of adversarial samples generated by transformers to other target models). To that effect, we first fine-tune a set of pre-trained transformer, Convolutional Neural Network (CNN), and hybrid (an ensemble of transformer and CNN) models to solve different down
    
[^60]: WaveAttack：基于不对称频率混淆的基于背门的深度神经网络攻击

    WaveAttack: Asymmetric Frequency Obfuscation-based Backdoor Attacks Against Deep Neural Networks. (arXiv:2310.11595v1 [cs.CV])

    [http://arxiv.org/abs/2310.11595](http://arxiv.org/abs/2310.11595)

    本文提出了一种名为WaveAttack的新型基于频率的背门攻击方法，通过离散小波变换获取图像的高频特征来生成背门触发器，并引入了一种不对称的频率混淆方法来改善触发器的影响力，有效提高了背门攻击的成功率并且不易被检测到。

    

    由于人工智能（AI）技术的普及，许多对手设计了背门攻击，通过操纵训练样本和训练过程，误导深度神经网络的预测。虽然背门攻击在各种实际场景中都很有效，但它们仍然存在被现有的背门检测算法轻易检测到的问题，主要表现为毒化样本的低保真性和隐藏空间中的非可忽略转换。为了克服这个弱点，本文提出了一种新颖的基于频率的背门攻击方法，称为WaveAttack，它通过离散小波变换（DWT）获取图像的高频特征来生成背门触发器。此外，我们引入了一种不对称的频率混淆方法，可以在训练和推断阶段添加自适应残差，以提高触发器的影响力，并进一步增强WaveAttack的有效性。综合实验结果表明，WaveAttack不仅提高了背门攻击的成功率并且不易被检测到。

    Due to the popularity of Artificial Intelligence (AI) technology, numerous backdoor attacks are designed by adversaries to mislead deep neural network predictions by manipulating training samples and training processes. Although backdoor attacks are effective in various real scenarios, they still suffer from the problems of both low fidelity of poisoned samples and non-negligible transfer in latent space, which make them easily detectable by existing backdoor detection algorithms. To overcome the weakness, this paper proposes a novel frequency-based backdoor attack method named WaveAttack, which obtains image high-frequency features through Discrete Wavelet Transform (DWT) to generate backdoor triggers. Furthermore, we introduce an asymmetric frequency obfuscation method, which can add an adaptive residual in the training and inference stage to improve the impact of triggers and further enhance the effectiveness of WaveAttack. Comprehensive experimental results show that WaveAttack not
    
[^61]: Adversarial Robustness Unhardening via Backdoor Attacks in Federated Learning. (arXiv:2310.11594v1 [cs.LG])

    Adversarial Robustness Unhardening via Backdoor Attacks in Federated Learning. (arXiv:2310.11594v1 [cs.LG])

    [http://arxiv.org/abs/2310.11594](http://arxiv.org/abs/2310.11594)

    本文研究了联邦学习中对抗性训练和后门攻击的交叉点，引入了Adversarial Robustness Unhardening（ARU），通过有意介入分散式训练过程中破坏模型的鲁棒性，使模型更容易受到更广泛的逃避攻击。

    

    在当今的数据驱动环境中，维护用户隐私和释放数据潜力之间微妙的平衡成为一个重要关注点。联邦学习是一种以隐私为中心的解决方案，它实现了协作模型训练而无需共享数据。这种分散式方法带来了安全挑战，特别是恶意实体注入损坏数据的中毒和后门攻击。我们的研究最初受到测试时间逃避攻击的启发，探讨了联邦学习中对抗性训练和后门攻击的交叉点，引入了Adversarial Robustness Unhardening（ARU）。ARU被一部分对手使用，以有意介入分散式训练过程中破坏模型的鲁棒性，使模型更容易受到更广泛的逃避攻击。我们进行了广泛的实证实验，评估了ARU对对抗性训练和现有的鲁棒聚合防御策略对中毒和后门攻击的影响。

    In today's data-driven landscape, the delicate equilibrium between safeguarding user privacy and unleashing data potential stands as a paramount concern. Federated learning, which enables collaborative model training without necessitating data sharing, has emerged as a privacy-centric solution. This decentralized approach brings forth security challenges, notably poisoning and backdoor attacks where malicious entities inject corrupted data. Our research, initially spurred by test-time evasion attacks, investigates the intersection of adversarial training and backdoor attacks within federated learning, introducing Adversarial Robustness Unhardening (ARU). ARU is employed by a subset of adversaries to intentionally undermine model robustness during decentralized training, rendering models susceptible to a broader range of evasion attacks. We present extensive empirical experiments evaluating ARU's impact on adversarial training and existing robust aggregation defenses against poisoning a
    
[^62]: 使用大型语言模型自动评价个性化文本生成

    Automated Evaluation of Personalized Text Generation using Large Language Models. (arXiv:2310.11593v1 [cs.CL])

    [http://arxiv.org/abs/2310.11593](http://arxiv.org/abs/2310.11593)

    这项研究提出了一种使用大型语言模型自动评价个性化文本生成的方法。传统的自动评价指标无法捕捉个性化质量的微妙差别，而人工判断又昂贵且困难。因此，本研究提出了一种新颖的评估方法，能够自动测量个性化、质量和相关性这三个重要语义方面。

    

    个性化文本生成提供了一种针对用户个人背景交付内容的专门机制。尽管在这个领域的研究进展迅速，但评估仍然是一个挑战。传统的自动评价指标（如BLEU和ROUGE）主要衡量与人工参考文本的词汇相似度，并不能区分个性化与其他微妙的语义方面，因此无法捕捉个性化生成内容质量的细微差别。另一方面，人工判断是昂贵的，特别是在个性化评估领域。受到这些挑战的启发，我们探索了使用大型语言模型（LLMs）来评估个性化文本生成，并检验它们理解细致的用户背景的能力。我们提出了AuPEL，一种新颖的评估方法，将生成文本的个性化、质量和相关性三个主要语义方面提取并自动测量。

    Personalized text generation presents a specialized mechanism for delivering content that is specific to a user's personal context. While the research progress in this area has been rapid, evaluation still presents a challenge. Traditional automated metrics such as BLEU and ROUGE primarily measure lexical similarity to human-written references, and are not able to distinguish personalization from other subtle semantic aspects, thus falling short of capturing the nuances of personalized generated content quality. On the other hand, human judgments are costly to obtain, especially in the realm of personalized evaluation. Inspired by these challenges, we explore the use of large language models (LLMs) for evaluating personalized text generation, and examine their ability to understand nuanced user context. We present AuPEL, a novel evaluation method that distills three major semantic aspects of the generated text: personalization, quality and relevance, and automatically measures these as
    
[^63]: 用语言模型引导获取人类偏好

    Eliciting Human Preferences with Language Models. (arXiv:2310.11589v1 [cs.CL])

    [http://arxiv.org/abs/2310.11589](http://arxiv.org/abs/2310.11589)

    本文介绍了一种生成式主动任务引导（GATE）的学习框架，该框架通过与用户进行自由形式的、基于语言的交互来引导和推断预期行为。在实验中展示，通过GATE引导的语言模型通常比用户编写的提示或标签更具信息量。

    

    语言模型可以通过使用标注示例或自然语言提示来执行目标任务。但是，在选择示例或撰写提示时可能具有挑战性——特别是在涉及异常情况、要求精确表达模糊偏好或需要准确的语言模型行为认知的任务中。我们提出使用*语言模型本身*来引导任务规范的过程。在本文中，我们介绍**生成式主动任务引导（GATE）**：一种学习框架，在其中模型通过与用户进行自由形式的、基于语言的交互来引导并推断预期行为。我们在三个领域研究了GATE：电子邮件验证、内容推荐和道德推理。在预先注册的实验中，我们展示了提示执行GATE的语言模型（例如通过生成开放式问题或合成信息丰富的边界案例）所引发的响应通常比用户编写的提示或标签更具信息量。用户报告称，交互式任务引导的方法能够有效地帮助他们表达偏好和指导模型。

    Language models (LMs) can be directed to perform target tasks by using labeled examples or natural language prompts. But selecting examples or writing prompts for can be challenging--especially in tasks that involve unusual edge cases, demand precise articulation of nebulous preferences, or require an accurate mental model of LM behavior. We propose to use *LMs themselves* to guide the task specification process. In this paper, we introduce **Generative Active Task Elicitation (GATE)**: a learning framework in which models elicit and infer intended behavior through free-form, language-based interaction with users. We study GATE in three domains: email validation, content recommendation, and moral reasoning. In preregistered experiments, we show that LMs prompted to perform GATE (e.g., by generating open-ended questions or synthesizing informative edge cases) elicit responses that are often more informative than user-written prompts or labels. Users report that interactive task elicitat
    
[^64]: 当刚性成为问题：软一致性正则化用于概率分层时间序列预测

    When Rigidity Hurts: Soft Consistency Regularization for Probabilistic Hierarchical Time Series Forecasting. (arXiv:2310.11569v1 [cs.LG])

    [http://arxiv.org/abs/2310.11569](http://arxiv.org/abs/2310.11569)

    提出了一个新的概率分层时间序列预测模型，该模型能够有效建模和预测具有层次化关系的多变量时间序列。相较于现有方法，该模型不仅考虑点预测，还能提供经过良好校准的概率预测分布，并且在建模过程中考虑了预测分布的相关性。

    

    概率分层时间序列预测是时间序列预测的重要变体，其目标是对具有层次化关系的多变量时间序列进行建模和预测。大多数方法关注点预测，并未提供经过良好校准的概率预测分布。最近的概率预测方法也在点预测和分布样本中施加层次关系，但未考虑预测分布的相关性。以往的研究也默认数据集总是与给定的层次关系保持一致，并未适应显示出偏离此假设的真实世界数据集。我们填补了这两个空白，并提出了PROFHiT模型，它是一个完全概率的分层预测模型，同时对整个层次的预测分布进行建模。PROFHiT使用灵活的概率贝叶斯方法，并引入了一种新颖的分布一致性正则化方法。

    Probabilistic hierarchical time-series forecasting is an important variant of time-series forecasting, where the goal is to model and forecast multivariate time-series that have underlying hierarchical relations. Most methods focus on point predictions and do not provide well-calibrated probabilistic forecasts distributions. Recent state-of-art probabilistic forecasting methods also impose hierarchical relations on point predictions and samples of distribution which does not account for coherency of forecast distributions. Previous works also silently assume that datasets are always consistent with given hierarchical relations and do not adapt to real-world datasets that show deviation from this assumption. We close both these gap and propose PROFHiT, which is a fully probabilistic hierarchical forecasting model that jointly models forecast distribution of entire hierarchy. PROFHiT uses a flexible probabilistic Bayesian approach and introduces a novel Distributional Coherency regulariz
    
[^65]: 通过知识图谱整合3D城市数据

    Integrating 3D City Data through Knowledge Graphs. (arXiv:2310.11555v1 [cs.DB])

    [http://arxiv.org/abs/2310.11555](http://arxiv.org/abs/2310.11555)

    通过知识图谱整合3D城市数据，能够利用CityGML的语义和拓扑属性对该数据进行查询，实现各种应用的分析。目前关于查询CityGML数据的潜力尚未充分开发，常见的处理方式是将其存储在3DCityDB系统中，使用SQL查询语言进行操作。然而，终端用户在针对特定任务制定查询时仍然面临一些挑战，因为CityGML的概念语义与关系模式之间存在差距。

    

    CityGML是由开放地理空间联盟（OGC）广泛采用的用于表示和交换3D城市模型的标准。CityGML中语义和拓扑属性的表示使得可以对这些3D城市数据进行查询，用于各种应用的分析，例如安全管理和应急响应、能源消耗和估计以及占用测量。然而，查询CityGML数据的潜力尚未完全开发。CityGML的官方GML/XML编码只是用作交换格式，不适合进行查询回答。处理CityGML数据的最常见方式是将其存储在3DCityDB系统中作为关系表，然后使用标准的SQL查询语言进行查询。然而，对于终端用户来说，直接在3DCityDB上为他们的特定分析任务制定查询仍然是一项具有挑战性的任务，因为CityGML的概念语义与所采用的关系模式之间存在差距。

    CityGML is a widely adopted standard by the Open Geospatial Consortium (OGC) for representing and exchanging 3D city models. The representation of semantic and topological properties in CityGML makes it possible to query such 3D city data to perform analysis in various applications, e.g., security management and emergency response, energy consumption and estimation, and occupancy measurement. However, the potential of querying CityGML data has not been fully exploited. The official GML/XML encoding of CityGML is only intended as an exchange format but is not suitable for query answering. The most common way of dealing with CityGML data is to store them in the 3DCityDB system as relational tables and then query them with the standard SQL query language. Nevertheless, for end users, it remains a challenging task to formulate queries over 3DCityDB directly for their ad-hoc analytical tasks, because there is a gap between the conceptual semantics of CityGML and the relational schema adopte
    
[^66]: 面向带有强对抗损失和强盗反馈的对抗性线性MDPs的最优遗憾

    Towards Optimal Regret in Adversarial Linear MDPs with Bandit Feedback. (arXiv:2310.11550v1 [cs.LG])

    [http://arxiv.org/abs/2310.11550](http://arxiv.org/abs/2310.11550)

    研究带有对抗损失和强盗反馈的线性MDPs问题，提出了两种算法，分别达到了$\widetilde{\mathcal{O}}\left(\sqrt{K}\right)$和$\widetilde{\mathcal{O}}\left(K^{\frac{3}{4}} \right)$的遗憾性能。

    

    我们研究了在线强化学习中的线性马尔可夫决策过程，并考虑了对抗性损失和强盗反馈，没有事先了解转换或访问模拟器的先验知识。我们引入了两种算法，相较于现有方法，它们都能取得更好的遗憾性能。第一种算法虽然计算效率低，但能保证$\widetilde{\mathcal{O}}\left(\sqrt{K}\right)$的遗憾性能，其中$K$是回合数。这是该设置下第一个具有最佳$K$依赖性的结果。第二种算法基于策略优化框架，能保证$\widetilde{\mathcal{O}}\left(K^{\frac{3}{4}} \right)$的遗憾性能，并且计算效率高。我们的两个结果都显著改善了现有最先进方法：Kong等人[2023]的计算效率低的算法，其遗憾性能为$\widetilde{\mathcal{O}}\left(K^{\frac{4}{5}}+poly\left(\frac{1}{\lambda_{\min}}\right) \right)$，其中$\lambda_{\min}$是问题相关常数。

    We study online reinforcement learning in linear Markov decision processes with adversarial losses and bandit feedback, without prior knowledge on transitions or access to simulators. We introduce two algorithms that achieve improved regret performance compared to existing approaches. The first algorithm, although computationally inefficient, ensures a regret of $\widetilde{\mathcal{O}}\left(\sqrt{K}\right)$, where $K$ is the number of episodes. This is the first result with the optimal $K$ dependence in the considered setting. The second algorithm, which is based on the policy optimization framework, guarantees a regret of $\widetilde{\mathcal{O}}\left(K^{\frac{3}{4}} \right)$ and is computationally efficient. Both our results significantly improve over the state-of-the-art: a computationally inefficient algorithm by Kong et al. [2023] with $\widetilde{\mathcal{O}}\left(K^{\frac{4}{5}}+poly\left(\frac{1}{\lambda_{\min}}\right) \right)$ regret, for some problem-dependent constant $\lam
    
[^67]: MUST&P-SRL: 多语言和统一音节标记的文本和音韵领域中的语音表示学习

    MUST&P-SRL: Multi-lingual and Unified Syllabification in Text and Phonetic Domains for Speech Representation Learning. (arXiv:2310.11541v1 [cs.CL])

    [http://arxiv.org/abs/2310.11541](http://arxiv.org/abs/2310.11541)

    本文提出了一种多语言和统一音节标记的文本和音韵领域中的语音表示学习方法，通过自动音节化单词并生成宝贵注释，适用于语音表示学习、语音单元发现和语音因素解缠。

    

    在本文中，我们提出了一种语言特征提取的方法，特别关注多种语言中自动音节化单词，并设计与强制对齐工具Montreal Forced Aligner（MFA）兼容。在文本和音韵领域中，我们的方法专注于从文本中提取音标转录、重音标记和统一的自动音节化。该系统采用了开源组件和资源构建。通过消融研究，我们证明了我们的方法在自动音节化多种语言（英语、法语和西班牙语）的单词方面的有效性。此外，我们将该技术应用于CMU ARCTIC数据集的转录中，生成了有助于语音表示学习、语音单元发现和语音因素解缠的宝贵注释，在线可用。

    In this paper, we present a methodology for linguistic feature extraction, focusing particularly on automatically syllabifying words in multiple languages, with a design to be compatible with a forced-alignment tool, the Montreal Forced Aligner (MFA). In both the textual and phonetic domains, our method focuses on the extraction of phonetic transcriptions from text, stress marks, and a unified automatic syllabification (in text and phonetic domains). The system was built with open-source components and resources. Through an ablation study, we demonstrate the efficacy of our approach in automatically syllabifying words from several languages (English, French and Spanish). Additionally, we apply the technique to the transcriptions of the CMU ARCTIC dataset, generating valuable annotations available online\footnote{\url{https://github.com/noetits/MUST_P-SRL}} that are ideal for speech representation learning, speech unit discovery, and disentanglement of speech factors in several speech-r
    
[^68]: 在无限时域的马尔可夫决策过程中，利用离线数据集进行高效在线学习：一种贝叶斯方法

    Efficient Online Learning with Offline Datasets for Infinite Horizon MDPs: A Bayesian Approach. (arXiv:2310.11531v1 [cs.LG])

    [http://arxiv.org/abs/2310.11531](http://arxiv.org/abs/2310.11531)

    本文研究了在存在离线数据集的情况下，如何在无限时域进行高效的在线学习。研究表明，学习代理模拟专家的行为策略能够显著减小累积遗憾。通过贝叶斯方法进行的先验相关遗憾分析提供了算法的性能上界，并提出了一种近似的模仿学习算法来结合离线数据集和在线学习。

    

    本文研究了当存在一个离线数据集时，如何在无限时域设置下进行高效的在线强化学习问题。我们假设离线数据集是由一个专家生成的，但其能力水平未知，即它不是完美的，也不一定使用最优策略。我们展示了如果学习代理模拟专家使用的行为策略（由能力参数参数化），在累积遗憾最小化方面能取得明显更好的结果。我们建立了一个以 $\tilde{O}(\sqrt{T})$ 为缩放的精确有用PSRL算法遗憾的上界。这需要对贝叶斯在线学习算法在无限时域设置下进行新颖的先验相关遗憾分析。然后，我们提出了一种近似的Informed RLSVI算法，可以理解为使用离线数据集进行模仿学习，然后进行在线学习。

    In this paper, we study the problem of efficient online reinforcement learning in the infinite horizon setting when there is an offline dataset to start with. We assume that the offline dataset is generated by an expert but with unknown level of competence, i.e., it is not perfect and not necessarily using the optimal policy. We show that if the learning agent models the behavioral policy (parameterized by a competence parameter) used by the expert, it can do substantially better in terms of minimizing cumulative regret, than if it doesn't do that. We establish an upper bound on regret of the exact informed PSRL algorithm that scales as $\tilde{O}(\sqrt{T})$. This requires a novel prior-dependent regret analysis of Bayesian online learning algorithms for the infinite horizon setting. We then propose an approximate Informed RLSVI algorithm that we can interpret as performing imitation learning with the offline dataset, and then performing online learning.
    
[^69]: 群体偏好优化：大规模语言模型的少样本对齐

    Group Preference Optimization: Few-Shot Alignment of Large Language Models. (arXiv:2310.11523v1 [cs.LG])

    [http://arxiv.org/abs/2310.11523](http://arxiv.org/abs/2310.11523)

    这项研究介绍了一种名为群体偏好优化（GPO）的对齐框架，可以以少样本的方式将大规模语言模型（LLMs）引导到个别群体的偏好。通过在基本LLM上加入独立的transformer模块来预测群体偏好，并通过元学习进行训练，GPO经过严格评估验证了其有效性。

    

    大规模语言模型（LLMs）的许多应用，从聊天机器人到创意写作，都需要细致入微的主观判断，这些判断在不同群体之间可能存在显著差异。现有的对齐算法在每个群体上对齐的成本很高，对于实际应用场景而言，需要大量的群体特定偏好数据和计算资源。我们引入了群体偏好优化（GPO），这是一个对齐框架，可以以少样本的方式将语言模型引导到个别群体的偏好。在GPO中，我们使用一个独立的transformer模块来扩充基本LLM，用于预测群体对LLM生成内容的偏好。对于少样本学习，我们将这个模块参数化为一个上下文自回归的transformer，并通过元学习在多个群体上进行训练。我们通过严格的评估，使用不同规模的LLM在三个人类意见适应任务上验证了GPO的效果。

    Many applications of large language models (LLMs), ranging from chatbots to creative writing, require nuanced subjective judgments that can differ significantly across different groups. Existing alignment algorithms can be expensive to align for each group, requiring prohibitive amounts of group-specific preference data and computation for real-world use cases. We introduce Group Preference Optimization (GPO), an alignment framework that steers language models to preferences of individual groups in a few-shot manner. In GPO, we augment the base LLM with an independent transformer module trained to predict the preferences of a group for the LLM generations. For few-shot learning, we parameterize this module as an in-context autoregressive transformer and train it via meta-learning on several groups. We empirically validate the efficacy of GPO through rigorous evaluations using LLMs with varied sizes on three human opinion adaptation tasks. These tasks involve adapting to the preferences
    
[^70]: 通过多矩阵可分解性在多人游戏中对自我对抗的保证

    Guarantees for Self-Play in Multiplayer Games via Polymatrix Decomposability. (arXiv:2310.11518v1 [cs.GT])

    [http://arxiv.org/abs/2310.11518](http://arxiv.org/abs/2310.11518)

    这篇论文研究了多人游戏中自我对抗的保证问题，通过多矩阵可分解性，在满足一定条件的情况下，通过自我对抗学习的算法能够产生有界脆弱性的策略。

    

    自我对抗是一种机器学习在多智能体系统中的技术，其中学习算法通过与自身的副本交互来学习。自我对抗对于生成大量的学习数据很有用，但它的缺点是训练后学习者将面对的智能体可能与通过与自身交互时所期望的智能体行为截然不同。对于两人常和游戏的特殊情况，达到纳什均衡的自我对抗能够保证产生对任何训练后对手表现良好的策略；然而，对于多人游戏来说没有这样的保证存在。我们展示了在近似分解为一组两人常和游戏（称为多矩阵游戏）的游戏中，其中全局 $\epsilon$-纳什均衡在每个子游戏中都与纳什均衡有有界距离的情况下，通过自我对抗学习的无外部遗憾算法将产生一个有界脆弱性的策略。我们的结果首次确定了……

    Self-play is a technique for machine learning in multi-agent systems where a learning algorithm learns by interacting with copies of itself. Self-play is useful for generating large quantities of data for learning, but has the drawback that the agents the learner will face post-training may have dramatically different behavior than the learner came to expect by interacting with itself. For the special case of two-player constant-sum games, self-play that reaches Nash equilibrium is guaranteed to produce strategies that perform well against any post-training opponent; however, no such guarantee exists for multi-player games. We show that in games that approximately decompose into a set of two-player constant-sum games (called polymatrix games) where global $\epsilon$-Nash equilibria are boundedly far from Nash-equilibria in each subgame, any no-external-regret algorithm that learns by self-play will produce a strategy with bounded vulnerability. For the first time, our results identify 
    
[^71]: Self-RAG: 通过自我反思学习检索、生成和评论

    Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection. (arXiv:2310.11511v1 [cs.CL])

    [http://arxiv.org/abs/2310.11511](http://arxiv.org/abs/2310.11511)

    Self-RAG是一种通过检索和自我反思提高语言模型质量和事实性的框架。

    

    尽管大型语言模型（LLMs）具有显著的能力，但由于它们完全依赖于它们所包含的参数化知识，因此往往会产生含有事实不准确性的响应。检索增强生成（RAG）是一种通过检索相关知识增强LM的临时方法，可以减少这些问题。然而，不加选择地检索并结合一定数量的检索段落，而不考虑检索是否必要或段落是否相关，会降低LM的多功能性或导致无效的响应生成。我们引入了一种称为Self-Reflective Retrieval-Augmented Generation （Self-RAG）的新框架，通过检索和自我反思提高LM的质量和事实性。我们的框架训练了一个单独的任意LM，它能够根据需求自适应地检索段落，并使用特殊的标记，称为反思标记，生成和反思检索的段落和自身的生成结果。

    Despite their remarkable capabilities, large language models (LLMs) often produce responses containing factual inaccuracies due to their sole reliance on the parametric knowledge they encapsulate. Retrieval-Augmented Generation (RAG), an ad hoc approach that augments LMs with retrieval of relevant knowledge, decreases such issues. However, indiscriminately retrieving and incorporating a fixed number of retrieved passages, regardless of whether retrieval is necessary, or passages are relevant, diminishes LM versatility or can lead to unhelpful response generation. We introduce a new framework called Self-Reflective Retrieval-Augmented Generation (Self-RAG) that enhances an LM's quality and factuality through retrieval and self-reflection. Our framework trains a single arbitrary LM that adaptively retrieves passages on-demand, and generates and reflects on retrieved passages and its own generations using special tokens, called reflection tokens. Generating reflection tokens makes the LM 
    
[^72]: CoMPosT: LLM模拟中的漫画表现特征和评估

    CoMPosT: Characterizing and Evaluating Caricature in LLM Simulations. (arXiv:2310.11501v1 [cs.CL])

    [http://arxiv.org/abs/2310.11501](http://arxiv.org/abs/2310.11501)

    利用CoMPosT框架，我们提出了一种对LLM模拟进行特征化的方法，评估其是否存在夸张刻板化，并发现在某些情况下存在夸张刻板化的现象。

    

    最近的研究致力于使用语言模型(LLMs)模拟特定人口群体在社会科学实验和舆论调查等情境中的反应，以捕捉人类行为的细微差别。然而，目前还没有确定的方法来讨论或评估这种LLM模拟的质量。此外，人们越来越担心这些LLM模拟是对他们所模拟的人物进行夸张刻板化的表现，未能捕捉到人的多维性并延续了刻板印象。为了弥补这些差距，我们提出了CoMPosT框架，用四个维度来描述LLM模拟：语境、模型、角色和主题。我们使用这个框架来衡量开放式LLM模拟对夸张刻板化的敏感性，通过两个标准来定义：个性化和夸张。我们评估了现有LLM模拟工作中的场景中夸张刻板化的程度。我们发现对于GPT-4，特定群体（政治和边缘群体）和

    Recent work has aimed to capture nuances of human behavior by using LLMs to simulate responses from particular demographics in settings like social science experiments and public opinion surveys. However, there are currently no established ways to discuss or evaluate the quality of such LLM simulations. Moreover, there is growing concern that these LLM simulations are flattened caricatures of the personas that they aim to simulate, failing to capture the multidimensionality of people and perpetuating stereotypes. To bridge these gaps, we present CoMPosT, a framework to characterize LLM simulations using four dimensions: Context, Model, Persona, and Topic. We use this framework to measure open-ended LLM simulations' susceptibility to caricature, defined via two criteria: individuation and exaggeration. We evaluate the level of caricature in scenarios from existing work on LLM simulations. We find that for GPT-4, simulations of certain demographics (political and marginalized groups) and
    
[^73]: 儿童阅读实时跟踪的端到端指针网络研究

    End-to-End real time tracking of children's reading with pointer network. (arXiv:2310.11486v1 [eess.AS])

    [http://arxiv.org/abs/2310.11486](http://arxiv.org/abs/2310.11486)

    本研究提出了一种用于儿童阅读的实时跟踪器模型，在语音跟踪的延迟方面具有较低的敏感性。通过使用指针网络和强制对齐生成训练信号，我们的模型可以准确地跟踪成人语音，并在儿童语音数据集上获得良好的效果。

    

    本研究探讨了如何高效地构建一个用于儿童语音的实时阅读跟踪器。之前提出的阅读跟踪器主要基于ASR的级联方法，我们提出了一个完全端到端的模型，使其对语音跟踪的延迟更少。我们采用指针网络，直接学习在流式语音中预测与真实文本位置对应的能力。为了训练这个指针网络，我们使用强制对齐在训练集上生成真实的训练信号，从而对读出的语音和被读文本进行对齐。在探索不同的强制对齐模型时，我们发现基于神经注意力的模型在对齐准确性上至少与蒙特利尔强制对齐器相当，但令人惊讶的是，它更适合用作指针网络的训练信号。我们的结果报告了一个成人语音数据集(TIMIT)和两个儿童语音数据集(CMU Kids和Reading Races)。我们的最佳模型能够以87.8%的准确率跟踪成人语音。

    In this work, we explore how a real time reading tracker can be built efficiently for children's voices. While previously proposed reading trackers focused on ASR-based cascaded approaches, we propose a fully end-to-end model making it less prone to lags in voice tracking. We employ a pointer network that directly learns to predict positions in the ground truth text conditioned on the streaming speech. To train this pointer network, we generate ground truth training signals by using forced alignment between the read speech and the text being read on the training set. Exploring different forced alignment models, we find a neural attention based model is at least as close in alignment accuracy to the Montreal Forced Aligner, but surprisingly is a better training signal for the pointer network. Our results are reported on one adult speech data (TIMIT) and two children's speech datasets (CMU Kids and Reading Races). Our best model can accurately track adult speech with 87.8% accuracy and t
    
[^74]: 在大型预训练模型时代重新思考增量学习的测试时适应方法

    Rethinking Class-incremental Learning in the Era of Large Pre-trained Models via Test-Time Adaptation. (arXiv:2310.11482v1 [cs.CV])

    [http://arxiv.org/abs/2310.11482](http://arxiv.org/abs/2310.11482)

    本研究提出了一种名为“增量学习的测试时适应”的方法，通过在测试实例上进行微调，避免了在每个新任务上进行训练，从而在增量学习中实现了预训练模型的稳定性和可塑性的平衡。

    

    增量学习是一个具有挑战性的任务，涉及持续学习将类别划分到新任务中，同时不会遗忘先前学到的信息。大型预训练模型的出现加快了增量学习的进展，因为高度可传输的预训练模型表示使得在调整一小组参数时，与从头开始训练的传统增量学习方法相比，可以获得最先进的性能。然而，对每个任务进行反复微调会破坏预训练模型的丰富表示，并导致遗忘之前的任务。为了在增量学习中在预训练模型的稳定性和可塑性之间取得平衡，我们提出了一种新颖的方法，即通过直接在测试实例上进行测试时适应。具体而言，我们提出了“增量学习的测试时适应”（TTACIL），它首先在每个测试实例上对预训练模型的层归一化参数进行微调。

    Class-incremental learning (CIL) is a challenging task that involves continually learning to categorize classes into new tasks without forgetting previously learned information. The advent of the large pre-trained models (PTMs) has fast-tracked the progress in CIL due to the highly transferable PTM representations, where tuning a small set of parameters results in state-of-the-art performance when compared with the traditional CIL methods that are trained from scratch. However, repeated fine-tuning on each task destroys the rich representations of the PTMs and further leads to forgetting previous tasks. To strike a balance between the stability and plasticity of PTMs for CIL, we propose a novel perspective of eliminating training on every new task and instead performing test-time adaptation (TTA) directly on the test instances. Concretely, we propose "Test-Time Adaptation for Class-Incremental Learning" (TTACIL) that first fine-tunes Layer Norm parameters of the PTM on each test instan
    
[^75]: 用吸收自动机扩展的合同Tsetlin机器

    Contracting Tsetlin Machine with Absorbing Automata. (arXiv:2310.11481v1 [cs.FL])

    [http://arxiv.org/abs/2310.11481](http://arxiv.org/abs/2310.11481)

    本文介绍了一种合同Tsetlin机器（TM）与吸收自动机（TA）状态的稀疏扩展，通过引入吸收性的排除和包含状态，加速学习过程并减少能量消耗。

    

    在本文中，我们介绍了一种具有吸收Tsetlin自动机（TA）状态的稀疏Tsetlin机器（TM）。简单来说，每个条款文字的TA具有吸收性的排除（Exclude）状态和吸收性的包含（Include）状态，使得学习方案具有吸收性而不是遍历性。当TA达到一个吸收状态时，它将永远不会再离开该状态。如果吸收状态是排除状态，自动机和文字都可以从进一步考虑中删除。作为结果，该文字在该条款中将永远不会参与。另一方面，如果吸收状态是包含状态，该文字将作为条款的永久部分存储，而TA将被丢弃。一种新的稀疏数据结构通过三个动作列表来支持这些更新：吸收的包含（Absorbed Include）、包含（Include）和排除（Exclude）。通过更新这些列表，TM随着文字及其TA的撤回变得越来越小。通过这种方式，学习过程加速，导致更快的学习和更少的能量消耗。

    In this paper, we introduce a sparse Tsetlin Machine (TM) with absorbing Tsetlin Automata (TA) states. In brief, the TA of each clause literal has both an absorbing Exclude- and an absorbing Include state, making the learning scheme absorbing instead of ergodic. When a TA reaches an absorbing state, it will never leave that state again. If the absorbing state is an Exclude state, both the automaton and the literal can be removed from further consideration. The literal will as a result never participates in that clause. If the absorbing state is an Include state, on the other hand, the literal is stored as a permanent part of the clause while the TA is discarded. A novel sparse data structure supports these updates by means of three action lists: Absorbed Include, Include, and Exclude. By updating these lists, the TM gets smaller and smaller as the literals and their TA withdraw. In this manner, the computation accelerates during learning, leading to faster learning and less energy cons
    
[^76]: ASP: 用于高效AutoML的自动选择代理数据集

    ASP: Automatic Selection of Proxy dataset for efficient AutoML. (arXiv:2310.11478v1 [cs.LG])

    [http://arxiv.org/abs/2310.11478](http://arxiv.org/abs/2310.11478)

    本文提出了一个自动选择代理数据集框架 (ASP)，通过动态地找到信息丰富的代理子集来减小训练数据大小并节省AutoML处理时间，实验证明ASP在不同基准测试上获得了优于其他方法的结果。

    

    由于数据量的增加和多样有效的神经网络设计, 深度神经网络取得了巨大的成功。然而, 这也给计算带来了沉重的负担, 因为训练数据量与训练时间成正比。此外, 一个良好的模型需要重复尝试不同的结构设计和超参数, 即使使用了最先进的超参数优化算法和神经架构搜索算法, 这可能也需要大量的时间。本文提出了一个自动选择代理数据集框架 (ASP), 旨在在每个epoch动态地找到信息丰富的代理子集, 减小训练数据大小并节省AutoML处理时间。我们在CIFAR10、CIFAR100、ImageNet16-120和ImageNet-1k上验证了ASP的有效性和泛化性能, 通过对不同公共模型基准的实验结果表明ASP可以获得比其他方法更好的结果。

    Deep neural networks have gained great success due to the increasing amounts of data, and diverse effective neural network designs. However, it also brings a heavy computing burden as the amount of training data is proportional to the training time. In addition, a well-behaved model requires repeated trials of different structure designs and hyper-parameters, which may take a large amount of time even with state-of-the-art (SOTA) hyper-parameter optimization (HPO) algorithms and neural architecture search (NAS) algorithms. In this paper, we propose an Automatic Selection of Proxy dataset framework (ASP) aimed to dynamically find the informative proxy subsets of training data at each epoch, reducing the training data size as well as saving the AutoML processing time. We verify the effectiveness and generalization of ASP on CIFAR10, CIFAR100, ImageNet16-120, and ImageNet-1k, across various public model benchmarks. The experiment results show that ASP can obtain better results than other 
    
[^77]: Robust-MBFD：使用多个深度学习训练策略和一种新的双损失函数进行电机轴承故障检测的稳健深度学习系统

    Robust-MBFD: A Robust Deep Learning System for Motor Bearing Faults Detection Using Multiple Deep Learning Training Strategies and A Novel Double Loss Function. (arXiv:2310.11477v1 [cs.LG])

    [http://arxiv.org/abs/2310.11477](http://arxiv.org/abs/2310.11477)

    本文提出了一种稳健的深度学习系统用于电机轴承故障检测，采用多个深度学习训练策略和一种新的双损失函数。通过对比评估不同系统并寻找最佳模型，我们展示了该系统对各种电机轴承故障的有效性。

    

    本文提出了对电机轴承故障检测（MBFD）进行全面分析的方法，该方法基于振动信号识别电机轴承的故障。首先，我们提出并评估了多种基于机器学习的MBFD系统。此外，我们还提出了三种基于深度学习的MBFD系统，分别探索了监督学习、半监督学习和无监督学习这三种训练策略。对提出的机器学习系统和深度学习系统进行了评估和比较，并找出了适用于MBFD任务的最佳模型。我们在包括美国机械故障预防技术协会（MFPT）、凯斯西储大学轴承中心（CWRU）和帕德博恩大学的电机驱动系统轴承损伤状态监测等不同基准数据集上进行了大量实验。

    This paper presents a comprehensive analysis of motor bearing fault detection (MBFD), which involves the task of identifying faults in a motor bearing based on its vibration. To this end, we first propose and evaluate various machine learning based systems for the MBFD task. Furthermore, we propose three deep learning based systems for the MBFD task, each of which explores one of the following training strategies: supervised learning, semi-supervised learning, and unsupervised learning. The proposed machine learning based systems and deep learning based systems are evaluated, compared, and then they are used to identify the best model for the MBFD task. We conducted extensive experiments on various benchmark datasets of motor bearing faults, including those from the American Society for Mechanical Failure Prevention Technology (MFPT), Case Western Reserve University Bearing Center (CWRU), and the Condition Monitoring of Bearing Damage in Electromechanical Drive Systems from Paderborn U
    
[^78]: 经典机器学习方法

    Classic machine learning methods. (arXiv:2310.11470v1 [cs.LG])

    [http://arxiv.org/abs/2310.11470](http://arxiv.org/abs/2310.11470)

    本章主要介绍了经典机器学习方法，包括监督学习和无监督学习。其中介绍了分类和回归的各种方法，以及解决过拟合问题的策略。

    

    在这一章中，我们介绍了主要的经典机器学习方法。本章的大部分内容都用于介绍用于分类和回归的监督学习技术，包括最近邻方法、线性回归和逻辑回归、支持向量机和基于树的算法。我们还描述了过拟合问题以及克服过拟合的策略。最后，我们简要概述了无监督学习方法，即用于聚类和降维的方法。

    In this chapter, we present the main classic machine learning methods. A large part of the chapter is devoted to supervised learning techniques for classification and regression, including nearest-neighbor methods, linear and logistic regressions, support vector machines and tree-based algorithms. We also describe the problem of overfitting as well as strategies to overcome it. We finally provide a brief overview of unsupervised learning methods, namely for clustering and dimensionality reduction.
    
[^79]: 提升二进制代码注释质量分类：整合生成式人工智能以提高准确性

    Enhancing Binary Code Comment Quality Classification: Integrating Generative AI for Improved Accuracy. (arXiv:2310.11467v1 [cs.SE])

    [http://arxiv.org/abs/2310.11467](http://arxiv.org/abs/2310.11467)

    本报告通过整合生成的代码和注释对，改进二进制代码注释质量分类模型，提高准确性。

    

    本报告旨在通过整合生成的代码和注释对，改进二进制代码注释质量分类模型，以提高模型的准确性。数据集包括9048对用C语言编写的代码和注释，每对都被注释为“有用”或“无用”。此外，使用大型语言模型架构生成代码和注释对，并对这些生成的对进行标记以指示其实用性。此项工作的成果包括两个分类模型：一个利用原始数据集，另一个利用新生成的代码注释对和标记的扩充数据集。

    This report focuses on enhancing a binary code comment quality classification model by integrating generated code and comment pairs, to improve model accuracy. The dataset comprises 9048 pairs of code and comments written in the C programming language, each annotated as "Useful" or "Not Useful." Additionally, code and comment pairs are generated using a Large Language Model Architecture, and these generated pairs are labeled to indicate their utility. The outcome of this effort consists of two classification models: one utilizing the original dataset and another incorporating the augmented dataset with the newly generated code comment pairs and labels.
    
[^80]: 蛋白质三维图结构学习用于稳健的基于结构的蛋白质性质预测

    Protein 3D Graph Structure Learning for Robust Structure-based Protein Property Prediction. (arXiv:2310.11466v1 [cs.LG])

    [http://arxiv.org/abs/2310.11466](http://arxiv.org/abs/2310.11466)

    本文研究了蛋白质基于结构的性质预测中使用预测结构时性能下降的原因，并将其归因为结构嵌入偏差。

    

    蛋白质基于结构的性质预测已经成为各种生物学任务（如蛋白质功能预测和亚细胞定位估计）的一种有希望的方法。现有方法高度依赖实验蛋白质结构数据，在这些数据不可用的情况下失败。利用人工智能工具（如AlphaFold2）预测的蛋白质结构作为替代方案。然而，我们观察到目前的做法，即在推理过程中仅使用准确预测的结构，会导致预测准确性明显下降。虽然类似现象已经在一般领域（如计算机视觉）中进行了广泛研究作为模型的稳健性，但它们对蛋白质性质预测的影响尚未被探索。在本文中，我们首先从结构表示学习的角度研究了在利用预测的结构时性能下降的原因，将其归因为结构嵌入偏差。为了研究这个问题

    Protein structure-based property prediction has emerged as a promising approach for various biological tasks, such as protein function prediction and sub-cellular location estimation. The existing methods highly rely on experimental protein structure data and fail in scenarios where these data are unavailable. Predicted protein structures from AI tools (e.g., AlphaFold2) were utilized as alternatives. However, we observed that current practices, which simply employ accurately predicted structures during inference, suffer from notable degradation in prediction accuracy. While similar phenomena have been extensively studied in general fields (e.g., Computer Vision) as model robustness, their impact on protein property prediction remains unexplored. In this paper, we first investigate the reason behind the performance decrease when utilizing predicted structures, attributing it to the structure embedding bias from the perspective of structure representation learning. To study this problem
    
[^81]: BaitBuster-Bangla:一个包含多特征和多模态分析的用于孟加拉语Clickbait检测的综合数据集

    BaitBuster-Bangla: A Comprehensive Dataset for Clickbait Detection in Bangla with Multi-Feature and Multi-Modal Analysis. (arXiv:2310.11465v1 [cs.LG])

    [http://arxiv.org/abs/2310.11465](http://arxiv.org/abs/2310.11465)

    本研究提出了一个大规模的孟加拉语YouTube clickbait多模态数据集，为研究人员提供了在低资源语言中建模clickbait现象的重要价值，并且可以开发出更复杂的跨语言检测方法。

    

    本研究提出了一个大规模的孟加拉语YouTube clickbait多模态数据集，通过使用YouTube API和Python网络自动化框架自动收集了253,070个数据点。该数据集包含了来自58个孟加拉语YouTube频道的单个视频的18个不同的特征，这些特征分类为元数据、主要内容、参与统计和标签。对这些特征进行了严格的预处理，去噪声、去重复和去偏差，确保了无偏倚和可靠的分析。作为迄今为止最大且最强大的孟加拉语clickbait语料库，该数据集对于自然语言处理和数据科学研究人员来说具有重要价值，他们希望在低资源语言中推进clickbait现象的建模。它的多模态性质使得可以对clickbait进行全面的分析，涵盖内容、用户交互和语言维度，以开发具有跨语言应用的更复杂的检测方法。

    This study presents a large multi-modal Bangla YouTube clickbait dataset consisting of 253,070 data points collected through an automated process using the YouTube API and Python web automation frameworks. The dataset contains 18 diverse features categorized into metadata, primary content, engagement statistics, and labels for individual videos from 58 Bangla YouTube channels. A rigorous preprocessing step has been applied to denoise, deduplicate, and remove bias from the features, ensuring unbiased and reliable analysis. As the largest and most robust clickbait corpus in Bangla to date, this dataset provides significant value for natural language processing and data science researchers seeking to advance modeling of clickbait phenomena in low-resource languages. Its multi-modal nature allows for comprehensive analyses of clickbait across content, user interactions, and linguistic dimensions to develop more sophisticated detection methods with cross-linguistic applications.
    
[^82]: GPT-4作为研究人员和计算软件之间的接口：提高可用性和可重复性

    GPT-4 as an interface between researchers and computational software: improving usability and reproducibility. (arXiv:2310.11458v1 [cond-mat.mtrl-sci])

    [http://arxiv.org/abs/2310.11458](http://arxiv.org/abs/2310.11458)

    GPT-4作为研究人员和计算软件之间接口的能力提高了科学软件的可用性和结果的可重复性。

    

    大型语言模型(LLMs)在科学和工程中发挥着越来越重要的作用。例如，它们解析和理解人类和计算机语言的能力使它们成为强大的解释器，并且它们在代码生成等应用中的使用被充分记录。我们探讨了GPT-4 LLM在计算材料科学中改善两个主要挑战的能力：i) 与使用自定义输入语言相关的科学软件采用的高门槛，以及ii) 由于对模拟方法的描述细节不足而导致的已发表结果的可重复性差。我们关注一个广泛使用的分子动力学模拟软件——大规模原子/分子并行模拟器(LAMMPS)，并量化GPT-4从英文任务描述生成的输入文件的实用性以及从输入文件生成计算任务的详细描述的能力。我们发现GPT-4可以生成正确的…

    Large language models (LLMs) are playing an increasingly important role in science and engineering. For example, their ability to parse and understand human and computer languages makes them powerful interpreters and their use in applications like code generation are well-documented. We explore the ability of the GPT-4 LLM to ameliorate two major challenges in computational materials science: i) the high barriers for adoption of scientific software associated with the use of custom input languages, and ii) the poor reproducibility of published results due to insufficient details in the description of simulation methods. We focus on a widely used software for molecular dynamics simulations, the Large-scale Atomic/Molecular Massively Parallel Simulator (LAMMPS), and quantify the usefulness of input files generated by GPT-4 from task descriptions in English and its ability to generate detailed descriptions of computational tasks from input files. We find that GPT-4 can generate correct an
    
[^83]: 理解算法公平性中的公平性代理函数

    Understanding Fairness Surrogate Functions in Algorithmic Fairness. (arXiv:2310.11211v1 [cs.LG])

    [http://arxiv.org/abs/2310.11211](http://arxiv.org/abs/2310.11211)

    本文研究了算法公平性中的公平性代理函数，并发现了代理和公平性定义之间存在一个差距。这个差距决定了一个代理函数能否适当替代一个公平性定义。

    

    已观察到机器学习算法对某些人群产生偏见的预测。为了减轻这种偏见并实现可比的准确性，一种有希望的方法是引入涉及公平性定义的代理函数，并解决一个受限制的优化问题。然而，在以往的研究中，一个有趣的问题是这种公平性代理函数可能导致不公平的结果。在本研究中，为了深入理解这个问题，我们以广泛使用的公平性定义——人口统计平等——为例，从理论和实证上证明了公平性定义和公平性代理函数之间存在一个代理-公平性差距。这个"差距"直接决定了一个代理函数是否适合替代一个公平性定义。此外，关于这个"差距"的理论分析和实验结果激发了我们的兴趣，表明无限制的代理函数将受到决策边界远离的点的影响。

    It has been observed that machine learning algorithms exhibit biased predictions against certain population groups. To mitigate such bias while achieving comparable accuracy, a promising approach is to introduce surrogate functions of the concerned fairness definition and solve a constrained optimization problem. However, an intriguing issue in previous work is that such fairness surrogate functions may yield unfair results. In this work, in order to deeply understand this issue, taking a widely used fairness definition, demographic parity as an example, we both theoretically and empirically show that there is a surrogate-fairness gap between the fairness definition and the fairness surrogate function. The "gap" directly determines whether a surrogate function is an appropriate substitute for a fairness definition. Also, the theoretical analysis and experimental results about the "gap" motivate us that the unbounded surrogate functions will be affected by the points far from the decisi
    
[^84]: 从神经网络增强的流体流动测量中揭示壁剪切应力动力学

    Uncovering wall-shear stress dynamics from neural-network enhanced fluid flow measurements. (arXiv:2310.11147v1 [physics.flu-dyn])

    [http://arxiv.org/abs/2310.11147](http://arxiv.org/abs/2310.11147)

    本文提出了一种从流动测量中推导出具有令人印象深刻的空间和时间分辨率的速度和壁剪切应力场的方法，该方法利用了深度光流估计器的物理知识。这对于准确预测壁剪切应力，并在交通运输、能源技术和医疗治疗等领域具有重要意义。

    

    来自流体在物体附近或内部移动的湍流的摩擦阻力在交通运输、公用事业基础设施、能源技术和人类健康等领域起着关键作用。作为剪切引起的摩擦力的直接测量，准确预测壁剪切应力可以促进民航的可持续发展、资源保护和碳中和，以及改进血管疾病和癌症的医疗治疗。尽管对现代社会如此重要，我们仍然缺乏足够的实验方法来捕捉瞬时壁剪切应力动力学。在这篇论文中，我们提出了一种整体方法，使用具有物理知识的深度光流估计器从流动测量中推导出具有令人印象深刻的空间和时间分辨率的速度和壁剪切应力场。使用合成和真实世界的实验数据证明了所推导流动量的有效性和物理正确性。

    Friction drag from a turbulent fluid moving past or inside an object plays a crucial role in domains as diverse as transportation, public utility infrastructure, energy technology, and human health. As a direct measure of the shear-induced friction forces, an accurate prediction of the wall-shear stress can contribute to sustainability, conservation of resources, and carbon neutrality in civil aviation as well as enhanced medical treatment of vascular diseases and cancer. Despite such importance for our modern society, we still lack adequate experimental methods to capture the instantaneous wall-shear stress dynamics. In this contribution, we present a holistic approach that derives velocity and wall-shear stress fields with impressive spatial and temporal resolution from flow measurements using a deep optical flow estimator with physical knowledge. The validity and physical correctness of the derived flow quantities is demonstrated with synthetic and real-world experimental data cover
    
[^85]: HGCVAE: 将生成式学习和对比学习整合为一体的异构图学习方法

    HGCVAE: Integrating Generative and Contrastive Learning for Heterogeneous Graph Learning. (arXiv:2310.11102v1 [cs.LG])

    [http://arxiv.org/abs/2310.11102](http://arxiv.org/abs/2310.11102)

    HGCVAE是一种将生成式学习和对比学习整合为一体的异构图学习方法，通过利用生成式的自监督学习能力来解决异构图学习的挑战。

    

    生成式自监督学习（SSL）在图学习中展示了巨大的潜力和越来越多的关注。本研究旨在探索生成式SSL在异构图学习（HGL）中的问题。以往关于异构图的SSL方法主要依赖对比学习，需要设计复杂的视图来捕捉异质性。然而，现有的生成式SSL方法并未充分利用生成模型的能力来解决HGL的挑战。在本文中，我们提出了HGCVAE，一种新颖的对比变分图自编码器，使HGL摆脱了复杂异质性的负担。HGCVAE不再专注于复杂的异质性，而是充分利用了生成式SSL的潜力。HGCVAE创新地将对比学习与生成式SSL相结合，引入了几个关键创新。首先，我们采用渐进机制生成高质量的hard样本，

    Generative self-supervised learning (SSL) has exhibited significant potential and garnered increasing interest in graph learning. In this study, we aim to explore the problem of generative SSL in the context of heterogeneous graph learning (HGL). The previous SSL approaches for heterogeneous graphs have primarily relied on contrastive learning, necessitating the design of complex views to capture heterogeneity. However, existing generative SSL methods have not fully leveraged the capabilities of generative models to address the challenges of HGL. In this paper, we present HGCVAE, a novel contrastive variational graph auto-encoder that liberates HGL from the burden of intricate heterogeneity capturing. Instead of focusing on complicated heterogeneity, HGCVAE harnesses the full potential of generative SSL. HGCVAE innovatively consolidates contrastive learning with generative SSL, introducing several key innovations. Firstly, we employ a progressive mechanism to generate high-quality hard
    
[^86]: 核心构建模块：下一代地理空间GPT应用

    Core Building Blocks: Next Gen Geo Spatial GPT Application. (arXiv:2310.11029v1 [cs.AI])

    [http://arxiv.org/abs/2310.11029](http://arxiv.org/abs/2310.11029)

    本研究提出了一种名为MapGPT的新方法，将语言模型和空间数据处理技术相结合，在自然语言理解和空间数据分析之间建立桥梁。MapGPT能够对基于位置的查询进行更精确和上下文感知的响应，通过构建基于地理空间的GPT应用的核心模块，实现了在空间和文本数据上生成向量表示，并探索了计算能力的潜力。

    

    本文提出了一种名为MapGPT的新方法，它将语言模型，特别是大型语言模型（LLMs）的能力与空间数据处理技术相结合。MapGPT旨在通过强调相关的核心构建模块，弥合自然语言理解和空间数据分析之间的差距。通过结合LLMs和地理空间分析的优势，MapGPT能够对基于位置的查询进行更精确和上下文感知的响应。所提出的方法强调在空间和文本数据上构建LLMs，利用特定于空间信息的标记化和向量表示。本文还探讨了生成空间向量表示所面临的挑战。此外，研究还讨论了MapGPT内的计算能力的潜力，使用户能够执行地理空间计算并获得可视化输出。总体而言，本研究论文介绍了构建基于地理空间的GPT应用所需要的核心模块的方法和挑战。

    This paper proposes MapGPT which is a novel approach that integrates the capabilities of language models, specifically large language models (LLMs), with spatial data processing techniques. This paper introduces MapGPT, which aims to bridge the gap between natural language understanding and spatial data analysis by highlighting the relevant core building blocks. By combining the strengths of LLMs and geospatial analysis, MapGPT enables more accurate and contextually aware responses to location-based queries. The proposed methodology highlights building LLMs on spatial and textual data, utilizing tokenization and vector representations specific to spatial information. The paper also explores the challenges associated with generating spatial vector representations. Furthermore, the study discusses the potential of computational capabilities within MapGPT, allowing users to perform geospatial computations and obtain visualized outputs. Overall, this research paper presents the building bl
    
[^87]: 从统计学角度揭开中毒后门攻击的神秘面纱

    Demystifying Poisoning Backdoor Attacks from a Statistical Perspective. (arXiv:2310.10780v1 [cs.CR])

    [http://arxiv.org/abs/2310.10780](http://arxiv.org/abs/2310.10780)

    从统计学角度揭开中毒后门攻击的神秘面纱，通过评估任何包含恒定触发器的后门攻击的有效性，确定了后门攻击成功的决定因素、最有效的攻击方向以及几乎不可察觉的人类触发器何时会成功。

    

    在现实世界中，对机器学习的依赖日益增长，强调了理解和确保其安全性的重要性。中毒后门攻击由于其隐蔽性和潜在的严重后果而构成了重大的安全风险。这类攻击涉及将触发器嵌入学习模型中，以在存在活动触发器时引起恶意行为，同时在没有触发器的情况下维持正常功能。本文通过为受损模型在清洁和后门测试数据上的性能建立严格的下限和上限，评估了任何包含恒定触发器的后门攻击的有效性。所开发的理论回答了一系列基本但以前未被充分探索的问题，包括（1）后门攻击成功的决定因素是什么，（2）最有效的后门攻击方向是什么，以及（3）几乎不可察觉的人类触发器何时会成功。我们得到的理解...

    The growing dependence on machine learning in real-world applications emphasizes the importance of understanding and ensuring its safety. Backdoor attacks pose a significant security risk due to their stealthy nature and potentially serious consequences. Such attacks involve embedding triggers within a learning model with the intention of causing malicious behavior when an active trigger is present while maintaining regular functionality without it. This paper evaluates the effectiveness of any backdoor attack incorporating a constant trigger, by establishing tight lower and upper boundaries for the performance of the compromised model on both clean and backdoor test data. The developed theory answers a series of fundamental but previously underexplored problems, including (1) what are the determining factors for a backdoor attack's success, (2) what is the direction of the most effective backdoor attack, and (3) when will a human-imperceptible trigger succeed. Our derived understandin
    
[^88]: 发挥LLMs的能量：通过新闻标题生成的视角评估人工智能协作创作

    Harnessing the Power of LLMs: Evaluating Human-AI text Co-Creation through the Lens of News Headline Generation. (arXiv:2310.10706v1 [cs.CL])

    [http://arxiv.org/abs/2310.10706](http://arxiv.org/abs/2310.10706)

    该研究通过对LLMs辅助新闻标题生成的人工智能协作方法进行比较，发现引导和选择模型输出能够带来最大的效益，并且与自由编辑相比并不损害参与者对控制的感知。

    

    为了探索人类如何最好地利用LLMs进行写作，并了解与这些模型的交互如何影响写作过程中的所有权感和信任度，我们在LLM辅助新闻标题生成的背景下比较了常见的人工智能协作类型（例如，引导系统，从系统输出中进行选择，后期编辑输出）。尽管LLMs单独可以生成令人满意的新闻标题，但平均而言，人类的控制是需要的，以修复不可取的模型输出。在各种交互方法中，引导和选择模型输出增加了最多的效益，代价最低（时间和精力）。此外，人工智能协助并没有损害参与者对控制的感知，与自由编辑相比。

    To explore how humans can best leverage LLMs for writing and how interacting with these models affects feelings of ownership and trust in the writing process, we compared common human-AI interaction types (e.g., guiding system, selecting from system outputs, post-editing outputs) in the context of LLM-assisted news headline generation. While LLMs alone can generate satisfactory news headlines, on average, human control is needed to fix undesirable model outputs. Of the interaction methods, guiding and selecting model output added the most benefit with the lowest cost (in time and effort). Further, AI assistance did not harm participants' perception of control compared to freeform editing.
    
[^89]: 深度学习的微扩展数据格式

    Microscaling Data Formats for Deep Learning. (arXiv:2310.10537v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.10537](http://arxiv.org/abs/2310.10537)

    本文评估了Microscaling（MX）数据格式在降低深度学习应用的计算和存储成本方面的可行性。实证结果显示MX数据格式可以作为基线FP32的替代，同时保持低用户摩擦，并且成功在超过两打基准测试中以小于8位的数据格式进行了训练。

    

    窄位宽数据格式对于降低现代深度学习应用的计算和存储成本至关重要。本文评估了将每个块的缩放因子与窄浮点和整数类型相结合的微扩展（MX）数据格式，以满足硬件效率、模型准确性和用户摩擦之间的竞争需求。对于AI推理和训练，MX数据格式在超过两打基准测试中的实证结果证明了其作为基线FP32的可行性，并且使用时用户摩擦小。我们还展示了在最小的准确性损失和无需修改训练配方的情况下，首次训练生成式语言模型在小于8位的权重、激活和渐变上。

    Narrow bit-width data formats are key to reducing the computational and storage costs of modern deep learning applications. This paper evaluates Microscaling (MX) data formats that combine a per-block scaling factor with narrow floating-point and integer types for individual elements. MX formats balance the competing needs of hardware efficiency, model accuracy, and user friction. Empirical results on over two dozen benchmarks demonstrate practicality of MX data formats as a drop-in replacement for baseline FP32 for AI inference and training with low user friction. We also show the first instance of training generative language models at sub-8-bit weights, activations, and gradients with minimal accuracy loss and no modifications to the training recipe.
    
[^90]: 用大型语言模型进行语义解析，用于复杂的零样本对话状态跟踪的更新策略

    Semantic Parsing by Large Language Models for Intricate Updating Strategies of Zero-Shot Dialogue State Tracking. (arXiv:2310.10520v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.10520](http://arxiv.org/abs/2310.10520)

    本论文提出了ParsingDST方法，利用大型语言模型和语义解析技术，实现了复杂的零样本对话状态跟踪的更新策略，并在实验中展示了明显的改进。

    

    零样本对话状态跟踪（DST）解决了获取和注释面向任务的对话的挑战，这可能耗时费力。然而，DST超出了简单的填槽，需要有效的更新策略来跟踪对话状态随着对话的进行。本文提出了ParsingDST，一种新的In-Context Learning（ICL）方法，以引入额外的复杂更新策略用于零样本DST。我们的方法通过利用强大的大型语言模型（LLMs）并通过语义解析将原始对话文本转换为JSON作为一个中间状态来重新定义DST任务。我们还设计了一个新颖的框架，其中包括更多的模块来确保文本到JSON过程中更新策略的有效性。实验结果表明，我们的方法在MultiWOZ数据集上优于现有的零样本DST方法，在联合目标准确率（JGA）和槽准确度方面与现有的ICL方法相比呈现出显著改进。

    Zero-shot Dialogue State Tracking (DST) addresses the challenge of acquiring and annotating task-oriented dialogues, which can be time consuming and costly. However, DST extends beyond simple slot-filling and requires effective updating strategies for tracking dialogue state as conversations progress. In this paper, we propose ParsingDST, a new In-Context Learning (ICL) method, to introduce additional intricate updating strategies in zero-shot DST. Our approach reformulates the DST task by leveraging powerful Large Language Models (LLMs) and translating the original dialogue text to JSON through semantic parsing as an intermediate state. We also design a novel framework that includes more modules to ensure the effectiveness of updating strategies in the text-to-JSON process. Experimental results demonstrate that our approach outperforms existing zero-shot DST methods on MultiWOZ, exhibiting significant improvements in Joint Goal Accuracy (JGA) and slot accuracy compared to existing ICL
    
[^91]: 使用大型语言模型的文本摘要: MPT-7b-instruct、Falcon-7b-instruct和OpenAI Chat-GPT模型的比较研究

    Text Summarization Using Large Language Models: A Comparative Study of MPT-7b-instruct, Falcon-7b-instruct, and OpenAI Chat-GPT Models. (arXiv:2310.10449v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.10449](http://arxiv.org/abs/2310.10449)

    本研究通过比较MPT-7b-instruct, Falcon-7b-instruct和OpenAI Chat-GPT模型，在不同的数据集上使用不同的超参数进行了文本摘要实验。实验结果表明，text-davinci-003模型表现最佳，并且提供了大型语言模型在文本摘要中的性能综述。

    

    文本摘要是一项重要的自然语言处理任务，应用范围包括信息检索和内容生成。利用大型语言模型在提升摘要技术方面展示了显著的潜力。本文使用多种大型语言模型（包括MPT-7b-instruct，falcon-7b-instruct和OpenAI ChatGPT text-davinci-003模型）进行文本摘要的探索。实验使用不同的超参数，并使用诸如双语评估衡量（BLEU）分数，面向回忆的视角评估（ROUGE）分数和双向编码器表示转换器（BERT）分数等广泛接受的指标评估生成的摘要。根据实验，text-davinci-003的性能优于其他模型。本次研究涉及CNN Daily Mail和XSum这两个不同的数据集，主要目标是全面了解大型语言模型在文本摘要中的性能。

    Text summarization is a critical Natural Language Processing (NLP) task with applications ranging from information retrieval to content generation. Leveraging Large Language Models (LLMs) has shown remarkable promise in enhancing summarization techniques. This paper embarks on an exploration of text summarization with a diverse set of LLMs, including MPT-7b-instruct, falcon-7b-instruct, and OpenAI ChatGPT text-davinci-003 models. The experiment was performed with different hyperparameters and evaluated the generated summaries using widely accepted metrics such as the Bilingual Evaluation Understudy (BLEU) Score, Recall-Oriented Understudy for Gisting Evaluation (ROUGE) Score, and Bidirectional Encoder Representations from Transformers (BERT) Score. According to the experiment, text-davinci-003 outperformed the others. This investigation involved two distinct datasets: CNN Daily Mail and XSum. Its primary objective was to provide a comprehensive understanding of the performance of Large
    
[^92]: 跨语言多语言模型中事实知识的跨语言一致性

    Cross-Lingual Consistency of Factual Knowledge in Multilingual Language Models. (arXiv:2310.10378v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.10378](http://arxiv.org/abs/2310.10378)

    本论文研究了多语言预训练语言模型中事实知识的跨语言一致性，提出了一种新的度量方法，并通过分析模型大小、语言配对等因素发现了影响一致性的因素。实验结果表明，增加模型大小可以提高准确性，但不会改善跨语言一致性。

    

    多语言大规模预训练语言模型（PLM）显示存储了大量的事实知识，但在不同语言之间存在较大的变化。为了确保不同语言背景的用户从同一个模型中获得一致的反馈，我们研究了各种多语言PLM中事实知识的跨语言一致性（CLC）。为此，我们提出了一种基于排序的一致性（RankC）度量，用于独立于准确性评估跨语言间的知识一致性。利用这个度量方法，我们对决定CLC的因素进行了深入分析，包括模型层面和语言对层面。在其他结果中，我们发现增加模型大小可以提高大多数语言中的事实探测准确性，但不能改善跨语言一致性。最后，我们通过模型编辑在PLMs中插入新的事实关联进行了一个CLC的案例研究。对一小部分事实进行了实验。

    Multilingual large-scale Pretrained Language Models (PLMs) have been shown to store considerable amounts of factual knowledge, but large variations are observed across languages. With the ultimate goal of ensuring that users with different language backgrounds obtain consistent feedback from the same model, we study the cross-lingual consistency (CLC) of factual knowledge in various multilingual PLMs. To this end, we propose a Ranking-based Consistency (RankC) metric to evaluate knowledge consistency across languages independently from accuracy. Using this metric, we conduct an in-depth analysis of the determining factors for CLC, both at model level and at language-pair level. Among other results, we find that increasing model size leads to higher factual probing accuracy in most languages, but does not improve cross-lingual consistency. Finally, we conduct a case study on CLC when new factual associations are inserted in the PLMs via model editing. Results on a small sample of facts 
    
[^93]: TRANSOM:一种用于训练LLMs的高效容错系统

    TRANSOM: An Efficient Fault-Tolerant System for Training LLMs. (arXiv:2310.10046v2 [cs.DC] UPDATED)

    [http://arxiv.org/abs/2310.10046](http://arxiv.org/abs/2310.10046)

    TRANSOM是一种用于训练LLMs的高效容错系统，包括训练流水线自动容错和恢复机制（TOL）、训练任务多维度度量的自动决策和调整机制（ADAM）以及在群集恢复之间自动决策和管理任务移动的模型（RMM）。

    

    大型语言模型（LLMs）如chatGPT在各个领域取得了显著进展，表明拥有数百亿甚至数万亿参数的LLMs将继续改变我们的日常生活。然而，训练如此大规模的模型需要更强大的GPU集群和持续数月的训练周期。在这样庞大的集群中，由于硬件和软件故障，保持不中断和长时间的训练变得异常困难。相当多的训练时间被用于任务检查点的保存和加载、异常检测和重启，导致整体训练效率显著降低。为了解决这些挑战，我们引入了一种名为TRANSOM的新型容错大规模模型训练系统。该系统包括三个核心组件:训练流水线自动容错和恢复机制（TOL）、训练任务多维度度量的自动决策和调整机制（ADAM）以及在群集恢复之间自动决策和管理任务移动的模型（RMM）。

    Large language models (LLMs), exemplified by chatGPT, have made significant strides in various domains, indicating that LLMs with hundreds of billions or even trillions of parameters will continue to revolutionize our daily lives. However, training such super-large-scale models demands even more powerful GPU clusters and extended training periods spanning months. Maintaining uninterrupted and long-duration training has become exceptionally challenging due to hardware and software failures in these extensive clusters. A substantial amount of training time is devoted to tasks checkpointing saving and loading, ananomaly detection and restarts, leading to a notable reduction in overall training efficiency.To address these challenges, we introduce novel fault-tolerant large-scale model training system named TRANSOM. This system comprises three integral components: the training pipeline automatic fault tolerance and recovery mechanism (TOL), the training task multi-dimensional metric automat
    
[^94]: 使用深度生成模型进行中国绘画风格转换

    Chinese Painting Style Transfer Using Deep Generative Models. (arXiv:2310.09978v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2310.09978](http://arxiv.org/abs/2310.09978)

    本文研究和利用不同的深度生成模型进行中国绘画风格转换，并提出了一种结合了多种模型的算法。在定性和定量方面评估了其性能。

    

    艺术风格转换旨在在保留图像内容的同时修改其风格。自2015年以来，使用深度学习模型进行风格转换已经被广泛研究，大多数应用都集中在像梵高、莫奈、塞尚这样的特定艺术家上。然而，在传统中国绘画风格转换方面的研究和应用较少。本文将研究和利用不同的最新深度生成模型进行中国绘画风格转换，并在定性和定量方面评估其性能。此外，我们还提出了一种结合了几种风格转换模型的算法。具体而言，我们将把传统中国绘画的两种主要风格，即“工笔”和“水墨”，应用到现代图像中，如自然对象、肖像和风景。

    Artistic style transfer aims to modify the style of the image while preserving its content. Style transfer using deep learning models has been widely studied since 2015, and most of the applications are focused on specific artists like Van Gogh, Monet, Cezanne. There are few researches and applications on traditional Chinese painting style transfer. In this paper, we will study and leverage different state-of-the-art deep generative models for Chinese painting style transfer and evaluate the performance both qualitatively and quantitatively. In addition, we propose our own algorithm that combines several style transfer models for our task. Specifically, we will transfer two main types of traditional Chinese painting style, known as "Gong-bi" and "Shui-mo" (to modern images like nature objects, portraits and landscapes.
    
[^95]: 提升对话式搜索：基于大型语言模型辅助的信息查询重写

    Enhancing Conversational Search: Large Language Model-Aided Informative Query Rewriting. (arXiv:2310.09716v2 [cs.HC] UPDATED)

    [http://arxiv.org/abs/2310.09716](http://arxiv.org/abs/2310.09716)

    该论文提出了一种利用大型语言模型(LLMs)作为查询重写器的方法，通过指令生成信息丰富的查询重写，以提升对话式搜索的检索性能。实验结果表明，这种方法在QReCC数据集上取得了良好的效果。

    

    查询重写在提升对话式搜索中起着重要作用，通过将上下文相关的用户查询转化为独立形式。现有方法主要利用人工重写的查询作为标签来训练查询重写模型。然而，人工重写可能缺乏足够的信息以实现最佳的检索性能。为了克服这个限制，我们提出利用大型语言模型(LLMs)作为查询重写器，通过精心设计的指令生成信息丰富的查询重写。我们定义了四个重要特性来定义规范的重写，并将其全部纳入指令中。此外，当初始查询重写可用时，我们引入了LLMs的重写编辑器的角色，形成一个“重写-编辑”过程。此外，我们提出将LLMs的重写能力提炼成较小的模型，以减少重写延迟。我们在QReCC数据集上进行的实验评估表明，信息丰富的查询重写可以提高搜索的效果。

    Query rewriting plays a vital role in enhancing conversational search by transforming context-dependent user queries into standalone forms. Existing approaches primarily leverage human-rewritten queries as labels to train query rewriting models. However, human rewrites may lack sufficient information for optimal retrieval performance. To overcome this limitation, we propose utilizing large language models (LLMs) as query rewriters, enabling the generation of informative query rewrites through well-designed instructions. We define four essential properties for well-formed rewrites and incorporate all of them into the instruction. In addition, we introduce the role of rewrite editors for LLMs when initial query rewrites are available, forming a "rewrite-then-edit" process. Furthermore, we propose distilling the rewriting capabilities of LLMs into smaller models to reduce rewriting latency. Our experimental evaluation on the QReCC dataset demonstrates that informative query rewrites can y
    
[^96]: Edge-InversionNet：使InversionNet在边缘设备上实现高效推理

    Edge-InversionNet: Enabling Efficient Inference of InversionNet on Edge Devices. (arXiv:2310.09667v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.09667](http://arxiv.org/abs/2310.09667)

    本论文提出了Edge-InversionNet，通过采用结构化修剪算法得到了InversionNet的轻量化版本，在资源受限的边缘设备上实现了高效的推理。实验结果显示，修剪后的InversionNet在性能略有下降的情况下，可以实现高达98.2%的计算资源减少。

    

    地震全波形反演(FWI)是地球物理学中广泛使用的一种技术，用于从地震数据中推断地下结构。而InversionNet是最成功的数据驱动机器学习模型之一，应用于地震FWI。然而，高计算成本使得InversionNet难以有效部署到通常资源受限的边缘设备上。因此，我们提出采用结构化修剪算法获得InversionNet的轻量化版本，以在边缘设备上进行高效推理。我们还使用树莓派制作了一个运行轻量化InversionNet的原型。实验结果表明，修剪后的InversionNet可以实现高达98.2%的计算资源减少，而模型性能略有下降。

    Seismic full waveform inversion (FWI) is a widely used technique in geophysics for inferring subsurface structures from seismic data. And InversionNet is one of the most successful data-driven machine learning models that is applied to seismic FWI. However, the high computing costs to run InversionNet have made it challenging to be efficiently deployed on edge devices that are usually resource-constrained. Therefore, we propose to employ the structured pruning algorithm to get a lightweight version of InversionNet, which can make an efficient inference on edge devices. And we also made a prototype with Raspberry Pi to run the lightweight InversionNet. Experimental results show that the pruned InversionNet can achieve up to 98.2 % reduction in computing resources with moderate model performance degradation.
    
[^97]: AI-机器人中的安全考虑：当前方法、挑战和机会的调查

    Security Considerations in AI-Robotics: A Survey of Current Methods, Challenges, and Opportunities. (arXiv:2310.08565v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2310.08565](http://arxiv.org/abs/2310.08565)

    本文调查和分类了AI-机器人系统中的安全问题，包括攻击面、道德和法律问题以及人机交互安全。旨在为用户、开发者和其他利益相关者提供指导。

    

    自从它们诞生以来，机器人和人工智能（AI）就密不可分地联系在一起。如今，AI-机器人系统已经成为我们日常生活的重要组成部分，从机器人吸尘器到半自动驾驶汽车。这些系统建立在三个基本的架构元素上：感知、导航与规划，以及控制。然而，尽管AI-机器人系统的整合提高了我们生活的质量，但也带来了一个严重的问题 - 这些系统容易受到安全攻击。构成AI-机器人系统的物理组件、算法和数据可能会被恶意行为者利用，可能导致严重后果。基于应对AI-机器人系统中的安全问题的需求，本文在攻击面、道德和法律问题以及人机交互安全三个维度上提供了一份全面的调查和分类。我们的目标是为用户、开发者和其他利益相关者提供指导。

    Robotics and Artificial Intelligence (AI) have been inextricably intertwined since their inception. Today, AI-Robotics systems have become an integral part of our daily lives, from robotic vacuum cleaners to semi-autonomous cars. These systems are built upon three fundamental architectural elements: perception, navigation and planning, and control. However, while the integration of AI-Robotics systems has enhanced the quality our lives, it has also presented a serious problem - these systems are vulnerable to security attacks. The physical components, algorithms, and data that make up AI-Robotics systems can be exploited by malicious actors, potentially leading to dire consequences. Motivated by the need to address the security concerns in AI-Robotics systems, this paper presents a comprehensive survey and taxonomy across three dimensions: attack surfaces, ethical and legal concerns, and Human-Robot Interaction (HRI) security. Our goal is to provide users, developers and other stakehol
    
[^98]: 在线推测解码

    Online Speculative Decoding. (arXiv:2310.07177v1 [cs.AI])

    [http://arxiv.org/abs/2310.07177](http://arxiv.org/abs/2310.07177)

    在线推测解码是通过利用多余计算能力，在LLM服务集群中持续更新草稿模型，从而加速大型语言模型推理的一种方法。

    

    推测解码是通过利用较小的草稿模型来预测目标模型的输出，从而加速大型语言模型（LLM）推理的关键技术。然而，在面对多样的文本输入和草稿模型与目标模型之间的显著能力差距时，其有效性可能受到限制。我们引入了在线推测解码（OSD）来解决这一挑战。其主要思想是利用LLM服务集群中丰富的多余计算能力，根据观察到的用户查询数据持续更新（多个）草稿模型。由于LLM推理受内存限制，典型的LLM服务集群中的剩余计算能力可以用于在线重新训练草稿模型，从而使训练成本保持中性。由于LLM服务的查询分布相对简单，根据查询分布进行重新训练可以使草稿模型更准确地预测目标模型的输出。

    Speculative decoding is a pivotal technique to accelerate the inference of large language models (LLMs) by employing a smaller draft model to predict the target model's outputs. However, its efficacy can be limited due to the low predictive accuracy of the draft model, particularly when faced with diverse text inputs and a significant capability gap between the draft and target models. We introduce online speculative decoding (OSD) to address this challenge. The main idea is to continually update (multiple) draft model(s) on observed user query data using the abundant excess computational power in an LLM serving cluster. Given that LLM inference is memory-bounded, the surplus computational power in a typical LLM serving cluster can be repurposed for online retraining of draft models, thereby making the training cost-neutral. Since the query distribution of an LLM service is relatively simple, retraining on query distribution enables the draft model to more accurately predict the target
    
[^99]: Crystal: 以自我反馈为增强的内省推理器

    Crystal: Introspective Reasoners Reinforced with Self-Feedback. (arXiv:2310.04921v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2310.04921](http://arxiv.org/abs/2310.04921)

    提出了一种名为Crystal的内省型常识推理器，通过内省知识和基于知识的推理相结合，提高了常识推理的性能和解释能力。

    

    大量工作表明，通过知识增强的推理方法可以提高常识推理的性能和可解释性，其中推理过程的基础知识明确表达和利用。然而，现有的实现，包括"思维链"及其变种，未能捕捉到常识推理中所需的内省性质，也未能解释知识生成和利用之间的相互适应。我们提出了一种新颖的方法来开发内省型常识推理器 Crystal。为了解决常识问题，它首先内省与给定问题相关的知识陈述，然后基于先前内省的知识进行知情预测。模型的知识内省和基于知识的推理模式通过强化学习进行调整，其中奖励来自反馈。

    Extensive work has shown that the performance and interpretability of commonsense reasoning can be improved via knowledge-augmented reasoning methods, where the knowledge that underpins the reasoning process is explicitly verbalized and utilized. However, existing implementations, including "chain-of-thought" and its variants, fall short in capturing the introspective nature of knowledge required in commonsense reasoning, and in accounting for the mutual adaptation between the generation and utilization of knowledge. We propose a novel method to develop an introspective commonsense reasoner, Crystal. To tackle commonsense problems, it first introspects for knowledge statements related to the given question, and subsequently makes an informed prediction that is grounded in the previously introspected knowledge. The knowledge introspection and knowledge-grounded reasoning modes of the model are tuned via reinforcement learning to mutually adapt, where the reward derives from the feedback
    
[^100]: 使用元胞自动机的智能客户端选择进行联邦学习

    Intelligent Client Selection for Federated Learning using Cellular Automata. (arXiv:2310.00627v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.00627](http://arxiv.org/abs/2310.00627)

    本研究提出了一种使用元胞自动机的智能客户端选择算法，用于解决联邦学习中由于传感器数量增加带来的通信和资源分配问题。

    

    联邦学习（FL）已成为解决隐私增强和延迟最小化等各种实际应用（如交通、通信和医疗）中的问题的有希望的解决方案。FL通过利用来自数百万设备和物联网传感器的数据将机器学习（ML）引入边缘，从而实现对动态环境的快速响应，并产生高度个性化的结果。然而，不同应用中传感器数量的增加在通信和资源分配方面带来了挑战，阻碍了所有设备参与联邦过程的能力，进而需要有效的FL客户端选择。为了解决这个问题，我们提出了基于元胞自动机的客户端选择（CA-CS），这是一种新颖的客户端选择算法，它利用元胞自动机（CA）作为模型，以有效地捕捉快速演变环境中的时空变化。CA-CS考虑了计算资源和通信能力。

    Federated Learning (FL) has emerged as a promising solution for privacy-enhancement and latency minimization in various real-world applications, such as transportation, communications, and healthcare. FL endeavors to bring Machine Learning (ML) down to the edge by harnessing data from million of devices and IoT sensors, thus enabling rapid responses to dynamic environments and yielding highly personalized results. However, the increased amount of sensors across diverse applications poses challenges in terms of communication and resource allocation, hindering the participation of all devices in the federated process and prompting the need for effective FL client selection. To address this issue, we propose Cellular Automaton-based Client Selection (CA-CS), a novel client selection algorithm, which leverages Cellular Automata (CA) as models to effectively capture spatio-temporal changes in a fast-evolving environment. CA-CS considers the computational resources and communication capacity
    
[^101]: 一种用于医学图像中一般移动目标分割的基础模型

    A Foundation Model for General Moving Object Segmentation in Medical Images. (arXiv:2309.17264v1 [cs.CV])

    [http://arxiv.org/abs/2309.17264](http://arxiv.org/abs/2309.17264)

    本文提出了一种用于医学图像中移动目标分割的基础模型iMOS，通过对序列中只有少量图像进行注释，即可实现高精度的分割效果

    

    医学图像分割旨在描绘感兴趣的解剖或病理结构，在临床诊断中起着关键作用。构建高精度的深度分割模型需要大量高质量的注释数据。然而，医学注释非常繁琐耗时，特别是对于医学视频或3D体积，由于巨大的标签空间和差的帧间一致性。最近，在自然图像中，一个名为Moving Object Segmentation (MOS)的基本任务在技术上取得了重大进展。它的目标是在图像序列中从背景中描绘移动物体，只需要最小的注释。在本文中，我们提出了第一个用于医学图像中MOS的基础模型，名为iMOS。对一个大规模多模态医学数据集进行的大量实验验证了所提出的iMOS的有效性。具体而言，只需对序列中少量的图像进行注释，iMOS就可以实现了

    Medical image segmentation aims to delineate the anatomical or pathological structures of interest, playing a crucial role in clinical diagnosis. A substantial amount of high-quality annotated data is crucial for constructing high-precision deep segmentation models. However, medical annotation is highly cumbersome and time-consuming, especially for medical videos or 3D volumes, due to the huge labeling space and poor inter-frame consistency. Recently, a fundamental task named Moving Object Segmentation (MOS) has made significant advancements in natural images. Its objective is to delineate moving objects from the background within image sequences, requiring only minimal annotations. In this paper, we propose the first foundation model, named iMOS, for MOS in medical images. Extensive experiments on a large multi-modal medical dataset validate the effectiveness of the proposed iMOS. Specifically, with the annotation of only a small number of images in the sequence, iMOS can achieve sati
    
[^102]: SA2-Net: 用于显微图像分割的尺度感知注意力网络

    SA2-Net: Scale-aware Attention Network for Microscopic Image Segmentation. (arXiv:2309.16661v1 [cs.CV])

    [http://arxiv.org/abs/2309.16661](http://arxiv.org/abs/2309.16661)

    SA2-Net是一种尺度感知注意力网络，用于处理显微图像中的多样结构。它结合了多尺度特征学习和尺度感知注意力模块，以实现准确的分割。

    

    显微图像分割是一项具有挑战性的任务，其目标是为给定的显微图像中的每个像素分配语义标签。虽然卷积神经网络（CNNs）是许多现有框架的基础，但它们通常难以明确捕捉长程依赖关系。尽管变压器最初是为了使用自注意力来解决这个问题，但已经证明，在显微图像中，包括形状、大小、外观和目标区域密度的各种挑战中，本地和全局特征都是至关重要的。在本文中，我们介绍了SA2-Net，这是一种利用多尺度特征学习来有效处理显微图像中多样结构的注意引导方法。具体而言，我们提出了尺度感知注意力（SA2）模块，用于捕捉显微区域（如细胞）尺度和形状的固有变化，以实现准确的分割。这个模块结合了局部注意力

    Microscopic image segmentation is a challenging task, wherein the objective is to assign semantic labels to each pixel in a given microscopic image. While convolutional neural networks (CNNs) form the foundation of many existing frameworks, they often struggle to explicitly capture long-range dependencies. Although transformers were initially devised to address this issue using self-attention, it has been proven that both local and global features are crucial for addressing diverse challenges in microscopic images, including variations in shape, size, appearance, and target region density. In this paper, we introduce SA2-Net, an attention-guided method that leverages multi-scale feature learning to effectively handle diverse structures within microscopic images. Specifically, we propose scale-aware attention (SA2) module designed to capture inherent variations in scales and shapes of microscopic regions, such as cells, for accurate segmentation. This module incorporates local attention
    
[^103]: 让PPO变得更好：基于值导向的Monte-Carlo Tree Search解码

    Making PPO even better: Value-Guided Monte-Carlo Tree Search decoding. (arXiv:2309.15028v1 [cs.CL])

    [http://arxiv.org/abs/2309.15028](http://arxiv.org/abs/2309.15028)

    本文提出了一种基于值导向的Monte-Carlo Tree Search解码算法PPO-MCTS，通过在PPO之上集成MCTS，解决了训练和测试之间部分输出评分机制的不匹配问题，实验证明该算法可以显著提升性能。

    

    在生成自然语言文本时，使用最新的强化学习算法，如Proximal Policy Optimization (PPO)，因此可以认为推理时间的搜索算法，如Monte-Carlo Tree Search (MCTS) 是不必要的。本文证明了通过在PPO之上集成MCTS，可以进一步提升PPO的性能。关键思想是在解码文本时，不要丢弃值网络，即PPO训练时用于评估部分输出序列的副产品，而是将其与策略网络紧密结合。具体而言，本文提出了一种称为PPO-MCTS的新颖的值导向解码算法，可以将来自PPO的值网络与推理时间产生的策略网络紧密结合。与基于MCTS的控制文本生成的先前方法相比，我们的方法的关键优势在于减少了训练和测试之间部分输出的评分机制的基本不匹配。在四个文本生成任务上的评估结果表明，PPO-MCTS可以显著提升性能。

    Inference-time search algorithms such as Monte-Carlo Tree Search (MCTS) may seem unnecessary when generating natural language text based on state-of-the-art reinforcement learning such as Proximal Policy Optimization (PPO). In this paper, we demonstrate that it is possible to get extra mileage out of PPO by integrating MCTS on top. The key idea is not to throw out the value network, a byproduct of PPO training for evaluating partial output sequences, when decoding text out of the policy network. More concretely, we present a novel value-guided decoding algorithm called PPO-MCTS, which can integrate the value network from PPO to work closely with the policy network during inference-time generation. Compared to prior approaches based on MCTS for controlled text generation, the key strength of our approach is to reduce the fundamental mismatch of the scoring mechanisms of the partial outputs between training and test. Evaluation on four text generation tasks demonstrate that PPO-MCTS grea
    
[^104]: 决策树策略在IBMDP中的Actor-Critic算法的局限性（arXiv:2309.13365v2 [cs.LG] UPDATED）

    Limits of Actor-Critic Algorithms for Decision Tree Policies Learning in IBMDPs. (arXiv:2309.13365v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2309.13365](http://arxiv.org/abs/2309.13365)

    该论文研究了在IBMDP中使用Actor-Critic算法学习决策树策略的局限性。结果表明，即使是在简单的玩具任务上，深度RL也可能失败。

    

    AI模型的可解释性可以通过用户安全检查来建立对这些AI的信任。特别是，决策树（DT）提供了对学习模型的整体视角，并透明地揭示了哪些输入特征对于做出决策至关重要。然而，如果决策树过大，可解释性就会受到影响。为了学习紧凑的决策树，最近提出了一种强化学习（RL）框架，用于使用深度RL探索DT的空间。该框架通过增加动作来收集关于隐藏输入特征的信息，通过适当地对这些动作进行惩罚，代理学习如何在树的大小和性能之间进行最优权衡。在实践中，仍然存在一个开放问题，即需要学习部分可观察马尔可夫决策过程（MDP）的反应性策略。本文表明，即使在这一类简单的玩具任务上，深度RL也可能失败。

    Interpretability of AI models allows for user safety checks to build trust in such AIs. In particular, Decision Trees (DTs) provide a global look at the learned model and transparently reveal which features of the input are critical for making a decision. However, interpretability is hindered if the DT is too large. To learn compact trees, a recent Reinforcement Learning (RL) framework has been proposed to explore the space of DTs using deep RL. This framework augments a decision problem (e.g. a supervised classification task) with additional actions that gather information about the features of an otherwise hidden input. By appropriately penalizing these actions, the agent learns to optimally trade-off size and performance of DTs. In practice, a reactive policy for a partially observable Markov decision process (MDP) needs to be learned, which is still an open problem. We show in this paper that deep RL can fail even on simple toy tasks of this class. However, when the underlying deci
    
[^105]: 缺失数据下的不确定性交通预测

    Uncertainty-aware Traffic Prediction under Missing Data. (arXiv:2309.06800v1 [cs.LG])

    [http://arxiv.org/abs/2309.06800](http://arxiv.org/abs/2309.06800)

    本研究提出了一种考虑不确定性的交通预测方法，可以处理缺失数据和测量不确定性，并适用于风险敏感任务和决策导向问题。

    

    交通预测是一个重要的课题，因为它在交通领域有广泛的应用。近期，许多研究取得了很好的结果。然而，大多数研究假设预测位置有完整或至少部分的历史记录，不能扩展到无历史记录的位置。在现实场景中，由于预算限制和安装可行性问题，传感器的部署可能受限，这使得大多数当前模型不适用。虽然少数文献尝试在缺失位置上插补交通状态，但这些方法需要与传感器位置同时观测的数据，使它们不适用于预测任务。另一个缺点是缺乏对预测不确定性的测量，使得之前的工作不适用于风险敏感的任务或涉及决策的情况。为了填补这一空白，受到先前的归纳图神经网络的启发，本文提出了一种考虑不确定性的方法。

    Traffic prediction is a crucial topic because of its broad scope of applications in the transportation domain. Recently, various studies have achieved promising results. However, most studies assume the prediction locations have complete or at least partial historical records and cannot be extended to non-historical recorded locations. In real-life scenarios, the deployment of sensors could be limited due to budget limitations and installation availability, which makes most current models not applicable. Though few pieces of literature tried to impute traffic states at the missing locations, these methods need the data simultaneously observed at the locations with sensors, making them not applicable to prediction tasks. Another drawback is the lack of measurement of uncertainty in prediction, making prior works unsuitable for risk-sensitive tasks or involving decision-making. To fill the gap, inspired by the previous inductive graph neural network, this work proposed an uncertainty-awa
    
[^106]: 通过大型语言模型进行交互机器人行动规划与不确定性分析和主动提问

    Interactively Robot Action Planning with Uncertainty Analysis and Active Questioning by Large Language Model. (arXiv:2308.15684v1 [cs.RO])

    [http://arxiv.org/abs/2308.15684](http://arxiv.org/abs/2308.15684)

    本文提出了一种交互式机器人行动规划方法，利用大型语言模型（LLM）通过向人类提问来分析并收集缺失信息，最大程度地减少生成精确机器人指令的设计成本。揭示了在机器人行动规划中使用LLM面临的挑战，并为未来研究提供了有价值的见解。

    

    将大型语言模型（LLM）应用于机器人行动规划已经被积极研究。通过自然语言给出的LLM指令可能存在歧义和缺乏信息，这取决于任务环境。可以通过使指令输入更详细来调整LLM的输出；然而，设计成本很高。在本文中，我们提出了一种交互式机器人行动规划方法，允许LLM通过向人类提问来分析并收集缺失信息。该方法可以最大程度地减少生成精确机器人指令的设计成本。我们通过烹饪任务的具体示例证明了我们方法的有效性。然而，我们的实验也揭示了LLM在机器人行动规划中面临的挑战，如提出不重要的问题和在不询问的情况下假设关键信息。对这些问题的阐明为未来利用LLM进行机器人技术研究提供了有价值的见解。

    The application of the Large Language Model (LLM) to robot action planning has been actively studied. The instructions given to the LLM by natural language may include ambiguity and lack of information depending on the task context. It is possible to adjust the output of LLM by making the instruction input more detailed; however, the design cost is high. In this paper, we propose the interactive robot action planning method that allows the LLM to analyze and gather missing information by asking questions to humans. The method can minimize the design cost of generating precise robot instructions. We demonstrated the effectiveness of our method through concrete examples in cooking tasks. However, our experiments also revealed challenges in robot action planning with LLM, such as asking unimportant questions and assuming crucial information without asking. Shedding light on these issues provides valuable insights for future research on utilizing LLM for robotics.
    
[^107]: 识别和减轻生成式人工智能的安全风险

    Identifying and Mitigating the Security Risks of Generative AI. (arXiv:2308.14840v1 [cs.AI])

    [http://arxiv.org/abs/2308.14840](http://arxiv.org/abs/2308.14840)

    生成式人工智能技术具有巨大的潜力，但也存在安全风险。这篇论文是一个研讨会的综合报道，讨论了生成式人工智能所带来的双重用途困境，提出了社区在这个领域的短期和长期目标。

    

    每一项重大技术发明都会带来双重用途的困境 - 新技术既有可能被用于善良，也可能被用于恶意行为。生成式人工智能（GenAI）技术，如大型语言模型（LLM）和扩散模型，展示了卓越的能力（例如上下文学习，代码补全，文本到图像的生成和编辑）。然而，攻击者同样可以利用GenAI生成新的攻击，并增加现有攻击的速度和有效性。本文报告了在Google举办的一个研讨会的发现（由斯坦福大学和威斯康星大学麦迪逊分校共同组织）。本文并不意味着全面，而是试图综合一些有趣的研讨会发现。我们讨论了这个主题的短期和长期目标。我们希望这篇论文既为这个重要主题的讨论提供一个起点，也引起兴趣。

    Every major technical invention resurfaces the dual-use dilemma -- the new technology has the potential to be used for good as well as for harm. Generative AI (GenAI) techniques, such as large language models (LLMs) and diffusion models, have shown remarkable capabilities (e.g., in-context learning, code-completion, and text-to-image generation and editing). However, GenAI can be used just as well by attackers to generate new attacks and increase the velocity and efficacy of existing attacks.  This paper reports the findings of a workshop held at Google (co-organized by Stanford University and the University of Wisconsin-Madison) on the dual-use dilemma posed by GenAI. This paper is not meant to be comprehensive, but is rather an attempt to synthesize some of the interesting findings from the workshop. We discuss short-term and long-term goals for the community on this topic. We hope this paper provides both a launching point for a discussion on this important topic as well as interest
    
[^108]: 基于强化学习的非自回归求解器用于旅行推销员问题

    Reinforcement Learning-based Non-Autoregressive Solver for Traveling Salesman Problems. (arXiv:2308.00560v1 [cs.AI])

    [http://arxiv.org/abs/2308.00560](http://arxiv.org/abs/2308.00560)

    基于强化学习的非自回归TSP求解器NAR4TSP使用特别设计的图神经网络进行推理，消除了昂贵标签的依赖，并在解决方案质量、推理延迟和泛化能力方面优于其他四个最先进的模型。

    

    旅行推销员问题（TSP）是组合优化中的一个众所周知的问题，具有在各个领域的应用。然而，现有的TSP求解器在产生高质量解决方案时面临低延迟的挑战。为了解决这个问题，我们提出了NAR4TSP，它使用一个特别设计的图神经网络（GNN）以非自回归（NAR）方式生成TSP解决方案，实现更快的推理速度。此外，NAR4TSP使用增强的强化学习（RL）策略进行训练，消除了传统监督学习基于NAR模型训练所使用的昂贵标签的依赖关系。据我们所知，NAR4TSP是第一个成功结合了RL和NAR解码的TSP求解器。在合成和真实的TSP实例上的实验结果表明，NAR4TSP在解决方案质量、推理延迟和泛化能力方面优于四个最先进的模型。最后，我们展示了NAR4TSP解码过程的可视化。

    The Traveling Salesman Problem (TSP) is a well-known problem in combinatorial optimization with applications in various domains. However, existing TSP solvers face challenges in producing high-quality solutions with low latency. To address this issue, we propose NAR4TSP, which produces TSP solutions in a Non-Autoregressive (NAR) manner using a specially designed Graph Neural Network (GNN), achieving faster inference speed. Moreover, NAR4TSP is trained using an enhanced Reinforcement Learning (RL) strategy, eliminating the dependency on costly labels used to train conventional supervised learning-based NAR models. To the best of our knowledge, NAR4TSP is the first TSP solver that successfully combines RL and NAR decoding. The experimental results on both synthetic and real-world TSP instances demonstrate that NAR4TSP outperforms four state-of-the-art models in terms of solution quality, inference latency, and generalization ability. Lastly, we present visualizations of NAR4TSP's decodin
    
[^109]: 大型语言模型作为属性化训练数据生成器：多样性和偏差的故事

    Large Language Model as Attributed Training Data Generator: A Tale of Diversity and Bias. (arXiv:2306.15895v1 [cs.CL])

    [http://arxiv.org/abs/2306.15895](http://arxiv.org/abs/2306.15895)

    本论文研究了大型语言模型作为属性化训练数据生成器的应用。通过使用具有多样性属性的提示，我们能够生成多样化且归因的数据。研究表明，在高基数和多样领域的数据集中，使用属性化提示对生成模型性能有积极影响。此外，论文还展示了关于偏差、多样性和效率的全面实证研究结果，并得出了三个关键观察：系统性偏差存在于生成数据中，多样性和效率之间存在权衡，属性化训练数据生成可以改善模型性能。

    

    近期大型语言模型(LLMs)被广泛应用于各种自然语言处理(NLP)任务的训练数据生成。尽管之前的研究探索了使用生成数据进行模型训练的不同方法，但它们通常依赖于简单的类别条件提示，这可能限制了生成数据的多样性，并且继承了LLM的系统性偏差。因此，我们研究了使用具有多样属性的提示(例如指定长度和风格等属性)进行训练数据生成，这有潜力产生多样和归因的生成数据。我们的研究关注具有高基数和多样领域的数据集，在这方面，我们证明了属性化提示在生成模型性能方面优于简单的类别条件提示。此外，我们还展示了一项包括偏差、多样性和效率等关键方面的全面实证研究，并强调了三个关键观察：首先，系统性偏差在生成数据中存在；其次，多样性和效率之间存在权衡；最后，进行属性化训练数据生成可以改善模型性能。

    Large language models (LLMs) have been recently leveraged as training data generators for various natural language processing (NLP) tasks. While previous research has explored different approaches to training models using generated data, they generally rely on simple class-conditional prompts, which may limit the diversity of the generated data and inherit systematic biases of LLM. Thus, we investigate training data generation with diversely attributed prompts (e.g., specifying attributes like length and style), which have the potential to yield diverse and attributed generated data. Our investigation focuses on datasets with high cardinality and diverse domains, wherein we demonstrate that attributed prompts outperform simple class-conditional prompts in terms of the resulting model's performance. Additionally, we present a comprehensive empirical study on data generation encompassing vital aspects like bias, diversity, and efficiency, and highlight three key observations: firstly, sy
    
[^110]: OpenSTL: 一个全面的时空预测学习基准

    OpenSTL: A Comprehensive Benchmark of Spatio-Temporal Predictive Learning. (arXiv:2306.11249v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2306.11249](http://arxiv.org/abs/2306.11249)

    OpenSTL是一个全面的时空预测学习基准，通过将流行的方法分为基于循环和不基于循环的模型，并提供一个模块化和可扩展的框架，对各种领域的数据集进行了标准评估，并对模型架构进行了详细分析。

    

    时空预测学习是一种学习范式，通过在无监督的情况下预测未来帧来学习空间和时间模式。尽管近年来取得了显著进展，但由于各种环境、复杂的实现和难以复现性，仍然存在着缺乏系统性理解的问题。没有标准化，比较可能不公平，洞见不确定。为了解决这个困境，我们提出了OpenSTL，一个全面的时空预测学习基准，将流行的方法分为基于循环和不基于循环的模型。OpenSTL提供了一个模块化和可扩展的框架，实现了各种最先进的方法。我们对包括合成移动物体轨迹、人体运动、驾驶场景、交通流量和天气预报在内的各种领域的数据集进行了标准评估。基于我们的观察，我们详细分析了模型架构的表现。

    Spatio-temporal predictive learning is a learning paradigm that enables models to learn spatial and temporal patterns by predicting future frames from given past frames in an unsupervised manner. Despite remarkable progress in recent years, a lack of systematic understanding persists due to the diverse settings, complex implementation, and difficult reproducibility. Without standardization, comparisons can be unfair and insights inconclusive. To address this dilemma, we propose OpenSTL, a comprehensive benchmark for spatio-temporal predictive learning that categorizes prevalent approaches into recurrent-based and recurrent-free models. OpenSTL provides a modular and extensible framework implementing various state-of-the-art methods. We conduct standard evaluations on datasets across various domains, including synthetic moving object trajectory, human motion, driving scenes, traffic flow and weather forecasting. Based on our observations, we provide a detailed analysis of how model arch
    
[^111]: DORSal: 基于扩散的物体中心场景表示

    DORSal: Diffusion for Object-centric Representations of Scenes $\textit{et al.}$. (arXiv:2306.08068v1 [cs.CV])

    [http://arxiv.org/abs/2306.08068](http://arxiv.org/abs/2306.08068)

    DORSal提出了一种基于扩散模型的物体中心场景表示方法，可以呈现高保真新视图，并在较大程度上保留了诸如基于物体的场景编辑之类的优点。

    

    最近在三维场景理解方面取得的进展使跨大量不同场景的数据集的可扩展表示学习成为可能。因此，对于未见过的场景和物体的泛化，仅通过单个或少数图像渲染新视图，以及支持编辑的可控场景生成现在成为可能。然而，联合训练大量场景通常会在渲染质量上妥协，而与单个场景优化模型（如NeRF）相比。在本文中，我们利用最近扩散模型的进展，使三维场景表示学习模型具备呈现高保真新视图的能力，同时在较大程度上保留了诸如基于物体的场景编辑之类的优点。特别地，我们提出了DORSal，它基于扩散视频架构，为基于物体中心的场景插槽表示的三维场景生成提供适应性。我们在复杂的合成多物体场景和现实世界大规模街景数据集上证明，我们的模型能够生成高质量的场景新视图，同时支持物体级别的编辑，并保留细粒度的纹理和反射等细节。

    Recent progress in 3D scene understanding enables scalable learning of representations across large datasets of diverse scenes. As a consequence, generalization to unseen scenes and objects, rendering novel views from just a single or a handful of input images, and controllable scene generation that supports editing, is now possible. However, training jointly on a large number of scenes typically compromises rendering quality when compared to single-scene optimized models such as NeRFs. In this paper, we leverage recent progress in diffusion models to equip 3D scene representation learning models with the ability to render high-fidelity novel views, while retaining benefits such as object-level scene editing to a large degree. In particular, we propose DORSal, which adapts a video diffusion architecture for 3D scene generation conditioned on object-centric slot-based representations of scenes. On both complex synthetic multi-object scenes and on the real-world large-scale Street View d
    
[^112]: 在可解释的科学文献推荐系统中采用不同细节级别的交互式解释

    Interactive Explanation with Varying Level of Details in an Explainable Scientific Literature Recommender System. (arXiv:2306.05809v1 [cs.IR])

    [http://arxiv.org/abs/2306.05809](http://arxiv.org/abs/2306.05809)

    本文旨在采用以用户为中心的交互式解释模型，在推荐系统中为用户提供不同细节级别的解释，赋予用户个性化解释的能力。

    

    传统上，可解释的推荐系统采用一种“一刀切”的方法，向每个用户提供相同程度的解释，而不考虑他们的个体需求和目标。此外，推荐系统中的解释大多以静态和非交互方式呈现。为填补这些研究空白，本文旨在采用以用户为中心的交互式解释模型，为用户提供不同细节级别的解释，并赋予用户基于其需求和偏好进行交互、控制和个性化解释的能力。我们采用以用户为中心的方法，设计了三个细节级别的交互式解释（基本、中级和高级），并在透明的推荐和兴趣建模应用（RIMA）中实现了它们。我们进行了一个定性用户研究（N=14），以调查提供不同细节级别的交互式解释对用户对系统可解释性的感知的影响。

    Explainable recommender systems (RS) have traditionally followed a one-size-fits-all approach, delivering the same explanation level of detail to each user, without considering their individual needs and goals. Further, explanations in RS have so far been presented mostly in a static and non-interactive manner. To fill these research gaps, we aim in this paper to adopt a user-centered, interactive explanation model that provides explanations with different levels of detail and empowers users to interact with, control, and personalize the explanations based on their needs and preferences. We followed a user-centered approach to design interactive explanations with three levels of detail (basic, intermediate, and advanced) and implemented them in the transparent Recommendation and Interest Modeling Application (RIMA). We conducted a qualitative user study (N=14) to investigate the impact of providing interactive explanations with varying level of details on the users' perception of the e
    
[^113]: MuZero学到了什么模型？

    What model does MuZero learn?. (arXiv:2306.00840v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.00840](http://arxiv.org/abs/2306.00840)

    本文研究了MuZero算法，发现它学习到的模型无法有效推广到评估未见策略，限制了其对当前策略的进一步改进。

    

    近年来，基于模型的强化学习引起了广泛关注，因为它有望提高样本效率。此外，当使用深度学习模型时，有可能从复杂的传感器数据中学习到紧凑的模型。然而，这些学习到的模型的有效性，特别是它们规划能力的提升当前策略的能力，仍然不清楚。在本研究中，我们研究了MuZero这个著名的基于深度模型的强化学习算法，并探讨了它在实现值等价模型的学习目标上的成就以及学习到的模型对策略改进的实用性。在诸多其他观点中，我们得出结论：MuZero学到的模型无法有效地推广到评估未见策略，这限制了我们通过模型规划来进一步改进当前策略的程度。

    Model-based reinforcement learning has drawn considerable interest in recent years, given its promise to improve sample efficiency. Moreover, when using deep-learned models, it is potentially possible to learn compact models from complex sensor data. However, the effectiveness of these learned models, particularly their capacity to plan, i.e., to improve the current policy, remains unclear. In this work, we study MuZero, a well-known deep model-based reinforcement learning algorithm, and explore how far it achieves its learning objective of a value-equivalent model and how useful the learned models are for policy improvement. Amongst various other insights, we conclude that the model learned by MuZero cannot effectively generalize to evaluate unseen policies, which limits the extent to which we can additionally improve the current policy by planning with the model.
    
[^114]: 超越一个模型适用于所有领域：大型语言模型的领域专门化综述

    Beyond One-Model-Fits-All: A Survey of Domain Specialization for Large Language Models. (arXiv:2305.18703v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.18703](http://arxiv.org/abs/2305.18703)

    本文综述了大型语言模型的领域专门化，包括动机、挑战、方法论和评估指标。此外，还提供了一个特定领域任务和数据集的分类法，对现有的领域自适应和定制技术进行了详细比较，并广泛讨论了这一领域中的未解决问题和未来的发展方向。

    

    大型语言模型（LLM）已经大大推动了自然语言处理（NLP）领域的发展，为广泛应用提供了高度实用、任务无关的基础。LLMs 作为通用任务求解器的巨大潜力，促使人们将其用于特定领域，如医疗保健、金融和教育，并将其用作助手甚至替代特定领域的专家和工具。但是，将LLMs直接应用于特定领域中的复杂问题会遇到许多困难，包括领域数据的异质性、领域知识的复杂性、领域目标的独特性以及约束的多样性。为了填补这种差距，最近几年进行了急剧增加的研究和实践致力于大型语言模型的领域专门化，然而这方面的研究尚未被系统地总结。在这篇综述中，我们对LLMs的领域专门化进行了全面概述，包括动机、挑战、方法论和评估指标。此外，我们提供了一个特定领域任务和数据集的分类法，对现有的领域自适应和定制技术进行了详细比较，并广泛讨论了这一领域中的未解决问题和未来的发展方向。

    Large language models (LLMs) have significantly advanced the field of natural language processing (NLP), providing a highly useful, task-agnostic foundation for a wide range of applications. The great promise of LLMs as general task solvers motivated people to extend their functionality largely beyond just a ``chatbot'', and use it as an assistant or even replacement for domain experts and tools in specific domains such as healthcare, finance, and education. However, directly applying LLMs to solve sophisticated problems in specific domains meets many hurdles, caused by the heterogeneity of domain data, the sophistication of domain knowledge, the uniqueness of domain objectives, and the diversity of the constraints (e.g., various social norms, cultural conformity, religious beliefs, and ethical standards in the domain applications). To fill such a gap, explosively-increase research, and practices have been conducted in very recent years on the domain specialization of LLMs, which, howe
    
[^115]: 用于从稀疏远程传感器数据重建非线性海洋波浪表面相位的机器学习方法

    Machine learning for phase-resolved reconstruction of nonlinear ocean wave surface elevations from sparse remote sensing data. (arXiv:2305.11913v1 [physics.ao-ph])

    [http://arxiv.org/abs/2305.11913](http://arxiv.org/abs/2305.11913)

    本文提出了一种基于神经网络的方法，利用高度现实的合成训练数据对稀疏雷达数据进行相位相关的波浪表面重建。

    

    准确预测相位相关的水波条件对于海洋工程的决策至关重要。然而，远程监测波浪预测模型的初始化首先需要从类似雷达的稀疏测量中重建波浪表面。现有的重建方法要么依赖于计算密集型的优化过程，要么依赖于简化的模型假设，这会影响整个预测过程的实时性或准确性。因此，我们提出了一种基于U-Net和Fourier神经算子（FNO）结构的神经网络方法，用于相位相关的波浪表面重建。我们的方法利用具有高度现实性的合成训练数据，这些数据在均匀的一维网格上由波浪模拟的高阶谱方法和几何雷达建模方法生成。研究结果表明，两种模型都可以提供准确的波浪重建结果。

    Accurate short-term prediction of phase-resolved water wave conditions is crucial for decision-making in ocean engineering. However, the initialization of remote-sensing-based wave prediction models first requires a reconstruction of wave surfaces from sparse measurements like radar. Existing reconstruction methods either rely on computationally intensive optimization procedures or simplistic modeling assumptions that compromise real-time capability or accuracy of the entire prediction process. We therefore address these issues by proposing a novel approach for phase-resolved wave surface reconstruction using neural networks based on the U-Net and Fourier neural operator (FNO) architectures. Our approach utilizes synthetic yet highly realistic training data on uniform one-dimensional grids, that is generated by the high-order spectral method for wave simulation and a geometric radar modeling approach. The investigation reveals that both models deliver accurate wave reconstruction resul
    
[^116]: LLM在医学系统综述中的潜在用途和风险评估

    Appraising the Potential Uses and Harms of LLMs for Medical Systematic Reviews. (arXiv:2305.11828v1 [cs.CL])

    [http://arxiv.org/abs/2305.11828](http://arxiv.org/abs/2305.11828)

    本文研究了使用LLM协助制作医学证据综述的潜在用途和风险，指出LLM有可能自动生成文献综述，但由于可能出现虚构或遗漏信息的情况，LLM的使用需要谨慎。

    

    医学系统综述对于制定临床决策和医疗政策至关重要。但是制作这样的综述很费力且耗时。因此，很多问题缺乏高质量的证据综述，即使这些综述可用，在审查过程中可能已经过时。现在，大型语言模型（LLM）已经能够生成长篇文本，这意味着自动生成文献综述的诱人可能性。然而，由于虚构或遗漏重要信息，LLM有时会产生不准确（甚至可能具有误导性）的文本。在医疗保健环境中，这可能使LLM在最好情况下无法使用，在最坏情况下会带来危险。对于LLM的益处和风险的大多数讨论与具体应用脱离了关系。在这项工作中，我们试图定性描述LLM在协助制作医学证据综述方面的潜在用途和风险。我们对16位国际专家进行了半结构化访谈。

    Medical systematic reviews are crucial for informing clinical decision making and healthcare policy. But producing such reviews is onerous and time-consuming. Thus, high-quality evidence synopses are not available for many questions and may be outdated even when they are available. Large language models (LLMs) are now capable of generating long-form texts, suggesting the tantalizing possibility of automatically generating literature reviews on demand. However, LLMs sometimes generate inaccurate (and potentially misleading) texts by hallucinating or omitting important information. In the healthcare context, this may render LLMs unusable at best and dangerous at worst. Most discussion surrounding the benefits and risks of LLMs have been divorced from specific applications. In this work, we seek to qualitatively characterize the potential utility and risks of LLMs for assisting in production of medical evidence reviews. We conducted 16 semi-structured interviews with international experts
    
[^117]: 大型语言模型中的内部一致性问题研究：通过辩论进行深入分析

    Diving into the Inter-Consistency of Large Language Models: An Insightful Analysis through Debate. (arXiv:2305.11595v1 [cs.CL])

    [http://arxiv.org/abs/2305.11595](http://arxiv.org/abs/2305.11595)

    本文提出了通过辩论探究大型语言模型之间的内部一致性问题，实验证明通过严格的辩论框架可以提高模型性能和常识知识的结构化学习。

    

    大型语言模型LLMs在各种自然语言处理NLP任务中展现出了惊人的零样本或少量样本通识推理性能。然而，尽管它们拥有强大的常识推理能力，但它们仍然存在各种不一致问题。本研究提出探索两个或多个LLMs之间的内部一致性问题，这对于不同和精确的决策过程至关重要。通过严格的辩论框架，在7个常识推理数据集上进行了广泛的实验。LLMs不仅通过妥协和反驳变得更具内部一致性，而且还实现了更高的性能和常识知识的结构化学习。

    Large language models (LLMs) have demonstrated impressive zero-shot or few-shot commonsense reasoning performance on various natural language processing (NLP) tasks. However, despite their strong commonsense reasoning abilities, LLMs still exhibit various kinds of inconsistency problems. While previous researches mainly focused on the self-consistency within a single LLM, we propose to explore the inter-consistency issue between two or more LLMs, which is critical for diverse and precise decision-making processes. Since the LLMs possess human-like intelligence after instruction tuning and reinforcement learning with human feedback (RLHF), we design a formal debate framework to delve into the inter-consistency problem among LLMs with three-stage debate: fair debate, mismatched debate, and roundtable debate. Through extensive experiments on 7 commonsense reasoning datasets, LLMs not only become more inter-consistent by compromising and refuting but also achieve higher performance and str
    
[^118]: “即插即用”医疗对话系统

    Plug-and-Play Medical Dialogue System. (arXiv:2305.11508v1 [cs.CL])

    [http://arxiv.org/abs/2305.11508](http://arxiv.org/abs/2305.11508)

    该论文提出了一种即插即用的医疗对话系统，使用大型语言模型实现医疗问答及诊断策略，避免了传统昂贵的LLMs微调。

    

    医疗对话系统旨在为患者提供准确的答案，需要特定的领域知识。大型语言模型（LLMs）的最近进展已经证明了其在医疗问答领域具有杰出的能力，表明具备了对常识的丰富理解。然而，由于缺乏诊断策略，LLMs无法直接用于诊断。传统的解决方法是昂贵的LLMs微调。另一种更具吸引力的解决方法是开发一个插件，赋予LLMs执行医疗对话任务的能力。受到上下文学习的启发，我们提出了PlugMed，一个即插即用的医疗对话系统，通过两个模块促进了LLMs的恰当对话动作：提示生成（PG）模块和回复排名（RR）模块。PG模块旨在从全局和局部角度捕获对话信息。它通过评估匹配度来选择合适的提示。

    Medical dialogue systems aim to provide accurate answers to patients, necessitating specific domain knowledge. Recent advancements in Large Language Models (LLMs) have demonstrated their exceptional capabilities in the medical Q&A domain, indicating a rich understanding of common sense. However, LLMs are insufficient for direct diagnosis due to the absence of diagnostic strategies. The conventional approach to address this challenge involves expensive fine-tuning of LLMs. Alternatively, a more appealing solution is the development of a plugin that empowers LLMs to perform medical conversation tasks. Drawing inspiration from in-context learning, we propose PlugMed, a Plug-and-Play Medical Dialogue System that facilitates appropriate dialogue actions by LLMs through two modules: the prompt generation (PG) module and the response ranking (RR) module. The PG module is designed to capture dialogue information from both global and local perspectives. It selects suitable prompts by assessing 
    
[^119]: Clifford群等变神经网络

    Clifford Group Equivariant Neural Networks. (arXiv:2305.11141v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2305.11141](http://arxiv.org/abs/2305.11141)

    我们引入了Clifford群等变神经网络，它可以构建O(n)和E(n)等变模型。该方法通过调整Clifford群的定义以及保持向量空间和乘法结构的作用来实现多个有利属性。

    

    我们引入了Clifford群等变神经网络：一种构建O(n)和E(n)等变模型的新方法。我们确定并研究了Clifford群，它是Clifford代数中的一个子群，其定义经过调整以实现多个有利属性。主要地，该群的作用形成了一个正交自同构，扩展到整个Clifford代数，同时尊重多矢分级。这导致了对应于多矢分解的多个非等价子表示。此外，我们证明该作用不仅尊重Clifford代数的向量空间结构，还尊重其乘法结构，即几何乘积。这些发现意味着我们可以得到在任意维的内积空间中优雅地推广的表达层。我们特别展示了从一个sin

    We introduce Clifford Group Equivariant Neural Networks: a novel approach for constructing $\mathrm{O}(n)$- and $\mathrm{E}(n)$-equivariant models. We identify and study the $\textit{Clifford group}$, a subgroup inside the Clifford algebra whose definition we adjust to achieve several favorable properties. Primarily, the group's action forms an orthogonal automorphism that extends beyond the typical vector space to the entire Clifford algebra while respecting the multivector grading. This leads to several non-equivalent subrepresentations corresponding to the multivector decomposition. Furthermore, we prove that the action respects not just the vector space structure of the Clifford algebra but also its multiplicative structure, i.e., the geometric product. These findings imply that every polynomial in multivectors, An advantage worth mentioning is that we obtain expressive layers that can elegantly generalize to inner-product spaces of any dimension. We demonstrate, notably from a sin
    
[^120]: 不要用明文上传测试数据：减轻数据外泄对于评估基准的持续影响的实用策略

    Stop Uploading Test Data in Plain Text: Practical Strategies for Mitigating Data Contamination by Evaluation Benchmarks. (arXiv:2305.10160v1 [cs.CL])

    [http://arxiv.org/abs/2305.10160](http://arxiv.org/abs/2305.10160)

    提出了三个适用策略：（1）公钥加密发布测试数据，仅允许特定派生发布；（2）对于API持有方，要求训练排除控制，保护测试数据，不停止评估直到达到要求；（3）如果测试数据来自互联网文本，需避免某些结果的使用。

    

    随着预训练模型在自动爬网资料库的大规模应用，数据外泄变得常见且部分难以应对。对于那些不会公开训练数据的模型，其数据成为了商业机密，即使在公开模型中，确定特定测试实例是否被泄露也不是一件容易的事情。本文提出三个可行的策略：（1）使用公钥加密发布的测试数据并限制派生发布的许可；（2）要求持有API训练数据的公司采用训练排除控制，并拒绝评估，直到训练排除控制无误为止；（3）如果测试数据来自互联网文本，那么需避免在网络搜索中出现包含正确提取部分的数据。

    Data contamination has become especially prevalent and challenging with the rise of models pretrained on very large, automatically-crawled corpora. For closed models, the training data becomes a trade secret, and even for open models, it is not trivial to ascertain whether a particular test instance has been compromised. Strategies such as live leaderboards with hidden answers, or using test data which is guaranteed to be unseen, are expensive and become fragile with time. Assuming that all relevant actors value clean test data and will cooperate to mitigate data contamination, what can be done? We propose three strategies that can make a difference: (1) Test data made public should be encrypted with a public key and licensed to disallow derivative distribution; (2) demand training exclusion controls from closed API holders, and protect your test data by refusing to evaluate until demands are met; (3) in case of test data based on internet text, avoid data which appears with its soluti
    
[^121]: 搜索UGLE真相：无监督GNN学习环境的调查

    Search for the UGLE Truth: An Investigation into Unsupervised GNN Learning Environments. (arXiv:2305.06026v1 [cs.LG])

    [http://arxiv.org/abs/2305.06026](http://arxiv.org/abs/2305.06026)

    本文提出了一种GNN学习环境下的社区检测算法比较框架，包括数据集和评估指标，以解决目前文献中对于基于GNN的社区检测缺乏公平且严谨评估的问题。

    

    图神经网络 (GNN) 是任何机器学习任务中的一个重要工具，因为它们能够学习图结构上的函数，这是一种强大和表达性强的数据表示。社区检测是一种无监督任务，越来越多地使用GNN进行。利用节点特征的多维度与图的连接性对图中的节点进行聚类，对从社交网络到基因组学的真实世界任务有许多应用。不幸的是，目前文献中缺乏公平且严谨评估基于GNN的社区检测的充分基准环境，从而可能阻碍这一新兴领域的进展。我们观察到这种情况下的特定困难是模糊的超参数调整环境与性能和评估数据集的冲突指标。在这项工作中，我们提出和评估了框架，用于在GNN学习环境中进行一致的社区检测算法比较。我们提供了一个基准数据集，并提出了评估指标，反映了检测到的社区的内在质量以及聚类的准确性。

    Graph Neural Networks (GNNs) are a pertinent tool for any machine learning task due to their ability to learn functions over graph structures, a powerful and expressive data representation. The detection of communities, an unsupervised task has increasingly been performed with GNNs. Clustering nodes in a graph using the multi-dimensionality of node features with the connectivity of the graph has many applications to real world tasks from social networks to genomics. Unfortunately, there is currently a gap in the literature with no established sufficient benchmarking environment for fairly and rigorously evaluating GNN based community detection, thereby potentially impeding progress in this nascent field. We observe the particular difficulties in this setting is the ambiguous hyperparameter tuning environments combined with conflicting metrics of performance and evaluation datasets. In this work, we propose and evaluate frameworks for the consistent comparisons of community detection al
    
[^122]: DeformerNet: 学习三维可塑物体的双手操纵

    DeformerNet: Learning Bimanual Manipulation of 3D Deformable Objects. (arXiv:2305.04449v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2305.04449](http://arxiv.org/abs/2305.04449)

    本论文介绍了一种名为DeformerNet的神经网络架构，通过学习三维可塑物体的低维表示来实现机器人对物体形状的操纵。这种方法不需要手工特征和物体特定的控制模型，可在仿真和真实机器人上进行演示和应用。

    

    从家庭护理到仓库配送再到外科手术助理等领域，应用需要机器人可靠地操纵三维可塑物体的形状。弹性三维可塑物体的分析模型需要大量参数来描述决定物体形状的可能无限自由度。以往的3D形状控制尝试依赖于手工特征来表示物体形状，并需要训练物体特定的控制模型。我们通过使用我们的新型DeformerNet神经网络架构来克服这些问题，该架构在被操纵物体的部分视图点云和目标形状的点云上运行，学习物体形状的低维表示。这个形状嵌入使机器人能够学习一种视觉伺服控制器，该控制器计算出所需的机器人末端执行器动作，将物体迭代地变形向目标形状。我们在仿真和真实机器人上演示了这一点。

    Applications in fields ranging from home care to warehouse fulfillment to surgical assistance require robots to reliably manipulate the shape of 3D deformable objects. Analytic models of elastic, 3D deformable objects require numerous parameters to describe the potentially infinite degrees of freedom present in determining the object's shape. Previous attempts at performing 3D shape control rely on hand-crafted features to represent the object shape and require training of object-specific control models. We overcome these issues through the use of our novel DeformerNet neural network architecture, which operates on a partial-view point cloud of the manipulated object and a point cloud of the goal shape to learn a low-dimensional representation of the object shape. This shape embedding enables the robot to learn a visual servo controller that computes the desired robot end-effector action to iteratively deform the object toward the target shape. We demonstrate both in simulation and on 
    
[^123]: Vera：一个用于通用常识语句可信度评估的模型

    Vera: A General-Purpose Plausibility Estimation Model for Commonsense Statements. (arXiv:2305.03695v1 [cs.CL])

    [http://arxiv.org/abs/2305.03695](http://arxiv.org/abs/2305.03695)

    本文提出了Vera模型，它是一个通用模型，可以基于常识知识估计陈述性语句的可信度。在解决验证格式的常识问题时，Vera明显优于现有的模型，并展现了对未见任务的泛化能力和良好的标定输出。

    

    尽管当今的语言模型在许多方面表现出色，但它们仍然容易出现荒谬和意外的常识失败。本文提出了一种回顾性验证方法，反思LM输出的正确性，并引入了Vera，一个通用模型，它基于常识知识估计陈述性语句的可信度。通过使用19个QA数据集和两个大规模知识库创建的约700万条常识语句以及三个训练目标的组合进行训练，Vera是一个多功能模型，可以有效地区分各种常识领域中的正确和错误语句。当应用于解决验证格式的常识问题时，Vera明显优于现有的可重用于常识验证的模型，并且它进一步展示了对未见任务的泛化能力并提供了良好的标定输出。我们发现Vera在过滤LM生成的常识知识方面表现突出，可以潜在地增强它们的可信度和实际应用。

    Despite the much discussed capabilities of today's language models, they are still prone to silly and unexpected commonsense failures. We consider a retrospective verification approach that reflects on the correctness of LM outputs, and introduce Vera, a general-purpose model that estimates the plausibility of declarative statements based on commonsense knowledge. Trained on ~7M commonsense statements created from 19 QA datasets and two large-scale knowledge bases, and with a combination of three training objectives, Vera is a versatile model that effectively separates correct from incorrect statements across diverse commonsense domains. When applied to solving commonsense problems in the verification format, Vera substantially outperforms existing models that can be repurposed for commonsense verification, and it further exhibits generalization capabilities to unseen tasks and provides well-calibrated outputs. We find that Vera excels at filtering LM-generated commonsense knowledge an
    
[^124]: 神经网络何时在表格数据上胜过增强树？

    When Do Neural Nets Outperform Boosted Trees on Tabular Data?. (arXiv:2305.02997v1 [cs.LG])

    [http://arxiv.org/abs/2305.02997](http://arxiv.org/abs/2305.02997)

    这项研究通过对176个数据集的比较分析发现，在许多数据集中，GBDT和NN之间的性能差异可以忽略不计，或者GBDT的轻微超参数调整比选择最佳算法更重要。此外，研究人员对965个元特征进行了分析，发现GBDT在高维稀疏数据上表现更好。

    

    表格数据是机器学习中最常用的数据类型之一。尽管神经网络（NN）在表格数据上取得了最近的进展，但人们仍在积极讨论NN是否通常优于梯度提升决策树（GBDT）在表格数据上的表现，一些最近的工作要么认为GBDT在表格数据上一贯优于NN，要么认为NN优于GBDT。在这项工作中，我们退一步问：'这重要吗？'我们通过对176个数据集比较19种算法，进行了迄今为止最大的表格数据分析，并发现'NN vs. GBDT'争论被过分强调：令人惊讶的是，在相当多的数据集中，GBDT和NN之间的性能差异要么可以忽略不计，要么GBDT的轻微超参数调整比选择最佳算法更重要。接下来，我们分析了965个元特征，以确定数据集的哪些特性使NN或GBDT更适合表现良好。例如，我们发现GBDT要比NN在高维稀疏数据上表现更好。

    Tabular data is one of the most commonly used types of data in machine learning. Despite recent advances in neural nets (NNs) for tabular data, there is still an active discussion on whether or not NNs generally outperform gradient-boosted decision trees (GBDTs) on tabular data, with several recent works arguing either that GBDTs consistently outperform NNs on tabular data, or vice versa. In this work, we take a step back and ask, 'does it matter?' We conduct the largest tabular data analysis to date, by comparing 19 algorithms across 176 datasets, and we find that the 'NN vs. GBDT' debate is overemphasized: for a surprisingly high number of datasets, either the performance difference between GBDTs and NNs is negligible, or light hyperparameter tuning on a GBDT is more important than selecting the best algorithm. Next, we analyze 965 metafeatures to determine what properties of a dataset make NNs or GBDTs better-suited to perform well. For example, we find that GBDTs are much better th
    
[^125]: 超越多链思维：基于元推理的问题解答方法

    Answering Questions by Meta-Reasoning over Multiple Chains of Thought. (arXiv:2304.13007v1 [cs.CL])

    [http://arxiv.org/abs/2304.13007](http://arxiv.org/abs/2304.13007)

    本论文提出了基于元推理的Multi-Chain Reasoning (MCR)方法，该方法检查多个推理链，混合它们之间的信息并选择最相关的事实，从而超越多链思维，解决多跳QA问题。 实验结果表明MCR胜过多个强基线，解释质量高。

    

    现代多跳问题解答（QA）系统通常将问题分解为一系列思考步骤（CoT），然后才得出最终答案。通常来说，多个链条被抽样并通过最终答案的投票机制进行聚合，但中间步骤本身被丢弃。虽然这种方法提高了性能，但它们并不考虑链之间的中间步骤之间的关系，并且不提供预测答案的统一解释。我们引入了基于元推理的 Multi-Chain Reasoning (MCR) 方法，该方法利用大型语言模型来超越多个思考链，而不是聚合回答。MCR检查不同的推理链，混合它们之间的信息并选择在生成解释和预测答案时最相关的事实。MCR在7个多跳QA数据集上胜过强基线。此外，我们的分析表明MCR的解释具有高质量。

    Modern systems for multi-hop question answering (QA) typically break questions into a sequence of reasoning steps, termed chain-of-thought (CoT), before arriving at a final answer. Often, multiple chains are sampled and aggregated through a voting mechanism over the final answers, but the intermediate steps themselves are discarded. While such approaches improve performance, they do not consider the relations between intermediate steps across chains and do not provide a unified explanation for the predicted answer. We introduce Multi-Chain Reasoning (MCR), an approach which prompts large language models to meta-reason over multiple chains of thought, rather than aggregating their answers. MCR examines different reasoning chains, mixes information between them and selects the most relevant facts in generating an explanation and predicting the answer. MCR outperforms strong baselines on 7 multi-hop QA datasets. Moreover, our analysis reveals that MCR explanations exhibit high quality, en
    
[^126]: SkillGPT: 一种使用大型语言模型进行技能提取和标准化的RESTful API服务

    SkillGPT: a RESTful API service for skill extraction and standardization using a Large Language Model. (arXiv:2304.11060v1 [cs.CL])

    [http://arxiv.org/abs/2304.11060](http://arxiv.org/abs/2304.11060)

    SkillGPT是一种使用大型语言模型进行技能提取和标准化的RESTful API服务，通过摘要和向量相似性搜索平衡速度和准确度。

    

    我们提出了 SkillGPT，一种利用开源的大型语言模型 (LLM) 进行从自由风格职位描述和用户资料中进行技能提取和标准化 (SES) 的工具。与大多数类似任务的以前方法不同，SkillGPT 直接使用最新的对话 LLM 进行标准技能的提示，通过摘要和向量相似性搜索来平衡速度和准确度。因此，我们的免费 SkillGPT 让用户能够高效可靠地进行对话型 SES。

    We present SkillGPT, a tool for skill extraction and standardization (SES) from free-style job descriptions and user profiles with an open-source Large Language Model (LLM) as backbone. Most previous methods for similar tasks either need supervision or rely on heavy data-preprocessing and feature engineering. Directly prompting the latest conversational LLM for standard skills, however, is slow, costly and inaccurate. In contrast, SkillGPT utilizes a LLM to perform its tasks in steps via summarization and vector similarity search, to balance speed with precision. The backbone LLM of SkillGPT is based on Llama, free for academic use and thus useful for exploratory research and prototype development. Hence, our cost-free SkillGPT gives users the convenience of conversational SES, efficiently and reliably.
    
[^127]: Nerfbusters：从随意捕获的NeRF中去除幽灵似的图像伪影

    Nerfbusters: Removing Ghostly Artifacts from Casually Captured NeRFs. (arXiv:2304.10532v1 [cs.CV])

    [http://arxiv.org/abs/2304.10532](http://arxiv.org/abs/2304.10532)

    通过使用新的数据集和评估程序，提出了一种使用3D扩散优先级别加上新颖的基于密度的得分蒸馏采样损失的方法来防止NeRF优化过程中出现图形伪影的解决方案。

    

    随意捕获的神经辐射场（NeRF）在渲染摄像机轨迹之外时会出现浮点错误或有缺陷的几何图形等伪影。现有的评估协议通常无法捕捉这些效应，因为通常仅在训练抓取的每个第八帧评估图像质量。为了推动新视角合成的进展，我们提出了一个新的数据集和评估程序，其中记录了场景的两个摄像机轨迹：一个用于训练，另一个用于评估。在这种更具挑战性的实际环境中，我们发现现有的手工制作的规则不仅不能去除浮点错误，而且也不能改善场景几何形状。因此，我们提出了一种基于3D扩散的方法，该方法利用本地3D先验和新颖的基于密度的得分蒸馏采样损失，在NeRF优化过程中防止出现伪像现象。我们展示了这种基于数据的优先级别能够去除浮点错误并改善随意捕获的场景几何形状。

    Casually captured Neural Radiance Fields (NeRFs) suffer from artifacts such as floaters or flawed geometry when rendered outside the camera trajectory. Existing evaluation protocols often do not capture these effects, since they usually only assess image quality at every 8th frame of the training capture. To push forward progress in novel-view synthesis, we propose a new dataset and evaluation procedure, where two camera trajectories are recorded of the scene: one used for training, and the other for evaluation. In this more challenging in-the-wild setting, we find that existing hand-crafted regularizers do not remove floaters nor improve scene geometry. Thus, we propose a 3D diffusion-based method that leverages local 3D priors and a novel density-based score distillation sampling loss to discourage artifacts during NeRF optimization. We show that this data-driven prior removes floaters and improves scene geometry for casual captures.
    
[^128]: 好奇心驱动探索中欧氏群与射影群对于智能体内部空间的作用：形式化分析

    Action of the Euclidean versus Projective group on an agent's internal space in curiosity driven exploration: a formal analysis. (arXiv:2304.00188v1 [cs.AI])

    [http://arxiv.org/abs/2304.00188](http://arxiv.org/abs/2304.00188)

    该论文将人类空间感知的3D射影几何学与智能体感知方案中的群概念相结合，探讨不同群结构如何影响智能体的好奇心驱动探索行为。

    

    在人类的空间感知中，信息似乎是根据三维射影几何学表示的。它将信息集成和行动规划组织在一个内部表示空间中。不同个体的第一人称视角是如何通过世界模型的变换相互关联，并定义智能体的特定感知方案。这些变换的集合在数学上被称为“群”，它通过对几何空间的操作来表征其特征。我们提出将拥有“几何”结构的世界模型，给出由群提供的一种方式来捕捉代理之间不同的感知方案。我们探讨了改变世界模型的几何结构如何影响智能体的行为。具体而言，我们着眼于这些几何运算如何通过在驱动智能体好奇心的主观推断的形式表达上进行转换，并相应地影响探索行为。我们使用了群作用。

    In human spatial awareness, information appears to be represented according to 3-D projective geometry. It structures information integration and action planning within an internal representation space. The way different first person perspectives of an agent relate to each other, through transformations of a world model, defines a specific perception scheme for the agent. In mathematics, this collection of transformations is called a `group' and it characterizes a geometric space by acting on it. We propose that imbuing world models with a `geometric' structure, given by a group, is one way to capture different perception schemes of agents. We explore how changing the geometric structure of a world model impacts the behavior of an agent.  In particular, we focus on how such geometrical operations transform the formal expression of epistemic value in active inference as driving an agent's curiosity about its environment, and impact exploration behaviors accordingly. We used group action
    
[^129]: 用于神经退行性疾病结构病理相关性定量分析的高分辨率7T离体MRI的自动化深度学习分割

    Automated deep learning segmentation of high-resolution 7 T ex vivo MRI for quantitative analysis of structure-pathology correlations in neurodegenerative diseases. (arXiv:2303.12237v1 [cs.CV])

    [http://arxiv.org/abs/2303.12237](http://arxiv.org/abs/2303.12237)

    本文提出了一个深度学习分割管道，用于离体MRI图像的自动化分割。基于37个标本的高分辨率7 T MRI图像，该方法可准确分割整个脑半球，包括皮层、皮质下结构、白质高信号以及正常出现的白质。该方法可为神经病理学研究提供帮助。

    

    相较于在 vivo MRI，大脑离体 MRI 提供了明显的优势，可用于可视化和表征详细的神经解剖，协助将微观组织学研究与形态测量相联系。然而，由于受限于标记数据集的有限可用性和扫描器硬件和采集协议的异质性，离体 MRI 的脑区域分割自动化方法并不发达。在本研究中，我们提出了一个高分辨率数据集，包含在7T全身MRI扫描器上扫描的37个离体人脑组织标本。我们开发了一个深度学习管道来分割皮层，通过对九种深度神经体系结构的性能进行基准测试。然后，我们对四个皮质下结构（尾状核，脑豆核，苍白球和丘脑）、白质高信号以及正常出现的白质进行分割。我们展示了不同标本的全脑半球之间的出色的泛化能力，也展示了在看不见的硬件上的泛化能力。我们的方法有潜力提高神经病理学和神经退行性疾病结构病理相关性的定量分析的效率和准确性。

    Ex vivo MRI of the brain provides remarkable advantages over in vivo MRI for visualizing and characterizing detailed neuroanatomy, and helps to link microscale histology studies with morphometric measurements. However, automated segmentation methods for brain mapping in ex vivo MRI are not well developed, primarily due to limited availability of labeled datasets, and heterogeneity in scanner hardware and acquisition protocols. In this work, we present a high resolution dataset of 37 ex vivo post-mortem human brain tissue specimens scanned on a 7T whole-body MRI scanner. We developed a deep learning pipeline to segment the cortical mantle by benchmarking the performance of nine deep neural architectures. We then segment the four subcortical structures: caudate, putamen, globus pallidus, and thalamus; white matter hyperintensities, and the normal appearing white matter. We show excellent generalizing capabilities across whole brain hemispheres in different specimens, and also on unseen i
    
[^130]: Taylor TD学习

    Taylor TD-learning. (arXiv:2302.14182v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.14182](http://arxiv.org/abs/2302.14182)

    Taylor TD是一个基于模型的RL框架，通过使用TD更新的泰勒级数展开，减少了连续状态-动作设置中的方差，并具有与标准TD学习相同的稳定学习保证。TaTD3是Taylor TD与TD3算法相结合所形成的方法，其表现优于一些最先进的无模型和基于模型的基准。

    

    许多强化学习方法依赖于时间差分（TD）学习来学习一个评论家。然而，TD学习的更新可能具有较高的方差。在这里，我们引入了一个基于模型的RL框架，即Taylor TD，它减少了连续状态-动作设置中的方差。Taylor TD使用TD更新的一阶泰勒级数展开。该展开允许Taylor TD在行动选择的随机性和每个TD更新的初始状态和动作的状态分布的一些随机性上进行分析积分。我们提供理论和实证证据，证明Taylor TD的更新确实比标准的TD更新具有较低的方差。此外，我们还展示了在合理的假设下，Taylor TD具有与线性函数逼近下的标准TD学习相同的稳定学习保证。接下来，我们将Taylor TD与TD3算法相结合，形成TaTD3。我们展示TaTD3的表现与几种最先进的无模型和基于模型的基准相当，甚至更好。

    Many reinforcement learning approaches rely on temporal-difference (TD) learning to learn a critic. However, TD-learning updates can be high variance. Here, we introduce a model-based RL framework, Taylor TD, which reduces this variance in continuous state-action settings. Taylor TD uses a first-order Taylor series expansion of TD updates. This expansion allows Taylor TD to analytically integrate over stochasticity in the action-choice, and some stochasticity in the state distribution for the initial state and action of each TD update. We include theoretical and empirical evidence that Taylor TD updates are indeed lower variance than standard TD updates. Additionally, we show Taylor TD has the same stable learning guarantees as standard TD-learning with linear function approximation under a reasonable assumption. Next, we combine Taylor TD with the TD3 algorithm, forming TaTD3. We show TaTD3 performs as well, if not better, than several state-of-the art model-free and model-based basel
    
[^131]: 在未知环境中为时间任务建立复杂自然语言命令的基础

    Grounding Complex Natural Language Commands for Temporal Tasks in Unseen Environments. (arXiv:2302.11649v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2302.11649](http://arxiv.org/abs/2302.11649)

    该论文提出了一个名为Lang2LTL的模块化系统和软件包，利用大型语言模型将导航命令与LTL规范进行关联。通过在没有先前语言数据的环境中全面评估Lang2LTL，证明了其在21个城市级规模的环境中与各种时态规范进行关联的最先进能力。并且通过展示物理机器人在两个室内环境中可以遵循52个语义多样的导航命令，进一步验证了Lang2LTL的实际应用价值。

    

    将导航命令与线性时态逻辑 (LTL) 进行关联，利用其明确的语义来推理长程任务和验证时间约束的满足性。现有方法需要来自特定环境和用于理解这些环境中的命令的地标的训练数据。我们提出了Lang2LTL，这是一个模块化系统和一个软件包，利用大型语言模型 (LLM) 在没有先前语言数据的环境中将时态导航命令与LTL规范进行关联。我们对Lang2LTL进行了五个明确定义的泛化行为的全面评估。Lang2LTL在21个城市级规模的环境中展示了单个模型将导航命令与各种时态规范进行关联的最先进能力。最后，我们展示了一个使用Lang2LTL的物理机器人在两个室内环境中遵循52个语义多样的导航命令的能力。

    Grounding navigational commands to linear temporal logic (LTL) leverages its unambiguous semantics for reasoning about long-horizon tasks and verifying the satisfaction of temporal constraints. Existing approaches require training data from the specific environment and landmarks that will be used in natural language to understand commands in those environments. We propose Lang2LTL, a modular system and a software package that leverages large language models (LLMs) to ground temporal navigational commands to LTL specifications in environments without prior language data. We comprehensively evaluate Lang2LTL for five well-defined generalization behaviors. Lang2LTL demonstrates the state-of-the-art ability of a single model to ground navigational commands to diverse temporal specifications in 21 city-scaled environments. Finally, we demonstrate a physical robot using Lang2LTL can follow 52 semantically diverse navigational commands in two indoor environments.
    
[^132]: SHINE: 基于深度学习的无障碍停车管理系统

    SHINE: Deep Learning-Based Accessible Parking Management System. (arXiv:2302.00837v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.00837](http://arxiv.org/abs/2302.00837)

    SHINE是一个基于深度学习的无障碍停车管理系统，能够实时识别停放在无障碍停车位上的车辆，并具备可访问性监测功能。实验结果表明，SHINE优于现有的车牌识别系统。

    

    科技的进步推动了城市区域的不断扩张，全世界私人车辆数量相应增加，其中韩国也不例外。这种车辆数量逐步增加也带来了与停车有关的问题，其中包括为残疾人指定的残疾人停车位被滥用。传统的车牌识别系统由于监控摄像头高帧率、自然和人为噪声的存在以及光照和天气条件的变化而导致实时检测和识别效率低下，难以有效解决这些问题。本文提出了SHINE，一个基于深度学习的无障碍停车管理系统，用于实时无障碍性监测和识别停放在无障碍停车位上的车辆。SHINE由两个主要组件组成：基于深度卷积神经网络的车牌识别系统和无障碍停车管理系统。此外，我们提供了一个数据集，包括从4个不同时段拍摄的21个无障碍停车位的4,780张图像，以评估SHINE的性能。实验结果表明，SHINE优于现有的车牌识别系统，在识别率和可访问性监测方面都达到了令人满意的结果。

    The ongoing expansion of urban areas facilitated by advancements in science and technology has resulted in a considerable increase in the number of privately owned vehicles worldwide, including in South Korea. However, this gradual increment in the number of vehicles has inevitably led to parking-related issues, including the abuse of disabled parking spaces (hereafter referred to as accessible parking spaces) designated for individuals with disabilities. Traditional license plate recognition (LPR) systems have proven inefficient in addressing such a problem in real-time due to the high frame rate of surveillance cameras, the presence of natural and artificial noise, and variations in lighting and weather conditions that impede detection and recognition by these systems. With the growing concept of parking 4.0, many sensors, IoT and deep learning-based approaches have been applied to automatic LPR and parking management systems. Nonetheless, the studies show a need for a robust and eff
    
[^133]: 学习用于排名的列表级别领域不变表示

    Learning List-Level Domain-Invariant Representations for Ranking. (arXiv:2212.10764v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2212.10764](http://arxiv.org/abs/2212.10764)

    本文提出了一种针对排名问题的列表级别对齐的学习方法，该方法利用列表的结构特性，在领域适应中实现从源领域到目标领域的知识转移。

    

    领域适应旨在将在（数据丰富）源领域学到的知识转移到（资源有限）目标领域，一种常用的方法是不变表示学习，它匹配并对齐特征空间上的数据分布。尽管这种方法在分类和回归问题上得到了广泛研究和应用，但在排名问题上的应用却是零散的，并且现有的几种实现缺乏理论上的证明。本文重新审视了用于排名的不变表示学习。在审查之前的工作时，我们发现他们实施了我们称之为项目级别对齐的方法，该方法在聚合的所有列表中对进行排名的项目分布进行对齐，但忽略了列表的结构。然而，列表的结构应该被利用，因为它是排名问题的固有特性，其中数据和度量是在列表上定义和计算的，而不是在项目本身上。为了解决这一不一致，我们提出了列表级别对齐的学习

    Domain adaptation aims to transfer the knowledge learned on (data-rich) source domains to (low-resource) target domains, and a popular method is invariant representation learning, which matches and aligns the data distributions on the feature space. Although this method is studied extensively and applied on classification and regression problems, its adoption on ranking problems is sporadic, and the few existing implementations lack theoretical justifications. This paper revisits invariant representation learning for ranking. Upon reviewing prior work, we found that they implement what we call item-level alignment, which aligns the distributions of the items being ranked from all lists in aggregate but ignores their list structure. However, the list structure should be leveraged, because it is intrinsic to ranking problems where the data and the metrics are defined and computed on lists, not the items by themselves. To close this discrepancy, we propose list-level alignment -learning
    
[^134]: 计划与学习：自主车辆的路径规划——文献综述

    Planning and Learning: Path-Planning for Autonomous Vehicles, a Review of the Literature. (arXiv:2207.13181v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2207.13181](http://arxiv.org/abs/2207.13181)

    这篇综述主要介绍了当前关于规划、调度和学习的最新工作，包括先进的规划算法、神经网络和图神经网络、增强学习方法以及将神经网络应用于路径规划的成功方法。

    

    这篇简短综述旨在让读者熟悉与规划、调度和学习相关的最新工作。首先，我们研究了最先进的规划算法。我们简要介绍了神经网络的概念。然后，我们更详细地探讨了图神经网络，这是一种适用于处理图结构输入的最新变体。我们简要描述了增强学习算法的概念和一些迄今为止设计的方法。接下来，我们研究了一些成功将神经网络与路径规划相结合的方法。最后，我们专注于具有不确定性的时态规划问题。

    This short review aims to make the reader familiar with state-of-the-art works relating to planning, scheduling and learning. First, we study state-of-the-art planning algorithms. We give a brief introduction of neural networks. Then we explore in more detail graph neural networks, a recent variant of neural networks suited for processing graph-structured inputs. We describe briefly the concept of reinforcement learning algorithms and some approaches designed to date. Next, we study some successful approaches combining neural networks for path-planning. Lastly, we focus on temporal planning problems with uncertainty.
    
[^135]: 量化方法的比较评估

    A Comparative Evaluation of Quantification Methods. (arXiv:2103.03223v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2103.03223](http://arxiv.org/abs/2103.03223)

    本研究通过对24种不同量化方法在超过40个数据集上进行全面实证比较，填补了量化方法比较研究的空白。我们发现在二分类设置中，基于阈值选择的Median Sweep和TSMax方法、DyS框架和弗里德曼的方法表现最佳；而在多分类设置中，Generaliz方法表现良好。

    

    量化是指在数据集中预测类别分布的问题。它也代表着一个在监督式机器学习中不断发展的研究领域，近年来提出了大量不同的算法。然而，目前还没有一份全面的实证比较量化方法的研究，以支持算法选择。在本研究中，我们通过对超过40个数据集进行了24种不同量化方法的彻底实证性性能比较，包括二分类和多分类量化设置，填补了这一研究空白。我们观察到没有单一算法能够在所有竞争对手中始终表现最佳，但我们确定了一组在二分类设置中表现最佳的方法，包括基于阈值选择的Median Sweep和TSMax方法、DyS框架和弗里德曼的方法。对于多分类设置，我们观察到另一组算法表现良好，包括Generaliz方法。

    Quantification represents the problem of predicting class distributions in a dataset. It also represents a growing research field in supervised machine learning, for which a large variety of different algorithms has been proposed in recent years. However, a comprehensive empirical comparison of quantification methods that supports algorithm selection is not available yet. In this work, we close this research gap by conducting a thorough empirical performance comparison of 24 different quantification methods on overall more than 40 data sets, considering binary as well as multiclass quantification settings. We observe that no single algorithm generally outperforms all competitors, but identify a group of methods including the threshold selection-based Median Sweep and TSMax methods, the DyS framework, and Friedman's method that performs best in the binary setting. For the multiclass setting, we observe that a different group of algorithms yields good performance, including the Generaliz
    
[^136]: 基于欧几里德范数诱导的Schatten-p准范则正则化在低秩张量补全和张量鲁棒主成分分析中的应用

    Euclidean-Norm-Induced Schatten-p Quasi-Norm Regularization for Low-Rank Tensor Completion and Tensor Robust Principal Component Analysis. (arXiv:2012.03436v5 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2012.03436](http://arxiv.org/abs/2012.03436)

    本文提出了一种新的张量秩正则化方法，通过计算张量的CP分量向量的欧几里德范数，间接最小化了Schatten-p准范，用于低秩张量补全和张量鲁棒主成分分析。该方法在处理大型张量时具有可扩展性，并且提供了比核范数更精确的秩代理。同时，通过比较理论分析，证明了该方法在LRTC的泛化能力上的优势。

    

    核范数和Schatten-p准范是低秩矩阵恢复中常用的秩代理。然而，在理论和实践中，计算张量的核范数或Schatten-p准范都很困难，阻碍了它们在低秩张量补全(LRTC)和张量鲁棒主成分分析(TRPCA)中的应用。本文提出了一种基于张量的CP分量向量的欧几里德范数的新类张量秩正则化器，并且证明了这些正则化器是张量Schatten-p准范的单调变换。这种连接使得我们能够通过分量向量隐式地最小化LRTC和TRPCA中的Schatten-p准范。该方法适用于大型张量，并且与核范数相比，在低秩张量恢复中提供了任意更尖锐的秩代理。另一方面，我们研究了具有Schatten-p准范正则化器和该提议正则化器的LRTC的泛化能力。定理表明

    The nuclear norm and Schatten-$p$ quasi-norm are popular rank proxies in low-rank matrix recovery. However, computing the nuclear norm or Schatten-$p$ quasi-norm of a tensor is hard in both theory and practice, hindering their application to low-rank tensor completion (LRTC) and tensor robust principal component analysis (TRPCA). In this paper, we propose a new class of tensor rank regularizers based on the Euclidean norms of the CP component vectors of a tensor and show that these regularizers are monotonic transformations of tensor Schatten-$p$ quasi-norm. This connection enables us to minimize the Schatten-$p$ quasi-norm in LRTC and TRPCA implicitly via the component vectors. The method scales to big tensors and provides an arbitrarily sharper rank proxy for low-rank tensor recovery compared to the nuclear norm. On the other hand, we study the generalization abilities of LRTC with the Schatten-$p$ quasi-norm regularizer and LRTC with the proposed regularizers. The theorems show that
    
[^137]: 模型检查器很酷：如何在Uppaal中对投票协议进行模型检查

    Model Checkers Are Cool: How to Model Check Voting Protocols in Uppaal. (arXiv:2007.12412v3 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2007.12412](http://arxiv.org/abs/2007.12412)

    本文介绍了如何使用Uppaal模型检查器对投票协议进行建模和验证，展示了对Prêter à Voter及其扩展模型的验证，并克服了模型检查器中属性规范语言的限制。

    

    设计和实现电子投票系统是一项具有挑战性的任务。形式化分析可以在这方面提供很大的帮助。特别是，它可以更好地理解投票系统的工作原理，以及对系统的要求是什么。在本文中，我们提出，最先进的模型检查器Uppaal为建模和初步验证投票协议提供了良好的环境。为了说明这一点，我们提供了Prêter à Voter的Uppaal模型，以及一些自然的扩展。我们还展示了如何验证一种变种的无票证性，尽管模型检查器中的属性规范语言具有严重的限制。

    The design and implementation of an e-voting system is a challenging task. Formal analysis can be of great help here. In particular, it can lead to a better understanding of how the voting system works, and what requirements on the system are relevant. In this paper, we propose that the state-of-art model checker Uppaal provides a good environment for modelling and preliminary verification of voting protocols. To illustrate this, we present an Uppaal model of Pr\^et \`a Voter, together with some natural extensions. We also show how to verify a variant of receipt-freeness, despite the severe limitations of the property specification language in the model checker.
    

