# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Credal Learning Theory](https://rss.arxiv.org/abs/2402.00957) | 本文提出了一种信任学习理论，通过使用凸集的概率来建模数据生成分布的变异性，从有限样本的训练集中推断出信任集，并推导出bounds。 |
| [^2] | [Learning Action-based Representations Using Invariance](https://arxiv.org/abs/2403.16369) | 提出了一种新的方法，动作双模拟编码，通过递归不变性约束扩展了单步控制性，学习了一个可以平滑折扣远期元素的多步控制度量 |
| [^3] | [From explainable to interpretable deep learning for natural language processing in healthcare: how far from reality?](https://arxiv.org/abs/2403.11894) | 该研究对医疗保健NLP中的深度学习进行了全面审查，提出了可解释和可解释的人工智能（XIAI）概念，并发现注意机制是主要新兴IAI，同时面临着缺乏全局建模、最佳实践以及系统评估和基准测试的挑战。 |
| [^4] | [Fisher Mask Nodes for Language Model Merging](https://arxiv.org/abs/2403.09891) | 介绍了一种用于Transformers的新型模型合并方法，利用Fisher信息进行加权平均，提高了多任务模型的性能。 |
| [^5] | [Simplicity in Complexity](https://arxiv.org/abs/2403.03134) | 本研究提出使用基于区段的图像表示来建模复杂性，与之前复杂的图像复杂性模型不同，这种方法既能泛化，又能为理论理解提供指导。 |
| [^6] | [Wukong: Towards a Scaling Law for Large-Scale Recommendation](https://arxiv.org/abs/2403.02545) | Wukong通过堆叠因子分解机和协同增长策略，在推荐领域建立了一个标度律，并在质量上优于现有模型。 |
| [^7] | [Wisdom of the Silicon Crowd: LLM Ensemble Prediction Capabilities Match Human Crowd Accuracy](https://arxiv.org/abs/2402.19379) | 该研究通过将十二个LLMs组成的LLM集成方法与925名人类预测者的群体预测进行比较，发现LLM群体优于简单的无信息基准，并在统计上等效于人类群体。 |
| [^8] | [Zero-shot generalization across architectures for visual classification](https://arxiv.org/abs/2402.14095) | 不同神经网络在跨架构和层间泛化到未知类别的能力存在差异，准确性并不是泛化能力的良好预测因子，泛化能力随着层深度呈非单调变化。 |
| [^9] | [Training Language Model Agents without Modifying Language Models](https://arxiv.org/abs/2402.11359) | 提出一种新的方法，在不修改语言模型的情况下训练语言模型代理，通过进化代理的功能来解决下游任务 |
| [^10] | [Hysteresis Compensation of Flexible Continuum Manipulator using RGBD Sensing and Temporal Convolutional Network](https://arxiv.org/abs/2402.11319) | 基于时间卷积网络的数据驱动方法用于捕捉柔性连续机械臂电缆驱动的非线性特性，提出了滞后补偿的解决方案。 |
| [^11] | [Large-scale Generative AI Models Lack Visual Number Sense](https://arxiv.org/abs/2402.03328) | 本研究调查了基于大规模Transformer架构的生成性AI模型是否能够准确命名物体数量或生成包含目标数量物品的图像，结果发现这些模型都没有以类似人类的方式表现，并且即使对于小数量的物体也会出现显著的错误。 |
| [^12] | [(A)I Am Not a Lawyer, But...: Engaging Legal Experts towards Responsible LLM Policies for Legal Advice](https://arxiv.org/abs/2402.01864) | 通过对法律领域进行调查，我们对使用大型语言模型（LLM）提供专业咨询的政策考虑进行了深入分析，通过基于案例的推理方法，从20名法律专家的讨论中提取了四个影响因素：用户属性、查询特征、AI能力和影响。 |
| [^13] | [Modular Neural Networks for Time Series Forecasting: Interpretability and Feature Selection using Attention](https://arxiv.org/abs/2311.16834) | 该论文提出了一种新颖的模块化神经网络模型，用于多变量时间序列预测，通过循环神经网络学习时间依赖关系，并使用基于注意力的特征选择组件实现解释性，实验结果表明其优于当前最先进的解释性神经加性模型（NAM）及其变体。 |
| [^14] | [High-fidelity Person-centric Subject-to-Image Synthesis](https://arxiv.org/abs/2311.10329) | 提出了Face-diffuser，一个有效的协作生成流水线，用于解决主体到图像合成中的训练不平衡和质量妥协问题。 |
| [^15] | [InceptionXML: A Lightweight Framework with Synchronized Negative Sampling for Short Text Extreme Classification](https://arxiv.org/abs/2109.07319) | 提出了一种轻量级框架InceptionXML，通过在embedding维度上重新分配卷积操作，应对短文本查询中的单词顺序缺失，同时提出了InceptionXML+框架，通过同步标签筛选器和极端分类器，改进了动态硬负采样技术。 |
| [^16] | [LangProp: A code optimization framework using Language Models applied to driving.](http://arxiv.org/abs/2401.10314) | LangProp是一种用于自动驾驶的代码优化框架，利用语言模型迭代优化生成的代码。它通过评估代码性能和捕捉异常来改进生成的代码，展示了在CARLA中实现自动驾驶的概念验证。 |
| [^17] | [Exploring the Privacy-Energy Consumption Tradeoff for Split Federated Learning.](http://arxiv.org/abs/2311.09441) | 本文研究了分割联邦学习（SFL）中隐私和能耗之间的权衡，强调了快速收敛的优势，并分析了切割层对客户端能耗和隐私的影响。 |
| [^18] | [From Neural Activations to Concepts: A Survey on Explaining Concepts in Neural Networks.](http://arxiv.org/abs/2310.11884) | 本文调查了解释神经网络中概念的最新方法，这对于实现基于可解释概念的神经符号化人工智能来说是重要的一步。 |
| [^19] | [RLAdapter: Bridging Large Language Models to Reinforcement Learning in Open Worlds.](http://arxiv.org/abs/2309.17176) | RLAdapter引入了一个框架，将大型语言模型（LLM）与强化学习相结合，以提高在稀疏奖励环境中的策略学习性能。这通过解决LLM在理解下游任务方面的困难，以及通过避免使用不可访问的模型权重或大量计算资源来微调LLM的方式实现。 |
| [^20] | [Cooperation Dynamics in Multi-Agent Systems: Exploring Game-Theoretic Scenarios with Mean-Field Equilibria.](http://arxiv.org/abs/2309.16263) | 本文研究在多智能体系统中激发合作的策略和方法，通过分析现有的合作策略和引入鼓励团队回报的修改，解决了在分布式系统中存在的现实困境。同时，利用均值场博弈理论，建立了无限大智能体集合中的平衡解和奖励结构。 |
| [^21] | [MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models.](http://arxiv.org/abs/2309.12284) | MetaMath是一种专门用于数学推理的微调语言模型，通过从多个角度重新编写问题来生成数学问题，并在两个基准测试中取得了优于其他开源语言模型的表现。 |
| [^22] | [Decolonial AI Alignment: Vi\'{s}esadharma, Argument, and Artistic Expression.](http://arxiv.org/abs/2309.05030) | 本文提出了去殖民化人工智能对齐的三个建议：改变基本道德哲学为达尔玛哲学，允许多元主义的论证传统存在于对齐技术中，以及将价值认识论扩展到超越自然语言中的指令。 |
| [^23] | [Compositional Learning of Visually-Grounded Concepts Using Reinforcement.](http://arxiv.org/abs/2309.04504) | 本研究探讨了深度强化学习代理如何学习和组合基于颜色和形状的组合指令，以解决空间导航任务中的新颖组合。通过利用冻结的文本编码器，代理所需的训练回合数减少了20倍。 |
| [^24] | [Diffusion Models for Computational Design at the Example of Floor Plans.](http://arxiv.org/abs/2307.02511) | 该论文探索了基于扩散模型的AI生成器在计算设计中的能力，并提出了具有改进的语义编码的新扩散模型。利用这些模型，可以提高生成楼层平面的有效性，并改进不同示例的查询性能。该研究还探讨了将扩散模型与建筑信息模型相结合的方法。 |
| [^25] | [Social AI and the Challenges of the Human-AI Ecosystem.](http://arxiv.org/abs/2306.13723) | 本文介绍了人工智能生态系统研究中出现的挑战，并探讨了社交AI提高集体问题解决能力方面的潜力，同时也需要解决新的技术和伦理问题。 |
| [^26] | [DORSal: Diffusion for Object-centric Representations of Scenes $\textit{et al.}$.](http://arxiv.org/abs/2306.08068) | DORSal提出了一种基于扩散模型的物体中心场景表示方法，可以呈现高保真新视图，并在较大程度上保留了诸如基于物体的场景编辑之类的优点。 |
| [^27] | [A Black-box Approach for Non-stationary Multi-agent Reinforcement Learning.](http://arxiv.org/abs/2306.07465) | 本文提出了一种通用的黑盒方法，适用于多种多智能体强化学习问题，可以在非平稳环境下实现低遗憾率的学习。 |
| [^28] | [Compressing neural network by tensor network with exponentially fewer variational parameters.](http://arxiv.org/abs/2305.06058) | 本文提出了一种通用的压缩方案，将神经网络的可变参数编码为多层张量网络，明显减少了可变参数的数量，并在多个神经网络和数据集上表现出了卓越的压缩性能，以VGG-16的测试精度提高为例。 |
| [^29] | [Metric Temporal Equilibrium Logic over Timed Traces.](http://arxiv.org/abs/2304.14778) | 提出了基于度量的线性时间平衡逻辑来处理涉及时间约束的动态系统问题，并给出了通过将度量公式转化为单一一阶公式实现模型检查的方法。 |
| [^30] | [Neural Common Neighbor with Completion for Link Prediction.](http://arxiv.org/abs/2302.00890) | 提出了神经通用邻居模型（NCN）用于链接预测，使用可学习的成对表示来捕捉节点之间的成对关系，以提高性能，同时解决链路不完整问题。 |
| [^31] | [Towards Unconstrained Audio Splicing Detection and Localization with Neural Networks.](http://arxiv.org/abs/2207.14682) | 研究提出了一种基于 Transformer 序列到序列（seq2seq）网络的音频拼接检测与定位方法，能够在各种攻击场景中准确检测出拼接并定位，具有普适性和鲁棒性。 |
| [^32] | [Assessing Confidence with Assurance 2.0.](http://arxiv.org/abs/2205.04522) | 本文提出了从三个方面考虑信心的属性来评估保证案例，其中主要的措施是将论证解释为逻辑证明的完备性。 |

# 详细

[^1]: 信任学习理论

    Credal Learning Theory

    [https://rss.arxiv.org/abs/2402.00957](https://rss.arxiv.org/abs/2402.00957)

    本文提出了一种信任学习理论，通过使用凸集的概率来建模数据生成分布的变异性，从有限样本的训练集中推断出信任集，并推导出bounds。

    

    统计学习理论是机器学习的基础，为从未知概率分布中学习到的模型的风险提供理论边界。然而，在实际部署中，数据分布可能会变化，导致领域适应/泛化问题。在本文中，我们建立了一个“信任”学习理论的基础，使用概率的凸集（信任集）来建模数据生成分布的变异性。我们认为，这样的信任集可以从有限样本的训练集中推断出来。对于有限假设空间（无论是否可实现）和无限模型空间，推导出界限，这直接推广了经典结果。

    Statistical learning theory is the foundation of machine learning, providing theoretical bounds for the risk of models learnt from a (single) training set, assumed to issue from an unknown probability distribution. In actual deployment, however, the data distribution may (and often does) vary, causing domain adaptation/generalization issues. In this paper we lay the foundations for a `credal' theory of learning, using convex sets of probabilities (credal sets) to model the variability in the data-generating distribution. Such credal sets, we argue, may be inferred from a finite sample of training sets. Bounds are derived for the case of finite hypotheses spaces (both assuming realizability or not) as well as infinite model spaces, which directly generalize classical results.
    
[^2]: 使用不变性学习基于动作的表示

    Learning Action-based Representations Using Invariance

    [https://arxiv.org/abs/2403.16369](https://arxiv.org/abs/2403.16369)

    提出了一种新的方法，动作双模拟编码，通过递归不变性约束扩展了单步控制性，学习了一个可以平滑折扣远期元素的多步控制度量

    

    强化学习代理使用高维度观测必须能够在许多外源性干扰中识别相关状态特征。一个能够捕捉可控性的表示通过确定影响代理控制的因素来识别这些状态元素。虽然诸如逆动力学和互信息等方法可以捕捉有限数量的时间步的可控性，但捕获长时间元素仍然是一个具有挑战性的问题。短视的可控性可以捕捉代理即将撞向墙壁的瞬间，但不能在代理还有一定距离之时捕捉墙壁的控制相关性。为解决这个问题，我们提出了动作双模拟编码，这是一种受到双模拟不变量假度量启发的方法，它通过递归不变性约束扩展了单步控制性。通过这种方式，动作双模拟学习了一个平滑折扣远期元素的多步控制度量。

    arXiv:2403.16369v1 Announce Type: cross  Abstract: Robust reinforcement learning agents using high-dimensional observations must be able to identify relevant state features amidst many exogeneous distractors. A representation that captures controllability identifies these state elements by determining what affects agent control. While methods such as inverse dynamics and mutual information capture controllability for a limited number of timesteps, capturing long-horizon elements remains a challenging problem. Myopic controllability can capture the moment right before an agent crashes into a wall, but not the control-relevance of the wall while the agent is still some distance away. To address this we introduce action-bisimulation encoding, a method inspired by the bisimulation invariance pseudometric, that extends single-step controllability with a recursive invariance constraint. By doing this, action-bisimulation learns a multi-step controllability metric that smoothly discounts dist
    
[^3]: 从可解释到可解释的深度学习在医疗自然语言处理中的应用：现实有多远？

    From explainable to interpretable deep learning for natural language processing in healthcare: how far from reality?

    [https://arxiv.org/abs/2403.11894](https://arxiv.org/abs/2403.11894)

    该研究对医疗保健NLP中的深度学习进行了全面审查，提出了可解释和可解释的人工智能（XIAI）概念，并发现注意机制是主要新兴IAI，同时面临着缺乏全局建模、最佳实践以及系统评估和基准测试的挑战。

    

    深度学习（DL）通过解决各种自然语言处理（NLP）任务，极大地增强了医疗保健研究。然而，基于DL的NLP方法日益复杂，需要透明的模型解释性，或至少是可解释性，以进行可靠的决策制定。本文对医疗健康NLP中的可解释和可解释的DL进行了彻底的范围审查。引入了术语“XIAI”（eXplainable和Interpretable Artificial Intelligence）以区分XAI和IAI。方法根据其功能（模型、输入、输出为基础）和范围（局部、全局）进一步分类。我们的分析表明，注意机制是最主要的新兴IAI。此外，IAI越来越多地用于对抗XAI。确定的主要挑战是大多数XIAI不探索“全局”建模过程，缺乏最佳实践，并且需要系统评估和基准测试。

    arXiv:2403.11894v1 Announce Type: cross  Abstract: Deep learning (DL) has substantially enhanced healthcare research by addressing various natural language processing (NLP) tasks. Yet, the increasing complexity of DL-based NLP methods necessitates transparent model interpretability, or at least explainability, for reliable decision-making. This work presents a thorough scoping review on explainable and interpretable DL in healthcare NLP. The term "XIAI" (eXplainable and Interpretable Artificial Intelligence) was introduced to distinguish XAI from IAI. Methods were further categorized based on their functionality (model-, input-, output-based) and scope (local, global). Our analysis shows that attention mechanisms were the most dominant emerging IAI. Moreover, IAI is increasingly used against XAI. The major challenges identified are that most XIAI do not explore "global" modeling processes, the lack of best practices, and the unmet need for systematic evaluation and benchmarks. Importan
    
[^4]: Fisher Mask节点用于语言模型合并

    Fisher Mask Nodes for Language Model Merging

    [https://arxiv.org/abs/2403.09891](https://arxiv.org/abs/2403.09891)

    介绍了一种用于Transformers的新型模型合并方法，利用Fisher信息进行加权平均，提高了多任务模型的性能。

    

    微调预训练模型在下游性能方面具有显著优势。预训练模型（如BERT及其衍生物）在自然语言处理中的普遍性也导致了任务特定微调模型的激增。在多任务场景中，由于这些模型通常只能很好地执行一项任务，因此需要额外的训练或集成。模型合并这一不断增长的领域提供了一个解决方案，解决了将多个任务特定模型合并为单个多任务模型的挑战。在本研究中，我们引入了一种新颖的用于Transformers的模型合并方法，结合了先前Fisher加权平均和Fisher信息在模型修剪中的应用的见解。通过利用Transformer架构内的mask节点的Fisher信息，我们设计了一个计算效率高的加权平均方案。我们的方法展现出了稳定且显著的性能。

    arXiv:2403.09891v1 Announce Type: cross  Abstract: Fine-tuning pre-trained models provides significant advantages in downstream performance. The ubiquitous nature of pre-trained models such as BERT and its derivatives in natural language processing has also led to a proliferation of task-specific fine-tuned models. As these models typically only perform one task well, additional training or ensembling is required in multi-task scenarios. The growing field of model merging provides a solution, dealing with the challenge of combining multiple task-specific models into a single multi-task model. In this study, we introduce a novel model merging method for Transformers, combining insights from previous work in Fisher-weighted averaging and the use of Fisher information in model pruning. Utilizing the Fisher information of mask nodes within the Transformer architecture, we devise a computationally efficient weighted-averaging scheme. Our method exhibits a regular and significant performance
    
[^5]: 复杂中的简单

    Simplicity in Complexity

    [https://arxiv.org/abs/2403.03134](https://arxiv.org/abs/2403.03134)

    本研究提出使用基于区段的图像表示来建模复杂性，与之前复杂的图像复杂性模型不同，这种方法既能泛化，又能为理论理解提供指导。

    

    视觉刺激的复杂性在许多认知现象中起着重要作用，包括注意力、参与度、易记性、时间感知和美学评价。然而，尽管其重要性，复杂性仍然知之甚少，讽刺的是，先前的图像复杂性模型相当复杂。早先的模型试图寻找手工制作的特征来解释复杂性，但这些特征通常是特定于数据集的，因此无法泛化。与此同时，最近的研究采用了深度神经网络来预测复杂性，但这些模型仍然难以解释，并且不指导对问题的理论理解。在本文中，我们提出使用基于区段的图像表示来建模复杂性。我们使用最先进的分割模型SAM和FC-CLIP，来量化图像中的多个粒度的区段数量，以及图像中的类别数量。

    arXiv:2403.03134v1 Announce Type: cross  Abstract: The complexity of visual stimuli plays an important role in many cognitive phenomena, including attention, engagement, memorability, time perception and aesthetic evaluation. Despite its importance, complexity is poorly understood and ironically, previous models of image complexity have been quite \textit{complex}. There have been many attempts to find handcrafted features that explain complexity, but these features are usually dataset specific, and hence fail to generalise. On the other hand, more recent work has employed deep neural networks to predict complexity, but these models remain difficult to interpret, and do not guide a theoretical understanding of the problem. Here we propose to model complexity using segment-based representations of images. We use state-of-the-art segmentation models, SAM and FC-CLIP, to quantify the number of segments at multiple granularities, and the number of classes in an image respectively. We find 
    
[^6]: Wukong: 迈向大规模推荐的标度律

    Wukong: Towards a Scaling Law for Large-Scale Recommendation

    [https://arxiv.org/abs/2403.02545](https://arxiv.org/abs/2403.02545)

    Wukong通过堆叠因子分解机和协同增长策略，在推荐领域建立了一个标度律，并在质量上优于现有模型。

    

    缩放定律在提高模型质量方面起着关键作用。然而，迄今为止的推荐模型并没有展现出类似于大型语言模型领域观察到的定律，这是由于它们的升级机制的低效性。本文提出了一种基于纯堆叠因子分解机和协同增长策略的有效网络架构，统称为Wukong，以在推荐领域建立一个标度律。Wukong的独特设计使其能够通过更高更宽的层次简单捕获各种任意阶的交互。我们在六个公共数据集上进行了广泛评估，结果表明，与最先进的模型相比，Wukong在质量方面始终表现优越。此外，我们评估了Wuko

    arXiv:2403.02545v1 Announce Type: cross  Abstract: Scaling laws play an instrumental role in the sustainable improvement in model quality. Unfortunately, recommendation models to date do not exhibit such laws similar to those observed in the domain of large language models, due to the inefficiencies of their upscaling mechanisms. This limitation poses significant challenges in adapting these models to increasingly more complex real-world datasets. In this paper, we propose an effective network architecture based purely on stacked factorization machines, and a synergistic upscaling strategy, collectively dubbed Wukong, to establish a scaling law in the domain of recommendation. Wukong's unique design makes it possible to capture diverse, any-order of interactions simply through taller and wider layers. We conducted extensive evaluations on six public datasets, and our results demonstrate that Wukong consistently outperforms state-of-the-art models quality-wise. Further, we assessed Wuko
    
[^7]: 硅谷人群的智慧：LLM集成预测能力达到人群准确率水平

    Wisdom of the Silicon Crowd: LLM Ensemble Prediction Capabilities Match Human Crowd Accuracy

    [https://arxiv.org/abs/2402.19379](https://arxiv.org/abs/2402.19379)

    该研究通过将十二个LLMs组成的LLM集成方法与925名人类预测者的群体预测进行比较，发现LLM群体优于简单的无信息基准，并在统计上等效于人类群体。

    

    实践中人类预测准确性依赖于“群体智慧”效应，即通过聚合一群个体预测者的预测可以显著提高对未来事件的预测。过去关于大型语言模型（LLMs）预测能力的研究表明，作为个体预测者的前沿LLMs表现不佳，与人类群体预测比赛的黄金标准相比。我们通过使用一个由十二个LLMs组成的LLM集成方法，扩展了研究。我们将31个二元问题的聚合LLM预测与一个来自三个月预测比赛的925名人类预测者的群体预测进行比较。我们的主要分析表明，LLM群体的表现优于简单的无信息基准，并在统计上等效于人类群体。我们还观察到一种顺从效应，平均模型预测明显高于50%，尽管几乎是平等的。

    arXiv:2402.19379v1 Announce Type: cross  Abstract: Human forecasting accuracy in practice relies on the 'wisdom of the crowd' effect, in which predictions about future events are significantly improved by aggregating across a crowd of individual forecasters. Past work on the forecasting ability of large language models (LLMs) suggests that frontier LLMs, as individual forecasters, underperform compared to the gold standard of a human crowd forecasting tournament aggregate. In Study 1, we expand this research by using an LLM ensemble approach consisting of a crowd of twelve LLMs. We compare the aggregated LLM predictions on 31 binary questions to that of a crowd of 925 human forecasters from a three-month forecasting tournament. Our main analysis shows that the LLM crowd outperforms a simple no-information benchmark and is statistically equivalent to the human crowd. We also observe an acquiescence effect, with mean model predictions being significantly above 50%, despite an almost even
    
[^8]: 跨架构零样本泛化的视觉分类

    Zero-shot generalization across architectures for visual classification

    [https://arxiv.org/abs/2402.14095](https://arxiv.org/abs/2402.14095)

    不同神经网络在跨架构和层间泛化到未知类别的能力存在差异，准确性并不是泛化能力的良好预测因子，泛化能力随着层深度呈非单调变化。

    

    深度网络的一个关键优势是对未见数据的泛化能力，但其与分类准确性的关系尚不清楚。我们利用一种极简的视觉数据集和一种泛化度量，展示了从深度卷积网络（CNNs）到transformers的流行网络在通过层和架构泛化到未见类别方面的能力存在差异。准确性并不是泛化能力的良好预测因子，并且泛化能力随着层深度呈非单调变化。代码可在https://github.com/dyballa/zero-shot-generalization 找到。

    arXiv:2402.14095v1 Announce Type: cross  Abstract: Generalization to unseen data is a key desideratum for deep networks, but its relation to classification accuracy is unclear. Using a minimalist vision dataset and a measure of generalizability, we show that popular networks, from deep convolutional networks (CNNs) to transformers, vary in their power to extrapolate to unseen classes both across layers and across architectures. Accuracy is not a good predictor of generalizability, and generalization varies non-monotonically with layer depth. Code is available at https://github.com/dyballa/zero-shot-generalization.
    
[^9]: 在不修改语言模型的情况下训练语言模型代理

    Training Language Model Agents without Modifying Language Models

    [https://arxiv.org/abs/2402.11359](https://arxiv.org/abs/2402.11359)

    提出一种新的方法，在不修改语言模型的情况下训练语言模型代理，通过进化代理的功能来解决下游任务

    

    研究人员和实践者最近已经将强大的大型语言模型（LLMs）重新定义为代理，使它们能够通过使用专门的功能自动化地完成复杂任务。为了促进LLM代理的发展，我们提出了一种在不修改LLM权重的情况下训练LLM代理的新范式，当LLM难以或无法进行修改时尤其有用。受到人类不断锻造工具以适应现实任务的启发，而不是改变我们的生物结构以适应一组静态工具，我们提出逐步锻造代理的功能，以更好地解决下游任务，而不是修改LLM权重。通过将这些功能视为可学习的“代理参数”并利用人工智能模型训练的基本思想，我们开发了AgentOptimizer，利用LLM更新代理的功能，并设计了一种代理训练算法

    arXiv:2402.11359v1 Announce Type: new  Abstract: Researchers and practitioners have recently reframed powerful Large Language Models (LLMs) as agents, enabling them to automate complex tasks largely via the use of specialized functions. To facilitate the development of LLM agents, we present a novel paradigm of training LLM agents without modifying the LLM weights, which is particularly useful when the LLMs are difficult or inaccessible for modifications. Inspired by how humans continuously forge tools to adapt to real-world tasks, rather than change our biological structure to fit a static set of tools, we propose to progressively forge agent's functions to better solve the downstream tasks instead of modifying the LLM weights. By treating the functions as learnable `agent parameters' and leveraging the fundamental idea of model training in artificial intelligence, we develop AgentOptimizer that employs the LLM to update agents' functions and devise an agent training algorithm with tw
    
[^10]: 使用RGBD感知和时间卷积网络对柔性连续机械臂的滞后补偿

    Hysteresis Compensation of Flexible Continuum Manipulator using RGBD Sensing and Temporal Convolutional Network

    [https://arxiv.org/abs/2402.11319](https://arxiv.org/abs/2402.11319)

    基于时间卷积网络的数据驱动方法用于捕捉柔性连续机械臂电缆驱动的非线性特性，提出了滞后补偿的解决方案。

    

    柔性连续机械臂因能够通过非线性路径进入狭窄空间而被重视于微创手术。但是受到电缆效应（如摩擦、伸长和耦合）引起的滞后效应导致电缆驱动机构面临控制困难。这些效应由于非线性而很难建模，并且在处理长且多节段机械臂时这些困难变得更加明显。本文提出了一种基于递归神经网络的数据驱动方法，以捕捉电缆驱动的这种非线性和以往状态依赖特性。我们设计定制的基准标记来收集物理关节配置作为数据集。对四种深度神经网络模型的学习性能进行比较研究的结果显示，时间卷积网络（TCN）表现出最高的预测能力。利用经过训练的TCN，我们构建了一个控制算法

    arXiv:2402.11319v1 Announce Type: cross  Abstract: Flexible continuum manipulators are valued for minimally invasive surgery, offering access to confined spaces through nonlinear paths. However, cable-driven manipulators face control difficulties due to hysteresis from cabling effects such as friction, elongation, and coupling. These effects are difficult to model due to nonlinearity and the difficulties become even more evident when dealing with long and multi-segmented manipulator. This paper proposes a data-driven approach based on recurrent neural networks to capture these nonlinear and previous states-dependent characteristics of cable actuation. We design customized fiducial markers to collect physical joint configurations as a dataset. Result on a study comparing the learning performance of four Deep Neural Network (DNN) models show that the Temporal Convolution Network (TCN) demonstrates the highest predictive capability. Leveraging trained TCNs, we build a control algorithm to
    
[^11]: 大规模生成AI模型缺乏视觉数字感知能力

    Large-scale Generative AI Models Lack Visual Number Sense

    [https://arxiv.org/abs/2402.03328](https://arxiv.org/abs/2402.03328)

    本研究调查了基于大规模Transformer架构的生成性AI模型是否能够准确命名物体数量或生成包含目标数量物品的图像，结果发现这些模型都没有以类似人类的方式表现，并且即使对于小数量的物体也会出现显著的错误。

    

    人类能够在视觉场景中轻松判断物体的数量，即使不进行计数，而且这种技能在各种动物物种和语言发展和正式学校教育之前的婴儿中都有记录。对于小的物体集，数字判断是无误的，而对于更大的集合，回应变得近似，并且变异性与目标数字成比例增加。尽管物体特征（如颜色或形状）存在差异，但这种回应模式在所有类型的物体上观察到，这表明我们的视觉数字感知依赖于数字数量的抽象表示。在本研究中，我们调查了基于大规模Transformer架构的生成性人工智能（AI）模型是否可以可靠地命名简单视觉刺激中的物体数量或生成包含目标物品数量的图像（1-10范围内）。令人惊讶的是，所考虑的所有基础模型都没有以类似人类一样的方式表现出来：即使是具有较小数量的物体也会犯下显著的错误。

    Humans can readily judge the number of objects in a visual scene, even without counting, and such a skill has been documented in a variety of animal species and in babies prior to language development and formal schooling. Numerical judgments are error-free for small sets, while for larger collections responses become approximate, with variability increasing proportionally to the target number. This response pattern is observed for items of all kinds, despite variation in object features (such as color or shape), suggesting that our visual number sense relies on abstract representations of numerosity. Here, we investigated whether generative Artificial Intelligence (AI) models based on large-scale transformer architectures can reliably name the number of objects in simple visual stimuli or generate images containing a target number of items in the 1-10 range. Surprisingly, none of the foundation models considered performed in a human-like way: They all made striking errors even with sm
    
[^12]: (A)我不是律师, 但是...: 向律师专家制定负责任的法律咨询的LLM政策

    (A)I Am Not a Lawyer, But...: Engaging Legal Experts towards Responsible LLM Policies for Legal Advice

    [https://arxiv.org/abs/2402.01864](https://arxiv.org/abs/2402.01864)

    通过对法律领域进行调查，我们对使用大型语言模型（LLM）提供专业咨询的政策考虑进行了深入分析，通过基于案例的推理方法，从20名法律专家的讨论中提取了四个影响因素：用户属性、查询特征、AI能力和影响。

    

    大型语言模型(LLM)作为通用聊天机器人迅速扩散, 带来了扩大公众获得法律、医学和金融专业指导的希望, 同时引发了公众对LLM在重大事件中的依赖的担忧。之前的研究猜测了高层次的伦理考虑, 但缺乏具体的标准来确定LLM聊天机器人何时以及为什么应该或不应该提供专业帮助。通过研究法律领域, 我们进行了结构化的专家分析, 以发现关于使用LLM进行专业咨询的政策考虑的细微差别, 并采用案例推理的方法。我们与20名法律专家召开了研讨会, 并从样本用户查询("案例")中提取出适当的AI辅助的维度。我们将专业维度分为: (1)用户属性, (2)查询特征, (3)AI能力, 和 (4)影响。除了已知的问题, 如幻觉, 专家们还

    The rapid proliferation of large language models (LLMs) as general purpose chatbots available to the public raises hopes around expanding access to professional guidance in law, medicine, and finance, while triggering concerns about public reliance on LLMs for high-stakes circumstances. Prior research has speculated on high-level ethical considerations but lacks concrete criteria determining when and why LLM chatbots should or should not provide professional assistance. Through examining the legal domain, we contribute a structured expert analysis to uncover nuanced policy considerations around using LLMs for professional advice, using methods inspired by case-based reasoning. We convened workshops with 20 legal experts and elicited dimensions on appropriate AI assistance for sample user queries (``cases''). We categorized our expert dimensions into: (1) user attributes, (2) query characteristics, (3) AI capabilities, and (4) impacts. Beyond known issues like hallucinations, experts re
    
[^13]: 模块化神经网络用于时间序列预测：使用注意力进行解释性和特征选择

    Modular Neural Networks for Time Series Forecasting: Interpretability and Feature Selection using Attention

    [https://arxiv.org/abs/2311.16834](https://arxiv.org/abs/2311.16834)

    该论文提出了一种新颖的模块化神经网络模型，用于多变量时间序列预测，通过循环神经网络学习时间依赖关系，并使用基于注意力的特征选择组件实现解释性，实验结果表明其优于当前最先进的解释性神经加性模型（NAM）及其变体。

    

    多变量时间序列在医疗保健、气象学和生命科学等领域有许多应用。虽然深度学习模型在时间序列预测方面表现出色，但被批评为“黑盒”或无法解释。本文提出了一种新颖的用于多变量时间序列预测的模块化神经网络模型，其构造具有解释性。循环神经网络学习数据中的时间依赖关系，而基于注意力的特征选择组件选择最相关的特征并抑制在学习时间依赖性中使用的冗余特征。从选择的特征独立训练模块化深度网络，向用户展示特征如何影响结果，使模型具有解释性。实验结果表明，这种方法可以超过最先进的可解释性神经加性模型（NAM）及其变体。

    arXiv:2311.16834v3 Announce Type: replace-cross  Abstract: Multivariate time series have many applications, from healthcare and meteorology to life science. Although deep learning models have shown excellent predictive performance for time series, they have been criticised for being "black-boxes" or non-interpretable. This paper proposes a novel modular neural network model for multivariate time series prediction that is interpretable by construction. A recurrent neural network learns the temporal dependencies in the data while an attention-based feature selection component selects the most relevant features and suppresses redundant features used in the learning of the temporal dependencies. A modular deep network is trained from the selected features independently to show the users how features influence outcomes, making the model interpretable. Experimental results show that this approach can outperform state-of-the-art interpretable Neural Additive Models (NAM) and variations thereo
    
[^14]: 高保真度以人为中心的主体到图像合成

    High-fidelity Person-centric Subject-to-Image Synthesis

    [https://arxiv.org/abs/2311.10329](https://arxiv.org/abs/2311.10329)

    提出了Face-diffuser，一个有效的协作生成流水线，用于解决主体到图像合成中的训练不平衡和质量妥协问题。

    

    当前以主体驱动的图像生成方法在以人为中心的图像生成中遇到了重大挑战。原因在于它们通过微调通用预训练扩散来学习语义场景和人物生成，这涉及到一种无法调和的训练不平衡。本文提出了Face-diffuser，这是一个有效的协作生成流水线，旨在消除上述训练不平衡和质量妥协。

    arXiv:2311.10329v3 Announce Type: replace-cross  Abstract: Current subject-driven image generation methods encounter significant challenges in person-centric image generation. The reason is that they learn the semantic scene and person generation by fine-tuning a common pre-trained diffusion, which involves an irreconcilable training imbalance. Precisely, to generate realistic persons, they need to sufficiently tune the pre-trained model, which inevitably causes the model to forget the rich semantic scene prior and makes scene generation over-fit to the training data. Moreover, even with sufficient fine-tuning, these methods can still not generate high-fidelity persons since joint learning of the scene and person generation also lead to quality compromise. In this paper, we propose Face-diffuser, an effective collaborative generation pipeline to eliminate the above training imbalance and quality compromise. Specifically, we first develop two specialized pre-trained diffusion models, i.
    
[^15]: InceptionXML：一种带有同步负采样的轻量级框架，用于短文本极端分类

    InceptionXML: A Lightweight Framework with Synchronized Negative Sampling for Short Text Extreme Classification

    [https://arxiv.org/abs/2109.07319](https://arxiv.org/abs/2109.07319)

    提出了一种轻量级框架InceptionXML，通过在embedding维度上重新分配卷积操作，应对短文本查询中的单词顺序缺失，同时提出了InceptionXML+框架，通过同步标签筛选器和极端分类器，改进了动态硬负采样技术。

    

    短文本数据对大量目标标签进行自动注释，被称为短文本极端分类，已经在许多应用中得到应用，包括相关搜索预测和产品推荐任务。本文提出了一种卷积架构InceptionXML，其轻量但功能强大，并且能够应对搜索和推荐任务中短文本查询中固有的缺乏单词顺序的特点。我们通过将卷积的操作沿着嵌入维度重新构建，而不是像传统CNNs一样沿着单词维度进行文本分类，证明了应用卷积的有效性。为了将我们的模型扩展到具有数百万标签的数据集，我们还提出了InceptionXML+框架，通过同步标签筛选器和极端分类器，改进了最近提出的动态硬负采样技术在标签筛选中的缺陷。

    arXiv:2109.07319v3 Announce Type: replace-cross  Abstract: Automatic annotation of short-text data to a large number of target labels, referred to as Short Text Extreme Classification, has found numerous applications including prediction of related searches and product recommendation tasks. In this paper, we propose a convolutional architecture InceptionXML which is light-weight, yet powerful, and robust to the inherent lack of word-order in short-text queries encountered in search and recommendation tasks. We demonstrate the efficacy of applying convolutions by recasting the operation along the embedding dimension instead of the word dimension as applied in conventional CNNs for text classification. Towards scaling our model to datasets with millions of labels, we also propose InceptionXML+ framework which improves upon the shortcomings of the recently proposed dynamic hard-negative mining technique for label shortlisting by synchronizing the label-shortlister and extreme classifier. 
    
[^16]: LangProp: 一种应用于自动驾驶的使用语言模型的代码优化框架

    LangProp: A code optimization framework using Language Models applied to driving. (arXiv:2401.10314v1 [cs.SE])

    [http://arxiv.org/abs/2401.10314](http://arxiv.org/abs/2401.10314)

    LangProp是一种用于自动驾驶的代码优化框架，利用语言模型迭代优化生成的代码。它通过评估代码性能和捕捉异常来改进生成的代码，展示了在CARLA中实现自动驾驶的概念验证。

    

    LangProp是一个框架，用于在监督/强化学习环境中迭代优化大型语言模型(LLM)生成的代码。虽然LLM能够零-shot地生成合理的解决方案，但这些解决方案往往是次优的。特别是对于代码生成任务，初始代码可能在某些边缘情况下失败。LangProp自动评估数据集上的代码性能，并捕捉任何异常，并将结果反馈给LLM进行训练，以使LLM可以迭代改进其生成的代码。通过采用基于度量和数据驱动的训练范式来进行代码优化过程，可以轻松地借鉴传统机器学习技术，如模仿学习、DAgger和强化学习。我们展示了在CARLA中自动驾驶的代码优化的第一个概念验证，证明了LangProp可以生成可解释和透明的驾驶代码。

    LangProp is a framework for iteratively optimizing code generated by large language models (LLMs) in a supervised/reinforcement learning setting. While LLMs can generate sensible solutions zero-shot, the solutions are often sub-optimal. Especially for code generation tasks, it is likely that the initial code will fail on certain edge cases. LangProp automatically evaluates the code performance on a dataset of input-output pairs, as well as catches any exceptions, and feeds the results back to the LLM in the training loop, so that the LLM can iteratively improve the code it generates. By adopting a metricand data-driven training paradigm for this code optimization procedure, one could easily adapt findings from traditional machine learning techniques such as imitation learning, DAgger, and reinforcement learning. We demonstrate the first proof of concept of automated code optimization for autonomous driving in CARLA, showing that LangProp can generate interpretable and transparent dri
    
[^17]: 探索分割联邦学习的隐私-能耗权衡

    Exploring the Privacy-Energy Consumption Tradeoff for Split Federated Learning. (arXiv:2311.09441v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2311.09441](http://arxiv.org/abs/2311.09441)

    本文研究了分割联邦学习（SFL）中隐私和能耗之间的权衡，强调了快速收敛的优势，并分析了切割层对客户端能耗和隐私的影响。

    

    分割联邦学习（SFL）最近已经成为一种有前景的分布式学习技术，充分利用了联邦学习和分割学习的优势。它强调了快速收敛的优势，同时解决了隐私问题。因此，这一创新受到了工业界和学术界的广泛关注。然而，由于SFL中模型在特定层（称为切割层）上被分割为客户端和服务器端模型，选择切割层可能对客户端的能耗和隐私产生重大影响，因为它影响了训练负担和客户端模型的输出。此外，确定切割层的设计挑战非常复杂，主要由于客户端的计算和网络能力的固有异质性。在本文中，我们全面概述了SFL的过程，并对能耗和隐私进行了深入分析。

    Split Federated Learning (SFL) has recently emerged as a promising distributed learning technology, leveraging the strengths of both federated learning and split learning. It emphasizes the advantages of rapid convergence while addressing privacy concerns. As a result, this innovation has received significant attention from both industry and academia. However, since the model is split at a specific layer, known as a cut layer, into both client-side and server-side models for the SFL, the choice of the cut layer in SFL can have a substantial impact on the energy consumption of clients and their privacy, as it influences the training burden and the output of the client-side models. Moreover, the design challenge of determining the cut layer is highly intricate, primarily due to the inherent heterogeneity in the computing and networking capabilities of clients. In this article, we provide a comprehensive overview of the SFL process and conduct a thorough analysis of energy consumption and
    
[^18]: 从神经激活到概念: 解释神经网络中的概念的调查

    From Neural Activations to Concepts: A Survey on Explaining Concepts in Neural Networks. (arXiv:2310.11884v1 [cs.AI])

    [http://arxiv.org/abs/2310.11884](http://arxiv.org/abs/2310.11884)

    本文调查了解释神经网络中概念的最新方法，这对于实现基于可解释概念的神经符号化人工智能来说是重要的一步。

    

    在本文中，我们审查了解释神经网络中概念的最新方法。概念可以作为学习和推理之间的自然桥梁：一旦确定了神经学习系统使用的概念，就可以将这些概念与推理系统整合，用于推理或使用推理系统对其进行改进或增强以改善学习系统。另一方面，不仅可以从神经网络中提取知识，还可以将概念知识插入神经网络体系结构中。由于整合学习和推理是神经符号化人工智能的核心，所以通过这项调查获得的见解可以成为实现基于可解释概念的神经符号化人工智能的重要一步。

    In this paper, we review recent approaches for explaining concepts in neural networks. Concepts can act as a natural link between learning and reasoning: once the concepts are identified that a neural learning system uses, one can integrate those concepts with a reasoning system for inference or use a reasoning system to act upon them to improve or enhance the learning system. On the other hand, knowledge can not only be extracted from neural networks but concept knowledge can also be inserted into neural network architectures. Since integrating learning and reasoning is at the core of neuro-symbolic AI, the insights gained from this survey can serve as an important step towards realizing neuro-symbolic AI based on explainable concepts.
    
[^19]: RLAdapter：在开放环境中将大型语言模型与强化学习相结合

    RLAdapter: Bridging Large Language Models to Reinforcement Learning in Open Worlds. (arXiv:2309.17176v1 [cs.AI])

    [http://arxiv.org/abs/2309.17176](http://arxiv.org/abs/2309.17176)

    RLAdapter引入了一个框架，将大型语言模型（LLM）与强化学习相结合，以提高在稀疏奖励环境中的策略学习性能。这通过解决LLM在理解下游任务方面的困难，以及通过避免使用不可访问的模型权重或大量计算资源来微调LLM的方式实现。

    

    强化学习在决策问题中取得了显著的成功，但通常需要与环境进行大量的交互，在稀疏奖励环境中学习有意义的策略是具有挑战性的。大型语言模型（LLM）可以为代理提供有价值的指导，从而增强RL算法在这些环境中的性能。然而，LLM通常在理解下游任务方面遇到困难，这阻碍了它们在这些任务中最优地帮助代理的能力。缓解这个问题的常见方法是使用与任务相关的数据来微调LLM，使其能够为RL代理提供有用的指导。然而，这种方法遇到了一些困难，比如无法访问的模型权重或需要大量的计算资源，使其不切实际。在这项工作中，我们引入了RLAdapter，这是一个框架，在RL算法和LLM之间建立更好的连接，从而整合它们的优势和能力。

    While reinforcement learning (RL) shows remarkable success in decision-making problems, it often requires a lot of interactions with the environment, and in sparse-reward environments, it is challenging to learn meaningful policies. Large Language Models (LLMs) can potentially provide valuable guidance to agents in learning policies, thereby enhancing the performance of RL algorithms in such environments. However, LLMs often encounter difficulties in understanding downstream tasks, which hinders their ability to optimally assist agents in these tasks. A common approach to mitigating this issue is to fine-tune the LLMs with task-related data, enabling them to offer useful guidance for RL agents. However, this approach encounters several difficulties, such as inaccessible model weights or the need for significant computational resources, making it impractical. In this work, we introduce RLAdapter, a framework that builds a better connection between RL algorithms and LLMs by incorporating
    
[^20]: 多智能体系统中的合作动力学：探索具有均值场均衡的博弈理论情景

    Cooperation Dynamics in Multi-Agent Systems: Exploring Game-Theoretic Scenarios with Mean-Field Equilibria. (arXiv:2309.16263v1 [cs.GT])

    [http://arxiv.org/abs/2309.16263](http://arxiv.org/abs/2309.16263)

    本文研究在多智能体系统中激发合作的策略和方法，通过分析现有的合作策略和引入鼓励团队回报的修改，解决了在分布式系统中存在的现实困境。同时，利用均值场博弈理论，建立了无限大智能体集合中的平衡解和奖励结构。

    

    合作是多智能体系统（MAS）和多智能体强化学习（MARL）中的基本要素，通常要求智能体在个体收益和集体回报之间保持平衡。本文旨在研究在博弈理论情景中激发合作的策略，例如迭代囚徒困境，在这种情况下，智能体必须优化个体和团队的结果。分析了现有的合作策略对于促进重复博弈中团队导向行为的有效性。提出了一种修改，即鼓励团队回报也将导致更高的个体收益，解决了分布式系统中存在的现实困境。研究还扩展到智能体人口指数增长的情景（$N \longrightarrow +\infty$），在这种情况下，传统计算和平衡确定具有挑战性。利用均值场博弈理论，建立了无限大智能体集合中的平衡解和奖励结构。

    Cooperation is fundamental in Multi-Agent Systems (MAS) and Multi-Agent Reinforcement Learning (MARL), often requiring agents to balance individual gains with collective rewards. In this regard, this paper aims to investigate strategies to invoke cooperation in game-theoretic scenarios, namely the Iterated Prisoner's Dilemma, where agents must optimize both individual and group outcomes. Existing cooperative strategies are analyzed for their effectiveness in promoting group-oriented behavior in repeated games. Modifications are proposed where encouraging group rewards will also result in a higher individual gain, addressing real-world dilemmas seen in distributed systems. The study extends to scenarios with exponentially growing agent populations ($N \longrightarrow +\infty$), where traditional computation and equilibrium determination are challenging. Leveraging mean-field game theory, equilibrium solutions and reward structures are established for infinitely large agent sets in repea
    
[^21]: MetaMath：为大型语言模型创建自己的数学问题

    MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models. (arXiv:2309.12284v1 [cs.CL])

    [http://arxiv.org/abs/2309.12284](http://arxiv.org/abs/2309.12284)

    MetaMath是一种专门用于数学推理的微调语言模型，通过从多个角度重新编写问题来生成数学问题，并在两个基准测试中取得了优于其他开源语言模型的表现。

    

    大型语言模型（LLMs）推动了自然语言理解的极限，并展示了出色的问题解决能力。尽管取得了巨大的成功，但大多数现有的开源LLMs（例如LLaMA-2）在解决数学问题方面仍然远远不够令人满意，原因是复杂的推理过程。为了弥合这一鸿沟，我们提出了MetaMath，一种专门用于数学推理的微调语言模型。具体而言，我们通过在没有额外知识的情况下以多个角度重新写入问题来引导数学问题，从而产生了一个名为MetaMathQA的新数据集。然后我们在MetaMathQA上对LLaMA-2模型进行了微调。对于数学推理的两个流行基准测试（即GSM8K和MATH），实验结果表明MetaMath在性能上明显优于一套开源LLMs。我们的MetaMath-7B模型在GSM8K上达到了66.4％，在MATH上达到了19.4％，超过了相同规模的最先进模型。

    Large language models (LLMs) have pushed the limits of natural language understanding and exhibited excellent problem-solving ability. Despite the great success, most existing open-source LLMs (\eg, LLaMA-2) are still far away from satisfactory for solving mathematical problem due to the complex reasoning procedures. To bridge this gap, we propose \emph{MetaMath}, a fine-tuned language model that specializes in mathematical reasoning. Specifically, we start by bootstrapping mathematical questions by rewriting the question from multiple perspectives without extra knowledge, which results in a new dataset called {MetaMathQA}. Then we fine-tune the LLaMA-2 models on MetaMathQA. Experimental results on two popular benchmarks (\ie, GSM8K and MATH) for mathematical reasoning demonstrate that MetaMath outperforms a suite of open-source LLMs by a significant margin. Our MetaMath-7B model achieves $66.4\%$ on GSM8K and $19.4\%$ on MATH, exceeding the state-of-the-art models of the same size by 
    
[^22]: 去殖民化的人工智能对齐：威色达尔玛、论证和艺术表达

    Decolonial AI Alignment: Vi\'{s}esadharma, Argument, and Artistic Expression. (arXiv:2309.05030v1 [cs.CY])

    [http://arxiv.org/abs/2309.05030](http://arxiv.org/abs/2309.05030)

    本文提出了去殖民化人工智能对齐的三个建议：改变基本道德哲学为达尔玛哲学，允许多元主义的论证传统存在于对齐技术中，以及将价值认识论扩展到超越自然语言中的指令。

    

    先前的研究已经阐明了人工智能（AI）开发和部署的殖民性。然而，这些研究很少涉及到对齐：即基于细致的人类反馈，调整大型语言模型（LLM）的行为与期望值一致。除了其他实践，殖民主义还有一部分是改变被殖民民族的信仰和价值观的历史；而当前的LLM对齐实践正是这一历史的复制。我们建议通过三个提议对AI对齐进行去殖民化：（a）将基本道德哲学从西方哲学转变为达尔玛哲学，（b）在对齐技术中允许论证和多元主义的传统，以及（c）将价值的认识论扩展到超越自然语言中的指令或命令。

    Prior work has explicated the coloniality of artificial intelligence (AI) development and deployment. One process that that work has not engaged with much is alignment: the tuning of large language model (LLM) behavior to be in line with desired values based on fine-grained human feedback. In addition to other practices, colonialism has a history of altering the beliefs and values of colonized peoples; this history is recapitulated in current LLM alignment practices. We suggest that AI alignment be decolonialized using three proposals: (a) changing the base moral philosophy from Western philosophy to dharma, (b) permitting traditions of argument and pluralism in alignment technologies, and (c) expanding the epistemology of values beyond instructions or commandments given in natural language.
    
[^23]: 使用强化学习进行基于视觉的概念组合学习

    Compositional Learning of Visually-Grounded Concepts Using Reinforcement. (arXiv:2309.04504v1 [cs.LG])

    [http://arxiv.org/abs/2309.04504](http://arxiv.org/abs/2309.04504)

    本研究探讨了深度强化学习代理如何学习和组合基于颜色和形状的组合指令，以解决空间导航任务中的新颖组合。通过利用冻结的文本编码器，代理所需的训练回合数减少了20倍。

    

    深度强化学习代理需要通过数百万个回合的训练才能较好地解决与指令相关的导航任务，并且它们是否能够推广到新颖的指令组合的能力尚不清楚。有趣的是，儿童可以分解基于语言的指令并导航到指定的物体，即使他们之前没有见过这些查询的组合。因此，我们创建了三个3D环境，研究深度强化学习代理如何学习和组合基于颜色和形状的组合指令，以解决空间导航任务中的新颖组合。首先，我们探讨代理是否能够进行组合学习，并且它们是否可以利用冻结的文本编码器（例如CLIP、BERT）在更少的回合中学习单词组合。接下来，我们证明当代理在形状或颜色概念上进行预训练时，它们所需的训练回合数减少了20倍，可以解决未见过的指令组合。最后，我们展示了...

    Deep reinforcement learning agents need to be trained over millions of episodes to decently solve navigation tasks grounded to instructions. Furthermore, their ability to generalize to novel combinations of instructions is unclear. Interestingly however, children can decompose language-based instructions and navigate to the referred object, even if they have not seen the combination of queries prior. Hence, we created three 3D environments to investigate how deep RL agents learn and compose color-shape based combinatorial instructions to solve novel combinations in a spatial navigation task. First, we explore if agents can perform compositional learning, and whether they can leverage on frozen text encoders (e.g. CLIP, BERT) to learn word combinations in fewer episodes. Next, we demonstrate that when agents are pretrained on the shape or color concepts separately, they show a 20 times decrease in training episodes needed to solve unseen combinations of instructions. Lastly, we show tha
    
[^24]: 用于计算设计的扩散模型在楼层平面示例中的应用

    Diffusion Models for Computational Design at the Example of Floor Plans. (arXiv:2307.02511v1 [cs.LG])

    [http://arxiv.org/abs/2307.02511](http://arxiv.org/abs/2307.02511)

    该论文探索了基于扩散模型的AI生成器在计算设计中的能力，并提出了具有改进的语义编码的新扩散模型。利用这些模型，可以提高生成楼层平面的有效性，并改进不同示例的查询性能。该研究还探讨了将扩散模型与建筑信息模型相结合的方法。

    

    最近，基于扩散模型的AI图像生成器因其能够根据简单的文本提示创建图像而受到广泛讨论。但是，在土木工程的实际应用中，它们需要能够根据给定的约束条件创建特定的建筑设计方案。在本文中，我们以楼层平面作为示例，探索基于扩散的AI生成器在计算设计中的能力，并确定它们目前的限制。我们解释了扩散模型的工作原理，并提出了具有改进的语义编码的新扩散模型。通过多次实验，我们展示了我们可以将生成的楼层平面的有效性从6%提高到90%，并改进了不同示例的查询性能。我们发现了一些问题，并针对这些模型提出了未来的研究挑战，并讨论了将扩散模型与建筑信息模型相结合的需要。通过这些，我们为土木工程中扩散模型的当前状态和未来方向提供了关键见解。

    AI Image generators based on diffusion models are widely discussed recently for their capability to create images from simple text prompts. But, for practical use in civil engineering they need to be able to create specific construction plans for given constraints. Within this paper we explore the capabilities of those diffusion-based AI generators for computational design at the example of floor plans and identify their current limitation. We explain how the diffusion-models work and propose new diffusion models with improved semantic encoding. In several experiments we show that we can improve validity of generated floor plans from 6% to 90% and query performance for different examples. We identify short comings and derive future research challenges of those models and discuss the need to combine diffusion models with building information modelling. With this we provide key insights into the current state and future directions for diffusion models in civil engineering.
    
[^25]: 社交AI与人工智能生态系统的挑战。

    Social AI and the Challenges of the Human-AI Ecosystem. (arXiv:2306.13723v1 [cs.AI])

    [http://arxiv.org/abs/2306.13723](http://arxiv.org/abs/2306.13723)

    本文介绍了人工智能生态系统研究中出现的挑战，并探讨了社交AI提高集体问题解决能力方面的潜力，同时也需要解决新的技术和伦理问题。

    

    大规模的社会技术系统中，人与人工智能（AI）系统相互作用的崛起（包括助手和推荐系统）增加了出现集体现象和临界点的机会，并可能带来意想不到的、可能是意外的后果。例如，导航系统的建议可能会在太多的司机被引导到同一路线时造成混乱，社交媒体上的个性化推荐可能会放大极化、过滤气泡和激进化。另一方面，我们可以学习如何培育“群体智慧”和集体行动效应，以应对社会和环境挑战。为了理解人工智能对社会技术系统的影响并设计与人类合作以帮助克服社会问题的下一代人工智能，我们建议在复杂系统、网络科学和人工智能的交叉点上建立社交AI的基础。在这个角度上，我们提出了从研究人工智能生态系统中出现的挑战开始讨论社交AI提高集体问题解决能力的潜力。我们认为，社交AI可以为社会带来显著的利益，但也引发了需要解决的新的技术和伦理挑战。

    The rise of large-scale socio-technical systems in which humans interact with artificial intelligence (AI) systems (including assistants and recommenders, in short AIs) multiplies the opportunity for the emergence of collective phenomena and tipping points, with unexpected, possibly unintended, consequences. For example, navigation systems' suggestions may create chaos if too many drivers are directed on the same route, and personalised recommendations on social media may amplify polarisation, filter bubbles, and radicalisation. On the other hand, we may learn how to foster the "wisdom of crowds" and collective action effects to face social and environmental challenges. In order to understand the impact of AI on socio-technical systems and design next-generation AIs that team with humans to help overcome societal problems rather than exacerbate them, we propose to build the foundations of Social AI at the intersection of Complex Systems, Network Science and AI. In this perspective pape
    
[^26]: DORSal: 基于扩散的物体中心场景表示

    DORSal: Diffusion for Object-centric Representations of Scenes $\textit{et al.}$. (arXiv:2306.08068v1 [cs.CV])

    [http://arxiv.org/abs/2306.08068](http://arxiv.org/abs/2306.08068)

    DORSal提出了一种基于扩散模型的物体中心场景表示方法，可以呈现高保真新视图，并在较大程度上保留了诸如基于物体的场景编辑之类的优点。

    

    最近在三维场景理解方面取得的进展使跨大量不同场景的数据集的可扩展表示学习成为可能。因此，对于未见过的场景和物体的泛化，仅通过单个或少数图像渲染新视图，以及支持编辑的可控场景生成现在成为可能。然而，联合训练大量场景通常会在渲染质量上妥协，而与单个场景优化模型（如NeRF）相比。在本文中，我们利用最近扩散模型的进展，使三维场景表示学习模型具备呈现高保真新视图的能力，同时在较大程度上保留了诸如基于物体的场景编辑之类的优点。特别地，我们提出了DORSal，它基于扩散视频架构，为基于物体中心的场景插槽表示的三维场景生成提供适应性。我们在复杂的合成多物体场景和现实世界大规模街景数据集上证明，我们的模型能够生成高质量的场景新视图，同时支持物体级别的编辑，并保留细粒度的纹理和反射等细节。

    Recent progress in 3D scene understanding enables scalable learning of representations across large datasets of diverse scenes. As a consequence, generalization to unseen scenes and objects, rendering novel views from just a single or a handful of input images, and controllable scene generation that supports editing, is now possible. However, training jointly on a large number of scenes typically compromises rendering quality when compared to single-scene optimized models such as NeRFs. In this paper, we leverage recent progress in diffusion models to equip 3D scene representation learning models with the ability to render high-fidelity novel views, while retaining benefits such as object-level scene editing to a large degree. In particular, we propose DORSal, which adapts a video diffusion architecture for 3D scene generation conditioned on object-centric slot-based representations of scenes. On both complex synthetic multi-object scenes and on the real-world large-scale Street View d
    
[^27]: 面向非平稳多智能体强化学习的黑盒方法

    A Black-box Approach for Non-stationary Multi-agent Reinforcement Learning. (arXiv:2306.07465v1 [cs.LG])

    [http://arxiv.org/abs/2306.07465](http://arxiv.org/abs/2306.07465)

    本文提出了一种通用的黑盒方法，适用于多种多智能体强化学习问题，可以在非平稳环境下实现低遗憾率的学习。

    

    本文研究了在非平稳多智能体系统中学习均衡的方法，并解决了区别于单智能体学习的挑战。我们重点关注带有赌徒反馈的游戏，其中即使待测试的差距很小，测试一个均衡也可能导致大量的遗憾，并且在静态游戏中存在多个最优解（均衡）会带来额外的难题。为了克服这些障碍，我们提出了一种通用的黑盒方法，适用于广泛的问题，如一般和博弈、潜在博弈和马尔可夫博弈，只要在静态环境下配备适当的学习和测试神谕。当非平稳程度（通过总变化量 $\Delta$ 测量）已知时，我们的算法可以实现 $\widetilde{O}\left(\Delta^{1/4}T^{3/4}\right)$ 的遗憾，当 $\Delta$ 未知时，可以实现 $\widetilde{O}\left(\Delta^{1/5}T^{4/5}\right)$ 的遗憾。

    We investigate learning the equilibria in non-stationary multi-agent systems and address the challenges that differentiate multi-agent learning from single-agent learning. Specifically, we focus on games with bandit feedback, where testing an equilibrium can result in substantial regret even when the gap to be tested is small, and the existence of multiple optimal solutions (equilibria) in stationary games poses extra challenges. To overcome these obstacles, we propose a versatile black-box approach applicable to a broad spectrum of problems, such as general-sum games, potential games, and Markov games, when equipped with appropriate learning and testing oracles for stationary environments. Our algorithms can achieve $\widetilde{O}\left(\Delta^{1/4}T^{3/4}\right)$ regret when the degree of nonstationarity, as measured by total variation $\Delta$, is known, and $\widetilde{O}\left(\Delta^{1/5}T^{4/5}\right)$ regret when $\Delta$ is unknown, where $T$ is the number of rounds. Meanwhile, 
    
[^28]: 使用指数级别的少量变分参数的张量网络压缩神经网络

    Compressing neural network by tensor network with exponentially fewer variational parameters. (arXiv:2305.06058v1 [cs.LG])

    [http://arxiv.org/abs/2305.06058](http://arxiv.org/abs/2305.06058)

    本文提出了一种通用的压缩方案，将神经网络的可变参数编码为多层张量网络，明显减少了可变参数的数量，并在多个神经网络和数据集上表现出了卓越的压缩性能，以VGG-16的测试精度提高为例。

    

    为了解决神经网络（NN）所包含的巨大可变的参数问题，本文提出了一种将这些参数 encoding 为多层张量网络（TN）的压缩方案。这种方案演示了出色的压缩性能，超过了以浅层张量网络为基础的现有最先进方法。例如，VGG-16中的3个卷积层的大约1000万参数被压缩到具有仅632个参数的TN中，而在CIFAR-10上的测试准确性令人惊喜地提高了81.14％。

    Neural network (NN) designed for challenging machine learning tasks is in general a highly nonlinear mapping that contains massive variational parameters. High complexity of NN, if unbounded or unconstrained, might unpredictably cause severe issues including over-fitting, loss of generalization power, and unbearable cost of hardware. In this work, we propose a general compression scheme that significantly reduces the variational parameters of NN by encoding them to multi-layer tensor networks (TN's) that contain exponentially-fewer free parameters. Superior compression performance of our scheme is demonstrated on several widely-recognized NN's (FC-2, LeNet-5, and VGG-16) and datasets (MNIST and CIFAR-10), surpassing the state-of-the-art method based on shallow tensor networks. For instance, about 10 million parameters in the three convolutional layers of VGG-16 are compressed in TN's with just $632$ parameters, while the testing accuracy on CIFAR-10 is surprisingly improved from $81.14
    
[^29]: 基于时间轨迹的度量时间平衡逻辑

    Metric Temporal Equilibrium Logic over Timed Traces. (arXiv:2304.14778v1 [cs.AI])

    [http://arxiv.org/abs/2304.14778](http://arxiv.org/abs/2304.14778)

    提出了基于度量的线性时间平衡逻辑来处理涉及时间约束的动态系统问题，并给出了通过将度量公式转化为单一一阶公式实现模型检查的方法。

    

    在基于线性时间的Answer Set Programming (ASP)的时间扩展中，动态系统的行为通过状态序列来捕获。虽然此表示反映了它们的相对顺序，但它抽象掉了与每个状态关联的具体时间。然而，时间约束在许多应用中是重要的，比如当计划和调度相互配合时。我们通过开发基于度量的线性时间平衡逻辑来解决这个问题，其中时间运算符受自然数区间的约束。由此得到的度量平衡逻辑为指定定性和定量动态约束的基于ASP的方法提供了基础。为此，我们将度量公式转化为单调一阶公式，并分别给出在Metric Equilibrium Logic和Monadic Quantified Equilibrium Logic中的模型之间的对应关系。有趣的是，我们的翻译提供了Metric Equilibrium Logic的实现模型检查的蓝图。

    In temporal extensions of Answer Set Programming (ASP) based on linear-time, the behavior of dynamic systems is captured by sequences of states. While this representation reflects their relative order, it abstracts away the specific times associated with each state. However, timing constraints are important in many applications like, for instance, when planning and scheduling go hand in hand. We address this by developing a metric extension of linear-time temporal equilibrium logic, in which temporal operators are constrained by intervals over natural numbers. The resulting Metric Equilibrium Logic provides the foundation of an ASP-based approach for specifying qualitative and quantitative dynamic constraints. To this end, we define a translation of metric formulas into monadic first-order formulas and give a correspondence between their models in Metric Equilibrium Logic and Monadic Quantified Equilibrium Logic, respectively. Interestingly, our translation provides a blue print for im
    
[^30]: 具有完成功能的神经通用邻居用于链接预测

    Neural Common Neighbor with Completion for Link Prediction. (arXiv:2302.00890v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.00890](http://arxiv.org/abs/2302.00890)

    提出了神经通用邻居模型（NCN）用于链接预测，使用可学习的成对表示来捕捉节点之间的成对关系，以提高性能，同时解决链路不完整问题。

    

    尽管vanilla信息传递神经网络（MPNN）在各种图任务中具有出色的性能，但在链接预测任务中通常失败，因为它只使用两个单独目标节点的表示，并忽略它们之间的成对关系。为了捕获成对关系，一些模型将手动功能添加到输入图中，并使用MPNN的输出来生成成对表示。相反，其他人直接将手动功能用作成对表示。尽管此简化避免了将GNN逐个链接地应用于每个链接，从而提高了可扩展性，但由于手工制作的和不可学习的成对特征，这些模型仍有很大的性能提升空间。为了在保持可扩展性的同时提高性能，我们提出了神经通用邻居（NCN），它使用可学习的成对表示。为了进一步提高NCN的性能，我们研究了未观察到的链接问题。图的不完整性是普遍存在的，并导致分布偏移

    Despite its outstanding performance in various graph tasks, vanilla Message Passing Neural Network (MPNN) usually fails in link prediction tasks, as it only uses representations of two individual target nodes and ignores the pairwise relation between them. To capture the pairwise relations, some models add manual features to the input graph and use the output of MPNN to produce pairwise representations. In contrast, others directly use manual features as pairwise representations. Though this simplification avoids applying a GNN to each link individually and thus improves scalability, these models still have much room for performance improvement due to the hand-crafted and unlearnable pairwise features. To upgrade performance while maintaining scalability, we propose Neural Common Neighbor (NCN), which uses learnable pairwise representations. To further boost NCN, we study the unobserved link problem. The incompleteness of the graph is ubiquitous and leads to distribution shifts between
    
[^31]: 基于神经网络的无约束音频拼接检测与定位方法研究

    Towards Unconstrained Audio Splicing Detection and Localization with Neural Networks. (arXiv:2207.14682v3 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2207.14682](http://arxiv.org/abs/2207.14682)

    研究提出了一种基于 Transformer 序列到序列（seq2seq）网络的音频拼接检测与定位方法，能够在各种攻击场景中准确检测出拼接并定位，具有普适性和鲁棒性。

    

    容易获取且易于使用的音频编辑工具使得音频拼接变得简单。可通过组合同一人的各种语音样本来创建令人信服的伪造品。检测此类拼接在公共领域中考虑到虚假信息甚至在法律背景下核实证据的完整性都至关重要。然而，大多数现有的音频拼接检测算法使用手工制作的特征并做出了特定的假设。但是，刑事调查人员通常面临来自未知来源具有未知特征的音频样本，这引发了对更普适的方法的需求。本文旨在朝着无约束音频拼接检测方向迈出第一步以满足这一需求。我们通过各种攻击形式的后处理操作来模拟不同的攻击场景，可能掩盖拼接存在。我们提出了一种基于 Transformer 序列到序列（seq2seq）网络用于拼接检测和定位。我们广泛的实验表明所提出的方法优于几种最先进的方法，能够检测和定位甚至存在强烈失真和背景噪声的拼接。

    Freely available and easy-to-use audio editing tools make it straightforward to perform audio splicing. Convincing forgeries can be created by combining various speech samples from the same person. Detection of such splices is important both in the public sector when considering misinformation, and in a legal context to verify the integrity of evidence. Unfortunately, most existing detection algorithms for audio splicing use handcrafted features and make specific assumptions. However, criminal investigators are often faced with audio samples from unconstrained sources with unknown characteristics, which raises the need for more generally applicable methods.  With this work, we aim to take a first step towards unconstrained audio splicing detection to address this need. We simulate various attack scenarios in the form of post-processing operations that may disguise splicing. We propose a Transformer sequence-to-sequence (seq2seq) network for splicing detection and localization. Our exte
    
[^32]: 评估“Assurance 2.0”中的信心

    Assessing Confidence with Assurance 2.0. (arXiv:2205.04522v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2205.04522](http://arxiv.org/abs/2205.04522)

    本文提出了从三个方面考虑信心的属性来评估保证案例，其中主要的措施是将论证解释为逻辑证明的完备性。

    

    保证案例旨在对其顶级声明（通常涉及安全性或安全）提供可证明的信心。那么问题来了，“这种信心”有多少？我们认为信心不能归结为单一属性或测量。相反，我们建议它应该基于三个不同视角的属性：积极，消极和剩余疑虑。积极视角考虑证据和整个案例的程度，将积极声明合理化为支持其主张的信仰。我们对证明设立了高门槛，要求证明是不可否认的。其中主要的正面措施是完备性，将该论证解释为逻辑证明。证据的信心可以以概率方式表达，并使用确认措施确保证据的"重量"越过某个阈值。此外，概率可以从证据中聚合，通过将证据视为贝叶斯网络节点来完成。

    An assurance case is intended to provide justifiable confidence in the truth of its top claim, which typically concerns safety or security. A natural question is then "how much" confidence does the case provide? We argue that confidence cannot be reduced to a single attribute or measurement. Instead, we suggest it should be based on attributes that draw on three different perspectives: positive, negative, and residual doubts.  Positive Perspectives consider the extent to which the evidence and overall argument of the case combine to make a positive statement justifying belief in its claims. We set a high bar for justification, requiring it to be indefeasible. The primary positive measure for this is soundness, which interprets the argument as a logical proof. Confidence in evidence can be expressed probabilistically and we use confirmation measures to ensure that the "weight" of evidence crosses some threshold. In addition, probabilities can be aggregated from evidence through the step
    

