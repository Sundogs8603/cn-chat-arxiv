# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Modality Translation for Object Detection Adaptation Without Forgetting Prior Knowledge](https://arxiv.org/abs/2404.01492) | 本文提出了一种ModTr方法，通过小型转换网络调整输入以最小化检测损失，实现了目标检测模型从一个或多个模态到另一个的有效适应，而无需微调参数。 |
| [^2] | [Transfer Learning with Reconstruction Loss](https://arxiv.org/abs/2404.00505) | 本文通过引入额外的重建阶段和重建损失，提出了一种具有共享模型参数和特征表示的模型训练方法，建立了共同信息的概念，用于解决相关任务。 |
| [^3] | [Few-Shot Cross-System Anomaly Trace Classification for Microservice-based systems](https://arxiv.org/abs/2403.18998) | 提出了针对微服务系统的少样本异常跟踪分类的新框架，利用多头注意力自编码器构建系统特定的跟踪表示，并应用基于Transformer编码器的模型无关元学习进行高效分类。 |
| [^4] | [Towards Measuring and Modeling "Culture" in LLMs: A Survey](https://arxiv.org/abs/2403.15412) | 这项研究调查了39篇最新论文，旨在研究大型语言模型中的文化表达和包容性，发现当前研究未对“文化”进行定义，而是在特定设计的数据集上对模型进行探究，研究了某些“文化”的方面，留下许多未被探究的有趣和重要方面，如语义领域和关于性。 |
| [^5] | [LLaVA-PruMerge: Adaptive Token Reduction for Efficient Large Multimodal Models](https://arxiv.org/abs/2403.15388) | PruMerge提出了一种自适应的视觉令牌减少方法，可以有效减少大型多模态模型中的视觉令牌数量，同时保持模型性能。 |
| [^6] | [Multi-Scale Subgraph Contrastive Learning](https://arxiv.org/abs/2403.02719) | 提出了一种多尺度子图对比学习方法，能够表征细粒度语义信息，解决了在图增强后原有假设不再成立的问题 |
| [^7] | [Re-Ex: Revising after Explanation Reduces the Factual Errors in LLM Responses](https://arxiv.org/abs/2402.17097) | 提出了一种名为Re-Ex的方法，通过引入事实错误说明步骤来修正LLM生成文本中的事实错误，并提出了新的提示技术来减少所需的标记数量和挂钟时间 |
| [^8] | [Multi-Task Learning for Routing Problem with Cross-Problem Zero-Shot Generalization](https://arxiv.org/abs/2402.16891) | 本研究首次尝试解决跨问题泛化的关键挑战，通过将VRPs定义为共享基础属性的不同组合，并通过属性组合同时解决它们，实现了零样本泛化的路径问题解决方法。 |
| [^9] | [UMBCLU at SemEval-2024 Task 1A and 1C: Semantic Textual Relatedness with and without machine translation](https://arxiv.org/abs/2402.12730) | 使用机器翻译和大型语言模型，本文开发了用于非洲和亚洲语言语义文本相关性任务的两种模型，取得了比部分官方基准更好的效果。 |
| [^10] | [Gauging Public Acceptance of Conditionally Automated Cars in the United States](https://arxiv.org/abs/2402.11444) | 本研究通过调查358名美国参与者，发现社会影响、性能期望、享受动机、便利条件和努力期望是影响有条件自动驾驶汽车接受度的重要因素。 |
| [^11] | [Comment-aided Video-Language Alignment via Contrastive Pre-training for Short-form Video Humor Detection](https://arxiv.org/abs/2402.09055) | 本文提出了一种新颖的通过对比预训练的方法，命名为CVLA，用于短视频幽默检测。CVLA不仅适用于各种模态信号，还能通过在一致的语义空间中对齐视频和语言组件产生适合的多模式表示。实验证明，CVLA显著优于现有最先进方法和几个竞争基准方法。 |
| [^12] | [UWB Based Static Gesture Classification](https://arxiv.org/abs/2310.15036) | 该论文提出了基于UWB的静态手势识别的稳健框架，经过数据集收集和处理，训练模型达到96.78%准确率，并开发了用户友好的GUI框架，为将UWB技术应用于静态手势识别带来了重要进展。 |
| [^13] | [Deep Classifier Mimicry without Data Access](https://arxiv.org/abs/2306.02090) | 提出了一种无需访问原始数据的模型-无关知识蒸馏过程CAKE，可以模拟深度分类器，通过生成噪声合成样本对比地扩散到模型的决策边界。 |
| [^14] | [Distributed Multi-Agent Reinforcement Learning Based on Graph-Induced Local Value Functions](https://arxiv.org/abs/2202.13046) | 通过利用图结构，本文提出了一种通用计算高效的分布式框架，基于局部值函数的分布式RL方法在协作多智能体强化学习中取得了显著的样本复杂性降低。 |
| [^15] | [Automated Verification of Equivalence Properties in Advanced Logic Programs -- Bachelor Thesis.](http://arxiv.org/abs/2310.19806) | 这篇论文介绍了一种自动验证工具，用于验证优化的逻辑子程序是否可以替代原始子程序，在工业应用中具有重要意义。 |
| [^16] | [Be Bayesian by Attachments to Catch More Uncertainty.](http://arxiv.org/abs/2310.13027) | 本文提出了一种附加结构贝叶斯神经网络(ABNN)，通过在主干网络中整合足够分布外数据的不确定性，来提高神经网络对不确定性的捕捉能力。 |
| [^17] | [Accelerating Thematic Investment with Prompt Tuned Pretrained Language Models.](http://arxiv.org/abs/2309.12075) | 本研究通过Benchmark测试，发现使用Prompt Tuning的预训练语言模型在多标签文本分类任务中具有较好的性能和计算效率。同时，提出了使用Trie搜索来解决生成标签匹配问题的限制。 |
| [^18] | [Deep Semi-supervised Anomaly Detection with Metapath-based Context Knowledge.](http://arxiv.org/abs/2308.10918) | 本文介绍了一种利用基于Metapath的半监督学习的新颖方法，用于图异常检测。通过在编码器和解码器中使用GCN层来有效传播上下文信息，以及特别设计的异常社区，该方法在结构和属性差异的学习中表现出优越性能。通过实验证明了该方法的有效性，为未来的研究提供了重要的思路和方向。 |
| [^19] | [Contrastive Graph Pooling for Explainable Classification of Brain Networks.](http://arxiv.org/abs/2307.11133) | 本论文提出了一种针对脑网络的对比图池化方法，以实现对脑网络的可解释分类。通过定制化的图神经网络和特殊设计的可解释特征提取方法，在5个静息态fMRI脑网络数据集上取得了优于最先进基准线的结果。 |
| [^20] | [Reinforcement Learning with Non-Cumulative Objective.](http://arxiv.org/abs/2307.04957) | 本文研究了最优控制和强化学习中非累积目标的挑战，并提出了修改现有算法的方法来优化这些目标。研究结果表明，在贝尔曼最优性方程中使用广义运算可以更好地处理非累积目标。 |
| [^21] | [CLIPMasterPrints: Fooling Contrastive Language-Image Pre-training Using Latent Variable Evolution.](http://arxiv.org/abs/2307.03798) | 本文展示了对比式语言-图像预训练（CLIP）模型的脆弱性，通过挖掘生成模型的潜在空间可以找到欺骗主图像，这些图像在许多不同的提示下能欺骗CLIP模型，而对人类来说是无法认出的。欺骗主图像在少量图像标题上的训练上可能适用于更多数量的语义相关的标题。两种可能的缓解策略被评估，并发现脆弱性与对比式预训练中的模态差距密切相关。 |
| [^22] | [Towards Measuring the Representation of Subjective Global Opinions in Language Models.](http://arxiv.org/abs/2306.16388) | 本文提出了一个方法来评估大型语言模型对全球观点的代表性。通过构建一个包含跨国调查问题和答案的数据集，并定义一个相似度度量标准，研究发现默认情况下语言模型的回应更倾向于某些人群的观点，但当模型考虑特定国家的观点时，回应会更加贴近该国家的观点。 |
| [^23] | [RDFC-GAN: RGB-Depth Fusion CycleGAN for Indoor Depth Completion.](http://arxiv.org/abs/2306.03584) | RDFC-GAN使用两个分支结构生成精确的深度图像，它通过解决室内环境中普遍缺失的大面积深度值问题，克服了现有方法的不足，可用于各种室内深度完成任务。 |
| [^24] | [HICO-DET-SG and V-COCO-SG: New Data Splits to Evaluate Systematic Generalization in Human-Object Interaction Detection.](http://arxiv.org/abs/2305.09948) | 本论文提出了两个新的HOI检测数据拆分，旨在评估系统性泛化。在新的数据拆分上测试结果表明，HOI检测模型对于未见过的对象和交互组合的泛化十分困难。 |
| [^25] | [A Vision-free Baseline for Multimodal Grammar Induction.](http://arxiv.org/abs/2212.10564) | 本论文研究了在多模式设置下，只使用文本进行训练的大型语言模型（LLMs）是否能够提供强大的辅助来进行语法归纳。结果显示，基于LLM的纯文本方法在多种多模式数据集上优于先前的方法，并且在性能、参数数量和训练速度方面取得了最先进的结果。 |
| [^26] | [What is the Solution for State-Adversarial Multi-Agent Reinforcement Learning?.](http://arxiv.org/abs/2212.02705) | 本文提出了一种解决面对对抗性状态的多智能体强化学习问题的方法，通过引入状态对抗性马尔科夫博弈，提出了鲁棒智能体策略的概念，并证明了其在有限状态和有限动作情况下的存在性。此外，还提出了一种鲁棒多智能体对抗性演员-评论家算法，用于学习在状态不确定性下的鲁棒性策略。 |

# 详细

[^1]: 不遗忘先验知识的目标检测适应模态转换

    Modality Translation for Object Detection Adaptation Without Forgetting Prior Knowledge

    [https://arxiv.org/abs/2404.01492](https://arxiv.org/abs/2404.01492)

    本文提出了一种ModTr方法，通过小型转换网络调整输入以最小化检测损失，实现了目标检测模型从一个或多个模态到另一个的有效适应，而无需微调参数。

    

    深度学习中常见的做法是在大规模数据集上训练大型神经网络，以在不同领域和任务中准确执行。然而，这种方法在许多应用领域只适用于跨模态，因为使用不同传感器捕获的数据存在更大的分布偏移。本文专注于将大型目标检测模型调整到一个或多个模态的问题，同时保持高效。为此，我们提出了ModTr作为普遍做法微调大型模型的替代方案。ModTr包括使用一个小型转换网络调整输入，该网络经过训练，直接使检测损失最小化。因此，原始模型可以在转换后的输入上工作，无需进行任何进一步的更改或参数微调。对两个知名数据集上从红外到RGB图像的转换的实验结果表明，这种简单的ModTr方法提供了检测器。

    arXiv:2404.01492v1 Announce Type: cross  Abstract: A common practice in deep learning consists of training large neural networks on massive datasets to perform accurately for different domains and tasks. While this methodology may work well in numerous application areas, it only applies across modalities due to a larger distribution shift in data captured using different sensors. This paper focuses on the problem of adapting a large object detection model to one or multiple modalities while being efficient. To do so, we propose ModTr as an alternative to the common approach of fine-tuning large models. ModTr consists of adapting the input with a small transformation network trained to minimize the detection loss directly. The original model can therefore work on the translated inputs without any further change or fine-tuning to its parameters. Experimental results on translating from IR to RGB images on two well-known datasets show that this simple ModTr approach provides detectors tha
    
[^2]: 具有重建损失的迁移学习

    Transfer Learning with Reconstruction Loss

    [https://arxiv.org/abs/2404.00505](https://arxiv.org/abs/2404.00505)

    本文通过引入额外的重建阶段和重建损失，提出了一种具有共享模型参数和特征表示的模型训练方法，建立了共同信息的概念，用于解决相关任务。

    

    在大多数利用神经网络进行数学优化的应用中，通常为每个特定优化目标训练一个专用模型。然而，在许多场景中，同一组问题输入上经常需要优化几个不同但相关的目标或任务。与为每个问题单独训练不同的神经网络相比，更有效的方法是利用这些目标之间的相关性，使用共享模型参数和特征表示训练多个神经网络模型。为实现这一目标，本文首先建立了共同信息的概念：解决相关任务所需的共享知识，然后提出了一种新颖的模型训练方法，通过在模型中添加一个额外的重建阶段以及相关的新重建损失。该损失用于从选择的隐藏状态开始重新构建共同信息。

    arXiv:2404.00505v1 Announce Type: cross  Abstract: In most applications of utilizing neural networks for mathematical optimization, a dedicated model is trained for each specific optimization objective. However, in many scenarios, several distinct yet correlated objectives or tasks often need to be optimized on the same set of problem inputs. Instead of independently training a different neural network for each problem separately, it would be more efficient to exploit the correlations between these objectives and to train multiple neural network models with shared model parameters and feature representations. To achieve this, this paper first establishes the concept of common information: the shared knowledge required for solving the correlated tasks, then proposes a novel approach for model training by adding into the model an additional reconstruction stage associated with a new reconstruction loss. This loss is for reconstructing the common information starting from a selected hidde
    
[^3]: 微服务系统的少样本跨系统异常跟踪分类

    Few-Shot Cross-System Anomaly Trace Classification for Microservice-based systems

    [https://arxiv.org/abs/2403.18998](https://arxiv.org/abs/2403.18998)

    提出了针对微服务系统的少样本异常跟踪分类的新框架，利用多头注意力自编码器构建系统特定的跟踪表示，并应用基于Transformer编码器的模型无关元学习进行高效分类。

    

    微服务系统（MSS）由于其复杂和动态的特性可能在各种故障类别中出现故障。为了有效处理故障，AIOps工具利用基于跟踪的异常检测和根本原因分析。本文提出了一个新颖的框架，用于微服务系统的少样本异常跟踪分类。我们的框架包括两个主要组成部分：（1）多头注意力自编码器用于构建系统特定的跟踪表示，从而实现（2）基于Transformer编码器的模型无关元学习，以进行有效和高效的少样本异常跟踪分类。该框架在两个代表性的MSS，Trainticket和OnlineBoutique上进行了评估，使用开放数据集。结果表明，我们的框架能够调整学到的知识，以对新的、未见的新颖故障类别的异常跟踪进行分类，无论是在最初训练的同一系统内，还是在其他系统中。

    arXiv:2403.18998v1 Announce Type: cross  Abstract: Microservice-based systems (MSS) may experience failures in various fault categories due to their complex and dynamic nature. To effectively handle failures, AIOps tools utilize trace-based anomaly detection and root cause analysis. In this paper, we propose a novel framework for few-shot abnormal trace classification for MSS. Our framework comprises two main components: (1) Multi-Head Attention Autoencoder for constructing system-specific trace representations, which enables (2) Transformer Encoder-based Model-Agnostic Meta-Learning to perform effective and efficient few-shot learning for abnormal trace classification. The proposed framework is evaluated on two representative MSS, Trainticket and OnlineBoutique, with open datasets. The results show that our framework can adapt the learned knowledge to classify new, unseen abnormal traces of novel fault categories both within the same system it was initially trained on and even in the 
    
[^4]: 在LLMs中测量和建模“文化”：一项调查

    Towards Measuring and Modeling "Culture" in LLMs: A Survey

    [https://arxiv.org/abs/2403.15412](https://arxiv.org/abs/2403.15412)

    这项研究调查了39篇最新论文，旨在研究大型语言模型中的文化表达和包容性，发现当前研究未对“文化”进行定义，而是在特定设计的数据集上对模型进行探究，研究了某些“文化”的方面，留下许多未被探究的有趣和重要方面，如语义领域和关于性。

    

    我们呈现了对39篇最新论文的调查，旨在研究大型语言模型中的文化表达和包容性。我们观察到，没有一篇研究定义“文化”，这是一个复杂、多层面的概念；相反，它们在一些特别设计的数据集上对模型进行探究，这些数据集代表了某些“文化”的方面。我们将这些方面称为文化的代理，并将它们组织在人口统计、语义和语言文化交互代理的三个维度上。我们还对采用的探查方法进行了分类。我们的分析表明，只有“文化”的某些方面，如价值观和目标，被研究了，留下了几个其他有趣且重要的方面，特别是大量语义领域和关于性（Hershcovich等人，2022）的未被探究。另外两个关键的空白是目前方法的鲁棒性和情境性的缺乏。基于这些观察结果，

    arXiv:2403.15412v1 Announce Type: cross  Abstract: We present a survey of 39 recent papers that aim to study cultural representation and inclusion in large language models. We observe that none of the studies define "culture," which is a complex, multifaceted concept; instead, they probe the models on some specially designed datasets which represent certain aspects of "culture." We call these aspects the proxies of cultures, and organize them across three dimensions of demographic, semantic and linguistic-cultural interaction proxies. We also categorize the probing methods employed. Our analysis indicates that only certain aspects of "culture," such as values and objectives, have been studied, leaving several other interesting and important facets, especially the multitude of semantic domains (Thompson et al., 2020) and aboutness (Hershcovich et al., 2022), unexplored. Two other crucial gaps are the lack of robustness and situatedness of the current methods. Based on these observations
    
[^5]: LLaVA-PruMerge: 自适应令牌减少用于高效大型多模态模型

    LLaVA-PruMerge: Adaptive Token Reduction for Efficient Large Multimodal Models

    [https://arxiv.org/abs/2403.15388](https://arxiv.org/abs/2403.15388)

    PruMerge提出了一种自适应的视觉令牌减少方法，可以有效减少大型多模态模型中的视觉令牌数量，同时保持模型性能。

    

    大型多模态模型(LMMs)通过连接视觉编码器和大型语言模型展现了显著的推理能力。最近的LMMs包括了更复杂的视觉输入，如高分辨率图像和视频，这显著增加了视觉令牌的数量。为了解决这个问题，我们探索了一种令牌减少机制，并发现类似于先前的工作，许多视觉令牌在空间上是冗余的。基于此，我们提出了PruMerge，一种新颖的自适应视觉令牌减少方法，大大减少了视觉令牌的数量，同时保持了可比的模型性能。

    arXiv:2403.15388v1 Announce Type: cross  Abstract: Large Multimodal Models (LMMs) have shown significant reasoning capabilities by connecting a visual encoder and a large language model. LMMs typically use a fixed amount of visual tokens, such as the penultimate layer features in the CLIP visual encoder, as the prefix content. Recent LMMs incorporate more complex visual inputs, such as high-resolution images and videos, which increase the number of visual tokens significantly. However, due to the design of the Transformer architecture, computational costs associated with these models tend to increase quadratically with the number of input tokens. To tackle this problem, we explore a token reduction mechanism and find, similar to prior work, that many visual tokens are spatially redundant. Based on this, we propose PruMerge, a novel adaptive visual token reduction approach, which largely reduces the number of visual tokens while maintaining comparable model performance. We first select 
    
[^6]: 多尺度子图对比学习

    Multi-Scale Subgraph Contrastive Learning

    [https://arxiv.org/abs/2403.02719](https://arxiv.org/abs/2403.02719)

    提出了一种多尺度子图对比学习方法，能够表征细粒度语义信息，解决了在图增强后原有假设不再成立的问题

    

    图级对比学习旨在通过对比两个增强图来学习每个图的表示，受到了广泛关注。先前的研究通常简单地假设一个图及其增强图为正对，否则为负对。然而，众所周知，图结构通常复杂且多尺度，这带来了一个根本问题：在图增强后，先前的假设是否仍然成立？通过实验分析，我们发现增强图结构的语义信息可能不一致于原始图结构，并且两个增强图是正对还是负对与多尺度结构密切相关。基于这一发现，我们提出了一种能够表征细粒度语义信息的多尺度子图对比学习方法。具体地，我们生成全局和局部

    arXiv:2403.02719v1 Announce Type: new  Abstract: Graph-level contrastive learning, aiming to learn the representations for each graph by contrasting two augmented graphs, has attracted considerable attention. Previous studies usually simply assume that a graph and its augmented graph as a positive pair, otherwise as a negative pair. However, it is well known that graph structure is always complex and multi-scale, which gives rise to a fundamental question: after graph augmentation, will the previous assumption still hold in reality? By an experimental analysis, we discover the semantic information of an augmented graph structure may be not consistent as original graph structure, and whether two augmented graphs are positive or negative pairs is highly related with the multi-scale structures. Based on this finding, we propose a multi-scale subgraph contrastive learning method which is able to characterize the fine-grained semantic information. Specifically, we generate global and local 
    
[^7]: 修复: 在说明后修正LLM响应中的事实错误

    Re-Ex: Revising after Explanation Reduces the Factual Errors in LLM Responses

    [https://arxiv.org/abs/2402.17097](https://arxiv.org/abs/2402.17097)

    提出了一种名为Re-Ex的方法，通过引入事实错误说明步骤来修正LLM生成文本中的事实错误，并提出了新的提示技术来减少所需的标记数量和挂钟时间

    

    缓解幻觉问题是LLM的主要挑战之一，我们需要克服这一挑战，以便可靠地在现实场景中使用它们。最近，提出了各种方法来检查LLM生成的文本中的事实错误，并相应地进行修订，以减少幻觉问题。在本文中，我们提出了Re-Ex，一种修订LLM生成文本的方法，它引入了一个称为事实错误说明步骤的新步骤。 Re-Ex使用3个步骤对LLM的初始响应进行修订：首先，使用外部工具获取响应中事实错误的证据；第二，要求LLM根据第一步中收集的证据解释响应中的问题部分；最后，LLM使用在第二步中获得的解释对响应进行修订。除了说明步骤，我们还提出了新的提示技术，以减少所需的标记数量和挂钟时间。

    arXiv:2402.17097v1 Announce Type: cross  Abstract: Mitigating hallucination issues is one of the main challenges of LLMs we need to overcome, in order to reliably use them in real-world scenarios. Recently, various methods are proposed to check the factual errors in the LLM-generated texts and revise them accordingly, to reduce the hallucination issue. In this paper, we propose Re-Ex, a method of revising LLM-generated texts, which introduces a novel step dubbed as the factual error explanation step. Re-Ex revises the initial response of LLMs using 3-steps: first, external tools are used to get the evidences on the factual errors in the response; second, LLMs are instructed to explain the problematic parts of the response based on the evidences gathered in the first step; finally, LLMs revise the response using the explanation obtained in the second step. In addition to the explanation step, we propose new prompting techniques to reduce the amount of tokens and wall-clock time required
    
[^8]: 多任务学习用于具有跨问题零样本泛化的路径问题

    Multi-Task Learning for Routing Problem with Cross-Problem Zero-Shot Generalization

    [https://arxiv.org/abs/2402.16891](https://arxiv.org/abs/2402.16891)

    本研究首次尝试解决跨问题泛化的关键挑战，通过将VRPs定义为共享基础属性的不同组合，并通过属性组合同时解决它们，实现了零样本泛化的路径问题解决方法。

    

    车辆路径问题（VRPs）在许多实际应用中都能找到，已经成为几十年的重要研究课题。最近，利用基于学习的模型来解决VRPs的神经组合优化（NCO）方法引起了相当大的关注。然而，当前的NCO方法通常需要为每个路径问题构建一个模型，这显著阻碍了它们在具有不同属性的真实工业问题中的实际应用。在这项工作中，我们首次尝试解决跨问题泛化的关键挑战。具体而言，我们将VRPs定义为一组共享的基础属性的不同组合，并通过属性组合同时通过单一模型解决它们。通过这种方式，我们提出的模型能够成功解决具有未见属性组合的VRPs，实现零样本泛化。

    arXiv:2402.16891v1 Announce Type: cross  Abstract: Vehicle routing problems (VRPs), which can be found in numerous real-world applications, have been an important research topic for several decades. Recently, the neural combinatorial optimization (NCO) approach that leverages a learning-based model to solve VRPs without manual algorithm design has gained substantial attention. However, current NCO methods typically require building one model for each routing problem, which significantly hinders their practical application for real-world industry problems with diverse attributes. In this work, we make the first attempt to tackle the crucial challenge of cross-problem generalization. In particular, we formulate VRPs as different combinations of a set of shared underlying attributes and solve them simultaneously via a single model through attribute composition. In this way, our proposed model can successfully solve VRPs with unseen attribute combinations in a zero-shot generalization mann
    
[^9]: UMBCLU在SemEval-2024任务1A和1C中的表现：带有和不带有机器翻译的语义文本相关性

    UMBCLU at SemEval-2024 Task 1A and 1C: Semantic Textual Relatedness with and without machine translation

    [https://arxiv.org/abs/2402.12730](https://arxiv.org/abs/2402.12730)

    使用机器翻译和大型语言模型，本文开发了用于非洲和亚洲语言语义文本相关性任务的两种模型，取得了比部分官方基准更好的效果。

    

    这篇论文描述了我们为SemEval-2024任务1开发的系统，“非洲和亚洲语言的语义文本相关性”。 该任务的目标是构建一个能够识别目标语言中属于非洲和亚洲语言集合的两个句子之间的语义文本相关性（STR）的模型。 我们参与了子任务A和C，并探索了利用大型语言模型（LLMs）进行监督和跨语言训练。 预训练的大型语言模型已被广泛用于机器翻译和语义相似性。 使用机器翻译和句子嵌入LLMs的组合，我们为子任务A开发了一个统一的STR模型，TranSem，并对STR数据上的T5系列模型进行了微调，用于子任务C的FineSem。 我们在子任务A中7种语言的模型结果比3种语言的官方基准更好，而与其他4种语言的基准相当。

    arXiv:2402.12730v1 Announce Type: cross  Abstract: This paper describes the system we developed for SemEval-2024 Task 1, "Semantic Textual Relatedness for African and Asian Languages." The aim of the task is to build a model that can identify semantic textual relatedness (STR) between two sentences of a target language belonging to a collection of African and Asian languages. We participated in Subtasks A and C and explored supervised and cross-lingual training leveraging large language models (LLMs). Pre-trained large language models have been extensively used for machine translation and semantic similarity. Using a combination of machine translation and sentence embedding LLMs, we developed a unified STR model, TranSem, for subtask A and fine-tuned the T5 family of models on the STR data, FineSem, for use in subtask C. Our model results for 7 languages in subtask A were better than the official baseline for 3 languages and on par with the baseline for the remaining 4 languages. Our m
    
[^10]: 在美国评估有条件自动驾驶汽车的公众接受度

    Gauging Public Acceptance of Conditionally Automated Cars in the United States

    [https://arxiv.org/abs/2402.11444](https://arxiv.org/abs/2402.11444)

    本研究通过调查358名美国参与者，发现社会影响、性能期望、享受动机、便利条件和努力期望是影响有条件自动驾驶汽车接受度的重要因素。

    

    在这项工作中，我们探讨了智能城市的一个元素，即有条件自动驾驶汽车（SAE Level 3），研究了影响美国公众接受度的因素。我们应用了UTUAT2模型的改编版。通过实验方法，我们研究了358名美国参与者，向他们展示了一个概述L3技术的短篇故事，然后提出一系列问题，以捕捉他们对有条件自动驾驶汽车的感知。采用PLS-SEM对收集到的数据进行了分析。结果表明，技术的接受度，按重要性递减的顺序，受社会影响、性能期望、享受动机、便利条件和努力期望的影响。此外，享受动机、社会影响、便利条件和努力期望都对技术的实用性感知有积极影响；便利条件、享受动机和社会影响...

    arXiv:2402.11444v1 Announce Type: cross  Abstract: In this work we look at an element of smart cities, conditionally automated cars (SAE Level 3), investigating the factors influencing public acceptance in the United States. We apply an adaptation of the UTUAT2 model. Taking an experimental approach study 358 participants in the US were presented with a vignette outlining the L3 technology followed by a series of questions to capture their perceptions of conditionally automated cars. PLS-SEM was used to analyze the collected data. The results reveal that the acceptance of the technology, in order of decreasing importance, was determined by social influence, performance expectancy, hedonic motivation, facilitating conditions, and effort expectancy. Furthermore, hedonic motivation, social influence, facilitating conditions and effort expectancy all have a positive influence on the perception of how useful the technology is; facilitating conditions, hedonic motivation, and social influenc
    
[^11]: 通过对比预训练的方法利用评论辅助视频语言对齐用于短视频幽默检测

    Comment-aided Video-Language Alignment via Contrastive Pre-training for Short-form Video Humor Detection

    [https://arxiv.org/abs/2402.09055](https://arxiv.org/abs/2402.09055)

    本文提出了一种新颖的通过对比预训练的方法，命名为CVLA，用于短视频幽默检测。CVLA不仅适用于各种模态信号，还能通过在一致的语义空间中对齐视频和语言组件产生适合的多模式表示。实验证明，CVLA显著优于现有最先进方法和几个竞争基准方法。

    

    随着短视频在社交媒体平台上的影响力日益扩大，多模式幽默检测在情感计算中的重要性也日益增加。本文提出了一种新颖的用于短视频幽默检测的两层分层模型，命名为通过数据增强的多模式对比预训练的评论辅助视频语言对齐（CVLA）。值得注意的是，我们的CVLA不仅适用于各种模态信号，并且通过在一致的语义空间中对齐视频和语言组件，产生一个适合的多模式表示。在两个幽默检测数据集DY11k和UR-FUNNY上的实验结果表明，CVLA显著优于现有最先进方法和几个竞争基准方法。我们的数据集、代码和模型发布在https://github.com/yliu-cs/CVLA上。

    arXiv:2402.09055v1 Announce Type: cross Abstract: The growing importance of multi-modal humor detection within affective computing correlates with the expanding influence of short-form video sharing on social media platforms. In this paper, we propose a novel two-branch hierarchical model for short-form video humor detection (SVHD), named Comment-aided Video-Language Alignment (CVLA) via data-augmented multi-modal contrastive pre-training. Notably, our CVLA not only operates on raw signals across various modal channels but also yields an appropriate multi-modal representation by aligning the video and language components within a consistent semantic space. The experimental results on two humor detection datasets, including DY11k and UR-FUNNY, demonstrate that CVLA dramatically outperforms state-of-the-art and several competitive baseline approaches. Our dataset, code and model release at https://github.com/yliu-cs/CVLA.
    
[^12]: 基于UWB的静态手势分类

    UWB Based Static Gesture Classification

    [https://arxiv.org/abs/2310.15036](https://arxiv.org/abs/2310.15036)

    该论文提出了基于UWB的静态手势识别的稳健框架，经过数据集收集和处理，训练模型达到96.78%准确率，并开发了用户友好的GUI框架，为将UWB技术应用于静态手势识别带来了重要进展。

    

    我们的论文提出了一个稳健的框架，用于基于UWB的静态手势识别，利用专有的UWB雷达传感器技术。进行了大量数据收集工作，编制了包含五种常用手势的数据集。我们的方法涉及全面的数据预处理流程，包括异常值处理、保持长宽比的调整大小和伪彩色图像转换。我们对处理后的图像训练了CNN和MobileNet模型。值得注意的是，我们表现最佳的模型达到了96.78%的准确率。此外，我们开发了一个用户友好的GUI框架，用于评估模型的系统资源使用情况和处理时间，显示出低内存利用和在不到一秒的实时任务完成。这项研究是在使用UWB技术增强静态手势识别方面迈出的重要一步，具有在各个领域中应用的潜力。

    arXiv:2310.15036v2 Announce Type: replace-cross  Abstract: Our paper presents a robust framework for UWB-based static gesture recognition, leveraging proprietary UWB radar sensor technology. Extensive data collection efforts were undertaken to compile datasets containing five commonly used gestures. Our approach involves a comprehensive data pre-processing pipeline that encompasses outlier handling, aspect ratio-preserving resizing, and false-color image transformation. Both CNN and MobileNet models were trained on the processed images. Remarkably, our best-performing model achieved an accuracy of 96.78%. Additionally, we developed a user-friendly GUI framework to assess the model's system resource usage and processing times, which revealed low memory utilization and real-time task completion in under one second. This research marks a significant step towards enhancing static gesture recognition using UWB technology, promising practical applications in various domains.
    
[^13]: 没有数据访问的深度分类器模拟

    Deep Classifier Mimicry without Data Access

    [https://arxiv.org/abs/2306.02090](https://arxiv.org/abs/2306.02090)

    提出了一种无需访问原始数据的模型-无关知识蒸馏过程CAKE，可以模拟深度分类器，通过生成噪声合成样本对比地扩散到模型的决策边界。

    

    最近，对预先训练模型的访问已经成为许多机器学习领域的标准。不幸的是，可能无法等同地获得模型训练所需的原始数据。这使得微调、压缩模型、持续调整或进行任何其他类型的数据驱动更新变得极具挑战性。我们认为可能无需原始数据访问。具体而言，我们提出了对比推理知识提取（CAKE），这是一种模型无关的知识蒸馏过程，可以模拟深度分类器而无需访问原始数据。为此，CAKE生成一对噪声合成样本，并将它们对比地扩散到模型的决策边界。我们通过几个基准数据集和各种架构选择在实证上证实了CAKE的有效性，为广泛应用铺平了道路。

    arXiv:2306.02090v2 Announce Type: replace-cross  Abstract: Access to pre-trained models has recently emerged as a standard across numerous machine learning domains. Unfortunately, access to the original data the models were trained on may not equally be granted. This makes it tremendously challenging to fine-tune, compress models, adapt continually, or to do any other type of data-driven update. We posit that original data access may however not be required. Specifically, we propose Contrastive Abductive Knowledge Extraction (CAKE), a model-agnostic knowledge distillation procedure that mimics deep classifiers without access to the original data. To this end, CAKE generates pairs of noisy synthetic samples and diffuses them contrastively toward a model's decision boundary. We empirically corroborate CAKE's effectiveness using several benchmark datasets and various architectural choices, paving the way for broad application.
    
[^14]: 基于图诱导的局部值函数的分布式多智能体强化学习

    Distributed Multi-Agent Reinforcement Learning Based on Graph-Induced Local Value Functions

    [https://arxiv.org/abs/2202.13046](https://arxiv.org/abs/2202.13046)

    通过利用图结构，本文提出了一种通用计算高效的分布式框架，基于局部值函数的分布式RL方法在协作多智能体强化学习中取得了显著的样本复杂性降低。

    

    实现大规模协作多智能体系统的分布式强化学习(RL)具有挑战性，因为：(i)每个智能体只能访问有限的信息；(ii)由于维度诅咒，会出现收敛或计算复杂性问题。本文提出了一种通用的计算高效的协作多智能体强化学习(MARL)分布式框架，通过利用该问题中涉及的图结构。我们引入了描述MARL中三种类型智能体耦合的三个耦合图，分别是状态图、观测图和奖励图。通过进一步考虑通信图，我们提出了两种基于耦合图中派生的局部值函数的分布式RL方法。第一种方法在前述四个图上的特定条件下可以显著降低样本复杂性。第二种

    arXiv:2202.13046v4 Announce Type: replace-cross  Abstract: Achieving distributed reinforcement learning (RL) for large-scale cooperative multi-agent systems (MASs) is challenging because: (i) each agent has access to only limited information; (ii) issues on convergence or computational complexity emerge due to the curse of dimensionality. In this paper, we propose a general computationally efficient distributed framework for cooperative multi-agent reinforcement learning (MARL) by utilizing the structures of graphs involved in this problem. We introduce three coupling graphs describing three types of inter-agent couplings in MARL, namely, the state graph, the observation graph and the reward graph. By further considering a communication graph, we propose two distributed RL approaches based on local value-functions derived from the coupling graphs. The first approach is able to reduce sample complexity significantly under specific conditions on the aforementioned four graphs. The second
    
[^15]: 高级逻辑程序等价性属性的自动验证-学士论文

    Automated Verification of Equivalence Properties in Advanced Logic Programs -- Bachelor Thesis. (arXiv:2310.19806v1 [cs.LO])

    [http://arxiv.org/abs/2310.19806](http://arxiv.org/abs/2310.19806)

    这篇论文介绍了一种自动验证工具，用于验证优化的逻辑子程序是否可以替代原始子程序，在工业应用中具有重要意义。

    

    随着使用答案集编程的工业应用增加，对形式验证工具，特别是对关键应用的需求也增加了。在程序优化过程中，希望有一种工具可以自动验证优化的子程序是否可以替代原始子程序。从形式上讲，这对应于验证两个程序的强等价性的问题。为了做到这一点，开发了翻译工具anthem。它可以与用于经典逻辑的自动定理证明器一起使用，以验证两个程序是否强等价。在当前版本的anthem中，只能验证具有受限输入语言的正程序的强等价性。这是anthem中实现的翻译τ*的结果，它生成了here-and-there逻辑中的公式，该逻辑只对正程序与经典逻辑相一致。这篇论文扩展了anthem，以便可以验证更广泛的高级逻辑程序的强等价性。

    With the increase in industrial applications using Answer Set Programming, the need for formal verification tools, particularly for critical applications, has also increased. During the program optimisation process, it would be desirable to have a tool which can automatically verify whether an optimised subprogram can replace the original subprogram. Formally this corresponds to the problem of verifying the strong equivalence of two programs. In order to do so, the translation tool anthem was developed. It can be used in conjunction with an automated theorem prover for classical logic to verify that two programs are strongly equivalent. With the current version of anthem, only the strong equivalence of positive programs with a restricted input language can be verified. This is a result of the translation $\tau^*$ implemented in anthem that produces formulas in the logic of here-and-there, which coincides with classical logic only for positive programs. This thesis extends anthem in ord
    
[^16]: 通过附加件变得贝叶斯，捕捉更多不确定性

    Be Bayesian by Attachments to Catch More Uncertainty. (arXiv:2310.13027v1 [cs.LG])

    [http://arxiv.org/abs/2310.13027](http://arxiv.org/abs/2310.13027)

    本文提出了一种附加结构贝叶斯神经网络(ABNN)，通过在主干网络中整合足够分布外数据的不确定性，来提高神经网络对不确定性的捕捉能力。

    

    贝叶斯神经网络(BNNs)已成为不确定性评估的有希望方法之一，由于其坚实的理论基础。然而，BNNs的性能受到捕捉不确定性的能力的影响。本文提出了一种新的附加结构贝叶斯神经网络(ABNN)，通过附加结构从足够分布外的数据(OOD)中捕捉更多的不确定性。我们首先根据先验分布为OOD数据的不确定性构建了一个数学描述，然后开发了一个附加的贝叶斯结构将OOD数据的不确定性整合到主干网络中。ABNN由期望模块和若干分布模块组成。期望模块是一个专注于原始任务的主干深度网络，而分布模块则是作为主干的附加结构的小贝叶斯结构。特别地，这些分布模块的目的是检测和传播OOD数据的不确定性，从而提高整体网络的贝叶斯性质。

    Bayesian Neural Networks (BNNs) have become one of the promising approaches for uncertainty estimation due to the solid theorical foundations. However, the performance of BNNs is affected by the ability of catching uncertainty. Instead of only seeking the distribution of neural network weights by in-distribution (ID) data, in this paper, we propose a new Bayesian Neural Network with an Attached structure (ABNN) to catch more uncertainty from out-of-distribution (OOD) data. We first construct a mathematical description for the uncertainty of OOD data according to the prior distribution, and then develop an attached Bayesian structure to integrate the uncertainty of OOD data into the backbone network. ABNN is composed of an expectation module and several distribution modules. The expectation module is a backbone deep network which focuses on the original task, and the distribution modules are mini Bayesian structures which serve as attachments of the backbone. In particular, the distribu
    
[^17]: 使用Prompt调优的预训练语言模型加速主题投资

    Accelerating Thematic Investment with Prompt Tuned Pretrained Language Models. (arXiv:2309.12075v1 [cs.CL])

    [http://arxiv.org/abs/2309.12075](http://arxiv.org/abs/2309.12075)

    本研究通过Benchmark测试，发现使用Prompt Tuning的预训练语言模型在多标签文本分类任务中具有较好的性能和计算效率。同时，提出了使用Trie搜索来解决生成标签匹配问题的限制。

    

    Prompt Tuning作为一种可扩展且成本效益高的方法，正在成为细调预训练语言模型（PLMs）的一种流行方法。本研究基于多标签文本分类任务对Prompt Tuning和基准方法的性能和计算效率进行了基准测试。将其应用于将公司分类为投资公司专有的行业分类法，以支持其主题投资策略。在多标签分类问题中，使用PLMs进行文本到文本分类经常被报告为优于使用分类头进行分类，但在每个标签由多个令牌组成的多标签分类问题中，存在一些限制：（a）生成的标签可能不匹配行业分类法中的任何标签；（b）在细调阶段，必须以任意顺序提供多个标签；（c）模型为每个标签提供二进制决策，而不是适当的置信度分数。通过应用Trie搜索来解决限制（a）。

    Prompt Tuning is emerging as a scalable and cost-effective method to fine-tune Pretrained Language Models (PLMs). This study benchmarks the performance and computational efficiency of Prompt Tuning and baseline methods on a multi-label text classification task. This is applied to the use case of classifying companies into an investment firm's proprietary industry taxonomy, supporting their thematic investment strategy. Text-to-text classification with PLMs is frequently reported to outperform classification with a classification head, but has several limitations when applied to a multi-label classification problem where each label consists of multiple tokens: (a) Generated labels may not match any label in the industry taxonomy; (b) During fine-tuning, multiple labels must be provided in an arbitrary order; (c) The model provides a binary decision for each label, rather than an appropriate confidence score. Limitation (a) is addressed by applying constrained decoding using Trie Search,
    
[^18]: 基于Metapath的上下文知识的深度半监督异常检测

    Deep Semi-supervised Anomaly Detection with Metapath-based Context Knowledge. (arXiv:2308.10918v1 [cs.LG])

    [http://arxiv.org/abs/2308.10918](http://arxiv.org/abs/2308.10918)

    本文介绍了一种利用基于Metapath的半监督学习的新颖方法，用于图异常检测。通过在编码器和解码器中使用GCN层来有效传播上下文信息，以及特别设计的异常社区，该方法在结构和属性差异的学习中表现出优越性能。通过实验证明了该方法的有效性，为未来的研究提供了重要的思路和方向。

    

    图异常检测近年来引起了广泛的关注。本文介绍了一种新颖的方法，利用基于Metapath的半监督学习，解决了之前方法的局限性。我们提出了一种新的框架，基于Metapath的半监督异常检测（MSAD），在编码器和解码器中都使用GCN层来有效地传播异常和正常节点之间的上下文信息。基于Metapath的上下文信息的设计和特别精心设计的异常社区增强了全局和局部结构和属性差异的学习过程。通过在七个真实网络上进行的一系列综合实验，本文证明了MSAD方法相对于最先进技术的优越性。本研究的有希望的结果为未来的研究铺平了道路，重点是优化和分析Metapath模式以进一步提高方法的效果。

    Graph anomaly detection has attracted considerable attention in recent years. This paper introduces a novel approach that leverages metapath-based semi-supervised learning, addressing the limitations of previous methods. We present a new framework, Metapath-based Semi-supervised Anomaly Detection (MSAD), incorporating GCN layers in both the encoder and decoder to efficiently propagate context information between abnormal and normal nodes. The design of metapath-based context information and a specifically crafted anomaly community enhance the process of learning differences in structures and attributes, both globally and locally. Through a comprehensive set of experiments conducted on seven real-world networks, this paper demonstrates the superiority of the MSAD method compared to state-of-the-art techniques. The promising results of this study pave the way for future investigations, focusing on the optimization and analysis of metapath patterns to further enhance the effectiveness of 
    
[^19]: 对脑网络的可解释分类进行对比图池化。

    Contrastive Graph Pooling for Explainable Classification of Brain Networks. (arXiv:2307.11133v1 [q-bio.NC])

    [http://arxiv.org/abs/2307.11133](http://arxiv.org/abs/2307.11133)

    本论文提出了一种针对脑网络的对比图池化方法，以实现对脑网络的可解释分类。通过定制化的图神经网络和特殊设计的可解释特征提取方法，在5个静息态fMRI脑网络数据集上取得了优于最先进基准线的结果。

    

    功能性磁共振成像(fMRI)是一种常用的测量神经活动的技术。其应用在识别帕金森病、阿尔茨海默病和自闭症等神经退行性疾病方面尤为重要。最近的fMRI数据分析将大脑建模为图，并通过图神经网络(GNN)提取特征。然而，fMRI数据的独特特征要求对GNN进行特殊设计。定制GNN以生成有效且可解释的特征仍然具有挑战性。在本文中，我们提出了对比双注意块和可微分图池化方法ContrastPool，以更好地利用GNN分析脑网络，满足fMRI的特殊要求。我们将我们的方法应用于5个静息态fMRI脑网络数据集的3种疾病，并证明其优于最先进的基准线。我们的案例研究证实，我们的方法提取的模式与神经科学文献中的领域知识相匹配。

    Functional magnetic resonance imaging (fMRI) is a commonly used technique to measure neural activation. Its application has been particularly important in identifying underlying neurodegenerative conditions such as Parkinson's, Alzheimer's, and Autism. Recent analysis of fMRI data models the brain as a graph and extracts features by graph neural networks (GNNs). However, the unique characteristics of fMRI data require a special design of GNN. Tailoring GNN to generate effective and domain-explainable features remains challenging. In this paper, we propose a contrastive dual-attention block and a differentiable graph pooling method called ContrastPool to better utilize GNN for brain networks, meeting fMRI-specific requirements. We apply our method to 5 resting-state fMRI brain network datasets of 3 diseases and demonstrate its superiority over state-of-the-art baselines. Our case study confirms that the patterns extracted by our method match the domain knowledge in neuroscience literatu
    
[^20]: 非累积目标的强化学习

    Reinforcement Learning with Non-Cumulative Objective. (arXiv:2307.04957v1 [cs.LG])

    [http://arxiv.org/abs/2307.04957](http://arxiv.org/abs/2307.04957)

    本文研究了最优控制和强化学习中非累积目标的挑战，并提出了修改现有算法的方法来优化这些目标。研究结果表明，在贝尔曼最优性方程中使用广义运算可以更好地处理非累积目标。

    

    在强化学习中，目标几乎总是定义为沿过程中奖励的\emph{累积}函数。然而，在许多最优控制和强化学习问题中，尤其是在通信和网络领域中，目标并不自然地表达为奖励的求和。本文中，我们认识到各种问题中非累积目标的普遍存在，并提出了修改现有算法以优化这些目标的方法。具体来说，我们深入研究了许多最优控制和强化学习算法的基本构建模块：贝尔曼最优性方程。为了优化非累积目标，我们用与目标相对应的广义运算替换了贝尔曼更新规则中的原始求和运算。此外，我们提供了广义运算形式的足够条件以及对马尔可夫决策的假设。

    In reinforcement learning, the objective is almost always defined as a \emph{cumulative} function over the rewards along the process. However, there are many optimal control and reinforcement learning problems in various application fields, especially in communications and networking, where the objectives are not naturally expressed as summations of the rewards. In this paper, we recognize the prevalence of non-cumulative objectives in various problems, and propose a modification to existing algorithms for optimizing such objectives. Specifically, we dive into the fundamental building block for many optimal control and reinforcement learning algorithms: the Bellman optimality equation. To optimize a non-cumulative objective, we replace the original summation operation in the Bellman update rule with a generalized operation corresponding to the objective. Furthermore, we provide sufficient conditions on the form of the generalized operation as well as assumptions on the Markov decision 
    
[^21]: CLIPMasterPrints: 使用潜在变量演化欺骗对比式语言-图像预训练

    CLIPMasterPrints: Fooling Contrastive Language-Image Pre-training Using Latent Variable Evolution. (arXiv:2307.03798v1 [cs.CV])

    [http://arxiv.org/abs/2307.03798](http://arxiv.org/abs/2307.03798)

    本文展示了对比式语言-图像预训练（CLIP）模型的脆弱性，通过挖掘生成模型的潜在空间可以找到欺骗主图像，这些图像在许多不同的提示下能欺骗CLIP模型，而对人类来说是无法认出的。欺骗主图像在少量图像标题上的训练上可能适用于更多数量的语义相关的标题。两种可能的缓解策略被评估，并发现脆弱性与对比式预训练中的模态差距密切相关。

    

    以对比式语言-图像预训练（CLIP）为代表的同时利用视觉和文本数据的模型越来越重要。本文展示了尽管这些模型具有多功能性，但它们对于所谓的欺骗主图像是脆弱的。欺骗主图像能够最大化CLIP模型在许多不同的提示下的置信度评分，同时对于人类来说是无法认出的。我们展示了如何通过使用演化策略或随机梯度下降在生成模型的潜在空间中搜索欺骗主图像。我们研究了挖掘出的欺骗主图像的特性，并发现在少量图像标题上训练的图像可能适用于更多数量的语义相关的标题。此外，我们评估了两种可能的缓解策略，并发现对欺骗主例子的脆弱性与对比式预训练中的模态差距密切相关。

    Models leveraging both visual and textual data such as Contrastive Language-Image Pre-training (CLIP), are increasingly gaining importance. In this work, we show that despite their versatility, such models are vulnerable to what we refer to as fooling master images. Fooling master images are capable of maximizing the confidence score of a CLIP model for a significant number of widely varying prompts, while being unrecognizable for humans. We demonstrate how fooling master images can be mined by searching the latent space of generative models by means of an evolution strategy or stochastic gradient descent. We investigate the properties of the mined fooling master images, and find that images trained on a small number of image captions potentially generalize to a much larger number of semantically related captions. Further, we evaluate two possible mitigation strategies and find that vulnerability to fooling master examples is closely related to a modality gap in contrastive pre-trained
    
[^22]: 测量语言模型中主观全球观点的方法研究

    Towards Measuring the Representation of Subjective Global Opinions in Language Models. (arXiv:2306.16388v1 [cs.CL])

    [http://arxiv.org/abs/2306.16388](http://arxiv.org/abs/2306.16388)

    本文提出了一个方法来评估大型语言模型对全球观点的代表性。通过构建一个包含跨国调查问题和答案的数据集，并定义一个相似度度量标准，研究发现默认情况下语言模型的回应更倾向于某些人群的观点，但当模型考虑特定国家的观点时，回应会更加贴近该国家的观点。

    

    大型语言模型（LLMs）可能无法公平地代表社会问题中多样化的全球观点。本文开发了一个定量框架，用于评估模型生成的回答与哪些人的观点更为相似。我们首先构建了一个数据集GlobalOpinionQA，包含了来自跨国调查的问题和答案，旨在捕捉不同国家关于全球问题的多样观点。然后，我们定义了一个度量标准，以国家为条件，量化了LLM生成的调查回答与人类回答之间的相似性。在我们的框架下，我们对一个经过宪法AI培训的LLM进行了三个实验，分别考虑其帮助性、诚实性和无害性。默认情况下，LLM的回应更倾向于与某些人群的观点更类似，例如来自美国、欧洲和南美洲的人群，凸显了潜在的偏见。当我们提示模型考虑某个特定国家的观点时，回应会更加类似于该国家的观点。

    Large language models (LLMs) may not equitably represent diverse global perspectives on societal issues. In this paper, we develop a quantitative framework to evaluate whose opinions model-generated responses are more similar to. We first build a dataset, GlobalOpinionQA, comprised of questions and answers from cross-national surveys designed to capture diverse opinions on global issues across different countries. Next, we define a metric that quantifies the similarity between LLM-generated survey responses and human responses, conditioned on country. With our framework, we run three experiments on an LLM trained to be helpful, honest, and harmless with Constitutional AI. By default, LLM responses tend to be more similar to the opinions of certain populations, such as those from the USA, and some European and South American countries, highlighting the potential for biases. When we prompt the model to consider a particular country's perspective, responses shift to be more similar to the
    
[^23]: RDFC-GAN:室内深度完形补全的RGB-Depth融合CycleGAN(arXiv:2306.03584v1 [cs.CV])

    RDFC-GAN: RGB-Depth Fusion CycleGAN for Indoor Depth Completion. (arXiv:2306.03584v1 [cs.CV])

    [http://arxiv.org/abs/2306.03584](http://arxiv.org/abs/2306.03584)

    RDFC-GAN使用两个分支结构生成精确的深度图像，它通过解决室内环境中普遍缺失的大面积深度值问题，克服了现有方法的不足，可用于各种室内深度完成任务。

    

    室内深度传感器捕捉的原始深度图像通常具有大量缺失深度值的范围，导致了很多带下游视觉任务的不完整的深度图，因此已经提出了越来越多的深度完成方法。为了解决这些问题，设计了一种名为RDFC-GAN的新颖的双支端到端融合网络，它需要一对RGB和不完整深度图像作为输入来预测一个密集的和完成的深度图。

    The raw depth image captured by indoor depth sensors usually has an extensive range of missing depth values due to inherent limitations such as the inability to perceive transparent objects and the limited distance range. The incomplete depth map with missing values burdens many downstream vision tasks, and a rising number of depth completion methods have been proposed to alleviate this issue. While most existing methods can generate accurate dense depth maps from sparse and uniformly sampled depth maps, they are not suitable for complementing large contiguous regions of missing depth values, which is common and critical in images captured in indoor environments. To overcome these challenges, we design a novel two-branch end-to-end fusion network named RDFC-GAN, which takes a pair of RGB and incomplete depth images as input to predict a dense and completed depth map. The first branch employs an encoder-decoder structure, by adhering to the Manhattan world assumption and utilizing norma
    
[^24]: HICO-DET-SG和V-COCO-SG：新的数据拆分用于评估人-物交互检测中的系统性泛化

    HICO-DET-SG and V-COCO-SG: New Data Splits to Evaluate Systematic Generalization in Human-Object Interaction Detection. (arXiv:2305.09948v1 [cs.CV])

    [http://arxiv.org/abs/2305.09948](http://arxiv.org/abs/2305.09948)

    本论文提出了两个新的HOI检测数据拆分，旨在评估系统性泛化。在新的数据拆分上测试结果表明，HOI检测模型对于未见过的对象和交互组合的泛化十分困难。

    

    人-物交互检测是一种预测图像中人与物品之间交互的任务。在实际场景中，需要对HOI检测模型进行系统性的泛化，即泛化到新的对象和交互组合上，因为训练数据仅可能涵盖所有可能组合的一小部分。然而，据我们所知，没有开放的基准测试或现有工作评估HOI检测中的系统性泛化。为解决这个问题，我们基于HICO-DET和V-COCO数据集创建了两个名为HICO-DET-SG和V-COCO-SG的新的HOI检测数据拆分。我们在新的数据拆分上评估了代表性的HOI检测模型，并观察到与原始数据集上相比测试性能有很大的降低。这个结果表明系统性泛化是HOI检测中一个具有挑战性的目标。我们希望我们的新数据拆分能够鼓励更多的研究朝着这个目标努力。

    Human-Object Interaction (HOI) detection is a task to predict interactions between humans and objects in an image. In real-world scenarios, HOI detection models are required systematic generalization, i.e., generalization to novel combinations of objects and interactions, because it is highly probable that the train data only cover a limited portion of all possible combinations. However, to our knowledge, no open benchmark or existing work evaluates the systematic generalization in HOI detection. To address this issue, we created two new sets of HOI detection data splits named HICO-DET-SG and V-COCO-SG based on HICO-DET and V-COCO datasets. We evaluated representative HOI detection models on the new data splits and observed large degradation in the test performances compared to those on the original datasets. This result shows that systematic generalization is a challenging goal in HOI detection. We hope our new data splits encourage more research toward this goal.
    
[^25]: 无视觉基线的多模式语法归纳

    A Vision-free Baseline for Multimodal Grammar Induction. (arXiv:2212.10564v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10564](http://arxiv.org/abs/2212.10564)

    本论文研究了在多模式设置下，只使用文本进行训练的大型语言模型（LLMs）是否能够提供强大的辅助来进行语法归纳。结果显示，基于LLM的纯文本方法在多种多模式数据集上优于先前的方法，并且在性能、参数数量和训练速度方面取得了最先进的结果。

    

    过去的研究表明，配对的视觉与语言信号能够显著改善多模式数据集（如MSCOCO）中的语法归纳。我们研究了只使用文本进行训练的大型语言模型（LLMs）在多模式设置下是否能够提供强大的辅助来进行语法归纳。我们发现，我们的纯文本方法，即基于LLM的C-PCFG（LC-PCFG），在各种多模式数据集上优于先前的多模式方法，并且获得了最先进的语法归纳性能。与带图像的语法归纳相比，LC-PCFG在语料库F1得分上超过了先前的最先进方法7.9个点，参数数量减少了85％，训练速度加快了1.7倍。在三个辅助视频的语法归纳基准中，LC-PCFG在语料库F1上优于先前的最先进方法最多7.7个点，训练速度加快了8.8倍。

    Past work has shown that paired vision-language signals substantially improve grammar induction in multimodal datasets such as MSCOCO. We investigate whether advancements in large language models (LLMs) that are only trained with text could provide strong assistance for grammar induction in multimodal settings. We find that our text-only approach, an LLM-based C-PCFG (LC-PCFG), outperforms previous multi-modal methods, and achieves state-of-the-art grammar induction performance for various multimodal datasets. Compared to image-aided grammar induction, LC-PCFG outperforms the prior state-of-the-art by 7.9 Corpus-F1 points, with an 85% reduction in parameter count and 1.7x faster training speed. Across three video-assisted grammar induction benchmarks, LC-PCFG outperforms prior state-of-the-art by up to 7.7 Corpus-F1, with 8.8x faster training. These results shed light on the notion that text-only language models might include visually grounded cues that aid in grammar induction in mult
    
[^26]: 怎样解决面对对抗状态的多智能体强化学习问题？

    What is the Solution for State-Adversarial Multi-Agent Reinforcement Learning?. (arXiv:2212.02705v4 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2212.02705](http://arxiv.org/abs/2212.02705)

    本文提出了一种解决面对对抗性状态的多智能体强化学习问题的方法，通过引入状态对抗性马尔科夫博弈，提出了鲁棒智能体策略的概念，并证明了其在有限状态和有限动作情况下的存在性。此外，还提出了一种鲁棒多智能体对抗性演员-评论家算法，用于学习在状态不确定性下的鲁棒性策略。

    

    在多智能体强化学习(MARL)中，已经开发了各种方法，假设智能体的策略基于准确的状态信息。然而，通过深度强化学习(DRL)学习的策略容易受到对抗性状态扰动攻击的影响。在这项工作中，我们提出了一种状态对抗性马尔科夫博弈(SAMG)，并首次尝试研究状态不确定性下MARL的基本属性。我们的分析表明，在SAMG中，通常使用的最优智能体策略和鲁棒纳什均衡解决概念并不总是存在的。为了克服这个困难，我们考虑了一种称为鲁棒智能体策略的新解决概念，其中智能体的目标是最大化最坏情况下的预期状态值。我们证明了有限状态和有限动作SAMG中存在鲁棒智能体策略。此外，我们提出了一种名为鲁棒多智能体对抗性演员-评论家(RMA3C)算法，用于学习在状态不确定性下的MARL智能体的鲁棒性策略。

    Various methods for Multi-Agent Reinforcement Learning (MARL) have been developed with the assumption that agents' policies are based on accurate state information. However, policies learned through Deep Reinforcement Learning (DRL) are susceptible to adversarial state perturbation attacks. In this work, we propose a State-Adversarial Markov Game (SAMG) and make the first attempt to investigate the fundamental properties of MARL under state uncertainties. Our analysis shows that the commonly used solution concepts of optimal agent policy and robust Nash equilibrium do not always exist in SAMGs. To circumvent this difficulty, we consider a new solution concept called robust agent policy, where agents aim to maximize the worst-case expected state value. We prove the existence of robust agent policy for finite state and finite action SAMGs. Additionally, we propose a Robust Multi-Agent Adversarial Actor-Critic (RMA3C) algorithm to learn robust policies for MARL agents under state uncertai
    

