# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Unsolvable Problem Detection: Evaluating Trustworthiness of Vision Language Models](https://arxiv.org/abs/2403.20331) | 本文提出了一个新颖且重要的挑战，即Unsolvable Problem Detection（UPD），用于评估视觉语言模型在视觉问答任务中能否在面对不可解问题时保持答案的能力，并通过广泛实验发现大多数模型存在改进的空间。 |
| [^2] | [ReALM: Reference Resolution As Language Modeling](https://arxiv.org/abs/2403.20329) | 本论文展示了如何利用LLMs创建一个极其有效的系统来解决各种类型的引用问题，通过将参考解析转化为语言建模问题，尽管涉及到屏幕上的实体等不易约简为纯文本形式的实体。 |
| [^3] | [MTLoRA: A Low-Rank Adaptation Approach for Efficient Multi-Task Learning](https://arxiv.org/abs/2403.20320) | MTLoRA提出了一种新颖的多任务学习模型参数高效训练框架，通过任务不可知和任务特定的低秩适应模块有效地实现了参数空间的分离，使得模型能够灵活处理任务专业化和在多任务学习环境中的相互作用 |
| [^4] | [SeaBird: Segmentation in Bird's View with Dice Loss Improves Monocular 3D Detection of Large Objects](https://arxiv.org/abs/2403.20318) | 通过研究回归和Dice损失在大物体上的表现，我们发现Dice损失相对于回归损失在大物体上具有更好的噪声鲁棒性和模型收敛性。 |
| [^5] | [ChainNet: Structured Metaphor and Metonymy in WordNet](https://arxiv.org/abs/2403.20308) | ChainNet是一个词典资源，首次明确地识别了WordNet中词义的结构化隐喻和转喻关系，成为第一个具有基础隐喻和转喻数据集的资源。 |
| [^6] | [Towards Greener LLMs: Bringing Energy-Efficiency to the Forefront of LLM Inference](https://arxiv.org/abs/2403.20306) | 本文旨在将能效作为LLM推理的主要目标，并探讨在满足性能目标的前提下如何最大程度地提高能源利用效率。 |
| [^7] | [Improving Learnt Local MAPF Policies with Heuristic Search](https://arxiv.org/abs/2403.20300) | 我们提出了通过在输出概率分布上使用启发式搜索方法来改进ML局部策略，以解决死锁并启用完整时间跨度规划的主要想法 |
| [^8] | [Can LLMs Correct Physicians, Yet? Investigating Effective Interaction Methods in the Medical Domain](https://arxiv.org/abs/2403.20288) | LLMs在医学决策中提供重要反馈，可以挑战不正确的诊断，促进更准确的决策。 |
| [^9] | [Sparse multimodal fusion with modal channel attention](https://arxiv.org/abs/2403.20280) | 研究了蒙特卡罗多模态变换器架构在模态样本稀疏对齐时学习稳健嵌入空间的能力，并提出了模态通道注意力（MCA）机制，可以改善生成的嵌入空间质量和下游任务性能。 |
| [^10] | [Latxa: An Open Language Model and Evaluation Suite for Basque](https://arxiv.org/abs/2403.20266) | Latxa是一种用于巴斯克语的大型语言模型系列，在语言熟练度和理解能力方面表现出色，优于所有以前的开放模型，并具有多个评估数据集，填补了巴斯克语高质量基准的不足。 |
| [^11] | [ELITR-Bench: A Meeting Assistant Benchmark for Long-Context Language Models](https://arxiv.org/abs/2403.20262) | 该论文提出了一个新的基准 ELITR-Bench，专注于长上下文语言模型的实际会议助理场景，通过在现有 ELITR 语料库的转录中添加手工制作的问题和真实答案，揭示了开源模型和专有模型之间的差距。 |
| [^12] | [FABind+: Enhancing Molecular Docking through Improved Pocket Prediction and Pose Generation](https://arxiv.org/abs/2403.20261) | FABind+通过改进口袋预测和姿态生成，提升分子对接表现 |
| [^13] | [Using LLMs to Model the Beliefs and Preferences of Targeted Populations](https://arxiv.org/abs/2403.20252) | 使用LLMs建模目标人群的信念和偏好，旨在实现各种应用，评估不同微调方法的效果，并检验其在匹配真实人类受访者偏好方面的能力。 |
| [^14] | [Optimal Policy Learning with Observational Data in Multi-Action Scenarios: Estimation, Risk Preference, and Potential Failures](https://arxiv.org/abs/2403.20250) | 本文讨论了多动作场景中利用观测数据进行最优策略学习的方法，着重探讨了估计、风险偏好和潜在故障三个方面。 |
| [^15] | [Artificial Neural Networks-based Real-time Classification of ENG Signals for Implanted Nerve Interfaces](https://arxiv.org/abs/2403.20234) | 本文探讨了基于人工神经网络的实时分类ENG信号的方法，通过比较ANNs在不同大小数据集上的表现来分析其在处理运动/感觉刺激分类任务中的可行性。 |
| [^16] | [Graph Neural Aggregation-diffusion with Metastability](https://arxiv.org/abs/2403.20221) | 提出了GRADE模型，通过图聚合-扩散方程实现了节点表示的亚稳定性，能够缓解图神经网络中过度平滑的问题。 |
| [^17] | [Distributed agency in second language learning and teaching through generative AI](https://arxiv.org/abs/2403.20216) | 生成式人工智能在第二语言学习和教学中提供了分布式机构，并可能使沉浸式技术更强大和多功能。 |
| [^18] | [On Size and Hardness Generalization in Unsupervised Learning for the Travelling Salesman Problem](https://arxiv.org/abs/2403.20212) | 研究了无监督学习在解决旅行商问题中的泛化能力，结果表明，使用更大的实例大小进行训练并增加嵌入维度可以构建更有效的表示，增强模型解决TSP问题的能力。 |
| [^19] | [The Future of Combating Rumors? Retrieval, Discrimination, and Generation](https://arxiv.org/abs/2403.20204) | 通过综合的辟谣流程，不仅能检测谣言，还能提供解释性生成内容来驳斥信息的真实性，并且利用专家-公民集体智慧模块确保信息可信度高精度评估。 |
| [^20] | [NeuraLunaDTNet: Feedforward Neural Network-Based Routing Protocol for Delay-Tolerant Lunar Communication Networks](https://arxiv.org/abs/2403.20199) | 提出了NeuraLunaDTNet协议，利用前馈神经网络增强了PRoPHET路由协议，通过学习动态变化的时空图中的联系计划来优化月球通信效率。 |
| [^21] | [Distributed Swarm Learning for Edge Internet of Things](https://arxiv.org/abs/2403.20188) | 本文探讨了一种名为分布式群智能学习（DSL）的新型框架，将人工智能和生物群智能结合在一起，为大规模IoT在无线网络边缘提供高效的解决方案和稳健的工具。 |
| [^22] | [HARMamba: Efficient Wearable Sensor Human Activity Recognition Based on Bidirectional Selective SSM](https://arxiv.org/abs/2403.20183) | HARMamba利用更轻量级的选择性SSM作为基础模型架构，以解决计算资源挑战 |
| [^23] | [Artificial consciousness. Some logical and conceptual preliminaries](https://arxiv.org/abs/2403.20177) | 需要在人工系统中平衡讨论意识的可能实现，提出了使用意识的维度和特征来进行讨论的必要性。 |
| [^24] | [ChatGPT v.s. Media Bias: A Comparative Study of GPT-3.5 and Fine-tuned Language Models](https://arxiv.org/abs/2403.20158) | 研究比较了ChatGPT与Fine-tuned语言模型在检测媒体偏见方面的表现，发现ChatGPT在检测仇恨言论和文本级上下文偏见方面表现一致，但在检测虚假新闻、种族、性别和认知偏见方面则存在困难。 |
| [^25] | [CAESAR: Enhancing Federated RL in Heterogeneous MDPs through Convergence-Aware Sampling with Screening](https://arxiv.org/abs/2403.20156) | CAESAR算法通过结合收敛感知采样和筛选机制，有效增强了个体代理在不同MDPs上的学习。 |
| [^26] | [A Learning-based Incentive Mechanism for Mobile AIGC Service in Decentralized Internet of Vehicles](https://arxiv.org/abs/2403.20151) | 本文提出了一个基于多智能体深度强化学习的分散式激励机制，旨在在车联网环境中为移动AIGC服务分配的供需平衡。 |
| [^27] | [TFB: Towards Comprehensive and Fair Benchmarking of Time Series Forecasting Methods](https://arxiv.org/abs/2403.20150) | TFB通过解决数据领域覆盖不足、对传统方法的刻板印象以及不一致、不灵活的流程等问题，推动了时间序列预测方法基准比较的最新技术发展。 |
| [^28] | [Accurate Block Quantization in LLMs with Outliers](https://arxiv.org/abs/2403.20137) | LLM中出现的离群值问题，通过引入Block浮点（BFP）格式，实现了准确的块量化，解决了大规模推理需求中的硬件支持效率问题。 |
| [^29] | [The Impact of Prompts on Zero-Shot Detection of AI-Generated Text](https://arxiv.org/abs/2403.20127) | 零样本检测器通常独立分析AI生成文本，而忽略了原始提示的影响，可能导致在可能性评估中存在差异 |
| [^30] | [Mol-AIR: Molecular Reinforcement Learning with Adaptive Intrinsic Rewards for Goal-directed Molecular Generation](https://arxiv.org/abs/2403.20109) | Mol-AIR 提出了使用自适应内在奖励的分子强化学习框架，通过利用历史和学习的内在奖励优势，在生成具有期望性质的分子方面表现出卓越性能。 |
| [^31] | [ITCMA: A Generative Agent Based on a Computational Consciousness Structure](https://arxiv.org/abs/2403.20097) | ITCMA是基于计算意识结构的生成式Agent，通过考虑Agent与环境的互动和推理，增强了LLMs理解隐含指令和应用常识知识的能力，在Alfworld环境中表现优于SOTA。 |
| [^32] | [Implications of the AI Act for Non-Discrimination Law and Algorithmic Fairness](https://arxiv.org/abs/2403.20089) | AI法案可能成为弥合算法公平性和欧盟非歧视法律的重要一环，通过将非歧视责任转移到AI模型设计阶段，推动偏见检测和偏见校正的相关实践。 |
| [^33] | [Revolutionizing Disease Diagnosis with simultaneous functional PET/MR and Deeply Integrated Brain Metabolic, Hemodynamic, and Perfusion Networks](https://arxiv.org/abs/2403.20058) | 提出了MX-ARM，一种基于AI的疾病诊断模型，利用同时功能PET/MR技术，能够在推理过程中同时接受单模态和多模态输入，具有创新的模态分离和重构功能。 |
| [^34] | [Adverb Is the Key: Simple Text Data Augmentation with Adverb Deletion](https://arxiv.org/abs/2403.20015) | 使用简单的副词删除策略，提出了一种新颖的文本数据增强方法，能有效增强文本数据，保留语义，适用于单一文本分类和自然语言推理。 |
| [^35] | [PURPLE: Making a Large Language Model a Better SQL Writer](https://arxiv.org/abs/2403.20014) | 提出了PURPLE模型，通过检索演示来提高大型语言模型在SQL生成中的准确性 |
| [^36] | [Colorful Cutout: Enhancing Image Data Augmentation with Curriculum Learning](https://arxiv.org/abs/2403.20012) | 采用课程学习的方法提出了一种名为多彩剪贴的图像数据增强技术，逐渐增加增强图像的噪声和难度，从而改善模型性能。 |
| [^37] | [Development of Compositionality and Generalization through Interactive Learning of Language and Action of Robots](https://arxiv.org/abs/2403.19995) | 提出了一个融合视觉、本体感知和语言的大脑启发式神经网络模型，通过预测编码和主动推断的框架，基于自由能原理，实现了语言组合性和感觉运动技能的联合发展。 |
| [^38] | [MindArm: Mechanized Intelligent Non-Invasive Neuro-Driven Prosthetic Arm System](https://arxiv.org/abs/2403.19992) | 提出了一种低成本技术解决方案MindArm，利用深度神经网络将大脑信号翻译成假肢运动，帮助患者执行各种活动 |
| [^39] | [Semantically-Shifted Incremental Adapter-Tuning is A Continual ViTransformer](https://arxiv.org/abs/2403.19979) | 适配器调整方法在持续学习中展现出较优性能，提出了增量调整共享适配器和利用存储原型进行特征采样和更新的方法来增强模型学习能力。 |
| [^40] | [Enhancing the General Agent Capabilities of Low-Parameter LLMs through Tuning and Multi-Branch Reasoning](https://arxiv.org/abs/2403.19962) | 通过构建特定于代理的数据并细调模型以及设计能够有效激活LLMs推理能力的提示，提出了一种综合方法来增强低参数LLMs的通用代理功能。 |
| [^41] | [A Peg-in-hole Task Strategy for Holes in Concrete](https://arxiv.org/abs/2403.19946) | 提出了一种使工业机器人能够在混凝土孔中完成插销任务的方法，该方法通过使用深度神经网络和轻微将插销与墙面分离的策略，在无需解析建模或控制参数调整的情况下有效地找到混凝土孔。 |
| [^42] | [TDANet: A Novel Temporal Denoise Convolutional Neural Network With Attention for Fault Diagnosis](https://arxiv.org/abs/2403.19943) | TDANet是一种新颖的具有注意力机制的时间去噪卷积神经网络，旨在改善噪声环境下的故障诊断性能。 |
| [^43] | [Diverse Feature Learning by Self-distillation and Reset](https://arxiv.org/abs/2403.19941) | 提出了一种名为Diverse Feature Learning (DFL)的方法，通过结合重要特征保留算法和新特征学习算法，利用自蒸馏和重置来解决模型学习多样特征时遇到的问题。 |
| [^44] | [Decision Mamba: Reinforcement Learning via Sequence Modeling with Selective State Spaces](https://arxiv.org/abs/2403.19925) | 本研究将Mamba框架整合到Decision Transformer架构中，提出了Decision Mamba，通过在不同决策环境中进行一系列实验，表明了神经网络的架构和训练方法对性能的重要影响 |
| [^45] | [CtRL-Sim: Reactive and Controllable Driving Agents with Offline Reinforcement Learning](https://arxiv.org/abs/2403.19918) | CtRL-Sim提出了一种利用离线强化学习生成反应性和可控交通代理的方法，通过在Nocturne模拟器中处理真实世界的驾驶数据来实现这一目标。 |
| [^46] | [MANGO: A Benchmark for Evaluating Mapping and Navigation Abilities of Large Language Models](https://arxiv.org/abs/2403.19913) | 提出了用于评估大型语言模型执行文本映射和导航能力的MANGO基准，发现即使是迄今为止最好的语言模型GPT-4在回答涉及映射和导航的问题时表现不佳。 |
| [^47] | [Beyond the Known: Novel Class Discovery for Open-world Graph Learning](https://arxiv.org/abs/2403.19907) | 本文提出了一种名为ORAL的新方法，用于在开放世界图学习中发现新类别，通过半监督原型学习和原型注意力网络解决了新类别和已知类别节点之间的相关性问题。 |
| [^48] | [Classification of Diabetic Retinopathy using Pre-Trained Deep Learning Models](https://arxiv.org/abs/2403.19905) | 本研究提出了一个使用预训练深度学习模型对糖尿病视网膜病变进行分类的计算机辅助诊断系统，通过微调技术训练模型，实现了高效的自动分类，实验结果证明了方法的有效性。 |
| [^49] | [Towards a Robust Retrieval-Based Summarization System](https://arxiv.org/abs/2403.19889) | 该论文对大型语言模型在检索增强生成-基础摘要任务中的健壮性进行了调查，并提出了一个创新的评估框架和一个全面的系统来增强模型在特定场景下的健壮性。 |
| [^50] | [MambaMixer: Efficient Selective State Space Models with Dual Token and Channel Selection](https://arxiv.org/abs/2403.19888) | MambaMixer是一种新的架构，提出了具有数据依赖权重的双重选择机制，称为选择性标记和通道混合器，对长序列建模具有潜在优势。 |
| [^51] | [Policy-Space Search: Equivalences, Improvements, and Compression](https://arxiv.org/abs/2403.19883) | 该论文研究并改进了AND*执行的政策空间搜索的性能，提出了三个政策之间的等价性概念，并利用政策等价性修剪政策搜索空间，从而使AND*在解决FOND任务时更加有效。 |
| [^52] | [IME: Integrating Multi-curvature Shared and Specific Embedding for Temporal Knowledge Graph Completion](https://arxiv.org/abs/2403.19881) | IME模型用于时间知识图完成任务，将知识图建模为多曲率空间，包括超球面、双曲线和欧几里得空间，并融合空间共享属性和空间特定属性。 |
| [^53] | [Towards Stable Machine Learning Model Retraining via Slowly Varying Sequences](https://arxiv.org/abs/2403.19871) | 通过混合整数优化算法，以保持一致的分析洞见为重点，在重新训练机器学习模型中实现比贪婪训练更强稳定性，同时在模型性能上有小幅、可控的牺牲。 |
| [^54] | [Finding Decision Tree Splits in Streaming and Massively Parallel Models](https://arxiv.org/abs/2403.19867) | 提出了在数据流学习中计算决策树最佳分割点的算法，能够在流式计算和大规模并行模型中高效运行 |
| [^55] | [Is Synthetic Image Useful for Transfer Learning? An Investigation into Data Generation, Volume, and Utilization](https://arxiv.org/abs/2403.19866) | 研究探讨了从文本到图像生成模型中生成和利用合成图像在迁移学习中的作用，提出了桥接迁移的两阶段框架以解决合成图像与真实图像之间的分布差异。 |
| [^56] | [LLMSense: Harnessing LLMs for High-level Reasoning Over Spatiotemporal Sensor Traces](https://arxiv.org/abs/2403.19857) | 本研究探讨了如何利用大语言模型（LLMs）的推理能力和世界知识来识别长期时空传感器轨迹中的复杂事件。 |
| [^57] | [Towards a Brazilian History Knowledge Graph](https://arxiv.org/abs/2403.19856) | 构建基于巴西历史词典和维基数据的知识图谱，以丰富葡萄牙文本信息提取，填补巴西命名实体在维基数据中缺失的概念。 |
| [^58] | [The New Agronomists: Language Models are Experts in Crop Management](https://arxiv.org/abs/2403.19839) | 本文介绍了一个更先进的智能作物管理系统，利用深度强化学习和语言模型结合决策支持系统来优化作物管理实践。 |
| [^59] | [Multi-Frame, Lightweight & Efficient Vision-Language Models for Question Answering in Autonomous Driving](https://arxiv.org/abs/2403.19838) | 提出了一种高效、轻量级、多帧视觉语言模型 EM-VLM4AD，用于自动驾驶的视觉问答，相比现有方法，内存和浮点运算需求至少减少十倍，并且在BLEU-4、METEOR、CIDEr和ROGUE分数上均取得更高的表现。 |
| [^60] | [Concept-based Analysis of Neural Networks via Vision-Language Models](https://arxiv.org/abs/2403.19837) | 本文提出利用视觉语言模型作为透镜，通过其隐含的高层次概念来进行对视觉模型的分析。 |
| [^61] | [ChatTracer: Large Language Model Powered Real-time Bluetooth Device Tracking System](https://arxiv.org/abs/2403.19833) | ChatTracer是一个由LLM驱动的实时蓝牙设备追踪系统，其创新之处在于可靠高效的BLE数据包分组算法和结合了监督微调和强化学习微调策略的LLM微调策略。 |
| [^62] | [Segmentation Re-thinking Uncertainty Estimation Metrics for Semantic Segmentation](https://arxiv.org/abs/2403.19826) | 重新思考了语义分割中的不确定性估计度量，发现并改进了PAvPU框架中的核心缺陷。 |
| [^63] | [Multi-Stage Multi-Modal Pre-Training for Automatic Speech Recognition](https://arxiv.org/abs/2403.19822) | 提出了一种结合多模态和多任务无监督预训练以及基于翻译的监督中间训练方法的新方法，能够在Librispeech和SUPERB上相对提高高达38.45%的词错误率（WER）。 |
| [^64] | [Evaluating Explanatory Capabilities of Machine Learning Models in Medical Diagnostics: A Human-in-the-Loop Approach](https://arxiv.org/abs/2403.19820) | 通过人机协作方法，评估医疗诊断中机器学习模型的解释能力，提出了使用医学指南和特征重要性确定胰腺癌治疗关键特征的方法，同时探索了使用相似度衡量的解释结果的方法。 |
| [^65] | [Developing Healthcare Language Model Embedding Spaces](https://arxiv.org/abs/2403.19802) | 通过深度对比学习训练的模型在医疗保健文本分类任务中表现出色，有效利用有限标记数据，并减少了模型参数更新。 |
| [^66] | [Gegenbauer Graph Neural Networks for Time-varying Signal Reconstruction](https://arxiv.org/abs/2403.19800) | 提出了一种新颖的Gegenbauer-based graph convolutional (GegenConv)算子，用于提高时变信号重构的准确性 |
| [^67] | [MAPL: Model Agnostic Peer-to-peer Learning](https://arxiv.org/abs/2403.19792) | MAPL提出了一种新颖的方法，即Model Agnostic Peer-to-peer Learning，通过点对点通信在邻近客户端之间同时学习异质个性化模型和协作图，在去中心化环境中实现了有效的协作，并且实验证明了MAPL在性能上具有竞争力。 |
| [^68] | [Bespoke Large Language Models for Digital Triage Assistance in Mental Health Care](https://arxiv.org/abs/2403.19790) | 利用大型语言模型处理心理健康护理中的非结构化临床数据，帮助英国国家卫生服务体系(NHS)解决专科精神保健长等待名单的问题。 |
| [^69] | [Hierarchical Deep Learning for Intention Estimation of Teleoperation Manipulation in Assembly Tasks](https://arxiv.org/abs/2403.19770) | 该论文提出了一种分层深度学习框架，将多尺度层次信息整合到神经网络中，通过采用分层依赖损失来提高意图估计的准确性，在装配任务中实现了较优的意图识别和预测性能。 |
| [^70] | [Leveraging Counterfactual Paths for Contrastive Explanations of POMDP Policies](https://arxiv.org/abs/2403.19760) | 本研究利用用户提供的反事实路径来生成对照性解释POMDP策略，并通过分析Search and Rescue（SAR）环境中的案例研究来讨论与之相关的挑战。 |
| [^71] | [Natural Language, AI, and Quantum Computing in 2024: Research Ingredients and Directions in QNLP](https://arxiv.org/abs/2403.19758) | 该论文调查了2024年自然语言处理、人工智能发展中的量子计算应用，在量子自然语言处理中使用了诸如词嵌入、序列模型、注意力和语法分析等NLP技术，提出了一种新的量子设计来处理文本编码，并探讨了量子理论对“不确定性是什么？”和“智能是什么？”等核心问题的关键贡献。 |
| [^72] | [Physics-Informed Neural Networks for Satellite State Estimation](https://arxiv.org/abs/2403.19736) | 物理信息神经网络与深度神经网络相结合，为卫星中一些难以建模的异常加速度情况提供了强大的工具 |
| [^73] | [New Semantic Task for the French Spoken Language Understanding MEDIA Benchmark](https://arxiv.org/abs/2403.19727) | 提出了一个用于法语口语理解的新语义任务，通过在MEDIA基准测试数据集上标注意图来扩展其用途和使用情况。 |
| [^74] | [A Benchmark Evaluation of Clinical Named Entity Recognition in French](https://arxiv.org/abs/2403.19726) | 该论文评估了生物医学法语掩码语言模型在临床命名实体识别任务上的性能，对几种模型进行了比较。 |
| [^75] | [MUGC: Machine Generated versus User Generated Content Detection](https://arxiv.org/abs/2403.19725) | 本研究对八种传统机器学习算法在识别机器生成和人类生成数据方面进行了比较评估，发现这些方法在识别机器生成数据方面具有较高的准确性。另外，机器生成的文本往往更短、词汇变化更少，而人类生成内容则使用了一些特定领域相关关键词被当前的大型语言模型忽略了。 |
| [^76] | [HGT: Leveraging Heterogeneous Graph-enhanced Large Language Models for Few-shot Complex Table Understanding](https://arxiv.org/abs/2403.19723) | HGT框架结合了异质图增强的大型语言模型，通过软提示和多粒度自监督HG预训练目标，实现了少样本复杂表格理解任务的最新成果。 |
| [^77] | [Computationally and Memory-Efficient Robust Predictive Analytics Using Big Data](https://arxiv.org/abs/2403.19721) | 本研究通过利用稳健主成分分析(RPCA)进行噪声降低和异常值排除，以及优化传感器放置(OSP)进行有效数据压缩和存储，提出了一种同时优化计算和内存效率的大数据预测分析方法。 |
| [^78] | [Capability-aware Prompt Reformulation Learning for Text-to-Image Generation](https://arxiv.org/abs/2403.19716) | 通过利用来自交互日志的用户重组数据来开发自动提示重组模型，CAPR框架创新性地将用户能力整合到提示重组过程中。 |
| [^79] | [STRUM-LLM: Attributed and Structured Contrastive Summarization](https://arxiv.org/abs/2403.19710) | STRUM-LLM提出了一种生成属性化、结构化和有帮助的对比摘要的方法，识别并突出两个选项之间的关键差异，不需要人工标记的数据或固定属性列表，具有高吞吐量和小体积。 |
| [^80] | [Hierarchical Recurrent Adapters for Efficient Multi-Task Adaptation of Large Speech Models](https://arxiv.org/abs/2403.19709) | 提出了一种分层递归适配器模块，能够在大规模多任务适配场景下降低每个任务的参数开销，同时保持在下游任务中的性能表现，优于先前的适配器方法和完整模型微调基线 |
| [^81] | [Analyzing the Roles of Language and Vision in Learning from Limited Data](https://arxiv.org/abs/2403.19669) | 研究人工智能中的复杂视觉-语言模型，发现即使缺乏视觉输入，利用所有组件的语言模型能够恢复大部分VLM的性能，表明语言通过提供对先前知识和推理的访问来对学习新任务有贡献 |
| [^82] | [Uncovering Misattributed Suicide Causes through Annotation Inconsistency Detection in Death Investigation Notes](https://arxiv.org/abs/2403.19432) | 通过自然语言处理方法检测并纠正国家暴力死亡报告系统中的注释不一致性，提高了自杀危机分类器的性能。 |
| [^83] | [STaR-GATE: Teaching Language Models to Ask Clarifying Questions](https://arxiv.org/abs/2403.19154) | 通过奖励语言模型生成有用问题来自我改进的方法，提问者通过询问角色扮演者来引出偏好，从而迭代微调以增加任务高质量响应的概率。 |
| [^84] | [Towards Human-Centered Construction Robotics: An RL-Driven Companion Robot For Contextually Assisting Carpentry Workers](https://arxiv.org/abs/2403.19060) | 本文提出了一种人类中心的建筑机器人方法，通过强化学习驱动的助手机器人为木工劳动者提供环境上下文协助，推进了机器人在建筑中的应用。 |
| [^85] | [Gamba: Marry Gaussian Splatting with Mamba for single view 3D reconstruction](https://arxiv.org/abs/2403.18795) | 提出了Gamba，一种单视图3D重建模型，创新地结合了大量的3D高斯点进行高效重建，并引入了基于曼巴的顺序网络，促进依赖上下文的推理，实现了线性可扩展性。 |
| [^86] | [On permutation-invariant neural networks](https://arxiv.org/abs/2403.17410) | 神经网络如Deep Sets和Transformers的出现显著推动了基于集合的数据处理的进展 |
| [^87] | [DASA: Delay-Adaptive Multi-Agent Stochastic Approximation](https://arxiv.org/abs/2403.17247) | DASA算法是第一个收敛速度仅依赖于混合时间和平均延迟的算法，同时在马尔科夫采样下实现N倍的收敛加速。 |
| [^88] | [Learning To Guide Human Decision Makers With Vision-Language Models](https://arxiv.org/abs/2403.16501) | 提出了“学习指导”（LTG）框架，旨在解决专家可能过度依赖机器决策和面临无助于模型放弃的决策的问题。 |
| [^89] | [FedAC: A Adaptive Clustered Federated Learning Framework for Heterogeneous Data](https://arxiv.org/abs/2403.16460) | FedAC框架通过解耦神经网络，使用不同聚合方法为每个子模块提供全局知识，引入经济高效的在线模型相似度度量，及集群数量微调模块，显著提高了性能。 |
| [^90] | [MedPromptX: Grounded Multimodal Prompting for Chest X-ray Diagnosis](https://arxiv.org/abs/2403.15585) | MedPromptX是第一个将多模态大型语言模型、少样本提示和视觉基础相结合，用于胸部X线诊断的模型，通过补充缺失的EHR信息，有效解决了幻觉问题，但选择最佳少样本示例和高质量候选者仍有待解决。 |
| [^91] | [WoLF: Large Language Model Framework for CXR Understanding](https://arxiv.org/abs/2403.15456) | WoLF框架提出了对于CXR的全面理解的改进，包括使用额外的健康相关数据、重构报告以提供更有组织的信息、以及改进生成答案的细致评估。 |
| [^92] | [PET-SQL: A Prompt-enhanced Two-stage Text-to-SQL Framework with Cross-consistency](https://arxiv.org/abs/2403.09732) | 提出了一个两阶段框架，通过引入参考增强表示和少样本演示，解决了在处理冗长的数据库信息和复杂用户意图时的挑战。 |
| [^93] | [STREAM: Spatio-TempoRal Evaluation and Analysis Metric for Video Generative Models](https://arxiv.org/abs/2403.09669) | 提出了STREAM，一种新的视频评估度量方法，弥补了当前视频生成模型评估中对于时空特性的不足 |
| [^94] | [Rectifying Demonstration Shortcut in In-Context Learning](https://arxiv.org/abs/2403.09488) | 本研究旨在纠正大型语言模型在上下文学习中的演示快捷方式，并引入了一种新的明示意识校准方法。 |
| [^95] | [What Generative Artificial Intelligence Means for Terminological Definitions](https://arxiv.org/abs/2402.16139) | 生成人工智能工具如ChatGPT在提供定制化的语境特定含义方面表现出色，但在准确性方面存在挑战，可以辅助术语学家进行术语编纂，实现AI效率与人类专业知识的结合。 |
| [^96] | [Defending Against Weight-Poisoning Backdoor Attacks for Parameter-Efficient Fine-Tuning](https://arxiv.org/abs/2402.12168) | PEFT相对于全参数微调更容易受到权重投毒后门攻击的影响，提出了一个通过置信度识别受污染样本的毒化样本识别模块（PSIM），为权重投毒后门攻击提供稳健防御 |
| [^97] | [MultiCorrupt: A Multi-Modal Robustness Dataset and Benchmark of LiDAR-Camera Fusion for 3D Object Detection](https://arxiv.org/abs/2402.11677) | MultiCorrupt是用于评估多模态3D目标检测器在十种不同数据损坏类型下的鲁棒性的综合基准。 |
| [^98] | [A Multi-Aspect Framework for Counter Narrative Evaluation using Large Language Models](https://arxiv.org/abs/2402.11676) | 提出了一个多方面框架，使用大型语言模型评估反叙事，通过5个方面从专门 NGO 指南中提取定义的内容，以解决以往评估方法的局限性。 |
| [^99] | [Variational Flow Models: Flowing in Your Style](https://arxiv.org/abs/2402.02977) | 我们引入了一种变分流模型的方法，并提出了一种系统的无需训练的转换方法，使得快速采样成为可能，同时保持了采样的准确性和效率。 |
| [^100] | [Enhance Reasoning for Large Language Models in the Game Werewolf](https://arxiv.org/abs/2402.02330) | 本文提出了一个创新的框架，将大型语言模型（LLM）与外部思考模块相结合，以增强推理能力，通过引入通信协议和使用大量数据进行训练，展示了其在游戏推理、语音生成和在线评估方面的有效性。 |
| [^101] | [SERNet-Former: Semantic Segmentation by Efficient Residual Network with Attention-Boosting Gates and Attention-Fusion Networks](https://arxiv.org/abs/2401.15741) | 这篇论文提出了一种名为SERNet-Former的高效剩余网络语义分割方法。它通过引入注意力增强门和注意力融合网络来改善语义分割方法的效率，并解决了从全局和局部上融合语义信息的问题。实验结果表明，该方法在挑战性的数据集上取得了良好的性能。 |
| [^102] | [Conversational Question Answering with Reformulations over Knowledge Graph](https://arxiv.org/abs/2312.17269) | 提出了使用重述技术改进对话式问答性能的CornNet模型 |
| [^103] | [Visual Spatial Attention and Proprioceptive Data-Driven Reinforcement Learning for Robust Peg-in-Hole Task Under Variable Conditions](https://arxiv.org/abs/2312.16438) | 提出了一种视觉空间注意力和本体感知数据驱动的机器人控制模型，通过SAP和DRL策略进行端到端训练，鲁棒地解决具有挑战性的照明和孔面条件下的插销孔任务。 |
| [^104] | [GlitchBench: Can large multimodal models detect video game glitches?](https://arxiv.org/abs/2312.05291) | GlitchBench是一个基于视频游戏质量保证任务的新基准，旨在挑战LMMs在检测和解释异常事件方面的视觉和语言推理能力。 |
| [^105] | [Rapid Motor Adaptation for Robotic Manipulator Arms](https://arxiv.org/abs/2312.04670) | 快速电机适应性（RMA）为机器人操作技能的泛化提出了解决方案，利用深度感知开发了针对各种操纵任务的代理。 |
| [^106] | [Learning from One Continuous Video Stream](https://arxiv.org/abs/2312.00598) | 我们提出了一个在线学习框架，允许从单个连续视频流中学习，通过像素级建模实现预训练和单流评估之间的灵活切换，并获得了大量单流学习的收益。 |
| [^107] | [TransNeXt: Robust Foveal Visual Perception for Vision Transformers](https://arxiv.org/abs/2311.17132) | TransNeXt提出了Aggregated Attention，一种仿生设计的令牌混合器，通过模拟生物视觉和连续眼动，使得每个特征图上的令牌具有全局感知，且不依赖于叠加层进行信息交换，有效避免了深度退化，实现了自然的视知觉。 |
| [^108] | [Emergent Open-Vocabulary Semantic Segmentation from Off-the-shelf Vision-Language Models](https://arxiv.org/abs/2311.17095) | 提出了一种简单但高效的无需训练的技术，用于开放词汇语义分割，通过使用VLM和显著性丢弃来解决过度分割和欠分割的问题 |
| [^109] | [Compositional Chain-of-Thought Prompting for Large Multimodal Models](https://arxiv.org/abs/2311.17076) | 提出了一种新颖的零样式思维提示（CCoT），以克服大型多模态模型难以捕捉到组合视觉推理方面的细节的问题。 |
| [^110] | [Learning From Mistakes Makes LLM Better Reasoner](https://arxiv.org/abs/2310.20689) | 本研究探索了大型语言模型（LLMs）是否可以从错误中学习，类似于人类学习的过程，并通过引入错误纠正的数据对来改进LLMs的推理能力。实验结果表明，这种方法能够持续提升仅使用CoT进行微调后的性能。 |
| [^111] | [Harmonic Self-Conditioned Flow Matching for Multi-Ligand Docking and Binding Site Design](https://arxiv.org/abs/2310.05764) | 该研究开发了一种谐波自调流匹配方法，在多配体对接和结合位点设计中表现出比现有方法更好的生成过程和设计效果。 |
| [^112] | [Language Model Beats Diffusion -- Tokenizer is Key to Visual Generation](https://arxiv.org/abs/2310.05737) | 分词器是视觉生成的关键，新的视频分词器MAGVIT-v2使得大型语言模型LLMs在图像和视频生成任务上胜过扩散模型，并在视频压缩和有效表示学习方面表现优异。 |
| [^113] | [Distribution-Aware Continual Test-Time Adaptation for Semantic Segmentation](https://arxiv.org/abs/2309.13604) | 提出了一种分布感知调整（DAT）方法，以使得面向语义分割的连续测试时适应（CTTA）在实际应用中更加高效和实用。 |
| [^114] | [DFWLayer: Differentiable Frank-Wolfe Optimization Layer](https://arxiv.org/abs/2308.10806) | 本文提出了一种名为Differentiable Frank-Wolfe Layer（DFWLayer）的可微层，通过推出Frank-Wolfe方法，有效处理具有范数约束的大规模凸优化问题，并在解和梯度准确性方面表现竞争性。 |
| [^115] | [A Comparison of Speech Data Augmentation Methods Using S3PRL Toolkit](https://arxiv.org/abs/2303.00510) | 通过使用S3PRL工具包，研究了不同的数据增强策略，发现SpecAugment略微提高了HuBERT和wav2vec在原始数据集上的性能，而使用高斯噪声和速度扰动数据集训练的模型在经过增强的测试集上表现更为稳健。 |
| [^116] | [Attending to Graph Transformers](https://arxiv.org/abs/2302.04181) | 提出了一种图转换器架构的分类法，概述了其理论性质，调查了结构和位置编码，并探讨了对重要图类的扩展，如3D分子图。 |
| [^117] | [Restricting to the chip architecture maintains the quantum neural network accuracy](https://arxiv.org/abs/2212.14426) | 该研究旨在探讨量子神经网络在量子芯片架构上表现出的准确性，并发现成本函数往往会收敛到一个平均值。 |
| [^118] | [GOTCHA: Real-Time Video Deepfake Detection via Challenge-Response](https://arxiv.org/abs/2210.06186) | 通过挑战-响应方式，针对AI Real-Time Deepfakes的限制，提出实时视频深度伪造检测解决方案。 |
| [^119] | [Meta Reinforcement Learning with Finite Training Tasks -- a Density Estimation Approach](https://arxiv.org/abs/2206.10716) | 通过密度估计技术直接学习任务分布，从而对元强化学习中所需训练任务数提出了新的界限分析方法 |
| [^120] | [QAGCN: Answering Multi-Relation Questions via Single-Step Implicit Reasoning over Knowledge Graphs](https://arxiv.org/abs/2206.01818) | 本文提出了 QAGCN 方法，通过对问题进行感知来实现单步隐式推理，从而回答多关系问题，相比于显式多步推理方法，该方法更简单、高效且易于采用。 |
| [^121] | [Multi-Agent Diagnostics for Robustness via Illuminated Diversity.](http://arxiv.org/abs/2401.13460) | MADRID是一种新方法，通过生成多样化的对抗场景来揭示预训练多Agent策略的战略漏洞，并通过遗憾值衡量漏洞的程度。 |
| [^122] | [Data-Efficient Multimodal Fusion on a Single GPU.](http://arxiv.org/abs/2312.10144) | 本论文提出了一种在单一GPU上进行数据高效多模态融合的方法，通过使用预训练的单模态编码器的潜在空间，我们在多模态对齐中取得了有竞争力的性能，且计算和数据量减少了数个数量级。 |
| [^123] | [DialogBench: Evaluating LLMs as Human-like Dialogue Systems.](http://arxiv.org/abs/2311.01677) | 本文提出了DialogBench，一个对话评估基准，用于评估LLMs作为人类对话系统的能力。通过对28个LLMs的广泛测试，发现指导微调对提升性能效果显著。 |
| [^124] | [Conversational Financial Information Retrieval Model (ConFIRM).](http://arxiv.org/abs/2310.13001) | ConFIRM是一种会话式金融信息检索模型，通过合成金融领域特定问答对和评估参数微调方法，实现了超过90%的准确性，为金融对话系统提供了数据高效的解决方案。 |
| [^125] | [GTA: A Geometry-Aware Attention Mechanism for Multi-View Transformers.](http://arxiv.org/abs/2310.10375) | 提出了一种面向几何的注意力机制（GTA），用于将几何结构编码为相对变换，从而改进了多视图Transformer的学习效率和性能。 |
| [^126] | [Interpreting CLIP's Image Representation via Text-Based Decomposition.](http://arxiv.org/abs/2310.05916) | 本文通过解析CLIP图像编码器的组件，揭示了图像表示的构成方式，并利用文本表示解释了其各个部分的作用。通过理解注意力头和图像块，作者实现了对模型的修复和改进，包括消除误特征和构建零样本图像分割器等方面。 |
| [^127] | [Exploring Naming Conventions (and Defects) of Pre-trained Deep Learning Models in Hugging Face and Other Model Hubs.](http://arxiv.org/abs/2310.01642) | 本研究首次系统研究了预训练深度学习模型的命名惯例和相关缺陷，为我们了解研究到实践过程提供了知识和认识。 |
| [^128] | [Advances in Kidney Biopsy Structural Assessment through Dense Instance Segmentation.](http://arxiv.org/abs/2309.17166) | 这项研究提出了一种基于密集实例分割的肾脏活检结构评估的方法，能够自动统计解剖结构上的统计数据，从而减少工作量和观察者间变异性。 |
| [^129] | [The Relational Bottleneck as an Inductive Bias for Efficient Abstraction.](http://arxiv.org/abs/2309.06629) | 本文介绍了一种新的归纳偏好方法——关系瓶颈，用于有效地诱导抽象概念的模型，强调了其在人类思维和大脑中抽象概念习得中的潜力。 |
| [^130] | [RLSynC: Offline-Online Reinforcement Learning for Synthon Completion.](http://arxiv.org/abs/2309.02671) | RLSynC是一种离线-在线强化学习方法，用于半模板化逆向合成中的合成物补全。它使用多个代理同时完成合成物的补全，并通过正向合成模型评估反应物的合成能力来指导行动搜索。 |
| [^131] | [A multiobjective continuation method to compute the regularization path of deep neural networks.](http://arxiv.org/abs/2308.12044) | 本文提出了一种多目标延续方法，用于计算深度神经网络的正则化路径，以解决DNNs中稀疏性和数值效率之间的冲突。 |
| [^132] | [Gradient strikes back: How filtering out high frequencies improves explanations.](http://arxiv.org/abs/2307.09591) | 本研究发现，基于预测的属性方法与基于梯度的方法产生的属性图具有不同的高频内容，滤除高频率可以提高解释性。 |
| [^133] | [Towards Sustainable Deep Learning for Multi-Label Classification on NILM.](http://arxiv.org/abs/2307.09244) | 本研究提出了一种面向NILM的新型深度学习模型，通过改进计算和能源效率，实现了对NILM的多标签分类的增强。同时，还提出了一种测试方法，可以比较不同模型在虚拟数据集上的性能。 |
| [^134] | [Reasoning or Reciting? Exploring the Capabilities and Limitations of Language Models Through Counterfactual Tasks.](http://arxiv.org/abs/2307.02477) | 通过反事实任务的研究，我们发现当前的语言模型具备一定的抽象推理能力，但它们在任务求解过程中往往也依赖于狭窄、难以转移的过程，这对语言模型的性能解释和理解有着重要的启示。 |
| [^135] | [Sample-Efficient and Surrogate-Based Design Optimization of Underwater Vehicle Hulls.](http://arxiv.org/abs/2304.12420) | 该论文使用了高效的样本集优化和基于代理的方法来设计水下航行器船体，其中代理模型显著提高了计算效率，使优化更加快速准确。 |
| [^136] | [Safe Explicable Robot Planning.](http://arxiv.org/abs/2304.03773) | 安全可解释机器人规划方法（SEP）扩展了可解释规划，支持安全界限的规定，以实现安全和可解释之间的权衡。 |
| [^137] | [OTS: A One-shot Learning Approach for Text Spotting in Historical Manuscripts.](http://arxiv.org/abs/2304.00746) | 提出了一种基于单次学习的历史手稿文本检测方法 OTS， 尤其对于低资源检测任务，使用新型的“环形损失”损失函数提高了检测能力，同时创建了包含古代东巴象形文字的手稿数据集。 |
| [^138] | [Making Batch Normalization Great in Federated Deep Learning.](http://arxiv.org/abs/2303.06530) | 本文研究了在联邦学习中使用批标准化和群组归一化的效果，发现在适当的处理下，批标准化可以在广泛的联邦学习设置中具有很高的竞争力，而且这不需要额外的训练或通信成本。 |
| [^139] | [Positive Unlabeled Contrastive Learning.](http://arxiv.org/abs/2206.01206) | 我们提出了一种正样本未标记对比学习的新方法，通过扩展对比损失和使用PU特定聚类方案，该方法在PU任务中学习到了优秀的表示，并在多个标准数据集上明显优于现有方法。 |

# 详细

[^1]: 不可解问题检测：评估视觉语言模型的可信度

    Unsolvable Problem Detection: Evaluating Trustworthiness of Vision Language Models

    [https://arxiv.org/abs/2403.20331](https://arxiv.org/abs/2403.20331)

    本文提出了一个新颖且重要的挑战，即Unsolvable Problem Detection（UPD），用于评估视觉语言模型在视觉问答任务中能否在面对不可解问题时保持答案的能力，并通过广泛实验发现大多数模型存在改进的空间。

    

    本文介绍了一个新颖而重要的挑战，即Unsolvable Problem Detection（UPD），用于评估视觉语言模型（VLMs）在视觉问答（VQA）任务中面对不可解问题时保持答案的能力。UPD包括三个不同的设置：缺失答案检测（AAD）、不兼容答案集检测（IASD）和不兼容视觉问题检测（IVQD）。通过广泛的实验深入研究UPD问题表明，大多数VLMs，包括GPT-4V和LLaVA-Next-34B，在各种程度上都很难应对我们的基准测试，突显了改进的重要空间。为了解决UPD，我们探索了无需训练和基于训练的解决方案，提供了对其有效性和局限性的新见解。我们希望我们的见解，以及在提议的UPD设置内的未来努力，将增强对VLMs的更广泛理解和发展。

    arXiv:2403.20331v1 Announce Type: cross  Abstract: This paper introduces a novel and significant challenge for Vision Language Models (VLMs), termed Unsolvable Problem Detection (UPD). UPD examines the VLM's ability to withhold answers when faced with unsolvable problems in the context of Visual Question Answering (VQA) tasks. UPD encompasses three distinct settings: Absent Answer Detection (AAD), Incompatible Answer Set Detection (IASD), and Incompatible Visual Question Detection (IVQD). To deeply investigate the UPD problem, extensive experiments indicate that most VLMs, including GPT-4V and LLaVA-Next-34B, struggle with our benchmarks to varying extents, highlighting significant room for the improvements. To address UPD, we explore both training-free and training-based solutions, offering new insights into their effectiveness and limitations. We hope our insights, together with future efforts within the proposed UPD settings, will enhance the broader understanding and development of
    
[^2]: ReALM: 参考解析作为语言建模

    ReALM: Reference Resolution As Language Modeling

    [https://arxiv.org/abs/2403.20329](https://arxiv.org/abs/2403.20329)

    本论文展示了如何利用LLMs创建一个极其有效的系统来解决各种类型的引用问题，通过将参考解析转化为语言建模问题，尽管涉及到屏幕上的实体等不易约简为纯文本形式的实体。

    

    参考解析是一个重要的问题，对于理解和成功处理各种上下文至关重要。 这种上下文既包括先前的对话，也包括与非对话实体相关的上下文，例如用户屏幕上的实体或后台运行的实体。 尽管已经证明了LLMs在各种任务中非常强大，但它们在参考解析中的运用，特别是对于非对话实体，仍未充分利用。 本文展示了LLMs如何被用来创建一个极其有效的系统来解决各种类型的引用问题，通过展示如何将参考解析转化为语言建模问题，尽管其中涉及屏幕上的这种实体等传统上不易约简为纯文本形式的实体。 我们展示了在不同类型的参考解析中相对于已有类似功能的系统的显着改进。

    arXiv:2403.20329v1 Announce Type: cross  Abstract: Reference resolution is an important problem, one that is essential to understand and successfully handle context of different kinds. This context includes both previous turns and context that pertains to non-conversational entities, such as entities on the user's screen or those running in the background. While LLMs have been shown to be extremely powerful for a variety of tasks, their use in reference resolution, particularly for non-conversational entities, remains underutilized. This paper demonstrates how LLMs can be used to create an extremely effective system to resolve references of various types, by showing how reference resolution can be converted into a language modeling problem, despite involving forms of entities like those on screen that are not traditionally conducive to being reduced to a text-only modality. We demonstrate large improvements over an existing system with similar functionality across different types of re
    
[^3]: MTLoRA: 一种用于高效多任务学习的低秩适应方法

    MTLoRA: A Low-Rank Adaptation Approach for Efficient Multi-Task Learning

    [https://arxiv.org/abs/2403.20320](https://arxiv.org/abs/2403.20320)

    MTLoRA提出了一种新颖的多任务学习模型参数高效训练框架，通过任务不可知和任务特定的低秩适应模块有效地实现了参数空间的分离，使得模型能够灵活处理任务专业化和在多任务学习环境中的相互作用

    

    适应在大规模数据集上预训练的模型到各种下游任务是深度学习中常见的策略。因此，参数高效的微调方法已经成为将预训练模型适应到不同任务的一种有前景的方式，同时仅训练少量参数。虽然大多数这些方法是为单任务适应而设计的，但在多任务学习（MTL）架构中进行参数高效训练仍未被探索。在本文中，我们介绍了MTLoRA，一种用于多任务学习模型参数高效训练的新框架。MTLoRA采用任务不可知和任务特定的低秩适应模块，有效地分开了MTL微调中的参数空间，从而使模型能够熟练处理MTL上下文中的任务专门化和交互。我们将MTLoRA应用于基于分层变压器的MTL架构，将它们调整到多个下游密集预测

    arXiv:2403.20320v1 Announce Type: cross  Abstract: Adapting models pre-trained on large-scale datasets to a variety of downstream tasks is a common strategy in deep learning. Consequently, parameter-efficient fine-tuning methods have emerged as a promising way to adapt pre-trained models to different tasks while training only a minimal number of parameters. While most of these methods are designed for single-task adaptation, parameter-efficient training in Multi-Task Learning (MTL) architectures is still unexplored. In this paper, we introduce MTLoRA, a novel framework for parameter-efficient training of MTL models. MTLoRA employs Task-Agnostic and Task-Specific Low-Rank Adaptation modules, which effectively disentangle the parameter space in MTL fine-tuning, thereby enabling the model to adeptly handle both task specialization and interaction within MTL contexts. We applied MTLoRA to hierarchical-transformer-based MTL architectures, adapting them to multiple downstream dense predictio
    
[^4]: SeaBird: 使用Dice损失进行鸟瞰图分割改进了单目大物体的3D检测

    SeaBird: Segmentation in Bird's View with Dice Loss Improves Monocular 3D Detection of Large Objects

    [https://arxiv.org/abs/2403.20318](https://arxiv.org/abs/2403.20318)

    通过研究回归和Dice损失在大物体上的表现，我们发现Dice损失相对于回归损失在大物体上具有更好的噪声鲁棒性和模型收敛性。

    

    单目3D检测器在汽车和较小物体上取得了显着的性能，但在较大物体上性能下降，导致致命事故。一些人认为失败的原因是训练数据稀缺或者大物体的感受野要求。在这篇文章中，我们突出了这个研究不足的问题，即对大物体的泛化。我们发现现代前置检测器甚至在几乎平衡的数据集上难以泛化到大物体。我们认为失败的原因是深度回归损失对大物体的噪声敏感性。为了弥合这一差距，我们全面研究了回归和dice损失，考察它们在不同误差水平和物体尺寸下的稳健性。我们数学上证明了与回归损失相比，在简化的情况下，dice损失对于大物体的噪声鲁棒性和模型收敛性更佳。利用我们的理论见解，我们...

    arXiv:2403.20318v1 Announce Type: cross  Abstract: Monocular 3D detectors achieve remarkable performance on cars and smaller objects. However, their performance drops on larger objects, leading to fatal accidents. Some attribute the failures to training data scarcity or their receptive field requirements of large objects. In this paper, we highlight this understudied problem of generalization to large objects. We find that modern frontal detectors struggle to generalize to large objects even on nearly balanced datasets. We argue that the cause of failure is the sensitivity of depth regression losses to noise of larger objects. To bridge this gap, we comprehensively investigate regression and dice losses, examining their robustness under varying error levels and object sizes. We mathematically prove that the dice loss leads to superior noise-robustness and model convergence for large objects compared to regression losses for a simplified case. Leveraging our theoretical insights, we pro
    
[^5]: ChainNet: 在WordNet中的结构化隐喻和转喻

    ChainNet: Structured Metaphor and Metonymy in WordNet

    [https://arxiv.org/abs/2403.20308](https://arxiv.org/abs/2403.20308)

    ChainNet是一个词典资源，首次明确地识别了WordNet中词义的结构化隐喻和转喻关系，成为第一个具有基础隐喻和转喻数据集的资源。

    

    一个词的意义展现出丰富的内部结构。在典型的词典中，这种结构往往被忽视：一个词的意义被编码为一个没有意义间关系的列表。我们介绍了ChainNet，这是一个词典资源，首次明确地识别了这些结构。ChainNet表达了在Open English Wordnet中词义如何从彼此衍生出来：一个词的每个名词意义要么通过隐喻或转喻与另一个意义相连，要么在同义词的情况下是断开的。由于WordNet的含义与捕捉其含义信息的资源相连，ChainNet代表了第一个具有基础隐喻和转喻的数据集。

    arXiv:2403.20308v1 Announce Type: cross  Abstract: The senses of a word exhibit rich internal structure. In a typical lexicon, this structure is overlooked: a word's senses are encoded as a list without inter-sense relations. We present ChainNet, a lexical resource which for the first time explicitly identifies these structures. ChainNet expresses how senses in the Open English Wordnet are derived from one another: every nominal sense of a word is either connected to another sense by metaphor or metonymy, or is disconnected in the case of homonymy. Because WordNet senses are linked to resources which capture information about their meaning, ChainNet represents the first dataset of grounded metaphor and metonymy.
    
[^6]: 朝着更绿色的LLMs：将能效引入LLM推理的前沿

    Towards Greener LLMs: Bringing Energy-Efficiency to the Forefront of LLM Inference

    [https://arxiv.org/abs/2403.20306](https://arxiv.org/abs/2403.20306)

    本文旨在将能效作为LLM推理的主要目标，并探讨在满足性能目标的前提下如何最大程度地提高能源利用效率。

    

    随着现代大型语言模型（LLMs）在各行业中的普遍使用，用于这些模型的推理服务正在不断扩展。鉴于现代LLMs的高计算和内存要求，越来越多顶尖的GPU被部署来提供这些模型的服务。能源供应已成为数据中心扩展以提供这些模型服务的最大挑战。本文提出了以能效为LLM服务的首要目标所带来的折衷方案，同时满足性能SLOs。我们表明，根据输入、模型和服务水平协议，LLM推理提供者有几个旋钮可用于实现能效。我们对这些旋钮对延迟、吞吐量以及能源的影响进行了表征。通过探索这些折衷方案，我们提供了优化能源使用而不牺牲性能的宝贵见解，从而铺平了道路。

    arXiv:2403.20306v1 Announce Type: new  Abstract: With the ubiquitous use of modern large language models (LLMs) across industries, the inference serving for these models is ever expanding. Given the high compute and memory requirements of modern LLMs, more and more top-of-the-line GPUs are being deployed to serve these models. Energy availability has come to the forefront as the biggest challenge for data center expansion to serve these models. In this paper, we present the trade-offs brought up by making energy efficiency the primary goal of LLM serving under performance SLOs. We show that depending on the inputs, the model, and the service-level agreements, there are several knobs available to the LLM inference provider to use for being energy efficient. We characterize the impact of these knobs on the latency, throughput, as well as the energy. By exploring these trade-offs, we offer valuable insights into optimizing energy usage without compromising on performance, thereby paving t
    
[^7]: 用启发式搜索改进学到的局部MAPF策略

    Improving Learnt Local MAPF Policies with Heuristic Search

    [https://arxiv.org/abs/2403.20300](https://arxiv.org/abs/2403.20300)

    我们提出了通过在输出概率分布上使用启发式搜索方法来改进ML局部策略，以解决死锁并启用完整时间跨度规划的主要想法

    

    多智能体路径规划（MAPF）是在团队智能体到达目标位置时找到无碰撞路径的问题。目前最先进的经典MAPF求解器通常采用启发式搜索来找到数百个智能体的解决方案，但通常是集中式的，并且在短时间内运行时很难扩展。学习每个智能体策略的机器学习（ML）方法很有吸引力，因为这些方法可以实现去中心化系统并且在保持良好解决方案质量的同时可以很好地扩展。当前关于MAPF的ML方法提出了一些方法，已经开始探讨这一潜力。然而，最先进的ML方法生成“局部”策略，仅计划单个时间步，并且成功率和可扩展性较差。我们的主要想法是，通过使用启发式搜索方法处理输出概率分布，我们可以改进ML局部策略以解决死锁并启用完整时间跨度的规划。

    arXiv:2403.20300v1 Announce Type: cross  Abstract: Multi-agent path finding (MAPF) is the problem of finding collision-free paths for a team of agents to reach their goal locations. State-of-the-art classical MAPF solvers typically employ heuristic search to find solutions for hundreds of agents but are typically centralized and can struggle to scale when run with short timeouts. Machine learning (ML) approaches that learn policies for each agent are appealing as these could enable decentralized systems and scale well while maintaining good solution quality. Current ML approaches to MAPF have proposed methods that have started to scratch the surface of this potential. However, state-of-the-art ML approaches produce "local" policies that only plan for a single timestep and have poor success rates and scalability. Our main idea is that we can improve a ML local policy by using heuristic search methods on the output probability distribution to resolve deadlocks and enable full horizon pla
    
[^8]: LLM能够在医学领域中纠正医生吗？研究有效的交互方法

    Can LLMs Correct Physicians, Yet? Investigating Effective Interaction Methods in the Medical Domain

    [https://arxiv.org/abs/2403.20288](https://arxiv.org/abs/2403.20288)

    LLMs在医学决策中提供重要反馈，可以挑战不正确的诊断，促进更准确的决策。

    

    我们探讨了大型语言模型（LLMs）在协助并可能纠正医生进行医疗决策任务方面的潜力。我们评估了几种LLMs，包括Meditron、Llama2和Mistral，分析这些模型在不同情景下与医生有效交互的能力。我们考虑了来自PubMedQA的问题和几项任务，从二元（是/否）回答到长答案生成，其中模型的答案是在与医生交互后产生的。我们的研究结果表明，提示设计显著影响了LLMs的下游准确性，并且LLMs可以为医生提供有价值的反馈，挑战不正确的诊断，促进更准确的决策。例如，当医生准确率为38%时，Mistral可以给出正确答案，根据所使用的提示，将准确性提高到74%，而Llama2和Meditron模型也能提供类似的改进。

    arXiv:2403.20288v1 Announce Type: cross  Abstract: We explore the potential of Large Language Models (LLMs) to assist and potentially correct physicians in medical decision-making tasks. We evaluate several LLMs, including Meditron, Llama2, and Mistral, to analyze the ability of these models to interact effectively with physicians across different scenarios. We consider questions from PubMedQA and several tasks, ranging from binary (yes/no) responses to long answer generation, where the answer of the model is produced after an interaction with a physician. Our findings suggest that prompt design significantly influences the downstream accuracy of LLMs and that LLMs can provide valuable feedback to physicians, challenging incorrect diagnoses and contributing to more accurate decision-making. For example, when the physician is accurate 38% of the time, Mistral can produce the correct answer, improving accuracy up to 74% depending on the prompt being used, while Llama2 and Meditron models
    
[^9]: 带有模态通道注意力的稀疏多模态融合

    Sparse multimodal fusion with modal channel attention

    [https://arxiv.org/abs/2403.20280](https://arxiv.org/abs/2403.20280)

    研究了蒙特卡罗多模态变换器架构在模态样本稀疏对齐时学习稳健嵌入空间的能力，并提出了模态通道注意力（MCA）机制，可以改善生成的嵌入空间质量和下游任务性能。

    

    通过测量生成的嵌入空间质量作为模态稀疏度函数的能力，研究了蒙特卡罗多模态变换器架构在模态样本稀疏对齐时学习稳健嵌入空间的能力。提出了一种扩展的蒙特卡罗多模态变压器模型，该模型在多头注意机制中引入了模态不完全通道，称为模态通道注意力（MCA）。使用了包含4种模态的两个数据集，CMU-MOSEI用于多模态情感识别，TCGA用于多组学。模型显示在大多数样本中只用了四种模态中的两种就学习出统一且对齐的嵌入空间。发现，即使没有模态稀疏，所提出的MCA机制也能提高生成的嵌入空间质量，召回指标，并提高下游任务的性能。

    arXiv:2403.20280v1 Announce Type: cross  Abstract: The ability of masked multimodal transformer architectures to learn a robust embedding space when modality samples are sparsely aligned is studied by measuring the quality of generated embedding spaces as a function of modal sparsity. An extension to the masked multimodal transformer model is proposed which incorporates modal-incomplete channels in the multihead attention mechanism called modal channel attention (MCA). Two datasets with 4 modalities are used, CMU-MOSEI for multimodal sentiment recognition and TCGA for multiomics. Models are shown to learn uniform and aligned embedding spaces with only two out of four modalities in most samples. It was found that, even with no modal sparsity, the proposed MCA mechanism improves the quality of generated embedding spaces, recall metrics, and subsequent performance on downstream tasks.
    
[^10]: Latxa: 一种用于巴斯克语的开放语言模型和评估套件

    Latxa: An Open Language Model and Evaluation Suite for Basque

    [https://arxiv.org/abs/2403.20266](https://arxiv.org/abs/2403.20266)

    Latxa是一种用于巴斯克语的大型语言模型系列，在语言熟练度和理解能力方面表现出色，优于所有以前的开放模型，并具有多个评估数据集，填补了巴斯克语高质量基准的不足。

    

    我们介绍了Latxa，这是一个基于Llama 2的大型巴斯克语言模型系列，参数范围从7到700亿。Latxa基于新的巴斯克语语料库预训练，包括430万个文档和42亿个标记。针对巴斯克语高质量基准的稀缺性，我们进一步提出了4个多项选择评估数据集：EusProficiency，包括来自官方语言能力考试的5169个问题；EusReading，包括352个阅读理解问题；EusTrivia，包括来自5个知识领域的1715个琐事问题；以及EusExams，包括来自公共考试的16774个问题。在我们的广泛评估中，Latxa在与我们比较的所有先前开放模型中表现出色。此外，尽管在阅读理解和知识密集型任务方面落后，但在语言熟练度和理解能力方面，它与GPT-4 Turbo具有竞争力。Latxa模型系列，以及

    arXiv:2403.20266v1 Announce Type: cross  Abstract: We introduce Latxa, a family of large language models for Basque ranging from 7 to 70 billion parameters. Latxa is based on Llama 2, which we continue pretraining on a new Basque corpus comprising 4.3M documents and 4.2B tokens. Addressing the scarcity of high-quality benchmarks for Basque, we further introduce 4 multiple choice evaluation datasets: EusProficiency, comprising 5,169 questions from official language proficiency exams; EusReading, comprising 352 reading comprehension questions; EusTrivia, comprising 1,715 trivia questions from 5 knowledge areas; and EusExams, comprising 16,774 questions from public examinations. In our extensive evaluation, Latxa outperforms all previous open models we compare to by a large margin. In addition, it is competitive with GPT-4 Turbo in language proficiency and understanding, despite lagging behind in reading comprehension and knowledge-intensive tasks. Both the Latxa family of models, as well
    
[^11]: ELITR-Bench: 面向长上下文语言模型的会议助理基准

    ELITR-Bench: A Meeting Assistant Benchmark for Long-Context Language Models

    [https://arxiv.org/abs/2403.20262](https://arxiv.org/abs/2403.20262)

    该论文提出了一个新的基准 ELITR-Bench，专注于长上下文语言模型的实际会议助理场景，通过在现有 ELITR 语料库的转录中添加手工制作的问题和真实答案，揭示了开源模型和专有模型之间的差距。

    

    最近，对大型语言模型（LLMs）的研究越来越受到关注，主要致力于扩展模型的上下文大小，以更好地捕捉长文档内部的依赖关系。尽管已经提出了用于评估长距离能力的基准，但现有的努力主要考虑的是不一定与现实应用相关的通用任务。相反，我们的工作提出了一个针对实际会议助理场景的长上下文LLMs的新基准。在这种情景下，长上下文由自动语音识别获得的转录组成，由于这些数据的固有嘈杂性和口语特性，这为LLMs提出了独特的挑战。我们的基准，名为ELITR-Bench，通过271个手工制作的问题及其真实答案来增强现有的ELITR语料库的转录。我们在ELITR-Bench上对最新的长上下文LLMs进行的实验凸显了开源模型和专有模型之间的差距。

    arXiv:2403.20262v1 Announce Type: cross  Abstract: Research on Large Language Models (LLMs) has recently witnessed an increasing interest in extending models' context size to better capture dependencies within long documents. While benchmarks have been proposed to assess long-range abilities, existing efforts primarily considered generic tasks that are not necessarily aligned with real-world applications. In contrast, our work proposes a new benchmark for long-context LLMs focused on a practical meeting assistant scenario. In this scenario, the long contexts consist of transcripts obtained by automatic speech recognition, presenting unique challenges for LLMs due to the inherent noisiness and oral nature of such data. Our benchmark, named ELITR-Bench, augments the existing ELITR corpus' transcripts with 271 manually crafted questions and their ground-truth answers. Our experiments with recent long-context LLMs on ELITR-Bench highlight a gap between open-source and proprietary models, e
    
[^12]: FABind+: 通过改进口袋预测和姿态生成增强分子对接

    FABind+: Enhancing Molecular Docking through Improved Pocket Prediction and Pose Generation

    [https://arxiv.org/abs/2403.20261](https://arxiv.org/abs/2403.20261)

    FABind+通过改进口袋预测和姿态生成，提升分子对接表现

    

    分子对接是药物发现中至关重要的过程。传统技术依赖于受物理原理支配的广泛采样和模拟，但这些方法往往速度慢且昂贵。基于深度学习的方法的出现显示出显著的前景，提供了精确性和效率的增长。建立在FABind的基础工作之上，这是一个专注于速度和准确性的模型，我们提出了FABind+，这是一个大大提升其前身性能的增强版。我们确定口袋预测是分子对接中的一个关键瓶颈，并提出了一种显著改进口袋预测的新方法，从而简化了对接过程。此外，我们对对接模块进行了修改，以增强其姿态生成能力。为了缩小与传统采样/生成方法之间的差距，我们结合了一个简单而有效的s

    arXiv:2403.20261v1 Announce Type: cross  Abstract: Molecular docking is a pivotal process in drug discovery. While traditional techniques rely on extensive sampling and simulation governed by physical principles, these methods are often slow and costly. The advent of deep learning-based approaches has shown significant promise, offering increases in both accuracy and efficiency. Building upon the foundational work of FABind, a model designed with a focus on speed and accuracy, we present FABind+, an enhanced iteration that largely boosts the performance of its predecessor. We identify pocket prediction as a critical bottleneck in molecular docking and propose a novel methodology that significantly refines pocket prediction, thereby streamlining the docking process. Furthermore, we introduce modifications to the docking module to enhance its pose generation capabilities. In an effort to bridge the gap with conventional sampling/generative methods, we incorporate a simple yet effective s
    
[^13]: 使用LLMs建模目标人群的信念和偏好

    Using LLMs to Model the Beliefs and Preferences of Targeted Populations

    [https://arxiv.org/abs/2403.20252](https://arxiv.org/abs/2403.20252)

    使用LLMs建模目标人群的信念和偏好，旨在实现各种应用，评估不同微调方法的效果，并检验其在匹配真实人类受访者偏好方面的能力。

    

    我们考虑了将大型语言模型(LLM)与人群的偏好进行对齐的问题。建模特定人群的信念、偏好和行为对于各种不同应用可能很有用，比如为新产品开展模拟焦点小组、进行虚拟调查以及测试行为干预，特别是对于昂贵、不切实际或不道德的干预。现有研究在不同情境下使用LLMs准确建模人类行为方面取得了不同程度的成功。我们对两种众所周知的微调方法进行基准测试和评估，评估得到的人群在匹配对电池电动汽车(BEVs)偏好调查中真实人类受访者偏好方面的能力。我们评估我们的模型是否能与整体人口统计数据以及个体回应相匹配，并研究LLMs在建模人群信念和偏好方面的作用。

    arXiv:2403.20252v1 Announce Type: cross  Abstract: We consider the problem of aligning a large language model (LLM) to model the preferences of a human population. Modeling the beliefs, preferences, and behaviors of a specific population can be useful for a variety of different applications, such as conducting simulated focus groups for new products, conducting virtual surveys, and testing behavioral interventions, especially for interventions that are expensive, impractical, or unethical. Existing work has had mixed success using LLMs to accurately model human behavior in different contexts. We benchmark and evaluate two well-known fine-tuning approaches and evaluate the resulting populations on their ability to match the preferences of real human respondents on a survey of preferences for battery electric vehicles (BEVs). We evaluate our models against their ability to match population-wide statistics as well as their ability to match individual responses, and we investigate the role
    
[^14]: 多动作场景中利用观测数据进行最优策略学习：估计、风险偏好和潜在故障

    Optimal Policy Learning with Observational Data in Multi-Action Scenarios: Estimation, Risk Preference, and Potential Failures

    [https://arxiv.org/abs/2403.20250](https://arxiv.org/abs/2403.20250)

    本文讨论了多动作场景中利用观测数据进行最优策略学习的方法，着重探讨了估计、风险偏好和潜在故障三个方面。

    

    本文讨论了利用观测数据进行最优策略学习（OPL），即数据驱动的最优决策，在多动作（或多臂）设置中，有限的决策选项可供选择。文章分为三个部分，分别讨论：估计、风险偏好和潜在故障。第一部分简要回顾了在这种分析背景下估计奖励（或值）函数和最优策略的关键方法。第二部分深入分析了决策风险。分析表明，决策者对风险的态度可以影响最优选择，具体体现在奖励条件均值与条件方差之间的权衡。在这里，作者将所提出的模型应用于...

    arXiv:2403.20250v1 Announce Type: cross  Abstract: This paper deals with optimal policy learning (OPL) with observational data, i.e. data-driven optimal decision-making, in multi-action (or multi-arm) settings, where a finite set of decision options is available. It is organized in three parts, where I discuss respectively: estimation, risk preference, and potential failures. The first part provides a brief review of the key approaches to estimating the reward (or value) function and optimal policy within this context of analysis. Here, I delineate the identification assumptions and statistical properties related to offline optimal policy learning estimators. In the second part, I delve into the analysis of decision risk. This analysis reveals that the optimal choice can be influenced by the decision maker's attitude towards risks, specifically in terms of the trade-off between reward conditional mean and conditional variance. Here, I present an application of the proposed model to rea
    
[^15]: 基于人工神经网络的植入神经接口实时分类ENG信号

    Artificial Neural Networks-based Real-time Classification of ENG Signals for Implanted Nerve Interfaces

    [https://arxiv.org/abs/2403.20234](https://arxiv.org/abs/2403.20234)

    本文探讨了基于人工神经网络的实时分类ENG信号的方法，通过比较ANNs在不同大小数据集上的表现来分析其在处理运动/感觉刺激分类任务中的可行性。

    

    神经病在临床环境中变得更加重要，因为它们有可能永久危及一个人的生命。为了支持患者的康复，使用完全植入式设备正成为最有前途的解决方案之一。然而，即使成为完全复杂神经纳米网络系统的一个组成部分，这些设备仍面临着诸多挑战。在本文中，我们解决其中之一，即运动/感觉刺激的分类问题。通过探索四种不同类型的人工神经网络（ANNs），从大鼠坐骨神经测量的电神经图（ENG）信号中提取各种感觉刺激来执行该任务。考虑不同大小的数据集以分析被调查的ANNs在实时分类中的可行性，通过比较它们在准确性、F1分数和预测时间方面的性能。

    arXiv:2403.20234v1 Announce Type: new  Abstract: Neuropathies are gaining higher relevance in clinical settings, as they risk permanently jeopardizing a person's life. To support the recovery of patients, the use of fully implanted devices is emerging as one of the most promising solutions. However, these devices, even if becoming an integral part of a fully complex neural nanonetwork system, pose numerous challenges. In this article, we address one of them, which consists of the classification of motor/sensory stimuli. The task is performed by exploring four different types of artificial neural networks (ANNs) to extract various sensory stimuli from the electroneurographic (ENG) signal measured in the sciatic nerve of rats. Different sizes of the data sets are considered to analyze the feasibility of the investigated ANNs for real-time classification through a comparison of their performance in terms of accuracy, F1-score, and prediction time. The design of the ANNs takes advantage of
    
[^16]: 带隐蔽状态的图神经聚合-扩散

    Graph Neural Aggregation-diffusion with Metastability

    [https://arxiv.org/abs/2403.20221](https://arxiv.org/abs/2403.20221)

    提出了GRADE模型，通过图聚合-扩散方程实现了节点表示的亚稳定性，能够缓解图神经网络中过度平滑的问题。

    

    基于微分方程的连续图神经模型扩展了图神经网络（GNN）的架构。由于图扩散与信息传递之间的联系，基于扩散的模型得到了广泛研究。然而，扩散自然地将系统推向平衡状态，导致问题，如过度平滑。为此，我们提出了受图聚合-扩散方程启发的GRADE，其中包括非线性扩散和相互作用势引起的聚合之间的微妙平衡。通过聚合-扩散方程获得的节点表示表现出亚稳态，表明特征可以聚合成多个簇。此外，这些簇内的动态可以持续很长时间，有望缓解过度平滑的影响。我们模型中的非线性扩散推广了现有基于扩散的模型并确立了

    arXiv:2403.20221v1 Announce Type: cross  Abstract: Continuous graph neural models based on differential equations have expanded the architecture of graph neural networks (GNNs). Due to the connection between graph diffusion and message passing, diffusion-based models have been widely studied. However, diffusion naturally drives the system towards an equilibrium state, leading to issues like over-smoothing. To this end, we propose GRADE inspired by graph aggregation-diffusion equations, which includes the delicate balance between nonlinear diffusion and aggregation induced by interaction potentials. The node representations obtained through aggregation-diffusion equations exhibit metastability, indicating that features can aggregate into multiple clusters. In addition, the dynamics within these clusters can persist for long time periods, offering the potential to alleviate over-smoothing effects. This nonlinear diffusion in our model generalizes existing diffusion-based models and estab
    
[^17]: 通过生成式人工智能在第二语言学习和教学中的分布式机构

    Distributed agency in second language learning and teaching through generative AI

    [https://arxiv.org/abs/2403.20216](https://arxiv.org/abs/2403.20216)

    生成式人工智能在第二语言学习和教学中提供了分布式机构，并可能使沉浸式技术更强大和多功能。

    

    arXiv:2403.20216v1 公告类型: 交叉摘要: 生成式人工智能为语言学习提供了重大机会。像ChatGPT这样的工具可以通过书面或口头形式的对话为第二语言提供非正式练习，学习者通过提示指定对话参数，如熟练程度、语言风格和讨论主题。人工智能可以被指导给予纠正性反馈，创建练习题，或制定扩展学习计划。教师可以使用人工智能构建各种媒体的学习和评估材料。人工智能可能会使沉浸式技术更强大和多功能，摆脱脚本化的互动。对于学习者和教师而言，重要的是要理解人工智能系统的局限性，这些局限性来自于它们对人类语言的纯统计模型，限制了它们处理语言使用中微妙社会和文化方面的能力。此外，人工智能系统的创造方式存在伦理问题。

    arXiv:2403.20216v1 Announce Type: cross  Abstract: Generative AI offers significant opportunities for language learning. Tools like ChatGPT can provide informal second language practice through chats in written or voice forms, with the learner specifying through prompts conversational parameters such as proficiency level, language register, and discussion topics. AI can be instructed to give corrective feedback, create practice exercises, or develop an extended study plan. Instructors can use AI to build learning and assessment materials in a variety of media. AI is likely to make immersive technologies more powerful and versatile, moving away from scripted interactions. For both learners and teachers, it is important to understand the limitations of AI systems that arise from their purely statistical model of human language, which limits their ability to deal with nuanced social and cultural aspects of language use. Additionally, there are ethical concerns over how AI systems are crea
    
[^18]: 无监督学习中旅行商问题中尺寸和难度的泛化

    On Size and Hardness Generalization in Unsupervised Learning for the Travelling Salesman Problem

    [https://arxiv.org/abs/2403.20212](https://arxiv.org/abs/2403.20212)

    研究了无监督学习在解决旅行商问题中的泛化能力，结果表明，使用更大的实例大小进行训练并增加嵌入维度可以构建更有效的表示，增强模型解决TSP问题的能力。

    

    我们研究了无监督学习在解决旅行商问题（TSP）中的泛化能力。我们使用一个用替代损失函数训练的图神经网络（GNN）来为每个节点生成嵌入。我们使用这些嵌入来构建一个热图，指示每条边成为最佳路径的可能性。然后我们应用局部搜索生成最终的预测。我们的研究探讨了不同训练实例大小、嵌入维数和分布如何影响无监督学习方法的结果。我们的结果表明，使用更大的实例大小进行训练并增加嵌入维度可以构建更有效的表示，增强模型解决TSP问题的能力。此外，在评估不同分布下的泛化能力时，我们首先确定了各种分布的难度，并探讨了不同难度如何影响最终结果。

    arXiv:2403.20212v1 Announce Type: new  Abstract: We study the generalization capability of Unsupervised Learning in solving the Travelling Salesman Problem (TSP). We use a Graph Neural Network (GNN) trained with a surrogate loss function to generate an embedding for each node. We use these embeddings to construct a heat map that indicates the likelihood of each edge being part of the optimal route. We then apply local search to generate our final predictions. Our investigation explores how different training instance sizes, embedding dimensions, and distributions influence the outcomes of Unsupervised Learning methods. Our results show that training with larger instance sizes and increasing embedding dimensions can build a more effective representation, enhancing the model's ability to solve TSP. Furthermore, in evaluating generalization across different distributions, we first determine the hardness of various distributions and explore how different hardnesses affect the final results
    
[^19]: 对抗谣言的未来？检索、辨别和生成

    The Future of Combating Rumors? Retrieval, Discrimination, and Generation

    [https://arxiv.org/abs/2403.20204](https://arxiv.org/abs/2403.20204)

    通过综合的辟谣流程，不仅能检测谣言，还能提供解释性生成内容来驳斥信息的真实性，并且利用专家-公民集体智慧模块确保信息可信度高精度评估。

    

    arXiv:2403.20204v1 通告类型：新的 摘要：人工智能生成内容（AIGC）技术的发展促使了带有错误信息的谣言的产生，影响了社会、经济和政治生态系统，挑战民主。当前的谣言检测工作仅仅通过标记潜在的错误信息（分类任务）来实现，未能充分解决问题，让权威机构在社交媒体上辟谣每一条信息是不现实的。我们提出的全面辟谣过程不仅能够检测谣言，而且还提供解释性生成内容来驳斥信息的真实性。我们设计的专家-公民集体智慧（ECCW）模块确保对信息可信度进行高精度评估，检索模块负责基于信息关键词从实时更新的辟谣数据库中检索相关知识。通过使用即时工程技术，

    arXiv:2403.20204v1 Announce Type: new  Abstract: Artificial Intelligence Generated Content (AIGC) technology development has facilitated the creation of rumors with misinformation, impacting societal, economic, and political ecosystems, challenging democracy. Current rumor detection efforts fall short by merely labeling potentially misinformation (classification task), inadequately addressing the issue, and it is unrealistic to have authoritative institutions debunk every piece of information on social media. Our proposed comprehensive debunking process not only detects rumors but also provides explanatory generated content to refute the authenticity of the information. The Expert-Citizen Collective Wisdom (ECCW) module we designed aensures high-precision assessment of the credibility of information and the retrieval module is responsible for retrieving relevant knowledge from a Real-time updated debunking database based on information keywords. By using prompt engineering techniques, 
    
[^20]: NeuraLunaDTNet：基于前馈神经网络的延迟容忍月球通信网络路由协议

    NeuraLunaDTNet: Feedforward Neural Network-Based Routing Protocol for Delay-Tolerant Lunar Communication Networks

    [https://arxiv.org/abs/2403.20199](https://arxiv.org/abs/2403.20199)

    提出了NeuraLunaDTNet协议，利用前馈神经网络增强了PRoPHET路由协议，通过学习动态变化的时空图中的联系计划来优化月球通信效率。

    

    空间通信面临严重延迟、难以预测的路径和通信中断等挑战。延迟容忍网络架构是为了解决这些情况而专门设计的，适用于应对一些挑战。传统的DTN路由协议在优化性能方面存在不足，由于空间通信的固有复杂性。研究人员致力于利用人工智能的最新进展来缓解一些路由挑战。我们提出利用前馈神经网络开发一种新颖的协议NeuraLunaDTNet，通过学习动态变化的时空图中的联系计划来提高PRoPHET路由协议在月球通信中的效率。

    arXiv:2403.20199v1 Announce Type: cross  Abstract: Space Communication poses challenges such as severe delays, hard-to-predict routes and communication disruptions. The Delay Tolerant Network architecture, having been specifically designed keeping such scenarios in mind, is suitable to address some challenges. The traditional DTN routing protocols fall short of delivering optimal performance, due to the inherent complexities of space communication. Researchers have aimed at using recent advancements in AI to mitigate some routing challenges [9]. We propose utilising a feedforward neural network to develop a novel protocol NeuraLunaDTNet, which enhances the efficiency of the PRoPHET routing protocol for lunar communication, by learning contact plans in dynamically changing spatio-temporal graph.
    
[^21]: 分布式群智能学习用于边缘物联网

    Distributed Swarm Learning for Edge Internet of Things

    [https://arxiv.org/abs/2403.20188](https://arxiv.org/abs/2403.20188)

    本文探讨了一种名为分布式群智能学习（DSL）的新型框架，将人工智能和生物群智能结合在一起，为大规模IoT在无线网络边缘提供高效的解决方案和稳健的工具。

    

    arXiv:2403.20188v1 公告类型: 跨领域  摘要: 物联网（IoT）的快速增长导致智能IoT设备在无线边缘进行协作机器学习任务，开启了边缘学习的新时代。面对在资源有限的无线网络中运行的大量硬件受限制的IoT设备，边缘学习面临着通信和计算瓶颈、设备和数据异构性、安全风险、隐私泄漏、非凸优化和复杂的无线环境等巨大挑战。为了解决这些问题，本文探讨了一种称为分布式群智能学习（DSL）的新型框架，将人工智能和生物群智能在整体上结合起来。通过运用先进的信号处理和通信技术，DSL为无线网络边缘的大规模IoT提供了高效的解决方案和稳健的工具。

    arXiv:2403.20188v1 Announce Type: cross  Abstract: The rapid growth of Internet of Things (IoT) has led to the widespread deployment of smart IoT devices at wireless edge for collaborative machine learning tasks, ushering in a new era of edge learning. With a huge number of hardware-constrained IoT devices operating in resource-limited wireless networks, edge learning encounters substantial challenges, including communication and computation bottlenecks, device and data heterogeneity, security risks, privacy leakages, non-convex optimization, and complex wireless environments. To address these issues, this article explores a novel framework known as distributed swarm learning (DSL), which combines artificial intelligence and biological swarm intelligence in a holistic manner. By harnessing advanced signal processing and communications, DSL provides efficient solutions and robust tools for large-scale IoT at the edge of wireless networks.
    
[^22]: HARMamba: 基于双向选择性SSM的高效可穿戴传感器人体活动识别

    HARMamba: Efficient Wearable Sensor Human Activity Recognition Based on Bidirectional Selective SSM

    [https://arxiv.org/abs/2403.20183](https://arxiv.org/abs/2403.20183)

    HARMamba利用更轻量级的选择性SSM作为基础模型架构，以解决计算资源挑战

    

    可穿戴传感器的人体活动识别（HAR）是活动感知领域的重要研究领域。最近，一种高效的硬件感知状态空间模型（SSM）Mamba作为一种有前途的替代方案出现。HARMamba引入了更轻量级的选择性SSM作为活动识别的基本模型架构，以解决系统计算负载和内存使用的挑战。

    arXiv:2403.20183v1 Announce Type: cross  Abstract: Wearable sensor human activity recognition (HAR) is a crucial area of research in activity sensing. While transformer-based temporal deep learning models have been extensively studied and implemented, their large number of parameters present significant challenges in terms of system computing load and memory usage, rendering them unsuitable for real-time mobile activity recognition applications. Recently, an efficient hardware-aware state space model (SSM) called Mamba has emerged as a promising alternative. Mamba demonstrates strong potential in long sequence modeling, boasts a simpler network architecture, and offers an efficient hardware-aware design. Leveraging SSM for activity recognition represents an appealing avenue for exploration. In this study, we introduce HARMamba, which employs a more lightweight selective SSM as the foundational model architecture for activity recognition. The goal is to address the computational resourc
    
[^23]: 人工意识。一些逻辑和概念初步

    Artificial consciousness. Some logical and conceptual preliminaries

    [https://arxiv.org/abs/2403.20177](https://arxiv.org/abs/2403.20177)

    需要在人工系统中平衡讨论意识的可能实现，提出了使用意识的维度和特征来进行讨论的必要性。

    

    arXiv:2403.20177v1 公告类型: 新的 摘要: 人工意识在理论上是否可能？是否合乎情理？如果是，那么技术上可行吗？要解决这些问题，有必要奠定一些基础，阐明人工意识产生的逻辑和经验条件以及涉及的相关术语的含义。意识是一个多义词：来自不同领域的研究人员，包括神经科学、人工智能、机器人技术和哲学等，有时会使用不同术语来指称相同现象，或者使用相同术语来指称不同现象。事实上，如果我们想探讨人工意识，就需要恰当界定关键概念。在此，经过一些逻辑和概念初步工作后，我们认为有必要使用意识的维度和特征进行平衡讨论，探讨它们在人工系统中的可能实例化或实现。我们在这项工作的主要目标是...

    arXiv:2403.20177v1 Announce Type: new  Abstract: Is artificial consciousness theoretically possible? Is it plausible? If so, is it technically feasible? To make progress on these questions, it is necessary to lay some groundwork clarifying the logical and empirical conditions for artificial consciousness to arise and the meaning of relevant terms involved. Consciousness is a polysemic word: researchers from different fields, including neuroscience, Artificial Intelligence, robotics, and philosophy, among others, sometimes use different terms in order to refer to the same phenomena or the same terms to refer to different phenomena. In fact, if we want to pursue artificial consciousness, a proper definition of the key concepts is required. Here, after some logical and conceptual preliminaries, we argue for the necessity of using dimensions and profiles of consciousness for a balanced discussion about their possible instantiation or realisation in artificial systems. Our primary goal in t
    
[^24]: ChatGPT与媒体偏见：GPT-3.5和Fine-tuned语言模型的比较研究

    ChatGPT v.s. Media Bias: A Comparative Study of GPT-3.5 and Fine-tuned Language Models

    [https://arxiv.org/abs/2403.20158](https://arxiv.org/abs/2403.20158)

    研究比较了ChatGPT与Fine-tuned语言模型在检测媒体偏见方面的表现，发现ChatGPT在检测仇恨言论和文本级上下文偏见方面表现一致，但在检测虚假新闻、种族、性别和认知偏见方面则存在困难。

    

    在我们快速发展的数字领域中，辨别媒体偏见的能力变得至关重要，因为它可以塑造公众情绪并影响关键决策。大型语言模型（LLMs），如ChatGPT，在各种自然语言处理（NLP）任务中具有广泛实用性，引发了对它们在媒体偏见检测中有效性的探究。ChatGPT能否检测媒体偏见？本研究旨在通过利用媒体偏见识别基准（MBIB）来评估ChatGPT在区分六种媒体偏见方面的能力，与Fine-tuned模型（如BART、ConvBERT和GPT-2）进行对比。研究结果呈现了一种二分法：ChatGPT在检测仇恨言论和文本级上下文偏见方面与Fine-tuned模型表现一致，但在其他偏见检测的更微妙要素上，即虚假新闻、种族、性别和认知偏见方面则面临困难。

    arXiv:2403.20158v1 Announce Type: cross  Abstract: In our rapidly evolving digital sphere, the ability to discern media bias becomes crucial as it can shape public sentiment and influence pivotal decisions. The advent of large language models (LLMs), such as ChatGPT, noted for their broad utility in various natural language processing (NLP) tasks, invites exploration of their efficacy in media bias detection. Can ChatGPT detect media bias? This study seeks to answer this question by leveraging the Media Bias Identification Benchmark (MBIB) to assess ChatGPT's competency in distinguishing six categories of media bias, juxtaposed against fine-tuned models such as BART, ConvBERT, and GPT-2. The findings present a dichotomy: ChatGPT performs at par with fine-tuned models in detecting hate speech and text-level context bias, yet faces difficulties with subtler elements of other bias detections, namely, fake news, racial, gender, and cognitive biases.
    
[^25]: 在异构MDPs中通过收敛感知采样与筛选增强联邦强化学习的CAESAR算法

    CAESAR: Enhancing Federated RL in Heterogeneous MDPs through Convergence-Aware Sampling with Screening

    [https://arxiv.org/abs/2403.20156](https://arxiv.org/abs/2403.20156)

    CAESAR算法通过结合收敛感知采样和筛选机制，有效增强了个体代理在不同MDPs上的学习。

    

    本研究探讨了在值为基础代理在不同马尔可夫决策过程（MDPs）之间运行时的联邦强化学习（FedRL）。现有的FedRL方法通常通过对代理的值函数进行平均来改善它们的表现。然而，在异构环境中，这种聚合策略在代理收敛到不同的最优值函数时是次优的。为了解决这个问题，我们引入了设计用于增强个体代理跨各种MDPs学习的Convergence-AwarE SAmpling with scReening（CAESAR）聚合方案。CAESAR是服务器使用的一种聚合策略，结合了收敛感知采样和筛选机制。通过利用学习相同MDP中代理收敛到相同最优值函数的事实，CAESAR使得能够从更熟练的同行那里有选择地吸收知识。

    arXiv:2403.20156v1 Announce Type: cross  Abstract: In this study, we delve into Federated Reinforcement Learning (FedRL) in the context of value-based agents operating across diverse Markov Decision Processes (MDPs). Existing FedRL methods typically aggregate agents' learning by averaging the value functions across them to improve their performance. However, this aggregation strategy is suboptimal in heterogeneous environments where agents converge to diverse optimal value functions. To address this problem, we introduce the Convergence-AwarE SAmpling with scReening (CAESAR) aggregation scheme designed to enhance the learning of individual agents across varied MDPs. CAESAR is an aggregation strategy used by the server that combines convergence-aware sampling with a screening mechanism. By exploiting the fact that agents learning in identical MDPs are converging to the same optimal value function, CAESAR enables the selective assimilation of knowledge from more proficient counterparts, 
    
[^26]: 基于学习的分散式车联网移动人工智能生成内容服务激励机制

    A Learning-based Incentive Mechanism for Mobile AIGC Service in Decentralized Internet of Vehicles

    [https://arxiv.org/abs/2403.20151](https://arxiv.org/abs/2403.20151)

    本文提出了一个基于多智能体深度强化学习的分散式激励机制，旨在在车联网环境中为移动AIGC服务分配的供需平衡。

    

    arXiv:2403.20151v1 公告类型: 新的 摘要: 人工智能生成内容（AIGC）指的是利用AI模型进行自动化内容生成的范式。车联网（IoV）网络中的移动AIGC服务比传统基于云的AIGC服务具有诸多优势，包括增强的网络效率、更好的可重构性，以及更强的数据安全和隐私性。然而，AIGC服务提供经常需要大量资源。因此，资源受限的路边单元（RSUs）面临着在不降低整体性能的情况下维护多样化AIGC服务池并满足所有用户服务请求的挑战。因此，在本文中，我们提出了一个用于移动AIGC服务分配的分散激励机制，利用多智能体深度强化学习找到RSUs上AIGC服务供应和IoV环境中用户服务需求之间的平衡，优化用户体验。

    arXiv:2403.20151v1 Announce Type: new  Abstract: Artificial Intelligence-Generated Content (AIGC) refers to the paradigm of automated content generation utilizing AI models. Mobile AIGC services in the Internet of Vehicles (IoV) network have numerous advantages over traditional cloud-based AIGC services, including enhanced network efficiency, better reconfigurability, and stronger data security and privacy. Nonetheless, AIGC service provisioning frequently demands significant resources. Consequently, resource-constrained roadside units (RSUs) face challenges in maintaining a heterogeneous pool of AIGC services and addressing all user service requests without degrading overall performance. Therefore, in this paper, we propose a decentralized incentive mechanism for mobile AIGC service allocation, employing multi-agent deep reinforcement learning to find the balance between the supply of AIGC services on RSUs and user demand for services within the IoV context, optimizing user experience
    
[^27]: TFB：面向时间序列预测方法全面且公平的基准比较

    TFB: Towards Comprehensive and Fair Benchmarking of Time Series Forecasting Methods

    [https://arxiv.org/abs/2403.20150](https://arxiv.org/abs/2403.20150)

    TFB通过解决数据领域覆盖不足、对传统方法的刻板印象以及不一致、不灵活的流程等问题，推动了时间序列预测方法基准比较的最新技术发展。

    

    时间序列会在经济、交通、健康和能源等不同领域中产生，对未来数值的预测在许多重要应用中起着关键作用。不出所料，许多预测方法被提出。为了确保进展，有必要能够以全面且可靠的方式经验性地研究和比较这些方法。为了实现这一目标，我们提出了TFB，一个自动化的时间序列预测（TSF）方法基准测试。TFB通过解决与数据集、比较方法和评估管道相关的缺点，推动了最新技术的发展：1）数据领域覆盖不足，2）对传统方法的刻板印象，3）不一致和不灵活的流程。为了获得更好的领域覆盖率，我们包括了来自10个不同领域的数据集：交通、电力、能源、环境、自然、经济、股票市场、银行、健康和网络。我们还提供了一个时间序列特性

    arXiv:2403.20150v1 Announce Type: cross  Abstract: Time series are generated in diverse domains such as economic, traffic, health, and energy, where forecasting of future values has numerous important applications. Not surprisingly, many forecasting methods are being proposed. To ensure progress, it is essential to be able to study and compare such methods empirically in a comprehensive and reliable manner. To achieve this, we propose TFB, an automated benchmark for Time Series Forecasting (TSF) methods. TFB advances the state-of-the-art by addressing shortcomings related to datasets, comparison methods, and evaluation pipelines: 1) insufficient coverage of data domains, 2) stereotype bias against traditional methods, and 3) inconsistent and inflexible pipelines. To achieve better domain coverage, we include datasets from 10 different domains: traffic, electricity, energy, the environment, nature, economic, stock markets, banking, health, and the web. We also provide a time series char
    
[^28]: LLM中带有离群值的准确块量化

    Accurate Block Quantization in LLMs with Outliers

    [https://arxiv.org/abs/2403.20137](https://arxiv.org/abs/2403.20137)

    LLM中出现的离群值问题，通过引入Block浮点（BFP）格式，实现了准确的块量化，解决了大规模推理需求中的硬件支持效率问题。

    

    最近几个月来，对LLMs进行极大规模推理的需求呈现出巨大增长。这凸显了专用硬件严重短缺的问题，因为它们无法高效快速地处理相关的计算和内存移动。问题加剧于所处理序列长度不断增长，因为这些序列需要与序列长度成比例的KV-cache的高效片上存储。为了使所需计算可行并将相关数据放入可用内存中，已经提出了许多量化技术，允许权重和激活的准确量化。在这方面的一个主要最近突破是引入一组具有共享比例因子的尾数块的Block浮点（BFP）格式，这些技术使得具有高效硬件支持的张量操作的记忆、功耗和计算变得更加高效。

    arXiv:2403.20137v1 Announce Type: new  Abstract: The demand for inference on extremely large scale LLMs has seen enormous growth in the recent months. It made evident the colossal shortage of dedicated hardware capable of efficient and fast processing of the involved compute and memory movement. The problem is aggravated by the exploding raise in the lengths of the sequences being processed, since those require efficient on-chip storage of the KV-cache of size proportional to the sequence length. To make the required compute feasible and fit the involved data into available memory, numerous quantization techniques have been proposed that allow accurate quantization for both weights and activations. One of the main recent breakthroughs in this direction was introduction of the family of Block Floating Point (BFP) formats characterized by a block of mantissas with a shared scale factor. These enable memory- power-, and compute- efficient hardware support of the tensor operations and prov
    
[^29]: 提示对AI生成文本的零样本检测的影响

    The Impact of Prompts on Zero-Shot Detection of AI-Generated Text

    [https://arxiv.org/abs/2403.20127](https://arxiv.org/abs/2403.20127)

    零样本检测器通常独立分析AI生成文本，而忽略了原始提示的影响，可能导致在可能性评估中存在差异

    

    近年来，大型语言模型（LLMs）的发展取得了显著进展。虽然它们的实际应用现在已经广泛，但其被滥用的潜力，例如生成假新闻和犯下剽窃行为，引起了重大关注。为解决这一问题，已经开发了检测器来评估给定文本是人类生成还是AI生成的能力。在许多方法中，零样本检测器是一种有效的方法，它们无需额外的训练数据，通常基于可能性。在基于聊天的应用程序中，用户通常输入提示并利用AI生成的文本。然而，零样本检测器通常独立分析这些文本，忽略了原始提示的影响。可以想象，这种方法可能导致文本生成阶段和检测阶段的可能性评估之间存在差异。到目前为止，仍然有一个未经验证的差距。

    arXiv:2403.20127v1 Announce Type: new  Abstract: In recent years, there have been significant advancements in the development of Large Language Models (LLMs). While their practical applications are now widespread, their potential for misuse, such as generating fake news and committing plagiarism, has posed significant concerns. To address this issue, detectors have been developed to evaluate whether a given text is human-generated or AI-generated. Among others, zero-shot detectors stand out as effective approaches that do not require additional training data and are often likelihood-based. In chat-based applications, users commonly input prompts and utilize the AI-generated texts. However, zero-shot detectors typically analyze these texts in isolation, neglecting the impact of the original prompts. It is conceivable that this approach may lead to a discrepancy in likelihood assessments between the text generation phase and the detection phase. So far, there remains an unverified gap co
    
[^30]: Mol-AIR：使用自适应内在奖励的分子强化学习用于目标导向的分子生成

    Mol-AIR: Molecular Reinforcement Learning with Adaptive Intrinsic Rewards for Goal-directed Molecular Generation

    [https://arxiv.org/abs/2403.20109](https://arxiv.org/abs/2403.20109)

    Mol-AIR 提出了使用自适应内在奖励的分子强化学习框架，通过利用历史和学习的内在奖励优势，在生成具有期望性质的分子方面表现出卓越性能。

    

    优化发现具有期望性质的分子结构的技术在基于人工智能(AI)的药物发现中至关重要。将深度生成模型与强化学习相结合已经成为生成具有特定性质的分子的有效策略。尽管具有潜力，但这种方法在探索庞大的化学空间和优化特定化学性质方面效果不佳。为了克服这些局限性，我们提出了Mol-AIR，这是一个基于强化学习的框架，使用自适应内在奖励进行有效的目标导向分子生成。Mol-AIR利用基于历史的和基于学习的内在奖励的优势，通过利用随机蒸馏网络和基于计数的策略。在基准测试中，Mol-AIR展现了超出现有方法的性能，在生成具有期望性质的分子方面，无需任何先验知识，包括pena

    arXiv:2403.20109v1 Announce Type: cross  Abstract: Optimizing techniques for discovering molecular structures with desired properties is crucial in artificial intelligence(AI)-based drug discovery. Combining deep generative models with reinforcement learning has emerged as an effective strategy for generating molecules with specific properties. Despite its potential, this approach is ineffective in exploring the vast chemical space and optimizing particular chemical properties. To overcome these limitations, we present Mol-AIR, a reinforcement learning-based framework using adaptive intrinsic rewards for effective goal-directed molecular generation. Mol-AIR leverages the strengths of both history-based and learning-based intrinsic rewards by exploiting random distillation network and counting-based strategies. In benchmark tests, Mol-AIR demonstrates superior performance over existing approaches in generating molecules with desired properties without any prior knowledge, including pena
    
[^31]: 基于计算意识结构的生成式Agent：ITCMA

    ITCMA: A Generative Agent Based on a Computational Consciousness Structure

    [https://arxiv.org/abs/2403.20097](https://arxiv.org/abs/2403.20097)

    ITCMA是基于计算意识结构的生成式Agent，通过考虑Agent与环境的互动和推理，增强了LLMs理解隐含指令和应用常识知识的能力，在Alfworld环境中表现优于SOTA。

    

    大型语言模型（LLMs）在需要理解隐含指令和应用常识知识的任务中仍然面临挑战。在这种情况下，LLMs可能需要多次尝试才能达到人类水平的表现，可能会导致在实际环境中产生不准确的响应或推理，影响它们的长期一致性和行为。本文介绍了内部时间意识机器（ITCM），一个计算意识结构。我们进一步提出了基于ITCM的Agent（ITCMA），支持在开放世界环境中生成行为和推理。ITCMA通过考虑Agent与环境的互动和推理，增强了LLMs理解隐含指令和应用常识知识的能力。在Alfworld环境中的评估显示，经过训练的ITCMA在已知集上比最先进技术（SOTA）表现提高了9%。即使未经训练的ITCMA也达到了96%的任务完成度。

    arXiv:2403.20097v1 Announce Type: new  Abstract: Large Language Models (LLMs) still face challenges in tasks requiring understanding implicit instructions and applying common-sense knowledge. In such scenarios, LLMs may require multiple attempts to achieve human-level performance, potentially leading to inaccurate responses or inferences in practical environments, affecting their long-term consistency and behavior. This paper introduces the Internal Time-Consciousness Machine (ITCM), a computational consciousness structure. We further propose the ITCM-based Agent (ITCMA), which supports behavior generation and reasoning in open-world settings. ITCMA enhances LLMs' ability to understand implicit instructions and apply common-sense knowledge by considering agents' interaction and reasoning with the environment. Evaluations in the Alfworld environment show that trained ITCMA outperforms the state-of-the-art (SOTA) by 9% on the seen set. Even untrained ITCMA achieves a 96% task completion 
    
[^32]: AI法案对非歧视法律和算法公平性的影响

    Implications of the AI Act for Non-Discrimination Law and Algorithmic Fairness

    [https://arxiv.org/abs/2403.20089](https://arxiv.org/abs/2403.20089)

    AI法案可能成为弥合算法公平性和欧盟非歧视法律的重要一环，通过将非歧视责任转移到AI模型设计阶段，推动偏见检测和偏见校正的相关实践。

    

    AI公平性的话题，正如在FATE（AI公平性、责任性、透明性和伦理）社区中讨论的那样，在过去几年中引发了有意义的讨论。然而，从法律角度来看，特别是从欧盟法律的角度，仍然存在许多待解的问题。虽然算法公平性旨在在设计阶段减轻结构不平等，但欧洲的非歧视法律则是针对AI模型部署后的个别歧视案件量身定制的。AI法案可能是朝着弥合这两个概念的巨大一步，通过将非歧视责任转移到AI模型设计阶段。基于对AI法案的综合阅读，我们评论了法律和技术执行问题，并提出了在偏见检测和偏见校正方面的实际影响，以便指定和符合特定的技术要求。

    arXiv:2403.20089v1 Announce Type: new  Abstract: The topic of fairness in AI, as debated in the FATE (Fairness, Accountability, Transparency, and Ethics in AI) communities, has sparked meaningful discussions in the past years. However, from a legal perspective, particularly from European Union law, many open questions remain. Whereas algorithmic fairness aims to mitigate structural inequalities at the design level, European non-discrimination law is tailored to individual cases of discrimination after an AI model has been deployed. The AI Act might present a tremendous step towards bridging these two concepts by shifting non-discrimination responsibilities into the design stage of AI models. Based on an integrative reading of the AI Act, we comment on legal as well as technical enforcement problems and propose practical implications on bias detection and bias correction in order to specify and comply with specific technical requirements.
    
[^33]: 利用同时功能PET/MR和深度整合的脑代谢、血液动力学和灌注网络彻底改变疾病诊断

    Revolutionizing Disease Diagnosis with simultaneous functional PET/MR and Deeply Integrated Brain Metabolic, Hemodynamic, and Perfusion Networks

    [https://arxiv.org/abs/2403.20058](https://arxiv.org/abs/2403.20058)

    提出了MX-ARM，一种基于AI的疾病诊断模型，利用同时功能PET/MR技术，能够在推理过程中同时接受单模态和多模态输入，具有创新的模态分离和重构功能。

    

    同时功能PET/MR（sf-PET/MR）是一种尖端的多模式神经影像技术。它提供了一个前所未有的机会，可以同时监测和整合由时空协变代谢活动、神经活动和脑血流（灌注）构建的多方面大脑网络。虽然在科学/临床价值上很高，但PET/MR硬件的可及性不足阻碍了其应用，更不用说现代基于AI的PET/MR融合模型。我们的目标是开发一个基于AI的临床可行疾病诊断模型，该模型基于全面的sf-PET/MR数据进行训练，在推理过程中具有允许单模态输入（例如，仅PET）以及强制多模态准确性的能力。为此，我们提出了MX-ARM，一种多模态专家混合对齐和重构模型。它是模态可分离和可交换的，动态分配不同的多层感知器（"混合）

    arXiv:2403.20058v1 Announce Type: cross  Abstract: Simultaneous functional PET/MR (sf-PET/MR) presents a cutting-edge multimodal neuroimaging technique. It provides an unprecedented opportunity for concurrently monitoring and integrating multifaceted brain networks built by spatiotemporally covaried metabolic activity, neural activity, and cerebral blood flow (perfusion). Albeit high scientific/clinical values, short in hardware accessibility of PET/MR hinders its applications, let alone modern AI-based PET/MR fusion models. Our objective is to develop a clinically feasible AI-based disease diagnosis model trained on comprehensive sf-PET/MR data with the power of, during inferencing, allowing single modality input (e.g., PET only) as well as enforcing multimodal-based accuracy. To this end, we propose MX-ARM, a multimodal MiXture-of-experts Alignment and Reconstruction Model. It is modality detachable and exchangeable, allocating different multi-layer perceptrons dynamically ("mixture 
    
[^34]: 副词是关键：使用副词删除进行简单文本数据增强

    Adverb Is the Key: Simple Text Data Augmentation with Adverb Deletion

    [https://arxiv.org/abs/2403.20015](https://arxiv.org/abs/2403.20015)

    使用简单的副词删除策略，提出了一种新颖的文本数据增强方法，能有效增强文本数据，保留语义，适用于单一文本分类和自然语言推理。

    

    在文本数据增强领域，基于规则的方法被广泛采用于现实世界的应用，因为它们具有成本效益。然而，传统的基于规则的方法存在可能丢失给定文本的原始语义的问题。我们提出了一种新颖的文本数据增强策略，通过简单地删除在句子中起辅助作用的副词来避免这种现象。我们的全面实验证明了我们提出的方法的效率和有效性，不仅适用于单一文本分类，还适用于需要语义保留的自然语言推理。我们公开发布了用于可重现性的源代码。

    arXiv:2403.20015v1 Announce Type: cross  Abstract: In the field of text data augmentation, rule-based methods are widely adopted for real-world applications owing to their cost-efficiency. However, conventional rule-based approaches suffer from the possibility of losing the original semantics of the given text. We propose a novel text data augmentation strategy that avoids such phenomena through a straightforward deletion of adverbs, which play a subsidiary role in the sentence. Our comprehensive experiments demonstrate the efficiency and effectiveness of our proposed approach for not just single text classification, but also natural language inference that requires semantic preservation. We publicly released our source code for reproducibility.
    
[^35]: PURPLE: 让大型语言模型成为更好的SQL编写器

    PURPLE: Making a Large Language Model a Better SQL Writer

    [https://arxiv.org/abs/2403.20014](https://arxiv.org/abs/2403.20014)

    提出了PURPLE模型，通过检索演示来提高大型语言模型在SQL生成中的准确性

    

    大型语言模型（LLM）技术在自然语言到SQL（NL2SQL）翻译中起着越来越重要的作用。通过大规模语料库训练的LLMs具有强大的自然语言理解和基本SQL生成能力，无需针对NL2SQL任务进行额外调整。现有基于LLMs的NL2SQL方法试图通过强调用户意图理解来提高翻译效果。然而，由于缺乏在组织复杂的逻辑运算符组合方面的知识，LLMs有时会生成不合适的SQL。一种有希望的方法是向LLMs输入演示，其中包括来自各种数据库的已知NL2SQL翻译。LLMs可以从输入演示中学习如何为给定任务组织运算符组合。在本文中，我们提出了PURPLE（Pre-trained models Utilized to Retrieve Prompts for Logical Enhancement），通过检索演示来提高准确性。

    arXiv:2403.20014v1 Announce Type: cross  Abstract: Large Language Model (LLM) techniques play an increasingly important role in Natural Language to SQL (NL2SQL) translation. LLMs trained by extensive corpora have strong natural language understanding and basic SQL generation abilities without additional tuning specific to NL2SQL tasks. Existing LLMs-based NL2SQL approaches try to improve the translation by enhancing the LLMs with an emphasis on user intention understanding. However, LLMs sometimes fail to generate appropriate SQL due to their lack of knowledge in organizing complex logical operator composition. A promising method is to input the LLMs with demonstrations, which include known NL2SQL translations from various databases. LLMs can learn to organize operator compositions from the input demonstrations for the given task. In this paper, we propose PURPLE (Pre-trained models Utilized to Retrieve Prompts for Logical Enhancement), which improves accuracy by retrieving demonstrati
    
[^36]: 多彩的剪贴：使用课程学习增强图像数据增强

    Colorful Cutout: Enhancing Image Data Augmentation with Curriculum Learning

    [https://arxiv.org/abs/2403.20012](https://arxiv.org/abs/2403.20012)

    采用课程学习的方法提出了一种名为多彩剪贴的图像数据增强技术，逐渐增加增强图像的噪声和难度，从而改善模型性能。

    

    数据增强是深度学习模型训练的一种正则化策略，它增强了泛化能力，防止过拟合，从而提高性能。作者在本研究中采用课程数据增强用于图像数据增强，并提出了多彩的剪贴，逐渐增加了增强图像中引入的噪声和难度。实验结果凸显了课程数据增强用于图像数据的可能性。作者公开发布了研究代码，以提高研究的可重现性。

    arXiv:2403.20012v1 Announce Type: cross  Abstract: Data augmentation is one of the regularization strategies for the training of deep learning models, which enhances generalizability and prevents overfitting, leading to performance improvement. Although researchers have proposed various data augmentation techniques, they often lack consideration for the difficulty of augmented data. Recently, another line of research suggests incorporating the concept of curriculum learning with data augmentation in the field of natural language processing. In this study, we adopt curriculum data augmentation for image data augmentation and propose colorful cutout, which gradually increases the noise and difficulty introduced in the augmented image. Our experimental results highlight the possibility of curriculum data augmentation for image data. We publicly released our source code to improve the reproducibility of our study.
    
[^37]: 通过交互学习语言和机器人动作实现组合性和泛化能力的发展

    Development of Compositionality and Generalization through Interactive Learning of Language and Action of Robots

    [https://arxiv.org/abs/2403.19995](https://arxiv.org/abs/2403.19995)

    提出了一个融合视觉、本体感知和语言的大脑启发式神经网络模型，通过预测编码和主动推断的框架，基于自由能原理，实现了语言组合性和感觉运动技能的联合发展。

    

    人类擅长将学到的行为应用于未学习过的情境。这种泛化行为的一个关键组成部分是我们能够将整体分解成可重复利用的部分的能力，即组合性。机器人领域的一个基本问题是涉及这种特征。“在个体只学习部分语言组合及其相应的感觉运动模式时，如何通过联想学习同时发展语言的组合性和感觉运动技能？”为了解决这个问题，我们提出了一个融合视觉、本体感知和语言的大脑启发式神经网络模型，将其纳入基于自由能原理的预测编码和主动推断框架中。通过与机器人手臂进行的各种模拟实验评估了这个模型的有效性和能力。我们的结果表明，在学习中对于遗忘。

    arXiv:2403.19995v1 Announce Type: new  Abstract: Humans excel at applying learned behavior to unlearned situations. A crucial component of this generalization behavior is our ability to compose/decompose a whole into reusable parts, an attribute known as compositionality. One of the fundamental questions in robotics concerns this characteristic. "How can linguistic compositionality be developed concomitantly with sensorimotor skills through associative learning, particularly when individuals only learn partial linguistic compositions and their corresponding sensorimotor patterns?" To address this question, we propose a brain-inspired neural network model that integrates vision, proprioception, and language into a framework of predictive coding and active inference, based on the free-energy principle. The effectiveness and capabilities of this model were assessed through various simulation experiments conducted with a robot arm. Our results show that generalization in learning to unlear
    
[^38]: MindArm: 机械智能非侵入式神经驱动假肢系统

    MindArm: Mechanized Intelligent Non-Invasive Neuro-Driven Prosthetic Arm System

    [https://arxiv.org/abs/2403.19992](https://arxiv.org/abs/2403.19992)

    提出了一种低成本技术解决方案MindArm，利用深度神经网络将大脑信号翻译成假肢运动，帮助患者执行各种活动

    

    目前，残疾或难以移动手臂的人（简称“患者”）在有效解决生理限制方面有非常有限的技术解决方案。这主要是由于两个原因：一是像以思维控制为主的假肢设备通常非常昂贵并需要昂贵的维护；二是其他解决方案需要昂贵的侵入性脑部手术，这种手术风险高，昂贵且维护困难。因此，当前的技术解决方案并不适用于具有不同财务背景的所有患者。为此，我们提出了一种低成本技术解决方案，名为MindArm，即一种机械智能非侵入式神经驱动假肢系统。我们的MindArm系统采用深度神经网络（DNN）引擎将大脑信号翻译成预期的假肢运动，从而帮助患者实施许多活动，尽管他们

    arXiv:2403.19992v1 Announce Type: new  Abstract: Currently, people with disability or difficulty to move their arms (referred to as "patients") have very limited technological solutions to efficiently address their physiological limitations. It is mainly due to two reasons: (1) the non-invasive solutions like mind-controlled prosthetic devices are typically very costly and require expensive maintenance; and (2) other solutions require costly invasive brain surgery, which is high risk to perform, expensive, and difficult to maintain. Therefore, current technological solutions are not accessible for all patients with different financial backgrounds. Toward this, we propose a low-cost technological solution called MindArm, a mechanized intelligent non-invasive neuro-driven prosthetic arm system. Our MindArm system employs a deep neural network (DNN) engine to translate brain signals into the intended prosthetic arm motion, thereby helping patients to perform many activities despite their 
    
[^39]: 语义转移增量适配器调整是一种持续的 ViTransformer

    Semantically-Shifted Incremental Adapter-Tuning is A Continual ViTransformer

    [https://arxiv.org/abs/2403.19979](https://arxiv.org/abs/2403.19979)

    适配器调整方法在持续学习中展现出较优性能，提出了增量调整共享适配器和利用存储原型进行特征采样和更新的方法来增强模型学习能力。

    

    类增量学习（CIL）旨在使模型能够在克服灾难性遗忘的同时持续学习新的类别。本文重新审视了在持续学习背景下的不同参数高效调整（PET）方法。我们观察到适配器调整表现优于基于提示的方法，甚至在每个学习会话中没有参数扩展的情况下也如此。受此启发，我们提出了增量调整共享适配器而不施加参数更新约束，增强骨干的学习能力。此外，我们从存储的原型中抽取特征样本来重新训练统一的分类器，进一步提高其性能。我们估计旧原型的语义转移，而无法访问过去的样本，并逐个会话更新存储的原型。我们提出的方法消除了模型的扩展和...

    arXiv:2403.19979v1 Announce Type: cross  Abstract: Class-incremental learning (CIL) aims to enable models to continuously learn new classes while overcoming catastrophic forgetting. The introduction of pre-trained models has brought new tuning paradigms to CIL. In this paper, we revisit different parameter-efficient tuning (PET) methods within the context of continual learning. We observe that adapter tuning demonstrates superiority over prompt-based methods, even without parameter expansion in each learning session. Motivated by this, we propose incrementally tuning the shared adapter without imposing parameter update constraints, enhancing the learning capacity of the backbone. Additionally, we employ feature sampling from stored prototypes to retrain a unified classifier, further improving its performance. We estimate the semantic shift of old prototypes without access to past samples and update stored prototypes session by session. Our proposed method eliminates model expansion and
    
[^40]: 通过调整和多支路推理增强低参数LLMs的通用代理功能

    Enhancing the General Agent Capabilities of Low-Parameter LLMs through Tuning and Multi-Branch Reasoning

    [https://arxiv.org/abs/2403.19962](https://arxiv.org/abs/2403.19962)

    通过构建特定于代理的数据并细调模型以及设计能够有效激活LLMs推理能力的提示，提出了一种综合方法来增强低参数LLMs的通用代理功能。

    

    arXiv:2403.19962v1 声明类型: 跨领域 摘要: 开源预训练的大型语言模型（LLM）表现出强大的语言理解和生成能力，使它们在各种任务中非常成功。然而，当将它们用作处理现实世界复杂问题的代理时，它们的性能远远不及ChatGPT和GPT-4等大型商用模型。作为智能代理，LLMs需要具备任务规划、长期记忆以及利用外部工具实现令人满意的性能的能力。各种方法已被提出来增强LLMs的代理能力。一方面，有些方法涉及构建特定于代理的数据和微调模型。另一方面，一些方法集中于设计能有效激活LLMs推理能力的提示。我们在7B和13B模型上同时探讨了这两种策略。我们提出了一种使用GPT-4构建特定于代理数据的全面方法。

    arXiv:2403.19962v1 Announce Type: cross  Abstract: Open-source pre-trained Large Language Models (LLMs) exhibit strong language understanding and generation capabilities, making them highly successful in a variety of tasks. However, when used as agents for dealing with complex problems in the real world, their performance is far inferior to large commercial models such as ChatGPT and GPT-4. As intelligent agents, LLMs need to have the capabilities of task planning, long-term memory, and the ability to leverage external tools to achieve satisfactory performance. Various methods have been proposed to enhance the agent capabilities of LLMs. On the one hand, methods involve constructing agent-specific data and fine-tuning the models. On the other hand, some methods focus on designing prompts that effectively activate the reasoning abilities of the LLMs. We explore both strategies on the 7B and 13B models. We propose a comprehensive method for constructing agent-specific data using GPT-4. T
    
[^41]: 用于混凝土孔的插销任务策略

    A Peg-in-hole Task Strategy for Holes in Concrete

    [https://arxiv.org/abs/2403.19946](https://arxiv.org/abs/2403.19946)

    提出了一种使工业机器人能够在混凝土孔中完成插销任务的方法，该方法通过使用深度神经网络和轻微将插销与墙面分离的策略，在无需解析建模或控制参数调整的情况下有效地找到混凝土孔。

    

    提出了一种使工业机器人能够完成混凝土孔中插销任务的方法。该方法包括在搜索位置间移动时轻微将插销与墙面分离，以避免混凝土高摩擦系数的负面影响。它使用经过强化学习训练的深度神经网络(DNN)有效地发现具有可变形状和表面处理的孔(由于混凝土脆性)，而无需解析建模或控制参数调整。该方法使用插销朝向墙面表面的位移，以及力和力矩作为DNN的输入之一。由于插销靠近孔时位移会增加(由于混凝土中孔的倒角形状)，因此这是一种用于输入DNN的有用参数。通过对DNN进行500次孔的训练并尝试发现12个未知孔来评估了该提出的方法。

    arXiv:2403.19946v1 Announce Type: cross  Abstract: A method that enables an industrial robot to accomplish the peg-in-hole task for holes in concrete is proposed. The proposed method involves slightly detaching the peg from the wall, when moving between search positions, to avoid the negative influence of the concrete's high friction coefficient. It uses a deep neural network (DNN), trained via reinforcement learning, to effectively find holes with variable shape and surface finish (due to the brittle nature of concrete) without analytical modeling or control parameter tuning. The method uses displacement of the peg toward the wall surface, in addition to force and torque, as one of the inputs of the DNN. Since the displacement increases as the peg gets closer to the hole (due to the chamfered shape of holes in concrete), it is a useful parameter for inputting in the DNN. The proposed method was evaluated by training the DNN on a hole 500 times and attempting to find 12 unknown holes. 
    
[^42]: TDANet：一种新颖的具有注意力机制的时间去噪卷积神经网络在故障诊断中的应用

    TDANet: A Novel Temporal Denoise Convolutional Neural Network With Attention for Fault Diagnosis

    [https://arxiv.org/abs/2403.19943](https://arxiv.org/abs/2403.19943)

    TDANet是一种新颖的具有注意力机制的时间去噪卷积神经网络，旨在改善噪声环境下的故障诊断性能。

    

    故障诊断在维护机械系统的运行完整性，避免由于意外故障造成的重大损失方面起着至关重要的作用。本文提出了一种名为TDANet的时间去噪卷积神经网络，旨在改善噪声环境下的故障诊断性能。该模型基于信号的周期性质将一维信号转换为二维张量，采用多尺度2D卷积核从周期内部和跨周期提取信号信息。这种方法能有效地识别信号特性。

    arXiv:2403.19943v1 Announce Type: cross  Abstract: Fault diagnosis plays a crucial role in maintaining the operational integrity of mechanical systems, preventing significant losses due to unexpected failures. As intelligent manufacturing and data-driven approaches evolve, Deep Learning (DL) has emerged as a pivotal technique in fault diagnosis research, recognized for its ability to autonomously extract complex features. However, the practical application of current fault diagnosis methods is challenged by the complexity of industrial environments. This paper proposed the Temporal Denoise Convolutional Neural Network With Attention (TDANet), designed to improve fault diagnosis performance in noise environments. This model transforms one-dimensional signals into two-dimensional tensors based on their periodic properties, employing multi-scale 2D convolution kernels to extract signal information both within and across periods. This method enables effective identification of signal chara
    
[^43]: 通过自蒸馏和重置实现多样特征学习

    Diverse Feature Learning by Self-distillation and Reset

    [https://arxiv.org/abs/2403.19941](https://arxiv.org/abs/2403.19941)

    提出了一种名为Diverse Feature Learning (DFL)的方法，通过结合重要特征保留算法和新特征学习算法，利用自蒸馏和重置来解决模型学习多样特征时遇到的问题。

    

    我们的论文解决了模型难以学习多样特征的问题，原因是它们要么忘记了先前学习的特征，要么无法学习新的特征。为了克服这个问题，我们引入了一种称为Diverse Feature Learning (DFL)的方法，它将重要特征保留算法与新特征学习算法相结合。具体地，为了保留重要特征，我们在训练过程中选择有意义的模型权重，通过自蒸馏在集成模型中进行。为了学习新的特征，我们采用了定期重新初始化模型的重置方法。通过在图像分类上对各种模型进行实验，我们发现了自蒸馏和重置之间的协同效应潜力。

    arXiv:2403.19941v1 Announce Type: new  Abstract: Our paper addresses the problem of models struggling to learn diverse features, due to either forgetting previously learned features or failing to learn new ones. To overcome this problem, we introduce Diverse Feature Learning (DFL), a method that combines an important feature preservation algorithm with a new feature learning algorithm. Specifically, for preserving important features, we utilize self-distillation in ensemble models by selecting the meaningful model weights observed during training. For learning new features, we employ reset that involves periodically re-initializing part of the model. As a result, through experiments with various models on the image classification, we have identified the potential for synergistic effects between self-distillation and reset.
    
[^44]: 决策巨蟒：通过选择性状态空间进行序列建模的强化学习

    Decision Mamba: Reinforcement Learning via Sequence Modeling with Selective State Spaces

    [https://arxiv.org/abs/2403.19925](https://arxiv.org/abs/2403.19925)

    本研究将Mamba框架整合到Decision Transformer架构中，提出了Decision Mamba，通过在不同决策环境中进行一系列实验，表明了神经网络的架构和训练方法对性能的重要影响

    

    Decision Transformer是一种将Transformer架构应用于强化学习的有前途的方法，它依赖因果自注意力来模拟状态、动作和奖励序列。本文研究了Mamba框架的整合，该框架以有效和高效的序列建模能力而闻名，将其整合到Decision Transformer架构中，关注在顺序决策任务中潜在的性能增强。我们通过在各种决策环境中进行一系列实验来系统评估这种整合，将修改后的Decision Transformer，Decision Mamba，与传统对应物进行比较。这项工作促进了顺序决策模型的发展，表明神经网络的架构和训练方法可以显著影响其性能

    arXiv:2403.19925v1 Announce Type: cross  Abstract: Decision Transformer, a promising approach that applies Transformer architectures to reinforcement learning, relies on causal self-attention to model sequences of states, actions, and rewards. While this method has shown competitive results, this paper investigates the integration of the Mamba framework, known for its advanced capabilities in efficient and effective sequence modeling, into the Decision Transformer architecture, focusing on the potential performance enhancements in sequential decision-making tasks. Our study systematically evaluates this integration by conducting a series of experiments across various decision-making environments, comparing the modified Decision Transformer, Decision Mamba, with its traditional counterpart. This work contributes to the advancement of sequential decision-making models, suggesting that the architecture and training methodology of neural networks can significantly impact their performance 
    
[^45]: CtRL-Sim：使用离线强化学习的反应性可控驾驶代理

    CtRL-Sim: Reactive and Controllable Driving Agents with Offline Reinforcement Learning

    [https://arxiv.org/abs/2403.19918](https://arxiv.org/abs/2403.19918)

    CtRL-Sim提出了一种利用离线强化学习生成反应性和可控交通代理的方法，通过在Nocturne模拟器中处理真实世界的驾驶数据来实现这一目标。

    

    在这项工作中，我们提出了CtRL-Sim，一种利用物理增强的Nocturne模拟器中的回报条件化离线强化学习来高效生成反应性和可控交通代理的方法。具体来说，我们通过Nocturne模拟器处理真实世界的驾驶数据，以生成多样化的离线数据。

    arXiv:2403.19918v1 Announce Type: cross  Abstract: Evaluating autonomous vehicle stacks (AVs) in simulation typically involves replaying driving logs from real-world recorded traffic. However, agents replayed from offline data do not react to the actions of the AV, and their behaviour cannot be easily controlled to simulate counterfactual scenarios. Existing approaches have attempted to address these shortcomings by proposing methods that rely on heuristics or learned generative models of real-world data but these approaches either lack realism or necessitate costly iterative sampling procedures to control the generated behaviours. In this work, we take an alternative approach and propose CtRL-Sim, a method that leverages return-conditioned offline reinforcement learning within a physics-enhanced Nocturne simulator to efficiently generate reactive and controllable traffic agents. Specifically, we process real-world driving data through the Nocturne simulator to generate a diverse offli
    
[^46]: MANGO：用于评估大型语言模型映射和导航能力的基准

    MANGO: A Benchmark for Evaluating Mapping and Navigation Abilities of Large Language Models

    [https://arxiv.org/abs/2403.19913](https://arxiv.org/abs/2403.19913)

    提出了用于评估大型语言模型执行文本映射和导航能力的MANGO基准，发现即使是迄今为止最好的语言模型GPT-4在回答涉及映射和导航的问题时表现不佳。

    

    如ChatGPT和GPT-4等大型语言模型最近在各种自然语言处理任务上取得了惊人的性能。本文提出了MANGO，这是一个用于评估它们执行基于文本映射和导航能力的基准。我们的基准包括来自一套文本游戏的53个迷宫：每个迷宫都与一个游览说明配对，其中包含每个位置的访问但不涵盖所有可能的路径。任务是问答：对于每个迷宫，大型语言模型读取游览说明并回答数百个映射和导航问题，例如“你应该从房子西部如何去阁楼？”和“如果我们从地下室向北和东走，我们会在哪里？”。尽管这些问题对人类来说很容易，但事实证明，迄今为止最好的语言模型GPT-4甚至在回答这些问题时表现不佳。此外，我们的实验表明，强大的映射和导航能力将有利于大型语言模型。

    arXiv:2403.19913v1 Announce Type: cross  Abstract: Large language models such as ChatGPT and GPT-4 have recently achieved astonishing performance on a variety of natural language processing tasks. In this paper, we propose MANGO, a benchmark to evaluate their capabilities to perform text-based mapping and navigation. Our benchmark includes 53 mazes taken from a suite of textgames: each maze is paired with a walkthrough that visits every location but does not cover all possible paths. The task is question-answering: for each maze, a large language model reads the walkthrough and answers hundreds of mapping and navigation questions such as "How should you go to Attic from West of House?" and "Where are we if we go north and east from Cellar?". Although these questions are easy to humans, it turns out that even GPT-4, the best-to-date language model, performs poorly at answering them. Further, our experiments suggest that a strong mapping and navigation ability would benefit large languag
    
[^47]: 超越已知：开放世界图学习中的新类别发现

    Beyond the Known: Novel Class Discovery for Open-world Graph Learning

    [https://arxiv.org/abs/2403.19907](https://arxiv.org/abs/2403.19907)

    本文提出了一种名为ORAL的新方法，用于在开放世界图学习中发现新类别，通过半监督原型学习和原型注意力网络解决了新类别和已知类别节点之间的相关性问题。

    

    图上的节点分类在许多应用中至关重要。由于现实世界开放场景中标记能力有限且发展迅速，未标记测试节点上可能会出现新类别。然而，目前对图上的新类别发现关注较少。由于图中的新类别和已知类别节点由边相关联，因此当应用消息传递GNN时它们的表示是不可区分的。此外，新类别缺乏标签信息来指导学习过程。本文提出了一种新方法Open-world gRAph neuraL network (ORAL)来解决这些挑战。ORAL首先通过半监督原型学习检测类别之间的相关性。然后通过原型注意力网络消除类间相关性，从而为不同类别提供独特的表示。此外，为了充分探索mu

    arXiv:2403.19907v1 Announce Type: cross  Abstract: Node classification on graphs is of great importance in many applications. Due to the limited labeling capability and evolution in real-world open scenarios, novel classes can emerge on unlabeled testing nodes. However, little attention has been paid to novel class discovery on graphs. Discovering novel classes is challenging as novel and known class nodes are correlated by edges, which makes their representations indistinguishable when applying message passing GNNs. Furthermore, the novel classes lack labeling information to guide the learning process. In this paper, we propose a novel method Open-world gRAph neuraL network (ORAL) to tackle these challenges. ORAL first detects correlations between classes through semi-supervised prototypical learning. Inter-class correlations are subsequently eliminated by the prototypical attention network, leading to distinctive representations for different classes. Furthermore, to fully explore mu
    
[^48]: 使用预训练深度学习模型对糖尿病视网膜病变进行分类

    Classification of Diabetic Retinopathy using Pre-Trained Deep Learning Models

    [https://arxiv.org/abs/2403.19905](https://arxiv.org/abs/2403.19905)

    本研究提出了一个使用预训练深度学习模型对糖尿病视网膜病变进行分类的计算机辅助诊断系统，通过微调技术训练模型，实现了高效的自动分类，实验结果证明了方法的有效性。

    

    研究表明，糖尿病视网膜病变（DR）是全球导致失明的主要原因，尤其影响20-70岁之间的个体。本文提出了一个计算机辅助诊断（CAD）系统，用于自动将视网膜图像分类为五个不同类别：正常、轻度、中度、重度和增殖性糖尿病视网膜病变（PDR）。所提出的系统利用卷积神经网络（CNN）结合预训练深度学习模型。通过微调技术，我们的模型在分辨率为350x350x3和224x224x3的糖尿病视网膜图像上进行了训练。在Kaggle平台上利用4个CPU、17 GB RAM和1 GB硬盘资源获得的实验结果表明了我们方法的有效性。CNN、MobileNet、VGG-16、InceptionV3和InceptionResNetV2模型的达到的曲线下面积（AUC）值分别为0.50、0.70、0.53、0.63和0。

    arXiv:2403.19905v1 Announce Type: cross  Abstract: Diabetic Retinopathy (DR) stands as the leading cause of blindness globally, particularly affecting individuals between the ages of 20 and 70. This paper presents a Computer-Aided Diagnosis (CAD) system designed for the automatic classification of retinal images into five distinct classes: Normal, Mild, Moderate, Severe, and Proliferative Diabetic Retinopathy (PDR). The proposed system leverages Convolutional Neural Networks (CNNs) employing pre-trained deep learning models. Through the application of fine-tuning techniques, our model is trained on fundus images of diabetic retinopathy with resolutions of 350x350x3 and 224x224x3. Experimental results obtained on the Kaggle platform, utilizing resources comprising 4 CPUs, 17 GB RAM, and 1 GB Disk, demonstrate the efficacy of our approach. The achieved Area Under the Curve (AUC) values for CNN, MobileNet, VGG-16, InceptionV3, and InceptionResNetV2 models are 0.50, 0.70, 0.53, 0.63, and 0
    
[^49]: 朝向一个强大的基于检索的摘要系统

    Towards a Robust Retrieval-Based Summarization System

    [https://arxiv.org/abs/2403.19889](https://arxiv.org/abs/2403.19889)

    该论文对大型语言模型在检索增强生成-基础摘要任务中的健壮性进行了调查，并提出了一个创新的评估框架和一个全面的系统来增强模型在特定场景下的健壮性。

    

    本文描述了对大型语言模型（LLMs）在检索增强生成（RAG）-基础摘要任务中的健壮性进行的调查。虽然LLMs提供了摘要能力，但它们在复杂的实际场景中的表现仍未得到充分探讨。我们的第一个贡献是LogicSumm，这是一个创新的评估框架，结合了现实场景，用来评估LLMs在RAG基础摘要过程中的健壮性。根据LogicSumm识别出的局限性，我们开发了SummRAG，这是一个全面的系统，用于创建训练对话并微调模型，以增强在LogicSumm场景中的健壮性。SummRAG是我们定义结构化方法来测试LLM能力的目标的一个示例，而不是一劳永逸地解决问题。实验结果证实了SummRAG的强大，展示了逻辑连贯性和摘要质量的提升。

    arXiv:2403.19889v1 Announce Type: cross  Abstract: This paper describes an investigation of the robustness of large language models (LLMs) for retrieval augmented generation (RAG)-based summarization tasks. While LLMs provide summarization capabilities, their performance in complex, real-world scenarios remains under-explored. Our first contribution is LogicSumm, an innovative evaluation framework incorporating realistic scenarios to assess LLM robustness during RAG-based summarization. Based on limitations identified by LogiSumm, we then developed SummRAG, a comprehensive system to create training dialogues and fine-tune a model to enhance robustness within LogicSumm's scenarios. SummRAG is an example of our goal of defining structured methods to test the capabilities of an LLM, rather than addressing issues in a one-off fashion. Experimental results confirm the power of SummRAG, showcasing improved logical coherence and summarization quality. Data, corresponding model weights, and Py
    
[^50]: MambaMixer：具有双重标记和通道选择的高效选择性状态空间模型

    MambaMixer: Efficient Selective State Space Models with Dual Token and Channel Selection

    [https://arxiv.org/abs/2403.19888](https://arxiv.org/abs/2403.19888)

    MambaMixer是一种新的架构，提出了具有数据依赖权重的双重选择机制，称为选择性标记和通道混合器，对长序列建模具有潜在优势。

    

    深度学习的最新进展主要依赖于Transformers，因为它们具有数据依赖性并且能够实现大规模学习。然而，这些架构中的注意力模块展现出输入大小的二次时间和空间，限制了它们用于长序列建模的可扩展性。尽管最近有尝试为多维数据设计高效有效的架构主干，例如图像和多变量时间序列，但现有模型要么是数据独立的，要么无法允许跨维度和内部维度之间的通信。最近，状态空间模型（SSMs），尤其是具有高效硬件感知实现的选择性状态空间模型，展现出了用于长序列建模的潜在优势。受到SSMs成功的启发，我们提出了MambaMixer，一种新的具有数据依赖权重的架构，使用跨标记和通道的双重选择机制，称为选择性标记和通道混合器。

    arXiv:2403.19888v1 Announce Type: cross  Abstract: Recent advances in deep learning have mainly relied on Transformers due to their data dependency and ability to learn at scale. The attention module in these architectures, however, exhibits quadratic time and space in input size, limiting their scalability for long-sequence modeling. Despite recent attempts to design efficient and effective architecture backbone for multi-dimensional data, such as images and multivariate time series, existing models are either data independent, or fail to allow inter- and intra-dimension communication. Recently, State Space Models (SSMs), and more specifically Selective State Space Models, with efficient hardware-aware implementation, have shown promising potential for long sequence modeling. Motivated by the success of SSMs, we present MambaMixer, a new architecture with data-dependent weights that uses a dual selection mechanism across tokens and channels, called Selective Token and Channel Mixer. M
    
[^51]: 政策空间搜索: 等价性、改进和压缩

    Policy-Space Search: Equivalences, Improvements, and Compression

    [https://arxiv.org/abs/2403.19883](https://arxiv.org/abs/2403.19883)

    该论文研究并改进了AND*执行的政策空间搜索的性能，提出了三个政策之间的等价性概念，并利用政策等价性修剪政策搜索空间，从而使AND*在解决FOND任务时更加有效。

    

    完全可观察的非确定性（FOND）规划是人工智能计划中不确定性的核心。它通过具有非确定性效果的动作来建模不确定性。AND*（Messa和Pereira，2023）是一个泛化了A* (Hart等人，1968) 用于FOND规划的FOND规划器。 本文研究并改进了AND*执行的政策空间搜索的性能。我们提出了一个多项式时间过程，仅给定应映射的状态集即可构造出解决方案政策。 这个过程，与对FOND政策结构的更好理解结合在一起，使我们能够提出三个政策之间的等价性概念。 我们使用政策等价性来修剪政策搜索空间的一部分，使AND*在解决FOND任务时更加有效。

    arXiv:2403.19883v1 Announce Type: new  Abstract: Fully-observable non-deterministic (FOND) planning is at the core of artificial intelligence planning with uncertainty. It models uncertainty through actions with non-deterministic effects. A* with Non-Determinism (AND*) (Messa and Pereira, 2023) is a FOND planner that generalizes A* (Hart et al., 1968) for FOND planning. It searches for a solution policy by performing an explicit heuristic search on the policy space of the FOND task. In this paper, we study and improve the performance of the policy-space search performed by AND*. We present a polynomial-time procedure that constructs a solution policy given just the set of states that should be mapped. This procedure, together with a better understanding of the structure of FOND policies, allows us to present three concepts of equivalences between policies. We use policy equivalences to prune part of the policy search space, making AND* substantially more effective in solving FOND tasks
    
[^52]: IME：集成多曲率共享和特定嵌入用于时间知识图完成

    IME: Integrating Multi-curvature Shared and Specific Embedding for Temporal Knowledge Graph Completion

    [https://arxiv.org/abs/2403.19881](https://arxiv.org/abs/2403.19881)

    IME模型用于时间知识图完成任务，将知识图建模为多曲率空间，包括超球面、双曲线和欧几里得空间，并融合空间共享属性和空间特定属性。

    

    时间知识图（TKG）融合了时间维度，允许精确捕捉知识的演化并反映现实世界的动态特性。通常，TKG包含复杂的几何结构，各种几何结构交织在一起。然而，现有的时间知识图完成（TKGC）方法要么将TKG建模在一个空间中，要么忽略不同曲率空间的异质性，从而限制了捕捉这些复杂几何结构的能力。在本文中，我们提出了一种新颖的集成多曲率共享和特定嵌入（IME）模型用于TKGC任务。具体而言，IME将TKG建模为多曲率空间，包括超球面、双曲线和欧几里得空间。随后，IME融合了两个关键属性，即空间共享属性和空间特定属性。

    arXiv:2403.19881v1 Announce Type: new  Abstract: Temporal Knowledge Graphs (TKGs) incorporate a temporal dimension, allowing for a precise capture of the evolution of knowledge and reflecting the dynamic nature of the real world. Typically, TKGs contain complex geometric structures, with various geometric structures interwoven. However, existing Temporal Knowledge Graph Completion (TKGC) methods either model TKGs in a single space or neglect the heterogeneity of different curvature spaces, thus constraining their capacity to capture these intricate geometric structures. In this paper, we propose a novel Integrating Multi-curvature shared and specific Embedding (IME) model for TKGC tasks. Concretely, IME models TKGs into multi-curvature spaces, including hyperspherical, hyperbolic, and Euclidean spaces. Subsequently, IME incorporates two key properties, namely space-shared property and space-specific property. The space-shared property facilitates the learning of commonalities across di
    
[^53]: 通过缓慢变化的序列实现稳定的机器学习模型重新训练

    Towards Stable Machine Learning Model Retraining via Slowly Varying Sequences

    [https://arxiv.org/abs/2403.19871](https://arxiv.org/abs/2403.19871)

    通过混合整数优化算法，以保持一致的分析洞见为重点，在重新训练机器学习模型中实现比贪婪训练更强稳定性，同时在模型性能上有小幅、可控的牺牲。

    

    重新训练机器学习模型仍然是实际机器学习模型部署的重要任务。现有方法主要关注贪婪方法，以找到表现最佳的模型，而不考虑通过不同的重新训练演变来保持训练模型结构的稳定性。在这项研究中，我们开发了一种混合整数优化算法，全面考虑了通过不同的数据批次更新重新训练机器学习模型的问题。我们的方法侧重于保留一致的分析洞见 - 这对于模型可解释性、实施简易性和与用户建立信任至关重要 - 通过使用可以直接纳入优化问题的自定义定义的距离度量。重要的是，我们的方法在真实的生产案例研究中表现出比贪婪训练模型更强的稳定性，同时在模型性能上有小幅、可控的牺牲。

    arXiv:2403.19871v1 Announce Type: cross  Abstract: Retraining machine learning models remains an important task for real-world machine learning model deployment. Existing methods focus largely on greedy approaches to find the best-performing model without considering the stability of trained model structures across different retraining evolutions. In this study, we develop a mixed integer optimization algorithm that holistically considers the problem of retraining machine learning models across different data batch updates. Our method focuses on retaining consistent analytical insights - which is important to model interpretability, ease of implementation, and fostering trust with users - by using custom-defined distance metrics that can be directly incorporated into the optimization problem. Importantly, our method shows stronger stability than greedily trained models with a small, controllable sacrifice in model performance in a real-world production case study. Finally, important an
    
[^54]: 在流式和大规模并行模型中找到决策树分割点

    Finding Decision Tree Splits in Streaming and Massively Parallel Models

    [https://arxiv.org/abs/2403.19867](https://arxiv.org/abs/2403.19867)

    提出了在数据流学习中计算决策树最佳分割点的算法，能够在流式计算和大规模并行模型中高效运行

    

    在这项工作中，我们提出了一种数据流算法，用于计算决策树学习中的最优分割点。具体而言，给定观测数据流$x_i$及其标签$y_i$，目标是找到将数据分为两组的最佳分割点$j$，使得均方误差（回归问题）或误分类率（分类问题）最小化。我们提供了多种快速的数据流算法，这些算法在这些问题中使用亚线性空间和少量次数的遍历。这些算法还可以扩展到大规模并行计算模型中。尽管不能直接比较，但我们的工作与Domingos和Hulten的开创性工作（KDD 2000）相互补充。

    arXiv:2403.19867v1 Announce Type: cross  Abstract: In this work, we provide data stream algorithms that compute optimal splits in decision tree learning. In particular, given a data stream of observations $x_i$ and their labels $y_i$, the goal is to find the optimal split point $j$ that divides the data into two sets such that the mean squared error (for regression) or misclassification rate (for classification) is minimized. We provide various fast streaming algorithms that use sublinear space and a small number of passes for these problems. These algorithms can also be extended to the massively parallel computation model. Our work, while not directly comparable, complements the seminal work of Domingos and Hulten (KDD 2000).
    
[^55]: 合成图像在迁移学习中有用吗？关于数据生成、数量和利用的调查

    Is Synthetic Image Useful for Transfer Learning? An Investigation into Data Generation, Volume, and Utilization

    [https://arxiv.org/abs/2403.19866](https://arxiv.org/abs/2403.19866)

    研究探讨了从文本到图像生成模型中生成和利用合成图像在迁移学习中的作用，提出了桥接迁移的两阶段框架以解决合成图像与真实图像之间的分布差异。

    

    合成图像数据生成代表了训练深度学习模型的一个有前景的途径，特别是在迁移学习领域，因为在特定领域获取真实图像可能会由于隐私和知识产权考虑而变得代价高昂。本研究深入探讨了从文本到图像生成模型中获取的合成图像的生成和利用，以促进迁移学习范式。尽管生成的图像具有高度的视觉逼真度，但我们观察到，将这些图像天真地纳入现有的真实图像数据集并不能始终提升模型性能，这是由于合成图像和真实图像之间固有的分布差异所致。为了解决这个问题，我们引入了一种名为“桥接迁移”的新颖的两阶段框架，该框架首先利用合成图像对预训练模型进行微调以提高其可迁移性，随后使用真实数据进行快速适应。

    arXiv:2403.19866v1 Announce Type: cross  Abstract: Synthetic image data generation represents a promising avenue for training deep learning models, particularly in the realm of transfer learning, where obtaining real images within a specific domain can be prohibitively expensive due to privacy and intellectual property considerations. This work delves into the generation and utilization of synthetic images derived from text-to-image generative models in facilitating transfer learning paradigms. Despite the high visual fidelity of the generated images, we observe that their naive incorporation into existing real-image datasets does not consistently enhance model performance due to the inherent distribution gap between synthetic and real images. To address this issue, we introduce a novel two-stage framework called bridged transfer, which initially employs synthetic images for fine-tuning a pre-trained model to improve its transferability and subsequently uses real data for rapid adaptat
    
[^56]: LLMSense：利用LLMs进行时空传感器轨迹的高级推理

    LLMSense: Harnessing LLMs for High-level Reasoning Over Spatiotemporal Sensor Traces

    [https://arxiv.org/abs/2403.19857](https://arxiv.org/abs/2403.19857)

    本研究探讨了如何利用大语言模型（LLMs）的推理能力和世界知识来识别长期时空传感器轨迹中的复杂事件。

    

    大多数关于传感系统中机器学习的研究都集中在处理短时间窗内的原始传感数据的低层感知任务上。然而，许多实际应用，如人类例行建模和占用跟踪，需要高级推理能力来理解概念，并根据长期传感器轨迹做出推断。现有的基于机器学习的处理这些复杂任务的方法由于训练样本有限和传感器轨迹的高维特性而难以泛化，需要融合人类知识来设计基本模型或逻辑推理方法。我们提出一个基本问题：我们能否利用大语言模型（LLMs）的推理能力和世界知识来识别长期时空传感器轨迹中的复杂事件？为了回答这个问题，我们设计了一个高级推理任务上LLMs的有效提示框架。

    arXiv:2403.19857v1 Announce Type: new  Abstract: Most studies on machine learning in sensing systems focus on low-level perception tasks that process raw sensory data within a short time window. However, many practical applications, such as human routine modeling and occupancy tracking, require high-level reasoning abilities to comprehend concepts and make inferences based on long-term sensor traces. Existing machine learning-based approaches for handling such complex tasks struggle to generalize due to the limited training samples and the high dimensionality of sensor traces, necessitating the integration of human knowledge for designing first-principle models or logic reasoning methods. We pose a fundamental question: Can we harness the reasoning capabilities and world knowledge of Large Language Models (LLMs) to recognize complex events from long-term spatiotemporal sensor traces? To answer this question, we design an effective prompting framework for LLMs on high-level reasoning ta
    
[^57]: 迈向巴西历史知识图谱

    Towards a Brazilian History Knowledge Graph

    [https://arxiv.org/abs/2403.19856](https://arxiv.org/abs/2403.19856)

    构建基于巴西历史词典和维基数据的知识图谱，以丰富葡萄牙文本信息提取，填补巴西命名实体在维基数据中缺失的概念。

    

    这篇简短的论文描述了在基于巴西历史词典（DHBB）和维基百科/维基数据构建巴西历史知识图谱项目的第一步。我们认为，巴西命名实体（人物、地点、组织、政治事件和运动）的大型存储库对从葡萄牙文本中提取信息将是有益的。我们展示了DHBB中描述的许多术语/实体在维基数据中没有相应的概念（或Q项），后者是与维基百科相关的最大结构化实体数据库。我们描述了从DHBB中提取信息的先前工作，并概述了构建基于维基数据的历史知识图谱的步骤。

    arXiv:2403.19856v1 Announce Type: new  Abstract: This short paper describes the first steps in a project to construct a knowledge graph for Brazilian history based on the Brazilian Dictionary of Historical Biographies (DHBB) and Wikipedia/Wikidata. We contend that large repositories of Brazilian-named entities (people, places, organizations, and political events and movements) would be beneficial for extracting information from Portuguese texts. We show that many of the terms/entities described in the DHBB do not have corresponding concepts (or Q items) in Wikidata, the largest structured database of entities associated with Wikipedia. We describe previous work on extracting information from the DHBB and outline the steps to construct a Wikidata-based historical knowledge graph.
    
[^58]: 新的农学家：语言模型是作物管理专家

    The New Agronomists: Language Models are Experts in Crop Management

    [https://arxiv.org/abs/2403.19839](https://arxiv.org/abs/2403.19839)

    本文介绍了一个更先进的智能作物管理系统，利用深度强化学习和语言模型结合决策支持系统来优化作物管理实践。

    

    作物管理在决定作物产量、经济盈利和环境可持续性方面起着至关重要的作用。本文在以往研究基础上引入了一个更先进的智能作物管理系统，该系统独特地将强化学习、语言模型（LM）和由决策支持系统为农业技术转移（DSSAT）实现的作物模拟相结合。我们利用深度强化学习，特别是深度Q网络，来训练处理模拟器中众多状态变量作为观测的管理策略。

    arXiv:2403.19839v1 Announce Type: cross  Abstract: Crop management plays a crucial role in determining crop yield, economic profitability, and environmental sustainability. Despite the availability of management guidelines, optimizing these practices remains a complex and multifaceted challenge. In response, previous studies have explored using reinforcement learning with crop simulators, typically employing simple neural-network-based reinforcement learning (RL) agents. Building on this foundation, this paper introduces a more advanced intelligent crop management system. This system uniquely combines RL, a language model (LM), and crop simulations facilitated by the Decision Support System for Agrotechnology Transfer (DSSAT). We utilize deep RL, specifically a deep Q-network, to train management policies that process numerous state variables from the simulator as observations. A novel aspect of our approach is the conversion of these state variables into more informative language, fac
    
[^59]: 多帧、轻量级和高效的视觉-语言模型用于自动驾驶问答

    Multi-Frame, Lightweight & Efficient Vision-Language Models for Question Answering in Autonomous Driving

    [https://arxiv.org/abs/2403.19838](https://arxiv.org/abs/2403.19838)

    提出了一种高效、轻量级、多帧视觉语言模型 EM-VLM4AD，用于自动驾驶的视觉问答，相比现有方法，内存和浮点运算需求至少减少十倍，并且在BLEU-4、METEOR、CIDEr和ROGUE分数上均取得更高的表现。

    

    视觉-语言模型（VLMs）和多模态语言模型（MMLMs）已经在自动驾驶研究中变得突出，因为这些模型可以利用交通场景图像和其他数据模态提供可解释的文本推理和响应，用于端到端自动驾驶安全任务。然而，当前针对这些系统的方法使用昂贵的大型语言模型（LLM）骨干和图像编码器，使得这些系统不适合具有严格内存限制和需要快速推理时间的实时自动驾驶系统。为解决这些先前问题，我们开发了EM-VLM4AD，一种高效、轻量级、多帧视觉语言模型，用于执行自动驾驶的视觉问答。

    arXiv:2403.19838v1 Announce Type: cross  Abstract: Vision-Language Models (VLMs) and Multi-Modal Language models (MMLMs) have become prominent in autonomous driving research, as these models can provide interpretable textual reasoning and responses for end-to-end autonomous driving safety tasks using traffic scene images and other data modalities. However, current approaches to these systems use expensive large language model (LLM) backbones and image encoders, making such systems unsuitable for real-time autonomous driving systems where tight memory constraints exist and fast inference time is necessary. To address these previous issues, we develop EM-VLM4AD, an efficient, lightweight, multi-frame vision language model which performs Visual Question Answering for autonomous driving. In comparison to previous approaches, EM-VLM4AD requires at least 10 times less memory and floating point operations, while also achieving higher BLEU-4, METEOR, CIDEr, and ROGUE scores than the existing b
    
[^60]: 通过视觉语言模型对神经网络进行基于概念的分析

    Concept-based Analysis of Neural Networks via Vision-Language Models

    [https://arxiv.org/abs/2403.19837](https://arxiv.org/abs/2403.19837)

    本文提出利用视觉语言模型作为透镜，通过其隐含的高层次概念来进行对视觉模型的分析。

    

    视觉深度神经网络（DNNs）的形式化分析非常可取，但由于难以表达视觉任务的形式化规范以及缺乏高效的验证程序，这是非常具有挑战性的。在本文中，我们提出利用新兴的多模态、视觉语言、基础模型（VLMs）作为一种通过其可以推理视觉模型的透镜。VLMs已经在大量图像及其文本描述上进行了训练，因此隐式地了解描述这些图像的高层次、人类可理解的概念。我们描述了一种名为$\texttt{Con}_{\texttt{spec}}$的逻辑规范语言，旨在便于按照这些概念编写规范。为了定义和形式化检查$\texttt{Con}_{\texttt{spec}}$规范，我们利用了一个VLM，它提供了一种编码和高效检查视觉模型的自然语言属性的方法。我们展示了我们的te

    arXiv:2403.19837v1 Announce Type: cross  Abstract: Formal analysis of vision-based deep neural networks (DNNs) is highly desirable but it is very challenging due to the difficulty of expressing formal specifications for vision tasks and the lack of efficient verification procedures. In this paper, we propose to leverage emerging multimodal, vision-language, foundation models (VLMs) as a lens through which we can reason about vision models. VLMs have been trained on a large body of images accompanied by their textual description, and are thus implicitly aware of high-level, human-understandable concepts describing the images. We describe a logical specification language $\texttt{Con}_{\texttt{spec}}$ designed to facilitate writing specifications in terms of these concepts. To define and formally check $\texttt{Con}_{\texttt{spec}}$ specifications, we leverage a VLM, which provides a means to encode and efficiently check natural-language properties of vision models. We demonstrate our te
    
[^61]: ChatTracer：大型语言模型驱动的实时蓝牙设备追踪系统

    ChatTracer: Large Language Model Powered Real-time Bluetooth Device Tracking System

    [https://arxiv.org/abs/2403.19833](https://arxiv.org/abs/2403.19833)

    ChatTracer是一个由LLM驱动的实时蓝牙设备追踪系统，其创新之处在于可靠高效的BLE数据包分组算法和结合了监督微调和强化学习微调策略的LLM微调策略。

    

    大型语言模型（LLMs），如OpenAI ChatGPT和Google Bard所展示的，已经改变了我们与网络技术互动的方式。本文研究了将LLM与无线传感器网络（WSN）相连接的可能性。一个成功的设计不仅会将LLM的知识领域延伸到物理世界，而且将彻底革新人们与WSN的互动。为此，我们提出了ChatTracer，一个由LLM驱动的实时蓝牙设备追踪系统。ChatTracer由三个关键组件组成：一系列蓝牙嗅探节点、一个数据库和一个经过精调的LLM。ChatTracer的设计基于我们的实验观察，商用的苹果/安卓设备即使在空闲状态下也会每分钟广播数百个BLE数据包。它的创新之处在于：i）一个可靠高效的BLE数据包分组算法；和ii）一个结合了监督微调（SFT）和强化学习微调策略的LLM微调策略。

    arXiv:2403.19833v1 Announce Type: cross  Abstract: Large language models (LLMs), exemplified by OpenAI ChatGPT and Google Bard, have transformed the way we interact with cyber technologies. In this paper, we study the possibility of connecting LLM with wireless sensor networks (WSN). A successful design will not only extend LLM's knowledge landscape to the physical world but also revolutionize human interaction with WSN. To the end, we present ChatTracer, an LLM-powered real-time Bluetooth device tracking system. ChatTracer comprises three key components: an array of Bluetooth sniffing nodes, a database, and a fine-tuned LLM. ChatTracer was designed based on our experimental observation that commercial Apple/Android devices always broadcast hundreds of BLE packets per minute even in their idle status. Its novelties lie in two aspects: i) a reliable and efficient BLE packet grouping algorithm; and ii) an LLM fine-tuning strategy that combines both supervised fine-tuning (SFT) and reinfo
    
[^62]: 重新思考语义分割中的不确定性估计度量

    Segmentation Re-thinking Uncertainty Estimation Metrics for Semantic Segmentation

    [https://arxiv.org/abs/2403.19826](https://arxiv.org/abs/2403.19826)

    重新思考了语义分割中的不确定性估计度量，发现并改进了PAvPU框架中的核心缺陷。

    

    在计算机视觉领域中，语义分割作为机器学习中的一个基本应用，将图像的每个像素分类为不同的语义类别。这项任务通过包含不确定性量化来超越传统的准确度度量，不确定性量化是评估每个分割预测可靠性的关键指标。我们的研究识别出PAvPU（Patch Accuracy versus Patch Uncertainty）框架中的三个核心缺陷，并提出旨在改进该度量的强大解决方案。通过解决这些问题，我们旨在增强可靠性和适用性。

    arXiv:2403.19826v1 Announce Type: new  Abstract: In the domain of computer vision, semantic segmentation emerges as a fundamental application within machine learning, wherein individual pixels of an image are classified into distinct semantic categories. This task transcends traditional accuracy metrics by incorporating uncertainty quantification, a critical measure for assessing the reliability of each segmentation prediction. Such quantification is instrumental in facilitating informed decision-making, particularly in applications where precision is paramount. Within this nuanced framework, the metric known as PAvPU (Patch Accuracy versus Patch Uncertainty) has been developed as a specialized tool for evaluating entropy-based uncertainty in image segmentation tasks. However, our investigation identifies three core deficiencies within the PAvPU framework and proposes robust solutions aimed at refining the metric. By addressing these issues, we aim to enhance the reliability and applic
    
[^63]: 多阶段多模态预训练用于自动语音识别

    Multi-Stage Multi-Modal Pre-Training for Automatic Speech Recognition

    [https://arxiv.org/abs/2403.19822](https://arxiv.org/abs/2403.19822)

    提出了一种结合多模态和多任务无监督预训练以及基于翻译的监督中间训练方法的新方法，能够在Librispeech和SUPERB上相对提高高达38.45%的词错误率（WER）。

    

    机器学习的最新进展表明，与随机初始化模型相比，多模态预训练可以提高自动语音识别（ASR）性能，即使模型在单模态任务上进行微调。现有的用于ASR任务的多模态预训练方法主要集中在单阶段预训练，即使用单个无监督任务进行预训练，然后在下游任务上进行微调。在这项工作中，我们介绍了一种将多模态和多任务无监督预训练与基于翻译的监督中间训练方法相结合的新方法。我们在实验中证明，这种多阶段方法在Librispeech和SUPERB上相对词错误率（WER）的改进最高达38.45％。此外，我们分享了选择预训练方法和数据集的一些重要发现。

    arXiv:2403.19822v1 Announce Type: cross  Abstract: Recent advances in machine learning have demonstrated that multi-modal pre-training can improve automatic speech recognition (ASR) performance compared to randomly initialized models, even when models are fine-tuned on uni-modal tasks. Existing multi-modal pre-training methods for the ASR task have primarily focused on single-stage pre-training where a single unsupervised task is used for pre-training followed by fine-tuning on the downstream task. In this work, we introduce a novel method combining multi-modal and multi-task unsupervised pre-training with a translation-based supervised mid-training approach. We empirically demonstrate that such a multi-stage approach leads to relative word error rate (WER) improvements of up to 38.45% over baselines on both Librispeech and SUPERB. Additionally, we share several important findings for choosing pre-training methods and datasets.
    
[^64]: 评估医疗诊断中机器学习模型的解释能力：一种人机协作方法

    Evaluating Explanatory Capabilities of Machine Learning Models in Medical Diagnostics: A Human-in-the-Loop Approach

    [https://arxiv.org/abs/2403.19820](https://arxiv.org/abs/2403.19820)

    通过人机协作方法，评估医疗诊断中机器学习模型的解释能力，提出了使用医学指南和特征重要性确定胰腺癌治疗关键特征的方法，同时探索了使用相似度衡量的解释结果的方法。

    

    本文针对决策树、随机森林和XGBoost模型在胰腺癌数据集上的解释能力进行了全面研究。我们利用人机协作技术和医学指南作为领域知识来源，以确定与制定胰腺癌治疗相关的不同特征的重要性。这些特征不仅用作机器学习模型的降维方法，还用作评估不同模型的可解释性能力的方式，使用无知和非无知的解释性技术。为了便于解释结果的解释，我们提出使用诸如加权杰卡相似系数之类的相似度衡量。我们的目标不仅是选择性能最佳的模型，还要选择能够最好解释其结论并与之保持一致的模型。

    arXiv:2403.19820v1 Announce Type: cross  Abstract: This paper presents a comprehensive study on the evaluation of explanatory capabilities of machine learning models, with a focus on Decision Trees, Random Forest and XGBoost models using a pancreatic cancer dataset. We use Human-in-the-Loop related techniques and medical guidelines as a source of domain knowledge to establish the importance of the different features that are relevant to establish a pancreatic cancer treatment. These features are not only used as a dimensionality reduction approach for the machine learning models, but also as way to evaluate the explainability capabilities of the different models using agnostic and non-agnostic explainability techniques. To facilitate interpretation of explanatory results, we propose the use of similarity measures such as the Weighted Jaccard Similarity coefficient. The goal is to not only select the best performing model but also the one that can best explain its conclusions and aligns
    
[^65]: 开发医疗保健语言模型嵌入空间

    Developing Healthcare Language Model Embedding Spaces

    [https://arxiv.org/abs/2403.19802](https://arxiv.org/abs/2403.19802)

    通过深度对比学习训练的模型在医疗保健文本分类任务中表现出色，有效利用有限标记数据，并减少了模型参数更新。

    

    预训练大型语言模型 (LLMs) 在诸如专注于医疗保健文本之类的跨领域数据集上经常面临困难。我们探索专门的预训练方法，以调整较小的LLMs以适应不同的医疗保健数据集。评估了三种方法：传统的掩码语言建模、用于无监督文本表示的深度对比学习 (DeCLUTR) 和一种利用医疗保健环境中的元数据类别的新颖预训练目标。对每个数据集进行了下游文档分类任务的评估，并对生成的嵌入空间进行了额外分析。对比训练的模型在分类任务上表现优于其他方法，能够在有限标记数据的情况下提供强大性能，并且需要较少的模型参数更新。虽然基于元数据的预训练并未进一步提高数据集上的分类性能，但它确实产生了有趣的嵌入聚类可分性。所有领域的调整

    arXiv:2403.19802v1 Announce Type: cross  Abstract: Pre-trained Large Language Models (LLMs) often struggle on out-of-domain datasets like healthcare focused text. We explore specialized pre-training to adapt smaller LLMs to different healthcare datasets. Three methods are assessed: traditional masked language modeling, Deep Contrastive Learning for Unsupervised Textual Representations (DeCLUTR), and a novel pre-training objective utilizing metadata categories from the healthcare settings. These schemes are evaluated on downstream document classification tasks for each dataset, with additional analysis of the resultant embedding spaces. Contrastively trained models outperform other approaches on the classification tasks, delivering strong performance from limited labeled data and with fewer model parameter updates required. While metadata-based pre-training does not further improve classifications across the datasets, it yields interesting embedding cluster separability. All domain adap
    
[^66]: Gegenbauer图神经网络用于时变信号重构

    Gegenbauer Graph Neural Networks for Time-varying Signal Reconstruction

    [https://arxiv.org/abs/2403.19800](https://arxiv.org/abs/2403.19800)

    提出了一种新颖的Gegenbauer-based graph convolutional (GegenConv)算子，用于提高时变信号重构的准确性

    

    重构时变图信号（或图时间序列插补）是机器学习和信号处理中的一个关键问题，具有广泛的应用，从传感器网络中的缺失数据插补到时间序列预测。准确捕捉这些信号固有的时空信息对于有效解决这些任务至关重要。然而，现有方法依赖于时间差的平滑性假设和简单的凸优化技术，存在固有限制。为了解决这些挑战，我们提出了一种结合学习模块以增强下游任务准确性的新方法。为此，我们引入基于Gegenbauer多项式理论的Gegenbauer-based graph convolutional（GegenConv）算子，这是传统切比雪夫图卷积的推 generalization。

    arXiv:2403.19800v1 Announce Type: cross  Abstract: Reconstructing time-varying graph signals (or graph time-series imputation) is a critical problem in machine learning and signal processing with broad applications, ranging from missing data imputation in sensor networks to time-series forecasting. Accurately capturing the spatio-temporal information inherent in these signals is crucial for effectively addressing these tasks. However, existing approaches relying on smoothness assumptions of temporal differences and simple convex optimization techniques have inherent limitations. To address these challenges, we propose a novel approach that incorporates a learning module to enhance the accuracy of the downstream task. To this end, we introduce the Gegenbauer-based graph convolutional (GegenConv) operator, which is a generalization of the conventional Chebyshev graph convolution by leveraging the theory of Gegenbauer polynomials. By deviating from traditional convex problems, we expand t
    
[^67]: MAPL: 模型无关的点对点学习

    MAPL: Model Agnostic Peer-to-peer Learning

    [https://arxiv.org/abs/2403.19792](https://arxiv.org/abs/2403.19792)

    MAPL提出了一种新颖的方法，即Model Agnostic Peer-to-peer Learning，通过点对点通信在邻近客户端之间同时学习异质个性化模型和协作图，在去中心化环境中实现了有效的协作，并且实验证明了MAPL在性能上具有竞争力。

    

    在去中心化环境中，异质客户端之间的有效协作在文献中是一个相当未被探索的领域。为了从结构上解决这个问题，我们引入了模型无关的点对点学习（简称MAPL），这是一种通过邻近客户端之间的点对点通信同时学习异质个性化模型和协作图的新方法。MAPL由两个主要模块组成：（i）本地级别的个性化模型学习（PML），利用客户端内部和客户端间对比损失的组合；（ii）网络范围的去中心化协作图学习（CGL），根据本地任务相似性以隐私保护的方式动态地优化协作权重。我们广泛的实验证明了MAPL的有效性，并且与其集中式模型无关的对应物相比，MAPL表现出竞争力（或者在大多数情况下更优），而且不依赖于任何中心服务器。

    arXiv:2403.19792v1 Announce Type: cross  Abstract: Effective collaboration among heterogeneous clients in a decentralized setting is a rather unexplored avenue in the literature. To structurally address this, we introduce Model Agnostic Peer-to-peer Learning (coined as MAPL) a novel approach to simultaneously learn heterogeneous personalized models as well as a collaboration graph through peer-to-peer communication among neighboring clients. MAPL is comprised of two main modules: (i) local-level Personalized Model Learning (PML), leveraging a combination of intra- and inter-client contrastive losses; (ii) network-wide decentralized Collaborative Graph Learning (CGL) dynamically refining collaboration weights in a privacy-preserving manner based on local task similarities. Our extensive experimentation demonstrates the efficacy of MAPL and its competitive (or, in most cases, superior) performance compared to its centralized model-agnostic counterparts, without relying on any central ser
    
[^68]: 为数字初级保健工作定制的大型语言模型

    Bespoke Large Language Models for Digital Triage Assistance in Mental Health Care

    [https://arxiv.org/abs/2403.19790](https://arxiv.org/abs/2403.19790)

    利用大型语言模型处理心理健康护理中的非结构化临床数据，帮助英国国家卫生服务体系(NHS)解决专科精神保健长等待名单的问题。

    

    当代大型语言模型（LLMs）可能对处理电子健康记录（EHRs）中包含的非结构化叙述性自由文本临床数据具有实用性，这对于精神健康领域尤为重要，因为大多数常规收集的患者数据缺乏结构化的机器可读内容。英国国家卫生服务体系（NHS）面临的一项重要问题是专科精神保健的长等待名单。根据NHS的数据，2023年每个月都有37万至47万人次向次级精神保健服务提出个体化的新推荐。推荐必须由临床医生进行筛选，使用患者EHR中包含的临床信息，以做出关于最适合的精神保健团队评估和可能治疗这些患者的决定。通过摄入潜在庞大的临床笔记，有效地推荐相关团队的能力

    arXiv:2403.19790v1 Announce Type: new  Abstract: Contemporary large language models (LLMs) may have utility for processing unstructured, narrative free-text clinical data contained in electronic health records (EHRs) -- a particularly important use-case for mental health where a majority of routinely-collected patient data lacks structured, machine-readable content.   A significant problem for the the United Kingdom's National Health Service (NHS) are the long waiting lists for specialist mental healthcare. According to NHS data, in each month of 2023, there were between 370,000 and 470,000 individual new referrals into secondary mental healthcare services. Referrals must be triaged by clinicians, using clinical information contained in the patient's EHR to arrive at a decision about the most appropriate mental healthcare team to assess and potentially treat these patients.   The ability to efficiently recommend a relevant team by ingesting potentially voluminous clinical notes could h
    
[^69]: 分层深度学习用于装配任务中远程操纵操作意图估计

    Hierarchical Deep Learning for Intention Estimation of Teleoperation Manipulation in Assembly Tasks

    [https://arxiv.org/abs/2403.19770](https://arxiv.org/abs/2403.19770)

    该论文提出了一种分层深度学习框架，将多尺度层次信息整合到神经网络中，通过采用分层依赖损失来提高意图估计的准确性，在装配任务中实现了较优的意图识别和预测性能。

    

    在人机协作中，共享控制为远程操作机器人操纵提供了提升制造和装配工艺效率的机会。在执行用户意图上，机器人需要辅助。为此，需要鲁棒和即时的意图估计，依赖于行为观察。该框架提出了一种分层级别的意图估计技术，即低级动作和高级任务，通过在神经网络中整合多尺度层次信息。从技术上讲，我们采用分层依赖损失来提高整体准确率。此外，我们提出了一种多窗口方法，为输入数据分配适当的分层预测窗口。通过对各种输入的预测能力进行分析，证明了深度分层模型在预测准确度和提前意图识别方面的优越性。我们将该算法实现在一

    arXiv:2403.19770v1 Announce Type: cross  Abstract: In human-robot collaboration, shared control presents an opportunity to teleoperate robotic manipulation to improve the efficiency of manufacturing and assembly processes. Robots are expected to assist in executing the user's intentions. To this end, robust and prompt intention estimation is needed, relying on behavioral observations. The framework presents an intention estimation technique at hierarchical levels i.e., low-level actions and high-level tasks, by incorporating multi-scale hierarchical information in neural networks. Technically, we employ hierarchical dependency loss to boost overall accuracy. Furthermore, we propose a multi-window method that assigns proper hierarchical prediction windows of input data. An analysis of the predictive power with various inputs demonstrates the predominance of the deep hierarchical model in the sense of prediction accuracy and early intention identification. We implement the algorithm on a
    
[^70]: 利用反事实路径解释POMDP策略的对照性

    Leveraging Counterfactual Paths for Contrastive Explanations of POMDP Policies

    [https://arxiv.org/abs/2403.19760](https://arxiv.org/abs/2403.19760)

    本研究利用用户提供的反事实路径来生成对照性解释POMDP策略，并通过分析Search and Rescue（SAR）环境中的案例研究来讨论与之相关的挑战。

    

    随着人类越来越依赖自主系统，确保这些系统的透明性对于它们持续被采纳而言至关重要。可解释人工智能（XAI）旨在通过提供对代理行为的解释来减少困惑，培养人们对系统的信任。部分可观察马尔可夫决策过程（POMDPs）提供了一个能够推理转变和状态不确定性的灵活框架，同时也适合解释。这项工作研究了使用用户提供的反事实来生成POMDP策略的对照性解释。特征期望被用作对比这些策略的性能的手段。我们在搜索与救援（SAR）环境中演示了我们的方法。通过两个案例研究，我们分析和讨论了相关的挑战。

    arXiv:2403.19760v1 Announce Type: new  Abstract: As humans come to rely on autonomous systems more, ensuring the transparency of such systems is important to their continued adoption. Explainable Artificial Intelligence (XAI) aims to reduce confusion and foster trust in systems by providing explanations of agent behavior. Partially observable Markov decision processes (POMDPs) provide a flexible framework capable of reasoning over transition and state uncertainty, while also being amenable to explanation. This work investigates the use of user-provided counterfactuals to generate contrastive explanations of POMDP policies. Feature expectations are used as a means of contrasting the performance of these policies. We demonstrate our approach in a Search and Rescue (SAR) setting. We analyze and discuss the associated challenges through two case studies.
    
[^71]: 2024年的自然语言、人工智能和量子计算：QNLP中的研究要点和方向

    Natural Language, AI, and Quantum Computing in 2024: Research Ingredients and Directions in QNLP

    [https://arxiv.org/abs/2403.19758](https://arxiv.org/abs/2403.19758)

    该论文调查了2024年自然语言处理、人工智能发展中的量子计算应用，在量子自然语言处理中使用了诸如词嵌入、序列模型、注意力和语法分析等NLP技术，提出了一种新的量子设计来处理文本编码，并探讨了量子理论对“不确定性是什么？”和“智能是什么？”等核心问题的关键贡献。

    

    arXiv:2403.19758v1 公告类型：跨领域 抽象：语言处理是当前人工智能发展的关键，同时量子计算也开始应用。这引起了量子自然语言处理的极大兴趣，出现了几个早期提案和实验。本文调查了这一领域的最新进展，展示了NLP相关技术，包括词嵌入、序列模型、注意力和语法分析是如何应用于量子语言处理中的。我们提出了一种新的量子设计用于文本编码的基本任务（在内存中表示一个字符串），这在以前没有详细讨论过。除了推动新技术，量子理论还对“不确定性是什么？”和“智能是什么？”等具有挑战性的问题做出了关键贡献。随着这些问题在人工系统中变得愈发紧迫，本文还考虑了一些事实概念化的方式。

    arXiv:2403.19758v1 Announce Type: cross  Abstract: Language processing is at the heart of current developments in artificial intelligence, and quantum computers are becoming available at the same time. This has led to great interest in quantum natural language processing, and several early proposals and experiments. This paper surveys the state of this area, showing how NLP-related techniques including word embeddings, sequential models, attention, and grammatical parsing have been used in quantum language processing. We introduce a new quantum design for the basic task of text encoding (representing a string of characters in memory), which has not been addressed in detail before.   As well as motivating new technologies, quantum theory has made key contributions to the challenging questions of 'What is uncertainty?' and 'What is intelligence?' As these questions are taking on fresh urgency with artificial systems, the paper also considers some of the ways facts are conceptualized and 
    
[^72]: 物理信息神经网络用于卫星状态估计

    Physics-Informed Neural Networks for Satellite State Estimation

    [https://arxiv.org/abs/2403.19736](https://arxiv.org/abs/2403.19736)

    物理信息神经网络与深度神经网络相结合，为卫星中一些难以建模的异常加速度情况提供了强大的工具

    

    《物理信息神经网络用于卫星状态估计》论文翻译摘要：太空领域意识（SDA）群体通过将轨道状态拟合到太空监视网络（SSN）观测到的卫星来定期跟踪发射卫星。为了拟合这样的轨道，需要准确的作用于卫星的力模型。过去几十年，为卫星状态估计和传播开发了高质量的基于物理的模型。这些模型在估算和传播非机动卫星的轨道状态方面表现非常出色；然而，卫星可能遇到几类不太好建模的异常加速度，比如使用低推力电推进来修改轨道的卫星。对于这些类别的卫星，物理信息神经网络（PINNs）是一个宝贵的工具，因为它们将物理模型与深度神经网络（DNNs）结合起来，DNN是高度表现力和多功能的函数逼近器。

    arXiv:2403.19736v1 Announce Type: cross  Abstract: The Space Domain Awareness (SDA) community routinely tracks satellites in orbit by fitting an orbital state to observations made by the Space Surveillance Network (SSN). In order to fit such orbits, an accurate model of the forces that are acting on the satellite is required. Over the past several decades, high-quality, physics-based models have been developed for satellite state estimation and propagation. These models are exceedingly good at estimating and propagating orbital states for non-maneuvering satellites; however, there are several classes of anomalous accelerations that a satellite might experience which are not well-modeled, such as satellites that use low-thrust electric propulsion to modify their orbit. Physics-Informed Neural Networks (PINNs) are a valuable tool for these classes of satellites as they combine physics models with Deep Neural Networks (DNNs), which are highly expressive and versatile function approximator
    
[^73]: 用于法语口语理解的新语义任务MEDIA基准测试

    New Semantic Task for the French Spoken Language Understanding MEDIA Benchmark

    [https://arxiv.org/abs/2403.19727](https://arxiv.org/abs/2403.19727)

    提出了一个用于法语口语理解的新语义任务，通过在MEDIA基准测试数据集上标注意图来扩展其用途和使用情况。

    

    意图分类和槽填充是口语理解（SLU）的基本任务。在大多数SLU系统中，这些任务由独立模块实现。近十五年来，提出了同时实现这两个任务并利用它们相互增强的模型。一个使用联合模型的多语言模块被设想用于为一个欧洲项目HumanE-AI-Net创建一个旅游对话系统。建议结合多个数据集，包括MEDIA数据集，来训练这个联合模型。MEDIA SLU数据集是由ELRA从2005年开始分发的法语数据集，主要被法国研究界使用，自2020年起用于学术研究免费使用。不幸的是，它只在槽上标注而不标注意图。已构建了一个带有意图标注的增强版本的MEDIA，以扩展其用途到更多任务和用例。本文介绍了用于获得此增强版本的半自动方法。

    arXiv:2403.19727v1 Announce Type: cross  Abstract: Intent classification and slot-filling are essential tasks of Spoken Language Understanding (SLU). In most SLUsystems, those tasks are realized by independent modules. For about fifteen years, models achieving both of themjointly and exploiting their mutual enhancement have been proposed. A multilingual module using a joint modelwas envisioned to create a touristic dialogue system for a European project, HumanE-AI-Net. A combination ofmultiple datasets, including the MEDIA dataset, was suggested for training this joint model. The MEDIA SLU datasetis a French dataset distributed since 2005 by ELRA, mainly used by the French research community and free foracademic research since 2020. Unfortunately, it is annotated only in slots but not intents. An enhanced version ofMEDIA annotated with intents has been built to extend its use to more tasks and use cases. This paper presents thesemi-automatic methodology used to obtain this enhanced ver
    
[^74]: 法语临床命名实体识别的基准评估

    A Benchmark Evaluation of Clinical Named Entity Recognition in French

    [https://arxiv.org/abs/2403.19726](https://arxiv.org/abs/2403.19726)

    该论文评估了生物医学法语掩码语言模型在临床命名实体识别任务上的性能，对几种模型进行了比较。

    

    背景：基于Transformer的语言模型在许多自然语言处理（NLP）任务中表现出了强大的性能。掩码语言模型（MLMs）吸引了持续的关注，因为它们可以通过在特定语料库上进行训练或微调来适应不同的语言和子域，同时保持比现代大语言模型（LLMs）更轻。最近，针对法语生物医学领域发布了几个MLMs，并且实验表明它们优于标准法语模型。然而，目前没有提供对同一语料库上所有模型进行比较的系统评估。目标：本文提出了一个评估生物医学法语掩码语言模型在临床命名实体识别任务上的性能。方法和材料：我们评估了生物医学模型CamemBERT-bio和DrBERT，并将它们与标准法语模型CamemBERT、FlauBERT和FrALBERT以及多语言mBERT进行比较。

    arXiv:2403.19726v1 Announce Type: cross  Abstract: Background: Transformer-based language models have shown strong performance on many Natural LanguageProcessing (NLP) tasks. Masked Language Models (MLMs) attract sustained interest because they can be adaptedto different languages and sub-domains through training or fine-tuning on specific corpora while remaining lighterthan modern Large Language Models (LLMs). Recently, several MLMs have been released for the biomedicaldomain in French, and experiments suggest that they outperform standard French counterparts. However, nosystematic evaluation comparing all models on the same corpora is available. Objective: This paper presentsan evaluation of masked language models for biomedical French on the task of clinical named entity recognition.Material and methods: We evaluate biomedical models CamemBERT-bio and DrBERT and compare them tostandard French models CamemBERT, FlauBERT and FrALBERT as well as multilingual mBERT using three publicall
    
[^75]: MUGC：机器生成与用户生成内容的检测

    MUGC: Machine Generated versus User Generated Content Detection

    [https://arxiv.org/abs/2403.19725](https://arxiv.org/abs/2403.19725)

    本研究对八种传统机器学习算法在识别机器生成和人类生成数据方面进行了比较评估，发现这些方法在识别机器生成数据方面具有较高的准确性。另外，机器生成的文本往往更短、词汇变化更少，而人类生成内容则使用了一些特定领域相关关键词被当前的大型语言模型忽略了。

    

    随着先进的现代系统如深度神经网络（DNNs）和生成式人工智能不断增强其产生令人信服和逼真内容的能力，区分用户生成与机器生成内容的需求变得越来越明显。在这项研究中，我们对八种传统机器学习算法进行了比较评估，以区分跨三个不同数据集（诗歌、摘要和论文）中的机器生成和人类生成数据。我们的结果表明，传统方法在识别机器生成数据方面表现出很高的准确性，反映了像RoBERT这样的热门预训练模型的有效性。我们注意到，与人类生成内容相比，机器生成的文本往往更短，词汇变化更少。虽然人类常用的特定领域相关关键词被当前的大型语言模型（LLMs）忽略了。

    arXiv:2403.19725v1 Announce Type: cross  Abstract: As advanced modern systems like deep neural networks (DNNs) and generative AI continue to enhance their capabilities in producing convincing and realistic content, the need to distinguish between user-generated and machine generated content is becoming increasingly evident. In this research, we undertake a comparative evaluation of eight traditional machine-learning algorithms to distinguish between machine-generated and human-generated data across three diverse datasets: Poems, Abstracts, and Essays. Our results indicate that traditional methods demonstrate a high level of accuracy in identifying machine-generated data, reflecting the documented effectiveness of popular pre-trained models like RoBERT. We note that machine-generated texts tend to be shorter and exhibit less word variety compared to human-generated content. While specific domain-related keywords commonly utilized by humans, albeit disregarded by current LLMs (Large Lang
    
[^76]: HGT：利用异质图增强的大型语言模型进行少样本复杂表格理解

    HGT: Leveraging Heterogeneous Graph-enhanced Large Language Models for Few-shot Complex Table Understanding

    [https://arxiv.org/abs/2403.19723](https://arxiv.org/abs/2403.19723)

    HGT框架结合了异质图增强的大型语言模型，通过软提示和多粒度自监督HG预训练目标，实现了少样本复杂表格理解任务的最新成果。

    

    表格理解 (TU) 取得了显著进展，但面临手动标记表格的稀缺性和复杂表格结构的挑战。为解决这些问题，我们提出了 HGT 框架，其中包含一个异质图 (HG) 增强的大型语言模型 (LLM)，用于解决少样本 TU 任务。它通过软提示和指导转换将表格语义与LLM的参数化知识对齐，并通过涉及三种新的多粒度自监督HG预训练目标的多任务预训练方案处理复杂表格。我们在几个基准测试上通过实证方法展示了HGT的有效性，表明它在少样本复杂TU方面的表现优于SOTA。

    arXiv:2403.19723v1 Announce Type: cross  Abstract: Table understanding (TU) has achieved promising advancements, but it faces the challenges of the scarcity of manually labeled tables and the presence of complex table structures.To address these challenges, we propose HGT, a framework with a heterogeneous graph (HG)-enhanced large language model (LLM) to tackle few-shot TU tasks.It leverages the LLM by aligning the table semantics with the LLM's parametric knowledge through soft prompts and instruction turning and deals with complex tables by a multi-task pre-training scheme involving three novel multi-granularity self-supervised HG pre-training objectives.We empirically demonstrate the effectiveness of HGT, showing that it outperforms the SOTA for few-shot complex TU on several benchmarks.
    
[^77]: 利用大数据进行高效稳健预测分析的计算和内存优化

    Computationally and Memory-Efficient Robust Predictive Analytics Using Big Data

    [https://arxiv.org/abs/2403.19721](https://arxiv.org/abs/2403.19721)

    本研究通过利用稳健主成分分析(RPCA)进行噪声降低和异常值排除，以及优化传感器放置(OSP)进行有效数据压缩和存储，提出了一种同时优化计算和内存效率的大数据预测分析方法。

    

    在当前数据密集的时代，大数据已经成为人工智能（AI）的重要资产，为开发基于数据的模型并深入探索各种未知领域奠定了基础。本研究探讨了使用大数据进行数据不确定性、存储限制和预测数据驱动建模的挑战。我们利用稳健主成分分析（RPCA）有效降噪和去除离群值，以及优化传感器放置（OSP）实现高效数据压缩和存储。所提出的OSP技术能够实现数据压缩，同时减少存储需求，且信息损失不大。虽然RPCA为高维数据管理提供了比传统主成分分析（PCA）更好的选择，但本研究的范围则扩展了其应用范围，专注于适用于实时海量数据集的稳健数据驱动建模。

    arXiv:2403.19721v1 Announce Type: cross  Abstract: In the current data-intensive era, big data has become a significant asset for Artificial Intelligence (AI), serving as a foundation for developing data-driven models and providing insight into various unknown fields. This study navigates through the challenges of data uncertainties, storage limitations, and predictive data-driven modeling using big data. We utilize Robust Principal Component Analysis (RPCA) for effective noise reduction and outlier elimination, and Optimal Sensor Placement (OSP) for efficient data compression and storage. The proposed OSP technique enables data compression without substantial information loss while simultaneously reducing storage needs. While RPCA offers an enhanced alternative to traditional Principal Component Analysis (PCA) for high-dimensional data management, the scope of this work extends its utilization, focusing on robust, data-driven modeling applicable to huge data sets in real-time. For tha
    
[^78]: 文本到图像生成的能力感知提示重组学习

    Capability-aware Prompt Reformulation Learning for Text-to-Image Generation

    [https://arxiv.org/abs/2403.19716](https://arxiv.org/abs/2403.19716)

    通过利用来自交互日志的用户重组数据来开发自动提示重组模型，CAPR框架创新性地将用户能力整合到提示重组过程中。

    

    文本到图像生成系统已经成为艺术创作领域中的革命性工具，为将文本提示转化为视觉艺术提供了前所未有的便利。然而，这些系统的效力与用户提供的提示质量密切相关，这常常对不熟悉提示制作的用户构成挑战。本文通过利用来自交互日志的用户重组数据来开发自动提示重组模型来解决这一挑战。我们对这些日志的深入分析表明，用户提示的重组在很大程度上取决于个体用户的能力，导致重组对的质量存在显著差异。为有效地利用这些数据进行训练，我们引入了能力感知提示重组（CAPR）框架。CAPR创新性地通过两个关键组件将用户能力整合到重组过程中：有条件的提示重组

    arXiv:2403.19716v1 Announce Type: cross  Abstract: Text-to-image generation systems have emerged as revolutionary tools in the realm of artistic creation, offering unprecedented ease in transforming textual prompts into visual art. However, the efficacy of these systems is intricately linked to the quality of user-provided prompts, which often poses a challenge to users unfamiliar with prompt crafting. This paper addresses this challenge by leveraging user reformulation data from interaction logs to develop an automatic prompt reformulation model. Our in-depth analysis of these logs reveals that user prompt reformulation is heavily dependent on the individual user's capability, resulting in significant variance in the quality of reformulation pairs. To effectively use this data for training, we introduce the Capability-aware Prompt Reformulation (CAPR) framework. CAPR innovatively integrates user capability into the reformulation process through two key components: the Conditional Refo
    
[^79]: STRUM-LLM: 属性化和结构化对比摘要

    STRUM-LLM: Attributed and Structured Contrastive Summarization

    [https://arxiv.org/abs/2403.19710](https://arxiv.org/abs/2403.19710)

    STRUM-LLM提出了一种生成属性化、结构化和有帮助的对比摘要的方法，识别并突出两个选项之间的关键差异，不需要人工标记的数据或固定属性列表，具有高吞吐量和小体积。

    

    用户经常在两个选项（A vs B）之间做决策时感到困难，因为这通常需要在多个网页上进行耗时的研究。我们提出了STRUM-LLM，通过生成带属性、结构化和有帮助的对比摘要，突出两个选项之间的关键差异，来解决这一挑战。STRUM-LLM识别了有帮助的对比：两个选项在哪些特定属性上有显著差异，以及最有可能影响用户决策。我们的技术是与领域无关的，并不需要任何人工标记的数据或固定属性列表作为监督。STRUM-LLM将所有提取的内容属性化，以及文本证据，且不限制其处理的输入来源的长度。STRUM-LLM Distilled的吞吐量比具有相似性能的模型高100倍，同时体积小10倍。在本文中，我们进行了广泛的评估。

    arXiv:2403.19710v1 Announce Type: cross  Abstract: Users often struggle with decision-making between two options (A vs B), as it usually requires time-consuming research across multiple web pages. We propose STRUM-LLM that addresses this challenge by generating attributed, structured, and helpful contrastive summaries that highlight key differences between the two options. STRUM-LLM identifies helpful contrast: the specific attributes along which the two options differ significantly and which are most likely to influence the user's decision. Our technique is domain-agnostic, and does not require any human-labeled data or fixed attribute list as supervision. STRUM-LLM attributes all extractions back to the input sources along with textual evidence, and it does not have a limit on the length of input sources that it can process. STRUM-LLM Distilled has 100x more throughput than the models with comparable performance while being 10x smaller. In this paper, we provide extensive evaluations
    
[^80]: 高效多任务调整大型语音模型的分层递归适配器

    Hierarchical Recurrent Adapters for Efficient Multi-Task Adaptation of Large Speech Models

    [https://arxiv.org/abs/2403.19709](https://arxiv.org/abs/2403.19709)

    提出了一种分层递归适配器模块，能够在大规模多任务适配场景下降低每个任务的参数开销，同时保持在下游任务中的性能表现，优于先前的适配器方法和完整模型微调基线

    

    参数高效的适配方法已经成为训练大型预训练模型用于下游任务的关键机制。我们引入了一种适配器模块，在大规模多任务适配场景下具有更好的效率。我们的适配器在适配器参数分配方面是分层的。适配器由一个共享的控制网络和多个任务级适配器头组成，以减少每个任务的参数开销，而不会影响下游任务的性能。适配器还是递归的，因此整个适配器参数在预训练模型的不同层之间被重用。我们的分层递归适配器（HRA）在单任务和多任务适配设置中都优于先前的基于适配器的方法以及完整模型微调基线。

    arXiv:2403.19709v1 Announce Type: cross  Abstract: Parameter efficient adaptation methods have become a key mechanism to train large pre-trained models for downstream tasks. However, their per-task parameter overhead is considered still high when the number of downstream tasks to adapt for is large. We introduce an adapter module that has a better efficiency in large scale multi-task adaptation scenario. Our adapter is hierarchical in terms of how the adapter parameters are allocated. The adapter consists of a single shared controller network and multiple task-level adapter heads to reduce the per-task parameter overhead without performance regression on downstream tasks. The adapter is also recurrent so the entire adapter parameters are reused across different layers of the pre-trained model. Our Hierarchical Recurrent Adapter (HRA) outperforms the previous adapter-based approaches as well as full model fine-tuning baseline in both single and multi-task adaptation settings when evalua
    
[^81]: 分析语言和视觉在从有限数据中学习中的作用

    Analyzing the Roles of Language and Vision in Learning from Limited Data

    [https://arxiv.org/abs/2403.19669](https://arxiv.org/abs/2403.19669)

    研究人工智能中的复杂视觉-语言模型，发现即使缺乏视觉输入，利用所有组件的语言模型能够恢复大部分VLM的性能，表明语言通过提供对先前知识和推理的访问来对学习新任务有贡献

    

    arXiv:2403.19669v1 公告类型：交叉摘要：语言是否有助于理解视觉世界？实际观察世界需要看到实际情况，而不是用文字描述吗？关于智能本质的这些基本问题很难回答，因为我们只有一个智能系统的例子——人类——以及有限的独立语言或视觉的案例。然而，人工智能研究人员开发出复杂的视觉-语言模型（VLMs）为我们提供了新的机会，探索语言和视觉对于学习世界的贡献。我们从这些模型的认知架构中切除组件，以确定它们对从有限数据中学习新任务的贡献。我们发现，利用所有组件的语言模型恢复了大部分VLM的性能，尽管它缺乏视觉输入，而语言似乎可以通过提供对先前知识和推理的访问来实现这一点。

    arXiv:2403.19669v1 Announce Type: cross  Abstract: Does language help make sense of the visual world? How important is it to actually see the world rather than having it described with words? These basic questions about the nature of intelligence have been difficult to answer because we only had one example of an intelligent system -- humans -- and limited access to cases that isolated language or vision. However, the development of sophisticated Vision-Language Models (VLMs) by artificial intelligence researchers offers us new opportunities to explore the contributions that language and vision make to learning about the world. We ablate components from the cognitive architecture of these models to identify their contributions to learning new tasks from limited data. We find that a language model leveraging all components recovers a majority of a VLM's performance, despite its lack of visual input, and that language seems to allow this by providing access to prior knowledge and reasoni
    
[^82]: 通过死因调查笔记中的注释不一致性检测揭示自杀原因的误归因

    Uncovering Misattributed Suicide Causes through Annotation Inconsistency Detection in Death Investigation Notes

    [https://arxiv.org/abs/2403.19432](https://arxiv.org/abs/2403.19432)

    通过自然语言处理方法检测并纠正国家暴力死亡报告系统中的注释不一致性，提高了自杀危机分类器的性能。

    

    数据准确性对科学研究和政策制定至关重要。国家暴力死亡报告系统（NVDRS）数据被广泛用于发现死亡的模式和原因。最近的研究表明NVDRS内存在注释不一致性，并可能影响错误的自杀原因归因。我们提出了一种经验性的自然语言处理（NLP）方法来检测注释不一致性，并采用类似交叉验证的范式来识别有问题的实例。我们分析了2003年至2020年间从NVDRS中的267,804起自杀死亡案例。结果显示，将目标州的数据纳入训练自杀危机分类器，使得在目标州测试集上的F-1分数增加了5.4％，在其他州测试集上降低了1.1％。总之，我们展示了NVDRS死因调查笔记中的注释不一致性，并确定了问题的实例。

    arXiv:2403.19432v1 Announce Type: cross  Abstract: Data accuracy is essential for scientific research and policy development. The National Violent Death Reporting System (NVDRS) data is widely used for discovering the patterns and causes of death. Recent studies suggested the annotation inconsistencies within the NVDRS and the potential impact on erroneous suicide-cause attributions. We present an empirical Natural Language Processing (NLP) approach to detect annotation inconsistencies and adopt a cross-validation-like paradigm to identify problematic instances. We analyzed 267,804 suicide death incidents between 2003 and 2020 from the NVDRS. Our results showed that incorporating the target state's data into training the suicide-crisis classifier brought an increase of 5.4% to the F-1 score on the target state's test set and a decrease of 1.1% on other states' test set. To conclude, we demonstrated the annotation inconsistencies in NVDRS's death investigation notes, identified problema
    
[^83]: STaR-GATE: 教授语言模型询问澄清问题

    STaR-GATE: Teaching Language Models to Ask Clarifying Questions

    [https://arxiv.org/abs/2403.19154](https://arxiv.org/abs/2403.19154)

    通过奖励语言模型生成有用问题来自我改进的方法，提问者通过询问角色扮演者来引出偏好，从而迭代微调以增加任务高质量响应的概率。

    

    当提示语言模型完成任务时，用户通常会遗漏重要的细节。虽然提问可以解决这种歧义，但模型往往很难提出好问题。我们探讨了语言模型通过奖励模型生成有用问题来自我改进的能力，这是一种简单方法，我们称之为STaR-GATE。我们生成了一个包含25,500个独特人物-任务提示的合成数据集，以模拟预训练语言模型--提问者--与一个其偏好未知的角色扮演者之间的对话。通过提问，提问者从角色扮演者那里引出偏好。提问者在那些增加高质量响应概率的问题上进行迭代微调，这些问题是由具有对角色扮演者访问权限的预言者生成的。

    arXiv:2403.19154v1 Announce Type: cross  Abstract: When prompting language models to complete a task, users often leave important aspects unsaid. While asking questions could resolve this ambiguity \citep[GATE;][]{li2023eliciting}, models often struggle to ask good questions. We explore a language model's ability to self-improve \citep[STaR;][]{zelikman2022star} by rewarding the model for generating useful questions -- a simple method we dub STaR-GATE. We generate a synthetic dataset of 25,500 unique persona-task prompts to simulate conversations between a pretrained language model -- the \texttt{Questioner} -- and a \texttt{Roleplayer} whose preferences are unknown to the \texttt{Questioner}. By asking questions, the \texttt{Questioner} elicits preferences from the \texttt{Roleplayer}. The \texttt{Questioner} is iteratively finetuned on questions that increase the probability of high-quality responses to the task, which are generated by an \texttt{Oracle} with access to the \texttt{Ro
    
[^84]: 人类中心施工机器人：基于强化学习的助手机器人为木工劳动者提供环境上下文协助

    Towards Human-Centered Construction Robotics: An RL-Driven Companion Robot For Contextually Assisting Carpentry Workers

    [https://arxiv.org/abs/2403.19060](https://arxiv.org/abs/2403.19060)

    本文提出了一种人类中心的建筑机器人方法，通过强化学习驱动的助手机器人为木工劳动者提供环境上下文协助，推进了机器人在建筑中的应用。

    

    在这个充满活力的建筑行业中，传统的机器人集成主要集中在自动化特定任务，通常忽略了建筑工作流程中人类因素的复杂性和变化性。本文提出了一种以人为本的方法，设计了一个“工作伴侣漫游器”，旨在协助建筑工人完成其现有实践，旨在增强安全性和工作流程的流畅性，同时尊重建筑劳动的技术性质。我们对在木工模板工程中部署机器人系统进行了深入研究，展示了一个原型，通过环境相关的强化学习（RL）驱动模块化框架，重点强调了在动态环境中的机动性、安全性和舒适的工人-机器人协作。我们的研究推进了机器人在建筑中的应用，倡导协作模型，其中自适应机器人支持而不是取代人类，强调了交互式的潜力。

    arXiv:2403.19060v1 Announce Type: cross  Abstract: In the dynamic construction industry, traditional robotic integration has primarily focused on automating specific tasks, often overlooking the complexity and variability of human aspects in construction workflows. This paper introduces a human-centered approach with a ``work companion rover" designed to assist construction workers within their existing practices, aiming to enhance safety and workflow fluency while respecting construction labor's skilled nature. We conduct an in-depth study on deploying a robotic system in carpentry formwork, showcasing a prototype that emphasizes mobility, safety, and comfortable worker-robot collaboration in dynamic environments through a contextual Reinforcement Learning (RL)-driven modular framework. Our research advances robotic applications in construction, advocating for collaborative models where adaptive robots support rather than replace humans, underscoring the potential for an interactive a
    
[^85]: Gamba：将高斯飘点与曼巴相结合，用于单视图3D重建

    Gamba: Marry Gaussian Splatting with Mamba for single view 3D reconstruction

    [https://arxiv.org/abs/2403.18795](https://arxiv.org/abs/2403.18795)

    提出了Gamba，一种单视图3D重建模型，创新地结合了大量的3D高斯点进行高效重建，并引入了基于曼巴的顺序网络，促进依赖上下文的推理，实现了线性可扩展性。

    

    我们致力于解决从单个图像高效重建3D资产的挑战，随着对自动化3D内容创建流水线的需求不断增长。我们引入了Gamba，这是一个端到端的从单视图图像进行摊余化3D重建的模型，强调了两个主要见解：(1) 3D表示：利用大量3D高斯来进行高效的3D高斯飘点过程；(2) 主干设计：引入基于曼巴的顺序网络，促进依赖上下文的推理，并具有与序列（标记）长度的线性可扩展性，适应大量高斯点。Gamba在数据预处理、正则化等方面融入了重大进展。

    arXiv:2403.18795v1 Announce Type: cross  Abstract: We tackle the challenge of efficiently reconstructing a 3D asset from a single image with growing demands for automated 3D content creation pipelines. Previous methods primarily rely on Score Distillation Sampling (SDS) and Neural Radiance Fields (NeRF). Despite their significant success, these approaches encounter practical limitations due to lengthy optimization and considerable memory usage. In this report, we introduce Gamba, an end-to-end amortized 3D reconstruction model from single-view images, emphasizing two main insights: (1) 3D representation: leveraging a large number of 3D Gaussians for an efficient 3D Gaussian splatting process; (2) Backbone design: introducing a Mamba-based sequential network that facilitates context-dependent reasoning and linear scalability with the sequence (token) length, accommodating a substantial number of Gaussians. Gamba incorporates significant advancements in data preprocessing, regularization
    
[^86]: 论排列不变神经网络

    On permutation-invariant neural networks

    [https://arxiv.org/abs/2403.17410](https://arxiv.org/abs/2403.17410)

    神经网络如Deep Sets和Transformers的出现显著推动了基于集合的数据处理的进展

    

    传统机器学习算法通常在假设输入数据遵循基于向量的格式的前提下设计，着重于基于向量的范式。然而，随着需求涉及基于集合的任务的增长，研究界对解决这些挑战的兴趣发生了范式转变。近年来，Deep Sets和Transformers等神经网络架构的出现在处理基于集合的数据方面取得了重大进展。这些架构专门设计为自然容纳集合作为输入，从而更有效地表示和处理集合结构。因此，近年来出现了大量致力于探索和利用这些架构能力的研究努力，以逼近集合函数的各种任务。这项综合调查旨在概述th

    arXiv:2403.17410v1 Announce Type: cross  Abstract: Conventional machine learning algorithms have traditionally been designed under the assumption that input data follows a vector-based format, with an emphasis on vector-centric paradigms. However, as the demand for tasks involving set-based inputs has grown, there has been a paradigm shift in the research community towards addressing these challenges. In recent years, the emergence of neural network architectures such as Deep Sets and Transformers has presented a significant advancement in the treatment of set-based data. These architectures are specifically engineered to naturally accommodate sets as input, enabling more effective representation and processing of set structures. Consequently, there has been a surge of research endeavors dedicated to exploring and harnessing the capabilities of these architectures for various tasks involving the approximation of set functions. This comprehensive survey aims to provide an overview of th
    
[^87]: DASA: 延迟自适应多智能体随机逼近

    DASA: Delay-Adaptive Multi-Agent Stochastic Approximation

    [https://arxiv.org/abs/2403.17247](https://arxiv.org/abs/2403.17247)

    DASA算法是第一个收敛速度仅依赖于混合时间和平均延迟的算法，同时在马尔科夫采样下实现N倍的收敛加速。

    

    我们考虑一种设置，其中$N$个智能体旨在通过并行操作并与中央服务器通信来加速一个常见的随机逼近（SA）问题。我们假定上行传输到服务器的传输受到异步和潜在无界时变延迟的影响。为了减轻延迟和落后者的影响，同时又能获得分布式计算的好处，我们提出了一种名为DASA的延迟自适应多智能体随机逼近算法。我们对DASA进行了有限时间分析，假设智能体的随机观测过程是独立马尔科夫链。与现有结果相比，DASA是第一个其收敛速度仅取决于混合时间$tmix$和平均延迟$\tau_{avg}$，同时在马尔科夫采样下实现N倍的收敛加速的算法。我们的工作对于各种SA应用是相关的。

    arXiv:2403.17247v1 Announce Type: new  Abstract: We consider a setting in which $N$ agents aim to speedup a common Stochastic Approximation (SA) problem by acting in parallel and communicating with a central server. We assume that the up-link transmissions to the server are subject to asynchronous and potentially unbounded time-varying delays. To mitigate the effect of delays and stragglers while reaping the benefits of distributed computation, we propose \texttt{DASA}, a Delay-Adaptive algorithm for multi-agent Stochastic Approximation. We provide a finite-time analysis of \texttt{DASA} assuming that the agents' stochastic observation processes are independent Markov chains. Significantly advancing existing results, \texttt{DASA} is the first algorithm whose convergence rate depends only on the mixing time $\tmix$ and on the average delay $\tau_{avg}$ while jointly achieving an $N$-fold convergence speedup under Markovian sampling. Our work is relevant for various SA applications, inc
    
[^88]: 学习使用视觉-语言模型指导人类决策者

    Learning To Guide Human Decision Makers With Vision-Language Models

    [https://arxiv.org/abs/2403.16501](https://arxiv.org/abs/2403.16501)

    提出了“学习指导”（LTG）框架，旨在解决专家可能过度依赖机器决策和面临无助于模型放弃的决策的问题。

    

    越来越多的人对开发人工智能以协助人类进行高风险任务中的决策表现出兴趣，比如医学诊断，旨在提高决策质量和减少认知负担。主流方法是将专家与机器学习模型合作，将更安全的决策下放，让前者专注于需要他们关注的情况。然而，在高风险场景中，这种“责任分工”设置是不够的。

    arXiv:2403.16501v1 Announce Type: new  Abstract: There is increasing interest in developing AIs for assisting human decision making in \textit{high-stakes} tasks, such as medical diagnosis, for the purpose of improving decision quality and reducing cognitive strain.   %   Mainstream approaches team up an expert with a machine learning model to which safer decisions are offloaded, thus letting the former focus on cases that demand their attention.   %   This \textit{separation of responsibilities} setup, however, is inadequate for high-stakes scenarios. On the one hand, the expert may end up over-relying on the machine's decisions due to \textit{anchoring bias}, thus losing the human oversight that is increasingly being required by regulatory agencies to ensure trustworthy AI. On the other hand, the expert is left entirely unassisted on the (typically hardest) decisions on which the model abstained.   %   As a remedy, we introduce \textit{learning to guide} (LTG), an alternative framewo
    
[^89]: FedAC：一种用于异构数据的自适应分簇联邦学习框架

    FedAC: A Adaptive Clustered Federated Learning Framework for Heterogeneous Data

    [https://arxiv.org/abs/2403.16460](https://arxiv.org/abs/2403.16460)

    FedAC框架通过解耦神经网络，使用不同聚合方法为每个子模块提供全局知识，引入经济高效的在线模型相似度度量，及集群数量微调模块，显著提高了性能。

    

    本文提出了一种自适应的分簇联邦学习框架FedAC，该框架通过解耦神经网络并利用不同的聚合方法为每个子模块有效地将全局知识整合到簇内学习中，显著提高了性能；引入了一种基于降维的经济高效的在线模型相似度度量；并且结合了一个用于改进复杂性的集群数量微调模块，从而提高了适应性和可伸缩性。

    arXiv:2403.16460v1 Announce Type: cross  Abstract: Clustered federated learning (CFL) is proposed to mitigate the performance deterioration stemming from data heterogeneity in federated learning (FL) by grouping similar clients for cluster-wise model training. However, current CFL methods struggle due to inadequate integration of global and intra-cluster knowledge and the absence of an efficient online model similarity metric, while treating the cluster count as a fixed hyperparameter limits flexibility and robustness. In this paper, we propose an adaptive CFL framework, named FedAC, which (1) efficiently integrates global knowledge into intra-cluster learning by decoupling neural networks and utilizing distinct aggregation methods for each submodule, significantly enhancing performance; (2) includes a costeffective online model similarity metric based on dimensionality reduction; (3) incorporates a cluster number fine-tuning module for improved adaptability and scalability in complex,
    
[^90]: MedPromptX：基于现实的多模态提示用于胸部X线诊断

    MedPromptX: Grounded Multimodal Prompting for Chest X-ray Diagnosis

    [https://arxiv.org/abs/2403.15585](https://arxiv.org/abs/2403.15585)

    MedPromptX是第一个将多模态大型语言模型、少样本提示和视觉基础相结合，用于胸部X线诊断的模型，通过补充缺失的EHR信息，有效解决了幻觉问题，但选择最佳少样本示例和高质量候选者仍有待解决。

    

    胸部X线图像通常用于预测急性和慢性心肺疾病，但是将它们与结构化临床数据整合的努力面临着因电子健康记录（EHR）不完整而带来的挑战。本文引入了MedPromptX，这是第一个将多模态大型语言模型（MLLMs）、少样本提示（FP）和视觉基础（VG）相结合，将图像与EHR数据用于胸部X线诊断的模型。预训练的MLLM被用来补充缺失的EHR信息，提供对患者病史的全面理解。此外，少样本提示减少了对MLLM的大量训练的必要性，同时有效解决了幻觉问题。然而，确定最佳少样本示例的过程和选择高质量候选者可能过于繁琐，但它对模型性能产生着深远影响。因此，我们提出了一种新技术来动态地...

    arXiv:2403.15585v1 Announce Type: cross  Abstract: Chest X-ray images are commonly used for predicting acute and chronic cardiopulmonary conditions, but efforts to integrate them with structured clinical data face challenges due to incomplete electronic health records (EHR). This paper introduces \textbf{MedPromptX}, the first model to integrate multimodal large language models (MLLMs), few-shot prompting (FP) and visual grounding (VG) to combine imagery with EHR data for chest X-ray diagnosis. A pre-trained MLLM is utilized to complement the missing EHR information, providing a comprehensive understanding of patients' medical history. Additionally, FP reduces the necessity for extensive training of MLLMs while effectively tackling the issue of hallucination. Nevertheless, the process of determining the optimal number of few-shot examples and selecting high-quality candidates can be burdensome, yet it profoundly influences model performance. Hence, we propose a new technique that dynam
    
[^91]: WoLF: 用于胸部X线图理解的大型语言模型框架

    WoLF: Large Language Model Framework for CXR Understanding

    [https://arxiv.org/abs/2403.15456](https://arxiv.org/abs/2403.15456)

    WoLF框架提出了对于CXR的全面理解的改进，包括使用额外的健康相关数据、重构报告以提供更有组织的信息、以及改进生成答案的细致评估。

    

    通过现代视觉语言模型(VLMs)取得了对胸部X线图(CXR)理解方面的显着方法进展，展示了令人印象深刻的视觉问答(VQA)和CXR报告生成能力。然而，现有的CXR理解框架仍存在几个程序上的缺陷。(1)以往的方法仅使用CXR报告，这对于全面的视觉问答(VQA)来说是不够的，特别是当需要额外的健康相关数据如用药历史和先前的诊断时。(2)以往的方法使用未经处理的CXR报告，这些报告往往结构随意。虽然现代语言模型可以理解各种文本格式，但为了提供更清晰、有组织的基于解剖学的信息，重构报告可能会增强它们的实用性。(3)目前用于CXR-VQA的评估方法主要强调语言正确性，缺乏对生成答案的微妙评估能力。

    arXiv:2403.15456v1 Announce Type: new  Abstract: Significant methodological strides have been made toward Chest X-ray (CXR) understanding via modern vision-language models (VLMs), demonstrating impressive Visual Question Answering (VQA) and CXR report generation abilities. However, existing CXR understanding frameworks still possess several procedural caveats. (1) Previous methods solely use CXR reports, which are insufficient for comprehensive Visual Question Answering (VQA), especially when additional health-related data like medication history and prior diagnoses are needed. (2) Previous methods use raw CXR reports, which are often arbitrarily structured. While modern language models can understand various text formats, restructuring reports for clearer, organized anatomy-based information could enhance their usefulness. (3) Current evaluation methods for CXR-VQA primarily emphasize linguistic correctness, lacking the capability to offer nuanced assessments of the generated answers.
    
[^92]: PET-SQL：一个带有交叉一致性的增强提示的两阶段文本到SQL框架

    PET-SQL: A Prompt-enhanced Two-stage Text-to-SQL Framework with Cross-consistency

    [https://arxiv.org/abs/2403.09732](https://arxiv.org/abs/2403.09732)

    提出了一个两阶段框架，通过引入参考增强表示和少样本演示，解决了在处理冗长的数据库信息和复杂用户意图时的挑战。

    

    最近文本到SQL（Text2SQL）领域的进展强调刺激大型语言模型（LLM）进行上下文学习，取得了显著成果。然而，他们在处理冗长的数据库信息和复杂的用户意图时面临挑战。本文提出了一个两阶段框架，以增强当前基于LLM的自然语言到SQL系统的性能。我们首先引入了一种新颖的提示表示，称为参考增强表示，其中包括模式信息和从表格随机抽样的单元格值，以指导LLM生成SQL查询。然后，在第一阶段，我们检索问题-SQL对作为少量演示，促使LLM生成初步SQL（PreSQL）。之后，解析PreSQL中提到的实体进行模式链接，可以显著压缩有用信息。在第二阶段，利用链接的模式，我们简化了

    arXiv:2403.09732v1 Announce Type: cross  Abstract: Recent advancements in Text-to-SQL (Text2SQL) emphasize stimulating the large language models (LLM) on in-context learning, achieving significant results. Nevertheless, they face challenges when dealing with verbose database information and complex user intentions. This paper presents a two-stage framework to enhance the performance of current LLM-based natural language to SQL systems. We first introduce a novel prompt representation, called reference-enhanced representation, which includes schema information and randomly sampled cell values from tables to instruct LLMs in generating SQL queries. Then, in the first stage, question-SQL pairs are retrieved as few-shot demonstrations, prompting the LLM to generate a preliminary SQL (PreSQL). After that, the mentioned entities in PreSQL are parsed to conduct schema linking, which can significantly compact the useful information. In the second stage, with the linked schema, we simplify the 
    
[^93]: STREAM：用于视频生成模型的时空评估和分析度量

    STREAM: Spatio-TempoRal Evaluation and Analysis Metric for Video Generative Models

    [https://arxiv.org/abs/2403.09669](https://arxiv.org/abs/2403.09669)

    提出了STREAM，一种新的视频评估度量方法，弥补了当前视频生成模型评估中对于时空特性的不足

    

    图像生成模型在生成逼真多样的图像方面取得了显著进展，得益于各种评估度量的全面指导。然而，当前的视频生成模型在生成短视频片段时仍然存在困难，缺乏提供改进见解的工具。目前的视频评估度量方法是通过将嵌入视频嵌入网络来简单调整图像度量方法而得到的，这可能低估了视频的独特特性。我们的分析表明，广泛使用的Frechet Video Distance (FVD) 在空间方面的重视程度要大于视频的时间自然性，且受到所使用的嵌入网络输入大小的限制，仅限于16帧视频。此外，它表现出相当大的不稳定性，并与人类评估存在差异。为了解决这些限制，我们提出了STREAM，一种新的视频评估度量方法，独特地设计以解决当前视频生成模型评估的挑战。

    arXiv:2403.09669v1 Announce Type: cross  Abstract: Image generative models have made significant progress in generating realistic and diverse images, supported by comprehensive guidance from various evaluation metrics. However, current video generative models struggle to generate even short video clips, with limited tools that provide insights for improvements. Current video evaluation metrics are simple adaptations of image metrics by switching the embeddings with video embedding networks, which may underestimate the unique characteristics of video. Our analysis reveals that the widely used Frechet Video Distance (FVD) has a stronger emphasis on the spatial aspect than the temporal naturalness of video and is inherently constrained by the input size of the embedding networks used, limiting it to 16 frames. Additionally, it demonstrates considerable instability and diverges from human evaluations. To address the limitations, we propose STREAM, a new video evaluation metric uniquely des
    
[^94]: 在上下文学习中纠正演示快捷方式

    Rectifying Demonstration Shortcut in In-Context Learning

    [https://arxiv.org/abs/2403.09488](https://arxiv.org/abs/2403.09488)

    本研究旨在纠正大型语言模型在上下文学习中的演示快捷方式，并引入了一种新的明示意识校准方法。

    

    大型语言模型（LLMs）能够利用它们的上下文学习（ICL）能力，仅凭少量演示便能解决各种任务。然而，LLMs常常依赖于它们对演示的预先训练的语义先验，而不是根据输入-标签关系继续进行ICL预测。本文将这一现象称为“演示快捷方式”。尽管先前的研究主要集中于改进预定义任务的ICL预测结果，我们的目标是纠正演示快捷方式，从而使LLM能够有效地从演示中学习新的输入-标签关系。为实现此目标，我们引入了一种明示意识的校准方法：In-Context Calibration。我们在两个设置中评估了所提出方法的有效性：（1）使用标准标签空间的原始ICL任务以及（2）任务学习设置，其中标签空间被语义无关的标记替换。

    arXiv:2403.09488v1 Announce Type: cross  Abstract: Large language models (LLMs) are able to solve various tasks with only a few demonstrations utilizing their in-context learning (ICL) abilities. However, LLMs often rely on their pre-trained semantic priors of demonstrations rather than on the input-label relationships to proceed with ICL prediction. In this work, we term this phenomenon as the `Demonstration Shortcut'. While previous works have primarily focused on improving ICL prediction results for predefined tasks, we aim to rectify the Demonstration Shortcut, thereby enabling the LLM to effectively learn new input-label relationships from demonstrations. To achieve this, we introduce In-Context Calibration, a demonstration-aware calibration method. We evaluate the effectiveness of the proposed method in two settings: (1) the Original ICL Task using the standard label space and (2) the Task Learning setting, where the label space is replaced with semantically unrelated tokens. In 
    
[^95]: 生成人工智能对术语定义的意义

    What Generative Artificial Intelligence Means for Terminological Definitions

    [https://arxiv.org/abs/2402.16139](https://arxiv.org/abs/2402.16139)

    生成人工智能工具如ChatGPT在提供定制化的语境特定含义方面表现出色，但在准确性方面存在挑战，可以辅助术语学家进行术语编纂，实现AI效率与人类专业知识的结合。

    

    本文探讨了生成人工智能（GenAI）对术语定义的创建和消费的影响。像ChatGPT这样的GenAI工具与传统术语资源相比，带来了一系列益处和挑战。ChatGPT在以交互式和定制化的方式提供特定语境含义方面表现出色，但在准确性方面面临挑战。识别资源中的术语定义可能会因其可靠性而继续存在。从术语学家的角度来看，诸如ChatGPT之类的工具使得AI辅助的术语编纂成为可能，包括后期编辑术语编纂，将AI效率与人类专业知识相结合，以实现更快速的定义创建。

    arXiv:2402.16139v1 Announce Type: cross  Abstract: This paper examines the impact of Generative Artificial Intelligence (GenAI) on the creation and consumption of terminological definitions. GenAI tools like ChatGPT present a mix of benefits and drawbacks compared to traditional terminological resources. ChatGPT excels in providing context-specific meanings in an interactive and customized fashion but faces challenges with accuracy. Terminological definitions in recognized resources will likely survive because of their reliability. From the point of view of the terminologist, tools like ChatGPT enable AI-assisted terminography, including post-editing terminography, as an approach blending AI efficiency with human expertise for faster definition creation.
    
[^96]: 针对参数高效微调的权重投毒后门攻击的防御

    Defending Against Weight-Poisoning Backdoor Attacks for Parameter-Efficient Fine-Tuning

    [https://arxiv.org/abs/2402.12168](https://arxiv.org/abs/2402.12168)

    PEFT相对于全参数微调更容易受到权重投毒后门攻击的影响，提出了一个通过置信度识别受污染样本的毒化样本识别模块（PSIM），为权重投毒后门攻击提供稳健防御

    

    最近，针对语言模型应用提出并成功实施了各种参数高效微调（PEFT）策略。然而，这引发了一个问题，即当面对权重投毒后门攻击时，仅更新有限模型参数的PEFT是否构成安全漏洞。我们展示了PEFT相对于全参数微调方法更容易受到权重投毒后门攻击的影响，预定义的触发器仍然易受利用，预定义的目标在微调后依然保持高置信度。受到这一见解的启发，我们开发了一个利用PEFT的毒化样本识别模块（PSIM），通过置信度识别受污染样本，提供针对权重投毒后门攻击的稳健防御。具体而言，我们利用PEFT训练PSIM，带有随机重置样本标签。在推断过程中，

    arXiv:2402.12168v1 Announce Type: cross  Abstract: Recently, various parameter-efficient fine-tuning (PEFT) strategies for application to language models have been proposed and successfully implemented. However, this raises the question of whether PEFT, which only updates a limited set of model parameters, constitutes security vulnerabilities when confronted with weight-poisoning backdoor attacks. In this study, we show that PEFT is more susceptible to weight-poisoning backdoor attacks compared to the full-parameter fine-tuning method, with pre-defined triggers remaining exploitable and pre-defined targets maintaining high confidence, even after fine-tuning. Motivated by this insight, we developed a Poisoned Sample Identification Module (PSIM) leveraging PEFT, which identifies poisoned samples through confidence, providing robust defense against weight-poisoning backdoor attacks. Specifically, we leverage PEFT to train the PSIM with randomly reset sample labels. During the inference pr
    
[^97]: MultiCorrupt：一种用于3D物体检测的LiDAR-相机融合的多模态鲁棒性数据集和基准

    MultiCorrupt: A Multi-Modal Robustness Dataset and Benchmark of LiDAR-Camera Fusion for 3D Object Detection

    [https://arxiv.org/abs/2402.11677](https://arxiv.org/abs/2402.11677)

    MultiCorrupt是用于评估多模态3D目标检测器在十种不同数据损坏类型下的鲁棒性的综合基准。

    

    多模态3D物体检测模型在计算机视觉基准数据集如nuScenes上展现出了出色的表现，但它们对密集采样的LiDAR点云和精心校准的传感器阵列依赖性使得在实际应用中面临挑战。为解决这一挑战，我们介绍了MultiCorrupt，一个旨在评估多模态3D目标检测器对十种不同类型数据损坏的鲁棒性的综合基准。

    arXiv:2402.11677v1 Announce Type: cross  Abstract: Multi-modal 3D object detection models for automated driving have demonstrated exceptional performance on computer vision benchmarks like nuScenes. However, their reliance on densely sampled LiDAR point clouds and meticulously calibrated sensor arrays poses challenges for real-world applications. Issues such as sensor misalignment, miscalibration, and disparate sampling frequencies lead to spatial and temporal misalignment in data from LiDAR and cameras. Additionally, the integrity of LiDAR and camera data is often compromised by adverse environmental conditions such as inclement weather, leading to occlusions and noise interference. To address this challenge, we introduce MultiCorrupt, a comprehensive benchmark designed to evaluate the robustness of multi-modal 3D object detectors against ten distinct types of corruptions. We evaluate five state-of-the-art multi-modal detectors on MultiCorrupt and analyze their performance in terms of
    
[^98]: 使用大型语言模型进行反叙事评估的多方面框架

    A Multi-Aspect Framework for Counter Narrative Evaluation using Large Language Models

    [https://arxiv.org/abs/2402.11676](https://arxiv.org/abs/2402.11676)

    提出了一个多方面框架，使用大型语言模型评估反叙事，通过5个方面从专门 NGO 指南中提取定义的内容，以解决以往评估方法的局限性。

    

    反叙事是对仇恨言论背景的知情回应，旨在驳斥仇恨主张并化解冲突，已成为一种有效的仇恨言论干预策略。先前的工作提出了自动生成反叙事的方法来辅助手动干预，但这些方法的评估仍未得到充分发展。先前用于反叙事评估的自动度量标准缺乏与人类判断的一致性，因为它们依赖于表面参考比较，而不是将反叙事质量的关键方面纳入评估标准。为解决先前的评估局限性，我们提出了一个新颖的评估框架，促使LLM提供生成的反叙事候选的得分和反馈，使用了来自专门NGO的反叙事指南中提取的5个定义的方面。

    arXiv:2402.11676v1 Announce Type: cross  Abstract: Counter narratives - informed responses to hate speech contexts designed to refute hateful claims and de-escalate encounters - have emerged as an effective hate speech intervention strategy. While previous work has proposed automatic counter narrative generation methods to aid manual interventions, the evaluation of these approaches remains underdeveloped. Previous automatic metrics for counter narrative evaluation lack alignment with human judgment as they rely on superficial reference comparisons instead of incorporating key aspects of counter narrative quality as evaluation criteria. To address prior evaluation limitations, we propose a novel evaluation framework prompting LLMs to provide scores and feedback for generated counter narrative candidates using 5 defined aspects derived from guidelines from counter narrative specialized NGOs. We found that LLM evaluators achieve strong alignment to human-annotated scores and feedback and
    
[^99]: 变分流模型：以你的风格流动

    Variational Flow Models: Flowing in Your Style

    [https://arxiv.org/abs/2402.02977](https://arxiv.org/abs/2402.02977)

    我们引入了一种变分流模型的方法，并提出了一种系统的无需训练的转换方法，使得快速采样成为可能，同时保持了采样的准确性和效率。

    

    我们引入了一种对"后验流"模型进行变分推理解释的方法——用以将"概率流"推广到更广泛的随机过程类别，不必局限于扩散过程。我们将这种结果称为"变分流模型"。此外，我们提出了一种无需训练的系统方法，将由方程Xt = at * X0 + st * X1所描述的"线性"随机过程的后验流转化为直线恒速(SC)流，类似于矫正流。这种转化使得可以快速沿着原始的后验流进行采样，而无需训练一个新的SC流模型。我们的方法的灵活性使我们能够将转换扩展到两个不同"线性"随机过程的后验流之间进行互相转化。此外，我们还可以将高阶数值解法轻松集成到转换后的SC流中，进一步提高采样的准确性和效率。我们进行了严格的理论分析和大量实验结果的验证。

    We introduce a variational inference interpretation for models of "posterior flows" - generalizations of "probability flows" to a broader class of stochastic processes not necessarily diffusion processes. We coin the resulting models as "Variational Flow Models". Additionally, we propose a systematic training-free method to transform the posterior flow of a "linear" stochastic process characterized by the equation Xt = at * X0 + st * X1 into a straight constant-speed (SC) flow, reminiscent of Rectified Flow. This transformation facilitates fast sampling along the original posterior flow without training a new model of the SC flow. The flexibility of our approach allows us to extend our transformation to inter-convert two posterior flows from distinct "linear" stochastic processes. Moreover, we can easily integrate high-order numerical solvers into the transformed SC flow, further enhancing sampling accuracy and efficiency. Rigorous theoretical analysis and extensive experimental result
    
[^100]: 在狼人游戏中增强大型语言模型的推理能力

    Enhance Reasoning for Large Language Models in the Game Werewolf

    [https://arxiv.org/abs/2402.02330](https://arxiv.org/abs/2402.02330)

    本文提出了一个创新的框架，将大型语言模型（LLM）与外部思考模块相结合，以增强推理能力，通过引入通信协议和使用大量数据进行训练，展示了其在游戏推理、语音生成和在线评估方面的有效性。

    

    本文提出了一个创新的框架，将大型语言模型（LLM）与外部思考模块相结合，以增强基于LLM的代理的推理能力。与通过prompt工程增加LLM不同，思考者直接利用数据库中的知识，并采用各种优化技术。该框架形成了一个推理层次结构，在其中LLM处理直观的系统1任务，如自然语言处理，而思考者专注于需要复杂的逻辑分析和领域特定知识的认知系统2任务。我们以需要双系统推理的9人狼人游戏为例介绍了该框架。我们引入了LLM和思考者之间的通信协议，并使用来自18800个人类会话和强化学习的数据训练了思考者。实验证明了该框架在演绎推理、语音生成和在线游戏评估方面的有效性。此外，我们通过微调6B LLM，超越了GPT4。

    This paper presents an innovative framework that integrates Large Language Models (LLMs) with an external Thinker module to enhance the reasoning capabilities of LLM-based agents. Unlike augmenting LLMs with prompt engineering, Thinker directly harnesses knowledge from databases and employs various optimization techniques. The framework forms a reasoning hierarchy where LLMs handle intuitive System-1 tasks such as natural language processing, while the Thinker focuses on cognitive System-2 tasks that require complex logical analysis and domain-specific knowledge. Our framework is presented using a 9-player Werewolf game that demands dual-system reasoning. We introduce a communication protocol between LLMs and the Thinker, and train the Thinker using data from 18800 human sessions and reinforcement learning. Experiments demonstrate the framework's effectiveness in deductive reasoning, speech generation, and online game evaluation. Additionally, we fine-tune a 6B LLM to surpass GPT4 when
    
[^101]: SERNet-Former: 带有注意力增强门和注意力融合网络的高效剩余网络语义分割方法

    SERNet-Former: Semantic Segmentation by Efficient Residual Network with Attention-Boosting Gates and Attention-Fusion Networks

    [https://arxiv.org/abs/2401.15741](https://arxiv.org/abs/2401.15741)

    这篇论文提出了一种名为SERNet-Former的高效剩余网络语义分割方法。它通过引入注意力增强门和注意力融合网络来改善语义分割方法的效率，并解决了从全局和局部上融合语义信息的问题。实验结果表明，该方法在挑战性的数据集上取得了良好的性能。

    

    在语义分割领域，改善最先进方法的效率需要解决不断增长的计算成本以及从全局和局部上融合语义信息的问题。基于最近在语义分割中卷积神经网络（CNN）的成功和问题，本研究提出了一种带有独特高效剩余网络的编码器-解码器架构。通过引入注意力增强门（AbGs）和注意力增强模块（AbMs），目标是在编码器中将基于特征的语义信息与高效剩余网络的全局上下文相结合。同时，在解码器部分采用了受到AbM启发的额外注意力融合网络（AfNs）。AfNs旨在通过在解码器部分部署额外的卷积层，改善语义信息的逐一转换的效率。我们将网络在具有挑战性的CamVid和Cityscapes数据集上进行了测试。

    Improving the efficiency of state-of-the-art methods in semantic segmentation requires overcoming the increasing computational cost as well as issues such as fusing semantic information from global and local contexts. Based on the recent success and problems that convolutional neural networks (CNNs) encounter in semantic segmentation, this research proposes an encoder-decoder architecture with a unique efficient residual network. Attention-boosting gates (AbGs) and attention-boosting modules (AbMs) are deployed by aiming to fuse the feature-based semantic information with the global context of the efficient residual network in the encoder. Respectively, the decoder network is developed with the additional attention-fusion networks (AfNs) inspired by AbM. AfNs are designed to improve the efficiency in the one-to-one conversion of the semantic information by deploying additional convolution layers in the decoder part. Our network is tested on the challenging CamVid and Cityscapes dataset
    
[^102]: 使用知识图谱上的重述进行对话式问答

    Conversational Question Answering with Reformulations over Knowledge Graph

    [https://arxiv.org/abs/2312.17269](https://arxiv.org/abs/2312.17269)

    提出了使用重述技术改进对话式问答性能的CornNet模型

    

    对话式问答（convQA）是关于知识图谱（KGs）中包含的信息的多轮自然语言问题的回答。目前的convQA方法通常在难以理解的问答配对方面遇到困难。这些输入对于人类来说在对话历史的基础上很容易理解，但对于机器来说很难解释，这可能会降低convQA性能。为了解决这个问题，我们提出了一个基于强化学习（RL）的模型CornNet，它利用大型语言模型（LLMs）生成的问题重述来提高convQA性能。CornNet采用教师-学生架构，其中教师模型使用人类编写的重述来学习问题表示，学生模型通过LLMs生成的重述来模仿教师模型的输出。然后，RL模型使用学到的问题表示来在KG中定位正确答案。

    arXiv:2312.17269v2 Announce Type: replace-cross  Abstract: Conversational question answering (convQA) over knowledge graphs (KGs) involves answering multi-turn natural language questions about information contained in a KG. State-of-the-art methods of ConvQA often struggle with inexplicit question-answer pairs. These inputs are easy for human beings to understand given a conversation history, but hard for a machine to interpret, which can degrade ConvQA performance. To address this problem, we propose a reinforcement learning (RL) based model, CornNet, which utilizes question reformulations generated by large language models (LLMs) to improve ConvQA performance. CornNet adopts a teacher-student architecture where a teacher model learns question representations using human writing reformulations, and a student model to mimic the teacher model's output via reformulations generated by LLMs. The learned question representation is then used by an RL model to locate the correct answer in a K
    
[^103]: 视觉空间注意力和本体感知数据驱动的强化学习用于不同条件下鲁棒的插销孔任务

    Visual Spatial Attention and Proprioceptive Data-Driven Reinforcement Learning for Robust Peg-in-Hole Task Under Variable Conditions

    [https://arxiv.org/abs/2312.16438](https://arxiv.org/abs/2312.16438)

    提出了一种视觉空间注意力和本体感知数据驱动的机器人控制模型，通过SAP和DRL策略进行端到端训练，鲁棒地解决具有挑战性的照明和孔面条件下的插销孔任务。

    

    锚栓插入是建筑领域中进行混凝土孔插销任务，已经做出了努力自动化这项任务，但是变化多端的光照和孔表面条件以及对短暂设置和任务执行时间的需求使得自动化具有挑战性。在这项研究中，我们引入了一个视觉和本体感知数据驱动的机器人控制模型，用于鲁棒地应对具有挑战性的照明和孔面条件。该模型由空间注意点网络（SAP）和深度强化学习（DRL）策略组成，二者共同端到端地进行训练以控制机器人。该模型以离线方式进行训练，设计了一种样本高效的框架，旨在减少训练时间并最小化在将模型转移到现实世界时的现实差距。通过对一台工业机器人在12个未知孔中进行任务执行的评估，始于16个不同的...

    arXiv:2312.16438v2 Announce Type: replace-cross  Abstract: Anchor-bolt insertion is a peg-in-hole task performed in the construction field for holes in concrete. Efforts have been made to automate this task, but the variable lighting and hole surface conditions, as well as the requirements for short setup and task execution time make the automation challenging. In this study, we introduce a vision and proprioceptive data-driven robot control model for this task that is robust to challenging lighting and hole surface conditions. This model consists of a spatial attention point network (SAP) and a deep reinforcement learning (DRL) policy that are trained jointly end-to-end to control the robot. The model is trained in an offline manner, with a sample-efficient framework designed to reduce training time and minimize the reality gap when transferring the model to the physical world. Through evaluations with an industrial robot performing the task in 12 unknown holes, starting from 16 diffe
    
[^104]: GlitchBench：大型多模态模型能够检测视频游戏漏洞吗？

    GlitchBench: Can large multimodal models detect video game glitches?

    [https://arxiv.org/abs/2312.05291](https://arxiv.org/abs/2312.05291)

    GlitchBench是一个基于视频游戏质量保证任务的新基准，旨在挑战LMMs在检测和解释异常事件方面的视觉和语言推理能力。

    

    大型多模态模型（LMMs）已从大型语言模型（LLMs）发展而来，以整合多种输入模态，如视觉输入。这种整合增强了LLMs在需要视觉理解和推理的任务上的能力。然而，尤其是在涉及真实世界任务时，它们增强的能力的程度和限制尚未完全被理解。为了填补这一空白，我们引入了GlitchBench，这是一个新颖的基准，源自于视频游戏质量保证任务，旨在测试和评估LMMs的推理能力。我们的基准是从各种视频游戏中的不寻常和出现故障的场景精心策划而成，旨在挑战LMMs在检测和解释非同寻常事件方面的视觉和语言推理能力。我们评估了多个最先进的LMMs，并展示了GlitchBench为这些模型提出了新挑战。 代码和数据可在以下链接找到：https://glitchb

    arXiv:2312.05291v2 Announce Type: replace-cross  Abstract: Large multimodal models (LMMs) have evolved from large language models (LLMs) to integrate multiple input modalities, such as visual inputs. This integration augments the capacity of LLMs for tasks requiring visual comprehension and reasoning. However, the extent and limitations of their enhanced abilities are not fully understood, especially when it comes to real-world tasks. To address this gap, we introduce GlitchBench, a novel benchmark derived from video game quality assurance tasks, to test and evaluate the reasoning capabilities of LMMs. Our benchmark is curated from a variety of unusual and glitched scenarios from video games and aims to challenge both the visual and linguistic reasoning powers of LMMs in detecting and interpreting out-of-the-ordinary events. We evaluate multiple state-of-the-art LMMs, and we show that GlitchBench presents a new challenge for these models. Code and data are available at: https://glitchb
    
[^105]: 机器人操纵臂的快速电机适应性

    Rapid Motor Adaptation for Robotic Manipulator Arms

    [https://arxiv.org/abs/2312.04670](https://arxiv.org/abs/2312.04670)

    快速电机适应性（RMA）为机器人操作技能的泛化提出了解决方案，利用深度感知开发了针对各种操纵任务的代理。

    

    开发通用机器人操作技能是体现人工智能的核心挑战。这包括跨越各种任务配置的泛化，涵盖了对象形状、密度、摩擦系数的变化以及外部干扰，如施加在机器人身上的力。快速电机适应性（Rapid Motor Adaptation，RMA）为这一挑战提供了一个有前景的解决方案。它认为，影响智能体任务表现的基本隐变量，如对象质量和形状，可以从智能体的动作和本体感性历史中有效地推断出来。我们借鉴了在移动和手内旋转中的RMA，利用深度感知来开发针对各种操纵任务的快速电机适应性代理。我们在Maniskill2基准测试中对我们的代理进行了评估，这些任务包括从YCB和EGAD数据集中数百个对象的取放操作，以及精确定位和

    arXiv:2312.04670v2 Announce Type: replace-cross  Abstract: Developing generalizable manipulation skills is a core challenge in embodied AI. This includes generalization across diverse task configurations, encompassing variations in object shape, density, friction coefficient, and external disturbances such as forces applied to the robot. Rapid Motor Adaptation (RMA) offers a promising solution to this challenge. It posits that essential hidden variables influencing an agent's task performance, such as object mass and shape, can be effectively inferred from the agent's action and proprioceptive history. Drawing inspiration from RMA in locomotion and in-hand rotation, we use depth perception to develop agents tailored for rapid motor adaptation in a variety of manipulation tasks. We evaluated our agents on four challenging tasks from the Maniskill2 benchmark, namely pick-and-place operations with hundreds of objects from the YCB and EGAD datasets, peg insertion with precise position and 
    
[^106]: 从单个连续视频流中学习

    Learning from One Continuous Video Stream

    [https://arxiv.org/abs/2312.00598](https://arxiv.org/abs/2312.00598)

    我们提出了一个在线学习框架，允许从单个连续视频流中学习，通过像素级建模实现预训练和单流评估之间的灵活切换，并获得了大量单流学习的收益。

    

    我们介绍了一个针对从单个连续视频流中进行在线学习的框架--就像人类和动物学习的方式一样，无需小批量、数据增强或洗牌。由于连续视频帧之间的高相关性，这带来了很大的挑战，并且在这方面几乎没有先前的工作。我们的框架使我们首次深入探讨了这一主题，包括了由两个现有视频数据集组成的一组流和任务，以及考虑了适应性和泛化性能评估的方法论。我们采用像素级建模作为一种实用且灵活的方式，可以在预训练和单个流评估之间以及在任意任务之间进行切换，而无需改变模型，并始终使用相同的像素损失。借助这个框架，我们通过预训练一组新颖的未来预测任务获得了大量单流学习的收益，foun

    arXiv:2312.00598v2 Announce Type: replace-cross  Abstract: We introduce a framework for online learning from a single continuous video stream -- the way people and animals learn, without mini-batches, data augmentation or shuffling. This poses great challenges given the high correlation between consecutive video frames and there is very little prior work on it. Our framework allows us to do a first deep dive into the topic and includes a collection of streams and tasks composed from two existing video datasets, plus methodology for performance evaluation that considers both adaptation and generalization. We employ pixel-to-pixel modelling as a practical and flexible way to switch between pre-training and single-stream evaluation as well as between arbitrary tasks, without ever requiring changes to models and always using the same pixel loss. Equipped with this framework we obtained large single-stream learning gains from pre-training with a novel family of future prediction tasks, foun
    
[^107]: TransNeXt：Vision Transformers的鲁棒伏脉视知觉

    TransNeXt: Robust Foveal Visual Perception for Vision Transformers

    [https://arxiv.org/abs/2311.17132](https://arxiv.org/abs/2311.17132)

    TransNeXt提出了Aggregated Attention，一种仿生设计的令牌混合器，通过模拟生物视觉和连续眼动，使得每个特征图上的令牌具有全局感知，且不依赖于叠加层进行信息交换，有效避免了深度退化，实现了自然的视知觉。

    

    由于残差连接中的深度退化效应，许多依赖于叠加层进行信息交换的高效Vision Transformers模型通常无法形成足够的信息混合，导致视知觉不自然。为了解决这个问题，在本文中，我们提出了聚合注意力，这是一种基于仿生设计的令牌混合器，模拟生物视觉和连续眼动，同时使特征图上的每个令牌具有全局感知。此外，我们将可学习的令牌纳入常规查询和密钥中，进一步使亲和矩阵的生成多样化，不仅仅依赖于查询和密钥之间的相似性。我们的方法不依赖于叠加进行信息交换，因此有效避免了深度退化，并实现了自然的视知觉。此外，我们提出了Convolutional GLU，这是一种通道混合器，搭起了视知觉中的断层。

    arXiv:2311.17132v2 Announce Type: replace-cross  Abstract: Due to the depth degradation effect in residual connections, many efficient Vision Transformers models that rely on stacking layers for information exchange often fail to form sufficient information mixing, leading to unnatural visual perception. To address this issue, in this paper, we propose Aggregated Attention, a biomimetic design-based token mixer that simulates biological foveal vision and continuous eye movement while enabling each token on the feature map to have a global perception. Furthermore, we incorporate learnable tokens that interact with conventional queries and keys, which further diversifies the generation of affinity matrices beyond merely relying on the similarity between queries and keys. Our approach does not rely on stacking for information exchange, thus effectively avoiding depth degradation and achieving natural visual perception. Additionally, we propose Convolutional GLU, a channel mixer that bridg
    
[^108]: 从现成的视觉语言模型中实现的紧急开放词汇语义分割

    Emergent Open-Vocabulary Semantic Segmentation from Off-the-shelf Vision-Language Models

    [https://arxiv.org/abs/2311.17095](https://arxiv.org/abs/2311.17095)

    提出了一种简单但高效的无需训练的技术，用于开放词汇语义分割，通过使用VLM和显著性丢弃来解决过度分割和欠分割的问题

    

    从图像-文本对中，大规模视觉语言模型（VLMs）学习隐式将图像区域与词汇关联起来，这对于诸如视觉问答等任务非常有效。然而，利用学习到的关联进行开放词汇语义分割仍然具有挑战性。在本文中，我们提出了一种简单但极其有效的无需训练的技术，Plug-and-Play Open-Vocabulary Semantic Segmentation (PnP-OVSS)。PnP-OVSS利用具有直接文本到图像交叉注意力和图像-文本匹配损失的VLM。为了在过度分割和欠分割之间取得平衡，我们引入了显著性丢弃（Salience Dropout）；通过迭代丢弃模型最关注的补丁，我们能够更好地解决整个分割掩模的范围。

    arXiv:2311.17095v2 Announce Type: replace-cross  Abstract: From image-text pairs, large-scale vision-language models (VLMs) learn to implicitly associate image regions with words, which prove effective for tasks like visual question answering. However, leveraging the learned association for open-vocabulary semantic segmentation remains a challenge. In this paper, we propose a simple, yet extremely effective, training-free technique, Plug-and-Play Open-Vocabulary Semantic Segmentation (PnP-OVSS) for this task. PnP-OVSS leverages a VLM with direct text-to-image cross-attention and an image-text matching loss. To balance between over-segmentation and under-segmentation, we introduce Salience Dropout; by iteratively dropping patches that the model is most attentive to, we are able to better resolve the entire extent of the segmentation mask. \shortname{} does not require any neural network training and performs hyperparameter tuning without the need for any segmentation annotations, even f
    
[^109]: 大型多模态模型的组合式思维提示

    Compositional Chain-of-Thought Prompting for Large Multimodal Models

    [https://arxiv.org/abs/2311.17076](https://arxiv.org/abs/2311.17076)

    提出了一种新颖的零样式思维提示（CCoT），以克服大型多模态模型难以捕捉到组合视觉推理方面的细节的问题。

    

    强大的视觉骨干和大规模语言模型(LLM)推理的结合已经导致大型多模态模型(LMM)成为当前广泛视觉和语言(VL)任务的标准。然而，最近的研究表明，即使是最先进的LMM仍然难以捕捉到组合视觉推理方面的细节，比如对象之间的属性和关系。一种解决方案是利用场景图(SGs)——对象及其关系和属性的形式化表达，它已被广泛用作视觉和文本领域之间的桥梁。然而，场景图数据需要场景图注释，这种数据收集成本高昂，因此难以扩展。此外，基于场景图数据微调LMM可能导致预训练目标的灾难性遗忘。为了克服这一问题，受到思维链方法的启发，我们提出了一种新颖的零样式思维提示（CCoT）。

    arXiv:2311.17076v2 Announce Type: replace-cross  Abstract: The combination of strong visual backbones and Large Language Model (LLM) reasoning has led to Large Multimodal Models (LMMs) becoming the current standard for a wide range of vision and language (VL) tasks. However, recent research has shown that even the most advanced LMMs still struggle to capture aspects of compositional visual reasoning, such as attributes and relationships between objects. One solution is to utilize scene graphs (SGs)--a formalization of objects and their relations and attributes that has been extensively used as a bridge between the visual and textual domains. Yet, scene graph data requires scene graph annotations, which are expensive to collect and thus not easily scalable. Moreover, finetuning an LMM based on SG data can lead to catastrophic forgetting of the pretraining objective. To overcome this, inspired by chain-of-thought methods, we propose Compositional Chain-of-Thought (CCoT), a novel zero-sho
    
[^110]: 学习从错误中使LLM成为更好的推理者

    Learning From Mistakes Makes LLM Better Reasoner

    [https://arxiv.org/abs/2310.20689](https://arxiv.org/abs/2310.20689)

    本研究探索了大型语言模型（LLMs）是否可以从错误中学习，类似于人类学习的过程，并通过引入错误纠正的数据对来改进LLMs的推理能力。实验结果表明，这种方法能够持续提升仅使用CoT进行微调后的性能。

    

    最近，大型语言模型（LLM）在解决数学问题方面展示出了卓越的推理能力。为了进一步提高它们的推理能力，本研究探讨了LLM是否可以学习从错误中获益（LEMA），类似于人类的学习过程。考虑一个未能解决数学问题的人类学生，他会从自己犯的错误中学习，并纠正它。模仿这种错误驱动的学习过程，LEMA在LLM的微调过程中引入了错误纠正的数据对。具体而言，我们首先收集来自各种LLM的错误推理路径，然后使用GPT-4作为“纠正者”来识别错误步骤，解释错误原因，纠正错误并生成最终答案。此外，我们还应用了一种基于纠正的进化策略，有效地扩展了生成纠正数据的问题集。在各种LLM和推理任务上的实验表明，LEMA始终可以提升仅使用CoT的微调。我们...

    Large language models (LLMs) recently exhibited remarkable reasoning capabilities on solving math problems. To further improve their reasoning capabilities, this work explores whether LLMs can LEarn from MistAkes (LEMA), akin to the human learning process. Consider a human student who failed to solve a math problem, he will learn from what mistake he has made and how to correct it. Mimicking this error-driven learning process, LEMA incorporates mistake-correction data pairs during fine-tuning LLMs. Specifically, we first collect inaccurate reasoning paths from various LLMs, and then employ GPT-4 as a "corrector" to identify the mistake step, explain the reason for the mistake, correct the mistake and generate the final answer. In addition, we apply a correction-centric evolution strategy that effectively expands the question set for generating correction data. Experiments across various LLMs and reasoning tasks show that \textsc{LeMa} consistently improves CoT-alone fine-tuning. Our fu
    
[^111]: 多配体对接和结合位点设计的谐波自调流匹配

    Harmonic Self-Conditioned Flow Matching for Multi-Ligand Docking and Binding Site Design

    [https://arxiv.org/abs/2310.05764](https://arxiv.org/abs/2310.05764)

    该研究开发了一种谐波自调流匹配方法，在多配体对接和结合位点设计中表现出比现有方法更好的生成过程和设计效果。

    

    大量蛋白质功能需要与小分子结合，包括酶催化。因此，为小分子设计结合口袋具有从药物合成到能量存储等多种影响深远的应用。为实现这一目标，我们首先开发了HarmonicFlow，这是一个改进的基于自调流匹配目标的3D蛋白质-配体结合结构生成过程。FlowSite将这种流模型扩展到联合生成蛋白质口袋的离散残基类型和分子的结合3D结构。我们展示了HarmonicFlow在口袋级对接中在简单性、普适性和平均样本质量上优于最先进的生成过程。借助于这种结构建模，FlowSite设计的结合位点明显优于基线方法。

    arXiv:2310.05764v3 Announce Type: replace-cross  Abstract: A significant amount of protein function requires binding small molecules, including enzymatic catalysis. As such, designing binding pockets for small molecules has several impactful applications ranging from drug synthesis to energy storage. Towards this goal, we first develop HarmonicFlow, an improved generative process over 3D protein-ligand binding structures based on our self-conditioned flow matching objective. FlowSite extends this flow model to jointly generate a protein pocket's discrete residue types and the molecule's binding 3D structure. We show that HarmonicFlow improves upon state-of-the-art generative processes for docking in simplicity, generality, and average sample quality in pocket-level docking. Enabled by this structure modeling, FlowSite designs binding sites substantially better than baseline approaches.
    
[^112]: 语言模型击败扩散模型--分词器是视觉生成的关键

    Language Model Beats Diffusion -- Tokenizer is Key to Visual Generation

    [https://arxiv.org/abs/2310.05737](https://arxiv.org/abs/2310.05737)

    分词器是视觉生成的关键，新的视频分词器MAGVIT-v2使得大型语言模型LLMs在图像和视频生成任务上胜过扩散模型，并在视频压缩和有效表示学习方面表现优异。

    

    大型语言模型(LLMs)是语言生成任务中的主导模型，但在图像和视频生成方面表现不如扩散模型。为了有效地利用LLMs进行视觉生成，一个至关重要的组件是视觉分词器，它将像素空间输入映射到适合LLM学习的离散标记中。本文介绍了MAGVIT-v2，一个视频分词器，旨在使用共同的标记词汇为视频和图像生成简洁和富有表现力的标记。配备了这个新的分词器，我们展示了LLMs在标准图像和视频生成基准上优于扩散模型，包括ImageNet和Kinetics。此外，我们证明了我们的分词器在两项任务上超过了先前表现最佳的视频分词器：(1)根据人类评估，视频压缩与下一代视频编解码器(VCC)相媲美，(2)学习有效的表示。

    arXiv:2310.05737v2 Announce Type: replace-cross  Abstract: While Large Language Models (LLMs) are the dominant models for generative tasks in language, they do not perform as well as diffusion models on image and video generation. To effectively use LLMs for visual generation, one crucial component is the visual tokenizer that maps pixel-space inputs to discrete tokens appropriate for LLM learning. In this paper, we introduce MAGVIT-v2, a video tokenizer designed to generate concise and expressive tokens for both videos and images using a common token vocabulary. Equipped with this new tokenizer, we show that LLMs outperform diffusion models on standard image and video generation benchmarks including ImageNet and Kinetics. In addition, we demonstrate that our tokenizer surpasses the previously top-performing video tokenizer on two more tasks: (1) video compression comparable to the next-generation video codec (VCC) according to human evaluations, and (2) learning effective representati
    
[^113]: 面向语义分割的分布感知连续测试时适应

    Distribution-Aware Continual Test-Time Adaptation for Semantic Segmentation

    [https://arxiv.org/abs/2309.13604](https://arxiv.org/abs/2309.13604)

    提出了一种分布感知调整（DAT）方法，以使得面向语义分割的连续测试时适应（CTTA）在实际应用中更加高效和实用。

    

    由于自动驾驶系统通常面临动态和不断变化的环境，连续测试时适应（CTTA）被提出作为一种将部署模型转移到不断变化的目标域的策略。然而，追求长期适应往往会引入灾难性遗忘和误差累积问题，这些问题阻碍了CTTA在实际世界中的实施。最近，现有的CTTA方法主要集中于利用大部分参数通过自训练来适应目标领域知识。不幸的是，这些方法往往会由于嘈杂的伪标签而加剧误差累积的挑战，并由于整个模型更新所带来的沉重计算成本而带来实际限制。在本文中，我们提出了一种分布感知调整（DAT）方法，使得语义分割CTTA在真实应用中既高效又实用。

    arXiv:2309.13604v2 Announce Type: replace-cross  Abstract: Since autonomous driving systems usually face dynamic and ever-changing environments, continual test-time adaptation (CTTA) has been proposed as a strategy for transferring deployed models to continually changing target domains. However, the pursuit of long-term adaptation often introduces catastrophic forgetting and error accumulation problems, which impede the practical implementation of CTTA in the real world. Recently, existing CTTA methods mainly focus on utilizing a majority of parameters to fit target domain knowledge through self-training. Unfortunately, these approaches often amplify the challenge of error accumulation due to noisy pseudo-labels, and pose practical limitations stemming from the heavy computational costs associated with entire model updates. In this paper, we propose a distribution-aware tuning (DAT) method to make the semantic segmentation CTTA efficient and practical in real-world applications. DAT ad
    
[^114]: DFWLayer: 可微化的Frank-Wolfe优化层

    DFWLayer: Differentiable Frank-Wolfe Optimization Layer

    [https://arxiv.org/abs/2308.10806](https://arxiv.org/abs/2308.10806)

    本文提出了一种名为Differentiable Frank-Wolfe Layer（DFWLayer）的可微层，通过推出Frank-Wolfe方法，有效处理具有范数约束的大规模凸优化问题，并在解和梯度准确性方面表现竞争性。

    

    不同iable优化因其在基于神经网络的机器学习领域中的基础作用而受到广泛关注。本文通过推出Frank-Wolfe方法提出了一种可微层，命名为Differentiable Frank-Wolfe Layer（DFWLayer），该方法是一种可以在不进行投影和Hessian矩阵计算的情况下解决约束优化问题的著名优化算法，从而有效地处理具有范数约束的大规模凸优化问题。实验结果表明，DFWLayer不仅在解和梯度精度上表现竞争性，而且始终遵守约束条件。

    arXiv:2308.10806v2 Announce Type: replace-cross  Abstract: Differentiable optimization has received a significant amount of attention due to its foundational role in the domain of machine learning based on neural networks. This paper proposes a differentiable layer, named Differentiable Frank-Wolfe Layer (DFWLayer), by rolling out the Frank-Wolfe method, a well-known optimization algorithm which can solve constrained optimization problems without projections and Hessian matrix computations, thus leading to an efficient way of dealing with large-scale convex optimization problems with norm constraints. Experimental results demonstrate that the DFWLayer not only attains competitive accuracy in solutions and gradients but also consistently adheres to constraints.
    
[^115]: 使用S3PRL工具包比较语音数据增强方法

    A Comparison of Speech Data Augmentation Methods Using S3PRL Toolkit

    [https://arxiv.org/abs/2303.00510](https://arxiv.org/abs/2303.00510)

    通过使用S3PRL工具包，研究了不同的数据增强策略，发现SpecAugment略微提高了HuBERT和wav2vec在原始数据集上的性能，而使用高斯噪声和速度扰动数据集训练的模型在经过增强的测试集上表现更为稳健。

    

    数据增强已知可以提高语音处理任务的鲁棒性。在这项研究中，我们使用S3PRL工具包总结并比较不同的数据增强策略。我们探讨了如何使用HuBERT和wav2vec结合不同增强技术（SpecAugment、高斯噪声、速度扰动）进行音素识别（PR）和自动语音识别（ASR）任务。我们根据音素错误率（PER）和词错误率（WER）评估模型性能。从实验中，我们观察到SpecAugment在原始数据集上略微提高了HuBERT和wav2vec的性能。此外，我们展示了使用高斯噪声和速度扰动数据集训练的模型在经过增强的测试集上表现更为稳健。

    arXiv:2303.00510v2 Announce Type: replace-cross  Abstract: Data augmentations are known to improve robustness in speech-processing tasks. In this study, we summarize and compare different data augmentation strategies using S3PRL toolkit. We explore how HuBERT and wav2vec perform using different augmentation techniques (SpecAugment, Gaussian Noise, Speed Perturbation) for Phoneme Recognition (PR) and Automatic Speech Recognition (ASR) tasks. We evaluate model performance in terms of phoneme error rate (PER) and word error rate (WER). From the experiments, we observed that SpecAugment slightly improves the performance of HuBERT and wav2vec on the original dataset. Also, we show that models trained using the Gaussian Noise and Speed Perturbation dataset are more robust when tested with augmented test sets.
    
[^116]: 关注图转换器

    Attending to Graph Transformers

    [https://arxiv.org/abs/2302.04181](https://arxiv.org/abs/2302.04181)

    提出了一种图转换器架构的分类法，概述了其理论性质，调查了结构和位置编码，并探讨了对重要图类的扩展，如3D分子图。

    

    最近，用于图形的转换器架构作为机器学习的替代技术出现，例如（消息传递）图神经网络。到目前为止，它们已经展示出有希望的实证结果，例如在分子预测数据集上，通常归因于其绕过图神经网络的缺点，如过度平滑和过度压缩。在这里，我们提出了一种图转换器架构的分类法，为这个新兴领域带来了一些秩序。我们概述它们的理论性质，调查结构和位置编码，并讨论了对重要图类的扩展，例如3D分子图。在实证方面，我们研究图转换器如何恢复各种图属性，如何处理异性图，以及它们在多大程度上可以防止过度压缩。此外，我们概述了未解决的挑战和研究方向，以促进未来工作。

    arXiv:2302.04181v3 Announce Type: replace-cross  Abstract: Recently, transformer architectures for graphs emerged as an alternative to established techniques for machine learning with graphs, such as (message-passing) graph neural networks. So far, they have shown promising empirical results, e.g., on molecular prediction datasets, often attributed to their ability to circumvent graph neural networks' shortcomings, such as over-smoothing and over-squashing. Here, we derive a taxonomy of graph transformer architectures, bringing some order to this emerging field. We overview their theoretical properties, survey structural and positional encodings, and discuss extensions for important graph classes, e.g., 3D molecular graphs. Empirically, we probe how well graph transformers can recover various graph properties, how well they can deal with heterophilic graphs, and to what extent they prevent over-squashing. Further, we outline open challenges and research direction to stimulate future wo
    
[^117]: 限制在芯片架构上保持量子神经网络的准确性

    Restricting to the chip architecture maintains the quantum neural network accuracy

    [https://arxiv.org/abs/2212.14426](https://arxiv.org/abs/2212.14426)

    该研究旨在探讨量子神经网络在量子芯片架构上表现出的准确性，并发现成本函数往往会收敛到一个平均值。

    

    在噪声中等规模量子设备的时代，变分量子算法（VQAs）作为构建量子机器学习模型的显著策略。这些模型包括量子部分和经典部分。量子部分通过参数化 $U$ 来表征，通常由各种量子门的组合得到。另一方面，经典部分涉及一个优化器，调节 $U$ 的参数以最小化成本函数 $C$。尽管VQAs有广泛的应用，但仍然存在一些关键问题，比如确定最佳门序列、设计高效的参数优化策略、选择合适的成本函数，以及了解量子芯片架构对最终结果的影响。本文旨在解决最后一个问题，并强调，一般情况下，成本函数倾向于收敛到一个平均值。

    arXiv:2212.14426v2 Announce Type: replace-cross  Abstract: In the era of noisy intermediate-scale quantum devices, variational quantum algorithms (VQAs) stand as a prominent strategy for constructing quantum machine learning models. These models comprise both a quantum and a classical component. The quantum facet is characterized by a parametrization $U$, typically derived from the composition of various quantum gates. On the other hand, the classical component involves an optimizer that adjusts the parameters of $U$ to minimize a cost function $C$. Despite the extensive applications of VQAs, several critical questions persist, such as determining the optimal gate sequence, devising efficient parameter optimization strategies, selecting appropriate cost functions, and understanding the influence of quantum chip architectures on the final results. This article aims to address the last question, emphasizing that, in general, the cost function tends to converge towards an average value as
    
[^118]: GOTCHA：通过挑战-响应实现实时视频深度伪造检测

    GOTCHA: Real-Time Video Deepfake Detection via Challenge-Response

    [https://arxiv.org/abs/2210.06186](https://arxiv.org/abs/2210.06186)

    通过挑战-响应方式，针对AI Real-Time Deepfakes的限制，提出实时视频深度伪造检测解决方案。

    

    随着AI-enabled Real-Time Deepfakes（RTDFs）的兴起，在线视频互动的完整性已成为一个日益令人担忧的问题。RTDFs现在使得在实时视频互动中将冒名顶替者的脸替换为其受害者成为可能。这种深度伪造的进步也促使检测达到同样的标准。然而，现有的深度伪造检测技术是异步的，因此不适用于RTDFs。为了弥补这一差距，我们提出了一种在实时环境中建立真实性的挑战-响应方法。我们专注于讲话头部风格的视频互动，并提出了一个专门针对RTDF生成管道固有限制的挑战分类。我们通过收集一个包含八个挑战的独特数据集来评估分类中的代表性示例，这些挑战一致和明显地降低了最先进的深度伪造生成器的质量。这些结果得到了人类的证实。

    arXiv:2210.06186v3 Announce Type: replace-cross  Abstract: With the rise of AI-enabled Real-Time Deepfakes (RTDFs), the integrity of online video interactions has become a growing concern. RTDFs have now made it feasible to replace an imposter's face with their victim in live video interactions. Such advancement in deepfakes also coaxes detection to rise to the same standard. However, existing deepfake detection techniques are asynchronous and hence ill-suited for RTDFs. To bridge this gap, we propose a challenge-response approach that establishes authenticity in live settings. We focus on talking-head style video interaction and present a taxonomy of challenges that specifically target inherent limitations of RTDF generation pipelines. We evaluate representative examples from the taxonomy by collecting a unique dataset comprising eight challenges, which consistently and visibly degrades the quality of state-of-the-art deepfake generators. These results are corroborated both by humans 
    
[^119]: 具有有限训练任务的元强化学习--一种密度估计方法

    Meta Reinforcement Learning with Finite Training Tasks -- a Density Estimation Approach

    [https://arxiv.org/abs/2206.10716](https://arxiv.org/abs/2206.10716)

    通过密度估计技术直接学习任务分布，从而对元强化学习中所需训练任务数提出了新的界限分析方法

    

    在元强化学习(meta RL)中，一个智能体通过一组训练任务学习如何快速解决一个新任务，新任务来自相同的任务分布。优化的元RL策略，即贝叶斯最优行为，是明确定义的，并保证期望下相对于任务分布的最优奖励。我们在这项工作中探讨的问题是需要多少个训练任务才能保证以高概率近似地获得最优行为。最近的工作为模型无关设置提供了第一个这样的PAC分析，其中从训练任务中学习了一种历史相关的策略。在这项工作中，我们提出了一种不同的方法：直接学习任务分布，使用密度估计技术，然后在学习的任务分布上训练策略。我们展示了我们的方法导致依赖于任务分布维度的界限。特别是，在任务分布维度较大的情况下。

    arXiv:2206.10716v2 Announce Type: replace-cross  Abstract: In meta reinforcement learning (meta RL), an agent learns from a set of training tasks how to quickly solve a new task, drawn from the same task distribution. The optimal meta RL policy, a.k.a. the Bayes-optimal behavior, is well defined, and guarantees optimal reward in expectation, taken with respect to the task distribution. The question we explore in this work is how many training tasks are required to guarantee approximately optimal behavior with high probability. Recent work provided the first such PAC analysis for a model-free setting, where a history-dependent policy was learned from the training tasks. In this work, we propose a different approach: directly learn the task distribution, using density estimation techniques, and then train a policy on the learned task distribution. We show that our approach leads to bounds that depend on the dimension of the task distribution. In particular, in settings where the task dis
    
[^120]: QAGCN：通过对知识图谱进行单步隐式推理回答多关系问题

    QAGCN: Answering Multi-Relation Questions via Single-Step Implicit Reasoning over Knowledge Graphs

    [https://arxiv.org/abs/2206.01818](https://arxiv.org/abs/2206.01818)

    本文提出了 QAGCN 方法，通过对问题进行感知来实现单步隐式推理，从而回答多关系问题，相比于显式多步推理方法，该方法更简单、高效且易于采用。

    

    多关系问题回答（QA）是一项具有挑战性的任务，通常需要在由多个关系组成的知识图谱中进行长时间推理链的问题。最近，在这一任务中明显使用了基于知识图谱的显式多步推理方法，并展现出了良好的性能。这些方法包括通过知识图谱三元组逐步标签传播的方法以及基于强化学习浏览知识图谱三元组的方法。这些方法的一个主要弱点是它们的推理机制通常复杂且难以实现或训练。在本文中，我们认为可以通过端到端单步隐式推理实现多关系QA，这种方法更简单、更高效且更易于采用。我们提出了 QAGCN -- 一种基于问题意识的图卷积网络（GCN）方法，其中包括一种新颖的具有受控问题相关信息传播的GCN架构。

    arXiv:2206.01818v3 Announce Type: replace  Abstract: Multi-relation question answering (QA) is a challenging task, where given questions usually require long reasoning chains in KGs that consist of multiple relations. Recently, methods with explicit multi-step reasoning over KGs have been prominently used in this task and have demonstrated promising performance. Examples include methods that perform stepwise label propagation through KG triples and methods that navigate over KG triples based on reinforcement learning. A main weakness of these methods is that their reasoning mechanisms are usually complex and difficult to implement or train. In this paper, we argue that multi-relation QA can be achieved via end-to-end single-step implicit reasoning, which is simpler, more efficient, and easier to adopt. We propose QAGCN -- a Question-Aware Graph Convolutional Network (GCN)-based method that includes a novel GCN architecture with controlled question-dependent message propagation for the 
    
[^121]: 通过多样性启示的多Agent诊断方法用于稳健性

    Multi-Agent Diagnostics for Robustness via Illuminated Diversity. (arXiv:2401.13460v1 [cs.LG])

    [http://arxiv.org/abs/2401.13460](http://arxiv.org/abs/2401.13460)

    MADRID是一种新方法，通过生成多样化的对抗场景来揭示预训练多Agent策略的战略漏洞，并通过遗憾值衡量漏洞的程度。

    

    在快速发展的多Agent系统领域中，确保在陌生和敌对环境中的稳健性至关重要。尽管这些系统在熟悉环境中表现出色，但在新情况下往往会因为训练阶段的过拟合而失败。在既包含合作又包含竞争行为的环境中，这一问题尤为突出，体现了过拟合和泛化挑战的双重性质。为了解决这个问题，我们提出了通过多样性启示的多Agent稳健性诊断（MADRID），这是一种生成多Agent策略中暴露战略漏洞的多样化对抗场景的新方法。MADRID利用开放式学习的概念，导航对抗环境的广阔空间，使用目标策略的遗憾值来衡量这些环境的漏洞。我们在11vs11版的Google Research Football上评估了MADRID的有效性。

    In the rapidly advancing field of multi-agent systems, ensuring robustness in unfamiliar and adversarial settings is crucial. Notwithstanding their outstanding performance in familiar environments, these systems often falter in new situations due to overfitting during the training phase. This is especially pronounced in settings where both cooperative and competitive behaviours are present, encapsulating a dual nature of overfitting and generalisation challenges. To address this issue, we present Multi-Agent Diagnostics for Robustness via Illuminated Diversity (MADRID), a novel approach for generating diverse adversarial scenarios that expose strategic vulnerabilities in pre-trained multi-agent policies. Leveraging the concepts from open-ended learning, MADRID navigates the vast space of adversarial settings, employing a target policy's regret to gauge the vulnerabilities of these settings. We evaluate the effectiveness of MADRID on the 11vs11 version of Google Research Football, one o
    
[^122]: 单一GPU上的数据高效多模态融合

    Data-Efficient Multimodal Fusion on a Single GPU. (arXiv:2312.10144v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2312.10144](http://arxiv.org/abs/2312.10144)

    本论文提出了一种在单一GPU上进行数据高效多模态融合的方法，通过使用预训练的单模态编码器的潜在空间，我们在多模态对齐中取得了有竞争力的性能，且计算和数据量减少了数个数量级。

    

    多模态对齐的目标是学习共享多模态输入之间的单一潜在空间。在这个领域中，最强大的模型通常是使用大规模数据集和大规模计算资源进行训练的，因此在许多实际场景中训练这些模型的成本非常高昂。我们推测，现有的在大量单模态数据上预训练的单模态编码器应该能够以更低的成本从单模态模型中创建多模态模型。因此，我们提出了FuseMix，一种多模态增强方案，该方案在任意预训练的单模态编码器的潜在空间中操作。通过使用FuseMix进行多模态对齐，我们在图像-文本和音频-文本检索任务中取得了有竞争力的性能，并在某些情况下超越了最先进的方法，而计算和数据量减少了数个数量级：例如，我们在Flickr30K的文本-图像检索任务中比CLIP的性能提高了约600倍，而计算和数据量减少了数个数量级。

    The goal of multimodal alignment is to learn a single latent space that is shared between multimodal inputs. The most powerful models in this space have been trained using massive datasets of paired inputs and large-scale computational resources, making them prohibitively expensive to train in many practical scenarios. We surmise that existing unimodal encoders pre-trained on large amounts of unimodal data should provide an effective bootstrap to create multimodal models from unimodal ones at much lower costs. We therefore propose FuseMix, a multimodal augmentation scheme that operates on the latent spaces of arbitrary pre-trained unimodal encoders. Using FuseMix for multimodal alignment, we achieve competitive performance -- and in certain cases outperform state-of-the art methods -- in both image-text and audio-text retrieval, with orders of magnitude less compute and data: for example, we outperform CLIP on the Flickr30K text-to-image retrieval task with $\sim \! 600\times$ fewer GP
    
[^123]: DialogBench: 将LLMs作为人类对话系统进行评估

    DialogBench: Evaluating LLMs as Human-like Dialogue Systems. (arXiv:2311.01677v1 [cs.CL])

    [http://arxiv.org/abs/2311.01677](http://arxiv.org/abs/2311.01677)

    本文提出了DialogBench，一个对话评估基准，用于评估LLMs作为人类对话系统的能力。通过对28个LLMs的广泛测试，发现指导微调对提升性能效果显著。

    

    大型语言模型(LLMs)在新的对话能力方面取得了显著突破，刷新了人们对对话系统的印象。对话系统长期以来的目标是足够像人类，以便通过满足交流、情感和社交归属的需要与用户建立长期联系。因此，迫切需要评估LLMs作为人类对话系统的能力。本文提出了DialogBench，一个对话评估基准，目前包含12个对话任务，评估LLMs作为人类对话系统应具备的能力。具体来说，我们使用GPT-4生成每个任务的评估实例。我们首先根据广泛使用的设计原则设计基本提示，并进一步减轻现有的偏见，生成更高质量的评估实例。我们对28个LLMs进行了广泛的测试（包括预训练和监督指导调优），结果显示指导微调效益显著。

    Large language models (LLMs) have achieved remarkable breakthroughs in new dialogue capabilities, refreshing human's impressions on dialogue systems. The long-standing goal of dialogue systems is to be human-like enough to establish long-term connections with users by satisfying the need for communication, affection and social belonging. Therefore, there has been an urgent need to evaluate LLMs as human-like dialogue systems. In this paper, we propose DialogBench, a dialogue evaluation benchmark that currently contains $12$ dialogue tasks to assess the capabilities of LLMs as human-like dialogue systems should have. Specifically, we prompt GPT-4 to generate evaluation instances for each task. We first design the basic prompt based on widely-used design principles and further mitigate the existing biases to generate higher-quality evaluation instances. Our extensive test over $28$ LLMs (including pre-trained and supervised instruction-tuning) shows that instruction fine-tuning benefits 
    
[^124]: 会话式金融信息检索模型（ConFIRM）

    Conversational Financial Information Retrieval Model (ConFIRM). (arXiv:2310.13001v1 [cs.IR])

    [http://arxiv.org/abs/2310.13001](http://arxiv.org/abs/2310.13001)

    ConFIRM是一种会话式金融信息检索模型，通过合成金融领域特定问答对和评估参数微调方法，实现了超过90%的准确性，为金融对话系统提供了数据高效的解决方案。

    

    随着大型语言模型（LLM）的指数级增长，利用它们在金融等专门领域的新兴特性具有探索的价值。然而，金融等受监管领域具有独特的约束条件，需要具备针对该领域的优化框架。我们提出了ConFIRM，一种基于LLM的会话式金融信息检索模型，用于查询意图分类和知识库标记。ConFIRM包括两个模块：1）一种合成金融领域特定问答对的方法，以及2）评估参数高效的微调方法来进行查询分类任务。我们生成了一个包含4000多个样本的数据集，并在单独的测试集上评估了准确性。ConFIRM实现了超过90%的准确性，这对于符合监管要求至关重要。ConFIRM提供了一种数据高效的解决方案，用于提取金融对话系统的精确查询意图。

    With the exponential growth in large language models (LLMs), leveraging their emergent properties for specialized domains like finance merits exploration. However, regulated fields such as finance pose unique constraints, requiring domain-optimized frameworks. We present ConFIRM, an LLM-based conversational financial information retrieval model tailored for query intent classification and knowledge base labeling.  ConFIRM comprises two modules:  1) a method to synthesize finance domain-specific question-answer pairs, and  2) evaluation of parameter efficient fine-tuning approaches for the query classification task. We generate a dataset of over 4000 samples, assessing accuracy on a separate test set.  ConFIRM achieved over 90% accuracy, essential for regulatory compliance. ConFIRM provides a data-efficient solution to extract precise query intent for financial dialog systems.
    
[^125]: GTA：一种面向几何的多视图Transformer的注意力机制

    GTA: A Geometry-Aware Attention Mechanism for Multi-View Transformers. (arXiv:2310.10375v1 [cs.CV])

    [http://arxiv.org/abs/2310.10375](http://arxiv.org/abs/2310.10375)

    提出了一种面向几何的注意力机制（GTA），用于将几何结构编码为相对变换，从而改进了多视图Transformer的学习效率和性能。

    

    随着transformers对输入标记的排列具有等变性，对标记的位置信息进行编码对许多任务是必要的。然而，由于现有的位置编码方案最初是为自然语言处理任务设计的，对于通常在其数据中表现出不同结构特性的视觉任务来说，它们的适用性值得怀疑。我们认为现有的位置编码方案对于3D视觉任务来说是次优的，因为它们不尊重其底层的3D几何结构。基于这个假设，我们提出了一种面向几何的注意力机制，它将标记的几何结构编码为由查询和键值对之间的几何关系所确定的相对变换。通过在稀疏宽基线多视图设置中评估多个新颖视图合成（NVS）数据集，我们展示了我们的注意力机制——几何变换注意力（GTA）如何提高了最先进的Transformer的学习效率和性能。

    As transformers are equivariant to the permutation of input tokens, encoding the positional information of tokens is necessary for many tasks. However, since existing positional encoding schemes have been initially designed for NLP tasks, their suitability for vision tasks, which typically exhibit different structural properties in their data, is questionable. We argue that existing positional encoding schemes are suboptimal for 3D vision tasks, as they do not respect their underlying 3D geometric structure. Based on this hypothesis, we propose a geometry-aware attention mechanism that encodes the geometric structure of tokens as relative transformation determined by the geometric relationship between queries and key-value pairs. By evaluating on multiple novel view synthesis (NVS) datasets in the sparse wide-baseline multi-view setting, we show that our attention, called Geometric Transform Attention (GTA), improves learning efficiency and performance of state-of-the-art transformer-b
    
[^126]: 通过基于文本的分解解释CLIP图像表示

    Interpreting CLIP's Image Representation via Text-Based Decomposition. (arXiv:2310.05916v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2310.05916](http://arxiv.org/abs/2310.05916)

    本文通过解析CLIP图像编码器的组件，揭示了图像表示的构成方式，并利用文本表示解释了其各个部分的作用。通过理解注意力头和图像块，作者实现了对模型的修复和改进，包括消除误特征和构建零样本图像分割器等方面。

    

    本文通过分析个别模型组件对最终表示的影响，探讨了CLIP图像编码器。我们将图像表示分解为各个图像块、模型层和注意力头的求和，并使用CLIP的文本表示来解释这些求和项。通过解释注意力头，我们通过自动寻找能够跨越输出空间的文本表示来表征每个头的作用，揭示出许多头的特定属性角色（例如位置或形状）。接下来，通过解释图像块，我们揭示了CLIP中的紧密空间定位。最后，我们利用这一理解消除了CLIP中的误特征，并创建了一个强大的零样本图像分割器。我们的结果表明，可扩展的对Transformer模型的理解是可实现的，并可用于修复和改进模型。

    We investigate the CLIP image encoder by analyzing how individual model components affect the final representation. We decompose the image representation as a sum across individual image patches, model layers, and attention heads, and use CLIP's text representation to interpret the summands. Interpreting the attention heads, we characterize each head's role by automatically finding text representations that span its output space, which reveals property-specific roles for many heads (e.g. location or shape). Next, interpreting the image patches, we uncover an emergent spatial localization within CLIP. Finally, we use this understanding to remove spurious features from CLIP and to create a strong zero-shot image segmenter. Our results indicate that a scalable understanding of transformer models is attainable and can be used to repair and improve models.
    
[^127]: 探索Hugging Face和其他模型仓库中预训练深度学习模型的命名惯例（及缺陷）

    Exploring Naming Conventions (and Defects) of Pre-trained Deep Learning Models in Hugging Face and Other Model Hubs. (arXiv:2310.01642v1 [cs.SE])

    [http://arxiv.org/abs/2310.01642](http://arxiv.org/abs/2310.01642)

    本研究首次系统研究了预训练深度学习模型的命名惯例和相关缺陷，为我们了解研究到实践过程提供了知识和认识。

    

    随着深度学习的创新不断推进，许多工程师希望将预训练深度学习模型（PTMs）作为计算系统的组成部分。PTMs是研究到实践的流程的一部分：研究人员发布PTMs，工程师根据质量或性能进行调整并部署。如果PTM的作者为其选择适当的名称，可以促进模型的发现和复用。然而，先前的研究已经报道了模型名称并不总是选择得很好，有时甚至是错误的。PTM包的命名惯例和命名缺陷尚未得到系统的研究，了解它们将增加我们对PTM包的研究到实践过程运作方式的认识。本文报告了对PTM命名惯例及相关命名缺陷的首次研究。我们定义了PTM包名称的组成部分，包括元数据中的包名称和声明的架构。我们展示了第一项旨在描述PTM命名性质的研究。

    As innovation in deep learning continues, many engineers want to adopt Pre-Trained deep learning Models (PTMs) as components in computer systems. PTMs are part of a research-to-practice pipeline: researchers publish PTMs, which engineers adapt for quality or performance and then deploy. If PTM authors choose appropriate names for their PTMs, it could facilitate model discovery and reuse. However, prior research has reported that model names are not always well chosen, and are sometimes erroneous. The naming conventions and naming defects for PTM packages have not been systematically studied - understanding them will add to our knowledge of how the research-to-practice process works for PTM packages  In this paper, we report the first study of PTM naming conventions and the associated PTM naming defects. We define the components of a PTM package name, comprising the package name and claimed architecture from the metadata. We present the first study focused on characterizing the nature o
    
[^128]: 通过密集实例分割在肾脏活检结构评估方面的进展

    Advances in Kidney Biopsy Structural Assessment through Dense Instance Segmentation. (arXiv:2309.17166v1 [cs.CV])

    [http://arxiv.org/abs/2309.17166](http://arxiv.org/abs/2309.17166)

    这项研究提出了一种基于密集实例分割的肾脏活检结构评估的方法，能够自动统计解剖结构上的统计数据，从而减少工作量和观察者间变异性。

    

    肾脏活检是肾脏疾病诊断的金标准。专家肾脏病理学家制定的病变评分是半定量的，并且存在高的观察者间变异性。因此，通过对分割的解剖对象进行自动统计可以显著减少工作量和这种观察者间变异性。然而，活检的实例分割是一个具有挑战性的问题，原因有：（a）平均数量较大（约300至1000个）密集接触的解剖结构，（b）具有多个类别（至少3个），（c）尺寸和形状各异。目前使用的实例分割模型不能以高效通用的方式同时解决这些挑战。在本文中，我们提出了第一个不需要锚点的实例分割模型，该模型将扩散模型、变换器模块和RCNN（区域卷积神经网络）结合起来。我们的模型在一台NVIDIA GeForce RTX 3090 GPU上进行训练，但可以提供可观的结果。

    The kidney biopsy is the gold standard for the diagnosis of kidney diseases. Lesion scores made by expert renal pathologists are semi-quantitative and suffer from high inter-observer variability. Automatically obtaining statistics per segmented anatomical object, therefore, can bring significant benefits in reducing labor and this inter-observer variability. Instance segmentation for a biopsy, however, has been a challenging problem due to (a) the on average large number (around 300 to 1000) of densely touching anatomical structures, (b) with multiple classes (at least 3) and (c) in different sizes and shapes. The currently used instance segmentation models cannot simultaneously deal with these challenges in an efficient yet generic manner. In this paper, we propose the first anchor-free instance segmentation model that combines diffusion models, transformer modules, and RCNNs (regional convolution neural networks). Our model is trained on just one NVIDIA GeForce RTX 3090 GPU, but can 
    
[^129]: 作为有效抽象的归纳偏好的关系瓶颈

    The Relational Bottleneck as an Inductive Bias for Efficient Abstraction. (arXiv:2309.06629v1 [cs.AI])

    [http://arxiv.org/abs/2309.06629](http://arxiv.org/abs/2309.06629)

    本文介绍了一种新的归纳偏好方法——关系瓶颈，用于有效地诱导抽象概念的模型，强调了其在人类思维和大脑中抽象概念习得中的潜力。

    

    认知科学的一个核心挑战是解释如何从有限经验中获取抽象概念。这一努力常常被描述为经验主义和天赋主义方法之间的二分法，最近主要体现在有关深度神经网络和符号认知模型的争论中。在这里，我们强调了一种最近兴起的工作线路，该线路通过利用我们称之为关系瓶颈的归纳偏好，提出了这些方法的一种新的调和方式。我们回顾了一系列采用这种方法在数据有效的方式下诱导出抽象的模型，强调了它们作为人类思维和大脑中抽象概念习得的候选模型的潜力。

    A central challenge for cognitive science is to explain how abstract concepts are acquired from limited experience. This effort has often been framed in terms of a dichotomy between empiricist and nativist approaches, most recently embodied by debates concerning deep neural networks and symbolic cognitive models. Here, we highlight a recently emerging line of work that suggests a novel reconciliation of these approaches, by exploiting an inductive bias that we term the relational bottleneck. We review a family of models that employ this approach to induce abstractions in a data-efficient manner, emphasizing their potential as candidate models for the acquisition of abstract concepts in the human mind and brain.
    
[^130]: RLSynC: 离线-在线强化学习用于合成方法的合成物补全

    RLSynC: Offline-Online Reinforcement Learning for Synthon Completion. (arXiv:2309.02671v1 [cs.LG])

    [http://arxiv.org/abs/2309.02671](http://arxiv.org/abs/2309.02671)

    RLSynC是一种离线-在线强化学习方法，用于半模板化逆向合成中的合成物补全。它使用多个代理同时完成合成物的补全，并通过正向合成模型评估反应物的合成能力来指导行动搜索。

    

    逆向合成是确定能够反应形成所需产物的一组反应物分子的过程。半模板化逆向合成方法首先预测产物中的反应中心，然后将生成的合成物重新补全成反应物。这些方法能够提供必要的可解释性和高实用性，以指导合成规划。我们开发了一种新的离线-在线强化学习方法RLSynC，用于半模板化方法中的合成物补全。RLSynC为每个合成物分配一个代理，所有代理都通过同步进行逐步行动，完成合成物的补全。RLSynC通过同时进行离线训练和在线交互来学习策略，从而可以探索新的反应空间。RLSynC使用正向合成模型来评估预测的反应物在合成产物时的可能性，从而指导行动搜索。

    Retrosynthesis is the process of determining the set of reactant molecules that can react to form a desired product. Semi-template-based retrosynthesis methods, which imitate the reverse logic of synthesis reactions, first predict the reaction centers in the products, and then complete the resulting synthons back into reactants. These methods enable necessary interpretability and high practical utility to inform synthesis planning. We develop a new offline-online reinforcement learning method RLSynC for synthon completion in semi-template-based methods. RLSynC assigns one agent to each synthon, all of which complete the synthons by conducting actions step by step in a synchronized fashion. RLSynC learns the policy from both offline training episodes and online interactions which allow RLSynC to explore new reaction spaces. RLSynC uses a forward synthesis model to evaluate the likelihood of the predicted reactants in synthesizing a product, and thus guides the action search. We compare 
    
[^131]: 用于计算深度神经网络正则化路径的多目标延续方法

    A multiobjective continuation method to compute the regularization path of deep neural networks. (arXiv:2308.12044v1 [cs.LG])

    [http://arxiv.org/abs/2308.12044](http://arxiv.org/abs/2308.12044)

    本文提出了一种多目标延续方法，用于计算深度神经网络的正则化路径，以解决DNNs中稀疏性和数值效率之间的冲突。

    

    稀疏性是深度神经网络(DNNs)中非常理想的特征，因为它确保了数值效率，提高了模型的可解释性(由于相关特征的数量较少)和鲁棒性。在基于线性模型的机器学习方法中，众所周知在$\ell^1$范数(即零权重)的最稀疏解和非正则化解之间存在一条连接路径，这条路径被称为正则化路径。最近，通过将经验损失和稀疏性($\ell^1$范数)作为两个冲突的标准，并解决由此产生的多目标优化问题，首次尝试将正则化路径的概念扩展到DNNs。然而，由于$\ell^1$范数的不光滑性和参数数量的高度，从计算的角度来看，这种方法并不是很有效。为了克服这个限制，我们提出了一种算法，可以近似计算整个帕累托曲线

    Sparsity is a highly desired feature in deep neural networks (DNNs) since it ensures numerical efficiency, improves the interpretability of models (due to the smaller number of relevant features), and robustness. In machine learning approaches based on linear models, it is well known that there exists a connecting path between the sparsest solution in terms of the $\ell^1$ norm (i.e., zero weights) and the non-regularized solution, which is called the regularization path. Very recently, there was a first attempt to extend the concept of regularization paths to DNNs by means of treating the empirical loss and sparsity ($\ell^1$ norm) as two conflicting criteria and solving the resulting multiobjective optimization problem. However, due to the non-smoothness of the $\ell^1$ norm and the high number of parameters, this approach is not very efficient from a computational perspective. To overcome this limitation, we present an algorithm that allows for the approximation of the entire Pareto
    
[^132]: 梯度反击：如何滤除高频率提高解释性

    Gradient strikes back: How filtering out high frequencies improves explanations. (arXiv:2307.09591v1 [cs.AI])

    [http://arxiv.org/abs/2307.09591](http://arxiv.org/abs/2307.09591)

    本研究发现，基于预测的属性方法与基于梯度的方法产生的属性图具有不同的高频内容，滤除高频率可以提高解释性。

    

    近年来，新型基于预测的属性方法的发展迅猛，逐渐取代了旧的基于梯度的方法来解释深度神经网络的决策。然而，预测型方法为何优于梯度型方法仍不清楚。本文从经验观察开始：这两种方法产生的属性图具有非常不同的功率谱，梯度型方法揭示了比预测型方法更多的高频内容。这一观察引发了多个问题：这种高频信息的来源是什么，它是否真正反映了系统所作出的决策？最后，为什么在多个评价指标下，预测型方法中缺乏高频信息将产生更好的可解释性分数？我们分析了三个代表性的视觉分类模型的梯度，并观察到它包含来自高频的噪声信息。

    Recent years have witnessed an explosion in the development of novel prediction-based attribution methods, which have slowly been supplanting older gradient-based methods to explain the decisions of deep neural networks. However, it is still not clear why prediction-based methods outperform gradient-based ones. Here, we start with an empirical observation: these two approaches yield attribution maps with very different power spectra, with gradient-based methods revealing more high-frequency content than prediction-based methods. This observation raises multiple questions: What is the source of this high-frequency information, and does it truly reflect decisions made by the system? Lastly, why would the absence of high-frequency information in prediction-based methods yield better explainability scores along multiple metrics? We analyze the gradient of three representative visual classification models and observe that it contains noisy information emanating from high-frequencies. Furthe
    
[^133]: 面向NILM的多标签分类的可持续深度学习

    Towards Sustainable Deep Learning for Multi-Label Classification on NILM. (arXiv:2307.09244v1 [cs.LG])

    [http://arxiv.org/abs/2307.09244](http://arxiv.org/abs/2307.09244)

    本研究提出了一种面向NILM的新型深度学习模型，通过改进计算和能源效率，实现了对NILM的多标签分类的增强。同时，还提出了一种测试方法，可以比较不同模型在虚拟数据集上的性能。

    

    非侵入式负载监测（NILM）是从单个计量点获取家庭或企业总电力消耗的电器级数据的过程。电器级数据可以直接用于需求响应应用、能源管理系统以及提高能效和减少碳足迹的意识提高和激励。最近，经典机器学习和深度学习（DL）技术在NILM分类中变得非常流行，并证明在增长的复杂性下对NILM分类非常有效，但随着复杂度的增加，这些方法在训练和操作过程中面临着显著的计算和能源需求。在本文中，我们引入了一种新的DL模型，旨在通过提高计算和能源效率来增强NILM的多标签分类。我们还提出了一种用于使用从测量数据集合成的数据比较不同模型的测试方法。

    Non-intrusive load monitoring (NILM) is the process of obtaining appliance-level data from a single metering point, measuring total electricity consumption of a household or a business. Appliance-level data can be directly used for demand response applications and energy management systems as well as for awareness raising and motivation for improvements in energy efficiency and reduction in the carbon footprint. Recently, classical machine learning and deep learning (DL) techniques became very popular and proved as highly effective for NILM classification, but with the growing complexity these methods are faced with significant computational and energy demands during both their training and operation. In this paper, we introduce a novel DL model aimed at enhanced multi-label classification of NILM with improved computation and energy efficiency. We also propose a testing methodology for comparison of different models using data synthesized from the measurement datasets so as to better 
    
[^134]: 推理还是背诵？通过反事实任务探索语言模型的能力和限制

    Reasoning or Reciting? Exploring the Capabilities and Limitations of Language Models Through Counterfactual Tasks. (arXiv:2307.02477v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.02477](http://arxiv.org/abs/2307.02477)

    通过反事实任务的研究，我们发现当前的语言模型具备一定的抽象推理能力，但它们在任务求解过程中往往也依赖于狭窄、难以转移的过程，这对语言模型的性能解释和理解有着重要的启示。

    

    最近语言模型在各种任务上的出色表现表明它们具备一定程度的抽象推理能力。这些能力是通用且可转移的，还是专门针对预训练过程中遇到的特定任务？为了分开这些效果，我们提出了一个评估框架，基于“反事实”任务变种，这些变种与支撑标准任务的默认假设有所偏离。在一套包含11个任务的实验中，我们观察到反事实变种的非平凡性能，但与默认条件相比，性能显著而持续地下降。这表明当前的语言模型可能在一定程度上具备抽象任务求解能力，但它们通常也依赖于狭窄、难以转移的任务求解过程。这些结果促使我们对语言模型性能进行更加谨慎的解释，以区分这些行为方面。

    The impressive performance of recent language models across a wide range of tasks suggests that they possess a degree of abstract reasoning skills. Are these skills general and transferable, or specialized to specific tasks seen during pretraining? To disentangle these effects, we propose an evaluation framework based on "counterfactual" task variants that deviate from the default assumptions underlying standard tasks. Across a suite of 11 tasks, we observe nontrivial performance on the counterfactual variants, but nevertheless find that performance substantially and consistently degrades compared to the default conditions. This suggests that while current LMs may possess abstract task-solving skills to a degree, they often also rely on narrow, non-transferable procedures for task-solving. These results motivate a more careful interpretation of language model performance that teases apart these aspects of behavior.
    
[^135]: 水下航行器船体的样本高效和基于代理的设计优化

    Sample-Efficient and Surrogate-Based Design Optimization of Underwater Vehicle Hulls. (arXiv:2304.12420v1 [cs.LG])

    [http://arxiv.org/abs/2304.12420](http://arxiv.org/abs/2304.12420)

    该论文使用了高效的样本集优化和基于代理的方法来设计水下航行器船体，其中代理模型显著提高了计算效率，使优化更加快速准确。

    

    物理模拟是计算机辅助设计(CAD)优化过程中的一个计算瓶颈。因此，为了使精确(计算昂贵)的模拟可用于设计优化中，需要一个高样本效率的优化框架或快速的数据驱动代理(代理模型)来代替长时间运行的模拟。在这项工作中，我们利用最近优化和人工智能(AI)的进展来解决这两个潜在的解决方案，以设计一个最佳的无人水下航行器(UUV)。我们首先研究并比较了不同优化技术在优化循环中与标准计算流体力学(CFD)求解器相结合时的样本效率和收敛行为。然后，我们开发了一个基于深度神经网络(DNN)的代理模型来逼近否则通过CFD求解器进行计算的阻力。代理模型进而用于样本高效的优化框架中，该框架在不使用代理模型的情况下优于标准优化方法。

    Physics simulations are a computational bottleneck in computer-aided design (CAD) optimization processes. Hence, in order to make accurate (computationally expensive) simulations feasible for use in design optimization, one requires either an optimization framework that is highly sample-efficient or fast data-driven proxies (surrogate models) for long running simulations. In this work, we leverage recent advances in optimization and artificial intelligence (AI) to address both of these potential solutions, in the context of designing an optimal unmanned underwater vehicle (UUV). We first investigate and compare the sample efficiency and convergence behavior of different optimization techniques with a standard computational fluid dynamics (CFD) solver in the optimization loop. We then develop a deep neural network (DNN) based surrogate model to approximate drag forces that would otherwise be computed via direct numerical simulation with the CFD solver. The surrogate model is in turn use
    
[^136]: 安全可解释机器人规划

    Safe Explicable Robot Planning. (arXiv:2304.03773v1 [cs.RO])

    [http://arxiv.org/abs/2304.03773](http://arxiv.org/abs/2304.03773)

    安全可解释机器人规划方法（SEP）扩展了可解释规划，支持安全界限的规定，以实现安全和可解释之间的权衡。

    

    人们的期望源自于他们对其他人和世界的了解。在涉及到人机交互的情况下，对机器人的了解可能与现实不符，导致机器人不能满足人们的期望。可解释规划被引入作为一种新颖的规划方法，以协调人类期望和最优机器人行为，进行更可解释的机器人决策。一个关键的问题尚未得到解决，那就是在可解释决策过程中的安全性问题，这可能会导致不安全的可解释行为。我们提出了安全可解释规划（SEP），它扩展了可解释规划，支持安全界限的规定。 SEP的目标是找到一种策略，生成接近于人类期望的行为，同时满足安全约束的要求。这是多目标优化的一种特殊情况，SEP的解决方案位于帕累托前沿，提供了一个切实可行的解决方案，在不牺牲任何方面的重要性的前提下，产生了安全性和解释性之间的一个权衡。

    Human expectations stem from their knowledge of the others and the world. Where human-robot interaction is concerned, such knowledge about the robot may be inconsistent with the ground truth, resulting in the robot not meeting its expectations. Explicable planning was previously introduced as a novel planning approach to reconciling human expectations and the optimal robot behavior for more interpretable robot decision-making. One critical issue that remains unaddressed is safety during explicable decision-making which can lead to explicable behaviors that are unsafe. We propose Safe Explicable Planning (SEP), which extends explicable planning to support the specification of a safety bound. The objective of SEP is to find a policy that generates a behavior close to human expectations while satisfying the safety constraints introduced by the bound, which is a special case of multi-objective optimization where the solution to SEP lies on the Pareto frontier. Under such a formulation, we 
    
[^137]: 基于单次学习的历史手稿文本检测方法 OTS

    OTS: A One-shot Learning Approach for Text Spotting in Historical Manuscripts. (arXiv:2304.00746v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2304.00746](http://arxiv.org/abs/2304.00746)

    提出了一种基于单次学习的历史手稿文本检测方法 OTS， 尤其对于低资源检测任务，使用新型的“环形损失”损失函数提高了检测能力，同时创建了包含古代东巴象形文字的手稿数据集。

    

    历史手稿处理面临有限的注释训练数据和新类别出现等挑战。为解决这一问题，我们提出了一种基于单次学习的文本检测方法 OTS，通过仅一个注释样本，准确可靠地检测出新颖字符。灵感源自认知研究，引入空间对齐模块，基于一个支持图像发现、关注和学习查询图像中最具有区别性的空间区域。尤其是，针对低资源检测任务通常面临样本不平衡问题，我们提出了一种名为“环形损失”的新型损失函数，可以使距离度量的嵌入空间更具有区分性。该方法高效，只需要少量的训练样本，具有处理新颖字符和符号的显著能力。为了增强数据集的多样性，我们创建了一个包含古代东巴象形文字（DBH）的手稿数据集。

    Historical manuscript processing poses challenges like limited annotated training data and novel class emergence. To address this, we propose a novel One-shot learning-based Text Spotting (OTS) approach that accurately and reliably spots novel characters with just one annotated support sample. Drawing inspiration from cognitive research, we introduce a spatial alignment module that finds, focuses on, and learns the most discriminative spatial regions in the query image based on one support image. Especially, since the low-resource spotting task often faces the problem of example imbalance, we propose a novel loss function called torus loss which can make the embedding space of distance metric more discriminative. Our approach is highly efficient and requires only a few training samples while exhibiting the remarkable ability to handle novel characters, and symbols. To enhance dataset diversity, a new manuscript dataset that contains the ancient Dongba hieroglyphics (DBH) is created. We
    
[^138]: 在联邦深度学习中优化批标准化

    Making Batch Normalization Great in Federated Deep Learning. (arXiv:2303.06530v1 [cs.LG])

    [http://arxiv.org/abs/2303.06530](http://arxiv.org/abs/2303.06530)

    本文研究了在联邦学习中使用批标准化和群组归一化的效果，发现在适当的处理下，批标准化可以在广泛的联邦学习设置中具有很高的竞争力，而且这不需要额外的训练或通信成本。

    This paper studies the use of batch normalization and group normalization in federated learning, and finds that with proper treatments, batch normalization can be highly competitive across a wide range of federated learning settings, and this requires no additional training or communication costs.

    批标准化（BN）通常用于现代深度神经网络（DNN）中，以提高稳定性并加速集中式训练的收敛速度。在具有非IID分散数据的联邦学习（FL）中，先前的研究观察到使用BN进行训练可能会由于训练和测试之间的BN统计不匹配而阻碍性能。因此，群组归一化（GN）更常用于FL作为BN的替代方法。然而，通过我们在各种FL设置下的实证研究，我们发现BN和GN之间没有一致的优胜者。这促使我们重新审视FL中归一化层的使用。我们发现，在适当的处理下，BN可以在广泛的FL设置中具有很高的竞争力，而且这不需要额外的训练或通信成本。我们希望我们的研究可以成为FL未来实际使用和理论分析的有价值参考。

    Batch Normalization (BN) is commonly used in modern deep neural networks (DNNs) to improve stability and speed up convergence during centralized training. In federated learning (FL) with non-IID decentralized data, previous works observed that training with BN could hinder performance due to the mismatch of the BN statistics between training and testing. Group Normalization (GN) is thus more often used in FL as an alternative to BN. However, from our empirical study across various FL settings, we see no consistent winner between BN and GN. This leads us to revisit the use of normalization layers in FL. We find that with proper treatments, BN can be highly competitive across a wide range of FL settings, and this requires no additional training or communication costs. We hope that our study could serve as a valuable reference for future practical usage and theoretical analysis in FL.
    
[^139]: 正样本未标记对比学习

    Positive Unlabeled Contrastive Learning. (arXiv:2206.01206v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.01206](http://arxiv.org/abs/2206.01206)

    我们提出了一种正样本未标记对比学习的新方法，通过扩展对比损失和使用PU特定聚类方案，该方法在PU任务中学习到了优秀的表示，并在多个标准数据集上明显优于现有方法。

    

    自我监督预训练无标签数据，然后在标记数据上进行监督微调是一种常见的从有限标记样本中学习的方法。我们将这个方法扩展到经典的正样本未标记（PU）设置，其中的任务是仅通过一些标记为正样本和（通常）大量的未标记样本（可以是正样本或负样本）来学习二分类器。我们首先对标准infoNCE对比损失的家族提出了一个简单的扩展，适用于PU设置；并且证明相比于现有的无监督和有监督方法，这种方法学习到了更好的表示。然后，我们开发了一种简单的方法，使用新的PU特定聚类方案为未标记样本构建伪标签；这些伪标签可以用来训练最终的（正样本 vs. 负样本）分类器。我们的方法在几个标准PU基准数据集上明显优于现有的PU方法，并且不需要任何类别的先验知识。

    Self-supervised pretraining on unlabeled data followed by supervised fine-tuning on labeled data is a popular paradigm for learning from limited labeled examples. We extend this paradigm to the classical positive unlabeled (PU) setting, where the task is to learn a binary classifier given only a few labeled positive samples, and (often) a large amount of unlabeled samples (which could be positive or negative).  We first propose a simple extension of standard infoNCE family of contrastive losses, to the PU setting; and show that this learns superior representations, as compared to existing unsupervised and supervised approaches. We then develop a simple methodology to pseudo-label the unlabeled samples using a new PU-specific clustering scheme; these pseudo-labels can then be used to train the final (positive vs. negative) classifier. Our method handily outperforms state-of-the-art PU methods over several standard PU benchmark datasets, while not requiring a-priori knowledge of any clas
    

