# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Neural Progressive Meshes.](http://arxiv.org/abs/2308.05741) | 本论文提出了一种神经渐进网格方法，通过共享的学习生成空间和逐渐传输额外的残余特征，实现了通过互联网传输大量的3D几何数据。 |
| [^2] | [AudioLDM 2: Learning Holistic Audio Generation with Self-supervised Pretraining.](http://arxiv.org/abs/2308.05734) | 本文提出了一种利用自监督预训练学习方法进行语音、音乐和音效生成的框架，通过引入通用音频表示LOA，将任何音频转换为LOA，并利用以LOA为条件的潜在扩散模型进行自监督音频生成学习。 |
| [^3] | [PDE-Refiner: Achieving Accurate Long Rollouts with Neural PDE Solvers.](http://arxiv.org/abs/2308.05732) | PDE-Refiner 是一种利用多步细化过程准确建模所有频率分量的神经PDE求解器，能够在长时间范围内提供稳定、准确的预测。 |
| [^4] | [Rethinking Integration of Prediction and Planning in Deep Learning-Based Automated Driving Systems: A Review.](http://arxiv.org/abs/2308.05731) | 这项综述重新思考了基于深度学习的自动驾驶系统中预测和规划的整合问题，提出了将其作为相互依赖的联合步骤来提高安全性、效率性和舒适性的必要性。 |
| [^5] | [Testing GPT-4 with Wolfram Alpha and Code Interpreter plug-ins on math and science problems.](http://arxiv.org/abs/2308.05713) | 本研究测试了GPT-4在科学和数学问题上使用Wolfram Alpha和Code Interpreter插件的效果，结果表明插件显著提升了GPT的问题解决能力，但接口故障仍然是其可靠性的主要挑战。 |
| [^6] | [Exploring the Potential of World Models for Anomaly Detection in Autonomous Driving.](http://arxiv.org/abs/2308.05701) | 本文探讨了在自动驾驶领域利用世界模型进行异常检测的潜力，并提供了相关研究的概述和组成部分的联系。 |
| [^7] | [SSLRec: A Self-Supervised Learning Library for Recommendation.](http://arxiv.org/abs/2308.05697) | SSLRec是一个自监督学习的推荐系统库，为评估各种SSL增强推荐系统提供了标准化、灵活和综合的框架。 |
| [^8] | [Hard No-Box Adversarial Attack on Skeleton-Based Human Action Recognition with Skeleton-Motion-Informed Gradient.](http://arxiv.org/abs/2308.05681) | 本文针对基于骨骼的人体动作识别方法的脆弱性进行了研究，提出了一种新的硬性无盒对抗攻击方法，通过学习运动流形和定义骨骼-动作知情梯度来攻击模型，揭示了这种脆弱性的存在。 |
| [^9] | [Exploring Deep Learning Approaches to Predict Person and Vehicle Trips: An Analysis of NHTS Data.](http://arxiv.org/abs/2308.05665) | 本研究利用深度学习技术分析了NHTS数据，开发了一个能够准确预测人员和车辆出行的模型，并取得了98%的准确率。这对传统交通规划模型的性能来说是一个显著的提升。 |
| [^10] | [Automatic Extraction of Relevant Road Infrastructure using Connected vehicle data and Deep Learning Model.](http://arxiv.org/abs/2308.05658) | 本论文提出了一种使用连接车辆数据和深度学习模型自动提取道路基础设施的新方法。通过将车辆轨迹分段并生成道路段的图像表示，我们利用YOLOv5算法准确分类直线道路段和交叉点。实验结果表明了令人印象深刻的整体准确性。 |
| [^11] | [Updating Clinical Risk Stratification Models Using Rank-Based Compatibility: Approaches for Evaluating and Optimizing Clinician-Model Team Performance.](http://arxiv.org/abs/2308.05619) | 提出了一种基于排名的兼容性度量和一种新的损失函数来更新临床机器学习模型，以解决更新模型引入的兼容性问题。在使用MIMIC数据的病死率风险分层案例研究中，该方法相对于现有技术能产生更兼容的模型并保持判别性能。 |
| [^12] | [A Neural Network Based Choice Model for Assortment Optimization.](http://arxiv.org/abs/2308.05617) | 本论文研究了基于神经网络的选择模型是否能够有效地预测购买概率，并解决了如何在这个模型中纳入商品组合效果和优化问题。 |
| [^13] | [A Smart Robotic System for Industrial Plant Supervision.](http://arxiv.org/abs/2308.05612) | 我们提出了一个智能机器人系统，可以自动检查化工生产厂的完整性并提供关键操作条件的有用信息。 |
| [^14] | [Multi-graph Spatio-temporal Graph Convolutional Network for Traffic Flow Prediction.](http://arxiv.org/abs/2308.05601) | 本文提出了一种基于多图空时图卷积网络的方法，用于预测高速公路每日交通流量。通过数据归一化策略处理数据不平衡问题，并利用图卷积网络捕捉空时特征。同时，还使用了气象和日历特征。 |
| [^15] | [Proximal Policy Optimization Actual Combat: Manipulating Output Tokenizer Length.](http://arxiv.org/abs/2308.05585) | 本文介绍了一种使用接近策略优化来操作模型输出标记器长度的方法，在复杂任务中验证了其有效性，并且发现了其他的特性。 |
| [^16] | [Generative Diffusion Models for Radio Wireless Channel Modelling and Sampling.](http://arxiv.org/abs/2308.05583) | 本文提出了一种基于扩散模型的信道抽样方法，用于快速合成有限数据的信道实现，相比于现有的基于 GAN 的方法，该方法训练稳定且能够生成多样化和高质量的信道数据。 |
| [^17] | [C5: Towards Better Conversation Comprehension and Contextual Continuity for ChatGPT.](http://arxiv.org/abs/2308.05567) | C5是一个交互式对话可视化系统，旨在解决多轮对话中的人类遗忘和模型上下文遗忘问题，提升ChatGPT的对话理解和上下文连贯性。 |
| [^18] | [Recent Advancements In The Field Of Deepfake Detection.](http://arxiv.org/abs/2308.05563) | 该论文调查了深度伪造的问题，包括恶意深度伪造的创建和缺乏普适深度伪造检测方法。通过对当前的深度伪造检测方法和进展进行调查和分析，旨在找到最全面、普适的检测方法。 |
| [^19] | [Learning (With) Distributed Optimization.](http://arxiv.org/abs/2308.05548) | 本文回顾了分布式优化技术的历史发展，介绍了增广Lagrange交替方向非精确牛顿(ALADIN)算法以及Alternating Direction Method of Multipliers (ADMM)等方法的改进。同时突出了近端中心方法的应用和ALADIN的独特特点。 |
| [^20] | [Enhancing AUV Autonomy With Model Predictive Path Integral Control.](http://arxiv.org/abs/2308.05547) | 本文研究了在AUV控制中使用模型预测路径积分控制（MPPI）的可行性，并对其性能做了详细评估，在与传统PID和级联PID方法的比较中表现出了优越性。 |
| [^21] | [Models Matter: The Impact of Single-Step Retrosynthesis on Synthesis Planning.](http://arxiv.org/abs/2308.05522) | 本研究通过将多个单步反合成模型应用于多步合成规划，发现单步性能较好并不一定能找到潜在的反应路径，强调了将单步模型与合成规划相结合的重要性。 |
| [^22] | [Mono-hydra: Real-time 3D scene graph construction from monocular camera input with IMU.](http://arxiv.org/abs/2308.05515) | Mono-Hydra是一个实时空间感知系统，通过结合单目相机和IMU传感器，能够实时构建室内场景的3D图。它使用深度学习算法从单目相机输入中推导深度和语义，并采用基于方根信息的机器人视觉惯性测距(VIO)算法来保证准确性和实时性。 |
| [^23] | [Multi-domain Recommendation with Embedding Disentangling and Domain Alignment.](http://arxiv.org/abs/2308.05508) | 该研究提出了一种新的多领域推荐方法EDDA，它通过嵌入解耦推荐器和领域对齐两个关键组件分别解决了知识解耦和跨领域知识转移的挑战。 |
| [^24] | [EFX Allocations Exist for Binary Valuations.](http://arxiv.org/abs/2308.05503) | 本文研究了公平分配问题中的EFX分配的存在性，扩展了之前对二进制和次模估值的结论，提出了一个计算EFX分配的多项式时间算法。 |
| [^25] | [Bringing order into the realm of Transformer-based language models for artificial intelligence and law.](http://arxiv.org/abs/2308.05502) | 本文提供了第一个对基于Transformer的语言模型在法律领域的人工智能问题和任务中的方法的系统概述。文章旨在突出这一领域的研究进展，以进一步了解Transformer在支持法律流程中的AI成功贡献以及当前的局限性。 |
| [^26] | [More Than Meets the Eye: Analyzing Anesthesiologists' Visual Attention in the Operating Room Using Deep Learning Models.](http://arxiv.org/abs/2308.05501) | 使用深度学习模型分析手术室中麻醉师的视觉注意力分布，通过处理监视器装置的摄像头收集连续的行为数据，以及比较了不同的方法。 |
| [^27] | [Exploring XAI for the Arts: Explaining Latent Space in Generative Music.](http://arxiv.org/abs/2308.05496) | 本研究旨在探索XAI在艺术领域的应用。通过使用可解释的生成音乐的潜变量模型，我们通过潜空间正则化、用户界面反馈循环和音乐属性的可视化来增加模型的可解释性。 |
| [^28] | [LLM As DBA.](http://arxiv.org/abs/2308.05481) | LLM变成DBA，提供数据库维护的诊断和优化建议，通过从文本来源中获取经验和多个LLMs的协作诊断。 |
| [^29] | [Reviewing 3D Object Detectors in the Context of High-Resolution 3+1D Radar.](http://arxiv.org/abs/2308.05478) | 这项研究在高分辨率3+1D雷达的背景下，综述了基于深度学习的3D目标检测器。由于3D激光雷达点云与3+1D雷达点云之间的相似性，现有的3D目标检测器可作为基于雷达数据进行深度学习的起点。但为了适应雷达领域，需要对这些现有检测器进行适应性调整。 |
| [^30] | [Explainable AI applications in the Medical Domain: a systematic review.](http://arxiv.org/abs/2308.05411) | 该论文通过文献综述探讨了医学决策支持中可解释的人工智能解决方案的最新发展，结果发现通用模型的XAI技术被广泛采用，深度学习模型被更多使用，解释性被应用于提高信任，但医生的参与仍较少报道。 |
| [^31] | [A Comparative Assessment of Multi-view fusion learning for Crop Classification.](http://arxiv.org/abs/2308.05407) | 本研究比较评估了多视角融合学习在农作物分类中的效果，提出的融合方法优于单一视角和先前方法，根据测试区域选择最佳融合方法。 |
| [^32] | [Enhancing Trust in LLM-Based AI Automation Agents: New Considerations and Future Challenges.](http://arxiv.org/abs/2308.05391) | 本论文研究了基于LLM的AI自动化代理的挑战与机遇，在现有文献中分析了AI代理信任的主要方面，并针对这一新一代自动化代理提出了具体的考虑因素和挑战。最终，强调了研究界面临的几个挑战。 |
| [^33] | [Adaptive Taxonomy Learning and Historical Patterns Modelling for Patent Classification.](http://arxiv.org/abs/2308.05385) | 本文介绍了一种综合考虑专利信息的框架，旨在为专利分类提供更准确的方法。该框架综合了专利的文本描述、权利人信息和IPC代码的相关性，从而为专利分类提供更全面的上下文信息。 |
| [^34] | [Beyond Semantics: Learning a Behavior Augmented Relevance Model with Self-supervised Learning.](http://arxiv.org/abs/2308.05379) | 这篇论文提出了一种行为增强的相关模型，利用自我监督学习，通过从用户历史行为数据中提取辅助查询-项目交互，来改进搜索引擎中的查询-项目匹配，提高准确性和鲁棒性。 |
| [^35] | [Trustworthy LLMs: a Survey and Guideline for Evaluating Large Language Models' Alignment.](http://arxiv.org/abs/2308.05374) | 本文介绍了一份关于评估LLM可信度的综合调查，并提供了指导。调查涵盖了可靠性、安全性、公平性、抵抗滥用、可解释性和推理能力、遵守社会规范以及鲁棒性等七个主要类别，共计29个子类别。 |
| [^36] | [Machine Learning aided Computer Architecture Design for CNN Inferencing Systems.](http://arxiv.org/abs/2308.05364) | 本研究提出了一种机器学习辅助的计算机架构设计方法，用于加快卷积神经网络推理系统的设计过程。通过快速而准确地预测CNN在推理过程中的功耗和性能，帮助计算机架构师在早期阶段进行估计，从而减少开发周期。 |
| [^37] | [Metacognitive Prompting Improves Understanding in Large Language Models.](http://arxiv.org/abs/2308.05342) | 元认知提示 (MP) 是一种改进大型语言模型 (LLMs) 理解能力的策略。实验结果表明，使用MP的PaLM在各种自然语言理解任务中接近于GPT-4的性能水平。 |
| [^38] | [Classification of Human- and AI-Generated Texts: Investigating Features for ChatGPT.](http://arxiv.org/abs/2308.05341) | 本研究探索了分类人工智能生成文本与人类生成文本的问题，并研究了在人工智能以难以被人类辨认的方式进行文本生成时的更高级情况。实验结果显示，我们的最佳系统在区分基础和高级人工生成/人工智能生成文本时的F1分数超过96%，在区分基础和高级人工生成/人工智能重新表达文本时的F1分数超过78%。 |
| [^39] | [Adv-Inpainting: Generating Natural and Transferable Adversarial Patch via Attention-guided Feature Fusion.](http://arxiv.org/abs/2308.05320) | 本文提出了一种称为Adv-Inpainting的创新攻击框架，通过注意力引导的特征融合生成自然且可迁移的对抗性贴纸，相比于传统的对抗性贴纸方法，该方法在生成图案和边界方面更加自然，并具有更强的迁移性能。 |
| [^40] | [Homophily-enhanced Structure Learning for Graph Clustering.](http://arxiv.org/abs/2308.05309) | 提出了一种名为HoLe的方法，通过在图结构中增强同类性可以显著改善图聚类任务的性能。 |
| [^41] | [Double-chain Constraints for 3D Human Pose Estimation in Images and Videos.](http://arxiv.org/abs/2308.05298) | DC-GCT是一种新颖的模型，通过双链设计来约束图像和视频中的3D人体姿势估计，它结合了GCN和Transformer的优点，充分捕捉了人体关节之间的多级依赖关系。 |
| [^42] | [Multimodal Pretrained Models for Sequential Decision-Making: Synthesis, Verification, Grounding, and Perception.](http://arxiv.org/abs/2308.05295) | 该论文介绍了一种利用预训练模型的知识来解决序列决策任务的算法，通过构建和验证控制器，并通过视觉观测来与任务环境相连接。 |
| [^43] | [Cross-heterogeneity Graph Few-shot Learning.](http://arxiv.org/abs/2308.05275) | 这项研究提出了一种跨异质图少样本学习模型，通过提取元模式和使用多视图异质图神经网络来捕获异质信息并学习跨异质图的元模式。 |
| [^44] | [AI4GCC -- Track 3: Consumption and the Challenges of Multi-Agent RL.](http://arxiv.org/abs/2308.05260) | AI4GCC竞赛在将机器学习与传统经济政策分析相结合的方向上迈出重要一步。建议改进评估标准，考虑消费/效用，并进一步研究代理的学习动力学及谈判协议的博弈论属性。 |
| [^45] | [Vector quantization loss analysis in VQGANs: a single-GPU ablation study for image-to-image synthesis.](http://arxiv.org/abs/2308.05242) | 本研究通过消融分析研究了图像合成中向量量化生成对抗网络（VQGAN）的影响，集中关注了向量量化损失、码书大小优化和与主成分分析的比较分析。虽然结果未超越现有基准，但对于较小数据集下VQGAN的行为和相关问题提供了重要的启示。 |
| [^46] | [Leveraging the Edge and Cloud for V2X-Based Real-Time Object Detection in Autonomous Driving.](http://arxiv.org/abs/2308.05234) | 本论文研究利用边缘和云端技术实现自动驾驶中的实时物体检测。通过创建合成数据集，评估不同的外部化策略，并使用真实硬件和网络模拟进行比较，找到了权衡预测质量和端到端延迟的最佳方法。 |
| [^47] | [Alexa, play with robot: Introducing the First Alexa Prize SimBot Challenge on Embodied AI.](http://arxiv.org/abs/2308.05221) | 这篇论文介绍了第一届Alexa奖Embibod AI SimBot挑战，它是一个新的挑战，大学团队需要构建能够在模拟物理环境中完成任务的机器人助手。论文总结了挑战的概述和为团队提供的基础设施和支持，以及参与团队的方法。 |
| [^48] | ["Generate" the Future of Work through AI: Empirical Evidence from Online Labor Markets.](http://arxiv.org/abs/2308.05201) | 这项研究通过利用ChatGPT作为外生冲击，揭示了其对在线劳动市场的影响。结果显示，直接接触ChatGPT的任务和自由职业者的交易量显著下降，但适应新技术并提供增强人工智能的服务的自由职业者仍能获得利益。 |
| [^49] | [Hierarchical Representations for Spatio-Temporal Visual Attention Modeling and Understanding.](http://arxiv.org/abs/2308.05189) | 本文研究了基于层次化表示的时空视觉注意力建模和理解，在视频序列中提出了上下文感知的生成概率模型以及用于建模时空视觉注意力和时间领域注意力的深度网络架构。 |
| [^50] | [PromptPaint: Steering Text-to-Image Generation Through Paint Medium-like Interactions.](http://arxiv.org/abs/2308.05184) | PromptPaint是一种结合了文字到图像生成和模拟绘画媒介交互的方法。它允许用户通过混合不同的提示来表达具有挑战性的概念，并支持在生成过程中对图像进行迭代塑造。研究结果表明，PromptPaint提供了一种灵活且强大的方式来生成图像。 |
| [^51] | [Comparative Analysis of Epileptic Seizure Prediction: Exploring Diverse Pre-Processing Techniques and Machine Learning Models.](http://arxiv.org/abs/2308.05176) | 本研究对使用EEG数据进行癫痫发作预测的五种机器学习模型进行了全面比较分析，通过应用多样的预处理技术和优化模型性能，为癫痫病人的有效管理和护理提供了准确且稳健的预测模型。 |
| [^52] | [FPGA Resource-aware Structured Pruning for Real-Time Neural Networks.](http://arxiv.org/abs/2308.05170) | 本文提出了一种FPGA资源感知的实时神经网络结构修剪方法，通过将修剪问题形式化为具有资源感知张量结构的背包问题，解决了修剪过程中非结构化稀疏和负载平衡效率低下的问题。 |
| [^53] | [Data-Free Model Extraction Attacks in the Context of Object Detection.](http://arxiv.org/abs/2308.05127) | 该论文提出了一种在目标检测中进行无数据模型提取的攻击方法，通过使用生成器生成特殊查询，成功实现了对私有数据集上训练的目标模型的窃取。通过定义损失函数和使用新颖的生成器设置，实现了对边界框坐标的预测问题的黑盒攻击。 |
| [^54] | [Balancing Accuracy and Training Time in Federated Learning for Violence Detection in Surveillance Videos: A Study of Neural Network Architectures.](http://arxiv.org/abs/2308.05106) | 本文研究了联邦学习环境下视频暴力检测的机器学习技术以及它们的适应性，通过在联邦学习环境中训练最佳暴力检测模型，实现了比现有模型更好的准确性结果。 |
| [^55] | [Prototypical Kernel Learning and Open-set Foreground Perception for Generalized Few-shot Semantic Segmentation.](http://arxiv.org/abs/2308.04952) | 本研究通过典型核学习和开放集前景感知，解决泛化少样本语义分割中的表示分割和嵌入偏见问题，并且在分割过程中使用了可学习的核以及典型学习和前景上下文感知模块来提高性能。 |
| [^56] | [Cumulative Reasoning With Large Language Models.](http://arxiv.org/abs/2308.04371) | 本文提出了一种名为累积推理（CR）的新方法，利用语言模型以累积和迭代的方式模拟人类思维过程，通过将任务分解为较小的组件，简化问题解决过程，取得了优于现有方法的性能，并在逻辑推理和24点游戏中实现了显著提升。 |
| [^57] | [Apple Vision Pro for Healthcare: "The Ultimate Display"?.](http://arxiv.org/abs/2308.04313) | 苹果推出了Vision Pro，一款具有混合现实和增强现实功能的虚拟现实设备，拥有独特的特点，例如内部屏幕展示佩戴者的眼睛以及数字皇冠按钮的融合功能。这款无线设备可能实现了“终极显示器”的潜力。 |
| [^58] | [Adapting Foundation Models for Information Synthesis of Wireless Communication Specifications.](http://arxiv.org/abs/2308.04033) | 本文介绍了NextGen Communications Copilot，这是一个用于无线通信规范信息综合的对话式人工智能工具。它采用基础模型，并引入了领域特定的数据库、上下文提取器和反馈机制，能够提供准确且相关的上下文信息，并结合专家反馈和数据贡献工具。在基准数据集的评估中，该系统展示了更多的优势。 |
| [^59] | [Guarding the Guardians: Automated Analysis of Online Child Sexual Abuse.](http://arxiv.org/abs/2308.03880) | 这项研究介绍了一种自动化工具，用于全面分析儿童性虐待报告。通过自动化分析和分类，降低了接触有害内容的风险，并利用多学科团队的专业知识进行更深入的分析，以改善对基本模式和趋势的理解，帮助执法部门和决策者制定针对性的政策和行动。 |
| [^60] | [AI-GOMS: Large AI-Driven Global Ocean Modeling System.](http://arxiv.org/abs/2308.03152) | 提出了AI-GOMS，一个大型AI驱动的全球海洋模拟系统，用于准确高效的全球海洋每日预测。 |
| [^61] | [Who Answers It Better? An In-Depth Analysis of ChatGPT and Stack Overflow Answers to Software Engineering Questions.](http://arxiv.org/abs/2308.02312) | 本研究深入分析了ChatGPT和Stack Overflow回答软件工程问题的特点和可用性。结果显示，ChatGPT回答中有52%错误，77%冗长，但由于其综合性和清晰的语言表达，仍然在39.34%的情况下被使用者偏好选择。 |
| [^62] | [Scaling Data Generation in Vision-and-Language Navigation.](http://arxiv.org/abs/2307.15644) | 这项研究提出了一种用于视觉语言导航中生成大规模数据的有效范式。通过利用逼真的环境和网络资源，合成了490万个指令轨迹对。通过使用这个大规模数据集，通过简单的模仿学习，已存在的代理的性能得到了显著提升至80%。 |
| [^63] | [Open Problems in Computer Vision for Wilderness SAR and The Search for Patricia Wu-Murad.](http://arxiv.org/abs/2307.14527) | 该论文介绍了在荒野搜救中应用计算机视觉系统的挑战，提出了使用EfficientDET模型和无监督RX光谱分类器的方法，但在真实世界中存在假阳性的问题。 |
| [^64] | [Revisiting Domain-Adaptive 3D Object Detection by Reliable, Diverse and Class-balanced Pseudo-Labeling.](http://arxiv.org/abs/2307.07944) | 本文通过提出一种适用于多类训练设置的新型ReDB框架来解决现有领域自适应方法在多类训练设置下性能下降的问题，通过产生可靠的、多样化的和类平衡的伪三维框来引导目标领域的自训练。 |
| [^65] | [Structure in Reinforcement Learning: A Survey and Open Problems.](http://arxiv.org/abs/2306.16021) | 这项调查研究了强化学习中结构的角色和重要性，并介绍了各个子领域在提高强化学习的性能方面所做的工作。 |
| [^66] | [Capturing Emerging Complexity in Lenia.](http://arxiv.org/abs/2305.09378) | 研究人工生命平台Lenia，通过识别复杂新兴行为的度量标准和使用遗传算法产生不同行为的结果，以进化出更好的Lenia行为。 |
| [^67] | [CLIP-Count: Towards Text-Guided Zero-Shot Object Counting.](http://arxiv.org/abs/2305.07304) | 该研究提出了CLIP-Count，一种基于零样本文本引导的物体计数方法，不需要对特定对象类别进行微调，通过引入补丁-文本对比损失和分层的patch-text交互模块，获得了高效的密集预测结果。 |
| [^68] | [Near-realtime Facial Animation by Deep 3D Simulation Super-Resolution.](http://arxiv.org/abs/2305.03216) | 该论文提出了一种基于神经网络的3D模拟超分辨率框架，能够高效、逼真地增强低成本、实时物理模拟产生的面部表现，使其接近于具有更高分辨率和准确物理建模的参考质量离线模拟器。 |
| [^69] | [Adaptive Gated Graph Convolutional Network for Explainable Diagnosis of Alzheimer's Disease using EEG Data.](http://arxiv.org/abs/2304.05874) | 本文提出了一种自适应门控图卷积网络(AGGCN)，该网络结合卷积节点特征增强和功能连接度量自适应学习图结构，实现了高精度的阿尔茨海默病诊断，并提供了重要的脑区信息。 |
| [^70] | [Diffusion Denoised Smoothing for Certified and Adversarial Robust Out-Of-Distribution Detection.](http://arxiv.org/abs/2303.14961) | 本研究提出了一个新的方法来证明$\ell_2$-norm下的样本外检测的鲁棒性，在不考虑网络架构和具体组件的情况下，改善了对抗攻击的检测技术。 |
| [^71] | [Let's have a chat! A Conversation with ChatGPT: Technology, Applications, and Limitations.](http://arxiv.org/abs/2302.13817) | 本文讨论了聊天机器人的历史概述以及ChatGPT背后的技术，强调了它在医疗保健、教育和研究中的潜在应用，并指出了其隐私和道德方面的担忧以及当前版本的重要限制。 |
| [^72] | [RobustPdM: Designing Robust Predictive Maintenance against Adversarial Attacks.](http://arxiv.org/abs/2301.10822) | 本文提出了一种设计抗对抗攻击的鲁棒性预测维护系统的方法，通过分析不同类型的对抗性攻击的影响，为预测维护模型提出了一种新颖的对抗性防御技术。 |
| [^73] | [Deep learning-based Crop Row Detection for Infield Navigation of Agri-Robots.](http://arxiv.org/abs/2209.04278) | 本文提出了一种基于深度学习的农机作物行检测算法，能够在农田环境中应对多样的田间条件，通过低成本相机实现作物行检测和导航功能。 |
| [^74] | [Overlooked Implications of the Reconstruction Loss for VAE Disentanglement.](http://arxiv.org/abs/2202.13341) | VAE解纷结果的成因有待重新审视，研究发现数据与重建损失之间的关系是解耦的主要贡献者，标准的基准数据集根据典型的VAE重建损失与感知轴之间存在意外的相关性。 |

# 详细

[^1]: 神经渐进网格

    Neural Progressive Meshes. (arXiv:2308.05741v1 [cs.CV])

    [http://arxiv.org/abs/2308.05741](http://arxiv.org/abs/2308.05741)

    本论文提出了一种神经渐进网格方法，通过共享的学习生成空间和逐渐传输额外的残余特征，实现了通过互联网传输大量的3D几何数据。

    

    最近，可以在手持设备上消费的3D内容的激增需要有效的工具来通过互联网传输大量的几何数据，例如3D网格。详细的高分辨率资源对于存储和传输带宽都是一个挑战，通常使用层次细节技术在适当的带宽预算下传输资源。对于这些方法来说，以渐进的方式传输数据，随着更多数据的加入，改进几何的质量尤其可取。我们的关键观点是，3D网格的几何细节通常在不同的形状之间都呈现出相似的局部模式，因此可以用共享的学习生成空间来有效表示这些细节。我们使用基于细分的编码器-解码器架构提前训练大量表面，在此空间中学习这些细节。我们进一步观察到，在中间细分级别之间可以逐渐传输额外的残余特征，从而实现了渐进式传输和改善几何。

    The recent proliferation of 3D content that can be consumed on hand-held devices necessitates efficient tools for transmitting large geometric data, e.g., 3D meshes, over the Internet. Detailed high-resolution assets can pose a challenge to storage as well as transmission bandwidth, and level-of-detail techniques are often used to transmit an asset using an appropriate bandwidth budget. It is especially desirable for these methods to transmit data progressively, improving the quality of the geometry with more data. Our key insight is that the geometric details of 3D meshes often exhibit similar local patterns even across different shapes, and thus can be effectively represented with a shared learned generative space. We learn this space using a subdivision-based encoder-decoder architecture trained in advance on a large collection of surfaces. We further observe that additional residual features can be transmitted progressively between intermediate levels of subdivision that enable the
    
[^2]: AudioLDM 2: 利用自监督预训练学习进行整体音频生成的方法

    AudioLDM 2: Learning Holistic Audio Generation with Self-supervised Pretraining. (arXiv:2308.05734v1 [cs.SD])

    [http://arxiv.org/abs/2308.05734](http://arxiv.org/abs/2308.05734)

    本文提出了一种利用自监督预训练学习方法进行语音、音乐和音效生成的框架，通过引入通用音频表示LOA，将任何音频转换为LOA，并利用以LOA为条件的潜在扩散模型进行自监督音频生成学习。

    

    虽然音频生成在不同类型的音频中共享一些共性，比如语音、音乐和音效，但为每种类型设计模型需要仔细考虑特定的目标和偏差，这些偏差可能与其他类型的目标有显著的差异。为了更好地实现音频生成的统一视角，本文提出了一种利用相同的学习方法进行语音、音乐和音效生成的框架。我们的框架引入了一种称为“语言音频（LOA）”的音频通用表示。任何音频都可以基于自监督预训练学习模型AudioMAE转换为LOA。在生成过程中，我们使用GPT-2模型将任何形式的音频转换为LOA，并利用以LOA为条件的潜在扩散模型进行自监督音频生成学习。所提出的框架自然地带来了诸如上下文学习能力和可重用的自监督预训练AudioMAE的优势。

    Although audio generation shares commonalities across different types of audio, such as speech, music, and sound effects, designing models for each type requires careful consideration of specific objectives and biases that can significantly differ from those of other types. To bring us closer to a unified perspective of audio generation, this paper proposes a framework that utilizes the same learning method for speech, music, and sound effect generation. Our framework introduces a general representation of audio, called language of audio (LOA). Any audio can be translated into LOA based on AudioMAE, a self-supervised pre-trained representation learning model. In the generation process, we translate any modalities into LOA by using a GPT-2 model, and we perform self-supervised audio generation learning with a latent diffusion model conditioned on LOA. The proposed framework naturally brings advantages such as in-context learning abilities and reusable self-supervised pretrained AudioMAE
    
[^3]: PDE-Refiner: 利用神经PDE求解器实现准确的长时间预测

    PDE-Refiner: Achieving Accurate Long Rollouts with Neural PDE Solvers. (arXiv:2308.05732v1 [cs.LG])

    [http://arxiv.org/abs/2308.05732](http://arxiv.org/abs/2308.05732)

    PDE-Refiner 是一种利用多步细化过程准确建模所有频率分量的神经PDE求解器，能够在长时间范围内提供稳定、准确的预测。

    

    时间相关的偏微分方程在科学和工程中非常普遍。最近，由于传统解法的高计算成本，基于深度神经网络的替代方法引起了极大关注。这些神经PDE求解器的实用价值依赖于它们能够在长时间范围内提供准确、稳定的预测，这是一个相当困难的问题。在本研究中，我们对常见的时间展开策略进行了大规模分析，发现忽略非主导空间频率信息（通常与PDE解中的高频率相关）是限制稳定、准确展开性能的主要陷阱。基于这些洞察，我们借鉴了扩散模型的最新进展，引入了PDE-Refiner；这是一种新颖的模型类别，通过多步细化过程实现对所有频率分量的更准确建模。我们在具有挑战性的基准测试中验证了PDE-Refiner的性能。

    Time-dependent partial differential equations (PDEs) are ubiquitous in science and engineering. Recently, mostly due to the high computational cost of traditional solution techniques, deep neural network based surrogates have gained increased interest. The practical utility of such neural PDE solvers relies on their ability to provide accurate, stable predictions over long time horizons, which is a notoriously hard problem. In this work, we present a large-scale analysis of common temporal rollout strategies, identifying the neglect of non-dominant spatial frequency information, often associated with high frequencies in PDE solutions, as the primary pitfall limiting stable, accurate rollout performance. Based on these insights, we draw inspiration from recent advances in diffusion models to introduce PDE-Refiner; a novel model class that enables more accurate modeling of all frequency components via a multistep refinement process. We validate PDE-Refiner on challenging benchmarks of co
    
[^4]: 重新思考基于深度学习的自动驾驶系统中的预测和规划的整合：一项综述

    Rethinking Integration of Prediction and Planning in Deep Learning-Based Automated Driving Systems: A Review. (arXiv:2308.05731v1 [cs.RO])

    [http://arxiv.org/abs/2308.05731](http://arxiv.org/abs/2308.05731)

    这项综述重新思考了基于深度学习的自动驾驶系统中预测和规划的整合问题，提出了将其作为相互依赖的联合步骤来提高安全性、效率性和舒适性的必要性。

    

    自动驾驶有可能彻底改变个人、公共和货运交通的方式。除了感知环境的巨大挑战外，即准确地使用可用的传感器数据感知环境，自动驾驶还包括规划一个安全、舒适和高效的运动轨迹。为了促进安全和进步，许多工作依赖于模块化的交通未来运动的预测。模块化的自动驾驶系统通常将预测和规划作为顺序的独立任务处理。虽然这考虑了周围交通对自车的影响，但它未能预测交通参与者对自车行为的反应。最近的研究表明，将预测和规划整合为相互依赖的联合步骤是实现安全、高效和舒适驾驶所必需的。虽然有各种模型实现了这种集成系统，但对不同原理的全面概述和理论理解仍然缺乏。

    Automated driving has the potential to revolutionize personal, public, and freight mobility. Besides the enormous challenge of perception, i.e. accurately perceiving the environment using available sensor data, automated driving comprises planning a safe, comfortable, and efficient motion trajectory. To promote safety and progress, many works rely on modules that predict the future motion of surrounding traffic. Modular automated driving systems commonly handle prediction and planning as sequential separate tasks. While this accounts for the influence of surrounding traffic on the ego-vehicle, it fails to anticipate the reactions of traffic participants to the ego-vehicle's behavior. Recent works suggest that integrating prediction and planning in an interdependent joint step is necessary to achieve safe, efficient, and comfortable driving. While various models implement such integrated systems, a comprehensive overview and theoretical understanding of different principles are lacking.
    
[^5]: 通过在数学和科学问题上使用Wolfram Alpha和Code Interpreter插件测试GPT-4

    Testing GPT-4 with Wolfram Alpha and Code Interpreter plug-ins on math and science problems. (arXiv:2308.05713v1 [cs.AI])

    [http://arxiv.org/abs/2308.05713](http://arxiv.org/abs/2308.05713)

    本研究测试了GPT-4在科学和数学问题上使用Wolfram Alpha和Code Interpreter插件的效果，结果表明插件显著提升了GPT的问题解决能力，但接口故障仍然是其可靠性的主要挑战。

    

    本报告描述了在2023年6月至8月期间对大型语言模型GPT-4在科学和数学领域进行的105个原创问题的测试，其中使用了Wolfram Alpha和Code Interpreter插件。我们的测试表明，这些插件显著增强了GPT解决这些问题的能力。然而，仍然经常出现“接口”故障；也就是说，GPT经常在问题的表述上遇到困难，无法从插件中得到有用的答案。解决这些接口故障似乎是使GPT成为可靠的大学级计算问题工具的关键挑战。

    This report describes a test of the large language model GPT-4 with the Wolfram Alpha and the Code Interpreter plug-ins on 105 original problems in science and math, at the high school and college levels, carried out in June-August 2023. Our tests suggest that the plug-ins significantly enhance GPT's ability to solve these problems. Having said that, there are still often "interface" failures; that is, GPT often has trouble formulating problems in a way that elicits useful answers from the plug-ins. Fixing these interface failures seems like a central challenge in making GPT a reliable tool for college-level calculation problems.
    
[^6]: 探索世界模型在自动驾驶异常检测中的潜力

    Exploring the Potential of World Models for Anomaly Detection in Autonomous Driving. (arXiv:2308.05701v1 [cs.AI])

    [http://arxiv.org/abs/2308.05701](http://arxiv.org/abs/2308.05701)

    本文探讨了在自动驾驶领域利用世界模型进行异常检测的潜力，并提供了相关研究的概述和组成部分的联系。

    

    近年来，自动驾驶技术取得了显著进展。尽管自动驾驶车辆在封闭条件下表现出高性能，但在面对意外情况时遇到困难。与此同时，世界模型在基于模型的增强学习领域中出现，作为一种使智能体能够根据潜在行动预测未来的方式。这在稀疏奖励和复杂控制任务中取得了出色的结果。本文概述了如何利用世界模型在自动驾驶领域进行异常检测，并将各个组成部分与先前的异常检测工作相关联，以促进进一步的研究。

    In recent years there have been remarkable advancements in autonomous driving. While autonomous vehicles demonstrate high performance in closed-set conditions, they encounter difficulties when confronted with unexpected situations. At the same time, world models emerged in the field of model-based reinforcement learning as a way to enable agents to predict the future depending on potential actions. This led to outstanding results in sparse reward and complex control tasks. This work provides an overview of how world models can be leveraged to perform anomaly detection in the domain of autonomous driving. We provide a characterization of world models and relate individual components to previous works in anomaly detection to facilitate further research in the field.
    
[^7]: SSLRec: 一个自监督学习的推荐系统库

    SSLRec: A Self-Supervised Learning Library for Recommendation. (arXiv:2308.05697v1 [cs.IR])

    [http://arxiv.org/abs/2308.05697](http://arxiv.org/abs/2308.05697)

    SSLRec是一个自监督学习的推荐系统库，为评估各种SSL增强推荐系统提供了标准化、灵活和综合的框架。

    

    自监督学习（SSL）作为解决推荐系统中稀疏和噪声数据挑战的解决方案，在最近几年引起了广泛关注。尽管设计了越来越多的SSL算法来在不同领域中提供最先进的推荐性能（例如图协同过滤、顺序推荐、社交推荐、知识图增强推荐），但目前仍缺乏一个统一框架来整合不同领域的推荐算法。这样的框架可以作为自监督推荐算法的基石，统一现有方法的验证，并推动新方法的设计。为了解决这个问题，我们介绍了SSLRec，一个新颖的基准平台，为评估各种SSL增强推荐系统提供了标准化、灵活和综合的框架。SSLRec库具有模块化架构，可以方便用户评估最先进的推荐器。

    Self-supervised learning (SSL) has gained significant interest in recent years as a solution to address the challenges posed by sparse and noisy data in recommender systems. Despite the growing number of SSL algorithms designed to provide state-of-the-art performance in various recommendation scenarios (e.g., graph collaborative filtering, sequential recommendation, social recommendation, KG-enhanced recommendation), there is still a lack of unified frameworks that integrate recommendation algorithms across different domains. Such a framework could serve as the cornerstone for self-supervised recommendation algorithms, unifying the validation of existing methods and driving the design of new ones. To address this gap, we introduce SSLRec, a novel benchmark platform that provides a standardized, flexible, and comprehensive framework for evaluating various SSL-enhanced recommenders. The SSLRec library features a modular architecture that allows users to easily evaluate state-of-the-art m
    
[^8]: 基于骨骼的人体动作识别面临的硬性无盒对抗攻击和骨骼-动作知情梯度

    Hard No-Box Adversarial Attack on Skeleton-Based Human Action Recognition with Skeleton-Motion-Informed Gradient. (arXiv:2308.05681v1 [cs.CV])

    [http://arxiv.org/abs/2308.05681](http://arxiv.org/abs/2308.05681)

    本文针对基于骨骼的人体动作识别方法的脆弱性进行了研究，提出了一种新的硬性无盒对抗攻击方法，通过学习运动流形和定义骨骼-动作知情梯度来攻击模型，揭示了这种脆弱性的存在。

    

    最近，基于骨骼的人体活动识别方法已被证明容易受到对抗攻击。然而，这些攻击方法要求要么完全了解受害者（即白盒攻击），要么有访问训练数据（即基于转移的攻击），或者频繁查询模型（即黑盒攻击）。所有这些要求都非常限制性，引发了对脆弱性的质疑。在本文中，我们证明了脆弱性确实存在。为此，我们考虑了一个新的攻击任务：攻击者无法访问受害者模型或训练数据或标签，我们将其称为硬性无盒攻击。具体来说，我们首先学习一个运动流形，然后定义一个用于计算攻击的对抗损失函数，称为骨骼-动作知情梯度（SMI梯度）。我们的梯度包含运动动力学的信息，这与现有的基于梯度的攻击方法不同，后者假设损失梯度是通过计算而来的。

    Recently, methods for skeleton-based human activity recognition have been shown to be vulnerable to adversarial attacks. However, these attack methods require either the full knowledge of the victim (i.e. white-box attacks), access to training data (i.e. transfer-based attacks) or frequent model queries (i.e. black-box attacks). All their requirements are highly restrictive, raising the question of how detrimental the vulnerability is. In this paper, we show that the vulnerability indeed exists. To this end, we consider a new attack task: the attacker has no access to the victim model or the training data or labels, where we coin the term hard no-box attack. Specifically, we first learn a motion manifold where we define an adversarial loss to compute a new gradient for the attack, named skeleton-motion-informed (SMI) gradient. Our gradient contains information of the motion dynamics, which is different from existing gradient-based attack methods that compute the loss gradient assuming 
    
[^9]: 探索深度学习方法预测人员和车辆出行：对NHTS数据的分析

    Exploring Deep Learning Approaches to Predict Person and Vehicle Trips: An Analysis of NHTS Data. (arXiv:2308.05665v1 [cs.AI])

    [http://arxiv.org/abs/2308.05665](http://arxiv.org/abs/2308.05665)

    本研究利用深度学习技术分析了NHTS数据，开发了一个能够准确预测人员和车辆出行的模型，并取得了98%的准确率。这对传统交通规划模型的性能来说是一个显著的提升。

    

    现代交通规划在准确预测人员和车辆出行方面依赖较多。然而，传统规划模型往往无法考虑出行行为的复杂性和动态性，导致预测准确性不佳。本研究探讨了深度学习技术的潜力，以改变我们对出行预测和交通规划的方法。利用全国家庭出行调查（NHTS）的全面数据集，我们开发和训练了一个用于预测人员和车辆出行的深度学习模型。该模型利用NHTS数据中的大量信息，捕捉以前传统模型忽视的复杂非线性关系。结果，我们的深度学习模型在预测人员出行方面达到了98%的准确率，在车辆出行估计方面达到了96%的准确率。相比传统交通模型的表现，这代表了显著的提升。

    Modern transportation planning relies heavily on accurate predictions of person and vehicle trips. However, traditional planning models often fail to account for the intricacies and dynamics of travel behavior, leading to less-than-optimal accuracy in these predictions. This study explores the potential of deep learning techniques to transform the way we approach trip predictions, and ultimately, transportation planning. Utilizing a comprehensive dataset from the National Household Travel Survey (NHTS), we developed and trained a deep learning model for predicting person and vehicle trips. The proposed model leverages the vast amount of information in the NHTS data, capturing complex, non-linear relationships that were previously overlooked by traditional models. As a result, our deep learning model achieved an impressive accuracy of 98% for person trip prediction and 96% for vehicle trip estimation. This represents a significant improvement over the performances of traditional transpo
    
[^10]: 使用连接车辆数据和深度学习模型自动提取相关道路基础设施

    Automatic Extraction of Relevant Road Infrastructure using Connected vehicle data and Deep Learning Model. (arXiv:2308.05658v1 [cs.AI])

    [http://arxiv.org/abs/2308.05658](http://arxiv.org/abs/2308.05658)

    本论文提出了一种使用连接车辆数据和深度学习模型自动提取道路基础设施的新方法。通过将车辆轨迹分段并生成道路段的图像表示，我们利用YOLOv5算法准确分类直线道路段和交叉点。实验结果表明了令人印象深刻的整体准确性。

    

    在当今快速发展的城市环境中，高效准确地绘制道路基础设施对于优化交通系统、增强道路安全并改善驾驶员和通勤者的整体出行体验至关重要。然而，一个严峻的瓶颈阻碍了进展-繁琐耗时的手动交叉点识别。考虑到需要识别的交叉点数量和每个交叉点所需的工时，自动化解决方案的需求变得不可忽视。为了解决这一挑战，我们提出了一种新颖的方法，利用连接车辆数据和先进的深度学习技术。通过使用地理散列对车辆轨迹进行分段，并生成道路段的图像表示，我们利用YOLOv5（You Only Look Once version 5）算法准确分类了直线道路段和交叉点。实验结果展示了令人印象深刻的整体准确性。

    In today's rapidly evolving urban landscapes, efficient and accurate mapping of road infrastructure is critical for optimizing transportation systems, enhancing road safety, and improving the overall mobility experience for drivers and commuters. Yet, a formidable bottleneck obstructs progress - the laborious and time-intensive manual identification of intersections. Simply considering the shear number of intersections that need to be identified, and the labor hours required per intersection, the need for an automated solution becomes undeniable. To address this challenge, we propose a novel approach that leverages connected vehicle data and cutting-edge deep learning techniques. By employing geohashing to segment vehicle trajectories and then generating image representations of road segments, we utilize the YOLOv5 (You Only Look Once version 5) algorithm for accurate classification of both straight road segments and intersections. Experimental results demonstrate an impressive overall
    
[^11]: 使用基于排名的兼容性更新临床风险分层模型：评估和优化临床医生-模型团队性能的方法

    Updating Clinical Risk Stratification Models Using Rank-Based Compatibility: Approaches for Evaluating and Optimizing Clinician-Model Team Performance. (arXiv:2308.05619v1 [stat.ML])

    [http://arxiv.org/abs/2308.05619](http://arxiv.org/abs/2308.05619)

    提出了一种基于排名的兼容性度量和一种新的损失函数来更新临床机器学习模型，以解决更新模型引入的兼容性问题。在使用MIMIC数据的病死率风险分层案例研究中，该方法相对于现有技术能产生更兼容的模型并保持判别性能。

    

    随着数据的变化或新数据的出现，更新临床机器学习模型可能是必要的，以保持或提高其性能。然而，更新模型可能会引入兼容性问题，当更新后的模型的行为与用户的期望不一致时，会导致用户-模型团队表现不佳。现有的兼容性度量依赖于模型的决策阈值，限制了它们在基于估计风险的排名生成模型的应用能力。为了解决这个限制，我们提出了一种新颖的基于排名的兼容性度量，$C^R$，以及一个旨在优化判别性能的新损失函数，同时鼓励良好的兼容性。在利用MIMIC数据的病死率风险分层的案例研究中，我们的方法相对于现有的模型选择技术，产生了更兼容的模型，同时保持了判别性能，$C^R$提高了0.019（$95\%$置信区间：...

    As data shift or new data become available, updating clinical machine learning models may be necessary to maintain or improve performance over time. However, updating a model can introduce compatibility issues when the behavior of the updated model does not align with user expectations, resulting in poor user-model team performance. Existing compatibility measures depend on model decision thresholds, limiting their applicability in settings where models are used to generate rankings based on estimated risk. To address this limitation, we propose a novel rank-based compatibility measure, $C^R$, and a new loss function that aims to optimize discriminative performance while encouraging good compatibility. Applied to a case study in mortality risk stratification leveraging data from MIMIC, our approach yields more compatible models while maintaining discriminative performance compared to existing model selection techniques, with an increase in $C^R$ of $0.019$ ($95\%$ confidence interval: 
    
[^12]: 基于神经网络的商品组合优化选择模型

    A Neural Network Based Choice Model for Assortment Optimization. (arXiv:2308.05617v1 [cs.AI])

    [http://arxiv.org/abs/2308.05617](http://arxiv.org/abs/2308.05617)

    本论文研究了基于神经网络的选择模型是否能够有效地预测购买概率，并解决了如何在这个模型中纳入商品组合效果和优化问题。

    

    離散选择模型在经济学、市场营销和收益管理中被用来预测客户购买概率，例如根据价格和其他特征进行预测。虽然它们已经被证明具有表达能力，可以捕捉到客户的异质性和行为，但是它们很难估计，通常基于许多无法观测到的效用，而且它们仍然无法捕捉到客户行为的许多显著特征。因此，一个自然的问题就是，鉴于它们在其他环境中的成功，是否神经网络可以消除仔细构建一个依赖于上下文的客户行为模型以及手工编码和调整估计的必要性。然而，如何将商品组合效果纳入这样一个神经网络以及如何使用这样一个黑盒生成模型进行商品组合优化的问题尚不清楚。在本文中，我们首先研究了一个单一的神经网络结构是否能够预测购买概率。

    Discrete-choice models are used in economics, marketing and revenue management to predict customer purchase probabilities, say as a function of prices and other features of the offered assortment. While they have been shown to be expressive, capturing customer heterogeneity and behaviour, they are also hard to estimate, often based on many unobservables like utilities; and moreover, they still fail to capture many salient features of customer behaviour. A natural question then, given their success in other contexts, is if neural networks can eliminate the necessity of carefully building a context-dependent customer behaviour model and hand-coding and tuning the estimation. It is unclear however how one would incorporate assortment effects into such a neural network, and also how one would optimize the assortment with such a black-box generative model of choice probabilities. In this paper we investigate first whether a single neural network architecture can predict purchase probabiliti
    
[^13]: 自动化工厂监控的智能机器人系统

    A Smart Robotic System for Industrial Plant Supervision. (arXiv:2308.05612v1 [cs.RO])

    [http://arxiv.org/abs/2308.05612](http://arxiv.org/abs/2308.05612)

    我们提出了一个智能机器人系统，可以自动检查化工生产厂的完整性并提供关键操作条件的有用信息。

    

    在现代化工生产厂中，人工操作员经常对工厂的完整性进行检查，以确保高安全标准，因此可能是第一个遇到危险操作条件的人。为了减轻他们在故障检测和监控方面的任务，我们提出了一个机器人系统，该系统由一个自主导航机器人和各种传感器和数据处理器组成。我们的目标是模拟人类的视觉、嗅觉和听觉感知和解释能力，以进行自动化检查。我们在一个废水处理设施中对我们的系统进行了广泛的评估，结果表明该系统能够稳定地导航工厂并提供有关关键操作条件的有用信息。

    In today's chemical production plants, human field operators perform frequent checks on the plant's integrity to guarantee high safety standards, and thus are possibly the first to encounter dangerous operating conditions. To alleviate their tasks of failure detection and monitoring by audio, visual, and olfactory perceptions, we present a robotic system that consists of an autonomously navigating robot integrated with various sensors and data processing. We aim to resemble the human sensing and interpretation capabilities of sight, smell, and hearing, for providing automated inspection. We evaluate our system extensively at a wastewater facility in full working conditions. Our results demonstrate that the system is able to robustly navigate a plant and to provide useful information about critical operating conditions.
    
[^14]: 多图空时图卷积网络用于交通流预测

    Multi-graph Spatio-temporal Graph Convolutional Network for Traffic Flow Prediction. (arXiv:2308.05601v1 [cs.LG])

    [http://arxiv.org/abs/2308.05601](http://arxiv.org/abs/2308.05601)

    本文提出了一种基于多图空时图卷积网络的方法，用于预测高速公路每日交通流量。通过数据归一化策略处理数据不平衡问题，并利用图卷积网络捕捉空时特征。同时，还使用了气象和日历特征。

    

    城市之间的高速公路交通对于城市生活至关重要。作为智能交通系统中的关键功能之一，交通评估在现今起到了重要作用，而每日交通流量预测在整个网络范围的收费站仍面临挑战。一方面，实际中各个位置之间的数据不平衡状况加剧了预测的性能。另一方面，复杂的相关空时因素无法全面地应用于长期持续时间。本文提出了一种基于空时深度学习的高速公路每日交通流预测方法。在我们的方法中，采用数据归一化策略来处理数据不平衡，由于网络范围的收费站交通流的长尾分布。然后，基于图卷积网络，我们构建了具有不同语义的网络来捕捉空时特征。除此之外，我们的模型还使用了气象和日历特征。

    Inter-city highway transportation is significant for urban life. As one of the key functions in intelligent transportation system (ITS), traffic evaluation always plays significant role nowadays, and daily traffic flow prediction still faces challenges at network-wide toll stations. On the one hand, the data imbalance in practice among various locations deteriorates the performance of prediction. On the other hand, complex correlative spatio-temporal factors cannot be comprehensively employed in long-term duration. In this paper, a prediction method is proposed for daily traffic flow in highway domain through spatio-temporal deep learning. In our method, data normalization strategy is used to deal with data imbalance, due to long-tail distribution of traffic flow at network-wide toll stations. And then, based on graph convolutional network, we construct networks in distinct semantics to capture spatio-temporal features. Beside that, meteorology and calendar features are used by our mod
    
[^15]: 接近策略优化实战：操作输出标记器长度

    Proximal Policy Optimization Actual Combat: Manipulating Output Tokenizer Length. (arXiv:2308.05585v1 [cs.AI])

    [http://arxiv.org/abs/2308.05585](http://arxiv.org/abs/2308.05585)

    本文介绍了一种使用接近策略优化来操作模型输出标记器长度的方法，在复杂任务中验证了其有效性，并且发现了其他的特性。

    

    从人类反馈中进行强化学习在塑造大型语言模型的影响方面起着关键作用，对于控制输出的毒性和选择输出风格做出了重要贡献，尤其是由于大型语言模型经常包含误导性内容，迫切需要将它们与人类价值观相一致以确保安全的人工智能系统。强化学习从人类反馈中主要存在复杂性、不稳定性和对超参数敏感性等特点，这使得对于复杂任务中奖励模型的评估变得困难，进而进一步增加了使用接近策略优化的复杂度。本文介绍了一项简单任务，旨在利用Gloden作为奖励模型，验证接近策略优化的有效性，并从中获得启示，主要解释了利用接近策略优化来操纵模型生成的输出的标记器长度的任务。实验证实，在这类任务中，接近策略优化不仅在一定程度上能够有效地操纵输出的标记器长度，还展示了其他的特性。

    The Reinforcement Learning from Human Feedback (RLHF) plays a pivotal role in shaping the impact of large language models (LLMs), contributing significantly to controlling output toxicity and selecting output styles, particularly as LLMs often harbor misleading content, highlighting the urgency to align them with human values for secure AI systems. The RLHF, characterized by complexity, instability, and sensitivity to hyperparameters, makes the evaluation of the reward model for complex tasks challenging, thereby further complicating the use of Proximal Policy Optimization (PPO). In this paper, we introduce a simple task designed to employ Gloden as a reward model that validates the effectiveness of PPO and inspires it, primarily explaining the task of utilizing PPO to manipulate the tokenizer length of the output generated by the model. Experiments confirm that PPO is not only effective in manipulating the output tokenizer length to a certain extent in this type of task but also exhib
    
[^16]: 无线电无线信道建模和抽样的生成扩散模型

    Generative Diffusion Models for Radio Wireless Channel Modelling and Sampling. (arXiv:2308.05583v1 [cs.AI])

    [http://arxiv.org/abs/2308.05583](http://arxiv.org/abs/2308.05583)

    本文提出了一种基于扩散模型的信道抽样方法，用于快速合成有限数据的信道实现，相比于现有的基于 GAN 的方法，该方法训练稳定且能够生成多样化和高质量的信道数据。

    

    信道建模对于设计现代无线通信系统至关重要。信道建模的复杂性和收集高质量无线信道数据的成本日益增加，已成为主要挑战。在本文中，我们提出了一种基于扩散模型的信道抽样方法，可以快速合成有限数据的信道实现。我们使用在频率空间域中操作的基于 U Net 的扩散模型。为了评估所提模型在训练数据集中如何准确地重现信道的真实分布，我们使用了两个评估指标：$i)$ 反映天线和频率领域中归一化功率谱的实际分布和生成分布之间的近似 $2$-Wasserstein 距离，和 $ii)$ 分布的精确度和召回率度量。我们证明，与现有的基于 GAN 的方法相比，该扩散模型方法训练稳定且能够生成多样化和高质量的信道数据。

    Channel modelling is essential to designing modern wireless communication systems. The increasing complexity of channel modelling and the cost of collecting high-quality wireless channel data have become major challenges. In this paper, we propose a diffusion model based channel sampling approach for rapidly synthesizing channel realizations from limited data. We use a diffusion model with a U Net based architecture operating in the frequency space domain. To evaluate how well the proposed model reproduces the true distribution of channels in the training dataset, two evaluation metrics are used: $i)$ the approximate $2$-Wasserstein distance between real and generated distributions of the normalized power spectrum in the antenna and frequency domains and $ii)$ precision and recall metric for distributions. We show that, compared to existing GAN based approaches which suffer from mode collapse and unstable training, our diffusion based approach trains stably and generates diverse and hi
    
[^17]: C5：为ChatGPT实现更好的对话理解和上下文连贯性

    C5: Towards Better Conversation Comprehension and Contextual Continuity for ChatGPT. (arXiv:2308.05567v1 [cs.AI])

    [http://arxiv.org/abs/2308.05567](http://arxiv.org/abs/2308.05567)

    C5是一个交互式对话可视化系统，旨在解决多轮对话中的人类遗忘和模型上下文遗忘问题，提升ChatGPT的对话理解和上下文连贯性。

    

    大型语言模型（LLMs），如ChatGPT，在各个领域，特别是自然语言理解和生成任务中表现出色。在复杂的应用场景中，用户倾向于与ChatGPT进行多轮对话，以保持上下文信息并获得全面的回复。然而，人类遗忘和模型上下文遗忘仍然是多轮对话场景中突出的问题，这挑战了用户对ChatGPT的对话理解和上下文连贯性。为了解决这些挑战，我们提出了一个交互式对话可视化系统C5，其中包括全局视图、主题视图和上下文相关的问答视图。全局视图使用GitLog图表的隐喻来表示对话结构，展示对话演变的趋势，并支持局部显著特征的探索。主题视图旨在显示所有的问题和答案节点。

    Large language models (LLMs), such as ChatGPT, have demonstrated outstanding performance in various fields, particularly in natural language understanding and generation tasks. In complex application scenarios, users tend to engage in multi-turn conversations with ChatGPT to keep contextual information and obtain comprehensive responses. However, human forgetting and model contextual forgetting remain prominent issues in multi-turn conversation scenarios, which challenge the users' conversation comprehension and contextual continuity for ChatGPT. To address these challenges, we propose an interactive conversation visualization system called C5, which includes Global View, Topic View, and Context-associated Q\&A View. The Global View uses the GitLog diagram metaphor to represent the conversation structure, presenting the trend of conversation evolution and supporting the exploration of locally salient features. The Topic View is designed to display all the question and answer nodes and 
    
[^18]: 深度伪造检测领域的最新进展

    Recent Advancements In The Field Of Deepfake Detection. (arXiv:2308.05563v1 [cs.AI])

    [http://arxiv.org/abs/2308.05563](http://arxiv.org/abs/2308.05563)

    该论文调查了深度伪造的问题，包括恶意深度伪造的创建和缺乏普适深度伪造检测方法。通过对当前的深度伪造检测方法和进展进行调查和分析，旨在找到最全面、普适的检测方法。

    

    深度伪造是指一个人的照片或视频被数字化改变或部分替换为其他人的图像。深度伪造可能导致各种问题，常被恶意使用。一种常见的用法是修改著名政治人物和名人的视频。这些深度伪造可以展示他们发表冒犯、有问题和/或不真实的声明。当前的深度伪造非常逼真，当以这种方式使用时，可能引发恐慌，甚至影响选举和政治观点。目前有许多深度伪造检测策略，但找到最全面、普适的方法至关重要。因此，在这项调查中，我们将解决恶意深度伪造创建和缺乏普适深度伪造检测方法的问题。我们的目标是调查和分析当前深度伪造检测领域的各种方法和进展。

    A deepfake is a photo or video of a person whose image has been digitally altered or partially replaced with an image of someone else. Deepfakes have the potential to cause a variety of problems and are often used maliciously. A common usage is altering videos of prominent political figures and celebrities. These deepfakes can portray them making offensive, problematic, and/or untrue statements. Current deepfakes can be very realistic, and when used in this way, can spread panic and even influence elections and political opinions. There are many deepfake detection strategies currently in use but finding the most comprehensive and universal method is critical. So, in this survey we will address the problems of malicious deepfake creation and the lack of universal deepfake detection methods. Our objective is to survey and analyze a variety of current methods and advances in the field of deepfake detection.
    
[^19]: 学习（与）分布式优化

    Learning (With) Distributed Optimization. (arXiv:2308.05548v1 [math.OC])

    [http://arxiv.org/abs/2308.05548](http://arxiv.org/abs/2308.05548)

    本文回顾了分布式优化技术的历史发展，介绍了增广Lagrange交替方向非精确牛顿(ALADIN)算法以及Alternating Direction Method of Multipliers (ADMM)等方法的改进。同时突出了近端中心方法的应用和ALADIN的独特特点。

    

    本文概述了分布式优化技术的历史发展，追溯到20世纪60年代丹齐格、沃尔夫和本德斯开创的基于对偶性的方法，直到增广Lagrange交替方向非精确牛顿(ALADIN)算法的出现。最初的重点是对凸问题的拉格朗日松弛和分解策略，导致了Alternating Direction Method of Multipliers (ADMM)等方法的改进。2000年代末分布式优化再度受到关注，特别是在机器学习和成像领域，证明了ADMM的实际有效性和统一潜力。本文还突出了近端中心方法的出现及其在不同领域的应用。此外，本文强调了ALADIN的独特特点，它为非凸情况提供了收敛保证，而无需引入辅助变量，与其他方法有所区分。

    This paper provides an overview of the historical progression of distributed optimization techniques, tracing their development from early duality-based methods pioneered by Dantzig, Wolfe, and Benders in the 1960s to the emergence of the Augmented Lagrangian Alternating Direction Inexact Newton (ALADIN) algorithm. The initial focus on Lagrangian relaxation for convex problems and decomposition strategies led to the refinement of methods like the Alternating Direction Method of Multipliers (ADMM). The resurgence of interest in distributed optimization in the late 2000s, particularly in machine learning and imaging, demonstrated ADMM's practical efficacy and its unifying potential. This overview also highlights the emergence of the proximal center method and its applications in diverse domains. Furthermore, the paper underscores the distinctive features of ALADIN, which offers convergence guarantees for non-convex scenarios without introducing auxiliary variables, differentiating it fro
    
[^20]: 用模型预测路径积分控制增强AUV的自主性

    Enhancing AUV Autonomy With Model Predictive Path Integral Control. (arXiv:2308.05547v1 [cs.RO])

    [http://arxiv.org/abs/2308.05547](http://arxiv.org/abs/2308.05547)

    本文研究了在AUV控制中使用模型预测路径积分控制（MPPI）的可行性，并对其性能做了详细评估，在与传统PID和级联PID方法的比较中表现出了优越性。

    

    自主水下车辆（AUV）在勘测海洋环境、进行水下检查任务和海洋探索中起着至关重要的作用。然而，为了确保AUV能够成功执行任务，需要一个能够适应不断变化的环境条件的控制系统。此外，为了确保机器人平台的安全运行，机载控制器应该能够在特定的约束条件下操作。在这项工作中，我们研究了将模型预测路径积分控制（MPPI）用于AUV控制的可行性。我们利用AUV的非线性模型传播MPPI的样本，从而实时计算出控制行动。我们详细评估了主要超参数对MPPI控制器性能的影响。此外，我们将所提出方法的性能与经典PID和级联PID方法进行了比较，证明了我们提出方法的优越性。

    Autonomous underwater vehicles (AUVs) play a crucial role in surveying marine environments, carrying out underwater inspection tasks, and ocean exploration. However, in order to ensure that the AUV is able to carry out its mission successfully, a control system capable of adapting to changing environmental conditions is required. Furthermore, to ensure the robotic platform's safe operation, the onboard controller should be able to operate under certain constraints. In this work, we investigate the feasibility of Model Predictive Path Integral Control (MPPI) for the control of an AUV. We utilise a non-linear model of the AUV to propagate the samples of the MPPI, which allow us to compute the control action in real time. We provide a detailed evaluation of the effect of the main hyperparameters on the performance of the MPPI controller. Furthermore, we compared the performance of the proposed method with a classical PID and Cascade PID approach, demonstrating the superiority of our propo
    
[^21]: 模型很重要：单步反合成对合成规划的影响

    Models Matter: The Impact of Single-Step Retrosynthesis on Synthesis Planning. (arXiv:2308.05522v1 [cs.AI])

    [http://arxiv.org/abs/2308.05522](http://arxiv.org/abs/2308.05522)

    本研究通过将多个单步反合成模型应用于多步合成规划，发现单步性能较好并不一定能找到潜在的反应路径，强调了将单步模型与合成规划相结合的重要性。

    

    反合成是将化学化合物逐步递归地分解为分子前体，直到找到一组商业上可用的分子为止，以提供合成路线。它的两个主要研究方向，即单步反合成预测和多步合成规划，它们的目标是模拟化学反应逻辑和找到正确的反应顺序，二者密切相关。然而，这种联系在当前的研究中没有得到体现。在这项工作中，我们通过将多个单步反合成模型应用于多步合成规划并使用公开和专有的反应数据进行分析，将这两个主要研究方向结合起来。我们发现单步性能较好与找到潜在的反应路径成功之间存在断裂，这表明将来必须在合成规划中评估单步模型。此外，我们还展示了常用的单步反合成模型在合成规划中的应用效果。

    Retrosynthesis consists of breaking down a chemical compound recursively step-by-step into molecular precursors until a set of commercially available molecules is found with the goal to provide a synthesis route. Its two primary research directions, single-step retrosynthesis prediction, which models the chemical reaction logic, and multi-step synthesis planning, which tries to find the correct sequence of reactions, are inherently intertwined. Still, this connection is not reflected in contemporary research. In this work, we combine these two major research directions by applying multiple single-step retrosynthesis models within multi-step synthesis planning and analyzing their impact using public and proprietary reaction data. We find a disconnection between high single-step performance and potential route-finding success, suggesting that single-step models must be evaluated within synthesis planning in the future. Furthermore, we show that the commonly used single-step retrosynthesi
    
[^22]: Mono-hydra: 单目相机输入与IMU实时3D场景图构建

    Mono-hydra: Real-time 3D scene graph construction from monocular camera input with IMU. (arXiv:2308.05515v1 [cs.RO])

    [http://arxiv.org/abs/2308.05515](http://arxiv.org/abs/2308.05515)

    Mono-Hydra是一个实时空间感知系统，通过结合单目相机和IMU传感器，能够实时构建室内场景的3D图。它使用深度学习算法从单目相机输入中推导深度和语义，并采用基于方根信息的机器人视觉惯性测距(VIO)算法来保证准确性和实时性。

    

    机器人在3D环境中自主导航的能力取决于对空间概念的理解，从低层几何到高层语义，如物体、地点和建筑物。为了实现这样的理解，3D场景图成为表示环境的分层概念和它们之间关系的强大工具。然而，使用单目视觉系统实时构建这些表示仍然是一个尚未深入探讨的困难任务。本文提出了一个实时空间感知系统Mono-Hydra，结合了单目相机和IMU传感器，专注于室内场景。然而，所提出的方法适用于户外应用，具有灵活性和潜在的用途。系统采用一套深度学习算法来推导深度和语义。它使用了基于方根信息的机器人视觉惯性测距(VIO)算法，从而确保

    The ability of robots to autonomously navigate through 3D environments depends on their comprehension of spatial concepts, ranging from low-level geometry to high-level semantics, such as objects, places, and buildings. To enable such comprehension, 3D scene graphs have emerged as a robust tool for representing the environment as a layered graph of concepts and their relationships. However, building these representations using monocular vision systems in real-time remains a difficult task that has not been explored in depth. This paper puts forth a real-time spatial perception system Mono-Hydra, combining a monocular camera and an IMU sensor setup, focusing on indoor scenarios. However, the proposed approach is adaptable to outdoor applications, offering flexibility in its potential uses. The system employs a suite of deep learning algorithms to derive depth and semantics. It uses a robocentric visual-inertial odometry (VIO) algorithm based on square-root information, thereby ensuring 
    
[^23]: 多领域推荐中的嵌入解耦与领域对齐

    Multi-domain Recommendation with Embedding Disentangling and Domain Alignment. (arXiv:2308.05508v1 [cs.IR])

    [http://arxiv.org/abs/2308.05508](http://arxiv.org/abs/2308.05508)

    该研究提出了一种新的多领域推荐方法EDDA，它通过嵌入解耦推荐器和领域对齐两个关键组件分别解决了知识解耦和跨领域知识转移的挑战。

    

    多领域推荐(MDR)旨在为具有重叠用户/物品的不同领域(例如产品类型)提供推荐，对于拥有多个服务的平台如亚马逊、Facebook和LinkedIn是常见的。现有的MDR模型面临两个挑战：首先，很难解耦可以泛化到所有领域的知识(例如，用户喜欢廉价的物品)与特定于单个领域的知识(例如，用户喜欢蓝色的服装但不喜欢蓝色的汽车)。其次，它们在具有小重叠的领域之间转移知识的能力有限。我们提出了一种名为EDDA的新的MDR方法，其中包含两个关键组成部分，即嵌入解耦推荐器和领域对齐，分别解决了这两个挑战。特别地，嵌入解耦推荐器分离了跨领域部分和单领域部分的模型和嵌入，而大多数现有的MDR方法只关注模型层面的解耦。领域对齐使用领域特定的对抗训练来提升不同领域之间的知识转移能力。

    Multi-domain recommendation (MDR) aims to provide recommendations for different domains (e.g., types of products) with overlapping users/items and is common for platforms such as Amazon, Facebook, and LinkedIn that host multiple services. Existing MDR models face two challenges: First, it is difficult to disentangle knowledge that generalizes across domains (e.g., a user likes cheap items) and knowledge specific to a single domain (e.g., a user likes blue clothing but not blue cars). Second, they have limited ability to transfer knowledge across domains with small overlaps. We propose a new MDR method named EDDA with two key components, i.e., embedding disentangling recommender and domain alignment, to tackle the two challenges respectively. In particular, the embedding disentangling recommender separates both the model and embedding for the inter-domain part and the intra-domain part, while most existing MDR methods only focus on model-level disentangling. The domain alignment leverag
    
[^24]: 二进制估值的EFX分配存在问题

    EFX Allocations Exist for Binary Valuations. (arXiv:2308.05503v1 [cs.CE])

    [http://arxiv.org/abs/2308.05503](http://arxiv.org/abs/2308.05503)

    本文研究了公平分配问题中的EFX分配的存在性，扩展了之前对二进制和次模估值的结论，提出了一个计算EFX分配的多项式时间算法。

    

    我们研究了公平分配问题以及满足公平条件（EFX）的分配的存在性。EFX分配的存在性是公平分配文献中的一个重要开放问题。我们考虑二进制估值，其中通过获得额外物品的边际增益为0或1。Babaioff等人[2021]证明了对于二进制和次模的估值，EFX分配总是存在的。在本文中，通过使用完全不同的技术，我们将这个存在性结果扩展到一般的二进制估值上，并提出了一个计算EFX分配的多项式时间算法。

    We study the fair division problem and the existence of allocations satisfying the fairness criterion envy-freeness up to any item (EFX). The existence of EFX allocations is a major open problem in the fair division literature. We consider binary valuations where the marginal gain of the value by receiving an extra item is either $0$ or $1$. Babaioff et al. [2021] proved that EFX allocations always exist for binary and submodular valuations. In this paper, by using completely different techniques, we extend this existence result to general binary valuations that are not necessarily submodular, and we present a polynomial time algorithm for computing an EFX allocation.
    
[^25]: 将顺序带入基于Transformer的语言模型中，用于人工智能和法律的应用

    Bringing order into the realm of Transformer-based language models for artificial intelligence and law. (arXiv:2308.05502v1 [cs.CL])

    [http://arxiv.org/abs/2308.05502](http://arxiv.org/abs/2308.05502)

    本文提供了第一个对基于Transformer的语言模型在法律领域的人工智能问题和任务中的方法的系统概述。文章旨在突出这一领域的研究进展，以进一步了解Transformer在支持法律流程中的AI成功贡献以及当前的局限性。

    

    基于Transformer的语言模型（TLM）被广泛认可是一种先进的技术，能够成功开发出基于深度学习的解决方案，用于需要自然语言处理和理解的问题和应用。与其他文本领域一样，TLM确实推动了法律领域许多感兴趣任务对人工智能方法的最新进展。尽管第一个Transformer模型提出了大约6年时间，但这项技术以前所未有的速度迅猛发展，BERT和相关模型成为主要参考，也在法律领域占有重要地位。本文首次系统概述了TLM在法律领域的人工智能驱动问题和任务中的方法。一个主要目标是突出研究在这一领域的进展，以便一方面了解Transformer在支持法律流程中取得的AI成功贡献是什么，另一方面了解当前的局限性是什么。

    Transformer-based language models (TLMs) have widely been recognized to be a cutting-edge technology for the successful development of deep-learning-based solutions to problems and applications that require natural language processing and understanding. Like for other textual domains, TLMs have indeed pushed the state-of-the-art of AI approaches for many tasks of interest in the legal domain. Despite the first Transformer model being proposed about six years ago, there has been a rapid progress of this technology at an unprecedented rate, whereby BERT and related models represent a major reference, also in the legal domain. This article provides the first systematic overview of TLM-based methods for AI-driven problems and tasks in the legal sphere. A major goal is to highlight research advances in this field so as to understand, on the one hand, how the Transformers have contributed to the success of AI in supporting legal processes, and on the other hand, what are the current limitati
    
[^26]: 超乎寻常的眼观六路：利用深度学习模型分析手术室中麻醉师的视觉注意力

    More Than Meets the Eye: Analyzing Anesthesiologists' Visual Attention in the Operating Room Using Deep Learning Models. (arXiv:2308.05501v1 [cs.AI])

    [http://arxiv.org/abs/2308.05501](http://arxiv.org/abs/2308.05501)

    使用深度学习模型分析手术室中麻醉师的视觉注意力分布，通过处理监视器装置的摄像头收集连续的行为数据，以及比较了不同的方法。

    

    患者的生命体征在监视器上显示，麻醉师的视觉注意力是安全管理全麻患者的关键组成部分；此外，视觉注意力的分布和在全程麻醉过程中获取特定线索的能力可能直接影响患者的结果。目前，大多数研究使用可穿戴的眼动追踪技术来分析麻醉师的视觉模式。虽然能够产生详细的数据，但可穿戴设备对于手术室中的大规模或长期数据收集并不可持续。因此，通过利用深度学习模型处理以监视器为基础的网络摄像头，我们使用了一种新颖的眼动追踪方法，收集连续的行为数据，并在最小干扰下了解麻醉师的视觉注意力分布。在本研究中，我们使用提出的框架收集手术室的视频录像，并比较了不同的方法。

    Patient's vital signs, which are displayed on monitors, make the anesthesiologist's visual attention (VA) a key component in the safe management of patients under general anesthesia; moreover, the distribution of said VA and the ability to acquire specific cues throughout the anesthetic, may have a direct impact on patient's outcome. Currently, most studies employ wearable eye-tracking technologies to analyze anesthesiologists' visual patterns. Albeit being able to produce meticulous data, wearable devices are not a sustainable solution for large-scale or long-term use for data collection in the operating room (OR). Thus, by utilizing a novel eye-tracking method in the form of deep learning models that process monitor-mounted webcams, we collected continuous behavioral data and gained insight into the anesthesiologist's VA distribution with minimal disturbance to their natural workflow. In this study, we collected OR video recordings using the proposed framework and compared different 
    
[^27]: 探索XAI在艺术领域的应用：解释生成音乐中的潜空间

    Exploring XAI for the Arts: Explaining Latent Space in Generative Music. (arXiv:2308.05496v1 [cs.AI])

    [http://arxiv.org/abs/2308.05496](http://arxiv.org/abs/2308.05496)

    本研究旨在探索XAI在艺术领域的应用。通过使用可解释的生成音乐的潜变量模型，我们通过潜空间正则化、用户界面反馈循环和音乐属性的可视化来增加模型的可解释性。

    

    可解释的人工智能（XAI）有潜力支持更具互动性和流畅性的协作创造型人工智能系统，这些系统可以与人类进行创造性的合作。为了实现这一点，创造性的人工智能模型需要具备可调试的特性，即可检查、可理解和可修改。然而，目前在艺术领域中几乎没有可解释的人工智能。在这项工作中，我们演示了如何使音乐生成的潜变量模型更加可解释；具体而言，我们扩展了生成音乐小节的MeasureVAE模型。我们通过以下方式增加了模型的可解释性：i）使用潜空间正则化，强制一些特定维度的潜空间映射到有意义的音乐属性，ii）提供用户界面反馈循环，允许用户调整潜空间的维度并实时观察这些变化的结果，iii）提供音乐属性在潜空间中的可视化，帮助用户理解和预测效果。

    Explainable AI has the potential to support more interactive and fluid co-creative AI systems which can creatively collaborate with people. To do this, creative AI models need to be amenable to debugging by offering eXplainable AI (XAI) features which are inspectable, understandable, and modifiable. However, currently there is very little XAI for the arts. In this work, we demonstrate how a latent variable model for music generation can be made more explainable; specifically we extend MeasureVAE which generates measures of music. We increase the explainability of the model by: i) using latent space regularisation to force some specific dimensions of the latent space to map to meaningful musical attributes, ii) providing a user interface feedback loop to allow people to adjust dimensions of the latent space and observe the results of these changes in real-time, iii) providing a visualisation of the musical attributes in the latent space to help people understand and predict the effect o
    
[^28]: LLM变成DBA

    LLM As DBA. (arXiv:2308.05481v1 [cs.DB])

    [http://arxiv.org/abs/2308.05481](http://arxiv.org/abs/2308.05481)

    LLM变成DBA，提供数据库维护的诊断和优化建议，通过从文本来源中获取经验和多个LLMs的协作诊断。

    

    数据库管理员（DBA）在管理、维护和优化数据库系统以确保数据可用性、性能和可靠性方面起着至关重要的作用。然而，对于DBA来说，管理大量数据库实例（例如，云数据库上的数百万个实例）是困难和繁琐的。最近，大型语言模型（LLMs）已经显示出了理解有价值文件并生成合理答案的巨大潜力。因此，我们提出了D-Bot，一种基于LLM的数据库管理员，它可以持续从文本来源中获取数据库维护经验，并为目标数据库提供合理、有理、及时的诊断和优化建议。本文介绍了一个革命性的以LLM为中心的数据库维护框架，包括（i）从文档和工具中检测数据库维护知识，（ii）根本原因分析的思维树，和（iii）多个LLM之间的协作诊断。我们进行了初步实验。

    Database administrators (DBAs) play a crucial role in managing, maintaining and optimizing a database system to ensure data availability, performance, and reliability. However, it is hard and tedious for DBAs to manage a large number of database instances (e.g., millions of instances on the cloud databases). Recently large language models (LLMs) have shown great potential to understand valuable documents and accordingly generate reasonable answers. Thus, we propose D-Bot, a LLM-based database administrator that can continuously acquire database maintenance experience from textual sources, and provide reasonable, well-founded, in-time diagnosis and optimization advice for target databases. This paper presents a revolutionary LLM-centric framework for database maintenance, including (i) database maintenance knowledge detection from documents and tools, (ii) tree of thought reasoning for root cause analysis, and (iii) collaborative diagnosis among multiple LLMs. Our preliminary experiment
    
[^29]: 在高分辨率3+1D雷达背景下，对3D目标检测器进行综述

    Reviewing 3D Object Detectors in the Context of High-Resolution 3+1D Radar. (arXiv:2308.05478v1 [cs.RO])

    [http://arxiv.org/abs/2308.05478](http://arxiv.org/abs/2308.05478)

    这项研究在高分辨率3+1D雷达的背景下，综述了基于深度学习的3D目标检测器。由于3D激光雷达点云与3+1D雷达点云之间的相似性，现有的3D目标检测器可作为基于雷达数据进行深度学习的起点。但为了适应雷达领域，需要对这些现有检测器进行适应性调整。

    

    最近高分辨率4D(3+1D)雷达传感器的发展和市场引入推动了基于深度学习的雷达感知研究。我们研究了在雷达点云上运行的基于深度学习的3D目标检测模型。3D激光雷达点云上的3D目标检测是3D视觉领域的成熟领域，已经提出了许多不同的架构，各具优势和劣势。由于3D激光雷达点云和3+1D雷达点云之间的相似性，现有的3D目标检测器是基于雷达数据进行深度学习的3D目标检测的自然基础。因此，第一步是分析现有模型在新数据模态上的检测性能，并对其进行深入评估。为了将针对激光雷达点云开发的现有3D点云目标检测器应用于雷达领域，首先需要进行适应性调整。虽然已经对一些检测器进行了适应性调整，例如PointPillars，以使其适用于雷达数据。

    Recent developments and the beginning market introduction of high-resolution imaging 4D (3+1D) radar sensors have initialized deep learning-based radar perception research. We investigate deep learning-based models operating on radar point clouds for 3D object detection. 3D object detection on lidar point cloud data is a mature area of 3D vision. Many different architectures have been proposed, each with strengths and weaknesses. Due to similarities between 3D lidar point clouds and 3+1D radar point clouds, those existing 3D object detectors are a natural basis to start deep learning-based 3D object detection on radar data. Thus, the first step is to analyze the detection performance of the existing models on the new data modality and evaluate them in depth. In order to apply existing 3D point cloud object detectors developed for lidar point clouds to the radar domain, they need to be adapted first. While some detectors, such as PointPillars, have already been adapted to be applicable 
    
[^30]: 医学领域可解释的人工智能应用：一项系统综述

    Explainable AI applications in the Medical Domain: a systematic review. (arXiv:2308.05411v1 [cs.AI])

    [http://arxiv.org/abs/2308.05411](http://arxiv.org/abs/2308.05411)

    该论文通过文献综述探讨了医学决策支持中可解释的人工智能解决方案的最新发展，结果发现通用模型的XAI技术被广泛采用，深度学习模型被更多使用，解释性被应用于提高信任，但医生的参与仍较少报道。

    

    医学人工智能在医学影像、患者护理和其他领域取得了显著进展。虽然这些应用在回顾性研究中取得了成功，但实际上很少有应用。医学人工智能领域面临着建立用户信任、遵守法规、合理使用数据等各种挑战。可解释的人工智能（XAI）旨在使人类理解人工智能并信任其结果。本文基于最近几年发表的198篇文章，对医学决策支持的XAI解决方案的最新发展进行了文献综述。相关文章的系统综合产生了几个发现：（1）这些解决方案主要采用了通用模型的XAI技术，（2）相比其他类型的机器学习模型，深度学习模型被更多地使用，（3）解释性被应用于提高信任，但很少有工作报道了医生的参与。

    Artificial Intelligence in Medicine has made significant progress with emerging applications in medical imaging, patient care, and other areas. While these applications have proven successful in retrospective studies, very few of them were applied in practice.The field of Medical AI faces various challenges, in terms of building user trust, complying with regulations, using data ethically.Explainable AI (XAI) aims to enable humans understand AI and trust its results. This paper presents a literature review on the recent developments of XAI solutions for medical decision support, based on a representative sample of 198 articles published in recent years. The systematic synthesis of the relevant articles resulted in several findings. (1) model-agnostic XAI techniques were mostly employed in these solutions, (2) deep learning models are utilized more than other types of machine learning models, (3) explainability was applied to promote trust, but very few works reported the physicians par
    
[^31]: 多视角融合学习用于农作物分类的比较评估

    A Comparative Assessment of Multi-view fusion learning for Crop Classification. (arXiv:2308.05407v1 [cs.CV])

    [http://arxiv.org/abs/2308.05407](http://arxiv.org/abs/2308.05407)

    本研究比较评估了多视角融合学习在农作物分类中的效果，提出的融合方法优于单一视角和先前方法，根据测试区域选择最佳融合方法。

    

    随着遥感数据源数量和多样性的快速增加，多视角学习建模越来越重要。然而，由于遥感数据的分辨率、幅度和噪声差异，这是一个复杂的任务。通常的方法是在输入级别进行融合，但其他更高级的融合策略可能会超越传统方法。本研究评估了在CropHarvest数据集中用于农作物分类的不同融合策略。本文提出的融合方法优于基于单个视角和先前的融合方法的模型。我们没有找到一个单一的融合方法一直优于其他方法。相反，我们对三个不同数据集的多视角融合方法进行了比较，并表明，在测试区域不同的方法获得最佳性能。尽管如此，我们提出了一个初步的选择融合方法的标准。

    With a rapidly increasing amount and diversity of remote sensing (RS) data sources, there is a strong need for multi-view learning modeling. This is a complex task when considering the differences in resolution, magnitude, and noise of RS data. The typical approach for merging multiple RS sources has been input-level fusion, but other - more advanced - fusion strategies may outperform this traditional approach. This work assesses different fusion strategies for crop classification in the CropHarvest dataset. The fusion methods proposed in this work outperform models based on individual views and previous fusion methods. We do not find one single fusion method that consistently outperforms all other approaches. Instead, we present a comparison of multi-view fusion methods for three different datasets and show that, depending on the test region, different methods obtain the best performance. Despite this, we suggest a preliminary criterion for the selection of fusion methods.
    
[^32]: 提升基于LLM的AI自动化代理的信任:新的考虑因素和未来挑战

    Enhancing Trust in LLM-Based AI Automation Agents: New Considerations and Future Challenges. (arXiv:2308.05391v1 [cs.AI])

    [http://arxiv.org/abs/2308.05391](http://arxiv.org/abs/2308.05391)

    本论文研究了基于LLM的AI自动化代理的挑战与机遇，在现有文献中分析了AI代理信任的主要方面，并针对这一新一代自动化代理提出了具体的考虑因素和挑战。最终，强调了研究界面临的几个挑战。

    

    AI代理的信任已在文献中得到广泛研究，从而对这一领域的理解取得了重要进展。然而，大型语言模型（LLMs）的快速发展和基于LLM的AI代理框架的出现为进一步研究带来了新的挑战和机遇。在流程自动化领域，出现了一代新的基于AI的代理，可以执行复杂任务。与此同时，通过用户友好的无代码工具和培训机制，建立自动化流程变得更加可行。本文探讨了这些新的挑战和机会，分析了现有文献中讨论的AI代理的信任主要方面，并确定了与这一新一代自动化代理相关的具体问题和挑战。我们还评估了此类产品如何解决这些问题。最后，我们强调了研究界面临的一些挑战。

    Trust in AI agents has been extensively studied in the literature, resulting in significant advancements in our understanding of this field. However, the rapid advancements in Large Language Models (LLMs) and the emergence of LLM-based AI agent frameworks pose new challenges and opportunities for further research. In the field of process automation, a new generation of AI-based agents has emerged, enabling the execution of complex tasks. At the same time, the process of building automation has become more accessible to business users via user-friendly no-code tools and training mechanisms. This paper explores these new challenges and opportunities, analyzes the main aspects of trust in AI agents discussed in existing literature, and identifies specific considerations and challenges relevant to this new generation of automation agents. We also evaluate how nascent products in this category address these considerations. Finally, we highlight several challenges that the research community
    
[^33]: 自适应分类学习和历史模式建模用于专利分类

    Adaptive Taxonomy Learning and Historical Patterns Modelling for Patent Classification. (arXiv:2308.05385v1 [cs.AI])

    [http://arxiv.org/abs/2308.05385](http://arxiv.org/abs/2308.05385)

    本文介绍了一种综合考虑专利信息的框架，旨在为专利分类提供更准确的方法。该框架综合了专利的文本描述、权利人信息和IPC代码的相关性，从而为专利分类提供更全面的上下文信息。

    

    专利分类旨在为给定的专利分配多个国际专利分类（IPC）代码。最近用于自动分类专利的方法主要集中于分析专利的文本描述。然而，除了文本之外，每个专利还与一些权利人相关联，了解他们申请的专利对于分类往往是有价值的。此外，IPC系统制定的层次化分类法提供了重要的上下文信息，并且使模型可以利用IPC代码之间的相关性进行更准确的分类。然而，现有方法未能综合考虑上述方面。在本文中，我们提出了一个综合考虑专利信息的整合框架来进行专利分类。具体而言，我们首先提出了一个IPC代码相关性学习模块，通过在同一层级和不同层级之间自适应地传递和聚合消息，从而得到它们的语义表示。

    Patent classification aims to assign multiple International Patent Classification (IPC) codes to a given patent. Recent methods for automatically classifying patents mainly focus on analyzing the text descriptions of patents. However, apart from the texts, each patent is also associated with some assignees, and the knowledge of their applied patents is often valuable for classification. Furthermore, the hierarchical taxonomy formulated by the IPC system provides important contextual information and enables models to leverage the correlations between IPC codes for more accurate classification. However, existing methods fail to incorporate the above aspects. In this paper, we propose an integrated framework that comprehensively considers the information on patents for patent classification. To be specific, we first present an IPC codes correlations learning module to derive their semantic representations via adaptively passing and aggregating messages within the same level and across dif
    
[^34]: 超越语义：利用自我监督学习的行为增强相关模型的学习

    Beyond Semantics: Learning a Behavior Augmented Relevance Model with Self-supervised Learning. (arXiv:2308.05379v1 [cs.IR])

    [http://arxiv.org/abs/2308.05379](http://arxiv.org/abs/2308.05379)

    这篇论文提出了一种行为增强的相关模型，利用自我监督学习，通过从用户历史行为数据中提取辅助查询-项目交互，来改进搜索引擎中的查询-项目匹配，提高准确性和鲁棒性。

    

    相关建模旨在定位与对应查询相关的理想项目，这对于搜索引擎确保用户体验非常重要。虽然大多数传统方法通过评估查询与项目之间的语义相似性来解决这个问题，但纯语义匹配并不是唯一的方法。实际上，从用户搜索记录的历史行为数据中提取的辅助查询-项目交互可以提供进一步揭示用户搜索意图的线索。得益于此，我们设计了一种新颖的基于行为增强相关学习模型的支付宝搜索模型（BARL-ASe），该模型利用目标项目的相邻查询和目标查询的相邻项目来补充目标查询-项目的语义匹配。具体而言，我们的模型建立了多层共同注意力，从相邻和目标视图中提取了粗粒度和细粒度的语义表示。模型随后采用邻居-目标的自我监督学习来提高精度和鲁棒性。

    Relevance modeling aims to locate desirable items for corresponding queries, which is crucial for search engines to ensure user experience. Although most conventional approaches address this problem by assessing the semantic similarity between the query and item, pure semantic matching is not everything. In reality, auxiliary query-item interactions extracted from user historical behavior data of the search log could provide hints to reveal users' search intents further. Drawing inspiration from this, we devise a novel Behavior Augmented Relevance Learning model for Alipay Search (BARL-ASe) that leverages neighbor queries of target item and neighbor items of target query to complement target query-item semantic matching. Specifically, our model builds multi-level co-attention for distilling coarse-grained and fine-grained semantic representations from both neighbor and target views. The model subsequently employs neighbor-target self-supervised learning to improve the accuracy and robu
    
[^35]: 可信的LLMs：评估大型语言模型对齐的调查和指南

    Trustworthy LLMs: a Survey and Guideline for Evaluating Large Language Models' Alignment. (arXiv:2308.05374v1 [cs.AI])

    [http://arxiv.org/abs/2308.05374](http://arxiv.org/abs/2308.05374)

    本文介绍了一份关于评估LLM可信度的综合调查，并提供了指导。调查涵盖了可靠性、安全性、公平性、抵抗滥用、可解释性和推理能力、遵守社会规范以及鲁棒性等七个主要类别，共计29个子类别。

    

    在将大型语言模型（LLMs）应用于现实世界应用之前，确保对齐是一项关键任务。然而，从业者面临的主要挑战是缺乏明确的指导来评估LLMs的输出是否符合社会规范、价值观和法规。本文提出了一个全面的调查，涵盖了评估LLM可信度时必须考虑的关键维度。调查涵盖了LLM可信度的七个主要类别：可靠性、安全性、公平性、抵抗滥用、可解释性和推理能力、遵守社会规范以及鲁棒性。每个主要类别进一步细分为若干子类别，共计29个子类别。

    Ensuring alignment, which refers to making models behave in accordance with human intentions [1,2], has become a critical task before deploying large language models (LLMs) in real-world applications. For instance, OpenAI devoted six months to iteratively aligning GPT-4 before its release [3]. However, a major challenge faced by practitioners is the lack of clear guidance on evaluating whether LLM outputs align with social norms, values, and regulations. This obstacle hinders systematic iteration and deployment of LLMs. To address this issue, this paper presents a comprehensive survey of key dimensions that are crucial to consider when assessing LLM trustworthiness. The survey covers seven major categories of LLM trustworthiness: reliability, safety, fairness, resistance to misuse, explainability and reasoning, adherence to social norms, and robustness. Each major category is further divided into several sub-categories, resulting in a total of 29 sub-categories. Additionally, a subset 
    
[^36]: 机器学习辅助的卷积神经网络推理系统的计算机架构设计

    Machine Learning aided Computer Architecture Design for CNN Inferencing Systems. (arXiv:2308.05364v1 [cs.AR])

    [http://arxiv.org/abs/2308.05364](http://arxiv.org/abs/2308.05364)

    本研究提出了一种机器学习辅助的计算机架构设计方法，用于加快卷积神经网络推理系统的设计过程。通过快速而准确地预测CNN在推理过程中的功耗和性能，帮助计算机架构师在早期阶段进行估计，从而减少开发周期。

    

    高效和及时计算机器学习（ML）算法对于自动驾驶、物联网（IoT）和边缘计算等新兴技术至关重要。这些系统中使用的主要ML算法之一是卷积神经网络（CNN），它需要高计算资源。为了满足设计约束，人们使用ML加速器如GPGPUs。然而，选择最合适的加速器通常涉及设计空间探索（DSE），这是一个耗时且需要大量手工努力的过程。我们的工作提出了一种加快DSE过程的方法，通过识别最适合CNN推理系统的GPGPU。我们开发了一种快速准确的技术，用于推理过程中的CNN功耗和性能预测，MAPE分别为5.03%和5.94%。我们的方法使计算机架构师能够在开发的早期估计功耗和性能，从而减少开发周期。

    Efficient and timely calculations of Machine Learning (ML) algorithms are essential for emerging technologies like autonomous driving, the Internet of Things (IoT), and edge computing. One of the primary ML algorithms used in such systems is Convolutional Neural Networks (CNNs), which demand high computational resources. This requirement has led to the use of ML accelerators like GPGPUs to meet design constraints. However, selecting the most suitable accelerator involves Design Space Exploration (DSE), a process that is usually time-consuming and requires significant manual effort. Our work presents approaches to expedite the DSE process by identifying the most appropriate GPGPU for CNN inferencing systems. We have developed a quick and precise technique for forecasting the power and performance of CNNs during inference, with a MAPE of 5.03% and 5.94%, respectively. Our approach empowers computer architects to estimate power and performance in the early stages of development, reducing 
    
[^37]: 元认知提示改善大型语言模型的理解能力

    Metacognitive Prompting Improves Understanding in Large Language Models. (arXiv:2308.05342v1 [cs.CL])

    [http://arxiv.org/abs/2308.05342](http://arxiv.org/abs/2308.05342)

    元认知提示 (MP) 是一种改进大型语言模型 (LLMs) 理解能力的策略。实验结果表明，使用MP的PaLM在各种自然语言理解任务中接近于GPT-4的性能水平。

    

    在大型语言模型 (LLMs) 中，通过有效的提示设计，任务特定性能一直在不断提高。尽管最近关于提示的研究增强了LLMs的推理能力，但在进一步提高它们的理解能力方面仍存在差距。在本研究中，我们介绍了元认知提示 (MP)，这是一种受人类内省推理过程启发的策略。使用MP，LLMs经历一系列有结构、自我意识的评估，利用其丰富的内在知识和新的见解。我们的实验涉及五个常见的LLMs：Llama2、Vicuna、PaLM、GPT-3.5和GPT-4，它们都涵盖了来自GLUE和SuperGLUE基准测试的各种通用自然语言理解 (NLU) 任务。结果表明，虽然GPT-4在大多数任务中始终表现出色，但配备MP的PaLM接近其性能水平。此外，跨模型和数据集，MP始终优于现有的提示方法。

    In Large Language Models (LLMs), there have been consistent advancements in task-specific performance, largely influenced by effective prompt design. While recent research on prompting has enhanced the reasoning capabilities of LLMs, a gap remains in further improving their understanding abilities. In this study, we introduce metacognitive prompting (MP), a strategy inspired by human introspective reasoning processes. Using MP, LLMs undergo a systematic series of structured, self-aware evaluations, drawing on both their vast inherent knowledge and new insights. Our experiments involve five prevalent LLMs: Llama2, Vicuna, PaLM, GPT-3.5, and GPT-4, all of which span various general natural language understanding (NLU) tasks from the GLUE and SuperGLUE benchmarks. Results indicate that, although GPT-4 consistently excels in most tasks, PaLM, when equipped with MP, approaches its performance level. Furthermore, across models and datasets, MP consistently outperforms existing prompting meth
    
[^38]: 人工智能生成文本与人类生成文本的分类：探索ChatGPT的特征

    Classification of Human- and AI-Generated Texts: Investigating Features for ChatGPT. (arXiv:2308.05341v1 [cs.CL])

    [http://arxiv.org/abs/2308.05341](http://arxiv.org/abs/2308.05341)

    本研究探索了分类人工智能生成文本与人类生成文本的问题，并研究了在人工智能以难以被人类辨认的方式进行文本生成时的更高级情况。实验结果显示，我们的最佳系统在区分基础和高级人工生成/人工智能生成文本时的F1分数超过96%，在区分基础和高级人工生成/人工智能重新表达文本时的F1分数超过78%。

    

    最近，像ChatGPT这样的生成型人工智能已经面向公众提供。这些工具可以被学生用来生成散文或整个论文。但是老师如何知道一篇文本是由学生还是由人工智能编写的？在我们的工作中，我们探索传统和新的特征来(1)检测由人工智能从头开始生成的文本和(2)由人工智能重新表达的文本。由于我们发现，当人工智能被指示以人类难以辨认的方式创建文本时，分类变得更加困难，我们还对这种更高级的情况进行了研究。为了进行实验，我们制作了涵盖10个学校话题的新文本语料库。我们最佳的基础和高级人工生成/人工智能生成文本分类系统的F1分数超过96%。我们最佳的对基础和高级人工生成/人工智能重新表达文本进行分类的系统的F1分数超过78%。

    Recently, generative AIs like ChatGPT have become available to the wide public. These tools can for instance be used by students to generate essays or whole theses. But how does a teacher know whether a text is written by a student or an AI? In our work, we explore traditional and new features to (1) detect text generated by AI from scratch and (2) text rephrased by AI. Since we found that classification is more difficult when the AI has been instructed to create the text in a way that a human would not recognize that it was generated by an AI, we also investigate this more advanced case. For our experiments, we produced a new text corpus covering 10 school topics. Our best systems to classify basic and advanced human-generated/AI-generated texts have F1-scores of over 96%. Our best systems for classifying basic and advanced human-generated/AI-rephrased texts have F1-scores of more than 78%. The systems use a combination of perplexity, semantic, list lookup, error-based, readability, A
    
[^39]: Adv-Inpainting:通过注意力引导的特征融合生成自然且可迁移的对抗性贴纸

    Adv-Inpainting: Generating Natural and Transferable Adversarial Patch via Attention-guided Feature Fusion. (arXiv:2308.05320v1 [cs.CV])

    [http://arxiv.org/abs/2308.05320](http://arxiv.org/abs/2308.05320)

    本文提出了一种称为Adv-Inpainting的创新攻击框架，通过注意力引导的特征融合生成自然且可迁移的对抗性贴纸，相比于传统的对抗性贴纸方法，该方法在生成图案和边界方面更加自然，并具有更强的迁移性能。

    

    最初的对抗性攻击利用加性噪声攻击人脸识别模型。然而，由于在实际环境中操作整个脸部是不切实际的，大多数现实世界中的人脸识别攻击都基于对抗性贴纸，将扰动限制在一个较小的区域内。先前的对抗性贴纸攻击常常导致不自然的图案和明显的边界，容易被察觉。我们认为生成带有合理内容的对抗性贴纸会比使用加性噪声或直接从潜在空间进行采样更具有更强的迁移性。为了生成自然且高度可迁移的对抗性贴纸，我们提出了一种创新的两阶段粗到精的攻击框架，称为Adv-Inpainting。在第一阶段中，我们提出了一种注意力引导的StyleGAN（Att-StyleGAN），根据注意力图自适应地结合纹理和身份特征，生成高度可迁移和自然的对抗性贴纸。

    The rudimentary adversarial attacks utilize additive noise to attack facial recognition (FR) models. However, because manipulating the total face is impractical in the physical setting, most real-world FR attacks are based on adversarial patches, which limit perturbations to a small area. Previous adversarial patch attacks often resulted in unnatural patterns and clear boundaries that were easily noticeable. In this paper, we argue that generating adversarial patches with plausible content can result in stronger transferability than using additive noise or directly sampling from the latent space. To generate natural-looking and highly transferable adversarial patches, we propose an innovative two-stage coarse-to-fine attack framework called Adv-Inpainting. In the first stage, we propose an attention-guided StyleGAN (Att-StyleGAN) that adaptively combines texture and identity features based on the attention map to generate high-transferable and natural adversarial patches. In the second
    
[^40]: 图聚类的同类性增强结构学习

    Homophily-enhanced Structure Learning for Graph Clustering. (arXiv:2308.05309v1 [cs.LG])

    [http://arxiv.org/abs/2308.05309](http://arxiv.org/abs/2308.05309)

    提出了一种名为HoLe的方法，通过在图结构中增强同类性可以显著改善图聚类任务的性能。

    

    图聚类是图分析中的一个基本任务，在利用图神经网络（GNNs）方面的最新进展已经取得了令人印象深刻的成果。尽管现有的基于GNN的图聚类方法取得了成功，但它们往往忽视了图结构的质量，这是由于现实世界图的稀疏性和多样性所固有的，从而导致了次优的性能。图结构学习可以通过添加缺失的连接和删除错误的连接来优化输入图。然而，以往的图结构学习工作主要集中在有监督的设置上，并且由于缺乏真实标签，不能直接应用于我们的特定聚类任务。为了弥补这个差距，我们提出了一种新颖的方法，称为同类性增强结构学习图聚类（HoLe）。我们的动机源于观察到，微妙地增强图结构中的同类性程度可以显著提升GNNs的性能。

    Graph clustering is a fundamental task in graph analysis, and recent advances in utilizing graph neural networks (GNNs) have shown impressive results. Despite the success of existing GNN-based graph clustering methods, they often overlook the quality of graph structure, which is inherent in real-world graphs due to their sparse and multifarious nature, leading to subpar performance. Graph structure learning allows refining the input graph by adding missing links and removing spurious connections. However, previous endeavors in graph structure learning have predominantly centered around supervised settings, and cannot be directly applied to our specific clustering tasks due to the absence of ground-truth labels. To bridge the gap, we propose a novel method called \textbf{ho}mophily-enhanced structure \textbf{le}arning for graph clustering (HoLe). Our motivation stems from the observation that subtly enhancing the degree of homophily within the graph structure can significantly improve G
    
[^41]: 图像和视频中的3D人体姿势估计的双链约束

    Double-chain Constraints for 3D Human Pose Estimation in Images and Videos. (arXiv:2308.05298v1 [cs.CV])

    [http://arxiv.org/abs/2308.05298](http://arxiv.org/abs/2308.05298)

    DC-GCT是一种新颖的模型，通过双链设计来约束图像和视频中的3D人体姿势估计，它结合了GCN和Transformer的优点，充分捕捉了人体关节之间的多级依赖关系。

    

    在缺乏深度信息的2D姿势重建3D姿势尤其具有挑战性，人类运动的复杂性和多样性是主要原因。关键在于有效地建模关节之间的空间约束，以利用它们的固有相互依赖性。因此，我们提出了一种新颖的模型，称为双链图卷积变换器 (DC-GCT)，通过由局部到全局和全局到局部构成的双链设计来约束姿势，以获得适用于当前人体姿势的复杂表示。具体而言，我们结合了GCN和Transformer的优点，并基于GCN设计了基于本地约束模块 (LCM) 和基于自注意力机制的全局约束模块 (GCM)，以及特征交互模块 (FIM)。所提出的方法充分捕捉了人体关节之间的多级依赖关系，以优化模型的建模能力。此外，我们还提出了一种将时间信息引入单帧模型的方法。

    Reconstructing 3D poses from 2D poses lacking depth information is particularly challenging due to the complexity and diversity of human motion. The key is to effectively model the spatial constraints between joints to leverage their inherent dependencies. Thus, we propose a novel model, called Double-chain Graph Convolutional Transformer (DC-GCT), to constrain the pose through a double-chain design consisting of local-to-global and global-to-local chains to obtain a complex representation more suitable for the current human pose. Specifically, we combine the advantages of GCN and Transformer and design a Local Constraint Module (LCM) based on GCN and a Global Constraint Module (GCM) based on self-attention mechanism as well as a Feature Interaction Module (FIM). The proposed method fully captures the multi-level dependencies between human body joints to optimize the modeling capability of the model. Moreover, we propose a method to use temporal information into the single-frame model 
    
[^42]: 多模态预训练模型用于序列决策：综合、验证、基础和感知

    Multimodal Pretrained Models for Sequential Decision-Making: Synthesis, Verification, Grounding, and Perception. (arXiv:2308.05295v1 [cs.AI])

    [http://arxiv.org/abs/2308.05295](http://arxiv.org/abs/2308.05295)

    该论文介绍了一种利用预训练模型的知识来解决序列决策任务的算法，通过构建和验证控制器，并通过视觉观测来与任务环境相连接。

    

    最近开发的预训练模型可以编码以多种形式表达的丰富世界知识，例如文本和图像。然而，这些模型的输出不能集成到解决序列决策任务的算法中。我们开发了一种算法，利用预训练模型的知识来构建和验证序列决策任务的控制器，并通过视觉观测将这些控制器与任务环境相连接。具体而言，该算法通过用户提供的基于文本的任务描述查询预训练模型，并使用模型的输出构建基于自动机的控制器，以编码模型的任务相关知识。然后，它验证控制器中编码的知识是否与其他独立可用的知识一致，这些知识可能包括环境的抽象信息或用户提供的规范。如果验证步骤发现任何不一致性，算法会自动纠正并重新验证，直到所有知识一致。

    Recently developed pretrained models can encode rich world knowledge expressed in multiple modalities, such as text and images. However, the outputs of these models cannot be integrated into algorithms to solve sequential decision-making tasks. We develop an algorithm that utilizes the knowledge from pretrained models to construct and verify controllers for sequential decision-making tasks, and to ground these controllers to task environments through visual observations. In particular, the algorithm queries a pretrained model with a user-provided, text-based task description and uses the model's output to construct an automaton-based controller that encodes the model's task-relevant knowledge. It then verifies whether the knowledge encoded in the controller is consistent with other independently available knowledge, which may include abstract information on the environment or user-provided specifications. If this verification step discovers any inconsistency, the algorithm automaticall
    
[^43]: 跨异质图少样本学习

    Cross-heterogeneity Graph Few-shot Learning. (arXiv:2308.05275v1 [cs.LG])

    [http://arxiv.org/abs/2308.05275](http://arxiv.org/abs/2308.05275)

    这项研究提出了一种跨异质图少样本学习模型，通过提取元模式和使用多视图异质图神经网络来捕获异质信息并学习跨异质图的元模式。

    

    近年来，异质图少样本学习被提出来解决异质图中标签稀疏问题，异质图包含多种类型的节点和边。现有的方法通过将从源异质图中丰富标记类提取的泛化知识转移到目标异质图中的少标记类来取得良好性能。然而，这些方法仅考虑源和目标异质图共享一组固定的节点/边类型的情况，忽略了更一般的跨异质图场景，即每个异质图可以有一个不同的、非固定的节点/边类型集合。为此，我们专注于未被探索的跨异质图场景，并提出了一种新的跨异质图少样本学习模型，即CGFL。在CGFL中，我们首先提取元模式来捕获异质信息，并提出了一种多视图异质图神经网络（MHGN）来学习跨异质图的元模式。然后，我们提出了一个范围子..

    In recent years, heterogeneous graph few-shot learning has been proposed to address the label sparsity issue in heterogeneous graphs (HGs), which contain various types of nodes and edges. The existing methods have achieved good performance by transferring generalized knowledge extracted from rich-labeled classes in source HG(s) to few-labeled classes in a target HG. However, these methods only consider the single-heterogeneity scenario where the source and target HGs share a fixed set of node/edge types, ignoring the more general scenario of cross-heterogeneity, where each HG can have a different and non-fixed set of node/edge types. To this end, we focus on the unexplored cross-heterogeneity scenario and propose a novel model for Cross-heterogeneity Graph Few-shot Learning, namely CGFL. In CGFL, we first extract meta-patterns to capture heterogeneous information and propose a multi-view heterogeneous graph neural network (MHGN) to learn meta-patterns across HGs. Then, we propose a sco
    
[^44]: AI4GCC -- 第三项赛道：消费和多机器人强化学习的挑战

    AI4GCC -- Track 3: Consumption and the Challenges of Multi-Agent RL. (arXiv:2308.05260v1 [cs.AI])

    [http://arxiv.org/abs/2308.05260](http://arxiv.org/abs/2308.05260)

    AI4GCC竞赛在将机器学习与传统经济政策分析相结合的方向上迈出重要一步。建议改进评估标准，考虑消费/效用，并进一步研究代理的学习动力学及谈判协议的博弈论属性。

    

    AI4GCC竞赛在将机器学习与传统经济政策分析相结合的方向上迈出了大胆的一步。在下面，我们强调了两个潜在的改进领域，可以增强比赛的能力，以识别和评估提出的谈判协议。首先，我们建议在评估标准中增加一个额外的指标，考虑到消费/效用。其次，我们建议进一步研究模拟器中代理的学习动力学以及来自提出的谈判协议的博弈论属性的结果。我们希望这些建议对未来的比赛/模拟有所帮助。

    The AI4GCC competition presents a bold step forward in the direction of integrating machine learning with traditional economic policy analysis. Below, we highlight two potential areas for improvement that could enhance the competition's ability to identify and evaluate proposed negotiation protocols. Firstly, we suggest the inclusion of an additional index that accounts for consumption/utility as part of the evaluation criteria. Secondly, we recommend further investigation into the learning dynamics of agents in the simulator and the game theoretic properties of outcomes from proposed negotiation protocols. We hope that these suggestions can be of use for future iterations of the competition/simulation.
    
[^45]: VQGAN中的向量量化损失分析：基于单个GPU的图像合成消融研究

    Vector quantization loss analysis in VQGANs: a single-GPU ablation study for image-to-image synthesis. (arXiv:2308.05242v1 [cs.CV])

    [http://arxiv.org/abs/2308.05242](http://arxiv.org/abs/2308.05242)

    本研究通过消融分析研究了图像合成中向量量化生成对抗网络（VQGAN）的影响，集中关注了向量量化损失、码书大小优化和与主成分分析的比较分析。虽然结果未超越现有基准，但对于较小数据集下VQGAN的行为和相关问题提供了重要的启示。

    

    本研究针对使用单个NVIDIA A100 GPU的图像合成进行了对向量量化生成对抗网络（VQGAN）的消融分析。本研究探索了在有限资源的约束下，包括纹理数量、码书向量属性和潜在维度等关键参数的微妙影响。值得注意的是，我们专注于向量量化损失，固定其他超参数和损失组件（GAN损失），以深入理解离散潜在空间以及变化大小对重构的影响。尽管我们的结果并没有超过现有的基准，但我们的发现在较小的数据集上对VQGAN的行为，特别是关于伪影、码书大小优化和与主成分分析（PCA）的比较分析方面，提供了重要的启示。

    This study performs an ablation analysis of Vector Quantized Generative Adversarial Networks (VQGANs), concentrating on image-to-image synthesis utilizing a single NVIDIA A100 GPU. The current work explores the nuanced effects of varying critical parameters including the number of epochs, image count, and attributes of codebook vectors and latent dimensions, specifically within the constraint of limited resources. Notably, our focus is pinpointed on the vector quantization loss, keeping other hyperparameters and loss components (GAN loss) fixed. This was done to delve into a deeper understanding of the discrete latent space, and to explore how varying its size affects the reconstruction. Though, our results do not surpass the existing benchmarks, however, our findings shed significant light on VQGAN's behaviour for a smaller dataset, particularly concerning artifacts, codebook size optimization, and comparative analysis with Principal Component Analysis (PCA). The study also uncovers t
    
[^46]: 利用边缘和云端技术实现自动驾驶中的实时物体检测

    Leveraging the Edge and Cloud for V2X-Based Real-Time Object Detection in Autonomous Driving. (arXiv:2308.05234v1 [cs.CV])

    [http://arxiv.org/abs/2308.05234](http://arxiv.org/abs/2308.05234)

    本论文研究利用边缘和云端技术实现自动驾驶中的实时物体检测。通过创建合成数据集，评估不同的外部化策略，并使用真实硬件和网络模拟进行比较，找到了权衡预测质量和端到端延迟的最佳方法。

    

    环境感知是自动驾驶的关键因素，因为感知模块接收到的信息会影响核心驾驶决策。实时感知在自动驾驶中的一大挑战在于在检测质量和延迟之间找到最佳权衡。对于自动驾驶中的实时感知，必须考虑到计算和功耗方面的主要限制。较大的物体检测模型往往能产生最佳结果，但在运行时也更慢。由于最准确的检测器无法在本地实时运行，我们研究将计算外部化到边缘和云平台的可能性，这些平台资源受限较少。我们创建了一个合成数据集来训练物体检测模型，并评估不同的外部化策略。我们使用真实硬件和网络模拟来比较不同的预测质量和端到端延迟之间的权衡。由于通过网络传送原始帧的实现存在困难和挑战，我们引入了压缩技术来降低数据传输量。

    Environmental perception is a key element of autonomous driving because the information received from the perception module influences core driving decisions. An outstanding challenge in real-time perception for autonomous driving lies in finding the best trade-off between detection quality and latency. Major constraints on both computation and power have to be taken into account for real-time perception in autonomous vehicles. Larger object detection models tend to produce the best results, but are also slower at runtime. Since the most accurate detectors cannot run in real-time locally, we investigate the possibility of offloading computation to edge and cloud platforms, which are less resource-constrained. We create a synthetic dataset to train object detection models and evaluate different offloading strategies. Using real hardware and network simulations, we compare different trade-offs between prediction quality and end-to-end delay. Since sending raw frames over the network impl
    
[^47]: Alexa，与机器人一起玩耍：引入第一届Alexa奖Embibod AI SimBot挑战

    Alexa, play with robot: Introducing the First Alexa Prize SimBot Challenge on Embodied AI. (arXiv:2308.05221v1 [cs.HC])

    [http://arxiv.org/abs/2308.05221](http://arxiv.org/abs/2308.05221)

    这篇论文介绍了第一届Alexa奖Embibod AI SimBot挑战，它是一个新的挑战，大学团队需要构建能够在模拟物理环境中完成任务的机器人助手。论文总结了挑战的概述和为团队提供的基础设施和支持，以及参与团队的方法。

    

    Alexa Prize计划赋予了许多大学生探索、实验和展示他们在构建会话代理方面的才能的机会，通过SocialBot大挑战和TaskBot挑战等挑战。随着会话代理在多模态和具体化的情境中越来越多地出现，探索通过计算机视觉和物理具体化增强的会话交互的能力变得重要。本文描述了SimBot挑战，这是一个新的挑战，在其中大学团队竞相构建能够在模拟物理环境中完成任务的机器人助手。本文概述了SimBot挑战，其中包括在线和离线挑战阶段。我们描述了为团队提供的基础设施和支持，包括Alexa Arena，模拟环境以及提供给团队加速构建视觉和语言模型的ML工具包。我们总结了参与团队的方法

    The Alexa Prize program has empowered numerous university students to explore, experiment, and showcase their talents in building conversational agents through challenges like the SocialBot Grand Challenge and the TaskBot Challenge. As conversational agents increasingly appear in multimodal and embodied contexts, it is important to explore the affordances of conversational interaction augmented with computer vision and physical embodiment. This paper describes the SimBot Challenge, a new challenge in which university teams compete to build robot assistants that complete tasks in a simulated physical environment. This paper provides an overview of the SimBot Challenge, which included both online and offline challenge phases. We describe the infrastructure and support provided to the teams including Alexa Arena, the simulated environment, and the ML toolkit provided to teams to accelerate their building of vision and language models. We summarize the approaches the participating teams to
    
[^48]: 通过人工智能"生成"工作：在线劳动市场的经验证据

    "Generate" the Future of Work through AI: Empirical Evidence from Online Labor Markets. (arXiv:2308.05201v1 [cs.AI])

    [http://arxiv.org/abs/2308.05201](http://arxiv.org/abs/2308.05201)

    这项研究通过利用ChatGPT作为外生冲击，揭示了其对在线劳动市场的影响。结果显示，直接接触ChatGPT的任务和自由职业者的交易量显著下降，但适应新技术并提供增强人工智能的服务的自由职业者仍能获得利益。

    

    随着通用生成式人工智能的出现，对其对劳动市场的影响的兴趣不断增加。为了填补现有的实证空白，我们将ChatGPT的推出解释为一种外生冲击，并采用差异法来量化其对在线劳动市场中与文本相关的工作和自由职业者的影响。我们的结果显示，直接接触ChatGPT的任务和自由职业者的交易量显著下降。此外，这种下降在相对较高的过去交易量或较低的质量标准下尤为显著。然而，并非所有服务提供商都普遍经历了负面影响。随后的分析表明，在这个转型期间，能够适应新进展并提供增强人工智能技术的服务的自由职业者可以获得可观的利益。因此，虽然ChatGPT的出现有可能替代人力劳动

    With the advent of general-purpose Generative AI, the interest in discerning its impact on the labor market escalates. In an attempt to bridge the extant empirical void, we interpret the launch of ChatGPT as an exogenous shock, and implement a Difference-in-Differences (DID) approach to quantify its influence on text-related jobs and freelancers within an online labor marketplace. Our results reveal a significant decrease in transaction volume for gigs and freelancers directly exposed to ChatGPT. Additionally, this decline is particularly marked in units of relatively higher past transaction volume or lower quality standards. Yet, the negative effect is not universally experienced among service providers. Subsequent analyses illustrate that freelancers proficiently adapting to novel advancements and offering services that augment AI technologies can yield substantial benefits amidst this transformative period. Consequently, even though the advent of ChatGPT could conceivably substitute
    
[^49]: 基于层次化表示的时空视觉注意力建模和理解

    Hierarchical Representations for Spatio-Temporal Visual Attention Modeling and Understanding. (arXiv:2308.05189v1 [cs.CV])

    [http://arxiv.org/abs/2308.05189](http://arxiv.org/abs/2308.05189)

    本文研究了基于层次化表示的时空视觉注意力建模和理解，在视频序列中提出了上下文感知的生成概率模型以及用于建模时空视觉注意力和时间领域注意力的深度网络架构。

    

    本博士论文研究和开发了基于层次化表示的时空视觉注意力建模和理解方法，针对视频序列中的视觉注意力问题，提出了两种计算模型。首先，我们提出了一种上下文感知的生成概率模型用于视觉注意力建模和理解。其次，我们开发了一个深度网络架构，用于建模上行的时空视觉注意力，并最终用于建模时间领域中的注意力。

    This PhD. Thesis concerns the study and development of hierarchical representations for spatio-temporal visual attention modeling and understanding in video sequences. More specifically, we propose two computational models for visual attention. First, we present a generative probabilistic model for context-aware visual attention modeling and understanding. Secondly, we develop a deep network architecture for visual attention modeling, which first estimates top-down spatio-temporal visual attention, and ultimately serves for modeling attention in the temporal domain.
    
[^50]: PromptPaint: 通过绘画媒介般的交互引导文本转图片生成

    PromptPaint: Steering Text-to-Image Generation Through Paint Medium-like Interactions. (arXiv:2308.05184v1 [cs.HC])

    [http://arxiv.org/abs/2308.05184](http://arxiv.org/abs/2308.05184)

    PromptPaint是一种结合了文字到图像生成和模拟绘画媒介交互的方法。它允许用户通过混合不同的提示来表达具有挑战性的概念，并支持在生成过程中对图像进行迭代塑造。研究结果表明，PromptPaint提供了一种灵活且强大的方式来生成图像。

    

    虽然基于扩散的文本转图片(T2I)模型提供了一种简单而强大的生成图像的方式，但是引导这种生成仍然是一个挑战。对于难以通过语言描述的概念，用户可能难以创建合适的提示。另外，许多这些模型都是以端到端系统的形式构建的，缺乏对图像的迭代塑造支持。为了应对这个问题，我们引入了PromptPaint，它将T2I生成与模拟我们使用彩色油漆的交互相结合。PromptPaint使用户能够超越语言，混合表达具有挑战性的概念的提示。就像我们通过在物理画布上层叠放置油漆来迭代调整颜色一样，PromptPaint同样允许用户在生成过程的不同画布区域和时间应用不同的提示。通过一系列的研究，我们对混合提示的不同方法、设计权衡以及生成模型的社会技术挑战进行了表征。通过PromptPaint，我们提供了对图像生成过程的洞察

    While diffusion-based text-to-image (T2I) models provide a simple and powerful way to generate images, guiding this generation remains a challenge. For concepts that are difficult to describe through language, users may struggle to create prompts. Moreover, many of these models are built as end-to-end systems, lacking support for iterative shaping of the image. In response, we introduce PromptPaint, which combines T2I generation with interactions that model how we use colored paints. PromptPaint allows users to go beyond language to mix prompts that express challenging concepts. Just as we iteratively tune colors through layered placements of paint on a physical canvas, PromptPaint similarly allows users to apply different prompts to different canvas areas and times of the generative process. Through a set of studies, we characterize different approaches for mixing prompts, design trade-offs, and socio-technical challenges for generative models. With PromptPaint we provide insight into
    
[^51]: 癫痫发作预测的比较分析：探索多样的预处理技术和机器学习模型

    Comparative Analysis of Epileptic Seizure Prediction: Exploring Diverse Pre-Processing Techniques and Machine Learning Models. (arXiv:2308.05176v1 [eess.SP])

    [http://arxiv.org/abs/2308.05176](http://arxiv.org/abs/2308.05176)

    本研究对使用EEG数据进行癫痫发作预测的五种机器学习模型进行了全面比较分析，通过应用多样的预处理技术和优化模型性能，为癫痫病人的有效管理和护理提供了准确且稳健的预测模型。

    

    癫痫是一种常见的神经系统疾病，其特点是反复发作和不可预测的癫痫发作，需要准确的预测以实施有效的管理和患者护理。机器学习（ML）应用于脑电图（EEG）记录，以及其在癫痫发作期间提供有价值的脑活动洞察的能力，使准确且稳健的癫痫发作预测成为相关研究中不可或缺的组成部分。在这项研究中，我们对使用EEG数据进行癫痫发作预测的五种机器学习模型进行了全面的比较分析 - 随机森林（RF），决策树（DT），极端森林（ET），逻辑回归（LR）和梯度提升（GB）。数据集经过了细致的预处理， 包括清理、归一化、异常值处理和过采样，以确保数据质量和便于准确的模型训练。这些预处理技术对于提高模型性能至关重要。

    Epilepsy is a prevalent neurological disorder characterized by recurrent and unpredictable seizures, necessitating accurate prediction for effective management and patient care. Application of machine learning (ML) on electroencephalogram (EEG) recordings, along with its ability to provide valuable insights into brain activity during seizures, is able to make accurate and robust seizure prediction an indispensable component in relevant studies. In this research, we present a comprehensive comparative analysis of five machine learning models - Random Forest (RF), Decision Tree (DT), Extra Trees (ET), Logistic Regression (LR), and Gradient Boosting (GB) - for the prediction of epileptic seizures using EEG data. The dataset underwent meticulous preprocessing, including cleaning, normalization, outlier handling, and oversampling, ensuring data quality and facilitating accurate model training. These preprocessing techniques played a crucial role in enhancing the models' performance. The res
    
[^52]: FPGA资源感知的实时神经网络结构修剪

    FPGA Resource-aware Structured Pruning for Real-Time Neural Networks. (arXiv:2308.05170v1 [cs.AR])

    [http://arxiv.org/abs/2308.05170](http://arxiv.org/abs/2308.05170)

    本文提出了一种FPGA资源感知的实时神经网络结构修剪方法，通过将修剪问题形式化为具有资源感知张量结构的背包问题，解决了修剪过程中非结构化稀疏和负载平衡效率低下的问题。

    

    神经网络在图像分类、语音识别、科学分析等众多应用领域中取得了最先进的性能。随着实时系统和物联网设备对更快的计算速度和更低的功耗需求的不断增加，FPGA已成为深度学习推断的合适设备。由于神经网络的高计算复杂性和内存占用，文献中提出了各种压缩技术，如修剪、量化和知识蒸馏。修剪稀疏化神经网络，减少了乘法和内存的数量。然而，修剪通常无法捕捉底层硬件的特性，导致非结构化稀疏和负载平衡效率低下，从而限制了资源改进。我们提出了一种以硬件为中心的修剪公式，将其形式化为具有资源感知张量结构的背包问题。

    Neural networks achieve state-of-the-art performance in image classification, speech recognition, scientific analysis and many more application areas. With the ever-increasing need for faster computation and lower power consumption, driven by real-time systems and Internet-of-Things (IoT) devices, FPGAs have emerged as suitable devices for deep learning inference. Due to the high computational complexity and memory footprint of neural networks, various compression techniques, such as pruning, quantization and knowledge distillation, have been proposed in literature. Pruning sparsifies a neural network, reducing the number of multiplications and memory. However, pruning often fails to capture properties of the underlying hardware, causing unstructured sparsity and load-balance inefficiency, thus bottlenecking resource improvements. We propose a hardware-centric formulation of pruning, by formulating it as a knapsack problem with resource-aware tensor structures. The primary emphasis is 
    
[^53]: 在目标检测的背景下，无数据模型提取攻击

    Data-Free Model Extraction Attacks in the Context of Object Detection. (arXiv:2308.05127v1 [cs.CR])

    [http://arxiv.org/abs/2308.05127](http://arxiv.org/abs/2308.05127)

    该论文提出了一种在目标检测中进行无数据模型提取的攻击方法，通过使用生成器生成特殊查询，成功实现了对私有数据集上训练的目标模型的窃取。通过定义损失函数和使用新颖的生成器设置，实现了对边界框坐标的预测问题的黑盒攻击。

    

    很多机器学习模型都容易受到模型提取攻击的威胁，这些攻击是通过使用针对目标模型的特殊查询来窃取模型的。这项任务通常使用训练数据的一部分或代理数据集来在白盒环境中训练一个模仿目标模型的新模型来完成。然而，在实际情况下，目标模型是在对手无法访问的私有数据集上训练的。无数据模型提取技术解决了这个问题，它使用类似生成对抗网络中使用的生成器来人工生成查询。我们首次提出了一个对回归问题的黑盒攻击，用于预测物体检测中的边界框坐标。在我们的研究中，我们发现定义损失函数和使用新颖的生成器设置是提取目标模型的关键因素之一。

    A significant number of machine learning models are vulnerable to model extraction attacks, which focus on stealing the models by using specially curated queries against the target model. This task is well accomplished by using part of the training data or a surrogate dataset to train a new model that mimics a target model in a white-box environment. In pragmatic situations, however, the target models are trained on private datasets that are inaccessible to the adversary. The data-free model extraction technique replaces this problem when it comes to using queries artificially curated by a generator similar to that used in Generative Adversarial Nets. We propose for the first time, to the best of our knowledge, an adversary black box attack extending to a regression problem for predicting bounding box coordinates in object detection. As part of our study, we found that defining a loss function and using a novel generator setup is one of the key aspects in extracting the target model. W
    
[^54]: 在联邦学习中平衡准确性和训练时间：暴力检测在监控视频中的神经网络架构研究

    Balancing Accuracy and Training Time in Federated Learning for Violence Detection in Surveillance Videos: A Study of Neural Network Architectures. (arXiv:2308.05106v1 [cs.CV])

    [http://arxiv.org/abs/2308.05106](http://arxiv.org/abs/2308.05106)

    本文研究了联邦学习环境下视频暴力检测的机器学习技术以及它们的适应性，通过在联邦学习环境中训练最佳暴力检测模型，实现了比现有模型更好的准确性结果。

    

    本文研究了联邦学习环境下视频暴力检测的机器学习技术以及它们的适应性。研究包括对基准视频数据集中提取的时空特征进行实验，比较不同方法，提出了一种修改版本的“Flow-Gated”架构，称为“Diff-Gated”。此外，探索了多种机器学习技术，包括超收敛和迁移学习，并开发了一种将集中式数据集适应到联邦学习环境的方法。通过在联邦学习环境中训练最佳暴力检测模型，研究实现了比现有模型更好的准确性结果。

    This paper presents an investigation into machine learning techniques for violence detection in videos and their adaptation to a federated learning context. The study includes experiments with spatio-temporal features extracted from benchmark video datasets, comparison of different methods, and proposal of a modified version of the "Flow-Gated" architecture called "Diff-Gated." Additionally, various machine learning techniques, including super-convergence and transfer learning, are explored, and a method for adapting centralized datasets to a federated learning context is developed. The research achieves better accuracy results compared to state-of-the-art models by training the best violence detection model in a federated learning context.
    
[^55]: 泛化少样本语义分割中的典型核学习与开放集前景感知

    Prototypical Kernel Learning and Open-set Foreground Perception for Generalized Few-shot Semantic Segmentation. (arXiv:2308.04952v1 [cs.CV])

    [http://arxiv.org/abs/2308.04952](http://arxiv.org/abs/2308.04952)

    本研究通过典型核学习和开放集前景感知，解决泛化少样本语义分割中的表示分割和嵌入偏见问题，并且在分割过程中使用了可学习的核以及典型学习和前景上下文感知模块来提高性能。

    

    泛化少样本语义分割（GFSS）将少样本语义分割（FSS）扩展到评估过程中同时分割未见过的类别和已见过的类别。先前的研究利用额外的分支或典型聚合来消除FSS的约束设置。然而，表示分割和嵌入偏见，严重影响GFSS的性能，尚未综合考虑。我们通过联合典型核学习和开放集前景感知来解决上述问题。具体而言，我们提出了一组可学习的核来对每个类别进行分割。然后，我们将典型学习与基类核的更新相结合，这与少样本新类别的原型知识聚合相一致。此外，采用与条件偏差基于推理的前景上下文感知模块，用于执行与类别无关的分割。

    Generalized Few-shot Semantic Segmentation (GFSS) extends Few-shot Semantic Segmentation (FSS) to simultaneously segment unseen classes and seen classes during evaluation. Previous works leverage additional branch or prototypical aggregation to eliminate the constrained setting of FSS. However, representation division and embedding prejudice, which heavily results in poor performance of GFSS, have not been synthetical considered. We address the aforementioned problems by jointing the prototypical kernel learning and open-set foreground perception. Specifically, a group of learnable kernels is proposed to perform segmentation with each kernel in charge of a stuff class. Then, we explore to merge the prototypical learning to the update of base-class kernels, which is consistent with the prototype knowledge aggregation of few-shot novel classes. In addition, a foreground contextual perception module cooperating with conditional bias based inference is adopted to perform class-agnostic as 
    
[^56]: 用大型语言模型进行累积推理的论文

    Cumulative Reasoning With Large Language Models. (arXiv:2308.04371v1 [cs.AI])

    [http://arxiv.org/abs/2308.04371](http://arxiv.org/abs/2308.04371)

    本文提出了一种名为累积推理（CR）的新方法，利用语言模型以累积和迭代的方式模拟人类思维过程，通过将任务分解为较小的组件，简化问题解决过程，取得了优于现有方法的性能，并在逻辑推理和24点游戏中实现了显著提升。

    

    虽然语言模型强大且多功能，但它们通常无法解决高度复杂的问题。这是因为解决复杂问题需要深思熟虑，而在训练过程中对此只有最小程度的指导。在本文中，我们提出了一种新方法，称为累积推理（CR），它以累积和迭代的方式利用语言模型来模拟人类的思维过程。通过将任务分解为较小的组件，我们的方法简化了问题解决过程，使其更易管理和更有效。对于逻辑推理任务，CR在性能上始终超过现有方法，提高了多达9.3％，并在经过策划的FOLIO维基数据集上实现了惊人的98.04％的准确率。在24点游戏的背景下，CR实现了94％的准确率，相比先前最先进的方法，提升了20％。

    While language models are powerful and versatile, they often fail to address highly complex problems. This is because solving complex problems requires deliberate thinking, which has been only minimally guided during training. In this paper, we propose a new method called Cumulative Reasoning (CR), which employs language models in a cumulative and iterative manner to emulate human thought processes. By decomposing tasks into smaller components, \ournameb streamlines the problem-solving process, rendering it both more manageable and effective. For logical inference tasks, CR consistently outperforms existing methods with an improvement up to 9.3\%, and achieves the astonishing accuracy of 98.04\% on the curated FOLIO wiki dataset. In the context of the Game of 24, CR achieves an accuracy of 94\%, which signifies a substantial enhancement of 20\% over the previous state-of-the-art method.
    
[^57]: Apple Vision Pro for Healthcare: “终极显示器”？（arXiv:2308.04313v1 [cs.AI]）

    Apple Vision Pro for Healthcare: "The Ultimate Display"?. (arXiv:2308.04313v1 [cs.AI])

    [http://arxiv.org/abs/2308.04313](http://arxiv.org/abs/2308.04313)

    苹果推出了Vision Pro，一款具有混合现实和增强现实功能的虚拟现实设备，拥有独特的特点，例如内部屏幕展示佩戴者的眼睛以及数字皇冠按钮的融合功能。这款无线设备可能实现了“终极显示器”的潜力。

    

    在2023年6月的全球开发者大会（WWDC）上，苹果推出了Vision Pro。Vision Pro是一款混合现实（MR）头盔，更具体地说，它是一款具有额外视频透视（VST）能力的虚拟现实（VR）设备。通过将真实世界通过摄像头传输到用户眼前的（VR）屏幕，使得Vision Pro也成为了增强现实（AR）设备。当然，这并不独特，与Varjo XR-3等其他设备类似。尽管如此，Vision Pro具有一些有趣的特点，例如内部屏幕可以向“外界”显示佩戴头盔者的眼睛，或者顶部的一个按钮称为“数字皇冠”，可以通过旋转无缝地融合数字内容与物理空间。此外，Vision Pro是无线的，只有电池的电缆连接，这使得头盔比Varjo XR-3更加灵活。这可能更接近“终极显示器”。

    At the Worldwide Developers Conference (WWDC) in June 2023, Apple introduced the Vision Pro. The Vision Pro is a Mixed Reality (MR) headset, more specifically it is a Virtual Reality (VR) device with an additional Video See-Through (VST) capability. The VST capability turns the Vision Pro also into an Augmented Reality (AR) device. The AR feature is enabled by streaming the real world via cameras to the (VR) screens in front of the user's eyes. This is of course not unique and similar to other devices, like the Varjo XR-3. Nevertheless, the Vision Pro has some interesting features, like an inside-out screen that can show the headset wearers' eyes to "outsiders" or a button on the top, called "Digital Crown", that allows you to seamlessly blend digital content with your physical space by turning it. In addition, it is untethered, except for the cable to the battery, which makes the headset more agile, compared to the Varjo XR-3. This could actually come closer to the "Ultimate Display",
    
[^58]: 适应无线通信规范信息综合的基础模型

    Adapting Foundation Models for Information Synthesis of Wireless Communication Specifications. (arXiv:2308.04033v1 [cs.NI])

    [http://arxiv.org/abs/2308.04033](http://arxiv.org/abs/2308.04033)

    本文介绍了NextGen Communications Copilot，这是一个用于无线通信规范信息综合的对话式人工智能工具。它采用基础模型，并引入了领域特定的数据库、上下文提取器和反馈机制，能够提供准确且相关的上下文信息，并结合专家反馈和数据贡献工具。在基准数据集的评估中，该系统展示了更多的优势。

    

    理解、开发和研究现代无线通信技术的现有方法涉及耗时且繁琐的过程，需要筛选大量的网页和技术规范文件，收集所需信息并进行综合。本文提出了NextGen Communications Copilot，这是一个用于无线通信规范信息综合的对话式人工智能工具。该系统基于最新的基础模型进展，并包括三个关键的附加组件：一个领域特定的数据库，一个上下文提取器和一个反馈机制。该系统可以从无线技术规范数据库中提取简洁的、与查询相关的上下文信息，并结合专家反馈和数据贡献工具。在使用由专家创建的查询和参考响应的基准数据集进行评估时，该系统展示了更多的优势。

    Existing approaches to understanding, developing and researching modern wireless communication technologies involves time-intensive and arduous process of sifting through numerous webpages and technical specification documents, gathering the required information and synthesizing it. This paper presents NextGen Communications Copilot, a conversational artificial intelligence tool for information synthesis of wireless communication specifications. The system builds on top of recent advancements in foundation models and consists of three key additional components: a domain-specific database, a context extractor, and a feedback mechanism. The system appends user queries with concise and query-dependent contextual information extracted from a database of wireless technical specifications and incorporates tools for expert feedback and data contributions. On evaluation using a benchmark dataset of queries and reference responses created by subject matter experts, the system demonstrated more 
    
[^59]: 保护守护者：在线儿童性虐待的自动化分析

    Guarding the Guardians: Automated Analysis of Online Child Sexual Abuse. (arXiv:2308.03880v1 [cs.AI])

    [http://arxiv.org/abs/2308.03880](http://arxiv.org/abs/2308.03880)

    这项研究介绍了一种自动化工具，用于全面分析儿童性虐待报告。通过自动化分析和分类，降低了接触有害内容的风险，并利用多学科团队的专业知识进行更深入的分析，以改善对基本模式和趋势的理解，帮助执法部门和决策者制定针对性的政策和行动。

    

    最近全球范围内对儿童的在线暴力事件有所增加，要求我们予以紧急关注。有关部门需要手动分析滥用投诉以了解犯罪动态并识别模式。然而，这些投诉的手动分析存在挑战，因为在审查过程中暴露分析员接触到有害内容。鉴于这些挑战，我们提出了一种创新的解决方案，即一种专为全面分析儿童性虐待报告而设计的自动化工具。通过自动化分析过程，我们的工具通过对报告在主题、犯罪程度和伤害程度三个维度进行分类，极大地降低了接触有害内容的风险。此外，利用我们多学科团队的专业知识，我们引入了一种新方法来对收集的数据进行注释，实现对报告的更深入分析。这种方法改善了对基本模式和趋势的理解，使执法部门和决策者能够创建

    Online violence against children has increased globally recently, demanding urgent attention. Competent authorities manually analyze abuse complaints to comprehend crime dynamics and identify patterns. However, the manual analysis of these complaints presents a challenge because it exposes analysts to harmful content during the review process. Given these challenges, we present a novel solution, an automated tool designed to analyze children's sexual abuse reports comprehensively. By automating the analysis process, our tool significantly reduces the risk of exposure to harmful content by categorizing the reports on three dimensions: Subject, Degree of Criminality, and Damage. Furthermore, leveraging our multidisciplinary team's expertise, we introduce a novel approach to annotate the collected data, enabling a more in-depth analysis of the reports. This approach improves the comprehension of fundamental patterns and trends, enabling law enforcement agencies and policymakers to create 
    
[^60]: AI-GOMS: 大型AI驱动的全球海洋模拟系统

    AI-GOMS: Large AI-Driven Global Ocean Modeling System. (arXiv:2308.03152v2 [physics.ao-ph] UPDATED)

    [http://arxiv.org/abs/2308.03152](http://arxiv.org/abs/2308.03152)

    提出了AI-GOMS，一个大型AI驱动的全球海洋模拟系统，用于准确高效的全球海洋每日预测。

    

    海洋模拟是模拟海洋的物理、化学和生物过程的强大工具，是海洋科学研究和运营海洋学的基础。现代数值海洋模拟主要包括控制方程和数值算法。非线性不稳定性、计算开销、低可重用效率和高耦合成本逐渐成为数值海洋模拟进一步发展的主要瓶颈。近年来，基于人工智能的科学计算模型展示了数字孪生和科学模拟的革命潜力，但数值海洋模拟的瓶颈尚未得到进一步解决。在这里，我们提出了AI-GOMS，一个大型AI驱动的全球海洋模拟系统，用于准确高效的全球海洋每日预测。AI-GOMS包括一个基于傅里叶变换的掩码自编码器结构的骨干模型，用于基本海洋变量预测和轻量级微调。

    Ocean modeling is a powerful tool for simulating the physical, chemical, and biological processes of the ocean, which is the foundation for marine science research and operational oceanography. Modern numerical ocean modeling mainly consists of governing equations and numerical algorithms. Nonlinear instability, computational expense, low reusability efficiency and high coupling costs have gradually become the main bottlenecks for the further development of numerical ocean modeling. Recently, artificial intelligence-based modeling in scientific computing has shown revolutionary potential for digital twins and scientific simulations, but the bottlenecks of numerical ocean modeling have not been further solved. Here, we present AI-GOMS, a large AI-driven global ocean modeling system, for accurate and efficient global ocean daily prediction. AI-GOMS consists of a backbone model with the Fourier-based Masked Autoencoder structure for basic ocean variable prediction and lightweight fine-tun
    
[^61]: 谁回答的更好？对ChatGPT和Stack Overflow回答软件工程问题进行深入分析

    Who Answers It Better? An In-Depth Analysis of ChatGPT and Stack Overflow Answers to Software Engineering Questions. (arXiv:2308.02312v1 [cs.SE])

    [http://arxiv.org/abs/2308.02312](http://arxiv.org/abs/2308.02312)

    本研究深入分析了ChatGPT和Stack Overflow回答软件工程问题的特点和可用性。结果显示，ChatGPT回答中有52%错误，77%冗长，但由于其综合性和清晰的语言表达，仍然在39.34%的情况下被使用者偏好选择。

    

    Q&A平台在过去十年中一直是程序员网上求助行为的重要组成部分。然而，随着ChatGPT的推出，网上求助行为的范式正在发生变化。尽管ChatGPT很受欢迎，但尚未进行全面的研究来评估ChatGPT回答软件工程问题的特点或可用性。为了填补这个空白，我们对ChatGPT回答517个Stack Overflow（SO）问题进行了首次深入分析，并对ChatGPT回答的正确性、一致性、综合性和简洁性进行了检查。此外，我们进行了大规模的语言分析和用户研究，以了解ChatGPT回答在语言和人类方面的特点。我们的分析表明，52％的ChatGPT回答是错误的，77％的回答冗长。尽管如此，由于其综合性和清晰的语言表达，ChatGPT回答仍然在39.34％的情况下受到青睐。

    Q&A platforms have been an integral part of the web-help-seeking behavior of programmers over the past decade. However, with the recent introduction of ChatGPT, the paradigm of web-help-seeking behavior is experiencing a shift. Despite the popularity of ChatGPT, no comprehensive study has been conducted to evaluate the characteristics or usability of ChatGPT's answers to software engineering questions. To bridge the gap, we conducted the first in-depth analysis of ChatGPT's answers to 517 Stack Overflow (SO) questions and examined the correctness, consistency, comprehensiveness, and conciseness of ChatGPT's answers. Furthermore, we conducted a large-scale linguistic analysis, and a user study to understand the characteristics of ChatGPT answers from linguistic and human aspects. Our analysis shows that 52\% of ChatGPT answers are incorrect and 77\% are verbose. Nonetheless, ChatGPT answers are still preferred 39.34\% of the time due to their comprehensiveness and well-articulated langu
    
[^62]: 视觉语言导航中的数据生成规模化

    Scaling Data Generation in Vision-and-Language Navigation. (arXiv:2307.15644v1 [cs.CV])

    [http://arxiv.org/abs/2307.15644](http://arxiv.org/abs/2307.15644)

    这项研究提出了一种用于视觉语言导航中生成大规模数据的有效范式。通过利用逼真的环境和网络资源，合成了490万个指令轨迹对。通过使用这个大规模数据集，通过简单的模仿学习，已存在的代理的性能得到了显著提升至80%。

    

    最近在语言引导的视觉导航研究中，对于遍历环境的多样性和训练可泛化代理的监督数量有了明显需求。为了解决现有视觉语言导航数据集中普遍存在的数据稀缺问题，我们提出了一种有效的范式，用于生成用于学习的大规模数据。我们应用了HM3D和Gibson数据集中的1200多个逼真的环境，并利用网络上的资源合成了490万个指令轨迹对。重要的是，我们调查了范式中每个组成部分对代理性能的影响，并研究了如何恰当地应用扩增数据来预训练和微调代理。得益于我们的大规模数据集，通过简单的模仿学习，现有代理的性能可以大幅提升（相对于之前的最佳结果绝对值增加了11%），在R2R测试集中单次运行成功率显著提升至80%。

    Recent research in language-guided visual navigation has demonstrated a significant demand for the diversity of traversable environments and the quantity of supervision for training generalizable agents. To tackle the common data scarcity issue in existing vision-and-language navigation datasets, we propose an effective paradigm for generating large-scale data for learning, which applies 1200+ photo-realistic environments from HM3D and Gibson datasets and synthesizes 4.9 million instruction trajectory pairs using fully-accessible resources on the web. Importantly, we investigate the influence of each component in this paradigm on the agent's performance and study how to adequately apply the augmented data to pre-train and fine-tune an agent. Thanks to our large-scale dataset, the performance of an existing agent can be pushed up (+11% absolute with regard to previous SoTA) to a significantly new best of 80% single-run success rate on the R2R test split by simple imitation learning. The
    
[^63]: 用于荒野SAR和寻找Patricia Wu-Murad的计算机视觉的开放问题

    Open Problems in Computer Vision for Wilderness SAR and The Search for Patricia Wu-Murad. (arXiv:2307.14527v1 [cs.CV])

    [http://arxiv.org/abs/2307.14527](http://arxiv.org/abs/2307.14527)

    该论文介绍了在荒野搜救中应用计算机视觉系统的挑战，提出了使用EfficientDET模型和无监督RX光谱分类器的方法，但在真实世界中存在假阳性的问题。

    

    本论文详细介绍了将两种计算机视觉系统，EfficientDET监督学习模型和无监督RX光谱分类器应用于来自日本Wu-Murad野外搜救（WSAR）努力的98.9 GB无人机图像的挑战，并确定了未来研究的3个方向。已经提出了至少19种方法和3个数据集，旨在在无人机图像中定位失踪人员，但只有3种方法（2种无监督和1种未知结构）在文献中被引用为实际WSAR操作中使用过。在这些提出的方法中，EfficientDET架构和无监督的RX光谱分类器被选择为最适合此情景的方法。EfficientDET模型应用于HERIDAL数据集，尽管在性能上达到了与最新技术相当的水平，但模型在假阳性方面无法在现实世界中有效识别（例如，识别树枝和岩石）

    This paper details the challenges in applying two computer vision systems, an EfficientDET supervised learning model and the unsupervised RX spectral classifier, to 98.9 GB of drone imagery from the Wu-Murad wilderness search and rescue (WSAR) effort in Japan and identifies 3 directions for future research. There have been at least 19 proposed approaches and 3 datasets aimed at locating missing persons in drone imagery, but only 3 approaches (2 unsupervised and 1 of an unknown structure) are referenced in the literature as having been used in an actual WSAR operation. Of these proposed approaches, the EfficientDET architecture and the unsupervised spectral RX classifier were selected as the most appropriate for this setting. The EfficientDET model was applied to the HERIDAL dataset and despite achieving performance that is statistically equivalent to the state-of-the-art, the model fails to translate to the real world in terms of false positives (e.g., identifying tree limbs and rocks 
    
[^64]: 通过可靠的、多样化的和类平衡的伪标签来重新审视领域自适应三维物体检测

    Revisiting Domain-Adaptive 3D Object Detection by Reliable, Diverse and Class-balanced Pseudo-Labeling. (arXiv:2307.07944v1 [cs.CV])

    [http://arxiv.org/abs/2307.07944](http://arxiv.org/abs/2307.07944)

    本文通过提出一种适用于多类训练设置的新型ReDB框架来解决现有领域自适应方法在多类训练设置下性能下降的问题，通过产生可靠的、多样化的和类平衡的伪三维框来引导目标领域的自训练。

    

    无监督领域自适应与伪标签技术的辅助已经成为领域自适应三维物体检测的关键方法。然而，现有的领域自适应方法在应用于多类训练设置时性能大幅下降，原因是伪标签的质量低和类别不平衡问题共存。本文通过提出一种针对同时学习检测所有类别的新型ReDB框架来解决这一挑战。我们的方法产生可靠的、多样化的和类平衡的伪三维框，通过迭代地引导不同分布的目标领域的自训练。为了减轻环境差异（例如，光束数量）带来的干扰，我们提出了跨域检查（CDE），通过将目标实例复制粘贴到源环境中并测量预测的一致性来评估伪标签的正确性。为了减少计算开销和缓解物体的转移（例如，

    Unsupervised domain adaptation (DA) with the aid of pseudo labeling techniques has emerged as a crucial approach for domain-adaptive 3D object detection. While effective, existing DA methods suffer from a substantial drop in performance when applied to a multi-class training setting, due to the co-existence of low-quality pseudo labels and class imbalance issues. In this paper, we address this challenge by proposing a novel ReDB framework tailored for learning to detect all classes at once. Our approach produces Reliable, Diverse, and class-Balanced pseudo 3D boxes to iteratively guide the self-training on a distributionally different target domain. To alleviate disruptions caused by the environmental discrepancy (e.g., beam numbers), the proposed cross-domain examination (CDE) assesses the correctness of pseudo labels by copy-pasting target instances into a source environment and measuring the prediction consistency. To reduce computational overhead and mitigate the object shift (e.g.
    
[^65]: 强化学习中的结构：调查与开放问题

    Structure in Reinforcement Learning: A Survey and Open Problems. (arXiv:2306.16021v1 [cs.LG])

    [http://arxiv.org/abs/2306.16021](http://arxiv.org/abs/2306.16021)

    这项调查研究了强化学习中结构的角色和重要性，并介绍了各个子领域在提高强化学习的性能方面所做的工作。

    

    强化学习（RL）借助深度神经网络（DNN）在函数逼近方面的表达能力，已经在许多应用中取得了相当大的成功。然而，在应对多样且不可预测的动态、嘈杂信号以及庞大的状态和动作空间等各种真实场景时，其实用性仍然有限。这个限制源于诸如数据效率低、泛化能力有限、缺少安全保证和不可解释性等问题。为了克服这些挑战并在这些关键指标上提高性能，一个有前途的途径是将问题的附加结构信息纳入强化学习的学习过程中。强化学习的各个子领域已经提出了许多方法来纳入这样的归纳偏差。我们将这些多样化的方法统一到一个框架下，揭示结构在学习问题中的作用。

    Reinforcement Learning (RL), bolstered by the expressive capabilities of Deep Neural Networks (DNNs) for function approximation, has demonstrated considerable success in numerous applications. However, its practicality in addressing a wide range of real-world scenarios, characterized by diverse and unpredictable dynamics, noisy signals, and large state and action spaces, remains limited. This limitation stems from issues such as poor data efficiency, limited generalization capabilities, a lack of safety guarantees, and the absence of interpretability, among other factors. To overcome these challenges and improve performance across these crucial metrics, one promising avenue is to incorporate additional structural information about the problem into the RL learning process. Various sub-fields of RL have proposed methods for incorporating such inductive biases. We amalgamate these diverse methodologies under a unified framework, shedding light on the role of structure in the learning prob
    
[^66]: 在Lenia中捕获新兴复杂性

    Capturing Emerging Complexity in Lenia. (arXiv:2305.09378v1 [cs.NE])

    [http://arxiv.org/abs/2305.09378](http://arxiv.org/abs/2305.09378)

    研究人工生命平台Lenia，通过识别复杂新兴行为的度量标准和使用遗传算法产生不同行为的结果，以进化出更好的Lenia行为。

    

    本研究项目探讨了Lenia，这是一个模拟数字生物系统的人工生命平台。Lenia的生态系统由简单的人工生物组成，它们可以移动、消耗、生长和繁殖。该平台是一个研究人工生命和进化的重要工具，因为它提供了一个可扩展和灵活的环境，用于创建具有不同能力和行为的多样化生物。该研究的关键是在Lenia中测量复杂性，识别测量规则的长期复杂性新兴行为的度量标准，旨在进化出尚未发现的更好的Lenia行为。遗传算法使用相邻区域或核作为基因型，同时保持Lenia的其他参数（例如生长函数）不变，以产生不同人口行为的结果，然后测量适应度值以决定所得行为的复杂性。首先，我们使用时间变化作为适应度函数，

    This research project investigates Lenia, an artificial life platform that simulates ecosystems of digital creatures. Lenia's ecosystem consists of simple, artificial organisms that can move, consume, grow, and reproduce. The platform is important as a tool for studying artificial life and evolution, as it provides a scalable and flexible environment for creating a diverse range of organisms with varying abilities and behaviors. Measuring complexity in Lenia is a key aspect of the study, which identifies the metrics for measuring long-term complex emerging behavior of rules, with the aim of evolving better Lenia behaviors which are yet not discovered. The Genetic Algorithm uses neighborhoods or kernels as genotype while keeping the rest of the parameters of Lenia as fixed, for example growth function, to produce different behaviors respective to the population and then measures fitness value to decide the complexity of the resulting behavior. First, we use Variation over Time as a fitn
    
[^67]: CLIP-Count：面向文本引导下零样本物体计数

    CLIP-Count: Towards Text-Guided Zero-Shot Object Counting. (arXiv:2305.07304v1 [cs.CV])

    [http://arxiv.org/abs/2305.07304](http://arxiv.org/abs/2305.07304)

    该研究提出了CLIP-Count，一种基于零样本文本引导的物体计数方法，不需要对特定对象类别进行微调，通过引入补丁-文本对比损失和分层的patch-text交互模块，获得了高效的密集预测结果。

    

    最近视觉-语言模型的进展显示出卓越的零样本文本-图像匹配能力，可转移到对象检测和分割等下游任务。然而，将这些模型适应于目标计数——估计图像中对象的数量，仍然是一个巨大的挑战。在本研究中，我们进行首次探索，将视觉-语言模型转移用于无类别偏见的物体计数。具体而言，我们提出了CLIP-Count，这是一种新颖的流程，它通过零样本的文本引导，为开放词汇对象估计密度图，而不需要在特定对象类别上进行任何微调。为了对齐文本嵌入和密集图像特征，我们引入了一个补丁-文本对比损失，指导模型学习有用的补丁级图像表示以进行密集预测。此外，我们设计了一个分层的patch-text交互模块，可以在不同的分辨率级别上传递语义信息。

    Recent advances in visual-language models have shown remarkable zero-shot text-image matching ability that is transferable to down-stream tasks such as object detection and segmentation. However, adapting these models for object counting, which involves estimating the number of objects in an image, remains a formidable challenge. In this study, we conduct the first exploration of transferring visual-language models for class-agnostic object counting. Specifically, we propose CLIP-Count, a novel pipeline that estimates density maps for open-vocabulary objects with text guidance in a zero-shot manner, without requiring any finetuning on specific object classes. To align the text embedding with dense image features, we introduce a patch-text contrastive loss that guides the model to learn informative patch-level image representations for dense prediction. Moreover, we design a hierarchical patch-text interaction module that propagates semantic information across different resolution level
    
[^68]: 基于神经网络的3D模拟超分辨率实现近实时面部动画表现

    Near-realtime Facial Animation by Deep 3D Simulation Super-Resolution. (arXiv:2305.03216v1 [cs.GR])

    [http://arxiv.org/abs/2305.03216](http://arxiv.org/abs/2305.03216)

    该论文提出了一种基于神经网络的3D模拟超分辨率框架，能够高效、逼真地增强低成本、实时物理模拟产生的面部表现，使其接近于具有更高分辨率和准确物理建模的参考质量离线模拟器。

    

    我们提出了一种基于神经网络的模拟超分辨率框架，能够高效、逼真地增强低成本、实时物理模拟产生的面部表现，使其接近于具有更高分辨率（在我们的实验中高达26倍的元素数）和准确物理建模的参考质量离线模拟器。我们的方法源于我们通过模拟构建一组配对帧序列的能力，这些序列分别来自于低分辨率和高分辨率模拟器，并且在语义上相互对应。我们以面部动画为例，创造这种语义一致性的方式就是在两个模拟器中调整同样的肌肉激活控制和骨架姿势。我们提出的神经网络超分辨率框架从这个训练集中泛化到看不见的表情，并且补偿两个模拟之间的建模差异。

    We present a neural network-based simulation super-resolution framework that can efficiently and realistically enhance a facial performance produced by a low-cost, realtime physics-based simulation to a level of detail that closely approximates that of a reference-quality off-line simulator with much higher resolution (26x element count in our examples) and accurate physical modeling. Our approach is rooted in our ability to construct - via simulation - a training set of paired frames, from the low- and high-resolution simulators respectively, that are in semantic correspondence with each other. We use face animation as an exemplar of such a simulation domain, where creating this semantic congruence is achieved by simply dialing in the same muscle actuation controls and skeletal pose in the two simulators. Our proposed neural network super-resolution framework generalizes from this training set to unseen expressions, compensates for modeling discrepancies between the two simulations du
    
[^69]: 自适应门控图卷积网络用于基于EEG数据的阿尔茨海默病可解释诊断

    Adaptive Gated Graph Convolutional Network for Explainable Diagnosis of Alzheimer's Disease using EEG Data. (arXiv:2304.05874v1 [q-bio.NC])

    [http://arxiv.org/abs/2304.05874](http://arxiv.org/abs/2304.05874)

    本文提出了一种自适应门控图卷积网络(AGGCN)，该网络结合卷积节点特征增强和功能连接度量自适应学习图结构，实现了高精度的阿尔茨海默病诊断，并提供了重要的脑区信息。

    

    近来，图神经网络(GNN)模型越来越多地被用于分类脑电图(EEG)数据，然而，基于GNN的神经系统疾病，如阿尔茨海默病(AD)的诊断仍然是相对未开发的领域。因此，本文提出了一种新颖的自适应门控图卷积网络(AGGCN)，该网络可以提供可解释的预测结果。AGGCN通过将基于卷积的节点特征增强与基于功能连接性的著名相关度量相结合来自适应学习图结构。此外，门控图卷积可以动态地加权考虑各种空间尺度的贡献。实验结果表明，该模型在闭眼和睁眼状态下均能取得较高的精度，表明学习到的表征结果的稳定性。最后，我们证明了所提出的AGGCN模型可以提供有关AD最受影响的脑区的重要见解。

    Graph neural network (GNN) models are increasingly being used for the classification of electroencephalography (EEG) data. However, GNN-based diagnosis of neurological disorders, such as Alzheimer's disease (AD), remains a relatively unexplored area of research. Previous studies have relied on functional connectivity methods to infer brain graph structures and used simple GNN architectures for the diagnosis of AD. In this work, we propose a novel adaptive gated graph convolutional network (AGGCN) that can provide explainable predictions. AGGCN adaptively learns graph structures by combining convolution-based node feature enhancement with a well-known correlation-based measure of functional connectivity. Furthermore, the gated graph convolution can dynamically weigh the contribution of various spatial scales. The proposed model achieves high accuracy in both eyes-closed and eyes-open conditions, indicating the stability of learned representations. Finally, we demonstrate that the propos
    
[^70]: 通过扩散去噪平滑进行认证和对抗性的鲁棒的样本外检测

    Diffusion Denoised Smoothing for Certified and Adversarial Robust Out-Of-Distribution Detection. (arXiv:2303.14961v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.14961](http://arxiv.org/abs/2303.14961)

    本研究提出了一个新的方法来证明$\ell_2$-norm下的样本外检测的鲁棒性，在不考虑网络架构和具体组件的情况下，改善了对抗攻击的检测技术。

    

    随着机器学习的应用不断扩展，确保其安全性变得尤为重要。其中一个主要关注点是识别给定样本是否来自训练分布，或者是一个“样本外”（OOD）样本。此外，对手可以以一种导致分类器做出自信预测的方式操纵OOD样本。本研究提出了一种新颖的方法，用于在输入的L2范围内证明在不考虑网络架构以及不需要特定组件或额外训练的情况下，对OOD检测的鲁棒性。此外，我们改进了检测OOD样本的对抗攻击的技术，同时提供了对于分布样本的高水平的认证和对抗的结果。在CIFAR10/100的所有OOD检测指标的平均值显示，与以前的方法相比提高了约13％/ 5％。

    As the use of machine learning continues to expand, the importance of ensuring its safety cannot be overstated. A key concern in this regard is the ability to identify whether a given sample is from the training distribution, or is an "Out-Of-Distribution" (OOD) sample. In addition, adversaries can manipulate OOD samples in ways that lead a classifier to make a confident prediction. In this study, we present a novel approach for certifying the robustness of OOD detection within a $\ell_2$-norm around the input, regardless of network architecture and without the need for specific components or additional training. Further, we improve current techniques for detecting adversarial attacks on OOD samples, while providing high levels of certified and adversarial robustness on in-distribution samples. The average of all OOD detection metrics on CIFAR10/100 shows an increase of $\sim 13 \% / 5\%$ relative to previous approaches.
    
[^71]: 让我们来聊聊吧！与ChatGPT的对话：技术，应用和限制。

    Let's have a chat! A Conversation with ChatGPT: Technology, Applications, and Limitations. (arXiv:2302.13817v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.13817](http://arxiv.org/abs/2302.13817)

    本文讨论了聊天机器人的历史概述以及ChatGPT背后的技术，强调了它在医疗保健、教育和研究中的潜在应用，并指出了其隐私和道德方面的担忧以及当前版本的重要限制。

    

    一款能够生成像人类一样的句子和写出连贯文章的人工智能聊天机器人ChatGPT的出现引起了世界的关注。本文讨论了聊天机器人的历史概述以及ChatGPT背后的技术。此外，还强调了ChatGPT在各个领域，包括医疗保健，教育和研究中的潜在应用。尽管有着令人期待的结果，但是ChatGPT周围存在着一些隐私和道德方面的担忧。另外，我们还强调了当前版本ChatGPT的一些重要限制。我们还向ChatGPT提出了一些问题，以便它表达自己的看法。

    The emergence of an AI-powered chatbot that can generate human-like sentences and write coherent essays has caught the world's attention. This paper discusses the historical overview of chatbots and the technology behind Chat Generative Pre-trained Transformer, better known as ChatGPT. Moreover, potential applications of ChatGPT in various domains, including healthcare, education, and research, are highlighted. Despite promising results, there are several privacy and ethical concerns surrounding ChatGPT. In addition, we highlight some of the important limitations of the current version of ChatGPT. We also ask ChatGPT to provide its point of view and present its responses to several questions we attempt to answer.
    
[^72]: RobustPdM：设计抗对抗攻击的鲁棒性预测维护

    RobustPdM: Designing Robust Predictive Maintenance against Adversarial Attacks. (arXiv:2301.10822v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2301.10822](http://arxiv.org/abs/2301.10822)

    本文提出了一种设计抗对抗攻击的鲁棒性预测维护系统的方法，通过分析不同类型的对抗性攻击的影响，为预测维护模型提出了一种新颖的对抗性防御技术。

    

    最先进的预测维护技术在降低复杂机器的维护成本和停机时间，提高整体生产率方面已经取得了巨大成功，通过广泛利用物联网和深度学习。不幸的是，物联网传感器和深度学习算法都容易受到网络攻击的影响。例如，深度学习算法对对抗性示例的敏感性已经被公认。然而，在预测维护领域，对抗性攻击的研究相对较少。这是因为在计算机视觉领域用于分类任务的对抗性攻击不能直接应用于多变量时间序列回归任务的预测维护领域。本文提出了一种端到端的方法来设计对抗性鲁棒的预测维护系统，通过广泛分析不同类型的对抗性攻击的影响，并为基于深度学习的预测维护模型提出了一种新颖的对抗性防御技术。

    The state-of-the-art predictive maintenance (PdM) techniques have shown great success in reducing maintenance costs and downtime of complicated machines while increasing overall productivity through extensive utilization of Internet-of-Things (IoT) and Deep Learning (DL). Unfortunately, IoT sensors and DL algorithms are both prone to cyber-attacks. For instance, DL algorithms are known for their susceptibility to adversarial examples. Such adversarial attacks are vastly under-explored in the PdM domain. This is because the adversarial attacks in the computer vision domain for classification tasks cannot be directly applied to the PdM domain for multivariate time series (MTS) regression tasks. In this work, we propose an end-to-end methodology to design adversarially robust PdM systems by extensively analyzing the effect of different types of adversarial attacks and proposing a novel adversarial defense technique for DL-enabled PdM models. First, we propose novel MTS Projected Gradient 
    
[^73]: 基于深度学习的农田导航农机作物行检测

    Deep learning-based Crop Row Detection for Infield Navigation of Agri-Robots. (arXiv:2209.04278v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2209.04278](http://arxiv.org/abs/2209.04278)

    本文提出了一种基于深度学习的农机作物行检测算法，能够在农田环境中应对多样的田间条件，通过低成本相机实现作物行检测和导航功能。

    

    农村环境中的自主导航面临着不断变化的田间条件的挑战。目前在这种环境下的自主导航解决方案需要昂贵的硬件，如RTK-GNSS。本文提出了一种强大的、能够应对这种田间变化的低成本相机作物行检测算法。现有的作物行检测数据集并不能代表所有可能的田间变化。我们创建了一个包含11个田间变化的甜菜图像数据集，包括多个生长阶段、光照水平变化、杂草密度不同、曲线作物行和不连续作物行等。所提出的方法使用基于深度学习的方法对作物行进行分割，并利用预测的分割掩模来提取中央作物，通过一种新颖的中央作物行选择算法。新颖的作物行检测算法经过测试，具有良好的作物行检测性能和可视伺服能力。

    Autonomous navigation in agricultural environments is challenged by varying field conditions that arise in arable fields. State-of-the-art solutions for autonomous navigation in such environments require expensive hardware such as RTK-GNSS. This paper presents a robust crop row detection algorithm that withstands such field variations using inexpensive cameras. Existing datasets for crop row detection does not represent all the possible field variations. A dataset of sugar beet images was created representing 11 field variations comprised of multiple grow stages, light levels, varying weed densities, curved crop rows and discontinuous crop rows. The proposed pipeline segments the crop rows using a deep learning-based method and employs the predicted segmentation mask for extraction of the central crop using a novel central crop row selection algorithm. The novel crop row detection algorithm was tested for crop row detection performance and the capability of visual servoing along a crop
    
[^74]: VAE解纷效果的重建损失被忽视的影响

    Overlooked Implications of the Reconstruction Loss for VAE Disentanglement. (arXiv:2202.13341v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2202.13341](http://arxiv.org/abs/2202.13341)

    VAE解纷结果的成因有待重新审视，研究发现数据与重建损失之间的关系是解耦的主要贡献者，标准的基准数据集根据典型的VAE重建损失与感知轴之间存在意外的相关性。

    

    学习具有变分自编码器（VAEs）的解耦表示通常归因于损失的正则化组件。在这项工作中，我们强调数据与损失的重建项之间的相互作用是VAEs中解耦的主要贡献者。我们发现，标准的基准数据集根据典型的VAE重建损失会导致它们的主观真实因素与数据中的感知轴之间存在意外的相关性。我们的工作利用这种关系为在给定重建损失下构建对抗数据集的理论提供了基础。我们通过构建一个示例数据集验证了这一点，该数据集阻碍了最先进框架中的解耦效果，同时保持了人类直观的真实因素。最后，我们通过设计一种示例重建损失，再次能够感知到真实因素来重新实现解耦效果。我们的发现证明了解耦的主观性质。

    Learning disentangled representations with variational autoencoders (VAEs) is often attributed to the regularisation component of the loss. In this work, we highlight the interaction between data and the reconstruction term of the loss as the main contributor to disentanglement in VAEs. We show that standard benchmark datasets have unintended correlations between their subjective ground-truth factors and perceived axes in the data according to typical VAE reconstruction losses. Our work exploits this relationship to provide a theory for what constitutes an adversarial dataset under a given reconstruction loss. We verify this by constructing an example dataset that prevents disentanglement in state-of-the-art frameworks while maintaining human-intuitive ground-truth factors. Finally, we re-enable disentanglement by designing an example reconstruction loss that is once again able to perceive the ground-truth factors. Our findings demonstrate the subjective nature of disentanglement and t
    

