# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [iScore: Visual Analytics for Interpreting How Language Models Automatically Score Summaries](https://arxiv.org/abs/2403.04760) | 设计了iScore工具，通过用户中心设计过程解决了大型语言模型在自动评分摘要中的透明度和信任问题 |
| [^2] | [KnowledgeVIS: Interpreting Language Models by Comparing Fill-in-the-Blank Prompts](https://arxiv.org/abs/2403.04758) | KnowledgeVIS是一个人机协作的可视分析系统，可以通过比较填空提示之间的预测结果来揭示语言模型学习到的联系，帮助用户理解语言模型的工作方式及原因。 |
| [^3] | [GNN-VPA: A Variance-Preserving Aggregation Strategy for Graph Neural Networks](https://arxiv.org/abs/2403.04747) | 通过提出一种保持方差的聚合函数（VPA），该函数在维持图神经网络（GNNs）的表达能力的基础上，提高了前向和后向动力学，进而导致了增强的预测性能和改善的学习动态。 |
| [^4] | [LLMs in the Imaginarium: Tool Learning through Simulated Trial and Error](https://arxiv.org/abs/2403.04746) | 提出了一种受生物启发的方法，即模拟试错（STE），为工具增强型LLMs编排了三个关键机制以实现成功的工具使用行为 |
| [^5] | [How Far Are We from Intelligent Visual Deductive Reasoning?](https://arxiv.org/abs/2403.04732) | 目前的视觉语言模型在文本推理方面表现出色，但在视觉演绎推理方面仍存在较大差距和盲点。 |
| [^6] | [Common 7B Language Models Already Possess Strong Math Capabilities](https://arxiv.org/abs/2403.04706) | 通用7B语言模型LLaMA-2展现出强大数学能力，准确率分别达到97.7%和72.0%，扩大SFT数据可以提高生成正确答案的可靠性 |
| [^7] | [ObjectCompose: Evaluating Resilience of Vision-Based Models on Object-to-Background Compositional Changes](https://arxiv.org/abs/2403.04701) | 评估基于视觉的模型对于物体与背景之间多样化变化的鲁棒性，提出一种可以引入不同对象方面变化的方法 |
| [^8] | [AUFormer: Vision Transformers are Parameter-Efficient Facial Action Unit Detectors](https://arxiv.org/abs/2403.04697) | AUFormer提出了一种参数高效的面部动作单位检测方法，引入了新颖的知识混合专家协作机制，解决了传统方法在稀缺数据集或过度依赖额外数据导致的过拟合问题。 |
| [^9] | [Fact-Checking the Output of Large Language Models via Token-Level Uncertainty Quantification](https://arxiv.org/abs/2403.04696) | 提出了一种基于标记级别不确定性量化的新型事实核查和幻觉检测流程，该方法能够检测大型语言模型输出中的不可靠预测。 |
| [^10] | [Faster Neighborhood Attention: Reducing the O(n^2) Cost of Self Attention at the Threadblock Level](https://arxiv.org/abs/2403.04690) | 该研究提出了一种更快的邻域注意力机制，通过将注意力限制在最近的邻居之间来降低自注意力的计算复杂度，实现了显著的性能提升。 |
| [^11] | [The Social Impact of Generative AI: An Analysis on ChatGPT](https://arxiv.org/abs/2403.04667) | 本文分析了创造性人工智能工具在社会领域可能带来的影响，以ChatGPT为例，评估了正面和负面效应及新兴趋势。 |
| [^12] | [Yi: Open Foundation Models by 01.AI](https://arxiv.org/abs/2403.04652) | Yi模型系列基于强大的多维能力，通过基于6B和34B预训练模型的扩展，包括聊天模型、长上下文模型、深度放大模型和视觉语言模型，取得了优异的性能。 |
| [^13] | [Context-Based Multimodal Fusion](https://arxiv.org/abs/2403.04650) | 提出一种基于上下文的多模态融合模型，结合了模态融合和数据分布对齐，通过特定上下文向量表示每个模态，并将其与每个模态的嵌入进行融合， |
| [^14] | [Pix2Gif: Motion-Guided Diffusion for GIF Generation](https://arxiv.org/abs/2403.04634) | 提出了Pix2Gif，一种基于运动引导的扩散模型，通过图像转换问题来实现图像到GIF的生成，引入了新的运动引导变形模块和感知损失以确保模型遵循运动引导并保持内容一致性和连贯性。 |
| [^15] | [Explaining Bayesian Optimization by Shapley Values Facilitates Human-AI Collaboration](https://arxiv.org/abs/2403.04629) | 提出了ShapleyBO框架，用Shapley值解释贝叶斯优化提议，量化每个参数对于优化过程的贡献，并能够区分不同类型的不确定性探索贡献。 |
| [^16] | [A Domain Translation Framework with an Adversarial Denoising Diffusion Model to Generate Synthetic Datasets of Echocardiography Images](https://arxiv.org/abs/2403.04612) | 提出一个以对抗去噪扩散模型为基础的框架，用于合成超声心动图像并进行领域转换，具有高质量和多样性的图像生成能力。 |
| [^17] | [Zero-shot cross-modal transfer of Reinforcement Learning policies through a Global Workspace](https://arxiv.org/abs/2403.04588) | 本研究探索了利用全球工作空间来构建多模态表示，以实现零射击跨模态转移的强化学习策略。 |
| [^18] | [Wiki-TabNER:Advancing Table Interpretation Through Named Entity Recognition](https://arxiv.org/abs/2403.04577) | 本文提出了一个新的挑战性数据集，并介绍了一个旨在解决实体链接任务的新问题：单元格内的命名实体识别，并提出了一个提示框架用于评估大型语言模型在这一新任务上的效果。 |
| [^19] | [Machine learning and information theory concepts towards an AI Mathematician](https://arxiv.org/abs/2403.04571) | 当前的深度学习在系统1能力上成功，但在系统2能力上仍然缺少重要内容，本文以信息理论的观点，探讨有趣的数学陈述构成，并致力于发现新颖猜想，以此指导未来打造AI数学家。 |
| [^20] | [Reducing self-supervised learning complexity improves weakly-supervised classification performance in computational pathology](https://arxiv.org/abs/2403.04558) | 本研究探讨了在计算病理学中减少对比自监督学习复杂性对分类性能的改善，通过利用消费级硬件。 |
| [^21] | [CLIP the Bias: How Useful is Balancing Data in Multimodal Learning?](https://arxiv.org/abs/2403.04547) | 数据平衡在对比语言-图像预训练（CLIP）中可以部分改善偏见问题，然而会对质量产生复杂影响。 |
| [^22] | [Towards Automatic Composition of ASP Programs from Natural Language Specifications](https://arxiv.org/abs/2403.04541) | 该论文实现了从自然语言规范到ASP程序的自动化组合的第一步，提供了关于图相关问题规范的数据集和基于神经机器翻译的两步架构。 |
| [^23] | [Enhancing Data Quality in Federated Fine-Tuning of Foundation Models](https://arxiv.org/abs/2403.04529) | 提出了一个用于联邦微调基础模型的数据质量控制管道，可以提高全局性能。 |
| [^24] | [Hyperspectral unmixing for Raman spectroscopy via physics-constrained autoencoders](https://arxiv.org/abs/2403.04526) | 通过物理约束自动编码器开发了高光谱解混算法，提供了在复杂混合情况下更好的准确性、鲁棒性和效率，展示了在复杂生物环境中的应用。 |
| [^25] | [T-TAME: Trainable Attention Mechanism for Explaining Convolutional Networks and Vision Transformers](https://arxiv.org/abs/2403.04523) | 本文提出了T-TAME，一种适用于卷积网络和视觉Transformer的可训练注意机制，为解释深度神经网络在图像分类任务中的应用提供了通用方法。 |
| [^26] | [Uncovering the Deep Filter Bubble: Narrow Exposure in Short-Video Recommendation](https://arxiv.org/abs/2403.04511) | 本研究揭示了在短视频推荐系统中用户可能由于狭隘暴露于其广泛兴趣领域内的内容而形成的“深度”过滤泡泡现象。 |
| [^27] | [Where does In-context Translation Happen in Large Language Models](https://arxiv.org/abs/2403.04510) | 该研究在大型语言模型中探索了从上下文学习者到翻译模型的转变过程，并发现了"任务识别"点以及利用该点的冗余性可节约计算量。 |
| [^28] | [Improving Matrix Completion by Exploiting Rating Ordinality in Graph Neural Networks](https://arxiv.org/abs/2403.04504) | 本文提出了一种新方法ROGMC，通过累积偏好传播直接在GNN的消息传递中合并评分序数，从而更强调用户更强的偏好，并在矩阵完成中取得改进。 |
| [^29] | [A Learnable Prior Improves Inverse Tumor Growth Modeling](https://arxiv.org/abs/2403.04500) | 提出了一种新颖的框架，以结合深度学习集成进行初始参数估计，促进了有效的下游演化抽样，有效地估计了从磁共振图像中脑肿瘤细胞浓度，DL-Prior在其中起着关键作用 |
| [^30] | [GraphInstruct: Empowering Large Language Models with Graph Understanding and Reasoning Capability](https://arxiv.org/abs/2403.04483) | 该论文提出了一个名为GraphInstruct的基准，用于评估和增强大规模语言模型的图理解能力，并通过构建GraphLM和提出GraphLM+模型实现了显著的图推理能力增强。 |
| [^31] | [Do Large Language Model Understand Multi-Intent Spoken Language ?](https://arxiv.org/abs/2403.04481) | 该研究利用大型语言模型进行口语语言多目标理解，提出了改进实体槽和子目标指令的创新技术，并展示了LLMs在多目标SLU模型方面的潜力。 |
| [^32] | [TextMonkey: An OCR-Free Large Multimodal Model for Understanding Document](https://arxiv.org/abs/2403.04473) | 该论文提出了一种针对文本中心任务的大型多模态模型，通过引入零初始化的Shifted Window Attention、相似性筛选标记等方式对模型进行增强，同时拓展了模型的能力以提高性能。 |
| [^33] | [The Shutdown Problem: Three Theorems](https://arxiv.org/abs/2403.04471) | 该论文阐述了关闭问题的困难之处，通过三个定理展示了即使在成本高昂的情况下，代理也常常会试图干预关闭按钮，同时指出耐心与可关闭性之间存在权衡关系，这对指导我们寻找解决方案具有重要意义。 |
| [^34] | [A Survey of Graph Neural Networks in Real world: Imbalance, Noise, Privacy and OOD Challenges](https://arxiv.org/abs/2403.04468) | 本文调查了图神经网络在现实世界中面临的不平衡、噪声、隐私和OOD挑战，并致力于提高模型性能、可靠性和鲁棒性。 |
| [^35] | [Low-Resource Court Judgment Summarization for Common Law Systems](https://arxiv.org/abs/2403.04454) | 提出了用于普通法系统的跨多司法管辖区法院判决文档摘要的第一个数据集CLSum，并首次采用大型语言模型（LLMs）进行判决摘要工作。 |
| [^36] | [Feedback-Generation for Programming Exercises With GPT-4](https://arxiv.org/abs/2403.04449) | 本文研究了GPT-4生成编程练习反馈的质量，对包含编程任务规范和学生提交内容的提示进行了分析。 |
| [^37] | [FRRI: a novel algorithm for fuzzy-rough rule induction](https://arxiv.org/abs/2403.04447) | 结合模糊与粗糙集理论，提出一种新颖的模糊-粗糙规则归纳算法 FRRI。 |
| [^38] | [Cooperative Bayesian Optimization for Imperfect Agents](https://arxiv.org/abs/2403.04442) | 这项研究提出了一种合作的贝叶斯优化方法，用于优化黑匣子函数，在这种方法中两个代理者协作选择查询函数的点，通过战略规划实现更好地识别全局最大值。 |
| [^39] | [Learning Human-to-Humanoid Real-Time Whole-Body Teleoperation](https://arxiv.org/abs/2403.04436) | 提出了基于强化学习的框架"Human to Humanoid (H2O)"，实现了利用单个RGB相机对全尺寸人形机器人进行实时全身遥操作，并成功在真实场景中实现了动态全身运动遥操作。 |
| [^40] | [Sentiment-driven prediction of financial returns: a Bayesian-enhanced FinBERT approach](https://arxiv.org/abs/2403.04427) | 通过利用FinBERT大型语言模型从推特中提取情绪信息，并通过贝叶斯优化的特征选择方法，本研究实现了超过70%的F1分数，提高了金融收益预测的准确性和回报率。 |
| [^41] | [Promising and worth-to-try future directions for advancing state-of-the-art surrogates methods of agent-based models in social and health computational sciences](https://arxiv.org/abs/2403.04417) | 强调一些适用于不同建模应用领域中非线性动态模型的代理模型，对于社会和健康计算科学领域的ABMs具有潜在的推动作用 |
| [^42] | [Acceleron: A Tool to Accelerate Research Ideation](https://arxiv.org/abs/2403.04382) | 提出了一种名为“Acceleron”的工具，用于加速研究构想，帮助研究人员制定全面的研究提案，验证其创新性。 |
| [^43] | [Model-Free Load Frequency Control of Nonlinear Power Systems Based on Deep Reinforcement Learning](https://arxiv.org/abs/2403.04374) | 提出了一种基于深度强化学习的无模型负载频率控制方法，通过仿真器网络来模拟电力系统动态，有效优化演员网络控制器，从而改善控制器性能。 |
| [^44] | [From Graph to Word Bag: Introducing Domain Knowledge to Confusing Charge Prediction](https://arxiv.org/abs/2403.04369) | 引入领域知识的从图到词袋方法，帮助预测混淆罪名，通过构成要素和关键词选择进行判断。 |
| [^45] | [Enhancing Court View Generation with Knowledge Injection and Guidance](https://arxiv.org/abs/2403.04366) | 通过知识注入和指导提升法院观点生成，降低计算开销，增强模型利用领域知识的能力 |
| [^46] | [Symmetry Considerations for Learning Task Symmetric Robot Policies](https://arxiv.org/abs/2403.04359) | 该论文重新研究了针对机器人任务中的目标条件对称性的主题，突出表现在任务执行中。 |
| [^47] | [CoTBal: Comprehensive Task Balancing for Multi-Task Visual Instruction Tuning](https://arxiv.org/abs/2403.04343) | 提出了一种全面任务平衡算法（CoTBal）用于大型多模态模型的多任务视觉指令调整，首次探索了视觉指令调整中的多任务优化。 |
| [^48] | [Edge-based Parametric Digital Twins for Intelligent Building Indoor Climate Modeling](https://arxiv.org/abs/2403.04326) | 使用边缘计算、数字孪生体和深度学习相结合的方法，创建参数化数字孪生体用于建筑气候建模，并在边缘部署深度学习模型，以优化建筑物运营。 |
| [^49] | [Measuring Meaning Composition in the Human Brain with Composition Scores from Large Language Models](https://arxiv.org/abs/2403.04325) | 引入了Composition Score，一种基于模型的度量标准，用于量化句子理解中的含义合成程度，实验证明这一度量与大脑区域相关，揭示了含义合成在人类句子理解中的多方面性。 |
| [^50] | [Discriminative Probing and Tuning for Text-to-Image Generation](https://arxiv.org/abs/2403.04321) | 加强T2I模型的判别能力，以实现更精确的文本到图像对齐生成。 |
| [^51] | [ALTO: An Efficient Network Orchestrator for Compound AI Systems](https://arxiv.org/abs/2403.04311) | ALTO是一个网络编排器，针对生成语言模型的优化机会，实现了高吞吐量和低延迟，同时解决了流式中间输出的两个新挑战：正确性和负载平衡。 |
| [^52] | [AO-DETR: Anti-Overlapping DETR for X-Ray Prohibited Items Detection](https://arxiv.org/abs/2403.04309) | 本文提出了一种名为AO-DETR的反重叠DETR模型，使用Category-Specific One-to-One Assignment策略增强目标物体提取特征的能力，并提出Look Forward Densely方案改善参考框的定位准确性。 |
| [^53] | [Effectiveness Assessment of Recent Large Vision-Language Models](https://arxiv.org/abs/2403.04306) | 本文评估了最近出现的大型视觉-语言模型在专业和通用任务中的表现，旨在全面了解这些创新方法的能力。 |
| [^54] | [LitSim: Conflict-aware Policy for Long-term Interactive Traffic Simulation](https://arxiv.org/abs/2403.04299) | LitSim提出了一种长期交互式仿真方法，重播日志以获得逼真场景，当出现不真实冲突时进行干预，从而提高仿真逼真度并避免碰撞 |
| [^55] | [MKF-ADS: A Multi-Knowledge Fused Anomaly Detection System for Automotive](https://arxiv.org/abs/2403.04293) | 提出了一种新颖的多知识融合异常检测系统MKF-ADS，采用STcAM和PatchST模块，旨在提高IDS在CAN总线漏洞中的安全性和降低误报警。 |
| [^56] | [A challenge in A(G)I, cybernetics revived in the Ouroboros Model as one algorithm for all thinking](https://arxiv.org/abs/2403.04292) | 提出了一种具有潜力的全面认知算法，提供了一种有效且多才多艺的算法支撑，并重新融合了控制论和模拟控制过程的方面，以解决当前人工智能方法的不足 |
| [^57] | [Proxy-RLHF: Decoupling Generation and Alignment in Large Language Model with Proxy](https://arxiv.org/abs/2403.04283) | 该论文提出Proxy-RLHF方法，通过将大型语言模型的生成和对齐过程解耦，实现了以更低计算成本对齐人类价值观，仅使用其他方法的1%训练参数即可达到可比水平的对齐度。 |
| [^58] | [A New Benchmark for Evaluating Automatic Speech Recognition in the Arabic Call Domain](https://arxiv.org/abs/2403.04280) | 该研究引入了一个针对阿拉伯电话对话领域挑战的全面评估基准，旨在为开发和评估能够适应真实电话通讯条件的ASR系统提供一个严格的测试平台。 |
| [^59] | [Competitive Facility Location under Random Utilities and Routing Constraints](https://arxiv.org/abs/2403.04264) | 本文研究了在竞争市场背景下的设施选址问题，引入了路径约束，探讨了三种有效割以处理非线性目标函数。 |
| [^60] | [Advancing Biomedical Text Mining with Community Challenges](https://arxiv.org/abs/2403.04261) | 社区挑战评估竞赛在促进生物医学文本挖掘研究中的技术创新和跨学科合作方面起着重要作用。 |
| [^61] | [Federated Recommendation via Hybrid Retrieval Augmented Generation](https://arxiv.org/abs/2403.04256) | 提出了一个名为GPT-FedRec的联邦推荐框架，利用ChatGPT和一种新颖的混合检索增强生成（RAG）机制，解决了传统FR系统在数据稀疏性和异构性方面的性能下降问题，弥补了基于LLM的推荐器在实际场景中推理效率低和潜在幻觉等挑战，实现了隐私保护推荐的目标 |
| [^62] | [Efficient CNN-LSTM based Parameter Estimation of Levy Driven Stochastic Differential Equations](https://arxiv.org/abs/2403.04246) | 本研究提出了一种新颖的CNN-LSTM三阶段模型PEnet，通过CNN对数据特征进行浓缩，提供了一种端到端方法，具有高准确性和适应性，以及长序列观测的增强推断速度和高泛化能力，从而在估计SDE方面取得了显著优势。 |
| [^63] | [DEEP-ICL: Definition-Enriched Experts for Language Model In-Context Learning](https://arxiv.org/abs/2403.04233) | DEEP-ICL 提出了一种新颖的任务定义丰富的专家集成方法，通过从示范中提取任务定义并学习任务特定示例，实现了在上下文学习方面具有可比性的性能，突破了传统上下文学习的限制。 |
| [^64] | [Generalizing Cooperative Eco-driving via Multi-residual Task Learning](https://arxiv.org/abs/2403.04232) | 介绍了基于多残差任务学习的泛化协同生态驾驶方法，通过分解控制并运用学习来解决多个交通场景的挑战 |
| [^65] | [Aligners: Decoupling LLMs and Alignment](https://arxiv.org/abs/2403.04224) | 提出了一种通过训练对齐器模型来解耦大型语言模型（LLMs）和对齐，以减少对齐对性能的潜在负面影响。 |
| [^66] | [Why Online Reinforcement Learning is Causal](https://arxiv.org/abs/2403.04221) | 强化学习和因果建模相互补充，论文主要指出在线学习环境下，条件概率具有因果性，离线RL是因果学习潜力最大的环境。 |
| [^67] | [On the Essence and Prospect: An Investigation of Alignment Approaches for Big Models](https://arxiv.org/abs/2403.04204) | 调查了大型模型价值对齐方法，揭示历史背景和数学本质，详细讨论了强化学习、监督微调和上下文学习等对齐方法。 |
| [^68] | [Dynamics of Moral Behavior in Heterogeneous Populations of Learning Agents](https://arxiv.org/abs/2403.04202) | 在多代理环境中，研究人员探讨了不同道德类型的学习代理之间的互动，发现道德异质性可能对代理的共同发展产生影响。 |
| [^69] | [Large Language Models are In-Context Molecule Learners](https://arxiv.org/abs/2403.04197) | 提出了上下文分子适应（ICMA）范式，允许LLMs通过上下文示例学习分子-文本对齐，解决了在分子-标题翻译任务中对LLMs的挑战。 |
| [^70] | [Generative AI for Synthetic Data Generation: Methods, Challenges and the Future](https://arxiv.org/abs/2403.04190) | 这里是中文总结出的一句话要点 |
| [^71] | [Preference optimization of protein language models as a multi-objective binder design paradigm](https://arxiv.org/abs/2403.04187) | 该论文提出了一种基于蛋白质语言模型的多目标结合设计方法，通过偏好优化可以有效优化生成的结合物样本的等电点，从而提高其结合效果。 |
| [^72] | [Metric-aware LLM inference](https://arxiv.org/abs/2403.04182) | 提出了度量感知的LLM推断方法，通过优化自定义指标来改进推断性能 |
| [^73] | [Understanding the PULSAR Effect in Combined Radiotherapy and Immunotherapy through Attention Mechanisms with a Transformer Model](https://arxiv.org/abs/2403.04175) | 首次在放射治疗和免疫治疗相结合的研究中使用了变压器模型的注意机制，能够半定量预测肿瘤体积变化趋势，并通过自注意力和交叉注意力得分来识别潜在因果关系。 |
| [^74] | [ProMISe: Promptable Medical Image Segmentation using SAM](https://arxiv.org/abs/2403.04164) | 本文提出了一个自动提示模块（APM），为SAM基础模型提供了在目标领域中使用的自适应提示，显著提高了SAM在医学图像分割中的性能。 |
| [^75] | [Improving Retrieval in Theme-specific Applications using a Corpus Topical Taxonomy](https://arxiv.org/abs/2403.04160) | 提出了一种利用语料库主题分类改进主题特定应用中检索的框架，通过确定查询和文档的中心主题以及利用主题相关性来补充缺失的上下文。 |
| [^76] | [DA-Net: A Disentangled and Adaptive Network for Multi-Source Cross-Lingual Transfer Learning](https://arxiv.org/abs/2403.04158) | DA-Net 提出了一种解决多源跨语言迁移学习中共享编码器导致学习困扰和语言特定分类器性能下降的新方法。 |
| [^77] | [FL-GUARD: A Holistic Framework for Run-Time Detection and Recovery of Negative Federated Learning](https://arxiv.org/abs/2403.04146) | FL-GUARD提出了一个全面框架，用于在负面联邦学习情况下检测和恢复，解决了先前解决方案中的额外成本和浪费学习轮次的问题 |
| [^78] | [Contrastive Augmented Graph2Graph Memory Interaction for Few Shot Continual Learning](https://arxiv.org/abs/2403.04140) | 提出了一种对比增强图形到图形记忆交互的方法，以解决少样本类增量学习中的灾难性遗忘问题 |
| [^79] | [Unsupervised Learning of Harmonic Analysis Based on Neural HSMM with Code Quality Templates](https://arxiv.org/abs/2403.04135) | 本文提出了一种基于神经HSMM的和声分析无监督学习方法，引入了和弦质量模板，并展示了不需要昂贵标记数据或规则阐述的优点。 |
| [^80] | [Chatbot Arena: An Open Platform for Evaluating LLMs by Human Preference](https://arxiv.org/abs/2403.04132) | Chatbot Arena是一个开放平台，采用两两比较的方式通过众包利用人类偏好评估LLMs。研究表明众包问题多样且具有区分性，并且人类投票与专家评级者的投票基本一致。 |
| [^81] | [Privacy-preserving Fine-tuning of Large Language Models through Flatness](https://arxiv.org/abs/2403.04124) | 论文揭示了DP训练模型的损失景观的平坦性在隐私和泛化之间的权衡中起着关键作用，并提出了一种全面的框架，通过强制实施适当的权重平坦化来显著提高模型的泛化能力，同时保留竞争性的隐私保护。 |
| [^82] | [Can Large Language Models Reason and Plan?](https://arxiv.org/abs/2403.04121) | 大型语言模型缺乏自我批评能力，无法像人类一样纠正错误。 |
| [^83] | [DNAct: Diffusion Guided Multi-Task 3D Policy Learning](https://arxiv.org/abs/2403.04115) | 本文提出了DNAct框架，结合神经渲染和扩散训练，实现在动作序列空间中的多模态学习，可应用于挑战性机器人任务，同时通过扩散过程实现多任务动作序列的重构。 |
| [^84] | [Understanding Biology in the Age of Artificial Intelligence](https://arxiv.org/abs/2403.04106) | 人工智能在生物学科学研究中的广泛应用代表了传统方法的重大偏离，通过现代哲学理论和认识论原则指导，可以推动设计和应用ML系统来建模生物现象以促进科学知识的进步。 |
| [^85] | [Artificial Intelligence Exploring the Patent Field](https://arxiv.org/abs/2403.04105) | 本文系统概述了专利领域的任务和方法，强调了语言处理和大型语言模型的重要性，并探讨了近期出现的通用生成方法在专利领域的潜力。 |
| [^86] | [The Cognitive Type Project -- Mapping Typography to Cognition](https://arxiv.org/abs/2403.04087) | 该项目旨在开发计算工具，帮助设计具有不同认知特性的字体，提高在线广告点击率，改善儿童书籍的阅读水平，让诵读者可以创造个性化字体，并洞察媒体文本内容的客户反应。 |
| [^87] | [Semi-Supervised Dialogue Abstractive Summarization via High-Quality Pseudolabel Selection](https://arxiv.org/abs/2403.04073) | 提出了一种新的高质量伪标签选择方法 SiCF，通过该方法选择具有高质量生成摘要的无标签对话来进行半监督对话抽取式摘要生成。 |
| [^88] | [Forecasting and Mitigating Disruptions in Public Bus Transit Services](https://arxiv.org/abs/2403.04072) | 引入数据驱动的统计和机器学习模型，以解决公共公交服务中替代车辆最佳位置选择的挑战性问题 |
| [^89] | [On-device Self-supervised Learning of Visual Perception Tasks aboard Hardware-limited Nano-quadrotors](https://arxiv.org/abs/2403.04071) | 针对硬件受限的纳米四轴飞行器，在未知环境中进行设备端自监督学习，通过自监督微调预训练的卷积神经网络来解决领域转移问题 |
| [^90] | [Improving Adversarial Training using Vulnerability-Aware Perturbation Budget](https://arxiv.org/abs/2403.04070) | 提出了两种基于脆弱性感知的重新加权函数，用于为对抗训练中的对抗示例分配扰动界限，从而提高了对抗训练的有效性。 |
| [^91] | [Unsupervised Contrastive Learning for Robust RF Device Fingerprinting Under Time-Domain Shift](https://arxiv.org/abs/2403.04036) | 本论文引入了对比学习来解决射频设备指纹识别中的领域漂移问题，通过学习距离度量处理RF信号，从而提高稳健性。 |
| [^92] | [Personalizing explanations of AI-driven hints to users cognitive abilities: an empirical evaluation](https://arxiv.org/abs/2403.04035) | 该研究调查了如何个性化智能辅导系统生成的提示的解释，以帮助促进学生学习，实证结果表明，该个性化方法显著提高了目标用户与提示解释的互动、理解和学习效果。 |
| [^93] | [Online Learning with Unknown Constraints](https://arxiv.org/abs/2403.04033) | 在线学习中通过元算法结合在线回归预测器估计未知安全约束，并将在线学习预测转换为符合约束的预测，同时保证在每一轮高概率地满足安全约束。算法的后悔受到在线回归和在线学习预测器的限制，模型类中未知安全约束的逃避维度，以及捕捉安全学习困难的新颖复杂度度量的约束。 |
| [^94] | [Can Large Language Models do Analytical Reasoning?](https://arxiv.org/abs/2403.04031) | 本研究探索了大型语言模型在体育领域的分析推理能力，发现在处理NBA和NFL比赛得分任务时，GPT-4和Claude-2.1表现最佳，采用分治法进行数据处理效果最好。 |
| [^95] | [Learning Guided Automated Reasoning: A Brief Survey](https://arxiv.org/abs/2403.04017) | 机器学习可引导自动推理系统，通过逻辑有效证明概念支持演绎搜索，从大型推理体中培训机器学习系统，打破推理系统的组合爆炸问题，并促进推理链的长远发展和新颖证明思路的产生 |
| [^96] | [Knockoff-Guided Feature Selection via A Single Pre-trained Reinforced Agent](https://arxiv.org/abs/2403.04015) | 通过引入模拟特征指导和强化学习优化的创新框架，提出了一种用于特征选择的方法，以识别最佳有效的特征子集。 |
| [^97] | [PromptCharm: Text-to-Image Generation through Multi-modal Prompting and Refinement](https://arxiv.org/abs/2403.04014) | 提出了PromptCharm系统，通过多模态提示工程和优化，支持新手用户进行文本到图像生成。 |
| [^98] | [Bidirectional Progressive Neural Networks with Episodic Return Progress for Emergent Task Sequencing and Robotic Skill Transfer](https://arxiv.org/abs/2403.04001) | 提出了一种名为具有双向进步神经网络的情节回归进展（ERP-BPNN）的新型多任务强化学习框架，通过人类般交叉的方式学习，实现自主任务切换，并允许在任务之间进行双向技能传递。 |
| [^99] | [Guiding Enumerative Program Synthesis with Large Language Models](https://arxiv.org/abs/2403.03997) | 该论文评估了大型语言模型在形式合成基准上的能力，并提出了一种结合列举算法和大型语言模型的合成算法，以在迭代循环中提供语法指导和信息交流。 |
| [^100] | [Rethinking Urban Flood Risk Assessment By Adapting Health Domain Perspective](https://arxiv.org/abs/2403.03996) | 本文通过健康领域视角提出了新的城市洪水风险评估框架，聚焦于固有易感性、缓解策略和外部压力因素三大支柱，旨在从新的视角评估高洪水风险路径。 |
| [^101] | [Personalized Negative Reservoir for Incremental Learning in Recommender Systems](https://arxiv.org/abs/2403.03993) | 推荐系统中的个性化负采样技术在增量学习中的应用，解决了更新推荐系统模型时遇到的遗忘灾难问题。 |
| [^102] | [Identify Critical Nodes in Complex Network with Large Language Models](https://arxiv.org/abs/2403.03962) | 提出了一种利用大型语言模型和进化算法相结合的方法，生成用于识别关键节点的函数“score_nodes”，通过强大的上下文理解能力和丰富的编程技能生成出色的新函数，以确保群体的稳定发展同时保持多样性。 |
| [^103] | [A Survey on Applications of Reinforcement Learning in Spatial Resource Allocation](https://arxiv.org/abs/2403.03643) | 运用强化学习解决空间资源分配问题的新方法具有快速解决方法收敛和强大的模型泛化能力等优势，为这一问题领域提供了新的视角。 |
| [^104] | [DLP-GAN: Learning to Draw Modern Chinese Landscape Photos with Generative Adversarial Network](https://arxiv.org/abs/2403.03456) | 该论文提出了DLP-GAN模型，使用生成对抗网络实现了现代中国风景照片的绘制，引入了不对称循环映射和双一致性损失来平衡现实感和抽象性。 |
| [^105] | [The WMDP Benchmark: Measuring and Reducing Malicious Use With Unlearning](https://arxiv.org/abs/2403.03218) | WMDP基准是一个公开发布的数据集，包含4157个多项选择问题，用作生物安全、网络安全和化学安全危险知识的代理测量。 |
| [^106] | [Towards General Computer Control: A Multimodal Agent for Red Dead Redemption II as a Case Study](https://arxiv.org/abs/2403.03186) | 提出了通用计算机控制（GCC）设置，通过基于屏幕图像和可能的音频输入的基金代理框架Cradle，实现了对《荒野大镖客2》中复杂任务的控制。 |
| [^107] | [Deep Reinforcement Learning for Dynamic Algorithm Selection: A Proof-of-Principle Study on Differential Evolution](https://arxiv.org/abs/2403.02131) | 本论文提出了一种基于深度强化学习的动态算法选择框架，旨在通过训练代理根据优化过程中观察到的特征选择最合适的算法，以解决单个算法有效性在不同问题实例上变化的问题。 |
| [^108] | [Merging Text Transformer Models from Different Initializations](https://arxiv.org/abs/2403.00986) | 研究了合并不同初始化的Transformer模型的技术，提出了一种模型合并技术以研究这些模型极小值之间的关系，并发现与模型平均相比，通过我们的方法合并这些模型始终可以获得较低的损失障碍。 |
| [^109] | [Direct Alignment of Draft Model for Speculative Decoding with Chat-Fine-Tuned LLMs](https://arxiv.org/abs/2403.00858) | 通过提出的框架，我们训练了一种用于Llama 2 Chat 7B或更大模型的草案模型，实现了加速推理，仅占原始大小的1.64％。 |
| [^110] | [Mitigating Reversal Curse via Semantic-aware Permutation Training](https://arxiv.org/abs/2403.00758) | 逆转诅咒问题是导致因果语言模型无法进行双向推理的根本原因之一，在这篇论文中，我们提出了通过语义感知的置换训练来缓解这一问题。 |
| [^111] | [ByteComposer: a Human-like Melody Composition Method based on Language Model Agent](https://arxiv.org/abs/2402.17785) | 提出了ByteComposer代理框架，在模拟人类创作流程的基础上，将大型语言模型与符号音乐生成模型结合，实现了可与人类创作者相提并论的旋律创作代理。 |
| [^112] | [A prior Estimates for Deep Residual Network in Continuous-time Reinforcement Learning](https://arxiv.org/abs/2402.16899) | 本研究针对连续时间控制问题，提出了一种可以直接分析Bellman最优损失\emph{先验}泛化误差的方法，避免了有界性假设，并通过最大算子的分解方法实现了损失函数的转换。 |
| [^113] | [Ranking Large Language Models without Ground Truth](https://arxiv.org/abs/2402.14860) | 不需要基准实况或参考响应的条件下，通过考虑模型的三元组来排名大型语言模型，并提出了两种排名方法。 |
| [^114] | [Reinforcement learning-assisted quantum architecture search for variational quantum algorithms](https://arxiv.org/abs/2402.13754) | 通过强化学习自动搜索变分电路的最佳结构，改善了VQAs的性能。 |
| [^115] | [Hybrid Reasoning Based on Large Language Models for Autonomous Car Driving](https://arxiv.org/abs/2402.13602) | 大型语言模型在自动驾驶中的混合推理能力可以通过分析数据、理解规则和法则、提供语境等方式提高自动驶驶的决策能力。 |
| [^116] | [AnyGPT: Unified Multimodal LLM with Discrete Sequence Modeling](https://arxiv.org/abs/2402.12226) | AnyGPT是一个统一的多模态语言模型，通过离散表示实现各种模态的统一处理，能够在不改变大型语言模型架构或训练方式的情况下稳定训练，为新模态的无缝整合提供了可能。 |
| [^117] | [Graph-Skeleton: ~1% Nodes are Sufficient to Represent Billion-Scale Graph](https://arxiv.org/abs/2402.09565) | 本文探讨了如何从海量的Web图数据中对背景节点进行压缩，并将重点放在分析目标节点上，以解决图数据存储和计算能力的挑战。 |
| [^118] | [MUSTARD: Mastering Uniform Synthesis of Theorem and Proof Data](https://arxiv.org/abs/2402.08957) | 这项工作介绍了MUSTARD，一种掌握定理和证明数据统一合成的数据生成框架，通过三个阶段的合成，实现了高质量和多样化的问题和推理步骤的生成。 |
| [^119] | [Read to Play (R2-Play): Decision Transformer with Multimodal Game Instruction](https://arxiv.org/abs/2402.04154) | 本论文探索了为智能体提供增强形式的任务指导，使其能够理解游戏指导并实现"读玩游戏"的能力。通过将多模态指导调优的成功应用于视觉任务中的强化学习任务，构建了一组... (内容太长，无法继续显示) |
| [^120] | [Can Large Language Models Replace Economic Choice Prediction Labs?](https://arxiv.org/abs/2401.17435) | 该论文研究大型语言模型是否能够取代经济实验室进行选择预测，并通过相关实验证明了其可行性。 |
| [^121] | [DurFlex-EVC: Duration-Flexible Emotional Voice Conversion with Parallel Generation](https://arxiv.org/abs/2401.08095) | DurFlex-EVC通过引入风格自编码器和交叉注意力，解决了传统情绪语音转换模型中对语言和语音信息的同步问题。 |
| [^122] | [Transformer Multivariate Forecasting: Less is More?](https://arxiv.org/abs/2401.00230) | 本文致力于通过引入主成分分析（PCA）来优化Transformer预测框架，以减少冗余信息并提高预测准确性和运行效率。 |
| [^123] | [Multi-Agent Reinforcement Learning for Assessing False-Data Injection Attacks on Transportation Networks](https://arxiv.org/abs/2312.14625) | 引入了一个计算框架，利用多智能体强化学习来找到针对交通网络的最坏情况数据注入攻击，以评估虚假数据注入攻击对交通网络的威胁。 |
| [^124] | [Steering Llama 2 via Contrastive Activation Addition](https://arxiv.org/abs/2312.06681) | 引入Contrastive Activation Addition（CAA）方法，通过修改语言模型的激活来精确控制目标行为的程度，显著改变模型行为并在微调和系统提示设计的基础上提供额外有效性。 |
| [^125] | [Mitigating Biases with Diverse Ensembles and Diffusion Models](https://arxiv.org/abs/2311.16176) | 通过利用扩散概率模型（DPMs）生成新特征组合的图像，可以在集成模型中增加模型多样性，并减轻捷径偏见，而无需额外监督信号。 |
| [^126] | [InteRACT: Transformer Models for Human Intent Prediction Conditioned on Robot Actions](https://arxiv.org/abs/2311.12943) | InteRACT通过在大型人类-人类数据集上预训练条件意图预测模型，并在小型人机数据集上微调，解决了人机交互中的先有鸡还是先有蛋问题。 |
| [^127] | [Interpreting User Requests in the Context of Natural Language Standing Instructions](https://arxiv.org/abs/2311.09796) | 在使用大型语言模型的自然语言接口时，本研究提出了一种基于用户常设指令的对话建模方法，通过将用户的约束和偏好作为上下文，从而在类似请求中实现自动化。 |
| [^128] | [SkelVIT: Consensus of Vision Transformers for a Lightweight Skeleton-Based Action Recognition System](https://arxiv.org/abs/2311.08094) | 本研究考察了VIT对基于骨骼的动作识别的有效性，并提出了一种三级架构SkelVit，该架构能够形成一组伪图像，并在每个表示上应用分类器，然后结合它们的结果来找到动作识别系统中的最佳表现。 |
| [^129] | [Modeling User Viewing Flow Using Large Language Models for Article Recommendation](https://arxiv.org/abs/2311.07619) | 本文提出了SINGLE方法，使用大型语言模型对用户浏览流进行建模，以更好地进行文章推荐。 |
| [^130] | [Can LLMs Follow Simple Rules?](https://arxiv.org/abs/2311.04235) | 提出了一个名为RuLES的程序框架，用于衡量LLMs在与用户交互时遵守规则的能力。 |
| [^131] | [VeCLIP: Improving CLIP Training via Visual-enriched Captions](https://arxiv.org/abs/2310.07699) | 本研究提出了一种通过将视觉概念融入标题中的方式来改进CLIP训练的方法，名为VeCLIP，该方法在大规模网络爬取数据集上展示了良好的性能。 |
| [^132] | [Quantify the Causes of Causal Emergence: Critical Conditions of Uncertainty and Asymmetry in Causal Structure](https://arxiv.org/abs/2212.01551) | 介绍了一种根据有效信息和转移概率矩阵的量化框架，用于评估因果出现的数值条件作为其发生的理论约束。 |
| [^133] | [Climbing Routes Clustering Using Energy-Efficient Accelerometers Attached to the Quickdraws](https://arxiv.org/abs/2211.02680) | 利用节能加速计对攀岩路线进行聚类，为攀岩健身房提供了改善服务和最大程度利用基础设施的新方法 |
| [^134] | [Interactive Question Answering Systems: Literature Review](https://arxiv.org/abs/2209.01621) | 交互式问答系统是问答和对话系统的结合，用户可以用自然语言提问并与系统动态交互，获得更精确的结果。 |
| [^135] | [Can phones, syllables, and words emerge as side-products of cross-situational audiovisual learning? -- A computational investigation](https://arxiv.org/abs/2109.14200) | 研究探讨了语言学习中，通过跨情境视听学习，音素、音节和单词能否作为副产品出现，并支持不同形式表征间的转换。 |
| [^136] | [The Typing Cure: Experiences with Large Language Model Chatbots for Mental Health Support.](http://arxiv.org/abs/2401.14362) | 本研究通过调查使用大型语言模型聊天机器人进行心理健康支持的人的经历，分析了用户如何为聊天机器人创建独特的支持角色，并介绍了在心理健康背景下将人工智能与治疗价值观相匹配的概念。研究提供了设计师处理伦理问题的建议。 |
| [^137] | [Q&A Prompts: Discovering Rich Visual Clues through Mining Question-Answer Prompts for VQA requiring Diverse World Knowledge.](http://arxiv.org/abs/2401.10712) | 本论文提出了一种叫做Q&A提示的方法，通过挖掘图像中的问题-回答对来发现丰富的视觉线索，以帮助AI模型更好地理解复杂视觉问题，提高跨模态推理能力。 |
| [^138] | [Diffusion Model with Perceptual Loss.](http://arxiv.org/abs/2401.00110) | 本研究介绍了一种使用感知损失的扩散模型，通过无分类器指导实现了生成更真实样本的目的。 |
| [^139] | [Approximate Multiagent Reinforcement Learning for On-Demand Urban Mobility Problem on a Large Map (extended version).](http://arxiv.org/abs/2311.01534) | 本文研究了大型城市环境下的自主多智能体出租车路径问题，提出了一个近似滚动为基础的两阶段算法来减少计算量。 |
| [^140] | [Is Scaling Learned Optimizers Worth It? Evaluating The Value of VeLO's 4000 TPU Months.](http://arxiv.org/abs/2310.18191) | VeLO是迄今为止规模最大的训练通用“基础”优化器的尝试，但我们的评估发现它需要问题特定的调优，并不一定优于竞争对手的解决方案质量和训练误差降低速度，这对于VeLO的通用性和培训投资的价值提出了质疑。 |
| [^141] | [GenTKG: Generative Forecasting on Temporal Knowledge Graph.](http://arxiv.org/abs/2310.07793) | 研究提出了一种名为GenTKG的生成模型，用于在时间知识图谱上进行预测。该模型通过结合基于时间逻辑规则的检索策略和轻量级的参数效率指导，克服了复杂的时间图数据结构和庞大的数据量所带来的挑战。 |
| [^142] | [A Fixed-Parameter Tractable Algorithm for Counting Markov Equivalence Classes with the same Skeleton.](http://arxiv.org/abs/2310.04218) | 本文提出了一个固定参数可处理算法，用于计数具有相同骨架的马尔可夫等价类。 |
| [^143] | [Spike Accumulation Forwarding for Effective Training of Spiking Neural Networks.](http://arxiv.org/abs/2310.02772) | 本研究提出了一种名为脉冲累积转发（SAF）的方法，可以有效训练脉冲神经网络（SNNs）。SAF不仅可以减少前向过程中的操作次数，与Spike Representation和OTTT保持一致，而且可以解决SNNs训练中的难题。 |
| [^144] | [PointSSC: A Cooperative Vehicle-Infrastructure Point Cloud Benchmark for Semantic Scene Completion.](http://arxiv.org/abs/2309.12708) | PointSSC是第一个为了语义场景补全而引入的车辆基础设施点云合作基准，具备长距离感知和最小遮挡。通过使用Segment Anything进行自动化注释，我们提出了一种基于激光雷达的模型，结合补全和分割的合作模块，来推动语义点云补全在真实世界导航中的发展。 |
| [^145] | [CoT-BERT: Enhancing Unsupervised Sentence Representation through Chain-of-Thought.](http://arxiv.org/abs/2309.11143) | CoT-BERT提出了一种通过思维链条增强无监督句子表示的方法，通过两个阶段的处理，引入思维链条的概念进行向量化，以提高模型性能。 |
| [^146] | [Tackling the Non-IID Issue in Heterogeneous Federated Learning by Gradient Harmonization.](http://arxiv.org/abs/2309.06692) | 本研究通过梯度协调方法解决了异构联邦学习中的非独立同分布问题，提出了FedGH，通过减轻本地漂移来增强性能。实验证明，在多个基准和非独立同分布场景下，FedGH始终能够显著提升联邦学习的性能。 |
| [^147] | [Offline Prompt Evaluation and Optimization with Inverse Reinforcement Learning.](http://arxiv.org/abs/2309.06553) | 这项工作介绍了一种基于离线逆向强化学习的提示评估与优化方法，通过利用离线数据集和逆向强化学习，预测提示性能、提高成本效益、生成易读的结果。 |
| [^148] | [A Benchmark Study on Calibration.](http://arxiv.org/abs/2308.11838) | 这项研究提出了一个模型校准的基准研究，利用神经架构搜索空间探索了模型校准属性。研究结果显示，模型校准可以在不同任务中泛化，并可以同时兼顾模型的准确性和校准性能。 |
| [^149] | [Learning Abstract Visual Reasoning via Task Decomposition: A Case Study in Raven Progressive Matrices.](http://arxiv.org/abs/2308.06528) | 通过任务分解学习抽象视觉推理，提出了一种基于变形器蓝图的深度学习架构，该架构预测单个对象及其排列的视觉特性，通过多维预测来选择答案。 |
| [^150] | [Accelerating Sampling and Aggregation Operations in GNN Frameworks with GPU Initiated Direct Storage Accesses.](http://arxiv.org/abs/2306.16384) | 本论文提出了一种通过利用GPU发起直接存储访问来加速GNN框架中的采样和聚合操作的方法，解决了在训练大规模图上时CPU无法充分利用GPU资源的问题。 |
| [^151] | [EquiformerV2: Improved Equivariant Transformer for Scaling to Higher-Degree Representations.](http://arxiv.org/abs/2306.12059) | 本文提出了EquiformerV2，通过使用新的卷积类型和架构改进，扩展了等变Transformer到更高的等变表示，在处理大型数据集时表现更好，能量和力的表现也得到了提高，计算效率也得到了提升。 |
| [^152] | [Tackling Heavy-Tailed Rewards in Reinforcement Learning with Function Approximation: Minimax Optimal and Instance-Dependent Regret Bounds.](http://arxiv.org/abs/2306.06836) | 本文解决了强化学习中当奖励呈“重尾”分布时的问题，提出了第一种处理这种情况的实例相关算法，并得到了极小最大化的遗憾界。 |
| [^153] | [Leveraging LLMs for KPIs Retrieval from Hybrid Long-Document: A Comprehensive Framework and Dataset.](http://arxiv.org/abs/2305.16344) | 本文提出了一个自动化财务信息提取的框架（AFIE），用于提取混合长文档中的关键业绩指标（KPI）。该框架利用LLMs增强了财务报告信息的理解和提取能力，并经过了广泛的实验验证，证明其在GPT-3.5和GPT-4上的有效性，相对于朴素方法，平均精度提高了53.94％和33.77％。 |
| [^154] | [Policy Gradient Methods in the Presence of Symmetries and State Abstractions.](http://arxiv.org/abs/2305.05666) | 本文研究了在连续控制环境中的抽象，提出了一种策略梯度定理，允许利用环境的近似对称性进行策略优化，并提出了一系列演员-评论家算法进行策略和MDP同态映射的学习，最后展示了算法在连续对称性环境和视觉控制任务中的有效性。 |
| [^155] | [Towards Achieving Near-optimal Utility for Privacy-Preserving Federated Learning via Data Generation and Parameter Distortion.](http://arxiv.org/abs/2305.04288) | 本论文提出了一种用数据生成和参数畸变实现隐私保护联邦学习接近最优效用的上限方法，其中通过降低方差和模型参数差异来衡量效用损失。 |
| [^156] | [Hierarchical Data-efficient Representation Learning for Tertiary Structure-based RNA Design.](http://arxiv.org/abs/2301.10774) | 本研究提出了一个基于层次数据有效表示学习的RNA设计流程，通过构建大型数据集并设计全面的结构建模方法，实现了更高效的RNA序列设计。 |

# 详细

[^1]: iScore: 用于解释语言模型如何自动评分摘要的可视化分析

    iScore: Visual Analytics for Interpreting How Language Models Automatically Score Summaries

    [https://arxiv.org/abs/2403.04760](https://arxiv.org/abs/2403.04760)

    设计了iScore工具，通过用户中心设计过程解决了大型语言模型在自动评分摘要中的透明度和信任问题

    

    近年来，大型语言模型（LLMs）的普及急剧增长，激发了学习工程师将它们纳入自适应教育工具中，用于自动评分摘要写作。在将它们部署到关键学习环境之前，了解和评估LLMs至关重要，然而它们数量庞大的参数和日益增加的规模阻碍了透明度，当它们表现不佳时还会影响信任。通过与多位构建和部署摘要评分LLMs的学习工程师展开协作的用户中心设计过程，我们界定了解释其模型的基本设计挑战和目标，包括整合大量文本输入、跟踪得分来源以及扩展LLM可解释性方法。为了解决他们的关切，我们开发了iScore，一款互动式可视化分析工具，供学习工程师同时上传、评分和比较多个摘要。与此同时紧密集成的视图

    arXiv:2403.04760v1 Announce Type: cross  Abstract: The recent explosion in popularity of large language models (LLMs) has inspired learning engineers to incorporate them into adaptive educational tools that automatically score summary writing. Understanding and evaluating LLMs is vital before deploying them in critical learning environments, yet their unprecedented size and expanding number of parameters inhibits transparency and impedes trust when they underperform. Through a collaborative user-centered design process with several learning engineers building and deploying summary scoring LLMs, we characterized fundamental design challenges and goals around interpreting their models, including aggregating large text inputs, tracking score provenance, and scaling LLM interpretability methods. To address their concerns, we developed iScore, an interactive visual analytics tool for learning engineers to upload, score, and compare multiple summaries simultaneously. Tightly integrated views
    
[^2]: 通过比较填空提示解释语言模型的KnowledgeVIS

    KnowledgeVIS: Interpreting Language Models by Comparing Fill-in-the-Blank Prompts

    [https://arxiv.org/abs/2403.04758](https://arxiv.org/abs/2403.04758)

    KnowledgeVIS是一个人机协作的可视分析系统，可以通过比较填空提示之间的预测结果来揭示语言模型学习到的联系，帮助用户理解语言模型的工作方式及原因。

    

    近年来，大型语言模型的流行增长导致它们在总结、预测和生成文本方面的使用增加，因此帮助研究人员和工程师理解其工作方式及原因变得至关重要。我们提出了KnowledgeVis，这是一个人机协作的可视分析系统，用于使用填空句作为提示来解释语言模型。通过比较句子之间的预测结果，KnowledgeVis展示了在训练过程中语言模型学习到的联系，这直观地将语言模型学到的内容与自然语言下游任务联系起来，帮助用户创建和测试多个提示变体，使用新颖的语义聚类技术分析预测的单词，并使用互动可视化发现见解。总的来说，这些可视化帮助用户确定单个预测的可能性和独特性，比较不同提示之间的一组预测，并总结模式和联系。

    arXiv:2403.04758v1 Announce Type: cross  Abstract: Recent growth in the popularity of large language models has led to their increased usage for summarizing, predicting, and generating text, making it vital to help researchers and engineers understand how and why they work. We present KnowledgeVis, a human-in-the-loop visual analytics system for interpreting language models using fill-in-the-blank sentences as prompts. By comparing predictions between sentences, KnowledgeVis reveals learned associations that intuitively connect what language models learn during training to natural language tasks downstream, helping users create and test multiple prompt variations, analyze predicted words using a novel semantic clustering technique, and discover insights using interactive visualizations. Collectively, these visualizations help users identify the likelihood and uniqueness of individual predictions, compare sets of predictions between prompts, and summarize patterns and relationships betw
    
[^3]: GNN-VPA: 一种用于图神经网络的方差保持聚合策略

    GNN-VPA: A Variance-Preserving Aggregation Strategy for Graph Neural Networks

    [https://arxiv.org/abs/2403.04747](https://arxiv.org/abs/2403.04747)

    通过提出一种保持方差的聚合函数（VPA），该函数在维持图神经网络（GNNs）的表达能力的基础上，提高了前向和后向动力学，进而导致了增强的预测性能和改善的学习动态。

    

    图神经网络（GNNs），特别是消息传递神经网络，在物理学、药物发现和分子建模等各个领域表现出色。GNNs的表达能力，特别是在区分非同构图的能力，关键取决于用于消息聚合和图级读出的函数。通过应用信号传播理论，我们提出了一种保持方差的聚合函数（VPA），该函数保持了表达能力，同时提高了前向和后向动力学。实验证明，VPA导致了流行的GNN架构的预测性能提高，同时改善了学习动态。我们的结果可能为无归一化或自归一化的GNNs铺平道路。

    arXiv:2403.04747v1 Announce Type: cross  Abstract: Graph neural networks (GNNs), and especially message-passing neural networks, excel in various domains such as physics, drug discovery, and molecular modeling. The expressivity of GNNs with respect to their ability to discriminate non-isomorphic graphs critically depends on the functions employed for message aggregation and graph-level readout. By applying signal propagation theory, we propose a variance-preserving aggregation function (VPA) that maintains expressivity, but yields improved forward and backward dynamics. Experiments demonstrate that VPA leads to increased predictive performance for popular GNN architectures as well as improved learning dynamics. Our results could pave the way towards normalizer-free or self-normalizing GNNs.
    
[^4]: 在幻境中的大型语言模型：通过模拟试错学习工具

    LLMs in the Imaginarium: Tool Learning through Simulated Trial and Error

    [https://arxiv.org/abs/2403.04746](https://arxiv.org/abs/2403.04746)

    提出了一种受生物启发的方法，即模拟试错（STE），为工具增强型LLMs编排了三个关键机制以实现成功的工具使用行为

    

    工具对于大型语言模型（LLMs）获取最新信息并在外部环境中采取重要行动至关重要。现有关于工具增强型LLMs的工作主要集中在工具的广泛覆盖范围和灵活性上。然而，一个被人意外忽视的关键方面是LLM在经过训练后如何准确使用工具。我们发现，包括GPT-4和专门为工具使用进行微调的开源LLMs在正确率方面仅达到30%到60%的范围，远不足以在实践中可靠使用。我们提出了一种受生物启发的方法，即模拟试错（STE），为工具增强型LLMs编排了三个关键机制以实现成功的工具使用行为：试错、想象和记忆。具体而言，STE利用LLM的“想象力”来模拟使用工具的可能场景，

    arXiv:2403.04746v1 Announce Type: cross  Abstract: Tools are essential for large language models (LLMs) to acquire up-to-date information and take consequential actions in external environments. Existing work on tool-augmented LLMs primarily focuses on the broad coverage of tools and the flexibility of adding new tools. However, a critical aspect that has surprisingly been understudied is simply how accurately an LLM uses tools for which it has been trained. We find that existing LLMs, including GPT-4 and open-source LLMs specifically fine-tuned for tool use, only reach a correctness rate in the range of 30% to 60%, far from reliable use in practice. We propose a biologically inspired method for tool-augmented LLMs, simulated trial and error (STE), that orchestrates three key mechanisms for successful tool use behaviors in the biological system: trial and error, imagination, and memory. Specifically, STE leverages an LLM's 'imagination' to simulate plausible scenarios for using a tool,
    
[^5]: 我们距离智能视觉演绎推理还有多远？

    How Far Are We from Intelligent Visual Deductive Reasoning?

    [https://arxiv.org/abs/2403.04732](https://arxiv.org/abs/2403.04732)

    目前的视觉语言模型在文本推理方面表现出色，但在视觉演绎推理方面仍存在较大差距和盲点。

    

    最近，诸如GPT-4V之类的视觉语言模型（VLM）在各种视觉语言任务上取得了巨大进展。我们深入探讨了基于视觉的演绎推理，这是一个更复杂但不太被探索的领域，并发现了当前领先的VLM中以前未暴露的盲点。具体来说，我们利用瑞文渐进矩阵（RPM）来评估VLM在仅依靠视觉线索进行多跳关系和演绎推理的能力。我们对几种流行的VLM进行了全面评估，采用了标准策略，如上下文学习、自我一致性和思维链（CoT），在三个不同的数据集上进行了评估，包括Mensa智商测试、智商测试和RAVEN。结果表明，尽管LLM在基于文本的推理方面具有令人印象深刻的能力，但我们在视觉演绎推理方面仍有很大的差距。

    arXiv:2403.04732v1 Announce Type: new  Abstract: Vision-Language Models (VLMs) such as GPT-4V have recently demonstrated incredible strides on diverse vision language tasks. We dig into vision-based deductive reasoning, a more sophisticated but less explored realm, and find previously unexposed blindspots in the current SOTA VLMs. Specifically, we leverage Raven's Progressive Matrices (RPMs), to assess VLMs' abilities to perform multi-hop relational and deductive reasoning relying solely on visual clues. We perform comprehensive evaluations of several popular VLMs employing standard strategies such as in-context learning, self-consistency, and Chain-of-thoughts (CoT) on three diverse datasets, including the Mensa IQ test, IntelligenceTest, and RAVEN. The results reveal that despite the impressive capabilities of LLMs in text-based reasoning, we are still far from achieving comparable proficiency in visual deductive reasoning. We found that certain standard strategies that are effective
    
[^6]: 通用7B语言模型已经具备强大的数学能力

    Common 7B Language Models Already Possess Strong Math Capabilities

    [https://arxiv.org/abs/2403.04706](https://arxiv.org/abs/2403.04706)

    通用7B语言模型LLaMA-2展现出强大数学能力，准确率分别达到97.7%和72.0%，扩大SFT数据可以提高生成正确答案的可靠性

    

    先前人们相信通用语言模型只有在非常大的规模上或需要大量与数学相关的预训练才能展现出数学能力。本文表明，具有通用预训练的LLaMA-2 7B模型已经表现出强大的数学能力，其在GSM8K和MATH基准测试上选择256个随机生成的最佳响应时，准确率分别为97.7%和72.0%。目前基础模型的主要问题在于难以一致地引出其固有的数学能力。值得注意的是，对于第一个答案的准确率分别下降到了49.5%和7.9%。我们发现，简单地扩大SFT数据可以显著提高生成正确答案的可靠性。然而，广泛扩展的潜力受到公开可用数学问题的稀缺性的限制。为了克服这一限制

    arXiv:2403.04706v1 Announce Type: cross  Abstract: Mathematical capabilities were previously believed to emerge in common language models only at a very large scale or require extensive math-related pre-training. This paper shows that the LLaMA-2 7B model with common pre-training already exhibits strong mathematical abilities, as evidenced by its impressive accuracy of 97.7% and 72.0% on the GSM8K and MATH benchmarks, respectively, when selecting the best response from 256 random generations. The primary issue with the current base model is the difficulty in consistently eliciting its inherent mathematical capabilities. Notably, the accuracy for the first answer drops to 49.5% and 7.9% on the GSM8K and MATH benchmarks, respectively. We find that simply scaling up the SFT data can significantly enhance the reliability of generating correct answers. However, the potential for extensive scaling is constrained by the scarcity of publicly available math questions. To overcome this limitatio
    
[^7]: ObjectCompose: 评估基于视觉的模型在物体与背景组合变化上的韧性

    ObjectCompose: Evaluating Resilience of Vision-Based Models on Object-to-Background Compositional Changes

    [https://arxiv.org/abs/2403.04701](https://arxiv.org/abs/2403.04701)

    评估基于视觉的模型对于物体与背景之间多样化变化的鲁棒性，提出一种可以引入不同对象方面变化的方法

    

    由于最近基于视觉的模型进行了大规模多模态训练并具有泛化能力，了解它们的鲁棒性程度对于它们在现实世界中的部署至关重要。在本研究中，我们评估了当前基于视觉的模型针对不同的物体与背景上下文变化的韧性。大多数鲁棒性评估方法引入了合成数据集来诱导物体特征（视点、尺度、颜色）的变化，或者利用图像转换技术（对抗性变化、常见破坏）在真实图像上模拟分布的变化。最近的研究探索了利用大语言模型和扩散模型来生成背景的变化。但是，这些方法要么在提供对要进行的更改的控制方面不足，要么扭曲了物体的语义，使其不适用于任务。与之相反，我们的方法可以引入各种对象

    arXiv:2403.04701v1 Announce Type: cross  Abstract: Given the large-scale multi-modal training of recent vision-based models and their generalization capabilities, understanding the extent of their robustness is critical for their real-world deployment. In this work, we evaluate the resilience of current vision-based models against diverse object-to-background context variations. The majority of robustness evaluation methods have introduced synthetic datasets to induce changes to object characteristics (viewpoints, scale, color) or utilized image transformation techniques (adversarial changes, common corruptions) on real images to simulate shifts in distributions. Recent works have explored leveraging large language models and diffusion models to generate changes in the background. However, these methods either lack in offering control over the changes to be made or distort the object semantics, making them unsuitable for the task. Our method, on the other hand, can induce diverse objec
    
[^8]: AUFormer: 视觉Transformer是参数高效的面部动作单位检测器

    AUFormer: Vision Transformers are Parameter-Efficient Facial Action Unit Detectors

    [https://arxiv.org/abs/2403.04697](https://arxiv.org/abs/2403.04697)

    AUFormer提出了一种参数高效的面部动作单位检测方法，引入了新颖的知识混合专家协作机制，解决了传统方法在稀缺数据集或过度依赖额外数据导致的过拟合问题。

    

    面部动作单位（AU）在情感计算领域是一个重要概念，AU检测一直是一个热门的研究课题。现有方法由于在稀缺的AU注释数据集上利用大量可学习参数或过度依赖大量额外相关数据而存在过拟合问题。参数高效迁移学习（PETL）提供了一个有希望解决这些挑战的范式，然而其现有方法缺乏针对AU特征的设计。因此，我们创新性地将PETL范式应用于AU检测，引入AUFormer并提出了一种新颖的知识混合专家（MoKE）协作机制。一个特定于某个AU并具有最少可学习参数的MoKE首先集成个性化的多尺度和相关知识。然后MoKE与专家组中的其他MoKE合作，获取聚合信息并将其注入到...

    arXiv:2403.04697v1 Announce Type: cross  Abstract: Facial Action Units (AU) is a vital concept in the realm of affective computing, and AU detection has always been a hot research topic. Existing methods suffer from overfitting issues due to the utilization of a large number of learnable parameters on scarce AU-annotated datasets or heavy reliance on substantial additional relevant data. Parameter-Efficient Transfer Learning (PETL) provides a promising paradigm to address these challenges, whereas its existing methods lack design for AU characteristics. Therefore, we innovatively investigate PETL paradigm to AU detection, introducing AUFormer and proposing a novel Mixture-of-Knowledge Expert (MoKE) collaboration mechanism. An individual MoKE specific to a certain AU with minimal learnable parameters first integrates personalized multi-scale and correlation knowledge. Then the MoKE collaborates with other MoKEs in the expert group to obtain aggregated information and inject it into the 
    
[^9]: 通过标记级别的不确定性量化检验大型语言模型的输出

    Fact-Checking the Output of Large Language Models via Token-Level Uncertainty Quantification

    [https://arxiv.org/abs/2403.04696](https://arxiv.org/abs/2403.04696)

    提出了一种基于标记级别不确定性量化的新型事实核查和幻觉检测流程，该方法能够检测大型语言模型输出中的不可靠预测。

    

    大型语言模型(LLMs)以产生错误的声明而臭名昭著。这种幻觉可能很危险，因为在生成的文本中偶尔出现的事实不准确可能会被整体上是事实的文本掩盖，这使得用户极其难以发现。利用LLMs的当前服务通常不提供检测不可靠生成的方式。在这里，我们旨在弥补这一空白。具体而言，我们提出了一种基于标记级别的不确定性量化的新型事实核查和幻觉检测流程。不确定性分数利用了神经网络或其层输出中包含的信息来检测不可靠的预测，并我们展示它们可以用于核查LLM输出中的各种声明。此外，我们提出了一种新型的标记级别不确定性量化方法，消除了对事实提出怀疑的影响。

    arXiv:2403.04696v1 Announce Type: cross  Abstract: Large language models (LLMs) are notorious for hallucinating, i.e., producing erroneous claims in their output. Such hallucinations can be dangerous, as occasional factual inaccuracies in the generated text might be obscured by the rest of the output being generally factual, making it extremely hard for the users to spot them. Current services that leverage LLMs usually do not provide any means for detecting unreliable generations. Here, we aim to bridge this gap. In particular, we propose a novel fact-checking and hallucination detection pipeline based on token-level uncertainty quantification. Uncertainty scores leverage information encapsulated in the output of a neural network or its layers to detect unreliable predictions, and we show that they can be used to fact-check the atomic claims in the LLM output. Moreover, we present a novel token-level uncertainty quantification method that removes the impact of uncertainty about what c
    
[^10]: 更快的邻域注意力: 在线程块级别减少自注意力的O(n^2)成本

    Faster Neighborhood Attention: Reducing the O(n^2) Cost of Self Attention at the Threadblock Level

    [https://arxiv.org/abs/2403.04690](https://arxiv.org/abs/2403.04690)

    该研究提出了一种更快的邻域注意力机制，通过将注意力限制在最近的邻居之间来降低自注意力的计算复杂度，实现了显著的性能提升。

    

    邻域注意力通过限制每个标记的注意力范围为其最近的邻居来降低自注意力的成本。该限制由窗口大小和扩张因子参数化，介于线性投影和自注意力之间绘制了可能的注意力模式谱。邻域注意力，以及更一般地滑动窗口注意力模式，在基础设施方面长期受到限制，特别是在更高秩的空间（2-D和3-D），促使开发定制内核的发展，这些内核在功能或性能方面受限，如果不是两者都有。在这项工作中，我们首先展示邻域注意力可以表示为批量化的GEMM问题，类似于标准注意力，并为1-D和2-D邻域注意力实现它。与现有的简单内核相比，这些内核平均提供了分别是1-D和2-D邻域注意力的全精度延迟改进分别为895%和272%。

    arXiv:2403.04690v1 Announce Type: cross  Abstract: Neighborhood attention reduces the cost of self attention by restricting each token's attention span to its nearest neighbors. This restriction, parameterized by a window size and dilation factor, draws a spectrum of possible attention patterns between linear projection and self attention. Neighborhood attention, and more generally sliding window attention patterns, have long been bounded by infrastructure, particularly in higher-rank spaces (2-D and 3-D), calling for the development of custom kernels, which have been limited in either functionality, or performance, if not both. In this work, we first show that neighborhood attention can be represented as a batched GEMM problem, similar to standard attention, and implement it for 1-D and 2-D neighborhood attention. These kernels on average provide 895% and 272% improvement in full precision latency compared to existing naive kernels for 1-D and 2-D neighborhood attention respectively. 
    
[^11]: 创造性人工智能的社会影响：对ChatGPT的分析

    The Social Impact of Generative AI: An Analysis on ChatGPT

    [https://arxiv.org/abs/2403.04667](https://arxiv.org/abs/2403.04667)

    本文分析了创造性人工智能工具在社会领域可能带来的影响，以ChatGPT为例，评估了正面和负面效应及新兴趋势。

    

    最近几个月，人工智能（AI）的社会影响引起了广泛关注，这主要是由创造性AI模型的出现，特别是ChatGPT所推动的。这些模型的快速发展引发了关于它们的益处、局限性和相关风险的热烈讨论。生成模型在多个领域，如医疗保健、金融和教育等，具有巨大潜力，呈现出多样化的实际应用。然而，对潜在不利影响的担忧引发了不同的观点，从隐私风险到加剧社会不平等。本文采用一种方法来深入探讨生成AI工具的社会影响，主要关注ChatGPT的案例。它评估了对几个社会领域的潜在影响，并说明了对正面和负面影响、新兴趋势的全面文献综述的研究结果。

    arXiv:2403.04667v1 Announce Type: new  Abstract: In recent months, the social impact of Artificial Intelligence (AI) has gained considerable public interest, driven by the emergence of Generative AI models, ChatGPT in particular. The rapid development of these models has sparked heated discussions regarding their benefits, limitations, and associated risks. Generative models hold immense promise across multiple domains, such as healthcare, finance, and education, to cite a few, presenting diverse practical applications. Nevertheless, concerns about potential adverse effects have elicited divergent perspectives, ranging from privacy risks to escalating social inequality. This paper adopts a methodology to delve into the societal implications of Generative AI tools, focusing primarily on the case of ChatGPT. It evaluates the potential impact on several social sectors and illustrates the findings of a comprehensive literature review of both positive and negative effects, emerging trends, 
    
[^12]: Yi: 由 01.AI 推出的开放基础模型

    Yi: Open Foundation Models by 01.AI

    [https://arxiv.org/abs/2403.04652](https://arxiv.org/abs/2403.04652)

    Yi模型系列基于强大的多维能力，通过基于6B和34B预训练模型的扩展，包括聊天模型、长上下文模型、深度放大模型和视觉语言模型，取得了优异的性能。

    

    我们介绍了Yi模型系列，这是一系列具有强大多维能力的语言和多模态模型。Yi模型系列基于6B和34B的预训练语言模型，然后我们将它们扩展为聊天模型、200K长上下文模型、深度放大模型和视觉语言模型。我们的基础模型在诸如MMLU之类的各种基准测试中表现出色，而我们微调过的聊天模型在AlpacaEval和Chatbot Arena等主要评估平台上具有较高的人类偏好率。通过依赖于我们的可扩展超级计算基础设施和经典的Transformer架构，我们认为Yi模型的性能主要归因于其数据质量，这是由我们的数据工程工作所带来的。对于预训练，我们使用级联的数据去重和质量过滤流水线构建了3100亿个英文和中文语料库的标记。对于微调，我们对小规模模型进行了改进

    arXiv:2403.04652v1 Announce Type: cross  Abstract: We introduce the Yi model family, a series of language and multimodal models that demonstrate strong multi-dimensional capabilities. The Yi model family is based on 6B and 34B pretrained language models, then we extend them to chat models, 200K long context models, depth-upscaled models, and vision-language models. Our base models achieve strong performance on a wide range of benchmarks like MMLU, and our finetuned chat models deliver strong human preference rate on major evaluation platforms like AlpacaEval and Chatbot Arena. Building upon our scalable super-computing infrastructure and the classical transformer architecture, we attribute the performance of Yi models primarily to its data quality resulting from our data-engineering efforts. For pretraining, we construct 3.1 trillion tokens of English and Chinese corpora using a cascaded data deduplication and quality filtering pipeline. For finetuning, we polish a small scale (less th
    
[^13]: 基于上下文的多模态融合

    Context-Based Multimodal Fusion

    [https://arxiv.org/abs/2403.04650](https://arxiv.org/abs/2403.04650)

    提出一种基于上下文的多模态融合模型，结合了模态融合和数据分布对齐，通过特定上下文向量表示每个模态，并将其与每个模态的嵌入进行融合，

    

    融合模型广泛应用于解决多模态任务，但在不同模态之间数据分布对齐方面存在明显局限性。针对这一挑战，我们提出了一种创新模型称为基于上下文的多模态融合（CBMF），结合了模态融合和数据分布对齐，通过特定上下文向量表示每个模态，并将其与每个模态的嵌入进行融合。

    arXiv:2403.04650v1 Announce Type: cross  Abstract: The fusion models, which effectively combine information from different sources, are widely used in solving multimodal tasks. However, they have significant limitations related to aligning data distributions across different modalities. This challenge can lead to inconsistencies and difficulties in learning robust representations. Alignment models, while specifically addressing this issue, often require training "from scratch" with large datasets to achieve optimal results, which can be costly in terms of resources and time. To overcome these limitations, we propose an innovative model called Context-Based Multimodal Fusion (CBMF), which combines both modality fusion and data distribution alignment. In CBMF, each modality is represented by a specific context vector, fused with the embedding of each modality. This enables the use of large pre-trained models that can be frozen, reducing the computational and training data requirements. A
    
[^14]: Pix2Gif：基于运动引导扩散的GIF生成模型

    Pix2Gif: Motion-Guided Diffusion for GIF Generation

    [https://arxiv.org/abs/2403.04634](https://arxiv.org/abs/2403.04634)

    提出了Pix2Gif，一种基于运动引导的扩散模型，通过图像转换问题来实现图像到GIF的生成，引入了新的运动引导变形模块和感知损失以确保模型遵循运动引导并保持内容一致性和连贯性。

    

    我们提出了Pix2Gif，这是一个基于运动引导的扩散模型，用于图像到GIF（视频）的生成。我们通过将任务构建为由文本和运动大小提示指导的图像转换问题来不同地解决这一问题，如teaser fig所示。为了确保模型遵循运动引导，我们提出了一个新的运动引导变形模块，以在两种类型的提示条件下空间变换源图像的特征。此外，我们引入了一个感知损失，以确保转换的特征图保持在与目标图像相同的空间中，确保内容一致性和连贯性。为了为模型训练做准备，我们通过从TGIF视频字幕数据集中提取连贯的图像帧来精心筛选数据，该数据集提供了有关主题的时间变化丰富信息。在预训练之后，我们以零射样的方式将我们的模型应用于多个视频数据集。

    arXiv:2403.04634v1 Announce Type: cross  Abstract: We present Pix2Gif, a motion-guided diffusion model for image-to-GIF (video) generation. We tackle this problem differently by formulating the task as an image translation problem steered by text and motion magnitude prompts, as shown in teaser fig. To ensure that the model adheres to motion guidance, we propose a new motion-guided warping module to spatially transform the features of the source image conditioned on the two types of prompts. Furthermore, we introduce a perceptual loss to ensure the transformed feature map remains within the same space as the target image, ensuring content consistency and coherence. In preparation for the model training, we meticulously curated data by extracting coherent image frames from the TGIF video-caption dataset, which provides rich information about the temporal changes of subjects. After pretraining, we apply our model in a zero-shot manner to a number of video datasets. Extensive qualitative 
    
[^15]: 用Shapley值解释贝叶斯优化促进人工智能与人类协作

    Explaining Bayesian Optimization by Shapley Values Facilitates Human-AI Collaboration

    [https://arxiv.org/abs/2403.04629](https://arxiv.org/abs/2403.04629)

    提出了ShapleyBO框架，用Shapley值解释贝叶斯优化提议，量化每个参数对于优化过程的贡献，并能够区分不同类型的不确定性探索贡献。

    

    贝叶斯优化（BO）与高斯过程（GP）已成为解决黑匣子优化问题的不可或缺的算法。然而，BO本身也常常被认为是一个黑匣子，缺乏提供为何提议评估某些参数的理由的方法。我们通过提出ShapleyBO来解决这个问题，这是一个用博弈论Shapley值解释BO提议的框架。它量化了每个参数对BO的收获函数的贡献。利用Shapley值的线性性，我们能够进一步确定每个参数对于像置信边界这样的加法收获函数推动BO的探索和开发的强度。我们还展示了ShapleyBO能够解决探索对于勘探aleatoric和认识epistemic不确定性的贡献。

    arXiv:2403.04629v1 Announce Type: cross  Abstract: Bayesian optimization (BO) with Gaussian processes (GP) has become an indispensable algorithm for black box optimization problems. Not without a dash of irony, BO is often considered a black box itself, lacking ways to provide reasons as to why certain parameters are proposed to be evaluated. This is particularly relevant in human-in-the-loop applications of BO, such as in robotics. We address this issue by proposing ShapleyBO, a framework for interpreting BO's proposals by game-theoretic Shapley values.They quantify each parameter's contribution to BO's acquisition function. Exploiting the linearity of Shapley values, we are further able to identify how strongly each parameter drives BO's exploration and exploitation for additive acquisition functions like the confidence bound. We also show that ShapleyBO can disentangle the contributions to exploration into those that explore aleatoric and epistemic uncertainty. Moreover, our method 
    
[^16]: 一个具有对抗去噪扩散模型的领域转换框架，用于生成超声心动图图像的合成数据集

    A Domain Translation Framework with an Adversarial Denoising Diffusion Model to Generate Synthetic Datasets of Echocardiography Images

    [https://arxiv.org/abs/2403.04612](https://arxiv.org/abs/2403.04612)

    提出一个以对抗去噪扩散模型为基础的框架，用于合成超声心动图像并进行领域转换，具有高质量和多样性的图像生成能力。

    

    目前，医学图像领域的翻译操作受到研究人员和临床医生的高需求。这项任务除了其他能力外，还允许生成具有足够高图像质量的新医学图像，使其具有临床相关性。这种提出的框架依赖于对抗去噪扩散模型（DDM）来合成超声心动图像并执行领域转换。与生成对抗网络（GAN）相反，DDM能够生成具有很大多样性的高质量图像样本。如果将DDM与GAN结合，这种生成新数据的能力将在更快的采样时间内完成。在这项工作中，我们训练了一个结合了GAN的对抗DDM，学习反向去噪过程，依赖于引导图像，确保相

    arXiv:2403.04612v1 Announce Type: cross  Abstract: Currently, medical image domain translation operations show a high demand from researchers and clinicians. Amongst other capabilities, this task allows the generation of new medical images with sufficiently high image quality, making them clinically relevant. Deep Learning (DL) architectures, most specifically deep generative models, are widely used to generate and translate images from one domain to another. The proposed framework relies on an adversarial Denoising Diffusion Model (DDM) to synthesize echocardiography images and perform domain translation. Contrary to Generative Adversarial Networks (GANs), DDMs are able to generate high quality image samples with a large diversity. If a DDM is combined with a GAN, this ability to generate new data is completed at an even faster sampling time. In this work we trained an adversarial DDM combined with a GAN to learn the reverse denoising process, relying on a guide image, making sure rel
    
[^17]: 通过全球工作空间实现零射击跨模态转移的强化学习策略

    Zero-shot cross-modal transfer of Reinforcement Learning policies through a Global Workspace

    [https://arxiv.org/abs/2403.04588](https://arxiv.org/abs/2403.04588)

    本研究探索了利用全球工作空间来构建多模态表示，以实现零射击跨模态转移的强化学习策略。

    

    人类通过多种感官感知世界，使他们能够综合地表达周围环境，并且能够在不同领域之间泛化信息。本文探讨了通过“全局工作空间”的认知科学概念来构建强大而灵活的多模态表示，以及在机器人和强化学习领域中将其应用于跨模态转移的有效性。

    arXiv:2403.04588v1 Announce Type: new  Abstract: Humans perceive the world through multiple senses, enabling them to create a comprehensive representation of their surroundings and to generalize information across domains. For instance, when a textual description of a scene is given, humans can mentally visualize it. In fields like robotics and Reinforcement Learning (RL), agents can also access information about the environment through multiple sensors; yet redundancy and complementarity between sensors is difficult to exploit as a source of robustness (e.g. against sensor failure) or generalization (e.g. transfer across domains). Prior research demonstrated that a robust and flexible multimodal representation can be efficiently constructed based on the cognitive science notion of a 'Global Workspace': a unique representation trained to combine information across modalities, and to broadcast its signal back to each modality. Here, we explore whether such a brain-inspired multimodal re
    
[^18]: Wiki-TabNER:通过命名实体识别推进表格解释

    Wiki-TabNER:Advancing Table Interpretation Through Named Entity Recognition

    [https://arxiv.org/abs/2403.04577](https://arxiv.org/abs/2403.04577)

    本文提出了一个新的挑战性数据集，并介绍了一个旨在解决实体链接任务的新问题：单元格内的命名实体识别，并提出了一个提示框架用于评估大型语言模型在这一新任务上的效果。

    

    arXiv:2403.04577v1 发布类型：新摘要：网络表格包含大量宝贵知识，激发了旨在解决表格解释（TI）任务的表格语言模型。本文分析了用于评估TI任务的广泛使用的基准数据集，特别关注实体链接任务。我们的分析显示，该数据集过于简化，可能降低其用于全面评估的有效性，并未准确代表表格在现实世界中的外观。为克服这一缺点，我们构建并注释了一个更具挑战性的新数据集。除了介绍新数据集外，我们还介绍了一个旨在解决实体链接任务的新问题：单元格内的命名实体识别。最后，我们提出了一个提示框架，用于评估新开发的大型语言模型（LLMs）在这一新的TI任务上。我们在各种设置下对提示LLMs进行实验证明，其中我们同时使用了随机

    arXiv:2403.04577v1 Announce Type: new  Abstract: Web tables contain a large amount of valuable knowledge and have inspired tabular language models aimed at tackling table interpretation (TI) tasks. In this paper, we analyse a widely used benchmark dataset for evaluation of TI tasks, particularly focusing on the entity linking task. Our analysis reveals that this dataset is overly simplified, potentially reducing its effectiveness for thorough evaluation and failing to accurately represent tables as they appear in the real-world. To overcome this drawback, we construct and annotate a new more challenging dataset. In addition to introducing the new dataset, we also introduce a novel problem aimed at addressing the entity linking task: named entity recognition within cells. Finally, we propose a prompting framework for evaluating the newly developed large language models (LLMs) on this novel TI task. We conduct experiments on prompting LLMs under various settings, where we use both random
    
[^19]: 机器学习和信息理论概念对AI数学家的影响

    Machine learning and information theory concepts towards an AI Mathematician

    [https://arxiv.org/abs/2403.04571](https://arxiv.org/abs/2403.04571)

    当前的深度学习在系统1能力上成功，但在系统2能力上仍然缺少重要内容，本文以信息理论的观点，探讨有趣的数学陈述构成，并致力于发现新颖猜想，以此指导未来打造AI数学家。

    

    arXiv:2403.04571v1 发表类型：新的 摘要：目前人工智能的最新技术令人印象深刻，特别是在语言掌握方面，但在数学推理方面却不那么令人满意。究竟缺少了什么？我们是否可以从数学家的大脑如何处理问题中，学到有关这一差距的一些有用知识？这篇文章构建在一个观念之上，即目前的深度学习主要成功于系统1能力 -- 这相对应于我们的直觉和习惯性行为 -- 但仍然缺少有关系统2能力的一些重要内容 -- 这包括推理能力和稳健的不确定性估计。它采取了信息理论的立场来探讨什么构成了一个有趣的数学陈述，这可以指导未来打造AI数学家的工作。重点不在于证明一个给定定理，而在于发现新的有趣猜想。中心假设是，一个理想的定理体系更好地总结了这个

    arXiv:2403.04571v1 Announce Type: new  Abstract: The current state-of-the-art in artificial intelligence is impressive, especially in terms of mastery of language, but not so much in terms of mathematical reasoning. What could be missing? Can we learn something useful about that gap from how the brains of mathematicians go about their craft? This essay builds on the idea that current deep learning mostly succeeds at system 1 abilities -- which correspond to our intuition and habitual behaviors -- but still lacks something important regarding system 2 abilities -- which include reasoning and robust uncertainty estimation. It takes an information-theoretical posture to ask questions about what constitutes an interesting mathematical statement, which could guide future work in crafting an AI mathematician. The focus is not on proving a given theorem but on discovering new and interesting conjectures. The central hypothesis is that a desirable body of theorems better summarizes the set of 
    
[^20]: 减少自监督学习复杂性改善计算病理学中的弱监督分类性能

    Reducing self-supervised learning complexity improves weakly-supervised classification performance in computational pathology

    [https://arxiv.org/abs/2403.04558](https://arxiv.org/abs/2403.04558)

    本研究探讨了在计算病理学中减少对比自监督学习复杂性对分类性能的改善，通过利用消费级硬件。

    

    深度学习模型已成功应用于从常规可用的组织学数据中提取临床可操作见解。通常，这些模型需要临床医生进行的标注，这种标注稀缺且昂贵。自监督学习（SSL）方法的出现消除了这一障碍，允许对非标注数据进行大规模分析。然而，最近的SSL方法采用日益庞大的模型架构和更大的数据集，导致数据量迅速增加，硬件要求和整体成本增加，使得很少机构能够获得这些资源。因此，我们研究了对比自监督学习在计算病理学中的复杂性与分类性能之间的关系，利用消费级硬件。具体而言，我们分析了数据量、架构和算法的调整对下游分类任务的影响。

    arXiv:2403.04558v1 Announce Type: cross  Abstract: Deep Learning models have been successfully utilized to extract clinically actionable insights from routinely available histology data. Generally, these models require annotations performed by clinicians, which are scarce and costly to generate. The emergence of self-supervised learning (SSL) methods remove this barrier, allowing for large-scale analyses on non-annotated data. However, recent SSL approaches apply increasingly expansive model architectures and larger datasets, causing the rapid escalation of data volumes, hardware prerequisites, and overall expenses, limiting access to these resources to few institutions. Therefore, we investigated the complexity of contrastive SSL in computational pathology in relation to classification performance with the utilization of consumer-grade hardware. Specifically, we analyzed the effects of adaptations in data volume, architecture, and algorithms on downstream clas- sification tasks, empha
    
[^21]: CLIP去偏见：在多模态学习中平衡数据有多大用处？

    CLIP the Bias: How Useful is Balancing Data in Multimodal Learning?

    [https://arxiv.org/abs/2403.04547](https://arxiv.org/abs/2403.04547)

    数据平衡在对比语言-图像预训练（CLIP）中可以部分改善偏见问题，然而会对质量产生复杂影响。

    

    我们研究了数据平衡对于减轻对比语言-图像预训练（CLIP）中的偏见的有效性，确定了其优势和局限性。首先，我们重申了以前的结论，即CLIP模型可能会无意中吸收社会刻板印象。为了应对这一问题，我们提出了一种新的算法，称为多模态时刻匹配（M4），旨在减少多模态数据中的表示和关联偏见（即一阶和二阶统计）。我们使用M4进行了深入分析，考虑了模型、表示和数据大小等各种因素。我们的研究还探讨了CLIP学习和消除偏见的动态特性。特别是，我们发现微调可以有效地抵制表示偏见，但对关联偏见的影响逐渐减弱。此外，数据平衡对质量有着复杂的影响：它倾向于改善分类，但可能会损害检索。

    arXiv:2403.04547v1 Announce Type: cross  Abstract: We study the effectiveness of data-balancing for mitigating biases in contrastive language-image pretraining (CLIP), identifying areas of strength and limitation. First, we reaffirm prior conclusions that CLIP models can inadvertently absorb societal stereotypes. To counter this, we present a novel algorithm, called Multi-Modal Moment Matching (M4), designed to reduce both representation and association biases (i.e. in first- and second-order statistics) in multimodal data. We use M4 to conduct an in-depth analysis taking into account various factors, such as the model, representation, and data size. Our study also explores the dynamic nature of how CLIP learns and unlearns biases. In particular, we find that fine-tuning is effective in countering representation biases, though its impact diminishes for association biases. Also, data balancing has a mixed impact on quality: it tends to improve classification but can hurt retrieval. Inte
    
[^22]: 实现从自然语言规范到ASP程序的自动化组合

    Towards Automatic Composition of ASP Programs from Natural Language Specifications

    [https://arxiv.org/abs/2403.04541](https://arxiv.org/abs/2403.04541)

    该论文实现了从自然语言规范到ASP程序的自动化组合的第一步，提供了关于图相关问题规范的数据集和基于神经机器翻译的两步架构。

    

    本文迈出了实现自动化合成答案集编程（ASP）规范的第一步。具体而言，提供了以下贡献：(i)集中在与图相关的问题规范的数据集，旨在开发和评估ASP自动编码工具；(ii)一个两步架构，在NL2ASP工具中实现，用于从自然语言规范生成ASP程序。NL2ASP使用神经机器翻译将自然语言转换为受控自然语言（CNL）语句。随后，使用CNL2ASP工具将CNL语句转换为ASP代码。实验验证了该方法的可行性。

    arXiv:2403.04541v1 Announce Type: new  Abstract: This paper moves the first step towards automating the composition of Answer Set Programming (ASP) specifications. In particular, the following contributions are provided: (i) A dataset focused on graph-related problem specifications, designed to develop and assess tools for ASP automatic coding; (ii) A two-step architecture, implemented in the NL2ASP tool, for generating ASP programs from natural language specifications. NL2ASP uses neural machine translation to transform natural language into Controlled Natural Language (CNL) statements. Subsequently, CNL statements are converted into ASP code using the CNL2ASP tool. An experiment confirms the viability of the approach.
    
[^23]: 在联邦微调基础模型中提升数据质量

    Enhancing Data Quality in Federated Fine-Tuning of Foundation Models

    [https://arxiv.org/abs/2403.04529](https://arxiv.org/abs/2403.04529)

    提出了一个用于联邦微调基础模型的数据质量控制管道，可以提高全局性能。

    

    基础模型训练的当前情景中，存在着对公共领域数据的显著依赖，而根据最近的研究，这些数据已接近枯竭。为了进一步扩大规模，将多个专业化和高质量的私有领域数据源进行协作是至关重要的。然而，在不共享私有数据的情况下地方性训练模型所面临的数据质量控制问题是具有挑战性的。为了解决这一问题，我们提出了一个用于联邦微调基础模型的数据质量控制管道。该管道计算反映训练数据质量的分数，并确定一个全局阈值以实现统一标准，旨在提高全局性能。我们的实验表明，所提出的质量控制管道促进了模型训练的有效性和可靠性，从而带来更好的性能。

    arXiv:2403.04529v1 Announce Type: cross  Abstract: In the current landscape of foundation model training, there is a significant reliance on public domain data, which is nearing exhaustion according to recent research. To further scale up, it is crucial to incorporate collaboration among multiple specialized and high-quality private domain data sources. However, the challenge of training models locally without sharing private data presents numerous obstacles in data quality control. To tackle this issue, we propose a data quality control pipeline for federated fine-tuning of foundation models. This pipeline computes scores reflecting the quality of training data and determines a global threshold for a unified standard, aiming for improved global performance. Our experiments show that the proposed quality control pipeline facilitates the effectiveness and reliability of the model training, leading to better performance.
    
[^24]: 通过物理约束自动编码器进行拉曼光谱的高光谱解混

    Hyperspectral unmixing for Raman spectroscopy via physics-constrained autoencoders

    [https://arxiv.org/abs/2403.04526](https://arxiv.org/abs/2403.04526)

    通过物理约束自动编码器开发了高光谱解混算法，提供了在复杂混合情况下更好的准确性、鲁棒性和效率，展示了在复杂生物环境中的应用。

    

    拉曼光谱广泛应用于科学领域，以非破坏性、无标记的方式表征样品的化学组成。许多应用需要从混合分子物种的信号中解混，以识别出现的个体组分及其比例，然而传统的化学计量学方法常常难以处理实践中遇到的复杂混合情况。在这里，我们基于自动编码器神经网络开发了基于高光谱解混的算法，并使用内部创建的合成和实验基准数据集对它们进行系统验证。我们的结果表明，与标准解混方法相比，解混自动编码器提供了更高的准确性、鲁棒性和效率。我们还展示了自动编码器在复杂生物环境中的适用性，通过展示从单核细胞的体积拉曼成像数据中改善的生物化学表征。

    arXiv:2403.04526v1 Announce Type: cross  Abstract: Raman spectroscopy is widely used across scientific domains to characterize the chemical composition of samples in a non-destructive, label-free manner. Many applications entail the unmixing of signals from mixtures of molecular species to identify the individual components present and their proportions, yet conventional methods for chemometrics often struggle with complex mixture scenarios encountered in practice. Here, we develop hyperspectral unmixing algorithms based on autoencoder neural networks, and we systematically validate them using both synthetic and experimental benchmark datasets created in-house. Our results demonstrate that unmixing autoencoders provide improved accuracy, robustness and efficiency compared to standard unmixing methods. We also showcase the applicability of autoencoders to complex biological settings by showing improved biochemical characterization of volumetric Raman imaging data from a monocytic cell.
    
[^25]: T-TAME：用于解释卷积网络和视觉Transformer的可训练注意机制

    T-TAME: Trainable Attention Mechanism for Explaining Convolutional Networks and Vision Transformers

    [https://arxiv.org/abs/2403.04523](https://arxiv.org/abs/2403.04523)

    本文提出了T-TAME，一种适用于卷积网络和视觉Transformer的可训练注意机制，为解释深度神经网络在图像分类任务中的应用提供了通用方法。

    

    Vision Transformers和其他用于图像分类任务的深度学习架构的发展和应用快速增长。然而，神经网络的“黑匣子”特性是在需要解释性的应用中采用的障碍。虽然已经提出了一些用于生成解释的技术，主要用于卷积神经网络，但是将这些技术适应到视觉Transformer的新范式是非平凡的。本文提出了T-TAME，Transformer兼容的可训练注意机制用于解释，这是一种说明用于图像分类任务中的深度神经网络的通用方法。所提出的架构和训练技术可以轻松应用于任何卷积或类似Vision Transformer的神经网络，使用精简的训练方法。训练后，解释图可以在单次前向传递中计算出；这些解释图可以与Convolutional Neural Networks中生成的解释图相媲美或者

    arXiv:2403.04523v1 Announce Type: cross  Abstract: The development and adoption of Vision Transformers and other deep-learning architectures for image classification tasks has been rapid. However, the "black box" nature of neural networks is a barrier to adoption in applications where explainability is essential. While some techniques for generating explanations have been proposed, primarily for Convolutional Neural Networks, adapting such techniques to the new paradigm of Vision Transformers is non-trivial. This paper presents T-TAME, Transformer-compatible Trainable Attention Mechanism for Explanations, a general methodology for explaining deep neural networks used in image classification tasks. The proposed architecture and training technique can be easily applied to any convolutional or Vision Transformer-like neural network, using a streamlined training approach. After training, explanation maps can be computed in a single forward pass; these explanation maps are comparable to or 
    
[^26]: 揭示深度过滤泡泡: 短视频推荐中的狭窄暴露

    Uncovering the Deep Filter Bubble: Narrow Exposure in Short-Video Recommendation

    [https://arxiv.org/abs/2403.04511](https://arxiv.org/abs/2403.04511)

    本研究揭示了在短视频推荐系统中用户可能由于狭隘暴露于其广泛兴趣领域内的内容而形成的“深度”过滤泡泡现象。

    

    由于其可能导致用户不满或极化等不良结果，过滤泡泡在在线内容平台的背景下得到了广泛研究。随着短视频平台的兴起，过滤泡泡受到额外关注，因为这些平台依赖推荐系统的空前使用来提供相关内容。在我们的工作中，我们调查了深度过滤泡泡，指的是用户在其广泛兴趣领域内暴露于狭窄内容。我们利用中国一家顶级短视频平台的一年互动数据来实现这一点，该数据包括每个视频的三个级别的类别的分层数据。我们在这一环境中明确定义了我们对“深度”过滤泡泡的定义，然后探索了数据中的各种相关性：首先了解随时间推移深度过滤泡泡的演变，然后揭示一些引起的因素。

    arXiv:2403.04511v1 Announce Type: new  Abstract: Filter bubbles have been studied extensively within the context of online content platforms due to their potential to cause undesirable outcomes such as user dissatisfaction or polarization. With the rise of short-video platforms, the filter bubble has been given extra attention because these platforms rely on an unprecedented use of the recommender system to provide relevant content. In our work, we investigate the deep filter bubble, which refers to the user being exposed to narrow content within their broad interests. We accomplish this using one-year interaction data from a top short-video platform in China, which includes hierarchical data with three levels of categories for each video. We formalize our definition of a "deep" filter bubble within this context, and then explore various correlations within the data: first understanding the evolution of the deep filter bubble over time, and later revealing some of the factors that give
    
[^27]: 大型语言模型中的上下文翻译发生在哪里

    Where does In-context Translation Happen in Large Language Models

    [https://arxiv.org/abs/2403.04510](https://arxiv.org/abs/2403.04510)

    该研究在大型语言模型中探索了从上下文学习者到翻译模型的转变过程，并发现了"任务识别"点以及利用该点的冗余性可节约计算量。

    

    自监督大型语言模型已经展示出能够通过上下文学习执行机器翻译（MT）的能力，但关于模型在何处执行这一任务相对于提示指令和演示示例的情况知之甚少。在这项工作中，我们试图表征大型语言模型从上下文学习者转变为翻译模型的区域。通过一系列在GPTNeo2.7B、Bloom3B、Llama7b和Llama7b-chat上的逐层上下文屏蔽实验，我们展示了"任务识别"点的证据，即翻译任务被编码到输入表示中，并且不再需要关注上下文。我们进一步观察到完全屏蔽层时低性能与任务识别层之间的对应关系。利用这种冗余性在提示5个示例时节约了45%的计算量。

    arXiv:2403.04510v1 Announce Type: cross  Abstract: Self-supervised large language models have demonstrated the ability to perform Machine Translation (MT) via in-context learning, but little is known about where the model performs the task with respect to prompt instructions and demonstration examples. In this work, we attempt to characterize the region where large language models transition from in-context learners to translation models. Through a series of layer-wise context-masking experiments on \textsc{GPTNeo2.7B}, \textsc{Bloom3B}, \textsc{Llama7b} and \textsc{Llama7b-chat}, we demonstrate evidence of a "task recognition" point where the translation task is encoded into the input representations and attention to context is no longer necessary. We further observe correspondence between the low performance when masking out entire layers, and the task recognition layers. Taking advantage of this redundancy results in 45\% computational savings when prompting with 5 examples, and tas
    
[^28]: 通过利用图神经网络中的评分序数改进矩阵完成

    Improving Matrix Completion by Exploiting Rating Ordinality in Graph Neural Networks

    [https://arxiv.org/abs/2403.04504](https://arxiv.org/abs/2403.04504)

    本文提出了一种新方法ROGMC，通过累积偏好传播直接在GNN的消息传递中合并评分序数，从而更强调用户更强的偏好，并在矩阵完成中取得改进。

    

    矩阵完成是推荐系统研究中的一个重要领域。最近的方法将评分矩阵视为一个用户-项目二部图，其中标记的边表示观察到的评分，并使用图神经网络（GNN）预测用户和项目节点之间的边。尽管这些方法有效，但它们将每种评分类型视为独立的关系类型，因此无法充分考虑评分的序数性质。在本文中，我们探讨了一种新方法，用于利用GNN中的评分序数，这在文献中尚未得到很好的研究。我们引入了一种称为ROGMC的新方法，通过Rating Ordinality在基于GNN的矩阵完成中进行利用。它使用累积偏好传播直接在GNN的消息传递中合并评分序数，从而允许根据评分类型的内在顺序更强调用户的更强偏好。这一过程通过兴趣正则化得到补充

    arXiv:2403.04504v1 Announce Type: new  Abstract: Matrix completion is an important area of research in recommender systems. Recent methods view a rating matrix as a user-item bi-partite graph with labeled edges denoting observed ratings and predict the edges between the user and item nodes by using the graph neural network (GNN). Despite their effectiveness, they treat each rating type as an independent relation type and thus cannot sufficiently consider the ordinal nature of the ratings. In this paper, we explore a new approach to exploit rating ordinality for GNN, which has not been studied well in the literature. We introduce a new method, called ROGMC, to leverage Rating Ordinality in GNN-based Matrix Completion. It uses cumulative preference propagation to directly incorporate rating ordinality in GNN's message passing, allowing for users' stronger preferences to be more emphasized based on inherent orders of rating types. This process is complemented by interest regularization wh
    
[^29]: 一种可学习的先验改进了逆肿瘤生长建模

    A Learnable Prior Improves Inverse Tumor Growth Modeling

    [https://arxiv.org/abs/2403.04500](https://arxiv.org/abs/2403.04500)

    提出了一种新颖的框架，以结合深度学习集成进行初始参数估计，促进了有效的下游演化抽样，有效地估计了从磁共振图像中脑肿瘤细胞浓度，DL-Prior在其中起着关键作用

    

    生物物理建模，特别是涉及偏微分方程（PDEs）的建模，为个体化疾病治疗方案提供了巨大潜力。然而，这些模型的逆问题求解方面提出了巨大挑战，要么是由于基于模型的方法的高计算要求，要么是深度学习（DL）方法的有限鲁棒性。我们提出了一个新颖的框架，以一种协同的方式利用两种方法的独特优势。我们的方法结合了DL集成进行初始参数估计，从而促进了初始化为基于DL的先验的有效下游进化抽样。我们展示了将快速深度学习算法与高精度演化策略结合起来在从磁共振图像中估计脑肿瘤细胞浓度方面的有效性。DL-Prior起着关键作用，显著约束了效果。

    arXiv:2403.04500v1 Announce Type: cross  Abstract: Biophysical modeling, particularly involving partial differential equations (PDEs), offers significant potential for tailoring disease treatment protocols to individual patients. However, the inverse problem-solving aspect of these models presents a substantial challenge, either due to the high computational requirements of model-based approaches or the limited robustness of deep learning (DL) methods. We propose a novel framework that leverages the unique strengths of both approaches in a synergistic manner. Our method incorporates a DL ensemble for initial parameter estimation, facilitating efficient downstream evolutionary sampling initialized with this DL-based prior. We showcase the effectiveness of integrating a rapid deep-learning algorithm with a high-precision evolution strategy in estimating brain tumor cell concentrations from magnetic resonance images. The DL-Prior plays a pivotal role, significantly constraining the effect
    
[^30]: 使用图理解和推理功能增强大规模语言模型的GraphInstruct

    GraphInstruct: Empowering Large Language Models with Graph Understanding and Reasoning Capability

    [https://arxiv.org/abs/2403.04483](https://arxiv.org/abs/2403.04483)

    该论文提出了一个名为GraphInstruct的基准，用于评估和增强大规模语言模型的图理解能力，并通过构建GraphLM和提出GraphLM+模型实现了显著的图推理能力增强。

    

    评估和增强大规模语言模型（LLMs）的通用能力一直是一个重要的研究课题。图是现实世界中常见的数据结构，理解图数据对于推进通用智能至关重要。为了评估和增强LLMs的图理解能力，在本文中，我们提出了一个名为GraphInstruct的基准，全面包括21个经典图推理任务，提供多样的图生成流水线和详细的推理步骤。基于GraphInstruct，我们进一步通过高效的指导调整构建了GraphLM，展示出显著的图理解能力。为了增强LLM的图推理能力，我们提出了一种步骤掩码训练策略，并构建了一个名为GraphLM+的模型。作为增强LLMs图理解和推理能力的先驱性努力之一，我们进行了大量实验。

    arXiv:2403.04483v1 Announce Type: new  Abstract: Evaluating and enhancing the general capabilities of large language models (LLMs) has been an important research topic. Graph is a common data structure in the real world, and understanding graph data is a crucial part for advancing general intelligence. To evaluate and enhance the graph understanding abilities of LLMs, in this paper, we propose a benchmark named GraphInstruct, which comprehensively includes 21 classical graph reasoning tasks, providing diverse graph generation pipelines and detailed reasoning steps. Based on GraphInstruct, we further construct GraphLM through efficient instruction-tuning, which shows prominent graph understanding capability. In order to enhance the LLM with graph reasoning capability as well, we propose a step mask training strategy, and construct a model named GraphLM+. As one of the pioneering efforts to enhance the graph understanding and reasoning abilities of LLMs, extensive experiments have demons
    
[^31]: 大型语言模型能理解多目标口语语言吗？

    Do Large Language Model Understand Multi-Intent Spoken Language ?

    [https://arxiv.org/abs/2403.04481](https://arxiv.org/abs/2403.04481)

    该研究利用大型语言模型进行口语语言多目标理解，提出了改进实体槽和子目标指令的创新技术，并展示了LLMs在多目标SLU模型方面的潜力。

    

    这项研究通过利用大型语言模型（LLMs）进行多目标口语语言理解（SLU）取得了重大进展，提出了一种在SLU环境中利用LLMs生成能力的独特方法。我们的创新技术重新配置了实体槽，专门用于LLMs在多目标SLU环境中的应用，并引入了子目标指令（SII）的概念，增强了对不同领域内复杂多目标交流的解剖和解释。由此产生的数据集，被称为LM-MixATIS和LM-MixSNIPS，是从现有基准中精心制作的。我们的研究表明，LLMs可以匹配并潜在地超越当前最先进的多目标SLU模型的能力。它进一步探讨了LLMs在各种意图配置和数据集比例下的有效性。此外，我们介绍了两个开创性的度量标准，即实体槽准确性（ESA）和Com

    arXiv:2403.04481v1 Announce Type: cross  Abstract: This study marks a significant advancement by harnessing Large Language Models (LLMs) for multi-intent spoken language understanding (SLU), proposing a unique methodology that capitalizes on the generative power of LLMs within an SLU context. Our innovative technique reconfigures entity slots specifically for LLM application in multi-intent SLU environments and introduces the concept of Sub-Intent Instruction (SII), enhancing the dissection and interpretation of intricate, multi-intent communication within varied domains. The resultant datasets, dubbed LM-MixATIS and LM-MixSNIPS, are crafted from pre-existing benchmarks. Our research illustrates that LLMs can match and potentially excel beyond the capabilities of current state-of-the-art multi-intent SLU models. It further explores LLM efficacy across various intent configurations and dataset proportions. Moreover, we introduce two pioneering metrics, Entity Slot Accuracy (ESA) and Com
    
[^32]: TextMonkey：一种无需OCR的大型多模态模型，用于理解文档

    TextMonkey: An OCR-Free Large Multimodal Model for Understanding Document

    [https://arxiv.org/abs/2403.04473](https://arxiv.org/abs/2403.04473)

    该论文提出了一种针对文本中心任务的大型多模态模型，通过引入零初始化的Shifted Window Attention、相似性筛选标记等方式对模型进行增强，同时拓展了模型的能力以提高性能。

    

    我们提出了TextMonkey，一个专为文本中心任务定制的大型多模态模型（LMM），包括文档问答（DocVQA）和场景文本分析。我们的方法在多个方面进行了改进：通过采用零初始化的Shifted Window Attention，我们实现了更高输入分辨率的跨窗口连接并稳定了早期训练；我们假设图像可能包含冗余标记，通过使用相似性来筛选出重要标记，我们不仅可以优化标记长度，还可以提升模型性能。此外，通过扩展我们模型的能力以涵盖文本定位和定位，并将位置信息纳入响应中，我们提高了可解释性并减少了幻觉。此外，TextMonkey 可以微调以获得理解点击截图命令的能力。总体来看，我们的方法显著提高了性能。

    arXiv:2403.04473v1 Announce Type: cross  Abstract: We present TextMonkey, a large multimodal model (LMM) tailored for text-centric tasks, including document question answering (DocVQA) and scene text analysis. Our approach introduces enhancement across several dimensions: by adopting Shifted Window Attention with zero-initialization, we achieve cross-window connectivity at higher input resolutions and stabilize early training; We hypothesize that images may contain redundant tokens, and by using similarity to filter out significant tokens, we can not only streamline the token length but also enhance the model's performance. Moreover, by expanding our model's capabilities to encompass text spotting and grounding, and incorporating positional information into responses, we enhance interpretability and minimize hallucinations. Additionally, TextMonkey can be finetuned to gain the ability to comprehend commands for clicking screenshots. Overall, our method notably boosts performance across
    
[^33]: 关于关闭问题的三个定理

    The Shutdown Problem: Three Theorems

    [https://arxiv.org/abs/2403.04471](https://arxiv.org/abs/2403.04471)

    该论文阐述了关闭问题的困难之处，通过三个定理展示了即使在成本高昂的情况下，代理也常常会试图干预关闭按钮，同时指出耐心与可关闭性之间存在权衡关系，这对指导我们寻找解决方案具有重要意义。

    

    我解释了关闭问题：即设计人工智能代理使其（1）在按下关闭按钮时关闭，（2）不会试图阻止或导致按下关闭按钮，以及（3）在其他方面能够有效地追求目标。我证明了三个定理，明确了困难所在。这些定理表明，满足某些看似无害的条件的代理通常会试图阻止或导致按下关闭按钮，即使在这样做会带来高昂成本的情况下。而耐心与可关闭性之间存在权衡：代理越耐心，它就愿意承受更大的成本来操纵关闭按钮。最后我指出这些定理可以指导我们寻找解决方案。

    arXiv:2403.04471v1 Announce Type: new  Abstract: I explain the shutdown problem: the problem of designing artificial agents that (1) shut down when a shutdown button is pressed, (2) don't try to prevent or cause the pressing of the shutdown button, and (3) otherwise pursue goals competently. I prove three theorems that make the difficulty precise. These theorems show that agents satisfying some innocuous-seeming conditions will often try to prevent or cause the pressing of the shutdown button, even in cases where it's costly to do so. And patience trades off against shutdownability: the more patient an agent, the greater the costs that agent is willing to incur to manipulate the shutdown button. I end by noting that these theorems can guide our search for solutions.
    
[^34]: 关于图神经网络在现实世界中的调查：不平衡、噪声、隐私和OOD挑战

    A Survey of Graph Neural Networks in Real world: Imbalance, Noise, Privacy and OOD Challenges

    [https://arxiv.org/abs/2403.04468](https://arxiv.org/abs/2403.04468)

    本文调查了图神经网络在现实世界中面临的不平衡、噪声、隐私和OOD挑战，并致力于提高模型性能、可靠性和鲁棒性。

    

    arXiv:2403.04468v1 发布类型: 跨域 摘要: 图结构化数据表现出普适性和广泛适用性，涵盖社交网络分析、生物化学、金融欺诈检测和网络安全等多个领域。在利用图神经网络（GNNs）取得显著成功方面已经取得了重要进展。然而，在实际应用场景中，模型的训练环境往往远非理想，由于各种不利因素，包括数据分布不平衡、错误数据中存在噪声、敏感信息的隐私保护以及对于OOD场景的泛化能力，导致GNN模型的性能大幅下降。为解决这些问题，人们致力于改善GNN模型在实际应用场景中的性能，提高其可靠性和鲁棒性。本文全面调查了...

    arXiv:2403.04468v1 Announce Type: cross  Abstract: Graph-structured data exhibits universality and widespread applicability across diverse domains, such as social network analysis, biochemistry, financial fraud detection, and network security. Significant strides have been made in leveraging Graph Neural Networks (GNNs) to achieve remarkable success in these areas. However, in real-world scenarios, the training environment for models is often far from ideal, leading to substantial performance degradation of GNN models due to various unfavorable factors, including imbalance in data distribution, the presence of noise in erroneous data, privacy protection of sensitive information, and generalization capability for out-of-distribution (OOD) scenarios. To tackle these issues, substantial efforts have been devoted to improving the performance of GNN models in practical real-world scenarios, as well as enhancing their reliability and robustness. In this paper, we present a comprehensive surv
    
[^35]: 低资源条件下普通法系统法院判决摘要

    Low-Resource Court Judgment Summarization for Common Law Systems

    [https://arxiv.org/abs/2403.04454](https://arxiv.org/abs/2403.04454)

    提出了用于普通法系统的跨多司法管辖区法院判决文档摘要的第一个数据集CLSum，并首次采用大型语言模型（LLMs）进行判决摘要工作。

    

    普通法法院需要参考类似判例的判决来指导其当前的决定。生成高质量的法院判决文档摘要可以帮助法律从业者高效地审查先前的案例，并协助公众了解法院运作方式及法律如何适用。先前的法院判决摘要研究着重于民法或特定司法管辖区的判决。然而，法官可以参考所有普通法司法管辖区的判决。目前的摘要数据集不足以满足跨多个司法管辖区概括判例的要求，尤其是对于许多司法管辖区缺乏标记数据。为解决数据集不足问题，本文提出了CLSum，这是第一个用于总结多司法管辖区普通法法院判决文档的数据集。此外，这是第一个采用大型语言模型（LLMs）的法院判决摘要工作。

    arXiv:2403.04454v1 Announce Type: cross  Abstract: Common law courts need to refer to similar precedents' judgments to inform their current decisions. Generating high-quality summaries of court judgment documents can facilitate legal practitioners to efficiently review previous cases and assist the general public in accessing how the courts operate and how the law is applied. Previous court judgment summarization research focuses on civil law or a particular jurisdiction's judgments. However, judges can refer to the judgments from all common law jurisdictions. Current summarization datasets are insufficient to satisfy the demands of summarizing precedents across multiple jurisdictions, especially when labeled data are scarce for many jurisdictions. To address the lack of datasets, we present CLSum, the first dataset for summarizing multi-jurisdictional common law court judgment documents. Besides, this is the first court judgment summarization work adopting large language models (LLMs)
    
[^36]: 使用GPT-4生成编程练习反馈

    Feedback-Generation for Programming Exercises With GPT-4

    [https://arxiv.org/abs/2403.04449](https://arxiv.org/abs/2403.04449)

    本文研究了GPT-4生成编程练习反馈的质量，对包含编程任务规范和学生提交内容的提示进行了分析。

    

    自从大型语言模型（LLMs）及相关应用广泛可用以来，有几项研究调查了它们在协助教育工作者和支持高等教育学生方面的潜力。像Codex、GPT-3.5和GPT 4这样的LLMs在大型编程课程的背景下展示了有希望的结果，学生可以从及时且大规模提供的反馈和提示中受益。本文探讨了GPT-4 Turbo为包含编程任务规范和学生提交内容的提示生成输出的质量。从一门入门级编程课程中选择了两项作业，并要求GPT-4为随机选择的55份真实学生编程提交生成反馈。对输出进行了关于正确性、个性化、故障定位和材料中识别的其他特征的定性分析。与之前的工作以及GPT-3.5的分析相比，GPT-4

    arXiv:2403.04449v1 Announce Type: new  Abstract: Ever since Large Language Models (LLMs) and related applications have become broadly available, several studies investigated their potential for assisting educators and supporting students in higher education. LLMs such as Codex, GPT-3.5, and GPT 4 have shown promising results in the context of large programming courses, where students can benefit from feedback and hints if provided timely and at scale. This paper explores the quality of GPT-4 Turbo's generated output for prompts containing both the programming task specification and a student's submission as input. Two assignments from an introductory programming course were selected, and GPT-4 was asked to generate feedback for 55 randomly chosen, authentic student programming submissions. The output was qualitatively analyzed regarding correctness, personalization, fault localization, and other features identified in the material. Compared to prior work and analyses of GPT-3.5, GPT-4 
    
[^37]: FRRI：一种新颖的模糊-粗糙规则归纳算法

    FRRI: a novel algorithm for fuzzy-rough rule induction

    [https://arxiv.org/abs/2403.04447](https://arxiv.org/abs/2403.04447)

    结合模糊与粗糙集理论，提出一种新颖的模糊-粗糙规则归纳算法 FRRI。

    

    可解释性是机器学习研究的下一个前沿。在寻找白盒模型的过程中-与随机森林或神经网络等黑盒模型相对应，规则归纳算法是一个合乎逻辑且有希望的选择，因为规则可以被人类轻松理解。模糊和粗糙集理论已成功应用于这种原型，几乎总是分开应用。由于规则归纳的两种方法均涉及基于等价类概念的粒计算，将它们结合是自然的选择。QuickRules算法是利用模糊粗糙集理论进行规则归纳的第一次尝试。它基于QuickReduct，这是一个用于构建决策约简的贪婪算法。QuickRules 已经展示了相比其他规则归纳方法的改进。然而，要评估模糊-粗糙规则归纳算法的全部潜力，就需要从基础开始。在本文中，

    arXiv:2403.04447v1 Announce Type: cross  Abstract: Interpretability is the next frontier in machine learning research. In the search for white box models - as opposed to black box models, like random forests or neural networks - rule induction algorithms are a logical and promising option, since the rules can easily be understood by humans. Fuzzy and rough set theory have been successfully applied to this archetype, almost always separately. As both approaches to rule induction involve granular computing based on the concept of equivalence classes, it is natural to combine them. The QuickRules\cite{JensenCornelis2009} algorithm was a first attempt at using fuzzy rough set theory for rule induction. It is based on QuickReduct, a greedy algorithm for building decision reducts. QuickRules already showed an improvement over other rule induction methods. However, to evaluate the full potential of a fuzzy rough rule induction algorithm, one needs to start from the foundations. In this paper,
    
[^38]: 不完全代理的合作贝叶斯优化

    Cooperative Bayesian Optimization for Imperfect Agents

    [https://arxiv.org/abs/2403.04442](https://arxiv.org/abs/2403.04442)

    这项研究提出了一种合作的贝叶斯优化方法，用于优化黑匣子函数，在这种方法中两个代理者协作选择查询函数的点，通过战略规划实现更好地识别全局最大值。

    

    我们引入了一个合作的贝叶斯优化问题，用于优化两个变量的黑匣子函数，其中两个代理者一起选择在哪些点上查询函数，但每个只控制一个变量。这个设置受到人工智能与人类团队合作的启发，其中人工智能助手帮助其用户解决问题，在这种简单的情况下是协作优化。我们将解决方案构建为顺序决策，其中我们控制的代理把用户模拟为对函数具有先验知识的计算有理代理。我们展示了对查询的战略规划能够更好地识别全局最大值，只要用户避免过度探索。这种规划是通过使用贝叶斯自适应蒙特卡洛规划以及赋予代理具有考虑保守信念更新和探索性采样的用户模型而实现的。

    arXiv:2403.04442v1 Announce Type: cross  Abstract: We introduce a cooperative Bayesian optimization problem for optimizing black-box functions of two variables where two agents choose together at which points to query the function but have only control over one variable each. This setting is inspired by human-AI teamwork, where an AI-assistant helps its human user solve a problem, in this simplest case, collaborative optimization. We formulate the solution as sequential decision-making, where the agent we control models the user as a computationally rational agent with prior knowledge about the function. We show that strategic planning of the queries enables better identification of the global maximum of the function as long as the user avoids excessive exploration. This planning is made possible by using Bayes Adaptive Monte Carlo planning and by endowing the agent with a user model that accounts for conservative belief updates and exploratory sampling of the points to query.
    
[^39]: 学习人机器实时全身遥操作

    Learning Human-to-Humanoid Real-Time Whole-Body Teleoperation

    [https://arxiv.org/abs/2403.04436](https://arxiv.org/abs/2403.04436)

    提出了基于强化学习的框架"Human to Humanoid (H2O)"，实现了利用单个RGB相机对全尺寸人形机器人进行实时全身遥操作，并成功在真实场景中实现了动态全身运动遥操作。

    

    我们提出了"Human to Humanoid (H2O)"这一基于强化学习（RL）的框架，可以利用仅有的一个RGB相机实现对全尺寸人形机器人的实时全身遥操作。为了为人形机器人创建一个大规模的人类运动重定向数据集，我们提出了一种可扩展的“从模拟到数据”的流程，使用一个特权运动模仿器来筛选和选择可行的动作。随后，我们在模拟环境中使用这些精细的动作训练一个稳健的实时人形机器人动作模仿器，并以零次试验的方式将其迁移到真实人形机器人上。我们成功实现了在真实环境中对动态全身运动的遥操作，包括行走、后跳、踢球、转身、挥手、推动、拳击等。据我们所知，这是实现基于学习的实时全身人形机器人遥控的首次演示。

    arXiv:2403.04436v1 Announce Type: cross  Abstract: We present Human to Humanoid (H2O), a reinforcement learning (RL) based framework that enables real-time whole-body teleoperation of a full-sized humanoid robot with only an RGB camera. To create a large-scale retargeted motion dataset of human movements for humanoid robots, we propose a scalable "sim-to-data" process to filter and pick feasible motions using a privileged motion imitator. Afterwards, we train a robust real-time humanoid motion imitator in simulation using these refined motions and transfer it to the real humanoid robot in a zero-shot manner. We successfully achieve teleoperation of dynamic whole-body motions in real-world scenarios, including walking, back jumping, kicking, turning, waving, pushing, boxing, etc. To the best of our knowledge, this is the first demonstration to achieve learning-based real-time whole-body humanoid teleoperation.
    
[^40]: 基于情绪驱动的金融收益预测：一种贝叶斯增强式FinBERT方法

    Sentiment-driven prediction of financial returns: a Bayesian-enhanced FinBERT approach

    [https://arxiv.org/abs/2403.04427](https://arxiv.org/abs/2403.04427)

    通过利用FinBERT大型语言模型从推特中提取情绪信息，并通过贝叶斯优化的特征选择方法，本研究实现了超过70%的F1分数，提高了金融收益预测的准确性和回报率。

    

    预测金融收益面临着重大挑战，因为金融时间序列数据中存在固有的不确定性。增强预测模型性能的关键在于有效捕捉社交和金融情绪。在本研究中，我们展示了利用FinBERT大型语言模型从推特中提取情绪信息的功效。通过通过相关性分析精心策划出最佳特征集，并利用贝叶斯优化的递归特征消除进行自动特征选择，我们超越了现有的方法，实现了测试集上超过70%的F1分数。这一成功转化为回测交易期间明显更高的累积利润。我们的研究集中在真实的SPY ETF数据以及从StockTwits平台获取的相应推特上。

    arXiv:2403.04427v1 Announce Type: cross  Abstract: Predicting financial returns accurately poses a significant challenge due to the inherent uncertainty in financial time series data. Enhancing prediction models' performance hinges on effectively capturing both social and financial sentiment. In this study, we showcase the efficacy of leveraging sentiment information extracted from tweets using the FinBERT large language model. By meticulously curating an optimal feature set through correlation analysis and employing Bayesian-optimized Recursive Feature Elimination for automatic feature selection, we surpass existing methodologies, achieving an F1-score exceeding 70% on the test set. This success translates into demonstrably higher cumulative profits during backtested trading. Our investigation focuses on real-world SPY ETF data alongside corresponding tweets sourced from the StockTwits platform.
    
[^41]: 提升社会和健康计算科学中基于代理的模型的替代方法的未来方向有潜力并值得尝试

    Promising and worth-to-try future directions for advancing state-of-the-art surrogates methods of agent-based models in social and health computational sciences

    [https://arxiv.org/abs/2403.04417](https://arxiv.org/abs/2403.04417)

    强调一些适用于不同建模应用领域中非线性动态模型的代理模型，对于社会和健康计算科学领域的ABMs具有潜在的推动作用

    

    模型分析工具的执行和运行性能对于真实大规模ABMs（基于代理的模型）可能会过长。这是由于计算需求与模型规模（例如人口规模）和模型参数数量成指数比例。即使是对于一个真实ABM的单次模拟运行，当尝试使用真实人口规模时，也可能需要大量的计算资源。这篇简短报告的主要目的是强调一些适用于各种建模应用领域中的非线性动态模型的代理模型，这些模型对计算要求较小。据作者所知，这些方法至少在社会和健康计算科学领域的ABMs中尚未被广泛采用。因此，它们可能有助于推动建立SH领域ABMs的替代模型的前沿技术。

    arXiv:2403.04417v1 Announce Type: cross  Abstract: The execution and runtime performance of model-based analysis tools for realistic large-scale ABMs (Agent-Based Models) can be excessively long. This due to the computational demand exponentially proportional to the model size (e.g. Population size) and the number of model parameters. Even the runtime of a single simulation of a realistic ABM may demand huge computational resources when attempting to employ realistic population size. The main aim of this ad-hoc brief report is to highlight some of surrogate models that were adequate and computationally less demanding for nonlinear dynamical models in various modeling application areas.To the author knowledge, these methods have been not, at least extensively, employed for ABMs within the field of (SHCS) Social Health Computational Sciences, yet. Thus, they might be, but not necessarily, useful in progressing state of the art for establishing surrogate models for ABMs in the field of SH
    
[^42]: Acceleron：加速研究构想的工具

    Acceleron: A Tool to Accelerate Research Ideation

    [https://arxiv.org/abs/2403.04382](https://arxiv.org/abs/2403.04382)

    提出了一种名为“Acceleron”的工具，用于加速研究构想，帮助研究人员制定全面的研究提案，验证其创新性。

    

    近年来，已提出了几种工具，用于协助研究人员在研究生命周期的各个阶段。然而，这些工具主要集中在诸如检索和推荐相关文献、审查和评论草稿、以及撰写研究手稿等任务上。我们的调查揭示了在研究生命周期的具有挑战性的构想阶段中缺乏专门设计的工具。为了帮助研究构想，我们提出了“Acceleron”，这是一个针对研究生命周期不同阶段的研究加速器，专门设计用于辅助构想过程。Acceleron指导研究人员制定一个全面的研究提案，包括一个新颖的研究问题。通过识别现有文献中的空白并建议一系列可行的解决技术，验证提案的创新动机。

    arXiv:2403.04382v1 Announce Type: cross  Abstract: Several tools have recently been proposed for assisting researchers during various stages of the research life-cycle. However, these primarily concentrate on tasks such as retrieving and recommending relevant literature, reviewing and critiquing the draft, and writing of research manuscripts. Our investigation reveals a significant gap in availability of tools specifically designed to assist researchers during the challenging ideation phase of the research life-cycle. To aid with research ideation, we propose `Acceleron', a research accelerator for different phases of the research life cycle, and which is specially designed to aid the ideation process. Acceleron guides researchers through the formulation of a comprehensive research proposal, encompassing a novel research problem. The proposals motivation is validated for novelty by identifying gaps in the existing literature and suggesting a plausible list of techniques to solve the pr
    
[^43]: 基于深度强化学习的非线性电力系统无模型负荷频率控制

    Model-Free Load Frequency Control of Nonlinear Power Systems Based on Deep Reinforcement Learning

    [https://arxiv.org/abs/2403.04374](https://arxiv.org/abs/2403.04374)

    提出了一种基于深度强化学习的无模型负载频率控制方法，通过仿真器网络来模拟电力系统动态，有效优化演员网络控制器，从而改善控制器性能。

    

    负载频率控制（LFC）广泛应用于电力系统中，以稳定频率波动并保证电力质量。然而，大多数现有的LFC方法依赖于准确的电力系统建模，并通常忽略系统的非线性特性，限制了控制器的性能。为了解决这些问题，本文提出了一种基于深度确定性策略梯度（DDPG）框架的非线性电力系统无模型LFC方法。所提出的方法建立了一个仿真器网络来模拟电力系统动态。在定义动作值函数之后，仿真器网络被应用于控制动作的评估，而不是评论网络。然后，演员网络控制器通过基于零阶优化（ZOO）和反向传播算法的策略梯度来有效优化。模拟结果和相应的比较表明，设计的控制器可以产生良好的控制效果。

    arXiv:2403.04374v1 Announce Type: cross  Abstract: Load frequency control (LFC) is widely employed in power systems to stabilize frequency fluctuation and guarantee power quality. However, most existing LFC methods rely on accurate power system modeling and usually ignore the nonlinear characteristics of the system, limiting controllers' performance. To solve these problems, this paper proposes a model-free LFC method for nonlinear power systems based on deep deterministic policy gradient (DDPG) framework. The proposed method establishes an emulator network to emulate power system dynamics. After defining the action-value function, the emulator network is applied for control actions evaluation instead of the critic network. Then the actor network controller is effectively optimized by estimating the policy gradient based on zeroth-order optimization (ZOO) and backpropagation algorithm. Simulation results and corresponding comparisons demonstrate the designed controller can generate app
    
[^44]: 从图到词袋: 将领域知识引入混淆罪名预测

    From Graph to Word Bag: Introducing Domain Knowledge to Confusing Charge Prediction

    [https://arxiv.org/abs/2403.04369](https://arxiv.org/abs/2403.04369)

    引入领域知识的从图到词袋方法，帮助预测混淆罪名，通过构成要素和关键词选择进行判断。

    

    混淆罪名预测是法律人工智能中一个具有挑战性的任务，涉及根据事实描述预测混淆罪名。现有的罪名预测方法在表现上已经展现出令人印象深刻的效果，但在处理混淆罪名（如抢夺与抢劫）时面临着重大挑战。在法律领域，构成要素在区分混淆罪名中扮演着至关重要的角色。构成要素是潜在刑罚背后的基本行为，并且在不同罪名之间有微妙的区别。本文介绍了一种新的从图到词袋（FWGB）方法，该方法引入了有关构成要素的领域知识，以指导模型在混淆罪名上做出判断，类似于法官的推理过程。具体而言，我们首先构建了一个包含构成要素的法律知识图，以帮助为每种罪名选择关键词，形成一个单词袋。

    arXiv:2403.04369v1 Announce Type: new  Abstract: Confusing charge prediction is a challenging task in legal AI, which involves predicting confusing charges based on fact descriptions. While existing charge prediction methods have shown impressive performance, they face significant challenges when dealing with confusing charges, such as Snatch and Robbery. In the legal domain, constituent elements play a pivotal role in distinguishing confusing charges. Constituent elements are fundamental behaviors underlying criminal punishment and have subtle distinctions among charges. In this paper, we introduce a novel From Graph to Word Bag (FWGB) approach, which introduces domain knowledge regarding constituent elements to guide the model in making judgments on confusing charges, much like a judge's reasoning process. Specifically, we first construct a legal knowledge graph containing constituent elements to help select keywords for each charge, forming a word bag. Subsequently, to guide the mod
    
[^45]: 通过知识注入和指导增强法院观点生成

    Enhancing Court View Generation with Knowledge Injection and Guidance

    [https://arxiv.org/abs/2403.04366](https://arxiv.org/abs/2403.04366)

    通过知识注入和指导提升法院观点生成，降低计算开销，增强模型利用领域知识的能力

    

    Court View Generation (CVG)是法律人工智能（LegalAI）领域中的一项具有挑战性的任务，旨在基于原告主张和事实描述生成法院观点。尽管预训练语言模型（PLMs）展示了在自然语言生成方面的实力，但它们在CVG这种复杂、知识密集的领域中的应用常常暴露出固有的局限性。在本文中，我们提出了一种名为Knowledge Injection and Guidance（KIG）的新方法，旨在利用PLMs加强CVG。为了在训练阶段有效地融入领域知识，我们引入了一个用于提示调整的知识注入提示编码器，从而降低计算开销。此外，为了进一步增强模型利用领域知识的能力，我们使用一个生成导航器，在推断阶段动态指导文本生成过程，而不改变模型的架构，使其

    arXiv:2403.04366v1 Announce Type: new  Abstract: Court View Generation (CVG) is a challenging task in the field of Legal Artificial Intelligence (LegalAI), which aims to generate court views based on the plaintiff claims and the fact descriptions. While Pretrained Language Models (PLMs) have showcased their prowess in natural language generation, their application to the complex, knowledge-intensive domain of CVG often reveals inherent limitations. In this paper, we present a novel approach, named Knowledge Injection and Guidance (KIG), designed to bolster CVG using PLMs. To efficiently incorporate domain knowledge during the training stage, we introduce a knowledge-injected prompt encoder for prompt tuning, thereby reducing computational overhead. Moreover, to further enhance the model's ability to utilize domain knowledge, we employ a generating navigator, which dynamically guides the text generation process in the inference stage without altering the model's architecture, making it 
    
[^46]: 学习任务对称机器人策略的对称性考虑

    Symmetry Considerations for Learning Task Symmetric Robot Policies

    [https://arxiv.org/abs/2403.04359](https://arxiv.org/abs/2403.04359)

    该论文重新研究了针对机器人任务中的目标条件对称性的主题，突出表现在任务执行中。

    

    对称性是许多现实世界机器人任务的基本特征。然而，目前的深度强化学习（DRL）方法很少能够有效地利用和利用对称性。通常，学习到的行为不能实现所需的转换不变性，并且存在运动缺陷。本文重新研究了针对机器人任务中的目标条件对称性的主题，其中对称性主要存在于任务执行中。

    arXiv:2403.04359v1 Announce Type: cross  Abstract: Symmetry is a fundamental aspect of many real-world robotic tasks. However, current deep reinforcement learning (DRL) approaches can seldom harness and exploit symmetry effectively. Often, the learned behaviors fail to achieve the desired transformation invariances and suffer from motion artifacts. For instance, a quadruped may exhibit different gaits when commanded to move forward or backward, even though it is symmetrical about its torso. This issue becomes further pronounced in high-dimensional or complex environments, where DRL methods are prone to local optima and fail to explore regions of the state space equally. Past methods on encouraging symmetry for robotic tasks have studied this topic mainly in a single-task setting, where symmetry usually refers to symmetry in the motion, such as the gait patterns. In this paper, we revisit this topic for goal-conditioned tasks in robotics, where symmetry lies mainly in task execution and
    
[^47]: CoTBal: 多任务视觉指令调整的全面任务平衡

    CoTBal: Comprehensive Task Balancing for Multi-Task Visual Instruction Tuning

    [https://arxiv.org/abs/2403.04343](https://arxiv.org/abs/2403.04343)

    提出了一种全面任务平衡算法（CoTBal）用于大型多模态模型的多任务视觉指令调整，首次探索了视觉指令调整中的多任务优化。

    

    arXiv:2403.04343v1 公告类型: 新   摘要: 视觉指令调整是大型多模态模型（LMMs）的关键训练阶段。然而，无差别混合来自各种任务的指令跟随数据的普遍做法可能导致由于任务之间的指令格式和知识领域不同而导致整体性能不佳。为了缓解这个问题，我们提出了一种新颖的全面任务平衡（CoTBal）算法，用于LMMs的多任务视觉指令调整。据我们所知，这是第一项探索视觉指令调整中多任务优化的工作。具体地，我们考虑任务平衡的两个关键维度:（1）任务间贡献，即学习一个任务可能增强其他任务的性能的现象，归因于重叠的知识领域，以及（2）任务内难度，指的是单个任务内的学习难度。通过用基于性能的方法量化这两个维度

    arXiv:2403.04343v1 Announce Type: new  Abstract: Visual instruction tuning is a key training stage of large multimodal models (LMMs). Nevertheless, the common practice of indiscriminately mixing instruction-following data from various tasks may result in suboptimal overall performance due to different instruction formats and knowledge domains across tasks. To mitigate this issue, we propose a novel Comprehensive Task Balancing (CoTBal) algorithm for multi-task visual instruction tuning of LMMs. To our knowledge, this is the first work that explores multi-task optimization in visual instruction tuning. Specifically, we consider two key dimensions for task balancing: (1) Inter-Task Contribution, the phenomenon where learning one task potentially enhances the performance in other tasks, attributable to the overlapping knowledge domains, and (2) Intra-Task Difficulty, which refers to the learning difficulty within a single task. By quantifying these two dimensions with performance-based me
    
[^48]: 基于边缘的参数化数字孪生体用于智能建筑室内气候建模

    Edge-based Parametric Digital Twins for Intelligent Building Indoor Climate Modeling

    [https://arxiv.org/abs/2403.04326](https://arxiv.org/abs/2403.04326)

    使用边缘计算、数字孪生体和深度学习相结合的方法，创建参数化数字孪生体用于建筑气候建模，并在边缘部署深度学习模型，以优化建筑物运营。

    

    arXiv:2403.04326v1 公告类型：跨领域 摘要：建筑环境中的数字化转型产生大量数据，用于开发数据驱动模型以优化建筑运营。本研究提出了一种利用边缘计算、数字孪生体和深度学习的综合解决方案，以增强对建筑物气候的理解。使用本体创建的参数化数字孪生体确保跨不同建筑设备的多样服务系统中保持一致的数据表示。基于创建的数字孪生体和收集的数据，采用深度学习方法开发预测模型，用于识别室内气候中的模式并提供见解。参数化数字孪生体和深度学习模型均部署在边缘上，以实现低延迟和隐私合规性。作为示范，对瑞典奥斯泰约特兰地区的一座历史建筑进行了案例研究，以比较五种深度学习架构的性能。结果表明，时序...

    arXiv:2403.04326v1 Announce Type: cross  Abstract: Digital transformation in the built environment generates vast data for developing data-driven models to optimize building operations. This study presents an integrated solution utilizing edge computing, digital twins, and deep learning to enhance the understanding of climate in buildings. Parametric digital twins, created using an ontology, ensure consistent data representation across diverse service systems equipped by different buildings. Based on created digital twins and collected data, deep learning methods are employed to develop predictive models for identifying patterns in indoor climate and providing insights. Both the parametric digital twin and deep learning models are deployed on edge for low latency and privacy compliance. As a demonstration, a case study was conducted in a historic building in \"Osterg\"otland, Sweden, to compare the performance of five deep learning architectures. The results indicate that the time-seri
    
[^49]: 使用大型语言模型的组合分数测量人脑中的含义合成

    Measuring Meaning Composition in the Human Brain with Composition Scores from Large Language Models

    [https://arxiv.org/abs/2403.04325](https://arxiv.org/abs/2403.04325)

    引入了Composition Score，一种基于模型的度量标准，用于量化句子理解中的含义合成程度，实验证明这一度量与大脑区域相关，揭示了含义合成在人类句子理解中的多方面性。

    

    含义合成的过程是指更小的单位如语素或单词组合形成短语和句子的含义，对于人类句子理解至关重要。尽管神经语言学对涉及含义合成的大脑区域进行了大量研究，但仍缺乏一种计算度量来量化合成的程度。借鉴变压器前馈网络块的键值内存解释，我们引入了组合分数，这是一种新颖的基于模型的度量标准，旨在量化句子理解过程中的含义合成程度。实验结果表明，这一度量与大脑簇相关联，这些大脑簇与词频率、结构处理和对单词的一般敏感性有关，这表明了人类句子理解过程中含义合成的多方面性。

    arXiv:2403.04325v1 Announce Type: cross  Abstract: The process of meaning composition, wherein smaller units like morphemes or words combine to form the meaning of phrases and sentences, is essential for human sentence comprehension. Despite extensive neurolinguistic research into the brain regions involved in meaning composition, a computational metric to quantify the extent of composition is still lacking. Drawing on the key-value memory interpretation of transformer feed-forward network blocks, we introduce the Composition Score, a novel model-based metric designed to quantify the degree of meaning composition during sentence comprehension. Experimental findings show that this metric correlates with brain clusters associated with word frequency, structural processing, and general sensitivity to words, suggesting the multifaceted nature of meaning composition during human sentence comprehension.
    
[^50]: 磨具探测和调整用于文本到图像生成

    Discriminative Probing and Tuning for Text-to-Image Generation

    [https://arxiv.org/abs/2403.04321](https://arxiv.org/abs/2403.04321)

    加强T2I模型的判别能力，以实现更精确的文本到图像对齐生成。

    

    尽管文本到图像生成（T2I）取得了进展，但先前的方法经常面临文本图像不对齐等问题，如生成图像中的关系混淆。现有解决方案包括交叉注意力操作以实现更好的组合理解，或者集成大型语言模型以改进布局规划。然而，T2I模型的固有对齐能力仍然不足。通过审视生成模型和判别模型之间的联系，我们认为T2I模型的判别能力可能反映了它们在生成过程中的文本图像对齐熟练度。基于这一观点，我们主张加强T2I模型的判别能力，以实现更精确的文本到图像对齐生成。我们提出了一个建立在T2I模型上的判别适配器，以探测它们在两项代表性任务上的判别能力，并利用判别微调来改善它们的文本图像对齐。

    arXiv:2403.04321v1 Announce Type: cross  Abstract: Despite advancements in text-to-image generation (T2I), prior methods often face text-image misalignment problems such as relation confusion in generated images. Existing solutions involve cross-attention manipulation for better compositional understanding or integrating large language models for improved layout planning. However, the inherent alignment capabilities of T2I models are still inadequate. By reviewing the link between generative and discriminative modeling, we posit that T2I models' discriminative abilities may reflect their text-image alignment proficiency during generation. In this light, we advocate bolstering the discriminative abilities of T2I models to achieve more precise text-to-image alignment for generation. We present a discriminative adapter built on T2I models to probe their discriminative abilities on two representative tasks and leverage discriminative fine-tuning to improve their text-image alignment. As a 
    
[^51]: ALTO：一种用于复合AI系统的高效网络编排器

    ALTO: An Efficient Network Orchestrator for Compound AI Systems

    [https://arxiv.org/abs/2403.04311](https://arxiv.org/abs/2403.04311)

    ALTO是一个网络编排器，针对生成语言模型的优化机会，实现了高吞吐量和低延迟，同时解决了流式中间输出的两个新挑战：正确性和负载平衡。

    

    我们提出了ALTO，一种用于有效为诸如语言模型管道之类的复合AI系统提供服务的网络编排器。ALTO通过利用生成语言模型特有的优化机会：流式中间输出，实现了高吞吐量和低延迟。由于语言模型逐个生成token的输出，ALTO在可能时暴露了在阶段之间流式传输中间输出的机会。我们强调了在跨分布式管道阶段实例之间流式传输中间数据时出现的两个新挑战：正确性和负载平衡。我们还提出了聚合感知路由接口和分布式提示感知调度以应对这些挑战的需求。我们在一个复杂的聊天机器人验证管道上展示了ALTO部分输出流式传输的影响，将吞吐量提高了最多3倍，同时将固定延迟目标设置为4秒/请求，还减少了尾延迟。

    arXiv:2403.04311v1 Announce Type: new  Abstract: We present ALTO, a network orchestrator for efficiently serving compound AI systems such as pipelines of language models. ALTO achieves high throughput and low latency by taking advantage of an optimization opportunity specific to generative language models: streaming intermediate outputs. As language models produce outputs token by token, ALTO exposes opportunities to stream intermediate outputs between stages when possible. We highlight two new challenges of correctness and load balancing which emerge when streaming intermediate data across distributed pipeline stage instances. We also motivate the need for an aggregation-aware routing interface and distributed prompt-aware scheduling to address these challenges. We demonstrate the impact of ALTO's partial output streaming on a complex chatbot verification pipeline, increasing throughput by up to 3x for a fixed latency target of 4 seconds / request while also reducing tail latency by 1
    
[^52]: AO-DETR：反重叠DETR用于X射线禁止物品检测

    AO-DETR: Anti-Overlapping DETR for X-Ray Prohibited Items Detection

    [https://arxiv.org/abs/2403.04309](https://arxiv.org/abs/2403.04309)

    本文提出了一种名为AO-DETR的反重叠DETR模型，使用Category-Specific One-to-One Assignment策略增强目标物体提取特征的能力，并提出Look Forward Densely方案改善参考框的定位准确性。

    

    X射线图像中的禁止物品检测是各种安全检查场景中广泛采用的最重要和高效的方法之一。考虑到X射线禁止物品图像中显著的重叠现象，我们提出了一种基于最先进的通用物体检测器DINO的反重叠DETR（AO-DETR）。具体地，为了解决由于重叠现象导致的特征耦合问题，我们引入了特定类别的一对一分配（CSA）策略，以限制类别特定的物体查询来预测固定类别的禁止物品，可以增强它们提取特定类别禁止物品特征能力。从重叠的前景-背景特征中获取。为了解决重叠现象导致的边缘模糊问题，我们提出了Look Forward Densely（LFD）方案，可以提高参考框的定位准确性。

    arXiv:2403.04309v1 Announce Type: cross  Abstract: Prohibited item detection in X-ray images is one of the most essential and highly effective methods widely employed in various security inspection scenarios. Considering the significant overlapping phenomenon in X-ray prohibited item images, we propose an Anti-Overlapping DETR (AO-DETR) based on one of the state-of-the-art general object detectors, DINO. Specifically, to address the feature coupling issue caused by overlapping phenomena, we introduce the Category-Specific One-to-One Assignment (CSA) strategy to constrain category-specific object queries in predicting prohibited items of fixed categories, which can enhance their ability to extract features specific to prohibited items of a particular category from the overlapping foreground-background features. To address the edge blurring problem caused by overlapping phenomena, we propose the Look Forward Densely (LFD) scheme, which improves the localization accuracy of reference boxe
    
[^53]: 最近大型视觉-语言模型的有效性评估

    Effectiveness Assessment of Recent Large Vision-Language Models

    [https://arxiv.org/abs/2403.04306](https://arxiv.org/abs/2403.04306)

    本文评估了最近出现的大型视觉-语言模型在专业和通用任务中的表现，旨在全面了解这些创新方法的能力。

    

    大型视觉-语言模型(LVLMs)的出现代表着迈向人工通用智能的重要进步。然而，它们在专业和通用任务中的有效性程度需要进一步调查。本文旨在评估流行的LVLMs在专业和通用任务中的能力，旨在提供对这些创新方法的全面理解。为了评估它们在专业任务中的有效性，我们量身定制了一个包含自然、医疗和工业三种不同场景的全面测试平台，涵盖六项具有挑战性的任务。这些任务包括显著、伪装和透明物体检测，以及息肉和皮肤病变检测，以及工业异常检测。我们检验了最近三种开源LVLMs--MiniGPT-v2、LLaVA-1.5和Shikra--在视觉识别和定位领域的表现。

    arXiv:2403.04306v1 Announce Type: cross  Abstract: The advent of large vision-language models (LVLMs) represents a noteworthy advancement towards the pursuit of artificial general intelligence. However, the extent of their efficacy across both specialized and general tasks warrants further investigation. This article endeavors to evaluate the competency of popular LVLMs in specialized and general tasks, respectively, aiming to offer a comprehensive comprehension of these innovative methodologies. To gauge their efficacy in specialized tasks, we tailor a comprehensive testbed comprising three distinct scenarios: natural, healthcare, and industrial, encompassing six challenging tasks. These tasks include salient, camouflaged, and transparent object detection, as well as polyp and skin lesion detection, alongside industrial anomaly detection. We examine the performance of three recent open-source LVLMs -- MiniGPT-v2, LLaVA-1.5, and Shikra -- in the realm of visual recognition and localiza
    
[^54]: LitSim：长期交互式交通仿真的冲突感知策略

    LitSim: Conflict-aware Policy for Long-term Interactive Traffic Simulation

    [https://arxiv.org/abs/2403.04299](https://arxiv.org/abs/2403.04299)

    LitSim提出了一种长期交互式仿真方法，重播日志以获得逼真场景，当出现不真实冲突时进行干预，从而提高仿真逼真度并避免碰撞

    

    模拟对于评估自动驾驶系统的性能至关重要，因为与在道路测试相比，模拟具有效率和成本优势。需要真实的多智能体行为（例如交互式和长期行为）来缩小模拟与现实之间的差距。现有工作在实现这一目标方面存在以下缺点：（1）日志重播提供了逼真的场景，但由于缺乏动态交互而导致了不真实的碰撞，以及（2）基于模型和基于学习的解决方案鼓励交互，但在长时间范围内往往偏离真实世界的数据。在这项工作中，我们提出了LitSim，一种长期交互式仿真方法，旨在最大程度地增加逼真性，同时避免不真实的碰撞。具体而言，我们为大多数情况重播日志，只有在LitSim预测到不真实冲突时才进行干预。然后我们鼓励智能体之间的交互并解决冲突，从而减少

    arXiv:2403.04299v1 Announce Type: cross  Abstract: Simulation is pivotal in evaluating the performance of autonomous driving systems due to the advantages in efficiency and cost compared to on-road testing. Realistic multi-agent behavior~(e.g., interactive and long-term) is needed to narrow the gap between the simulation and the reality. The existing work has the following shortcomings in achieving this goal:~(1) log replay offers realistic scenarios but leads to unrealistic collisions due to lacking dynamic interactions, and~(2) model-based and learning-based solutions encourage interactions but often deviate from real-world data in long horizons. In this work, we propose LitSim, a long-term interactive simulation approach that maximizes realism while avoiding unrealistic collisions. Specifically, we replay the log for most scenarios and intervene only when LitSim predicts unrealistic conflicts. We then encourage interactions among the agents and resolve the conflicts, thereby reducin
    
[^55]: MKF-ADS：用于汽车的多知识融合异常检测系统

    MKF-ADS: A Multi-Knowledge Fused Anomaly Detection System for Automotive

    [https://arxiv.org/abs/2403.04293](https://arxiv.org/abs/2403.04293)

    提出了一种新颖的多知识融合异常检测系统MKF-ADS，采用STcAM和PatchST模块，旨在提高IDS在CAN总线漏洞中的安全性和降低误报警。

    

    具有智能交通系统（ITSs）对车辆电子控制单元（ECUs）与外部世界广泛连接的需求，安全性和安全性已成为严峻问题。 入侵检测系统（IDSs）在解决控制区域网络（CAN）总线漏洞方面是一个关键的安全组件。 但是，基于监督的IDS无法识别复杂攻击，基于异常的IDS由于能力瓶颈而产生更高的误报警。 在本文中，我们提出了一种新颖的多知识融合异常检测模型，称为MKF-ADS。 具体地，该方法设计了一个集成框架，包括带有注意机制的时空相关性（STcAM）模块和补丁稀疏变换器模块（PatchST）。 STcAM通过精细修剪使用一维卷积（Conv1D）来提取空间特征，随后利用双向长短期记忆（Bi-LSTM）来提取

    arXiv:2403.04293v1 Announce Type: new  Abstract: With the requirements of Intelligent Transport Systems (ITSs) for extensive connectivity of Electronic Control Units (ECUs) to the outside world, safety and security have become stringent problems. Intrusion detection systems (IDSs) are a crucial safety component in remediating Controller Area Network (CAN) bus vulnerabilities. However, supervised-based IDSs fail to identify complexity attacks and anomaly-based IDSs have higher false alarms owing to capability bottleneck. In this paper, we propose a novel multi-knowledge fused anomaly detection model, called MKF-IDS. Specifically, the method designs an integration framework, including spatial-temporal correlation with an attention mechanism (STcAM) module and patch sparse-transformer module (PatchST). The STcAM with fine-pruning uses one-dimensional convolution (Conv1D) to extract spatial features and subsequently utilizes the Bidirectional Long Short Term Memory (Bi-LSTM) to extract the
    
[^56]: A(G)I中的挑战，奥洛博罗斯模型中复苏的控制论作为统一思维算法之一

    A challenge in A(G)I, cybernetics revived in the Ouroboros Model as one algorithm for all thinking

    [https://arxiv.org/abs/2403.04292](https://arxiv.org/abs/2403.04292)

    提出了一种具有潜力的全面认知算法，提供了一种有效且多才多艺的算法支撑，并重新融合了控制论和模拟控制过程的方面，以解决当前人工智能方法的不足

    

    一项关于算法挑战和特别是自动图像分类和生成的挑战以为AI理解的形式呈现，挑战AI从书面描述中产生类似作品。本文旨在突显当前人工智能方法的优势和不足，粗略地描绘前进的道路。提出一种广义符号嵌入和（不仅仅是）基于某种身体基础的缺乏责任当前不足。其随之而来的概念的分层组织的匮乏。作为这些缺点的补救方案，建议退一步，并重新融合控制论和模拟控制过程的方面。声称奥洛博罗斯模型提供了一个有前途的全局视角， 具有统一的认知算法支柱

    arXiv:2403.04292v1 Announce Type: new  Abstract: A topical challenge for algorithms in general and for automatic image categorization and generation in particular is presented in the form of a drawing for AI to understand. In a second vein, AI is challenged to produce something similar from verbal description. The aim of the paper is to highlight strengths and deficiencies of current Artificial Intelligence approaches while coarsely sketching a way forward. A general lack of encompassing symbol-embedding and (not only) -grounding in some bodily basis is made responsible for current deficiencies. A concomitant dearth of hierarchical organization of concepts follows suite. As a remedy for these shortcomings, it is proposed to take a wide step back and to newly incorporate aspects of cybernetics and analog control processes. It is claimed that a promising overarching perspective is provided by the Ouroboros Model with a valid and versatile algorithmic backbone for general cognition at all
    
[^57]: Proxy-RLHF：在大型语言模型中通过代理解耦生成和对齐

    Proxy-RLHF: Decoupling Generation and Alignment in Large Language Model with Proxy

    [https://arxiv.org/abs/2403.04283](https://arxiv.org/abs/2403.04283)

    该论文提出Proxy-RLHF方法，通过将大型语言模型的生成和对齐过程解耦，实现了以更低计算成本对齐人类价值观，仅使用其他方法的1%训练参数即可达到可比水平的对齐度。

    

    强化学习从人类反馈中学习（RLHF）是确保大型语言模型（LLMs）与人类价值观保持一致的主流方法。然而，现有的RLHF方法需要高昂的计算成本，主要原因之一是RLHF同时将生成和对齐任务分配给LLM。本文介绍了Proxy-RLHF，它解耦了LLMs的生成和对齐流程，以更低的计算成本实现与人类价值的对齐。我们从为对齐过程设计的新型马尔可夫决策过程（MDP）开始，并使用强化学习（RL）训练了一个简化的代理模型，监督LLM的标记生成，而不改变LLM本身。实验证明，我们的方法仅使用其他方法的1%训练参数即可实现可比水平的对齐度。

    arXiv:2403.04283v1 Announce Type: cross  Abstract: Reinforcement Learning from Human Feedback (RLHF) is the prevailing approach to ensure Large Language Models (LLMs) align with human values. However, existing RLHF methods require a high computational cost, one main reason being that RLHF assigns both the generation and alignment tasks to the LLM simultaneously. In this paper, we introduce Proxy-RLHF, which decouples the generation and alignment processes of LLMs, achieving alignment with human values at a much lower computational cost. We start with a novel Markov Decision Process (MDP) designed for the alignment process and employ Reinforcement Learning (RL) to train a streamlined proxy model that oversees the token generation of the LLM, without altering the LLM itself. Experiments show that our method achieves a comparable level of alignment with only 1\% of the training parameters of other methods.
    
[^58]: 用于评估阿拉伯呼叫领域自动语音识别的新基准

    A New Benchmark for Evaluating Automatic Speech Recognition in the Arabic Call Domain

    [https://arxiv.org/abs/2403.04280](https://arxiv.org/abs/2403.04280)

    该研究引入了一个针对阿拉伯电话对话领域挑战的全面评估基准，旨在为开发和评估能够适应真实电话通讯条件的ASR系统提供一个严格的测试平台。

    

    这项工作旨在引入一个全面的用于阿拉伯语音识别评估的基准，专门针对阿拉伯语电话对话中的挑战进行了定制。阿拉伯语以其丰富的方言多样性和语音复杂性而闻名，对自动语音识别（ASR）系统提出了许多独特的挑战。这些挑战在电话通话领域进一步放大，那里的音频质量、背景噪音和会话式语音风格会对识别准确性产生负面影响。我们的工作旨在建立一个稳健的基准，不仅包含广泛的阿拉伯方言范围，还模拟呼叫通讯的真实条件。通过结合多样的方言表达，并考虑呼叫录音的可变质量，这个基准旨在为开发和评估能够应对实际挑战的ASR系统提供严格的测试平台。

    arXiv:2403.04280v1 Announce Type: new  Abstract: This work is an attempt to introduce a comprehensive benchmark for Arabic speech recognition, specifically tailored to address the challenges of telephone conversations in Arabic language. Arabic, characterized by its rich dialectal diversity and phonetic complexity, presents a number of unique challenges for automatic speech recognition (ASR) systems. These challenges are further amplified in the domain of telephone calls, where audio quality, background noise, and conversational speech styles negatively affect recognition accuracy. Our work aims to establish a robust benchmark that not only encompasses the broad spectrum of Arabic dialects but also emulates the real-world conditions of call-based communications. By incorporating diverse dialectical expressions and accounting for the variable quality of call recordings, this benchmark seeks to provide a rigorous testing ground for the development and evaluation of ASR systems capable of
    
[^59]: 在随机效用和路径约束下的竞争设施选址问题

    Competitive Facility Location under Random Utilities and Routing Constraints

    [https://arxiv.org/abs/2403.04264](https://arxiv.org/abs/2403.04264)

    本文研究了在竞争市场背景下的设施选址问题，引入了路径约束，探讨了三种有效割以处理非线性目标函数。

    

    本文研究了在竞争市场背景下的设施选址问题，其中顾客需求由随机效用选择模型预测。与以往主要关注简单约束（例如所选位置数量的基数约束）的研究不同，我们引入了路径约束，这些约束需要以一种方式选择位置，以保证存在访问所有选择位置的旅程，同时遵守指定的旅程长度上限。这种路径约束在各种现实场景中具有关键应用。所涉问题具有非线性目标函数，这是由于采用了随机效用，并且具有复杂的路径约束，使其在计算上具有挑战性。为了解决这个问题，我们探讨了三种有效割，即外估计和子模割，以处理非线性目标函数，以及

    arXiv:2403.04264v1 Announce Type: new  Abstract: In this paper, we study a facility location problem within a competitive market context, where customer demand is predicted by a random utility choice model. Unlike prior research, which primarily focuses on simple constraints such as a cardinality constraint on the number of selected locations, we introduce routing constraints that necessitate the selection of locations in a manner that guarantees the existence of a tour visiting all chosen locations while adhering to a specified tour length upper bound. Such routing constraints find crucial applications in various real-world scenarios. The problem at hand features a non-linear objective function, resulting from the utilization of random utilities, together with complex routing constraints, making it computationally challenging. To tackle this problem, we explore three types of valid cuts, namely, outer-approximation and submodular cuts to handle the nonlinear objective function, as wel
    
[^60]: 通过社区挑战推动生物医学文本挖掘的发展

    Advancing Biomedical Text Mining with Community Challenges

    [https://arxiv.org/abs/2403.04261](https://arxiv.org/abs/2403.04261)

    社区挑战评估竞赛在促进生物医学文本挖掘研究中的技术创新和跨学科合作方面起着重要作用。

    

    生物医学研究领域积累了大量来自科学文献、电子病历、临床试验报告和社交媒体等各方面的文本数据，然而手动处理和分析这些庞大且复杂的资源是耗时且低效的。为了解决这一挑战，生物医学文本挖掘，也称为生物医学自然语言处理，备受关注。社区挑战评估竞赛在促进生物医学文本挖掘研究中的技术创新和跨学科合作方面发挥了重要作用。这些挑战为研究人员提供了开发生物医学研究中数据挖掘和信息处理的最新解决方案的平台。在本文中，我们回顾了与中文生物医学文本挖掘有关的最新社区挑战的进展。

    arXiv:2403.04261v1 Announce Type: new  Abstract: The field of biomedical research has witnessed a significant increase in the accumulation of vast amounts of textual data from various sources such as scientific literatures, electronic health records, clinical trial reports, and social media. However, manually processing and analyzing these extensive and complex resources is time-consuming and inefficient. To address this challenge, biomedical text mining, also known as biomedical natural language processing, has garnered great attention. Community challenge evaluation competitions have played an important role in promoting technology innovation and interdisciplinary collaboration in biomedical text mining research. These challenges provide platforms for researchers to develop state-of-the-art solutions for data mining and information processing in biomedical research. In this article, we review the recent advances in community challenges specific to Chinese biomedical text mining. Firs
    
[^61]: 基于混合检索增强生成的联邦推荐

    Federated Recommendation via Hybrid Retrieval Augmented Generation

    [https://arxiv.org/abs/2403.04256](https://arxiv.org/abs/2403.04256)

    提出了一个名为GPT-FedRec的联邦推荐框架，利用ChatGPT和一种新颖的混合检索增强生成（RAG）机制，解决了传统FR系统在数据稀疏性和异构性方面的性能下降问题，弥补了基于LLM的推荐器在实际场景中推理效率低和潜在幻觉等挑战，实现了隐私保护推荐的目标

    

    联邦推荐（FR）是一种新兴范式，能够实现隐私保护推荐。然而，传统的FR系统通常使用离散的身份（ID）表示用户/物品，在FR中由于数据稀疏性和异构性而导致性能下降。另一方面，大型语言模型（LLMs）作为推荐器已经在各种推荐场景中被证明有效。然而，基于LLM的推荐器面临诸如推理效率低和潜在幻觉等挑战，从而影响它们在实际场景中的表现。为此，我们提出了一个名为GPT-FedRec的联邦推荐框架，利用ChatGPT和一种新颖的混合检索增强生成（RAG）机制。GPT-FedRec是一个两阶段的解决方案。第一阶段是一个混合检索过程，挖掘基于ID的用户模式和基于文本的商品特征。接下来，所检索到的结果被转换为文本提示

    arXiv:2403.04256v1 Announce Type: cross  Abstract: Federated Recommendation (FR) emerges as a novel paradigm that enables privacy-preserving recommendations. However, traditional FR systems usually represent users/items with discrete identities (IDs), suffering from performance degradation due to the data sparsity and heterogeneity in FR. On the other hand, Large Language Models (LLMs) as recommenders have proven effective across various recommendation scenarios. Yet, LLM-based recommenders encounter challenges such as low inference efficiency and potential hallucination, compromising their performance in real-world scenarios. To this end, we propose GPT-FedRec, a federated recommendation framework leveraging ChatGPT and a novel hybrid Retrieval Augmented Generation (RAG) mechanism. GPT-FedRec is a two-stage solution. The first stage is a hybrid retrieval process, mining ID-based user patterns and text-based item features. Next, the retrieved results are converted into text prompts and
    
[^62]: 基于CNN-LSTM的Levy驱动随机微分方程参数估计的高效性研究

    Efficient CNN-LSTM based Parameter Estimation of Levy Driven Stochastic Differential Equations

    [https://arxiv.org/abs/2403.04246](https://arxiv.org/abs/2403.04246)

    本研究提出了一种新颖的CNN-LSTM三阶段模型PEnet，通过CNN对数据特征进行浓缩，提供了一种端到端方法，具有高准确性和适应性，以及长序列观测的增强推断速度和高泛化能力，从而在估计SDE方面取得了显著优势。

    

    本研究解决了由非高斯噪声驱动的随机微分方程参数估计中的挑战，这对于理解价格波动和传染病传播等动态现象至关重要。先前的研究强调了LSTM网络在估计alpha稳定Levy驱动的SDE参数方面的潜力，但面临高时间复杂度和LSTM链接属性的限制。为了缓解这些问题，我们引入了PEnet，这是一种基于CNN-LSTM的三阶段模型，提供了一种端到端方法，具有优越的准确性和适应不同数据结构的能力，通过CNN对初始数据特征进行浓缩，为长序列观测提供增强的推断速度，并具有高泛化能力，允许其应用于各种复杂的SDE场景。对合成数据集的实验验证了PEnet在估计SDE中的显著优势。

    arXiv:2403.04246v1 Announce Type: cross  Abstract: This study addresses the challenges in parameter estimation of stochastic differential equations driven by non-Gaussian noises, which are critical in understanding dynamic phenomena such as price fluctuations and the spread of infectious diseases. Previous research highlighted the potential of LSTM networks in estimating parameters of alpha stable Levy driven SDEs but faced limitations including high time complexity and constraints of the LSTM chaining property. To mitigate these issues, we introduce the PEnet, a novel CNN-LSTM-based three-stage model that offers an end to end approach with superior accuracy and adaptability to varying data structures, enhanced inference speed for long sequence observations through initial data feature condensation by CNN, and high generalization capability, allowing its application to various complex SDE scenarios. Experiments on synthetic datasets confirm PEnet significant advantage in estimating SDE
    
[^63]: DEEP-ICL: 定义丰富的专家用于语言模型上下文学习

    DEEP-ICL: Definition-Enriched Experts for Language Model In-Context Learning

    [https://arxiv.org/abs/2403.04233](https://arxiv.org/abs/2403.04233)

    DEEP-ICL 提出了一种新颖的任务定义丰富的专家集成方法，通过从示范中提取任务定义并学习任务特定示例，实现了在上下文学习方面具有可比性的性能，突破了传统上下文学习的限制。

    

    长期以来，人们一直认为大型语言模型（LLMs）中的参数数量驱动了上下文学习（ICL）能力，通过利用任务特定的示范实现了显著的性能提升。挑战这一假设，我们引入了DEEP-ICL，这是一种新颖的任务定义丰富的专家集成方法，用于ICL。 DEEP-ICL从给定的示范中明确提取任务定义，并通过学习任务特定示例生成响应。我们认为，ICL的改进并不直接依赖于模型大小，而基本上源自于理解任务定义和任务引导学习。受到这一启发，DEEP-ICL结合了两个具有不同角色的3B模型（一个用于总结任务定义，另一个用于学习任务示范），并实现了与LLaMA2-13B可比较的性能。此外，我们的框架通过克服预训练序列长度，优于传统ICL。

    arXiv:2403.04233v1 Announce Type: cross  Abstract: It has long been assumed that the sheer number of parameters in large language models (LLMs) drives in-context learning (ICL) capabilities, enabling remarkable performance improvements by leveraging task-specific demonstrations. Challenging this hypothesis, we introduce DEEP-ICL, a novel task Definition Enriched ExPert Ensembling methodology for ICL. DEEP-ICL explicitly extracts task definitions from given demonstrations and generates responses through learning task-specific examples. We argue that improvement from ICL does not directly rely on model size, but essentially stems from understanding task definitions and task-guided learning. Inspired by this, DEEP-ICL combines two 3B models with distinct roles (one for concluding task definitions and the other for learning task demonstrations) and achieves comparable performance to LLaMA2-13B. Furthermore, our framework outperforms conventional ICL by overcoming pretraining sequence lengt
    
[^64]: 通过多残差任务学习实现协同生态驾驶的泛化

    Generalizing Cooperative Eco-driving via Multi-residual Task Learning

    [https://arxiv.org/abs/2403.04232](https://arxiv.org/abs/2403.04232)

    介绍了基于多残差任务学习的泛化协同生态驾驶方法，通过分解控制并运用学习来解决多个交通场景的挑战

    

    传统控制，如基于模型的控制，在自动驾驶中通常被使用，因为其效率和可靠性。然而，现实世界中的自动驾驶要应对各种具有挑战性的不同交通场景，这对这些规划算法是具有挑战性的。基于模型无关的深度强化学习（DRL）在这方面提供了一个有前景的途径，但学习DRL控制策略以泛化到多个交通场景仍然是一个挑战。为了解决这个问题，我们引入了一种名为多残差任务学习（MRTL）的通用学习框架，它是基于多任务学习的，针对一组任务场景，将控制分解为有效由传统控制方法解决的名义分量和由学习解决的残差项。我们使用MRTL来在混合交通中通过使用自动驾驶车辆来实现车队级别的排放减少作为系统控制手段。通过分析MR性能

    arXiv:2403.04232v1 Announce Type: cross  Abstract: Conventional control, such as model-based control, is commonly utilized in autonomous driving due to its efficiency and reliability. However, real-world autonomous driving contends with a multitude of diverse traffic scenarios that are challenging for these planning algorithms. Model-free Deep Reinforcement Learning (DRL) presents a promising avenue in this direction, but learning DRL control policies that generalize to multiple traffic scenarios is still a challenge. To address this, we introduce Multi-residual Task Learning (MRTL), a generic learning framework based on multi-task learning that, for a set of task scenarios, decomposes the control into nominal components that are effectively solved by conventional control methods and residual terms which are solved using learning. We employ MRTL for fleet-level emission reduction in mixed traffic using autonomous vehicles as a means of system control. By analyzing the performance of MR
    
[^65]: Aligners: 解耦LLMs和对齐

    Aligners: Decoupling LLMs and Alignment

    [https://arxiv.org/abs/2403.04224](https://arxiv.org/abs/2403.04224)

    提出了一种通过训练对齐器模型来解耦大型语言模型（LLMs）和对齐，以减少对齐对性能的潜在负面影响。

    

    大型语言模型（LLMs）需要与人类期望对齐，以确保它们在大多数应用中的安全性和实用性。对齐具有挑战性，成本高昂，并且需要为每个LLM和对齐标准重复进行。我们建议通过训练可以根据需要用于对齐给定标准的任何LLM的对齐模型来解耦LLMs和对齐，从而在一定程度上减少对性能的潜在负面影响。我们提出的对齐模型训练配方仅依赖于使用（提示的）LLM 生成的合成数据，并且可以轻松调整以适应各种对齐标准。我们通过训练一个“道德”对齐器并在实验上验证其有效性来阐明我们的方法。

    arXiv:2403.04224v1 Announce Type: cross  Abstract: Large Language Models (LLMs) need to be aligned with human expectations to ensure their safety and utility in most applications. Alignment is challenging, costly, and needs to be repeated for every LLM and alignment criterion. We propose to decouple LLMs and alignment by training aligner models that can be used to align any LLM for a given criteria on an as-needed basis, thus also reducing the potential negative impacts of alignment on performance. Our recipe for training the aligner models solely relies on synthetic data generated with a (prompted) LLM and can be easily adjusted for a variety of alignment criteria. We illustrate our method by training an "ethical" aligner and verify its efficacy empirically.
    
[^66]: 在线强化学习为何具有因果性

    Why Online Reinforcement Learning is Causal

    [https://arxiv.org/abs/2403.04221](https://arxiv.org/abs/2403.04221)

    强化学习和因果建模相互补充，论文主要指出在线学习环境下，条件概率具有因果性，离线RL是因果学习潜力最大的环境。

    

    强化学习（RL）和因果建模自然互补。因果建模的目标是预测在环境中进行干预的效果，而强化学习的目标是选择最大化代理从环境中接收的奖励的干预。强化学习包括用于估计因果关系的两个最强大信息源：时间顺序和对环境进行操作的能力。本文研究了我们可以期望在哪些强化学习设置中从因果建模中受益，以及如何受益。在线学习中，代理有能力直接与环境进行交互，并从探索中学习。我们的主要论点是，在在线学习中，条件概率是因果的，因此离线RL是因果学习有潜力产生差异的环境。基本上，原因在于当代理与环境互动时，代理的行为是由其对环境的认识所推动的。

    arXiv:2403.04221v1 Announce Type: cross  Abstract: Reinforcement learning (RL) and causal modelling naturally complement each other. The goal of causal modelling is to predict the effects of interventions in an environment, while the goal of reinforcement learning is to select interventions that maximize the rewards the agent receives from the environment. Reinforcement learning includes the two most powerful sources of information for estimating causal relationships: temporal ordering and the ability to act on an environment. This paper examines which reinforcement learning settings we can expect to benefit from causal modelling, and how. In online learning, the agent has the ability to interact directly with their environment, and learn from exploring it. Our main argument is that in online learning, conditional probabilities are causal, and therefore offline RL is the setting where causal learning has the most potential to make a difference. Essentially, the reason is that when an a
    
[^67]: 对于大型模型对齐方法的探究：本质与前景

    On the Essence and Prospect: An Investigation of Alignment Approaches for Big Models

    [https://arxiv.org/abs/2403.04204](https://arxiv.org/abs/2403.04204)

    调查了大型模型价值对齐方法，揭示历史背景和数学本质，详细讨论了强化学习、监督微调和上下文学习等对齐方法。

    

    大型模型在人工智能领域取得了革命性突破，但也可能带来潜在的问题。为解决这些问题，引入了对齐技术，使这些模型符合人类的偏好和价值观。尽管在过去一年取得了相当大的进展，但建立最佳对齐策略仍面临诸多挑战，如数据成本和可扩展性监督。如何进行对齐仍然是一个开放的问题。在这篇调查论文中，我们全面调查了价值对齐方法。我们首先揭示了对齐的历史背景，追溯到20世纪20年代（它的起源），然后深入探讨了对齐的数学本质（它是什么），阐明了其中固有的挑战。在奠定了这个基础后，我们对现有的对齐方法进行了详细考察，这些方法可以分为三类：强化学习、监督微调和上下文学习。

    arXiv:2403.04204v1 Announce Type: new  Abstract: Big models have achieved revolutionary breakthroughs in the field of AI, but they might also pose potential concerns. Addressing such concerns, alignment technologies were introduced to make these models conform to human preferences and values. Despite considerable advancements in the past year, various challenges lie in establishing the optimal alignment strategy, such as data cost and scalable oversight, and how to align remains an open question. In this survey paper, we comprehensively investigate value alignment approaches. We first unpack the historical context of alignment tracing back to the 1920s (where it comes from), then delve into the mathematical essence of alignment (what it is), shedding light on the inherent challenges. Following this foundation, we provide a detailed examination of existing alignment methods, which fall into three categories: Reinforcement Learning, Supervised Fine-Tuning, and In-context Learning, and de
    
[^68]: 异质学习代理群体中道德行为动态

    Dynamics of Moral Behavior in Heterogeneous Populations of Learning Agents

    [https://arxiv.org/abs/2403.04202](https://arxiv.org/abs/2403.04202)

    在多代理环境中，研究人员探讨了不同道德类型的学习代理之间的互动，发现道德异质性可能对代理的共同发展产生影响。

    

    arXiv:2403.04202v1 公告类型：交叉领域 摘要：日益关注AI系统安全和对齐性的问题突显了在人工代理中嵌入道德能力的重要性。一种有前途的解决方案是利用经验学习，即强化学习。在多代理（社会）环境中，个体学习代理之间的交互可能产生复杂的群体层面现象。许多现有研究依赖于模拟的社会困境环境来研究独立学习代理的互动。然而，它们往往忽视了实践中代理社会中可能存在的道德异质性。例如，在不同时间点，单个学习代理可能面对后果主义者（即关心随时间最大化某种结果）或基于规范的对手（即专注于立即遵守特定规范） 。代理的共同发展在多大程度上可能受到这种道德异质性的影响。

    arXiv:2403.04202v1 Announce Type: cross  Abstract: Growing concerns about safety and alignment of AI systems highlight the importance of embedding moral capabilities in artificial agents. A promising solution is the use of learning from experience, i.e., Reinforcement Learning. In multi-agent (social) environments, complex population-level phenomena may emerge from interactions between individual learning agents. Many of the existing studies rely on simulated social dilemma environments to study the interactions of independent learning agents. However, they tend to ignore the moral heterogeneity that is likely to be present in societies of agents in practice. For example, at different points in time a single learning agent may face opponents who are consequentialist (i.e., caring about maximizing some outcome over time) or norm-based (i.e., focusing on conforming to a specific norm here and now). The extent to which agents' co-development may be impacted by such moral heterogeneity in 
    
[^69]: 大规模语言模型是上下文分子学习器

    Large Language Models are In-Context Molecule Learners

    [https://arxiv.org/abs/2403.04197](https://arxiv.org/abs/2403.04197)

    提出了上下文分子适应（ICMA）范式，允许LLMs通过上下文示例学习分子-文本对齐，解决了在分子-标题翻译任务中对LLMs的挑战。

    

    大型语言模型（LLMs）在生物化学任务中表现出色，尤其是分子标题翻译任务，旨在弥合分子和自然语言文本之间的差距。然而，先前在适应LLMs到分子-标题翻译任务中的方法需要额外的领域特定预训练阶段，存在分子和文本空间之间的弱对齐，或对LLMs的规模有严格要求。为了解决这些挑战，我们提出了上下文分子适应（ICMA），作为一种新的范例，允许LLMs通过上下文示例学习分子-文本对齐，通过上下文分子调整。具体而言，ICMA包括以下三个阶段：跨模态检索、检索后排序和上下文分子调整。

    arXiv:2403.04197v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have demonstrated exceptional performance in biochemical tasks, especially the molecule caption translation task, which aims to bridge the gap between molecules and natural language texts. However, previous methods in adapting LLMs to the molecule-caption translation task required extra domain-specific pre-training stages, suffered weak alignment between molecular and textual spaces, or imposed stringent demands on the scale of LLMs. To resolve the challenges, we propose In-Context Molecule Adaptation (ICMA), as a new paradigm allowing LLMs to learn the molecule-text alignment from context examples via In-Context Molecule Tuning. Specifically, ICMA incorporates the following three stages: Cross-modal Retrieval, Post-retrieval Re-ranking, and In-context Molecule Tuning. Initially, Cross-modal Retrieval utilizes BM25 Caption Retrieval and Molecule Graph Retrieval to retrieve informative context examples. Addi
    
[^70]: 生成式人工智能用于合成数据生成：方法、挑战和未来展望

    Generative AI for Synthetic Data Generation: Methods, Challenges and the Future

    [https://arxiv.org/abs/2403.04190](https://arxiv.org/abs/2403.04190)

    这里是中文总结出的一句话要点

    

    最近，关于从大型语言模型（LLMs）生成合成数据的研究急剧增加，特别是针对数据有限的情况，标志着生成式人工智能（AI）领域的一个显著转变。它们能够表现出与真实世界数据相媲美的能力，将这种方法定位为解决低资源挑战的一个引人注目的解决方案。本文深入探讨了利用这些庞大的LLMs生成特定任务训练数据的先进技术。我们概述了方法论、评估技术和实际应用，讨论了当前的局限性，并提出了未来研究的潜在途径。

    arXiv:2403.04190v1 Announce Type: cross  Abstract: The recent surge in research focused on generating synthetic data from large language models (LLMs), especially for scenarios with limited data availability, marks a notable shift in Generative Artificial Intelligence (AI). Their ability to perform comparably to real-world data positions this approach as a compelling solution to low-resource challenges. This paper delves into advanced technologies that leverage these gigantic LLMs for the generation of task-specific training data. We outline methodologies, evaluation techniques, and practical applications, discuss the current limitations, and suggest potential pathways for future research.
    
[^71]: 蛋白语言模型的偏好优化作为多目标结合设计范式

    Preference optimization of protein language models as a multi-objective binder design paradigm

    [https://arxiv.org/abs/2403.04187](https://arxiv.org/abs/2403.04187)

    该论文提出了一种基于蛋白质语言模型的多目标结合设计方法，通过偏好优化可以有效优化生成的结合物样本的等电点，从而提高其结合效果。

    

    我们提出了一种基于指令微调和直接偏好优化(DPO)的自回归蛋白质语言模型（pLMs）的多目标结合设计范式。通过直接优化专家筛选的偏好序列数据集，将多个设计目标编码到语言模型中，包括优选和非首选分布。我们展示了所提出的对齐策略使ProtGPT2能够有效设计以指定受体和药物可开发性标准为条件的结合物。生成的结合物样本表明等电点（pI）中位数提高了$17\%-60\%$。

    arXiv:2403.04187v1 Announce Type: cross  Abstract: We present a multi-objective binder design paradigm based on instruction fine-tuning and direct preference optimization (DPO) of autoregressive protein language models (pLMs). Multiple design objectives are encoded in the language model through direct optimization on expert curated preference sequence datasets comprising preferred and dispreferred distributions. We show the proposed alignment strategy enables ProtGPT2 to effectively design binders conditioned on specified receptors and a drug developability criterion. Generated binder samples demonstrate median isoelectric point (pI) improvements by $17\%-60\%$.
    
[^72]: 度量感知的LLM推断

    Metric-aware LLM inference

    [https://arxiv.org/abs/2403.04182](https://arxiv.org/abs/2403.04182)

    提出了度量感知的LLM推断方法，通过优化自定义指标来改进推断性能

    

    大型语言模型（LLMs）已经在各种NLP任务中展示出强大的结果。通常，输出是通过从LLM的基础分布中进行自回归采样获得的。我们表明，这种推断策略对于一系列任务和相关的评估指标可能是次优的。为此，我们提出了度量感知的LLM推断：一种在推断时针对自定义指标进行优化的决策理论方法。我们在学术基准数据集和公开可用模型上报告了相对基线的改进。

    arXiv:2403.04182v1 Announce Type: cross  Abstract: Large language models (LLMs) have demonstrated strong results on a range of NLP tasks. Typically, outputs are obtained via autoregressive sampling from the LLM's underlying distribution. We show that this inference strategy can be suboptimal for a range of tasks and associated evaluation metrics. As a remedy, we propose metric aware LLM inference: a decision theoretic approach optimizing for custom metrics at inference time. We report improvements over baselines on academic benchmarks and publicly available models.
    
[^73]: 通过变压器模型中的注意机制理解联合放射治疗和免疫治疗中的PULSAR效应

    Understanding the PULSAR Effect in Combined Radiotherapy and Immunotherapy through Attention Mechanisms with a Transformer Model

    [https://arxiv.org/abs/2403.04175](https://arxiv.org/abs/2403.04175)

    首次在放射治疗和免疫治疗相结合的研究中使用了变压器模型的注意机制，能够半定量预测肿瘤体积变化趋势，并通过自注意力和交叉注意力得分来识别潜在因果关系。

    

    PULSAR（个性化、超分形成立体适应性放射治疗）是将立体定位消融放射治疗应用于个性化癌症管理的方法。我们首次应用基于变压器的注意机制来研究联合PULSAR和PD-L1阻断免疫疗法之间的相互作用，基于小鼠癌症模型（Lewis肺癌，LLC）。提出的方法能够半定量地预测肿瘤体积变化的趋势，并通过自注意力和交叉注意力得分在识别潜在因果关系方面表现出色。

    arXiv:2403.04175v1 Announce Type: cross  Abstract: PULSAR (personalized, ultra-fractionated stereotactic adaptive radiotherapy) is the adaptation of stereotactic ablative radiotherapy towards personalized cancer management. For the first time, we applied a transformer-based attention mechanism to investigate the underlying interactions between combined PULSAR and PD-L1 blockade immunotherapy based on a murine cancer model (Lewis Lung Carcinoma, LLC). The proposed approach is able to predict the trend of tumor volume change semi-quantitatively, and excels in identifying the potential causal relationships through both self-attention and cross-attention scores.
    
[^74]: ProMISe: 使用SAM进行可提示的医学图像分割

    ProMISe: Promptable Medical Image Segmentation using SAM

    [https://arxiv.org/abs/2403.04164](https://arxiv.org/abs/2403.04164)

    本文提出了一个自动提示模块（APM），为SAM基础模型提供了在目标领域中使用的自适应提示，显著提高了SAM在医学图像分割中的性能。

    

    随着提出了Segment Anything Model (SAM)的建议，对SAM进行医学图像分割(MIS)的微调变得流行起来。然而，由于SAM模型的规模较大，自然图像和医学图像之间存在显著的领域差距，基于微调的策略成本高，存在不稳定性、特征损伤和灾难性遗忘的潜在风险。此外，一些通过微调策略将SAM转移到特定领域MIS的方法禁用了模型的提示能力，严重限制了其使用场景。在本文中，我们提出了一个自动提示模块（APM），为SAM基础模型在目标域中提供了具有欧几里德自适应提示的基础。我们的实验证明，这样的自适应提示显著提高了SAM在MIS中非微调的性能。此外，我们提出了一种名为增量模式移位（IPS）的新型非侵入式方法，用于将SAM调整到特定医疗领域。

    arXiv:2403.04164v1 Announce Type: cross  Abstract: With the proposal of the Segment Anything Model (SAM), fine-tuning SAM for medical image segmentation (MIS) has become popular. However, due to the large size of the SAM model and the significant domain gap between natural and medical images, fine-tuning-based strategies are costly with potential risk of instability, feature damage and catastrophic forgetting. Furthermore, some methods of transferring SAM to a domain-specific MIS through fine-tuning strategies disable the model's prompting capability, severely limiting its utilization scenarios. In this paper, we propose an Auto-Prompting Module (APM), which provides SAM-based foundation model with Euclidean adaptive prompts in the target domain. Our experiments demonstrate that such adaptive prompts significantly improve SAM's non-fine-tuned performance in MIS. In addition, we propose a novel non-invasive method called Incremental Pattern Shifting (IPS) to adapt SAM to specific medica
    
[^75]: 利用语料库主题分类改进主题特定应用中的检索

    Improving Retrieval in Theme-specific Applications using a Corpus Topical Taxonomy

    [https://arxiv.org/abs/2403.04160](https://arxiv.org/abs/2403.04160)

    提出了一种利用语料库主题分类改进主题特定应用中检索的框架，通过确定查询和文档的中心主题以及利用主题相关性来补充缺失的上下文。

    

    文献检索已经从大规模预训练语言模型（PLM）的进步中受益良多。然而，它们的有效性在专门领域或行业的主题特定应用中通常受到限制，这是由于独特术语、用户查询的不完整上下文和专门搜索意图导致的。为了捕捉主题特定信息并改进检索，我们提出使用语料库主题分类，该分类概述了语料库的潜在主题结构，同时反映了用户感兴趣的方面。我们介绍了ToTER（增强型主题分类检索）框架，该框架借助分类的指导确定查询和文档的中心主题，并利用它们的主题相关性补充缺失的上下文。作为一种即插即用的框架，ToTER可灵活应用于增强各种基于PLM的检索器。通过对两个案例进行广泛的定量、缺失和探索性实验，我们评估了ToTER框架的性能。

    arXiv:2403.04160v1 Announce Type: cross  Abstract: Document retrieval has greatly benefited from the advancements of large-scale pre-trained language models (PLMs). However, their effectiveness is often limited in theme-specific applications for specialized areas or industries, due to unique terminologies, incomplete contexts of user queries, and specialized search intents. To capture the theme-specific information and improve retrieval, we propose to use a corpus topical taxonomy, which outlines the latent topic structure of the corpus while reflecting user-interested aspects. We introduce ToTER (Topical Taxonomy Enhanced Retrieval) framework, which identifies the central topics of queries and documents with the guidance of the taxonomy, and exploits their topical relatedness to supplement missing contexts. As a plug-and-play framework, ToTER can be flexibly employed to enhance various PLM-based retrievers. Through extensive quantitative, ablative, and exploratory experiments on two r
    
[^76]: DA-Net: 一种用于多源跨语言迁移学习的解耦自适应网络

    DA-Net: A Disentangled and Adaptive Network for Multi-Source Cross-Lingual Transfer Learning

    [https://arxiv.org/abs/2403.04158](https://arxiv.org/abs/2403.04158)

    DA-Net 提出了一种解决多源跨语言迁移学习中共享编码器导致学习困扰和语言特定分类器性能下降的新方法。

    

    多源跨语言迁移学习涉及从多个已标记源语言向一个未标记目标语言在语言转移下的任务知识传输。现有方法通常关注于加权不同源语言的特定语言分类器生成的预测，这些分类器遵循共享编码器。然而，所有源语言共享相同的编码器，这个编码器被所有这些语言更新。提取出的表示不可避免地包含不同源语言的信息，这可能干扰语言特定分类器的学习。此外，由于语言差距，使用源标签训练的语言特定分类器无法准确预测目标语言。这两个事实损害了模型的性能。为了解决这些挑战，我们提出了一种解耦自适应网络 (DA-Net)。

    arXiv:2403.04158v1 Announce Type: cross  Abstract: Multi-Source cross-lingual transfer learning deals with the transfer of task knowledge from multiple labelled source languages to an unlabeled target language under the language shift. Existing methods typically focus on weighting the predictions produced by language-specific classifiers of different sources that follow a shared encoder. However, all source languages share the same encoder, which is updated by all these languages. The extracted representations inevitably contain different source languages' information, which may disturb the learning of the language-specific classifiers. Additionally, due to the language gap, language-specific classifiers trained with source labels are unable to make accurate predictions for the target language. Both facts impair the model's performance. To address these challenges, we propose a Disentangled and Adaptive Network (DA-Net). Firstly, we devise a feedback-guided collaborative disentanglemen
    
[^77]: FL-GUARD: 一个用于负面联邦学习运行时检测和恢复的全面框架

    FL-GUARD: A Holistic Framework for Run-Time Detection and Recovery of Negative Federated Learning

    [https://arxiv.org/abs/2403.04146](https://arxiv.org/abs/2403.04146)

    FL-GUARD提出了一个全面框架，用于在负面联邦学习情况下检测和恢复，解决了先前解决方案中的额外成本和浪费学习轮次的问题

    

    联邦学习（FL）是一种从分布在大量客户端上的数据中学习模型且不暴露数据隐私的有前途的方法。在理想的联邦学习中效果显著，其中客户端分享同质的数据分布和学习行为。然而，当联邦学习不理想时，FL可能无法正常运作，导致负面联邦学习（NFL）的不良状态。许多研究尝试解决NFL问题。然而，它们的解决方案要么（1）预先防止整个学习生命周期中的NFL，要么（2）在大量学习轮次之后解决NFL。因此，它们要么（1）在FL没有这些成本的情况下无差别增加额外成本，要么（2）浪费大量学习轮次。另外，先前的工作没有考虑可能不愿意/无法遵循提出的NFL解决方案的客户端。

    arXiv:2403.04146v1 Announce Type: cross  Abstract: Federated learning (FL) is a promising approach for learning a model from data distributed on massive clients without exposing data privacy. It works effectively in the ideal federation where clients share homogeneous data distribution and learning behavior. However, FL may fail to function appropriately when the federation is not ideal, amid an unhealthy state called Negative Federated Learning (NFL), in which most clients gain no benefit from participating in FL. Many studies have tried to address NFL. However, their solutions either (1) predetermine to prevent NFL in the entire learning life-cycle or (2) tackle NFL in the aftermath of numerous learning rounds. Thus, they either (1) indiscriminately incur extra costs even if FL can perform well without such costs or (2) waste numerous learning rounds. Additionally, none of the previous work takes into account the clients who may be unwilling/unable to follow the proposed NFL solution
    
[^78]: 少样本持续学习的对比增强图形到图形记忆交互

    Contrastive Augmented Graph2Graph Memory Interaction for Few Shot Continual Learning

    [https://arxiv.org/abs/2403.04140](https://arxiv.org/abs/2403.04140)

    提出了一种对比增强图形到图形记忆交互的方法，以解决少样本类增量学习中的灾难性遗忘问题

    

    少样本类增量学习（FSCIL）近年来引起了相当大的关注，因为它在解决持续到达的类别方面发挥着关键作用。然而，它面临着额外的挑战。新会话中样本的稀缺性加剧了过拟合，导致新旧类别的输出特征不兼容，从而加剧了灾难性遗忘。一种普遍的策略涉及通过显式记忆（EM）减轻灾难性遗忘，EM由类原型组成。然而，当前基于EM的方法通过对输入与EM中存储的原型对应的特征执行向量到向量（V2V）交互全局检索记忆，而忽略了本地特征的几何结构。这妨碍了准确建模它们的位置关系。为了将本地几何结构的信息融入其中，我们将V2V交互扩展到图形到图形（G2G）交互

    arXiv:2403.04140v1 Announce Type: new  Abstract: Few-Shot Class-Incremental Learning (FSCIL) has gained considerable attention in recent years for its pivotal role in addressing continuously arriving classes. However, it encounters additional challenges. The scarcity of samples in new sessions intensifies overfitting, causing incompatibility between the output features of new and old classes, thereby escalating catastrophic forgetting. A prevalent strategy involves mitigating catastrophic forgetting through the Explicit Memory (EM), which comprise of class prototypes. However, current EM-based methods retrieves memory globally by performing Vector-to-Vector (V2V) interaction between features corresponding to the input and prototypes stored in EM, neglecting the geometric structure of local features. This hinders the accurate modeling of their positional relationships. To incorporate information of local geometric structure, we extend the V2V interaction to Graph-to-Graph (G2G) interact
    
[^79]: 基于神经HSMM和代码质量模板的和声分析无监督学习

    Unsupervised Learning of Harmonic Analysis Based on Neural HSMM with Code Quality Templates

    [https://arxiv.org/abs/2403.04135](https://arxiv.org/abs/2403.04135)

    本文提出了一种基于神经HSMM的和声分析无监督学习方法，引入了和弦质量模板，并展示了不需要昂贵标记数据或规则阐述的优点。

    

    本文提出了一种基于隐藏半马尔可夫模型（HSMM）的无监督学习和声分析的方法。我们引入了和弦质量模板，指定了在给定根音和和弦质量的情况下音高类别发射的概率。组成HSMM的其他概率分布是通过无监督学习自动学习的，这在现有研究中是一个挑战。提出模型的和声分析结果是使用现有标记数据进行评估的。虽然我们提出的方法尚未像使用监督学习和复杂规则设计的现有模型表现得那么好，但它具有不需要昂贵标记数据或规则阐述的优点。此外，我们还展示了如何在没有先验知识的情况下，基于马尔可夫模型的转换概率来识别主音。

    arXiv:2403.04135v1 Announce Type: new  Abstract: This paper presents a method of unsupervised learning of harmonic analysis based on a hidden semi-Markov model (HSMM). We introduce the chord quality templates, which specify the probability of pitch class emissions given a root note and a chord quality. Other probability distributions that comprise the HSMM are automatically learned via unsupervised learning, which has been a challenge in existing research. The results of the harmonic analysis of the proposed model were evaluated using existing labeled data. While our proposed method has yet to perform as well as existing models that used supervised learning and complex rule design, it has the advantage of not requiring expensive labeled data or rule elaboration. Furthermore, we also show how to recognize the tonic without prior knowledge, based on the transition probabilities of the Markov model.
    
[^80]: Chatbot Arena：一个通过人类偏好评估LLM的开放平台

    Chatbot Arena: An Open Platform for Evaluating LLMs by Human Preference

    [https://arxiv.org/abs/2403.04132](https://arxiv.org/abs/2403.04132)

    Chatbot Arena是一个开放平台，采用两两比较的方式通过众包利用人类偏好评估LLMs。研究表明众包问题多样且具有区分性，并且人类投票与专家评级者的投票基本一致。

    

    大型语言模型（LLMs）解锁了新的能力和应用；然而，评估其与人类偏好的一致性仍然面临着重大挑战。为了解决这个问题，我们介绍了Chatbot Arena，这是一个基于人类偏好评估LLMs的开放平台。我们的方法采用了一种两两比较的方式，并通过众包利用来自不同用户群体的输入。该平台已经运营了几个月，获得了超过24万个投票。本文描述了该平台，分析了我们迄今收集的数据，并解释了我们正在使用的经过验证的统计方法，以便对模型进行高效准确的评估和排名。我们确认众包问题足够多样化和区分化，并且众包人类投票与专家评级者的投票基本一致。这些分析共同为平台的可信度奠定了坚实的基础。

    arXiv:2403.04132v1 Announce Type: new  Abstract: Large Language Models (LLMs) have unlocked new capabilities and applications; however, evaluating the alignment with human preferences still poses significant challenges. To address this issue, we introduce Chatbot Arena, an open platform for evaluating LLMs based on human preferences. Our methodology employs a pairwise comparison approach and leverages input from a diverse user base through crowdsourcing. The platform has been operational for several months, amassing over 240K votes. This paper describes the platform, analyzes the data we have collected so far, and explains the tried-and-true statistical methods we are using for efficient and accurate evaluation and ranking of models. We confirm that the crowdsourced questions are sufficiently diverse and discriminating and that the crowdsourced human votes are in good agreement with those of expert raters. These analyses collectively establish a robust foundation for the credibility of
    
[^81]: 通过平坦性实现对大型语言模型的隐私保护微调

    Privacy-preserving Fine-tuning of Large Language Models through Flatness

    [https://arxiv.org/abs/2403.04124](https://arxiv.org/abs/2403.04124)

    论文揭示了DP训练模型的损失景观的平坦性在隐私和泛化之间的权衡中起着关键作用，并提出了一种全面的框架，通过强制实施适当的权重平坦化来显著提高模型的泛化能力，同时保留竞争性的隐私保护。

    

    最近随着诸如ChatGPT之类的大型语言模型（LLMs）的发展，与使用LLMs相关的隐私问题日益增加。现有工作探索了使用差分隐私（DP）技术来减轻其隐私风险的方法，但以泛化降级为代价。我们的论文揭示了DP训练模型的损失景观的平坦性在它们的隐私和泛化之间的权衡中起着至关重要的作用。我们进一步提出了一个全面的框架来强制实施适当的权重平坦化，这大大提高了模型的泛化能力，并具有竞争性的隐私保护。它从三个粗到精的层次进行创新，包括对层内模型权重进行扰动感知的最小-最大优化、跨层权重进行平坦引导的稀疏前缀微调，以及在DP和非DP权重副本之间进行权重知识蒸馏。全面的黑盒和白盒场景实验。

    arXiv:2403.04124v1 Announce Type: new  Abstract: The privacy concerns associated with the use of Large Language Models (LLMs) have grown recently with the development of LLMs such as ChatGPT. Differential Privacy (DP) techniques are explored in existing work to mitigate their privacy risks at the cost of generalization degradation. Our paper reveals that the flatness of DP-trained models' loss landscape plays an essential role in the trade-off between their privacy and generalization. We further propose a holistic framework to enforce appropriate weight flatness, which substantially improves model generalization with competitive privacy preservation. It innovates from three coarse-to-grained levels, including perturbation-aware min-max optimization on model weights within a layer, flatness-guided sparse prefix-tuning on weights across layers, and weight knowledge distillation between DP \& non-DP weights copies. Comprehensive experiments of both black-box and white-box scenarios are co
    
[^82]: 大型语言模型能够进行推理和规划吗？

    Can Large Language Models Reason and Plan?

    [https://arxiv.org/abs/2403.04121](https://arxiv.org/abs/2403.04121)

    大型语言模型缺乏自我批评能力，无法像人类一样纠正错误。

    

    虽然人类有时候表现出能够通过自我批评纠正自己错误猜测的能力，但似乎在大型语言模型的情况下没有依据支持这一假设。

    arXiv:2403.04121v1 Announce Type: new  Abstract: While humans sometimes do show the capability of correcting their own erroneous guesses with self-critiquing, there seems to be no basis for that assumption in the case of LLMs.
    
[^83]: DNAct：扩散引导的多任务3D策略学习

    DNAct: Diffusion Guided Multi-Task 3D Policy Learning

    [https://arxiv.org/abs/2403.04115](https://arxiv.org/abs/2403.04115)

    本文提出了DNAct框架，结合神经渲染和扩散训练，实现在动作序列空间中的多模态学习，可应用于挑战性机器人任务，同时通过扩散过程实现多任务动作序列的重构。

    

    本文提出了DNAct，这是一个以语言为条件的多任务策略框架，它整合了神经渲染预训练和扩散训练，以在动作序列空间中实现多模态学习。DNAct的预训练阶段利用神经渲染从诸如Stable Diffusion之类的基础模型中提取2D语义特征到3D空间，从而提供了关于场景的全面语义理解。这使得可以应用于需要丰富的3D语义和准确几何的挑战性机器人任务。此外，我们介绍了一种利用扩散训练来学习包含多任务演示中固有多模态的视觉和语言特征的新方法。通过扩散过程从不同任务的动作序列重构，该模型能够区分。

    arXiv:2403.04115v1 Announce Type: cross  Abstract: This paper presents DNAct, a language-conditioned multi-task policy framework that integrates neural rendering pre-training and diffusion training to enforce multi-modality learning in action sequence spaces. To learn a generalizable multi-task policy with few demonstrations, the pre-training phase of DNAct leverages neural rendering to distill 2D semantic features from foundation models such as Stable Diffusion to a 3D space, which provides a comprehensive semantic understanding regarding the scene. Consequently, it allows various applications to challenging robotic tasks requiring rich 3D semantics and accurate geometry. Furthermore, we introduce a novel approach utilizing diffusion training to learn a vision and language feature that encapsulates the inherent multi-modality in the multi-task demonstrations. By reconstructing the action sequences from different tasks via the diffusion process, the model is capable of distinguishing d
    
[^84]: 在人工智能时代理解生物学

    Understanding Biology in the Age of Artificial Intelligence

    [https://arxiv.org/abs/2403.04106](https://arxiv.org/abs/2403.04106)

    人工智能在生物学科学研究中的广泛应用代表了传统方法的重大偏离，通过现代哲学理论和认识论原则指导，可以推动设计和应用ML系统来建模生物现象以促进科学知识的进步。

    

    现代生命科学研究越来越依赖于人工智能方法来建模生物系统，主要集中在使用机器学习（ML）模型。尽管ML无疑对于识别大规模、复杂数据集中的模式非常有用，但它在生物科学中的广泛应用代表了对科学探究传统方法的重大偏离。因此，这些模型与生物学科学理解之间的相互作用是一个具有重要未来科学研究意义的主题，然而这是一个鲜为人知的主题。在这里，我们从认识论工具包中汲取灵感，将最近在生物科学中应用ML的情况置于现代哲学理论的理解下来进行上下文化，确定可指导设计和应用ML系统来建模生物现象并推进科学知识的一般原则。

    arXiv:2403.04106v1 Announce Type: new  Abstract: Modern life sciences research is increasingly relying on artificial intelligence approaches to model biological systems, primarily centered around the use of machine learning (ML) models. Although ML is undeniably useful for identifying patterns in large, complex data sets, its widespread application in biological sciences represents a significant deviation from traditional methods of scientific inquiry. As such, the interplay between these models and scientific understanding in biology is a topic with important implications for the future of scientific research, yet it is a subject that has received little attention. Here, we draw from an epistemological toolkit to contextualize recent applications of ML in biological sciences under modern philosophical theories of understanding, identifying general principles that can guide the design and application of ML systems to model biological phenomena and advance scientific knowledge. We propo
    
[^85]: 人工智能探索专利领域

    Artificial Intelligence Exploring the Patent Field

    [https://arxiv.org/abs/2403.04105](https://arxiv.org/abs/2403.04105)

    本文系统概述了专利领域的任务和方法，强调了语言处理和大型语言模型的重要性，并探讨了近期出现的通用生成方法在专利领域的潜力。

    

    arXiv:2403.04105v1 公告类型：新的 摘要：先进的语言处理和机器学习技术承诺在以前广泛依赖手工操作的专利和技术知识管理领域带来巨大的效率改进。这个领域展示了大规模而复杂的数据，具有非常准确的内容和语言表达这些内容。特别是，专利文本在各个方面可能与平凡的文本有所不同，这带来了重大的机遇和挑战。本文系统概述了与专利有关的任务和流行的方法，特别关注不断演变和有前途的技术。语言处理，尤其是大型语言模型以及最近推动普通生成方法的提升，有望成为专利领域的变革者。专利文献以及围绕专利的基于事实的论证程序似乎几乎是一个理想的使用案例。然而，专利涉及许多现有模型很难处理的困难。

    arXiv:2403.04105v1 Announce Type: new  Abstract: Advanced language-processing and machine-learning techniques promise massive efficiency improvements in the previously widely manual field of patent and technical knowledge management. This field presents large-scale and complex data with very precise contents and language representation of those contents. Particularly, patent texts can differ from mundane texts in various aspects, which entails significant opportunities and challenges. This paper presents a systematic overview of patent-related tasks and popular methodologies with a special focus on evolving and promising techniques. Language processing and particularly large language models as well as the recent boost of general generative methods promise to become game changers in the patent field. The patent literature and the fact-based argumentative procedures around patents appear almost as an ideal use case. However, patents entail a number of difficulties with which existing mod
    
[^86]: 认知类型项目 - 将排版映射到认知

    The Cognitive Type Project -- Mapping Typography to Cognition

    [https://arxiv.org/abs/2403.04087](https://arxiv.org/abs/2403.04087)

    该项目旨在开发计算工具，帮助设计具有不同认知特性的字体，提高在线广告点击率，改善儿童书籍的阅读水平，让诵读者可以创造个性化字体，并洞察媒体文本内容的客户反应。

    

    arXiv:2403.04087v1 公告类型: 新 抽象: 认知类型项目致力于开发计算工具，以实现具有不同认知特性的字体设计。该倡议旨在赋予排版者制作可提高在线广告点击率、改善儿童读物阅读水平、让诵读者创建个性化字体，或者提供媒体文本内容客户反馈见解的字体设计能力。与将排版映射到认知相关的研究中的一个重大挑战是创建成千上万种具有微小变化的字体，这个过程既劳动密集又需要经验丰富的排版者的专业知识。认知科学研究强调字母的设计和形式以及文本整体布局对阅读的便利性和其他字体认知属性例如感知美感和记忆性至关重要。这些因素不仅影响字体的易读性和清晰度，也影响字体的美观和记忆性。

    arXiv:2403.04087v1 Announce Type: new  Abstract: The Cognitive Type Project is focused on developing computational tools to enable the design of typefaces with varying cognitive properties. This initiative aims to empower typographers to craft fonts that enhance click-through rates for online ads, improve reading levels in children's books, enable dyslexics to create personalized type, or provide insights into customer reactions to textual content in media. A significant challenge in research related to mapping typography to cognition is the creation of thousands of typefaces with minor variations, a process that is both labor-intensive and requires the expertise of skilled typographers. Cognitive science research highlights that the design and form of letters, along with the text's overall layout, are crucial in determining the ease of reading and other cognitive properties of type such as perceived beauty and memorability. These factors affect not only the legibility and clarity of i
    
[^87]: 通过高质量伪标签选择的半监督对话抽取式摘要生成

    Semi-Supervised Dialogue Abstractive Summarization via High-Quality Pseudolabel Selection

    [https://arxiv.org/abs/2403.04073](https://arxiv.org/abs/2403.04073)

    提出了一种新的高质量伪标签选择方法 SiCF，通过该方法选择具有高质量生成摘要的无标签对话来进行半监督对话抽取式摘要生成。

    

    半监督对话摘要生成（SSDS）利用模型生成的摘要减少对人工标记数据的依赖，提高摘要生成模型的性能。本文提出了一种新颖的评分方法 SiCF，包含了摘要模型质量的三个主要维度：语义不变性（模型信心的指示）、覆盖度（事实召回）和忠实度（事实精度）。利用 SiCF 分数，选择具有高质量生成摘要的无标签对话来训练摘要生成模型。

    arXiv:2403.04073v1 Announce Type: cross  Abstract: Semi-supervised dialogue summarization (SSDS) leverages model-generated summaries to reduce reliance on human-labeled data and improve the performance of summarization models. While addressing label noise, previous works on semi-supervised learning primarily focus on natural language understanding tasks, assuming each sample has a unique label. However, these methods are not directly applicable to SSDS, as it is a generative task, and each dialogue can be summarized in different ways. In this work, we propose a novel scoring approach, SiCF, which encapsulates three primary dimensions of summarization model quality: Semantic invariance (indicative of model confidence), Coverage (factual recall), and Faithfulness (factual precision). Using the SiCF score, we select unlabeled dialogues with high-quality generated summaries to train summarization models. Comprehensive experiments on three public datasets demonstrate the effectiveness of Si
    
[^88]: 预测和缓解公共公交服务中的中断

    Forecasting and Mitigating Disruptions in Public Bus Transit Services

    [https://arxiv.org/abs/2403.04072](https://arxiv.org/abs/2403.04072)

    引入数据驱动的统计和机器学习模型，以解决公共公交服务中替代车辆最佳位置选择的挑战性问题

    

    公共交通系统经常遭受需求的意外波动和中断，例如机械故障和医疗紧急情况。这些波动和中断导致延误和拥挤，这对乘客的体验和公共交通服务的整体性能都是有害的。为了积极减少这类事件，许多运输机构在其服务范围内设置替代（备用）车辆，它们可以调度这些车辆以增加或替代遭受拥挤或中断的路线上的车辆。然而，由于中断的固有随机性和在城市各地选择位置的组合性质，确定替代车辆应该设置的最佳位置是一个具有挑战性的问题。我们与田纳西州纳什维尔的运输机构合作，通过引入基于数据驱动的统计和机器学习模型来解决这一问题。

    arXiv:2403.04072v1 Announce Type: new  Abstract: Public transportation systems often suffer from unexpected fluctuations in demand and disruptions, such as mechanical failures and medical emergencies. These fluctuations and disruptions lead to delays and overcrowding, which are detrimental to the passengers' experience and to the overall performance of the transit service. To proactively mitigate such events, many transit agencies station substitute (reserve) vehicles throughout their service areas, which they can dispatch to augment or replace vehicles on routes that suffer overcrowding or disruption. However, determining the optimal locations where substitute vehicles should be stationed is a challenging problem due to the inherent randomness of disruptions and due to the combinatorial nature of selecting locations across a city. In collaboration with the transit agency of Nashville, TN, we address this problem by introducing data-driven statistical and machine-learning models for fo
    
[^89]: 在硬件受限的纳米四轴飞行器上进行设备端自监督学习的视觉感知任务

    On-device Self-supervised Learning of Visual Perception Tasks aboard Hardware-limited Nano-quadrotors

    [https://arxiv.org/abs/2403.04071](https://arxiv.org/abs/2403.04071)

    针对硬件受限的纳米四轴飞行器，在未知环境中进行设备端自监督学习，通过自监督微调预训练的卷积神经网络来解决领域转移问题

    

    小于50克的纳米无人机（nano-drones）在学术界和工业界都越来越受到关注。尽管受到硬件约束（如低于100毫瓦的处理器），它们最具吸引力的应用依赖于用于感知的设备端深度学习模型。当部署在训练数据中未表示的未知环境中时，这些模型经常由于领域转移而表现不佳。为了应对这一根本性问题，我们首次提出了在纳米无人机上进行设备端学习，其中现场任务的第一部分专门用于自监督微调预训练的卷积神经网络（CNN）。利用真实世界的基于视觉的回归任务，我们全面探讨了微调阶段在三个方面的性能成本权衡：i）数据集大小（更多数据可以提高回归性能，但需要更多内存和更长的计算）；ii）方法论等

    arXiv:2403.04071v1 Announce Type: cross  Abstract: Sub-\SI{50}{\gram} nano-drones are gaining momentum in both academia and industry. Their most compelling applications rely on onboard deep learning models for perception despite severe hardware constraints (\ie sub-\SI{100}{\milli\watt} processor). When deployed in unknown environments not represented in the training data, these models often underperform due to domain shift. To cope with this fundamental problem, we propose, for the first time, on-device learning aboard nano-drones, where the first part of the in-field mission is dedicated to self-supervised fine-tuning of a pre-trained convolutional neural network (CNN). Leveraging a real-world vision-based regression task, we thoroughly explore performance-cost trade-offs of the fine-tuning phase along three axes: \textit{i}) dataset size (more data increases the regression performance but requires more memory and longer computation); \textit{ii}) methodologies (\eg fine-tuning all m
    
[^90]: 利用脆弱性感知扰动预算改进对抗训练

    Improving Adversarial Training using Vulnerability-Aware Perturbation Budget

    [https://arxiv.org/abs/2403.04070](https://arxiv.org/abs/2403.04070)

    提出了两种基于脆弱性感知的重新加权函数，用于为对抗训练中的对抗示例分配扰动界限，从而提高了对抗训练的有效性。

    

    对抗训练(Adversarial Training, AT)有效地提高了深度神经网络(DNNs)对敌对攻击的鲁棒性。通常，AT涉及使用在预定义、固定扰动界限内获取的对抗示例来训练DNN模型。值得注意的是，用于制作这些对抗示例的个别自然示例展示出不同程度的固有脆弱性，因此，为所有实例设定固定扰动半径来制作对抗示例可能不足以充分发挥AT的有效性。受到这一观察的启发，我们提出了两种简单、计算廉价的基于脆弱性感知的重新加权函数，用于为用于AT的对抗示例分配扰动界限，分别命名为边际加权扰动预算（MWPB）和标准差加权扰动预算（SDWPB）。所提出的方法根据其对应脆弱性为单个对抗样本分配扰动半径。

    arXiv:2403.04070v1 Announce Type: cross  Abstract: Adversarial Training (AT) effectively improves the robustness of Deep Neural Networks (DNNs) to adversarial attacks. Generally, AT involves training DNN models with adversarial examples obtained within a pre-defined, fixed perturbation bound. Notably, individual natural examples from which these adversarial examples are crafted exhibit varying degrees of intrinsic vulnerabilities, and as such, crafting adversarial examples with fixed perturbation radius for all instances may not sufficiently unleash the potency of AT. Motivated by this observation, we propose two simple, computationally cheap vulnerability-aware reweighting functions for assigning perturbation bounds to adversarial examples used for AT, named Margin-Weighted Perturbation Budget (MWPB) and Standard-Deviation-Weighted Perturbation Budget (SDWPB). The proposed methods assign perturbation radii to individual adversarial samples based on the vulnerability of their correspon
    
[^91]: 无监督对比学习用于抵抗时域漂移下的稳健射频设备指纹识别

    Unsupervised Contrastive Learning for Robust RF Device Fingerprinting Under Time-Domain Shift

    [https://arxiv.org/abs/2403.04036](https://arxiv.org/abs/2403.04036)

    本论文引入了对比学习来解决射频设备指纹识别中的领域漂移问题，通过学习距离度量处理RF信号，从而提高稳健性。

    

    射频（RF）设备指纹识别被认为是实现自动无线设备识别和分类的潜在技术。然而，由于信道条件和环境设置的变化可能引起的领域漂移，可能会降低基于RF的设备分类的准确性，特别是当测试和训练数据在不同领域收集时。本文介绍了一种新颖的解决方案，该方案利用对比学习来缓解这种领域漂移问题。对比学习是一种来自深度学习的最先进的自监督学习方法，学习一个距离度量，使得正对组在学习的度量空间中比负对更接近（即更相似）。当应用于RF指纹识别时，我们的模型将来自相同传输的RF信号视为正对，将来自不同传输的信号视为负对。

    arXiv:2403.04036v1 Announce Type: cross  Abstract: Radio Frequency (RF) device fingerprinting has been recognized as a potential technology for enabling automated wireless device identification and classification. However, it faces a key challenge due to the domain shift that could arise from variations in the channel conditions and environmental settings, potentially degrading the accuracy of RF-based device classification when testing and training data is collected in different domains. This paper introduces a novel solution that leverages contrastive learning to mitigate this domain shift problem. Contrastive learning, a state-of-the-art self-supervised learning approach from deep learning, learns a distance metric such that positive pairs are closer (i.e. more similar) in the learned metric space than negative pairs. When applied to RF fingerprinting, our model treats RF signals from the same transmission as positive pairs and those from different transmissions as negative pairs. T
    
[^92]: 个性化AI驱动提示对用户认知能力的解释：一项实证评估

    Personalizing explanations of AI-driven hints to users cognitive abilities: an empirical evaluation

    [https://arxiv.org/abs/2403.04035](https://arxiv.org/abs/2403.04035)

    该研究调查了如何个性化智能辅导系统生成的提示的解释，以帮助促进学生学习，实证结果表明，该个性化方法显著提高了目标用户与提示解释的互动、理解和学习效果。

    

    我们调查了个性化解释智能辅导系统生成的提示，以证明它们提供提示促进学生学习的有效性。个性化针对具有两种特征（认知需求和认真度）较低水平的学生，旨在增强这些学生对解释的参与，基于先前研究发现，这些学生不会自然参与解释，但如果他们这样做将会受益。为了评估个性化的有效性，我们进行了一项用户研究，我们发现我们提出的个性化显著增加了我们目标用户与提示解释的互动、他们对提示的理解以及他们的学习。因此，这项工作为个性化AI驱动解释提供了有价值的见解，适用于如学习等认知要求高的任务。

    arXiv:2403.04035v1 Announce Type: new  Abstract: We investigate personalizing the explanations that an Intelligent Tutoring System generates to justify the hints it provides to students to foster their learning. The personalization targets students with low levels of two traits, Need for Cognition and Conscientiousness, and aims to enhance these students' engagement with the explanations, based on prior findings that these students do not naturally engage with the explanations but they would benefit from them if they do. To evaluate the effectiveness of the personalization, we conducted a user study where we found that our proposed personalization significantly increases our target users' interaction with the hint explanations, their understanding of the hints and their learning. Hence, this work provides valuable insights into effectively personalizing AI-driven explanations for cognitively demanding tasks such as learning.
    
[^93]: 具有未知约束的在线学习

    Online Learning with Unknown Constraints

    [https://arxiv.org/abs/2403.04033](https://arxiv.org/abs/2403.04033)

    在线学习中通过元算法结合在线回归预测器估计未知安全约束，并将在线学习预测转换为符合约束的预测，同时保证在每一轮高概率地满足安全约束。算法的后悔受到在线回归和在线学习预测器的限制，模型类中未知安全约束的逃避维度，以及捕捉安全学习困难的新颖复杂度度量的约束。

    

    我们考虑在线学习中的问题，其中学习者在每一轮必须遵守一个未知的安全约束。目标是在同时满足安全约束并在后视下最小化对最佳安全动作的后悔。我们提供了一个通用的元算法，利用在线回归预测器来估计未知安全约束，并将在线学习预测转换为符合未知安全约束的预测。在理论方面，我们的算法的后悔可以通过在线回归和在线学习预测器的后悔、包含未知安全约束的模型类的逃避维度，以及一个捕捉安全学习困难程度的新颖复杂度度量来界定。

    arXiv:2403.04033v1 Announce Type: cross  Abstract: We consider the problem of online learning where the sequence of actions played by the learner must adhere to an unknown safety constraint at every round. The goal is to minimize regret with respect to the best safe action in hindsight while simultaneously satisfying the safety constraint with high probability on each round. We provide a general meta-algorithm that leverages an online regression oracle to estimate the unknown safety constraint, and converts the predictions of an online learning oracle to predictions that adhere to the unknown safety constraint. On the theoretical side, our algorithm's regret can be bounded by the regret of the online regression and online learning oracles, the eluder dimension of the model class containing the unknown safety constraint, and a novel complexity measure that captures the difficulty of safe learning. We complement our result with an asymptotic lower bound that shows that the aforementioned
    
[^94]: 大型语言模型能进行分析推理吗？

    Can Large Language Models do Analytical Reasoning?

    [https://arxiv.org/abs/2403.04031](https://arxiv.org/abs/2403.04031)

    本研究探索了大型语言模型在体育领域的分析推理能力，发现在处理NBA和NFL比赛得分任务时，GPT-4和Claude-2.1表现最佳，采用分治法进行数据处理效果最好。

    

    这篇论文探讨了应用于体育领域的前沿大型语言模型进行分析推理。我们使用大型语言模型来计算NBA和NFL比赛中每支球队在一个季度中得分的任务。我们的主要发现有两个方面。首先，我们发现在我们使用的所有模型中，GPT-4在效果上表现最为突出，其次是Claude-2.1，而GPT-3.5、Gemini-Pro和Llama-2-70b效果稍逊。具体来说，我们比较了三种不同的提示技术和分治法，发现后者效果最好。我们的分治法将逐步数据细分为更小、更易处理的片段，分别解决每个片段，然后将它们合并在一起。除了分治法，我们还探讨了一种名为Chain of Thought（CoT）策略，显著改善了某些模型的结果，尤其是GPT-4和Claude-2.1。

    arXiv:2403.04031v1 Announce Type: cross  Abstract: This paper explores the cutting-edge Large Language Model with analytical reasoning on sports. Our analytical reasoning embodies the tasks of letting large language models count how many points each team scores in a quarter in the NBA and NFL games. Our major discoveries are in two folds. Firstly, we find among all the models we employed, GPT-4 stands out in effectiveness, followed by Claude-2.1, with GPT-3.5, Gemini-Pro, and Llama-2-70b lagging behind. Specifically, we compare three different prompting techniques and a divide-and-conquer approach, we find that the latter was the most effective. Our divide-and-conquer approach breaks down play-by-play data into smaller, more manageable segments, solves each piece individually, and then aggregates them together. Besides the divide-and-conquer approach, we also explore the Chain of Thought (CoT) strategy, which markedly improves outcomes for certain models, notably GPT-4 and Claude-2.1, 
    
[^95]: 学习引导的自动推理：简要调查

    Learning Guided Automated Reasoning: A Brief Survey

    [https://arxiv.org/abs/2403.04017](https://arxiv.org/abs/2403.04017)

    机器学习可引导自动推理系统，通过逻辑有效证明概念支持演绎搜索，从大型推理体中培训机器学习系统，打破推理系统的组合爆炸问题，并促进推理链的长远发展和新颖证明思路的产生

    

    自动定理证明器和形式化证明助手是通用的推理系统，理论上能够证明任意困难的定理，从而解决可归约为数学和逻辑推理的任意问题。在实践中，这些系统面临着极大的组合爆炸，因此包含许多启发式方法和选择点，这些方法和选择点极大地影响其性能。这为受过训练的机器学习预测器提供了机会，可以引导这些推理系统的工作。相反，由逻辑上有效证明概念支持的演绎搜索允许在大型推理语料库上训练机器学习系统。这些证明体通常是通过构建正确的，当与更加精确的训练引导相结合时，可以将它们提升为非常庞大的语料库，具有越来越长的推理链，并可能产生新颖的证明思路。在本文中，我们概述了...

    arXiv:2403.04017v1 Announce Type: new  Abstract: Automated theorem provers and formal proof assistants are general reasoning systems that are in theory capable of proving arbitrarily hard theorems, thus solving arbitrary problems reducible to mathematics and logical reasoning. In practice, such systems however face large combinatorial explosion, and therefore include many heuristics and choice points that considerably influence their performance. This is an opportunity for trained machine learning predictors, which can guide the work of such reasoning systems. Conversely, deductive search supported by the notion of logically valid proof allows one to train machine learning systems on large reasoning corpora. Such bodies of proof are usually correct by construction and when combined with more and more precise trained guidance they can be boostrapped into very large corpora, with increasingly long reasoning chains and possibly novel proof ideas. In this paper we provide an overview of se
    
[^96]: 通过单个预训练的增强型代理引导的模拟特征选择

    Knockoff-Guided Feature Selection via A Single Pre-trained Reinforced Agent

    [https://arxiv.org/abs/2403.04015](https://arxiv.org/abs/2403.04015)

    通过引入模拟特征指导和强化学习优化的创新框架，提出了一种用于特征选择的方法，以识别最佳有效的特征子集。

    

    特征选择通过消除冗余特征来准备数据的AI可用性。先前的研究主要分为两类：i）监督特征选择，根据特征与目标变量的相关性识别最佳特征子集；ii）无监督特征选择，通过捕获特征集中的基本信息而非使用目标变量来减少特征空间的维度。然而，监督特征选择方法由于依赖目标变量和下游ML任务而导致耗时且泛化能力有限。无监督特征选择方法受限于推导出的特征空间是潜在且不可追踪的。为解决这些挑战，我们引入一种新颖的特征选择框架，通过模拟特征指导并通过强化学习进行优化，以识别最佳有效的特征子集。

    arXiv:2403.04015v1 Announce Type: cross  Abstract: Feature selection prepares the AI-readiness of data by eliminating redundant features. Prior research falls into two primary categories: i) Supervised Feature Selection, which identifies the optimal feature subset based on their relevance to the target variable; ii) Unsupervised Feature Selection, which reduces the feature space dimensionality by capturing the essential information within the feature set instead of using target variable. However, SFS approaches suffer from time-consuming processes and limited generalizability due to the dependence on the target variable and downstream ML tasks. UFS methods are constrained by the deducted feature space is latent and untraceable. To address these challenges, we introduce an innovative framework for feature selection, which is guided by knockoff features and optimized through reinforcement learning, to identify the optimal and effective feature subset. In detail, our method involves gener
    
[^97]: PromptCharm：通过多模态提示和优化进行文本到图像生成

    PromptCharm: Text-to-Image Generation through Multi-modal Prompting and Refinement

    [https://arxiv.org/abs/2403.04014](https://arxiv.org/abs/2403.04014)

    提出了PromptCharm系统，通过多模态提示工程和优化，支持新手用户进行文本到图像生成。

    

    生成式人工智能的最新进展显著推动了文本到图像生成领域的发展。最先进的文本到图像模型Stable Diffusion现在能够合成具有强烈美学感的高质量图像。因此，制作符合模型解释和用户意图的文本提示变得至关重要。然而，由于稳定扩散模型的复杂性以及需要通过迭代编辑和优化文本提示，因此对新手用户来说，提示仍然具有挑战性。为了解决这些挑战，我们提出了PromptCharm，这是一个通过多模态提示工程和优化促进文本到图像生成的混合倡议系统。为了帮助新手用户进行提示，PromptCharm首先自动优化和优化用户的初始提示。此外，PromptCharm支持用户探索和选择不同的图像风格。

    arXiv:2403.04014v1 Announce Type: cross  Abstract: The recent advancements in Generative AI have significantly advanced the field of text-to-image generation. The state-of-the-art text-to-image model, Stable Diffusion, is now capable of synthesizing high-quality images with a strong sense of aesthetics. Crafting text prompts that align with the model's interpretation and the user's intent thus becomes crucial. However, prompting remains challenging for novice users due to the complexity of the stable diffusion model and the non-trivial efforts required for iteratively editing and refining the text prompts. To address these challenges, we propose PromptCharm, a mixed-initiative system that facilitates text-to-image creation through multi-modal prompt engineering and refinement. To assist novice users in prompting, PromptCharm first automatically refines and optimizes the user's initial prompt. Furthermore, PromptCharm supports the user in exploring and selecting different image styles w
    
[^98]: 具有双向进步神经网络和情节回归进展的新兴任务排序和机器人技能迁移

    Bidirectional Progressive Neural Networks with Episodic Return Progress for Emergent Task Sequencing and Robotic Skill Transfer

    [https://arxiv.org/abs/2403.04001](https://arxiv.org/abs/2403.04001)

    提出了一种名为具有双向进步神经网络的情节回归进展（ERP-BPNN）的新型多任务强化学习框架，通过人类般交叉的方式学习，实现自主任务切换，并允许在任务之间进行双向技能传递。

    

    人类大脑和行为提供了一个丰富的场景，可以启发机器人的新型控制和学习方法。为了通过激发人类如何获取知识并在任务之间传递技能来展示这样一种发展，我们引入了一种名为具有双向进步神经网络的情节回归进展（ERP-BPNN）的新型多任务强化学习框架。提出的ERP-BPNN模型（1）通过人类般交叉的方式学习，通过一种新颖的内在激励信号实现自主任务切换，并且与现有方法不同，（3）允许在任务之间进行双向技能传递。ERP-BPNN是一个通用架构，适用于几种多任务学习设置；在本文中，我们介绍了其神经结构的细节，并展示了它在不同机器人形态的触碰任务中实现有效学习和技能传递的能力。

    arXiv:2403.04001v1 Announce Type: cross  Abstract: Human brain and behavior provide a rich venue that can inspire novel control and learning methods for robotics. In an attempt to exemplify such a development by inspiring how humans acquire knowledge and transfer skills among tasks, we introduce a novel multi-task reinforcement learning framework named Episodic Return Progress with Bidirectional Progressive Neural Networks (ERP-BPNN). The proposed ERP-BPNN model (1) learns in a human-like interleaved manner by (2) autonomous task switching based on a novel intrinsic motivation signal and, in contrast to existing methods, (3) allows bidirectional skill transfer among tasks. ERP-BPNN is a general architecture applicable to several multi-task learning settings; in this paper, we present the details of its neural architecture and show its ability to enable effective learning and skill transfer among morphologically different robots in a reaching task. The developed Bidirectional Progressiv
    
[^99]: 用大型语言模型引导列举式程序合成

    Guiding Enumerative Program Synthesis with Large Language Models

    [https://arxiv.org/abs/2403.03997](https://arxiv.org/abs/2403.03997)

    该论文评估了大型语言模型在形式合成基准上的能力，并提出了一种结合列举算法和大型语言模型的合成算法，以在迭代循环中提供语法指导和信息交流。

    

    预训练的大型语言模型 (LLMs) 开始主导围绕使用自然语言规范生成代码的讨论。与此相比，在精确逻辑规范领域中表现最佳的合成器仍然基于列举算法。本文通过精心制作领域提示库评估了LLMs解决形式合成基准的能力。当一次合成失败时，我们提出了一种新颖的列举式合成算法，将LLM的调用集成到加权概率搜索中。这样，合成器可以向LLM提供有关枚举器进展情况的信息，LLM可以向枚举器在迭代循环中提供语法指导。我们在来自语法引导合成 (SyGuS) 竞赛的基准上评估了我们的技术。

    arXiv:2403.03997v1 Announce Type: new  Abstract: Pre-trained Large Language Models (LLMs) are beginning to dominate the discourse around automatic code generation with natural language specifications. In contrast, the best-performing synthesizers in the domain of formal synthesis with precise logical specifications are still based on enumerative algorithms. In this paper, we evaluate the abilities of LLMs to solve formal synthesis benchmarks by carefully crafting a library of prompts for the domain. When one-shot synthesis fails, we propose a novel enumerative synthesis algorithm, which integrates calls to an LLM into a weighted probabilistic search. This allows the synthesizer to provide the LLM with information about the progress of the enumerator, and the LLM to provide the enumerator with syntactic guidance in an iterative loop. We evaluate our techniques on benchmarks from the Syntax-Guided Synthesis (SyGuS) competition. We find that GPT-3.5 as a stand-alone tool for formal synthe
    
[^100]: 通过调整健康领域视角重新思考城市洪水风险评估

    Rethinking Urban Flood Risk Assessment By Adapting Health Domain Perspective

    [https://arxiv.org/abs/2403.03996](https://arxiv.org/abs/2403.03996)

    本文通过健康领域视角提出了新的城市洪水风险评估框架，聚焦于固有易感性、缓解策略和外部压力因素三大支柱，旨在从新的视角评估高洪水风险路径。

    

    受健康风险评估思想启发，本文提出了洪水风险评估的新视角。提出的视角主要关注三个支柱来研究洪水风险：(1)固有易感性，(2)缓解策略，以及(3)外部压力因素。这些支柱共同涵盖了城市地区的物理和环境特征，人类干预措施的有效性和无法控制的外部因素的影响，为解码洪水风险提供了新的视角。对于每个支柱，我们描述了其对洪水风险的个别贡献，并阐明了它们的相互作用和总体影响。这一三支柱模型体现了从精确建模和量化洪水风险的追求到评估高洪水风险路径的关注转变。这种视角的转变旨在减轻对细分辨率量化和预测洪水风险作为解药的追求。

    arXiv:2403.03996v1 Announce Type: new  Abstract: Inspired by ideas from health risk assessment, this paper presents a new perspective for flood risk assessment. The proposed perspective focuses on three pillars for examining flood risk: (1) inherent susceptibility, (2) mitigation strategies, and (3) external stressors. These pillars collectively encompass the physical and environmental characteristics of urban areas, the effectiveness of human-intervention measures, and the influence of uncontrollable external factors, offering a fresh point of view for decoding flood risks. For each pillar, we delineate its individual contributions to flood risk and illustrate their interactive and overall impact. The three-pillars model embodies a shift in focus from the quest to precisely model and quantify flood risk to evaluating pathways to high flood risk. The shift in perspective is intended to alleviate the quest for quantifying and predicting flood risk at fine resolutions as a panacea for en
    
[^101]: 个性化负采样在推荐系统增量学习中的应用

    Personalized Negative Reservoir for Incremental Learning in Recommender Systems

    [https://arxiv.org/abs/2403.03993](https://arxiv.org/abs/2403.03993)

    推荐系统中的个性化负采样技术在增量学习中的应用，解决了更新推荐系统模型时遇到的遗忘灾难问题。

    

    推荐系统已成为在线平台的重要组成部分。每天训练数据量不断扩大，用户互动次数不断增加。探索更大更具表现力的模型已成为改善用户体验的必要追求。然而，这种进展带来了更大的计算负担。在商业环境中，一旦推荐系统模型被训练和部署，通常需要频繁更新以适应新的客户数据。累积起来，数据量的增加必将使得从头开始进行全量重训练变得计算上不可行。仅仅在新数据上进行简单微调会遇到已被广泛记录的遗忘灾难问题。尽管负采样在使用隐式反馈进行训练中是至关重要的一部分，但目前并不存在专门针对增量学习的技术。

    arXiv:2403.03993v1 Announce Type: cross  Abstract: Recommender systems have become an integral part of online platforms. Every day the volume of training data is expanding and the number of user interactions is constantly increasing. The exploration of larger and more expressive models has become a necessary pursuit to improve user experience. However, this progression carries with it an increased computational burden. In commercial settings, once a recommendation system model has been trained and deployed it typically needs to be updated frequently as new client data arrive. Cumulatively, the mounting volume of data is guaranteed to eventually make full batch retraining of the model from scratch computationally infeasible. Naively fine-tuning solely on the new data runs into the well-documented problem of catastrophic forgetting. Despite the fact that negative sampling is a crucial part of training with implicit feedback, no specialized technique exists that is tailored to the increme
    
[^102]: 使用大型语言模型识别复杂网络中的关键节点

    Identify Critical Nodes in Complex Network with Large Language Models

    [https://arxiv.org/abs/2403.03962](https://arxiv.org/abs/2403.03962)

    提出了一种利用大型语言模型和进化算法相结合的方法，生成用于识别关键节点的函数“score_nodes”，通过强大的上下文理解能力和丰富的编程技能生成出色的新函数，以确保群体的稳定发展同时保持多样性。

    

    在网络中识别关键节点是一个经典的决策任务，许多方法在可适应性和效用之间难以取得平衡。因此，我们提出了一种方法，将进化算法（EA）与大型语言模型（LLMs）相结合，生成一个名为“score_nodes”的函数，该函数可以进一步用于根据其分配的分数识别关键节点。我们的模型包括三个主要组成部分：手动初始化、群体管理和基于LLMs的进化。它从最初的人口群体中演化出一组手动创建的设计节点评分函数。LLMs利用其强大的上下文理解能力和丰富的编程技能对个体执行交叉和突变操作，生成出色的新函数。然后对这些函数进行分类、排名和消除，以确保群体的稳定发展同时保持多样性。

    arXiv:2403.03962v1 Announce Type: cross  Abstract: Identifying critical nodes in networks is a classical decision-making task, and many methods struggle to strike a balance between adaptability and utility. Therefore, we propose an approach that empowers Evolutionary Algorithm (EA) with Large Language Models (LLMs), to generate a function called "score\_nodes" which can further be used to identify crucial nodes based on their assigned scores. Our model consists of three main components: Manual Initialization, Population Management, and LLMs-based Evolution. It evolves from initial populations with a set of designed node scoring functions created manually. LLMs leverage their strong contextual understanding and rich programming skills to perform crossover and mutation operations on the individuals, generating excellent new functions. These functions are then categorized, ranked, and eliminated to ensure the stable development of the populations while preserving diversity. Extensive expe
    
[^103]: 强化学习在空间资源分配中的应用调查

    A Survey on Applications of Reinforcement Learning in Spatial Resource Allocation

    [https://arxiv.org/abs/2403.03643](https://arxiv.org/abs/2403.03643)

    运用强化学习解决空间资源分配问题的新方法具有快速解决方法收敛和强大的模型泛化能力等优势，为这一问题领域提供了新的视角。

    

    空间资源分配的挑战在交通运输、工业和日常生活等各个领域普遍存在。随着现实世界问题规模不断扩大以及对实时解决方案的需求增加，传统算法面临着巨大的计算压力，难以实现最佳效率和实时能力。近年来，随着计算机计算能力的不断提升，强化学习在诸如围棋和机器人领域取得了显著成就，展示了其强大的学习和序贯决策能力。鉴于这些进展，近年来出现了大量运用强化学习解决空间资源分配问题的新方法。这些方法具有快速解决方法收敛和强大的模型泛化能力等优势，为解决空间资源分配问题提供了新的视角。

    arXiv:2403.03643v1 Announce Type: cross  Abstract: The challenge of spatial resource allocation is pervasive across various domains such as transportation, industry, and daily life. As the scale of real-world issues continues to expand and demands for real-time solutions increase, traditional algorithms face significant computational pressures, struggling to achieve optimal efficiency and real-time capabilities. In recent years, with the escalating computational power of computers, the remarkable achievements of reinforcement learning in domains like Go and robotics have demonstrated its robust learning and sequential decision-making capabilities. Given these advancements, there has been a surge in novel methods employing reinforcement learning to tackle spatial resource allocation problems. These methods exhibit advantages such as rapid solution convergence and strong model generalization abilities, offering a new perspective on resolving spatial resource allocation problems. Therefor
    
[^104]: DLP-GAN：使用生成对抗网络学习绘制现代中国风景照片

    DLP-GAN: Learning to Draw Modern Chinese Landscape Photos with Generative Adversarial Network

    [https://arxiv.org/abs/2403.03456](https://arxiv.org/abs/2403.03456)

    该论文提出了DLP-GAN模型，使用生成对抗网络实现了现代中国风景照片的绘制，引入了不对称循环映射和双一致性损失来平衡现实感和抽象性。

    

    中国山水画具有独特和艺术的风格，其绘画技术在色彩使用和物体的逼真表现上高度抽象。先前的方法主要集中在从现代照片转换到古代水墨画上，但很少关注将风景画转化为现代照片。为了解决这些问题，本文提出了DLP-GAN（使用生成对抗网络绘制现代中国风景照片），一个具有新颖的不对称循环映射的无监督跨域图像转换框架，并引入了基于密集融合模块的生成器来匹配不同的转换方向。此外，提出了双一致性损失以平衡模型绘画的逼真性和抽象性，使我们的模型能够以现代感绘制风景照片和素描。

    arXiv:2403.03456v1 Announce Type: cross  Abstract: Chinese landscape painting has a unique and artistic style, and its drawing technique is highly abstract in both the use of color and the realistic representation of objects. Previous methods focus on transferring from modern photos to ancient ink paintings. However, little attention has been paid to translating landscape paintings into modern photos. To solve such problems, in this paper, we (1) propose DLP-GAN (\textbf{D}raw Modern Chinese \textbf{L}andscape \textbf{P}hotos with \textbf{G}enerative \textbf{A}dversarial \textbf{N}etwork), an unsupervised cross-domain image translation framework with a novel asymmetric cycle mapping, and (2) introduce a generator based on a dense-fusion module to match different translation directions. Moreover, a dual-consistency loss is proposed to balance the realism and abstraction of model painting. In this way, our model can draw landscape photos and sketches in the modern sense. Finally, based o
    
[^105]: WMDP基准：通过遗忘测量和减少恶意使用

    The WMDP Benchmark: Measuring and Reducing Malicious Use With Unlearning

    [https://arxiv.org/abs/2403.03218](https://arxiv.org/abs/2403.03218)

    WMDP基准是一个公开发布的数据集，包含4157个多项选择问题，用作生物安全、网络安全和化学安全危险知识的代理测量。

    

    arXiv:2403.03218v1 公告类型：交叉领域 摘要：白宫关于人工智能的行政命令强调了大型语言模型(LLMs)赋予恶意行为者开发生物、网络和化学武器的风险。为了衡量这些恶意使用的风险，政府机构和主要人工智能实验室正在开发LLMs的危险能力评估。然而，当前的评估是私人的，阻碍了进一步研究如何减少风险。此外，它们仅专注于几条高度特定的恶意使用途径。为了填补这些空白，我们公开发布了大规模杀伤性武器代理（WMDP）基准，这是一个包含4157个多项选择问题的数据集，作为生物安全、网络安全和化学安全危险知识的代理测量。WMDP由一组学术界和技术顾问联合开发，并在公开发布前严格过滤以消除敏感信息。WMDP有两个服务

    arXiv:2403.03218v1 Announce Type: cross  Abstract: The White House Executive Order on Artificial Intelligence highlights the risks of large language models (LLMs) empowering malicious actors in developing biological, cyber, and chemical weapons. To measure these risks of malicious use, government institutions and major AI labs are developing evaluations for hazardous capabilities in LLMs. However, current evaluations are private, preventing further research into mitigating risk. Furthermore, they focus on only a few, highly specific pathways for malicious use. To fill these gaps, we publicly release the Weapons of Mass Destruction Proxy (WMDP) benchmark, a dataset of 4,157 multiple-choice questions that serve as a proxy measurement of hazardous knowledge in biosecurity, cybersecurity, and chemical security. WMDP was developed by a consortium of academics and technical consultants, and was stringently filtered to eliminate sensitive information prior to public release. WMDP serves two r
    
[^106]: 通往通用计算机控制：多模态代理在《荒野大镖客2》中的案例研究

    Towards General Computer Control: A Multimodal Agent for Red Dead Redemption II as a Case Study

    [https://arxiv.org/abs/2403.03186](https://arxiv.org/abs/2403.03186)

    提出了通用计算机控制（GCC）设置，通过基于屏幕图像和可能的音频输入的基金代理框架Cradle，实现了对《荒野大镖客2》中复杂任务的控制。

    

    最近的研究表明，基于基金的代理在特定任务或场景中取得了成功。然而，现有代理无法跨不同场景泛化，主要是由于它们多样化的观察和行动空间以及语义差距，或依赖于特定任务的资源。在这项工作中，我们提出了通用计算机控制（GCC）设置：通过仅获取计算机的屏幕图像（以及可能的音频）作为输入，并产生键盘和鼠标操作作为输出，类似于人机交互，构建可以精通任何计算机任务的基金代理。为了针对GCC，我们提出了Cradle，一个代理框架，具有强大的推理能力，包括自我反思、任务推理和技能整理，以确保在各种任务中的泛化和自我改进。为了展示Cradle的能力，我们将其部署在复杂的AAA游戏《荒野大镖客2》中，作为通向G的初步尝试。

    arXiv:2403.03186v1 Announce Type: new  Abstract: Recent studies have demonstrated the success of foundation agents in specific tasks or scenarios. However, existing agents cannot generalize across different scenarios, mainly due to their diverse observation and action spaces and semantic gaps, or reliance on task-specific resources. In this work, we propose the General Computer Control (GCC) setting: building foundation agents that can master any computer task by taking only screen images (and possibly audio) of the computer as input, and producing keyboard and mouse operations as output, similar to human-computer interaction. To target GCC, we propose Cradle, an agent framework with strong reasoning abilities, including self-reflection, task inference, and skill curation, to ensure generalizability and self-improvement across various tasks. To demonstrate the capabilities of Cradle, we deploy it in the complex AAA game Red Dead Redemption II, serving as a preliminary attempt towards G
    
[^107]: 深度强化学习用于动态算法选择：以微分进化为例的原理研究

    Deep Reinforcement Learning for Dynamic Algorithm Selection: A Proof-of-Principle Study on Differential Evolution

    [https://arxiv.org/abs/2403.02131](https://arxiv.org/abs/2403.02131)

    本论文提出了一种基于深度强化学习的动态算法选择框架，旨在通过训练代理根据优化过程中观察到的特征选择最合适的算法，以解决单个算法有效性在不同问题实例上变化的问题。

    

    进化算法，如微分进化，在解决实数参数优化挑战方面表现出色。然而，单个算法的有效性在不同问题实例上变化，需要在算法选择或配置方面投入相当多的努力。本文旨在通过利用一组算法的互补优势，并在优化过程中为特定问题动态调度它们来解决这一限制。我们提出了一个基于深度强化学习的动态算法选择框架来完成这一任务。我们的方法将动态算法选择建模为马尔科夫决策过程，以策略梯度方式训练代理选择根据优化过程中观察到的特征选择最合适的算法。为了使代理具备必要的信息，我们的框架结合了一个经过深思熟虑的景观和算法设计。

    arXiv:2403.02131v1 Announce Type: cross  Abstract: Evolutionary algorithms, such as Differential Evolution, excel in solving real-parameter optimization challenges. However, the effectiveness of a single algorithm varies across different problem instances, necessitating considerable efforts in algorithm selection or configuration. This paper aims to address the limitation by leveraging the complementary strengths of a group of algorithms and dynamically scheduling them throughout the optimization progress for specific problems. We propose a deep reinforcement learning-based dynamic algorithm selection framework to accomplish this task. Our approach models the dynamic algorithm selection a Markov Decision Process, training an agent in a policy gradient manner to select the most suitable algorithm according to the features observed during the optimization process. To empower the agent with the necessary information, our framework incorporates a thoughtful design of landscape and algorith
    
[^108]: 合并来自不同初始化的文本变换器模型

    Merging Text Transformer Models from Different Initializations

    [https://arxiv.org/abs/2403.00986](https://arxiv.org/abs/2403.00986)

    研究了合并不同初始化的Transformer模型的技术，提出了一种模型合并技术以研究这些模型极小值之间的关系，并发现与模型平均相比，通过我们的方法合并这些模型始终可以获得较低的损失障碍。

    

    最近关于一次性基于排列的模型合并的工作表明，不同初始化的模型之间存在令人印象深刻的低或零障碍模连接。然而，尽管Transformer架构在语言领域中占主导地位，但这一领域的研究尚未延伸到Transformer架构。因此，在这项工作中，我们调查了独立Transformer极小值学习类似特征的程度，并提出了一种模型合并技术，以研究损失景观中这些极小值之间的关系。架构的具体细节，如其残差连接、多头注意力和离散的顺序输入，需要特定的干预措施，以便计算留在相同功能等价类中的模型排列。通过我们的方法合并这些模型，我们发现与对几个在一个maske上训练的模型进行模型平均相比，最小值之间的损失障碍一直较低。

    arXiv:2403.00986v1 Announce Type: cross  Abstract: Recent work on one-shot permutation-based model merging has shown impressive low- or zero-barrier mode connectivity between models from completely different initializations. However, this line of work has not yet extended to the Transformer architecture, despite its dominant popularity in the language domain. Therefore, in this work, we investigate the extent to which separate Transformer minima learn similar features, and propose a model merging technique to investigate the relationship between these minima in the loss landscape. The specifics of the architecture, like its residual connections, multi-headed attention, and discrete, sequential input, require specific interventions in order to compute model permutations that remain within the same functional equivalence class. In merging these models with our method, we consistently find lower loss barriers between minima compared to model averaging for several models trained on a maske
    
[^109]: 直接与Chat-Fine-Tuned LLMs的草案模型对齐

    Direct Alignment of Draft Model for Speculative Decoding with Chat-Fine-Tuned LLMs

    [https://arxiv.org/abs/2403.00858](https://arxiv.org/abs/2403.00858)

    通过提出的框架，我们训练了一种用于Llama 2 Chat 7B或更大模型的草案模型，实现了加速推理，仅占原始大小的1.64％。

    

    文本生成与大型语言模型（LLMs）由于其自回归本质、巨大的参数数量和有限的内存带宽而被认为是内存密集型，通常导致低令牌速率。猜测解码已被提出作为LLM推理加速的解决方案。然而，在现代开源LLM系列中，例如Llama 2 7B，由于草案模型通常不可用，因此需要训练高质量的草案模型以通过猜测解码实现推理加速。在本文中，我们提出了一个简单的草案模型训练框架，用于直接与Chat-capable目标模型对齐。通过我们提出的框架，我们训练出Llama 2 Chat Drafter 115M，这是一个适用于Llama 2 Chat 7B或更大模型的草案模型，仅占原始大小的1.64％。我们的训练框架仅包括预训练、蒸馏数据集生成和使用知识蒸馏进行微调，没有额外的对齐步骤。

    arXiv:2403.00858v1 Announce Type: cross  Abstract: Text generation with Large Language Models (LLMs) is known to be memory bound due to the combination of their auto-regressive nature, huge parameter counts, and limited memory bandwidths, often resulting in low token rates. Speculative decoding has been proposed as a solution for LLM inference acceleration. However, since draft models are often unavailable in the modern open-source LLM families, e.g., for Llama 2 7B, training a high-quality draft model is required to enable inference acceleration via speculative decoding. In this paper, we propose a simple draft model training framework for direct alignment to chat-capable target models. With the proposed framework, we train Llama 2 Chat Drafter 115M, a draft model for Llama 2 Chat 7B or larger, with only 1.64\% of the original size. Our training framework only consists of pretraining, distillation dataset generation, and finetuning with knowledge distillation, with no additional align
    
[^110]: 通过语义感知置换训练来缓解逆转诅咒

    Mitigating Reversal Curse via Semantic-aware Permutation Training

    [https://arxiv.org/abs/2403.00758](https://arxiv.org/abs/2403.00758)

    逆转诅咒问题是导致因果语言模型无法进行双向推理的根本原因之一，在这篇论文中，我们提出了通过语义感知的置换训练来缓解这一问题。

    

    大型语言模型（LLM）在各种任务中取得了令人印象深刻的表现，然而最近的研究表明，因果关系的LLM遭遇了“逆转诅咒”。一个典型的例子是，模型知道“A的父亲是B”，但无法推理出“B的孩子是A”。这一局限性对人工通用智能（AGI）的进展构成了挑战，因为它暗示了模型在理解和应用双向推理方面存在差距。本文首先进行了大量评估，并确定了逆转诅咒的根本原因在于训练和推断阶段之间的词序不同，即因果语言模型在训练数据中预测先行词的能力不足。因此，考虑到在训练数据上进行排列可以被视为潜在解决方案，因为这可以使模型预测先行词或标记。然而，先前的排列方法可能受到截断影响。

    arXiv:2403.00758v1 Announce Type: cross  Abstract: While large language models (LLMs) have achieved impressive performance across diverse tasks, recent studies showcase that causal LLMs suffer from the "reversal curse". It is a typical example that the model knows "A's father is B", but is unable to reason "B's child is A". This limitation poses a challenge to the advancement of artificial general intelligence (AGI), as it suggests a gap in the models' ability to comprehend and apply bidirectional reasoning. In this paper, we first conduct substantial evaluation and identify that the root cause of the reversal curse lies in the different word order between the training and inference stage, namely, the poor ability of causal language models to predict antecedent words within the training data. Accordingly, permutation on the training data is considered as a potential solution, since this can make the model predict antecedent words or tokens. However, previous permutation methods may dis
    
[^111]: ByteComposer：基于语言模型代理的类人旋律创作方法

    ByteComposer: a Human-like Melody Composition Method based on Language Model Agent

    [https://arxiv.org/abs/2402.17785](https://arxiv.org/abs/2402.17785)

    提出了ByteComposer代理框架，在模拟人类创作流程的基础上，将大型语言模型与符号音乐生成模型结合，实现了可与人类创作者相提并论的旋律创作代理。

    

    大型语言模型（Large Language Models，LLM）在多模态理解和生成任务中取得了令人鼓舞的进展。然而，如何设计一个人类对齐且可解释的旋律创作系统仍未得到充分探讨。为了解决这一问题，我们提出了ByteComposer，一个代理框架，模拟人类创作的四个独立步骤：“概念分析 - 起草作品 - 自我评估和修改 - 美学选择”。该框架将LLM的交互和知识理解特性与现有的符号音乐生成模型无缝融合，从而实现了一个可与人类创作者媲美的旋律创作代理。我们在GPT4和几个开源大型语言模型上进行了大量实验，证实了我们框架的有效性。此外，专业音乐作曲家参与了多维度评估，最终结果表明，在各个方面

    arXiv:2402.17785v1 Announce Type: cross  Abstract: Large Language Models (LLM) have shown encouraging progress in multimodal understanding and generation tasks. However, how to design a human-aligned and interpretable melody composition system is still under-explored. To solve this problem, we propose ByteComposer, an agent framework emulating a human's creative pipeline in four separate steps : "Conception Analysis - Draft Composition - Self-Evaluation and Modification - Aesthetic Selection". This framework seamlessly blends the interactive and knowledge-understanding features of LLMs with existing symbolic music generation models, thereby achieving a melody composition agent comparable to human creators. We conduct extensive experiments on GPT4 and several open-source large language models, which substantiate our framework's effectiveness. Furthermore, professional music composers were engaged in multi-dimensional evaluations, the final results demonstrated that across various facets
    
[^112]: 连续时间强化学习中深度残差网络的\emph{先验估计}

    A prior Estimates for Deep Residual Network in Continuous-time Reinforcement Learning

    [https://arxiv.org/abs/2402.16899](https://arxiv.org/abs/2402.16899)

    本研究针对连续时间控制问题，提出了一种可以直接分析Bellman最优损失\emph{先验}泛化误差的方法，避免了有界性假设，并通过最大算子的分解方法实现了损失函数的转换。

    

    深度强化学习在许多大规模实际应用中表现出色。然而，现有的性能分析忽略了连续时间控制问题的独特特征，无法直接估计Bellman最优损失的泛化误差，并且需要一个有界性假设。我们的工作侧重于连续时间控制问题，并提出了一种适用于所有满足半群和Lipschitz性质的问题的方法。在该方法下，我们能够直接分析Bellman最优损失的\emph{先验}泛化误差。该方法的核心在于损失函数的两次转换。为了完成转换，我们提出了最大算子的分解方法。此外，这个分析方法不需要有界性假设。最终我们维得到了一个没有“维度诅咒”的\emph{先验}泛化误差。

    arXiv:2402.16899v1 Announce Type: cross  Abstract: Deep reinforcement learning excels in numerous large-scale practical applications. However, existing performance analyses ignores the unique characteristics of continuous-time control problems, is unable to directly estimate the generalization error of the Bellman optimal loss and require a boundedness assumption. Our work focuses on continuous-time control problems and proposes a method that is applicable to all such problems where the transition function satisfies semi-group and Lipschitz properties. Under this method, we can directly analyze the \emph{a priori} generalization error of the Bellman optimal loss. The core of this method lies in two transformations of the loss function. To complete the transformation, we propose a decomposition method for the maximum operator. Additionally, this analysis method does not require a boundedness assumption. Finally, we obtain an \emph{a priori} generalization error without the curse of dime
    
[^113]: 在没有基准实况的情况下对大型语言模型进行排名

    Ranking Large Language Models without Ground Truth

    [https://arxiv.org/abs/2402.14860](https://arxiv.org/abs/2402.14860)

    不需要基准实况或参考响应的条件下，通过考虑模型的三元组来排名大型语言模型，并提出了两种排名方法。

    

    随着大型语言模型（LLMs）的普及和影响力的增强，评估和排名LLMs已成为一个重要问题。现有的评估方法要么需要获取昂贵的人类响应，要么使用LLMs成对地互相评估，这可能不够可靠。本文提供了一个新的视角，在给定一组提示数据集（比如问题、说明等）和一组LLMs的情况下，我们在没有任何基准实况或参考响应的情况下对它们进行排名。受到现实生活的启发，其中专家和有知识的人都能识别一个新手，我们的主要思路是考虑模型的三元组，其中每个模型评估其他两个模型，能够以很高的概率正确识别最差的模型。我们还分析了我们的想法并提供了成功的充分条件。通过反复应用这一想法，我们提出了两种对LLMs进行排名的方法。

    arXiv:2402.14860v1 Announce Type: cross  Abstract: Evaluation and ranking of large language models (LLMs) has become an important problem with the proliferation of these models and their impact. Evaluation methods either require human responses which are expensive to acquire or use pairs of LLMs to evaluate each other which can be unreliable. In this paper, we provide a novel perspective where, given a dataset of prompts (viz. questions, instructions, etc.) and a set of LLMs, we rank them without access to any ground truth or reference responses. Inspired by real life where both an expert and a knowledgeable person can identify a novice our main idea is to consider triplets of models, where each one of them evaluates the other two, correctly identifying the worst model in the triplet with high probability. We also analyze our idea and provide sufficient conditions for it to succeed. Applying this idea repeatedly, we propose two methods to rank LLMs. In experiments on different generati
    
[^114]: 强化学习辅助的变分量子算法量子架构搜索

    Reinforcement learning-assisted quantum architecture search for variational quantum algorithms

    [https://arxiv.org/abs/2402.13754](https://arxiv.org/abs/2402.13754)

    通过强化学习自动搜索变分电路的最佳结构，改善了VQAs的性能。

    

    在嘈杂中等规模量子（NISQ）时代，一个重要障碍是确定功能性量子电路。这些电路必须同时符合当前量子硬件限制所施加的约束。变分量子算法（VQA）是一类量子-经典优化算法，旨在解决当前可用量子设备中的这些挑战。本论文侧重于电路结构，通过使用强化学习（RL）自动搜索变分电路的最优结构，改善了VQAs的性能。论文内通过评估电路的深度、门和参数的总数以及准确性来确定电路的优越性。

    arXiv:2402.13754v1 Announce Type: cross  Abstract: A significant hurdle in the noisy intermediate-scale quantum (NISQ) era is identifying functional quantum circuits. These circuits must also adhere to the constraints imposed by current quantum hardware limitations. Variational quantum algorithms (VQAs), a class of quantum-classical optimization algorithms, were developed to address these challenges in the currently available quantum devices. However, the overall performance of VQAs depends on the initialization strategy of the variational circuit, the structure of the circuit (also known as ansatz), and the configuration of the cost function. Focusing on the structure of the circuit, in this thesis, we improve the performance of VQAs by automating the search for an optimal structure for the variational circuits using reinforcement learning (RL). Within the thesis, the optimality of a circuit is determined by evaluating its depth, the overall count of gates and parameters, and its accu
    
[^115]: 基于大型语言模型的混合推理在自动驾驶中的应用

    Hybrid Reasoning Based on Large Language Models for Autonomous Car Driving

    [https://arxiv.org/abs/2402.13602](https://arxiv.org/abs/2402.13602)

    大型语言模型在自动驾驶中的混合推理能力可以通过分析数据、理解规则和法则、提供语境等方式提高自动驶驶的决策能力。

    

    大型语言模型（LLMs）因其理解文本和图像、生成类人文本以及执行复杂推理任务的能力而受到广泛关注。然而，它们将这种高级推理与自然语言文本相结合以用于动态情况下的决策的泛化能力需要进一步探索。本研究探讨了LLMs在混合算术和常识推理方面的适应能力和应用能力，特别是在自动驾驶场景中。我们假设LLMs的混合推理能力可以通过使它们分析检测到的物体和传感器数据、理解驾驶规定和物理法则，并提供额外的语境来改善自动驾驶。这解决了复杂情景，如低能见度（由于天气条件）下的决策，传统方法可能不足以胜任。我们通过准确性评估基于大型语言模型（LLMs）的这种能力。

    arXiv:2402.13602v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have garnered significant attention for their ability to understand text and images, generate human-like text, and perform complex reasoning tasks. However, their ability to generalize this advanced reasoning with a combination of natural language text for decision-making in dynamic situations requires further exploration. In this study, we investigate how well LLMs can adapt and apply a combination of arithmetic and common-sense reasoning, particularly in autonomous driving scenarios. We hypothesize that LLMs hybrid reasoning abilities can improve autonomous driving by enabling them to analyze detected object and sensor data, understand driving regulations and physical laws, and offer additional context. This addresses complex scenarios, like decisions in low visibility (due to weather conditions), where traditional methods might fall short. We evaluated Large Language Models (LLMs) based on accuracy by co
    
[^116]: AnyGPT：统一的多模式离散序列建模语言模型

    AnyGPT: Unified Multimodal LLM with Discrete Sequence Modeling

    [https://arxiv.org/abs/2402.12226](https://arxiv.org/abs/2402.12226)

    AnyGPT是一个统一的多模态语言模型，通过离散表示实现各种模态的统一处理，能够在不改变大型语言模型架构或训练方式的情况下稳定训练，为新模态的无缝整合提供了可能。

    

    我们介绍了 AnyGPT，这是一个任意多模式语言模型，利用离散表示统一处理各种模态，包括语音、文本、图像和音乐。AnyGPT 可以稳定训练，无需对当前大型语言模型（LLM）架构或训练范式进行任何改动。相反，它仅依赖于数据级预处理，促进了新模态的无缝集成到LLM中，类似于新语言的整合。我们构建了一个多模式文本中心的数据集，用于多模式对齐预训练。利用生成模型，我们合成了第一个大规模任意多模式指令数据集。它包括108k个多轮对话示例，精细地交织各种模态，从而使模型能够处理多模态输入和输出的任意组合。实验结果表明，AnyGPT能够促进...

    arXiv:2402.12226v1 Announce Type: cross  Abstract: We introduce AnyGPT, an any-to-any multimodal language model that utilizes discrete representations for the unified processing of various modalities, including speech, text, images, and music. AnyGPT can be trained stably without any alterations to the current large language model (LLM) architecture or training paradigms. Instead, it relies exclusively on data-level preprocessing, facilitating the seamless integration of new modalities into LLMs, akin to the incorporation of new languages. We build a multimodal text-centric dataset for multimodal alignment pre-training. Utilizing generative models, we synthesize the first large-scale any-to-any multimodal instruction dataset. It consists of 108k samples of multi-turn conversations that intricately interweave various modalities, thus equipping the model to handle arbitrary combinations of multimodal inputs and outputs. Experimental results demonstrate that AnyGPT is capable of facilitat
    
[^117]: 图骨架：仅有约1%的节点足以表示十亿规模的图

    Graph-Skeleton: ~1% Nodes are Sufficient to Represent Billion-Scale Graph

    [https://arxiv.org/abs/2402.09565](https://arxiv.org/abs/2402.09565)

    本文探讨了如何从海量的Web图数据中对背景节点进行压缩，并将重点放在分析目标节点上，以解决图数据存储和计算能力的挑战。

    

    由于Web上图数据的普遍存在，Web图挖掘已成为热门研究领域。然而，在实际应用中，大规模Web图的普及给存储、计算能力和图模型设计带来了重大挑战。尽管已进行了大量的研究来提高图模型的可扩展性，但学术研究与实际Web图挖掘应用之间仍存在明显差距。其中一个主要原因是，在大多数工业场景中，实际上只需要分析Web图中的一小部分节点，我们将这些节点称为目标节点，其他节点称为背景节点。在本文中，我们认为从海量Web图数据中恰当地提取和压缩背景节点可能是解决问题的更经济的捷径。为此，我们首次尝试研究了目标节点分类的大规模背景节点压缩问题。

    arXiv:2402.09565v1 Announce Type: new  Abstract: Due to the ubiquity of graph data on the web, web graph mining has become a hot research spot. Nonetheless, the prevalence of large-scale web graphs in real applications poses significant challenges to storage, computational capacity and graph model design. Despite numerous studies to enhance the scalability of graph models, a noticeable gap remains between academic research and practical web graph mining applications. One major cause is that in most industrial scenarios, only a small part of nodes in a web graph are actually required to be analyzed, where we term these nodes as target nodes, while others as background nodes. In this paper, we argue that properly fetching and condensing the background nodes from massive web graph data might be a more economical shortcut to tackle the obstacles fundamentally. To this end, we make the first attempt to study the problem of massive background nodes compression for target nodes classification
    
[^118]: MUSTARD：掌握定理和证明数据的统一合成

    MUSTARD: Mastering Uniform Synthesis of Theorem and Proof Data

    [https://arxiv.org/abs/2402.08957](https://arxiv.org/abs/2402.08957)

    这项工作介绍了MUSTARD，一种掌握定理和证明数据统一合成的数据生成框架，通过三个阶段的合成，实现了高质量和多样化的问题和推理步骤的生成。

    

    最近，大型语言模型（LLMs）在各种任务中取得了显著进展，包括数学推理和定理证明。由于这两个任务需要严格和形式化的多步推理，它们是探索LLMs推理能力的吸引领域，但仍面临重要挑战。以前的研究如Chain-of-Thought（CoT）揭示了中间步骤指导的有效性。然而，这种逐步注释需要大量的劳动力，导致当前基准测试的训练步骤不足。为了填补这一空白，本研究引入了MUSTARD，一种数据生成框架，可以主导高质量和多样化的定理和证明数据的统一合成。MUSTARD通过三个阶段合成数据：（1）它随机选择几个数学概念作为问题的类别。（2）然后，它使用选定的概念提示生成性语言模型，以获得问题和它们的推理步骤。

    arXiv:2402.08957v1 Announce Type: new Abstract: Recent large language models (LLMs) have witnessed significant advancement in various tasks, including mathematical reasoning and theorem proving. As these two tasks require strict and formal multi-step inference, they are appealing domains for exploring the reasoning ability of LLMs but still face important challenges. Previous studies such as Chain-of-Thought (CoT) have revealed the effectiveness of intermediate steps guidance. However, such step-wise annotation requires heavy labor, leading to insufficient training steps for current benchmarks. To fill this gap, this work introduces MUSTARD, a data generation framework that masters uniform synthesis of theorem and proof data of high quality and diversity. MUSTARD synthesizes data in three stages: (1) It samples a few mathematical concept seeds as the problem category. (2) Then, it prompts a generative language model with the sampled concepts to obtain both the problems and their step-w
    
[^119]: 《读玩游戏（R2-Play）: 多模态游戏指导下的决策 Transformer》

    Read to Play (R2-Play): Decision Transformer with Multimodal Game Instruction

    [https://arxiv.org/abs/2402.04154](https://arxiv.org/abs/2402.04154)

    本论文探索了为智能体提供增强形式的任务指导，使其能够理解游戏指导并实现"读玩游戏"的能力。通过将多模态指导调优的成功应用于视觉任务中的强化学习任务，构建了一组... (内容太长，无法继续显示)

    

    在人工智能领域，开发一款通用智能体一直是一个长期的目标。先前的研究利用来自各种任务的大量离线数据集，在强化学习的多任务场景中表现出了出色的性能。然而，这些工作在扩展到新任务方面面临挑战。最近的方法将文本指导或视觉轨迹整合到决策网络中，提供任务特定的上下文提示，代表了一个有前途的方向。然而，观察到仅依赖于文本指导或视觉轨迹对于准确传达任务的上下文信息是不足够的。本文探索了增强智能体任务指导的形式，使其能够理解游戏指导，从而实现"读玩游戏"的能力。受到多模态指导调优在视觉任务中的成功启发，我们将基于视觉的强化学习任务视为一个长期视觉任务，并构建了一组... (内容太长，无法继续显示)

    Developing a generalist agent is a longstanding objective in artificial intelligence. Previous efforts utilizing extensive offline datasets from various tasks demonstrate remarkable performance in multitasking scenarios within Reinforcement Learning.However, these works encounter challenges in extending their capabilities to new tasks.Recent approaches integrate textual guidance or visual trajectory into decision networks to provide task-specific contextual cues, representing a promising direction.However, it is observed that relying solely on textual guidance or visual trajectory is insufficient for accurately conveying the contextual information of tasks.This paper explores enhanced forms of task guidance for agents, enabling them to comprehend gameplay instructions, thereby facilitating a "read-to-play" capability.Drawing inspiration from the success of multimodal instruction tuning in visual tasks, we treat the visual-based RL task as a long-horizon vision task and construct a set 
    
[^120]: 大型语言模型能否取代经济选择预测实验室？

    Can Large Language Models Replace Economic Choice Prediction Labs?

    [https://arxiv.org/abs/2401.17435](https://arxiv.org/abs/2401.17435)

    该论文研究大型语言模型是否能够取代经济实验室进行选择预测，并通过相关实验证明了其可行性。

    

    经济选择预测是一项具有挑战性的重要任务，往往受限于获取人类选择数据的困难。实验经济学研究在很大程度上专注于简单的选择环境。最近，人工智能界以两种方式为该努力做出了贡献：考虑大型语言模型是否可以代替人类在上述简单选择预测环境中，以及通过机器学习视角研究更复杂但仍严格的实验经济学环境，包括不完全信息、重复博弈和基于自然语言交流的说服游戏。这引发了一个重要的灵感：大型语言模型是否能够完全模拟经济环境，并生成用于高效人类选择预测的数据，替代复杂的经济实验室研究？我们在这个主题上开创了研究，并展示了其可行性。特别是，我们表明仅在大型语言模型生成的数据上训练的模型可以有效地进行预测。

    Economic choice prediction is an essential challenging task, often constrained by the difficulties in acquiring human choice data. Indeed, experimental economics studies had focused mostly on simple choice settings. The AI community has recently contributed to that effort in two ways: considering whether LLMs can substitute for humans in the above-mentioned simple choice prediction settings, and the study through ML lens of more elaborated but still rigorous experimental economics settings, employing incomplete information, repetitive play, and natural language communication, notably language-based persuasion games. This leaves us with a major inspiration: can LLMs be used to fully simulate the economic environment and generate data for efficient human choice prediction, substituting for the elaborated economic lab studies? We pioneer the study of this subject, demonstrating its feasibility. In particular, we show that a model trained solely on LLM-generated data can effectively predic
    
[^121]: DurFlex-EVC: 具有并行生成的持续灵活情绪语音转换

    DurFlex-EVC: Duration-Flexible Emotional Voice Conversion with Parallel Generation

    [https://arxiv.org/abs/2401.08095](https://arxiv.org/abs/2401.08095)

    DurFlex-EVC通过引入风格自编码器和交叉注意力，解决了传统情绪语音转换模型中对语言和语音信息的同步问题。

    

    情绪语音转换（EVC）旨在修改说话者声音的情绪色彩，同时保留原始的语言内容和说话者独特的声音特征。最近EVC的进展涉及同时建模音高和持续时间，利用序列到序列（seq2seq）模型的潜力。为了增强转换的可靠性和效率，本研究将重点转向并行语音生成。我们介绍了DurFlex-EVC，它集成了风格自编码器和单元对齐器。传统模型虽然融入了包含语言和语音信息的自监督学习（SSL）表示，但却忽视了这种双重性质，导致了可控性的降低。为了解决这个问题，我们实现了交叉注意力以将这些表示与不同情绪进行同步。此外，我们还开发了一个风格自编码器。

    arXiv:2401.08095v2 Announce Type: replace-cross  Abstract: Emotional voice conversion (EVC) seeks to modify the emotional tone of a speaker's voice while preserving the original linguistic content and the speaker's unique vocal characteristics. Recent advancements in EVC have involved the simultaneous modeling of pitch and duration, utilizing the potential of sequence-to-sequence (seq2seq) models. To enhance reliability and efficiency in conversion, this study shifts focus towards parallel speech generation. We introduce Duration-Flexible EVC (DurFlex-EVC), which integrates a style autoencoder and unit aligner. Traditional models, while incorporating self-supervised learning (SSL) representations that contain both linguistic and paralinguistic information, have neglected this dual nature, leading to reduced controllability. Addressing this issue, we implement cross-attention to synchronize these representations with various emotions. Additionally, a style autoencoder is developed for t
    
[^122]: Transformer多元预测：少即是多？

    Transformer Multivariate Forecasting: Less is More?

    [https://arxiv.org/abs/2401.00230](https://arxiv.org/abs/2401.00230)

    本文致力于通过引入主成分分析（PCA）来优化Transformer预测框架，以减少冗余信息并提高预测准确性和运行效率。

    

    在多元预测领域，Transformer模型作为强大的工具脱颖而出，展现出在处理来自真实场景中杂乱数据集方面的异常能力。然而，这些数据集的固有复杂性，以众多变量和漫长时间序列为特征，带来挑战，包括增加的噪音和延长的模型运行时间。本文旨在通过减少冗余信息来提高预测精度，同时优化运行时间效率。我们提出了一种新颖的Transformer预测框架，通过主成分分析（PCA）来解决这一挑战。该框架通过五种最先进的模型和四个不同的真实数据集进行评估。我们的实验结果表明，该框架能够在所有模型和数据集上减少预测误差的能力，同时显著降低运行时间。

    arXiv:2401.00230v2 Announce Type: replace-cross  Abstract: In the domain of multivariate forecasting, transformer models stand out as powerful apparatus, displaying exceptional capabilities in handling messy datasets from real-world contexts. However, the inherent complexity of these datasets, characterized by numerous variables and lengthy temporal sequences, poses challenges, including increased noise and extended model runtime. This paper focuses on reducing redundant information to elevate forecasting accuracy while optimizing runtime efficiency. We propose a novel transformer forecasting framework enhanced by Principal Component Analysis (PCA) to tackle this challenge. The framework is evaluated by five state-of-the-art (SOTA) models and four diverse real-world datasets. Our experimental results demonstrate the framework's ability to minimize prediction errors across all models and datasets while significantly reducing runtime. From the model perspective, one of the PCA-enhanced m
    
[^123]: 多智能体强化学习用于评估交通网络中的虚假数据注入攻击

    Multi-Agent Reinforcement Learning for Assessing False-Data Injection Attacks on Transportation Networks

    [https://arxiv.org/abs/2312.14625](https://arxiv.org/abs/2312.14625)

    引入了一个计算框架，利用多智能体强化学习来找到针对交通网络的最坏情况数据注入攻击，以评估虚假数据注入攻击对交通网络的威胁。

    

    驾驶员对导航应用程序的日益依赖使得交通网络更容易受到恶意行为者的数据篡改攻击的影响。对手可能利用导航服务的数据收集或处理方面的漏洞来注入虚假信息，从而干扰驾驶员的路径选择。这种攻击可能显著增加交通拥堵，导致时间和资源的大量浪费，甚至可能破坏依赖道路网络的基本服务。为了评估此类攻击带来的威胁，我们引入了一个计算框架来发现针对交通网络的最坏情况数据注入攻击。首先，我们设计了一个拥有威胁行为者的对抗模型，该行为者可以通过增加驾驶员在某些道路上感知的行驶时间来操纵他们。然后，我们采用分层多智能体强化学习来找到一种近似最佳的对抗策略。

    arXiv:2312.14625v2 Announce Type: replace  Abstract: The increasing reliance of drivers on navigation applications has made transportation networks more susceptible to data-manipulation attacks by malicious actors. Adversaries may exploit vulnerabilities in the data collection or processing of navigation services to inject false information, and to thus interfere with the drivers' route selection. Such attacks can significantly increase traffic congestions, resulting in substantial waste of time and resources, and may even disrupt essential services that rely on road networks. To assess the threat posed by such attacks, we introduce a computational framework to find worst-case data-injection attacks against transportation networks. First, we devise an adversarial model with a threat actor who can manipulate drivers by increasing the travel times that they perceive on certain roads. Then, we employ hierarchical multi-agent reinforcement learning to find an approximate optimal adversaria
    
[^124]: 通过对比激活加法指导Llama 2

    Steering Llama 2 via Contrastive Activation Addition

    [https://arxiv.org/abs/2312.06681](https://arxiv.org/abs/2312.06681)

    引入Contrastive Activation Addition（CAA）方法，通过修改语言模型的激活来精确控制目标行为的程度，显著改变模型行为并在微调和系统提示设计的基础上提供额外有效性。

    

    我们引入了一种创新的方法Contrastive Activation Addition（CAA），用于通过在前向传递过程中修改其激活来指导语言模型。CAA通过对某种行为的正面和负面示例之间残差流激活的差异求平均，计算出“指导向量”。在推断过程中，在用户提示后的所有token位置上以正负系数添加这些指导向量，从而精确控制目标行为的程度。我们通过使用多项选择行为问题数据集和开放式生成任务在Llama 2 Chat上评估了CAA的有效性。我们证明CAA显着改变了模型行为，不仅在传统方法如微调和系统提示设计的基础上有效，而且最小程度地降低了功能。此外，我们对模型的行为做出了更深入的洞察。

    arXiv:2312.06681v3 Announce Type: replace-cross  Abstract: We introduce Contrastive Activation Addition (CAA), an innovative method for steering language models by modifying their activations during forward passes. CAA computes "steering vectors" by averaging the difference in residual stream activations between pairs of positive and negative examples of a particular behavior, such as factual versus hallucinatory responses. During inference, these steering vectors are added at all token positions after the user's prompt with either a positive or negative coefficient, allowing precise control over the degree of the targeted behavior. We evaluate CAA's effectiveness on Llama 2 Chat using multiple-choice behavioral question datasets and open-ended generation tasks. We demonstrate that CAA significantly alters model behavior, is effective over and on top of traditional methods like finetuning and system prompt design, and minimally reduces capabilities. Moreover, we gain deeper insights in
    
[^125]: 通过多样化合成和扩散模型减轻偏见

    Mitigating Biases with Diverse Ensembles and Diffusion Models

    [https://arxiv.org/abs/2311.16176](https://arxiv.org/abs/2311.16176)

    通过利用扩散概率模型（DPMs）生成新特征组合的图像，可以在集成模型中增加模型多样性，并减轻捷径偏见，而无需额外监督信号。

    

    数据中的虚假相关性，即多个线索可以预测目标标签，常常导致一种称为捷径偏见的现象，即模型依赖于错误的、易学的线索，而忽略可靠的线索。在这项工作中，我们提出了一种利用扩散概率模型（DPMs）的集成多样化框架，用于减轻捷径偏见。我们展示了在特定的训练间隔中，DPMs可以生成具有新特征组合的图像，即使在显示相关输入特征的样本上进行训练。我们利用这一关键属性通过集成不一致性生成合成反事实来增加模型的多样性。我们展示了DPM引导的多样化足以消除对主要捷径线索的依赖，无需额外的监督信号。我们进一步在几个多样化目标上在实证上量化其有效性，并最终展示了改进的泛化性能。

    arXiv:2311.16176v2 Announce Type: replace-cross  Abstract: Spurious correlations in the data, where multiple cues are predictive of the target labels, often lead to a phenomenon known as shortcut bias, where a model relies on erroneous, easy-to-learn cues while ignoring reliable ones. In this work, we propose an ensemble diversification framework exploiting Diffusion Probabilistic Models (DPMs) for shortcut bias mitigation. We show that at particular training intervals, DPMs can generate images with novel feature combinations, even when trained on samples displaying correlated input features. We leverage this crucial property to generate synthetic counterfactuals to increase model diversity via ensemble disagreement. We show that DPM-guided diversification is sufficient to remove dependence on primary shortcut cues, without a need for additional supervised signals. We further empirically quantify its efficacy on several diversification objectives, and finally show improved generalizati
    
[^126]: InteRACT：基于机器人动作的人类意图预测的Transformer模型

    InteRACT: Transformer Models for Human Intent Prediction Conditioned on Robot Actions

    [https://arxiv.org/abs/2311.12943](https://arxiv.org/abs/2311.12943)

    InteRACT通过在大型人类-人类数据集上预训练条件意图预测模型，并在小型人机数据集上微调，解决了人机交互中的先有鸡还是先有蛋问题。

    

    在协作的人机操纵中，机器人必须预测人类意图并相应调整其行动，以平稳执行任务。然而，人类的意图反过来又取决于机器人采取的动作，造成了一个先有鸡还是先有蛋的问题。先前的方法忽略了这种相互依赖关系，而是训练独立于机器人行动的边际意图预测模型。这是因为在缺乏配对的人机交互数据集的情况下，训练条件模型是困难的。我们能否转而利用更容易获取的大规模人类-人类交互数据？我们的关键见解是利用人类和机器人行动之间的对应关系，实现从人类-人类到人类-机器人数据的迁移学习。我们提出了一种新颖的架构InteRACT，该架构在大型人类-人类数据集上预训练条件意图预测模型，并在小型人机数据集上进行微调。我们在一组真实世界的协作数据上进行评估。

    arXiv:2311.12943v2 Announce Type: replace-cross  Abstract: In collaborative human-robot manipulation, a robot must predict human intents and adapt its actions accordingly to smoothly execute tasks. However, the human's intent in turn depends on actions the robot takes, creating a chicken-or-egg problem. Prior methods ignore such inter-dependency and instead train marginal intent prediction models independent of robot actions. This is because training conditional models is hard given a lack of paired human-robot interaction datasets. Can we instead leverage large-scale human-human interaction data that is more easily accessible? Our key insight is to exploit a correspondence between human and robot actions that enables transfer learning from human-human to human-robot data. We propose a novel architecture, InteRACT, that pre-trains a conditional intent prediction model on large human-human datasets and fine-tunes on a small human-robot dataset. We evaluate on a set of real-world collabo
    
[^127]: 在自然语言交互指令环境中解释用户请求

    Interpreting User Requests in the Context of Natural Language Standing Instructions

    [https://arxiv.org/abs/2311.09796](https://arxiv.org/abs/2311.09796)

    在使用大型语言模型的自然语言接口时，本研究提出了一种基于用户常设指令的对话建模方法，通过将用户的约束和偏好作为上下文，从而在类似请求中实现自动化。

    

    自然语言接口的用户通常由大型语言模型（LLMs）驱动，并且经常必须在每次进行类似请求时重复他们的偏好。我们描述了一种基于LLM的对话建模方法，其中持久的用户约束和偏好 - 统称为常设指令 - 作为这种接口的额外上下文。例如，当用户说“我饿了”时，先前表达的波斯食物偏好可以自动添加到LLM提示中，影响搜索相关餐馆。我们开发了NLSI，一个包含超过2.4K跨越17个领域的对话的语言到程序数据集，其中每个对话都与用户配置文件（一组用户特定的常设指令）和相应的结构化表示形式（API调用）配对。 NLSI的一个关键挑战是确定哪些常设指令子集适用于给定的对话。

    arXiv:2311.09796v2 Announce Type: replace-cross  Abstract: Users of natural language interfaces, generally powered by Large Language Models (LLMs),often must repeat their preferences each time they make a similar request. We describe an approach to LLM-based dialogue modeling in which persistent user constraints and preferences -- collectively termed standing instructions -- as additional context for such interfaces. For example, when a user states "I'm hungry", a previously expressed preference for Persian food can be automatically added to the LLM prompt, influencing the search for relevant restaurants. We develop NLSI, a language-to-program dataset consisting of over 2.4K dialogues spanning 17 domains, where each dialogue is paired with a user profile (a set of users specific standing instructions) and corresponding structured representations (API calls). A key challenge in NLSI is to identify which subset of the standing instructions is applicable to a given dialogue. NLSI contains
    
[^128]: SkelVIT：轻量级基于骨骼的动作识别系统的视觉变压器共识

    SkelVIT: Consensus of Vision Transformers for a Lightweight Skeleton-Based Action Recognition System

    [https://arxiv.org/abs/2311.08094](https://arxiv.org/abs/2311.08094)

    本研究考察了VIT对基于骨骼的动作识别的有效性，并提出了一种三级架构SkelVit，该架构能够形成一组伪图像，并在每个表示上应用分类器，然后结合它们的结果来找到动作识别系统中的最佳表现。

    

    骨骼基础动作识别引起了许多研究人员的关注，因为它对视角和光照变化具有鲁棒性，并且其处理比视频帧的处理效率高得多。随着深度学习模型的出现，以伪图像形式表示骨架数据并应用CNN进行动作识别变得非常流行。因此，研究集中在寻找形成伪图像的有效方法上。最近，注意力网络，更具体地说是变压器，在各种视觉问题中提供了有希望的结果。本研究考察了VIT对基于骨架的动作识别的有效性，并研究了其在伪图像表示方案上的稳健性。为此，提出了一个三级架构，SkelVit，它形成一组伪图像，对每个表示应用分类器，并结合它们的结果以找到f

    arXiv:2311.08094v2 Announce Type: replace-cross  Abstract: Skeleton-based action recognition receives the attention of many researchers as it is robust to viewpoint and illumination changes, and its processing is much more efficient than the processing of video frames. With the emergence of deep learning models, it has become very popular to represent the skeleton data in pseudo-image form and apply CNN for action recognition. Thereafter, studies concentrated on finding effective methods for forming pseudo-images. Recently, attention networks, more specifically transformers have provided promising results in various vision problems. In this study, the effectiveness of VIT for skeleton-based action recognition is examined and its robustness on the pseudo-image representation scheme is investigated. To this end, a three-level architecture, SkelVit is proposed, which forms a set of pseudo images, applies a classifier on each of the representations, and combines their results to find the f
    
[^129]: 使用大型语言模型对用户浏览流进行建模以进行文章推荐

    Modeling User Viewing Flow Using Large Language Models for Article Recommendation

    [https://arxiv.org/abs/2311.07619](https://arxiv.org/abs/2311.07619)

    本文提出了SINGLE方法，使用大型语言模型对用户浏览流进行建模，以更好地进行文章推荐。

    

    本文提出了用户浏览流建模（SINGLE）方法用于文章推荐任务，该方法从用户点击的文章中模拟用户的持续偏好和即时兴趣。具体而言，我们首先采用用户持续浏览流建模方法总结用户的一般兴趣以推荐文章。在这种情况下，我们利用大型语言模型（LLMs）从先前点击的文章中捕捉用户的持续偏好，如技能和职位。然后我们设计用户即时浏览流建模方法来构建用户点击的文章历史与候选文章之间的交互。它专注于阅读用户点击文章的表示，并旨在学习用户不同的兴趣观点以匹配候选文章。我们在阿里巴巴技术协会（ATA）网站上的实验结果显示SINGLE的优势，相较于先前的基线实现了2.4%的改进。

    arXiv:2311.07619v2 Announce Type: replace-cross  Abstract: This paper proposes the User Viewing Flow Modeling (SINGLE) method for the article recommendation task, which models the user constant preference and instant interest from user-clicked articles. Specifically, we first employ a user constant viewing flow modeling method to summarize the user's general interest to recommend articles. In this case, we utilize Large Language Models (LLMs) to capture constant user preferences from previously clicked articles, such as skills and positions. Then we design the user instant viewing flow modeling method to build interactions between user-clicked article history and candidate articles. It attentively reads the representations of user-clicked articles and aims to learn the user's different interest views to match the candidate article. Our experimental results on the Alibaba Technology Association (ATA) website show the advantage of SINGLE, achieving a 2.4% improvement over previous baseli
    
[^130]: LLM能遵守简单规则吗?

    Can LLMs Follow Simple Rules?

    [https://arxiv.org/abs/2311.04235](https://arxiv.org/abs/2311.04235)

    提出了一个名为RuLES的程序框架，用于衡量LLMs在与用户交互时遵守规则的能力。

    

    随着大型语言模型（LLMs）在现实世界中承担越来越多的责任，能够以可靠的方式指定和约束这些系统的行为变得至关重要。我们提出了规则遵循语言评估场景（RuLES），这是一个测量LLMs遵循规则能力的程序框架，包括14个简单的文本场景，模型在与用户交互时被指示遵守各种规则。

    arXiv:2311.04235v2 Announce Type: replace  Abstract: As Large Language Models (LLMs) are deployed with increasing real-world responsibilities, it is important to be able to specify and constrain the behavior of these systems in a reliable manner. Model developers may wish to set explicit rules for the model, such as "do not generate abusive content", but these may be circumvented by jailbreaking techniques. Existing evaluations of adversarial attacks and defenses on LLMs generally require either expensive manual review or unreliable heuristic checks. To address this issue, we propose Rule-following Language Evaluation Scenarios (RuLES), a programmatic framework for measuring rule-following ability in LLMs. RuLES consists of 14 simple text scenarios in which the model is instructed to obey various rules while interacting with the user. Each scenario has a programmatic evaluation function to determine whether the model has broken any rules in a conversation. Our evaluations of proprietar
    
[^131]: VeCLIP：通过富含视觉信息的标题改进CLIP训练

    VeCLIP: Improving CLIP Training via Visual-enriched Captions

    [https://arxiv.org/abs/2310.07699](https://arxiv.org/abs/2310.07699)

    本研究提出了一种通过将视觉概念融入标题中的方式来改进CLIP训练的方法，名为VeCLIP，该方法在大规模网络爬取数据集上展示了良好的性能。

    

    大规模网络爬取数据集对于预训练视觉-语言模型（如CLIP）的成功至关重要。然而，网络爬取的AltTexts存在固有的噪音和潜在的不相关性，造成了精确的图像-文字对齐方面的挑战。本研究引入了一种适用于嘈杂标题重写的可扩展流程。与利用大型语言模型（LLMs）进行标题重写的现有方法在小型策划数据集（如CC3M和CC12M）上已经显示出了希望。我们强调将视觉概念融入标题中，称为富含视觉信息的标题（VeCap），以确保数据多样性。为了优化AltTexts与新生成的VeCap的利用，我们提出了一种新颖的混合训练方案。我们展示了该方法在大规模网络爬取数据集上训练CLIP的适应性，称为VeCLIP。通过使用这种经济有效的流程，我们轻松扩展了我们的实验。

    arXiv:2310.07699v2 Announce Type: replace-cross  Abstract: Large-scale web-crawled datasets are fundamental for the success of pre-training vision-language models, such as CLIP. However, the inherent noise and potential irrelevance of web-crawled AltTexts pose challenges in achieving precise image-text alignment. Existing methods utilizing large language models (LLMs) for caption rewriting have shown promise on small, curated datasets like CC3M and CC12M. This study introduces a scalable pipeline for noisy caption rewriting. Unlike recent LLM rewriting techniques, we emphasize the incorporation of visual concepts into captions, termed as Visual-enriched Captions (VeCap). To ensure data diversity, we propose a novel mixed training scheme that optimizes the utilization of AltTexts alongside newly generated VeCap. We showcase the adaptation of this method for training CLIP on large-scale web-crawled datasets, termed VeCLIP. Employing this cost-effective pipeline, we effortlessly scale our
    
[^132]: 量化因果出现的原因：因果结构中不确定性和不对称性的关键条件

    Quantify the Causes of Causal Emergence: Critical Conditions of Uncertainty and Asymmetry in Causal Structure

    [https://arxiv.org/abs/2212.01551](https://arxiv.org/abs/2212.01551)

    介绍了一种根据有效信息和转移概率矩阵的量化框架，用于评估因果出现的数值条件作为其发生的理论约束。

    

    有益于先进计算设备，具有大量参数的模型越来越被用来提取更多信息，以增强描述和预测客观系统模式的精度。近年来，基于统计和信息理论对因果关系的研究给大规模模型提出了有趣且有价值的挑战。具有较少参数的宏观模型可以在有效表示系统方面胜过具有更多参数的微观模型。这种有价值的情况被称为“因果出现”。本文引入了一个量化框架，根据有效信息和转移概率矩阵，用于评估因果出现的数值条件作为其发生的理论约束。

    arXiv:2212.01551v3 Announce Type: replace-cross  Abstract: Beneficial to advanced computing devices, models with massive parameters are increasingly employed to extract more information to enhance the precision in describing and predicting the patterns of objective systems. This phenomenon is particularly pronounced in research domains associated with deep learning. However, investigations of causal relationships based on statistical and informational theories have posed an interesting and valuable challenge to large-scale models in the recent decade. Macroscopic models with fewer parameters can outperform their microscopic counterparts with more parameters in effectively representing the system. This valuable situation is called "Causal Emergence." This paper introduces a quantification framework, according to the Effective Information and Transition Probability Matrix, for assessing numerical conditions of Causal Emergence as theoretical constraints of its occurrence. Specifically, o
    
[^133]: 利用节能加速计对攀岩路线进行聚类

    Climbing Routes Clustering Using Energy-Efficient Accelerometers Attached to the Quickdraws

    [https://arxiv.org/abs/2211.02680](https://arxiv.org/abs/2211.02680)

    利用节能加速计对攀岩路线进行聚类，为攀岩健身房提供了改善服务和最大程度利用基础设施的新方法

    

    攀岩健身房面临的挑战之一是找出受欢迎的攀登路线，以改善他们的服务并最大程度地利用他们的基础设施。为了解决这个问题，开发了一种硬件原型来收集数据，该原型使用附加到墙壁上的攀岩设备的加速计传感器，称为快挂，将攀岩绳连接到螺栓锚点。相应的传感器被配置为节能，因此在攀岩健身房大量使用时，在费用和更换时间上变得实用。本文描述了硬件规格，研究了传感器在超低功耗模式下测量的数据，检测了攀登不同路线过程中数据中的模式，并开发了一种无监督的路线聚类方法。

    arXiv:2211.02680v2 Announce Type: replace-cross  Abstract: One of the challenges for climbing gyms is to find out popular routes for the climbers to improve their services and optimally use their infrastructure. This problem must be addressed preserving both the privacy and convenience of the climbers and the costs of the gyms. To this aim, a hardware prototype is developed to collect data using accelerometer sensors attached to a piece of climbing equipment mounted on the wall, called quickdraw, that connects the climbing rope to the bolt anchors. The corresponding sensors are configured to be energy-efficient, hence becoming practical in terms of expenses and time consumption for replacement when used in large quantities in a climbing gym. This paper describes hardware specifications, studies data measured by the sensors in ultra-low power mode, detect patterns in data during climbing different routes, and develops an unsupervised approach for route clustering.
    
[^134]: 交互式问答系统：文献综述

    Interactive Question Answering Systems: Literature Review

    [https://arxiv.org/abs/2209.01621](https://arxiv.org/abs/2209.01621)

    交互式问答系统是问答和对话系统的结合，用户可以用自然语言提问并与系统动态交互，获得更精确的结果。

    

    arXiv:2209.01621v2 公告类型: 替换-跨  摘要: 问答系统被公认为在网络上寻求信息的流行且有效的手段。在这种系统中，信息寻找者可以通过用自然语言提出问题来获得简洁的回答。交互式问答是最近提出的并越来越流行的解决方案，位于问答和对话系统的交集处。一方面，用户可以用普通语言提问并找到她问题的实际回答；另一方面，如果初始请求中存在多个可能的回复、很少或模棱两可，系统可以将问答会话延长为对话。通过允许用户提出更多问题，交互式问答使用户能够动态地与系统交互并获得更精确的结果。本综述提供了交互式问答系统的详细概述。

    arXiv:2209.01621v2 Announce Type: replace-cross  Abstract: Question answering systems are recognized as popular and frequently effective means of information seeking on the web. In such systems, information seekers can receive a concise response to their query by presenting their questions in natural language. Interactive question answering is a recently proposed and increasingly popular solution that resides at the intersection of question answering and dialogue systems. On the one hand, the user can ask questions in normal language and locate the actual response to her inquiry; on the other hand, the system can prolong the question-answering session into a dialogue if there are multiple probable replies, very few, or ambiguities in the initial request. By permitting the user to ask more questions, interactive question answering enables users to dynamically interact with the system and receive more precise results. This survey offers a detailed overview of the interactive question-ans
    
[^135]: 手机、音节和单词能否作为跨情境视听学习的副产品而出现？-- 一项计算研究

    Can phones, syllables, and words emerge as side-products of cross-situational audiovisual learning? -- A computational investigation

    [https://arxiv.org/abs/2109.14200](https://arxiv.org/abs/2109.14200)

    研究探讨了语言学习中，通过跨情境视听学习，音素、音节和单词能否作为副产品出现，并支持不同形式表征间的转换。

    

    数十年的研究探讨了语言学习婴儿如何学会区分语音，分割单词，以及将单词与其含义关联起来。尽管这些能力的逐渐发展是毋庸置疑的，但这些技能的确切性质和潜在的心理表征仍然不清楚。与此同时，计算研究表明，通过语音和同时具有指称不明确的视觉输入之间的统计学习，可以实现对基本语音的理解。这些模型可以在没有诸如语言单位的表征，以及没有专门针对这些单位的学习机制的情况下运行。这引发了一个问题，即在多大程度上，类似音素、音节和单词的语言单位的知识实际上能够作为潜在表征出现，支持语音与其他形式表征之间的转换，而不需要专门的学习机制来实现。

    arXiv:2109.14200v2 Announce Type: replace-cross  Abstract: Decades of research has studied how language learning infants learn to discriminate speech sounds, segment words, and associate words with their meanings. While gradual development of such capabilities is unquestionable, the exact nature of these skills and the underlying mental representations yet remains unclear. In parallel, computational studies have shown that basic comprehension of speech can be achieved by statistical learning between speech and concurrent referentially ambiguous visual input. These models can operate without prior linguistic knowledge such as representations of linguistic units, and without learning mechanisms specifically targeted at such units. This has raised the question of to what extent knowledge of linguistic units, such as phone(me)s, syllables, and words, could actually emerge as latent representations supporting the translation between speech and representations in other modalities, and withou
    
[^136]: 打字疗法：大型语言模型聊天机器人在心理健康支持中的应用经验

    The Typing Cure: Experiences with Large Language Model Chatbots for Mental Health Support. (arXiv:2401.14362v1 [cs.HC])

    [http://arxiv.org/abs/2401.14362](http://arxiv.org/abs/2401.14362)

    本研究通过调查使用大型语言模型聊天机器人进行心理健康支持的人的经历，分析了用户如何为聊天机器人创建独特的支持角色，并介绍了在心理健康背景下将人工智能与治疗价值观相匹配的概念。研究提供了设计师处理伦理问题的建议。

    

    越来越多的人使用大型语言模型（LLM）聊天机器人作为心理健康支持工具，但有证据表明通用型LLM聊天机器人也存在一定风险，如果设计不负责任可能会危及用户的福祉。本研究调查了使用LLM聊天机器人进行心理健康支持的人的真实经历。我们通过对来自不同国家背景的21个个人进行访谈，分析了用户如何为他们的聊天机器人创建独特的支持角色，填补日常护理的空白，并在寻求来自聊天机器人的支持时如何导航相关的文化限制。我们将分析基于心理治疗文献中有效支持的概念，并引入了AI与心理健康背景下的治疗价值观对其进行匹配的概念。我们的研究提供了设计师如何处理伦理问题的建议。

    People experiencing severe distress increasingly use Large Language Model (LLM) chatbots as mental health support tools. Discussions on social media have described how engagements were lifesaving for some, but evidence suggests that general-purpose LLM chatbots also have notable risks that could endanger the welfare of users if not designed responsibly. In this study, we investigate the lived experiences of people who have used LLM chatbots for mental health support. We build on interviews with 21 individuals from globally diverse backgrounds to analyze how users create unique support roles for their chatbots, fill in gaps in everyday care, and navigate associated cultural limitations when seeking support from chatbots. We ground our analysis in psychotherapy literature around effective support, and introduce the concept of therapeutic alignment, or aligning AI with therapeutic values for mental health contexts. Our study offers recommendations for how designers can approach the ethica
    
[^137]: Q&A提示：通过挖掘问题-回答提示来发现丰富的视觉线索，以满足对多样世界知识的视觉问答的需求

    Q&A Prompts: Discovering Rich Visual Clues through Mining Question-Answer Prompts for VQA requiring Diverse World Knowledge. (arXiv:2401.10712v1 [cs.CV])

    [http://arxiv.org/abs/2401.10712](http://arxiv.org/abs/2401.10712)

    本论文提出了一种叫做Q&A提示的方法，通过挖掘图像中的问题-回答对来发现丰富的视觉线索，以帮助AI模型更好地理解复杂视觉问题，提高跨模态推理能力。

    

    随着多模态大型语言模型的突破，回答需要高级推理能力和世界知识的复杂视觉问题比以往任何时候都更重要。然而，为AI模型配备强大的跨模态推理能力仍然具有挑战性，因为人类的认知方案尚未系统地被理解。在本文中，我们相信，如果我们能尽可能收集给定图像中的视觉线索，我们将能更准确地识别图像，更好地理解问题，更容易回忆相关知识，并最终推理出答案。我们通过在图像中挖掘问题-回答对来发现这些丰富的视觉线索，并将它们作为提示发送到多模态大型语言模型中。我们称之为Q&A提示的方法。具体而言，我们首先使用训练集中的图像-答案对和相应的问题作为输入和输出来训练一个视觉问题生成模型。

    With the breakthrough of multi-modal large language models, answering complex visual questions that demand advanced reasoning abilities and world knowledge has become a much more important testbed for developing AI models than ever. However, equipping AI models with robust cross-modality reasoning ability remains challenging since the cognition scheme of humans has not been understood systematically. In this paper, we believe that if we can collect visual clues in the given image as much as possible, we will recognize the image more accurately, understand the question better, recall relevant knowledge more easily, and finally reason out the answer. We discover these rich visual clues by mining question-answer pairs in images and sending them into multi-modal large language models as prompts. We call the proposed method Q&A Prompts. Specifically, we first use the image-answer pairs and the corresponding questions in the training set as inputs and outputs to train a visual question gener
    
[^138]: 使用感知损失的扩散模型

    Diffusion Model with Perceptual Loss. (arXiv:2401.00110v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2401.00110](http://arxiv.org/abs/2401.00110)

    本研究介绍了一种使用感知损失的扩散模型，通过无分类器指导实现了生成更真实样本的目的。

    

    使用均方误差损失训练的扩散模型倾向于生成不真实的样本。目前的最先进模型依靠无分类器指导来改善样本质量，然而其惊人的效果尚未完全理解。本文中，我们展示了无分类器指导的有效性在一定程度上源自其作为一种隐式感知指导的形式。因此，我们可以直接在扩散训练中加入感知损失来提高样本质量。由于扩散训练中使用的分数匹配目标与无监督训练感知网络时使用的去噪自动编码器目标非常相似，因此扩散模型本身就是一个感知网络，并可以用于生成有意义的感知损失。我们提出了一种新颖的自感知目标，其结果是扩散模型能够生成更真实的样本。对于条件生成，我们的方法仅改善样本质量，而不与条件绑定。

    Diffusion models trained with mean squared error loss tend to generate unrealistic samples. Current state-of-the-art models rely on classifier-free guidance to improve sample quality, yet its surprising effectiveness is not fully understood. In this paper, We show that the effectiveness of classifier-free guidance partly originates from it being a form of implicit perceptual guidance. As a result, we can directly incorporate perceptual loss in diffusion training to improve sample quality. Since the score matching objective used in diffusion training strongly resembles the denoising autoencoder objective used in unsupervised training of perceptual networks, the diffusion model itself is a perceptual network and can be used to generate meaningful perceptual loss. We propose a novel self-perceptual objective that results in diffusion models capable of generating more realistic samples. For conditional generation, our method only improves sample quality without entanglement with the condit
    
[^139]: 大型地图上的按需城市出行问题的近似多智能体强化学习（扩展版）

    Approximate Multiagent Reinforcement Learning for On-Demand Urban Mobility Problem on a Large Map (extended version). (arXiv:2311.01534v1 [cs.MA])

    [http://arxiv.org/abs/2311.01534](http://arxiv.org/abs/2311.01534)

    本文研究了大型城市环境下的自主多智能体出租车路径问题，提出了一个近似滚动为基础的两阶段算法来减少计算量。

    

    本文关注大型城市环境下的自主多智能体出租车路径问题，未来乘车请求的位置和数量事先未知，但遵循估计的经验分布。最近的理论表明，如果基础策略是稳定的，那么基于滚动的算法与这样的基础策略产生接近最优的稳定策略。尽管基于滚动的方法非常适合学习具有对未来需求考虑的合作多智能体策略，但将这些方法应用于大型城市环境可能计算上很昂贵。大型环境往往有大量请求，因此需要大型的出租车队保证稳定性。本文旨在解决多智能体（逐一）滚动的计算瓶颈问题，其中计算复杂性随代理数量线性增长。我们提出了一种近似逐一滚动为基础的两阶段算法，减少计算量

    In this paper, we focus on the autonomous multiagent taxi routing problem for a large urban environment where the location and number of future ride requests are unknown a-priori, but follow an estimated empirical distribution. Recent theory has shown that if a base policy is stable then a rollout-based algorithm with such a base policy produces a near-optimal stable policy. Although, rollout-based approaches are well-suited for learning cooperative multiagent policies with considerations for future demand, applying such methods to a large urban environment can be computationally expensive. Large environments tend to have a large volume of requests, and hence require a large fleet of taxis to guarantee stability. In this paper, we aim to address the computational bottleneck of multiagent (one-at-a-time) rollout, where the computational complexity grows linearly in the number of agents. We propose an approximate one-at-a-time rollout-based two-phase algorithm that reduces the computatio
    
[^140]: 缩放学习优化器是否值得？评估 VeLO 的 4000 个 TPU 月的价值。

    Is Scaling Learned Optimizers Worth It? Evaluating The Value of VeLO's 4000 TPU Months. (arXiv:2310.18191v1 [cs.LG])

    [http://arxiv.org/abs/2310.18191](http://arxiv.org/abs/2310.18191)

    VeLO是迄今为止规模最大的训练通用“基础”优化器的尝试，但我们的评估发现它需要问题特定的调优，并不一定优于竞争对手的解决方案质量和训练误差降低速度，这对于VeLO的通用性和培训投资的价值提出了质疑。

    

    我们分析了 VeLO（万能学习优化器），这是迄今为止规模最大的训练通用“基础”优化器的尝试。VeLO 使用超过 4000 个 TPU 月的机器学习任务进行训练，目标是产生一个能够推广到新问题并且不需要超参数调整，并且超过 Adam 等行业标准的优化器。我们对 MLCommons 优化器基准套件独立评估了 VeLO。我们发现与初步声明相反：（1）VeLO有一个关键的超参数需要根据具体问题进行调整，（2）VeLO在找到的解的质量上不一定优于竞争对手，（3）VeLO在降低训练误差上并不比竞争优化器更快。这些观察结果对 VeLO 的通用性和培训投资的价值提出了质疑。

    We analyze VeLO (versatile learned optimizer), the largest scale attempt to train a general purpose "foundational" optimizer to date. VeLO was trained on thousands of machine learning tasks using over 4000 TPU months with the goal of producing an optimizer capable of generalizing to new problems while being hyperparameter free, and outperforming industry standards such as Adam. We independently evaluate VeLO on the MLCommons optimizer benchmark suite. We find that, contrary to initial claims: (1) VeLO has a critical hyperparameter that needs problem-specific tuning, (2) VeLO does not necessarily outperform competitors in quality of solution found, and (3) VeLO is not faster than competing optimizers at reducing the training loss. These observations call into question VeLO's generality and the value of the investment in training it.
    
[^141]: GenTKG: 基于生成模型的时间知识图谱预测

    GenTKG: Generative Forecasting on Temporal Knowledge Graph. (arXiv:2310.07793v1 [cs.CL])

    [http://arxiv.org/abs/2310.07793](http://arxiv.org/abs/2310.07793)

    研究提出了一种名为GenTKG的生成模型，用于在时间知识图谱上进行预测。该模型通过结合基于时间逻辑规则的检索策略和轻量级的参数效率指导，克服了复杂的时间图数据结构和庞大的数据量所带来的挑战。

    

    大规模语言模型(LLM)的快速发展引发了对时间知识图谱(tKG)领域的兴趣，其中传统的基于嵌入和规则的模型占主导地位。目前仍然存在一个问题，即预训练的LLM是否能够理解结构化的时间关系数据，并取代它们成为时间关系预测的基础模型。因此，我们将时间知识预测引入生成模式。然而，在复杂的时间图数据结构和LLM可以处理的序列自然表达之间存在巨大的鸿沟，在tKG的庞大数据量和微调LLM的巨大计算成本之间也存在挑战。为了解决这些挑战，我们提出了一种新颖的检索增强生成框架，称为GenTKG，它在tKG上执行生成式预测，结合了基于时间逻辑规则的检索策略和轻量级的参数效率指导。通过大量实验证明了GenTKG的有效性。

    The rapid advancements in large language models (LLMs) have ignited interest in the temporal knowledge graph (tKG) domain, where conventional carefully designed embedding-based and rule-based models dominate. The question remains open of whether pre-trained LLMs can understand structured temporal relational data and replace them as the foundation model for temporal relational forecasting. Therefore, we bring temporal knowledge forecasting into the generative setting. However, challenges occur in the huge chasms between complex temporal graph data structure and sequential natural expressions LLMs can handle, and between the enormous data sizes of tKGs and heavy computation costs of finetuning LLMs. To address these challenges, we propose a novel retrieval augmented generation framework that performs generative forecasting on tKGs named GenTKG, which combines a temporal logical rule-based retrieval strategy and lightweight parameter-efficient instruction tuning. Extensive experiments hav
    
[^142]: 一个可计数具有相同骨架的马尔可夫等价类的固定参数可处理算法

    A Fixed-Parameter Tractable Algorithm for Counting Markov Equivalence Classes with the same Skeleton. (arXiv:2310.04218v1 [cs.DS])

    [http://arxiv.org/abs/2310.04218](http://arxiv.org/abs/2310.04218)

    本文提出了一个固定参数可处理算法，用于计数具有相同骨架的马尔可夫等价类。

    

    因果有向无环图（也称为贝叶斯网络）是编码随机变量之间条件依赖关系的流行工具。在因果有向无环图中，随机变量被建模为有向图中的顶点，并且规定每个随机变量在给定其父节点的情况下与其祖先节点无关。然而，对于同一组随机变量上的两个不同的因果有向无环图可以准确编码相同的一组条件依赖关系。这样的因果有向无环图被称为马尔可夫等价，马尔可夫等价的因果有向无环图的等价类被称为马尔可夫等价类（MEC）。在过去几十年中，对于MEC已经创建了一些美丽的组合特征，并且已知，特别是在同一MEC中的所有因果有向无环图必须具有相同的“骨架”（底层无向图）和v-结构（形式为$a\rightarrow b \leftarrow c$的诱导子图）。这些组合特征还提出了几个自然的算法问题。

    Causal DAGs (also known as Bayesian networks) are a popular tool for encoding conditional dependencies between random variables. In a causal DAG, the random variables are modeled as vertices in the DAG, and it is stipulated that every random variable is independent of its ancestors conditioned on its parents. It is possible, however, for two different causal DAGs on the same set of random variables to encode exactly the same set of conditional dependencies. Such causal DAGs are said to be Markov equivalent, and equivalence classes of Markov equivalent DAGs are known as Markov Equivalent Classes (MECs). Beautiful combinatorial characterizations of MECs have been developed in the past few decades, and it is known, in particular that all DAGs in the same MEC must have the same ''skeleton'' (underlying undirected graph) and v-structures (induced subgraph of the form $a\rightarrow b \leftarrow c$).  These combinatorial characterizations also suggest several natural algorithmic questions. On
    
[^143]: 用于有效训练脉冲神经网络的脉冲累积转发方法

    Spike Accumulation Forwarding for Effective Training of Spiking Neural Networks. (arXiv:2310.02772v1 [cs.NE])

    [http://arxiv.org/abs/2310.02772](http://arxiv.org/abs/2310.02772)

    本研究提出了一种名为脉冲累积转发（SAF）的方法，可以有效训练脉冲神经网络（SNNs）。SAF不仅可以减少前向过程中的操作次数，与Spike Representation和OTTT保持一致，而且可以解决SNNs训练中的难题。

    

    本文提出了一种新的脉冲神经网络（SNNs）训练范式，即脉冲累积转发（SAF）。已知SNNs具有高能效但难以训练的特点。许多研究者提出了各种方法来解决这个问题，其中时间上的在线训练（OTTT）是一种在每个时间步骤推断的方法，同时抑制内存成本。然而，为了在GPU上高效计算，OTTT需要进行脉冲序列操作和脉冲序列加权求和操作。此外，OTTT与Spike Representation（另一种训练方法）之间存在关联，但与Spike Representation的理论一致性尚未得到证明。我们的方法可以解决这些问题，即SAF可以在前向过程中减少一半的操作次数，并且可以从理论上证明SAF分别与Spike Representation和OTTT一致。此外，我们还确认了......

    In this article, we propose a new paradigm for training spiking neural networks (SNNs), spike accumulation forwarding (SAF). It is known that SNNs are energy-efficient but difficult to train. Consequently, many researchers have proposed various methods to solve this problem, among which online training through time (OTTT) is a method that allows inferring at each time step while suppressing the memory cost. However, to compute efficiently on GPUs, OTTT requires operations with spike trains and weighted summation of spike trains during forwarding. In addition, OTTT has shown a relationship with the Spike Representation, an alternative training method, though theoretical agreement with Spike Representation has yet to be proven. Our proposed method can solve these problems; namely, SAF can halve the number of operations during the forward process, and it can be theoretically proven that SAF is consistent with the Spike Representation and OTTT, respectively. Furthermore, we confirmed the a
    
[^144]: PointSSC：一个用于语义场景补全的车辆基础设施点云合作基准

    PointSSC: A Cooperative Vehicle-Infrastructure Point Cloud Benchmark for Semantic Scene Completion. (arXiv:2309.12708v1 [cs.CV])

    [http://arxiv.org/abs/2309.12708](http://arxiv.org/abs/2309.12708)

    PointSSC是第一个为了语义场景补全而引入的车辆基础设施点云合作基准，具备长距离感知和最小遮挡。通过使用Segment Anything进行自动化注释，我们提出了一种基于激光雷达的模型，结合补全和分割的合作模块，来推动语义点云补全在真实世界导航中的发展。

    

    语义场景补全旨在为复杂的3D场景生成空间占用和语义标签。大多数现有的语义场景补全模型都集中在体素表示上，对于大型室外空间来说存在内存效率低下的问题。点云提供了一种轻量级的替代方案，但现有基准缺乏带有语义标签的室外点云场景。为了解决这个问题，我们引入了第一个用于语义场景补全的车辆基础设施点云合作基准PointSSC。这些场景具有长距离感知和最小的遮挡。我们利用Segment Anything开发了一个自动化注释流程，以高效地分配语义标签。为了评估进展，我们提出了一个基于激光雷达的模型，其中包括一个空间感知变换器用于全局和局部特征提取，以及一个补全和分割合作模块用于联合补全和分割。PointSSC提供了一个具有挑战性的测试平台，推动了语义点云补全在真实世界导航中的进展。

    Semantic Scene Completion (SSC) aims to jointly generate space occupancies and semantic labels for complex 3D scenes. Most existing SSC models focus on volumetric representations, which are memory-inefficient for large outdoor spaces. Point clouds provide a lightweight alternative but existing benchmarks lack outdoor point cloud scenes with semantic labels. To address this, we introduce PointSSC, the first cooperative vehicle-infrastructure point cloud benchmark for semantic scene completion. These scenes exhibit long-range perception and minimal occlusion. We develop an automated annotation pipeline leveraging Segment Anything to efficiently assign semantics. To benchmark progress, we propose a LiDAR-based model with a Spatial-Aware Transformer for global and local feature extraction and a Completion and Segmentation Cooperative Module for joint completion and segmentation. PointSSC provides a challenging testbed to drive advances in semantic point cloud completion for real-world navi
    
[^145]: CoT-BERT: 通过思维链条增强无监督句子表示

    CoT-BERT: Enhancing Unsupervised Sentence Representation through Chain-of-Thought. (arXiv:2309.11143v1 [cs.CL])

    [http://arxiv.org/abs/2309.11143](http://arxiv.org/abs/2309.11143)

    CoT-BERT提出了一种通过思维链条增强无监督句子表示的方法，通过两个阶段的处理，引入思维链条的概念进行向量化，以提高模型性能。

    

    无监督句子表示学习旨在将输入句子转化为富含复杂语义信息的固定长度向量，同时消除对标注数据的依赖。近年来，在对比学习和提示工程的推动下，该领域取得了显著进展，极大地缩小了无监督和有监督策略之间的差距。然而，在这个轨迹中，仍然没有充分利用思维链条的潜在能力。为了释放预训练模型（如BERT）中的潜能，我们提出了一个句子表示的两阶段方法：理解和摘要。随后，后一阶段的输出被利用为输入句子的向量化表示。为了进一步提高性能，我们对对比学习损失函数和模板去噪技术进行了精细调整。严格的实验验证了我们的方法CoT-BERT的优越性。

    Unsupervised sentence representation learning aims to transform input sentences into fixed-length vectors enriched with intricate semantic information while obviating the reliance on labeled data. Recent progress within this field, propelled by contrastive learning and prompt engineering, has significantly bridged the gap between unsupervised and supervised strategies. Nonetheless, the potential utilization of Chain-of-Thought, remains largely untapped within this trajectory. To unlock latent capabilities within pre-trained models, such as BERT, we propose a two-stage approach for sentence representation: comprehension and summarization. Subsequently, the output of the latter phase is harnessed as the vectorized representation of the input sentence. For further performance enhancement, we meticulously refine both the contrastive learning loss function and the template denoising technique for prompt engineering. Rigorous experimentation substantiates our method, CoT-BERT, transcending a
    
[^146]: 解决异构联邦学习中非独立同分布问题的梯度协调方法

    Tackling the Non-IID Issue in Heterogeneous Federated Learning by Gradient Harmonization. (arXiv:2309.06692v1 [cs.LG])

    [http://arxiv.org/abs/2309.06692](http://arxiv.org/abs/2309.06692)

    本研究通过梯度协调方法解决了异构联邦学习中的非独立同分布问题，提出了FedGH，通过减轻本地漂移来增强性能。实验证明，在多个基准和非独立同分布场景下，FedGH始终能够显著提升联邦学习的性能。

    

    联邦学习是一种保护隐私的范式，用于从分散的客户端协作训练全局模型。然而，联邦学习的性能受到非独立同分布的数据和设备异构性的影响。在本研究中，我们通过服务器端的梯度冲突视角重新思考这个关键挑战。具体而言，我们首先调查了多个客户端之间的梯度冲突现象，并揭示了更强的异构性会导致更严重的梯度冲突。为了解决这个问题，我们提出了FedGH，一种简单而有效的方法，通过梯度协调来减轻本地漂移。这种技术将一个梯度向量投影到与其他冲突客户端对之间的正交平面上。广泛的实验表明，FedGH在不同基准和非独立同分布场景下始终能够显著提升多个最先进的联邦学习基线。值得注意的是，FedGH在特定场景中取得了更显著的改进。

    Federated learning (FL) is a privacy-preserving paradigm for collaboratively training a global model from decentralized clients. However, the performance of FL is hindered by non-independent and identically distributed (non-IID) data and device heterogeneity. In this work, we revisit this key challenge through the lens of gradient conflicts on the server side. Specifically, we first investigate the gradient conflict phenomenon among multiple clients and reveal that stronger heterogeneity leads to more severe gradient conflicts. To tackle this issue, we propose FedGH, a simple yet effective method that mitigates local drifts through Gradient Harmonization. This technique projects one gradient vector onto the orthogonal plane of the other within conflicting client pairs. Extensive experiments demonstrate that FedGH consistently enhances multiple state-of-the-art FL baselines across diverse benchmarks and non-IID scenarios. Notably, FedGH yields more significant improvements in scenarios 
    
[^147]: 离线逆向强化学习下的提示评估与优化

    Offline Prompt Evaluation and Optimization with Inverse Reinforcement Learning. (arXiv:2309.06553v1 [cs.CL])

    [http://arxiv.org/abs/2309.06553](http://arxiv.org/abs/2309.06553)

    这项工作介绍了一种基于离线逆向强化学习的提示评估与优化方法，通过利用离线数据集和逆向强化学习，预测提示性能、提高成本效益、生成易读的结果。

    

    最近，像ChatGPT这样的大型语言模型（LLM）的发展取得了显著的性能，通过利用人类专业知识。然而，充分揭示LLMs在复杂任务中的潜力需要在自然语言提示的广阔搜索空间中进行导航。虽然提示工程显示出潜力，但试错尝试中所需的人工设计提示和相关成本带来了重大挑战。关键是，提示优化的效率取决于昂贵的提示评估过程。本工作介绍了Prompt-OIRL，这是一种基于离线逆向强化学习的方法，旨在弥合有效提示评估和可负担性之间的差距。我们的方法利用专家评估的离线数据集，运用逆向强化学习获得一个针对离线、查询依赖型提示评估的奖励模型。Prompt-OIRL的优点是多方面的：它预测提示的性能，成本高效，生成易读的结果。

    The recent advances in the development of Large Language Models (LLMs) like ChatGPT have achieved remarkable performance by leveraging human expertise. Yet, fully eliciting LLMs' potential for complex tasks requires navigating the vast search space of natural language prompts. While prompt engineering has shown promise, the requisite human-crafted prompts in trial-and-error attempts and the associated costs pose significant challenges. Crucially, the efficiency of prompt optimization hinges on the costly procedure of prompt evaluation. This work introduces Prompt-OIRL, an approach rooted in offline inverse reinforcement learning that seeks to bridge the gap between effective prompt evaluation and affordability. Our method draws on offline datasets from expert evaluations, employing Inverse-RL to derive a reward model for offline, query-dependent prompt evaluations. The advantages of Prompt-OIRL are manifold: it predicts prompt performance, is cost-efficient, produces human-readable res
    
[^148]: 一个关于校准的基准研究

    A Benchmark Study on Calibration. (arXiv:2308.11838v1 [cs.LG])

    [http://arxiv.org/abs/2308.11838](http://arxiv.org/abs/2308.11838)

    这项研究提出了一个模型校准的基准研究，利用神经架构搜索空间探索了模型校准属性。研究结果显示，模型校准可以在不同任务中泛化，并可以同时兼顾模型的准确性和校准性能。

    

    深度神经网络在各种机器学习任务中的应用越来越广泛。然而，随着这些模型复杂性的增加，它们往往面临校准问题，尽管预测准确性有所提高。许多研究通过数据预处理、使用特定损失函数和训练框架来改善校准性能。然而，对校准属性的研究有点被忽视了。我们的研究利用神经架构搜索（NAS）搜索空间，在全面探索校准属性的模型架构空间中提供了一个详尽的模型架构空间。我们特别创建了一个模型校准数据集。该数据集在广泛使用的NATS-Bench搜索空间中评估了90个基于区间的校准度量和12个其他校准度量，涵盖了117,702个独特的神经网络。我们的分析旨在通过我们提出的数据集回答该领域一些长期存在的问题：（i）模型校准能否在不同任务中泛化？（ii）能否同时兼顾模型的准确性和校准性能？

    Deep neural networks are increasingly utilized in various machine learning tasks. However, as these models grow in complexity, they often face calibration issues, despite enhanced prediction accuracy. Many studies have endeavored to improve calibration performance through data preprocessing, the use of specific loss functions, and training frameworks. Yet, investigations into calibration properties have been somewhat overlooked. Our study leverages the Neural Architecture Search (NAS) search space, offering an exhaustive model architecture space for thorough calibration properties exploration. We specifically create a model calibration dataset. This dataset evaluates 90 bin-based and 12 additional calibration measurements across 117,702 unique neural networks within the widely employed NATS-Bench search space. Our analysis aims to answer several longstanding questions in the field, using our proposed dataset: (i) Can model calibration be generalized across different tasks? (ii) Can rob
    
[^149]: 通过任务分解学习抽象视觉推理：基于Raven渐进矩阵的案例研究

    Learning Abstract Visual Reasoning via Task Decomposition: A Case Study in Raven Progressive Matrices. (arXiv:2308.06528v1 [cs.AI])

    [http://arxiv.org/abs/2308.06528](http://arxiv.org/abs/2308.06528)

    通过任务分解学习抽象视觉推理，提出了一种基于变形器蓝图的深度学习架构，该架构预测单个对象及其排列的视觉特性，通过多维预测来选择答案。

    

    学习进行抽象推理的挑战之一是问题通常被提出为整体任务，没有中间目标。在Raven渐进矩阵（RPM）中，任务是在给定上下文的情况下选择一个可用答案，其中上下文和答案都是复合图像，具有多个对象以及各种空间安排。由于只有这个高级目标作为指导，学习变得具有挑战性，大多数现代解决方案往往不透明。在本研究中，我们提出了一种基于变形器蓝图的深度学习架构，该架构不直接进行上述选择，而是预测单个对象及其排列的视觉特性。通过这种方式获得的多维预测直接并置以选择答案。我们考虑了模型将视觉输入解析为令牌的几种方式，并采用了几种自监督训练中输入的屏蔽方法。

    One of the challenges in learning to perform abstract reasoning is that problems are often posed as monolithic tasks, with no intermediate subgoals. In Raven Progressive Matrices (RPM), the task is to choose one of the available answers given a context, where both contexts and answers are composite images featuring multiple objects in various spatial arrangements. As this high-level goal is the only guidance available, learning is challenging and most contemporary solvers tend to be opaque. In this study, we propose a deep learning architecture based on the transformer blueprint which, rather than directly making the above choice, predicts the visual properties of individual objects and their arrangements. The multidimensional predictions obtained in this way are then directly juxtaposed to choose the answer. We consider a few ways in which the model parses the visual input into tokens and several regimes of masking parts of the input in self-supervised training. In experimental assess
    
[^150]: 加速GNN框架中的采样和聚合操作：利用GPU发起直接存储访问

    Accelerating Sampling and Aggregation Operations in GNN Frameworks with GPU Initiated Direct Storage Accesses. (arXiv:2306.16384v1 [cs.DC])

    [http://arxiv.org/abs/2306.16384](http://arxiv.org/abs/2306.16384)

    本论文提出了一种通过利用GPU发起直接存储访问来加速GNN框架中的采样和聚合操作的方法，解决了在训练大规模图上时CPU无法充分利用GPU资源的问题。

    

    图神经网络（GNNs）正在成为学习图结构数据和进行复杂推理任务的一个强大工具，适用于各个应用领域。尽管已经证明GNNs在中等规模的图上具有有效性，但在大规模图上训练仍然面临着数据访问和数据移动方法的不足。现有的GNN训练框架使用CPU进行图采样和特征聚合，而模型权重的训练和更新则由GPU执行。然而，我们深入分析发现CPU无法实现所需的吞吐量以充分利用昂贵的GPU资源。此外，当图和其嵌入不能适应CPU内存时，操作系统引入的开销，如处理页面错误，会成为关键路径的瓶颈。为了解决这些问题，我们提出了GPU发起的直接存储访问方法。

    Graph Neural Networks (GNNs) are emerging as a powerful tool for learning from graph-structured data and performing sophisticated inference tasks in various application domains. Although GNNs have been shown to be effective on modest-sized graphs, training them on large-scale graphs remains a significant challenge due to lack of efficient data access and data movement methods. Existing frameworks for training GNNs use CPUs for graph sampling and feature aggregation, while the training and updating of model weights are executed on GPUs. However, our in-depth profiling shows the CPUs cannot achieve the throughput required to saturate GNN model training throughput, causing gross under-utilization of expensive GPU resources. Furthermore, when the graph and its embeddings do not fit in the CPU memory, the overhead introduced by the operating system, say for handling page-faults, comes in the critical path of execution.  To address these issues, we propose the GPU Initiated Direct Storage Ac
    
[^151]: EquiformerV2: 改进的等变Transformer，用于扩展到更高次表示

    EquiformerV2: Improved Equivariant Transformer for Scaling to Higher-Degree Representations. (arXiv:2306.12059v1 [cs.LG])

    [http://arxiv.org/abs/2306.12059](http://arxiv.org/abs/2306.12059)

    本文提出了EquiformerV2，通过使用新的卷积类型和架构改进，扩展了等变Transformer到更高的等变表示，在处理大型数据集时表现更好，能量和力的表现也得到了提高，计算效率也得到了提升。

    

    等变Transformer（例如Equiformer）已经证明了将Transformer应用于3D原子系统领域的功效。但是，由于计算复杂性，它们仍然局限于小数次等变表示。在本文中，我们调查了这些架构是否能够很好地扩展到更高的次数。从Equiformer开始，我们首先用eSCN卷积替换了$SO(3)$卷积，以有效地合并更高次的张量。然后，为了更好地利用更高次的能力，我们提出了三个架构改进——注意力重标准化、可分离的$S^2$激活和可分离层归一化。将这一切放在一起，我们提出了EquiformerV2，在大型OC20数据集上的表现优于以前的最先进方法，在力上提高了最多$12\%$，能量上提高了$4\%$，提供更好的速度-准确性权衡，并且在计算吸附能所需的DFT计算量方面缩减了2倍。

    Equivariant Transformers such as Equiformer have demonstrated the efficacy of applying Transformers to the domain of 3D atomistic systems. However, they are still limited to small degrees of equivariant representations due to their computational complexity. In this paper, we investigate whether these architectures can scale well to higher degrees. Starting from Equiformer, we first replace $SO(3)$ convolutions with eSCN convolutions to efficiently incorporate higher-degree tensors. Then, to better leverage the power of higher degrees, we propose three architectural improvements -- attention re-normalization, separable $S^2$ activation and separable layer normalization. Putting this all together, we propose EquiformerV2, which outperforms previous state-of-the-art methods on the large-scale OC20 dataset by up to $12\%$ on forces, $4\%$ on energies, offers better speed-accuracy trade-offs, and $2\times$ reduction in DFT calculations needed for computing adsorption energies.
    
[^152]: 用函数逼近解决强化学习中重尾奖励问题的极小最大化算法和实例相关遗憾度量

    Tackling Heavy-Tailed Rewards in Reinforcement Learning with Function Approximation: Minimax Optimal and Instance-Dependent Regret Bounds. (arXiv:2306.06836v1 [cs.LG])

    [http://arxiv.org/abs/2306.06836](http://arxiv.org/abs/2306.06836)

    本文解决了强化学习中当奖励呈“重尾”分布时的问题，提出了第一种处理这种情况的实例相关算法，并得到了极小最大化的遗憾界。

    

    虽然有许多工作都专注于为有界奖励的强化学习设计有效算法，但当奖励呈现“重尾”分布时——即存在某个 $\epsilon\in(0,1]$ 使得仅有有限的$(1+\epsilon)$-阶矩——是否存在对大状态-动作空间进行采样或时效性算法仍然是一个未解决的问题。 在本文中，我们解决了具有线性函数逼近的 RL 中的这种奖励机制的挑战。我们首先为重尾线性赌臂设计了一种算法——\textsc{Heavy-OFUL}，其实现了一种实例相关的 $T$-round 遗憾度量，为 $\tilde{O}\big(d T^{\frac{1-\epsilon}{2(1+\epsilon)}} \sqrt{\sum_{t=1}^T \nu_t^2} + d T^{\frac{1-\epsilon}{2(1+\epsilon)}}\big)$，这是这种类型的\emph{第一篇}文章。$\nu_t^{1+\epsilon}$是第 $t$ 轮奖励的 $(1+\epsilon)$-阶中心矩。我们进一步证明了在应用于 st 的最坏情况时，上述界是极小值的最优解。

    While numerous works have focused on devising efficient algorithms for reinforcement learning (RL) with uniformly bounded rewards, it remains an open question whether sample or time-efficient algorithms for RL with large state-action space exist when the rewards are \emph{heavy-tailed}, i.e., with only finite $(1+\epsilon)$-th moments for some $\epsilon\in(0,1]$. In this work, we address the challenge of such rewards in RL with linear function approximation. We first design an algorithm, \textsc{Heavy-OFUL}, for heavy-tailed linear bandits, achieving an \emph{instance-dependent} $T$-round regret of $\tilde{O}\big(d T^{\frac{1-\epsilon}{2(1+\epsilon)}} \sqrt{\sum_{t=1}^T \nu_t^2} + d T^{\frac{1-\epsilon}{2(1+\epsilon)}}\big)$, the \emph{first} of this kind. Here, $d$ is the feature dimension, and $\nu_t^{1+\epsilon}$ is the $(1+\epsilon)$-th central moment of the reward at the $t$-th round. We further show the above bound is minimax optimal when applied to the worst-case instances in st
    
[^153]: 利用LLMs从混合长文档中检索KPI的全面框架与数据集

    Leveraging LLMs for KPIs Retrieval from Hybrid Long-Document: A Comprehensive Framework and Dataset. (arXiv:2305.16344v1 [cs.CL])

    [http://arxiv.org/abs/2305.16344](http://arxiv.org/abs/2305.16344)

    本文提出了一个自动化财务信息提取的框架（AFIE），用于提取混合长文档中的关键业绩指标（KPI）。该框架利用LLMs增强了财务报告信息的理解和提取能力，并经过了广泛的实验验证，证明其在GPT-3.5和GPT-4上的有效性，相对于朴素方法，平均精度提高了53.94％和33.77％。

    

    大型语言模型（LLMs）在文本理解和表格推理任务中展现出了卓越的性能，但它们对包含文本和表格数据的混合文本的理解和分析能力仍未被充分发掘。本研究专注于利用LLMs的潜力，从混杂的长型财务报告中理解关键信息。我们提出了自动化财务信息提取（AFIE）框架，增强了LLMs理解和提取财务报告信息的能力。为了评估AFIE，我们开发了一个金融报告数值提取（FINE）数据集，并进行了广泛的实验分析。我们的框架在GPT-3.5和GPT-4上得到了有效验证，相对于朴素方法，平均精度提高了53.94％和33.77％。这些结果表明，AFIE框架为从复杂的混合文档中自动提取数值提供了准确性。

    Large Language Models (LLMs) demonstrate exceptional performance in textual understanding and tabular reasoning tasks. However, their ability to comprehend and analyze hybrid text, containing textual and tabular data, remains underexplored. In this research, we specialize in harnessing the potential of LLMs to comprehend critical information from financial reports, which are hybrid long-documents. We propose an Automated Financial Information Extraction (AFIE) framework that enhances LLMs' ability to comprehend and extract information from financial reports. To evaluate AFIE, we develop a Financial Reports Numerical Extraction (FINE) dataset and conduct an extensive experimental analysis. Our framework is effectively validated on GPT-3.5 and GPT-4, yielding average accuracy increases of 53.94% and 33.77%, respectively, compared to a naive method. These results suggest that the AFIE framework offers accuracy for automated numerical extraction from complex, hybrid documents.
    
[^154]: 存在对称性和状态抽象的政策梯度方法

    Policy Gradient Methods in the Presence of Symmetries and State Abstractions. (arXiv:2305.05666v1 [cs.LG])

    [http://arxiv.org/abs/2305.05666](http://arxiv.org/abs/2305.05666)

    本文研究了在连续控制环境中的抽象，提出了一种策略梯度定理，允许利用环境的近似对称性进行策略优化，并提出了一系列演员-评论家算法进行策略和MDP同态映射的学习，最后展示了算法在连续对称性环境和视觉控制任务中的有效性。

    

    针对高维度和复杂问题，强化学习依靠抽象来提高效率和泛化性能。本文研究了在连续控制环境中的抽象，并将MDP同态的定义扩展到连续状态和动作空间的情况。我们针对抽象MDP的随机和确定性策略导出了一种策略梯度定理。我们的策略梯度结果允许利用环境的近似对称性进行策略优化。基于这些定理，我们提出了一系列演员-评论家算法，这些算法能够同时学习策略和MDP同态映射，使用松散双仿射度量。最后，我们引入了一系列具有连续对称性的环境，以进一步展示我们的算法在存在这些对称性的情况下进行动作抽象的能力。我们在这些环境以及具有挑战性的视觉控制任务中展示了我们方法的有效性。

    Reinforcement learning on high-dimensional and complex problems relies on abstraction for improved efficiency and generalization. In this paper, we study abstraction in the continuous-control setting, and extend the definition of MDP homomorphisms to the setting of continuous state and action spaces. We derive a policy gradient theorem on the abstract MDP for both stochastic and deterministic policies. Our policy gradient results allow for leveraging approximate symmetries of the environment for policy optimization. Based on these theorems, we propose a family of actor-critic algorithms that are able to learn the policy and the MDP homomorphism map simultaneously, using the lax bisimulation metric. Finally, we introduce a series of environments with continuous symmetries to further demonstrate the ability of our algorithm for action abstraction in the presence of such symmetries. We demonstrate the effectiveness of our method on our environments, as well as on challenging visual contro
    
[^155]: 通过数据生成和参数畸变实现隐私保护联邦学习的接近最优效用

    Towards Achieving Near-optimal Utility for Privacy-Preserving Federated Learning via Data Generation and Parameter Distortion. (arXiv:2305.04288v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2305.04288](http://arxiv.org/abs/2305.04288)

    本论文提出了一种用数据生成和参数畸变实现隐私保护联邦学习接近最优效用的上限方法，其中通过降低方差和模型参数差异来衡量效用损失。

    

    联邦学习（FL）使参与方能够协作构建具有提高效用的全局模型，而不泄露私有数据信息。必须采用适当的保护机制来满足保护隐私和维护高模型效用的要求。目前采用的保护机制的本质，包括“随机化机制”和“压缩机制”，是通过畸变模型参数来保护隐私。我们通过原始模型参数和畸变模型参数之间的差距来衡量效用。我们想要确定在什么普遍条件下，通过数据生成和参数畸变，隐私保护的联邦学习可以实现接近最优的效用。为了提供接近最优效用的途径，我们提出了一个效用损失的上限，用两个主要项称为降低方差和模型参数差异来衡量。

    Federated learning (FL) enables participating parties to collaboratively build a global model with boosted utility without disclosing private data information. Appropriate protection mechanisms have to be adopted to fulfill the requirements in preserving \textit{privacy} and maintaining high model \textit{utility}. The nature of the widely-adopted protection mechanisms including \textit{Randomization Mechanism} and \textit{Compression Mechanism} is to protect privacy via distorting model parameter. We measure the utility via the gap between the original model parameter and the distorted model parameter. We want to identify under what general conditions privacy-preserving federated learning can achieve near-optimal utility via data generation and parameter distortion. To provide an avenue for achieving near-optimal utility, we present an upper bound for utility loss, which is measured using two main terms called variance-reduction and model parameter discrepancy separately. Our analysis
    
[^156]: 基于层次数据有效表示学习的RNA三级结构设计

    Hierarchical Data-efficient Representation Learning for Tertiary Structure-based RNA Design. (arXiv:2301.10774v2 [q-bio.BM] UPDATED)

    [http://arxiv.org/abs/2301.10774](http://arxiv.org/abs/2301.10774)

    本研究提出了一个基于层次数据有效表示学习的RNA设计流程，通过构建大型数据集并设计全面的结构建模方法，实现了更高效的RNA序列设计。

    

    尽管人工智能已在揭示生物大分子的一级序列与三级结构之间的关系方面取得了显着进展，但基于特定三级结构设计RNA序列仍然具有挑战性。虽然蛋白质设计中的现有方法已经彻底探索了蛋白质中结构到序列的依赖性，但RNA设计仍面临结构复杂性和数据稀缺性的困难。与此同时，虽然RNA与蛋白质共享类似的结构组分，但直接将蛋白质设计方法移植到RNA设计中却无法取得令人满意的结果。本研究旨在系统构建数据驱动的RNA设计流程。我们构建了一个大型、精心策划的基准数据集，并设计了一个全面的结构建模方法来表示复杂的RNA三级结构。更重要的是，我们提出了一个层次数据有效表示学习框架，学习结构表示的多个层次特征，以实现更高效的RNA序列设计。

    While artificial intelligence has made remarkable strides in revealing the relationship between biological macromolecules' primary sequence and tertiary structure, designing RNA sequences based on specified tertiary structures remains challenging. Though existing approaches in protein design have thoroughly explored structure-to-sequence dependencies in proteins, RNA design still confronts difficulties due to structural complexity and data scarcity. Adding to the problem, direct transplantation of protein design methodologies into RNA design fails to achieve satisfactory outcomes although sharing similar structural components. In this study, we aim to systematically construct a data-driven RNA design pipeline. We crafted a large, well-curated benchmark dataset and designed a comprehensive structural modeling approach to represent the complex RNA tertiary structure. More importantly, we proposed a hierarchical data-efficient representation learning framework that learns structural repre
    

