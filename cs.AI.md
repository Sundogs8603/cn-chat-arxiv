# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Step length measurement in the wild using FMCW radar.](http://arxiv.org/abs/2401.01868) | 该论文提出了一种基于FMCW雷达的在家中进行步长测量的系统，通过雷达点云的检测和跟踪，以及对躯干的多普勒速度分析来获取步长信息。这填补了现有基于雷达的步长测量方法在家庭环境中的研究空白，并具有预测风险的重要意义。 |
| [^2] | [Multilingual Instruction Tuning With Just a Pinch of Multilinguality.](http://arxiv.org/abs/2401.01854) | 本研究研究了多语言指令调优中的多语言性对跨语言指令遵循的影响。研究发现，即使在单语调优过程中，许多语言也可以将一些指令遵循能力转移到其他语言上。此外，只有40个多语言示例能够显著提高多语言指令遵循。总体来说，多语言混合调优的模型在多种语言上的表现相比单语调优的模型要好或者不相上下，尽管使用的这些语言的训练示例数量只有10倍少。 |
| [^3] | [The Power of Training: How Different Neural Network Setups Influence the Energy Demand.](http://arxiv.org/abs/2401.01851) | 本文研究了机器学习训练方案和学习范式对能源消耗的影响，并探讨了预训练和多任务训练在可持续机器学习方面的潜力。 |
| [^4] | [Act as You Learn: Adaptive Decision-Making in Non-Stationary Markov Decision Processes.](http://arxiv.org/abs/2401.01841) | 本文提出了一种自适应蒙特卡洛树搜索算法来应对非稳态环境下的决策问题，解决了传统方法中对环境动态假设的限制和规划过程的悲观性问题。 |
| [^5] | [NODEC: Neural ODE For Optimal Control of Unknown Dynamical Systems.](http://arxiv.org/abs/2401.01836) | NODEC是一种用神经ODE模型将动力学建模与控制器训练相结合的新框架，用于控制未知动态系统。 |
| [^6] | [Concurrent Brainstorming & Hypothesis Satisfying: An Iterative Framework for Enhanced Retrieval-Augmented Generation (R2CBR3H-SR).](http://arxiv.org/abs/2401.01835) | 本论文介绍了一种迭代的检索增强生成系统，通过并发的头脑风暴和假设满足相结合的策略，加快了高度相关文档的检索，并简化了查询的生成过程，提高了处理效率和准确性。 |
| [^7] | [Iterative Mask Filling: An Effective Text Augmentation Method Using Masked Language Modeling.](http://arxiv.org/abs/2401.01830) | 本文提出了一种新颖的文本增强方法，利用基于Transformer的BERT模型的填充-掩码功能，通过迭代掩码和语言模型预测进行替换，显著提高了自然语言处理任务的性能。 |
| [^8] | [Large Language Models Relearn Removed Concepts.](http://arxiv.org/abs/2401.01814) | 大型语言模型可以通过重新分配概念到不同层级和修剪前的神经元实现对已删除概念的重新学习，这表明模型具有多义能力，但同时也带来了在改善模型安全性方面的挑战。 |
| [^9] | [A quatum inspired neural network for geometric modeling.](http://arxiv.org/abs/2401.01801) | 这个论文介绍了一种创新的矩阵乘积态(MPS)的消息传递策略，通过这种策略可以更好地捕捉几何图中的复杂关系。 |
| [^10] | [CoMoSVC: Consistency Model-based Singing Voice Conversion.](http://arxiv.org/abs/2401.01792) | 本文提出了一种基于一致性模型的唱歌声音转换方法。通过设计扩散教师模型和提取自一致性学生模型，该方法实现了高质量的声音生成和高速的采样，相比于最先进的扩散方法，具有更快的推理速度，并在主观和客观指标上实现了可比或更优的声音转换性能。 |
| [^11] | [Deep learning the Hurst parameter of linear fractional processes and assessing its reliability.](http://arxiv.org/abs/2401.01789) | 本研究利用深度学习（特别是LSTM网络）评估了分数随机过程中的Hurst参数，并探讨了其可靠性。实证结果表明，在分数布朗运动和分数奥恩斯坦-乌伦贝克过程中，LSTM网络优于传统统计方法，但在线性分数稳定运动过程中准确性受限。 |
| [^12] | [Applications of machine learning and IoT for Outdoor Air Pollution Monitoring and Prediction: A Systematic Literature Review.](http://arxiv.org/abs/2401.01788) | 本文系统综述了机器学习和物联网在室外空气污染预测中的应用，以及使用的监测传感器和输入特征的组合。研究结果突出了高成本监测、低成本物联网和混合预测这三种方法。 |
| [^13] | [A Novel Paradigm for Neural Computation: X-Net with Learnable Neurons and Adaptable Structure.](http://arxiv.org/abs/2401.01772) | 本研究提出了一种名为X-Net的新型神经网络，通过利用交替反向传播机制，在训练过程中根据导数信息动态选择适当的激活函数，以增强网络的表示能力。 |
| [^14] | [Incremental FastPitch: Chunk-based High Quality Text to Speech.](http://arxiv.org/abs/2401.01755) | 提出了增量式FastPitch，一种能够增量生成高质量Mel块的文本到语音合成模型。通过改进的架构和训练技术，以及固定大小的过去模型状态进行推理，它在实时语音应用中具有更低的延迟和更短的响应时间。 |
| [^15] | [Using AI/ML to Find and Remediate Enterprise Secrets in Code & Document Sharing Platforms.](http://arxiv.org/abs/2401.01754) | 该论文提出了一个新的挑战，即利用AI在代码和文档分享平台中准确检测和标记机密信息，并自动修复这些问题。研究人员引入了两种性能良好的基准AI模型，并提出了一种自动机制来修复发现的机密信息问题，为更广泛的社区打开了研究的可能性。 |
| [^16] | [A Generative AI Assistant to Accelerate Cloud Migration.](http://arxiv.org/abs/2401.01753) | 一种利用生成型人工智能的助手，能够加速将本地应用程序迁移到云端，并通过提供迁移策略和架构图的方式帮助用户选择合适的迁移配置文件，避免手动方法的复杂性。 |
| [^17] | [Task and Explanation Network.](http://arxiv.org/abs/2401.01732) | 该论文介绍了一个基本框架——任务和解释网络（TENet），它不仅能完成任务，还能解释为什么这样完成任务。它强调整个AI领域都应该重视可解释性。 |
| [^18] | [Ravnest: Decentralized Asynchronous Training on Heterogeneous Devices.](http://arxiv.org/abs/2401.01728) | 本文提出了一种用于大型现代深度学习模型的异步分散式训练范式，通过连接互联网上的资源受限的异构个人计算机，利用计算能力来实现有利的性能指标。Ravnest通过有效地将计算节点组织成具有类似数据传输速率和计算能力的集群，实现了分散式训练，而不需要每个节点承载整个模型。 |
| [^19] | [Deep Automated Mechanism Design for Integrating Ad Auction and Allocation in Feed.](http://arxiv.org/abs/2401.01656) | 本论文提出了一种深度自动化的机制设计，用于在Feed中集成广告拍卖和分配。这种设计解决了广告拍卖不考虑外部性和广告分配无法保持激励兼容性的问题。 |
| [^20] | [AIGCBench: Comprehensive Evaluation of Image-to-Video Content Generated by AI.](http://arxiv.org/abs/2401.01651) | 本论文介绍了AIGCBench，一个全面评估AI生成的图像到视频内容的基准。通过引入多样化且开放领域的图像-文本数据集，AIGCBench解决了现有基准的局限性。为了建立统一的评估框架，该基准包括11个度量指标，涵盖控制视频对齐、动态效果、时间一致性和视频质量等方面。 |
| [^21] | [A Cybersecurity Risk Analysis Framework for Systems with Artificial Intelligence Components.](http://arxiv.org/abs/2401.01630) | 本文提供了一个网络安全风险分析框架，旨在评估带有人工智能组件的系统。研究人员使用了自动驾驶系统作为示例来说明该框架的应用。 |
| [^22] | [Synthetic Data in AI: Challenges, Applications, and Ethical Implications.](http://arxiv.org/abs/2401.01629) | 这篇论文讨论了人工智能中合成数据的挑战、应用和伦理影响。它介绍了合成数据的生成方法和应用领域，并强调了确保公平性、减少偏见和维护伦理标准在人工智能发展中的重要性。 |
| [^23] | [On the Expressive Power of Graph Neural Networks.](http://arxiv.org/abs/2401.01626) | 研究人员对图神经网络的表达能力和设计架构进行了大量工作，以提高其在各领域任务中的性能。主要方法包括研究GNN的通用逼近性质和其在区分不同图之间的能力程度。 |
| [^24] | [Can AI Be as Creative as Humans?.](http://arxiv.org/abs/2401.01623) | 本文引入了一个新概念【相对创造力】，通过将焦点转向AI是否能够与人类具备相同的创造能力，实现对创造力的统计量化评估和直接比较。 |
| [^25] | [Large Language Model Capabilities in Perioperative Risk Prediction and Prognostication.](http://arxiv.org/abs/2401.01620) | 在这项研究中，我们探讨了使用通用领域大型语言模型在术中风险预测和预后方面的能力。通过使用手术描述和患者临床记录，我们在8个不同的任务上考察了预测性能，并发现少量样本和链式启发式策略可以提高预测性能。此外，我们的研究表明当前一代大型语言模型可以帮助临床医生在术中风险分层和生成高质量的自然语言总结方面发挥作用。 |
| [^26] | [GPT-4V(ision) is a Generalist Web Agent, if Grounded.](http://arxiv.org/abs/2401.01614) | GPT-4V(ision)是一个通用的网络代理，具有综合视觉理解和网页操作的能力。实验证明，如果将文本计划转化为实际行动，GPT-4V可以在50%的任务上取得成功。这一结果显著优于传统方法。 |
| [^27] | [PLLaMa: An Open-source Large Language Model for Plant Science.](http://arxiv.org/abs/2401.01600) | PLLaMa是一种用于植物科学的开源大型语言模型，通过综合数据库增强，显著丰富了其在植物和农业科学方面的知识和专长，并通过与专业人员小组的合作验证了其准确性。 |
| [^28] | [MedSumm: A Multimodal Approach to Summarizing Code-Mixed Hindi-English Clinical Queries.](http://arxiv.org/abs/2401.01596) | 本研究提出了一种多模态方法，用于总结混合码Hindi-English临床查询，通过整合文本和视觉线索，提供更全面的患者医疗状况的表示。为了解决这个问题，研究还提出了一个名为MedSumm的框架，利用LLMs和VLMs来完成任务。 |
| [^29] | [Adversarial Machine Learning-Enabled Anonymization of OpenWiFi Data.](http://arxiv.org/abs/2401.01542) | 这篇论文提出了一种对开放WiFi数据进行对抗机器学习启发的匿名化处理的方法，通过应用条件表格生成对抗网络（CTGAN）生成伪装成真实数据的合成数据，并使用聚类算法对合成数据与实际数据的相似性进行评估和性能比较。 |
| [^30] | [The Art of Deception: Robust Backdoor Attack using Dynamic Stacking of Triggers.](http://arxiv.org/abs/2401.01537) | 这项研究介绍了一种使用动态触发器进行强健后门攻击的方法，通过巧妙设计的调整，使损坏的样本与干净的样本无法区分，实验证明这种方法可以成功地欺骗语音识别系统。 |
| [^31] | [GOAT-Bench: Safety Insights to Large Multimodal Models through Meme-Based Social Abuse.](http://arxiv.org/abs/2401.01523) | 通过基于迷因的社交虐待研究对大型多模态模型的安全洞察，我们引入了综合的迷因基准测试集GOAT-Bench，评估各种LMMs在识别和回应迷因中体现的微妙社交虐待方面的能力。 |
| [^32] | [Exploring the Frontiers of LLMs in Psychological Applications: A Comprehensive Review.](http://arxiv.org/abs/2401.01519) | 本文综述了大型语言模型（LLMs）在心理学应用中的前沿，包括如何模拟人类认知和行为、提供创新工具进行文献回顾、假设生成、实验设计等。 |
| [^33] | [From Pixel to Slide image: Polarization Modality-based Pathological Diagnosis Using Representation Learning.](http://arxiv.org/abs/2401.01496) | 本研究提出了一种使用表示学习的三阶段模型，结合像素级和切片级注释，能够准确区分甲状腺肿瘤，解决了病理诊断中的挑战。 |
| [^34] | [Free Lunch for Federated Remote Sensing Target Fine-Grained Classification: A Parameter-Efficient Framework.](http://arxiv.org/abs/2401.01493) | 这项研究提出了一个名为PRFL的隐私保护TFGC框架，基于联邦学习，旨在解决遥感目标细粒度分类中的数据隐私和通信效率问题。 |
| [^35] | [Uncertainty Regularized Evidential Regression.](http://arxiv.org/abs/2401.01484) | 本文研究了证据回归网络（ERN）中的模型性能限制问题，并提出了一种基于正则化的改进方法，使ERN能够从整个训练集中学习。 |
| [^36] | [Incorporating Geo-Diverse Knowledge into Prompting for Increased Geographical Robustness in Object Recognition.](http://arxiv.org/abs/2401.01482) | 本文研究了在目标识别中将地理多样知识融入提示以提高地理鲁棒性的方法，探索了通过大型语言模型获取地理特定对象知识并结合CLIP视觉语言模型的零样本和可学习软提示。通过提出一种地理知识正则化方法，实现了从源地理位置推广到未见目标地理位置的鲁棒性提升。 |
| [^37] | [Token Propagation Controller for Efficient Vision Transformer.](http://arxiv.org/abs/2401.01470) | 本文提出一种新颖的令牌传播控制器（TPC），通过结合暂停概率和重新开始概率，实现了对令牌的减少和重复利用的控制，从而提高了视觉Transformer的效率和令牌利用率。 |
| [^38] | [Question-Answering Based Summarization of Electronic Health Records using Retrieval Augmented Generation.](http://arxiv.org/abs/2401.01469) | 提出了一种基于检索增强生成的问答式电子健康记录摘要方法，通过结合语义搜索、RAG和最新的LLMs，摘要是提取被专业人士认为重要的特定问题的答案。 |
| [^39] | [Outlier Ranking in Large-Scale Public Health Streams.](http://arxiv.org/abs/2401.01459) | 本论文提出了一种在大规模公共卫生数据流中排名异常值的任务，并通过结合层级网络和极值分析的新算法，在人工专家评估中表现最好。最重要的是，专家们使用了我们的实现后，发现值得调查的异常值的速度提高了9.1倍。 |
| [^40] | [Concurrent Self-testing of Neural Networks Using Uncertainty Fingerprint.](http://arxiv.org/abs/2401.01458) | 本文提出了使用不确定性指纹进行神经网络的并发自测的方法，可以在在线操作中检测并纠正单个和多个永久和软错误，适用于始终开启的安全关键应用。 |
| [^41] | [Hierarchical Over-the-Air Federated Learning with Awareness of Interference and Data Heterogeneity.](http://arxiv.org/abs/2401.01442) | 本文介绍了一种具有干扰和数据异质性意识的分层无线联邦学习方法，通过优化接收机的归一化因子来最小化干扰影响，并利用梯度聚合对抗数据异质性，实现了较高的学习准确性，并且可以优于传统的分层算法。 |
| [^42] | [Modular Learning of Deep Causal Generative Models for High-dimensional Causal Inference.](http://arxiv.org/abs/2401.01426) | 本文提出了一种用于高维因果推断的模块化深度生成模型学习算法，该算法利用预训练的模型来回答由高维数据引起的因果查询。 |
| [^43] | [SwapTransformer: highway overtaking tactical planner model via imitation learning on OSHA dataset.](http://arxiv.org/abs/2401.01425) | 本文旨在通过在OSHA数据集上的模仿学习，设计高速公路上的自动超车和换道策略规划模型SwapTransformer。通过引入辅助任务和比较基准模型，证明了该模型在仿真环境中的性能优势。 |
| [^44] | [Quantifying the Uniqueness of Donald Trump in Presidential Discourse.](http://arxiv.org/abs/2401.01405) | 这项研究使用了一种新的度量标准来量化唐纳德·特朗普在总统演讲中的独特性，并发现了他在使用具有分裂性和对抗性的语言、重复强调等方面与其他总统候选人存在显著差异。此外，特朗普比共和党同僚更具独特性。 |
| [^45] | [Directional Antenna Systems for Long-Range Through-Wall Human Activity Recognition.](http://arxiv.org/abs/2401.01388) | 本论文研究了适用于长距离穿墙人体活动识别的定向天线系统，提出了ESP32-S3与定向双极天线和ESP32-S3与印刷倒F天线结合的两个有前景的系统。这些系统在WiFi-based HAR中展现出出色的性能。 |
| [^46] | [Strong Transitivity Relations and Graph Neural Networks.](http://arxiv.org/abs/2401.01384) | 这项研究提出了一种基于传递关系的相似性扩展，通过引入传递图神经网络（TransGNN）从全局和局部的角度捕捉整个图的相似性，显著提高了几个GNN模型的性能。 |
| [^47] | [Predicting Infant Brain Connectivity with Federated Multi-Trajectory GNNs using Scarce Data.](http://arxiv.org/abs/2401.01383) | 我们提出了一种使用联邦多轨迹GNN的方法，通过稀缺数据预测婴儿脑连接性。通过联邦学习，我们通过聚合多个医院的本地学习结果来提高模型性能，同时保护数据隐私。 |
| [^48] | [Does Few-shot Learning Suffer from Backdoor Attacks?.](http://arxiv.org/abs/2401.01377) | 本研究探索了少样本学习对后门攻击的脆弱性，并提出了少样本学习后门攻击方法（FLBA）。 |
| [^49] | [Boosting Defect Detection in Manufacturing using Tensor Convolutional Neural Networks.](http://arxiv.org/abs/2401.01373) | 我们引入了一种张量卷积神经网络（T-CNN）来提高制造业中的缺陷检测任务，通过减少模型参数空间，我们实现了比等效CNN模型更快的训练速度和性能。与传统的人类视觉检查相比，在质量指标方面，T-CNN在参数数量上只有15倍少，训练时间快4%至19%。这项研究在实际制造应用中取得了显著的成果。 |
| [^50] | [RL-MPCA: A Reinforcement Learning Based Multi-Phase Computation Allocation Approach for Recommender Systems.](http://arxiv.org/abs/2401.01369) | RL-MPCA是一种基于强化学习的多阶段计算分配方法，用于解决推荐系统中在计算资源有限情况下的计算成本和业务收益之间的权衡问题。 |
| [^51] | [Multi-Modal Cognitive Maps based on Neural Networks trained on Successor Representations.](http://arxiv.org/abs/2401.01364) | 该研究通过使用神经网络和后继表示训练，建立了一个能够模拟位置细胞动态和认知地图表示的多模态认知地图模型。该模型能够以超过90%的准确率从一种形式推断到另一种形式，对于改善当前人工智能系统对环境的理解具有潜在意义。 |
| [^52] | [The Anatomy Spread of Online Opinion Polarization: The Pivotal Role of Super-Spreaders in Social Networks.](http://arxiv.org/abs/2401.01349) | 该研究揭示了在社交网络中塑造意见的超级传播者的重要角色，通过对超级传播者行为的调查和分析，提供了对群体动态和意见形成的条件的理解，对改进在线交流安全和社交影响力的认识具有启示作用。 |
| [^53] | [IoTGeM: Generalizable Models for Behaviour-Based IoT Attack Detection.](http://arxiv.org/abs/2401.01343) | 本研究提出了一种通用模型，用于基于行为的物联网攻击检测。该模型通过改进滚动窗口特征提取、引入多步骤特征选择、使用隔离的训练和测试数据集以及使用可解释的人工智能技术来提高检测和性能，并且经过严格评估。 |
| [^54] | [Fairness Certification for Natural Language Processing and Large Language Models.](http://arxiv.org/abs/2401.01262) | 这项研究旨在为自然语言处理领域开发公平性认证方法。通过综述大量文献和专家访谈，我们提出了六个公平性标准，为操作化和测试过程提供了基础。 |
| [^55] | [Vietnamese Poem Generation & The Prospect Of Cross-Language Poem-To-Poem Translation.](http://arxiv.org/abs/2401.01078) | 本文通过使用大型语言模型，成功提出了一种生成越南诗歌的方法，并探索了将诗歌翻译成不同语言的可能性，同时保持对生成内容的完全控制。 |
| [^56] | [Brain-Conditional Multimodal Synthesis: A Survey and Taxonomy.](http://arxiv.org/abs/2401.00430) | 脑条件多模态合成是一项利用脑信号解码为知觉体验的技术，可以用于开发实用的脑-计算机接口系统以及揭示大脑感知和理解外部刺激的复杂机制。 |
| [^57] | [Diffusion Model with Perceptual Loss.](http://arxiv.org/abs/2401.00110) | 本研究介绍了一种使用感知损失的扩散模型，通过无分类器指导实现了生成更真实样本的目的。 |
| [^58] | [SVGDreamer: Text Guided SVG Generation with Diffusion Model.](http://arxiv.org/abs/2312.16476) | 该论文提出了一种名为SVGDreamer的方法，用于基于文本引导的SVG生成。它通过引入语义驱动的图像矢量化过程和基于注意力的元素控制，增强了生成结果的可编辑性和质量。同时，采用基于矢量化粒子分数蒸馏的方法解决了现有方法中的颜色、平滑度和结果多样性方面的挑战。 |
| [^59] | [LLM-SAP: Large Language Model Situational Awareness Based Planning.](http://arxiv.org/abs/2312.16127) | 本文提出了一种基于大型语言模型的情景感知的紧急规划能力评估方法，并提供了新的基准和指标，以及独特的数据集。研究结果表明，提示和多智能体方案可以显著提高上下文敏感规划任务的性能。 |
| [^60] | [Unlocking the Potential of Large Language Models for Explainable Recommendations.](http://arxiv.org/abs/2312.15661) | 本研究提出了LLMXRec框架，一种简单而有效的两阶段解释推荐方法，利用大型语言模型进一步提升解释质量，通过与先前的推荐模型密切协作，在推荐效果和解释质量方面取得了显著提升。 |
| [^61] | [Recourse under Model Multiplicity via Argumentative Ensembling (Technical Report).](http://arxiv.org/abs/2312.15097) | 本研究提出了一种名为“追索感知的集成”的方法，通过使用计算论证方法来解决模型多样性下提供反事实解释的挑战性。该方法保证了在模型多样性情况下CEs的鲁棒性，并可以适应用户的个性化偏好。 |
| [^62] | [Not All Steps are Equal: Efficient Generation with Progressive Diffusion Models.](http://arxiv.org/abs/2312.13307) | 提出了一种步骤自适应训练的两阶段策略，解决了传统扩散模型中训练过程中的冲突问题，将模型大小调整与噪声预测难度相匹配，提高了生成效果。 |
| [^63] | [Retrieval-Augmented Generation for Large Language Models: A Survey.](http://arxiv.org/abs/2312.10997) | 本综述论文调查了基于检索增强的大型语言模型的发展，包括三个主要范式：Naive RAG、Advanced RAG和Modular RAG。RAG通过整合外部数据库的知识，增强模型的准确性和可信度，并实现了持续更新知识和整合领域特定信息的功能。 |
| [^64] | [EQ-Bench: An Emotional Intelligence Benchmark for Large Language Models.](http://arxiv.org/abs/2312.06281) | EQ-Bench是一种为评估大型语言模型（LLMs）的情商而设计的新型基准。该基准通过要求模型预测对话中角色的情绪状态强度来评估模型对复杂情绪和社交交互的理解能力。它能够有效区分不同模型，并与其他综合基准相关性很高。 |
| [^65] | [SkateboardAI: The Coolest Video Action Recognition for Skateboarding.](http://arxiv.org/abs/2311.11467) | 我们提出了SkateboardAI，这是一个用于最酷的滑板视频动作识别的数据集。我们设计了多种单模态和多模态的识别方法，并比较了它们的性能。这个研究的目标是开发一个优秀的AI体育裁判。 |
| [^66] | [Jina Embeddings 2: 8192-Token General-Purpose Text Embeddings for Long Documents.](http://arxiv.org/abs/2310.19923) | Jina Embeddings 2是一个能够处理长篇文档的文本嵌入模型，突破了传统512个标记限制，提供了高达8192个标记的容量。 |
| [^67] | [Othello is Solved.](http://arxiv.org/abs/2310.19387) | Othello是世界上最复杂和受欢迎的游戏之一，经过计算证明双方玩家的完美游戏将导致平局。 |
| [^68] | [Understanding the Effects of RLHF on LLM Generalisation and Diversity.](http://arxiv.org/abs/2310.06452) | 本研究深入分析了强化学习从人类反馈中调整的大型语言模型每个阶段对超出分布泛化和输出多样性的影响。 |
| [^69] | [GMMFormer: Gaussian-Mixture-Model Based Transformer for Efficient Partially Relevant Video Retrieval.](http://arxiv.org/abs/2310.05195) | GMMFormer是一种基于高斯混合模型的Transformer，用于高效的部分相关视频检索。它通过隐式建模剪辑表示，采用多尺度剪辑信息，并引入了一个多样性损失函数来解决语义差异导致的稀疏嵌入空间问题。 |
| [^70] | [What's the Magic Word? A Control Theory of LLM Prompting.](http://arxiv.org/abs/2310.04444) | 本论文将提示工程形式化为LLM上的最优控制问题，研究了给定token序列时是否存在一种最优提示能够准确预测最终的token，并提出了控制理论中的指标来描述LLM的可操纵性。 |
| [^71] | [Dynamic Relation-Attentive Graph Neural Networks for Fraud Detection.](http://arxiv.org/abs/2310.04171) | 本研究针对欺诈检测问题，通过动态关系注意聚合机制，提出了一种基于图神经网络（GNN）的方法。该方法学习每个关系的节点表示，并利用可学习的注意函数进行节点表示的聚合。通过结合不同层次的节点表示，考虑目标节点的局部和全局结构，以提高欺诈检测性能。通过使用动态图注意力，可以自适应地计算关系之间的重要程度。 |
| [^72] | [On Memorization and Privacy Risks of Sharpness Aware Minimization.](http://arxiv.org/abs/2310.00488) | 本研究通过对过度参数化模型中的数据记忆的剖析，揭示了尖锐意识最小化算法在非典型数据点上实现的泛化收益。同时，也发现了与此算法相关的更高隐私风险，并提出了缓解策略，以达到更理想的准确度与隐私权衡。 |
| [^73] | [Accurate and Fast Compressed Video Captioning.](http://arxiv.org/abs/2309.12867) | 这项研究提出了一种准确快速的压缩视频字幕生成方法，通过从压缩域进行学习，避免了手动帧采样和冗余处理，提高了性能和效率。 |
| [^74] | [Incentivizing Massive Unknown Workers for Budget-Limited Crowdsensing: From Off-Line and On-Line Perspectives.](http://arxiv.org/abs/2309.12113) | 本文提出了一种离线的基于上下文感知的CMAB激励（CACI）机制，通过对一个精细划分的上下文空间中的探索-开发权衡，有效地激励具有非常有限预算的大规模未知工作者。 |
| [^75] | [Investigating the Applicability of Self-Assessment Tests for Personality Measurement of Large Language Models.](http://arxiv.org/abs/2309.08163) | 研究发现，使用自我评估测试对大型语言模型的人格进行测量时，不同的提示会导致非常不同的人格得分，因此缺乏客观标准来判断哪个提示更正确。 |
| [^76] | [Minimum Coverage Sets for Training Robust Ad Hoc Teamwork Agents.](http://arxiv.org/abs/2308.09595) | 这篇论文提出了最小覆盖集合（MCS）概念，通过训练代理模拟MCS中的最佳策略，提高了自组织团队协作代理的鲁棒性。 |
| [^77] | [TIAM -- A Metric for Evaluating Alignment in Text-to-Image Generation.](http://arxiv.org/abs/2307.05134) | 本文提出了一种评估文本到图像生成中对齐性的新度量方法TIAM，该方法基于提示模板，可以更好地描述生成图像与提示中内容的对齐程度，包括对象类型、数量和颜色。研究结果表明，图像质量可以有很大的变化。 |
| [^78] | [LMBot: Distilling Graph Knowledge into Language Model for Graph-less Deployment in Twitter Bot Detection.](http://arxiv.org/abs/2306.17408) | LMBot是一种新颖的推特机器人检测框架，将图神经网络的知识融入到语言模型中，实现了无图形部署，以解决数据依赖性的挑战。 |
| [^79] | [Computationally Assisted Quality Control for Public Health Data Streams.](http://arxiv.org/abs/2306.16914) | 开发了一个实用的异常点检测框架FlaSH，用于公共卫生数据流。该框架考虑了数据量和统计特性，并在实验中展现了良好的性能。 |
| [^80] | [LaDe: The First Comprehensive Last-mile Delivery Dataset from Industry.](http://arxiv.org/abs/2306.10675) | LaDe是第一个公开可用的末端配送数据集，包含了数百万个来自产业界的包裹，具有大规模、全面的信息和多样性的特点。 |
| [^81] | [Hyperbolic Graph Diffusion Model for Molecule Generation.](http://arxiv.org/abs/2306.07618) | 本文提出了基于双曲图扩散模型的分子生成方法，可以更全面地捕捉分子的内部非欧几里德结构，实现数据生成，并提取复杂几何特征的能力。 |
| [^82] | [EmotionGesture: Audio-Driven Diverse Emotional Co-Speech 3D Gesture Generation.](http://arxiv.org/abs/2305.18891) | 本文提出了EmotionGesture框架，可以从音频中生成生动多样的情感共语3D手势。通过情感-节奏挖掘模块提取情感和音频节奏特征，并建模它们之间的关联；然后使用空间-时间提示器从给定的初始姿势生成未来的手势，实现空间-时间一致的姿势提示。 |
| [^83] | [Logit-Q Dynamics for Efficient Learning in Stochastic Teams.](http://arxiv.org/abs/2302.09806) | 本文提出了两种Logit-Q学习动力学，通过将经典和独立的对数线性学习更新与在政策上的值迭代更新相结合，实现了在随机博弈中的高效学习。通过对比和量化分析，证明了该动力学在随机团队中可以达到（接近）高效均衡。 |
| [^84] | [Low Variance Off-policy Evaluation with State-based Importance Sampling.](http://arxiv.org/abs/2212.03932) | 本文提出了一种基于状态的重要性抽样（SIS）方法，通过检测“忽略状态”的子轨迹来实现低方差的离线评估。 |
| [^85] | [Disentangled (Un)Controllable Features.](http://arxiv.org/abs/2211.00086) | 该论文提出了一种新方法，可以将潜在特征分解为可控和不可控的部分，并证明了这种分解表示在不同环境中易于解释和使用可解释的规划算法。 |
| [^86] | [TrAISformer-A generative transformer for AIS trajectory prediction.](http://arxiv.org/abs/2109.03958) | 本文提出了一种新颖的离散、高维表示的AIS数据和一种新的损失函数，用于显式考虑异质性和多样性，并通过修改变压器网络来预测船舶位置。实验证明，该模型明显优于现有的最新方法。 |

# 详细

[^1]: 在野外使用FMCW雷达进行步长测量

    Step length measurement in the wild using FMCW radar. (arXiv:2401.01868v1 [cs.CV])

    [http://arxiv.org/abs/2401.01868](http://arxiv.org/abs/2401.01868)

    该论文提出了一种基于FMCW雷达的在家中进行步长测量的系统，通过雷达点云的检测和跟踪，以及对躯干的多普勒速度分析来获取步长信息。这填补了现有基于雷达的步长测量方法在家庭环境中的研究空白，并具有预测风险的重要意义。

    

    随着人口老龄化，许多辅助和监测技术正在开发中，以使老年人能够在家中养老。为了促进在家中养老，预测跌倒、住院等风险因素，并提供早期干预非常重要。目前，关于风险预测的环境监测工作主要集中在步态速度分析方面，利用隐私保护传感器如雷达来进行。尽管已有强有力的证据表明除步态速度外，步长的监测对于预测风险同样重要，但基于雷达的方法尚未研究在家庭环境中的步长测量。此外，基于雷达的步长测量实验仅限于几位健康受试者的概念验证研究。为了弥补这一空白，提出了一种基于雷达点云检测和跟踪、通过雷达多普勒速度对躯干进行分析以获取步长的家庭基于雷达的步长测量系统。

    With an aging population, numerous assistive and monitoring technologies are under development to enable older adults to age in place. To facilitate aging in place predicting risk factors such as falls, and hospitalization and providing early interventions are important. Much of the work on ambient monitoring for risk prediction has centered on gait speed analysis, utilizing privacy-preserving sensors like radar. Despite compelling evidence that monitoring step length, in addition to gait speed, is crucial for predicting risk, radar-based methods have not explored step length measurement in the home. Furthermore, laboratory experiments on step length measurement using radars are limited to proof of concept studies with few healthy subjects. To address this gap, a radar-based step length measurement system for the home is proposed based on detection and tracking using radar point cloud, followed by Doppler speed profiling of the torso to obtain step lengths in the home. The proposed met
    
[^2]: 多语言指令调优中的多语言性

    Multilingual Instruction Tuning With Just a Pinch of Multilinguality. (arXiv:2401.01854v1 [cs.CL])

    [http://arxiv.org/abs/2401.01854](http://arxiv.org/abs/2401.01854)

    本研究研究了多语言指令调优中的多语言性对跨语言指令遵循的影响。研究发现，即使在单语调优过程中，许多语言也可以将一些指令遵循能力转移到其他语言上。此外，只有40个多语言示例能够显著提高多语言指令遵循。总体来说，多语言混合调优的模型在多种语言上的表现相比单语调优的模型要好或者不相上下，尽管使用的这些语言的训练示例数量只有10倍少。

    

    随着大型语言模型（LLMs）的全球采纳，它们在多语言指令遵循能力变得越来越重要。一种有前途的方法是跨语言转移，通过在另一种语言上微调，模型可以在某种语言上获得特定的功能。本文研究了多语言LLM在指令调优过程中的多语言性对跨语言指令遵循的影响。首先我们发现，即使在单语调优过程中，许多语言也可以将一些指令遵循能力转移到其他语言上。此外，我们发现在英语调优集合中，只有40个多语言示例能够显著提高多语言指令遵循，在调优过程中不论是已见语言还是未见语言。总的来说，我们观察到在多语言混合调优的模型在多种语言上的表现相比单语调优的模型要好或者不相上下，尽管使用的这些语言的训练示例数量只有10倍少。

    As instruction-tuned large language models (LLMs) gain global adoption, their ability to follow instructions in multiple languages becomes increasingly crucial. One promising approach is cross-lingual transfer, where a model acquires specific functionality on some language by finetuning on another language. In this work, we investigate how multilinguality during instruction tuning of a multilingual LLM affects instruction-following across languages. We first show that many languages transfer some instruction-following capabilities to other languages from even monolingual tuning. Furthermore, we find that only 40 multilingual examples in an English tuning set substantially improve multilingual instruction-following, both in seen and unseen languages during tuning. In general, we observe that models tuned on multilingual mixtures exhibit comparable or superior performance in several languages compared to monolingually tuned models, despite training on 10x fewer examples in those language
    
[^3]: 训练的力量：不同的神经网络设置对能源需求的影响

    The Power of Training: How Different Neural Network Setups Influence the Energy Demand. (arXiv:2401.01851v1 [cs.LG])

    [http://arxiv.org/abs/2401.01851](http://arxiv.org/abs/2401.01851)

    本文研究了机器学习训练方案和学习范式对能源消耗的影响，并探讨了预训练和多任务训练在可持续机器学习方面的潜力。

    

    本研究探讨机器学习训练方案和学习范式的变化对相应能源消耗的影响。虽然数据的可用性提高和高性能硬件的创新推动了复杂模型的训练，但也支持了能源消耗和碳排放的消隐。因此，本研究的目标是增加人们对一般训练参数和过程（从学习率到批量大小再到知识传输）的能源影响的认识。使用不同的超参数初始化在两种不同的硬件配置上评估多种设置，以获得有意义的结果。在基准结果上进行了预训练和多任务训练实验，以确定它们对可持续机器学习的潜力。

    This work examines the effects of variations in machine learning training regimes and learning paradigms on the corresponding energy consumption. While increasing data availability and innovation in high-performance hardware fuels the training of sophisticated models, it also supports the fading perception of energy consumption and carbon emission. Therefore, the goal of this work is to create awareness about the energy impact of general training parameters and processes, from learning rate over batch size to knowledge transfer. Multiple setups with different hyperparameter initializations are evaluated on two different hardware configurations to obtain meaningful results. Experiments on pretraining and multitask training are conducted on top of the baseline results to determine their potential towards sustainable machine learning.
    
[^4]: 按照你的学习行动：非稳态马尔可夫决策过程中的自适应决策

    Act as You Learn: Adaptive Decision-Making in Non-Stationary Markov Decision Processes. (arXiv:2401.01841v1 [cs.AI])

    [http://arxiv.org/abs/2401.01841](http://arxiv.org/abs/2401.01841)

    本文提出了一种自适应蒙特卡洛树搜索算法来应对非稳态环境下的决策问题，解决了传统方法中对环境动态假设的限制和规划过程的悲观性问题。

    

    在顺序决策中，处理非稳态环境是一个基本（且在很大程度上是未解决的）挑战，其中外部环境条件随时间变化。这类问题通常被建模为非稳态马尔可夫决策过程（NSMDP）。然而，现有的NSMDP决策方法存在两个主要缺点：首先，它们假设当前时刻更新的环境动态是已知的（尽管未来动态可能会改变）；其次，规划过程主要是悲观的，即代理人会“安全行动”以考虑环境的非稳态演变。我们认为这两个假设在实践中是无效的-更新的环境条件很少是已知的，并且当代理人与环境交互时，它可以学习更新的动态并避免悲观，至少在其对动态有信心的状态下。我们提出了一种启发式搜索算法，称为自适应蒙特卡洛树搜索。

    A fundamental (and largely open) challenge in sequential decision-making is dealing with non-stationary environments, where exogenous environmental conditions change over time. Such problems are traditionally modeled as non-stationary Markov decision processes (NSMDP). However, existing approaches for decision-making in NSMDPs have two major shortcomings: first, they assume that the updated environmental dynamics at the current time are known (although future dynamics can change); and second, planning is largely pessimistic, i.e., the agent acts ``safely'' to account for the non-stationary evolution of the environment. We argue that both these assumptions are invalid in practice -updated environmental conditions are rarely known, and as the agent interacts with the environment, it can learn about the updated dynamics and avoid being pessimistic, at least in states whose dynamics it is confident about. We present a heuristic search algorithm called \textit{Adaptive Monte Carlo Tree Se
    
[^5]: NODEC: 用于未知动态系统最优控制的神经ODE

    NODEC: Neural ODE For Optimal Control of Unknown Dynamical Systems. (arXiv:2401.01836v1 [cs.AI])

    [http://arxiv.org/abs/2401.01836](http://arxiv.org/abs/2401.01836)

    NODEC是一种用神经ODE模型将动力学建模与控制器训练相结合的新框架，用于控制未知动态系统。

    

    控制复杂动态系统通常涉及在变化计算框架下最小化具有已知动力学的某些控制目标。对于具有未知动力学的系统，需要额外进行动力学建模。然而，动力学建模的任何不准确都会导致结果控制函数的次优性。另一种用于控制未知动态系统的方法 - 强化学习，将动力学建模融入控制器训练中，通过与环境的广泛交互来近似值函数或策略梯度，但它的数据效率低。为了解决这些问题，我们引入了NODEC，这是一种用神经ODE模型将动力学建模与控制器训练相结合的新框架。通过两个耦合神经网络之间的有趣相互作用，NODEC学习了系统动力学以及指导未知动态系统的最优控制。

    Controlling complex dynamical systems is generally associated with minimizing certain control objectives with known dynamics under the variational calculus framework. For systems with unknown dynamics, an additional step of dynamics modeling is required. However, any inaccuracy in dynamics modeling will lead to sub-optimality in the resulting control function. Another set of approaches for controlling unknown dynamical systems - reinforcement learning, folds the dynamics modeling into controller training via value function approximation or policy gradient through extensively interacting with the environment, but it suffers from low data efficiency. To address these, we introduce NODEC, a novel framework for controlling unknown dynamical systems, which combines dynamics modelling and controller training using a coupled neural ODE model. Through an intriguing interplay between the two coupled neural networks, NODEC learns system dynamics as well as optimal controls that guides the unknow
    
[^6]: 并发头脑风暴和假设满足：一种增强检索增强生成的迭代框架

    Concurrent Brainstorming & Hypothesis Satisfying: An Iterative Framework for Enhanced Retrieval-Augmented Generation (R2CBR3H-SR). (arXiv:2401.01835v1 [cs.IT])

    [http://arxiv.org/abs/2401.01835](http://arxiv.org/abs/2401.01835)

    本论文介绍了一种迭代的检索增强生成系统，通过并发的头脑风暴和假设满足相结合的策略，加快了高度相关文档的检索，并简化了查询的生成过程，提高了处理效率和准确性。

    

    为了解决全面信息检索的复杂性，本研究引入了一种创新的迭代检索增强生成系统。我们的方法独特地将向量空间驱动的重新排名机制与并发的头脑风暴相结合，加快高度相关文档的检索，从而简化潜在查询的生成。这为我们的新颖混合过程铺平了道路，该过程以假设形成和满足决策策略相结合，利用基于思维链的提示技术确定内容的充分性。这个统一的假设满意阶段智能地提炼信息，确定用户的查询是否得到满意的解答。达到这个标准后，系统将其输出精炼为简洁的表示形式，最大限度地提高概念密度，同时减少冗长。迭代的工作流增强了处理效率和准确性。

    Addressing the complexity of comprehensive information retrieval, this study introduces an innovative, iterative retrieval-augmented generation system. Our approach uniquely integrates a vector-space driven re-ranking mechanism with concurrent brainstorming to expedite the retrieval of highly relevant documents, thereby streamlining the generation of potential queries. This sets the stage for our novel hybrid process, which synergistically combines hypothesis formulation with satisfying decision-making strategy to determine content adequacy, leveraging a chain of thought-based prompting technique. This unified hypothesize-satisfied phase intelligently distills information to ascertain whether user queries have been satisfactorily addressed. Upon reaching this criterion, the system refines its output into a concise representation, maximizing conceptual density with minimal verbosity. The iterative nature of the workflow enhances process efficiency and accuracy. Crucially, the concurrenc
    
[^7]: 迭代掩码填充：一种使用掩码语言建模的有效文本增强方法

    Iterative Mask Filling: An Effective Text Augmentation Method Using Masked Language Modeling. (arXiv:2401.01830v1 [cs.CL])

    [http://arxiv.org/abs/2401.01830](http://arxiv.org/abs/2401.01830)

    本文提出了一种新颖的文本增强方法，利用基于Transformer的BERT模型的填充-掩码功能，通过迭代掩码和语言模型预测进行替换，显著提高了自然语言处理任务的性能。

    

    数据增强是提高机器学习模型性能的有效技术，但在自然语言处理领域，它的应用远不及计算机视觉领域广泛。本文提出了一种新颖的文本增强方法，利用基于Transformer的BERT模型的填充-掩码功能。我们的方法涉及对句子中的单词进行迭代掩码，并用语言模型预测进行替换。我们在各种自然语言处理任务上测试了我们的方法，并发现它在许多情况下都很有效。我们的实验结果与现有的增强方法进行了比较。实验结果表明，我们的方法在主题分类数据集上显著提高了性能。

    Data augmentation is an effective technique for improving the performance of machine learning models. However, it has not been explored as extensively in natural language processing (NLP) as it has in computer vision. In this paper, we propose a novel text augmentation method that leverages the Fill-Mask feature of the transformer-based BERT model. Our method involves iteratively masking words in a sentence and replacing them with language model predictions. We have tested our proposed method on various NLP tasks and found it to be effective in many cases. Our results are presented along with a comparison to existing augmentation methods. Experimental results show that our proposed method significantly improves performance, especially on topic classification datasets.
    
[^8]: 大型语言模型可以重新学习已删除的概念

    Large Language Models Relearn Removed Concepts. (arXiv:2401.01814v1 [cs.AI])

    [http://arxiv.org/abs/2401.01814](http://arxiv.org/abs/2401.01814)

    大型语言模型可以通过重新分配概念到不同层级和修剪前的神经元实现对已删除概念的重新学习，这表明模型具有多义能力，但同时也带来了在改善模型安全性方面的挑战。

    

    通过神经元修剪来改进模型编辑有望从大型语言模型中去除不理想的概念。然而，模型是否具有重新学习修剪掉的概念的能力仍不清楚。为了调查这个问题，我们通过跟踪修剪神经元中的概念显著性和相似性，在模型中评估了概念的重新学习。我们的研究发现，模型可以通过将高级概念重新分配给较早的层，并将修剪掉的概念重新分配给具有相似语义的神经元来迅速恢复修剪后的性能。这表明模型具有多义能力，可以在单个神经元中融合旧的和新的概念。尽管神经元修剪提供了对模型概念的可解释性，但我们的结果突显了永久删除概念以改善模型安全性的挑战。监控概念重新出现并开发减少重新学习不安全概念的技术将是更好的模型安全方向的重要研究方向。

    Advances in model editing through neuron pruning hold promise for removing undesirable concepts from large language models. However, it remains unclear whether models have the capacity to reacquire pruned concepts after editing. To investigate this, we evaluate concept relearning in models by tracking concept saliency and similarity in pruned neurons during retraining. Our findings reveal that models can quickly regain performance post-pruning by relocating advanced concepts to earlier layers and reallocating pruned concepts to primed neurons with similar semantics. This demonstrates that models exhibit polysemantic capacities and can blend old and new concepts in individual neurons. While neuron pruning provides interpretability into model concepts, our results highlight the challenges of permanent concept removal for improved model \textit{safety}. Monitoring concept reemergence and developing techniques to mitigate relearning of unsafe concepts will be important directions for more 
    
[^9]: 一个量子启发的用于几何建模的神经网络

    A quatum inspired neural network for geometric modeling. (arXiv:2401.01801v1 [cs.LG])

    [http://arxiv.org/abs/2401.01801](http://arxiv.org/abs/2401.01801)

    这个论文介绍了一种创新的矩阵乘积态(MPS)的消息传递策略，通过这种策略可以更好地捕捉几何图中的复杂关系。

    

    通过将物理系统构想为3D多体点云，几何图神经网络(GNN)，如SE(3)/E(3)等效GNN，展示了良好的性能。特别是，它们高效的消息传递机制使它们能够熟练地对分子和晶体材料进行建模。然而，当前的几何GNN只提供了多体系统的平均场近似，封装在两体消息传递中，因此在捕捉这些几何图中的复杂关系方面有所欠缺。为了解决这个局限性，计算物理学中广泛使用的高阶张量来处理多体系统的张量网络被引入。然而，将这些张量化网络整合到GNN的消息传递框架中面临着可扩展性和对称性保持（如置换和旋转）的挑战。作为回应，我们引入了一种创新的等变矩阵乘积态(MPS)的消息传递策略，通过实现一个

    By conceiving physical systems as 3D many-body point clouds, geometric graph neural networks (GNNs), such as SE(3)/E(3) equivalent GNNs, have showcased promising performance. In particular, their effective message-passing mechanics make them adept at modeling molecules and crystalline materials. However, current geometric GNNs only offer a mean-field approximation of the many-body system, encapsulated within two-body message passing, thus falling short in capturing intricate relationships within these geometric graphs. To address this limitation, tensor networks, widely employed by computational physics to handle manybody systems using high-order tensors, have been introduced. Nevertheless, integrating these tensorized networks into the message-passing framework of GNNs faces scalability and symmetry conservation (e.g., permutation and rotation) challenges. In response, we introduce an innovative equivariant Matrix Product State (MPS)-based message-passing strategy, through achieving a
    
[^10]: CoMoSVC: 基于一致性模型的唱歌声音转换

    CoMoSVC: Consistency Model-based Singing Voice Conversion. (arXiv:2401.01792v1 [eess.AS])

    [http://arxiv.org/abs/2401.01792](http://arxiv.org/abs/2401.01792)

    本文提出了一种基于一致性模型的唱歌声音转换方法。通过设计扩散教师模型和提取自一致性学生模型，该方法实现了高质量的声音生成和高速的采样，相比于最先进的扩散方法，具有更快的推理速度，并在主观和客观指标上实现了可比或更优的声音转换性能。

    

    基于扩散的唱歌声音转换（SVC）方法已经取得了显著的性能，产生了与目标音色相似度高的自然音频。然而，迭代采样过程导致推理速度慢，因此加速变得至关重要。在本文中，我们提出了基于一致性模型的CoMoSVC方法，旨在实现高质量生成和高速采样。首先，设计了针对SVC的基于扩散的教师模型，然后通过自一致性特性进一步提取学生模型，实现一步采样。在单个NVIDIA GTX4090 GPU上进行的实验证明，虽然CoMoSVC的推理速度比最先进的（SOTA）基于扩散的SVC系统要快得多，但在主观和客观指标上仍实现了可比或更优的转换性能。音频样本和代码可在网址https://comosvc.github.io/获取。

    The diffusion-based Singing Voice Conversion (SVC) methods have achieved remarkable performances, producing natural audios with high similarity to the target timbre. However, the iterative sampling process results in slow inference speed, and acceleration thus becomes crucial. In this paper, we propose CoMoSVC, a consistency model-based SVC method, which aims to achieve both high-quality generation and high-speed sampling. A diffusion-based teacher model is first specially designed for SVC, and a student model is further distilled under self-consistency properties to achieve one-step sampling. Experiments on a single NVIDIA GTX4090 GPU reveal that although CoMoSVC has a significantly faster inference speed than the state-of-the-art (SOTA) diffusion-based SVC system, it still achieves comparable or superior conversion performance based on both subjective and objective metrics. Audio samples and codes are available at https://comosvc.github.io/.
    
[^11]: 深度学习线性分数过程的Hurst参数及其可靠性评估

    Deep learning the Hurst parameter of linear fractional processes and assessing its reliability. (arXiv:2401.01789v1 [stat.ML])

    [http://arxiv.org/abs/2401.01789](http://arxiv.org/abs/2401.01789)

    本研究利用深度学习（特别是LSTM网络）评估了分数随机过程中的Hurst参数，并探讨了其可靠性。实证结果表明，在分数布朗运动和分数奥恩斯坦-乌伦贝克过程中，LSTM网络优于传统统计方法，但在线性分数稳定运动过程中准确性受限。

    

    本研究探讨了深度学习（特别是长短时记忆网络）在估计分数随机过程中的Hurst参数的可靠性。研究集中在三种类型的过程上：分数布朗运动（fBm），分数奥恩斯坦-乌伦贝克（fOU）过程和线性分数稳定运动（lfsm）。研究包括对fBm和fOU的大规模数据集的快速生成，以便在合理的时间内训练LSTM网络。研究分析了LSTM网络在Hurst参数估计方面的准确性，包括均方根误差（RMSE），平均绝对误差（MAE），相对误差的分位数等各种性能指标。研究发现，在fBm和fOU过程的情况下，LSTM优于传统的统计方法；然而，在lfsm过程上的准确性有限。研究还深入探讨了训练长度和评估序列长度对LSTM性能的影响。该方法被应用于...

    This research explores the reliability of deep learning, specifically Long Short-Term Memory (LSTM) networks, for estimating the Hurst parameter in fractional stochastic processes. The study focuses on three types of processes: fractional Brownian motion (fBm), fractional Ornstein-Uhlenbeck (fOU) process, and linear fractional stable motions (lfsm). The work involves a fast generation of extensive datasets for fBm and fOU to train the LSTM network on a large volume of data in a feasible time. The study analyses the accuracy of the LSTM network's Hurst parameter estimation regarding various performance measures like RMSE, MAE, MRE, and quantiles of the absolute and relative errors. It finds that LSTM outperforms the traditional statistical methods in the case of fBm and fOU processes; however, it has limited accuracy on lfsm processes. The research also delves into the implications of training length and valuation sequence length on the LSTM's performance. The methodology is applied by 
    
[^12]: 机器学习和物联网在室外空气污染监测和预测中的应用：一个系统文献综述

    Applications of machine learning and IoT for Outdoor Air Pollution Monitoring and Prediction: A Systematic Literature Review. (arXiv:2401.01788v1 [cs.LG])

    [http://arxiv.org/abs/2401.01788](http://arxiv.org/abs/2401.01788)

    本文系统综述了机器学习和物联网在室外空气污染预测中的应用，以及使用的监测传感器和输入特征的组合。研究结果突出了高成本监测、低成本物联网和混合预测这三种方法。

    

    根据世界卫生组织（WHO）的数据，空气污染每年致使七百万人死亡。室外空气污染是影响低收入、中收入和高收入国家的主要环境健康问题。在过去几年中，研究界已经探索了物联网和机器学习应用于室外空气污染预测的可能性。本文的总体目标是系统地综述机器学习和物联网在室外空气污染预测中的应用以及使用的监测传感器和输入特征的组合。本文为此综述制定了两个研究问题。在初始PRISMA阶段共收集了1086篇文献。通过筛选和确定资格的阶段，最终选择了37篇文章进行分析。对结果进行了基于成本的分析，突出了高成本监测、低成本物联网和混合预测。研究确定了三种预测方法：时间序列、基于特征和空间预测。

    According to the World Health Organization (WHO), air pollution kills seven million people every year. Outdoor air pollution is a major environmental health problem affecting low, middle, and high-income countries. In the past few years, the research community has explored IoT-enabled machine learning applications for outdoor air pollution prediction. The general objective of this paper is to systematically review applications of machine learning and Internet of Things (IoT) for outdoor air pollution prediction and the combination of monitoring sensors and input features used. Two research questions were formulated for this review. 1086 publications were collected in the initial PRISMA stage. After the screening and eligibility phases, 37 papers were selected for inclusion. A cost-based analysis was conducted on the findings to highlight high-cost monitoring, low-cost IoT and hybrid enabled prediction. Three methods of prediction were identified: time series, feature-based and spatio-t
    
[^13]: 一种新的神经计算范式：可学习神经元和可适应结构的X-Net

    A Novel Paradigm for Neural Computation: X-Net with Learnable Neurons and Adaptable Structure. (arXiv:2401.01772v1 [cs.AI])

    [http://arxiv.org/abs/2401.01772](http://arxiv.org/abs/2401.01772)

    本研究提出了一种名为X-Net的新型神经网络，通过利用交替反向传播机制，在训练过程中根据导数信息动态选择适当的激活函数，以增强网络的表示能力。

    

    人工神经网络(ANNs)已经渗透到各个学科领域，从生物信息学到金融分析，在当代科学研究中已经成为不可或缺的一部分。然而，传统神经网络的固定网络结构和激活函数的固有限制导致了一些问题。为了解决这些问题，本研究提出了一种称为X-Net的新型神经网络。通过利用我们设计的交替反向传播机制，在训练过程中根据导数信息动态选择适当的激活函数，以增强网络的表示能力。

    Artificial neural networks (ANNs) have permeated various disciplinary domains, ranging from bioinformatics to financial analytics, where their application has become an indispensable facet of contemporary scientific research endeavors. However, the inherent limitations of traditional neural networks arise due to their relatively fixed network structures and activation functions. 1, The type of activation function is single and relatively fixed, which leads to poor "unit representation ability" of the network, and it is often used to solve simple problems with very complex networks; 2, the network structure is not adaptive, it is easy to cause network structure redundant or insufficient. To address the aforementioned issues, this study proposes a novel neural network called X-Net. By utilizing our designed Alternating Backpropagation mechanism, X-Net dynamically selects appropriate activation functions based on derivative information during training to enhance the network's representati
    
[^14]: 增量式FastPitch：基于分块的高质量文本到语音合成

    Incremental FastPitch: Chunk-based High Quality Text to Speech. (arXiv:2401.01755v1 [cs.SD])

    [http://arxiv.org/abs/2401.01755](http://arxiv.org/abs/2401.01755)

    提出了增量式FastPitch，一种能够增量生成高质量Mel块的文本到语音合成模型。通过改进的架构和训练技术，以及固定大小的过去模型状态进行推理，它在实时语音应用中具有更低的延迟和更短的响应时间。

    

    并行的文本到语音模型在实时语音合成中得到了广泛应用，与传统的自回归模型相比，它们具有更多的可控性和更快的合成过程。尽管并行模型在许多方面都有优势，但由于其完全并行的架构（如transformer），它们在增量合成方面自然无法适应。在这项工作中，我们提出了增量式FastPitch，它是一种改进架构的FastPitch变体，能够通过改进的分块FFT块进行增量生成高质量的Mel块，通过受限接受域的分块注意力掩码进行训练，并通过固定大小的过去模型状态进行推理。实验结果表明，我们的提议能够产生与并行FastPitch相当的语音质量，同时具有显著更低的延迟，可以在实时语音应用中实现更低的响应时间。

    Parallel text-to-speech models have been widely applied for real-time speech synthesis, and they offer more controllability and a much faster synthesis process compared with conventional auto-regressive models. Although parallel models have benefits in many aspects, they become naturally unfit for incremental synthesis due to their fully parallel architecture such as transformer. In this work, we propose Incremental FastPitch, a novel FastPitch variant capable of incrementally producing high-quality Mel chunks by improving the architecture with chunk-based FFT blocks, training with receptive-field constrained chunk attention masks, and inference with fixed size past model states. Experimental results show that our proposal can produce speech quality comparable to the parallel FastPitch, with a significant lower latency that allows even lower response time for real-time speech applications.
    
[^15]: 使用AI/ML在代码和文档分享平台中查找和修复企业机密问题

    Using AI/ML to Find and Remediate Enterprise Secrets in Code & Document Sharing Platforms. (arXiv:2401.01754v1 [cs.SE])

    [http://arxiv.org/abs/2401.01754](http://arxiv.org/abs/2401.01754)

    该论文提出了一个新的挑战，即利用AI在代码和文档分享平台中准确检测和标记机密信息，并自动修复这些问题。研究人员引入了两种性能良好的基准AI模型，并提出了一种自动机制来修复发现的机密信息问题，为更广泛的社区打开了研究的可能性。

    

    我们向软件开发社区提出一个新的挑战：1）利用人工智能准确地检测和标记代码和常用文档分享平台中的机密信息，如Confluence，并且2）自动修复这些检测到的问题（例如，建议使用密码保险库功能）。这是一个具有挑战性且大多数情况下未解决的任务。现有方法利用启发式和正则表达式，但噪声很大，从而增加开发人员的工作量。下一步是修改代码本身，以自动修复检测到的问题，这是一个复杂的任务。我们引入了两种性能良好的基准AI模型，并提出了一个自动机制来修复在代码中发现的机密信息问题，从而将这个任务的研究扩展到更广泛的社区。

    We introduce a new challenge to the software development community: 1) leveraging AI to accurately detect and flag up secrets in code and on popular document sharing platforms that frequently used by developers, such as Confluence and 2) automatically remediating the detections (e.g. by suggesting password vault functionality). This is a challenging, and mostly unaddressed task. Existing methods leverage heuristics and regular expressions, that can be very noisy, and therefore increase toil on developers. The next step modifying code itself - to automatically remediate a detection, is a complex task. We introduce two baseline AI models that have good detection performance and propose an automatic mechanism for remediating secrets found in code, opening up the study of this task to the wider community.
    
[^16]: 一种利用生成型人工智能加速云迁移的助手

    A Generative AI Assistant to Accelerate Cloud Migration. (arXiv:2401.01753v1 [cs.AI])

    [http://arxiv.org/abs/2401.01753](http://arxiv.org/abs/2401.01753)

    一种利用生成型人工智能的助手，能够加速将本地应用程序迁移到云端，并通过提供迁移策略和架构图的方式帮助用户选择合适的迁移配置文件，避免手动方法的复杂性。

    

    我们提出了一种利用生成型人工智能的工具，以加快将本地应用程序迁移到云端。云迁移LLM接受用户输入，指定迁移参数，并输出具有架构图的迁移策略。一项用户研究表明，迁移LLM可以帮助没有经验的用户找到合适的云迁移配置文件，同时避免手动方法的复杂性。

    We present a tool that leverages generative AI to accelerate the migration of on-premises applications to the cloud. The Cloud Migration LLM accepts input from the user specifying the parameters of their migration, and outputs a migration strategy with an architecture diagram. A user study suggests that the migration LLM can assist inexperienced users in finding the right cloud migration profile, while avoiding complexities of a manual approach.
    
[^17]: 任务和解释网络

    Task and Explanation Network. (arXiv:2401.01732v1 [cs.LG])

    [http://arxiv.org/abs/2401.01732](http://arxiv.org/abs/2401.01732)

    该论文介绍了一个基本框架——任务和解释网络（TENet），它不仅能完成任务，还能解释为什么这样完成任务。它强调整个AI领域都应该重视可解释性。

    

    在最近几年中，深度网络的可解释性变得越来越重要。我们在此论文中提出，AI不仅要完成任务，还要解释为什么这样完成任务。我们提出了一个基本框架——任务和解释网络（TENet），它完全整合了任务完成和解释。我们认为整个AI领域都应该强调可解释性。

    Explainability in deep networks has gained increased importance in recent years. We argue herein that an AI must be tasked not just with a task but also with an explanation of why said task was accomplished as such. We present a basic framework -- Task and Explanation Network (TENet) -- which fully integrates task completion and its explanation. We believe that the field of AI as a whole should insist -- quite emphatically -- on explainability.
    
[^18]: Ravnest: 异构设备上的分散式异步训练

    Ravnest: Decentralized Asynchronous Training on Heterogeneous Devices. (arXiv:2401.01728v1 [cs.LG])

    [http://arxiv.org/abs/2401.01728](http://arxiv.org/abs/2401.01728)

    本文提出了一种用于大型现代深度学习模型的异步分散式训练范式，通过连接互联网上的资源受限的异构个人计算机，利用计算能力来实现有利的性能指标。Ravnest通过有效地将计算节点组织成具有类似数据传输速率和计算能力的集群，实现了分散式训练，而不需要每个节点承载整个模型。

    

    现代的深度学习模型越来越大、越来越复杂，通过在大型数据集上进行训练，已经展示出了异常的泛化和准确性。这一趋势预计将继续。然而，这些模型的增大使得传统的集中式方法在这种规模上受到内存限制的挑战。本文提出了一种用于大型现代深度学习模型的异步分散式训练范式，利用了连接在互联网上的资源受限的异构个人计算机的计算能力，以实现有利的性能指标。Ravnest通过有效地将计算节点组织成具有类似数据传输速率和计算能力的集群来实现分散式训练，而不需要每个节点承载整个模型。这些集群参与$\textit{零气泡异步模型并行}$训练，利用$\textit{并行多环全局汇聚}$方法可以有效地进行通信和模型聚合。

    Modern deep learning models, growing larger and more complex, have demonstrated exceptional generalization and accuracy due to training on huge datasets. This trend is expected to continue. However, the increasing size of these models poses challenges in training, as traditional centralized methods are limited by memory constraints at such scales. This paper proposes an asynchronous decentralized training paradigm for large modern deep learning models that harnesses the compute power of regular heterogeneous PCs with limited resources connected across the internet to achieve favourable performance metrics. Ravnest facilitates decentralized training by efficiently organizing compute nodes into clusters with similar data transfer rates and compute capabilities, without necessitating that each node hosts the entire model. These clusters engage in $\textit{Zero-Bubble Asynchronous Model Parallel}$ training, and a $\textit{Parallel Multi-Ring All-Reduce}$ method is employed to effectively e
    
[^19]: 在Feed中集成广告拍卖和分配的深度自动化机制设计

    Deep Automated Mechanism Design for Integrating Ad Auction and Allocation in Feed. (arXiv:2401.01656v1 [cs.GT])

    [http://arxiv.org/abs/2401.01656](http://arxiv.org/abs/2401.01656)

    本论文提出了一种深度自动化的机制设计，用于在Feed中集成广告拍卖和分配。这种设计解决了广告拍卖不考虑外部性和广告分配无法保持激励兼容性的问题。

    

    为了响应每个用户的页面请求，电子商务平台通常呈现一个有序列表，其中包含几个有机物品和一个广告。这个列表是广告拍卖和分配过程的结果，直接影响平台的广告收入和总交易额。广告拍卖确定显示的广告和相应的支付，而广告分配决定广告和有机物品的显示位置。目前的方法将广告拍卖和分配分为两个不同的阶段，面临两个问题：1）广告拍卖没有考虑外部性，如实际显示位置和上下文对广告点击率的影响；2）广告分配利用拍卖获胜广告的支付来动态确定显示位置，未能保持广告的激励兼容性。例如，在使用传统的广义二价(GSP)拍卖阶段，广告分配阶段无法维持激励兼容性。

    E-commerce platforms usually present an ordered list, mixed with several organic items and an advertisement, in response to each user's page view request. This list, the outcome of ad auction and allocation processes, directly impacts the platform's ad revenue and gross merchandise volume (GMV). Specifically, the ad auction determines which ad is displayed and the corresponding payment, while the ad allocation decides the display positions of the advertisement and organic items. The prevalent methods of segregating the ad auction and allocation into two distinct stages face two problems: 1) Ad auction does not consider externalities, such as the influence of actual display position and context on ad Click-Through Rate (CTR); 2) The ad allocation, which utilizes the auction-winning ad's payment to determine the display position dynamically, fails to maintain incentive compatibility (IC) for the advertisement. For instance, in the auction stage employing the traditional Generalized Secon
    
[^20]: AIGCBench：AI生成的图像到视频内容的全面评估

    AIGCBench: Comprehensive Evaluation of Image-to-Video Content Generated by AI. (arXiv:2401.01651v1 [cs.CV])

    [http://arxiv.org/abs/2401.01651](http://arxiv.org/abs/2401.01651)

    本论文介绍了AIGCBench，一个全面评估AI生成的图像到视频内容的基准。通过引入多样化且开放领域的图像-文本数据集，AIGCBench解决了现有基准的局限性。为了建立统一的评估框架，该基准包括11个度量指标，涵盖控制视频对齐、动态效果、时间一致性和视频质量等方面。

    

    人工智能生成内容（AIGC）领域正在迅速发展，尤其是视频生成。本论文介绍了AIGCBench，这是一种开创性的综合性和可扩展性基准，旨在评估各种视频生成任务，主要关注图像到视频（I2V）生成。AIGCBench解决了现有基准的局限性，这些基准缺乏多样化的数据集，通过包括一个多样化且开放领域的图像-文本数据集来评估不同的最先进算法在相等条件下的性能。我们采用了一种新颖的文本组合器和GPT-4来创建丰富的文本提示，然后使用先进的文本到图像模型生成图像。为了建立一个统一的视频生成任务评估框架，我们的基准包括11个度量指标，涵盖四个维度，以评估算法性能。这些维度是控制视频对齐，动态效果，时间一致性和视频质量。

    The burgeoning field of Artificial Intelligence Generated Content (AIGC) is witnessing rapid advancements, particularly in video generation. This paper introduces AIGCBench, a pioneering comprehensive and scalable benchmark designed to evaluate a variety of video generation tasks, with a primary focus on Image-to-Video (I2V) generation. AIGCBench tackles the limitations of existing benchmarks, which suffer from a lack of diverse datasets, by including a varied and open-domain image-text dataset that evaluates different state-of-the-art algorithms under equivalent conditions. We employ a novel text combiner and GPT-4 to create rich text prompts, which are then used to generate images via advanced Text-to-Image models. To establish a unified evaluation framework for video generation tasks, our benchmark includes 11 metrics spanning four dimensions to assess algorithm performance. These dimensions are control-video alignment, motion effects, temporal consistency, and video quality. These 
    
[^21]: 一个适用于带有人工智能组件的系统的网络安全风险分析框架

    A Cybersecurity Risk Analysis Framework for Systems with Artificial Intelligence Components. (arXiv:2401.01630v1 [cs.AI])

    [http://arxiv.org/abs/2401.01630](http://arxiv.org/abs/2401.01630)

    本文提供了一个网络安全风险分析框架，旨在评估带有人工智能组件的系统。研究人员使用了自动驾驶系统作为示例来说明该框架的应用。

    

    随着欧盟人工智能法案、NIST人工智能风险管理框架以及相关规范的引入，更好地理解和实施评估带有人工智能组件的系统的新型风险分析方法变得至关重要。本文提供了一个网络安全风险分析框架，可以帮助评估此类系统。我们使用了一个关于自动驾驶系统的示例来说明。

    The introduction of the European Union Artificial Intelligence Act, the NIST Artificial Intelligence Risk Management Framework, and related norms demands a better understanding and implementation of novel risk analysis approaches to evaluate systems with Artificial Intelligence components. This paper provides a cybersecurity risk analysis framework that can help assessing such systems. We use an illustrative example concerning automated driving systems.
    
[^22]: AI中的合成数据:挑战，应用和伦理影响

    Synthetic Data in AI: Challenges, Applications, and Ethical Implications. (arXiv:2401.01629v1 [cs.LG])

    [http://arxiv.org/abs/2401.01629](http://arxiv.org/abs/2401.01629)

    这篇论文讨论了人工智能中合成数据的挑战、应用和伦理影响。它介绍了合成数据的生成方法和应用领域，并强调了确保公平性、减少偏见和维护伦理标准在人工智能发展中的重要性。

    

    在快速发展的人工智能领域中，合成数据的创造和利用变得越来越重要。本报告深入探讨了合成数据的多方面问题，特别强调这些数据集可能存在的挑战和潜在偏见。它探讨了合成数据生成的方法，包括传统的统计模型和先进的深度学习技术，并研究了它们在各个领域的应用。本报告还批判性地讨论了与合成数据集相关的伦理考虑和法律影响，强调了确保公平性，减少偏见和维护人工智能发展的伦理标准的机制的紧迫性。

    In the rapidly evolving field of artificial intelligence, the creation and utilization of synthetic datasets have become increasingly significant. This report delves into the multifaceted aspects of synthetic data, particularly emphasizing the challenges and potential biases these datasets may harbor. It explores the methodologies behind synthetic data generation, spanning traditional statistical models to advanced deep learning techniques, and examines their applications across diverse domains. The report also critically addresses the ethical considerations and legal implications associated with synthetic datasets, highlighting the urgent need for mechanisms to ensure fairness, mitigate biases, and uphold ethical standards in AI development.
    
[^23]: 关于图神经网络的表达能力研究

    On the Expressive Power of Graph Neural Networks. (arXiv:2401.01626v1 [cs.LG])

    [http://arxiv.org/abs/2401.01626](http://arxiv.org/abs/2401.01626)

    研究人员对图神经网络的表达能力和设计架构进行了大量工作，以提高其在各领域任务中的性能。主要方法包括研究GNN的通用逼近性质和其在区分不同图之间的能力程度。

    

    过去几年来，图神经网络的研究引起了相当大的兴趣。通过将深度学习扩展到图结构化数据，GNN可以解决社会科学、化学和医学等领域的各种任务。GNN架构的发展主要集中在改进节点或图分类等任务的实证性性能。然而，最近的一系列工作则寻求找到具有理论特性的GNN架构，通过研究其表达能力并设计最大化这种表达能力的架构。虽然关于如何定义GNN的表达能力还没有共识，但可以从几个有很好动机的角度来看待。也许最自然的方法是研究GNN的通用逼近性质，就像MLP的这种性质一样得到了广泛的研究。另一个方向关注的是GNN在区分不同图之间的能力程度。

    The study of Graph Neural Networks has received considerable interest in the past few years. By extending deep learning to graph-structured data, GNNs can solve a diverse set of tasks in fields including social science, chemistry, and medicine. The development of GNN architectures has largely been focused on improving empirical performance on tasks like node or graph classification. However, a line of recent work has instead sought to find GNN architectures that have desirable theoretical properties - by studying their expressive power and designing architectures that maximize this expressiveness.  While there is no consensus on the best way to define the expressiveness of a GNN, it can be viewed from several well-motivated perspectives. Perhaps the most natural approach is to study the universal approximation properties of GNNs, much in the way that this has been studied extensively for MLPs. Another direction focuses on the extent to which GNNs can distinguish between different graph
    
[^24]: AI是否能像人类一样具备创造力？

    Can AI Be as Creative as Humans?. (arXiv:2401.01623v1 [cs.AI])

    [http://arxiv.org/abs/2401.01623](http://arxiv.org/abs/2401.01623)

    本文引入了一个新概念【相对创造力】，通过将焦点转向AI是否能够与人类具备相同的创造能力，实现对创造力的统计量化评估和直接比较。

    

    创造力是社会进步和创新的基石，但其评估仍然是一个复杂且主观的任务。随着先进的生成型AI模型的出现，能够完成曾经只属于人类创造力的任务，探索AI的创造潜力变得至关重要，以确保其负责任的发展和应用。本文通过引入一个名为“相对创造力”的新概念来解决定义和评估创造力的复杂性。我们不再试图对创造力进行普遍定义，而是将焦点转向AI是否能够与一位假设的人类具备相同的创造能力。这种观点借鉴了图灵测试的思想，并扩展其范围以解决评估创造力中所固有的挑战和主观性。这种方法的转变使得对AI创造力的统计量化评估成为可能，我们将其称为统计创造力。这种方法允许直接比较AI与特定人类的创造能力。

    Creativity serves as a cornerstone for societal progress and innovation, but its assessment remains a complex and often subjective endeavor. With the rise of advanced generative AI models capable of tasks once reserved for human creativity, the study of AI's creative potential becomes imperative for its responsible development and application. This paper addresses the complexities in defining and evaluating creativity by introducing a new concept called Relative Creativity. Instead of trying to define creativity universally, we shift the focus to whether AI can match the creative abilities of a hypothetical human. This perspective draws inspiration from the Turing Test, expanding upon it to address the challenges and subjectivities inherent in evaluating creativity. This methodological shift facilitates a statistically quantifiable evaluation of AI's creativity, which we term Statistical Creativity. This approach allows for direct comparisons of AI's creative abilities with those of sp
    
[^25]: 术中风险预测和预后中的大型语言模型能力研究

    Large Language Model Capabilities in Perioperative Risk Prediction and Prognostication. (arXiv:2401.01620v1 [cs.AI])

    [http://arxiv.org/abs/2401.01620](http://arxiv.org/abs/2401.01620)

    在这项研究中，我们探讨了使用通用领域大型语言模型在术中风险预测和预后方面的能力。通过使用手术描述和患者临床记录，我们在8个不同的任务上考察了预测性能，并发现少量样本和链式启发式策略可以提高预测性能。此外，我们的研究表明当前一代大型语言模型可以帮助临床医生在术中风险分层和生成高质量的自然语言总结方面发挥作用。

    

    我们研究了通用领域的大型语言模型，如GPT-4 Turbo，能否使用手术的描述和来自电子健康记录的患者临床记录，进行风险分层和预测术后结果指标。我们对8个不同任务的预测性能进行了考察：ASA生理状态分类的预测、住院、重症监护室入院、非计划入院、住院死亡、PACU第一阶段持续时间、住院时间和重症监护室时间的预测。少量样本和链式启发式策略改善了几个任务的预测性能。我们在ASA生理状态分类预测上达到了0.50的F1得分，在重症监护室入院预测上达到了0.81的F1得分，在住院死亡预测上达到了0.86的F1得分。所有提示策略在持续时间预测任务上的表现普遍较差。当前一代大型语言模型可以帮助临床医生在分类任务中进行术中风险分层，并生成高质量的自然语言总结。

    We investigate whether general-domain large language models such as GPT-4 Turbo can perform risk stratification and predict post-operative outcome measures using a description of the procedure and a patient's clinical notes derived from the electronic health record. We examine predictive performance on 8 different tasks: prediction of ASA Physical Status Classification, hospital admission, ICU admission, unplanned admission, hospital mortality, PACU Phase 1 duration, hospital duration, and ICU duration. Few-shot and chain-of-thought prompting improves predictive performance for several of the tasks. We achieve F1 scores of 0.50 for ASA Physical Status Classification, 0.81 for ICU admission, and 0.86 for hospital mortality. Performance on duration prediction tasks were universally poor across all prompt strategies. Current generation large language models can assist clinicians in perioperative risk stratification on classification tasks and produce high-quality natural language summarie
    
[^26]: GPT-4V(ision)是一个通用的网络代理，如果有基础的话。

    GPT-4V(ision) is a Generalist Web Agent, if Grounded. (arXiv:2401.01614v1 [cs.IR])

    [http://arxiv.org/abs/2401.01614](http://arxiv.org/abs/2401.01614)

    GPT-4V(ision)是一个通用的网络代理，具有综合视觉理解和网页操作的能力。实验证明，如果将文本计划转化为实际行动，GPT-4V可以在50%的任务上取得成功。这一结果显著优于传统方法。

    

    最近对大型多模型（LMM）的研究，特别是GPT-4V(ision)和Gemini，快速推动了多模型的能力边界超越传统任务，如图像字幕和视觉问答。在这项工作中，我们探索了像GPT-4V这样的LMM作为通用网络代理的潜力，可以根据自然语言指令在任何给定的网站上完成任务。我们提出了SEEACT，一种利用LMM的力量进行综合视觉理解和网页操作的通用网络代理。我们在最新的MIND2WEB基准上进行评估。除了对缓存网站的标准离线评估外，我们还通过开发一个允许在实时网站上运行网络代理的工具，实现了一种新的在线评估设置。我们展示了GPT-4V在网页代理方面表现出巨大的潜力-如果我们将其文本计划手动地实施为网站上的行动，它可以成功地完成50%的任务。此结果明显超过了传统方法。

    The recent development on large multimodal models (LMMs), especially GPT-4V(ision) and Gemini, has been quickly expanding the capability boundaries of multimodal models beyond traditional tasks like image captioning and visual question answering. In this work, we explore the potential of LMMs like GPT-4V as a generalist web agent that can follow natural language instructions to complete tasks on any given website. We propose SEEACT, a generalist web agent that harnesses the power of LMMs for integrated visual understanding and acting on the web. We evaluate on the recent MIND2WEB benchmark. In addition to standard offline evaluation on cached websites, we enable a new online evaluation setting by developing a tool that allows running web agents on live websites. We show that GPT-4V presents a great potential for web agents - it can successfully complete 50% of the tasks on live websites if we manually ground its textual plans into actions on the websites. This substantially outperforms
    
[^27]: PLLaMa：一种用于植物科学的开源大型语言模型

    PLLaMa: An Open-source Large Language Model for Plant Science. (arXiv:2401.01600v1 [cs.CL])

    [http://arxiv.org/abs/2401.01600](http://arxiv.org/abs/2401.01600)

    PLLaMa是一种用于植物科学的开源大型语言模型，通过综合数据库增强，显著丰富了其在植物和农业科学方面的知识和专长，并通过与专业人员小组的合作验证了其准确性。

    

    大型语言模型（LLMs）在理解和与自然语言进行交互方面展示了出色的能力。然而，在植物科学等需要高准确性的专业领域中，由于缺乏相关领域的专业知识，它们的效果受到了限制。本文介绍了PLLaMa，一种从LLaMa-2进化而来的开源语言模型。它通过包括超过150万篇植物科学学术文章的综合数据库进行增强。这一发展显著丰富了PLLaMa在植物和农业科学方面的知识和专长。我们的初步测试中，涉及与植物和农业相关的特定数据集，显示PLLaMa显著提高了对植物科学相关主题的理解。此外，我们还组建了一个国际专业人员小组，包括植物科学家、农业工程师和植物育种员。该团队在验证PLLaMa的准确性方面起着关键作用。

    Large Language Models (LLMs) have exhibited remarkable capabilities in understanding and interacting with natural language across various sectors. However, their effectiveness is limited in specialized areas requiring high accuracy, such as plant science, due to a lack of specific expertise in these fields. This paper introduces PLLaMa, an open-source language model that evolved from LLaMa-2. It's enhanced with a comprehensive database, comprising more than 1.5 million scholarly articles in plant science. This development significantly enriches PLLaMa with extensive knowledge and proficiency in plant and agricultural sciences. Our initial tests, involving specific datasets related to plants and agriculture, show that PLLaMa substantially improves its understanding of plant science-related topics. Moreover, we have formed an international panel of professionals, including plant scientists, agricultural engineers, and plant breeders. This team plays a crucial role in verifying the accura
    
[^28]: MedSumm：一种多模态方法用于总结混合码Hindi-English临床查询

    MedSumm: A Multimodal Approach to Summarizing Code-Mixed Hindi-English Clinical Queries. (arXiv:2401.01596v1 [cs.AI])

    [http://arxiv.org/abs/2401.01596](http://arxiv.org/abs/2401.01596)

    本研究提出了一种多模态方法，用于总结混合码Hindi-English临床查询，通过整合文本和视觉线索，提供更全面的患者医疗状况的表示。为了解决这个问题，研究还提出了一个名为MedSumm的框架，利用LLMs和VLMs来完成任务。

    

    在医疗领域中，总结患者提出的医疗问题对于改善医患互动和医疗决策至关重要。虽然医疗数据的复杂性和数量不断增长，但目前在这个领域的研究主要集中在基于文本的方法上，忽视了视觉线索的整合。此外，在医学问题总结的领域中，之前的研究仅限于英语语言。本研究引入了在低资源环境下针对混合码输入进行多模态医学问题总结的任务。为了解决这个问题，我们引入了Multimodal Medical Codemixed Question Summarization（MMCQS）数据集，该数据集结合了Hindi-English混合码医学查询和视觉辅助工具。这种整合丰富了患者的医疗状况的表示，提供了更全面的视角。我们还提出了一个名为MedSumm的框架，利用LLMs和VLMs的能力来完成这个任务。

    In the healthcare domain, summarizing medical questions posed by patients is critical for improving doctor-patient interactions and medical decision-making. Although medical data has grown in complexity and quantity, the current body of research in this domain has primarily concentrated on text-based methods, overlooking the integration of visual cues. Also prior works in the area of medical question summarisation have been limited to the English language. This work introduces the task of multimodal medical question summarization for codemixed input in a low-resource setting. To address this gap, we introduce the Multimodal Medical Codemixed Question Summarization MMCQS dataset, which combines Hindi-English codemixed medical queries with visual aids. This integration enriches the representation of a patient's medical condition, providing a more comprehensive perspective. We also propose a framework named MedSumm that leverages the power of LLMs and VLMs for this task. By utilizing our 
    
[^29]: 对开放WiFi数据进行对抗机器学习启发的匿名化处理

    Adversarial Machine Learning-Enabled Anonymization of OpenWiFi Data. (arXiv:2401.01542v1 [cs.NI])

    [http://arxiv.org/abs/2401.01542](http://arxiv.org/abs/2401.01542)

    这篇论文提出了一种对开放WiFi数据进行对抗机器学习启发的匿名化处理的方法，通过应用条件表格生成对抗网络（CTGAN）生成伪装成真实数据的合成数据，并使用聚类算法对合成数据与实际数据的相似性进行评估和性能比较。

    

    在将数据转发给其他可能使用数据的机构之前，网络运营商或数据所有者通过匿名化保护数据隐私是一个关键问题。随着人工智能的采用，数据匿名化增加了掩盖必要敏感信息的可能性，防止数据泄漏和信息丢失。OpenWiFi网络容易受到试图获取或了解流量的任何敌对方的攻击，而不考虑数据所有者所拥有的知识。应用条件表格生成对抗网络（CTGAN）来解决发现实际流量信息的几率问题。CTGAN产生合成数据，伪装成真实数据，但透露了真实数据的隐藏信息。本文展示了使用聚类算法对合成数据与实际数据的相似性评估，然后比较了针对无监督聚类验证指标的性能。一个广为人知的算法，K-Means表现优秀。

    Data privacy and protection through anonymization is a critical issue for network operators or data owners before it is forwarded for other possible use of data. With the adoption of Artificial Intelligence (AI), data anonymization augments the likelihood of covering up necessary sensitive information; preventing data leakage and information loss. OpenWiFi networks are vulnerable to any adversary who is trying to gain access or knowledge on traffic regardless of the knowledge possessed by data owners. The odds for discovery of actual traffic information is addressed by applied conditional tabular generative adversarial network (CTGAN). CTGAN yields synthetic data; which disguises as actual data but fostering hidden acute information of actual data. In this paper, the similarity assessment of synthetic with actual data is showcased in terms of clustering algorithms followed by a comparison of performance for unsupervised cluster validation metrics. A well-known algorithm, K-means outper
    
[^30]: 欺骗的艺术：使用动态触发器的强健后门攻击

    The Art of Deception: Robust Backdoor Attack using Dynamic Stacking of Triggers. (arXiv:2401.01537v1 [cs.CR])

    [http://arxiv.org/abs/2401.01537](http://arxiv.org/abs/2401.01537)

    这项研究介绍了一种使用动态触发器进行强健后门攻击的方法，通过巧妙设计的调整，使损坏的样本与干净的样本无法区分，实验证明这种方法可以成功地欺骗语音识别系统。

    

    由于人工智能行业的最新进展，机器学习作为服务（MLaaS）领域正在经历增长的实施。然而，这种增长引发了对AI防御机制的担忧，特别是对于来自不完全可信的第三方提供商的潜在隐蔽攻击。最近的研究发现，听觉后门可能使用某些修改作为其启动机制。DynamicTrigger作为一种方法被引入，用于进行使用巧妙设计的调整来确保损坏的样本与干净的样本无法区分的动态后门攻击。通过利用波动的信号采样率，并通过动态声音触发器（比如拍手声）对说话者身份进行掩盖，可以欺骗语音识别系统（ASR）。我们的实证测试表明，DynamicTrigger在隐蔽攻击中既有效又隐蔽，并在攻击过程中取得了令人印象深刻的成功率。

    The area of Machine Learning as a Service (MLaaS) is experiencing increased implementation due to recent advancements in the AI (Artificial Intelligence) industry. However, this spike has prompted concerns regarding AI defense mechanisms, specifically regarding potential covert attacks from third-party providers that cannot be entirely trusted. Recent research has uncovered that auditory backdoors may use certain modifications as their initiating mechanism. DynamicTrigger is introduced as a methodology for carrying out dynamic backdoor attacks that use cleverly designed tweaks to ensure that corrupted samples are indistinguishable from clean. By utilizing fluctuating signal sampling rates and masking speaker identities through dynamic sound triggers (such as the clapping of hands), it is possible to deceive speech recognition systems (ASR). Our empirical testing demonstrates that DynamicTrigger is both potent and stealthy, achieving impressive success rates during covert attacks while 
    
[^31]: GOAT-Bench: 通过基于迷因的社交虐待研究对大型多模态模型的安全洞察

    GOAT-Bench: Safety Insights to Large Multimodal Models through Meme-Based Social Abuse. (arXiv:2401.01523v1 [cs.CL])

    [http://arxiv.org/abs/2401.01523](http://arxiv.org/abs/2401.01523)

    通过基于迷因的社交虐待研究对大型多模态模型的安全洞察，我们引入了综合的迷因基准测试集GOAT-Bench，评估各种LMMs在识别和回应迷因中体现的微妙社交虐待方面的能力。

    

    社交媒体的指数级增长深刻改变了信息的创造、传播和吸收方式，在数字时代产生了前所未有的影响。遗憾的是，这个爆炸也导致了网络迷因的滥用数量显著增加。评估迷因的负面影响是相当具有挑战性的，因为它们通常具有微妙和隐晦的含义，这些含义不能直接通过显性的文本和图像传达出来。鉴于此，大型多模态模型(LMMs)作为处理多样化多模态任务的卓越能力的焦点引起了人们的兴趣。针对这一发展，我们的论文旨在深入研究各种LMMs(如GPT-4V)识别和回应迷因中体现的微妙社交虐待方面的能力。我们引入了综合的迷因基准测试集GOAT-Bench，其中包含超过6K个多样的迷因，涵盖的主题包括隐性仇恨言论、性别歧视和网络欺凌等。利用GOAT-Be

    The exponential growth of social media has profoundly transformed how information is created, disseminated, and absorbed, exceeding any precedent in the digital age. Regrettably, this explosion has also spawned a significant increase in the online abuse of memes. Evaluating the negative impact of memes is notably challenging, owing to their often subtle and implicit meanings, which are not directly conveyed through the overt text and imagery. In light of this, large multimodal models (LMMs) have emerged as a focal point of interest due to their remarkable capabilities in handling diverse multimodal tasks. In response to this development, our paper aims to thoroughly examine the capacity of various LMMs (e.g. GPT-4V) to discern and respond to the nuanced aspects of social abuse manifested in memes. We introduce the comprehensive meme benchmark, GOAT-Bench, comprising over 6K varied memes encapsulating themes such as implicit hate speech, sexism, and cyberbullying, etc. Utilizing GOAT-Be
    
[^32]: 探索LLMs在心理学应用中的前沿：一份综述

    Exploring the Frontiers of LLMs in Psychological Applications: A Comprehensive Review. (arXiv:2401.01519v1 [cs.LG])

    [http://arxiv.org/abs/2401.01519](http://arxiv.org/abs/2401.01519)

    本文综述了大型语言模型（LLMs）在心理学应用中的前沿，包括如何模拟人类认知和行为、提供创新工具进行文献回顾、假设生成、实验设计等。

    

    本文探索了大型语言模型（LLMs）在心理学应用中的前沿。心理学经历了几次理论变革，当前人工智能（AI）和机器学习，特别是LLMs的使用有望开启新的研究方向。我们详细探讨了LLMs如ChatGPT在心理学研究中的转变。文章讨论了LLMs在认知与行为心理学、临床与咨询心理学、教育与发展心理学以及社会与文化心理学等心理学分支中的影响，强调了它们模拟人类认知和行为方面的潜力。本文深入探讨了这些模型模拟人类文本生成的能力，为心理学中的文献回顾、假设生成、实验设计、实验对象、数据分析、学术写作和同行评审等提供创新工具。虽然LLMs在推动研究方法学方面起着重要作用，

    This paper explores the frontiers of large language models (LLMs) in psychology applications. Psychology has undergone several theoretical changes, and the current use of Artificial Intelligence (AI) and Machine Learning, particularly LLMs, promises to open up new research directions. We provide a detailed exploration of how LLMs like ChatGPT are transforming psychological research. It discusses the impact of LLMs across various branches of psychology, including cognitive and behavioral, clinical and counseling, educational and developmental, and social and cultural psychology, highlighting their potential to simulate aspects of human cognition and behavior. The paper delves into the capabilities of these models to emulate human-like text generation, offering innovative tools for literature review, hypothesis generation, experimental design, experimental subjects, data analysis, academic writing, and peer review in psychology. While LLMs are essential in advancing research methodologie
    
[^33]: 从像素到切片图像: 使用表示学习进行基于极化模态的病理诊断

    From Pixel to Slide image: Polarization Modality-based Pathological Diagnosis Using Representation Learning. (arXiv:2401.01496v1 [eess.IV])

    [http://arxiv.org/abs/2401.01496](http://arxiv.org/abs/2401.01496)

    本研究提出了一种使用表示学习的三阶段模型，结合像素级和切片级注释，能够准确区分甲状腺肿瘤，解决了病理诊断中的挑战。

    

    甲状腺癌是最常见的内分泌恶性肿瘤，准确区分良性和恶性甲状腺肿瘤对于制定有效的治疗方案至关重要。病理学上，由于样本采集不当，甲状腺肿瘤存在诊断挑战。本研究设计了一个使用表示学习来集成像素级和切片级注释的三阶段模型，用于区分甲状腺肿瘤。该结构包括一个病理结构识别方法，用于预测与甲状腺肿瘤相关的结构，一个编码器-解码器网络，通过学习图像块的特征表示来提取像素级注释信息，以及一个基于注意力机制的学习机制，用于最终的分类任务。该机制全局考虑了病理区域中不同图像块的信息，学习了每个块的重要性。在第三阶段，通过切片区域中的图像块的所有信息进行分类。

    Thyroid cancer is the most common endocrine malignancy, and accurately distinguishing between benign and malignant thyroid tumors is crucial for developing effective treatment plans in clinical practice. Pathologically, thyroid tumors pose diagnostic challenges due to improper specimen sampling. In this study, we have designed a three-stage model using representation learning to integrate pixel-level and slice-level annotations for distinguishing thyroid tumors. This structure includes a pathology structure recognition method to predict structures related to thyroid tumors, an encoder-decoder network to extract pixel-level annotation information by learning the feature representations of image blocks, and an attention-based learning mechanism for the final classification task. This mechanism learns the importance of different image blocks in a pathological region, globally considering the information from each block. In the third stage, all information from the image blocks in a region
    
[^34]: 自由午餐为联邦遥感目标细粒度分类提供了一个参数高效的框架

    Free Lunch for Federated Remote Sensing Target Fine-Grained Classification: A Parameter-Efficient Framework. (arXiv:2401.01493v1 [cs.LG])

    [http://arxiv.org/abs/2401.01493](http://arxiv.org/abs/2401.01493)

    这项研究提出了一个名为PRFL的隐私保护TFGC框架，基于联邦学习，旨在解决遥感目标细粒度分类中的数据隐私和通信效率问题。

    

    遥感目标的细粒度分类对军事和民用领域都具有重要意义。由于位置差异、数据规模增长和集中式服务器存储限制，这些数据通常存储在不同地区/国家的不同数据库中。然而，隐私法律和国家安全问题限制研究人员进一步分析这些敏感的遥感图像。此外，低资源的遥感设备在处理不断增长的数据和模型规模时，也面临通信开销和效率方面的挑战。为了解决上述挑战，本文提出了一种基于联邦学习的新型隐私保护TFGC框架，称为PRFL。所提出的框架允许每个客户端在统计异构（非独立同分布，IID）的环境中学习全局和局部知识，以增强私有数据的本地表示。

    Remote Sensing Target Fine-grained Classification (TFGC) is of great significance in both military and civilian fields. Due to location differences, growth in data size, and centralized server storage constraints, these data are usually stored under different databases across regions/countries. However, privacy laws and national security concerns constrain researchers from accessing these sensitive remote sensing images for further analysis. Additionally, low-resource remote sensing devices encounter challenges in terms of communication overhead and efficiency when dealing with the ever-increasing data and model scales. To solve the above challenges, this paper proposes a novel Privacy-Reserving TFGC Framework based on Federated Learning, dubbed PRFL. The proposed framework allows each client to learn global and local knowledge to enhance the local representation of private data in environments with extreme statistical heterogeneity (non. Independent and Identically Distributed, IID). 
    
[^35]: 不确定性规范化的证据回归

    Uncertainty Regularized Evidential Regression. (arXiv:2401.01484v1 [cs.LG])

    [http://arxiv.org/abs/2401.01484](http://arxiv.org/abs/2401.01484)

    本文研究了证据回归网络（ERN）中的模型性能限制问题，并提出了一种基于正则化的改进方法，使ERN能够从整个训练集中学习。

    

    证据回归网络（ERN）是一种将深度学习与Dempster-Shafer理论相结合的新方法，用于预测目标并量化相关的不确定性。在底层理论的指导下，必须使用特定的激活函数来强制非负值，这种约束限制了模型从所有样本中学习的能力，从而危害了模型的性能。本文对这种限制进行了理论分析，并引入了一种改进方法来克服它。首先，我们定义了模型无法有效学习样本的区域。然后，我们对ERN进行了深入分析，研究了这个约束。基于我们分析的见解，通过引入一种新的正则化项，我们解决了这个限制，使ERN能够从整个训练集中学习。我们的广泛实验证实了我们的理论发现，并证明了所提出的解决方案的有效性。

    The Evidential Regression Network (ERN) represents a novel approach that integrates deep learning with Dempster-Shafer's theory to predict a target and quantify the associated uncertainty. Guided by the underlying theory, specific activation functions must be employed to enforce non-negative values, which is a constraint that compromises model performance by limiting its ability to learn from all samples. This paper provides a theoretical analysis of this limitation and introduces an improvement to overcome it. Initially, we define the region where the models can't effectively learn from the samples. Following this, we thoroughly analyze the ERN and investigate this constraint. Leveraging the insights from our analysis, we address the limitation by introducing a novel regularization term that empowers the ERN to learn from the whole training set. Our extensive experiments substantiate our theoretical findings and demonstrate the effectiveness of the proposed solution.
    
[^36]: 在目标识别中将地理多样知识融入提示以提高地理鲁棒性

    Incorporating Geo-Diverse Knowledge into Prompting for Increased Geographical Robustness in Object Recognition. (arXiv:2401.01482v1 [cs.CV])

    [http://arxiv.org/abs/2401.01482](http://arxiv.org/abs/2401.01482)

    本文研究了在目标识别中将地理多样知识融入提示以提高地理鲁棒性的方法，探索了通过大型语言模型获取地理特定对象知识并结合CLIP视觉语言模型的零样本和可学习软提示。通过提出一种地理知识正则化方法，实现了从源地理位置推广到未见目标地理位置的鲁棒性提升。

    

    现有的目标识别模型在不同地理情景下缺乏鲁棒性，这是由于设计和环境中存在重要的领域转移。为了更准确地反映这些转移下的对象概念，需要调整类别表示。在缺乏目标地理位置训练数据的情况下，我们假设可以利用地理特定的对象类别描述性知识来增强鲁棒性。为此，我们探索了通过探测大型语言模型的地理特定对象知识的可行性，并研究了在CLIP视觉语言模型中集成知识的零样本和可学习软提示。特别地，我们提出了一种地理知识正则化方法，以确保在一组源地理位置上训练的软提示能够推广到未见过的目标地理位置集合。当仅依赖来自欧洲的数据进行训练时，我们在DollarStreet上的增益达到了+2.8个国家。

    Existing object recognition models have been shown to lack robustness in diverse geographical scenarios due to significant domain shifts in design and context. Class representations need to be adapted to more accurately reflect an object concept under these shifts. In the absence of training data from target geographies, we hypothesize that geography-specific descriptive knowledge of object categories can be leveraged to enhance robustness. For this purpose, we explore the feasibility of probing a large-language model for geography-specific object knowledge, and we investigate integrating knowledge in zero-shot and learnable soft prompting with the CLIP vision-language model. In particular, we propose a geography knowledge regularization method to ensure that soft prompts trained on a source set of geographies generalize to an unseen target set of geographies. Our gains on DollarStreet when generalizing from a model trained only on data from Europe are as large as +2.8 on countries fro
    
[^37]: 高效视觉Transformer的令牌传播控制器

    Token Propagation Controller for Efficient Vision Transformer. (arXiv:2401.01470v1 [cs.CV])

    [http://arxiv.org/abs/2401.01470](http://arxiv.org/abs/2401.01470)

    本文提出一种新颖的令牌传播控制器（TPC），通过结合暂停概率和重新开始概率，实现了对令牌的减少和重复利用的控制，从而提高了视觉Transformer的效率和令牌利用率。

    

    视觉Transformer（ViTs）在各种计算机视觉任务上取得了有希望的结果，然而它们在输入令牌数量上的二次复杂度限制了它们在资源受限环境下的应用。以前的方法采用逐渐减少令牌来解决这个挑战，假设一个层中的令牌冗余意味着所有后续层中也有冗余。我们经验证明这个假设通常是不正确的，即一个层中多余的令牌在后面的层中可以是有用的。基于这个关键洞察力，我们提出了一种新颖的令牌传播控制器（TPC），它结合了两种不同的令牌分布，即暂停概率和重新开始概率，用来控制令牌的减少和重复利用，从而实现更高效的令牌利用。为了改善令牌分布的估计，我们提出了一种平滑机制，作为正则化器，有助于去除噪声异常值。此外

    Vision transformers (ViTs) have achieved promising results on a variety of Computer Vision tasks, however their quadratic complexity in the number of input tokens has limited their application specially in resource-constrained settings. Previous approaches that employ gradual token reduction to address this challenge assume that token redundancy in one layer implies redundancy in all the following layers. We empirically demonstrate that this assumption is often not correct, i.e., tokens that are redundant in one layer can be useful in later layers. We employ this key insight to propose a novel token propagation controller (TPC) that incorporates two different token-distributions, i.e., pause probability and restart probability to control the reduction and reuse of tokens respectively, which results in more efficient token utilization. To improve the estimates of token distributions, we propose a smoothing mechanism that acts as a regularizer and helps remove noisy outliers. Furthermore
    
[^38]: 基于检索增强生成的问答式电子健康记录摘要

    Question-Answering Based Summarization of Electronic Health Records using Retrieval Augmented Generation. (arXiv:2401.01469v1 [cs.CL])

    [http://arxiv.org/abs/2401.01469](http://arxiv.org/abs/2401.01469)

    提出了一种基于检索增强生成的问答式电子健康记录摘要方法，通过结合语义搜索、RAG和最新的LLMs，摘要是提取被专业人士认为重要的特定问题的答案。

    

    电子健康记录（EHRs）的摘要可以大大减少患者和医务人员的“屏幕时间”。近年来，EHRs的摘要已经使用最先进的神经模型进行机器学习流程。然而，由于难以获得足够的注释数据进行训练，这些模型产生的结果不够满意。此外，由于现代大型语言模型（LLMs）中的注意机制在输入大小方面增加了二次复杂性，因此需要考虑整个EHR内容的摘要效果较差。我们提出了一种通过结合语义搜索、检索增强生成（RAG）和最新的LLMs来缓解这些缺点的方法。在我们的方法中，摘要是提取被专业人士认为重要的特定问题的答案。

    Summarization of electronic health records (EHRs) can substantially minimize 'screen time' for both patients as well as medical personnel. In recent years summarization of EHRs have employed machine learning pipelines using state of the art neural models. However, these models have produced less than adequate results that are attributed to the difficulty of obtaining sufficient annotated data for training. Moreover, the requirement to consider the entire content of an EHR in summarization has resulted in poor performance due to the fact that attention mechanisms in modern large language models (LLMs) adds a quadratic complexity in terms of the size of the input. We propose here a method that mitigates these shortcomings by combining semantic search, retrieval augmented generation (RAG) and question-answering using the latest LLMs. In our approach summarization is the extraction of answers to specific questions that are deemed important by subject-matter experts (SMEs). Our approach is 
    
[^39]: 大规模公共卫生数据流中的异常值排名

    Outlier Ranking in Large-Scale Public Health Streams. (arXiv:2401.01459v1 [cs.AI])

    [http://arxiv.org/abs/2401.01459](http://arxiv.org/abs/2401.01459)

    本论文提出了一种在大规模公共卫生数据流中排名异常值的任务，并通过结合层级网络和极值分析的新算法，在人工专家评估中表现最好。最重要的是，专家们使用了我们的实现后，发现值得调查的异常值的速度提高了9.1倍。

    

    疾病控制专家每天会检查公共卫生数据流中的异常值，如与数据质量问题或疾病爆发相关的异常值。然而，他们只能检查到由应用于大规模公共卫生数据流的单变量异常值检测方法返回的少数几个最大绑定异常值。为了帮助专家从这些成千上万个绑定的异常值中区分出最重要的异常值，我们提出了一种新的任务，即对应用于许多数据流的任何单变量方法的输出进行排名。我们为这个任务提出的新颖算法，在使用公共卫生数据流进行人工专家评估时，在传统的异常值检测指标中表现最好。最重要的是，自2023年4月以来，专家们已经使用我们的开源Python实现，并报告比之前的基线快了9.1倍地发现值得调查的异常值。其他组织可以轻松地阅读和使用我们的实现来提高异常值的发现速度。

    Disease control experts inspect public health data streams daily for outliers worth investigating, like those corresponding to data quality issues or disease outbreaks. However, they can only examine a few of the thousands of maximally-tied outliers returned by univariate outlier detection methods applied to large-scale public health data streams. To help experts distinguish the most important outliers from these thousands of tied outliers, we propose a new task for algorithms to rank the outputs of any univariate method applied to each of many streams. Our novel algorithm for this task, which leverages hierarchical networks and extreme value analysis, performed the best across traditional outlier detection metrics in a human-expert evaluation using public health data streams. Most importantly, experts have used our open-source Python implementation since April 2023 and report identifying outliers worth investigating 9.1x faster than their prior baseline. Other organizations can readil
    
[^40]: 使用不确定性指纹实现神经网络的并发自测

    Concurrent Self-testing of Neural Networks Using Uncertainty Fingerprint. (arXiv:2401.01458v1 [cs.LG])

    [http://arxiv.org/abs/2401.01458](http://arxiv.org/abs/2401.01458)

    本文提出了使用不确定性指纹进行神经网络的并发自测的方法，可以在在线操作中检测并纠正单个和多个永久和软错误，适用于始终开启的安全关键应用。

    

    神经网络（NN）越来越广泛地应用于硬件加速器（NN-HA）上的始终开启的安全关键应用中，这些应用采用各种存储技术。对于安全关键应用来说，可靠的持续操作是至关重要的。在在线操作中，NN因辐射、老化和热效应等因素而容易出现单个和多个永久和软错误。显式的NN-HA测试方法不能检测到推断过程中的瞬态故障，对于始终开启的应用来说也不适用，并且需要大量的测试向量生成和存储。因此，在本文中，我们提出了一种表示NN在线故障状态的“不确定性指纹”方法。此外，我们还提出了一种特定的双头NN拓扑结构，专门设计用于生成不确定性指纹和NN的主要预测。在在线操作过程中，通过匹配不确定性指纹，我们可以同时自测NN，可达到100

    Neural networks (NNs) are increasingly used in always-on safety-critical applications deployed on hardware accelerators (NN-HAs) employing various memory technologies. Reliable continuous operation of NN is essential for safety-critical applications. During online operation, NNs are susceptible to single and multiple permanent and soft errors due to factors such as radiation, aging, and thermal effects. Explicit NN-HA testing methods cannot detect transient faults during inference, are unsuitable for always-on applications, and require extensive test vector generation and storage. Therefore, in this paper, we propose the \emph{uncertainty fingerprint} approach representing the online fault status of NN. Furthermore, we propose a dual head NN topology specifically designed to produce uncertainty fingerprints and the primary prediction of the NN in \emph{a single shot}. During the online operation, by matching the uncertainty fingerprint, we can concurrently self-test NNs with up to $100
    
[^41]: 具有干扰和数据异质性意识的分层无线联邦学习

    Hierarchical Over-the-Air Federated Learning with Awareness of Interference and Data Heterogeneity. (arXiv:2401.01442v1 [cs.IT])

    [http://arxiv.org/abs/2401.01442](http://arxiv.org/abs/2401.01442)

    本文介绍了一种具有干扰和数据异质性意识的分层无线联邦学习方法，通过优化接收机的归一化因子来最小化干扰影响，并利用梯度聚合对抗数据异质性，实现了较高的学习准确性，并且可以优于传统的分层算法。

    

    在无线网络上实施分层联邦学习时，可扩展性保证和处理干扰和设备数据异质性的能力至关重要。本文介绍了一种旨在应对这些挑战的学习方法，以及通过空中计算高效利用单一无线资源的可扩展传输方案。为了提供对抗数据异质性的能力，我们采用了梯度聚合。同时，通过优化接收机归一化因子，最小化了干扰的影响。为此，我们使用随机几何模型对多簇无线网络进行建模，并将聚合估计的均方误差表征为网络参数的函数。我们表明，尽管存在干扰和数据异质性，所提出的方案实现了较高的学习准确性，并且可以明显优于传统的分层算法。

    When implementing hierarchical federated learning over wireless networks, scalability assurance and the ability to handle both interference and device data heterogeneity are crucial. This work introduces a learning method designed to address these challenges, along with a scalable transmission scheme that efficiently uses a single wireless resource through over-the-air computation. To provide resistance against data heterogeneity, we employ gradient aggregations. Meanwhile, the impact of interference is minimized through optimized receiver normalizing factors. For this, we model a multi-cluster wireless network using stochastic geometry, and characterize the mean squared error of the aggregation estimations as a function of the network parameters. We show that despite the interference and the data heterogeneity, the proposed scheme achieves high learning accuracy and can significantly outperform the conventional hierarchical algorithm.
    
[^42]: 高维因果推断的模块化深度生成模型学习

    Modular Learning of Deep Causal Generative Models for High-dimensional Causal Inference. (arXiv:2401.01426v1 [cs.LG])

    [http://arxiv.org/abs/2401.01426](http://arxiv.org/abs/2401.01426)

    本文提出了一种用于高维因果推断的模块化深度生成模型学习算法，该算法利用预训练的模型来回答由高维数据引起的因果查询。

    

    Pearl的因果层次结构在观测、干预和反事实问题之间建立了明确的分离。研究人员提出了计算可辨识因果查询的声音和完整算法，在给定层次的因果结构和数据的情况下使用较低层次的层次的数据。然而，大多数这些算法假设我们可以准确估计数据的概率分布，这对于如图像这样的高维变量是一个不切实际的假设。另一方面，现代生成式深度学习架构可以被训练来学习如何准确地从这样的高维分布中采样。特别是随着图像基模型的最近兴起，利用预训练模型来回答带有这样高维数据的因果查询是非常有吸引力的。为了解决这个问题，我们提出了一个顺序训练算法，给定因果结构和预训练的条件生成模型，可以训练一个模型来估计由高维数据引起的因果关系。

    Pearl's causal hierarchy establishes a clear separation between observational, interventional, and counterfactual questions. Researchers proposed sound and complete algorithms to compute identifiable causal queries at a given level of the hierarchy using the causal structure and data from the lower levels of the hierarchy. However, most of these algorithms assume that we can accurately estimate the probability distribution of the data, which is an impractical assumption for high-dimensional variables such as images. On the other hand, modern generative deep learning architectures can be trained to learn how to accurately sample from such high-dimensional distributions. Especially with the recent rise of foundation models for images, it is desirable to leverage pre-trained models to answer causal queries with such high-dimensional data. To address this, we propose a sequential training algorithm that, given the causal structure and a pre-trained conditional generative model, can train a
    
[^43]: SwapTransformer：通过在OSHA数据集上的模仿学习，实现高速公路超车策略规划模型

    SwapTransformer: highway overtaking tactical planner model via imitation learning on OSHA dataset. (arXiv:2401.01425v1 [cs.AI])

    [http://arxiv.org/abs/2401.01425](http://arxiv.org/abs/2401.01425)

    本文旨在通过在OSHA数据集上的模仿学习，设计高速公路上的自动超车和换道策略规划模型SwapTransformer。通过引入辅助任务和比较基准模型，证明了该模型在仿真环境中的性能优势。

    

    本文研究了高速公路场景中的高级决策问题，例如换道和超车。具体而言，本文旨在改进用于高速公路上的自动超车和换道的出行辅助功能。在仿真环境中收集了约900万个样本，包括车道图像和其他动态物体。这个数据集被称为OSHA（模拟高速公路上的超车）数据集，用于解决这个挑战。为了解决这个问题，设计并实现了一个名为SwapTransformer的架构，作为在OSHA数据集上的模仿学习方法。此外，还提出了辅助任务，如未来点和车辆距离网络预测，以帮助模型更好地理解周围环境。在仿真环境中，将所提出的解决方案与多层感知机（MLP）和多头自注意力网络作为基准进行了性能比较。同时也展示了模型的性能。

    This paper investigates the high-level decision-making problem in highway scenarios regarding lane changing and over-taking other slower vehicles. In particular, this paper aims to improve the Travel Assist feature for automatic overtaking and lane changes on highways. About 9 million samples including lane images and other dynamic objects are collected in simulation. This data; Overtaking on Simulated HighwAys (OSHA) dataset is released to tackle this challenge. To solve this problem, an architecture called SwapTransformer is designed and implemented as an imitation learning approach on the OSHA dataset. Moreover, auxiliary tasks such as future points and car distance network predictions are proposed to aid the model in better understanding the surrounding environment. The performance of the proposed solution is compared with a multi-layer perceptron (MLP) and multi-head self-attention networks as baselines in a simulation environment. We also demonstrate the performance of the model 
    
[^44]: 量化唐纳德·特朗普在总统演讲中的独特性

    Quantifying the Uniqueness of Donald Trump in Presidential Discourse. (arXiv:2401.01405v1 [cs.CL])

    [http://arxiv.org/abs/2401.01405](http://arxiv.org/abs/2401.01405)

    这项研究使用了一种新的度量标准来量化唐纳德·特朗普在总统演讲中的独特性，并发现了他在使用具有分裂性和对抗性的语言、重复强调等方面与其他总统候选人存在显著差异。此外，特朗普比共和党同僚更具独特性。

    

    唐纳德·特朗普与其他总统在演讲中是否表达出不同的风格？如果是，有哪些方面的不同？这些差异是否局限于任何单一的沟通媒介？为了调查这些问题，本文引入了一种基于大型语言模型的独特性度量标准，开发了一个新的分裂性演讲词库，并提出了比较政治对手词汇特征的框架。将这些工具应用于多种总统演讲语料库，我们发现有相当多的证据表明特朗普的讲话模式与近代历任主要总统候选人不同。一些显著的发现包括特朗普使用特别具有分裂性和对抗性的语言针对他的政治对手，并且他重复强调的模式。此外，特朗普比他的共和党同僚更加独特，而他们的独特性值与民主党相对较接近。这些差异在多种度量方法下保持一致。

    Does Donald Trump speak differently from other presidents? If so, in what ways? Are these differences confined to any single medium of communication? To investigate these questions, this paper introduces a novel metric of uniqueness based on large language models, develops a new lexicon for divisive speech, and presents a framework for comparing the lexical features of political opponents. Applying these tools to a variety of corpora of presidential speeches, we find considerable evidence that Trump's speech patterns diverge from those of all major party nominees for the presidency in recent history. Some notable findings include Trump's employment of particularly divisive and antagonistic language targeting of his political opponents and his patterns of repetition for emphasis. Furthermore, Trump is significantly more distinctive than his fellow Republicans, whose uniqueness values are comparably closer to those of the Democrats. These differences hold across a variety of measurement 
    
[^45]: 适用于长距离穿墙人体活动识别的定向天线系统

    Directional Antenna Systems for Long-Range Through-Wall Human Activity Recognition. (arXiv:2401.01388v1 [cs.CV])

    [http://arxiv.org/abs/2401.01388](http://arxiv.org/abs/2401.01388)

    本论文研究了适用于长距离穿墙人体活动识别的定向天线系统，提出了ESP32-S3与定向双极天线和ESP32-S3与印刷倒F天线结合的两个有前景的系统。这些系统在WiFi-based HAR中展现出出色的性能。

    

    基于WiFi信道状态信息（CSI）的人体活动识别（HAR）使得在空间受限的环境中保持视觉隐私的情况下实现了非接触式、长距离感知。然而，尽管周围存在许多支持WiFi的设备，但很少有设备向用户公开CSI，导致感知硬件选择有限。Espressif ESP32的变体已经成为潜在的低成本、易于部署的WiFi CSI-based HAR解决方案。在这项工作中，对基于四个ESP32-S3的2.4GHz定向天线系统进行了评估，以评估其支持长距离穿墙HAR的能力。提出了两个有前景的系统，其中一个将ESP32-S3与定向双极天线相结合。据我们所知，这种组合是WiFi基础HAR中的首次演示。第二个系统依靠ESP32-S3的内置印刷倒F天线（PIFA）并通过平面反射器实现方向性。在全面评估中，这两个系统显示出很好的性能。

    WiFi Channel State Information (CSI)-based human activity recognition (HAR) enables contactless, long-range sensing in spatially constrained environments while preserving visual privacy. However, despite the presence of numerous WiFi-enabled devices around us, few expose CSI to users, resulting in a lack of sensing hardware options. Variants of the Espressif ESP32 have emerged as potential low-cost and easy-to-deploy solutions for WiFi CSI-based HAR. In this work, four ESP32-S3-based 2.4GHz directional antenna systems are evaluated for their ability to facilitate long-range through-wall HAR. Two promising systems are proposed, one of which combines the ESP32-S3 with a directional biquad antenna. This combination represents, to the best of our knowledge, the first demonstration of such a system in WiFi-based HAR. The second system relies on the built-in printed inverted-F antenna (PIFA) of the ESP32-S3 and achieves directionality through a plane reflector. In a comprehensive evaluation 
    
[^46]: 强传递关系与图神经网络

    Strong Transitivity Relations and Graph Neural Networks. (arXiv:2401.01384v1 [cs.SI])

    [http://arxiv.org/abs/2401.01384](http://arxiv.org/abs/2401.01384)

    这项研究提出了一种基于传递关系的相似性扩展，通过引入传递图神经网络（TransGNN）从全局和局部的角度捕捉整个图的相似性，显著提高了几个GNN模型的性能。

    

    在基于图的学习中，局部邻域在嵌入生成中起着关键作用。人们普遍认为节点应该具有类似于其邻居的嵌入。在这项研究中，我们试图将相似性的概念从附近邻域扩展到整个图。我们提供了一种基于传递关系的相似性扩展，使得图神经网络（GNNs）能够捕捉整个图的全局相似性和局部相似性。我们引入了传递图神经网络（TransGNN），它不仅考虑了局部节点相似性，还通过区分强传递关系和弱传递关系并利用它们来考虑全局相似性。我们在几个真实世界数据集上评估了我们的模型，并显示出它显著改善了几个知名GNN模型的性能，例如节点分类。

    Local neighborhoods play a crucial role in embedding generation in graph-based learning. It is commonly believed that nodes ought to have embeddings that resemble those of their neighbors. In this research, we try to carefully expand the concept of similarity from nearby neighborhoods to the entire graph. We provide an extension of similarity that is based on transitivity relations, which enables Graph Neural Networks (GNNs) to capture both global similarities and local similarities over the whole graph. We introduce Transitivity Graph Neural Network (TransGNN), which more than local node similarities, takes into account global similarities by distinguishing strong transitivity relations from weak ones and exploiting them. We evaluate our model over several real-world datasets and showed that it considerably improves the performance of several well-known GNN models, for tasks such as node classification.
    
[^47]: 使用稀缺数据和联邦多轨迹GNN预测婴儿脑连接性

    Predicting Infant Brain Connectivity with Federated Multi-Trajectory GNNs using Scarce Data. (arXiv:2401.01383v1 [q-bio.NC])

    [http://arxiv.org/abs/2401.01383](http://arxiv.org/abs/2401.01383)

    我们提出了一种使用联邦多轨迹GNN的方法，通过稀缺数据预测婴儿脑连接性。通过联邦学习，我们通过聚合多个医院的本地学习结果来提高模型性能，同时保护数据隐私。

    

    对于识别早期脑连接性发展的动态过程，了解婴儿脑网络在出生后的第一年中的复杂演化至关重要。现有的深度学习解决方案存在三个主要局限性。首先，它们不能泛化到多轨迹预测任务，其中每个图轨迹对应于特定的成像模态或连接类型（例如T1-w MRI）。其次，现有模型需要大量的训练数据集才能达到令人满意的性能，而这往往很难获取。第三，它们不能有效利用不完整的时间序列数据。为了解决这些限制，我们引入了FedGmTE-Net++，一种联邦图形多轨迹演化网络。通过联邦学习的力量，我们在有限的医院数据集中聚合了不同医院的本地学习结果。结果即可提高每个医院本地生成模型的性能，同时保护数据隐私。

    The understanding of the convoluted evolution of infant brain networks during the first postnatal year is pivotal for identifying the dynamics of early brain connectivity development. Existing deep learning solutions suffer from three major limitations. First, they cannot generalize to multi-trajectory prediction tasks, where each graph trajectory corresponds to a particular imaging modality or connectivity type (e.g., T1-w MRI). Second, existing models require extensive training datasets to achieve satisfactory performance which are often challenging to obtain. Third, they do not efficiently utilize incomplete time series data. To address these limitations, we introduce FedGmTE-Net++, a federated graph-based multi-trajectory evolution network. Using the power of federation, we aggregate local learnings among diverse hospitals with limited datasets. As a result, we enhance the performance of each hospital's local generative model, while preserving data privacy. The three key innovation
    
[^48]: 少样本学习是否容易受到后门攻击？

    Does Few-shot Learning Suffer from Backdoor Attacks?. (arXiv:2401.01377v1 [cs.CR])

    [http://arxiv.org/abs/2401.01377](http://arxiv.org/abs/2401.01377)

    本研究探索了少样本学习对后门攻击的脆弱性，并提出了少样本学习后门攻击方法（FLBA）。

    

    少样本学习（FSL）在训练数据有限的情况下表现出了很好的结果，但它对后门攻击的脆弱性仍然未被充分探索。我们首先通过评估现有后门攻击方法在少样本学习场景中的表现来探索这个问题。与标准的监督学习不同，现有的后门攻击方法在少样本学习中无法进行有效的攻击，主要存在两个问题。首先，模型往往过拟合于良性特征或触发特征，导致攻击成功率和良性准确率之间存在很难平衡的问题。其次，由于训练样本数量较少，支持集中的脏标签或可见触发器很容易被受攻击者检测到，从而降低了攻击的隐蔽性。似乎少样本学习可以抵御后门攻击。然而，在本文中，我们提出了少样本学习后门攻击（FLBA）来展示少样本学习仍然容易受到后门攻击的情况。

    The field of few-shot learning (FSL) has shown promising results in scenarios where training data is limited, but its vulnerability to backdoor attacks remains largely unexplored. We first explore this topic by first evaluating the performance of the existing backdoor attack methods on few-shot learning scenarios. Unlike in standard supervised learning, existing backdoor attack methods failed to perform an effective attack in FSL due to two main issues. Firstly, the model tends to overfit to either benign features or trigger features, causing a tough trade-off between attack success rate and benign accuracy. Secondly, due to the small number of training samples, the dirty label or visible trigger in the support set can be easily detected by victims, which reduces the stealthiness of attacks. It seemed that FSL could survive from backdoor attacks. However, in this paper, we propose the Few-shot Learning Backdoor Attack (FLBA) to show that FSL can still be vulnerable to backdoor attacks.
    
[^49]: 使用张量卷积神经网络提高制造业中的缺陷检测

    Boosting Defect Detection in Manufacturing using Tensor Convolutional Neural Networks. (arXiv:2401.01373v1 [cs.CV])

    [http://arxiv.org/abs/2401.01373](http://arxiv.org/abs/2401.01373)

    我们引入了一种张量卷积神经网络（T-CNN）来提高制造业中的缺陷检测任务，通过减少模型参数空间，我们实现了比等效CNN模型更快的训练速度和性能。与传统的人类视觉检查相比，在质量指标方面，T-CNN在参数数量上只有15倍少，训练时间快4%至19%。这项研究在实际制造应用中取得了显著的成果。

    

    缺陷检测是制造业质量控制阶段中最重要但也最具挑战性的任务之一。在本研究中，我们引入了一种张量卷积神经网络（T-CNN），并在罗伯特·博世制造厂生产的超声波传感器组件的真实缺陷检测应用中考察其性能。我们的量子启发式T-CNN在减少的模型参数空间上运行，极大地提高了等效CNN模型的训练速度和性能，而不会牺牲准确性。具体来说，我们演示了T-CNN可以通过质量指标来衡量与传统CNN相同的性能，但参数数量只有其15倍少，训练时间快4%至19%。我们的结果表明，T-CNN大大超越了传统人类视觉检查的结果，在当前制造应用中具有价值。

    Defect detection is one of the most important yet challenging tasks in the quality control stage in the manufacturing sector. In this work, we introduce a Tensor Convolutional Neural Network (T-CNN) and examine its performance on a real defect detection application in one of the components of the ultrasonic sensors produced at Robert Bosch's manufacturing plants. Our quantum-inspired T-CNN operates on a reduced model parameter space to substantially improve the training speed and performance of an equivalent CNN model without sacrificing accuracy. More specifically, we demonstrate how T-CNNs are able to reach the same performance as classical CNNs as measured by quality metrics, with up to fifteen times fewer parameters and 4% to 19% faster training times. Our results demonstrate that the T-CNN greatly outperforms the results of traditional human visual inspection, providing value in a current real application in manufacturing.
    
[^50]: RL-MPCA: 基于强化学习的多阶段计算分配方法用于推荐系统

    RL-MPCA: A Reinforcement Learning Based Multi-Phase Computation Allocation Approach for Recommender Systems. (arXiv:2401.01369v1 [cs.IR])

    [http://arxiv.org/abs/2401.01369](http://arxiv.org/abs/2401.01369)

    RL-MPCA是一种基于强化学习的多阶段计算分配方法，用于解决推荐系统中在计算资源有限情况下的计算成本和业务收益之间的权衡问题。

    

    推荐系统旨在从大量候选项中向用户推荐最合适的物品。随着用户请求的增加和服务（或模型）的复杂性增加，其计算成本也在增加。在计算资源有限的情况下，如何在计算成本和业务收益之间做出权衡成为一个重要问题。现有的研究集中于在队列截断场景中动态分配计算资源（即分配候选项的大小），并将计算资源分配问题建模为带约束条件的优化问题。其中一些研究集中于单阶段的计算资源分配，而其他研究则集中于多阶段的计算资源分配，但引入了一些关于队列截断场景的假设。然而，这些假设在其他情景下（如检索通道选择和预测模型选择）是不成立的。此外，现有的研究忽略了请求在不同阶段之间的状态转移过程，限制了其有效性。

    Recommender systems aim to recommend the most suitable items to users from a large number of candidates. Their computation cost grows as the number of user requests and the complexity of services (or models) increases. Under the limitation of computation resources (CRs), how to make a trade-off between computation cost and business revenue becomes an essential question. The existing studies focus on dynamically allocating CRs in queue truncation scenarios (i.e., allocating the size of candidates), and formulate the CR allocation problem as an optimization problem with constraints. Some of them focus on single-phase CR allocation, and others focus on multi-phase CR allocation but introduce some assumptions about queue truncation scenarios. However, these assumptions do not hold in other scenarios, such as retrieval channel selection and prediction model selection. Moreover, existing studies ignore the state transition process of requests between different phases, limiting the effectiven
    
[^51]: 基于神经网络和后继表示训练的多模态认知地图

    Multi-Modal Cognitive Maps based on Neural Networks trained on Successor Representations. (arXiv:2401.01364v1 [q-bio.NC])

    [http://arxiv.org/abs/2401.01364](http://arxiv.org/abs/2401.01364)

    该研究通过使用神经网络和后继表示训练，建立了一个能够模拟位置细胞动态和认知地图表示的多模态认知地图模型。该模型能够以超过90%的准确率从一种形式推断到另一种形式，对于改善当前人工智能系统对环境的理解具有潜在意义。

    

    认知地图是关于大脑如何有效地组织记忆和提取上下文的一个提议概念。内隐-海马复合体在情节和关系记忆处理以及空间导航中起着重要作用，并被认为通过位置细胞和网格细胞建立认知地图。为了利用认知地图的有希望的特性，我们使用后继表示建立了一个多模态神经网络，能够模拟位置细胞动态和认知地图表示。在这里，我们使用由图像和词嵌入组成的多模态输入。网络学习了新输入与训练数据库之间的相似性，从而成功建立了认知地图的表示。随后，网络的预测可以以超过90%的准确率从一种形式推断到另一种形式。所提出的方法可能成为改进当前人工智能系统以更好理解环境的基石。

    Cognitive maps are a proposed concept on how the brain efficiently organizes memories and retrieves context out of them. The entorhinal-hippocampal complex is heavily involved in episodic and relational memory processing, as well as spatial navigation and is thought to built cognitive maps via place and grid cells. To make use of the promising properties of cognitive maps, we set up a multi-modal neural network using successor representations which is able to model place cell dynamics and cognitive map representations. Here, we use multi-modal inputs consisting of images and word embeddings. The network learns the similarities between novel inputs and the training database and therefore the representation of the cognitive map successfully. Subsequently, the prediction of the network can be used to infer from one modality to another with over $90\%$ accuracy. The proposed method could therefore be a building block to improve current AI systems for better understanding of the environment
    
[^52]: 在线意见极化的传播解剖：超级传播者在社交网络中的关键作用

    The Anatomy Spread of Online Opinion Polarization: The Pivotal Role of Super-Spreaders in Social Networks. (arXiv:2401.01349v1 [physics.soc-ph])

    [http://arxiv.org/abs/2401.01349](http://arxiv.org/abs/2401.01349)

    该研究揭示了在社交网络中塑造意见的超级传播者的重要角色，通过对超级传播者行为的调查和分析，提供了对群体动态和意见形成的条件的理解，对改进在线交流安全和社交影响力的认识具有启示作用。

    

    该研究探讨了在网络中塑造意见的“超级传播者”的角色，区分了三种类型：A、B和C。A型在塑造意见方面具有重要影响力，B型则起到了平衡A型的作用，C型则像媒体一样，提供客观观点，并潜在地调控A型和B型的影响力。研究使用置信系数和z分数来调查超级传播者的行为，着重考察影响群体动态和意见形成的条件，包括环境因素和随时间的遗忘。研究结果为改善在线交流安全和了解社会影响力提供了深入见解。

    The study investigates the role of 'superspreaders' in shaping opinions within networks, distinguishing three types: A, B, and C. Type A has a significant influence in shaping opinions, Type B acts as a counterbalance to A, and Type C functions like media, providing an objective viewpoint and potentially regulating A and B's influence. The research uses a confidence coefficient and z-score to survey superspreaders' behaviors, with a focus on the conditions affecting group dynamics and opinion formation, including environmental factors and forgetfulness over time. The findings offer insights for improving online communication security and understanding social influence.
    
[^53]: IoTGeM: 用于基于行为的物联网攻击检测的通用模型

    IoTGeM: Generalizable Models for Behaviour-Based IoT Attack Detection. (arXiv:2401.01343v1 [cs.CR])

    [http://arxiv.org/abs/2401.01343](http://arxiv.org/abs/2401.01343)

    本研究提出了一种通用模型，用于基于行为的物联网攻击检测。该模型通过改进滚动窗口特征提取、引入多步骤特征选择、使用隔离的训练和测试数据集以及使用可解释的人工智能技术来提高检测和性能，并且经过严格评估。

    

    过去关于物联网设备网络的基于行为的攻击检测研究，所得到的机器学习模型的适应能力有限，并且往往没有得到证明。本文提出了一种针对建模物联网网络攻击的方法，着重于通用性，同时也能提高检测和性能。首先，我们提出了一种改进的滚动窗口特征提取方法，并引入了一个多步骤特征选择过程来减少过拟合。其次，我们使用隔离的训练和测试数据集来构建和测试模型，从而避免了先前模型在通用性方面的常见数据泄漏问题。第三，我们使用多样化的机器学习模型、评估指标和数据集对我们的方法进行了严格评估。最后，我们使用可解释的人工智能技术来增加模型的可信度，从而能够识别出支撑攻击准确检测的特征。

    Previous research on behaviour-based attack detection on networks of IoT devices has resulted in machine learning models whose ability to adapt to unseen data is limited, and often not demonstrated. In this paper we present an approach for modelling IoT network attacks that focuses on generalizability, yet also leads to better detection and performance. First, we present an improved rolling window approach for feature extraction, and introduce a multi-step feature selection process that reduces overfitting. Second, we build and test models using isolated train and test datasets, thereby avoiding common data leaks that have limited the generalizability of previous models. Third, we rigorously evaluate our methodology using a diverse portfolio of machine learning models, evaluation metrics and datasets. Finally, we build confidence in the models by using explainable AI techniques, allowing us to identify the features that underlie accurate detection of attacks.
    
[^54]: 自然语言处理和大型语言模型公平性认证

    Fairness Certification for Natural Language Processing and Large Language Models. (arXiv:2401.01262v1 [cs.CL])

    [http://arxiv.org/abs/2401.01262](http://arxiv.org/abs/2401.01262)

    这项研究旨在为自然语言处理领域开发公平性认证方法。通过综述大量文献和专家访谈，我们提出了六个公平性标准，为操作化和测试过程提供了基础。

    

    自然语言处理（NLP）在我们的日常生活中扮演着重要角色，特别是由于大型语言模型（LLM）的巨大进展。然而，NLP在招聘等公平关键应用场景中存在许多问题，例如作为专家系统或基于LLM的教育导师。由于NLP基于人类语言，可能会导致潜在的有害偏见渗入NLP系统，产生不公平的结果，歧视少数群体或引发法律问题。因此，开展NLP方法的公平性认证非常重要。我们采用定性研究方法，对算法公平性的大量文献进行了综述，并与该领域的多位专家进行了半结构化的专家访谈。我们系统地提出了NLP的六个公平性标准，并进一步细化为18个子类别。我们的标准为实施和测试过程提供了基础。

    Natural Language Processing (NLP) plays an important role in our daily lives, particularly due to the enormous progress of Large Language Models (LLM). However, NLP has many fairness-critical use cases, e.g., as an expert system in recruitment or as an LLM-based tutor in education. Since NLP is based on human language, potentially harmful biases can diffuse into NLP systems and produce unfair results, discriminate against minorities or generate legal issues. Hence, it is important to develop a fairness certification for NLP approaches. We follow a qualitative research approach towards a fairness certification for NLP. In particular, we have reviewed a large body of literature on algorithmic fairness, and we have conducted semi-structured expert interviews with a wide range of experts from that area. We have systematically devised six fairness criteria for NLP, which can be further refined into 18 sub-categories. Our criteria offer a foundation for operationalizing and testing processes
    
[^55]: 越南诗歌生成与跨语言诗歌翻译的前景

    Vietnamese Poem Generation & The Prospect Of Cross-Language Poem-To-Poem Translation. (arXiv:2401.01078v1 [cs.CL])

    [http://arxiv.org/abs/2401.01078](http://arxiv.org/abs/2401.01078)

    本文通过使用大型语言模型，成功提出了一种生成越南诗歌的方法，并探索了将诗歌翻译成不同语言的可能性，同时保持对生成内容的完全控制。

    

    诗歌生成一直是自然语言处理领域的一项挑战任务，因为它要求模型理解语言、情感和风格的细微差别。在本文中，我们提出使用大型语言模型从自然语言提示中生成越南诗歌，从而实现直观的过程和增强的内容控制。我们最有效的模型，GPT-3 Babbage变种，在越南诗歌的“六八词”类型中实现了0.8的自定义评分。此外，我们还探索了将诗歌改写成正常文本提示的想法，并在“六八词”类型中获得了相对较高的0.718分数。这个实验展示了以翻译后的诗歌作为输入进行跨语言诗歌翻译的潜力，并同时保持对生成内容的完全控制。

    Poetry generation has been a challenging task in the field of Natural Language Processing, as it requires the model to understand the nuances of language, sentiment, and style. In this paper, we propose using Large Language Models to generate Vietnamese poems from natural language prompts, thereby facilitating an intuitive process with enhanced content control. Our most efficacious model, the GPT-3 Babbage variant, achieves a custom evaluation score of 0.8, specifically tailored to the "luc bat" genre of Vietnamese poetry. Furthermore, we also explore the idea of paraphrasing poems into normal text prompts and yield a relatively high score of 0.718 in the "luc bat" genre. This experiment presents the potential for cross-Language poem-to-poem translation with translated poems as the inputs while concurrently maintaining complete control over the generated content.
    
[^56]: 脑条件多模态合成：一项调查与分类综述

    Brain-Conditional Multimodal Synthesis: A Survey and Taxonomy. (arXiv:2401.00430v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2401.00430](http://arxiv.org/abs/2401.00430)

    脑条件多模态合成是一项利用脑信号解码为知觉体验的技术，可以用于开发实用的脑-计算机接口系统以及揭示大脑感知和理解外部刺激的复杂机制。

    

    在人工智能生成内容（AIGC）时代，条件多模态合成技术（如文本到图像、文本到视频、文本到音频等）正在逐渐改变现实世界中的自然内容。多模态合成技术的关键是建立不同模态之间的映射关系。作为大脑解读外部信息的潜在反映，脑信号与各种外部模态之间存在着独特的一对多对应关系。这种对应关系使得脑信号成为多模态内容合成的有希望的引导条件。脑条件多模态合成指的是将脑信号解码为知觉体验，这对于发展实用的脑-计算机接口系统和揭示大脑感知和理解外部刺激的复杂机制至关重要。本调查全面审视了基于AIGC的脑条件多模态合成领域。

    In the era of Artificial Intelligence Generated Content (AIGC), conditional multimodal synthesis technologies (e.g., text-to-image, text-to-video, text-to-audio, etc) are gradually reshaping the natural content in the real world. The key to multimodal synthesis technology is to establish the mapping relationship between different modalities. Brain signals, serving as potential reflections of how the brain interprets external information, exhibit a distinctive One-to-Many correspondence with various external modalities. This correspondence makes brain signals emerge as a promising guiding condition for multimodal content synthesis. Brian-conditional multimodal synthesis refers to decoding brain signals back to perceptual experience, which is crucial for developing practical brain-computer interface systems and unraveling complex mechanisms underlying how the brain perceives and comprehends external stimuli. This survey comprehensively examines the emerging field of AIGC-based Brain-cond
    
[^57]: 使用感知损失的扩散模型

    Diffusion Model with Perceptual Loss. (arXiv:2401.00110v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2401.00110](http://arxiv.org/abs/2401.00110)

    本研究介绍了一种使用感知损失的扩散模型，通过无分类器指导实现了生成更真实样本的目的。

    

    使用均方误差损失训练的扩散模型倾向于生成不真实的样本。目前的最先进模型依靠无分类器指导来改善样本质量，然而其惊人的效果尚未完全理解。本文中，我们展示了无分类器指导的有效性在一定程度上源自其作为一种隐式感知指导的形式。因此，我们可以直接在扩散训练中加入感知损失来提高样本质量。由于扩散训练中使用的分数匹配目标与无监督训练感知网络时使用的去噪自动编码器目标非常相似，因此扩散模型本身就是一个感知网络，并可以用于生成有意义的感知损失。我们提出了一种新颖的自感知目标，其结果是扩散模型能够生成更真实的样本。对于条件生成，我们的方法仅改善样本质量，而不与条件绑定。

    Diffusion models trained with mean squared error loss tend to generate unrealistic samples. Current state-of-the-art models rely on classifier-free guidance to improve sample quality, yet its surprising effectiveness is not fully understood. In this paper, We show that the effectiveness of classifier-free guidance partly originates from it being a form of implicit perceptual guidance. As a result, we can directly incorporate perceptual loss in diffusion training to improve sample quality. Since the score matching objective used in diffusion training strongly resembles the denoising autoencoder objective used in unsupervised training of perceptual networks, the diffusion model itself is a perceptual network and can be used to generate meaningful perceptual loss. We propose a novel self-perceptual objective that results in diffusion models capable of generating more realistic samples. For conditional generation, our method only improves sample quality without entanglement with the condit
    
[^58]: SVGDreamer：基于文本引导的SVG生成与扩散模型

    SVGDreamer: Text Guided SVG Generation with Diffusion Model. (arXiv:2312.16476v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2312.16476](http://arxiv.org/abs/2312.16476)

    该论文提出了一种名为SVGDreamer的方法，用于基于文本引导的SVG生成。它通过引入语义驱动的图像矢量化过程和基于注意力的元素控制，增强了生成结果的可编辑性和质量。同时，采用基于矢量化粒子分数蒸馏的方法解决了现有方法中的颜色、平滑度和结果多样性方面的挑战。

    

    最近，基于文本引导的可缩放矢量图形（SVG）合成在图标设计和草图等领域展示出了潜力。然而，现有的文本到SVG生成方法存在缺乏可编辑性、视觉质量和结果多样性不足的问题。为了解决这些限制，我们提出了一种新颖的基于文本引导的矢量图形合成方法，称为SVGDreamer。SVGDreamer整合了一种语义驱动的图像矢量化（SIVE）过程，可以将合成过程分解为前景对象和背景，从而增强了可编辑性。具体而言，SIVE过程引入了基于注意力的基本元素控制和注意力掩蔽损失函数，以有效控制和操作各个元素。此外，我们提出了一种基于矢量化粒子分数蒸馏（VPSD）的方法，以解决现有文本到SVG生成方法中颜色过饱和、矢量基元过平滑和结果多样性有限的挑战。

    Recently, text-guided scalable vector graphics (SVGs) synthesis has shown promise in domains such as iconography and sketch. However, existing text-to-SVG generation methods lack editability and struggle with visual quality and result diversity. To address these limitations, we propose a novel text-guided vector graphics synthesis method called SVGDreamer. SVGDreamer incorporates a semantic-driven image vectorization (SIVE) process that enables the decomposition of synthesis into foreground objects and background, thereby enhancing editability. Specifically, the SIVE process introduce attention-based primitive control and an attention-mask loss function for effective control and manipulation of individual elements. Additionally, we propose a Vectorized Particle-based Score Distillation (VPSD) approach to tackle the challenges of color over-saturation, vector primitives over-smoothing, and limited result diversity in existing text-to-SVG generation methods. Furthermore, on the basis of 
    
[^59]: LLM-SAP: 大语言模型情景感知的基于规划

    LLM-SAP: Large Language Model Situational Awareness Based Planning. (arXiv:2312.16127v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2312.16127](http://arxiv.org/abs/2312.16127)

    本文提出了一种基于大型语言模型的情景感知的紧急规划能力评估方法，并提供了新的基准和指标，以及独特的数据集。研究结果表明，提示和多智能体方案可以显著提高上下文敏感规划任务的性能。

    

    本文首次在大型语言模型中评估基于情景感知的紧急规划能力。我们贡献了（i）用于标准化评估的新型基准和指标；（ii）一个独特的数据集来推动进展；以及（iii）演示以提示和多智能体方案显著提高了上下文敏感规划任务的性能。将其纳入到一个处境智能体和自动化规划研究中，我们强调了固有的可靠性挑战-尽管在模拟领域的进步中，如何在没有环境指导的情况下有效地将世界状态映射到行动仍然是一个开放的问题。尽管超出范围，对于验证方法和数据可用性的限制表明了令人兴奋的方向，包括对扩展规划语料库进行微调和针对快速潜在规划的优化。通过通过严密的比较来确实地展示当前方法的承诺和局限性，我们推动了对可靠目标导向推理的研究

    This work pioneers evaluating emergent planning capabilities based on situational awareness in large language models. We contribute (i) novel benchmarks and metrics for standardized assessment; (ii) a unique dataset to spur progress; and (iii) demonstrations that prompting and multi-agent schemes significantly enhance planning performance in context-sensitive planning tasks. Positioning this within a situated agent and automated planning research, we highlight inherent reliability challenges--efficiently mapping world states to actions without environmental guidance remains open despite simulated domain advances. Although out-of-scope, limitations around validation methodology and data availability indicate exciting directions, including fine-tuning on expanded planning corpora and optimizations for triggering fast latent planning. By conclusively demonstrating current methods' promise and limitations via rigorous comparison, we catalyze investigating reliable goal-directed reasoning f
    
[^60]: 大型语言模型在可解释推荐中的潜力解锁

    Unlocking the Potential of Large Language Models for Explainable Recommendations. (arXiv:2312.15661v3 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2312.15661](http://arxiv.org/abs/2312.15661)

    本研究提出了LLMXRec框架，一种简单而有效的两阶段解释推荐方法，利用大型语言模型进一步提升解释质量，通过与先前的推荐模型密切协作，在推荐效果和解释质量方面取得了显著提升。

    

    生成关于为何推荐某个项目的用户友好解释已经变得越来越常见，这主要归功于语言生成技术的进步，这可以增强用户的信任并在使用在线服务时促进更明智的决策。然而，现有的可解释推荐系统主要使用小型语言模型。目前尚不清楚将解释生成器替换为最近出现的大型语言模型（LLMs）会产生何种影响。我们能否期望前所未有的结果？在这项研究中，我们提出了LLMXRec，一个简单而有效的两阶段可解释推荐框架，旨在通过使用LLMs进一步提高解释质量。与大多数现有的基于LLM的推荐工作不同，LLMXRec的一个重要特点是它强调先前的推荐模型与基于LLM的解释生成器之间的密切协作。具体而言，通过采用几种关键的微调技术，包括参数调优技术，我们的方法在推荐效果和解释质量方面实现了显著提升。

    Generating user-friendly explanations regarding why an item is recommended has become increasingly common, largely due to advances in language generation technology, which can enhance user trust and facilitate more informed decision-making when using online services. However, existing explainable recommendation systems focus on using small-size language models. It remains uncertain what impact replacing the explanation generator with the recently emerging large language models (LLMs) would have. Can we expect unprecedented results?  In this study, we propose LLMXRec, a simple yet effective two-stage explainable recommendation framework aimed at further boosting the explanation quality by employing LLMs. Unlike most existing LLM-based recommendation works, a key characteristic of LLMXRec is its emphasis on the close collaboration between previous recommender models and LLM-based explanation generators. Specifically, by adopting several key fine-tuning techniques, including parameter-eff
    
[^61]: 通过论据集成实现模型多样性下的追索（技术报告）

    Recourse under Model Multiplicity via Argumentative Ensembling (Technical Report). (arXiv:2312.15097v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2312.15097](http://arxiv.org/abs/2312.15097)

    本研究提出了一种名为“追索感知的集成”的方法，通过使用计算论证方法来解决模型多样性下提供反事实解释的挑战性。该方法保证了在模型多样性情况下CEs的鲁棒性，并可以适应用户的个性化偏好。

    

    模型多样性（MM）是指在解决同一预测任务时可以训练出多个性能相同的机器学习模型。最近的研究表明，在MM下获得的模型对于相同的输入可能产生不一致的预测。当出现这种情况时，为受到模型预测影响的个体提供反事实解释（CEs）变得具有挑战性。在本文中，我们正式定义了这个问题，称之为追索感知的集成，并确定了解决这个问题的方法应该满足的几个理想属性。我们发现现有的集成方法在不同方式下自然扩展以提供CEs时未能满足这些属性。然后，我们引入了论证集成，采用计算论证方法来确保CEs对MM的鲁棒性，并适应可定制的用户偏好。我们从理论和实验上证明了论证集成满足了这些属性。

    Model Multiplicity (MM) arises when multiple, equally performing machine learning models can be trained to solve the same prediction task. Recent studies show that models obtained under MM may produce inconsistent predictions for the same input. When this occurs, it becomes challenging to provide counterfactual explanations (CEs), a common means for offering recourse recommendations to individuals negatively affected by models' predictions. In this paper, we formalise this problem, which we name recourse-aware ensembling, and identify several desirable properties which methods for solving it should satisfy. We show that existing ensembling methods, naturally extended in different ways to provide CEs, fail to satisfy these properties. We then introduce argumentative ensembling, deploying computational argumentation to guarantee robustness of CEs to MM, while also accommodating customisable user preferences. We show theoretically and experimentally that argumentative ensembling satisfies
    
[^62]: 并非所有步骤都相等：进展扩散模型的高效生成

    Not All Steps are Equal: Efficient Generation with Progressive Diffusion Models. (arXiv:2312.13307v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2312.13307](http://arxiv.org/abs/2312.13307)

    提出了一种步骤自适应训练的两阶段策略，解决了传统扩散模型中训练过程中的冲突问题，将模型大小调整与噪声预测难度相匹配，提高了生成效果。

    

    扩散模型在多种生成任务中展示了出色的效能，具有去噪模型的预测能力。目前，这些模型在所有时间步上都采用统一的去噪方法。然而，每个时间步的噪声潜在变化导致了训练中的冲突，限制了扩散模型的潜力。为了解决这个挑战，我们提出了一种新的两阶段训练策略，称为步骤自适应训练。在初始阶段，训练一个基础的去噪模型来包括所有的时间步。随后，我们将时间步分为不同的组，对每个组内的模型进行微调，以达到专门的去噪能力。我们认识到，不同时间步的噪声预测困难程度是不同的，所以我们引入了多样的模型大小要求。我们通过估计每个时间步的信噪比来动态调整模型大小，以进行微调之前。此调整简化了模型的训练流程并提高了生成效果。

    Diffusion models have demonstrated remarkable efficacy in various generative tasks with the predictive prowess of denoising model. Currently, these models employ a uniform denoising approach across all timesteps. However, the inherent variations in noisy latents at each timestep lead to conflicts during training, constraining the potential of diffusion models. To address this challenge, we propose a novel two-stage training strategy termed Step-Adaptive Training. In the initial stage, a base denoising model is trained to encompass all timesteps. Subsequently, we partition the timesteps into distinct groups, fine-tuning the model within each group to achieve specialized denoising capabilities. Recognizing that the difficulties of predicting noise at different timesteps vary, we introduce a diverse model size requirement. We dynamically adjust the model size for each timestep by estimating task difficulty based on its signal-to-noise ratio before fine-tuning. This adjustment is facilitat
    
[^63]: 基于检索增强的大型语言模型：一项调研

    Retrieval-Augmented Generation for Large Language Models: A Survey. (arXiv:2312.10997v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.10997](http://arxiv.org/abs/2312.10997)

    本综述论文调查了基于检索增强的大型语言模型的发展，包括三个主要范式：Naive RAG、Advanced RAG和Modular RAG。RAG通过整合外部数据库的知识，增强模型的准确性和可信度，并实现了持续更新知识和整合领域特定信息的功能。

    

    大型语言模型（LLMs）展示了显著的能力，但面临幻觉、过时知识和非透明、不可追溯的推理过程等挑战。检索增强生成（RAG）已经成为一种有前途的解决方案，通过整合来自外部数据库的知识，增强模型的准确性和可信度，特别适用于知识密集型任务，并允许持续更新知识和整合领域特定信息。RAG将LLMs自身的知识与庞大、动态的外部数据库相结合，实现协同效应。本综述论文详细考察了RAG范式的发展，包括Naive RAG、Advanced RAG和Modular RAG。它详细审视了RAG框架的三个基本要素，包括检索、生成和增强技术。本文强调了嵌入在RAG框架中的最新技术。

    Large Language Models (LLMs) demonstrate significant capabilities but face challenges such as hallucination, outdated knowledge, and non-transparent, untraceable reasoning processes. Retrieval-Augmented Generation (RAG) has emerged as a promising solution by incorporating knowledge from external databases. This enhances the accuracy and credibility of the models, particularly for knowledge-intensive tasks, and allows for continuous knowledge updates and integration of domain-specific information. RAG synergistically merges LLMs' intrinsic knowledge with the vast, dynamic repositories of external databases. This comprehensive review paper offers a detailed examination of the progression of RAG paradigms, encompassing the Naive RAG, the Advanced RAG, and the Modular RAG. It meticulously scrutinizes the tripartite foundation of RAG frameworks, which includes the retrieval , the generation and the augmentation techniques. The paper highlights the state-of-the-art technologies embedded in e
    
[^64]: EQ-Bench:一种用于大型语言模型的情商评估基准

    EQ-Bench: An Emotional Intelligence Benchmark for Large Language Models. (arXiv:2312.06281v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.06281](http://arxiv.org/abs/2312.06281)

    EQ-Bench是一种为评估大型语言模型（LLMs）的情商而设计的新型基准。该基准通过要求模型预测对话中角色的情绪状态强度来评估模型对复杂情绪和社交交互的理解能力。它能够有效区分不同模型，并与其他综合基准相关性很高。

    

    我们介绍了EQ-Bench，这是一种用于评估大型语言模型（LLMs）情商方面的新型基准。我们通过要求LLMs预测对话中角色的情绪状态的强度来评估LLMs理解复杂情绪和社交交互的能力。这个基准可以有效地区分不同模型。我们发现EQ-Bench与综合多领域基准（如MMLU）之间存在很强的相关性（r=0.97），这表明我们可能捕捉到了广泛智能的相似方面。我们的基准使用60个英语问题产生高度可重复的结果。我们还在https://github.com/EQ-bench/EQ-Bench上提供了开源代码用于自动化基准测试流程，以及https://eqbench.com上的排行榜。

    We introduce EQ-Bench, a novel benchmark designed to evaluate aspects of emotional intelligence in Large Language Models (LLMs). We assess the ability of LLMs to understand complex emotions and social interactions by asking them to predict the intensity of emotional states of characters in a dialogue. The benchmark is able to discriminate effectively between a wide range of models. We find that EQ-Bench correlates strongly with comprehensive multi-domain benchmarks like MMLU (Hendrycks et al., 2020) (r=0.97), indicating that we may be capturing similar aspects of broad intelligence. Our benchmark produces highly repeatable results using a set of 60 English-language questions. We also provide open-source code for an automated benchmarking pipeline at https://github.com/EQ-bench/EQ-Bench and a leaderboard at https://eqbench.com
    
[^65]: SkateboardAI：最酷的滑板视频动作识别

    SkateboardAI: The Coolest Video Action Recognition for Skateboarding. (arXiv:2311.11467v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2311.11467](http://arxiv.org/abs/2311.11467)

    我们提出了SkateboardAI，这是一个用于最酷的滑板视频动作识别的数据集。我们设计了多种单模态和多模态的识别方法，并比较了它们的性能。这个研究的目标是开发一个优秀的AI体育裁判。

    

    受2021年东京奥运会最酷的滑板运动节目的启发，我们首次策划了原始的现实世界视频数据集“SkateboardAI”，并且自行设计和实现了不同单模态和多模态视频动作识别方法，以准确识别不同的技巧。对于单模态方法，我们分别应用了（1）CNN和LSTM；（2）CNN和BiLSTM；（3）带有效注意机制的CNN和BiLSTM；（4）基于Transformer的动作识别流程。转移到多模态条件下，我们调查了在“SkateboardAI”数据集上使用双流Inflated-3D架构，并将其与单模态情况进行了比较。总之，我们的目标是为最酷的滑板比赛开发出一款优秀的AI体育裁判。

    Impressed by the coolest skateboarding sports program from 2021 Tokyo Olympic Games, we are the first to curate the original real-world video datasets "SkateboardAI" in the wild, even self-design and implement diverse uni-modal and multi-modal video action recognition approaches to recognize different tricks accurately. For uni-modal methods, we separately apply (1) CNN and LSTM; (2) CNN and BiLSTM; (3) CNN and BiLSTM with effective attention mechanisms; (4) Transformer-based action recognition pipeline. Transferred to the multi-modal conditions, we investigated the two-stream Inflated-3D architecture on "SkateboardAI" datasets to compare its performance with uni-modal cases. In sum, our objective is developing an excellent AI sport referee for the coolest skateboarding competitions.
    
[^66]: Jina Embeddings 2: 面向长篇文档的8192-Token通用文本嵌入模型

    Jina Embeddings 2: 8192-Token General-Purpose Text Embeddings for Long Documents. (arXiv:2310.19923v1 [cs.CL])

    [http://arxiv.org/abs/2310.19923](http://arxiv.org/abs/2310.19923)

    Jina Embeddings 2是一个能够处理长篇文档的文本嵌入模型，突破了传统512个标记限制，提供了高达8192个标记的容量。

    

    文本嵌入模型已经成为将句子转化为固定大小特征向量的强大工具，这些向量包含了语义信息。尽管这些模型对于信息检索、语义聚类和文本重排序等任务至关重要，但大多数现有的开源模型，尤其是基于BERT等架构构建的模型，难以表示长篇文档，并且常常会进行截断。为了缓解这个挑战，一种常见的方法是将文档分割成更小的段落进行嵌入。然而，这种策略会导致更大的向量集合，进而增加内存消耗，并且在向量搜索时会出现计算密集和延迟升高的问题。为了解决这些挑战，我们介绍了Jina Embeddings 2，这是一个开源的文本嵌入模型，可以容纳高达8192个标记。该模型旨在突破传统的512个标记限制，能够灵活处理长篇文档。

    Text embedding models have emerged as powerful tools for transforming sentences into fixed-sized feature vectors that encapsulate semantic information. While these models are essential for tasks like information retrieval, semantic clustering, and text re-ranking, most existing open-source models, especially those built on architectures like BERT, struggle to represent lengthy documents and often resort to truncation. One common approach to mitigate this challenge involves splitting documents into smaller paragraphs for embedding. However, this strategy results in a much larger set of vectors, consequently leading to increased memory consumption and computationally intensive vector searches with elevated latency.  To address these challenges, we introduce Jina Embeddings 2, an open-source text embedding model capable of accommodating up to 8192 tokens. This model is designed to transcend the conventional 512-token limit and adeptly process long documents. Jina Embeddings 2 not only ach
    
[^67]: Othello已被解决

    Othello is Solved. (arXiv:2310.19387v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2310.19387](http://arxiv.org/abs/2310.19387)

    Othello是世界上最复杂和受欢迎的游戏之一，经过计算证明双方玩家的完美游戏将导致平局。

    

    Othello是世界上最复杂和受欢迎的游戏之一，尚未在计算机上解决。 Othello大约有10的58次方个可能的游戏记录和10的28次方个可能的游戏位置。解决Othello的挑战，即确定没有双方玩家犯错误时的游戏结果，一直是计算机科学的一个重大挑战。本文宣布了一个重要的里程碑：Othello现已解决。通过计算证明，如果双方玩家都以完美的方式进行游戏，结果将是平局。长期以来，人们使用启发式设计的搜索技术构建了强大的Othello软件。解决一个游戏提供了一个解决方案，使软件能够完美地进行游戏。

    The game of Othello is one of the world's most complex and popular games that has yet to be computationally solved. Othello has roughly ten octodecillion (10 to the 58th power) possible game records and ten octillion (10 to the 28th power) possible game positions. The challenge of solving Othello, determining the outcome of a game with no mistake made by either player, has long been a grand challenge in computer science. This paper announces a significant milestone: Othello is now solved. It is computationally proved that perfect play by both players lead to a draw. Strong Othello software has long been built using heuristically designed search techniques. Solving a game provides a solution that enables the software to play the game perfectly.
    
[^68]: 理解RLHF对LLM泛化和多样性的影响

    Understanding the Effects of RLHF on LLM Generalisation and Diversity. (arXiv:2310.06452v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.06452](http://arxiv.org/abs/2310.06452)

    本研究深入分析了强化学习从人类反馈中调整的大型语言模型每个阶段对超出分布泛化和输出多样性的影响。

    

    在最广泛使用的AI模型中，如OpenAI的ChatGPT或Anthropic的Claude，使用强化学习从人类反馈中调整的大型语言模型（LLM）。尽管在这些方法的开发方面有大量的研究，但我们对RLHF过程中每个阶段的利与弊的理解仍然有限。为了填补这一空白，我们对每个阶段（即监督微调（SFT），奖励建模和RLHF）如何影响两个关键属性进行了全面分析：超出分布的泛化和输出多样性。在这些模型被广泛应用于真实世界中的各种情景的背景下，超出分布的泛化非常重要，而输出多样性指的是模型生成各种不同输出的能力，对于各种用例来说都非常重要。我们在摘要和指令遵循任务中对两个基本模型进行了分析，后者非常相关。

    Large language models (LLMs) fine-tuned with reinforcement learning from human feedback (RLHF) have been used in some of the most widely deployed AI models to date, such as OpenAI's ChatGPT or Anthropic's Claude. % , or Meta's LLaMA-2. While there has been significant work developing these methods, our understanding of the benefits and downsides of each stage in RLHF is still limited. To fill this gap, we present an extensive analysis of how each stage of the process (i.e.~supervised fine-tuning (SFT), reward modelling, and RLHF) affects two key properties: out-of-distribution (OOD) generalisation and output diversity. OOD generalisation is crucial given the wide range of real-world scenarios in which these models are being used, while output diversity refers to the model's ability to generate varied outputs and is important for a variety of use cases. We perform our analysis across two base models on both summarisation and instruction following tasks, the latter being highly relevant 
    
[^69]: GMMFormer: 基于高斯混合模型的Transformer用于高效的部分相关视频检索

    GMMFormer: Gaussian-Mixture-Model Based Transformer for Efficient Partially Relevant Video Retrieval. (arXiv:2310.05195v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2310.05195](http://arxiv.org/abs/2310.05195)

    GMMFormer是一种基于高斯混合模型的Transformer，用于高效的部分相关视频检索。它通过隐式建模剪辑表示，采用多尺度剪辑信息，并引入了一个多样性损失函数来解决语义差异导致的稀疏嵌入空间问题。

    

    在给定一个文本查询的情况下，部分相关视频检索（PRVR）旨在在数据库中找到包含相关片段的未剪辑视频。对于PRVR，剪辑建模对于捕捉文本和视频之间的部分关系至关重要。当前的PRVR方法采用基于扫描的剪辑构建来实现显式剪辑建模，这种方法的信息冗余且需要大量的存储开销。为了解决PRVR方法的效率问题，本文提出了GMMFormer，一种基于高斯混合模型的Transformer，它隐式地建模了剪辑表示。在帧交互过程中，我们采用高斯混合模型约束，使每个帧专注于其相邻帧而不是整个视频。然后生成的表示将包含多尺度的剪辑信息，实现隐式剪辑建模。此外，PRVR方法忽视了与同一视频相关的文本查询之间的语义差异，导致稀疏的嵌入空间。我们提出了一个多样性损失函数来解决这个问题。

    Given a text query, partially relevant video retrieval (PRVR) seeks to find untrimmed videos containing pertinent moments in a database. For PRVR, clip modeling is essential to capture the partial relationship between texts and videos. Current PRVR methods adopt scanning-based clip construction to achieve explicit clip modeling, which is information-redundant and requires a large storage overhead. To solve the efficiency problem of PRVR methods, this paper proposes GMMFormer, a Gaussian-Mixture-Model based Transformer which models clip representations implicitly. During frame interactions, we incorporate Gaussian-Mixture-Model constraints to focus each frame on its adjacent frames instead of the whole video. Then generated representations will contain multi-scale clip information, achieving implicit clip modeling. In addition, PRVR methods ignore semantic differences between text queries relevant to the same video, leading to a sparse embedding space. We propose a query diverse loss to
    
[^70]: 魔法词是什么？LLM提示的控制理论研究

    What's the Magic Word? A Control Theory of LLM Prompting. (arXiv:2310.04444v1 [cs.CL])

    [http://arxiv.org/abs/2310.04444](http://arxiv.org/abs/2310.04444)

    本论文将提示工程形式化为LLM上的最优控制问题，研究了给定token序列时是否存在一种最优提示能够准确预测最终的token，并提出了控制理论中的指标来描述LLM的可操纵性。

    

    提示工程在LLM的部署中是有效和重要的，但在数学上理解不足。在这里，我们将提示工程形式化为LLM上的最优控制问题，其中提示被认为是调节LLM输出分布的控制变量。在这个框架内，我们提出一个简单的问题：给定一个token序列，是否总存在一个我们可以添加的提示，使得LLM能够准确预测最终的token？我们将这样的最优提示称为魔法词，因为添加提示会导致LLM输出正确的答案。如果存在魔法词，我们能否找到它们？如果可以，它们的特性是什么？我们提供了将控制理论应用于自注意力头的分析分析，证明了其权重矩阵的奇异值函数为可控制性的上界。我们借鉴控制理论来提出了一种叫做$k-\epsilon$可控制性的指标，用于描述LLM的可操纵性。

    Prompt engineering is effective and important in the deployment of LLMs but is poorly understood mathematically. Here, we formalize prompt engineering as an optimal control problem on LLMs -- where the prompt is considered a control variable for modulating the output distribution of the LLM. Within this framework, we ask a simple question: given a sequence of tokens, does there always exist a prompt we can prepend that will steer the LLM toward accurately predicting the final token? We call such an optimal prompt the magic word since prepending the prompt causes the LLM to output the correct answer. If magic words exist, can we find them? If so, what are their properties? We offer analytic analysis on the controllability of the self-attention head where we prove a bound on controllability as a function of the singular values of its weight matrices. We take inspiration from control theory to propose a metric called $k-\epsilon$ controllability to characterize LLM steerability. We comput
    
[^71]: 动态关系注意力图神经网络用于欺诈检测

    Dynamic Relation-Attentive Graph Neural Networks for Fraud Detection. (arXiv:2310.04171v1 [cs.LG])

    [http://arxiv.org/abs/2310.04171](http://arxiv.org/abs/2310.04171)

    本研究针对欺诈检测问题，通过动态关系注意聚合机制，提出了一种基于图神经网络（GNN）的方法。该方法学习每个关系的节点表示，并利用可学习的注意函数进行节点表示的聚合。通过结合不同层次的节点表示，考虑目标节点的局部和全局结构，以提高欺诈检测性能。通过使用动态图注意力，可以自适应地计算关系之间的重要程度。

    

    欺诈检测旨在发现欺诈者通过留下假评论或进行异常交易欺骗其他用户。基于图的欺诈检测方法将这个任务视为一个包含两个类别（欺诈或正常）的分类问题。我们通过提出一种动态关系注意聚合机制，利用图神经网络（GNN）来解决这个问题。基于实际世界图表中包含不同类型的关系的观察，我们建议学习每个关系的节点表示，并使用可学习的注意函数聚合节点表示，该函数为每个关系分配不同的注意系数。此外，我们结合不同层次的节点表示，以考虑目标节点的局部和全局结构，这有助于提高在具有异质性的图上进行欺诈检测的性能。通过在所有聚合过程中采用动态图注意力，我们的方法可以自适应地计算关系之间的重要程度。

    Fraud detection aims to discover fraudsters deceiving other users by, for example, leaving fake reviews or making abnormal transactions. Graph-based fraud detection methods consider this task as a classification problem with two classes: frauds or normal. We address this problem using Graph Neural Networks (GNNs) by proposing a dynamic relation-attentive aggregation mechanism. Based on the observation that many real-world graphs include different types of relations, we propose to learn a node representation per relation and aggregate the node representations using a learnable attention function that assigns a different attention coefficient to each relation. Furthermore, we combine the node representations from different layers to consider both the local and global structures of a target node, which is beneficial to improving the performance of fraud detection on graphs with heterophily. By employing dynamic graph attention in all the aggregation processes, our method adaptively comput
    
[^72]: 关于尖锐意识最小化的记忆和隐私风险研究

    On Memorization and Privacy Risks of Sharpness Aware Minimization. (arXiv:2310.00488v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.00488](http://arxiv.org/abs/2310.00488)

    本研究通过对过度参数化模型中的数据记忆的剖析，揭示了尖锐意识最小化算法在非典型数据点上实现的泛化收益。同时，也发现了与此算法相关的更高隐私风险，并提出了缓解策略，以达到更理想的准确度与隐私权衡。

    

    在许多最近的研究中，设计寻求神经网络损失优化中更平坦的极值的算法成为焦点，因为有经验证据表明这会在许多数据集上导致更好的泛化性能。在这项工作中，我们通过过度参数化模型中的数据记忆视角来剖析这些性能收益。我们定义了一个新的度量指标，帮助我们确定相对于普通SGD，寻求更平坦极值的算法在哪些数据点上表现更好。我们发现，尖锐意识最小化（SAM）所实现的泛化收益在非典型数据点上特别显著，这需要记忆。这一认识帮助我们揭示与SAM相关的更高的隐私风险，并通过详尽的实证评估进行验证。最后，我们提出缓解策略，以实现更理想的准确度与隐私权衡。

    In many recent works, there is an increased focus on designing algorithms that seek flatter optima for neural network loss optimization as there is empirical evidence that it leads to better generalization performance in many datasets. In this work, we dissect these performance gains through the lens of data memorization in overparameterized models. We define a new metric that helps us identify which data points specifically do algorithms seeking flatter optima do better when compared to vanilla SGD. We find that the generalization gains achieved by Sharpness Aware Minimization (SAM) are particularly pronounced for atypical data points, which necessitate memorization. This insight helps us unearth higher privacy risks associated with SAM, which we verify through exhaustive empirical evaluations. Finally, we propose mitigation strategies to achieve a more desirable accuracy vs privacy tradeoff.
    
[^73]: 准确快速的压缩视频字幕生成研究

    Accurate and Fast Compressed Video Captioning. (arXiv:2309.12867v1 [cs.CV])

    [http://arxiv.org/abs/2309.12867](http://arxiv.org/abs/2309.12867)

    这项研究提出了一种准确快速的压缩视频字幕生成方法，通过从压缩域进行学习，避免了手动帧采样和冗余处理，提高了性能和效率。

    

    现有的视频字幕生成方法通常需要从解码视频中首先采样视频帧，然后进行后续处理（例如，特征提取和字幕模型学习）。在这个过程中，手动帧采样可能会忽略视频中的关键信息，从而降低性能。此外，采样帧中的冗余信息可能导致视频字幕生成推理的效率低下。针对这个问题，我们从压缩域的不同角度研究视频字幕生成，这种方法相比现有的流水线具有多重优势：1）与解码视频的原始图像相比，由I-帧、运动矢量和残差构成的压缩视频更具可识别性，这使得我们可以通过专用模型设计在学习过程中使用整个视频而不需要手动采样；2）字幕生成模型的推理效率更高，因为处理的信息更少且更少冗余。我们提出了一个简单但有效的方法。

    Existing video captioning approaches typically require to first sample video frames from a decoded video and then conduct a subsequent process (e.g., feature extraction and/or captioning model learning). In this pipeline, manual frame sampling may ignore key information in videos and thus degrade performance. Additionally, redundant information in the sampled frames may result in low efficiency in the inference of video captioning. Addressing this, we study video captioning from a different perspective in compressed domain, which brings multi-fold advantages over the existing pipeline: 1) Compared to raw images from the decoded video, the compressed video, consisting of I-frames, motion vectors and residuals, is highly distinguishable, which allows us to leverage the entire video for learning without manual sampling through a specialized model design; 2) The captioning model is more efficient in inference as smaller and less redundant information is processed. We propose a simple yet e
    
[^74]: 利用有限预算激励大规模未知工作者的众感知：从离线和在线视角考虑

    Incentivizing Massive Unknown Workers for Budget-Limited Crowdsensing: From Off-Line and On-Line Perspectives. (arXiv:2309.12113v1 [cs.AI])

    [http://arxiv.org/abs/2309.12113](http://arxiv.org/abs/2309.12113)

    本文提出了一种离线的基于上下文感知的CMAB激励（CACI）机制，通过对一个精细划分的上下文空间中的探索-开发权衡，有效地激励具有非常有限预算的大规模未知工作者。

    

    尽管现有的提案通过在探索和开发之间进行权衡来解决工作者的不确定性，标准的组合多臂赌博机（CMAB）框架可以解决工作者的不确定性，但当工作者数量巨大而预算有限时，可能无法对个体工作者进行权衡。此外，标准的CMAB通常假设工作者始终留在系统中，而工作者可能在时间上加入或离开系统，因此在工作者离开后，我们学到的对于单个工作者的知识无法应用。为了解决上述问题，本文首先提出了一种离线的基于上下文感知的CMAB激励（CACI）机制。我们创新地利用了一个精心划分的上下文空间中的探索-开发权衡，而不是针对个体工作者，以有效地激励具有非常有限预算的大规模未知工作者。

    Although the uncertainties of the workers can be addressed by the standard Combinatorial Multi-Armed Bandit (CMAB) framework in existing proposals through a trade-off between exploration and exploitation, we may not have sufficient budget to enable the trade-off among the individual workers, especially when the number of the workers is huge while the budget is limited. Moreover, the standard CMAB usually assumes the workers always stay in the system, whereas the workers may join in or depart from the system over time, such that what we have learnt for an individual worker cannot be applied after the worker leaves. To address the above challenging issues, in this paper, we first propose an off-line Context-Aware CMAB-based Incentive (CACI) mechanism. We innovate in leveraging the exploration-exploitation trade-off in a elaborately partitioned context space instead of the individual workers, to effectively incentivize the massive unknown workers with very limited budget. We also extend t
    
[^75]: 研究自我评估测试在大型语言模型的人格测量中的适用性

    Investigating the Applicability of Self-Assessment Tests for Personality Measurement of Large Language Models. (arXiv:2309.08163v1 [cs.CL])

    [http://arxiv.org/abs/2309.08163](http://arxiv.org/abs/2309.08163)

    研究发现，使用自我评估测试对大型语言模型的人格进行测量时，不同的提示会导致非常不同的人格得分，因此缺乏客观标准来判断哪个提示更正确。

    

    随着大型语言模型的能力不断发展，各种最近的研究试图使用用于研究人类行为的心理工具来量化它们的行为。其中一个例子是使用人格自我评估测试来衡量大型语言模型的“人格”。在本文中，我们选择了三个关于使用人格自我评估测试来量化大型语言模型的人格的研究。我们使用这三个不同论文中使用的提示来评估同一大型语言模型的人格。我们发现，这三个提示导致了非常不同的人格得分。这一简单测试揭示了大型语言模型中的人格自我评估得分取决于提示者的主观选择。由于我们不知道大型语言模型的人格得分的真实值，因为此类问题没有正确答案，所以无法声明某个提示比其他提示更正确或更不正确。然后，我们引入了人格选项顺序对称性的属性。

    As large language models (LLM) evolve in their capabilities, various recent studies have tried to quantify their behavior using psychological tools created to study human behavior. One such example is the measurement of "personality" of LLMs using personality self-assessment tests. In this paper, we take three such studies on personality measurement of LLMs that use personality self-assessment tests created to study human behavior. We use the prompts used in these three different papers to measure the personality of the same LLM. We find that all three prompts lead very different personality scores. This simple test reveals that personality self-assessment scores in LLMs depend on the subjective choice of the prompter. Since we don't know the ground truth value of personality scores for LLMs as there is no correct answer to such questions, there's no way of claiming if one prompt is more or less correct than the other. We then introduce the property of option order symmetry for persona
    
[^76]: 最小覆盖集合用于训练鲁棒自组织团队协作代理

    Minimum Coverage Sets for Training Robust Ad Hoc Teamwork Agents. (arXiv:2308.09595v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2308.09595](http://arxiv.org/abs/2308.09595)

    这篇论文提出了最小覆盖集合（MCS）概念，通过训练代理模拟MCS中的最佳策略，提高了自组织团队协作代理的鲁棒性。

    

    由于合作伙伴可能采用各种不同的合作约定，与未知的代理和人类合作具有重大挑战。现有的自组织团队协作（AHT）方法通过训练代理与通过最大化特定多样性度量获得的多样的队友策略群进行合作，从而解决了这一挑战。然而，先前基于启发式的多样性度量并不总是在所有合作问题中最大化代理的鲁棒性。在这项工作中，我们首先提出最大化AHT代理的鲁棒性需要它模拟最小覆盖集（MCS）中的策略，即对环境中的任何合作伙伴策略的最优响应策略集合。然后，我们引入了L-BRDiv算法，该算法生成一组队友策略，用于AHT训练时鼓励代理模拟MCS中的策略。L-BRDiv通过解决约束优化问题来共同训练AHT训练的队友策略，以及近似AHT代理策略。

    Robustly cooperating with unseen agents and human partners presents significant challenges due to the diverse cooperative conventions these partners may adopt. Existing Ad Hoc Teamwork (AHT) methods address this challenge by training an agent with a population of diverse teammate policies obtained through maximizing specific diversity metrics. However, prior heuristic-based diversity metrics do not always maximize the agent's robustness in all cooperative problems. In this work, we first propose that maximizing an AHT agent's robustness requires it to emulate policies in the minimum coverage set (MCS), the set of best-response policies to any partner policies in the environment. We then introduce the L-BRDiv algorithm that generates a set of teammate policies that, when used for AHT training, encourage agents to emulate policies from the MCS. L-BRDiv works by solving a constrained optimization problem to jointly train teammate policies for AHT training and approximating AHT agent polic
    
[^77]: TIAM -- 一种评估文本到图像生成中对齐性的度量方法

    TIAM -- A Metric for Evaluating Alignment in Text-to-Image Generation. (arXiv:2307.05134v1 [cs.CV])

    [http://arxiv.org/abs/2307.05134](http://arxiv.org/abs/2307.05134)

    本文提出了一种评估文本到图像生成中对齐性的新度量方法TIAM，该方法基于提示模板，可以更好地描述生成图像与提示中内容的对齐程度，包括对象类型、数量和颜色。研究结果表明，图像质量可以有很大的变化。

    

    合成图像生成的进展使得评估其质量变得至关重要。尽管已经提出了几种用于评估图像渲染的度量方法，但对于基于提示生成图像的文本到图像（T2I）模型而言，考虑到生成图像与提示中重要内容之间的相似程度等额外因素至关重要。此外，虽然生成的图像通常是从随机起始点开始的，但通常不考虑这一影响。本文提出了一种基于提示模板的新度量方法，用于研究提示中指定的内容与生成的图像之间的对齐性。它允许我们更好地描述对齐性，包括指定对象的类型、数量和颜色。我们对几个最近的T2I模型进行了研究，并获得了一个有趣的额外结果，即图像质量可以大幅度变化。

    The progress in the generation of synthetic images has made it crucial to assess their quality. While several metrics have been proposed to assess the rendering of images, it is crucial for Text-to-Image (T2I) models, which generate images based on a prompt, to consider additional aspects such as to which extent the generated image matches the important content of the prompt. Moreover, although the generated images usually result from a random starting point, the influence of this one is generally not considered. In this article, we propose a new metric based on prompt templates to study the alignment between the content specified in the prompt and the corresponding generated images. It allows us to better characterize the alignment in terms of the type of the specified objects, their number, and their color. We conducted a study on several recent T2I models about various aspects. An additional interesting result we obtained with our approach is that image quality can vary drastically 
    
[^78]: LMBot: 将图形知识融入语言模型以进行无图形部署的推特机器人检测

    LMBot: Distilling Graph Knowledge into Language Model for Graph-less Deployment in Twitter Bot Detection. (arXiv:2306.17408v1 [cs.AI])

    [http://arxiv.org/abs/2306.17408](http://arxiv.org/abs/2306.17408)

    LMBot是一种新颖的推特机器人检测框架，将图神经网络的知识融入到语言模型中，实现了无图形部署，以解决数据依赖性的挑战。

    

    随着恶意行为者使用越来越先进和广泛的机器人来传播错误信息和操纵舆论，推特机器人的检测已成为一项至关重要的任务。尽管基于图形的推特机器人检测方法取得了最先进的性能，但我们发现它们的推理依赖于距离目标用户多跳的邻居用户，并且获取邻居用户是耗时的，并可能引入偏差。与此同时，我们发现在推特机器人检测上微调后，预训练的语言模型在竞争性性能方面取得了良好的表现，并且在部署过程中不需要图形结构。受到这一发现的启发，我们提出了一种新颖的机器人检测框架LMBot，它将图神经网络(GNNs)的知识融入语言模型(LMs)，以在推特机器人检测中进行无图形部署，以应对数据依赖性的挑战。此外，LMBot对基于图形和不使用图形的数据集兼容。具体而言，我们首先将每个用户表示为一段文本

    As malicious actors employ increasingly advanced and widespread bots to disseminate misinformation and manipulate public opinion, the detection of Twitter bots has become a crucial task. Though graph-based Twitter bot detection methods achieve state-of-the-art performance, we find that their inference depends on the neighbor users multi-hop away from the targets, and fetching neighbors is time-consuming and may introduce bias. At the same time, we find that after finetuning on Twitter bot detection, pretrained language models achieve competitive performance and do not require a graph structure during deployment. Inspired by this finding, we propose a novel bot detection framework LMBot that distills the knowledge of graph neural networks (GNNs) into language models (LMs) for graph-less deployment in Twitter bot detection to combat the challenge of data dependency. Moreover, LMBot is compatible with graph-based and graph-less datasets. Specifically, we first represent each user as a tex
    
[^79]: 计算辅助公共卫生数据流的质量控制

    Computationally Assisted Quality Control for Public Health Data Streams. (arXiv:2306.16914v1 [cs.AI])

    [http://arxiv.org/abs/2306.16914](http://arxiv.org/abs/2306.16914)

    开发了一个实用的异常点检测框架FlaSH，用于公共卫生数据流。该框架考虑了数据量和统计特性，并在实验中展现了良好的性能。

    

    公共卫生数据流中的异常情况（如COVID-19病例）阻碍了公共卫生利益相关者基于数据的决策。实时生成的计算机列表可以帮助专家评审员识别成千上万个每日更新的公共卫生数据流中最重要的异常数据点。然而，现有的异常点检测框架在该任务上表现不佳，因为它们没有考虑数据量或公共卫生数据流的统计特性。因此，我们开发了FlaSH（旗标公共卫生数据流），它是一个实用的公共卫生数据用户用的异常点检测框架，使用简单可扩展的模型来明确捕捉这些统计特性。在一个实验中，人类专家评估了FlaSH和现有方法（包括深度学习方法），FlaSH适应了该任务的数据量，与其他方法在平均准确度上达到或超过，并且可以识别出异常数据点。

    Irregularities in public health data streams (like COVID-19 Cases) hamper data-driven decision-making for public health stakeholders. A real-time, computer-generated list of the most important, outlying data points from thousands of daily-updated public health data streams could assist an expert reviewer in identifying these irregularities. However, existing outlier detection frameworks perform poorly on this task because they do not account for the data volume or for the statistical properties of public health streams. Accordingly, we developed FlaSH (Flagging Streams in public Health), a practical outlier detection framework for public health data users that uses simple, scalable models to capture these statistical properties explicitly. In an experiment where human experts evaluate FlaSH and existing methods (including deep learning approaches), FlaSH scales to the data volume of this task, matches or exceeds these other methods in mean accuracy, and identifies the outlier points th
    
[^80]: LaDe: 产业界第一个全面的末端配送数据集

    LaDe: The First Comprehensive Last-mile Delivery Dataset from Industry. (arXiv:2306.10675v2 [cs.DB] UPDATED)

    [http://arxiv.org/abs/2306.10675](http://arxiv.org/abs/2306.10675)

    LaDe是第一个公开可用的末端配送数据集，包含了数百万个来自产业界的包裹，具有大规模、全面的信息和多样性的特点。

    

    现实世界中的末端配送数据集对于物流、供应链管理和时空数据挖掘的研究至关重要。尽管迄今已经开发了大量算法，但尚无公认的、公开可用的末端配送数据集来支持这个领域的研究。在本文中，我们介绍了LaDe，这是第一个公开可用的末端配送数据集，包含了数百万个来自产业界的包裹。LaDe具有三个独特的特点：(1)大规模。它涉及到6个月的真实运营中的10,677k个包裹和21k个快递员。(2)全面的信息。它提供原始包裹信息，如位置和时间要求，以及任务事件信息，记录了快递员何时何地进行任务接受和完成。(3)多样性。该数据集包括来自各种场景的数据，包括包裹的取送和来自多个城市的数据，每个城市都有其独特的时空属性。

    Real-world last-mile delivery datasets are crucial for research in logistics, supply chain management, and spatio-temporal data mining. Despite a plethora of algorithms developed to date, no widely accepted, publicly available last-mile delivery dataset exists to support research in this field. In this paper, we introduce \texttt{LaDe}, the first publicly available last-mile delivery dataset with millions of packages from the industry. LaDe has three unique characteristics: (1) Large-scale. It involves 10,677k packages of 21k couriers over 6 months of real-world operation. (2) Comprehensive information. It offers original package information, such as its location and time requirements, as well as task-event information, which records when and where the courier is while events such as task-accept and task-finish events happen. (3) Diversity. The dataset includes data from various scenarios, including package pick-up and delivery, and from multiple cities, each with its unique spatio-tem
    
[^81]: 基于双曲图扩散模型的分子生成

    Hyperbolic Graph Diffusion Model for Molecule Generation. (arXiv:2306.07618v1 [cs.LG])

    [http://arxiv.org/abs/2306.07618](http://arxiv.org/abs/2306.07618)

    本文提出了基于双曲图扩散模型的分子生成方法，可以更全面地捕捉分子的内部非欧几里德结构，实现数据生成，并提取复杂几何特征的能力。

    

    最近，扩散模型在数据生成方面取得了显著的成果，例如生成高质量的图像。然而，化学分子通常具有复杂的非欧几里德空间结构，其行为动态变化且难以预测。大多数现有的扩散模型高度依赖于计算欧几里德空间中的概率分布，即高斯分布，不能捕捉分子的内部非欧几里德结构，特别是分子所表示的隐式流形表面的分层结构。观察到，双曲嵌入空间中的复杂分层结构变得更加明显且更容易被捕捉。为了充分利用扩散模型的数据生成能力和提取复杂几何特征的双曲嵌入的强大能力，我们提出将扩散模型扩展到双曲流形上进行分子生成，即基于双曲图扩散模型的分子生成。

    Recently, diffusion models have achieved remarkable performance in data generation, e.g., generating high-quality images. Nevertheless, chemistry molecules often have complex non-Euclidean spatial structures, with the behavior changing dynamically and unpredictably. Most existing diffusion models highly rely on computing the probability distribution, i.e., Gaussian distribution, in Euclidean space, which cannot capture internal non-Euclidean structures of molecules, especially the hierarchical structures of the implicit manifold surface represented by molecules. It has been observed that the complex hierarchical structures in hyperbolic embedding space become more prominent and easier to be captured. In order to leverage both the data generation power of diffusion models and the strong capability to extract complex geometric features of hyperbolic embedding, we propose to extend the diffusion model to hyperbolic manifolds for molecule generation, namely, Hyperbolic Graph Diffusion Mode
    
[^82]: EmotionGesture：音频驱动的多样化情感共语3D手势生成

    EmotionGesture: Audio-Driven Diverse Emotional Co-Speech 3D Gesture Generation. (arXiv:2305.18891v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2305.18891](http://arxiv.org/abs/2305.18891)

    本文提出了EmotionGesture框架，可以从音频中生成生动多样的情感共语3D手势。通过情感-节奏挖掘模块提取情感和音频节奏特征，并建模它们之间的关联；然后使用空间-时间提示器从给定的初始姿势生成未来的手势，实现空间-时间一致的姿势提示。

    

    生成生动多样的3D共语手势对于给虚拟角色注入生气至关重要。尽管大多数现有方法可以直接从音频中生成手势，但它们通常忽视情感是真实共语手势生成的关键因素之一。在这项工作中，我们提出了EmotionGesture，一种从音频中合成生动多样的情感共语3D手势的新框架。考虑到情感常常与语音节奏交织在一起，我们首先开发了一个情感-节奏挖掘模块（EBM），通过基于转录的视觉-节奏对齐提取情感和音频节奏特征，并建模它们之间的关联。然后，我们提出了一个基于初始姿势的空间-时间提示器（STP），从给定的初始姿势生成未来的手势。STP有效地建模了初始姿势和未来手势之间的空间-时间关系，从而产生空间-时间一致的姿势提示。

    Generating vivid and diverse 3D co-speech gestures is crucial for various applications in animating virtual avatars. While most existing methods can generate gestures from audio directly, they usually overlook that emotion is one of the key factors of authentic co-speech gesture generation. In this work, we propose EmotionGesture, a novel framework for synthesizing vivid and diverse emotional co-speech 3D gestures from audio. Considering emotion is often entangled with the rhythmic beat in speech audio, we first develop an Emotion-Beat Mining module (EBM) to extract the emotion and audio beat features as well as model their correlation via a transcript-based visual-rhythm alignment. Then, we propose an initial pose based Spatial-Temporal Prompter (STP) to generate future gestures from the given initial poses. STP effectively models the spatial-temporal correlations between the initial poses and the future gestures, thus producing the spatial-temporal coherent pose prompt. Once we obtai
    
[^83]: Logit-Q动力学对于随机团队中的高效学习

    Logit-Q Dynamics for Efficient Learning in Stochastic Teams. (arXiv:2302.09806v2 [cs.GT] UPDATED)

    [http://arxiv.org/abs/2302.09806](http://arxiv.org/abs/2302.09806)

    本文提出了两种Logit-Q学习动力学，通过将经典和独立的对数线性学习更新与在政策上的值迭代更新相结合，实现了在随机博弈中的高效学习。通过对比和量化分析，证明了该动力学在随机团队中可以达到（接近）高效均衡。

    

    我们提出了两种Logit-Q学习动力学，将经典和独立的对数线性学习更新与一个在政策上的值迭代更新相结合，以实现在随机博弈中的高效学习。我们证明所提出的Logit-Q动力学在随机团队中达到（接近）高效均衡。我们量化了近似误差的上界。我们还展示了Logit-Q动力学对纯定态策略的合理性，并证明了动力学在奖励函数导致潜在博弈的随机博弈中的收敛性，然而只有一个智能体控制状态转换超出随机团队。关键思路是将动力学与一个虚构的场景近似，其中Q函数估计仅在有限长度的纪元中是定态的，仅用于分析。然后，我们将主要场景和虚构场景中的动力学耦合起来，以展示这两个场景由于逐步减小的步长而越来越相似。

    We present two logit-Q learning dynamics combining the classical and independent log-linear learning updates with an on-policy value iteration update for efficient learning in stochastic games. We show that the logit-Q dynamics presented reach (near) efficient equilibrium in stochastic teams. We quantify a bound on the approximation error. We also show the rationality of the logit-Q dynamics against agents following pure stationary strategies and the convergence of the dynamics in stochastic games where the reward functions induce potential games, yet only a single agent controls the state transitions beyond stochastic teams. The key idea is to approximate the dynamics with a fictional scenario where the Q-function estimates are stationary over finite-length epochs only for analysis. We then couple the dynamics in the main and fictional scenarios to show that these two scenarios become more and more similar across epochs due to the vanishing step size.
    
[^84]: 基于状态的重要性抽样方法实现低方差的行为策略离线评估

    Low Variance Off-policy Evaluation with State-based Importance Sampling. (arXiv:2212.03932v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.03932](http://arxiv.org/abs/2212.03932)

    本文提出了一种基于状态的重要性抽样（SIS）方法，通过检测“忽略状态”的子轨迹来实现低方差的离线评估。

    

    在强化学习的离线评估中，需要评估目标策略的性能，而这需要使用由行为策略采集的样本数据。传统的重要性抽样方法由于计算动作概率比值的乘积而导致方差增加，从而在涉及长期规划的任务中出现估计不准确的问题。本文提出了一种基于状态的重要性抽样（SIS）方法，通过检测“忽略状态”的子轨迹来实现低方差的离线评估。

    In off-policy reinforcement learning, a behaviour policy performs exploratory interactions with the environment to obtain state-action-reward samples which are then used to learn a target policy that optimises the expected return. This leads to a problem of off-policy evaluation, where one needs to evaluate the target policy from samples collected by the often unrelated behaviour policy. Importance sampling is a traditional statistical technique that is often applied to off-policy evaluation. While importance sampling estimators are unbiased, their variance increases exponentially with the horizon of the decision process due to computing the importance weight as a product of action probability ratios, yielding estimates with low accuracy for domains involving long-term planning. This paper proposes state-based importance sampling (SIS), which drops the action probability ratios of sub-trajectories with "negligible states" -- roughly speaking, those for which the chosen actions have no 
    
[^85]: 解开 (不)可控特征

    Disentangled (Un)Controllable Features. (arXiv:2211.00086v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.00086](http://arxiv.org/abs/2211.00086)

    该论文提出了一种新方法，可以将潜在特征分解为可控和不可控的部分，并证明了这种分解表示在不同环境中易于解释和使用可解释的规划算法。

    

    在具有高维状态的MDP背景下，下游任务通常在原始输入空间的压缩、低维表示上运行。因此，为了获得有用的表示，我们使用了各种学习目标。然而，这些表示通常缺乏对不同特征的可解释性。我们提出了一种新方法，能够将潜在特征分解为可控和不可控的部分。我们证明了得到的分区表示在三种类型的环境中是易于解释的，并且在分离的可控潜在分区中，能够在一组程序生成的迷宫环境中使用可解释的规划算法。

    In the context of MDPs with high-dimensional states, downstream tasks are predominantly applied on a compressed, low-dimensional representation of the original input space. A variety of learning objectives have therefore been used to attain useful representations. However, these representations usually lack interpretability of the different features. We present a novel approach that is able to disentangle latent features into a controllable and an uncontrollable partition. We illustrate that the resulting partitioned representations are easily interpretable on three types of environments and show that, in a distribution of procedurally generated maze environments, it is feasible to interpretably employ a planning algorithm in the isolated controllable latent partition.
    
[^86]: TrAISformer——用于AIS轨迹预测的生成变压器

    TrAISformer-A generative transformer for AIS trajectory prediction. (arXiv:2109.03958v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2109.03958](http://arxiv.org/abs/2109.03958)

    本文提出了一种新颖的离散、高维表示的AIS数据和一种新的损失函数，用于显式考虑异质性和多样性，并通过修改变压器网络来预测船舶位置。实验证明，该模型明显优于现有的最新方法。

    

    预测船舶在未来特定时间点的位置是许多海事应用的基本方面。虽然自动识别系统（AIS）提供了丰富的信息来实现这一任务，但使用AIS数据来预测船舶轨迹仍然具有极大的挑战性，即使对于现代机器学习/深度学习技术也是如此，因为运动数据本质上具有复杂性和多样性。本文通过引入一种新颖的AIS数据离散化高维表示和一种新的损失函数来显式考虑异质性和多样性来解决这些挑战。所提出的模型——TrAISformer——是一个修改后的变压器网络，在所提出的丰富空间中提取AIS轨迹的长期相关性，以预测几个小时后船舶的位置。我们在公开可用的真实AIS数据上报告实验结果。TrAISformer明显优于现有的最新方法。

    The prediction of vessel positions at a specified point in the future is a fundamental aspect of many maritime applications. While Automatic Identification System (AIS) provides a rich source of information to enable this task, vessel trajectory forecasting using AIS data remains formidably challenging, even for modern machine learning/deep learning, because of the complexity and multimodality inherent in motion data. In this paper, we address these challenges by introducing a novel discrete, high-dimensional representation of AIS data and a new loss function to explicitly account for heterogeneity and multimodality. The proposed model -- referred to as TrAISformer -- is a modified transformer network that extracts long-term correlations of AIS trajectories in the proposed enriched space to forecast the positions of vessels several hours into the future. We report experimental results on publicly available, real AIS data. TrAISformer significantly outperforms state-of-the-art methods a
    

