# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [SHARCS: Shared Concept Space for Explainable Multimodal Learning.](http://arxiv.org/abs/2307.00316) | SHARCS是一种解释性多模态学习方法，它通过学习和映射可解释的概念到一个统一的概念空间，实现了解释性的任务预测和改进性能。 |
| [^2] | [Gradients Look Alike: Sensitivity is Often Overestimated in DP-SGD.](http://arxiv.org/abs/2307.00310) | 本文开发了一种新的DP-SGD分析方法，可以在训练过程中对许多数据点的隐私泄漏进行更准确的评估。 |
| [^3] | [SyMFM6D: Symmetry-aware Multi-directional Fusion for Multi-View 6D Object Pose Estimation.](http://arxiv.org/abs/2307.00306) | 该论文介绍了一种叫做SyMFM6D的面向对称多视角融合的6D物体姿态估计方法。该方法通过多方向融合网络有效地融合多个视角的RGB-D帧，并通过预测关键点和实例语义分割来计算6D姿态。通过新的训练过程和目标函数，该方法能够解决对称物体的歧义问题，并在单视角和多视角姿态估计方面取得了显著的性能提升。 |
| [^4] | [SysNoise: Exploring and Benchmarking Training-Deployment System Inconsistency.](http://arxiv.org/abs/2307.00280) | SysNoise是一种在深度学习的训练-部署周期中经常发生的噪音，该论文通过实验证明了SysNoise对不同任务的模型稳健性会带来一定影响，并提出了常见的缓解方法。 |
| [^5] | [Hierarchical Pretraining for Biomedical Term Embeddings.](http://arxiv.org/abs/2307.00266) | 分层预训练用于生物医学术语嵌入，通过将临床术语表示为语义嵌入并利用低维嵌入作为特征向量，可以提高临床记录的自然语言处理（NLP）效果。 |
| [^6] | [InstructEval: Systematic Evaluation of Instruction Selection Methods.](http://arxiv.org/abs/2307.00259) | InstructEval开发了一个评估套件，用于对指令选择方法进行全面评估。通过使用策划的手动编写的指令，可以显著提高性能。 |
| [^7] | [Efficient Subclass Segmentation in Medical Images.](http://arxiv.org/abs/2307.00257) | 这篇论文提出了一种在医学图像中高效学习细粒度子类分割的方法，通过利用层次结构设计网络架构，并引入任务驱动的数据生成方法来增强分割的置信度。 |
| [^8] | [An ML approach to resolution of singularities.](http://arxiv.org/abs/2307.00252) | 该论文介绍了一种新的机器学习方法，使用强化学习代理来解决奇点问题中的最优解。实验证明在多项式相加的总数方面，该方法超过了当前最先进的选择启发式算法，展示了近期研究的潜力。 |
| [^9] | [THUIR2 at NTCIR-16 Session Search (SS) Task.](http://arxiv.org/abs/2307.00250) | 本文介绍了THUIR2团队在NTCIR-16 Session搜索任务中的表现，他们在FOSS和POSS子任务中使用了学习排序和预训练语言模型，并取得了最佳性能。 |
| [^10] | [VesselMorph: Domain-Generalized Retinal Vessel Segmentation via Shape-Aware Representation.](http://arxiv.org/abs/2307.00240) | VesselMorph使用一个基于形状感知的表征方法，通过合成血管的形态学特征来推广视网膜血管分割任务，以提高深度模型的通用性。 |
| [^11] | [Forward-Forward Algorithm for Hyperspectral Image Classification: A Preliminary Study.](http://arxiv.org/abs/2307.00231) | 本研究调查了在高光谱图像分类中应用前向前向算法（FFA），该算法通过计算局部优势函数来减轻对计算资源和架构扩展的依赖。 |
| [^12] | [Image Matters: A New Dataset and Empirical Study for Multimodal Hyperbole Detection.](http://arxiv.org/abs/2307.00209) | 本研究提出了一个新的多模态夸张检测数据集，并使用文本和图像作为两种模态进行研究。同时，评估了不同预训练的多模态编码器在此任务中的表现。该研究探索了夸张检测的跨领域性能。 |
| [^13] | [General Part Assembly Planning.](http://arxiv.org/abs/2307.00206) | 本论文研究了通用零件组装的问题，提出了一种基于Transformer的模型架构GPAT，能够准确预测零件的姿态并具有泛化能力。 |
| [^14] | [An Interpretable Constructive Algorithm for Incremental Random Weight Neural Networks and Its Application.](http://arxiv.org/abs/2307.00185) | 本文提出了一种可解释的增量随机权重神经网络的构造算法，通过几何信息约束和节点池策略解决了难以解释隐藏参数与残差误差之间关系的问题。这种算法在大规模数据建模任务中表现出了良好的性能。 |
| [^15] | [Personality Traits in Large Language Models.](http://arxiv.org/abs/2307.00184) | 该研究介绍了一种综合方法，用于验证大型语言模型（LLMs）生成的文本中展示的人格特质。研究发现，部分LLMs在特定提示配置下模拟的人格可靠且有效，特别是对于更大和经过指导微调的模型。此外，LLMs的输出中的人格特质可以根据需要进行塑造。 |
| [^16] | [The Integer Linear Programming Inference Cookbook.](http://arxiv.org/abs/2307.00171) | 本论文介绍了一个整数线性规划推理手册，用于将推理问题转化为整数线性规划实例。通过一系列技巧的演示，帮助读者理解如何应用这些方法。论文最后提供了两个示例以说明这些技巧的使用。 |
| [^17] | [VoxWatch: An open-set speaker recognition benchmark on VoxCeleb.](http://arxiv.org/abs/2307.00169) | 本研究提出了一个针对VoxCeleb的开放式演讲者识别基准，并探讨了处理观察名单大小对检测性能影响的技术。 |
| [^18] | [FFPDG: Fast, Fair and Private Data Generation.](http://arxiv.org/abs/2307.00161) | 提出了一种快速、公平、灵活和私密的数据生成方法，可以在真实应用场景下表现良好。 |
| [^19] | [Stitched ViTs are Flexible Vision Backbones.](http://arxiv.org/abs/2307.00154) | 本研究通过拼接预训练模型族群，提出了SN-Netv2，它是一个灵活的视觉骨干网络框架，可以在运行时实现多样性的性能和效率权衡。 |
| [^20] | [Large Language Models (GPT) for automating feedback on programming assignments.](http://arxiv.org/abs/2307.00150) | 本研究使用OpenAI的GPT-3.5模型自动生成编程作业的个性化提示，该提示被学生们评价为有用。实验组在启用GPT提示的任务中表现出更好的提交成功率，同时减少对平台常规反馈的依赖。对于无法使用GPT提示的任务，实验组学生解决作业所需的时间也较少。 |
| [^21] | [A Personalized Household Assistive Robot that Learns and Creates New Breakfast Options through Human-Robot Interaction.](http://arxiv.org/abs/2307.00114) | 本文提出了一个认知架构，用于个性化家庭辅助机器人通过人机交互学习并创造新的早餐选择。 |
| [^22] | [Performance of ChatGPT on USMLE: Unlocking the Potential of Large Language Models for AI-Assisted Medical Education.](http://arxiv.org/abs/2307.00112) | 这项研究评估了ChatGPT在回答复杂医学问题上的可靠性，发现其生成的答案更加注重上下文并具有较高的可靠性。 |
| [^23] | [Ticket-BERT: Labeling Incident Management Tickets with Language Models.](http://arxiv.org/abs/2307.00108) | Ticket-BERT是一个使用语言模型为事件管理票据进行标注的方法，在解决复杂的票据数据和时间敏感性问题方面具有优势。 |
| [^24] | [Obscured Wildfire Flame Detection By Temporal Analysis of Smoke Patterns Captured by Unmanned Aerial Systems.](http://arxiv.org/abs/2307.00104) | 本论文通过对视频序列中烟雾模式的时间分析，提出了一种用于实时检测被遮挡的野火火焰的方法，通过预测火灾位置来帮助无人机对抗森林火灾。这种方法具有独特的检测被遮挡的火灾的能力。 |
| [^25] | [Queer People are People First: Deconstructing Sexual Identity Stereotypes in Large Language Models.](http://arxiv.org/abs/2307.00101) | 本文通过比较研究了大型语言模型（LLMs）在生成描述不同性别认同的人的文本时产生的偏见问题，发现存在对同志人群的偏见。研究者提出了一种基于SHAP分析的思维链触发的事后方法，可以增加句子的regard，为去除LLMs输出偏见提供了一个有希望的途径。 |
| [^26] | [Qualitative Prediction of Multi-Agent Spatial Interactions.](http://arxiv.org/abs/2307.00065) | 本文提出了三种新方法，用于预测密集场景中的多智能体交互，其中包括使用直观的定性表示。这些方法利用了输入和时间关注机制，并结合了定性轨迹计算和深度神经网络，采用符号驱动的神经结构进行预测，实现了较好的效果。 |
| [^27] | [DisCo: Disentangled Control for Referring Human Dance Generation in Real World.](http://arxiv.org/abs/2307.00040) | 这篇论文提出了一个新的问题设置：引用人类舞蹈生成。在现实世界的舞蹈场景中，通过解耦控制来解决舞蹈合成中的挑战，包括忠实性、泛化能力和组合性。 |
| [^28] | [Towards Brain Inspired Design for Addressing the Shortcomings of ANNs.](http://arxiv.org/abs/2307.00039) | 本研究通过对比人工神经网络和小脑中基于错误的神经元组织方式，发现在人工神经网络中引入个性化错误视图的神经元群体可以提高学习效率、减少不平衡数据和捷径策略的影响，从而提高泛化能力。 |
| [^29] | [Uncertainty Informed Optimal Resource Allocation with Gaussian Process based Bayesian Inference.](http://arxiv.org/abs/2307.00032) | 本研究提出了一种基于高斯过程贝叶斯推理的数据驱动方法，用于将医疗资源（疫苗）不确定性导向地分配给异质人群以管理流行病传播。研究解决了参数估计和整合、非线性ODE约束和参数不确定性等问题。 |
| [^30] | [Seeing in Words: Learning to Classify through Language Bottlenecks.](http://arxiv.org/abs/2307.00028) | 本文提出了一种通过语言瓶颈学习分类的方法，利用文本表示特征的视觉模型能够有效分类ImageNet图像，可以增加神经网络的可解释性。 |
| [^31] | [CASEIN: Cascading Explicit and Implicit Control for Fine-grained Emotion Intensity Regulation.](http://arxiv.org/abs/2307.00020) | CASEIN是一个层层级联的显式和隐式控制框架，通过准确解离参考语音中的情感流形，学习低语义级别的隐式表示。在实验中，CASEIN在可控性和自然度方面超过了现有方法，首次实现了对多种情感强度的细粒度控制。 |
| [^32] | [Inertial Navigation Meets Deep Learning: A Survey of Current Trends and Future Directions.](http://arxiv.org/abs/2307.00014) | 本文综述了惯性导航领域中当前的深度学习方法，包括对不同车辆操作领域的研究、滤波参数学习的改进以及惯性传感器的校准和去噪方法。翻译过的论文标题: 惯性导航与深度学习：当前趋势与未来方向的综述 |
| [^33] | [Black-Box Prediction of Flaky Test Fix Categories Using Language Models.](http://arxiv.org/abs/2307.00012) | 本文提出了一个使用语言模型的框架，可以自动生成易出错测试的标记数据集，并通过分析测试代码来预测测试的修复类别。实验结果表明UniXcoder优于CodeBERT。 |
| [^34] | [Investigating Masking-based Data Generation in Language Models.](http://arxiv.org/abs/2307.00008) | 本研究探索了基于掩码的数据生成在语言模型中的应用，结果表明该方法可以提高模型性能。 |
| [^35] | [PV Fleet Modeling via Smooth Periodic Gaussian Copula.](http://arxiv.org/abs/2307.00004) | 本文提出了一种通过平滑周期高斯Copula模型联合建模光伏系统群发电的方法，该方法可以捕捉数据的昼夜变化、系统间的依赖关系和随时间的依赖关系。通过该模型可以进行合成数据生成、缺失数据填补、异常检测和预测。 |
| [^36] | [Sphere2Vec: A General-Purpose Location Representation Learning over a Spherical Surface for Large-Scale Geospatial Predictions.](http://arxiv.org/abs/2306.17624) | Sphere2Vec是一种多尺度位置编码器，用于在球面上编码点坐标时保持球面距离，解决了大规模真实世界GPS坐标数据集中的距离度量问题。 |
| [^37] | [LMBot: Distilling Graph Knowledge into Language Model for Graph-less Deployment in Twitter Bot Detection.](http://arxiv.org/abs/2306.17408) | LMBot是一种新颖的推特机器人检测框架，将图神经网络的知识融入到语言模型中，实现了无图形部署，以解决数据依赖性的挑战。 |
| [^38] | [Presenting an approach based on weighted CapsuleNet networks for Arabic and Persian multi-domain sentiment analysis.](http://arxiv.org/abs/2306.17068) | 本文提出了一种基于加权胶囊网络的阿拉伯语和波斯语多领域情感分析方法，通过训练单独的胶囊网络并使用加权度量来实现情感分类，具有较好的准确性和适应性。 |
| [^39] | [Improving Online Continual Learning Performance and Stability with Temporal Ensembles.](http://arxiv.org/abs/2306.16817) | 该研究通过模型集成方法改进了在线连续学习的性能和稳定性，通过综合利用来自不同训练任务的模型，显著提高了在线连续学习的表现。 |
| [^40] | [GraMMaR: Ground-aware Motion Model for 3D Human Motion Reconstruction.](http://arxiv.org/abs/2306.16736) | 提出了一种用于3D人体运动重建的地面感知运动模型（GraMMaR），通过学习姿势和关节与地面之间的互动的过渡分布，明确促进运动和与地面距离变化之间的一致性。 |
| [^41] | [NNQS-Transformer: an Efficient and Scalable Neural Network Quantum States Approach for Ab initio Quantum Chemistry.](http://arxiv.org/abs/2306.16705) | NNQS-Transformer是一种高效可扩展的神经网络量子态方法，用于从头计算量子化学。其主要创新包括基于Transformer的量子波函数安萨茨、数据中心并行化方案、并行批量采样策略和并行局域能量评估方案。研究结果显示了与最先进方法相比的优越精度和对于大分子系统的强可扩展性和弱可扩展性。 |
| [^42] | [Separable Physics-Informed Neural Networks.](http://arxiv.org/abs/2306.15969) | 这项研究提出了一种可分离的物理信息神经网络（SPINN），通过逐个处理轴来显著减少了多维 PDE 中的网络传播数量，并使用正向模式自动微分降低了计算成本，使得可以在单个普通 GPU 上使用大量的配点。 |
| [^43] | [SparseOptimizer: Sparsify Language Models through Moreau-Yosida Regularization and Accelerate through Compiler Co-design.](http://arxiv.org/abs/2306.15656) | SparseOptimizer是一种深度学习优化器，通过Moreau-Yosida正则化在大型语言模型中引入稀疏性。它采用嵌入的收缩操作符，无需对代码进行修改即可适应各种大型语言模型，并在各种基准数据集上实现与密集型模型相当的性能，同时减少参数数量。 |
| [^44] | [Learning non-Markovian Decision-Making from State-only Sequences.](http://arxiv.org/abs/2306.15156) | 本文提出了一种从仅状态序列学习非马尔科夫决策的方法，通过深度生成建模和最大似然估计实现基于模型的模仿。学习的模型能够实现“推理式决策”，并在路径规划任务中展示了有效性。 |
| [^45] | [G-NM: A Group of Numerical Time Series Prediction Models.](http://arxiv.org/abs/2306.11667) | G-NM是一组集合了传统和现代模型的数字时间序列预测模型，旨在提高对复杂自然现象中的模式和趋势的预测能力。 |
| [^46] | [Tourist Attractions Recommendation based on Attention Knowledge Graph Convolution Network.](http://arxiv.org/abs/2306.10946) | 本文提出了一种基于注意力知识图卷积网络的旅游景点推荐模型，通过自动语义发掘目标景点的相邻实体，根据旅客的喜好选择，预测类似景点的概率，实验中取得良好效果。 |
| [^47] | [A HRNet-based Rehabilitation Monitoring System.](http://arxiv.org/abs/2306.10756) | 该论文介绍了一种基于HRNet的康复监测系统，旨在通过智能手机进行康复训练的管理。患者可以通过系统进行应用程序来进行训练，而治疗师可以通过服务器端进行进度的监测。 |
| [^48] | [Evolving Strategies for Competitive Multi-Agent Search.](http://arxiv.org/abs/2306.10640) | 本文研究了基于竞争多智能体搜索的演化策略，通过实验验证了进化计算可以用于发现在不同竞争环境中的有效搜索策略。 |
| [^49] | [Can We Trust AI-Generated Educational Content? Comparative Analysis of Human and AI-Generated Learning Resources.](http://arxiv.org/abs/2306.10509) | AI-generated educational content has been found to be perceived as equivalent in quality to content created by students, suggesting that AI-generated resources may serve as viable learning materials. |
| [^50] | [Taxonomy-Structured Domain Adaptation.](http://arxiv.org/abs/2306.07874) | 本文提出了分层结构领域自适应方法，通过分层结构领域的形式化描述来缓解不同领域之间的分布偏移，该方法在合成和实际数据集上实现了最先进的性能。 |
| [^51] | [Automated 3D Pre-Training for Molecular Property Prediction.](http://arxiv.org/abs/2306.07812) | 通过在3D分子图上进行预训练，该论文提出了一种更有效地预测分子属性的方法，该方法可以在不需要分子几何结构的情况下进行微调。 |
| [^52] | [V-LoL: A Diagnostic Dataset for Visual Logical Learning.](http://arxiv.org/abs/2306.07743) | V-LoL是一个结合视觉和逻辑挑战的诊断数据集，其中包括了V-LoL-Trains，该数据集首次将复杂的视觉场景和灵活的逻辑推理任务结合起来，为研究广泛的视觉逻辑学习挑战提供了平台。 |
| [^53] | [Artificial General Intelligence for Medical Imaging.](http://arxiv.org/abs/2306.05480) | 本文探讨了人工通用智能模型在医学成像中的应用，重点关注基础的大型语言、视觉和多模态模型。通过整合临床专业知识、领域知识和多模态能力来开发和部署AGI能够解决医学领域面临的挑战和问题。 |
| [^54] | [Label Shift Quantification with Robustness Guarantees via Distribution Feature Matching.](http://arxiv.org/abs/2306.04376) | 本文提出一种名为DFM框架的方法，用于量化标签偏移，并证明了其性能上限和鲁棒性。使用基于核的DFM版本可以提高效率、可扩展性和鲁棒性。 |
| [^55] | [Knowledge-Driven Robot Program Synthesis from Human VR Demonstrations.](http://arxiv.org/abs/2306.02739) | 本文提出了一种从人类虚拟现实（VR）任务演示中自动生成可执行机器人控制程序的系统。通过利用常识知识和基于游戏引擎的物理学进行语义解释，并结合通用任务表示和自动路径规划和代码生成算法，实现了机器人购物助手的力敏抓取和放置任务。 |
| [^56] | [LLM-Blender: Ensembling Large Language Models with Pairwise Ranking and Generative Fusion.](http://arxiv.org/abs/2306.02561) | 本论文提出了LLM-Blender，它是一个集成框架，旨在利用不同的开源大型语言模型的优秀特性，实现始终如一的卓越性能。PairRanker和GenFuser是该框架的两个模块，PairRanker使用成对比较方法来区分候选输出，并且GenFuser旨在合并排名最高的候选者，以生成改进的输出。 |
| [^57] | [Optimization for truss design using Bayesian optimization.](http://arxiv.org/abs/2306.01763) | 本文提出了利用贝叶斯优化算法进行桁架设计优化的方法，通过迭代评估候选设计并更新概率模型的方式优化桁架结构，该方法在优化复杂系统方面表现出有效性。 |
| [^58] | [Train Offline, Test Online: A Real Robot Learning Benchmark.](http://arxiv.org/abs/2306.00942) | 这是一个提供离线训练和在线测试的机器人学习基准系统，通过共享机器人硬件和开源数据集，解决了机器人学习研究中的挑战，并为未来的研究提供了方便和直接的比较方法。 |
| [^59] | [BigVideo: A Large-scale Video Subtitle Translation Dataset for Multimodal Machine Translation.](http://arxiv.org/abs/2305.18326) | 提出了一个大规模的视频字幕翻译数据集BigVideo， 集成了4.5 million句子对和9981小时视频，设计了有歧义和明确的测试集，引入了一种对比学习方法，实验结果表明，视觉信息可以提高NMT模型的BLEU、BLEURT和COMET得分，有助于消除歧义，数据集和翻译模型公开可用。 |
| [^60] | [Practical PCG Through Large Language Models.](http://arxiv.org/abs/2305.18243) | 本研究介绍了如何利用语言模型生成游戏房间，在仅有少量数据的情况下，可以生成多达37%的可玩新颖关卡，该技术有助于解决包含许多局部和全局约束的PCG问题。 |
| [^61] | [Scan and Snap: Understanding Training Dynamics and Token Composition in 1-layer Transformer.](http://arxiv.org/abs/2305.16380) | 本文分析了1层Transformer在下一个标记预测任务中的SGD训练动态，证明了自我关注层充当了“区分性扫描算法”，从而逐步关注到相关标记并排除不相关的标记，总结相关信息在编码表示中。同时研究了标记频率、上下文和初始化自我关注层等对Transformer性能的影响。 |
| [^62] | [MERGE: Fast Private Text Generation.](http://arxiv.org/abs/2305.15769) | 该论文提出了MERGE，一个基于Transformer语言模型的快速私有文本生成框架。实验结果表明，MERGE在保护隐私的同时，实现了26.5倍的加速和80%的通信字节数减少。 |
| [^63] | [Zero-shot Approach to Overcome Perturbation Sensitivity of Prompts.](http://arxiv.org/abs/2305.15689) | 本研究提出了一种零样本方法，自动生成多个类似于基础提示的高质量提示，并使用新的度量方法进行排名，从而克服了提示的扰动敏感性，并在情感分类任务中具有较高的准确性。 |
| [^64] | [GUARD: A Safe Reinforcement Learning Benchmark.](http://arxiv.org/abs/2305.13681) | GUARD是一个广义统一安全强化学习开发基准测试平台，是目前广泛遍布且包含各种RL代理、任务和安全约束规范的一站式基准测试，能够全面涵盖最先进的安全RL算法，并具有高度的可自定义性。 |
| [^65] | [Restore Anything Pipeline: Segment Anything Meets Image Restoration.](http://arxiv.org/abs/2305.13093) | 本文提出了一种新颖的交互式和基于对象级别的图像恢复方法，即Restore Anything Pipeline (RAP)，该方法通过将图像分割技术与可控的图像恢复模型相结合，为多个图像恢复任务创建了一个用户友好的流程。 |
| [^66] | [How to Index Item IDs for Recommendation Foundation Models.](http://arxiv.org/abs/2305.06569) | 本研究对推荐基础模型的项目索引问题进行了系统检查，提出了一种新的上下文感知索引方法，该方法在项目推荐准确性和文本生成质量方面具有优势。 |
| [^67] | [Analysis of Climate Campaigns on Social Media using Bayesian Model Averaging.](http://arxiv.org/abs/2305.06174) | 本文分析了工业、倡导组织和气候倡导组织在社交媒体上如何影响气候变化的叙事，并提出了一个最小化监督模型组合方法，用于识别Facebook上气候广告的立场。 |
| [^68] | [On the Relation between Sharpness-Aware Minimization and Adversarial Robustness.](http://arxiv.org/abs/2305.05392) | SAM和对抗性训练（AT）都可以视为特定的特征扰动，其改善了对抗性能。然而，SAM和AT在扰动强度方面是不同的，从而带来了不同的精度和鲁棒性权衡。SAM单独使用可以在不牺牲清晰度精度的情况下提高对抗鲁棒性。 |
| [^69] | [Wearing face mask detection using deep learning through COVID-19 pandemic.](http://arxiv.org/abs/2305.00068) | 本研究探讨了在 COVID-19 疫情期间使用深度学习模型进行口罩佩戴检测的可行性。通过比较不同模型，选择了适用于实时和移动设备应用的最佳模型，并取得了高准确度。 |
| [^70] | [Let the Chart Spark: Embedding Semantic Context into Chart with Text-to-Image Generative Model.](http://arxiv.org/abs/2304.14630) | 本文提出了一个新的系统ChartSpark，利用文本到图像生成模型将语义上下文嵌入到图表中，以生成具有高质量语义上下文的图示可视化。 |
| [^71] | [Breaching FedMD: Image Recovery via Paired-Logits Inversion Attack.](http://arxiv.org/abs/2304.11436) | 本文揭示了即便使用FedMD的安全机制，仍存在被精心设计的恶意攻击利用的风险，如Paired-Logits反演攻击，会导致隐私数据曝光。 |
| [^72] | [AMP in the wild: Learning robust, agile, natural legged locomotion skills.](http://arxiv.org/abs/2304.10888) | 本文提出了一种新算法，可推断动态系统参数信息并从之前的观察数据中估计机器人状态的重要信息。将该算法与Adversarial Motion Priors相结合，实现了在仿真和真实世界中健壮、灵活、自然的步态，可用于穿越具有挑战性的地形。 |
| [^73] | [Towards Better Evaluation of GNN Expressiveness with BREC Dataset.](http://arxiv.org/abs/2304.07702) | 本论文介绍了一个新的Benchmark for Evaluating the Robustness of GNNs to Topological Changes (BREC)数据集，并使用BREC评估了几种现有的GNN模型的表达力，表明一些模型在以前的基准测试中表现良好，但在BREC上遇到了困难，突显了需要更好的GNN表现力评估的必要性。 |
| [^74] | [Interpretable Symbolic Regression for Data Science: Analysis of the 2022 Competition.](http://arxiv.org/abs/2304.01117) | 本文分析了2022年基因与进化计算会议举办的竞赛，评估了符号回归的新方法在面对现实数据时的表现，并提供了可解释性评估的实际方法。 |
| [^75] | [RegionPLC: Regional Point-Language Contrastive Learning for Open-World 3D Scene Understanding.](http://arxiv.org/abs/2304.00962) | 提出了一种用于开放世界3D场景理解的Regional Point-Language Contrastive Learning框架，通过密集的视觉提示和点独立对比学习来实现对新颖类别的识别和密集场景理解。 |
| [^76] | [Roots and Requirements for Collaborative AI.](http://arxiv.org/abs/2303.12040) | 论文探讨了AI协同合作的历史和要求，是协同AI研究的动机和背景。 |
| [^77] | [Soft Actor-Critic Algorithm with Truly-satisfied Inequality Constraint.](http://arxiv.org/abs/2303.04356) | 本文改进了软Actor-Critic（SAC）算法的实现，通过引入可学习的状态相关的松弛变量来适当处理不等式约束，实现了最大化策略熵。这对于增强机器人控制器的鲁棒性非常有用。 |
| [^78] | [Zero-Shot Cross-Lingual Summarization via Large Language Models.](http://arxiv.org/abs/2302.14229) | 本文实验性地使用各种提示来指导大型语言模型从不同的范式执行零样本跨语言摘要，并成功提高了它们的CLS性能。其中，GPT-4实现了零样本CLS的最先进性能，并且在性能方面与最佳方法相当。 |
| [^79] | [Graph Neural Networks with Learnable and Optimal Polynomial Bases.](http://arxiv.org/abs/2302.12432) | 本文提出了两种具有可学习和最优多项式基函数的谱图神经网络模型，通过学习多项式基函数和计算最优基函数，解决了多项式滤波器在模型有效性方面的问题。 |
| [^80] | [Exploration by self-supervised exploitation.](http://arxiv.org/abs/2302.11563) | 该论文介绍了一种基于自我监督学习的内在动机算法类别SND，并将其应用于探索困难环境。实验结果表明这种方法是有效的。 |
| [^81] | [Likelihood Annealing: Fast Calibrated Uncertainty for Regression.](http://arxiv.org/abs/2302.11012) | 该论文提出了一种名为似然退火的快速校准回归任务不确定性估计方法，能够改进深度回归模型的收敛性并产生校准的不确定性估计。 |
| [^82] | [Red Teaming Deep Neural Networks with Feature Synthesis Tools.](http://arxiv.org/abs/2302.10894) | 本文提出了一个用于评估可解释性工具的基准，通过训练模型以对特定触发器产生特定输出的方式，可以解决传统可解释性方法无法分析未知特征行为的问题。 |
| [^83] | [FrankenSplit: Saliency Guided Neural Feature Compression with Shallow Variational Bottleneck Injection.](http://arxiv.org/abs/2302.10681) | 本文提出了一种基于显著性指导的神经特征压缩与浅层变分瓶颈注入的新的资源意识压缩模型的框架，实现了比最先进的SC方法低60％的比特率，并且比现有的编解码标准的下放快16倍。 |
| [^84] | [Neural Algorithmic Reasoning with Causal Regularisation.](http://arxiv.org/abs/2302.10258) | 提出了一种具有因果正则化的神经算法推理方法，通过观察到对于某些中间计算来说存在许多不同的输入，可以开发数据增强程序，生成能够使目标算法有完全相同下一轨迹步骤的输入，从而提高在分布外测试数据上的性能。 |
| [^85] | [Topological Feature Selection: A Graph-Based Filter Feature Selection Approach.](http://arxiv.org/abs/2302.09543) | 本文提出了一种基于图论的特征选择方法，利用拓扑学和依赖关系，具有高度灵活性和解释性，在16个基准数据集上显示出优于或匹配于当前最先进技术的表现。 |
| [^86] | [Less is More: Selective Layer Finetuning with SubTuning.](http://arxiv.org/abs/2302.06354) | 本研究提出了一种选择性层微调与子微调的方法，通过仅对精心选择的层进行微调，而将其余权重保持在预训练值上。该方法在准确性上能够与全模型微调相媲美，并在训练数据稀缺时表现更好。这一简单而有效的方法适用于多任务学习，并能够在推理过程中实现任务间的资源共享。 |
| [^87] | [State-wise Safe Reinforcement Learning: A Survey.](http://arxiv.org/abs/2302.03122) | 本文综合回顾了强化学习中解决基于状态约束的方法，讨论了它们在安全保障和可扩展性、安全性和奖励表现、收敛后和训练过程中的安全性等方面的联系、差异和权衡，并讨论了未来发展方向。 |
| [^88] | [Diversity Induced Environment Design via Self-Play.](http://arxiv.org/abs/2302.02119) | 本文提出了一种利用自我对战技术的任务不可知方法，来识别环境中的观察/隐藏状态，并将多样性引入非监督环境设计框架中，从而提高了环境设计的效率和有效性。 |
| [^89] | [Learning to Optimize for Reinforcement Learning.](http://arxiv.org/abs/2302.01470) | 学习优化器在监督学习中取得了显著的成功，但在强化学习中面临梯度范围变化大、梯度分布非独立且不同、高方差偏差等问题。本文提出了梯度处理、管道训练和一种新颖的优化器结构来解决这些问题。 |
| [^90] | [Sample Efficient Deep Reinforcement Learning via Local Planning.](http://arxiv.org/abs/2301.12579) | 提出了一种名为UFLP的算法框架，通过重置环境到高不确定性状态来提高深度强化学习的样本效率，实验证明这个简单的过程可以显著改善采样成本，并在困难的探索任务上取得超人类的表现。 |
| [^91] | [Increasing Fairness via Combination with Learning Guarantees.](http://arxiv.org/abs/2301.10813) | 该论文提出了一种公平质量度量方法，名为判别风险，旨在反映个体和群体公平性。此外，研究者还讨论了公平性是否可以在理论上得到保证。 |
| [^92] | [Finding Lookalike Customers for E-Commerce Marketing.](http://arxiv.org/abs/2301.03147) | 本文介绍了一个以客户为中心的营销活动中寻找相似客户的可扩展和高效系统。该系统能处理亿级客户，并使用深度学习嵌入模型和近似最近邻搜索方法来寻找感兴趣的相似客户。通过构建可解释且有意义的客户相似度度量，该模型能够处理各种业务兴趣。 |
| [^93] | [CC-FedAvg: Computationally Customized Federated Averaging.](http://arxiv.org/abs/2212.13679) | 本论文提出了一个称为CC-FedAvg的计算定制的联邦平均算法，可让参与者根据其计算预算决定在每轮中是否执行传统的本地训练或模型估算。实验结果表明，CC-FedAvg能够显著提高模型性能并降低通信成本。 |
| [^94] | [When Not to Trust Language Models: Investigating Effectiveness and Limitations of Parametric and Non-Parametric Memories.](http://arxiv.org/abs/2212.10511) | 本文通过对10个模型和4种增强方法的实验，发现语言模型在记忆不太流行的实际知识方面存在困难，而检索增强的语言模型表现较好，提出了一种检索增强语言模型的简单有效方法。 |
| [^95] | [Robotic Skill Acquisition via Instruction Augmentation with Vision-Language Models.](http://arxiv.org/abs/2211.11736) | 本文提出了一种通过视觉-语言模型的指令增强方法，利用预训练模型将互联网规模的知识导入现有机器人数据集，实现机器人技能的获取。 |
| [^96] | [TAX-Pose: Task-Specific Cross-Pose Estimation for Robot Manipulation.](http://arxiv.org/abs/2211.09325) | 本论文提出了一种名为TAX-Pose的系统，在机器人操作中实现了任务特定跨姿势的估计。通过学习对象之间的对应关系，这种系统能够在给定操作任务的情况下准确估计两个对象之间的跨姿势，并利用估计结果指导下游的运动规划。 |
| [^97] | [MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis.](http://arxiv.org/abs/2211.05862) | 提出了一种新的数据增强方法MixUp-MIL用于多示例学习，通过应用切片内插值方法可以改善甲状腺癌诊断的准确性。 |
| [^98] | [Active Acquisition for Multimodal Temporal Data: A Challenging Decision-Making Task.](http://arxiv.org/abs/2211.05039) | 该论文提出了一个具有挑战性的决策任务，主动获取多模态时间数据。通过权衡获取成本和预测性能，学习代理程序来主动选择获取的输入模态。该方法能够解决具有实际相关推理技能的合成情景，并在真实数据集上成功学习到成本反应式的获取行为，但无法学习到自适应的获取策略，突显了任务的困难性。 |
| [^99] | [Causal Explanation for Reinforcement Learning: Quantifying State and Temporal Importance.](http://arxiv.org/abs/2210.13507) | 本文开发了一种因果解释机制，能够量化状态对行动的因果重要性和随时间变化的重要性，并通过一系列的模拟研究证明了该机制在强化学习策略解释方面的优势。 |
| [^100] | [RSC: Accelerating Graph Neural Networks Training via Randomized Sparse Computations.](http://arxiv.org/abs/2210.10737) | 通过随机稀疏计算，本研究提出了一种加速图神经网络训练的方法，解决了稀疏图操作难以加速和不规则数据格式导致的效率问题。 |
| [^101] | [Embeddings as Epistemic States: Limitations on the Use of Pooling Operators for Accumulating Knowledge.](http://arxiv.org/abs/2210.05723) | 本文研究了用于汇聚信息的各种汇聚运算符在嵌入编码中的应用。我们发现所有考虑的汇聚运算符都可以满足认识汇聚原则，但这仅在嵌入具有足够高维度并满足特定约束的情况下成立。这些约束对嵌入在实践中的使用具有重要影响。 |
| [^102] | [FAIR-FATE: Fair Federated Learning with Momentum.](http://arxiv.org/abs/2209.13678) | FAIR-FATE是一种公平联邦学习算法，通过公平感知的聚合方法实现组公平性并保持高效用性。 |
| [^103] | [Learning When to Advise Human Decision Makers.](http://arxiv.org/abs/2209.13578) | 本文提出了一种新颖的人工智能系统设计，其中算法与人类用户以双向互动的方式交互，仅在对用户的决策有益时提供建议。实验证明，这种方法能够改善人类的决策能力，并在促进人类学习、保留人类决策的补充优势方面具有额外的优势。 |
| [^104] | [A Survey on Generative Diffusion Model.](http://arxiv.org/abs/2209.02646) | 本综述总结了生成扩散模型的先进技术，包括采样加速、新的扩散过程设计以及在不同空间中实现扩散模型的策略。这些创新努力旨在提高扩散模型的功能和效率。 |
| [^105] | [Imputation Strategies Under Clinical Presence: Impact on Algorithmic Fairness.](http://arxiv.org/abs/2208.06648) | 本文研究了填补选择对不同群体的重建误差和下游预测的算法公平性属性的影响。 |
| [^106] | [Truth Set Algebra: A New Way to Prove Undefinability.](http://arxiv.org/abs/2208.04422) | 本文提出了真值集代数，一种用于证明逻辑连接符相互无法定义的新方法。 |
| [^107] | [Infant movement classification through pressure distribution analysis -- added value for research and clinical implementation.](http://arxiv.org/abs/2208.00884) | 本文提出了一种创新型的非侵入式方法，使用压力传感器对婴儿的一般运动进行分类，旨在实现早期神经肌肉障碍（如脑瘫）的客观检测。研究结果表明，使用压力数据可以区分婴儿的典型运动模式，即“坐立不安期”和“坐立不安前期”。 |
| [^108] | [MABe22: A Multi-Species Multi-Task Benchmark for Learned Representations of Behavior.](http://arxiv.org/abs/2207.10553) | MABe22是一个多物种多任务基准，用于评估学习行为表示的质量。它采集了来自各种生物学实验的数据，测试了多种自监督学习方法，并发现人类行动数据集上的方法不能完全适用于动物数据集。 |
| [^109] | [Rethinking Symbolic Regression Datasets and Benchmarks for Scientific Discovery.](http://arxiv.org/abs/2206.10540) | 本文重新审视并重新创建了符号回归数据集，以评估符号回归在科学发现中的潜力和能力，并提出使用归一化编辑距离进行度量。 |
| [^110] | [How Biased are Your Features?: Computing Fairness Influence Functions with Global Sensitivity Analysis.](http://arxiv.org/abs/2206.00667) | 本论文介绍了公正影响函数（FIF），通过全局敏感性分析的方法量化了不同特征对分类器偏见的影响，从而解决了公平性问题中的核心关注点。 |
| [^111] | [Learning Hidden Markov Models When the Locations of Missing Observations are Unknown.](http://arxiv.org/abs/2203.06527) | 本文研究了当缺失观测的位置未知时学习隐马尔可夫模型的问题，并提供了不需要先验信息的重建算法。 |
| [^112] | [CPTAM: Constituency Parse Tree Aggregation Method.](http://arxiv.org/abs/2201.07905) | 本文提出了一种依存句法树聚合方法，通过估计不同解析器的可靠性，以持续获得高质量的聚合依存句法树。具体来说，通过最小化树之间的经典对称距离度量，罗宾逊-福尔兹距离的加权和，实现了树结构的真实性发现。 |
| [^113] | [Efficient Multi-objective Neural Architecture Search Framework via Policy Gradient Algorithm.](http://arxiv.org/abs/2111.03892) | 本论文提出了TND-NAS框架，利用可微架构搜索框架和多目标NAS的兼容性，通过策略梯度算法实现高效多目标神经架构搜索。实验结果表明其优于现有方法。 |
| [^114] | [A unified logical framework for explanations in classifier systems.](http://arxiv.org/abs/2105.14452) | 本研究提出了一种以ceteris paribus为基础的模态语言，用于解释二进制分类器及其属性的推理。我们证明了两个关于语言基数的证明系统的完备性，并研究了无限变量和有限变量情况下的可满足性检查问题。我们还使用这种语言来形式化多种解释概念，包括对事实、对比和反事实解释以及偏见。 |
| [^115] | [Bridging Offline Reinforcement Learning and Imitation Learning: A Tale of Pessimism.](http://arxiv.org/abs/2103.12021) | 本论文提出了一种新的联机强化学习框架，通过平滑插值的方式将模仿学习和纯联机强化学习统一起来。框架围绕着一种衡量行为策略与专家策略偏离程度的弱版本集中系数展开。通过该框架，研究者进一步研究了算法设计的问题：能否开发出实现最小极大最优性的算法？ |
| [^116] | [Transfer Learning in Deep Reinforcement Learning: A Survey.](http://arxiv.org/abs/2009.07888) | 这篇综述调查了深度强化学习领域中的迁移学习方法的最新进展，并提供了一个对这些方法进行分类的框架。分析了它们的目标、方法学、兼容的强化学习背景以及实际应用，并探讨了迁移学习与其他相关主题之间的联系。 |
| [^117] | [Failures of Contingent Thinking.](http://arxiv.org/abs/2007.07703) | 本文提供了分析智能体错误解读或错误感知真实决策问题的理论框架，并提出了一种行为定义来评估智能体因果思维水平，同时提供了一种策略来识别智能体在缺乏完全理性的情况下的信念。 |
| [^118] | [A model of interaction semantics.](http://arxiv.org/abs/2007.06258) | 本研究提出了一种交互语义模型，通过构建系统交互模型，并不依赖于字符到概念的“心理”映射，来理解交互中字符的“含义”。 |
| [^119] | [Meta Adaptation using Importance Weighted Demonstrations.](http://arxiv.org/abs/1911.10322) | 本文提出了一种使用重要权重示范的元适应性学习算法，通过对特定任务的先前知识进行分配重要权重，实现了在任何相关任务上的泛化。实验证明，该方法能够使机器人在多样化环境任务中进行训练，并通过少量示范适应未知环境。 |

# 详细

[^1]: SHARCS: 解释性多模态学习的共享概念空间

    SHARCS: Shared Concept Space for Explainable Multimodal Learning. (arXiv:2307.00316v1 [cs.LG])

    [http://arxiv.org/abs/2307.00316](http://arxiv.org/abs/2307.00316)

    SHARCS是一种解释性多模态学习方法，它通过学习和映射可解释的概念到一个统一的概念空间，实现了解释性的任务预测和改进性能。

    

    多模态学习是解决复杂现实世界问题的重要范式，在这种问题中，单个数据模态通常无法准确解决给定的建模任务。虽然各种深度学习方法已经成功地解决了这些挑战，但它们的推理过程通常是不透明的，限制了原则性的可解释跨模态分析和领域专家干预的能力。在本文中，我们介绍了SHARCS（SHARed Concept Space）——一种用于解释性多模态学习的新概念方法。SHARCS从不同的异构模态中学习和映射可解释的概念到一个统一的概念流形，从而产生了语义相似的跨模态概念的直观投影。我们证明了这种方法可以导致固有可解释的任务预测，同时也提高了下游的预测性能。此外，我们还展示了SHARCS可以运行并明显优于其他方法。

    Multimodal learning is an essential paradigm for addressing complex real-world problems, where individual data modalities are typically insufficient to accurately solve a given modelling task. While various deep learning approaches have successfully addressed these challenges, their reasoning process is often opaque; limiting the capabilities for a principled explainable cross-modal analysis and any domain-expert intervention. In this paper, we introduce SHARCS (SHARed Concept Space) -- a novel concept-based approach for explainable multimodal learning. SHARCS learns and maps interpretable concepts from different heterogeneous modalities into a single unified concept-manifold, which leads to an intuitive projection of semantically similar cross-modal concepts. We demonstrate that such an approach can lead to inherently explainable task predictions while also improving downstream predictive performance. Moreover, we show that SHARCS can operate and significantly outperform other approac
    
[^2]: 梯度相似：敏感度经常被过高估计在DP-SGD中

    Gradients Look Alike: Sensitivity is Often Overestimated in DP-SGD. (arXiv:2307.00310v1 [cs.LG])

    [http://arxiv.org/abs/2307.00310](http://arxiv.org/abs/2307.00310)

    本文开发了一种新的DP-SGD分析方法，可以在训练过程中对许多数据点的隐私泄漏进行更准确的评估。

    

    差分隐私随机梯度下降（DP-SGD）是私有深度学习的标准算法。虽然已知其隐私分析在最坏情况下是紧密的，但是一些实证结果表明，在常见的基准数据集上训练时，所得到的模型对许多数据点的隐私泄漏显著减少。在本文中，我们为DP-SGD开发了一种新的分析方法，捕捉到在数据集中具有相似邻居的点享受更好隐私性的直觉。形式上来说，这是通过修改从训练数据集计算得到的模型更新的每步隐私性分析来实现的。我们进一步开发了一个新的组合定理，以有效地利用这个新的每步分析来推理整个训练过程。总而言之，我们的评估结果表明，这种新颖的DP-SGD分析使我们能够正式地显示DP-SGD对许多数据点的隐私泄漏显著减少。

    Differentially private stochastic gradient descent (DP-SGD) is the canonical algorithm for private deep learning. While it is known that its privacy analysis is tight in the worst-case, several empirical results suggest that when training on common benchmark datasets, the models obtained leak significantly less privacy for many datapoints. In this paper, we develop a new analysis for DP-SGD that captures the intuition that points with similar neighbors in the dataset enjoy better privacy than outliers. Formally, this is done by modifying the per-step privacy analysis of DP-SGD to introduce a dependence on the distribution of model updates computed from a training dataset. We further develop a new composition theorem to effectively use this new per-step analysis to reason about an entire training run. Put all together, our evaluation shows that this novel DP-SGD analysis allows us to now formally show that DP-SGD leaks significantly less privacy for many datapoints. In particular, we ob
    
[^3]: SyMFM6D：面向对称多方位融合的多视角6D物体姿态估计

    SyMFM6D: Symmetry-aware Multi-directional Fusion for Multi-View 6D Object Pose Estimation. (arXiv:2307.00306v1 [cs.CV])

    [http://arxiv.org/abs/2307.00306](http://arxiv.org/abs/2307.00306)

    该论文介绍了一种叫做SyMFM6D的面向对称多视角融合的6D物体姿态估计方法。该方法通过多方向融合网络有效地融合多个视角的RGB-D帧，并通过预测关键点和实例语义分割来计算6D姿态。通过新的训练过程和目标函数，该方法能够解决对称物体的歧义问题，并在单视角和多视角姿态估计方面取得了显著的性能提升。

    

    检测物体并估计其6D姿态对于自动化系统与环境安全互动至关重要。然而，大多数6D姿态估计器仅依赖于单个摄像头帧，并且受到由于物体对称性而引起的遮挡和模糊的影响。我们通过提出一种新颖的面向对称多视角6D姿态估计器SyMFM6D来解决这个问题。我们的方法通过深度多方向融合网络有效地融合多个角度的RGB-D帧，并同时预测场景中所有物体的预定义关键点。基于关键点和实例语义分割，我们通过最小二乘拟合高效计算6D姿态。为了解决对称物体的歧义问题，我们提出了一种新的训练过程用于对称感知的关键点检测，包括一种新的目标函数。我们的SyMFM6D网络在单视角和多视角6D姿态估计方面显著优于现有技术。此外，我们还展示了该方法对姿态估计的影响。

    Detecting objects and estimating their 6D poses is essential for automated systems to interact safely with the environment. Most 6D pose estimators, however, rely on a single camera frame and suffer from occlusions and ambiguities due to object symmetries. We overcome this issue by presenting a novel symmetry-aware multi-view 6D pose estimator called SyMFM6D. Our approach efficiently fuses the RGB-D frames from multiple perspectives in a deep multi-directional fusion network and predicts predefined keypoints for all objects in the scene simultaneously. Based on the keypoints and an instance semantic segmentation, we efficiently compute the 6D poses by least-squares fitting. To address the ambiguity issues for symmetric objects, we propose a novel training procedure for symmetry-aware keypoint detection including a new objective function. Our SyMFM6D network significantly outperforms the state-of-the-art in both single-view and multi-view 6D pose estimation. We furthermore show the effe
    
[^4]: SysNoise: 探索和评估训练-部署系统的不一致性

    SysNoise: Exploring and Benchmarking Training-Deployment System Inconsistency. (arXiv:2307.00280v1 [cs.LG])

    [http://arxiv.org/abs/2307.00280](http://arxiv.org/abs/2307.00280)

    SysNoise是一种在深度学习的训练-部署周期中经常发生的噪音，该论文通过实验证明了SysNoise对不同任务的模型稳健性会带来一定影响，并提出了常见的缓解方法。

    

    大量研究表明，深度学习模型容易受到敌对和自然噪音的影响，然而对于由不同系统实现引起的噪音对模型的稳健性知之甚少。本文首次引入SysNoise，一种在深度学习的训练-部署周期中经常发生但往往被忽视的噪音。具体而言，SysNoise发生在源训练系统在部署时切换到不同的目标系统时，各种微小系统不匹配累加起来会产生显著差异。我们首先对SysNoise进行了识别和分类，分为基于推理阶段的三个类别；然后建立了一个综合性评估标准，以定量评估SysNoise对20多种模型的影响，包括图像分类、目标检测、实例分割和自然语言处理任务。我们广泛的实验揭示了SysNoise对不同任务的模型稳健性会带来一定的影响，并提出了常见的缓解方法。

    Extensive studies have shown that deep learning models are vulnerable to adversarial and natural noises, yet little is known about model robustness on noises caused by different system implementations. In this paper, we for the first time introduce SysNoise, a frequently occurred but often overlooked noise in the deep learning training-deployment cycle. In particular, SysNoise happens when the source training system switches to a disparate target system in deployments, where various tiny system mismatch adds up to a non-negligible difference. We first identify and classify SysNoise into three categories based on the inference stage; we then build a holistic benchmark to quantitatively measure the impact of SysNoise on 20+ models, comprehending image classification, object detection, instance segmentation and natural language processing tasks. Our extensive experiments revealed that SysNoise could bring certain impacts on model robustness across different tasks and common mitigations li
    
[^5]: 分层预训练用于生物医学术语嵌入

    Hierarchical Pretraining for Biomedical Term Embeddings. (arXiv:2307.00266v1 [cs.CL])

    [http://arxiv.org/abs/2307.00266](http://arxiv.org/abs/2307.00266)

    分层预训练用于生物医学术语嵌入，通过将临床术语表示为语义嵌入并利用低维嵌入作为特征向量，可以提高临床记录的自然语言处理（NLP）效果。

    

    电子健康记录（EHR）包含了关于患者的医疗状况和管理的详细说明。通过自然语言处理（NLP）对临床记录进行处理，可以利用临床术语的观察频率作为预测特征，用于临床决策和患者轨迹预测等下游应用。然而，由于大量相似且相关的临床概念，更有效的建模策略是通过表示学习将临床术语表示为语义嵌入，并将低维嵌入作为特征向量用于预测建模。为了实现高效的表示，利用与生物医学知识图谱进行预训练语言模型的微调，可能会生成比仅使用标准语言模型获得的生物医学术语嵌入更好的嵌入。这些嵌入可以有效区分同义词对和不相关的词对。然而，它们常常无法捕捉到不同的程度

    Electronic health records (EHR) contain narrative notes that provide extensive details on the medical condition and management of patients. Natural language processing (NLP) of clinical notes can use observed frequencies of clinical terms as predictive features for downstream applications such as clinical decision making and patient trajectory prediction. However, due to the vast number of highly similar and related clinical concepts, a more effective modeling strategy is to represent clinical terms as semantic embeddings via representation learning and use the low dimensional embeddings as feature vectors for predictive modeling. To achieve efficient representation, fine-tuning pretrained language models with biomedical knowledge graphs may generate better embeddings for biomedical terms than those from standard language models alone. These embeddings can effectively discriminate synonymous pairs of from those that are unrelated. However, they often fail to capture different degrees o
    
[^6]: InstructEval: 系统评估指令选择方法

    InstructEval: Systematic Evaluation of Instruction Selection Methods. (arXiv:2307.00259v1 [cs.CL])

    [http://arxiv.org/abs/2307.00259](http://arxiv.org/abs/2307.00259)

    InstructEval开发了一个评估套件，用于对指令选择方法进行全面评估。通过使用策划的手动编写的指令，可以显著提高性能。

    

    上下文学习 (ICL) 通过使用指令和一小组注释示例来提示一个大型语言模型 (LLM) 来执行任务。最近的工作表明，提示中使用的输入的细节对 ICL 有着重要影响，这激励了指令选择算法的发展。然而，指令选择的影响尚未得到深入探索，现有的分析仅限于模型和任务的浅层子集，这限制了洞察力的普适性。我们开发了一个 ICL 评估套件，以对这些技术进行全面评估。该套件包括来自4个不同模型家族的13个开源LLM，涵盖9个不同的任务，代表了3个分类中各种类型的任务。在本研究中，我们使用我们的基准测试评估了7种受欢迎的指令选择方法相对于ICL相关的五项期望性能。我们发现使用策划的手动编写的指令可以显著地提高性能。

    In-context learning (ICL) performs tasks by prompting a large language model (LLM) using an instruction and a small set of annotated examples called demonstrations. Recent work has shown that the precise details of the inputs used in the prompt significantly impacts ICL, which has incentivized instruction selection algorithms. The effect of instruction-choice however is severely underexplored, with existing analyses being restricted to shallow subsets of models and tasks, which limits the generalizability of their insights. We develop an ICL evaluation suite to conduct a thorough assessment of these techniques. The suite includes 13 open-sourced LLMs of varying scales from 4 distinct model families and covers 9 different tasks, representing a range of task types across 3 categories. In this work, we evaluate the relative performance of 7 popular instruction selection methods using our benchmark over five desiderata relevant to ICL. We discover that using curated manually-written instru
    
[^7]: 医学图像中高效的子类分割

    Efficient Subclass Segmentation in Medical Images. (arXiv:2307.00257v1 [cs.CV])

    [http://arxiv.org/abs/2307.00257](http://arxiv.org/abs/2307.00257)

    这篇论文提出了一种在医学图像中高效学习细粒度子类分割的方法，通过利用层次结构设计网络架构，并引入任务驱动的数据生成方法来增强分割的置信度。

    

    随着医学图像分析的研究兴趣越来越细致，广泛标注的成本也在上升。为了减少成本，一种可行的方法是用粗粒度的超类标签进行标注，同时使用有限的精细标注作为补充。通过这种方式，充足的粗粒度注释辅助了精细数据学习。最近的分类任务研究在采用这种方法以取得令人满意的结果。然而，在语义分割任务中，对于高效学习细粒度子类的研究还不足。在本文中，我们提出了一种新颖的方法，利用类别的层次结构来设计网络架构。同时，提出了一种任务驱动的数据生成方法，使得网络更容易识别不同的子类别。具体而言，我们引入了一个前向连接模块，通过连接来自超类预测结果的标签，增强了子类分割的置信度。

    As research interests in medical image analysis become increasingly fine-grained, the cost for extensive annotation also rises. One feasible way to reduce the cost is to annotate with coarse-grained superclass labels while using limited fine-grained annotations as a complement. In this way, fine-grained data learning is assisted by ample coarse annotations. Recent studies in classification tasks have adopted this method to achieve satisfactory results. However, there is a lack of research on efficient learning of fine-grained subclasses in semantic segmentation tasks. In this paper, we propose a novel approach that leverages the hierarchical structure of categories to design network architecture. Meanwhile, a task-driven data generation method is presented to make it easier for the network to recognize different subclass categories. Specifically, we introduce a Prior Concatenation module that enhances confidence in subclass segmentation by concatenating predicted logits from the superc
    
[^8]: 一种解决奇点问题的机器学习方法

    An ML approach to resolution of singularities. (arXiv:2307.00252v1 [cs.LG])

    [http://arxiv.org/abs/2307.00252](http://arxiv.org/abs/2307.00252)

    该论文介绍了一种新的机器学习方法，使用强化学习代理来解决奇点问题中的最优解。实验证明在多项式相加的总数方面，该方法超过了当前最先进的选择启发式算法，展示了近期研究的潜力。

    

    多项式方程组的解集通常包含不光滑、奇异的点。解决奇点是几何中的基本过程，我们将奇点替换为光滑点，同时保持解集的剩余部分不变。解决奇点并不是唯一的：通常的方法是反复进行被称为“blowing-up”的基本操作，解决的复杂性高度依赖于某些选择。这个过程可以转化成不同版本的两人博弈，即所谓的Hironaka游戏，而第一位玩家的获胜策略提供了解决奇点问题的解。本文介绍了一种新的Hironaka游戏方法，使用强化学习代理来寻找奇点的最优解。在某些领域中，训练模型在多项式相加的总数方面优于最先进的选择启发式算法，这证明了最近发展的潜力。

    The solution set of a system of polynomial equations typically contains ill-behaved, singular points. Resolution is a fundamental process in geometry in which we replace singular points with smooth points, while keeping the rest of the solution set unchanged. Resolutions are not unique: the usual way to describe them involves repeatedly performing a fundamental operation known as "blowing-up", and the complexity of the resolution highly depends on certain choices. The process can be translated into various versions of a 2-player game, the so-called Hironaka game, and a winning strategy for the first player provides a solution to the resolution problem. In this paper we introduce a new approach to the Hironaka game that uses reinforcement learning agents to find optimal resolutions of singularities. In certain domains, the trained model outperforms state-of-the-art selection heuristics in total number of polynomial additions performed, which provides a proof-of-concept that recent devel
    
[^9]: THUIR2在NTCIR-16 Session搜索（SS）任务中的表现

    THUIR2 at NTCIR-16 Session Search (SS) Task. (arXiv:2307.00250v1 [cs.IR])

    [http://arxiv.org/abs/2307.00250](http://arxiv.org/abs/2307.00250)

    本文介绍了THUIR2团队在NTCIR-16 Session搜索任务中的表现，他们在FOSS和POSS子任务中使用了学习排序和预训练语言模型，并取得了最佳性能。

    

    我们的团队（THUIR2）参加了NTCIR-16 Session搜索（SS）任务的FOSS和POSS子任务。本文描述了我们的方法和结果。在FOSS子任务中，我们使用学习排序和精细调整的预训练语言模型提交了五个运行。我们使用自适应数据和会话信息对预训练语言模型进行了精细调整，并通过学习排序方法组装起来。组装的模型在初步评估中在所有参与者中取得了最佳性能。在POSS子任务中，我们使用了一个组装的模型，在初步评估中也取得了最佳性能。

    Our team(THUIR2) participated in both FOSS and POSS subtasks of the NTCIR-161 Session Search (SS) Task. This paper describes our approaches and results. In the FOSS subtask, we submit five runs using learning-to-rank and fine-tuned pre-trained language models. We fine-tuned the pre-trained language model with ad-hoc data and session information and assembled them by a learning-to-rank method. The assembled model achieves the best performance among all participants in the preliminary evaluation. In the POSS subtask, we used an assembled model which also achieves the best performance in the preliminary evaluation.
    
[^10]: VesselMorph: 基于形状感知表征的领域通用的视网膜血管分割方法

    VesselMorph: Domain-Generalized Retinal Vessel Segmentation via Shape-Aware Representation. (arXiv:2307.00240v1 [cs.CV])

    [http://arxiv.org/abs/2307.00240](http://arxiv.org/abs/2307.00240)

    VesselMorph使用一个基于形状感知的表征方法，通过合成血管的形态学特征来推广视网膜血管分割任务，以提高深度模型的通用性。

    

    由于缺乏统一的成像协议，来自不同站点的数据之间的领域转移是医学图像的固有属性，已经成为学习算法大规模应用的主要障碍。对于视网膜血管图像，领域转移通常表现为强度、对比度和分辨率的变化，而血管的基本管状形状保持不变。因此，利用这种领域不变的形态学特征可以大大提高深度模型的通用性。在本研究中，我们提出了一种名为VesselMorph的方法，通过合成形状感知表征来推广2D视网膜血管分割任务。受传统Frangi滤波器和扩散张量成像文献的启发，我们引入了一种基于Hessian的双极张量场来描述血管的形态学特征，从而考虑到形状信息。我们将强度图像和张量场映射到潜在空间中。

    Due to the absence of a single standardized imaging protocol, domain shift between data acquired from different sites is an inherent property of medical images and has become a major obstacle for large-scale deployment of learning-based algorithms. For retinal vessel images, domain shift usually presents as the variation of intensity, contrast and resolution, while the basic tubular shape of vessels remains unaffected. Thus, taking advantage of such domain-invariant morphological features can greatly improve the generalizability of deep models. In this study, we propose a method named VesselMorph which generalizes the 2D retinal vessel segmentation task by synthesizing a shape-aware representation. Inspired by the traditional Frangi filter and the diffusion tensor imaging literature, we introduce a Hessian-based bipolar tensor field to depict the morphology of the vessels so that the shape information is taken into account. We map the intensity image and the tensor field to a latent sp
    
[^11]: 前向前向算法用于高光谱图像分类：初步研究

    Forward-Forward Algorithm for Hyperspectral Image Classification: A Preliminary Study. (arXiv:2307.00231v1 [cs.CV])

    [http://arxiv.org/abs/2307.00231](http://arxiv.org/abs/2307.00231)

    本研究调查了在高光谱图像分类中应用前向前向算法（FFA），该算法通过计算局部优势函数来减轻对计算资源和架构扩展的依赖。

    

    反向传播算法长期以来一直是神经网络中优化权重和偏差的事实标准，尤其在先进的深度学习模型中。它在自然语言处理、计算机视觉和遥感等领域的广泛应用已经在各种任务的自动化方面引发了革命。反向传播的流行源于它在分类、检测和分割等任务中能够实现卓越的性能。然而，反向传播并非没有限制，包括对初始条件的敏感性、梯度消失、过拟合和计算复杂性。最近引入的一种前向前向算法（FFA）通过计算局部优势函数来优化网络参数，从而减轻了对大量计算资源和不断扩展架构的依赖。本研究调查了FFA在高光谱图像分类中的应用。

    The back-propagation algorithm has long been the de-facto standard in optimizing weights and biases in neural networks, particularly in cutting-edge deep learning models. Its widespread adoption in fields like natural language processing, computer vision, and remote sensing has revolutionized automation in various tasks. The popularity of back-propagation stems from its ability to achieve outstanding performance in tasks such as classification, detection, and segmentation. Nevertheless, back-propagation is not without its limitations, encompassing sensitivity to initial conditions, vanishing gradients, overfitting, and computational complexity. The recent introduction of a forward-forward algorithm (FFA), which computes local goodness functions to optimize network parameters, alleviates the dependence on substantial computational resources and the constant need for architectural scaling. This study investigates the application of FFA for hyperspectral image classification. Experimental
    
[^12]: 图像的重要性：多模态夸张检测的新数据集和实证研究

    Image Matters: A New Dataset and Empirical Study for Multimodal Hyperbole Detection. (arXiv:2307.00209v1 [cs.CV])

    [http://arxiv.org/abs/2307.00209](http://arxiv.org/abs/2307.00209)

    本研究提出了一个新的多模态夸张检测数据集，并使用文本和图像作为两种模态进行研究。同时，评估了不同预训练的多模态编码器在此任务中的表现。该研究探索了夸张检测的跨领域性能。

    

    夸张，即夸大其词，是一种常见的语言现象。夸张检测是理解人类表达的重要部分。已经有几项关于夸张检测的研究，但大多数的研究只关注文本模态。然而，随着社交媒体的发展，人们可以使用各种模态（包括文本、图像、视频等）来表达夸张。在本文中，我们专注于多模态夸张检测。我们从微博（中国的一种社交媒体）创建了一个多模态检测数据集，并对其进行了一些研究。我们将微博的文本和图像视为两种模态，探索了文本和图像在夸张检测中的作用。此外，我们还评估了不同预训练的多模态编码器在这个下游任务上的性能。由于这个数据集是从五个不同的主题构建的，我们还评估了不同领域之间的性能。

    Hyperbole, or exaggeration, is a common linguistic phenomenon. The detection of hyperbole is an important part of understanding human expression. There have been several studies on hyperbole detection, but most of which focus on text modality only. However, with the development of social media, people can create hyperbolic expressions with various modalities, including text, images, videos, etc. In this paper, we focus on multimodal hyperbole detection. We create a multimodal detection dataset\footnote{The dataset will be released to the community.} from Weibo (a Chinese social media) and carry out some studies on it. We treat the text and image from a piece of weibo as two modalities and explore the role of text and image for hyperbole detection. Different pre-trained multimodal encoders are also evaluated on this downstream task to show their performance. Besides, since this dataset is constructed from five different topics, we also evaluate the cross-domain performance of different 
    
[^13]: 通用零件组装规划

    General Part Assembly Planning. (arXiv:2307.00206v1 [cs.RO])

    [http://arxiv.org/abs/2307.00206](http://arxiv.org/abs/2307.00206)

    本论文研究了通用零件组装的问题，提出了一种基于Transformer的模型架构GPAT，能够准确预测零件的姿态并具有泛化能力。

    

    自主机器人组装领域的大多数成功都局限于单个目标或者单一类别。我们提出研究通用零件组装，即使用未见过的零件形状创建新颖目标组装的任务。为了解决通用零件组装的规划问题，我们提出了通用零件组装Transformer（GPAT），这是一种基于Transformer模型的架构，通过推断每个零件形状如何对应目标形状，准确预测零件的姿态。我们在3D CAD模型和现实世界扫描数据上进行的实验表明，GPAT具有对新颖和多样化的目标和零件形状的泛化能力。

    Most successes in autonomous robotic assembly have been restricted to single target or category. We propose to investigate general part assembly, the task of creating novel target assemblies with unseen part shapes. To tackle the planning of general part assembly, we present General Part Assembly Transformer (GPAT), a transformer based model architecture that accurately predicts part poses by inferring how each part shape corresponds to the target shape. Our experiments on both 3D CAD models and real-world scans demonstrate GPAT's generalization abilities to novel and diverse target and part shapes. Project website: https://general-part-assembly.github.io/
    
[^14]: 一种可解释的增量随机权重神经网络及其应用的构造算法

    An Interpretable Constructive Algorithm for Incremental Random Weight Neural Networks and Its Application. (arXiv:2307.00185v1 [cs.LG])

    [http://arxiv.org/abs/2307.00185](http://arxiv.org/abs/2307.00185)

    本文提出了一种可解释的增量随机权重神经网络的构造算法，通过几何信息约束和节点池策略解决了难以解释隐藏参数与残差误差之间关系的问题。这种算法在大规模数据建模任务中表现出了良好的性能。

    

    增量随机权重神经网络(IRWNNs)由于易于实现和快速学习而受到关注。然而，IRWNNs的一个显著缺点是难以解释隐藏参数（节点）与残差误差（模型性能）之间的关系。为了解决这个问题，本文提出了一个具有几何信息约束的可解释的构造算法(ICA)。首先，基于隐藏参数与残差误差之间的几何关系，提出了一个可解释的几何信息约束来随机分配隐藏参数。同时，采用节点池策略获取更有利于收敛的隐藏参数。此外，证明了ICA的通用逼近性质。最后，提出了ICA的轻量级版本用于大规模数据建模任务。在六个基准数据集上的实验结果表明了该算法的有效性。

    Incremental random weight neural networks (IRWNNs) have gained attention in view of its easy implementation and fast learning. However, a significant drawback of IRWNNs is that the elationship between the hidden parameters (node)and the residual error (model performance) is difficult to be interpreted. To address the above issue, this article proposes an interpretable constructive algorithm (ICA) with geometric information constraint. First, based on the geometric relationship between the hidden parameters and the residual error, an interpretable geometric information constraint is proposed to randomly assign the hidden parameters. Meanwhile, a node pool strategy is employed to obtain hidden parameters that is more conducive to convergence from hidden parameters satisfying the proposed constraint. Furthermore, the universal approximation property of the ICA is proved. Finally, a lightweight version of ICA is presented for large-scale data modeling tasks. Experimental results on six ben
    
[^15]: 大型语言模型中的人格特质

    Personality Traits in Large Language Models. (arXiv:2307.00184v1 [cs.CL])

    [http://arxiv.org/abs/2307.00184](http://arxiv.org/abs/2307.00184)

    该研究介绍了一种综合方法，用于验证大型语言模型（LLMs）生成的文本中展示的人格特质。研究发现，部分LLMs在特定提示配置下模拟的人格可靠且有效，特别是对于更大和经过指导微调的模型。此外，LLMs的输出中的人格特质可以根据需要进行塑造。

    

    大型语言模型（LLMs）的出现彻底改变了自然语言处理，使得能够生成连贯且上下文相关的文本。随着LLMs越来越多地用于驱动对话代理，这些模型通过训练大量人工生成的数据获得的人格特质引起了人们的关注。由于人格是决定交流效果的重要因素，我们提出了一种全面的方法来进行验证的心理测量测试，并对从广泛使用的LLMs生成的文本中展示的人格特质进行量化、分析和塑造。我们发现：1）某些LLMs的输出中模拟的人格（在特定的提示配置下）是可靠和有效的；2）LLM模拟的人格的可靠性和有效性的证据对于更大的和经过指导微调的模型更强；3）LLM输出中的人格可以根据需要的维度进行塑造，以模仿特定的人格特点。

    The advent of large language models (LLMs) has revolutionized natural language processing, enabling the generation of coherent and contextually relevant text. As LLMs increasingly power conversational agents, the synthesized personality embedded in these models by virtue of their training on large amounts of human-generated data draws attention. Since personality is an important factor determining the effectiveness of communication, we present a comprehensive method for administering validated psychometric tests and quantifying, analyzing, and shaping personality traits exhibited in text generated from widely-used LLMs. We find that: 1) personality simulated in the outputs of some LLMs (under specific prompting configurations) is reliable and valid; 2) evidence of reliability and validity of LLM-simulated personality is stronger for larger and instruction fine-tuned models; and 3) personality in LLM outputs can be shaped along desired dimensions to mimic specific personality profiles. 
    
[^16]: 整数线性规划推理手册

    The Integer Linear Programming Inference Cookbook. (arXiv:2307.00171v1 [cs.AI])

    [http://arxiv.org/abs/2307.00171](http://arxiv.org/abs/2307.00171)

    本论文介绍了一个整数线性规划推理手册，用于将推理问题转化为整数线性规划实例。通过一系列技巧的演示，帮助读者理解如何应用这些方法。论文最后提供了两个示例以说明这些技巧的使用。

    

    多年来，整数线性规划已被用于模拟自然语言处理问题中的推理。本调查旨在指导读者将新的推理问题框架化为整数线性规划的实例，并以一系列的技巧进行组织。最后，我们将通过两个实例来说明这些技巧的使用。

    Over the years, integer linear programs have been employed to model inference in many natural language processing problems. This survey is meant to guide the reader through the process of framing a new inference problem as an instance of an integer linear program and is structured as a collection of recipes. At the end, we will see two worked examples to illustrate the use of these recipes.
    
[^17]: VoxWatch: VoxCeleb上的开放式演讲者识别基准。 (arXiv:2307.00169v1 [eess.AS])

    VoxWatch: An open-set speaker recognition benchmark on VoxCeleb. (arXiv:2307.00169v1 [eess.AS])

    [http://arxiv.org/abs/2307.00169](http://arxiv.org/abs/2307.00169)

    本研究提出了一个针对VoxCeleb的开放式演讲者识别基准，并探讨了处理观察名单大小对检测性能影响的技术。

    

    尽管开放式演讲者识别（OSI）在欺诈预防等广泛实际应用中具有广泛的应用，但与演讲者验证（SV）相比，演讲者识别社区对其关注较少。 OSI涉及确定测试语音样本是否属于一组预先注册的个体（内部集）的演讲者，或者是否来自一个外部集演讲者。除了与语音变异相关的典型挑战外，OSI还容易出现“误报问题”；随着内部集演讲者人口（也称为观察名单）的增加，外部集分数变大，导致误报率增加。这对金融机构和边境安全等应用尤为具有挑战性，其中观察名单的大小通常为几千个演讲者。因此，系统地量化误报问题并开发减轻观察名单大小对检测性能影响的技术是重要的。以前的研究

    Despite its broad practical applications such as in fraud prevention, open-set speaker identification (OSI) has received less attention in the speaker recognition community compared to speaker verification (SV). OSI deals with determining if a test speech sample belongs to a speaker from a set of pre-enrolled individuals (in-set) or if it is from an out-of-set speaker. In addition to the typical challenges associated with speech variability, OSI is prone to the "false-alarm problem"; as the size of the in-set speaker population (a.k.a watchlist) grows, the out-of-set scores become larger, leading to increased false alarm rates. This is in particular challenging for applications in financial institutions and border security where the watchlist size is typically of the order of several thousand speakers. Therefore, it is important to systematically quantify the false-alarm problem, and develop techniques that alleviate the impact of watchlist size on detection performance. Prior studies 
    
[^18]: FFPDG: 快速、公平和私密的数据生成

    FFPDG: Fast, Fair and Private Data Generation. (arXiv:2307.00161v1 [cs.LG])

    [http://arxiv.org/abs/2307.00161](http://arxiv.org/abs/2307.00161)

    提出了一种快速、公平、灵活和私密的数据生成方法，可以在真实应用场景下表现良好。

    

    生成建模经常被用于合成数据生成。公平性和隐私权是合成数据面临的两个大问题。尽管最近的基于GAN的方法在保护隐私方面表现良好，但生成的数据可能更具偏见。与此同时，这些方法需要高计算资源。在这项工作中，我们设计了一种快速、公平、灵活和私密的数据生成方法。我们理论上和实践上证明了我们方法的有效性。我们展示了通过该方法生成的数据训练的模型在真实应用场景下（推断阶段）表现良好。

    Generative modeling has been used frequently in synthetic data generation. Fairness and privacy are two big concerns for synthetic data. Although Recent GAN [\cite{goodfellow2014generative}] based methods show good results in preserving privacy, the generated data may be more biased. At the same time, these methods require high computation resources. In this work, we design a fast, fair, flexible and private data generation method. We show the effectiveness of our method theoretically and empirically. We show that models trained on data generated by the proposed method can perform well (in inference stage) on real application scenarios.
    
[^19]: Stitched ViTs是灵活的视觉骨干网络

    Stitched ViTs are Flexible Vision Backbones. (arXiv:2307.00154v1 [cs.CV])

    [http://arxiv.org/abs/2307.00154](http://arxiv.org/abs/2307.00154)

    本研究通过拼接预训练模型族群，提出了SN-Netv2，它是一个灵活的视觉骨干网络框架，可以在运行时实现多样性的性能和效率权衡。

    

    大型预训练的普通视觉Transformer（ViTs）已成为许多下游任务的主力。然而，利用现成的ViTs的现有工作在训练和部署方面效率低下，因为采用不同大小的ViTs需要单独训练，并受到固定的性能-效率权衡的限制。在本文中，我们受到可拼接神经网络的启发，这是一个通过拼接预训练模型族群来快速生成涵盖丰富子网络的单一模型的新框架，支持在运行时的多样性性能-效率权衡。在此基础上，我们引入了SN-Netv2，这是一个系统改进的模型拼接框架，用于促进下游任务的适应。具体而言，我们首先提出了一个双向拼接方案来扩大拼接空间。然后，我们设计了一个考虑空间中底层FLOPs分布的资源受限采样策略，以改善采样质量。最后，我们对SN-Netv2进行了细微调整来进一步提高性能和效率。

    Large pretrained plain vision Transformers (ViTs) have been the workhorse for many downstream tasks. However, existing works utilizing off-the-shelf ViTs are inefficient in terms of training and deployment, because adopting ViTs with individual sizes requires separate training and is restricted by fixed performance-efficiency trade-offs. In this paper, we are inspired by stitchable neural networks, which is a new framework that cheaply produces a single model that covers rich subnetworks by stitching pretrained model families, supporting diverse performance-efficiency trade-offs at runtime. Building upon this foundation, we introduce SN-Netv2, a systematically improved model stitching framework to facilitate downstream task adaptation. Specifically, we first propose a Two-way stitching scheme to enlarge the stitching space. We then design a resource-constrained sampling strategy that takes into account the underlying FLOPs distributions in the space for improved sampling. Finally, we o
    
[^20]: 用于自动化编程作业反馈的大型语言模型（GPT）

    Large Language Models (GPT) for automating feedback on programming assignments. (arXiv:2307.00150v1 [cs.HC])

    [http://arxiv.org/abs/2307.00150](http://arxiv.org/abs/2307.00150)

    本研究使用OpenAI的GPT-3.5模型自动生成编程作业的个性化提示，该提示被学生们评价为有用。实验组在启用GPT提示的任务中表现出更好的提交成功率，同时减少对平台常规反馈的依赖。对于无法使用GPT提示的任务，实验组学生解决作业所需的时间也较少。

    

    针对生成个性化编程作业反馈的挑战，由于代码语法的复杂性和正确解决任务的不同方法等多个因素，要求很高。在这个实验研究中，我们使用OpenAI的GPT-3.5模型自动化了反馈生成的过程，为学生在一个自动评估平台上解决编程作业生成个性化提示。学生对GPT生成的提示的有用性进行了积极评价。实验组（启用了GPT提示）在任务中的连续尝试中，提交成功的百分比表现更好，但对平台的常规反馈依赖较少。对于不可用GPT反馈的任务，实验组解决作业所需的时间显著较少。此外，当GPT提示不可用时，实验组学生初始对解决作业的可能性较低。

    Addressing the challenge of generating personalized feedback for programming assignments is demanding due to several factors, like the complexity of code syntax or different ways to correctly solve a task. In this experimental study, we automated the process of feedback generation by employing OpenAI's GPT-3.5 model to generate personalized hints for students solving programming assignments on an automated assessment platform. Students rated the usefulness of GPT-generated hints positively. The experimental group (with GPT hints enabled) relied less on the platform's regular feedback but performed better in terms of percentage of successful submissions across consecutive attempts for tasks, where GPT hints were enabled. For tasks where the GPT feedback was made unavailable, the experimental group needed significantly less time to solve assignments. Furthermore, when GPT hints were unavailable, students in the experimental condition were initially less likely to solve the assignment cor
    
[^21]: 一个通过人机交互学习和创造新的早餐选择的个性化家庭辅助机器人

    A Personalized Household Assistive Robot that Learns and Creates New Breakfast Options through Human-Robot Interaction. (arXiv:2307.00114v1 [cs.RO])

    [http://arxiv.org/abs/2307.00114](http://arxiv.org/abs/2307.00114)

    本文提出了一个认知架构，用于个性化家庭辅助机器人通过人机交互学习并创造新的早餐选择。

    

    为了帮助用户完成家务任务，机器人首先必须从用户那里学习任务。此外，每天以相同方式执行相同任务会让机器人的使用者感到无趣，因此辅助机器人必须找到创造性的方法来完成家务任务。在本文中，我们提出了一个认知架构，借助此架构，家庭辅助机器人能够从用户那里学习个性化的早餐选择，并使用所学知识来准备早餐。该架构还可以利用所学知识在较长时间内创建新的早餐选择。所提出的认知架构结合了最先进的感知学习算法、计算实施的认知记忆编码和学习的模型、一个用于在家庭中拾取和放置物体的任务规划器、与用户交互的图形用户界面(GUI)以及使用所学知识创建新早餐选择的新方法。

    For robots to assist users with household tasks, they must first learn about the tasks from the users. Further, performing the same task every day, in the same way, can become boring for the robot's user(s), therefore, assistive robots must find creative ways to perform tasks in the household. In this paper, we present a cognitive architecture for a household assistive robot that can learn personalized breakfast options from its users and then use the learned knowledge to set up a table for breakfast. The architecture can also use the learned knowledge to create new breakfast options over a longer period of time. The proposed cognitive architecture combines state-of-the-art perceptual learning algorithms, computational implementation of cognitive models of memory encoding and learning, a task planner for picking and placing objects in the household, a graphical user interface (GUI) to interact with the user and a novel approach for creating new breakfast options using the learned knowl
    
[^22]: ChatGPT在USMLE上的表现：为AI辅助医学教育开启大型语言模型的潜力

    Performance of ChatGPT on USMLE: Unlocking the Potential of Large Language Models for AI-Assisted Medical Education. (arXiv:2307.00112v1 [cs.CY])

    [http://arxiv.org/abs/2307.00112](http://arxiv.org/abs/2307.00112)

    这项研究评估了ChatGPT在回答复杂医学问题上的可靠性，发现其生成的答案更加注重上下文并具有较高的可靠性。

    

    人工智能正在以前所未有的方式获得越来越多的关注。自从OpenAI发布ChatGPT以来，语言模型和基于AI的业务的流行度大幅增长。人们在职业和个人生活中越来越普遍地使用ChatGPT。考虑到ChatGPT的广泛使用和人们对其的依赖，本研究旨在确定ChatGPT在回答复杂医学和临床问题上的可靠性。该研究使用哈佛大学解剖学知识和美国医学执照考试（USMLE）问卷来实现目标。本文使用双因素方差分析和事后分析评估了获得的结果。两者都显示出格式和提示之间的系统协变。此外，医生评估者还对结果的准确性、一致性和洞察力进行了独立评价。分析结果发现，ChatGPT生成的答案更加注重上下文并且具有较高的可靠性。

    Artificial intelligence is gaining traction in more ways than ever before. The popularity of language models and AI-based businesses has soared since ChatGPT was made available to the general public via OpenAI. It is becoming increasingly common for people to use ChatGPT both professionally and personally. Considering the widespread use of ChatGPT and the reliance people place on it, this study determined how reliable ChatGPT can be for answering complex medical and clinical questions. Harvard University gross anatomy along with the United States Medical Licensing Examination (USMLE) questionnaire were used to accomplish the objective. The paper evaluated the obtained results using a 2-way ANOVA and posthoc analysis. Both showed systematic covariation between format and prompt. Furthermore, the physician adjudicators independently rated the outcome's accuracy, concordance, and insight. As a result of the analysis, ChatGPT-generated answers were found to be more context-oriented and rep
    
[^23]: Ticket-BERT:使用语言模型为事件管理票据进行标注

    Ticket-BERT: Labeling Incident Management Tickets with Language Models. (arXiv:2307.00108v1 [cs.CL])

    [http://arxiv.org/abs/2307.00108](http://arxiv.org/abs/2307.00108)

    Ticket-BERT是一个使用语言模型为事件管理票据进行标注的方法，在解决复杂的票据数据和时间敏感性问题方面具有优势。

    

    对于解决优先级事件票据的一个重要方面是高效地使用精细分类来标注这些票据。然而，票据数据通常很复杂，给现代机器学习方法带来了几个独特的挑战：（1）票据既可以由预定义算法的机器生成，也可以由具有不同协议的具有领域专业知识的工程师更新和创建，（2）票据频繁进行修订，通过修改全部或部分票据描述来更新票据状态，（3）票据标注是时间敏感的，需要根据软件和硬件改进的快速生命周期进行知识更新和新的标签。为了解决这些问题，我们介绍了Ticket-BERT，它使用我们提出的票据数据集训练了一个简单但健壮的语言模型来为票据进行标注。实验证明，Ticket-BERT在Azure认知服务上优于基线和最先进的文本分类器。我们进一步将Ticket-BERT封装到一个积极的le...

    An essential aspect of prioritizing incident tickets for resolution is efficiently labeling tickets with fine-grained categories. However, ticket data is often complex and poses several unique challenges for modern machine learning methods: (1) tickets are created and updated either by machines with pre-defined algorithms or by engineers with domain expertise that share different protocols, (2) tickets receive frequent revisions that update ticket status by modifying all or parts of ticket descriptions, and (3) ticket labeling is time-sensitive and requires knowledge updates and new labels per the rapid software and hardware improvement lifecycle. To handle these issues, we introduce Ticket- BERT which trains a simple yet robust language model for labeling tickets using our proposed ticket datasets. Experiments demonstrate the superiority of Ticket-BERT over baselines and state-of-the-art text classifiers on Azure Cognitive Services. We further encapsulate Ticket-BERT with an active le
    
[^24]: 通过对无人机捕捉的烟雾模式的时间分析来检测被遮挡的野火火焰

    Obscured Wildfire Flame Detection By Temporal Analysis of Smoke Patterns Captured by Unmanned Aerial Systems. (arXiv:2307.00104v1 [cs.CV])

    [http://arxiv.org/abs/2307.00104](http://arxiv.org/abs/2307.00104)

    本论文通过对视频序列中烟雾模式的时间分析，提出了一种用于实时检测被遮挡的野火火焰的方法，通过预测火灾位置来帮助无人机对抗森林火灾。这种方法具有独特的检测被遮挡的火灾的能力。

    

    本研究论文解决了使用仅配备RGB相机的无人机实时检测被树木、烟雾、云雾和其他自然屏障遮挡的野火（当火焰被遮挡时）的挑战。我们提出了一种新的方法，利用视频序列中烟雾模式的语义分割进行时间分析。我们的方法利用了基于深度卷积神经网络的编码器-解码器架构，采用预训练的CNN编码器和3D卷积进行解码，并使用特征的顺序叠加来利用时间变化。预测的火灾位置可以帮助无人机有效地对抗森林火灾，并准确定位火焰位置进行阻燃化学物质投放。我们将我们的方法应用于从FLAME2数据集衍生的精选数据集，该数据集包括RGB视频和IR视频以确定地面真实情况。我们提出的方法具有检测被遮挡的火灾的独特属性，并实现了一种Dice系数。

    This research paper addresses the challenge of detecting obscured wildfires (when the fire flames are covered by trees, smoke, clouds, and other natural barriers) in real-time using drones equipped only with RGB cameras. We propose a novel methodology that employs semantic segmentation based on the temporal analysis of smoke patterns in video sequences. Our approach utilizes an encoder-decoder architecture based on deep convolutional neural network architecture with a pre-trained CNN encoder and 3D convolutions for decoding while using sequential stacking of features to exploit temporal variations. The predicted fire locations can assist drones in effectively combating forest fires and pinpoint fire retardant chemical drop on exact flame locations. We applied our method to a curated dataset derived from the FLAME2 dataset that includes RGB video along with IR video to determine the ground truth. Our proposed method has a unique property of detecting obscured fire and achieves a Dice sc
    
[^25]: 同志人群首先是人：解构大型语言模型中的性别认同刻板印象

    Queer People are People First: Deconstructing Sexual Identity Stereotypes in Large Language Models. (arXiv:2307.00101v1 [cs.CL])

    [http://arxiv.org/abs/2307.00101](http://arxiv.org/abs/2307.00101)

    本文通过比较研究了大型语言模型（LLMs）在生成描述不同性别认同的人的文本时产生的偏见问题，发现存在对同志人群的偏见。研究者提出了一种基于SHAP分析的思维链触发的事后方法，可以增加句子的regard，为去除LLMs输出偏见提供了一个有希望的途径。

    

    大型语言模型（LLMs）主要在经过最小化处理的网络文本上进行训练，这些文本展现了创建该内容的人们所持有的各种社会偏见。因此，LLMs生成的文本可能无意中将刻板印象传递给边缘化群体，如LGBTQIA+社群。本文对LLMs生成描述具有不同性别认同的人的文本进行了比较研究。使用regard分数分析文本中的偏见显示出存在对同志人群的可测量偏见。然后，我们展示了一种基于SHAP分析的思维链触发的事后方法可以增加句子的regard，这代表了解决此类情况下LLMs输出偏见的一个有希望的方法。

    Large Language Models (LLMs) are trained primarily on minimally processed web text, which exhibits the same wide range of social biases held by the humans who created that content. Consequently, text generated by LLMs can inadvertently perpetuate stereotypes towards marginalized groups, like the LGBTQIA+ community. In this paper, we perform a comparative study of how LLMs generate text describing people with different sexual identities. Analyzing bias in the text generated by an LLM using regard score shows measurable bias against queer people. We then show that a post-hoc method based on chain-of-thought prompting using SHAP analysis can increase the regard of the sentence, representing a promising approach towards debiasing the output of LLMs in this setting.
    
[^26]: 多智能体空间交互的定性预测

    Qualitative Prediction of Multi-Agent Spatial Interactions. (arXiv:2307.00065v1 [cs.AI])

    [http://arxiv.org/abs/2307.00065](http://arxiv.org/abs/2307.00065)

    本文提出了三种新方法，用于预测密集场景中的多智能体交互，其中包括使用直观的定性表示。这些方法利用了输入和时间关注机制，并结合了定性轨迹计算和深度神经网络，采用符号驱动的神经结构进行预测，实现了较好的效果。

    

    在餐厅、仓库或医院等日常生活中部署服务机器人需要对密集和动态场景中发生的交互进行推理。本文提出并对三种新的方法进行了基准测试，用于建模和预测密集场景中的多智能体交互，包括使用直观的定性表示。所提出的解决方案考虑了静态和动态的上下文来预测个体之间的交互。它们利用了输入和时间关注机制，并在中长期时间范围内进行了测试。前两种方法将称为定性轨迹计算(QTC)的不同关系与最先进的深度神经网络相结合，创建了一个符号驱动的神经结构，用于预测空间交互。第三种方法实现了一种纯数据驱动的网络用于运动预测，该网络的输出经过后期处理以预测QTC空间交互。实验结果表明...

    Deploying service robots in our daily life, whether in restaurants, warehouses or hospitals, calls for the need to reason on the interactions happening in dense and dynamic scenes. In this paper, we present and benchmark three new approaches to model and predict multi-agent interactions in dense scenes, including the use of an intuitive qualitative representation. The proposed solutions take into account static and dynamic context to predict individual interactions. They exploit an input- and a temporal-attention mechanism, and are tested on medium and long-term time horizons. The first two approaches integrate different relations from the so-called Qualitative Trajectory Calculus (QTC) within a state-of-the-art deep neural network to create a symbol-driven neural architecture for predicting spatial interactions. The third approach implements a purely data-driven network for motion prediction, the output of which is post-processed to predict QTC spatial interactions. Experimental resul
    
[^27]: DisCo: 用于现实世界中基于人类舞蹈的引用生成的解耦控制

    DisCo: Disentangled Control for Referring Human Dance Generation in Real World. (arXiv:2307.00040v1 [cs.CV])

    [http://arxiv.org/abs/2307.00040](http://arxiv.org/abs/2307.00040)

    这篇论文提出了一个新的问题设置：引用人类舞蹈生成。在现实世界的舞蹈场景中，通过解耦控制来解决舞蹈合成中的挑战，包括忠实性、泛化能力和组合性。

    

    生成AI在计算机视觉领域取得了显著的进展，特别是在基于文本描述的图像/视频合成方面。尽管有了这些进步，但在生成人类中心内容（如舞蹈合成）方面仍然存在挑战。现有的舞蹈合成方法在合成内容与现实世界舞蹈场景之间存在差距。在本文中，我们定义了一个新的问题设置：引用人类舞蹈生成，重点关注具有三个重要属性的现实世界舞蹈场景：（i）忠实性：合成应该保留引用图像中人类主体前景和背景的外观，并精确地遵循目标姿势；（ii）泛化能力：模型应该适用于未见过的人类主体、背景和姿势；（iii）组合性：它应该允许来自不同来源的已见/未见主体、背景和姿势的组合。为了应对这些挑战，我们引入了一种新颖的方法，D

    Generative AI has made significant strides in computer vision, particularly in image/video synthesis conditioned on text descriptions. Despite the advancements, it remains challenging especially in the generation of human-centric content such as dance synthesis. Existing dance synthesis methods struggle with the gap between synthesized content and real-world dance scenarios. In this paper, we define a new problem setting: Referring Human Dance Generation, which focuses on real-world dance scenarios with three important properties: (i) Faithfulness: the synthesis should retain the appearance of both human subject foreground and background from the reference image, and precisely follow the target pose; (ii) Generalizability: the model should generalize to unseen human subjects, backgrounds, and poses; (iii) Compositionality: it should allow for composition of seen/unseen subjects, backgrounds, and poses from different sources. To address these challenges, we introduce a novel approach, D
    
[^28]: 以脑启发设计解决人工神经网络的不足之处

    Towards Brain Inspired Design for Addressing the Shortcomings of ANNs. (arXiv:2307.00039v1 [cs.NE])

    [http://arxiv.org/abs/2307.00039](http://arxiv.org/abs/2307.00039)

    本研究通过对比人工神经网络和小脑中基于错误的神经元组织方式，发现在人工神经网络中引入个性化错误视图的神经元群体可以提高学习效率、减少不平衡数据和捷径策略的影响，从而提高泛化能力。

    

    随着对大脑功能机制的理解提高，从神经科学中获得的洞察力对于AI算法的发展值得进一步考虑。本文通过将一种基于树状结构的人工神经网络架构与最近的神经科学研究[27]进行对比，认为小脑中基于错误的神经元组织方式可能是行为和学习的几个理想特征的原因。我们随后分析了模型在不同情景下的学习行为和特点，以评估类似机制在人工神经网络中的潜在好处。我们的实证结果表明，在个性化错误视图的神经元群体可以有效地在类别不平衡和有限数据情况下进行学习，并减少受意外捷径策略的影响，从而提高泛化能力。这项工作突出了将学习方式从神经科学中转化为人工神经网络中的潜力。

    As our understanding of the mechanisms of brain function is enhanced, the value of insights gained from neuroscience to the development of AI algorithms deserves further consideration. Here, we draw parallels with an existing tree-based ANN architecture and a recent neuroscience study[27] arguing that the error-based organization of neurons in the cerebellum that share a preference for a personalized view of the entire error space, may account for several desirable features of behavior and learning. We then analyze the learning behavior and characteristics of the model under varying scenarios to gauge the potential benefits of a similar mechanism in ANN. Our empirical results suggest that having separate populations of neurons with personalized error views can enable efficient learning under class imbalance and limited data, and reduce the susceptibility to unintended shortcut strategies, leading to improved generalization. This work highlights the potential of translating the learning
    
[^29]: 基于高斯过程贝叶斯推理的不确定性导向最优资源分配

    Uncertainty Informed Optimal Resource Allocation with Gaussian Process based Bayesian Inference. (arXiv:2307.00032v1 [math.OC])

    [http://arxiv.org/abs/2307.00032](http://arxiv.org/abs/2307.00032)

    本研究提出了一种基于高斯过程贝叶斯推理的数据驱动方法，用于将医疗资源（疫苗）不确定性导向地分配给异质人群以管理流行病传播。研究解决了参数估计和整合、非线性ODE约束和参数不确定性等问题。

    

    我们关注于将医疗资源（疫苗）不确定性导向地分配给异质人群以管理流行病传播的问题。我们解决了两个相关问题：（1）对于一个流行病传播的常微分方程（ODE）模型，我们如何在资源分配决策中估计和整合参数不确定性？（2）对于一个通用的随机优化问题（资源分配）如何计算处理非线性ODE约束和参数不确定性？据我们所知，当前的文献无法完全解决这些问题。在这里，我们提出了一种数据驱动的方法，在新的随机优化问题表达式中准确而可行地表示参数不确定性。我们首先使用高斯过程进行贝叶斯推理来估计ODE模型参数的分布，从而生成可行的情景集。然后，我们开发了一个并行化的解算算法，考虑到情景和参数不确定性。

    We focus on the problem of uncertainty informed allocation of medical resources (vaccines) to heterogeneous populations for managing epidemic spread. We tackle two related questions: (1) For a compartmental ordinary differential equation (ODE) model of epidemic spread, how can we estimate and integrate parameter uncertainty into resource allocation decisions? (2) How can we computationally handle both nonlinear ODE constraints and parameter uncertainties for a generic stochastic optimization problem for resource allocation? To the best of our knowledge current literature does not fully resolve these questions. Here, we develop a data-driven approach to represent parameter uncertainty accurately and tractably in a novel stochastic optimization problem formulation. We first generate a tractable scenario set by estimating the distribution on ODE model parameters using Bayesian inference with Gaussian processes. Next, we develop a parallelized solution algorithm that accounts for scenario-
    
[^30]: 通过语言瓶颈学习分类的“看见文字”论文

    Seeing in Words: Learning to Classify through Language Bottlenecks. (arXiv:2307.00028v1 [cs.CV])

    [http://arxiv.org/abs/2307.00028](http://arxiv.org/abs/2307.00028)

    本文提出了一种通过语言瓶颈学习分类的方法，利用文本表示特征的视觉模型能够有效分类ImageNet图像，可以增加神经网络的可解释性。

    

    尽管计算机视觉的神经网络在基准测试中取得了高准确性，但它们提取的特征往往是无法解释的。相比之下，人类可以用简洁直观的描述来解释他们的预测。为了将可解释性引入神经网络，我们训练了一个将特征表示为文本的视觉模型。我们展示了这样的模型在对ImageNet图像进行分类时的有效性，并讨论了我们在训练过程中遇到的挑战。

    Neural networks for computer vision extract uninterpretable features despite achieving high accuracy on benchmarks. In contrast, humans can explain their predictions using succinct and intuitive descriptions. To incorporate explainability into neural networks, we train a vision model whose feature representations are text. We show that such a model can effectively classify ImageNet images, and we discuss the challenges we encountered when training it.
    
[^31]: CASEIN: 层层级联的显式和隐式控制用于细粒度情感强度调节

    CASEIN: Cascading Explicit and Implicit Control for Fine-grained Emotion Intensity Regulation. (arXiv:2307.00020v1 [cs.SD])

    [http://arxiv.org/abs/2307.00020](http://arxiv.org/abs/2307.00020)

    CASEIN是一个层层级联的显式和隐式控制框架，通过准确解离参考语音中的情感流形，学习低语义级别的隐式表示。在实验中，CASEIN在可控性和自然度方面超过了现有方法，首次实现了对多种情感强度的细粒度控制。

    

    现有的细粒度情感强度调节方法依赖于通过预测的情感概率进行显式控制。然而，这些高层语义概率在音素级别上往往不准确且不平滑，导致学习中存在偏差。特别是当我们尝试在特定音素中混合多种情感强度时，会导致合成的可控性和自然度明显降低。为了解决这个问题，我们提出了一种名为“CASEIN”的层层级联的显式和隐式控制框架，该框架通过准确解离参考语音中情感流形，学习低语义级别的隐式表示。这种表示桥接了显式概率和合成模型之间的语义差距，减少了学习中的偏差。在实验中，我们的CASEIN在可控性和自然度方面超过了现有方法。值得注意的是，我们是第一个实现多种情感强度混合的细粒度控制的方法。

    Existing fine-grained intensity regulation methods rely on explicit control through predicted emotion probabilities. However, these high-level semantic probabilities are often inaccurate and unsmooth at the phoneme level, leading to bias in learning. Especially when we attempt to mix multiple emotion intensities for specific phonemes, resulting in markedly reduced controllability and naturalness of the synthesis. To address this issue, we propose the CAScaded Explicit and Implicit coNtrol framework (CASEIN), which leverages accurate disentanglement of emotion manifolds from the reference speech to learn the implicit representation at a lower semantic level. This representation bridges the semantical gap between explicit probabilities and the synthesis model, reducing bias in learning. In experiments, our CASEIN surpasses existing methods in both controllability and naturalness. Notably, we are the first to achieve fine-grained control over the mixed intensity of multiple emotions.
    
[^32]: 惯性导航与深度学习：当前趋势与未来方向的综述

    Inertial Navigation Meets Deep Learning: A Survey of Current Trends and Future Directions. (arXiv:2307.00014v1 [cs.RO])

    [http://arxiv.org/abs/2307.00014](http://arxiv.org/abs/2307.00014)

    本文综述了惯性导航领域中当前的深度学习方法，包括对不同车辆操作领域的研究、滤波参数学习的改进以及惯性传感器的校准和去噪方法。翻译过的论文标题: 惯性导航与深度学习：当前趋势与未来方向的综述

    

    惯性传感在许多应用和平台中被使用，从智能手机等日常设备到自动驾驶车辆等复杂设备。近年来，机器学习和深度学习技术在惯性传感领域取得了显著发展。这是由于高效的计算硬件的发展和公开可用的传感器数据的可获得性。这些数据驱动的方法被用于强化基于模型的导航和传感器融合算法。本文提供了对这些深度学习方法的深入综述。我们分别考察了每个车辆操作领域，包括陆地、空中和海洋。每个领域分为纯惯性进展和基于滤波参数学习的改进。此外，我们还回顾了用于校准和去噪惯性传感器的深度学习方法。在整篇论文中，我们讨论了这些趋势和未来方向。我们还提供了常用的统计数据。

    Inertial sensing is used in many applications and platforms, ranging from day-to-day devices such as smartphones to very complex ones such as autonomous vehicles. In recent years, the development of machine learning and deep learning techniques has increased significantly in the field of inertial sensing. This is due to the development of efficient computing hardware and the accessibility of publicly available sensor data. These data-driven approaches are used to empower model-based navigation and sensor fusion algorithms. This paper provides an in-depth review of those deep learning methods. We examine separately, each vehicle operation domain including land, air, and sea. Each domain is divided into pure inertial advances and improvements based on filter parameters learning. In addition, we review deep learning approaches for calibrating and denoising inertial sensors. Throughout the paper, we discuss these trends and future directions. We also provide statistics on the commonly used
    
[^33]: 使用语言模型的黑盒预测易出错测试修复类别

    Black-Box Prediction of Flaky Test Fix Categories Using Language Models. (arXiv:2307.00012v1 [cs.SE])

    [http://arxiv.org/abs/2307.00012](http://arxiv.org/abs/2307.00012)

    本文提出了一个使用语言模型的框架，可以自动生成易出错测试的标记数据集，并通过分析测试代码来预测测试的修复类别。实验结果表明UniXcoder优于CodeBERT。

    

    易出错测试会在相同软件版本的测试下非确定性地通过或失败，引起混乱并浪费开发者时间。尽管机器学习模型已经被用于预测易出错性及其根本原因，但在提供修复支持方面仍有较少工作。为了填补这一空白，我们提出了一个框架，通过仅分析测试代码自动生成13个修复类别的标记数据集，并训练模型来预测易出错测试的修复类别。虽然在当前阶段准确预测修复本身是不现实的，但这些类别提供了关于需要检查的测试代码部分的精确指导。我们的方法基于语言模型，即CodeBERT和UniXcoder，其输出经过前馈神经网络（FNN）或基于孪生网络的Few Shot Learning（FSL）进行了微调。我们的实验结果表明，UniXcoder在正确预测大多数修复类别方面表现优于CodeBERT。

    Flaky tests are problematic because they non-deterministically pass or fail for the same software version under test, causing confusion and wasting developer time. While machine learning models have been used to predict flakiness and its root causes, there is less work on providing support to fix the problem. To address this gap, we propose a framework that automatically generates labeled datasets for 13 fix categories and train models to predict the fix category of a flaky test by analyzing the test code only. Though it is unrealistic at this stage to accurately predict the fix itself, the categories provide precise guidance about what part of the test code to look at. Our approach is based on language models, namely CodeBERT and UniXcoder, whose output is fine-tuned with a Feed Forward Neural Network (FNN) or a Siamese Network-based Few Shot Learning (FSL). Our experimental results show that UniXcoder outperforms CodeBERT, in correctly predicting most of the categories of fixes a dev
    
[^34]: 探索基于掩码的数据生成在语言模型中的应用

    Investigating Masking-based Data Generation in Language Models. (arXiv:2307.00008v1 [cs.CL])

    [http://arxiv.org/abs/2307.00008](http://arxiv.org/abs/2307.00008)

    本研究探索了基于掩码的数据生成在语言模型中的应用，结果表明该方法可以提高模型性能。

    

    当BERT问世以来，当前自然语言处理（NLP）的时代已经被预训练语言模型的重要性所定义。BERT和类似结构的模型的一个特点是掩码语言建模的目标，其中部分输入被有意地掩盖，模型被训练以预测这部分被掩码的信息。数据增强是一种数据驱动的技术，广泛应用于机器学习，包括计算机视觉和自然语言处理等研究领域，通过指定的技术人工增加训练数据集以改善模型性能。掩码语言模型（MLM）是BERT的一个重要训练特点，它为基于Transformer的模型在自然语言处理任务中提供了有效的预训练方法。最近的研究利用掩码语言模型生成人工增强数据用于NLP下游任务。实验结果表明，基于掩码的数据增强可以提高模型性能。

    The current era of natural language processing (NLP) has been defined by the prominence of pre-trained language models since the advent of BERT. A feature of BERT and models with similar architecture is the objective of masked language modeling, in which part of the input is intentionally masked and the model is trained to predict this piece of masked information. Data augmentation is a data-driven technique widely used in machine learning, including research areas like computer vision and natural language processing, to improve model performance by artificially augmenting the training data set by designated techniques. Masked language models (MLM), an essential training feature of BERT, have introduced a novel approach to perform effective pre-training on Transformer based models in natural language processing tasks. Recent studies have utilized masked language model to generate artificially augmented data for NLP downstream tasks. The experimental results show that Mask based data au
    
[^35]: 通过平滑周期高斯Copula模型建模光伏电站群

    PV Fleet Modeling via Smooth Periodic Gaussian Copula. (arXiv:2307.00004v1 [stat.AP])

    [http://arxiv.org/abs/2307.00004](http://arxiv.org/abs/2307.00004)

    本文提出了一种通过平滑周期高斯Copula模型联合建模光伏系统群发电的方法，该方法可以捕捉数据的昼夜变化、系统间的依赖关系和随时间的依赖关系。通过该模型可以进行合成数据生成、缺失数据填补、异常检测和预测。

    

    我们提出了一种联合建模光伏（PV）系统群的发电方法。我们提出了一种白盒方法，它可以找到一个函数，可以将矢量时间序列数据映射为独立同分布的标准正态变量。基于一种新颖的方法来拟合平滑周期Copula变换到数据，该方法可以捕捉到数据的许多方面，如功率输出分布的昼夜变化、不同PV系统之间的依赖关系以及随时间的依赖关系。它由可解释的步骤组成，并且可扩展到许多系统。通过系统和时间的光伏电站群联合概率模型可以用来生成合成数据、填补缺失数据、进行异常检测和进行预测。本文中，我们解释了该方法并展示了这些应用。

    We present a method for jointly modeling power generation from a fleet of photovoltaic (PV) systems. We propose a white-box method that finds a function that invertibly maps vector time-series data to independent and identically distributed standard normal variables. The proposed method, based on a novel approach for fitting a smooth, periodic copula transform to data, captures many aspects of the data such as diurnal variation in the distribution of power output, dependencies among different PV systems, and dependencies across time. It consists of interpretable steps and is scalable to many systems. The resulting joint probability model of PV fleet output across systems and time can be used to generate synthetic data, impute missing data, perform anomaly detection, and make forecasts. In this paper, we explain the method and demonstrate these applications.
    
[^36]: Sphere2Vec：一种适用于大规模地理空间预测的球面上通用位置表示学习方法

    Sphere2Vec: A General-Purpose Location Representation Learning over a Spherical Surface for Large-Scale Geospatial Predictions. (arXiv:2306.17624v1 [cs.CV])

    [http://arxiv.org/abs/2306.17624](http://arxiv.org/abs/2306.17624)

    Sphere2Vec是一种多尺度位置编码器，用于在球面上编码点坐标时保持球面距离，解决了大规模真实世界GPS坐标数据集中的距离度量问题。

    

    在机器学习中，为空间中的点生成适合学习的表示是一个基本且长期存在的问题。最近，提出了多尺度编码方案（如Space2Vec和NeRF），可以直接将二维/三维欧几里得空间中的任意点编码为高维向量，并成功应用于各种地理空间预测和生成任务。然而，目前所有的二维和三维位置编码器都是设计用来模拟欧几里得空间中的点距离。因此，在应用于需要在球面上进行距离度量学习的大规模真实世界GPS坐标数据集时，这两种类型的模型都会出现问题，原因是地图投影失真问题（2D）和球面到欧几里得距离近似误差（3D）。为了解决这些问题，我们提出了一种称为Sphere2Vec的多尺度位置编码器，可以在球面上编码点坐标时保持球面距离。我们在球面上的位置编码的距离保持编码的统一视角上进行了探索。

    Generating learning-friendly representations for points in space is a fundamental and long-standing problem in ML. Recently, multi-scale encoding schemes (such as Space2Vec and NeRF) were proposed to directly encode any point in 2D/3D Euclidean space as a high-dimensional vector, and has been successfully applied to various geospatial prediction and generative tasks. However, all current 2D and 3D location encoders are designed to model point distances in Euclidean space. So when applied to large-scale real-world GPS coordinate datasets, which require distance metric learning on the spherical surface, both types of models can fail due to the map projection distortion problem (2D) and the spherical-to-Euclidean distance approximation error (3D). To solve these problems, we propose a multi-scale location encoder called Sphere2Vec which can preserve spherical distances when encoding point coordinates on a spherical surface. We developed a unified view of distance-reserving encoding on sph
    
[^37]: LMBot: 将图形知识融入语言模型以进行无图形部署的推特机器人检测

    LMBot: Distilling Graph Knowledge into Language Model for Graph-less Deployment in Twitter Bot Detection. (arXiv:2306.17408v1 [cs.AI])

    [http://arxiv.org/abs/2306.17408](http://arxiv.org/abs/2306.17408)

    LMBot是一种新颖的推特机器人检测框架，将图神经网络的知识融入到语言模型中，实现了无图形部署，以解决数据依赖性的挑战。

    

    随着恶意行为者使用越来越先进和广泛的机器人来传播错误信息和操纵舆论，推特机器人的检测已成为一项至关重要的任务。尽管基于图形的推特机器人检测方法取得了最先进的性能，但我们发现它们的推理依赖于距离目标用户多跳的邻居用户，并且获取邻居用户是耗时的，并可能引入偏差。与此同时，我们发现在推特机器人检测上微调后，预训练的语言模型在竞争性性能方面取得了良好的表现，并且在部署过程中不需要图形结构。受到这一发现的启发，我们提出了一种新颖的机器人检测框架LMBot，它将图神经网络(GNNs)的知识融入语言模型(LMs)，以在推特机器人检测中进行无图形部署，以应对数据依赖性的挑战。此外，LMBot对基于图形和不使用图形的数据集兼容。具体而言，我们首先将每个用户表示为一段文本

    As malicious actors employ increasingly advanced and widespread bots to disseminate misinformation and manipulate public opinion, the detection of Twitter bots has become a crucial task. Though graph-based Twitter bot detection methods achieve state-of-the-art performance, we find that their inference depends on the neighbor users multi-hop away from the targets, and fetching neighbors is time-consuming and may introduce bias. At the same time, we find that after finetuning on Twitter bot detection, pretrained language models achieve competitive performance and do not require a graph structure during deployment. Inspired by this finding, we propose a novel bot detection framework LMBot that distills the knowledge of graph neural networks (GNNs) into language models (LMs) for graph-less deployment in Twitter bot detection to combat the challenge of data dependency. Moreover, LMBot is compatible with graph-based and graph-less datasets. Specifically, we first represent each user as a tex
    
[^38]: 基于加权CapsuleNet网络的阿拉伯语和波斯语多领域情感分析方法

    Presenting an approach based on weighted CapsuleNet networks for Arabic and Persian multi-domain sentiment analysis. (arXiv:2306.17068v1 [cs.CL])

    [http://arxiv.org/abs/2306.17068](http://arxiv.org/abs/2306.17068)

    本文提出了一种基于加权胶囊网络的阿拉伯语和波斯语多领域情感分析方法，通过训练单独的胶囊网络并使用加权度量来实现情感分类，具有较好的准确性和适应性。

    

    情感分类是自然语言处理中的基本任务，对自由文本进行正面、负面或中性的分类。然而，情感分类模型高度依赖于领域，分类器在一个领域中可能具有合理的准确性，但在另一个领域中由于词语的语义多重性而准确率较低。本文提出了一种新的波斯语/阿拉伯语多领域情感分析方法，使用累积加权胶囊网络的方法。加权胶囊集合由为每个领域训练的单独的胶囊网络和称为领域所属度（DBD）的加权度量组成。这个度量由TF和IDF组成，计算每个文档对于每个领域的依赖关系，然后乘以每个胶囊创建的可能输出。最终，这些乘积的总和是最终输出的标签，并用于确定极性。

    Sentiment classification is a fundamental task in natural language processing, assigning one of the three classes, positive, negative, or neutral, to free texts. However, sentiment classification models are highly domain dependent; the classifier may perform classification with reasonable accuracy in one domain but not in another due to the Semantic multiplicity of words getting poor accuracy. This article presents a new Persian/Arabic multi-domain sentiment analysis method using the cumulative weighted capsule networks approach. Weighted capsule ensemble consists of training separate capsule networks for each domain and a weighting measure called domain belonging degree (DBD). This criterion consists of TF and IDF, which calculates the dependency of each document for each domain separately; this value is multiplied by the possible output that each capsule creates. In the end, the sum of these multiplications is the title of the final output, and is used to determine the polarity. And 
    
[^39]: 使用时间集成改进在线连续学习性能和稳定性

    Improving Online Continual Learning Performance and Stability with Temporal Ensembles. (arXiv:2306.16817v1 [cs.LG])

    [http://arxiv.org/abs/2306.16817](http://arxiv.org/abs/2306.16817)

    该研究通过模型集成方法改进了在线连续学习的性能和稳定性，通过综合利用来自不同训练任务的模型，显著提高了在线连续学习的表现。

    

    当神经网络在大型数据集上进行大量迭代训练时，它们非常有效。然而，当它们在非平稳的数据流和在线方式下进行训练时，其性能会下降：(1)在线设置限制了数据的可用性，(2)由于数据的非平稳性导致灾难性遗忘。此外，几篇最近的文章表明连续学习中使用的重放方法在模型持续评估时存在稳定性差距。在本文中，我们研究了模型集成作为改进在线连续学习性能和稳定性的一种方法。我们观察到，简单地集成来自各种训练任务的模型显著提高了在线连续学习的性能。基于这一观察，并从半监督学习中获取灵感，我们提出了一种改进的连续学习框架，该框架综合利用了显式和隐式知识。

    Neural networks are very effective when trained on large datasets for a large number of iterations. However, when they are trained on non-stationary streams of data and in an online fashion, their performance is reduced (1) by the online setup, which limits the availability of data, (2) due to catastrophic forgetting because of the non-stationary nature of the data. Furthermore, several recent works (Caccia et al., 2022; Lange et al., 2023) arXiv:2205.1345(2) showed that replay methods used in continual learning suffer from the stability gap, encountered when evaluating the model continually (rather than only on task boundaries). In this article, we study the effect of model ensembling as a way to improve performance and stability in online continual learning. We notice that naively ensembling models coming from a variety of training tasks increases the performance in online continual learning considerably. Starting from this observation, and drawing inspirations from semi-supervised l
    
[^40]: GraMMaR: 用于3D人体运动重建的地面感知运动模型

    GraMMaR: Ground-aware Motion Model for 3D Human Motion Reconstruction. (arXiv:2306.16736v1 [cs.CV])

    [http://arxiv.org/abs/2306.16736](http://arxiv.org/abs/2306.16736)

    提出了一种用于3D人体运动重建的地面感知运动模型（GraMMaR），通过学习姿势和关节与地面之间的互动的过渡分布，明确促进运动和与地面距离变化之间的一致性。

    

    对于准确和真实的从RGB视频中重建3D人体运动，解密复杂的人地互动对于保证人类和地面之间的一致性至关重要。以往的方法要么隐式地模拟人地互动，要么以稀疏的方式模拟，往往在面对噪声和不确定性时导致不真实和不正确的运动。相反，我们的方法以一种密集和连续的方式明确表示这些互动。为此，我们提出了一种新颖的用于3D人体运动重建的地面感知运动模型，称为GraMMaR，它在运动序列中每个时间步骤中同时学习姿势和每个关节与地面之间的互动的过渡分布。它被训练用于明确促进运动和与地面距离变化之间的一致性。训练后，我们建立了一种联合优化策略，利用GraMMaR作为双重先验，规范优化过程朝着

    Demystifying complex human-ground interactions is essential for accurate and realistic 3D human motion reconstruction from RGB videos, as it ensures consistency between the humans and the ground plane. Prior methods have modeled human-ground interactions either implicitly or in a sparse manner, often resulting in unrealistic and incorrect motions when faced with noise and uncertainty. In contrast, our approach explicitly represents these interactions in a dense and continuous manner. To this end, we propose a novel Ground-aware Motion Model for 3D Human Motion Reconstruction, named GraMMaR, which jointly learns the distribution of transitions in both pose and interaction between every joint and ground plane at each time step of a motion sequence. It is trained to explicitly promote consistency between the motion and distance change towards the ground. After training, we establish a joint optimization strategy that utilizes GraMMaR as a dual-prior, regularizing the optimization towards 
    
[^41]: NNQS-Transformer: 一种高效可扩展的神经网络量子态方法用于从头计算量子化学

    NNQS-Transformer: an Efficient and Scalable Neural Network Quantum States Approach for Ab initio Quantum Chemistry. (arXiv:2306.16705v1 [quant-ph])

    [http://arxiv.org/abs/2306.16705](http://arxiv.org/abs/2306.16705)

    NNQS-Transformer是一种高效可扩展的神经网络量子态方法，用于从头计算量子化学。其主要创新包括基于Transformer的量子波函数安萨茨、数据中心并行化方案、并行批量采样策略和并行局域能量评估方案。研究结果显示了与最先进方法相比的优越精度和对于大分子系统的强可扩展性和弱可扩展性。

    

    神经网络量子态（NNQS）已成为量子多体问题的有希望的候选方法，但其实际应用常受到采样和局域能量计算的高成本的限制。我们开发了一种高性能的NNQS方法，用于从头电子结构计算。主要创新包括：（1）将Transformer作为量子波函数的安萨茨；（2）一种以数据为中心的并行化方案，用于变分蒙特卡洛（VMC）算法，可以保持数据的局部性并适应不同的计算架构；（3）一种并行批量采样策略，降低采样成本并实现良好的负载平衡；（4）一种既具有内存又具有计算效率的并行局域能量评估方案；（5）对真实化学系统的研究表明，我们的方法相比最先进方法具有更高的精度，并且对于具有高达120个自旋的大分子系统具有很强的可扩展性和弱可扩展性。

    Neural network quantum state (NNQS) has emerged as a promising candidate for quantum many-body problems, but its practical applications are often hindered by the high cost of sampling and local energy calculation. We develop a high-performance NNQS method for \textit{ab initio} electronic structure calculations. The major innovations include: (1) A transformer based architecture as the quantum wave function ansatz; (2) A data-centric parallelization scheme for the variational Monte Carlo (VMC) algorithm which preserves data locality and well adapts for different computing architectures; (3) A parallel batch sampling strategy which reduces the sampling cost and achieves good load balance; (4) A parallel local energy evaluation scheme which is both memory and computationally efficient; (5) Study of real chemical systems demonstrates both the superior accuracy of our method compared to state-of-the-art and the strong and weak scalability for large molecular systems with up to $120$ spin o
    
[^42]: 可分离的物理信息神经网络

    Separable Physics-Informed Neural Networks. (arXiv:2306.15969v1 [cs.LG])

    [http://arxiv.org/abs/2306.15969](http://arxiv.org/abs/2306.15969)

    这项研究提出了一种可分离的物理信息神经网络（SPINN），通过逐个处理轴来显著减少了多维 PDE 中的网络传播数量，并使用正向模式自动微分降低了计算成本，使得可以在单个普通 GPU 上使用大量的配点。

    

    物理信息神经网络(PINNs)最近已经成为有希望的基于数据的PDE求解器，在各种PDE上显示出令人鼓舞的结果。然而，训练PINNs来解决多维PDE和逼近高度复杂解函数存在根本限制。在这些具有挑战性的PDE上所需的训练点数量(配点)大大增加，但由于昂贵的计算成本和庞大的内存开销，其受到严重限制。为了解决这个问题，我们提出了一种用于PINNs的网络架构和训练算法。所提出的方法，可分离的PINN (SPINN)，在多维PDE中按轴逐个处理，从而显著减少了网络传播的数量，不同于传统PINNs中的逐点处理。我们还提出使用正向模式自动微分来降低计算PDE残差的计算成本，从而在单个普通GPU上可以使用大量的配点(>10^7)。

    Physics-informed neural networks (PINNs) have recently emerged as promising data-driven PDE solvers showing encouraging results on various PDEs. However, there is a fundamental limitation of training PINNs to solve multi-dimensional PDEs and approximate highly complex solution functions. The number of training points (collocation points) required on these challenging PDEs grows substantially, but it is severely limited due to the expensive computational costs and heavy memory overhead. To overcome this issue, we propose a network architecture and training algorithm for PINNs. The proposed method, separable PINN (SPINN), operates on a per-axis basis to significantly reduce the number of network propagations in multi-dimensional PDEs unlike point-wise processing in conventional PINNs. We also propose using forward-mode automatic differentiation to reduce the computational cost of computing PDE residuals, enabling a large number of collocation points (>10^7) on a single commodity GPU. The
    
[^43]: SparseOptimizer: 通过Moreau-Yosida正则化来降低语言模型的稀疏性，并通过编译器共同设计来加速

    SparseOptimizer: Sparsify Language Models through Moreau-Yosida Regularization and Accelerate through Compiler Co-design. (arXiv:2306.15656v1 [cs.LG])

    [http://arxiv.org/abs/2306.15656](http://arxiv.org/abs/2306.15656)

    SparseOptimizer是一种深度学习优化器，通过Moreau-Yosida正则化在大型语言模型中引入稀疏性。它采用嵌入的收缩操作符，无需对代码进行修改即可适应各种大型语言模型，并在各种基准数据集上实现与密集型模型相当的性能，同时减少参数数量。

    

    本文介绍了SparseOptimizer，一种新颖的深度学习优化器，通过Moreau-Yosida正则化在大型语言模型（如BERT，ALBERT和GPT）中自然地引入稀疏性。SparseOptimizer设计的关键是嵌入的收缩操作符，它在优化过程中直接引入稀疏性。这个操作符通过坚实的理论框架支持，并包含了一个分析解，从而增强了优化器的鲁棒性和效果。重要的是，SparseOptimizer的即插即用功能消除了对代码修改的需求，使其成为适用于各种大型语言模型的通用适应工具。在GLUE、RACE、SQuAD1和SQuAD2等基准数据集上的实证评估表明，通过SparseOptimizer稀疏化后的SparseBERT和SparseALBERT在性能上与密集型的BERT和ALBERT相当，同时显著减少了参数数量。

    This paper introduces SparseOptimizer, a novel deep learning optimizer that exploits Moreau-Yosida regularization to naturally induce sparsity in large language models such as BERT, ALBERT and GPT. Key to the design of SparseOptimizer is an embedded shrinkage operator, which imparts sparsity directly within the optimization process. This operator, backed by a sound theoretical framework, includes an analytical solution, thereby reinforcing the optimizer's robustness and efficacy. Crucially, SparseOptimizer's plug-and-play functionality eradicates the need for code modifications, making it a universally adaptable tool for a wide array of large language models. Empirical evaluations on benchmark datasets such as GLUE, RACE, SQuAD1, and SQuAD2 confirm that SparseBERT and SparseALBERT, when sparsified using SparseOptimizer, achieve performance comparable to their dense counterparts, BERT and ALBERT, while significantly reducing their parameter count. Further, this work proposes an innovati
    
[^44]: 从仅状态序列学习非马尔科夫决策

    Learning non-Markovian Decision-Making from State-only Sequences. (arXiv:2306.15156v1 [cs.LG])

    [http://arxiv.org/abs/2306.15156](http://arxiv.org/abs/2306.15156)

    本文提出了一种从仅状态序列学习非马尔科夫决策的方法，通过深度生成建模和最大似然估计实现基于模型的模仿。学习的模型能够实现“推理式决策”，并在路径规划任务中展示了有效性。

    

    传统的模仿学习假设能够获得展示者的动作，但是在自然环境中这些动作通常无法观测。此外，在这些环境中的序列决策行为可能偏离标准马尔科夫决策过程（MDP）的假设。为了解决这些挑战，我们探索了非马尔科夫决策过程（nMDP）中仅状态序列的深度生成建模，其中策略是潜在状态转移生成器的能量先验。我们开发了最大似然估计来实现基于模型的模仿，其中包括对先验进行短期MCMC采样和对后验进行重要性采样。学习的模型实现了“推理式决策”，即无模型策略执行等价于先验采样，基于模型的规划则是从策略初始化的后验采样。我们在一个具有非马尔科夫特征的原型路径规划任务中证明了所提方法的有效性。

    Conventional imitation learning assumes access to the actions of demonstrators, but these motor signals are often non-observable in naturalistic settings. Additionally, sequential decision-making behaviors in these settings can deviate from the assumptions of a standard Markov Decision Process (MDP). To address these challenges, we explore deep generative modeling of state-only sequences with non-Markov Decision Process (nMDP), where the policy is an energy-based prior in the latent space of the state transition generator. We develop maximum likelihood estimation to achieve model-based imitation, which involves short-run MCMC sampling from the prior and importance sampling for the posterior. The learned model enables \textit{decision-making as inference}: model-free policy execution is equivalent to prior sampling, model-based planning is posterior sampling initialized from the policy. We demonstrate the efficacy of the proposed method in a prototypical path planning task with non-Mark
    
[^45]: G-NM：一组数字时间序列预测模型

    G-NM: A Group of Numerical Time Series Prediction Models. (arXiv:2306.11667v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.11667](http://arxiv.org/abs/2306.11667)

    G-NM是一组集合了传统和现代模型的数字时间序列预测模型，旨在提高对复杂自然现象中的模式和趋势的预测能力。

    

    本研究聚焦于开发和实施一个综合的数字时间序列预测模型集合，统称为数字时间序列预测模型组（G-NM）。该集合包括传统模型如自回归综合移动平均（ARIMA）、Holt-Winters方法和支持向量回归（SVR），以及现代神经网络模型，如循环神经网络（RNN）和长短期记忆（LSTM）。G-NM明确构建以增强我们对复杂自然现象中固有模式和趋势的预测能力。通过利用与这些事件相关的时间序列数据，G-NM便于对此类现象在延长时间段内进行预测。本研究的主要目标是推进我们对此类事件的理解，并大幅提高预测准确性。G-NM包括线性和非线性依赖关系，以及季节性趋势。

    In this study, we focus on the development and implementation of a comprehensive ensemble of numerical time series forecasting models, collectively referred to as the Group of Numerical Time Series Prediction Model (G-NM). This inclusive set comprises traditional models such as Autoregressive Integrated Moving Average (ARIMA), Holt-Winters' method, and Support Vector Regression (SVR), in addition to modern neural network models including Recurrent Neural Network (RNN) and Long Short-Term Memory (LSTM). G-NM is explicitly constructed to augment our predictive capabilities related to patterns and trends inherent in complex natural phenomena. By utilizing time series data relevant to these events, G-NM facilitates the prediction of such phenomena over extended periods. The primary objective of this research is to both advance our understanding of such occurrences and to significantly enhance the accuracy of our forecasts. G-NM encapsulates both linear and non-linear dependencies, seasonal
    
[^46]: 基于注意力知识图卷积网络的旅游景点推荐

    Tourist Attractions Recommendation based on Attention Knowledge Graph Convolution Network. (arXiv:2306.10946v1 [cs.IR] CROSS LISTED)

    [http://arxiv.org/abs/2306.10946](http://arxiv.org/abs/2306.10946)

    本文提出了一种基于注意力知识图卷积网络的旅游景点推荐模型，通过自动语义发掘目标景点的相邻实体，根据旅客的喜好选择，预测类似景点的概率，实验中取得良好效果。

    

    基于知识图谱的推荐算法在相对成熟阶段，但在特定领域的推荐仍存在问题。例如在旅游领域，选择适合的旅游景点属性流程作为推荐基础较为复杂。本文提出改进的注意力知识图卷积网络模型(Att-KGCN)，自动语义地发掘目标景点的相邻实体，利用注意力层将相对相似的位置进行聚合，并通过推理旅客喜好选择，预测类似景点的概率作为推荐系统。实验中，采用索科特拉岛-也门的旅游数据，证明了注意力知识图卷积网络在旅游领域的景点推荐效果良好。

    The recommendation algorithm based on knowledge graphs is at a relatively mature stage. However, there are still some problems in the recommendation of specific areas. For example, in the tourism field, selecting suitable tourist attraction attributes process is complicated as the recommendation basis for tourist attractions. In this paper, we propose the improved Attention Knowledge Graph Convolution Network model, named (Att-KGCN), which automatically discovers the neighboring entities of the target scenic spot semantically. The attention layer aggregates relatively similar locations and represents them with an adjacent vector. Then, according to the tourist's preferred choices, the model predicts the probability of similar spots as a recommendation system. A knowledge graph dataset of tourist attractions used based on tourism data on Socotra Island-Yemen. Through experiments, it is verified that the Attention Knowledge Graph Convolution Network has a good effect on the recommendatio
    
[^47]: 基于HRNet的康复监测系统

    A HRNet-based Rehabilitation Monitoring System. (arXiv:2306.10756v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2306.10756](http://arxiv.org/abs/2306.10756)

    该论文介绍了一种基于HRNet的康复监测系统，旨在通过智能手机进行康复训练的管理。患者可以通过系统进行应用程序来进行训练，而治疗师可以通过服务器端进行进度的监测。

    

    康复治疗有助于治愈轻微的体育和职业伤害。传统的康复过程中，治疗师会指定某些动作供患者在医院访问之间执行，这将依赖于患者正确地记住动作和执行计划。不幸的是，许多患者会忘记执行动作或无法详细回想动作。因此，康复治疗受到阻碍，或者在最坏的情况下，患者可能会因执行不正确的动作而遭受额外的伤害。为了解决这些问题，我们提出了一种基于HRNet的康复监测系统，它可以通过患者的智能手机提醒患者何时执行动作并展示动作供患者跟随。此外，它还帮助治疗师监测患者的康复进展。我们的系统由一款iOS应用程序和几个服务器组件组成。该应用程序负责显示...

    The rehabilitation treatment helps to heal minor sports and occupational injuries. In a traditional rehabilitation process, a therapist will assign certain actions to a patient to perform in between hospital visits, and it will rely on the patient to remember actions correctly and the schedule to perform them. Unfortunately, many patients forget to perform actions or fail to recall actions in detail. As a consequence, the rehabilitation treatment is hampered or, in the worst case, the patient may suffer from additional injury caused by performing incorrect actions. To resolve these issues, we propose a HRNet-based rehabilitation monitoring system, which can remind a patient when to perform the actions and display the actions for the patient to follow via the patient's smartphone. In addition, it helps the therapist to monitor the progress of the rehabilitation for the patient. Our system consists of an iOS app and several components at the server side. The app is in charge of displayin
    
[^48]: 基于竞争多智能体搜索的演化策略

    Evolving Strategies for Competitive Multi-Agent Search. (arXiv:2306.10640v2 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2306.10640](http://arxiv.org/abs/2306.10640)

    本文研究了基于竞争多智能体搜索的演化策略，通过实验验证了进化计算可以用于发现在不同竞争环境中的有效搜索策略。

    

    虽然进化计算适用于工程领域的自动发现，但它也可用于揭示人类和组织如何更有效地执行任务。通过以组织中的创新搜索问题为例，本文首先将人类创造性问题解决形式化为竞争多智能体搜索（CMAS）。CMAS不同于现有的单智能体和团队搜索问题，因为智能体通过了解其他智能体的搜索情况以及这些搜索导致的搜索景观的动态变化来进行交互。主要假设是，进化计算可以用于发现CMAS的有效策略；该假设在一系列关于NK模型的实验中得到验证，即部分相关且可调整崎岖的适应度景观。不同的专门策略针对每个不同的竞争环境进行了演化，同时还演化出了表现良好的通用策略。

    While evolutionary computation is well suited for automatic discovery in engineering, it can also be used to gain insight into how humans and organizations could perform more effectively. Using a real-world problem of innovation search in organizations as the motivating example, this article first formalizes human creative problem solving as competitive multi-agent search (CMAS). CMAS is different from existing single-agent and team search problems in that the agents interact through knowledge of other agents' searches and through the dynamic changes in the search landscape that result from these searches. The main hypothesis is that evolutionary computation can be used to discover effective strategies for CMAS; this hypothesis is verified in a series of experiments on the NK model, i.e.\ partially correlated and tunably rugged fitness landscapes. Different specialized strategies are evolved for each different competitive environment, and also general strategies that perform well acros
    
[^49]: 我们能相信AI生成的教育内容吗？人工智能和人类生成的学习资源的比较分析

    Can We Trust AI-Generated Educational Content? Comparative Analysis of Human and AI-Generated Learning Resources. (arXiv:2306.10509v2 [cs.HC] UPDATED)

    [http://arxiv.org/abs/2306.10509](http://arxiv.org/abs/2306.10509)

    AI-generated educational content has been found to be perceived as equivalent in quality to content created by students, suggesting that AI-generated resources may serve as viable learning materials.

    

    随着越来越多的学生转向提供个性化学习体验的在线学习平台，对高质量教育内容的需求日益增长。大型语言模型（LLMs）似乎为快速创建大规模学习材料提供了有希望的解决方案，减轻了教师的负担。在本研究中，我们通过比较LLMs生成的资源与学生作为学习来源的一部分创建的资源的质量，在入门编程语境下研究了LLMs生成学习资源的潜力。在受试者报告评估中，学生在初步提供相同示例后评估了AI和同学生成的资源的正确性和帮助程度。我们的结果表明，学生感知到的AI生成资源的质量与同学生成的资源的质量相当。这表明AI生成的资源可能作为辅助学习资料。

    As an increasing number of students move to online learning platforms that deliver personalized learning experiences, there is a great need for the production of high-quality educational content. Large language models (LLMs) appear to offer a promising solution to the rapid creation of learning materials at scale, reducing the burden on instructors. In this study, we investigated the potential for LLMs to produce learning resources in an introductory programming context, by comparing the quality of the resources generated by an LLM with those created by students as part of a learnersourcing activity. Using a blind evaluation, students rated the correctness and helpfulness of resources generated by AI and their peers, after both were initially provided with identical exemplars. Our results show that the quality of AI-generated resources, as perceived by students, is equivalent to the quality of resources generated by their peers. This suggests that AI-generated resources may serve as vi
    
[^50]: 分层结构领域自适应

    Taxonomy-Structured Domain Adaptation. (arXiv:2306.07874v1 [cs.LG])

    [http://arxiv.org/abs/2306.07874](http://arxiv.org/abs/2306.07874)

    本文提出了分层结构领域自适应方法，通过分层结构领域的形式化描述来缓解不同领域之间的分布偏移，该方法在合成和实际数据集上实现了最先进的性能。

    

    领域自适应旨在缓解不同领域之间的分布偏移。然而，传统的方法大多限于分类领域，这严重简化了真实世界中微妙的领域关系。在本文中，我们通过分层结构领域进行推广，将领域形式化为具有嵌套的层次相似结构，例如动物物种和产品目录。我们建立在经典对抗框架之上，并引入了一种新颖的分类器，该分类器与对抗性鉴别器竞争以保留层次结构信息。当给定非信息领域分类（例如，所有叶节点都链接到根节点的扁平分类）时，平衡点恢复经典的对抗领域适应解决方案，同时在其他分类中产生非平凡的结果。在合成和实际数据集上实证结果表明，我们的方法实现了最先进的性能，并成功进行了自适应。代码可在https://gith获得。

    Domain adaptation aims to mitigate distribution shifts among different domains. However, traditional formulations are mostly limited to categorical domains, greatly simplifying nuanced domain relationships in the real world. In this work, we tackle a generalization with taxonomy-structured domains, which formalizes domains with nested, hierarchical similarity structures such as animal species and product catalogs. We build on the classic adversarial framework and introduce a novel taxonomist, which competes with the adversarial discriminator to preserve the taxonomy information. The equilibrium recovers the classic adversarial domain adaptation's solution if given a non-informative domain taxonomy (e.g., a flat taxonomy where all leaf nodes connect to the root node) while yielding non-trivial results with other taxonomies. Empirically, our method achieves state-of-the-art performance on both synthetic and real-world datasets with successful adaptation. Code is available at https://gith
    
[^51]: 分子属性预测的自动化三维预训练

    Automated 3D Pre-Training for Molecular Property Prediction. (arXiv:2306.07812v1 [q-bio.QM])

    [http://arxiv.org/abs/2306.07812](http://arxiv.org/abs/2306.07812)

    通过在3D分子图上进行预训练，该论文提出了一种更有效地预测分子属性的方法，该方法可以在不需要分子几何结构的情况下进行微调。

    

    分子属性预测是药物研发和材料科学中的重要问题。由于分子的几何结构对于分子属性预测的必要性已经被证明，因此将3D信息与各种图形学习方法相结合以提高预测性能。然而，由于高计算成本，在许多现实应用中获得分子的几何结构是不可行的。在这项工作中，我们提出了一种新的3D预训练框架（称为3D PGT），它在3D分子图上预训练模型，然后在没有3D结构的分子图上进行微调。基于化学键长，化学键角和二面角这三个基本几何描述符对应于完整的分子3D构形，我们首先开发了一个基于这三个属性的多任务生成预训练框架。接下来，为了自动融合这三项生成任务，我们设计了一种使用“总能量”来搜索的替代指标。

    Molecular property prediction is an important problem in drug discovery and materials science. As geometric structures have been demonstrated necessary for molecular property prediction, 3D information has been combined with various graph learning methods to boost prediction performance. However, obtaining the geometric structure of molecules is not feasible in many real-world applications due to the high computational cost. In this work, we propose a novel 3D pre-training framework (dubbed 3D PGT), which pre-trains a model on 3D molecular graphs, and then fine-tunes it on molecular graphs without 3D structures. Based on fact that bond length, bond angle, and dihedral angle are three basic geometric descriptors corresponding to a complete molecular 3D conformer, we first develop a multi-task generative pre-train framework based on these three attributes. Next, to automatically fuse these three generative tasks, we design a surrogate metric using the \textit{total energy} to search for 
    
[^52]: V-LoL: 一种用于视觉逻辑学习的诊断数据集

    V-LoL: A Diagnostic Dataset for Visual Logical Learning. (arXiv:2306.07743v1 [cs.AI])

    [http://arxiv.org/abs/2306.07743](http://arxiv.org/abs/2306.07743)

    V-LoL是一个结合视觉和逻辑挑战的诊断数据集，其中包括了V-LoL-Trains，该数据集首次将复杂的视觉场景和灵活的逻辑推理任务结合起来，为研究广泛的视觉逻辑学习挑战提供了平台。

    

    尽管近期在视觉AI领域有了许多成功的进展，但仍存在不同的缺点；包括缺少精确的逻辑推理、抽象的概括能力以及理解复杂和嘈杂的场景等。不幸的是，现有的基准测试数据集并不能捕捉到这些方面中的多数。深度学习数据集关注视觉复杂数据但只有简单的视觉推理任务，归纳逻辑数据集包括复杂的逻辑学习任务，但是缺乏视觉的组成部分。为了解决这个问题，我们提出了视觉逻辑学习数据集V-LoL，它无缝地结合了视觉和逻辑的挑战。值得注意的是，我们首次推出了V-LoL的第一个实例，名为V-LoL-Trains，它是符号AI中一个经典基准测试的视觉呈现，即Michalski火车问题。通过在一个通用框架内结合复杂的视觉场景和灵活的逻辑推理任务，V-LoL-Trains为研究广泛的视觉逻辑学习挑战提供了平台。

    Despite the successes of recent developments in visual AI, different shortcomings still exist; from missing exact logical reasoning, to abstract generalization abilities, to understanding complex and noisy scenes. Unfortunately, existing benchmarks, were not designed to capture more than a few of these aspects. Whereas deep learning datasets focus on visually complex data but simple visual reasoning tasks, inductive logic datasets involve complex logical learning tasks, however, lack the visual component. To address this, we propose the visual logical learning dataset, V-LoL, that seamlessly combines visual and logical challenges. Notably, we introduce the first instantiation of V-LoL, V-LoL-Trains, -- a visual rendition of a classic benchmark in symbolic AI, the Michalski train problem. By incorporating intricate visual scenes and flexible logical reasoning tasks within a versatile framework, V-LoL-Trains provides a platform for investigating a wide range of visual logical learning ch
    
[^53]: 医学成像的人工通用智能

    Artificial General Intelligence for Medical Imaging. (arXiv:2306.05480v1 [cs.AI])

    [http://arxiv.org/abs/2306.05480](http://arxiv.org/abs/2306.05480)

    本文探讨了人工通用智能模型在医学成像中的应用，重点关注基础的大型语言、视觉和多模态模型。通过整合临床专业知识、领域知识和多模态能力来开发和部署AGI能够解决医学领域面临的挑战和问题。

    

    本文探讨了人工通用智能模型在医疗保健中的潜在应用，重点关注基础的大型语言模型、大型视觉模型和大型多模态模型。我们强调将临床专业知识、领域知识和多模态能力整合到AGI模型中的重要性。此外，我们提出了指导医疗保健AGI模型开发和部署的路线图。在整个综述过程中，我们提供了关于在医学领域部署大规模AGI模型可能面临的潜在挑战和缺陷的关键观点。这篇综合性的综述旨在提供有关AGI对医学成像、医疗保健和其他领域未来影响的见解。

    In this review, we explore the potential applications of Artificial General Intelligence (AGI) models in healthcare, focusing on foundational Large Language Models (LLMs), Large Vision Models, and Large Multimodal Models. We emphasize the importance of integrating clinical expertise, domain knowledge, and multimodal capabilities into AGI models. In addition, we lay out key roadmaps that guide the development and deployment of healthcare AGI models. Throughout the review, we provide critical perspectives on the potential challenges and pitfalls associated with deploying large-scale AGI models in the medical field. This comprehensive review aims to offer insights into the future implications of AGI in medical imaging, healthcare and beyond.
    
[^54]: 基于分布特征匹配的标签偏移量量化及其鲁棒性保证

    Label Shift Quantification with Robustness Guarantees via Distribution Feature Matching. (arXiv:2306.04376v1 [stat.ML])

    [http://arxiv.org/abs/2306.04376](http://arxiv.org/abs/2306.04376)

    本文提出一种名为DFM框架的方法，用于量化标签偏移，并证明了其性能上限和鲁棒性。使用基于核的DFM版本可以提高效率、可扩展性和鲁棒性。

    

    量化学习处理在标签偏移下估计目标标签分布的任务。本文首先提出了一个统一的框架，分布特征匹配（DFM），将先前文献中引入的各种估计器恢复为特定实例。我们推导了DFM程序的一般性能界，改进了先前在特定情况下推导的界限的若干关键方面。然后，我们将这一分析扩展到研究DFM程序在未精确假设标签偏移量的情况下的鲁棒性，特别是在目标受到未知分布污染的情况下。这些理论发现在模拟和实际数据集上得到了详细的数字研究确认。我们还使用随机傅里叶特征原理介绍了一种高效，可扩展且具有鲁棒性的基于核的DFM版本。

    Quantification learning deals with the task of estimating the target label distribution under label shift. In this paper, we first present a unifying framework, distribution feature matching (DFM), that recovers as particular instances various estimators introduced in previous literature. We derive a general performance bound for DFM procedures, improving in several key aspects upon previous bounds derived in particular cases. We then extend this analysis to study robustness of DFM procedures in the misspecified setting under departure from the exact label shift hypothesis, in particular in the case of contamination of the target by an unknown distribution. These theoretical findings are confirmed by a detailed numerical study on simulated and real-world datasets. We also introduce an efficient, scalable and robust version of kernel-based DFM using the Random Fourier Feature principle.
    
[^55]: 从人类虚拟现实演示中驱动的机器人程序综合

    Knowledge-Driven Robot Program Synthesis from Human VR Demonstrations. (arXiv:2306.02739v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2306.02739](http://arxiv.org/abs/2306.02739)

    本文提出了一种从人类虚拟现实（VR）任务演示中自动生成可执行机器人控制程序的系统。通过利用常识知识和基于游戏引擎的物理学进行语义解释，并结合通用任务表示和自动路径规划和代码生成算法，实现了机器人购物助手的力敏抓取和放置任务。

    

    人口老化、劳动力短缺和不断增加的工资成本需要能够自主执行各种真实世界任务的辅助机器人。这种开放式机器人操作不仅需要强大的知识表示和推理（KR＆R）算法，还需要人们教导机器人执行任务和如何执行任务的方法。本文提出了一种从人类虚拟现实（VR）任务演示中自动生成可执行机器人控制程序的系统。我们利用常识知识和基于游戏引擎的物理学来语义化解释人类虚拟现实演示，以及用于表达和自动路径规划和代码生成的通用任务表示和最先进认知架构上的嵌入。我们在机器人购物助手的力敏抓取和放置环境中演示了我们的方法。源代码可在https://github.com/ease-crc/vr-program-synthesis找到。

    Aging societies, labor shortages and increasing wage costs call for assistance robots capable of autonomously performing a wide array of real-world tasks. Such open-ended robotic manipulation requires not only powerful knowledge representations and reasoning (KR&R) algorithms, but also methods for humans to instruct robots what tasks to perform and how to perform them. In this paper, we present a system for automatically generating executable robot control programs from human task demonstrations in virtual reality (VR). We leverage common-sense knowledge and game engine-based physics to semantically interpret human VR demonstrations, as well as an expressive and general task representation and automatic path planning and code generation, embedded into a state-of-the-art cognitive architecture. We demonstrate our approach in the context of force-sensitive fetch-and-place for a robotic shopping assistant. The source code is available at https://github.com/ease-crc/vr-program-synthesis.
    
[^56]: LLM-Blender: 利用成对排名和生成融合集成大型语言模型

    LLM-Blender: Ensembling Large Language Models with Pairwise Ranking and Generative Fusion. (arXiv:2306.02561v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.02561](http://arxiv.org/abs/2306.02561)

    本论文提出了LLM-Blender，它是一个集成框架，旨在利用不同的开源大型语言模型的优秀特性，实现始终如一的卓越性能。PairRanker和GenFuser是该框架的两个模块，PairRanker使用成对比较方法来区分候选输出，并且GenFuser旨在合并排名最高的候选者，以生成改进的输出。

    

    本论文提出了LLM-Blender，一个集成框架，旨在通过利用多个开源大型语言模型（LLMs）的不同优势来达到始终如一的卓越性能。我们的框架由两个模块组成：PairRanker和GenFuser，以应对不同示例的最优LLMs可以显着变化的观察。PairRanker使用专门的成对比较方法来区分候选输出之间的微小差异。它联合编码输入文本和一对候选者，使用交叉注意编码器来确定优越者。我们的结果表明，PairRanker与ChatGPT的排名相关性最高。然后，GenFuser旨在合并排名最高的候选者，通过利用它们的优势和减少它们的弱点来生成改进的输出。为了促进大规模评估，我们介绍了一个基准数据集MixInstruct，它是多个指令数据集的混合，具有oracle p。

    We present LLM-Blender, an ensembling framework designed to attain consistently superior performance by leveraging the diverse strengths of multiple open-source large language models (LLMs). Our framework consists of two modules: PairRanker and GenFuser, addressing the observation that optimal LLMs for different examples can significantly vary. PairRanker employs a specialized pairwise comparison method to distinguish subtle differences between candidate outputs. It jointly encodes the input text and a pair of candidates, using cross-attention encoders to determine the superior one. Our results demonstrate that PairRanker exhibits the highest correlation with ChatGPT-based ranking. Then, GenFuser aims to merge the top-ranked candidates, generating an improved output by capitalizing on their strengths and mitigating their weaknesses. To facilitate large-scale evaluation, we introduce a benchmark dataset, MixInstruct, which is a mixture of multiple instruction datasets featuring oracle p
    
[^57]: 基于贝叶斯优化的桁架设计优化

    Optimization for truss design using Bayesian optimization. (arXiv:2306.01763v1 [stat.AP])

    [http://arxiv.org/abs/2306.01763](http://arxiv.org/abs/2306.01763)

    本文提出了利用贝叶斯优化算法进行桁架设计优化的方法，通过迭代评估候选设计并更新概率模型的方式优化桁架结构，该方法在优化复杂系统方面表现出有效性。

    

    本文提出了一种利用计算机辅助有限元分析进行机械桁架几何优化的方法。桁架的形状是确定其承载能力的主要因素。在给定的参数空间中，我们旨在找到最大化承载能力且不会产生应力的外壳参数。我们选择贝叶斯优化作为我们的优化框架，以解决这种昂贵计算的设计评估问题。通过利用贝叶斯优化算法，桁架设计涉及迭代评估一组候选桁架设计，并基于结果更新设计空间的概率模型。该模型用于预测每个候选设计的性能，下一个候选设计是基于模型对性能改进的预测。我们的结果表明，概率模型有助于评估桁架设计空间，并且贝叶斯优化是优化复杂系统的有效方法。

    In this work, geometry optimization of mechanical truss using computer-aided finite element analysis is presented. The shape of the truss is a dominant factor in determining the capacity of load it can bear. At a given parameter space, our goal is to find the parameters of a hull that maximize the load-bearing capacity and also don't yield to the induced stress. We rely on finite element analysis, which is a computationally costly design analysis tool for design evaluation. For such expensive to-evaluate functions, we chose Bayesian optimization as our optimization framework which has empirically proven sample efficient than other simulation-based optimization methods.  By utilizing Bayesian optimization algorithms, the truss design involves iteratively evaluating a set of candidate truss designs and updating a probabilistic model of the design space based on the results. The model is used to predict the performance of each candidate design, and the next candidate design is selected ba
    
[^58]: 离线训练，在线测试：一个真实的机器人学习基准

    Train Offline, Test Online: A Real Robot Learning Benchmark. (arXiv:2306.00942v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2306.00942](http://arxiv.org/abs/2306.00942)

    这是一个提供离线训练和在线测试的机器人学习基准系统，通过共享机器人硬件和开源数据集，解决了机器人学习研究中的挑战，并为未来的研究提供了方便和直接的比较方法。

    

    机器人学习研究受到三个挑战的限制：机器人昂贵（很少有实验室可以参与），每个人使用不同的机器人（研究结果在实验室之间不具有普遍性），我们缺乏互联网规模的机器人数据。通过一个新的基准系统：离线训练、在线测试（TOTO），我们解决了这些挑战。TOTO为远程用户提供共享机器人硬件以评估常见任务上的方法，并提供这些任务的开源数据集进行离线训练。它的操作任务套件需要在看不见的对象、位置和光照条件下进行挑战性的泛化。我们通过TOTO在五个机构远程贡献的，比较了五个预训练视觉表示和四个离线策略学习基线的初步结果。然而，TOTO真正的潜力在于未来：我们发布了这个基准系统，任何用户都可以提交进一步的研究成果，轻松地直接与多种方法进行比较，无需获得硬件或收集数据。

    Three challenges limit the progress of robot learning research: robots are expensive (few labs can participate), everyone uses different robots (findings do not generalize across labs), and we lack internet-scale robotics data. We take on these challenges via a new benchmark: Train Offline, Test Online (TOTO). TOTO provides remote users with access to shared robotic hardware for evaluating methods on common tasks and an open-source dataset of these tasks for offline training. Its manipulation task suite requires challenging generalization to unseen objects, positions, and lighting. We present initial results on TOTO comparing five pretrained visual representations and four offline policy learning baselines, remotely contributed by five institutions. The real promise of TOTO, however, lies in the future: we release the benchmark for additional submissions from any user, enabling easy, direct comparison to several methods without the need to obtain hardware or collect data.
    
[^59]: BigVideo:一个用于多模式机器翻译的大规模视频字幕翻译数据集

    BigVideo: A Large-scale Video Subtitle Translation Dataset for Multimodal Machine Translation. (arXiv:2305.18326v1 [cs.CV])

    [http://arxiv.org/abs/2305.18326](http://arxiv.org/abs/2305.18326)

    提出了一个大规模的视频字幕翻译数据集BigVideo， 集成了4.5 million句子对和9981小时视频，设计了有歧义和明确的测试集，引入了一种对比学习方法，实验结果表明，视觉信息可以提高NMT模型的BLEU、BLEURT和COMET得分，有助于消除歧义，数据集和翻译模型公开可用。

    

    我们提出了一个大规模的视频字幕翻译数据集BigVideo，以促进多模式机器翻译的研究。与广泛使用的How2和VaTeX数据集相比，BigVideo超过10倍，包括450万个句子对和9981小时的视频。我们还引入了两个有意设计的测试集来验证视觉信息的必要性：一个是一个有歧义词的不确定集合，另一个是在其中文本上下文对于翻译是自包含的明确集合。为了更好地建模文本和视频共享的共同语义，我们在跨模态编码器中引入了一种对比学习方法。在BigVideo上进行的广泛实验表明：a）视觉信息在歧义和明确的测试集上始终提高NMT模型的BLEU、BLEURT和COMET得分。b）视觉信息对于术语定位得分和人工评估而言，有助于消除歧义，与强文本基线相比。数据集和我们的翻译模型都是公开可用的。

    We present a large-scale video subtitle translation dataset, BigVideo, to facilitate the study of multi-modality machine translation. Compared with the widely used How2 and VaTeX datasets, BigVideo is more than 10 times larger, consisting of 4.5 million sentence pairs and 9,981 hours of videos. We also introduce two deliberately designed test sets to verify the necessity of visual information: Ambiguous with the presence of ambiguous words, and Unambiguous in which the text context is self-contained for translation. To better model the common semantics shared across texts and videos, we introduce a contrastive learning method in the cross-modal encoder. Extensive experiments on the BigVideo show that: a) Visual information consistently improves the NMT model in terms of BLEU, BLEURT, and COMET on both Ambiguous and Unambiguous test sets. b) Visual information helps disambiguation, compared to the strong text baseline on terminology-targeted scores and human evaluation. Dataset and our 
    
[^60]: 通过大型语言模型实现实用的PCG

    Practical PCG Through Large Language Models. (arXiv:2305.18243v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.18243](http://arxiv.org/abs/2305.18243)

    本研究介绍了如何利用语言模型生成游戏房间，在仅有少量数据的情况下，可以生成多达37%的可玩新颖关卡，该技术有助于解决包含许多局部和全局约束的PCG问题。

    

    大型语言模型(LLMs)已经被证明是自然语言处理领域之外的各种领域中非常有用的工具。本研究提供了如何使用LLMs为正在开发中的游戏Metavoidal生成2D游戏房间的实用方向。我们的技术可以通过人类参与的微调，利用GPT-3的能力，仅使用60个手动设计的房间数据，在复杂的游戏场景下，生成37%的可玩新颖关卡，这是针对存在大量局部和全局约束的PCG的。

    Large Language Models (LLMs) have proven to be useful tools in various domains outside of the field of their inception, which was natural language processing. In this study, we provide practical directions on how to use LLMs to generate 2D-game rooms for an under-development game, named Metavoidal. Our technique can harness the power of GPT-3 by Human-in-the-loop fine-tuning which allows our method to create 37% Playable-Novel levels from as scarce data as only 60 hand-designed rooms under a scenario of the non-trivial game, with respect to (Procedural Content Generation) PCG, that has a good amount of local and global constraints.
    
[^61]: 扫描与拍照：理解1层Transformer中的训练动态和标记组成

    Scan and Snap: Understanding Training Dynamics and Token Composition in 1-layer Transformer. (arXiv:2305.16380v1 [cs.CL])

    [http://arxiv.org/abs/2305.16380](http://arxiv.org/abs/2305.16380)

    本文分析了1层Transformer在下一个标记预测任务中的SGD训练动态，证明了自我关注层充当了“区分性扫描算法”，从而逐步关注到相关标记并排除不相关的标记，总结相关信息在编码表示中。同时研究了标记频率、上下文和初始化自我关注层等对Transformer性能的影响。

    

    Transformer架构在多个研究领域表现出了惊人的性能，并成为许多神经网络模型的基础。然而，我们对其如何工作的理解仍然有限。特别是，通过简单的预测性损失，表示如何从梯度训练动态中出现仍然是一个谜。在本文中，针对具有一个自我关注层和一个解码器层的1层Transformer，我们以数学严谨的方式分析其在下一个标记预测任务中的SGD训练动态。我们打开了自我关注层组合输入标记的动态过程的黑盒子，并揭示了底层归纳偏差的本质。具体而言，在没有位置编码、长输入序列和解码器层学习速度快于自我关注层的假设下，我们证明了自我关注层充当了“区分性扫描算法”：从均匀注意力开始，它逐渐关注到相关标记，排除不相关的标记，直到所有相关信息被扫描并总结在编码表示中。我们的分析还显示了标记频率和上下文如何影响注意权重，以及自我关注层初始化如何影响收敛速度。

    Transformer architecture has shown impressive performance in multiple research domains and has become the backbone of many neural network models. However, there is limited understanding on how it works. In particular, with a simple predictive loss, how the representation emerges from the gradient \emph{training dynamics} remains a mystery. In this paper, for 1-layer transformer with one self-attention layer plus one decoder layer, we analyze its SGD training dynamics for the task of next token prediction in a mathematically rigorous manner. We open the black box of the dynamic process of how the self-attention layer combines input tokens, and reveal the nature of underlying inductive bias. More specifically, with the assumption (a) no positional encoding, (b) long input sequence, and (c) the decoder layer learns faster than the self-attention layer, we prove that self-attention acts as a \emph{discriminative scanning algorithm}: starting from uniform attention, it gradually attends mor
    
[^62]: MERGE: 快速的私有文本生成

    MERGE: Fast Private Text Generation. (arXiv:2305.15769v1 [cs.CL])

    [http://arxiv.org/abs/2305.15769](http://arxiv.org/abs/2305.15769)

    该论文提出了MERGE，一个基于Transformer语言模型的快速私有文本生成框架。实验结果表明，MERGE在保护隐私的同时，实现了26.5倍的加速和80%的通信字节数减少。

    

    近年来，人们越来越关注NLP服务和Transformer模型的私有推理。然而，现有的两方隐私保护方法仅考虑NLU场景，而文本生成的私有推理，如翻译、对话和代码补全，仍未解决。此外，将现有的隐私保护方法迁移到NLG模型时，性能表现差，而在训练阶段受到收敛问题的困扰。为了解决这些问题，我们提出了MERGE，这是一个基于Transformer语言模型的快速私有文本生成框架。具体而言，MERGE重用输出隐藏状态作为单词嵌入，以跳过嵌入计算，并重新组织Transformer模块中的线性操作以加速向前过程。基于这两个优化，大量的实验表明，在序列长度为512时，MERGE可实现26.5倍的加速，并减少80\%的通信字节数。

    Recent years have seen increasing concerns about the private inference of NLP services and Transformer models. However, existing two-party privacy-preserving methods solely consider NLU scenarios, while the private inference of text generation such as translation, dialogue, and code completion remains unsolved. Besides, while migrated to NLG models, existing privacy-preserving methods perform poorly in terms of inference speed, and suffer from the convergence problem during the training stage. To address these issues, we propose MERGE, a fast private text generation framework for Transformer-based language models. Specifically, MERGE reuse the output hidden state as the word embedding to bypass the embedding computation, and reorganize the linear operations in the Transformer module to accelerate the forward procedure. Based on these two optimizations, extensive experiments show that MERGE can achieve a 26.5x speedup under the sequence length 512, and reduce 80\% communication bytes, w
    
[^63]: 克服提示扰动敏感性的零样本方法

    Zero-shot Approach to Overcome Perturbation Sensitivity of Prompts. (arXiv:2305.15689v1 [cs.CL])

    [http://arxiv.org/abs/2305.15689](http://arxiv.org/abs/2305.15689)

    本研究提出了一种零样本方法，自动生成多个类似于基础提示的高质量提示，并使用新的度量方法进行排名，从而克服了提示的扰动敏感性，并在情感分类任务中具有较高的准确性。

    

    最近的研究表明，自然语言提示可以帮助利用预训练语言模型学习的知识进行二元句级情感分类任务。具体来说，这些方法利用少量样本学习设置，使用手动或自动生成的提示来微调情感分类模型。然而，这些方法的性能对所使用提示的扰动敏感。此外，这些方法依赖于少量带标签实例进行自动提示生成和提示排序。本研究旨在在零样本设置中为所给定的任务找到高质量的提示。我们的提议方法给定一个基础提示，采用位置、推理和释义技术自动生成多个类似于基础提示的提示，然后使用一种新的度量方法对提示进行排名。我们从实验上证明，排名靠前的提示具有很高的质量，并在提示扰动鲁棒性和整体准确性方面显著优于基础提示和其他现有的提示生成方法。

    Recent studies have demonstrated that natural-language prompts can help to leverage the knowledge learned by pre-trained language models for the binary sentence-level sentiment classification task. Specifically, these methods utilize few-shot learning settings to fine-tune the sentiment classification model using manual or automatically generated prompts. However, the performance of these methods is sensitive to the perturbations of the utilized prompts. Furthermore, these methods depend on a few labeled instances for automatic prompt generation and prompt ranking. This study aims to find high-quality prompts for the given task in a zero-shot setting. Given a base prompt, our proposed approach automatically generates multiple prompts similar to the base prompt employing positional, reasoning, and paraphrasing techniques and then ranks the prompts using a novel metric. We empirically demonstrate that the top-ranked prompts are high-quality and significantly outperform the base prompt an
    
[^64]: GUARD: 一个安全强化学习基准测试平台

    GUARD: A Safe Reinforcement Learning Benchmark. (arXiv:2305.13681v1 [cs.LG])

    [http://arxiv.org/abs/2305.13681](http://arxiv.org/abs/2305.13681)

    GUARD是一个广义统一安全强化学习开发基准测试平台，是目前广泛遍布且包含各种RL代理、任务和安全约束规范的一站式基准测试，能够全面涵盖最先进的安全RL算法，并具有高度的可自定义性。

    

    由于试错的性质，将RL算法应用于安全关键的现实应用（例如自动驾驶、人机交互、机器人操作等）通常是具有挑战性的，因为这些错误是不可容忍的。最近，安全RL（即约束RL）已经在文献中迅速出现，其中代理在满足约束条件的同时，探索环境。由于算法和任务的多样性，比较现有的安全RL算法仍然很困难。为了填补这一空白，我们介绍了GUARD，一个广义统一安全强化学习开发基准测试平台。与现有基准相比，GUARD具有几个优点。首先，GUARD是一个广义基准测试平台，具有各种RL代理、任务和安全约束规范。其次，GUARD全面涵盖了最先进的安全RL算法，并具有自包含的实现。第三，GUARD在任务和算法方面具有高度的可自定义性。我们提供了状态下现有方法在GUARD上的基准测试结果。

    Due to the trial-and-error nature, it is typically challenging to apply RL algorithms to safety-critical real-world applications, such as autonomous driving, human-robot interaction, robot manipulation, etc, where such errors are not tolerable. Recently, safe RL (i.e. constrained RL) has emerged rapidly in the literature, in which the agents explore the environment while satisfying constraints. Due to the diversity of algorithms and tasks, it remains difficult to compare existing safe RL algorithms. To fill that gap, we introduce GUARD, a Generalized Unified SAfe Reinforcement Learning Development Benchmark. GUARD has several advantages compared to existing benchmarks. First, GUARD is a generalized benchmark with a wide variety of RL agents, tasks, and safety constraint specifications. Second, GUARD comprehensively covers state-of-the-art safe RL algorithms with self-contained implementations. Third, GUARD is highly customizable in tasks and algorithms. We present a comparison of state
    
[^65]: Restore Anything Pipeline: Segment Anything Meets Image Restoration.

    Restore Anything Pipeline: Segment Anything Meets Image Restoration. (arXiv:2305.13093v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2305.13093](http://arxiv.org/abs/2305.13093)

    本文提出了一种新颖的交互式和基于对象级别的图像恢复方法，即Restore Anything Pipeline (RAP)，该方法通过将图像分割技术与可控的图像恢复模型相结合，为多个图像恢复任务创建了一个用户友好的流程。

    

    近期的图像恢复方法使用深度学习取得了显著的进展。然而，现有方法往往将整个图像视为一个单一实体，无法考虑到图像中表现出个体纹理属性的不同对象。现有方法通常生成单一结果，可能无法满足不同用户的偏好。本文介绍了一种新颖的交互式和基于对象级别的图像恢复方法，即Restore Anything Pipeline (RAP)，该方法采用可控模型来生成用户可以选择的不同结果。RAP将最近的Segment Anything Model (SAM)的图像分割技术与可控的图像恢复模型相结合，为多个图像恢复任务创建了一个用户友好的流程。我们通过将RAP应用于图像去模糊、图像去噪和JPEG伪影去除这三个常见的图像恢复任务来展示其多功能性。实验结果表明，RAP能够在不同图像恢复任务上表现出色。

    Recent image restoration methods have produced significant advancements using deep learning. However, existing methods tend to treat the whole image as a single entity, failing to account for the distinct objects in the image that exhibit individual texture properties. Existing methods also typically generate a single result, which may not suit the preferences of different users. In this paper, we introduce the Restore Anything Pipeline (RAP), a novel interactive and per-object level image restoration approach that incorporates a controllable model to generate different results that users may choose from. RAP incorporates image segmentation through the recent Segment Anything Model (SAM) into a controllable image restoration model to create a user-friendly pipeline for several image restoration tasks. We demonstrate the versatility of RAP by applying it to three common image restoration tasks: image deblurring, image denoising, and JPEG artifact removal. Our experiments show that RAP p
    
[^66]: 如何为推荐基础模型索引项目ID

    How to Index Item IDs for Recommendation Foundation Models. (arXiv:2305.06569v1 [cs.IR])

    [http://arxiv.org/abs/2305.06569](http://arxiv.org/abs/2305.06569)

    本研究对推荐基础模型的项目索引问题进行了系统检查，提出了一种新的上下文感知索引方法，该方法在项目推荐准确性和文本生成质量方面具有优势。

    

    推荐基础模型将推荐任务转换为自然语言任务，利用大型语言模型（LLM）进行推荐。它通过直接生成建议的项目而不是计算传统推荐模型中每个候选项目的排名得分，简化了推荐管道，避免了多段过滤的问题。为了避免在决定要推荐哪些项目时生成过长的文本，为推荐基础模型创建LLM兼容的项目ID是必要的。本研究系统地研究了推荐基础模型的项目索引问题，以P5为代表的主干模型，并使用各种索引方法复制其结果。我们首先讨论了几种微不足道的项目索引方法（如独立索引、标题索引和随机索引）的问题，并表明它们不适用于推荐基础模型，然后提出了一种新的索引方法，称为上下文感知索引。我们表明，这种索引方法在项目推荐准确性和文本生成质量方面优于其他索引方法。

    Recommendation foundation model utilizes large language models (LLM) for recommendation by converting recommendation tasks into natural language tasks. It enables generative recommendation which directly generates the item(s) to recommend rather than calculating a ranking score for each and every candidate item in traditional recommendation models, simplifying the recommendation pipeline from multi-stage filtering to single-stage filtering. To avoid generating excessively long text when deciding which item(s) to recommend, creating LLM-compatible item IDs is essential for recommendation foundation models. In this study, we systematically examine the item indexing problem for recommendation foundation models, using P5 as the representative backbone model and replicating its results with various indexing methods. To emphasize the importance of item indexing, we first discuss the issues of several trivial item indexing methods, such as independent indexing, title indexing, and random inde
    
[^67]: 使用贝叶斯模型平均分析社交媒体上的气候宣传活动

    Analysis of Climate Campaigns on Social Media using Bayesian Model Averaging. (arXiv:2305.06174v1 [cs.CL])

    [http://arxiv.org/abs/2305.06174](http://arxiv.org/abs/2305.06174)

    本文分析了工业、倡导组织和气候倡导组织在社交媒体上如何影响气候变化的叙事，并提出了一个最小化监督模型组合方法，用于识别Facebook上气候广告的立场。

    

    气候变化是我们时代的核心问题，我们正处于一个关键时刻。各种利益集团、社会运动组织和个人在社交媒体上开展针对这个问题的集体行动。此外，社交媒体上的问题倡导活动往往是针对当前社会关注的问题，特别是能源行业面临的问题。本文的目标是分析工业、倡导组织和气候倡导组织如何利用社交媒体影响气候变化的叙事。在这项工作中，我们提出了一个最小化监督模型组合方法，并结合消息主题来识别Facebook上气候广告的立场。最后，我们发布了我们的立场数据集、模型和与气候宣传活动相关的主题，供未来的舆情挖掘和自动检测气候变化立场的研究使用。

    Climate change is the defining issue of our time, and we are at a defining moment. Various interest groups, social movement organizations, and individuals engage in collective action on this issue on social media. In addition, issue advocacy campaigns on social media often arise in response to ongoing societal concerns, especially those faced by energy industries. Our goal in this paper is to analyze how those industries, their advocacy group, and climate advocacy group use social media to influence the narrative on climate change. In this work, we propose a minimally supervised model soup [56] approach combined with messaging themes to identify the stances of climate ads on Facebook. Finally, we release our stance dataset, model, and set of themes related to climate campaigns for future work on opinion mining and the automatic detection of climate change stances.
    
[^68]: 关于锐度感知优化与对抗鲁棒性之间的关系

    On the Relation between Sharpness-Aware Minimization and Adversarial Robustness. (arXiv:2305.05392v1 [cs.LG])

    [http://arxiv.org/abs/2305.05392](http://arxiv.org/abs/2305.05392)

    SAM和对抗性训练（AT）都可以视为特定的特征扰动，其改善了对抗性能。然而，SAM和AT在扰动强度方面是不同的，从而带来了不同的精度和鲁棒性权衡。SAM单独使用可以在不牺牲清晰度精度的情况下提高对抗鲁棒性。

    

    我们在对抗鲁棒性的背景下提出了对锐度感知优化（SAM）的新理解。本文指出，SAM和对抗性训练（AT）都可以视为特定的特征扰动，其改善了对抗鲁棒性。然而，SAM和AT在扰动强度方面是不同的，从而带来了不同的精度和鲁棒性权衡。在一个简化模型中，我们提供了这些声明的理论证据和严格的数学证明。此外，我们进行了实验证明，仅利用SAM可以实现比标准训练更好的对抗鲁棒性，这是意外的好处。由于对抗训练可能会导致清晰度精度的降低，我们展示了仅使用SAM可以在不牺牲清晰度精度的情况下提高鲁棒性。源代码可在https://github.com/weizeming/SAM_AT获取。

    We propose a novel understanding of Sharpness-Aware Minimization (SAM) in the context of adversarial robustness. In this paper, we point out that both SAM and adversarial training (AT) can be viewed as specific feature perturbations, which improve adversarial robustness. However, we note that SAM and AT are distinct in terms of perturbation strength, leading to different accuracy and robustness trade-offs. We provide theoretical evidence for these claims in a simplified model with rigorous mathematical proofs. Furthermore, we conduct experiment to demonstrate that only utilizing SAM can achieve superior adversarial robustness compared to standard training, which is an unexpected benefit. As adversarial training can suffer from a decrease in clean accuracy, we show that using SAM alone can improve robustness without sacrificing clean accuracy. Code is available at https://github.com/weizeming/SAM_AT.
    
[^69]: 基于深度学习的口罩佩戴检测在COVID-19大流行期间的应用

    Wearing face mask detection using deep learning through COVID-19 pandemic. (arXiv:2305.00068v1 [cs.CV])

    [http://arxiv.org/abs/2305.00068](http://arxiv.org/abs/2305.00068)

    本研究探讨了在 COVID-19 疫情期间使用深度学习模型进行口罩佩戴检测的可行性。通过比较不同模型，选择了适用于实时和移动设备应用的最佳模型，并取得了高准确度。

    

    在COVID-19疫情期间，佩戴口罩已被知晓为预防病毒传播的有效方法之一。深度学习模型的出色性能取代了人类在许多监控任务中的角色。监控口罩佩戴就是这样一项可以由深度学习模型完成的任务。 由于隔离的原因，面部口罩照片的数量有限，因此是这项任务的主要挑战。本文使用三种最先进的目标检测神经网络模型对口罩检测进行了研究，包括 Single Shot Detector（SSD）、两个版本的 You Only Look Once。根据不同模型的表现，选择最适合在现实世界和移动设备应用中使用的模型。实验结果表明，所提出的方法实现了用于实时和移动设备应用的高准确度。

    During the COVID-19 pandemic, wearing a face mask has been known to be an effective way to prevent the spread of COVID-19. In lots of monitoring tasks, humans have been replaced with computers thanks to the outstanding performance of the deep learning models. Monitoring the wearing of a face mask is another task that can be done by deep learning models with acceptable accuracy. The main challenge of this task is the limited amount of data because of the quarantine. In this paper, we did an investigation on the capability of three state-of-the-art object detection neural networks on face mask detection for real-time applications. As mentioned, here are three models used, Single Shot Detector (SSD), two versions of You Only Look Once (YOLO) i.e., YOLOv4-tiny, and YOLOv4-tiny-3l from which the best was selected. In the proposed method, according to the performance of different models, the best model that can be suitable for use in real-world and mobile device applications in comparison to
    
[^70]: 让图表闪亮起来：利用文本到图像生成模型将语义上下文嵌入到图表中

    Let the Chart Spark: Embedding Semantic Context into Chart with Text-to-Image Generative Model. (arXiv:2304.14630v1 [cs.AI])

    [http://arxiv.org/abs/2304.14630](http://arxiv.org/abs/2304.14630)

    本文提出了一个新的系统ChartSpark，利用文本到图像生成模型将语义上下文嵌入到图表中，以生成具有高质量语义上下文的图示可视化。

    

    图示可视化将数据和语义上下文良好地整合到视觉表现中，以一种既引人又信息量大的方式传达复杂信息。本文提出了一个新系统ChartSpark，它基于文本到图像生成模型将语义上下文嵌入在图表中生成图示化的可视化。该方法适用于前景和背景的图示生成，旨在创造具有语义上下文的高质量图示可视化。

    Pictorial visualization seamlessly integrates data and semantic context into visual representation, conveying complex information in a manner that is both engaging and informative. Extensive studies have been devoted to developing authoring tools to simplify the creation of pictorial visualizations. However, mainstream works mostly follow a retrieving-and-editing pipeline that heavily relies on retrieved visual elements from a dedicated corpus, which often compromise the data integrity. Text-guided generation methods are emerging, but may have limited applicability due to its predefined recognized entities. In this work, we propose ChartSpark, a novel system that embeds semantic context into chart based on text-to-image generative model. ChartSpark generates pictorial visualizations conditioned on both semantic context conveyed in textual inputs and data information embedded in plain charts. The method is generic for both foreground and background pictorial generation, satisfying the d
    
[^71]: 通过Paired-Logits反演攻击恢复图像的FedMD

    Breaching FedMD: Image Recovery via Paired-Logits Inversion Attack. (arXiv:2304.11436v1 [cs.CR])

    [http://arxiv.org/abs/2304.11436](http://arxiv.org/abs/2304.11436)

    本文揭示了即便使用FedMD的安全机制，仍存在被精心设计的恶意攻击利用的风险，如Paired-Logits反演攻击，会导致隐私数据曝光。

    

    联邦学习与模型蒸馏（FedMD）是一种新兴的协作学习范式，其中仅传输公共数据集的输出logits作为蒸馏知识，而不是传递易受梯度反演攻击的私有模型参数，这是联邦学习中已知的隐私风险。本文发现，即使共享公共数据集的输出 logit比直接共享梯度更安全，仍存在因精心设计的恶意攻击导致的数据曝光风险。我们的研究表明，恶意服务器可以训练一个反演神经网络来利用服务器和客户端模型之间的置信度差，针对FedMD及其变种进行PLI（配对logits反演）攻击。在多个人脸识别数据集上进行的实验证明，在类似于FedMD的方案中，仅使用公共数据集的配对服务器-客户端logits，恶意服务器能够重构私有图像。

    Federated Learning with Model Distillation (FedMD) is a nascent collaborative learning paradigm, where only output logits of public datasets are transmitted as distilled knowledge, instead of passing on private model parameters that are susceptible to gradient inversion attacks, a known privacy risk in federated learning. In this paper, we found that even though sharing output logits of public datasets is safer than directly sharing gradients, there still exists a substantial risk of data exposure caused by carefully designed malicious attacks. Our study shows that a malicious server can inject a PLI (Paired-Logits Inversion) attack against FedMD and its variants by training an inversion neural network that exploits the confidence gap between the server and client models. Experiments on multiple facial recognition datasets validate that under FedMD-like schemes, by using paired server-client logits of public datasets only, the malicious server is able to reconstruct private images on a
    
[^72]: 野外环境下的AMP：学习健壮、灵活、自然的有腿移动技能

    AMP in the wild: Learning robust, agile, natural legged locomotion skills. (arXiv:2304.10888v1 [cs.RO])

    [http://arxiv.org/abs/2304.10888](http://arxiv.org/abs/2304.10888)

    本文提出了一种新算法，可推断动态系统参数信息并从之前的观察数据中估计机器人状态的重要信息。将该算法与Adversarial Motion Priors相结合，实现了在仿真和真实世界中健壮、灵活、自然的步态，可用于穿越具有挑战性的地形。

    

    将一个学习控制器从仿真环境转移到真实世界中的四足机器人需要不仅能够识别系统，而且还需要准确地估计机器人的状态。本文提出了一种新算法，不仅可以推断动态系统参数信息，还可以从之前的观察数据中估计机器人状态的重要信息。我们将该算法与Adversarial Motion Priors相结合，在仿真和在Unitree A1四足机器人真实世界中实现了健壮、灵活、自然的步态。实证结果表明，与基准方法相比，我们提出的算法能够以更低的功耗穿越具有挑战性的地形。本文提供了定性和定量的结果。

    The successful transfer of a learned controller from simulation to the real world for a legged robot requires not only the ability to identify the system, but also accurate estimation of the robot's state. In this paper, we propose a novel algorithm that can infer not only information about the parameters of the dynamic system, but also estimate important information about the robot's state from previous observations. We integrate our algorithm with Adversarial Motion Priors and achieve a robust, agile, and natural gait in both simulation and on a Unitree A1 quadruped robot in the real world. Empirical results demonstrate that our proposed algorithm enables traversing challenging terrains with lower power consumption compared to the baselines. Both qualitative and quantitative results are presented in this paper.
    
[^73]: 用BREC数据集更好地评估GNN表达力

    Towards Better Evaluation of GNN Expressiveness with BREC Dataset. (arXiv:2304.07702v1 [cs.LG])

    [http://arxiv.org/abs/2304.07702](http://arxiv.org/abs/2304.07702)

    本论文介绍了一个新的Benchmark for Evaluating the Robustness of GNNs to Topological Changes (BREC)数据集，并使用BREC评估了几种现有的GNN模型的表达力，表明一些模型在以前的基准测试中表现良好，但在BREC上遇到了困难，突显了需要更好的GNN表现力评估的必要性。

    

    关于图神经网络（GNN）的理论表达力的研究得到了快速发展，并提出了许多增强表达力的方法。然而，除了严格遵循k维Weisfeiler-Lehman（k-WL）测试层次结构的少数方法外，大多数方法都没有统一的表达力度量。它们的理论分析通常限于区分某些非同构图族，导致在定量比较表达力方面存在困难。与理论分析相反，衡量表达能力的另一种方法是在包含1-WL不可区分图的特定数据集上评估模型性能。然而，以前专门设计用于此目的的数据集面临着难度（任何超越1-WL的模型准确率几乎达到100％）、粒度（模型倾向于要么完全正确，要么接近随机猜测）和规模（每个数据集中仅有少量本质不同的图）的问题。为了解决这些受限制的评估问题，我们提出了一个新的GNN鲁棒性评估基准（BREC），该基准包含许多结构多样的图，并允许对模型表达力进行更精细的评估。我们使用BREC评估了几种现有的GNN模型的表达力，并展示了一些模型在以前的基准测试中表现良好，但在BREC上遇到了困难，突显了需要更好的GNN表现力评估的必要性。

    Research on the theoretical expressiveness of Graph Neural Networks (GNNs) has developed rapidly, and many methods have been proposed to enhance the expressiveness. However, most methods do not have a uniform expressiveness measure except for a few that strictly follow the $k$-dimensional Weisfeiler-Lehman ($k$-WL) test hierarchy. Their theoretical analyses are often limited to distinguishing certain families of non-isomorphic graphs, leading to difficulties in quantitatively comparing their expressiveness. In contrast to theoretical analysis, another way to measure expressiveness is by evaluating model performance on certain datasets containing 1-WL-indistinguishable graphs. Previous datasets specifically designed for this purpose, however, face problems with difficulty (any model surpassing 1-WL has nearly 100% accuracy), granularity (models tend to be either 100% correct or near random guess), and scale (only a few essentially different graphs in each dataset). To address these limi
    
[^74]: 数据科学中的可解释符号回归：2022年竞赛分析

    Interpretable Symbolic Regression for Data Science: Analysis of the 2022 Competition. (arXiv:2304.01117v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2304.01117](http://arxiv.org/abs/2304.01117)

    本文分析了2022年基因与进化计算会议举办的竞赛，评估了符号回归的新方法在面对现实数据时的表现，并提供了可解释性评估的实际方法。

    

    符号回归是寻找能够准确描述研究现象的解析表达式的方法。这种方法的主要优势是返回可解释的模型，能够给用户提供深刻的见解。历史上，符号回归的大多数算法都基于进化算法。然而，最近出现了大量新的提案，这些提案使用了列举算法、混合线性整数规划、神经网络和贝叶斯优化等方法。为了评估这些新方法在面对现实世界数据中经常遇到的一组常见挑战时的表现如何，我们在2022年遗传与进化计算会议上举办了一次竞赛，其中包含不同的合成和真实世界数据集，参赛者对这些数据集是盲测试的。对于真实世界的部分，我们使用了领域专家来评估候选模型的可解释性。我们对结果进行了深入分析。

    Symbolic regression searches for analytic expressions that accurately describe studied phenomena. The main attraction of this approach is that it returns an interpretable model that can be insightful to users. Historically, the majority of algorithms for symbolic regression have been based on evolutionary algorithms. However, there has been a recent surge of new proposals that instead utilize approaches such as enumeration algorithms, mixed linear integer programming, neural networks, and Bayesian optimization. In order to assess how well these new approaches behave on a set of common challenges often faced in real-world data, we hosted a competition at the 2022 Genetic and Evolutionary Computation Conference consisting of different synthetic and real-world datasets which were blind to entrants. For the real-world track, we assessed interpretability in a realistic way by using a domain expert to judge the trustworthiness of candidate models.We present an in-depth analysis of the result
    
[^75]: RegionPLC：用于开放世界3D场景理解的区域点-语言对比学习

    RegionPLC: Regional Point-Language Contrastive Learning for Open-World 3D Scene Understanding. (arXiv:2304.00962v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2304.00962](http://arxiv.org/abs/2304.00962)

    提出了一种用于开放世界3D场景理解的Regional Point-Language Contrastive Learning框架，通过密集的视觉提示和点独立对比学习来实现对新颖类别的识别和密集场景理解。

    

    现有的3D场景理解任务在闭集基准上取得了高性能，但在现实世界应用中无法处理新颖类别。为此，我们提出了一种称为RegionPLC的开放世界3D场景理解的区域点-语言对比学习框架，它使经过封闭集数据集训练的模型具备开放词汇识别能力。我们提出了密集的视觉提示，通过标题生成从2D基础模型中引发区域级视觉-语言知识，进而使我们能够建立密集的区域点-语言关联。然后，我们设计了一种点判别对比学习目标，使得从标题中进行点独立学习以实现密集场景理解。我们在ScanNet、ScanNet200和nuScenes数据集上进行了大量实验。相比之前的基于注释的3D开放世界场景理解方法，我们的RegionPLC在语义和实例分割方面的性能平均提高了11.6%和6.6%。

    Existing 3D scene understanding tasks have achieved high performance on close-set benchmarks but fail to handle novel categories in real-world applications. To this end, we propose a Regional Point-Language Contrastive learning framework, namely RegionPLC, for open-world 3D scene understanding, which equips models trained on closed-set datasets with open-vocabulary recognition capabilities. We propose dense visual prompts to elicit region-level visual-language knowledge from 2D foundation models via captioning, which further allows us to build dense regional point-language associations. Then, we design a point-discriminative contrastive learning objective to enable point-independent learning from captions for dense scene understanding. We conduct extensive experiments on ScanNet, ScanNet200, and nuScenes datasets. Our RegionPLC significantly outperforms previous base-annotated 3D open-world scene understanding approaches by an average of 11.6\% and 6.6\% for semantic and instance segme
    
[^76]: 协同人工智能的根源和要求

    Roots and Requirements for Collaborative AI. (arXiv:2303.12040v1 [cs.AI])

    [http://arxiv.org/abs/2303.12040](http://arxiv.org/abs/2303.12040)

    论文探讨了AI协同合作的历史和要求，是协同AI研究的动机和背景。

    

    AI协作者的愿景长期以来一直是科幻小说的经典素材，其中人工智能代理理解协作和人类沟通的微妙差别。它们通过贡献特殊的才能给他们的人类合作者和团队带来优势。多年来，政府咨询团体和人工智能领域的领袖一直倡导AIs应该具有人类兼容性和有效协作的能力。然而，具备像才华横溢的人那样协作能力的强大的AI仍然遥不可及。这篇论文依据对人工智能和人类代理有效和强大协作所需认知的分析，概述了公众和AI愿景中关于人工协作者的历史，开始于早期智能增强(IA)和人工智能(AI)的愿景。这篇论文旨在成为协同AI的第二个立场文件(Stefik & Price, 2023)的动机和背景。第二篇论文回顾了多学科的现状，并提出了一个AI协作研究的路线图。

    The vision of AI collaborators has long been a staple of science fiction, where artificial agents understand nuances of collaboration and human communication. They bring advantages to their human collaborators and teams by contributing their special talents. Government advisory groups and leaders in AI have advocated for years that AIs should be human compatible and be capable of effective collaboration. Nonetheless, robust AIs that can collaborate like talented people remain out of reach. This position paper draws on a cognitive analysis of what effective and robust collaboration requires of human and artificial agents. It sketches a history of public and AI visions for artificial collaborators, starting with early visions of intelligence augmentation (IA) and artificial intelligence (AI). It is intended as motivation and context for a second position paper on collaborative AI (Stefik & Price, 2023). The second paper reviews the multi-disciplinary state-of-the-art and proposes a roadm
    
[^77]: 具有真正满足不等式约束的软Actor-Critic算法

    Soft Actor-Critic Algorithm with Truly-satisfied Inequality Constraint. (arXiv:2303.04356v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.04356](http://arxiv.org/abs/2303.04356)

    本文改进了软Actor-Critic（SAC）算法的实现，通过引入可学习的状态相关的松弛变量来适当处理不等式约束，实现了最大化策略熵。这对于增强机器人控制器的鲁棒性非常有用。

    

    在强化学习中，软Actor-Critic（SAC）被认为是下一代机器人控制方案之一。其最大化策略熵的能力可以使机器人控制器对噪声和扰动具有鲁棒性，这对于实际的机器人应用非常有用。然而，在当前的实现中，最大化策略熵的优先级是自动调节的，其规则可以解释为等式约束，将策略熵绑定到指定的下界。因此，当前的SAC不再最大化策略熵，与我们的期望相反。为了解决SAC中的这个问题，本文改进了其实现，引入了一个可学习的状态相关的松弛变量，以适当处理不等式约束，通过将其重新制定为相应的等式约束来最大化策略熵。引入的松弛变量通过考虑满足不等式约束的双重目标的切换型损失函数进行优化。

    Soft actor-critic (SAC) in reinforcement learning is expected to be one of the next-generation robot control schemes. Its ability to maximize policy entropy would make a robotic controller robust to noise and perturbation, which is useful for real-world robot applications. However, the priority of maximizing the policy entropy is automatically tuned in the current implementation, the rule of which can be interpreted as one for equality constraint, binding the policy entropy into its specified lower bound. The current SAC is therefore no longer maximize the policy entropy, contrary to our expectation. To resolve this issue in SAC, this paper improves its implementation with a learnable state-dependent slack variable for appropriately handling the inequality constraint to maximize the policy entropy by reformulating it as the corresponding equality constraint. The introduced slack variable is optimized by a switching-type loss function that takes into account the dual objectives of satis
    
[^78]: 基于大语言模型的零样本跨语言摘要

    Zero-Shot Cross-Lingual Summarization via Large Language Models. (arXiv:2302.14229v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.14229](http://arxiv.org/abs/2302.14229)

    本文实验性地使用各种提示来指导大型语言模型从不同的范式执行零样本跨语言摘要，并成功提高了它们的CLS性能。其中，GPT-4实现了零样本CLS的最先进性能，并且在性能方面与最佳方法相当。

    

    给定一个源语言文本，跨语言摘要（CLS）旨在生成另一种目标语言的摘要。最近，大型语言模型（LLM）的出现，比如GPT-3.5、ChatGPT和GPT-4，引起了计算语言学界的广泛关注。然而，目前尚不清楚LLM在CLS上的表现如何。本文实验性地使用各种提示来指导LLM从不同的范式（即端到端和流水线）执行零样本CLS，并对生成的摘要进行初步评估。我们发现，ChatGPT和GPT-4原本更喜欢生成详细信息的长摘要。但这两个LLM在交互式提示的帮助下可以进一步平衡信息量和简洁性，显著提高它们的CLS性能。在三个广泛使用的CLS数据集上的实验结果表明，GPT-4实现了零样本CLS的最先进性能，并且在性能方面与最佳方法相当。

    Given a document in a source language, cross-lingual summarization (CLS) aims to generate a summary in a different target language. Recently, the emergence of Large Language Models (LLMs), such as GPT-3.5, ChatGPT and GPT-4, has attracted wide attention from the computational linguistics community. However, it is not yet known the performance of LLMs on CLS. In this report, we empirically use various prompts to guide LLMs to perform zero-shot CLS from different paradigms (i.e., end-to-end and pipeline), and provide a preliminary evaluation on the generated summaries. We find that ChatGPT and GPT-4 originally prefer to produce lengthy summaries with detailed information. These two LLMs can further balance informativeness and conciseness with the help of an interactive prompt, significantly improving their CLS performance. Experimental results on three widely-used CLS datasets show that GPT-4 achieves state-of-the-art zero-shot CLS performance, and performs competitively compared with th
    
[^79]: 具有可学习和最优多项式基函数的图神经网络

    Graph Neural Networks with Learnable and Optimal Polynomial Bases. (arXiv:2302.12432v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.12432](http://arxiv.org/abs/2302.12432)

    本文提出了两种具有可学习和最优多项式基函数的谱图神经网络模型，通过学习多项式基函数和计算最优基函数，解决了多项式滤波器在模型有效性方面的问题。

    

    多项式滤波器是一种图神经网络，通常使用预定的多项式基函数，并从训练数据中学习系数。然而，模型的有效性很大程度上取决于多项式基函数的性质。因此，我们提出了两种谱图神经网络模型，它们能够肯定回答上述问题。首先，受到Favard定理的启发，我们提出了FavardGNN模型，该模型从所有可能的正交基函数空间中学习多项式基函数。其次，我们研究了Wang和Zhang（2022年）提出的所谓无法解决的最优多项式基函数的定义，并提出了一个简单模型OptBasisGNN，可计算给定图结构和图信号的最优基函数。进行了大量实验验证。

    Polynomial filters, a kind of Graph Neural Networks, typically use a predetermined polynomial basis and learn the coefficients from the training data. It has been observed that the effectiveness of the model is highly dependent on the property of the polynomial basis. Consequently, two natural and fundamental questions arise: Can we learn a suitable polynomial basis from the training data? Can we determine the optimal polynomial basis for a given graph and node features?  In this paper, we propose two spectral GNN models that provide positive answers to the questions posed above. First, inspired by Favard's Theorem, we propose the FavardGNN model, which learns a polynomial basis from the space of all possible orthonormal bases. Second, we examine the supposedly unsolvable definition of optimal polynomial basis from Wang & Zhang (2022) and propose a simple model, OptBasisGNN, which computes the optimal basis for a given graph structure and graph signal. Extensive experiments are conduct
    
[^80]: 自我监督利用的探索

    Exploration by self-supervised exploitation. (arXiv:2302.11563v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2302.11563](http://arxiv.org/abs/2302.11563)

    该论文介绍了一种基于自我监督学习的内在动机算法类别SND，并将其应用于探索困难环境。实验结果表明这种方法是有效的。

    

    强化学习可以解决决策问题，并训练一个代理根据预先设计的奖励函数在环境中行为。然而，如果奖励过于稀疏，代理在环境探索中不会遇到奖励，这种方法就变得非常棘手。解决这个问题的方法可能是为代理装备内在动机，这样代理在探索过程中也可能遇到外部奖励。新颖性检测是内在动机研究的一个有前途的分支。我们提出了一种基于蒸馏误差作为新颖性指标的自我监督网络蒸馏（SND）算法类别，其中目标模型使用自我监督学习进行训练。我们为此改编了三种现有的自我监督方法，并在被认为难以探索的十个环境上进行了实验测试。

    Reinforcement learning can solve decision-making problems and train an agent to behave in an environment according to a predesigned reward function. However, such an approach becomes very problematic if the reward is too sparse and the agent does not come across the reward during the environmental exploration. The solution to such a problem may be in equipping the agent with an intrinsic motivation, which will provide informed exploration, during which the agent is likely to also encounter external reward. Novelty detection is one of the promising branches of intrinsic motivation research. We present Self-supervised Network Distillation (SND), a class of internal motivation algorithms based on the distillation error as a novelty indicator, where the target model is trained using self-supervised learning. We adapted three existing self-supervised methods for this purpose and experimentally tested them on a set of ten environments that are considered difficult to explore. The results sho
    
[^81]: 可用于回归的快速校准不确定性的似然退火方法

    Likelihood Annealing: Fast Calibrated Uncertainty for Regression. (arXiv:2302.11012v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.11012](http://arxiv.org/abs/2302.11012)

    该论文提出了一种名为似然退火的快速校准回归任务不确定性估计方法，能够改进深度回归模型的收敛性并产生校准的不确定性估计。

    

    近年来，深度学习的发展表明，不确定性估计在医学影像、自然语言处理和自主系统等应用中变得越来越重要。然而，准确量化不确定性仍然是一个具有挑战性的问题，特别是在输出空间连续的回归任务中。允许回归问题进行不确定性估计的深度学习方法通常收敛速度较慢，并产生不良校准的不确定性估计，不能有效用于量化。最近提出的事后校准技术很少适用于回归问题，并且常常给已经较慢的模型训练阶段增加了额外开销。本文提出了一种用于回归任务的快速校准不确定性估计方法，称为似然退火，它能够持续改进深度回归模型的收敛性，并在没有任何事后校准阶段的情况下产生校准的不确定性。

    Recent advances in deep learning have shown that uncertainty estimation is becoming increasingly important in applications such as medical imaging, natural language processing, and autonomous systems. However, accurately quantifying uncertainty remains a challenging problem, especially in regression tasks where the output space is continuous. Deep learning approaches that allow uncertainty estimation for regression problems often converge slowly and yield poorly calibrated uncertainty estimates that can not be effectively used for quantification. Recently proposed post hoc calibration techniques are seldom applicable to regression problems and often add overhead to an already slow model training phase. This work presents a fast calibrated uncertainty estimation method for regression tasks called Likelihood Annealing, that consistently improves the convergence of deep regression models and yields calibrated uncertainty without any post hoc calibration phase. Unlike previous methods for 
    
[^82]: 使用特征合成工具对深度神经网络进行红队演练

    Red Teaming Deep Neural Networks with Feature Synthesis Tools. (arXiv:2302.10894v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.10894](http://arxiv.org/abs/2302.10894)

    本文提出了一个用于评估可解释性工具的基准，通过训练模型以对特定触发器产生特定输出的方式，可以解决传统可解释性方法无法分析未知特征行为的问题。

    

    可解释的人工智能工具通常旨在理解模型在超出分布范围（OOD）的情况下的行为。尽管这个研究领域受到了关注，但在这些工具中很少有能够发现模型中的新颖、以前未知的错误的案例。我们认为，这部分原因在于许多可解释性方法的共同特点：它们使用特定的数据集分析和解释模型的行为。虽然这很有用，但这些工具只能分析用户可以事先采样或识别的特征所引发的行为。为了解决这个问题，一个不断增加的研究领域涉及使用不依赖于数据集的特征合成方法来解释模型。本文的主要贡献是提出了一个评估可解释性工具的基准。我们的关键观点是，我们可以训练模型以对特定触发器（例如，插入图像的特定补丁）产生特定输出（即标签），然后评估可解释性工具的有效性。

    Interpretable AI tools are often motivated by the goal of understanding model behavior in out-of-distribution (OOD) contexts. Despite the attention this area of study receives, there are comparatively few cases where these tools have identified novel, previously unknown, bugs in models. We argue that this is due, in part, to a common feature of many interpretability methods: they analyze and explain the behavior of a model using a particular dataset. While this is useful, such tools can only analyze behaviors induced by features that the user can sample or identify in advance. To address this, a growing body of research involves interpreting models using feature synthesis methods which do not depend on a dataset.  In this paper, our primary contribution is a benchmark to evaluate interpretability tools. Our key insight is that we can train models that respond to specific triggers (e.g., a specific patch inserted into an image) with specific outputs (i.e. a label) and then evaluate inte
    
[^83]: FrankenSplit:基于显著性指导的神经特征压缩与浅层变分瓶颈注入

    FrankenSplit: Saliency Guided Neural Feature Compression with Shallow Variational Bottleneck Injection. (arXiv:2302.10681v2 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2302.10681](http://arxiv.org/abs/2302.10681)

    本文提出了一种基于显著性指导的神经特征压缩与浅层变分瓶颈注入的新的资源意识压缩模型的框架，实现了比最先进的SC方法低60％的比特率，并且比现有的编解码标准的下放快16倍。

    

    移动AI加速器的崛起使得对延迟敏感的应用可以在客户端上执行轻量级深度神经网络（DNN）。然而，需要强大模型的关键应用程序需要将请求下放，而高维数据将争夺有限的带宽。本文提出了一种新的资源意识压缩模型的框架并在反映边缘设备和服务器之间不对称资源分配的环境中进行了广泛评估。我们的方法在不降低准确性的情况下实现了比最先进的SC方法低60％的比特率，并且比现有的编解码标准的下放快16倍。

    The rise of mobile AI accelerators allows latency-sensitive applications to execute lightweight Deep Neural Networks (DNNs) on the client side. However, critical applications require powerful models that edge devices cannot host and must therefore offload requests, where the high-dimensional data will compete for limited bandwidth. This work proposes shifting away from focusing on executing shallow layers of partitioned DNNs. Instead, it advocates concentrating the local resources on variational compression optimized for machine interpretability. We introduce a novel framework for resource-conscious compression models and extensively evaluate our method in an environment reflecting the asymmetric resource distribution between edge devices and servers. Our method achieves 60\% lower bitrate than a state-of-the-art SC method without decreasing accuracy and is up to 16x faster than offloading with existing codec standards.
    
[^84]: 具有因果正则化的神经算法推理

    Neural Algorithmic Reasoning with Causal Regularisation. (arXiv:2302.10258v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.10258](http://arxiv.org/abs/2302.10258)

    提出了一种具有因果正则化的神经算法推理方法，通过观察到对于某些中间计算来说存在许多不同的输入，可以开发数据增强程序，生成能够使目标算法有完全相同下一轨迹步骤的输入，从而提高在分布外测试数据上的性能。

    

    最近关于神经算法推理的研究探究了神经网络的推理能力，有效地证明了它们可以学习在训练分布中未见过的数据上执行经典算法。然而，现有神经推理器在分布外（OOD）的测试数据上性能显著下降，因为输入的规模更大。在这项工作中，我们做出了重要观察：对于算法来说，有很多不同的输入会表现出完全相同的中间计算。这种洞察力使我们能够开发数据增强的程序，根据算法的中间轨迹生成能够使目标算法有完全相同下一轨迹步骤的输入。我们通过使用由我们的观察导出并在因果图中形式化的自监督目标来确保这些输入下的下一步预测的不变性。我们证明了由此产生的方法，我们称之为Hint-ReLIC，改善了OOD测试数据上的性能。

    Recent work on neural algorithmic reasoning has investigated the reasoning capabilities of neural networks, effectively demonstrating they can learn to execute classical algorithms on unseen data coming from the train distribution. However, the performance of existing neural reasoners significantly degrades on out-of-distribution (OOD) test data, where inputs have larger sizes. In this work, we make an important observation: there are many different inputs for which an algorithm will perform certain intermediate computations identically. This insight allows us to develop data augmentation procedures that, given an algorithm's intermediate trajectory, produce inputs for which the target algorithm would have exactly the same next trajectory step. We ensure invariance in the next-step prediction across such inputs, by employing a self-supervised objective derived by our observation, formalised in a causal graph. We prove that the resulting method, which we call Hint-ReLIC, improves the OO
    
[^85]: 基于拓扑学的特征选择方法：一种基于图论的过滤特征选择方法

    Topological Feature Selection: A Graph-Based Filter Feature Selection Approach. (arXiv:2302.09543v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.09543](http://arxiv.org/abs/2302.09543)

    本文提出了一种基于图论的特征选择方法，利用拓扑学和依赖关系，具有高度灵活性和解释性，在16个基准数据集上显示出优于或匹配于当前最先进技术的表现。

    

    本文介绍了一种新型的无监督的基于图论过滤方法进行特征选择的技术，利用了拓扑约束网络表示的威力。我们使用一系列弦图（三角最大过滤图）模拟特征之间的相互依赖关系，并通过研究特征在网络内的相对位置来最大化特征相关性的可能性。这种方法相对于其他方法有三个特点：（i）高度可调，易于适应输入数据的性质；（ii）完全可解释，同时保持了显著的简单性；（iii）计算成本比其替代方案更加便宜。我们在来自不同应用领域的16个基准数据集上测试了我们的算法，结果表明在异构评估条件下，它优于或与当前最先进技术相匹配。

    In this paper, we introduce a novel unsupervised, graph-based filter feature selection technique which exploits the power of topologically constrained network representations. We model dependency structures among features using a family of chordal graphs (the Triangulated Maximally Filtered Graph), and we maximise the likelihood of features' relevance by studying their relative position inside the network. Such an approach presents three aspects that are particularly satisfactory compared to its alternatives: (i) it is highly tunable and easily adaptable to the nature of input data; (ii) it is fully explainable, maintaining, at the same time, a remarkable level of simplicity; (iii) it is computationally cheaper compared to its alternatives. We test our algorithm on 16 benchmark datasets from different applicative domains showing that it outperforms or matches the current state-of-the-art under heterogeneous evaluation conditions.
    
[^86]: 少即是多：选择性层微调与子微调

    Less is More: Selective Layer Finetuning with SubTuning. (arXiv:2302.06354v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.06354](http://arxiv.org/abs/2302.06354)

    本研究提出了一种选择性层微调与子微调的方法，通过仅对精心选择的层进行微调，而将其余权重保持在预训练值上。该方法在准确性上能够与全模型微调相媲美，并在训练数据稀缺时表现更好。这一简单而有效的方法适用于多任务学习，并能够在推理过程中实现任务间的资源共享。

    

    对预训练模型进行微调已成为在新任务上训练神经网络的标准方法，导致了快速收敛和改善的性能。在这项工作中，我们研究了一种替代的微调方法，即不对网络的所有权重进行微调，而是只训练一组精心选择的层，使其余的权重保持在其初始（预训练）值上。我们证明了\emph{子微调}（SubTuning）经常能够达到与对模型进行全微调相当的准确性，并且在训练数据稀缺时甚至超过了全微调的性能。因此，SubTuning允许以最小的计算成本部署新任务，同时享受整个模型微调的好处。这为多任务学习提供了一种简单有效的方法，在推理时不同任务之间不干扰，而在大部分资源上共享。我们展示了SubTuning在多个任务上的效率。

    Finetuning a pretrained model has become a standard approach for training neural networks on novel tasks, resulting in fast convergence and improved performance. In this work, we study an alternative finetuning method, where instead of finetuning all the weights of the network, we only train a carefully chosen subset of layers, keeping the rest of the weights frozen at their initial (pretrained) values. We demonstrate that \emph{subset finetuning} (or SubTuning) often achieves accuracy comparable to full finetuning of the model, and even surpasses the performance of full finetuning when training data is scarce. Therefore, SubTuning allows deploying new tasks at minimal computational cost, while enjoying the benefits of finetuning the entire model. This yields a simple and effective method for multi-task learning, where different tasks do not interfere with one another, and yet share most of the resources at inference time. We demonstrate the efficiency of SubTuning across multiple task
    
[^87]: 基于状态的安全强化学习：综述

    State-wise Safe Reinforcement Learning: A Survey. (arXiv:2302.03122v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.03122](http://arxiv.org/abs/2302.03122)

    本文综合回顾了强化学习中解决基于状态约束的方法，讨论了它们在安全保障和可扩展性、安全性和奖励表现、收敛后和训练过程中的安全性等方面的联系、差异和权衡，并讨论了未来发展方向。

    

    尽管强化学习在仿真环境中取得了巨大的成功，但将其应用于实际场景仍然面临许多挑战。其中一个主要关注点是安全性，也就是约束满足。状态约束是实际应用中最常见且最具挑战性的约束之一，这对于许多挑战性任务，如自动驾驶、机器人操作等而言是必要和关键的。本文综述了现有的解决基于状态的约束的强化学习方法，并在状态约束马尔可夫决策过程的框架下，从安全保障和可扩展性、安全性和奖励表现、收敛后和训练过程中的安全性等方面，讨论了现有方法的联系、差异和权衡。我们还总结了当前方法的局限性并讨论了未来发展方向。

    Despite the tremendous success of Reinforcement Learning (RL) algorithms in simulation environments, applying RL to real-world applications still faces many challenges. A major concern is safety, in another word, constraint satisfaction. State-wise constraints are one of the most common constraints in real-world applications and one of the most challenging constraints in Safe RL. Enforcing state-wise constraints is necessary and essential to many challenging tasks such as autonomous driving, robot manipulation. This paper provides a comprehensive review of existing approaches that address state-wise constraints in RL. Under the framework of State-wise Constrained Markov Decision Process (SCMDP), we will discuss the connections, differences, and trade-offs of existing approaches in terms of (i) safety guarantee and scalability, (ii) safety and reward performance, and (iii) safety after convergence and during training. We also summarize limitations of current methods and discuss potentia
    
[^88]: 通过自我对战实现多样化诱导的环境设计

    Diversity Induced Environment Design via Self-Play. (arXiv:2302.02119v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2302.02119](http://arxiv.org/abs/2302.02119)

    本文提出了一种利用自我对战技术的任务不可知方法，来识别环境中的观察/隐藏状态，并将多样性引入非监督环境设计框架中，从而提高了环境设计的效率和有效性。

    

    最近关于环境分布设计的研究已经展示出训练有效的通用能力代理的前景。它的成功部分在于一种自适应课程学习的形式，该形式通过生成代理能力的前沿环境实例（或级别）。然而，这种环境设计框架经常在具有挑战性的设计空间中发现有效级别方面存在困难，并需要与环境进行高成本交互。本文的目的是在非监督环境设计（UED）框架中引入多样性。具体来说，我们提出了一种任务不可知的方法来识别对给定级别具有代表性的观察/隐藏状态。然后利用这种方法的结果来表征两个级别之间的多样性，正如我们所展示的，这对于有效性能至关重要。此外，为了提高采样效率，我们加入了自我对战技术，使得环境生成器能够自动生成环境。

    Recent work on designing an appropriate distribution of environments has shown promise for training effective generally capable agents. Its success is partly because of a form of adaptive curriculum learning that generates environment instances (or levels) at the frontier of the agent's capabilities. However, such an environment design framework often struggles to find effective levels in challenging design spaces and requires costly interactions with the environment. In this paper, we aim to introduce diversity in the Unsupervised Environment Design (UED) framework. Specifically, we propose a task-agnostic method to identify observed/hidden states that are representative of a given level. The outcome of this method is then utilized to characterize the diversity between two levels, which as we show can be crucial to effective performance. In addition, to improve sampling efficiency, we incorporate the self-play technique that allows the environment generator to automatically generate e
    
[^89]: 学习优化增强学习

    Learning to Optimize for Reinforcement Learning. (arXiv:2302.01470v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.01470](http://arxiv.org/abs/2302.01470)

    学习优化器在监督学习中取得了显著的成功，但在强化学习中面临梯度范围变化大、梯度分布非独立且不同、高方差偏差等问题。本文提出了梯度处理、管道训练和一种新颖的优化器结构来解决这些问题。

    

    近年来，通过利用更多的数据、计算和不同的任务，学习优化器在监督学习中取得了显著的成功，超过了传统手动设计的优化器。然而，强化学习与监督学习本质上不同，这些学习优化器在简单的强化学习任务中效果不佳。我们调查了这一现象，发现了三个问题。首先，强化学习代理的梯度在对数上变化范围很大，而在绝对值上范围较小，这使得神经网络难以获得准确的参数更新。其次，代理梯度分布非独立且不同，导致元训练效率低下。最后，由于代理与环境之间的高度随机交互，代理梯度存在较高的偏差和方差，增加了强化学习优化器的学习难度。我们提出了梯度处理、管道训练和一种新颖的优化器结构。

    In recent years, by leveraging more data, computation, and diverse tasks, learned optimizers have achieved remarkable success in supervised learning, outperforming classical hand-designed optimizers. Reinforcement learning (RL) is essentially different from supervised learning and in practice these learned optimizers do not work well even in simple RL tasks. We investigate this phenomenon and identity three issues. First, the gradients of an RL agent vary across a wide range in logarithms while their absolute values are in a small range, making neural networks hard to obtain accurate parameter updates. Second, the agent-gradient distribution is non-independent and identically distributed, leading to inefficient meta-training. Finally, due to highly stochastic agent-environment interactions, the agent-gradients have high bias and variance, which increase the difficulty of learning an optimizer for RL. We propose gradient processing, pipeline training, and a novel optimizer structure wit
    
[^90]: 通过本地规划实现样本有效的深度强化学习

    Sample Efficient Deep Reinforcement Learning via Local Planning. (arXiv:2301.12579v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.12579](http://arxiv.org/abs/2301.12579)

    提出了一种名为UFLP的算法框架，通过重置环境到高不确定性状态来提高深度强化学习的样本效率，实验证明这个简单的过程可以显著改善采样成本，并在困难的探索任务上取得超人类的表现。

    

    本文的重点是在模拟器上进行样本有效的深度强化学习。模拟器的一个有用特性是可以将环境重置到先前观察到的状态。我们提出了一种名为“不确定性优先本地规划”（UFLP）的算法框架，利用了这个特性。具体而言，在每个数据收集迭代中，我们的元算法以一定的概率将环境重置为具有高不确定性的观察状态，而不是根据初始状态分布进行采样。然后，代理-环境交互就像在标准在线强化学习设置中一样进行。我们证明了这个简单的过程可以显著改善几个基线强化学习算法在困难的探索任务上的采样成本。值得注意的是，利用我们的框架，我们可以使用简单（分布式）双重DQN在臭名昭著的难度很高的Atari游戏“蒙特祖玛之复仇”上实现超人类的表现。我们的工作可以看作是一种有效的方法。

    The focus of this work is sample-efficient deep reinforcement learning (RL) with a simulator. One useful property of simulators is that it is typically easy to reset the environment to a previously observed state. We propose an algorithmic framework, named uncertainty-first local planning (UFLP), that takes advantage of this property. Concretely, in each data collection iteration, with some probability, our meta-algorithm resets the environment to an observed state which has high uncertainty, instead of sampling according to the initial-state distribution. The agent-environment interaction then proceeds as in the standard online RL setting. We demonstrate that this simple procedure can dramatically improve the sample cost of several baseline RL algorithms on difficult exploration tasks. Notably, with our framework, we can achieve super-human performance on the notoriously hard Atari game, Montezuma's Revenge, with a simple (distributional) double DQN. Our work can be seen as an efficie
    
[^91]: 通过学习保证提高公平性

    Increasing Fairness via Combination with Learning Guarantees. (arXiv:2301.10813v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.10813](http://arxiv.org/abs/2301.10813)

    该论文提出了一种公平质量度量方法，名为判别风险，旨在反映个体和群体公平性。此外，研究者还讨论了公平性是否可以在理论上得到保证。

    

    随着机器学习系统在越来越多的现实场景中得到广泛应用，对于隐藏在机器学习模型中的潜在歧视的担忧正在增加。许多技术已经被开发出来以增强公平性，包括常用的群体公平性度量和几种结合集成学习的公平感知方法。然而，现有的公平度量只能关注其中之一，即群体公平性或个体公平性，它们之间的硬性兼容性暗示了即使其中之一得到满足，仍可能存在偏见。此外，现有的提升公平性的机制通常只提供经验结果来证明其有效性，但很少有论文讨论公平性是否可以在理论上得到保证。为了解决这些问题，本文提出了一种公平质量度量方法——判别风险，以反映个体和群体公平性两个方面。此外，我们还研究了p...

    The concern about underlying discrimination hidden in ML models is increasing, as ML systems have been widely applied in more and more real-world scenarios and any discrimination hidden in them will directly affect human life. Many techniques have been developed to enhance fairness including commonly-used group fairness measures and several fairness-aware methods combining ensemble learning. However, existing fairness measures can only focus on one aspect -- either group or individual fairness, and the hard compatibility among them indicates a possibility of remaining biases even if one of them is satisfied. Moreover, existing mechanisms to boost fairness usually present empirical results to show validity, yet few of them discuss whether fairness can be boosted with certain theoretical guarantees. To address these issues, we propose a fairness quality measure named discriminative risk in this paper to reflect both individual and group fairness aspects. Furthermore, we investigate the p
    
[^92]: 寻找电子商务营销的相似客户

    Finding Lookalike Customers for E-Commerce Marketing. (arXiv:2301.03147v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.03147](http://arxiv.org/abs/2301.03147)

    本文介绍了一个以客户为中心的营销活动中寻找相似客户的可扩展和高效系统。该系统能处理亿级客户，并使用深度学习嵌入模型和近似最近邻搜索方法来寻找感兴趣的相似客户。通过构建可解释且有意义的客户相似度度量，该模型能够处理各种业务兴趣。

    

    以客户为中心的营销活动为沃尔玛的电子商务网站流量贡献了很大的一部分。随着客户数据规模的增大，扩大营销受众以触达更多客户对电子商务公司的业务增长和为客户带来更多价值变得更为关键。在本文中，我们提出了一个可扩展且高效的系统来扩大营销活动的目标受众，该系统可以处理亿级客户。我们使用基于深度学习的嵌入模型来表示客户，使用一种近似最近邻搜索方法快速找到感兴趣的相似客户。该模型能够通过构建可解释且有意义的客户相似度度量来处理各种业务兴趣。我们进行了大量实验来展示我们的系统和客户嵌入模型的出色性能。

    Customer-centric marketing campaigns generate a large portion of e-commerce website traffic for Walmart. As the scale of customer data grows larger, expanding the marketing audience to reach more customers is becoming more critical for e-commerce companies to drive business growth and bring more value to customers. In this paper, we present a scalable and efficient system to expand targeted audience of marketing campaigns, which can handle hundreds of millions of customers. We use a deep learning based embedding model to represent customers and an approximate nearest neighbor search method to quickly find lookalike customers of interest. The model can deal with various business interests by constructing interpretable and meaningful customer similarity metrics. We conduct extensive experiments to demonstrate the great performance of our system and customer embedding model.
    
[^93]: CC-FedAvg：计算定制的联邦平均算法

    CC-FedAvg: Computationally Customized Federated Averaging. (arXiv:2212.13679v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.13679](http://arxiv.org/abs/2212.13679)

    本论文提出了一个称为CC-FedAvg的计算定制的联邦平均算法，可让参与者根据其计算预算决定在每轮中是否执行传统的本地训练或模型估算。实验结果表明，CC-FedAvg能够显著提高模型性能并降低通信成本。

    

    联邦学习是一种新兴的模型训练方式，通过分布在众多物联网设备上的数据进行模型训练。它在本质上假设参与者的计算能力相同，但实际上，由于不同的能源预算或并行执行的任务不同，参与者计算资源存在着差异。缺乏计算预算的参与者必须适当规划其受限计算资源的使用，否则他们将无法完成整个训练过程，导致模型性能下降。为了解决这个问题，我们提出了一种估算本地模型而无需计算密集迭代的策略。基于此，我们提出了计算定制的联邦平均算法(CC-FedAvg)，允许参与者根据其当前的计算预算，在每个轮次中决定是执行传统的本地训练还是模型估算。理论分析和实验结果均表明，与传统的联邦平均算法相比，CC-FedAvg能显著提高模型性能并降低通信成本。

    Federated learning (FL) is an emerging paradigm to train model with distributed data from numerous Internet of Things (IoT) devices. It inherently assumes a uniform capacity among participants. However, due to different conditions such as differing energy budgets or executing parallel unrelated tasks, participants have diverse computational resources in practice. Participants with insufficient computation budgets must plan for the use of restricted computational resources appropriately, otherwise they would be unable to complete the entire training procedure, resulting in model performance decline. To address the this issue, we propose a strategy for estimating local models without computationally intensive iterations. Based on it, we propose Computationally Customized Federated Averaging (CC-FedAvg), which allows participants to determine whether to perform traditional local training or model estimation in each round based on their current computational budgets. Both theoretical analy
    
[^94]: 何时不信任语言模型：探索参数和非参数记忆的有效性和限制。

    When Not to Trust Language Models: Investigating Effectiveness and Limitations of Parametric and Non-Parametric Memories. (arXiv:2212.10511v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10511](http://arxiv.org/abs/2212.10511)

    本文通过对10个模型和4种增强方法的实验，发现语言模型在记忆不太流行的实际知识方面存在困难，而检索增强的语言模型表现较好，提出了一种检索增强语言模型的简单有效方法。

    

    尽管大型语言模型在各种任务上表现出色，但仍然难以处理需要丰富世界知识的任务，这暗示了仅依靠其参数来编码丰富的世界知识的局限性。本文旨在通过对10个模型和4种增强方法在PopQA上进行大规模知识探测实验，以了解语言模型在记忆事实知识方面的优点和局限性。我们发现，语言模型难以记忆不太流行的实际知识，并且在长尾中，扩展规模无法明显改善记忆实际知识。然后，我们展示了检索增强的语言模型在很大程度上胜过级别大得多的语言模型，而未经协助的语言模型在涉及高流行实体的问题上仍然具有竞争力。基于这些发现，我们设计了一种简单而有效的强大和高效的检索增强语言模型方法，该方法仅在需要时检索非参数记忆。

    Despite their impressive performance on diverse tasks, large language models (LMs) still struggle with tasks requiring rich world knowledge, implying the limitations of relying solely on their parameters to encode a wealth of world knowledge. This paper aims to understand LMs' strengths and limitations in memorizing factual knowledge, by conducting large-scale knowledge probing experiments of 10 models and 4 augmentation methods on PopQA, our new open-domain QA dataset with 14k questions. We find that LMs struggle with less popular factual knowledge, and that scaling fails to appreciably improve memorization of factual knowledge in the long tail. We then show that retrieval-augmented LMs largely outperform orders of magnitude larger LMs, while unassisted LMs remain competitive in questions about high-popularity entities. Based on those findings, we devise a simple, yet effective, method for powerful and efficient retrieval-augmented LMs, which retrieves non-parametric memories only whe
    
[^95]: 通过视觉-语言模型的指令增强实现机器人技能获取

    Robotic Skill Acquisition via Instruction Augmentation with Vision-Language Models. (arXiv:2211.11736v3 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2211.11736](http://arxiv.org/abs/2211.11736)

    本文提出了一种通过视觉-语言模型的指令增强方法，利用预训练模型将互联网规模的知识导入现有机器人数据集，实现机器人技能的获取。

    

    最近几年，在学习遵循自然语言指令的机器人操作策略方面取得了很大进展。这些方法通常从机器人-语言数据语料库中学习，该数据要么是为特定任务而收集的，要么是在事后由人工昂贵地重新标注的，带有丰富的语言描述。最近，大规模预训练的视觉-语言模型（VLMs）如CLIP或ViLD已应用于机器人学习表示和场景描述。这些预训练模型能否作为机器人数据的自动标注工具，将互联网规模的知识导入现有数据集，使其对于未在其地面真实注释中反映的任务也能发挥作用？为了实现这一目标，我们引入了数据驱动的指令增强（DIAL）来用于基于语言的控制：我们利用CLIP的语义理解，利用半监督的语言标签将知识传递到大规模无标签演示数据集上。

    In recent years, much progress has been made in learning robotic manipulation policies that follow natural language instructions. Such methods typically learn from corpora of robot-language data that was either collected with specific tasks in mind or expensively re-labelled by humans with rich language descriptions in hindsight. Recently, large-scale pretrained vision-language models (VLMs) like CLIP or ViLD have been applied to robotics for learning representations and scene descriptors. Can these pretrained models serve as automatic labelers for robot data, effectively importing Internet-scale knowledge into existing datasets to make them useful even for tasks that are not reflected in their ground truth annotations? To accomplish this, we introduce Data-driven Instruction Augmentation for Language-conditioned control (DIAL): we utilize semi-supervised language labels leveraging the semantic understanding of CLIP to propagate knowledge onto large datasets of unlabelled demonstration
    
[^96]: TAX-Pose：机器人操作的任务特定跨姿势估计

    TAX-Pose: Task-Specific Cross-Pose Estimation for Robot Manipulation. (arXiv:2211.09325v2 [cs.RO] CROSS LISTED)

    [http://arxiv.org/abs/2211.09325](http://arxiv.org/abs/2211.09325)

    本论文提出了一种名为TAX-Pose的系统，在机器人操作中实现了任务特定跨姿势的估计。通过学习对象之间的对应关系，这种系统能够在给定操作任务的情况下准确估计两个对象之间的跨姿势，并利用估计结果指导下游的运动规划。

    

    我们如何赋予机器人有效地操作未知物体的能力，并基于示范转移相关技能？端到端学习方法通常无法泛化到新的物体或未见过的配置。相反，我们关注交互对象相关部分的任务特定姿势关系。我们推测这种关系是一种可以转移到同一类别新物体的操作任务的可泛化概念；例如，平底锅相对于烤箱的姿势关系或者杯子相对于杯架的姿势关系。我们称这种任务特定姿势关系为“跨姿势”，并提供了该概念的数学定义。我们提出了一个基于视觉的系统，使用学习的对象间对应关系来学习估计给定操作任务的两个对象之间的跨姿势。然后，估计的跨姿势用于引导下游的运动规划器将对象操纵到所需的姿势。

    How do we imbue robots with the ability to efficiently manipulate unseen objects and transfer relevant skills based on demonstrations? End-to-end learning methods often fail to generalize to novel objects or unseen configurations. Instead, we focus on the task-specific pose relationship between relevant parts of interacting objects. We conjecture that this relationship is a generalizable notion of a manipulation task that can transfer to new objects in the same category; examples include the relationship between the pose of a pan relative to an oven or the pose of a mug relative to a mug rack. We call this task-specific pose relationship "cross-pose" and provide a mathematical definition of this concept. We propose a vision-based system that learns to estimate the cross-pose between two objects for a given manipulation task using learned cross-object correspondences. The estimated cross-pose is then used to guide a downstream motion planner to manipulate the objects into the desired po
    
[^97]: MixUp-MIL：一种新的数据增强方法用于多示例学习并在甲状腺癌诊断中的研究

    MixUp-MIL: Novel Data Augmentation for Multiple Instance Learning and a Study on Thyroid Cancer Diagnosis. (arXiv:2211.05862v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.05862](http://arxiv.org/abs/2211.05862)

    提出了一种新的数据增强方法MixUp-MIL用于多示例学习，通过应用切片内插值方法可以改善甲状腺癌诊断的准确性。

    

    在像素或补丁级别注释缺失的情况下，多示例学习展示了一种基于整张切片图像的诊断的强大方法。尽管整张切片图像的大小很大，但个别切片的数量往往相对较小，导致标记样本数量少。为了提高训练效果，我们提出并研究了基于特征向量的线性插值（即MixUp）思想的不同数据增强策略。基于最先进的多示例学习架构和两个甲状腺癌数据集，进行了一项详尽的研究，考虑了多种常见的数据增强策略。尽管基于原始MixUp方法的策略表现出准确度降低，但使用一种新颖的切片内插值方法却实现了一致的准确度提高。

    Multiple instance learning exhibits a powerful approach for whole slide image-based diagnosis in the absence of pixel- or patch-level annotations. In spite of the huge size of hole slide images, the number of individual slides is often rather small, leading to a small number of labeled samples. To improve training, we propose and investigate different data augmentation strategies for multiple instance learning based on the idea of linear interpolations of feature vectors (known as MixUp). Based on state-of-the-art multiple instance learning architectures and two thyroid cancer data sets, an exhaustive study is conducted considering a range of common data augmentation strategies. Whereas a strategy based on to the original MixUp approach showed decreases in accuracy, the use of a novel intra-slide interpolation method led to consistent increases in accuracy.
    
[^98]: 多模态时间数据的主动获取：一个具有挑战性的决策任务

    Active Acquisition for Multimodal Temporal Data: A Challenging Decision-Making Task. (arXiv:2211.05039v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.05039](http://arxiv.org/abs/2211.05039)

    该论文提出了一个具有挑战性的决策任务，主动获取多模态时间数据。通过权衡获取成本和预测性能，学习代理程序来主动选择获取的输入模态。该方法能够解决具有实际相关推理技能的合成情景，并在真实数据集上成功学习到成本反应式的获取行为，但无法学习到自适应的获取策略，突显了任务的困难性。

    

    我们介绍了一个具有挑战性的决策任务，我们称之为多模态时间数据的主动获取（A2MT）。在许多实际场景中，输入特征在测试时不容易获得，必须以较大代价获取。通过A2MT，我们的目标是学习代理程序，使其能够主动选择要获取的输入模态，权衡获取成本与预测性能。A2MT扩展了之前的任务，称为主动特征获取，以便进行关于高维输入的时间决策。我们提出了一种基于Perceiver IO架构的方法来实现A2MT。我们的代理程序能够解决一个需要实际相关的跨模态推理技能的新颖合成情景。在两个大规模的真实数据集Kinetics-700和AudioSet上，我们的代理程序成功地学习了成本反应式的获取行为。然而，消融实验表明它们无法学习到自适应的获取策略，突显了该任务的困难性。

    We introduce a challenging decision-making task that we call active acquisition for multimodal temporal data (A2MT). In many real-world scenarios, input features are not readily available at test time and must instead be acquired at significant cost. With A2MT, we aim to learn agents that actively select which modalities of an input to acquire, trading off acquisition cost and predictive performance. A2MT extends a previous task called active feature acquisition to temporal decision making about high-dimensional inputs. We propose a method based on the Perceiver IO architecture to address A2MT in practice. Our agents are able to solve a novel synthetic scenario requiring practically relevant cross-modal reasoning skills. On two large-scale, real-world datasets, Kinetics-700 and AudioSet, our agents successfully learn cost-reactive acquisition behavior. However, an ablation reveals they are unable to learn adaptive acquisition strategies, emphasizing the difficulty of the task even for 
    
[^99]: 强化学习的因果解释：量化状态和时间重要性

    Causal Explanation for Reinforcement Learning: Quantifying State and Temporal Importance. (arXiv:2210.13507v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2210.13507](http://arxiv.org/abs/2210.13507)

    本文开发了一种因果解释机制，能够量化状态对行动的因果重要性和随时间变化的重要性，并通过一系列的模拟研究证明了该机制在强化学习策略解释方面的优势。

    

    解释性在机器学习中起着越来越重要的作用。此外，人们通过因果镜头来看待世界，因此更倾向于因果解释而非关联解释。因此，在本文中，我们开发了一种因果解释机制，以量化状态对行动的因果重要性和随时间变化的重要性。我们还通过一系列的模拟研究，包括农田灌溉、21点、避碰和月球着陆器等，展示了我们机制在强化学习策略解释方面相对于最先进的关联方法的优势。

    Explainability plays an increasingly important role in machine learning. Furthermore, humans view the world through a causal lens and thus prefer causal explanations over associational ones. Therefore, in this paper, we develop a causal explanation mechanism that quantifies the causal importance of states on actions and such importance over time. We also demonstrate the advantages of our mechanism over state-of-the-art associational methods in terms of RL policy explanation through a series of simulation studies, including crop irrigation, Blackjack, collision avoidance, and lunar lander.
    
[^100]: RSC: 通过随机稀疏计算加速图神经网络训练

    RSC: Accelerating Graph Neural Networks Training via Randomized Sparse Computations. (arXiv:2210.10737v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.10737](http://arxiv.org/abs/2210.10737)

    通过随机稀疏计算，本研究提出了一种加速图神经网络训练的方法，解决了稀疏图操作难以加速和不规则数据格式导致的效率问题。

    

    图神经网络（GNN）的训练非常耗时，因为硬件难以加速稀疏图操作。先前的研究通过基于采样的逼近来降低时间复杂度，但牺牲了计算精度。在这个思路的基础上，以往的工作成功地加速了基于稠密矩阵的操作（如卷积和线性操作），准确度下降可以忽略不计。然而，与稠密矩阵不同，稀疏矩阵以不规则的数据格式存储，每行/列可能有不同数量的非零元素。因此，与稠密矩阵相比，逼近稀疏操作存在两个独特的挑战：（1）我们无法直接控制逼近稀疏操作的效率，因为计算仅在非零元素上执行；（2）基于子采样的稀疏矩阵处理效率更低，因为存在不规则数据格式。为了解决这些问题，我们的关键思想是控制准确度和效率的权衡。

    The training of graph neural networks (GNNs) is extremely time consuming because sparse graph-based operations are hard to be accelerated by hardware. Prior art explores trading off the computational precision to reduce the time complexity via sampling-based approximation. Based on the idea, previous works successfully accelerate the dense matrix based operations (e.g., convolution and linear) with negligible accuracy drop. However, unlike dense matrices, sparse matrices are stored in the irregular data format such that each row/column may have different number of non-zero entries. Thus, compared to the dense counterpart, approximating sparse operations has two unique challenges (1) we cannot directly control the efficiency of approximated sparse operation since the computation is only executed on non-zero entries; (2) sub-sampling sparse matrices is much more inefficient due to the irregular data format. To address the issues, our key idea is to control the accuracy-efficiency trade o
    
[^101]: 嵌入作为认识状态：关于用于获得知识的汇聚运算符的限制

    Embeddings as Epistemic States: Limitations on the Use of Pooling Operators for Accumulating Knowledge. (arXiv:2210.05723v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2210.05723](http://arxiv.org/abs/2210.05723)

    本文研究了用于汇聚信息的各种汇聚运算符在嵌入编码中的应用。我们发现所有考虑的汇聚运算符都可以满足认识汇聚原则，但这仅在嵌入具有足够高维度并满足特定约束的情况下成立。这些约束对嵌入在实践中的使用具有重要影响。

    

    各种神经网络架构依靠汇聚运算符来聚合来自不同来源的信息。在这种情况下，通常默认向量编码为认识状态，即向量捕捉到已获取有关某些感兴趣属性的证据，并且汇聚这些向量会得到一个结合这些证据的向量。我们研究了一系列标准汇聚运算符，在什么条件下它们与这个被称为认识汇聚原则的想法兼容。我们发现所有考虑的汇聚运算符都可以满足认识汇聚原则，但这仅在嵌入具有足够高维度的情况下成立，对于大多数汇聚运算符，嵌入需要满足特定约束（例如具有非负坐标）。此外，我们还展示了这些约束对嵌入在实践中的使用具有重要影响。特别是，我们发现当认识汇聚原则不能被满足时，使用一个无约束的稀疏解更好。

    Various neural network architectures rely on pooling operators to aggregate information coming from different sources. It is often implicitly assumed in such contexts that vectors encode epistemic states, i.e. that vectors capture the evidence that has been obtained about some properties of interest, and that pooling these vectors yields a vector that combines this evidence. We study, for a number of standard pooling operators, under what conditions they are compatible with this idea, which we call the epistemic pooling principle. While we find that all the considered pooling operators can satisfy the epistemic pooling principle, this only holds when embeddings are sufficiently high-dimensional and, for most pooling operators, when the embeddings satisfy particular constraints (e.g. having non-negative coordinates). We furthermore show that these constraints have important implications on how the embeddings can be used in practice. In particular, we find that when the epistemic pooling
    
[^102]: FAIR-FATE: 具有动量的公平联邦学习

    FAIR-FATE: Fair Federated Learning with Momentum. (arXiv:2209.13678v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.13678](http://arxiv.org/abs/2209.13678)

    FAIR-FATE是一种公平联邦学习算法，通过公平感知的聚合方法实现组公平性并保持高效用性。

    

    虽然公平感知的机器学习算法受到了越来越多的关注，但重点一直是集中式机器学习，对分散式方法的研究还不够。联邦学习是一种分散式的机器学习形式，其中客户端训练本地模型，服务器汇总它们以获得共享的全局模型。客户端之间的数据异质性是联邦学习的一个常见特征，这可能导致或加剧由敏感属性（如种族或性别）定义的特权组的歧视。在这项工作中，我们提出了FAIR-FATE：一种新颖的公平联邦学习算法，旨在通过一种公平感知的聚合方法计算全局模型，从而实现组公平性同时保持高效用性。为实现这一目标，全局模型更新采用一个动量项来估计公平模型更新，帮助克服非公平梯度的震荡。

    While fairness-aware machine learning algorithms have been receiving increasing attention, the focus has been on centralized machine learning, leaving decentralized methods underexplored. Federated Learning is a decentralized form of machine learning where clients train local models with a server aggregating them to obtain a shared global model. Data heterogeneity amongst clients is a common characteristic of Federated Learning, which may induce or exacerbate discrimination of unprivileged groups defined by sensitive attributes such as race or gender. In this work we propose FAIR-FATE: a novel FAIR FederATEd Learning algorithm that aims to achieve group fairness while maintaining high utility via a fairness-aware aggregation method that computes the global model by taking into account the fairness of the clients. To achieve that, the global model update is computed by estimating a fair model update using a Momentum term that helps to overcome the oscillations of non-fair gradients. To 
    
[^103]: 学习什么时候为人类决策者提供建议

    Learning When to Advise Human Decision Makers. (arXiv:2209.13578v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2209.13578](http://arxiv.org/abs/2209.13578)

    本文提出了一种新颖的人工智能系统设计，其中算法与人类用户以双向互动的方式交互，仅在对用户的决策有益时提供建议。实验证明，这种方法能够改善人类的决策能力，并在促进人类学习、保留人类决策的补充优势方面具有额外的优势。

    

    人工智能系统越来越多地被用于提供建议，以促进在医疗、刑事司法和金融等各个领域的人类决策。我们提出一个新颖的人工智能系统设计，其中算法与人类用户以双向互动的方式交互，旨在仅在对用户的决策有益时提供建议。一项大规模实验的结果表明，与固定的非交互式建议方法相比，我们的建议方法能够在需要的时候提供建议，并显著改善人类的决策能力。这种方法在促进人类学习、保留人类决策的补充优势方面还具有额外的优势。

    Artificial intelligence (AI) systems are increasingly used for providing advice to facilitate human decision making in a wide range of domains, such as healthcare, criminal justice, and finance. Motivated by limitations of the current practice where algorithmic advice is provided to human users as a constant element in the decision-making pipeline, in this paper we raise the question of when should algorithms provide advice? We propose a novel design of AI systems in which the algorithm interacts with the human user in a two-sided manner and aims to provide advice only when it is likely to be beneficial for the user in making their decision. The results of a large-scale experiment show that our advising approach manages to provide advice at times of need and to significantly improve human decision making compared to fixed, non-interactive, advising approaches. This approach has additional advantages in facilitating human learning, preserving complementary strengths of human decision ma
    
[^104]: 生成扩散模型综述

    A Survey on Generative Diffusion Model. (arXiv:2209.02646v9 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2209.02646](http://arxiv.org/abs/2209.02646)

    本综述总结了生成扩散模型的先进技术，包括采样加速、新的扩散过程设计以及在不同空间中实现扩散模型的策略。这些创新努力旨在提高扩散模型的功能和效率。

    

    深度生成模型是一种用于数据生成的重要方法，在各个领域中被用来生成高质量的样本。生成扩散模型作为一种新兴的深度生成模型，因其出色的生成质量而受到广泛关注。然而，它们具有一定的局限性，包括耗时的迭代生成过程和限制在高维欧几里得空间中。本综述介绍了大量旨在增强扩散模型的先进技术，包括采样加速和新的扩散过程设计。此外，我们还深入探讨了在流形和离散空间中实现扩散模型的策略，扩散模型的最大似然训练方法，以及创建两个任意分布之间桥梁的方法。我们讨论的创新代表了近年来改进扩散模型功能和效率的努力。

    Deep generative models are a prominent approach for data generation, and have been used to produce high quality samples in various domains. Diffusion models, an emerging class of deep generative models, have attracted considerable attention owing to their exceptional generative quality. Despite this, they have certain limitations, including a time-consuming iterative generation process and confinement to high-dimensional Euclidean space. This survey presents a plethora of advanced techniques aimed at enhancing diffusion models, including sampling acceleration and the design of new diffusion processes. In addition, we delve into strategies for implementing diffusion models in manifold and discrete spaces, maximum likelihood training for diffusion models, and methods for creating bridges between two arbitrary distributions. The innovations we discuss represent the efforts for improving the functionality and efficiency of diffusion models in recent years. To examine the efficacy of existi
    
[^105]: 在临床存在下的填补策略：对算法公平性的影响

    Imputation Strategies Under Clinical Presence: Impact on Algorithmic Fairness. (arXiv:2208.06648v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2208.06648](http://arxiv.org/abs/2208.06648)

    本文研究了填补选择对不同群体的重建误差和下游预测的算法公平性属性的影响。

    

    机器学习可能会强化数据中的偏见，而我们在这个工作中提出，数据中缺失的内容也会产生偏见。在医疗领域，偏见已经在医疗历史上留下了深深的烙印，导致边缘化群体受到不平等的护理。缺失数据中的模式通常反映了这些群体的差异，但是特定群体缺失的算法公平性影响还不太清楚。尽管其潜在影响巨大，但填补往往被忽视为一个预处理步骤，而关注点放在了重建误差的减少和整体性能上，忽略了填补如何对不同群体产生影响。我们的工作研究了填补选择对不同群体的重建误差和下游预测的算法公平性属性的影响。

    Machine learning risks reinforcing biases present in data, and, as we argue in this work, in what is absent from data. In healthcare, biases have marked medical history, leading to unequal care affecting marginalised groups. Patterns in missing data often reflect these group discrepancies, but the algorithmic fairness implications of group-specific missingness are not well understood. Despite its potential impact, imputation is often an overlooked preprocessing step, with attention placed on the reduction of reconstruction error and overall performance, ignoring how imputation can affect groups differently. Our work studies how imputation choices affect reconstruction errors across groups and algorithmic fairness properties of downstream predictions.
    
[^106]: 真值集代数：一种证明逻辑连接符无法定义的新方法。

    Truth Set Algebra: A New Way to Prove Undefinability. (arXiv:2208.04422v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2208.04422](http://arxiv.org/abs/2208.04422)

    本文提出了真值集代数，一种用于证明逻辑连接符相互无法定义的新方法。

    

    本文提出了一种新的技术，用于证明通过彼此之间的逻辑连接符的不可定义性，并通过几个例子说明了该技术。其中一些结果是现有定理的新证明，另一些结果是本文的原创。

    The article proposes a new technique for proving the undefinability of logical connectives through each other and illustrates the technique with several examples. Some of the obtained results are new proofs of the existing theorems, others are original to this work.
    
[^107]: 基于压力分布分析的婴儿运动分类——研究和临床应用的附加价值

    Infant movement classification through pressure distribution analysis -- added value for research and clinical implementation. (arXiv:2208.00884v2 [eess.SP] UPDATED)

    [http://arxiv.org/abs/2208.00884](http://arxiv.org/abs/2208.00884)

    本文提出了一种创新型的非侵入式方法，使用压力传感器对婴儿的一般运动进行分类，旨在实现早期神经肌肉障碍（如脑瘫）的客观检测。研究结果表明，使用压力数据可以区分婴儿的典型运动模式，即“坐立不安期”和“坐立不安前期”。

    

    本研究旨在通过使用压力传感设备来对婴儿的一般运动进行分类，从而实现早期的神经肌肉障碍（如脑瘫）的客观检测。本文测试了使用压力数据来区分“坐立不安期”（即坐立不安运动）与“坐立不安前期”（即扭动运动）的典型运动模式的可行性。在此过程中，我们记录了每个婴儿在出生后 4-16 周的间隔期内连续七个实验室会话的多模态传感器数据，包括来自一个 32x32 网格压力传感垫及其 1024 个传感器的压力数据。为了验证概念，从两个目标年龄段中，每个持续 5 秒的 1776 个压力数据片段被用于运动分类。每个片段都是根据相应的同步视频数据由人工评估员进行预注释的，标记为坐立不安存在或不存在。

    Aiming at objective early detection of neuromotor disorders such as cerebral palsy, we proposed an innovative non-intrusive approach using a pressure sensing device to classify infant general movements (GMs). Here, we tested the feasibility of using pressure data to differentiate typical GM patterns of the ''fidgety period'' (i.e., fidgety movements) vs. the ''pre-fidgety period'' (i.e., writhing movements). Participants (N = 45) were sampled from a typically-developing infant cohort. Multi-modal sensor data, including pressure data from a 32x32-grid pressure sensing mat with 1024 sensors, were prospectively recorded for each infant in seven succeeding laboratory sessions in biweekly intervals from 4-16 weeks of post-term age. For proof-of-concept, 1776 pressure data snippets, each 5s long, from the two targeted age periods were taken for movement classification. Each snippet was pre-annotated based on corresponding synchronised video data by human assessors as either fidgety present (
    
[^108]: MABe22：一种用于学习行为表示的多物种多任务基准

    MABe22: A Multi-Species Multi-Task Benchmark for Learned Representations of Behavior. (arXiv:2207.10553v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2207.10553](http://arxiv.org/abs/2207.10553)

    MABe22是一个多物种多任务基准，用于评估学习行为表示的质量。它采集了来自各种生物学实验的数据，测试了多种自监督学习方法，并发现人类行动数据集上的方法不能完全适用于动物数据集。

    

    我们引入了MABe22，一个大规模的多智能体视频和轨迹基准，用于评估学习行为表示的质量。该数据集采集自各种生物学实验，包括三个相互作用的小鼠三元组（470万帧的视频+姿态跟踪数据，1000万帧的仅姿态数据），共生甲虫-蚂蚁相互作用（1000万帧的视频数据）和一群互动的苍蝇（440万帧的姿态跟踪数据）。除了这些数据，我们还引入了一系列真实生活中的下游分析任务，以评估学习表示的质量，通过评估它们在保留关于实验条件（例如品系、时间、光遗传刺激）和动物行为信息方面的能力。我们测试了多种最先进的自监督视频和轨迹表示学习方法，以展示我们基准的用途，并揭示了使用人类行动数据集开发的方法不能完全适用于动物数据集。

    We introduce MABe22, a large-scale, multi-agent video and trajectory benchmark to assess the quality of learned behavior representations. This dataset is collected from a variety of biology experiments, and includes triplets of interacting mice (4.7 million frames video+pose tracking data, 10 million frames pose only), symbiotic beetle-ant interactions (10 million frames video data), and groups of interacting flies (4.4 million frames of pose tracking data). Accompanying these data, we introduce a panel of real-life downstream analysis tasks to assess the quality of learned representations by evaluating how well they preserve information about the experimental conditions (e.g. strain, time of day, optogenetic stimulation) and animal behavior. We test multiple state-of-the-art self-supervised video and trajectory representation learning methods to demonstrate the use of our benchmark, revealing that methods developed using human action datasets do not fully translate to animal datasets.
    
[^109]: 重新思考科学发现中符号回归数据集和基准

    Rethinking Symbolic Regression Datasets and Benchmarks for Scientific Discovery. (arXiv:2206.10540v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.10540](http://arxiv.org/abs/2206.10540)

    本文重新审视并重新创建了符号回归数据集，以评估符号回归在科学发现中的潜力和能力，并提出使用归一化编辑距离进行度量。

    

    本文重新审视符号回归（SR）的数据集和评估标准，特别关注其在科学发现中的潜力。针对现有数据集中基于费曼物理讲义的一组公式，我们重新创建了120个数据集，讨论符号回归在科学发现中的性能（SRSD）。对于这120个SRSD数据集，我们仔细审查了公式及其变量的属性，设计了合理的实值范围来采样值，以便我们的新SRSD数据集可用于评估SRSD的潜力，如SR方法是否能从这样的数据集中（重新）发现物理定律。我们还创建了另外120个包含虚拟变量的数据集，以检验SR方法是否能够仅选择必要变量。另外，我们提出使用预测方程与真实方程树之间的归一化编辑距离（NED）来解决现有SR度量存在的一个关键问题，即二元度量问题。

    This paper revisits datasets and evaluation criteria for Symbolic Regression (SR), specifically focused on its potential for scientific discovery. Focused on a set of formulas used in the existing datasets based on Feynman Lectures on Physics, we recreate 120 datasets to discuss the performance of symbolic regression for scientific discovery (SRSD). For each of the 120 SRSD datasets, we carefully review the properties of the formula and its variables to design reasonably realistic sampling ranges of values so that our new SRSD datasets can be used for evaluating the potential of SRSD such as whether or not an SR method can (re)discover physical laws from such datasets. We also create another 120 datasets that contain dummy variables to examine whether SR methods can choose necessary variables only. Besides, we propose to use normalized edit distances (NED) between a predicted equation and the true equation trees for addressing a critical issue that existing SR metrics are either binary
    
[^110]: 特征有多偏见？：通过全局敏感性分析计算公正影响函数

    How Biased are Your Features?: Computing Fairness Influence Functions with Global Sensitivity Analysis. (arXiv:2206.00667v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.00667](http://arxiv.org/abs/2206.00667)

    本论文介绍了公正影响函数（FIF），通过全局敏感性分析的方法量化了不同特征对分类器偏见的影响，从而解决了公平性问题中的核心关注点。

    

    在机器学习中的公平性问题因其在高风险决策任务中的广泛应用而受到广泛关注。未受监管的机器学习分类器可能对数据中的某些人口群体表现出偏见，因此量化和减轻分类器偏见是公平性问题的核心关注点。本文旨在量化数据集中不同特征对分类器偏见的影响。为了做到这一点，我们引入了公正影响函数（FIF）。该函数将偏见分解为其在个体特征和多个特征的交集中的组成部分。关键思想是将现有的群体公平性度量表示为分类器预测的条件方差的差异，并根据全局敏感性分析的分解进行方差估计。为了估计FIFs，我们提出了一个名为FairXplainer的算法，该算法应用分类器预测的方差分解。

    Fairness in machine learning has attained significant focus due to the widespread application in high-stake decision-making tasks. Unregulated machine learning classifiers can exhibit bias towards certain demographic groups in data, thus the quantification and mitigation of classifier bias is a central concern in fairness in machine learning. In this paper, we aim to quantify the influence of different features in a dataset on the bias of a classifier. To do this, we introduce the Fairness Influence Function (FIF). This function breaks down bias into its components among individual features and the intersection of multiple features. The key idea is to represent existing group fairness metrics as the difference of the scaled conditional variances in the classifier's prediction and apply a decomposition of variance according to global sensitivity analysis. To estimate FIFs, we instantiate an algorithm FairXplainer that applies variance decomposition of classifier's prediction following l
    
[^111]: 当缺失观测的位置未知时学习隐马尔可夫模型

    Learning Hidden Markov Models When the Locations of Missing Observations are Unknown. (arXiv:2203.06527v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2203.06527](http://arxiv.org/abs/2203.06527)

    本文研究了当缺失观测的位置未知时学习隐马尔可夫模型的问题，并提供了不需要先验信息的重建算法。

    

    隐马尔可夫模型（HMM）是用于序列数据分析的最常用的统计模型之一。HMM具有处理缺失数据的能力，这也是它具有通用性的关键之一。然而，标准的HMM学习算法基于缺失观测在观测序列中的位置已知的假设。在自然科学中，这种假设常常不成立，因此通常使用特殊变体的HMM，称为Silent-state HMMs（SHMMs）。尽管这些算法被广泛使用，但它们严重依赖于潜在链的特定结构假设，比如非循环性，这限制了这些方法的适用性。而且，即使在非循环情况下，已经证明这些方法可能导致重建效果差。本文研究了从具有未知缺失观测位置数据中学习HMM的一般问题。我们提供了不需要任何先验信息的重建算法。

    The Hidden Markov Model (HMM) is one of the most widely used statistical models for sequential data analysis. One of the key reasons for this versatility is the ability of HMM to deal with missing data. However, standard HMM learning algorithms rely crucially on the assumption that the positions of the missing observations \emph{within the observation sequence} are known. In the natural sciences, where this assumption is often violated, special variants of HMM, commonly known as Silent-state HMMs (SHMMs), are used. Despite their widespread use, these algorithms strongly rely on specific structural assumptions of the underlying chain, such as acyclicity, thus limiting the applicability of these methods. Moreover, even in the acyclic case, it has been shown that these methods can lead to poor reconstruction. In this paper we consider the general problem of learning an HMM from data with unknown missing observation locations. We provide reconstruction algorithms that do not require any as
    
[^112]: CPTAM: 依存句法树聚合方法

    CPTAM: Constituency Parse Tree Aggregation Method. (arXiv:2201.07905v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2201.07905](http://arxiv.org/abs/2201.07905)

    本文提出了一种依存句法树聚合方法，通过估计不同解析器的可靠性，以持续获得高质量的聚合依存句法树。具体来说，通过最小化树之间的经典对称距离度量，罗宾逊-福尔兹距离的加权和，实现了树结构的真实性发现。

    

    许多自然语言处理任务使用依存句法分析来根据短语结构语法理解句子的句法结构。许多最先进的依存句法分析器已被提出，但它们对于相同的句子可能会提供不同的结果，特别是对于训练领域之外的语料库。本文采用真实性发现的思想，通过估计不同解析器的可靠性来聚合来自不同解析器的依存句法树，以持续获得高质量的聚合依存句法树。我们将依存句法树聚合问题分为两个步骤：结构聚合和成分标签聚合。具体地，我们提出了第一个用于树结构的真实性发现解决方案，通过最小化两个树之间的经典对称距离度量，即罗宾逊-福尔兹距离的加权和。对不同语言的基准数据集进行了广泛的实验。

    Diverse Natural Language Processing tasks employ constituency parsing to understand the syntactic structure of a sentence according to a phrase structure grammar. Many state-of-the-art constituency parsers are proposed, but they may provide different results for the same sentences, especially for corpora outside their training domains. This paper adopts the truth discovery idea to aggregate constituency parse trees from different parsers by estimating their reliability in the absence of ground truth. Our goal is to consistently obtain high-quality aggregated constituency parse trees. We formulate the constituency parse tree aggregation problem in two steps, structure aggregation and constituent label aggregation. Specifically, we propose the first truth discovery solution for tree structures by minimizing the weighted sum of Robinson-Foulds (RF) distances, a classic symmetric distance metric between two trees. Extensive experiments are conducted on benchmark datasets in different langu
    
[^113]: 通过策略梯度算法的高效多目标神经架构搜索框架

    Efficient Multi-objective Neural Architecture Search Framework via Policy Gradient Algorithm. (arXiv:2111.03892v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2111.03892](http://arxiv.org/abs/2111.03892)

    本论文提出了TND-NAS框架，利用可微架构搜索框架和多目标NAS的兼容性，通过策略梯度算法实现高效多目标神经架构搜索。实验结果表明其优于现有方法。

    

    可微架构搜索已成为神经架构搜索领域的主流研究课题，相对于早期的EA-based和RL-based方法，其高效率备受青睐。然而，这些方法已不再能够自然地应对不可微参数，如能源和资源受限效率等。针对多目标NAS领域的研究旨在解决这个问题，但由于对每个候选架构进行唯一的优化，因此需要大量的计算资源。基于此，我们提出了TND-NAS，它具有不可微参数的兼容性和不同iable NAS框架中的高效性。实验结果表明，在几个基准数据集上，我们提出的TND-NAS在搜索效率和解决方案质量方面优于现有方法。

    Differentiable architecture search has gradually become the mainstream research topic in the field of Neural Architecture Search (NAS) for its high efficiency compared with the early NAS (EA-based, RL-based) methods. Recent differentiable NAS also aims at further improving the search performance and reducing the GPU-memory consumption. However, these methods are no longer naturally capable of tackling the non-differentiable objectives, e.g., energy, resource-constrained efficiency, and other metrics, let alone the multi-objective search demands. Researches in the multi-objective NAS field target this but requires vast computational resources cause of the sole optimization of each candidate architecture. In light of this discrepancy, we propose the TND-NAS, which is with the merits of the high efficiency in differentiable NAS framework and the compatibility among non-differentiable metrics in Multi-objective NAS. Under the differentiable NAS framework, with the continuous relaxation of 
    
[^114]: 一种统一的逻辑框架用于分类器系统的解释

    A unified logical framework for explanations in classifier systems. (arXiv:2105.14452v6 [cs.LO] UPDATED)

    [http://arxiv.org/abs/2105.14452](http://arxiv.org/abs/2105.14452)

    本研究提出了一种以ceteris paribus为基础的模态语言，用于解释二进制分类器及其属性的推理。我们证明了两个关于语言基数的证明系统的完备性，并研究了无限变量和有限变量情况下的可满足性检查问题。我们还使用这种语言来形式化多种解释概念，包括对事实、对比和反事实解释以及偏见。

    

    在可解释的人工智能（XAI）领域中，布尔函数对于解释二进制分类器越来越受关注。传统的布尔函数方法采用命题逻辑。我们提出了一种以ceteris paribus为基础的模态语言，支持对二进制输入分类器及其属性进行推理。我们研究了一系列分类器模型，将其公理化为关于语言基数的两个证明系统，并证明了我们公理系统的完备性。此外，我们证明了在无限变量情况下，我们模态语言的可满足性检查问题是NEXPTIME完全的，而在有限变量情况下，该问题变为多项式复杂度。我们还在无限变量情况下确定了一个有趣的NP片段。我们利用这种语言来形式化对事实条件以及包括从属、对比和反事实解释以及偏见在内的各种解释概念。最后，我们提出了两种扩展的方法。

    Recent years have witnessed a renewed interest in Boolean function in explaining binary classifiers in the field of explainable AI (XAI). The standard approach of Boolean function is propositional logic. We present a modal language of a ceteris paribus nature which supports reasoning about binary input classifiers and their properties. We study a family of classifier models, axiomatize it as two proof systems regarding the cardinality of the language and show completeness of our axiomatics. Moreover, we prove that satisfiability checking problem for our modal language is NEXPTIME-complete in the infinite-variable case, while it becomes polynomial in the finite-variable case. We furthermore identify an interesting NP fragment of our language in the infinite-variable case. We leverage the language to formalize counterfactual conditional as well as a variety of notions of explanation including abductive, contrastive and counterfactual explanations, and biases. Finally, we present two exte
    
[^115]: 联机强化学习与模仿学习的桥梁：一个悲观的故事

    Bridging Offline Reinforcement Learning and Imitation Learning: A Tale of Pessimism. (arXiv:2103.12021v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2103.12021](http://arxiv.org/abs/2103.12021)

    本论文提出了一种新的联机强化学习框架，通过平滑插值的方式将模仿学习和纯联机强化学习统一起来。框架围绕着一种衡量行为策略与专家策略偏离程度的弱版本集中系数展开。通过该框架，研究者进一步研究了算法设计的问题：能否开发出实现最小极大最优性的算法？

    

    联机（或批次）强化学习算法旨在从固定的数据集中学习最优策略，而无需主动收集数据。根据离线数据集的组成，主要使用两种方法：适用于专家数据集的模仿学习和通常需要均匀覆盖数据集的纯联机强化学习。从实践的角度来看，数据集通常偏离这两个极端，并且通常事先不知道确切的数据组成。为了填补这一差距，我们提出了一个新的联机强化学习框架，它在数据组成的两个极端之间平滑插值，从而统一了模仿学习和纯联机强化学习。新的框架围绕一个弱版本的集中系数展开，该系数衡量了行为策略与专家策略之间的偏离程度。在这个新的框架下，我们进一步研究了算法设计的问题：能否开发出一种实现最小极大最优性的算法？

    Offline (or batch) reinforcement learning (RL) algorithms seek to learn an optimal policy from a fixed dataset without active data collection. Based on the composition of the offline dataset, two main categories of methods are used: imitation learning which is suitable for expert datasets and vanilla offline RL which often requires uniform coverage datasets. From a practical standpoint, datasets often deviate from these two extremes and the exact data composition is usually unknown a priori. To bridge this gap, we present a new offline RL framework that smoothly interpolates between the two extremes of data composition, hence unifying imitation learning and vanilla offline RL. The new framework is centered around a weak version of the concentrability coefficient that measures the deviation from the behavior policy to the expert policy alone.  Under this new framework, we further investigate the question on algorithm design: can one develop an algorithm that achieves a minimax optimal r
    
[^116]: 深度强化学习中的迁移学习综述

    Transfer Learning in Deep Reinforcement Learning: A Survey. (arXiv:2009.07888v6 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2009.07888](http://arxiv.org/abs/2009.07888)

    这篇综述调查了深度强化学习领域中的迁移学习方法的最新进展，并提供了一个对这些方法进行分类的框架。分析了它们的目标、方法学、兼容的强化学习背景以及实际应用，并探讨了迁移学习与其他相关主题之间的联系。

    

    强化学习是解决序列决策问题的学习范式。近年来，随着深度神经网络的快速发展，强化学习取得了显著的进展。除了在机器人和游戏等诸多领域中具有良好前景的强化学习，迁移学习作为一种解决强化学习面临的各种挑战的方法已经出现，通过从外部专业知识中转移知识，以提高学习过程的效率和效果。在这项综述中，我们系统地调查了深度强化学习领域中的迁移学习方法的最新进展。具体而言，我们提供了一个对最先进的迁移学习方法进行分类的框架，在此框架下分析了它们的目标、方法学、兼容的强化学习背景以及实际应用。我们还探讨了迁移学习与其他相关主题之间的联系。

    Reinforcement learning is a learning paradigm for solving sequential decision-making problems. Recent years have witnessed remarkable progress in reinforcement learning upon the fast development of deep neural networks. Along with the promising prospects of reinforcement learning in numerous domains such as robotics and game-playing, transfer learning has arisen to tackle various challenges faced by reinforcement learning, by transferring knowledge from external expertise to facilitate the efficiency and effectiveness of the learning process. In this survey, we systematically investigate the recent progress of transfer learning approaches in the context of deep reinforcement learning. Specifically, we provide a framework for categorizing the state-of-the-art transfer learning approaches, under which we analyze their goals, methodologies, compatible reinforcement learning backbones, and practical applications. We also draw connections between transfer learning and other relevant topics 
    
[^117]: 《因果思维失败》

    Failures of Contingent Thinking. (arXiv:2007.07703v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2007.07703](http://arxiv.org/abs/2007.07703)

    本文提供了分析智能体错误解读或错误感知真实决策问题的理论框架，并提出了一种行为定义来评估智能体因果思维水平，同时提供了一种策略来识别智能体在缺乏完全理性的情况下的信念。

    

    本文提供了一个理论框架来分析一个错误解读或错误感知真实决策问题的智能体。我们展示了一系列行为在实验环境中观察到的表现为无法理解含义，换句话说，无法正确考虑各种与关键支付相关的情况之间的逻辑关系。我们提出了对感知因果关系的行为定义，从而提供了一种引导技术，并展示了一个智能体对因果关系的解释确定了其行为的主观状态空间。通过分析这个状态空间，我们描述了驱动经验现象的逻辑复杂性的不同基准。我们区分了静态和动态的理性。因此，我们的框架既提供了评估智能体因果思维水平的方法，又提供了在没有完全理性的情况下识别其信念的策略。

    In this paper, we provide a theoretical framework to analyze an agent who misinterprets or misperceives the true decision problem she faces. We show that a wide range of behavior observed in experimental settings manifest as failures to perceive implications, in other words, to properly account for the logical relationships between various payoff relevant contingencies. We present a behavioral definition of perceived implication, thereby providing an elicitation technique, and show that an agent's account of implication identifies a subjective state-space that underlies her behavior. By analyzing this state-space, we characterize distinct benchmarks of logical sophistication that drive empirical phenomena. We disentangle static and dynamic rationality. Thus, our framework delivers both a methodology for assessing an agent's level of contingent thinking and a strategy for identifying her beliefs in the absence full rationality.
    
[^118]: 交互语义模型

    A model of interaction semantics. (arXiv:2007.06258v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2007.06258](http://arxiv.org/abs/2007.06258)

    本研究提出了一种交互语义模型，通过构建系统交互模型，并不依赖于字符到概念的“心理”映射，来理解交互中字符的“含义”。

    

    本文基于交互语义模型，提出了关于交互中“含义”理解的某种观点。通过构建系统交互模型，我将交互语义模型结构化，类似于形式语言的语义：首先，我确定适当的变量以赋值，然后，我确定解释函数以提供意义。从而得到一个交互语义模型，可以不依赖于从字符到概念的“心理”映射，这与路德维希·维特根斯坦的观点相符。

    Purpose: The purpose of this article is to propose, based on a model of an interaction semantics, a certain understanding of the ''meaning'' of the exchanged characters within an interaction.  Methodology: Based on a model of system interaction, I structure the model of interaction semantics similar to the semantics of a formal language: first, I identify adequate variables in my interaction model to assign values to, and second, I identify the interpretation function to provide meaning. Thereby I arrive at a model of interaction semantics which, in the sense of the late Ludwig Wittgenstein, can do without a 'mental' mapping from characters to concepts.  Findings: The key findings are a better understanding of the tight relation between the informatical approach to model interactions and game theory; of the central 'chicken and egg' problem, any natural language has to solve, namely that to interact sensibly, we have to understand each other and to acquire a common understanding, we ha
    
[^119]: 使用重要权重示范的元适应性学习

    Meta Adaptation using Importance Weighted Demonstrations. (arXiv:1911.10322v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/1911.10322](http://arxiv.org/abs/1911.10322)

    本文提出了一种使用重要权重示范的元适应性学习算法，通过对特定任务的先前知识进行分配重要权重，实现了在任何相关任务上的泛化。实验证明，该方法能够使机器人在多样化环境任务中进行训练，并通过少量示范适应未知环境。

    

    由于其高样本效率，模仿学习变得极为流行。然而，在实际应用场景中，由于大多数任务的轨迹分布不断变化，仅仅基于连续聚合的数据来进行模型拟合是徒劳的。在某些情况下，分布发生如此大的变化，以至于智能体很难推断出新任务。我们提出了一种新颖的算法，通过对一组特定任务的先前知识进行分配重要权重，从而在任何相关任务上进行泛化。我们展示了一些实验，在这些实验中，机器人从多样化的环境任务中训练，并能够通过少量示范进行学习，从而适应未知环境。我们还开发了一个原型机器人系统，在视觉导航任务上测试我们的方法，并获得了能够验证这些假设的实验证据。

    Imitation learning has gained immense popularity because of its high sample-efficiency. However, in real-world scenarios, where the trajectory distribution of most of the tasks dynamically shifts, model fitting on continuously aggregated data alone would be futile. In some cases, the distribution shifts, so much, that it is difficult for an agent to infer the new task. We propose a novel algorithm to generalize on any related task by leveraging prior knowledge on a set of specific tasks, which involves assigning importance weights to each past demonstration. We show experiments where the robot is trained from a diversity of environmental tasks and is also able to adapt to an unseen environment, using few-shot learning. We also developed a prototype robot system to test our approach on the task of visual navigation, and experimental results obtained were able to confirm these suppositions.
    

