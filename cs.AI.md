# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Deep reinforcement learning for the dynamic vehicle dispatching problem: An event-based approach.](http://arxiv.org/abs/2307.07508) | 本文介绍了将动态车辆调度问题建模为半马尔可夫决策过程的基于事件的方法，并通过实际场景的数值实验验证了该方法的有效性。 |
| [^2] | [Interactive Spatiotemporal Token Attention Network for Skeleton-based General Interactive Action Recognition.](http://arxiv.org/abs/2307.07469) | 本研究提出了一个交互式时空注意力网络(ISTA-Net)，通过同时建模空间、时间和交互关系，解决了以往方法在交互动作识别中的限制和不足。我们的网络利用分段器将多个不同实体的动作划分成交互式时空令牌(ISTs)，并通过多头自注意力块和3D卷积实现了在ISTs的三个维度上的联合学习。 |
| [^3] | [Structured Pruning of Neural Networks for Constraints Learning.](http://arxiv.org/abs/2307.07457) | 本文将神经网络结构化裁剪应用于约束学习，解决了人工神经网络参数过多导致可扩展性问题的挑战。 |
| [^4] | [Depth-bounded Epistemic Logic.](http://arxiv.org/abs/2307.07448) | 这篇论文介绍了一种针对有深度限制的智能体的认知逻辑扩展DBEL，通过引入深度原子来实现对智能体深度的明确推理，并提供了DBEL的公理化和扩展。同时，作者还提出了DPAL逻辑以及其它两种扩展，并指出了这些扩展的不可取的特性。 |
| [^5] | [TSNet-SAC: Leveraging Transformers for Efficient Task Scheduling.](http://arxiv.org/abs/2307.07445) | TSNet-SAC是一种基于Transformer的创新网络，利用启发式算法指导训练，通过引入滑动增强组件和扩展组件来提高鲁棒性和解决算法缺陷，适应不同的接入场景。模拟实验表明，TSNet-SAC在准确性和鲁棒性方面优于现有网络，并具有更优的调度决策延迟。 |
| [^6] | [Can Large Language Models Empower Molecular Property Prediction?.](http://arxiv.org/abs/2307.07443) | 本研究提出了利用大型语言模型（LLMs）对分子属性预测进行增强的方法，通过零/少样本分子分类和生成新的解释来推进这一目标。 |
| [^7] | [Real-time Percussive Technique Recognition and Embedding Learning for the Acoustic Guitar.](http://arxiv.org/abs/2307.07426) | 本研究开发了针对增强击弦指弹的实时音乐信息检索技术，通过卷积神经网络和变分自动编码器，实现了吉他体击打的识别和嵌入学习。 |
| [^8] | [Named entity recognition using GPT for identifying comparable companies.](http://arxiv.org/abs/2307.07420) | 本文使用GPT以识别可比公司。传统的可比公司方法通常使用定性方法来识别相似的同行公司，而我们使用大型语言模型通过提取公司描述/摘要从而进行相似性分析，实现更量化的方法。 |
| [^9] | [RoPDA: Robust Prompt-based Data Augmentation for Low-Resource Named Entity Recognition.](http://arxiv.org/abs/2307.07417) | RoPDA是一种用于低资源NER的数据增强方法，通过基于预训练语言模型和连续提示进行实体和上下文增强，并提出了自一致性过滤和混合技术以优化增强样本的利用。 |
| [^10] | [AutoHint: Automatic Prompt Optimization with Hint Generation.](http://arxiv.org/abs/2307.07415) | 本文介绍了AutoHint，一种用于大型语言模型的自动提示生成和优化的新框架。该方法通过从输入-输出演示中生成提示，并利用上下文学习和零样本学习的优点，优化原始提示，从而提高了大型语言模型在特定任务上的表现。 |
| [^11] | [Exploiting Counter-Examples for Active Learning with Partial labels.](http://arxiv.org/abs/2307.07413) | 本论文研究了一个新的问题，即带有部分标签的主动学习（ALPL）。为了解决过度拟合问题和增强选择代表性样本的过程，我们利用反例构造了一种简单有效的 WorseNet 来进行学习。 |
| [^12] | [KU-DMIS-MSRA at RadSum23: Pre-trained Vision-Language Model for Radiology Report Summarization.](http://arxiv.org/abs/2307.07409) | 本文介绍了一种新型的预训练视觉语言模型CheXOFA，通过在一般领域的训练数据上进行预训练，然后转移到胸部X射线领域，该模型能够有效地学习所需的知识和技能，并在放射学报告摘要任务上取得了卓越的性能，获得了RadSum23测试集的第一名。 |
| [^13] | [Rank Your Summaries: Enhancing Bengali Text Summarization via Ranking-based Approach.](http://arxiv.org/abs/2307.07392) | 该论文利用基于排名的方法，通过比较四种不同的预训练孟加拉文本摘要模型的输出来确定给定文本的最准确和信息丰富的摘要。 |
| [^14] | [AIC-AB NET: A Neural Network for Image Captioning with Spatial Attention and Text Attributes.](http://arxiv.org/abs/2307.07370) | 一种新型的图像字幕神经网络AIC-AB NET将空间注意力和文本属性相结合，通过自适应空间注意力和输入文本属性信息，提升图像字幕的性能和减少不确定性。 |
| [^15] | [Are Large Language Models a Threat to Digital Public Goods? Evidence from Activity on Stack Overflow.](http://arxiv.org/abs/2307.07367) | 大型语言模型如ChatGPT可能对公开的人工生成数据和知识资源带来重大影响，尤其在Stack Overflow这样的编程问答平台上，ChatGPT的使用导致了活动显著减少。 |
| [^16] | [Representation Learning With Hidden Unit Clustering For Low Resource Speech Applications.](http://arxiv.org/abs/2307.07325) | 本文提出了一种使用隐藏单元聚类框架进行自监督表示学习的方法，用于无文本资源下的语音表示学习。模型使用卷积神经网络和长短期记忆层对音频样本进行处理并生成上下文向量表示，通过隐藏单元聚类框架将这些表示归类为少量类似音素的单元，用于学习语义丰富的语音表示。研究结果表明这种方法可以提高模型性能。 |
| [^17] | [C3: Zero-shot Text-to-SQL with ChatGPT.](http://arxiv.org/abs/2307.07306) | C3是基于ChatGPT的零-shot Text-to-SQL方法，通过三个关键组件提供系统性的处理方法，在Spider Challenge上取得了82.3%的执行准确率，成为最先进的方法。 |
| [^18] | [One-Shot Action Recognition via Multi-Scale Spatial-Temporal Skeleton Matching.](http://arxiv.org/abs/2307.07286) | 通过多尺度时空骨架匹配，本研究提出了一种新颖的一次性动作识别技术，能够处理骨架动作识别中的空间结构和时间顺序，实现了最优特征匹配。 |
| [^19] | [AudioInceptionNeXt: TCL AI LAB Submission to EPIC-SOUND Audio-Based-Interaction-Recognition Challenge 2023.](http://arxiv.org/abs/2307.07265) | AudioInceptionNeXt是一个基于单个流的CNN架构，通过使用时间-频率log-mel-spectrogram的音频样本，结合并行的多尺度深度可分离卷积核来更有效地学习时间和频率信息，实现了在2023年EPIC-SOUND音频交互识别挑战赛上55.43%的准确率。 |
| [^20] | [A Dynamic Points Removal Benchmark in Point Cloud Maps.](http://arxiv.org/abs/2307.07260) | 本论文提出了一个易于扩展的统一评估框架，用于评估地图中动态点去除技术，重构了最先进的方法并引入了新的度量指标来分析方法的局限性，可以帮助研究人员深入了解这些方法背后的原因。该基准使用多种传感器类型的数据集，并提供公开获取的代码和数据集。 |
| [^21] | [Dialogue Agents 101: A Beginner's Guide to Critical Ingredients for Designing Effective Conversational Systems.](http://arxiv.org/abs/2307.07255) | 本文提供了一个对话代理设计的相关要素的综合概述，包括对话代理的主要特征、支持任务、数据集和评估方法。研究表明，构建单独的模型来处理不同的对话任务是昂贵且冗余的。 |
| [^22] | [Mitigating Adversarial Vulnerability through Causal Parameter Estimation by Adversarial Double Machine Learning.](http://arxiv.org/abs/2307.07250) | 通过敌对双机器学习方法，可以量化和缓解深度神经网络在面对敌对输入时的脆弱性。 |
| [^23] | [Rigorous Runtime Analysis of Diversity Optimization with GSEMO on OneMinMax.](http://arxiv.org/abs/2307.07248) | 本文进行了对OneMinMax问题上使用GSEMO算法进行多样性优化的严格运行时分析，证明了算法能在期望时间$O(n^2)$内找到具有最佳多样性的种群。 |
| [^24] | [Multiplicative update rules for accelerating deep learning training and increasing robustness.](http://arxiv.org/abs/2307.07189) | 本文提出了一种优化框架，通过使用乘法更新规则，加速深度学习训练并提高模型的鲁棒性。 |
| [^25] | [TriFormer: A Multi-modal Transformer Framework For Mild Cognitive Impairment Conversion Prediction.](http://arxiv.org/abs/2307.07177) | TriFormer是一种基于Transformer的多模态框架，用于准确预测轻度认知损害转化为稳定MCI或进展MCI的情况。该框架包括图像Transformer、临床Transformer和模态融合Transformer，通过整合多模态数据来提高预测性能，并在实验中优于先前的单模态和多模态方法。 |
| [^26] | [Safe DreamerV3: Safe Reinforcement Learning with World Models.](http://arxiv.org/abs/2307.07176) | Safe DreamerV3是一种通过集成基于拉格朗日和计划的方法到世界模型中的新算法，实现了在低维度和仅采用视觉的任务中几乎零成本的安全强化学习。 |
| [^27] | [Vulnerability-Aware Instance Reweighting For Adversarial Training.](http://arxiv.org/abs/2307.07167) | 该论文提出了一种新的实例级别重新加权方案，通过考虑每个自然示例的易受攻击性和对抗攻击导致的信息损失，来改进对抗训练算法的性能。 |
| [^28] | [Federated Learning-Empowered AI-Generated Content in Wireless Networks.](http://arxiv.org/abs/2307.07146) | 本论文研究了在无线网络中使用联邦学习来增强人工智能生成的内容，以提供多样化、个性化和高质量的内容。 |
| [^29] | [Multi-Dimensional Ability Diagnosis for Machine Learning Algorithms.](http://arxiv.org/abs/2307.07134) | 本文提出了一个任务无关的评估框架Camilla，通过定义多维度的诊断度量Ability来协同测量每个机器学习算法的多面体强度，解决了机器学习算法在实际性能和标准化评估中存在的差距问题。 |
| [^30] | [DataAssist: A Machine Learning Approach to Data Cleaning and Preparation.](http://arxiv.org/abs/2307.07119) | DataAssist是一种机器学习方法，用于提高数据集质量和节省数据清洗和准备时间。 |
| [^31] | [Espaloma-0.3.0: Machine-learned molecular mechanics force field for the simulation of protein-ligand systems and beyond.](http://arxiv.org/abs/2307.07085) | Espaloma-0.3.0是一个用于蛋白质-配体系统模拟的机器学习分子力学力场，通过能量和力的拟合纳入量子化学数据进行训练，具有灵活性和可扩展性。 |
| [^32] | [Safe Reinforcement Learning as Wasserstein Variational Inference: Formal Methods for Interpretability.](http://arxiv.org/abs/2307.07084) | 本研究提出了一种新的自适应Wasserstein变分优化（AWaVO）方法，利用形式方法解决了顺序决策中的解释和透明性问题，并提供了奖励设计和策略收敛的概率解释。 |
| [^33] | [Vertex-based Networks to Accelerate Path Planning Algorithms.](http://arxiv.org/abs/2307.07059) | 本文提出了一种基于顶点的网络加速路径规划算法，通过专注最优路径上的关键顶点，提供更高效的路径规划。实验结果表明，在随机生成的地图上，相比基准模型，我们的解决方案实现了超过400%的速度增益。 |
| [^34] | [A metric learning approach for endoscopic kidney stone identification.](http://arxiv.org/abs/2307.07046) | 本文提出了一种用于内窥镜肾结石识别的度量学习方法，该方法能够处理样本稀缺类别，并且在推广到新样本以及添加新类别到数据库时能有更好的应对能力 |
| [^35] | [Leveraging Factored Action Spaces for Off-Policy Evaluation.](http://arxiv.org/abs/2307.07014) | 本文研究了如何利用分解的动作空间来减轻涉及大型组合动作空间问题的非策略评估（OPE）的高偏差和高方差问题。通过提出一种基于分解动作空间的新型“分解”重要性抽样（IS）估计器系列，我们证明了分解IS估计器具有比非分解版本更小的方差，同时具有零偏差的性质，并通过模拟实验证实了该理论结果。 |
| [^36] | [Classical Out-of-Distribution Detection Methods Benchmark in Text Classification Tasks.](http://arxiv.org/abs/2307.07002) | 本文评估了八种易于集成到现有NLP系统中且不需要额外带外数据或模型修改的带外分布检测方法，并提供了一个完全可复现实验结果的研究环境。分析表明现有的NLP任务中带外分布检测方法对于捕捉所有由不同类型分布转换特征的样本尚不够敏感，这需要未来的工作来开发更有效的方法。 |
| [^37] | [IR Design for Application-Specific Natural Language: A Case Study on Traffic Data.](http://arxiv.org/abs/2307.06983) | 该论文提出了一种面向特定应用自然语言的IR设计，可将交通数据统一处理成图形数据格式，大大提高了数据处理性能。 |
| [^38] | [Short Boolean Formulas as Explanations in Practice.](http://arxiv.org/abs/2307.06971) | 本论文研究了基于一元关系的数据模型的短布尔公式解释的可行性，提出了对期望错误的定量界限，并展示了在三个具体数据集上的实际应用。通过限制公式长度，可以获得避免过拟合且准确且易于理解的解释。 |
| [^39] | [Machine Learning-Assisted Pattern Recognition Algorithms for Estimating Ultimate Tensile Strength in Fused Deposition Modeled Polylactic Acid Specimens.](http://arxiv.org/abs/2307.06970) | 本研究使用机器学习算法估计了采用FDM工艺制造的PLA试样的极限抗拉强度（UTS），结果表明KNN算法优于其他算法，在区分不同UTS类别方面表现出更好的效果。 |
| [^40] | [Is Task-Agnostic Explainable AI a Myth?.](http://arxiv.org/abs/2307.06963) | 我们提出了一个框架来统一当代可解释人工智能的挑战，指出虽然XAI方法为模型提供了有用的输出，但研究人员和决策者应注意它们的限制，需要在该领域有一个概念突破以解决XAI方法和应用任务之间的兼容性挑战。 |
| [^41] | [Copy Is All You Need.](http://arxiv.org/abs/2307.06962) | 本文将文本生成定义为从现有文本集合中逐步复制文本片段，并通过复制和粘贴操作来实现生成，相比传统的顺序选择单词生成的模型，在自动和人工评估中取得了更好的生成质量，并且推理效率与基于标记的自回归模型相当。 |
| [^42] | [ACTI at EVALITA 2023: Overview of the Conspiracy Theory Identification Task.](http://arxiv.org/abs/2307.06954) | ACTI在EVALITA 2023中的阴谋论辨识任务共有15支团队参与，通过使用大型语言模型判断阴谋内容和分类，得出了关于利用这些模型抵制在在线平台传播错误信息的结论。 |
| [^43] | [AI For Global Climate Cooperation 2023 Competition Proceedings.](http://arxiv.org/abs/2307.06951) | 国际社会必须合作应对气候变化，通过结合人工智能和气候经济模拟，设计促进和激励合作的国际框架，解决协议遵守、政策目标实现和持续承诺等挑战。 |
| [^44] | [Pathway toward prior knowledge-integrated machine learning in engineering.](http://arxiv.org/abs/2307.06950) | 本研究提出了一种整合先验知识的机器学习方法，对工程领域中的信息不确定性进行了检查，并探索了以三层知识整合的机器学习范式进行知识分解。这种方法平衡了整体论和还原论观点。 |
| [^45] | [Uncovering Unique Concept Vectors through Latent Space Decomposition.](http://arxiv.org/abs/2307.06913) | 通过潜在空间分解和无监督聚类，我们提出了一种自动揭示深度学习模型学习到的概念向量的方法，这些概念向量与模型预测相关且具有语义的独特概念，并且在实验中表明这些概念对人类来说易于理解和与任务相关。 |
| [^46] | [Hybrid Control Policy for Artificial Pancreas via Ensemble Deep Reinforcement Learning.](http://arxiv.org/abs/2307.06501) | 本研究提出了一种名为HyCPAP的混合控制策略，通过结合模型预测控制和集成深度强化学习，并充分利用它们各自的优势，以解决人工胰腺的复杂生理过程、延迟胰岛素反应和不准确血糖测量等挑战。 |
| [^47] | [Bag of Views: An Appearance-based Approach to Next-Best-View Planning for 3D Reconstruction.](http://arxiv.org/abs/2307.05832) | 这篇论文提出了一种基于外观的方法，通过视图袋（Bag-of-Views）模型来对捕获的视图进行离线数据集细化和在线下一个最佳视图（NBV）规划应用分配效用，以实现3D重建的任务。同时，还开发了视图规划工具箱（VPT）。 |
| [^48] | [Unleashing Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration.](http://arxiv.org/abs/2307.05300) | 本论文提出了单人表现提示（SPP）的概念，通过与多个角色进行多轮自我协作，将单个语言模型转化为认知协同者，从而增强其在复杂任务中的问题解决能力和整体性能。 |
| [^49] | [Intrinsically motivated graph exploration using network theories of human curiosity.](http://arxiv.org/abs/2307.04962) | 在这项工作中，我们通过应用人类好奇心的两个理论，发展了一种内在驱动的图探索方法。我们利用图神经网络的强化学习将拓扑特征作为奖励，从而实现了对图结构数据的探索。在多类合成生成图上进行的实验证明，我们的方法不仅可以推广到更大的环境，还可以进行更长的探索步行。同时，我们的方法比传统的贪婪评估方法更高效。 |
| [^50] | [On Formal Feature Attribution and Its Approximation.](http://arxiv.org/abs/2307.03380) | 这篇论文研究了解释性人工智能（XAI）中的形式特征归因方法及其近似方法。现有的特征选择和归因方法存在一些问题，而形式化的XAI方法虽然是一个有希望的解决方案，但仍存在一些限制。 |
| [^51] | [Few-Shot Continual Learning via Flat-to-Wide Approaches.](http://arxiv.org/abs/2306.14369) | 本文提出了一种少样本持续学习方法，名为FLat-tO-WidE AppRoach (FLOWER)，通过寻找扁平化宽化极小值的过程来解决灾难性遗忘问题，利用球体生成器概念进行数据增强方法来克服数据稀缺性问题。在小型基础任务中，FLOWER表现出显著改进的性能。 |
| [^52] | [A HRNet-based Rehabilitation Monitoring System.](http://arxiv.org/abs/2306.10756) | 该论文介绍了一种基于HRNet的康复监测系统，旨在通过智能手机进行康复训练的管理。患者可以通过系统进行应用程序来进行训练，而治疗师可以通过服务器端进行进度的监测。 |
| [^53] | [Dink-Net: Neural Clustering on Large Graphs.](http://arxiv.org/abs/2305.18405) | Dink-Net是一个可扩展的大规模图形神经聚类方法，该方法利用了膨胀和收缩的思想来处理百万节点的大图，并在各种基准数据集上优于现有的最先进方法。 |
| [^54] | [Attention Schema in Neural Agents.](http://arxiv.org/abs/2305.17375) | 本文研究了神经智能中的注意力模式，并提出了注意力模式理论（AST）。作者发现将AS实现为一种循环内部控制的智能体效果最佳，这一理论为应用与改进神经智能提供了新思路。 |
| [^55] | [I Spy a Metaphor: Large Language Models and Diffusion Models Co-Create Visual Metaphors.](http://arxiv.org/abs/2305.14724) | 本论文提出一个新的任务——从语言隐喻生成视觉隐喻，并且基于大语言模型和扩散模型之间的协作，成功地实现了共创出具有视觉冲击力和语义含义的隐喻。 |
| [^56] | [ARBEx: Attentive Feature Extraction with Reliability Balancing for Robust Facial Expression Learning.](http://arxiv.org/abs/2305.01486) | 本论文提出了一个名为ARBEx的框架，它采用了可靠性平衡方法来应对面部表情学习任务中的数据偏差和不确定性。该框架还引入了可学习的锚点和多头自注意机制，并在多个公共数据集上取得了有效性验证。 |
| [^57] | [Deep Explainable Relational Reinforcement Learning: A Neuro-Symbolic Approach.](http://arxiv.org/abs/2304.08349) | 本论文提出了一种深度可解释关系强化学习框架，通过将神经和符号世界相结合，利用神经符号化的方法提取出可解释的策略，解决了深度强化学习中不可解释性和处理环境结构变化的困难。 |
| [^58] | [DiffTAD: Temporal Action Detection with Proposal Denoising Diffusion.](http://arxiv.org/abs/2303.14863) | DiffTAD是一种新的时间动作检测方法，使用Proposal Denoising Diffusion的生成建模视角，并通过正向/噪声过程和反向/去噪过程实现准确的动作提议。 |
| [^59] | [Breaking Common Sense: WHOOPS! A Vision-and-Language Benchmark of Synthetic and Compositional Images.](http://arxiv.org/abs/2303.07274) | WHOOPS!是一个新的视觉常识数据集和基准测试，包括了图像字幕、跨模态匹配和视觉问答等若干个任务，引入了解释生成任务，挑战了AI模型识别和解释不合常规的图像的能力。 |
| [^60] | [Open-Vocabulary Affordance Detection in 3D Point Clouds.](http://arxiv.org/abs/2303.02401) | 本文提出了一种在3D点云中进行无限数量支撑检测的开放词汇支撑检测方法，通过同时学习支撑文本和点特征来利用支撑之间的语义关系，实现了零-shot检测，能够在没有注释示例的情况下检测以前未见到的支撑。实验结果表明，OpenAD在各种设置上表现出优异性能。 |
| [^61] | [DoCoFL: Downlink Compression for Cross-Device Federated Learning.](http://arxiv.org/abs/2302.00543) | 本研究提出了DoCoFL，一种用于跨设备联合学习的下行压缩框架，能够在降低双向带宽的同时保持竞争力的准确性。 |
| [^62] | [Vision Transformer Based Model for Describing a Set of Images as a Story.](http://arxiv.org/abs/2210.02762) | 本研究提出了一种基于视觉Transformer的模型，用于将一组图像描述为一个故事。该模型通过ViT提取输入图像的特征，并使用双向LSTM捕捉图像补丁的过去和未来上下文信息。通过注意力机制加权计算得到最终的故事描述向量。 |
| [^63] | [Privacy-preserving machine learning with tensor networks.](http://arxiv.org/abs/2202.12319) | 本文展示了张量网络架构在保护隐私的机器学习中具有潜在优势，并提出了确保鲁棒性的明确条件。 |
| [^64] | [Unpacking the Black Box: Regulating Algorithmic Decisions.](http://arxiv.org/abs/2110.03443) | 本文研究如何在代理使用复杂的“黑盒”预测函数进行决策的情况下，对算法决策进行最优调控。研究发现，限制代理使用透明度足够高的预测函数是低效的，而针对激励偏差源头的目标化工具可以提供次优解决方案，从而改善福利。 |

# 详细

[^1]: 深度强化学习用于动态车辆调度问题的基于事件的方法

    Deep reinforcement learning for the dynamic vehicle dispatching problem: An event-based approach. (arXiv:2307.07508v1 [cs.AI])

    [http://arxiv.org/abs/2307.07508](http://arxiv.org/abs/2307.07508)

    本文介绍了将动态车辆调度问题建模为半马尔可夫决策过程的基于事件的方法，并通过实际场景的数值实验验证了该方法的有效性。

    

    动态车辆调度问题涉及决定将哪些车辆分配给随机产生的时间和空间请求。该问题出现在各个领域，如将卡车分配给要运输的货物、应急系统和顺风车服务中。本文将该问题建模为半马尔可夫决策过程，这使我们能够将时间视为连续变量。在此设置中，决策时刻与事件一致，其时间间隔是随机的。我们认为基于事件的方法大大降低了决策空间的组合复杂性，并克服了文献中常提出的离散时间模型的其他局限性。为了测试我们的方法，我们开发了一个新的离散事件模拟器，并使用双深度Q学习训练我们的决策代理。在使用纽约市的数据进行实际场景的数值实验中，我们将通过我们的方法获得的策略与启发式方法进行了比较。

    The dynamic vehicle dispatching problem corresponds to deciding which vehicles to assign to requests that arise stochastically over time and space. It emerges in diverse areas, such as in the assignment of trucks to loads to be transported; in emergency systems; and in ride-hailing services. In this paper, we model the problem as a semi-Markov decision process, which allows us to treat time as continuous. In this setting, decision epochs coincide with discrete events whose time intervals are random. We argue that an event-based approach substantially reduces the combinatorial complexity of the decision space and overcomes other limitations of discrete-time models often proposed in the literature. In order to test our approach, we develop a new discrete-event simulator and use double deep q-learning to train our decision agents. Numerical experiments are carried out in realistic scenarios using data from New York City. We compare the policies obtained through our approach with heuristic
    
[^2]: 基于骨骼的交互动作识别的交互式时空注意力网络

    Interactive Spatiotemporal Token Attention Network for Skeleton-based General Interactive Action Recognition. (arXiv:2307.07469v1 [cs.CV])

    [http://arxiv.org/abs/2307.07469](http://arxiv.org/abs/2307.07469)

    本研究提出了一个交互式时空注意力网络(ISTA-Net)，通过同时建模空间、时间和交互关系，解决了以往方法在交互动作识别中的限制和不足。我们的网络利用分段器将多个不同实体的动作划分成交互式时空令牌(ISTs)，并通过多头自注意力块和3D卷积实现了在ISTs的三个维度上的联合学习。

    

    在人机交互和协作中，识别交互动作起着重要作用。先前的方法使用后期融合和共同关注机制来捕捉交互关系，但学习能力有限，或者适应更多的交互实体效率低。基于每个实体的先验已知的假设，它们也缺乏对更一般设置的评估，以应对主体的多样性。为了解决这些问题，我们提出了一个交互式时空注意力网络(ISTA-Net)，同时建模空间、时间和交互关系。具体来说，我们的网络包含一个分段器，用于分割交互式时空令牌(ISTs)，这是一种统一的表示多个不同实体动作的方式。通过扩展实体维度，ISTs提供了更好的交互表示。为了在ISTs中的三个维度上联合学习，我们使用了与3D卷积集成的多头自注意力块。

    Recognizing interactive action plays an important role in human-robot interaction and collaboration. Previous methods use late fusion and co-attention mechanism to capture interactive relations, which have limited learning capability or inefficiency to adapt to more interacting entities. With assumption that priors of each entity are already known, they also lack evaluations on a more general setting addressing the diversity of subjects. To address these problems, we propose an Interactive Spatiotemporal Token Attention Network (ISTA-Net), which simultaneously model spatial, temporal, and interactive relations. Specifically, our network contains a tokenizer to partition Interactive Spatiotemporal Tokens (ISTs), which is a unified way to represent motions of multiple diverse entities. By extending the entity dimension, ISTs provide better interactive representations. To jointly learn along three dimensions in ISTs, multi-head self-attention blocks integrated with 3D convolutions are des
    
[^3]: 神经网络的结构化裁剪用于约束学习

    Structured Pruning of Neural Networks for Constraints Learning. (arXiv:2307.07457v1 [cs.LG])

    [http://arxiv.org/abs/2307.07457](http://arxiv.org/abs/2307.07457)

    本文将神经网络结构化裁剪应用于约束学习，解决了人工神经网络参数过多导致可扩展性问题的挑战。

    

    近年来，在机器学习（ML）模型与运筹学（OR）工具的整合方面在各种应用中都受到了广泛的关注，包括癌症治疗、算法配置和化学过程优化。在这个领域中，ML和OR的组合通常依赖于使用混合整数规划（MIP）形式表示ML模型输出。文献中的许多研究已经开发了这样的形式化方法来处理许多ML预测器，特别是人工神经网络（ANNs），因为它们在许多应用中具有重要的兴趣。然而，由于人工神经网络经常包含大量参数，导致 MIP 形式化方法难以解决，从而限制了可扩展性。事实上，机器学习界已经引入了几种技术来减少人工神经网络的参数数量，而不影响性能，因为现代人工神经网络的庞大规模对机器学习应用提出了挑战，它明显降低了系统的可扩展性。

    In recent years, the integration of Machine Learning (ML) models with Operation Research (OR) tools has gained popularity across diverse applications, including cancer treatment, algorithmic configuration, and chemical process optimization. In this domain, the combination of ML and OR often relies on representing the ML model output using Mixed Integer Programming (MIP) formulations. Numerous studies in the literature have developed such formulations for many ML predictors, with a particular emphasis on Artificial Neural Networks (ANNs) due to their significant interest in many applications. However, ANNs frequently contain a large number of parameters, resulting in MIP formulations that are impractical to solve, thereby impeding scalability. In fact, the ML community has already introduced several techniques to reduce the parameter count of ANNs without compromising their performance, since the substantial size of modern ANNs presents challenges for ML applications as it significantly
    
[^4]: 有深度限制的认知逻辑

    Depth-bounded Epistemic Logic. (arXiv:2307.07448v1 [cs.AI])

    [http://arxiv.org/abs/2307.07448](http://arxiv.org/abs/2307.07448)

    这篇论文介绍了一种针对有深度限制的智能体的认知逻辑扩展DBEL，通过引入深度原子来实现对智能体深度的明确推理，并提供了DBEL的公理化和扩展。同时，作者还提出了DPAL逻辑以及其它两种扩展，并指出了这些扩展的不可取的特性。

    

    认知逻辑模型描述了智能体如何推理他们的信念以及其他智能体的信念。现有的逻辑通常假设智能体能够完美地推理无界模态深度的命题。我们提出了DBEL，它是S5的扩展，可以模拟只能推理到特定模态深度的智能体。为了支持对智能体深度的明确推理，DBEL包括深度原子Ead（代理人a的深度恰好为d）和Pad（代理人a的深度至少为d）。我们提供了DBEL的完备的公理化。我们扩展了DBEL以支持有深度限制的公开公告，展示了结果DPAL逻辑如何推广公开公告逻辑的标准公理。我们提出了两种替代扩展，并确定了这些扩展有但DPAL没有的两个不可取的特性——遗忘和知识泄漏。我们提供了这些逻辑的公理化以及可满足性和模型检验的复杂性结果。

    Epistemic logics model how agents reason about their beliefs and the beliefs of other agents. Existing logics typically assume the ability of agents to reason perfectly about propositions of unbounded modal depth. We present DBEL, an extension of S5 that models agents that can reason about epistemic formulas only up to a specific modal depth. To support explicit reasoning about agent depths, DBEL includes depth atoms Ead (agent a has depth exactly d) and Pad (agent a has depth at least d). We provide a sound and complete axiomatization of DBEL.  We extend DBEL to support public announcements for bounded depth agents and show how the resulting DPAL logic generalizes standard axioms from public announcement logic. We present two alternate extensions and identify two undesirable properties, amnesia and knowledge leakage, that these extensions have but DPAL does not. We provide axiomatizations of these logics as well as complexity results for satisfiability and model checking.  Finally, we
    
[^5]: TSNet-SAC: 利用Transformer进行高效任务调度

    TSNet-SAC: Leveraging Transformers for Efficient Task Scheduling. (arXiv:2307.07445v1 [cs.NI])

    [http://arxiv.org/abs/2307.07445](http://arxiv.org/abs/2307.07445)

    TSNet-SAC是一种基于Transformer的创新网络，利用启发式算法指导训练，通过引入滑动增强组件和扩展组件来提高鲁棒性和解决算法缺陷，适应不同的接入场景。模拟实验表明，TSNet-SAC在准确性和鲁棒性方面优于现有网络，并具有更优的调度决策延迟。

    

    在未来的6G移动边缘计算（MEC）中，自动驾驶系统需要具备处理多模态数据和强相互依赖性的能力。然而，传统启发式算法由于需要多次迭代来得到最优方案，在实时调度方面表现不佳。我们提出了一种基于Transformer的创新网络TSNet-SAC，仅利用启发式算法指导TSNet的训练。此外，我们引入了滑动增强组件（SAC）来增强鲁棒性和解决算法缺陷。此外，我们设计了扩展组件来处理多尺度训练数据并提供网络可扩展性，使得TSNet能够适应不同的接入场景。模拟实验表明，TSNet-SAC在准确性和鲁棒性方面优于现有网络，与启发式算法相比具有更优的调度决策延迟。

    In future 6G Mobile Edge Computing (MEC), autopilot systems require the capability of processing multimodal data with strong interdependencies. However, traditional heuristic algorithms are inadequate for real-time scheduling due to their requirement for multiple iterations to derive the optimal scheme. We propose a novel TSNet-SAC based on Transformer, that utilizes heuristic algorithms solely to guide the training of TSNet. Additionally, a Sliding Augment Component (SAC) is introduced to enhance the robustness and resolve algorithm defects. Furthermore, the Extender component is designed to handle multi-scale training data and provide network scalability, enabling TSNet to adapt to different access scenarios. Simulation demonstrates that TSNet-SAC outperforms existing networks in accuracy and robustness, achieving superior scheduling-making latency compared to heuristic algorithms.
    
[^6]: 大型语言模型能增强分子属性预测吗？

    Can Large Language Models Empower Molecular Property Prediction?. (arXiv:2307.07443v1 [cs.LG])

    [http://arxiv.org/abs/2307.07443](http://arxiv.org/abs/2307.07443)

    本研究提出了利用大型语言模型（LLMs）对分子属性预测进行增强的方法，通过零/少样本分子分类和生成新的解释来推进这一目标。

    

    分子属性预测因其在多个科学领域中的改变潜力而受到重视。传统上，分子图可以表示为图结构化数据或SMILES文本。最近，大型语言模型（LLMs）的快速发展彻底改变了自然语言处理领域。尽管利用LLMs来理解用SMILES表示的分子是自然的，但LLMs如何影响分子属性预测的探索仍处于早期阶段。在这项工作中，我们从零/少样本分子分类和使用LLMs生成的新解释作为分子表示两个角度推进了这一目标。具体而言，我们首先提示LLMs进行上下文分子分类并评估其性能。然后，我们利用LLMs为原始SMILES生成语义丰富的解释，并利用此来微调小规模的LM模型。

    Molecular property prediction has gained significant attention due to its transformative potential in multiple scientific disciplines. Conventionally, a molecule graph can be represented either as a graph-structured data or a SMILES text. Recently, the rapid development of Large Language Models (LLMs) has revolutionized the field of NLP. Although it is natural to utilize LLMs to assist in understanding molecules represented by SMILES, the exploration of how LLMs will impact molecular property prediction is still in its early stage. In this work, we advance towards this objective through two perspectives: zero/few-shot molecular classification, and using the new explanations generated by LLMs as representations of molecules. To be specific, we first prompt LLMs to do in-context molecular classification and evaluate their performance. After that, we employ LLMs to generate semantically enriched explanations for the original SMILES and then leverage that to fine-tune a small-scale LM mode
    
[^7]: 声学吉他的实时敲击技术识别和嵌入学习

    Real-time Percussive Technique Recognition and Embedding Learning for the Acoustic Guitar. (arXiv:2307.07426v1 [cs.SD])

    [http://arxiv.org/abs/2307.07426](http://arxiv.org/abs/2307.07426)

    本研究开发了针对增强击弦指弹的实时音乐信息检索技术，通过卷积神经网络和变分自动编码器，实现了吉他体击打的识别和嵌入学习。

    

    实时音乐信息检索（RT-MIR）在增强传统声学乐器的能力方面具有巨大潜力。我们开发了针对增强击弦指弹的实时音乐信息检索技术，将声学吉他演奏与吉他体击打相结合。我们为增强乐器表演的实时音乐信息检索系统制定了几个设计目标：（i）因果约束，（ii）感知上可忽略的音动延迟，（iii）控制亲密性支持，（iv）合成控制支持。我们基于卷积神经网络（CNNs）和与变分自动编码器（VAEs）共同训练的CNNs，提出并评估了实时吉他体击打识别和嵌入学习技术。我们基于手部部位和位置，引入了吉他体击打的分类系统。通过收集并根据分类系统标记的三个数据集，采用跨数据集评估方法评估了模型的嵌入质量。

    Real-time music information retrieval (RT-MIR) has much potential to augment the capabilities of traditional acoustic instruments. We develop RT-MIR techniques aimed at augmenting percussive fingerstyle, which blends acoustic guitar playing with guitar body percussion. We formulate several design objectives for RT-MIR systems for augmented instrument performance: (i) causal constraint, (ii) perceptually negligible action-to-sound latency, (iii) control intimacy support, (iv) synthesis control support. We present and evaluate real-time guitar body percussion recognition and embedding learning techniques based on convolutional neural networks (CNNs) and CNNs jointly trained with variational autoencoders (VAEs). We introduce a taxonomy of guitar body percussion based on hand part and location. We follow a cross-dataset evaluation approach by collecting three datasets labelled according to the taxonomy. The embedding quality of the models is assessed using KL-Divergence across distribution
    
[^8]: 使用GPT进行命名实体识别以识别可比公司

    Named entity recognition using GPT for identifying comparable companies. (arXiv:2307.07420v1 [cs.CL])

    [http://arxiv.org/abs/2307.07420](http://arxiv.org/abs/2307.07420)

    本文使用GPT以识别可比公司。传统的可比公司方法通常使用定性方法来识别相似的同行公司，而我们使用大型语言模型通过提取公司描述/摘要从而进行相似性分析，实现更量化的方法。

    

    对于公共和私人公司，可比公司分析被广泛用作公司估值的方法。特别是对于私募股权公司的估值，该方法非常有价值。可比公司方法的几种方法通常依赖于定性方法来识别相似的同行公司，这往往使用已建立的行业分类方案和/或分析师的直觉和知识。然而，文献和私募股权行业开始使用更多的量化方法，特别是机器学习聚类和自然语言处理（NLP）。对于NLP方法，该过程包括从公司的网站或来自某些金融数据库系统的公司描述中提取产品实体，然后进行相似性分析。在这里，我们使用公开可用的公司维基百科网站的公司描述/摘要，展示了使用大型语言模型（LLM），例如GPT

    For both public and private firms, comparable companies analysis is widely used as a method for company valuation. In particular, the method is of great value for valuation of private equity companies. The several approaches to the comparable companies method usually rely on a qualitative approach to identifying similar peer companies, which tends to use established industry classification schemes and/or analyst intuition and knowledge. However, more quantitative methods have started being used in the literature and in the private equity industry, in particular, machine learning clustering, and natural language processing (NLP). For NLP methods, the process consists of extracting product entities from e.g., the company's website or company descriptions from some financial database system and then to perform similarity analysis. Here, using companies descriptions/summaries from publicly available companies' Wikipedia websites, we show that using large language models (LLMs), such as GPT
    
[^9]: RoPDA：用于低资源命名实体识别的鲁棒基于提示的数据增强

    RoPDA: Robust Prompt-based Data Augmentation for Low-Resource Named Entity Recognition. (arXiv:2307.07417v1 [cs.CL])

    [http://arxiv.org/abs/2307.07417](http://arxiv.org/abs/2307.07417)

    RoPDA是一种用于低资源NER的数据增强方法，通过基于预训练语言模型和连续提示进行实体和上下文增强，并提出了自一致性过滤和混合技术以优化增强样本的利用。

    

    数据增强在低资源NER任务中被广泛使用以解决数据稀缺的问题。然而，先前的数据增强方法存在破坏句法结构、标记-标签不匹配和对外部知识或手动工作的需求的缺点。为了解决这些问题，我们提出了RoPDA: 一种用于低资源NER的鲁棒基于提示的数据增强方法。基于预训练语言模型（PLMs）和连续提示，RoPDA通过五个基本的增强操作进行实体增强和上下文增强，生成标签翻转和保留标签的样本。为了优化增强样本的利用，我们提出了两种技术：自一致性过滤和混合。前者有效地消除低质量样本，后者防止直接利用标签翻转样本导致性能下降。在三个基准测试中进行了大量实验...

    Data augmentation has been widely used in low-resource NER tasks to tackle the problem of data sparsity. However, previous data augmentation methods have the disadvantages of disrupted syntactic structures, token-label mismatch, and requirement for external knowledge or manual effort. To address these issues, we propose \textbf{Ro}bust \textbf{P}rompt-based \textbf{D}ata \textbf{A}ugmentation (RoPDA) for low-resource NER. Based on pre-trained language models (PLMs) with continuous prompt, RoPDA performs entity augmentation and context augmentation through five fundamental augmentation operations to generate label-flipping and label-preserving examples. To optimize the utilization of the augmented samples, we present two techniques: Self-Consistency Filtering and mixup. The former effectively eliminates low-quality samples, while the latter prevents performance degradation arising from the direct utilization of label-flipping samples. Extensive experiments on three benchmarks from diffe
    
[^10]: AutoHint: 自动提示生成与优化的新框架

    AutoHint: Automatic Prompt Optimization with Hint Generation. (arXiv:2307.07415v1 [cs.CL])

    [http://arxiv.org/abs/2307.07415](http://arxiv.org/abs/2307.07415)

    本文介绍了AutoHint，一种用于大型语言模型的自动提示生成和优化的新框架。该方法通过从输入-输出演示中生成提示，并利用上下文学习和零样本学习的优点，优化原始提示，从而提高了大型语言模型在特定任务上的表现。

    

    本文提出了AutoHint，一种用于大型语言模型（LLM）的自动提示工程和优化的新框架。虽然LLM在各种任务中展示了出色的注释能力，但将此能力应用于特定任务的关键在于开发高质量的提示。因此，我们提出了一种框架，通过将从输入-输出演示中派生的丰富指导纳入原始提示，以继承上下文学习和零样本学习的优点。我们将这种丰富称为“提示”，并提出了一种从标记数据中自动生成提示的框架。具体而言，从一个初始提示开始，我们的方法首先指导LLM从错误预测中推断出选定样本的新提示，然后从每个样本的提示中进行总结，并将结果添加回初始提示，形成一个新的丰富指导。该方法在BIG-Bench指令推导任务上进行了评估。

    This paper presents AutoHint, a novel framework for automatic prompt engineering and optimization for Large Language Models (LLM). While LLMs have demonstrated remarkable ability in achieving high-quality annotation in various tasks, the key to applying this ability to specific tasks lies in developing high-quality prompts. Thus we propose a framework to inherit the merits of both in-context learning and zero-shot learning by incorporating enriched instructions derived from input-output demonstrations to optimize original prompt. We refer to the enrichment as the hint and propose a framework to automatically generate the hint from labeled data. More concretely, starting from an initial prompt, our method first instructs a LLM to deduce new hints for selected samples from incorrect predictions, and then summarizes from per-sample hints and adds the results back to the initial prompt to form a new, enriched instruction. The proposed method is evaluated on the BIG-Bench Instruction Induct
    
[^11]: 利用反例对带有部分标签的主动学习进行探索

    Exploiting Counter-Examples for Active Learning with Partial labels. (arXiv:2307.07413v1 [cs.LG])

    [http://arxiv.org/abs/2307.07413](http://arxiv.org/abs/2307.07413)

    本论文研究了一个新的问题，即带有部分标签的主动学习（ALPL）。为了解决过度拟合问题和增强选择代表性样本的过程，我们利用反例构造了一种简单有效的 WorseNet 来进行学习。

    

    本论文研究了一个新的问题，即带有部分标签的主动学习（ALPL）。在这种设置中，一个 oracle 用部分标签对查询样本进行注释，放宽了对准确标注过程的要求。为了解决 ALPL，我们首先建立了一个直观的基线，可以无缝地融入到现有的 AL 框架中。虽然有效，但这个基线仍然容易过度拟合，并且在查询过程中缺乏代表性的基于部分标签的样本。受认知科学中人类推理的启发，我们的目标是利用这种类似人类的学习模式来解决过度拟合问题，同时增强 ALPL 中选择代表性样本的过程。具体而言，我们通过反转每个实例的部分标签构造反例，然后提出了一个简单但有效的 WorseNet 来直接从这些反例中学习。

    This paper studies a new problem, \emph{active learning with partial labels} (ALPL). In this setting, an oracle annotates the query samples with partial labels, relaxing the oracle from the demanding accurate labeling process. To address ALPL, we first build an intuitive baseline that can be seamlessly incorporated into existing AL frameworks. Though effective, this baseline is still susceptible to the \emph{overfitting}, and falls short of the representative partial-label-based samples during the query process. Drawing inspiration from human inference in cognitive science, where accurate inferences can be explicitly derived from \emph{counter-examples} (CEs), our objective is to leverage this human-like learning pattern to tackle the \emph{overfitting} while enhancing the process of selecting representative samples in ALPL. Specifically, we construct CEs by reversing the partial labels for each instance, and then we propose a simple but effective WorseNet to directly learn from this c
    
[^12]: KU-DMIS-MSRA在RadSum23中的预训练视觉语言模型用于放射学报告摘要

    KU-DMIS-MSRA at RadSum23: Pre-trained Vision-Language Model for Radiology Report Summarization. (arXiv:2307.07409v1 [cs.CL])

    [http://arxiv.org/abs/2307.07409](http://arxiv.org/abs/2307.07409)

    本文介绍了一种新型的预训练视觉语言模型CheXOFA，通过在一般领域的训练数据上进行预训练，然后转移到胸部X射线领域，该模型能够有效地学习所需的知识和技能，并在放射学报告摘要任务上取得了卓越的性能，获得了RadSum23测试集的第一名。

    

    本文介绍了CheXOFA，一种用于胸部X射线领域的新型预训练视觉语言模型(VLM)。我们的模型首先在一般领域的多模态数据集上进行预训练，然后再转移到胸部X射线领域。在一个著名的VLM中，我们将各种特定领域的任务统一为一个简单的序列到序列的模式。这使得模型能够从有限的领域资源中有效地学习所需的知识和技能。通过在BioNLP共享任务提供的基准数据集上展示出卓越的性能，我们的模型受益于跨多个任务和领域的训练。通过集成和事实校准等微妙的技巧，我们的系统在RadSum23的隐藏测试集上取得了第一名。

    In this paper, we introduce CheXOFA, a new pre-trained vision-language model (VLM) for the chest X-ray domain. Our model is initially pre-trained on various multimodal datasets within the general domain before being transferred to the chest X-ray domain. Following a prominent VLM, we unify various domain-specific tasks into a simple sequence-to-sequence schema. It enables the model to effectively learn the required knowledge and skills from limited resources in the domain. Demonstrating superior performance on the benchmark datasets provided by the BioNLP shared task, our model benefits from its training across multiple tasks and domains. With subtle techniques including ensemble and factual calibration, our system achieves first place on the RadSum23 leaderboard for the hidden test set.
    
[^13]: 利用基于排名的方法增强孟加拉文本摘要的质量

    Rank Your Summaries: Enhancing Bengali Text Summarization via Ranking-based Approach. (arXiv:2307.07392v1 [cs.CL])

    [http://arxiv.org/abs/2307.07392](http://arxiv.org/abs/2307.07392)

    该论文利用基于排名的方法，通过比较四种不同的预训练孟加拉文本摘要模型的输出来确定给定文本的最准确和信息丰富的摘要。

    

    随着对既高效又准确的文本摘要技术的需求日益增加，探索能够增强专为孟加拉文本摘要而设计的预训练模型的质量和精确性变得至关重要。在文本摘要任务中，人们可以使用众多的预训练转换器模型。因此，在这些预训练摘要模型生成的各种选项中，确定给定文本的最具信息量和相关性的摘要变得非常具有挑战性。本文旨在通过利用一种简单而有效的基于排名的方法，比较四种不同的预训练孟加拉文本摘要模型的输出来确定给定文本的最准确和信息丰富的摘要。该过程首先对输入文本进行预处理，包括去除特殊字符和标点符号等不必要的元素。接下来，我们利用四个预训练的摘要模型。

    With the increasing need for text summarization techniques that are both efficient and accurate, it becomes crucial to explore avenues that enhance the quality and precision of pre-trained models specifically tailored for summarizing Bengali texts. When it comes to text summarization tasks, there are numerous pre-trained transformer models at one's disposal. Consequently, it becomes quite a challenge to discern the most informative and relevant summary for a given text among the various options generated by these pre-trained summarization models. This paper aims to identify the most accurate and informative summary for a given text by utilizing a simple but effective ranking-based approach that compares the output of four different pre-trained Bengali text summarization models. The process begins by carrying out preprocessing of the input text that involves eliminating unnecessary elements such as special characters and punctuation marks. Next, we utilize four pre-trained summarization
    
[^14]: AIC-AB NET：一种具有空间注意力和文本属性的图像字幕神经网络

    AIC-AB NET: A Neural Network for Image Captioning with Spatial Attention and Text Attributes. (arXiv:2307.07370v1 [cs.CV])

    [http://arxiv.org/abs/2307.07370](http://arxiv.org/abs/2307.07370)

    一种新型的图像字幕神经网络AIC-AB NET将空间注意力和文本属性相结合，通过自适应空间注意力和输入文本属性信息，提升图像字幕的性能和减少不确定性。

    

    图像字幕在计算机视觉和自然语言处理领域中具有重要意义。我们提出并展示了一种新型的属性-信息-组合注意力网络AIC-AB NET，该网络将空间注意力架构和文本属性结合在编码器-解码器中。对于字幕生成，自适应空间注意力确定最能代表图像的图像区域，并决定是侧重于视觉特征还是视觉标记。文本属性信息同步输入解码器，以帮助图像识别并减少不确定性。我们在MS COCO数据集和一个新提出的时尚数据集上进行了对AICAB NET的测试和评估。该时尚数据集被用作单物体图像的基准。结果表明，相对于现有的基线模型和去除了部分结构的模型，我们提出的模型在MSCOCO图像和我们的单物体图像上表现出了优越的性能。我们的AIC-AB NET优于基线自适应注意力网络。

    Image captioning is a significant field across computer vision and natural language processing. We propose and present AIC-AB NET, a novel Attribute-Information-Combined Attention-Based Network that combines spatial attention architecture and text attributes in an encoder-decoder. For caption generation, adaptive spatial attention determines which image region best represents the image and whether to attend to the visual features or the visual sentinel. Text attribute information is synchronously fed into the decoder to help image recognition and reduce uncertainty. We have tested and evaluated our AICAB NET on the MS COCO dataset and a new proposed Fashion dataset. The Fashion dataset is employed as a benchmark of single-object images. The results show the superior performance of the proposed model compared to the state-of-the-art baseline and ablated models on both the images from MSCOCO and our single-object images. Our AIC-AB NET outperforms the baseline adaptive attention network 
    
[^15]: 大型语言模型对数字公共资源构成威胁吗？来自Stack Overflow活动的证据。

    Are Large Language Models a Threat to Digital Public Goods? Evidence from Activity on Stack Overflow. (arXiv:2307.07367v1 [cs.SI])

    [http://arxiv.org/abs/2307.07367](http://arxiv.org/abs/2307.07367)

    大型语言模型如ChatGPT可能对公开的人工生成数据和知识资源带来重大影响，尤其在Stack Overflow这样的编程问答平台上，ChatGPT的使用导致了活动显著减少。

    

    类似ChatGPT的大型语言模型可以高效地为用户提供各种主题的信息，成为搜索网络和在线求助的潜在替代品。但由于用户与模型进行私下交互，这些模型可能大幅减少公开可用的人工生成数据和知识资源。这种替代可能给未来模型的训练数据获取带来重大问题。在这项工作中，我们通过分析Stack Overflow的活动情况（这是计算机编程领域领先的在线问答平台），研究了ChatGPT发布如何改变了网络上的人工生成开放数据。我们发现相对于俄罗斯和中国的类似平台（因为ChatGPT的访问受限）以及数学相关论坛（ChatGPT能力较弱），Stack Overflow的活动显著减少。差分中差分模型估计Stack Overflow的每周帖子数量减少了16％。这个效应在...

    Large language models like ChatGPT efficiently provide users with information about various topics, presenting a potential substitute for searching the web and asking people for help online. But since users interact privately with the model, these models may drastically reduce the amount of publicly available human-generated data and knowledge resources. This substitution can present a significant problem in securing training data for future models. In this work, we investigate how the release of ChatGPT changed human-generated open data on the web by analyzing the activity on Stack Overflow, the leading online Q\&A platform for computer programming. We find that relative to its Russian and Chinese counterparts, where access to ChatGPT is limited, and to similar forums for mathematics, where ChatGPT is less capable, activity on Stack Overflow significantly decreased. A difference-in-differences model estimates a 16\% decrease in weekly posts on Stack Overflow. This effect increases in 
    
[^16]: 无资源语音应用的隐藏单元聚类表示学习

    Representation Learning With Hidden Unit Clustering For Low Resource Speech Applications. (arXiv:2307.07325v1 [eess.AS])

    [http://arxiv.org/abs/2307.07325](http://arxiv.org/abs/2307.07325)

    本文提出了一种使用隐藏单元聚类框架进行自监督表示学习的方法，用于无文本资源下的语音表示学习。模型使用卷积神经网络和长短期记忆层对音频样本进行处理并生成上下文向量表示，通过隐藏单元聚类框架将这些表示归类为少量类似音素的单元，用于学习语义丰富的语音表示。研究结果表明这种方法可以提高模型性能。

    

    无文本资源下的语音表示学习是许多低资源语音应用中一个非常感兴趣的领域。本文介绍了一种使用隐藏单元聚类（HUC）框架从原始音频中进行自监督表示学习的方法。模型的输入包括被窗口化并经过1-D卷积层处理的音频样本。从卷积神经网络（CNN）模块学习到的"时频"表示经过长短期记忆（LSTM）层进一步处理，为每个窗口化片段生成上下文向量表示。使用隐藏单元聚类框架对这些表示进行分类，将其归类为少量类似音素的单元，用于训练模型学习语义丰富的语音表示。目标包括每个音频片段的类似音素伪标签，这些标签是使用迭代k-means算法生成的。我们探索了一些可以提高模型性能的技术。

    The representation learning of speech, without textual resources, is an area of significant interest for many low resource speech applications. In this paper, we describe an approach to self-supervised representation learning from raw audio using a hidden unit clustering (HUC) framework. The input to the model consists of audio samples that are windowed and processed with 1-D convolutional layers. The learned "time-frequency" representations from the convolutional neural network (CNN) module are further processed with long short term memory (LSTM) layers which generate a contextual vector representation for every windowed segment. The HUC framework, allowing the categorization of the representations into a small number of phoneme-like units, is used to train the model for learning semantically rich speech representations. The targets consist of phoneme-like pseudo labels for each audio segment and these are generated with an iterative k-means algorithm. We explore techniques that impro
    
[^17]: C3: 使用ChatGPT进行零-shot Text-to-SQL

    C3: Zero-shot Text-to-SQL with ChatGPT. (arXiv:2307.07306v1 [cs.CL])

    [http://arxiv.org/abs/2307.07306](http://arxiv.org/abs/2307.07306)

    C3是基于ChatGPT的零-shot Text-to-SQL方法，通过三个关键组件提供系统性的处理方法，在Spider Challenge上取得了82.3%的执行准确率，成为最先进的方法。

    

    本文提出了一种基于ChatGPT的零-shot Text-to-SQL方法，名为C3，其在Spider的测试集上达到82.3%的执行准确率，并成为Spider Challenge中最先进的零-shot Text-to-SQL方法。C3由三个关键组件组成：Clear Prompting (CP)，Calibration with Hints (CH)和Consistent Output (CO)，分别对应于模型输入，模型偏差和模型输出。它为零-shot Text-to-SQL提供了系统性的处理方法。我们进行了大量实验证明了我们提出的方法的有效性和效率。

    This paper proposes a ChatGPT-based zero-shot Text-to-SQL method, dubbed C3, which achieves 82.3\% in terms of execution accuracy on the holdout test set of Spider and becomes the state-of-the-art zero-shot Text-to-SQL method on the Spider Challenge. C3 consists of three key components: Clear Prompting (CP), Calibration with Hints (CH), and Consistent Output (CO), which are corresponding to the model input, model bias and model output respectively. It provides a systematic treatment for zero-shot Text-to-SQL. Extensive experiments have been conducted to verify the effectiveness and efficiency of our proposed method.
    
[^18]: 一种通过多尺度时空骨架匹配的一次性动作识别方法

    One-Shot Action Recognition via Multi-Scale Spatial-Temporal Skeleton Matching. (arXiv:2307.07286v1 [cs.CV])

    [http://arxiv.org/abs/2307.07286](http://arxiv.org/abs/2307.07286)

    通过多尺度时空骨架匹配，本研究提出了一种新颖的一次性动作识别技术，能够处理骨架动作识别中的空间结构和时间顺序，实现了最优特征匹配。

    

    一次性骨架动作识别旨在通过单个训练样本学习骨架动作识别模型，由于收集和标注大规模骨架动作数据的挑战，它引起了越来越多的关注。然而，大多数现有研究通过直接比较特征向量来匹配骨架序列，忽略了骨架数据的空间结构和时间顺序。本文提出了一种新颖的一次性骨架动作识别技术，通过多尺度时空特征匹配来处理骨架动作识别。我们在多个空间和时间尺度上表示骨架数据，并从两个角度实现最优特征匹配。第一种是多尺度匹配，同时捕捉多个空间和时间尺度上骨架数据的语义相关性。第二种是跨尺度匹配，通过捕捉样本间的相关性来处理不同的运动幅度和速度。

    One-shot skeleton action recognition, which aims to learn a skeleton action recognition model with a single training sample, has attracted increasing interest due to the challenge of collecting and annotating large-scale skeleton action data. However, most existing studies match skeleton sequences by comparing their feature vectors directly which neglects spatial structures and temporal orders of skeleton data. This paper presents a novel one-shot skeleton action recognition technique that handles skeleton action recognition via multi-scale spatial-temporal feature matching. We represent skeleton data at multiple spatial and temporal scales and achieve optimal feature matching from two perspectives. The first is multi-scale matching which captures the scale-wise semantic relevance of skeleton data at multiple spatial and temporal scales simultaneously. The second is cross-scale matching which handles different motion magnitudes and speeds by capturing sample-wise relevance across multi
    
[^19]: AudioInceptionNeXt：TCL AI LAB对EPIC-SOUND音频交互识别挑战赛2023的投稿

    AudioInceptionNeXt: TCL AI LAB Submission to EPIC-SOUND Audio-Based-Interaction-Recognition Challenge 2023. (arXiv:2307.07265v1 [cs.SD])

    [http://arxiv.org/abs/2307.07265](http://arxiv.org/abs/2307.07265)

    AudioInceptionNeXt是一个基于单个流的CNN架构，通过使用时间-频率log-mel-spectrogram的音频样本，结合并行的多尺度深度可分离卷积核来更有效地学习时间和频率信息，实现了在2023年EPIC-SOUND音频交互识别挑战赛上55.43%的准确率。

    

    本报告介绍了我们对2023年Epic-Kitchen EPIC-SOUNDS音频交互识别挑战赛的提交的技术细节。任务是学习从音频样本到相应动作标签的映射。为了实现这个目标，我们提出了一种名为AudioInceptionNeXt的简单而有效的基于单个流的CNN架构，它基于音频样本的时间-频率对数-梅尔谱图进行操作。受InceptionNeXt设计的启发，我们在AudioInceptionNeXt块中提出了并行的多尺度深度可分离卷积核，使得模型能够更有效地学习时间和频率信息。大尺度可分离卷积核捕捉活动的长时间持续性和全局频率语义信息，而小尺度可分离卷积核捕捉活动的短时间持续性和频率信息的局部细节。我们的方法在挑战测试集上达到了55.43%的top-1准确率，排名为...

    This report presents the technical details of our submission to the 2023 Epic-Kitchen EPIC-SOUNDS Audio-Based Interaction Recognition Challenge. The task is to learn the mapping from audio samples to their corresponding action labels. To achieve this goal, we propose a simple yet effective single-stream CNN-based architecture called AudioInceptionNeXt that operates on the time-frequency log-mel-spectrogram of the audio samples. Motivated by the design of the InceptionNeXt, we propose parallel multi-scale depthwise separable convolutional kernels in the AudioInceptionNeXt block, which enable the model to learn the time and frequency information more effectively. The large-scale separable kernels capture the long duration of activities and the global frequency semantic information, while the small-scale separable kernels capture the short duration of activities and local details of frequency information. Our approach achieved 55.43% of top-1 accuracy on the challenge test set, ranked as 
    
[^20]: 一种点云地图中动态点去除的动态评估基准

    A Dynamic Points Removal Benchmark in Point Cloud Maps. (arXiv:2307.07260v1 [cs.RO])

    [http://arxiv.org/abs/2307.07260](http://arxiv.org/abs/2307.07260)

    本论文提出了一个易于扩展的统一评估框架，用于评估地图中动态点去除技术，重构了最先进的方法并引入了新的度量指标来分析方法的局限性，可以帮助研究人员深入了解这些方法背后的原因。该基准使用多种传感器类型的数据集，并提供公开获取的代码和数据集。

    

    在机器人领域，点云已经成为一种重要的地图表示方式。从定位和全局路径规划等下游任务的角度来看，与动态物体对应的点会对它们的性能产生不利影响。现有的点云中动态点去除方法往往缺乏清晰的比较评估和全面的分析。因此，我们提出了一个易于扩展的统一评估框架，用于评估地图中动态点去除技术。它包括重构的最先进方法和新的度量指标，用于分析这些方法的局限性。这使得研究人员能够深入了解这些局限性背后的原因。该基准使用多种传感器类型的数据集。与我们研究相关的所有代码和数据集都可以公开获得，以便进行进一步的开发和利用。

    In the field of robotics, the point cloud has become an essential map representation. From the perspective of downstream tasks like localization and global path planning, points corresponding to dynamic objects will adversely affect their performance. Existing methods for removing dynamic points in point clouds often lack clarity in comparative evaluations and comprehensive analysis. Therefore, we propose an easy-to-extend unified benchmarking framework for evaluating techniques for removing dynamic points in maps. It includes refactored state-of-art methods and novel metrics to analyze the limitations of these approaches. This enables researchers to dive deep into the underlying reasons behind these limitations. The benchmark makes use of several datasets with different sensor types. All the code and datasets related to our study are publicly available for further development and utilization.
    
[^21]: 对话代理101：设计有效的对话系统的关键要素初学者指南

    Dialogue Agents 101: A Beginner's Guide to Critical Ingredients for Designing Effective Conversational Systems. (arXiv:2307.07255v1 [cs.CL])

    [http://arxiv.org/abs/2307.07255](http://arxiv.org/abs/2307.07255)

    本文提供了一个对话代理设计的相关要素的综合概述，包括对话代理的主要特征、支持任务、数据集和评估方法。研究表明，构建单独的模型来处理不同的对话任务是昂贵且冗余的。

    

    通过与同行进行交流来分享想法是人类互动的主要方式。因此，在对话人工智能领域进行了广泛的研究，导致对话任务、数据集和方法的可用性和多样性增加。然而，由于多个任务同时探索，当前对话人工智能的现状变得分散。因此，为了帮助从零开始设计对话代理的从业者，本研究提供了对对话代理的主要特征、支持任务、相应的开放领域数据集以及用于基准测试这些数据集的方法的综合概述。我们观察到不同的方法已被用于解决不同的对话任务。然而，为每个任务构建单独的模型是昂贵且冗余的。

    Sharing ideas through communication with peers is the primary mode of human interaction. Consequently, extensive research has been conducted in the area of conversational AI, leading to an increase in the availability and diversity of conversational tasks, datasets, and methods. However, with numerous tasks being explored simultaneously, the current landscape of conversational AI becomes fragmented. Therefore, initiating a well-thought-out model for a dialogue agent can pose significant challenges for a practitioner. Towards highlighting the critical ingredients needed for a practitioner to design a dialogue agent from scratch, the current study provides a comprehensive overview of the primary characteristics of a dialogue agent, the supporting tasks, their corresponding open-domain datasets, and the methods used to benchmark these datasets. We observe that different methods have been used to tackle distinct dialogue tasks. However, building separate models for each task is costly and 
    
[^22]: 通过敌对双机器学习的因果参数估计来缓解敌对脆弱性

    Mitigating Adversarial Vulnerability through Causal Parameter Estimation by Adversarial Double Machine Learning. (arXiv:2307.07250v1 [cs.LG])

    [http://arxiv.org/abs/2307.07250](http://arxiv.org/abs/2307.07250)

    通过敌对双机器学习方法，可以量化和缓解深度神经网络在面对敌对输入时的脆弱性。

    

    从经过精心设计的视觉输入中衍生出的敌对例子可以轻松地损害深度神经网络的决策过程。为了防止潜在的威胁，各种基于敌对训练的防御方法迅速增长，并成为稳健性的事实上标准方法。尽管最近取得了竞争性的成就，我们观察到敌对脆弱性在不同目标之间存在差异，并且某些脆弱性仍然普遍存在。有趣的是，即使使用更深层次的架构和先进的防御方法，这种奇特的现象仍然无法缓解。为了解决这个问题，本文介绍了一种称为敌对双机器学习（ADML）的因果方法，它允许我们量化网络预测的敌对脆弱性程度，并捕捉对结果的处理效果。ADML可以直接估计敌对扰动本身的因果参数，并减轻可能损害稳健性的负面效应。

    Adversarial examples derived from deliberately crafted perturbations on visual inputs can easily harm decision process of deep neural networks. To prevent potential threats, various adversarial training-based defense methods have grown rapidly and become a de facto standard approach for robustness. Despite recent competitive achievements, we observe that adversarial vulnerability varies across targets and certain vulnerabilities remain prevalent. Intriguingly, such peculiar phenomenon cannot be relieved even with deeper architectures and advanced defense methods. To address this issue, in this paper, we introduce a causal approach called Adversarial Double Machine Learning (ADML), which allows us to quantify the degree of adversarial vulnerability for network predictions and capture the effect of treatments on outcome of interests. ADML can directly estimate causal parameter of adversarial perturbations per se and mitigate negative effects that can potentially damage robustness, bridgi
    
[^23]: 对OneMinMax上使用GSEMO进行多样性优化的严格运行时分析

    Rigorous Runtime Analysis of Diversity Optimization with GSEMO on OneMinMax. (arXiv:2307.07248v1 [cs.NE])

    [http://arxiv.org/abs/2307.07248](http://arxiv.org/abs/2307.07248)

    本文进行了对OneMinMax问题上使用GSEMO算法进行多样性优化的严格运行时分析，证明了算法能在期望时间$O(n^2)$内找到具有最佳多样性的种群。

    

    进化多样性优化旨在寻找满足其适应度约束的多样性解集。在多目标优化的上下文中，该约束可能要求解决方案为帕累托最优解。本文研究了GSEMO算法在一个双目标基准问题OneMinMax上如何通过增强多样性的启发式优化其种群的多样性。我们对优化的最后一步进行了严格的运行时分析，即算法从具有次优多样性的种群开始，并证明在问题规模$n$为奇数时，它以期望时间$O(n^2)$找到具有最佳多样性的种群。为了达到我们的目标，我们分析了种群的随机游走，这反映了种群中变化的频率及其结果。

    The evolutionary diversity optimization aims at finding a diverse set of solutions which satisfy some constraint on their fitness. In the context of multi-objective optimization this constraint can require solutions to be Pareto-optimal. In this paper we study how the GSEMO algorithm with additional diversity-enhancing heuristic optimizes a diversity of its population on a bi-objective benchmark problem OneMinMax, for which all solutions are Pareto-optimal.  We provide a rigorous runtime analysis of the last step of the optimization, when the algorithm starts with a population with a second-best diversity, and prove that it finds a population with optimal diversity in expected time $O(n^2)$, when the problem size $n$ is odd. For reaching our goal, we analyse the random walk of the population, which reflects the frequency of changes in the population and their outcomes.
    
[^24]: 用于加速深度学习训练和提高鲁棒性的乘法更新规则

    Multiplicative update rules for accelerating deep learning training and increasing robustness. (arXiv:2307.07189v1 [cs.LG])

    [http://arxiv.org/abs/2307.07189](http://arxiv.org/abs/2307.07189)

    本文提出了一种优化框架，通过使用乘法更新规则，加速深度学习训练并提高模型的鲁棒性。

    

    尽管深度学习在许多研究领域已经达到了最先进的性能，但仍然加速训练和构建鲁棒的深度学习模型仍然是一个具有挑战性的任务。本文提出了一种优化框架，适用于各种优化算法，并使得可以应用替代的参数更新方法，从而加快训练和增强模型的鲁棒性。

    Even nowadays, where Deep Learning (DL) has achieved state-of-the-art performance in a wide range of research domains, accelerating training and building robust DL models remains a challenging task. To this end, generations of researchers have pursued to develop robust methods for training DL architectures that can be less sensitive to weight distributions, model architectures and loss landscapes. However, such methods are limited to adaptive learning rate optimizers, initialization schemes, and clipping gradients without investigating the fundamental rule of parameters update. Although multiplicative updates have contributed significantly to the early development of machine learning and hold strong theoretical claims, to best of our knowledge, this is the first work that investigate them in context of DL training acceleration and robustness. In this work, we propose an optimization framework that fits to a wide range of optimization algorithms and enables one to apply alternative upda
    
[^25]: TriFormer:一种用于轻度认知损害转化预测的多模态Transformer框架

    TriFormer: A Multi-modal Transformer Framework For Mild Cognitive Impairment Conversion Prediction. (arXiv:2307.07177v1 [cs.CV])

    [http://arxiv.org/abs/2307.07177](http://arxiv.org/abs/2307.07177)

    TriFormer是一种基于Transformer的多模态框架，用于准确预测轻度认知损害转化为稳定MCI或进展MCI的情况。该框架包括图像Transformer、临床Transformer和模态融合Transformer，通过整合多模态数据来提高预测性能，并在实验中优于先前的单模态和多模态方法。

    

    对于早期治疗以防止或减缓阿尔茨海默病（AD）进展，轻度认知损害（MCI）转化为AD的预测非常重要。为了准确预测MCI转化为稳定MCI或进展MCI，我们提出了一种新颖的基于Transformer的框架TriFormer，它包括三个专门的Transformer来整合多模态数据。TriFormer使用I）图像Transformer从医学扫描中提取多视图图像特征，II）临床Transformer嵌入和相关多模态临床数据， III）模态融合Transformer根据图像和临床Transformer的输出融合产生准确预测。TriFormer在阿尔茨海默病神经影像学计划（ANDI）1和ADNI2数据集上进行评估，并在先前最先进的单模态和多模态方法上表现出更好的性能。

    The prediction of mild cognitive impairment (MCI) conversion to Alzheimer's disease (AD) is important for early treatment to prevent or slow the progression of AD. To accurately predict the MCI conversion to stable MCI or progressive MCI, we propose Triformer, a novel transformer-based framework with three specialized transformers to incorporate multi-model data. Triformer uses I) an image transformer to extract multi-view image features from medical scans, II) a clinical transformer to embed and correlate multi-modal clinical data, and III) a modality fusion transformer that produces an accurate prediction based on fusing the outputs from the image and clinical transformers. Triformer is evaluated on the Alzheimer's Disease Neuroimaging Initiative (ANDI)1 and ADNI2 datasets and outperforms previous state-of-the-art single and multi-modal methods.
    
[^26]: Safe DreamerV3：带有世界模型的安全强化学习

    Safe DreamerV3: Safe Reinforcement Learning with World Models. (arXiv:2307.07176v1 [cs.LG])

    [http://arxiv.org/abs/2307.07176](http://arxiv.org/abs/2307.07176)

    Safe DreamerV3是一种通过集成基于拉格朗日和计划的方法到世界模型中的新算法，实现了在低维度和仅采用视觉的任务中几乎零成本的安全强化学习。

    

    强化学习在真实世界场景中的广泛应用还没有实现, 这主要是因为其未能满足这些系统的基本安全需求。现有的安全强化学习方法使用成本函数来增强安全性，在复杂场景中，包括仅采用视觉的任务中，即使进行全面的数据采样和训练，也无法实现零成本。为了解决这个问题，我们引入了Safe DreamerV3，这是一种将基于拉格朗日和计划的方法集成到世界模型中的新算法。我们的方法论在SafeRL中代表了一个重要的进步，是第一个在Safety-Gymnasium基准中实现近乎零成本的算法。我们的项目网站可以在以下链接找到：https://sites.google.com/view/safedreamerv3。

    The widespread application of Reinforcement Learning (RL) in real-world situations is yet to come to fruition, largely as a result of its failure to satisfy the essential safety demands of such systems. Existing safe reinforcement learning (SafeRL) methods, employing cost functions to enhance safety, fail to achieve zero-cost in complex scenarios, including vision-only tasks, even with comprehensive data sampling and training. To address this, we introduce Safe DreamerV3, a novel algorithm that integrates both Lagrangian-based and planning-based methods within a world model. Our methodology represents a significant advancement in SafeRL as the first algorithm to achieve nearly zero-cost in both low-dimensional and vision-only tasks within the Safety-Gymnasium benchmark. Our project website can be found in: https://sites.google.com/view/safedreamerv3.
    
[^27]: 对抗训练中的易受攻击性实例重新加权

    Vulnerability-Aware Instance Reweighting For Adversarial Training. (arXiv:2307.07167v1 [cs.LG])

    [http://arxiv.org/abs/2307.07167](http://arxiv.org/abs/2307.07167)

    该论文提出了一种新的实例级别重新加权方案，通过考虑每个自然示例的易受攻击性和对抗攻击导致的信息损失，来改进对抗训练算法的性能。

    

    对抗训练一直被发现能大大提高深度学习分类器对抗性攻击的鲁棒性。对抗训练通过在训练分类器时加入对抗性样本来获得鲁棒性。大多数对抗训练算法的变体将每个训练样本平等对待。然而，最近的研究表明通过将它们不平等地对待可以获得更好的性能。此外，对抗训练对训练集中的不同类别产生了不均衡的影响，并不公平地损害了与本质上更难分类的类别相对应的示例。因此，已经提出了各种重新加权方案，为训练集中各个示例的鲁棒损失分配不平等的权重。在这项工作中，我们提出了一种新的实例级别重新加权方案。它考虑了每个自然示例的易受攻击性和由于对抗攻击而导致的其对手示例上的信息损失。通过广泛的实验验证

    Adversarial Training (AT) has been found to substantially improve the robustness of deep learning classifiers against adversarial attacks. AT involves obtaining robustness by including adversarial examples in training a classifier. Most variants of AT algorithms treat every training example equally. However, recent works have shown that better performance is achievable by treating them unequally. In addition, it has been observed that AT exerts an uneven influence on different classes in a training set and unfairly hurts examples corresponding to classes that are inherently harder to classify. Consequently, various reweighting schemes have been proposed that assign unequal weights to robust losses of individual examples in a training set. In this work, we propose a novel instance-wise reweighting scheme. It considers the vulnerability of each natural example and the resulting information loss on its adversarial counterpart occasioned by adversarial attacks. Through extensive experiment
    
[^28]: 在无线网络中使用联邦学习增强人工智能生成的内容

    Federated Learning-Empowered AI-Generated Content in Wireless Networks. (arXiv:2307.07146v1 [cs.DC])

    [http://arxiv.org/abs/2307.07146](http://arxiv.org/abs/2307.07146)

    本论文研究了在无线网络中使用联邦学习来增强人工智能生成的内容，以提供多样化、个性化和高质量的内容。

    

    人工智能生成的内容（AIGC）已经成为一种有前景的技术，通过采用各种生成型人工智能模型，它可以提高内容创建过程的效率、质量、多样性和灵活性。在无线网络中部署AIGC服务被期望可以提升用户体验。然而，现有的AIGC服务在预训练、微调和推理过程中存在一些限制，特别是在隐私保护的无线网络中的实现。联邦学习（FL）作为一种协作学习框架，可以将模型训练分布到协作数据所有者，无需共享数据，可以同时提高学习效率并实现对AIGC的隐私保护。为此，我们提出了基于FL的技术，以增强AIGC，并旨在使用户能够生成多样化、个性化和高质量的内容。

    Artificial intelligence generated content (AIGC) has emerged as a promising technology to improve the efficiency, quality, diversity and flexibility of the content creation process by adopting a variety of generative AI models. Deploying AIGC services in wireless networks has been expected to enhance the user experience. However, the existing AIGC service provision suffers from several limitations, e.g., the centralized training in the pre-training, fine-tuning and inference processes, especially their implementations in wireless networks with privacy preservation. Federated learning (FL), as a collaborative learning framework where the model training is distributed to cooperative data owners without the need for data sharing, can be leveraged to simultaneously improve learning efficiency and achieve privacy protection for AIGC. To this end, we present FL-based techniques for empowering AIGC, and aim to enable users to generate diverse, personalized, and high-quality content. Furthermo
    
[^29]: 机器学习算法的多维能力诊断

    Multi-Dimensional Ability Diagnosis for Machine Learning Algorithms. (arXiv:2307.07134v1 [cs.LG])

    [http://arxiv.org/abs/2307.07134](http://arxiv.org/abs/2307.07134)

    本文提出了一个任务无关的评估框架Camilla，通过定义多维度的诊断度量Ability来协同测量每个机器学习算法的多面体强度，解决了机器学习算法在实际性能和标准化评估中存在的差距问题。

    

    机器学习算法已经在许多应用中变得无处不在（例如图像分类）。然而，由于传统指标（例如每个分类器的粗粒度准确度）的测量不足，通常在这些算法的实际性能和标准化评估中存在实质性差距。在本文中，受到人类测量中的心理测量理论的启发，我们提出了一个任务无关的评估框架Camilla，其中定义了一个多维诊断度量Ability来协同测量每个机器学习算法的多面体强度。具体来说，给定不同算法对数据样本的响应日志，我们利用认知诊断假设和神经网络来学习算法、样本以及每个样本的技能（显式或隐式预定义）之间的复杂交互。通过这种方式，可以同时评估每个算法在多个技能上的表现能力。

    Machine learning algorithms have become ubiquitous in a number of applications (e.g. image classification). However, due to the insufficient measurement of traditional metrics (e.g. the coarse-grained Accuracy of each classifier), substantial gaps are usually observed between the real-world performance of these algorithms and their scores in standardized evaluations. In this paper, inspired by the psychometric theories from human measurement, we propose a task-agnostic evaluation framework Camilla, where a multi-dimensional diagnostic metric Ability is defined for collaboratively measuring the multifaceted strength of each machine learning algorithm. Specifically, given the response logs from different algorithms to data samples, we leverage cognitive diagnosis assumptions and neural networks to learn the complex interactions among algorithms, samples and the skills (explicitly or implicitly pre-defined) of each sample. In this way, both the abilities of each algorithm on multiple skil
    
[^30]: DataAssist:一种用于数据清洗和准备的机器学习方法

    DataAssist: A Machine Learning Approach to Data Cleaning and Preparation. (arXiv:2307.07119v1 [cs.LG])

    [http://arxiv.org/abs/2307.07119](http://arxiv.org/abs/2307.07119)

    DataAssist是一种机器学习方法，用于提高数据集质量和节省数据清洗和准备时间。

    

    目前的自动化机器学习工具主要关注于模型选择和参数优化，忽略了数据清洗和整理所占据的大部分时间。本文介绍了一种名为DataAssist的自动化数据准备和清洗平台，利用机器学习方法提高数据集质量。我们展示了DataAssist提供了一个用于探索性数据分析和数据清洗的管道，包括为用户选择的变量生成可视化，统一数据注释，提供异常值删除建议以及对数据进行预处理。导出的数据集可以轻松与其他自动化机器学习工具或用户指定的模型进行整合，以进行后续分析。我们的数据中心化工具适用于多个领域，包括经济学、商业和预测应用，可节省超过50\%的数据清理和准备时间。

    Current automated machine learning (ML) tools are model-centric, focusing on model selection and parameter optimization. However, the majority of the time in data analysis is devoted to data cleaning and wrangling, for which limited tools are available. Here we present DataAssist, an automated data preparation and cleaning platform that enhances dataset quality using ML-informed methods. We show that DataAssist provides a pipeline for exploratory data analysis and data cleaning, including generating visualization for user-selected variables, unifying data annotation, suggesting anomaly removal, and preprocessing data. The exported dataset can be readily integrated with other autoML tools or user-specified model for downstream analysis. Our data-centric tool is applicable to a variety of fields, including economics, business, and forecasting applications saving over 50\% time of the time spent on data cleansing and preparation.
    
[^31]: Espaloma-0.3.0: 用于蛋白质-配体系统模拟的机器学习分子力学力场及其扩展

    Espaloma-0.3.0: Machine-learned molecular mechanics force field for the simulation of protein-ligand systems and beyond. (arXiv:2307.07085v1 [physics.chem-ph])

    [http://arxiv.org/abs/2307.07085](http://arxiv.org/abs/2307.07085)

    Espaloma-0.3.0是一个用于蛋白质-配体系统模拟的机器学习分子力学力场，通过能量和力的拟合纳入量子化学数据进行训练，具有灵活性和可扩展性。

    

    分子力学（MM）力场是通过简单的一对一和多项式项来表征分子系统能量景观的模型。传统上，它们依赖于人工专家策划、不灵活且难以扩展的离散化化学参数赋值规则，即原子或价态类型。最近，人们对使用图神经网络替代此过程，并使参数化方案能够直接从量子化学计算或凝聚相数据中以端到端的可微分方式进行学习表示出了巨大兴趣。在本文中，我们通过将能量和力的适应性拟合直接纳入训练过程，扩展了Espaloma的端到端可微分力场构建方法。基于OpenMM SPICE数据集，我们策划了一个包含与生物分子建模广泛相关的化学空间的数据集，涵盖小分子、蛋白质和RNA。最终得到了一个适用于蛋白质-配体系统模拟的机器学习分子力学力场。

    Molecular mechanics (MM) force fields -- the models that characterize the energy landscape of molecular systems via simple pairwise and polynomial terms -- have traditionally relied on human expert-curated, inflexible, and poorly extensible discrete chemical parameter assignment rules, namely atom or valence types. Recently, there has been significant interest in using graph neural networks to replace this process, while enabling the parametrization scheme to be learned in an end-to-end differentiable manner directly from quantum chemical calculations or condensed-phase data. In this paper, we extend the Espaloma end-to-end differentiable force field construction approach by incorporating both energy and force fitting directly to quantum chemical data into the training process. Building on the OpenMM SPICE dataset, we curate a dataset containing chemical spaces highly relevant to the broad interest of biomolecular modeling, covering small molecules, proteins, and RNA. The resulting for
    
[^32]: 安全强化学习作为Wasserstein变分推理：可解释性的形式方法

    Safe Reinforcement Learning as Wasserstein Variational Inference: Formal Methods for Interpretability. (arXiv:2307.07084v1 [cs.LG])

    [http://arxiv.org/abs/2307.07084](http://arxiv.org/abs/2307.07084)

    本研究提出了一种新的自适应Wasserstein变分优化（AWaVO）方法，利用形式方法解决了顺序决策中的解释和透明性问题，并提供了奖励设计和策略收敛的概率解释。

    

    强化学习或最优控制可以为具有可变动态的顺序决策问题提供有效的推理。然而，在实际实施中，解释奖励函数和相应的最优策略一直是一个持久的挑战。因此，将顺序决策问题形式化为推理具有重要价值，因为概率推理原则上提供了多样且强大的数学工具来推断随机动态，同时提供了奖励设计和策略收敛的概率解释。在本研究中，我们提出了一种新颖的自适应Wasserstein变分优化（AWaVO）方法来解决这些顺序决策中的挑战。我们的方法利用形式方法来解释奖励设计，透明地训练收敛，以及对顺序决策的概率解释。为了证明实用性，我们展示了收敛训练并保证了收敛的训练。

    Reinforcement Learning or optimal control can provide effective reasoning for sequential decision-making problems with variable dynamics. Such reasoning in practical implementation, however, poses a persistent challenge in interpreting the reward function and corresponding optimal policy. Consequently, formalizing the sequential decision-making problems as inference has a considerable value, as probabilistic inference in principle offers diverse and powerful mathematical tools to infer the stochastic dynamics whilst suggesting a probabilistic interpretation of the reward design and policy convergence. In this study, we propose a novel Adaptive Wasserstein Variational Optimization (AWaVO) to tackle these challenges in sequential decision-making. Our approach utilizes formal methods to provide interpretations of reward design, transparency of training convergence, and probabilistic interpretation of sequential decisions. To demonstrate practicality, we show convergent training with guara
    
[^33]: 基于顶点的网络加速路径规划算法

    Vertex-based Networks to Accelerate Path Planning Algorithms. (arXiv:2307.07059v1 [cs.AI])

    [http://arxiv.org/abs/2307.07059](http://arxiv.org/abs/2307.07059)

    本文提出了一种基于顶点的网络加速路径规划算法，通过专注最优路径上的关键顶点，提供更高效的路径规划。实验结果表明，在随机生成的地图上，相比基准模型，我们的解决方案实现了超过400%的速度增益。

    

    路径规划在自主应用中起着关键作用，RRT*是该领域的主要解决方案之一。本文提出利用基于顶点的网络来增强RRT*的采样过程，从而实现更高效的路径规划。我们的方法专注于最优路径上的关键顶点，提供了关键但更稀疏的路径抽象。我们采用聚焦损失函数来解决相关的数据不平衡问题，并探索不同的掩码配置以确定系统性能的实际权衡。通过对随机生成的地图进行实验，我们的解决方案展示了显著的速度提升，相比基准模型提高了400%以上。

    Path planning plays a crucial role in various autonomy applications, and RRT* is one of the leading solutions in this field. In this paper, we propose the utilization of vertex-based networks to enhance the sampling process of RRT*, leading to more efficient path planning. Our approach focuses on critical vertices along the optimal paths, which provide essential yet sparser abstractions of the paths. We employ focal loss to address the associated data imbalance issue, and explore different masking configurations to determine practical tradeoffs in system performance. Through experiments conducted on randomly generated floor maps, our solutions demonstrate significant speed improvements, achieving over a 400% enhancement compared to the baseline model.
    
[^34]: 一种用于内窥镜肾结石识别的度量学习方法

    A metric learning approach for endoscopic kidney stone identification. (arXiv:2307.07046v1 [cs.CV])

    [http://arxiv.org/abs/2307.07046](http://arxiv.org/abs/2307.07046)

    本文提出了一种用于内窥镜肾结石识别的度量学习方法，该方法能够处理样本稀缺类别，并且在推广到新样本以及添加新类别到数据库时能有更好的应对能力

    

    最近提出了几种深度学习（DL）方法用于在输尿管镜检查期间自动识别肾结石，以便快速进行治疗决策。尽管这些DL方法取得了有希望的结果，但它们主要适用于有大量标记数据的肾结石类型。然而，对于一些罕见的肾结石类型，只有很少的标记图像可用。本文利用深度度量学习（DML）方法来处理这些样本稀缺的类别，并且能够很好地推广到分布样本之外，并且对于添加到数据库的新类别能够有更好的应对能力。所提出的引导式深度度量学习方法基于一种新颖的架构，设计了一种更好地学习数据表示的方式。解决方案受到少样本学习（FSL）的启发，并采用了师生模型的方法。师模型（GEMINI）基于已知标签的先验知识生成了一个缩小的假设空间

    Several Deep Learning (DL) methods have recently been proposed for an automated identification of kidney stones during an ureteroscopy to enable rapid therapeutic decisions. Even if these DL approaches led to promising results, they are mainly appropriate for kidney stone types for which numerous labelled data are available. However, only few labelled images are available for some rare kidney stone types. This contribution exploits Deep Metric Learning (DML) methods i) to handle such classes with few samples, ii) to generalize well to out of distribution samples, and iii) to cope better with new classes which are added to the database. The proposed Guided Deep Metric Learning approach is based on a novel architecture which was designed to learn data representations in an improved way. The solution was inspired by Few-Shot Learning (FSL) and makes use of a teacher-student approach. The teacher model (GEMINI) generates a reduced hypothesis space based on prior knowledge from the labeled 
    
[^35]: 利用分解的动作空间进行非策略评估

    Leveraging Factored Action Spaces for Off-Policy Evaluation. (arXiv:2307.07014v1 [cs.LG])

    [http://arxiv.org/abs/2307.07014](http://arxiv.org/abs/2307.07014)

    本文研究了如何利用分解的动作空间来减轻涉及大型组合动作空间问题的非策略评估（OPE）的高偏差和高方差问题。通过提出一种基于分解动作空间的新型“分解”重要性抽样（IS）估计器系列，我们证明了分解IS估计器具有比非分解版本更小的方差，同时具有零偏差的性质，并通过模拟实验证实了该理论结果。

    

    非策略评估（OPE）旨在估计根据执行序列收集的数据，遵循反事实的一系列动作的效益。然而，现有的OPE估计器在涉及大型组合动作空间的问题中经常表现出高偏差和高方差。我们研究如何利用分解的动作空间来减轻这个问题，即将每个动作表示为来自较小动作空间的独立子动作的组合。这种方法有助于对动作在其效果上的差异进行更精细的分析。在这项工作中，我们提出了一种基于分解动作空间的新型“分解”重要性抽样（IS）估计器系列。在对底层问题结构进行一定的假设的情况下，我们证明了分解IS估计器的方差比其原始非分解版本小，同时保持零偏差的性质。通过模拟，我们经验证实了我们的理论结果，检验了各种假设的有效性。

    Off-policy evaluation (OPE) aims to estimate the benefit of following a counterfactual sequence of actions, given data collected from executed sequences. However, existing OPE estimators often exhibit high bias and high variance in problems involving large, combinatorial action spaces. We investigate how to mitigate this issue using factored action spaces i.e. expressing each action as a combination of independent sub-actions from smaller action spaces. This approach facilitates a finer-grained analysis of how actions differ in their effects. In this work, we propose a new family of "decomposed" importance sampling (IS) estimators based on factored action spaces. Given certain assumptions on the underlying problem structure, we prove that the decomposed IS estimators have less variance than their original non-decomposed versions, while preserving the property of zero bias. Through simulations, we empirically verify our theoretical results, probing the validity of various assumptions. P
    
[^36]: 文本分类任务中经典的带外分布检测方法的基准研究

    Classical Out-of-Distribution Detection Methods Benchmark in Text Classification Tasks. (arXiv:2307.07002v1 [cs.CL])

    [http://arxiv.org/abs/2307.07002](http://arxiv.org/abs/2307.07002)

    本文评估了八种易于集成到现有NLP系统中且不需要额外带外数据或模型修改的带外分布检测方法，并提供了一个完全可复现实验结果的研究环境。分析表明现有的NLP任务中带外分布检测方法对于捕捉所有由不同类型分布转换特征的样本尚不够敏感，这需要未来的工作来开发更有效的方法。

    

    最先进的模型在受控环境下表现良好，但面对带外分布的例子时往往表现出困难，因此带外分布检测成为NLP系统中关键的组成部分。本文着重强调了现有NLP领域带外分布检测方法的局限性。具体来说，我们评估了八种易于集成到现有NLP系统中且不需要额外带外数据或模型修改的带外分布检测方法。我们的贡献之一是提供了一个结构良好的研究环境，可以完全复现实验结果。此外，我们的分析表明现有的NLP任务中带外分布检测方法对于捕捉所有由不同类型分布转换特征的样本尚不够敏感。在领域背景转变和单词随机排列的情况下，测试情景尤其具有挑战性。这突显了未来需要开展更有效的工作来发展带外分布检测方法。

    State-of-the-art models can perform well in controlled environments, but they often struggle when presented with out-of-distribution (OOD) examples, making OOD detection a critical component of NLP systems. In this paper, we focus on highlighting the limitations of existing approaches to OOD detection in NLP. Specifically, we evaluated eight OOD detection methods that are easily integrable into existing NLP systems and require no additional OOD data or model modifications. One of our contributions is providing a well-structured research environment that allows for full reproducibility of the results. Additionally, our analysis shows that existing OOD detection methods for NLP tasks are not yet sufficiently sensitive to capture all samples characterized by various types of distributional shifts. Particularly challenging testing scenarios arise in cases of background shift and randomly shuffled word order within in domain texts. This highlights the need for future work to develop more ef
    
[^37]: 面向特定应用自然语言的IR设计:以交通数据为例的案例研究

    IR Design for Application-Specific Natural Language: A Case Study on Traffic Data. (arXiv:2307.06983v1 [cs.SE])

    [http://arxiv.org/abs/2307.06983](http://arxiv.org/abs/2307.06983)

    该论文提出了一种面向特定应用自然语言的IR设计，可将交通数据统一处理成图形数据格式，大大提高了数据处理性能。

    

    在交通行业的软件应用领域，由于易于使用和其他各种好处，领域专用语言(DSLs)已经广泛应用。随着计算机性能的不断提升和大规模模型的快速发展，使用自然语言进行编程的可能性在特定应用中已经出现，被称为应用特定自然语言(ASNL)。ASNL具有更大的灵活性和自由度，从而导致解析的计算复杂度增加，处理性能降低。为了解决这个问题，我们的论文提出了一种针对ASNL的中间表示(IR)的设计，可以将交通数据统一处理成图形数据格式，提高数据处理性能。实验比较表明，在标准数据查询操作中，我们提出的IR设计可以实现超过四十倍的速度提升，与直接使用ASNL进行处理相比。

    In the realm of software applications in the transportation industry, Domain-Specific Languages (DSLs) have enjoyed widespread adoption due to their ease of use and various other benefits. With the ceaseless progress in computer performance and the rapid development of large-scale models, the possibility of programming using natural language in specified applications - referred to as Application-Specific Natural Language (ASNL) - has emerged. ASNL exhibits greater flexibility and freedom, which, in turn, leads to an increase in computational complexity for parsing and a decrease in processing performance. To tackle this issue, our paper advances a design for an intermediate representation (IR) that caters to ASNL and can uniformly process transportation data into graph data format, improving data processing performance. Experimental comparisons reveal that in standard data query operations, our proposed IR design can achieve a speed improvement of over forty times compared to direct us
    
[^38]: 实践中的短布尔公式作为解释

    Short Boolean Formulas as Explanations in Practice. (arXiv:2307.06971v1 [cs.LO])

    [http://arxiv.org/abs/2307.06971](http://arxiv.org/abs/2307.06971)

    本论文研究了基于一元关系的数据模型的短布尔公式解释的可行性，提出了对期望错误的定量界限，并展示了在三个具体数据集上的实际应用。通过限制公式长度，可以获得避免过拟合且准确且易于理解的解释。

    

    我们研究了基于一元关系的数据模型中通过短布尔公式进行解释的可行性。作为长度为k的解释，我们采用一个长度为k的布尔公式，该公式在解释目标属性方面的错误最小化。我们首先为这种情况提供了新颖的期望错误的定量界限。然后，我们通过研究三个具体的数据集来演示该设置在实践中的运作方式。在每种情况下，我们使用Answer Set Programming中的编码计算不同长度的解释公式。我们得到的最准确的公式在相同的数据集上实现了与其他方法类似的错误。然而，由于过拟合的原因，这些公式不一定是理想的解释，因此我们使用交叉验证来确定合适的解释长度。通过限制为更短的公式，我们得到的解释不仅避免了过拟合，而且依然相当准确，并且重要的是，易于人类解释。

    We investigate explainability via short Boolean formulas in the data model based on unary relations. As an explanation of length k, we take a Boolean formula of length k that minimizes the error with respect to the target attribute to be explained. We first provide novel quantitative bounds for the expected error in this scenario. We then also demonstrate how the setting works in practice by studying three concrete data sets. In each case, we calculate explanation formulas of different lengths using an encoding in Answer Set Programming. The most accurate formulas we obtain achieve errors similar to other methods on the same data sets. However, due to overfitting, these formulas are not necessarily ideal explanations, so we use cross validation to identify a suitable length for explanations. By limiting to shorter formulas, we obtain explanations that avoid overfitting but are still reasonably accurate and also, importantly, human interpretable.
    
[^39]: 机器学习辅助模式识别算法用于估计熔融沉积模式聚乳酸酸（PLA）试样的极限抗拉强度

    Machine Learning-Assisted Pattern Recognition Algorithms for Estimating Ultimate Tensile Strength in Fused Deposition Modeled Polylactic Acid Specimens. (arXiv:2307.06970v1 [cs.LG])

    [http://arxiv.org/abs/2307.06970](http://arxiv.org/abs/2307.06970)

    本研究使用机器学习算法估计了采用FDM工艺制造的PLA试样的极限抗拉强度（UTS），结果表明KNN算法优于其他算法，在区分不同UTS类别方面表现出更好的效果。

    

    本研究探讨了使用监督式机器学习算法来估计采用熔融沉积模型（FDM）工艺制造的聚乳酸酸（PLA）试样的极限抗拉强度（UTS）。总共制备了31个PLA试样，其中填充百分比、层高、打印速度和挤出温度作为输入参数。主要目标是评估四种不同监督分类算法，分别是逻辑回归分类、梯度提升分类、决策树和K近邻，在预测试样UTS方面的准确性和效果。结果显示，决策树和K近邻算法的F1分数均为0.71，但KNN算法的曲线下面积（AUC）分数更高，达到0.79，优于其他算法。这表明KNN算法在区分两类极限抗拉强度方面具有较强的能力。

    In this study, we investigate the application of supervised machine learning algorithms for estimating the Ultimate Tensile Strength (UTS) of Polylactic Acid (PLA) specimens fabricated using the Fused Deposition Modeling (FDM) process. A total of 31 PLA specimens were prepared, with Infill Percentage, Layer Height, Print Speed, and Extrusion Temperature serving as input parameters. The primary objective was to assess the accuracy and effectiveness of four distinct supervised classification algorithms, namely Logistic Classification, Gradient Boosting Classification, Decision Tree, and K-Nearest Neighbor, in predicting the UTS of the specimens. The results revealed that while the Decision Tree and K-Nearest Neighbor algorithms both achieved an F1 score of 0.71, the KNN algorithm exhibited a higher Area Under the Curve (AUC) score of 0.79, outperforming the other algorithms. This demonstrates the superior ability of the KNN algorithm in differentiating between the two classes of ultimate
    
[^40]: 任务无关的可解释人工智能是个神话吗？

    Is Task-Agnostic Explainable AI a Myth?. (arXiv:2307.06963v1 [cs.AI])

    [http://arxiv.org/abs/2307.06963](http://arxiv.org/abs/2307.06963)

    我们提出了一个框架来统一当代可解释人工智能的挑战，指出虽然XAI方法为模型提供了有用的输出，但研究人员和决策者应注意它们的限制，需要在该领域有一个概念突破以解决XAI方法和应用任务之间的兼容性挑战。

    

    我们的工作提供了一个框架，用于统一当代可解释人工智能(XAI)的挑战。我们证明了虽然XAI方法为机器学习模型提供了补充和潜在有用的输出，研究人员和决策者应该注意它们的概念和技术限制，这经常导致这些方法本身成为黑盒子。我们研究了三个XAI研究方向，涵盖图像、文本和图形数据，包括显著性、注意力和图形解释器。尽管所提及的案例的上下文和时间跨度各不相同，但同样的持续阻碍出现了，突显出在该领域中解决XAI方法和应用任务之间兼容性挑战的概念突破的需求。

    Our work serves as a framework for unifying the challenges of contemporary explainable AI (XAI). We demonstrate that while XAI methods provide supplementary and potentially useful output for machine learning models, researchers and decision-makers should be mindful of their conceptual and technical limitations, which frequently result in these methods themselves becoming black boxes. We examine three XAI research avenues spanning image, textual, and graph data, covering saliency, attention, and graph-type explainers. Despite the varying contexts and timeframes of the mentioned cases, the same persistent roadblocks emerge, highlighting the need for a conceptual breakthrough in the field to address the challenge of compatibility between XAI methods and application tasks.
    
[^41]: 复制就是你所需的。

    Copy Is All You Need. (arXiv:2307.06962v1 [cs.CL])

    [http://arxiv.org/abs/2307.06962](http://arxiv.org/abs/2307.06962)

    本文将文本生成定义为从现有文本集合中逐步复制文本片段，并通过复制和粘贴操作来实现生成，相比传统的顺序选择单词生成的模型，在自动和人工评估中取得了更好的生成质量，并且推理效率与基于标记的自回归模型相当。

    

    主导的文本生成模型通过顺序选择来自固定词汇表的单词来组成输出。在本文中，我们将文本生成定义为从现有文本集合中逐步复制文本片段（例如单词或短语）。我们使用高效的向量搜索工具包计算有意义的文本片段的上下文表示并对其进行索引。然后，文本生成的任务被分解为一系列的复制和粘贴操作：在每个时间步骤，我们从文本集合中寻找合适的文本片段，而不是从独立的词汇表中选择。在标准语言建模基准测试（WikiText-103）上的实验表明，我们的方法在自动和人工评估中都实现了更好的生成质量。此外，由于减少了解码步骤，我们的方法的推理效率与基于标记的自回归模型相当。我们还展示了我们的方法通过简单地切换到不同领域，可以实现有效的领域自适应。

    The dominant text generation models compose the output by sequentially selecting words from a fixed vocabulary. In this paper, we formulate text generation as progressively copying text segments (e.g., words or phrases) from an existing text collection. We compute the contextualized representations of meaningful text segments and index them using efficient vector search toolkits. The task of text generation is then decomposed into a series of copy-and-paste operations: at each time step, we seek suitable text spans from the text collection rather than selecting from a standalone vocabulary. Experiments on the standard language modeling benchmark (WikiText-103) show that our approach achieves better generation quality according to both automatic and human evaluations. Besides, its inference efficiency is comparable to token-level autoregressive models thanks to the reduction of decoding steps. We also show that our approach allows for effective domain adaptation by simply switching to d
    
[^42]: ACTI在EVALITA 2023中的综述：阴谋论辨识任务概述

    ACTI at EVALITA 2023: Overview of the Conspiracy Theory Identification Task. (arXiv:2307.06954v1 [cs.CL])

    [http://arxiv.org/abs/2307.06954](http://arxiv.org/abs/2307.06954)

    ACTI在EVALITA 2023中的阴谋论辨识任务共有15支团队参与，通过使用大型语言模型判断阴谋内容和分类，得出了关于利用这些模型抵制在在线平台传播错误信息的结论。

    

    阴谋论辨识任务是Evalita 2023首次提出的新共享任务。ACTI挑战仅基于Telegram上的阴谋频道评论，分为两个子任务：(i) 阴谋内容分类：辨识阴谋内容和(ii) 阴谋类别分类：针对特定阴谋理论分类。共有15支团队参与了该任务，总共提交了81个结果。我们说明了基于大型语言模型的最佳方法。最后，我们得出了关于利用这些模型来抵制在在线平台上传播错误信息的结论。

    Conspiracy Theory Identication task is a new shared task proposed for the first time at the Evalita 2023. The ACTI challenge, based exclusively on comments published on conspiratorial channels of telegram, is divided into two subtasks: (i) Conspiratorial Content Classification: identifying conspiratorial content and (ii) Conspiratorial Category Classification about specific conspiracy theory classification. A total of fifteen teams participated in the task for a total of 81 submissions. We illustrate the best performing approaches were based on the utilization of large language models. We finally draw conclusions about the utilization of these models for counteracting the spreading of misinformation in online platforms.
    
[^43]: 人工智能在全球气候合作2023竞赛论文集

    AI For Global Climate Cooperation 2023 Competition Proceedings. (arXiv:2307.06951v1 [cs.AI])

    [http://arxiv.org/abs/2307.06951](http://arxiv.org/abs/2307.06951)

    国际社会必须合作应对气候变化，通过结合人工智能和气候经济模拟，设计促进和激励合作的国际框架，解决协议遵守、政策目标实现和持续承诺等挑战。

    

    国际社会必须合作应对气候变化并保持经济增长。然而，由于没有全球权威机构能确保国际气候协议的遵守，合作很难实现。将人工智能与气候经济模拟相结合，提供了设计促进和激励合作的国际框架的有希望的解决方案，包括谈判协议和气候协议。此外，这些框架还应考虑到气候经济动态和战略行为，以实现政策目标的实现和持续承诺。这些挑战需要跨机器学习、经济学、气候科学、法律、政策、伦理学等领域的跨学科方法。为了实现这一目标，我们组织了AI for Global Climate Cooperation（全球气候合作人工智能）竞赛，参赛团队提交了基于（修改的）RICE-N的国际框架的提案和分析。

    The international community must collaborate to mitigate climate change and sustain economic growth. However, collaboration is hard to achieve, partly because no global authority can ensure compliance with international climate agreements. Combining AI with climate-economic simulations offers a promising solution to design international frameworks, including negotiation protocols and climate agreements, that promote and incentivize collaboration. In addition, these frameworks should also have policy goals fulfillment, and sustained commitment, taking into account climate-economic dynamics and strategic behaviors. These challenges require an interdisciplinary approach across machine learning, economics, climate science, law, policy, ethics, and other fields.  Towards this objective, we organized AI for Global Climate Cooperation, a Mila competition in which teams submitted proposals and analyses of international frameworks, based on (modifications of) RICE-N, an AI-driven integrated ass
    
[^44]: 迈向工程中先验知识整合的机器学习路径

    Pathway toward prior knowledge-integrated machine learning in engineering. (arXiv:2307.06950v1 [cs.AI])

    [http://arxiv.org/abs/2307.06950](http://arxiv.org/abs/2307.06950)

    本研究提出了一种整合先验知识的机器学习方法，对工程领域中的信息不确定性进行了检查，并探索了以三层知识整合的机器学习范式进行知识分解。这种方法平衡了整体论和还原论观点。

    

    尽管数字化趋势和数据量激增，但基于第一原理的模型（也称为逻辑驱动、基于物理、基于规则或基于知识的模型）与数据驱动方法存在并行存在，反映了关于符号主义与连接主义的持续AI辩论。在数据驱动过程中传输和利用领域知识的过程开发研究很少见。本研究强调将多学科领域专业知识整合到机器知识化的数据驱动过程中的努力和主流趋势，以两种方式组织：检查知识表示中的信息不确定性来源，并探索以三层知识整合的机器学习范式进行知识分解。这种方法平衡了工程领域的整体论和还原论观点。

    Despite the digitalization trend and data volume surge, first-principles models (also known as logic-driven, physics-based, rule-based, or knowledge-based models) and data-driven approaches have existed in parallel, mirroring the ongoing AI debate on symbolism versus connectionism. Research for process development to integrate both sides to transfer and utilize domain knowledge in the data-driven process is rare. This study emphasizes efforts and prevailing trends to integrate multidisciplinary domain professions into machine acknowledgeable, data-driven processes in a two-fold organization: examining information uncertainty sources in knowledge representation and exploring knowledge decomposition with a three-tier knowledge-integrated machine learning paradigm. This approach balances holist and reductionist perspectives in the engineering domain.
    
[^45]: 通过潜在空间分解揭示独特的概念向量

    Uncovering Unique Concept Vectors through Latent Space Decomposition. (arXiv:2307.06913v1 [cs.LG])

    [http://arxiv.org/abs/2307.06913](http://arxiv.org/abs/2307.06913)

    通过潜在空间分解和无监督聚类，我们提出了一种自动揭示深度学习模型学习到的概念向量的方法，这些概念向量与模型预测相关且具有语义的独特概念，并且在实验中表明这些概念对人类来说易于理解和与任务相关。

    

    解释深度学习模型的内部工作对于建立信任和确保模型安全至关重要。基于概念的解释已经成为一种更易解释的方法，比如像素显著性等特征归因估计。然而，定义解释分析的概念会受到用户对概念期望的偏差影响。为了解决这个问题，我们提出了一种新的事后无监督方法，可以自动揭示深度模型在训练期间学习到的概念。通过分解一个层的潜在空间成奇异向量，并通过无监督聚类对其进行精炼，我们揭示了与模型预测相关的高方差方向上的概念向量，并指向语义上独特的概念。我们广泛的实验结果显示，我们的大部分概念对人类来说是易于理解的，具有一致性，并与所需任务相关。此外，我们还展示了...

    Interpreting the inner workings of deep learning models is crucial for establishing trust and ensuring model safety. Concept-based explanations have emerged as a superior approach that is more interpretable than feature attribution estimates such as pixel saliency. However, defining the concepts for the interpretability analysis biases the explanations by the user's expectations on the concepts. To address this, we propose a novel post-hoc unsupervised method that automatically uncovers the concepts learned by deep models during training. By decomposing the latent space of a layer in singular vectors and refining them by unsupervised clustering, we uncover concept vectors aligned with directions of high variance that are relevant to the model prediction, and that point to semantically distinct concepts. Our extensive experiments reveal that the majority of our concepts are readily understandable to humans, exhibit coherency, and bear relevance to the task at hand. Moreover, we showcase
    
[^46]: 通过集成深度强化学习的混合控制策略实现人工胰腺

    Hybrid Control Policy for Artificial Pancreas via Ensemble Deep Reinforcement Learning. (arXiv:2307.06501v1 [cs.AI])

    [http://arxiv.org/abs/2307.06501](http://arxiv.org/abs/2307.06501)

    本研究提出了一种名为HyCPAP的混合控制策略，通过结合模型预测控制和集成深度强化学习，并充分利用它们各自的优势，以解决人工胰腺的复杂生理过程、延迟胰岛素反应和不准确血糖测量等挑战。

    

    目标：人工胰腺(AP)在实现1型糖尿病患者闭环血糖控制方面显示出有希望的潜力。然而，由于复杂的生理过程、延迟的胰岛素反应和不准确的血糖测量，设计一种有效的AP控制策略仍然具有挑战性。虽然模型预测控制(MPC)通过动态模型和安全约束提供了安全性和稳定性，但其缺乏个性化，并且受到未宣布的饮食影响。相反，深度强化学习(DRL)提供了个性化和自适应策略，但面临分布偏移和大量数据需求的挑战。方法：我们提出了一种混合控制策略，即HyCPAP，来应对上述挑战。HyCPAP将MPC策略与集成DRL策略相结合，充分利用两种策略的优势，同时弥补各自的局限性。

    Objective: The artificial pancreas (AP) has shown promising potential in achieving closed-loop glucose control for individuals with type 1 diabetes mellitus (T1DM). However, designing an effective control policy for the AP remains challenging due to the complex physiological processes, delayed insulin response, and inaccurate glucose measurements. While model predictive control (MPC) offers safety and stability through the dynamic model and safety constraints, it lacks individualization and is adversely affected by unannounced meals. Conversely, deep reinforcement learning (DRL) provides personalized and adaptive strategies but faces challenges with distribution shifts and substantial data requirements. Methods: We propose a hybrid control policy for the artificial pancreas (HyCPAP) to address the above challenges. HyCPAP combines an MPC policy with an ensemble DRL policy, leveraging the strengths of both policies while compensating for their respective limitations. To facilitate faste
    
[^47]: 视图袋：一种基于外观的用于3D重建下一个最佳视图规划的方法

    Bag of Views: An Appearance-based Approach to Next-Best-View Planning for 3D Reconstruction. (arXiv:2307.05832v1 [cs.CV])

    [http://arxiv.org/abs/2307.05832](http://arxiv.org/abs/2307.05832)

    这篇论文提出了一种基于外观的方法，通过视图袋（Bag-of-Views）模型来对捕获的视图进行离线数据集细化和在线下一个最佳视图（NBV）规划应用分配效用，以实现3D重建的任务。同时，还开发了视图规划工具箱（VPT）。

    

    基于无人机的智能数据采集用于3D重建和基础设施监测，由于图像处理和深度学习技术的最新进展，正经历着越来越多的兴趣。视图规划是这个任务的重要部分，它决定了信息捕获策略，并且严重影响从捕获的数据生成的3D模型的质量。最近的方法使用先前的知识或目标的部分重建来实现主动重建的视图规划；前一种方法对于复杂或新识别的目标构成了挑战，而后者计算开销很大。在这项工作中，我们提出了视图袋（BoV），这是一种完全基于外观的模型，用于为离线数据集的细化和在线下一个最佳视图（NBV）规划应用分配效用，以实现3D重建的任务。通过这个工作，我们还开发了视图规划工具箱（VPT），

    UAV-based intelligent data acquisition for 3D reconstruction and monitoring of infrastructure has been experiencing an increasing surge of interest due to the recent advancements in image processing and deep learning-based techniques. View planning is an essential part of this task that dictates the information capture strategy and heavily impacts the quality of the 3D model generated from the captured data. Recent methods have used prior knowledge or partial reconstruction of the target to accomplish view planning for active reconstruction; the former approach poses a challenge for complex or newly identified targets while the latter is computationally expensive. In this work, we present Bag-of-Views (BoV), a fully appearance-based model used to assign utility to the captured views for both offline dataset refinement and online next-best-view (NBV) planning applications targeting the task of 3D reconstruction. With this contribution, we also developed the View Planning Toolbox (VPT), 
    
[^48]: 在大型语言模型中释放认知协同：通过多人格自我协作实现任务解决代理

    Unleashing Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration. (arXiv:2307.05300v1 [cs.AI])

    [http://arxiv.org/abs/2307.05300](http://arxiv.org/abs/2307.05300)

    本论文提出了单人表现提示（SPP）的概念，通过与多个角色进行多轮自我协作，将单个语言模型转化为认知协同者，从而增强其在复杂任务中的问题解决能力和整体性能。

    

    人类智慧依赖于认知协同的概念，即在不同认知过程之间进行协作和信息整合，以获得比个体认知过程更出色的结果。尽管大型语言模型（LLM）作为通用任务解决代理表现出了令人期待的性能，但它们在需要丰富领域知识和复杂推理的任务上仍然面临困难。在这项工作中，我们提出了单人表现提示（SPP）的概念，通过与多个角色进行多轮自我协作，将单个LLM转化为认知协同者。认知协同者指的是一个智能代理，与多个智慧合作，结合他们的个体优势和知识，从而增强复杂任务的问题解决能力和整体性能。通过根据任务输入动态识别和模拟不同的角色，SPP释放了LLM中认知协同的潜力。

    Human intelligence thrives on the concept of cognitive synergy, where collaboration and information integration among different cognitive processes yield superior outcomes compared to individual cognitive processes in isolation. Although Large Language Models (LLMs) have demonstrated promising performance as general task-solving agents, they still struggle with tasks that require intensive domain knowledge and complex reasoning. In this work, we propose Solo Performance Prompting (SPP), which transforms a single LLM into a cognitive synergist by engaging in multi-turn self-collaboration with multiple personas. A cognitive synergist refers to an intelligent agent that collaborates with multiple minds, combining their individual strengths and knowledge, to enhance problem-solving and overall performance in complex tasks. By dynamically identifying and simulating different personas based on task inputs, SPP unleashes the potential of cognitive synergy in LLMs. We have discovered that assi
    
[^49]: 利用人类好奇心的网络理论进行内在驱动的图探索

    Intrinsically motivated graph exploration using network theories of human curiosity. (arXiv:2307.04962v1 [cs.LG])

    [http://arxiv.org/abs/2307.04962](http://arxiv.org/abs/2307.04962)

    在这项工作中，我们通过应用人类好奇心的两个理论，发展了一种内在驱动的图探索方法。我们利用图神经网络的强化学习将拓扑特征作为奖励，从而实现了对图结构数据的探索。在多类合成生成图上进行的实验证明，我们的方法不仅可以推广到更大的环境，还可以进行更长的探索步行。同时，我们的方法比传统的贪婪评估方法更高效。

    

    内在驱动的探索在强化学习中已被证明具有用途，即使没有额外的外在奖励。当环境自然表示为图时，如何最好地引导探索仍是一个未解决的问题。在这项工作中，我们提出了一种新的方法，通过人类好奇心的两个理论：信息差理论和压缩进展理论，来激励对图结构数据进行探索。这些理论将好奇心视为对环境中访问节点所引发的子图的拓扑特征进行优化的内在动机。我们将这些提出的特征作为基于图神经网络的强化学习的奖励。在多个类别的合成生成图上，我们发现训练代理可以推广到更大的环境和比训练过程中更长的探索性步行。我们的方法的计算效率高于相关拓扑属性的贪婪评估。所提出的内在动机产生的奖励在多类合成生成图生成上推广良好，并且在训练期间能够在更大的环境中进行更长的探索步行。

    Intrinsically motivated exploration has proven useful for reinforcement learning, even without additional extrinsic rewards. When the environment is naturally represented as a graph, how to guide exploration best remains an open question. In this work, we propose a novel approach for exploring graph-structured data motivated by two theories of human curiosity: the information gap theory and the compression progress theory. The theories view curiosity as an intrinsic motivation to optimize for topological features of subgraphs induced by the visited nodes in the environment. We use these proposed features as rewards for graph neural-network-based reinforcement learning. On multiple classes of synthetically generated graphs, we find that trained agents generalize to larger environments and to longer exploratory walks than are seen during training. Our method computes more efficiently than the greedy evaluation of the relevant topological properties. The proposed intrinsic motivations bea
    
[^50]: 关于形式特征归因及其近似方法

    On Formal Feature Attribution and Its Approximation. (arXiv:2307.03380v1 [cs.AI])

    [http://arxiv.org/abs/2307.03380](http://arxiv.org/abs/2307.03380)

    这篇论文研究了解释性人工智能（XAI）中的形式特征归因方法及其近似方法。现有的特征选择和归因方法存在一些问题，而形式化的XAI方法虽然是一个有希望的解决方案，但仍存在一些限制。

    

    近年来，人工智能（AI）算法和机器学习（ML）模型得到了广泛应用。尽管取得了巨大成功，但ML模型脆弱性，公平性以及解释性的缺乏等重要问题需要积极发展可解释的人工智能（XAI）和形式化的ML模型验证。XAI的两个主要研究方向包括特征选择方法（例如，Anchors）和特征归因技术（例如，LIME和SHAP）。尽管有希望，但大多数现有的特征选择和归因方法都容易出现一系列关键问题，包括解释不正确和超出分布采样。近期一种形式化的XAI方法（FXAI）虽然作为以上方法的替代品并避免了这些问题，但仍存在一些限制。例如，除了可扩展性限制外，这种形式化方法无法解决特征归因问题。

    Recent years have witnessed the widespread use of artificial intelligence (AI) algorithms and machine learning (ML) models. Despite their tremendous success, a number of vital problems like ML model brittleness, their fairness, and the lack of interpretability warrant the need for the active developments in explainable artificial intelligence (XAI) and formal ML model verification. The two major lines of work in XAI include feature selection methods, e.g. Anchors, and feature attribution techniques, e.g. LIME and SHAP. Despite their promise, most of the existing feature selection and attribution approaches are susceptible to a range of critical issues, including explanation unsoundness and out-of-distribution sampling. A recent formal approach to XAI (FXAI) although serving as an alternative to the above and free of these issues suffers from a few other limitations. For instance and besides the scalability limitation, the formal approach is unable to tackle the feature attribution prob
    
[^51]: 利用扁平化到宽化方法进行少样本持续学习

    Few-Shot Continual Learning via Flat-to-Wide Approaches. (arXiv:2306.14369v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.14369](http://arxiv.org/abs/2306.14369)

    本文提出了一种少样本持续学习方法，名为FLat-tO-WidE AppRoach (FLOWER)，通过寻找扁平化宽化极小值的过程来解决灾难性遗忘问题，利用球体生成器概念进行数据增强方法来克服数据稀缺性问题。在小型基础任务中，FLOWER表现出显著改进的性能。

    

    现有的持续学习方法在训练过程中需要大量的样本。由于过拟合问题，这些方法在拥有有限样本的许多实际问题中是不现实的。本文提出了一种少样本持续学习方法，称为FLat-tO-WidE AppRoach (FLOWER)，其中提出了一种寻找扁平化宽化极小值的扁平化到宽化学习过程，以解决灾难性遗忘问题。通过使用球体生成器概念进行数据增强方法来克服数据稀缺性问题，将采样空间限制在最小外接球内。我们的数值研究表明，FLOWER相比先前的方法在小型基础任务中实现了显著改进的性能。为了进一步研究，FLOWER的源代码，竞争算法和实验日志公开共享在\url{https://github.com/anwarmaxsum/FLOWER}。

    Existing approaches on continual learning call for a lot of samples in their training processes. Such approaches are impractical for many real-world problems having limited samples because of the overfitting problem. This paper proposes a few-shot continual learning approach, termed FLat-tO-WidE AppRoach (FLOWER), where a flat-to-wide learning process finding the flat-wide minima is proposed to address the catastrophic forgetting problem. The issue of data scarcity is overcome with a data augmentation approach making use of a ball generator concept to restrict the sampling space into the smallest enclosing ball. Our numerical studies demonstrate the advantage of FLOWER achieving significantly improved performances over prior arts notably in the small base tasks. For further study, source codes of FLOWER, competitor algorithms and experimental logs are shared publicly in \url{https://github.com/anwarmaxsum/FLOWER}.
    
[^52]: 基于HRNet的康复监测系统

    A HRNet-based Rehabilitation Monitoring System. (arXiv:2306.10756v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2306.10756](http://arxiv.org/abs/2306.10756)

    该论文介绍了一种基于HRNet的康复监测系统，旨在通过智能手机进行康复训练的管理。患者可以通过系统进行应用程序来进行训练，而治疗师可以通过服务器端进行进度的监测。

    

    康复治疗有助于治愈轻微的体育和职业伤害。传统的康复过程中，治疗师会指定某些动作供患者在医院访问之间执行，这将依赖于患者正确地记住动作和执行计划。不幸的是，许多患者会忘记执行动作或无法详细回想动作。因此，康复治疗受到阻碍，或者在最坏的情况下，患者可能会因执行不正确的动作而遭受额外的伤害。为了解决这些问题，我们提出了一种基于HRNet的康复监测系统，它可以通过患者的智能手机提醒患者何时执行动作并展示动作供患者跟随。此外，它还帮助治疗师监测患者的康复进展。我们的系统由一款iOS应用程序和几个服务器组件组成。该应用程序负责显示...

    The rehabilitation treatment helps to heal minor sports and occupational injuries. In a traditional rehabilitation process, a therapist will assign certain actions to a patient to perform in between hospital visits, and it will rely on the patient to remember actions correctly and the schedule to perform them. Unfortunately, many patients forget to perform actions or fail to recall actions in detail. As a consequence, the rehabilitation treatment is hampered or, in the worst case, the patient may suffer from additional injury caused by performing incorrect actions. To resolve these issues, we propose a HRNet-based rehabilitation monitoring system, which can remind a patient when to perform the actions and display the actions for the patient to follow via the patient's smartphone. In addition, it helps the therapist to monitor the progress of the rehabilitation for the patient. Our system consists of an iOS app and several components at the server side. The app is in charge of displayin
    
[^53]: Dink-Net: 大规模图形神经聚类方法

    Dink-Net: Neural Clustering on Large Graphs. (arXiv:2305.18405v1 [cs.LG])

    [http://arxiv.org/abs/2305.18405](http://arxiv.org/abs/2305.18405)

    Dink-Net是一个可扩展的大规模图形神经聚类方法，该方法利用了膨胀和收缩的思想来处理百万节点的大图，并在各种基准数据集上优于现有的最先进方法。

    

    近年来，深度图聚类通过深度神经网络将图形的节点进行分组取得了很大的进展，但现有方法无法处理百万节点的大图。为了解决这个问题，我们提出了一种可扩展的Dink-Net深度图聚类方法，利用了膨胀和收缩的思想。首先，通过区分带增强的跟不带增强的节点，自我监督方式学习表示形式。同时，将聚类中心初始化为可学习的神经网络参数。随后，通过对抗性方式最小化提出的集群膨胀损失和集群收缩损失，优化聚类分布。通过这些设置，我们将表示学习和聚类优化两个步骤统一为一个端到端框架，引导网络学习聚类友好的特征。此外，Dink-Net能很好地扩展到大规模的图形上，因为设计的膨胀收缩操作可以有效地减少计算和内存消耗。实验结果表明，Dink-Net在处理百万节点图形的各种基准数据集上优于现有的最先进方法，证明了该方法在大图聚类中的可扩展性和有效性。

    Deep graph clustering, which aims to group the nodes of a graph into disjoint clusters with deep neural networks, has achieved promising progress in recent years. However, the existing methods fail to scale to the large graph with million nodes. To solve this problem, a scalable deep graph clustering method (Dink-Net) is proposed with the idea of dilation and shrink. Firstly, by discriminating nodes, whether being corrupted by augmentations, representations are learned in a self-supervised manner. Meanwhile, the cluster centres are initialized as learnable neural parameters. Subsequently, the clustering distribution is optimized by minimizing the proposed cluster dilation loss and cluster shrink loss in an adversarial manner. By these settings, we unify the two-step clustering, i.e., representation learning and clustering optimization, into an end-to-end framework, guiding the network to learn clustering-friendly features. Besides, Dink-Net scales well to large graphs since the designe
    
[^54]: 神经智能中的注意力模式

    Attention Schema in Neural Agents. (arXiv:2305.17375v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2305.17375](http://arxiv.org/abs/2305.17375)

    本文研究了神经智能中的注意力模式，并提出了注意力模式理论（AST）。作者发现将AS实现为一种循环内部控制的智能体效果最佳，这一理论为应用与改进神经智能提供了新思路。

    

    注意力已经成为深度学习架构中的常见要素。它通过加入动态信息选择，支持静态的权重选择。同样地，我们可以想象在注意力之上构建一个更高阶的信息过滤器：注意力模式（AS）。也就是说，一个描述性和预测性的注意力模型。在认知神经科学中，注意力模式理论（AST）支持这种区分注意力和AS的想法。该理论的一个重要预测是，一个智能体可以使用自己的AS来推断其他智能体的注意状态，从而增强与其他智能体的协调。因此，多智能体强化学习是一个实验测试AST有效性的理想场景。我们探讨了注意力和AS相互作用的不同方式，初步结果表明，将AS实现为一种循环内部控制的智能体效果最佳。总体而言，这些实验为理解以及改进神经智能中的注意力模式提供了新的思路。

    Attention has become a common ingredient in deep learning architectures. It adds a dynamical selection of information on top of the static selection of information supported by weights. In the same way, we can imagine a higher-order informational filter built on top of attention: an Attention Schema (AS), namely, a descriptive and predictive model of attention. In cognitive neuroscience, Attention Schema Theory (AST) supports this idea of distinguishing attention from AS. A strong prediction of this theory is that an agent can use its own AS to also infer the states of other agents' attention and consequently enhance coordination with other agents. As such, multi-agent reinforcement learning would be an ideal setting to experimentally test the validity of AST. We explore different ways in which attention and AS interact with each other. Our preliminary results indicate that agents that implement the AS as a recurrent internal control achieve the best performance. In general, these expl
    
[^55]: 我寻觅一个隐喻：大语言模型和扩散模型共创视觉隐喻

    I Spy a Metaphor: Large Language Models and Diffusion Models Co-Create Visual Metaphors. (arXiv:2305.14724v1 [cs.CL])

    [http://arxiv.org/abs/2305.14724](http://arxiv.org/abs/2305.14724)

    本论文提出一个新的任务——从语言隐喻生成视觉隐喻，并且基于大语言模型和扩散模型之间的协作，成功地实现了共创出具有视觉冲击力和语义含义的隐喻。

    

    视觉隐喻是通过图像来说服或传达创意想法的强大修辞手法。与语言隐喻类似，它们通过符号主义和符号的并置隐含地传达含义。我们提出了一个从语言隐喻生成视觉隐喻的新任务。这对于基于扩散的文本到图像模型（如DALL $\cdot$ E 2）来说是一项具有挑战性的任务，因为它需要模拟隐含含义和组合性。我们提出了通过大型语言模型（LLMs）和扩散模型之间的协作来解决这个问题：采用以“串联思维”为提示的Instruct GPT-3（davinci-002）生成代表语言隐喻的视觉阐述的文本，其中包含隐含含义和相关对象，然后将其用作扩散的文本到图像模型的输入。通过人机协作框架，人们与LLM和表现最佳的扩散模型进行交互，创建一个高质量的隐喻和它们的视觉对应的数据集。我们的实验表明，LLMs和扩散模型之间的协作可以共同创造出具有视觉冲击力和语义含义的隐喻。

    Visual metaphors are powerful rhetorical devices used to persuade or communicate creative ideas through images. Similar to linguistic metaphors, they convey meaning implicitly through symbolism and juxtaposition of the symbols. We propose a new task of generating visual metaphors from linguistic metaphors. This is a challenging task for diffusion-based text-to-image models, such as DALL$\cdot$E 2, since it requires the ability to model implicit meaning and compositionality. We propose to solve the task through the collaboration between Large Language Models (LLMs) and Diffusion Models: Instruct GPT-3 (davinci-002) with Chain-of-Thought prompting generates text that represents a visual elaboration of the linguistic metaphor containing the implicit meaning and relevant objects, which is then used as input to the diffusion-based text-to-image models.Using a human-AI collaboration framework, where humans interact both with the LLM and the top-performing diffusion model, we create a high-qu
    
[^56]: ARBEx：用于鲁棒性面部表情学习的关注特征提取与可靠性平衡框架

    ARBEx: Attentive Feature Extraction with Reliability Balancing for Robust Facial Expression Learning. (arXiv:2305.01486v1 [cs.CV])

    [http://arxiv.org/abs/2305.01486](http://arxiv.org/abs/2305.01486)

    本论文提出了一个名为ARBEx的框架，它采用了可靠性平衡方法来应对面部表情学习任务中的数据偏差和不确定性。该框架还引入了可学习的锚点和多头自注意机制，并在多个公共数据集上取得了有效性验证。

    

    本论文提出了一个名为ARBEx的框架，它是由Vision Transformer驱动的新型关注特征提取框架，带有可靠性平衡，以应对面部表情学习任务中的较差类分布、偏差和不确定性。我们采用了多种数据预处理和精化方法以及基于窗口的交叉关注ViT来充分利用数据。我们还在嵌入空间中引入了可学习的锚点，加上标签分布和多头自注意机制，以通过可靠性平衡优化对弱预测的性能，这是一种提高标签预测韧性的策略。为了确保正确的标签分类并提高模型的区分能力，我们引入了锚损失，鼓励锚点之间的大间隔。另外，多头自注意机制也是可训练的，对于提升在FEL任务中的表现至关重要。最后，我们在多个公共数据集上验证了ARBEx的有效性。

    In this paper, we introduce a framework ARBEx, a novel attentive feature extraction framework driven by Vision Transformer with reliability balancing to cope against poor class distributions, bias, and uncertainty in the facial expression learning (FEL) task. We reinforce several data pre-processing and refinement methods along with a window-based cross-attention ViT to squeeze the best of the data. We also employ learnable anchor points in the embedding space with label distributions and multi-head self-attention mechanism to optimize performance against weak predictions with reliability balancing, which is a strategy that leverages anchor points, attention scores, and confidence values to enhance the resilience of label predictions. To ensure correct label classification and improve the models' discriminative power, we introduce anchor loss, which encourages large margins between anchor points. Additionally, the multi-head self-attention mechanism, which is also trainable, plays an i
    
[^57]: 深度可解释关系强化学习：一种神经符号化方法

    Deep Explainable Relational Reinforcement Learning: A Neuro-Symbolic Approach. (arXiv:2304.08349v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2304.08349](http://arxiv.org/abs/2304.08349)

    本论文提出了一种深度可解释关系强化学习框架，通过将神经和符号世界相结合，利用神经符号化的方法提取出可解释的策略，解决了深度强化学习中不可解释性和处理环境结构变化的困难。

    

    尽管深度强化学习（DRL）取得了许多成功，学习到的策略仍然是不可解释的。此外，由于DRL没有利用符号关系表示，它在处理环境结构变化（如对象数量增加）方面存在困难。另一方面，关系强化学习从符号计划继承了关系表示，以学习可重用的策略。然而，迄今为止，关系强化学习无法扩展并充分利用深度神经网络的能力。我们提出了一种深度可解释关系强化学习（DERRL）框架，它结合了神经和符号世界的优势。通过采用神经符号化方法，DERRL将符号计划中的关系表示和约束与深度学习相结合，提取出可解释的策略。这些策略以逻辑规则的形式解释了每个决策（或动作）的产生过程。通过多个实验，我们展示了DERRL在处理环境结构变化方面的优越性能。

    Despite numerous successes in Deep Reinforcement Learning (DRL), the learned policies are not interpretable. Moreover, since DRL does not exploit symbolic relational representations, it has difficulties in coping with structural changes in its environment (such as increasing the number of objects). Relational Reinforcement Learning, on the other hand, inherits the relational representations from symbolic planning to learn reusable policies. However, it has so far been unable to scale up and exploit the power of deep neural networks. We propose Deep Explainable Relational Reinforcement Learning (DERRL), a framework that exploits the best of both -- neural and symbolic worlds. By resorting to a neuro-symbolic approach, DERRL combines relational representations and constraints from symbolic planning with deep learning to extract interpretable policies. These policies are in the form of logical rules that explain how each decision (or action) is arrived at. Through several experiments, in 
    
[^58]: DiffTAD: 使用Proposal Denoising Diffusion的时间动作检测

    DiffTAD: Temporal Action Detection with Proposal Denoising Diffusion. (arXiv:2303.14863v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2303.14863](http://arxiv.org/abs/2303.14863)

    DiffTAD是一种新的时间动作检测方法，使用Proposal Denoising Diffusion的生成建模视角，并通过正向/噪声过程和反向/去噪过程实现准确的动作提议。

    

    我们提出了一种新的时间动作检测（TAD）的表达形式，即DiffTAD。它采用随机时间提议作为输入，在给定未修剪的长时间视频的情况下能够准确地产生动作提议。这是一种生成建模的视角，与先前的判别学习方式相对立。通过首先将地面真实提议扩散到随机提议（即正向/噪声过程），然后学习逆转噪声过程（即反向/去噪过程）来实现这种能力。具体来说，我们通过在Transformer解码器（如DETR）中引入具有更快收敛速度的时间位置查询设计来建立去噪过程。我们还提出了一种用于推理加速的交叉步选择性调节算法。对ActivityNet和THUMOS进行的广泛评估表明，我们的DiffTAD相比先前的替代方案表现出更高的性能。代码将在https://github.com/sauradip/Di上提供。

    We propose a new formulation of temporal action detection (TAD) with denoising diffusion, DiffTAD in short. Taking as input random temporal proposals, it can yield action proposals accurately given an untrimmed long video. This presents a generative modeling perspective, against previous discriminative learning manners. This capability is achieved by first diffusing the ground-truth proposals to random ones (i.e., the forward/noising process) and then learning to reverse the noising process (i.e., the backward/denoising process). Concretely, we establish the denoising process in the Transformer decoder (e.g., DETR) by introducing a temporal location query design with faster convergence in training. We further propose a cross-step selective conditioning algorithm for inference acceleration. Extensive evaluations on ActivityNet and THUMOS show that our DiffTAD achieves top performance compared to previous art alternatives. The code will be made available at https://github.com/sauradip/Di
    
[^59]: 打破常识：WHOOPS！一个基于合成和组合图像的视觉与语言基准测试

    Breaking Common Sense: WHOOPS! A Vision-and-Language Benchmark of Synthetic and Compositional Images. (arXiv:2303.07274v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2303.07274](http://arxiv.org/abs/2303.07274)

    WHOOPS!是一个新的视觉常识数据集和基准测试，包括了图像字幕、跨模态匹配和视觉问答等若干个任务，引入了解释生成任务，挑战了AI模型识别和解释不合常规的图像的能力。

    

    奇怪、异常和神秘的图像会引起观察者的好奇心，因为它们挑战了常识。我们提出WHOOPS！一个新的视觉常识数据集和基准测试。该数据集由设计师使用Midjourney等公共可用图像生成工具制作，并包含若干个任务。除了图像字幕、跨模态匹配和视觉问答之外，我们还引入了一个困难的解释生成任务，其中模型必须识别并解释给定图像的异常之处。

    Weird, unusual, and uncanny images pique the curiosity of observers because they challenge commonsense. For example, an image released during the 2022 world cup depicts the famous soccer stars Lionel Messi and Cristiano Ronaldo playing chess, which playfully violates our expectation that their competition should occur on the football field. Humans can easily recognize and interpret these unconventional images, but can AI models do the same? We introduce WHOOPS!, a new dataset and benchmark for visual commonsense. The dataset is comprised of purposefully commonsense-defying images created by designers using publicly-available image generation tools like Midjourney. We consider several tasks posed over the dataset. In addition to image captioning, cross-modal matching, and visual question answering, we introduce a difficult explanation generation task, where models must identify and explain why a given image is unusual. Our results show that state-of-the-art models such as GPT3 and BLIP2
    
[^60]: 在3D点云中的开放词汇支撑检测

    Open-Vocabulary Affordance Detection in 3D Point Clouds. (arXiv:2303.02401v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2303.02401](http://arxiv.org/abs/2303.02401)

    本文提出了一种在3D点云中进行无限数量支撑检测的开放词汇支撑检测方法，通过同时学习支撑文本和点特征来利用支撑之间的语义关系，实现了零-shot检测，能够在没有注释示例的情况下检测以前未见到的支撑。实验结果表明，OpenAD在各种设置上表现出优异性能。

    

    支撑检测是一个具有广泛机器人应用的挑战性问题。传统的支撑检测方法局限于预定义的支撑标签，可能限制了智能机器人在复杂和动态环境中的适应性。在本文中，我们提出了开放词汇支撑检测（OpenAD）方法，能够在3D点云中检测无限数量的支撑。通过同时学习支撑文本和点特征，OpenAD成功地利用了支撑之间的语义关系。因此，我们提出的方法实现了零-shot检测，并能够在没有任何注释示例的情况下检测以前未见到的支撑。大量实验结果表明，OpenAD在各种支撑检测设置上有效，并且在性能上超过了其他基线方法。此外，我们还展示了OpenAD在实际中的实用性。

    Affordance detection is a challenging problem with a wide variety of robotic applications. Traditional affordance detection methods are limited to a predefined set of affordance labels, hence potentially restricting the adaptability of intelligent robots in complex and dynamic environments. In this paper, we present the Open-Vocabulary Affordance Detection (OpenAD) method, which is capable of detecting an unbounded number of affordances in 3D point clouds. By simultaneously learning the affordance text and the point feature, OpenAD successfully exploits the semantic relationships between affordances. Therefore, our proposed method enables zero-shot detection and can be able to detect previously unseen affordances without a single annotation example. Intensive experimental results show that OpenAD works effectively on a wide range of affordance detection setups and outperforms other baselines by a large margin. Additionally, we demonstrate the practicality of the proposed OpenAD in real
    
[^61]: DoCoFL：用于跨设备联合学习的下行压缩

    DoCoFL: Downlink Compression for Cross-Device Federated Learning. (arXiv:2302.00543v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.00543](http://arxiv.org/abs/2302.00543)

    本研究提出了DoCoFL，一种用于跨设备联合学习的下行压缩框架，能够在降低双向带宽的同时保持竞争力的准确性。

    

    许多压缩技术已被提出用于减少联合学习训练过程中的通信开销。然而，这些技术通常用于压缩模型更新，而模型更新在训练过程中会逐渐减少。因此，这些方法不适用于跨设备的下行（即从服务器到客户端）压缩，在这种场景下，异构客户端在训练期间可能只出现一次，因此必须下载模型参数。因此，我们提出了DoCoFL——一个新的用于跨设备下行压缩的框架。重要的是，DoCoFL可以无缝地与许多上行压缩方案结合使用，使其适用于双向压缩。通过广泛的评估，我们证明DoCoFL在显著降低双向带宽的同时，实现了与没有任何压缩的基准模型相当的准确性。

    Many compression techniques have been proposed to reduce the communication overhead of Federated Learning training procedures. However, these are typically designed for compressing model updates, which are expected to decay throughout training. As a result, such methods are inapplicable to downlink (i.e., from the parameter server to clients) compression in the cross-device setting, where heterogeneous clients $\textit{may appear only once}$ during training and thus must download the model parameters. Accordingly, we propose $\textsf{DoCoFL}$ -- a new framework for downlink compression in the cross-device setting. Importantly, $\textsf{DoCoFL}$ can be seamlessly combined with many uplink compression schemes, rendering it suitable for bi-directional compression. Through extensive evaluation, we show that $\textsf{DoCoFL}$ offers significant bi-directional bandwidth reduction while achieving competitive accuracy to that of a baseline without any compression.
    
[^62]: 基于视觉Transformer的模型用于将一组图像描述为一个故事

    Vision Transformer Based Model for Describing a Set of Images as a Story. (arXiv:2210.02762v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2210.02762](http://arxiv.org/abs/2210.02762)

    本研究提出了一种基于视觉Transformer的模型，用于将一组图像描述为一个故事。该模型通过ViT提取输入图像的特征，并使用双向LSTM捕捉图像补丁的过去和未来上下文信息。通过注意力机制加权计算得到最终的故事描述向量。

    

    视觉故事讲述是将一组图像形成多句故事的过程。恰当地包含输入图像内捕捉到的视觉变化和上下文信息是视觉故事讲述中最具挑战性的方面之一。因此，由一组图像开发的故事经常缺乏凝聚力、相关性和语义关系。在本文中，我们提出了一种新颖的基于视觉Transformer的模型，用于将一组图像描述为一个故事。所提出的方法使用视觉Transformer（ViT）提取输入图像的独特特征。首先，将输入图像分成16X16的补丁，并捆绑到扁平化补丁的线性投影中。从单个图像到多个图像补丁的转换捕捉到了输入视觉模式的视觉多样性。这些特征作为输入传递给双向LSTM，它是序列编码器的一部分。这样可以捕捉到所有图像补丁的过去和未来图像上下文。然后，通过注意力机制来加权计算图像补丁的特征向量，以产生最终的故事描述向量。

    Visual Story-Telling is the process of forming a multi-sentence story from a set of images. Appropriately including visual variation and contextual information captured inside the input images is one of the most challenging aspects of visual storytelling. Consequently, stories developed from a set of images often lack cohesiveness, relevance, and semantic relationship. In this paper, we propose a novel Vision Transformer Based Model for describing a set of images as a story. The proposed method extracts the distinct features of the input images using a Vision Transformer (ViT). Firstly, input images are divided into 16X16 patches and bundled into a linear projection of flattened patches. The transformation from a single image to multiple image patches captures the visual variety of the input visual patterns. These features are used as input to a Bidirectional-LSTM which is part of the sequence encoder. This captures the past and future image context of all image patches. Then, an atten
    
[^63]: 保护隐私的张量网络机器学习

    Privacy-preserving machine learning with tensor networks. (arXiv:2202.12319v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2202.12319](http://arxiv.org/abs/2202.12319)

    本文展示了张量网络架构在保护隐私的机器学习中具有潜在优势，并提出了确保鲁棒性的明确条件。

    

    张量网络被广泛用于提供低能量态的高效表示，最近被提出作为机器学习架构的一种新方法。本文展示了张量网络架构在保护隐私的机器学习中具有潜在优势，这对于处理医疗记录等任务非常重要。首先，我们描述了前馈神经网络中存在的新隐私漏洞，并在合成和真实数据集中进行了说明。然后，我们提出了确保对这种漏洞具有鲁棒性的明确条件，这涉及到在规范对称性下等价的模型的刻画。我们严格证明了张量网络架构满足这些条件。在此过程中，我们定义了一种新型的矩阵乘积态的规范形式，具有高度的规律性并修正了残余规范问题。

    Tensor networks, widely used for providing efficient representations of low-energy states of local quantum many-body systems, have been recently proposed as machine learning architectures which could present advantages with respect to traditional ones. In this work we show that tensor network architectures have especially prospective properties for privacy-preserving machine learning, which is important in tasks such as the processing of medical records. First, we describe a new privacy vulnerability that is present in feedforward neural networks, illustrating it in synthetic and real-world datasets. Then, we develop well-defined conditions to guarantee robustness to such vulnerability, which involve the characterization of models equivalent under gauge symmetry. We rigorously prove that such conditions are satisfied by tensor-network architectures. In doing so, we define a novel canonical form for matrix product states, which has a high degree of regularity and fixes the residual gaug
    
[^64]: 揭开黑盒子：调控算法决策

    Unpacking the Black Box: Regulating Algorithmic Decisions. (arXiv:2110.03443v2 [econ.GN] UPDATED)

    [http://arxiv.org/abs/2110.03443](http://arxiv.org/abs/2110.03443)

    本文研究如何在代理使用复杂的“黑盒”预测函数进行决策的情况下，对算法决策进行最优调控。研究发现，限制代理使用透明度足够高的预测函数是低效的，而针对激励偏差源头的目标化工具可以提供次优解决方案，从而改善福利。

    

    我们展示了如何在一个代理使用复杂的“黑盒”预测函数进行决策（如贷款、医疗测试或招聘）且委托人在了解代理的黑盒模型方面有限的情况下，最优地调控预测算法。我们证明，只要诱导不足，且最优预测函数足够复杂，将代理限制在足够透明的预测函数中是低效的。算法审计有助于提高福利，但其收益取决于审计工具的设计。许多解释工具倾向于最小化整体信息损失，但这通常是低效的，因为它们集中于解释预测函数的平均行为。针对性的工具，如针对激励偏差源头（如过多的假阳性或种族差异）的工具，可以提供次优解决方案。我们提供了对我们理论的实证支持。

    We show how to optimally regulate prediction algorithms in a world where an agent uses complex 'black-box' prediction functions to make decisions such as lending, medical testing, or hiring, and where a principal is limited in how much she can learn about the agent's black-box model. We show that limiting agents to prediction functions that are simple enough to be fully transparent is inefficient as long as the misalignment is limited and first-best prediction functions are sufficiently complex. Algorithmic audits can improve welfare, but the gains depend on the design of the audit tools. Tools that focus on minimizing overall information loss, the focus of many explainer tools, will generally be inefficient since they focus on explaining the average behavior of the prediction function. Targeted tools that focus on the source of incentive misalignment, e.g., excess false positives or racial disparities, can provide second-best solutions. We provide empirical support for our theoretical
    

