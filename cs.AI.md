# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Is Model Collapse Inevitable? Breaking the Curse of Recursion by Accumulating Real and Synthetic Data](https://arxiv.org/abs/2404.01413) | 本文通过比较数据取代和数据积累两种情况，发现累积数据可以防止模型崩溃。 |
| [^2] | [NUMTEMP: A real-world benchmark to verify claims with statistical and temporal expressions](https://arxiv.org/abs/2403.17169) | NUMTEMP是一个真实世界基准，专注于验证复杂的数字论点，量化了现有解决方案的局限性，并提供了一种解决真实世界数字论点验证挑战的方法。 |
| [^3] | [Linguacodus: A Synergistic Framework for Transformative Code Generation in Machine Learning Pipelines](https://arxiv.org/abs/2403.11585) | Linguacodus是一种创新框架，通过部署动态流水线和精细调整的大型语言模型，实现了将自然语言任务描述转换为代码的自动化过程，极大地推进了机器学习应用的发展。 |
| [^4] | [Just Say the Name: Online Continual Learning with Category Names Only via Data Generation](https://arxiv.org/abs/2403.10853) | 提出了在线连续学习框架G-NoCL，采用生成数据并利用DIverSity和COmplexity enhancing ensemBlER（DISCOBER）进行数据融合，展示了其在在线连续学习基准测试中的优越性能。 |
| [^5] | [People Attribute Purpose to Autonomous Vehicles When Explaining Their Behavior](https://arxiv.org/abs/2403.08828) | 人们会给自主车辆的行为赋予目的属性，并在生成解释和评估这些解释时表现出对目的论解释的倾向。 |
| [^6] | [Introducing First-Principles Calculations: New Approach to Group Dynamics and Bridging Social Phenomena in TeNP-Chain Based Social Dynamics Simulations](https://arxiv.org/abs/2403.05593) | 本文介绍了一种利用第一原理计算的新方法，用于桥接量子力学原理与社会系统复杂动力学之间的联系，基于碲纳米颗粒和石墨烯结构特征与社会群体行为模式的隐喻对应。 |
| [^7] | [Plasmon Resonance Model: Investigation of Analysis of Fake News Diffusion Model with Third Mover Intervention Using Soliton Solution in Non-Complete Information Game under Repeated Dilemma Condition](https://arxiv.org/abs/2403.05585) | 该研究提出了一个新的模型，使用非线性偏微分方程和孤子解方法研究了假新闻在不完全信息博弈中的扩散过程，探讨了各类动者在系统中的相互作用，旨在理解和防止假新闻扩散。 |
| [^8] | [Medical Speech Symptoms Classification via Disentangled Representation](https://arxiv.org/abs/2403.05000) | 该论文提出了一种名为DRSC的医学言语分类模型，实现了自动学习从文本-声学数据中分离意图和内容表示以进行分类，并在检测25种不同医学症状时取得了95%的平均准确率。 |
| [^9] | [Note: Harnessing Tellurium Nanoparticles in the Digital Realm Plasmon Resonance, in the Context of Brewster's Angle and the Drude Model for Fake News Adsorption in Incomplete Information Games](https://arxiv.org/abs/2403.03239) | 这篇论文探讨了孤子理论和等离子现象在数字健康平台中建模用户行为和参与方面的创新应用，通过引入孤子解的概念，提出了理解健康改善行为模式的新方法，同时深入研究了硒化镉纳米颗粒在吸附假新闻中的等离子特性对用户互动和参与水平的影响。 |
| [^10] | [Diffusion Models as Constrained Samplers for Optimization with Unknown Constraints](https://arxiv.org/abs/2402.18012) | 使用扩散模型在数据流形内进行优化，通过在目标函数定义的Boltzmann分布和扩散模型学习的数据分布的乘积上进行抽样来解决具有未知约束的优化问题。 |
| [^11] | [Symmetry-aware Reinforcement Learning for Robotic Assembly under Partial Observability with a Soft Wrist](https://arxiv.org/abs/2402.18002) | 本研究利用部分可观测性和深度强化学习处理机器人装配中的零件装配任务，通过利用领域对称性提高样本效率，成功构建了一种基于记忆的代理模型。 |
| [^12] | [QUCE: The Minimisation and Quantification of Path-Based Uncertainty for Generative Counterfactual Explanations](https://arxiv.org/abs/2402.17516) | QUCE方法旨在通过减少路径不确定性来量化和缓解基于路径的不确定性，从而改善对抗性反事实解释的表现。 |
| [^13] | [PANDAS: Prototype-based Novel Class Discovery and Detection](https://arxiv.org/abs/2402.17420) | PANDAS是一种用于新类别发现和检测的方法，通过从无标签数据中发现代表新类别的聚类，并用原型表示类别，实现了在基础类别的基础上检测新发现的类别。 |
| [^14] | [Stick to your Role! Stability of Personal Values Expressed in Large Language Models](https://arxiv.org/abs/2402.14846) | 本文提出研究在大型语言模型中个人价值在不同背景下的表达稳定性，通过模拟对话的方式进行评估，对19个LLMs进行比较研究。 |
| [^15] | [Universal Physics Transformers](https://arxiv.org/abs/2402.12365) | 提出了通用物理变压器（UPTs）这一新颖学习范式，能够模拟广泛的时空问题，同时适用于拉格朗日和欧拉离散化方案，有效地传播动态并允许查询潜在空间 |
| [^16] | [End-to-end multilingual fact-checking at scale](https://arxiv.org/abs/2402.12147) | 使用Factiverse AI模型，可以进行跨语言的端到端事实核查，并且通过实验证明，为事实核查任务进行微调的模型优于大型语言模型。 |
| [^17] | [Tracking Changing Probabilities via Dynamic Learners](https://arxiv.org/abs/2402.10142) | 该论文介绍了通过动态学习器追踪概率变化的方法，通过输出候选项目及其概率来预测离散项目序列中下一个可能出现的项目。 |
| [^18] | [The Essential Role of Causality in Foundation World Models for Embodied AI](https://arxiv.org/abs/2402.06665) | 基于因果关系的基础世界模型对于具身人工智能的发展至关重要，当前的基础模型无法准确建模与现实世界的物理相互作用。因果关系的研究有助于构建真实世界模型，提高对可能相互作用结果的准确预测能力。 |
| [^19] | [Anatomy of a Robotaxi Crash: Lessons from the Cruise Pedestrian Dragging Mishap](https://arxiv.org/abs/2402.06046) | 2023年10月，一起GM Cruise机器人出租车与行人相撞的事故给公司造成了巨大的动荡，同时也揭示了该公司在处理事故后的失误。这一事件的解剖提供了在技术、操作安全实践和组织反应方面的安全教训。 |
| [^20] | [Do Diffusion Models Learn Semantically Meaningful and Efficient Representations?](https://arxiv.org/abs/2402.03305) | 本研究通过实验探究了条件DDPMs学习生成2D球形高斯凸起的过程，在学习的过程中发现了潜在表示的关键，产生了与不同阶段对应的 qualitatively 不同的生成行为。 |
| [^21] | [Layered and Staged Monte Carlo Tree Search for SMT Strategy Synthesis](https://arxiv.org/abs/2401.17159) | 本文提出了一种基于蒙特卡洛树搜索的方法，用于自动合成SMT策略。创新之处在于采用了分层和分阶段的MCTS搜索，以在保持成本低的同时发现有效的策略。 |
| [^22] | [An extended asymmetric sigmoid with Perceptron (SIGTRON) for imbalanced linear classification](https://arxiv.org/abs/2312.16043) | 本文提出了一个新的多项式参数化sigmoid函数(SIGTRON)，并且介绍了其伴随的SIC模型。相比传统的成本敏感学习模型，在给定的训练数据集接近良好平衡的条件下，所提出的SIC模型对于数据集的变化更加适应，并通过创建倾斜的超平面方程来实现。 |
| [^23] | [The Machine Vision Iceberg Explained: Advancing Dynamic Testing by Considering Holistic Environmental Circumstances.](http://arxiv.org/abs/2401.14831) | 本研究提出了一个名为粒度等级的层次级别模型，用于更好地理解机器视觉在不同环境条件下的操作。这一模型旨在提供对影响机器视觉功能的各个实体的全面概述。 |
| [^24] | [Benchmarking the Fairness of Image Upsampling Methods.](http://arxiv.org/abs/2401.13555) | 这项工作提出了一个评估有条件生成模型性能和公平性的框架，并针对图像上采样应用创建了一个涵盖现代方法的基准测试。实证研究发现使用无偏训练集对结果至关重要，并揭示了不同算法对该问题的响应变化。 |
| [^25] | [Faithful Path Language Modelling for Explainable Recommendation over Knowledge Graph.](http://arxiv.org/abs/2310.16452) | 本文提出了一个名为PEARLM的方法，通过语言建模开展基于路径的知识图谱推荐，解决了现有方法中对预训练知识图谱嵌入的依赖以及未充分利用实体和关系之间相互依赖性的问题，还避免了生成不准确的解释。实验结果表明，与现有方法相比，我们的方法效果显著。 |
| [^26] | [Contrastive Preference Learning: Learning from Human Feedback without RL.](http://arxiv.org/abs/2310.13639) | 对比偏好学习方法解决了传统强化学习从人类反馈中学习奖励函数的假设错误以及优化挑战的问题。 |
| [^27] | [Learning Separable Hidden Unit Contributions for Speaker-Adaptive Lip-Reading.](http://arxiv.org/abs/2310.05058) | 本文提出了一种用于适应个体的唇读方法，通过学习可分离的隐藏单元贡献，实现了对浅层和深层的不同处理，并利用个体的特征来自适应地增强或抑制唇读特征，提高唇读的性能和鲁棒性。 |
| [^28] | [Constraint-Conditioned Policy Optimization for Versatile Safe Reinforcement Learning.](http://arxiv.org/abs/2310.03718) | 这个论文提出了一种约束条件下的策略优化框架，用于训练多功能安全强化学习智能体。通过引入多功能值估计和有条件的变分推理模块，该框架在训练效率和零-shot适应能力方面表现优于基准方法。 |
| [^29] | [AutoAgents: A Framework for Automatic Agent Generation.](http://arxiv.org/abs/2309.17288) | AutoAgents是一个创新的框架，它能够根据不同的任务自动生成和协调多个专业代理，以构建一个适应不同任务的AI团队，提高多智能体协作的适应性和效率。 |
| [^30] | [Human labeling errors and their impact on ConvNets for satellite image scene classification.](http://arxiv.org/abs/2305.12106) | 本文针对卫星图像场景分类中人工标注数据集的不可避免的误差问题，收集了真实标签数据，并探讨这些误差如何影响三个ConvNets的分类结果。研究发现，人类标注误差具有显着的类和实例依赖性，并且对不同CNN结构的影响不同，因此需要仔细考虑这些误差并开发更强大的ConvNets来解决这一挑战。 |
| [^31] | [Multi-Prompt with Depth Partitioned Cross-Modal Learning.](http://arxiv.org/abs/2305.06221) | 本研究提出了划分的多模态提示（PMPO）方法，将软提示从一个扩展到多个，通过连接多个提示到视觉编码器的不同深度上，能够更好地捕捉视觉表示的上下文深度，与传统单提示方法相比，在下游视觉语言任务中具有更好的表现。 |
| [^32] | [FlightBERT++: A Non-autoregressive Multi-Horizon Flight Trajectory Prediction Framework.](http://arxiv.org/abs/2305.01658) | FlightBERT++提出了一种非自回归的多时域飞行轨迹预测框架，通过引入时域感知上下文生成器解决了误差累积和低效率的问题。 |
| [^33] | [Illusory Attacks: Detectability Matters in Adversarial Attacks on Sequential Decision-Makers.](http://arxiv.org/abs/2207.10170) | 对于顺序决策者的敌对攻击来说，弱点是缺乏时间上的一致性，使其容易被检测出来；而R-attack是一种既有效又可证明是统计不可检测的攻击，可以更难以使用自动化方法检测出来。 |

# 详细

[^1]: 模型崩溃是否不可避免？通过累积真实和合成数据打破递归的诅咒

    Is Model Collapse Inevitable? Breaking the Curse of Recursion by Accumulating Real and Synthetic Data

    [https://arxiv.org/abs/2404.01413](https://arxiv.org/abs/2404.01413)

    本文通过比较数据取代和数据积累两种情况，发现累积数据可以防止模型崩溃。

    

    随着生成模型的激增，以及在网络规模数据上的预训练，一个及时的问题浮出水面：当这些模型被训练在它们自己生成的输出上时会发生什么？最近对模型数据反馈循环的研究发现，这样的循环可能导致模型崩溃，即性能随着每次模型拟合迭代逐渐下降，直到最新的模型变得无用。然而，最近几篇研究模型崩溃的论文都假设随着时间推移，新数据会取代旧数据，而不是假设数据会随时间累积。在本文中，我们比较了这两种情况，并表明积累数据可以防止模型崩溃。我们首先研究了一个解析可处理的设置，其中一系列线性模型拟合到先前模型的预测。先前的工作表明，如果数据被替换，测试误差会随着模型拟合迭代次数线性增加；我们扩展了这个研究探讨了数据逐渐累积的情况下会发生什么。

    arXiv:2404.01413v1 Announce Type: cross  Abstract: The proliferation of generative models, combined with pretraining on web-scale data, raises a timely question: what happens when these models are trained on their own generated outputs? Recent investigations into model-data feedback loops discovered that such loops can lead to model collapse, a phenomenon where performance progressively degrades with each model-fitting iteration until the latest model becomes useless. However, several recent papers studying model collapse assumed that new data replace old data over time rather than assuming data accumulate over time. In this paper, we compare these two settings and show that accumulating data prevents model collapse. We begin by studying an analytically tractable setup in which a sequence of linear models are fit to the previous models' predictions. Previous work showed if data are replaced, the test error increases linearly with the number of model-fitting iterations; we extend this r
    
[^2]: NUMTEMP：一个用于验证带有统计和时间表达式的论点的真实世界基准

    NUMTEMP: A real-world benchmark to verify claims with statistical and temporal expressions

    [https://arxiv.org/abs/2403.17169](https://arxiv.org/abs/2403.17169)

    NUMTEMP是一个真实世界基准，专注于验证复杂的数字论点，量化了现有解决方案的局限性，并提供了一种解决真实世界数字论点验证挑战的方法。

    

    自动事实检查在数字时代应对不断增长的错误信息方面引起了极大兴趣。现有系统主要专注于维基百科上的合成论点，并且在真实世界论点上也取得了显著进展。在本文中，我们发布了Numtemp，一个多样化、多领域的数据集，专门关注数字论点，包括时间、统计和多样化方面的细粒度元数据，并且具有不泄露的证据收集。这解决了验证真实世界数字论点的挑战，这些论点复杂，往往缺乏精确信息，这是现有作品主要关注合成论点未解决的问题。我们评估并量化了现有解决方案在验证数字论点任务中的局限性。我们还评估了基于论点分解的方法、基于数字理解的模型，我们的最佳基线实现了58.32的宏F1分数。这证明了Numtemp的关键价值。

    arXiv:2403.17169v1 Announce Type: cross  Abstract: Automated fact checking has gained immense interest to tackle the growing misinformation in the digital era. Existing systems primarily focus on synthetic claims on Wikipedia, and noteworthy progress has also been made on real-world claims. In this work, we release Numtemp, a diverse, multi-domain dataset focused exclusively on numerical claims, encompassing temporal, statistical and diverse aspects with fine-grained metadata and an evidence collection without leakage. This addresses the challenge of verifying real-world numerical claims, which are complex and often lack precise information, not addressed by existing works that mainly focus on synthetic claims. We evaluate and quantify the limitations of existing solutions for the task of verifying numerical claims. We also evaluate claim decomposition based methods, numerical understanding based models and our best baselines achieves a macro-F1 of 58.32. This demonstrates that Numtemp
    
[^3]: Linguacodus：一种在机器学习流水线中进行变革性代码生成的协同框架

    Linguacodus: A Synergistic Framework for Transformative Code Generation in Machine Learning Pipelines

    [https://arxiv.org/abs/2403.11585](https://arxiv.org/abs/2403.11585)

    Linguacodus是一种创新框架，通过部署动态流水线和精细调整的大型语言模型，实现了将自然语言任务描述转换为代码的自动化过程，极大地推进了机器学习应用的发展。

    

    在不断发展的机器学习领域中，将自然语言描述无缝转化为可执行代码仍然是一个巨大的挑战。本文介绍了Linguacodus，这是一个创新性框架，旨在通过部署一个动态流水线，通过高级数据塑形指令，将自然语言任务描述迭代地转换为代码来应对这一挑战。Linguacodus的核心是一个经过精细调整的大型语言模型（LLM），能够评估各种问题的多样解决方案，并为特定任务选择最合适的解决方案。本文详细介绍了精细调整过程，并阐明了如何将自然语言描述转化为功能性代码。Linguacodus代表了自动化代码生成的重大飞跃，有效地弥合了任务描述和可执行代码之间的差距。它对推进跨不同领域的机器学习应用具有巨大潜力。

    arXiv:2403.11585v1 Announce Type: cross  Abstract: In the ever-evolving landscape of machine learning, seamless translation of natural language descriptions into executable code remains a formidable challenge. This paper introduces Linguacodus, an innovative framework designed to tackle this challenge by deploying a dynamic pipeline that iteratively transforms natural language task descriptions into code through high-level data-shaping instructions. The core of Linguacodus is a fine-tuned large language model (LLM), empowered to evaluate diverse solutions for various problems and select the most fitting one for a given task. This paper details the fine-tuning process, and sheds light on how natural language descriptions can be translated into functional code. Linguacodus represents a substantial leap towards automated code generation, effectively bridging the gap between task descriptions and executable code. It holds great promise for advancing machine learning applications across div
    
[^4]: 只说名称：通过数据生成实现仅利用类别名称进行在线连续学习

    Just Say the Name: Online Continual Learning with Category Names Only via Data Generation

    [https://arxiv.org/abs/2403.10853](https://arxiv.org/abs/2403.10853)

    提出了在线连续学习框架G-NoCL，采用生成数据并利用DIverSity和COmplexity enhancing ensemBlER（DISCOBER）进行数据融合，展示了其在在线连续学习基准测试中的优越性能。

    

    在现实世界的场景中，由于成本过高，对于连续学习进行大量手动注释是不切实际的。虽然之前的研究受到大规模网络监督训练的影响，建议在连续学习中利用网络抓取的数据，但这带来了诸如数据不平衡、使用限制和隐私问题等挑战。为了解决连续网络监督训练的风险，我们提出了一种在线连续学习框架 - 仅使用名称的生成式连续学习（G-NoCL）。所提出的G-NoCL使用一组生成器G以及学习者。当遇到新概念（例如，类别）时，G-NoCL采用新颖的样本复杂性引导数据合成技术DIverSity and COmplexity enhancing ensemBlER（DISCOBER）从生成的数据中最优抽样训练数据。通过大量实验，我们展示了DISCOBER在G-NoCL在线连续学习基准测试中表现出的优越性能，涵盖了In-Distributi。

    arXiv:2403.10853v1 Announce Type: cross  Abstract: In real-world scenarios, extensive manual annotation for continual learning is impractical due to prohibitive costs. Although prior arts, influenced by large-scale webly supervised training, suggest leveraging web-scraped data in continual learning, this poses challenges such as data imbalance, usage restrictions, and privacy concerns. Addressing the risks of continual webly supervised training, we present an online continual learning framework - Generative Name only Continual Learning (G-NoCL). The proposed G-NoCL uses a set of generators G along with the learner. When encountering new concepts (i.e., classes), G-NoCL employs the novel sample complexity-guided data ensembling technique DIverSity and COmplexity enhancing ensemBlER (DISCOBER) to optimally sample training data from generated data. Through extensive experimentation, we demonstrate superior performance of DISCOBER in G-NoCL online CL benchmarks, covering both In-Distributi
    
[^5]: 当解释自主车辆的行为时，人们会给予其属性目的

    People Attribute Purpose to Autonomous Vehicles When Explaining Their Behavior

    [https://arxiv.org/abs/2403.08828](https://arxiv.org/abs/2403.08828)

    人们会给自主车辆的行为赋予目的属性，并在生成解释和评估这些解释时表现出对目的论解释的倾向。

    

    一款优秀的可解释人工智能系统的标志是用户可以理解并采取行动的解释。许多情况下，这需要系统提供可理解的因果或反事实解释。认知科学可以帮助我们理解用户可能期望的解释类型，以及在哪种格式下呈现这些解释。本文简要回顾了认知科学解释方面的相关文献，特别关注目的论，即以达到目的为解释决策的倾向。然后，我们报告了人们如何为自主车辆的行为产生解释以及他们如何评估这些解释的经验数据。在第一项调查中，参与者（n = 54）观看了道路场景的视频，并被要求为车辆的行为生成机械的、反事实的或目的论的言语解释。在第二项调查中，另一组参与者（n = 356）对这些进行评分。

    arXiv:2403.08828v1 Announce Type: cross  Abstract: A hallmark of a good XAI system is explanations that users can understand and act on. In many cases, this requires a system to offer causal or counterfactual explanations that are intelligible. Cognitive science can help us understand what kinds of explanations users might expect, and in which format to frame these explanations. We briefly review relevant literature from the cognitive science of explanation, particularly as it concerns teleology, the tendency to explain a decision in terms of the purpose it was meant to achieve. We then report empirical data on how people generate explanations for the behavior of autonomous vehicles, and how they evaluate these explanations. In a first survey, participants (n=54) were shown videos of a road scene and asked to generate either mechanistic, counterfactual, or teleological verbal explanations for a vehicle's actions. In the second survey, a different set of participants (n=356) rated these
    
[^6]: 引入第一原理计算：一种新的方法用于群体动态和在TeNP-链社会动态模拟中架设社会现象之间的联系

    Introducing First-Principles Calculations: New Approach to Group Dynamics and Bridging Social Phenomena in TeNP-Chain Based Social Dynamics Simulations

    [https://arxiv.org/abs/2403.05593](https://arxiv.org/abs/2403.05593)

    本文介绍了一种利用第一原理计算的新方法，用于桥接量子力学原理与社会系统复杂动力学之间的联系，基于碲纳米颗粒和石墨烯结构特征与社会群体行为模式的隐喻对应。

    

    本文考虑了一种创新的跨学科方法论，它架起了量子力学基本原理与材料研究（如碲纳米颗粒和石墨烯）以及社会系统复杂动力学之间的鸿沟。这种方法的基础在于碲纳米颗粒和石墨烯的结构特征与社会群体行为模式之间的隐喻对应。碲纳米颗粒具有独特的属性，如提高碲链中共价键的强化和引发次生结构破坏导致这些链的分离。这类似于社会群体内部凝聚力加强和不同分组之间信息流动的干扰。同样，石墨烯的出色特性，如高电导性、强度和柔韧性，为理解社会群体动力学提供了更多层面。

    arXiv:2403.05593v1 Announce Type: cross  Abstract: This note considers an innovative interdisciplinary methodology that bridges the gap between the fundamental principles of quantum mechanics applied to the study of materials such as tellurium nanoparticles (TeNPs) and graphene and the complex dynamics of social systems. The basis for this approach lies in the metaphorical parallels drawn between the structural features of TeNPs and graphene and the behavioral patterns of social groups in the face of misinformation. TeNPs exhibit unique properties such as the strengthening of covalent bonds within telluric chains and the disruption of secondary structure leading to the separation of these chains. This is analogous to increased cohesion within social groups and disruption of information flow between different subgroups, respectively. . Similarly, the outstanding properties of graphene, such as high electrical conductivity, strength, and flexibility, provide additional aspects for unders
    
[^7]: 悬浮复共振模型：使用孤子解研究第三方干预下非完全信息博弈中的假新闻扩散模型

    Plasmon Resonance Model: Investigation of Analysis of Fake News Diffusion Model with Third Mover Intervention Using Soliton Solution in Non-Complete Information Game under Repeated Dilemma Condition

    [https://arxiv.org/abs/2403.05585](https://arxiv.org/abs/2403.05585)

    该研究提出了一个新的模型，使用非线性偏微分方程和孤子解方法研究了假新闻在不完全信息博弈中的扩散过程，探讨了各类动者在系统中的相互作用，旨在理解和防止假新闻扩散。

    

    在这篇研究说明中，我们提出了一种新的方法来模拟虚假新闻在不完全信息博弈框架内的扩散过程。具体而言，我们使用非线性偏微分方程来表示悬浮复共振现象，其中虚假新闻的扩散在特定社交群体或通信网络内被迅速放大，并通过孤子解方法分析其动态。此外，我们考虑头部动者、次头动者和第三方干预策略如何在这个非线性系统中相互作用，并对虚假新闻的扩散起到放大或抑制的作用。该模型旨在理解虚假新闻传播机制，并提供防止或打击其的见解。通过结合社会科学和自然科学的概念，本研究试图为当今的假新闻问题开发一个新的理论框架。

    arXiv:2403.05585v1 Announce Type: cross  Abstract: In this research note, we propose a new approach to model the fake news diffusion process within the framework of incomplete information games. In particular, we use nonlinear partial differential equations to represent the phenomenon of plasmon resonance, in which the diffusion of fake news is rapidly amplified within a particular social group or communication network, and analyze its dynamics through a soliton solution approach. In addition, we consider how first mover, second mover, and third mover strategies interact within this nonlinear system and contribute to the amplification or suppression of fake news diffusion. The model aims to understand the mechanisms of fake news proliferation and provide insights into how to prevent or combat it. By combining concepts from the social sciences and the physical sciences, this study attempts to develop a new theoretical framework for the contemporary problem of fake news.
    
[^8]: 通过分解表示进行医学言语症状分类

    Medical Speech Symptoms Classification via Disentangled Representation

    [https://arxiv.org/abs/2403.05000](https://arxiv.org/abs/2403.05000)

    该论文提出了一种名为DRSC的医学言语分类模型，实现了自动学习从文本-声学数据中分离意图和内容表示以进行分类，并在检测25种不同医学症状时取得了95%的平均准确率。

    

    arXiv:2403.05000v1 公告类型:new 摘要: 在现有工作中，意图被定义用于理解口头语言。医学言语中涉及的文本特征和声学特征均包含意图，这对于症状诊断非常重要。本文提出了一种名为DRSC的医学言语分类模型，该模型自动学习从文本-声学数据中分离意图和内容表示以进行分类。 通过意图编码器提取文本域和Mel-频谱图域的意图表示，然后通过两个交换获取重构的文本特征和Mel-频谱图特征。在将两个域的意图结合成一个联合表示后，综合意图表示被输入决策层进行分类。实验结果显示，我们的模型在检测25种不同医学症状时获得了平均准确率达到95%。

    arXiv:2403.05000v1 Announce Type: new  Abstract: Intent is defined for understanding spoken language in existing works. Both textual features and acoustic features involved in medical speech contain intent, which is important for symptomatic diagnosis. In this paper, we propose a medical speech classification model named DRSC that automatically learns to disentangle intent and content representations from textual-acoustic data for classification. The intent representations of the text domain and the Mel-spectrogram domain are extracted via intent encoders, and then the reconstructed text feature and the Mel-spectrogram feature are obtained through two exchanges. After combining the intent from two domains into a joint representation, the integrated intent representation is fed into a decision layer for classification. Experimental results show that our model obtains an average accuracy rate of 95% in detecting 25 different medical symptoms.
    
[^9]: 注意：利用硒化镉纳米颗粒在数字领域的布鲁斯特角和德鲁德模型中等离激元共振，用于假新闻吸附在不完全信息游戏中的背景

    Note: Harnessing Tellurium Nanoparticles in the Digital Realm Plasmon Resonance, in the Context of Brewster's Angle and the Drude Model for Fake News Adsorption in Incomplete Information Games

    [https://arxiv.org/abs/2403.03239](https://arxiv.org/abs/2403.03239)

    这篇论文探讨了孤子理论和等离子现象在数字健康平台中建模用户行为和参与方面的创新应用，通过引入孤子解的概念，提出了理解健康改善行为模式的新方法，同时深入研究了硒化镉纳米颗粒在吸附假新闻中的等离子特性对用户互动和参与水平的影响。

    

    这篇笔记探讨了孤子理论和等离子现象在建模数字健康平台内用户行为和参与方面的创新应用。通过引入孤子解的概念，我们提出了理解随时间稳定的健康改善行为模式的新方法。此外，我们深入探讨了硒化镉纳米颗粒及其在吸附假新闻中的等离子特性，从而影响用户互动和参与水平。通过将非线性动力学与硒化镉纳米颗粒的独特特征相结合的理论框架，我们旨在提供新的见解，以了解数字健康环境中用户参与动态。我们的分析突出了孤子理论在捕捉用户行为的复杂非线性动态方面的潜力，而等离子现象的应用为提高灵敏度和效果提供了一个有前景的途径。

    arXiv:2403.03239v1 Announce Type: cross  Abstract: This note explores the innovative application of soliton theory and plasmonic phenomena in modeling user behavior and engagement within digital health platforms. By introducing the concept of soliton solutions, we present a novel approach to understanding stable patterns of health improvement behaviors over time. Additionally, we delve into the role of tellurium nanoparticles and their plasmonic properties in adsorbing fake news, thereby influencing user interactions and engagement levels. Through a theoretical framework that combines nonlinear dynamics with the unique characteristics of tellurium nanoparticles, we aim to provide new insights into the dynamics of user engagement in digital health environments. Our analysis highlights the potential of soliton theory in capturing the complex, nonlinear dynamics of user behavior, while the application of plasmonic phenomena offers a promising avenue for enhancing the sensitivity and effec
    
[^10]: 扩散模型作为具有未知约束的优化约束抽样器

    Diffusion Models as Constrained Samplers for Optimization with Unknown Constraints

    [https://arxiv.org/abs/2402.18012](https://arxiv.org/abs/2402.18012)

    使用扩散模型在数据流形内进行优化，通过在目标函数定义的Boltzmann分布和扩散模型学习的数据分布的乘积上进行抽样来解决具有未知约束的优化问题。

    

    处理现实世界的优化问题在分析客观函数或约束不可用时变得尤为具有挑战性。虽然许多研究已经解决了未知目标的问题，但有限研究关注了约束条件未明确给出的情况。忽略这些约束可能导致在实践中不现实的虚假解决方案。为了处理这种未知约束，我们建议使用扩散模型在数据流形内进行优化。为了将优化过程限制在数据流形内，我们将原始优化问题重新构造为通过客观函数定义的Boltzmann分布和扩散模型学习的数据分布的乘积的抽样问题。为了增强抽样效率，我们提出了一个两阶段框架，以引导扩散过程进行预热，然后是Langevin动态。

    arXiv:2402.18012v1 Announce Type: cross  Abstract: Addressing real-world optimization problems becomes particularly challenging when analytic objective functions or constraints are unavailable. While numerous studies have addressed the issue of unknown objectives, limited research has focused on scenarios where feasibility constraints are not given explicitly. Overlooking these constraints can lead to spurious solutions that are unrealistic in practice. To deal with such unknown constraints, we propose to perform optimization within the data manifold using diffusion models. To constrain the optimization process to the data manifold, we reformulate the original optimization problem as a sampling problem from the product of the Boltzmann distribution defined by the objective function and the data distribution learned by the diffusion model. To enhance sampling efficiency, we propose a two-stage framework that begins with a guided diffusion process for warm-up, followed by a Langevin dyna
    
[^11]: 考虑对称性的软腕部分可观测性下机器人装配的强化学习

    Symmetry-aware Reinforcement Learning for Robotic Assembly under Partial Observability with a Soft Wrist

    [https://arxiv.org/abs/2402.18002](https://arxiv.org/abs/2402.18002)

    本研究利用部分可观测性和深度强化学习处理机器人装配中的零件装配任务，通过利用领域对称性提高样本效率，成功构建了一种基于记忆的代理模型。

    

    本研究运用软腕来解决机器人装配中的代表性但具有挑战性的富接触PEG-IN-HOLE任务，该软腕可以比刚性腕部更安全地操作并容忍较低频率的控制信号。与以往研究通常使用完全可观测公式不同，该公式需要外部设置或估计器来获取PEG-TO-HOLE姿态。相反，我们使用部分可观测公式和基于深度强化学习的示范来学习一种基于记忆的代理，该代理完全基于触觉和本体感知信号行动。此外，以前的研究未融合潜在领域对称性，因此必须在更大的空间中搜索解决方案。相反，我们建议利用对称性来提高样本效率，通过增加训练数据并构建辅助损失来强迫代理遵守对称性。在模拟实验中，使用五种不同对称PEG形状显示，我们提出的代理可以与

    arXiv:2402.18002v1 Announce Type: cross  Abstract: This study tackles the representative yet challenging contact-rich peg-in-hole task of robotic assembly, using a soft wrist that can operate more safely and tolerate lower-frequency control signals than a rigid one. Previous studies often use a fully observable formulation, requiring external setups or estimators for the peg-to-hole pose. In contrast, we use a partially observable formulation and deep reinforcement learning from demonstrations to learn a memory-based agent that acts purely on haptic and proprioceptive signals. Moreover, previous works do not incorporate potential domain symmetry and thus must search for solutions in a bigger space. Instead, we propose to leverage the symmetry for sample efficiency by augmenting the training data and constructing auxiliary losses to force the agent to adhere to the symmetry. Results in simulation with five different symmetric peg shapes show that our proposed agent can be comparable to 
    
[^12]: QUCE: 减少和量化基于路径的不确定性以生成对抗性反事实解释

    QUCE: The Minimisation and Quantification of Path-Based Uncertainty for Generative Counterfactual Explanations

    [https://arxiv.org/abs/2402.17516](https://arxiv.org/abs/2402.17516)

    QUCE方法旨在通过减少路径不确定性来量化和缓解基于路径的不确定性，从而改善对抗性反事实解释的表现。

    

    arXiv:2402.17516v1 公告类型：跨学科 深度神经网络（DNNs）作为机器学习领域最突出的方法之一。DNNs的有效性随着最近计算能力的增加而激增，使得这些方法能够扩展到处理大数据中的重要复杂性以应对预测挑战。然而，随着DNN模型复杂性的提高，可解释性降低。针对这一挑战，诸如对抗梯度整合（AGI）这样的可解释模型利用DNN提供的基于路径的梯度来阐明它们的决策。然而，当梯度在越界路径遍历期间表现出不规则性时，基于路径的解释器的性能可能会受到损害。在这种情况下，我们介绍了Quantified Uncertainty Counterfactual Explanations（QUCE），这是一种旨在减少路径不确定性的方法，以缓解越界遍历。 QUCE不仅在提出解释时量化不确定性

    arXiv:2402.17516v1 Announce Type: cross  Abstract: Deep Neural Networks (DNNs) stand out as one of the most prominent approaches within the Machine Learning (ML) domain. The efficacy of DNNs has surged alongside recent increases in computational capacity, allowing these approaches to scale to significant complexities for addressing predictive challenges in big data. However, as the complexity of DNN models rises, interpretability diminishes. In response to this challenge, explainable models such as Adversarial Gradient Integration (AGI) leverage path-based gradients provided by DNNs to elucidate their decisions. Yet the performance of path-based explainers can be compromised when gradients exhibit irregularities during out-of-distribution path traversal. In this context, we introduce Quantified Uncertainty Counterfactual Explanations (QUCE), a method designed to mitigate out-of-distribution traversal by minimizing path uncertainty. QUCE not only quantifies uncertainty when presenting e
    
[^13]: PANDAS: 基于原型的新类别发现与检测

    PANDAS: Prototype-based Novel Class Discovery and Detection

    [https://arxiv.org/abs/2402.17420](https://arxiv.org/abs/2402.17420)

    PANDAS是一种用于新类别发现和检测的方法，通过从无标签数据中发现代表新类别的聚类，并用原型表示类别，实现了在基础类别的基础上检测新发现的类别。

    

    目标检测器通常在固定的一组类别上进行一次训练。然而，这种封闭世界的假设在实践中是不现实的，因为在检测器部署在野外后，新的类别必然会出现。在这项工作中，我们研究了扩展训练为一组基础类别的检测器的方法，使其能够 i) 发现新类别的存在，并 ii) 自动丰富其库以能够检测这些新发现的类别以及基础类别。我们提出了 PANDAS，一种用于新类别发现和检测的方法。它从无标签数据中发现代表新类别的聚类，并用原型来表示旧类别和新类别。在推断过程中，基于距离的分类器使用这些原型为每个检测到的对象实例分配标签。我们的方法的简单性使其具有广泛的适用性。我们在VOC 2012和COCO-to-LVIS数据集上通过实验展示了PANDAS的有效性。

    arXiv:2402.17420v1 Announce Type: cross  Abstract: Object detectors are typically trained once and for all on a fixed set of classes. However, this closed-world assumption is unrealistic in practice, as new classes will inevitably emerge after the detector is deployed in the wild. In this work, we look at ways to extend a detector trained for a set of base classes so it can i) spot the presence of novel classes, and ii) automatically enrich its repertoire to be able to detect those newly discovered classes together with the base ones. We propose PANDAS, a method for novel class discovery and detection. It discovers clusters representing novel classes from unlabeled data, and represents old and new classes with prototypes. During inference, a distance-based classifier uses these prototypes to assign a label to each detected object instance. The simplicity of our method makes it widely applicable. We experimentally demonstrate the effectiveness of PANDAS on the VOC 2012 and COCO-to-LVIS 
    
[^14]: 坚持你的角色！个人价值在大型语言模型中的稳定性

    Stick to your Role! Stability of Personal Values Expressed in Large Language Models

    [https://arxiv.org/abs/2402.14846](https://arxiv.org/abs/2402.14846)

    本文提出研究在大型语言模型中个人价值在不同背景下的表达稳定性，通过模拟对话的方式进行评估，对19个LLMs进行比较研究。

    

    通过基准测试或心理问卷的标准方式研究大型语言模型(LLMs)是提供许多来源于类似最小背景的不同查询（例如多项选择问题）。然而，由于LLM高度依赖于背景，因此从这种最小背景评估中得出的结论可能对模型在部署中的行为（在那里它将暴露于许多新背景）的说明很少。我们认为，依赖于背景的特性应该作为LLM比较的另一个维度来研究，而不是其他维度，如认知能力、知识或模型大小。在本文中，我们提出了一个关于在不同背景下（模拟对不同话题的对话）价值表达稳定性的案例研究，并使用标准心理学问卷（PVQ）和行为下游任务进行测量。我们考虑了来自五个家族的19个开源LLM。借鉴心理学方法，我们研究了等级稳定性。

    arXiv:2402.14846v1 Announce Type: cross  Abstract: The standard way to study Large Language Models (LLMs) through benchmarks or psychology questionnaires is to provide many different queries from similar minimal contexts (e.g. multiple choice questions). However, due to LLM's highly context-dependent nature, conclusions from such minimal-context evaluations may be little informative about the model's behavior in deployment (where it will be exposed to many new contexts). We argue that context-dependence should be studied as another dimension of LLM comparison alongside others such as cognitive abilities, knowledge, or model size. In this paper, we present a case-study about the stability of value expression over different contexts (simulated conversations on different topics), and as measured using a standard psychology questionnaire (PVQ) and a behavioral downstream task. We consider 19 open-sourced LLMs from five families. Reusing methods from psychology, we study Rank-order stabilit
    
[^15]: 通用物理变压器

    Universal Physics Transformers

    [https://arxiv.org/abs/2402.12365](https://arxiv.org/abs/2402.12365)

    提出了通用物理变压器（UPTs）这一新颖学习范式，能够模拟广泛的时空问题，同时适用于拉格朗日和欧拉离散化方案，有效地传播动态并允许查询潜在空间

    

    基于深度神经网络的偏微分方程替代者近来引起了越来越多的关注。然而，类似于它们的数值对应物，在不同应用中使用不同的技术，即使系统的基础动态相似。一个著名的例子是在计算流体动力学中的拉格朗日和欧拉表述，这为神经网络有效地建模基于粒子而不是网格的动态构成了挑战。我们引入了通用物理变压器（UPTs），这是一种新颖的学习范式，它模拟了一系列时空问题 - 对拉格朗日和欧拉离散化方案。UPTs在没有基于网格或基于粒子的潜在结构的情况下运行，从而在网格和粒子之间实现了灵活性。UPTs在潜在空间中高效传播动态，强调了逆编码和解码技术。最后，UPTs允许查询潜在空间表现

    arXiv:2402.12365v1 Announce Type: cross  Abstract: Deep neural network based surrogates for partial differential equations have recently gained increased interest. However, akin to their numerical counterparts, different techniques are used across applications, even if the underlying dynamics of the systems are similar. A prominent example is the Lagrangian and Eulerian specification in computational fluid dynamics, posing a challenge for neural networks to effectively model particle- as opposed to grid-based dynamics. We introduce Universal Physics Transformers (UPTs), a novel learning paradigm which models a wide range of spatio-temporal problems - both for Lagrangian and Eulerian discretization schemes. UPTs operate without grid- or particle-based latent structures, enabling flexibility across meshes and particles. UPTs efficiently propagate dynamics in the latent space, emphasized by inverse encoding and decoding techniques. Finally, UPTs allow for queries of the latent space repre
    
[^16]: 跨语言规模的端到端事实核查

    End-to-end multilingual fact-checking at scale

    [https://arxiv.org/abs/2402.12147](https://arxiv.org/abs/2402.12147)

    使用Factiverse AI模型，可以进行跨语言的端到端事实核查，并且通过实验证明，为事实核查任务进行微调的模型优于大型语言模型。

    

    在本文中，我们描述了如何使用Factiverse AI模型在100多种语言中进行端到端事实核查。我们还通过实验性基准测试展示，为事实核查任务进行微调的模型胜过GPT-4、GPT-3.5-Turbo和Mistral-7b等大型语言模型。

    arXiv:2402.12147v1 Announce Type: cross  Abstract: In this article, we describe how you can perform end-to-end fact-checking in over 100 languages using Factiverse AI models. We also show through an experimental benchmark that fine-tuned models tailored for fact-checking tasks outperform Large Language Models such as GPT-4, GPT-3.5-Turbo, and Mistral-7b.
    
[^17]: 通过动态学习器追踪概率变化

    Tracking Changing Probabilities via Dynamic Learners

    [https://arxiv.org/abs/2402.10142](https://arxiv.org/abs/2402.10142)

    该论文介绍了通过动态学习器追踪概率变化的方法，通过输出候选项目及其概率来预测离散项目序列中下一个可能出现的项目。

    

    考虑一个预测器，即一个学习器，其输入是一系列离散项目。预测器的任务是在每个时间点进行概率多类别预测，即通过输出有零个或多个候选项目及其概率来预测接下来可能发生的项目，然后揭示实际项目并从中学习。为了输出概率，预测器会跟踪其所见项目的比例。预测器具有恒定（有限）的空间，我们寻求高效的预测和更新技术：流是无界的，项目的集合对预测器是未知的，它们的总数也可能无限增长。此外，存在非平稳性：项目的潜在频率可能会不时发生显著变化。例如，新项目可能开始出现，一些当前频繁出现的项目可能再次停止出现。由于有空间限制，预测器只需要提供概率。

    arXiv:2402.10142v1 Announce Type: cross  Abstract: Consider a predictor, a learner, whose input is a stream of discrete items. The predictor's task, at every time point, is probabilistic multiclass prediction, i.e., to predict which item may occur next by outputting zero or more candidate items, each with a probability, after which the actual item is revealed and the predictor learns from this observation. To output probabilities, the predictor keeps track of the proportions of the items it has seen. The predictor has constant (limited) space and we seek efficient prediction and update techniques: The stream is unbounded, the set of items is unknown to the predictor and their totality can also grow unbounded. Moreover, there is non-stationarity: the underlying frequencies of items may change, substantially, from time to time. For instance, new items may start appearing and a few currently frequent items may cease to occur again. The predictor, being space-bounded, need only provide pro
    
[^18]: 基于因果关系的基础世界模型在具身人工智能中的重要作用

    The Essential Role of Causality in Foundation World Models for Embodied AI

    [https://arxiv.org/abs/2402.06665](https://arxiv.org/abs/2402.06665)

    基于因果关系的基础世界模型对于具身人工智能的发展至关重要，当前的基础模型无法准确建模与现实世界的物理相互作用。因果关系的研究有助于构建真实世界模型，提高对可能相互作用结果的准确预测能力。

    

    最近在基础模型中取得的进展，尤其是在大型多模态模型和对话代理方面，引发了对具备普遍能力的具身代理人潜力的兴趣。这样的代理人需要能够在许多不同的真实世界环境中执行新任务。然而，当前的基础模型未能准确建模与现实世界的物理相互作用，因此对于具身人工智能而言是不够的。因果关系的研究有助于构建真实世界模型，这对于准确预测可能相互作用的结果至关重要。本文着重探讨了为即将到来的具身代理生成基础世界模型的前景，并对其中的因果关系的重要性提出了新的观点。我们认为整合因果关系是促进与世界的有意义的物理相互作用至关重要的。最后，我们揭示了这一背景下对因果关系的误解，并展示了我们对未来的展望。

    Recent advances in foundation models, especially in large multi-modal models and conversational agents, have ignited interest in the potential of generally capable embodied agents. Such agents would require the ability to perform new tasks in many different real-world environments. However, current foundation models fail to accurately model physical interactions with the real world thus not sufficient for Embodied AI. The study of causality lends itself to the construction of veridical world models, which are crucial for accurately predicting the outcomes of possible interactions. This paper focuses on the prospects of building foundation world models for the upcoming generation of embodied agents and presents a novel viewpoint on the significance of causality within these. We posit that integrating causal considerations is vital to facilitate meaningful physical interactions with the world. Finally, we demystify misconceptions about causality in this context and present our outlook fo
    
[^19]: 机器人出租车事故的解剖：从Cruise行人拖拽事故中吸取教训

    Anatomy of a Robotaxi Crash: Lessons from the Cruise Pedestrian Dragging Mishap

    [https://arxiv.org/abs/2402.06046](https://arxiv.org/abs/2402.06046)

    2023年10月，一起GM Cruise机器人出租车与行人相撞的事故给公司造成了巨大的动荡，同时也揭示了该公司在处理事故后的失误。这一事件的解剖提供了在技术、操作安全实践和组织反应方面的安全教训。

    

    2023年10月，在旧金山，一辆通用汽车Cruise的机器人出租车与一名行人相撞，造成了严重的伤害，同时也对该公司造成了巨大的动荡，这很可能会对整个行业产生长期影响。问题不仅仅源于事故本身，还包括Cruise在处理机器人出租车撞到行人后被拖行的过程中的失误。两份外部调查报告提供了描述事件的原始材料，并从监管互动的角度批评了公司的反应，但并未包含潜在的安全建议。我们利用这些报告材料来强调具体的事实和事件之间的关系，通过将报告材料的不同部分联系起来。然后我们探讨在技术、操作安全实践和组织对事件的反应方面可能可以学到的安全教训。

    An October 2023 crash between a GM Cruise robotaxi and a pedestrian in San Francisco resulted not only in a severe injury, but also dramatic upheaval at that company that will likely have lasting effects throughout the industry. The issues stem not just from the crash facts themselves, but also how Cruise mishandled dealing with their robotaxi dragging a pedestrian under the vehicle after the initial post-crash stop. A pair of external investigation reports provide raw material describing the incident and critique the company response from a regulatory interaction point of view, but did not include potential safety recommendations in scope. We use that report material to highlight specific facts and relationships between events by tying together different pieces of the report material. We then explore safety lessons that might be learned with regard to technology, operational safety practices, and organizational reaction to incidents.
    
[^20]: 扩散模型是否学习语义有意义和高效的表示？

    Do Diffusion Models Learn Semantically Meaningful and Efficient Representations?

    [https://arxiv.org/abs/2402.03305](https://arxiv.org/abs/2402.03305)

    本研究通过实验探究了条件DDPMs学习生成2D球形高斯凸起的过程，在学习的过程中发现了潜在表示的关键，产生了与不同阶段对应的 qualitatively 不同的生成行为。

    

    扩散模型能够以不寻常的方式生成图像，例如宇航员骑在月球上的马，并且有正确的阴影。这些输出表明了模型具有组合泛化的能力，但是模型是如何做到这一点的呢？我们在条件DDPMs上进行了控制实验，学习生成以指定的$x$和$y$位置为中心的2D球形高斯凸起。我们的结果表明，产生语义有意义的潜在表示对于实现高性能至关重要。在学习过程中，模型经历了三个不同的潜在表示阶段：(A阶段)没有潜在结构，(B阶段)一个混乱状态的2D流形，以及(C阶段)一个有序的2D流形。对应于这些阶段，我们发现了 qualitatively 不同的生成行为：1）生成多个凸起，2）生成一个凸起，但$x$和$y$位置不准确，3）生成一个凸起且位置准确。

    Diffusion models are capable of impressive feats of image generation with uncommon juxtapositions such as astronauts riding horses on the moon with properly placed shadows. These outputs indicate the ability to perform compositional generalization, but how do the models do so? We perform controlled experiments on conditional DDPMs learning to generate 2D spherical Gaussian bumps centered at specified $x$- and $y$-positions. Our results show that the emergence of semantically meaningful latent representations is key to achieving high performance. En route to successful performance over learning, the model traverses three distinct phases of latent representations: (phase A) no latent structure, (phase B) a 2D manifold of disordered states, and (phase C) a 2D ordered manifold. Corresponding to each of these phases, we identify qualitatively different generation behaviors: 1) multiple bumps are generated, 2) one bump is generated but at inaccurate $x$ and $y$ locations, 3) a bump is genera
    
[^21]: 分层和分阶段的蒙特卡洛树搜索用于SMT策略合成

    Layered and Staged Monte Carlo Tree Search for SMT Strategy Synthesis

    [https://arxiv.org/abs/2401.17159](https://arxiv.org/abs/2401.17159)

    本文提出了一种基于蒙特卡洛树搜索的方法，用于自动合成SMT策略。创新之处在于采用了分层和分阶段的MCTS搜索，以在保持成本低的同时发现有效的策略。

    

    现代SMT求解器（例如Z3）提供用户可控的策略，使用户能够根据自己的实例集定制求解器，从而显著提高求解器在特定用例中的性能。然而，这种策略定制的方法带来了一个重要挑战：为一类SMT实例手工设计一个优化的策略仍然是求解器开发人员和用户面临的复杂和艰巨任务。在本文中，我们通过一种新颖的基于蒙特卡洛树搜索（MCTS）的方法来解决这个自动进行SMT策略合成的问题。我们的方法将策略合成视为一种序列决策过程，其搜索树对应于策略空间，并利用MCTS来遍历这个庞大的搜索空间。使我们的方法能够在保持成本低的同时找到有效的策略的关键创新是分层和分阶段的MCTS搜索的理念。这些新颖的方法允许对策略空间进行更深入和更高效的探索。

    Modern SMT solvers, such as Z3, offer user-controllable strategies, enabling users to tailor them for their unique set of instances, thus dramatically enhancing solver performance for their use case. However, this approach of strategy customization presents a significant challenge: handcrafting an optimized strategy for a class of SMT instances remains a complex and demanding task for both solver developers and users alike.   In this paper, we address this problem of automatic SMT strategy synthesis via a novel Monte Carlo Tree Search (MCTS) based method. Our method treats strategy synthesis as a sequential decision-making process, whose search tree corresponds to the strategy space, and employs MCTS to navigate this vast search space. The key innovations that enable our method to identify effective strategies, while keeping costs low, are the ideas of layered and staged MCTS search. These novel approaches allow for a deeper and more efficient exploration of the strategy space, enablin
    
[^22]: 一种针对不平衡线性分类的扩展非对称sigmoid和感知机(SIGTRON)

    An extended asymmetric sigmoid with Perceptron (SIGTRON) for imbalanced linear classification

    [https://arxiv.org/abs/2312.16043](https://arxiv.org/abs/2312.16043)

    本文提出了一个新的多项式参数化sigmoid函数(SIGTRON)，并且介绍了其伴随的SIC模型。相比传统的成本敏感学习模型，在给定的训练数据集接近良好平衡的条件下，所提出的SIC模型对于数据集的变化更加适应，并通过创建倾斜的超平面方程来实现。

    

    本文提出了一种新的多项式参数化sigmoid函数，称为SIGTRON，它是一种扩展的非对称sigmoid函数和感知机的结合，以及它的伴随凸模型SIGTRON-不平衡分类(SIC)模型，该模型使用了虚拟SIGTRON产生的凸损失函数。与传统的$\pi$-加权成本敏感学习模型相比，SIC模型在损失函数上没有外部的$\pi$-权重，而是在虚拟的SIGTRON产生的损失函数中有内部参数。因此，当给定的训练数据集接近良好平衡的条件时，我们展示了所提出的SIC模型对数据集的变化更加适应，比如训练集和测试集之间比例不平衡的不一致性。这种适应是通过创建一个倾斜的超平面方程来实现的。另外，我们提出了一个基于拟牛顿优化(L-BFGS)框架的虚拟凸损失，通过开发一个基于区间的二分线性搜索算法来实现。

    This article presents a new polynomial parameterized sigmoid called SIGTRON, which is an extended asymmetric sigmoid with Perceptron, and its companion convex model called SIGTRON-imbalanced classification (SIC) model that employs a virtual SIGTRON-induced convex loss function. In contrast to the conventional $\pi$-weighted cost-sensitive learning model, the SIC model does not have an external $\pi$-weight on the loss function but has internal parameters in the virtual SIGTRON-induced loss function. As a consequence, when the given training dataset is close to the well-balanced condition, we show that the proposed SIC model is more adaptive to variations of the dataset, such as the inconsistency of the scale-class-imbalance ratio between the training and test datasets. This adaptation is achieved by creating a skewed hyperplane equation. Additionally, we present a quasi-Newton optimization(L-BFGS) framework for the virtual convex loss by developing an interval-based bisection line sear
    
[^23]: 机器视觉冰山的解释：通过考虑全面环境条件推进动态测试

    The Machine Vision Iceberg Explained: Advancing Dynamic Testing by Considering Holistic Environmental Circumstances. (arXiv:2401.14831v1 [cs.RO])

    [http://arxiv.org/abs/2401.14831](http://arxiv.org/abs/2401.14831)

    本研究提出了一个名为粒度等级的层次级别模型，用于更好地理解机器视觉在不同环境条件下的操作。这一模型旨在提供对影响机器视觉功能的各个实体的全面概述。

    

    当前的机器视觉测试是否会带来冰山的危险？本研究深入探讨了机器视觉（MV）测试的领域，这在高度自动驾驶（HAD）系统中是非常必要的。借助向冰山航行的隐喻，我们讨论了当前测试策略中潜在的缺陷。我们强调了对如何处理MV在开发过程中的不透明功能的更深入了解的紧迫需要，因为忽视了这些考虑可能会造成生命的丧失。我们的主要贡献是层次级别模型，我们将其称为粒度等级。该模型鼓励对MV操作环境条件的各个层次进行精细探索，从个体实体之间的关系到整个环境场景。该模型旨在提供对可能影响MV功能的所有实体的全面概述。

    Are we heading for an iceberg with the current testing of machine vision? This work delves into the landscape of Machine Vision (MV) testing, which is heavily required in Highly Automated Driving (HAD) systems. Utilizing the metaphorical notion of navigating towards an iceberg, we discuss the potential shortcomings concealed within current testing strategies. We emphasize the urgent need for a deeper understanding of how to deal with the opaque functions of MV in development processes. As overlooked considerations can cost lives. Our main contribution is the hierarchical level model, which we call Granularity Grades. The model encourages a refined exploration of the multi-scaled depths of understanding about the circumstances of environments in which MV is intended to operate. This model aims to provide a holistic overview of all entities that may impact MV functions, ranging from relations of individual entities like object attributes to entire environmental scenes. The application of
    
[^24]: 图像上采样方法的公平性基准测试

    Benchmarking the Fairness of Image Upsampling Methods. (arXiv:2401.13555v1 [cs.CV])

    [http://arxiv.org/abs/2401.13555](http://arxiv.org/abs/2401.13555)

    这项工作提出了一个评估有条件生成模型性能和公平性的框架，并针对图像上采样应用创建了一个涵盖现代方法的基准测试。实证研究发现使用无偏训练集对结果至关重要，并揭示了不同算法对该问题的响应变化。

    

    近年来，深度生成模型在创建合成媒体（如图像和视频）方面取得了快速发展。虽然这些模型在日常任务中的实际应用非常诱人，但评估其公平性相关的潜在风险至关重要。在这项工作中，我们引入了一个全面的框架，用于评估有条件生成模型的性能和公平性。我们开发了一套度量标准——受监督公平性的灵感来源——来评估模型的公平性和多样性。我们针对图像上采样这个特定应用，创建了一个涵盖各种现代上采样方法的基准测试。作为基准测试的一部分，我们引入了UnfairFace，这是FairFace的一个子集，复制了常见大规模人脸数据集的种族分布。我们的实证研究凸显了使用无偏训练集的重要性，并揭示了算法对该问题的响应变化。

    Recent years have witnessed a rapid development of deep generative models for creating synthetic media, such as images and videos. While the practical applications of these models in everyday tasks are enticing, it is crucial to assess the inherent risks regarding their fairness. In this work, we introduce a comprehensive framework for benchmarking the performance and fairness of conditional generative models. We develop a set of metrics$\unicode{x2013}$inspired by their supervised fairness counterparts$\unicode{x2013}$to evaluate the models on their fairness and diversity. Focusing on the specific application of image upsampling, we create a benchmark covering a wide variety of modern upsampling methods. As part of the benchmark, we introduce UnfairFace, a subset of FairFace that replicates the racial distribution of common large-scale face datasets. Our empirical study highlights the importance of using an unbiased training set and reveals variations in how the algorithms respond to 
    
[^25]: 可解释的基于路径的知识图推荐中的忠实路径语言建模

    Faithful Path Language Modelling for Explainable Recommendation over Knowledge Graph. (arXiv:2310.16452v1 [cs.IR])

    [http://arxiv.org/abs/2310.16452](http://arxiv.org/abs/2310.16452)

    本文提出了一个名为PEARLM的方法，通过语言建模开展基于路径的知识图谱推荐，解决了现有方法中对预训练知识图谱嵌入的依赖以及未充分利用实体和关系之间相互依赖性的问题，还避免了生成不准确的解释。实验结果表明，与现有方法相比，我们的方法效果显著。

    

    针对知识图谱中的路径推理方法在提高推荐系统透明度方面的潜力，本文提出了一种名为PEARLM的新方法，该方法通过语言建模有效捕获用户行为和产品端知识。我们的方法通过语言模型直接从知识图谱上的路径中学习知识图谱嵌入，并将实体和关系统一在同一优化空间中。序列解码的约束保证了路径对知识图谱的忠实性。在两个数据集上的实验证明了我们方法与现有最先进方法的有效性。

    Path reasoning methods over knowledge graphs have gained popularity for their potential to improve transparency in recommender systems. However, the resulting models still rely on pre-trained knowledge graph embeddings, fail to fully exploit the interdependence between entities and relations in the KG for recommendation, and may generate inaccurate explanations. In this paper, we introduce PEARLM, a novel approach that efficiently captures user behaviour and product-side knowledge through language modelling. With our approach, knowledge graph embeddings are directly learned from paths over the KG by the language model, which also unifies entities and relations in the same optimisation space. Constraints on the sequence decoding additionally guarantee path faithfulness with respect to the KG. Experiments on two datasets show the effectiveness of our approach compared to state-of-the-art baselines. Source code and datasets: AVAILABLE AFTER GETTING ACCEPTED.
    
[^26]: 对比偏好学习：学习用户反馈而无需RL的方法

    Contrastive Preference Learning: Learning from Human Feedback without RL. (arXiv:2310.13639v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.13639](http://arxiv.org/abs/2310.13639)

    对比偏好学习方法解决了传统强化学习从人类反馈中学习奖励函数的假设错误以及优化挑战的问题。

    

    "从人类反馈中进行强化学习（RLHF）已经成为一种与人类意图对齐的流行范式。通常的RLHF算法分为两个阶段：首先，利用人类偏好学习奖励函数，然后通过强化学习（RL）优化学习到的奖励函数以对齐模型。这种范式假设人类偏好是根据奖励分布的，但最近的研究表明，实际上它们遵循用户最佳策略下的遗憾。因此，从反馈中学习奖励函数不仅基于人类偏好的错误假设，还导致了由于策略梯度或RL阶段的自助法引起的棘手的优化挑战。由于这些优化挑战，当代的RLHF方法限制自己只能应用于上下文强化学习（如大型语言模型）或限制了观测维度（如基于状态的机器人）。我们通过引入一种新的方法来克服这些限制。"

    Reinforcement Learning from Human Feedback (RLHF) has emerged as a popular paradigm for aligning models with human intent. Typically RLHF algorithms operate in two phases: first, use human preferences to learn a reward function and second, align the model by optimizing the learned reward via reinforcement learning (RL). This paradigm assumes that human preferences are distributed according to reward, but recent work suggests that they instead follow the regret under the user's optimal policy. Thus, learning a reward function from feedback is not only based on a flawed assumption of human preference, but also leads to unwieldy optimization challenges that stem from policy gradients or bootstrapping in the RL phase. Because of these optimization challenges, contemporary RLHF methods restrict themselves to contextual bandit settings (e.g., as in large language models) or limit observation dimensionality (e.g., state-based robotics). We overcome these limitations by introducing a new famil
    
[^27]: 学习可分离的隐藏单元贡献用于适应个体的唇读技术

    Learning Separable Hidden Unit Contributions for Speaker-Adaptive Lip-Reading. (arXiv:2310.05058v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2310.05058](http://arxiv.org/abs/2310.05058)

    本文提出了一种用于适应个体的唇读方法，通过学习可分离的隐藏单元贡献，实现了对浅层和深层的不同处理，并利用个体的特征来自适应地增强或抑制唇读特征，提高唇读的性能和鲁棒性。

    

    本文提出了一种新颖的适应个体的唇读方法。首先，一个个体的特征可以通过他/她的几张面部图像，甚至是一张浅层网络的单一图像来准确描绘，而与讲话面部相关的细粒度动态特征则需要深层序列网络来准确表示。因此，我们将浅层和深层分别处理以适应不同的唇读情境。其次，我们观察到一个个体独特的特征（例如突出的口腔和下颌）对于不同的单词和发音的唇读表现具有不同的影响，需要自适应地增强或抑制特征以实现稳健的唇读。基于这两点观察，我们提出利用个体的特征来自动学习具有不同目标的可分离隐藏单元贡献。

    In this paper, we propose a novel method for speaker adaptation in lip reading, motivated by two observations. Firstly, a speaker's own characteristics can always be portrayed well by his/her few facial images or even a single image with shallow networks, while the fine-grained dynamic features associated with speech content expressed by the talking face always need deep sequential networks to represent accurately. Therefore, we treat the shallow and deep layers differently for speaker adaptive lip reading. Secondly, we observe that a speaker's unique characteristics ( e.g. prominent oral cavity and mandible) have varied effects on lip reading performance for different words and pronunciations, necessitating adaptive enhancement or suppression of the features for robust lip reading. Based on these two observations, we propose to take advantage of the speaker's own characteristics to automatically learn separable hidden unit contributions with different targets for shallow layers and de
    
[^28]: 约束条件下的策略优化用于多功能安全强化学习

    Constraint-Conditioned Policy Optimization for Versatile Safe Reinforcement Learning. (arXiv:2310.03718v1 [cs.LG])

    [http://arxiv.org/abs/2310.03718](http://arxiv.org/abs/2310.03718)

    这个论文提出了一种约束条件下的策略优化框架，用于训练多功能安全强化学习智能体。通过引入多功能值估计和有条件的变分推理模块，该框架在训练效率和零-shot适应能力方面表现优于基准方法。

    

    安全强化学习（RL）专注于训练在预定义安全约束条件下能够最大化奖励的智能体。然而，在部署过程中，学习能够适应不同安全约束要求且无需重新训练的多功能安全策略仍然是一个较为未开发和具有挑战性的领域。在这项工作中，我们提出了多功能安全强化学习问题，并考虑了两个主要需求：训练效率和零-shot适应能力。为了解决这些问题，我们引入了Conditioned Constrained Policy Optimization（CCPO）框架，包括两个关键模块：（1）多功能值估计（VVE），用于在未见过的阈值条件下近似值函数，并且（2）有条件的变分推理（CVI），用于在策略优化中编码任意约束阈值。我们的大量实验表明，CCPO在安全和任务性能方面优于基准，并保持了对不同约束的零-shot适应能力。

    Safe reinforcement learning (RL) focuses on training reward-maximizing agents subject to pre-defined safety constraints. Yet, learning versatile safe policies that can adapt to varying safety constraint requirements during deployment without retraining remains a largely unexplored and challenging area. In this work, we formulate the versatile safe RL problem and consider two primary requirements: training efficiency and zero-shot adaptation capability. To address them, we introduce the Conditioned Constrained Policy Optimization (CCPO) framework, consisting of two key modules: (1) Versatile Value Estimation (VVE) for approximating value functions under unseen threshold conditions, and (2) Conditioned Variational Inference (CVI) for encoding arbitrary constraint thresholds during policy optimization. Our extensive experiments demonstrate that CCPO outperforms the baselines in terms of safety and task performance while preserving zero-shot adaptation capabilities to different constraint 
    
[^29]: AutoAgents: 一个自动生成智能代理的框架

    AutoAgents: A Framework for Automatic Agent Generation. (arXiv:2309.17288v1 [cs.AI])

    [http://arxiv.org/abs/2309.17288](http://arxiv.org/abs/2309.17288)

    AutoAgents是一个创新的框架，它能够根据不同的任务自动生成和协调多个专业代理，以构建一个适应不同任务的AI团队，提高多智能体协作的适应性和效率。

    

    大型语言模型（LLM）在多智能体系统的自动化任务解决中取得了显著进展。然而，大多数现有基于LLM的多智能体方法依赖于预定义的代理来处理简单任务，限制了多智能体协作在不同场景中的适应性。因此，我们引入了AutoAgents，一个创新的框架，根据不同任务自适应生成和协调多个专业代理以构建AI团队。具体而言，AutoAgents通过动态生成多个所需代理来耦合任务和角色之间的关系，并且根据生成的专家代理为当前任务规划解决方案。多个专业代理相互协作以高效完成任务。同时，观察者角色被纳入框架中以反思指定的计划和代理的响应，并对其进行改进。我们对多种基准测试进行的实验表明，AutoAgents能够根据不同的任务适应性生成和协调多个专业代理，实现高效的任务完成。

    Large language models (LLMs) have enabled remarkable advances in automated task-solving with multi-agent systems. However, most existing LLM-based multi-agent approaches rely on predefined agents to handle simple tasks, limiting the adaptability of multi-agent collaboration to different scenarios. Therefore, we introduce AutoAgents, an innovative framework that adaptively generates and coordinates multiple specialized agents to build an AI team according to different tasks. Specifically, AutoAgents couples the relationship between tasks and roles by dynamically generating multiple required agents based on task content and planning solutions for the current task based on the generated expert agents. Multiple specialized agents collaborate with each other to efficiently accomplish tasks. Concurrently, an observer role is incorporated into the framework to reflect on the designated plans and agents' responses and improve upon them. Our experiments on various benchmarks demonstrate that Au
    
[^30]: 人类标注误差及其对卫星图像场景分类的ConvNets的影响

    Human labeling errors and their impact on ConvNets for satellite image scene classification. (arXiv:2305.12106v1 [cs.CV])

    [http://arxiv.org/abs/2305.12106](http://arxiv.org/abs/2305.12106)

    本文针对卫星图像场景分类中人工标注数据集的不可避免的误差问题，收集了真实标签数据，并探讨这些误差如何影响三个ConvNets的分类结果。研究发现，人类标注误差具有显着的类和实例依赖性，并且对不同CNN结构的影响不同，因此需要仔细考虑这些误差并开发更强大的ConvNets来解决这一挑战。

    

    卷积神经网络(ConvNets)已成功应用于卫星图像场景分类。对于ConvNets执行准确分类，人工标注的训练数据集至关重要。然而，由于卫星图像的复杂性，人工标注数据集中的误差是不可避免的。然而，人类标注误差在卫星图像上的分布及其对ConvNets的影响尚未进行研究。为了填补这一研究空白，本研究首次收集了来自32位参与者的真实标签，并探讨了它们的误差如何影响高分辨率卫星图像场景分类中的三个ConvNets（VGG16，GoogleNet和ResNet-50）。我们发现：（1）人类标注误差具有显着的类和实例依赖性，这与以前研究中的模拟噪声本质上不同，（2）关于所有类的总体精度，当训练数据的人工标注误差增加1个单位时，ConvNets的总体精度会降低0.67%~1.02%；（3）人类标注误差对不同CNN结构的影响各不相同。本研究强调了仔细检查卫星图像场景分类中的人类标注误差的重要性，并呼吁开发强大的ConvNets来解决这一挑战。

    Convolutional neural networks (ConvNets) have been successfully applied to satellite image scene classification. Human-labeled training datasets are essential for ConvNets to perform accurate classification. Errors in human-labeled training datasets are unavoidable due to the complexity of satellite images. However, the distribution of human labeling errors on satellite images and their impact on ConvNets have not been investigated. To fill this research gap, this study, for the first time, collected real-world labels from 32 participants and explored how their errors affect three ConvNets (VGG16, GoogleNet and ResNet-50) for high-resolution satellite image scene classification. We found that: (1) human labeling errors have significant class and instance dependence, which is fundamentally different from the simulation noise in previous studies; (2) regarding the overall accuracy of all classes, when human labeling errors in training data increase by one unit, the overall accuracy of Co
    
[^31]: 带深度划分的多提示模态交叉学习

    Multi-Prompt with Depth Partitioned Cross-Modal Learning. (arXiv:2305.06221v1 [cs.CV])

    [http://arxiv.org/abs/2305.06221](http://arxiv.org/abs/2305.06221)

    本研究提出了划分的多模态提示（PMPO）方法，将软提示从一个扩展到多个，通过连接多个提示到视觉编码器的不同深度上，能够更好地捕捉视觉表示的上下文深度，与传统单提示方法相比，在下游视觉语言任务中具有更好的表现。

    

    近年来，软提示学习方法被提出来微调大型视觉-语言预训练模型以完成各种下游任务。这些方法通常将可学习的文本标记与类别标记组合作为模型的输入，其中模型的参数被冻结。然而，它们经常使用单一提示来描述类别上下文，而不能充分捕捉类别的多样属性。本研究介绍了划分的多模态提示（PMPO），这是一种多模态提示技术，将软提示从一个可学习提示扩展到多个提示。我们的方法将视觉编码器深度进行分割，并将可学习提示连接到分离的视觉深度上，使不同提示能够捕捉视觉表示的层次上下文深度。此外，为了最大限度地利用多提示学习的优势，我们将来自手动设计的模板和可学习的多提示的先验信息结合在一起，从而提高了模型的泛化能力。

    In recent years, soft prompt learning methods have been proposed to fine-tune large-scale vision-language pre-trained models for various downstream tasks. These methods typically combine learnable textual tokens with class tokens as input for models with frozen parameters. However, they often employ a single prompt to describe class contexts, failing to capture categories' diverse attributes adequately. This study introduces the Partitioned Multi-modal Prompt (PMPO), a multi-modal prompting technique that extends the soft prompt from a single learnable prompt to multiple prompts. Our method divides the visual encoder depths and connects learnable prompts to the separated visual depths, enabling different prompts to capture the hierarchical contextual depths of visual representations. Furthermore, to maximize the advantages of multi-prompt learning, we incorporate prior information from manually designed templates and learnable multi-prompts, thus improving the generalization capabiliti
    
[^32]: FlightBERT++：一种非自回归多时域飞行轨迹预测框架

    FlightBERT++: A Non-autoregressive Multi-Horizon Flight Trajectory Prediction Framework. (arXiv:2305.01658v1 [cs.LG])

    [http://arxiv.org/abs/2305.01658](http://arxiv.org/abs/2305.01658)

    FlightBERT++提出了一种非自回归的多时域飞行轨迹预测框架，通过引入时域感知上下文生成器解决了误差累积和低效率的问题。

    

    飞行轨迹预测是空中交通管制中的重要任务，可以帮助空管员更安全高效地管理空域。现有方法通常采用自回归方式执行多时域飞行轨迹预测任务，容易出现误差累积和低效率问题。本文提出了一种新的框架，称为FlightBERT++，以i）直接以非自回归方式预测多时域飞行轨迹，和ii）改善FlightBERT框架中二进制编码（BE）表示的限制。具体而言，所提出的框架通过通用的编码器-解码器架构实现，其中编码器从历史观测中学习时空模式，而解码器预测未来时间步的飞行状态。与传统架构相比，额外的时域感知上下文生成器（HACG）专门设计考虑先前的时域。

    Flight Trajectory Prediction (FTP) is an essential task in Air Traffic Control (ATC), which can assist air traffic controllers to manage airspace more safely and efficiently. Existing approaches generally perform multi-horizon FTP tasks in an autoregressive manner, which is prone to suffer from error accumulation and low-efficiency problems. In this paper, a novel framework, called FlightBERT++, is proposed to i) forecast multi-horizon flight trajectories directly in a non-autoregressive way, and ii) improved the limitation of the binary encoding (BE) representation in the FlightBERT framework. Specifically, the proposed framework is implemented by a generalized Encoder-Decoder architecture, in which the encoder learns the temporal-spatial patterns from historical observations and the decoder predicts the flight status for the future time steps. Compared to conventional architecture, an extra horizon-aware contexts generator (HACG) is dedicatedly designed to consider the prior horizon 
    
[^33]: 幻觉攻击：对顺序决策者的敌对攻击中可检测性很重要

    Illusory Attacks: Detectability Matters in Adversarial Attacks on Sequential Decision-Makers. (arXiv:2207.10170v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2207.10170](http://arxiv.org/abs/2207.10170)

    对于顺序决策者的敌对攻击来说，弱点是缺乏时间上的一致性，使其容易被检测出来；而R-attack是一种既有效又可证明是统计不可检测的攻击，可以更难以使用自动化方法检测出来。

    

    在实际世界中部署的自主代理需要对感官输入的敌对攻击具备强大的鲁棒性。强化代理策略需要预测可能的最强攻击。我们证明了现有的强化学习代理的观测空间攻击具有共同的弱点：虽然有效，但它们缺乏时间上的一致性，因此可以使用自动化手段或人工检查来检测。对于敌手来说，可检测性是不希望出现的，因为它可能会引发安全事态升级。我们引入了完美的幻觉攻击，这是一种新形式的顺序决策者的敌对攻击，既有效又可证明是统计不可检测的。随后，我们提出了更加灵活的R-attack，其生成的观测转换与无敌对环境的状态转换函数一致且可以端到端学习。实验结果显示，与现有的攻击相比，R-attack更难以使用自动化方法检测出来。

    Autonomous agents deployed in the real world need to be robust against adversarial attacks on sensory inputs. Robustifying agent policies requires anticipating the strongest attacks possible. We demonstrate that existing observation-space attacks on reinforcement learning agents have a common weakness: while effective, their lack of temporal consistency makes them detectable using automated means or human inspection. Detectability is undesirable to adversaries as it may trigger security escalations. We introduce perfect illusory attacks, a novel form of adversarial attack on sequential decision-makers that is both effective and provably statistically undetectable. We then propose the more versatile R-attacks, which result in observation transitions that are consistent with the state-transition function of the adversary-free environment and can be learned end-to-end. Compared to existing attacks, we empirically find R-attacks to be significantly harder to detect with automated methods, 
    

