# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [A Proactive and Dual Prevention Mechanism against Illegal Song Covers empowered by Singing Voice Conversion.](http://arxiv.org/abs/2401.17133) | 这项工作提出了一种主动性的双重防护机制，通过引入人类无法察觉的扰动，干扰歌唱声音转换的生成过程，防止未经授权的基于歌唱声音转换的非法歌曲翻唱。该机制既扰乱了歌手身份，又扰乱了歌词，使得歌唱声音既不模仿目标歌手，也不保留原始歌词。 |
| [^2] | [Enhanced Sound Event Localization and Detection in Real 360-degree audio-visual soundscapes.](http://arxiv.org/abs/2401.17129) | 这份论文介绍了一种增强的音频视觉声事件定位和检测网络，通过合并音频和视频信息提升了系统性能，并利用目标检测器和数据增强技术进一步改进了模型。 |
| [^3] | [Unsupervised Discovery of Steerable Factors When Graph Deep Generative Models Are Entangled.](http://arxiv.org/abs/2401.17123) | 这项工作提出了GraphCG方法，用于在预训练图深度生成模型的潜在空间中无监督发现可操纵因素，通过最大化语义丰富方向之间的互信息来学习这些可操纵因素。实验证明GraphCG优于其他竞争方法。 |
| [^4] | [Traffic estimation in unobserved network locations using data-driven macroscopic models.](http://arxiv.org/abs/2401.17095) | 本文提出了一种利用宏观模型和多源时空数据的方法来估计无法观测到的网络位置的交通流量和行驶时间。该方法可以在传感器覆盖范围有限的情况下进行准确的估计，并满足基本的流量守恒约束条件。 |
| [^5] | [BlockFusion: Expandable 3D Scene Generation using Latent Tri-plane Extrapolation.](http://arxiv.org/abs/2401.17053) | BlockFusion是一种使用扩散和外推技术生成三维场景的模型，能无缝地添加新的块以扩展场景。采用混合神经场和潜在三平面空间来保证高质量和多样化的生成结果。 |
| [^6] | [ViTree: Single-path Neural Tree for Step-wise Interpretable Fine-grained Visual Categorization.](http://arxiv.org/abs/2401.17050) | ViTree是一种用于细粒度视觉分类的新方法，通过结合视觉变换器和神经决策树，逐步突出信息丰富的局部区域，并选择单个树路径来提高模型的可解释性。 |
| [^7] | [Explaining Explanations in Probabilistic Logic Programming.](http://arxiv.org/abs/2401.17045) | 该论文介绍了基于概率逻辑编程的解释解释方法，以解决在不透明系统中生成合适解释的困难。 |
| [^8] | [Scalable Mechanism Design for Multi-Agent Path Finding.](http://arxiv.org/abs/2401.17044) | 这项工作介绍了可扩展的多智能体路径规划机制设计问题，并提出了三种对策。 |
| [^9] | [Finetuning Large Language Models for Vulnerability Detection.](http://arxiv.org/abs/2401.17010) | 本文优化了大规模语言模型用于源代码中的漏洞检测任务，通过微调最先进的代码语言模型WizardCoder并改进其训练过程和策略，实现了对漏洞数据集的分类性能的提升。 |
| [^10] | [ActDroid: An active learning framework for Android malware detection.](http://arxiv.org/abs/2401.16982) | ActDroid是一种用于Android恶意软件检测的主动学习框架，能够在及时和经济有效的情况下对恶意应用程序进行准确分类，帮助解决恶意软件检测的标记问题和概念漂移问题。 |
| [^11] | [CORE: Towards Scalable and Efficient Causal Discovery with Reinforcement Learning.](http://arxiv.org/abs/2401.16974) | CORE是一种基于深度强化学习的因果推断和干预规划方法，可以高效地揭示因果结构，并在结构估计准确性和样本效率方面表现优于现有方法。 |
| [^12] | [Two Heads Are Better Than One: Integrating Knowledge from Knowledge Graphs and Large Language Models for Entity Alignment.](http://arxiv.org/abs/2401.16960) | 本研究提出了一种大型语言模型增强的实体对齐框架（LLMEA），将知识图谱中的结构知识与大型语言模型中的语义知识相结合，以提升实体对齐的效果。 |
| [^13] | [Reinforcement Learning for Versatile, Dynamic, and Robust Bipedal Locomotion Control.](http://arxiv.org/abs/2401.16889) | 本论文使用深度强化学习创建了一种通用的双足机器人动态运动控制器，该控制器可以应用于多种动态双足技能，并且在模拟环境和实际环境中展现出了优越性能。 |
| [^14] | [A Tournament of Transformation Models: B-Spline-based vs. Mesh-based Multi-Objective Deformable Image Registration.](http://arxiv.org/abs/2401.16867) | 本论文对比了B样条模型和网格模型两种常用的变形模型，在实践中它们使用了不同的优化方法。同时，论文强调了通过多目标优化方法可以获得更全面的图像配准效果。 |
| [^15] | [Encoding Temporal Statistical-space Priors via Augmented Representation.](http://arxiv.org/abs/2401.16808) | 通过增加表示的方式编码时间统计空间先验，以应对时间序列数据建模中的挑战。我们的方法在两个数据集上的实证推广性能明显优于五个最新的基准方法。具有高度模块化性质的方法适用于各种场景。 |
| [^16] | [Detecting LLM-Assisted Writing in Scientific Communication: Are We There Yet?.](http://arxiv.org/abs/2401.16807) | 这项研究评估了四种先进的文本检测器对LLM辅助写作的表现，发现它们的性能不如一个简单的检测器。研究认为需要开发专门用于LLM辅助写作的特定检测器，以解决当前承认实践中的挑战。 |
| [^17] | [Performance Insights-based AI-driven Football Transfer Fee Prediction.](http://arxiv.org/abs/2401.16795) | 该研究开发了一种利用人工智能的方法，可以预测足球球员的转会费用。这可以帮助俱乐部做出更好的决策，提高表现并增加俱乐部的预算。 |
| [^18] | [Can Large Language Models be Trusted for Evaluation? Scalable Meta-Evaluation of LLMs as Evaluators via Agent Debate.](http://arxiv.org/abs/2401.16788) | 本论文提出了ScaleEval，一个基于代理辩论的元评估框架，通过利用多个交流型LLM代理的能力来有效、可靠、高效地评估LLMs在不同任务和场景中作为评估者的性能。 |
| [^19] | [Graph Fairness Learning under Distribution Shifts.](http://arxiv.org/abs/2401.16784) | 论文主要研究了在分布变化下的图公平学习，通过理论分析和实证研究发现了决定图中偏差的因素，并探索了训练图和测试图之间表示距离的影响，对于在图结构数据上确保公平性具有重要意义。 |
| [^20] | [Extrinsicaly Rewarded Soft Q Imitation Learning with Discriminator.](http://arxiv.org/abs/2401.16772) | 本论文提出了一种基于外部奖励的鉴别器的软Q模仿学习方法，旨在解决在少量专家数据和采样数据中进行模仿学习时遇到的困难，同时通过添加基于对抗的奖励函数，使算法更加稳健和高效。 |
| [^21] | [Detection and Recovery Against Deep Neural Network Fault Injection Attacks Based on Contrastive Learning.](http://arxiv.org/abs/2401.16766) | 本文提出了一个基于对比学习的深度神经网络故障注入攻击检测和恢复框架（CFDR），通过将对比学习应用于训练和推理流程中，实现了具有自适应能力的深度神经网络推理引擎，在只有一个批次的测试数据和少量无标签测试数据的情况下，能够实时检测并快速恢复多种类型的故障注入攻击。 |
| [^22] | [A Cross-Language Investigation into Jailbreak Attacks in Large Language Models.](http://arxiv.org/abs/2401.16765) | 大型语言模型面临着越狱攻击的威胁，在跨语言的环境下，恶意问题可以逃避安全过滤器。本研究填补了这一研究空白，通过广泛的经验研究和语义保留算法的开发，揭示了多语言越狱攻击的模式和安全威胁。 |
| [^23] | [SwapNet: Efficient Swapping for DNN Inference on Edge AI Devices Beyond the Memory Budget.](http://arxiv.org/abs/2401.16757) | SwapNet是一种高效的边缘AI设备DNN块交换中间件，在超出内存预算的情况下，通过分解DNN为块并进行交换，实现了大型DNN的高效执行。 |
| [^24] | [Diffusion model for relational inference.](http://arxiv.org/abs/2401.16755) | 这项研究提出了一种关系推理的扩散模型(DiffRI)，通过条件扩散建模学习推断组件之间连接存在的概率，并在无监督方式下发现地面真实相互作用方面具有很高的能力。 |
| [^25] | [ShaRP: Explaining Rankings with Shapley Values.](http://arxiv.org/abs/2401.16744) | ShaRP是一个基于Shapley值的框架，用于解释排名结果中各个特征的贡献。即使使用线性评分函数，特征的权重也不一定对应其Shapley值的贡献，而是取决于特征分布和评分特征之间的局部相互作用。 |
| [^26] | [Generative AI-based closed-loop fMRI system.](http://arxiv.org/abs/2401.16742) | DecNefGAN是一种基于生成型人工智能的闭环fMRI系统，通过结合生成对抗系统和神经强化模型，研究人类如何对抗和应对生成型人工智能的潜在影响。 |
| [^27] | [Towards Generating Informative Textual Description for Neurons in Language Models.](http://arxiv.org/abs/2401.16731) | 本文提出了一种新颖而可伸缩的框架，将文本描述与语言模型中的神经元联系起来，从而解释模型中理解的信息。通过使用生成语言模型发现人可解释的描述符，并使用无监督方法解释神经元，通过定性和定量分析证明了该方法的有效性。 |
| [^28] | [Multivariate Beta Mixture Model: Probabilistic Clustering With Flexible Cluster Shapes.](http://arxiv.org/abs/2401.16708) | 本文提出了一种名为多元贝塔混合模型（MBMM）的新的概率模型，用于软聚类。MBMM通过其灵活的多元贝塔分布的概率密度函数适应不同的聚类形状，并在合成和真实数据集上展示了其适应性。 |
| [^29] | [AutoIE: An Automated Framework for Information Extraction from Scientific Literature.](http://arxiv.org/abs/2401.16672) | AutoIE是一个自动提取科学文献信息的创新框架，集成了多个关键组件，包括PDF文档布局分析、科学文本功能块识别、分子筛合成信息提取和在线学习等，具有高效提取关键数据的能力。应用于石化领域的实践证明了其有效性。 |
| [^30] | [Is Artificial Intelligence Providing the Second Revolution for Weather Forecasting?.](http://arxiv.org/abs/2401.16669) | 人工智能技术在天气预报领域的快速发展代表了一个重大突破，它克服了传统模型的局限性，有潜力引领天气预报的第二次革命。 |
| [^31] | [Recovering Mental Representations from Large Language Models with Markov Chain Monte Carlo.](http://arxiv.org/abs/2401.16657) | 本文研究了使用马尔可夫链蒙特卡洛（MCMC）方法从大型语言模型中恢复心智表示的方法，并且发现使用基于MCMC的自适应采样算法可以显著提高效率和性能，这对于进行贝叶斯推理具有潜在意义。 |
| [^32] | [Augmenting Replay in World Models for Continual Reinforcement Learning.](http://arxiv.org/abs/2401.16650) | 本研究通过在回放缓冲区中应用增强方法，成功地解决了增强连续强化学习中的内存限制问题，并在世界模型中有效防止灾难性遗忘。 |
| [^33] | [Incoherent Probability Judgments in Large Language Models.](http://arxiv.org/abs/2401.16646) | 在本论文中，研究人员通过对大型语言模型(LLMs)进行实验证明，这些模型产生的概率判断经常是不连贯的，显示出类似于人类一样的非理性偏差。他们还提出了将自回归LLMs与隐性贝叶斯推断联系起来的解释。 |
| [^34] | [Breaking Free Transformer Models: Task-specific Context Attribution Promises Improved Generalizability Without Fine-tuning Pre-trained LLMs.](http://arxiv.org/abs/2401.16638) | 本文提出了一种框架，通过任务特定的上下文归因来提高模型在下游任务中的性能，而不需要对预训练的语言模型进行微调，从而保持了模型的泛化性能。 |
| [^35] | [Improving Reinforcement Learning from Human Feedback with Efficient Reward Model Ensemble.](http://arxiv.org/abs/2401.16635) | 本论文提出一种通过高效的奖励模型集成来改进人工反馈强化学习的方法，以解决由于奖励模型预测不准确而导致RLHF输出与人类价值观不一致的问题。 |
| [^36] | [I came, I saw, I certified: some perspectives on the safety assurance of cyber-physical systems.](http://arxiv.org/abs/2401.16633) | 对于网络物理系统的安全保证，开发令人信服的保证案例是关键，包括检测缺陷、改进结构和自动生成案例。 |
| [^37] | [A comparison of RL-based and PID controllers for 6-DOF swimming robots: hybrid underwater object tracking.](http://arxiv.org/abs/2401.16618) | 本文比较了基于RL和PID控制器的六自由度游泳机器人，重点研究了水下目标跟踪。使用中央深度Q网络（DQN）控制器代替PID控制器在数据效率和离策略学习方面具有优势，并且较易实现。在没有动力学模型的情况下，我们提出了一个RL代理来控制多输入多输出的系统，中心控制器可能比独立的PID控制器提供更强健的控制。 |
| [^38] | [A Linguistic Comparison between Human and ChatGPT-Generated Conversations.](http://arxiv.org/abs/2401.16587) | 本研究比较了人类和ChatGPT生成的对话的语言差异，发现ChatGPT在社交、分析、认知、关注焦点和积极情绪等方面表现出色，但人类对话更具变异性和真实性，尽管在情绪方面无显著差异。同时，该研究还提供了一个新颖的、由ChatGPT生成的对话组成的数据集。 |
| [^39] | [Attention-based Reinforcement Learning for Combinatorial Optimization: Application to Job Shop Scheduling Problem.](http://arxiv.org/abs/2401.16580) | 本论文提出了一种基于注意力的强化学习方法，用于解决作业车间调度问题。通过集成策略梯度强化学习和修改后的Transformer结构，我们的方法在解决大规模问题上表现出色，优于最近研究和广泛采用的启发式规则。 |
| [^40] | [Leveraging Professional Radiologists' Expertise to Enhance LLMs' Evaluation for Radiology Reports.](http://arxiv.org/abs/2401.16578) | 该论文提出了一种方法，将专业放射科医生的专业知识与大型语言模型相结合，来提升自动生成报告的自动评估。实验结果显示，该方法的模型在评估中表现优于传统的度量标准。 |
| [^41] | [LLMs as On-demand Customizable Service.](http://arxiv.org/abs/2401.16577) | 提出了一种分层、分布式的LLM架构概念，通过在通用计算机和物联网设备上提供按需访问的可定制服务，解决了LLMs训练、部署和访问过程中的挑战，并能够实现资源和应用需求的最佳平衡。 |
| [^42] | [Autoencoder-Based Domain Learning for Semantic Communication with Conceptual Spaces.](http://arxiv.org/abs/2401.16569) | 这篇论文研究了基于概念空间的语义通信，提出了一个自编码器学习的框架，解决了无法捕捉和量化“意义”的问题。 |
| [^43] | [Multi-class Regret Detection in Hindi Devanagari Script.](http://arxiv.org/abs/2401.16561) | 本研究聚焦于印地语社交媒体上的后悔表达，建立了一个新的数据集，并通过研究后悔语言表达的特征和相关领域，揭示了后悔的来源和影响。 |
| [^44] | [SelectLLM: Can LLMs Select Important Instructions to Annotate?.](http://arxiv.org/abs/2401.16553) | 这项工作提出了一种名为SelectLLM的新方法，利用LLMs选择高质量指令。通过提示LLMs估计每个无标签指令的有用性和影响力，并使用聚类算法将指令分为多个聚类。 |
| [^45] | [GuReT: Distinguishing Guilt and Regret related Text.](http://arxiv.org/abs/2401.16541) | 本文介绍了GuReT数据集，用于研究内疚和后悔之间的关系，并探索其在文本中的独特特征。通过使用机器学习和深度学习技术，结果表明基于变压器的模型在内疚和后悔识别任务中表现出优于传统机器学习方法的性能。 |
| [^46] | [Validation, Robustness, and Accuracy of Perturbation-Based Sensitivity Analysis Methods for Time-Series Deep Learning Models.](http://arxiv.org/abs/2401.16521) | 本研究验证了时间序列深度学习模型的扰动敏感性分析方法的可靠性和准确性，并比较了不同方法和模型的影响。 |
| [^47] | [AFSD-Physics: Exploring the governing equations of temperature evolution during additive friction stir deposition by a human-AI teaming approach.](http://arxiv.org/abs/2401.16501) | 本文使用人工智能与人类协作的方法，提出了AFSD-Physics模型，通过学习实验数据，得到了添加摩擦搅拌堆积过程中温度演变的控制方程。该模型具有物理解释性、计算成本低且准确度高，与实际测量结果吻合较好。 |
| [^48] | [ReGAL: Refactoring Programs to Discover Generalizable Abstractions.](http://arxiv.org/abs/2401.16467) | ReGAL提出了一种用于发现通用抽象的程序重构方法，可以通过重构代码学习可重用的函数库，利用这些共享函数库可以更准确地预测程序。 |
| [^49] | [Supervised Contrastive Learning based Dual-Mixer Model for Remaining Useful Life Prediction.](http://arxiv.org/abs/2401.16462) | 本文提出了一种基于监督对比学习的双混合模型，用于剩余寿命预测。该模型通过灵活的特征融合和特征空间全局关系不变性训练方法，提高了预测准确性。 |
| [^50] | [Norm Enforcement with a Soft Touch: Faster Emergence, Happier Agents.](http://arxiv.org/abs/2401.16461) | 通过温和的规范执行，该研究提出了一种新的方法，通过智能体之间的交流推动合作并促进规范的出现。 |
| [^51] | [Credit Risk Meets Large Language Models: Building a Risk Indicator from Loan Descriptions in P2P Lending.](http://arxiv.org/abs/2401.16458) | 本文研究了如何利用P2P借贷平台上借款人提供的文本描述来构建风险指标。结果显示，利用大型语言模型生成的风险评分可以明显提高信用风险分类器的性能。 |
| [^52] | [Effective Controllable Bias Mitigation for Classification and Retrieval using Gate Adapters.](http://arxiv.org/abs/2401.16457) | 本文引入了可控门适配器（ConGater），一种具有可调节敏感性参数的新颖模块化门机制，可在推理时逐渐过渡从模型的偏向状态到完全去偏的版本，并通过实验证明了其在分类和检索任务中的性能。 |
| [^53] | [KAUCUS: Knowledge Augmented User Simulators for Training Language Model Assistants.](http://arxiv.org/abs/2401.16454) | KAUCUS引入了知识增强用户模拟器框架，可以生成多样化的模拟器助手交互，并能够快速引入外部知识，从而提高语言模型助手的训练效果。 |
| [^54] | [Hybrid Transformer and Spatial-Temporal Self-Supervised Learning for Long-term Traffic Prediction.](http://arxiv.org/abs/2401.16453) | 本文提出了一个将混合Transformer和时空自监督学习相结合的模型，通过应用自适应数据增强技术和Chebyshev多项式图卷积来提高模型的鲁棒性和对复杂空间依赖性的捕捉能力，并设计了两个自监督学习任务来建模时空异质性，从而提高了模型的准确性和泛化能力。 |
| [^55] | [Context-Former: Stitching via Latent Conditioned Sequence Modeling.](http://arxiv.org/abs/2401.16452) | Context-Former是一种集成了基于情境信息的模仿学习和序列建模的方法，通过拼接次优轨迹片段来改善决策，并提高了Decision Transformer的性能。 |
| [^56] | [ACCESS: Prompt Engineering for Automated Web Accessibility Violation Corrections.](http://arxiv.org/abs/2401.16450) | 本研究提出了一种用于修复网页无障碍违规的新方法，通过实时修改文档对象模型(DOM)和利用大型语言模型(LLMs)以及提示工程技术，解决了自动修复无障碍错误的问题。 |
| [^57] | [LLM4SecHW: Leveraging Domain Specific Large Language Model for Hardware Debugging.](http://arxiv.org/abs/2401.16448) | LLM4SecHW是一种利用领域特定大型语言模型进行硬件调试的新框架，通过编制一个开源硬件设计缺陷及其纠正步骤的数据集，并进行中型LLM的精细调优，实现对硬件设计中的错误进行识别和纠正。这为在其他研究领域中应用精细调优领域特定LLM提供了参考工作流程。 |
| [^58] | [Enhancing Human Experience in Human-Agent Collaboration: A Human-Centered Modeling Approach Based on Positive Human Gain.](http://arxiv.org/abs/2401.16444) | 本研究提出了一种以人为中心的协作代理人建模方法，旨在增强人类的体验。通过引入基于人类收益的强化学习方法，代理人可以在保持自身能力的同时，增强人类实现预期目标的程度。 |
| [^59] | [Evaluating Deep Networks for Detecting User Familiarity with VR from Hand Interactions.](http://arxiv.org/abs/2401.16443) | 通过使用深度分类器和手部追踪技术，本文提出了一种评估用户对虚拟现实熟悉程度的方法，以便在用户不熟悉虚拟现实时为其提供按需培训，从而提高其在虚拟环境中的任务完成效率。 |
| [^60] | [FaKnow: A Unified Library for Fake News Detection.](http://arxiv.org/abs/2401.16441) | FaKnow是一个统一的虚假新闻检测算法库，包含多种常用的模型和工具，并解决了不同框架下的可重复性和冗余问题。 |
| [^61] | [Beyond Eviction Prediction: Leveraging Local Spatiotemporal Public Records to Inform Action.](http://arxiv.org/abs/2401.16440) | 该研究利用当地时空公共记录来预测驱逐风险，并证明这些预测对于指导有针对性的外展政策是有用的。 |
| [^62] | [Do deep neural networks utilize the weight space efficiently?.](http://arxiv.org/abs/2401.16438) | 该论文介绍了一种利用权重矩阵的列空间和行空间的新概念，可以大幅减少深度学习模型的参数而不影响性能。实验证明该方法能够在资源有限的情况下实现参数高效的深度学习模型，并在ImageNet数据集上展现了竞争性的性能。 |
| [^63] | [Self-Supervised Learning in Event Sequences: A Comparative Study and Hybrid Approach of Generative Modeling and Contrastive Learning.](http://arxiv.org/abs/2401.15935) | 本研究通过比较研究和混合方法，调查了事件序列的自我监督学习技术，并引入了一种新的方法，将生成模型和对比嵌入进行对齐。结果显示，这种对齐模型在各种任务上表现优越，为预测事件序列中的信息提供了潜在的好处。 |
| [^64] | [Distribution-consistency Structural Causal Models.](http://arxiv.org/abs/2401.15911) | 本文提出了分布一致的结构因果模型（DiscoSCMs），用于解决因果建模中的反事实建模挑战。这种模型通过引入分布一致假设来解决因果模型的容量限制，从而提高反事实推理的准确性和实用性。 |
| [^65] | [GarchingSim: An Autonomous Driving Simulator with Photorealistic Scenes and Minimalist Workflow.](http://arxiv.org/abs/2401.15803) | GarchingSim是一种具有逼真场景和用户友好工作流程的自动驾驶仿真器，能与外部算法通信并具有高精度的车辆动力学模型，适用于生成合成数据和使用机器学习算法驾驶。 |
| [^66] | [DiffuserLite: Towards Real-time Diffusion Planning.](http://arxiv.org/abs/2401.15443) | DiffuserLite是一个快速轻量级的扩散规划框架，通过引入计划细化过程（PRP）来提高决策频率，相比之前的框架，它只产生了很小的运行时间成本，并在D4RL基准测试中达到了最先进的性能。 |
| [^67] | [A RAG-based Question Answering System Proposal for Understanding Islam: MufassirQAS LLM.](http://arxiv.org/abs/2401.15378) | 基于RAG的MufassirQAS问答系统利用NLP技术建立联系并准确回答复杂问题，提高了LLMs的准确性和透明度，帮助理解伊斯兰教的复杂性和教义深度。 |
| [^68] | [Under the Surface: Tracking the Artifactuality of LLM-Generated Data.](http://arxiv.org/abs/2401.14698) | 本研究是针对大型语言模型（LLM）生成的人工数据的追踪研究，将各种类型的LLM生成文本数据进行了汇总和测试，并揭示了隐藏的质量和多样性问题。这是第一次对LLM生成数据进行综合分析和比较，并引发了对人工数据质量的关注。 |
| [^69] | [Discovering Mathematical Formulas from Data via GPT-guided Monte Carlo Tree Search.](http://arxiv.org/abs/2401.14424) | 通过结合MCTS和生成式预训练模型，我们提出了一种新的符号回归算法SR-GPT，在发现数据中的数学公式方面取得了显著的改进。 |
| [^70] | [CreativeSynth: Creative Blending and Synthesis of Visual Arts based on Multimodal Diffusion.](http://arxiv.org/abs/2401.14066) | CreativeSynth是一种基于多模态扩散的创新统一框架，通过整合多模态特征和定制的注意力机制，实现了将现实世界的语义内容导入到艺术领域中，能够协调多模态输入和多任务，在艺术图像生成方面具有重要意义。 |
| [^71] | [Investigating the Efficacy of Large Language Models for Code Clone Detection.](http://arxiv.org/abs/2401.13802) | 这项研究探索了大型语言模型在代码克隆检测任务中的应用。 |
| [^72] | [Tensor-view Topological Graph Neural Network.](http://arxiv.org/abs/2401.12007) | 提出了一种新颖的Tensor视图拓扑图神经网络（TTG-NN），该方法结合了持久同调、图卷积和张量运算，同时捕捉了局部和全局层面上的Tensor视图拓扑（TT）和Tensor视图图（TG）结构信息。 |
| [^73] | [A Systematic Evaluation of Euclidean Alignment with Deep Learning for EEG Decoding.](http://arxiv.org/abs/2401.10746) | 本研究系统评估了使用深度学习和欧几里得对齐对脑电解码的影响。结果表明，欧几里得对齐能够显著提高解码率，并且减少了收敛时间。 |
| [^74] | [Noise Contrastive Estimation-based Matching Framework for Low-resource Security Attack Pattern Recognition.](http://arxiv.org/abs/2401.10337) | 该论文提出了一种基于噪声对比估计的低资源安全攻击模式识别匹配框架，通过直接语义相似度决定文本与攻击模式之间的关联，以降低大量类别、标签分布不均和标签空间复杂性带来的学习难度。 |
| [^75] | [Rethinking Spectral Graph Neural Networks with Spatially Adaptive Filtering.](http://arxiv.org/abs/2401.09071) | 本文重新思考了谱图神经网络，并揭示了谱滤波和空间聚合之间的联系。该研究发现，谱滤波在隐含地将原始图转换成适应性新图，并明确计算用于空间聚合的新图。适应性新图展现出非局部性，并能够反映节点之间的标签一致性。 |
| [^76] | [Augmenting Math Word Problems via Iterative Question Composing.](http://arxiv.org/abs/2401.09003) | 本研究通过引入MMIQC数据集和迭代组合问题(IQC)的新颖增强方法，成功提高了大型语言模型的数学推理能力，在竞赛级数学问题上取得了优于先前最佳结果的准确率。 |
| [^77] | [CoSSegGaussians: Compact and Swift Scene Segmenting 3D Gaussians.](http://arxiv.org/abs/2401.05925) | CoSSegGaussians是一种紧凑且迅速的3D高斯场景分割方法，通过映射空间和语义特征实现紧凑和可靠的零样本场景分割。 |
| [^78] | [TwinBooster: Synergising Large Language Models with Barlow Twins and Gradient Boosting for Enhanced Molecular Property Prediction.](http://arxiv.org/abs/2401.04478) | TwinBooster结合了大语言模型、Barlow Twins和梯度提升，通过整合生物检测方法和分子指纹，实现了对未见过的生物检测方法和分子属性的精确预测，该方法在数据稀缺的情况下展现出了优秀的性能。 |
| [^79] | [From LLM to Conversational Agent: A Memory Enhanced Architecture with Fine-Tuning of Large Language Models.](http://arxiv.org/abs/2401.02777) | 这项工作介绍了一种名为RAISE的架构，它将大型语言模型（LLMs）如GPT-4整合到对话代理中，通过引入双组件记忆系统来增强代理在多轮对话中的可控性和适应性。预liminary evaluations表明，RAISE在房地产销售领域具有优势，并具有广泛应用的潜力。 |
| [^80] | [Survey of 3D Human Body Pose and Shape Estimation Methods for Contemporary Dance Applications.](http://arxiv.org/abs/2401.02383) | 这项研究调查了现代舞和表演艺术中的三维人体形状和姿势估计方法，发现多帧方法在现代舞蹈表演中的姿势估计方面比单帧方法效果更好。 |
| [^81] | [FENet: Focusing Enhanced Network for Lane Detection.](http://arxiv.org/abs/2312.17163) | FENet是一个增强聚焦网络用于精准车道检测，通过聚焦采样和部分视野评估等创新方法，显著提高了检测准确性，尤其适用于曲线和远距离车道，在安全性方面具有重要意义。 |
| [^82] | [Semantic Guidance Tuning for Text-To-Image Diffusion Models.](http://arxiv.org/abs/2312.15964) | 本文提出了一种简单的、不需要训练的方法，用于调节文本到图像扩散模型在推理过程中的引导方向，以提高生成图像的语义对齐性。 |
| [^83] | [Auto311: A Confidence-guided Automated System for Non-emergency Calls.](http://arxiv.org/abs/2312.14185) | Auto311是第一个处理非紧急电话的自动化系统，它通过减轻非紧急电话负担，提供快速有效的响应。通过预测事件类型并生成个性化的案件报告，并从对话上下文中提取关键信息来完善报告，系统与主叫人之间的对话结构得到优化。 |
| [^84] | [Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs.](http://arxiv.org/abs/2312.05934) | 该研究比较了无监督的微调和检索增强生成（RAG）这两种常见方法在LLMs中的应用。结果发现，RAG在现有知识和新知识上表现出更好的性能，而LLMs通过无监督的微调学习新的事实信息较困难。 |
| [^85] | [Generative AI enhances individual creativity but reduces the collective diversity of novel content.](http://arxiv.org/abs/2312.00506) | 生成AI增强了个体创造力，但降低了新内容的集体多样性。 |
| [^86] | [War and Peace (WarAgent): Large Language Model-based Multi-Agent Simulation of World Wars.](http://arxiv.org/abs/2311.17227) | 本研究提出了一个名为WarAgent的大语言模型驱动的多智能体AI系统，用于模拟历史国际冲突，并通过评估其效果和研究智能体之间的相互作用，探讨了战争的引发因素和条件。 |
| [^87] | [Perceptions and Detection of AI Use in Manuscript Preparation for Academic Journals.](http://arxiv.org/abs/2311.14720) | 该研究调查了学术界对于在稿件准备中使用AI是否有必要进行披露的观点，并研究了检测器对于学术写作中使用AI的反应。 |
| [^88] | [Meta Prompting for AGI Systems.](http://arxiv.org/abs/2311.11482) | 本文全面研究了元提示技术，这是一种创新方法，重塑了大型语言模型、多模态模型和人工智能系统在问题解决和数据解释方面的应用。通过强调信息的结构和句法，元提示将复杂问题拆解为简单的子问题，提高了效率，并且能够与少样本方法进行公平的比较。同时，本文还提出了元提示用于自动生成提示的方法。 |
| [^89] | [Clover: Closed-Loop Verifiable Code Generation.](http://arxiv.org/abs/2310.17807) | Clover是一种闭环可验证代码生成的范式，通过在代码、docstrings和形式注释之间进行一致性检查，确保生成的代码的正确性。 |
| [^90] | [Solving large flexible job shop scheduling instances by generating a diverse set of scheduling policies with deep reinforcement learning.](http://arxiv.org/abs/2310.15706) | 本文提出了一种能够通过生成多样化的调度策略来解决大型柔性车间调度实例的方法，并应用深度强化学习来优化调度质量。 |
| [^91] | [Towards Zero Shot Learning in Restless Multi-armed Bandits.](http://arxiv.org/abs/2310.14526) | 通过开发一个基于神经网络的预训练模型，我们实现了在不断变化的多臂赌博机中的零样本学习，该模型具有泛化能力，并且能够在特定实例上进行高效微调，同时适用于多行为设置和离散或连续状态空间。 |
| [^92] | [Learning Interpretable Rules for Scalable Data Representation and Classification.](http://arxiv.org/abs/2310.14336) | 这项研究提出了一种名为RRL的新型分类器，通过自动学习可解释的非模糊规则，实现了数据表示和分类的良好可扩展性和解释性。 |
| [^93] | [One-Shot Sensitivity-Aware Mixed Sparsity Pruning for Large Language Models.](http://arxiv.org/abs/2310.09499) | 我们提出了一种基于敏感度感知混合稀疏化剪枝的方法，可以在不重新训练的情况下将大型语言模型剪枝至至少50％的稀疏性，同时保持稀疏性水平和减少剪枝引起的误差。此外，该方法还与量化兼容，可以进一步压缩语言模型。 |
| [^94] | [Syllable-level lyrics generation from melody exploiting character-level language model.](http://arxiv.org/abs/2310.00863) | 该论文提出了一种利用字符级语言模型从旋律中生成音节级歌词的方法，并通过融合语言模型知识和生成器网络进行优化。通过探索ChatGPT的评估方法，以及人工评估，证明了该方法提高了生成歌词的连贯性和正确性。 |
| [^95] | [Adversarial Machine Learning in Latent Representations of Neural Networks.](http://arxiv.org/abs/2309.17401) | 这项研究通过分析分布式深度神经网络对抗性行为的韧性填补了现有研究空白，并发现潜在特征在相同信息失真水平下比输入表示更加韧性，并且对抗性韧性由特征维度和神经网络的泛化能力共同决定。 |
| [^96] | [Creativity Support in the Age of Large Language Models: An Empirical Study Involving Emerging Writers.](http://arxiv.org/abs/2309.12570) | 本文通过实证研究探讨了大型语言模型（LLM）在协助专业作家方面的效用，并发现作家们更倾向于在翻译和审查阶段中寻求LLM的帮助。 |
| [^97] | [MAPLE: Mobile App Prediction Leveraging Large Language model Embeddings.](http://arxiv.org/abs/2309.08648) | MAPLE是一个利用大型语言模型嵌入进行移动应用预测的模型，通过严格测试验证了其在解密复杂模式和理解用户环境方面的能力，并强调了语言模型在不同领域中的广泛适用性。 |
| [^98] | [Data Distribution Bottlenecks in Grounding Language Models to Knowledge Bases.](http://arxiv.org/abs/2309.08345) | 本文通过实验调查揭示了语言模型在与知识库进行连接时的数据分布瓶颈，包括推广到未见域、适应语言变体和在不同数据集之间的可转移性等方面。即使采用数据增强技术，先进的语言模型在多个方面表现出较差的性能。 |
| [^99] | [Dual Relation Alignment for Composed Image Retrieval.](http://arxiv.org/abs/2309.02169) | 本研究提出了双重关系对齐的方法，用于组合图像检索任务。通过利用显性和隐性关系，可以更好地学习网络并提升检索性能。 |
| [^100] | [On CNF formulas irredundant with respect to unit clause propagation.](http://arxiv.org/abs/2309.01750) | 对于单子句传播而言，在CNF公式中不可简化的公式，其大小与最小可等价的公式大小的比值最大为n^2，其中n是变量数量。一般上界不会小于n/ln n倍。 |
| [^101] | [Recommender AI Agent: Integrating Large Language Models for Interactive Recommendations.](http://arxiv.org/abs/2308.16505) | 本论文的创新点是将推荐模型和大型语言模型（LLMs）融合，创建了一个多功能交互式推荐系统，解决了推荐模型在提供解释和参与对话任务方面的困难。 |
| [^102] | [Complementing Onboard Sensors with Satellite Map: A New Perspective for HD Map Construction.](http://arxiv.org/abs/2308.15427) | 本研究通过补充卫星地图，增强了车载传感器构建高精度地图的方法，利用卫星地图的广阔覆盖能力。我们释放了卫星地图瓦片作为nuScenes数据集的补充，同时提出了一个分层融合模块来更好地融合车载传感器与卫星地图的信息。 |
| [^103] | [Efficient Benchmarking (of Language Models).](http://arxiv.org/abs/2308.11696) | 本研究提出了一种名为"Efficient Benchmarking"的问题，旨在智能地减少语言模型评估的计算成本而不降低可靠性，并使用一种名为Decision Impact on Reliability（DIoR）的新度量来评估决策的可靠性。通过HELM基准测试的案例研究，发现只需删除一个低排名模型即可改变领先者，并仅需少量示例即可得到正确的基准测试排名。 |
| [^104] | [SSLRec: A Self-Supervised Learning Library for Recommendation.](http://arxiv.org/abs/2308.05697) | SSLRec是一个自监督学习的推荐系统库，为评估各种SSL增强推荐系统提供了标准化、灵活和综合的框架。 |
| [^105] | [An Open-Source Knowledge Graph Ecosystem for the Life Sciences.](http://arxiv.org/abs/2307.05727) | PheKnowLator是一个开源的知识图谱生态系统，用于自动化构建可定制的FAIR本体化基础的知识图谱，以解决生命科学中的整合挑战。 |
| [^106] | [Give Us the Facts: Enhancing Large Language Models with Knowledge Graphs for Fact-aware Language Modeling.](http://arxiv.org/abs/2306.11489) | 这篇论文研究了如何通过知识图谱增强大型语言模型，提高其生成内容的准确性和对用户查询的回复能力。 |
| [^107] | [Are ChatGPT and Other Similar Systems the Modern Lernaean Hydras of AI?.](http://arxiv.org/abs/2306.09267) | 生成式人工智能系统的崛起引发了版权和创新保护的问题。建议对开源代码许可证进行更改，限制AI系统对代码的访问和使用，并探讨与AI和版权之间的关系引发的问题。 |
| [^108] | [Simple and Controllable Music Generation.](http://arxiv.org/abs/2306.05284) | 本文提出了 MusicGen，一个单一的语言模型，可以在条件描述或旋律特征控制下生成高质量的样本，并且在标准的文本到音乐基准上的实证研究中，该方法优于其他基线模型。 |
| [^109] | [Proximal Policy Gradient Arborescence for Quality Diversity Reinforcement Learning.](http://arxiv.org/abs/2305.13795) | 本论文提出了一种将近端策略优化(PPO)方法与质量多样性(QD)相结合的新型QD-RL方法，用于在高吞吐量、大规模并行化机器人模拟器环境下训练能够在未知动态环境中表现出色的机器人学习智能体。 |
| [^110] | [Scaling laws for language encoding models in fMRI.](http://arxiv.org/abs/2305.11863) | 本文揭示了基于fMRI的语言编码模型预测性能与模型大小呈对数线性关系，在125M到30B参数模型进行规模扩展时，表现提高了约15％。 |
| [^111] | [Incorporating Attribution Importance for Improving Faithfulness Metrics.](http://arxiv.org/abs/2305.10496) | 本研究提出了一种软删除标准来评估归因方法的忠实度，该方法随机遮盖标记的部分向量表示，这种方法比现有的硬删除标准更准确。 |
| [^112] | [Qualifying Chinese Medical Licensing Examination with Knowledge Enhanced Generative Pre-training Model.](http://arxiv.org/abs/2305.10163) | 本研究通过在ChatGPT中集成医学领域知识和启用少样本学习的新方法，在中国国家医学执业医师资格考试中取得成功，这为建立在自然语言处理技术和医学领域知识的创新应用提供了可能。 |
| [^113] | [Machine-learned Adversarial Attacks against Fault Prediction Systems in Smart Electrical Grids.](http://arxiv.org/abs/2303.18136) | 该论文提出了针对智能电网故障预测系统的机器学习对抗攻击的研究，证明智能电网中使用的深度神经网络方法容易受到对抗性攻击，并突出了目前在智能电网中的机器学习算法存在对各种对抗性攻击的弱点。 |
| [^114] | [News and Load: A Quantitative Exploration of Natural Language Processing Applications for Forecasting Day-ahead Electricity System Demand.](http://arxiv.org/abs/2301.07535) | 本文利用自然语言处理技术研究了电力需求和社会事件之间的关联，并通过分析词频、公众情感、主题分布和词嵌入等文本特征，改进了次日的电力需求预测。研究结果提供了新的视角，证实了从非结构化文本中改进预测的可行性。 |
| [^115] | [Reachability Verification Based Reliability Assessment for Deep Reinforcement Learning Controlled Robotics and Autonomous Systems.](http://arxiv.org/abs/2210.14991) | 本文提出了一个基于可达性验证的深度强化学习控制的机器人和自主系统的可靠性评估框架，通过验证证据生成对于不准确观测的安全属性检查，提供了局部和整体的可靠性量化指标。 |
| [^116] | [Dynamic Sensor Matching based on Geomagnetic Inertial Navigation.](http://arxiv.org/abs/2208.06233) | 本研究提出了一种基于地磁惯性导航的动态传感器匹配方法，通过将多传感器数据转化为地球的磁场作为世界坐标系来实现对动态环境的重建。 |
| [^117] | [Estimating counterfactual treatment outcomes over time in complex multi-agent scenarios.](http://arxiv.org/abs/2206.01900) | 本论文提出了一个可解释的反事实循环网络，用于在复杂的多智能体场景中估计干预效果。该模型考虑了时间变化的多智能体关系和协变量反事实预测的复杂结构，能够准确评估个体治疗效果，并提供解释性。 |

# 详细

[^1]: 一种针对非法歌曲翻唱的主动性双重防护机制：基于歌唱声音转换的能力

    A Proactive and Dual Prevention Mechanism against Illegal Song Covers empowered by Singing Voice Conversion. (arXiv:2401.17133v1 [cs.SD])

    [http://arxiv.org/abs/2401.17133](http://arxiv.org/abs/2401.17133)

    这项工作提出了一种主动性的双重防护机制，通过引入人类无法察觉的扰动，干扰歌唱声音转换的生成过程，防止未经授权的基于歌唱声音转换的非法歌曲翻唱。该机制既扰乱了歌手身份，又扰乱了歌词，使得歌唱声音既不模仿目标歌手，也不保留原始歌词。

    

    歌唱声音转换(SVC)通过将一个歌手的歌唱声音转换成另一个目标歌手的歌唱声音，并使用原始歌词和旋律，自动化了歌曲翻唱。然而，这引发了对版权和公民权利的严重担忧。本研究提出了 SongBsAb，这是第一个主动性方法，用于减轻未经授权的基于 SVC 的非法歌曲翻唱。SongBsAb 在发布歌唱声音之前引入了人类无法察觉的扰动，这样当它们被使用时，SVC 的生成过程将被干扰，导致意外的歌唱声音。 SongBsAb 具有双重预防效果，引起歌手身份和歌词的混乱，即 SVC 覆盖的歌唱声音既不模仿目标歌手，也不保留原始歌词。为了提高扰动的不可察觉性，我们使用了一个以伴奏曲作为额外掩蔽者的基于心理声学模型的损失模型。

    Singing voice conversion (SVC) automates song covers by converting one singer's singing voice into another target singer's singing voice with the original lyrics and melody. However, it raises serious concerns about copyright and civil right infringements to multiple entities. This work proposes SongBsAb, the first proactive approach to mitigate unauthorized SVC-based illegal song covers. SongBsAb introduces human-imperceptible perturbations to singing voices before releasing them, so that when they are used, the generation process of SVC will be interfered, resulting in unexpected singing voices. SongBsAb features a dual prevention effect by causing both (singer) identity disruption and lyric disruption, namely, the SVC-covered singing voice neither imitates the target singer nor preserves the original lyrics. To improve the imperceptibility of perturbations, we refine a psychoacoustic model-based loss with the backing track as an additional masker, a unique accompanying element for s
    
[^2]: 增强的360度实时音频视觉声景音事件定位和检测

    Enhanced Sound Event Localization and Detection in Real 360-degree audio-visual soundscapes. (arXiv:2401.17129v1 [cs.SD])

    [http://arxiv.org/abs/2401.17129](http://arxiv.org/abs/2401.17129)

    这份论文介绍了一种增强的音频视觉声事件定位和检测网络，通过合并音频和视频信息提升了系统性能，并利用目标检测器和数据增强技术进一步改进了模型。

    

    这份技术报告详细介绍了我们在构建增强的音频视觉声事件定位和检测（SELD）网络方面的工作。我们在仅音频的SELDnet23模型基础上进行改进，将音频和视频信息在仅音频网络的门控循环单元（GRU）之前合并。我们的模型利用了YOLO和DETIC目标检测器。我们还建立了一个实施音频视觉数据增强和音频视觉合成数据生成的框架。我们提供了一个音频视觉SELDnet系统，其性能优于现有的音频视觉SELD基线。

    This technical report details our work towards building an enhanced audio-visual sound event localization and detection (SELD) network. We build on top of the audio-only SELDnet23 model and adapt it to be audio-visual by merging both audio and video information prior to the gated recurrent unit (GRU) of the audio-only network. Our model leverages YOLO and DETIC object detectors. We also build a framework that implements audio-visual data augmentation and audio-visual synthetic data generation. We deliver an audio-visual SELDnet system that outperforms the existing audio-visual SELD baseline.
    
[^3]: 无监督发现当图深度生成模型出现交织时的可操纵因素

    Unsupervised Discovery of Steerable Factors When Graph Deep Generative Models Are Entangled. (arXiv:2401.17123v1 [cs.LG])

    [http://arxiv.org/abs/2401.17123](http://arxiv.org/abs/2401.17123)

    这项工作提出了GraphCG方法，用于在预训练图深度生成模型的潜在空间中无监督发现可操纵因素，通过最大化语义丰富方向之间的互信息来学习这些可操纵因素。实验证明GraphCG优于其他竞争方法。

    

    深度生成模型(DGMs)广泛用于图数据。然而，对于这种预训练图DGMs的潜在空间的理解研究相对较少。这些理解有潜力为重要任务提供有益的指导，例如图的可控制生成。因此，在这项工作中，我们对这个问题很感兴趣，并提出GraphCG，一种用于在预训练图DGMs的潜在空间中无监督发现可操纵因素的方法。我们首先使用六个解缠度度量标准检验了三个预训练图DGMs的表示空间，并观察到预训练表示空间是交织的。受这个观察的启发，GraphCG通过最大化语义丰富方向之间的互信息来学习可操纵因素，沿着相同方向移动的图将共享相同的可操纵因素。我们定量验证了GraphCG优于其他四个竞争方法。

    Deep generative models (DGMs) have been widely developed for graph data. However, much less investigation has been carried out on understanding the latent space of such pretrained graph DGMs. These understandings possess the potential to provide constructive guidelines for crucial tasks, such as graph controllable generation. Thus in this work, we are interested in studying this problem and propose GraphCG, a method for the unsupervised discovery of steerable factors in the latent space of pretrained graph DGMs. We first examine the representation space of three pretrained graph DGMs with six disentanglement metrics, and we observe that the pretrained representation space is entangled. Motivated by this observation, GraphCG learns the steerable factors via maximizing the mutual information between semantic-rich directions, where the controlled graph moving along the same direction will share the same steerable factors. We quantitatively verify that GraphCG outperforms four competitive 
    
[^4]: 在未观测到的网络位置使用数据驱动的宏观模型进行交通估计

    Traffic estimation in unobserved network locations using data-driven macroscopic models. (arXiv:2401.17095v1 [cs.LG])

    [http://arxiv.org/abs/2401.17095](http://arxiv.org/abs/2401.17095)

    本文提出了一种利用宏观模型和多源时空数据的方法来估计无法观测到的网络位置的交通流量和行驶时间。该方法可以在传感器覆盖范围有限的情况下进行准确的估计，并满足基本的流量守恒约束条件。

    

    本文利用宏观模型和自动交通计数器和探测车辆收集的多源时空数据，准确估计无法获得这些测量数据的路段的交通流量和行驶时间。这个问题在交通规划应用中是关键的，因为传感器覆盖范围有限，规划的干预措施会对整个网络产生影响。提出的模型命名为宏观交通估计器（MaTE），可以仅使用这些数量的观测测量来进行网络范围的交通流量和行驶时间估计。由于MaTE基于宏观流量理论，所有参数和变量都是可以解释的。估计的交通流量满足基本的流量守恒约束条件，并且与估计的行驶时间呈递增的单调关系。将基于logit的随机交通分配作为流量行为路由的原则使得模型在可微方面具有完全可区分性。

    This paper leverages macroscopic models and multi-source spatiotemporal data collected from automatic traffic counters and probe vehicles to accurately estimate traffic flow and travel time in links where these measurements are unavailable. This problem is critical in transportation planning applications where the sensor coverage is low and the planned interventions have network-wide impacts. The proposed model, named the Macroscopic Traffic Estimator (MaTE), can perform network-wide estimations of traffic flow and travel time only using the set of observed measurements of these quantities. Because MaTE is grounded in macroscopic flow theory, all parameters and variables are interpretable. The estimated traffic flow satisfies fundamental flow conservation constraints and exhibits an increasing monotonic relationship with the estimated travel time. Using logit-based stochastic traffic assignment as the principle for routing flow behavior makes the model fully differentiable with respect
    
[^5]: BlockFusion: 使用潜在三平面外推扩展的可扩展三维场景生成模型

    BlockFusion: Expandable 3D Scene Generation using Latent Tri-plane Extrapolation. (arXiv:2401.17053v1 [cs.CV])

    [http://arxiv.org/abs/2401.17053](http://arxiv.org/abs/2401.17053)

    BlockFusion是一种使用扩散和外推技术生成三维场景的模型，能无缝地添加新的块以扩展场景。采用混合神经场和潜在三平面空间来保证高质量和多样化的生成结果。

    

    我们提出了BlockFusion，一种基于扩散的模型，以单位块形式生成三维场景，并无缝地添加新的块以扩展场景。BlockFusion使用从完整的三维场景中随机裁剪的3D块数据集进行训练。通过块拟合，将所有训练块转换为混合神经场：它包含几何特征的三平面，以及用于解码有符号距离值的多层感知机(MLP)。采用变分自动编码器将三平面压缩到潜在三平面空间，并在其上执行去噪扩散过程。对潜在表示应用扩散，可以实现高质量和多样化的三维场景生成。在生成过程中扩展场景时，只需将空块添加到与当前场景重叠，并外推现有的潜在三平面以填充新块。外推过程通过使用特征对生成过程进行约束来完成。

    We present BlockFusion, a diffusion-based model that generates 3D scenes as unit blocks and seamlessly incorporates new blocks to extend the scene. BlockFusion is trained using datasets of 3D blocks that are randomly cropped from complete 3D scene meshes. Through per-block fitting, all training blocks are converted into the hybrid neural fields: with a tri-plane containing the geometry features, followed by a Multi-layer Perceptron (MLP) for decoding the signed distance values. A variational auto-encoder is employed to compress the tri-planes into the latent tri-plane space, on which the denoising diffusion process is performed. Diffusion applied to the latent representations allows for high-quality and diverse 3D scene generation. To expand a scene during generation, one needs only to append empty blocks to overlap with the current scene and extrapolate existing latent tri-planes to populate new blocks. The extrapolation is done by conditioning the generation process with the feature 
    
[^6]: ViTree: 单路径神经树用于逐步可解释的细粒度视觉分类

    ViTree: Single-path Neural Tree for Step-wise Interpretable Fine-grained Visual Categorization. (arXiv:2401.17050v1 [cs.CV])

    [http://arxiv.org/abs/2401.17050](http://arxiv.org/abs/2401.17050)

    ViTree是一种用于细粒度视觉分类的新方法，通过结合视觉变换器和神经决策树，逐步突出信息丰富的局部区域，并选择单个树路径来提高模型的可解释性。

    

    随着计算机视觉的不断发展和广泛应用于各个领域，深度学习模型的可解释性变得至关重要。现有的方法常常采用事后技术或原型来解释决策过程，这种方法可能间接并且缺乏内在的说明。在这项研究中，我们引入了ViTree，一种用于细粒度视觉分类的新方法，它将流行的视觉变换器作为特征提取骨干，与神经决策树相结合。通过遍历树路径，ViTree有效地从变换器处理的特征中选择补丁来突出信息丰富的局部区域，从而逐步优化表示。与以前依赖软分布或路径集合的基于树的模型不同，ViTree选择单个树路径，提供更清晰、更简化的决策过程。这种补丁和路径的选择性提高了ViTree模型的可解释性，从而实现了更好的模型解释能力。

    As computer vision continues to advance and finds widespread applications across various domains, the need for interpretability in deep learning models becomes paramount. Existing methods often resort to post-hoc techniques or prototypes to explain the decision-making process, which can be indirect and lack intrinsic illustration. In this research, we introduce ViTree, a novel approach for fine-grained visual categorization that combines the popular vision transformer as a feature extraction backbone with neural decision trees. By traversing the tree paths, ViTree effectively selects patches from transformer-processed features to highlight informative local regions, thereby refining representations in a step-wise manner. Unlike previous tree-based models that rely on soft distributions or ensembles of paths, ViTree selects a single tree path, offering a clearer and simpler decision-making process. This patch and path selectivity enhances model interpretability of ViTree, enabling bette
    
[^7]: 在概率逻辑编程中解释解释

    Explaining Explanations in Probabilistic Logic Programming. (arXiv:2401.17045v1 [cs.AI])

    [http://arxiv.org/abs/2401.17045](http://arxiv.org/abs/2401.17045)

    该论文介绍了基于概率逻辑编程的解释解释方法，以解决在不透明系统中生成合适解释的困难。

    

    基于人工智能的工具的出现也导致了产生人类可理解的解释的需求。在一些方法中，系统是不透明的（通常被称为“黑盒子”），这使得生成适当的解释变得困难。然而，在概率逻辑编程中，我们考虑了逻辑编程（用于知识表示）和概率（用于建模不确定性）的结合。在这个设置中，可以说模型是可以解释的，这方便了对模型的理解。然而，对于特定的查询，通常的“解释”的概念是与模型的每个随机变量的选择集相关联的。不幸的是，这个集合没有因果结构，实际上，一些选择实际上与所考虑的查询无关。为了克服这些缺点，我们提出了一种基于查询驱动推理定义的解释解释方法。

    The emergence of tools based on artificial intelligence has also led to the need of producing explanations which are understandable by a human being. In some approaches, the system is not transparent (often referred to as a "black box"), making it difficult to generate appropriate explanations. In this work, though, we consider probabilistic logic programming, a combination of logic programming (for knowledge representation) and probability (to model uncertainty). In this setting, one can say that models are interpretable, which eases its understanding. However, given a particular query, the usual notion of "explanation" is associated with a set of choices, one for each random variable of the model. Unfortunately, this set does not have a causal structure and, in fact, some of the choices are actually irrelevant to the considered query. In order to overcome these shortcomings, we present an approach to explaining explanations which is based on the definition of a query-driven inference
    
[^8]: 可扩展的多智能体路径规划机制设计

    Scalable Mechanism Design for Multi-Agent Path Finding. (arXiv:2401.17044v1 [cs.AI])

    [http://arxiv.org/abs/2401.17044](http://arxiv.org/abs/2401.17044)

    这项工作介绍了可扩展的多智能体路径规划机制设计问题，并提出了三种对策。

    

    多智能体路径规划(MAPF)涉及确定多个智能体同时穿过共享区域前往特定目标位置的路径。这个问题在处理大量智能体时具有计算复杂性，尤其在像自动驾驶车辆协调这样的实际应用中。找到最优解通常是计算上不可行的，因此使用近似算法至关重要。同时，智能体可能以自私和策略性的方式行动，如果对MAPF算法有利，可能会歪曲其目标。虽然机制设计领域提供了用于对齐激励的工具，但如果不仔细考虑使用这些工具可能会在仅有近似最优结果时失败。由于近似对于可扩展的MAPF算法至关重要，这带来了重大挑战。在这项工作中，我们介绍了可扩展MAPF机制设计问题，并提出了三种对策。

    Multi-Agent Path Finding (MAPF) involves determining paths for multiple agents to travel simultaneously through a shared area toward particular goal locations. This problem is computationally complex, especially when dealing with large numbers of agents, as is common in realistic applications like autonomous vehicle coordination. Finding an optimal solution is often computationally infeasible, making the use of approximate algorithms essential. Adding to the complexity, agents might act in a self-interested and strategic way, possibly misrepresenting their goals to the MAPF algorithm if it benefits them. Although the field of mechanism design offers tools to align incentives, using these tools without careful consideration can fail when only having access to approximately optimal outcomes. Since approximations are crucial for scalable MAPF algorithms, this poses a significant challenge. In this work, we introduce the problem of scalable mechanism design for MAPF and propose three strat
    
[^9]: 优化大规模语言模型用于漏洞检测

    Finetuning Large Language Models for Vulnerability Detection. (arXiv:2401.17010v1 [cs.CR])

    [http://arxiv.org/abs/2401.17010](http://arxiv.org/abs/2401.17010)

    本文优化了大规模语言模型用于源代码中的漏洞检测任务，通过微调最先进的代码语言模型WizardCoder并改进其训练过程和策略，实现了对漏洞数据集的分类性能的提升。

    

    本文介绍了对大规模语言模型进行微调，并将其用于源代码中的漏洞检测的结果。我们利用最先进的语言模型StarCoder的改进版本WizardCoder，并通过进一步微调将其适应于漏洞检测任务。为了加速训练，我们修改了WizardCoder的训练过程，并探究了最佳的训练策略。针对负样本远多于正样本的不平衡数据集，我们还尝试了不同的技术来提高分类性能。微调后的WizardCoder模型在平衡和不平衡的漏洞数据集上在ROC AUC和F1度量上实现了改进，证明了将预训练的语言模型用于源代码中的漏洞检测的有效性。主要贡献包括对最先进的代码语言模型WizardCoder进行微调，提高其训练速度而不影响性能，并对训练过程和策略进行了优化。

    This paper presents the results of finetuning large language models (LLMs) for the task of detecting vulnerabilities in source code. We leverage WizardCoder, a recent improvement of the state-of-the-art LLM StarCoder, and adapt it for vulnerability detection through further finetuning. To accelerate training, we modify WizardCoder's training procedure, also we investigate optimal training regimes. For the imbalanced dataset with many more negative examples than positive, we also explore different techniques to improve classification performance. The finetuned WizardCoder model achieves improvement in ROC AUC and F1 measures on balanced and imbalanced vulnerability datasets over CodeBERT-like model, demonstrating the effectiveness of adapting pretrained LLMs for vulnerability detection in source code. The key contributions are finetuning the state-of-the-art code LLM, WizardCoder, increasing its training speed without the performance harm, optimizing the training procedure and regimes, 
    
[^10]: ActDroid：一种用于Android恶意软件检测的主动学习框架

    ActDroid: An active learning framework for Android malware detection. (arXiv:2401.16982v1 [cs.CR])

    [http://arxiv.org/abs/2401.16982](http://arxiv.org/abs/2401.16982)

    ActDroid是一种用于Android恶意软件检测的主动学习框架，能够在及时和经济有效的情况下对恶意应用程序进行准确分类，帮助解决恶意软件检测的标记问题和概念漂移问题。

    

    Android的日益普及要求恶意软件检测系统能够跟上新软件发布的速度。根据最近的研究，每12秒就有一种新的恶意软件出现在互联网上。为了解决这个问题，我们将Android恶意软件检测视为一个流数据问题，并探索使用主动在线学习作为一种及时和经济有效的标记应用程序的手段。我们的框架实现了高达96％的准确率，只需对24％的训练数据进行标记，并补偿了应用程序发布和标记之间发生的概念漂移。我们还考虑了Android恶意软件检测中在线学习的更广泛实用性，并系统地探讨了使用不同静态、动态和混合特征集对恶意软件进行分类的权衡。

    The growing popularity of Android requires malware detection systems that can keep up with the pace of new software being released. According to a recent study, a new piece of malware appears online every 12 seconds. To address this, we treat Android malware detection as a streaming data problem and explore the use of active online learning as a means of mitigating the problem of labelling applications in a timely and cost-effective manner. Our resulting framework achieves accuracies of up to 96\%, requires as little of 24\% of the training data to be labelled, and compensates for concept drift that occurs between the release and labelling of an application. We also consider the broader practicalities of online learning within Android malware detection, and systematically explore the trade-offs between using different static, dynamic and hybrid feature sets to classify malware.
    
[^11]: CORE: 通过强化学习实现可扩展高效的因果推断

    CORE: Towards Scalable and Efficient Causal Discovery with Reinforcement Learning. (arXiv:2401.16974v1 [cs.LG])

    [http://arxiv.org/abs/2401.16974](http://arxiv.org/abs/2401.16974)

    CORE是一种基于深度强化学习的因果推断和干预规划方法，可以高效地揭示因果结构，并在结构估计准确性和样本效率方面表现优于现有方法。

    

    因果推断是从数据中推断因果结构的具有挑战性的任务。受到Pearl的因果层次结构（Causal Hierarchy）的启发，该论文呼吁将干预引入到机器学习研究中。强化学习提供了一个方便的框架，用于实现这种主动的学习方法。本文提出了CORE，一种基于深度强化学习的因果推断和干预规划方法。CORE学习从数据中顺序重建因果图，并学习执行信息丰富的干预。我们的结果表明，CORE可以推广到未见过的图，并高效地揭示因果结构。此外，CORE可以扩展到具有多达10个变量的更大的图，并在结构估计准确性和样本效率方面优于现有方法。

    Causal discovery is the challenging task of inferring causal structure from data. Motivated by Pearl's Causal Hierarchy (PCH), which tells us that passive observations alone are not enough to distinguish correlation from causation, there has been a recent push to incorporate interventions into machine learning research. Reinforcement learning provides a convenient framework for such an active approach to learning. This paper presents CORE, a deep reinforcement learning-based approach for causal discovery and intervention planning. CORE learns to sequentially reconstruct causal graphs from data while learning to perform informative interventions. Our results demonstrate that CORE generalizes to unseen graphs and efficiently uncovers causal structures. Furthermore, CORE scales to larger graphs with up to 10 variables and outperforms existing approaches in structure estimation accuracy and sample efficiency. All relevant code and supplementary material can be found at https://github.com/s
    
[^12]: 两个头胜于一: 为实体对齐整合知识图谱和大型语言模型的知识

    Two Heads Are Better Than One: Integrating Knowledge from Knowledge Graphs and Large Language Models for Entity Alignment. (arXiv:2401.16960v1 [cs.CL])

    [http://arxiv.org/abs/2401.16960](http://arxiv.org/abs/2401.16960)

    本研究提出了一种大型语言模型增强的实体对齐框架（LLMEA），将知识图谱中的结构知识与大型语言模型中的语义知识相结合，以提升实体对齐的效果。

    

    实体对齐是创建更全面的知识图谱的先决条件，涉及在不同的知识图谱中定位等价实体。目前的实体对齐方法主要利用知识嵌入模型获取包含各种相似性（结构、关系和属性）的实体嵌入。然后通过基于注意力的信息融合机制进行集成。尽管取得了一定的进展，但由于固有的异质性，有效利用多方面的信息仍然具有挑战性。此外，虽然大型语言模型（LLM）通过隐式捕捉实体语义，在各种下游任务上表现出色，但这种隐式知识尚未被用于实体对齐。在本研究中，我们提出了一个增强实体对齐的大型语言模型增强实体对齐框架（LLMEA），将知识图谱中的结构知识与LLM中的语义知识相结合，以增强实体对齐。

    Entity alignment, which is a prerequisite for creating a more comprehensive Knowledge Graph (KG), involves pinpointing equivalent entities across disparate KGs. Contemporary methods for entity alignment have predominantly utilized knowledge embedding models to procure entity embeddings that encapsulate various similarities-structural, relational, and attributive. These embeddings are then integrated through attention-based information fusion mechanisms. Despite this progress, effectively harnessing multifaceted information remains challenging due to inherent heterogeneity. Moreover, while Large Language Models (LLMs) have exhibited exceptional performance across diverse downstream tasks by implicitly capturing entity semantics, this implicit knowledge has yet to be exploited for entity alignment. In this study, we propose a Large Language Model-enhanced Entity Alignment framework (LLMEA), integrating structural knowledge from KGs with semantic knowledge from LLMs to enhance entity alig
    
[^13]: 强化学习用于多功能、动态和稳健的双足运动控制

    Reinforcement Learning for Versatile, Dynamic, and Robust Bipedal Locomotion Control. (arXiv:2401.16889v1 [cs.RO])

    [http://arxiv.org/abs/2401.16889](http://arxiv.org/abs/2401.16889)

    本论文使用深度强化学习创建了一种通用的双足机器人动态运动控制器，该控制器可以应用于多种动态双足技能，并且在模拟环境和实际环境中展现出了优越性能。

    

    本论文提出了一项关于使用深度强化学习（RL）创建双足机器人动态运动控制器的综合研究。我们不仅仅专注于单一的运动技能，而是开发了一种通用的控制解决方案，可以用于一系列动态双足技能，从周期性行走和奔跑到非周期性跳跃和站立。我们基于RL的控制器采用了一种新颖的双历史架构，利用机器人的长期和短期输入/输出（I/O）历史。通过提出的端到端RL方法进行训练时，这种控制架构在模拟环境和实际环境中的多样化技能上始终表现优于其他方法。该研究还深入探讨了所提出的RL系统在开发运动控制器方面引入的适应性和稳健性。我们证明了所提出的架构可以适应时间不变的动力学变化和时间变化的变化，如接触事件，通过有效地

    This paper presents a comprehensive study on using deep reinforcement learning (RL) to create dynamic locomotion controllers for bipedal robots. Going beyond focusing on a single locomotion skill, we develop a general control solution that can be used for a range of dynamic bipedal skills, from periodic walking and running to aperiodic jumping and standing. Our RL-based controller incorporates a novel dual-history architecture, utilizing both a long-term and short-term input/output (I/O) history of the robot. This control architecture, when trained through the proposed end-to-end RL approach, consistently outperforms other methods across a diverse range of skills in both simulation and the real world.The study also delves into the adaptivity and robustness introduced by the proposed RL system in developing locomotion controllers. We demonstrate that the proposed architecture can adapt to both time-invariant dynamics shifts and time-variant changes, such as contact events, by effectivel
    
[^14]: 变形图像配准中的B样条和网格多目标变形模型的对比研究

    A Tournament of Transformation Models: B-Spline-based vs. Mesh-based Multi-Objective Deformable Image Registration. (arXiv:2401.16867v1 [cs.CV])

    [http://arxiv.org/abs/2401.16867](http://arxiv.org/abs/2401.16867)

    本论文对比了B样条模型和网格模型两种常用的变形模型，在实践中它们使用了不同的优化方法。同时，论文强调了通过多目标优化方法可以获得更全面的图像配准效果。

    

    变换模型是任何可变形图像配准方法的关键组成部分。它提供了图像间物理变形的表示，从而定义了可以找到的配准范围和逼真度。B样条模型和网格模型是两种流行的选择。虽然这两种模型都已经得到了详细研究，但由于实践中使用了非常不同的优化方法，因此尚未进行直接比较。B样条模型主要使用梯度下降方法进行优化，而网格模型通常使用有限元方法求解器或进化算法进行优化。多目标优化方法旨在寻找一组高质量的权衡注册结果，在可变形图像配准中越来越受到重视。由于这些方法寻找一组多样的注册结果，它们可以提供更完整的图像配准效果。

    The transformation model is an essential component of any deformable image registration approach. It provides a representation of physical deformations between images, thereby defining the range and realism of registrations that can be found. Two types of transformation models have emerged as popular choices: B-spline models and mesh models. Although both models have been investigated in detail, a direct comparison has not yet been made, since the models are optimized using very different optimization methods in practice. B-spline models are predominantly optimized using gradient-descent methods, while mesh models are typically optimized using finite-element method solvers or evolutionary algorithms. Multi-objective optimization methods, which aim to find a diverse set of high-quality trade-off registrations, are increasingly acknowledged to be important in deformable image registration. Since these methods search for a diverse set of registrations, they can provide a more complete pic
    
[^15]: 通过增加表示来编码时间统计空间先验

    Encoding Temporal Statistical-space Priors via Augmented Representation. (arXiv:2401.16808v1 [cs.LG])

    [http://arxiv.org/abs/2401.16808](http://arxiv.org/abs/2401.16808)

    通过增加表示的方式编码时间统计空间先验，以应对时间序列数据建模中的挑战。我们的方法在两个数据集上的实证推广性能明显优于五个最新的基准方法。具有高度模块化性质的方法适用于各种场景。

    

    时间序列数据建模仍然是一个普遍存在的问题，因为时间维度与许多领域密切相关。尽管在时间序列预测方面取得了显著进展，但高噪声信号比、非正态性、非平稳性和数据缺乏仍然是挑战从业者的问题。为此，我们利用一种简单的表示增强技术来克服这些挑战。我们的增强表示在每个时间步骤上作为统计空间先验进行编码。作为响应，我们将我们的方法命名为统计空间增强表示（SSAR）。基于高维数据生成过程，启发了我们的表示增强。我们在两个数据集上对两个下游时间学习算法的经验泛化性能进行了严格的检查。我们的方法明显击败了五个最新的基准线。此外，我们的方法具有高度模块化的性质，可以轻松应用于各种情况。最后，我们提供了全面的理论视角。

    Modeling time series data remains a pervasive issue as the temporal dimension is inherent to numerous domains. Despite significant strides in time series forecasting, high noise-to-signal ratio, non-normality, non-stationarity, and lack of data continue challenging practitioners. In response, we leverage a simple representation augmentation technique to overcome these challenges. Our augmented representation acts as a statistical-space prior encoded at each time step. In response, we name our method Statistical-space Augmented Representation (SSAR). The underlying high-dimensional data-generating process inspires our representation augmentation. We rigorously examine the empirical generalization performance on two data sets with two downstream temporal learning algorithms. Our approach significantly beats all five up-to-date baselines. Moreover, the highly modular nature of our approach can easily be applied to various settings. Lastly, fully-fledged theoretical perspectives are availa
    
[^16]: 在科学交流中检测LLM辅助写作：我们已经到达了吗？

    Detecting LLM-Assisted Writing in Scientific Communication: Are We There Yet?. (arXiv:2401.16807v1 [cs.IR])

    [http://arxiv.org/abs/2401.16807](http://arxiv.org/abs/2401.16807)

    这项研究评估了四种先进的文本检测器对LLM辅助写作的表现，发现它们的性能不如一个简单的检测器。研究认为需要开发专门用于LLM辅助写作的特定检测器，以解决当前承认实践中的挑战。

    

    大型语言模型（LLMs），如ChatGPT，在文本生成方面产生了重大影响，尤其是在写作辅助领域。尽管伦理考虑强调了在科学交流中透明地承认LLM的使用的重要性，但真实的承认仍然很少见。鼓励准确承认LLM辅助写作的一个潜在途径涉及使用自动检测器。我们对四个前沿的LLM生成文本检测器进行了评估，发现它们的性能不如一个简单的临时检测器，该检测器设计用于识别在LLM大量出现时的突然写作风格变化。我们认为，开发专门用于LLM辅助写作检测的专用检测器是必要的。这样的检测器可以在促进对LLM参与科学交流的更真实认可、解决当前承认实践中的挑战方面发挥关键作用。

    Large Language Models (LLMs), exemplified by ChatGPT, have significantly reshaped text generation, particularly in the realm of writing assistance. While ethical considerations underscore the importance of transparently acknowledging LLM use, especially in scientific communication, genuine acknowledgment remains infrequent. A potential avenue to encourage accurate acknowledging of LLM-assisted writing involves employing automated detectors. Our evaluation of four cutting-edge LLM-generated text detectors reveals their suboptimal performance compared to a simple ad-hoc detector designed to identify abrupt writing style changes around the time of LLM proliferation. We contend that the development of specialized detectors exclusively dedicated to LLM-assisted writing detection is necessary. Such detectors could play a crucial role in fostering more authentic recognition of LLM involvement in scientific communication, addressing the current challenges in acknowledgment practices.
    
[^17]: 基于性能洞察的人工智能驱动的足球转会费用预测

    Performance Insights-based AI-driven Football Transfer Fee Prediction. (arXiv:2401.16795v1 [cs.LG])

    [http://arxiv.org/abs/2401.16795](http://arxiv.org/abs/2401.16795)

    该研究开发了一种利用人工智能的方法，可以预测足球球员的转会费用。这可以帮助俱乐部做出更好的决策，提高表现并增加俱乐部的预算。

    

    我们开发了一种人工智能方法来预测足球球员的转会费用。该模型可以帮助俱乐部在购买和出售球员时做出更好的决策，从而提高表现和增加俱乐部预算。通过收集球员表现、转会费用和其他可能影响球员价值的因素的数据，我们训练了一个能够准确预测球员对比赛影响的机器学习模型。我们进一步将所得结果作为转会费用预测器的特征之一。该模型可以帮助俱乐部识别被低估的球员，并在出售时获得利润。它还可以帮助俱乐部避免为球员支付过高费用。我们相信我们的模型可以成为足球俱乐部的有价值工具，为他们在球员招募和转会方面做出更好的决策。

    We developed an artificial intelligence approach to predict the transfer fee of a football player. This model can help clubs make better decisions about which players to buy and sell, which can lead to improved performance and increased club budgets. Having collected data on player performance, transfer fees, and other factors that might affect a player's value, we then used this data to train a machine learning model that can accurately predict a player's impact on the game. We further passed the obtained results as one of the features to the predictor of transfer fees. The model can help clubs identify players who are undervalued and who could be sold for a profit. It can also help clubs avoid overpaying for players. We believe that our model can be a valuable tool for football clubs. It can help them make better decisions about player recruitment and transfers.
    
[^18]: 大型语言模型作为评估者是否可信？通过代理辩论进行可扩展的元评估来评估LLMs

    Can Large Language Models be Trusted for Evaluation? Scalable Meta-Evaluation of LLMs as Evaluators via Agent Debate. (arXiv:2401.16788v1 [cs.CL])

    [http://arxiv.org/abs/2401.16788](http://arxiv.org/abs/2401.16788)

    本论文提出了ScaleEval，一个基于代理辩论的元评估框架，通过利用多个交流型LLM代理的能力来有效、可靠、高效地评估LLMs在不同任务和场景中作为评估者的性能。

    

    尽管大型语言模型（LLMs）在各种任务和场景中具有实用性，但要在不同的上下文中可靠地评估LLMs仍然具有挑战性。现代评估方法通常使用LLMs来评估LLMs生成的响应。然而，用于评估这些LLMs作为评估者的元评估通常受现有基准的覆盖范围限制，或者需要大量的人工标注。这凸显了迫切需要可扩展的元评估方法，能够有效、可靠、高效地评估LLMs在各种任务和场景中作为评估者的性能，特别是在潜在的新的、用户定义的场景中。为了填补这一空白，我们提出了ScaleEval，这是一个代理辩论辅助的元评估框架，利用多个交流型LLM代理的能力。这个框架支持多轮讨论，以帮助人工标注者判断最具能力的

    Despite the utility of Large Language Models (LLMs) across a wide range of tasks and scenarios, developing a method for reliably evaluating LLMs across varied contexts continues to be challenging. Modern evaluation approaches often use LLMs to assess responses generated by LLMs. However, the meta-evaluation conducted to assess the effectiveness of these LLMs as evaluators is typically constrained by the coverage of existing benchmarks or requires extensive human annotation. This underscores the urgency of methods for scalable meta-evaluation that can effectively, reliably, and efficiently evaluate the performance of LLMs as evaluators across diverse tasks and scenarios, particularly in potentially new, user-defined scenarios. To fill this gap, we propose ScaleEval, an agent-debate-assisted meta-evaluation framework that leverages the capabilities of multiple communicative LLM agents. This framework supports multi-round discussions to assist human annotators in discerning the most capab
    
[^19]: 在分布变化下的图公平学习

    Graph Fairness Learning under Distribution Shifts. (arXiv:2401.16784v1 [cs.LG])

    [http://arxiv.org/abs/2401.16784](http://arxiv.org/abs/2401.16784)

    论文主要研究了在分布变化下的图公平学习，通过理论分析和实证研究发现了决定图中偏差的因素，并探索了训练图和测试图之间表示距离的影响，对于在图结构数据上确保公平性具有重要意义。

    

    图神经网络（GNNs）在图结构数据上取得了显著的性能。然而，GNNs可能会从训练数据中继承偏见，并根据敏感属性（如性别和种族）做出歧视性预测。最近，越来越多的人关注在GNNs上确保公平性，但所有这些方法都基于训练数据和测试数据在相同分布下的假设，即训练数据和测试数据来自同一个图。在分布变化下，图的公平性性能是否会降低？分布变化如何影响图的公平学习？所有这些开放问题从理论上很大程度上未被探索。为了回答这些问题，我们首先在理论上确定了决定图中偏差的因素。随后，我们探索了影响测试图公平性的因素，其中一个值得注意的因素是训练图和测试图之间某些群体的表示距离。

    Graph neural networks (GNNs) have achieved remarkable performance on graph-structured data. However, GNNs may inherit prejudice from the training data and make discriminatory predictions based on sensitive attributes, such as gender and race. Recently, there has been an increasing interest in ensuring fairness on GNNs, but all of them are under the assumption that the training and testing data are under the same distribution, i.e., training data and testing data are from the same graph. Will graph fairness performance decrease under distribution shifts? How does distribution shifts affect graph fairness learning? All these open questions are largely unexplored from a theoretical perspective. To answer these questions, we first theoretically identify the factors that determine bias on a graph. Subsequently, we explore the factors influencing fairness on testing graphs, with a noteworthy factor being the representation distances of certain groups between the training and testing graph. M
    
[^20]: 基于外部奖励的鉴别器的软Q模仿学习

    Extrinsicaly Rewarded Soft Q Imitation Learning with Discriminator. (arXiv:2401.16772v1 [cs.LG])

    [http://arxiv.org/abs/2401.16772](http://arxiv.org/abs/2401.16772)

    本论文提出了一种基于外部奖励的鉴别器的软Q模仿学习方法，旨在解决在少量专家数据和采样数据中进行模仿学习时遇到的困难，同时通过添加基于对抗的奖励函数，使算法更加稳健和高效。

    

    在难以设计奖励或奖励稀疏的环境中，模仿学习常常与强化学习结合使用，但在少量专家数据和采样数据中很难在未知状态中良好地进行模仿。行为克隆等监督学习方法不需要采样数据，但通常会受到分布偏移的困扰。基于强化学习的方法，如逆向强化学习和生成对抗模仿学习（GAIL），可以从少量专家数据中进行学习，但通常需要与环境进行交互。软Q模仿学习（SQIL）解决了这些问题，并通过将行为克隆和常数奖励的软Q学习相结合，表明能够高效学习。为了使该算法对分布偏移更加稳健，我们提出了一种更高效和更稳健的算法，通过在该方法中添加基于对抗的奖励函数。

    Imitation learning is often used in addition to reinforcement learning in environments where reward design is difficult or where the reward is sparse, but it is difficult to be able to imitate well in unknown states from a small amount of expert data and sampling data. Supervised learning methods such as Behavioral Cloning do not require sampling data, but usually suffer from distribution shift. The methods based on reinforcement learning, such as inverse reinforcement learning and Generative Adversarial imitation learning (GAIL), can learn from only a few expert data. However, they often need to interact with the environment. Soft Q imitation learning (SQIL) addressed the problems, and it was shown that it could learn efficiently by combining Behavioral Cloning and soft Q-learning with constant rewards. In order to make this algorithm more robust to distribution shift, we propose more efficient and robust algorithm by adding to this method a reward function based on adversarial invers
    
[^21]: 基于对比学习的深度神经网络故障注入攻击检测和恢复

    Detection and Recovery Against Deep Neural Network Fault Injection Attacks Based on Contrastive Learning. (arXiv:2401.16766v1 [cs.LG])

    [http://arxiv.org/abs/2401.16766](http://arxiv.org/abs/2401.16766)

    本文提出了一个基于对比学习的深度神经网络故障注入攻击检测和恢复框架（CFDR），通过将对比学习应用于训练和推理流程中，实现了具有自适应能力的深度神经网络推理引擎，在只有一个批次的测试数据和少量无标签测试数据的情况下，能够实时检测并快速恢复多种类型的故障注入攻击。

    

    深度神经网络在执行设备上作为推理引擎实施时容易受到故障注入攻击，这些攻击操纵模型参数以破坏推理执行的性能。本文将对比学习应用于深度学习的训练和推理流程中，以实现具有自适应能力的深度神经网络推理引擎，以应对故障注入攻击。我们提出的基于对比学习的故障注入攻击检测和恢复（CFDR）框架具有以下特点：（i）仅需一个批次的测试数据进行实时检测，（ii）即使仅有少量无标签测试数据，也能实现快速的恢复效果。在CIFAR-10数据集上对多种类型的故障注入攻击进行评估，我们的CFDR展现出了良好的检测和恢复效果。

    Deep Neural Network (DNN) models when implemented on executing devices as the inference engines are susceptible to Fault Injection Attacks (FIAs) that manipulate model parameters to disrupt inference execution with disastrous performance. This work introduces Contrastive Learning (CL) of visual representations i.e., a self-supervised learning approach into the deep learning training and inference pipeline to implement DNN inference engines with self-resilience under FIAs. Our proposed CL based FIA Detection and Recovery (CFDR) framework features (i) real-time detection with only a single batch of testing data and (ii) fast recovery effective even with only a small amount of unlabeled testing data. Evaluated with the CIFAR-10 dataset on multiple types of FIAs, our CFDR shows promising detection and recovery effectiveness.
    
[^22]: 大型语言模型中的越狱攻击的跨语言研究

    A Cross-Language Investigation into Jailbreak Attacks in Large Language Models. (arXiv:2401.16765v1 [cs.CR])

    [http://arxiv.org/abs/2401.16765](http://arxiv.org/abs/2401.16765)

    大型语言模型面临着越狱攻击的威胁，在跨语言的环境下，恶意问题可以逃避安全过滤器。本研究填补了这一研究空白，通过广泛的经验研究和语义保留算法的开发，揭示了多语言越狱攻击的模式和安全威胁。

    

    大型语言模型（LLMs）因其在各个领域中先进的文本生成能力而越来越受欢迎。然而，像任何软件一样，它们面临安全挑战，包括“越狱”攻击的风险，即操纵LLMs生成被禁内容。一个在研究中尚未得到充分探索的领域是多语言越狱攻击，即将恶意问题翻译成各种语言以逃避安全过滤器。目前，尚缺乏全面的经验证据的研究来解决这一特定威胁。为了填补这一研究空白，我们对多语言越狱攻击进行了广泛的经验研究。我们开发了一种新颖的语义保留算法来创建一个多语言越狱数据集，并对包括GPT-4和LLaMa在内的广泛使用的开源和商业LLMs进行了详尽的评估。此外，我们进行了可解释性分析，以揭示多语言越狱攻击中的模式，并实施了精调。

    Large Language Models (LLMs) have become increasingly popular for their advanced text generation capabilities across various domains. However, like any software, they face security challenges, including the risk of 'jailbreak' attacks that manipulate LLMs to produce prohibited content. A particularly underexplored area is the Multilingual Jailbreak attack, where malicious questions are translated into various languages to evade safety filters. Currently, there is a lack of comprehensive empirical studies addressing this specific threat.  To address this research gap, we conducted an extensive empirical study on Multilingual Jailbreak attacks. We developed a novel semantic-preserving algorithm to create a multilingual jailbreak dataset and conducted an exhaustive evaluation on both widely-used open-source and commercial LLMs, including GPT-4 and LLaMa. Additionally, we performed interpretability analysis to uncover patterns in Multilingual Jailbreak attacks and implemented a fine-tuning
    
[^23]: SwapNet: 超出内存预算的边缘AI设备上进行DNN推理的高效交换技术

    SwapNet: Efficient Swapping for DNN Inference on Edge AI Devices Beyond the Memory Budget. (arXiv:2401.16757v1 [cs.LG])

    [http://arxiv.org/abs/2401.16757](http://arxiv.org/abs/2401.16757)

    SwapNet是一种高效的边缘AI设备DNN块交换中间件，在超出内存预算的情况下，通过分解DNN为块并进行交换，实现了大型DNN的高效执行。

    

    在边缘人工智能（AI）设备上执行深度神经网络（DNN）可以实现各种自主移动计算应用。然而，边缘AI设备的内存预算限制了这些应用中允许的DNN数量和复杂性。现有的解决方案，如模型压缩或云卸载，减少了DNN推理的内存占用，但同时也降低了模型准确度或自主性。为了避免这些缺点，我们将DNN分解成块，并按顺序互相交换，以便在较小的内存预算下执行大型DNN。然而，在边缘AI设备上进行简单交换会引起显著的延迟，因为在边缘AI设备的DNN开发生态系统中存在冗余的内存操作。为此，我们开发了SwapNet，一种高效的边缘AI设备DNN块交换中间件。我们系统地消除了块交换过程中不必要的内存操作，同时保持与深度学习框架和GPU后端的兼容性。

    Executing deep neural networks (DNNs) on edge artificial intelligence (AI) devices enables various autonomous mobile computing applications. However, the memory budget of edge AI devices restricts the number and complexity of DNNs allowed in such applications. Existing solutions, such as model compression or cloud offloading, reduce the memory footprint of DNN inference at the cost of decreased model accuracy or autonomy. To avoid these drawbacks, we divide DNN into blocks and swap them in and out in order, such that large DNNs can execute within a small memory budget. Nevertheless, naive swapping on edge AI devices induces significant delays due to the redundant memory operations in the DNN development ecosystem for edge AI devices. To this end, we develop SwapNet, an efficient DNN block swapping middleware for edge AI devices. We systematically eliminate the unnecessary memory operations during block swapping while retaining compatible with the deep learning frameworks, GPU backends,
    
[^24]: 关系推理的扩散模型

    Diffusion model for relational inference. (arXiv:2401.16755v1 [cs.LG])

    [http://arxiv.org/abs/2401.16755](http://arxiv.org/abs/2401.16755)

    这项研究提出了一种关系推理的扩散模型(DiffRI)，通过条件扩散建模学习推断组件之间连接存在的概率，并在无监督方式下发现地面真实相互作用方面具有很高的能力。

    

    复杂相互作用系统的动态行为，包括大脑活动、金融价格波动和物理集体现象，与系统组成部分之间的相互作用相关。利用可观测的动态来发现这些系统中的相互作用关系被称为关系推理。在本研究中，我们提出了一种关系推理的扩散模型(DiffRI)，它借鉴了一种自监督的概率时间序列插值方法。DiffRI通过条件扩散建模学习推断组件之间连接存在的概率。对于模拟和准真实数据集的实验证明，DiffRI在无监督方式下发现地面真实相互作用方面与其他最先进的模型相比具有很高的能力。我们的代码将很快公开。

    Dynamical behaviors of complex interacting systems, including brain activities, financial price movements, and physical collective phenomena, are associated with underlying interactions between the system's components. The issue of uncovering interaction relations in such systems using observable dynamics is called relational inference. In this study, we propose a Diffusion model for Relational Inference (DiffRI), inspired by a self-supervised method for probabilistic time series imputation. DiffRI learns to infer the probability of the presence of connections between components through conditional diffusion modeling. Experiments on both simulated and quasi-real datasets show that DiffRI is highly competent compared with other state-of-the-art models in discovering ground truth interactions in an unsupervised manner. Our code will be made public soon.
    
[^25]: ShaRP：用Shapley值解释排名

    ShaRP: Explaining Rankings with Shapley Values. (arXiv:2401.16744v1 [cs.AI])

    [http://arxiv.org/abs/2401.16744](http://arxiv.org/abs/2401.16744)

    ShaRP是一个基于Shapley值的框架，用于解释排名结果中各个特征的贡献。即使使用线性评分函数，特征的权重也不一定对应其Shapley值的贡献，而是取决于特征分布和评分特征之间的局部相互作用。

    

    在招聘、大学招生和贷款等重要领域的算法决策常常是基于排名的。由于这些决策对个人、组织和人群的影响，有必要了解它们：了解决策是否遵守法律，帮助个人提高他们的排名，并设计更好的排名程序。本文提出了ShaRP（Shapley for Rankings and Preferences），这是一个基于Shapley值的框架，用于解释特征对排名结果不同方面的贡献。使用ShaRP，我们展示了即使算法排名器使用的评分函数是已知的且是线性的，每个特征的权重也不一定对应其Shapley值的贡献。贡献取决于特征的分布以及评分特征之间微妙的局部相互作用。ShaRP基于量化输入影响框架，并可以计算贡献。

    Algorithmic decisions in critical domains such as hiring, college admissions, and lending are often based on rankings. Because of the impact these decisions have on individuals, organizations, and population groups, there is a need to understand them: to know whether the decisions are abiding by the law, to help individuals improve their rankings, and to design better ranking procedures.  In this paper, we present ShaRP (Shapley for Rankings and Preferences), a framework that explains the contributions of features to different aspects of a ranked outcome, and is based on Shapley values. Using ShaRP, we show that even when the scoring function used by an algorithmic ranker is known and linear, the weight of each feature does not correspond to its Shapley value contribution. The contributions instead depend on the feature distributions, and on the subtle local interactions between the scoring features. ShaRP builds on the Quantitative Input Influence framework, and can compute the contri
    
[^26]: 基于生成型人工智能的闭环fMRI系统

    Generative AI-based closed-loop fMRI system. (arXiv:2401.16742v1 [cs.HC])

    [http://arxiv.org/abs/2401.16742](http://arxiv.org/abs/2401.16742)

    DecNefGAN是一种基于生成型人工智能的闭环fMRI系统，通过结合生成对抗系统和神经强化模型，研究人类如何对抗和应对生成型人工智能的潜在影响。

    

    虽然生成型人工智能现在在社会中广泛应用，并且具有很大的用处，但是存在潜在的滥用风险，例如，无意识地影响认知过程或决策。尽管这在认知领域中引起了安全问题，但至今没有关于在人类身上对抗恶意生成型人工智能影响的神经和计算机机制的研究。我们提出了DecNefGAN，一种结合了生成对抗系统和神经强化模型的新框架。具体而言，DecNefGAN在一个闭环系统中连接了人类和生成型人工智能，其中人工智能创建诱发特定心理状态的刺激，从而对神经活动施加外部控制。人类的目标相反，要竞争并达到一个正交的心理状态。这个框架可以有助于阐明人脑如何对抗和应对生成型人工智能的潜在影响。

    While generative AI is now widespread and useful in society, there are potential risks of misuse, e.g., unconsciously influencing cognitive processes or decision-making. Although this causes a security problem in the cognitive domain, there has been no research about neural and computational mechanisms counteracting the impact of malicious generative AI in humans. We propose DecNefGAN, a novel framework that combines a generative adversarial system and a neural reinforcement model. More specifically, DecNefGAN bridges human and generative AI in a closed-loop system, with the AI creating stimuli that induce specific mental states, thus exerting external control over neural activity. The objective of the human is the opposite, to compete and reach an orthogonal mental state. This framework can contribute to elucidating how the human brain responds to and counteracts the potential influence of generative AI.
    
[^27]: 为语言模型中的神经元生成信息性文本描述的研究

    Towards Generating Informative Textual Description for Neurons in Language Models. (arXiv:2401.16731v1 [cs.CL])

    [http://arxiv.org/abs/2401.16731](http://arxiv.org/abs/2401.16731)

    本文提出了一种新颖而可伸缩的框架，将文本描述与语言模型中的神经元联系起来，从而解释模型中理解的信息。通过使用生成语言模型发现人可解释的描述符，并使用无监督方法解释神经元，通过定性和定量分析证明了该方法的有效性。

    

    近期基于Transformer的语言模型的发展使其能够捕捉到各种世界知识并适应具有有限资源的下游任务。然而，这些模型理解哪些信息尚不清楚，而在识别它们方面的神经元级贡献基本上是未知的。神经元解释的传统方法要么依赖于有限的预定义描述符，要么需要手动注释以训练一个能够解释主模型神经元的次要模型。本文以BERT为例，尝试摆脱这些限制，提出了一种新颖而可伸缩的框架，将文本描述与神经元联系起来。我们利用生成语言模型的潜力，在数据集中发现人可解释的描述符，并使用无监督方法解释带有这些描述符的神经元。通过各种定性和定量分析，我们展示了这种方法的有效性。

    Recent developments in transformer-based language models have allowed them to capture a wide variety of world knowledge that can be adapted to downstream tasks with limited resources. However, what pieces of information are understood in these models is unclear, and neuron-level contributions in identifying them are largely unknown. Conventional approaches in neuron explainability either depend on a finite set of pre-defined descriptors or require manual annotations for training a secondary model that can then explain the neurons of the primary model. In this paper, we take BERT as an example and we try to remove these constraints and propose a novel and scalable framework that ties textual descriptions to neurons. We leverage the potential of generative language models to discover human-interpretable descriptors present in a dataset and use an unsupervised approach to explain neurons with these descriptors. Through various qualitative and quantitative analyses, we demonstrate the effe
    
[^28]: 多元贝塔混合模型：具有灵活聚类形状的概率聚类方法

    Multivariate Beta Mixture Model: Probabilistic Clustering With Flexible Cluster Shapes. (arXiv:2401.16708v1 [cs.LG])

    [http://arxiv.org/abs/2401.16708](http://arxiv.org/abs/2401.16708)

    本文提出了一种名为多元贝塔混合模型（MBMM）的新的概率模型，用于软聚类。MBMM通过其灵活的多元贝塔分布的概率密度函数适应不同的聚类形状，并在合成和真实数据集上展示了其适应性。

    

    本文介绍了多元贝塔混合模型（MBMM），这是一种新的概率模型用于软聚类。MBMM通过多元贝塔分布的灵活概率密度函数适应不同的聚类形状。我们介绍了MBMM的属性，描述了参数学习过程，并展示了在合成和真实数据集上适合各种聚类形状的实验结果。代码匿名发布在\url{https://github.com/hhchen1105/mbmm/}上。

    This paper introduces the multivariate beta mixture model (MBMM), a new probabilistic model for soft clustering. MBMM adapts to diverse cluster shapes because of the flexible probability density function of the multivariate beta distribution. We introduce the properties of MBMM, describe the parameter learning procedure, and present the experimental results, showing that MBMM fits diverse cluster shapes on synthetic and real datasets. The code is released anonymously at \url{https://github.com/hhchen1105/mbmm/}.
    
[^29]: AutoIE：一种从科学文献中自动提取信息的框架

    AutoIE: An Automated Framework for Information Extraction from Scientific Literature. (arXiv:2401.16672v1 [cs.IR])

    [http://arxiv.org/abs/2401.16672](http://arxiv.org/abs/2401.16672)

    AutoIE是一个自动提取科学文献信息的创新框架，集成了多个关键组件，包括PDF文档布局分析、科学文本功能块识别、分子筛合成信息提取和在线学习等，具有高效提取关键数据的能力。应用于石化领域的实践证明了其有效性。

    

    在快速发展的科学研究领域中，高效地从大量科学论文中提取关键信息仍然是一个巨大的挑战。本文介绍了一个创新框架，旨在自动提取科学PDF文档中的重要数据，使研究人员更容易辨别未来的研究方向。AutoIE独特地集成了四个创新组件：（1）基于多语义特征融合的PDF文档布局分析方法；（2）科学文本中的高级功能块识别；（3）一种针对分子筛合成的信息提取和相关性的协同技术；（4）针对分子筛文献量身定制的在线学习范式。我们的SBERT模型在CoNLL04和ADE数据集上实现了高达87.19和89.65的Marco F1分数。此外，将AutoIE应用于石化领域的分子筛合成实践证明了其有效性，通过惊人的78%的...

    In the rapidly evolving field of scientific research, efficiently extracting key information from the burgeoning volume of scientific papers remains a formidable challenge. This paper introduces an innovative framework designed to automate the extraction of vital data from scientific PDF documents, enabling researchers to discern future research trajectories more readily. AutoIE uniquely integrates four novel components: (1) A multi-semantic feature fusion-based approach for PDF document layout analysis; (2) Advanced functional block recognition in scientific texts; (3) A synergistic technique for extracting and correlating information on molecular sieve synthesis; (4) An online learning paradigm tailored for molecular sieve literature. Our SBERT model achieves high Marco F1 scores of 87.19 and 89.65 on CoNLL04 and ADE datasets. In addition, a practical application of AutoIE in the petrochemical molecular sieve synthesis domain demonstrates its efficacy, evidenced by an impressive 78\%
    
[^30]: 人工智能是否为天气预报带来了第二次革命？

    Is Artificial Intelligence Providing the Second Revolution for Weather Forecasting?. (arXiv:2401.16669v1 [cs.LG])

    [http://arxiv.org/abs/2401.16669](http://arxiv.org/abs/2401.16669)

    人工智能技术在天气预报领域的快速发展代表了一个重大突破，它克服了传统模型的局限性，有潜力引领天气预报的第二次革命。

    

    人工智能技术的快速发展，特别是近年来，导致了几种大参数人工智能天气预报模型的出现。这些模型代表了一个重大突破，克服了传统数值天气预报模型的局限性，并表明了天气预报可能迎来第二次革命的潜力。本研究探讨了这些先进人工智能预报模型的演变，并在确定的共同点的基础上，提出了它们的发展的“三大规则”。我们讨论了人工智能在革命数值天气预报中的潜力，并简要概述了潜在的原因。此外，我们还探讨了大型人工智能天气预报模型未来发展前景的关键领域，将整个数值预报过程进行整合。通过将大型人工智能模型与其他信息综合，给出了一个应用实例。

    The rapid advancement of artificial intelligence technologies, particularly in recent years, has led to the emergence of several large parameter artificial intelligence weather forecast models. These models represent a significant breakthrough, overcoming the limitations of traditional numerical weather prediction models and indicating a potential second revolution for weather forecast. This study explores the evolution of these advanced artificial intelligence forecast models, and based on the identified commonalities, proposes the "Three Large Rules" for their development. We discuss the potential of artificial intelligence in revolutionizing numerical weather prediction, briefly outlining the underlying reasons for this potential. Additionally, we explore key areas for future development prospects for large artificial intelligence weather forecast models, integrating the entire numerical prediction process. Through an example that combines a large artificial intelligence model with 
    
[^31]: 从大型语言模型中通过马尔可夫链蒙特卡洛恢复心智表示

    Recovering Mental Representations from Large Language Models with Markov Chain Monte Carlo. (arXiv:2401.16657v1 [cs.AI])

    [http://arxiv.org/abs/2401.16657](http://arxiv.org/abs/2401.16657)

    本文研究了使用马尔可夫链蒙特卡洛（MCMC）方法从大型语言模型中恢复心智表示的方法，并且发现使用基于MCMC的自适应采样算法可以显著提高效率和性能，这对于进行贝叶斯推理具有潜在意义。

    

    通过模拟采样算法进行人类研究已被证明是一种有效的方法，可以高效地探索和理解其心智表示。我们提出相同的方法可以用来研究大型语言模型（LLMs）的表示。虽然人类或LLMs都可以通过内省的方式直接揭示其心智表示，但我们表明，使用LLMs作为一种采样算法的元素可以提高效率。我们探索了在使用直接采样和马尔可夫链蒙特卡洛（MCMC）进行LLMs插问时恢复人类化表示程度的程度。我们发现使用基于MCMC的自适应采样算法可以显著提高效率和性能。我们还强调了我们的方法潜力，可以产生一种更通用的使用LLMs进行贝叶斯推理的方法。

    Simulating sampling algorithms with people has proven a useful method for efficiently probing and understanding their mental representations. We propose that the same methods can be used to study the representations of Large Language Models (LLMs). While one can always directly prompt either humans or LLMs to disclose their mental representations introspectively, we show that increased efficiency can be achieved by using LLMs as elements of a sampling algorithm. We explore the extent to which we recover human-like representations when LLMs are interrogated with Direct Sampling and Markov chain Monte Carlo (MCMC). We found a significant increase in efficiency and performance using adaptive sampling algorithms based on MCMC. We also highlight the potential of our method to yield a more general method of conducting Bayesian inference \textit{with} LLMs.
    
[^32]: 增强连续强化学习中的回放在世界模型中

    Augmenting Replay in World Models for Continual Reinforcement Learning. (arXiv:2401.16650v1 [cs.LG])

    [http://arxiv.org/abs/2401.16650](http://arxiv.org/abs/2401.16650)

    本研究通过在回放缓冲区中应用增强方法，成功地解决了增强连续强化学习中的内存限制问题，并在世界模型中有效防止灾难性遗忘。

    

    在连续强化学习中，强化学习代理的环境会发生变化。成功的系统应该适当平衡保持已学习任务上的代理性能、稳定性和学习新任务的可塑性之间的矛盾要求。首进先出缓冲区通常用于增强此类设置中的学习，但需要大量内存。我们探索了将增强方法应用于此缓冲区中，以缓解内存限制，并与基于世界模型的强化学习算法一起使用，评估其在促进连续学习方面的效果。我们在Procgen和Atari强化学习基准测试中评估了我们方法的有效性，并证明了在潜在世界模型的背景下，回放缓冲区中的分布匹配增强可以成功防止灾难性遗忘，并显著降低计算开销。然而，我们也发现这种解决方案并非完全无懈可击，

    In continual RL, the environment of a reinforcement learning (RL) agent undergoes change. A successful system should appropriately balance the conflicting requirements of retaining agent performance on already learned tasks, stability, whilst learning new tasks, plasticity. The first-in-first-out buffer is commonly used to enhance learning in such settings but requires significant memory. We explore the application of an augmentation to this buffer which alleviates the memory constraints, and use it with a world model model-based reinforcement learning algorithm, to evaluate its effectiveness in facilitating continual learning. We evaluate the effectiveness of our method in Procgen and Atari RL benchmarks and show that the distribution matching augmentation to the replay-buffer used in the context of latent world models can successfully prevent catastrophic forgetting with significantly reduced computational overhead. Yet, we also find such a solution to not be entirely infallible, and
    
[^33]: 大型语言模型中的不连贯概率判断

    Incoherent Probability Judgments in Large Language Models. (arXiv:2401.16646v1 [cs.CL])

    [http://arxiv.org/abs/2401.16646](http://arxiv.org/abs/2401.16646)

    在本论文中，研究人员通过对大型语言模型(LLMs)进行实验证明，这些模型产生的概率判断经常是不连贯的，显示出类似于人类一样的非理性偏差。他们还提出了将自回归LLMs与隐性贝叶斯推断联系起来的解释。

    

    针对下一个词预测训练的自回归大型语言模型(LLMs)展示出出色的连贯文本生成能力。但它们是否同样擅长形成连贯的概率判断？我们使用概率身份和重复判断来评估LLMs生成的概率判断的连贯性。我们的结果显示，这些模型产生的判断经常是不连贯的，显示出人类一样的概率理论规则偏离。此外，当要求对同一事件进行判断时，LLMs产生的概率判断的均值-方差关系呈现出人类所见到的倒U形状。我们提出这些非理性的偏离可以通过将自回归LLMs与隐性贝叶斯推断联系起来，并与人类概率判断的贝叶斯抽样器模型进行类比来解释。

    Autoregressive Large Language Models (LLMs) trained for next-word prediction have demonstrated remarkable proficiency at producing coherent text. But are they equally adept at forming coherent probability judgments? We use probabilistic identities and repeated judgments to assess the coherence of probability judgments made by LLMs. Our results show that the judgments produced by these models are often incoherent, displaying human-like systematic deviations from the rules of probability theory. Moreover, when prompted to judge the same event, the mean-variance relationship of probability judgments produced by LLMs shows an inverted-U-shaped like that seen in humans. We propose that these deviations from rationality can be explained by linking autoregressive LLMs to implicit Bayesian inference and drawing parallels with the Bayesian Sampler model of human probability judgments.
    
[^34]: 打破Transformer模型的束缚：任务特定的上下文归因提供了在不微调预训练LLMs的情况下提高泛化性能的承诺

    Breaking Free Transformer Models: Task-specific Context Attribution Promises Improved Generalizability Without Fine-tuning Pre-trained LLMs. (arXiv:2401.16638v1 [cs.CL])

    [http://arxiv.org/abs/2401.16638](http://arxiv.org/abs/2401.16638)

    本文提出了一种框架，通过任务特定的上下文归因来提高模型在下游任务中的性能，而不需要对预训练的语言模型进行微调，从而保持了模型的泛化性能。

    

    在自然语言处理（NLP）分类任务中，对特定数据集进行大型预训练语言模型（LLMs）的微调是一种常用策略。然而，这种方法通常会导致模型的泛化性能下降。在本文中，我们提出了一个框架，通过利用任务特定的上下文归因，实现了泛化性能的保持，并提升了下游任务的性能。我们展示了任何Transformer模型的文本表示的线性变换，使用任务特定的概念运算符，会得到一个投影到潜在概念空间上的结果，本文中称之为上下文归因。特定的概念运算符在监督学习阶段通过新颖的损失函数进行优化。所提出的框架表明，对于每个任务目标的文本表示进行上下文归因可以改善鉴别器函数的能力，从而实现更好的分类性能。

    Fine-tuning large pre-trained language models (LLMs) on particular datasets is a commonly employed strategy in Natural Language Processing (NLP) classification tasks. However, this approach usually results in a loss of models generalizability. In this paper, we present a framework that allows for maintaining generalizability, and enhances the performance on the downstream task by utilizing task-specific context attribution. We show that a linear transformation of the text representation from any transformer model using the task-specific concept operator results in a projection onto the latent concept space, referred to as context attribution in this paper. The specific concept operator is optimized during the supervised learning stage via novel loss functions. The proposed framework demonstrates that context attribution of the text representation for each task objective can improve the capacity of the discriminator function and thus achieve better performance for the classification tas
    
[^35]: 通过高效的奖励模型集成改进人工反馈强化学习

    Improving Reinforcement Learning from Human Feedback with Efficient Reward Model Ensemble. (arXiv:2401.16635v1 [cs.LG])

    [http://arxiv.org/abs/2401.16635](http://arxiv.org/abs/2401.16635)

    本论文提出一种通过高效的奖励模型集成来改进人工反馈强化学习的方法，以解决由于奖励模型预测不准确而导致RLHF输出与人类价值观不一致的问题。

    

    人工反馈强化学习（RLHF）是一种广泛使用的方法，用于将大型语言模型与人类价值观对齐。然而，RLHF依赖于通过有限的人类偏好数据训练的奖励模型，这可能导致不准确的预测。因此，RLHF可能产生与人类价值观不一致的输出。为了缓解这个问题，我们提出了一种奖励集成方法，可以使奖励模型做出更准确的预测。考虑到使用基于大型语言模型的奖励模型集成可能具有计算和资源昂贵的问题，我们探索了包括线性层集成和基于LoRA的集成在内的高效集成方法。实证上，我们使用我们的集成奖励模型运行Best-of-$n$和Proximal Policy Optimization，并验证我们的集成方法有助于改善RLHF输出的对齐性能。

    Reinforcement Learning from Human Feedback (RLHF) is a widely adopted approach for aligning large language models with human values. However, RLHF relies on a reward model that is trained with a limited amount of human preference data, which could lead to inaccurate predictions. As a result, RLHF may produce outputs that are misaligned with human values. To mitigate this issue, we contribute a reward ensemble method that allows the reward model to make more accurate predictions. As using an ensemble of large language model-based reward models can be computationally and resource-expensive, we explore efficient ensemble methods including linear-layer ensemble and LoRA-based ensemble. Empirically, we run Best-of-$n$ and Proximal Policy Optimization with our ensembled reward models, and verify that our ensemble methods help improve the alignment performance of RLHF outputs.
    
[^36]: 我来了，我看到了，我认证了：对于网络物理系统安全保证的几个观点

    I came, I saw, I certified: some perspectives on the safety assurance of cyber-physical systems. (arXiv:2401.16633v1 [cs.SE])

    [http://arxiv.org/abs/2401.16633](http://arxiv.org/abs/2401.16633)

    对于网络物理系统的安全保证，开发令人信服的保证案例是关键，包括检测缺陷、改进结构和自动生成案例。

    

    网络物理系统（例如自动驾驶系统、无人机系统和机器人系统）的执行失败可能导致生命丧失、严重伤害、大规模环境破坏、财产损毁和重大经济损失。因此，这些系统通常需要强有力的理由来支持它们能够有效地支撑其设计的关键要求（例如安全性、可靠性和可用性）。因此，通常需要开发令人信服的保证案例来支持这种理由，并允许监管机构对此类系统进行认证。在这种情况下，检测保证案例中的缺陷，依赖模式来改进保证案例的结构，改进现有的保证案例符号，并（半）自动化生成保证案例是发展令人信服的保证案例并促进消费者接受的关键。因此，我们探讨了与这些保证启用器相关的挑战，并概述了一些潜在的方向。

    The execution failure of cyber-physical systems (e.g., autonomous driving systems, unmanned aerial systems, and robotic systems) could result in the loss of life, severe injuries, large-scale environmental damage, property destruction, and major economic loss. Hence, such systems usually require a strong justification that they will effectively support critical requirements (e.g., safety, security, and reliability) for which they were designed. Thus, it is often mandatory to develop compelling assurance cases to support that justification and allow regulatory bodies to certify such systems. In such contexts, detecting assurance deficits, relying on patterns to improve the structure of assurance cases, improving existing assurance case notations, and (semi-)automating the generation of assurance cases are key to develop compelling assurance cases and foster consumer acceptance. We therefore explore challenges related to such assurance enablers and outline some potential directions that 
    
[^37]: 基于RL和PID控制器的六自由度游泳机器人的比较：混合水下目标跟踪

    A comparison of RL-based and PID controllers for 6-DOF swimming robots: hybrid underwater object tracking. (arXiv:2401.16618v1 [cs.RO])

    [http://arxiv.org/abs/2401.16618](http://arxiv.org/abs/2401.16618)

    本文比较了基于RL和PID控制器的六自由度游泳机器人，重点研究了水下目标跟踪。使用中央深度Q网络（DQN）控制器代替PID控制器在数据效率和离策略学习方面具有优势，并且较易实现。在没有动力学模型的情况下，我们提出了一个RL代理来控制多输入多输出的系统，中心控制器可能比独立的PID控制器提供更强健的控制。

    

    本文在六自由度游泳机器人的背景下，探讨和评估了使用中央深度Q网络（DQN）控制器来代替常用的PID控制器的可能性。我们主要将重点放在水下目标跟踪这一具体案例上，DQN具有数据效率和离策略学习的优势，同时比其他强化学习方法更容易实现。考虑到我们的机器人没有动力学模型，我们提出了一个RL代理来控制这个多输入多输出（MIMO）系统，在这种情况下，中心控制器可能比独立的PID控制器提供更强健的控制。我们的方法涉及使用经典控制器进行安全探索，然后逐渐转向DQN来完全掌控机器人。我们将水下跟踪任务分为视觉和控制模块，使用了已建立的基于视觉的跟踪方法，并引入了一个中心DQN控制器。

    In this paper, we present an exploration and assessment of employing a centralized deep Q-network (DQN) controller as a substitute for the prevalent use of PID controllers in the context of 6DOF swimming robots. Our primary focus centers on illustrating this transition with the specific case of underwater object tracking. DQN offers advantages such as data efficiency and off-policy learning, while remaining simpler to implement than other reinforcement learning methods. Given the absence of a dynamic model for our robot, we propose an RL agent to control this multi-input-multi-output (MIMO) system, where a centralized controller may offer more robust control than distinct PIDs. Our approach involves initially using classical controllers for safe exploration, then gradually shifting to DQN to take full control of the robot.  We divide the underwater tracking task into vision and control modules. We use established methods for vision-based tracking and introduce a centralized DQN control
    
[^38]: 人类与ChatGPT生成对话之间的语言对比

    A Linguistic Comparison between Human and ChatGPT-Generated Conversations. (arXiv:2401.16587v1 [cs.CL])

    [http://arxiv.org/abs/2401.16587](http://arxiv.org/abs/2401.16587)

    本研究比较了人类和ChatGPT生成的对话的语言差异，发现ChatGPT在社交、分析、认知、关注焦点和积极情绪等方面表现出色，但人类对话更具变异性和真实性，尽管在情绪方面无显著差异。同时，该研究还提供了一个新颖的、由ChatGPT生成的对话组成的数据集。

    

    本研究探讨了人类和LLM生成的对话之间的语言差异，使用了由ChatGPT-3.5生成的19.5K个对话作为EmpathicDialogues数据集的补充。研究采用Linguistic Inquiry and Word Count (LIWC) 分析，比较了ChatGPT生成的对话和人类对话在118个语言类别上的差异。结果显示人类对话具有更大的变异性和真实性，但ChatGPT在社交过程、分析风格、认知、关注焦点和积极情绪色彩等方面表现出色，这进一步证明了LLMs“比真人更像真人”的最新发现。然而，在ChatGPT和人类对话之间没有找到积极或消极情绪的显著差异。对话嵌入的分类器分析表明，尽管对话中没有明确提及情绪，但对情感价值的隐性编码存在。研究还提供了一个新颖的、由两个ChatGPT生成的对话组成的数据集。

    This study explores linguistic differences between human and LLM-generated dialogues, using 19.5K dialogues generated by ChatGPT-3.5 as a companion to the EmpathicDialogues dataset. The research employs Linguistic Inquiry and Word Count (LIWC) analysis, comparing ChatGPT-generated conversations with human conversations across 118 linguistic categories. Results show greater variability and authenticity in human dialogues, but ChatGPT excels in categories such as social processes, analytical style, cognition, attentional focus, and positive emotional tone, reinforcing recent findings of LLMs being "more human than human." However, no significant difference was found in positive or negative affect between ChatGPT and human dialogues. Classifier analysis of dialogue embeddings indicates implicit coding of the valence of affect despite no explicit mention of affect in the conversations. The research also contributes a novel, companion ChatGPT-generated dataset of conversations between two i
    
[^39]: 基于注意力的强化学习在组合优化中的应用：以作业车间调度问题为例

    Attention-based Reinforcement Learning for Combinatorial Optimization: Application to Job Shop Scheduling Problem. (arXiv:2401.16580v1 [cs.AI])

    [http://arxiv.org/abs/2401.16580](http://arxiv.org/abs/2401.16580)

    本论文提出了一种基于注意力的强化学习方法，用于解决作业车间调度问题。通过集成策略梯度强化学习和修改后的Transformer结构，我们的方法在解决大规模问题上表现出色，优于最近研究和广泛采用的启发式规则。

    

    作业车间调度问题是一类重要且具有挑战性的组合优化问题，主要通过精确或近似的解决方法来解决。然而，寻找精确解对于实际问题来说是不可行的，即使采用近似解决方法，也可能需要大量的时间来找到近似最优解，并且找到的解决方案通常不能应用于新问题。为了解决这些挑战，我们提出了一种基于注意力的强化学习方法，用于解决作业车间调度问题，该方法将策略梯度强化学习与修改后的Transformer结构进行了集成。一个重要的结果是，我们在所提出的方法中训练的学习者可以用于解决未参与训练的大规模问题，并且证明我们的方法优于最近研究和广泛采用的启发式规则的结果。

    Job shop scheduling problems are one of the most important and challenging combinatorial optimization problems that have been tackled mainly by exact or approximate solution approaches. However, finding an exact solution can be infeasible for real-world problems, and even with an approximate solution approach, it can require a prohibitive amount of time to find a near-optimal solution, and the found solutions are not applicable to new problems in general. To address these challenges, we propose an attention-based reinforcement learning method for the class of job shop scheduling problems by integrating policy gradient reinforcement learning with a modified transformer architecture. An important result is that our trained learners in the proposed method can be reused to solve large-scale problems not used in training and demonstrate that our approach outperforms the results of recent studies and widely adopted heuristic rules.
    
[^40]: 发挥专业放射科医生的专长，提升放射学报告的LLM评估

    Leveraging Professional Radiologists' Expertise to Enhance LLMs' Evaluation for Radiology Reports. (arXiv:2401.16578v1 [cs.CL])

    [http://arxiv.org/abs/2401.16578](http://arxiv.org/abs/2401.16578)

    该论文提出了一种方法，将专业放射科医生的专业知识与大型语言模型相结合，来提升自动生成报告的自动评估。实验结果显示，该方法的模型在评估中表现优于传统的度量标准。

    

    在放射学领域，人工智能（AI）已经大大推进了报告生成，但自动生成报告的自动评估仍然具有挑战性。目前的度量标准，如传统自然语言生成（NLG）和临床效能（CE），往往无法捕捉临床背景的语义复杂性，或者过分强调临床细节，降低了报告的清晰性。为了解决这些问题，我们提出的方法将专业放射科医生的专业知识与大型语言模型（LLMs），如GPT-3.5和GPT-4 1，相结合。利用上下文指导学习（ICIL）和思维链（CoT）推理，我们的方法使LLM的评估与放射科医生的标准保持一致，实现了人工智能生成报告与人类生成报告之间的详细比较。这进一步通过回归模型来综合句子评估分数。实验结果表明，我们的“详细GPT-4（5次训练）”模型获得了0.48的分数，优于METEOR指标。

    In radiology, Artificial Intelligence (AI) has significantly advanced report generation, but automatic evaluation of these AI-produced reports remains challenging. Current metrics, such as Conventional Natural Language Generation (NLG) and Clinical Efficacy (CE), often fall short in capturing the semantic intricacies of clinical contexts or overemphasize clinical details, undermining report clarity. To overcome these issues, our proposed method synergizes the expertise of professional radiologists with Large Language Models (LLMs), like GPT-3.5 and GPT-4 1. Utilizing In-Context Instruction Learning (ICIL) and Chain of Thought (CoT) reasoning, our approach aligns LLM evaluations with radiologist standards, enabling detailed comparisons between human and AI generated reports. This is further enhanced by a Regression model that aggregates sentence evaluation scores. Experimental results show that our ''Detailed GPT-4 (5-shot)'' model achieves a 0.48 score, outperforming the METEOR metric 
    
[^41]: LLM作为按需可定制的服务

    LLMs as On-demand Customizable Service. (arXiv:2401.16577v1 [cs.CL])

    [http://arxiv.org/abs/2401.16577](http://arxiv.org/abs/2401.16577)

    提出了一种分层、分布式的LLM架构概念，通过在通用计算机和物联网设备上提供按需访问的可定制服务，解决了LLMs训练、部署和访问过程中的挑战，并能够实现资源和应用需求的最佳平衡。

    

    大型语言模型（LLMs）展示了卓越的语言理解和生成能力。然而，训练、部署和访问这些模型都存在显著的挑战，包括资源密集需求、长时间训练和可扩展性问题。为了解决这些问题，我们引入了一个分层、分布式的LLM架构概念，旨在增强LLMs在异构计算平台上的可访问性和可部署性，包括通用计算机（如笔记本电脑）和物联网设备（如嵌入式系统）。通过引入"分层"方法，所提出的架构使LLMs可以按需访问，作为可定制的服务。这种方法还可以确保可用计算资源和用户应用需求之间的最佳权衡。我们预见到，分层LLM的概念将赋予广泛的众包用户基础利用LLM的能力，从而促进技术进步。

    Large Language Models (LLMs) have demonstrated remarkable language understanding and generation capabilities. However, training, deploying, and accessing these models pose notable challenges, including resource-intensive demands, extended training durations, and scalability issues. To address these issues, we introduce a concept of hierarchical, distributed LLM architecture that aims at enhancing the accessibility and deployability of LLMs across heterogeneous computing platforms, including general-purpose computers (e.g., laptops) and IoT-style devices (e.g., embedded systems). By introducing a "layered" approach, the proposed architecture enables on-demand accessibility to LLMs as a customizable service. This approach also ensures optimal trade-offs between the available computational resources and the user's application needs. We envision that the concept of hierarchical LLM will empower extensive, crowd-sourced user bases to harness the capabilities of LLMs, thereby fostering advan
    
[^42]: 基于自编码器的概念空间语义通信的领域学习

    Autoencoder-Based Domain Learning for Semantic Communication with Conceptual Spaces. (arXiv:2401.16569v1 [cs.LG])

    [http://arxiv.org/abs/2401.16569](http://arxiv.org/abs/2401.16569)

    这篇论文研究了基于概念空间的语义通信，提出了一个自编码器学习的框架，解决了无法捕捉和量化“意义”的问题。

    

    与准确传递符号相比，以准确传递意义为目标的语义通信已成为一个越来越受关注的领域。这种范式通常利用人工智能和机器学习的现代发展，以提高通信系统的效率和鲁棒性。然而，对于捕捉和量化“意义”的细节缺乏一个标准模型，许多领先的语义通信方法采用黑盒框架，对模型的具体学习内容知之甚少。一种解决方案是利用概念空间框架，以几何方式明确建模意义。虽然以前使用概念空间研究语义通信的工作已经取得了良好的结果，但这些先前的尝试涉及手工制作概念空间模型，严重限制了该方法的可扩展性和实用性。在这项工作中，我们开发了一个学习框架，用于学习一个自编码器，实现概念空间语义通信。

    Communication with the goal of accurately conveying meaning, rather than accurately transmitting symbols, has become an area of growing interest. This paradigm, termed semantic communication, typically leverages modern developments in artificial intelligence and machine learning to improve the efficiency and robustness of communication systems. However, a standard model for capturing and quantifying the details of "meaning" is lacking, with many leading approaches to semantic communication adopting a black-box framework with little understanding of what exactly the model is learning. One solution is to utilize the conceptual spaces framework, which models meaning explicitly in a geometric manner. Though prior work studying semantic communication with conceptual spaces has shown promising results, these previous attempts involve hand-crafting a conceptual space model, severely limiting the scalability and practicality of the approach. In this work, we develop a framework for learning a 
    
[^43]: 印地语天城字母脚本中的多类后悔检测

    Multi-class Regret Detection in Hindi Devanagari Script. (arXiv:2401.16561v1 [cs.CL])

    [http://arxiv.org/abs/2401.16561](http://arxiv.org/abs/2401.16561)

    本研究聚焦于印地语社交媒体上的后悔表达，建立了一个新的数据集，并通过研究后悔语言表达的特征和相关领域，揭示了后悔的来源和影响。

    

    近年来，社交媒体上使用印地语的人数大幅增加。后悔是我们日常生活中常见的情感体验。许多社交媒体上的使用者经常分享他们的后悔经历和意见。如果有机会，这可能会导致对自己的选择进行重新评估和对不同选择的渴望。因此，了解后悔的来源对于研究其对行为和决策的影响至关重要。本研究聚焦于后悔以及它如何在印地语中表达，特别是在各种社交媒体平台上。在我们的研究中，我们提供了一个新颖的数据集，来自三个不同的来源，每个句子都被手动分类为“行动后悔”、“不作为后悔”和“无后悔”中的一类。接下来，我们使用该数据集研究印地语文本中的后悔语言表达，并确定与后悔最频繁相关的文本领域。我们的研究结果表明，个体们最常与后悔相关的领域是...

    The number of Hindi speakers on social media has increased dramatically in recent years. Regret is a common emotional experience in our everyday life. Many speakers on social media, share their regretful experiences and opinions regularly. It might cause a re-evaluation of one's choices and a desire to make a different option if given the chance. As a result, knowing the source of regret is critical for investigating its impact on behavior and decision-making. This study focuses on regret and how it is expressed, specifically in Hindi, on various social media platforms. In our study, we present a novel dataset from three different sources, where each sentence has been manually classified into one of three classes "Regret by action", "Regret by inaction", and "No regret". Next, we use this dataset to investigate the linguistic expressions of regret in Hindi text and also identify the textual domains that are most frequently associated with regret. Our findings indicate that individuals 
    
[^44]: SelectLLM：LLMs能否选择重要的指令进行注释？

    SelectLLM: Can LLMs Select Important Instructions to Annotate?. (arXiv:2401.16553v1 [cs.CL])

    [http://arxiv.org/abs/2401.16553](http://arxiv.org/abs/2401.16553)

    这项工作提出了一种名为SelectLLM的新方法，利用LLMs选择高质量指令。通过提示LLMs估计每个无标签指令的有用性和影响力，并使用聚类算法将指令分为多个聚类。

    

    使用大量且多样化的指令数据集训练大型语言模型(LLMs)可以使模型理解和遵循人类指令。最近的研究表明，使用一小组高质量的指令可以超过使用大量更嘈杂的指令。由于指令是无标签的，且响应是自然文本，传统的主动学习方案无法直接应用于选择无标签指令。在这项工作中，我们提出了一种新的指令选择方法，称为SelectLLM，它利用LLMs选择高质量指令。我们的高级思想是利用LLMs通过提示来估计每个指令在没有相应标签（即响应）的情况下的有用性和影响力。SelectLLM包括两个步骤：使用聚类算法（例如CoreSet）将无标签指令划分为多个聚类，然后提示LLMs在其中选择高质量指令。

    Training large language models (LLMs) with a large and diverse instruction dataset aligns the models to comprehend and follow human instructions. Recent works have shown that using a small set of high-quality instructions can outperform using large yet more noisy ones. Because instructions are unlabeled and their responses are natural text, traditional active learning schemes with the model's confidence cannot be directly applied to the selection of unlabeled instructions. In this work, we propose a novel method for instruction selection, called SelectLLM, that leverages LLMs for the selection of high-quality instructions. Our high-level idea is to use LLMs to estimate the usefulness and impactfulness of each instruction without the corresponding labels (i.e., responses), via prompting. SelectLLM involves two steps: dividing the unlabelled instructions using a clustering algorithm (e.g., CoreSet) to multiple clusters, and then prompting LLMs to choose high-quality instructions within e
    
[^45]: GuReT：区分与内疚相关和后悔相关的文本

    GuReT: Distinguishing Guilt and Regret related Text. (arXiv:2401.16541v1 [cs.CL])

    [http://arxiv.org/abs/2401.16541](http://arxiv.org/abs/2401.16541)

    本文介绍了GuReT数据集，用于研究内疚和后悔之间的关系，并探索其在文本中的独特特征。通过使用机器学习和深度学习技术，结果表明基于变压器的模型在内疚和后悔识别任务中表现出优于传统机器学习方法的性能。

    

    人类决策和情绪（特别是内疚和后悔）之间错综复杂的关系对行为和幸福感有重要影响。然而，在计算模型中往往忽视了这些情绪的微妙区别和相互作用。本文介绍了一个特定的数据集，用于剖析内疚和后悔之间的关系及其独特的文本标志，弥补了情感计算研究中的一个显著空白。我们的方法将内疚和后悔识别视为二分类任务，并采用三种机器学习和六种基于变压器的深度学习技术对新创建的数据集进行基准测试。该研究还采用了链状思维和树状思维等创新推理方法来评估模型的解释逻辑。结果表明，基于变压器的模型具有明显的性能优势，相比于最好的机器学习分类器的85.3%的宏F1分数，可以达到90.4%的宏F1分数，展示了其较强的能力。

    The intricate relationship between human decision-making and emotions, particularly guilt and regret, has significant implications on behavior and well-being. Yet, these emotions subtle distinctions and interplay are often overlooked in computational models. This paper introduces a dataset tailored to dissect the relationship between guilt and regret and their unique textual markers, filling a notable gap in affective computing research. Our approach treats guilt and regret recognition as a binary classification task and employs three machine learning and six transformer-based deep learning techniques to benchmark the newly created dataset. The study further implements innovative reasoning methods like chain-of-thought and tree-of-thought to assess the models interpretive logic. The results indicate a clear performance edge for transformer-based models, achieving a 90.4% macro F1 score compared to the 85.3% scored by the best machine learning classifier, demonstrating their superior ca
    
[^46]: 时间序列深度学习模型的扰动敏感性分析方法的验证、健壮性和准确性

    Validation, Robustness, and Accuracy of Perturbation-Based Sensitivity Analysis Methods for Time-Series Deep Learning Models. (arXiv:2401.16521v1 [cs.LG])

    [http://arxiv.org/abs/2401.16521](http://arxiv.org/abs/2401.16521)

    本研究验证了时间序列深度学习模型的扰动敏感性分析方法的可靠性和准确性，并比较了不同方法和模型的影响。

    

    本研究对时间序列深度学习的可解释性方法进行评估。敏感性分析评估输入变化对输出的影响，是解释的关键组成部分。在后期解释方法中，如反向传播、扰动和近似法中，本研究将调查现代Transformer模型上的基于扰动的敏感性分析方法，以评估其性能。具体而言，本研究回答了三个研究问题：1）不同的敏感性分析方法是否产生可比较的输出和属性重要性排序？2）使用相同的敏感性分析方法，不同的深度学习模型是否对敏感性分析的输出产生影响？3）敏感性分析方法的结果与基本事实的一致性如何？

    This work undertakes studies to evaluate Interpretability Methods for Time-Series Deep Learning. Sensitivity analysis assesses how input changes affect the output, constituting a key component of interpretation. Among the post-hoc interpretation methods such as back-propagation, perturbation, and approximation, my work will investigate perturbation-based sensitivity Analysis methods on modern Transformer models to benchmark their performances. Specifically, my work answers three research questions: 1) Do different sensitivity analysis (SA) methods yield comparable outputs and attribute importance rankings? 2) Using the same sensitivity analysis method, do different Deep Learning (DL) models impact the output of the sensitivity analysis? 3) How well do the results from sensitivity analysis methods align with the ground truth?
    
[^47]: AFSD-Physics：通过人工智能与人类协作方法探索添加摩擦搅拌堆积过程中温度演变的控制方程

    AFSD-Physics: Exploring the governing equations of temperature evolution during additive friction stir deposition by a human-AI teaming approach. (arXiv:2401.16501v1 [cs.LG])

    [http://arxiv.org/abs/2401.16501](http://arxiv.org/abs/2401.16501)

    本文使用人工智能与人类协作的方法，提出了AFSD-Physics模型，通过学习实验数据，得到了添加摩擦搅拌堆积过程中温度演变的控制方程。该模型具有物理解释性、计算成本低且准确度高，与实际测量结果吻合较好。

    

    本文提出了一种模型方法，通过人工智能与人类协作方法研究添加摩擦搅拌堆积（AFSD）过程中温度演变的物理原理。AFSD是一种新兴的固态增材制造技术，可以在没有熔融的情况下进行材料堆积。然而，目前对于该过程的建模以及AFSD工具的建模还处于早期阶段。本文提出了一种人工智能与人类协作的方法，将基于第一原理的模型与人工智能相结合。得到的人工智能学习方法被命名为AFSD-Physics，能够有效地学习工具和堆积过程中温度演变的控制方程，通过过程中的测量数据进行学习。设计并进行了实验，采集了30层铝7075材料堆积过程中的测量数据。得到的控制方程是具有物理解释性、计算成本低且准确度高的模型。模型预测结果与测量结果具有良好的一致性。

    This paper presents a modeling effort to explore the underlying physics of temperature evolution during additive friction stir deposition (AFSD) by a human-AI teaming approach. AFSD is an emerging solid-state additive manufacturing technology that deposits materials without melting. However, both process modeling and modeling of the AFSD tool are at an early stage. In this paper, a human-AI teaming approach is proposed to combine models based on first principles with AI. The resulting human-informed machine learning method, denoted as AFSD-Physics, can effectively learn the governing equations of temperature evolution at the tool and the build from in-process measurements. Experiments are designed and conducted to collect in-process measurements for the deposition of aluminum 7075 with a total of 30 layers. The acquired governing equations are physically interpretable models with low computational cost and high accuracy. Model predictions show good agreement with the measurements. Expe
    
[^48]: ReGAL: 用于发现通用抽象的程序重构方法

    ReGAL: Refactoring Programs to Discover Generalizable Abstractions. (arXiv:2401.16467v1 [cs.SE])

    [http://arxiv.org/abs/2401.16467](http://arxiv.org/abs/2401.16467)

    ReGAL提出了一种用于发现通用抽象的程序重构方法，可以通过重构代码学习可重用的函数库，利用这些共享函数库可以更准确地预测程序。

    

    虽然大型语言模型（LLMs）越来越多地被用于程序合成，但它们缺乏开发有用抽象所需的全局视角；它们通常一次预测一个程序，经常重复相同的功能。从头开始生成冗余代码既低效又容易出错。为了解决这个问题，我们提出了用于通用抽象学习的重构方法（ReGAL），通过代码重构来学习可重用函数库，即在不改变代码执行输出的情况下重组代码。ReGAL从一小组现有程序中学习，通过执行验证和细化抽象。我们发现，ReGAL发现的共享函数库使得在不同领域预测程序变得更加容易。在三个数据集（LOGO图形生成、日期推理和基于Minecraft的文字游戏TextCraft）上，开源和专有的LLMs在使用ReGAL函数库预测程序时准确性得到提高。

    While large language models (LLMs) are increasingly being used for program synthesis, they lack the global view needed to develop useful abstractions; they generally predict programs one at a time, often repeating the same functionality. Generating redundant code from scratch is both inefficient and error-prone. To address this, we propose Refactoring for Generalizable Abstraction Learning (ReGAL), a gradient-free method for learning a library of reusable functions via code refactorization, i.e. restructuring code without changing its execution output. ReGAL learns from a small set of existing programs, iteratively verifying and refining its abstractions via execution. We find that the shared function libraries discovered by ReGAL make programs easier to predict across diverse domains. On three datasets (LOGO graphics generation, Date reasoning, and TextCraft, a Minecraft-based text game), both open-source and proprietary LLMs improve in accuracy when predicting programs with ReGAL fun
    
[^49]: 基于监督对比学习的双混合模型用于剩余寿命预测

    Supervised Contrastive Learning based Dual-Mixer Model for Remaining Useful Life Prediction. (arXiv:2401.16462v1 [cs.LG])

    [http://arxiv.org/abs/2401.16462](http://arxiv.org/abs/2401.16462)

    本文提出了一种基于监督对比学习的双混合模型，用于剩余寿命预测。该模型通过灵活的特征融合和特征空间全局关系不变性训练方法，提高了预测准确性。

    

    近年来，剩余寿命（RUL）预测问题已经引起了研究人员的广泛关注，旨在准确估计从当前预测时刻到设备完全失效的剩余时间。为了克服现有RUL预测方法中时间和空间特征刚性组合的缺点，本文首次提出了一种名为双混合模型的时空同质特征提取器。采用灵活的逐层递进特征融合，以确保时空特征的同质性并提高预测准确性。其次，基于监督对比学习引入了特征空间全局关系不变性（FSGRI）训练方法。该方法在模型训练过程中维持样本特征与其退化模式之间的关系一致性，简化了输出层中的回归任务，提高了预测性能。

    The problem of the Remaining Useful Life (RUL) prediction, aiming at providing an accurate estimate of the remaining time from the current predicting moment to the complete failure of the device, has gained significant attention from researchers in recent years. In this paper, to overcome the shortcomings of rigid combination for temporal and spatial features in most existing RUL prediction approaches, a spatial-temporal homogeneous feature extractor, named Dual-Mixer model, is firstly proposed. Flexible layer-wise progressive feature fusion is employed to ensure the homogeneity of spatial-temporal features and enhance the prediction accuracy. Secondly, the Feature Space Global Relationship Invariance (FSGRI) training method is introduced based on supervised contrastive learning. This method maintains the consistency of relationships among sample features with their degradation patterns during model training, simplifying the subsequently regression task in the output layer and improvin
    
[^50]: 温和的规范执行：更快的出现，更快乐的智能体

    Norm Enforcement with a Soft Touch: Faster Emergence, Happier Agents. (arXiv:2401.16461v1 [cs.MA])

    [http://arxiv.org/abs/2401.16461](http://arxiv.org/abs/2401.16461)

    通过温和的规范执行，该研究提出了一种新的方法，通过智能体之间的交流推动合作并促进规范的出现。

    

    多智能体系统可视为一个自主智能体的社会，通过社会规范可以有效地调控智能体的交互。一般来说，一个社会的规范并不是硬编码的，而是从智能体的交互中产生的。具体来说，一个社会中的智能体对另一个智能体的行为作出的反应以及对他人反应的回应，决定了社会中出现哪些规范。我们将一个智能体对另一个智能体的满意或不满意行为的反应视为第一个智能体向第二个智能体的交流。理解这些交流是一种社会智能：这些交流通过推动智能体朝着某些行为进行，从而促进规范的出现。虽然众所周知惩罚可以导致规范的出现，但我们认为更宽泛的社会智能可能在促进多智能体系统中的合作方面更有效。因此，我们开发了一种被称为Ne的方法

    A multiagent system can be viewed as a society of autonomous agents, whose interactions can be effectively regulated via social norms. In general, the norms of a society are not hardcoded but emerge from the agents' interactions. Specifically, how the agents in a society react to each other's behavior and respond to the reactions of others determines which norms emerge in the society. We think of these reactions by an agent to the satisfactory or unsatisfactory behaviors of another agent as communications from the first agent to the second agent. Understanding these communications is a kind of social intelligence: these communications provide natural drivers for norm emergence by pushing agents toward certain behaviors, which can become established as norms. Whereas it is well-known that sanctioning can lead to the emergence of norms, we posit that a broader kind of social intelligence can prove more effective in promoting cooperation in a multiagent system.  Accordingly, we develop Ne
    
[^51]: 信用风险与大型语言模型相结合：从P2P借贷的贷款描述中构建风险指标。

    Credit Risk Meets Large Language Models: Building a Risk Indicator from Loan Descriptions in P2P Lending. (arXiv:2401.16458v1 [q-fin.RM])

    [http://arxiv.org/abs/2401.16458](http://arxiv.org/abs/2401.16458)

    本文研究了如何利用P2P借贷平台上借款人提供的文本描述来构建风险指标。结果显示，利用大型语言模型生成的风险评分可以明显提高信用风险分类器的性能。

    

    P2P借贷作为一种独特的融资机制，通过在线平台将借款人与放款人联系起来。然而，P2P借贷面临信息不对称的挑战，因为放款人往往缺乏足够的数据来评估借款人的信用价值。本文提出了一种新颖的方法来解决这个问题，即利用借款人在贷款申请过程中提供的文本描述。我们的方法涉及使用大型语言模型（LLM）处理这些文本描述，LLM是一种能够识别文本中的模式和语义的强大工具。将迁移学习应用于将LLM适应特定任务。我们从Lending Club数据集的分析结果显示，BERT生成的风险评分显著提高了信用风险分类器的性能。然而，基于LLM的系统固有的不透明性，以及潜在偏差的不确定性，限制了其应用。

    Peer-to-peer (P2P) lending has emerged as a distinctive financing mechanism, linking borrowers with lenders through online platforms. However, P2P lending faces the challenge of information asymmetry, as lenders often lack sufficient data to assess the creditworthiness of borrowers. This paper proposes a novel approach to address this issue by leveraging the textual descriptions provided by borrowers during the loan application process. Our methodology involves processing these textual descriptions using a Large Language Model (LLM), a powerful tool capable of discerning patterns and semantics within the text. Transfer learning is applied to adapt the LLM to the specific task at hand.  Our results derived from the analysis of the Lending Club dataset show that the risk score generated by BERT, a widely used LLM, significantly improves the performance of credit risk classifiers. However, the inherent opacity of LLM-based systems, coupled with uncertainties about potential biases, unders
    
[^52]: 有效的可控偏差缓解方法，利用门适配器进行分类和检索。(arXiv:2401.16457v1 [cs.LG])

    Effective Controllable Bias Mitigation for Classification and Retrieval using Gate Adapters. (arXiv:2401.16457v1 [cs.LG])

    [http://arxiv.org/abs/2401.16457](http://arxiv.org/abs/2401.16457)

    本文引入了可控门适配器（ConGater），一种具有可调节敏感性参数的新颖模块化门机制，可在推理时逐渐过渡从模型的偏向状态到完全去偏的版本，并通过实验证明了其在分类和检索任务中的性能。

    

    语言模型的偏差缓解已经成为许多研究的主题，最近关注的焦点是学习独立的模块，例如适配器进行按需去偏。除了优化模块化去偏模型外，在实践中通常需要在推理时控制偏差减少的程度，例如，为了在搜索结果中调整期望的性能-公平性权衡或在分类任务中控制去偏的强度。在本文中，我们引入了可控门适配器（ConGater），一种具有可调节敏感性参数的新颖模块化门机制，允许在推理时从模型的偏向状态逐渐过渡到完全去偏的版本。通过在三个分类任务上对三个不同模型进行对抗性去偏实验，并通过公平性列表正则化来减少搜索结果的偏差，我们展示了ConGater的性能。

    Bias mitigation of Language Models has been the topic of many studies with a recent focus on learning separate modules like adapters for on-demand debiasing. Besides optimizing for a modularized debiased model, it is often critical in practice to control the degree of bias reduction at inference time, e.g., in order to tune for a desired performance-fairness trade-off in search results or to control the strength of debiasing in classification tasks. In this paper, we introduce Controllable Gate Adapter (ConGater), a novel modular gating mechanism with adjustable sensitivity parameters, which allows for a gradual transition from the biased state of the model to the fully debiased version at inference time. We demonstrate ConGater performance by (1) conducting adversarial debiasing experiments with three different models on three classification tasks with four protected attributes, and (2) reducing the bias of search results through fairness list-wise regularization to enable adjusting a
    
[^53]: KAUCUS: 知识增强用户模拟器用于训练语言模型助手

    KAUCUS: Knowledge Augmented User Simulators for Training Language Model Assistants. (arXiv:2401.16454v1 [cs.HC])

    [http://arxiv.org/abs/2401.16454](http://arxiv.org/abs/2401.16454)

    KAUCUS引入了知识增强用户模拟器框架，可以生成多样化的模拟器助手交互，并能够快速引入外部知识，从而提高语言模型助手的训练效果。

    

    通过创建一个能够生成有用交互数据的模拟器，可以开发出一个有效的多轮指令跟随助手。理想的用户模拟器除了依靠其内在权重外，还应能够快速引入外部知识来模拟互联网上多样化的文本。以往的用户模拟器通常缺乏多样性，主要是封闭领域的，并且需要严格的模式，使得它们无法快速扩展以融入外部知识。在这方面，我们介绍了一个名为Kaucus的知识增强用户模拟器框架，以概述创建多样化用户模拟器的过程，并能够无缝地利用外部知识，同时受益于下游助手模型的训练。通过两个基于GPT-J的模拟器，即检索增强模拟器和摘要控制模拟器，我们生成多样化的模拟器助手交互。

    An effective multi-turn instruction-following assistant can be developed by creating a simulator that can generate useful interaction data. Apart from relying on its intrinsic weights, an ideal user simulator should also be able to bootstrap external knowledge rapidly in its raw form to simulate the multifarious diversity of text available over the internet. Previous user simulators generally lacked diversity, were mostly closed domain, and necessitated rigid schema making them inefficient to rapidly scale to incorporate external knowledge. In this regard, we introduce, Kaucus, a Knowledge-Augmented User Simulator framework, to outline a process of creating diverse user simulators, that can seamlessly exploit external knowledge as well as benefit downstream assistant model training. Through two GPT-J based simulators viz., a Retrieval Augmented Simulator and a Summary Controlled Simulator we generate diverse simulator-assistant interactions. Through reward and preference model-based ev
    
[^54]: 混合Transformer和时空自监督学习用于长期交通预测

    Hybrid Transformer and Spatial-Temporal Self-Supervised Learning for Long-term Traffic Prediction. (arXiv:2401.16453v1 [cs.LG])

    [http://arxiv.org/abs/2401.16453](http://arxiv.org/abs/2401.16453)

    本文提出了一个将混合Transformer和时空自监督学习相结合的模型，通过应用自适应数据增强技术和Chebyshev多项式图卷积来提高模型的鲁棒性和对复杂空间依赖性的捕捉能力，并设计了两个自监督学习任务来建模时空异质性，从而提高了模型的准确性和泛化能力。

    

    长期交通预测一直是一项具有挑战性的任务，由于其动态时间依赖性和复杂的空间依赖性。本文提出了一种将混合Transformer和时空自监督学习相结合的模型。该模型通过在交通数据的序列级和图级应用自适应数据增强技术，增强了其鲁棒性。它利用Transformer克服了循环神经网络在捕捉长期序列方面的局限性，并采用Chebyshev多项式图卷积来捕捉复杂的空间依赖性。此外，考虑到时空异质性对交通速度的影响，我们设计了两个自监督学习任务来建模时空异质性，从而提高了模型的准确性和泛化能力。在两个实际数据集PeMS04和PeMS08上进行了实验评估，并进行了可视化和分析，展示了模型的效果。

    Long-term traffic prediction has always been a challenging task due to its dynamic temporal dependencies and complex spatial dependencies. In this paper, we propose a model that combines hybrid Transformer and spatio-temporal self-supervised learning. The model enhances its robustness by applying adaptive data augmentation techniques at the sequence-level and graph-level of the traffic data. It utilizes Transformer to overcome the limitations of recurrent neural networks in capturing long-term sequences, and employs Chebyshev polynomial graph convolution to capture complex spatial dependencies. Furthermore, considering the impact of spatio-temporal heterogeneity on traffic speed, we design two self-supervised learning tasks to model the temporal and spatial heterogeneity, thereby improving the accuracy and generalization ability of the model. Experimental evaluations are conducted on two real-world datasets, PeMS04 and PeMS08, and the results are visualized and analyzed, demonstrating 
    
[^55]: Context-Former：基于潜在条件序列建模的拼接技术

    Context-Former: Stitching via Latent Conditioned Sequence Modeling. (arXiv:2401.16452v1 [cs.LG])

    [http://arxiv.org/abs/2401.16452](http://arxiv.org/abs/2401.16452)

    Context-Former是一种集成了基于情境信息的模仿学习和序列建模的方法，通过拼接次优轨迹片段来改善决策，并提高了Decision Transformer的性能。

    

    离线强化学习（RL）算法可以通过拼接次优轨迹来改善决策，从而获得更优的结果。这种能力是使RL能够学习优于行为策略的策略的关键因素。另一方面，Decision Transformer（DT）将决策建模为序列建模，展示了在离线RL基准测试中竞争性的性能，然而，最近的研究表明DT缺乏拼接能力，因此提高DT性能需要利用拼接能力。为了赋予DT拼接能力，我们将轨迹拼接抽象为专家匹配，并引入了我们的方法ContextFormer，通过模拟有限数量的专家轨迹的表示来集成基于情境信息的模仿学习（IL）和序列建模，以拼接次优轨迹片段。为了验证我们的观点，我们从两个角度进行实验证明：

    Offline reinforcement learning (RL) algorithms can improve the decision making via stitching sub-optimal trajectories to obtain more optimal ones. This capability is a crucial factor in enabling RL to learn policies that are superior to the behavioral policy. On the other hand, Decision Transformer (DT) abstracts the decision-making as sequence modeling, showcasing competitive performance on offline RL benchmarks, however, recent studies demonstrate that DT lacks of stitching capability, thus exploit stitching capability for DT is vital to further improve its performance. In order to endow stitching capability to DT, we abstract trajectory stitching as expert matching and introduce our approach, ContextFormer, which integrates contextual information-based imitation learning (IL) and sequence modeling to stitch sub-optimal trajectory fragments by emulating the representations of a limited number of expert trajectories. To validate our claim, we conduct experiments from two perspectives:
    
[^56]: ACCESS：用于自动修复网页无障碍违规的提示工程

    ACCESS: Prompt Engineering for Automated Web Accessibility Violation Corrections. (arXiv:2401.16450v1 [cs.HC])

    [http://arxiv.org/abs/2401.16450](http://arxiv.org/abs/2401.16450)

    本研究提出了一种用于修复网页无障碍违规的新方法，通过实时修改文档对象模型(DOM)和利用大型语言模型(LLMs)以及提示工程技术，解决了自动修复无障碍错误的问题。

    

    随着对包容性和用户友好技术的需求不断增加，网页无障碍对于确保残障人士(包括视觉、听觉、认知或运动障碍)平等获取在线内容至关重要。尽管存在诸如Web内容无障碍指南(WCAG)和Web无障碍倡议(W3C)等无障碍指导方针和标准，但超过90%的网站仍无法满足必要的无障碍要求。对于残障人士来说，需要一种工具来自动修复网页的无障碍错误。虽然研究已经证明了发现和定位无障碍错误的方法，但没有研究专注于有效修复此类违规行为。本文提出了一种通过实时修改文档对象模型(DOM)来修复网页无障碍违规的新方法，该方法利用无障碍错误信息、大型语言模型(LLMs)和提示工程技术。

    With the increasing need for inclusive and user-friendly technology, web accessibility is crucial to ensuring equal access to online content for individuals with disabilities, including visual, auditory, cognitive, or motor impairments. Despite the existence of accessibility guidelines and standards such as Web Content Accessibility Guidelines (WCAG) and the Web Accessibility Initiative (W3C), over 90\% of websites still fail to meet the necessary accessibility requirements. For web users with disabilities, there exists a need for a tool to automatically fix web page accessibility errors. While research has demonstrated methods to find and target accessibility errors, no research has focused on effectively correcting such violations. This paper presents a novel approach to correcting accessibility violations on the web by modifying the document object model (DOM) in real time with foundation models. Leveraging accessibility error information, large language models (LLMs), and prompt en
    
[^57]: LLM4SecHW: 利用领域特定大型语言模型进行硬件调试

    LLM4SecHW: Leveraging Domain Specific Large Language Model for Hardware Debugging. (arXiv:2401.16448v1 [cs.AR])

    [http://arxiv.org/abs/2401.16448](http://arxiv.org/abs/2401.16448)

    LLM4SecHW是一种利用领域特定大型语言模型进行硬件调试的新框架，通过编制一个开源硬件设计缺陷及其纠正步骤的数据集，并进行中型LLM的精细调优，实现对硬件设计中的错误进行识别和纠正。这为在其他研究领域中应用精细调优领域特定LLM提供了参考工作流程。

    

    本文介绍了LLM4SecHW，一种利用领域特定大型语言模型（LLM）进行硬件调试的新框架。虽然LLM在自动化各种软件开发任务方面取得了成功，但在硬件安全领域的应用受到商业LLM的限制和领域特定数据的稀缺性的影响较大。为了解决这些挑战，我们提出了一种独特的方法，利用版本控制数据编制了一个开源硬件设计缺陷及其纠正步骤的数据集。该数据集为训练硬件的机器学习模型提供了坚实的基础。LLM4SecHW基于该数据集进行中型LLM的精细调优，实现了对硬件设计中的错误进行识别和纠正。这种开创性的方法为在其他研究领域中应用精细调优领域特定LLM提供了参考工作流程。我们对我们提出的系统在多种开源硬件上进行了性能评估。

    This paper presents LLM4SecHW, a novel framework for hardware debugging that leverages domain specific Large Language Model (LLM). Despite the success of LLMs in automating various software development tasks, their application in the hardware security domain has been limited due to the constraints of commercial LLMs and the scarcity of domain specific data. To address these challenges, we propose a unique approach to compile a dataset of open source hardware design defects and their remediation steps, utilizing version control data. This dataset provides a substantial foundation for training machine learning models for hardware. LLM4SecHW employs fine tuning of medium sized LLMs based on this dataset, enabling the identification and rectification of bugs in hardware designs. This pioneering approach offers a reference workflow for the application of fine tuning domain specific LLMs in other research areas. We evaluate the performance of our proposed system on various open source hardwa
    
[^58]: 提升人机协作中的人类体验：基于积极人类收益的以人为中心的建模方法

    Enhancing Human Experience in Human-Agent Collaboration: A Human-Centered Modeling Approach Based on Positive Human Gain. (arXiv:2401.16444v1 [cs.HC])

    [http://arxiv.org/abs/2401.16444](http://arxiv.org/abs/2401.16444)

    本研究提出了一种以人为中心的协作代理人建模方法，旨在增强人类的体验。通过引入基于人类收益的强化学习方法，代理人可以在保持自身能力的同时，增强人类实现预期目标的程度。

    

    现有的游戏人工智能研究主要集中在提升代理人在游戏中的能力，但这并不能本质上让人们在与这些代理人协作时拥有更好的体验。例如，代理人可能会控制协作并展示意外或有害的行为，导致人类合作伙伴的体验不佳。换句话说，大多数游戏人工智能代理人是以“自我为中心”建模的。在本文中，我们提出了一种“以人为中心”的协作代理人建模方案，旨在增强人类的体验。具体而言，我们将人类的体验建模为他们在任务期望达到的目标。我们期望代理人能够学会在保持其原始能力（如在游戏中获胜）的同时，增强人类实现这些目标的程度。为此，我们提出了基于人类收益的强化学习（RLHG）方法。RLHG方法引入了一个“基准”，对应于人类最初预期的程度。

    Existing game AI research mainly focuses on enhancing agents' abilities to win games, but this does not inherently make humans have a better experience when collaborating with these agents. For example, agents may dominate the collaboration and exhibit unintended or detrimental behaviors, leading to poor experiences for their human partners. In other words, most game AI agents are modeled in a "self-centered" manner. In this paper, we propose a "human-centered" modeling scheme for collaborative agents that aims to enhance the experience of humans. Specifically, we model the experience of humans as the goals they expect to achieve during the task. We expect that agents should learn to enhance the extent to which humans achieve these goals while maintaining agents' original abilities (e.g., winning games). To achieve this, we propose the Reinforcement Learning from Human Gain (RLHG) approach. The RLHG approach introduces a "baseline", which corresponds to the extent to which humans primi
    
[^59]: 评估深度网络用于通过手部交互检测用户对虚拟现实的熟悉程度

    Evaluating Deep Networks for Detecting User Familiarity with VR from Hand Interactions. (arXiv:2401.16443v1 [cs.HC])

    [http://arxiv.org/abs/2401.16443](http://arxiv.org/abs/2401.16443)

    通过使用深度分类器和手部追踪技术，本文提出了一种评估用户对虚拟现实熟悉程度的方法，以便在用户不熟悉虚拟现实时为其提供按需培训，从而提高其在虚拟环境中的任务完成效率。

    

    随着虚拟现实设备在消费领域的普及，对于对虚拟现实不熟悉的用户而言，虚拟现实应用的使用可能越来越普遍。检测用户对虚拟现实的熟悉程度作为交互媒介，具有通过提供按需培训进行适应和防止用户在完成任务时被虚拟现实环境所拖累的潜力。本文介绍了使用深度分类器进行自动检测用户对虚拟现实的熟悉程度的初步结果，通过用户使用手部与虚拟现实门锁数字密码输入面板进行交互来解锁虚拟现实门。我们将虚拟现实门作为企业虚拟空间的第一入口点，例如会议室、办公室或诊所。对于不熟悉虚拟现实的用户而言，在现实世界中已经使用过手部打开带有密码输入面板的门。因此，虽然用户可能对虚拟现实不熟悉，但他们对打开门的任务应该是熟悉的。使用 pilot d

    As VR devices become more prevalent in the consumer space, VR applications are likely to be increasingly used by users unfamiliar with VR. Detecting the familiarity level of a user with VR as an interaction medium provides the potential of providing on-demand training for acclimatization and prevents the user from being burdened by the VR environment in accomplishing their tasks. In this work, we present preliminary results of using deep classifiers to conduct automatic detection of familiarity with VR by using hand tracking of the user as they interact with a numeric passcode entry panel to unlock a VR door. We use a VR door as we envision it to the first point of entry to collaborative virtual spaces, such as meeting rooms, offices, or clinics. Users who are unfamiliar with VR will have used their hands to open doors with passcode entry panels in the real world. Thus, while the user may not be familiar with VR, they would be familiar with the task of opening the door. Using a pilot d
    
[^60]: FaKnow: 一个用于虚假新闻检测的统一库

    FaKnow: A Unified Library for Fake News Detection. (arXiv:2401.16441v1 [cs.LG])

    [http://arxiv.org/abs/2401.16441](http://arxiv.org/abs/2401.16441)

    FaKnow是一个统一的虚假新闻检测算法库，包含多种常用的模型和工具，并解决了不同框架下的可重复性和冗余问题。

    

    在过去的几年中，基于深度学习的大量虚假新闻检测算法应运而生。然而，它们往往在不同的框架下开发，每个框架又要求使用不同的方法，因此阻碍了可重复性。此外，这些虚假新闻检测模型的代码开发中存在大量的冗余。为了解决这些问题，我们提出了FaKnow，一个统一且全面的虚假新闻检测算法库。它涵盖了多种常用的虚假新闻检测模型，包括基于内容和基于社会环境的方法。该库涵盖了模型训练和评估流程的完整范围，在一个统一框架内有效组织了数据、模型和训练程序。此外，它还提供了一系列辅助功能和工具，包括可视化和日志记录。我们的工作为虚假新闻检测的标准化和统一化做出了贡献。

    Over the past years, a large number of fake news detection algorithms based on deep learning have emerged. However, they are often developed under different frameworks, each mandating distinct utilization methodologies, consequently hindering reproducibility. Additionally, a substantial amount of redundancy characterizes the code development of such fake news detection models. To address these concerns, we propose FaKnow, a unified and comprehensive fake news detection algorithm library. It encompasses a variety of widely used fake news detection models, categorized as content-based and social context-based approaches. This library covers the full spectrum of the model training and evaluation process, effectively organizing the data, models, and training procedures within a unified framework. Furthermore, it furnishes a series of auxiliary functionalities and tools, including visualization, and logging. Our work contributes to the standardization and unification of fake news detection 
    
[^61]: 超越驱逐预测：利用当地时空公共记录来指导行动

    Beyond Eviction Prediction: Leveraging Local Spatiotemporal Public Records to Inform Action. (arXiv:2401.16440v1 [cs.LG])

    [http://arxiv.org/abs/2401.16440](http://arxiv.org/abs/2401.16440)

    该研究利用当地时空公共记录来预测驱逐风险，并证明这些预测对于指导有针对性的外展政策是有用的。

    

    近年来，基于驱逐风险对房产进行评分引起了相当大的关注。驱逐预测方法的成功通常是通过不同的预测准确度指标来评估的。然而，这种预测的根本目标是为了向可能面临更大风险的家庭提供适当的帮助，以保持住房稳定。因此，我们必须问一个问题，那就是这样的预测在指导外展行动方面有多大的用处。本文利用一个新颖的数据集，将房产、驱逐和业主的信息进行匹配，研究这个问题。我们进行了一项驱逐预测任务，生成风险得分，然后利用这些风险得分来规划有针对性的外展政策。我们显示这些风险得分实际上是有用的，能够使一个理论上的工作人员团队在相同的时间内接触更多容易发生驱逐的房产，相比于以街区为基础或关注特定建筑物的外展政策。

    There has been considerable recent interest in scoring properties on the basis of eviction risk. The success of methods for eviction prediction is typically evaluated using different measures of predictive accuracy. However, the underlying goal of such prediction is to direct appropriate assistance to households that may be at greater risk so they remain stably housed. Thus, we must ask the question of how useful such predictions are in targeting outreach efforts - informing action. In this paper, we investigate this question using a novel dataset that matches information on properties, evictions, and owners. We perform an eviction prediction task to produce risk scores and then use these risk scores to plan targeted outreach policies. We show that the risk scores are, in fact, useful, enabling a theoretical team of caseworkers to reach more eviction-prone properties in the same amount of time, compared to outreach policies that are either neighborhood-based or focus on buildings with 
    
[^62]: 深度神经网络是否高效利用了权重空间？

    Do deep neural networks utilize the weight space efficiently?. (arXiv:2401.16438v1 [cs.LG])

    [http://arxiv.org/abs/2401.16438](http://arxiv.org/abs/2401.16438)

    该论文介绍了一种利用权重矩阵的列空间和行空间的新概念，可以大幅减少深度学习模型的参数而不影响性能。实验证明该方法能够在资源有限的情况下实现参数高效的深度学习模型，并在ImageNet数据集上展现了竞争性的性能。

    

    深度学习模型如Transformer和卷积神经网络（CNN）已经在各个领域引起了革命，但是它们参数密集的特性限制了在资源有限的情况下的应用。在本文中，我们引入一种新的概念，利用权重矩阵的列空间和行空间，可以大幅减少模型参数而不影响性能。利用这种范式，我们实现了参数高效的深度学习模型。我们的方法适用于瓶颈层和注意力层，可以将参数减半，仅带来轻微的性能降低。我们在ImageNet数据集上使用ViT和ResNet50进行了大量实验，证明了我们方法的有效性，在与传统模型的比较中展示了竞争性的性能。这种方法不仅解决了对参数高效的深度学习解决方案的紧迫需求，而且在真实场景的实际部署中具有巨大的潜力。

    Deep learning models like Transformers and Convolutional Neural Networks (CNNs) have revolutionized various domains, but their parameter-intensive nature hampers deployment in resource-constrained settings. In this paper, we introduce a novel concept utilizes column space and row space of weight matrices, which allows for a substantial reduction in model parameters without compromising performance. Leveraging this paradigm, we achieve parameter-efficient deep learning models.. Our approach applies to both Bottleneck and Attention layers, effectively halving the parameters while incurring only minor performance degradation. Extensive experiments conducted on the ImageNet dataset with ViT and ResNet50 demonstrate the effectiveness of our method, showcasing competitive performance when compared to traditional models. This approach not only addresses the pressing demand for parameter efficient deep learning solutions but also holds great promise for practical deployment in real-world scena
    
[^63]: 事件序列的自我监督学习：生成建模和对比学习的比较研究和混合方法的应用

    Self-Supervised Learning in Event Sequences: A Comparative Study and Hybrid Approach of Generative Modeling and Contrastive Learning. (arXiv:2401.15935v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2401.15935](http://arxiv.org/abs/2401.15935)

    本研究通过比较研究和混合方法，调查了事件序列的自我监督学习技术，并引入了一种新的方法，将生成模型和对比嵌入进行对齐。结果显示，这种对齐模型在各种任务上表现优越，为预测事件序列中的信息提供了潜在的好处。

    

    本研究调查了获取事件序列表示的自我监督学习技术。这是各种应用中的关键模态，包括但不限于银行、电子商务和医疗保健。我们对自我监督学习中的生成模型和对比方法进行了全面的研究，并分别应用了它们。我们发现没有一种绝对优越的方法。因此，我们探讨了结合这些方法的潜在好处。为了实现这个目标，我们引入了一种新的方法，将生成模型和对比嵌入作为不同的模态进行对齐，从当代多模态研究中汲取灵感。生成模型和对比方法通常被视为互斥的，因此存在它们的联合探索的空白。我们的结果表明，这种对齐模型在至少与现有方法持平，并且在各种任务上更加普适。此外，我们证明了自我监督学习在预测事件序列中包含的信息方面的潜力。

    This study investigates self-supervised learning techniques to obtain representations of Event Sequences. It is a key modality in various applications, including but not limited to banking, e-commerce, and healthcare.  We perform a comprehensive study of generative and contrastive approaches in self-supervised learning, applying them both independently. We find that there is no single supreme method. Consequently, we explore the potential benefits of combining these approaches. To achieve this goal, we introduce a novel method that aligns generative and contrastive embeddings as distinct modalities, drawing inspiration from contemporary multimodal research.  Generative and contrastive approaches are often treated as mutually exclusive, leaving a gap for their combined exploration. Our results demonstrate that this aligned model performs at least on par with, and mostly surpasses, existing methods and is more universal across a variety of tasks. Furthermore, we demonstrate that self-sup
    
[^64]: 分布一致的结构因果模型

    Distribution-consistency Structural Causal Models. (arXiv:2401.15911v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2401.15911](http://arxiv.org/abs/2401.15911)

    本文提出了分布一致的结构因果模型（DiscoSCMs），用于解决因果建模中的反事实建模挑战。这种模型通过引入分布一致假设来解决因果模型的容量限制，从而提高反事实推理的准确性和实用性。

    

    在因果建模领域，潜在结果和结构因果模型是主要的框架。然而，这些框架在实际建模反事实情况时面临着显著挑战，这些反事实情况形式化为潜在结果的联合分布参数。反事实推理在当代决策过程中具有重要的意义，特别是在需要基于$(Y(0),Y(1))$的联合值进行个性化激励的情景中。本文首先研究了潜在结果和结构因果模型的反事实建模框架。通过分析，我们发现了一种固有的模型容量限制，称为“退化的反事实问题”，这是这两个框架的基石一致性规则所导致的。为了解决这个限制，我们引入了一种新的“分布一致”假设，并根据这个假设提出了分布一致的结构因果模型（DiscoSCMs）。

    In the field of causal modeling, potential outcomes (PO) and structural causal models (SCMs) stand as the predominant frameworks. However, these frameworks face notable challenges in practically modeling counterfactuals, formalized as parameters of the joint distribution of potential outcomes. Counterfactual reasoning holds paramount importance in contemporary decision-making processes, especially in scenarios that demand personalized incentives based on the joint values of $(Y(0), Y(1))$. This paper begins with an investigation of the PO and SCM frameworks for modeling counterfactuals. Through the analysis, we identify an inherent model capacity limitation, termed as the ``degenerative counterfactual problem'', emerging from the consistency rule that is the cornerstone of both frameworks. To address this limitation, we introduce a novel \textit{distribution-consistency} assumption, and in alignment with it, we propose the Distribution-consistency Structural Causal Models (DiscoSCMs) o
    
[^65]: GarchingSim:一种具有逼真场景和极简工作流程的自动驾驶仿真器

    GarchingSim: An Autonomous Driving Simulator with Photorealistic Scenes and Minimalist Workflow. (arXiv:2401.15803v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2401.15803](http://arxiv.org/abs/2401.15803)

    GarchingSim是一种具有逼真场景和用户友好工作流程的自动驾驶仿真器，能与外部算法通信并具有高精度的车辆动力学模型，适用于生成合成数据和使用机器学习算法驾驶。

    

    对于小型创业公司和研究机构来说，进行自动驾驶算法的真实道路测试可能昂贵且不切实际。因此，仿真成为评估这些算法的重要方法。然而，免费和开源的仿真器的可用性有限，对于初学者和跨学科研究人员来说，安装和配置过程可能令人生畏。我们介绍了一个具有逼真场景且用户友好的自动驾驶仿真器。该仿真器能够通过ROS2或Socket.IO与外部算法进行通信，与现有软件堆栈兼容。此外，我们在仿真器中实现了一个高精度的车辆动力学模型，以增强车辆物理效应的真实性。该仿真器能够执行多种功能，包括生成合成数据和使用基于机器学习的算法进行驾驶。此外，我们更注重简约化。

    Conducting real road testing for autonomous driving algorithms can be expensive and sometimes impractical, particularly for small startups and research institutes. Thus, simulation becomes an important method for evaluating these algorithms. However, the availability of free and open-source simulators is limited, and the installation and configuration process can be daunting for beginners and interdisciplinary researchers. We introduce an autonomous driving simulator with photorealistic scenes, meanwhile keeping a user-friendly workflow. The simulator is able to communicate with external algorithms through ROS2 or Socket.IO, making it compatible with existing software stacks. Furthermore, we implement a highly accurate vehicle dynamics model within the simulator to enhance the realism of the vehicle's physical effects. The simulator is able to serve various functions, including generating synthetic data and driving with machine learning-based algorithms. Moreover, we prioritize simplic
    
[^66]: DiffuserLite: 实时扩散规划的研究

    DiffuserLite: Towards Real-time Diffusion Planning. (arXiv:2401.15443v1 [cs.AI])

    [http://arxiv.org/abs/2401.15443](http://arxiv.org/abs/2401.15443)

    DiffuserLite是一个快速轻量级的扩散规划框架，通过引入计划细化过程（PRP）来提高决策频率，相比之前的框架，它只产生了很小的运行时间成本，并在D4RL基准测试中达到了最先进的性能。

    

    扩散规划被认为是各个领域中有效的决策范式。长时间跨度轨迹的高质量条件生成能力使其成为一个有前途的研究方向。然而，现有的扩散规划方法由于迭代抽样成本昂贵而导致决策频率低。为了解决这个问题，我们引入了DiffuserLite，一个快速而轻量级的扩散规划框架。DiffuserLite使用了一个计划细化过程（PRP）来生成粗到细粒度的轨迹，这显著减少了冗余信息的建模，从而显著提高了决策频率。我们的实验结果表明，与之前的框架相比，DiffuserLite仅产生了$0.88\%$的运行时间成本，平均决策频率达到了122Hz，并在D4RL基准测试上达到了最先进的性能。此外，我们的干净DiffuserLite框架可以提供...

    Diffusion planning has been recognized as an effective decision-making paradigm in various domains. The high-quality conditional generation capability of long-horizon trajectories makes it a promising research direction. However, existing diffusion planning methods suffer from low decision-making frequencies because of the expensive iterative sampling cost. To address this issue, we introduce DiffuserLite, a fast and lightweight diffusion planning framework. DiffuserLite employs a planning refinement process (PRP) to generate coarse-to-fine-grained trajectories, which significantly reduces the modeling of redundant information and leads to notable increases in decision-making frequency. Our experimental results demonstrate that DiffuserLite incurs only $0.88\%$ of the runtime cost compared to previous frameworks, achieves an average decision-making frequency of $122$Hz, and reaches state-of-the-art performance on D4RL benchmarks. In addition, our clean DiffuserLite framework can serve 
    
[^67]: 基于RAG的理解伊斯兰教问题回答系统提案：MufassirQAS LLM

    A RAG-based Question Answering System Proposal for Understanding Islam: MufassirQAS LLM. (arXiv:2401.15378v1 [cs.CL])

    [http://arxiv.org/abs/2401.15378](http://arxiv.org/abs/2401.15378)

    基于RAG的MufassirQAS问答系统利用NLP技术建立联系并准确回答复杂问题，提高了LLMs的准确性和透明度，帮助理解伊斯兰教的复杂性和教义深度。

    

    学习和理解宗教存在复杂性和教义深度的挑战。问答机器人作为解决这些挑战的问题回答系统，可以帮助。LLM聊天机器人利用自然语言处理技术建立主题之间的联系，准确回答复杂问题。这些能力使其成为用于宗教启蒙的问题回答聊天机器人的理想选择。然而，LLM也有生成虚假信息的倾向，称为幻觉。聊天机器人的回答可能包含侮辱个人宗教信仰、跨宗派冲突和有争议或敏感的话题的内容。它需要避免这种情况，而不会宣扬仇恨言论或冒犯某些群体的人或他们的信仰。本研究使用基于向量数据库的检索增强生成（RAG）方法来提高LLMs的准确性和透明度。我们的问答系统称为"MufassirQAS"。我们创建了一个模型来评估该系统并证明其在解决宗教行业问题中的效果。

    There exist challenges in learning and understanding religions as the presence of complexity and depth of religious doctrines and teachings. Chatbots as question-answering systems can help in solving these challenges. LLM chatbots use NLP techniques to establish connections between topics and accurately respond to complex questions. These capabilities make it perfect to be used in enlightenment on religion as a question answering chatbot. However, LLMs also have a tendency to generate false information, known as hallucination. The responses of the chatbots can include content that insults personal religious beliefs, interfaith conflicts, and controversial or sensitive topics. It needs to avoid such cases without promoting hate speech or offending certain groups of people or their beliefs. This study uses a vector database-based Retrieval Augmented Generation (RAG) approach to enhance the accuracy and transparency of LLMs. Our question-answering system is called as "MufassirQAS". We cre
    
[^68]: 反思LLM生成数据的真实性：对LLM生成数据的追踪研究

    Under the Surface: Tracking the Artifactuality of LLM-Generated Data. (arXiv:2401.14698v1 [cs.CL])

    [http://arxiv.org/abs/2401.14698](http://arxiv.org/abs/2401.14698)

    本研究是针对大型语言模型（LLM）生成的人工数据的追踪研究，将各种类型的LLM生成文本数据进行了汇总和测试，并揭示了隐藏的质量和多样性问题。这是第一次对LLM生成数据进行综合分析和比较，并引发了对人工数据质量的关注。

    

    本研究探讨了大型语言模型（LLM）在生成人工数据方面的不断扩大的作用。LLM越来越多地用于生成多种输出，包括注释、偏好、指令提示、模拟对话和自由文本。由于这些LLM生成数据形式在应用中经常交叉，它们相互影响，并引发了对训练循环中合并的人工数据质量和多样性的重大关注，形成了一个人工数据生态系统。据我们所知，这是第一项研究将各种类型的LLM生成文本数据汇总起来，从更严格受限的数据如“任务标签”到更自由的“自由文本”。然后我们对LLM生成的人工数据的质量和影响进行了压力测试，并与人工数据在各种现有基准上进行比较。尽管人工数据能够匹配人类表现，但本文揭示了隐藏的巨大隐患。

    This work delves into the expanding role of large language models (LLMs) in generating artificial data. LLMs are increasingly employed to create a variety of outputs, including annotations, preferences, instruction prompts, simulated dialogues, and free text. As these forms of LLM-generated data often intersect in their application, they exert mutual influence on each other and raise significant concerns about the quality and diversity of the artificial data incorporated into training cycles, leading to an artificial data ecosystem. To the best of our knowledge, this is the first study to aggregate various types of LLM-generated text data, from more tightly constrained data like "task labels" to more lightly constrained "free-form text". We then stress test the quality and implications of LLM-generated artificial data, comparing it with human data across various existing benchmarks. Despite artificial data's capability to match human performance, this paper reveals significant hidden d
    
[^69]: 通过GPT引导的蒙特卡洛树搜索从数据中发现数学公式

    Discovering Mathematical Formulas from Data via GPT-guided Monte Carlo Tree Search. (arXiv:2401.14424v1 [cs.LG])

    [http://arxiv.org/abs/2401.14424](http://arxiv.org/abs/2401.14424)

    通过结合MCTS和生成式预训练模型，我们提出了一种新的符号回归算法SR-GPT，在发现数据中的数学公式方面取得了显著的改进。

    

    在科学研究和人工智能中，找到一个简洁且可解释的数学公式来准确描述数据中每个变量与预测值之间的关系是一个关键任务，也是一个重大挑战。这个问题被称为符号回归，是一个NP困难问题。去年，提出了一种基于蒙特卡洛树搜索（MCTS）的符号回归方法，并在多个数据集上获得了sota。虽然与以前的方法相比，该算法在恢复目标表达式方面显示出了相当大的改进，但是在MCTS过程中缺乏引导严重阻碍了其搜索效率。最近，一些算法在MCTS的搜索中添加了一个预训练的策略网络，但是这个预训练的策略网络的泛化能力很差。为了平衡效率和通用性，我们提出了SR-GPT，结合了AlphaZero的思想。SR-GPT是一种新的符号回归算法，将MCTS与一个通用性较好的生成式预训练模型相结合。

    Finding a concise and interpretable mathematical formula that accurately describes the relationship between each variable and the predicted value in the data is a crucial task in scientific research, as well as a significant challenge in artificial intelligence. This problem is referred to as symbolic regression, which is an NP-hard problem. Last year, a symbolic regression method based on Monte Carlo Tree Search (MCTS) was proposed and sota was obtained on multiple datasets. While this algorithm has shown considerable improvement in recovering target expressions compared to previous methods, the lack of guidance during the MCTS process severely hampers its search efficiency. Recently, some algorithms have added a pre-trained policy network to guide the search of MCTS, but the pre-trained policy network generalizes poorly. To balance efficiency and generality, we propose SR-GPT combining ideas from AlphaZero. SR-GPT is a new symbolic regression algorithm that combines MCTS with a Gener
    
[^70]: CreativeSynth：基于多模态扩散的视觉艺术创意融合与合成

    CreativeSynth: Creative Blending and Synthesis of Visual Arts based on Multimodal Diffusion. (arXiv:2401.14066v1 [cs.CV])

    [http://arxiv.org/abs/2401.14066](http://arxiv.org/abs/2401.14066)

    CreativeSynth是一种基于多模态扩散的创新统一框架，通过整合多模态特征和定制的注意力机制，实现了将现实世界的语义内容导入到艺术领域中，能够协调多模态输入和多任务，在艺术图像生成方面具有重要意义。

    

    大规模的文本到图像生成模型取得了巨大的进步，展示了其合成各种高质量图像的能力。然而，将这些模型应用于艺术图像编辑面临两个重要挑战。首先，用户往往难以构建详细描述输入图像视觉元素的文本提示。其次，现有模型在特定区域进行修改时常常会破坏整体艺术风格，使得实现一致且具有审美统一的作品变得更加复杂。为了克服这些障碍，我们构建了一种创新的统一框架CreativeSynth，该框架基于具有协调多模态输入和多任务能力的扩散模型，通过整合多模态特征和定制的注意力机制，CreativeSynth实现了将现实世界的语义内容导入到艺术领域中，实现了反转和实时风格转移。

    Large-scale text-to-image generative models have made impressive strides, showcasing their ability to synthesize a vast array of high-quality images. However, adapting these models for artistic image editing presents two significant challenges. Firstly, users struggle to craft textual prompts that meticulously detail visual elements of the input image. Secondly, prevalent models, when effecting modifications in specific zones, frequently disrupt the overall artistic style, complicating the attainment of cohesive and aesthetically unified artworks. To surmount these obstacles, we build the innovative unified framework CreativeSynth, which is based on a diffusion model with the ability to coordinate multimodal inputs and multitask in the field of artistic image generation. By integrating multimodal features with customized attention mechanisms, CreativeSynth facilitates the importation of real-world semantic content into the domain of art through inversion and real-time style transfer. T
    
[^71]: 研究大型语言模型在代码克隆检测方面的功效

    Investigating the Efficacy of Large Language Models for Code Clone Detection. (arXiv:2401.13802v1 [cs.SE])

    [http://arxiv.org/abs/2401.13802](http://arxiv.org/abs/2401.13802)

    这项研究探索了大型语言模型在代码克隆检测任务中的应用。

    

    大型语言模型（LLMs）在各种自然语言处理和软件工程任务中表现出了显著的成功，例如代码生成。LLMs主要在基于提示的零/少样本范式中被用于指导模型完成任务。本研究探索了LLMs在代码克隆检测（CCD）这一非生成任务中的适用性。

    Large Language Models (LLMs) have demonstrated remarkable success in various natural language processing and software engineering tasks, such as code generation. The LLMs are mainly utilized in the prompt-based zero/few-shot paradigm to guide the model in accomplishing the task. %\textbf{Goal:} GPT-based models are one of the popular ones studied for tasks such as code comment generation or test generation. These tasks are `generative' tasks. However, there is limited research on the usage of LLMs for `non-generative' tasks such as classification using the prompt-based paradigm. In this preliminary exploratory study, we investigated the applicability of LLMs for Code Clone Detection (CCD), a non-generative task. %\textbf{Method:} By building a mono-lingual and cross-lingual CCD dataset derived from CodeNet, we first investigated two different prompts using ChatGPT to detect \textcolor{black}{Type-4} code clones in Java-Java and Java-Ruby pairs in a zero-shot setting. We \textcolor{blac
    
[^72]: Tensor视图拓扑图神经网络

    Tensor-view Topological Graph Neural Network. (arXiv:2401.12007v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2401.12007](http://arxiv.org/abs/2401.12007)

    提出了一种新颖的Tensor视图拓扑图神经网络（TTG-NN），该方法结合了持久同调、图卷积和张量运算，同时捕捉了局部和全局层面上的Tensor视图拓扑（TT）和Tensor视图图（TG）结构信息。

    

    图分类是一项重要的图结构数据学习任务。图神经网络（GNNs）近年来在图学习中引起了越来越多的关注，并在许多重要的图问题上显示出显著的改进。尽管现有的GNNs在性能上处于最前沿，但它们只使用了每个节点周围非常有限的邻域的局部信息，导致了多模态信息的丢失和过多计算的开销。为了解决这些问题，我们提出了一种新颖的Tensor视图拓扑图神经网络（TTG-NN），这是一种简单而有效的基于持久同调、图卷积和张量运算的拓扑深度学习方法。这种新方法同时捕捉了局部和全局层面上的Tensor视图拓扑（TT）和Tensor视图图（TG）结构信息，并在计算上充分利用了图的拓扑和结构。

    Graph classification is an important learning task for graph-structured data. Graph neural networks (GNNs) have recently gained growing attention in graph learning and have shown significant improvements in many important graph problems. Despite their state-of-the-art performances, existing GNNs only use local information from a very limited neighborhood around each node, suffering from loss of multi-modal information and overheads of excessive computation. To address these issues, we propose a novel Tensor-view Topological Graph Neural Network (TTG-NN), a class of simple yet effective topological deep learning built upon persistent homology, graph convolution, and tensor operations. This new method incorporates tensor learning to simultaneously capture Tensor-view Topological (TT), as well as Tensor-view Graph (TG) structural information on both local and global levels. Computationally, to fully exploit graph topology and structure, we propose two flexible TT and TG representation lea
    
[^73]: 利用深度学习对脑电解码中的欧几里得对齐进行系统评估

    A Systematic Evaluation of Euclidean Alignment with Deep Learning for EEG Decoding. (arXiv:2401.10746v1 [eess.SP])

    [http://arxiv.org/abs/2401.10746](http://arxiv.org/abs/2401.10746)

    本研究系统评估了使用深度学习和欧几里得对齐对脑电解码的影响。结果表明，欧几里得对齐能够显著提高解码率，并且减少了收敛时间。

    

    脑电图（EEG）信号经常用于各种脑机接口（BCI）任务。尽管深度学习（DL）技术显示出有希望的结果，但它们受到大量数据要求的限制。通过利用来自多个受试者的数据，迁移学习能够更有效地训练DL模型。一种越来越受欢迎的技术是欧几里得对齐（EA），因为它易于使用、计算复杂度低并且与深度学习模型兼容。然而，很少有研究评估其对共享和个体DL模型的训练效果的影响。在这项工作中，我们系统地评估了EA与DL相结合在解码BCI信号中的效果。我们使用EA来训练来自多个受试者的共享模型，并评估其对新受试者的可迁移性。我们的实验结果表明，它将目标受试者的解码率提高了4.33％，并且收敛时间缩短了超过70％。我们还为个体模型进行了训练。

    Electroencephalography (EEG) signals are frequently used for various Brain-Computer Interface (BCI) tasks. While Deep Learning (DL) techniques have shown promising results, they are hindered by the substantial data requirements. By leveraging data from multiple subjects, transfer learning enables more effective training of DL models. A technique that is gaining popularity is Euclidean Alignment (EA) due to its ease of use, low computational complexity, and compatibility with Deep Learning models. However, few studies evaluate its impact on the training performance of shared and individual DL models. In this work, we systematically evaluate the effect of EA combined with DL for decoding BCI signals. We used EA to train shared models with data from multiple subjects and evaluated its transferability to new subjects. Our experimental results show that it improves decoding in the target subject by 4.33% and decreases convergence time by more than 70%. We also trained individual models for 
    
[^74]: 基于噪声对比估计的低资源安全攻击模式识别匹配框架

    Noise Contrastive Estimation-based Matching Framework for Low-resource Security Attack Pattern Recognition. (arXiv:2401.10337v1 [cs.LG])

    [http://arxiv.org/abs/2401.10337](http://arxiv.org/abs/2401.10337)

    该论文提出了一种基于噪声对比估计的低资源安全攻击模式识别匹配框架，通过直接语义相似度决定文本与攻击模式之间的关联，以降低大量类别、标签分布不均和标签空间复杂性带来的学习难度。

    

    战术、技术和程序（TTPs）是网络安全领域中复杂的攻击模式，在文本知识库中有详细的描述。在网络安全写作中识别TTPs，通常称为TTP映射，是一个重要而具有挑战性的任务。传统的学习方法通常以经典的多类或多标签分类设置为目标。由于存在大量的类别（即TTPs），标签分布的不均衡和标签空间的复杂层次结构，这种设置限制了模型的学习能力。我们采用了一种不同的学习范式来解决这个问题，其中将文本与TTP标签之间的直接语义相似度决定为文本分配给TTP标签，从而减少了仅仅在大型标签空间上竞争的复杂性。为此，我们提出了一种具有有效的基于采样的学习比较机制的神经匹配架构，促进学习过程。

    Tactics, Techniques and Procedures (TTPs) represent sophisticated attack patterns in the cybersecurity domain, described encyclopedically in textual knowledge bases. Identifying TTPs in cybersecurity writing, often called TTP mapping, is an important and challenging task. Conventional learning approaches often target the problem in the classical multi-class or multilabel classification setting. This setting hinders the learning ability of the model due to a large number of classes (i.e., TTPs), the inevitable skewness of the label distribution and the complex hierarchical structure of the label space. We formulate the problem in a different learning paradigm, where the assignment of a text to a TTP label is decided by the direct semantic similarity between the two, thus reducing the complexity of competing solely over the large labeling space. To that end, we propose a neural matching architecture with an effective sampling-based learn-to-compare mechanism, facilitating the learning pr
    
[^75]: 用空间自适应滤波重新思考谱图神经网络

    Rethinking Spectral Graph Neural Networks with Spatially Adaptive Filtering. (arXiv:2401.09071v1 [cs.LG])

    [http://arxiv.org/abs/2401.09071](http://arxiv.org/abs/2401.09071)

    本文重新思考了谱图神经网络，并揭示了谱滤波和空间聚合之间的联系。该研究发现，谱滤波在隐含地将原始图转换成适应性新图，并明确计算用于空间聚合的新图。适应性新图展现出非局部性，并能够反映节点之间的标签一致性。

    

    尽管谱图神经网络（GNN）在理论上在谱域中有很好的基础，但它们实际上依赖于多项式逼近，意味着它们与空间域有着深刻的联系。由于以前的研究很少从空间角度研究谱图GNN，因此它们在空间域的可解释性仍然难以捉摸，例如，谱图GNN在空间域中实际上编码了哪些信息？为了回答这个问题，本文在谱滤波和空间聚合之间建立了一个理论上的联系，揭示了谱滤波隐含地将原始图转换成适应性新图的内在交互作用，并明确地计算用于空间聚合的适应性新图。理论和经验研究表明，适应性新图不仅表现出非局部性，还能够容纳有符号的边权重以反映节点之间的标签一致性。因此，这些发现突显了谱图GNN在空间中的可解释性角色。

    Whilst spectral Graph Neural Networks (GNNs) are theoretically well-founded in the spectral domain, their practical reliance on polynomial approximation implies a profound linkage to the spatial domain. As previous studies rarely examine spectral GNNs from the spatial perspective, their spatial-domain interpretability remains elusive, e.g., what information is essentially encoded by spectral GNNs in the spatial domain? In this paper, to answer this question, we establish a theoretical connection between spectral filtering and spatial aggregation, unveiling an intrinsic interaction that spectral filtering implicitly leads the original graph to an adapted new graph, explicitly computed for spatial aggregation. Both theoretical and empirical investigations reveal that the adapted new graph not only exhibits non-locality but also accommodates signed edge weights to reflect label consistency between nodes. These findings thus highlight the interpretable role of spectral GNNs in the spatial 
    
[^76]: 通过迭代组合问题来增强数学问题求解

    Augmenting Math Word Problems via Iterative Question Composing. (arXiv:2401.09003v1 [cs.CL])

    [http://arxiv.org/abs/2401.09003](http://arxiv.org/abs/2401.09003)

    本研究通过引入MMIQC数据集和迭代组合问题(IQC)的新颖增强方法，成功提高了大型语言模型的数学推理能力，在竞赛级数学问题上取得了优于先前最佳结果的准确率。

    

    尽管在改善大型语言模型(LLMs)的数学推理能力方面取得了一定进展，但在不使用外部工具的情况下解决竞赛级数学问题仍然对开源LLMs具有挑战性。在这项工作中，我们介绍了MMIQC数据集，这是一个混合处理的网络数据和合成问题-响应对的混合数据集，以提供基础模型更好的数学推理能力。通过在MMIQC上对Mistral-7B(arXiv:2310.06825)进行微调获得的模型Mistral-7B-MMIQC，在MATH(arXiv:2103.03874)上达到了36.0%的准确率，比之前(model size $\sim$7B)的最佳结果高出5.8%。我们的实验还表明，改进的一个重要部分归功于我们的新颖增强方法IQC(迭代组合问题)，其中我们迭代地要求LLM从给定的种子问题中组合新问题，并从另一个LLM中进行拒绝抽样。MMIQC现已在https://huggingface.co/datasets/Vivacem/MMIQC上发布。

    Despite recent progress in improving the mathematical reasoning ability of large language models(LLMs), solving competition-level math problems without the use of external tools remains challenging for open-source LLMs. In this work, we introduce the MMIQC dataset, a mixture of processed web data and synthetic question-response pairs, to equip base models with better mathematical reasoning skills. Mistral-7B-MMIQC, the model obtained by fine-tuning Mistral-7B(arXiv:2310.06825) on MMIQC, achieves 36.0\% accuracy on MATH(arXiv:2103.03874), 5.8\% higher than the previous (model size $\sim$7B) SOTA. Our experiments also show that a large part of the improvement attributes to our novel augmentation method IQC(Iterative Question Composing), where we iteratively ask an LLM to compose new questions from the given seed problems and do rejection sampling from another LLM. MMIQC has now been released on https://huggingface.co/datasets/Vivacem/MMIQC.
    
[^77]: CoSSegGaussians：紧凑且迅速的3D高斯场景分割方法

    CoSSegGaussians: Compact and Swift Scene Segmenting 3D Gaussians. (arXiv:2401.05925v1 [cs.CV])

    [http://arxiv.org/abs/2401.05925](http://arxiv.org/abs/2401.05925)

    CoSSegGaussians是一种紧凑且迅速的3D高斯场景分割方法，通过映射空间和语义特征实现紧凑和可靠的零样本场景分割。

    

    我们提出了一种紧凑且迅速的3D高斯场景分割方法（CoSSegGaussians），该方法仅使用RGB图像输入，以快速的渲染速度实现紧凑的3D一致性场景分割。先前基于NeRF的3D分割方法依赖于隐式或体素神经场表示和光线行进体积渲染，这些方法耗时较长。最近的3D高斯场投影显著提高了渲染速度，然而，现有的基于高斯的分割方法（例如高斯分组）在零样本分割中没有提供紧凑的分割掩模，主要原因是在遇到不一致的2D机器生成标签时，无法直接为每个高斯分配可学习参数，缺乏鲁棒性和紧凑性。我们的方法旨在通过使用浅层解码网络将每个高斯点的融合空间和语义上有意义的特征映射，迅速实现紧凑且可靠的零样本场景分割。

    We propose Compact and Swift Segmenting 3D Gaussians(CoSSegGaussians), a method for compact 3D-consistent scene segmentation at fast rendering speed with only RGB images input. Previous NeRF-based 3D segmentation methods have relied on implicit or voxel neural scene representation and ray-marching volume rendering which are time consuming. Recent 3D Gaussian Splatting significantly improves the rendering speed, however, existing Gaussians-based segmentation methods(eg: Gaussian Grouping) fail to provide compact segmentation masks especially in zero-shot segmentation, which is mainly caused by the lack of robustness and compactness for straightforwardly assigning learnable parameters to each Gaussian when encountering inconsistent 2D machine-generated labels. Our method aims to achieve compact and reliable zero-shot scene segmentation swiftly by mapping fused spatial and semantically meaningful features for each Gaussian point with a shallow decoding network. Specifically, our method fi
    
[^78]: TwinBooster: 结合Barlow Twins和梯度提升的大语言模型协同增强分子属性预测

    TwinBooster: Synergising Large Language Models with Barlow Twins and Gradient Boosting for Enhanced Molecular Property Prediction. (arXiv:2401.04478v1 [q-bio.BM])

    [http://arxiv.org/abs/2401.04478](http://arxiv.org/abs/2401.04478)

    TwinBooster结合了大语言模型、Barlow Twins和梯度提升，通过整合生物检测方法和分子指纹，实现了对未见过的生物检测方法和分子属性的精确预测，该方法在数据稀缺的情况下展现出了优秀的性能。

    

    药物发现和开发的成功依赖于对分子活性和属性的精确预测。虽然基于计算的分子属性预测显示出了显著的潜力，但其使用迄今为止仅限于大量数据可用的检测方法。在本研究中，我们使用经过微调的大语言模型，结合了基于文本信息的生物检测方法，并使用了一种新颖的自监督学习方法的Siamese神经网络Barlow Twins。该架构利用检测方法信息和分子指纹提取真实的分子信息。TwinBooster通过提供最先进的零样本学习任务，实现了对未见过的生物检测方法和分子的属性预测。值得注意的是，我们的人工智能流水线在FS-Mol基准测试上表现出优秀的性能。这一突破展示了深度学习在通常数据稀缺的关键属性预测任务中的应用。

    The success of drug discovery and development relies on the precise prediction of molecular activities and properties. While in silico molecular property prediction has shown remarkable potential, its use has been limited so far to assays for which large amounts of data are available. In this study, we use a fine-tuned large language model to integrate biological assays based on their textual information, coupled with Barlow Twins, a Siamese neural network using a novel self-supervised learning approach. This architecture uses both assay information and molecular fingerprints to extract the true molecular information. TwinBooster enables the prediction of properties of unseen bioassays and molecules by providing state-of-the-art zero-shot learning tasks. Remarkably, our artificial intelligence pipeline shows excellent performance on the FS-Mol benchmark. This breakthrough demonstrates the application of deep learning to critical property prediction tasks where data is typically scarce.
    
[^79]: 从LLM到对话代理：具有大型语言模型微调的记忆增强架构

    From LLM to Conversational Agent: A Memory Enhanced Architecture with Fine-Tuning of Large Language Models. (arXiv:2401.02777v1 [cs.CL])

    [http://arxiv.org/abs/2401.02777](http://arxiv.org/abs/2401.02777)

    这项工作介绍了一种名为RAISE的架构，它将大型语言模型（LLMs）如GPT-4整合到对话代理中，通过引入双组件记忆系统来增强代理在多轮对话中的可控性和适应性。预liminary evaluations表明，RAISE在房地产销售领域具有优势，并具有广泛应用的潜力。

    

    本文介绍了RAISE（Scratchpad和Examples辅助推理和行为）,一种先进的架构，增强了将GPT-4等大型语言模型（LLMs）整合到对话代理中的能力。RAISE是ReAct框架的改进版本，包括一个双组件记忆系统，模仿人类的短期记忆和长期记忆，以保持对话的上下文和连续性。它包括了一个全面的代理构建情景，包括对话选择，场景提取，CoT完成和场景增强等阶段，最终导致LLMs的训练阶段。这种方法似乎提高了代理在复杂的多轮对话中的可控性和适应性。我们在房地产销售环境中的初步评估表明，RAISE相对于传统代理有一些优势，表明它在更广泛的应用中具有潜力。通过提供一个强大的框架来开发更具上下文感知和多功能的对话代理，这项工作为AI领域做出了贡献。

    This paper introduces RAISE (Reasoning and Acting through Scratchpad and Examples), an advanced architecture enhancing the integration of Large Language Models (LLMs) like GPT-4 into conversational agents. RAISE, an enhancement of the ReAct framework, incorporates a dual-component memory system, mirroring human short-term and long-term memory, to maintain context and continuity in conversations. It entails a comprehensive agent construction scenario, including phases like Conversation Selection, Scene Extraction, CoT Completion, and Scene Augmentation, leading to the LLMs Training phase. This approach appears to enhance agent controllability and adaptability in complex, multi-turn dialogues. Our preliminary evaluations in a real estate sales context suggest that RAISE has some advantages over traditional agents, indicating its potential for broader applications. This work contributes to the AI field by providing a robust framework for developing more context-aware and versatile convers
    
[^80]: 现代舞应用中三维人体姿势和形状估计方法调查

    Survey of 3D Human Body Pose and Shape Estimation Methods for Contemporary Dance Applications. (arXiv:2401.02383v1 [cs.CV])

    [http://arxiv.org/abs/2401.02383](http://arxiv.org/abs/2401.02383)

    这项研究调查了现代舞和表演艺术中的三维人体形状和姿势估计方法，发现多帧方法在现代舞蹈表演中的姿势估计方面比单帧方法效果更好。

    

    从RGB图像中估计三维人体形状和姿势是一个具有挑战性的问题，具有增强/虚拟现实、医疗保健和健身技术以及虚拟零售等潜在应用。最近的解决方案主要关注三种类型的输入：i）单个图像，ii）多视图图像和iii）视频。在这项研究中，我们调查并比较了现代舞和表演艺术中的三维人体形状和姿势估计方法，特别关注人体姿势和穿着、摄像机视角、照明条件和背景条件。我们证明了对于现代舞蹈表演中的姿势估计，如PHALP这样的多帧方法比单帧方法提供更好的结果。

    3D human body shape and pose estimation from RGB images is a challenging problem with potential applications in augmented/virtual reality, healthcare and fitness technology and virtual retail. Recent solutions have focused on three types of inputs: i) single images, ii) multi-view images and iii) videos. In this study, we surveyed and compared 3D body shape and pose estimation methods for contemporary dance and performing arts, with a special focus on human body pose and dressing, camera viewpoint, illumination conditions and background conditions. We demonstrated that multi-frame methods, such as PHALP, provide better results than single-frame method for pose estimation when dancers are performing contemporary dances.
    
[^81]: FENet: 增强聚焦网络用于车道检测

    FENet: Focusing Enhanced Network for Lane Detection. (arXiv:2312.17163v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2312.17163](http://arxiv.org/abs/2312.17163)

    FENet是一个增强聚焦网络用于精准车道检测，通过聚焦采样和部分视野评估等创新方法，显著提高了检测准确性，尤其适用于曲线和远距离车道，在安全性方面具有重要意义。

    

    受到人类驾驶注意力的启发，本研究首次开发了增强聚焦采样、部分视野评估、增强FPN架构和定向IoU损失的网络创新，解决了自动驾驶车道检测中的精准性障碍。实验证明，我们的聚焦采样策略，强调远处重要细节，与均匀方法相比，显著提高了基准和实际曲线/远距离车道识别的准确性，这对安全至关重要。虽然FENetV1通过模拟驾驶员视觉的透视感知上下文改进，实现了最先进的传统度量性能，但FENetV2在提出的部分视野分析中证明是最可靠的。因此，我们特别推荐V2用于实际车道导航，尽管在标准的整张图像测量上有轻微的降级。未来的方向包括收集实际道路数据和集成互补的双重框架，以进一步通过人类感知指导实现突破性进展。

    Inspired by human driving focus, this research pioneers networks augmented with Focusing Sampling, Partial Field of View Evaluation, Enhanced FPN architecture and Directional IoU Loss - targeted innovations addressing obstacles to precise lane detection for autonomous driving. Experiments demonstrate our Focusing Sampling strategy, emphasizing vital distant details unlike uniform approaches, significantly boosts both benchmark and practical curved/distant lane recognition accuracy essential for safety. While FENetV1 achieves state-of-the-art conventional metric performance via enhancements isolating perspective-aware contexts mimicking driver vision, FENetV2 proves most reliable on the proposed Partial Field analysis. Hence we specifically recommend V2 for practical lane navigation despite fractional degradation on standard entire-image measures. Future directions include collecting on-road data and integrating complementary dual frameworks to further breakthroughs guided by human perc
    
[^82]: 文本到图像扩散模型的语义引导调整

    Semantic Guidance Tuning for Text-To-Image Diffusion Models. (arXiv:2312.15964v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2312.15964](http://arxiv.org/abs/2312.15964)

    本文提出了一种简单的、不需要训练的方法，用于调节文本到图像扩散模型在推理过程中的引导方向，以提高生成图像的语义对齐性。

    

    最近文本到图像（T2I）扩散模型的进展展现出了令人印象深刻的成功，能够生成具有零样本泛化能力的高质量图像。然而，目前的模型在紧密遵循提示语义方面存在困难，经常错误地表示或忽视特定属性。为了解决这个问题，我们提出了一种简单的、不需要训练的方法，在推理过程中调节扩散模型的引导方向。我们首先将提示语义分解为一组概念，并监控引导轨迹与每个概念的关系。我们的关键观察是，模型在遵循提示语义方面的偏差与引导与一个或多个这些概念的偏离高度相关。基于这个观察，我们设计了一种技术，将引导方向引导到模型偏离的任何概念。广泛的实验验证了我们的方法改善了扩散模型生成的图像的语义对齐性。

    Recent advancements in Text-to-Image (T2I) diffusion models have demonstrated impressive success in generating high-quality images with zero-shot generalization capabilities. Yet, current models struggle to closely adhere to prompt semantics, often misrepresenting or overlooking specific attributes. To address this, we propose a simple, training-free approach that modulates the guidance direction of diffusion models during inference. We first decompose the prompt semantics into a set of concepts, and monitor the guidance trajectory in relation to each concept. Our key observation is that deviations in model's adherence to prompt semantics are highly correlated with divergence of the guidance from one or more of these concepts. Based on this observation, we devise a technique to steer the guidance direction towards any concept from which the model diverges. Extensive experimentation validates that our method improves the semantic alignment of images generated by diffusion models in resp
    
[^83]: Auto311: 一种基于信心指导的自动非紧急通话系统

    Auto311: A Confidence-guided Automated System for Non-emergency Calls. (arXiv:2312.14185v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.14185](http://arxiv.org/abs/2312.14185)

    Auto311是第一个处理非紧急电话的自动化系统，它通过减轻非紧急电话负担，提供快速有效的响应。通过预测事件类型并生成个性化的案件报告，并从对话上下文中提取关键信息来完善报告，系统与主叫人之间的对话结构得到优化。

    

    紧急和非紧急响应系统是地方政府提供的基本服务，对于保护生命、环境和财产至关重要。有效处理（非）紧急电话对公共安全和福祉至关重要。通过减轻非紧急电话的负担，亟需911求助的居民将获得快速有效的响应。我们与纳什维尔紧急通信部门合作，分析了11,796个非紧急呼叫录音，并开发了Auto311，第一个处理311非紧急呼叫的自动化系统，该系统（1）有效动态地预测正在进行的非紧急事件类型，以在通话过程中生成个性化的案件报告；（2）从对话上下文中提取关键信息，完成生成的报告；（3）以优化的信心水平安排系统和主叫人之间的对话结构。我们使用实际数据评估了该系统的有效性。

    Emergency and non-emergency response systems are essential services provided by local governments and critical to protecting lives, the environment, and property. The effective handling of (non-)emergency calls is critical for public safety and well-being. By reducing the burden through non-emergency callers, residents in critical need of assistance through 911 will receive a fast and effective response. Collaborating with the Department of Emergency Communications (DEC) in Nashville, we analyzed 11,796 non-emergency call recordings and developed Auto311, the first automated system to handle 311 non-emergency calls, which (1) effectively and dynamically predicts ongoing non-emergency incident types to generate tailored case reports during the call; (2) itemizes essential information from dialogue contexts to complete the generated reports; and (3) strategically structures system-caller dialogues with optimized confidence. We used real-world data to evaluate the system's effectiveness a
    
[^84]: Fine-Tuning还是检索？比较在LLMs中的知识注入

    Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs. (arXiv:2312.05934v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2312.05934](http://arxiv.org/abs/2312.05934)

    该研究比较了无监督的微调和检索增强生成（RAG）这两种常见方法在LLMs中的应用。结果发现，RAG在现有知识和新知识上表现出更好的性能，而LLMs通过无监督的微调学习新的事实信息较困难。

    

    大型语言模型（LLMs）在其预训练的权重中封装了大量的事实信息，正如它们能够在不同领域回答各种问题所证明的那样。然而，这种知识本质上是有限的，很大程度上依赖于训练数据的特性。因此，使用外部数据集来整合新的信息或改进LLMs在已见信息上的能力面临着重大挑战。在这个研究中，我们比较了两种常见的方法：无监督的微调和检索增强生成（RAG）。我们在不同主题的各种知识密集型任务上评估了这两种方法。我们的发现表明，虽然无监督的微调能够提供一定的改进，但RAG在现有知识和完全新知识上始终表现出更好的性能。此外，我们发现LLMs很难通过无监督的微调来学习新的事实信息，并且暴露

    Large language models (LLMs) encapsulate a vast amount of factual information within their pre-trained weights, as evidenced by their ability to answer diverse questions across different domains. However, this knowledge is inherently limited, relying heavily on the characteristics of the training data. Consequently, using external datasets to incorporate new information or refine the capabilities of LLMs on previously seen information poses a significant challenge. In this study, we compare two common approaches: unsupervised fine-tuning and retrieval-augmented generation (RAG). We evaluate both approaches on a variety of knowledge-intensive tasks across different topics. Our findings reveal that while unsupervised fine-tuning offers some improvement, RAG consistently outperforms it, both for existing knowledge encountered during training and entirely new knowledge. Moreover, we find that LLMs struggle to learn new factual information through unsupervised fine-tuning, and that exposing
    
[^85]: 生成AI增强了个体创造力，但降低了新内容的集体多样性

    Generative AI enhances individual creativity but reduces the collective diversity of novel content. (arXiv:2312.00506v2 [cs.HC] UPDATED)

    [http://arxiv.org/abs/2312.00506](http://arxiv.org/abs/2312.00506)

    生成AI增强了个体创造力，但降低了新内容的集体多样性。

    

    创造力是人类的核心。生成人工智能（GenAI），包括越来越强大的大型语言模型（LLM），通过提供新的想法使人类更具创造力，或通过锚定于GenAI的想法而变得不那么创造性。本研究通过在线实验研究探究了GenAI想法对一篇短篇小说创作的因果影响，其中一些作者可以从GenAI平台获取故事创意。我们发现，获取GenAI想法导致故事被评为更有创造力、写得更好和更令人愉悦，特别是在创造力较低的作者中。然而，GenAI启用的故事之间更相似，而不是仅由人类创作的故事。这些结果表明，个体创造力增加的同时，集体新颖性可能会减少。这种动态类似于社会困境：通过GenAI，个别作家能受益，但可能会产生更窄范围的新内容。我们的结果对研究人员、决策者有重要影响。

    Creativity is core to being human. Generative artificial intelligence (GenAI) -- including ever more powerful large language models (LLMs) -- holds promise for humans to be more creative by offering new ideas, or less creative by anchoring on GenAI ideas. We study the causal impact of GenAI ideas on the production of a short story in an online experimental study where some writers could obtain story ideas from a GenAI platform. We find that access to GenAI ideas causes stories to be evaluated as more creative, better written, and more enjoyable, especially among less creative writers. However, GenAI-enabled stories are more similar to each other than stories by humans alone. These results point to an increase in individual creativity at the risk of losing collective novelty. This dynamic resembles a social dilemma: with GenAI, individual writers are better off, but collectively a narrower scope of novel content may be produced. Our results have implications for researchers, policy-make
    
[^86]: 战争与和平（WarAgent）：基于大语言模型的世界大战多智能体模拟

    War and Peace (WarAgent): Large Language Model-based Multi-Agent Simulation of World Wars. (arXiv:2311.17227v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2311.17227](http://arxiv.org/abs/2311.17227)

    本研究提出了一个名为WarAgent的大语言模型驱动的多智能体AI系统，用于模拟历史国际冲突，并通过评估其效果和研究智能体之间的相互作用，探讨了战争的引发因素和条件。

    

    我们能否在历史的十字路口避免战争？这个问题在人类历史上一直被个人、学者、决策者和组织追求。在这项研究中，我们尝试根据人工智能（AI）和大语言模型（LLM）的最新进展来回答这个问题。我们提出了一种名为WarAgent的LLM驱动的多智能体AI系统，以模拟参与国家，在历史上的国际冲突，包括第一次世界大战（WWI）、第二次世界大战（WWII）和中国古代的战国时期（WSP）中的决策和后果。通过评估模拟的有效性，我们研究了尖端AI系统在研究复杂的集体人类行为，如国际冲突在不同环境下的能力的进展和局限性。在这些模拟中，智能体之间的相互作用也为考察引发战争的触发因素和条件提供了一种新视角。我们的发现为了解战争的触发因素和条件提供了新的观点。

    Can we avoid wars at the crossroads of history? This question has been pursued by individuals, scholars, policymakers, and organizations throughout human history. In this research, we attempt to answer the question based on the recent advances of Artificial Intelligence (AI) and Large Language Models (LLMs). We propose \textbf{WarAgent}, an LLM-powered multi-agent AI system, to simulate the participating countries, their decisions, and the consequences, in historical international conflicts, including the World War I (WWI), the World War II (WWII), and the Warring States Period (WSP) in Ancient China. By evaluating the simulation effectiveness, we examine the advancements and limitations of cutting-edge AI systems' abilities in studying complex collective human behaviors such as international conflicts under diverse settings. In these simulations, the emergent interactions among agents also offer a novel perspective for examining the triggers and conditions that lead to war. Our findin
    
[^87]: 学术期刊中AI在稿件准备中的应用的感知与检测

    Perceptions and Detection of AI Use in Manuscript Preparation for Academic Journals. (arXiv:2311.14720v2 [cs.CY] UPDATED)

    [http://arxiv.org/abs/2311.14720](http://arxiv.org/abs/2311.14720)

    该研究调查了学术界对于在稿件准备中使用AI是否有必要进行披露的观点，并研究了检测器对于学术写作中使用AI的反应。

    

    大型语言模型（LLMs）的新兴能力使得像ChatGPT和Bard这样的工具成为可能，这既带来了对AI对学术写作的影响的兴奋和担忧。为了应对对AI使用的不断增加的担忧，学术出版物的作者可能决定自愿披露他们在修改稿件时使用的AI工具，期刊和会议也可以开始要求披露和/或使用检测服务，就像许多教师在课堂环境中对学生的写作进行检测一样。鉴于这些逼近的可能性，我们调查了学者们是否认为有必要报告AI在稿件准备中的使用，并研究了检测器对学术写作中使用AI的反应。

    The emergent abilities of Large Language Models (LLMs), which power tools like ChatGPT and Bard, have produced both excitement and worry about how AI will impact academic writing. In response to rising concerns about AI use, authors of academic publications may decide to voluntarily disclose any AI tools they use to revise their manuscripts, and journals and conferences could begin mandating disclosure and/or turn to using detection services, as many teachers have done with student writing in class settings. Given these looming possibilities, we investigate whether academics view it as necessary to report AI use in manuscript preparation and how detectors react to the use of AI in academic writing.
    
[^88]: AGI系统的元提示

    Meta Prompting for AGI Systems. (arXiv:2311.11482v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2311.11482](http://arxiv.org/abs/2311.11482)

    本文全面研究了元提示技术，这是一种创新方法，重塑了大型语言模型、多模态模型和人工智能系统在问题解决和数据解释方面的应用。通过强调信息的结构和句法，元提示将复杂问题拆解为简单的子问题，提高了效率，并且能够与少样本方法进行公平的比较。同时，本文还提出了元提示用于自动生成提示的方法。

    

    本文介绍了元提示(meta prompting)的全面研究，这是一种创新技术，重新塑造了大型语言模型(LLMs)、多模态基础模型和人工智能系统在问题解决和数据解释方面的利用。基于类型理论和范畴论，元提示注重信息的结构和句法，而不是传统以内容为中心的方法。本文探讨了元提示的形式定义，并将其与少样本提示(few-shot prompting)区分开来，并强调其在各种人工智能应用中的有效性。重点关注将元提示扩展到复杂推理任务上，展示如何将复杂问题拆分成较为简单的子问题，提高令牌效率，并使问题求解的比较更加公平，尤其是与少样本示例方法相比。此外，本文还引入了元提示用于提示任务，允许LLMs以迭代的元编程形式自动生成新的提示。

    This paper presents a comprehensive study of Meta Prompting, an innovative technique reshaping the utilization of large language models (LLMs), multi-modal foundation models, and AI systems in problem-solving and data interpretation. Grounded in type theory and category theory, Meta Prompting emphasizes the structure and syntax of information over traditional content-centric methods. The paper explores the formal definitions of Meta Prompting (MP), sets it apart from Few-Shot Prompting, and underlines its effectiveness in various AI applications. A key focus is on extending Meta Prompting to complex reasoning tasks, showing how it effectively deconstructs intricate problems into simpler sub-problems, enhancing token efficiency and enabling more equitable problem-solving comparisons, especially against few-shot example methods. Additionally, the paper introduces Meta Prompting for Prompting Tasks, allowing LLMs to self-generate new prompts in an iterative, metaprogramming-like manner. T
    
[^89]: Clover: 闭环可验证代码生成

    Clover: Closed-Loop Verifiable Code Generation. (arXiv:2310.17807v1 [cs.SE])

    [http://arxiv.org/abs/2310.17807](http://arxiv.org/abs/2310.17807)

    Clover是一种闭环可验证代码生成的范式，通过在代码、docstrings和形式注释之间进行一致性检查，确保生成的代码的正确性。

    

    在软件开发中，使用大型语言模型进行代码生成是一个快速增长的趋势。然而，如果没有有效的方法来确保生成的代码的正确性，这个趋势可能会导致许多不良结果。在本文中，我们提出了一个解决这个挑战的愿景：Clover范式，即闭环可验证代码生成，它将正确性检查简化为更可访问的一致性检查问题。在Clover的核心是一个检查器，它在代码、docstrings和形式注释之间进行一致性检查。该检查器使用了形式验证工具和大型语言模型的新颖集成实现。我们提供了理论分析来支持我们的论点，即Clover在一致性检查方面应该是有效的。我们还在一个由手工设计的数据集（CloverBench）上进行了实证调查，该数据集包含了注释的Dafny程序，难度水平与教科书相当。实验结果显示

    The use of large language models for code generation is a rapidly growing trend in software development. However, without effective methods for ensuring the correctness of generated code, this trend could lead to any number of undesirable outcomes. In this paper, we lay out a vision for addressing this challenge: the Clover paradigm, short for Closed-Loop Verifiable Code Generation, which reduces correctness checking to the more accessible problem of consistency checking. At the core of Clover lies a checker that performs consistency checks among code, docstrings, and formal annotations. The checker is implemented using a novel integration of formal verification tools and large language models. We provide a theoretical analysis to support our thesis that Clover should be effective at consistency checking. We also empirically investigate its feasibility on a hand-designed dataset (CloverBench) featuring annotated Dafny programs at a textbook level of difficulty. Experimental results sho
    
[^90]: 用深度强化学习生成多样化调度策略来解决大型柔性车间调度实例

    Solving large flexible job shop scheduling instances by generating a diverse set of scheduling policies with deep reinforcement learning. (arXiv:2310.15706v1 [cs.AI])

    [http://arxiv.org/abs/2310.15706](http://arxiv.org/abs/2310.15706)

    本文提出了一种能够通过生成多样化的调度策略来解决大型柔性车间调度实例的方法，并应用深度强化学习来优化调度质量。

    

    柔性车间调度问题（FJSSP）在文献中得到了广泛研究，提出了许多启发式、精确和元启发式方法。然而，工业对实时响应突发事件的需求产生了在几秒内生成新调度的必要性。在这些方法中，只有调度规则（DRs）能够在约束下生成调度，尽管其质量可以得到改进。为了改善结果，最近的方法将FJSSP建模为马尔可夫决策过程（MDP），并应用强化学习生成一个策略，将操作分配到机器上生成最优解。然而，在大型的FJSSP实例中仍然有改进的空间，而这在实际情况中很常见。因此，本文的目标是提出一种能够稳健解决大型FJSSP实例的方法。

    The Flexible Job Shop Scheduling Problem (FJSSP) has been extensively studied in the literature, and multiple approaches have been proposed within the heuristic, exact, and metaheuristic methods. However, the industry's demand to be able to respond in real-time to disruptive events has generated the necessity to be able to generate new schedules within a few seconds. Among these methods, under this constraint, only dispatching rules (DRs) are capable of generating schedules, even though their quality can be improved. To improve the results, recent methods have been proposed for modeling the FJSSP as a Markov Decision Process (MDP) and employing reinforcement learning to create a policy that generates an optimal solution assigning operations to machines. Nonetheless, there is still room for improvement, particularly in the larger FJSSP instances which are common in real-world scenarios. Therefore, the objective of this paper is to propose a method capable of robustly solving large insta
    
[^91]: 在不断变化的多臂赌博机中实现零样本学习

    Towards Zero Shot Learning in Restless Multi-armed Bandits. (arXiv:2310.14526v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.14526](http://arxiv.org/abs/2310.14526)

    通过开发一个基于神经网络的预训练模型，我们实现了在不断变化的多臂赌博机中的零样本学习，该模型具有泛化能力，并且能够在特定实例上进行高效微调，同时适用于多行为设置和离散或连续状态空间。

    

    近来，通过多智能体强化学习的视角研究了一类资源分配问题——不断变化的多臂赌博机（RMABs），该问题在医疗保健、在线广告和反盗猎等领域具有广泛应用。先前的RMAB研究存在一些限制，例如没有充分解决连续状态问题，并且在多个真实世界应用中，当赌博机的入选和退出不断发生时，需要从头开始重新训练，这是一个常见的挑战。为了解决这些限制，我们开发了一个基于神经网络的预训练模型（PreFeRMAB），该模型具有对之前未见过的广泛RMAB问题的零样本能力，并且可以比从头训练更加高效地对特定实例进行微调。此外，我们的模型还适用于一般的多行为设置和离散或连续状态空间。为了实现快速泛化，我们学习了一种新颖的单一策略网络模型，该模型利用特征信息并采用了一种新的训练方式。

    Restless multi-arm bandits (RMABs), a class of resource allocation problems with broad application in areas such as healthcare, online advertising, and anti-poaching, have recently been studied from a multi-agent reinforcement learning perspective. Prior RMAB research suffers from several limitations, e.g., it fails to adequately address continuous states, and requires retraining from scratch when arms opt-in and opt-out over time, a common challenge in many real world applications. We address these limitations by developing a neural network-based pre-trained model (PreFeRMAB) that has general zero-shot ability on a wide range of previously unseen RMABs, and which can be fine-tuned on specific instances in a more sample-efficient way than retraining from scratch. Our model also accommodates general multi-action settings and discrete or continuous state spaces. To enable fast generalization, we learn a novel single policy network model that utilizes feature information and employs a tra
    
[^92]: 学习可解释的规则以实现可扩展的数据表示和分类

    Learning Interpretable Rules for Scalable Data Representation and Classification. (arXiv:2310.14336v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.14336](http://arxiv.org/abs/2310.14336)

    这项研究提出了一种名为RRL的新型分类器，通过自动学习可解释的非模糊规则，实现了数据表示和分类的良好可扩展性和解释性。

    

    基于规则的模型（如决策树）在需要高模型解释性的场景中被广泛使用，因为它们具有透明的内部结构和良好的模型表达能力。然而，由于离散的参数和结构，基于规则的模型在优化方面很难应对大规模的数据集。集成方法和模糊/软规则通常用于提高性能，但会牺牲模型的解释性。为了获得良好的可扩展性和可解释性，我们提出了一种新的分类器，称为基于规则的表示学习器（RRL），它可以自动学习用于数据表示和分类的可解释的非模糊规则。为了有效训练不可微分的RRL，我们将其映射到连续空间，并提出一种称为梯度嵌入的新的训练方法，可以使用梯度下降直接优化离散模型。此外，还设计了一种新颖的逻辑激活函数，以增加RRL的可扩展性，并使其能够进行判别。

    Rule-based models, e.g., decision trees, are widely used in scenarios demanding high model interpretability for their transparent inner structures and good model expressivity. However, rule-based models are hard to optimize, especially on large data sets, due to their discrete parameters and structures. Ensemble methods and fuzzy/soft rules are commonly used to improve performance, but they sacrifice the model interpretability. To obtain both good scalability and interpretability, we propose a new classifier, named Rule-based Representation Learner (RRL), that automatically learns interpretable non-fuzzy rules for data representation and classification. To train the non-differentiable RRL effectively, we project it to a continuous space and propose a novel training method, called Gradient Grafting, that can directly optimize the discrete model using gradient descent. A novel design of logical activation functions is also devised to increase the scalability of RRL and enable it to discr
    
[^93]: 一种用于大型语言模型的一次敏感度感知混合稀疏化剪枝方法

    One-Shot Sensitivity-Aware Mixed Sparsity Pruning for Large Language Models. (arXiv:2310.09499v1 [cs.CL])

    [http://arxiv.org/abs/2310.09499](http://arxiv.org/abs/2310.09499)

    我们提出了一种基于敏感度感知混合稀疏化剪枝的方法，可以在不重新训练的情况下将大型语言模型剪枝至至少50％的稀疏性，同时保持稀疏性水平和减少剪枝引起的误差。此外，该方法还与量化兼容，可以进一步压缩语言模型。

    

    从生成预训练变压器（GPT）系列中的各种大型语言模型（LLMs）在各种文本生成任务中取得了卓越的性能。然而，由于高推理延迟，巨大的模型大小阻碍了它们在实际应用中的实用性。因此，通过量化、剪枝和其他方法提高LLMs的效率成为LLM研究的一个关键问题。在这项工作中，我们提出了一种基于Hessian敏感度感知混合稀疏化剪枝的方法，可以将LLMs剪枝至至少50%的稀疏性，而无需重新训练。它根据敏感度自适应地分配稀疏性，使我们能够降低剪枝引起的误差，同时保持整体稀疏性水平。当稀疏度非常高时，所提出的方法的优势更加明显。此外，我们的方法与量化兼容，可以进一步压缩LLMs。

    Various Large Language Models(LLMs) from the Generative Pretrained Transformer~(GPT) family have achieved outstanding performances in a wide range of text generation tasks. However, the enormous model sizes have hindered their practical use in real-world applications due to high inference latency. Therefore, improving the efficiencies of LLMs through quantization, pruning, and other means has been a key issue in LLM studies. In this work, we propose a method based on Hessian sensitivity-aware mixed sparsity pruning to prune LLMs to at least 50\% sparsity without the need of any retraining. It allocates sparsity adaptively based on sensitivity, allowing us to reduce pruning-induced error while maintaining the overall sparsity level. The advantages of the proposed method exhibit even more when the sparsity is extremely high. Furthermore, our method is compatible with quantization, enabling further compression of LLMs.
    
[^94]: 从旋律中利用字符级语言模型生成音节级歌词

    Syllable-level lyrics generation from melody exploiting character-level language model. (arXiv:2310.00863v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.00863](http://arxiv.org/abs/2310.00863)

    该论文提出了一种利用字符级语言模型从旋律中生成音节级歌词的方法，并通过融合语言模型知识和生成器网络进行优化。通过探索ChatGPT的评估方法，以及人工评估，证明了该方法提高了生成歌词的连贯性和正确性。

    

    生成与伴奏旋律紧密相关的歌词涉及建立音乐音符与歌词音节之间的映射。这个过程需要对音节级、词级和句级语义意义上的音乐约束和语义模式有深入的理解。然而，公开的音节级预训练语言模型并不存在。为了解决这些具有挑战性的问题，我们提出利用以字符级语言模型进行音节级歌词生成。特别地，我们的方法将语言模型的语言知识融入音节级Transformer生成器网络的束搜索过程中。此外，通过探索基于ChatGPT的生成歌词评估方法，以及人工主观评估，我们证明了我们的方法增强了生成歌词的连贯性和正确性，消除了训练昂贵的新模型的需求。

    The generation of lyrics tightly connected to accompanying melodies involves establishing a mapping between musical notes and syllables of lyrics. This process requires a deep understanding of music constraints and semantic patterns at syllable-level, word-level, and sentence-level semantic meanings. However, pre-trained language models specifically designed at the syllable level are publicly unavailable. To solve these challenging issues, we propose to exploit fine-tuning character-level language models for syllable-level lyrics generation from symbolic melody. In particular, our method endeavors to incorporate linguistic knowledge of the language model into the beam search process of a syllable-level Transformer generator network. Additionally, by exploring ChatGPT-based evaluation for generated lyrics, along with human subjective evaluation, we demonstrate that our approach enhances the coherence and correctness of the generated lyrics, eliminating the need to train expensive new la
    
[^95]: 神经网络潜在表示中的对抗性机器学习

    Adversarial Machine Learning in Latent Representations of Neural Networks. (arXiv:2309.17401v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2309.17401](http://arxiv.org/abs/2309.17401)

    这项研究通过分析分布式深度神经网络对抗性行为的韧性填补了现有研究空白，并发现潜在特征在相同信息失真水平下比输入表示更加韧性，并且对抗性韧性由特征维度和神经网络的泛化能力共同决定。

    

    分布式深度神经网络已被证明可以减轻移动设备的计算负担，并降低边缘计算场景中的端到端推理延迟。尽管已经对分布式深度神经网络进行了研究，但据我们所知，分布式深度神经网络对于对抗性行为的韧性仍然是一个开放问题。在本文中，我们通过严格分析分布式深度神经网络对抗性行为的韧性来填补现有的研究空白。我们将这个问题置于信息论的背景下，并引入了两个新的衡量指标来衡量失真和韧性。我们的理论发现表明：（i）在假设具有相同信息失真水平的情况下，潜在特征始终比输入表示更加韧性；（ii）对抗性韧性同时由特征维度和深度神经网络的泛化能力决定。为了验证我们的理论发现，我们进行了广泛的实验分析，考虑了6种不同的深度神经网络架构。

    Distributed deep neural networks (DNNs) have been shown to reduce the computational burden of mobile devices and decrease the end-to-end inference latency in edge computing scenarios. While distributed DNNs have been studied, to the best of our knowledge the resilience of distributed DNNs to adversarial action still remains an open problem. In this paper, we fill the existing research gap by rigorously analyzing the robustness of distributed DNNs against adversarial action. We cast this problem in the context of information theory and introduce two new measurements for distortion and robustness. Our theoretical findings indicate that (i) assuming the same level of information distortion, latent features are always more robust than input representations; (ii) the adversarial robustness is jointly determined by the feature dimension and the generalization capability of the DNN. To test our theoretical findings, we perform extensive experimental analysis by considering 6 different DNN arc
    
[^96]: 大型语言模型下的创造力支持: 一项涉及新兴作家的实证研究

    Creativity Support in the Age of Large Language Models: An Empirical Study Involving Emerging Writers. (arXiv:2309.12570v1 [cs.HC])

    [http://arxiv.org/abs/2309.12570](http://arxiv.org/abs/2309.12570)

    本文通过实证研究探讨了大型语言模型（LLM）在协助专业作家方面的效用，并发现作家们更倾向于在翻译和审查阶段中寻求LLM的帮助。

    

    大型语言模型（LLM）的发展使得其能够遵循指令并参与对话互动，引发了在各种支持工具中利用它们的兴趣增加。我们通过一项实证用户研究（n=30）探讨了现代LLM在协助专业作家方面的效用。我们的合作写作界面设计基于将写作视为一个目标导向的思维过程的认知过程模型，涵盖了非线性的认知活动：规划、翻译和审查。参与者被要求提交一份后完成调查，以提供关于LLM作为写作合作者潜力和问题的反馈。通过分析作家-LLM互动,我们发现作家在三种类型的认知活动中都寻求LLM的帮助，但他们发现LLM在翻译和审查方面更有帮助。通过分析互动和调查结果，我们的发现强调了未来研究的方向。

    The development of large language models (LLMs) capable of following instructions and engaging in conversational interactions sparked increased interest in their utilization across various support tools. We investigate the utility of modern LLMs in assisting professional writers via an empirical user study (n=30). The design of our collaborative writing interface is grounded in the cognitive process model of writing that views writing as a goal-oriented thinking process encompassing non-linear cognitive activities: planning, translating, and reviewing. Participants are asked to submit a post-completion survey to provide feedback on the potential and pitfalls of LLMs as writing collaborators. Upon analyzing the writer-LLM interactions, we find that while writers seek LLM's help across all three types of cognitive activities, they find LLMs more helpful in translation and reviewing. Our findings from analyzing both the interactions and the survey responses highlight future research direc
    
[^97]: MAPLE: 基于大型语言模型嵌入的移动应用预测

    MAPLE: Mobile App Prediction Leveraging Large Language model Embeddings. (arXiv:2309.08648v1 [cs.CL])

    [http://arxiv.org/abs/2309.08648](http://arxiv.org/abs/2309.08648)

    MAPLE是一个利用大型语言模型嵌入进行移动应用预测的模型，通过严格测试验证了其在解密复杂模式和理解用户环境方面的能力，并强调了语言模型在不同领域中的广泛适用性。

    

    尽管移动应用的发展迅速，但由于复杂的用户行为和不断演变的环境，预测应用的使用仍然是一个严峻的挑战。为了解决这些问题，本文介绍了Mobile App Prediction Leveraging Large Language Model Embeddings (MAPLE)模型。这种创新的方法利用大型语言模型(LLM)来准确预测应用的使用情况。通过对两个公开数据集进行严格测试，MAPLE的能力在解密复杂模式和理解用户环境方面得到了验证。这些强大的结果证实了MAPLE在不同场景中的多功能性和弹性。尽管其主要设计面向应用预测，但结果也强调了LLM在不同领域中的广泛适用性。通过这项研究，我们强调了LLM在应用使用预测中的潜力，并建议在建模各种领域中的人类行为方面，它们具有变革能力。

    Despite the rapid advancement of mobile applications, predicting app usage remains a formidable challenge due to intricate user behaviours and ever-evolving contexts. To address these issues, this paper introduces the Mobile App Prediction Leveraging Large Language Model Embeddings (MAPLE) model. This innovative approach utilizes Large Language Models (LLMs) to predict app usage accurately. Rigorous testing on two public datasets highlights MAPLE's capability to decipher intricate patterns and comprehend user contexts. These robust results confirm MAPLE's versatility and resilience across various scenarios. While its primary design caters to app prediction, the outcomes also emphasize the broader applicability of LLMs in different domains. Through this research, we emphasize the potential of LLMs in app usage prediction and suggest their transformative capacity in modelling human behaviours across diverse fields.
    
[^98]: 语言模型在与知识库进行连接时的数据分布瓶颈

    Data Distribution Bottlenecks in Grounding Language Models to Knowledge Bases. (arXiv:2309.08345v1 [cs.CL])

    [http://arxiv.org/abs/2309.08345](http://arxiv.org/abs/2309.08345)

    本文通过实验调查揭示了语言模型在与知识库进行连接时的数据分布瓶颈，包括推广到未见域、适应语言变体和在不同数据集之间的可转移性等方面。即使采用数据增强技术，先进的语言模型在多个方面表现出较差的性能。

    

    语言模型（LM）已经展示了在理解和生成自然语言和形式语言方面的卓越能力。尽管取得了这些进展，但它们与大规模知识库等现实环境的整合仍然是一个欠发展的领域，影响了语义解析等应用，并且容易出现“产生虚假信息”的问题。本文通过实验调查揭示了LM在处理知识库问答（KBQA）任务时所遇到的健壮性挑战。研究覆盖了训练和推断之间数据分布不一致的场景，例如推广到未见域、适应各种语言变体和在不同数据集之间的可转移性。我们的全面实验揭示了即使在采用我们提出的数据增强技术的情况下，先进的小型和大型语言模型在多个方面表现出较差的性能。

    Language models (LMs) have already demonstrated remarkable abilities in understanding and generating both natural and formal language. Despite these advances, their integration with real-world environments such as large-scale knowledge bases (KBs) remains an underdeveloped area, affecting applications such as semantic parsing and indulging in "hallucinated" information. This paper is an experimental investigation aimed at uncovering the robustness challenges that LMs encounter when tasked with knowledge base question answering (KBQA). The investigation covers scenarios with inconsistent data distribution between training and inference, such as generalization to unseen domains, adaptation to various language variations, and transferability across different datasets. Our comprehensive experiments reveal that even when employed with our proposed data augmentation techniques, advanced small and large language models exhibit poor performance in various dimensions. While the LM is a promisin
    
[^99]: 双重关系对齐用于组合图像检索

    Dual Relation Alignment for Composed Image Retrieval. (arXiv:2309.02169v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2309.02169](http://arxiv.org/abs/2309.02169)

    本研究提出了双重关系对齐的方法，用于组合图像检索任务。通过利用显性和隐性关系，可以更好地学习网络并提升检索性能。

    

    组合图像检索是一项通过使用参考图像和补充文本作为查询，来搜索目标图像的任务。随着跨模态建模的进展，这一任务取得了显著的进展。与仅存在一种对齐关系的一般图像-文本检索问题不同，我们认为在组合图像检索中存在着两种类型的关系。显性关系涉及参考图像 & 补充文本-目标图像，这是现有方法常用的关系。除了这种直观关系之外，我们在实践中观察到另一种隐含但关键的关系，即参考图像 & 目标图像-补充文本。因为我们发现，通过研究目标图像和参考图像之间的关系，可以推断出补充文本。可惜的是，现有方法主要关注利用显性关系来学习网络，而忽视了隐性关系。

    Composed image retrieval, a task involving the search for a target image using a reference image and a complementary text as the query, has witnessed significant advancements owing to the progress made in cross-modal modeling. Unlike the general image-text retrieval problem with only one alignment relation, i.e., image-text, we argue for the existence of two types of relations in composed image retrieval. The explicit relation pertains to the reference image & complementary text-target image, which is commonly exploited by existing methods. Besides this intuitive relation, the observations during our practice have uncovered another implicit yet crucial relation, i.e., reference image & target image-complementary text, since we found that the complementary text can be inferred by studying the relation between the target image and the reference image. Regrettably, existing methods largely focus on leveraging the explicit relation to learn their networks, while overlooking the implicit re
    
[^100]: 关于相对于单子句传播不可简化的CNF公式

    On CNF formulas irredundant with respect to unit clause propagation. (arXiv:2309.01750v2 [math.CO] UPDATED)

    [http://arxiv.org/abs/2309.01750](http://arxiv.org/abs/2309.01750)

    对于单子句传播而言，在CNF公式中不可简化的公式，其大小与最小可等价的公式大小的比值最大为n^2，其中n是变量数量。一般上界不会小于n/ln n倍。

    

    如果两个CNF公式在单子句传播（UCP）方面的行为相同，则它们被称为ucp等价。如果移除任意一个子句会导致一个与原始公式在ucp方面不等价的公式，则称该公式为ucp不可简化。根据已知结果，ucp不可简化公式的大小与最小ucp等价公式的大小的比值最大为n^2，其中n是变量的数量。我们展示了对称确定Horn函数的一个ucp不可简化公式的例子，其大小比最小的ucp等价公式大n/ln n倍，因此，上述比值的一般上界不能小于这个值。

    Two CNF formulas are called ucp-equivalent, if they behave in the same way with respect to the unit clause propagation (UCP). A formula is called ucp-irredundant, if removing any clause leads to a formula which is not ucp-equivalent to the original one. As a consequence of known results, the ratio of the size of a ucp-irredundant formula and the size of a smallest ucp-equivalent formula is at most $n^2$, where $n$ is the number of the variables. We demonstrate an example of a ucp-irredundant formula for a symmetric definite Horn function which is larger than a smallest ucp-equivalent formula by a factor $\Omega(n/\ln n)$ and, hence, a general upper bound on the above ratio cannot be smaller than this.
    
[^101]: 推荐AI代理：将大型语言模型整合到交互式推荐中

    Recommender AI Agent: Integrating Large Language Models for Interactive Recommendations. (arXiv:2308.16505v1 [cs.IR])

    [http://arxiv.org/abs/2308.16505](http://arxiv.org/abs/2308.16505)

    本论文的创新点是将推荐模型和大型语言模型（LLMs）融合，创建了一个多功能交互式推荐系统，解决了推荐模型在提供解释和参与对话任务方面的困难。

    

    推荐模型通过利用广泛的用户行为数据来提供领域特定的物品推荐，展现出轻量级领域专家的能力。然而，它们在提供解释和参与对话等多样化任务方面存在困难。另一方面，大型语言模型（LLMs）代表了人工通用智能的重要进展，在指令理解、常识推理和人类交互方面表现出了显著能力。然而，LLMs缺乏领域特定物品目录和行为模式的知识，特别是在与一般世界知识不同的领域，如在线电子商务。为每个领域微调LLMs既不经济又不高效。在本文中，我们将推荐模型和LLMs之间的差距，结合各自的优势，创建了一个多功能交互式推荐系统。我们引入了一个高效的框架称为RecAgent，该框架使用LLMs

    Recommender models excel at providing domain-specific item recommendations by leveraging extensive user behavior data. Despite their ability to act as lightweight domain experts, they struggle to perform versatile tasks such as providing explanations and engaging in conversations. On the other hand, large language models (LLMs) represent a significant step towards artificial general intelligence, showcasing remarkable capabilities in instruction comprehension, commonsense reasoning, and human interaction. However, LLMs lack the knowledge of domain-specific item catalogs and behavioral patterns, particularly in areas that diverge from general world knowledge, such as online e-commerce. Finetuning LLMs for each domain is neither economic nor efficient.  In this paper, we bridge the gap between recommender models and LLMs, combining their respective strengths to create a versatile and interactive recommender system. We introduce an efficient framework called RecAgent, which employs LLMs a
    
[^102]: 通过卫星地图补充车载传感器：高精度地图构建的新视角

    Complementing Onboard Sensors with Satellite Map: A New Perspective for HD Map Construction. (arXiv:2308.15427v1 [cs.CV])

    [http://arxiv.org/abs/2308.15427](http://arxiv.org/abs/2308.15427)

    本研究通过补充卫星地图，增强了车载传感器构建高精度地图的方法，利用卫星地图的广阔覆盖能力。我们释放了卫星地图瓦片作为nuScenes数据集的补充，同时提出了一个分层融合模块来更好地融合车载传感器与卫星地图的信息。

    

    高精度（HD）地图对自动驾驶系统至关重要。最近的方法尝试基于车载传感器获取的信息实时构建HD地图。然而，这些方法的性能受到车辆周围环境的显著影响，这是由于车载传感器的固有限制，如对远程探测的能力不足。在本研究中，我们证明了通过补充卫星地图可以增强HD地图构建方法的性能，利用卫星地图的广泛覆盖能力。为了进一步的研究，我们发布了卫星地图瓦片作为nuScenes数据集的补充数据集。与此同时，我们提出了一个分层融合模块，使卫星地图信息与现有方法更好地融合。具体来说，我们设计了基于分割和距离的注意力掩码，应用交叉注意力机制来融合车载传感器与卫星地图的信息。

    High-Definition (HD) maps play a crucial role in autonomous driving systems. Recent methods have attempted to construct HD maps in real-time based on information obtained from vehicle onboard sensors. However, the performance of these methods is significantly susceptible to the environment surrounding the vehicle due to the inherent limitation of onboard sensors, such as weak capacity for long-range detection. In this study, we demonstrate that supplementing onboard sensors with satellite maps can enhance the performance of HD map construction methods, leveraging the broad coverage capability of satellite maps. For the purpose of further research, we release the satellite map tiles as a complementary dataset of nuScenes dataset. Meanwhile, we propose a hierarchical fusion module that enables better fusion of satellite maps information with existing methods. Specifically, we design an attention mask based on segmentation and distance, applying the cross-attention mechanism to fuse onboa
    
[^103]: 有效的语言模型基准测试

    Efficient Benchmarking (of Language Models). (arXiv:2308.11696v1 [cs.CL])

    [http://arxiv.org/abs/2308.11696](http://arxiv.org/abs/2308.11696)

    本研究提出了一种名为"Efficient Benchmarking"的问题，旨在智能地减少语言模型评估的计算成本而不降低可靠性，并使用一种名为Decision Impact on Reliability（DIoR）的新度量来评估决策的可靠性。通过HELM基准测试的案例研究，发现只需删除一个低排名模型即可改变领先者，并仅需少量示例即可得到正确的基准测试排名。

    

    语言模型的多功能性增加导致了一类全面评估广泛能力的基准测试的出现。这些基准测试与大规模计算成本相关，每个模型需要数千个GPU小时。然而，关于评估效率方面的问题在文献中讨论较少。本文提出了一种名为"Efficient Benchmarking"的问题，即在不损害可靠性的情况下智能地减少语言模型评估的计算成本。通过使用HELM基准测试作为示例，我们研究了不同基准测试设计选择如何影响计算-可靠性权衡。我们提出使用一种名为Decision Impact on Reliability（DIoR）的新度量来评估这些决策的可靠性。例如，我们发现仅通过从基准测试中删除一个低排名模型，当前在HELM上的领先者可能会改变，并且观察到只需一小部分示例即可获得正确的基准测试排名。

    The increasing versatility of language models LMs has given rise to a new class of benchmarks that comprehensively assess a broad range of capabilities. Such benchmarks are associated with massive computational costs reaching thousands of GPU hours per model. However the efficiency aspect of these evaluation efforts had raised little discussion in the literature. In this work we present the problem of Efficient Benchmarking namely intelligently reducing the computation costs of LM evaluation without compromising reliability. Using the HELM benchmark as a test case we investigate how different benchmark design choices affect the computation-reliability tradeoff. We propose to evaluate the reliability of such decisions by using a new measure Decision Impact on Reliability DIoR for short. We find for example that the current leader on HELM may change by merely removing a low-ranked model from the benchmark and observe that a handful of examples suffice to obtain the correct benchmark rank
    
[^104]: SSLRec: 一个自监督学习的推荐系统库

    SSLRec: A Self-Supervised Learning Library for Recommendation. (arXiv:2308.05697v1 [cs.IR])

    [http://arxiv.org/abs/2308.05697](http://arxiv.org/abs/2308.05697)

    SSLRec是一个自监督学习的推荐系统库，为评估各种SSL增强推荐系统提供了标准化、灵活和综合的框架。

    

    自监督学习（SSL）作为解决推荐系统中稀疏和噪声数据挑战的解决方案，在最近几年引起了广泛关注。尽管设计了越来越多的SSL算法来在不同领域中提供最先进的推荐性能（例如图协同过滤、顺序推荐、社交推荐、知识图增强推荐），但目前仍缺乏一个统一框架来整合不同领域的推荐算法。这样的框架可以作为自监督推荐算法的基石，统一现有方法的验证，并推动新方法的设计。为了解决这个问题，我们介绍了SSLRec，一个新颖的基准平台，为评估各种SSL增强推荐系统提供了标准化、灵活和综合的框架。SSLRec库具有模块化架构，可以方便用户评估最先进的推荐器。

    Self-supervised learning (SSL) has gained significant interest in recent years as a solution to address the challenges posed by sparse and noisy data in recommender systems. Despite the growing number of SSL algorithms designed to provide state-of-the-art performance in various recommendation scenarios (e.g., graph collaborative filtering, sequential recommendation, social recommendation, KG-enhanced recommendation), there is still a lack of unified frameworks that integrate recommendation algorithms across different domains. Such a framework could serve as the cornerstone for self-supervised recommendation algorithms, unifying the validation of existing methods and driving the design of new ones. To address this gap, we introduce SSLRec, a novel benchmark platform that provides a standardized, flexible, and comprehensive framework for evaluating various SSL-enhanced recommenders. The SSLRec library features a modular architecture that allows users to easily evaluate state-of-the-art m
    
[^105]: 一个开源的知识图谱生态系统用于生命科学

    An Open-Source Knowledge Graph Ecosystem for the Life Sciences. (arXiv:2307.05727v1 [cs.AI])

    [http://arxiv.org/abs/2307.05727](http://arxiv.org/abs/2307.05727)

    PheKnowLator是一个开源的知识图谱生态系统，用于自动化构建可定制的FAIR本体化基础的知识图谱，以解决生命科学中的整合挑战。

    

    转化研究需要多个生物组织尺度上的数据。测序和多组学技术的进步增加了这些数据的可用性，但研究人员面临着重大的整合挑战。知识图谱（KGs）用于建模复杂现象，已经存在自动构建它们的方法。然而，解决复杂的生物医学整合问题需要在知识建模方式上灵活性。此外，现有的KG构建方法在提供强大工具的同时，也会限制在知识表示模型中固定或有限的选择。PheKnowLator（Phenotype Knowledge Translator）是一个语义生态系统，用于自动化具有完全可定制的知识表示的FAIR（可找到，可访问，可互操作，可重复使用）本体化基础的知识图谱的构建。该生态系统包括KG构建资源（例如，数据准备API），分析工具（例如，SPARQL端点和抽象算法），还有

    Translational research requires data at multiple scales of biological organization. Advancements in sequencing and multi-omics technologies have increased the availability of these data but researchers face significant integration challenges. Knowledge graphs (KGs) are used to model complex phenomena, and methods exist to automatically construct them. However, tackling complex biomedical integration problems requires flexibility in the way knowledge is modeled. Moreover, existing KG construction methods provide robust tooling at the cost of fixed or limited choices among knowledge representation models. PheKnowLator (Phenotype Knowledge Translator) is a semantic ecosystem for automating the FAIR (Findable, Accessible, Interoperable, and Reusable) construction of ontologically grounded KGs with fully customizable knowledge representation. The ecosystem includes KG construction resources (e.g., data preparation APIs), analysis tools (e.g., SPARQL endpoints and abstraction algorithms), an
    
[^106]: 为事实感知语言建模增强大型语言模型的知识图谱

    Give Us the Facts: Enhancing Large Language Models with Knowledge Graphs for Fact-aware Language Modeling. (arXiv:2306.11489v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.11489](http://arxiv.org/abs/2306.11489)

    这篇论文研究了如何通过知识图谱增强大型语言模型，提高其生成内容的准确性和对用户查询的回复能力。

    

    最近，ChatGPT作为一个代表性的大型语言模型（LLM），因其强大的新兴能力而受到了相当大的关注。一些研究人员认为，LLMs有可能取代知识图谱（KGs）这样的结构化知识库，成为参数化知识库。然而，虽然LLMs擅长基于大语料库学习概率语言模式，并与人类进行对话，但它们与之前较小的预训练语言模型（PLMs）一样，在生成基于知识的内容时仍然难以回忆事实。为了克服这些局限性，研究人员提出了通过知识图谱增强数据驱动的PLMs，将明确的事实知识融入PLMs，从而提高其生成需要事实知识的文本的性能，并为用户查询提供更多见解的回复。本文回顾了有关使用KG增强PLMs的研究，详细介绍了现有的知识图谱增强预训练模型PLM的方法。

    Recently, ChatGPT, a representative large language model (LLM), has gained considerable attention due to its powerful emergent abilities. Some researchers suggest that LLMs could potentially replace structured knowledge bases like knowledge graphs (KGs) and function as parameterized knowledge bases. However, while LLMs are proficient at learning probabilistic language patterns based on large corpus and engaging in conversations with humans, they, like previous smaller pre-trained language models (PLMs), still have difficulty in recalling facts while generating knowledge-grounded contents. To overcome these limitations, researchers have proposed enhancing data-driven PLMs with knowledge-based KGs to incorporate explicit factual knowledge into PLMs, thus improving their performance to generate texts requiring factual knowledge and providing more informed responses to user queries. This paper reviews the studies on enhancing PLMs with KGs, detailing existing knowledge graph enhanced pre-t
    
[^107]: ChatGPT和其他类似系统是AI的现代勒纳恩九头蛇吗？

    Are ChatGPT and Other Similar Systems the Modern Lernaean Hydras of AI?. (arXiv:2306.09267v3 [cs.CY] UPDATED)

    [http://arxiv.org/abs/2306.09267](http://arxiv.org/abs/2306.09267)

    生成式人工智能系统的崛起引发了版权和创新保护的问题。建议对开源代码许可证进行更改，限制AI系统对代码的访问和使用，并探讨与AI和版权之间的关系引发的问题。

    

    生成式人工智能系统的崛起引发了前所未有的社交参与。AI代码生成系统通过访问过去几十年开发人员创建的大量开源代码来提供回答或响应问题或请求。然而，它们被指控窃取存储在虚拟库中的开源代码。本文着重讨论此类问题，并探讨是否有解决方案来保护创新并避免多年的诉讼。对AI和版权之间的关系引发的一系列问题也进行了讨论。展望未来，我们提出以下建议：(a)对开发人员创建的开源代码的许可证进行即时更改，限制对任何开源代码的访问和/或使用仅限于人类；(b)建议对麻省理工学院（MIT）许可证进行修订，要求AI系统从开源代码部分获取适当的许可证。

    The rise of Generative Artificial Intelligence systems ("AI systems") has created unprecedented social engagement. AI code generation systems provide responses (output) to questions or requests by accessing the vast library of open-source code created by developers over the past few decades. However, they do so by allegedly stealing the open-source code stored in virtual libraries, known as repositories. This Article focuses on how this happens and whether there is a solution that protects innovation and avoids years of litigation. We also touch upon the array of issues raised by the relationship between AI and copyright. Looking ahead, we propose the following: (a) immediate changes to the licenses for open-source code created by developers that will limit access and/or use of any open-source code to humans only; (b) we suggest revisions to the Massachusetts Institute of Technology ("MIT") license so that AI systems are required to procure appropriate licenses from open-source code de
    
[^108]: 简单且可控的音乐生成

    Simple and Controllable Music Generation. (arXiv:2306.05284v1 [cs.SD])

    [http://arxiv.org/abs/2306.05284](http://arxiv.org/abs/2306.05284)

    本文提出了 MusicGen，一个单一的语言模型，可以在条件描述或旋律特征控制下生成高质量的样本，并且在标准的文本到音乐基准上的实证研究中，该方法优于其他基线模型。

    

    本研究解决了条件音乐生成的问题。我们介绍了MusicGen，它是一个单一的语言模型，可以操作多个压缩离散音乐表示流，即令牌。与以往的工作不同，MusicGen由一个单一阶段的Transformer LM和高效的令牌交错模式组成，消除了级联多个模型的需要，例如分层或上采样。采用这种方法，我们展示了MusicGen如何在条件描述或旋律特征的控制下生成高质量的样本。我们进行了广泛的实证评估，考虑了自动和人为研究，展示了所提出的方法优于标准文本到音乐基准上评估的基线。通过消融研究，我们阐明了MusicGen所包含组件的重要性。音乐样本、代码和模型可以在https://github.com/fac找到。

    We tackle the task of conditional music generation. We introduce MusicGen, a single Language Model (LM) that operates over several streams of compressed discrete music representation, i.e., tokens. Unlike prior work, MusicGen is comprised of a single-stage transformer LM together with efficient token interleaving patterns, which eliminates the need for cascading several models, e.g., hierarchically or upsampling. Following this approach, we demonstrate how MusicGen can generate high-quality samples, while being conditioned on textual description or melodic features, allowing better controls over the generated output. We conduct extensive empirical evaluation, considering both automatic and human studies, showing the proposed approach is superior to the evaluated baselines on a standard text-to-music benchmark. Through ablation studies, we shed light over the importance of each of the components comprising MusicGen. Music samples, code, and models are available at https://github.com/fac
    
[^109]: 质量多样性强化学习中的近端策略梯度树枝方法

    Proximal Policy Gradient Arborescence for Quality Diversity Reinforcement Learning. (arXiv:2305.13795v1 [cs.LG])

    [http://arxiv.org/abs/2305.13795](http://arxiv.org/abs/2305.13795)

    本论文提出了一种将近端策略优化(PPO)方法与质量多样性(QD)相结合的新型QD-RL方法，用于在高吞吐量、大规模并行化机器人模拟器环境下训练能够在未知动态环境中表现出色的机器人学习智能体。

    

    培训通常能够在未知动态环境中表现良好的机器人学习智能体是一个长期目标。质量多样性强化学习(QD-RL)是一类新兴的强化学习算法，它将质量多样性(QD)和RL的见解相结合，产生一系列关于行为嵌入的高性能和行为多样性的策略集。然而，现有的QD-RL方法迄今为止利用了样本有效的离策略RL算法。然而，最近高吞吐量、大规模并行化的机器人模拟器的进步已经打开了能够利用这种并行性的算法的大门，而将现有的离策略QD-RL方法扩展到这些新的数据丰富的环境还不清楚。在这项工作中，我们首次采用了能够利用大规模并行性的近端策略优化(PPO)等策略方法与QD相结合，提出了一种新的QD-RL方法。

    Training generally capable agents that perform well in unseen dynamic environments is a long-term goal of robot learning. Quality Diversity Reinforcement Learning (QD-RL) is an emerging class of reinforcement learning (RL) algorithms that blend insights from Quality Diversity (QD) and RL to produce a collection of high performing and behaviorally diverse policies with respect to a behavioral embedding. Existing QD-RL approaches have thus far taken advantage of sample-efficient off-policy RL algorithms. However, recent advances in high-throughput, massively parallelized robotic simulators have opened the door for algorithms that can take advantage of such parallelism, and it is unclear how to scale existing off-policy QD-RL methods to these new data-rich regimes. In this work, we take the first steps to combine on-policy RL methods, specifically Proximal Policy Optimization (PPO), that can leverage massive parallelism, with QD, and propose a new QD-RL method with these high-throughput s
    
[^110]: 基于fMRI的语言编码模型的规模定律研究

    Scaling laws for language encoding models in fMRI. (arXiv:2305.11863v1 [cs.CL])

    [http://arxiv.org/abs/2305.11863](http://arxiv.org/abs/2305.11863)

    本文揭示了基于fMRI的语言编码模型预测性能与模型大小呈对数线性关系，在125M到30B参数模型进行规模扩展时，表现提高了约15％。

    

    基于变压器的单向语言模型的表示已被证明能够有效地预测大脑对自然语言的反应。然而，大多数比较语言模型与大脑的研究都使用了类似GPT-2大小的语言模型。本研究测试了是否更大的开源模型（如OPT和LLaMA系列）更适用于预测使用fMRI记录的大脑反应。结果显示，在从125M到30B参数模型进行规模扩展时，大脑预测性能与模型大小呈对数线性关系，跨3个受试者的保留测试集相关性表现提高了约15％。当扩展fMRI训练集的大小时，我们也观察到了类似的对数线性行为。我们还对使用HuBERT，WavLM和Whisper的声学编码模型进行了规模定律研究，发现模型大小的增加带来了类似的改进。我们还使用噪音天花板分析了这些大规模且高性能的编码模型。

    Representations from transformer-based unidirectional language models are known to be effective at predicting brain responses to natural language. However, most studies comparing language models to brains have used GPT-2 or similarly sized language models. Here we tested whether larger open-source models such as those from the OPT and LLaMA families are better at predicting brain responses recorded using fMRI. Mirroring scaling results from other contexts, we found that brain prediction performance scales log-linearly with model size from 125M to 30B parameter models, with ~15% increased encoding performance as measured by correlation with a held-out test set across 3 subjects. Similar log-linear behavior was observed when scaling the size of the fMRI training set. We also characterized scaling for acoustic encoding models that use HuBERT, WavLM, and Whisper, and we found comparable improvements with model size. A noise ceiling analysis of these large, high-performance encoding models 
    
[^111]: 融合归因重要性以提高忠实度评估的方法

    Incorporating Attribution Importance for Improving Faithfulness Metrics. (arXiv:2305.10496v1 [cs.CL])

    [http://arxiv.org/abs/2305.10496](http://arxiv.org/abs/2305.10496)

    本研究提出了一种软删除标准来评估归因方法的忠实度，该方法随机遮盖标记的部分向量表示，这种方法比现有的硬删除标准更准确。

    

    特征归因方法是提供对模型推理过程进行预测的流行方法。一个更加准确的归因方法标志着它更加忠实，它可以更加准确地反映哪些部分的输入对预测更加重要。然而，现有的忠实度评估方法，如充分性和全面性，只使用一种硬删除标准，即完全删除或保留由给定归因方法排名最高的顶部标记，并观察预测可能性的变化。因此，这种硬删除标准忽略了每个标记的重要性，把它们全部等同地处理。在本文中，我们提出了一个简单而有效的软删除标准。我们不会完全删除或保留输入中的标记，而是随机地遮盖代表归因方法重要性的部分标记向量表示。基于各种自然语言处理任务和不同的归因方法进行的广泛实验表明，我们的方法显著优于现有的评估方法。

    Feature attribution methods (FAs) are popular approaches for providing insights into the model reasoning process of making predictions. The more faithful a FA is, the more accurately it reflects which parts of the input are more important for the prediction. Widely used faithfulness metrics, such as sufficiency and comprehensiveness use a hard erasure criterion, i.e. entirely removing or retaining the top most important tokens ranked by a given FA and observing the changes in predictive likelihood. However, this hard criterion ignores the importance of each individual token, treating them all equally for computing sufficiency and comprehensiveness. In this paper, we propose a simple yet effective soft erasure criterion. Instead of entirely removing or retaining tokens from the input, we randomly mask parts of the token vector representations proportionately to their FA importance. Extensive experiments across various natural language processing tasks and different FAs show that our sof
    
[^112]: 基于知识增强的生成预训练模型在中国医学执业医师资格考试上的应用研究

    Qualifying Chinese Medical Licensing Examination with Knowledge Enhanced Generative Pre-training Model. (arXiv:2305.10163v1 [cs.CL])

    [http://arxiv.org/abs/2305.10163](http://arxiv.org/abs/2305.10163)

    本研究通过在ChatGPT中集成医学领域知识和启用少样本学习的新方法，在中国国家医学执业医师资格考试中取得成功，这为建立在自然语言处理技术和医学领域知识的创新应用提供了可能。

    

    生成式预训练模型（GPT），如ChatGPT，在各种自然语言处理任务中展现出了出色的性能。尽管ChatGPT已被整合到各个领域的工作流中以提高效率，但其微调过程的灵活性不足，阻碍了其在需要广泛领域专业知识和语义知识的领域，如医疗保健，的应用。在本文中，我们评估了ChatGPT在中国国家医学执业医师资格考试（CNMLE）中的表现，并提出了一种新的方法来改进ChatGPT，即从两个方面集成医学领域知识和启用少样本学习。通过使用简单但有效的检索方法，将医学背景知识提取为语义指令来指导ChatGPT的推断。类似地，相关的医疗问题被识别并作为演示输入给ChatGPT。实验结果表明，直接应用ChatGPT无法在CNMLE上获得合格分数（51分），只有基于知识增强训练的模型成功通过考试。

    Generative Pre-Training (GPT) models like ChatGPT have demonstrated exceptional performance in various Natural Language Processing (NLP) tasks. Although ChatGPT has been integrated into the overall workflow to boost efficiency in many domains, the lack of flexibility in the finetuning process hinders its applications in areas that demand extensive domain expertise and semantic knowledge, such as healthcare. In this paper, we evaluate ChatGPT on the China National Medical Licensing Examination (CNMLE) and propose a novel approach to improve ChatGPT from two perspectives: integrating medical domain knowledge and enabling few-shot learning. By using a simple but effective retrieval method, medical background knowledge is extracted as semantic instructions to guide the inference of ChatGPT. Similarly, relevant medical questions are identified and fed as demonstrations to ChatGPT. Experimental results show that directly applying ChatGPT fails to qualify the CNMLE at a score of 51 (i.e., onl
    
[^113]: 智能电网故障预测系统的机器学习对抗攻击

    Machine-learned Adversarial Attacks against Fault Prediction Systems in Smart Electrical Grids. (arXiv:2303.18136v1 [cs.CR])

    [http://arxiv.org/abs/2303.18136](http://arxiv.org/abs/2303.18136)

    该论文提出了针对智能电网故障预测系统的机器学习对抗攻击的研究，证明智能电网中使用的深度神经网络方法容易受到对抗性攻击，并突出了目前在智能电网中的机器学习算法存在对各种对抗性攻击的弱点。

    

    在智能电网中，由于经济和关键性的原因，故障检测任务可能会对社会产生很大的影响。近年来，许多智能电网应用程序，如缺陷检测和负载预测，已经采用了数据驱动的方法。本研究的目的是研究智能电网情况下机器学习（ML）应用的安全性挑战。事实上，这些数据驱动算法的鲁棒性和安全性尚未与所有电网应用程序相关地进行广泛研究。我们首先证明了智能电网中使用的深度神经网络方法容易受到对抗性攻击。接着，我们突出展示了故障定位和类型分类方面的研究，说明了目前在智能电网中的机器学习算法对各种对抗性攻击的弱点。

    In smart electrical grids, fault detection tasks may have a high impact on society due to their economic and critical implications. In the recent years, numerous smart grid applications, such as defect detection and load forecasting, have embraced data-driven methodologies. The purpose of this study is to investigate the challenges associated with the security of machine learning (ML) applications in the smart grid scenario. Indeed, the robustness and security of these data-driven algorithms have not been extensively studied in relation to all power grid applications. We demonstrate first that the deep neural network method used in the smart grid is susceptible to adversarial perturbation. Then, we highlight how studies on fault localization and type classification illustrate the weaknesses of present ML algorithms in smart grids to various adversarial attacks
    
[^114]: 新闻和负荷：基于自然语言处理的用于预测次日电力系统需求的量化探索

    News and Load: A Quantitative Exploration of Natural Language Processing Applications for Forecasting Day-ahead Electricity System Demand. (arXiv:2301.07535v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.07535](http://arxiv.org/abs/2301.07535)

    本文利用自然语言处理技术研究了电力需求和社会事件之间的关联，并通过分析词频、公众情感、主题分布和词嵌入等文本特征，改进了次日的电力需求预测。研究结果提供了新的视角，证实了从非结构化文本中改进预测的可行性。

    

    电力需求与天气之间的关系在电力系统中得到了确认，同时也强调了假日和重大事件等行为和社会因素的重要性。本研究利用成熟的自然语言处理（NLP）和需求预测技术，探索了电力需求与更细致的社会事件信息之间的关联。结果表明，词频、公众情感、主题分布和词嵌入等文本特征可以改善次日预测。这些特征中包含了全球大流行、政治、国际冲突、交通等社会事件。通过讨论因果效应和相关性，提出了关联机制的解释。本研究认为可以为传统的电力需求分析提供新的视角，证实了从非结构化文本中改进预测的可行性。

    The relationship between electricity demand and weather is well established in power systems, along with the importance of behavioral and social aspects such as holidays and significant events. This study explores the link between electricity demand and more nuanced information about social events. This is done using mature Natural Language Processing (NLP) and demand forecasting techniques. The results indicate that day-ahead forecasts are improved by textual features such as word frequencies, public sentiments, topic distributions, and word embeddings. The social events contained in these features include global pandemics, politics, international conflicts, transportation, etc. Causality effects and correlations are discussed to propose explanations for the mechanisms behind the links highlighted. This study is believed to bring a new perspective to traditional electricity demand analysis. It confirms the feasibility of improving forecasts from unstructured text, with potential conse
    
[^115]: 基于可达性验证的深度强化学习控制的机器人和自主系统的可靠性评估

    Reachability Verification Based Reliability Assessment for Deep Reinforcement Learning Controlled Robotics and Autonomous Systems. (arXiv:2210.14991v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2210.14991](http://arxiv.org/abs/2210.14991)

    本文提出了一个基于可达性验证的深度强化学习控制的机器人和自主系统的可靠性评估框架，通过验证证据生成对于不准确观测的安全属性检查，提供了局部和整体的可靠性量化指标。

    

    深度强化学习在机器人和自主系统领域取得了令人瞩目的性能。其在真实世界中应用的关键挑战是存在不安全的深度强化学习策略。未探索的状态可能导致Agent做出错误决策，可能会导致危险，特别是在DRL训练的端到端控制器指导下的应用中。本文提出了一种新颖的定量可靠性评估框架，针对DRL控制的RAS，利用从神经网络的形式可靠性分析生成的验证证据。引入了一个两级验证框架，用于检查与不准确的观测相关的安全属性，例如环境噪声和状态变化。通过本地利用可达性验证工具生成轨迹的安全证据。相反，在全局级别上，我们将整体可靠性量化为本地安全证据的聚合指标。

    Deep Reinforcement Learning (DRL) has achieved impressive performance in robotics and autonomous systems (RAS). A key challenge to its deployment in real-life operations is the presence of spuriously unsafe DRL policies. Unexplored states may lead the agent to make wrong decisions that could result in hazards, especially in applications where DRL-trained end-to-end controllers govern the behaviour of RAS. This paper proposes a novel quantitative reliability assessment framework for DRL-controlled RAS, leveraging verification evidence generated from formal reliability analysis of neural networks. A two-level verification framework is introduced to check the safety property with respect to inaccurate observations that are due to, e.g., environmental noise and state changes. Reachability verification tools are leveraged locally to generate safety evidence of trajectories. In contrast, at the global level, we quantify the overall reliability as an aggregated metric of local safety evidence
    
[^116]: 基于地磁惯性导航的动态传感器匹配

    Dynamic Sensor Matching based on Geomagnetic Inertial Navigation. (arXiv:2208.06233v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2208.06233](http://arxiv.org/abs/2208.06233)

    本研究提出了一种基于地磁惯性导航的动态传感器匹配方法，通过将多传感器数据转化为地球的磁场作为世界坐标系来实现对动态环境的重建。

    

    光学传感器能够捕捉动态环境并在几乎实时中获得深度信息。这些数字重建的质量取决于因素，如照明、表面和纹理条件、感测速度和其他传感器特性以及传感器与物体的关系。可以通过使用多传感器动态采集的数据来改进。然而，匹配来自多个传感器的数据需要一个共享的世界坐标系。我们提出了一种将多传感器数据转化为一个共同参考的世界坐标系的概念：地球的磁场。我们行使的磁场提供了一个可靠的世界坐标系，可以作为确定位置的动态环境重建的参考。我们的方法使用来自Stereolabs的ZED 2立体相机的磁场传感器进行评估，该传感器提供与北极的方向相对应的方向。

    Optical sensors can capture dynamic environments and derive depth information in near real-time. The quality of these digital reconstructions is determined by factors like illumination, surface and texture conditions, sensing speed and other sensor characteristics as well as the sensor-object relations. Improvements can be obtained by using dynamically collected data from multiple sensors. However, matching the data from multiple sensors requires a shared world coordinate system. We present a concept for transferring multi-sensor data into a commonly referenced world coordinate system: the earth's magnetic field. The steady presence of our planetary magnetic field provides a reliable world coordinate system, which can serve as a reference for a position-defined reconstruction of dynamic environments. Our approach is evaluated using magnetic field sensors of the ZED 2 stereo camera from Stereolabs, which provides orientation relative to the North Pole similar to a compass. With the help
    
[^117]: 在复杂的多智能体场景中估计反事实治疗结果的时间变化

    Estimating counterfactual treatment outcomes over time in complex multi-agent scenarios. (arXiv:2206.01900v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2206.01900](http://arxiv.org/abs/2206.01900)

    本论文提出了一个可解释的反事实循环网络，用于在复杂的多智能体场景中估计干预效果。该模型考虑了时间变化的多智能体关系和协变量反事实预测的复杂结构，能够准确评估个体治疗效果，并提供解释性。

    

    在各种工程和科学领域中，评估多智能体系统中的干预行为（例如，人类何时应该干预自动驾驶系统，何时球员应该传给队友进行好射门）是一项具有挑战性的任务。使用反事实的长期预测来估计个体治疗效果（ITE）是评估此类干预措施的实用方法。然而，大多数传统框架没有考虑到多智能体关系的时间变化和协变量反事实预测的复杂结构，这可能导致ITE的错误评估和解释困难。在这里，我们提出了一个可解释的反事实循环网络，用于估计干预的效果。我们的模型利用图形变分循环神经网络和基于领域知识的计算来进行基于多智能体协变量和结果的长期预测的ITE估计框架，能够确认循环结构。

    Evaluation of intervention in a multi-agent system, e.g., when humans should intervene in autonomous driving systems and when a player should pass to teammates for a good shot, is challenging in various engineering and scientific fields. Estimating the individual treatment effect (ITE) using counterfactual long-term prediction is practical to evaluate such interventions. However, most of the conventional frameworks did not consider the time-varying complex structure of multi-agent relationships and covariate counterfactual prediction. This may lead to erroneous assessments of ITE and difficulty in interpretation. Here we propose an interpretable, counterfactual recurrent network in multi-agent systems to estimate the effect of the intervention. Our model leverages graph variational recurrent neural networks and theory-based computation with domain knowledge for the ITE estimation framework based on long-term prediction of multi-agent covariates and outcomes, which can confirm the circu
    

