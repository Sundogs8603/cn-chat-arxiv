# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [My Art My Choice: Adversarial Protection Against Unruly AI.](http://arxiv.org/abs/2309.03198) | 该论文提出了一种名为"我是我艺术的选择"（MAMC）的方法，旨在通过对抗手段保护艺术作品的版权，该方法通过生成对抗性扰动后的图像来"破解"扩散模型的功能。这种方法可以平衡内容的失真和保护，并且可以攻击黑盒扩散模型。 |
| [^2] | [Split-Boost Neural Networks.](http://arxiv.org/abs/2309.03167) | 这篇论文提出了一种称为分割增强的训练策略，通过自动包含正则化行为，降低了神经网络训练的复杂性和计算资源需求。 |
| [^3] | [J-Guard: Journalism Guided Adversarially Robust Detection of AI-generated News.](http://arxiv.org/abs/2309.03164) | J-Guard是一个能够在AI生成新闻中检测AI生成文本的框架，通过引入新闻属性和提高对抗鲁棒性，解决了现有方法的不可靠性和误报问题。 |
| [^4] | [Risk-reducing design and operations toolkit: 90 strategies for managing risk and uncertainty in decision problems.](http://arxiv.org/abs/2309.03133) | 该论文研究了风险降低设计和运营工具包（RDOT）中的90种策略，这些策略可在高度不确定的决策问题中提供有效的响应。这些策略包括将稳健性纳入设计、事后预防措施等，能够帮助工程师、公共规划者和其他决策者应对挑战。 |
| [^5] | [MyoDex: A Generalizable Prior for Dexterous Manipulation.](http://arxiv.org/abs/2309.03130) | 本研究从人类灵巧操作的多样先前经验中汲取灵感，开发了能够利用以前的经验快速获得新行为的代理者。我们的方法利用了多任务学习来捕捉通用的行为先验（MyoDex），并使用了基于生理学的人手模型 - MyoHand。实验证明，利用MyoDex的代理者可以解决更多的任务，并且具有良好的泛化能力。 |
| [^6] | [Detecting Manufacturing Defects in PCBs via Data-Centric Machine Learning on Solder Paste Inspection Features.](http://arxiv.org/abs/2309.03113) | 通过利用锡膏检查特征，基于数据的机器学习方法能够在PCB制造中的三个阶段检测缺陷，提高操作效率和减少人工干预。 |
| [^7] | [Smoothing ADMM for Sparse-Penalized Quantile Regression with Non-Convex Penalties.](http://arxiv.org/abs/2309.03094) | 本文提出了一种适用于稀疏加权分位数回归的新型单循环平滑ADMM算法，名为SIAD，它在存在非凸和非光滑稀疏惩罚条件下能够加速收敛速度。 |
| [^8] | [Establishing Markov Equivalence in Cyclic Directed Graphs.](http://arxiv.org/abs/2309.03092) | 本论文提出了一种在循环有向图中建立马尔可夫等价关系的新方法，该方法不再需要对d-分离进行测试，大大减小了算法的复杂性，并且在存在潜在混淆因素的情况下具有重要的理论研究价值。 |
| [^9] | [Unreflected Acceptance -- Investigating the Negative Consequences of ChatGPT-Assisted Problem Solving in Physics Education.](http://arxiv.org/abs/2309.03087) | 在高等物理教育中，研究发现使用ChatGPT辅助问题解决的学生往往过于依赖模型，导致近一半的解答被错误地认为是正确的。 |
| [^10] | [Pure Monte Carlo Counterfactual Regret Minimization.](http://arxiv.org/abs/2309.03084) | 纯蒙特卡洛反事实遗憾最小化算法（PCFR）是一种结合了反事实遗憾最小化（CFR）和虚拟游戏（FP）概念的新算法，能够与各种CFR变体相结合，包括蒙特卡洛CFR（MCCFR）。PCFR具有更好的性能和较快的收敛速度，同时降低了时间和空间复杂度。 |
| [^11] | [A Multimodal Analysis of Influencer Content on Twitter.](http://arxiv.org/abs/2309.03064) | 本研究通过引入一个新的Twitter数据集，结合文本和视觉信息，实验了多种预测模型，旨在自动检测影响者内容中的商业推广行为。 |
| [^12] | [Hide and Seek (HaS): A Lightweight Framework for Prompt Privacy Protection.](http://arxiv.org/abs/2309.03057) | 本论文提出了一种名为Hide and Seek (HaS)的轻量级框架，通过训练一个小型本地模型，可以在保护用户隐私的同时，对大型语言模型返回的结果进行解匿名化。 |
| [^13] | [Combining pre-trained Vision Transformers and CIDER for Out Of Domain Detection.](http://arxiv.org/abs/2309.03047) | 本研究探讨了将预训练的Vision Transformers和CIDER方法相结合用于域外检测任务的性能。实验结果显示，预训练的Transformer模型在开箱即用的情况下表现出更高的检测性能。通过将ViT和CNN与CIDER方法结合，可以进一步提高OOD检测性能。这些结果表明Transformer是一种有前途的OOD检测方法，并为该任务设立了更强的基准。 |
| [^14] | [A Refutation of Shapley Values for Explainability.](http://arxiv.org/abs/2309.03041) | 这篇论文驳斥了Shapley Values在规则解释中的适用性，并证明了存在布尔函数，使得Shapley值给出的特征重要性信息具有误导性。该论文提供了一种蛮力方法来识别这种问题，但对于特征数量较大的布尔函数仍存在问题。 |
| [^15] | [An Efficient Temporary Deepfake Location Approach Based Embeddings for Partially Spoofed Audio Detection.](http://arxiv.org/abs/2309.03036) | 该论文提出了一种基于嵌入的临时Deepfake位置方法（TDL）用于部分伪造音频检测，通过嵌入相似性模块和时间卷积操作，能有效捕捉音频的特征和位置信息。实验结果表明，在ASVspoof2019 Partial Spoof数据集中，该方法优于基准模型。 |
| [^16] | [Universal Preprocessing Operators for Embedding Knowledge Graphs with Literals.](http://arxiv.org/abs/2309.03023) | 本文提出了一组通用预处理操作符，用于将具有数值、时间、文本和图像信息的知识图谱转换为能够使用任何嵌入方法的形式，并在数据集上展示了有希望的结果。 |
| [^17] | [EdgeFL: A Lightweight Decentralized Federated Learning Framework.](http://arxiv.org/abs/2309.02936) | EdgeFL是一种轻量级分散式联邦学习框架，通过仅在边缘进行模型训练和汇总的方法，消除了中央服务器的需求，实现了对各种用例的无缝可扩展性，并提供了灵活的定制汇总函数的能力。 |
| [^18] | [Estimating irregular water demands with physics-informed machine learning to inform leakage detection.](http://arxiv.org/abs/2309.02935) | 本研究提出了一种利用物理信息的机器学习算法，通过分析压力数据估计未知的不规则用水需求，并通过简化泄漏检测问题实现线性化。 |
| [^19] | [On the Challenges of Building Datasets for Hate Speech Detection.](http://arxiv.org/abs/2309.02912) | 本研究旨在分析仇恨言论检测中的问题，并提出了一种综合框架来指导未来构建仇恨言论数据集的最佳实践。 |
| [^20] | [DECODE: Data-driven Energy Consumption Prediction leveraging Historical Data and Environmental Factors in Buildings.](http://arxiv.org/abs/2309.02908) | 本论文介绍了一种基于历史数据、占用模式和天气条件的LSTM模型，用于准确预测建筑能耗，该模型在预测精度上表现出卓越性能。 |
| [^21] | [A deep Natural Language Inference predictor without language-specific training data.](http://arxiv.org/abs/2309.02887) | 本文介绍了一种处理目标语言句子对之间推理关系问题的新方法，该方法不需要特定语言的训练数据集。通过利用一个通用的翻译数据集和两个预训练模型的实例，模型可以在不同任务上展现出通用性，且在多个数据集上得到了验证。 |
| [^22] | [MAD: Modality Agnostic Distance Measure for Image Registration.](http://arxiv.org/abs/2309.02875) | MAD是一种利用随机卷积学习图像固有几何特性的深度图像距离度量方法，它能够有效解决多模态图像配准中的外观差异问题。 |
| [^23] | [Rethinking Momentum Knowledge Distillation in Online Continual Learning.](http://arxiv.org/abs/2309.02870) | 该论文重新思考了在线连续学习中的动量知识蒸馏问题，通过将动量知识蒸馏应用于OCL方法，提高了现有方法的准确性，并对MKD在OCL中的训练过程进行了深入分析。 |
| [^24] | [Generalised Mutual Information: a Framework for Discriminative Clustering.](http://arxiv.org/abs/2309.02858) | 本文介绍了通用互信息（GEMINI）作为一种辨别聚类的框架，相比互信息（MI），GEMINI在无监督神经网络训练过程中不需要正则化，其可以选择合适的聚类数量。 |
| [^25] | [Getting too personal(ized): The importance of feature choice in online adaptive algorithms.](http://arxiv.org/abs/2309.02856) | 该论文讨论了在线自适应算法中特征选择的重要性。研究发现，在需要学习最佳操作时，个性化学习能够提高算法性能。然而，在其他情况下，包含不必要的学生特征可能会降低算法性能。 |
| [^26] | [Promoting Open-domain Dialogue Generation through Learning Pattern Information between Contexts and Responses.](http://arxiv.org/abs/2309.02823) | 本文通过学习上下文和回复之间的隐式模式信息提高了开放领域对话生成模型的质量，采用了改进的预训练模型的计划采样方法，使生成的回复更加生动和信息丰富。 |
| [^27] | [Roulette: A Semantic Privacy-Preserving Device-Edge Collaborative Inference Framework for Deep Learning Classification Tasks.](http://arxiv.org/abs/2309.02820) | Roulette是一种用于深度学习分类任务的语义隐私保护的设备边缘协同推理框架，通过混淆和加噪声实现隐私保护，同时保持高准确性。 |
| [^28] | [Combining Thermodynamics-based Model of the Centrifugal Compressors and Active Machine Learning for Enhanced Industrial Design Optimization.](http://arxiv.org/abs/2309.02818) | 结合离心压缩机的热力学模型和主动机器学习，提出了Active-CompDesign框架用于离心压缩机的优化设计。在离线和在线环境中进行实验，显示出显著的性能提升。 |
| [^29] | [Near-continuous time Reinforcement Learning for continuous state-action spaces.](http://arxiv.org/abs/2309.02815) | 本文提出了一种几乎连续时间的强化学习方法，用于控制连续状态动作空间中的未知动力系统，在单个轨迹上最大化长期平均奖励，并通过使用泊松时钟对交互时间进行建模，从离散到连续时间捕捉任意时间尺度。 |
| [^30] | [Norm Tweaking: High-performance Low-bit Quantization of Large Language Models.](http://arxiv.org/abs/2309.02784) | 本文介绍了一种称为“norm tweaking”的技术，通过调整量化的激活分布来实现高精度的低比特量化，以提高大型语言模型的压缩性能。 |
| [^31] | [Improving diagnosis and prognosis of lung cancer using vision transformers: A scoping review.](http://arxiv.org/abs/2309.02783) | 这项范围审查总结了最近基于视觉变换器的人工智能方法在肺癌成像应用方面的发展，重点探讨了如何改善肺癌的诊断和预后，以及相关数据集的贡献。 |
| [^32] | [SWAP: Exploiting Second-Ranked Logits for Adversarial Attacks on Time Series.](http://arxiv.org/abs/2309.02752) | 该论文提出了一种针对时间序列的新的对抗攻击方法SWAP，通过提高次级logits的置信度，同时最小化对其他logits的干扰来实现攻击。实验证明，该方法在ASR上取得了最先进的性能。 |
| [^33] | [MLN-net: A multi-source medical image segmentation method for clustered microcalcifications using multiple layer normalization.](http://arxiv.org/abs/2309.02742) | 提出了一种名为MLN-net的新型框架，用于集群微钙化的准确分割。该方法能够使用单一源图像来准确地分割多源图像，通过多层归一化层结构来处理不同领域的图像分割，进而提高了泛化性能。 |
| [^34] | [Rubric-Specific Approach to Automated Essay Scoring with Augmentation Training.](http://arxiv.org/abs/2309.02740) | 本文提出一种用于自动评分的细分标准特定方法，通过增强培训和测试数据来学习之前研究中忽视的特征和功能，达到了最新性能。 |
| [^35] | [HC3 Plus: A Semantic-Invariant Human ChatGPT Comparison Corpus.](http://arxiv.org/abs/2309.02731) | 本文介绍了HC3 Plus，一个语义不变的人类ChatGPT对比语料库。与以往的工作相比，该语料库考虑了更多类型的任务，包括语义不变任务。研究发现，在语义不变任务中检测模型生成的文本更加困难。通过大量任务指令微调和Tk-instruct，建立了一个更强大的模型。 |
| [^36] | [Stylebook: Content-Dependent Speaking Style Modeling for Any-to-Any Voice Conversion using Only Speech Data.](http://arxiv.org/abs/2309.02730) | 这项工作提出了一种新的方法，即 Stylebook，它通过使用自监督学习模型从目标语音中提取丰富的风格信息，并将其高效地转移到源语音内容上，无需文本转录或说话者标记。该方法引入了注意力机制和样式手册，可以实现目标说话者的忠实复制和风格转移。 |
| [^37] | [Large Language Models for Automated Open-domain Scientific Hypotheses Discovery.](http://arxiv.org/abs/2309.02726) | 这项研究提出了用于社会科学学术假设发现的第一个自然语言处理数据集，旨在开发一个系统，能够基于原始网络语料库自动生成有效、新颖且对人类研究者有帮助的假设。 |
| [^38] | [Offensive Hebrew Corpus and Detection using BERT.](http://arxiv.org/abs/2309.02724) | 本研究提出了一个新的希伯来语侮辱性语料库，并使用两个希伯来语BERT模型（HeBERT和AlephBERT）进行了微调。我们观察到，我们的数据结合D_OLaH可以提高HeBERT模型的性能2%。此外，我们的数据对AlephBERT模型也具有一定的泛化性能。 |
| [^39] | [SlAction: Non-intrusive, Lightweight Obstructive Sleep Apnea Detection using Infrared Video.](http://arxiv.org/abs/2309.02713) | SlAction利用红外视频进行无干扰、轻量级的OSA检测，通过分析睡眠期间的人体运动与OSA事件之间的相关性，可用于日常睡眠环境中，可以避免传统的多导睡眠图的不准确性。 |
| [^40] | [Unveiling the frontiers of deep learning: innovations shaping diverse domains.](http://arxiv.org/abs/2309.02712) | 本文广泛研究了深度学习在各个主要研究领域中的潜在应用，揭示了其准确性和计算能力的优势，以及相关的挑战。 |
| [^41] | [Addressing Imperfect Symmetry: a Novel Symmetry-Learning Actor-Critic Extension.](http://arxiv.org/abs/2309.02711) | 本研究提出了自适应对称学习（ASL）方法，通过模型最小化的方法，在学习过程中自适应地解决不完全或不精确的对称描述。ASL包括对称拟合组件和模块化损失函数，能高效适应对称性任务。 |
| [^42] | [Certifying LLM Safety against Adversarial Prompting.](http://arxiv.org/abs/2309.02705) | 本研究提出了首个具有可验证安全保证的框架——消除和检查，用于对抗敌对提示。通过逐个消除标记并使用安全过滤器检查生成的子序列，确保任何敌对修改的有害输入提示都能被正确标识为有害。 |
| [^43] | [Diffusion-EDFs: Bi-equivariant Denoising Generative Modeling on SE(3) for Visual Robotic Manipulation.](http://arxiv.org/abs/2309.02685) | 本文提出了Diffusion-EDFs，一种在视觉机器人操作中应用的基于SE(3)的等变去噪生成建模方法。通过集成SE(3)等变性，我们的方法展示了出色的数据效率和泛化能力。 |
| [^44] | [RLSynC: Offline-Online Reinforcement Learning for Synthon Completion.](http://arxiv.org/abs/2309.02671) | RLSynC是一种离线-在线强化学习方法，用于半模板化逆向合成中的合成物补全。它使用多个代理同时完成合成物的补全，并通过正向合成模型评估反应物的合成能力来指导行动搜索。 |
| [^45] | [Subsethood Measures of Spatial Granules.](http://arxiv.org/abs/2309.02662) | 本文介绍了空间粒子的子集测度以及与之相关的粗精关系和操作。通过这些概念，我们可以构建粗糙集模型和空间粗糙粒子模型，这对于解决结构问题非常重要。 |
| [^46] | [TFBEST: Dual-Aspect Transformer with Learnable Positional Encoding for Failure Prediction.](http://arxiv.org/abs/2309.02641) | 本文提出了一种新颖的双重方面Transformer模型，用于故障预测，有效处理长序列日志和提供预测值的置信区间。 |
| [^47] | [Deep Reinforcement Learning from Hierarchical Weak Preference Feedback.](http://arxiv.org/abs/2309.02632) | 本研究探讨了如何利用分层的弱偏好反馈进行深度强化学习。通过学习奖励函数，与人类偏好非常一致的复杂奖励可以帮助强化学习解决日益困难的问题。 |
| [^48] | [Utilizing Generative Adversarial Networks for Stable Structure Generation in Angry Birds.](http://arxiv.org/abs/2309.02614) | 本文研究了使用生成对抗网络（GANs）为愤怒的小鸟生成复杂且稳定的结构。实验结果表明GANs可以成功应用于生成多样化的愤怒的小鸟结构。 |
| [^49] | [Detection of Unknown-Unknowns in Cyber-Physical Systems using Statistical Conformance with Physics Guided Process Models.](http://arxiv.org/abs/2309.02603) | 该论文提出了一个新的框架来分析安全关键的协同实体系统的操作输出特性的随机符合性，从而发现未知-未知情况并评估潜在的安全风险。 |
| [^50] | [Comparative Evaluation of Metaheuristic Algorithms for Hyperparameter Selection in Short-Term Weather Forecasting.](http://arxiv.org/abs/2309.02600) | 本文比较评估了短期天气预报中元启发式算法（遗传算法、差分进化算法和粒子群优化算法）在优化深度学习模型的超参数选择方面的应用，证明了这些算法在全局优化中的优势和可扩展性。 |
| [^51] | [Using Physics-Informed Neural Networks to Calculate Minimal Surfaces in Higher Dimensions.](http://arxiv.org/abs/2309.02589) | 本文使用物理知识的神经网络（PINN）计算更高维度中的最小曲面的数值逼近，解决了维数诅咒问题，并且能够在没有GPU的笔记本电脑上进行快速训练。 |
| [^52] | [Representation Learning for Sequential Volumetric Design Tasks.](http://arxiv.org/abs/2309.02583) | 本研究提出了一种顺序体积设计任务的表示学习方法，通过利用transformer模型从专家的设计序列中提取有用的表示来提高自动生成体积设计的质量，以及支持设计偏好评估和程序化设计生成。 |
| [^53] | [Unveiling Intractable Epileptogenic Brain Networks with Deep Learning Algorithms: A Novel and Comprehensive Framework for Scalable Seizure Prediction with Unimodal Neuroimaging Data in Pediatric Patients.](http://arxiv.org/abs/2309.02580) | 本研究提出了一种新颖而全面的框架，通过评估机器学习算法对儿童患者的脑电图信号进行分析，揭示了难治性癫痫的脑网络，并实现了可扩展的癫痫预测。 |
| [^54] | [Diffusion-based Time Series Data Imputation for Microsoft 365.](http://arxiv.org/abs/2309.02564) | 本研究提出了一种基于扩散的数据插补方法Diffusion+，通过观察到的数据高效地插补缺失数据，提高了微软365的数据质量，进而改善了下游故障预测任务的性能。 |
| [^55] | [Recurrence-Free Survival Prediction for Anal Squamous Cell Carcinoma Chemoradiotherapy using Planning CT-based Radiomics Model.](http://arxiv.org/abs/2309.02562) | 通过提取放射组学特征，我们开发了一个模型，能够利用计划CT图像来预测肛门鳞状细胞癌化疗放疗后的无复发生存期。放射组学特征显著预测了RFS。 |
| [^56] | [Physically Grounded Vision-Language Models for Robotic Manipulation.](http://arxiv.org/abs/2309.02561) | 该论文介绍了一个用于机器人操作的具有物理基础的视觉语言模型，通过在物体上微调模型，提高了模型对物理概念的理解，在语言交互框架中展现了良好的性能。 |
| [^57] | [Automating Behavioral Testing in Machine Translation.](http://arxiv.org/abs/2309.02553) | 本文提出了一种利用大型语言模型自动生成源句子的方法，以测试机器翻译模型在多种情况下的行为。通过对多个机器翻译系统应用该方法，发现在测试结果与传统准确率度量存在差异的情况下，仍可观察到一致的趋势。 |
| [^58] | [Continual Improvement of Threshold-Based Novelty Detection.](http://arxiv.org/abs/2309.02551) | 论文提出了一种新的方法，利用线性搜索和离一标准交叉验证自动选择阈值，从而改进了动态环境中神经网络的新颖性检测准确率。 |
| [^59] | [Structural Concept Learning via Graph Attention for Multi-Level Rearrangement Planning.](http://arxiv.org/abs/2309.02547) | 本论文提出了一种名为结构概念学习（SCL）的深度学习方法，利用图注意力网络进行多层次物体重组规划。该方法在自动生成的模拟数据集上训练，可以适应具有复杂结构依赖的未知场景，推断出独立的子结构以实现任务并行化，并且在现实世界中具有泛化能力。 |
| [^60] | [Experience and Prediction: A Metric of Hardness for a Novel Litmus Test.](http://arxiv.org/abs/2309.02534) | 该论文实现了一种自动化系统，通过设计和输出Winograd模式的硬度指数，可以在未来的挑战或WSC CAPTCHA服务中对模式进行区分分类。 |
| [^61] | [Do You Trust ChatGPT? -- Perceived Credibility of Human and AI-Generated Content.](http://arxiv.org/abs/2309.02524) | 本文研究了人们对来自人类作者和由大型语言模型生成的内容的可信度感知，发现不论用户界面如何呈现，参与者倾向于赋予相似水平的可信度。尽管人们对人类和AI生成内容的能力和值得信赖程度没有不同的感知，但他们认为AI生成的内容更加清晰且更具吸引力。这项研究呼吁我们在评估信息来源时更加审慎，并鼓励用户保持警惕和批判性思维。 |
| [^62] | [Enhancing Semantic Communication with Deep Generative Models -- An ICASSP Special Session Overview.](http://arxiv.org/abs/2309.02478) | 用深度生成模型增强语义通信，解决从复杂数据中提取语义信息和处理通道干扰的挑战。 |
| [^63] | [A Survey of Imitation Learning: Algorithms, Recent Developments, and Challenges.](http://arxiv.org/abs/2309.02473) | 这篇论文综述了模仿学习的算法、最新进展和挑战，指出在复杂和非结构化的环境中，通过模仿专家行为来学习所需行为更具吸引力。 |
| [^64] | [Towards Foundational AI Models for Additive Manufacturing: Language Models for G-Code Debugging, Manipulation, and Comprehension.](http://arxiv.org/abs/2309.02465) | 本文针对三维打印的G代码文件提出了六种基础大型语言模型（LLMs），通过评估它们在G代码调试和操作方面的性能，包括错误检测和修正以及几何变换等。结果表明这些模型具有潜力应用于增材制造领域。 |
| [^65] | [Effective Multi-Graph Neural Networks for Illicit Account Detection on Cryptocurrency Transaction Networks.](http://arxiv.org/abs/2309.02460) | 本文介绍了一种新颖的多图神经网络模型DIAM，用于有效地检测加密货币交易网络上的非法账户。该模型通过自动学习节点表示并保留平行边的内在交易模式，在大型交易网络中取得了良好的效果。 |
| [^66] | [Towards frugal unsupervised detection of subtle abnormalities in medical imaging.](http://arxiv.org/abs/2309.02458) | 本文研究了无监督医学影像微小异常检测的节俭方法，通过使用概率分布混合模型来代替人工神经网络，实现了在准确度和计算需求之间的最优权衡。 |
| [^67] | [Observe Locally, Classify Globally: Using GNNs to Identify Sparse Matrix Structure.](http://arxiv.org/abs/2309.02442) | 使用图神经网络识别稀疏矩阵结构的框架在匹配数据格式和避免读取整个数据集的挑战中取得了成功。 |
| [^68] | [Information Processing by Neuron Populations in the Central Nervous System: Mathematical Structure of Data and Operations.](http://arxiv.org/abs/2309.02332) | 神经群体在中枢神经系统中使用数学结构精确地表示和操作信息，实现了特化、泛化、新奇检测等多种功能。 |
| [^69] | [FSD: An Initial Chinese Dataset for Fake Song Detection.](http://arxiv.org/abs/2309.02232) | 本论文中，我们首次构建了一个用于研究歌曲深度伪造检测的中文数据集，并发现现有训练于语音的DeepFake检测模型在此任务上不起作用。 |
| [^70] | [CodeApex: A Bilingual Programming Evaluation Benchmark for Large Language Models.](http://arxiv.org/abs/2309.01940) | CodeApex是一个双语编程评估基准，用于评估大型语言模型在编程理解和代码生成任务上的能力。该基准包括多个选择题和算法问题，评估了14个LLM的编程能力，并发现仍有改进空间。 |
| [^71] | [Efficient Query-Based Attack against ML-Based Android Malware Detection under Zero Knowledge Setting.](http://arxiv.org/abs/2309.01866) | 本论文介绍了一种在无知识环境下高效的基于查询的攻击框架，针对机器学习型安卓恶意软件检测方法。对各种主流方法和杀毒软件进行了广泛评估，结果表明该框架具有强大的攻击效果。 |
| [^72] | [Neural-Singular-Hessian: Implicit Neural Representation of Unoriented Point Clouds by Enforcing Singular Hessian.](http://arxiv.org/abs/2309.01793) | 本研究提出了一种神经奇异黑塞矩阵的方法，通过强制神经隐式函数的黑塞矩阵在靠近表面的点上具有零行列式，从质量较差的无定向点云中重构高保真的形状。 |
| [^73] | [Memory Efficient Optimizers with 4-bit States.](http://arxiv.org/abs/2309.01507) | 本论文通过将优化器状态的位宽压缩至4位，实现了内存高效的训练神经网络。通过对一阶和二阶矩的详细经验分析，我们发现当前的块状量化方法无法准确近似复杂的异常值模式。为此，我们使用较小的块大小并同时利用行上和列上的信息进行更好的量化。此外，我们还通过排除零点的线性量化器解决了量化第二阶矩时的零点问题。我们的工作在多个基准测试上进行了评估，结果表明我们的4位优化器具有出色的性能。 |
| [^74] | [Refined Temporal Pyramidal Compression-and-Amplification Transformer for 3D Human Pose Estimation.](http://arxiv.org/abs/2309.01365) | 通过优化的时间金字塔压缩和放大变换器，该论文提出了一种在视频序列中准确估计人体3D姿势的方法。该方法通过扩展时间建模和细化特征交互来解决其他方法中的细节和稳定性问题，展示了较好的效果。 |
| [^75] | [Separable Hamiltonian Neural Networks.](http://arxiv.org/abs/2309.01069) | 这篇论文介绍了可分离哈密顿神经网络的应用，它通过嵌入可加性分离性来解决高维哈密顿系统中的复杂性问题。 |
| [^76] | [CPSP: Learning Speech Concepts From Phoneme Supervision.](http://arxiv.org/abs/2309.00424) | 论文提出了一种名为CPSP的方法，通过对比学习来从语音中提取细粒度的中间表示，使得提取的信息既包含语言内容又去除了发言人身份和声学细节，适用于TTS、VC和ASR等任务。 |
| [^77] | [StratMed: Relevance Stratification for Low-resource Medication Recommendation.](http://arxiv.org/abs/2308.16781) | StratMed是一种面向低资源药物推荐的模型，通过相关性分层机制来解决医疗数据长尾分布不平衡的问题，平衡了药物组合的安全性和准确性。 |
| [^78] | [Socratis: Are large multimodal models emotionally aware?.](http://arxiv.org/abs/2308.16741) | 这项研究提出了Socratis，一个新的社会反应基准，用于学习多模态内容的多样化情绪反应。根据人类研究结果，人们更喜欢人工撰写的情感原因，比机器生成的要多2倍以上。 |
| [^79] | [Empowering LLM to use Smartphone for Intelligent Task Automation.](http://arxiv.org/abs/2308.15272) | 本论文提出了AutoDroid，一个移动任务自动化系统，可以在任何Android应用程序上自动处理任意任务。它通过结合LLMs的常识知识和应用的领域特定知识来实现，通过自动化的动态分析来实现功能意识的UI表示方法和基于探索的内存注入技术。 |
| [^80] | [Conflict-Aware Active Automata Learning.](http://arxiv.org/abs/2308.14781) | C3AL是一种冲突感知的主动有限状态机学习框架，能够处理观测数据中的冲突，通过将观测树作为学习过程的一等公民并最小化测试次数，具有很好的效果。 |
| [^81] | [InstructME: An Instruction Guided Music Edit And Remix Framework with Latent Diffusion Models.](http://arxiv.org/abs/2308.14360) | InstructME是一个基于潜在扩散模型的指导音乐编辑和混音框架，通过多尺度聚合和引入和弦进展矩阵来保持编辑的一致性和提高旋律和谐性。 |
| [^82] | [DynED: Dynamic Ensemble Diversification in Data Stream Classification.](http://arxiv.org/abs/2308.10807) | DynED是一种动态集成多样化方法，基于MRR结合了组件的多样性和预测准确性，在数据流环境中实现了更高的准确率。 |
| [^83] | [Proceedings of the 2nd International Workshop on Adaptive Cyber Defense.](http://arxiv.org/abs/2308.09520) | 第二届自适应网络防御国际研讨会的目标是探索利用人工智能和机器学习作为自适应网络防御基础能力的研究，并通过填补AI和网络研究人员之间的差距来加速开发半自主网络防御系统。 |
| [^84] | [Federated Learning: Organizational Opportunities, Challenges, and Adoption Strategies.](http://arxiv.org/abs/2308.02219) | 本文探讨了联邦学习的技术基础和潜在应用，提出了联邦学习的采用策略框架，并指出联邦学习为商业和信息系统工程学界提供了跨学科研究机会。 |
| [^85] | [Spherical and Hyperbolic Toric Topology-Based Codes On Graph Embedding for Ising MRF Models: Classical and Quantum Topology Machine Learning.](http://arxiv.org/abs/2307.15778) | 本论文介绍了在图嵌入中应用信息几何来描述Ising模型的基态，通过利用球面和双曲面拓扑上的编码，建立了机器学习和纠错编码之间的联系，并通过优化纠错码和发展嵌入方法提出了一种新的编码方法。 |
| [^86] | [Towards eXplainable AI for Mobility Data Science.](http://arxiv.org/abs/2307.08461) | 本文介绍了朝着可解释的AI在移动数据科学中的应用的工作，包括可解释模型的设计和使用时间图神经网络和反事实来学习从密集轨迹数据中提取信息的方法。 |
| [^87] | [Fed-CPrompt: Contrastive Prompt for Rehearsal-Free Federated Continual Learning.](http://arxiv.org/abs/2307.04869) | 本文提出了一种名为Fed-CPrompt的方法，用于解决无重复学习的联邦持续学习中的遗忘问题。该方法通过异步提示学习和对比持续损失处理异步任务到达和异构数据分布，并在实验证明其在该领域取得了最先进的性能。 |
| [^88] | [Loss Functions and Metrics in Deep Learning. A Review.](http://arxiv.org/abs/2307.02694) | 本文回顾了深度学习中最常见的损失函数和性能测量方法，旨在帮助从业者选择最适合其特定任务的方法。 |
| [^89] | [Beyond Known Reality: Exploiting Counterfactual Explanations for Medical Research.](http://arxiv.org/abs/2307.02131) | 本研究利用反事实解释来探索医学研究中的“假如”场景，通过提供个性化和情境特定的见解，拓展了我们对现有边界的理解，并填补了机器学习算法结果解释的缺失。 |
| [^90] | [Optimism and Adaptivity in Policy Optimization.](http://arxiv.org/abs/2306.10587) | 本文通过将看似无关的策略优化算法重新构造为共同的两个交错步骤，即乐观策略改进和后见适应，统一了强化学习中的策略优化方法，揭示了加速方法中的乐观性和适应性的共同理论属性。 |
| [^91] | [High-dimensional and Permutation Invariant Anomaly Detection.](http://arxiv.org/abs/2306.03933) | 该研究引入了一种置换不变的高维密度估计方法，通过学习后将其用于高能物理数据中的异常检测，能够有效地识别出在仅具备背景假设下排除异常的喷注。 |
| [^92] | [SourceP: Smart Ponzi Schemes Detection on Ethereum Using Pre-training Model with Data Flow.](http://arxiv.org/abs/2306.01665) | 本文提出了一种使用预训练模型和数据流的方法，通过智能合约的源代码特征，实现检测以太坊上的智能庞兹骗局。该方法提高了模型的可解释性和降低了数据获取和特征提取的难度。 |
| [^93] | [Layout and Task Aware Instruction Prompt for Zero-shot Document Image Question Answering.](http://arxiv.org/abs/2306.00526) | 该论文提出了一种布局和任务感知的指导提示模型，称为LATIN-Prompt，通过将文档图像问答对齐到现成的指导调优语言基础模型，利用其零样本能力来提高效果。该模型包括布局感知的文档内容和任务感知的描述，能够恢复文本片段之间的布局信息，并生成符合任务需求的答案。 |
| [^94] | [AnoOnly: Semi-Supervised Anomaly Detection without Loss on Normal Data.](http://arxiv.org/abs/2305.18798) | AnoOnly是一个新的半监督异常检测框架，通过引入一种对正常数据的弱监督形式来解决同质数据对异常的影响，以实现平衡的监督。该框架在各种模型和数据集上表现出了显著的性能提升，达到了新的最佳性能。 |
| [^95] | [Open problems in causal structure learning: A case study of COVID-19 in the UK.](http://arxiv.org/abs/2305.03859) | 本文研究了因果机器学习在COVID-19英国疫情数据中的应用挑战，探讨了不同数据格式对学习类别不同的算法的影响，并突出了因果结构学习中的未解问题和未来研究方向。 |
| [^96] | [Generative Steganography Diffusion.](http://arxiv.org/abs/2305.03472) | 提出了一种称为“生成式隐写扩散”（GSD）的新型生成式隐写方案，利用一种反演扩散模型可以100％地恢复隐藏的秘密数据，并实现了高质量的隐写图像生成。 |
| [^97] | [Learning solution of nonlinear constitutive material models using physics-informed neural networks: COMM-PINN.](http://arxiv.org/abs/2304.06044) | 通过物理训练的神经网络可解决非线性材料行为的本构关系，无需初始数据，避免重复的牛顿迭代。训练好的模型可作为有限元程序的用户定义材料模型，但需要解决诸多挑战。 |
| [^98] | [Text-to-Image Diffusion Models are Zero-Shot Classifiers.](http://arxiv.org/abs/2303.15233) | 文本到图像扩散模型被提出用于零样本分类器，具有竞争性的零样本图像分类表现和先进的形状/纹理偏差测试结果，能够成功执行属性绑定。 |
| [^99] | [TSMixer: An all-MLP Architecture for Time Series Forecasting.](http://arxiv.org/abs/2303.06053) | TSMixer是一种通过堆叠多层感知器（MLP）设计的新型结构，基于沿时间和特征维度的混合操作，能够在时间序列预测中表现出极好的性能。 |
| [^100] | [ChatGPT Is on the Horizon: Could a Large Language Model Be All We Need for Intelligent Transportation?.](http://arxiv.org/abs/2303.05382) | 本文探讨了ChatGPT在解决交通问题方面的应用。通过利用具有跨模态编码器的LLM，可以处理来自不同模态的交通数据并执行交通运营。作者提供了一个基于智能手机的碰撞报告自动生成和分析框架作为用例展示了这种潜力。 |
| [^101] | [Dynamic Graph Convolutional Network with Attention Fusion for Traffic Flow Prediction.](http://arxiv.org/abs/2302.12598) | 提出了一种用于交通流量预测的具有注意融合的动态图卷积网络，通过增强时间特征维度的交互作用和捕捉多尺度空间-时间依赖关系，以及有效捕捉远距离、多方面领域的空间-时间模式，实现精确且实时的交通状态预测。 |
| [^102] | [An Empirical Evaluation of Using Large Language Models for Automated Unit Test Generation.](http://arxiv.org/abs/2302.06527) | 本研究通过大规模实证评估证明，无需额外训练或手动努力，利用大型语言模型（LLMs）自动化生成单元测试是有效的。实验结果表明LLMs结合函数的签名、实现和文档中的使用示例可以成功生成单元测试，并通过重新提示模型来修复生成失败的测试。 |
| [^103] | [Mixed formulation of physics-informed neural networks for thermo-mechanically coupled systems and heterogeneous domains.](http://arxiv.org/abs/2302.04954) | 本文提出了将混合形式应用于解决多物理问题，特别是稳态热力学耦合方程组的物理信息神经网络方法。 |
| [^104] | [Fake detection in imbalance dataset by Semi-supervised learning with GAN.](http://arxiv.org/abs/2212.01071) | 本文提出了一种在不平衡数据集中使用半监督学习和生成对抗网络进行虚假检测的方法，实验证明仅使用100个标记样本的情况下，准确率达到了91\%。 |
| [^105] | [Towards Privacy-Aware Causal Structure Learning in Federated Setting.](http://arxiv.org/abs/2211.06919) | 本文研究了在联合设置中隐私感知因果结构学习的问题，并提出了一种新的联邦PC（FedPC）算法，通过两种新策略保护数据隐私。 |
| [^106] | [Optimal Settings for Cryptocurrency Trading Pairs.](http://arxiv.org/abs/2210.10971) | 本文研究了加密货币交易对的最优设置问题，并提出了一个两阶段过程来解决这个优化问题。该问题的特殊之处在于大部分可能的交易对之间的交易量无法直接观察，且需要满足连通性约束。 |
| [^107] | [jsdp: a Java Stochastic Dynamic Programming Library.](http://arxiv.org/abs/2209.09979) | jsdp是一个Java库，通过利用Java中的lambda表达式、函数接口、集合和聚合运算符，实现了对随机动态规划问题的建模和求解。 |
| [^108] | [Unified Bayesian Frameworks for Multi-criteria Decision-making Problems.](http://arxiv.org/abs/2208.13390) | 本文引入了贝叶斯框架解决多准则决策问题，在团体决策问题和准则相关性方面提供了统计优雅的解决方案，适应了不同形式的决策者偏好，开发了识别决策者子群的混合模型，并设计了评估准则和备选方案相对重要性的概率排序方案。 |
| [^109] | [Generative Action Description Prompts for Skeleton-based Action Recognition.](http://arxiv.org/abs/2208.05318) | 本文提出了一种基于骨骼的动作识别的生成式动作描述提示（GAP）方法，利用预训练的语言模型自动生成动作的身体部位运动的文本描述，并采用多模态训练方案。 |
| [^110] | [An Experimental Evaluation of Machine Learning Training on a Real Processing-in-Memory System.](http://arxiv.org/abs/2207.07886) | 该研究评估了在处理内存系统上训练机器学习算法的潜能，并证明基于PIM的ML训练实现了显着的加速和能量效率。 |
| [^111] | [Neural-IMLS: Self-supervised Implicit Moving Least-Squares Network for Surface Reconstruction.](http://arxiv.org/abs/2109.04398) | Neural-IMLS是一种自监督的方法，能够从未定向的原始点云中学习抗噪声的有符号距离函数，实现准确的表面重建。 |
| [^112] | [Explaining the Behavior of Black-Box Prediction Algorithms with Causal Learning.](http://arxiv.org/abs/2006.02482) | 本文提出了一种用于解释黑箱预测算法行为的因果学习方法，通过学习因果图表示来提供因果解释，弥补了现有方法的缺点，即解释单元更加可解释且考虑了宏观级特征和未测量的混淆。 |

# 详细

[^1]: 我的艺术我的选择：对抗不守规矩的人工智能的保护

    My Art My Choice: Adversarial Protection Against Unruly AI. (arXiv:2309.03198v1 [cs.CV])

    [http://arxiv.org/abs/2309.03198](http://arxiv.org/abs/2309.03198)

    该论文提出了一种名为"我是我艺术的选择"（MAMC）的方法，旨在通过对抗手段保护艺术作品的版权，该方法通过生成对抗性扰动后的图像来"破解"扩散模型的功能。这种方法可以平衡内容的失真和保护，并且可以攻击黑盒扩散模型。

    

    生成式人工智能的崛起使得每个人都能通过公开可用的接口产生逼真的内容。特别是对于引导式图像生成，扩散模型通过产生高质量低成本的内容改变了创作者经济。与此同时，艺术家们正在对抗不守规矩的人工智能，因为他们的作品被大型生成模型利用、分发和伪装。我们的方法"我是我艺术的选择"（MAMC）旨在通过对抗手段保护版权材料，使内容所有者能够获得更多权力。MAMC学习生成对抗性扰动后的"受保护"版本的图像，从而"破解"扩散模型。扰动量由艺术家决定，以平衡内容的失真和保护。MAMC采用基于UNet的简单生成器，攻击黑盒扩散模型，结合多个损失函数创建原始艺术作品的对抗性双胞胎。我们在三个数据集上进行实验。

    Generative AI is on the rise, enabling everyone to produce realistic content via publicly available interfaces. Especially for guided image generation, diffusion models are changing the creator economy by producing high quality low cost content. In parallel, artists are rising against unruly AI, since their artwork are leveraged, distributed, and dissimulated by large generative models. Our approach, My Art My Choice (MAMC), aims to empower content owners by protecting their copyrighted materials from being utilized by diffusion models in an adversarial fashion. MAMC learns to generate adversarially perturbed "protected" versions of images which can in turn "break" diffusion models. The perturbation amount is decided by the artist to balance distortion vs. protection of the content. MAMC is designed with a simple UNet-based generator, attacking black box diffusion models, combining several losses to create adversarial twins of the original artwork. We experiment on three datasets for v
    
[^2]: 分割增强神经网络

    Split-Boost Neural Networks. (arXiv:2309.03167v1 [cs.LG])

    [http://arxiv.org/abs/2309.03167](http://arxiv.org/abs/2309.03167)

    这篇论文提出了一种称为分割增强的训练策略，通过自动包含正则化行为，降低了神经网络训练的复杂性和计算资源需求。

    

    神经网络的校准和训练是一个复杂且耗时的过程，需要大量的计算资源才能达到令人满意的结果。关键障碍是需要选择大量的超参数，并且在数据量较少的情况下容易出现过拟合。在这个框架中，我们提出了一种创新的前馈架构训练策略，称为分割增强（split-boost），它能够提高性能并自动包含一种正则化行为，而无需显式地建模。这种新颖的方法最终使我们能够避免显式建模正则化项，减少总的超参数数量并加速调优阶段。该策略在一个匿名的现实世界数据集上进行了测试，应用于基准医疗保险设计问题。

    The calibration and training of a neural network is a complex and time-consuming procedure that requires significant computational resources to achieve satisfactory results. Key obstacles are a large number of hyperparameters to select and the onset of overfitting in the face of a small amount of data. In this framework, we propose an innovative training strategy for feed-forward architectures - called split-boost - that improves performance and automatically includes a regularizing behaviour without modeling it explicitly. Such a novel approach ultimately allows us to avoid explicitly modeling the regularization term, decreasing the total number of hyperparameters and speeding up the tuning phase. The proposed strategy is tested on a real-world (anonymized) dataset within a benchmark medical insurance design problem.
    
[^3]: J-Guard：新闻指导的对抗鲁棒AI生成新闻检测

    J-Guard: Journalism Guided Adversarially Robust Detection of AI-generated News. (arXiv:2309.03164v1 [cs.CL])

    [http://arxiv.org/abs/2309.03164](http://arxiv.org/abs/2309.03164)

    J-Guard是一个能够在AI生成新闻中检测AI生成文本的框架，通过引入新闻属性和提高对抗鲁棒性，解决了现有方法的不可靠性和误报问题。

    

    AI生成文本在网络上的迅速扩张正在深刻地改变信息格局。在各种类型的AI生成文本中，AI生成新闻作为一种显著的来源，对网络上的误导信息构成了重大威胁。虽然最近有一些努力致力于对AI生成文本的检测，但考虑到其面临的简单对抗攻击的易受攻击性，这些方法需要更高的可靠性。此外，由于新闻写作的特异性，将这些检测方法应用于AI生成新闻可能会产生误报，潜在地破坏新闻机构的声誉。为解决这些挑战，我们利用一个跨学科团队的专门知识来开发一个名为J-Guard的框架，该框架可以引导现有的基于监督的AI文本检测器以检测AI生成新闻，并提升对抗鲁棒性。通过引入受独特新闻属性启发的文体暗示，J-Guard能有效抵制对抗攻击并降低误报率。

    The rapid proliferation of AI-generated text online is profoundly reshaping the information landscape. Among various types of AI-generated text, AI-generated news presents a significant threat as it can be a prominent source of misinformation online. While several recent efforts have focused on detecting AI-generated text in general, these methods require enhanced reliability, given concerns about their vulnerability to simple adversarial attacks. Furthermore, due to the eccentricities of news writing, applying these detection methods for AI-generated news can produce false positives, potentially damaging the reputation of news organizations. To address these challenges, we leverage the expertise of an interdisciplinary team to develop a framework, J-Guard, capable of steering existing supervised AI text detectors for detecting AI-generated news while boosting adversarial robustness. By incorporating stylistic cues inspired by the unique journalistic attributes, J-Guard effectively dis
    
[^4]: 风险降低设计和运营工具包: 管理决策问题中的风险和不确定性的90种策略

    Risk-reducing design and operations toolkit: 90 strategies for managing risk and uncertainty in decision problems. (arXiv:2309.03133v1 [q-fin.RM])

    [http://arxiv.org/abs/2309.03133](http://arxiv.org/abs/2309.03133)

    该论文研究了风险降低设计和运营工具包（RDOT）中的90种策略，这些策略可在高度不确定的决策问题中提供有效的响应。这些策略包括将稳健性纳入设计、事后预防措施等，能够帮助工程师、公共规划者和其他决策者应对挑战。

    

    不确定性是决策分析中普遍存在的挑战，决策理论承认两类解决方案: 概率模型和认知启发式。然而，工程师、公共规划者和其他决策者使用的是另一类被称为RDOT（风险降低设计和运营工具包）的策略。这些策略包括将稳健性纳入设计、事后预防措施等，并不属于概率模型或认知启发式的类别。此外，相同的策略出现在多个领域和学科中，指向了一个重要的共享工具包。本文的重点是开发这些策略的目录并为其开发一个框架。本文发现了超过90个属于六个广泛类别的这样的策略，并认为它们对于由于高度不确定性而似乎棘手的决策问题提供了高效的响应。然后，本文提出了一个将它们纳入决策模型的框架。

    Uncertainty is a pervasive challenge in decision analysis, and decision theory recognizes two classes of solutions: probabilistic models and cognitive heuristics. However, engineers, public planners and other decision-makers instead use a third class of strategies that could be called RDOT (Risk-reducing Design and Operations Toolkit). These include incorporating robustness into designs, contingency planning, and others that do not fall into the categories of probabilistic models or cognitive heuristics. Moreover, identical strategies appear in several domains and disciplines, pointing to an important shared toolkit.  The focus of this paper is to develop a catalog of such strategies and develop a framework for them. The paper finds more than 90 examples of such strategies falling into six broad categories and argues that they provide an efficient response to decision problems that are seemingly intractable due to high uncertainty. It then proposes a framework to incorporate them into 
    
[^5]: MyoDex：灵巧操作的通用先验

    MyoDex: A Generalizable Prior for Dexterous Manipulation. (arXiv:2309.03130v1 [cs.RO])

    [http://arxiv.org/abs/2309.03130](http://arxiv.org/abs/2309.03130)

    本研究从人类灵巧操作的多样先前经验中汲取灵感，开发了能够利用以前的经验快速获得新行为的代理者。我们的方法利用了多任务学习来捕捉通用的行为先验（MyoDex），并使用了基于生理学的人手模型 - MyoHand。实验证明，利用MyoDex的代理者可以解决更多的任务，并且具有良好的泛化能力。

    

    人类的灵巧操作是运动控制的标志。尽管骨骼肌感觉运动回路的复杂性（多关节和多动作，由40多块肌肉控制的23个关节） ，但我们的手可以迅速合成新的行为。在这项工作中，我们受到人类灵巧操作如何建立在多样的先前经验之上的启发，而不是通过单一任务获得。受此观察的启发，我们着手开发能够利用以前的经验快速获得新的（以前无法达到的）行为的代理者。具体而言，我们的方法利用多任务学习来隐式地捕捉面向任务的行为先验（MyoDex） ，用生理实际的人手模型 - MyoHand。我们展示了MyoDex在少样本泛化和对一大批未见的灵巧操作任务的积极迁移中的有效性。利用MyoDex的代理者可以解决大约3倍的任务，4倍的...

    Human dexterity is a hallmark of motor control. Our hands can rapidly synthesize new behaviors despite the complexity (multi-articular and multi-joints, with 23 joints controlled by more than 40 muscles) of musculoskeletal sensory-motor circuits. In this work, we take inspiration from how human dexterity builds on a diversity of prior experiences, instead of being acquired through a single task. Motivated by this observation, we set out to develop agents that can build upon their previous experience to quickly acquire new (previously unattainable) behaviors. Specifically, our approach leverages multi-task learning to implicitly capture task-agnostic behavioral priors (MyoDex) for human-like dexterity, using a physiologically realistic human hand model - MyoHand. We demonstrate MyoDex's effectiveness in few-shot generalization as well as positive transfer to a large repertoire of unseen dexterous manipulation tasks. Agents leveraging MyoDex can solve approximately 3x more tasks, and 4x 
    
[^6]: 通过基于数据的机器学习在锡膏检查特征上检测PCB制造缺陷

    Detecting Manufacturing Defects in PCBs via Data-Centric Machine Learning on Solder Paste Inspection Features. (arXiv:2309.03113v1 [cs.LG])

    [http://arxiv.org/abs/2309.03113](http://arxiv.org/abs/2309.03113)

    通过利用锡膏检查特征，基于数据的机器学习方法能够在PCB制造中的三个阶段检测缺陷，提高操作效率和减少人工干预。

    

    利用锡膏检查（SPI）和自动光学检查（AOI）机器自动检测印制电路板（PCB）制造中的缺陷可以提高操作效率，显著减少人工干预的需要。本文利用从SPI提取的600万个引脚的特征，展示了一种基于数据的方法来训练机器学习（ML）模型以在PCB制造的三个阶段检测缺陷。这600万个PCB引脚对应于属于15,387个PCB的200万个组件。我们使用基于极限梯度提升（XGBoost）的ML模型，迭代数据预处理步骤以提高检测性能。通过使用组件和PCB ID组合的引脚级SPI特征，我们还开发了组件和PCB级别的训练实例。这使得ML模型能够捕捉到在引脚级别可能不明显的引脚间、组件间或空间效应。模型在引脚、组件和PCB级别进行训练。

    Automated detection of defects in Printed Circuit Board (PCB) manufacturing using Solder Paste Inspection (SPI) and Automated Optical Inspection (AOI) machines can help improve operational efficiency and significantly reduce the need for manual intervention. In this paper, using SPI-extracted features of 6 million pins, we demonstrate a data-centric approach to train Machine Learning (ML) models to detect PCB defects at three stages of PCB manufacturing. The 6 million PCB pins correspond to 2 million components that belong to 15,387 PCBs. Using a base extreme gradient boosting (XGBoost) ML model, we iterate on the data pre-processing step to improve detection performance. Combining pin-level SPI features using component and PCB IDs, we developed training instances also at the component and PCB level. This allows the ML model to capture any inter-pin, inter-component, or spatial effects that may not be apparent at the pin level. Models are trained at the pin, component, and PCB levels, 
    
[^7]: 具有非凸惩罚的稀疏加权分位数回归的平滑ADMM

    Smoothing ADMM for Sparse-Penalized Quantile Regression with Non-Convex Penalties. (arXiv:2309.03094v1 [stat.ML])

    [http://arxiv.org/abs/2309.03094](http://arxiv.org/abs/2309.03094)

    本文提出了一种适用于稀疏加权分位数回归的新型单循环平滑ADMM算法，名为SIAD，它在存在非凸和非光滑稀疏惩罚条件下能够加速收敛速度。

    

    本文研究了在非凸和非光滑稀疏惩罚条件下的分位数回归，如最小最大凹惩罚（MCP）和平滑剪切绝对偏差（SCAD）。这些问题的非光滑和非凸特性经常导致许多算法的收敛困难。虽然迭代技术如坐标下降和局部线性近似可以促进收敛，但过程通常很慢。这种缓慢的速度主要是因为需要在每一步运行这些近似技术直到完全收敛，这是我们称之为\emph{二次收敛迭代}的要求。为了加速收敛速度，我们采用了交替方向乘法（ADMM）并引入了一种新的具有递增惩罚参数的单循环平滑ADMM算法，命名为SIAD，专门用于稀疏加权分位数回归。我们首先深入研究了所提出的SIAD算法的收敛性质和估计。

    This paper investigates quantile regression in the presence of non-convex and non-smooth sparse penalties, such as the minimax concave penalty (MCP) and smoothly clipped absolute deviation (SCAD). The non-smooth and non-convex nature of these problems often leads to convergence difficulties for many algorithms. While iterative techniques like coordinate descent and local linear approximation can facilitate convergence, the process is often slow. This sluggish pace is primarily due to the need to run these approximation techniques until full convergence at each step, a requirement we term as a \emph{secondary convergence iteration}. To accelerate the convergence speed, we employ the alternating direction method of multipliers (ADMM) and introduce a novel single-loop smoothing ADMM algorithm with an increasing penalty parameter, named SIAD, specifically tailored for sparse-penalized quantile regression. We first delve into the convergence properties of the proposed SIAD algorithm and est
    
[^8]: 在循环有向图中建立马尔可夫等价关系

    Establishing Markov Equivalence in Cyclic Directed Graphs. (arXiv:2309.03092v1 [cs.AI])

    [http://arxiv.org/abs/2309.03092](http://arxiv.org/abs/2309.03092)

    本论文提出了一种在循环有向图中建立马尔可夫等价关系的新方法，该方法不再需要对d-分离进行测试，大大减小了算法的复杂性，并且在存在潜在混淆因素的情况下具有重要的理论研究价值。

    

    我们提出了一种新的高效的方法来在可能包含循环的有向图上建立马尔可夫等价关系，该方法基于Thomas Richardson在90年代中期关于循环模型的开创性工作中的循环等价定理(CET)，但是现在从一个祖先的角度重新表述。得到的特征导致了一种建立马尔可夫等价关系的过程，不再需要对d-分离进行测试，从而大大减小了算法的复杂性。这种概念上简化的特征可能有助于在存在潜在混淆因素的情况下重新激发对循环发现的理论研究的兴趣。该版本包括了定理1中规则(iv)的修正，以及算法2第2部分的相关调整。

    We present a new, efficient procedure to establish Markov equivalence between directed graphs that may or may not contain cycles under the \textit{d}-separation criterion. It is based on the Cyclic Equivalence Theorem (CET) in the seminal works on cyclic models by Thomas Richardson in the mid '90s, but now rephrased from an ancestral perspective. The resulting characterization leads to a procedure for establishing Markov equivalence between graphs that no longer requires tests for d-separation, leading to a significantly reduced algorithmic complexity. The conceptually simplified characterization may help to reinvigorate theoretical research towards sound and complete cyclic discovery in the presence of latent confounders. This version includes a correction to rule (iv) in Theorem 1, and the subsequent adjustment in part 2 of Algorithm 2.
    
[^9]: 未经反思的接受 —— 对ChatGPT辅助物理教育中负面后果的调查

    Unreflected Acceptance -- Investigating the Negative Consequences of ChatGPT-Assisted Problem Solving in Physics Education. (arXiv:2309.03087v1 [physics.ed-ph])

    [http://arxiv.org/abs/2309.03087](http://arxiv.org/abs/2309.03087)

    在高等物理教育中，研究发现使用ChatGPT辅助问题解决的学生往往过于依赖模型，导致近一半的解答被错误地认为是正确的。

    

    大型语言模型（LLMs）近来越来越受欢迎。然而，这些模型通过ChatGPT在教育等敏感领域的普遍可用性对于已有的教育方法的社会影响尚不清楚。尽管如此，学生和教育者已经在已有的教育方法方面体验到了社会影响。我们的工作侧重于高等物理教育，并研究问题解决策略。在一项研究中，具有物理背景的学生被分配解决物理习题，其中一个组有使用互联网搜索引擎的权利（N=12），而另一个组允许使用ChatGPT（N=27）。我们评估了他们的表现、策略和与提供的工具的互动。我们的结果显示，几乎一半的通过ChatGPT支持提供的解答被学生错误地认为是正确的，这表明他们过分信任ChatGPT，即使在他们的专业领域内也是如此。同样地，在42%的情况下，学生使用了复制粘贴来进行查询操作。

    Large language models (LLMs) have recently gained popularity. However, the impact of their general availability through ChatGPT on sensitive areas of everyday life, such as education, remains unclear. Nevertheless, the societal impact on established educational methods is already being experienced by both students and educators. Our work focuses on higher physics education and examines problem solving strategies. In a study, students with a background in physics were assigned to solve physics exercises, with one group having access to an internet search engine (N=12) and the other group being allowed to use ChatGPT (N=27). We evaluated their performance, strategies, and interaction with the provided tools. Our results showed that nearly half of the solutions provided with the support of ChatGPT were mistakenly assumed to be correct by the students, indicating that they overly trusted ChatGPT even in their field of expertise. Likewise, in 42% of cases, students used copy & paste to quer
    
[^10]: 纯蒙特卡洛反事实遗憾最小化

    Pure Monte Carlo Counterfactual Regret Minimization. (arXiv:2309.03084v1 [cs.AI])

    [http://arxiv.org/abs/2309.03084](http://arxiv.org/abs/2309.03084)

    纯蒙特卡洛反事实遗憾最小化算法（PCFR）是一种结合了反事实遗憾最小化（CFR）和虚拟游戏（FP）概念的新算法，能够与各种CFR变体相结合，包括蒙特卡洛CFR（MCCFR）。PCFR具有更好的性能和较快的收敛速度，同时降低了时间和空间复杂度。

    

    反事实遗憾最小化（CFR）及其变体是目前解决大规模不完全信息博弈的最佳算法。本文在CFR的基础上提出了一种名为纯CFR（PCFR）的新算法，以实现更好的性能。PCFR可以看作是CFR和虚拟游戏（FP）的结合，继承了CFR的反事实遗憾（值）的概念，并在下一次迭代中使用最佳响应策略而不是遗憾匹配策略。我们的理论证明了PCFR可以实现Blackwell可达性，使PCFR能够与包括蒙特卡洛CFR（MCCFR）在内的任何CFR变体相结合。由此产生的纯MCCFR（PMCCFR）可以大大降低时间和空间复杂度。特别地，PMCCFR的收敛速度至少比MCCFR快三倍。此外，由于PMCCFR不通过严格被支配策略的路径，我们开发了一种新的启动算法，受到了严格被支配策略的启示。

    Counterfactual Regret Minimization (CFR) and its variants are the best algorithms so far for solving large-scale incomplete information games. Building upon CFR, this paper proposes a new algorithm named Pure CFR (PCFR) for achieving better performance. PCFR can be seen as a combination of CFR and Fictitious Play (FP), inheriting the concept of counterfactual regret (value) from CFR, and using the best response strategy instead of the regret matching strategy for the next iteration. Our theoretical proof that PCFR can achieve Blackwell approachability enables PCFR's ability to combine with any CFR variant including Monte Carlo CFR (MCCFR). The resultant Pure MCCFR (PMCCFR) can significantly reduce time and space complexity. Particularly, the convergence speed of PMCCFR is at least three times more than that of MCCFR. In addition, since PMCCFR does not pass through the path of strictly dominated strategies, we developed a new warm-start algorithm inspired by the strictly dominated strat
    
[^11]: 在Twitter上对影响者内容的多模态分析

    A Multimodal Analysis of Influencer Content on Twitter. (arXiv:2309.03064v1 [cs.CL])

    [http://arxiv.org/abs/2309.03064](http://arxiv.org/abs/2309.03064)

    本研究通过引入一个新的Twitter数据集，结合文本和视觉信息，实验了多种预测模型，旨在自动检测影响者内容中的商业推广行为。

    

    影响者营销涉及一系列的策略，品牌与受欢迎的内容创作者（即影响者）合作，利用他们的影响力、信任度和对他们的受众的影响力，推广和背书产品或服务。由于影响者的粉丝在接收到真实的产品认可后更有可能购买产品，而不是明确的直接产品推广，个人观点与商业内容推广之间的界限经常模糊。这使得自动检测与影响者广告相关的监管合规违规行为（例如误导性广告或隐藏赞助）尤为困难。在这项工作中，我们（1）引入了一个新的Twitter（现在是X）数据集，其中包含15,998个影响者的帖子，分为商业和非商业类别，以协助自动检测商业影响者内容；（2）尝试了一系列结合文本和视觉信息的预测模型实验。

    Influencer marketing involves a wide range of strategies in which brands collaborate with popular content creators (i.e., influencers) to leverage their reach, trust, and impact on their audience to promote and endorse products or services. Because followers of influencers are more likely to buy a product after receiving an authentic product endorsement rather than an explicit direct product promotion, the line between personal opinions and commercial content promotion is frequently blurred. This makes automatic detection of regulatory compliance breaches related to influencer advertising (e.g., misleading advertising or hidden sponsorships) particularly difficult. In this work, we (1) introduce a new Twitter (now X) dataset consisting of 15,998 influencer posts mapped into commercial and non-commercial categories for assisting in the automatic detection of commercial influencer content; (2) experiment with an extensive set of predictive models that combine text and visual information 
    
[^12]: Hide and Seek (HaS): 一种用于保护隐私的轻量级提示隐私保护框架的研究

    Hide and Seek (HaS): A Lightweight Framework for Prompt Privacy Protection. (arXiv:2309.03057v1 [cs.CR])

    [http://arxiv.org/abs/2309.03057](http://arxiv.org/abs/2309.03057)

    本论文提出了一种名为Hide and Seek (HaS)的轻量级框架，通过训练一个小型本地模型，可以在保护用户隐私的同时，对大型语言模型返回的结果进行解匿名化。

    

    许多公司已开始提供基于大型语言模型 (LLM) 的服务，如 ChatGPT，这不可避免地引起了隐私问题，因为用户的提示暴露给了模型提供者。之前关于使用多方计算 (MPC) 进行安全推理的研究已经证明对于 LLM 应用来说不可行，因为它耗时且通信密集。虽然轻量级的匿名化技术可以通过替换或掩盖来保护提示中的私人信息，但它们无法恢复 LLM 生成的结果中替换的敏感数据。本文通过训练一个小型本地模型来解匿名化 LLM 返回的结果，从而扩展了匿名化技术的应用场景，并且计算开销最小化。我们介绍了 Hide and Seek (HaS) 框架，其中 "Hide" 和 "Seek" 分别代表其两个核心过程：隐藏私有实体以进行匿名化，寻找私有实体以进行解匿名化。为了定量评估 HaS 的性能，

    Numerous companies have started offering services based on large language models (LLM), such as ChatGPT, which inevitably raises privacy concerns as users' prompts are exposed to the model provider. Previous research on secure reasoning using multi-party computation (MPC) has proven to be impractical for LLM applications due to its time-consuming and communication-intensive nature. While lightweight anonymization techniques can protect private information in prompts through substitution or masking, they fail to recover sensitive data replaced in the LLM-generated results. In this paper, we expand the application scenarios of anonymization techniques by training a small local model to de-anonymize the LLM's returned results with minimal computational overhead. We introduce the HaS framework, where "H(ide)" and "S(eek)" represent its two core processes: hiding private entities for anonymization and seeking private entities for de-anonymization, respectively. To quantitatively assess HaS'
    
[^13]: 将预训练的视觉Transformer和CIDER结合进行域外检测

    Combining pre-trained Vision Transformers and CIDER for Out Of Domain Detection. (arXiv:2309.03047v1 [cs.CV])

    [http://arxiv.org/abs/2309.03047](http://arxiv.org/abs/2309.03047)

    本研究探讨了将预训练的Vision Transformers和CIDER方法相结合用于域外检测任务的性能。实验结果显示，预训练的Transformer模型在开箱即用的情况下表现出更高的检测性能。通过将ViT和CNN与CIDER方法结合，可以进一步提高OOD检测性能。这些结果表明Transformer是一种有前途的OOD检测方法，并为该任务设立了更强的基准。

    

    域外（OOD）检测是工业应用中的关键组成部分，它帮助识别模型遇到的超出训练分布的输入。大多数工业流程依赖于预训练模型，如CNN或Vision Transformers，用于下游任务。本文研究了这些模型在域外检测任务中的性能。我们的实验表明，预训练的Transformer模型在开箱即用的情况下实现了更高的检测性能。此外，我们还展示了将预训练的ViT和CNN与CIDER等改进方法结合起来，可以进一步提高它们的OOD检测性能。我们的结果表明，Transformer是一种有前途的OOD检测方法，并在许多情境下为这个任务建立了更强的基准。

    Out-of-domain (OOD) detection is a crucial component in industrial applications as it helps identify when a model encounters inputs that are outside the training distribution. Most industrial pipelines rely on pre-trained models for downstream tasks such as CNN or Vision Transformers. This paper investigates the performance of those models on the task of out-of-domain detection. Our experiments demonstrate that pre-trained transformers models achieve higher detection performance out of the box. Furthermore, we show that pre-trained ViT and CNNs can be combined with refinement methods such as CIDER to improve their OOD detection performance even more. Our results suggest that transformers are a promising approach for OOD detection and set a stronger baseline for this task in many contexts
    
[^14]: 驳斥Shapley Values用于可解释性的论证

    A Refutation of Shapley Values for Explainability. (arXiv:2309.03041v1 [cs.AI])

    [http://arxiv.org/abs/2309.03041](http://arxiv.org/abs/2309.03041)

    这篇论文驳斥了Shapley Values在规则解释中的适用性，并证明了存在布尔函数，使得Shapley值给出的特征重要性信息具有误导性。该论文提供了一种蛮力方法来识别这种问题，但对于特征数量较大的布尔函数仍存在问题。

    

    最近的研究证明了在基于规则的解释中，Shapley值对特征的相对重要性提供了误导性信息的布尔函数的存在。这些误导性信息被广泛分类为几个可能的问题。每个问题都涉及与预测相关的特征的相关性或无关性，并且在基于规则的解释中，所有这些问题都与Shapley值的不足有关。其中的一个研究使用了一种蛮力方法来识别仅包含少数特征和相关实例的布尔函数，展示了Shapley值不足的问题，并作为证明在规则解释中Shapley值的不足的证据。然而，一个重要的问题是这种Shapley值不足的问题在具有任意大数量特征的布尔函数中有多频繁出现。很显然，蛮力方法不太可能提供洞察如何处理具有任意大数量特征的问题的见解。

    Recent work demonstrated the existence of Boolean functions for which Shapley values provide misleading information about the relative importance of features in rule-based explanations. Such misleading information was broadly categorized into a number of possible issues. Each of those issues relates with features being relevant or irrelevant for a prediction, and all are significant regarding the inadequacy of Shapley values for rule-based explainability. This earlier work devised a brute-force approach to identify Boolean functions, defined on small numbers of features, and also associated instances, which displayed such inadequacy-revealing issues, and so served as evidence to the inadequacy of Shapley values for rule-based explainability. However, an outstanding question is how frequently such inadequacy-revealing issues can occur for Boolean functions with arbitrary large numbers of features. It is plain that a brute-force approach would be unlikely to provide insights on how to ta
    
[^15]: 基于嵌入的高效临时Deepfake位置方法用于部分伪造音频检测

    An Efficient Temporary Deepfake Location Approach Based Embeddings for Partially Spoofed Audio Detection. (arXiv:2309.03036v1 [cs.SD])

    [http://arxiv.org/abs/2309.03036](http://arxiv.org/abs/2309.03036)

    该论文提出了一种基于嵌入的临时Deepfake位置方法（TDL）用于部分伪造音频检测，通过嵌入相似性模块和时间卷积操作，能有效捕捉音频的特征和位置信息。实验结果表明，在ASVspoof2019 Partial Spoof数据集中，该方法优于基准模型。

    

    部分伪造音频检测是一项具有挑战性的任务，需要在帧级别准确地定位音频的真实性。为了解决这个问题，我们提出了一种精细化的部分伪造音频检测方法，即临时Deepfake位置（TDL），可以有效地捕捉特征和位置信息。具体而言，我们的方法包括两个新颖的部分：嵌入相似性模块和时间卷积操作。为了增强真实特征和伪造特征之间的区分度，嵌入相似性模块被设计用于生成一个嵌入空间，可以将真实帧与伪造帧分离开来。为了有效地关注位置信息，我们提出了时间卷积操作，用于计算相邻帧之间的特定帧相似性，并动态选择信息丰富的邻居进行卷积。广泛的实验表明，我们的方法在ASVspoof2019 Partial Spoof数据集中优于基准模型。

    Partially spoofed audio detection is a challenging task, lying in the need to accurately locate the authenticity of audio at the frame level. To address this issue, we propose a fine-grained partially spoofed audio detection method, namely Temporal Deepfake Location (TDL), which can effectively capture information of both features and locations. Specifically, our approach involves two novel parts: embedding similarity module and temporal convolution operation. To enhance the identification between the real and fake features, the embedding similarity module is designed to generate an embedding space that can separate the real frames from fake frames. To effectively concentrate on the position information, temporal convolution operation is proposed to calculate the frame-specific similarities among neighboring frames, and dynamically select informative neighbors to convolution. Extensive experiments show that our method outperform baseline models in ASVspoof2019 Partial Spoof dataset and
    
[^16]: 用于将知识图谱与文字嵌入的通用预处理操作符

    Universal Preprocessing Operators for Embedding Knowledge Graphs with Literals. (arXiv:2309.03023v1 [cs.AI])

    [http://arxiv.org/abs/2309.03023](http://arxiv.org/abs/2309.03023)

    本文提出了一组通用预处理操作符，用于将具有数值、时间、文本和图像信息的知识图谱转换为能够使用任何嵌入方法的形式，并在数据集上展示了有希望的结果。

    

    知识图谱嵌入是知识图谱中实体的密集数值表示。大多数方法仅关注实体之间的关系信息，较少有方法将文字描述或数值信息等知识也考虑在内。已有的方法通常针对特定的文字类型和嵌入方法。本文提出一组通用预处理操作符，可用于将带有数值、时间、文本和图像信息的知识图谱转换为能够使用任何方法进行嵌入的形式。在kgbench数据集上使用三种不同的嵌入方法进行实验，结果显示出有希望的成果。

    Knowledge graph embeddings are dense numerical representations of entities in a knowledge graph (KG). While the majority of approaches concentrate only on relational information, i.e., relations between entities, fewer approaches exist which also take information about literal values (e.g., textual descriptions or numerical information) into account. Those which exist are typically tailored towards a particular modality of literal and a particular embedding method. In this paper, we propose a set of universal preprocessing operators which can be used to transform KGs with literals for numerical, temporal, textual, and image information, so that the transformed KGs can be embedded with any method. The results on the kgbench dataset with three different embedding methods show promising results.
    
[^17]: EdgeFL：一种轻量级分散式联邦学习框架

    EdgeFL: A Lightweight Decentralized Federated Learning Framework. (arXiv:2309.02936v1 [cs.SE])

    [http://arxiv.org/abs/2309.02936](http://arxiv.org/abs/2309.02936)

    EdgeFL是一种轻量级分散式联邦学习框架，通过仅在边缘进行模型训练和汇总的方法，消除了中央服务器的需求，实现了对各种用例的无缝可扩展性，并提供了灵活的定制汇总函数的能力。

    

    联邦学习（FL）已成为一种有前景的协作机器学习方法，解决了数据隐私问题。然而，现有的FL平台和框架在软件工程师方面存在复杂性、有限的定制选项和可扩展性限制的挑战。在本文中，我们介绍了EdgeFL，一种仅在边缘部署的轻量级分散式FL框架，旨在克服集中式汇总和可伸缩性方面的限制。通过采用仅在边缘进行模型训练和汇总的方法，EdgeFL消除了需要中央服务器的需求，实现了对各种用例的无缝可扩展性。通过简单的集成过程，仅需要四行代码（LOC），软件工程师可以轻松将FL功能融入其AI产品中。此外，EdgeFL提供了灵活的定制汇总函数的能力，使工程师能够根据特定需求进行调整。根据结果，我们证明了EdgeFL在多个数据集和场景中的性能提升。

    Federated Learning (FL) has emerged as a promising approach for collaborative machine learning, addressing data privacy concerns. However, existing FL platforms and frameworks often present challenges for software engineers in terms of complexity, limited customization options, and scalability limitations. In this paper, we introduce EdgeFL, an edge-only lightweight decentralized FL framework, designed to overcome the limitations of centralized aggregation and scalability in FL deployments. By adopting an edge-only model training and aggregation approach, EdgeFL eliminates the need for a central server, enabling seamless scalability across diverse use cases. With a straightforward integration process requiring just four lines of code (LOC), software engineers can easily incorporate FL functionalities into their AI products. Furthermore, EdgeFL offers the flexibility to customize aggregation functions, empowering engineers to adapt them to specific needs. Based on the results, we demons
    
[^18]: 利用物理信息机器学习估计不规则用水需求以支持泄漏检测

    Estimating irregular water demands with physics-informed machine learning to inform leakage detection. (arXiv:2309.02935v1 [cs.LG])

    [http://arxiv.org/abs/2309.02935](http://arxiv.org/abs/2309.02935)

    本研究提出了一种利用物理信息的机器学习算法，通过分析压力数据估计未知的不规则用水需求，并通过简化泄漏检测问题实现线性化。

    

    饮用水供应网络中的漏水问题给水务公司带来了重大挑战，导致了基础设施故障、运营中断、环境风险、财产损失和经济损失。及时识别和准确定位这些泄漏对于水务公司来说至关重要，然而，泄漏检测算法的实施在实践中受到水力模型或大量训练数据要求的限制。利用物理信息的机器学习可以利用水力信息，从而避免这两个限制。在本研究中，我们提出了一种利用物理信息的机器学习算法，通过一个全连接神经网络分析压力数据，并从中估计未知的不规则用水需求，最终利用伯努利方程有效线性化泄漏检测问题。我们的算法在L-Town基准网络的数据上进行了测试，结果表明，

    Leakages in drinking water distribution networks pose significant challenges to water utilities, leading to infrastructure failure, operational disruptions, environmental hazards, property damage, and economic losses. The timely identification and accurate localisation of such leakages is paramount for utilities to mitigate these unwanted effects. However, implementation of algorithms for leakage detection is limited in practice by requirements of either hydraulic models or large amounts of training data. Physics-informed machine learning can utilise hydraulic information thereby circumventing both limitations. In this work, we present a physics-informed machine learning algorithm that analyses pressure data and therefrom estimates unknown irregular water demands via a fully connected neural network, ultimately leveraging the Bernoulli equation and effectively linearising the leakage detection problem. Our algorithm is tested on data from the L-Town benchmark network, and results indic
    
[^19]: 关于构建仇恨言论检测数据集的挑战

    On the Challenges of Building Datasets for Hate Speech Detection. (arXiv:2309.02912v1 [cs.CL])

    [http://arxiv.org/abs/2309.02912](http://arxiv.org/abs/2309.02912)

    本研究旨在分析仇恨言论检测中的问题，并提出了一种综合框架来指导未来构建仇恨言论数据集的最佳实践。

    

    仇恨言论的检测被提出为自然语言处理的一个独立应用，并采用了不同的方法来识别目标群体、获取原始数据、定义标记过程、选择检测算法以及评估所需环境下的性能。然而，与其他下游任务不同，由于任务的高度主观性，仇恨言论的数据集缺乏大规模、精心筛选、具有普适性的特点。本文通过数据为中心的视角首先分析了围绕仇恨言论检测的问题。然后，我们提出了一个综合性框架，以仇恨言论对性少数群体的特定示例为例，概括了涵盖七个方面的数据创建流程。我们认为从未来构建仇恨言论数据集的最佳实践角度出发，从业者将受益于遵循这一框架。

    Detection of hate speech has been formulated as a standalone application of NLP and different approaches have been adopted for identifying the target groups, obtaining raw data, defining the labeling process, choosing the detection algorithm, and evaluating the performance in the desired setting. However, unlike other downstream tasks, hate speech suffers from the lack of large-sized, carefully curated, generalizable datasets owing to the highly subjective nature of the task. In this paper, we first analyze the issues surrounding hate speech detection through a data-centric lens. We then outline a holistic framework to encapsulate the data creation pipeline across seven broad dimensions by taking the specific example of hate speech towards sexual minorities. We posit that practitioners would benefit from following this framework as a form of best practice when creating hate speech datasets in the future.
    
[^20]: DECODE: 基于历史数据和环境因素的数据驱动能耗预测在建筑中的应用

    DECODE: Data-driven Energy Consumption Prediction leveraging Historical Data and Environmental Factors in Buildings. (arXiv:2309.02908v1 [cs.LG])

    [http://arxiv.org/abs/2309.02908](http://arxiv.org/abs/2309.02908)

    本论文介绍了一种基于历史数据、占用模式和天气条件的LSTM模型，用于准确预测建筑能耗，该模型在预测精度上表现出卓越性能。

    

    建筑中的能耗预测在有效的能源管理中起着至关重要的作用。精确的预测对于实现优化的能耗和电网分配是必要的。本论文引入了一种基于历史能源数据、占用模式和天气条件的长短期记忆（LSTM）模型，用于预测建筑能耗。与现有的预测模型相比，LSTM模型提供了准确的短期、中期和长期能耗预测，适用于住宅和商业建筑。我们将我们的LSTM模型与线性回归、决策树和随机森林等已有的预测方法进行了比较。令人鼓舞的是，提出的LSTM模型在所有指标上表现出优越性能。它具有出色的预测精度，R2得分为0.97，最低的平均绝对误差（MAE）为0.007。我们开发的模型的另一个优点是能够实现高效的能耗。

    Energy prediction in buildings plays a crucial role in effective energy management. Precise predictions are essential for achieving optimal energy consumption and distribution within the grid. This paper introduces a Long Short-Term Memory (LSTM) model designed to forecast building energy consumption using historical energy data, occupancy patterns, and weather conditions. The LSTM model provides accurate short, medium, and long-term energy predictions for residential and commercial buildings compared to existing prediction models. We compare our LSTM model with established prediction methods, including linear regression, decision trees, and random forest. Encouragingly, the proposed LSTM model emerges as the superior performer across all metrics. It demonstrates exceptional prediction accuracy, boasting the highest R2 score of 0.97 and the most favorable mean absolute error (MAE) of 0.007. An additional advantage of our developed model is its capacity to achieve efficient energy consu
    
[^21]: 一种没有语言特定训练数据的深度自然语言推理预测器

    A deep Natural Language Inference predictor without language-specific training data. (arXiv:2309.02887v1 [cs.CL])

    [http://arxiv.org/abs/2309.02887](http://arxiv.org/abs/2309.02887)

    本文介绍了一种处理目标语言句子对之间推理关系问题的新方法，该方法不需要特定语言的训练数据集。通过利用一个通用的翻译数据集和两个预训练模型的实例，模型可以在不同任务上展现出通用性，且在多个数据集上得到了验证。

    

    本文介绍了一种处理目标语言句子对之间推理关系（NLI）问题的自然语言处理技术，无需语言特定的训练数据集。我们利用一个通用的手动翻译数据集，并利用同一个预训练模型的两个实例——第一个用于生成源语言的句子嵌入，第二个在目标语言上进行微调以模仿第一个实例。这种技术称为知识蒸馏。我们将模型在机器翻译的斯坦福NLI测试数据集、机器翻译的多类型NLI测试数据集和手动翻译的RTE3-ITA测试数据集上进行了评估。我们还在不同任务上测试了所提出的体系结构，以实证地展示NLI任务的通用性。模型在意大利本地的ABSITA数据集上的情感分析、基于方面的情感分析和主题识别任务上进行了评估。

    In this paper we present a technique of NLP to tackle the problem of inference relation (NLI) between pairs of sentences in a target language of choice without a language-specific training dataset. We exploit a generic translation dataset, manually translated, along with two instances of the same pre-trained model - the first to generate sentence embeddings for the source language, and the second fine-tuned over the target language to mimic the first. This technique is known as Knowledge Distillation. The model has been evaluated over machine translated Stanford NLI test dataset, machine translated Multi-Genre NLI test dataset, and manually translated RTE3-ITA test dataset. We also test the proposed architecture over different tasks to empirically demonstrate the generality of the NLI task. The model has been evaluated over the native Italian ABSITA dataset, on the tasks of Sentiment Analysis, Aspect-Based Sentiment Analysis, and Topic Recognition. We emphasise the generality and explo
    
[^22]: MAD: 图像配准的模态无关距离度量

    MAD: Modality Agnostic Distance Measure for Image Registration. (arXiv:2309.02875v1 [cs.CV])

    [http://arxiv.org/abs/2309.02875](http://arxiv.org/abs/2309.02875)

    MAD是一种利用随机卷积学习图像固有几何特性的深度图像距离度量方法，它能够有效解决多模态图像配准中的外观差异问题。

    

    多模态图像配准是许多医学应用中的关键预处理步骤。然而，由于不同成像模态之间复杂的强度关系，这是一个具有挑战性的任务，可能导致图像外观上的显著差异。无论是传统的还是基于深度学习的多模态图像配准的成功，都取决于选择适当的距离（或相似度）度量。特别是，深度学习配准算法在尝试对来自“未见过”模态的数据进行配准时精度不足甚至完全失败。在这项工作中，我们提出了一种名为Modality Agnostic Distance（MAD）的深度图像距离度量，它利用随机卷积来学习图像的固有几何特性，同时对大幅度外观变化具有鲁棒性。随机卷积是保持几何性质的模块，我们用它们来模拟无限数量的合成模态，在训练过程中消除了对齐配对数据的需求。

    Multi-modal image registration is a crucial pre-processing step in many medical applications. However, it is a challenging task due to the complex intensity relationships between different imaging modalities, which can result in large discrepancy in image appearance. The success of multi-modal image registration, whether it is conventional or learning based, is predicated upon the choice of an appropriate distance (or similarity) measure. Particularly, deep learning registration algorithms lack in accuracy or even fail completely when attempting to register data from an "unseen" modality. In this work, we present Modality Agnostic Distance (MAD), a deep image distance}] measure that utilises random convolutions to learn the inherent geometry of the images while being robust to large appearance changes. Random convolutions are geometry-preserving modules which we use to simulate an infinite number of synthetic modalities alleviating the need for aligned paired data during training. We c
    
[^23]: 在在线连续学习中重新思考动量知识蒸馏

    Rethinking Momentum Knowledge Distillation in Online Continual Learning. (arXiv:2309.02870v1 [cs.LG])

    [http://arxiv.org/abs/2309.02870](http://arxiv.org/abs/2309.02870)

    该论文重新思考了在线连续学习中的动量知识蒸馏问题，通过将动量知识蒸馏应用于OCL方法，提高了现有方法的准确性，并对MKD在OCL中的训练过程进行了深入分析。

    

    在线连续学习（OCL）解决了神经网络在连续的数据流上训练的问题，其中多个分类任务按顺序出现。与离线连续学习相比，在OCL中只能看到数据一次。在这种情况下，基于回放的策略取得了令人印象深刻的结果，大多数最先进的方法都严重依赖它们。尽管知识蒸馏（KD）在离线连续学习中已被广泛使用，但在OCL中仍然未充分利用其潜力。在本文中，我们在理论上分析了将KD应用于OCL中面临的挑战。我们介绍了一种直接而有效的方法，将动量知识蒸馏（MKD）应用于许多旗舰OCL方法，并展示了它在增强现有方法方面的能力。除了将现有的最先进的ImageNet100准确率提高了超过10个百分点之外，我们还阐明了MKD在OCL中的训练过程中的内部机制和影响。

    Online Continual Learning (OCL) addresses the problem of training neural networks on a continuous data stream where multiple classification tasks emerge in sequence. In contrast to offline Continual Learning, data can be seen only once in OCL. In this context, replay-based strategies have achieved impressive results and most state-of-the-art approaches are heavily depending on them. While Knowledge Distillation (KD) has been extensively used in offline Continual Learning, it remains under-exploited in OCL, despite its potential. In this paper, we theoretically analyze the challenges in applying KD to OCL. We introduce a direct yet effective methodology for applying Momentum Knowledge Distillation (MKD) to many flagship OCL methods and demonstrate its capabilities to enhance existing approaches. In addition to improving existing state-of-the-arts accuracy by more than $10\%$ points on ImageNet100, we shed light on MKD internal mechanics and impacts during training in OCL. We argue that 
    
[^24]: 通用互信息：一种辨别聚类的框架

    Generalised Mutual Information: a Framework for Discriminative Clustering. (arXiv:2309.02858v1 [stat.ML])

    [http://arxiv.org/abs/2309.02858](http://arxiv.org/abs/2309.02858)

    本文介绍了通用互信息（GEMINI）作为一种辨别聚类的框架，相比互信息（MI），GEMINI在无监督神经网络训练过程中不需要正则化，其可以选择合适的聚类数量。

    

    在过去十年中，深度聚类的最新成果主要涉及作为无监督训练神经网络的客观函数的互信息（MI），并增加了正则项。尽管正则化的质量已经被广泛讨论以进行改进，但对于MI作为聚类目标的相关性却没有得到足够的关注。本文首先强调了最大化MI并不能得到令人满意的聚类结果。我们发现库尔巴克-莱布勒散度是这一行为的主要原因。因此，我们通过改变其核心差异，引入通用互信息（GEMINI）来推广互信息：一组用于无监督神经网络训练的度量。与MI不同的是，一些GEMINI在训练时不需要正则化，因为它们在数据空间中具有几何意识的距离或核函数。最后，我们强调，GEMINI可以自动选择相关数量的聚类，这是一个有意义的特性。

    In the last decade, recent successes in deep clustering majorly involved the Mutual Information (MI) as an unsupervised objective for training neural networks with increasing regularisations. While the quality of the regularisations have been largely discussed for improvements, little attention has been dedicated to the relevance of MI as a clustering objective. In this paper, we first highlight how the maximisation of MI does not lead to satisfying clusters. We identified the Kullback-Leibler divergence as the main reason of this behaviour. Hence, we generalise the mutual information by changing its core distance, introducing the Generalised Mutual Information (GEMINI): a set of metrics for unsupervised neural network training. Unlike MI, some GEMINIs do not require regularisations when training as they are geometry-aware thanks to distances or kernels in the data space. Finally, we highlight that GEMINIs can automatically select a relevant number of clusters, a property that has been
    
[^25]: 太过个性化：在线自适应算法中特征选择的重要性

    Getting too personal(ized): The importance of feature choice in online adaptive algorithms. (arXiv:2309.02856v1 [cs.AI])

    [http://arxiv.org/abs/2309.02856](http://arxiv.org/abs/2309.02856)

    该论文讨论了在线自适应算法中特征选择的重要性。研究发现，在需要学习最佳操作时，个性化学习能够提高算法性能。然而，在其他情况下，包含不必要的学生特征可能会降低算法性能。

    

    数字教育技术具有个性化学习的潜力，可以根据学生的特点进行定制化教育，提高技术的效果。我们考虑了个性化学习是否存在成本，例如是否会延迟受益于所有学生的政策的采用。我们在使用多臂赌博机算法学习教育技术展示版本的政策时，探讨了学生特征和结果之间的关系以及算法是否意识到这些特征的问题。通过模拟实验，我们证明了在需要学习最佳操作时，包含学生特征进行个性化能够带来益处。在其他情况下，这种包含会降低赌博机算法的性能。而且，包含不必要的学生特征还有可能增加算法的计算复杂性。

    Digital educational technologies offer the potential to customize students' experiences and learn what works for which students, enhancing the technology as more students interact with it. We consider whether and when attempting to discover how to personalize has a cost, such as if the adaptation to personal information can delay the adoption of policies that benefit all students. We explore these issues in the context of using multi-armed bandit (MAB) algorithms to learn a policy for what version of an educational technology to present to each student, varying the relation between student characteristics and outcomes and also whether the algorithm is aware of these characteristics. Through simulations, we demonstrate that the inclusion of student characteristics for personalization can be beneficial when those characteristics are needed to learn the optimal action. In other scenarios, this inclusion decreases performance of the bandit algorithm. Moreover, including unneeded student ch
    
[^26]: 通过学习上下文和回复之间的模式信息促进开放领域对话生成

    Promoting Open-domain Dialogue Generation through Learning Pattern Information between Contexts and Responses. (arXiv:2309.02823v1 [cs.CL])

    [http://arxiv.org/abs/2309.02823](http://arxiv.org/abs/2309.02823)

    本文通过学习上下文和回复之间的隐式模式信息提高了开放领域对话生成模型的质量，采用了改进的预训练模型的计划采样方法，使生成的回复更加生动和信息丰富。

    

    近年来，利用深度神经网络构建开放领域对话模型已成为热门话题。然而，这些模型生成的回复存在许多问题，如缺乏上下文化和容易生成缺乏信息内容的通用回复，严重影响用户体验。因此，许多研究试图引入更多信息到对话模型中，使生成的回复更加生动和信息丰富。与它们不同，本文通过学习训练样本中上下文和回复之间的隐式模式信息来提高生成的回复质量。首先，我们基于预训练语言模型（即GPT-2）构建了一个开放领域对话模型。然后，提出了一种改进的预训练模型的计划采样方法，通过该方法，在训练阶段可以利用生成的回复来指导回复生成，同时避免暴露偏差问题。更重要的是，我们将这种方法与传统的基于最大似然估计的方法进行了比较，并表明了我们方法的优势。

    Recently, utilizing deep neural networks to build the opendomain dialogue models has become a hot topic. However, the responses generated by these models suffer from many problems such as responses not being contextualized and tend to generate generic responses that lack information content, damaging the user's experience seriously. Therefore, many studies try introducing more information into the dialogue models to make the generated responses more vivid and informative. Unlike them, this paper improves the quality of generated responses by learning the implicit pattern information between contexts and responses in the training samples. In this paper, we first build an open-domain dialogue model based on the pre-trained language model (i.e., GPT-2). And then, an improved scheduled sampling method is proposed for pre-trained models, by which the responses can be used to guide the response generation in the training phase while avoiding the exposure bias problem. More importantly, we de
    
[^27]: Roulette：一种用于深度学习分类任务的语义隐私保护的设备边缘协同推理框架

    Roulette: A Semantic Privacy-Preserving Device-Edge Collaborative Inference Framework for Deep Learning Classification Tasks. (arXiv:2309.02820v1 [cs.LG])

    [http://arxiv.org/abs/2309.02820](http://arxiv.org/abs/2309.02820)

    Roulette是一种用于深度学习分类任务的语义隐私保护的设备边缘协同推理框架，通过混淆和加噪声实现隐私保护，同时保持高准确性。

    

    在人工智能时代，深度学习分类器至关重要。设备边缘协同推理已被广泛采用作为在物联网和5G/6G网络中推广其应用的高效框架。然而，在非独立同分布数据分布和隐私泄露方面都存在精度下降问题。对于精度下降，直接使用迁移学习和分割学习成本较高，隐私问题仍然存在。对于隐私泄露，基于密码学的方法会导致巨大的开销。其他轻量级方法假设真实标签是非敏感的并且可以被公开。但是对于许多应用来说，真实标签是用户的关键敏感信息。在本文中，我们提出了一种名为Roulette的框架，它是一种面向任务的语义隐私保护的深度学习分类器的协同推理框架。除了输入数据，我们将数据的真实标签视为私密信息。我们开发了一种新颖的方法，通过混淆和加噪声来实现隐私保护，并通过推理结果的概率模型来保持高准确性。

    Deep learning classifiers are crucial in the age of artificial intelligence. The device-edge-based collaborative inference has been widely adopted as an efficient framework for promoting its applications in IoT and 5G/6G networks. However, it suffers from accuracy degradation under non-i.i.d. data distribution and privacy disclosure. For accuracy degradation, direct use of transfer learning and split learning is high cost and privacy issues remain. For privacy disclosure, cryptography-based approaches lead to a huge overhead. Other lightweight methods assume that the ground truth is non-sensitive and can be exposed. But for many applications, the ground truth is the user's crucial privacy-sensitive information. In this paper, we propose a framework of Roulette, which is a task-oriented semantic privacy-preserving collaborative inference framework for deep learning classifiers. More than input data, we treat the ground truth of the data as private information. We develop a novel paradig
    
[^28]: 结合离心压缩机的热力学模型和主动机器学习的增强工业设计优化

    Combining Thermodynamics-based Model of the Centrifugal Compressors and Active Machine Learning for Enhanced Industrial Design Optimization. (arXiv:2309.02818v1 [cs.LG])

    [http://arxiv.org/abs/2309.02818](http://arxiv.org/abs/2309.02818)

    结合离心压缩机的热力学模型和主动机器学习，提出了Active-CompDesign框架用于离心压缩机的优化设计。在离线和在线环境中进行实验，显示出显著的性能提升。

    

    离心压缩机的设计过程需要应用一个优化过程，由于该过程下面的分析方程，计算开销较大。虽然回归替代模型可以大幅减少这个过程的计算开销，主要挑战是缺乏用于训练替代模型的数据。为了战略性地利用标记样本，我们提出了Active-CompDesign框架，其中在可部署的主动学习（AL）环境中将基于热力学的压缩机模型（即我们内部的压缩机设计软件）与基于高斯过程的替代模型结合起来。我们首先在离线设置中进行实验，并进一步将其扩展到在线AL框架，其中与基于热力学的压缩机模型的实时交互允许在生产中部署。ActiveCompDesign在替代建模方面显示出显著的性能提升。

    The design process of centrifugal compressors requires applying an optimization process which is computationally expensive due to complex analytical equations underlying the compressor's dynamical equations. Although the regression surrogate models could drastically reduce the computational cost of such a process, the major challenge is the scarcity of data for training the surrogate model. Aiming to strategically exploit the labeled samples, we propose the Active-CompDesign framework in which we combine a thermodynamics-based compressor model (i.e., our internal software for compressor design) and Gaussian Process-based surrogate model within a deployable Active Learning (AL) setting. We first conduct experiments in an offline setting and further, extend it to an online AL framework where a real-time interaction with the thermodynamics-based compressor's model allows the deployment in production. ActiveCompDesign shows a significant performance improvement in surrogate modeling by lev
    
[^29]: 连续状态动作空间的几乎连续时间强化学习

    Near-continuous time Reinforcement Learning for continuous state-action spaces. (arXiv:2309.02815v1 [cs.AI])

    [http://arxiv.org/abs/2309.02815](http://arxiv.org/abs/2309.02815)

    本文提出了一种几乎连续时间的强化学习方法，用于控制连续状态动作空间中的未知动力系统，在单个轨迹上最大化长期平均奖励，并通过使用泊松时钟对交互时间进行建模，从离散到连续时间捕捉任意时间尺度。

    

    本文研究控制未知动力系统以在单个轨迹上最大化长期平均奖励的强化学习问题。大多数文献考虑的是在离散时间和离散状态-动作空间中发生的系统交互。尽管这种观点适用于游戏，但对于交互频率高（如果不是连续时间）且状态空间大（如果不是固有连续的）的机械或数字系统来说，通常是不够的。也许唯一的例外是线性二次框架，它在离散和连续时间中都有结果。然而，它处理连续状态的能力带来了动态和奖励结构的刚性缺点。本文旨在通过使用频率为ε的泊松时钟对建模交互时间，从离散（ε=1）到连续时间（ε↓0）捕捉任意时间尺度，克服这些缺点。

    We consider the Reinforcement Learning problem of controlling an unknown dynamical system to maximise the long-term average reward along a single trajectory. Most of the literature considers system interactions that occur in discrete time and discrete state-action spaces. Although this standpoint is suitable for games, it is often inadequate for mechanical or digital systems in which interactions occur at a high frequency, if not in continuous time, and whose state spaces are large if not inherently continuous. Perhaps the only exception is the Linear Quadratic framework for which results exist both in discrete and continuous time. However, its ability to handle continuous states comes with the drawback of a rigid dynamic and reward structure. This work aims to overcome these shortcomings by modelling interaction times with a Poisson clock of frequency $\varepsilon^{-1}$, which captures arbitrary time scales: from discrete ($\varepsilon=1$) to continuous time ($\varepsilon\downarrow0$)
    
[^30]: Norm调整：大型语言模型的高性能低比特量化

    Norm Tweaking: High-performance Low-bit Quantization of Large Language Models. (arXiv:2309.02784v1 [cs.LG])

    [http://arxiv.org/abs/2309.02784](http://arxiv.org/abs/2309.02784)

    本文介绍了一种称为“norm tweaking”的技术，通过调整量化的激活分布来实现高精度的低比特量化，以提高大型语言模型的压缩性能。

    

    随着大型语言模型（LLMs）的尺寸不断增大，在保持精度的前提下进行模型压缩已成为部署的关键挑战。虽然一些量化方法，如GPTQ，在实现可接受的4比特权重量化方面取得了进展，但尝试更低位的量化往往导致严重的性能降低。在本文中，我们引入了一种称为“norm tweaking”的技术，它可以作为当前PTQ方法的插件，实现高精度和成本高效。我们的方法受到一项观察的启示，即使调整量化的激活分布以与其浮点对应物匹配，也可以恢复LLMs的准确性。为了实现这一点，我们精心设计了一个调整策略，包括生成校准数据和通道距离约束，以更新归一化层的权重以获得更好的泛化性能。我们在各种数据集上进行了大量实验，使用了几个开源的LLMs。

    As the size of large language models (LLMs) continues to grow, model compression without sacrificing accuracy has become a crucial challenge for deployment. While some quantization methods, such as GPTQ, have made progress in achieving acceptable 4-bit weight-only quantization, attempts at lower bit quantization often result in severe performance degradation. In this paper, we introduce a technique called norm tweaking, which can be used as a plugin in current PTQ methods to achieve high precision while being cost-efficient. Our approach is inspired by the observation that rectifying the quantized activation distribution to match its float counterpart can readily restore accuracy for LLMs. To achieve this, we carefully design a tweaking strategy that includes calibration data generation and channel-wise distance constraint to update the weights of normalization layers for better generalization. We conduct extensive experiments on various datasets using several open-sourced LLMs. Our me
    
[^31]: 使用视觉变换器提高肺癌的诊断和预后：一项范围审查

    Improving diagnosis and prognosis of lung cancer using vision transformers: A scoping review. (arXiv:2309.02783v1 [eess.IV])

    [http://arxiv.org/abs/2309.02783](http://arxiv.org/abs/2309.02783)

    这项范围审查总结了最近基于视觉变换器的人工智能方法在肺癌成像应用方面的发展，重点探讨了如何改善肺癌的诊断和预后，以及相关数据集的贡献。

    

    基于视觉变换器的方法在医学人工智能和癌症成像领域取得了进展，包括肺癌应用。最近，许多研究人员开发了基于视觉变换器的人工智能方法来诊断和预测肺癌。本范围审查旨在确定基于视觉变换器的人工智能方法在肺癌成像应用方面的最新发展。它提供了关于如何将视觉变换器与人工智能和深度学习方法相结合来提高肺癌性能的关键见解。此外，该审查还确定了促进该领域发展的数据集。在检索到的314项研究中，本审查包括了从2020年到2022年发表的34项研究。这些研究中最常见的任务是对肺癌类型进行分类，如肺鳞状细胞癌与肺腺癌，并鉴别良性与恶性肺结节。其他应用包括肺癌的生存预测。

    Vision transformer-based methods are advancing the field of medical artificial intelligence and cancer imaging, including lung cancer applications. Recently, many researchers have developed vision transformer-based AI methods for lung cancer diagnosis and prognosis. This scoping review aims to identify the recent developments on vision transformer-based AI methods for lung cancer imaging applications. It provides key insights into how vision transformers complemented the performance of AI and deep learning methods for lung cancer. Furthermore, the review also identifies the datasets that contributed to advancing the field. Of the 314 retrieved studies, this review included 34 studies published from 2020 to 2022. The most commonly addressed task in these studies was the classification of lung cancer types, such as lung squamous cell carcinoma versus lung adenocarcinoma, and identifying benign versus malignant pulmonary nodules. Other applications included survival prediction of lung can
    
[^32]: SWAP:利用次级logits对时间序列进行对抗攻击

    SWAP: Exploiting Second-Ranked Logits for Adversarial Attacks on Time Series. (arXiv:2309.02752v1 [cs.LG])

    [http://arxiv.org/abs/2309.02752](http://arxiv.org/abs/2309.02752)

    该论文提出了一种针对时间序列的新的对抗攻击方法SWAP，通过提高次级logits的置信度，同时最小化对其他logits的干扰来实现攻击。实验证明，该方法在ASR上取得了最先进的性能。

    

    时间序列分类（TSC）已成为各个领域中的一个重要任务，在TSC任务中，深度神经模型显示出优越的性能。然而，这些模型容易受到对抗攻击的影响，微小的扰动可以显著影响预测结果。现有的对抗方法经常面临着超参数化或随机logit扰动的问题，从而影响其效果。此外，提高攻击成功率（ASR）通常需要生成更多的噪声，使得攻击更容易被检测出来。为了解决这些问题，我们提出了一种新的针对TSC模型的攻击方法SWAP。SWAP主要关注提高次级logits的置信度，同时最小化对其他logits的干扰。这是通过最小化目标logit分布和预测logit分布之间的Kullback-Leibler散度来实现的。实验结果表明，SWAP取得了最先进的性能，ASR达到了...

    Time series classification (TSC) has emerged as a critical task in various domains, and deep neural models have shown superior performance in TSC tasks. However, these models are vulnerable to adversarial attacks, where subtle perturbations can significantly impact the prediction results. Existing adversarial methods often suffer from over-parameterization or random logit perturbation, hindering their effectiveness. Additionally, increasing the attack success rate (ASR) typically involves generating more noise, making the attack more easily detectable. To address these limitations, we propose SWAP, a novel attacking method for TSC models. SWAP focuses on enhancing the confidence of the second-ranked logits while minimizing the manipulation of other logits. This is achieved by minimizing the Kullback-Leibler divergence between the target logit distribution and the predictive logit distribution. Experimental results demonstrate that SWAP achieves state-of-the-art performance, with an ASR
    
[^33]: MLN-net：一种利用多层归一化进行集群微钙化的多源医学图像分割方法

    MLN-net: A multi-source medical image segmentation method for clustered microcalcifications using multiple layer normalization. (arXiv:2309.02742v1 [cs.CV])

    [http://arxiv.org/abs/2309.02742](http://arxiv.org/abs/2309.02742)

    提出了一种名为MLN-net的新型框架，用于集群微钙化的准确分割。该方法能够使用单一源图像来准确地分割多源图像，通过多层归一化层结构来处理不同领域的图像分割，进而提高了泛化性能。

    

    针对乳腺X线摄影中集群微钙化的准确分割对于乳腺癌的诊断和治疗至关重要。尽管近期深度学习在医学图像分割方面取得了专家级准确性，但由于患者体位、个体腺体密度和乳腺X线摄影成像模式等方面的差异造成了领域转移，导致在实际应用中贡献有限。本文提出了一种名为MLN-net的新型框架，仅使用单一源图像即可准确地分割多源图像，用于集群微钙化分割。首先，我们提出了一种源域图像增强方法来生成多源图像，从而提高泛化性能。其次，采用了多层归一化（LN）层的结构来构建分割网络，在不同领域中对于集群微钙化分割具有良好效果。此外，还提出了一种支路选择策略来优化分割性能。

    Accurate segmentation of clustered microcalcifications in mammography is crucial for the diagnosis and treatment of breast cancer. Despite exhibiting expert-level accuracy, recent deep learning advancements in medical image segmentation provide insufficient contribution to practical applications, due to the domain shift resulting from differences in patient postures, individual gland density, and imaging modalities of mammography etc. In this paper, a novel framework named MLN-net, which can accurately segment multi-source images using only single source images, is proposed for clustered microcalcification segmentation. We first propose a source domain image augmentation method to generate multi-source images, leading to improved generalization. And a structure of multiple layer normalization (LN) layers is used to construct the segmentation network, which can be found efficient for clustered microcalcification segmentation in different domains. Additionally, a branch selection strateg
    
[^34]: 用细分标准特定方法进行增强培训的自动化作文评分

    Rubric-Specific Approach to Automated Essay Scoring with Augmentation Training. (arXiv:2309.02740v1 [cs.CL])

    [http://arxiv.org/abs/2309.02740](http://arxiv.org/abs/2309.02740)

    本文提出一种用于自动评分的细分标准特定方法，通过增强培训和测试数据来学习之前研究中忽视的特征和功能，达到了最新性能。

    

    相比于传统的基于规则和特征工程的解决方案，基于神经网络的主观答案自动评估方法表现出更优异的性能和效率。然而，最近的研究并没有妥善考虑到在模型训练和验证过程中对于自动化作文评分至关重要的细分标准。在本文中，我们提出了一系列数据增强操作，通过训练和测试一个自动评分模型，学习了之前研究中忽视的特征和功能，同时在自动化学生评估奖数据集中取得了最新的性能。

    Neural based approaches to automatic evaluation of subjective responses have shown superior performance and efficiency compared to traditional rule-based and feature engineering oriented solutions. However, it remains unclear whether the suggested neural solutions are sufficient replacements of human raters as we find recent works do not properly account for rubric items that are essential for automated essay scoring during model training and validation. In this paper, we propose a series of data augmentation operations that train and test an automated scoring model to learn features and functions overlooked by previous works while still achieving state-of-the-art performance in the Automated Student Assessment Prize dataset.
    
[^35]: HC3 Plus：一个语义不变的人类ChatGPT对比语料库

    HC3 Plus: A Semantic-Invariant Human ChatGPT Comparison Corpus. (arXiv:2309.02731v1 [cs.CL])

    [http://arxiv.org/abs/2309.02731](http://arxiv.org/abs/2309.02731)

    本文介绍了HC3 Plus，一个语义不变的人类ChatGPT对比语料库。与以往的工作相比，该语料库考虑了更多类型的任务，包括语义不变任务。研究发现，在语义不变任务中检测模型生成的文本更加困难。通过大量任务指令微调和Tk-instruct，建立了一个更强大的模型。

    

    ChatGPT因其出色的性能而引起了人们的广泛关注，但人们对其潜在风险，尤其是对AI生成内容（AIGC）的检测越来越关注，这对未经训练的人类来说往往很难识别。目前用于检测ChatGPT生成文本的数据集主要集中在问答方面，但往往忽视了具有语义不变性的任务，如摘要、翻译和改写。我们的研究表明，在语义不变任务上检测模型生成的文本更加困难。为了填补这一空白，我们引入了一个更广泛、更全面的数据集，考虑了比以前的工作更多类型的任务，包括语义不变任务。此外，经过大量任务指令微调的模型表现出很强的性能。基于以前的成功，我们进一步指导微调了Tk-instruct，并构建了一个更强大的模型。

    ChatGPT has gained significant interest due to its impressive performance, but people are increasingly concerned about its potential risks, particularly around the detection of AI-generated content (AIGC), which is often difficult for untrained humans to identify. Current datasets utilized for detecting ChatGPT-generated text primarily center around question-answering, yet they tend to disregard tasks that possess semantic-invariant properties, such as summarization, translation, and paraphrasing. Our primary studies demonstrate that detecting model-generated text on semantic-invariant tasks is more difficult. To fill this gap, we introduce a more extensive and comprehensive dataset that considers more types of tasks than previous work, including semantic-invariant tasks. In addition, the model after a large number of task instruction fine-tuning shows a strong powerful performance. Owing to its previous success, we further instruct fine-tuning Tk-instruct and built a more powerful det
    
[^36]: Stylebook: 在只使用语音数据的任意-任意语音转换中进行依赖内容的说话风格建模

    Stylebook: Content-Dependent Speaking Style Modeling for Any-to-Any Voice Conversion using Only Speech Data. (arXiv:2309.02730v1 [eess.AS])

    [http://arxiv.org/abs/2309.02730](http://arxiv.org/abs/2309.02730)

    这项工作提出了一种新的方法，即 Stylebook，它通过使用自监督学习模型从目标语音中提取丰富的风格信息，并将其高效地转移到源语音内容上，无需文本转录或说话者标记。该方法引入了注意力机制和样式手册，可以实现目标说话者的忠实复制和风格转移。

    

    尽管许多最近的任意-任意语音转换模型成功地将一些目标语音的风格信息转移到转换的语音中，但它们仍然缺乏忠实地复制目标说话者的说话风格的能力。在这项工作中，我们提出了一种新的方法，从目标语音中提取丰富的风格信息，并将其高效地转移到源语音内容上，而无需文本转录或说话者标记。我们提出的方法引入了一个注意力机制，利用自监督学习（SSL）模型收集与不同音素内容相对应的目标说话者的说话风格。这些风格用一组称为样式手册的嵌入表示。在下一步中，样式手册与源语音的音素内容一起参与，以确定每个源内容的最终目标风格。最后，从源语音中提取的内容信息和依赖内容的目标风格嵌入被输入到一个...

    While many recent any-to-any voice conversion models succeed in transferring some target speech's style information to the converted speech, they still lack the ability to faithfully reproduce the speaking style of the target speaker. In this work, we propose a novel method to extract rich style information from target utterances and to efficiently transfer it to source speech content without requiring text transcriptions or speaker labeling. Our proposed approach introduces an attention mechanism utilizing a self-supervised learning (SSL) model to collect the speaking styles of a target speaker each corresponding to the different phonetic content. The styles are represented with a set of embeddings called stylebook. In the next step, the stylebook is attended with the source speech's phonetic content to determine the final target style for each source content. Finally, content information extracted from the source speech and content-dependent target style embeddings are fed into a dif
    
[^37]: 用于自动开放领域科学假设发现的大语言模型

    Large Language Models for Automated Open-domain Scientific Hypotheses Discovery. (arXiv:2309.02726v1 [cs.CL])

    [http://arxiv.org/abs/2309.02726](http://arxiv.org/abs/2309.02726)

    这项研究提出了用于社会科学学术假设发现的第一个自然语言处理数据集，旨在开发一个系统，能够基于原始网络语料库自动生成有效、新颖且对人类研究者有帮助的假设。

    

    当科学家观察世界并试图提出解释这些观察结果的假设时，假设归纳被认为是主要的推理类型。过去关于假设归纳的研究存在以下限制：（1）数据集的观察注释不是原始的网络语料库，而是手动选择的句子（导致了一个封闭领域的设置）；（2）实际的假设注释主要是常识知识，使得任务不太具有挑战性。在本文中，我们提出了第一个用于社会科学学术假设发现的自然语言处理数据集，包含50篇发表在顶级社会科学期刊上的最新论文。数据集中还收集了开发论文中的假设所需的原始网络语料库，最终目标是创建一个系统，仅通过一堆原始网络语料库就可以自动生成有效、新颖且对人类研究者有帮助的假设。这个新数据集可以解决以前关于假设归纳的研究所面临的限制问题。

    Hypothetical induction is recognized as the main reasoning type when scientists make observations about the world and try to propose hypotheses to explain those observations. Past research on hypothetical induction has a limited setting that (1) the observation annotations of the dataset are not raw web corpus but are manually selected sentences (resulting in a close-domain setting); and (2) the ground truth hypotheses annotations are mostly commonsense knowledge, making the task less challenging. In this work, we propose the first NLP dataset for social science academic hypotheses discovery, consisting of 50 recent papers published in top social science journals. Raw web corpora that are necessary for developing hypotheses in the published papers are also collected in the dataset, with the final goal of creating a system that automatically generates valid, novel, and helpful (to human researchers) hypotheses, given only a pile of raw web corpora. The new dataset can tackle the previou
    
[^38]: 希伯来语侮辱性语料库及BERT模型的检测

    Offensive Hebrew Corpus and Detection using BERT. (arXiv:2309.02724v1 [cs.CL])

    [http://arxiv.org/abs/2309.02724](http://arxiv.org/abs/2309.02724)

    本研究提出了一个新的希伯来语侮辱性语料库，并使用两个希伯来语BERT模型（HeBERT和AlephBERT）进行了微调。我们观察到，我们的数据结合D_OLaH可以提高HeBERT模型的性能2%。此外，我们的数据对AlephBERT模型也具有一定的泛化性能。

    

    侮辱性语言检测在许多语言中已经有很多研究，但在低资源语言(如希伯来语)中仍有所滞后。本文介绍了一个新的希伯来语侮辱性语料库，从Twitter上收集了15881条推文。每条推文都由阿拉伯-希伯来双语人士标记为五个类别(辱骂、仇恨、暴力、色情或非侮辱性)。标注过程具有挑战性，因为每个标注者都需要熟悉以色列的文化、政治和实践，以理解每条推文的背景。我们使用提出的数据集和另一个已发布的数据集对两个希伯来语BERT模型(HeBERT和AlephBERT)进行微调。我们观察到，我们的数据与D_OLaH结合后，提高了HeBERT模型2%的性能。在我们的数据上对AlephBERT进行微调并在D_OLaH上进行测试，准确率达到69%，而在D_OLaH上进行微调并在我们的数据上进行测试时，准确率为57%，这可能表明我们的数据具有一定的泛化性能。

    Offensive language detection has been well studied in many languages, but it is lagging behind in low-resource languages, such as Hebrew. In this paper, we present a new offensive language corpus in Hebrew. A total of 15,881 tweets were retrieved from Twitter. Each was labeled with one or more of five classes (abusive, hate, violence, pornographic, or none offensive) by Arabic-Hebrew bilingual speakers. The annotation process was challenging as each annotator is expected to be familiar with the Israeli culture, politics, and practices to understand the context of each tweet. We fine-tuned two Hebrew BERT models, HeBERT and AlephBERT, using our proposed dataset and another published dataset. We observed that our data boosts HeBERT performance by 2% when combined with D_OLaH. Fine-tuning AlephBERT on our data and testing on D_OLaH yields 69% accuracy, while fine-tuning on D_OLaH and testing on our data yields 57% accuracy, which may be an indication to the generalizability our data offer
    
[^39]: SlAction：使用红外视频进行无干扰、轻量级的阻塞性睡眠呼吸暂停检测

    SlAction: Non-intrusive, Lightweight Obstructive Sleep Apnea Detection using Infrared Video. (arXiv:2309.02713v1 [cs.CV])

    [http://arxiv.org/abs/2309.02713](http://arxiv.org/abs/2309.02713)

    SlAction利用红外视频进行无干扰、轻量级的OSA检测，通过分析睡眠期间的人体运动与OSA事件之间的相关性，可用于日常睡眠环境中，可以避免传统的多导睡眠图的不准确性。

    

    阻塞性睡眠呼吸暂停（OSA）是一种影响全球约十亿人口的常见睡眠障碍。目前诊断OSA的黄金标准是多导睡眠图（PSG），它需要在医院过夜并连接多个传感器，从而可能因首夜效应而导致不准确。为了解决这个问题，我们提出了一种名为SlAction的非干扰性OSA检测系统，可以在日常睡眠环境中使用红外视频。由于睡眠视频中展现出的运动极少，本研究探究了一个基本问题：“在睡眠期间，呼吸事件是否适当地反映在人体运动中？”通过分析最大的睡眠视频数据集（总计5098小时），我们建立了OSA事件与睡眠期间人体运动之间的相关性。我们的方法使用了低帧率（2.5 FPS）、大尺寸（60秒）和滑动窗口分析的步长（30秒），以捕捉与OSA相关的缓慢和长期运动。此外，我们还利用了一个轻量级深度神经网络进行呼吸事件的分类。

    Obstructive sleep apnea (OSA) is a prevalent sleep disorder affecting approximately one billion people world-wide. The current gold standard for diagnosing OSA, Polysomnography (PSG), involves an overnight hospital stay with multiple attached sensors, leading to potential inaccuracies due to the first-night effect. To address this, we present SlAction, a non-intrusive OSA detection system for daily sleep environments using infrared videos. Recognizing that sleep videos exhibit minimal motion, this work investigates the fundamental question: "Are respiratory events adequately reflected in human motions during sleep?" Analyzing the largest sleep video dataset of 5,098 hours, we establish correlations between OSA events and human motions during sleep. Our approach uses a low frame rate (2.5 FPS), a large size (60 seconds) and step (30 seconds) for sliding window analysis to capture slow and long-term motions related to OSA. Furthermore, we utilize a lightweight deep neural network for res
    
[^40]: 揭示深度学习的前沿：塑造多个领域的创新

    Unveiling the frontiers of deep learning: innovations shaping diverse domains. (arXiv:2309.02712v1 [cs.LG])

    [http://arxiv.org/abs/2309.02712](http://arxiv.org/abs/2309.02712)

    本文广泛研究了深度学习在各个主要研究领域中的潜在应用，揭示了其准确性和计算能力的优势，以及相关的挑战。

    

    深度学习（DL）使得开发能够学习、可视化、优化、改进和预测数据的计算机模型成为可能。近年来，DL已经应用于多个领域，包括音频-视觉数据处理、农业、交通预测、自然语言、生物医学、灾害管理、生物信息学、药物设计、基因组学、人脸识别和生态学。为了探索深度学习的当前状态，有必要研究深度学习在这些学科中的最新发展和应用。然而，文献中缺乏对深度学习在所有潜在领域中的应用的探索。因此，本文广泛调查了深度学习在所有主要研究领域中的潜在应用，以及相关的优势和挑战。正如文献所证明的那样，DL在预测和分析方面表现出准确性，使其成为一种强大的计算工具，并具有表达能力。

    Deep learning (DL) enables the development of computer models that are capable of learning, visualizing, optimizing, refining, and predicting data. In recent years, DL has been applied in a range of fields, including audio-visual data processing, agriculture, transportation prediction, natural language, biomedicine, disaster management, bioinformatics, drug design, genomics, face recognition, and ecology. To explore the current state of deep learning, it is necessary to investigate the latest developments and applications of deep learning in these disciplines. However, the literature is lacking in exploring the applications of deep learning in all potential sectors. This paper thus extensively investigates the potential applications of deep learning across all major fields of study as well as the associated benefits and challenges. As evidenced in the literature, DL exhibits accuracy in prediction and analysis, makes it a powerful computational tool, and has the ability to articulate i
    
[^41]: 解决不完全对称性：一种新的对称学习的演员-评论者扩展

    Addressing Imperfect Symmetry: a Novel Symmetry-Learning Actor-Critic Extension. (arXiv:2309.02711v1 [cs.LG])

    [http://arxiv.org/abs/2309.02711](http://arxiv.org/abs/2309.02711)

    本研究提出了自适应对称学习（ASL）方法，通过模型最小化的方法，在学习过程中自适应地解决不完全或不精确的对称描述。ASL包括对称拟合组件和模块化损失函数，能高效适应对称性任务。

    

    对称性是理解我们的环境的基本概念，但往往从数学的角度过于简化了现实。人类是个很好的例子，外貌和认知偏见（例如有一只占主导地位的手）都不完美地偏离了对称性。尽管如此，我们的大脑很容易克服这些不完美并高效地适应对称性任务。本研究的驱动动机在于通过强化学习捕捉这种能力。为此，我们引入了自适应对称学习（ASL）-一种模型最小化的演员-评论者扩展，通过在学习过程中自适应地解决不完全或不精确的对称描述。ASL包括一个对称拟合组件和一个模块化损失函数，它在所有状态中强制实施共同的对称关系，并适应了所学策略。将ASL的性能与现有的对称增强方法在一个涉及四足蚂蚁模型的案例研究中进行了比较。

    Symmetry, a fundamental concept to understand our environment, often oversimplifies reality from a mathematical perspective. Humans are a prime example, deviating from perfect symmetry in terms of appearance and cognitive biases (e.g. having a dominant hand). Nevertheless, our brain can easily overcome these imperfections and efficiently adapt to symmetrical tasks. The driving motivation behind this work lies in capturing this ability through reinforcement learning. To this end, we introduce Adaptive Symmetry Learning (ASL) $\unicode{x2013}$ a model-minimization actor-critic extension that addresses incomplete or inexact symmetry descriptions by adapting itself during the learning process. ASL consists of a symmetry fitting component and a modular loss function that enforces a common symmetric relation across all states while adapting to the learned policy. The performance of ASL is compared to existing symmetry-enhanced methods in a case study involving a four-legged ant model for mul
    
[^42]: 证明LLM对抗敌对提示的安全性

    Certifying LLM Safety against Adversarial Prompting. (arXiv:2309.02705v1 [cs.CL])

    [http://arxiv.org/abs/2309.02705](http://arxiv.org/abs/2309.02705)

    本研究提出了首个具有可验证安全保证的框架——消除和检查，用于对抗敌对提示。通过逐个消除标记并使用安全过滤器检查生成的子序列，确保任何敌对修改的有害输入提示都能被正确标识为有害。

    

    为了确保语言模型的输出安全，公开使用的大型语言模型（LLM）引入了所谓的“模型对齐”防护措施。一个对齐的语言模型应该拒绝用户的请求生成有害内容。然而，这种安全措施容易受到敌对提示的攻击，敌对提示包含恶意设计的标记序列，以规避模型的安全防护并导致生成有害内容。在这项工作中，我们介绍了可验证安全保证的第一个对抗敌对提示的框架——消除和检查。我们逐个消除标记，并使用安全过滤器检查生成的子序列。如果安全过滤器检测到任何子序列或输入提示有害，我们的过程将将输入提示标记为有害。这保证了对于某个特定大小的有害输入提示的任何敌对修改也将被标记为有害。我们对抗三种攻击模式：i)敌对后缀，即附加敌对序列…

    Large language models (LLMs) released for public use incorporate guardrails to ensure their output is safe, often referred to as "model alignment." An aligned language model should decline a user's request to produce harmful content. However, such safety measures are vulnerable to adversarial prompts, which contain maliciously designed token sequences to circumvent the model's safety guards and cause it to produce harmful content. In this work, we introduce erase-and-check, the first framework to defend against adversarial prompts with verifiable safety guarantees. We erase tokens individually and inspect the resulting subsequences using a safety filter. Our procedure labels the input prompt as harmful if any subsequences or the input prompt are detected as harmful by the filter. This guarantees that any adversarial modification of a harmful prompt up to a certain size is also labeled harmful. We defend against three attack modes: i) adversarial suffix, which appends an adversarial seq
    
[^43]: Diffusion-EDFs: 基于SE(3)的等变去噪生成建模在视觉机器人操作中的应用

    Diffusion-EDFs: Bi-equivariant Denoising Generative Modeling on SE(3) for Visual Robotic Manipulation. (arXiv:2309.02685v1 [cs.RO])

    [http://arxiv.org/abs/2309.02685](http://arxiv.org/abs/2309.02685)

    本文提出了Diffusion-EDFs，一种在视觉机器人操作中应用的基于SE(3)的等变去噪生成建模方法。通过集成SE(3)等变性，我们的方法展示了出色的数据效率和泛化能力。

    

    最近的研究已经验证了等变方法可以显著提高机器人学习中的数据效率、泛化能力和鲁棒性。与此同时，去噪扩散生成建模最近作为一种具有随机行为的机器人操作学习的有前途的方法引起了极大关注。本文提出了Diffusion-EDFs，一种将空间旋转平移等变性即SE(3)等变性引入扩散生成建模的新方法。通过将SE(3)等变性集成到我们的模型架构中，我们展示了我们提出的方法具有明显的数据效率，在进行端到端训练时只需5到10个任务演示即可。此外，与之前基于扩散的操作方法相比，我们的方法展示了更好的泛化能力。

    Recent studies have verified that equivariant methods can significantly improve the data efficiency, generalizability, and robustness in robot learning. Meanwhile, denoising diffusion-based generative modeling has recently gained significant attention as a promising approach for robotic manipulation learning from demonstrations with stochastic behaviors. In this paper, we present Diffusion-EDFs, a novel approach that incorporates spatial roto-translation equivariance, i.e., SE(3)-equivariance to diffusion generative modeling. By integrating SE(3)-equivariance into our model architectures, we demonstrate that our proposed method exhibits remarkable data efficiency, requiring only 5 to 10 task demonstrations for effective end-to-end training. Furthermore, our approach showcases superior generalizability compared to previous diffusion-based manipulation methods.
    
[^44]: RLSynC: 离线-在线强化学习用于合成方法的合成物补全

    RLSynC: Offline-Online Reinforcement Learning for Synthon Completion. (arXiv:2309.02671v1 [cs.LG])

    [http://arxiv.org/abs/2309.02671](http://arxiv.org/abs/2309.02671)

    RLSynC是一种离线-在线强化学习方法，用于半模板化逆向合成中的合成物补全。它使用多个代理同时完成合成物的补全，并通过正向合成模型评估反应物的合成能力来指导行动搜索。

    

    逆向合成是确定能够反应形成所需产物的一组反应物分子的过程。半模板化逆向合成方法首先预测产物中的反应中心，然后将生成的合成物重新补全成反应物。这些方法能够提供必要的可解释性和高实用性，以指导合成规划。我们开发了一种新的离线-在线强化学习方法RLSynC，用于半模板化方法中的合成物补全。RLSynC为每个合成物分配一个代理，所有代理都通过同步进行逐步行动，完成合成物的补全。RLSynC通过同时进行离线训练和在线交互来学习策略，从而可以探索新的反应空间。RLSynC使用正向合成模型来评估预测的反应物在合成产物时的可能性，从而指导行动搜索。

    Retrosynthesis is the process of determining the set of reactant molecules that can react to form a desired product. Semi-template-based retrosynthesis methods, which imitate the reverse logic of synthesis reactions, first predict the reaction centers in the products, and then complete the resulting synthons back into reactants. These methods enable necessary interpretability and high practical utility to inform synthesis planning. We develop a new offline-online reinforcement learning method RLSynC for synthon completion in semi-template-based methods. RLSynC assigns one agent to each synthon, all of which complete the synthons by conducting actions step by step in a synchronized fashion. RLSynC learns the policy from both offline training episodes and online interactions which allow RLSynC to explore new reaction spaces. RLSynC uses a forward synthesis model to evaluate the likelihood of the predicted reactants in synthesizing a product, and thus guides the action search. We compare 
    
[^45]: 空间粒子的子集测度

    Subsethood Measures of Spatial Granules. (arXiv:2309.02662v1 [cs.AI])

    [http://arxiv.org/abs/2309.02662](http://arxiv.org/abs/2309.02662)

    本文介绍了空间粒子的子集测度以及与之相关的粗精关系和操作。通过这些概念，我们可以构建粗糙集模型和空间粗糙粒子模型，这对于解决结构问题非常重要。

    

    子集测度用于测量集合包含关系的程度，在模糊集合理论中占主导地位。本文介绍了空间粒子、粗精关系以及meet、join、quotient meet和quotient join等操作的基本概念。所有原子粒子可以通过集合包含关系进行层次化，所有粒子可以通过粗精关系进行层次化。通过从微观和宏观的视角看待信息系统，我们可以获得微观知识空间和宏观知识空间，从中分别获得一个粗糙集模型和一个空间粗糙粒子模型。经过从微观知识空间导出的粗糙集模型，是经典粗糙集模型的特殊情况，而空间粗糙粒子模型将在结构问题的解决中起到关键作用。我们讨论了十二个单调递增的子集测度公理和十二个相应的单调递减的超集测度公理，并推广了子集测度和超集测度。

    Subsethood, which is to measure the degree of set inclusion relation, is predominant in fuzzy set theory. This paper introduces some basic concepts of spatial granules, coarse-fine relation, and operations like meet, join, quotient meet and quotient join. All the atomic granules can be hierarchized by set-inclusion relation and all the granules can be hierarchized by coarse-fine relation. Viewing an information system from the micro and the macro perspectives, we can get a micro knowledge space and a micro knowledge space, from which a rough set model and a spatial rough granule model are respectively obtained. The classical rough set model is the special case of the rough set model induced from the micro knowledge space, while the spatial rough granule model will be play a pivotal role in the problem-solving of structures. We discuss twelve axioms of monotone increasing subsethood and twelve corresponding axioms of monotone decreasing supsethood, and generalize subsethood and supsetho
    
[^46]: TFBEST: 具有可学习位置编码的双重方面Transformer用于故障预测

    TFBEST: Dual-Aspect Transformer with Learnable Positional Encoding for Failure Prediction. (arXiv:2309.02641v1 [cs.LG])

    [http://arxiv.org/abs/2309.02641](http://arxiv.org/abs/2309.02641)

    本文提出了一种新颖的双重方面Transformer模型，用于故障预测，有效处理长序列日志和提供预测值的置信区间。

    

    数据中心中的硬盘故障是昂贵的 - 从灾难性的数据丢失到商业信誉的问题，利益相关者希望像瘟疫一样避免它。积极监测硬盘故障的重要工具是及时估计剩余寿命（RUL）。为此，硬盘驱动器内部使用的自我监测、分析和报告技术（S.M.A.R.T.）为这些重要数据存储设备的长期维护提供了关键的日志。过去的数据驱动预测模型经常使用这些S.M.A.R.T.日志和基于CNN/RNN的架构。然而，它们在提供预测的RUL值的置信区间以及处理非常长的日志序列方面遇到了重大困难。此外，一些使用LSTM等方法的研究在训练速度上很慢，并且需要繁琐的特征工程开销。为了克服这些挑战，在这项工作中，我们提出了一种新颖的Transformer模型，其中包括了学习位置编码的双重方面。

    Hard Disk Drive (HDD) failures in datacenters are costly - from catastrophic data loss to a question of goodwill, stakeholders want to avoid it like the plague. An important tool in proactively monitoring against HDD failure is timely estimation of the Remaining Useful Life (RUL). To this end, the Self-Monitoring, Analysis and Reporting Technology employed within HDDs (S.M.A.R.T.) provide critical logs for long-term maintenance of the security and dependability of these essential data storage devices. Data-driven predictive models in the past have used these S.M.A.R.T. logs and CNN/RNN based architectures heavily. However, they have suffered significantly in providing a confidence interval around the predicted RUL values as well as in processing very long sequences of logs. In addition, some of these approaches, such as those based on LSTMs, are inherently slow to train and have tedious feature engineering overheads. To overcome these challenges, in this work we propose a novel transfo
    
[^47]: 从分层的弱偏好反馈中进行深度强化学习

    Deep Reinforcement Learning from Hierarchical Weak Preference Feedback. (arXiv:2309.02632v1 [cs.LG])

    [http://arxiv.org/abs/2309.02632](http://arxiv.org/abs/2309.02632)

    本研究探讨了如何利用分层的弱偏好反馈进行深度强化学习。通过学习奖励函数，与人类偏好非常一致的复杂奖励可以帮助强化学习解决日益困难的问题。

    

    奖励设计是实际强化学习中一个基本但具有挑战性的方面。对于简单任务，研究人员通常手工设计奖励函数，例如使用若干个奖励因子的线性组合。然而，这种奖励工程受到近似偏差的影响，需要大量的调优成本，并且通常无法提供复杂任务所需的细粒度。为了避免这些困难，研究人员开始转向从人类反馈中进行强化学习（RLHF），从轨迹序列对之间的人类偏好中学习奖励函数。通过利用基于偏好的奖励建模，RLHF学习到与人类偏好非常一致的复杂奖励，使得强化学习能够解决日益困难的问题。不幸的是，RLHF的适用性受到获得人类偏好数据的高成本和困难的限制。鉴于这个成本，我们研究了在复杂任务中使用更少人力投入的方式来学习奖励函数。

    Reward design is a fundamental, yet challenging aspect of practical reinforcement learning (RL). For simple tasks, researchers typically handcraft the reward function, e.g., using a linear combination of several reward factors. However, such reward engineering is subject to approximation bias, incurs large tuning cost, and often cannot provide the granularity required for complex tasks. To avoid these difficulties, researchers have turned to reinforcement learning from human feedback (RLHF), which learns a reward function from human preferences between pairs of trajectory sequences. By leveraging preference-based reward modeling, RLHF learns complex rewards that are well aligned with human preferences, allowing RL to tackle increasingly difficult problems. Unfortunately, the applicability of RLHF is limited due to the high cost and difficulty of obtaining human preference data. In light of this cost, we investigate learning reward functions for complex tasks with less human effort; sim
    
[^48]: 利用生成对抗网络为愤怒的小鸟生成稳定的结构

    Utilizing Generative Adversarial Networks for Stable Structure Generation in Angry Birds. (arXiv:2309.02614v1 [cs.LG])

    [http://arxiv.org/abs/2309.02614](http://arxiv.org/abs/2309.02614)

    本文研究了使用生成对抗网络（GANs）为愤怒的小鸟生成复杂且稳定的结构。实验结果表明GANs可以成功应用于生成多样化的愤怒的小鸟结构。

    

    本文研究了使用生成对抗网络（GANs）生成物理基础拼图游戏愤怒的小鸟中稳定结构的适用性。尽管先前对于关卡生成的GANs应用主要局限于基于瓦片的表示，本文探讨了它们在创建由多个较小块组成的稳定结构方面的适用性。这包括了详细的编码/解码过程，将愤怒的小鸟关卡描述转换为适合的基于网格的表示，以及利用最先进的GAN架构和训练方法来生成新的结构设计。结果表明，GANs成功应用于生成各种复杂且稳定的愤怒的小鸟结构。

    This paper investigates the suitability of using Generative Adversarial Networks (GANs) to generate stable structures for the physics-based puzzle game Angry Birds. While previous applications of GANs for level generation have been mostly limited to tile-based representations, this paper explores their suitability for creating stable structures made from multiple smaller blocks. This includes a detailed encoding/decoding process for converting between Angry Birds level descriptions and a suitable grid-based representation, as well as utilizing state-of-the-art GAN architectures and training methods to produce new structure designs. Our results show that GANs can be successfully applied to generate a varied range of complex and stable Angry Birds structures.
    
[^49]: 使用统计学与物理引导的过程模型在协同实体系统中检测未知-未知情况

    Detection of Unknown-Unknowns in Cyber-Physical Systems using Statistical Conformance with Physics Guided Process Models. (arXiv:2309.02603v1 [cs.AI])

    [http://arxiv.org/abs/2309.02603](http://arxiv.org/abs/2309.02603)

    该论文提出了一个新的框架来分析安全关键的协同实体系统的操作输出特性的随机符合性，从而发现未知-未知情况并评估潜在的安全风险。

    

    未知-未知情况是指在设计和测试阶段未考虑到的协同实体系统中的操作场景。在未知-未知情况下，协同实体系统的操作行为不能保证满足通过输出轨迹上的信号时间逻辑（STL）指定的安全性和有效性等要求。我们提出了一种新颖的框架，用于分析安全关键协同实体系统操作输出特性的随机符合性，可以发现未知-未知情况并评估潜在的安全风险。我们提出了一种动力学诱导的混合循环神经网络（DiH-RNN），用于挖掘物理引导的代理模型（PGSM），并使用STL对模型系数进行模型一致性检查。我们演示了通过未知胰岛素卡带错误导致人工胰腺(AP)操作变化的检测。

    Unknown unknowns are operational scenarios in a cyber-physical system that are not accounted for in the design and test phase. As such under unknown-unknown scenarios, the operational behavior of the CPS is not guaranteed to meet requirements such as safety and efficacy specified using Signal Temporal Logic (STL) on the output trajectories. We propose a novel framework for analyzing the stochastic conformance of operational output characteristics of safety-critical cyber-physical systems that can discover unknown-unknown scenarios and evaluate potential safety hazards. We propose dynamics-induced hybrid recurrent neural networks (DiH-RNN) to mine a physics-guided surrogate model (PGSM) which is used to check the model conformance using STL on the model coefficients. We demonstrate the detection of operational changes in an Artificial Pancreas(AP) due to unknown insulin cartridge errors.
    
[^50]: 短期天气预报中元启发式算法对超参数选择的比较评估

    Comparative Evaluation of Metaheuristic Algorithms for Hyperparameter Selection in Short-Term Weather Forecasting. (arXiv:2309.02600v1 [cs.NE])

    [http://arxiv.org/abs/2309.02600](http://arxiv.org/abs/2309.02600)

    本文比较评估了短期天气预报中元启发式算法（遗传算法、差分进化算法和粒子群优化算法）在优化深度学习模型的超参数选择方面的应用，证明了这些算法在全局优化中的优势和可扩展性。

    

    天气预报在许多领域都起着至关重要的作用，但能够准确捕捉天气系统的复杂动态仍然是传统统计模型面临的挑战。除了自回归时间预测模型（如ARIMA）之外，深度学习技术（如普通的人工神经网络、LSTM和GRU网络）通过捕捉时间依赖性，显示出提高预测准确性的潜力。本文探讨了应用元启发式算法，即遗传算法（GA）、差分进化算法（DE）和粒子群优化算法（PSO），自动搜索这些模型结构中的最优超参数。元启发式算法在全局优化方面表现突出，具有处理非线性问题的鲁棒性、多功能性和可扩展性。我们对集成了元启发式优化的不同模型结构进行了比较分析，评估了它们在天气预报中的表现，基于均方误差（MSE）和平均绝对误差（MAE）等指标。

    Weather forecasting plays a vital role in numerous sectors, but accurately capturing the complex dynamics of weather systems remains a challenge for traditional statistical models. Apart from Auto Regressive time forecasting models like ARIMA, deep learning techniques (Vanilla ANNs, LSTM and GRU networks), have shown promise in improving forecasting accuracy by capturing temporal dependencies. This paper explores the application of metaheuristic algorithms, namely Genetic Algorithm (GA), Differential Evolution (DE), and Particle Swarm Optimization (PSO), to automate the search for optimal hyperparameters in these model architectures. Metaheuristic algorithms excel in global optimization, offering robustness, versatility, and scalability in handling non-linear problems. We present a comparative analysis of different model architectures integrated with metaheuristic optimization, evaluating their performance in weather forecasting based on metrics such as Mean Squared Error (MSE) and Mea
    
[^51]: 使用物理知识的神经网络计算更高维度中的最小曲面

    Using Physics-Informed Neural Networks to Calculate Minimal Surfaces in Higher Dimensions. (arXiv:2309.02589v1 [math.AP])

    [http://arxiv.org/abs/2309.02589](http://arxiv.org/abs/2309.02589)

    本文使用物理知识的神经网络（PINN）计算更高维度中的最小曲面的数值逼近，解决了维数诅咒问题，并且能够在没有GPU的笔记本电脑上进行快速训练。

    

    本文中，我们计算了更高维度中最小曲面的数值逼近，这是一种重要的偏微分方程类型。由于维数的诅咒导致传统方法无法处理这种情况，这些方法的计算成本会随维数增加而指数级增长，远远超出任何现代超级计算机的计算能力。只有在过去几年中，机器学习研究人员才能够缓解这个问题。本文选择的解决方法是一种称为物理知识的神经网络（Physics-Informed Neural Network，PINN）的模型，它训练了一个深度神经网络（Deep Neural Network，DNN）来解决最小曲面偏微分方程。它可以在更高维度上扩展，并且即使在没有GPU的笔记本电脑上也能相对快速地训练。由于无法查看高维度输出，我们的数据以足够的固定轴的片段形式呈现，以便通过3D图形进行查看。

    In this paper, we compute numerical approximations of the minimal surfaces, an essential type of Partial Differential Equation (PDE), in higher dimensions. Classical methods cannot handle it in this case because of the Curse of Dimensionality, where the computational cost of these methods increases exponentially fast in response to higher problem dimensions, far beyond the computing capacity of any modern supercomputers. Only in the past few years have machine learning researchers been able to mitigate this problem. The solution method chosen here is a model known as a Physics-Informed Neural Network (PINN) which trains a deep neural network (DNN) to solve the minimal surface PDE. It can be scaled up into higher dimensions and trained relatively quickly even on a laptop with no GPU. Due to the inability to view the high-dimension output, our data is presented as snippets of a higher-dimension shape with enough fixed axes so that it is viewable with 3-D graphs. Not only will the functio
    
[^52]: 顺序体积设计任务的表示学习

    Representation Learning for Sequential Volumetric Design Tasks. (arXiv:2309.02583v1 [cs.LG])

    [http://arxiv.org/abs/2309.02583](http://arxiv.org/abs/2309.02583)

    本研究提出了一种顺序体积设计任务的表示学习方法，通过利用transformer模型从专家的设计序列中提取有用的表示来提高自动生成体积设计的质量，以及支持设计偏好评估和程序化设计生成。

    

    体积设计，也称为质量设计，是专业建筑设计中的第一步关键性任务，具有顺序性。由于体积设计过程复杂，顺序化设计过程中包含了对设计师有价值的信息。许多努力已经被投入到自动生成合理的体积设计上，但生成的设计解决方案的质量存在差异，并且评估一个设计解决方案要么需要一套过于全面的度量标准，要么需要昂贵的人力专业知识。而之前的方法主要关注学习最终设计，而不是顺序设计任务，我们提出利用专家或高性能设计序列的设计知识，并使用基于transformer的模型提取有用的表示。然后，我们提出利用所学的表示在关键的下游应用中，如设计偏好评估和程序化设计生成。我们开发了prefer

    Volumetric design, also called massing design, is the first and critical step in professional building design which is sequential in nature. As the volumetric design process is complex, the underlying sequential design process encodes valuable information for designers. Many efforts have been made to automatically generate reasonable volumetric designs, but the quality of the generated design solutions varies, and evaluating a design solution requires either a prohibitively comprehensive set of metrics or expensive human expertise. While previous approaches focused on learning only the final design instead of sequential design tasks, we propose to encode the design knowledge from a collection of expert or high-performing design sequences and extract useful representations using transformer-based models. Later we propose to utilize the learned representations for crucial downstream applications such as design preference evaluation and procedural design generation. We develop the prefere
    
[^53]: 用深度学习算法揭示难治性癫痫脑网络：一种针对儿童患者单模态神经影像数据的可扩展癫痫预测新方法

    Unveiling Intractable Epileptogenic Brain Networks with Deep Learning Algorithms: A Novel and Comprehensive Framework for Scalable Seizure Prediction with Unimodal Neuroimaging Data in Pediatric Patients. (arXiv:2309.02580v1 [cs.LG])

    [http://arxiv.org/abs/2309.02580](http://arxiv.org/abs/2309.02580)

    本研究提出了一种新颖而全面的框架，通过评估机器学习算法对儿童患者的脑电图信号进行分析，揭示了难治性癫痫的脑网络，并实现了可扩展的癫痫预测。

    

    癫痫是一种常见的神经系统疾病，全球有5000万人受到影响，美国有120万人受到影响。存在着大量儿童患者患有难治性癫痫，即癫痫发作无法得到控制。癫痫发作可能导致身体伤害、迷失方向、失去意识，以及其他可能妨碍儿童参与日常活动的症状。预测癫痫发作可以帮助家长和医护人员采取预防措施，避免危险情况，并让儿童在面对癫痫的不确定性时减少焦虑和紧张感。本研究提出了一种新颖而全面的框架，通过评估机器学习算法对以脑电图信号为基础的单模态神经影像数据进行癫痫预测。

    Epilepsy is a prevalent neurological disorder affecting 50 million individuals worldwide and 1.2 million Americans. There exist millions of pediatric patients with intractable epilepsy, a condition in which seizures fail to come under control. The occurrence of seizures can result in physical injury, disorientation, unconsciousness, and additional symptoms that could impede children's ability to participate in everyday tasks. Predicting seizures can help parents and healthcare providers take precautions, prevent risky situations, and mentally prepare children to minimize anxiety and nervousness associated with the uncertainty of a seizure. This research proposes a novel and comprehensive framework to predict seizures in pediatric patients by evaluating machine learning algorithms on unimodal neuroimaging data consisting of electroencephalogram signals. The bandpass filtering and independent component analysis proved to be effective in reducing the noise and artifacts from the dataset. 
    
[^54]: 基于扩散的微软365时间序列数据插补

    Diffusion-based Time Series Data Imputation for Microsoft 365. (arXiv:2309.02564v1 [cs.DC])

    [http://arxiv.org/abs/2309.02564](http://arxiv.org/abs/2309.02564)

    本研究提出了一种基于扩散的数据插补方法Diffusion+，通过观察到的数据高效地插补缺失数据，提高了微软365的数据质量，进而改善了下游故障预测任务的性能。

    

    可靠性对于像微软365这样的大规模云系统非常重要。云故障（如磁盘故障、节点故障等）威胁到服务的可靠性，导致在线服务中断和经济损失。现有的工作侧重于预测云故障并在故障发生之前采取积极行动。然而，他们在模型训练和预测中存在数据缺失等数据质量差的问题，这限制了性能。本文通过提出的Diffusion+（一种样本效率高的扩散模型），通过观察到的数据高效地插补缺失数据，以提高数据质量。我们的实验和应用实践表明，我们的模型有助于提高下游故障预测任务的性能。

    Reliability is extremely important for large-scale cloud systems like Microsoft 365. Cloud failures such as disk failure, node failure, etc. threaten service reliability, resulting in online service interruptions and economic loss. Existing works focus on predicting cloud failures and proactively taking action before failures happen. However, they suffer from poor data quality like data missing in model training and prediction, which limits the performance. In this paper, we focus on enhancing data quality through data imputation by the proposed Diffusion+, a sample-efficient diffusion model, to impute the missing data efficiently based on the observed data. Our experiments and application practice show that our model contributes to improving the performance of the downstream failure prediction task.
    
[^55]: 使用基于计划CT的放射组学模型预测肛门鳞状细胞癌化疗放疗的无复发生存期

    Recurrence-Free Survival Prediction for Anal Squamous Cell Carcinoma Chemoradiotherapy using Planning CT-based Radiomics Model. (arXiv:2309.02562v1 [cs.CV])

    [http://arxiv.org/abs/2309.02562](http://arxiv.org/abs/2309.02562)

    通过提取放射组学特征，我们开发了一个模型，能够利用计划CT图像来预测肛门鳞状细胞癌化疗放疗后的无复发生存期。放射组学特征显著预测了RFS。

    

    目的：约30%的非转移性肛门鳞状细胞癌（ASCC）患者在化疗放疗后会出现复发，目前可用的临床变量对治疗反应的预测能力较差。我们旨在开发一个模型，利用从放射治疗前的CT图像中提取的信息来预测ASCC患者在化疗放疗后的无复发生存期（RFS）。方法：从96名ASCC患者的计划CT图像中提取了放射组学特征。在进行特征选择之前，通过多变量Cox比例风险模型的逐步前向特征选择选出了最佳特征集合。利用五次重复的五折交叉验证，从一个基于最佳特征集合的放射组学-临床组合模型中生成了RFS预测。采用Kaplan-Meier分析评估所提出模型的风险分层能力。结果：基于形状和纹理的放射组学特征能够显著预测RFS。

    Objectives: Approximately 30% of non-metastatic anal squamous cell carcinoma (ASCC) patients will experience recurrence after chemoradiotherapy (CRT), and currently available clinical variables are poor predictors of treatment response. We aimed to develop a model leveraging information extracted from radiation pretreatment planning CT to predict recurrence-free survival (RFS) in ASCC patients after CRT. Methods: Radiomics features were extracted from planning CT images of 96 ASCC patients. Following pre-feature selection, the optimal feature set was selected via step-forward feature selection with a multivariate Cox proportional hazard model. The RFS prediction was generated from a radiomics-clinical combined model based on an optimal feature set with five repeats of five-fold cross validation. The risk stratification ability of the proposed model was evaluated with Kaplan-Meier analysis. Results: Shapeand texture-based radiomics features significantly predicted RFS. Compared to a c
    
[^56]: 用于机器人操作的具有物理基础的视觉语言模型

    Physically Grounded Vision-Language Models for Robotic Manipulation. (arXiv:2309.02561v1 [cs.RO])

    [http://arxiv.org/abs/2309.02561](http://arxiv.org/abs/2309.02561)

    该论文介绍了一个用于机器人操作的具有物理基础的视觉语言模型，通过在物体上微调模型，提高了模型对物理概念的理解，在语言交互框架中展现了良好的性能。

    

    最近对于视觉语言模型（VLMs）的研究进展导致在视觉问答和图像描述等任务上的性能得到了提升。因此，这些模型现在可以在物理世界中进行推理，特别是在机器人操作领域。然而，当前的VLMs在对常见物体的物理概念（例如材料、脆弱性）的理解方面存在局限，这限制了它们在涉及与这些物体的相互作用和物理推理的机器人操作任务中的实用性。为了解决这个问题，我们提出了PhysObjects，这是一个以物体为中心的数据集，包含36.9K个众包和417K个自动化的常见家居物品的物理概念注释。我们证明，在PhysObjects上对VLM进行微调可以提高其对物理物体概念的理解，通过从视觉外观中捕捉这些概念的人类先验知识。我们在一个大型的语言交互框架中将这个具有物理基础的VLM结合在一起。

    Recent advances in vision-language models (VLMs) have led to improved performance on tasks such as visual question answering and image captioning. Consequently, these models are now well-positioned to reason about the physical world, particularly within domains such as robotic manipulation. However, current VLMs are limited in their understanding of the physical concepts (e.g., material, fragility) of common objects, which restricts their usefulness for robotic manipulation tasks that involve interaction and physical reasoning about such objects. To address this limitation, we propose PhysObjects, an object-centric dataset of 36.9K crowd-sourced and 417K automated physical concept annotations of common household objects. We demonstrate that fine-tuning a VLM on PhysObjects improves its understanding of physical object concepts, by capturing human priors of these concepts from visual appearance. We incorporate this physically-grounded VLM in an interactive framework with a large languag
    
[^57]: 自动化机器翻译的行为测试

    Automating Behavioral Testing in Machine Translation. (arXiv:2309.02553v1 [cs.CL])

    [http://arxiv.org/abs/2309.02553](http://arxiv.org/abs/2309.02553)

    本文提出了一种利用大型语言模型自动生成源句子的方法，以测试机器翻译模型在多种情况下的行为。通过对多个机器翻译系统应用该方法，发现在测试结果与传统准确率度量存在差异的情况下，仍可观察到一致的趋势。

    

    NLP中的行为测试通过分析输入-输出行为来细粒度评估系统的语言能力。然而，目前关于机器翻译中行为测试的研究仅限于手工设计的测试范围有限、涵盖的语言种类也有限。为了解决这一限制，我们提出利用大型语言模型生成多样化的源句子，以测试机器翻译模型在不同情况下的行为。然后，我们可以使用相同的语言模型生成备选集，以验证机器翻译模型是否表现出预期的行为。我们的方法旨在使机器翻译系统的行为测试实际可行，同时只需要最少的人力投入。在实验中，我们将提出的评估框架应用于多个可用的机器翻译系统，结果显示，尽管总体上通过率与传统准确率度量可观察到的趋势相符，但仍存在差异。

    Behavioral testing in NLP allows fine-grained evaluation of systems by examining their linguistic capabilities through the analysis of input-output behavior. Unfortunately, existing work on behavioral testing in Machine Translation (MT) is currently restricted to largely handcrafted tests covering a limited range of capabilities and languages. To address this limitation, we propose to use Large Language Models (LLMs) to generate a diverse set of source sentences tailored to test the behavior of MT models in a range of situations. We can then verify whether the MT model exhibits the expected behavior through matching candidate sets that are also generated using LLMs. Our approach aims to make behavioral testing of MT systems practical while requiring only minimal human effort. In our experiments, we apply our proposed evaluation framework to assess multiple available MT systems, revealing that while in general pass-rates follow the trends observable from traditional accuracy-based metri
    
[^58]: 持续改进基于阈值的新颖性检测

    Continual Improvement of Threshold-Based Novelty Detection. (arXiv:2309.02551v1 [cs.LG])

    [http://arxiv.org/abs/2309.02551](http://arxiv.org/abs/2309.02551)

    论文提出了一种新的方法，利用线性搜索和离一标准交叉验证自动选择阈值，从而改进了动态环境中神经网络的新颖性检测准确率。

    

    在动态开放的环境中，神经网络在检测未见类别时面临困难。这个问题使得在现实环境中部署持续学习变得复杂，因为代理程序在遇到新类型时并没有明确的通知。一种常见的检测新颖性的方法是基于观察数据点与训练数据的相似度阈值。然而，这些方法通常需要手动指定这些阈值的值（提前），因此无法适应数据的性质。我们提出了一种新的方法，利用线性搜索和离一标准交叉验证自动选择这些阈值。我们证明了这种选择阈值的新方法在MNIST，时尚MNIST和CIFAR-10上提高了总体准确率。

    When evaluated in dynamic, open-world situations, neural networks struggle to detect unseen classes. This issue complicates the deployment of continual learners in realistic environments where agents are not explicitly informed when novel categories are encountered. A common family of techniques for detecting novelty relies on thresholds of similarity between observed data points and the data used for training. However, these methods often require manually specifying (ahead of time) the value of these thresholds, and are therefore incapable of adapting to the nature of the data. We propose a new method for automatically selecting these thresholds utilizing a linear search and leave-one-out cross-validation on the ID classes. We demonstrate that this novel method for selecting thresholds results in improved total accuracy on MNIST, Fashion MNIST, and CIFAR-10.
    
[^59]: 通过图注意力进行结构概念学习，实现多层次重组规划

    Structural Concept Learning via Graph Attention for Multi-Level Rearrangement Planning. (arXiv:2309.02547v1 [cs.RO])

    [http://arxiv.org/abs/2309.02547](http://arxiv.org/abs/2309.02547)

    本论文提出了一种名为结构概念学习（SCL）的深度学习方法，利用图注意力网络进行多层次物体重组规划。该方法在自动生成的模拟数据集上训练，可以适应具有复杂结构依赖的未知场景，推断出独立的子结构以实现任务并行化，并且在现实世界中具有泛化能力。

    

    机器人的操作任务，如物体重组，在使机器人能够与复杂和任意环境进行交互方面起着至关重要的作用。现有的工作主要集中在单层重组规划上，即使存在多个层次，子结构之间的依赖关系几何上也较简单，如塔式堆叠。我们提出了结构概念学习（SCL），这是一种利用图注意力网络进行多层次物体重组规划的深度学习方法，用直观的结构在自动生成的模拟数据集上训练，适用于具有结构依赖层次的未知场景，具有任意数量的对象和更复杂的结构，推断出独立的子结构，通过多个操纵器实现任务并行化，并且在现实世界中具有泛化能力。我们将我们的方法与一系列经典和基于模型的基准进行比较，以显示我们的方法利用了场景的理解能力。

    Robotic manipulation tasks, such as object rearrangement, play a crucial role in enabling robots to interact with complex and arbitrary environments. Existing work focuses primarily on single-level rearrangement planning and, even if multiple levels exist, dependency relations among substructures are geometrically simpler, like tower stacking. We propose Structural Concept Learning (SCL), a deep learning approach that leverages graph attention networks to perform multi-level object rearrangement planning for scenes with structural dependency hierarchies. It is trained on a self-generated simulation data set with intuitive structures, works for unseen scenes with an arbitrary number of objects and higher complexity of structures, infers independent substructures to allow for task parallelization over multiple manipulators, and generalizes to the real world. We compare our method with a range of classical and model-based baselines to show that our method leverages its scene understanding
    
[^60]: 经验与预测:一种新型硬度度量的标准化试验

    Experience and Prediction: A Metric of Hardness for a Novel Litmus Test. (arXiv:2309.02534v1 [cs.AI])

    [http://arxiv.org/abs/2309.02534](http://arxiv.org/abs/2309.02534)

    该论文实现了一种自动化系统，通过设计和输出Winograd模式的硬度指数，可以在未来的挑战或WSC CAPTCHA服务中对模式进行区分分类。

    

    在过去的十年里，Winograd Schema Challenge (WSC) 已成为研究界的一个重要方面，作为一种新型的标准化试验。因此，WSC引起了研究兴趣，因为它被视为理解人类行为的手段。在这方面，新技术的发展使得Winograd模式能够在各个领域中使用，例如设计新型的CAPTCHAs形式。早些时候的研究工作已经为人类成年人在WSC上的表现建立了基线，表明并不是所有的模式都是相同的，这意味着它们可能根据人类的感知难度进行分类。在这方面，这种"硬度度量"可以在未来的挑战或WSC CAPTCHA服务中使用，以区分Winograd模式。我们最近的工作表明，通过设计一个能够输出Winograd模式的硬度指数的自动化系统，可以实现这一目标，尽管存在一些限制。

    In the last decade, the Winograd Schema Challenge (WSC) has become a central aspect of the research community as a novel litmus test. Consequently, the WSC has spurred research interest because it can be seen as the means to understand human behavior. In this regard, the development of new techniques has made possible the usage of Winograd schemas in various fields, such as the design of novel forms of CAPTCHAs.  Work from the literature that established a baseline for human adult performance on the WSC has shown that not all schemas are the same, meaning that they could potentially be categorized according to their perceived hardness for humans. In this regard, this \textit{hardness-metric} could be used in future challenges or in the WSC CAPTCHA service to differentiate between Winograd schemas.  Recent work of ours has shown that this could be achieved via the design of an automated system that is able to output the hardness-indexes of Winograd schemas, albeit with limitations regar
    
[^61]: 你相信ChatGPT吗？-- 关于人类与AI生成内容的可信度感知

    Do You Trust ChatGPT? -- Perceived Credibility of Human and AI-Generated Content. (arXiv:2309.02524v1 [cs.HC])

    [http://arxiv.org/abs/2309.02524](http://arxiv.org/abs/2309.02524)

    本文研究了人们对来自人类作者和由大型语言模型生成的内容的可信度感知，发现不论用户界面如何呈现，参与者倾向于赋予相似水平的可信度。尽管人们对人类和AI生成内容的能力和值得信赖程度没有不同的感知，但他们认为AI生成的内容更加清晰且更具吸引力。这项研究呼吁我们在评估信息来源时更加审慎，并鼓励用户保持警惕和批判性思维。

    

    本文考察了个体对人类作者撰写内容和由大型语言模型生成的内容（如ChatGPT所采用的GPT语言模型系列）的可信度感知，同时比较了不同用户界面版本下的情况。令人惊讶的是，研究结果表明，不论用户界面的呈现形式如何，参与者倾向于赋予相似水平的可信度。尽管参与者对人类和AI生成内容的能力和值得信赖程度没有不同的感知，但他们认为AI生成的内容更加清晰且更具吸引力。这项研究的发现呼吁我们在评估信息来源时采取更加审慎的方式，鼓励用户在接触由AI系统生成的内容时保持警惕和批判性思维。

    This paper examines how individuals perceive the credibility of content originating from human authors versus content generated by large language models, like the GPT language model family that powers ChatGPT, in different user interface versions. Surprisingly, our results demonstrate that regardless of the user interface presentation, participants tend to attribute similar levels of credibility. While participants also do not report any different perceptions of competence and trustworthiness between human and AI-generated content, they rate AI-generated content as being clearer and more engaging. The findings from this study serve as a call for a more discerning approach to evaluating information sources, encouraging users to exercise caution and critical thinking when engaging with content generated by AI systems.
    
[^62]: 用深度生成模型增强语义通信 - ICASSP特别会议概述

    Enhancing Semantic Communication with Deep Generative Models -- An ICASSP Special Session Overview. (arXiv:2309.02478v1 [cs.LG])

    [http://arxiv.org/abs/2309.02478](http://arxiv.org/abs/2309.02478)

    用深度生成模型增强语义通信，解决从复杂数据中提取语义信息和处理通道干扰的挑战。

    

    语义通信在塑造未来的人工智能驱动通信系统中将发挥重要作用。从机器学习的角度揭示了语义通信面临的挑战，并揭示了深度生成模型如何在处理复杂数据、提取和利用语义信息以及对通道干扰具有鲁棒性方面显著增强语义通信框架。除了建立这个新兴领域，本文还为下一代生成语义通信框架的新研究途径做了规划。

    Semantic communication is poised to play a pivotal role in shaping the landscape of future AI-driven communication systems. Its challenge of extracting semantic information from the original complex content and regenerating semantically consistent data at the receiver, possibly being robust to channel corruptions, can be addressed with deep generative models. This ICASSP special session overview paper discloses the semantic communication challenges from the machine learning perspective and unveils how deep generative models will significantly enhance semantic communication frameworks in dealing with real-world complex data, extracting and exploiting semantic information, and being robust to channel corruptions. Alongside establishing this emerging field, this paper charts novel research pathways for the next generative semantic communication frameworks.
    
[^63]: 模仿学习综述：算法、最新进展与挑战

    A Survey of Imitation Learning: Algorithms, Recent Developments, and Challenges. (arXiv:2309.02473v1 [cs.LG])

    [http://arxiv.org/abs/2309.02473](http://arxiv.org/abs/2309.02473)

    这篇论文综述了模仿学习的算法、最新进展和挑战，指出在复杂和非结构化的环境中，通过模仿专家行为来学习所需行为更具吸引力。

    

    近年来，机器人和人工智能系统的发展令人瞩目。随着这些系统的不断演进，它们越来越被应用于复杂和非结构化的环境中，如自动驾驶、空中机器人和自然语言处理。由于这些环境需要高度的灵活性和适应性，因此手动编程行为或通过奖励函数来定义行为（如强化学习中的做法）变得非常困难。在这样的环境中，通过模仿专家行为来学习更具吸引力。这就是模仿学习的作用 - 通过模仿专家的行为来学习所期望的行为，而这些行为是通过演示提供的。

    In recent years, the development of robotics and artificial intelligence (AI) systems has been nothing short of remarkable. As these systems continue to evolve, they are being utilized in increasingly complex and unstructured environments, such as autonomous driving, aerial robotics, and natural language processing. As a consequence, programming their behaviors manually or defining their behavior through reward functions (as done in reinforcement learning (RL)) has become exceedingly difficult. This is because such environments require a high degree of flexibility and adaptability, making it challenging to specify an optimal set of rules or reward signals that can account for all possible situations. In such environments, learning from an expert's behavior through imitation is often more appealing. This is where imitation learning (IL) comes into play - a process where desired behavior is learned by imitating an expert's behavior, which is provided through demonstrations.  This paper a
    
[^64]: 面向增材制造的基础AI模型：用于G代码调试、操作和理解的语言模型

    Towards Foundational AI Models for Additive Manufacturing: Language Models for G-Code Debugging, Manipulation, and Comprehension. (arXiv:2309.02465v1 [cs.SE])

    [http://arxiv.org/abs/2309.02465](http://arxiv.org/abs/2309.02465)

    本文针对三维打印的G代码文件提出了六种基础大型语言模型（LLMs），通过评估它们在G代码调试和操作方面的性能，包括错误检测和修正以及几何变换等。结果表明这些模型具有潜力应用于增材制造领域。

    

    三维打印或增材制造是一项革命性的技术，它可以从数字模型中创建物理对象。然而，三维打印的质量和准确性取决于G代码的正确性和效率，G代码是一种低级数控编程语言，指导三维打印机如何移动和挤出材料。调试G代码是一项具有挑战性的任务，它需要对G代码格式和所打印零件的几何形状的语法和语义理解。在本文中，我们对六种最先进的基础大型语言模型（LLMs）进行了首次广泛评估，用于理解和调试三维打印的G代码文件。我们设计了有效的提示，使预训练的LLMs能够理解和操作G代码，并在G代码调试和操作的各个方面，包括检测和修正常见错误以及执行几何变换方面测试了它们的性能。我们对它们的优点进行了分析。

    3D printing or additive manufacturing is a revolutionary technology that enables the creation of physical objects from digital models. However, the quality and accuracy of 3D printing depend on the correctness and efficiency of the G-code, a low-level numerical control programming language that instructs 3D printers how to move and extrude material. Debugging G-code is a challenging task that requires a syntactic and semantic understanding of the G-code format and the geometry of the part to be printed. In this paper, we present the first extensive evaluation of six state-of-the-art foundational large language models (LLMs) for comprehending and debugging G-code files for 3D printing. We design effective prompts to enable pre-trained LLMs to understand and manipulate G-code and test their performance on various aspects of G-code debugging and manipulation, including detection and correction of common errors and the ability to perform geometric transformations. We analyze their strength
    
[^65]: 有效的多图神经网络用于加密货币交易网络上的非法账户检测

    Effective Multi-Graph Neural Networks for Illicit Account Detection on Cryptocurrency Transaction Networks. (arXiv:2309.02460v1 [cs.LG])

    [http://arxiv.org/abs/2309.02460](http://arxiv.org/abs/2309.02460)

    本文介绍了一种新颖的多图神经网络模型DIAM，用于有效地检测加密货币交易网络上的非法账户。该模型通过自动学习节点表示并保留平行边的内在交易模式，在大型交易网络中取得了良好的效果。

    

    我们研究了在线金融市场中日益重要的加密货币交易网络上的非法账户检测。在加密货币上的非法活动激增导致了普通用户数十亿的损失。现有的解决方案要么依赖于繁琐的特征工程来获得手工特征，要么不能充分利用加密货币交易数据中丰富的语义信息，从而导致亚优化的性能。在本文中，我们将非法账户检测问题定义为带有边属性的有向多图上的分类任务，并提出了DIAM，一种新颖的多图神经网络模型，用于在大型交易网络上有效地检测非法账户。首先，DIAM包含一个Edge2Seq模块，通过同时考虑边属性和有向边序列依赖关系，自动学习有效的节点表示，保留平行边的内在交易模式。然后利用t

    We study illicit account detection on transaction networks of cryptocurrencies that are increasi_testngly important in online financial markets. The surge of illicit activities on cryptocurrencies has resulted in billions of losses from normal users. Existing solutions either rely on tedious feature engineering to get handcrafted features, or are inadequate to fully utilize the rich semantics of cryptocurrency transaction data, and consequently, yield sub-optimal performance. In this paper, we formulate the illicit account detection problem as a classification task over directed multigraphs with edge attributes, and present DIAM, a novel multi-graph neural network model to effectively detect illicit accounts on large transaction networks. First, DIAM includes an Edge2Seq module that automatically learns effective node representations preserving intrinsic transaction patterns of parallel edges, by considering both edge attributes and directed edge sequence dependencies. Then utilizing t
    
[^66]: 走向节俭的无监督医学影像微小异常检测

    Towards frugal unsupervised detection of subtle abnormalities in medical imaging. (arXiv:2309.02458v1 [eess.IV])

    [http://arxiv.org/abs/2309.02458](http://arxiv.org/abs/2309.02458)

    本文研究了无监督医学影像微小异常检测的节俭方法，通过使用概率分布混合模型来代替人工神经网络，实现了在准确度和计算需求之间的最优权衡。

    

    在没有异常标注的情况下，医学影像的异常检测是一个具有挑战性的任务。这个问题可以通过无监督的异常检测方法来解决，该方法可以识别与正常模型不匹配的特征。虽然人工神经网络在无监督异常检测中被广泛使用，但它们通常不能在准确度和计算需求之间实现最优的权衡。作为一种替代方案，我们研究了概率分布混合模型，其在各种数据和任务中的多功能性得到广泛认可，并且不需要过多设计和调整。它们的表达能力使它们成为解释复杂多元参考模型的良好选择。它们的参数数量更小，更容易解释和学习。然而，标准的估计算法（如期望最大化算法）在大数据量下不易扩展。

    Anomaly detection in medical imaging is a challenging task in contexts where abnormalities are not annotated. This problem can be addressed through unsupervised anomaly detection (UAD) methods, which identify features that do not match with a reference model of normal profiles. Artificial neural networks have been extensively used for UAD but they do not generally achieve an optimal trade-o$\hookleftarrow$ between accuracy and computational demand. As an alternative, we investigate mixtures of probability distributions whose versatility has been widely recognized for a variety of data and tasks, while not requiring excessive design e$\hookleftarrow$ort or tuning. Their expressivity makes them good candidates to account for complex multivariate reference models. Their much smaller number of parameters makes them more amenable to interpretation and e cient learning. However, standard estimation procedures, such as the Expectation-Maximization algorithm, do not scale well to large data vo
    
[^67]: 观察局部，全局分类：使用图神经网络识别稀疏矩阵结构

    Observe Locally, Classify Globally: Using GNNs to Identify Sparse Matrix Structure. (arXiv:2309.02442v1 [math.NA])

    [http://arxiv.org/abs/2309.02442](http://arxiv.org/abs/2309.02442)

    使用图神经网络识别稀疏矩阵结构的框架在匹配数据格式和避免读取整个数据集的挑战中取得了成功。

    

    稀疏矩阵计算的性能高度依赖于矩阵格式与要计算的数据的底层结构的匹配。不同的稀疏矩阵格式适用于不同的数据结构。因此，首要挑战是在计算之前识别矩阵结构，以将其与适当的数据格式相匹配。第二个挑战是避免在对数据进行分类之前读取整个数据集。这可以通过识别矩阵结构通过样本及其特征来实现。然而，全局特征可能无法从一个采样集中确定，而必须从局部特征中推断出来。为了应对这些挑战，我们开发了一个使用图卷积网络生成稀疏矩阵结构分类器的框架。该框架还可以通过用户提供的生成器扩展到其他矩阵结构。该方法在一组代表性稀疏矩阵上实现了97%的分类准确率。

    The performance of sparse matrix computation highly depends on the matching of the matrix format with the underlying structure of the data being computed on. Different sparse matrix formats are suitable for different structures of data. Therefore, the first challenge is identifying the matrix structure before the computation to match it with an appropriate data format. The second challenge is to avoid reading the entire dataset before classifying it. This can be done by identifying the matrix structure through samples and their features. Yet, it is possible that global features cannot be determined from a sampling set and must instead be inferred from local features. To address these challenges, we develop a framework that generates sparse matrix structure classifiers using graph convolutional networks. The framework can also be extended to other matrix structures using user-provided generators. The approach achieves 97% classification accuracy on a set of representative sparse matrix 
    
[^68]: 神经群体在中枢神经系统中的信息处理：数据和操作的数学结构

    Information Processing by Neuron Populations in the Central Nervous System: Mathematical Structure of Data and Operations. (arXiv:2309.02332v1 [q-bio.NC] CROSS LISTED)

    [http://arxiv.org/abs/2309.02332](http://arxiv.org/abs/2309.02332)

    神经群体在中枢神经系统中使用数学结构精确地表示和操作信息，实现了特化、泛化、新奇检测等多种功能。

    

    在哺乳动物中枢神经系统的复杂结构中，神经元形成群体。轴索束通过脉冲列作为媒介在这些群集之间进行通信。然而，这些神经群体的精确编码和操作还有待发现。在我们的分析中，出发点是一个具有可塑性的通用神经元的先进的机械模型。从这个简单的框架中出现了一个深刻的数学构造：通过有限凸锥的代数可以准确地描述信息的表示和操作。此外，这些神经群体不仅仅是被动传输者。它们在这个代数结构中扮演着运算符的角色，反映了低级编程语言的功能。当这些群体互连时，它们具有简洁而强大的代数表达式。这些网络使它们能够实现许多操作，如特化、泛化、新奇检测、维度降低等。

    In the intricate architecture of the mammalian central nervous system, neurons form populations. Axonal bundles communicate between these clusters using spike trains as their medium. However, these neuron populations' precise encoding and operations have yet to be discovered. In our analysis, the starting point is a state-of-the-art mechanistic model of a generic neuron endowed with plasticity. From this simple framework emerges a profound mathematical construct: The representation and manipulation of information can be precisely characterized by an algebra of finite convex cones. Furthermore, these neuron populations are not merely passive transmitters. They act as operators within this algebraic structure, mirroring the functionality of a low-level programming language. When these populations interconnect, they embody succinct yet potent algebraic expressions. These networks allow them to implement many operations, such as specialization, generalization, novelty detection, dimensiona
    
[^69]: FSD: 一份用于歌曲深度伪造检测的初步中文数据集

    FSD: An Initial Chinese Dataset for Fake Song Detection. (arXiv:2309.02232v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2309.02232](http://arxiv.org/abs/2309.02232)

    本论文中，我们首次构建了一个用于研究歌曲深度伪造检测的中文数据集，并发现现有训练于语音的DeepFake检测模型在此任务上不起作用。

    

    唱歌声音合成和转换技术的快速发展使得音乐体验得到了革命性的提升。然而，由这些技术生成的“Deepfake Songs”的兴起引发了对真实性的关注。与音频DeepFake检测（ADD）不同，歌曲深度伪造检测领域缺乏专门的数据集或方法用于歌曲真实性的验证。本文中，我们首次构建了一个用于研究歌曲深度伪造检测领域的中文Fake Song Detection (FSD)数据集。FSD数据集中的伪造歌曲由五种最先进的唱歌声音合成和转换方法生成。我们在FSD上的初步实验揭示了现有训练于语音的ADD模型在歌曲深度伪造检测任务上的不有效性。因此，我们利用FSD数据集对ADD模型进行训练。随后，我们在两种情况下对这些模型进行评估：一种是使用原始歌曲，另一种是使用分离的人声音轨。实验结果表明

    Singing voice synthesis and singing voice conversion have significantly advanced, revolutionizing musical experiences. However, the rise of "Deepfake Songs" generated by these technologies raises concerns about authenticity. Unlike Audio DeepFake Detection (ADD), the field of song deepfake detection lacks specialized datasets or methods for song authenticity verification. In this paper, we initially construct a Chinese Fake Song Detection (FSD) dataset to investigate the field of song deepfake detection. The fake songs in the FSD dataset are generated by five state-of-the-art singing voice synthesis and singing voice conversion methods. Our initial experiments on FSD revealed the ineffectiveness of existing speech-trained ADD models for the task of song deepFake detection. Thus, we employ the FSD dataset for the training of ADD models. We subsequently evaluate these models under two scenarios: one with the original songs and another with separated vocal tracks. Experiment results show 
    
[^70]: CodeApex：用于大型语言模型的双语编程评估基准

    CodeApex: A Bilingual Programming Evaluation Benchmark for Large Language Models. (arXiv:2309.01940v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2309.01940](http://arxiv.org/abs/2309.01940)

    CodeApex是一个双语编程评估基准，用于评估大型语言模型在编程理解和代码生成任务上的能力。该基准包括多个选择题和算法问题，评估了14个LLM的编程能力，并发现仍有改进空间。

    

    随着大型语言模型（LLM）的出现，模型的编程能力得到了显著提升，吸引了研究人员日益增长的关注。我们提出了CodeApex，一种双语基准数据集，专注于LLM的编程理解和代码生成能力。CodeApex包括三种类型的多项选择题：概念理解、常识推理和多跳推理，旨在评估LLM在编程理解任务上的能力。此外，CodeApex利用算法问题和相应的测试用例来评估LLM生成的代码质量。我们评估了14个最先进的LLM，包括通用和专门化模型。GPT展现出最佳的编程能力，在这两个任务上的准确率分别达到了约50%和56%。编程任务仍有很大的改进空间。我们希望CodeApex能够为评估编程能力提供参考。

    With the emergence of Large Language Models (LLMs), there has been a significant improvement in the programming capabilities of models, attracting growing attention from researchers. We propose CodeApex, a bilingual benchmark dataset focusing on the programming comprehension and code generation abilities of LLMs. CodeApex comprises three types of multiple-choice questions: conceptual understanding, commonsense reasoning, and multi-hop reasoning, designed to evaluate LLMs on programming comprehension tasks. Additionally, CodeApex utilizes algorithmic questions and corresponding test cases to assess the code quality generated by LLMs. We evaluate 14 state-of-the-art LLMs, including both general-purpose and specialized models. GPT exhibits the best programming capabilities, achieving approximate accuracies of 50% and 56% on the two tasks, respectively. There is still significant room for improvement in programming tasks. We hope that CodeApex can serve as a reference for evaluating the co
    
[^71]: 在无知识环境下，对基于查询的高效攻击机器学习型安卓恶意软件检测方法

    Efficient Query-Based Attack against ML-Based Android Malware Detection under Zero Knowledge Setting. (arXiv:2309.01866v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2309.01866](http://arxiv.org/abs/2309.01866)

    本论文介绍了一种在无知识环境下高效的基于查询的攻击框架，针对机器学习型安卓恶意软件检测方法。对各种主流方法和杀毒软件进行了广泛评估，结果表明该框架具有强大的攻击效果。

    

    安卓操作系统的广泛应用使得恶意安卓应用成为攻击者的吸引目标。基于机器学习（ML）的安卓恶意软件检测方法在解决这个问题上至关重要；然而，它们对对抗性样本的脆弱性引起了关注。目前对ML-based AMD方法的攻击表现出卓越的性能，但是这些攻击依赖于在实际场景中可能不现实的强假设，例如特征空间、模型参数和训练数据集的知识需求。为了解决这个限制，我们引入了AdvDroidZero，一种对ML-based AMD方法的高效查询式攻击框架，在无知识环境下工作。我们的广泛评估表明，AdvDroidZero对各种主流ML-based AMD方法具有很强的攻击效果，特别是最先进的方法和实际的杀毒软件解决方案。

    The widespread adoption of the Android operating system has made malicious Android applications an appealing target for attackers. Machine learning-based (ML-based) Android malware detection (AMD) methods are crucial in addressing this problem; however, their vulnerability to adversarial examples raises concerns. Current attacks against ML-based AMD methods demonstrate remarkable performance but rely on strong assumptions that may not be realistic in real-world scenarios, e.g., the knowledge requirements about feature space, model parameters, and training dataset. To address this limitation, we introduce AdvDroidZero, an efficient query-based attack framework against ML-based AMD methods that operates under the zero knowledge setting. Our extensive evaluation shows that AdvDroidZero is effective against various mainstream ML-based AMD methods, in particular, state-of-the-art such methods and real-world antivirus solutions.
    
[^72]: 神经奇异黑塞矩阵：通过强制奇异黑塞矩阵隐式表示无定向点云

    Neural-Singular-Hessian: Implicit Neural Representation of Unoriented Point Clouds by Enforcing Singular Hessian. (arXiv:2309.01793v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2309.01793](http://arxiv.org/abs/2309.01793)

    本研究提出了一种神经奇异黑塞矩阵的方法，通过强制神经隐式函数的黑塞矩阵在靠近表面的点上具有零行列式，从质量较差的无定向点云中重构高保真的形状。

    

    神经隐式表示是从点云重构表面的一种有希望的方法。现有的方法结合了各种正则化项，如Eikonal和Laplacian能量项，以强制学习的神经函数具有有符号距离函数(SDF)的特性。然而，从质量较差的无定向点云中推断出潜在表面的实际拓扑和几何仍然具有挑战性。根据微分几何，在围绕表面的微分薄壳空间内，SDF的黑塞矩阵是奇异的。我们的方法强制神经隐式函数的黑塞矩阵在靠近表面的点上具有零行列式。这种技术对于近表面点及其在表面上投影点对齐梯度，仅需几次迭代即可生成粗略但忠实的形状。通过逐渐降低奇异黑塞矩阵项的权重，我们的方法最终产生高保真的重建。

    Neural implicit representation is a promising approach for reconstructing surfaces from point clouds. Existing methods combine various regularization terms, such as the Eikonal and Laplacian energy terms, to enforce the learned neural function to possess the properties of a Signed Distance Function (SDF). However, inferring the actual topology and geometry of the underlying surface from poor-quality unoriented point clouds remains challenging. In accordance with Differential Geometry, the Hessian of the SDF is singular for points within the differential thin-shell space surrounding the surface. Our approach enforces the Hessian of the neural implicit function to have a zero determinant for points near the surface. This technique aligns the gradients for a near-surface point and its on-surface projection point, producing a rough but faithful shape within just a few iterations. By annealing the weight of the singular-Hessian term, our approach ultimately produces a high-fidelity reconstr
    
[^73]: 内存高效的具有4位状态的优化器

    Memory Efficient Optimizers with 4-bit States. (arXiv:2309.01507v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2309.01507](http://arxiv.org/abs/2309.01507)

    本论文通过将优化器状态的位宽压缩至4位，实现了内存高效的训练神经网络。通过对一阶和二阶矩的详细经验分析，我们发现当前的块状量化方法无法准确近似复杂的异常值模式。为此，我们使用较小的块大小并同时利用行上和列上的信息进行更好的量化。此外，我们还通过排除零点的线性量化器解决了量化第二阶矩时的零点问题。我们的工作在多个基准测试上进行了评估，结果表明我们的4位优化器具有出色的性能。

    

    优化器状态是训练神经网络时的主要内存消耗来源，限制了在给定内存预算内可训练的最大模型。将优化器状态从32位浮点数压缩到更低的位宽有望减小训练内存占用，而当前最低可达到的位宽为8位。在这项工作中，我们通过详细的经验分析将优化器状态位宽降至4位。具体而言，我们发现矩具有复杂的异常值模式，无法通过当前的块状量化方法准确近似。我们使用较小的块大小，并提出同时利用行上和列上的信息进行更好的量化。我们还发现了量化第二阶矩时的零点问题，并通过排除零点的线性量化器来解决这个问题。我们的4位优化器在包括自然语言理解、机器翻译在内的各种基准测试上进行了评估。

    Optimizer states are a major source of memory consumption for training neural networks, limiting the maximum trainable model within given memory budget. Compressing the optimizer states from 32-bit floating points to lower bitwidth is promising to reduce the training memory footprint, while the current lowest achievable bitwidth is 8-bit. In this work, we push optimizer states bitwidth down to 4-bit through a detailed empirical analysis of first and second moments. Specifically, we find that moments have complicated outlier patterns, that current block-wise quantization cannot accurately approximate. We use a smaller block size and propose to utilize both row-wise and column-wise information for better quantization. We further identify a zero point problem of quantizing the second moment, and solve this problem with a linear quantizer that excludes the zero point. Our 4-bit optimizer is evaluated on a wide variety of benchmarks including natural language understanding, machine translat
    
[^74]: 优化的时间金字塔压缩和放大变换器用于3D人体姿势估计

    Refined Temporal Pyramidal Compression-and-Amplification Transformer for 3D Human Pose Estimation. (arXiv:2309.01365v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2309.01365](http://arxiv.org/abs/2309.01365)

    通过优化的时间金字塔压缩和放大变换器，该论文提出了一种在视频序列中准确估计人体3D姿势的方法。该方法通过扩展时间建模和细化特征交互来解决其他方法中的细节和稳定性问题，展示了较好的效果。

    

    在视频序列中准确估计人体的3D姿势需要准确性和良好的结构化架构。基于transformer的成功，我们引入了优化的时间金字塔压缩和放大（RTPCA）变换器。RTPCA通过其时间金字塔压缩和放大（TPCA）结构扩展了块内时间建模，并通过交叉层细化（XLR）模块细化块间特征交互。特别地，TPCA块利用时间金字塔范例，增强关键和值表示能力，并从运动序列中无缝提取空间语义。我们将这些TPCA块与XLR连接起来，通过连续的查询、关键字和值的相互作用促进丰富的语义表示。这种策略通过当前流程体现了早期信息，解决了其他基于Transformer方法中常见的细节和稳定性不足。我们展示了改进后的模型在3D人体姿势估计上的效果。

    Accurately estimating the 3D pose of humans in video sequences requires both accuracy and a well-structured architecture. With the success of transformers, we introduce the Refined Temporal Pyramidal Compression-and-Amplification (RTPCA) transformer. Exploiting the temporal dimension, RTPCA extends intra-block temporal modeling via its Temporal Pyramidal Compression-and-Amplification (TPCA) structure and refines inter-block feature interaction with a Cross-Layer Refinement (XLR) module. In particular, TPCA block exploits a temporal pyramid paradigm, reinforcing key and value representation capabilities and seamlessly extracting spatial semantics from motion sequences. We stitch these TPCA blocks with XLR that promotes rich semantic representation through continuous interaction of queries, keys, and values. This strategy embodies early-stage information with current flows, addressing typical deficits in detail and stability seen in other transformer-based methods. We demonstrate the eff
    
[^75]: 可分离哈密顿神经网络

    Separable Hamiltonian Neural Networks. (arXiv:2309.01069v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2309.01069](http://arxiv.org/abs/2309.01069)

    这篇论文介绍了可分离哈密顿神经网络的应用，它通过嵌入可加性分离性来解决高维哈密顿系统中的复杂性问题。

    

    利用离散观测数据建模动力系统是现代科学和工程数据系统面临的挑战之一。 哈密顿系统是一类基本且广泛存在的动力系统。 哈密顿神经网络是最先进的模型，可以在汉密尔顿方程的学习偏差下，从离散观测的向量场中无监督地回归动力系统的哈密顿量。然而，哈密顿动力学通常很复杂，特别是在高维情况下，其中哈密顿系统的状态空间相对于样本数量是很大的。 最近发现的一种缓解状态变量之间复杂性的方法是利用哈密顿系统的可加性分离性，并将该可加性分离性嵌入哈密顿神经网络中。根据物理学驱动的机器学习的术语，我们提出了三种可分离的哈密顿神经网络。这些模型嵌入了可加性分离性。

    The modelling of dynamical systems from discrete observations is a challenge faced by modern scientific and engineering data systems. Hamiltonian systems are one such fundamental and ubiquitous class of dynamical systems. Hamiltonian neural networks are state-of-the-art models that unsupervised-ly regress the Hamiltonian of a dynamical system from discrete observations of its vector field under the learning bias of Hamilton's equations. Yet Hamiltonian dynamics are often complicated, especially in higher dimensions where the state space of the Hamiltonian system is large relative to the number of samples. A recently discovered remedy to alleviate the complexity between state variables in the state space is to leverage the additive separability of the Hamiltonian system and embed that additive separability into the Hamiltonian neural network. Following the nomenclature of physics-informed machine learning, we propose three separable Hamiltonian neural networks. These models embed additi
    
[^76]: CPSP: 从音素监督中学习语音概念

    CPSP: Learning Speech Concepts From Phoneme Supervision. (arXiv:2309.00424v1 [eess.AS])

    [http://arxiv.org/abs/2309.00424](http://arxiv.org/abs/2309.00424)

    论文提出了一种名为CPSP的方法，通过对比学习来从语音中提取细粒度的中间表示，使得提取的信息既包含语言内容又去除了发言人身份和声学细节，适用于TTS、VC和ASR等任务。

    

    对于诸如最小监督的文本转语音（TTS）、语音转换（VC）和自动语音识别（ASR）等细粒度生成和识别任务，从语音中提取的中间表示应包含介于文本编码和声学编码之间的信息。语言内容突出，而发言人身份和声学细节等语音信息应该被去除。然而，现有的从语音中提取细粒度中间表示的方法存在冗余性过高和维度爆炸的问题。此外，音频领域中现有的对比学习方法主要关注提取用于下游音频分类任务的全局描述信息，不适合TTS、VC和ASR任务。为了解决这些问题，我们提出了一种名为对比音素-语音预训练（CPSP）的方法，该方法使用三个编码器、一个解码器和对比学习来将音素和语音信息相结合。

    For fine-grained generation and recognition tasks such as minimally-supervised text-to-speech (TTS), voice conversion (VC), and automatic speech recognition (ASR), the intermediate representation extracted from speech should contain information that is between text coding and acoustic coding. The linguistic content is salient, while the paralinguistic information such as speaker identity and acoustic details should be removed. However, existing methods for extracting fine-grained intermediate representations from speech suffer from issues of excessive redundancy and dimension explosion. Additionally, existing contrastive learning methods in the audio field focus on extracting global descriptive information for downstream audio classification tasks, making them unsuitable for TTS, VC, and ASR tasks. To address these issues, we propose a method named Contrastive Phoneme-Speech Pretraining (CPSP), which uses three encoders, one decoder, and contrastive learning to bring phoneme and speech
    
[^77]: StratMed：面向低资源药物推荐的相关性分层方法

    StratMed: Relevance Stratification for Low-resource Medication Recommendation. (arXiv:2308.16781v1 [cs.AI])

    [http://arxiv.org/abs/2308.16781](http://arxiv.org/abs/2308.16781)

    StratMed是一种面向低资源药物推荐的模型，通过相关性分层机制来解决医疗数据长尾分布不平衡的问题，平衡了药物组合的安全性和准确性。

    

    随着有限医疗资源与日益增长的需求之间的失衡，基于人工智能的临床任务变得至关重要。作为一个子领域，药物推荐旨在将患者的纵向历史与医学知识相结合，帮助医生更安全、更准确地开具药物组合处方。现有方法忽视了医疗数据中固有的长尾分布，缺乏头尾数据之间的平衡表示，导致模型性能次优。为了解决这个挑战，我们引入了StratMed，这是一个结合了创新的相关性分层机制的模型。它通过协调数据长尾分布中的差异，并在药物组合的安全性和准确性之间取得平衡。具体而言，我们首先使用深度学习网络构建预训练方法来获取实体表示。然后，我们设计了一个类似金字塔的数据分层方法，以获得更通用的实体表示。

    With the growing imbalance between limited medical resources and escalating demands, AI-based clinical tasks have become paramount. Medication recommendation, as a sub-domain, aims to amalgamate longitudinal patient history with medical knowledge, assisting physicians in prescribing safer and more accurate medication combinations. Existing methods overlook the inherent long-tail distribution in medical data, lacking balanced representation between head and tail data, which leads to sub-optimal model performance. To address this challenge, we introduce StratMed, a model that incorporates an innovative relevance stratification mechanism. It harmonizes discrepancies in data long-tail distribution and strikes a balance between the safety and accuracy of medication combinations. Specifically, we first construct a pre-training method using deep learning networks to obtain entity representation. After that, we design a pyramid-like data stratification method to obtain more generalized entity 
    
[^78]: Socratis：大型多模态模型是否具有情绪意识？

    Socratis: Are large multimodal models emotionally aware?. (arXiv:2308.16741v1 [cs.AI])

    [http://arxiv.org/abs/2308.16741](http://arxiv.org/abs/2308.16741)

    这项研究提出了Socratis，一个新的社会反应基准，用于学习多模态内容的多样化情绪反应。根据人类研究结果，人们更喜欢人工撰写的情感原因，比机器生成的要多2倍以上。

    

    现有的情绪预测基准包含粗糙的情绪标签，不考虑图像和文本在人类中引发多样化情绪的各种原因。学习多样化的对于多模态内容的反应非常重要，因为智能机器在生成和传递内容给社会中起到核心作用。为了填补这一空白，我们提出了Socratis，一个社会反应基准，在其中每个图像-标题（IC）对都附带有多种情绪和感受它们的原因的注释。Socratis包含了来自5个广泛阅读的新闻和图像标题（IC）数据集的2075个图像-标题对的980个情绪的18K个自由形式反应。我们评估了最先进的多模态大型语言模型在给定IC对的情感原因生成方面的能力。根据一个初步的人类研究，我们观察到，人们更喜欢人工撰写的原因，比机器生成的要多2倍以上。

    Existing emotion prediction benchmarks contain coarse emotion labels which do not consider the diversity of emotions that an image and text can elicit in humans due to various reasons. Learning diverse reactions to multimodal content is important as intelligent machines take a central role in generating and delivering content to society. To address this gap, we propose Socratis, a \underline{soc}ietal \underline{r}e\underline{a}c\underline{ti}on\underline{s} benchmark, where each image-caption (IC) pair is annotated with multiple emotions and the reasons for feeling them. Socratis contains 18K free-form reactions for 980 emotions on 2075 image-caption pairs from 5 widely-read news and image-caption (IC) datasets. We benchmark the capability of state-of-the-art multimodal large language models to generate the reasons for feeling an emotion given an IC pair. Based on a preliminary human study, we observe that humans prefer human-written reasons over 2 times more often than machine-genera
    
[^79]: 让LLM能够使用智能手机进行智能任务自动化

    Empowering LLM to use Smartphone for Intelligent Task Automation. (arXiv:2308.15272v1 [cs.AI])

    [http://arxiv.org/abs/2308.15272](http://arxiv.org/abs/2308.15272)

    本论文提出了AutoDroid，一个移动任务自动化系统，可以在任何Android应用程序上自动处理任意任务。它通过结合LLMs的常识知识和应用的领域特定知识来实现，通过自动化的动态分析来实现功能意识的UI表示方法和基于探索的内存注入技术。

    

    移动任务自动化是一种吸引人的技术，旨在实现基于语音的免提用户与智能手机的交互。然而，现有的方法由于语言理解能力有限，以及开发人员或终端用户需要付出非常努力的手动工作而导致可扩展性差。最近大型语言模型（LLMs）在语言理解和推理方面的进展激发了我们从模型中心化的角度重新思考这个问题，即通过统一的语言模型处理任务准备、理解和执行。在这项工作中，我们介绍了AutoDroid，这是一个能够在任何Android应用程序上无需手动工作处理任意任务的移动任务自动化系统。关键洞察力是通过自动化的动态分析将LLMs的常识知识与应用的领域特定知识相结合。主要组件包括功能意识的UI表示方法，桥接了UI和LLM，基于探索的内存注入技术

    Mobile task automation is an attractive technique that aims to enable voice-based hands-free user interaction with smartphones. However, existing approaches suffer from poor scalability due to the limited language understanding ability and the non-trivial manual efforts required from developers or end-users. The recent advance of large language models (LLMs) in language understanding and reasoning inspires us to rethink the problem from a model-centric perspective, where task preparation, comprehension, and execution are handled by a unified language model. In this work, we introduce AutoDroid, a mobile task automation system that can handle arbitrary tasks on any Android application without manual efforts. The key insight is to combine the commonsense knowledge of LLMs and domain-specific knowledge of apps through automated dynamic analysis. The main components include a functionality-aware UI representation method that bridges the UI with the LLM, exploration-based memory injection t
    
[^80]: 冲突感知的主动有限状态机学习

    Conflict-Aware Active Automata Learning. (arXiv:2308.14781v1 [cs.LG])

    [http://arxiv.org/abs/2308.14781](http://arxiv.org/abs/2308.14781)

    C3AL是一种冲突感知的主动有限状态机学习框架，能够处理观测数据中的冲突，通过将观测树作为学习过程的一等公民并最小化测试次数，具有很好的效果。

    

    主动有限状态机学习算法在处理观测数据中的冲突（同一输入对应不同输出）方面存在困难。这种固有的冲突恢复能力不足，影响了它们在存在噪声或学习中的系统变化场景中的有效应用。我们提出了冲突感知的主动有限状态机学习（C3AL）框架，以在学习过程中处理冲突信息。核心思想是将所谓的观测树视为学习过程的一等公民。尽管这个想法在最近的研究中得到了探索，但我们通过将其与任何现有的学习算法结合，并在面对冲突时最小化对正在学习的系统执行的测试次数，充分发挥了它的作用。我们在大量的基准测试中评估了C3AL，涵盖了30多个不同的真实目标和18,000多个不同的场景。评估结果表明，C3AL是一个合适的替代方法。

    Active automata learning algorithms cannot easily handle \emph{conflict} in the observation data (different outputs observed for the same inputs). This inherent inability to recover after a conflict impairs their effective applicability in scenarios where noise is present or the system under learning is mutating.  We propose the Conflict-Aware Active Automata Learning (C3AL) framework to enable handling conflicting information during the learning process. The core idea is to consider the so-called observation tree as a first-class citizen in the learning process. Though this idea is explored in recent work, we take it to its full effect by enabling its use with any existing learner and minimizing the number of tests performed on the system under learning, specially in the face of conflicts. We evaluate C3AL in a large set of benchmarks, covering over 30 different realistic targets, and over 18,000 different scenarios. The results of the evaluation show that C3AL is a suitable alternati
    
[^81]: InstructME:一个基于潜在扩散模型的指导音乐编辑和混音框架

    InstructME: An Instruction Guided Music Edit And Remix Framework with Latent Diffusion Models. (arXiv:2308.14360v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2308.14360](http://arxiv.org/abs/2308.14360)

    InstructME是一个基于潜在扩散模型的指导音乐编辑和混音框架，通过多尺度聚合和引入和弦进展矩阵来保持编辑的一致性和提高旋律和谐性。

    

    音乐编辑主要涉及到修改乐器轨道或整体混音，通过一系列操作为原始作品提供了新颖的重新诠释。这些音乐处理方法在各种应用中具有巨大的潜力，但需要深厚的专业知识。以往的方法虽然对图像和音频修改有效，但直接应用于音乐时存在问题。这归因于音乐的独特数据性质，这些方法可能会无意中破坏音乐的内在和谐一致性。本文介绍了InstructME，一种基于潜在扩散模型的指导音乐编辑和混音框架。我们的框架在编辑之前和之后通过多尺度聚合强化了U-Net以保持一致性。此外，我们引入了和弦进展矩阵作为条件信息，并将其融入语义空间以提高编辑时的旋律和谐性。为了适应外部需求，我们还创新地提出了半监督学习方法来改进混音质量。

    Music editing primarily entails the modification of instrument tracks or remixing in the whole, which offers a novel reinterpretation of the original piece through a series of operations. These music processing methods hold immense potential across various applications but demand substantial expertise. Prior methodologies, although effective for image and audio modifications, falter when directly applied to music. This is attributed to music's distinctive data nature, where such methods can inadvertently compromise the intrinsic harmony and coherence of music. In this paper, we develop InstructME, an Instruction guided Music Editing and remixing framework based on latent diffusion models. Our framework fortifies the U-Net with multi-scale aggregation in order to maintain consistency before and after editing. In addition, we introduce chord progression matrix as condition information and incorporate it in the semantic space to improve melodic harmony while editing. For accommodating ext
    
[^82]: DynED: 数据流分类中的动态集成多样化

    DynED: Dynamic Ensemble Diversification in Data Stream Classification. (arXiv:2308.10807v1 [cs.LG] CROSS LISTED)

    [http://arxiv.org/abs/2308.10807](http://arxiv.org/abs/2308.10807)

    DynED是一种动态集成多样化方法，基于MRR结合了组件的多样性和预测准确性，在数据流环境中实现了更高的准确率。

    

    鉴于数据分布的突变性变化，也称为概念漂移，在数据流环境中实现高准确度是一项具有挑战性的任务。在这种情况下，集合方法被广泛应用于分类，因为它们具有出色的性能。 在集合内部的更大多样性已被证明可以提高预测准确性。尽管集合内组件的多样性很高，但并不是所有组件都像预期的那样对整体性能有所贡献。这需要一种方法来选择展现出高性能和多样性的组件。我们提出了一种基于MMR（最大边际相关性）的新型集合构建和维护方法，在组合集合的过程中动态地结合了组件的多样性和预测准确性。在四个真实和11个合成数据集上的实验结果表明，所提出的方法（DynED）相比于五种最先进的基准方法提供了更高的平均准确率

    Ensemble methods are commonly used in classification due to their remarkable performance. Achieving high accuracy in a data stream environment is a challenging task considering disruptive changes in the data distribution, also known as concept drift. A greater diversity of ensemble components is known to enhance prediction accuracy in such settings. Despite the diversity of components within an ensemble, not all contribute as expected to its overall performance. This necessitates a method for selecting components that exhibit high performance and diversity. We present a novel ensemble construction and maintenance approach based on MMR (Maximal Marginal Relevance) that dynamically combines the diversity and prediction accuracy of components during the process of structuring an ensemble. The experimental results on both four real and 11 synthetic datasets demonstrate that the proposed approach (DynED) provides a higher average mean accuracy compared to the five state-of-the-art baselines
    
[^83]: 第二届自适应网络防御国际研讨会论文集

    Proceedings of the 2nd International Workshop on Adaptive Cyber Defense. (arXiv:2308.09520v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2308.09520](http://arxiv.org/abs/2308.09520)

    第二届自适应网络防御国际研讨会的目标是探索利用人工智能和机器学习作为自适应网络防御基础能力的研究，并通过填补AI和网络研究人员之间的差距来加速开发半自主网络防御系统。

    

    第二届自适应网络防御国际研讨会在佛罗里达理工学院举行，该研讨会旨在分享利用人工智能（AI）和机器学习（ML）作为自适应网络防御基础能力的研究。当前的网络领域无法可靠有效地进行防御，必须广泛依赖人工专家。熟练的网络防御人员供应不足，往往无法及时应对网络威胁。借鉴AI和ML的最新进展，网络防御研究社区被激励着通过将AI和ML技术应用于网络环境中，开发新的动态可持续的防御措施。填补AI和网络研究人员与实践者之间的关键差距可以加速创建能够学习识别和应对网络攻击，或者发现和减轻弱点的半自主网络防御系统的努力。

    The 2nd International Workshop on Adaptive Cyber Defense was held at the Florida Institute of Technology, Florida. This workshop was organized to share research that explores unique applications of Artificial Intelligence (AI) and Machine Learning (ML) as foundational capabilities for the pursuit of adaptive cyber defense. The cyber domain cannot currently be reliably and effectively defended without extensive reliance on human experts. Skilled cyber defenders are in short supply and often cannot respond fast enough to cyber threats.  Building on recent advances in AI and ML the Cyber defense research community has been motivated to develop new dynamic and sustainable defenses through the adoption of AI and ML techniques to cyber settings. Bridging critical gaps between AI and Cyber researchers and practitioners can accelerate efforts to create semi-autonomous cyber defenses that can learn to recognize and respond to cyber attacks or discover and mitigate weaknesses in cooperation with
    
[^84]: 联邦学习：机构机遇、挑战和采用策略

    Federated Learning: Organizational Opportunities, Challenges, and Adoption Strategies. (arXiv:2308.02219v1 [cs.CY])

    [http://arxiv.org/abs/2308.02219](http://arxiv.org/abs/2308.02219)

    本文探讨了联邦学习的技术基础和潜在应用，提出了联邦学习的采用策略框架，并指出联邦学习为商业和信息系统工程学界提供了跨学科研究机会。

    

    在许多行业中，数据共享的限制性规则导致联邦学习的发展。联邦学习是一种机器学习技术，允许分布式客户端合作训练模型，而无需与他人共享其各自的训练数据。本文首先探讨了联邦学习的技术基础和潜在应用。其次，我们提出了一个用于采用联邦学习的概念框架，将组织按照其人工智能能力和环境进行了映射。然后，我们讨论了为什么不同行业的典型组织，包括行业联盟、建立银行、公共机构和数据密集型中小企业可能考虑不同的联邦学习方法。最后，我们认为联邦学习为商业和信息系统工程学界提供了充满跨学科研究机会的机构转变。

    Restrictive rules for data sharing in many industries have led to the development of \ac{FL}. \ac{FL} is a \ac{ML} technique that allows distributed clients to train models collaboratively without the need to share their respective training data with others. In this article, we first explore the technical basics of FL and its potential applications. Second, we present a conceptual framework for the adoption of \ac{FL}, mapping organizations along the lines of their \ac{AI} capabilities and environment. We then discuss why exemplary organizations in different industries, including industry consortia, established banks, public authorities, and data-intensive SMEs might consider different approaches to \ac{FL}. To conclude, we argue that \ac{FL} presents an institutional shift with ample interdisciplinary research opportunities for the business and information systems engineering community.
    
[^85]: 在图嵌入中基于球面和双曲面拓扑的编码应用于Ising MRF模型：经典和量子拓扑机器学习

    Spherical and Hyperbolic Toric Topology-Based Codes On Graph Embedding for Ising MRF Models: Classical and Quantum Topology Machine Learning. (arXiv:2307.15778v1 [cs.IT])

    [http://arxiv.org/abs/2307.15778](http://arxiv.org/abs/2307.15778)

    本论文介绍了在图嵌入中应用信息几何来描述Ising模型的基态，通过利用球面和双曲面拓扑上的编码，建立了机器学习和纠错编码之间的联系，并通过优化纠错码和发展嵌入方法提出了一种新的编码方法。

    

    本文介绍了将信息几何应用于描述Ising模型的基态的方法。通过利用托里克和球面拓扑上的循环和准循环码的奇偶检验矩阵来实现。该方法建立了机器学习和纠错编码之间的联系，特别是在自同构和准循环码循环矩阵的尺寸方面。这种方法对基于捕获集的嵌入方法的发展具有影响。利用统计物理学和数字几何学来优化纠错码，从而导致这些嵌入和稀疏因子化方法的出现。本文通过演示长距离领域的最新DNN架构（ChordMixer，Mega，Mega-chunk，CDIL，...）与特定类型（Cage-graph，Repeat Accumulate）的区块和卷积LDPC码等价的方式，建立了DNN架构和纠错编码之间的直接联系。

    The paper introduces the application of information geometry to describe the ground states of Ising models. This is achieved by utilizing parity-check matrices of cyclic and quasi-cyclic codes on toric and spherical topologies. The approach establishes a connection between machine learning and error-correcting coding, specifically in terms of automorphism and the size of the circulant of the quasi-cyclic code. This proposed approach has implications for the development of new embedding methods based on trapping sets. Statistical physics and number geometry are utilized to optimize error-correcting codes, leading to these embedding and sparse factorization methods. The paper establishes a direct connection between DNN architecture and error-correcting coding by demonstrating how state-of-the-art DNN architectures (ChordMixer, Mega, Mega-chunk, CDIL, ...) from the long-range arena can be equivalent to specific types (Cage-graph, Repeat Accumulate) of block and convolutional LDPC codes. Q
    
[^86]: 朝着可解释的AI在移动数据科学中的应用

    Towards eXplainable AI for Mobility Data Science. (arXiv:2307.08461v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2307.08461](http://arxiv.org/abs/2307.08461)

    本文介绍了朝着可解释的AI在移动数据科学中的应用的工作，包括可解释模型的设计和使用时间图神经网络和反事实来学习从密集轨迹数据中提取信息的方法。

    

    本文介绍了我们正在进行的关于可解释AI在移动数据科学应用中的工作，重点是能够从密集轨迹数据（如车辆和船只的GPS轨迹）中学习的可解释模型，使用时间图神经网络（GNN）和反事实。我们回顾了现有的GeoXAI研究，提出了以人为中心的可理解解释的需求，并勾画出了朝着可解释的AI在移动数据科学中的研究路径。

    This paper presents our ongoing work towards XAI for Mobility Data Science applications, focusing on explainable models that can learn from dense trajectory data, such as GPS tracks of vehicles and vessels using temporal graph neural networks (GNNs) and counterfactuals. We review the existing GeoXAI studies, argue the need for comprehensible explanations with human-centered approaches, and outline a research path toward XAI for Mobility Data Science.
    
[^87]: Fed-CPrompt: 无重复学习的联邦持续学习的对比提示

    Fed-CPrompt: Contrastive Prompt for Rehearsal-Free Federated Continual Learning. (arXiv:2307.04869v1 [cs.LG])

    [http://arxiv.org/abs/2307.04869](http://arxiv.org/abs/2307.04869)

    本文提出了一种名为Fed-CPrompt的方法，用于解决无重复学习的联邦持续学习中的遗忘问题。该方法通过异步提示学习和对比持续损失处理异步任务到达和异构数据分布，并在实验证明其在该领域取得了最先进的性能。

    

    联邦持续学习（FCL）从分布在客户端上的机密数据集中逐步学习任务。本文着重研究无重复学习的FCL，在学习新任务时存在因无法访问历史任务数据而导致严重遗忘的问题。为解决此问题，我们提出了基于提示学习技术的Fed-CPrompt，以一种高效的通信方式获得任务特定的提示。Fed-CPrompt引入了两个关键组件，异步提示学习和对比持续损失，以分别处理FCL中的异步任务到达和异构数据分布。大量实验证明了Fed-CPrompt在实现最先进的无重复学习FCL性能方面的有效性。

    Federated continual learning (FCL) learns incremental tasks over time from confidential datasets distributed across clients. This paper focuses on rehearsal-free FCL, which has severe forgetting issues when learning new tasks due to the lack of access to historical task data. To address this issue, we propose Fed-CPrompt based on prompt learning techniques to obtain task-specific prompts in a communication-efficient way. Fed-CPrompt introduces two key components, asynchronous prompt learning, and contrastive continual loss, to handle asynchronous task arrival and heterogeneous data distributions in FCL, respectively. Extensive experiments demonstrate the effectiveness of Fed-CPrompt in achieving SOTA rehearsal-free FCL performance.
    
[^88]: 深度学习中的损失函数和度量方法：一项评论

    Loss Functions and Metrics in Deep Learning. A Review. (arXiv:2307.02694v1 [cs.LG])

    [http://arxiv.org/abs/2307.02694](http://arxiv.org/abs/2307.02694)

    本文回顾了深度学习中最常见的损失函数和性能测量方法，旨在帮助从业者选择最适合其特定任务的方法。

    

    深度学习的一个重要组成部分是选择用于训练和评估模型的损失函数和性能度量。本文回顾了深度学习中最常见的损失函数和性能测量方法。我们探讨了每种技术的优势和局限性，并举例说明它们在各种深度学习问题上的应用。我们的评论旨在全面了解最常见的深度学习任务中使用的不同损失函数和性能指标，并帮助从业者选择最适合其特定任务的方法。

    One of the essential components of deep learning is the choice of the loss function and performance metrics used to train and evaluate models. This paper reviews the most prevalent loss functions and performance measurements in deep learning. We examine the benefits and limits of each technique and illustrate their application to various deep-learning problems. Our review aims to give a comprehensive picture of the different loss functions and performance indicators used in the most common deep learning tasks and help practitioners choose the best method for their specific task.
    
[^89]: 超越已知现实：利用反事实解释进行医学研究 (arXiv：2307.02131v2 [cs.AI] 已更新)

    Beyond Known Reality: Exploiting Counterfactual Explanations for Medical Research. (arXiv:2307.02131v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2307.02131](http://arxiv.org/abs/2307.02131)

    本研究利用反事实解释来探索医学研究中的“假如”场景，通过提供个性化和情境特定的见解，拓展了我们对现有边界的理解，并填补了机器学习算法结果解释的缺失。

    

    本研究利用反事实解释来探索医学研究中的“假如”场景，旨在拓展我们对现有边界的理解。具体而言，我们重点研究利用磁共振成像特征来诊断儿科后颅窝脑肿瘤。人工智能和可解释性领域已经见证了越来越多的研究和学术兴趣。然而，机器学习算法结果的人类友好解释的缺乏显著阻碍了这些方法在临床实践中的接受度。为了解决这个问题，我们的方法融入了反事实解释，为检查替代决策场景提供了一种新的方式。这些解释提供了个性化和情境特定的见解，使得我们可以验证预测并澄清不同情况下的差异。重要的是，我们的方法同时保持了统计学的可解释性和人类可理解性。

    This study employs counterfactual explanations to explore "what if?" scenarios in medical research, with the aim of expanding our understanding beyond existing boundaries. Specifically, we focus on utilizing MRI features for diagnosing pediatric posterior fossa brain tumors as a case study. The field of artificial intelligence and explainability has witnessed a growing number of studies and increasing scholarly interest. However, the lack of human-friendly interpretations in explaining the outcomes of machine learning algorithms has significantly hindered the acceptance of these methods by clinicians in their clinical practice. To address this, our approach incorporates counterfactual explanations, providing a novel way to examine alternative decision-making scenarios. These explanations offer personalized and context-specific insights, enabling the validation of predictions and clarification of variations under diverse circumstances. Importantly, our approach maintains both statistica
    
[^90]: 策略优化中的乐观性和适应性

    Optimism and Adaptivity in Policy Optimization. (arXiv:2306.10587v1 [cs.LG])

    [http://arxiv.org/abs/2306.10587](http://arxiv.org/abs/2306.10587)

    本文通过将看似无关的策略优化算法重新构造为共同的两个交错步骤，即乐观策略改进和后见适应，统一了强化学习中的策略优化方法，揭示了加速方法中的乐观性和适应性的共同理论属性。

    

    本文致力于通过“乐观性”和“适应性”在强化学习中加速策略优化方法的统一范式。通过利用策略迭代和策略梯度方法之间的深刻联系，我们将一些看似无关的策略优化算法重新构造为两个交错步骤（i）乐观策略改进操作器使用“梯度上升预测”将先前的策略$\pi_t$映射到一个假设$\pi_{t+1}$，然后（ii）对$\pi_{t+1}$的性能进行部分评估，并基于此进行“后见适应”。我们使用这个共享的视角来共同表达其他众所周知的算法，包括软件和乐观策略迭代、自然演员-评论家方法、基于前向搜索的基于模型的策略改进和元学习算法。通过这样做，我们揭示了关于通过乐观性和适应性加速的共同理论属性。

    We work towards a unifying paradigm for accelerating policy optimization methods in reinforcement learning (RL) through \emph{optimism} \& \emph{adaptivity}. Leveraging the deep connection between policy iteration and policy gradient methods, we recast seemingly unrelated policy optimization algorithms as the repeated application of two interleaving steps (i) an \emph{optimistic policy improvement operator} maps a prior policy $\pi_t$ to a hypothesis $\pi_{t+1}$ using a \emph{gradient ascent prediction}, followed by (ii) a \emph{hindsight adaptation} of the optimistic prediction based on a partial evaluation of the performance of $\pi_{t+1}$. We use this shared lens to jointly express other well-known algorithms, including soft and optimistic policy iteration, natural actor-critic methods, model-based policy improvement based on forward search, and meta-learning algorithms. By doing so, we shed light on collective theoretical properties related to acceleration via optimism \& adaptivit
    
[^91]: 高维和置换不变异常检测。

    High-dimensional and Permutation Invariant Anomaly Detection. (arXiv:2306.03933v1 [hep-ph])

    [http://arxiv.org/abs/2306.03933](http://arxiv.org/abs/2306.03933)

    该研究引入了一种置换不变的高维密度估计方法，通过学习后将其用于高能物理数据中的异常检测，能够有效地识别出在仅具备背景假设下排除异常的喷注。

    

    由于学习高维概率密度的困难，新物理过程的异常检测方法通常局限于低维空间。特别是在成分级别上，将置换不变性和可变长度的输入等良好性质合并到流行的密度估计方法中变得更加困难。在本研究中，我们引入了一种基于扩散模型的粒子物理数据置换不变密度估计器，专门设计用于处理可变长度的输入。我们通过将学习到的密度用作置换不变的异常检测评分来展示我们方法的功效，有效地识别出在仅具备背景假设下的可能性较低的喷注。为了验证我们的密度估计方法，我们研究了学习到的密度比与被监督分类算法获得的密度之间的比较。

    Methods for anomaly detection of new physics processes are often limited to low-dimensional spaces due to the difficulty of learning high-dimensional probability densities. Particularly at the constituent level, incorporating desirable properties such as permutation invariance and variable-length inputs becomes difficult within popular density estimation methods. In this work, we introduce a permutation-invariant density estimator for particle physics data based on diffusion models, specifically designed to handle variable-length inputs. We demonstrate the efficacy of our methodology by utilizing the learned density as a permutation-invariant anomaly detection score, effectively identifying jets with low likelihood under the background-only hypothesis. To validate our density estimation method, we investigate the ratio of learned densities and compare to those obtained by a supervised classification algorithm.
    
[^92]: SourceP：使用预训练模型和数据流智能检测以太坊上的智能庞兹骗局

    SourceP: Smart Ponzi Schemes Detection on Ethereum Using Pre-training Model with Data Flow. (arXiv:2306.01665v1 [cs.SE])

    [http://arxiv.org/abs/2306.01665](http://arxiv.org/abs/2306.01665)

    本文提出了一种使用预训练模型和数据流的方法，通过智能合约的源代码特征，实现检测以太坊上的智能庞兹骗局。该方法提高了模型的可解释性和降低了数据获取和特征提取的难度。

    

    随着区块链技术越来越流行，典型的金融骗局庞兹骗局也在区块链平台以太坊上出现。通过智能合约部署的这种庞兹骗局，也称为智能庞兹骗局，已经造成了大量的经济损失和负面影响。现有的以太坊智能庞兹骗局检测方法主要依赖于智能合约的字节码特征、操作码特征、账户特征和交易行为特征，这些方法缺乏可解释性和可持续性。本文提出了SourceP，一种使用预训练模型和数据流在以太坊平台上检测智能庞兹骗局的方法。该方法只需要利用智能合约的源代码作为特征，从另一个角度探索检测智能庞兹骗局的可能性。SourceP降低了现有检测方法的数据获取和特征提取难度，同时增加了模型的可解释性。

    As blockchain technology becomes more and more popular, a typical financial scam, the Ponzi scheme, has also emerged in the blockchain platform Ethereum. This Ponzi scheme deployed through smart contracts, also known as the smart Ponzi scheme, has caused a lot of economic losses and negative impacts. Existing methods for detecting smart Ponzi schemes on Ethereum mainly rely on bytecode features, opcode features, account features, and transaction behavior features of smart contracts, and such methods lack interpretability and sustainability. In this paper, we propose SourceP, a method to detect smart Ponzi schemes on the Ethereum platform using pre-training models and data flow, which only requires using the source code of smart contracts as features to explore the possibility of detecting smart Ponzi schemes from another direction. SourceP reduces the difficulty of data acquisition and feature extraction of existing detection methods while increasing the interpretability of the model. 
    
[^93]: 布局和任务感知的零样本文档图像问答指导模型

    Layout and Task Aware Instruction Prompt for Zero-shot Document Image Question Answering. (arXiv:2306.00526v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.00526](http://arxiv.org/abs/2306.00526)

    该论文提出了一种布局和任务感知的指导提示模型，称为LATIN-Prompt，通过将文档图像问答对齐到现成的指导调优语言基础模型，利用其零样本能力来提高效果。该模型包括布局感知的文档内容和任务感知的描述，能够恢复文本片段之间的布局信息，并生成符合任务需求的答案。

    

    基于布局感知多模态预训练模型的预训练-微调范式在文档图像问答方面取得了显著进展。然而，领域预训练和任务微调对于额外的视觉、布局和任务模块阻止了其直接利用现成的指导调优语言基础模型，而这些模型最近在零样本学习方面显示出了良好的潜力。与将语言模型与文档图像问答领域对齐相反，我们将文档图像问答与现成的指导调优语言基础模型对齐，利用其零样本能力。具体而言，我们提出了布局和任务感知的指导提示模型，称为LATIN-Prompt，它包括布局感知的文档内容和任务感知的描述。前者通过适当的空格和换行符从OCR工具中恢复文本片段之间的布局信息。后者确保模型生成符合任务需求的答案。

    The pre-training-fine-tuning paradigm based on layout-aware multimodal pre-trained models has achieved significant progress on document image question answering. However, domain pre-training and task fine-tuning for additional visual, layout, and task modules prevent them from directly utilizing off-the-shelf instruction-tuning language foundation models, which have recently shown promising potential in zero-shot learning. Contrary to aligning language models to the domain of document image question answering, we align document image question answering to off-the-shell instruction-tuning language foundation models to utilize their zero-shot capability. Specifically, we propose layout and task aware instruction prompt called LATIN-Prompt, which consists of layout-aware document content and task-aware descriptions. The former recovers the layout information among text segments from OCR tools by appropriate spaces and line breaks. The latter ensures that the model generates answers that m
    
[^94]: AnoOnly:无需损失正常数据的半监督异常检测

    AnoOnly: Semi-Supervised Anomaly Detection without Loss on Normal Data. (arXiv:2305.18798v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2305.18798](http://arxiv.org/abs/2305.18798)

    AnoOnly是一个新的半监督异常检测框架，通过引入一种对正常数据的弱监督形式来解决同质数据对异常的影响，以实现平衡的监督。该框架在各种模型和数据集上表现出了显著的性能提升，达到了新的最佳性能。

    

    半监督异常检测(SSAD)方法通过利用少量但有指导作用的异常实例，增强了无监督异常检测(UAD)的效果。然而，同质正常数据对异常的统治使得SSAD模型无法有效地感知异常。为了解决这个问题并在严重不平衡的正常和异常数据之间实现平衡的监督，我们开发了一个名为AnoOnly(仅异常)的新框架。与现有的SSAD方法不同，AnoOnly暂停了严格的损失监督，引入了一种对正常数据的弱监督形式。这种弱监督通过批量归一化实现，隐式地对正常数据进行聚类学习。当集成到现有的SSAD方法中时，所提出的AnoOnly在各种模型和数据集上展示了显著的性能提升，达到了新的最佳性能。此外，我们的A

    Semi-supervised anomaly detection (SSAD) methods have demonstrated their effectiveness in enhancing unsupervised anomaly detection (UAD) by leveraging few-shot but instructive abnormal instances. However, the dominance of homogeneous normal data over anomalies biases the SSAD models against effectively perceiving anomalies. To address this issue and achieve balanced supervision between heavily imbalanced normal and abnormal data, we develop a novel framework called AnoOnly (Anomaly Only). Unlike existing SSAD methods that resort to strict loss supervision, AnoOnly suspends it and introduces a form of weak supervision for normal data. This weak supervision is instantiated through the utilization of batch normalization, which implicitly performs cluster learning on normal data. When integrated into existing SSAD methods, the proposed AnoOnly demonstrates remarkable performance enhancements across various models and datasets, achieving new state-of-the-art performance. Additionally, our A
    
[^95]: 因果结构学习中的未解问题：以英国COVID-19为例研究

    Open problems in causal structure learning: A case study of COVID-19 in the UK. (arXiv:2305.03859v1 [cs.LG])

    [http://arxiv.org/abs/2305.03859](http://arxiv.org/abs/2305.03859)

    本文研究了因果机器学习在COVID-19英国疫情数据中的应用挑战，探讨了不同数据格式对学习类别不同的算法的影响，并突出了因果结构学习中的未解问题和未来研究方向。

    

    因果机器学习算法可以恢复图形结构，从而揭示因果关系。这些算法提供的因果表示使得透明度和可解释性得以实现。然而，与关联性机器学习相比，因果机器学习在实践中的影响有限。本文研究了因果机器学习在COVID-19英国疫情数据中的应用挑战。我们从各种公共来源整合数据，并研究各种结构学习算法从这些数据中学到的内容。我们探讨了不同数据格式对学习类别不同的算法的影响，并评估了每个算法及算法组产生的结果，包括图形结构、模型维度、敏感性分析、混淆变量、预测和干预推断等。我们利用这些结果来突出因果结构学习中的未解问题和未来研究方向。

    Causal machine learning (ML) algorithms recover graphical structures that tell us something about cause-and-effect relationships. The causal representation provided by these algorithms enables transparency and explainability, which is necessary in critical real-world problems. Yet, causal ML has had limited impact in practice compared to associational ML. This paper investigates the challenges of causal ML with application to COVID-19 UK pandemic data. We collate data from various public sources and investigate what the various structure learning algorithms learn from these data. We explore the impact of different data formats on algorithms spanning different classes of learning, and assess the results produced by each algorithm, and groups of algorithms, in terms of graphical structure, model dimensionality, sensitivity analysis, confounding variables, predictive and interventional inference. We use these results to highlight open problems in causal structure learning and directions f
    
[^96]: 生成式隐写扩散

    Generative Steganography Diffusion. (arXiv:2305.03472v1 [cs.MM])

    [http://arxiv.org/abs/2305.03472](http://arxiv.org/abs/2305.03472)

    提出了一种称为“生成式隐写扩散”（GSD）的新型生成式隐写方案，利用一种反演扩散模型可以100％地恢复隐藏的秘密数据，并实现了高质量的隐写图像生成。

    

    生成式隐写术（GS）是一种新兴技术，它直接从秘密数据中生成隐藏信息图像。最近已经开发了基于GAN或Flow的各种GS方法。然而，现有的基于GAN的GS方法由于缺乏网络可逆性，无法完全恢复隐藏的秘密数据，而基于Flow的方法由于每个模块中严格的可逆限制而产生质量较差的图像。为了解决这个问题，我们提出了一种新的GS方案，称为“生成式隐写扩散”（GSD），通过设计一种反演扩散模型“StegoDiffusion”来实现。它不仅生成逼真的隐写图像，而且允许100％地恢复隐藏的秘密数据。所提出的StegoDiffusion模型利用非马尔可夫链和快速采样技术实现高效的隐写图像生成。通过根据StegoDiffusion中的生成过程的转移概率构造一个普通微分方程（ODE），秘密数据和隐写信息可以被有效和可逆地嵌入到隐写图像中。实验结果表明了所提出的GSD方案在隐写图像质量和秘密数据恢复性能方面的有效性。

    Generative steganography (GS) is an emerging technique that generates stego images directly from secret data. Various GS methods based on GANs or Flow have been developed recently. However, existing GAN-based GS methods cannot completely recover the hidden secret data due to the lack of network invertibility, while Flow-based methods produce poor image quality due to the stringent reversibility restriction in each module. To address this issue, we propose a novel GS scheme called "Generative Steganography Diffusion" (GSD) by devising an invertible diffusion model named "StegoDiffusion". It not only generates realistic stego images but also allows for 100\% recovery of the hidden secret data. The proposed StegoDiffusion model leverages a non-Markov chain with a fast sampling technique to achieve efficient stego image generation. By constructing an ordinary differential equation (ODE) based on the transition probability of the generation process in StegoDiffusion, secret data and stego i
    
[^97]: 使用物理训练的神经网络学习非线性本构材料模型：COMM-PINN。

    Learning solution of nonlinear constitutive material models using physics-informed neural networks: COMM-PINN. (arXiv:2304.06044v1 [cs.CE])

    [http://arxiv.org/abs/2304.06044](http://arxiv.org/abs/2304.06044)

    通过物理训练的神经网络可解决非线性材料行为的本构关系，无需初始数据，避免重复的牛顿迭代。训练好的模型可作为有限元程序的用户定义材料模型，但需要解决诸多挑战。

    

    我们使用物理训练的神经网络来解决非线性、路径相关材料行为的本构关系。训练好的网络不仅满足所有热力学约束，而且在任何给定的加载情况下，立即提供关于当前材料状态（即自由能，应力和内部变量的演变）的信息，而不需要初始数据。这项工作的一个优点是它规避了求解复材料模型中非线性方程所需的重复牛顿迭代。此外，我们提供了减少获取切向算子所需的导数次序的策略。训练好的模型可以直接用作任何有限元程序（或其他数值方法）中的用户定义材料模型。然而，在定义配点和整合同时激活或非激活的多个非相等约束方面仍存在挑战。

    We applied physics-informed neural networks to solve the constitutive relations for nonlinear, path-dependent material behavior. As a result, the trained network not only satisfies all thermodynamic constraints but also instantly provides information about the current material state (i.e., free energy, stress, and the evolution of internal variables) under any given loading scenario without requiring initial data. One advantage of this work is that it bypasses the repetitive Newton iterations needed to solve nonlinear equations in complex material models. Additionally, strategies are provided to reduce the required order of derivation for obtaining the tangent operator. The trained model can be directly used in any finite element package (or other numerical methods) as a user-defined material model. However, challenges remain in the proper definition of collocation points and in integrating several non-equality constraints that become active or non-active simultaneously. We tested this
    
[^98]: 文本到图像扩散模型是零样本分类器。

    Text-to-Image Diffusion Models are Zero-Shot Classifiers. (arXiv:2303.15233v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2303.15233](http://arxiv.org/abs/2303.15233)

    文本到图像扩散模型被提出用于零样本分类器，具有竞争性的零样本图像分类表现和先进的形状/纹理偏差测试结果，能够成功执行属性绑定。

    

    文本到图像扩散模型具有优秀的生成能力，这表明它们学习了图像文本数据的信息表达。然而，它们所捕捉的知识尚未被充分理解，且在下游任务上尚未进行深入探索。本文提出了一种评估扩散模型作为零样本分类器的方法。关键思想是利用扩散模型根据标签的文本描述去除噪声图像的能力作为该标签概率的代理。我们将该方法应用于稳定扩散和Imagen，并与CLIP的零样本能力进行对比，探索了模型的知识的细粒度方面。在广泛的零样本图像分类数据集上，他们与CLIP的竞争性表现相当。此外，他们在形状/纹理偏差测试上取得了最先进的结果，并且能够成功执行属性绑定，而CLIP不能。尽管生成性预训练在自然语言处理中很常见，v

    The excellent generative capabilities of text-to-image diffusion models suggest they learn informative representations of image-text data. However, what knowledge their representations capture is not fully understood, and they have not been thoroughly explored on downstream tasks. We investigate diffusion models by proposing a method for evaluating them as zero-shot classifiers. The key idea is using a diffusion model's ability to denoise a noised image given a text description of a label as a proxy for that label's likelihood. We apply our method to Stable Diffusion and Imagen, using it to probe fine-grained aspects of the models' knowledge and comparing them with CLIP's zero-shot abilities. They perform competitively with CLIP on a wide range of zero-shot image classification datasets. Additionally, they achieve state-of-the-art results on shape/texture bias tests and can successfully perform attribute binding while CLIP cannot. Although generative pre-training is prevalent in NLP, v
    
[^99]: TSMixer：一种全MLP架构用于时间序列预测

    TSMixer: An all-MLP Architecture for Time Series Forecasting. (arXiv:2303.06053v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.06053](http://arxiv.org/abs/2303.06053)

    TSMixer是一种通过堆叠多层感知器（MLP）设计的新型结构，基于沿时间和特征维度的混合操作，能够在时间序列预测中表现出极好的性能。

    

    实际时间序列数据集通常是多变量且具有复杂的动态。为了捕获这种复杂性，像循环或基于注意力的顺序深度学习模型这样的高容量结构变得受欢迎。然而，最近的研究表明，简单的单变量线性模型可以在几个常用的学术基准测试中胜过这样的深度学习模型。扩展它们，本文研究线性模型在时间序列预测中的能力，并提出了时序混合器（TSMixer），这是一种通过堆叠多层感知器（MLP）设计的新型结构。 TSMixer基于沿时间和特征维度的混合操作，以有效地提取信息。在流行的学术基准测试上，简单易行的TSMixer与利用特定基准的归纳偏差的专业先进模型相媲美。在具有挑战性和大规模的M5基准测试中，即一个实际的零售数据集上，TSMixer表现出非常出色的性能。

    Real-world time-series datasets are often multivariate with complex dynamics. To capture this complexity, high capacity architectures like recurrent- or attention-based sequential deep learning models have become popular. However, recent work demonstrates that simple univariate linear models can outperform such deep learning models on several commonly used academic benchmarks. Extending them, in this paper, we investigate the capabilities of linear models for time-series forecasting and present Time-Series Mixer (TSMixer), a novel architecture designed by stacking multi-layer perceptrons (MLPs). TSMixer is based on mixing operations along both the time and feature dimensions to extract information efficiently. On popular academic benchmarks, the simple-to-implement TSMixer is comparable to specialized state-of-the-art models that leverage the inductive biases of specific benchmarks. On the challenging and large scale M5 benchmark, a real-world retail dataset, TSMixer demonstrates super
    
[^100]: ChatGPT已在地平线上：大语言模型是否就是我们需要的智能交通解决方案？

    ChatGPT Is on the Horizon: Could a Large Language Model Be All We Need for Intelligent Transportation?. (arXiv:2303.05382v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.05382](http://arxiv.org/abs/2303.05382)

    本文探讨了ChatGPT在解决交通问题方面的应用。通过利用具有跨模态编码器的LLM，可以处理来自不同模态的交通数据并执行交通运营。作者提供了一个基于智能手机的碰撞报告自动生成和分析框架作为用例展示了这种潜力。

    

    ChatGPT是由OpenAI开发的具有60亿参数的重要大语言模型之一。ChatGPT展示了LLM的卓越的语言理解能力，特别是在生成对话响应方面。随着LLM在各种研究或工程领域越来越受到关注，现在是时候设想LLM如何革新我们处理智能交通系统的方式了。本文探讨了LLM在解决关键交通问题方面的未来应用。通过利用具有跨模态编码器的LLM，智能系统还可以处理来自不同模态的交通数据并通过LLM执行交通运营。我们提出并验证了LLM装备的这些潜在的交通应用。为了进一步证明这种潜力，我们还提供了一个具体的基于智能手机的碰撞报告自动生成和分析框架作为用例。尽管存在潜在的益处，但与数据隐私相关的挑战仍然存在。

    ChatGPT, developed by OpenAI, is one of the milestone large language models (LLMs) with 6 billion parameters. ChatGPT has demonstrated the impressive language understanding capability of LLM, particularly in generating conversational response. As LLMs start to gain more attention in various research or engineering domains, it is time to envision how LLM may revolutionize the way we approach intelligent transportation systems. This paper explores the future applications of LLM in addressing key transportation problems. By leveraging LLM with cross-modal encoder, an intelligent system can also process traffic data from different modalities and execute transportation operations through an LLM. We present and validate these potential transportation applications equipped by LLM. To further demonstrate this potential, we also provide a concrete smartphone-based crash report auto-generation and analysis framework as a use case. Despite the potential benefits, challenges related to data privac
    
[^101]: 具有注意融合的动态图卷积网络用于交通流量预测

    Dynamic Graph Convolutional Network with Attention Fusion for Traffic Flow Prediction. (arXiv:2302.12598v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.12598](http://arxiv.org/abs/2302.12598)

    提出了一种用于交通流量预测的具有注意融合的动态图卷积网络，通过增强时间特征维度的交互作用和捕捉多尺度空间-时间依赖关系，以及有效捕捉远距离、多方面领域的空间-时间模式，实现精确且实时的交通状态预测。

    

    精确的实时交通状态预测对于城市交通控制和网络地图服务具有重要的实际意义。在大数据的支持下，深度学习方法在捕捉交通网络的复杂时空模式方面显示出强大的能力。然而，现有方法使用预定义的图和简单的空间-时间组件，难以建模多尺度的空间-时间依赖关系。在本文中，我们提出了一种新颖的动态图卷积网络与注意融合的方法来解决这个问题。该方法首先增强了时间特征维度的交互作用，然后将动态图学习器与GRU相结合，共同建模同步的空间-时间相关性。我们还融入了空间-时间注意模块，以有效捕捉远距离、多方面领域的空间-时间模式。我们在四个真实世界的交通数据集上进行了大量实验，证明了我们的方法的有效性。

    Accurate and real-time traffic state prediction is of great practical importance for urban traffic control and web mapping services. With the support of massive data, deep learning methods have shown their powerful capability in capturing the complex spatialtemporal patterns of traffic networks. However, existing approaches use pre-defined graphs and a simple set of spatial-temporal components, making it difficult to model multi-scale spatial-temporal dependencies. In this paper, we propose a novel dynamic graph convolution network with attention fusion to tackle this gap. The method first enhances the interaction of temporal feature dimensions, and then it combines a dynamic graph learner with GRU to jointly model synchronous spatial-temporal correlations. We also incorporate spatial-temporal attention modules to effectively capture longrange, multifaceted domain spatial-temporal patterns. We conduct extensive experiments in four real-world traffic datasets to demonstrate that our met
    
[^102]: 使用大型语言模型进行自动化单元测试生成的实证评估

    An Empirical Evaluation of Using Large Language Models for Automated Unit Test Generation. (arXiv:2302.06527v3 [cs.SE] UPDATED)

    [http://arxiv.org/abs/2302.06527](http://arxiv.org/abs/2302.06527)

    本研究通过大规模实证评估证明，无需额外训练或手动努力，利用大型语言模型（LLMs）自动化生成单元测试是有效的。实验结果表明LLMs结合函数的签名、实现和文档中的使用示例可以成功生成单元测试，并通过重新提示模型来修复生成失败的测试。

    

    单元测试在确保软件正确性方面起着关键作用。然而，手动创建单元测试是一项费力的任务，这促使自动化的需求。最近，大型语言模型（LLMs）已被应用于解决这个问题，利用对现有测试样例的额外训练或少样本学习。本文对LLMs在无需额外训练或手动努力的情况下自动化生成单元测试的有效性进行了大规模实证评估，为LLM提供被测试函数的签名和实现以及从文档中提取的使用示例。我们还尝试通过重新提示模型使用失败的测试和错误消息来修复生成失败的测试。我们在JavaScript中实现了我们的方法，使用TestPilot作为一个自动为npm软件包中的所有API函数生成单元测试的测试生成工具，并使用OpenAI的gpt3.5-turbo LLM在25个npm软件包上进行了评估，共计1,684个API函数。

    Unit tests play a key role in ensuring the correctness of software. However, manually creating unit tests is a laborious task, motivating the need for automation. Large Language Models (LLMs) have recently been applied to this problem, utilizing additional training or few-shot learning on examples of existing tests. This paper presents a large-scale empirical evaluation on the effectiveness of LLMs for automated unit test generation without additional training or manual effort, providing the LLM with the signature and implementation of the function under test, along with usage examples extracted from documentation. We also attempt to repair failed generated tests by re-prompting the model with the failing test and error message. We implement our approach in TestPilot, a test generation tool for JavaScript that automatically generates unit tests for all API functions in an npm package. We evaluate TestPilot using OpenAI's gpt3.5-turbo LLM on 25 npm packages with a total of 1,684 API fun
    
[^103]: 物理信息神经网络多元素耦合系统和异质域的混合形式

    Mixed formulation of physics-informed neural networks for thermo-mechanically coupled systems and heterogeneous domains. (arXiv:2302.04954v2 [cs.CE] UPDATED)

    [http://arxiv.org/abs/2302.04954](http://arxiv.org/abs/2302.04954)

    本文提出了将混合形式应用于解决多物理问题，特别是稳态热力学耦合方程组的物理信息神经网络方法。

    

    物理信息神经网络（PINNs）是一种通过定义神经网络的损失函数来解决边界值问题的新工具，该损失函数基于控制方程、边界条件和初始条件。最近的研究表明，当设计许多工程问题的损失函数时，使用一阶导数并结合强形式和弱形式的方程可以提高准确性，尤其是在领域中存在异质性和变量跳变的情况下。这种新方法被称为PINNs的混合形式，它借鉴了混合有限元方法的思想。在该方法中，PDE被重新表述为一个方程系统，其中主要未知量是解的通量或梯度，而次要未知量是解本身。在这项工作中，我们提出将混合形式应用于解决多物理问题，特别是稳态热力学耦合方程组。

    Physics-informed neural networks (PINNs) are a new tool for solving boundary value problems by defining loss functions of neural networks based on governing equations, boundary conditions, and initial conditions. Recent investigations have shown that when designing loss functions for many engineering problems, using first-order derivatives and combining equations from both strong and weak forms can lead to much better accuracy, especially when there are heterogeneity and variable jumps in the domain. This new approach is called the mixed formulation for PINNs, which takes ideas from the mixed finite element method. In this method, the PDE is reformulated as a system of equations where the primary unknowns are the fluxes or gradients of the solution, and the secondary unknowns are the solution itself. In this work, we propose applying the mixed formulation to solve multi-physical problems, specifically a stationary thermo-mechanically coupled system of equations. Additionally, we discus
    
[^104]: 通过半监督学习和生成对抗网络在不平衡数据集中进行虚假检测

    Fake detection in imbalance dataset by Semi-supervised learning with GAN. (arXiv:2212.01071v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.01071](http://arxiv.org/abs/2212.01071)

    本文提出了一种在不平衡数据集中使用半监督学习和生成对抗网络进行虚假检测的方法，实验证明仅使用100个标记样本的情况下，准确率达到了91\%。

    

    随着社交媒体的快速发展，骚扰行为变得更加普遍，这导致了虚假检测成为研究人员中引人注目的领域。数据的图形特性以及大量节点导致了许多障碍，包括矩阵中大量无关特征的高离散度和不平衡类别。为了解决这些问题，本文采用了自编码器和半监督学习与生成对抗网络算法的组合，即SGAN。本文将少量标签应用于SGAN作为分类器。实验结果表明，仅使用100个标记样本，该方法在检测虚假账户方面的准确率达到了91\%。

    As social media grows faster, harassment becomes more prevalent which leads to considered fake detection a fascinating field among researchers. The graph nature of data with the large number of nodes caused different obstacles including a considerable amount of unrelated features in matrices as high dispersion and imbalance classes in the dataset. To deal with these issues Auto-encoders and a combination of semi-supervised learning and the GAN algorithm which is called SGAN were used. This paper is deploying a smaller number of labels and applying SGAN as a classifier. The result of this test showed that the accuracy had reached 91\% in detecting fake accounts using only 100 labeled samples.
    
[^105]: 在联合设置中面向隐私感知的因果结构学习的探索

    Towards Privacy-Aware Causal Structure Learning in Federated Setting. (arXiv:2211.06919v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.06919](http://arxiv.org/abs/2211.06919)

    本文研究了在联合设置中隐私感知因果结构学习的问题，并提出了一种新的联邦PC（FedPC）算法，通过两种新策略保护数据隐私。

    

    因果结构学习在机器学习和各种应用中得到了广泛研究和应用。为了达到理想的性能，现有的因果结构学习算法通常需要将来自多个数据源的大量数据集中在一起。然而，在隐私保护的设置中，不可能将所有数据集中并放在一个数据集中。为了保护数据隐私，联邦学习作为一种新的学习范式在近年来在机器学习中引起了广泛关注。在本文中，我们研究了联合设置中的隐私感知因果结构学习问题，并提出了一种新的联邦PC（FedPC）算法，采用两种新策略来保护数据隐私而不集中数据。具体而言，我们首先提出了一种新的逐层聚合策略，将PC算法平稳地适应到联邦学习范式中，以实现联合骨架学习，然后我们设计了一种有效的策略。

    Causal structure learning has been extensively studied and widely used in machine learning and various applications. To achieve an ideal performance, existing causal structure learning algorithms often need to centralize a large amount of data from multiple data sources. However, in the privacy-preserving setting, it is impossible to centralize data from all sources and put them together as a single dataset. To preserve data privacy, federated learning as a new learning paradigm has attracted much attention in machine learning in recent years. In this paper, we study a privacy-aware causal structure learning problem in the federated setting and propose a novel Federated PC (FedPC) algorithm with two new strategies for preserving data privacy without centralizing data. Specifically, we first propose a novel layer-wise aggregation strategy for a seamless adaptation of the PC algorithm into the federated learning paradigm for federated skeleton learning, then we design an effective strate
    
[^106]: 加密货币交易对的最优设置

    Optimal Settings for Cryptocurrency Trading Pairs. (arXiv:2210.10971v2 [q-fin.TR] UPDATED)

    [http://arxiv.org/abs/2210.10971](http://arxiv.org/abs/2210.10971)

    本文研究了加密货币交易对的最优设置问题，并提出了一个两阶段过程来解决这个优化问题。该问题的特殊之处在于大部分可能的交易对之间的交易量无法直接观察，且需要满足连通性约束。

    

    加密货币的目标是去中心化，所有货币原则上地位相等。与传统股市不同，没有默认的货币单位（法币），因此可以自由设置交易对。然而，为每两种货币之间建立一个交易市场是不切实际的。为了控制管理成本并确保足够的流动性，我们必须优先考虑那些大量交易的交易对，并确保所有货币都是可以交易的。我们注意到这是一个优化问题，其特殊之处在于：1）大部分（>99.5%）可能的交易对之间的交易量无法直接观察。2）它满足连通性约束，即保证所有货币都可以交易。为了解决这个问题，我们采用了一个两阶段的过程：1）基于正则化的截断特征值分解填充缺失值，其中正则化项用于控制缺失值被限制为零的程度。

    The goal of cryptocurrencies is decentralization. In principle, all currencies have equal status. Unlike traditional stock markets, there is no default currency of denomination (fiat), thus the trading pairs can be set freely. However, it is impractical to set up a trading market between every two currencies. In order to control management costs and ensure sufficient liquidity, we must give priority to covering those large-volume trading pairs and ensure that all coins are reachable. We note that this is an optimization problem. Its particularity lies in: 1) the trading volume between most (>99.5%) possible trading pairs cannot be directly observed. 2) It satisfies the connectivity constraint, that is, all currencies are guaranteed to be tradable.  To solve this problem, we use a two-stage process: 1) Fill in missing values based on a regularized, truncated eigenvalue decomposition, where the regularization term is used to control what extent missing values should be limited to zero. 2
    
[^107]: jsdp: 一个Java随机动态规划库。

    jsdp: a Java Stochastic Dynamic Programming Library. (arXiv:2209.09979v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2209.09979](http://arxiv.org/abs/2209.09979)

    jsdp是一个Java库，通过利用Java中的lambda表达式、函数接口、集合和聚合运算符，实现了对随机动态规划问题的建模和求解。

    

    随机规划是一种用于建模和解决不确定性决策问题的框架。随机动态规划是随机规划的一个分支，采用“函数方程”方法来发现最优策略。通过利用Java中实现的lambda表达式、函数接口、集合和聚合运算符来操作MapReduce框架，jsdp提供了一个通用的库，用于建模和解决随机动态规划问题。

    Stochastic Programming is a framework for modelling and solving problems of decision making under uncertainty. Stochastic Dynamic Programming is a branch of Stochastic Programming that takes a "functional equation" approach to the discovery of optimal policies. By leveraging constructs - lambda expressions, functional interfaces, collections and aggregate operators - implemented in Java to operationalise the MapReduce framework, jsdp provides a general purpose library for modelling and solving Stochastic Dynamic Programs.
    
[^108]: 统一贝叶斯框架用于多准则决策问题

    Unified Bayesian Frameworks for Multi-criteria Decision-making Problems. (arXiv:2208.13390v4 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2208.13390](http://arxiv.org/abs/2208.13390)

    本文引入了贝叶斯框架解决多准则决策问题，在团体决策问题和准则相关性方面提供了统计优雅的解决方案，适应了不同形式的决策者偏好，开发了识别决策者子群的混合模型，并设计了评估准则和备选方案相对重要性的概率排序方案。

    

    本文引入了贝叶斯框架来解决多准则决策问题的各个方面，利用概率解释多准则决策方法和挑战。通过利用贝叶斯模型的灵活性，提出的框架为多准则决策问题中的关键挑战，如团体决策问题和准则相关性，提供了统计优雅的解决方案。此外，这些模型可以适应决策者偏好中各种形式的不确定性，包括正态分布、三角分布和区间偏好。为了解决大规模团体多准则决策场景，开发了一个概率混合模型，可以识别出一致的决策者子群。此外，设计了一个概率排序方案，根据决策者偏好评估准则和备选方案的相对重要性。通过在各种数值示例上实验，验证了提出的框架，证明了它们的有效性。

    This paper introduces Bayesian frameworks for tackling various aspects of multi-criteria decision-making (MCDM) problems, leveraging a probabilistic interpretation of MCDM methods and challenges. By harnessing the flexibility of Bayesian models, the proposed frameworks offer statistically elegant solutions to key challenges in MCDM, such as group decision-making problems and criteria correlation. Additionally, these models can accommodate diverse forms of uncertainty in decision makers' (DMs) preferences, including normal and triangular distributions, as well as interval preferences. To address large-scale group MCDM scenarios, a probabilistic mixture model is developed, enabling the identification of homogeneous subgroups of DMs. Furthermore, a probabilistic ranking scheme is devised to assess the relative importance of criteria and alternatives based on DM(s) preferences. Through experimentation on various numerical examples, the proposed frameworks are validated, demonstrating their
    
[^109]: 基于骨骼的动作识别的生成式动作描述提示

    Generative Action Description Prompts for Skeleton-based Action Recognition. (arXiv:2208.05318v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2208.05318](http://arxiv.org/abs/2208.05318)

    本文提出了一种基于骨骼的动作识别的生成式动作描述提示（GAP）方法，利用预训练的语言模型自动生成动作的身体部位运动的文本描述，并采用多模态训练方案。

    

    基于骨骼的动作识别近年来受到了相当大的关注。目前的基于骨骼的动作识别方法通常被定义为单热分类任务，并没有充分利用动作之间的语义关系。例如，“做胜利手势”和“竖起大拇指”是手势的两种动作，其主要区别在于手部的运动。这些信息与动作类别的单热编码无关，但可以从动作描述中揭示出来。因此，在训练中利用动作描述可能有助于表示学习。在这项工作中，我们提出了一种基于骨骼的动作识别的生成式动作描述提示（GAP）方法。具体而言，我们使用预训练的大规模语言模型作为知识引擎，自动生成动作的身体部位运动的文本描述，并提出了一种多模态训练方案，利用文本编码器。

    Skeleton-based action recognition has recently received considerable attention. Current approaches to skeleton-based action recognition are typically formulated as one-hot classification tasks and do not fully exploit the semantic relations between actions. For example, "make victory sign" and "thumb up" are two actions of hand gestures, whose major difference lies in the movement of hands. This information is agnostic from the categorical one-hot encoding of action classes but could be unveiled from the action description. Therefore, utilizing action description in training could potentially benefit representation learning. In this work, we propose a Generative Action-description Prompts (GAP) approach for skeleton-based action recognition. More specifically, we employ a pre-trained large-scale language model as the knowledge engine to automatically generate text descriptions for body parts movements of actions, and propose a multi-modal training scheme by utilizing the text encoder t
    
[^110]: 基于处理内存系统的机器学习训练的实验评估

    An Experimental Evaluation of Machine Learning Training on a Real Processing-in-Memory System. (arXiv:2207.07886v2 [cs.AR] UPDATED)

    [http://arxiv.org/abs/2207.07886](http://arxiv.org/abs/2207.07886)

    该研究评估了在处理内存系统上训练机器学习算法的潜能，并证明基于PIM的ML训练实现了显着的加速和能量效率。

    

    训练机器学习算法是一种计算密集型的过程，由于不断访问大型训练数据集，这种过程通常会受到内存限制。因此，以处理器为中心的系统（例如CPU，GPU）在内存单元和处理单元之间的数据传输方面存在昂贵的瓶颈，这会消耗大量的能量和执行周期。具有处理内存（PIM）功能的内存中心计算系统可以缓解这种数据移动瓶颈。我们的目标是了解现代通用PIM架构加速ML训练的潜力。为此，我们（1）在实际通用PIM架构上实现了几种代表性的传统ML算法（即线性回归，逻辑回归，决策树，K-Means聚类），（2）严格评估和表征这些算法的准确性，性能和扩展性，并且（3）与它们在CPU和GPU上的相应实现进行比较。我们在实际内存中心计算平台上的评估表明，与相应的CPU和GPU方法相比，基于PIM的ML训练实现了显着的加速和能量效率。

    Training machine learning (ML) algorithms is a computationally intensive process, which is frequently memory-bound due to repeatedly accessing large training datasets. As a result, processor-centric systems (e.g., CPU, GPU) suffer from costly data movement between memory units and processing units, which consumes large amounts of energy and execution cycles. Memory-centric computing systems, i.e., with processing-in-memory (PIM) capabilities, can alleviate this data movement bottleneck.  Our goal is to understand the potential of modern general-purpose PIM architectures to accelerate ML training. To do so, we (1) implement several representative classic ML algorithms (namely, linear regression, logistic regression, decision tree, K-Means clustering) on a real-world general-purpose PIM architecture, (2) rigorously evaluate and characterize them in terms of accuracy, performance and scaling, and (3) compare to their counterpart implementations on CPU and GPU. Our evaluation on a real mem
    
[^111]: Neural-IMLS: 用于表面重建的自监督隐式移动最小二乘网络

    Neural-IMLS: Self-supervised Implicit Moving Least-Squares Network for Surface Reconstruction. (arXiv:2109.04398v4 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2109.04398](http://arxiv.org/abs/2109.04398)

    Neural-IMLS是一种自监督的方法，能够从未定向的原始点云中学习抗噪声的有符号距离函数，实现准确的表面重建。

    

    当输入的点云，特别是真实扫描的点云存在噪声且缺乏法线时，表面重建非常具有挑战性。我们观察到多层感知器（MLP）和隐式移动最小二乘函数（IMLS）提供了底层表面的双重表示，因此我们引入了Neural-IMLS，一种新颖的方法，它直接从未定向原始点云中自监督地学习抗噪声的有符号距离函数（SDF）。我们使用IMLS来正则化MLP报告的距离值，同时使用MLP来正则化数据点的法线以运行IMLS。我们还证明，在收敛时，我们的神经网络由于MLP和IMLS之间的相互学习机制，能够产生一个忠实的SDF，其零级集近似于底层表面。我们对各种基准进行了大量实验，包括合成扫描和真实扫描。实验结果表明，Neural-IMLS可以进行准确的表面重建。

    Surface reconstruction is very challenging when the input point clouds, particularly real scans, are noisy and lack normals. Observing that the Multilayer Perceptron (MLP) and the implicit moving least-square function (IMLS) provide a dual representation of the underlying surface, we introduce Neural-IMLS, a novel approach that directly learns the noise-resistant signed distance function (SDF) from unoriented raw point clouds in a self-supervised fashion. We use the IMLS to regularize the distance values reported by the MLP while using the MLP to regularize the normals of the data points for running the IMLS. We also prove that at the convergence, our neural network, benefiting from the mutual learning mechanism between the MLP and the IMLS, produces a faithful SDF whose zero-level set approximates the underlying surface. We conducted extensive experiments on various benchmarks, including synthetic scans and real scans. The experimental results show that {\em Neural-IMLS} can reconstru
    
[^112]: 用因果学习解释黑箱预测算法的行为

    Explaining the Behavior of Black-Box Prediction Algorithms with Causal Learning. (arXiv:2006.02482v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2006.02482](http://arxiv.org/abs/2006.02482)

    本文提出了一种用于解释黑箱预测算法行为的因果学习方法，通过学习因果图表示来提供因果解释，弥补了现有方法的缺点，即解释单元更加可解释且考虑了宏观级特征和未测量的混淆。

    

    因果学方法在解释黑箱预测模型（例如基于图像像素数据训练的深度神经网络）方面越来越受欢迎。然而，现有方法存在两个重要缺点：（i）“解释单元”是相关预测模型的微观级输入，例如图像像素，而不是更有用于理解如何可能改变算法行为的可解释的宏观级特征；（ii）现有方法假设特征与目标模型预测之间不存在未测量的混淆，这在解释单元是宏观级变量时不成立。我们关注的是在分析人员无法访问目标预测算法内部工作原理的重要情况，而只能根据特定输入查询模型输出的能力。为了在这种情况下提供因果解释，我们提出学习因果图表示，允许更好地理解算法的行为。

    Causal approaches to post-hoc explainability for black-box prediction models (e.g., deep neural networks trained on image pixel data) have become increasingly popular. However, existing approaches have two important shortcomings: (i) the "explanatory units" are micro-level inputs into the relevant prediction model, e.g., image pixels, rather than interpretable macro-level features that are more useful for understanding how to possibly change the algorithm's behavior, and (ii) existing approaches assume there exists no unmeasured confounding between features and target model predictions, which fails to hold when the explanatory units are macro-level variables. Our focus is on the important setting where the analyst has no access to the inner workings of the target prediction algorithm, rather only the ability to query the output of the model in response to a particular input. To provide causal explanations in such a setting, we propose to learn causal graphical representations that allo
    

