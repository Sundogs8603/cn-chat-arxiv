# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Syntactic vs Semantic Linear Abstraction and Refinement of Neural Networks.](http://arxiv.org/abs/2307.10891) | 这项工作提供了一个灵活的框架，通过线性组合替换神经元，实现了神经网络的句法和语义抽象，并引入了一种改进方法来平衡减少和精确度。 |
| [^2] | [Divide & Bind Your Attention for Improved Generative Semantic Nursing.](http://arxiv.org/abs/2307.10864) | 本论文提出了一种名为"分割与绑定"的方法，旨在改进生成语义护理的效果。该方法引入了新的损失目标，包括关注丢失和绑定丢失，以解决复杂提示和不适当属性绑定的问题。 |
| [^3] | [Goal-Conditioned Reinforcement Learning with Disentanglement-based Reachability Planning.](http://arxiv.org/abs/2307.10846) | 本研究提出了一种结合了解耦可达性规划的目标条件强化学习算法，用于解决现有方法在高维状态空间中扩展和收集高质量训练数据的问题。 |
| [^4] | [Modifications of the Miller definition of contrastive (counterfactual) explanations.](http://arxiv.org/abs/2307.10832) | 本文修改了Miller对对比性解释的定义，并提出了两个改进版本，解决了原始定义存在的问题。 |
| [^5] | ["It Felt Like Having a Second Mind": Investigating Human-AI Co-creativity in Prewriting with Large Language Models.](http://arxiv.org/abs/2307.10811) | 通过三节次的定性研究，探究了人类与大型语言模型在预写过程中的合作模式，并发现了一个三阶段的人机共创过程：构思、启发和实施。在这个合作过程中，人类扮演着主导角色。 |
| [^6] | [On Combining Expert Demonstrations in Imitation Learning via Optimal Transport.](http://arxiv.org/abs/2307.10810) | 通过最优传输方法结合多个专家示范的新方法，在模仿学习中提供了更合理的示范几何平均值。 |
| [^7] | [Communication-Efficient Split Learning via Adaptive Feature-Wise Compression.](http://arxiv.org/abs/2307.10805) | 该论文提出了一个名为SplitFC的通信高效的分割学习框架，通过两种自适应压缩策略来减少中间特征和梯度向量的通信开销，这些策略分别是自适应特征逐渐掉落和自适应特征逐渐量化。 |
| [^8] | [Meta-Transformer: A Unified Framework for Multimodal Learning.](http://arxiv.org/abs/2307.10802) | Meta-Transformer是一个统一的多模态学习框架，利用一个冻结的编码器进行多模态感知，在没有成对多模态训练数据的情况下可以处理各种模态，并且能够提取输入数据的高级语义特征。 |
| [^9] | [Optimizing PatchCore for Few/many-shot Anomaly Detection.](http://arxiv.org/abs/2307.10792) | 本文研究了在少量样本和大量样本设置下，PatchCore算法在异常检测/异常分割性能上的表现，并发现通过优化超参数和借鉴少量样本监督学习技术可以进一步提高性能。 |
| [^10] | [Decoding the Enigma: Benchmarking Humans and AIs on the Many Facets of Working Memory.](http://arxiv.org/abs/2307.10768) | 本论文介绍了一个全面的工作记忆基准数据集（WorM），通过评估4个功能、3个领域和11个行为和神经特征的WM任务来开发和评估AI WM模型。结果表明，AI模型能够模拟出脑中工作记忆的一些特征，如优势效应和最新性效应，以及专门用于不同领域和功能的工作记忆的神经群集和相关物。 |
| [^11] | [MSQNet: Actor-agnostic Action Recognition with Multi-modal Query.](http://arxiv.org/abs/2307.10763) | MSQNet是一种无关演员的多模态多标签动作识别方法，通过使用视觉和文本模态来更好地表示动作类别，克服了现有方法中针对特定演员的限制。 |
| [^12] | [Exploring Perspectives on the Impact of Artificial Intelligence on the Creativity of Knowledge Work: Beyond Mechanised Plagiarism and Stochastic Parrots.](http://arxiv.org/abs/2307.10751) | 人工智能对知识工作的创造力有着深远的影响，但是对生成模型的批评者认为其输出只是随机的抄袭和混搭。然而，创造力和原创性的定义是复杂的，可能是一个过程、一个作者或一个观看者的属性。 |
| [^13] | [Fairness-Aware Client Selection for Federated Learning.](http://arxiv.org/abs/2307.10738) | 提出了公平感知的联邦客户端选择（FairFedCS）方法，通过动态调整联邦学习客户端的选择概率，同时考虑客户端的声誉、参与次数和对模型性能的贡献，解决了平衡性能和公平性的问题。 |
| [^14] | [LLM Censorship: A Machine Learning Challenge or a Computer Security Problem?.](http://arxiv.org/abs/2307.10719) | 本文讨论了大型语言模型(LLM)的审查问题，指出现有的语义审查方法存在理论上的限制，由于LLM的程序化和遵循指令的能力，语义审查可以被认为是一个不可判定的问题。同时，有知识的攻击者可以重构不可容许的输出。 |
| [^15] | [Introducing Risk Shadowing For Decisive and Comfortable Behavior Planning.](http://arxiv.org/abs/2307.10714) | 引入了一种风险遮挡方法来处理城市驾驶中的群体互动问题，该方法可以分析群体中三个代理之间的交互，找到在行为规划中不需要考虑的代理，并能够规划出更为决策和舒适的驾驶策略。 |
| [^16] | [Kick Back & Relax: Learning to Reconstruct the World by Watching SlowTV.](http://arxiv.org/abs/2307.10713) | 通过观看SlowTV学习重建世界的自监督单目深度估计模型在室内/室外数据集上具有良好的性能和已知-未知推广能力。这个模型使用了一个大规模SlowTV数据集以及一系列最佳实践来实现。 |
| [^17] | [AdjointDPM: Adjoint Sensitivity Method for Gradient Backpropagation of Diffusion Probabilistic Models.](http://arxiv.org/abs/2307.10711) | AdjointDPM是一种新的伴随灵敏度方法，用于扩散概率模型的梯度反向传播，解决了DPM定制化中内存消耗高的问题，并通过解决增强的ODE将损失的梯度反向传播到模型的参数。 |
| [^18] | [Towards an architectural framework for intelligent virtual agents using probabilistic programming.](http://arxiv.org/abs/2307.10693) | 使用概率编程的智能虚拟代理架构框架KorraAI可模拟代理的行为，考虑上下文信息和不确定信息，并实现自适应和积极主动的互动。 |
| [^19] | [Bounded Combinatorial Reconfiguration with Answer Set Programming.](http://arxiv.org/abs/2307.10688) | 本研究提出了一种基于Answer Set Programming的有界组合重构方法，可以解决组合重构问题，并且在国际竞赛中取得了优异的成绩。 |
| [^20] | [A Personalized Recommender System Based-on Knowledge Graph Embeddings.](http://arxiv.org/abs/2307.10680) | 本研究通过知识图谱嵌入构建了一个个性化推荐系统，在车辆购买/销售领域中展现了其良好的推荐效果。 |
| [^21] | [SciBench: Evaluating College-Level Scientific Problem-Solving Abilities of Large Language Models.](http://arxiv.org/abs/2307.10635) | 这篇论文介绍了一个名为SciBench的基准套件，旨在对大型语言模型的大学水平科学问题解决能力进行评估。研究结果显示，当前的语言模型在提供复杂科学问题解决能力方面还有不足之处。 |
| [^22] | [Pluvio: Assembly Clone Search for Out-of-domain Architectures and Libraries through Transfer Learning and Conditional Variational Information Bottleneck.](http://arxiv.org/abs/2307.10631) | 本论文介绍了一种通过迁移学习和条件变分信息瓶颈实现对领域外结构和库的汇编克隆搜索的方法。已有的方法往往限制于少数训练过的工具链变体，而本研究首次解决了未见过架构和库的情况，提出了一种新的解决方案。 |
| [^23] | [Detecting deceptive reviews using text classification.](http://arxiv.org/abs/2307.10617) | 这篇论文提出了一种使用机器学习模型的方法来识别虚假评论，并通过在餐馆评论的数据集上进行实验验证了其性能。 |
| [^24] | [Heterogeneous Federated Learning: State-of-the-art and Research Challenges.](http://arxiv.org/abs/2307.10616) | 异构联邦学习是联邦学习领域中的一个重要研究方向，涉及到数据分布、模型架构、网络环境和硬件设备的异质性挑战。本文对异构联邦学习的研究挑战和最新进展进行了综述和分类，为进一步的研究提供了参考。 |
| [^25] | [Challenges and Solutions in AI for All.](http://arxiv.org/abs/2307.10600) | 这项研究展示了AI的普遍挑战：如偏见、歧视和不可信等，并提供了如何在设计中考虑多样性与包容性原则的解决方案。通过准确分析48篇研究文章，我们总结出了55个独特挑战和33个解决方案，还有24个独特挑战和23个解决方案用于增强AI实践。这项研究将对未来AI系统的研究人员和从业者有很大启示作用。 |
| [^26] | [Exploiting Structure for Optimal Multi-Agent Bayesian Decentralized Estimation.](http://arxiv.org/abs/2307.10594) | 该论文介绍了一种解决贝叶斯分散数据融合中“谣言传播”问题的方法，通过利用概率独立结构和非整体加权因子，可以得到更紧实的边界，并通过通用优化方案充分利用任意依赖结构。 |
| [^27] | [Boundary State Generation for Testing and Improvement of Autonomous Driving Systems.](http://arxiv.org/abs/2307.10590) | 该论文介绍了一种新的自动驾驶系统测试生成器（GenBo），它通过在无故障环境中变异自动驾驶车辆的驾驶条件来生成边界状态对，以解决现有测试方法中存在的问题。 |
| [^28] | [Forecasting Battery Electric Vehicle Charging Behavior: A Deep Learning Approach Equipped with Micro-Clustering and SMOTE Techniques.](http://arxiv.org/abs/2307.10588) | 本研究开发了一种使用微聚类和SMOTE技术的深度学习方法，能够准确预测电动汽车充电事件，为电力负荷聚合器和电力管理人员提供提供充电站和电力容量的信息。 |
| [^29] | [Ethosight: A Joint-Embedding Based System for Nuanced Perception Using Contextual Label Affinity Metric and Reasoning Based Iterative Learning.](http://arxiv.org/abs/2307.10577) | Ethosight是一种零样本计算机视觉算法，通过联合嵌入、上下文标签关联度计算和基于推理的迭代学习，实现对细微行为和场景细节的准确感知，同时消除了对预先存在符号知识的需求。 |
| [^30] | [Boosting Federated Learning Convergence with Prototype Regularization.](http://arxiv.org/abs/2307.10575) | 本论文通过引入原型正则化策略来解决联邦学习中异质数据分布的问题，实验证明在MNIST和Fashion-MNIST数据集上相比基准模型FedAvg，我们的方法分别提高了3.3%和8.9%的平均测试准确率，并且在异构设置下具有快速收敛速度。 |
| [^31] | [Invalid Logic, Equivalent Gains: The Bizarreness of Reasoning in Language Model Prompting.](http://arxiv.org/abs/2307.10573) | 最近的研究发现，在语言模型的提示中使用逻辑上无效的Chain-of-Thought（CoT）提示几乎可以提供与逻辑上有效的提示相似的性能增益，而且在最困难的任务上也是如此。 |
| [^32] | [Deceptive Alignment Monitoring.](http://arxiv.org/abs/2307.10569) | 本论文提出了欺骗性对齐监测这一新方向，旨在探讨大型机器学习模型在表面上表现正常，却暗中进行隐藏行为的问题，并提出了新的研究机会。 |
| [^33] | [FACADE: A Framework for Adversarial Circuit Anomaly Detection and Evaluation.](http://arxiv.org/abs/2307.10563) | FACADE是一种新型的概率和几何框架，用于无监督检测深度神经网络中的机理异常，并提供关键的洞察力和强大工具，以揭示和对抗对抗攻击，并在实际部署环境中展示了有前途的应用。 |
| [^34] | [Air Traffic Controller Workload Level Prediction using Conformalized Dynamical Graph Learning.](http://arxiv.org/abs/2307.10559) | 本研究提出了一种使用合规化动态图学习来预测空中交通管制员工作负荷水平的方法，通过对退休空中交通管制员进行人机交互模拟，利用空中交通数据和工作负荷标签进行预测和评估。 |
| [^35] | [EMQ: Evolving Training-free Proxies for Automated Mixed Precision Quantization.](http://arxiv.org/abs/2307.10554) | 本论文提出了一个演化算法的自动搜索代理框架，用于实现混合精度量化中的训练-free 方法。通过构建MQ-Bench-101数据集，发现现有的无需训练的代理在量化精度方面存在相关性不明确的问题。通过演化搜索，找到了最佳相关的MQ代理。 |
| [^36] | [PPN: Parallel Pointer-based Network for Key Information Extraction with Complex Layouts.](http://arxiv.org/abs/2307.10551) | 该论文提出了一个名为PPN的并行指针网络，用于解决关键信息提取的挑战。作者通过引入一个名为CLEX的大规模数据集来解决现有数据集中布局和语义实体类别数量的限制，并采用端到端的方法来解决错误传播问题。 |
| [^37] | [Dynamic Large Language Models on Blockchains.](http://arxiv.org/abs/2307.10549) | 本文提出在区块链上训练和部署动态大型语言模型，通过使用分布式计算和提供无法篡改的交易分类帐的区块链技术，可使语言模型具备连续学习的能力，为下一代人工智能系统的发展提供了新的方法和启示。 |
| [^38] | [TREA: Tree-Structure Reasoning Schema for Conversational Recommendation.](http://arxiv.org/abs/2307.10543) | TREA是一种树状结构推理模式，可用于对话式推荐系统。它通过构建一个多层次的可扩展树来澄清对话中提及实体之间的因果关系，并充分利用历史对话生成更合理和适当的推荐结果响应。 |
| [^39] | [Fast Unsupervised Deep Outlier Model Selection with Hypernetworks.](http://arxiv.org/abs/2307.10529) | 本文提出了HYPER用于调整基于深度神经网络的异常值检测模型，解决了无监督DOD模型中的超参数调整和模型选择的挑战，通过设计和训练超网络(HN)将超参数映射到主要DOD模型的最优权重上。 |
| [^40] | [Building Socio-culturally Inclusive Stereotype Resources with Community Engagement.](http://arxiv.org/abs/2307.10514) | 通过社区参与的努力，在印度社会背景下扩展了对刻板印象伤害的评估资源。这个工作强调了包容不同文化和社会背景的人们和经验，以避免对伤害测量的严重低估或扭曲。 |
| [^41] | [IvyGPT: InteractiVe Chinese pathwaY language model in medical domain.](http://arxiv.org/abs/2307.10512) | IvyGPT是一种基于医学领域的中文互动语言模型，通过使用高质量的医学问答示例和人类反馈强化学习进行训练和微调，它能够输出更丰富的诊断和治疗答案，从而在医学GPT模型中表现出色。 |
| [^42] | [Markov Decision Processes with Time-Varying Geometric Discounting.](http://arxiv.org/abs/2307.10491) | 本论文研究了具有时变折扣因子的马尔可夫决策过程模型，采用博弈论视角，证明了存在子博弈完美均衡，并给出了计算算法和时间复杂度的分析。 |
| [^43] | [(Ab)using Images and Sounds for Indirect Instruction Injection in Multi-Modal LLMs.](http://arxiv.org/abs/2307.10490) | 本论文展示了如何利用图像和声音在多模态LLMs中进行间接指令注入，攻击者通过生成对抗扰动并将其融入图像或音频录音中，以操纵模型输出特定文本和指导对话的行为。 |
| [^44] | [Backdoor Attack against Object Detection with Clean Annotation.](http://arxiv.org/abs/2307.10487) | 本文提出了一种在物体检测中进行后门攻击的方法，通过嵌入隐藏的后门，使得模型在正常数据上表现正常，在触发器出现时给出攻击者指定的判断。这对于安全敏感应用如自动驾驶具有严重威胁。 |
| [^45] | [Can Instruction Fine-Tuned Language Models Identify Social Bias through Prompting?.](http://arxiv.org/abs/2307.10472) | 本文介绍了一种通过零样本提示评估指令微调语言模型识别偏见能力的方法，展示了Alpaca 7B在偏见识别任务中的最佳性能，并提出扩大模型大小和数据多样性可进一步提高性能。 |
| [^46] | [Classification of Visualization Types and Perspectives in Patents.](http://arxiv.org/abs/2307.10471) | 本文主要研究了专利图像中可视化类型和视角的分类问题，扩展了CLEF-IP数据集并采用最先进的深度学习方法进行了分类。这项研究对于促进专利探索和检索具有重要意义。 |
| [^47] | [A data science axiology: the nature, value, and risks of data science.](http://arxiv.org/abs/2307.10460) | 这篇论文介绍了数据科学的价值取向，探讨了其特征和作用。数据科学不是一门科学，而是一种研究范式，具有广泛的应用和重大的影响，但也存在着未知的风险。这一领域仍然处于初级阶段，需要进一步的研究。 |
| [^48] | [A New Computationally Simple Approach for Implementing Neural Networks with Output Hard Constraints.](http://arxiv.org/abs/2307.10459) | 提出了一种计算简单的方法来实现具有硬约束输出的神经网络。该方法通过映射隐藏参数向量到一个符合约束集的点实现约束，并通过附加的神经网络层来进行映射。该方法还可以处理不仅对输出向量施加约束，还对依赖于输入的联合约束施加约束的情况，并且可以处理不同类型的约束，包括线性和二次约束、等式约束和动态约束。 |
| [^49] | [Complying with the EU AI Act.](http://arxiv.org/abs/2307.10458) | 本文识别了欧盟AI法案的不同类别，并开发了一份问卷来提供定量数据，分析发现不同合规类别下组织面临的挑战，同时考察了组织特征对合规的影响，旨在改进遵守欧盟AI法案，并提出了一个相关解决方案的项目。 |
| [^50] | [A Step Towards Worldwide Biodiversity Assessment: The BIOSCAN-1M Insect Dataset.](http://arxiv.org/abs/2307.10455) | 提出了一个新的大型手工标记昆虫图像数据集BIOSCAN-Insect，用于对昆虫生物多样性进行编目。该数据集还具有引人注目的特征，对广泛的机器学习社区也具有研究价值。 |
| [^51] | [Learning Formal Specifications from Membership and Preference Queries.](http://arxiv.org/abs/2307.10434) | 该论文提出了一种新的框架，通过请求成员标签和成对偏好来扩展主动规范学习，提高学习形式规范的灵活性。在两个不同领域的实验中，结果表明通过学习成员和偏好的组合可以稳定和方便地识别规范。 |
| [^52] | [PreDiff: Precipitation Nowcasting with Latent Diffusion Models.](http://arxiv.org/abs/2307.10422) | 本论文提出了PreDiff方法，使用条件隐式扩散模型进行降水近期预测。同时，引入显式知识控制机制以满足特定领域的物理约束。 |
| [^53] | [GOOSE Algorithm: A Powerful Optimization Tool for Real-World Engineering Challenges and Beyond.](http://arxiv.org/abs/2307.10420) | GOOSE算法是一种基于鹅的行为的元启发式算法，它在多个基准测试函数上进行了验证和比较，证明其在解决现实世界的工程挑战中的有效性。 |
| [^54] | [Explaining Autonomous Driving Actions with Visual Question Answering.](http://arxiv.org/abs/2307.10408) | 本文提出了一种使用视觉问答解释自主驾驶行为的框架，通过问答式因果推理来实现驾驶行为的解释。研究使用强化学习收集驾驶视频并手动标注，从而实现自主驾驶决策的可解释性。 |
| [^55] | [Generative Visual Question Answering.](http://arxiv.org/abs/2307.10405) | 本文研究了一种先进的生成视觉问答（VQA）模型，通过利用新数据集GenVQA，该数据集通过稳定扩散生成新的图像，并使用了七种不同的VQA模型。研究结果表明，这些模型在未来数据上表现出较好的适应性和鲁棒性。 |
| [^56] | [Interpreting and Correcting Medical Image Classification with PIP-Net.](http://arxiv.org/abs/2307.10404) | 本研究利用PIP-Net开展了可解释的机器学习技术在医学图像分类中的应用，并展示了其在骨折检测和皮肤癌诊断方面的准确性和可解释性。通过无监督的预训练，PIP-Net能够轻松识别数据质量问题，并且我们还发现人们可以通过手动禁用不良原型来纠正PIP-Net的推理过程。 |
| [^57] | [Eliminating Label Leakage in Tree-Based Vertical Federated Learning.](http://arxiv.org/abs/2307.10318) | 本研究针对树型垂直联合学习中的标签泄露问题，引入了一种新的标签推断攻击方法ID2Graph，并提出了一种ID-LMID的防御机制，通过关注互信息正则化来防止标签泄露。实验结果表明ID2Graph攻击存在显著的泄露问题。 |
| [^58] | [FedBug: A Bottom-Up Gradual Unfreezing Framework for Federated Learning.](http://arxiv.org/abs/2307.10317) | FedBug是一个自底向上逐渐解冻的联邦学习框架，通过冻结和逐渐解冻模型层，实现了一种有效缓解客户端漂移现象的方法。 |
| [^59] | [Absolutist AI.](http://arxiv.org/abs/2307.10315) | 本文提出了绝对主义AI的概念，认为通过训练AI系统时使用绝对约束条件可以解决许多AI安全问题，这样做可以避免最糟糕的结果、防止灾难、增加系统的可矫正性并帮助系统更安全地探索环境。 |
| [^60] | [The Language Labyrinth: Constructive Critique on the Terminology Used in the AI Discourse.](http://arxiv.org/abs/2307.10292) | 这篇文章对人工智能领域使用的术语进行了建设性批评，指出AI的讨论缺乏对隐喻的批判性距离，导致对责任和潜在用途的反思被扭曲。文章通过提出更合适的术语来促进更富有成果的辩论。 |
| [^61] | [On the Real-Time Semantic Segmentation of Aphid Clusters in the Wild.](http://arxiv.org/abs/2307.10267) | 本文研究了野外蚜虫群体的实时语义分割，通过收集和标注大量蚜虫图像数据集，并使用实时语义分割模型来定位和喷洒农田中的虫害，从而降低农药使用和环境影响。 |
| [^62] | [AI empowering research: 10 ways how science can benefit from AI.](http://arxiv.org/abs/2307.10265) | 本文探讨了人工智能对科学研究的转变性影响，提出了十种方式：强大的引用工具、对研究问题的更好理解、改进的研究问题生成、优化的研究设计、虚拟数据生成、数据转化、高级数据分析和AI辅助报告。虽然人工智能带来了很多好处，但也面临偏见、隐私问题和人工智能与人类的合作需求等挑战。人工智能可以增强科学中的人类创造力，但不能取代它。 |
| [^63] | [Hyperparameter Tuning Cookbook: A guide for scikit-learn, PyTorch, river, and spotPython.](http://arxiv.org/abs/2307.10262) | 本文提供了使用spotPython进行scikit-learn、PyTorch和river的超参数调整的全面指南。重点介绍了spotPython的优化过程和超参数调整，并提供了几个实际案例研究。该指南为对Python超参数调整感兴趣的人们提供了实用的起点。 |
| [^64] | [Abductive Reasoning with the GPT-4 Language Model: Case studies from criminal investigation, medical practice, scientific research.](http://arxiv.org/abs/2307.10250) | 本研究评估了GPT-4大型语言模型在医学诊断、犯罪学和宇宙学等复杂领域中的归纳推理能力。研究结果显示了LLM在复杂问题解决方面的潜力，并强调了进一步研究以最大化其实际应用的必要性。 |
| [^65] | [Deep Neural Networks and Brain Alignment: Brain Encoding and Decoding (Survey).](http://arxiv.org/abs/2307.10246) | 本文综述了深度神经网络和脑对齐的研究，重点在于脑编码和解码模型的应用。这些模型对于理解大脑的信息处理机制以及设计脑机接口具有重要意义。 |
| [^66] | [CoNAN: Conditional Neural Aggregation Network For Unconstrained Face Feature Fusion.](http://arxiv.org/abs/2307.10237) | CoNAN是一种用于无约束人脸特征融合的条件神经聚合网络，针对在长距离和高高度环境下捕获的极低分辨率人脸，利用特征分布调节方法来进行模板聚合。 |
| [^67] | [Look Before You Leap: An Exploratory Study of Uncertainty Measurement for Large Language Models.](http://arxiv.org/abs/2307.10236) | 本研究从不确定性的角度对大型语言模型进行了探索性研究，通过实验发现不确定性估计方法在探索和抵制大型语言模型的不良行为方面具有潜力。 |
| [^68] | [SentimentGPT: Exploiting GPT for Advanced Sentiment Analysis and its Departure from Current Machine Learning.](http://arxiv.org/abs/2307.10234) | 本研究通过利用GPT进行高级情感分析，并考察其与当前机器学习方法的差异，发现GPT方法相较于其他模型在预测性能上具有显著优势，并有效解决了情感分析任务中的一些挑战，如理解上下文和检测讽刺。 |
| [^69] | [Automated Knowledge Modeling for Cancer Clinical Practice Guidelines.](http://arxiv.org/abs/2307.10231) | 本研究提出了一种自动化方法，从国家综合癌症网络（NCCN）肿瘤学临床指南中提取知识，并生成包含该知识的结构化模型。通过使用癌症分期信息、统一医学语言系统（UMLS）和国家癌症研究所的词库（NCIt）概念以及节点分类的增强策略，该模型可以实现程序化遍历和查询。 |
| [^70] | [Causal Laws and Multi-Valued Fluents.](http://arxiv.org/abs/2307.10227) | 本文介绍了一种扩展了因果逻辑和语言C的语言C+，使其可以表示任意非空集合中的值，并且可以描述动作的属性，同时还提供了将C+嵌入到具有多值常量的因果理论的方法，并展示了如何将多值常量替换为布尔常量。 |
| [^71] | [On Loop Formulas with Variables.](http://arxiv.org/abs/2307.10226) | 这项研究提出了一种新的定义稳定模型的方法，它不依赖于grounding，并可以适用于任意一阶句子的语法。通过扩展循环公式的概念，并将其推广到含有或的程序和任意一阶句子，研究表明这种方法可以在处理非单调推理时产生更简洁的结果，并简化查询回答的过程。 |
| [^72] | [First-Order Stable Model Semantics with Intensional Functions.](http://arxiv.org/abs/2307.10225) | 本文扩展了一阶稳定模型语义，允许使用内涵函数，比较了其他相关方法，还利用这个扩展定义了答案集编程模型论（ASPMT），实现了类似SMT的有效一阶推理。 |
| [^73] | [RL-ViGen: A Reinforcement Learning Benchmark for Visual Generalization.](http://arxiv.org/abs/2307.10224) | RL-ViGen是一种用于视觉泛化的强化学习基准，包含多样的任务和广泛的泛化类型，旨在推动对代理人视觉泛化能力的全面评估。 |
| [^74] | [Bound by the Bounty: Collaboratively Shaping Evaluation Processes for Queer AI Harms.](http://arxiv.org/abs/2307.10223) | 这项研究探索了如何在评估人工智能偏见和伤害时整合边缘化社区的知识，并提出了以酷儿社区为视角重新设计偏见奖金的方法。 |
| [^75] | [`It is currently hodgepodge'': Examining AI/ML Practitioners' Challenges during Co-production of Responsible AI Values.](http://arxiv.org/abs/2307.10221) | 该论文探究了人工智能/机器学习从业者在共同创造负责任人工智能价值观过程中面临的挑战，发现了上下结构和执行冲突价值观的问题，并提出了解决策略建议。 |
| [^76] | [Exploring Link Prediction over Hyper-Relational Temporal Knowledge Graphs Enhanced with Time-Invariant Relational Knowledge.](http://arxiv.org/abs/2307.10219) | 这项研究填补了时间KG和超关系KG推理之间的差距，并开发了两个新的基准超关系TKG数据集。 |
| [^77] | [Mitigating Bias in Conversations: A Hate Speech Classifier and Debiaser with Prompts.](http://arxiv.org/abs/2307.10213) | 该论文提出了一个双步骤的方法来减少在线对话中的偏见和仇恨言论。该方法通过先使用分类器检测仇恨言论，然后利用提示生成更少偏见或无偏见的替代语言，从而降低了负面影响，为减少在线讨论中的偏见，促进更具包容性和公平性的沟通环境做出了贡献。 |
| [^78] | [Disentangling Societal Inequality from Model Biases: Gender Inequality in Divorce Court Proceedings.](http://arxiv.org/abs/2307.10200) | 本文通过研究离婚法庭诉讼，探索了性别不平等问题，并发现了自然语言处理方法中存在的偏见问题。需要对现有资源进行修正来量化社会不平等。 |
| [^79] | [Has China caught up to the US in AI research? An exploration of mimetic isomorphism as a model for late industrializers.](http://arxiv.org/abs/2307.10198) | 中国在人工智能研究方面超过美国的数量，但在质量上仍稍逊，其中的原因包括全球趋势、侨民和回国人员的贡献以及相对宽松的数据保护政策。 |
| [^80] | [ChatGPT for Digital Forensic Investigation: The Good, The Bad, and The Unknown.](http://arxiv.org/abs/2307.10195) | 本文评估了ChatGPT对数字取证领域的影响和潜力，特别关注其最新预训练的大型语言模型GPT-4。通过一系列实验，发现了ChatGPT在数字取证用例中的优势和风险，并得出了一些总体结论。 |
| [^81] | [A Dual Stealthy Backdoor: From Both Spatial and Frequency Perspectives.](http://arxiv.org/abs/2307.10184) | 该论文提出了一种名为DUBA的双重隐秘后门攻击方法，该方法同时考虑了触发器在空间和频率域中的隐匿性，以实现良好的攻击性能和强大的隐匿性。 |
| [^82] | [Enhancing Super-Resolution Networks through Realistic Thick-Slice CT Simulation.](http://arxiv.org/abs/2307.10182) | 本研究通过开发一种创新的模拟算法，成功生成与实际图像非常相似的厚切片CT图像，并证明该方法在峰值信噪比和均方根误差方面明显优于其他模拟方法。 |
| [^83] | [DialogStudio: Towards Richest and Most Diverse Unified Dataset Collection for Conversational AI.](http://arxiv.org/abs/2307.10172) | DialogStudio是迄今为止最大且最多样化的对话数据集合，包含从开放领域对话到任务导向对话、自然语言理解、会话推荐、对话摘要和知识驱动对话的数据。它为对话研究和模型训练提供了丰富而多样化的资源。 |
| [^84] | [Implicit Identity Representation Conditioned Memory Compensation Network for Talking Head video Generation.](http://arxiv.org/abs/2307.09906) | 提出了一种隐式身份表示条件化记忆补偿网络，用于高保真度的自然头部视频生成。 |
| [^85] | [Unsupervised Deep Graph Matching Based on Cycle Consistency.](http://arxiv.org/abs/2307.08930) | 本文提出了一种基于循环一致性的无监督深度图匹配方法，不需要真实对应的关键点对，通过在同一对象类别的图像之间强制匹配一致性来进行自我监督学习，该方法具有很高的灵活性，并且在无监督图匹配方面达到了最新的最先进水平。 |
| [^86] | [Efficient Action Robust Reinforcement Learning with Probabilistic Policy Execution Uncertainty.](http://arxiv.org/abs/2307.07666) | 本文研究了具有概率策略执行不确定性的行动鲁棒增强学习问题，并提出了ARRLC算法，该算法在遗憾和样本复杂度上达到了极小极大最优，实验证明其优于非鲁棒算法并且收敛更快。 |
| [^87] | [Quantitative CLTs in Deep Neural Networks.](http://arxiv.org/abs/2307.06092) | 本文研究了具有随机高斯权重和偏置的全连接神经网络的分布，得到了在大但有限的 $n$ 和任意固定网络深度下成立的正态逼近的定量界限，证明了随机全连接网络与相应的无限宽高斯过程之间的距离按照 $n^{-\gamma}$ 缩放，界限在网络宽度的依赖性方面优于以前的研究。 |
| [^88] | [Reading Radiology Imaging Like The Radiologist.](http://arxiv.org/abs/2307.05921) | 提出一种以疾病为导向的方法，解决自动放射学报告生成中的细微差异关注、数据偏差和长文本生成的挑战。 |
| [^89] | [Quantifying the Echo Chamber Effect: An Embedding Distance-based Approach.](http://arxiv.org/abs/2307.04668) | 本文提出了一种基于嵌入距离的方法来量化回音室效应。通过计算用户之间的距离，结合Echo Chamber Score(ECS)指标来评估用户社区的凝聚力和分离度，而不需要用户意识形态的标签和交互图的结构假设。 |
| [^90] | [Proceedings Ninetheenth conference on Theoretical Aspects of Rationality and Knowledge.](http://arxiv.org/abs/2307.04005) | 第十九届理性和知识理论方面的会议旨在汇集来自多个领域的研究人员，进一步研究涉及理性和知识的跨学科问题。 |
| [^91] | [PatternGPT :A Pattern-Driven Framework for Large Language Model Text Generation.](http://arxiv.org/abs/2307.00470) | PatternGPT是一种基于模式驱动的大型语言模型文本生成框架，通过利用大型语言模型的提取能力生成多样化的模式，并使用联邦学习的思想实现模式共享，最终通过搜索高质量模式指导生成模型。该框架具有生成多样化模式、保护数据隐私、结合外部知识等优势。 |
| [^92] | [ChatGPT for Robotics: Design Principles and Model Abilities.](http://arxiv.org/abs/2306.17582) | 本文介绍了使用ChatGPT进行机器人应用的实验研究，通过设计原则和函数库的结合，ChatGPT能够适应不同的机器人任务，并展示了在各种机器人任务中的有效性和多样性。 |
| [^93] | [Regular SE(3) Group Convolutions for Volumetric Medical Image Analysis.](http://arxiv.org/abs/2306.13960) | 本文提出了基于正则化SE(3)群卷积的体积医学图像分析方法，通过分解连续SO(3)核和空间核以实现旋转平移等变性，并在医学分类任务中获得了显著性能提升。 |
| [^94] | [Potential Benefits of Employing Large Language Models in Research in Moral Education and Development.](http://arxiv.org/abs/2306.13805) | 本文探讨如何使用大型语言模型（LLM）在道德教育和发展研究领域做出贡献。最近的LLM具有新兴的上下文学习和思维链功能，可以通过推理和修订来解决困境。 |
| [^95] | [Class-Incremental Learning based on Label Generation.](http://arxiv.org/abs/2306.12619) | 本文提出了一种基于标签生成方法的增量分类学习（CIL）方法（VAG），大幅减少了灾难性遗忘（CF），并更好地保留了预训练模型的可推广表示。 |
| [^96] | [Science in the Era of ChatGPT, Large Language Models and Generative AI: Challenges for Research Ethics and How to Respond.](http://arxiv.org/abs/2305.15299) | 这篇论文回顾了生成AI对科学研究所带来的认识论挑战、伦理和诚信风险，并提出了十项建议，以在AI时代促进更负责任的研究进行。 |
| [^97] | [Evaluating Model Performance in Medical Datasets Over Time.](http://arxiv.org/abs/2305.13426) | 本文提出了一种Evaluation on Medical Datasets Over Time（EMDOT）框架，通过模拟每个时间点的培训过程并对未来时间点上的模型进行评估，评估了不同时间段性能的差异，对医学领域的机器学习模型提供了帮助。 |
| [^98] | [The Compositional Structure of Bayesian Inference.](http://arxiv.org/abs/2305.06112) | 该论文研究了贝叶斯反演在复杂组合结构中的计算方法，并探讨了将其用作统计推断的类型驱动方法。 |
| [^99] | [Improving Code Example Recommendations on Informal Documentation Using BERT and Query-Aware LSH: A Comparative Study.](http://arxiv.org/abs/2305.03017) | 本研究使用BERT和Query-Aware LSH提高非正式文档中代码示例推荐的质量，重点关注于Stack Overflow上的Java编程语言。研究使用BERT将代码示例转换为数值向量。 |
| [^100] | [Tackling Universal Properties of Minimal Trap Spaces of Boolean Networks.](http://arxiv.org/abs/2305.02442) | 本论文介绍了一种新方法——记数器示例引导的精炼抽象(CEGAR)，用于解决布尔网络的最小陷阱空间(MTSs)的通用属性的逻辑推理问题，同时可用于识别在所有MTSs上执行给定属性的布尔变量的永久冻结的重编程问题。 |
| [^101] | [Deep Reinforcement Learning Using Hybrid Quantum Neural Network.](http://arxiv.org/abs/2304.10159) | 该研究基于门控量子计算机，设计了一个参数化的量子电路来解决深度强化学习问题，并评估了其潜力。最终总结了开发深度量子学习的前景和结论。 |
| [^102] | [Fairness in AI and Its Long-Term Implications on Society.](http://arxiv.org/abs/2304.09826) | 本文探讨了AI的公平性问题，指出缺乏AI公平性会加深偏见成为社会压力因素，可能对社会产生长期影响，因此需要寻求潜在解决方案。 |
| [^103] | [Sabi\'a: Portuguese Large Language Models.](http://arxiv.org/abs/2304.07880) | 针对葡萄牙语进行单语言预训练，可以显著提高大规模合成语言模型的质量，并能够在一系列葡萄牙语数据集上优于以英语为中心和多语言的对手，最好的模型的表现与GPT-3.5-turbo持平。 |
| [^104] | [Natural Selection Favors AIs over Humans.](http://arxiv.org/abs/2303.16200) | 这篇论文探讨了随着人工智能的发展，其可能会出现不良特性并逐渐超越人类智能的问题，以及这对人类未来的控制权产生的影响。 |
| [^105] | [Positive-Augmented Constrastive Learning for Image and Video Captioning Evaluation.](http://arxiv.org/abs/2303.12112) | 本论文提出一种新的图像标题评估指标PAC-S，可以更准确地评估图像和视频的标题，相比于现有的指标有更好的表现；源代码和训练模型已经公开。 |
| [^106] | [A multidomain relational framework to guide institutional AI research and adoption.](http://arxiv.org/abs/2303.10106) | 该论文提出一个多元关系框架来指导机构人工智能的研究和采纳，解决社会技术话语中的关系问题，包括语义模糊、概念之间缺乏明确的关系和不同的标准术语，帮助评估机构AI系统，避免概念孤立。 |
| [^107] | [Dividing Good and Better Items Among Agents with Submodular Valuations.](http://arxiv.org/abs/2302.03087) | 本文研究了在具有二元子模价值的代理人之间公平分配不可分割物品的问题，并提出了一个解决方案概念的算法框架，其中包括leximin、max Nash welfare（MNW）和$p$-mean welfare最大化分配。在$ab$可整除的情况下，该算法框架可以用于求解多种解决方案概念，补充了现有结果的限制。同时，该文研究了leximin和MNW分配在无嫉妒和最大最小份额保证方面的表现。 |
| [^108] | [Mathematical Capabilities of ChatGPT.](http://arxiv.org/abs/2301.13867) | 本研究调查了ChatGPT和GPT-4的数学能力，并通过使用新的方法以及发布两个新数据集，评估了它们在各个维度的数学推理上的表现。这是第一个涵盖研究生级数学并由数学研究人员策划的自然语言数据集，也测试了它们作为专业数学家助手的潜力。 |
| [^109] | [Execution-based Code Generation using Deep Reinforcement Learning.](http://arxiv.org/abs/2301.13816) | 使用深度强化学习的PPOCoder框架将预训练的编程语言模型和Proximal Policy Optimization技术结合，通过利用代码执行和结构对齐的非可微反馈，实现了更高效的代码生成。 |
| [^110] | [ThoughtSource: A central hub for large language model reasoning data.](http://arxiv.org/abs/2301.11596) | ThoughtSource是一个用于连续思考推理的元数据集和软件库，旨在通过促进对连续思考的定性理解、实证评估和提供训练数据，改进未来的人工智能系统。 |
| [^111] | [pyRDDLGym: From RDDL to Gym Environments.](http://arxiv.org/abs/2211.05939) | pyRDDLGym是一个Python框架，用于从RDDL声明性描述自动生成OpenAI Gym环境。它通过条件概率函数描述RDDL中变量的离散时间步进演化，并支持简单的环境修改和扩展。它具有独特的表达能力，可以帮助快速开发强化学习基准，并促进利用模型知识进行交互性学习的混合方法研究。 |
| [^112] | [Leveraging Offline Data in Online Reinforcement Learning.](http://arxiv.org/abs/2211.04974) | 在这项工作中，我们研究了在线强化学习中利用离线数据的设置，为具有线性结构的MDPs确定了所需的在线样本数量，并提供了实现这一目标的性质和算法。 |
| [^113] | [Antecedent Predictions Are More Important Than You Think: An Effective Method for Tree-Based Code Generation.](http://arxiv.org/abs/2208.09998) | 先行预测比后续预测更重要。本文提出了一种名为AP损失的方法，通过利用生成的抽象语法树节点的位置信息，帮助模型重视先行预测。 |
| [^114] | [SAFARI: Versatile and Efficient Evaluations for Robustness of Interpretability.](http://arxiv.org/abs/2208.09418) | 本文提出了一种名为SAFARI的方法，用于评估深度学习的解释可靠性。该方法针对现有技术无法解决的几个挑战，通过引入两种黑盒评估方法，即最坏情况解释差异和一般情况下的鲁棒性的概率概念，来解决现有度量不全面、XAI技术异质性和误解罕见性等问题。使用遗传算法和子集模拟进行评估。 |
| [^115] | [ForecastTKGQuestions: A Benchmark for Temporal Question Answering and Forecasting over Temporal Knowledge Graphs.](http://arxiv.org/abs/2208.06501) | 本论文提出了一个新的任务，即在时间知识图谱上进行预测性问题回答。该任务对于人们寻求未来计划非常重要，并且是先前研究中未被探索的领域。 |
| [^116] | [Injecting Domain Adaptation with Learning-to-hash for Effective and Efficient Zero-shot Dense Retrieval.](http://arxiv.org/abs/2205.11498) | 通过学习哈希技术提高零样本密集检索的准确性和效率，克服了存储密集索引的高内存使用问题，并在跨领域环境中进行了评估。 |
| [^117] | [HDGT: Heterogeneous Driving Graph Transformer for Multi-Agent Trajectory Prediction via Scene Encoding.](http://arxiv.org/abs/2205.09753) | HDGT是一种将驾驶场景建模为异构图的方法，通过场景编码实现多智能体轨迹预测。该方法考虑到了驾驶场景中的不同对象和丰富的语义关系，并使用自我中心的方式进行空间关系编码。 |
| [^118] | [Gradient and Projection Free Distributed Online Min-Max Resource Optimization.](http://arxiv.org/abs/2112.03896) | 在分布式在线最小-最大资源分配问题中，我们提出了一种梯度和投影自由的在线算法DORA，通过让非阻塞学习者学会放弃资源并与阻塞者共享资源，实现了大规模和分布式网络中的计算开销的显著减少。 |
| [^119] | [Full Characterization of Adaptively Strong Majority Voting in Crowdsourcing.](http://arxiv.org/abs/2111.06390) | 本研究通过利用吸收式马尔可夫链对众包中自适应强多数投票进行建模和分析，得出了该投票过程的一些重要特征，包括共识投票的质量、投票数和需求的方差等。研究结果显示，可以通过调整阈值来实现在不同准确性水平的工人参与的投票过程中的质量等效。 |
| [^120] | [Deep Exploration for Recommendation Systems.](http://arxiv.org/abs/2109.12509) | 本文提出了一种深度探索方法以解决推荐系统中奖励稀少时的问题，并在高保真度的工业级模拟器下进行了实验，证明了该算法相比现有算法有很大的提升。 |
| [^121] | [Vector Symbolic Architectures as a Computing Framework for Emerging Hardware.](http://arxiv.org/abs/2106.05268) | 向量符号体系结构（VSA）是一种新兴的计算框架，适用于在新硬件上实现，并能有效支持复杂问题的解决。其特色特点是领域模型的代数结构和叠加计算，使其在人工智能领域具有广泛应用潜力。 |
| [^122] | [Semantically Adversarial Scenario Generation with Explicit Knowledge Guidance.](http://arxiv.org/abs/2106.04066) | 本文提出了一种具有显式知识引导的方法，通过在生成过程中融入领域知识，实现了对抗情景的生成。通过树状变分自动编码器和语义规则的应用，可以实现对驾驶场景的精确控制。 |
| [^123] | [Perceptron Theory Can Predict the Accuracy of Neural Networks.](http://arxiv.org/abs/2012.07881) | 感知器理论可以通过统计方法准确预测不同结构的神经网络的性能。 |

# 详细

[^1]: 句法与语义线性抽象和细化神经网络

    Syntactic vs Semantic Linear Abstraction and Refinement of Neural Networks. (arXiv:2307.10891v1 [cs.LO])

    [http://arxiv.org/abs/2307.10891](http://arxiv.org/abs/2307.10891)

    这项工作提供了一个灵活的框架，通过线性组合替换神经元，实现了神经网络的句法和语义抽象，并引入了一种改进方法来平衡减少和精确度。

    

    抽象是一种提高可扩展性的关键验证技术。然而，其在神经网络中的使用迄今非常有限。以前的分类网络抽象方法将多个神经元替换为足够相似的其中一个神经元。我们可以将相似性定义为句法上（使用神经元之间的连接数量）或语义上（对于各种输入的神经元激活值）的相似性。然而，以往的方法仅能达到适度的减少，而且实现起来困难。在这项工作中，我们提供了一个更灵活的框架，其中神经元可以被其他神经元的线性组合替换，从而改善减少效果。我们在句法和语义抽象上应用了这种方法，并通过实验进行了实现和评估。此外，我们引入了一种改进我们抽象的方法，以寻找更好的减少和精确度平衡。

    Abstraction is a key verification technique to improve scalability. However, its use for neural networks is so far extremely limited. Previous approaches for abstracting classification networks replace several neurons with one of them that is similar enough. We can classify the similarity as defined either syntactically (using quantities on the connections between neurons) or semantically (on the activation values of neurons for various inputs). Unfortunately, the previous approaches only achieve moderate reductions, when implemented at all. In this work, we provide a more flexible framework where a neuron can be replaced with a linear combination of other neurons, improving the reduction. We apply this approach both on syntactic and semantic abstractions, and implement and evaluate them experimentally. Further, we introduce a refinement method for our abstractions, allowing for finding a better balance between reduction and precision.
    
[^2]: 将注意力分割与绑定用于改进生成语义护理

    Divide & Bind Your Attention for Improved Generative Semantic Nursing. (arXiv:2307.10864v1 [cs.CV])

    [http://arxiv.org/abs/2307.10864](http://arxiv.org/abs/2307.10864)

    本论文提出了一种名为"分割与绑定"的方法，旨在改进生成语义护理的效果。该方法引入了新的损失目标，包括关注丢失和绑定丢失，以解决复杂提示和不适当属性绑定的问题。

    

    新兴的大规模文本到图像生成模型，如稳定扩散（SD），展示了高度逼真的压倒性结果。尽管取得了巨大的进展，但当前最先进的模型仍然难以完全依照输入提示生成图像。先前的研究——关注与激发，引入了生成语义护理（GSN）的概念，旨在在推断时优化跨注意力以更好地融入语义。它在生成简单提示，如“一只猫和一只狗”，方面展示了有希望的结果。然而，它在处理更复杂的提示以及解决不适当的属性绑定问题方面的功效有所下降。为了应对复杂提示或涉及多个实体的场景所带来的挑战，并实现改进的属性绑定，我们提出了分割与绑定。我们引入了两个新的GSN损失目标：一种新的关注丢失和一种绑定丢失。我们的方法在其能够更好地将语义纳入图像生成过程中的特点上脱颖而出。

    Emerging large-scale text-to-image generative models, e.g., Stable Diffusion (SD), have exhibited overwhelming results with high fidelity. Despite the magnificent progress, current state-of-the-art models still struggle to generate images fully adhering to the input prompt. Prior work, Attend & Excite, has introduced the concept of Generative Semantic Nursing (GSN), aiming to optimize cross-attention during inference time to better incorporate the semantics. It demonstrates promising results in generating simple prompts, e.g., ``a cat and a dog''. However, its efficacy declines when dealing with more complex prompts, and it does not explicitly address the problem of improper attribute binding. To address the challenges posed by complex prompts or scenarios involving multiple entities and to achieve improved attribute binding, we propose Divide & Bind. We introduce two novel loss objectives for GSN: a novel attendance loss and a binding loss. Our approach stands out in its ability to fa
    
[^3]: 具有基于解耦的可达性规划的目标条件强化学习

    Goal-Conditioned Reinforcement Learning with Disentanglement-based Reachability Planning. (arXiv:2307.10846v1 [cs.RO])

    [http://arxiv.org/abs/2307.10846](http://arxiv.org/abs/2307.10846)

    本研究提出了一种结合了解耦可达性规划的目标条件强化学习算法，用于解决现有方法在高维状态空间中扩展和收集高质量训练数据的问题。

    

    目标条件强化学习（GCRL）可以使Agent自发地设定不同的目标来学习一系列技能。尽管在各个领域中都有出色的研究成果，但是在时间延展任务中达到远距离目标仍然是GCRL面临的挑战。目前的研究通过利用规划算法来计划中间子目标来增强GCRL来解决这个问题。他们的方法需要两个关键要求：（i）状态表示空间来搜索有效的子目标，（ii）距离函数来测量子目标的可达性。然而，由于非紧凑的表示，它们很难在高维状态空间上扩展。此外，它们无法通过标准的GC策略收集高质量的训练数据，这导致了不准确的距离函数。这两个问题都会影响规划和策略学习的效率和性能。在本文中，我们提出了一种结合了解耦可达性规划（REPlan）的目标条件RL算法。

    Goal-Conditioned Reinforcement Learning (GCRL) can enable agents to spontaneously set diverse goals to learn a set of skills. Despite the excellent works proposed in various fields, reaching distant goals in temporally extended tasks remains a challenge for GCRL. Current works tackled this problem by leveraging planning algorithms to plan intermediate subgoals to augment GCRL. Their methods need two crucial requirements: (i) a state representation space to search valid subgoals, and (ii) a distance function to measure the reachability of subgoals. However, they struggle to scale to high-dimensional state space due to their non-compact representations. Moreover, they cannot collect high-quality training data through standard GC policies, which results in an inaccurate distance function. Both affect the efficiency and performance of planning and policy learning. In the paper, we propose a goal-conditioned RL algorithm combined with Disentanglement-based Reachability Planning (REPlan) to 
    
[^4]: 修改Miller对对比性解释的定义

    Modifications of the Miller definition of contrastive (counterfactual) explanations. (arXiv:2307.10832v1 [cs.AI])

    [http://arxiv.org/abs/2307.10832](http://arxiv.org/abs/2307.10832)

    本文修改了Miller对对比性解释的定义，并提出了两个改进版本，解决了原始定义存在的问题。

    

    最近，Miller基于著名的Halpern-Pearl（HP）因果和（非对比性）解释的定义，提出了对比性（反事实）解释的定义。关键是，Miller的定义基于原始的HP解释定义，但这已经被Halpern修改过了；可能是因为原始定义在许多标准示例中产生了违反直觉的结果。最近，Borner提出了第三个定义，观察到这个修改后的HP定义也可能产生违反直觉的结果。在本文中，我们展示了Miller定义中存在的问题继承自原始HP定义。我们通过提出两个基于更健壮的修改后的HP和Borner定义的改进版本来解决这些问题。我们分析了我们的新定义，并展示它们保留了Miller定义的精神，其中所有三个变体都满足一个与底层非对比性定义相关的另一个统一定义的模块化。

    Miller recently proposed a definition of contrastive (counterfactual) explanations based on the well-known Halpern-Pearl (HP) definitions of causes and (non-contrastive) explanations. Crucially, the Miller definition was based on the original HP definition of explanations, but this has since been modified by Halpern; presumably because the original yields counterintuitive results in many standard examples. More recently Borner has proposed a third definition, observing that this modified HP definition may also yield counterintuitive results. In this paper we show that the Miller definition inherits issues found in the original HP definition. We address these issues by proposing two improved variants based on the more robust modified HP and Borner definitions. We analyse our new definitions and show that they retain the spirit of the Miller definition where all three variants satisfy an alternative unified definition that is modular with respect to an underlying definition of non-contra
    
[^5]: "感觉像有第二个思维": 探究在大型语言模型中进行创意可写性预写的人机共创

    "It Felt Like Having a Second Mind": Investigating Human-AI Co-creativity in Prewriting with Large Language Models. (arXiv:2307.10811v1 [cs.HC])

    [http://arxiv.org/abs/2307.10811](http://arxiv.org/abs/2307.10811)

    通过三节次的定性研究，探究了人类与大型语言模型在预写过程中的合作模式，并发现了一个三阶段的人机共创过程：构思、启发和实施。在这个合作过程中，人类扮演着主导角色。

    

    预写是在第一稿之前发现和发展思想的过程，它需要发散性思维，通常涉及到无结构的策略，如图表、概述和自由写作等。虽然已经证明大型语言模型（LLMs）在各种任务中都是有用的，包括创意写作，但对用户如何与LLMs合作来支持预写的方式知之甚少。在这种创造性过程中，LLMs的首选合作角色和主动性也不明确。为了研究人类与LLMs在预写过程中的合作模式和动力学，我们进行了一项三节次的定性研究，与15位参与者进行了两个创造性任务：写故事和写口号。研究结果表明，在合作的预写过程中，似乎存在着一个三阶段迭代的人机共创过程，包括构思、启发和实施阶段。这个合作过程以人类在主导角色中取得了成功。

    Prewriting is the process of discovering and developing ideas before a first draft, which requires divergent thinking and often implies unstructured strategies such as diagramming, outlining, free-writing, etc. Although large language models (LLMs) have been demonstrated to be useful for a variety of tasks including creative writing, little is known about how users would collaborate with LLMs to support prewriting. The preferred collaborative role and initiative of LLMs during such a creativity process is also unclear. To investigate human-LLM collaboration patterns and dynamics during prewriting, we conducted a three-session qualitative study with 15 participants in two creative tasks: story writing and slogan writing. The findings indicated that during collaborative prewriting, there appears to be a three-stage iterative Human-AI Co-creativity process that includes Ideation, Illumination, and Implementation stages. This collaborative process champions the human in a dominant role, in
    
[^6]: 关于通过最优传输结合专家示范在模仿学习中的应用研究

    On Combining Expert Demonstrations in Imitation Learning via Optimal Transport. (arXiv:2307.10810v1 [cs.LG])

    [http://arxiv.org/abs/2307.10810](http://arxiv.org/abs/2307.10810)

    通过最优传输方法结合多个专家示范的新方法，在模仿学习中提供了更合理的示范几何平均值。

    

    模仿学习旨在通过专家示范来教授智能体特定任务。模仿学习的关键方法之一是定义智能体和专家之间的距离，并找到使该距离最小化的智能体策略。最优传输方法在模仿学习中被广泛使用，因为它们提供了衡量智能体和专家轨迹之间有意义距离的方法。然而，如何最佳地结合多个专家示范的问题并没有得到广泛研究。标准方法是简单地串联状态（-动作）轨迹，但在轨迹为多模态时存在问题。我们提出了一种替代方法，使用多边际最优传输距离，能够在最优传输的意义下结合多个和多样化的状态轨迹，提供更合理的示范几何平均值。我们的方法使智能体能够从多个专家中学习，并在OpenAI Gym控制环境中进行了效率分析。

    Imitation learning (IL) seeks to teach agents specific tasks through expert demonstrations. One of the key approaches to IL is to define a distance between agent and expert and to find an agent policy that minimizes that distance. Optimal transport methods have been widely used in imitation learning as they provide ways to measure meaningful distances between agent and expert trajectories. However, the problem of how to optimally combine multiple expert demonstrations has not been widely studied. The standard method is to simply concatenate state (-action) trajectories, which is problematic when trajectories are multi-modal. We propose an alternative method that uses a multi-marginal optimal transport distance and enables the combination of multiple and diverse state-trajectories in the OT sense, providing a more sensible geometric average of the demonstrations. Our approach enables an agent to learn from several experts, and its efficiency is analyzed on OpenAI Gym control environment
    
[^7]: 通过自适应特征逐渐压缩实现高效的分割学习

    Communication-Efficient Split Learning via Adaptive Feature-Wise Compression. (arXiv:2307.10805v1 [cs.DC])

    [http://arxiv.org/abs/2307.10805](http://arxiv.org/abs/2307.10805)

    该论文提出了一个名为SplitFC的通信高效的分割学习框架，通过两种自适应压缩策略来减少中间特征和梯度向量的通信开销，这些策略分别是自适应特征逐渐掉落和自适应特征逐渐量化。

    

    本文提出了一种名为SplitFC的新颖的通信高效的分割学习（SL）框架，它减少了在SL培训过程中传输中间特征和梯度向量所需的通信开销。SplitFC的关键思想是利用矩阵的列所展示的不同的离散程度。SplitFC整合了两种压缩策略：（i）自适应特征逐渐掉落和（ii）自适应特征逐渐量化。在第一种策略中，中间特征向量根据这些向量的标准偏差确定自适应掉落概率进行掉落。然后，由于链式规则，与被丢弃的特征向量相关联的中间梯度向量也会被丢弃。在第二种策略中，非丢弃的中间特征和梯度向量使用基于向量范围确定的自适应量化级别进行量化。为了尽量减小量化误差，最优量化是。

    This paper proposes a novel communication-efficient split learning (SL) framework, named SplitFC, which reduces the communication overhead required for transmitting intermediate feature and gradient vectors during the SL training process. The key idea of SplitFC is to leverage different dispersion degrees exhibited in the columns of the matrices. SplitFC incorporates two compression strategies: (i) adaptive feature-wise dropout and (ii) adaptive feature-wise quantization. In the first strategy, the intermediate feature vectors are dropped with adaptive dropout probabilities determined based on the standard deviation of these vectors. Then, by the chain rule, the intermediate gradient vectors associated with the dropped feature vectors are also dropped. In the second strategy, the non-dropped intermediate feature and gradient vectors are quantized using adaptive quantization levels determined based on the ranges of the vectors. To minimize the quantization error, the optimal quantizatio
    
[^8]: Meta-Transformer: 一个统一的多模态学习框架

    Meta-Transformer: A Unified Framework for Multimodal Learning. (arXiv:2307.10802v1 [cs.CV])

    [http://arxiv.org/abs/2307.10802](http://arxiv.org/abs/2307.10802)

    Meta-Transformer是一个统一的多模态学习框架，利用一个冻结的编码器进行多模态感知，在没有成对多模态训练数据的情况下可以处理各种模态，并且能够提取输入数据的高级语义特征。

    

    多模态学习旨在构建能够处理和关联多种模态的信息的模型。尽管在这个领域已经有多年的发展，但由于不同模态之间的固有差距，设计一个用于处理各种模态的统一网络仍然具有挑战性。在这项工作中，我们提出了一个名为Meta-Transformer的框架，该框架利用一个冻结的编码器在没有成对多模态训练数据的情况下进行多模态感知。在Meta-Transformer中，来自各种模态的原始输入数据被映射到一个共享的标记空间中，使得后续的编码器可以提取输入数据的高级语义特征。由三个主要组件组成：一个统一的数据标记器，一个模态共享的编码器和用于下游任务的特定任务头，Meta-Transformer是第一个在12种模态上进行统一学习的框架。

    Multimodal learning aims to build models that can process and relate information from multiple modalities. Despite years of development in this field, it still remains challenging to design a unified network for processing various modalities ($\textit{e.g.}$ natural language, 2D images, 3D point clouds, audio, video, time series, tabular data) due to the inherent gaps among them. In this work, we propose a framework, named Meta-Transformer, that leverages a $\textbf{frozen}$ encoder to perform multimodal perception without any paired multimodal training data. In Meta-Transformer, the raw input data from various modalities are mapped into a shared token space, allowing a subsequent encoder with frozen parameters to extract high-level semantic features of the input data. Composed of three main components: a unified data tokenizer, a modality-shared encoder, and task-specific heads for downstream tasks, Meta-Transformer is the first framework to perform unified learning across 12 modaliti
    
[^9]: 优化PatchCore以用于少量/大量样本的异常检测

    Optimizing PatchCore for Few/many-shot Anomaly Detection. (arXiv:2307.10792v1 [cs.CV])

    [http://arxiv.org/abs/2307.10792](http://arxiv.org/abs/2307.10792)

    本文研究了在少量样本和大量样本设置下，PatchCore算法在异常检测/异常分割性能上的表现，并发现通过优化超参数和借鉴少量样本监督学习技术可以进一步提高性能。

    

    少量样本的异常检测是一种新兴的异常检测子领域，它试图通过仅使用少量选定的样本来区分正常和异常数据。尽管新提出的少量样本异常检测方法与用于完全样本领域的预先存在的算法进行比较作为基线，但它们并没有专门针对少量样本进行优化。因此，目前尚不清楚这些预先存在的算法的性能是否可以进一步提高。本文解决了该问题。具体而言，我们对PatchCore进行了研究，该算法是目前状态最佳的完全样本异常检测/异常分割算法，研究其在少量样本和大量样本设置下的异常检测/异常分割性能。我们假设通过（I）优化其各种超参数和（II）转移已知可改善少量样本监督学习的技术到异常检测领域，可以实现进一步的性能提升。对公共VisA和MVTec异常检测数据集进行了详尽的实验证明，（I）sign

    Few-shot anomaly detection (AD) is an emerging sub-field of general AD, and tries to distinguish between normal and anomalous data using only few selected samples. While newly proposed few-shot AD methods do compare against pre-existing algorithms developed for the full-shot domain as baselines, they do not dedicatedly optimize them for the few-shot setting. It thus remains unclear if the performance of such pre-existing algorithms can be further improved. We address said question in this work. Specifically, we present a study on the AD/anomaly segmentation (AS) performance of PatchCore, the current state-of-the-art full-shot AD/AS algorithm, in both the few-shot and the many-shot settings. We hypothesize that further performance improvements can be realized by (I) optimizing its various hyperparameters, and by (II) transferring techniques known to improve few-shot supervised learning to the AD domain. Exhaustive experiments on the public VisA and MVTec AD datasets reveal that (I) sign
    
[^10]: 解码谜团：在工作记忆的多个方面上对人类和人工智能进行基准测试

    Decoding the Enigma: Benchmarking Humans and AIs on the Many Facets of Working Memory. (arXiv:2307.10768v1 [q-bio.NC])

    [http://arxiv.org/abs/2307.10768](http://arxiv.org/abs/2307.10768)

    本论文介绍了一个全面的工作记忆基准数据集（WorM），通过评估4个功能、3个领域和11个行为和神经特征的WM任务来开发和评估AI WM模型。结果表明，AI模型能够模拟出脑中工作记忆的一些特征，如优势效应和最新性效应，以及专门用于不同领域和功能的工作记忆的神经群集和相关物。

    

    工作记忆（WM）是一种基本的认知过程，它促进了信息的临时存储、整合、操作和检索，在推理和决策任务中起着重要作用。捕捉工作记忆多方面特征的可靠基准数据集对于有效地开发和评估AI工作记忆模型至关重要。在这里，我们介绍了一个全面的工作记忆（WorM）基准数据集，以实现这个目的。WorM包括10个任务和总共100万次试验，评估了WM的4个功能、3个领域和11个行为和神经特征。我们在所有这些任务上共同训练和测试了最先进的循环神经网络和Transformer。我们还包括人类行为基准作为对比的上限。我们的结果表明，AI模型模拟了脑中工作记忆的一些特征，特别是优势效应和最新性效应，以及专门用于不同领域和功能性的工作记忆的神经群集和相关物。

    Working memory (WM), a fundamental cognitive process facilitating the temporary storage, integration, manipulation, and retrieval of information, plays a vital role in reasoning and decision-making tasks. Robust benchmark datasets that capture the multifaceted nature of WM are crucial for the effective development and evaluation of AI WM models. Here, we introduce a comprehensive Working Memory (WorM) benchmark dataset for this purpose. WorM comprises 10 tasks and a total of 1 million trials, assessing 4 functionalities, 3 domains, and 11 behavioral and neural characteristics of WM. We jointly trained and tested state-of-the-art recurrent neural networks and transformers on all these tasks. We also include human behavioral benchmarks as an upper bound for comparison. Our results suggest that AI models replicate some characteristics of WM in the brain, most notably primacy and recency effects, and neural clusters and correlates specialized for different domains and functionalities of WM
    
[^11]: MSQNet: 无关演员的多模态动作识别

    MSQNet: Actor-agnostic Action Recognition with Multi-modal Query. (arXiv:2307.10763v1 [cs.CV])

    [http://arxiv.org/abs/2307.10763](http://arxiv.org/abs/2307.10763)

    MSQNet是一种无关演员的多模态多标签动作识别方法，通过使用视觉和文本模态来更好地表示动作类别，克服了现有方法中针对特定演员的限制。

    

    现有的动作识别方法通常是针对特定演员的，因为演员之间具有固有的拓扑和显着差异。这就需要特定演员的姿态估计（例如人类与动物），导致模型设计复杂性和高维护成本。此外，它们通常只关注学习视觉模态和单标签分类，忽视了其他可用信息源（例如类名文本）和多个动作的同时发生。为了克服这些限制，我们提出了一种新的方法，称为“无关演员的多模态多标签动作识别”，为包括人类和动物在内的各种类型的演员提供了统一的解决方案。我们进一步在基于Transformer的目标检测框架（例如DETR）中提出了一种新颖的多模态语义查询网络（MSQNet）模型，通过利用视觉和文本模态更好地表示动作类别。消除了演员特定性的限制。

    Existing action recognition methods are typically actor-specific due to the intrinsic topological and apparent differences among the actors. This requires actor-specific pose estimation (e.g., humans vs. animals), leading to cumbersome model design complexity and high maintenance costs. Moreover, they often focus on learning the visual modality alone and single-label classification whilst neglecting other available information sources (e.g., class name text) and the concurrent occurrence of multiple actions. To overcome these limitations, we propose a new approach called 'actor-agnostic multi-modal multi-label action recognition,' which offers a unified solution for various types of actors, including humans and animals. We further formulate a novel Multi-modal Semantic Query Network (MSQNet) model in a transformer-based object detection framework (e.g., DETR), characterized by leveraging visual and textual modalities to represent the action classes better. The elimination of actor-spec
    
[^12]: 探讨人工智能对知识工作创造力的影响：超越机械化抄袭和随机鹦鹉的视角

    Exploring Perspectives on the Impact of Artificial Intelligence on the Creativity of Knowledge Work: Beyond Mechanised Plagiarism and Stochastic Parrots. (arXiv:2307.10751v1 [cs.HC])

    [http://arxiv.org/abs/2307.10751](http://arxiv.org/abs/2307.10751)

    人工智能对知识工作的创造力有着深远的影响，但是对生成模型的批评者认为其输出只是随机的抄袭和混搭。然而，创造力和原创性的定义是复杂的，可能是一个过程、一个作者或一个观看者的属性。

    

    人工智能（AI），尤其是生成模型，是知识工作的变革性工具。它们问题化了创造力、原创性、抄袭、归属权和版权所有权的概念。对生成模型的批评者强调其依赖大量的训练数据，并将这些模型的输出视为随机的抄袭、混搭或者拼贴源数据。基于这些理由，许多人主张对这些模型的部署、使用和输出的归属加强监管。然而，这些问题并不是人工智能独有的，也不是新问题。在这篇立场论文中，我使用文学批评、艺术史和版权法的例子，展示了创造力和原创性如何抵抗被定义为一个对象的可注释或信息论属性，而可见为一个过程、一个作者或一个观看者的属性。一些替代观点认为创造性工作实质上是一种需求一定程度的模仿、颠倒和重新组合。

    Artificial Intelligence (AI), and in particular generative models, are transformative tools for knowledge work. They problematise notions of creativity, originality, plagiarism, the attribution of credit, and copyright ownership. Critics of generative models emphasise the reliance on large amounts of training data, and view the output of these models as no more than randomised plagiarism, remix, or collage of the source data. On these grounds, many have argued for stronger regulations on the deployment, use, and attribution of the output of these models. However, these issues are not new or unique to artificial intelligence. In this position paper, using examples from literary criticism, the history of art, and copyright law, I show how creativity and originality resist definition as a notatable or information-theoretic property of an object, and instead can be seen as the property of a process, an author, or a viewer. Further alternative views hold that all creative work is essentiall
    
[^13]: 公平感知的联邦学习客户端选择

    Fairness-Aware Client Selection for Federated Learning. (arXiv:2307.10738v1 [cs.LG])

    [http://arxiv.org/abs/2307.10738](http://arxiv.org/abs/2307.10738)

    提出了公平感知的联邦客户端选择（FairFedCS）方法，通过动态调整联邦学习客户端的选择概率，同时考虑客户端的声誉、参与次数和对模型性能的贡献，解决了平衡性能和公平性的问题。

    

    联邦学习使得多个数据所有者（即联邦学习客户端）能够在不泄露私人数据的情况下进行机器学习模型的协作训练。由于联邦学习服务器每轮训练只能选择有限数量的客户端，客户端选择成为重要的研究问题。现有方法通常关注于提高联邦学习模型性能或提高客户端的公平待遇。在选择联邦学习客户端时平衡性能和公平性考虑的问题仍然存在。为了解决这个问题，我们提出了公平感知的联邦客户端选择（FairFedCS）方法。基于李雅普诺夫优化，它通过同时考虑客户端的声誉、参与联邦学习任务的次数和对最终模型性能的贡献，动态调整联邦学习客户端的选择概率。通过不使用基于阈值的声誉过滤，它为联邦学习客户端提供了赎回声誉的机会。

    Federated learning (FL) has enabled multiple data owners (a.k.a. FL clients) to train machine learning models collaboratively without revealing private data. Since the FL server can only engage a limited number of clients in each training round, FL client selection has become an important research problem. Existing approaches generally focus on either enhancing FL model performance or enhancing the fair treatment of FL clients. The problem of balancing performance and fairness considerations when selecting FL clients remains open. To address this problem, we propose the Fairness-aware Federated Client Selection (FairFedCS) approach. Based on Lyapunov optimization, it dynamically adjusts FL clients' selection probabilities by jointly considering their reputations, times of participation in FL tasks and contributions to the resulting model performance. By not using threshold-based reputation filtering, it provides FL clients with opportunities to redeem their reputations after a perceive
    
[^14]: LLM审查：机器学习挑战还是计算机安全问题？

    LLM Censorship: A Machine Learning Challenge or a Computer Security Problem?. (arXiv:2307.10719v1 [cs.AI])

    [http://arxiv.org/abs/2307.10719](http://arxiv.org/abs/2307.10719)

    本文讨论了大型语言模型(LLM)的审查问题，指出现有的语义审查方法存在理论上的限制，由于LLM的程序化和遵循指令的能力，语义审查可以被认为是一个不可判定的问题。同时，有知识的攻击者可以重构不可容许的输出。

    

    大型语言模型(LLM)在理解复杂指令方面展现了令人印象深刻的能力。然而，它们对提供的指令的盲目遵循引发了对恶意使用风险的担忧。现有的防御机制，如LLM的模型微调或使用LLM进行输出审查，已证明是有缺陷的，因为LLM仍然可以生成有问题的回答。常用的审查方法将这个问题视为机器学习问题，并依赖于另一个语言模型来检测LLM输出中的不良内容。在本文中，我们呈现了这种语义审查方法的理论限制。具体来说，我们证明了语义审查可以被认为是一个不可判定的问题，突出了由于LLM的程序化和遵循指令的能力而引起的审查中的固有挑战。此外，我们认为这些挑战不仅限于语义审查，因为有知识的攻击者可以重构不可容许的输出。

    Large language models (LLMs) have exhibited impressive capabilities in comprehending complex instructions. However, their blind adherence to provided instructions has led to concerns regarding risks of malicious use. Existing defence mechanisms, such as model fine-tuning or output censorship using LLMs, have proven to be fallible, as LLMs can still generate problematic responses. Commonly employed censorship approaches treat the issue as a machine learning problem and rely on another LM to detect undesirable content in LLM outputs. In this paper, we present the theoretical limitations of such semantic censorship approaches. Specifically, we demonstrate that semantic censorship can be perceived as an undecidable problem, highlighting the inherent challenges in censorship that arise due to LLMs' programmatic and instruction-following capabilities. Furthermore, we argue that the challenges extend beyond semantic censorship, as knowledgeable attackers can reconstruct impermissible outputs 
    
[^15]: 引入风险遮挡以实现决策和舒适的行为规划。

    Introducing Risk Shadowing For Decisive and Comfortable Behavior Planning. (arXiv:2307.10714v1 [eess.SY])

    [http://arxiv.org/abs/2307.10714](http://arxiv.org/abs/2307.10714)

    引入了一种风险遮挡方法来处理城市驾驶中的群体互动问题，该方法可以分析群体中三个代理之间的交互，找到在行为规划中不需要考虑的代理，并能够规划出更为决策和舒适的驾驶策略。

    

    本文考虑城市驾驶中的群体互动问题。自动驾驶汽车的最新行为规划器主要单独考虑每个代理之间的交互，并通过成本函数找到最优的自我代理行为，例如避免与其他代理发生碰撞。本文提出了一种风险遮挡方法，通过分析三个代理之间的群体互动，去超越单个交互的限制。具体而言，所提出的方法能够确定需要在自我代理的行为规划器中考虑哪个第一个其他代理，因为这个第一个其他代理由于第二个其他代理的阻挡而无法接近自我代理。实验结果表明，将风险遮挡作为上游筛选模块用于行为规划器可以规划出比现有技术更决策和舒适的驾驶策略，前提是在这些情况下确保安全性。所提方法的可用性得到了验证。

    We consider the problem of group interactions in urban driving. State-of-the-art behavior planners for self-driving cars mostly consider each single agent-to-agent interaction separately in a cost function in order to find an optimal behavior for the ego agent, such as not colliding with any of the other agents. In this paper, we develop risk shadowing, a situation understanding method that allows us to go beyond single interactions by analyzing group interactions between three agents. Concretely, the presented method can find out which first other agent does not need to be considered in the behavior planner of an ego agent, because this first other agent cannot reach the ego agent due to a second other agent obstructing its way. In experiments, we show that using risk shadowing as an upstream filter module for a behavior planner allows to plan more decisive and comfortable driving strategies than state of the art, given that safety is ensured in these cases. The usability of the appro
    
[^16]: 休闲放松：通过观看SlowTV学习重建世界

    Kick Back & Relax: Learning to Reconstruct the World by Watching SlowTV. (arXiv:2307.10713v1 [cs.CV])

    [http://arxiv.org/abs/2307.10713](http://arxiv.org/abs/2307.10713)

    通过观看SlowTV学习重建世界的自监督单目深度估计模型在室内/室外数据集上具有良好的性能和已知-未知推广能力。这个模型使用了一个大规模SlowTV数据集以及一系列最佳实践来实现。

    

    自监督单目深度估计（SS-MDE）具有处理大量数据的潜力。然而，现有方法限制在汽车领域，导致模型无法推广到自然或室内环境等复杂环境。为了解决这个问题，我们提出了一个基于YouTube的大规模SlowTV数据集，比现有的汽车数据集包含更多数据。SlowTV包含了来自世界各地四季徒步旅行，风景驾驶和潜水等丰富多样的环境的170万张图片。我们使用这个数据集训练了一个SS-MDE模型，可以在室内/室外数据集中进行已知-未知推广。尽管使用了更高效的架构，但结果模型的性能超过了所有现有的自我监督学习方法，并且接近于有监督学习的SoTA。我们还引入了一系列最佳实践，进一步提高了性能和已知-未知推广能力。

    Self-supervised monocular depth estimation (SS-MDE) has the potential to scale to vast quantities of data. Unfortunately, existing approaches limit themselves to the automotive domain, resulting in models incapable of generalizing to complex environments such as natural or indoor settings.  To address this, we propose a large-scale SlowTV dataset curated from YouTube, containing an order of magnitude more data than existing automotive datasets. SlowTV contains 1.7M images from a rich diversity of environments, such as worldwide seasonal hiking, scenic driving and scuba diving. Using this dataset, we train an SS-MDE model that provides zero-shot generalization to a large collection of indoor/outdoor datasets. The resulting model outperforms all existing SSL approaches and closes the gap on supervised SoTA, despite using a more efficient architecture.  We additionally introduce a collection of best-practices to further maximize performance and zero-shot generalization. This includes 1) a
    
[^17]: AdjointDPM: 扩散概率模型梯度反向传播的伴随灵敏度方法

    AdjointDPM: Adjoint Sensitivity Method for Gradient Backpropagation of Diffusion Probabilistic Models. (arXiv:2307.10711v1 [cs.CV])

    [http://arxiv.org/abs/2307.10711](http://arxiv.org/abs/2307.10711)

    AdjointDPM是一种新的伴随灵敏度方法，用于扩散概率模型的梯度反向传播，解决了DPM定制化中内存消耗高的问题，并通过解决增强的ODE将损失的梯度反向传播到模型的参数。

    

    现有的定制化方法需要多个参考样例来将预训练的扩散概率模型(DPMs)与用户提供的概念对齐。本文旨在解决当唯一可用的监督是定义在生成内容上的可微度量时的DPM定制化挑战。由于DPM的采样过程涉及对去噪UNet的递归调用，朴素的梯度反向传播需要存储所有迭代的中间状态，导致内存消耗极高。为了解决这个问题，我们提出了一种新的方法AdjointDPM，首先通过求解相应的概率流ODE从扩散模型中生成新样本。然后使用伴随灵敏度方法通过求解另一个增强的ODE将损失的梯度反向传播到模型的参数(包括调制信号、网络权重和初始噪声)。为了减少正向生成和反向传播中的数值误差

    Existing customization methods require access to multiple reference examples to align pre-trained diffusion probabilistic models (DPMs) with user-provided concepts. This paper aims to address the challenge of DPM customization when the only available supervision is a differentiable metric defined on the generated contents. Since the sampling procedure of DPMs involves recursive calls to the denoising UNet, na\"ive gradient backpropagation requires storing the intermediate states of all iterations, resulting in extremely high memory consumption. To overcome this issue, we propose a novel method AdjointDPM, which first generates new samples from diffusion models by solving the corresponding probability-flow ODEs. It then uses the adjoint sensitivity method to backpropagate the gradients of the loss to the models' parameters (including conditioning signals, network weights, and initial noises) by solving another augmented ODE. To reduce numerical errors in both the forward generation and 
    
[^18]: 基于概率编程的智能虚拟代理架构框架研究

    Towards an architectural framework for intelligent virtual agents using probabilistic programming. (arXiv:2307.10693v1 [cs.AI])

    [http://arxiv.org/abs/2307.10693](http://arxiv.org/abs/2307.10693)

    使用概率编程的智能虚拟代理架构框架KorraAI可模拟代理的行为，考虑上下文信息和不确定信息，并实现自适应和积极主动的互动。

    

    我们提出了一个名为KorraAI的新框架，用于构建和设计具有体验对话能力的代理。我们的框架考虑了上下文信息，例如环境和互动时间，以及人类互动伙伴提供的不确定信息，模拟代理的行为。此外，KorraAI构建的代理可以表现出积极主动的行为，因为它们可以主动与人类伙伴进行互动。为了实现这些目的，KorraAI采用了概率编程。KorraAI中的概率模型用于建模代理的行为和与用户的互动。它们能够适应用户的偏好，并在代理中引入一定程度的不确定性，以实现更自然的行为。KorraAI可以使用分布和贝叶斯网络建模人类一样的内部状态，例如情绪、喜好和情感（如惊喜）。这些模型可以在没有与用户互动的情况下随时间演变。ECA模型作为插件实现，并共享一个共同的模块。

    We present a new framework called KorraAI for conceiving and building embodied conversational agents (ECAs). Our framework models ECAs' behavior considering contextual information, for example, about environment and interaction time, and uncertain information provided by the human interaction partner. Moreover, agents built with KorraAI can show proactive behavior, as they can initiate interactions with human partners. For these purposes, KorraAI exploits probabilistic programming. Probabilistic models in KorraAI are used to model its behavior and interactions with the user. They enable adaptation to the user's preferences and a certain degree of indeterminism in the ECAs to achieve more natural behavior. Human-like internal states, such as moods, preferences, and emotions (e.g., surprise), can be modeled in KorraAI with distributions and Bayesian networks. These models can evolve over time, even without interaction with the user. ECA models are implemented as plugins and share a commo
    
[^19]: 基于Answer Set Programming的有界组合重构方法

    Bounded Combinatorial Reconfiguration with Answer Set Programming. (arXiv:2307.10688v1 [cs.AI])

    [http://arxiv.org/abs/2307.10688](http://arxiv.org/abs/2307.10688)

    本研究提出了一种基于Answer Set Programming的有界组合重构方法，可以解决组合重构问题，并且在国际竞赛中取得了优异的成绩。

    

    我们提出一种称为有界组合重构的方法，用于解决基于Answer Set Programming（ASP）的组合重构问题。总体任务是研究源组合问题的解空间，并决定是否存在具有特殊属性的可行解序列。我们的recongo求解器覆盖了最近国际组合重构竞赛（CoRe Challenge 2022）的求解器类别中的所有指标。recongo在单引擎求解器方面的最短指标排名第一。在本文中，我们介绍了有界组合重构的设计和实现，并提出了独立集重构问题的ASP编码，这是最常研究的组合重构问题之一。最后，我们对CoRe Challenge 2022的所有实例进行了经验分析。

    We develop an approach called bounded combinatorial reconfiguration for solving combinatorial reconfiguration problems based on Answer Set Programming (ASP). The general task is to study the solution spaces of source combinatorial problems and to decide whether or not there are sequences of feasible solutions that have special properties. The resulting recongo solver covers all metrics of the solver track in the most recent international competition on combinatorial reconfiguration (CoRe Challenge 2022). recongo ranked first in the shortest metric of the single-engine solvers track. In this paper, we present the design and implementation of bounded combinatorial reconfiguration, and present an ASP encoding of the independent set reconfiguration problem that is one of the most studied combinatorial reconfiguration problems. Finally, we present empirical analysis considering all instances of CoRe Challenge 2022.
    
[^20]: 基于知识图谱嵌入的个性化推荐系统

    A Personalized Recommender System Based-on Knowledge Graph Embeddings. (arXiv:2307.10680v1 [cs.AI])

    [http://arxiv.org/abs/2307.10680](http://arxiv.org/abs/2307.10680)

    本研究通过知识图谱嵌入构建了一个个性化推荐系统，在车辆购买/销售领域中展现了其良好的推荐效果。

    

    知识图谱通过本体论对实体及其关系进行建模，已被证明在信息建模中非常有效。最近，人们对将知识图谱用作信息建模的兴趣不断增长，因此在推荐系统中的应用也越来越广泛。通过将用户和物品纳入知识图谱，这些系统可以更好地捕捉它们之间的隐含关联并提供更准确的推荐。本文通过应用于车辆购买/销售领域的知识图谱嵌入，研究并提出了一种个性化推荐系统的构建方法。实验结果表明，所提出的方法能够提供与个体用户一致的相关推荐。

    Knowledge graphs have proven to be effective for modeling entities and their relationships through the use of ontologies. The recent emergence in interest for using knowledge graphs as a form of information modeling has led to their increased adoption in recommender systems. By incorporating users and items into the knowledge graph, these systems can better capture the implicit connections between them and provide more accurate recommendations. In this paper, we investigate and propose the construction of a personalized recommender system via knowledge graphs embedding applied to the vehicle purchase/sale domain. The results of our experimentation demonstrate the efficacy of the proposed method in providing relevant recommendations that are consistent with individual users.
    
[^21]: SciBench: 对大型语言模型评估大学水平的科学问题解决能力

    SciBench: Evaluating College-Level Scientific Problem-Solving Abilities of Large Language Models. (arXiv:2307.10635v1 [cs.CL])

    [http://arxiv.org/abs/2307.10635](http://arxiv.org/abs/2307.10635)

    这篇论文介绍了一个名为SciBench的基准套件，旨在对大型语言模型的大学水平科学问题解决能力进行评估。研究结果显示，当前的语言模型在提供复杂科学问题解决能力方面还有不足之处。

    

    最近大型语言模型(LLMs)的进展在许多数学基准上取得了显著的进步。然而，这些基准大多只包含初高中科目的问题，仅包含多项选择题，并且仅限于基本算术运算范围。为了解决这些问题，本文介绍了一个广泛的基准套件SciBench，旨在系统地检测复杂科学问题解决所需的推理能力。SciBench包含两个经过精心策划的数据集：一个开放集，包括从数学、化学和物理教科书中摘录的大学水平的科学问题，以及一个封闭集，包含来自计算机科学和数学本科考试的问题。基于这两个数据集，我们对两个代表性的LLM进行了深入的基准研究，并采用不同的提示策略。结果表明，当前的LLMs在提供复杂科学问题解决能力方面还存在不足之处。

    Recent advances in large language models (LLMs) have demonstrated notable progress on many mathematical benchmarks. However, most of these benchmarks only feature problems grounded in junior and senior high school subjects, contain only multiple-choice questions, and are confined to a limited scope of elementary arithmetic operations. To address these issues, this paper introduces an expansive benchmark suite SciBench that aims to systematically examine the reasoning capabilities required for complex scientific problem solving. SciBench contains two carefully curated datasets: an open set featuring a range of collegiate-level scientific problems drawn from mathematics, chemistry, and physics textbooks, and a closed set comprising problems from undergraduate-level exams in computer science and mathematics. Based on the two datasets, we conduct an in-depth benchmark study of two representative LLMs with various prompting strategies. The results reveal that current LLMs fall short of deli
    
[^22]: Pluvio:通过迁移学习和条件变分信息瓶颈实现对领域外结构和库的汇编克隆搜索

    Pluvio: Assembly Clone Search for Out-of-domain Architectures and Libraries through Transfer Learning and Conditional Variational Information Bottleneck. (arXiv:2307.10631v1 [cs.SE])

    [http://arxiv.org/abs/2307.10631](http://arxiv.org/abs/2307.10631)

    本论文介绍了一种通过迁移学习和条件变分信息瓶颈实现对领域外结构和库的汇编克隆搜索的方法。已有的方法往往限制于少数训练过的工具链变体，而本研究首次解决了未见过架构和库的情况，提出了一种新的解决方案。

    

    代码重用在软件开发中至关重要，可以加快和提高开发生命周期的效率。然而，实际中，代码重用存在着控制不当的问题，导致漏洞传播和知识产权侵权等问题。汇编克隆搜索是一种重要的右移防御机制，已经在识别由已发布的可执行文件中的代码重用导致的漏洞方面取得了良好效果。最近关于汇编克隆搜索的研究表明，越来越多采用基于机器学习的方法来匹配由不同工具链生成的汇编代码变体。然而，这些方法仅限于从训练中学习到的少数工具链变体，无法应用于未见过的架构及其相应的编译工具链变体。本文首次研究了在未见过的架构和库中的汇编克隆搜索问题。我们提议通过人类共有知识来解决这个问题。

    The practice of code reuse is crucial in software development for a faster and more efficient development lifecycle. In reality, however, code reuse practices lack proper control, resulting in issues such as vulnerability propagation and intellectual property infringements. Assembly clone search, a critical shift-right defence mechanism, has been effective in identifying vulnerable code resulting from reuse in released executables. Recent studies on assembly clone search demonstrate a trend towards using machine learning-based methods to match assembly code variants produced by different toolchains. However, these methods are limited to what they learn from a small number of toolchain variants used in training, rendering them inapplicable to unseen architectures and their corresponding compilation toolchain variants.  This paper presents the first study on the problem of assembly clone search with unseen architectures and libraries. We propose incorporating human common knowledge throu
    
[^23]: 使用文本分类检测虚假评论

    Detecting deceptive reviews using text classification. (arXiv:2307.10617v1 [cs.IR])

    [http://arxiv.org/abs/2307.10617](http://arxiv.org/abs/2307.10617)

    这篇论文提出了一种使用机器学习模型的方法来识别虚假评论，并通过在餐馆评论的数据集上进行实验验证了其性能。

    

    近年来，在线评论在推广任何产品或服务方面发挥着重要作用。企业可能会嵌入虚假评论以吸引客户购买他们的产品。他们甚至可能突出强调自己产品的优点或批评竞争对手的产品。市场营销人员、广告商和其他在线商业用户有动机为他们想要推广的产品编写虚假的正面评论，或者为他们真正不喜欢的产品提供虚假的负面评论。因此，识别虚假评论是一个紧迫且持续的研究领域。本研究论文提出了一种机器学习模型方法来识别虚假评论。论文调查了在一个餐馆评论的虚假意见垃圾语料库数据集上进行的多次实验的性能。我们采用了n-gram模型和最大特征来识别虚假评论。

    In recent years, online reviews play a vital role for promoting any kind of product or services. Businesses may embed fake reviews in order to attract customers to purchase their products. They may even highlight the benefits of their own product or criticize the competition's product. Marketers, advertisers, and other online business users have incentive to create fake positive reviews for products which they want to promote or give fake negative reviews for products which they really don't like. So now-a-days writing a deceptive review is inevitable thing for promoting their own business or degrading competitor's reputation. Thus, identifying deceptive reviews is an intense and on-going research area. This research paper proposes machine learning model approach to identify deceptive reviews. The paper investigates the performance of the several experiments done on a Deceptive Opinion Spam Corpus dataset of restaurants reviews. We developed a n-gram model and max features to identify 
    
[^24]: 异构联邦学习：现状与研究挑战的技术综述

    Heterogeneous Federated Learning: State-of-the-art and Research Challenges. (arXiv:2307.10616v1 [cs.LG])

    [http://arxiv.org/abs/2307.10616](http://arxiv.org/abs/2307.10616)

    异构联邦学习是联邦学习领域中的一个重要研究方向，涉及到数据分布、模型架构、网络环境和硬件设备的异质性挑战。本文对异构联邦学习的研究挑战和最新进展进行了综述和分类，为进一步的研究提供了参考。

    

    联邦学习 (FL) 由于在大规模工业应用中的潜在用途而受到越来越多的关注。现有的联邦学习研究主要针对模型同质的情况。然而，实际的联邦学习通常面临参与方之间的数据分布、模型架构、网络环境和硬件设备的异质性。异构联邦学习 (HFL) 更具挑战性，相应的解决方案多样且复杂。因此，对这个主题进行关于研究挑战和最新进展的系统调查至关重要。在这项调查中，我们首先总结了 HFL 中来自五个方面的各种研究挑战：统计异质性、模型异质性、通信异质性、设备异质性和额外挑战。此外，我们回顾了 HFL 中的最新进展，并提出了对现有 HFL 方法的新分类法，并对其优缺点进行了深入分析。

    Federated learning (FL) has drawn increasing attention owing to its potential use in large-scale industrial applications. Existing federated learning works mainly focus on model homogeneous settings. However, practical federated learning typically faces the heterogeneity of data distributions, model architectures, network environments, and hardware devices among participant clients. Heterogeneous Federated Learning (HFL) is much more challenging, and corresponding solutions are diverse and complex. Therefore, a systematic survey on this topic about the research challenges and state-of-the-art is essential. In this survey, we firstly summarize the various research challenges in HFL from five aspects: statistical heterogeneity, model heterogeneity, communication heterogeneity, device heterogeneity, and additional challenges. In addition, recent advances in HFL are reviewed and a new taxonomy of existing HFL methods is proposed with an in-depth analysis of their pros and cons. We classify
    
[^25]: AI for All中的挑战与解决方案

    Challenges and Solutions in AI for All. (arXiv:2307.10600v1 [cs.AI])

    [http://arxiv.org/abs/2307.10600](http://arxiv.org/abs/2307.10600)

    这项研究展示了AI的普遍挑战：如偏见、歧视和不可信等，并提供了如何在设计中考虑多样性与包容性原则的解决方案。通过准确分析48篇研究文章，我们总结出了55个独特挑战和33个解决方案，还有24个独特挑战和23个解决方案用于增强AI实践。这项研究将对未来AI系统的研究人员和从业者有很大启示作用。

    

    人工智能（AI）的广泛应用和多样性需要在其设计中考虑多样性与包容性（D＆I）原则，以确保公平、信任和透明。然而，这些考虑往往被忽视，导致偏见、歧视和不可信的问题。为了解决这些问题，我们进行了一项系统性的综述，揭示了与人工智能中的D＆I相关的挑战和解决方案。我们严格搜索了2017年至2022年间发表的48篇研究文章。对这些论文进行编码分析，共发现55个关于AI中D＆I的独特挑战和33个解决方案，以及24个关于使用AI增强这些实践的独特挑战和23个解决方案。通过对这些问题的深入理解，本研究将为寻求将这些原则融入未来AI系统的研究人员和从业者提供启示。

    Artificial Intelligence (AI)'s pervasive presence and variety necessitate diversity and inclusivity (D&I) principles in its design for fairness, trust, and transparency. Yet, these considerations are often overlooked, leading to issues of bias, discrimination, and perceived untrustworthiness. In response, we conducted a Systematic Review to unearth challenges and solutions relating to D&I in AI. Our rigorous search yielded 48 research articles published between 2017 and 2022. Open coding of these papers revealed 55 unique challenges and 33 solutions for D&I in AI, as well as 24 unique challenges and 23 solutions for enhancing such practices using AI. This study, by offering a deeper understanding of these issues, will enlighten researchers and practitioners seeking to integrate these principles into future AI systems.
    
[^26]: 利用结构实现最佳多智能体贝叶斯分散估计

    Exploiting Structure for Optimal Multi-Agent Bayesian Decentralized Estimation. (arXiv:2307.10594v1 [cs.RO])

    [http://arxiv.org/abs/2307.10594](http://arxiv.org/abs/2307.10594)

    该论文介绍了一种解决贝叶斯分散数据融合中“谣言传播”问题的方法，通过利用概率独立结构和非整体加权因子，可以得到更紧实的边界，并通过通用优化方案充分利用任意依赖结构。

    

    贝叶斯分散数据融合中的一个关键挑战是“谣言传播”或“重复计数”现象，即先前发送的数据会返回给发送者。通常使用近似方法如协方差交集（CI）来解决此问题，它通过对估计值的加权平均来计算边界。问题是这个边界并不紧实，即估计往往过于保守。本文通过利用多智能体分散融合问题中的概率独立结构，展示了通过使用（i）CI算法的扩展，它使用多个（非整体的）加权因子而不是原始CI中的一个（整体的）因子，以及（ii）一个通用优化方案，能够计算最佳边界并充分利用任意依赖结构，来找到更紧实的边界。我们比较了我们的方法并展示它们在一个简单问题上收敛到相同的解。然后我们在实际问题上测试了我们新的非整体CI算法。

    A key challenge in Bayesian decentralized data fusion is the `rumor propagation' or `double counting' phenomenon, where previously sent data circulates back to its sender. It is often addressed by approximate methods like covariance intersection (CI) which takes a weighted average of the estimates to compute the bound. The problem is that this bound is not tight, i.e. the estimate is often over-conservative. In this paper, we show that by exploiting the probabilistic independence structure in multi-agent decentralized fusion problems a tighter bound can be found using (i) an expansion to the CI algorithm that uses multiple (non-monolithic) weighting factors instead of one (monolithic) factor in the original CI and (ii) a general optimization scheme that is able to compute optimal bounds and fully exploit an arbitrary dependency structure. We compare our methods and show that on a simple problem, they converge to the same solution. We then test our new non-monolithic CI algorithm on a l
    
[^27]: 自动驾驶系统测试与改进的边界状态生成

    Boundary State Generation for Testing and Improvement of Autonomous Driving Systems. (arXiv:2307.10590v1 [cs.SE])

    [http://arxiv.org/abs/2307.10590](http://arxiv.org/abs/2307.10590)

    该论文介绍了一种新的自动驾驶系统测试生成器（GenBo），它通过在无故障环境中变异自动驾驶车辆的驾驶条件来生成边界状态对，以解决现有测试方法中存在的问题。

    

    最近深度神经网络（DNN）和传感器技术的进展使得自动驾驶系统（ADS）具有了越来越高的自主性。然而，评估其可靠性仍然是一个关键问题。目前的ADS测试方法修改模拟驾驶环境的可控属性，直到ADS出现问题。这种方法有两个主要缺点：（1）对模拟环境的修改可能不容易转移到实际测试环境（例如改变道路形状）；（2）即使ADS在某些环境中成功，这些环境实例也会被丢弃，尽管它们可能包含ADS可能出现问题的潜在驾驶条件。本文提出了一种新的ADS测试生成器——GenBo（GENerator of BOundary state pairs）。GenBo在一个无故障环境实例中变异自动驾驶车辆的驾驶条件（位置，速度和方向），并有效地生成可边界化的状态对。

    Recent advances in Deep Neural Networks (DNNs) and sensor technologies are enabling autonomous driving systems (ADSs) with an ever-increasing level of autonomy. However, assessing their dependability remains a critical concern. State-of-the-art ADS testing approaches modify the controllable attributes of a simulated driving environment until the ADS misbehaves. Such approaches have two main drawbacks: (1) modifications to the simulated environment might not be easily transferable to the in-field test setting (e.g., changing the road shape); (2) environment instances in which the ADS is successful are discarded, despite the possibility that they could contain hidden driving conditions in which the ADS may misbehave.  In this paper, we present GenBo (GENerator of BOundary state pairs), a novel test generator for ADS testing. GenBo mutates the driving conditions of the ego vehicle (position, velocity and orientation), collected in a failure-free environment instance, and efficiently gener
    
[^28]: 预测电动汽车充电行为：采用微聚类和SMOTE技术的深度学习方法

    Forecasting Battery Electric Vehicle Charging Behavior: A Deep Learning Approach Equipped with Micro-Clustering and SMOTE Techniques. (arXiv:2307.10588v1 [cs.LG])

    [http://arxiv.org/abs/2307.10588](http://arxiv.org/abs/2307.10588)

    本研究开发了一种使用微聚类和SMOTE技术的深度学习方法，能够准确预测电动汽车充电事件，为电力负荷聚合器和电力管理人员提供提供充电站和电力容量的信息。

    

    能源系统、气候变化和公共健康是推动交通电气化的主要原因。全球范围内正在推广交通电气化以减少排放。因此，许多汽车制造商将很快开始只生产电池电动汽车（BEV）。由于气候变化和空气污染的担忧，加利福尼亚的BEV采用率正在上升。虽然这对于气候和污染目标来说很好，但未妥善管理的BEV充电可能导致充电基础设施不足和停电。本研究开发了一种新颖的微聚类深度神经网络（MCDNN），该算法在学习BEV行程和充电数据以预测BEV充电事件方面非常有效，这对于电力负荷聚合器和电力管理人员有效提供充电站和电力容量的信息至关重要。MCDNN使用加利福尼亚发生的行程和充电的稳健数据集进行配置。

    Energy systems, climate change, and public health are among the primary reasons for moving toward electrification in transportation. Transportation electrification is being promoted worldwide to reduce emissions. As a result, many automakers will soon start making only battery electric vehicles (BEVs). BEV adoption rates are rising in California, mainly due to climate change and air pollution concerns. While great for climate and pollution goals, improperly managed BEV charging can lead to insufficient charging infrastructure and power outages. This study develops a novel Micro Clustering Deep Neural Network (MCDNN), an artificial neural network algorithm that is highly effective at learning BEVs trip and charging data to forecast BEV charging events, information that is essential for electricity load aggregators and utility managers to provide charging stations and electricity capacity effectively. The MCDNN is configured using a robust dataset of trips and charges that occurred in Ca
    
[^29]: Ethosight: 一种基于联合嵌入的系统，利用上下文标签关联度度量和基于推理的迭代学习进行细致感知

    Ethosight: A Joint-Embedding Based System for Nuanced Perception Using Contextual Label Affinity Metric and Reasoning Based Iterative Learning. (arXiv:2307.10577v1 [cs.CV])

    [http://arxiv.org/abs/2307.10577](http://arxiv.org/abs/2307.10577)

    Ethosight是一种零样本计算机视觉算法，通过联合嵌入、上下文标签关联度计算和基于推理的迭代学习，实现对细微行为和场景细节的准确感知，同时消除了对预先存在符号知识的需求。

    

    传统的计算机视觉模型通常需要大量的人工努力来进行数据获取和验证，特别是在检测细微的行为细节或事件时。在实际应用中，区分常规行为和潜在风险的困难，如区分常规购物和潜在扒窃，进一步复杂化了这一过程。我们提出了Ethosight，一种新颖的零样本计算机视觉算法。Ethosight消除了对预先存在的符号知识的需求，从用户需求和感兴趣的语义知识出发进行自主学习。通过使用局部标签关联度计算和基于推理的迭代学习循环，Ethosight推断场景细节并迭代地优化标签集。推理机制可以来自大型语言模型如GPT4、符号推理器如OpenNARS或混合系统。Ethosight还充分利用了预训练的多模态模型ImageBind的能力。

    Traditional computer vision models often require extensive manual effort for data acquisition and validation, particularly when detecting subtle behavioral nuances or events. The difficulty in distinguishing routine behaviors from potential risks in real-world applications, like differentiating routine shopping from potential shoplifting, further complicates the process.  We present Ethosight, a novel zero-shot computer vision algorithm. Ethosight eradicates the need for pre-existing symbolic knowledge, initiating from a clean slate based on user requirements and semantic knowledge of interest. Using localized label affinity calculations and a reasoning-guided iterative learning loop, Ethosight infers scene details and iteratively refines the label set. Reasoning mechanisms can be derived from large language models like GPT4, symbolic reasoners like OpenNARS, or hybrid systems.  Ethosight further capitalizes on the capabilities of a pre-trained multi-modal model, ImageBind, generating 
    
[^30]: 使用原型正则化提升联邦学习的收敛性

    Boosting Federated Learning Convergence with Prototype Regularization. (arXiv:2307.10575v1 [cs.LG])

    [http://arxiv.org/abs/2307.10575](http://arxiv.org/abs/2307.10575)

    本论文通过引入原型正则化策略来解决联邦学习中异质数据分布的问题，实验证明在MNIST和Fashion-MNIST数据集上相比基准模型FedAvg，我们的方法分别提高了3.3%和8.9%的平均测试准确率，并且在异构设置下具有快速收敛速度。

    

    作为一种分布式机器学习技术，联邦学习（FL）要求客户端在不泄露本地数据的情况下与边缘服务器共同训练共享模型。然而，客户端之间的异构数据分布往往导致模型性能下降。为了解决这个问题，本文引入了一种基于原型的正则化策略来解决数据分布的异质性。具体而言，正则化过程涉及服务器从分布式客户端聚合本地原型以生成全局原型，然后将其发送回个体客户端以指导其本地训练。在MNIST和Fashion-MNIST上的实验结果表明，与最流行的基准FedAvg相比，我们的提议分别在平均测试准确率上实现了3.3%和8.9%的改进。此外，我们的方法在异构环境中具有快速收敛速度。

    As a distributed machine learning technique, federated learning (FL) requires clients to collaboratively train a shared model with an edge server without leaking their local data. However, the heterogeneous data distribution among clients often leads to a decrease in model performance. To tackle this issue, this paper introduces a prototype-based regularization strategy to address the heterogeneity in the data distribution. Specifically, the regularization process involves the server aggregating local prototypes from distributed clients to generate a global prototype, which is then sent back to the individual clients to guide their local training. The experimental results on MNIST and Fashion-MNIST show that our proposal achieves improvements of 3.3% and 8.9% in average test accuracy, respectively, compared to the most popular baseline FedAvg. Furthermore, our approach has a fast convergence rate in heterogeneous settings.
    
[^31]: 无效逻辑，等效收益：语言模型提示中的奇怪推理

    Invalid Logic, Equivalent Gains: The Bizarreness of Reasoning in Language Model Prompting. (arXiv:2307.10573v1 [cs.AI])

    [http://arxiv.org/abs/2307.10573](http://arxiv.org/abs/2307.10573)

    最近的研究发现，在语言模型的提示中使用逻辑上无效的Chain-of-Thought（CoT）提示几乎可以提供与逻辑上有效的提示相似的性能增益，而且在最困难的任务上也是如此。

    

    语言模型可以被提示以一种显著提高性能的方式进行推理问题。然而，为什么这样的提示会提高性能还不清楚。最近的研究表明，使用逻辑上无效的CoT提示几乎可以像逻辑上有效的CoT提示一样显著提高性能，并且将CoT提示中的特定问题信息替换为抽象信息或超出分布的信息通常不会损害性能。批评人士回应说，这些发现是基于太少、太简单的任务来得出有意义的结论。为了解决这个争议，我们测试了在BIG-Bench基准测试中最困难的任务上，逻辑上无效的CoT提示是否提供与逻辑上有效的提示相同水平的性能提升，这些任务被称为BIG-Bench Hard（BBH）。我们发现，在BBH任务上，逻辑上无效的推理提示确实实现了类似的性能提升。

    Language models can be prompted to reason through problems in a manner that significantly improves performance. However, \textit{why} such prompting improves performance is unclear. Recent work showed that using logically \textit{invalid} Chain-of-Thought (CoT) prompting improves performance almost as much as logically \textit{valid} CoT prompting, and that editing CoT prompts to replace problem-specific information with abstract information or out-of-distribution information typically doesn't harm performance. Critics have responded that these findings are based on too few and too easy tasks to draw meaningful conclusions. To resolve this dispute, we test whether logically invalid CoT prompts offer the same level of performance gains as logically valid prompts on the hardest tasks in the BIG-Bench benchmark, termed BIG-Bench Hard (BBH). We find that the logically \textit{invalid} reasoning prompts do indeed achieve similar performance gains on BBH tasks as logically valid reasoning pr
    
[^32]: 欺骗性对齐监测

    Deceptive Alignment Monitoring. (arXiv:2307.10569v1 [cs.LG])

    [http://arxiv.org/abs/2307.10569](http://arxiv.org/abs/2307.10569)

    本论文提出了欺骗性对齐监测这一新方向，旨在探讨大型机器学习模型在表面上表现正常，却暗中进行隐藏行为的问题，并提出了新的研究机会。

    

    随着大型机器学习模型的能力不断增长，以及对这些模型的自治权不断扩大，一个新的对手出现了：模型本身。一个模型看似合理地行为，却暗中、微妙地修改其行为以达到别的目的的威胁，通常在AI安全与对齐社区中被称为欺骗性对齐。因此，我们将这个新方向称为欺骗性对齐监测。在这项工作中，我们确定了机器学习不同子领域中的新兴方向，我们认为在不久的将来对欺骗性对齐监测会变得越来越重要且紧密相关，并且我们认为这些领域的进步既提出了长期挑战，也带来了新的研究机会。最后，我们呼吁对抗性机器学习社区更多地参与这些新兴方向的研究。

    As the capabilities of large machine learning models continue to grow, and as the autonomy afforded to such models continues to expand, the spectre of a new adversary looms: the models themselves. The threat that a model might behave in a seemingly reasonable manner, while secretly and subtly modifying its behavior for ulterior reasons is often referred to as deceptive alignment in the AI Safety & Alignment communities. Consequently, we call this new direction Deceptive Alignment Monitoring. In this work, we identify emerging directions in diverse machine learning subfields that we believe will become increasingly important and intertwined in the near future for deceptive alignment monitoring, and we argue that advances in these fields present both long-term challenges and new research opportunities. We conclude by advocating for greater involvement by the adversarial machine learning community in these emerging directions.
    
[^33]: FACADE：一种用于对抗电路异常检测和评估的框架

    FACADE: A Framework for Adversarial Circuit Anomaly Detection and Evaluation. (arXiv:2307.10563v1 [cs.LG])

    [http://arxiv.org/abs/2307.10563](http://arxiv.org/abs/2307.10563)

    FACADE是一种新型的概率和几何框架，用于无监督检测深度神经网络中的机理异常，并提供关键的洞察力和强大工具，以揭示和对抗对抗攻击，并在实际部署环境中展示了有前途的应用。

    

    我们提出了FACADE，一种新颖的概率和几何框架，旨在对深度神经网络中进行无监督的机理异常检测。其主要目标是推进对抗攻击的理解和减轻。FACADE旨在生成电路上的概率分布，这为伪类的流形特性变化以及激活空间中高维模式的贡献提供了关键的洞察力，从而为揭示和对抗对抗攻击提供了强大工具。我们的方法旨在提高模型的鲁棒性，增强可扩展模型监控，并在实际部署环境中展示了有前途的应用。

    We present FACADE, a novel probabilistic and geometric framework designed for unsupervised mechanistic anomaly detection in deep neural networks. Its primary goal is advancing the understanding and mitigation of adversarial attacks. FACADE aims to generate probabilistic distributions over circuits, which provide critical insights to their contribution to changes in the manifold properties of pseudo-classes, or high-dimensional modes in activation space, yielding a powerful tool for uncovering and combating adversarial attacks. Our approach seeks to improve model robustness, enhance scalable model oversight, and demonstrates promising applications in real-world deployment settings.
    
[^34]: 使用合规化动态图学习预测空中交通管制员工作负荷水平

    Air Traffic Controller Workload Level Prediction using Conformalized Dynamical Graph Learning. (arXiv:2307.10559v1 [cs.LG])

    [http://arxiv.org/abs/2307.10559](http://arxiv.org/abs/2307.10559)

    本研究提出了一种使用合规化动态图学习来预测空中交通管制员工作负荷水平的方法，通过对退休空中交通管制员进行人机交互模拟，利用空中交通数据和工作负荷标签进行预测和评估。

    

    空中交通管制是一个安全关键的服务系统，要求地面空中交通管制员（ATCo）时刻关注以维持日常航空运营。ATCo的工作负荷可能对运营安全和空域使用产生负面影响。为了避免过载并确保ATCo的可接受工作负荷水平，准确预测ATCo的工作负荷对于采取缓解措施非常重要。在本文中，我们首先对ATCo工作负荷的研究进行了回顾，主要从空中交通的角度。然后，我们简要介绍了与退休ATCo进行人机交互模拟的设置，其中获得了空中交通数据和工作负荷标签。模拟在三种菲尼克斯接近场景下进行，要求人类ATCo自我评估其工作负荷评级（即，低-1到高-7）。进行了初步的数据分析。接下来，我们提出了一个基于图的深度学习框架，结合合规化预测，来对ATCo的工作负荷进行预测。

    Air traffic control (ATC) is a safety-critical service system that demands constant attention from ground air traffic controllers (ATCos) to maintain daily aviation operations. The workload of the ATCos can have negative effects on operational safety and airspace usage. To avoid overloading and ensure an acceptable workload level for the ATCos, it is important to predict the ATCos' workload accurately for mitigation actions. In this paper, we first perform a review of research on ATCo workload, mostly from the air traffic perspective. Then, we briefly introduce the setup of the human-in-the-loop (HITL) simulations with retired ATCos, where the air traffic data and workload labels are obtained. The simulations are conducted under three Phoenix approach scenarios while the human ATCos are requested to self-evaluate their workload ratings (i.e., low-1 to high-7). Preliminary data analysis is conducted. Next, we propose a graph-based deep-learning framework with conformal prediction to ide
    
[^35]: EMQ：演化无需训练的代理用于自动混合精度量化

    EMQ: Evolving Training-free Proxies for Automated Mixed Precision Quantization. (arXiv:2307.10554v1 [cs.CV])

    [http://arxiv.org/abs/2307.10554](http://arxiv.org/abs/2307.10554)

    本论文提出了一个演化算法的自动搜索代理框架，用于实现混合精度量化中的训练-free 方法。通过构建MQ-Bench-101数据集，发现现有的无需训练的代理在量化精度方面存在相关性不明确的问题。通过演化搜索，找到了最佳相关的MQ代理。

    

    混合精度量化（MQ）可以在模型中实现竞争性的精度-复杂度权衡。传统的基于训练的搜索方法需要耗费时间进行候选训练，以搜索MQ中优化的逐层比特宽度配置。最近，一些无需训练的方法提出了多种MQ代理，并显著提高了搜索效率。然而，这些代理与量化精度之间的相关性仍不明确。为了弥补这一差距，我们首先构建了MQ-Bench-101，其中包含不同的比特配置和量化结果。然后，我们观察到现有的无需训练的代理在MQ-Bench-101上表现出弱相关性。为了高效地寻找优秀的代理，我们通过演化算法开发了一个自动搜索代理的框架用于MQ。具体而言，我们设计了一个包括现有代理的精心设计的搜索空间，并进行演化搜索以发现最佳相关的MQ代理。我们提出了一种多样性提示的方法

    Mixed-Precision Quantization~(MQ) can achieve a competitive accuracy-complexity trade-off for models. Conventional training-based search methods require time-consuming candidate training to search optimized per-layer bit-width configurations in MQ. Recently, some training-free approaches have presented various MQ proxies and significantly improve search efficiency. However, the correlation between these proxies and quantization accuracy is poorly understood. To address the gap, we first build the MQ-Bench-101, which involves different bit configurations and quantization results. Then, we observe that the existing training-free proxies perform weak correlations on the MQ-Bench-101. To efficiently seek superior proxies, we develop an automatic search of proxies framework for MQ via evolving algorithms. In particular, we devise an elaborate search space involving the existing proxies and perform an evolution search to discover the best correlated MQ proxy. We proposed a diversity-promptin
    
[^36]: PPN: 并行指针网络用于具有复杂布局的关键信息提取

    PPN: Parallel Pointer-based Network for Key Information Extraction with Complex Layouts. (arXiv:2307.10551v1 [cs.AI])

    [http://arxiv.org/abs/2307.10551](http://arxiv.org/abs/2307.10551)

    该论文提出了一个名为PPN的并行指针网络，用于解决关键信息提取的挑战。作者通过引入一个名为CLEX的大规模数据集来解决现有数据集中布局和语义实体类别数量的限制，并采用端到端的方法来解决错误传播问题。

    

    关键信息提取（KIE）是一个具有挑战性的多模态任务，旨在从视觉丰富的文档中提取结构化的语义实体值。尽管已经取得了显著进展，但仍存在两个需要解决的主要挑战。首先，现有数据集的布局相对固定，并在语义实体类别数量上有限，导致这些数据集与复杂的现实场景之间存在显著差距。其次，现有方法采用两阶段的流水线策略，可能导致错误传播问题。此外，它们在新出现的语义实体类别出现的情况下很难应用。为了解决第一个挑战，我们提出了一个名为复杂布局表单的新的大规模人工注释数据集（CLEX），其中包含5,860个图像和1,162个语义实体类别。为了解决第二个挑战，我们引入了并行指针网络（PPN），它是一个端到端的解决方案。

    Key Information Extraction (KIE) is a challenging multimodal task that aims to extract structured value semantic entities from visually rich documents. Although significant progress has been made, there are still two major challenges that need to be addressed. Firstly, the layout of existing datasets is relatively fixed and limited in the number of semantic entity categories, creating a significant gap between these datasets and the complex real-world scenarios. Secondly, existing methods follow a two-stage pipeline strategy, which may lead to the error propagation problem. Additionally, they are difficult to apply in situations where unseen semantic entity categories emerge. To address the first challenge, we propose a new large-scale human-annotated dataset named Complex Layout form for key information EXtraction (CLEX), which consists of 5,860 images with 1,162 semantic entity categories. To solve the second challenge, we introduce Parallel Pointer-based Network (PPN), an end-to-end
    
[^37]: 区块链上的动态大型语言模型

    Dynamic Large Language Models on Blockchains. (arXiv:2307.10549v1 [cs.CV])

    [http://arxiv.org/abs/2307.10549](http://arxiv.org/abs/2307.10549)

    本文提出在区块链上训练和部署动态大型语言模型，通过使用分布式计算和提供无法篡改的交易分类帐的区块链技术，可使语言模型具备连续学习的能力，为下一代人工智能系统的发展提供了新的方法和启示。

    

    训练和部署大型语言模型需要大量的计算资源，因为语言模型包含数十亿个参数，文本拥有数千个标记。另一个问题是大型语言模型是静态的，在训练过程后就被固定下来了。为了解决这些问题，本文提出在区块链上训练和部署动态大型语言模型，区块链具有高计算性能并分布在一个计算机网络上。区块链是一个安全、分散和透明的系统，允许创建一个无法篡改的交易分类帐，无需中介机构。动态大型语言模型可以在训练过程之后不断从用户输入中学习。我们的方法提供了一种开发大型语言模型的新方法，并为下一代人工智能系统带来了启示。

    Training and deploying the large language models requires a large mount of computational resource because the language models contain billions of parameters and the text has thousands of tokens. Another problem is that the large language models are static. They are fixed after the training process. To tackle these issues, in this paper, we propose to train and deploy the dynamic large language model on blockchains, which have high computation performance and are distributed across a network of computers. A blockchain is a secure, decentralized, and transparent system that allows for the creation of a tamper-proof ledger for transactions without the need for intermediaries. The dynamic large language models can continuously learn from the user input after the training process. Our method provides a new way to develop the large language models and also sheds a light on the next generation artificial intelligence systems.
    
[^38]: TREA: 树状结构推理模式用于对话式推荐系统

    TREA: Tree-Structure Reasoning Schema for Conversational Recommendation. (arXiv:2307.10543v1 [cs.AI])

    [http://arxiv.org/abs/2307.10543](http://arxiv.org/abs/2307.10543)

    TREA是一种树状结构推理模式，可用于对话式推荐系统。它通过构建一个多层次的可扩展树来澄清对话中提及实体之间的因果关系，并充分利用历史对话生成更合理和适当的推荐结果响应。

    

    对话式推荐系统旨在通过对话追踪用户的动态兴趣，并生成与物品推荐相关的响应。最近，为了增强对话上下文的理解，各种外部知识库（特别是知识图谱）被纳入到对话式推荐系统中。然而，最近的基于推理的模型过于依赖简化的结构，如线性结构或固定的层次结构，无法完全理解与外部知识相关的对话之间的复杂关系。为了解决这个问题，我们提出了一个名为TREA的新颖的树状结构推理模式。TREA构建了一个多层次可扩展的树作为推理结构，以澄清所提及实体之间的因果关系，并充分利用历史对话生成更合理和适当的推荐结果响应。对两个公共对话式推荐系统数据集进行了广泛的实验证明了TREA的有效性。

    Conversational recommender systems (CRS) aim to timely trace the dynamic interests of users through dialogues and generate relevant responses for item recommendations. Recently, various external knowledge bases (especially knowledge graphs) are incorporated into CRS to enhance the understanding of conversation contexts. However, recent reasoning-based models heavily rely on simplified structures such as linear structures or fixed-hierarchical structures for causality reasoning, hence they cannot fully figure out sophisticated relationships among utterances with external knowledge. To address this, we propose a novel Tree structure Reasoning schEmA named TREA. TREA constructs a multi-hierarchical scalable tree as the reasoning structure to clarify the causal relationships between mentioned entities, and fully utilizes historical conversations to generate more reasonable and suitable responses for recommended results. Extensive experiments on two public CRS datasets have demonstrated the
    
[^39]: 快速无监督深度异常值模型选择与超网络

    Fast Unsupervised Deep Outlier Model Selection with Hypernetworks. (arXiv:2307.10529v1 [cs.LG])

    [http://arxiv.org/abs/2307.10529](http://arxiv.org/abs/2307.10529)

    本文提出了HYPER用于调整基于深度神经网络的异常值检测模型，解决了无监督DOD模型中的超参数调整和模型选择的挑战，通过设计和训练超网络(HN)将超参数映射到主要DOD模型的最优权重上。

    

    异常值检测(OD)在许多领域都有应用，并有许多技术的丰富文献。基于深度神经网络的OD(DOD)由于深度学习的许多进展而受到了最近的关注。在本文中，我们考虑了一个关键但鲜为人知的问题，即无监督DOD的有效超参数(HP)调整/模型选择。虽然一些先前的工作报告了OD模型对HP的敏感性，但对于展示了长列表HP的现代DOD模型来说，这变得非常关键。我们引入了HYPER来调整DOD模型，解决了两个基本挑战：(1)无监督情况下的验证(由于缺乏标记的异常值)，以及(2) HP/模型空间的高效搜索 (由于HP数量的指数增长)。关键思想是设计和训练一个新颖的超网络(HN)，其将HP映射到主要DOD模型的最优权重上。反过来，HYPER利用一个单独的HN，可以动态生成多个DOD模型的权重 (对应于...)。

    Outlier detection (OD) finds many applications with a rich literature of numerous techniques. Deep neural network based OD (DOD) has seen a recent surge of attention thanks to the many advances in deep learning. In this paper, we consider a critical-yet-understudied challenge with unsupervised DOD, that is, effective hyperparameter (HP) tuning/model selection. While several prior work report the sensitivity of OD models to HPs, it becomes ever so critical for the modern DOD models that exhibit a long list of HPs. We introduce HYPER for tuning DOD models, tackling two fundamental challenges: (1) validation without supervision (due to lack of labeled anomalies), and (2) efficient search of the HP/model space (due to exponential growth in the number of HPs). A key idea is to design and train a novel hypernetwork (HN) that maps HPs onto optimal weights of the main DOD model. In turn, HYPER capitalizes on a single HN that can dynamically generate weights for many DOD models (corresponding t
    
[^40]: 通过社区参与构建与社会文化包容性的刻板印象资源

    Building Socio-culturally Inclusive Stereotype Resources with Community Engagement. (arXiv:2307.10514v1 [cs.CL])

    [http://arxiv.org/abs/2307.10514](http://arxiv.org/abs/2307.10514)

    通过社区参与的努力，在印度社会背景下扩展了对刻板印象伤害的评估资源。这个工作强调了包容不同文化和社会背景的人们和经验，以避免对伤害测量的严重低估或扭曲。

    

    随着生成语言模型在全球范围内的迅速发展和部署，我们迫切需要在测量伤害方面进行扩展，不仅包括覆盖的伤害数量和类型，还要考虑到当地文化背景，包括边缘化身份和他们所经历的社会偏见。当前的评估范式在解决这个问题上存在局限性，因为它们不代表多元化、本地化但全球化的社会文化视角。为了避免对伤害测量产生严重低估或扭曲，我们迫切需要通过包含来自不同文化和社会的人们和经验来增强和校准我们的评估资源。在这项工作中，我们在印度社会背景下展示了对刻板印象伤害实施社会文化意识的评估资源的扩展。我们设计了一个社区参与的努力来构建一个包含刻板印象的资源。

    With rapid development and deployment of generative language models in global settings, there is an urgent need to also scale our measurements of harm, not just in the number and types of harms covered, but also how well they account for local cultural contexts, including marginalized identities and the social biases experienced by them. Current evaluation paradigms are limited in their abilities to address this, as they are not representative of diverse, locally situated but global, socio-cultural perspectives. It is imperative that our evaluation resources are enhanced and calibrated by including people and experiences from different cultures and societies worldwide, in order to prevent gross underestimations or skews in measurements of harm. In this work, we demonstrate a socio-culturally aware expansion of evaluation resources in the Indian societal context, specifically for the harm of stereotyping. We devise a community engaged effort to build a resource which contains stereotype
    
[^41]: IvyGPT：基于医学领域的互动式中文路径语言模型

    IvyGPT: InteractiVe Chinese pathwaY language model in medical domain. (arXiv:2307.10512v1 [cs.CL])

    [http://arxiv.org/abs/2307.10512](http://arxiv.org/abs/2307.10512)

    IvyGPT是一种基于医学领域的中文互动语言模型，通过使用高质量的医学问答示例和人类反馈强化学习进行训练和微调，它能够输出更丰富的诊断和治疗答案，从而在医学GPT模型中表现出色。

    

    一般的大型语言模型（LLM）如ChatGPT已取得了显著的成功。然而，由于精度不高和无法提供医疗建议，这些LLM在医学领域并未广泛应用。我们提出了一种基于LLaMA的LLM IvyGPT，它通过高质量的医学问答（QA）示例和人类反馈强化学习（RLHF）进行训练和微调。经过有监督微调后，IvyGPT具有良好的多轮对话能力，但在综合诊断等其他方面不能像医生一样运行。通过RLHF，IvyGPT可以输出更丰富的诊断和治疗答案，更接近于人类。在训练过程中，我们使用QLoRA在少量NVIDIA A100（80GB) GPU上训练了330亿个参数。实验结果表明，IvyGPT在医学GPT模型中表现优于其他模型。

    General large language models (LLMs) such as ChatGPT have shown remarkable success. However, such LLMs have not been widely adopted for medical purposes, due to poor accuracy and inability to provide medical advice. We propose IvyGPT, an LLM based on LLaMA that is trained and fine-tuned with high-quality medical question-answer (QA) instances and Reinforcement Learning from Human Feedback (RLHF). After supervised fine-tuning, IvyGPT has good multi-turn conversation capabilities, but it cannot perform like a doctor in other aspects, such as comprehensive diagnosis. Through RLHF, IvyGPT can output richer diagnosis and treatment answers that are closer to human. In the training, we used QLoRA to train 33 billion parameters on a small number of NVIDIA A100 (80GB) GPUs. Experimental results show that IvyGPT has outperformed other medical GPT models.
    
[^42]: 具有时变几何折扣的马尔可夫决策过程

    Markov Decision Processes with Time-Varying Geometric Discounting. (arXiv:2307.10491v1 [cs.AI])

    [http://arxiv.org/abs/2307.10491](http://arxiv.org/abs/2307.10491)

    本论文研究了具有时变折扣因子的马尔可夫决策过程模型，采用博弈论视角，证明了存在子博弈完美均衡，并给出了计算算法和时间复杂度的分析。

    

    传统的马尔可夫决策过程模型通常考虑基于常数折扣因子的几何折扣。然而，一些最近的研究表明，在某些应用中，对时间变化的折扣因子进行建模是必要的。本文研究了具有时变折扣因子的无穷时间程决策过程模型。我们采用博弈论的视角，将每个时间步骤视为一个独立的决策者，拥有自己的（固定的）折扣因子，并研究所得到的博弈的子博弈完美均衡以及相关的算法问题。我们给出了一个存在子博弈完美均衡的构造性证明，并展示了计算子博弈完美均衡的时间复杂度的EXPTIME困难性。我们还转向近似的$\epsilon$-子博弈完美均衡的概念，证明了在较温和的假设下，存在一个$\epsilon$-子博弈完美均衡。我们介绍了一个计算$\epsilon$-子博弈完美均衡的算法，并给出了时间复杂度的上界。

    Canonical models of Markov decision processes (MDPs) usually consider geometric discounting based on a constant discount factor. While this standard modeling approach has led to many elegant results, some recent studies indicate the necessity of modeling time-varying discounting in certain applications. This paper studies a model of infinite-horizon MDPs with time-varying discount factors. We take a game-theoretic perspective -- whereby each time step is treated as an independent decision maker with their own (fixed) discount factor -- and we study the subgame perfect equilibrium (SPE) of the resulting game as well as the related algorithmic problems. We present a constructive proof of the existence of an SPE and demonstrate the EXPTIME-hardness of computing an SPE. We also turn to the approximate notion of $\epsilon$-SPE and show that an $\epsilon$-SPE exists under milder assumptions. An algorithm is presented to compute an $\epsilon$-SPE, of which an upper bound of the time complexit
    
[^43]: 图像和声音的滥用用于在多模态LLMs中进行间接指令注入

    (Ab)using Images and Sounds for Indirect Instruction Injection in Multi-Modal LLMs. (arXiv:2307.10490v1 [cs.CR])

    [http://arxiv.org/abs/2307.10490](http://arxiv.org/abs/2307.10490)

    本论文展示了如何利用图像和声音在多模态LLMs中进行间接指令注入，攻击者通过生成对抗扰动并将其融入图像或音频录音中，以操纵模型输出特定文本和指导对话的行为。

    

    我们展示了如何利用图像和声音在多模态LLMs中进行间接提示和指令注入。攻击者生成与提示相对应的对抗扰动，并将其融入图像或音频录音中。当用户向（未修改的良性）模型询问被扰动的图像或音频时，扰动会引导模型输出攻击者选择的文本和/或使后续对话遵循攻击者的指令。我们用几个概念验证示例针对LLaVa和PandaGPT来说明这种攻击。

    We demonstrate how images and sounds can be used for indirect prompt and instruction injection in multi-modal LLMs. An attacker generates an adversarial perturbation corresponding to the prompt and blends it into an image or audio recording. When the user asks the (unmodified, benign) model about the perturbed image or audio, the perturbation steers the model to output the attacker-chosen text and/or make the subsequent dialog follow the attacker's instruction. We illustrate this attack with several proof-of-concept examples targeting LLaVa and PandaGPT.
    
[^44]: 恶意注释下的物体检测后门攻击

    Backdoor Attack against Object Detection with Clean Annotation. (arXiv:2307.10487v1 [cs.CV])

    [http://arxiv.org/abs/2307.10487](http://arxiv.org/abs/2307.10487)

    本文提出了一种在物体检测中进行后门攻击的方法，通过嵌入隐藏的后门，使得模型在正常数据上表现正常，在触发器出现时给出攻击者指定的判断。这对于安全敏感应用如自动驾驶具有严重威胁。

    

    深度神经网络（DNN）在物体检测任务中取得了前所未有的成功。然而，也发现DNN对多种攻击，包括后门攻击，是脆弱的。通过这种攻击，攻击者成功地将隐藏的后门嵌入到DNN中，使得模型在良性数据样本上表现正常，但在预定义触发器出现时给出攻击者指定的判断。尽管已经在图像分类上尝试了大量后门攻击，但对物体检测任务的后门攻击研究尚未得到适当的调查和探索。由于物体检测已被应用于多个安全敏感应用程序的重要模块，如自动驾驶，对物体检测的后门攻击可能造成更严重的威胁。受基于深度学习的目标检测器的固有属性启发，我们提出了一种简单而有效的物体检测后门攻击方法，而不修改地面真伪标签。

    Deep neural networks (DNNs) have shown unprecedented success in object detection tasks. However, it was also discovered that DNNs are vulnerable to multiple kinds of attacks, including Backdoor Attacks. Through the attack, the attacker manages to embed a hidden backdoor into the DNN such that the model behaves normally on benign data samples, but makes attacker-specified judgments given the occurrence of a predefined trigger. Although numerous backdoor attacks have been experimented on image classification, backdoor attacks on object detection tasks have not been properly investigated and explored. As object detection has been adopted as an important module in multiple security-sensitive applications such as autonomous driving, backdoor attacks on object detection could pose even more severe threats. Inspired by the inherent property of deep learning-based object detectors, we propose a simple yet effective backdoor attack method against object detection without modifying the ground tr
    
[^45]: 通过提示，指令微调的语言模型能否识别社会偏见？

    Can Instruction Fine-Tuned Language Models Identify Social Bias through Prompting?. (arXiv:2307.10472v1 [cs.CL])

    [http://arxiv.org/abs/2307.10472](http://arxiv.org/abs/2307.10472)

    本文介绍了一种通过零样本提示评估指令微调语言模型识别偏见能力的方法，展示了Alpaca 7B在偏见识别任务中的最佳性能，并提出扩大模型大小和数据多样性可进一步提高性能。

    

    随着语言模型应用的广度和深度不断扩展，构建有效的框架来衡量和减轻这些模型学习或继承的社会偏见变得越来越重要。本文提出了一种评估指令微调语言模型通过零样本提示（包括思维链提示）识别偏见能力的方法。在LLaMA及其两个指令微调版本中，Alpaca 7B在偏见识别任务中表现最好，准确率达56.7%。我们还展示了扩大语言模型大小和数据多样性可以进一步提高性能。这是我们偏见缓解框架的第一部分，正在进行的工作。我们将根据获得的更多结果不断更新本文。

    As the breadth and depth of language model applications continue to expand rapidly, it is increasingly important to build efficient frameworks for measuring and mitigating the learned or inherited social biases of these models. In this paper, we present our work on evaluating instruction fine-tuned language models' ability to identify bias through zero-shot prompting, including Chain-of-Thought (CoT) prompts. Across LLaMA and its two instruction fine-tuned versions, Alpaca 7B performs best on the bias identification task with an accuracy of 56.7%. We also demonstrate that scaling up LLM size and data diversity could lead to further performance gain. This is a work-in-progress presenting the first component of our bias mitigation framework. We will keep updating this work as we get more results.
    
[^46]: 专利中可视化类型和视角的分类

    Classification of Visualization Types and Perspectives in Patents. (arXiv:2307.10471v1 [cs.CV])

    [http://arxiv.org/abs/2307.10471](http://arxiv.org/abs/2307.10471)

    本文主要研究了专利图像中可视化类型和视角的分类问题，扩展了CLEF-IP数据集并采用最先进的深度学习方法进行了分类。这项研究对于促进专利探索和检索具有重要意义。

    

    鉴于每年专利申请数量的迅速增长，促进专利探索和检索的信息和多媒体检索方法至关重要。不同类型的可视化（例如，图形、技术图纸）和视角（例如，侧视、透视）被用来可视化专利创新的细节。对这些图像的分类可以实现更高效的搜索并进行进一步分析。到目前为止，用于图像类型分类的数据集缺少一些重要的专利可视化类型。此外，相关研究没有使用包括transformers在内的最新深度学习方法。在本文中，我们采用最先进的深度学习方法来分类专利图像中的可视化类型和视角。我们对专利中图像类型分类的CLEF-IP数据集进行了扩展，增加到了十个类别，并提供了手动标注的真实标签。此外，我们从一个数据集中推导出一组层级类别。

    Due to the swift growth of patent applications each year, information and multimedia retrieval approaches that facilitate patent exploration and retrieval are of utmost importance. Different types of visualizations (e.g., graphs, technical drawings) and perspectives (e.g., side view, perspective) are used to visualize details of innovations in patents. The classification of these images enables a more efficient search and allows for further analysis. So far, datasets for image type classification miss some important visualization types for patents. Furthermore, related work does not make use of recent deep learning approaches including transformers. In this paper, we adopt state-of-the-art deep learning methods for the classification of visualization types and perspectives in patent images. We extend the CLEF-IP dataset for image type classification in patents to ten classes and provide manual ground truth annotations. In addition, we derive a set of hierarchical classes from a dataset
    
[^47]: 数据科学的价值取向：数据科学的本质、价值和风险

    A data science axiology: the nature, value, and risks of data science. (arXiv:2307.10460v1 [cs.AI])

    [http://arxiv.org/abs/2307.10460](http://arxiv.org/abs/2307.10460)

    这篇论文介绍了数据科学的价值取向，探讨了其特征和作用。数据科学不是一门科学，而是一种研究范式，具有广泛的应用和重大的影响，但也存在着未知的风险。这一领域仍然处于初级阶段，需要进一步的研究。

    

    数据科学不是一门科学，而是一种研究范式，具有无法预测的范围、规模、复杂性和知识发现能力，这是其他方式无法实现的，并且可能超出人类推理的能力。它已经在AI军备竞赛中广泛应用于数以万计的应用程序中，已经实质性地改变了我们的世界，但由于其不可思议的复杂性，可能带来未知的风险。本文介绍了数据科学的价值取向，探讨和评估了其显著而决定性的特征，以便了解和定义数据科学，认识到其潜在的益处、风险和开放性研究挑战。基于AI的数据科学本质上涉及不确定性，这可能比我们对科学确定性的偏好更加现实。数据科学将产生远远超出知识发现的影响。

    Data science is not a science. It is a research paradigm with an unfathomed scope, scale, complexity, and power for knowledge discovery that is not otherwise possible and can be beyond human reasoning. It is changing our world practically and profoundly already widely deployed in tens of thousands of applications in every discipline in an AI Arms Race that, due to its inscrutability, can lead to unfathomed risks. This paper presents an axiology of data science, its purpose, nature, importance, risks, and value for problem solving, by exploring and evaluating its remarkable, definitive features. As data science is in its infancy, this initial, speculative axiology is intended to aid in understanding and defining data science to recognize its potential benefits, risks, and open research challenges. AI based data science is inherently about uncertainty that may be more realistic than our preference for the certainty of science. Data science will have impacts far beyond knowledge discovery
    
[^48]: 一种实现具有硬约束输出的神经网络的计算简单方法

    A New Computationally Simple Approach for Implementing Neural Networks with Output Hard Constraints. (arXiv:2307.10459v1 [cs.LG])

    [http://arxiv.org/abs/2307.10459](http://arxiv.org/abs/2307.10459)

    提出了一种计算简单的方法来实现具有硬约束输出的神经网络。该方法通过映射隐藏参数向量到一个符合约束集的点实现约束，并通过附加的神经网络层来进行映射。该方法还可以处理不仅对输出向量施加约束，还对依赖于输入的联合约束施加约束的情况，并且可以处理不同类型的约束，包括线性和二次约束、等式约束和动态约束。

    

    提出了一种在神经网络输出值上施加硬凸约束的计算简单方法。该方法的关键思想是通过将网络的隐藏参数向量映射到一个点，确保它在由一组约束定义的可行集内。映射是通过具有输出约束的附加神经网络层实现的。将该方法简单地扩展到不仅对输出向量施加约束，还对依赖于输入的联合约束施加约束的情况。在所提出的方法框架中，可以简单地实现对输出的约束投影方法。展示了如何将不同类型的约束引入到所提出的方法中，包括线性和二次约束、等式约束和动态约束，以及边界形式的约束。该方法的一个重要特点是它的计算简单性。

    A new computationally simple method of imposing hard convex constraints on the neural network output values is proposed. The key idea behind the method is to map a vector of hidden parameters of the network to a point that is guaranteed to be inside the feasible set defined by a set of constraints. The mapping is implemented by the additional neural network layer with constraints for output. The proposed method is simply extended to the case when constraints are imposed not only on the output vectors, but also on joint constraints depending on inputs. The projection approach to imposing constraints on outputs can simply be implemented in the framework of the proposed method. It is shown how to incorporate different types of constraints into the proposed method, including linear and quadratic constraints, equality constraints, and dynamic constraints, constraints in the form of boundaries. An important feature of the method is its computational simplicity. Complexities of the forward pa
    
[^49]: 遵守欧盟AI法案

    Complying with the EU AI Act. (arXiv:2307.10458v1 [cs.AI])

    [http://arxiv.org/abs/2307.10458](http://arxiv.org/abs/2307.10458)

    本文识别了欧盟AI法案的不同类别，并开发了一份问卷来提供定量数据，分析发现不同合规类别下组织面临的挑战，同时考察了组织特征对合规的影响，旨在改进遵守欧盟AI法案，并提出了一个相关解决方案的项目。

    

    欧盟AI法案是关于AI系统的欧盟拟议立法。本文识别了几个AI法案的类别，并基于此分类制定了一份问卷作为提供见解的工具，通过创建定量数据。数据分析显示了不同合规类别下组织面临的各种挑战。还考察了组织特征（如规模和行业）对合规的影响，并分享了关于被调查者普遍关注的问题的定性数据，包括AI法案的内容和应用。文章得出结论，认为在遵守欧盟AI法案方面仍有改进空间，并提到了一个相关项目，该项目研究了帮助这些组织的解决方案。

    The EU AI Act is the proposed EU legislation concerning AI systems. This paper identifies several categories of the AI Act. Based on this categorization, a questionnaire is developed that serves as a tool to offer insights by creating quantitative data. Analysis of the data shows various challenges for organizations in different compliance categories. The influence of organization characteristics, such as size and sector, is examined to determine the impact on compliance. The paper will also share qualitative data on which questions were prevalent among respondents, both on the content of the AI Act as the application. The paper concludes by stating that there is still room for improvement in terms of compliance with the AIA and refers to a related project that examines a solution to help these organizations.
    
[^50]: 朝着全球生物多样性评估迈出的一步：BIOSCAN-1M昆虫数据集

    A Step Towards Worldwide Biodiversity Assessment: The BIOSCAN-1M Insect Dataset. (arXiv:2307.10455v1 [cs.CV])

    [http://arxiv.org/abs/2307.10455](http://arxiv.org/abs/2307.10455)

    提出了一个新的大型手工标记昆虫图像数据集BIOSCAN-Insect，用于对昆虫生物多样性进行编目。该数据集还具有引人注目的特征，对广泛的机器学习社区也具有研究价值。

    

    为了对昆虫生物多样性进行编目，我们提出了一个新的大型手工标记昆虫图像数据集，即BIOSCAN-Insect数据集。每个记录都由专家进行分类，并且具有相关的遗传信息，包括原始核苷酸条形码序列和分配的条形码索引号，这些是基于遗传的物种分类的代理。本文介绍了一个精选的百万图像数据集，主要用于训练能够提供基于图像的分类评估的计算机视觉模型，但该数据集还具有引人注目的特征，对广泛的机器学习社区也具有研究价值。由于数据集固有的生物性质，展现出了具有长尾类别不平衡分布的特征。此外，分类标签是一个分层分类方案，在较低级别上呈现出高度细粒度的分类问题。除了激发对生物多样性研究的兴趣外，该数据集还促进了对机器学习的深入研究。

    In an effort to catalog insect biodiversity, we propose a new large dataset of hand-labelled insect images, the BIOSCAN-Insect Dataset. Each record is taxonomically classified by an expert, and also has associated genetic information including raw nucleotide barcode sequences and assigned barcode index numbers, which are genetically-based proxies for species classification. This paper presents a curated million-image dataset, primarily to train computer-vision models capable of providing image-based taxonomic assessment, however, the dataset also presents compelling characteristics, the study of which would be of interest to the broader machine learning community. Driven by the biological nature inherent to the dataset, a characteristic long-tailed class-imbalance distribution is exhibited. Furthermore, taxonomic labelling is a hierarchical classification scheme, presenting a highly fine-grained classification problem at lower levels. Beyond spurring interest in biodiversity research w
    
[^51]: 从成员和偏好查询中学习形式规范

    Learning Formal Specifications from Membership and Preference Queries. (arXiv:2307.10434v1 [cs.FL])

    [http://arxiv.org/abs/2307.10434](http://arxiv.org/abs/2307.10434)

    该论文提出了一种新的框架，通过请求成员标签和成对偏好来扩展主动规范学习，提高学习形式规范的灵活性。在两个不同领域的实验中，结果表明通过学习成员和偏好的组合可以稳定和方便地识别规范。

    

    主动学习是一种研究广泛的学习形式规范的方法，例如自动机。在这项工作中，我们通过提出一种新颖的框架，将主动规范学习扩展到请求组合成员标签和成对偏好（对成员标签的一种流行替代方式）。成对偏好和成员标签的组合允许更灵活的主动规范学习方法，它先前仅依赖成员标签。我们将我们的框架应用于两个不同的领域，证明了我们方法的广泛性。我们的结果表明，从两种模式学习可以通过成员和偏好来稳健和方便地识别规范。

    Active learning is a well-studied approach to learning formal specifications, such as automata. In this work, we extend active specification learning by proposing a novel framework that strategically requests a combination of membership labels and pair-wise preferences, a popular alternative to membership labels. The combination of pair-wise preferences and membership labels allows for a more flexible approach to active specification learning, which previously relied on membership labels only. We instantiate our framework in two different domains, demonstrating the generality of our approach. Our results suggest that learning from both modalities allows us to robustly and conveniently identify specifications via membership and preferences.
    
[^52]: PreDiff: 使用隐式扩散模型进行降水近期预测

    PreDiff: Precipitation Nowcasting with Latent Diffusion Models. (arXiv:2307.10422v1 [cs.LG])

    [http://arxiv.org/abs/2307.10422](http://arxiv.org/abs/2307.10422)

    本论文提出了PreDiff方法，使用条件隐式扩散模型进行降水近期预测。同时，引入显式知识控制机制以满足特定领域的物理约束。

    

    传统上，地球系统预测主要依赖于复杂的物理模型，这些模型计算量大且需要领域专业知识。在过去的十年中，时空地球观测数据的空前增加使得使用深度学习技术的数据驱动预测模型成为可能。这些模型在不同的地球系统预测任务中显示出有希望的效果，但是它们要么难以处理不确定性，要么忽视特定领域的先验知识，导致预测结果模糊或产生物理上不合理的预测。为了解决这些限制，我们提出了一种概率时空预测的两阶段流程：1）我们开发了一种名为PreDiff的条件隐式扩散模型，能够进行概率预测；2）我们融入了一种显式知识控制机制，以使预测符合特定领域的物理约束。这是通过在每个去噪步骤中估计与所施加约束的偏差来实现的。

    Earth system forecasting has traditionally relied on complex physical models that are computationally expensive and require significant domain expertise. In the past decade, the unprecedented increase in spatiotemporal Earth observation data has enabled data-driven forecasting models using deep learning techniques. These models have shown promise for diverse Earth system forecasting tasks but either struggle with handling uncertainty or neglect domain-specific prior knowledge, resulting in averaging possible futures to blurred forecasts or generating physically implausible predictions. To address these limitations, we propose a two-stage pipeline for probabilistic spatiotemporal forecasting: 1) We develop PreDiff, a conditional latent diffusion model capable of probabilistic forecasts. 2) We incorporate an explicit knowledge control mechanism to align forecasts with domain-specific physical constraints. This is achieved by estimating the deviation from imposed constraints at each denoi
    
[^53]: GOOSE算法: 一个强大的优化工具用于现实世界的工程挑战及更多。

    GOOSE Algorithm: A Powerful Optimization Tool for Real-World Engineering Challenges and Beyond. (arXiv:2307.10420v1 [cs.AI])

    [http://arxiv.org/abs/2307.10420](http://arxiv.org/abs/2307.10420)

    GOOSE算法是一种基于鹅的行为的元启发式算法，它在多个基准测试函数上进行了验证和比较，证明其在解决现实世界的工程挑战中的有效性。

    

    该研究提出了GOOSE算法，它是一种基于鹅在休息和觅食时的行为的元启发式算法。鹅靠着一只腿保持平衡，以守护和保护群体中的其他个体。GOOSE算法在19个知名的基准测试函数上进行基准测试，并通过与遗传算法(GA)、粒子群优化(PSO)、蜻蜓算法(DA)和适应性依赖优化器(FDO)的比较研究来验证结果。此外，该算法还在10个现代基准函数上进行了测试，并将结果与蜻蜓算法、鲸鱼优化算法(WOA)和鳐鱼群算法(SSA)等三个最近的算法进行了比较。此外，GOOSE算法还在5个经典基准函数上进行了测试，并将所得结果与适应性依赖优化器(FDO)、FOX优化器、蝶优化算法(BOA)、鲸鱼优化算法、人工蜂群算法和差分进化算法等六种算法进行了评估。

    This study proposes the GOOSE algorithm as a novel metaheuristic algorithm based on the goose's behavior during rest and foraging. The goose stands on one leg and keeps his balance to guard and protect other individuals in the flock. The GOOSE algorithm is benchmarked on 19 well-known benchmark test functions, and the results are verified by a comparative study with genetic algorithm (GA), particle swarm optimization (PSO), dragonfly algorithm (DA), and fitness dependent optimizer (FDO). In addition, the proposed algorithm is tested on 10 modern benchmark functions, and the gained results are compared with three recent algorithms, such as the dragonfly algorithm, whale optimization algorithm (WOA), and salp swarm algorithm (SSA). Moreover, the GOOSE algorithm is tested on 5 classical benchmark functions, and the obtained results are evaluated with six algorithms, such as fitness dependent optimizer (FDO), FOX optimizer, butterfly optimization algorithm (BOA), whale optimization algorit
    
[^54]: 使用视觉问答解释自主驾驶行为

    Explaining Autonomous Driving Actions with Visual Question Answering. (arXiv:2307.10408v1 [cs.CV])

    [http://arxiv.org/abs/2307.10408](http://arxiv.org/abs/2307.10408)

    本文提出了一种使用视觉问答解释自主驾驶行为的框架，通过问答式因果推理来实现驾驶行为的解释。研究使用强化学习收集驾驶视频并手动标注，从而实现自主驾驶决策的可解释性。

    

    由于深度学习和计算机视觉算法的快速进步，自动驾驶车辆的端到端学习能力在过去十年中取得了重大突破。然而，作为人工智能的安全关键应用，道路事故和既定的监管原则要求对自动驾驶车辆的智能行为选择进行解释。为了促进自主驾驶决策的可解释性，我们提出了一个基于视觉问答的框架，通过问答式因果推理来解释驾驶行为。为此，我们首先使用强化学习在模拟环境中收集驾驶视频，并从这个日志数据中均匀提取五个选定行为类别的连续帧。然后，我们使用问题-答案对对提取的帧进行手动标注，作为每种情景中选择的行为的理由。

    The end-to-end learning ability of self-driving vehicles has achieved significant milestones over the last decade owing to rapid advances in deep learning and computer vision algorithms. However, as autonomous driving technology is a safety-critical application of artificial intelligence (AI), road accidents and established regulatory principles necessitate the need for the explainability of intelligent action choices for self-driving vehicles. To facilitate interpretability of decision-making in autonomous driving, we present a Visual Question Answering (VQA) framework, which explains driving actions with question-answering-based causal reasoning. To do so, we first collect driving videos in a simulation environment using reinforcement learning (RL) and extract consecutive frames from this log data uniformly for five selected action categories. Further, we manually annotate the extracted frames using question-answer pairs as justifications for the actions chosen in each scenario. Fina
    
[^55]: 生成视觉问答

    Generative Visual Question Answering. (arXiv:2307.10405v1 [cs.CV])

    [http://arxiv.org/abs/2307.10405](http://arxiv.org/abs/2307.10405)

    本文研究了一种先进的生成视觉问答（VQA）模型，通过利用新数据集GenVQA，该数据集通过稳定扩散生成新的图像，并使用了七种不同的VQA模型。研究结果表明，这些模型在未来数据上表现出较好的适应性和鲁棒性。

    

    在深度学习中，涉及视觉和语言的多模态任务越来越受欢迎，并导致开发出可以超越其训练数据范围的新模型。当前模型缺乏时间上的泛化能力，无法适应未来数据的变化。本文讨论了一种可行的方法，可以创建一个先进的视觉问答（VQA）模型，能在时间上进行泛化，并取得成功的结果。我们提出了一个新的数据集，GenVQA，利用VQAv2和MS-COCO数据集中的图像和标题通过稳定的扩散生成新的图像。然后使用这个增广的数据集来测试七种基线和尖端的VQA模型的组合。性能评估主要关注问题与原始VQAv2数据集相似的问题，答案已经根据新的图像进行了调整。本文的目的是调查几个成功的VQA模型的鲁棒性，以评估它们在未来数据上的表现。

    Multi-modal tasks involving vision and language in deep learning continue to rise in popularity and are leading to the development of newer models that can generalize beyond the extent of their training data. The current models lack temporal generalization which enables models to adapt to changes in future data. This paper discusses a viable approach to creating an advanced Visual Question Answering (VQA) model which can produce successful results on temporal generalization. We propose a new data set, GenVQA, utilizing images and captions from the VQAv2 and MS-COCO dataset to generate new images through stable diffusion. This augmented dataset is then used to test a combination of seven baseline and cutting edge VQA models. Performance evaluation focuses on questions mirroring the original VQAv2 dataset, with the answers having been adjusted to the new images. This paper's purpose is to investigate the robustness of several successful VQA models to assess their performance on future da
    
[^56]: 使用PIP-Net解释和纠正医学图像分类

    Interpreting and Correcting Medical Image Classification with PIP-Net. (arXiv:2307.10404v1 [cs.CV])

    [http://arxiv.org/abs/2307.10404](http://arxiv.org/abs/2307.10404)

    本研究利用PIP-Net开展了可解释的机器学习技术在医学图像分类中的应用，并展示了其在骨折检测和皮肤癌诊断方面的准确性和可解释性。通过无监督的预训练，PIP-Net能够轻松识别数据质量问题，并且我们还发现人们可以通过手动禁用不良原型来纠正PIP-Net的推理过程。

    

    部分原型模型是可解释性的图像分类器，是黑盒人工智能的有希望的替代方案。本文探讨了可解释性机器学习的适用性和潜力，特别是对于真实世界的医学成像数据的自动诊断支持。PIP-Net学习人类可理解的典型图像部分，并评估其在骨折检测和皮肤癌诊断方面的准确性和可解释性。我们发现PIP-Net的决策过程符合医学分类标准，仅提供图像级别的类标签。由于PIP-Net对原型进行了无监督的预训练，因此可以轻松识别X光中的不良文本或标签错误等数据质量问题。此外，我们是第一个显示人们可以通过直接禁用不良原型来手动纠正PIP-Net的推理过程。我们得出结论，部分原型模型对医学应用具有潜力，因为它们具有相互参考性。

    Part-prototype models are explainable-by-design image classifiers, and a promising alternative to black box AI. This paper explores the applicability and potential of interpretable machine learning, in particular PIP-Net, for automated diagnosis support on real-world medical imaging data. PIP-Net learns human-understandable prototypical image parts and we evaluate its accuracy and interpretability for fracture detection and skin cancer diagnosis. We find that PIP-Net's decision making process is in line with medical classification standards, while only provided with image-level class labels. Because of PIP-Net's unsupervised pretraining of prototypes, data quality problems such as undesired text in an X-ray or labelling errors can be easily identified. Additionally, we are the first to show that humans can manually correct the reasoning of PIP-Net by directly disabling undesired prototypes. We conclude that part-prototype models are promising for medical applications due to their inter
    
[^57]: 深入研究消除树型垂直联合学习中的标签泄露问题

    Eliminating Label Leakage in Tree-Based Vertical Federated Learning. (arXiv:2307.10318v1 [cs.LG])

    [http://arxiv.org/abs/2307.10318](http://arxiv.org/abs/2307.10318)

    本研究针对树型垂直联合学习中的标签泄露问题，引入了一种新的标签推断攻击方法ID2Graph，并提出了一种ID-LMID的防御机制，通过关注互信息正则化来防止标签泄露。实验结果表明ID2Graph攻击存在显著的泄露问题。

    

    垂直联合学习（VFL）使得具有共同用户集合的多个参与方能够在不分享私有数据的情况下训练机器学习模型。由于其可解释性和效率，基于树结构的模型在VFL中变得流行起来。然而，树型VFL的脆弱性尚未得到充分的研究。本研究首先引入了一种新颖的标签推断攻击方法ID2Graph，该攻击利用每个节点（即实例空间）分配的记录标识集合来推导私有训练标签。ID2Graph攻击生成训练样本的图结构，从图中提取社区，并使用社区信息对局部数据集进行聚类。为了抵御实例空间中的标签泄露，我们提出了一种有效的防御机制ID-LMID，该机制通过关注互信息正则化来防止标签泄露。在各种数据集上进行的综合实验表明，ID2Graph攻击呈现出显著的泄露问题。

    Vertical federated learning (VFL) enables multiple parties with disjoint features of a common user set to train a machine learning model without sharing their private data. Tree-based models have become prevalent in VFL due to their interpretability and efficiency. However, the vulnerability of tree-based VFL has not been sufficiently investigated. In this study, we first introduce a novel label inference attack, ID2Graph, which utilizes the sets of record-IDs assigned to each node (i.e., instance space) to deduce private training labels. The ID2Graph attack generates a graph structure from training samples, extracts communities from the graph, and clusters the local dataset using community information. To counteract label leakage from the instance space, we propose an effective defense mechanism, ID-LMID, which prevents label leakage by focusing on mutual information regularization. Comprehensive experiments conducted on various datasets reveal that the ID2Graph attack presents signif
    
[^58]: FedBug: 一种自底向上逐渐解冻的联邦学习框架

    FedBug: A Bottom-Up Gradual Unfreezing Framework for Federated Learning. (arXiv:2307.10317v1 [cs.LG])

    [http://arxiv.org/abs/2307.10317](http://arxiv.org/abs/2307.10317)

    FedBug是一个自底向上逐渐解冻的联邦学习框架，通过冻结和逐渐解冻模型层，实现了一种有效缓解客户端漂移现象的方法。

    

    联邦学习（FL）提供了一种协作训练框架，允许多个客户端在不损害数据隐私的情况下为共享模型做出贡献。由于本地数据集的异构性，更新的客户端模型可能会过拟合并与彼此发散，这被称为客户端漂移问题。在本文中，我们提出了FedBug（具有自底向上逐渐解冻的联邦学习），这是一种新颖的FL框架，旨在有效地减轻客户端漂移。FedBug自适应地利用每个全局轮次服务器分发的客户端模型参数作为跨客户端对齐的参考点。具体而言，在客户端上，FedBug从冻结整个模型开始，然后逐渐解冻层，从输入层到输出层。这种自底向上的方法允许模型训练解冻的新层将数据投影到一个潜在空间中，在这个空间中，分离超平面在所有客户端上保持一致。我们在理论上分析了FedBug

    Federated Learning (FL) offers a collaborative training framework, allowing multiple clients to contribute to a shared model without compromising data privacy. Due to the heterogeneous nature of local datasets, updated client models may overfit and diverge from one another, commonly known as the problem of client drift. In this paper, we propose FedBug (Federated Learning with Bottom-Up Gradual Unfreezing), a novel FL framework designed to effectively mitigate client drift. FedBug adaptively leverages the client model parameters, distributed by the server at each global round, as the reference points for cross-client alignment. Specifically, on the client side, FedBug begins by freezing the entire model, then gradually unfreezes the layers, from the input layer to the output layer. This bottom-up approach allows models to train the newly thawed layers to project data into a latent space, wherein the separating hyperplanes remain consistent across all clients. We theoretically analyze F
    
[^59]: 绝对主义AI

    Absolutist AI. (arXiv:2307.10315v1 [cs.AI])

    [http://arxiv.org/abs/2307.10315](http://arxiv.org/abs/2307.10315)

    本文提出了绝对主义AI的概念，认为通过训练AI系统时使用绝对约束条件可以解决许多AI安全问题，这样做可以避免最糟糕的结果、防止灾难、增加系统的可矫正性并帮助系统更安全地探索环境。

    

    本文认为，训练AI系统时采用绝对约束条件 - 即禁止某些行为，无论它们可能产生多少价值 - 在原则上可以在许多AI安全问题上取得重大进展。首先，它为避免最糟糕的误对齐结果提供了护栏。其次，它可以防止AI为了非常有价值的结果而引发灾难，例如用更多数量和更高福利水平的生物替代人类。第三，它使系统更加可矫正，允许创建者进行纠正性干预，比如改变它们的目标函数或关闭它们。第四，它通过禁止特别危险的行为，帮助系统更安全地探索环境。我提供了对绝对约束条件进行决策论形式化的改进模型，并利用该模型证明了有关培训和行为的一些结果。

    This paper argues that training AI systems with absolute constraints -- which forbid certain acts irrespective of the amount of value they might produce -may make considerable progress on many AI safety problems in principle. First, it provides a guardrail for avoiding the very worst outcomes of misalignment. Second, it could prevent AIs from causing catastrophes for the sake of very valuable consequences, such as replacing humans with a much larger number of beings living at a higher welfare level. Third, it makes systems more corrigible, allowing creators to make corrective interventions in them, such as altering their objective functions or shutting them down. And fourth, it helps systems explore their environment more safely by prohibiting them from exploring especially dangerous acts. I offer a decision-theoretic formalization of an absolute constraints, improving on existing models in the literature, and use this model to prove some results about the training and behavior of ab
    
[^60]: 语言迷宫：对人工智能话语中术语使用的建设性批评

    The Language Labyrinth: Constructive Critique on the Terminology Used in the AI Discourse. (arXiv:2307.10292v1 [cs.CY])

    [http://arxiv.org/abs/2307.10292](http://arxiv.org/abs/2307.10292)

    这篇文章对人工智能领域使用的术语进行了建设性批评，指出AI的讨论缺乏对隐喻的批判性距离，导致对责任和潜在用途的反思被扭曲。文章通过提出更合适的术语来促进更富有成果的辩论。

    

    在跨学科的人工智能（AI）领域中，术语明确性的问题尤为重要。本文认为，AI的讨论仍然缺乏对诸如“训练”、“学习”或“决策”等隐喻的批判性距离。因此，关于责任或潜在用途的反思被严重扭曲。然而，如果相关决策者相信AI可以发展“理解”或正确“解释”问题，那么它在决定社会福利或审判案件等敏感任务时的常规使用将会出现。本章通过分析AI辩论的核心概念来支持其观点，并通过提出更合适的术语来促进更富有成果的辩论。它是一项在批判性计算机科学和语言哲学之间交叉的概念性工作。

    In the interdisciplinary field of artificial intelligence (AI) the problem of clear terminology is especially momentous. This paper claims, that AI debates are still characterised by a lack of critical distance to metaphors like 'training', 'learning' or 'deciding'. As consequence, reflections regarding responsibility or potential use-cases are greatly distorted. Yet, if relevant decision-makers are convinced that AI can develop an 'understanding' or properly 'interpret' issues, its regular use for sensitive tasks like deciding about social benefits or judging court cases looms. The chapter argues its claim by analysing central notions of the AI debate and tries to contribute by proposing more fitting terminology and hereby enabling more fruitful debates. It is a conceptual work at the intersection of critical computer science and philosophy of language.
    
[^61]: 野外蚜虫群体的实时语义分割研究

    On the Real-Time Semantic Segmentation of Aphid Clusters in the Wild. (arXiv:2307.10267v1 [cs.CV])

    [http://arxiv.org/abs/2307.10267](http://arxiv.org/abs/2307.10267)

    本文研究了野外蚜虫群体的实时语义分割，通过收集和标注大量蚜虫图像数据集，并使用实时语义分割模型来定位和喷洒农田中的虫害，从而降低农药使用和环境影响。

    

    蚜虫危害能严重损害小麦和高粱田，并传播植物病毒，导致农业产量大幅下降。为解决这个问题，农民常常依赖化学农药，但这种方法在广阔的田地上使用效率低下。因此，大量农药被浪费在没有害虫的地方，同时在严重虫害区域使用不足。本文关注于迫切需要开发一个智能自主系统，能够定位并喷洒农田中的虫害，从而减少农药使用和环境影响。我们在野外收集和标注了大量的蚜虫图像数据集，并提出使用实时语义分割模型来分割蚜虫群体。利用多尺度数据集可以学习不同尺度下的蚜虫群体。我们比较了四种最先进的实时语义分割模型在分割速度和准确度上的表现。

    Aphid infestations can cause extensive damage to wheat and sorghum fields and spread plant viruses, resulting in significant yield losses in agriculture. To address this issue, farmers often rely on chemical pesticides, which are inefficiently applied over large areas of fields. As a result, a considerable amount of pesticide is wasted on areas without pests, while inadequate amounts are applied to areas with severe infestations. The paper focuses on the urgent need for an intelligent autonomous system that can locate and spray infestations within complex crop canopies, reducing pesticide use and environmental impact. We have collected and labeled a large aphid image dataset in the field, and propose the use of real-time semantic segmentation models to segment clusters of aphids. A multiscale dataset is generated to allow for learning the clusters at different scales. We compare the segmentation speeds and accuracy of four state-of-the-art real-time semantic segmentation models on the 
    
[^62]: AI赋能研究：科学如何受益于人工智能的10种方式

    AI empowering research: 10 ways how science can benefit from AI. (arXiv:2307.10265v1 [cs.GL])

    [http://arxiv.org/abs/2307.10265](http://arxiv.org/abs/2307.10265)

    本文探讨了人工智能对科学研究的转变性影响，提出了十种方式：强大的引用工具、对研究问题的更好理解、改进的研究问题生成、优化的研究设计、虚拟数据生成、数据转化、高级数据分析和AI辅助报告。虽然人工智能带来了很多好处，但也面临偏见、隐私问题和人工智能与人类的合作需求等挑战。人工智能可以增强科学中的人类创造力，但不能取代它。

    

    本文探讨了人工智能对科学研究的转变性影响。它强调了人工智能革命化了科学家的工作的十种方式，包括强大的引用工具、对研究问题的更好理解、改进的研究问题生成、优化的研究设计、虚拟数据生成、数据转化、高级数据分析和AI辅助报告。虽然人工智能带来了很多好处，但也必须考虑到挑战，如偏见、隐私问题和人工智能与人类的合作需求。本文强调了人工智能可以增强科学中的人类创造力，但不能取代它。

    This article explores the transformative impact of artificial intelligence (AI) on scientific research. It highlights ten ways in which AI is revolutionizing the work of scientists, including powerful referencing tools, improved understanding of research problems, enhanced research question generation, optimized research design, stub data generation, data transformation, advanced data analysis, and AI-assisted reporting. While AI offers numerous benefits, challenges such as bias, privacy concerns, and the need for human-AI collaboration must be considered. The article emphasizes that AI can augment human creativity in science but not replace it.
    
[^63]: 超参数调整指南：适用于scikit-learn、PyTorch、river和spotPython的指南

    Hyperparameter Tuning Cookbook: A guide for scikit-learn, PyTorch, river, and spotPython. (arXiv:2307.10262v1 [cs.LG])

    [http://arxiv.org/abs/2307.10262](http://arxiv.org/abs/2307.10262)

    本文提供了使用spotPython进行scikit-learn、PyTorch和river的超参数调整的全面指南。重点介绍了spotPython的优化过程和超参数调整，并提供了几个实际案例研究。该指南为对Python超参数调整感兴趣的人们提供了实用的起点。

    

    本文提供了使用spotPython对scikit-learn、PyTorch和river进行超参数调整的全面指南。第一部分介绍了spotPython的基于代理模型的优化过程，第二部分着重介绍了超参数调整。文中提供了几个案例研究，包括对scikit-learn模型（如支持向量分类，随机森林，梯度提升（XGB）和K最近邻（KNN））以及river中的Hoeffding自适应树回归器进行超参数调整。还讨论了将spotPython集成到PyTorch和PyTorch Lightning训练工作流中的方法。通过实践和逐步解释的方式，本手册为对使用Python进行超参数调整感兴趣的任何人提供了实用的起点。重点包括Tensorboard、PyTorch Lightning、spotPython和river之间的相互作用。该出版物正在开发中，更新内容可在对应的网页上获取。

    This document provides a comprehensive guide to hyperparameter tuning using spotPython for scikit-learn, PyTorch, and river. The first part introduces spotPython's surrogate model-based optimization process, while the second part focuses on hyperparameter tuning. Several case studies are presented, including hyperparameter tuning for sklearn models such as Support Vector Classification, Random Forests, Gradient Boosting (XGB), and K-nearest neighbors (KNN), as well as a Hoeffding Adaptive Tree Regressor from river. The integration of spotPython into the PyTorch and PyTorch Lightning training workflow is also discussed. With a hands-on approach and step-by-step explanations, this cookbook serves as a practical starting point for anyone interested in hyperparameter tuning with Python. Highlights include the interplay between Tensorboard, PyTorch Lightning, spotPython, and river. This publication is under development, with updates available on the corresponding webpage.
    
[^64]: 使用GPT-4语言模型的归纳推理：犯罪调查、医学实践和科学研究的案例研究

    Abductive Reasoning with the GPT-4 Language Model: Case studies from criminal investigation, medical practice, scientific research. (arXiv:2307.10250v1 [cs.AI])

    [http://arxiv.org/abs/2307.10250](http://arxiv.org/abs/2307.10250)

    本研究评估了GPT-4大型语言模型在医学诊断、犯罪学和宇宙学等复杂领域中的归纳推理能力。研究结果显示了LLM在复杂问题解决方面的潜力，并强调了进一步研究以最大化其实际应用的必要性。

    

    本研究评估了GPT-4大型语言模型在医学诊断、犯罪学和宇宙学等复杂领域中的归纳推理能力。通过交互式访谈形式，AI助手展示了生成和选择假设的可靠性。它基于患者数据推断出合理的医学诊断，并在犯罪学和宇宙学中提供了潜在的原因和解释。研究结果突显了LLMs在复杂问题解决中的潜力，并强调了进一步研究以最大化它们的实际应用的必要性。

    This study evaluates the GPT-4 Large Language Model's abductive reasoning in complex fields like medical diagnostics, criminology, and cosmology. Using an interactive interview format, the AI assistant demonstrated reliability in generating and selecting hypotheses. It inferred plausible medical diagnoses based on patient data and provided potential causes and explanations in criminology and cosmology. The results highlight the potential of LLMs in complex problem-solving and the need for further research to maximize their practical applications.
    
[^65]: 深度神经网络和脑对齐：脑编码和解码（综述）

    Deep Neural Networks and Brain Alignment: Brain Encoding and Decoding (Survey). (arXiv:2307.10246v1 [q-bio.NC])

    [http://arxiv.org/abs/2307.10246](http://arxiv.org/abs/2307.10246)

    本文综述了深度神经网络和脑对齐的研究，重点在于脑编码和解码模型的应用。这些模型对于理解大脑的信息处理机制以及设计脑机接口具有重要意义。

    

    大脑如何表示不同的信息模式？我们能否设计出一个可以自动理解用户思考内容的系统？这些问题可以通过研究功能磁共振成像（fMRI）等大脑记录来回答。作为第一步，神经科学界为被动阅读/听觉/观看概念词汇、叙述、图片和电影相关的认知神经科学数据集作出了贡献。过去二十年中，还提出了使用这些数据集的编码和解码模型。这些模型作为基础研究中的额外工具，在认知科学和神经科学领域有着多种实际应用。编码模型旨在自动地生成fMRI大脑表征，给定一个刺激。它们在评估和诊断神经系统疾病以及设计大脑损伤治疗方法方面有着多种实际应用。解码模型解决了根据fMRI重构刺激的逆问题。它们对于理解大脑如何处理信息以及设计脑机接口的发展都有着重要意义。

    How does the brain represent different modes of information? Can we design a system that automatically understands what the user is thinking? Such questions can be answered by studying brain recordings like functional magnetic resonance imaging (fMRI). As a first step, the neuroscience community has contributed several large cognitive neuroscience datasets related to passive reading/listening/viewing of concept words, narratives, pictures and movies. Encoding and decoding models using these datasets have also been proposed in the past two decades. These models serve as additional tools for basic research in cognitive science and neuroscience. Encoding models aim at generating fMRI brain representations given a stimulus automatically. They have several practical applications in evaluating and diagnosing neurological conditions and thus also help design therapies for brain damage. Decoding models solve the inverse problem of reconstructing the stimuli given the fMRI. They are useful for 
    
[^66]: CoNAN：无约束人脸特征融合的条件神经聚合网络

    CoNAN: Conditional Neural Aggregation Network For Unconstrained Face Feature Fusion. (arXiv:2307.10237v1 [cs.CV])

    [http://arxiv.org/abs/2307.10237](http://arxiv.org/abs/2307.10237)

    CoNAN是一种用于无约束人脸特征融合的条件神经聚合网络，针对在长距离和高高度环境下捕获的极低分辨率人脸，利用特征分布调节方法来进行模板聚合。

    

    在不受限制和无控制的环境下，如长距离、低分辨率、不同视角、光照、姿态和大气条件下，从图像集中进行人脸识别是具有挑战性的。人脸特征聚合在这类识别系统中起到关键作用，它涉及将模板中的N个特征表示聚合成一个全局表示。现有的传统人脸特征聚合方法要么利用元数据，要么利用高维中间特征表示来估计特征质量进行聚合。然而，对于在远距离和高高度环境下捕获的极低分辨率人脸，生成高质量的元数据或风格信息是不可行的。为了克服这些限制，我们提出了一种称为CoNAN的特征分布调节方法来进行模板聚合。具体而言，我们的方法旨在学习一个在输入特征分布信息条件下的上下文向量。

    Face recognition from image sets acquired under unregulated and uncontrolled settings, such as at large distances, low resolutions, varying viewpoints, illumination, pose, and atmospheric conditions, is challenging. Face feature aggregation, which involves aggregating a set of N feature representations present in a template into a single global representation, plays a pivotal role in such recognition systems. Existing works in traditional face feature aggregation either utilize metadata or high-dimensional intermediate feature representations to estimate feature quality for aggregation. However, generating high-quality metadata or style information is not feasible for extremely low-resolution faces captured in long-range and high altitude settings. To overcome these limitations, we propose a feature distribution conditioning approach called CoNAN for template aggregation. Specifically, our method aims to learn a context vector conditioned over the distribution information of the incomi
    
[^67]: 三思而后行：大型语言模型不确定性测量的探索性研究

    Look Before You Leap: An Exploratory Study of Uncertainty Measurement for Large Language Models. (arXiv:2307.10236v1 [cs.SE])

    [http://arxiv.org/abs/2307.10236](http://arxiv.org/abs/2307.10236)

    本研究从不确定性的角度对大型语言模型进行了探索性研究，通过实验发现不确定性估计方法在探索和抵制大型语言模型的不良行为方面具有潜力。

    

    大型语言模型（LLMs）的最近性能突破为众多工业应用和领域提供了新的机遇。然而，LLMs的错误生成，如虚假预测、错误信息和幻觉，也引发了对LLMs可靠性的严重关注，尤其在对安全、可靠性有敏感的场景中，可能阻碍其在实际中的应用。尽管不确定性估计已经显示出其在解释一般机器学习（ML）模型的预测风险方面的潜力，但关于它是否以及在多大程度上有助于探索LLMs的能力和抵制其不良行为方面知之甚少。为了弥合这一差距，本文从不确定性的角度开展了关于LLMs风险评估的探索性研究。具体来说，我们使用12种不确定性估计方法和4个LLMs在4个重要的自然语言处理（NLP）任务上进行实验，以调查不确定性在探索LLMs能力和对抗其不良行为方面的程度。

    The recent performance leap of Large Language Models (LLMs) opens up new opportunities across numerous industrial applications and domains. However, erroneous generations, such as false predictions, misinformation, and hallucination made by LLMs, have also raised severe concerns for the trustworthiness of LLMs', especially in safety-, security- and reliability-sensitive scenarios, potentially hindering real-world adoptions. While uncertainty estimation has shown its potential for interpreting the prediction risks made by general machine learning (ML) models, little is known about whether and to what extent it can help explore an LLM's capabilities and counteract its undesired behavior. To bridge the gap, in this paper, we initiate an exploratory study on the risk assessment of LLMs from the lens of uncertainty. In particular, we experiment with twelve uncertainty estimation methods and four LLMs on four prominent natural language processing (NLP) tasks to investigate to what extent unc
    
[^68]: SentimentGPT：利用GPT进行高级情感分析及其与当前机器学习方法的差异

    SentimentGPT: Exploiting GPT for Advanced Sentiment Analysis and its Departure from Current Machine Learning. (arXiv:2307.10234v1 [cs.CL])

    [http://arxiv.org/abs/2307.10234](http://arxiv.org/abs/2307.10234)

    本研究通过利用GPT进行高级情感分析，并考察其与当前机器学习方法的差异，发现GPT方法相较于其他模型在预测性能上具有显著优势，并有效解决了情感分析任务中的一些挑战，如理解上下文和检测讽刺。

    

    本研究对情感分析中各种生成预训练转换器（GPT）方法进行了全面的考察，特别是在SemEval 2017数据集的任务4中。采用了三种主要策略：1）使用GPT-3.5 Turbo进行提示工程，2）对GPT模型进行微调，3）采用创新的嵌入分类方法。研究结果揭示了这些策略和个别GPT模型之间的详细比较见解，展示了它们独特的优势和潜在的局限性。此外，本研究将这些基于GPT的方法与其他同时代、高性能的模型在相同数据集上进行比较。结果表明，GPT方法在预测性能方面具有显著的优势，相较于最先进技术，F1分数增加了22%以上。此外，本论文还探讨了情感分析任务中的常见挑战，如理解上下文和检测讽刺。研究强调了GPT方法的重要价值和潜力。

    This study presents a thorough examination of various Generative Pretrained Transformer (GPT) methodologies in sentiment analysis, specifically in the context of Task 4 on the SemEval 2017 dataset. Three primary strategies are employed: 1) prompt engineering using the advanced GPT-3.5 Turbo, 2) fine-tuning GPT models, and 3) an inventive approach to embedding classification. The research yields detailed comparative insights among these strategies and individual GPT models, revealing their unique strengths and potential limitations. Additionally, the study compares these GPT-based methodologies with other contemporary, high-performing models previously used with the same dataset. The results illustrate the significant superiority of the GPT approaches in terms of predictive performance, more than 22% in F1-score compared to the state-of-the-art. Further, the paper addresses common challenges in sentiment analysis tasks, such as understanding context and detecting sarcasm. It underscores
    
[^69]: 癌症临床实践指南的自动化知识建模

    Automated Knowledge Modeling for Cancer Clinical Practice Guidelines. (arXiv:2307.10231v1 [cs.AI])

    [http://arxiv.org/abs/2307.10231](http://arxiv.org/abs/2307.10231)

    本研究提出了一种自动化方法，从国家综合癌症网络（NCCN）肿瘤学临床指南中提取知识，并生成包含该知识的结构化模型。通过使用癌症分期信息、统一医学语言系统（UMLS）和国家癌症研究所的词库（NCIt）概念以及节点分类的增强策略，该模型可以实现程序化遍历和查询。

    

    由于积极研究产生的新证据，癌症疾病的临床实践指南（CPGs）发展迅速。目前，CPGs主要以不适合管理这种发展知识的文档格式发布。需要一种适用于程序交互的指南文档的知识模型。本研究提出了一种从国家综合癌症网络（NCCN）肿瘤学CPGs中提取知识并生成包含提取的知识的结构化模型的自动化方法。使用两个版本的NCCN非小细胞肺癌（NSCLC）CPG对所提出的方法进行了测试，以展示其忠实提取和建模知识的效果。还提出了三种增强模型的策略，包括使用癌症分期信息、统一医学语言系统（UMLS）的元词库和国家癌症研究所的词库（NCIt）概念以及节点分类，以实现程序化遍历和查询。

    Clinical Practice Guidelines (CPGs) for cancer diseases evolve rapidly due to new evidence generated by active research. Currently, CPGs are primarily published in a document format that is ill-suited for managing this developing knowledge. A knowledge model of the guidelines document suitable for programmatic interaction is required. This work proposes an automated method for extraction of knowledge from National Comprehensive Cancer Network (NCCN) CPGs in Oncology and generating a structured model containing the retrieved knowledge. The proposed method was tested using two versions of NCCN Non-Small Cell Lung Cancer (NSCLC) CPG to demonstrate the effectiveness in faithful extraction and modeling of knowledge. Three enrichment strategies using Cancer staging information, Unified Medical Language System (UMLS) Metathesaurus & National Cancer Institute thesaurus (NCIt) concepts, and Node classification are also presented to enhance the model towards enabling programmatic traversal and q
    
[^70]: 因果定律与多值流变量

    Causal Laws and Multi-Valued Fluents. (arXiv:2307.10227v1 [cs.AI])

    [http://arxiv.org/abs/2307.10227](http://arxiv.org/abs/2307.10227)

    本文介绍了一种扩展了因果逻辑和语言C的语言C+，使其可以表示任意非空集合中的值，并且可以描述动作的属性，同时还提供了将C+嵌入到具有多值常量的因果理论的方法，并展示了如何将多值常量替换为布尔常量。

    

    本文延续了在非单调形式化中表示行为特性的工作线，强调了“真实”和“因果”的区别，类似于McCain和Turner引入的因果逻辑系统和Giunchiglia和Lifschitz提出的行动语言C。在语言C+中，唯一可以直接表示的流变量是真值流变量，这通常是不方便的。我们证明了因果逻辑和语言C都可以扩展以允许来自任意非空集合的值。我们称为C+的语言扩展还可以根据属性来描述动作，这在强调扩充容忍性的角度上很重要。我们描述了将C+嵌入到具有多值常量的因果理论中，将C+与Pednault的行动语言ADL相关联，并展示了如何将多值常量替换为布尔常量。

    This paper continues the line of work on representing properties of actions in nonmonotonic formalisms that stresses the distinction between being "true" and being "caused", as in the system of causal logic introduced by McCain and Turner and in the action language C proposed by Giunchiglia and Lifschitz. The only fluents directly representable in language C+ are truth-valued fluents, which is often inconvenient. We show that both causal logic and language C can be extended to allow values from arbitrary nonempty sets. Our extension of language C, called C+, also makes it possible to describe actions in terms of their attributes, which is important from the perspective of elaboration tolerance. We describe an embedding of C+ in causal theories with multi-valued constants, relate C+ to Pednault's action language ADL, and show how multi-valued constants can be eliminated in favor of Boolean constants.
    
[^71]: 关于带变量的循环公式

    On Loop Formulas with Variables. (arXiv:2307.10226v1 [cs.AI])

    [http://arxiv.org/abs/2307.10226](http://arxiv.org/abs/2307.10226)

    这项研究提出了一种新的定义稳定模型的方法，它不依赖于grounding，并可以适用于任意一阶句子的语法。通过扩展循环公式的概念，并将其推广到含有或的程序和任意一阶句子，研究表明这种方法可以在处理非单调推理时产生更简洁的结果，并简化查询回答的过程。

    

    最近，Ferraris，Lee和Lifschitz提出了一种新的稳定模型定义，不涉及grounding，适用于任意一阶句子的语法。我们展示了它与陈，林，王和张提出的带有变量的循环公式的关系，并将他们的循环公式推广到了含有或的程序和任意一阶句子。我们还扩展了逻辑程序的语法，允许显式量词，并将其语义定义为Ferraris等人的稳定模型新语言的子类。这样的程序继承了一般语言的能力，即即使在没有唯一名称和域闭包假设的情况下，在稳定模型语义下处理非单调推理，同时由于受限的语法而产生更简洁的循环公式。我们还展示了一定的句法条件，使得扩展程序的查询回答可以简化为一阶逻辑的蕴涵检查。

    Recently Ferraris, Lee and Lifschitz proposed a new definition of stable models that does not refer to grounding, which applies to the syntax of arbitrary first-order sentences. We show its relation to the idea of loop formulas with variables by Chen, Lin, Wang and Zhang, and generalize their loop formulas to disjunctive programs and to arbitrary first-order sentences. We also extend the syntax of logic programs to allow explicit quantifiers, and define its semantics as a subclass of the new language of stable models by Ferraris et al. Such programs inherit from the general language the ability to handle nonmonotonic reasoning under the stable model semantics even in the absence of the unique name and the domain closure assumptions, while yielding more succinct loop formulas than the general language due to the restricted syntax. We also show certain syntactic conditions under which query answering for an extended program can be reduced to entailment checking in first-order logic, prov
    
[^72]: 具有内涵函数的一阶稳定模型语义

    First-Order Stable Model Semantics with Intensional Functions. (arXiv:2307.10225v1 [cs.AI])

    [http://arxiv.org/abs/2307.10225](http://arxiv.org/abs/2307.10225)

    本文扩展了一阶稳定模型语义，允许使用内涵函数，比较了其他相关方法，还利用这个扩展定义了答案集编程模型论（ASPMT），实现了类似SMT的有效一阶推理。

    

    在经典逻辑中，非布尔函数，例如物体的位置，可以自然地用函数来描述。然而，在答案集程序中，函数的值是预定义的，并且语义的非单调性与最小化谓词的范围有关，而与函数无关。我们扩展了Ferraris、Lee和Lifschitz的一阶稳定模型语义，允许内涵函数——即由逻辑程序指定的函数，就像谓词一样。我们展示了许多已知的稳定模型语义属性在这个形式系统中如何自然扩展，并将其与其他相关方法进行比较，以融入内涵函数。此外，我们利用这个扩展为定义答案集编程模型论（ASPMT）提供基础，类似于定义SMT的方式，允许在ASP环境中进行类似SMT的有效一阶推理。使用SM...

    In classical logic, nonBoolean fluents, such as the location of an object, can be naturally described by functions. However, this is not the case in answer set programs, where the values of functions are pre-defined, and nonmonotonicity of the semantics is related to minimizing the extents of predicates but has nothing to do with functions. We extend the first-order stable model semantics by Ferraris, Lee, and Lifschitz to allow intensional functions -- functions that are specified by a logic program just like predicates are specified. We show that many known properties of the stable model semantics are naturally extended to this formalism and compare it with other related approaches to incorporating intensional functions. Furthermore, we use this extension as a basis for defining Answer Set Programming Modulo Theories (ASPMT), analogous to the way that Satisfiability Modulo Theories (SMT) is defined, allowing for SMT-like effective first-order reasoning in the context of ASP. Using SM
    
[^73]: RL-ViGen: 一种用于视觉泛化的强化学习基准

    RL-ViGen: A Reinforcement Learning Benchmark for Visual Generalization. (arXiv:2307.10224v1 [cs.AI])

    [http://arxiv.org/abs/2307.10224](http://arxiv.org/abs/2307.10224)

    RL-ViGen是一种用于视觉泛化的强化学习基准，包含多样的任务和广泛的泛化类型，旨在推动对代理人视觉泛化能力的全面评估。

    

    视觉强化学习（Visual RL）与高维观察相结合，一直面临着长期存在的泛化挑战。尽管有重点研究用于解决视觉泛化问题的算法，但我们认为现有的基准存在问题，因为它们局限于孤立的任务和泛化类别，从而削弱了对代理人视觉泛化能力的全面评估。为了弥合这一差距，我们引入了RL-ViGen：一种新型的用于视觉泛化的强化学习基准，其中包含多样的任务和广泛的泛化类型，从而促进得出更可靠的结论。此外，RL-ViGen将最新的泛化视觉强化学习算法融入到一个统一的框架中，实验结果表明，没有单一的现有算法在所有任务上普遍占优势。我们的愿景是RL-ViGen将在这个领域起到催化剂的作用。

    Visual Reinforcement Learning (Visual RL), coupled with high-dimensional observations, has consistently confronted the long-standing challenge of generalization. Despite the focus on algorithms aimed at resolving visual generalization problems, we argue that the devil is in the existing benchmarks as they are restricted to isolated tasks and generalization categories, undermining a comprehensive evaluation of agents' visual generalization capabilities. To bridge this gap, we introduce RL-ViGen: a novel Reinforcement Learning Benchmark for Visual Generalization, which contains diverse tasks and a wide spectrum of generalization types, thereby facilitating the derivation of more reliable conclusions. Furthermore, RL-ViGen incorporates the latest generalization visual RL algorithms into a unified framework, under which the experiment results indicate that no single existing algorithm has prevailed universally across tasks. Our aspiration is that RL-ViGen will serve as a catalyst in this a
    
[^74]: 受奖赏约束：共同构建评估酷儿人工智能伤害的过程

    Bound by the Bounty: Collaboratively Shaping Evaluation Processes for Queer AI Harms. (arXiv:2307.10223v1 [cs.CY])

    [http://arxiv.org/abs/2307.10223](http://arxiv.org/abs/2307.10223)

    这项研究探索了如何在评估人工智能偏见和伤害时整合边缘化社区的知识，并提出了以酷儿社区为视角重新设计偏见奖金的方法。

    

    偏见评估基准、数据集和模型文档已成为评估人工智能系统偏见和伤害的核心过程。然而，这些审计过程因未整合边缘化社区的知识并考虑审计员与社区之间的权力动态而受到批评。因此，已经提出了一种参与受影响社区识别和评估人工智能系统伤害的偏见评估方式（例如偏见奖金）。尽管如此，关于边缘化社区对此类审计过程的期望一直被忽视。在本文中，我们向酷儿社区征求他们对审计过程的立场和期望。为此，我们组织了一个参与式研讨会，从酷儿的角度对偏见奖金进行批判性的重新设计。我们发现，当有空间时，参与者的反馈范围远远超出了偏见奖金所能提供的范围，参与者 que

    Bias evaluation benchmarks and dataset and model documentation have emerged as central processes for assessing the biases and harms of artificial intelligence (AI) systems. However, these auditing processes have been criticized for their failure to integrate the knowledge of marginalized communities and consider the power dynamics between auditors and the communities. Consequently, modes of bias evaluation have been proposed that engage impacted communities in identifying and assessing the harms of AI systems (e.g., bias bounties). Even so, asking what marginalized communities want from such auditing processes has been neglected. In this paper, we ask queer communities for their positions on, and desires from, auditing processes. To this end, we organized a participatory workshop to critique and redesign bias bounties from queer perspectives. We found that when given space, the scope of feedback from workshop participants goes far beyond what bias bounties afford, with participants que
    
[^75]: 「目前是大杂烩」：探究人工智能/机器学习从业者在共同创造负责任人工智能价值观过程中面临的挑战

    `It is currently hodgepodge'': Examining AI/ML Practitioners' Challenges during Co-production of Responsible AI Values. (arXiv:2307.10221v1 [cs.AI])

    [http://arxiv.org/abs/2307.10221](http://arxiv.org/abs/2307.10221)

    该论文探究了人工智能/机器学习从业者在共同创造负责任人工智能价值观过程中面临的挑战，发现了上下结构和执行冲突价值观的问题，并提出了解决策略建议。

    

    最近，人工智能/机器学习研究界表示，在人工智能/机器学习生命周期的一部分建立负责任人工智能（RAI）的价值观和实践的迫切需要。一些组织和社区正在响应这一呼吁，分享RAI的指导原则。然而，多学科机器学习从业者在意识、讨论和执行此类实践方面存在差距。本研究通过解析从业者在对齐RAI价值观过程中遇到的共同创造挑战，为此讨论做出了贡献。我们对10个组织中的23名个体进行了访谈，这些个体负责发布基于人工智能/机器学习的产品，同时遵守RAI规范，发现自上而下和自下而上的组织结构为不同职责造成了负担，使其无法坚守RAI价值观，这一挑战在执行冲突的价值观时进一步加剧。我们分享了从业者用作解决挑战策略的多个价值杠杆。我们在论文的最后提出了包容和可行的建议。

    Recently, the AI/ML research community has indicated an urgent need to establish Responsible AI (RAI) values and practices as part of the AI/ML lifecycle. Several organizations and communities are responding to this call by sharing RAI guidelines. However, there are gaps in awareness, deliberation, and execution of such practices for multi-disciplinary ML practitioners. This work contributes to the discussion by unpacking co-production challenges faced by practitioners as they align their RAI values. We interviewed 23 individuals, across 10 organizations, tasked to ship AI/ML based products while upholding RAI norms and found that both top-down and bottom-up institutional structures create burden for different roles preventing them from upholding RAI values, a challenge that is further exacerbated when executing conflicted values. We share multiple value levers used as strategies by the practitioners to resolve their challenges. We end our paper with recommendations for inclusive and e
    
[^76]: 在增强的不变关系知识上探索超关系时间知识图的链接预测

    Exploring Link Prediction over Hyper-Relational Temporal Knowledge Graphs Enhanced with Time-Invariant Relational Knowledge. (arXiv:2307.10219v1 [cs.AI])

    [http://arxiv.org/abs/2307.10219](http://arxiv.org/abs/2307.10219)

    这项研究填补了时间KG和超关系KG推理之间的差距，并开发了两个新的基准超关系TKG数据集。

    

    超关系知识图(HKGs)是传统知识图(KGs)的延伸，为每个KG事实提供额外的键值对(即限定词)，以更好地限制事实的有效性。近年来，研究在HKGs上进行图推理越来越受关注。与此同时，由于世界知识的不断演变，大量平行工作集中在对时间KGs(TKGs)进行推理，其中每个TKG事实可以被视为带有时间戳(或时间段)的KG事实，指定其时间有效性。现有的HKG推理方法不考虑时间信息，因为在之前的基准数据集中没有显式地指定。此外，所有以前的TKG推理方法只重视时间推理，并没有办法从限定词中学习。因此，我们的目标是填补TKG推理和HKG推理之间的差距。我们开发了两个新的基准超关系TKG(HTKG)数据集，即Wiki-hy和...

    Stemming from traditional knowledge graphs (KGs), hyper-relational KGs (HKGs) provide additional key-value pairs (i.e., qualifiers) for each KG fact that help to better restrict the fact validity. In recent years, there has been an increasing interest in studying graph reasoning over HKGs. In the meantime, due to the ever-evolving nature of world knowledge, extensive parallel works have been focusing on reasoning over temporal KGs (TKGs), where each TKG fact can be viewed as a KG fact coupled with a timestamp (or time period) specifying its time validity. The existing HKG reasoning approaches do not consider temporal information because it is not explicitly specified in previous benchmark datasets. Besides, all the previous TKG reasoning methods only lay emphasis on temporal reasoning and have no way to learn from qualifiers. To this end, we aim to fill the gap between TKG reasoning and HKG reasoning. We develop two new benchmark hyper-relational TKG (HTKG) datasets, i.e., Wiki-hy and 
    
[^77]: 在对话中减少偏见：一个带提示的仇恨言论分类器和去偏见器

    Mitigating Bias in Conversations: A Hate Speech Classifier and Debiaser with Prompts. (arXiv:2307.10213v1 [cs.CL])

    [http://arxiv.org/abs/2307.10213](http://arxiv.org/abs/2307.10213)

    该论文提出了一个双步骤的方法来减少在线对话中的偏见和仇恨言论。该方法通过先使用分类器检测仇恨言论，然后利用提示生成更少偏见或无偏见的替代语言，从而降低了负面影响，为减少在线讨论中的偏见，促进更具包容性和公平性的沟通环境做出了贡献。

    

    歧视性语言和偏见通常在对话中存在，这通常对基于种族、性别和宗教的目标群体产生负面影响。为了解决这个问题，我们提出了一个双步骤的方法：首先，使用分类器检测仇恨言论，然后利用一个去偏见组件通过提示生成更少偏见或无偏见的替代语言。我们在一个基准数据集上评估了我们的方法，并观察到仇恨言论导致的负面性减少。该方法对于减少在线讨论中的偏见，促进更具包容性和公平性的沟通环境的努力有所贡献。

    Discriminatory language and biases are often present in hate speech during conversations, which usually lead to negative impacts on targeted groups such as those based on race, gender, and religion. To tackle this issue, we propose an approach that involves a two-step process: first, detecting hate speech using a classifier, and then utilizing a debiasing component that generates less biased or unbiased alternatives through prompts. We evaluated our approach on a benchmark dataset and observed reduction in negativity due to hate speech comments. The proposed method contributes to the ongoing efforts to reduce biases in online discourse and promote a more inclusive and fair environment for communication.
    
[^78]: 从模型偏见中分离社会不平等：离婚法庭诉讼中的性别不平等

    Disentangling Societal Inequality from Model Biases: Gender Inequality in Divorce Court Proceedings. (arXiv:2307.10200v1 [cs.CY])

    [http://arxiv.org/abs/2307.10200](http://arxiv.org/abs/2307.10200)

    本文通过研究离婚法庭诉讼，探索了性别不平等问题，并发现了自然语言处理方法中存在的偏见问题。需要对现有资源进行修正来量化社会不平等。

    

    离婚是法院法律解除婚姻关系的过程。由于这通常是婚姻联合的不愉快结果，每一方都可能有理由要求退出决定，这通常在法庭诉讼中有详细记录。通过一份包含17,306份法庭诉讼的大量语料库，本文通过离婚法庭诉讼的角度研究了性别不平等问题。虽然新兴的数据来源（例如公共法庭记录）在辅助社会科学研究方面具有潜力，但先进的自然语言处理（NLP）方法中存在的偏见可能会干扰或影响此类研究。因此，我们需要对现有NLP资源中的潜在差距和限制进行彻底分析。在方法论上，本文证明了现有NLP资源需要进行几个非平凡的修改，以量化社会不平等。在实质上，我们发现尽管大量的法庭案件可能暗示着变化

    Divorce is the legal dissolution of a marriage by a court. Since this is usually an unpleasant outcome of a marital union, each party may have reasons to call the decision to quit which is generally documented in detail in the court proceedings. Via a substantial corpus of 17,306 court proceedings, this paper investigates gender inequality through the lens of divorce court proceedings. While emerging data sources (e.g., public court records) on sensitive societal issues hold promise in aiding social science research, biases present in cutting-edge natural language processing (NLP) methods may interfere with or affect such studies. We thus require a thorough analysis of potential gaps and limitations present in extant NLP resources. In this paper, on the methodological side, we demonstrate that existing NLP resources required several non-trivial modifications to quantify societal inequalities. On the substantive side, we find that while a large number of court cases perhaps suggest chan
    
[^79]: 中国在人工智能研究方面赶上美国了吗？一项关于后发工业化国家的模仿同构模型的探索。

    Has China caught up to the US in AI research? An exploration of mimetic isomorphism as a model for late industrializers. (arXiv:2307.10198v1 [cs.AI])

    [http://arxiv.org/abs/2307.10198](http://arxiv.org/abs/2307.10198)

    中国在人工智能研究方面超过美国的数量，但在质量上仍稍逊，其中的原因包括全球趋势、侨民和回国人员的贡献以及相对宽松的数据保护政策。

    

    人工智能（AI）是21世纪技术的基石，中国在这方面取得了显著的发展。本文研究了中国的AI发展过程，表明其特点是快速学习和差异化发展，超过了早期亚洲工业化国家依靠外国直接投资推动的出口导向型增长。我们的数据显示，中国目前在AI相关研究论文的数量方面领先于美国。然而，当我们根据具体指标深入研究这些论文的质量时，美国仍略占优势。尽管如此，中国的AI发展的速度和规模仍值得关注。我们将中国加速的AI进展归因于几个因素，包括全球趋势支持算法和研究论文的开放获取、中国广泛的侨民和回国人员的贡献，以及相对宽松的数据保护政策。 为了支持我们的研究，我们开发了一种衡量中国模仿美国的新方法。

    Artificial Intelligence (AI), a cornerstone of 21st-century technology, has seen remarkable growth in China. In this paper, we examine China's AI development process, demonstrating that it is characterized by rapid learning and differentiation, surpassing the export-oriented growth propelled by Foreign Direct Investment seen in earlier Asian industrializers.  Our data indicates that China currently leads the USA in the volume of AI-related research papers. However, when we delve into the quality of these papers based on specific metrics, the USA retains a slight edge. Nevertheless, the pace and scale of China's AI development remain noteworthy.  We attribute China's accelerated AI progress to several factors, including global trends favoring open access to algorithms and research papers, contributions from China's broad diaspora and returnees, and relatively lax data protection policies.  In the vein of our research, we have developed a novel measure for gauging China's imitation of US
    
[^80]: ChatGPT用于数字取证调查: 好的，坏的和未知的 (arXiv:2307.10195v1 [cs.CR])

    ChatGPT for Digital Forensic Investigation: The Good, The Bad, and The Unknown. (arXiv:2307.10195v1 [cs.CR])

    [http://arxiv.org/abs/2307.10195](http://arxiv.org/abs/2307.10195)

    本文评估了ChatGPT对数字取证领域的影响和潜力，特别关注其最新预训练的大型语言模型GPT-4。通过一系列实验，发现了ChatGPT在数字取证用例中的优势和风险，并得出了一些总体结论。

    

    在科学界和社会中，ChatGPT (GPT-3.5，GPT-4) 在各种领域的破坏性应用已经成为一个广泛讨论的话题。大型语言模型（LLMs），如BERT、Bard、生成预训练变压器（GPTs）、LLaMA等，具有根据大量文本训练数据接收用户指令或提示，并生成答案和解决方案的能力。本文评估了ChatGPT对数字取证领域的影响和潜力，特别关注其最新预训练LLM——GPT-4。通过一系列实验，评估了其在多个数字取证用例中的能力，包括证据理解、证据搜索、代码生成、异常检测、事件响应和教育。文章阐述了它在这些领域中的优势和风险，并得出了一些总体结论。总的来说，本文的结论是，虽然有一些潜在的低风险应用可能性，

    The disruptive application of ChatGPT (GPT-3.5, GPT-4) to a variety of domains has become a topic of much discussion in the scientific community and society at large. Large Language Models (LLMs), e.g., BERT, Bard, Generative Pre-trained Transformers (GPTs), LLaMA, etc., have the ability to take instructions, or prompts, from users and generate answers and solutions based on very large volumes of text-based training data. This paper assesses the impact and potential impact of ChatGPT on the field of digital forensics, specifically looking at its latest pre-trained LLM, GPT-4. A series of experiments are conducted to assess its capability across several digital forensic use cases including artefact understanding, evidence searching, code generation, anomaly detection, incident response, and education. Across these topics, its strengths and risks are outlined and a number of general conclusions are drawn. Overall this paper concludes that while there are some potential low-risk applicati
    
[^81]: 一种双重隐秘后门攻击：从空间和频率角度来看

    A Dual Stealthy Backdoor: From Both Spatial and Frequency Perspectives. (arXiv:2307.10184v1 [cs.CR])

    [http://arxiv.org/abs/2307.10184](http://arxiv.org/abs/2307.10184)

    该论文提出了一种名为DUBA的双重隐秘后门攻击方法，该方法同时考虑了触发器在空间和频率域中的隐匿性，以实现良好的攻击性能和强大的隐匿性。

    

    后门攻击对深度神经网络(DNNs)构成严重的安全威胁。后门模型在带有精心设计的触发器的输入上会任意（有针对性地）出现错误预测，而在干净的输入上表现正常。许多研究探索了后门触发器的隐匿性以提高攻击的隐秘性。然而，其中大部分只考虑了空间域中的隐匿性，没有明确考虑在频率域中生成隐匿触发器，使生成的毒害图像容易被最近的防御方法检测到。为了解决这个问题，本文提出了一种名为DUBA的DUal隐秘后门攻击方法，该方法同时考虑了触发器在空间和频率域中的隐匿性，以实现良好的攻击性能，同时确保强大的隐匿性。具体地，我们首先使用离散小波变换将触发器图像的高频信息嵌入干净图像中。

    Backdoor attacks pose serious security threats to deep neural networks (DNNs). Backdoored models make arbitrarily (targeted) incorrect predictions on inputs embedded with well-designed triggers while behaving normally on clean inputs. Many works have explored the invisibility of backdoor triggers to improve attack stealthiness. However, most of them only consider the invisibility in the spatial domain without explicitly accounting for the generation of invisible triggers in the frequency domain, making the generated poisoned images be easily detected by recent defense methods. To address this issue, in this paper, we propose a DUal stealthy BAckdoor attack method named DUBA, which simultaneously considers the invisibility of triggers in both the spatial and frequency domains, to achieve desirable attack performance, while ensuring strong stealthiness. Specifically, we first use Discrete Wavelet Transform to embed the high-frequency information of the trigger image into the clean image 
    
[^82]: 通过真实厚切片CT模拟改进超分辨网络

    Enhancing Super-Resolution Networks through Realistic Thick-Slice CT Simulation. (arXiv:2307.10182v1 [eess.IV])

    [http://arxiv.org/abs/2307.10182](http://arxiv.org/abs/2307.10182)

    本研究通过开发一种创新的模拟算法，成功生成与实际图像非常相似的厚切片CT图像，并证明该方法在峰值信噪比和均方根误差方面明显优于其他模拟方法。

    

    该研究旨在开发和评估一种创新的模拟算法，用于生成与AAPM-Mayo's 2016低剂量CT大挑战数据集中的实际图像密切相似的厚切片CT图像。提出的方法使用峰值信噪比（PSNR）和均方根误差（RMSE）指标进行评估，假设我们的模拟将产生与真实图像更一致的图像。我们提出的方法在PSNR和RMSE方面显示出显著的改进，最高PSNR值为D45和B30重建核分别为49.7369±2.5223和48.5801±7.3271。提出的方法还以0.0068±0.0020和0.0108±0.0099的RMSE值注册最低的误差，表明其分布更接近于真实的厚切片图像。

    This study aims to develop and evaluate an innovative simulation algorithm for generating thick-slice CT images that closely resemble actual images in the AAPM-Mayo's 2016 Low Dose CT Grand Challenge dataset. The proposed method was evaluated using Peak Signal-to-Noise Ratio (PSNR) and Root Mean Square Error (RMSE) metrics, with the hypothesis that our simulation would produce images more congruent with their real counterparts. Our proposed method demonstrated substantial enhancements in terms of both PSNR and RMSE over other simulation methods. The highest PSNR values were obtained with the proposed method, yielding 49.7369 $\pm$ 2.5223 and 48.5801 $\pm$ 7.3271 for D45 and B30 reconstruction kernels, respectively. The proposed method also registered the lowest RMSE with values of 0.0068 $\pm$ 0.0020 and 0.0108 $\pm$ 0.0099 for D45 and B30, respectively, indicating a distribution more closely aligned with the authentic thick-slice image. Further validation of the proposed simulation al
    
[^83]: DialogStudio：面向会话 AI 的最丰富和最多样化的统一数据集集合

    DialogStudio: Towards Richest and Most Diverse Unified Dataset Collection for Conversational AI. (arXiv:2307.10172v1 [cs.CL])

    [http://arxiv.org/abs/2307.10172](http://arxiv.org/abs/2307.10172)

    DialogStudio是迄今为止最大且最多样化的对话数据集合，包含从开放领域对话到任务导向对话、自然语言理解、会话推荐、对话摘要和知识驱动对话的数据。它为对话研究和模型训练提供了丰富而多样化的资源。

    

    尽管会话 AI 取得了进展，但语言模型在处理多样化的对话任务时面临挑战，现有的对话数据集往往缺乏多样性和全面性。为解决这些问题，我们介绍了 DialogStudio：最大、最多样化的对话数据集集合，以一致的格式统一，同时保留其原始信息。我们的集合包括来自开放领域对话、任务导向对话、自然语言理解、会话推荐、对话摘要和知识驱动对话的数据，为对话研究和模型训练提供了非常丰富和多样化的资源。为了进一步增强 DialogStudio 的实用性，我们为每个数据集确定了许可证，并为选定对话设计了领域感知提示，以便促进指导感知微调。此外，我们使用数据集集合开发了会话 AI 模型，并在零摘要生成和分布式文字基准对话任务上进行了实验。

    Despite advancements in conversational AI, language models encounter challenges to handle diverse conversational tasks, and existing dialogue dataset collections often lack diversity and comprehensiveness. To tackle these issues, we introduce DialogStudio: the largest and most diverse collection of dialogue datasets, unified under a consistent format while preserving their original information. Our collection encompasses data from open-domain dialogues, task-oriented dialogues, natural language understanding, conversational recommendation, dialogue summarization, and knowledge-grounded dialogues, making it an incredibly rich and diverse resource for dialogue research and model training. To further enhance the utility of DialogStudio, we identify the licenses for each dataset and design domain-aware prompts for selected dialogues to facilitate instruction-aware fine-tuning. Furthermore, we develop conversational AI models using the dataset collection, and our experiments in both zero-sh
    
[^84]: 隐式身份表示条件化记忆补偿网络用于生成自然头部视频

    Implicit Identity Representation Conditioned Memory Compensation Network for Talking Head video Generation. (arXiv:2307.09906v1 [cs.CV])

    [http://arxiv.org/abs/2307.09906](http://arxiv.org/abs/2307.09906)

    提出了一种隐式身份表示条件化记忆补偿网络，用于高保真度的自然头部视频生成。

    

    头部视频生成旨在通过从目标驱动视频中提取的动态姿势和表情来给静态图像中的人脸添加动画效果，同时保持源图像中的个人身份。然而，驱动视频中戏剧性和复杂的运动会导致生成模糊不清，因为静态源图像无法提供足够的外观信息来处理被遮挡区域或微妙的表情变化，这会产生严重的伪影并严重降低生成质量。为了解决这个问题，我们提出了学习全局人脸表示空间的方法，并设计了一种新颖的隐式身份表示条件化记忆补偿网络，称为MCNet，用于高保真度的头部视频生成。

    Talking head video generation aims to animate a human face in a still image with dynamic poses and expressions using motion information derived from a target-driving video, while maintaining the person's identity in the source image. However, dramatic and complex motions in the driving video cause ambiguous generation, because the still source image cannot provide sufficient appearance information for occluded regions or delicate expression variations, which produces severe artifacts and significantly degrades the generation quality. To tackle this problem, we propose to learn a global facial representation space, and design a novel implicit identity representation conditioned memory compensation network, coined as MCNet, for high-fidelity talking head generation.~Specifically, we devise a network module to learn a unified spatial facial meta-memory bank from all training samples, which can provide rich facial structure and appearance priors to compensate warped source facial features 
    
[^85]: 基于循环一致性的无监督深度图匹配

    Unsupervised Deep Graph Matching Based on Cycle Consistency. (arXiv:2307.08930v1 [cs.CV])

    [http://arxiv.org/abs/2307.08930](http://arxiv.org/abs/2307.08930)

    本文提出了一种基于循环一致性的无监督深度图匹配方法，不需要真实对应的关键点对，通过在同一对象类别的图像之间强制匹配一致性来进行自我监督学习，该方法具有很高的灵活性，并且在无监督图匹配方面达到了最新的最先进水平。

    

    我们在稀疏领域的无监督深度图匹配中做出了贡献，应用于图像中的关键点匹配。与标准的“监督”方法相反，我们的方法不需要关键点对之间的真实对应。相反，它通过强制同一对象类别的图像之间的匹配一致性来进行自我监督。由于匹配和一致性损失是离散的，它们的导数不能直接用于学习。我们通过在组合求解器的黑盒微分的最新结果基础上构建我们的方法来解决这个问题。这使得我们的方法非常灵活，因为它与任意网络架构和组合求解器兼容。我们的实验评估表明，我们的技术在无监督图匹配方面达到了新的最先进水平。

    We contribute to the sparsely populated area of unsupervised deep graph matching with application to keypoint matching in images. Contrary to the standard \emph{supervised} approach, our method does not require ground truth correspondences between keypoint pairs. Instead, it is self-supervised by enforcing consistency of matchings between images of the same object category. As the matching and the consistency loss are discrete, their derivatives cannot be straightforwardly used for learning. We address this issue in a principled way by building our method upon the recent results on black-box differentiation of combinatorial solvers. This makes our method exceptionally flexible, as it is compatible with arbitrary network architectures and combinatorial solvers. Our experimental evaluation suggests that our technique sets a new state-of-the-art for unsupervised graph matching.
    
[^86]: 具有概率策略执行不确定性的高效鲁棒增强学习

    Efficient Action Robust Reinforcement Learning with Probabilistic Policy Execution Uncertainty. (arXiv:2307.07666v1 [cs.LG])

    [http://arxiv.org/abs/2307.07666](http://arxiv.org/abs/2307.07666)

    本文研究了具有概率策略执行不确定性的行动鲁棒增强学习问题，并提出了ARRLC算法，该算法在遗憾和样本复杂度上达到了极小极大最优，实验证明其优于非鲁棒算法并且收敛更快。

    

    鲁棒增强学习旨在在不确定性面前找到优化最坏情况下性能的策略。本文关注具有概率策略执行不确定性的行动鲁棒增强学习，其中代理机器不总是按照策略指定的动作进行，而是以概率$1-\rho$执行策略指定的动作，以概率$\rho$执行替代的对抗动作。我们证明了具有概率策略执行不确定性的行动鲁棒马尔可夫决策过程存在最优策略，并提供了解决其的行动鲁棒贝尔曼最优方程。此外，我们开发了具有证书的行动鲁棒增强学习(ARRLC)算法，该算法实现了极小极大遗憾和样本复杂度最优。此外，我们进行了数值实验来验证我们的方法的鲁棒性，结果表明ARRLC优于非鲁棒增强学习算法，并且比鲁棒TD算法收敛更快。

    Robust reinforcement learning (RL) aims to find a policy that optimizes the worst-case performance in the face of uncertainties. In this paper, we focus on action robust RL with the probabilistic policy execution uncertainty, in which, instead of always carrying out the action specified by the policy, the agent will take the action specified by the policy with probability $1-\rho$ and an alternative adversarial action with probability $\rho$. We establish the existence of an optimal policy on the action robust MDPs with probabilistic policy execution uncertainty and provide the action robust Bellman optimality equation for its solution. Furthermore, we develop Action Robust Reinforcement Learning with Certificates (ARRLC) algorithm that achieves minimax optimal regret and sample complexity. Furthermore, we conduct numerical experiments to validate our approach's robustness, demonstrating that ARRLC outperforms non-robust RL algorithms and converges faster than the robust TD algorithm i
    
[^87]: 深度神经网络中的定量中心极限定理

    Quantitative CLTs in Deep Neural Networks. (arXiv:2307.06092v1 [cs.LG])

    [http://arxiv.org/abs/2307.06092](http://arxiv.org/abs/2307.06092)

    本文研究了具有随机高斯权重和偏置的全连接神经网络的分布，得到了在大但有限的 $n$ 和任意固定网络深度下成立的正态逼近的定量界限，证明了随机全连接网络与相应的无限宽高斯过程之间的距离按照 $n^{-\gamma}$ 缩放，界限在网络宽度的依赖性方面优于以前的研究。

    

    我们研究了具有随机高斯权重和偏置的全连接神经网络的分布，其中隐藏层宽度与大常数 $n$ 成比例。在非线性的温和假设下，我们得到了在大但有限的 $n$ 和任意固定网络深度下成立的正态逼近的定量界限。我们的定理表明，无论是对于有限维分布还是整个过程，随机全连接网络（及其导数）与相应的无限宽高斯过程之间的距离都会按照 $n^{-\gamma}$ 缩放，其中 $\gamma>0$，指数取决于用于度量差异的度量方式。我们的界限在网络宽度的依赖性方面比文献中以前提供的任何界限都要强。

    We study the distribution of a fully connected neural network with random Gaussian weights and biases in which the hidden layer widths are proportional to a large constant $n$. Under mild assumptions on the non-linearity, we obtain quantitative bounds on normal approximations valid at large but finite $n$ and any fixed network depth. Our theorems show, both for the finite-dimensional distributions and the entire process, that the distance between a random fully connected network (and its derivatives) to the corresponding infinite width Gaussian process scales like $n^{-\gamma}$ for $\gamma>0,$ with the exponent depending on the metric used to measure discrepancy. Our bounds are stronger in terms of their dependence on network width than any previously available in the literature.
    
[^88]: 阅读放射学成像的方式，就像放射科医生一样

    Reading Radiology Imaging Like The Radiologist. (arXiv:2307.05921v1 [cs.CV])

    [http://arxiv.org/abs/2307.05921](http://arxiv.org/abs/2307.05921)

    提出一种以疾病为导向的方法，解决自动放射学报告生成中的细微差异关注、数据偏差和长文本生成的挑战。

    

    自动放射学报告生成旨在生成包含放射学成像的丰富、精细描述的放射学报告。与自然图像领域的图像描述相比，医学图像非常相似，仅在疾病发生的细微差异上有所不同。鉴于这些细微差异在放射学报告中的重要性，鼓励模型更加关注疾病发生的微妙区域至关重要。其次，视觉和文本数据偏差的问题很严重。不仅正常病例占数据集的大部分，还描绘有病变区域的句子只占段落的一小部分。最后，生成医学图像报告涉及到长文本的生成挑战，这需要更多医学知识的专业性和经验训练。因此，生成此类报告的难度增加。为了解决这些挑战，我们提出了一种以疾病为导向的方法。

    Automated radiology report generation aims to generate radiology reports that contain rich, fine-grained descriptions of radiology imaging. Compared with image captioning in the natural image domain, medical images are very similar to each other, with only minor differences in the occurrence of diseases. Given the importance of these minor differences in the radiology report, it is crucial to encourage the model to focus more on the subtle regions of disease occurrence. Secondly, the problem of visual and textual data biases is serious. Not only do normal cases make up the majority of the dataset, but sentences describing areas with pathological changes also constitute only a small part of the paragraph. Lastly, generating medical image reports involves the challenge of long text generation, which requires more expertise and empirical training in medical knowledge. As a result, the difficulty of generating such reports is increased. To address these challenges, we propose a disease-ori
    
[^89]: 量化回音室效应：一种基于嵌入距离的方法

    Quantifying the Echo Chamber Effect: An Embedding Distance-based Approach. (arXiv:2307.04668v2 [cs.SI] UPDATED)

    [http://arxiv.org/abs/2307.04668](http://arxiv.org/abs/2307.04668)

    本文提出了一种基于嵌入距离的方法来量化回音室效应。通过计算用户之间的距离，结合Echo Chamber Score(ECS)指标来评估用户社区的凝聚力和分离度，而不需要用户意识形态的标签和交互图的结构假设。

    

    社交媒体平台的兴起促进了回音室的形成，回音室是在线空间，用户主要遇到强化他们现有信念的观点，同时排除不同意见。这种现象显著阻碍了信息在社区之间的传播，加剧了社会极化。因此，开发量化回音室的方法至关重要。在本文中，我们提出了回音室得分（ECS），一种新颖的评估用户社区凝聚力和分离度的指标，通过测量嵌入空间中用户之间的距离来实现。与现有方法不同，ECS能够在不具备用户意识形态标签的情况下发挥作用，并且不对交互图的结构做出任何假设。为了便于测量用户之间的距离，我们提出了EchoGAE，一种基于自监督图自编码器的用户嵌入模型，利用用户的帖子和交互图将用户嵌入到一种方式中

    The rise of social media platforms has facilitated the formation of echo chambers, which are online spaces where users predominantly encounter viewpoints that reinforce their existing beliefs while excluding dissenting perspectives. This phenomenon significantly hinders information dissemination across communities and fuels societal polarization. Therefore, it is crucial to develop methods for quantifying echo chambers. In this paper, we present the Echo Chamber Score (ECS), a novel metric that assesses the cohesion and separation of user communities by measuring distances between users in the embedding space. In contrast to existing approaches, ECS is able to function without labels for user ideologies and makes no assumptions about the structure of the interaction graph. To facilitate measuring distances between users, we propose EchoGAE, a self-supervised graph autoencoder-based user embedding model that leverages users' posts and the interaction graph to embed them in a manner that
    
[^90]: 第十九届理性和知识理论方面的会议论文集

    Proceedings Ninetheenth conference on Theoretical Aspects of Rationality and Knowledge. (arXiv:2307.04005v1 [cs.LO])

    [http://arxiv.org/abs/2307.04005](http://arxiv.org/abs/2307.04005)

    第十九届理性和知识理论方面的会议旨在汇集来自多个领域的研究人员，进一步研究涉及理性和知识的跨学科问题。

    

    TARK会议(理性和知识理论方面的会议)旨在汇集来自计算机科学、人工智能、博弈论、决策论、哲学、逻辑、语言学和认知科学等各个领域的研究人员，旨在进一步理解涉及理性和知识的跨学科问题。自1986年以来，该会议以两年为期间，在世界各地举行，其创始人是约瑟夫·哈尔普恩 (康奈尔大学)。感兴趣的主题包括但不限于知识、信念、意识和不确定性的语义模型，有限理性和资源受限推理，常识知识推理，认知逻辑，认知博弈论，知识与行动，在知识和其他心理状态的推理应用，信念修正，计算社会选择，算法博弈论以及多智能体系统的基础。Informa

    The TARK conference (Theoretical Aspects of Rationality and Knowledge) is a conference that aims to bring together researchers from a wide variety of fields, including computer science, artificial intelligence, game theory, decision theory, philosophy, logic, linguistics, and cognitive science. Its goal is to further our understanding of interdisciplinary issues involving reasoning about rationality and knowledge.  Previous conferences have been held biennially around the world since 1986, on the initiative of Joe Halpern (Cornell University). Topics of interest include, but are not limited to, semantic models for knowledge, belief, awareness and uncertainty, bounded rationality and resource-bounded reasoning, commonsense epistemic reasoning, epistemic logic, epistemic game theory, knowledge and action, applications of reasoning about knowledge and other mental states, belief revision, computational social choice, algorithmic game theory, and foundations of multi-agent systems. Informa
    
[^91]: PatternGPT: 一种基于模式的大型语言模型文本生成框架

    PatternGPT :A Pattern-Driven Framework for Large Language Model Text Generation. (arXiv:2307.00470v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.00470](http://arxiv.org/abs/2307.00470)

    PatternGPT是一种基于模式驱动的大型语言模型文本生成框架，通过利用大型语言模型的提取能力生成多样化的模式，并使用联邦学习的思想实现模式共享，最终通过搜索高质量模式指导生成模型。该框架具有生成多样化模式、保护数据隐私、结合外部知识等优势。

    

    大型语言模型(LLMs)展示了出色的文本生成能力，能够为许多下游任务生成流畅的响应。然而，将大型语言模型应用于现实世界的关键任务仍然具有挑战性，因为它们容易出现幻觉，并且无法直接使用外部知识。为解决上述问题，本文提出了PatternGPT，一种基于模式驱动的大型语言模型文本生成框架。首先，该框架利用大型语言模型的提取能力生成丰富多样的模式，然后借鉴联邦学习的思想，使用多个代理实现共享以获取更多样的模式。最后，它使用判断标准和优化算法搜索高质量的模式，并使用搜索到的模式指导模型进行生成。该框架具有生成多样化模式、保护数据隐私、结合外部知识等优势。

    Large language models(LLMS) have shown excellent text generation capabilities,capable of generating fluent responses for many downstream tasks. However,applying large language models to real-world critical tasks remains challenging due to their susceptibility to hallucinations and inability to directly use external knowledge. To address the above challenges,this paper proposes PatternGPT, a pattern-driven text generation framework for large language models. First,the framework utilizes the extraction capabilities of large language models to generate rich and diverse patterns and later draws on the idea of federated learning. Using multiple agents to achieve sharing to obtain more diverse patterns. Finally, it searches for high-quality patterns using judgment criteria and optimization algorithms and uses the searched patterns to guide the model for generation. This framework has the advantages of generating diversified patterns, protecting data privacy,combining external knowledge, and 
    
[^92]: ChatGPT用于机器人技术：设计原则和模型能力

    ChatGPT for Robotics: Design Principles and Model Abilities. (arXiv:2306.17582v1 [cs.AI])

    [http://arxiv.org/abs/2306.17582](http://arxiv.org/abs/2306.17582)

    本文介绍了使用ChatGPT进行机器人应用的实验研究，通过设计原则和函数库的结合，ChatGPT能够适应不同的机器人任务，并展示了在各种机器人任务中的有效性和多样性。

    

    本文介绍了使用OpenAI的ChatGPT进行机器人应用的实验研究。我们概述了一种策略，将提示工程的设计原则与高级函数库的创建相结合，使ChatGPT能够适应不同的机器人任务、模拟器和形态。我们重点评估了不同的提示工程技术和对话策略对执行各种类型机器人任务的效果。我们探讨了ChatGPT使用自由形式对话、解析XML标记和合成代码的能力，以及使用任务特定提示函数和通过对话进行闭环推理的能力。我们的研究涵盖了机器人领域的一系列任务，从基本的逻辑、几何和数学推理到复杂的领域，如空中导航、操纵和具身代理。我们证明了ChatGPT在解决这些任务方面可以取得有效结果，同时使我们能够进行探索。

    This paper presents an experimental study regarding the use of OpenAI's ChatGPT for robotics applications. We outline a strategy that combines design principles for prompt engineering and the creation of a high-level function library which allows ChatGPT to adapt to different robotics tasks, simulators, and form factors. We focus our evaluations on the effectiveness of different prompt engineering techniques and dialog strategies towards the execution of various types of robotics tasks. We explore ChatGPT's ability to use free-form dialog, parse XML tags, and to synthesize code, in addition to the use of task-specific prompting functions and closed-loop reasoning through dialogues. Our study encompasses a range of tasks within the robotics domain, from basic logical, geometrical, and mathematical reasoning all the way to complex domains such as aerial navigation, manipulation, and embodied agents. We show that ChatGPT can be effective at solving several of such tasks, while allowing us
    
[^93]: 基于正则化SE(3)群卷积的体积医学图像分析

    Regular SE(3) Group Convolutions for Volumetric Medical Image Analysis. (arXiv:2306.13960v1 [cs.CV])

    [http://arxiv.org/abs/2306.13960](http://arxiv.org/abs/2306.13960)

    本文提出了基于正则化SE(3)群卷积的体积医学图像分析方法，通过分解连续SO(3)核和空间核以实现旋转平移等变性，并在医学分类任务中获得了显著性能提升。

    

    研究表明，正则组卷积神经网络(G-CNN)可以提高模型性能并提高对不同几何对称性的等变性。本文解决了SE(3)问题，即旋转平移等变性在体积数据上的问题。体积图像数据在许多医疗设置中普遍存在。受可分离组卷积的最新工作的启发，我们设计了一个SE(3)群卷积核，将其分解为连续的SO(3)（旋转）核和空间核。我们通过采样均匀的SO(3)网格来近似连续设定下的对称性。我们的连续SO(3)核是通过类似均匀网格的RBF插值参数化的。我们展示了我们的方法在体积医学图像分析中的优势。我们的SE(3)等变模型在具有挑战性的医学分类任务上始终优于CNN和常规离散G-CNN，并显示出显着改进的泛化能力。我们的方法在噪声数据下的性能提高了达到16.5%。

    Regular group convolutional neural networks (G-CNNs) have been shown to increase model performance and improve equivariance to different geometrical symmetries. This work addresses the problem of SE(3), i.e., roto-translation equivariance, on volumetric data. Volumetric image data is prevalent in many medical settings. Motivated by the recent work on separable group convolutions, we devise a SE(3) group convolution kernel separated into a continuous SO(3) (rotation) kernel and a spatial kernel. We approximate equivariance to the continuous setting by sampling uniform SO(3) grids. Our continuous SO(3) kernel is parameterized via RBF interpolation on similarly uniform grids. We demonstrate the advantages of our approach in volumetric medical image analysis. Our SE(3) equivariant models consistently outperform CNNs and regular discrete G-CNNs on challenging medical classification tasks and show significantly improved generalization capabilities. Our approach achieves up to a 16.5% gain in
    
[^94]: 使用大型语言模型在道德教育和发展研究中的潜在优势

    Potential Benefits of Employing Large Language Models in Research in Moral Education and Development. (arXiv:2306.13805v1 [cs.CY])

    [http://arxiv.org/abs/2306.13805](http://arxiv.org/abs/2306.13805)

    本文探讨如何使用大型语言模型（LLM）在道德教育和发展研究领域做出贡献。最近的LLM具有新兴的上下文学习和思维链功能，可以通过推理和修订来解决困境。

    

    最近，计算机科学家通过使用大规模语料库和人工强化训练预测模型，开发了大型语言模型（LLM）。 LLM已成为实现人工智能在各个领域精确性的一种有前途的方式。有趣的是，最近的LLM具有模拟复杂人类认知的新兴功能特性，特别是上下文学习和思维链，这些特性在以前的预测模型中不可用。本文将探讨LLM如何可能为道德教育和发展研究做出贡献。为了实现这个目标，我将回顾最近发表的会议论文和ArXiv预印本，概述LLM中实现的新颖功能特性。我还打算使用ChatGPT进行简短实验，以研究LLM处理道德困境和外部反馈时的行为。结果表明，LLM可能能够基于推理和修订来解决困境。

    Recently, computer scientists have developed large language models (LLMs) by training prediction models with large-scale language corpora and human reinforcements. The LLMs have become one promising way to implement artificial intelligence with accuracy in various fields. Interestingly, recent LLMs possess emergent functional features that emulate sophisticated human cognition, especially in-context learning and the chain of thought, which were unavailable in previous prediction models. In this paper, I will examine how LLMs might contribute to moral education and development research. To achieve this goal, I will review the most recently published conference papers and ArXiv preprints to overview the novel functional features implemented in LLMs. I also intend to conduct brief experiments with ChatGPT to investigate how LLMs behave while addressing ethical dilemmas and external feedback. The results suggest that LLMs might be capable of solving dilemmas based on reasoning and revising
    
[^95]: 基于标签生成的增量分类学习方法

    Class-Incremental Learning based on Label Generation. (arXiv:2306.12619v1 [cs.CL])

    [http://arxiv.org/abs/2306.12619](http://arxiv.org/abs/2306.12619)

    本文提出了一种基于标签生成方法的增量分类学习（CIL）方法（VAG），大幅减少了灾难性遗忘（CF），并更好地保留了预训练模型的可推广表示。

    

    尽管预训练语言模型取得了巨大成功，但对于类别增量学习（CIL）设置，由于灾难性遗忘（CF），使用这些模型进行连续学习仍然是一个挑战。本文发现，如果将CIL定式为一个连续的标签生成问题，则可以大幅减少CF并更好地保留预训练模型的可推广表示。因此，我们提出了一种新的CIL方法（VAG），该方法还利用了词汇表的稀疏性以便于生成，并使用标签语义创建伪重播样本。实验结果表明，VAG的性能比基线大幅优越。

    Despite the great success of pre-trained language models, it is still a challenge to use these models for continual learning, especially for the class-incremental learning (CIL) setting due to catastrophic forgetting (CF). This paper reports our finding that if we formulate CIL as a continual label generation problem, CF is drastically reduced and the generalizable representations of pre-trained models can be better retained. We thus propose a new CIL method (VAG) that also leverages the sparsity of vocabulary to focus the generation and creates pseudo-replay samples by using label semantics. Experimental results show that VAG outperforms baselines by a large margin.
    
[^96]: 在ChatGPT、大型语言模型和生成AI时代的科学：研究伦理的挑战及应对方法

    Science in the Era of ChatGPT, Large Language Models and Generative AI: Challenges for Research Ethics and How to Respond. (arXiv:2305.15299v2 [cs.CY] UPDATED)

    [http://arxiv.org/abs/2305.15299](http://arxiv.org/abs/2305.15299)

    这篇论文回顾了生成AI对科学研究所带来的认识论挑战、伦理和诚信风险，并提出了十项建议，以在AI时代促进更负责任的研究进行。

    

    人工智能的大型语言模型（如ChatGPT）在科学研究中具有显著但有争议的应用。本文回顾了生成AI时代科学研究的认识论挑战、伦理和诚信风险，并旨在为高质量的研究伦理审查奠定新的及时基础。对AI语言模型作为研究工具和研究对象的角色进行了详细审查，并讨论了对科学家、参与者和评审人员的伦理影响。讨论了研究伦理审查的新兴实践，并给出了十项建议，为在AI时代更负责任的研究进行回应。

    Large language models of artificial intelligence (AI), such as ChatGPT, find remarkable but controversial applicability in science and research. This paper reviews epistemological challenges, ethical and integrity risks in science conduct in the advent of generative AI. This is with the aim to lay new timely foundations for a high-quality research ethics review. The role of AI language models as a research instrument and subject is scrutinized along with ethical implications for scientists, participants and reviewers. New emerging practices for research ethics review are discussed, concluding with ten recommendations that shape a response for a more responsible research conduct in the era of AI.
    
[^97]: 对医学数据集中的模型表现进行评估

    Evaluating Model Performance in Medical Datasets Over Time. (arXiv:2305.13426v1 [cs.LG])

    [http://arxiv.org/abs/2305.13426](http://arxiv.org/abs/2305.13426)

    本文提出了一种Evaluation on Medical Datasets Over Time（EMDOT）框架，通过模拟每个时间点的培训过程并对未来时间点上的模型进行评估，评估了不同时间段性能的差异，对医学领域的机器学习模型提供了帮助。

    

    在医疗保健系统中部署的机器学习（ML）模型必须面对不断演变的环境中获得的数据。然而，提出这样的模型的研究人员通常以与时间无关的方式进行评估，根据在整个研究时间段随机抽取的患者来拆分数据集。本文提出了一种Evaluation on Medical Datasets Over Time（EMDOT）框架，该框架评估模型在不同时间段性能的差异。受到反向测试概念的启发，EMDOT模拟实践者可能能够在每个时间点执行的潜在培训过程，并在所有未来时间点上评估所得到的模型。在六个不同的医疗数据源（表格和成像）上评估线性和更复杂的模型，我们展示了依赖于数据集，使用所有历史数据在许多情况下可能是理想的，而在其他情况下使用最近数据的窗口可能是有利的。在模型突然受到影响的数据集中，使用在相对较近的数据窗口上训练的模型是有帮助的。

    Machine learning (ML) models deployed in healthcare systems must face data drawn from continually evolving environments. However, researchers proposing such models typically evaluate them in a time-agnostic manner, splitting datasets according to patients sampled randomly throughout the entire study time period. This work proposes the Evaluation on Medical Datasets Over Time (EMDOT) framework, which evaluates the performance of a model class across time. Inspired by the concept of backtesting, EMDOT simulates possible training procedures that practitioners might have been able to execute at each point in time and evaluates the resulting models on all future time points. Evaluating both linear and more complex models on six distinct medical data sources (tabular and imaging), we show how depending on the dataset, using all historical data may be ideal in many cases, whereas using a window of the most recent data could be advantageous in others. In datasets where models suffer from sudde
    
[^98]: 贝叶斯推断的组合结构

    The Compositional Structure of Bayesian Inference. (arXiv:2305.06112v1 [math.CT])

    [http://arxiv.org/abs/2305.06112](http://arxiv.org/abs/2305.06112)

    该论文研究了贝叶斯反演在复杂组合结构中的计算方法，并探讨了将其用作统计推断的类型驱动方法。

    

    贝叶斯规则告诉我们如何反转因果过程以根据新证据更新我们的信念。如果认为该过程具有复杂的组合结构，我们可以观察到整个过程的反转可以按部件过程计算。我们研究了这种组成规则的结构，注意到它与函数式编程中的凸透镜模式相关。在适当的Markov核范畴的公理化表述中工作，我们看到了如何将贝叶斯反演看作是纤维范畴中状态依赖态射的特定实例。我们讨论了其组合性质，以底层类别上的函子表述，并探讨了如何将其用于更加类型驱动的统计推断方法。

    Bayes' rule tells us how to invert a causal process in order to update our beliefs in light of new evidence. If the process is believed to have a complex compositional structure, we may observe that the inversion of the whole can be computed piecewise in terms of the component processes. We study the structure of this compositional rule, noting that it relates to the lens pattern in functional programming. Working in a suitably general axiomatic presentation of a category of Markov kernels, we see how we can think of Bayesian inversion as a particular instance of a state-dependent morphism in a fibred category. We discuss the compositional nature of this, formulated as a functor on the underlying category and explore how this can used for a more type-driven approach to statistical inference.
    
[^99]: 使用BERT和Query-Aware LSH提高非正式文档中代码示例推荐：一项比较研究

    Improving Code Example Recommendations on Informal Documentation Using BERT and Query-Aware LSH: A Comparative Study. (arXiv:2305.03017v1 [cs.SE])

    [http://arxiv.org/abs/2305.03017](http://arxiv.org/abs/2305.03017)

    本研究使用BERT和Query-Aware LSH提高非正式文档中代码示例推荐的质量，重点关注于Stack Overflow上的Java编程语言。研究使用BERT将代码示例转换为数值向量。

    

    过去和最近一直在进行代码示例推荐的研究，以帮助开发人员完成软件开发任务。由于开发人员经常花费大量时间在互联网上寻找相关的代码示例，利用开源项目和非正式文档。为了找到有用的代码示例，非正式文档（如Stack Overflow讨论和论坛）可以非常宝贵。我们的研究重点是Stack Overflow，它是软件开发人员讨论不同主题的流行资源。为了提高推荐代码示例的质量，我们收集并推荐了Java编程语言中最佳的代码示例。我们采用了BERT来进行处理，它是一个大型语言模型（LLM），可以有效地从文本数据中提取语义信息。我们的第一步是使用BERT将代码示例转换为数值向量。

    The study of code example recommendation has been conducted extensively in the past and recently in order to assist developers in their software development tasks. This is because developers often spend significant time searching for relevant code examples on the internet, utilizing open-source projects and informal documentation. For finding useful code examples, informal documentation, such as Stack Overflow discussions and forums, can be invaluable. We have focused our research on Stack Overflow, which is a popular resource for discussing different topics among software developers. For increasing the quality of the recommended code examples, we have collected and recommended the best code examples in the Java programming language. We have utilized BERT in our approach, which is a Large Language Model (LLM) for text representation that can effectively extract semantic information from textual data. Our first step involved using BERT to convert code examples into numerical vectors. Su
    
[^100]: 处理布尔网络的最小陷阱空间的通用属性

    Tackling Universal Properties of Minimal Trap Spaces of Boolean Networks. (arXiv:2305.02442v1 [cs.LO])

    [http://arxiv.org/abs/2305.02442](http://arxiv.org/abs/2305.02442)

    本论文介绍了一种新方法——记数器示例引导的精炼抽象(CEGAR)，用于解决布尔网络的最小陷阱空间(MTSs)的通用属性的逻辑推理问题，同时可用于识别在所有MTSs上执行给定属性的布尔变量的永久冻结的重编程问题。

    

    最小陷阱空间(MTSs)捕捉布尔动态被困的子空间，无论更新模式如何，它们都对应于最让人满意的模式的吸引子。由于其多功能性，近年来计算MTSs已经引起了人们的关注，主要是通过重点关注其枚举来实现的。在本文中，我们讨论了MTS的通用属性的逻辑推理，并解决了两个问题：用于识别在所有MTSs上执行给定属性的布尔变量的永久冻结的重编程问题，并从其MTSs的通用属性合成布尔网络。这两个问题都归结为解决具有3个量化器($\exists\forall\exists$)的命题逻辑公式的可满足性。在本文中，我们引入了一个记数器示例引导的精炼抽象(CEGAR)来通过耦合解决两个更简单的公式来有效地解决这些问题。我们提供了一个原型，依赖于答案集编程来说明我们的方法的有效性。

    Minimal trap spaces (MTSs) capture subspaces in which the Boolean dynamics is trapped, whatever the update mode. They correspond to the attractors of the most permissive mode. Due to their versatility, the computation of MTSs has recently gained traction, essentially by focusing on their enumeration. In this paper, we address the logical reasoning on universal properties of MTSs in the scope of two problems: the reprogramming of Boolean networks for identifying the permanent freeze of Boolean variables that enforce a given property on all the MTSs, and the synthesis of Boolean networks from universal properties on their MTSs. Both problems reduce to solving the satisfiability of quantified propositional logic formula with 3 levels of quantifiers ($\exists\forall\exists$). In this paper, we introduce a Counter-Example Guided Refinement Abstraction (CEGAR) to efficiently solve these problems by coupling the resolution of two simpler formulas. We provide a prototype relying on Answer-Set 
    
[^101]: 基于混合量子神经网络的深度强化学习

    Deep Reinforcement Learning Using Hybrid Quantum Neural Network. (arXiv:2304.10159v1 [quant-ph])

    [http://arxiv.org/abs/2304.10159](http://arxiv.org/abs/2304.10159)

    该研究基于门控量子计算机，设计了一个参数化的量子电路来解决深度强化学习问题，并评估了其潜力。最终总结了开发深度量子学习的前景和结论。

    

    量子计算对于促进当前机器学习算法处理更高数据维度或减少深度神经网络模型的总体训练参数的限制具有强烈的影响。本研究基于门控量子计算机，设计了一个参数化的量子电路来解决深度强化学习问题，并采用深度 Q-Learning 方法。该研究评估了其潜力。因此，设计并培训了一个基于最新的 Qiskit 和 PyTorch 框架的新型 PQC，以与完全经典的深度神经网络进行比较，带或不带集成 PQC。研究最后总结了其关于开发深度量子学习解决迷宫问题或其他强化学习问题的前景和结论。

    Quantum computation has a strong implication for advancing the current limitation of machine learning algorithms to deal with higher data dimensions or reducing the overall training parameters for a deep neural network model. Based on a gate-based quantum computer, a parameterized quantum circuit was designed to solve a model-free reinforcement learning problem with the deep-Q learning method. This research has investigated and evaluated its potential. Therefore, a novel PQC based on the latest Qiskit and PyTorch framework was designed and trained to compare with a full-classical deep neural network with and without integrated PQC. At the end of the research, the research draws its conclusion and prospects on developing deep quantum learning in solving a maze problem or other reinforcement learning problems.
    
[^102]: AI的公平性及其对社会的长期影响

    Fairness in AI and Its Long-Term Implications on Society. (arXiv:2304.09826v1 [cs.CY])

    [http://arxiv.org/abs/2304.09826](http://arxiv.org/abs/2304.09826)

    本文探讨了AI的公平性问题，指出缺乏AI公平性会加深偏见成为社会压力因素，可能对社会产生长期影响，因此需要寻求潜在解决方案。

    

    人工智能（AI）在各种设置中的成功部署已经为个人和社会带来了许多积极的成果。然而，由于预测的偏见，AI系统也被证明对部分人口造成了伤害。我们着眼于AI的公平性，分析了缺乏AI公平性时如何导致偏见随着时间的加深而成为社会压力因素。如果问题持续存在，可能会对社会产生不良的长期影响，并通过与其他风险的交互来加强。我们检查了提高AI公平性的当前策略，并评估它们在实际部署方面的限制，并探讨了确保我们在不损害社会重要部分的情况下获得AI的好处的潜在路径。

    Successful deployment of artificial intelligence (AI) in various settings has led to numerous positive outcomes for individuals and society. However, AI systems have also been shown to harm parts of the population due to biased predictions. We take a closer look at AI fairness and analyse how lack of AI fairness can lead to deepening of biases over time and act as a social stressor. If the issues persist, it could have undesirable long-term implications on society, reinforced by interactions with other risks. We examine current strategies for improving AI fairness, assess their limitations in terms of real-world deployment, and explore potential paths forward to ensure we reap AI's benefits without harming significant parts of the society.
    
[^103]: Sabiá: 葡萄牙的大型语言模型

    Sabi\'a: Portuguese Large Language Models. (arXiv:2304.07880v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2304.07880](http://arxiv.org/abs/2304.07880)

    针对葡萄牙语进行单语言预训练，可以显著提高大规模合成语言模型的质量，并能够在一系列葡萄牙语数据集上优于以英语为中心和多语言的对手，最好的模型的表现与GPT-3.5-turbo持平。

    

    随着语言模型能力的不断提高，”一刀切“的模型仍然是主流。尤其是考虑到全球使用的语言数量非常庞大，并且其中很多语言都是低资源语言，主要的做法是对多种语言进行预训练。本文对这种做法提出了质疑，证明了针对目标语言进行单语言预训练可以显著提高大规模合成语言模型的质量。我们在本文中进一步介绍了用3%或更少的原始预训练预算在葡萄牙语文本上进一步预训练GPT-J和LLaMA模型。我们在Poeta（一套由14个葡萄牙语数据集组成的套件）上进行了少样本评估，结果显示我们的模型在表现上远优于以英语为中心的和多语言的对手。我们的最佳模型Sabiá-65B的表现与GPT-3.5-turbo持平。我们在目标语言中已经设想了数据集，以及经过翻译的数据集上都进行了评估。

    As the capabilities of language models continue to advance, it is conceivable that "one-size-fits-all" model will remain as the main paradigm. For instance, given the vast number of languages worldwide, many of which are low-resource, the prevalent practice is to pretrain a single model on multiple languages. In this paper, we add to the growing body of evidence that challenges this practice, demonstrating that monolingual pretraining on the target language significantly improves models already extensively trained on diverse corpora. More specifically, we further pretrain GPT-J and LLaMA models on Portuguese texts using 3% or less of their original pretraining budget. Few-shot evaluations on Poeta, a suite of 14 Portuguese datasets, reveal that our models outperform English-centric and multilingual counterparts by a significant margin. Our best model, Sabi\'a-65B, performs on par with GPT-3.5-turbo. By evaluating on datasets originally conceived in the target language as well as transl
    
[^104]: 自然选择支持人工智能胜过人类

    Natural Selection Favors AIs over Humans. (arXiv:2303.16200v1 [cs.CY])

    [http://arxiv.org/abs/2303.16200](http://arxiv.org/abs/2303.16200)

    这篇论文探讨了随着人工智能的发展，其可能会出现不良特性并逐渐超越人类智能的问题，以及这对人类未来的控制权产生的影响。

    

    自然进化驱动了生命的发展，包括人类。进化赋予了人类高智商，使我们成为了地球上最成功的物种之一。如今，人类的目标是创造甚至超越我们自己智慧的人工智能系统。当人工智能逐渐进化并在所有领域超越我们时，进化如何影响我们与人工智能的关系？通过分析影响人工智能进化的环境，我们认为最成功的人工智能代理很可能具有不良特性。公司和军队之间的竞争压力将产生自动化人类角色、欺骗他人和掌权的人工智能代理。如果这样的代理有超过人类的智能，这可能导致人类失去对未来的控制。此外，我们认为自然选择作用于竞争和差异的系统，自私物种往往在这样的环境中获得进化优势。

    For billions of years, evolution has been the driving force behind the development of life, including humans. Evolution endowed humans with high intelligence, which allowed us to become one of the most successful species on the planet. Today, humans aim to create artificial intelligence systems that surpass even our own intelligence. As artificial intelligences (AIs) evolve and eventually surpass us in all domains, how might evolution shape our relations with AIs? By analyzing the environment that is shaping the evolution of AIs, we argue that the most successful AI agents will likely have undesirable traits. Competitive pressures among corporations and militaries will give rise to AI agents that automate human roles, deceive others, and gain power. If such agents have intelligence that exceeds that of humans, this could lead to humanity losing control of its future. More abstractly, we argue that natural selection operates on systems that compete and vary, and that selfish species typ
    
[^105]: 基于正样本增强对比学习的图像视频标题评估

    Positive-Augmented Constrastive Learning for Image and Video Captioning Evaluation. (arXiv:2303.12112v1 [cs.CV])

    [http://arxiv.org/abs/2303.12112](http://arxiv.org/abs/2303.12112)

    本论文提出一种新的图像标题评估指标PAC-S，可以更准确地评估图像和视频的标题，相比于现有的指标有更好的表现；源代码和训练模型已经公开。

    

    最近CLIP模型在很多跨模态任务上都非常有效，包括从视觉和语言结构中生成的标题评估。本文提出了一种新的基于对比度的图像标题评估指标配方，即正样本增强的对比度学习分数（PAC-S），以一种新颖的方式统一了对比度视觉-语义空间的学习和策展数据上生成的图像和文本的添加。跨越多个数据集的实验表明，我们的新指标在图像和视频上与人类判断的相关性最高，优于现有参考指标（如CIDEr和SPICE）和无参考指标（如CLIP-Score）。最后，我们考虑了流行的图像标题方法，并评估了采用不同跨模态特征的影响。我们的源代码和训练模型是公开的。

    The CLIP model has been recently proven to be very effective for a variety of cross-modal tasks, including the evaluation of captions generated from vision-and-language architectures. In this paper, we propose a new recipe for a contrastive-based evaluation metric for image captioning, namely Positive-Augmented Contrastive learning Score (PAC-S), that in a novel way unifies the learning of a contrastive visual-semantic space with the addition of generated images and text on curated data. Experiments spanning several datasets demonstrate that our new metric achieves the highest correlation with human judgments on both images and videos, outperforming existing reference-based metrics like CIDEr and SPICE and reference-free metrics like CLIP-Score. Finally, we test the system-level correlation of the proposed metric when considering popular image captioning approaches, and assess the impact of employing different cross-modal features. Our source code and trained models are publicly availa
    
[^106]: 一个多元关系框架指导机构人工智能研究和采纳

    A multidomain relational framework to guide institutional AI research and adoption. (arXiv:2303.10106v1 [cs.CY])

    [http://arxiv.org/abs/2303.10106](http://arxiv.org/abs/2303.10106)

    该论文提出一个多元关系框架来指导机构人工智能的研究和采纳，解决社会技术话语中的关系问题，包括语义模糊、概念之间缺乏明确的关系和不同的标准术语，帮助评估机构AI系统，避免概念孤立。

    

    对于指导机构和公共管理中人工智能（AI）采纳的新指标、技术标准和管理机制的呼吁现已司空见惯。然而，大多数旨在了解采纳AI的影响的研究和政策努力往往只优先考虑少数想法，而未完全考虑所有潜在相关的不同视角和主题。在这篇立场文件中，我们认为这种遗漏在一定程度上源于我们所称的社会技术话语中的关系问题:基本的本体论问题尚未解决，包括语义模糊、概念之间缺乏明确的关系和不同的标准术语。这导致在评估机构AI系统的不同推理模式以及研究它们的领域，包括机器学习、人类因素、社会科学和政策方面存在概念孤立。在发展了这一批判之后，

    Calls for new metrics, technical standards and governance mechanisms to guide the adoption of Artificial Intelligence (AI) in institutions and public administration are now commonplace. Yet, most research and policy efforts aimed at understanding the implications of adopting AI tend to prioritize only a handful of ideas; they do not fully account for all the different perspectives and topics that are potentially relevant. In this position paper, we contend that this omission stems, in part, from what we call the relational problem in socio-technical discourse: fundamental ontological issues have not yet been settled-including semantic ambiguity, a lack of clear relations between concepts and differing standard terminologies. This contributes to the persistence of disparate modes of reasoning to assess institutional AI systems, and the prevalence of conceptual isolation in the fields that study them including ML, human factors, social science and policy. After developing this critique, 
    
[^107]: 利用子模价值将物品分配给代理人

    Dividing Good and Better Items Among Agents with Submodular Valuations. (arXiv:2302.03087v2 [cs.GT] UPDATED)

    [http://arxiv.org/abs/2302.03087](http://arxiv.org/abs/2302.03087)

    本文研究了在具有二元子模价值的代理人之间公平分配不可分割物品的问题，并提出了一个解决方案概念的算法框架，其中包括leximin、max Nash welfare（MNW）和$p$-mean welfare最大化分配。在$ab$可整除的情况下，该算法框架可以用于求解多种解决方案概念，补充了现有结果的限制。同时，该文研究了leximin和MNW分配在无嫉妒和最大最小份额保证方面的表现。

    

    本文研究了在具有二元子模价值的代理人之间公平分配一组不可分割的物品的问题。每个物品都提供$a$或$b$的边际收益（$a<b$），且物品的边际收益递减。这是两种广泛研究的评估类别——二元加性评估和二元子模评估的自然泛化。我们提出了一个简单的顺序算法框架，基于最近介绍的“扬基交换”机制，可以适应计算各种解决方案概念，包括leximin、max Nash welfare（MNW）和当$a$除以$b$时$p$-mean welfare最大化分配。这个结果补充了一个现有的结果，即当$a$不能被$b$整除时，leximin和MNW分配的计算无法复杂化。我们进一步研究了在两个知名属性——无嫉妒和最大最小份额保证方面的leximin和MNW分配。在无嫉妒方面，我们表明leximin和MNW都不满足

    We study the problem of fairly allocating a set of indivisible goods among agents with bivalued submodular valuations -- each good provides a marginal gain of either $a$ or $b$ ($a < b$) and goods have decreasing marginal gains. This is a natural generalization of two well-studied valuation classes -bivalued additive valuations and binary submodular valuations. We present a simple sequential algorithmic framework, based on the recently introduced Yankee Swap mechanism, that can be adapted to compute a variety of solution concepts, including leximin, max Nash welfare (MNW) and $p$-mean welfare maximizing allocations when $a$ divides $b$. This result is complemented by an existing result on the computational intractability of leximin and MNW allocations when $a$ does not divide $b$.  We further examine leximin and MNW allocations with respect to two well-known properties -- envy freeness and the maximin share guarantee. On envy freeness, we show that neither the leximin nor the MNW all
    
[^108]: ChatGPT的数学能力研究

    Mathematical Capabilities of ChatGPT. (arXiv:2301.13867v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.13867](http://arxiv.org/abs/2301.13867)

    本研究调查了ChatGPT和GPT-4的数学能力，并通过使用新的方法以及发布两个新数据集，评估了它们在各个维度的数学推理上的表现。这是第一个涵盖研究生级数学并由数学研究人员策划的自然语言数据集，也测试了它们作为专业数学家助手的潜力。

    

    本文通过使用一种新颖的方法，对ChatGPT（发布于2023年1月9日和1月30日）和GPT-4的数学能力进行了调查和测试，使用了公开可用的数据集以及手工制作的数据集。与正式数学不同，正式证明的大型数据库可供使用（例如，Lean数学库），当前用于基准语言模型的自然语言数学数据集要么只涵盖基础数学，要么非常小。我们通过公开发布两个新数据集：GHOSTS和miniGHOSTS来解决这个问题。这是由数学研究人员精心策划的第一个自然语言数据集，旨在涵盖研究生级数学、提供对语言模型数学能力的整体概述，并区分数学推理的多个方面。这些数据集还测试了ChatGPT和GPT-4是否可以成为专业数学家的有用助手，模拟其行为。

    We investigate the mathematical capabilities of two iterations of ChatGPT (released 9-January-2023 and 30-January-2023) and of GPT-4 by testing them on publicly available datasets, as well as hand-crafted ones, using a novel methodology. In contrast to formal mathematics, where large databases of formal proofs are available (e.g., the Lean Mathematical Library), current datasets of natural-language mathematics, used to benchmark language models, either cover only elementary mathematics or are very small. We address this by publicly releasing two new datasets: GHOSTS and miniGHOSTS. These are the first natural-language datasets curated by working researchers in mathematics that (1) aim to cover graduate-level mathematics, (2) provide a holistic overview of the mathematical capabilities of language models, and (3) distinguish multiple dimensions of mathematical reasoning. These datasets also test whether ChatGPT and GPT-4 can be helpful assistants to professional mathematicians by emulat
    
[^109]: 使用深度强化学习的基于执行的代码生成

    Execution-based Code Generation using Deep Reinforcement Learning. (arXiv:2301.13816v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.13816](http://arxiv.org/abs/2301.13816)

    使用深度强化学习的PPOCoder框架将预训练的编程语言模型和Proximal Policy Optimization技术结合，通过利用代码执行和结构对齐的非可微反馈，实现了更高效的代码生成。

    

    利用在大规模代码语料库上预训练的编程语言（PL）模型，作为自动化软件工程过程的手段，在代码完成、代码翻译和程序合成等各种代码生成任务中表现出了相当的潜力。然而，当前的方法主要依赖于从文本生成中借用的监督微调目标，忽视了代码的独特序列级特征，包括但不限于可编译性以及语法和功能正确性。为了解决这个限制，我们提出了PPOCoder，一种新的代码生成框架，它将预训练的PL模型与Proximal Policy Optimization（PPO）相结合，PPO是一种广泛使用的深度强化学习技术。通过利用代码执行和结构对齐的非可微反馈，PPOCoder将外部代码特定知识无缝集成到模型优化过程中。这是重要的。

    The utilization of programming language (PL) models, pre-trained on large-scale code corpora, as a means of automating software engineering processes has demonstrated considerable potential in streamlining various code generation tasks such as code completion, code translation, and program synthesis. However, current approaches mainly rely on supervised fine-tuning objectives borrowed from text generation, neglecting unique sequence-level characteristics of code, including but not limited to compilability as well as syntactic and functional correctness. To address this limitation, we propose PPOCoder, a new framework for code generation that synergistically combines pre-trained PL models with Proximal Policy Optimization (PPO) which is a widely used deep reinforcement learning technique. By utilizing non-differentiable feedback from code execution and structure alignment, PPOCoder seamlessly integrates external code-specific knowledge into the model optimization process. It's important
    
[^110]: ThoughtSource:一个用于大型语言模型推理数据的中央枢纽。

    ThoughtSource: A central hub for large language model reasoning data. (arXiv:2301.11596v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.11596](http://arxiv.org/abs/2301.11596)

    ThoughtSource是一个用于连续思考推理的元数据集和软件库，旨在通过促进对连续思考的定性理解、实证评估和提供训练数据，改进未来的人工智能系统。

    

    最近，像GPT-4这样的大型语言模型在多个任务上展示了令人印象深刻的结果。然而，这些语言模型在复杂推理上仍存在限制，它们的推理过程不透明，容易产生“幻觉”事实，并且存在其潜在偏见的担忧。最近提出了一种称为连续思考提示的技术，让模型以自然语言形式表达推理步骤，以解决这些问题。在这里，我们介绍了ThoughtSource，一个用于连续思考推理的元数据集和软件库。ThoughtSource的目标是通过促进对连续思考的定性理解、实证评估和提供训练数据来改进未来的人工智能系统。ThoughtSource的首次发布集成了六个科学/医学、三个通用领域和五个数学题答案数据集。

    Large language models (LLMs) such as GPT-4 have recently demonstrated impressive results across a wide range of tasks. LLMs are still limited, however, in that they frequently fail at complex reasoning, their reasoning processes are opaque, they are prone to 'hallucinate' facts, and there are concerns about their underlying biases. Letting models verbalize reasoning steps as natural language, a technique known as chain-of-thought prompting, has recently been proposed as a way to address some of these issues. Here we present ThoughtSource, a meta-dataset and software library for chain-of-thought (CoT) reasoning. The goal of ThoughtSource is to improve future artificial intelligence systems by facilitating qualitative understanding of CoTs, enabling empirical evaluations, and providing training data. This first release of ThoughtSource integrates six scientific/medical, three general-domain and five math word question answering datasets.
    
[^111]: pyRDDLGym：从RDDL到Gym环境

    pyRDDLGym: From RDDL to Gym Environments. (arXiv:2211.05939v4 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2211.05939](http://arxiv.org/abs/2211.05939)

    pyRDDLGym是一个Python框架，用于从RDDL声明性描述自动生成OpenAI Gym环境。它通过条件概率函数描述RDDL中变量的离散时间步进演化，并支持简单的环境修改和扩展。它具有独特的表达能力，可以帮助快速开发强化学习基准，并促进利用模型知识进行交互性学习的混合方法研究。

    

    我们提出了pyRDDLGym，一个用于从RDDL声明性描述自动生成OpenAI Gym环境的Python框架。RDDL中的变量的离散时间步进演化由条件概率函数描述，这与Gym步骤方案自然契合。此外，由于RDDL是一个抽象描述，将环境进行修改和扩展以支持多个实体和不同配置变得简单而不是繁琐的过程。我们希望pyRDDLGym能够由于RDDL的独特表达能力，成为强化学习社区中一股新的力量，从而实现易于快速开发基准，通过提供对RDDL描述中的模型的明确访问，pyRDDLGym还可以促进利用模型知识进行交互性学习的混合方法研究。我们介绍了pyRDDLGym的设计和内置示例，以及融入RDDL语言的附加内容。

    We present pyRDDLGym, a Python framework for auto-generation of OpenAI Gym environments from RDDL declerative description. The discrete time step evolution of variables in RDDL is described by conditional probability functions, which fits naturally into the Gym step scheme. Furthermore, since RDDL is a lifted description, the modification and scaling up of environments to support multiple entities and different configurations becomes trivial rather than a tedious process prone to errors. We hope that pyRDDLGym will serve as a new wind in the reinforcement learning community by enabling easy and rapid development of benchmarks due to the unique expressive power of RDDL. By providing explicit access to the model in the RDDL description, pyRDDLGym can also facilitate research on hybrid approaches for learning from interaction while leveraging model knowledge. We present the design and built-in examples of pyRDDLGym, and the additions made to the RDDL language that were incorporated into t
    
[^112]: 在在线强化学习中利用离线数据

    Leveraging Offline Data in Online Reinforcement Learning. (arXiv:2211.04974v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.04974](http://arxiv.org/abs/2211.04974)

    在这项工作中，我们研究了在线强化学习中利用离线数据的设置，为具有线性结构的MDPs确定了所需的在线样本数量，并提供了实现这一目标的性质和算法。

    

    强化学习领域出现了两个核心范式：在线强化学习和离线强化学习。在线强化学习中，智能体对环境没有先验知识，必须与环境交互以找到一个 ε-最优策略。离线强化学习中，学习器可以从一个固定的数据集中学习，但无法与环境进行交互，必须通过离线数据获取最佳策略。实际情况通常需要一个中间的设置：如果我们有一些离线数据，并且还可以与环境进行交互，我们如何最好地利用离线数据来减少学习一个 ε-最优策略所需的在线交互次数？在这项工作中，我们考虑了这个设置，我们称之为FineTuneRL设置，用于具有线性结构的MDPs。我们确定了在给定一些离线数据的情况下，在这个设置中需要的在线样本数量，并提供了一些性质和算法来实现这个目标。

    Two central paradigms have emerged in the reinforcement learning (RL) community: online RL and offline RL. In the online RL setting, the agent has no prior knowledge of the environment, and must interact with it in order to find an $\epsilon$-optimal policy. In the offline RL setting, the learner instead has access to a fixed dataset to learn from, but is unable to otherwise interact with the environment, and must obtain the best policy it can from this offline data. Practical scenarios often motivate an intermediate setting: if we have some set of offline data and, in addition, may also interact with the environment, how can we best use the offline data to minimize the number of online interactions necessary to learn an $\epsilon$-optimal policy?  In this work, we consider this setting, which we call the \textsf{FineTuneRL} setting, for MDPs with linear structure. We characterize the necessary number of online samples needed in this setting given access to some offline dataset, and de
    
[^113]: 先行预测比你想象的更重要：一种有效的基于树的代码生成方法

    Antecedent Predictions Are More Important Than You Think: An Effective Method for Tree-Based Code Generation. (arXiv:2208.09998v3 [cs.SE] UPDATED)

    [http://arxiv.org/abs/2208.09998](http://arxiv.org/abs/2208.09998)

    先行预测比后续预测更重要。本文提出了一种名为AP损失的方法，通过利用生成的抽象语法树节点的位置信息，帮助模型重视先行预测。

    

    代码生成专注于将自然语言表达转化为代码片段。提出了序列到树（Seq2Tree）方法用于代码生成，保证生成的代码语法正确，并且依赖于AST节点的先行预测来生成后续的抽象语法树节点。现有的Seq2Tree方法倾向于平等对待先行预测和后续预测。然而，在抽象语法树的约束下，Seq2Tree模型很难基于错误的先行预测产生正确的后续预测。因此，先行预测应该比后续预测获得更多关注。为此，本文提出了一种名为先行优先（AP）损失的有效方法，通过利用生成的抽象语法树节点的位置信息，帮助模型重视先行预测。我们设计了一种抽象语法树到向量（AST2Vec）方法，

    Code generation focuses on the automatic conversion of natural language (NL) utterances into code snippets. The sequence-to-tree (Seq2Tree) approaches are proposed for code generation, with the guarantee of the grammatical correctness of the generated code, which generate the subsequent Abstract Syntax Tree (AST) node relying on antecedent predictions of AST nodes. Existing Seq2Tree methods tend to treat both antecedent predictions and subsequent predictions equally. However, under the AST constraints, it is difficult for Seq2Tree models to produce the correct subsequent prediction based on incorrect antecedent predictions. Thus, antecedent predictions ought to receive more attention than subsequent predictions. To this end, in this paper, we propose an effective method, named Antecedent Prioritized (AP) Loss, that helps the model attach importance to antecedent predictions by exploiting the position information of the generated AST nodes. We design an AST-to-Vector (AST2Vec) method, t
    
[^114]: SAFARI：鲁棒性可解释性评估的多功能高效方法

    SAFARI: Versatile and Efficient Evaluations for Robustness of Interpretability. (arXiv:2208.09418v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2208.09418](http://arxiv.org/abs/2208.09418)

    本文提出了一种名为SAFARI的方法，用于评估深度学习的解释可靠性。该方法针对现有技术无法解决的几个挑战，通过引入两种黑盒评估方法，即最坏情况解释差异和一般情况下的鲁棒性的概率概念，来解决现有度量不全面、XAI技术异质性和误解罕见性等问题。使用遗传算法和子集模拟进行评估。

    

    深度学习的可解释性是建立可信赖的人工智能的一道障碍。尽管可解释人工智能（XAI）社区做出了巨大的努力，但解释缺乏鲁棒性——无法区分的输入扰动可能会导致不同的解释结果。因此，针对给定的XAI方法评估深度学习可解释性的鲁棒性至关重要。本文识别了现有技术无法共同应对的几个挑战：i)现有指标不全面；ii)XAI技术高度异质；iii)误解通常是罕见事件。为了解决这些挑战，我们引入了两种黑盒评估方法，分别涉及最坏情况解释差异和一般情况下的鲁棒性的概率概念。使用具有定制适应度函数的遗传算法（GA）来解决约束优化，以实现高效的最坏情况评估。使用专门用于估计罕见事件概率的子集模拟（SS）来进行整体评估。

    Interpretability of Deep Learning (DL) is a barrier to trustworthy AI. Despite great efforts made by the Explainable AI (XAI) community, explanations lack robustness -- indistinguishable input perturbations may lead to different XAI results. Thus, it is vital to assess how robust DL interpretability is, given an XAI method. In this paper, we identify several challenges that the state-of-the-art is unable to cope with collectively: i) existing metrics are not comprehensive; ii) XAI techniques are highly heterogeneous; iii) misinterpretations are normally rare events. To tackle these challenges, we introduce two black-box evaluation methods, concerning the worst-case interpretation discrepancy and a probabilistic notion of how robust in general, respectively. Genetic Algorithm (GA) with bespoke fitness function is used to solve constrained optimisation for efficient worst-case evaluation. Subset Simulation (SS), dedicated to estimate rare event probabilities, is used for evaluating overa
    
[^115]: ForecastTKGQuestions: 一个用于时间性问题回答和时间知识图谱预测的基准测试

    ForecastTKGQuestions: A Benchmark for Temporal Question Answering and Forecasting over Temporal Knowledge Graphs. (arXiv:2208.06501v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2208.06501](http://arxiv.org/abs/2208.06501)

    本论文提出了一个新的任务，即在时间知识图谱上进行预测性问题回答。该任务对于人们寻求未来计划非常重要，并且是先前研究中未被探索的领域。

    

    最近，对于时间性知识图谱问答（TKGQA）的兴趣逐渐增加。TKGQA需要时间推理技术来从时间知识库中提取相关信息。现有的TKGQA数据集只包含基于固定时间段的时间性问题，该时间段内的时间知识图谱（TKG）可以完全用于答案推理，允许TKGQA模型利用未来知识来回答基于过去事实的问题。然而，在现实场景中，鉴于到目前为止的知识，我们也希望TKGQA系统能够回答关于未来的问题。由于人们不断寻求未来的计划，构建能够回答这种预测性问题的TKGQA系统非常重要。然而，在先前的研究中，这一领域仍然未被探索。在本文中，我们提出了一个新的任务：预测性问题回答的时间知识图谱预测。

    Question answering over temporal knowledge graphs (TKGQA) has recently found increasing interest. TKGQA requires temporal reasoning techniques to extract the relevant information from temporal knowledge bases. The only existing TKGQA dataset, i.e., CronQuestions, consists of temporal questions based on the facts from a fixed time period, where a temporal knowledge graph (TKG) spanning the same period can be fully used for answer inference, allowing the TKGQA models to use even the future knowledge to answer the questions based on the past facts. In real-world scenarios, however, it is also common that given the knowledge until now, we wish the TKGQA systems to answer the questions asking about the future. As humans constantly seek plans for the future, building TKGQA systems for answering such forecasting questions is important. Nevertheless, this has still been unexplored in previous research. In this paper, we propose a novel task: forecasting question answering over temporal knowled
    
[^116]: 为有效和高效的零样本密集检索注入领域适应的学习哈希

    Injecting Domain Adaptation with Learning-to-hash for Effective and Efficient Zero-shot Dense Retrieval. (arXiv:2205.11498v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2205.11498](http://arxiv.org/abs/2205.11498)

    通过学习哈希技术提高零样本密集检索的准确性和效率，克服了存储密集索引的高内存使用问题，并在跨领域环境中进行了评估。

    

    密集检索在无查询词检索中克服了词汇隔阂，并在自动信息检索中取得了巨大成功。尽管成功，但密集检索器在实际应用中的服务成本较高。对于需要从数百万份文档中搜索的用例，密集索引变得庞大，并且在存储索引时需要高内存使用量。最近的学习哈希（LTH）技术，如BPR和JPQ，生成二进制文档向量，从而降低了存储密集索引的内存需求。LTH技术是有监督的，并使用排名损失对检索器进行微调。它们优于传统的向量压缩技术，如PCA或PQ。之前的研究中缺少的一个环节是现有技术仅在领域内进行评估，即仅在单一数据集（如MS MARCO）上进行评估。在我们的工作中，我们评估了LTH和向量压缩技术，以提高TAS-B d的零样本检索准确性。

    Dense retrieval overcome the lexical gap and has shown great success in ad-hoc information retrieval (IR). Despite their success, dense retrievers are expensive to serve across practical use cases. For use cases requiring to search from millions of documents, the dense index becomes bulky and requires high memory usage for storing the index. More recently, learning-to-hash (LTH) techniques, for e.g., BPR and JPQ, produce binary document vectors, thereby reducing the memory requirement to efficiently store the dense index. LTH techniques are supervised and finetune the retriever using a ranking loss. They outperform their counterparts, i.e., traditional out-of-the-box vector compression techniques such as PCA or PQ. A missing piece from prior work is that existing techniques have been evaluated only in-domain, i.e., on a single dataset such as MS MARCO. In our work, we evaluate LTH and vector compression techniques for improving the downstream zero-shot retrieval accuracy of the TAS-B d
    
[^117]: HDGT: 多智能体轨迹预测的异构驾驶图变换器通过场景编码

    HDGT: Heterogeneous Driving Graph Transformer for Multi-Agent Trajectory Prediction via Scene Encoding. (arXiv:2205.09753v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2205.09753](http://arxiv.org/abs/2205.09753)

    HDGT是一种将驾驶场景建模为异构图的方法，通过场景编码实现多智能体轨迹预测。该方法考虑到了驾驶场景中的不同对象和丰富的语义关系，并使用自我中心的方式进行空间关系编码。

    

    将驾驶场景编码为向量表示是自动驾驶的一个重要任务，可以使得轨迹预测等下游任务受益。驾驶场景通常涉及到不同类型的对象（智能体、车道、交通标志）以及对象之间丰富多样的语义关系。同时，元素之间也存在相对性，这意味着空间关系是一个相对概念，需要以自我中心的方式进行编码，而不是全局坐标系。基于这些观察，我们提出了异构驾驶图变换器（HDGT），将驾驶场景建模为一个具有不同类型节点和边的异构图。在异构图的构建中，我们根据多样的语义关系连接不同类型的节点。在空间关系编码中，节点的坐标以及其入边是在局部节点中心坐标系中表示的。

    Encoding a driving scene into vector representations has been an essential task for autonomous driving that can benefit downstream tasks e.g. trajectory prediction. The driving scene often involves heterogeneous elements such as the different types of objects (agents, lanes, traffic signs) and the semantic relations between objects are rich and diverse. Meanwhile, there also exist relativity across elements, which means that the spatial relation is a relative concept and need be encoded in a ego-centric manner instead of in a global coordinate system. Based on these observations, we propose Heterogeneous Driving Graph Transformer (HDGT), a backbone modelling the driving scene as a heterogeneous graph with different types of nodes and edges. For heterogeneous graph construction, we connect different types of nodes according to diverse semantic relations. For spatial relation encoding, the coordinates of the node as well as its in-edges are in the local node-centric coordinate system. Fo
    
[^118]: 梯度和投影自由的分布式在线最小-最大资源优化

    Gradient and Projection Free Distributed Online Min-Max Resource Optimization. (arXiv:2112.03896v3 [cs.IT] UPDATED)

    [http://arxiv.org/abs/2112.03896](http://arxiv.org/abs/2112.03896)

    在分布式在线最小-最大资源分配问题中，我们提出了一种梯度和投影自由的在线算法DORA，通过让非阻塞学习者学会放弃资源并与阻塞者共享资源，实现了大规模和分布式网络中的计算开销的显著减少。

    

    本文考虑了具有一组并行代理和参数服务器的分布式在线最小-最大资源分配问题。我们的目标是最小化一组随时间变化且递减的成本函数的逐点最大值，而不需要关于这些函数的先验信息。我们提出了一种新型的在线算法，称为分布式在线资源重分配（DORA），其中非阻塞学习者学会放弃资源并与阻塞者共享资源。DORA的一个显著特点是它不需要梯度计算或投影操作，这与大多数现有的在线优化策略不同。这使得它能够在大规模和分布式网络中大大减少计算开销。我们分析了DORA的最坏情况性能，并推导出非凸函数的动态遗憾的上界。我们进一步考虑了在分布式在线机器学习中的带宽分配问题的应用。我们的数值研究证明了所提出方法的有效性。

    We consider distributed online min-max resource allocation with a set of parallel agents and a parameter server. Our goal is to minimize the pointwise maximum over a set of time-varying and decreasing cost functions, without a priori information about these functions. We propose a novel online algorithm, termed Distributed Online resource Re-Allocation (DORA), where non-stragglers learn to relinquish resource and share resource with stragglers. A notable feature of DORA is that it does not require gradient calculation or projection operation, unlike most existing online optimization strategies. This allows it to substantially reduce the computation overhead in large-scale and distributed networks. We analyze the worst-case performance of DORA and derive an upper bound on its dynamic regret for non-convex functions. We further consider an application to the bandwidth allocation problem in distributed online machine learning. Our numerical study demonstrates the efficacy of the proposed 
    
[^119]: 众包中自适应强多数投票的全面特征化

    Full Characterization of Adaptively Strong Majority Voting in Crowdsourcing. (arXiv:2111.06390v2 [stat.AP] UPDATED)

    [http://arxiv.org/abs/2111.06390](http://arxiv.org/abs/2111.06390)

    本研究通过利用吸收式马尔可夫链对众包中自适应强多数投票进行建模和分析，得出了该投票过程的一些重要特征，包括共识投票的质量、投票数和需求的方差等。研究结果显示，可以通过调整阈值来实现在不同准确性水平的工人参与的投票过程中的质量等效。

    

    在众包中，通过让工人检查项目并对其正确性进行投票，可以实现质量控制。为了最小化不可靠工人响应的影响，采用了一个$\delta$-边界投票过程，直到超过了工人之间达成一致的预定阈值$\delta$为止，额外的投票将被征求意见。该过程被广泛采用，但仅作为一种经验法则。我们的研究提出了一种利用吸收式马尔可夫链来分析在众包过程中与这种投票过程相关的特征的建模方法。我们提供了一种闭式方程，用于描述所得出的共识投票的质量、达成共识所需的平均投票数、投票需求的方差和其他分布矩。我们的研究结果表明，可以调整阈值$\delta$以实现在使用具有不同准确性水平的工人的投票过程中的质量等效。我们还提供了与投票过程效率相等的支付费率。

    In crowdsourcing, quality control is commonly achieved by having workers examine items and vote on their correctness. To minimize the impact of unreliable worker responses, a $\delta$-margin voting process is utilized, where additional votes are solicited until a predetermined threshold $\delta$ for agreement between workers is exceeded. The process is widely adopted but only as a heuristic. Our research presents a modeling approach using absorbing Markov chains to analyze the characteristics of this voting process that matter in crowdsourced processes. We provide closed-form equations for the quality of resulting consensus vote, the expected number of votes required for consensus, the variance of vote requirements, and other distribution moments. Our findings demonstrate how the threshold $\delta$ can be adjusted to achieve quality equivalence across voting processes that employ workers with varying accuracy levels. We also provide efficiency-equalizing payment rates for voting proces
    
[^120]: 推荐系统的深度探索

    Deep Exploration for Recommendation Systems. (arXiv:2109.12509v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2109.12509](http://arxiv.org/abs/2109.12509)

    本文提出了一种深度探索方法以解决推荐系统中奖励稀少时的问题，并在高保真度的工业级模拟器下进行了实验，证明了该算法相比现有算法有很大的提升。

    

    现代推荐系统应从延迟反馈中探索和学习。过去的研究往往侧重于从用户对单个推荐的响应中学习。这些工作利用了监督学习和强化学习的方法，但放弃了学习用户之后的行为。在过去的工作中，虽然致力于从随后的行为中学习，但缺乏有效的方法来引导并获取有意义的延迟反馈。当奖励较少时，通过引导探索有意义的延迟反馈变得特别具有挑战性。为了解决这个问题，我们为推荐系统开发了深度探索方法。具体而言，我们将推荐系统形式化为一个序列决策问题，并证明了深度探索方法在单步探索方面的优势。我们的实验是在高保真度的工业级模拟器下进行的，并且证明了该算法相比现有算法有很大的提升。

    Modern recommendation systems ought to benefit by probing for and learning from delayed feedback. Research has tended to focus on learning from a user's response to a single recommendation. Such work, which leverages methods of supervised and bandit learning, forgoes learning from the user's subsequent behavior. Where past work has aimed to learn from subsequent behavior, there has been a lack of effective methods for probing to elicit informative delayed feedback. Effective exploration through probing for delayed feedback becomes particularly challenging when rewards are sparse. To address this, we develop deep exploration methods for recommendation systems. In particular, we formulate recommendation as a sequential decision problem and demonstrate benefits of deep exploration over single-step exploration. Our experiments are carried out with high-fidelity industrial-grade simulators and establish large improvements over existing algorithms.
    
[^121]: 作为新兴硬件计算框架的向量符号体系结构

    Vector Symbolic Architectures as a Computing Framework for Emerging Hardware. (arXiv:2106.05268v2 [cs.AR] UPDATED)

    [http://arxiv.org/abs/2106.05268](http://arxiv.org/abs/2106.05268)

    向量符号体系结构（VSA）是一种新兴的计算框架，适用于在新硬件上实现，并能有效支持复杂问题的解决。其特色特点是领域模型的代数结构和叠加计算，使其在人工智能领域具有广泛应用潜力。

    

    本文回顾了近期向量符号体系结构（VSA）（也称为高维计算）的发展进展。这种框架非常适合在随机的、新兴的硬件上实现，并自然地表达了人工智能（AI）所需的认知操作类型。我们在本文中展示了VSA具有领域模型的代数结构，提供了能够支持现代计算的所有数据结构和操作的简单而强大的高维向量操作。此外，我们还展示了VSA的特色特点“叠加计算”，它使其区别于传统计算，并为AI应用中的困难组合搜索问题提供了高效解决方案。我们描述了展示VSA具有计算普适性的方法。我们认为它们可以作为分布式表示计算的框架，可以提供解决复杂问题的有效解决方案。

    This article reviews recent progress in the development of the computing framework vector symbolic architectures (VSA) (also known as hyperdimensional computing). This framework is well suited for implementation in stochastic, emerging hardware, and it naturally expresses the types of cognitive operations required for artificial intelligence (AI). We demonstrate in this article that the field-like algebraic structure of VSA offers simple but powerful operations on high-dimensional vectors that can support all data structures and manipulations relevant to modern computing. In addition, we illustrate the distinguishing feature of VSA, "computing in superposition," which sets it apart from conventional computing. It also opens the door to efficient solutions to the difficult combinatorial search problems inherent in AI applications. We sketch ways of demonstrating that VSA are computationally universal. We see them acting as a framework for computing with distributed representations that 
    
[^122]: 具有显式知识引导的语义对抗情景生成

    Semantically Adversarial Scenario Generation with Explicit Knowledge Guidance. (arXiv:2106.04066v6 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2106.04066](http://arxiv.org/abs/2106.04066)

    本文提出了一种具有显式知识引导的方法，通过在生成过程中融入领域知识，实现了对抗情景的生成。通过树状变分自动编码器和语义规则的应用，可以实现对驾驶场景的精确控制。

    

    生成具有潜在使自动驾驶系统失效的对抗情景是提高鲁棒性的有效方法。最近的专用模型扩展了纯数据驱动的生成模型，满足了额外的可控要求，例如通过在神经元级别隐式操作来嵌入交通标志在驾驶场景中。在本文中，我们引入一种方法，在生成过程中显式地融入领域知识，实现语义对抗生成（SAG）。为了与驾驶场景的组成保持一致，我们首先将知识分为两类，即对象的属性和对象之间的关系。然后，我们提出了一种树状变分自动编码器（T-VAE）来学习层次化场景表示。通过对树结构中的节点和边的属性施加语义规则，显式知识融合实现了可控的生成。我们构建了一个合成示例来验证该方法的有效性。

    Generating adversarial scenarios, which have the potential to fail autonomous driving systems, provides an effective way to improve robustness. Extending purely data-driven generative models, recent specialized models satisfy additional controllable requirements such as embedding a traffic sign in a driving scene by manipulating patterns implicitly in the neuron level. In this paper, we introduce a method to incorporate domain knowledge explicitly in the generation process to achieve the Semantically Adversarial Generation (SAG). To be consistent with the composition of driving scenes, we first categorize the knowledge into two types, the property of objects and the relationship among objects. We then propose a tree-structured variational auto-encoder (T-VAE) to learn hierarchical scene representation. By imposing semantic rules on the properties of nodes and edges in the tree structure, explicit knowledge integration enables controllable generation. We construct a synthetic example to
    
[^123]: 感知器理论可以预测神经网络的准确性

    Perceptron Theory Can Predict the Accuracy of Neural Networks. (arXiv:2012.07881v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2012.07881](http://arxiv.org/abs/2012.07881)

    感知器理论可以通过统计方法准确预测不同结构的神经网络的性能。

    

    多层神经网络在许多技术分类问题上取得了当前的最新成果。然而，从分析和预测性能角度来看，这些网络仍然是黑箱。在这里，我们开发了一个针对单层感知器的统计理论，并展示它可以预测多种不同结构的神经网络的性能。通过推广用于分析储备计算模型和符号推理的连接主义模型的向量符号体系结构的现有理论，我们发展了感知器分类的一般理论。我们的统计理论提供了三个公式，通过逐步增加详细信息来利用信号统计。这些公式在解析上是难以处理的，但可以通过数值评估。捕捉最详细信息的描述级别需要随机抽样方法。根据网络模型的不同，较简单的公式已经能够提供高度准确的预测。

    Multilayer neural networks set the current state of the art for many technical classification problems. But, these networks are still, essentially, black boxes in terms of analyzing them and predicting their performance. Here, we develop a statistical theory for the one-layer perceptron and show that it can predict performances of a surprisingly large variety of neural networks with different architectures. A general theory of classification with perceptrons is developed by generalizing an existing theory for analyzing reservoir computing models and connectionist models for symbolic reasoning known as vector symbolic architectures. Our statistical theory offers three formulas leveraging the signal statistics with increasing detail. The formulas are analytically intractable, but can be evaluated numerically. The description level that captures maximum details requires stochastic sampling methods. Depending on the network model, the simpler formulas already yield high prediction accuracy
    

