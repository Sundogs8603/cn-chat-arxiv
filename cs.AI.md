# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Push it to the Demonstrated Limit: Multimodal Visuotactile Imitation Learning with Force Matching.](http://arxiv.org/abs/2311.01248) | 本研究利用视觉触觉传感器和模仿学习相结合，通过配对优化触觉力量曲线和简化传感器应用，对接触丰富的操作任务进行了研究。 |
| [^2] | [Multi-view Relation Learning for Cross-domain Few-shot Hyperspectral Image Classification.](http://arxiv.org/abs/2311.01212) | 本文提出了一种在跨领域少样本高光谱图像分类中学习样本关系的方法，通过从不同视角对样本进行学习，并利用对抗性学习来改进分类性能。 |
| [^3] | [DeTiME: Diffusion-Enhanced Topic Modeling using Encoder-decoder based LLM.](http://arxiv.org/abs/2310.15296) | DeTiME是一种使用基于编码-解码的LLMs增强扩散的主题建模方法，能够产生高度聚类的嵌入和具有增强语义一致性的主题，并能生成与主题相关的内容。 |
| [^4] | [Improving Generalization of Alignment with Human Preferences through Group Invariant Learning.](http://arxiv.org/abs/2310.11971) | 该论文提出了一种通过强化学习实现在不同数据组或领域中学习一致策略的方法，该方法可以提高AI助手对不同领域的泛化能力，并更好地与人类偏好对齐。 |
| [^5] | [Can We Edit Multimodal Large Language Models?.](http://arxiv.org/abs/2310.08475) | 本文提出了编辑多模式大型语言模型（MLLMs）的挑战，并构建了一个新的基准用于评估和比较不同编辑方法的效果。实验结果表明，编辑多模式LLMs仍然存在困难，但这项工作为NLP社区提供了宝贵的见解。 |
| [^6] | [Co-NavGPT: Multi-Robot Cooperative Visual Semantic Navigation using Large Language Models.](http://arxiv.org/abs/2310.07937) | Co-NavGPT是一个创新的框架，使用大型语言模型作为全局规划器，实现多机器人合作的视觉目标导航。在实验中表现出了超越现有模型的成功率和效率，展示了大型语言模型的巨大潜力。 |
| [^7] | [Iterative Option Discovery for Planning, by Planning.](http://arxiv.org/abs/2310.01569) | 本文提出了一种迭代式选项发现方法，通过学习一组局部强策略来指导搜索算法，从而在强化学习和规划中应用于复杂领域。 |
| [^8] | [Natural Language based Context Modeling and Reasoning with LLMs: A Tutorial.](http://arxiv.org/abs/2309.15074) | 本教程介绍了基于大型语言模型的自然语言上下文建模和推理，通过与LLMs交互，使用自然语言进行上下文建模和推理。 |
| [^9] | [Recurrent Hypernetworks are Surprisingly Strong in Meta-RL.](http://arxiv.org/abs/2309.14970) | 递归超网络和循环神经网络在元强化学习中的端到端学习表现出惊人的强大性能，相比于现有专门方法更为简单但效果更好。 |
| [^10] | [Beta Diffusion.](http://arxiv.org/abs/2309.07867) | beta扩散是一种新型生成模型方法，通过引入去掩盖和去噪的技术，利用缩放和偏移的beta分布进行乘法转换，实现在有界范围内生成数据。相比于传统的基于扩散的生成模型，它通过KL散度上界进行优化，证明了效果更好。 |
| [^11] | [Knowledge Graph Prompting for Multi-Document Question Answering.](http://arxiv.org/abs/2308.11730) | 这篇论文提出了一种知识图谱引导的方法，用于在多文档问答任务中为大型语言模型（LLMs）提示正确的上下文。通过构建多个文档上的知识图谱，并设计基于语言模型的图遍历器，该方法能够帮助LLMs在MD-QA中进行答案预测。 |
| [^12] | [Artificial intelligence is ineffective and potentially harmful for fact checking.](http://arxiv.org/abs/2308.10800) | 这项研究发现人工智能语言模型在事实核查中表现出色，但在帮助用户判断标题准确性和分享准确新闻方面影响不大。然而，在某些情况下，它会误导用户对真实标题的信仰，并增加对未确定虚假标题的信仰。 |
| [^13] | [SwinLSTM:Improving Spatiotemporal Prediction Accuracy using Swin Transformer and LSTM.](http://arxiv.org/abs/2308.09891) | SwinLSTM是一种将Swin Transformer和LSTM结合起来以提高时空预测准确性的新循环单元，在四个数据集上表现出优越的性能，特别是在预测准确性方面有显著提高。 |
| [^14] | [Leveraging Symmetries in Pick and Place.](http://arxiv.org/abs/2308.07948) | 该论文研究了物品搬运任务中的对称性，提出了一种称为等变Transporter Net的模型，利用等变神经模型捕捉了所有对称性，能够在不同的搬运位置推广搬运知识。 |
| [^15] | [VisIT-Bench: A Benchmark for Vision-Language Instruction Following Inspired by Real-World Use.](http://arxiv.org/abs/2308.06595) | VisIT-Bench是一个用于评价真实世界中视觉语言模型指示遵循的基准，包含了各种任务并提供了详细描述，可以自动评估多模态生成的质量差距。 |
| [^16] | [EnrichEvent: Enriching Social Data with Contextual Information for Emerging Event Extraction.](http://arxiv.org/abs/2307.16082) | 本文提出了一个利用词汇、语义和上下文表示的框架，旨在解决现有事件检测方法在识别新兴社交事件方面的局限性，并提供了对社交数据进行丰富的上下文化处理的方法。 |
| [^17] | [Towards Automatic Boundary Detection for Human-AI Collaborative Hybrid Essay in Education.](http://arxiv.org/abs/2307.12267) | 本研究探索了在教育领域中，由人类和生成性语言模型协作编写的混合文本的AI内容检测方法，将其形式化为识别转换点的任务，以区分人类编写和AI生成的部分。 |
| [^18] | [Exploring Large Language Model for Graph Data Understanding in Online Job Recommendations.](http://arxiv.org/abs/2307.05722) | 本论文探索了大规模语言模型在在线职位推荐中对图数据的理解能力，并提出了新的框架来分析行为图，发现其中的潜在模式和关系。 |
| [^19] | [Learned Kernels for Interpretable and Efficient PPG Signal Quality Assessment and Artifact Segmentation.](http://arxiv.org/abs/2307.05385) | 本文提出了一种通过学习核技术，具有解释性且参数较少的方法来评估和分割PPG信号的质量和伪影，与现有的深度神经网络方法相比有着类似甚至更好的性能。 |
| [^20] | [TransformerG2G: Adaptive time-stepping for learning temporal graph embeddings using transformers.](http://arxiv.org/abs/2307.02588) | TransformerG2G是一种使用Transformer进行自适应时间步长的图嵌入模型，通过学习历史上的长程依赖关系，准确地捕捉时态图的动态特征。 |
| [^21] | [About the Cost of Central Privacy in Density Estimation.](http://arxiv.org/abs/2306.14535) | 本研究对于利普希茨和 Sobolev 空间中的非参数密度估计，通过考虑中心隐私的影响，发现了直方图估计器在 L2 风险下对于利普希茨分布是最优的，并且在正常差分隐私情况下也是如此；同时发现，在一些情况下，施加隐私会降低对于 Sobolev 密度的正则极小风险估计。此外，本研究还发现在纯投影估计设定下，所谓的投影估计器对于相同类密度几乎是最优的。 |
| [^22] | [Judging LLM-as-a-judge with MT-Bench and Chatbot Arena.](http://arxiv.org/abs/2306.05685) | 研究使用强大的LLM作为评判员，通过引入两个基准测试来确认LLM评判员和人类偏好之间的一致性，并可调整聊天助手的模型架构和微调方法来提高其性能。 |
| [^23] | [Tuning Models of Code with Compiler-Generated Reinforcement Learning Feedback.](http://arxiv.org/abs/2305.18341) | 本文提出了一种叫做RLCF的方法，使用代码编译器反馈进一步训练预训练的大型语言模型，以生成符合目标分布的代码，并通过所有静态正确性检查，显著提高了性能。 |
| [^24] | [Lift Yourself Up: Retrieval-augmented Text Generation with Self Memory.](http://arxiv.org/abs/2305.02437) | 本文提出了一种新的检索增强文本生成模型Selfmem，通过迭代生成自我记忆池并采用记忆选择器，使检索更加自适应，提高了文本生成的质量和多样性。 |
| [^25] | [Mixed-Integer Optimal Control via Reinforcement Learning: A Case Study on Hybrid Vehicle Energy Management.](http://arxiv.org/abs/2305.01461) | 本研究提出了一种新的混合整数最优控制问题的强化学习算法，可同时处理连续和离散控制变量， 并在混合动力车辆能源管理问题上优于现有方法和强化学习算法。 |
| [^26] | [Sampling-based Reactive Synthesis for Nondeterministic Hybrid Systems.](http://arxiv.org/abs/2304.06876) | 本文提出了一种基于采样的策略综合算法，用于具有复杂连续动力学和时间和可达性约束的非确定性混合系统。算法基于在混合空间中生长（搜索）游戏树，以合成一种反应（鲁棒）策略，以满足目标并在可扩展性和效率方面优于最新技术水平。 |
| [^27] | [Structured prompt interrogation and recursive extraction of semantics (SPIRES): A method for populating knowledge bases using zero-shot learning.](http://arxiv.org/abs/2304.02711) | SPIRES是一种新的知识提取方法，利用大型语言模型进行零样本学习和通用查询回答，能够填充复杂的知识库而无需显式训练数据。 |
| [^28] | [Polytuplet Loss: A Reverse Approach to Training Reading Comprehension and Logical Reasoning Models.](http://arxiv.org/abs/2304.01046) | 本文研究了一种训练阅读理解和逻辑推理模型的反向方法，利用相对准确性的策略来训练模型，通过Polytuplet Loss函数来确保优先学习答案选择的相对正确性，获得了不错的成果，提出了具有一般性的训练方法和模型架构。 |
| [^29] | [CRN: Camera Radar Net for Accurate, Robust, Efficient 3D Perception.](http://arxiv.org/abs/2304.00670) | 本文提出了CRN，一个新颖的相机雷达融合框架，通过将图像视图特征转换为鸟瞰特征图和使用多模态可变形注意力，实现了准确、稳健、高效的3D感知任务 |
| [^30] | [Learning with Explanation Constraints.](http://arxiv.org/abs/2303.14496) | 本文研究了解释约束下的学习问题，提出了EPAC模型，探讨了使用这些解释时模型的益处，并提供了一种基于变分近似的算法解决方案。 |
| [^31] | [DualStreamFoveaNet: A Dual Stream Fusion Architecture with Anatomical Awareness for Robust Fovea Localization.](http://arxiv.org/abs/2302.06961) | DualStreamFoveaNet是一种具有解剖意识的双流融合架构，通过利用视网膜和血管分布进行多线索融合，实现对鲁棒的中央凹点定位。实验证明该架构在中央凹点定位方面达到了最先进的性能。 |
| [^32] | [DynGFN: Towards Bayesian Inference of Gene Regulatory Networks with GFlowNets.](http://arxiv.org/abs/2302.04178) | DynGFN是一种借助RNA速度技术进行基因调控网络推断的方法，能够捕捉网络结构的不确定性，并在准确度上超过现有方法。 |
| [^33] | [EHRSQL: A Practical Text-to-SQL Benchmark for Electronic Health Records.](http://arxiv.org/abs/2301.07695) | 该论文提出了一个面向电子病历数据的文本转SQL数据集，该数据集具有一系列独特挑战，包括生成SQL查询、理解时间表达式以及区分有无答案的问题。 |
| [^34] | [A Survey on Generative Diffusion Model.](http://arxiv.org/abs/2209.02646) | 本综述总结了生成扩散模型的先进技术，包括采样加速、新的扩散过程设计以及在不同空间中实现扩散模型的策略。这些创新努力旨在提高扩散模型的功能和效率。 |
| [^35] | [On-Device Learning: A Neural Network Based Field-Trainable Edge AI.](http://arxiv.org/abs/2203.01077) | 本研究介绍了一种基于神经网络的设备上学习方法，针对边缘人工智能应用中的环境因素对准确性造成的影响进行了解决。通过重新训练，在嘈杂环境下显著提高了异常检测的准确性，同时节约了低功耗设备的计算和通信成本。 |
| [^36] | [A Longitudinal Multi-modal Dataset for Dementia Monitoring and Diagnosis.](http://arxiv.org/abs/2109.01537) | 该论文提出了一个纵向多模态数据集，用于痴呆监测和诊断。通过分析语言、言语和语用指标，可以区分神经退行性疾病患者和对照组，从而为痴呆研究提供了宝贵的资源。 |

# 详细

[^1]: 将其推向展示极限：多模态视觉触觉模仿学习与力匹配

    Push it to the Demonstrated Limit: Multimodal Visuotactile Imitation Learning with Force Matching. (arXiv:2311.01248v1 [cs.RO])

    [http://arxiv.org/abs/2311.01248](http://arxiv.org/abs/2311.01248)

    本研究利用视觉触觉传感器和模仿学习相结合，通过配对优化触觉力量曲线和简化传感器应用，对接触丰富的操作任务进行了研究。

    

    光学触觉传感器已经成为机器人操作过程中获取密集接触信息的有效手段。最近引入的“透视你的皮肤”（STS）型传感器具有视觉和触觉模式，通过利用半透明表面和可控照明实现。本文研究了视觉触觉传感与模仿学习在富有接触的操作任务中的好处。首先，我们使用触觉力测量和一种新的算法，在运动示范中产生更好匹配人体示范者的力曲线。其次，我们添加了视觉/触觉STS模式切换作为控制策略输出，简化传感器的应用。最后，我们研究了多种观察配置，比较和对比了视觉/触觉数据（包括模式切换和不切换）与手腕挂载的眼在手摄像机的视觉数据的价值。我们在一个广泛的实验系列上进行实验。

    Optical tactile sensors have emerged as an effective means to acquire dense contact information during robotic manipulation. A recently-introduced `see-through-your-skin' (STS) variant of this type of sensor has both visual and tactile modes, enabled by leveraging a semi-transparent surface and controllable lighting. In this work, we investigate the benefits of pairing visuotactile sensing with imitation learning for contact-rich manipulation tasks. First, we use tactile force measurements and a novel algorithm during kinesthetic teaching to yield a force profile that better matches that of the human demonstrator. Second, we add visual/tactile STS mode switching as a control policy output, simplifying the application of the sensor. Finally, we study multiple observation configurations to compare and contrast the value of visual/tactile data (both with and without mode switching) with visual data from a wrist-mounted eye-in-hand camera. We perform an extensive series of experiments on a
    
[^2]: 多视角关系学习用于跨领域少样本高光谱图像分类

    Multi-view Relation Learning for Cross-domain Few-shot Hyperspectral Image Classification. (arXiv:2311.01212v1 [cs.CV])

    [http://arxiv.org/abs/2311.01212](http://arxiv.org/abs/2311.01212)

    本文提出了一种在跨领域少样本高光谱图像分类中学习样本关系的方法，通过从不同视角对样本进行学习，并利用对抗性学习来改进分类性能。

    

    跨领域少样本高光谱图像分类侧重于从源领域中大量标记样本中学习先前的知识，然后将这些知识转移到目标领域中仅包含少量标记样本的任务中。在度量方法的基础上，许多当前的方法首先提取查询样本和支持样本的特征，然后根据查询样本到支持样本或原型的距离直接预测查询样本的类别。样本之间的关系尚未得到充分的探索和利用。与当前的方法不同，本文提出了从不同视角学习样本关系并将其纳入模型学习过程中，以提高跨领域少样本高光谱图像分类的性能。在当前DCFSL方法的基础上，该方法采用对抗性学习来学习类别级别的样本关系。

    Cross-domain few-shot hyperspectral image classification focuses on learning prior knowledge from a large number of labeled samples from source domain and then transferring the knowledge to the tasks which contain only few labeled samples in target domains. Following the metric-based manner, many current methods first extract the features of the query and support samples, and then directly predict the classes of query samples according to their distance to the support samples or prototypes. The relations between samples have not been fully explored and utilized. Different from current works, this paper proposes to learn sample relations from different views and take them into the model learning process, to improve the cross-domain few-shot hyperspectral image classification. Building on current DCFSL method which adopts a domain discriminator to deal with domain-level distribution difference, the proposed method applys contrastive learning to learn the class-level sample relations to o
    
[^3]: DeTiME: 使用基于编码-解码的LLM增强扩散的主题建模方法

    DeTiME: Diffusion-Enhanced Topic Modeling using Encoder-decoder based LLM. (arXiv:2310.15296v1 [cs.CL])

    [http://arxiv.org/abs/2310.15296](http://arxiv.org/abs/2310.15296)

    DeTiME是一种使用基于编码-解码的LLMs增强扩散的主题建模方法，能够产生高度聚类的嵌入和具有增强语义一致性的主题，并能生成与主题相关的内容。

    

    在充满活力的自然语言处理领域，神经主题模型（NTMs）和大型语言模型（LLMs）已成为重要的研究领域。尽管如此，NTMs主要使用来自LLMs的上下文嵌入，这对于聚类或主题生成来说并不是最佳选择。我们的研究通过引入名为DeTiME的新框架来解决这一问题。DeTiME利用编码-解码的LLMs产生高度可聚类的嵌入，与现有方法相比，能够生成既具有优越的聚类性又具有增强的语义一致性的主题。此外，通过利用扩散的能力，我们的框架还提供了生成与已识别主题相关内容的能力。这种双重功能使用户能够同时高效产生高度聚类的主题和相关内容。DeTiME的潜力还包括生成集群化的嵌入。

    In the burgeoning field of natural language processing, Neural Topic Models (NTMs) and Large Language Models (LLMs) have emerged as areas of significant research interest. Despite this, NTMs primarily utilize contextual embeddings from LLMs, which are not optimal for clustering or capable for topic generation. Our study addresses this gap by introducing a novel framework named Diffusion-Enhanced Topic Modeling using Encoder-Decoder-based LLMs (DeTiME). DeTiME leverages ncoder-Decoder-based LLMs to produce highly clusterable embeddings that could generate topics that exhibit both superior clusterability and enhanced semantic coherence compared to existing methods. Additionally, by exploiting the power of diffusion, our framework also provides the capability to generate content relevant to the identified topics. This dual functionality allows users to efficiently produce highly clustered topics and related content simultaneously. DeTiME's potential extends to generating clustered embeddi
    
[^4]: 通过群体不变性学习提高与人类偏好的对齐的泛化能力

    Improving Generalization of Alignment with Human Preferences through Group Invariant Learning. (arXiv:2310.11971v1 [cs.LG])

    [http://arxiv.org/abs/2310.11971](http://arxiv.org/abs/2310.11971)

    该论文提出了一种通过强化学习实现在不同数据组或领域中学习一致策略的方法，该方法可以提高AI助手对不同领域的泛化能力，并更好地与人类偏好对齐。

    

    基于语言模型(LLMs)的AI助手的成功在于强化学习从人类反馈中, 使生成的回答更加与人类偏好一致. 作为通用AI助手, 人们越来越期望它们在不同领域中表现一致. 然而, 先前的工作表明,强化学习(RL)经常利用捷径以获得较高的奖励, 忽略了具有挑战性的样本. 这种对快速奖励收益的关注不仅削弱了训练的稳定性, 也削弱了模型对新的未见数据的泛化能力. 在这项工作中, 我们提出了一种新颖的方法, 可以通过RL在不同数据组或领域中学习一致的策略. 鉴于获得群体标注的挑战, 我们的方法会自动将数据分类到不同的组中, 有意地最大化性能差异. 然后, 我们优化策略以在具有挑战性的组中表现良好. 最后, 利用已建立的

    The success of AI assistants based on language models (LLMs) hinges crucially on Reinforcement Learning from Human Feedback (RLHF), which enables the generation of responses more aligned with human preferences. As universal AI assistants, there's a growing expectation for them to perform consistently across various domains. However, previous work shows that Reinforcement Learning (RL) often exploits shortcuts to attain high rewards and overlooks challenging samples. This focus on quick reward gains undermines both the stability in training and the model's ability to generalize to new, unseen data. In this work, we propose a novel approach that can learn a consistent policy via RL across various data groups or domains. Given the challenges associated with acquiring group annotations, our method automatically classifies data into different groups, deliberately maximizing performance variance. Then, we optimize the policy to perform well on challenging groups. Lastly, leveraging the estab
    
[^5]: 我们能编辑多模式大型语言模型吗？

    Can We Edit Multimodal Large Language Models?. (arXiv:2310.08475v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.08475](http://arxiv.org/abs/2310.08475)

    本文提出了编辑多模式大型语言模型（MLLMs）的挑战，并构建了一个新的基准用于评估和比较不同编辑方法的效果。实验结果表明，编辑多模式LLMs仍然存在困难，但这项工作为NLP社区提供了宝贵的见解。

    

    本文关注编辑多模式大型语言模型（MLLMs）。与编辑单模式LLMs相比，多模式模型的编辑更具挑战性，需要更高级别的审查和慎重考虑。为了促进这一领域的研究，我们构建了一个新的基准，称为MMEdit，用于编辑多模式LLMs，并建立了一套创新的度量标准进行评估。我们进行了包括各种模型编辑基线的综合实验，并分析了编辑多模式LLMs的不同组件的影响。根据经验，我们发现之前的基线在某种程度上可以实现编辑多模式LLMs，但效果仍然不理想，表明这个任务可能存在的困难。我们希望我们的工作能为NLP社区提供见解。代码和数据集可在https://github.com/zjunlp/EasyEdit获取。

    In this paper, we focus on editing Multimodal Large Language Models (MLLMs). Compared to editing single-modal LLMs, multimodal model editing is more challenging, which demands a higher level of scrutiny and careful consideration in the editing process. To facilitate research in this area, we construct a new benchmark, dubbed MMEdit, for editing multimodal LLMs and establishing a suite of innovative metrics for evaluation. We conduct comprehensive experiments involving various model editing baselines and analyze the impact of editing different components for multimodal LLMs. Empirically, we notice that previous baselines can implement editing multimodal LLMs to some extent, but the effect is still barely satisfactory, indicating the potential difficulty of this task. We hope that our work can provide the NLP community with insights. Code and dataset are available in https://github.com/zjunlp/EasyEdit.
    
[^6]: Co-NavGPT: 使用大型语言模型的多机器人合作视觉语义导航

    Co-NavGPT: Multi-Robot Cooperative Visual Semantic Navigation using Large Language Models. (arXiv:2310.07937v1 [cs.RO])

    [http://arxiv.org/abs/2310.07937](http://arxiv.org/abs/2310.07937)

    Co-NavGPT是一个创新的框架，使用大型语言模型作为全局规划器，实现多机器人合作的视觉目标导航。在实验中表现出了超越现有模型的成功率和效率，展示了大型语言模型的巨大潜力。

    

    在高级人机交互任务中，对于自主机器人在未知环境中进行视觉目标导航至关重要。尽管过去已经开发了许多方法，但大多数都是设计用于单一机器人操作，这往往由于环境复杂性而导致效率和鲁棒性降低。此外，学习多机器人协作的策略需要资源密集型。为了解决这些挑战，我们提出了Co-NavGPT，这是一个创新的框架，将大型语言模型(LLMs)作为多机器人合作视觉目标导航的全局规划器。Co-NavGPT将探索的环境数据编码为提示，增强LLMs对场景的理解。然后，它为每个机器人分配探索前沿以实现高效的目标搜索。在Habitat-Matterport 3D (HM3D)上的实验结果表明，Co-NavGPT在成功率和效率方面超过了现有模型，而无需任何学习过程，展示了LLMs的巨大潜力。

    In advanced human-robot interaction tasks, visual target navigation is crucial for autonomous robots navigating unknown environments. While numerous approaches have been developed in the past, most are designed for single-robot operations, which often suffer from reduced efficiency and robustness due to environmental complexities. Furthermore, learning policies for multi-robot collaboration are resource-intensive. To address these challenges, we propose Co-NavGPT, an innovative framework that integrates Large Language Models (LLMs) as a global planner for multi-robot cooperative visual target navigation. Co-NavGPT encodes the explored environment data into prompts, enhancing LLMs' scene comprehension. It then assigns exploration frontiers to each robot for efficient target search. Experimental results on Habitat-Matterport 3D (HM3D) demonstrate that Co-NavGPT surpasses existing models in success rates and efficiency without any learning process, demonstrating the vast potential of LLMs
    
[^7]: 迭代式规划中的选项发现

    Iterative Option Discovery for Planning, by Planning. (arXiv:2310.01569v1 [cs.AI])

    [http://arxiv.org/abs/2310.01569](http://arxiv.org/abs/2310.01569)

    本文提出了一种迭代式选项发现方法，通过学习一组局部强策略来指导搜索算法，从而在强化学习和规划中应用于复杂领域。

    

    发现有用的时间抽象，也就是选项，被广泛认为是将强化学习和规划应用于日益复杂的领域的关键。在AlphaZero中使用的Expert Iteration策略学习方法的经验成功基础上，提出了Option Iteration，一种类似的选项发现方法。Option Iteration不是学习一个单一的强策略，而是学习一组选项策略，对于遇到的每个状态，至少有一种策略在某个未来的时间点与搜索结果吻合。直观地说，这可能更容易，因为它允许算法根据情况灵活调整，而不是学习一个在当前状态的细节上具有复杂依赖性的全局策略。通过学习这样一组局部强策略，我们可以使用它们来指导搜索算法，从而形成良性循环，获得更好的结果。

    Discovering useful temporal abstractions, in the form of options, is widely thought to be key to applying reinforcement learning and planning to increasingly complex domains. Building on the empirical success of the Expert Iteration approach to policy learning used in AlphaZero, we propose Option Iteration, an analogous approach to option discovery. Rather than learning a single strong policy that is trained to match the search results everywhere, Option Iteration learns a set of option policies trained such that for each state encountered, at least one policy in the set matches the search results for some horizon into the future. Intuitively, this may be significantly easier as it allows the algorithm to hedge its bets compared to learning a single globally strong policy, which may have complex dependencies on the details of the current state. Having learned such a set of locally strong policies, we can use them to guide the search algorithm resulting in a virtuous cycle where better 
    
[^8]: 基于大型语言模型（LLMs）的自然语言上下文建模与推理：教程

    Natural Language based Context Modeling and Reasoning with LLMs: A Tutorial. (arXiv:2309.15074v1 [cs.CL])

    [http://arxiv.org/abs/2309.15074](http://arxiv.org/abs/2309.15074)

    本教程介绍了基于大型语言模型的自然语言上下文建模和推理，通过与LLMs交互，使用自然语言进行上下文建模和推理。

    

    大型语言模型（LLMs）自2018年以来急剧增长，自引入上下文感知计算系统20年后。上下文感知计算通过考虑普适设备、用户和社会的情况，实现了广泛的创新应用，如辅助生活、基于位置的社交网络服务等。为了识别上下文并相应地做出决策，采用了各种人工智能技术（如本体论和OWL）作为上下文建模和推理的表示方法。最近，随着LLMs的崛起和它们改进的自然语言理解和推理能力，使用自然语言建模上下文并通过与ChatGPT和GPT-4等LLMs交互进行上下文推理变得可行。在本教程中，我们演示了使用文本、提示和自主代理（AutoAgents）使LLMs能够执行上下文建模的方法。

    Large language models (LLMs) have become phenomenally surging, since 2018--two decades after introducing context-awareness into computing systems. Through taking into account the situations of ubiquitous devices, users and the societies, context-aware computing has enabled a wide spectrum of innovative applications, such as assisted living, location-based social network services and so on. To recognize contexts and make decisions for actions accordingly, various artificial intelligence technologies, such as Ontology and OWL, have been adopted as representations for context modeling and reasoning. Recently, with the rise of LLMs and their improved natural language understanding and reasoning capabilities, it has become feasible to model contexts using natural language and perform context reasoning by interacting with LLMs such as ChatGPT and GPT-4. In this tutorial, we demonstrate the use of texts, prompts, and autonomous agents (AutoAgents) that enable LLMs to perform context modeling 
    
[^9]: 递归超网络在元强化学习中表现出惊人的强大性能

    Recurrent Hypernetworks are Surprisingly Strong in Meta-RL. (arXiv:2309.14970v1 [cs.LG])

    [http://arxiv.org/abs/2309.14970](http://arxiv.org/abs/2309.14970)

    递归超网络和循环神经网络在元强化学习中的端到端学习表现出惊人的强大性能，相比于现有专门方法更为简单但效果更好。

    

    深度强化学习在实际应用时因样本效率低而不易部署。元强化学习通过学习在元训练时利用相关任务的分布来实现少样本学习，直接解决了这个样本效率问题。最近的研究表明，与专门的元强化学习方法相比，与一个通用的序列模型（如循环神经网络）结合的端到端学习是一个令人惊讶的强基准。然而，这样的观点由于有限的支持证据而引起了争议，特别是在之前的研究中确立了完全相反的观点。在本文中，我们进行了实证研究。虽然我们同样发现循环网络可以达到强大的性能，但我们证明了超网络的使用对于发挥循环基线的潜力至关重要。令人惊讶的是，与超网络相结合时，这种远比现有专门方法简单的循环基准实际上能取得更好的表现。

    Deep reinforcement learning (RL) is notoriously impractical to deploy due to sample inefficiency. Meta-RL directly addresses this sample inefficiency by learning to perform few-shot learning when a distribution of related tasks is available for meta-training. While many specialized meta-RL methods have been proposed, recent work suggests that end-to-end learning in conjunction with an off-the-shelf sequential model, such as a recurrent network, is a surprisingly strong baseline. However, such claims have been controversial due to limited supporting evidence, particularly in the face of prior work establishing precisely the opposite. In this paper, we conduct an empirical investigation. While we likewise find that a recurrent network can achieve strong performance, we demonstrate that the use of hypernetworks is crucial to maximizing their potential. Surprisingly, when combined with hypernetworks, the recurrent baselines that are far simpler than existing specialized methods actually ac
    
[^10]: Beta Diffusion. (arXiv:2309.07867v1 [cs.LG])

    Beta Diffusion. (arXiv:2309.07867v1 [cs.LG])

    [http://arxiv.org/abs/2309.07867](http://arxiv.org/abs/2309.07867)

    beta扩散是一种新型生成模型方法，通过引入去掩盖和去噪的技术，利用缩放和偏移的beta分布进行乘法转换，实现在有界范围内生成数据。相比于传统的基于扩散的生成模型，它通过KL散度上界进行优化，证明了效果更好。

    

    我们引入了beta扩散，一种将去掩盖和去噪集成到一起的新型生成建模方法，用于在有界范围内生成数据。使用了缩放和偏移的beta分布，beta扩散利用了随时间的乘法转换来创建正向和反向的扩散过程，同时维持着正向边缘分布和反向条件分布，给定任意时间点的数据。与传统的基于扩散的生成模型不同，传统模型依赖于加性高斯噪声和重新加权的证据下界（ELBO），beta扩散是乘法的，并且通过从KL散度的凸性推导出来的KL散度上界（KLUB）进行优化。我们证明了所提出的KLUB相对于负ELBO来说对于优化beta扩散更加有效，负ELBO也可以作为相同KL散度的KLUB，只是其两个参数交换了位置。beta扩散的损失函数以Bregman散度为指标来表示。

    We introduce beta diffusion, a novel generative modeling method that integrates demasking and denoising to generate data within bounded ranges. Using scaled and shifted beta distributions, beta diffusion utilizes multiplicative transitions over time to create both forward and reverse diffusion processes, maintaining beta distributions in both the forward marginals and the reverse conditionals, given the data at any point in time. Unlike traditional diffusion-based generative models relying on additive Gaussian noise and reweighted evidence lower bounds (ELBOs), beta diffusion is multiplicative and optimized with KL-divergence upper bounds (KLUBs) derived from the convexity of the KL divergence. We demonstrate that the proposed KLUBs are more effective for optimizing beta diffusion compared to negative ELBOs, which can also be derived as the KLUBs of the same KL divergence with its two arguments swapped. The loss function of beta diffusion, expressed in terms of Bregman divergence, furt
    
[^11]: 多文档问答中的知识图谱引导

    Knowledge Graph Prompting for Multi-Document Question Answering. (arXiv:2308.11730v1 [cs.CL])

    [http://arxiv.org/abs/2308.11730](http://arxiv.org/abs/2308.11730)

    这篇论文提出了一种知识图谱引导的方法，用于在多文档问答任务中为大型语言模型（LLMs）提示正确的上下文。通过构建多个文档上的知识图谱，并设计基于语言模型的图遍历器，该方法能够帮助LLMs在MD-QA中进行答案预测。

    

    大型语言模型（LLMs）的“预训练、提示、预测”范式在开放域问答（OD-QA）中取得了显著的成功。然而，很少有工作在多文档问答（MD-QA）场景下探索这个范式，这是一个要求对不同文档的内容和结构之间的逻辑关联有深入理解的任务。为了填补这一重要的空白，我们提出了一种知识图谱引导（KGP）方法，用于在MD-QA中为LLMs提示正确的上下文，该方法包括图构建模块和图遍历模块。对于图构建，我们使用节点来表示文段或文档结构（例如，页面/表格），而使用边来表示文段之间的语义/词汇相似性或者文档内的结构关系。对于图遍历，我们设计了一个基于LM的图遍历器，它在节点之间导航并收集支持性的文段，以帮助LLMs在MD-QA中进行答案预测。

    The 'pre-train, prompt, predict' paradigm of large language models (LLMs) has achieved remarkable success in open-domain question answering (OD-QA). However, few works explore this paradigm in the scenario of multi-document question answering (MD-QA), a task demanding a thorough understanding of the logical associations among the contents and structures of different documents. To fill this crucial gap, we propose a Knowledge Graph Prompting (KGP) method to formulate the right context in prompting LLMs for MD-QA, which consists of a graph construction module and a graph traversal module. For graph construction, we create a knowledge graph (KG) over multiple documents with nodes symbolizing passages or document structures (e.g., pages/tables), and edges denoting the semantic/lexical similarity between passages or intra-document structural relations. For graph traversal, we design an LM-guided graph traverser that navigates across nodes and gathers supporting passages assisting LLMs in MD
    
[^12]: 人工智能在事实核查中无效且具有潜在危害性

    Artificial intelligence is ineffective and potentially harmful for fact checking. (arXiv:2308.10800v2 [cs.HC] UPDATED)

    [http://arxiv.org/abs/2308.10800](http://arxiv.org/abs/2308.10800)

    这项研究发现人工智能语言模型在事实核查中表现出色，但在帮助用户判断标题准确性和分享准确新闻方面影响不大。然而，在某些情况下，它会误导用户对真实标题的信仰，并增加对未确定虚假标题的信仰。

    

    事实核查是对抗错误信息的有效策略，但是它在规模上的实施受到了网络上信息过于庞大的阻碍。近期的人工智能语言模型在事实核查任务中展现出了令人印象深刻的能力，但人们在使用这些模型提供的事实核查信息时的作用机制并不清楚。在这里，我们通过一项预先登记的随机对照实验，研究了一款热门人工智能模型生成的事实核查对政治新闻信仰和分享意图的影响。尽管该人工智能在揭穿虚假标题方面表现得相当不错，但我们发现它并没有对参与者识别标题准确性或分享准确新闻的能力产生显著影响。然而，在特定情况下，该人工智能事实核查器具有危害性：将一些真实标题误标为虚假会降低对其的信仰，而对其未确定的虚假标题则会增加对其的信仰。在积极方面，该人工智能提高了正确标定标题的分享意愿。

    Fact checking can be an effective strategy against misinformation, but its implementation at scale is impeded by the overwhelming volume of information online. Recent artificial intelligence (AI) language models have shown impressive ability in fact-checking tasks, but how humans interact with fact-checking information provided by these models is unclear. Here we investigate the impact of fact checks generated by a popular AI model on belief in, and sharing intent of, political news in a preregistered randomized control experiment. Although the AI performs reasonably well in debunking false headlines, we find that it does not significantly affect participants' ability to discern headline accuracy or share accurate news. However, the AI fact-checker is harmful in specific cases: it decreases beliefs in true headlines that it mislabels as false and increases beliefs for false headlines that it is unsure about. On the positive side, the AI increases sharing intents for correctly labeled t
    
[^13]: SwinLSTM：使用Swin Transformer和LSTM提高时空预测准确性

    SwinLSTM:Improving Spatiotemporal Prediction Accuracy using Swin Transformer and LSTM. (arXiv:2308.09891v1 [cs.CV])

    [http://arxiv.org/abs/2308.09891](http://arxiv.org/abs/2308.09891)

    SwinLSTM是一种将Swin Transformer和LSTM结合起来以提高时空预测准确性的新循环单元，在四个数据集上表现出优越的性能，特别是在预测准确性方面有显著提高。

    

    将CNN和RNN集成以捕捉时空依赖关系是时空预测任务中常用的策略。然而，CNN学习局部空间信息的属性降低了它们在捕捉时空依赖关系方面的效率，从而限制了它们的预测准确性。本文提出了一种新的循环单元SwinLSTM，它将Swin Transformer块和简化的LSTM集成在一起，将ConvLSTM中的卷积结构替换为自注意机制。此外，我们构建了一个以SwinLSTM单元为核心的时空预测网络。SwinLSTM在Moving MNIST，Human3.6m，TaxiBJ和KTH数据集上表现比最先进的方法更好，特别是在预测准确性方面有显著提高。我们的竞争性实验结果表明，学习全局空间依赖关系对于模型捕捉时空依赖关系更有优势。

    Integrating CNNs and RNNs to capture spatiotemporal dependencies is a prevalent strategy for spatiotemporal prediction tasks. However, the property of CNNs to learn local spatial information decreases their efficiency in capturing spatiotemporal dependencies, thereby limiting their prediction accuracy. In this paper, we propose a new recurrent cell, SwinLSTM, which integrates Swin Transformer blocks and the simplified LSTM, an extension that replaces the convolutional structure in ConvLSTM with the self-attention mechanism. Furthermore, we construct a network with SwinLSTM cell as the core for spatiotemporal prediction. Without using unique tricks, SwinLSTM outperforms state-of-the-art methods on Moving MNIST, Human3.6m, TaxiBJ, and KTH datasets. In particular, it exhibits a significant improvement in prediction accuracy compared to ConvLSTM. Our competitive experimental results demonstrate that learning global spatial dependencies is more advantageous for models to capture spatiotempo
    
[^14]: 利用对称性在物品搬运中的应用

    Leveraging Symmetries in Pick and Place. (arXiv:2308.07948v1 [cs.RO])

    [http://arxiv.org/abs/2308.07948](http://arxiv.org/abs/2308.07948)

    该论文研究了物品搬运任务中的对称性，提出了一种称为等变Transporter Net的模型，利用等变神经模型捕捉了所有对称性，能够在不同的搬运位置推广搬运知识。

    

    机器人的物品搬运任务在物品和目标放置位置的平移和旋转下具有对称性。例如，如果物品被旋转或平移，最佳搬运动作也应该旋转或平移。对于放置位置也是如此，如果目标放置位置发生变化，放置动作也应相应改变。最近提出的搬运框架Transporter Net捕捉了部分这些对称性，但不完全。本文通过分析平面机器人物品搬运中的对称性，提出了一种将等变神经模型整合到Transporter Net中以捕捉所有对称性的方法。这个新模型被称为等变Transporter Net，对于物品的搬运和放置具有等变性，可以立即将搬运知识推广到不同的搬运位置。我们通过实验证明了这个新模型的效果，并显示它比传统模型更加高效。

    Robotic pick and place tasks are symmetric under translations and rotations of both the object to be picked and the desired place pose. For example, if the pick object is rotated or translated, then the optimal pick action should also rotate or translate. The same is true for the place pose; if the desired place pose changes, then the place action should also transform accordingly. A recently proposed pick and place framework known as Transporter Net captures some of these symmetries, but not all. This paper analytically studies the symmetries present in planar robotic pick and place and proposes a method of incorporating equivariant neural models into Transporter Net in a way that captures all symmetries. The new model, which we call Equivariant Transporter Net, is equivariant to both pick and place symmetries and can immediately generalize pick and place knowledge to different pick and place poses. We evaluate the new model empirically and show that it is much more sample efficient t
    
[^15]: VisIT-Bench: 一个受真实世界使用启发的视觉语言指示评估基准

    VisIT-Bench: A Benchmark for Vision-Language Instruction Following Inspired by Real-World Use. (arXiv:2308.06595v1 [cs.CL])

    [http://arxiv.org/abs/2308.06595](http://arxiv.org/abs/2308.06595)

    VisIT-Bench是一个用于评价真实世界中视觉语言模型指示遵循的基准，包含了各种任务并提供了详细描述，可以自动评估多模态生成的质量差距。

    

    我们引入了VisIT-Bench（Visual InsTruction Benchmark），这是一个评价用于真实世界使用的视觉语言模型的指示遵循基准。我们的起点是策划了70个“指示家族”，我们认为指示调优的视觉语言模型应该能够解决这些家族。任务不仅限于VQAv2和COCO等评估，涵盖了从基本识别到游戏玩法和创造性生成的各种任务。在策划之后，我们的数据集包括592个测试查询，每个查询都带有一个人工编写的指示条件化的字幕。这些描述展现了特定指示因素，例如对于询问店面对于轮椅用户的易访问性的指示，条件化的字幕描述了斜坡/潜在障碍物。这些描述使得我们可以：1）收集每个实例的人工验证的参考输出；2）使用仅文本的语言模型对候选多模态生成进行自动评估，与人类判断相一致。我们量化了质量差距。

    We introduce VisIT-Bench (Visual InsTruction Benchmark), a benchmark for evaluation of instruction-following vision-language models for real-world use. Our starting point is curating 70 'instruction families' that we envision instruction tuned vision-language models should be able to address. Extending beyond evaluations like VQAv2 and COCO, tasks range from basic recognition to game playing and creative generation. Following curation, our dataset comprises 592 test queries, each with a human-authored instruction-conditioned caption. These descriptions surface instruction-specific factors, e.g., for an instruction asking about the accessibility of a storefront for wheelchair users, the instruction-conditioned caption describes ramps/potential obstacles. These descriptions enable 1) collecting human-verified reference outputs for each instance; and 2) automatic evaluation of candidate multimodal generations using a text-only LLM, aligning with human judgment. We quantify quality gaps be
    
[^16]: EnrichEvent: 使用上下文信息为新出现的事件提供丰富的社交数据

    EnrichEvent: Enriching Social Data with Contextual Information for Emerging Event Extraction. (arXiv:2307.16082v1 [cs.CL])

    [http://arxiv.org/abs/2307.16082](http://arxiv.org/abs/2307.16082)

    本文提出了一个利用词汇、语义和上下文表示的框架，旨在解决现有事件检测方法在识别新兴社交事件方面的局限性，并提供了对社交数据进行丰富的上下文化处理的方法。

    

    社交平台已成为传播和讨论真实事件信息的关键平台，为及早发现有新闻价值的事件提供了良好的机会。然而，现有的大多数事件检测方法仅利用关键词突发性或网络结构来检测热点事件。因此，对于事件和社交数据的复杂性而言，它们往往无法在达到趋势状态之前识别出新出现的社交事件。社交数据，例如推文，具有拼写错误、不完整性、歧义性和语言不规范性，以及意见方面的变化。此外，利用有限的上下文知识来学习事件的演变特征对于机器学习模型几乎是不可行的。为了解决这些问题，本文提出了一个利用流式社交数据的词汇、语义和上下文表示的框架。

    Social platforms have emerged as a crucial platform for disseminating and discussing information about real-life events, which offers an excellent opportunity for early detection of newsworthy events. However, most existing approaches for event detection solely exploit keyword burstiness or network structures to detect hot events. Thus, they often fail to identify emerging social events before reaching a trending state regarding the challenging nature of events and social data. Social data, e.g., tweets, is characterized by misspellings, incompleteness, ambiguity, and irregular language, as well as variation in aspects of opinions. Moreover, learning the evolving characteristics of the events utilizing limited contextual knowledge is almost infeasible for machine learning models. To address these problems, in this paper, we propose a framework that exploits the lexical, semantic, and contextual representations of streaming social data. In particular, we leverage contextual knowledge to
    
[^17]: 面向教育中人工智能协作混合论文的自动边界检测

    Towards Automatic Boundary Detection for Human-AI Collaborative Hybrid Essay in Education. (arXiv:2307.12267v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.12267](http://arxiv.org/abs/2307.12267)

    本研究探索了在教育领域中，由人类和生成性语言模型协作编写的混合文本的AI内容检测方法，将其形式化为识别转换点的任务，以区分人类编写和AI生成的部分。

    

    最近的大型语言模型（如ChatGPT）能够在提供具体指导的情况下生成类似于人类的流畅回答。尽管承认技术进步带来的便利，教育者也担心学生可能利用语言模型来完成写作任务并将其假冒为自己的原创作品。虽然有很多AI内容检测研究是基于这些担忧进行的，但大多数之前的研究将AI内容检测建模为一个分类问题，假设一个文本要么完全由人类编写，要么完全由AI生成。在本研究中，我们研究了AI内容检测在一个少有探索但却现实的情况下，即检测的文本由人类和生成性语言模型（即混合文本）协作编写。我们首先将检测任务形式化为从给定的混合文本中识别人类编写内容和AI生成内容之间的转换点（边界检测）。

    The recent large language models (LLMs), e.g., ChatGPT, have been able to generate human-like and fluent responses when provided with specific instructions. While admitting the convenience brought by technological advancement, educators also have concerns that students might leverage LLMs to complete their writing assignments and pass them off as their original work. Although many AI content detection studies have been conducted as a result of such concerns, most of these prior studies modeled AI content detection as a classification problem, assuming that a text is either entirely human-written or entirely AI-generated. In this study, we investigated AI content detection in a rarely explored yet realistic setting where the text to be detected is collaboratively written by human and generative LLMs (i.e., hybrid text). We first formalized the detection task as identifying the transition points between human-written content and AI-generated content from a given hybrid text (boundary det
    
[^18]: 探索大规模语言模型在在线职位推荐中对图数据的理解

    Exploring Large Language Model for Graph Data Understanding in Online Job Recommendations. (arXiv:2307.05722v1 [cs.AI])

    [http://arxiv.org/abs/2307.05722](http://arxiv.org/abs/2307.05722)

    本论文探索了大规模语言模型在在线职位推荐中对图数据的理解能力，并提出了新的框架来分析行为图，发现其中的潜在模式和关系。

    

    大规模语言模型（LLMs）在各个领域展示了其出色的能力，彻底改变了自然语言处理任务。然而，它们在职位推荐中对行为图的理解潜力仍然未被充分探索。本文旨在揭示大规模语言模型在理解行为图方面的能力，并利用这种理解来提升在线招聘中的推荐，包括促进非分布式的应用。我们提出了一个新的框架，利用大规模语言模型提供的丰富上下文信息和语义表示来分析行为图并揭示其中的潜在模式和关系。具体而言，我们提出了一个元路径提示构造器，利用LLM推荐器首次理解行为图，并设计了相应的路径增强模块来缓解基于路径的序列输入引入的提示偏差。通过利用将LM的特点引入到行为图的大规模数据分析中，我们取得了显著的实验结果，证明了我们提出的方法的有效性和性能。

    Large Language Models (LLMs) have revolutionized natural language processing tasks, demonstrating their exceptional capabilities in various domains. However, their potential for behavior graph understanding in job recommendations remains largely unexplored. This paper focuses on unveiling the capability of large language models in understanding behavior graphs and leveraging this understanding to enhance recommendations in online recruitment, including the promotion of out-of-distribution (OOD) application. We present a novel framework that harnesses the rich contextual information and semantic representations provided by large language models to analyze behavior graphs and uncover underlying patterns and relationships. Specifically, we propose a meta-path prompt constructor that leverages LLM recommender to understand behavior graphs for the first time and design a corresponding path augmentation module to alleviate the prompt bias introduced by path-based sequence input. By leveragin
    
[^19]: 学习核技术用于可解释和高效的PPG信号质量评估和伪影分割

    Learned Kernels for Interpretable and Efficient PPG Signal Quality Assessment and Artifact Segmentation. (arXiv:2307.05385v1 [eess.SP])

    [http://arxiv.org/abs/2307.05385](http://arxiv.org/abs/2307.05385)

    本文提出了一种通过学习核技术，具有解释性且参数较少的方法来评估和分割PPG信号的质量和伪影，与现有的深度神经网络方法相比有着类似甚至更好的性能。

    

    光电容抗(PPG)提供了一种低成本、非侵入性的方法来持续监测各种心血管参数。PPG信号由可穿戴设备产生，常常包含由外部因素(如人体运动)引起的大型伪影。为了确保对生理参数进行稳健和准确的提取，信号的损坏区域需要被正确地识别和处理。之前的方法依靠手工特征检测器或信号度量，结果性能不佳，或依靠深度神经网络(DNN)等机器学习技术，缺乏可解释性，计算和内存密集。在这项工作中，我们提出了一种新的方法，学习一小组可解释的卷积核，其性能与现有技术DNN方法相似，甚至更好，而参数数量比DNN方法少几个数量级。这项工作实现了高效、稳健和可解释的PPG信号质量评估和伪影分割。

    Photoplethysmography (PPG) provides a low-cost, non-invasive method to continuously monitor various cardiovascular parameters. PPG signals are generated by wearable devices and frequently contain large artifacts caused by external factors, such as motion of the human subject. In order to ensure robust and accurate extraction of physiological parameters, corrupted areas of the signal need to be identified and handled appropriately. Previous methodology relied either on handcrafted feature detectors or signal metrics which yield sub-optimal performance, or relied on machine learning techniques such as deep neural networks (DNN) which lack interpretability and are computationally and memory intensive. In this work, we present a novel method to learn a small set of interpretable convolutional kernels that has performance similar to -- and often better than -- the state-of-the-art DNN approach with several orders of magnitude fewer parameters. This work allows for efficient, robust, and int
    
[^20]: TransformerG2G：使用Transformer进行自适应时间步长的学习时态图嵌入

    TransformerG2G: Adaptive time-stepping for learning temporal graph embeddings using transformers. (arXiv:2307.02588v1 [cs.LG])

    [http://arxiv.org/abs/2307.02588](http://arxiv.org/abs/2307.02588)

    TransformerG2G是一种使用Transformer进行自适应时间步长的图嵌入模型，通过学习历史上的长程依赖关系，准确地捕捉时态图的动态特征。

    

    动态图嵌入已成为处理不同时间图分析任务（如链路预测、节点分类、推荐系统、异常检测和图生成）的一种非常有效的技术，广泛应用于各种应用领域。这些时态图展现了异质的瞬时动态、不同的时间间隔以及在演化过程中高度变化的节点特征。因此，将历史图上的长程依赖融入到学习时态动态的过程中至关重要。本文提出了一个带有不确定性量化的图嵌入模型TransformerG2G，通过利用先进的Transformer编码器从当前状态（$t$）和之前的上下文（时间戳[$t-1, t-l$]，$l$是上下文的长度）中首先学习中间节点表示。此外，我们采用两个投影层来生成每个节点的低维多元高斯分布，作为其潜在嵌入。

    Dynamic graph embedding has emerged as a very effective technique for addressing diverse temporal graph analytic tasks (i.e., link prediction, node classification, recommender systems, anomaly detection, and graph generation) in various applications. Such temporal graphs exhibit heterogeneous transient dynamics, varying time intervals, and highly evolving node features throughout their evolution. Hence, incorporating long-range dependencies from the historical graph context plays a crucial role in accurately learning their temporal dynamics. In this paper, we develop a graph embedding model with uncertainty quantification, TransformerG2G, by exploiting the advanced transformer encoder to first learn intermediate node representations from its current state ($t$) and previous context (over timestamps [$t-1, t-l$], $l$ is the length of context). Moreover, we employ two projection layers to generate lower-dimensional multivariate Gaussian distributions as each node's latent embedding at ti
    
[^21]: 关于中心隐私在密度估计中的成本

    About the Cost of Central Privacy in Density Estimation. (arXiv:2306.14535v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2306.14535](http://arxiv.org/abs/2306.14535)

    本研究对于利普希茨和 Sobolev 空间中的非参数密度估计，通过考虑中心隐私的影响，发现了直方图估计器在 L2 风险下对于利普希茨分布是最优的，并且在正常差分隐私情况下也是如此；同时发现，在一些情况下，施加隐私会降低对于 Sobolev 密度的正则极小风险估计。此外，本研究还发现在纯投影估计设定下，所谓的投影估计器对于相同类密度几乎是最优的。

    

    我们研究利普希茨和 Sobolev 空间中的非参数密度估计，在中心隐私条件下进行。我们考虑了隐私预算不是常数的情况。我们考虑了经典的中心差分隐私定义，以及较新的中心集中差分隐私概念。我们证实了 Barber & Duchi (2014) 的结果，即直方图估计器在对于 L2 风险下对于利普希茨分布是最优的，并且在正常差分隐私情况下也是如此，我们将其扩展到其他范数和隐私概念。然后，我们研究更高程度的光滑性，得出两个结论：首先，与常数隐私预算需要的情况相反（Wasserman &amp; Zhou, 2010），在 Sobolev 密度上施加隐私会降低正则极小风险估计。其次，在这种新的纯投影估计设定下，所谓的投影估计器对于相同类密度是几乎最优的。

    We study non-parametric density estimation for densities in Lipschitz and Sobolev spaces, and under central privacy. In particular, we investigate regimes where the privacy budget is not supposed to be constant. We consider the classical definition of central differential privacy, but also the more recent notion of central concentrated differential privacy. We recover the result of Barber \& Duchi (2014) stating that histogram estimators are optimal against Lipschitz distributions for the L2 risk, and under regular differential privacy, and we extend it to other norms and notions of privacy. Then, we investigate higher degrees of smoothness, drawing two conclusions: First, and contrary to what happens with constant privacy budget (Wasserman \& Zhou, 2010), there are regimes where imposing privacy degrades the regular minimax risk of estimation on Sobolev densities. Second, so-called projection estimators are near-optimal against the same classes of densities in this new setup with pure
    
[^22]: 用MT-Bench和Chatbot Arena评估以LLM为基础的聊天助手

    Judging LLM-as-a-judge with MT-Bench and Chatbot Arena. (arXiv:2306.05685v1 [cs.CL])

    [http://arxiv.org/abs/2306.05685](http://arxiv.org/abs/2306.05685)

    研究使用强大的LLM作为评判员，通过引入两个基准测试来确认LLM评判员和人类偏好之间的一致性，并可调整聊天助手的模型架构和微调方法来提高其性能。

    

    评估基于大语言模型（LLM）的聊天助手会面临挑战，因为它们具有广泛的功能，而现有的基准无法衡量人类偏好。为了解决这个问题，我们探索使用强大的LLM作为评判员，在更加开放的问题上评估这些模型。我们研究了LLM作为评判员的使用和局限性，如位置和冗余偏见以及有限的推理能力，并提出解决方案来迁移其中一些问题。然后，我们通过引入两个基准测试（一个多轮问答集和一个众包竞技平台）来确认LLM评判员和人类偏好之间的一致性。我们的结果显示，像GPT-4这样的强大LLM评判员可以很好地匹配受控和众包人类偏好，达到了80％以上的一致性，与人类一致性水平相同。因此，LLM作为评判员是一种可扩展且可解释的逼近人类偏好的方式，而这些偏好是非常昂贵获取的。此外，我们证明，通过使用LLM作为评判员，可以通过调整聊天助手的模型架构和微调方法来提高其性能。

    Evaluating large language model (LLM) based chat assistants is challenging due to their broad capabilities and the inadequacy of existing benchmarks in measuring human preferences. To address this, we explore using strong LLMs as judges to evaluate these models on more open-ended questions. We examine the usage and limitations of LLM-as-a-judge, such as position and verbosity biases and limited reasoning ability, and propose solutions to migrate some of them. We then verify the agreement between LLM judges and human preferences by introducing two benchmarks: MT-bench, a multi-turn question set; and Chatbot Arena, a crowdsourced battle platform. Our results reveal that strong LLM judges like GPT-4 can match both controlled and crowdsourced human preferences well, achieving over 80\% agreement, the same level of agreement between humans. Hence, LLM-as-a-judge is a scalable and explainable way to approximate human preferences, which are otherwise very expensive to obtain. Additionally, we
    
[^23]: 使用编译器生成的强化学习反馈调整代码模型

    Tuning Models of Code with Compiler-Generated Reinforcement Learning Feedback. (arXiv:2305.18341v1 [cs.PL])

    [http://arxiv.org/abs/2305.18341](http://arxiv.org/abs/2305.18341)

    本文提出了一种叫做RLCF的方法，使用代码编译器反馈进一步训练预训练的大型语言模型，以生成符合目标分布的代码，并通过所有静态正确性检查，显著提高了性能。

    

    最近，对代码进行预训练的大型语言模型成为程序合成的主要方法。然而，这些模型生成的代码可能违反基本的语言级别不变性，从而降低下游任务的性能。本文提出了一种称为RLCF的方法，它使用代码编译器的反馈进一步训练预训练的大型语言模型。 RLCF将LLM视为通过RL代理逐步生成代码，并接收以下反馈：（i）编译器派生的反馈与所生成的代码是否通过一组正确性检查有关; （ii）不同LLM的反馈，与训练语料库中一组参考程序相似。这些反馈机制帮助所生成的代码在通过所有静态正确性检查的同时保持在目标分布中。RLCF是模型和语言无关的。我们在Java的MBJP和MathQA任务上进行了实证评估，实验结果表明，RLCF显著提高了性能。

    Large Language Models (LLMs) pre-trained on code have recently emerged as the dominant approach to program synthesis. However, the code that these models produce can violate basic language-level invariants, leading to lower performance in downstream tasks. We address this issue through an approach, called RLCF, that further trains a pre-trained LLM using feedback from a code compiler. RLCF views the LLM as an RL agent that generates code step by step and receives: (i) compiler-derived feedback on whether the code it generates passes a set of correctness checks; and (ii) feedback from a different LLM on whether the generated code is similar to a set of reference programs in the training corpus. Together, these feedback mechanisms help the generated code remain within the target distribution while passing all static correctness checks. RLCF is model- and language-agnostic. We empirically evaluate it on the MBJP and MathQA tasks for Java. Our experiments show that RLCF significantly raise
    
[^24]: 运用自我记忆的检索增强文本生成模型

    Lift Yourself Up: Retrieval-augmented Text Generation with Self Memory. (arXiv:2305.02437v1 [cs.CL])

    [http://arxiv.org/abs/2305.02437](http://arxiv.org/abs/2305.02437)

    本文提出了一种新的检索增强文本生成模型Selfmem，通过迭代生成自我记忆池并采用记忆选择器，使检索更加自适应，提高了文本生成的质量和多样性。

    

    相较于传统文本生成模型，检索增强文本生成模型能够直接迭代人类编写的参考库，并从中检索出相应的信息，以生成更优质的文本。但当前文献存在一个关键问题：检索到的记忆来自于固定的语料库，其质量存在一定局限性，可能会限制记忆增强模型的潜力。本文提出一种名为Selfmem的框架，该框架通过迭代地采用检索增强生成器自身以生成无限制的自我记忆池，并使用记忆选择器为下一轮生成选择一个生成的记忆。相结合，这两个主要问题提出了运用自我记忆的检索增强文本生成模型。

    With direct access to human-written reference as memory, retrieval-augmented generation has achieved much progress in a wide range of text generation tasks. Since better memory would typically prompt better generation~(we define this as primal problem), previous works mainly focus on how to retrieve better memory. However, one fundamental limitation exists for current literature: the memory is retrieved from a fixed corpus and is bounded by the quality of the corpus. Due to the finite retrieval space, bounded memory would greatly limit the potential of the memory-augmented generation model. In this paper, by exploring the duality of the primal problem: better generation also prompts better memory, we propose a framework called Selfmem, which iteratively adopts a retrieval-augmented generator itself to generate an unbounded memory pool and uses a memory selector to pick one generated memory for the next generation round. By combining the primal and dual problem, a retrieval-augmented ge
    
[^25]: 混合整数最优控制在混合动力车辆能量管理中的强化学习研究

    Mixed-Integer Optimal Control via Reinforcement Learning: A Case Study on Hybrid Vehicle Energy Management. (arXiv:2305.01461v1 [eess.SY])

    [http://arxiv.org/abs/2305.01461](http://arxiv.org/abs/2305.01461)

    本研究提出了一种新的混合整数最优控制问题的强化学习算法，可同时处理连续和离散控制变量， 并在混合动力车辆能源管理问题上优于现有方法和强化学习算法。

    

    许多最优控制问题需要同时输出连续和离散控制变量。这些问题通常被制定为混合整数最优控制(MIOC)问题，由于解决方案空间的复杂性而难以解决。数值方法如分支定界法计算成本高，不适合实时控制。本文提出了一种新的连续离散强化学习(CDRL)算法，双延迟深度确定性演员- Q(TD3AQ)，用于MIOC问题。TD3AQ结合了演员-批评家和Q学习方法的优点，同时可以处理连续和离散动作空间。该算法在混合动力车辆(HEV)能量管理问题上进行评估，其中连续变量发动机转矩和离散变量齿轮比的实时控制对于最大化燃油经济性并满足驾驶约束条件至关重要。不同驱动循环的仿真结果表明，所提出的CDRL算法在解决质量、收敛速度和计算效率方面优于最先进的数值方法和现有的强化学习算法。

    Many optimal control problems require the simultaneous output of continuous and discrete control variables. Such problems are usually formulated as mixed-integer optimal control (MIOC) problems, which are challenging to solve due to the complexity of the solution space. Numerical methods such as branch-and-bound are computationally expensive and unsuitable for real-time control. This paper proposes a novel continuous-discrete reinforcement learning (CDRL) algorithm, twin delayed deep deterministic actor-Q (TD3AQ), for MIOC problems. TD3AQ combines the advantages of both actor-critic and Q-learning methods, and can handle the continuous and discrete action spaces simultaneously. The proposed algorithm is evaluated on a hybrid electric vehicle (HEV) energy management problem, where real-time control of the continuous variable engine torque and discrete variable gear ratio is essential to maximize fuel economy while satisfying driving constraints. Simulation results on different drive cyc
    
[^26]: 基于采样的反应综合算法应用于非确定性混合系统

    Sampling-based Reactive Synthesis for Nondeterministic Hybrid Systems. (arXiv:2304.06876v1 [eess.SY])

    [http://arxiv.org/abs/2304.06876](http://arxiv.org/abs/2304.06876)

    本文提出了一种基于采样的策略综合算法，用于具有复杂连续动力学和时间和可达性约束的非确定性混合系统。算法基于在混合空间中生长（搜索）游戏树，以合成一种反应（鲁棒）策略，以满足目标并在可扩展性和效率方面优于最新技术水平。

    

    本文提出了一种基于采样的策略综合算法，用于具有复杂连续动力学和时间和可达性约束的非确定性混合系统。我们将混合系统的演化视为一个双人游戏，其中非确定性是一个对手玩家，其目标是阻止实现时间和可达性目标。旨在合成一种获胜策略——一种反应（鲁棒）策略，它保证在对手玩家的所有可能移动下满足目标。该方法基于在混合空间中生长（搜索）游戏树，通过将基于采样的规划方法与一种用于选择和改进部分策略的新型乘客舱机技术相结合。我们提供的条件下，算法是概率上完备的，即，如果存在获胜策略，该算法几乎肯定会找到它。案例研究和基准结果表明，该算法具有广泛的适用性，并在可扩展性和效率方面始终优于最新技术水平。

    This paper introduces a sampling-based strategy synthesis algorithm for nondeterministic hybrid systems with complex continuous dynamics under temporal and reachability constraints. We view the evolution of the hybrid system as a two-player game, where the nondeterminism is an adversarial player whose objective is to prevent achieving temporal and reachability goals. The aim is to synthesize a winning strategy -- a reactive (robust) strategy that guarantees the satisfaction of the goals under all possible moves of the adversarial player. The approach is based on growing a (search) game-tree in the hybrid space by combining a sampling-based planning method with a novel bandit-based technique to select and improve on partial strategies. We provide conditions under which the algorithm is probabilistically complete, i.e., if a winning strategy exists, the algorithm will almost surely find it. The case studies and benchmark results show that the algorithm is general and consistently outperf
    
[^27]: 结构化提示询问与递归语义提取（SPIRES）：使用零样本学习填充知识库的方法

    Structured prompt interrogation and recursive extraction of semantics (SPIRES): A method for populating knowledge bases using zero-shot learning. (arXiv:2304.02711v1 [cs.AI])

    [http://arxiv.org/abs/2304.02711](http://arxiv.org/abs/2304.02711)

    SPIRES是一种新的知识提取方法，利用大型语言模型进行零样本学习和通用查询回答，能够填充复杂的知识库而无需显式训练数据。

    

    创建知识库和本体是一项耗时的任务，依赖于手动管理。AI / NLP方法可以帮助专业策展人填充这些知识库，但当前方法依赖于大量训练数据，并且不能填充任意复杂的嵌套知识模式。在这里我们提出了Structured Prompt Interrogation and Recursive Extraction of Semantics（SPIRES），一种知识提取方法，该方法依赖于大型语言模型（LLM）执行零样本学习（ZSL）和通用查询回答，以及从灵活提示返回符合指定模式的信息。 SPIRES针对给定的详细用户定义的知识模式和输入文本，对GPT-3+执行递归提示询问，以获得与提供的模式匹配的一组响应。 SPIRES使用现有的本体和词汇表为所有匹配元素提供标识符。 我们提供了在不同领域（包括音乐，体育和政治）中使用SPIRES的示例，展示了其能够填充复杂的知识库而无需显式训练数据。

    Creating knowledge bases and ontologies is a time consuming task that relies on a manual curation. AI/NLP approaches can assist expert curators in populating these knowledge bases, but current approaches rely on extensive training data, and are not able to populate arbitrary complex nested knowledge schemas.  Here we present Structured Prompt Interrogation and Recursive Extraction of Semantics (SPIRES), a Knowledge Extraction approach that relies on the ability of Large Language Models (LLMs) to perform zero-shot learning (ZSL) and general-purpose query answering from flexible prompts and return information conforming to a specified schema. Given a detailed, user-defined knowledge schema and an input text, SPIRES recursively performs prompt interrogation against GPT-3+ to obtain a set of responses matching the provided schema. SPIRES uses existing ontologies and vocabularies to provide identifiers for all matched elements.  We present examples of use of SPIRES in different domains, inc
    
[^28]: “Polytuplet Loss: 训练阅读理解和逻辑推理模型的反向方法”

    Polytuplet Loss: A Reverse Approach to Training Reading Comprehension and Logical Reasoning Models. (arXiv:2304.01046v1 [cs.CL] CROSS LISTED)

    [http://arxiv.org/abs/2304.01046](http://arxiv.org/abs/2304.01046)

    本文研究了一种训练阅读理解和逻辑推理模型的反向方法，利用相对准确性的策略来训练模型，通过Polytuplet Loss函数来确保优先学习答案选择的相对正确性，获得了不错的成果，提出了具有一般性的训练方法和模型架构。

    

    在整个学校教育过程中，学生们将受到阅读理解和逻辑推理的考验。学生们已经开发了各种策略来完成此类考试，其中有些被认为是通常表现优于其他策略的。这样一种策略涉及强调相对准确性而非绝对准确性，理论上可以在不完全掌握解题所需信息的情况下得出正确答案。本文研究了应用这种策略来训练迁移学习模型以解决阅读理解和逻辑推理问题的有效性。这些模型在具有挑战性的阅读理解和逻辑推理基准数据集ReClor上进行了评估。尽管以前的研究集中于逻辑推理技能，但我们专注于一种通用的训练方法和模型架构。我们提出了Polytuplet Loss函数，是三元组损失函数的扩展，以确保优先学习答案选择的相对正确性而非学习绝对正确性。

    Throughout schooling, students are tested on reading comprehension and logical reasoning. Students have developed various strategies for completing such exams, some of which are generally thought to outperform others. One such strategy involves emphasizing relative accuracy over absolute accuracy and can theoretically produce the correct answer without full knowledge of the information required to solve the question. This paper examines the effectiveness of applying such a strategy to train transfer learning models to solve reading comprehension and logical reasoning questions. The models were evaluated on the ReClor dataset, a challenging reading comprehension and logical reasoning benchmark. While previous studies targeted logical reasoning skills, we focus on a general training method and model architecture. We propose the polytuplet loss function, an extension of the triplet loss function, to ensure prioritization of learning the relative correctness of answer choices over learning
    
[^29]: CRN：用于准确、稳健、高效的3D感知的相机雷达网络

    CRN: Camera Radar Net for Accurate, Robust, Efficient 3D Perception. (arXiv:2304.00670v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2304.00670](http://arxiv.org/abs/2304.00670)

    本文提出了CRN，一个新颖的相机雷达融合框架，通过将图像视图特征转换为鸟瞰特征图和使用多模态可变形注意力，实现了准确、稳健、高效的3D感知任务

    

    自动驾驶需要一个准确快速的3D感知系统，包括3D物体检测、跟踪和分割。虽然最近的低成本基于相机的方法显示出了有希望的结果，但是它们容易受到糟糕的光照或恶劣的天气条件的影响，并且具有较大的定位误差。因此，将相机与低成本雷达相结合，后者可以在所有环境中提供精确的远程测量并可靠运行，是有希望的，但尚未得到全面的研究。在本文中，我们提出了一个名为Camera Radar Net（CRN）的新颖的相机雷达融合框架，为各种任务生成一个语义丰富、空间精确的鸟瞰特征图（BEV）。为了克服图像中缺乏空间信息的问题，我们使用稀疏但准确的雷达点将透视视图图像特征转换为BEV。我们进一步使用多模态可变形注意力在BEV中聚合图像和雷达特征图，以解决空间对齐错误问题

    Autonomous driving requires an accurate and fast 3D perception system that includes 3D object detection, tracking, and segmentation. Although recent low-cost camera-based approaches have shown promising results, they are susceptible to poor illumination or bad weather conditions and have a large localization error. Hence, fusing camera with low-cost radar, which provides precise long-range measurement and operates reliably in all environments, is promising but has not yet been thoroughly investigated. In this paper, we propose Camera Radar Net (CRN), a novel camera-radar fusion framework that generates a semantically rich and spatially accurate bird's-eye-view (BEV) feature map for various tasks. To overcome the lack of spatial information in an image, we transform perspective view image features to BEV with the help of sparse but accurate radar points. We further aggregate image and radar feature maps in BEV using multi-modal deformable attention designed to tackle the spatial misalig
    
[^30]: 解释约束下的学习

    Learning with Explanation Constraints. (arXiv:2303.14496v1 [cs.LG])

    [http://arxiv.org/abs/2303.14496](http://arxiv.org/abs/2303.14496)

    本文研究了解释约束下的学习问题，提出了EPAC模型，探讨了使用这些解释时模型的益处，并提供了一种基于变分近似的算法解决方案。

    

    尽管监督学习假设存在标注数据，但我们可能有关于模型应如何运行的先验信息。本文将其形式化为从解释约束中学习，并提供了一个学习理论框架，分析了这些解释如何提高模型的学习能力。本文的第一项关键贡献是通过定义我们称之为EPAC模型（在新数据期望中满足这些约束的模型）来回答哪些模型会受益于解释这一问题。我们使用标准的学习理论工具分析了这类模型。第二个关键贡献是对于由线性模型和两层神经网络的梯度信息给出的规范解释的限制（以其Rademacher复杂度为衡量标准）进行了表征。最后，我们通过一种变分近似提供了我们的框架的算法解决方案，它能够实现更好的性能并满足这些约束。

    While supervised learning assumes the presence of labeled data, we may have prior information about how models should behave. In this paper, we formalize this notion as learning from explanation constraints and provide a learning theoretic framework to analyze how such explanations can improve the learning of our models. For what models would explanations be helpful? Our first key contribution addresses this question via the definition of what we call EPAC models (models that satisfy these constraints in expectation over new data), and we analyze this class of models using standard learning theoretic tools. Our second key contribution is to characterize these restrictions (in terms of their Rademacher complexities) for a canonical class of explanations given by gradient information for linear models and two layer neural networks. Finally, we provide an algorithmic solution for our framework, via a variational approximation that achieves better performance and satisfies these constraint
    
[^31]: DualStreamFoveaNet: 一种具有解剖意识的双流融合架构用于鲁棒的中央凹点定位

    DualStreamFoveaNet: A Dual Stream Fusion Architecture with Anatomical Awareness for Robust Fovea Localization. (arXiv:2302.06961v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.06961](http://arxiv.org/abs/2302.06961)

    DualStreamFoveaNet是一种具有解剖意识的双流融合架构，通过利用视网膜和血管分布进行多线索融合，实现对鲁棒的中央凹点定位。实验证明该架构在中央凹点定位方面达到了最先进的性能。

    

    准确的中央凹点定位对于分析视网膜疾病以预防不可逆视力损失至关重要。当前基于深度学习的方法虽然优于传统方法，但仍面临一些挑战，如中央凹点周围局部解剖标记的缺失、不能鲁棒地处理病变视网膜图像和图像条件的变化。本文提出了一种新颖的基于Transformer的架构称为DualStreamFoveaNet (DSFN)用于多线索融合。该架构明确地利用视网膜和血管分布来实现长程连接和全局特征的融合，实现鲁棒的中央凹点定位。我们在双流编码器中引入了一种空间注意机制，用于提取和融合自学习的解剖信息，更注重分布在血管沿线的特征，并通过减少令牌数量显著降低计算成本。我们的广泛实验结果表明，所提出的架构达到了最先进的性能。

    Accurate fovea localization is essential for analyzing retinal diseases to prevent irreversible vision loss. While current deep learning-based methods outperform traditional ones, they still face challenges such as the lack of local anatomical landmarks around the fovea, the inability to robustly handle diseased retinal images, and the variations in image conditions. In this paper, we propose a novel transformer-based architecture called DualStreamFoveaNet (DSFN) for multi-cue fusion. This architecture explicitly incorporates long-range connections and global features using retina and vessel distributions for robust fovea localization. We introduce a spatial attention mechanism in the dual-stream encoder to extract and fuse self-learned anatomical information, focusing more on features distributed along blood vessels and significantly reducing computational costs by decreasing token numbers. Our extensive experiments show that the proposed architecture achieves state-of-the-art perform
    
[^32]: DynGFN: 借助RNA速度技术进行贝叶斯基因调控网络推断的GFlowNets方法

    DynGFN: Towards Bayesian Inference of Gene Regulatory Networks with GFlowNets. (arXiv:2302.04178v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.04178](http://arxiv.org/abs/2302.04178)

    DynGFN是一种借助RNA速度技术进行基因调控网络推断的方法，能够捕捉网络结构的不确定性，并在准确度上超过现有方法。

    

    细胞生物学的一个重要挑战是推断基因调控网络（GRN），该网络描述了控制基因表达和细胞功能的基因及其产物之间的相互作用。本文借助RNA速度技术开发了一种方法DynGFN，该方法训练生成流网络，使用RNA速度数据执行基因调控网络的贝叶斯推断，并捕捉网络结构的不确定性。

    One of the grand challenges of cell biology is inferring the gene regulatory network (GRN) which describes interactions between genes and their products that control gene expression and cellular function. We can treat this as a causal discovery problem but with two non-standard challenges: (1) regulatory networks are inherently cyclic so we should not model a GRN as a directed acyclic graph (DAG), and (2) observations have significant measurement noise, so for typical sample sizes there will always be a large equivalence class of graphs that are likely given the data, and we want methods that capture this uncertainty. Existing methods either focus on challenge (1), identifying cyclic structure from dynamics, or on challenge (2) learning complex Bayesian posteriors over DAGs, but not both. In this paper we leverage the fact that it is possible to estimate the "velocity" of gene expression with RNA velocity techniques to develop an approach that addresses both challenges. Because we have
    
[^33]: EHRSQL：面向电子病历的实用文本转SQL基准测试

    EHRSQL: A Practical Text-to-SQL Benchmark for Electronic Health Records. (arXiv:2301.07695v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.07695](http://arxiv.org/abs/2301.07695)

    该论文提出了一个面向电子病历数据的文本转SQL数据集，该数据集具有一系列独特挑战，包括生成SQL查询、理解时间表达式以及区分有无答案的问题。

    

    我们为电子病历（EHR）提供了一个新的文本到SQL数据集。对话是由222个医院工作人员包括医生、护士、保险审查和健康档案团队等手机而来。为了构建关于结构化EHR数据的QA数据集，我们在一所大学医院进行了一次民调并制作了模板话术以创建种子问题。然后，我们手动将它们链接到两个开源的EHR数据库（MIMIC-III和eICU）中，并在数据集中包含了来自民意调查的各种时间表达式和未能回答的问题。我们的数据集提出了一系列独特的挑战：模型需要 1）生成反映医院中各种需求的SQL查询，包括简单的检索和复杂的操作，如计算生存率，2）理解各种时间表达式以回答与时间敏感的医疗问题相关的问题，3）根据预测区分给定问题是可回答还是不可回答。

    We present a new text-to-SQL dataset for electronic health records (EHRs). The utterances were collected from 222 hospital staff, including physicians, nurses, insurance review and health records teams, and more. To construct the QA dataset on structured EHR data, we conducted a poll at a university hospital and templatized the responses to create seed questions. Then, we manually linked them to two open-source EHR databases, MIMIC-III and eICU, and included them with various time expressions and held-out unanswerable questions in the dataset, which were all collected from the poll. Our dataset poses a unique set of challenges: the model needs to 1) generate SQL queries that reflect a wide range of needs in the hospital, including simple retrieval and complex operations such as calculating survival rate, 2) understand various time expressions to answer time-sensitive questions in healthcare, and 3) distinguish whether a given question is answerable or unanswerable based on the predicti
    
[^34]: 生成扩散模型综述

    A Survey on Generative Diffusion Model. (arXiv:2209.02646v9 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2209.02646](http://arxiv.org/abs/2209.02646)

    本综述总结了生成扩散模型的先进技术，包括采样加速、新的扩散过程设计以及在不同空间中实现扩散模型的策略。这些创新努力旨在提高扩散模型的功能和效率。

    

    深度生成模型是一种用于数据生成的重要方法，在各个领域中被用来生成高质量的样本。生成扩散模型作为一种新兴的深度生成模型，因其出色的生成质量而受到广泛关注。然而，它们具有一定的局限性，包括耗时的迭代生成过程和限制在高维欧几里得空间中。本综述介绍了大量旨在增强扩散模型的先进技术，包括采样加速和新的扩散过程设计。此外，我们还深入探讨了在流形和离散空间中实现扩散模型的策略，扩散模型的最大似然训练方法，以及创建两个任意分布之间桥梁的方法。我们讨论的创新代表了近年来改进扩散模型功能和效率的努力。

    Deep generative models are a prominent approach for data generation, and have been used to produce high quality samples in various domains. Diffusion models, an emerging class of deep generative models, have attracted considerable attention owing to their exceptional generative quality. Despite this, they have certain limitations, including a time-consuming iterative generation process and confinement to high-dimensional Euclidean space. This survey presents a plethora of advanced techniques aimed at enhancing diffusion models, including sampling acceleration and the design of new diffusion processes. In addition, we delve into strategies for implementing diffusion models in manifold and discrete spaces, maximum likelihood training for diffusion models, and methods for creating bridges between two arbitrary distributions. The innovations we discuss represent the efforts for improving the functionality and efficiency of diffusion models in recent years. To examine the efficacy of existi
    
[^35]: 设备上学习：基于神经网络的可训练边缘人工智能

    On-Device Learning: A Neural Network Based Field-Trainable Edge AI. (arXiv:2203.01077v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2203.01077](http://arxiv.org/abs/2203.01077)

    本研究介绍了一种基于神经网络的设备上学习方法，针对边缘人工智能应用中的环境因素对准确性造成的影响进行了解决。通过重新训练，在嘈杂环境下显著提高了异常检测的准确性，同时节约了低功耗设备的计算和通信成本。

    

    在真实世界的边缘人工智能应用中，其准确性经常受到各种环境因素的影响，如噪声、传感器的位置/校准和时间相关的变化。本文介绍了一种基于神经网络的设备上学习方法，以解决这个问题而不需要深入了解。我们的方法与事实上的反向传播训练有很大区别，而是专为低端边缘设备量身定制。本文介绍了其算法和在由树莓派Pico和低功耗无线模块组成的无线传感器节点上的实现。通过使用旋转机器的振动模式进行实验证明，通过设备上学习的重新训练在嘈杂环境下显著提高了异常检测的准确性，同时节约了低功耗设备的计算和通信成本。

    In real-world edge AI applications, their accuracy is often affected by various environmental factors, such as noises, location/calibration of sensors, and time-related changes. This article introduces a neural network based on-device learning approach to address this issue without going deep. Our approach is quite different from de facto backpropagation based training but tailored for low-end edge devices. This article introduces its algorithm and implementation on a wireless sensor node consisting of Raspberry Pi Pico and low-power wireless module. Experiments using vibration patterns of rotating machines demonstrate that retraining by the on-device learning significantly improves an anomaly detection accuracy at a noisy environment while saving computation and communication costs for low power.
    
[^36]: 用于痴呆监测和诊断的纵向多模态数据集

    A Longitudinal Multi-modal Dataset for Dementia Monitoring and Diagnosis. (arXiv:2109.01537v1 [cs.CL] CROSS LISTED)

    [http://arxiv.org/abs/2109.01537](http://arxiv.org/abs/2109.01537)

    该论文提出了一个纵向多模态数据集，用于痴呆监测和诊断。通过分析语言、言语和语用指标，可以区分神经退行性疾病患者和对照组，从而为痴呆研究提供了宝贵的资源。

    

    痴呆是一系列神经退行性疾病，影响越来越多的全球老龄人口的记忆和认知能力。自动化分析语言、言语和语用指标作为认知衰退的潜在指标日益受到关注。在这里，我们提出了一个新颖的纵向多模态数据集，该数据集在自然环境下收集了轻度痴呆患者和配对的年龄匹配对照组的数据，时间跨度为几个月。多模态数据包括口头会话，其中的一部分被转录，以及输入和书写的思考内容，以及相关的非语言信息，如笔画和按键。我们详细描述了该数据集，并着重讨论了使用语音模态的任务。后者涉及利用数据的纵向特性来区分对照组和痴呆患者。我们的实验显示，会话间语音的变化在不同的会话之间存在显著差异。

    Dementia is a family of neurogenerative conditions affecting memory and cognition in an increasing number of individuals in our globally aging population. Automated analysis of language, speech and paralinguistic indicators have been gaining popularity as potential indicators of cognitive decline. Here we propose a novel longitudinal multi-modal dataset collected from people with mild dementia and age matched controls over a period of several months in a natural setting. The multi-modal data consists of spoken conversations, a subset of which are transcribed, as well as typed and written thoughts and associated extra-linguistic information such as pen strokes and keystrokes. We describe the dataset in detail and proceed to focus on a task using the speech modality. The latter involves distinguishing controls from people with dementia by exploiting the longitudinal nature of the data. Our experiments showed significant differences in how the speech varied from session to session in the 
    

