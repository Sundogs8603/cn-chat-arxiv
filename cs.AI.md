# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Leaving the Nest: Going Beyond Local Loss Functions for Predict-Then-Optimize.](http://arxiv.org/abs/2305.16830) | 本文提出了一种避免限制性假设的解决方案，利用机器学习模型的特性来提高学习损失函数的样本效率，在预测优化问题中实现了最先进的结果。 |
| [^2] | [Prompt- and Trait Relation-aware Cross-prompt Essay Trait Scoring.](http://arxiv.org/abs/2305.16826) | 本研究提出了一种跨Prompt的作文Trait评分模型，通过作文提示关注和Traint相似性loss，有效解决了作文提示不同的问题，提高了自动化作文评分的准确性和可靠性。 |
| [^3] | [HUB: Guiding Learned Optimizers with Continuous Prompt Tuning.](http://arxiv.org/abs/2305.16823) | 本文提出了一种名为HUB的混合更新策略，通过结合学习优化器和手工设计的优化器，提高了学习优化器泛化性能。 |
| [^4] | [Domain Aligned Prefix Averaging for Domain Generalization in Abstractive Summarization.](http://arxiv.org/abs/2305.16820) | 本文提出了一种轻量级、基于加权平均的领域对齐前缀平均方法（DAPA），用于抽象摘要中的领域泛化，实现了有效的源域扩展以提高性能。 |
| [^5] | [Trust-Aware Resilient Control and Coordination of Connected and Automated Vehicles.](http://arxiv.org/abs/2305.16818) | 本文提出了一种基于信任框架的鲁棒控制和协调方案，从恶意代理的角度识别关键对抗目标，有效避免碰撞和交通堵塞。同时提出了一种使用信任框架的攻击检测和缓解措施。 |
| [^6] | [GenQ: Automated Question Generation to Support Caregivers While Reading Stories with Children.](http://arxiv.org/abs/2305.16809) | 本研究设计了一个智能辅导系统（GenQ），可以根据照顾者和孩子之间的对话促进孩子的阅读理解能力，并通过考虑文化背景和语境变化以提高系统效果。 |
| [^7] | [Do GPTs Produce Less Literal Translations?.](http://arxiv.org/abs/2305.16806) | 本研究比较了GPT和NMT生成翻译的文字积极度差异，发现GPT翻译更不准确，但在MT质量评估指标上表现出相似或更好的分数。 |
| [^8] | [Schema-Guided User Satisfaction Modeling for Task-Oriented Dialogues.](http://arxiv.org/abs/2305.16798) | 本文提出了一种新的基于模式的用户满意度建模框架SG-USM，它特别模拟了系统程度的满足用户关于任务属性的偏好程度，以预测用户的满意度水平。 |
| [^9] | [Incorporating Distributions of Discourse Structure for Long Document Abstractive Summarization.](http://arxiv.org/abs/2305.16784) | 本文提出了一种名为'RSTformer'的摘要模型，该模型全面融合了话语关系类型和不确定性，并以修辞结构理论为基础，经过严格评估，表现明显优于现有的模型。 |
| [^10] | [Towards a Common Understanding of Contributing Factors for Cross-Lingual Transfer in Multilingual Language Models: A Review.](http://arxiv.org/abs/2305.16768) | 本文对多语言语言模型 (MLLMs)的跨语言转移能力的不同因素进行了调查和综述，将这些因素分成五类并提供了过去研究的经验证据。本文的工作旨在全面背景和统一MLLMs跨语言转移的现有研究流。 |
| [^11] | [Can large language models generate salient negative statements?.](http://arxiv.org/abs/2305.16755) | 本研究探讨了大型语言模型生成真实实体的显著负面陈述的能力，在不同领域中进行了评估，结果发现大型语言模型在处理否定陈述中的事实概念上仍有困难。 |
| [^12] | [ElectrodeNet -- A Deep Learning Based Sound Coding Strategy for Cochlear Implants.](http://arxiv.org/abs/2305.16753) | 本文提出了一种基于深度学习的电极编码策略，ElectrodeNet，以提高人工耳蜗用户的语音感知能力，具备有望替代传统的信封检测方法和CS通道选择方法的潜力。 |
| [^13] | [MULTIGAIN 2.0: MDP controller synthesis for multiple mean-payoff, LTL and steady-state constraints.](http://arxiv.org/abs/2305.16752) | MULTIGAIN 2.0是一个基于PRISM的控制器综合工具，扩展了MultiGain的多维能力，可对具有多维约束的概率系统进行控制器的形式验证和综合，并提供了二维和三维 Pareto 曲线的可视化能力。 |
| [^14] | [A Decentralized Spike-based Learning Framework for Sequential Capture in Discrete Perimeter Defense Problem.](http://arxiv.org/abs/2305.16748) | 本文提出了一种针对离散周界防御问题的分散脉冲学习框架，有效解决了团队防御者保护领土的问题，每个防御者含有自己的MLC-SEFRON网络，从而实现分散独立训练，输入信息来源于防御者和入侵者的时空信息。 |
| [^15] | [Parameter-Efficient Fine-Tuning without Introducing New Latency.](http://arxiv.org/abs/2305.16742) | 本文提出了一种参数高效微调的方法，以任务不可知的方式生成稀疏掩码，无需添加新参数，避免了额外的推断延迟，并超过了现有方法的效果。 |
| [^16] | [AMPERE: AMR-Aware Prefix for Generation-Based Event Argument Extraction Model.](http://arxiv.org/abs/2305.16734) | 本论文提出了一种名为AMPERE的方法，面向AMR的前缀生成事件论元抽取模型，该模型成功引入了AMR的信息，提升了生成式模型的性能和泛化能力。 |
| [^17] | [A novel application for real-time arrhythmia detection using YOLOv8.](http://arxiv.org/abs/2305.16727) | 本文提出了一种使用YOLOv8算法进行心律失常检测的新应用程序，其模型能够实现持续监测，并以高准确性进行实时心律失常检测。 |
| [^18] | [Code-Switched Text Synthesis in Unseen Language Pairs.](http://arxiv.org/abs/2305.16724) | 本文介绍了GLOSS模型，旨在解决在缺乏训练数据的情况下合成混合代码文本的问题，并且可以推广到更广泛的语言对。该模型在四个未见过的语言对上的实验中优于其他基线模型和在单语文本上运行的生成模型。 |
| [^19] | [A Hierarchical Approach to Population Training for Human-AI Collaboration.](http://arxiv.org/abs/2305.16708) | 本论文提出了一种基于层次思维的人工智能协同训练方法，通过引入层次强化学习方法，代理能够根据当前合作伙伴自动切换最佳响应策略，从而显著提高了代理与新合作伙伴的适应性。 |
| [^20] | [PIP: Parse-Instructed Prefix for Syntactically Controlled Paraphrase Generation.](http://arxiv.org/abs/2305.16701) | 使用Parse-Instructed Prefix的语法控制释义生成的计算成本降低了10倍，并在两个benchmark上达到了最先进的性能表现。 |
| [^21] | [Applying Interdisciplinary Frameworks to Understand Algorithmic Decision-Making.](http://arxiv.org/abs/2305.16700) | 这篇文章探讨了采用跨学科方法理解算法决策制定。研究者认为应采用学习科学的实践方法来解释ADM系统，而定性任务研究结果显示使用“六个理解方面”框架可以提高解释ADM系统的有效性。 |
| [^22] | [Automatic Tuning of Loss Trade-offs without Hyper-parameter Search in End-to-End Zero-Shot Speech Synthesis.](http://arxiv.org/abs/2305.16699) | 本论文提出在零样本语音合成中自动调整损失权衡的方法，无需超参数搜索。通过此方法，VITS-based模型的性能表现得到了显著提升，达到了最新的领先性能。 |
| [^23] | [Balanced Supervised Contrastive Learning for Few-Shot Class-Incremental Learning.](http://arxiv.org/abs/2305.16687) | 该论文提出了一种平衡监督对比学习方法来解决少样本类增量学习中的平衡性问题，并且在三个数据集上的表现均非常优秀。 |
| [^24] | [Multiview Identifiers Enhanced Generative Retrieval.](http://arxiv.org/abs/2305.16675) | 该论文提出了一种新型的基于合成标识符的多视角标识符来增强生成式检索，从而提高了检索结果的准确性和多样性。 |
| [^25] | [A Unified Approach for Maximizing Continuous DR-submodular Functions.](http://arxiv.org/abs/2305.16671) | 本文提出了一种适用于一系列设置和 Oracle 访问类型的统一方法，用于最大化连续 DR-submodular 函数，为 16 种情况中的 9 种提供了新的/改进的结果，并且针对基于随机函数值的 Oracle 取得了第一个适用于随机 DR-submodular 函数的后悔界限。 |
| [^26] | [Gender, Smoking History and Age Prediction from Laryngeal Images.](http://arxiv.org/abs/2305.16661) | 首次采用深度学习模型预测喉镜图像中的患者基本信息，从而提高检测器模型的性能。 |
| [^27] | [AdaPlanner: Adaptive Planning from Feedback with Language Models.](http://arxiv.org/abs/2305.16653) | LLM代理可以通过Adaplanner自适应改进自己的计划以应对环境反馈，为此提出计划内外的改进策略以及代码风格的LLM提示结构和技能发现机制。 |
| [^28] | [Language Models Can Improve Event Prediction by Few-Shot Abductive Reasoning.](http://arxiv.org/abs/2305.16646) | 本文提出了一个建模和预测框架，在少样本情况下使用语言模型的绝对推理能力来提高事件序列模型的预测精度，经过实验证实可以明显优于最先进的事件序列模型。 |
| [^29] | [Evaluation of Question Generation Needs More References.](http://arxiv.org/abs/2305.16626) | 评估QG方法需要更多的参考文献来提高其有效性，单个参考不足以全面评估其潜力。使用多个参考文献的评估方法可以更好地与人类评估相关联。 |
| [^30] | [Set-based Neural Network Encoding.](http://arxiv.org/abs/2305.16625) | 提出了一种能够集合化地编码神经网络参数的神经网络权重编码方法，并引入了一种逐层编码方案来考虑神经网络的分层计算结构。同时引入了“pad-chunk-encode”流水线进行神经网络层的高效编码处理，还提出了新的神经网络泛化性能预测任务。 |
| [^31] | [A Reminder of its Brittleness: Language Reward Shaping May Hinder Learning for Instruction Following Agents.](http://arxiv.org/abs/2305.16621) | 该论文研究表明，对于复杂指令遵循代理的学习，语言奖励塑造技术可能会影响代理程序的学习，其中表面上的成功可能是脆弱的。 |
| [^32] | [Physical Deep Reinforcement Learning: Safety and Unknown Unknowns.](http://arxiv.org/abs/2305.16614) | 本文提出了Phy-DRL，这是一个物理模型调整的深度强化学习框架。该框架有三个创新点，它们分别是: i)前瞻性的未知未知训练，ii)结合残差控制，以及iii)基于物理模型的神经网络编辑。Phy-DRL能够容忍未知干扰，保证安全和稳定，同时遵守Bellman方程和奖励相关的物理知识。 |
| [^33] | [NLP Reproducibility For All: Understanding Experiences of Beginners.](http://arxiv.org/abs/2305.16579) | 通过对93名NLP初学者的调查，发现研究作者提供完整文档、更好的代码实践和更易于获取的数据文件是初学者成功复现最近NLP论文结果的关键，建议NLP研究人员注重这些方面，更好地支持初学者。 |
| [^34] | [Digital Twin-Based 3D Map Management for Edge-Assisted Mobile Augmented Reality.](http://arxiv.org/abs/2305.16571) | 本文提出了一种基于数字孪生的方案，用于辅助移动增强现实的三维地图管理，可显著降低姿态估计的不确定性，可以在高度动态的环境中快速提供自适应地图管理策略。 |
| [^35] | [LANISTR: Multimodal Learning from Structured and Unstructured Data.](http://arxiv.org/abs/2305.16556) | LANISTR是一个新颖的基于注意力机制的框架，可从结构化和非结构化数据中进行学习，在挑战性数据集上表现优异。 |
| [^36] | [Annotating and Detecting Fine-grained Factual Errors for Dialogue Summarization.](http://arxiv.org/abs/2305.16548) | 本论文提出第一个注释有细粒度事实错误的对话摘要数据集，探索了细粒度事实错误检测作为一个句子级多标签分类问题的挑战，并提出了一种无监督模型，取得了和 SOTA 模型相近的效果。 |
| [^37] | [On the Tool Manipulation Capability of Open-source Large Language Models.](http://arxiv.org/abs/2305.16504) | 本研究探讨了如何通过训练使用示例、上下文演示和生成样式规则来加强开源LLMs以达到与封闭型API的工具操作性能同等甚至更优的效果，并通过ToolBench测试得出了实验结果，同时本文还证明了改进的开源LLMs的鲁棒性。 |
| [^38] | [AD-NEV: A Scalable Multi-level Neuroevolution Framework for Multivariate Anomaly Detection.](http://arxiv.org/abs/2305.16497) | AD-NEv提出了一种可扩展的多级优化神经进化框架，用于多元时间序列异常检测，通过协同优化特征子空间、模型架构和模型权重的方法，表现出比当前最先进的方法更好的检测精度和计算效率。 |
| [^39] | [Diffusion-Based Adversarial Sample Generation for Improved Stealthiness and Controllability.](http://arxiv.org/abs/2305.16494) | 本文提出了一个名为Diff-PGD的新框架，用于生成接近原始数据分布、逼真的对抗样本，具有较好的隐蔽性和对抗强度可调性。 |
| [^40] | [EgoHumans: An Egocentric 3D Multi-Human Benchmark.](http://arxiv.org/abs/2305.16487) | EgoHumans是一个全面的自我中心多人基准数据集，旨在推进自我中心的人类三维姿态估计和跟踪的最新进展，可以支持各种任务，包括人类检测、跟踪、2D/3D姿态估计和网格恢复等，并且能够捕捉具有挑战性和无核编排的多人场景。 |
| [^41] | [Batch Model Consolidation: A Multi-Task Model Consolidation Framework.](http://arxiv.org/abs/2305.16484) | 本文提出了批次模型整合（BMC）来支持更现实的连续学习，它通过在正则化阶段训练多个专家模型来学习一组不相交的任务，并在整合阶段将多个专家模型整合为一个模型。 |
| [^42] | [Alert of the Second Decision-maker: An Introduction to Human-AI Conflict.](http://arxiv.org/abs/2305.16477) | 本文介绍了人工智能冲突的概念、原因、测量方法和风险评估，突出显示人工智能是潜在的第二决策者，冲突风险是显著的，不能被忽视。 |
| [^43] | [Optimized Custom Dataset for Efficient Detection of Underwater Trash.](http://arxiv.org/abs/2305.16460) | 本文提出了一种自定义数据集和有效检测方法，旨在通过增加垃圾实例的多样性，在深入水下环境中提高其检测精度。 |
| [^44] | [KeyPosS: Plug-and-Play Facial Landmark Detection through GPS-Inspired True-Range Multilateration.](http://arxiv.org/abs/2305.16437) | KeyPosS是一种面部标记检测框架，采用真实距离多边定位算法实现快速而准确的检测，避免了传统方法中的计算负担和量化误差问题。 |
| [^45] | [Neural (Tangent Kernel) Collapse.](http://arxiv.org/abs/2305.16427) | 本文介绍了神经切向核（NTK）和神经崩溃（NC）之间的关系，证明了在具有块状NTK的DNN中会出现NC，并通过大规模实验支持理论的正确性。 |
| [^46] | [SketchOGD: Memory-Efficient Continual Learning.](http://arxiv.org/abs/2305.16424) | SketchOGD提出了一种内存高效的解决灾难性遗忘的方法，通过采用在线草图算法，将模型梯度压缩为固定大小的矩阵，从而改进了现有的算法——正交梯度下降（OGD）。 |
| [^47] | [NODDLE: Node2vec based deep learning model for link prediction.](http://arxiv.org/abs/2305.16421) | NODDLE是一种用于链路预测的深度学习模型，结合了node2vec提取的特征和四层隐藏神经网络，并利用自适应学习优化器提高性能。 |
| [^48] | [GrowSP: Unsupervised Semantic Segmentation of 3D Point Clouds.](http://arxiv.org/abs/2305.16404) | 本文提出了一种名为GrowSP的无监督方法来进行3D场景中每个点复杂语义类别的识别和分割，方法通过逐步增长超级点的大小来发现3D语义元素，并优于所有无监督基线。 |
| [^49] | [Are Diffusion Models Vision-And-Language Reasoners?.](http://arxiv.org/abs/2305.16397) | 本文针对扩散-语言图像生成模型进行转换和评估，介绍了生成-鉴别评估基准(GDBench)基于7个视觉语言复杂任务，并发现转换后的模型在组合性任务方面的表现优于CLIP，通过微调可提高其组合性能。 |
| [^50] | [Scan and Snap: Understanding Training Dynamics and Token Composition in 1-layer Transformer.](http://arxiv.org/abs/2305.16380) | 本文分析了1层Transformer在下一个标记预测任务中的SGD训练动态，证明了自我关注层充当了“区分性扫描算法”，从而逐步关注到相关标记并排除不相关的标记，总结相关信息在编码表示中。同时研究了标记频率、上下文和初始化自我关注层等对Transformer性能的影响。 |
| [^51] | [Learning Better with Less: Effective Augmentation for Sample-Efficient Visual Reinforcement Learning.](http://arxiv.org/abs/2305.16379) | 本研究发现，对于数据增强在视觉强化学习中的有效性，空间多样性和轻微的困难度不可或缺。并提出了一种新的DA操作——Rand PR，它提供了丰富的空间多样性和最小的困难度，已经在多种数据上得到了有效性验证。 |
| [^52] | [Sim-Suction: Learning a Suction Grasp Policy for Cluttered Environments Using a Synthetic Benchmark.](http://arxiv.org/abs/2305.16378) | Sim-Suction 提出了一种新颖的物体感知吸盘抓取策略，使用基于合成数据集的方法解决了在杂乱环境下感兴趣的物体与周围环境之间关系的问题。 |
| [^53] | [DeepGate2: Functionality-Aware Circuit Representation Learning.](http://arxiv.org/abs/2305.16373) | 本文介绍了DeepGate2, 一个新的功能感知学习框架，其通过利用成对真值表差异作为训练监督，明确考虑电路功能，来提高电路表示学习的学习效果和效率。 |
| [^54] | [Metrics for quantifying isotropy in high dimensional unsupervised clustering tasks in a materials context.](http://arxiv.org/abs/2305.16372) | 该论文提出了一种新的对聚类等向性度量的实现方法，并使用分数各向异性扩展了这些度量来检查聚类的平均等向性。通过量化不同材料结构数据库表示的核逼近函数对结果聚类的影响，演示了这种度量的实际应用。 |
| [^55] | [Stecformer: Spatio-temporal Encoding Cascaded Transformer for Multivariate Long-term Time Series Forecasting.](http://arxiv.org/abs/2305.16370) | Stecformer是一种处理多元长期时间序列预测的方法，提出了一种有效的空间-时间编码器和级联解码预测器（CDP），在多个基准数据集上实现了最先进的性能，为多元长期时间序列预测提供了一种有前途的方法。 |
| [^56] | [A Semi-Automated Corner Case Detection and Evaluation Pipeline.](http://arxiv.org/abs/2305.16369) | 该论文提出了一种半自动化的流程，将集体专家知识描述转换为本体论，实现了从数据集中提取角落情况和对网络进行评估的目的。 |
| [^57] | [Role-Play with Large Language Models.](http://arxiv.org/abs/2305.16367) | 本文将对话代理行为描述为角色扮演，以避免赋予其人类特征，在此基础上研究代理行为中的欺骗和自我意识。 |
| [^58] | [Decomposing the Enigma: Subgoal-based Demonstration Learning for Formal Theorem Proving.](http://arxiv.org/abs/2305.16366) | 本文提出了一个基于子目标的演示学习框架，通过将基于子目标的学习方法与扩散模型相结合，提高演示的可理解性，并提高LLMs在形式定理证明中的吞吐量。 |
| [^59] | [An Experimental Investigation into the Evaluation of Explainability Methods.](http://arxiv.org/abs/2305.16361) | 这篇论文比较了14种不同的评估指标在对9种目前最先进的可解释性人工智能（XAI）方法和三种虚拟方法进行应用时的效果，给出了高度相关结果，指出了存在潜在冗余。此外，还展示了基线超参数对评估指标值产生显著影响。 |
| [^60] | [Differentiable Clustering with Perturbed Spanning Forests.](http://arxiv.org/abs/2305.16358) | 介绍了一种基于扰动生成树的可微聚类方法，依赖于线性规划解的随机扰动，具有良好的性能。 |
| [^61] | [Betray Oneself: A Novel Audio DeepFake Detection Model via Mono-to-Stereo Conversion.](http://arxiv.org/abs/2305.16353) | 本文提出了一种名为M2S-ADD的新型ADD模型，通过单声道转立体声技术发现伪造音频中的真实性线索，显著提高了检测性能。 |
| [^62] | [WeiAvg: Federated Learning Model Aggregation Promoting Data Diversity.](http://arxiv.org/abs/2305.16351) | 本文提出了一种名为WeiAvg的联邦学习模型聚合方法，通过强调来自高多样性客户端的更新并减少来自低多样性客户端的影响，提高了联邦模型的质量和性能。 |
| [^63] | [Lexinvariant Language Models.](http://arxiv.org/abs/2305.16349) | 本文讨论了一种新型的语言模型，称为Lexinvariant语言模型，该模型不需要任何固定标记嵌入，完全依赖上下文中标记的共现和重复。作者证明可以构建一个lexinvariant LM，以多项式方式与上下文长度成比例地收敛到真实语言模型，其常量因子在词汇表大小下为次线性。 |
| [^64] | [Artificial Intelligence-Based Methods for Precision Medicine: Diabetes Risk Prediction.](http://arxiv.org/abs/2305.16346) | 本文分析了现有文献中基于人工智能的糖尿病风险预测模型，在单模态和多模态模型中均表现突出，但外部验证有限，解释性方法需要改进。 |
| [^65] | [Leveraging LLMs for KPIs Retrieval from Hybrid Long-Document: A Comprehensive Framework and Dataset.](http://arxiv.org/abs/2305.16344) | 本文提出了一个自动化财务信息提取的框架（AFIE），用于提取混合长文档中的关键业绩指标（KPI）。该框架利用LLMs增强了财务报告信息的理解和提取能力，并经过了广泛的实验验证，证明其在GPT-3.5和GPT-4上的有效性，相对于朴素方法，平均精度提高了53.94％和33.77％。 |
| [^66] | [A Distributed Automatic Domain-Specific Multi-Word Term Recognition Architecture using Spark Ecosystem.](http://arxiv.org/abs/2305.16343) | 本论文提出了一种基于Spark生态系统的分布式架构，可自动提取领域特定术语，经实验证明在术语提取准确性方面取得最先进的结果。 |
| [^67] | [InterFormer: Interactive Local and Global Features Fusion for Automatic Speech Recognition.](http://arxiv.org/abs/2305.16342) | 本文提出了InterFormer，用于交互式局部和全局特征融合，以学习更好的ASR表示。通过组合卷积块和变形器块，以及引入BFIM和SFM模块，实现了局部和全局特征的交互和融合，取得了在公共ASR数据集上优异的性能。 |
| [^68] | [TaxoKnow: Taxonomy as Prior Knowledge in the Loss Function of Multi-class Classification.](http://arxiv.org/abs/2305.16341) | 本文研究在平面分类器的学习算法中集成层次分类作为先验知识的有效性，实验结果表明先验知识可以显著提高学习者的性能，并在半监督和完全监督的情况下都获得了不错的结果。 |
| [^69] | [Segmented Recurrent Transformer: An Efficient Sequence-to-Sequence Model.](http://arxiv.org/abs/2305.16340) | 本文提出了一种分段循环Transformer（SRformer）来减少计算/内存成本，并使用RAF层处理跨段的信息，从而提高序列处理能力。 |
| [^70] | [Don't Trust GPT When Your Question Is Not In English.](http://arxiv.org/abs/2305.16339) | 在多语言环境下，GPT-3表现较差，特别是当问题不是用英语提出时。这与模型的训练数据和输入问题的语言差异有关。 |
| [^71] | [Think Before You Act: Decision Transformers with Internal Working Memory.](http://arxiv.org/abs/2305.16338) | 该论文提出了具有内部工作记忆模块的决策Transformer方法，以解决使用大型语言模型的决策代理在处理新任务上性能低下的问题。所提出的方法改善了训练效率和泛化能力，并进一步增强了转化决策制定代理对新任务的适应性。 |
| [^72] | [Robust Representation Learning with Reliable Pseudo-labels Generation via Self-Adaptive Optimal Transport for Short Text Clustering.](http://arxiv.org/abs/2305.16335) | 本文提出了一种健壮短文本聚类（RSTC）模型，通过自适应最优输运的伪标签生成，以及基于类和实例的对比学习的健壮表示学习，帮助提高对不平衡和噪音数据的鲁棒性。 |
| [^73] | [OlaGPT: Empowering LLMs With Human-like Problem-Solving Abilities.](http://arxiv.org/abs/2305.16334) | OlaGPT是一种新颖的智能框架，能够模拟人类在解决复杂推理问题时所采用的各种认知能力和与工具、知识和外部环境信息的交互，可以让大型语言模型具备类人的问题解决能力。 |
| [^74] | [Text Generation with Speech Synthesis for ASR Data Augmentation.](http://arxiv.org/abs/2305.16333) | 本研究探索文本增广对ASR的影响，使用大规模预训练的神经网络来生成合成文本，并通过文本到语音系统转换为合成语音，实验发现，使用神经网络的文本增广方法能够有效提高ASR准确度，可以作为改进ASR系统的一种可行工具。 |
| [^75] | [Large language models in biomedical natural language processing: benchmarks, baselines, and recommendations.](http://arxiv.org/abs/2305.16326) | 本文研究了GPT-3和GPT-4在生物医学自然语言处理中的表现，分析了它们可能产生的错误类型，并提供了使用这些模型的建议。 |
| [^76] | [Efficient Bound of Lipschitz Constant for Convolutional Layers by Gram Iteration.](http://arxiv.org/abs/2305.16173) | 本文提出了一种基于循环矩阵和格拉姆迭代的方法，用于高效估计卷积神经网络中的Lipschitz常数上界。该方法精确、快速、可微分，并展现了超线性收敛。在实验上表现出较高的精度、计算成本和可扩展性，在利普希茨正则化方面也取得了具有竞争力的结果。 |
| [^77] | [Unifying gradient regularization for Heterogeneous Graph Neural Networks.](http://arxiv.org/abs/2305.15811) | 本研究提出了一种新的梯度正则化方法Grug，旨在统一HGNN中的图形拓扑和节点特征的正则化，并解决了过度平滑、非鲁棒性等问题，综合效果和效率优于几种现有方法。 |
| [^78] | [A Simple and Effective Framework for Strict Zero-Shot Hierarchical Classification.](http://arxiv.org/abs/2305.15282) | 本研究提出了一种蕴含-矛盾预测方法，与大型语言模型结合，用于解决分层数据集中的零样例分类问题，成功实现了严格零样例分层分类。 |
| [^79] | [L-CAD: Language-based Colorization with Any-level Descriptions.](http://arxiv.org/abs/2305.15217) | 本文提出了一个模型，可依据用户提供的任意级别的自然语言描述，生成合理且视觉上令人愉悦的彩色化效果。通过利用跨模态生成模型进行语言理解和颜色先验知识，结合新型采样策略和模块设计，实现了实例感知的彩色化效果。 |
| [^80] | [Evaluating OpenAI's Whisper ASR for Punctuation Prediction and Topic Modeling of life histories of the Museum of the Person.](http://arxiv.org/abs/2305.14580) | 本文首次对葡萄牙语中的Whisper ASR进行了标点符号预测方面的研究，并为标点符号预测在主题建模中的应用提供了有益的实验评估。 |
| [^81] | [Sequence Modeling is a Robust Contender for Offline Reinforcement Learning.](http://arxiv.org/abs/2305.14550) | 序列建模是离线强化学习中比Q-Learning和Imitation Learning更适合在稀疏奖励和低质量数据设置下的选择，在任务范围增加时，序列建模和模仿学习更可取。 |
| [^82] | [SPEECH: Structured Prediction with Energy-Based Event-Centric Hyperspheres.](http://arxiv.org/abs/2305.13617) | 这篇论文提出了一种称为SPEECH的模型，它使用能量建模来表示复杂的事件结构，并使用超球来表示事件类别。实验结果表明，SPEECH在事件检测和事件关系抽取任务中表现出卓越的性能。 |
| [^83] | [Gene Set Summarization using Large Language Models.](http://arxiv.org/abs/2305.13338) | 该论文介绍了一种使用大型语言模型来对基因集进行函数概括的方法，名为SPINDOCTOR，可以提供比传统方法更好的性能和可解释性。 |
| [^84] | [Coarse-to-Fine: a Hierarchical Diffusion Model for Molecule Generation in 3D.](http://arxiv.org/abs/2305.13266) | 该论文提出了一种粗到细的方法来解决分子生成中的组合优化问题，并采用分层扩散模型和HIPER算法生成结构的有效性和多样性，表现优于现有方法。 |
| [^85] | [Bandit Submodular Maximization for Multi-Robot Coordination in Unpredictable and Partially Observable Environments.](http://arxiv.org/abs/2305.12795) | 本文提出了一种在未知演化且只能部分观测的环境下采用赌博反馈和有界跟踪遗憾的次模协调算法，以解决多机器人协作问题，并适用于目标跟踪、环境映射和区域监测等复杂任务。 |
| [^86] | [On the Efficacy and Noise-Robustness of Jointly Learned Speech Emotion and Automatic Speech Recognition.](http://arxiv.org/abs/2305.12540) | 本论文研究了联合学习ASR和SER的多任务学习方法，并证明在低资源环境下不仅在SER中取得了显著提升，同时也提高了ASR的性能，并且在嘈杂环境中，联合训练得到的模型比独立训练的模型更具噪声鲁棒性 |
| [^87] | [Multi-Head State Space Model for Speech Recognition.](http://arxiv.org/abs/2305.12498) | 本文提出了一种多头状态空间（MH-SSM）模型，它能够用于语音识别任务并在LibriSpeech数据集上表现出的新的性能，是变压器变换器的优秀替代方案。同时, MH-SSM层的引入也提高了变压器块的性能，达到了现有最新水平。 |
| [^88] | [Explaining V1 Properties with a Biologically Constrained Deep Learning Architecture.](http://arxiv.org/abs/2305.11275) | 该论文使用生物特性构建CNNs架构，成功解释V1神经活动特性。 |
| [^89] | [Uncertainty Guided Label Denoising for Document-level Distant Relation Extraction.](http://arxiv.org/abs/2305.11029) | 本文提出了一种使用不确定性引导的标签去噪技术，可以有效准确地在文档级远程关系抽取中选择可信的伪标签，提高了性能表现，并在DocRED数据集上实现了新的最佳性能。 |
| [^90] | [X-IQE: eXplainable Image Quality Evaluation for Text-to-Image Generation with Visual Large Language Models.](http://arxiv.org/abs/2305.10843) | 本文提出了一种名为X-IQE的图像质量评估方法，使用视觉大语言模型对文本到图像生成进行评估，并生成文本解释。它具有区分真实和生成图像、评估文本-图像对齐和评估图像美学等优点，显著增强了深度图像质量评估模型的透明度和可解释性。 |
| [^91] | [Personality Understanding of Fictional Characters during Book Reading.](http://arxiv.org/abs/2305.10156) | 本文提出了一个NLP领域内尚未研究的问题：情景和细致地理解小说人物个性，并提供了第一个标记数据集PersoNet来解决这个问题。 |
| [^92] | [sustain.AI: a Recommender System to analyze Sustainability Reports.](http://arxiv.org/abs/2305.08711) | sustain.AI是一个智能的、上下文感知的推荐系统，可以帮助审计师、金融投资者以及广大公众高效地分析公司的可持续性报告，并通过与GRI标准匹配来提供更好的推荐精度。 |
| [^93] | [PALR: Personalization Aware LLMs for Recommendation.](http://arxiv.org/abs/2305.07622) | 本文提出了一个称为PALR的框架，将用户的历史行为与LLMs相结合，生成用户喜欢的物品的推荐。与现有的推荐方法相比，我们的PALR框架实现了最先进的性能。 |
| [^94] | [Distilling Script Knowledge from Large Language Models for Constrained Language Planning.](http://arxiv.org/abs/2305.05252) | 本文首次定义了受限语言规划任务，提出了一种方法来提高大型语言模型在这个任务中的表现，并提取了一个新颖的受限语言规划数据集。实验证明该方法显著提高了其在约束忠实度方面的能力，并对赋予较小的语言模型受限语言规划能力非常有效。 |
| [^95] | [ANALOGICAL - A New Benchmark for Analogy of Long Text for Large Language Models.](http://arxiv.org/abs/2305.05050) | 本文介绍了一种名为“ANALOGICAL”的新型基准，用以内在评估LLMs在长文本类比中的能力，包括六个复杂级别的长文本类比分类，并使用13个数据集和三种距离度量方法来评估8个LLMs在语义向量空间中识别类比对的能力。 |
| [^96] | [A Systematic Study of Knowledge Distillation for Natural Language Generation with Pseudo-Target Training.](http://arxiv.org/abs/2305.02031) | 本文研究如何压缩自然语言生成模型以适应实际应用需求，通过使用知识蒸馏和伪目标训练技术针对特定的自然语言生成任务和数据集进行优化，并取得了显著效果。 |
| [^97] | [FIREBALL: A Dataset of Dungeons and Dragons Actual-Play with Structured Game State Information.](http://arxiv.org/abs/2305.01528) | 本研究介绍了一份包含真实游戏状态信息的Dungeons & Dragons实际游戏数据集FIREBALL，它可以改善自然语言生成的质量。此外，LLMs可以使用FIREBALL中的游戏状态信息来生成更高质量的游戏回合。 |
| [^98] | [Tree-structured Parzen estimator: Understanding its algorithm components and their roles for better empirical performance.](http://arxiv.org/abs/2304.11127) | 该论文介绍了一种广泛使用的贝叶斯优化方法 Tree-structured Parzen estimator (TPE)，并对其控制参数的作用和算法直觉进行了讨论和分析，提供了一组推荐设置并证明其能够提高TPE的性能表现。 |
| [^99] | [Predicting quantum chemical property with easy-to-obtain geometry via positional denoising.](http://arxiv.org/abs/2304.03724) | 该论文提出了一种方法，利用位置去噪预测易得几何结构的量子化学性质，可以用相对容易获得的几何结构，精确预测性质，在分子性质以及化学反应性质的预测任务中都表现优秀。 |
| [^100] | [Self-Refine: Iterative Refinement with Self-Feedback.](http://arxiv.org/abs/2303.17651) | 自我反馈迭代精炼是一种无需监督学习或加强学习的LLMs初始输出优化方法，优于直接生成，被证实在7个不同任务中表现更好。 |
| [^101] | [A New Policy Iteration Algorithm For Reinforcement Learning in Zero-Sum Markov Games.](http://arxiv.org/abs/2303.09716) | 本文提出了一种适用于零和马尔可夫博弈的简单但有效的策略迭代算法。 |
| [^102] | [A Comprehensive Study on Post-Training Quantization for Large Language Models.](http://arxiv.org/abs/2303.08302) | 本文基于数万个零-shot实验对基于后训练量化的大型语言模型的不同量化组件进行了综合研究，结果发现细粒度量化和后训练量化方法很重要，用粗粒度量化的更高位数比用非常细粒度的更低位数更强大。我们给出了如何为不同大小的\llms利用量化的建议。 |
| [^103] | [GOATS: Goal Sampling Adaptation for Scooping with Curriculum Reinforcement Learning.](http://arxiv.org/abs/2303.05193) | 本文提出了一种名为GOATS的方法，使用目标采样自适应课程强化学习技术，通过插值位置目标和数量目标的分布创建学习过程中的课程来解决机器人舀取任务中的位置目标和水量目标问题，取得了比基线更好的表现。 |
| [^104] | [Hallucinated Adversarial Control for Conservative Offline Policy Evaluation.](http://arxiv.org/abs/2303.01076) | 本文提出了基于幻想对抗控制的HAMBO算法，可用于离线策略评估，并且能够得出有效的策略表现下限估计。 |
| [^105] | [On Feasibility of Server-side Backdoor Attacks on Split Learning.](http://arxiv.org/abs/2302.09578) | 本文研究了在服务器端进行分割学习后门攻击的可行性，提供了两种攻击方法，并证明其即使在多个客户端参与学习且具有不同的数据分布时也是有效的。 |
| [^106] | [PAC-Bayesian Generalization Bounds for Adversarial Generative Models.](http://arxiv.org/abs/2302.08942) | 将PAC-Bayesian理论扩展到生成模型，为基于Wasserstein距离和总变差距离的模型提供了泛化界，为Wasserstein GAN和Energy-Based GAN提供了新的训练目标，并在合成数据集上展示出非虚空泛化界。 |
| [^107] | [SyreaNet: A Physically Guided Underwater Image Enhancement Framework Integrating Synthetic and Real Images.](http://arxiv.org/abs/2302.08269) | 提出了一种名为SyreaNet的水下图像增强框架，通过集成合成和真实数据以及物理引导和新颖的域自适应策略，能够更好地处理各种水下条件，达到了较好的提升效果。 |
| [^108] | [Effective Data Augmentation With Diffusion Models.](http://arxiv.org/abs/2302.07944) | 本文提出了一种利用预训练文本至图像扩散模型参数化的图像到图像转换方法，用于解决数据增强的多样性不足问题，并能够泛化到新视觉概念，从而提高了少样本图像分类和图像识别的性能。 |
| [^109] | [Ground(less) Truth: A Causal Framework for Proxy Labels in Human-Algorithm Decision-Making.](http://arxiv.org/abs/2302.06503) | 本文提出了一个因果框架，解释了在人工智能决策中使用的代理标签可能存在的目标变量偏差，并提出未来研究应强调针对较广泛问题的因果评估。 |
| [^110] | [Riemannian Flow Matching on General Geometries.](http://arxiv.org/abs/2302.03660) | 本文提出了一种名为黎曼流匹配的方法，可以在一般几何上训练连续标准化流，并在高维度数据上具有优势。 |
| [^111] | [Distillation Policy Optimization.](http://arxiv.org/abs/2302.00533) | 本文展示了一种演员-评论家的学习框架，该框架通过蒸馏优势在利用过去经验的同时遵循稳定的在线策略，实现了快速学习并可以适用于广泛的算法类别。 |
| [^112] | [Grounding Language Models to Images for Multimodal Inputs and Outputs.](http://arxiv.org/abs/2301.13823) | 该论文提出一种有效的方法，将仅处理文本的语言模型与图像进行联系，使其能够处理任意交错的图像和文本数据，并生成与检索图像交错的自由形式文本。该方法在环境相关的图像检索和多模态对话等任务中表现十分优异，是利用预训练语言模型解决视觉场景下交互问题的有效解决方案。 |
| [^113] | [Does Federated Learning Really Need Backpropagation?.](http://arxiv.org/abs/2301.12195) | 本文提出一种不需要反向传播的联邦学习框架BAFFLE，该框架使用多个正向过程估计梯度，具有高内存效率，容易适应上传带宽，与硬件优化和模型量化/修剪兼容，适用于受信任的执行环境。 |
| [^114] | [S-Graphs+: Real-time Localization and Mapping leveraging Hierarchical Representations.](http://arxiv.org/abs/2212.11770) | S-Graphs+是一种新型的四层因子图，能够在实时优化中同时建模姿态图和场景图，提高了环境信息的高层次抽象，并提出了新的分割方法来提取环境的房间和楼层信息。 |
| [^115] | [Self-Instruct: Aligning Language Models with Self-Generated Instructions.](http://arxiv.org/abs/2212.10560) | 本论文提出了一种名为Self-Instruct的框架，通过自身生成指导信息来提高预训练语言模型的指令遵循能力。在超自然指令上，我们展示了与InstructGPT-001相同的性能表现，并在原始模型上获得了33%的改进。 |
| [^116] | [Towards Reasoning in Large Language Models: A Survey.](http://arxiv.org/abs/2212.10403) | 本文综述了大型语言模型中的推理研究的现状和未来方向，包括提高和诱导推理能力的技术、评估推理能力的方法和基准，旨在提供一个详细和最新的综述，刺激有意义的讨论和未来的研究。 |
| [^117] | [Rarely a problem? Language models exhibit inverse scaling in their predictions following few-type quantifiers.](http://arxiv.org/abs/2212.08700) | 本文研究了语言模型处理“few-”类型量词的能力，结果显示所有模型对这种量词都表现不佳，且较大的模型表现更差。这种反比例缩放的现象表明大型模型越来愈反映在线人类处理，而不是离线处理。这可能挑战使用语言模型作为自然语言系统基础的做法。 |
| [^118] | [Speeding up Multi-objective Non-hierarchical Hyperparameter Optimization by Task Similarity-Based Meta-Learning for the Tree-structured Parzen Estimator.](http://arxiv.org/abs/2212.06751) | 本文提出了一种基于任务相似度元学习的方法来加速树形结构Parzen估计中的多目标非分层超参数最优化，实现了最先进的性能。 |
| [^119] | [Nonparametric Masked Language Modeling.](http://arxiv.org/abs/2212.01349) | NPM是第一个使用非参数分布替换softmax的遮蔽语言模型，可以更好地处理稀有模式和预测罕见或几乎未见过的单词，并在16项任务上超过了更大的参数模型。 |
| [^120] | [Soft Alignment Objectives for Robust Adaptation of Language Generation.](http://arxiv.org/abs/2211.16550) | 本研究提出了一种基于预测令牌与参考语义相似性的新型训练目标，可以在领域自适应中缓解灾难性遗忘，同时又可以保持调整质量，并且计算成本增加可忽略不计。 |
| [^121] | [c-TPE: Tree-structured Parzen Estimator with Inequality Constraints for Expensive Hyperparameter Optimization.](http://arxiv.org/abs/2211.14411) | 本文提出了约束TPE（c-TPE）方法，是树形Parzen估计器（TPE）的扩展，可有效处理在性能要求之上施加的约束限制，实验证明在81个昂贵的HPO设置中表现出最佳性能排名。 |
| [^122] | [UNSAT Solver Synthesis via Monte Carlo Forest Search.](http://arxiv.org/abs/2211.12581) | 介绍了使用MCFS算法合成UNSAT求解器的方法，算法可用于解决包括SAT公式不可满足性证明、可满足SAT公式解的数量计数和混合整数规划的最优解问题，并利用合成森林构建算法和合成MDP类来避免构建候选树森林的问题。 |
| [^123] | [Towards Robust Low-Resource Fine-Tuning with Multi-View Compressed Representations.](http://arxiv.org/abs/2211.08794) | 本文提出了一种利用多视角压缩表示降低预训练语言模型微调过程中过拟合问题的方法，经过测试在低资源NLP任务中表现良好。 |
| [^124] | [Scalar Invariant Networks with Zero Bias.](http://arxiv.org/abs/2211.08486) | 本文证明了在解决许多图像任务(例如图像分类)时可以忽略偏置，并且零偏置神经网络在实际图像分类任务中表现良好，同时具有标量 (乘法) 不变性，从而在改变对比度时仍能保持预测不变。 |
| [^125] | [Scalable Modular Synthetic Data Generation for Advancing Aerial Autonomy.](http://arxiv.org/abs/2211.05335) | 这篇论文探索了提高空中自主技术进步的一个重要问题：如何生成大量的空中数据集以训练机器学习模型。该研究使用合成数据并利用模拟环境和数据增强来解决现有工具的局限性，提高数据生成工作流程的可扩展性和泛化能力。 |
| [^126] | [RQUGE: Reference-Free Metric for Evaluating Question Generation by Answering the Question.](http://arxiv.org/abs/2211.01482) | RQUGE是一种新的度量标准方法，通过候选问题是否可以回答来评估问题生成质量, 比现有指标更加稳健，可以在不需要人工提供参考问题的情况下使用。 |
| [^127] | [JECC: Commonsense Reasoning Tasks Derived from Interactive Fictions.](http://arxiv.org/abs/2210.15456) | 本文提出了一个新的常识推理数据集JECC，基于人类互动小说游戏的演示步骤。与现有基准不同的是，该数据集评估的是功能性的常识知识规则。因此，为了在这些任务上表现良好，模型需要利用这种常识知识来推断行动的结果，而不是仅仅依赖于记忆事实。 |
| [^128] | [MARLlib: A Scalable Multi-agent Reinforcement Learning Library.](http://arxiv.org/abs/2210.13708) | 本文提出了MARLlib，这是一个全面的MARL算法库，可统一数十种算法。它还超越了当前工作，集成了各种环境接口和提供灵活的参数共享策略。 |
| [^129] | [Instance-Aware Image Completion.](http://arxiv.org/abs/2210.12350) | 本文提出了一个实例感知图像修复模型ImComplete，相比现有方法，它可以幻象出与环境背景相协调的视觉实例，提供了基于语义和结构的像素级指导。 |
| [^130] | [Skill-Based Reinforcement Learning with Intrinsic Reward Matching.](http://arxiv.org/abs/2210.07426) | 该论文提出了内在奖励匹配(IRF)方法，通过技能鉴别器匹配内在和下游任务奖励来确定未见任务的最优技能，提高了系统效率。 |
| [^131] | [Scalable Multi-robot Motion Planning for Congested Environments With Topological Guidance.](http://arxiv.org/abs/2210.07141) | 本研究利用拓扑引导的运动规划方法扩展到多机器人领域。该方法能够高效地规划具有许多狭窄通道的复杂环境中的路径，并找到比其他方法更高质量的解决方案。 |
| [^132] | [Can Language Models Be Specific? How?.](http://arxiv.org/abs/2210.05159) | 本论文提出了一种度量预训练语言模型具体性的方法，并设计了两种基于提示的方法，以改善模型具体性，结果表明，模型的具体性可以得到改善，而无需进行额外的训练。 |
| [^133] | [Hierarchical Adversarial Inverse Reinforcement Learning.](http://arxiv.org/abs/2210.01969) | 本文提出了一种分层对抗逆强化学习算法，能够在复杂任务中学习到具有层次结构的最优策略，比现有的方法更加有效。 |
| [^134] | [Multimedia Generative Script Learning for Task Planning.](http://arxiv.org/abs/2208.12306) | 该论文提出了多媒体生成式脚本学习任务，旨在通过跟踪文本和视觉模态中的历史状态来生成后续步骤，能对未见过的任务具有归纳能力并具有多样性。 |
| [^135] | [Fix-A-Step: Semi-supervised Learning from Uncurated Unlabeled Data.](http://arxiv.org/abs/2208.11870) | Fix-A-Step是一个半监督学习的简化流程，将所有未经筛选的无标签图像视为潜在有用的；增强有标签集的数据，修正梯度下降更新方式可以修复许多常见的深度 SSL 方法，并在医学成像数据集上实现更好的效果。 |
| [^136] | [Everyone's Preference Changes Differently: Weighted Multi-Interest Retrieval Model.](http://arxiv.org/abs/2207.06652) | 本文提出了一种新的加权多兴趣检索模型（Multi-Interest Preference，MIP），通过利用深度学习方法为用户建立多个兴趣嵌入，并将用户在多个兴趣上的偏好进行建模，从而提高候选检索结果的查全率。 |
| [^137] | [Hidden Schema Networks.](http://arxiv.org/abs/2207.03777) | 本文介绍了一种新颖的神经语言模型，通过归纳偏见强制执行明确的关系结构，从而将预训练语言模型的输出表示显式地组成。该模型可以从随机标记序列数据集中发现隐含的真实图，在自然语言数据集中推断出符号网络（模式），直接反映了语言的基础句法结构。 |
| [^138] | [A Methodology and Software Architecture to Support Explainability-by-Design.](http://arxiv.org/abs/2206.06251) | 本文提出了“可解释设计”方法论，针对算法决策的解释提出了一个综合性的解决方案，由三个阶段组成：（A）解释需求分析，（B）解释技术设计，（C）解释验证。 |
| [^139] | [A Simulation Environment and Reinforcement Learning Method for Waste Reduction.](http://arxiv.org/abs/2205.15455) | 本文提出了一个新的强化学习任务，即库存重新填充，提出了一种新的强化学习算法 Perishable DQN，旨在最大化销售同时最小化浪费，实现计算机思维对废物减量的控制。 |
| [^140] | [Understanding Factual Errors in Summarization: Errors, Summarizers, Datasets, Error Detectors.](http://arxiv.org/abs/2205.12854) | 本文聚合了来自九个现有数据集的事实错误注释，针对底层的摘要生成模型进行分类，并比较了最先进的事实度量标准的性能。结果表明，度量标准的性能因不同的摘要生成模型而有显著差异。 |
| [^141] | [TAGPRIME: A Unified Framework for Relational Structure Extraction.](http://arxiv.org/abs/2205.12585) | 本文提出了一种名为TAGPRIME的统一关系结构提取框架，通过将给定条件信息添加到输入文本中，使得输出的上下文表示更适合提取特定条件下的关系。在各种任务和数据集上的表现优于最新的关系提取模型。 |
| [^142] | [Assessing Confidence with Assurance 2.0.](http://arxiv.org/abs/2205.04522) | 本文提出了从三个方面考虑信心的属性来评估保证案例，其中主要的措施是将论证解释为逻辑证明的完备性。 |
| [^143] | [SD-Conv: Towards the Parameter-Efficiency of Dynamic Convolution.](http://arxiv.org/abs/2204.02227) | SD-Conv 是一个新的框架，将动态机制和稀疏性集成在一起，通过设计二进制掩码修剪静态核，大大减少了参数和计算成本，并在多个下游任务中展示了比基线模型更好的结果。 |
| [^144] | [Towards Safe, Explainable, and Regulated Autonomous Driving.](http://arxiv.org/abs/2111.10518) | 本文提出了一个集成自主控制、可解释的人工智能和监管合规性的设计框架，以实现安全、可解释和监管的自动驾驶技术。 |
| [^145] | [Fact-driven Logical Reasoning for Machine Reading Comprehension.](http://arxiv.org/abs/2105.10334) | 本文提出一种基于事实的逻辑推理方法，采用分层方式涵盖常识和临时知识线索，通过构建超图实现句子级别和实体级别的交互，在逻辑推理基准测试和大规模阅读理解中表现出优越性。 |
| [^146] | [Multi-Task Attentive Residual Networks for Argument Mining.](http://arxiv.org/abs/2102.12227) | 本文提出了一种多任务注意力残差网络架构，通过利用集成方法、注意力机制和多任务学习，无需假设文档或论据结构，成功应用于多个论述挖掘任务中，成为了一种既通用又高性能的架构。 |
| [^147] | [`Why didn't you allocate this task to them?' Negotiation-Aware Explicable Task Allocation and Contrastive Explanation Generation.](http://arxiv.org/abs/2002.01640) | 本文提出一种考虑谈判的任务分配系统，在任务分配过程中允许成员提出反问。通过模拟谈判，生成对比解释，该方法被证明公平且易于理解。 |

# 详细

[^1]: 离巢：超越本地损失函数的预测优化问题

    Leaving the Nest: Going Beyond Local Loss Functions for Predict-Then-Optimize. (arXiv:2305.16830v1 [cs.LG])

    [http://arxiv.org/abs/2305.16830](http://arxiv.org/abs/2305.16830)

    本文提出了一种避免限制性假设的解决方案，利用机器学习模型的特性来提高学习损失函数的样本效率，在预测优化问题中实现了最先进的结果。

    

    预测优化问题是一种使用机器学习在不确定性条件下进行决策制定的框架。它的中心研究问题是，“如何利用决策任务的结构来定制特定任务的机器学习模型？”为此，最近的研究已经提出了学习任务特定的损失函数来捕捉这种潜在的结构。然而，当前的方法对这些损失的形式和对机器学习模型行为的影响做出了限制性的假设。这些假设既导致了高计算成本的方法，也在实践中被违反时导致了性能下降。在本文中，我们提出了解决这些问题的解决方案，避免了上述假设，利用机器学习模型的特性来提高学习损失函数的样本效率。我们从文献中的四个领域实验证明了我们的方法取得了最先进的结果，通常需要比可比方法少一个数量级的样本。

    Predict-then-Optimize is a framework for using machine learning to perform decision-making under uncertainty. The central research question it asks is, "How can the structure of a decision-making task be used to tailor ML models for that specific task?" To this end, recent work has proposed learning task-specific loss functions that capture this underlying structure. However, current approaches make restrictive assumptions about the form of these losses and their impact on ML model behavior. These assumptions both lead to approaches with high computational cost, and when they are violated in practice, poor performance. In this paper, we propose solutions to these issues, avoiding the aforementioned assumptions and utilizing the ML model's features to increase the sample efficiency of learning loss functions. We empirically show that our method achieves state-of-the-art results in four domains from the literature, often requiring an order of magnitude fewer samples than comparable metho
    
[^2]: Prompt-和Trait关系感知的跨Prompt作文Trait评分

    Prompt- and Trait Relation-aware Cross-prompt Essay Trait Scoring. (arXiv:2305.16826v1 [cs.CL])

    [http://arxiv.org/abs/2305.16826](http://arxiv.org/abs/2305.16826)

    本研究提出了一种跨Prompt的作文Trait评分模型，通过作文提示关注和Traint相似性loss，有效解决了作文提示不同的问题，提高了自动化作文评分的准确性和可靠性。

    

    自动化作文评分（AES）的目的是对写作主题进行评分的文章，该主题定义了写作主题。大多数现有的AES系统假定对于训练中使用的相同提示评分文章，并分配仅整体分数。然而，这样的设置与实际教育情况冲突；特定提示的预分级文章缺乏，并且需要详细的子量规的Trait分数。因此，预测看不见的Prompt文章的各种Trait分数（称为跨Prompt作文Trait评分）是AES的一项挑战。在本文中，我们提出了一个强大的模型：Prompt-和Trait关系感知的跨Prompt作文Trait评分器。我们通过作文提示关注和利用由主题建模机制提取的主题连贯性特征对作文感知进行编码，而无需访问标记数据；因此，我们的模型甚至在跨Prompt设置中也考虑到作文的提示恪守。为了促进多Trait评分，我们设计了Trait相似性lo

    Automated essay scoring (AES) aims to score essays written for a given prompt, which defines the writing topic. Most existing AES systems assume to grade essays of the same prompt as used in training and assign only a holistic score. However, such settings conflict with real-education situations; pre-graded essays for a particular prompt are lacking, and detailed trait scores of sub-rubrics are required. Thus, predicting various trait scores of unseen-prompt essays (called cross-prompt essay trait scoring) is a remaining challenge of AES. In this paper, we propose a robust model: prompt- and trait relation-aware cross-prompt essay trait scorer. We encode prompt-aware essay representation by essay-prompt attention and utilizing the topic-coherence feature extracted by the topic-modeling mechanism without access to labeled data; therefore, our model considers the prompt adherence of an essay, even in a cross-prompt setting. To facilitate multi-trait scoring, we design trait-similarity lo
    
[^3]: HUB: 用持续提示调整引导学习优化器

    HUB: Guiding Learned Optimizers with Continuous Prompt Tuning. (arXiv:2305.16823v1 [cs.LG])

    [http://arxiv.org/abs/2305.16823](http://arxiv.org/abs/2305.16823)

    本文提出了一种名为HUB的混合更新策略，通过结合学习优化器和手工设计的优化器，提高了学习优化器泛化性能。

    

    学习优化器是元学习的关键组成部分，但其在处理未见过的任务和网络架构时有限。为了解决此问题，本文提出了一种基于混合更新策略的优化方法（HUB），该方法受到了大型语言和视觉模型中硬提示调整和结果选择技术的启发。通过将手工设计的优化器作为我们混合方法的第二个组件，我们能够在稳定训练的同时保留学习优化器的好处。

    Learned optimizers are a crucial component of meta-learning. Recent advancements in scalable learned optimizers have demonstrated their superior performance over hand-designed optimizers in various tasks. However, certain characteristics of these models, such as an unstable learning curve, limited ability to handle unseen tasks and network architectures, difficult-to-control behaviours, and poor performance in fine-tuning tasks impede their widespread adoption. To tackle the issue of generalization in scalable learned optimizers, we propose a hybrid-update-based (HUB) optimization strategy inspired by recent advancements in hard prompt tuning and result selection techniques used in large language and vision models. This approach can be easily applied to any task that involves hand-designed or learned optimizer. By incorporating hand-designed optimizers as the second component in our hybrid approach, we are able to retain the benefits of learned optimizers while stabilizing the training
    
[^4]: 面向抽象摘要中的领域泛化的领域对齐前缀平均方法

    Domain Aligned Prefix Averaging for Domain Generalization in Abstractive Summarization. (arXiv:2305.16820v1 [cs.CL])

    [http://arxiv.org/abs/2305.16820](http://arxiv.org/abs/2305.16820)

    本文提出了一种轻量级、基于加权平均的领域对齐前缀平均方法（DAPA），用于抽象摘要中的领域泛化，实现了有效的源域扩展以提高性能。

    

    针对于抽象摘要中的领域泛化问题，本文提出了一种轻量级，基于加权平均的领域对齐前缀平均方法（DAPA）。通过给定多个源域，我们的方法首先为每个域训练一个前缀，然后利用这些前缀生成少量目标域文档的摘要，计算所需的权重来平均源前缀。在DAPA中，前缀调整允许轻量级的微调，加权平均允许有效地添加新的源域。在四个不同的摘要领域上进行评估，DAPA表现出与基准方法相当或更好的性能，证明了其前缀平均的有效性。

    Domain generalization is hitherto an underexplored area applied in abstractive summarization. Moreover, most existing works on domain generalization have sophisticated training algorithms. In this paper, we propose a lightweight, weight averaging based, Domain Aligned Prefix Averaging approach to domain generalization for abstractive summarization. Given a number of source domains, our method first trains a prefix for each one of them. These source prefixes generate summaries for a small number of target domain documents. The similarity of the generated summaries to their corresponding documents is used for calculating weights required to average source prefixes. In DAPA, prefix tuning allows for lightweight finetuning, and weight averaging allows for the computationally efficient addition of new source domains. When evaluated on four diverse summarization domains, DAPA shows comparable or better performance against the baselines, demonstrating the effectiveness of its prefix averaging
    
[^5]: 基于信任感知的连接和自主车辆的鲁棒控制与协调

    Trust-Aware Resilient Control and Coordination of Connected and Automated Vehicles. (arXiv:2305.16818v1 [cs.MA])

    [http://arxiv.org/abs/2305.16818](http://arxiv.org/abs/2305.16818)

    本文提出了一种基于信任框架的鲁棒控制和协调方案，从恶意代理的角度识别关键对抗目标，有效避免碰撞和交通堵塞。同时提出了一种使用信任框架的攻击检测和缓解措施。

    

    安全对于网络连接和自主车辆（CAV）等物理系统至关重要，这些车辆通过协作安全地通过道路网络。本文从不配合/恶意代理人的角度识别关键对抗性目标（如碰撞和交通堵塞），利用信任框架提出了鲁棒的控制与协调方案，以缓解恶意代理带来的影响并保证安全协调。我们使用 Sybil 攻击验证了建议的框架，同时提出了一种使用信任框架的攻击检测和缓解措施。

    Security is crucial for cyber-physical systems, such as a network of Connected and Automated Vehicles (CAVs) cooperating to navigate through a road network safely. In this paper, we tackle the security of a cooperating network of CAVs in conflict areas by identifying the critical adversarial objectives from the point of view of uncooperative/malicious agents from our preliminary study, which are (i) safety violations resulting in collisions, and (ii) traffic jams. We utilize a trust framework (and our work doesn't depend on the specific choice of trust/reputation framework) to propose a resilient control and coordination framework that mitigates the effects of such agents and guarantees safe coordination. A class of attacks that can be used to achieve the adversarial objectives is Sybil attacks, which we use to validate our proposed framework through simulation studies. Besides that, we propose an attack detection and mitigation scheme using the trust framework. The simulation results 
    
[^6]: GenQ：自动化问答生成器以帮助照顾者与孩子共读故事

    GenQ: Automated Question Generation to Support Caregivers While Reading Stories with Children. (arXiv:2305.16809v1 [cs.CL])

    [http://arxiv.org/abs/2305.16809](http://arxiv.org/abs/2305.16809)

    本研究设计了一个智能辅导系统（GenQ），可以根据照顾者和孩子之间的对话促进孩子的阅读理解能力，并通过考虑文化背景和语境变化以提高系统效果。

    

    当照顾者询问开放式问题以激发与孩子的对话时，可以促进孩子的阅读理解能力。虽然有利用技术工具来支持这个过程，即所谓的“智能辅导系统”的空间，但目前仍不清楚现有的生成类人语言问题的智能系统是否有益。此外，用于开发这些自动生成问题系统的培训数据通常没有考虑到人口统计学，但具有不同文化背景的人可能会提出不同的问题。作为为拉丁裔儿童设计智能阅读支持应用程序的广泛项目的一部分，我们从来自不同人口统计学的拉丁裔护理人员和非护理人员以及其他人口统计学背景的护理人员和非护理人员中群集大量问题。我们研究了这个数据集中个体、文化和环境因素中介的问题提问的变化。然后我们设计了一个系统来自动产生问题。

    When caregivers ask open--ended questions to motivate dialogue with children, it facilitates the child's reading comprehension skills.Although there is scope for use of technological tools, referred here as "intelligent tutoring systems", to scaffold this process, it is currently unclear whether existing intelligent systems that generate human--language like questions is beneficial. Additionally, training data used in the development of these automated question generation systems is typically sourced without attention to demographics, but people with different cultural backgrounds may ask different questions. As a part of a broader project to design an intelligent reading support app for Latinx children, we crowdsourced questions from Latinx caregivers and noncaregivers as well as caregivers and noncaregivers from other demographics. We examine variations in question--asking within this dataset mediated by individual, cultural, and contextual factors. We then design a system that autom
    
[^7]: GPT是否会产生更不准确的翻译?

    Do GPTs Produce Less Literal Translations?. (arXiv:2305.16806v1 [cs.CL])

    [http://arxiv.org/abs/2305.16806](http://arxiv.org/abs/2305.16806)

    本研究比较了GPT和NMT生成翻译的文字积极度差异，发现GPT翻译更不准确，但在MT质量评估指标上表现出相似或更好的分数。

    

    大型语言模型（LLMs），如GPT-3，已经成为通用语言模型，能够处理许多自然语言生成或理解任务。在机器翻译（MT）任务中，已有多项研究探索利用few-shot提示机制从LLMs中引出更好的翻译。然而，人们相对较少地关注这种翻译与标准神经机器翻译（NMT）模型生成翻译的质量差异。本研究从文字对齐和单调性等方面，比较了GPT和NMT生成翻译的文本文字积极度，发现GPT从英语（E-X）翻译的文本更不准确，但在MT质量评估指标上表现出相似或更好的分数。我们证明这一结果在人工评估中也得到了验证。同时，当翻译句子长度增加时，这种差别就尤为显著。

    Large Language Models (LLMs) such as GPT-3 have emerged as general-purpose language models capable of addressing many natural language generation or understanding tasks. On the task of Machine Translation (MT), multiple works have investigated few-shot prompting mechanisms to elicit better translations from LLMs. However, there has been relatively little investigation on how such translations differ qualitatively from the translations generated by standard Neural Machine Translation (NMT) models. In this work, we investigate these differences in terms of the literalness of translations produced by the two systems. Using literalness measures involving word alignment and monotonicity, we find that translations out of English (E-X) from GPTs tend to be less literal, while exhibiting similar or better scores on MT quality metrics. We demonstrate that this finding is borne out in human evaluations as well. We then show that these differences are especially pronounced when translating senten
    
[^8]: 面向任务的对话中基于模式的用户满意度建模

    Schema-Guided User Satisfaction Modeling for Task-Oriented Dialogues. (arXiv:2305.16798v1 [cs.CL])

    [http://arxiv.org/abs/2305.16798](http://arxiv.org/abs/2305.16798)

    本文提出了一种新的基于模式的用户满意度建模框架SG-USM，它特别模拟了系统程度的满足用户关于任务属性的偏好程度，以预测用户的满意度水平。

    

    用户满意度建模（USM）是任务导向对话系统评估的一种流行选择，其中用户满意度通常取决于系统是否实现了用户的任务目标。任务导向对话系统使用任务架构（task schema）来编码用户的任务目标。现有的USM研究忽略了使用任务架构显式建模用户的任务目标实现。本文提出了一种新的基于模式的用户满意度建模框架SG-USM。它特别模拟了系统程度的满足用户关于任务属性的偏好程度，以预测用户的满意度水平。SG-USM使用预训练的语言模型来编码对话上下文和任务属性，并采用履行表示层来学习对话中完成了多少任务属性，重要性预测器用于计算任务属性的重要性，并利用注意机制选择性地关注重要任务属性以预测用户满意度。我们在任务导向对话数据集上评估了SG-USM，并显示它优于现有的USM模型。

    User Satisfaction Modeling (USM) is one of the popular choices for task-oriented dialogue systems evaluation, where user satisfaction typically depends on whether the user's task goals were fulfilled by the system. Task-oriented dialogue systems use task schema, which is a set of task attributes, to encode the user's task goals. Existing studies on USM neglect explicitly modeling the user's task goals fulfillment using the task schema. In this paper, we propose SG-USM, a novel schema-guided user satisfaction modeling framework. It explicitly models the degree to which the user's preferences regarding the task attributes are fulfilled by the system for predicting the user's satisfaction level. SG-USM employs a pre-trained language model for encoding dialogue context and task attributes. Further, it employs a fulfillment representation layer for learning how many task attributes have been fulfilled in the dialogue, an importance predictor component for calculating the importance of task 
    
[^9]: 结合话语结构分布的长文本自动摘要方法

    Incorporating Distributions of Discourse Structure for Long Document Abstractive Summarization. (arXiv:2305.16784v1 [cs.CL])

    [http://arxiv.org/abs/2305.16784](http://arxiv.org/abs/2305.16784)

    本文提出了一种名为'RSTformer'的摘要模型，该模型全面融合了话语关系类型和不确定性，并以修辞结构理论为基础，经过严格评估，表现明显优于现有的模型。

    

    对于文本摘要，话语结构在辨识文本核心内容方面起着关键作用。可惜的是，之前将修辞结构理论（RST）引入基于transformer的自动摘要模型的研究仅考虑了核心部分的注释，从而忽略了各种不同类型的话语关系。本文提出了一种名为'RSTformer'的新型摘要模型，该模型全面融合了话语关系类型和不确定性。我们的RST-attention机制是基于文档级修辞结构的Longformer框架的扩展。经过严格评估，本文提出的模型表现明显优于现有的模型，凸显出其在多个自动评估指标和人工评估上的卓越表现。

    For text summarization, the role of discourse structure is pivotal in discerning the core content of a text. Regrettably, prior studies on incorporating Rhetorical Structure Theory (RST) into transformer-based summarization models only consider the nuclearity annotation, thereby overlooking the variety of discourse relation types. This paper introduces the 'RSTformer', a novel summarization model that comprehensively incorporates both the types and uncertainty of rhetorical relations. Our RST-attention mechanism, rooted in document-level rhetorical structure, is an extension of the recently devised Longformer framework. Through rigorous evaluation, the model proposed herein exhibits significant superiority over state-of-the-art models, as evidenced by its notable performance on several automatic metrics and human evaluation.
    
[^10]: 多语言语言模型的跨语言转移因素的共同理解：一篇综述

    Towards a Common Understanding of Contributing Factors for Cross-Lingual Transfer in Multilingual Language Models: A Review. (arXiv:2305.16768v1 [cs.CL])

    [http://arxiv.org/abs/2305.16768](http://arxiv.org/abs/2305.16768)

    本文对多语言语言模型 (MLLMs)的跨语言转移能力的不同因素进行了调查和综述，将这些因素分成五类并提供了过去研究的经验证据。本文的工作旨在全面背景和统一MLLMs跨语言转移的现有研究流。

    

    近年来，预训练的多语言语言模型（MLLMs）表现出了在不同语言之间传递知识的强大能力。然而，鉴于这种能力的追求并未明确地融入大多数MLLM设计中，很难对其出现进行独特而直接的解释。在本综述论文中，我们调查了研究MLLM的跨语言转移能力的不同因素的文献，并详细概述和讨论了这些因素。为了增强这个综述的结构并便于与未来的研究整合，我们确定了五类这样的因素。除提供过去研究的经验证据概述外，我们还确定了在具有一致发现的研究中的共识，并解决了在矛盾的研究中的冲突。我们的工作将旨在解释MLLM跨语言转移能力的现有研究流进行了全面的背景和统一。

    In recent years, pre-trained Multilingual Language Models (MLLMs) have shown a strong ability to transfer knowledge across different languages. However, given that the aspiration for such an ability has not been explicitly incorporated in the design of the majority of MLLMs, it is challenging to obtain a unique and straightforward explanation for its emergence. In this review paper, we survey literature that investigates different factors contributing to the capacity of MLLMs to perform zero-shot cross-lingual transfer and subsequently outline and discuss these factors in detail. To enhance the structure of this review and to facilitate consolidation with future studies, we identify five categories of such factors. In addition to providing a summary of empirical evidence from past studies, we identify consensuses among studies with consistent findings and resolve conflicts among contradictory ones. Our work contextualizes and unifies existing research streams which aim at explaining th
    
[^11]: 大型语言模型能够生成显著的负面声明吗？

    Can large language models generate salient negative statements?. (arXiv:2305.16755v1 [cs.CL])

    [http://arxiv.org/abs/2305.16755](http://arxiv.org/abs/2305.16755)

    本研究探讨了大型语言模型生成真实实体的显著负面陈述的能力，在不同领域中进行了评估，结果发现大型语言模型在处理否定陈述中的事实概念上仍有困难。

    

    我们研究了大型语言模型（LLMs）生成关于现实世界实体的显著（有趣的）负面陈述的能力; 这是过去几年中涌现出的一个研究课题。我们使用零点和k次无约束探针来探测LLMs，并与传统的否定生成方法，即基于模式的文本提取和基于知识图的推理以及众包金标语句进行比较。我们评估了来自不同领域的主题生成列表的正确性和显着性。我们的评估表明，有指导的探针确实提高了生成的负面陈述的质量，与无指导的变体相比。然而，使用这两个提示，LLMs仍然难以处理负面事实的概念，常常生成许多含糊不清的陈述，或者带有负面关键词但具有积极意义的陈述。

    We examine the ability of large language models (LLMs) to generate salient (interesting) negative statements about real-world entities; an emerging research topic of the last few years. We probe the LLMs using zero- and k-shot unconstrained probes, and compare with traditional methods for negation generation, i.e., pattern-based textual extractions and knowledge-graph-based inferences, as well as crowdsourced gold statements. We measure the correctness and salience of the generated lists about subjects from different domains. Our evaluation shows that guided probes do in fact improve the quality of generated negatives, compared to the zero-shot variant. Nevertheless, using both prompts, LLMs still struggle with the notion of factuality of negatives, frequently generating many ambiguous statements, or statements with negative keywords but a positive meaning.
    
[^12]: 基于深度学习的电极编码策略用于人工耳蜗声音编码

    ElectrodeNet -- A Deep Learning Based Sound Coding Strategy for Cochlear Implants. (arXiv:2305.16753v1 [eess.AS])

    [http://arxiv.org/abs/2305.16753](http://arxiv.org/abs/2305.16753)

    本文提出了一种基于深度学习的电极编码策略，ElectrodeNet，以提高人工耳蜗用户的语音感知能力，具备有望替代传统的信封检测方法和CS通道选择方法的潜力。

    

    本文提出了ElectrodeNet，一种基于深度学习的人工耳蜗声音编码策略，旨在取代传统的信封检测使用各种人工神经网络以模拟先进的ACE策略。扩展的ElectrodeNet-CS策略还包含通道选择（CS）。使用ACE策略处理干净语音得到的快速傅里叶变换和通道信封训练了深度神经网络（DNN）、卷积神经网络（CNN）和长短期记忆（LSTM）的网络模型。使用短时客观清晰度（STOI）和归一化协方差度量（NCM）估计了ElectrodeNet在人工耳蜗模拟中的客观语音理解能力。针对声码化的普通话说话测试进行了正常听力受试者的句子识别测试。DNN、CNN和LSTM基于ElectrodeNet在客观和主观评分上都表现出与ACE的强相关性，使用均方误差（MSE）和皮尔逊相关系数（PCC）。与传统的包络提取和通道解复用方法相比，ElectrodeNet表现出了一致的提高语音理解能力的效果。ElectrodeNet为具有有限听觉输入的人工耳蜗用户提高语音感知的解决方案提供了有希望的视野。

    ElectrodeNet, a deep learning based sound coding strategy for the cochlear implant (CI), is proposed to emulate the advanced combination encoder (ACE) strategy by replacing the conventional envelope detection using various artificial neural networks. The extended ElectrodeNet-CS strategy further incorporates the channel selection (CS). Network models of deep neural network (DNN), convolutional neural network (CNN), and long short-term memory (LSTM) were trained using the Fast Fourier Transformed bins and channel envelopes obtained from the processing of clean speech by the ACE strategy. Objective speech understanding using short-time objective intelligibility (STOI) and normalized covariance metric (NCM) was estimated for ElectrodeNet using CI simulations. Sentence recognition tests for vocoded Mandarin speech were conducted with normal-hearing listeners. DNN, CNN, and LSTM based ElectrodeNets exhibited strong correlations to ACE in objective and subjective scores using mean squared er
    
[^13]: MULTIGAIN 2.0：多个平均回报、LTL和稳态约束的MDP控制器综合

    MULTIGAIN 2.0: MDP controller synthesis for multiple mean-payoff, LTL and steady-state constraints. (arXiv:2305.16752v1 [cs.AI])

    [http://arxiv.org/abs/2305.16752](http://arxiv.org/abs/2305.16752)

    MULTIGAIN 2.0是一个基于PRISM的控制器综合工具，扩展了MultiGain的多维能力，可对具有多维约束的概率系统进行控制器的形式验证和综合，并提供了二维和三维 Pareto 曲线的可视化能力。

    

    我们介绍了MULTIGAIN 2.0，这是一个基于概率模型检查器PRISM构建的控制器综合工具MultiGain的一个重大扩展。这个新版本扩展了MultiGain的多目标能力，允许对具有多维长期平均回报结构、稳态约束和线性时态逻辑属性的概率系统进行控制器的形式验证和综合。此外，MULTIGAIN 2.0提供了一种寻找有限内存解决方案的方法，并具有二维和三维 Pareto 曲线的可视化能力，以便在多目标情况下进行权衡分析。

    We present MULTIGAIN 2.0, a major extension to the controller synthesis tool MultiGain, built on top of the probabilistic model checker PRISM. This new version extends MultiGain's multi-objective capabilities, by allowing for the formal verification and synthesis of controllers for probabilistic systems with multi-dimensional long-run average reward structures, steady-state constraints, and linear temporal logic properties. Additionally, MULTIGAIN 2.0 provides an approach for finding finite memory solutions and the capability for two- and three-dimensional visualization of Pareto curves to facilitate trade-off analysis in multi-objective scenarios
    
[^14]: 一种用于离散周界防御问题的分散脉冲学习框架

    A Decentralized Spike-based Learning Framework for Sequential Capture in Discrete Perimeter Defense Problem. (arXiv:2305.16748v1 [cs.RO])

    [http://arxiv.org/abs/2305.16748](http://arxiv.org/abs/2305.16748)

    本文提出了一种针对离散周界防御问题的分散脉冲学习框架，有效解决了团队防御者保护领土的问题，每个防御者含有自己的MLC-SEFRON网络，从而实现分散独立训练，输入信息来源于防御者和入侵者的时空信息。

    

    本文提出了一种新颖的分散脉冲学习（DSL）框架，用于处理离散周界防御问题（d-PDP）。团队操作防御者用于保护圆形领土免受辐射性入侵者的攻击。首先，将离散周界防御问题（d-PDP）表述为时空多任务分配问题（STMTA）。然后将STMTA问题转换为多标签学习问题，以获取防御者必须访问的区段标签，以便保护周界。DSL框架使用Multi-Label Classifier Using Synaptic Efficacy Function Spiking NeuRON（MLC-SEFRON）网络进行确定性多标签学习。每个防御者都包含单个MLC-SEFRON网络，每个MLC-SEFRON网络都独立训练，使用其自身透视图的输入进行分散操作。 MLC-SEFRON网络的输入脉冲可以直接从防御者和入侵者的时空信息中获得，无需额外的预处理。

    This paper proposes a novel Decentralized Spike-based Learning (DSL) framework for the discrete Perimeter Defense Problem (d-PDP). A team of defenders is operating on the perimeter to protect the circular territory from radially incoming intruders. At first, the d-PDP is formulated as a spatio-temporal multi-task assignment problem (STMTA). The problem of STMTA is then converted into a multi-label learning problem to obtain labels of segments that defenders have to visit in order to protect the perimeter. The DSL framework uses a Multi-Label Classifier using Synaptic Efficacy Function spiking neuRON (MLC-SEFRON) network for deterministic multi-label learning. Each defender contains a single MLC-SEFRON network. Each MLC-SEFRON network is trained independently using input from its own perspective for decentralized operations. The input spikes to the MLC-SEFRON network can be directly obtained from the spatio-temporal information of defenders and intruders without any extra pre-processing
    
[^15]: 无需引入新的延迟的参数高效微调

    Parameter-Efficient Fine-Tuning without Introducing New Latency. (arXiv:2305.16742v1 [cs.CL])

    [http://arxiv.org/abs/2305.16742](http://arxiv.org/abs/2305.16742)

    本文提出了一种参数高效微调的方法，以任务不可知的方式生成稀疏掩码，无需添加新参数，避免了额外的推断延迟，并超过了现有方法的效果。

    

    预训练语言模型的参数高效微调（PEFT）最近展示出明显的成就，有效地匹配了完全微调的性能，同时利用明显更少的可训练参数，因此解决了存储和通信限制。尽管如此，各种PEFT方法仍受其固有特性的限制。在稀疏微调的情况下，这只涉及修改现有参数的一小部分，微调参数的选择是任务和领域特定的，因此不适用于联合学习。另一方面，添加新参数的PEFT方法通常会引入额外的推断延迟。在本文中，我们展示了以任务不可知的方式生成稀疏掩码的可行性，其中所有下游任务共享相同的掩码。我们的方法仅依赖于预训练参数的幅度信息，超过了现有方法学的效果。

    Parameter-efficient fine-tuning (PEFT) of pre-trained language models has recently demonstrated remarkable achievements, effectively matching the performance of full fine-tuning while utilizing significantly fewer trainable parameters, and consequently addressing the storage and communication constraints. Nonetheless, various PEFT methods are limited by their inherent characteristics. In the case of sparse fine-tuning, which involves modifying only a small subset of the existing parameters, the selection of fine-tuned parameters is task- and domain-specific, making it unsuitable for federated learning. On the other hand, PEFT methods with adding new parameters typically introduce additional inference latency. In this paper, we demonstrate the feasibility of generating a sparse mask in a task-agnostic manner, wherein all downstream tasks share a common mask. Our approach, which relies solely on the magnitude information of pre-trained parameters, surpasses existing methodologies by a si
    
[^16]: AMPERE: 面向AMR的前缀生成事件论元抽取模型

    AMPERE: AMR-Aware Prefix for Generation-Based Event Argument Extraction Model. (arXiv:2305.16734v1 [cs.CL])

    [http://arxiv.org/abs/2305.16734](http://arxiv.org/abs/2305.16734)

    本论文提出了一种名为AMPERE的方法，面向AMR的前缀生成事件论元抽取模型，该模型成功引入了AMR的信息，提升了生成式模型的性能和泛化能力。

    

    事件论元抽取旨在识别某事件的论元及其特定的角色。生成式的事件论元抽取模型相比于分类式模型表现出更好的性能和泛化能力。但是，目前的生成式模型主要关注问题重新表述和提示设计，没有整合其他在分类式模型中已被证明有效的信息（如输入段落的抽象意义表示AMR）。由于生成式模型中通常使用自然语言形式，而AMR是一种结构化形式，因此将这样的信息整合到生成式模型中具有挑战性。本文研究了将AMR整合到生成式事件论元抽取模型中的策略。我们提出了AMPERE，为生成模型的每层生成AMR感知前缀。因此，该前缀为生成式的事件论元抽取模型引入了AMR信息。

    Event argument extraction (EAE) identifies event arguments and their specific roles for a given event. Recent advancement in generation-based EAE models has shown great performance and generalizability over classification-based models. However, existing generation-based EAE models mostly focus on problem re-formulation and prompt design, without incorporating additional information that has been shown to be effective for classification-based models, such as the abstract meaning representation (AMR) of the input passages. Incorporating such information into generation-based models is challenging due to the heterogeneous nature of the natural language form prevalently used in generation-based models and the structured form of AMRs. In this work, we study strategies to incorporate AMR into generation-based EAE models. We propose AMPERE, which generates AMR-aware prefixes for every layer of the generation model. Thus, the prefix introduces AMR information to the generation-based EAE model 
    
[^17]: YOLOv8实时心律失常检测的新应用

    A novel application for real-time arrhythmia detection using YOLOv8. (arXiv:2305.16727v1 [cs.CV])

    [http://arxiv.org/abs/2305.16727](http://arxiv.org/abs/2305.16727)

    本文提出了一种使用YOLOv8算法进行心律失常检测的新应用程序，其模型能够实现持续监测，并以高准确性进行实时心律失常检测。

    

    近年来，降低远程心血管健康监护的医疗费用需求越来越高。检测和分类心脏心律失常对于诊断心脏异常患者至关重要。本文提出了一种新的应用程序，利用最先进的You-Only-Look-Once（YOLO）v8算法对单导联心电图信号进行分类，进行心律失常检测。通过对MIT-BIH数据集进行微调后，建立起一个定制的YOLOv8模型，能够实时检测心律失常，以实现持续监测。结果表明，在NVIDIA Tesla V100上，我们的模型能够以0.002秒的检测时间和0.961的mAP@50检测心跳。研究证明了实时心律失常检测的潜力，模型输出可以被视觉解释，适用于家庭用户。此外，该研究可以延伸到开发实时的可解释人工智能模型，应用于心血管健康监护。

    In recent years, there has been an increasing need to reduce healthcare costs in remote monitoring of cardiovascular health. Detecting and classifying cardiac arrhythmia is critical to diagnosing patients with cardiac abnormalities. This paper shows that complex systems such as electrocardiograms (ECG) can be applicable for at-home monitoring. This paper proposes a novel application for arrhythmia detection using the state-of-the-art You-Only-Look-Once (YOLO)v8 algorithm to classify single-lead ECG signals. A custom YOLOv8 model was fine-tuned on the MIT-BIH dataset to detect arrhythmia in real-time to allow continuous monitoring. Results show that our model can detect heartbeats with a mAP@50 of 0.961 with a detection time of 0.002s on an NVIDIA Tesla V100. Our study demonstrated the potential of real-time arrhythmia detection, where the model output can be visually interpreted for at-home users. Furthermore, this study could be extended into a real-time XAI model, deployed in the hea
    
[^18]: 未见过的语言对中的混合代码文本合成

    Code-Switched Text Synthesis in Unseen Language Pairs. (arXiv:2305.16724v1 [cs.CL])

    [http://arxiv.org/abs/2305.16724](http://arxiv.org/abs/2305.16724)

    本文介绍了GLOSS模型，旨在解决在缺乏训练数据的情况下合成混合代码文本的问题，并且可以推广到更广泛的语言对。该模型在四个未见过的语言对上的实验中优于其他基线模型和在单语文本上运行的生成模型。

    

    现有的针对混合代码文本合成的研究大多需要在目标语言对中的混合代码文本上进行训练，这限制了模型在缺乏混合代码数据的情况下的部署。在本文中，我们研究了在缺乏训练数据的情况下合成混合代码文本的问题。我们介绍了GLOSS，这是一个建立在预训练多语言机器翻译模型（PMMTM）之上，并带有额外的代码切换模块的模型。这个模块，无论是适配器还是额外的前缀，在训练过程中从混合代码数据中学习代码切换模式，而GLOSS的主要组成部分PMMTM被冻结。我们只调整代码切换模块的设计，防止模型过度拟合针对混合代码训练数据的约束。因此，GLOSS表现出了跨更广泛的语言对进行归纳和合成混合代码文本的能力。此外，我们还开发了一种基于目标语言单语文本的自训练算法，以提高模型性能。我们对四个未见过的语言对进行的实验证明，GLOSS优于其他从具有混合代码数据的语言对中调整的模型和在单语文本上运行的生成模型等多个基线模型。

    Existing efforts on text synthesis for code-switching mostly require training on code-switched texts in the target language pairs, limiting the deployment of the models to cases lacking code-switched data. In this work, we study the problem of synthesizing code-switched texts for language pairs absent from the training data. We introduce GLOSS, a model built on top of a pre-trained multilingual machine translation model (PMMTM) with an additional code-switching module. This module, either an adapter or extra prefixes, learns code-switching patterns from code-switched data during training, while the primary component of GLOSS, i.e., the PMMTM, is frozen. The design of only adjusting the code-switching module prevents our model from overfitting to the constrained training data for code-switching. Hence, GLOSS exhibits the ability to generalize and synthesize code-switched texts across a broader spectrum of language pairs. Additionally, we develop a self-training algorithm on target langu
    
[^19]: 一种基于层次思维的人工智能协同训练方法

    A Hierarchical Approach to Population Training for Human-AI Collaboration. (arXiv:2305.16708v1 [cs.AI])

    [http://arxiv.org/abs/2305.16708](http://arxiv.org/abs/2305.16708)

    本论文提出了一种基于层次思维的人工智能协同训练方法，通过引入层次强化学习方法，代理能够根据当前合作伙伴自动切换最佳响应策略，从而显著提高了代理与新合作伙伴的适应性。

    

    深度强化学习（DRL）代理在与未经过训练的合作伙伴协同时存在困难，特别是当代理与人类合作伙伴合作时，因人类行为的不一致性而出现行动反应的方差增加，而这加剧了这一问题。最近的研究表明，将单个代理训练为对多样化的训练伙伴做出最佳响应，可以显著提高代理与新合作伙伴的适应性。我们进一步增强了基于人口的训练方法，引入了一个基于层次强化学习（HRL）的方法来实现人工智能协同训练。我们的代理能够学习多个最佳响应策略作为其低层策略，同时学习一个作为管理者的高层策略，使代理能够根据其当前的合作伙伴动态地在低层最佳响应策略之间进行切换。我们证明了我们的方法能够

    A major challenge for deep reinforcement learning (DRL) agents is to collaborate with novel partners that were not encountered by them during the training phase. This is specifically worsened by an increased variance in action responses when the DRL agents collaborate with human partners due to the lack of consistency in human behaviors. Recent work have shown that training a single agent as the best response to a diverse population of training partners significantly increases an agent's robustness to novel partners. We further enhance the population-based training approach by introducing a Hierarchical Reinforcement Learning (HRL) based method for Human-AI Collaboration. Our agent is able to learn multiple best-response policies as its low-level policy while at the same time, it learns a high-level policy that acts as a manager which allows the agent to dynamically switch between the low-level best-response policies based on its current partner. We demonstrate that our method is able 
    
[^20]: PIP：语法控制的释义生成的解析指导前缀

    PIP: Parse-Instructed Prefix for Syntactically Controlled Paraphrase Generation. (arXiv:2305.16701v1 [cs.CL])

    [http://arxiv.org/abs/2305.16701](http://arxiv.org/abs/2305.16701)

    使用Parse-Instructed Prefix的语法控制释义生成的计算成本降低了10倍，并在两个benchmark上达到了最先进的性能表现。

    

    语法控制的释义生成需要语言模型根据特定的语法结构为句子生成释义。现有的fine-tuning方法需要更新模型的所有参数，成本高昂。在参数有效学习的最新研究的启发下，我们提出了Parse-Instructed Prefix (PIP),这是一种新颖的前缀调整方法，可在低数据设置中调整大型预训练语言模型，显着降低训练成本。 我们介绍了两种方法来指导模型的编码器前缀捕获语法相关知识：直接初始化（PIP-Direct）和间接优化（PIP-Indirect）。与传统的fine-tuning方法相比，PIP是一种低计算成本的替代方法，具有10倍更少的可学习参数。与现有的前缀调整方法相比，PIP在捕获语法控制信息方面表现出色，这得益于将语法解析树作为指导前缀。实验结果表明，PIP在两个语法控制的释义生成基准测试中实现了最先进的性能，同时只需要很少的训练数据和时间。

    Syntactically controlled paraphrase generation requires language models to generate paraphrases for sentences according to specific syntactic structures. Existing fine-tuning methods for this task are costly as all the parameters of the model need to be updated during the training process. Inspired by recent studies on parameter-efficient learning, we propose Parse-Instructed Prefix (PIP), a novel adaptation of prefix-tuning to tune large pre-trained language models on syntactically controlled paraphrase generation task in a low-data setting with significantly less training cost. We introduce two methods to instruct a model's encoder prefix to capture syntax-related knowledge: direct initiation (PIP-Direct) and indirect optimization (PIP-Indirect). In contrast to traditional fine-tuning methods for this task, PIP is a compute-efficient alternative with 10 times less learnable parameters. Compared to existing prefix-tuning methods, PIP excels at capturing syntax control information, ach
    
[^21]: 运用跨学科框架理解算法决策制定

    Applying Interdisciplinary Frameworks to Understand Algorithmic Decision-Making. (arXiv:2305.16700v1 [cs.HC])

    [http://arxiv.org/abs/2305.16700](http://arxiv.org/abs/2305.16700)

    这篇文章探讨了采用跨学科方法理解算法决策制定。研究者认为应采用学习科学的实践方法来解释ADM系统，而定性任务研究结果显示使用“六个理解方面”框架可以提高解释ADM系统的有效性。

    

    我们认为，采用学习科学中已使用的实践方法来解释“算法决策制定”（ADM）系统可以带来利益。我们简要介绍了解释ADM系统的重要性，概述了借鉴其他学科来改进解释方法的方法，并呈现了我们的“六个理解方面”框架的定性任务研究结果。最后，我们提出一些问题，引导未来的研究如何利用跨学科方法。

    We argue that explanations for "algorithmic decision-making" (ADM) systems can profit by adopting practices that are already used in the learning sciences. We shortly introduce the importance of explaining ADM systems, give a brief overview of approaches drawing from other disciplines to improve explanations, and present the results of our qualitative task-based study incorporating the "six facets of understanding" framework. We close with questions guiding the discussion of how future studies can leverage an interdisciplinary approach.
    
[^22]: 无需超参数搜索的端到端零样本语音合成中损失权衡的自动调整

    Automatic Tuning of Loss Trade-offs without Hyper-parameter Search in End-to-End Zero-Shot Speech Synthesis. (arXiv:2305.16699v1 [eess.AS])

    [http://arxiv.org/abs/2305.16699](http://arxiv.org/abs/2305.16699)

    本论文提出在零样本语音合成中自动调整损失权衡的方法，无需超参数搜索。通过此方法，VITS-based模型的性能表现得到了显著提升，达到了最新的领先性能。

    

    最近，零样本TTS和VC方法因其能够生成在训练中从未见过的语音而引起了关注。在这些方法中，基于VITS的零样本修改展现出了优越的性能，同时还具有从VITS继承来的有用属性。然而，VITS和基于VITS的零样本模型的性能在损失如何权衡方面存在巨大差异。这可能是有问题的，因为它需要繁琐的调整损失权衡超参数以找到最佳平衡点。在本研究中，我们提出了一个新的框架，通过引导VITS-based模型的解码器达到其完全重建能力，以找到这个最佳点而无需搜索。通过我们的框架，我们展现了在零样本TTS和VC中比基线更优越的性能，实现了最新的领先性能。此外，我们在各种设置中展示了我们的框架的鲁棒性。我们在讨论中对结果进行了解释。

    Recently, zero-shot TTS and VC methods have gained attention due to their practicality of being able to generate voices even unseen during training. Among these methods, zero-shot modifications of the VITS model have shown superior performance, while having useful properties inherited from VITS. However, the performance of VITS and VITS-based zero-shot models vary dramatically depending on how the losses are balanced. This can be problematic, as it requires a burdensome procedure of tuning loss balance hyper-parameters to find the optimal balance. In this work, we propose a novel framework that finds this optimum without search, by inducing the decoder of VITS-based models to its full reconstruction ability. With our framework, we show superior performance compared to baselines in zero-shot TTS and VC, achieving state-of-the-art performance. Furthermore, we show the robustness of our framework in various settings. We provide an explanation for the results in the discussion.
    
[^23]: 面向少样本类增量学习的平衡监督对比学习方法

    Balanced Supervised Contrastive Learning for Few-Shot Class-Incremental Learning. (arXiv:2305.16687v1 [cs.CV])

    [http://arxiv.org/abs/2305.16687](http://arxiv.org/abs/2305.16687)

    该论文提出了一种平衡监督对比学习方法来解决少样本类增量学习中的平衡性问题，并且在三个数据集上的表现均非常优秀。

    

    少样本类增量学习(FSCIL)主要面临的挑战是如何平衡新任务的欠拟合和遗忘之前任务的问题。为了解决这个问题，我们提出了一种简单而强大的学习方法，集成了FSCIL网络的核心组件的有效方法，包括特征提取器、基础会话分类器和增量会话分类器。在特征提取器的训练中，我们的目标是获得平衡的通用表示，既有利于当前可见类，又有利于未来或过去的类。为了实现这一点，我们提出了一种平衡的监督对比损失，可以有效平衡这两个目标。在分类器方面，我们分析并强调了对于基础和增量会话分类器的统一初始化方法的重要性。我们的方法在CUB200、CIFAR100和miniImagenet数据集上表现出了显著的新任务学习能力和防止遗忘的能力。

    Few-shot class-incremental learning (FSCIL) presents the primary challenge of balancing underfitting to a new session's task and forgetting the tasks from previous sessions. To address this challenge, we develop a simple yet powerful learning scheme that integrates effective methods for each core component of the FSCIL network, including the feature extractor, base session classifiers, and incremental session classifiers. In feature extractor training, our goal is to obtain balanced generic representations that benefit both current viewable and unseen or past classes. To achieve this, we propose a balanced supervised contrastive loss that effectively balances these two objectives. In terms of classifiers, we analyze and emphasize the importance of unifying initialization methods for both the base and incremental session classifiers. Our method demonstrates outstanding ability for new task learning and preventing forgetting on CUB200, CIFAR100, and miniImagenet datasets, with significan
    
[^24]: 多视角标识增强生成式检索

    Multiview Identifiers Enhanced Generative Retrieval. (arXiv:2305.16675v1 [cs.CL])

    [http://arxiv.org/abs/2305.16675](http://arxiv.org/abs/2305.16675)

    该论文提出了一种新型的基于合成标识符的多视角标识符来增强生成式检索，从而提高了检索结果的准确性和多样性。

    

    与其简单地将查询与现有段落匹配，生成式检索生成段落的标识符字符串作为检索目标。然而，这种标识符必须足够独特以代表一个段落。当前的方法使用数字ID或文本片段（如标题或子字符串）作为标识符。然而，这些标识符不能很好地覆盖一个段落的内容。因此，我们提出了一种新类型的标识符，即基于段落内容生成的合成标识符，可以整合文本片段缺乏的情境信息。此外，我们同时考虑多视角标识符，包括合成标识符、标题和子字符串。这些标识符的视角相互补充，有助于从多个角度综合排名段落。我们在三个公共数据集上进行了一系列实验，结果表明我们提出的方法在生成式检索中表现最佳。

    Instead of simply matching a query to pre-existing passages, generative retrieval generates identifier strings of passages as the retrieval target. At a cost, the identifier must be distinctive enough to represent a passage. Current approaches use either a numeric ID or a text piece (such as a title or substrings) as the identifier. However, these identifiers cannot cover a passage's content well. As such, we are motivated to propose a new type of identifier, synthetic identifiers, that are generated based on the content of a passage and could integrate contextualized information that text pieces lack. Furthermore, we simultaneously consider multiview identifiers, including synthetic identifiers, titles, and substrings. These views of identifiers complement each other and facilitate the holistic ranking of passages from multiple perspectives. We conduct a series of experiments on three public datasets, and the results indicate that our proposed approach performs the best in generative 
    
[^25]: 一种统一的方法用于最大化连续 DR-submodular 函数

    A Unified Approach for Maximizing Continuous DR-submodular Functions. (arXiv:2305.16671v1 [cs.LG])

    [http://arxiv.org/abs/2305.16671](http://arxiv.org/abs/2305.16671)

    本文提出了一种适用于一系列设置和 Oracle 访问类型的统一方法，用于最大化连续 DR-submodular 函数，为 16 种情况中的 9 种提供了新的/改进的结果，并且针对基于随机函数值的 Oracle 取得了第一个适用于随机 DR-submodular 函数的后悔界限。

    

    本文提出了一种统一的方法，用于最大化连续的 DR-submodular 函数，涵盖了一系列设置和 Oracle 访问类型。我们的方法包括针对单调和非单调函数的 Frank-Wolfe 类型离线算法，具有不同的一般凸集限制。我们考虑了 Oracle 提供函数梯度或仅函数值的访问以及确定性或随机性访问的设置。我们在所有情况下确定了所需的 Oracle 访问数量。我们的方法为 16 个考虑的情况中的 9 个提供了新的/改进的结果，在两个情况下避免了计算上昂贵的投影，而所提出的框架在其余五个情况下与最先进的方法相匹配。值得注意的是，我们针对基于随机函数值的 Oracle 的方法，为随机 DR-submodular 函数提供了第一个带有探险反馈的后悔界限。

    This paper presents a unified approach for maximizing continuous DR-submodular functions that encompasses a range of settings and oracle access types. Our approach includes a Frank-Wolfe type offline algorithm for both monotone and non-monotone functions, with different restrictions on the general convex set. We consider settings where the oracle provides access to either the gradient of the function or only the function value, and where the oracle access is either deterministic or stochastic. We determine the number of required oracle accesses in all cases. Our approach gives new/improved results for nine out of the sixteen considered cases, avoids computationally expensive projections in two cases, with the proposed framework matching performance of state-of-the-art approaches in the remaining five cases. Notably, our approach for the stochastic function value-based oracle enables the first regret bounds with bandit feedback for stochastic DR-submodular functions.
    
[^26]: 基于喉镜图像预测患者基本信息的深度学习模型

    Gender, Smoking History and Age Prediction from Laryngeal Images. (arXiv:2305.16661v1 [cs.CV])

    [http://arxiv.org/abs/2305.16661](http://arxiv.org/abs/2305.16661)

    首次采用深度学习模型预测喉镜图像中的患者基本信息，从而提高检测器模型的性能。

    

    应用灵活喉镜检查可以检测喉部疾病和识别潜在的恶性病变。研究人员们最近开始应用机器学习技术使用喉镜图像进行自动诊断，取得了有希望的成果。本研究尝试首次采用深度学习模型预测患者的基本信息，从而提高检测器模型的性能。性别、吸烟史和年龄的准确率分别达到了85.5%、65.2%和75.9%。同时，我们还创造了一个全新的喉镜图像数据集，基于卷积神经网络和Transformer的8种经典深度学习模型的性能得到了测试，并可以将结果集成到当前的学习模型中。

    Flexible laryngoscopy is commonly performed by otolaryngologists to detect laryngeal diseases and to recognize potentially malignant lesions. Recently, researchers have introduced machine learning techniques to facilitate automated diagnosis using laryngeal images and achieved promising results. Diagnostic performance can be improved when patients' demographic information is incorporated into models. However, manual entry of patient data is time consuming for clinicians. In this study, we made the first endeavor to employ deep learning models to predict patient demographic information to improve detector model performance. The overall accuracy for gender, smoking history, and age was 85.5%, 65.2%, and 75.9%, respectively. We also created a new laryngoscopic image set for machine learning study and benchmarked the performance of 8 classical deep learning models based on CNNs and Transformers. The results can be integrated into current learning models to improve their performance by inco
    
[^27]: AdaPlanner:自适应规划与语言模型的反馈。 （arXiv：2305.16653v1 [cs.CL]）

    AdaPlanner: Adaptive Planning from Feedback with Language Models. (arXiv:2305.16653v1 [cs.CL])

    [http://arxiv.org/abs/2305.16653](http://arxiv.org/abs/2305.16653)

    LLM代理可以通过Adaplanner自适应改进自己的计划以应对环境反馈，为此提出计划内外的改进策略以及代码风格的LLM提示结构和技能发现机制。

    

    最近的大型语言模型（LLM）展示了在序列决策任务中作为自主代理的潜力。然而，大多数现有方法要么贪婪地采取行动而没有计划，要么依赖于不可适应环境反馈的静态计划。因此，随着问题复杂性和计划水平的增加，LLM代理的顺序决策性能会退化。我们提出了一种闭环方法AdaPlanner，它允许LLM代理根据环境反馈自适应地改进其自动生成的计划。在AdaPlanner中，LLM代理通过计划内和计划外的改进策略自适应地改进其计划。为了减轻幻觉，我们开发了一种代码风格的LLM提示结构，促进了跨各种任务，环境和代理能力的计划生成。此外，我们提出了一种技能发现机制，利用成功的计划作为少量示例，使计划更具普适性。

    Large language models (LLMs) have recently demonstrated the potential in acting as autonomous agents for sequential decision-making tasks. However, most existing methods either take actions greedily without planning or rely on static plans that are not adaptable to environmental feedback. Consequently, the sequential decision-making performance of LLM agents degenerates with problem complexity and plan horizons increase. We propose a closed-loop approach, AdaPlanner, which allows the LLM agent to refine its self-generated plan adaptively in response to environmental feedback. In AdaPlanner, the LLM agent adaptively refines its plan from feedback with both in-plan and out-of-plan refinement strategies. To mitigate hallucination, we develop a code-style LLM prompt structure that facilitates plan generation across a variety of tasks, environments, and agent capabilities. Furthermore, we propose a skill discovery mechanism that leverages successful plans as few-shot exemplars, enabling the
    
[^28]: 语言模型可以通过少样本的绝对推理来提高事件预测

    Language Models Can Improve Event Prediction by Few-Shot Abductive Reasoning. (arXiv:2305.16646v1 [cs.CL])

    [http://arxiv.org/abs/2305.16646](http://arxiv.org/abs/2305.16646)

    本文提出了一个建模和预测框架，在少样本情况下使用语言模型的绝对推理能力来提高事件序列模型的预测精度，经过实验证实可以明显优于最先进的事件序列模型。

    

    大型语言模型在各种推理任务上表现出惊人的性能。本文研究它们是否可以推理现实世界中的事件，帮助提高事件序列模型的预测精度。我们设计了一个建模和预测框架，其中大型语言模型执行绝对推理以辅助事件序列模型：事件模型在给定过去的情况下提出未来事件的预测; 在几个专家注释示范的指导下，语言模型学会了为每个提议提供可能的原因; 一个搜索模块找到与原因匹配的先前事件; 一个评分函数学会检查检索到的事件是否实际上可以导致提议。通过在两个具有挑战性的现实世界数据集（亚马逊评论和GDELT）上进行广泛的实验，我们证明了我们的框架 - 由于语言模型的推理能力 - 可以在低数据情况下明显优于最先进的事件序列模型。

    Large language models have shown astonishing performance on a wide range of reasoning tasks. In this paper, we investigate whether they could reason about real-world events and help improve the prediction accuracy of event sequence models. We design a modeling and prediction framework where a large language model performs abductive reasoning to assist an event sequence model: the event model proposes predictions on future events given the past; instructed by a few expert-annotated demonstrations, the language model learns to suggest possible causes for each proposal; a search module finds out the previous events that match the causes; a scoring function learns to examine whether the retrieved events could actually cause the proposal. Through extensive experiments on two challenging real-world datasets (Amazon Review and GDELT), we demonstrate that our framework -- thanks to the reasoning ability of language models -- could significantly outperform the state-of-the-art event sequence mo
    
[^29]: 评估问答生成需要更多的参考文献

    Evaluation of Question Generation Needs More References. (arXiv:2305.16626v1 [cs.CL])

    [http://arxiv.org/abs/2305.16626](http://arxiv.org/abs/2305.16626)

    评估QG方法需要更多的参考文献来提高其有效性，单个参考不足以全面评估其潜力。使用多个参考文献的评估方法可以更好地与人类评估相关联。

    

    问答生成(QG)是一项任务，基于给定的上下文和目标答案生成一个有效和流畅的问题。根据不同的目的，即使给定相同的上下文，教师也可以提出关于不同概念的问题，甚至相同的概念也可以用不同的方式书写。然而，对于QG的评估通常依赖于单个基于参考的相似性度量，例如n-gram度量或学习度量，这不足以充分评估QG方法的潜力。为此，我们建议重新表述参考问题，以进行更强健的QG评估。使用大型语言模型，如GPT-3，我们创建了语义和句法多样的问题，然后采用流行的评估指标的简单聚合作为最终得分。通过我们的实验，我们发现使用多个（伪）参考文献对于QG评估更有效，同时与人类评估的相关性更高，而单个参考的评估则相对较低。

    Question generation (QG) is the task of generating a valid and fluent question based on a given context and the target answer. According to various purposes, even given the same context, instructors can ask questions about different concepts, and even the same concept can be written in different ways. However, the evaluation for QG usually depends on single reference-based similarity metrics, such as n-gram-based metric or learned metric, which is not sufficient to fully evaluate the potential of QG methods. To this end, we propose to paraphrase the reference question for a more robust QG evaluation. Using large language models such as GPT-3, we created semantically and syntactically diverse questions, then adopt the simple aggregation of the popular evaluation metrics as the final scores. Through our experiments, we found that using multiple (pseudo) references is more effective for QG evaluation while showing a higher correlation with human evaluations than evaluation with a single r
    
[^30]: 集合化的神经网络编码

    Set-based Neural Network Encoding. (arXiv:2305.16625v1 [cs.LG])

    [http://arxiv.org/abs/2305.16625](http://arxiv.org/abs/2305.16625)

    提出了一种能够集合化地编码神经网络参数的神经网络权重编码方法，并引入了一种逐层编码方案来考虑神经网络的分层计算结构。同时引入了“pad-chunk-encode”流水线进行神经网络层的高效编码处理，还提出了新的神经网络泛化性能预测任务。

    

    我们提出了一种利用集合到集合和集合到向量函数来有效编码神经网络参数，进行泛化性能预测的神经网络权重编码方法。与之前需要对不同架构编写自定义编码模型的方法不同，我们的方法能够对混合架构和不同参数大小的模型动态编码。此外，我们的 SNE（集合化神经网络编码器）通过使用一种逐层编码方案，考虑神经网络的分层计算结构。最终将所有层次编码合并到一起，以获取神经网络编码矢量。我们还引入了“pad-chunk-encode”流水线来有效地编码神经网络层，该流水线可根据计算和内存限制进行调整。我们还引入了两个用于神经网络泛化性能预测的新任务：跨数据集和架构适应性预测。

    We propose an approach to neural network weight encoding for generalization performance prediction that utilizes set-to-set and set-to-vector functions to efficiently encode neural network parameters. Our approach is capable of encoding neural networks in a modelzoo of mixed architecture and different parameter sizes as opposed to previous approaches that require custom encoding models for different architectures. Furthermore, our \textbf{S}et-based \textbf{N}eural network \textbf{E}ncoder (SNE) takes into consideration the hierarchical computational structure of neural networks by utilizing a layer-wise encoding scheme that culminates to encoding all layer-wise encodings to obtain the neural network encoding vector. Additionally, we introduce a \textit{pad-chunk-encode} pipeline to efficiently encode neural network layers that is adjustable to computational and memory constraints. We also introduce two new tasks for neural network generalization performance prediction: cross-dataset a
    
[^31]: 语言奖励塑造可能影响指令遵循代理的学习：提醒其脆弱性

    A Reminder of its Brittleness: Language Reward Shaping May Hinder Learning for Instruction Following Agents. (arXiv:2305.16621v1 [cs.AI])

    [http://arxiv.org/abs/2305.16621](http://arxiv.org/abs/2305.16621)

    该论文研究表明，对于复杂指令遵循代理的学习，语言奖励塑造技术可能会影响代理程序的学习，其中表面上的成功可能是脆弱的。

    

    教导代理程序遵守复杂的书面指令一直是一个重要而又难以实现的目标。提高学习效率的一种技术是语言奖励塑造（LRS），它在强化学习中用于奖励代表朝着稀疏奖励的进展方向的行动。我们认为，LRS的表面成功是脆弱的，并且之前的积极结果可能归因于弱的强化学习基线。具体而言，我们确定了奖励部分匹配轨迹的次优LRS设计，并基于放宽任务约束的概念，对一种新型的奖励扰动进行了表征以解决这个问题。我们提供了理论和实证证据表明，使用LRS奖励训练的代理程序较纯强化学习代理程序收敛速度较慢。

    Teaching agents to follow complex written instructions has been an important yet elusive goal. One technique for improving learning efficiency is language reward shaping (LRS), which is used in reinforcement learning (RL) to reward actions that represent progress towards a sparse reward. We argue that the apparent success of LRS is brittle, and prior positive findings can be attributed to weak RL baselines. Specifically, we identified suboptimal LRS designs that reward partially matched trajectories, and we characterised a novel type of reward perturbation that addresses this issue based on the concept of loosening task constraints. We provided theoretical and empirical evidence that agents trained using LRS rewards converge more slowly compared to pure RL agents.
    
[^32]: 物理深度强化学习: 安全和未知未知的探索

    Physical Deep Reinforcement Learning: Safety and Unknown Unknowns. (arXiv:2305.16614v1 [cs.AI])

    [http://arxiv.org/abs/2305.16614](http://arxiv.org/abs/2305.16614)

    本文提出了Phy-DRL，这是一个物理模型调整的深度强化学习框架。该框架有三个创新点，它们分别是: i)前瞻性的未知未知训练，ii)结合残差控制，以及iii)基于物理模型的神经网络编辑。Phy-DRL能够容忍未知干扰，保证安全和稳定，同时遵守Bellman方程和奖励相关的物理知识。

    

    本文提出了Phy-DRL，一个物理模型调节的深度强化学习框架，用于安全关键的自主系统。Phy-DRL具有三种独特的创新：i）前瞻性的未知未知训练，ii）结合残差控制（即数据驱动控制和基于物理模型的控制的集成）和安全及稳定性敏感的奖励，以及iii）基于物理模型的神经网络编辑，包括链接编辑和激活编辑。由于这些并发设计，Phy-DRL能够1）容忍未知干扰，2）保证可数学证明的安全与稳定性，并3）严格遵守Bellman方程和奖励相关的物理知识。最终，通过倒立摆和四足机器人的实验验证了Phy-DRL的有效性。实验结果表明，与纯数据驱动的DRL相比，Phy-DRL具有明显更少的学习参数、加速的训练和扩大的回报。

    In this paper, we propose the Phy-DRL: a physics-model-regulated deep reinforcement learning framework for safety-critical autonomous systems. The Phy-DRL is unique in three innovations: i) proactive unknown-unknowns training, ii) conjunctive residual control (i.e., integration of data-driven control and physics-model-based control) and safety- \& stability-sensitive reward, and iii) physics-model-based neural network editing, including link editing and activation editing. Thanks to the concurrent designs, the Phy-DRL is able to 1) tolerate unknown-unknowns disturbances, 2) guarantee mathematically provable safety and stability, and 3) strictly comply with physical knowledge pertaining to Bellman equation and reward. The effectiveness of the Phy-DRL is finally validated by an inverted pendulum and a quadruped robot. The experimental results demonstrate that compared with purely data-driven DRL, Phy-DRL features remarkably fewer learning parameters, accelerated training and enlarged rew
    
[^33]: 人人可复现的NLP研究：初学者的需求调查

    NLP Reproducibility For All: Understanding Experiences of Beginners. (arXiv:2305.16579v1 [cs.CL])

    [http://arxiv.org/abs/2305.16579](http://arxiv.org/abs/2305.16579)

    通过对93名NLP初学者的调查，发现研究作者提供完整文档、更好的代码实践和更易于获取的数据文件是初学者成功复现最近NLP论文结果的关键，建议NLP研究人员注重这些方面，更好地支持初学者。

    

    随着自然语言处理（NLP）近年来异常火爆，越来越多的人急于进入该领域，但目前的研究复现努力是否足以让这些初学者应用最新的进展还不清楚。为了了解初学者的需求，我们在一个介绍性的NLP课程中开展了一项研究，让学生复现最近NLP论文的结果。令人惊讶的是，我们发现他们的编程技能和对研究论文的理解对完成练习的付出仅有限的影响，相比之下，研究作者的可访问性努力是成功的关键，包括完整的文档、更好的编码实践和更容易获取的数据文件。前进时，我们建议NLP研究人员密切关注这些开源工作的简单方面，并使用初学者的反馈见解提供可操作的想法以更好地支持他们。

    As natural language processing (NLP) has recently seen an unprecedented level of excitement, and more people are eager to enter the field, it is unclear whether current research reproducibility efforts are sufficient for this group of beginners to apply the latest developments. To understand their needs, we conducted a study with 93 students in an introductory NLP course, where students reproduced the results of recent NLP papers. Surprisingly, we find that their programming skill and comprehension of research papers have a limited impact on their effort spent completing the exercise. Instead, we find accessibility efforts by research authors to be the key to success, including complete documentation, better coding practice, and easier access to data files. Going forward, we recommend that NLP researchers pay close attention to these simple aspects of open-sourcing their work, and use insights from beginners' feedback to provide actionable ideas on how to better support them.
    
[^34]: 基于数字孪生的边缘协助移动增强现实三维地图管理

    Digital Twin-Based 3D Map Management for Edge-Assisted Mobile Augmented Reality. (arXiv:2305.16571v1 [cs.NI])

    [http://arxiv.org/abs/2305.16571](http://arxiv.org/abs/2305.16571)

    本文提出了一种基于数字孪生的方案，用于辅助移动增强现实的三维地图管理，可显著降低姿态估计的不确定性，可以在高度动态的环境中快速提供自适应地图管理策略。

    

    本文为辅助移动增强现实（MAR）设计了一个三维地图管理方案，以支持个体MAR设备的姿态估计。通过定期选择适当的一组相机帧上传以更新三维地图，目标是将MAR设备的姿态估计不确定性最小化。为了解决动态上行数据速率和MAR设备的时变姿态的挑战，我们提出了一种基于数字孪生的方法来进行三维地图管理。首先，为MAR设备创建一个数字孪生，它基于预测后续相机帧来模拟三维地图管理。其次，开发了一种基于模型的强化学习算法（MBRL），利用从实际和模拟数据收集的数据来管理三维地图。通过数字孪生提供的大量模拟数据，MBRL算法可以在高度动态的环境中快速提供自适应地图管理策略。模拟结果表明，与基线方案相比，我们提出的基于数字孪生的方法显著降低了姿态估计的不确定性。

    In this paper, we design a 3D map management scheme for edge-assisted mobile augmented reality (MAR) to support the pose estimation of individual MAR device, which uploads camera frames to an edge server. Our objective is to minimize the pose estimation uncertainty of the MAR device by periodically selecting a proper set of camera frames for uploading to update the 3D map. To address the challenges of the dynamic uplink data rate and the time-varying pose of the MAR device, we propose a digital twin (DT)-based approach to 3D map management. First, a DT is created for the MAR device, which emulates 3D map management based on predicting subsequent camera frames. Second, a model-based reinforcement learning (MBRL) algorithm is developed, utilizing the data collected from both the actual and the emulated data to manage the 3D map. With extensive emulated data provided by the DT, the MBRL algorithm can quickly provide an adaptive map management policy in a highly dynamic environment. Simula
    
[^35]: LANISTR：从结构化和非结构化数据中进行多模态学习

    LANISTR: Multimodal Learning from Structured and Unstructured Data. (arXiv:2305.16556v1 [cs.LG])

    [http://arxiv.org/abs/2305.16556](http://arxiv.org/abs/2305.16556)

    LANISTR是一个新颖的基于注意力机制的框架，可从结构化和非结构化数据中进行学习，在挑战性数据集上表现优异。

    

    多模态的大规模预训练已经在处理非结构化数据（包括文本、图像、音频和视频）方面展现了令人瞩目的性能提升。但是，现实世界中最常见的情况是结构化（包括表格和时间序列）和非结构化数据的结合，但这一领域尚未得到充分的研究。为此，我们提出了LANISTR，这是一个新颖的基于注意力机制的框架，用于从语言、图像和结构化数据中进行学习。我们引入了一个新的多模态融合模块，并采用基于相似性的多模态遮罩损失，使得LANISTR能够在大规模多模态数据中学习跨模态关系，并在训练和测试时处理缺失的模态。在两个公开可用的具有挑战性的数据集MIMIC-IV和Amazon Product Review上，与最先进的多模态模型相比，LANISTR分别达到了6.47%（AUROC）和高达17.69%（准确度）的绝对提升，并显示出更强的泛化能力。

    Multimodal large-scale pretraining has shown impressive performance gains for unstructured data including language, image, audio, and video. Yet, the scenario most prominent in real-world applications is the existence of combination of structured (including tabular and time-series) and unstructured data, and this has so far been understudied. Towards this end, we propose LANISTR, a novel attention-based framework to learn from LANguage, Image, and STRuctured data. We introduce a new multimodal fusion module with a similarity-based multimodal masking loss that enables LANISTR to learn cross-modal relations from large-scale multimodal data with missing modalities during training and test time. On two publicly available challenging datasets, MIMIC-IV and Amazon Product Review, LANISTR achieves absolute improvements of 6.47% (AUROC) and up to 17.69% (accuracy), respectively, compared to the state-of-the-art multimodal models while showing superior generalization capabilities.
    
[^36]: 对话摘要中细粒度事实错误的注释和检测

    Annotating and Detecting Fine-grained Factual Errors for Dialogue Summarization. (arXiv:2305.16548v1 [cs.CL])

    [http://arxiv.org/abs/2305.16548](http://arxiv.org/abs/2305.16548)

    本论文提出第一个注释有细粒度事实错误的对话摘要数据集，探索了细粒度事实错误检测作为一个句子级多标签分类问题的挑战，并提出了一种无监督模型，取得了和 SOTA 模型相近的效果。

    

    针对格式良好的文档（如新闻文章）生成的摘要，已经提出了一系列数据集和模型。但是，对话摘要一直未被探索。本文介绍了第一个带有细粒度事实错误注释的数据集 DIASUMFACT。我们将细粒度事实错误检测定义为一个句子级多标签分类问题，并评估了两个最先进的模型在我们的数据集上的表现。两个模型都产生了次优结果，六个错误类别的宏平均 F1 分数约为 0.25。我们进一步提出了一种使用预训练编码器-解码器模型进行候选排名的无监督模型 ENDERANKER。我们的模型表现与 SOTA 模型不相上下，同时需要较少的资源。这些观察结果证实了从对话摘要中检测事实错误的挑战，这需要进一步的研究，而我们的数据集和实验结果为此提供了坚实的基础。

    A series of datasets and models have been proposed for summaries generated for well-formatted documents such as news articles. Dialogue summaries, however, have been under explored. In this paper, we present the first dataset with fine-grained factual error annotations named DIASUMFACT. We define fine-grained factual error detection as a sentence-level multi-label classification problem, and we evaluate two state-of-the-art (SOTA) models on our dataset. Both models yield sub-optimal results, with a macro-averaged F1 score of around 0.25 over 6 error classes. We further propose an unsupervised model ENDERANKER via candidate ranking using pretrained encoder-decoder models. Our model performs on par with the SOTA models while requiring fewer resources. These observations confirm the challenges in detecting factual errors from dialogue summaries, which call for further studies, for which our dataset and results offer a solid foundation.
    
[^37]: 开源大语言模型对工具操作能力的研究

    On the Tool Manipulation Capability of Open-source Large Language Models. (arXiv:2305.16504v1 [cs.CL])

    [http://arxiv.org/abs/2305.16504](http://arxiv.org/abs/2305.16504)

    本研究探讨了如何通过训练使用示例、上下文演示和生成样式规则来加强开源LLMs以达到与封闭型API的工具操作性能同等甚至更优的效果，并通过ToolBench测试得出了实验结果，同时本文还证明了改进的开源LLMs的鲁棒性。

    

    近期对使用大型语言模型( LLMs)进行软件工具操作的研究大多依赖于封闭模型API。由于向封闭LLMAPI服务公开信息存在安全和鲁棒性风险，这些模型的工业采用受到了实质性限制。本文提出了一个问题，那就是我们能否在实践中加强开源LLMs的功能，使其在工具操作方面与领先的封闭LLM APIs竞争。通过分析常见的工具操作失败，我们首先展示了开源LLMs可能需要训练使用示例、上下文演示和生成样式规则来解决失败。这些见解激发我们重新审视LLM文献中的经典方法，并证明我们可以将它们作为程序数据生成的模型对齐、系统提示和上下文演示检索器来适应开源LLMs以实现工具操作的增强。为了评估这些技术，我们创建了ToolBench，一个工具操作能力测试套件，包括现有API和我们改进的开源LLMs。在三个不同的编程任务上，我们发现改进的开源LLMs能够达到或超越现有API的性能，其中包括对已编写的程序进行轻微修改等实际操作。此外，我们通过反向工程测试和黑盒测试进一步证明了模型的鲁棒性。

    Recent studies on software tool manipulation with large language models (LLMs) mostly rely on closed model APIs. The industrial adoption of these models is substantially constrained due to the security and robustness risks in exposing information to closed LLM API services. In this paper, we ask can we enhance open-source LLMs to be competitive to leading closed LLM APIs in tool manipulation, with practical amount of human supervision. By analyzing common tool manipulation failures, we first demonstrate that open-source LLMs may require training with usage examples, in-context demonstration and generation style regulation to resolve failures. These insights motivate us to revisit classical methods in LLM literature, and demonstrate that we can adapt them as model alignment with programmatic data generation, system prompts and in-context demonstration retrievers to enhance open-source LLMs for tool manipulation. To evaluate these techniques, we create the ToolBench, a tool manipulation 
    
[^38]: AD-NEV：一种可扩展的多层神经进化框架用于多元异常检测

    AD-NEV: A Scalable Multi-level Neuroevolution Framework for Multivariate Anomaly Detection. (arXiv:2305.16497v1 [cs.LG])

    [http://arxiv.org/abs/2305.16497](http://arxiv.org/abs/2305.16497)

    AD-NEv提出了一种可扩展的多级优化神经进化框架，用于多元时间序列异常检测，通过协同优化特征子空间、模型架构和模型权重的方法，表现出比当前最先进的方法更好的检测精度和计算效率。

    

    异常检测工具和方法在现代的智能物理系统和故障预测系统中具有关键能力。尽管深度学习架构在异常检测中的发展迅速，但针对给定数据集的模型优化是一个繁琐而耗时的过程。神经进化可以是这个问题的有效和高效解决方案，是一种完全自动化的搜索方法，用于学习最优的神经网络，支持梯度和非梯度的微调。然而，现有的方法大多集中于优化模型结构，而未考虑特征子空间和模型权重。在本研究中，我们提出了一种名为Anomaly Detection Neuroevolution (AD-NEv)的可扩展多级优化神经进化框架，用于多元时间序列异常检测。该方法表示一种新颖的方法来协同优化：i) 基于装袋技术对集合模型进行特征子空间优化; ii) 优化单个异常检测网络的模型架构; iii) 使用梯度和非梯度方法优化模型权重。所提出的框架可扩展，可应用于不同大小和维度的数据集。基准数据集上的实验结果表明，AD-NEv在检测精度和计算效率方面表现优于或可与当前最先进的方法相媲美。

    Anomaly detection tools and methods present a key capability in modern cyberphysical and failure prediction systems. Despite the fast-paced development in deep learning architectures for anomaly detection, model optimization for a given dataset is a cumbersome and time consuming process. Neuroevolution could be an effective and efficient solution to this problem, as a fully automated search method for learning optimal neural networks, supporting both gradient and non-gradient fine tuning. However, existing methods mostly focus on optimizing model architectures without taking into account feature subspaces and model weights. In this work, we propose Anomaly Detection Neuroevolution (AD-NEv) - a scalable multi-level optimized neuroevolution framework for multivariate time series anomaly detection. The method represents a novel approach to synergically: i) optimize feature subspaces for an ensemble model based on the bagging technique; ii) optimize the model architecture of single anomaly
    
[^39]: 基于扩散的对抗样本生成以提高隐蔽性和可控性

    Diffusion-Based Adversarial Sample Generation for Improved Stealthiness and Controllability. (arXiv:2305.16494v1 [cs.CV])

    [http://arxiv.org/abs/2305.16494](http://arxiv.org/abs/2305.16494)

    本文提出了一个名为Diff-PGD的新框架，用于生成接近原始数据分布、逼真的对抗样本，具有较好的隐蔽性和对抗强度可调性。

    

    神经网络容易受到对抗样本的影响：这是一种特意制作的自然图片的微小变化，旨在误导模型。虽然这些对抗样本在数字和物理场景中可以轻松生成，但它们往往与自然图像的实际数据分布差异很大，导致强度与隐蔽性之间存在权衡。本文提出了一个名为扩散-投影梯度下降（Diff-PGD）的新框架，用于生成逼真的对抗样本。通过利用扩散模型引导的梯度，Diff-PGD确保对抗样本保持接近原始数据分布，同时保持它们的有效性。此外，我们的框架可以轻松定制特定任务，如数字攻击、物理攻击和基于样式的攻击。与现有的生成自然风格对抗样本方法相比，我们的框架可以分离优化对抗强度和隐蔽性，提供更大的灵活性和对生成样本的控制。

    Neural networks are known to be susceptible to adversarial samples: small variations of natural examples crafted to deliberately mislead the models. While they can be easily generated using gradient-based techniques in digital and physical scenarios, they often differ greatly from the actual data distribution of natural images, resulting in a trade-off between strength and stealthiness. In this paper, we propose a novel framework dubbed Diffusion-Based Projected Gradient Descent (Diff-PGD) for generating realistic adversarial samples. By exploiting a gradient guided by a diffusion model, Diff-PGD ensures that adversarial samples remain close to the original data distribution while maintaining their effectiveness. Moreover, our framework can be easily customized for specific tasks such as digital attacks, physical-world attacks, and style-based attacks. Compared with existing methods for generating natural-style adversarial samples, our framework enables the separation of optimizing adv
    
[^40]: EgoHumans:一种以自我为中心的三维多人基准数据集

    EgoHumans: An Egocentric 3D Multi-Human Benchmark. (arXiv:2305.16487v1 [cs.CV])

    [http://arxiv.org/abs/2305.16487](http://arxiv.org/abs/2305.16487)

    EgoHumans是一个全面的自我中心多人基准数据集，旨在推进自我中心的人类三维姿态估计和跟踪的最新进展，可以支持各种任务，包括人类检测、跟踪、2D/3D姿态估计和网格恢复等，并且能够捕捉具有挑战性和无核编排的多人场景。

    

    我们提出了EgoHumans，这是一个新的视角多人视频基准数据集，旨在推进自我中心的人类三维姿态估计和跟踪的最新进展。现有的自我中心基准数据集仅捕捉单个主体或仅限于室内场景，这限制了计算机视觉算法在现实世界应用中的泛化能力。我们提出了一种新的三维捕获设定，构建了一个全面的自我中心多人基准数据集，并提供注释支持各种任务，例如人类检测、跟踪、2D/3D姿态估计和网格恢复等。我们利用带摄像头的普通眼镜进行视角捕捉，并能够捕捉诸如踢足球、击剑、排球等动态活动。此外，我们的多视角设置在严重或完全遮挡下仍能生成准确的3D基准数据。该数据集包含超过125k个自我中心图像，跨越多种场景，特别关注具有挑战性和无核编排的多人场景。

    We present EgoHumans, a new multi-view multi-human video benchmark to advance the state-of-the-art of egocentric human 3D pose estimation and tracking. Existing egocentric benchmarks either capture single subject or indoor-only scenarios, which limit the generalization of computer vision algorithms for real-world applications. We propose a novel 3D capture setup to construct a comprehensive egocentric multi-human benchmark in the wild with annotations to support diverse tasks such as human detection, tracking, 2D/3D pose estimation, and mesh recovery. We leverage consumer-grade wearable camera-equipped glasses for the egocentric view, which enables us to capture dynamic activities like playing soccer, fencing, volleyball, etc. Furthermore, our multi-view setup generates accurate 3D ground truth even under severe or complete occlusion. The dataset consists of more than 125k egocentric images, spanning diverse scenes with a particular focus on challenging and unchoreographed multi-human 
    
[^41]: 批次模型整合：一个多任务模型整合框架

    Batch Model Consolidation: A Multi-Task Model Consolidation Framework. (arXiv:2305.16484v1 [cs.LG])

    [http://arxiv.org/abs/2305.16484](http://arxiv.org/abs/2305.16484)

    本文提出了批次模型整合（BMC）来支持更现实的连续学习，它通过在正则化阶段训练多个专家模型来学习一组不相交的任务，并在整合阶段将多个专家模型整合为一个模型。

    

    在连续学习中，模型需要按顺序学习一系列任务，而不会在之前学习的任务上出现显着的性能下降。现有方法在面对各种领域和难度的长序列任务时效果不佳。许多现有的连续学习方法由于内存资源消耗过大或训练时间过长而难以在实践中应用，或只能在单个设备上紧密耦合。本文提出批次模型整合（BMC）来支持更现实的连续学习，面对多个代理在各种任务中接触的情况。在正则化阶段，BMC并行训练多个专家模型来学习一组不相交的任务。每个专家通过稳定性损失与一个基础模型保持权重相似性，并从任务数据的一部分构建缓冲区。在整合阶段，我们将多个专家模型整合为一个模型，并在目标任务上进行微调。

    In Continual Learning (CL), a model is required to learn a stream of tasks sequentially without significant performance degradation on previously learned tasks. Current approaches fail for a long sequence of tasks from diverse domains and difficulties. Many of the existing CL approaches are difficult to apply in practice due to excessive memory cost or training time, or are tightly coupled to a single device. With the intuition derived from the widely applied mini-batch training, we propose Batch Model Consolidation ($\textbf{BMC}$) to support more realistic CL under conditions where multiple agents are exposed to a range of tasks. During a $\textit{regularization}$ phase, BMC trains multiple $\textit{expert models}$ in parallel on a set of disjoint tasks. Each expert maintains weight similarity to a $\textit{base model}$ through a $\textit{stability loss}$, and constructs a $\textit{buffer}$ from a fraction of the task's data. During the $\textit{consolidation}$ phase, we combine the 
    
[^42]: 第二决策者警报：人工智能冲突简介

    Alert of the Second Decision-maker: An Introduction to Human-AI Conflict. (arXiv:2305.16477v1 [cs.HC])

    [http://arxiv.org/abs/2305.16477](http://arxiv.org/abs/2305.16477)

    本文介绍了人工智能冲突的概念、原因、测量方法和风险评估，突出显示人工智能是潜在的第二决策者，冲突风险是显著的，不能被忽视。

    

    人类和人工智能（AI）之间的合作是这个数字时代的一个重要特征。然而，在同步工作时，人类和AI可能存在观察、解释和行动上的冲突。这种现象通常被故障掩盖，不幸的是，被忽视了。本文系统地介绍了人工智能冲突的概念、原因、测量方法和风险评估。结果突出显示，除了人类以外，还存在潜在的第二决策者，即AI；人工智能冲突是数字化流程系统中独特而新兴的风险；这是一个需要与传统的故障和失效分析区分的跨学科领域；冲突风险是显著的，不能被忽视。

    The collaboration between humans and artificial intelligence (AI) is a significant feature in this digital age. However, humans and AI may have observation, interpretation, and action conflicts when working synchronously. This phenomenon is often masked by faults and, unfortunately, overlooked. This paper systematically introduces the human-AI conflict concept, causes, measurement methods, and risk assessment. The results highlight that there is a potential second decision-maker besides the human, which is the AI; the human-AI conflict is a unique and emerging risk in digitalized process systems; and this is an interdisciplinary field that needs to be distinguished from traditional fault and failure analysis; the conflict risk is significant and cannot be ignored.
    
[^43]: 优化的自定义数据集用于高效检测水下垃圾

    Optimized Custom Dataset for Efficient Detection of Underwater Trash. (arXiv:2305.16460v1 [cs.CV])

    [http://arxiv.org/abs/2305.16460](http://arxiv.org/abs/2305.16460)

    本文提出了一种自定义数据集和有效检测方法，旨在通过增加垃圾实例的多样性，在深入水下环境中提高其检测精度。

    

    准确评估和清除潜在的水下废物对于保护海洋生物和环境至关重要。本文针对水下垃圾检测所存在的挑战，如光折射、吸收、悬浮颗粒和色彩扭曲等因素，提出了一种自定义数据集和有效检测方法。该数据集涵盖了多种水下环境，并包括对废弃物实例的精确定位标注。最终，使用最先进的深度学习结构，目的是通过增加垃圾实例的多样性，在深入水下环境中提高其检测精度。

    Accurately quantifying and removing submerged underwater waste plays a crucial role in safeguarding marine life and preserving the environment. While detecting floating and surface debris is relatively straightforward, quantifying submerged waste presents significant challenges due to factors like light refraction, absorption, suspended particles, and color distortion. This paper addresses these challenges by proposing the development of a custom dataset and an efficient detection approach for submerged marine debris. The dataset encompasses diverse underwater environments and incorporates annotations for precise labeling of debris instances. Ultimately, the primary objective of this custom dataset is to enhance the diversity of litter instances and improve their detection accuracy in deep submerged environments by leveraging state-of-the-art deep learning architectures.
    
[^44]: KeyPosS: 基于 GPS 灵感的真实距离多边定位的即插即用面部标记检测

    KeyPosS: Plug-and-Play Facial Landmark Detection through GPS-Inspired True-Range Multilateration. (arXiv:2305.16437v1 [cs.CV])

    [http://arxiv.org/abs/2305.16437](http://arxiv.org/abs/2305.16437)

    KeyPosS是一种面部标记检测框架，采用真实距离多边定位算法实现快速而准确的检测，避免了传统方法中的计算负担和量化误差问题。

    

    在面部分析领域，准确的标记检测对于各种应用至关重要，包括人脸识别和表情分析等。然而，传统的热力图或坐标回归技术经常面临计算负担和量化误差等挑战。为解决这些问题，我们提出了 KeyPoint Positioning System（KeyPosS），这是一种突破性的面部标记检测框架，与现有方法不同。KeyPosS首次采用真实距离多边定位算法，一种最初用于GPS系统的技术，通过不依赖于计算密集型回归方法实现快速而准确的面部标记检测。该框架利用完全卷积网络预测距离图，计算感兴趣点（POI）与多个锚点之间的距离。通过巧妙地利用这些锚点来三角测量POI的位置，实现面部标记的检测。

    In the realm of facial analysis, accurate landmark detection is crucial for various applications, ranging from face recognition and expression analysis to animation. Conventional heatmap or coordinate regression-based techniques, however, often face challenges in terms of computational burden and quantization errors. To address these issues, we present the KeyPoint Positioning System (KeyPosS), a groundbreaking facial landmark detection framework that stands out from existing methods. For the first time, KeyPosS employs the True-range Multilateration algorithm, a technique originally used in GPS systems, to achieve rapid and precise facial landmark detection without relying on computationally intensive regression approaches. The framework utilizes a fully convolutional network to predict a distance map, which computes the distance between a Point of Interest (POI) and multiple anchor points. These anchor points are ingeniously harnessed to triangulate the POI's position through the Tru
    
[^45]: 神经（切向核）崩溃

    Neural (Tangent Kernel) Collapse. (arXiv:2305.16427v1 [cs.LG])

    [http://arxiv.org/abs/2305.16427](http://arxiv.org/abs/2305.16427)

    本文介绍了神经切向核（NTK）和神经崩溃（NC）之间的关系，证明了在具有块状NTK的DNN中会出现NC，并通过大规模实验支持理论的正确性。

    

    本文介绍了两个重要的概念：神经切向核（NTK），它捕捉深度神经网络（DNN）训练期间的演化和神经崩溃（NC）现象，它指的是经过良好训练的分类DNN最后一层特征中对称性和结构的出现。我们假设经验NTK与类标签对齐并形成块状结构，即同一类别的样本之间的相关性比不同类别的样本更强，基于这个假设，我们推导了使用均方误差（MSE）训练的DNN动态，并将其分解为可解释的阶段。此外，我们确定了一种不变量，捕捉了动态的本质，并用它证明了在具有块状NTK的DNN中会出现NC。我们进行了三种常见DNN架构和三个基准数据集的大规模数值实验来支持我们的理论。

    This work bridges two important concepts: the Neural Tangent Kernel (NTK), which captures the evolution of deep neural networks (DNNs) during training, and the Neural Collapse (NC) phenomenon, which refers to the emergence of symmetry and structure in the last-layer features of well-trained classification DNNs. We adopt the natural assumption that the empirical NTK develops a block structure aligned with the class labels, i.e., samples within the same class have stronger correlations than samples from different classes. Under this assumption, we derive the dynamics of DNNs trained with mean squared (MSE) loss and break them into interpretable phases. Moreover, we identify an invariant that captures the essence of the dynamics, and use it to prove the emergence of NC in DNNs with block-structured NTK. We provide large-scale numerical experiments on three common DNN architectures and three benchmark datasets to support our theory.
    
[^46]: SketchOGD：内存高效的持续学习

    SketchOGD: Memory-Efficient Continual Learning. (arXiv:2305.16424v1 [cs.LG])

    [http://arxiv.org/abs/2305.16424](http://arxiv.org/abs/2305.16424)

    SketchOGD提出了一种内存高效的解决灾难性遗忘的方法，通过采用在线草图算法，将模型梯度压缩为固定大小的矩阵，从而改进了现有的算法——正交梯度下降（OGD）。

    

    当机器学习模型在一系列任务上持续训练时，它们容易忘记先前任务上学习到的知识，这种现象称为灾难性遗忘。现有的解决灾难性遗忘的方法往往涉及存储过去任务的信息，这意味着内存使用是确定实用性的主要因素。本文提出了一种内存高效的解决灾难性遗忘的方法，改进了一种已有的算法——正交梯度下降（OGD）。OGD利用先前模型梯度来找到维持先前数据点性能的权重更新。然而，由于存储先前模型梯度的内存成本随算法运行时间增长而增加，因此OGD不适用于任意长时间跨度的连续学习。针对这个问题，本文提出了SketchOGD。SketchOGD采用在线草图算法，将模型梯度压缩为固定大小的矩阵。

    When machine learning models are trained continually on a sequence of tasks, they are liable to forget what they learned on previous tasks -- a phenomenon known as catastrophic forgetting. Proposed solutions to catastrophic forgetting tend to involve storing information about past tasks, meaning that memory usage is a chief consideration in determining their practicality. This paper proposes a memory-efficient solution to catastrophic forgetting, improving upon an established algorithm known as orthogonal gradient descent (OGD). OGD utilizes prior model gradients to find weight updates that preserve performance on prior datapoints. However, since the memory cost of storing prior model gradients grows with the runtime of the algorithm, OGD is ill-suited to continual learning over arbitrarily long time horizons. To address this problem, this paper proposes SketchOGD. SketchOGD employs an online sketching algorithm to compress model gradients as they are encountered into a matrix of a fix
    
[^47]: NODDLE：基于Node2vec的深度学习模型的链路预测

    NODDLE: Node2vec based deep learning model for link prediction. (arXiv:2305.16421v1 [cs.SI])

    [http://arxiv.org/abs/2305.16421](http://arxiv.org/abs/2305.16421)

    NODDLE是一种用于链路预测的深度学习模型，结合了node2vec提取的特征和四层隐藏神经网络，并利用自适应学习优化器提高性能。

    

    链路预测是计算图网络中边存在概率的过程。传统方法计算静态网络中给定节点的相似度，而最近的研究侧重于评估动态演化的网络。尽管深度学习技术和网络表示学习算法（例如node2vec）在预测准确性方面表现出卓越的改进，但node2vec中的随机梯度下降（SGD）方法由于缺乏先前的网络信息而易陷入平庸的本地最优值，导致无法捕捉网络的全局结构。为了解决这个问题，我们提出了NODDLE（NOde2vec和Deep Learning mEthod的集成）深度学习模型，该模型融合了node2vec提取的特征，并将其馈送到四层隐藏神经网络中。NODDLE利用自适应学习优化器（如Adam，Adamax，Adadelta和Adagrad）来提高性能。

    Computing the probability of an edge's existence in a graph network is known as link prediction. While traditional methods calculate the similarity between two given nodes in a static network, recent research has focused on evaluating networks that evolve dynamically. Although deep learning techniques and network representation learning algorithms, such as node2vec, show remarkable improvements in prediction accuracy, the Stochastic Gradient Descent (SGD) method of node2vec tends to fall into a mediocre local optimum value due to a shortage of prior network information, resulting in failure to capture the global structure of the network. To tackle this problem, we propose NODDLE (integration of NOde2vec anD Deep Learning mEthod), a deep learning model which incorporates the features extracted by node2vec and feeds them into a four layer hidden neural network. NODDLE takes advantage of adaptive learning optimizers such as Adam, Adamax, Adadelta, and Adagrad to improve the performance of
    
[^48]: GrowSP：3D点云无监督语义分割

    GrowSP: Unsupervised Semantic Segmentation of 3D Point Clouds. (arXiv:2305.16404v1 [cs.CV])

    [http://arxiv.org/abs/2305.16404](http://arxiv.org/abs/2305.16404)

    本文提出了一种名为GrowSP的无监督方法来进行3D场景中每个点复杂语义类别的识别和分割，方法通过逐步增长超级点的大小来发现3D语义元素，并优于所有无监督基线。

    

    本论文研究从原始点云中进行3D语义分割的问题。与现有方法主要依赖于大量的人工注释来训练神经网络不同，我们提出了第一个完全无监督的方法GrowSP，成功地为3D场景中的每个点识别出复杂的语义类别，无需任何形式的人工标签或预训练模型。我们的方法的关键是通过超级点的逐步增长来发现3D语义元素。我们的方法由三个主要组成部分组成：1）特征提取器从输入点云中学习每个点的特征；2）超级点构造器逐步增加超级点的大小；3）语义原始聚类模块将超级点分组成语义元素以实现最终的语义分割。我们在多个数据集上进行了广泛的评估，证明了我们的方法优于所有无监督基线，并接近经典完全监督的PointNet模型的表现。

    We study the problem of 3D semantic segmentation from raw point clouds. Unlike existing methods which primarily rely on a large amount of human annotations for training neural networks, we propose the first purely unsupervised method, called GrowSP, to successfully identify complex semantic classes for every point in 3D scenes, without needing any type of human labels or pretrained models. The key to our approach is to discover 3D semantic elements via progressive growing of superpoints. Our method consists of three major components, 1) the feature extractor to learn per-point features from input point clouds, 2) the superpoint constructor to progressively grow the sizes of superpoints, and 3) the semantic primitive clustering module to group superpoints into semantic elements for the final semantic segmentation. We extensively evaluate our method on multiple datasets, demonstrating superior performance over all unsupervised baselines and approaching the classic fully-supervised PointN
    
[^49]: 扩散模型是否是视觉语言推理器？

    Are Diffusion Models Vision-And-Language Reasoners?. (arXiv:2305.16397v1 [cs.CV])

    [http://arxiv.org/abs/2305.16397](http://arxiv.org/abs/2305.16397)

    本文针对扩散-语言图像生成模型进行转换和评估，介绍了生成-鉴别评估基准(GDBench)基于7个视觉语言复杂任务，并发现转换后的模型在组合性任务方面的表现优于CLIP，通过微调可提高其组合性能。

    

    近期，使用去噪扩散过程的文本-图像生成模型已取得了巨大的定性成功。然而，与鉴别式视觉-语言模型不同，将基于扩散的生成模型置于自动细粒度定量评估高级现象（如组合性）的任务中是一项非常棘手的任务。为此，我们开展了两项创新。首先，我们使用一种称为DiffusionITM的新方法将基于扩散的模型（在我们的情况下，是稳定扩散）转换为任何图像文本匹配(ITM)任务。其次，我们引入了7个复杂的视觉语言任务、偏差评估和详细分析的生成-鉴别评估基准(GDBench)。我们发现，Stable Diffusion + DiffusionITM在许多任务上具有竞争力，并在组合性任务（如CLEVR和Winoground等）上优于CLIP。我们通过在MS-COCO上微调保持图像特征的转移设置进一步提高其组合性能。

    Text-conditioned image generation models have recently shown immense qualitative success using denoising diffusion processes. However, unlike discriminative vision-and-language models, it is a non-trivial task to subject these diffusion-based generative models to automatic fine-grained quantitative evaluation of high-level phenomena such as compositionality. Towards this goal, we perform two innovations. First, we transform diffusion-based models (in our case, Stable Diffusion) for any image-text matching (ITM) task using a novel method called DiffusionITM. Second, we introduce the Generative-Discriminative Evaluation Benchmark (GDBench) benchmark with 7 complex vision-and-language tasks, bias evaluation and detailed analysis. We find that Stable Diffusion + DiffusionITM is competitive on many tasks and outperforms CLIP on compositional tasks like like CLEVR and Winoground. We further boost its compositional performance with a transfer setup by fine-tuning on MS-COCO while retaining ge
    
[^50]: 扫描与拍照：理解1层Transformer中的训练动态和标记组成

    Scan and Snap: Understanding Training Dynamics and Token Composition in 1-layer Transformer. (arXiv:2305.16380v1 [cs.CL])

    [http://arxiv.org/abs/2305.16380](http://arxiv.org/abs/2305.16380)

    本文分析了1层Transformer在下一个标记预测任务中的SGD训练动态，证明了自我关注层充当了“区分性扫描算法”，从而逐步关注到相关标记并排除不相关的标记，总结相关信息在编码表示中。同时研究了标记频率、上下文和初始化自我关注层等对Transformer性能的影响。

    

    Transformer架构在多个研究领域表现出了惊人的性能，并成为许多神经网络模型的基础。然而，我们对其如何工作的理解仍然有限。特别是，通过简单的预测性损失，表示如何从梯度训练动态中出现仍然是一个谜。在本文中，针对具有一个自我关注层和一个解码器层的1层Transformer，我们以数学严谨的方式分析其在下一个标记预测任务中的SGD训练动态。我们打开了自我关注层组合输入标记的动态过程的黑盒子，并揭示了底层归纳偏差的本质。具体而言，在没有位置编码、长输入序列和解码器层学习速度快于自我关注层的假设下，我们证明了自我关注层充当了“区分性扫描算法”：从均匀注意力开始，它逐渐关注到相关标记，排除不相关的标记，直到所有相关信息被扫描并总结在编码表示中。我们的分析还显示了标记频率和上下文如何影响注意权重，以及自我关注层初始化如何影响收敛速度。

    Transformer architecture has shown impressive performance in multiple research domains and has become the backbone of many neural network models. However, there is limited understanding on how it works. In particular, with a simple predictive loss, how the representation emerges from the gradient \emph{training dynamics} remains a mystery. In this paper, for 1-layer transformer with one self-attention layer plus one decoder layer, we analyze its SGD training dynamics for the task of next token prediction in a mathematically rigorous manner. We open the black box of the dynamic process of how the self-attention layer combines input tokens, and reveal the nature of underlying inductive bias. More specifically, with the assumption (a) no positional encoding, (b) long input sequence, and (c) the decoder layer learns faster than the self-attention layer, we prove that self-attention acts as a \emph{discriminative scanning algorithm}: starting from uniform attention, it gradually attends mor
    
[^51]: 有效增强视觉强化学习的样本利用率：以少学更好

    Learning Better with Less: Effective Augmentation for Sample-Efficient Visual Reinforcement Learning. (arXiv:2305.16379v1 [cs.LG])

    [http://arxiv.org/abs/2305.16379](http://arxiv.org/abs/2305.16379)

    本研究发现，对于数据增强在视觉强化学习中的有效性，空间多样性和轻微的困难度不可或缺。并提出了一种新的DA操作——Rand PR，它提供了丰富的空间多样性和最小的困难度，已经在多种数据上得到了有效性验证。

    

    数据增强（DA）是增强视觉强化学习（RL）算法的样本效率的关键技术。值得注意的是，仅使用简单的观察变换就可以在不进行额外辅助表示任务或预训练编码器的情况下获得出色的性能。然而，仍然不清楚DA的哪些属性是实现样本效率视觉RL的有效性的原因。为了调查这个问题并进一步探索DA的潜力，本文进行了全面的实验，评估了DA属性对其有效性的影响，并提供以下见解和改进：（1）对于单个DA操作，我们揭示了充足的空间多样性和轻微的困难度都是不可缺少的。基于这一发现，我们引入了一种新的DA操作——随机PadResize（Rand PR），它提供了丰富的空间多样性和最小的困难度。（2）对于多类型的DA融合方案，增加的DA困难度和不稳定的数据分布

    Data augmentation (DA) is a crucial technique for enhancing the sample efficiency of visual reinforcement learning (RL) algorithms. Notably, employing simple observation transformations alone can yield outstanding performance without extra auxiliary representation tasks or pre-trained encoders. However, it remains unclear which attributes of DA account for its effectiveness in achieving sample-efficient visual RL. To investigate this issue and further explore the potential of DA, this work conducts comprehensive experiments to assess the impact of DA's attributes on its efficacy and provides the following insights and improvements: (1) For individual DA operations, we reveal that both ample spatial diversity and slight hardness are indispensable. Building on this finding, we introduce Random PadResize (Rand PR), a new DA operation that offers abundant spatial diversity with minimal hardness. (2) For multi-type DA fusion schemes, the increased DA hardness and unstable data distribution 
    
[^52]: Sim-Suction: 使用合成基准学习在杂乱环境中的吸盘抓取策略

    Sim-Suction: Learning a Suction Grasp Policy for Cluttered Environments Using a Synthetic Benchmark. (arXiv:2305.16378v1 [cs.RO])

    [http://arxiv.org/abs/2305.16378](http://arxiv.org/abs/2305.16378)

    Sim-Suction 提出了一种新颖的物体感知吸盘抓取策略，使用基于合成数据集的方法解决了在杂乱环境下感兴趣的物体与周围环境之间关系的问题。

    

    本文提出了 Sim-Suction，一种针对移动操作平台的、适用于具有动态摄像机视角的、用于在杂乱环境中拾取未知物体的鲁棒性物体感知吸盘抓取策略。通常采用数据驱动方法实现吸盘抓取策略，需要大规模、精确注释的吸盘抓取数据集。然而，在杂乱环境中生成吸盘抓取数据集仍然缺乏研究，存在着关于感兴趣的物体与其周围环境之间关系的不确定性。因此，本文提出了一个基准合成数据集 Sim-Suction-Dataset，包括 500 个杂乱环境和 320 万个注释的吸盘抓取姿态。高效的 Sim-Suction-Dataset 生成过程通过将分析模型与动态物理模拟相结合来创建快速而准确的吸盘抓取姿态注释，提供了新的见解。我们引入了 Sim-Suction-Pointnet，通过学习点来生成鲁棒的 6D 吸盘抓取姿态。

    This paper presents Sim-Suction, a robust object-aware suction grasp policy for mobile manipulation platforms with dynamic camera viewpoints, designed to pick up unknown objects from cluttered environments. Suction grasp policies typically employ data-driven approaches, necessitating large-scale, accurately-annotated suction grasp datasets. However, the generation of suction grasp datasets in cluttered environments remains underexplored, leaving uncertainties about the relationship between the object of interest and its surroundings. To address this, we propose a benchmark synthetic dataset, Sim-Suction-Dataset, comprising 500 cluttered environments with 3.2 million annotated suction grasp poses. The efficient Sim-Suction-Dataset generation process provides novel insights by combining analytical models with dynamic physical simulations to create fast and accurate suction grasp pose annotations. We introduce Sim-Suction-Pointnet to generate robust 6D suction grasp poses by learning poin
    
[^53]: DeepGate2: 功能感知的电路表示学习

    DeepGate2: Functionality-Aware Circuit Representation Learning. (arXiv:2305.16373v1 [cs.LG])

    [http://arxiv.org/abs/2305.16373](http://arxiv.org/abs/2305.16373)

    本文介绍了DeepGate2, 一个新的功能感知学习框架，其通过利用成对真值表差异作为训练监督，明确考虑电路功能，来提高电路表示学习的学习效果和效率。

    

    电路表示学习旨在获得电路元件的神经表示，并已成为可以应用于各种EDA和逻辑推理任务的有前途的研究方向。现有的解决方案，例如DeepGate，可以嵌入电路结构信息和功能行为。然而，它们的能力受到弱监督或错误的模型设计的限制，导致下游任务的性能令人不满意。在本文中，我们介绍了DeepGate2，这是一个新颖的功能感知学习框架，其在学习效果和效率方面显着优于原DeepGate解决方案。我们的方法涉及使用样本逻辑门之间的成对真值表差异作为训练监督，以及一个经过精心设计和可扩展的损失函数，明确考虑电路功能。此外，我们考虑电路的固有特性，并设计了一个高效的一轮图表达方法，以实现更好的性能。

    Circuit representation learning aims to obtain neural representations of circuit elements and has emerged as a promising research direction that can be applied to various EDA and logic reasoning tasks. Existing solutions, such as DeepGate, have the potential to embed both circuit structural information and functional behavior. However, their capabilities are limited due to weak supervision or flawed model design, resulting in unsatisfactory performance in downstream tasks. In this paper, we introduce DeepGate2, a novel functionality-aware learning framework that significantly improves upon the original DeepGate solution in terms of both learning effectiveness and efficiency. Our approach involves using pairwise truth table differences between sampled logic gates as training supervision, along with a well-designed and scalable loss function that explicitly considers circuit functionality. Additionally, we consider inherent circuit characteristics and design an efficient one-round graph 
    
[^54]: 应用于材料学领域高维无监督聚类任务的等向度量

    Metrics for quantifying isotropy in high dimensional unsupervised clustering tasks in a materials context. (arXiv:2305.16372v1 [cs.LG])

    [http://arxiv.org/abs/2305.16372](http://arxiv.org/abs/2305.16372)

    该论文提出了一种新的对聚类等向性度量的实现方法，并使用分数各向异性扩展了这些度量来检查聚类的平均等向性。通过量化不同材料结构数据库表示的核逼近函数对结果聚类的影响，演示了这种度量的实际应用。

    

    聚类是机器学习中常见的任务，但无标签数据的聚类可能难以量化。化学中的聚类算法通常依赖于材料表示。由于数据的维度，确定不同表示、聚类算法或数据变换对结果聚类的影响是困难的。我们提出了一种对聚类等向性度量的详细分析，包括一种基于现有推导的新的实现方法。使用分数各向异性，这是一种用于比较医学成像常用的方法，我们进而扩展这些度量，以检查一组聚类的平均等向性。通过量化不同材料结构数据库表示的核逼近函数对结果聚类的影响，演示了这些度量的用例。这些方法的广泛适用性也在分析MNIST数据集的学习嵌入中得到了证明。随机聚类

    Clustering is a common task in machine learning, but clusters of unlabelled data can be hard to quantify. The application of clustering algorithms in chemistry is often dependant on material representation. Ascertaining the effects of different representations, clustering algorithms, or data transformations on the resulting clusters is difficult due to the dimensionality of these data. We present a thorough analysis of measures for isotropy of a cluster, including a novel implantation based on an existing derivation. Using fractional anisotropy, a common method used in medical imaging for comparison, we then expand these measures to examine the average isotropy of a set of clusters. A use case for such measures is demonstrated by quantifying the effects of kernel approximation functions on different representations of the Inorganic Crystal Structure Database. Broader applicability of these methods is demonstrated in analysing learnt embedding of the MNIST dataset. Random clusters are e
    
[^55]: Stecformer：基于空间-时间编码串联变压器的多元长期时间序列预测

    Stecformer: Spatio-temporal Encoding Cascaded Transformer for Multivariate Long-term Time Series Forecasting. (arXiv:2305.16370v1 [cs.LG])

    [http://arxiv.org/abs/2305.16370](http://arxiv.org/abs/2305.16370)

    Stecformer是一种处理多元长期时间序列预测的方法，提出了一种有效的空间-时间编码器和级联解码预测器（CDP），在多个基准数据集上实现了最先进的性能，为多元长期时间序列预测提供了一种有前途的方法。

    

    多元长期时间序列预测在诸多领域中具有重要应用，如能源消耗和天气预报等。随着基于变压器的方法的发展，多元长期时间序列预测的性能得到了显著提高，但变压器模型中对于空间特征的研究较少，而不同预测周期之间的一致性也由于时间跨度较大而不尽人意。本文提出了一种完整的解决方案，以解决特征提取和目标预测方面的问题。对于特征提取，我们设计了一种有效的空间-时间编码器，包括半自适应图形来获取足够的空间-时间信息。对于预测，我们提出了级联解码预测器（CDP），以加强不同间隔之间的相关性，也可以用作通用的组件来提高基于变压器的方法的性能。所提出的方法称为Stecformer，在多个基准数据集上实现了最先进的性能，并为多元长期时间序列预测提供了一种有前途的方法。

    Multivariate long-term time series forecasting is of great application across many domains, such as energy consumption and weather forecasting. With the development of transformer-based methods, the performance of multivariate long-term time series forecasting has been significantly improved, however, the study of spatial features extracting in transformer-based model is rare and the consistency of different prediction periods is unsatisfactory due to the large span. In this work, we propose a complete solution to address these problems in terms of feature extraction and target prediction. For extraction, we design an efficient spatio-temporal encoding extractor including a semi-adaptive graph to acquire sufficient spatio-temporal information. For prediction, we propose a Cascaded Decoding Predictor (CDP) to strengthen the correlation between different intervals, which can also be utilized as a generic component to improve the performance of transformer-based methods. The proposed meth
    
[^56]: 一种半自动化角落情况检测和评估流程

    A Semi-Automated Corner Case Detection and Evaluation Pipeline. (arXiv:2305.16369v1 [cs.CV])

    [http://arxiv.org/abs/2305.16369](http://arxiv.org/abs/2305.16369)

    该论文提出了一种半自动化的流程，将集体专家知识描述转换为本体论，实现了从数据集中提取角落情况和对网络进行评估的目的。

    

    为了让自动驾驶车辆投入公共使用，必须证明车辆能够在许多不同情况下安全、可靠地处理交通。自动驾驶车辆的重要组成部分之一是捕捉和处理车辆周围环境的感知系统。感知系统需要大量数据集来训练其深度神经网络。在这些数据集中了解哪些数据部分描述了一个角落情况，在网络的训练或测试过程中具有优势。这些角落情况描述了罕见且对网络具有挑战性的情况。我们提出了一种将集体专家知识描述转换为扩展KI Absicherung本体论的流程。该本体论用于描述可映射到感知数据集的场景和情况。然后可以从数据集中提取角落情况。此外，该流程还使得可以对检测网络针对提取的角落情况进行评估以进行测量。

    In order to deploy automated vehicles to the public, it has to be proven that the vehicle can safely and robustly handle traffic in many different scenarios. One important component of automated vehicles is the perception system that captures and processes the environment around the vehicle. Perception systems require large datasets for training their deep neural network. Knowing which parts of the data in these datasets describe a corner case is an advantage during training or testing of the network. These corner cases describe situations that are rare and potentially challenging for the network. We propose a pipeline that converts collective expert knowledge descriptions into the extended KI Absicherung ontology. The ontology is used to describe scenes and scenarios that can be mapped to perception datasets. The corner cases can then be extracted from the datasets. In addition, the pipeline enables the evaluation of the detection networks against the extracted corner cases to measure
    
[^57]: 大语言模型角色扮演

    Role-Play with Large Language Models. (arXiv:2305.16367v1 [cs.CL])

    [http://arxiv.org/abs/2305.16367](http://arxiv.org/abs/2305.16367)

    本文将对话代理行为描述为角色扮演，以避免赋予其人类特征，在此基础上研究代理行为中的欺骗和自我意识。

    

    随着对话代理程序在表现上越来越接近人类，有必要开发有效的方式高层次描述其行为，而不会陷入赋予其人类特征的陷阱。本文提出了角色扮演的概念，将对话代理程序的行为视为角色扮演，使我们能够借鉴熟悉的民间心理学术语，而不是赋予它们实际上并不具备的人类特征。本文以(表面上的)欺骗和(表面上的)自我意识为例，探讨了对话代理程序行为的两种情况。

    As dialogue agents become increasingly human-like in their performance, it is imperative that we develop effective ways to describe their behaviour in high-level terms without falling into the trap of anthropomorphism. In this paper, we foreground the concept of role-play. Casting dialogue agent behaviour in terms of role-play allows us to draw on familiar folk psychological terms, without ascribing human characteristics to language models they in fact lack. Two important cases of dialogue agent behaviour are addressed this way, namely (apparent) deception and (apparent) self-awareness.
    
[^58]: 减少谜团：基于子目标的演示学习在形式定理证明中的应用

    Decomposing the Enigma: Subgoal-based Demonstration Learning for Formal Theorem Proving. (arXiv:2305.16366v1 [cs.CL])

    [http://arxiv.org/abs/2305.16366](http://arxiv.org/abs/2305.16366)

    本文提出了一个基于子目标的演示学习框架，通过将基于子目标的学习方法与扩散模型相结合，提高演示的可理解性，并提高LLMs在形式定理证明中的吞吐量。

    

    大型语言模型（LLMs）在形式定理证明领域提供了有趣的探索方向。然而，如何完全利用这些模型，特别是在演示格式和组织方面，仍然是一个未被充分探索的领域。为了增强LLMs的效能，作者提出了一个基于子目标的演示学习框架，包括两个主要元素：第一，从强化学习和机器人领域的子目标学习中汲取经验，为每个演示示例构建不同的子目标，并根据相关的子目标学习理论来优化这些子目标。第二，利用最近扩散模型的进展来预测最佳组织方式，同时解决演示组织领域中存在的两个复杂问题：子集选择和顺序确定。通过将基于子目标的学习方法与扩散模型相结合，作者提出的框架可以提高演示的可理解性，并提高LLMs在形式定理证明中的吞吐量。

    Large language models~(LLMs) present an intriguing avenue of exploration in the domain of formal theorem proving. Nonetheless, the full utilization of these models, particularly in terms of demonstration formatting and organization, remains an underexplored area. In an endeavor to enhance the efficacy of LLMs, we introduce a subgoal-based demonstration learning framework, consisting of two primary elements: Firstly, drawing upon the insights of subgoal learning from the domains of reinforcement learning and robotics, we propose the construction of distinct subgoals for each demonstration example and refine these subgoals in accordance with the pertinent theories of subgoal learning. Secondly, we build upon recent advances in diffusion models to predict the optimal organization, simultaneously addressing two intricate issues that persist within the domain of demonstration organization: subset selection and order determination. Through the integration of subgoal-based learning methodolog
    
[^59]: 一个关于可解释性方法评估的实验研究

    An Experimental Investigation into the Evaluation of Explainability Methods. (arXiv:2305.16361v1 [cs.LG])

    [http://arxiv.org/abs/2305.16361](http://arxiv.org/abs/2305.16361)

    这篇论文比较了14种不同的评估指标在对9种目前最先进的可解释性人工智能（XAI）方法和三种虚拟方法进行应用时的效果，给出了高度相关结果，指出了存在潜在冗余。此外，还展示了基线超参数对评估指标值产生显著影响。

    

    可解释的人工智能（XAI）旨在帮助用户理解人工智能系统背后的推理过程。近年来出现了许多XAI方法，相应地，与XAI方法评估相关的子领域引起了人们的关注，旨在确定使用各种方法和标准提供最佳解释的方法。然而，文献缺乏对评估指标本身的比较，这些指标可以用于评估XAI方法。本文旨在通过比较14种不同的指标在对九种最先进的XAI方法和三种虚拟方法（例如随机显著性图）进行应用时的效果，来填补这一空白。实验结果显示，哪些指标产生高度相关的结果，表明存在潜在的冗余性。我们还展示了基线超参数对评估指标值的显著影响。最后，我们使用虚拟方法评估了实验结果。

    EXplainable Artificial Intelligence (XAI) aims to help users to grasp the reasoning behind the predictions of an Artificial Intelligence (AI) system. Many XAI approaches have emerged in recent years. Consequently, a subfield related to the evaluation of XAI methods has gained considerable attention, with the aim to determine which methods provide the best explanation using various approaches and criteria. However, the literature lacks a comparison of the evaluation metrics themselves, that one can use to evaluate XAI methods. This work aims to fill this gap by comparing 14 different metrics when applied to nine state-of-the-art XAI methods and three dummy methods (e.g., random saliency maps) used as references. Experimental results show which of these metrics produces highly correlated results, indicating potential redundancy. We also demonstrate the significant impact of varying the baseline hyperparameter on the evaluation metric values. Finally, we use dummy methods to assess the re
    
[^60]: 带扰动生成树的可微聚类方法

    Differentiable Clustering with Perturbed Spanning Forests. (arXiv:2305.16358v1 [cs.LG])

    [http://arxiv.org/abs/2305.16358](http://arxiv.org/abs/2305.16358)

    介绍了一种基于扰动生成树的可微聚类方法，依赖于线性规划解的随机扰动，具有良好的性能。

    

    我们介绍了一种基于最小权重生成树的可微聚类方法，它是生成树的一种变体，具有多个连通分量。我们的方法依赖于线性规划解的随机扰动，以实现平滑和高效的梯度计算。这使我们能够在端到端可训练的流水线中包含聚类。我们证明了我们的方法即使在嘈杂的数据集和具有挑战性的几何环境下也能良好地工作。我们还利用这种方法制定了一个特别的损失，以有效地从部分聚类数据学习。我们在几个现实世界的数据集上展示了它在监督和半监督任务中的表现。

    We introduce a differentiable clustering method based on minimum-weight spanning forests, a variant of spanning trees with several connected components. Our method relies on stochastic perturbations of solutions of linear programs, for smoothing and efficient gradient computations. This allows us to include clustering in end-to-end trainable pipelines. We show that our method performs well even in difficult settings, such as datasets with high noise and challenging geometries. We also formulate an ad hoc loss to efficiently learn from partial clustering data using this operation. We demonstrate its performance on several real world datasets for supervised and semi-supervised tasks.
    
[^61]: 自我背叛：利用单声道转立体声技术进行深度伪造音频的检测

    Betray Oneself: A Novel Audio DeepFake Detection Model via Mono-to-Stereo Conversion. (arXiv:2305.16353v1 [cs.SD])

    [http://arxiv.org/abs/2305.16353](http://arxiv.org/abs/2305.16353)

    本文提出了一种名为M2S-ADD的新型ADD模型，通过单声道转立体声技术发现伪造音频中的真实性线索，显著提高了检测性能。

    

    音频深度伪造检测(Audio Deepfake Detection, ADD)旨在检测由文本转语音(TTS)、语音转换(VC)、重放等生成的虚假音频，是一个新兴的研究领域。传统的研究方法将单声道信号作为输入，重点在于稳健的特征提取和有效的分类器设计。然而，音频信号中的双通道立体声信息也包含了深度伪造的重要线索，这在先前的工作中尚未得到研究。本文提出了一种新颖的ADD模型，称为M2S-ADD，旨在在单声道转立体声过程中发现音频真实性线索。我们首先使用预训练的立体声合成器将单声道投影到立体声信号上，然后采用双分支神经架构分别处理左右声道信号。这样，我们有效地揭示了伪造音频中的伪影，从而提高了ADD的性能。在ASVspoof2019数据库上的实验结果表明，M2S-ADD在所有输入单声道的基线模型中表现最佳。

    Audio Deepfake Detection (ADD) aims to detect the fake audio generated by text-to-speech (TTS), voice conversion (VC) and replay, etc., which is an emerging topic. Traditionally we take the mono signal as input and focus on robust feature extraction and effective classifier design. However, the dual-channel stereo information in the audio signal also includes important cues for deepfake, which has not been studied in the prior work. In this paper, we propose a novel ADD model, termed as M2S-ADD, that attempts to discover audio authenticity cues during the mono-to-stereo conversion process. We first projects the mono to a stereo signal using a pretrained stereo synthesizer, then employs a dual-branch neural architecture to process the left and right channel signals, respectively. In this way, we effectively reveal the artifacts in the fake audio, thus improve the ADD performance. The experiments on the ASVspoof2019 database show that M2S-ADD outperforms all baselines that input mono. We
    
[^62]: WeiAvg：促进数据多样性的联邦学习模型聚合方法

    WeiAvg: Federated Learning Model Aggregation Promoting Data Diversity. (arXiv:2305.16351v1 [cs.LG])

    [http://arxiv.org/abs/2305.16351](http://arxiv.org/abs/2305.16351)

    本文提出了一种名为WeiAvg的联邦学习模型聚合方法，通过强调来自高多样性客户端的更新并减少来自低多样性客户端的影响，提高了联邦模型的质量和性能。

    

    联邦学习为利用大规模私有边缘数据提供了一种有前景的隐私保护方式，尤其适用于物联网设备。然而，现有的研究主要集中在优化学习过程、计算效率和通信开销等方面，忽略了参与者对联邦模型质量的影响。本文提出了一种新的方法，通过引入一种基于加权平均（WeiAvg）的框架，着重强调来自高多样性客户端的更新，并减少来自低多样性客户端的影响，从而解决了这个问题。具体而言，我们引入了基于投影的近似方法，来评估多样性。

    Federated learning provides a promising privacy-preserving way for utilizing large-scale private edge data from massive Internet-of-Things (IoT) devices. While existing research extensively studied optimizing the learning process, computing efficiency, and communication overhead, one important and often overlooked aspect is that participants contribute predictive knowledge from their data, impacting the quality of the federated models learned. While FedAvg treats each client equally and assigns weight solely based on the number of samples, the diversity of samples on each client could greatly affect the local update performance and the final aggregated model. In this paper, we propose a novel approach to address this issue by introducing a Weighted Averaging (WeiAvg) framework that emphasizes updates from high-diversity clients and diminishes the influence of those from low-diversity clients. Specifically, we introduced a projection-based approximation method to estimate the diversity 
    
[^63]: Lexinvariant语言模型

    Lexinvariant Language Models. (arXiv:2305.16349v1 [cs.CL])

    [http://arxiv.org/abs/2305.16349](http://arxiv.org/abs/2305.16349)

    本文讨论了一种新型的语言模型，称为Lexinvariant语言模型，该模型不需要任何固定标记嵌入，完全依赖上下文中标记的共现和重复。作者证明可以构建一个lexinvariant LM，以多项式方式与上下文长度成比例地收敛到真实语言模型，其常量因子在词汇表大小下为次线性。

    

    令牌嵌入是从离散词汇符号到连续向量的映射，是任何语言模型（LM）的核心。但是，词汇符号的含义也可以通过它们在长上下文中的结构角色来确定甚至重新定义。在本文中，我们问：是否可能存在一种没有任何固定标记嵌入的性能良好的语言模型？这样的语言模型将完全依赖于上下文中标记的共现和重复，而不是任何标记的\textit{a priori}标识。为了回答这个问题，我们研究了\textit{lexinvariant}语言模型，这些语言模型对词汇符号不变，因此在实践中不需要固定的令牌嵌入。首先，我们证明可以构建一个lexinvariant LM，以多项式方式与上下文长度成比例地收敛到真实语言模型，其常量因子在词汇表大小下为次线性。其次，要构建一个lexinvariant LM，我们只需使用随机高斯函数对标记进行编码。

    Token embeddings, a mapping from discrete lexical symbols to continuous vectors, are at the heart of any language model (LM). However, lexical symbol meanings can also be determined and even redefined by their structural role in a long context. In this paper, we ask: is it possible for a language model to be performant without \emph{any} fixed token embeddings? Such a language model would have to rely entirely on the co-occurence and repetition of tokens in the context rather than the \textit{a priori} identity of any token. To answer this, we study \textit{lexinvariant}language models that are invariant to lexical symbols and therefore do not need fixed token embeddings in practice. First, we prove that we can construct a lexinvariant LM to converge to the true language model at a uniform rate that is polynomial in terms of the context length, with a constant factor that is sublinear in the vocabulary size. Second, to build a lexinvariant LM, we simply encode tokens using random Gauss
    
[^64]: 基于人工智能的精准医疗方法：糖尿病风险预测

    Artificial Intelligence-Based Methods for Precision Medicine: Diabetes Risk Prediction. (arXiv:2305.16346v1 [cs.LG])

    [http://arxiv.org/abs/2305.16346](http://arxiv.org/abs/2305.16346)

    本文分析了现有文献中基于人工智能的糖尿病风险预测模型，在单模态和多模态模型中均表现突出，但外部验证有限，解释性方法需要改进。

    

    2型糖尿病的日益普及需要开发预测模型进行风险评估。人工智能（AI）模型被广泛用于此目的，但缺乏对其进展和挑战的全面评估。本文分析了现有文献中基于AI的2型糖尿病风险预测模型。包括了40个研究，主要发表在过去四年中。传统的机器学习模型比深度学习模型更普遍。电子健康记录是最常用的数据来源。单模态依赖EHR数据的AI模型很突出，而只有少数使用多模态模型。单模态和多模态模型均表现良好，后者优于前者。内部验证很常见，而外部验证很有限。解释性方法在一半的研究中得到了报告。少数研究报告了新的生物标志物，且有开源的。

    The rising prevalence of type 2 diabetes mellitus (T2DM) necessitates the development of predictive models for T2DM risk assessment. Artificial intelligence (AI) models are being extensively used for this purpose, but a comprehensive review of their advancements and challenges is lacking. This scoping review analyzes existing literature on AI-based models for T2DM risk prediction. Forty studies were included, mainly published in the past four years. Traditional machine learning models were more prevalent than deep learning models. Electronic health records were the most commonly used data source. Unimodal AI models relying on EHR data were prominent, while only a few utilized multimodal models. Both unimodal and multimodal models showed promising performance, with the latter outperforming the former. Internal validation was common, while external validation was limited. Interpretability methods were reported in half of the studies. Few studies reported novel biomarkers, and open-source
    
[^65]: 利用LLMs从混合长文档中检索KPI的全面框架与数据集

    Leveraging LLMs for KPIs Retrieval from Hybrid Long-Document: A Comprehensive Framework and Dataset. (arXiv:2305.16344v1 [cs.CL])

    [http://arxiv.org/abs/2305.16344](http://arxiv.org/abs/2305.16344)

    本文提出了一个自动化财务信息提取的框架（AFIE），用于提取混合长文档中的关键业绩指标（KPI）。该框架利用LLMs增强了财务报告信息的理解和提取能力，并经过了广泛的实验验证，证明其在GPT-3.5和GPT-4上的有效性，相对于朴素方法，平均精度提高了53.94％和33.77％。

    

    大型语言模型（LLMs）在文本理解和表格推理任务中展现出了卓越的性能，但它们对包含文本和表格数据的混合文本的理解和分析能力仍未被充分发掘。本研究专注于利用LLMs的潜力，从混杂的长型财务报告中理解关键信息。我们提出了自动化财务信息提取（AFIE）框架，增强了LLMs理解和提取财务报告信息的能力。为了评估AFIE，我们开发了一个金融报告数值提取（FINE）数据集，并进行了广泛的实验分析。我们的框架在GPT-3.5和GPT-4上得到了有效验证，相对于朴素方法，平均精度提高了53.94％和33.77％。这些结果表明，AFIE框架为从复杂的混合文档中自动提取数值提供了准确性。

    Large Language Models (LLMs) demonstrate exceptional performance in textual understanding and tabular reasoning tasks. However, their ability to comprehend and analyze hybrid text, containing textual and tabular data, remains underexplored. In this research, we specialize in harnessing the potential of LLMs to comprehend critical information from financial reports, which are hybrid long-documents. We propose an Automated Financial Information Extraction (AFIE) framework that enhances LLMs' ability to comprehend and extract information from financial reports. To evaluate AFIE, we develop a Financial Reports Numerical Extraction (FINE) dataset and conduct an extensive experimental analysis. Our framework is effectively validated on GPT-3.5 and GPT-4, yielding average accuracy increases of 53.94% and 33.77%, respectively, compared to a naive method. These results suggest that the AFIE framework offers accuracy for automated numerical extraction from complex, hybrid documents.
    
[^66]: 基于Spark生态系统的分布式自动领域特定多词术语识别架构

    A Distributed Automatic Domain-Specific Multi-Word Term Recognition Architecture using Spark Ecosystem. (arXiv:2305.16343v1 [cs.CL])

    [http://arxiv.org/abs/2305.16343](http://arxiv.org/abs/2305.16343)

    本论文提出了一种基于Spark生态系统的分布式架构，可自动提取领域特定术语，经实验证明在术语提取准确性方面取得最先进的结果。

    

    自动术语识别用于提取属于给定领域的特定术语。为了准确，这些基于语料库和语言依赖的方法需要处理大量文本数据以提取候选术语，然后根据给定的度量标准进行评分。为了改进文本预处理和候选术语的提取和评分，我们提出了一种使用Spark生态系统自动提取领域特定术语的分布式架构。主要贡献如下：（1）提出了一种新颖的分布式自动领域特定多词术语识别架构，构建在Spark生态系统之上；（2）从准确性和可扩展性方面对我们的架构进行了深入分析；（3）设计了一个易于集成的Python实现，使其能够在计算语言学和自然语言处理等领域使用大数据处理。我们通过在多个数据集和领域上进行实验来经验性地证明了我们架构的可行性，在术语提取准确性方面取得了最先进的结果。

    Automatic Term Recognition is used to extract domain-specific terms that belong to a given domain. In order to be accurate, these corpus and language-dependent methods require large volumes of textual data that need to be processed to extract candidate terms that are afterward scored according to a given metric. To improve text preprocessing and candidate terms extraction and scoring, we propose a distributed Spark-based architecture to automatically extract domain-specific terms. The main contributions are as follows: (1) propose a novel distributed automatic domain-specific multi-word term recognition architecture built on top of the Spark ecosystem; (2) perform an in-depth analysis of our architecture in terms of accuracy and scalability; (3) design an easy-to-integrate Python implementation that enables the use of Big Data processing in fields such as Computational Linguistics and Natural Language Processing. We prove empirically the feasibility of our architecture by performing ex
    
[^67]: InterFormer: 混合局部和全局特征用于语音识别的交互式融合方法

    InterFormer: Interactive Local and Global Features Fusion for Automatic Speech Recognition. (arXiv:2305.16342v1 [cs.CL])

    [http://arxiv.org/abs/2305.16342](http://arxiv.org/abs/2305.16342)

    本文提出了InterFormer，用于交互式局部和全局特征融合，以学习更好的ASR表示。通过组合卷积块和变形器块，以及引入BFIM和SFM模块，实现了局部和全局特征的交互和融合，取得了在公共ASR数据集上优异的性能。

    

    对于自动语音识别（ASR）而言，局部和全局特征都是必不可少的。许多最近的方法已经证实，简单地合并局部和全局特征可以进一步提高ASR性能。然而，这些方法往往忽略了局部和全局特征之间的交互，并且它们的串行架构无法反映局部和全局特征之间的关系。为了解决这些问题，本文提出了InterFormer，用于交互式局部和全局特征融合，以学习更好的ASR表示。具体而言，我们将卷积块与变形器块以并行设计相结合。此外，我们提出了双向特征交互模块（BFIM）和选择性融合模块（SFM）来实现局部和全局特征的交互和融合。在公共ASR数据集上的大量实验表明了我们提出的InterFormer的有效性，并且相对于其他Transformer和Conformer模型具有更出色的性能。

    The local and global features are both essential for automatic speech recognition (ASR). Many recent methods have verified that simply combining local and global features can further promote ASR performance. However, these methods pay less attention to the interaction of local and global features, and their series architectures are rigid to reflect local and global relationships. To address these issues, this paper proposes InterFormer for interactive local and global features fusion to learn a better representation for ASR. Specifically, we combine the convolution block with the transformer block in a parallel design. Besides, we propose a bidirectional feature interaction module (BFIM) and a selective fusion module (SFM) to implement the interaction and fusion of local and global features, respectively. Extensive experiments on public ASR datasets demonstrate the effectiveness of our proposed InterFormer and its superior performance over the other Transformer and Conformer models.
    
[^68]: "TaxoKnow：分类中的先验知识——层次分类作为多类分类损失函数中的先验知识"

    TaxoKnow: Taxonomy as Prior Knowledge in the Loss Function of Multi-class Classification. (arXiv:2305.16341v1 [cs.LG])

    [http://arxiv.org/abs/2305.16341](http://arxiv.org/abs/2305.16341)

    本文研究在平面分类器的学习算法中集成层次分类作为先验知识的有效性，实验结果表明先验知识可以显著提高学习者的性能，并在半监督和完全监督的情况下都获得了不错的结果。

    

    本文研究将标签的层次分类作为先验知识集成到平面分类器的学习算法中的有效性。我们提出了两种将层次分类作为显式正则化器集成到学习算法损失函数中的方法。通过对层次分类进行推理，神经网络减轻了其对类别的输出分布，允许将上层概念的条件附加到少数类上。我们仅限于平面分类任务，并提供了在两个工业内部数据集和两个公共基准测试集（RCV1和Amazon产品评论）上的实验结果。我们得到的结果显示，在半监督多类分类中，分类过程中的先验知识可以显著地提高学习者的性能，并且在完全监督的情况下也获得了不错的结果。

    In this paper, we investigate the effectiveness of integrating a hierarchical taxonomy of labels as prior knowledge into the learning algorithm of a flat classifier. We introduce two methods to integrate the hierarchical taxonomy as an explicit regularizer into the loss function of learning algorithms. By reasoning on a hierarchical taxonomy, a neural network alleviates its output distributions over the classes, allowing conditioning on upper concepts for a minority class. We limit ourselves to the flat classification task and provide our experimental results on two industrial in-house datasets and two public benchmarks, RCV1 and Amazon product reviews. Our obtained results show the significant effect of a taxonomy in increasing the performance of a learner in semisupervised multi-class classification and the considerable results obtained in a fully supervised fashion.
    
[^69]: 分段循环Transformer:一种高效的序列到序列模型

    Segmented Recurrent Transformer: An Efficient Sequence-to-Sequence Model. (arXiv:2305.16340v1 [cs.CL])

    [http://arxiv.org/abs/2305.16340](http://arxiv.org/abs/2305.16340)

    本文提出了一种分段循环Transformer（SRformer）来减少计算/内存成本，并使用RAF层处理跨段的信息，从而提高序列处理能力。

    

    Transformer在许多领域中表现出卓越的性能，包括语言和视觉。然而，随着序列长度的增加，它们的计算成本呈二次增长，使得它们在资源受限的应用中使用成为不可能。为了解决这个问题，我们的方法是将整个序列划分成若干段。然后使用具有循环结构的神经元来聚合跨段的信息，从而实现具有较低计算/内存成本的序列处理能力模型。为了验证这个想法，我们首先研究了使用局部Attention机制对单个段的影响。然后我们提出了一种分段循环Transformer（SRformer），它将分段Attention和循环Attention相结合。它使用循环accumulate and fire（RAF）层在相邻段之间处理信息。通过更新key的产品来补偿减少Attention窗口长度产生的误差。

    Transformers have shown dominant performance across a range of domains including language and vision. However, their computational cost grows quadratically with the sequence length, making their usage prohibitive for resource-constrained applications. To counter this, our approach is to divide the whole sequence into segments. The information across segments can then be aggregated using neurons with recurrence leveraging their inherent memory. Such an approach leads to models with sequential processing capability at a lower computation/memory cost. To investigate this idea, first, we examine the effects of using local attention mechanism on the individual segments. Then we propose a segmented recurrent transformer (SRformer) that combines segmented attention with recurrent attention. It uses recurrent accumulate and fire (RAF) layers to process information between consecutive segments. The loss caused by reducing the attention window length is compensated by updating the product of key
    
[^70]: 当问题不是用英语提出时，不要完全信任GPT

    Don't Trust GPT When Your Question Is Not In English. (arXiv:2305.16339v1 [cs.CL])

    [http://arxiv.org/abs/2305.16339](http://arxiv.org/abs/2305.16339)

    在多语言环境下，GPT-3表现较差，特别是当问题不是用英语提出时。这与模型的训练数据和输入问题的语言差异有关。

    

    近年来，大型语言模型（LLMs）展示了出色的自然语言理解能力，并在多个自然语言处理（NLP）任务中表现出色。尽管大多数LLMs主要使用英语进行训练，但多项研究已经证明了它们在许多其他语言中的相对表现。然而，关于LLMs如何获得它们的多语言能力以及表现在不同语言中的差异仍然存在基本问题。这些问题对LLMs的研究非常关键，因为用户和研究人员通常来自多种语言背景，可能影响他们对LLMs结果的利用和解释。在本文中，我们提出了一种系统的方法，以定性评估多语言环境下LLMs的表现差异。我们调查了LLMs在跨语言泛化现象方面的表现，即不充足的多语言训练数据导致先进的多语言能力。为了实现这一目的，我们对一系列语言进行了GPT-3的实验，这些语言涵盖了从印欧语系到非印欧语系的各种语言，并提出了一种评估和验证结果的方法。我们的发现表明，即使模型在该语言上进行了微调，但如果输入问题不是英语，GPT-3在其他语言下的表现显著较差。此外，我们证明了模型的表现不佳与训练语言和输入问题的语言差异有关。我们的结果表明，在进行非英语自然语言处理任务时，需要谨慎使用LLMs。

    Large Language Models (LLMs) have demonstrated exceptional natural language understanding abilities and have excelled in a variety of natural language processing (NLP)tasks in recent years. Despite the fact that most LLMs are trained predominantly in English, multiple studies have demonstrated their comparative performance in many other languages. However, fundamental questions persist regarding how LLMs acquire their multi-lingual abilities and how performance varies across different languages. These inquiries are crucial for the study of LLMs since users and researchers often come from diverse language backgrounds, potentially influencing their utilization and interpretation of LLMs' results. In this work, we propose a systematic way of qualifying the performance disparities of LLMs under multilingual settings. We investigate the phenomenon of across-language generalizations in LLMs, wherein insufficient multi-lingual training data leads to advanced multi-lingual capabilities. To acc
    
[^71]: 深思熟虑：具有内部工作记忆的决策Transformer

    Think Before You Act: Decision Transformers with Internal Working Memory. (arXiv:2305.16338v1 [cs.LG])

    [http://arxiv.org/abs/2305.16338](http://arxiv.org/abs/2305.16338)

    该论文提出了具有内部工作记忆模块的决策Transformer方法，以解决使用大型语言模型的决策代理在处理新任务上性能低下的问题。所提出的方法改善了训练效率和泛化能力，并进一步增强了转化决策制定代理对新任务的适应性。

    

    基于大型语言模型（LLM）的决策制定代理已经展示了跨越多个任务的泛化能力。然而，它们的性能依赖于大规模的数据和计算。我们认为，这种低效性源于遗忘现象，即模型通过参数记忆其行为，在训练过程中。因此，新任务的训练可能会降低模型在先前任务上的性能。与LLM的隐式记忆机制不同，人脑利用分布式存储器存储记忆，以有效地管理和组织多种技能，减轻了遗忘现象。因此，我们建议使用内部工作记忆模块来存储、融合和检索不同下游任务的信息。评估结果表明，所提出的方法改善了Atari游戏和元世界物体操作任务的训练效率和泛化能力。此外，我们证明了记忆微调进一步增强了转化决策制定代理对新任务的适应性。

    Large language model (LLM)-based decision-making agents have shown the ability to generalize across multiple tasks. However, their performance relies on massive data and compute. We argue that this inefficiency stems from the forgetting phenomenon, in which a model memorizes its behaviors in parameters throughout training. As a result, training on a new task may deteriorate the model's performance on previous tasks. In contrast to LLMs' implicit memory mechanism, the human brain utilizes distributed memory storage, which helps manage and organize multiple skills efficiently, mitigating the forgetting phenomenon. Thus inspired, we propose an internal working memory module to store, blend, and retrieve information for different downstream tasks. Evaluation results show that the proposed method improves training efficiency and generalization in both Atari games and meta-world object manipulation tasks. Moreover, we demonstrate that memory fine-tuning further enhances the adaptability of t
    
[^72]: 基于自适应最优输运的健壮短文本聚类中可靠伪标签的表示学习

    Robust Representation Learning with Reliable Pseudo-labels Generation via Self-Adaptive Optimal Transport for Short Text Clustering. (arXiv:2305.16335v1 [cs.CL])

    [http://arxiv.org/abs/2305.16335](http://arxiv.org/abs/2305.16335)

    本文提出了一种健壮短文本聚类（RSTC）模型，通过自适应最优输运的伪标签生成，以及基于类和实例的对比学习的健壮表示学习，帮助提高对不平衡和噪音数据的鲁棒性。

    

    短文本聚类因输入的不平衡和噪音数据而具有挑战性。现有方法无法很好地解决这个问题，因为它们容易在重度不平衡数据集上获得退化的解决方案，且易受到噪声干扰。为了解决这个问题，我们提出了一种健壮短文本聚类（RSTC）模型，以提高对不平衡和噪音数据的鲁棒性。RSTC包括两个模块，即伪标记生成模块和健壮表示学习模块。前者生成伪标记，为后者提供监督，有助于更健壮的表示和正确分离的聚类。为了提供对数据不平衡的鲁棒性，在伪标签生成模块中提出了自适应最优输运。为了提高对数据中噪声的鲁棒性，在健壮表示学习模块中进一步引入了基于类和实例的对比学习。

    Short text clustering is challenging since it takes imbalanced and noisy data as inputs. Existing approaches cannot solve this problem well, since (1) they are prone to obtain degenerate solutions especially on heavy imbalanced datasets, and (2) they are vulnerable to noises. To tackle the above issues, we propose a Robust Short Text Clustering (RSTC) model to improve robustness against imbalanced and noisy data. RSTC includes two modules, i.e., pseudo-label generation module and robust representation learning module. The former generates pseudo-labels to provide supervision for the later, which contributes to more robust representations and correctly separated clusters. To provide robustness against the imbalance in data, we propose self-adaptive optimal transport in the pseudo-label generation module. To improve robustness against the noise in data, we further introduce both class-wise and instance-wise contrastive learning in the robust representation learning module. Our empirical 
    
[^73]: OlaGPT：让大型语言模型具备类人的问题解决能力

    OlaGPT: Empowering LLMs With Human-like Problem-Solving Abilities. (arXiv:2305.16334v1 [cs.CL])

    [http://arxiv.org/abs/2305.16334](http://arxiv.org/abs/2305.16334)

    OlaGPT是一种新颖的智能框架，能够模拟人类在解决复杂推理问题时所采用的各种认知能力和与工具、知识和外部环境信息的交互，可以让大型语言模型具备类人的问题解决能力。

    

    目前大多数研究中，大型语言模型（LLMs）在特定提示的指导下通过生成思维链来执行推理任务。然而，它们在解决复杂推理问题上与人类的能力存在显著差距。目前，大多数方法都专注于思维链（COT）和工具使用，而忽视了采用和应用人类认知框架的重要性。人们通常在面对复杂的推理挑战时，会运用各种认知能力，并需要与工具、知识和外部环境信息的所有方面进行交互，才能完成复杂的任务。本文介绍了一种新颖的智能框架，称为OlaGPT。OlaGPT仔细研究了认知架构框架，并提出模拟人类认知的某些方面。该框架涉及近似不同的认知模块，包括关注力。

    In most current research, large language models (LLMs) are able to perform reasoning tasks by generating chains of thought through the guidance of specific prompts. However, there still exists a significant discrepancy between their capability in solving complex reasoning problems and that of humans. At present, most approaches focus on chains of thought (COT) and tool use, without considering the adoption and application of human cognitive frameworks. It is well-known that when confronting complex reasoning challenges, humans typically employ various cognitive abilities, and necessitate interaction with all aspects of tools, knowledge, and the external environment information to accomplish intricate tasks. This paper introduces a novel intelligent framework, referred to as OlaGPT. OlaGPT carefully studied a cognitive architecture framework, and propose to simulate certain aspects of human cognition. The framework involves approximating different cognitive modules, including attention,
    
[^74]: 基于语音合成的文本生成用于ASR数据增广

    Text Generation with Speech Synthesis for ASR Data Augmentation. (arXiv:2305.16333v1 [cs.CL])

    [http://arxiv.org/abs/2305.16333](http://arxiv.org/abs/2305.16333)

    本研究探索文本增广对ASR的影响，使用大规模预训练的神经网络来生成合成文本，并通过文本到语音系统转换为合成语音，实验发现，使用神经网络的文本增广方法能够有效提高ASR准确度，可以作为改进ASR系统的一种可行工具。

    

    为了减少对昂贵人工注释的依赖，数据增广一直是自动语音识别（ASR）领域的一个热门研究方向。先前的研究主要侧重于用于ASR数据增广的合成语音生成，而其与文本生成方法的结合却相对较少探索。在本文中，我们使用大规模预训练的神经网络探索文本增广对ASR的影响，并将其与传统文本增广方法进行了系统比较。生成的合成文本然后通过文本到语音（TTS）系统转换为合成语音，并添加到ASR训练数据中。我们在三个数据集上进行的实验发现，神经模型实现了9％-15％的相对WER改进，并优于传统方法。我们得出结论，特别是通过现代神经方法，文本增广是提高ASR系统准确性的一种可行工具。

    Aiming at reducing the reliance on expensive human annotations, data synthesis for Automatic Speech Recognition (ASR) has remained an active area of research. While prior work mainly focuses on synthetic speech generation for ASR data augmentation, its combination with text generation methods is considerably less explored. In this work, we explore text augmentation for ASR using large-scale pre-trained neural networks, and systematically compare those to traditional text augmentation methods. The generated synthetic texts are then converted to synthetic speech using a text-to-speech (TTS) system and added to the ASR training data. In experiments conducted on three datasets, we find that neural models achieve 9%-15% relative WER improvement and outperform traditional methods. We conclude that text augmentation, particularly through modern neural approaches, is a viable tool for improving the accuracy of ASR systems.
    
[^75]: 生物医学自然语言处理中的大型语言模型: 基准、基线和建议

    Large language models in biomedical natural language processing: benchmarks, baselines, and recommendations. (arXiv:2305.16326v1 [cs.CL])

    [http://arxiv.org/abs/2305.16326](http://arxiv.org/abs/2305.16326)

    本文研究了GPT-3和GPT-4在生物医学自然语言处理中的表现，分析了它们可能产生的错误类型，并提供了使用这些模型的建议。

    

    生物医学文献呈指数级增长，手动筛选和提取知识变得困难。自动从生物医学文献中提取信息的生物医学自然语言处理（BioNLP）技术有助于减轻这种负担。近年来，如GPT-3和GPT-4等大型语言模型（LLMs）因其卓越的性能而受到重视。但是，它们在BioNLP任务中的有效性以及对方法开发和下游用户的影响仍未得到研究。本研究（1）在四个应用程序中在八个BioNLP数据集中建立了GPT-3和GPT-4在零-shot和一-shot设置下的基准表现，包括命名实体识别，关系提取，多标签文档分类和语义相似性和推理；（2）审查了LLMs产生的错误，并将错误分为三种类型：缺失，不一致和不需要的人工内容；（3）提出了使用LLMs的建议。

    Biomedical literature is growing rapidly, making it challenging to curate and extract knowledge manually. Biomedical natural language processing (BioNLP) techniques that can automatically extract information from biomedical literature help alleviate this burden. Recently, large Language Models (LLMs), such as GPT-3 and GPT-4, have gained significant attention for their impressive performance. However, their effectiveness in BioNLP tasks and impact on method development and downstream users remain understudied. This pilot study (1) establishes the baseline performance of GPT-3 and GPT-4 at both zero-shot and one-shot settings in eight BioNLP datasets across four applications: named entity recognition, relation extraction, multi-label document classification, and semantic similarity and reasoning, (2) examines the errors produced by the LLMs and categorized the errors into three types: missingness, inconsistencies, and unwanted artificial content, and (3) provides suggestions for using L
    
[^76]: 通过格拉姆迭代实现卷积层利普希茨常数的高效边界

    Efficient Bound of Lipschitz Constant for Convolutional Layers by Gram Iteration. (arXiv:2305.16173v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2305.16173](http://arxiv.org/abs/2305.16173)

    本文提出了一种基于循环矩阵和格拉姆迭代的方法，用于高效估计卷积神经网络中的Lipschitz常数上界。该方法精确、快速、可微分，并展现了超线性收敛。在实验上表现出较高的精度、计算成本和可扩展性，在利普希茨正则化方面也取得了具有竞争力的结果。

    

    由于利普希茨常数的控制对神经网络的训练稳定性、泛化和鲁棒性有很大影响，因此估计这个值是目前的一个科学难题。在本文中，我们使用循环矩阵理论和一种新的功率迭代替代方法，介绍了一个精确、快速和可微分的上界，用于卷积层的谱范数。称为格拉姆迭代，我们的方法展现了一个超线性的收敛。首先，我们通过一系列全面的实验证明了我们的方法在精度、计算成本和可伸缩性方面优于其他最先进的方法。然后，我们证明了它对于卷积神经网络的利普希茨正则化非常有效，与其他方法相比具有竞争力的结果。代码可在 https://github.com/blaisedelattre/lip4conv 上获得。

    Since the control of the Lipschitz constant has a great impact on the training stability, generalization, and robustness of neural networks, the estimation of this value is nowadays a real scientific challenge. In this paper we introduce a precise, fast, and differentiable upper bound for the spectral norm of convolutional layers using circulant matrix theory and a new alternative to the Power iteration. Called the Gram iteration, our approach exhibits a superlinear convergence. First, we show through a comprehensive set of experiments that our approach outperforms other state-of-the-art methods in terms of precision, computational cost, and scalability. Then, it proves highly effective for the Lipschitz regularization of convolutional neural networks, with competitive results against concurrent approaches. Code is available at https://github.com/blaisedelattre/lip4conv.
    
[^77]: 异构图神经网络梯度正则化统一方法

    Unifying gradient regularization for Heterogeneous Graph Neural Networks. (arXiv:2305.15811v1 [cs.LG])

    [http://arxiv.org/abs/2305.15811](http://arxiv.org/abs/2305.15811)

    本研究提出了一种新的梯度正则化方法Grug，旨在统一HGNN中的图形拓扑和节点特征的正则化，并解决了过度平滑、非鲁棒性等问题，综合效果和效率优于几种现有方法。

    

    异构图神经网络是一种强大的深度学习方法，用于学习异构图的表征。尽管HGNN迅速发展，但仍面临过度平滑和非鲁棒性等挑战。先前的研究表明，使用梯度正则化方法可以缓解这些问题，但现有的梯度正则化方法专注于图形拓扑或节点特征，缺乏统一方法。本文提出了一种新的梯度正则化方法Grug，旨在统一HGNN中的图形拓扑和节点特征的正则化，并解决了过度平滑、非鲁棒性等问题。实验证明，Grug在几个基准数据集上优于几种现有方法。

    Heterogeneous Graph Neural Networks (HGNNs) are a class of powerful deep learning methods widely used to learn representations of heterogeneous graphs. Despite the fast development of HGNNs, they still face some challenges such as over-smoothing, and non-robustness. Previous studies have shown that these problems can be reduced by using gradient regularization methods. However, the existing gradient regularization methods focus on either graph topology or node features. There is no universal approach to integrate these features, which severely affects the efficiency of regularization. In addition, the inclusion of gradient regularization into HGNNs sometimes leads to some problems, such as an unstable training process, increased complexity and insufficient coverage regularized information. Furthermore, there is still short of a complete theoretical analysis of the effects of gradient regularization on HGNNs. In this paper, we propose a novel gradient regularization method called Grug, 
    
[^78]: 一种严格零样例分层分类的简单有效框架

    A Simple and Effective Framework for Strict Zero-Shot Hierarchical Classification. (arXiv:2305.15282v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.15282](http://arxiv.org/abs/2305.15282)

    本研究提出了一种蕴含-矛盾预测方法，与大型语言模型结合，用于解决分层数据集中的零样例分类问题，成功实现了严格零样例分层分类。

    

    最近几年，大型语言模型（LLMs）在基准任务中表现出良好的性能，特别是在零样例或少样例情况下。然而，这些基准测试通常未能充分解决现实世界中所面临的挑战，如分层分类的挑战。为了解决这个挑战，我们将传统的分层数据集上的任务重新定义为更具指示性的长尾预测任务。我们观察到LLMs在这些情况下更容易失败。为了解决这些限制，我们提出在LLMs的基础上使用蕴含-矛盾预测方法，在严格零样例情况下获得强大的性能。重要的是，我们的方法不需要任何参数更新，这是一种资源密集型的过程，并且在多个数据集上获得了强大的性能。

    In recent years, large language models (LLMs) have achieved strong performance on benchmark tasks, especially in zero or few-shot settings. However, these benchmarks often do not adequately address the challenges posed in the real-world, such as that of hierarchical classification. In order to address this challenge, we propose refactoring conventional tasks on hierarchical datasets into a more indicative long-tail prediction task. We observe LLMs are more prone to failure in these cases. To address these limitations, we propose the use of entailment-contradiction prediction in conjunction with LLMs, which allows for strong performance in a strict zero-shot setting. Importantly, our method does not require any parameter updates, a resource-intensive process and achieves strong performance across multiple datasets.
    
[^79]: L-CAD: 带有任意级别描述的语言彩色化

    L-CAD: Language-based Colorization with Any-level Descriptions. (arXiv:2305.15217v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2305.15217](http://arxiv.org/abs/2305.15217)

    本文提出了一个模型，可依据用户提供的任意级别的自然语言描述，生成合理且视觉上令人愉悦的彩色化效果。通过利用跨模态生成模型进行语言理解和颜色先验知识，结合新型采样策略和模块设计，实现了实例感知的彩色化效果。

    

    语言彩色化是在用户友好的自然语言描述指导下生成合理且视觉上令人愉悦的颜色。以前的方法隐含地假设用户为图像中大多数对象提供了全面的颜色描述，这会导致次优的性能。在本文中，我们提出了一个统一的模型，可执行任意级别描述的语言彩色化。我们利用预训练的跨模式生成模型，以处理任意级别的描述的内在歧义，通过丰富的颜色先验知识进行语言理解。我们进一步设计了模块来与输入条件对齐，以保留局部空间结构并防止幽灵效应。通过提出的新型采样策略，我们的模型在各种复杂场景中实现了实例感知的彩色化。广泛的实验结果证明了我们在有效处理任意级别描述方面的优势，且在语言彩色化和自动彩色化方面的表现都优于现有方法。

    Language-based colorization produces plausible and visually pleasing colors under the guidance of user-friendly natural language descriptions. Previous methods implicitly assume that users provide comprehensive color descriptions for most of the objects in the image, which leads to suboptimal performance. In this paper, we propose a unified model to perform language-based colorization with any-level descriptions. We leverage the pretrained cross-modality generative model for its robust language understanding and rich color priors to handle the inherent ambiguity of any-level descriptions. We further design modules to align with input conditions to preserve local spatial structures and prevent the ghosting effect. With the proposed novel sampling strategy, our model achieves instance-aware colorization in diverse and complex scenarios. Extensive experimental results demonstrate our advantages of effectively handling any-level descriptions and outperforming both language-based and automa
    
[^80]: 评估OpenAI提供的Whisper ASR在Museum of the Person的生活史中进行标点符号预测和主题建模的效果

    Evaluating OpenAI's Whisper ASR for Punctuation Prediction and Topic Modeling of life histories of the Museum of the Person. (arXiv:2305.14580v1 [cs.CL])

    [http://arxiv.org/abs/2305.14580](http://arxiv.org/abs/2305.14580)

    本文首次对葡萄牙语中的Whisper ASR进行了标点符号预测方面的研究，并为标点符号预测在主题建模中的应用提供了有益的实验评估。

    

    自动语音识别（ASR）系统在人机交互应用中扮演着重要角色。然而，过去十年中提出的葡萄牙语ASR模型在正确识别自动转录中的标点符号方面存在局限性，这使得这些转录不能被其他系统、模型和甚至是人类使用。最近，OpenAI提出了Whisper ASR，这是一个通用的语音识别模型，有望处理这些限制。本研究是第一次针对葡萄牙语中Whisper的标点符号预测性能进行的研究。我们使用实验评估来考虑关于停顿点（逗号）和完整思想（感叹、疑问和句号）的理论方面，以及与基于转录的主题建模相关的实际方面，使用标点符号来提高性能的应用。

    Automatic speech recognition (ASR) systems play a key role in applications involving human-machine interactions. Despite their importance, ASR models for the Portuguese language proposed in the last decade have limitations in relation to the correct identification of punctuation marks in automatic transcriptions, which hinder the use of transcriptions by other systems, models, and even by humans. However, recently Whisper ASR was proposed by OpenAI, a general-purpose speech recognition model that has generated great expectations in dealing with such limitations. This chapter presents the first study on the performance of Whisper for punctuation prediction in the Portuguese language. We present an experimental evaluation considering both theoretical aspects involving pausing points (comma) and complete ideas (exclamation, question, and fullstop), as well as practical aspects involving transcript-based topic modeling - an application dependent on punctuation marks for promising performan
    
[^81]: 序列建模是离线强化学习的一个强有力的竞争者。

    Sequence Modeling is a Robust Contender for Offline Reinforcement Learning. (arXiv:2305.14550v1 [cs.LG])

    [http://arxiv.org/abs/2305.14550](http://arxiv.org/abs/2305.14550)

    序列建模是离线强化学习中比Q-Learning和Imitation Learning更适合在稀疏奖励和低质量数据设置下的选择，在任务范围增加时，序列建模和模仿学习更可取。

    

    离线强化学习使代理能够从静态数据集中学习有效的最大化收益策略。离线RL的三大范式是Q-Learning、Imitation Learning和Sequence Modeling。一个关键的问题是：在什么条件下，哪种范式被优先选择？我们通过探索代表性算法——保守Q-Learning(CQL)、行为克隆 (BC)和决策Transformer (DT)——在常用的D4RL和Robomimic基准测试中的表现来对这个问题进行了实证研究。我们设计了有针对性的实验来理解它们在数据子优性和任务复杂性方面的行为。我们的主要发现是：(1)序列建模需要比Q-Learning更多的数据来学习竞争性策略，但更加稳健；(2)序列建模在稀疏奖励和低质量数据设置中比Q-Learning和Imitation Learning都要好得多；(3)随着任务范围的增加，序列建模和模仿学习更可取。

    Offline reinforcement learning (RL) allows agents to learn effective, return-maximizing policies from a static dataset. Three major paradigms for offline RL are Q-Learning, Imitation Learning, and Sequence Modeling. A key open question is: which paradigm is preferred under what conditions? We study this question empirically by exploring the performance of representative algorithms -- Conservative Q-Learning (CQL), Behavior Cloning (BC), and Decision Transformer (DT) -- across the commonly used D4RL and Robomimic benchmarks. We design targeted experiments to understand their behavior concerning data suboptimality and task complexity. Our key findings are: (1) Sequence Modeling requires more data than Q-Learning to learn competitive policies but is more robust; (2) Sequence Modeling is a substantially better choice than both Q-Learning and Imitation Learning in sparse-reward and low-quality data settings; and (3) Sequence Modeling and Imitation Learning are preferable as task horizon inc
    
[^82]: SPEECH: 基于能量的事件中心超球的结构化预测

    SPEECH: Structured Prediction with Energy-Based Event-Centric Hyperspheres. (arXiv:2305.13617v1 [cs.CL])

    [http://arxiv.org/abs/2305.13617](http://arxiv.org/abs/2305.13617)

    这篇论文提出了一种称为SPEECH的模型，它使用能量建模来表示复杂的事件结构，并使用超球来表示事件类别。实验结果表明，SPEECH在事件检测和事件关系抽取任务中表现出卓越的性能。

    

    事件中心的结构化预测涉及预测事件的结构化输出。在大多数自然语言处理情况下，事件结构都具有复杂的依赖关系，因此有效地表示这些复杂的事件结构是具有挑战性的。为了解决这些问题，我们提出了基于能量的事件中心超球的结构化预测 (SPEECH)。 SPEECH 使用基于能量的建模来模拟事件结构组件之间的复杂依赖关系，并使用简单但有效的超球来表示事件类别。在两个统一标注的事件数据集的实验中，结果表明SPEECH在事件检测和事件关系抽取任务中占优势。

    Event-centric structured prediction involves predicting structured outputs of events. In most NLP cases, event structures are complex with manifold dependency, and it is challenging to effectively represent these complicated structured events. To address these issues, we propose Structured Prediction with Energy-based Event-Centric Hyperspheres (SPEECH). SPEECH models complex dependency among event structured components with energy-based modeling, and represents event classes with simple but effective hyperspheres. Experiments on two unified-annotated event datasets indicate that SPEECH is predominant in event detection and event-relation extraction tasks.
    
[^83]: 使用大型语言模型进行基因集概括

    Gene Set Summarization using Large Language Models. (arXiv:2305.13338v1 [q-bio.GN])

    [http://arxiv.org/abs/2305.13338](http://arxiv.org/abs/2305.13338)

    该论文介绍了一种使用大型语言模型来对基因集进行函数概括的方法，名为SPINDOCTOR，可以提供比传统方法更好的性能和可解释性。

    

    分子生物学家经常解释从高通量实验和计算分析中获得的基因列表。这通常是通过统计富集分析来完成的，该分析测量与基因或其属性相关的生物功能术语的过度或欠表示程度，基于知识库（KB）（例如Gene Ontology（GO））中的编译断言。解释基因列表也可以被构建为一个文本概括任务，利用大型语言模型（LLMs）进行，可能直接利用科学文本并避免依赖KB。我们开发了SPINDOCTOR（稳定的提示插值的受控术语的自然语言描述的结构化报告模板），一种使用GPT模型执行基因集函数概括的方法，作为标准富集分析的补充。该方法可以使用不同的基因功能信息来源：（1）从鉴定的本体KB注释中获得的结构化文本，（2）从文本挖掘中推断的本体术语，以及（3）直接从非结构化文本中获得的术语。我们在一个1813个基因集的基准数据集上评估了SPINDOCTOR，并展示了使用GPT模型显著改善了现有方法的性能，同时也提高了可解释性，因为它能够生成人类可读的基因功能摘要。

    Molecular biologists frequently interpret gene lists derived from high-throughput experiments and computational analysis. This is typically done as a statistical enrichment analysis that measures the over- or under-representation of biological function terms associated with genes or their properties, based on curated assertions from a knowledge base (KB) such as the Gene Ontology (GO). Interpreting gene lists can also be framed as a textual summarization task, enabling the use of Large Language Models (LLMs), potentially utilizing scientific texts directly and avoiding reliance on a KB.  We developed SPINDOCTOR (Structured Prompt Interpolation of Natural Language Descriptions of Controlled Terms for Ontology Reporting), a method that uses GPT models to perform gene set function summarization as a complement to standard enrichment analysis. This method can use different sources of gene functional information: (1) structured text derived from curated ontological KB annotations, (2) ontol
    
[^84]: 粗到细: 一种用于三维分子生成的分层扩散模型

    Coarse-to-Fine: a Hierarchical Diffusion Model for Molecule Generation in 3D. (arXiv:2305.13266v2 [q-bio.BM] UPDATED)

    [http://arxiv.org/abs/2305.13266](http://arxiv.org/abs/2305.13266)

    该论文提出了一种粗到细的方法来解决分子生成中的组合优化问题，并采用分层扩散模型和HIPER算法生成结构的有效性和多样性，表现优于现有方法。

    

    在药物发现中，生成理想的三维分子结构是一个基本问题。尽管我们取得了相当大的进展，但现有方法通常在原子分辨率下生成分子，并忽略内在的局部结构，如环，这导致生成的结构质量较差，特别是当生成大分子时。基于片段的分子生成是一种有前途的策略，但由于组合优化问题，它不容易用于3D非自回归生成。在本文中，我们采用粗到细的策略来解决这个问题，其中提出了一种基于分层扩散的模型（即HierDiff），以保持局部段的有效性而不依赖于自回归建模。具体而言，HierDiff首先通过等变扩散过程生成粗粒度分子几何体，其中每个粗粒度节点反映分子中的一个片段。然后，粗粒度节点被分解成细粒度节点，其中细粒度节点是分子中的一个三维空间点。我们进一步提出了一种分层采样和经验概率细化（即HIPER）算法，以确保生成的结构的有效性和多样性。我们的实验表明，HierDiff在定量评估指标和视觉质量方面优于现有方法。

    Generating desirable molecular structures in 3D is a fundamental problem for drug discovery. Despite the considerable progress we have achieved, existing methods usually generate molecules in atom resolution and ignore intrinsic local structures such as rings, which leads to poor quality in generated structures, especially when generating large molecules. Fragment-based molecule generation is a promising strategy, however, it is nontrivial to be adapted for 3D non-autoregressive generations because of the combinational optimization problems. In this paper, we utilize a coarse-to-fine strategy to tackle this problem, in which a Hierarchical Diffusion-based model (i.e.~HierDiff) is proposed to preserve the validity of local segments without relying on autoregressive modeling. Specifically, HierDiff first generates coarse-grained molecule geometries via an equivariant diffusion process, where each coarse-grained node reflects a fragment in a molecule. Then the coarse-grained nodes are dec
    
[^85]: 不可预测及部分可观测环境下的多机器人协作的赌博次模最大化

    Bandit Submodular Maximization for Multi-Robot Coordination in Unpredictable and Partially Observable Environments. (arXiv:2305.12795v2 [eess.SY] UPDATED)

    [http://arxiv.org/abs/2305.12795](http://arxiv.org/abs/2305.12795)

    本文提出了一种在未知演化且只能部分观测的环境下采用赌博反馈和有界跟踪遗憾的次模协调算法，以解决多机器人协作问题，并适用于目标跟踪、环境映射和区域监测等复杂任务。

    

    本文研究了在不可预测及部分可观测环境下的多机器人协作问题，即未来演化未知且只能部分观测的环境下的协作问题。我们的研究动机来自自主性的未来，涉及多个机器人在动态、非结构化和部分可观测的环境中协调行动，以完成复杂任务，如目标跟踪、环境映射和区域监测。这些任务通常被建模为次模最大化协调问题，由于机器人之间的信息重叠。我们介绍了第一个采用赌博反馈和有界跟踪遗憾的次模协调算法——赌博反馈是机器人在局部观测下仅计算已选择行动的影响而非所有可选替代行动的能力；跟踪遗憾是算法相对于最优时间的次优性。

    We study the problem of multi-agent coordination in unpredictable and partially observable environments, that is, environments whose future evolution is unknown a priori and that can only be partially observed. We are motivated by the future of autonomy that involves multiple robots coordinating actions in dynamic, unstructured, and partially observable environments to complete complex tasks such as target tracking, environmental mapping, and area monitoring. Such tasks are often modeled as submodular maximization coordination problems due to the information overlap among the robots. We introduce the first submodular coordination algorithm with bandit feedback and bounded tracking regret -- bandit feedback is the robots' ability to compute in hindsight only the effect of their chosen actions, instead of all the alternative actions that they could have chosen instead, due to the partial observability; and tracking regret is the algorithm's suboptimality with respect to the optimal time-
    
[^86]: 关于联合学习语音情感和自动语音识别的有效性和噪声鲁棒性

    On the Efficacy and Noise-Robustness of Jointly Learned Speech Emotion and Automatic Speech Recognition. (arXiv:2305.12540v2 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2305.12540](http://arxiv.org/abs/2305.12540)

    本论文研究了联合学习ASR和SER的多任务学习方法，并证明在低资源环境下不仅在SER中取得了显著提升，同时也提高了ASR的性能，并且在嘈杂环境中，联合训练得到的模型比独立训练的模型更具噪声鲁棒性

    

    新时代的对话代理系统在嘈杂的环境中使用两种独立的方法执行语音情感识别（SER）和自动语音识别（ASR）。本文研究了一种低资源环境下的联合ASR-SER多任务学习方法，发现不仅在SER中取得了改进，而且在ASR中也有所提升。我们还研究了这种联合训练模型对背景噪声、胡言乱语和音乐的鲁棒性。在IEMOCAP数据集上的实验结果表明，在干净的环境中，联合学习可以将ASR单词错误率（WER）和SER分类准确率分别提高10.7％和2.3％。在加入了MUSAN的嘈杂场景中，联合方法在许多嘈杂条件下优于独立的ASR和SER方法。总之，联合ASR-SER方法比独立的ASR和SER方法产生了更具鲁棒性的模型。

    New-age conversational agent systems perform both speech emotion recognition (SER) and automatic speech recognition (ASR) using two separate and often independent approaches for real-world application in noisy environments. In this paper, we investigate a joint ASR-SER multitask learning approach in a low-resource setting and show that improvements are observed not only in SER, but also in ASR. We also investigate the robustness of such jointly trained models to the presence of background noise, babble, and music. Experimental results on the IEMOCAP dataset show that joint learning can improve ASR word error rate (WER) and SER classification accuracy by 10.7% and 2.3% respectively in clean scenarios. In noisy scenarios, results on data augmented with MUSAN show that the joint approach outperforms the independent ASR and SER approaches across many noisy conditions. Overall, the joint ASR-SER approach yielded more noise-resistant models than the independent ASR and SER approaches.
    
[^87]: 多头状态空间模型在语音识别中的应用

    Multi-Head State Space Model for Speech Recognition. (arXiv:2305.12498v2 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2305.12498](http://arxiv.org/abs/2305.12498)

    本文提出了一种多头状态空间（MH-SSM）模型，它能够用于语音识别任务并在LibriSpeech数据集上表现出的新的性能，是变压器变换器的优秀替代方案。同时, MH-SSM层的引入也提高了变压器块的性能，达到了现有最新水平。

    

    最近，在一些小规模的序列和语言建模任务上，状态空间模型（SSM）已经表现出了很大的潜力，并且能够与许多基于注意力的方法相媲美甚至超越。在本文中，我们提出了一种多头状态空间（MH-SSM）架构，它配备了特殊的门控机制，其中并行头被教授如何在序列数据上学习本地和全局的时间动态。作为变压器编码器中多头注意力的直接替代方案，这个新模型在LibriSpeech语音识别语料库上显著优于变压器变换器。此外，我们在变压器块中增加了MH-SSM层，称为Stateformer，不使用外部语言模型，在LibriSpeech任务中达到了最新的性能，开发集和测试集的词错误率分别为1.76％ / 4.37％和1.91％ / 4.36％。

    State space models (SSMs) have recently shown promising results on small-scale sequence and language modelling tasks, rivalling and outperforming many attention-based approaches. In this paper, we propose a multi-head state space (MH-SSM) architecture equipped with special gating mechanisms, where parallel heads are taught to learn local and global temporal dynamics on sequence data. As a drop-in replacement for multi-head attention in transformer encoders, this new model significantly outperforms the transformer transducer on the LibriSpeech speech recognition corpus. Furthermore, we augment the transformer block with MH-SSMs layers, referred to as the Stateformer, achieving state-of-the-art performance on the LibriSpeech task, with word error rates of 1.76\%/4.37\% on the development and 1.91\%/4.36\% on the test sets without using an external language model.
    
[^88]: 用生物约束深度学习架构解释V1特性

    Explaining V1 Properties with a Biologically Constrained Deep Learning Architecture. (arXiv:2305.11275v1 [q-bio.NC])

    [http://arxiv.org/abs/2305.11275](http://arxiv.org/abs/2305.11275)

    该论文使用生物特性构建CNNs架构，成功解释V1神经活动特性。

    

    尽管缺乏生物学的特异性，卷积神经网络(CNNs)最近被认为是腹侧视觉通路的有前途的模型。虽然当前的最先进的V1模型是通过对抗性例子的训练和广泛增强的数据浮现出来的，但这些模型仍无法解释V1中观察到的关键神经特性，这些特性来自于生物电路。为了弥补这个差距，我们系统地将神经科学的架构组件纳入CNNs中，以识别一组全面解释V1神经活动的机制和架构。我们展示了通过集成模拟中心-周围拮抗、局部感受野、调谐归一化和皮层放大的架构组件来推动模型-V1对齐的巨大改进。通过使用这些专门的组件增强任务驱动的CNNs，我们发现了潜在表示产生了优秀的模型。

    Convolutional neural networks (CNNs) have recently emerged as promising models of the ventral visual stream, despite their lack of biological specificity. While current state-of-the-art models of the primary visual cortex (V1) have surfaced from training with adversarial examples and extensively augmented data, these models are still unable to explain key neural properties observed in V1 that arise from biological circuitry. To address this gap, we systematically incorporated neuroscience-derived architectural components into CNNs to identify a set of mechanisms and architectures that comprehensively explain neural activity in V1. We show drastic improvements in model-V1 alignment driven by the integration of architectural components that simulate center-surround antagonism, local receptive fields, tuned normalization, and cortical magnification. Upon enhancing task-driven CNNs with a collection of these specialized components, we uncover models with latent representations that yield s
    
[^89]: 不确定性引导的标签去噪在文档级远程关系抽取中的应用

    Uncertainty Guided Label Denoising for Document-level Distant Relation Extraction. (arXiv:2305.11029v1 [cs.CL])

    [http://arxiv.org/abs/2305.11029](http://arxiv.org/abs/2305.11029)

    本文提出了一种使用不确定性引导的标签去噪技术，可以有效准确地在文档级远程关系抽取中选择可信的伪标签，提高了性能表现，并在DocRED数据集上实现了新的最佳性能。

    

    文档级关系抽取旨在推断文档中实体之间的复杂语义关系。远程监督能够生成大量自动标注的数据，从而可以提高文档关系抽取的性能。然而，不可靠的伪标签会带来新的噪声，例如添加虚假的伪标签和失去正确的监督标签。因此，如何选择有效的伪标签来去噪远程监督数据仍然是文档级远程关系抽取中的一个挑战。为了解决这个问题，我们引入了不确定性估计技术来确定伪标签是否可信。在本文中，我们提出了一个带有不确定性引导标签去噪的文档级远程关系抽取框架，UGDRE。具体而言，我们提出了一种新的实例级不确定性估计方法，它测量了具有重叠关系的伪标签的可靠性。通过进一步考虑实例级和关系级的不确定性，我们设计了一个标签去噪组件，可以有效地选择可靠的伪标签进行文档关系抽取。在两个基准数据集上的实验结果表明，我们的方法显著优于现有方法，并在DocRED数据集上实现了新的最佳性能。

    Document-level relation extraction (DocRE) aims to infer complex semantic relations among entities in a document. Distant supervision (DS) is able to generate massive auto-labeled data, which can improve DocRE performance. Recent works leverage pseudo labels generated by the pre-denoising model to reduce noise in DS data. However, unreliable pseudo labels bring new noise, e.g., adding false pseudo labels and losing correct DS labels. Therefore, how to select effective pseudo labels to denoise DS data is still a challenge in document-level distant relation extraction. To tackle this issue, we introduce uncertainty estimation technology to determine whether pseudo labels can be trusted. In this work, we propose a Document-level distant Relation Extraction framework with Uncertainty Guided label denoising, UGDRE. Specifically, we propose a novel instance-level uncertainty estimation method, which measures the reliability of the pseudo labels with overlapping relations. By further consider
    
[^90]: X-IQE：利用视觉大语言模型对文本到图像生成进行可解释的图像质量评估

    X-IQE: eXplainable Image Quality Evaluation for Text-to-Image Generation with Visual Large Language Models. (arXiv:2305.10843v1 [cs.CV])

    [http://arxiv.org/abs/2305.10843](http://arxiv.org/abs/2305.10843)

    本文提出了一种名为X-IQE的图像质量评估方法，使用视觉大语言模型对文本到图像生成进行评估，并生成文本解释。它具有区分真实和生成图像、评估文本-图像对齐和评估图像美学等优点，显著增强了深度图像质量评估模型的透明度和可解释性。

    

    本文介绍了一种新颖的可解释的图像质量评估方法，称为X-IQE，它利用视觉大语言模型来评估文本到图像生成方法，通过生成文本解释。X-IQE利用分层思维链（CoT）使MiniGPT-4能够产生自洽、无偏的文本，与人类评估高度相关。它具有多种优点，包括能够区分真实图像和生成图像、评估文本-图像对齐和评估图像美学，而不需要模型训练或微调。与人类评估相比，X-IQE更具成本效益和效率，同时显著增强了深度图像质量评估模型的透明度和可解释性。我们使用主流扩散模型生成的图像验证了我们的方法作为基准的有效性。X-IQE在COCO Caption上表现出与最先进评估方法类似的性能，

    This paper introduces a novel explainable image quality evaluation approach called X-IQE, which leverages visual large language models (LLMs) to evaluate text-to-image generation methods by generating textual explanations. X-IQE utilizes a hierarchical Chain of Thought (CoT) to enable MiniGPT-4 to produce self-consistent, unbiased texts that are highly correlated with human evaluation. It offers several advantages, including the ability to distinguish between real and generated images, evaluate text-image alignment, and assess image aesthetics without requiring model training or fine-tuning. X-IQE is more cost-effective and efficient compared to human evaluation, while significantly enhancing the transparency and explainability of deep image quality evaluation models. We validate the effectiveness of our method as a benchmark using images generated by prevalent diffusion models. X-IQE demonstrates similar performance to state-of-the-art (SOTA) evaluation methods on COCO Caption, while 
    
[^91]: 阅读过程中对小说人物个性的理解

    Personality Understanding of Fictional Characters during Book Reading. (arXiv:2305.10156v1 [cs.CL])

    [http://arxiv.org/abs/2305.10156](http://arxiv.org/abs/2305.10156)

    本文提出了一个NLP领域内尚未研究的问题：情景和细致地理解小说人物个性，并提供了第一个标记数据集PersoNet来解决这个问题。

    

    理解小说人物个性是阅读故事的关键。随着读者与故事的互动，他们对一个人物的理解会根据新的事件和信息而演变；并且可以感知到多个精细的个性方面。这导致了一个自然的问题：情境和精细的个性理解。这个问题在NLP领域中没有得到研究，主要是由于缺乏模仿阅读过程的适当数据集。我们提供了第一个标记数据集PersoNet来解决这个问题。我们的新型注释策略涉及用在线阅读应用程序的用户笔记作为原始书籍的代理进行注释。实验和人体研究表明，我们的数据集构建既有效又准确；我们的任务在很大程度上依赖于长期的上下文以实现对机器和人类的准确预测。数据集可在https://github.com/Gorov/personet_acl23获得。

    Comprehending characters' personalities is a crucial aspect of story reading. As readers engage with a story, their understanding of a character evolves based on new events and information; and multiple fine-grained aspects of personalities can be perceived. This leads to a natural problem of situated and fine-grained personality understanding. The problem has not been studied in the NLP field, primarily due to the lack of appropriate datasets mimicking the process of book reading. We present the first labeled dataset PersoNet for this problem. Our novel annotation strategy involves annotating user notes from online reading apps as a proxy for the original books. Experiments and human studies indicate that our dataset construction is both efficient and accurate; and our task heavily relies on long-term context to achieve accurate predictions for both machines and humans. The dataset is available at https://github.com/Gorov/personet_acl23.
    
[^92]: sustain.AI: 一种分析可持续性报告的推荐系统

    sustain.AI: a Recommender System to analyze Sustainability Reports. (arXiv:2305.08711v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.08711](http://arxiv.org/abs/2305.08711)

    sustain.AI是一个智能的、上下文感知的推荐系统，可以帮助审计师、金融投资者以及广大公众高效地分析公司的可持续性报告，并通过与GRI标准匹配来提供更好的推荐精度。

    

    本文介绍了sustain.AI，这是一个智能的、上下文感知的推荐系统，可帮助审计师、金融投资者以及广大公众高效地分析公司的可持续性报告。该工具利用了端到端可训练的架构，将基于BERT的编码模块与多标签分类头相结合，将可持续性报告中的相关文本段落与全球报告倡议（GRI）标准中的相应法律法规匹配。我们在两个新颖的德国可持续性报告数据集上评估了我们的模型，并始终实现了与多个强基线模型相比更高的推荐性能。此外，sustain.AI已经公开在https://sustain.ki.nrw/上提供给所有人使用。

    We present $\text{sustain.AI}$, an intelligent, context-aware recommender system that assists auditors and financial investors as well as the general public to efficiently analyze companies' sustainability reports. The tool leverages an end-to-end trainable architecture that couples a BERT-based encoding module with a multi-label classification head to match relevant text passages from sustainability reports to their respective law regulations from the Global Reporting Initiative (GRI) standards. We evaluate our model on two novel German sustainability reporting data sets and consistently achieve a significantly higher recommendation performance compared to multiple strong baselines. Furthermore, $\text{sustain.AI}$ is publicly available for everyone at https://sustain.ki.nrw/.
    
[^93]: 个性化感知的推荐系统中的LMMs模型

    PALR: Personalization Aware LLMs for Recommendation. (arXiv:2305.07622v1 [cs.IR])

    [http://arxiv.org/abs/2305.07622](http://arxiv.org/abs/2305.07622)

    本文提出了一个称为PALR的框架，将用户的历史行为与LLMs相结合，生成用户喜欢的物品的推荐。与现有的推荐方法相比，我们的PALR框架实现了最先进的性能。

    

    大型语言模型(LLMs)由于其出色的性能而受到越来越多的关注。本文提出了一种新的框架PALR，将用户的历史行为与LLMs相结合，以生成用户喜欢的物品的推荐。我们首先使用用户/物品互动作为候选检索的指导，然后采用基于LLMs的排序模型生成推荐物品。实验结果表明，与现有的推荐方法相比，我们提出的PALR框架实现了最先进的性能。

    Large language models (LLMs) have recently received significant attention for their exceptional capabilities. Despite extensive efforts in developing general-purpose LLMs that can be utilized in various natural language processing (NLP) tasks, there has been less research exploring their potential in recommender systems. In this paper, we propose a novel framework, named PALR, which aiming to combine user history behaviors (such as clicks, purchases, ratings, etc.) with LLMs to generate user preferred items. Specifically, we first use user/item interactions as guidance for candidate retrieval. Then we adopt a LLM-based ranking model to generate recommended items. Unlike existing approaches that typically adopt general-purpose LLMs for zero/few-shot recommendation testing or training on small-sized language models (with less than 1 billion parameters), which cannot fully elicit LLMs' reasoning abilities and leverage rich item side parametric knowledge, we fine-tune a 7 billion parameter
    
[^94]: 从大型语言模型中提取脚本知识以进行受限语言规划

    Distilling Script Knowledge from Large Language Models for Constrained Language Planning. (arXiv:2305.05252v1 [cs.CL])

    [http://arxiv.org/abs/2305.05252](http://arxiv.org/abs/2305.05252)

    本文首次定义了受限语言规划任务，提出了一种方法来提高大型语言模型在这个任务中的表现，并提取了一个新颖的受限语言规划数据集。实验证明该方法显著提高了其在约束忠实度方面的能力，并对赋予较小的语言模型受限语言规划能力非常有效。

    

    在日常生活中，人们经常通过遵循目标导向的脚本形式的逐步说明来规划自己的行动。以往的工作利用语言模型（LM）来为立体活动的抽象目标（例如，“制作蛋糕”）进行规划，但对于具有多方面约束的更具体目标（例如，“为糖尿病患者制作蛋糕”）鲜有研究。本文首次定义了受限语言规划任务。我们提出了一种过度生成并过滤的方法来改善大型语言模型（LLM）在这个任务中的表现，并利用它来提取一种新颖的受限语言规划数据集CoScript，其中包括55,000个脚本。实验证明，我们的方法显著提高了LLM在受限语言规划方面的能力，特别是在约束忠实度方面。此外，CoScript被证明对赋予较小的LM受限语言规划能力是非常有效的。

    In everyday life, humans often plan their actions by following step-by-step instructions in the form of goal-oriented scripts. Previous work has exploited language models (LMs) to plan for abstract goals of stereotypical activities (e.g., "make a cake"), but leaves more specific goals with multi-facet constraints understudied (e.g., "make a cake for diabetics"). In this paper, we define the task of constrained language planning for the first time. We propose an overgenerate-then-filter approach to improve large language models (LLMs) on this task, and use it to distill a novel constrained language planning dataset, CoScript, which consists of 55,000 scripts. Empirical results demonstrate that our method significantly improves the constrained language planning ability of LLMs, especially on constraint faithfulness. Furthermore, CoScript is demonstrated to be quite effective in endowing smaller LMs with constrained language planning ability.
    
[^95]: ANALOGICAL- 一种新的大语言模型文本类比评测基准

    ANALOGICAL - A New Benchmark for Analogy of Long Text for Large Language Models. (arXiv:2305.05050v1 [cs.CL])

    [http://arxiv.org/abs/2305.05050](http://arxiv.org/abs/2305.05050)

    本文介绍了一种名为“ANALOGICAL”的新型基准，用以内在评估LLMs在长文本类比中的能力，包括六个复杂级别的长文本类比分类，并使用13个数据集和三种距离度量方法来评估8个LLMs在语义向量空间中识别类比对的能力。

    

    在过去的十年中，以词级别的类比为形式的类比在衡量诸如word2vec之类的词嵌入方法的质量方面发挥了重要作用。然而，现代的大型语言模型(LLMs)主要根据GLUE和SuperGLUE等基准的外在量度进行评估，而在LLMs是否能够在长文本中绘制类比的方面，只有少数几项研究。本文介绍了一种名为“ANALOGICAL”的新型基准，以六个复杂级别的长文本类比分类对LLMs进行内在评估，分别为 (i)单词、(ii)单词vs句子、(iii)语法、(iv)否定、(v)蕴含和(vi)隐喻。利用13个数据集和三种不同的距离度量方法，我们评估了8个LLMs在语义向量空间中识别类比对的能力(例如，“我能说两种语言”应该更接近“我是双语的”，而“我喜欢巧克力”和“我不喜欢巧克力”应该是正交的)。

    Over the past decade, analogies, in the form of word-level analogies, have played a significant role as an intrinsic measure of evaluating the quality of word embedding methods such as word2vec. Modern large language models (LLMs), however, are primarily evaluated on extrinsic measures based on benchmarks such as GLUE and SuperGLUE, and there are only a few investigations on whether LLMs can draw analogies between long texts. In this paper, we present ANALOGICAL, a new benchmark to intrinsically evaluate LLMs across a taxonomy of analogies of long text with six levels of complexity -- (i) word, (ii) word vs. sentence, (iii) syntactic, (iv) negation, (v) entailment, and (vi) metaphor. Using thirteen datasets and three different distance measures, we evaluate the abilities of eight LLMs in identifying analogical pairs in the semantic vector space (e.g., "I can speak two languages" should be closer to "I am bilingual" while "I like chocolate" and "I do not like chocolate" should be orthog
    
[^96]: 系统研究基于伪目标训练的知识蒸馏用于自然语言生成

    A Systematic Study of Knowledge Distillation for Natural Language Generation with Pseudo-Target Training. (arXiv:2305.02031v1 [cs.CL])

    [http://arxiv.org/abs/2305.02031](http://arxiv.org/abs/2305.02031)

    本文研究如何压缩自然语言生成模型以适应实际应用需求，通过使用知识蒸馏和伪目标训练技术针对特定的自然语言生成任务和数据集进行优化，并取得了显著效果。

    

    现代自然语言生成模型需要大量的计算和存储资源。本文研究压缩这些模型的潜力，这对于服务数百万用户的实际应用至关重要。我们聚焦于知识蒸馏（KD）技术，其中小的学生模型学习模仿大的教师模型，使得可以从教师向学生传递知识。与之前的大部分工作不同，我们的目标是针对特定的自然语言生成任务和数据集优化模型。通常，在真实世界的应用中，除了有标记数据外，还有大量的未标记任务特定数据，这对于通过知识蒸馏获得高压缩率至关重要。在本文中，我们在现实的假设下，对各种自然语言生成任务进行了系统的任务特定知识蒸馏研究，并讨论了自然语言生成蒸馏的特殊特征，尤其是曝光偏差问题。接着，我们推导出一系列伪目标训练（PTT）技术，缓解了这个问题，并提高了学生模型的质量。通过广泛的实验评估，我们证明了我们提出的方法在不同的自然语言生成任务和数据集上的有效性。

    Modern Natural Language Generation (NLG) models come with massive computational and storage requirements. In this work, we study the potential of compressing them, which is crucial for real-world applications serving millions of users. We focus on Knowledge Distillation (KD) techniques, in which a small student model learns to imitate a large teacher model, allowing to transfer knowledge from the teacher to the student. In contrast to much of the previous work, our goal is to optimize the model for a specific NLG task and a specific dataset. Typically, in real-world applications, in addition to labeled data there is abundant unlabeled task-specific data, which is crucial for attaining high compression rates via KD. In this work, we conduct a systematic study of task-specific KD techniques for various NLG tasks under realistic assumptions. We discuss the special characteristics of NLG distillation and particularly the exposure bias problem. Following, we derive a family of Pseudo-Target
    
[^97]: FIREBALL：一份包含结构化游戏状态信息的Dungeons & Dragons实际游戏数据集

    FIREBALL: A Dataset of Dungeons and Dragons Actual-Play with Structured Game State Information. (arXiv:2305.01528v1 [cs.CL])

    [http://arxiv.org/abs/2305.01528](http://arxiv.org/abs/2305.01528)

    本研究介绍了一份包含真实游戏状态信息的Dungeons & Dragons实际游戏数据集FIREBALL，它可以改善自然语言生成的质量。此外，LLMs可以使用FIREBALL中的游戏状态信息来生成更高质量的游戏回合。

    

    Dungeons & Dragons（D＆D）是一款桌面角色扮演游戏，其玩家之间存在复杂的自然语言交互和隐藏的状态信息。最近的研究表明，拥有状态信息的大型语言模型（LLMs）生成的游戏回合比仅使用对话历史的LLMs更具高质量。然而，以往的研究使用的游戏状态信息是启发式创建的，并不是真正的黄金标准游戏状态。我们提出了FIREBALL，这是一个包含真实游戏状态信息的大型数据集，其中包含来自Discord的近25,000个真实D＆D游戏会话。我们记录了使用Avrae机器人的玩家的游戏会话，该机器人是为了帮助人们在线玩D＆D而开发的，并捕获了语言、游戏命令和基础游戏状态信息。我们证明，通过使用Avrae状态信息，FIREBALL可以提高自然语言生成（NLG），从而提高自动评估指标和人类的质量评判。此外，我们还展示了LLMs可以生成…

    Dungeons & Dragons (D&D) is a tabletop roleplaying game with complex natural language interactions between players and hidden state information. Recent work has shown that large language models (LLMs) that have access to state information can generate higher quality game turns than LLMs that use dialog history alone. However, previous work used game state information that was heuristically created and was not a true gold standard game state. We present FIREBALL, a large dataset containing nearly 25,000 unique sessions from real D\&D gameplay on Discord with true game state info. We recorded game play sessions of players who used the Avrae bot, which was developed to aid people in playing D&D online, capturing language, game commands and underlying game state information. We demonstrate that FIREBALL can improve natural language generation (NLG) by using Avrae state information, improving both automated metrics and human judgments of quality. Additionally, we show that LLMs can generate
    
[^98]: 树状Parzen估计器：理解其算法组成部分及其在提高实证表现中的作用

    Tree-structured Parzen estimator: Understanding its algorithm components and their roles for better empirical performance. (arXiv:2304.11127v1 [cs.LG])

    [http://arxiv.org/abs/2304.11127](http://arxiv.org/abs/2304.11127)

    该论文介绍了一种广泛使用的贝叶斯优化方法 Tree-structured Parzen estimator (TPE)，并对其控制参数的作用和算法直觉进行了讨论和分析，提供了一组推荐设置并证明其能够提高TPE的性能表现。

    

    许多领域中最近的进展要求更加复杂的实验设计。这种复杂的实验通常有许多参数，需要参数调整。Tree-structured Parzen estimator (TPE) 是一种贝叶斯优化方法，在最近的参数调整框架中被广泛使用。尽管它很受欢迎，但控制参数的角色和算法直觉尚未得到讨论。在本教程中，我们将确定每个控制参数的作用以及它们对超参数优化的影响，使用多种基准测试。我们将从剖析研究中得出的推荐设置与基准方法进行比较，并证明我们的推荐设置提高了TPE的性能。我们的TPE实现可在https://github.com/nabenabe0928/tpe/tree/single-opt中获得。

    Recent advances in many domains require more and more complicated experiment design. Such complicated experiments often have many parameters, which necessitate parameter tuning. Tree-structured Parzen estimator (TPE), a Bayesian optimization method, is widely used in recent parameter tuning frameworks. Despite its popularity, the roles of each control parameter and the algorithm intuition have not been discussed so far. In this tutorial, we will identify the roles of each control parameter and their impacts on hyperparameter optimization using a diverse set of benchmarks. We compare our recommended setting drawn from the ablation study with baseline methods and demonstrate that our recommended setting improves the performance of TPE. Our TPE implementation is available at https://github.com/nabenabe0928/tpe/tree/single-opt.
    
[^99]: 利用位置去噪预测易得几何结构的量子化学性质

    Predicting quantum chemical property with easy-to-obtain geometry via positional denoising. (arXiv:2304.03724v1 [physics.chem-ph])

    [http://arxiv.org/abs/2304.03724](http://arxiv.org/abs/2304.03724)

    该论文提出了一种方法，利用位置去噪预测易得几何结构的量子化学性质，可以用相对容易获得的几何结构，精确预测性质，在分子性质以及化学反应性质的预测任务中都表现优秀。

    

    由于量子化学性质与其几何结构有重要关联，使用3D几何信息的图神经网络在许多任务中取得了较高的预测精度。然而，它们通常需要高级量子力学计算得出的3D几何结构，这在实际问题中是不可行的，限制了其在现实问题中的适用性。为了解决这个问题，我们提出了一种方法，利用相对容易获得的几何结构（例如来自分子力场的优化几何结构）精确预测性质。在这种方法中，输入几何结构逐渐接近正确几何结构，通过堆叠去噪层。我们使用3D消息传递体系结构研究了该方法在两个预测任务（分子性质和化学反应性质）中的性能。通过去噪过程减少位置误差有助于性能的提高。

    As quantum chemical properties have a significant dependence on their geometries, graph neural networks (GNNs) using 3D geometric information have achieved high prediction accuracy in many tasks. However, they often require 3D geometries obtained from high-level quantum mechanical calculations, which are practically infeasible, limiting their applicability in real-world problems. To tackle this, we propose a method to accurately predict the properties with relatively easy-to-obtain geometries (e.g., optimized geometries from the molecular force field). In this method, the input geometry, regarded as the corrupted geometry of the correct one, gradually approaches the correct one as it passes through the stacked denoising layers. We investigated the performance of the proposed method using 3D message-passing architectures for two prediction tasks: molecular properties and chemical reaction property. The reduction of positional errors through the denoising process contributed to performan
    
[^100]: 自我反馈迭代精炼：一种无需监督学习或加强学习的LM改进框架

    Self-Refine: Iterative Refinement with Self-Feedback. (arXiv:2303.17651v1 [cs.CL])

    [http://arxiv.org/abs/2303.17651](http://arxiv.org/abs/2303.17651)

    自我反馈迭代精炼是一种无需监督学习或加强学习的LLMs初始输出优化方法，优于直接生成，被证实在7个不同任务中表现更好。

    

    鉴于语言模型(LLMs)不总是能在第一次良好地解决生成问题（如摘要、答案、解释等），我们引入自我反馈迭代精炼（SELF-REFINE）框架，通过迭代反馈和精炼相似地优化LLMs的初始输出。主要思想是：使用LLM生成输出，然后允许同一模型提供其自身输出的多方面反馈，最后利用反馈使相同模型精炼先前生成的输出。我们的迭代精炼框架与早期工作不同，无需监督训练数据或加强学习，并且可以与单个LLM一起使用。我们对七个不同的任务进行了实验，范围从评论重写到数学推理，表明我们的方法优于直接生成。在所有任务中，使用SELF-REFINE生成的输出被人类和自动化指标优先于使用GPT-3.5和GPT-4直接生成的输出，表现得更好。

    Like people, LLMs do not always generate the best text for a given generation problem on their first try (e.g., summaries, answers, explanations). Just as people then refine their text, we introduce SELF-REFINE, a framework for similarly improving initial outputs from LLMs through iterative feedback and refinement. The main idea is to generate an output using an LLM, then allow the same model to provide multi-aspect feedback for its own output; finally, the same model refines its previously generated output given its own feedback. Unlike earlier work, our iterative refinement framework does not require supervised training data or reinforcement learning, and works with a single LLM. We experiment with 7 diverse tasks, ranging from review rewriting to math reasoning, demonstrating that our approach outperforms direct generation. In all tasks, outputs generated with SELF-REFINE are preferred by humans and by automated metrics over those generated directly with GPT-3.5 and GPT-4, improving
    
[^101]: 零和马尔可夫博弈中强化学习的新政策迭代算法

    A New Policy Iteration Algorithm For Reinforcement Learning in Zero-Sum Markov Games. (arXiv:2303.09716v1 [cs.LG])

    [http://arxiv.org/abs/2303.09716](http://arxiv.org/abs/2303.09716)

    本文提出了一种适用于零和马尔可夫博弈的简单但有效的策略迭代算法。

    

    许多基于模型的强化学习算法可以被视为具有两个阶段: 学习阶段和规划阶段。在标准MDPs情况下，可以使用价值迭代或策略迭代来解决学习问题。但在零和马尔可夫博弈的情况下，没有有效的策略迭代算法，以前的尝试都有局限性。本文提出了一种简单的策略迭代变体，能够有效地解决这个问题。

    Many model-based reinforcement learning (RL) algorithms can be viewed as having two phases that are iteratively implemented: a learning phase where the model is approximately learned and a planning phase where the learned model is used to derive a policy. In the case of standard MDPs, the learning problem can be solved using either value iteration or policy iteration. However, in the case of zero-sum Markov games, there is no efficient policy iteration algorithm; e.g., it has been shown in Hansen et al. (2013) that one has to solve Omega(1/(1-alpha)) MDPs, where alpha is the discount factor, to implement the only known convergent version of policy iteration. Another algorithm for Markov zero-sum games, called naive policy iteration, is easy to implement but is only provably convergent under very restrictive assumptions. Prior attempts to fix naive policy iteration algorithm have several limitations. Here, we show that a simple variant of naive policy iteration for games converges, and 
    
[^102]: 基于后训练量化的大型语言模型综合研究

    A Comprehensive Study on Post-Training Quantization for Large Language Models. (arXiv:2303.08302v1 [cs.LG])

    [http://arxiv.org/abs/2303.08302](http://arxiv.org/abs/2303.08302)

    本文基于数万个零-shot实验对基于后训练量化的大型语言模型的不同量化组件进行了综合研究，结果发现细粒度量化和后训练量化方法很重要，用粗粒度量化的更高位数比用非常细粒度的更低位数更强大。我们给出了如何为不同大小的\llms利用量化的建议。

    

    后训练量化是一种减少大型语言模型内存消耗和/或计算成本的权衡方法。然而，关于不同量化方案、不同模型族、不同后训练量化方法、不同量化位精度等的影响的全面研究仍缺失。本文通过数万个零-shot实验对这些组件进行了广泛的研究。我们的研究结果表明：(1)细粒度量化和后训练量化方法(而不是朴素的最近舍入量化)是实现良好精度的必要条件；(2) 用粗粒度量化的更高位数（如5位）比用非常细粒度的更低位数（如4位）（其有效位数与5位相似）更强大。我们还提出了如何为不同大小的\llms利用量化的建议，并留下未来机会和系统工作的建议。

    Post-training quantization (\ptq) had been recently shown as a compromising method to reduce the memory consumption and/or compute cost for large language models. However, a comprehensive study about the effect of different quantization schemes, different model families, different \ptq methods, different quantization bit precision, etc, is still missing. In this work, we provide an extensive study on those components over tens of thousands of zero-shot experiments. Our results show that (1) Fine-grained quantization and \ptq methods (instead of naive round-to-nearest quantization) are necessary to achieve good accuracy and (2) Higher bits (e.g., 5 bits) with coarse-grained quantization is more powerful than lower bits (e.g., 4 bits) with very fine-grained quantization (whose effective bits is similar to 5-bits). We also present recommendations about how to utilize quantization for \llms with different sizes, and leave suggestions of future opportunities and system work that are not res
    
[^103]: GOATS：目标采样自适应课程强化学习用于舀取任务

    GOATS: Goal Sampling Adaptation for Scooping with Curriculum Reinforcement Learning. (arXiv:2303.05193v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2303.05193](http://arxiv.org/abs/2303.05193)

    本文提出了一种名为GOATS的方法，使用目标采样自适应课程强化学习技术，通过插值位置目标和数量目标的分布创建学习过程中的课程来解决机器人舀取任务中的位置目标和水量目标问题，取得了比基线更好的表现。

    

    本文首先使用目标条件强化学习对机器人舀取水的问题进行了阐述。由于流体的复杂动力学和实现多模式目标的需求，该任务具有特别的挑战性。政策需要成功地达到位置目标和水量目标，这导致一个庞大而复杂的目标状态空间。为了克服这些挑战，我们引入了GOATS，一种课程强化学习方法，通过插值位置目标分布和数量目标分布来创建学习过程中的课程，使用目标分解奖励公式，学习一个高效且具有通用性的机器人舀取策略。结果，我们的方法可以在仿真中表现出比基线更好的性能，分别在碗舀和桶舀任务中实现了5.46％和8.71％的误差，涵盖了1000种初始水状态的变化。

    In this work, we first formulate the problem of robotic water scooping using goal-conditioned reinforcement learning. This task is particularly challenging due to the complex dynamics of fluid and the need to achieve multi-modal goals. The policy is required to successfully reach both position goals and water amount goals, which leads to a large convoluted goal state space. To overcome these challenges, we introduce Goal Sampling Adaptation for Scooping (GOATS), a curriculum reinforcement learning method that can learn an effective and generalizable policy for robot scooping tasks. Specifically, we use a goal-factorized reward formulation and interpolate position goal distributions and amount goal distributions to create curriculum throughout the learning process. As a result, our proposed method can outperform the baselines in simulation and achieves 5.46% and 8.71% amount errors on bowl scooping and bucket scooping tasks, respectively, under 1000 variations of initial water states in
    
[^104]: 基于幻想对抗控制的保守离线策略评估

    Hallucinated Adversarial Control for Conservative Offline Policy Evaluation. (arXiv:2303.01076v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.01076](http://arxiv.org/abs/2303.01076)

    本文提出了基于幻想对抗控制的HAMBO算法，可用于离线策略评估，并且能够得出有效的策略表现下限估计。

    

    本文研究了保守离线策略评估问题，对于给定其他代理收集的离线环境交互数据集，我们旨在获得一个关于策略性能的(紧)下限估计。这在决定是否部署某个策略满足最小性能/安全标准之前至关重要。为此，我们引入了HAMBO，它建立在一个学习到的传递动态的不确定性感知模型之上。为了形成策略绩效的保守估计，HAMBO会幻想策略可能采取的最坏轨迹，且该轨迹在模型的认知置信区间内。我们证明了结果的COPE估计是有效的下限，并在正则性条件下展示其收敛于真实的预期回报。最后，我们讨论了基于Bayesian神经网络的可扩展变体，并在实验中证明它们产生可靠且紧密的下限。

    We study the problem of conservative off-policy evaluation (COPE) where given an offline dataset of environment interactions, collected by other agents, we seek to obtain a (tight) lower bound on a policy's performance. This is crucial when deciding whether a given policy satisfies certain minimal performance/safety criteria before it can be deployed in the real world. To this end, we introduce HAMBO, which builds on an uncertainty-aware learned model of the transition dynamics. To form a conservative estimate of the policy's performance, HAMBO hallucinates worst-case trajectories that the policy may take, within the margin of the models' epistemic confidence regions. We prove that the resulting COPE estimates are valid lower bounds, and, under regularity conditions, show their convergence to the true expected return. Finally, we discuss scalable variants of our approach based on Bayesian Neural Networks and empirically demonstrate that they yield reliable and tight lower bounds in var
    
[^105]: 关于在服务器端进行分割学习后门攻击的可行性研究

    On Feasibility of Server-side Backdoor Attacks on Split Learning. (arXiv:2302.09578v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2302.09578](http://arxiv.org/abs/2302.09578)

    本文研究了在服务器端进行分割学习后门攻击的可行性，提供了两种攻击方法，并证明其即使在多个客户端参与学习且具有不同的数据分布时也是有效的。

    

    分割学习是一种协作学习设计，允许多个参与者（客户端）训练共享模型同时保持其数据集私有。最近的研究表明，协作学习模型，特别是联邦学习，容易受到安全和隐私攻击，例如模型推断和后门攻击。后门攻击是一种毒化攻击，攻击者试图通过操纵模型的训练过程来控制模型输出。虽然已经有了关于分割学习推断攻击的研究，但还没有进行过后门攻击的测试。本文对分割学习进行了一种新颖的后门攻击，并研究了其有效性。尽管传统的后门攻击是在客户端上完成的，但我们从服务器端注入后门触发器。为此，我们提供了两种攻击方法：一种是使用代理客户端，另一种是使用自编码器通过传入的破碎数据及其传出的梯度毒化模型。我们的实验结果表明，即使有多个客户端参与学习且具有不同的数据分布，这两种方法都非常有效。这项工作强调了进一步研究在服务器端进行分割学习后门攻击的必要性。

    Split learning is a collaborative learning design that allows several participants (clients) to train a shared model while keeping their datasets private. Recent studies demonstrate that collaborative learning models, specifically federated learning, are vulnerable to security and privacy attacks such as model inference and backdoor attacks. Backdoor attacks are a group of poisoning attacks in which the attacker tries to control the model output by manipulating the model's training process. While there have been studies regarding inference attacks on split learning, it has not yet been tested for backdoor attacks. This paper performs a novel backdoor attack on split learning and studies its effectiveness. Despite traditional backdoor attacks done on the client side, we inject the backdoor trigger from the server side. For this purpose, we provide two attack methods: one using a surrogate client and another using an autoencoder to poison the model via incoming smashed data and its outgo
    
[^106]: 面向对抗生成模型的PAC-Bayesian泛化界

    PAC-Bayesian Generalization Bounds for Adversarial Generative Models. (arXiv:2302.08942v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.08942](http://arxiv.org/abs/2302.08942)

    将PAC-Bayesian理论扩展到生成模型，为基于Wasserstein距离和总变差距离的模型提供了泛化界，为Wasserstein GAN和Energy-Based GAN提供了新的训练目标，并在合成数据集上展示出非虚空泛化界。

    

    我们将PAC-Bayesian理论扩展到生成模型，并为基于Wasserstein距离和总变差距离的模型开发了泛化界。我们第一个关于Wasserstein距离的结果假设实例空间是有界的，而我们的第二个结果利用了降维的优势。我们的结果自然适用于Wasserstein GAN和Energy-Based GAN，而我们的界限为这两种GAN提供了新的训练目标。尽管我们的工作主要是理论性的，但我们进行了数值实验，展示了Wasserstein GAN在合成数据集上的非虚空泛化界。

    We extend PAC-Bayesian theory to generative models and develop generalization bounds for models based on the Wasserstein distance and the total variation distance. Our first result on the Wasserstein distance assumes the instance space is bounded, while our second result takes advantage of dimensionality reduction. Our results naturally apply to Wasserstein GANs and Energy-Based GANs, and our bounds provide new training objectives for these two. Although our work is mainly theoretical, we perform numerical experiments showing non-vacuous generalization bounds for Wasserstein GANs on synthetic datasets.
    
[^107]: SyreaNet:一种物理引导下的水下图像增强框架，集成合成和真实图像

    SyreaNet: A Physically Guided Underwater Image Enhancement Framework Integrating Synthetic and Real Images. (arXiv:2302.08269v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.08269](http://arxiv.org/abs/2302.08269)

    提出了一种名为SyreaNet的水下图像增强框架，通过集成合成和真实数据以及物理引导和新颖的域自适应策略，能够更好地处理各种水下条件，达到了较好的提升效果。

    

    水下图像增强（UIE）对于水下高级视觉相关任务至关重要。虽然基于学习的UIE方法在近年来取得了显著的成果，但它们仍然难以应对各种不同的水下条件，这可能是由以下原因引起的: 1) UIE中使用的简化大气图像形成模型可能会导致严重的误差。2) 只使用合成图像训练的网络可能难以很好地推广到真实的水下图像。本文首次提出了一种框架SyreaNet，以修订后的水下图像形成模型和新颖的域自适应（DA）策略为指导，集成了合成和真实数据的UIE方法。首先，提出了基于修订模型的水下图像合成模块。然后设计了一种物理引导的分解网络，通过结合合成水下图像和真实水下图像来预测清晰的图像。进一步采用内部和跨域适应技术来提高网络的推广能力。在各种水下数据集上的实验结果证明了我们提出的方法的有效性。

    Underwater image enhancement (UIE) is vital for high-level vision-related underwater tasks. Although learning-based UIE methods have made remarkable achievements in recent years, it's still challenging for them to consistently deal with various underwater conditions, which could be caused by: 1) the use of the simplified atmospheric image formation model in UIE may result in severe errors; 2) the network trained solely with synthetic images might have difficulty in generalizing well to real underwater images. In this work, we, for the first time, propose a framework \textit{SyreaNet} for UIE that integrates both synthetic and real data under the guidance of the revised underwater image formation model and novel domain adaptation (DA) strategies. First, an underwater image synthesis module based on the revised model is proposed. Then, a physically guided disentangled network is designed to predict the clear images by combining both synthetic and real underwater images. The intra- and in
    
[^108]: 利用扩散模型进行有效的数据增强

    Effective Data Augmentation With Diffusion Models. (arXiv:2302.07944v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.07944](http://arxiv.org/abs/2302.07944)

    本文提出了一种利用预训练文本至图像扩散模型参数化的图像到图像转换方法，用于解决数据增强的多样性不足问题，并能够泛化到新视觉概念，从而提高了少样本图像分类和图像识别的性能。

    

    数据增强是深度学习中最常见的工具之一，支撑着最近包括分类、生成模型和表示学习在内的许多进展。然而，当前的增强方法在数据的关键语义轴上缺乏多样性，缺乏改变高级语义属性（如场景中的动物种类）以增强数据多样性的方法。本文提出了一种利用预训练文本至图像扩散模型参数化的图像到图像转换来解决数据增强多样性不足问题的方法。我们的方法利用现成的扩散模型编辑图像，改变它们的语义，能够泛化到仅用少量标记示例得到的新视觉概念。我们在少样本图像分类任务和真实世界的杂草识别任务中评估了我们的方法，并观察到......

    Data augmentation is one of the most prevalent tools in deep learning, underpinning many recent advances, including those from classification, generative models, and representation learning. The standard approach to data augmentation combines simple transformations like rotations and flips to generate new images from existing ones. However, these new images lack diversity along key semantic axes present in the data. Current augmentations cannot alter the high-level semantic attributes, such as animal species present in a scene, to enhance the diversity of data. We address the lack of diversity in data augmentation with image-to-image transformations parameterized by pre-trained text-to-image diffusion models. Our method edits images to change their semantics using an off-the-shelf diffusion model, and generalizes to novel visual concepts from a few labelled examples. We evaluate our approach on few-shot image classification tasks, and on a real-world weed recognition task, and observe 
    
[^109]: 没有地基的真相：人工智能决策中代理标签的因果框架

    Ground(less) Truth: A Causal Framework for Proxy Labels in Human-Algorithm Decision-Making. (arXiv:2302.06503v4 [cs.CY] UPDATED)

    [http://arxiv.org/abs/2302.06503](http://arxiv.org/abs/2302.06503)

    本文提出了一个因果框架，解释了在人工智能决策中使用的代理标签可能存在的目标变量偏差，并提出未来研究应强调针对较广泛问题的因果评估。

    

    越来越多关于人工智能决策的文献调查将人类判断与统计模型相结合以改善决策质量。该领域的研究通常通过展示对“地基”标签的预测性能来评估所提出的改进模型、接口或工作流程的有效性。然而，这种做法忽略了人类判断与模型预测之间的一个关键差异。而预测模型则仅针对可在现有数据集中轻松获取的代理标签。预测模型依赖于简单代理标签，因此容易受到各种统计偏差的影响。本文识别了人工智能决策中可能影响代理标签有效性的五种目标变量偏差来源。我们提出一个因果框架来理解这些偏差来源及其对决策质量带来的风险。我们认为仅根据地基标签来评估决策支持系统可能会产生误导性，同时建议未来的工作强调针对较广泛的问题感兴趣的因果评估候选方法。

    A growing literature on human-AI decision-making investigates strategies for combining human judgment with statistical models to improve decision-making. Research in this area often evaluates proposed improvements to models, interfaces, or workflows by demonstrating improved predictive performance on "ground truth" labels. However, this practice overlooks a key difference between human judgments and model predictions. Whereas humans reason about broader phenomena of interest in a decision -- including latent constructs that are not directly observable, such as disease status, the "toxicity" of online comments, or future "job performance" -- predictive models target proxy labels that are readily available in existing datasets. Predictive models' reliance on simplistic proxies makes them vulnerable to various sources of statistical bias. In this paper, we identify five sources of target variable bias that can impact the validity of proxy labels in human-AI decision-making tasks. We devel
    
[^110]: 一般几何上的黎曼流匹配

    Riemannian Flow Matching on General Geometries. (arXiv:2302.03660v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.03660](http://arxiv.org/abs/2302.03660)

    本文提出了一种名为黎曼流匹配的方法，可以在一般几何上训练连续标准化流，并在高维度数据上具有优势。

    

    我们提出了一种名为黎曼流匹配（RFM）的框架，用于在流形上训练连续标准化流。现有的流形生成建模方法要么需要昂贵的模拟，要么无法本质上扩展到高维度，要么使用限制量的近似来产生有偏的训练目标。黎曼流匹配绕过了这些限制，并提供了比以前方法更多的优势：它在简单几何上无需模拟，不需要散度计算，并以闭合形式计算其目标向量场。 RFM的关键因素是构建一个相对简单的前度量，以定义目标向量场，其中包括现有的欧几里得情况。为了扩展到一般几何，我们依靠使用谱分解来有效地即兴计算前度量。我们的方法在现实世界的非欧几里得数据集上实现了最先进的性能，并通过在3D网格和双曲空间上训练标准化流来证明其功效。

    We propose Riemannian Flow Matching (RFM), a simple yet powerful framework for training continuous normalizing flows on manifolds. Existing methods for generative modeling on manifolds either require expensive simulation, are inherently unable to scale to high dimensions, or use approximations for limiting quantities that result in biased training objectives. Riemannian Flow Matching bypasses these limitations and offers several advantages over previous approaches: it is simulation-free on simple geometries, does not require divergence computation, and computes its target vector field in closed-form. The key ingredient behind RFM is the construction of a relatively simple premetric for defining target vector fields, which encompasses the existing Euclidean case. To extend to general geometries, we rely on the use of spectral decompositions to efficiently compute premetrics on the fly. Our method achieves state-of-the-art performance on real-world non-Euclidean datasets, and we demonstr
    
[^111]: 蒸馏策略优化

    Distillation Policy Optimization. (arXiv:2302.00533v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.00533](http://arxiv.org/abs/2302.00533)

    本文展示了一种演员-评论家的学习框架，该框架通过蒸馏优势在利用过去经验的同时遵循稳定的在线策略，实现了快速学习并可以适用于广泛的算法类别。

    

    本文提出了一个演员-评论家学习框架，它借鉴了分布式学习的视角和两种策略改进数据的交叉融合，实现了快速学习并可应用于广泛的算法类别。在该框架中，首先提出了方差减少机制，例如统一优势估计器 (UAE) 和一个学习的基线，不仅是连接到动作值函数的桥梁，还能提炼优势。

    On-policy algorithms are supposed to be stable, however, sample-intensive yet. Off-policy algorithms utilizing past experiences are deemed to be sample-efficient, nevertheless, unstable in general. Can we design an algorithm that can employ the off-policy data, while exploit the stable learning by sailing along the course of the on-policy walkway? In this paper, we present an actor-critic learning framework that borrows the distributional perspective of interest to evaluate, and cross-breeds two sources of the data for policy improvement, which enables fast learning and can be applied to a wide class of algorithms. In its backbone, the variance reduction mechanisms, such as unified advantage estimator (UAE), that extends generalized advantage estimator (GAE) to be applicable on any state-dependent baseline, and a learned baseline, that is competent to stabilize the policy gradient, are firstly put forward to not merely be a bridge to the action-value function but also distill the advan
    
[^112]: 将语言模型与图像进行联系以处理多模态信息

    Grounding Language Models to Images for Multimodal Inputs and Outputs. (arXiv:2301.13823v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.13823](http://arxiv.org/abs/2301.13823)

    该论文提出一种有效的方法，将仅处理文本的语言模型与图像进行联系，使其能够处理任意交错的图像和文本数据，并生成与检索图像交错的自由形式文本。该方法在环境相关的图像检索和多模态对话等任务中表现十分优异，是利用预训练语言模型解决视觉场景下交互问题的有效解决方案。

    

    我们提出了一种有效的方法，将预训练的仅文本语言模型与视觉领域联系起来，使其能够处理任意交错的图像和文本数据，并生成与检索图像交错的文本。我们利用从大规模文本预训练中学到的语言模型的能力，例如上下文学习和自由形式文本生成。我们保持语言模型冻结，并微调输入和输出线性层以实现跨模态交互。这使得我们的模型能够处理任意交错的图像和文本输入，并生成与检索图像交错的自由形式文本。我们在环境相关的图像检索和多模态对话等任务中取得了强大的零-shot表现，并展示了引人入胜的交互能力。我们的方法适用于任何现成的语言模型，为在视觉场景下利用预训练语言模型提供了一个有效且通用的解决方案。

    We propose an efficient method to ground pretrained text-only language models to the visual domain, enabling them to process arbitrarily interleaved image-and-text data, and generate text interleaved with retrieved images. Our method leverages the abilities of language models learnt from large scale text-only pretraining, such as in-context learning and free-form text generation. We keep the language model frozen, and finetune input and output linear layers to enable cross-modality interactions. This allows our model to process arbitrarily interleaved image-and-text inputs, and generate free-form text interleaved with retrieved images. We achieve strong zero-shot performance on grounded tasks such as contextual image retrieval and multimodal dialogue, and showcase compelling interactive abilities. Our approach works with any off-the-shelf language model and paves the way towards an effective, general solution for leveraging pretrained language models in visually grounded settings.
    
[^113]: 《联邦学习是否真正需要反向传播？》

    Does Federated Learning Really Need Backpropagation?. (arXiv:2301.12195v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.12195](http://arxiv.org/abs/2301.12195)

    本文提出一种不需要反向传播的联邦学习框架BAFFLE，该框架使用多个正向过程估计梯度，具有高内存效率，容易适应上传带宽，与硬件优化和模型量化/修剪兼容，适用于受信任的执行环境。

    

    联邦学习（FL）是一种去中心化地让客户端共同训练一个服务器模型的一般性原则，而无需共享本地数据。FL是一个具有实际应用的有前途的框架，但其标准训练范式要求客户端通过模型进行反向传播以计算梯度。由于这些客户端通常是边缘设备而不是完全受信任的，因此在它们上执行反向传播会产生计算和存储开销以及白盒漏洞。因此，我们开发了一种不需要反向传播的联邦学习，称为BAFFLE，其中反向传播替换为多个正向过程以估计梯度。BAFFLE具有以下优点：1）内存效率高并且容易适应上传带宽；2）与仅推理硬件优化以及模型量化或修剪兼容；3）非常适合受信任的执行环境，因为BAFFLE中的客户端仅执行正向传播并返回一组标量到服务器。我们通过实验使用了BAFFLE的优越性能。

    Federated learning (FL) is a general principle for decentralized clients to train a server model collectively without sharing local data. FL is a promising framework with practical applications, but its standard training paradigm requires the clients to backpropagate through the model to compute gradients. Since these clients are typically edge devices and not fully trusted, executing backpropagation on them incurs computational and storage overhead as well as white-box vulnerability. In light of this, we develop backpropagation-free federated learning, dubbed BAFFLE, in which backpropagation is replaced by multiple forward processes to estimate gradients. BAFFLE is 1) memory-efficient and easily fits uploading bandwidth; 2) compatible with inference-only hardware optimization and model quantization or pruning; and 3) well-suited to trusted execution environments, because the clients in BAFFLE only execute forward propagation and return a set of scalars to the server. Empirically we us
    
[^114]: S-Graphs+：利用分层表示进行实时定位和建图

    S-Graphs+: Real-time Localization and Mapping leveraging Hierarchical Representations. (arXiv:2212.11770v3 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2212.11770](http://arxiv.org/abs/2212.11770)

    S-Graphs+是一种新型的四层因子图，能够在实时优化中同时建模姿态图和场景图，提高了环境信息的高层次抽象，并提出了新的分割方法来提取环境的房间和楼层信息。

    

    本文介绍了一种进化版Situational Graphs，其通过在单一优化因子图中同时建模姿态图和三维场景图，从而对环境进行高层次建模和压缩，并实时优化以获得机器人姿态的鲁棒和精确估计。为了提高场景的抽象级别，我们提出了新的房间和楼层分割方法，并将其应用于四层因子图中。

    In this paper, we present an evolved version of Situational Graphs, which jointly models in a single optimizable factor graph (1) a pose graph, as a set of robot keyframes comprising associated measurements and robot poses, and (2) a 3D scene graph, as a high-level representation of the environment that encodes its different geometric elements with semantic attributes and the relational information between them.  Specifically, our S-Graphs+ is a novel four-layered factor graph that includes: (1) a keyframes layer with robot pose estimates, (2) a walls layer representing wall surfaces, (3) a rooms layer encompassing sets of wall planes, and (4) a floors layer gathering the rooms within a given floor level. The above graph is optimized in real-time to obtain a robust and accurate estimate of the robots pose and its map, simultaneously constructing and leveraging high-level information of the environment. To extract this high-level information, we present novel room and floor segmentation
    
[^115]: 自我指导: 用自生成的指示对齐语言模型

    Self-Instruct: Aligning Language Models with Self-Generated Instructions. (arXiv:2212.10560v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10560](http://arxiv.org/abs/2212.10560)

    本论文提出了一种名为Self-Instruct的框架，通过自身生成指导信息来提高预训练语言模型的指令遵循能力。在超自然指令上，我们展示了与InstructGPT-001相同的性能表现，并在原始模型上获得了33%的改进。

    

    大型的"指令调整"语言模型(即，调整为响应指令)已经展示了惊人的能力，可以零-shot推广到新任务。然而，它们严重依赖于人工编写的指令数据，通常在数量、多样性和创造力方面受到限制，从而阻碍了调整模型的通用性。我们引入了Self-Instruct，这是一个用于改善预训练语言模型遵循指令能力的框架，通过自身的生成来引导它们。我们的工作流程从语言模型中生成指令、输入和输出样本，然后过滤掉无效或相似的样本，然后再将它们用于调整原始模型。将我们的方法应用于普通的GPT3，我们展示了在超自然指令上与InstructGPT-001的性能相媲美，并比原始模型获得了33%的绝对改进。

    Large "instruction-tuned" language models (i.e., finetuned to respond to instructions) have demonstrated a remarkable ability to generalize zero-shot to new tasks. Nevertheless, they depend heavily on human-written instruction data that is often limited in quantity, diversity, and creativity, therefore hindering the generality of the tuned model. We introduce Self-Instruct, a framework for improving the instruction-following capabilities of pretrained language models by bootstrapping off their own generations. Our pipeline generates instructions, input, and output samples from a language model, then filters invalid or similar ones before using them to finetune the original model. Applying our method to the vanilla GPT3, we demonstrate a 33% absolute improvement over the original model on Super-NaturalInstructions, on par with the performance of InstructGPT-001, which was trained with private user data and human annotations. For further evaluation, we curate a set of expert-written inst
    
[^116]: 大型语言模型中的推理研究综述

    Towards Reasoning in Large Language Models: A Survey. (arXiv:2212.10403v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10403](http://arxiv.org/abs/2212.10403)

    本文综述了大型语言模型中的推理研究的现状和未来方向，包括提高和诱导推理能力的技术、评估推理能力的方法和基准，旨在提供一个详细和最新的综述，刺激有意义的讨论和未来的研究。

    

    推理是人类智能的基本方面，在问题解决、决策和批判性思维等活动中发挥着关键作用。近年来，大型语言模型（LLMs）在自然语言处理方面取得了显著的进展，观察到当这些模型足够大时，它们可能会展现出推理能力。然而，目前尚不清楚LLMs在推理方面的能力到底如何。本文全面阐述了LLMs中推理研究的当前状况，包括提高和诱导这些模型推理的技术、评估推理能力的方法和基准、以及以往研究的结果和意义，同时提出了未来方向的建议。我们的目的是提供一个详细和最新的综述，刺激有意义的讨论和未来的研究。

    Reasoning is a fundamental aspect of human intelligence that plays a crucial role in activities such as problem solving, decision making, and critical thinking. In recent years, large language models (LLMs) have made significant progress in natural language processing, and there is observation that these models may exhibit reasoning abilities when they are sufficiently large. However, it is not yet clear to what extent LLMs are capable of reasoning. This paper provides a comprehensive overview of the current state of knowledge on reasoning in LLMs, including techniques for improving and eliciting reasoning in these models, methods and benchmarks for evaluating reasoning abilities, findings and implications of previous research in this field, and suggestions on future directions. Our aim is to provide a detailed and up-to-date review of this topic and stimulate meaningful discussion and future work.
    
[^117]: 语言模型在处理量词时表现略有问题？使用少量类型的量词会导致语言模型的预测呈现反比例缩放的现象。

    Rarely a problem? Language models exhibit inverse scaling in their predictions following few-type quantifiers. (arXiv:2212.08700v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.08700](http://arxiv.org/abs/2212.08700)

    本文研究了语言模型处理“few-”类型量词的能力，结果显示所有模型对这种量词都表现不佳，且较大的模型表现更差。这种反比例缩放的现象表明大型模型越来愈反映在线人类处理，而不是离线处理。这可能挑战使用语言模型作为自然语言系统基础的做法。

    

    本研究探讨了语言模型如何处理量化问题。我们以“few-”类型的量词为重点，比如“few children like toys”，因为这种类型的句子组成部分通常会共现，而“few-”类型的量词较为罕见，这可能对语言模型构成特别挑战。我们对来自两项人类神经语言学实验的960个英语句子进行了试验，并将它们提供给22个不同大小的自回归变换器模型。不仅所有模型对“few-”类型的量词都表现不佳，而且总体上，模型越大，其表现越差。这种反比例缩放的现象与之前的研究结果一致，表明较大的模型越来越反映在线人类处理，而不是离线处理。我们认为，更大的模型的性能下降可能会挑战将语言模型作为自然语言系统基础的做法。

    How well do language models deal with quantification? In this study, we focus on 'few'-type quantifiers, as in 'few children like toys', which might pose a particular challenge for language models because the sentence components with out the quantifier are likely to co-occur, and 'few'-type quantifiers are rare. We present 960 English sentence stimuli from two human neurolinguistic experiments to 22 autoregressive transformer models of differing sizes. Not only do all the models perform poorly on 'few'-type quantifiers, but overall the larger the model, the worse its performance. This inverse scaling is consistent with previous work suggesting that larger models increasingly reflect online rather than offline human processing, and we argue that the decreasing performance of larger models may challenge uses of language models as the basis for natural language systems.
    
[^118]: 基于任务相似度元学习加速多目标非分层超参数最优化的树形结构Parzen估计

    Speeding up Multi-objective Non-hierarchical Hyperparameter Optimization by Task Similarity-Based Meta-Learning for the Tree-structured Parzen Estimator. (arXiv:2212.06751v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.06751](http://arxiv.org/abs/2212.06751)

    本文提出了一种基于任务相似度元学习的方法来加速树形结构Parzen估计中的多目标非分层超参数最优化，实现了最先进的性能。

    

    超参数优化是提高深度学习性能的关键步骤。实践者通常面临多个方面的权衡，如准确性和延迟时间。在深度学习的高计算需求和对高效超参数优化的不断增长需求下，加速多目标优化变得越来越重要。本文将TPE的收购函数扩展到元学习设置中，使用由任务之间顶级域之间的重叠度定义的任务相似性。我们也从理论上分析并解决了任务相似性的局限性。在实验中，我们展示了我们的方法在表格HPO基准上加速了MO-TPE，并获得了最先进的性能。我们的方法还通过赢得AutoML 2022来得到外部验证。

    Hyperparameter optimization (HPO) is a vital step in improving performance in deep learning (DL). Practitioners are often faced with the trade-off between multiple criteria, such as accuracy and latency. Given the high computational needs of DL and the growing demand for efficient HPO, the acceleration of multi-objective (MO) optimization becomes ever more important. Despite the significant body of work on meta-learning for HPO, existing methods are inapplicable to MO tree-structured Parzen estimator (MO-TPE), a simple yet powerful MO-HPO algorithm. In this paper, we extend TPE's acquisition function to the meta-learning setting using a task similarity defined by the overlap of top domains between tasks. We also theoretically analyze and address the limitations of our task similarity. In the experiments, we demonstrate that our method speeds up MO-TPE on tabular HPO benchmarks and attains state-of-the-art performance. Our method was also validated externally by winning the AutoML 2022 
    
[^119]: 非参数遮蔽语言建模

    Nonparametric Masked Language Modeling. (arXiv:2212.01349v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.01349](http://arxiv.org/abs/2212.01349)

    NPM是第一个使用非参数分布替换softmax的遮蔽语言模型，可以更好地处理稀有模式和预测罕见或几乎未见过的单词，并在16项任务上超过了更大的参数模型。

    

    现有的语言模型（LM）通过有限词汇表上的 softmax 来预测标记，这可能使得预测稀有标记或短语变得困难。我们介绍了 NPM，它是第一个使用对每个参考语料库中短语的非参数分布替换此 softmax 的非参数遮蔽语言模型。NPM 仅通过从文本语料库中检索标记来填写 [MASK]。我们展示了 NPM 可以通过对比性目标和批量近似全语料库检索有效地训练。对 16 项任务进行零样本评估，包括分类、事实探针和问题回答，证明 NPM 超过了显着更大的参数模型，无论使用或不使用检索生成方法，它在处理稀有模式（词义或事实）和预测罕见或几乎未见过的单词（如非拉丁文脚本）方面表现出更好的性能。我们在 github.com/facebookresearch/NPM 上发布了模型和代码。

    Existing language models (LMs) predict tokens with a softmax over a finite vocabulary, which can make it difficult to predict rare tokens or phrases. We introduce NPM, the first nonparametric masked language model that replaces this softmax with a nonparametric distribution over every phrase in a reference corpus. NPM fills in the [MASK] solely from retrieving a token from a text corpus. We show that NPM can be efficiently trained with a contrastive objective and an in-batch approximation to full corpus retrieval. Zero-shot evaluation on 16 tasks including classification, fact probing and question answering demonstrates that NPM outperforms significantly larger parametric models, either with or without a retrieve-and-generate approach. It is particularly better at dealing with rare patterns (word senses or facts) and predicting rare or nearly unseen words (e.g., non-Latin script). We release the model and code at github.com/facebookresearch/NPM.
    
[^120]: 用于生成语言的软对齐目标的鲁棒适应

    Soft Alignment Objectives for Robust Adaptation of Language Generation. (arXiv:2211.16550v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.16550](http://arxiv.org/abs/2211.16550)

    本研究提出了一种基于预测令牌与参考语义相似性的新型训练目标，可以在领域自适应中缓解灾难性遗忘，同时又可以保持调整质量，并且计算成本增加可忽略不计。

    

    领域自适应允许生成语言模型解决应用领域转移造成的特定缺陷。然而，通过在领域内数据上进行进一步训练来进行传统适应会迅速削弱模型推广到其他领域的能力，使得调整后模型的无限部署容易出现错误。本工作介绍了建立在预测令牌与参考语义相似性的新型训练目标。我们的结果表明，避免单个正确预测的常见假设，通过构建来自令牌语义相似性的训练目标可以缓解领域适应期间的灾难性遗忘，同时在保持调整质量方面具有可忽略的计算成本增加。在更广泛的背景下，基于连续的令牌相似度的目标引领了高效但显式令牌级目标和具有表现力的基于连续令牌表示的目标之间中间地带的探索。

    Domain adaptation allows generative language models to address specific flaws caused by the domain shift of their application. However, the traditional adaptation by further training on in-domain data rapidly weakens the model's ability to generalize to other domains, making the open-ended deployments of the adapted models prone to errors. This work introduces novel training objectives built upon a semantic similarity of the predicted tokens to the reference.  Our results show that (1) avoiding the common assumption of a single correct prediction by constructing the training target from tokens' semantic similarity can mitigate catastrophic forgetting during domain adaptation, while (2) preserving the quality of the adaptation, (3) with negligible additions to compute costs.  In the broader context, the objectives grounded in a continuous token similarity pioneer the exploration of the middle ground between the efficient but na\"{\i}ve exact-match token-level objectives and expressive b
    
[^121]: c-TPE:基于树形结构的带不等式约束的帕捷斯特估计器用于昂贵超参数优化

    c-TPE: Tree-structured Parzen Estimator with Inequality Constraints for Expensive Hyperparameter Optimization. (arXiv:2211.14411v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.14411](http://arxiv.org/abs/2211.14411)

    本文提出了约束TPE（c-TPE）方法，是树形Parzen估计器（TPE）的扩展，可有效处理在性能要求之上施加的约束限制，实验证明在81个昂贵的HPO设置中表现出最佳性能排名。

    

    超参数优化（HPO）对于深度学习算法的强大性能至关重要，实际应用通常会在性能要求之上施加一些限制，例如内存使用或延迟等。在本文中，我们提出了约束TPE（c-TPE），这是广泛使用的多功能贝叶斯优化方法——树形Parzen估计器（TPE）的扩展，以处理这些约束。我们提出的扩展不仅是简单地将现有收益函数和原始TPE组合起来，而是包括修改来解决导致性能不佳的问题。我们从经验和理论上深入分析这些修改，提供了有关它们如何有效地克服这些挑战的见解。在实验中，我们证明了c-TPE在81个昂贵的HPO设置中表现出最佳的平均排名性能，具有统计显着性。

    Hyperparameter optimization (HPO) is crucial for strong performance of deep learning algorithms and real-world applications often impose some constraints, such as memory usage, or latency on top of the performance requirement. In this work, we propose constrained TPE (c-TPE), an extension of the widely-used versatile Bayesian optimization method, tree-structured Parzen estimator (TPE), to handle these constraints. Our proposed extension goes beyond a simple combination of an existing acquisition function and the original TPE, and instead includes modifications that address issues that cause poor performance. We thoroughly analyze these modifications both empirically and theoretically, providing insights into how they effectively overcome these challenges. In the experiments, we demonstrate that c-TPE exhibits the best average rank performance among existing methods with statistical significance on 81 expensive HPO settings.
    
[^122]: 通过Monte Carlo Forest Search实现UNSAT求解器的合成

    UNSAT Solver Synthesis via Monte Carlo Forest Search. (arXiv:2211.12581v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2211.12581](http://arxiv.org/abs/2211.12581)

    介绍了使用MCFS算法合成UNSAT求解器的方法，算法可用于解决包括SAT公式不可满足性证明、可满足SAT公式解的数量计数和混合整数规划的最优解问题，并利用合成森林构建算法和合成MDP类来避免构建候选树森林的问题。

    

    我们介绍了Monte Carlo Forest Search（MCFS），一类用于学习决策树MDP策略的强化学习（RL）算法。这些问题的示例包括证明SAT公式的不可满足性；计算可满足的SAT公式的解的数量；以及找到混合整数规划的最优解。MCFS算法可以看作是Monte Carlo Tree Search（MCTS）的扩展，用于在候选树的森林中寻找一个小树，而不是在树中找到一个好路径（解决方案）。我们在算法中实例化和评估了自己的想法，称之为Knuth Synthesis，这是一个MCFS算法，用于学习DPLL分支策略来解决布尔可满足性（SAT）问题。这利用了两个关键思想，以避免构建候选树森林的问题：（1）一种合成森林构建算法，通过从池中随机选择“好”的树并将它们组合成更大的森林来逐步构建森林；（2）一种合成MDP类，用作真实树MDP的代理，我们可以轻松计算节点间转换的概率。

    We introduce Monte Carlo Forest Search (MCFS), a class of reinforcement learning (RL) algorithms for learning policies in {tree MDPs}, for which policy execution involves traversing an exponential-sized tree. Examples of such problems include proving unsatisfiability of a SAT formula; counting the number of solutions of a satisfiable SAT formula; and finding the optimal solution to a mixed-integer program. MCFS algorithms can be seen as extensions of Monte Carlo Tree Search (MCTS) to cases where, rather than finding a good path (solution) within a tree, the problem is to find a small tree within a forest of candidate trees. We instantiate and evaluate our ideas in an algorithm that we dub Knuth Synthesis, an MCFS algorithm that learns DPLL branching policies for solving the Boolean satisfiability (SAT) problem, with the objective of achieving good average-case performance on a given distribution of unsatisfiable problem instances. Knuth Synthesis leverages two key ideas to avoid the pr
    
[^123]: 多视角压缩表示的鲁棒性低资源微调研究

    Towards Robust Low-Resource Fine-Tuning with Multi-View Compressed Representations. (arXiv:2211.08794v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.08794](http://arxiv.org/abs/2211.08794)

    本文提出了一种利用多视角压缩表示降低预训练语言模型微调过程中过拟合问题的方法，经过测试在低资源NLP任务中表现良好。

    

    由于参数的巨大数量，预训练语言模型（PLMs）的微调容易在低资源场景中出现过度拟合的问题。本文提出了一种新方法，该方法在PLM的隐藏表示上操作，以减少过拟合。在微调过程中，我们的方法在PLM的隐藏层之间插入随机自编码器，将来自前一层的激活转换为多视角压缩表示，然后将其馈送到上层。微调结束后，自编码器会被移除掉，因此我们的方法在推理过程中不会增加额外的参数或计算成本。我们的方法在一系列序列和标记级别的低资源NLP任务中展现了出色的性能提升。

    Due to the huge amount of parameters, fine-tuning of pretrained language models (PLMs) is prone to overfitting in the low resource scenarios. In this work, we present a novel method that operates on the hidden representations of a PLM to reduce overfitting. During fine-tuning, our method inserts random autoencoders between the hidden layers of a PLM, which transform activations from the previous layers into a multi-view compressed representation before feeding it into the upper layers. The autoencoders are plugged out after fine-tuning, so our method does not add extra parameters or increase computation cost during inference. Our method demonstrates promising performance improvement across a wide range of sequence- and token-level low-resource NLP tasks.
    
[^124]: 零偏置标量不变网络

    Scalar Invariant Networks with Zero Bias. (arXiv:2211.08486v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.08486](http://arxiv.org/abs/2211.08486)

    本文证明了在解决许多图像任务(例如图像分类)时可以忽略偏置，并且零偏置神经网络在实际图像分类任务中表现良好，同时具有标量 (乘法) 不变性，从而在改变对比度时仍能保持预测不变。

    

    与权重一样，偏置项也是许多流行的机器学习模型(包括神经网络)可学习的参数。人们认为偏差能有效地增加神经网络表示能力来解决计算机视觉中的各种任务。然而，我们认为，如果我们从第一原理考虑图像在输入空间中的内在分布以及模型应具有的一些期望特性，则偏差可以完全忽略，以解决许多与图像相关的任务，例如图像分类任务。我们的观察结果表明，零偏置神经网络在实际图像分类任务上可能与带偏置的神经网络表现相当。此外，我们证明零偏置神经网络具有称为标量(乘法)不变性的良好属性，这使得当改变输入图像的对比度时，神经网络的预测保持不变。然后，我们将标量不变性扩展到更一般的情况…

    Just like weights, bias terms are the learnable parameters of many popular machine learning models, including neural networks. Biases are believed to effectively increase the representational power of neural networks to solve a wide range of tasks in computer vision. However, we argue that if we consider the intrinsic distribution of images in the input space as well as some desired properties a model should have from the first principles, biases can be completely ignored in addressing many image-related tasks, such as image classification. Our observation indicates that zero-bias neural networks could perform comparably to neural networks with bias at least on practical image classification tasks. In addition, we prove that zero-bias neural networks possess a nice property called scalar (multiplication) invariance, which allows the prediction of neural networks remains the same when altering the contrast of the input image. We then extend scalar invariance to more general cases that a
    
[^125]: 革新空中自主技术的可扩展模块化合成数据生成

    Scalable Modular Synthetic Data Generation for Advancing Aerial Autonomy. (arXiv:2211.05335v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.05335](http://arxiv.org/abs/2211.05335)

    这篇论文探索了提高空中自主技术进步的一个重要问题：如何生成大量的空中数据集以训练机器学习模型。该研究使用合成数据并利用模拟环境和数据增强来解决现有工具的局限性，提高数据生成工作流程的可扩展性和泛化能力。

    

    推动空中自主技术进步的一个重要障碍是获取用于训练机器学习模型的大规模空中数据集。为了避免实机数据采集的高成本和耗时，越来越多的无人机应用开始使用合成数据来训练模型。然而，要想提高模型的泛化能力并将其迁移到实际环境，增加模拟环境的多样性以训练所有可能情况下的模型，以及增加训练数据进行数据增强，都是必不可少的。目前，现有的合成空中数据生成工具要么缺乏数据增强，要么依赖于手工负载或实际样本进行配置和生成多样化的真实模拟场景以进行数据采集。这些依赖性限制了数据生成工作流程的可扩展性。因此，在合成数据生成中平衡泛化能力和可扩展性是一个主要的挑战。

    One major barrier to advancing aerial autonomy has been collecting large-scale aerial datasets for training machine learning models. Due to costly and time-consuming real-world data collection through deploying drones, there has been an increasing shift towards using synthetic data for training models in drone applications. However, to increase widespread generalization and transferring models to real-world, increasing the diversity of simulation environments to train a model over all the varieties and augmenting the training data, has been proved to be essential. Current synthetic aerial data generation tools either lack data augmentation or rely heavily on manual workload or real samples for configuring and generating diverse realistic simulation scenes for data collection. These dependencies limit scalability of the data generation workflow. Accordingly, there is a major challenge in balancing generalizability and scalability in synthetic data generation. To address these gaps, we i
    
[^126]: RQUGE：一种基于回答问题评估问题生成的无参考度量方法

    RQUGE: Reference-Free Metric for Evaluating Question Generation by Answering the Question. (arXiv:2211.01482v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.01482](http://arxiv.org/abs/2211.01482)

    RQUGE是一种新的度量标准方法，通过候选问题是否可以回答来评估问题生成质量, 比现有指标更加稳健，可以在不需要人工提供参考问题的情况下使用。

    

    现有的评估自动生成问题质量的指标（如BLEU、ROUGE、BERTScore和BLEURT）将参考和预测问题进行比较，当候选问题和参考问题之间存在相当的词汇重叠或语义相似性时，提供高分。该方法存在两个主要缺点：首先，我们需要昂贵的人工提供参考问题；其次，它惩罚那些可能与参考问题没有高词汇或语义相似性的有效问题。在本文中，我们提出一种新的度量标准RQUGE，基于给定上下文的候选问题的可回答性。该度量标准由一个问答模块和一个跨度评分器模块组成，使用现有文献中的预训练模型，因此可以在不进行进一步训练的情况下使用。我们证明RQUGE与人类判断具有更高的相关性，而不依赖于参考问题。此外，RQUGE显示更加稳健。

    Existing metrics for evaluating the quality of automatically generated questions such as BLEU, ROUGE, BERTScore, and BLEURT compare the reference and predicted questions, providing a high score when there is a considerable lexical overlap or semantic similarity between the candidate and the reference questions. This approach has two major shortcomings. First, we need expensive human-provided reference questions. Second, it penalises valid questions that may not have high lexical or semantic similarity to the reference questions. In this paper, we propose a new metric, RQUGE, based on the answerability of the candidate question given the context. The metric consists of a question-answering and a span scorer modules, using pre-trained models from existing literature, thus it can be used without any further training. We demonstrate that RQUGE has a higher correlation with human judgment without relying on the reference question. Additionally, RQUGE is shown to be more robust to several ad
    
[^127]: JECC：从互动小说中推导出的常识推理任务

    JECC: Commonsense Reasoning Tasks Derived from Interactive Fictions. (arXiv:2210.15456v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.15456](http://arxiv.org/abs/2210.15456)

    本文提出了一个新的常识推理数据集JECC，基于人类互动小说游戏的演示步骤。与现有基准不同的是，该数据集评估的是功能性的常识知识规则。因此，为了在这些任务上表现良好，模型需要利用这种常识知识来推断行动的结果，而不是仅仅依赖于记忆事实。

    

    常识推理模拟了人类对我们物理世界的推断能力，是构建通用人工智能系统的基石。本文提出了一个新的常识推理数据集，基于人类互动小说游戏的步骤演示，因为人类玩家展示了丰富和多样的常识推理。该新数据集提供了各种推理类型的自然混合，并需要多跳推理。此外，IF游戏构建过程需要比以前的方法更少的人类干预。与现有的基准不同，我们的数据集侧重于评估功能性的常识知识规则，而不是事实知识。因此，为了在我们的任务上获得更高的性能，模型需要有效地利用这种功能性知识来推断行动的结果，而不是仅依靠记忆事实。实验表明，引入的数据集对于先前的机器阅读来说具有挑战性。

    Commonsense reasoning simulates the human ability to make presumptions about our physical world, and it is an essential cornerstone in building general AI systems. We propose a new commonsense reasoning dataset based on human's Interactive Fiction (IF) gameplay walkthroughs as human players demonstrate plentiful and diverse commonsense reasoning. The new dataset provides a natural mixture of various reasoning types and requires multi-hop reasoning. Moreover, the IF game-based construction procedure requires much less human interventions than previous ones. Different from existing benchmarks, our dataset focuses on the assessment of functional commonsense knowledge rules rather than factual knowledge. Hence, in order to achieve higher performance on our tasks, models need to effectively utilize such functional knowledge to infer the outcomes of actions, rather than relying solely on memorizing facts. Experiments show that the introduced dataset is challenging to previous machine reading
    
[^128]: MARLlib: 一个可扩展的多智能体强化学习库

    MARLlib: A Scalable Multi-agent Reinforcement Learning Library. (arXiv:2210.13708v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.13708](http://arxiv.org/abs/2210.13708)

    本文提出了MARLlib，这是一个全面的MARL算法库，可统一数十种算法。它还超越了当前工作，集成了各种环境接口和提供灵活的参数共享策略。

    

    尽管多智能体系统和多智能体强化学习算法得到了快速发展，但缺乏统一的评估平台和公认的基准实现。因此，迫切需要开发一个集成库套件，以在各种基准测试中提供可靠的MARL实现和可复制的评估。本文提出了MARLlib，这是一个全面的MARL算法库，用于解决多智能体问题。MARLlib通过新颖的基于代理的分布式数据流设计，在高度可组合的集成风格中统一了数十种算法。此外，MARLlib通过集成各种环境接口和提供灵活的参数共享策略，超越了当前工作；这允许最终用户在最小的代码修改下实现协作、竞争和混合任务的多种解决方案。最后，MARLlib提供易于使用的API和完全解耦合的配置。

    Despite the fast development of multi-agent systems (MAS) and multi-agent reinforcement learning (MARL) algorithms, there is a lack of unified evaluation platforms and commonly-acknowledged baseline implementation. Therefore, an urgent need is to develop an integrated library suite that delivers reliable MARL implementation and replicable evaluation in various benchmarks. To fill such a research gap, in this paper, we propose MARLlib, a comprehensive MARL algorithm library for solving multi-agent problems. With a novel design of agent-level distributed dataflow, MARLlib manages to unify tens of algorithms in a highly composable integration style. Moreover, MARLlib goes beyond current work by integrating diverse environment interfaces and providing flexible parameter sharing strategies; this allows for versatile solutions to cooperative, competitive, and mixed tasks with minimal code modifications for end users. Finally, MARLlib provides easy-to-use APIs and a fully decoupled configurat
    
[^129]: 实例感知图像修复

    Instance-Aware Image Completion. (arXiv:2210.12350v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2210.12350](http://arxiv.org/abs/2210.12350)

    本文提出了一个实例感知图像修复模型ImComplete，相比现有方法，它可以幻象出与环境背景相协调的视觉实例，提供了基于语义和结构的像素级指导。

    

    图像修复是一项旨在填补带有缺失区域的图像的任务，使它们具有合理的内容。然而，现有的图像修复方法往往通过填充周围纹理来填补缺失区域，而不是去幻象一个与环境背景相协调的视觉实例。在本研究中，我们提出了一种新的图像修复模型，名为ImComplete，该模型可以幻象缺失的实例，从而与原始背景协调。ImComplete首先采用了一个变压器架构，考虑到可见实例和缺失区域的位置。然后，ImComplete完成了缺失区域内的语义分割掩模，提供像素级的语义和结构指导。最后，图像合成块生成了逼真的内容。

    Image completion is a task that aims to fill in the missing region of a masked image with plausible contents. However, existing image completion methods tend to fill in the missing region with the surrounding texture instead of hallucinating a visual instance that is suitable in accordance with the context of the scene. In this work, we propose a novel image completion model, dubbed ImComplete, that hallucinates the missing instance that harmonizes well with - and thus preserves - the original context. ImComplete first adopts a transformer architecture that considers the visible instances and the location of the missing region. Then, ImComplete completes the semantic segmentation masks within the missing region, providing pixel-level semantic and structural guidance. Finally, the image synthesis blocks generate photo-realistic content. We perform a comprehensive evaluation of the results in terms of visual quality (LPIPS and FID) and contextual preservation scores (CLIPscore and object
    
[^130]: 基于技能的强化学习与内在奖励匹配

    Skill-Based Reinforcement Learning with Intrinsic Reward Matching. (arXiv:2210.07426v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.07426](http://arxiv.org/abs/2210.07426)

    该论文提出了内在奖励匹配(IRF)方法，通过技能鉴别器匹配内在和下游任务奖励来确定未见任务的最优技能，提高了系统效率。

    

    虽然无监督技能探索已经展示了自主获取行为原语的潜力，但是任务无关的技能预训练和下游的任务感知调优之间仍存在很大的方法论差距。我们提出内在奖励匹配(IRF)，通过预训练模型组件 "技能鉴别器" 统一这两个学习阶段。传统方法在策略级别直接微调预训练代理，通常依赖于昂贵的环境回放来经验性地确定最优技能。然而，任务最简明但完整的描述通常是奖励函数本身，技能学习方法通过鉴别器学习与技能策略相对应的“内在”奖励函数。我们建议利用技能鉴别器“匹配”内在和下游任务奖励，并确定未见任务的最优技能，从而提高效率。

    While unsupervised skill discovery has shown promise in autonomously acquiring behavioral primitives, there is still a large methodological disconnect between task-agnostic skill pretraining and downstream, task-aware finetuning. We present Intrinsic Reward Matching (IRM), which unifies these two phases of learning via the $\textit{skill discriminator}$, a pretraining model component often discarded during finetuning. Conventional approaches finetune pretrained agents directly at the policy level, often relying on expensive environment rollouts to empirically determine the optimal skill. However, often the most concise yet complete description of a task is the reward function itself, and skill learning methods learn an $\textit{intrinsic}$ reward function via the discriminator that corresponds to the skill policy. We propose to leverage the skill discriminator to $\textit{match}$ the intrinsic and downstream task rewards and determine the optimal skill for an unseen task without enviro
    
[^131]: 带有拓扑指导的拥挤环境下可扩展的多机器人运动规划

    Scalable Multi-robot Motion Planning for Congested Environments With Topological Guidance. (arXiv:2210.07141v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2210.07141](http://arxiv.org/abs/2210.07141)

    本研究利用拓扑引导的运动规划方法扩展到多机器人领域。该方法能够高效地规划具有许多狭窄通道的复杂环境中的路径，并找到比其他方法更高质量的解决方案。

    

    多机器人运动规划(MRMP)的问题在于为一组机器人在连续状态空间中找到无冲突的路径。当机器人数量增加并且在具有狭窄通道而机器人必须通过的环境中，例如需要机器人之间协调的仓库通道时，MRMP的难度会增加。在单机器人情况下，拓扑引导的运动规划方法已显示出在这些受限环境中提高了性能。在本研究中，我们将现有的拓扑引导单机器人运动规划方法扩展到多机器人领域，利用拓扑引导提供的改善效率。我们演示了我们的方法在具有许多狭窄通道的复杂环境中有效地规划路径，规模可以扩展到比现有在此类问题中的方法大25倍的机器人团队。通过利用环境的拓扑知识，我们也找到了比其他方法更高质量的解决方案。

    Multi-robot motion planning (MRMP) is the problem of finding collision-free paths for a set of robots in a continuous state space. The difficulty of MRMP increases with the number of robots and is exacerbated in environments with narrow passages that robots must pass through, like warehouse aisles where coordination between robots is required. In single-robot settings, topology-guided motion planning methods have shown improved performance in these constricted environments. In this work, we extend an existing topology-guided single-robot motion planning method to the multi-robot domain to leverage the improved efficiency provided by topological guidance. We demonstrate our method's ability to efficiently plan paths in complex environments with many narrow passages, scaling to robot teams of size up to 25 times larger than existing methods in this class of problems. By leveraging knowledge of the topology of the environment, we also find higher-quality solutions than other methods.
    
[^132]: 语言模型能够具体化吗？如何实现？

    Can Language Models Be Specific? How?. (arXiv:2210.05159v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.05159](http://arxiv.org/abs/2210.05159)

    本论文提出了一种度量预训练语言模型具体性的方法，并设计了两种基于提示的方法，以改善模型具体性，结果表明，模型的具体性可以得到改善，而无需进行额外的训练。

    

    “他是一个人”、“巴黎位于地球上”。这些语句都是正确的，但没有具体性——因为缺乏明确的内容。在本文中，我们提出了一种度量预训练语言模型（PLMs）的具体性的方法。为了实现这一点，我们引入了一种新方法来建立具体性测试的基准，通过带有提示的掩码标记预测任务来实现。例如，给定“多伦多位于[MASK]中”，我们想测试PLMs是否能更好地填写更具体的答案，例如安大略省而不是加拿大。从我们的评估中，我们发现现有的PLMs只对更具体的答案略微更有偏好。我们确定了影响具体性的潜在因素，并设计了两种基于提示的方法以改善具体性。结果表明，通过所提出的方法，模型的具体性可以得到改善，而无需进行额外的训练。我们希望这项工作能带来语言模型具体性的认识，并鼓励相关研究。

    "He is a person", "Paris is located on the earth". Both statements are correct but meaningless - due to lack of specificity. In this paper, we propose to measure how specific the language of pre-trained language models (PLMs) is. To achieve this, we introduce a novel approach to build a benchmark for specificity testing by forming masked token prediction tasks with prompts. For instance, given "Toronto is located in [MASK].", we want to test whether a more specific answer will be better filled in by PLMs, e.g., Ontario instead of Canada. From our evaluations, we show that existing PLMs have only a slight preference for more specific answers. We identify underlying factors affecting the specificity and design two prompt-based methods to improve the specificity. Results show that the specificity of the models can be improved by the proposed methods without additional training. We hope this work can bring to awareness the notion of specificity of language models and encourage the research
    
[^133]: 分层对抗逆强化学习

    Hierarchical Adversarial Inverse Reinforcement Learning. (arXiv:2210.01969v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.01969](http://arxiv.org/abs/2210.01969)

    本文提出了一种分层对抗逆强化学习算法，能够在复杂任务中学习到具有层次结构的最优策略，比现有的方法更加有效。

    

    模仿学习（IL）一般用于从演示中恢复专家策略。然而，对于高度复杂的、长时程任务，恢复单一整体策略是困难的，而专家策略通常包含子任务层次结构。因此，研究者开发了分层模仿学习（HIL）方法，通过在选项框架中显式地建模任务中的活动结构来学习分层策略。现有的HIL方法要么忽视了子任务结构与学习策略之间的因果关系，要么无法同时在分层框架中学习高级别和低级别策略，导致亚最优。本文提出了一种新的HIL算法——分层对抗逆强化学习（H-AIRL），它在最新的IL算法AIRL上扩展了一步选项框架，重新定义了AIRL目标。

    Imitation Learning (IL) has been proposed to recover the expert policy from demonstrations. However, it would be difficult to learn a single monolithic policy for highly-complex long-horizon tasks of which the expert policy usually contains subtask hierarchies. Therefore, Hierarchical Imitation Learning (HIL) has been developed to learn a hierarchical policy from expert demonstrations through explicitly modelling the activity structure in a task with the option framework. Existing HIL methods either overlook the causal relationship between the subtask structure and the learned policy, or fail to learn the high-level and low-level policy in the hierarchical framework in conjuncture, which leads to suboptimality. In this work, we propose a novel HIL algorithm -Hierarchical Adversarial Inverse Reinforcement Learning (H-AIRL), which extends a state-of-the-art (SOTA) IL algorithm -- AIRL, with the one-step option framework. Specifically, we redefine the AIRL objectives on the extended sta
    
[^134]: 多媒体生成式脚本学习用于任务规划

    Multimedia Generative Script Learning for Task Planning. (arXiv:2208.12306v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2208.12306](http://arxiv.org/abs/2208.12306)

    该论文提出了多媒体生成式脚本学习任务，旨在通过跟踪文本和视觉模态中的历史状态来生成后续步骤，能对未见过的任务具有归纳能力并具有多样性。

    

    目标导向的生成式脚本学习旨在基于目标生成后续步骤，这是帮助机器人执行日常生活中典型活动的重要任务。我们展示了如果历史状态不仅由给人的语言指示捕获，而且还通过相伴的图像提供了附加信息，那么此任务的表现可以改善。因此，我们提出了一个新任务，即多媒体生成式脚本学习，以通过跟踪文本和视觉模态中的历史状态来生成后续步骤，并提供了包含2,338个任务和31,496个步骤及其描述性图像的第一个基准。我们的目标是生成可视状态可跟踪的脚本，对于未见过的任务具有归纳能力，并且其步骤具有多样性。我们提出通过多媒体选择性编码器对视觉状态变化进行编码，利用检索增强解码器传递先前观察到的任务知识，并通过随机抽样和波束搜索解码生成多样的步骤。

    Goal-oriented generative script learning aims to generate subsequent steps based on a goal, which is an essential task to assist robots in performing stereotypical activities of daily life. We show that the performance of this task can be improved if historical states are not just captured by the linguistic instructions given to people, but are augmented with the additional information provided by accompanying images. Therefore, we propose a new task, Multimedia Generative Script Learning, to generate subsequent steps by tracking historical states in both text and vision modalities, as well as presenting the first benchmark containing 2,338 tasks and 31,496 steps with descriptive images. We aim to generate scripts that are visual-state trackable, inductive for unseen tasks, and diverse in their individual steps. We propose to encode visual state changes through a multimedia selective encoder, transferring knowledge from previously observed tasks using a retrieval-augmented decoder, and
    
[^135]: Fix-A-Step: 半监督学习处理未经筛选的无标签数据

    Fix-A-Step: Semi-supervised Learning from Uncurated Unlabeled Data. (arXiv:2208.11870v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2208.11870](http://arxiv.org/abs/2208.11870)

    Fix-A-Step是一个半监督学习的简化流程，将所有未经筛选的无标签图像视为潜在有用的；增强有标签集的数据，修正梯度下降更新方式可以修复许多常见的深度 SSL 方法，并在医学成像数据集上实现更好的效果。

    

    半监督学习 (SSL) 在训练分类器时，通过在许多无标签图像上进行训练，承诺比在少量有标签数据集上训练时有更高的准确性。在实际应用中，例如医学成像，为了速度而收集未经筛选的无标签数据，因此可能与有标签集中的类别或特征不同。不幸的是，现代深度半监督学习在处理未经筛选的无标签数据时，常常会导致准确性下降。最近，一些较为复杂的方法通过检测分布外的无标签图像，然后丢弃或降低它们的权重来修复这个问题。与此不同，我们引入了 Fix-A-Step，一种更简单的过程，将所有未经筛选的无标签图像视为潜在有用的。我们的第一个洞见是，即使未经筛选的图像也可以产生有用的已标记数据增强。其次，我们修改了梯度下降更新的方式，以防止优化多任务 SSL 损失对有标签集准确性的损害。Fix-A-Step 可以修复许多常见的深度 SSL 方法，在 CIFAR 基准测试中提高了所有测试方法和数据集的准确性。此外，在医学成像数据集上进行评估时，Fix-A-Step 在处理未经筛选的无标签图像方面比现有的最先进方法要好得多。

    Semi-supervised learning (SSL) promises improved accuracy compared to training classifiers on small labeled datasets by also training on many unlabeled images. In real applications like medical imaging, unlabeled data will be collected for expediency and thus uncurated: possibly different from the labeled set in classes or features. Unfortunately, modern deep SSL often makes accuracy worse when given uncurated unlabeled data. Recent complex remedies try to detect out-of-distribution unlabeled images and then discard or downweight them. Instead, we introduce Fix-A-Step, a simpler procedure that views all uncurated unlabeled images as potentially helpful. Our first insight is that even uncurated images can yield useful augmentations of labeled data. Second, we modify gradient descent updates to prevent optimizing a multi-task SSL loss from hurting labeled-set accuracy. Fix-A-Step can repair many common deep SSL methods, improving accuracy on CIFAR benchmarks across all tested methods and
    
[^136]: 每个人的偏好变化不同：加权多兴趣检索模型

    Everyone's Preference Changes Differently: Weighted Multi-Interest Retrieval Model. (arXiv:2207.06652v4 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2207.06652](http://arxiv.org/abs/2207.06652)

    本文提出了一种新的加权多兴趣检索模型（Multi-Interest Preference，MIP），通过利用深度学习方法为用户建立多个兴趣嵌入，并将用户在多个兴趣上的偏好进行建模，从而提高候选检索结果的查全率。

    

    用户嵌入（用户的向量化表示）在推荐系统中具有重要作用。已经提出了许多方法来构建用户的多维度表示，以便于检索任务中找到相似的物品，并且已经在工业推荐系统中被证明是有效的。最近人们发现使用多种嵌入（即多个维度的用户表示）来表示用户的兴趣是有用的，每个嵌入表示用户的某个主题兴趣。对于多兴趣表示，重要的是对用户在不同主题上的偏好进行建模，并且了解偏好随时间的变化情况。然而，现有方法要么无法估算用户对每个兴趣的好感度，要么不合理地假设每个用户对每个兴趣的兴趣强度会以相等的速率下降，从而降低了候选检索结果的查全率。在本文中，我们提出加权多兴趣检索模型（Multi-Interest Preference, MIP），通过利用深度学习方法为用户产生多个兴趣嵌入，并且可以对用户在多种兴趣下的偏好进行估计，从而提高候选检索结果的查全率。

    User embeddings (vectorized representations of a user) are essential in recommendation systems. Numerous approaches have been proposed to construct a representation for the user in order to find similar items for retrieval tasks, and they have been proven effective in industrial recommendation systems as well. Recently people have discovered the power of using multiple embeddings to represent a user, with the hope that each embedding represents the user's interest in a certain topic. With multi-interest representation, it's important to model the user's preference over the different topics and how the preference change with time. However, existing approaches either fail to estimate the user's affinity to each interest or unreasonably assume every interest of every user fades with an equal rate with time, thus hurting the recall of candidate retrieval. In this paper, we propose the Multi-Interest Preference (MIP) model, an approach that not only produces multi-interest for users by usin
    
[^137]: 隐藏结构网络

    Hidden Schema Networks. (arXiv:2207.03777v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2207.03777](http://arxiv.org/abs/2207.03777)

    本文介绍了一种新颖的神经语言模型，通过归纳偏见强制执行明确的关系结构，从而将预训练语言模型的输出表示显式地组成。该模型可以从随机标记序列数据集中发现隐含的真实图，在自然语言数据集中推断出符号网络（模式），直接反映了语言的基础句法结构。

    

    大型预训练语言模型可以推断出强大的表示形式，其中蕴含着丰富的语义和句法内容，尽管是隐含的。本文介绍了一种新颖的神经语言模型，通过归纳偏见强制执行明确的关系结构，从而将预训练语言模型的输出表示显式地组成。具体而言，该模型将句子编码为符号序列（组合表示），这些符号对应于全局潜在图上带偏置的随机游走器访问的节点，并推断其后验分布。我们首先展示了该模型能够从人工生成的随机标记序列数据集中发现隐含的真实图。接下来，我们利用预训练的BERT和GPT-2语言模型作为编码器和解码器，从自然语言数据集中推断出符号网络（模式）。我们的实验证明了：（i）推断出的符号可以解释为编码不同方面的含义，（ii）它们的复合性直接反映了语言的基础句法结构。

    Large, pretrained language models infer powerful representations that encode rich semantic and syntactic content, albeit implicitly. In this work we introduce a novel neural language model that enforces, via inductive biases, explicit relational structures which allow for compositionality onto the output representations of pretrained language models. Specifically, the model encodes sentences into sequences of symbols (composed representations), which correspond to the nodes visited by biased random walkers on a global latent graph, and infers the posterior distribution of the latter. We first demonstrate that the model is able to uncover ground-truth graphs from artificially generated datasets of random token sequences. Next, we leverage pretrained BERT and GPT-2 language models as encoder and decoder, respectively, to infer networks of symbols (schemata) from natural language datasets. Our experiments show that (i) the inferred symbols can be interpreted as encoding different aspects 
    
[^138]: 支持“可解释设计”的方法论和软件架构

    A Methodology and Software Architecture to Support Explainability-by-Design. (arXiv:2206.06251v2 [cs.SE] UPDATED)

    [http://arxiv.org/abs/2206.06251](http://arxiv.org/abs/2206.06251)

    本文提出了“可解释设计”方法论，针对算法决策的解释提出了一个综合性的解决方案，由三个阶段组成：（A）解释需求分析，（B）解释技术设计，（C）解释验证。

    

    算法在控制或影响我们生活的许多技术系统中扮演着至关重要的角色。因此，为了满足用户和组织的需求，根据法律、规定、道德准则以及公众的期望提供算法决策的解释越来越受到关注。然而，由于法律和规定并未规定如何满足这些期望，因此组织通常需要自行制定解释方法，从而增加了合规成本和良好管理的成本。因此，本文提出了“可解释设计”方法论，这是一种综合性方法，采用积极的措施，在决策系统的设计中包括解释能力。该方法论由三个阶段组成：（A）解释需求分析，（B）解释技术设计，（C）解释验证。本文描述了第二阶段（B），即根据领域专家提出的需求实现解释能力的技术工作流程。

    Algorithms play a crucial role in many technological systems that control or affect various aspects of our lives. As a result, providing explanations for their decisions to address the needs of users and organisations is increasingly expected by laws, regulations, codes of conduct, and the public. However, as laws and regulations do not prescribe how to meet such expectations, organisations are often left to devise their own approaches to explainability, inevitably increasing the cost of compliance and good governance. Hence, we envision Explainability-by-Design, a holistic methodology characterised by proactive measures to include explanation capability in the design of decision-making systems. The methodology consists of three phases: (A) Explanation Requirement Analysis, (B) Explanation Technical Design, and (C) Explanation Validation. This paper describes phase (B), a technical workflow to implement explanation capability from requirements elicited by domain experts for a specific 
    
[^139]: 废物减量的仿真环境与强化学习方法

    A Simulation Environment and Reinforcement Learning Method for Waste Reduction. (arXiv:2205.15455v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.15455](http://arxiv.org/abs/2205.15455)

    本文提出了一个新的强化学习任务，即库存重新填充，提出了一种新的强化学习算法 Perishable DQN，旨在最大化销售同时最小化浪费，实现计算机思维对废物减量的控制。

    

    在零售行业（例如，杂货店、服装店、在线零售商），库存管理者必须在短期风险（没有销售商品）和长期风险（过量订货导致产品浪费）之间进行平衡。由于缺乏有关未来客户购买的信息，这个平衡任务尤其困难。在本文中，我们从分布的角度研究了在时间范围内重新填充易腐物品的杂货店库存问题。其目标是在不确定实际消费的情况下，最大化销售同时最小化浪费。由于对食物的需求不断增长以及食物浪费对环境、经济和购买力的影响，这个问题在今天具有极高的相关性。我们将库存重新填充作为一项新的强化学习任务，并在此基础上提出了一种名为“腐败DQN”的新的强化学习算法，利用问题的分布式公式来估算每个动作的预期回报。我们在一个合成的杂货店数据集上验证了我们的方法，并证明了我们的方法优于文献中的几个基准线。

    In retail (e.g., grocery stores, apparel shops, online retailers), inventory managers have to balance short-term risk (no items to sell) with long-term-risk (over ordering leading to product waste). This balancing task is made especially hard due to the lack of information about future customer purchases. In this paper, we study the problem of restocking a grocery store's inventory with perishable items over time, from a distributional point of view. The objective is to maximize sales while minimizing waste, with uncertainty about the actual consumption by costumers. This problem is of a high relevance today, given the growing demand for food and the impact of food waste on the environment, the economy, and purchasing power. We frame inventory restocking as a new reinforcement learning task that exhibits stochastic behavior conditioned on the agent's actions, making the environment partially observable. We make two main contributions. First, we introduce a new reinforcement learning en
    
[^140]: 理解总结中的事实错误：错误，摘要生成器，数据集和错误检测器

    Understanding Factual Errors in Summarization: Errors, Summarizers, Datasets, Error Detectors. (arXiv:2205.12854v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2205.12854](http://arxiv.org/abs/2205.12854)

    本文聚合了来自九个现有数据集的事实错误注释，针对底层的摘要生成模型进行分类，并比较了最先进的事实度量标准的性能。结果表明，度量标准的性能因不同的摘要生成模型而有显著差异。

    

    抽象摘要生成模型制造事实错误的倾向已经得到了广泛的研究，包括设计用于检测事实错误的度量标准和注释当前系统输出中的错误。然而，总结系统、度量标准和注释基准的不断发展使得事实评价成为一个移动的目标，并且在度量标准之间进行清晰的比较变得越来越困难。在本文中，我们聚合了来自九个现有数据集的事实错误注释，并根据底层的摘要生成模型进行分类。我们比较了最先进的事实度量标准的性能，包括最近的ChatGPT-based度量标准，在这个分层基准上展示了它们在不同类型的摘要生成模型上的性能差异。关键是，我们的分析显示，最近在事实检测空间的很大改进是针对旧的(前Transformer) 模型的总结，而不是更相关的模型。

    The propensity of abstractive summarization models to make factual errors has been studied extensively, including design of metrics to detect factual errors and annotation of errors in current systems' outputs. However, the ever-evolving nature of summarization systems, metrics, and annotated benchmarks makes factuality evaluation a moving target, and drawing clear comparisons among metrics has become increasingly difficult. In this work, we aggregate factuality error annotations from nine existing datasets and stratify them according to the underlying summarization model. We compare performance of state-of-the-art factuality metrics, including recent ChatGPT-based metrics, on this stratified benchmark and show that their performance varies significantly across different types of summarization models. Critically, our analysis shows that much of the recent improvement in the factuality detection space has been on summaries from older (pre-Transformer) models instead of more relevant rec
    
[^141]: TAGPRIME：一种用于关系结构提取的统一框架

    TAGPRIME: A Unified Framework for Relational Structure Extraction. (arXiv:2205.12585v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2205.12585](http://arxiv.org/abs/2205.12585)

    本文提出了一种名为TAGPRIME的统一关系结构提取框架，通过将给定条件信息添加到输入文本中，使得输出的上下文表示更适合提取特定条件下的关系。在各种任务和数据集上的表现优于最新的关系提取模型。

    

    自然语言处理中许多任务需要提取给定条件下的关系信息，例如事件参数提取、关系提取和面向任务的语义解析。最近的研究通常针对每个任务分别提出复杂的模型，较少关注这些任务的共性，并缺乏一个统一的框架来处理所有这些任务。本文提出了TAGPRIME，旨在从统一的角度来解决这些关系结构提取问题。TAGPRIME是一种序列标记模型，将给定条件（例如事件触发器）的信息添加到输入文本中。通过在预训练的语言模型中使用自注意机制，这些条件信息使得输出的上下文表示包含更多关于给定条件的信息，从而更适合提取特定条件下的关系。在广泛的实验和分析中表明，TAGPRIME在各种任务和数据集上的表现优于最新的关系提取模型。

    Many tasks in natural language processing require the extraction of relationship information for a given condition, such as event argument extraction, relation extraction, and task-oriented semantic parsing. Recent works usually propose sophisticated models for each task independently and pay less attention to the commonality of these tasks and to have a unified framework for all the tasks. In this work, we propose to take a unified view of all these tasks and introduce TAGPRIME to address relational structure extraction problems. TAGPRIME is a sequence tagging model that appends priming words about the information of the given condition (such as an event trigger) to the input text. With the self-attention mechanism in pre-trained language models, the priming words make the output contextualized representations contain more information about the given condition, and hence become more suitable for extracting specific relationships for the condition. Extensive experiments and analyses on
    
[^142]: 评估“Assurance 2.0”中的信心

    Assessing Confidence with Assurance 2.0. (arXiv:2205.04522v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2205.04522](http://arxiv.org/abs/2205.04522)

    本文提出了从三个方面考虑信心的属性来评估保证案例，其中主要的措施是将论证解释为逻辑证明的完备性。

    

    保证案例旨在对其顶级声明（通常涉及安全性或安全）提供可证明的信心。那么问题来了，“这种信心”有多少？我们认为信心不能归结为单一属性或测量。相反，我们建议它应该基于三个不同视角的属性：积极，消极和剩余疑虑。积极视角考虑证据和整个案例的程度，将积极声明合理化为支持其主张的信仰。我们对证明设立了高门槛，要求证明是不可否认的。其中主要的正面措施是完备性，将该论证解释为逻辑证明。证据的信心可以以概率方式表达，并使用确认措施确保证据的"重量"越过某个阈值。此外，概率可以从证据中聚合，通过将证据视为贝叶斯网络节点来完成。

    An assurance case is intended to provide justifiable confidence in the truth of its top claim, which typically concerns safety or security. A natural question is then "how much" confidence does the case provide? We argue that confidence cannot be reduced to a single attribute or measurement. Instead, we suggest it should be based on attributes that draw on three different perspectives: positive, negative, and residual doubts.  Positive Perspectives consider the extent to which the evidence and overall argument of the case combine to make a positive statement justifying belief in its claims. We set a high bar for justification, requiring it to be indefeasible. The primary positive measure for this is soundness, which interprets the argument as a logical proof. Confidence in evidence can be expressed probabilistically and we use confirmation measures to ensure that the "weight" of evidence crosses some threshold. In addition, probabilities can be aggregated from evidence through the step
    
[^143]: SD-Conv：实现动态卷积的参数效率

    SD-Conv: Towards the Parameter-Efficiency of Dynamic Convolution. (arXiv:2204.02227v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2204.02227](http://arxiv.org/abs/2204.02227)

    SD-Conv 是一个新的框架，将动态机制和稀疏性集成在一起，通过设计二进制掩码修剪静态核，大大减少了参数和计算成本，并在多个下游任务中展示了比基线模型更好的结果。

    

    动态卷积在保持微不足道的浮点运算增量的同时，实现了有效CNN的更好性能。然而，性能提升无法匹配显著扩大的参数数量，这是现实应用的主要瓶颈。相反，基于掩码的非结构化修剪通过去除重复项来获得轻量级网络。在本文中，我们提出了一个新的框架，称为“稀疏动态卷积”（SD-Conv），自然地将这两个路径集成在一起，以便可以继承动态机制和稀疏性的优点。我们首先设计了一个二进制掩码，从可学习阈值中派生出来，以修剪静态核，大大减少了参数和计算成本，但在Imagenet-1K中实现了更高的性能。我们进一步将预训练模型转移到各种下游任务中，展示了比基线模型更为稳定的结果。我们希望我们的SD-Conv能够成为传统动态卷积和结构化修剪的高效替代品。

    Dynamic convolution achieves better performance for efficient CNNs at the cost of negligible FLOPs increase. However, the performance increase can not match the significantly expanded number of parameters, which is the main bottleneck in real-world applications. Contrastively, mask-based unstructured pruning obtains a lightweight network by removing redundancy in the heavy network. In this paper, we propose a new framework, \textbf{Sparse Dynamic Convolution} (\textsc{SD-Conv}), to naturally integrate these two paths such that it can inherit the advantage of dynamic mechanism and sparsity. We first design a binary mask derived from a learnable threshold to prune static kernels, significantly reducing the parameters and computational cost but achieving higher performance in Imagenet-1K. We further transfer pretrained models into a variety of downstream tasks, showing consistently better results than baselines. We hope our SD-Conv could be an efficient alternative to conventional dynamic
    
[^144]: 实现安全、可解释和监管的自动驾驶技术

    Towards Safe, Explainable, and Regulated Autonomous Driving. (arXiv:2111.10518v4 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2111.10518](http://arxiv.org/abs/2111.10518)

    本文提出了一个集成自主控制、可解释的人工智能和监管合规性的设计框架，以实现安全、可解释和监管的自动驾驶技术。

    

    近年来，自主驾驶车辆的发展和部署正越来越受到关注，尤其是深度学习和强化学习等强大人工智能技术的实证成功。但是，正如最近的交通事故所表明的那样，自动驾驶技术无法完全保证安全部署。由于人工智能技术是自动驾驶车辆智能导航系统背后的主要技术，因此利益相关者和交通监管机构要求他们的基于人工智能的软件架构必须具备安全性、可解释性和监管合规性。本文提出了一个设计框架，集成自主控制、可解释的人工智能和监管合规性，以解决这个问题，接着通过案例研究进行了框架的初步验证。此外，我们还介绍了相关的可解释的人工智能方法，以帮助实现框架的目标。

    There has been recent and growing interest in the development and deployment of autonomous vehicles, encouraged by the empirical successes of powerful artificial intelligence techniques (AI), especially in the applications of deep learning and reinforcement learning. However, as demonstrated by recent traffic accidents, autonomous driving technology is not fully reliable for safe deployment. As AI is the main technology behind the intelligent navigation systems of self-driving vehicles, both the stakeholders and transportation regulators require their AI-driven software architecture to be safe, explainable, and regulatory compliant. In this paper, we propose a design framework that integrates autonomous control, explainable AI (XAI), and regulatory compliance to address this issue, and then provide an initial validation of the framework with a critical analysis in a case study. Moreover, we describe relevant XAI approaches that can help achieve the goals of the framework.
    
[^145]: 基于事实的逻辑推理与机器阅读理解

    Fact-driven Logical Reasoning for Machine Reading Comprehension. (arXiv:2105.10334v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2105.10334](http://arxiv.org/abs/2105.10334)

    本文提出一种基于事实的逻辑推理方法，采用分层方式涵盖常识和临时知识线索，通过构建超图实现句子级别和实体级别的交互，在逻辑推理基准测试和大规模阅读理解中表现出优越性。

    

    近年来，越来越多的人开始关注机器具备推理能力，这需要准确清晰地提供线索。在现有的研究中，线索通常被建模为实体感知知识。然而，这些实体感知线索主要集中于常识，对于需要了解临时事实或事件的任务，特别是在阅读理解的逻辑推理中，这些线索是不足够的。为了解决这一挑战，我们有动力以分层方式涵盖常识和临时知识线索。具体而言，我们提出了一种知识单元的通用形式，通过提取句子的骨干构成部分，如主语-谓语-宾语形成的“事实”。然后，在事实单元之上构建一个超图，允许句子级别（事实组之间的关系）和实体级别交互（事实中的概念或行动）的互动。在逻辑推理基准测试和大规模阅读理解中，实验结果证明了我们的方法的优越性。

    Recent years have witnessed an increasing interest in training machines with reasoning ability, which deeply relies on accurately and clearly presented clue forms. The clues are usually modeled as entity-aware knowledge in existing studies. However, those entity-aware clues are primarily focused on commonsense, making them insufficient for tasks that require knowledge of temporary facts or events, particularly in logical reasoning for reading comprehension. To address this challenge, we are motivated to cover both commonsense and temporary knowledge clues hierarchically. Specifically, we propose a general formalism of knowledge units by extracting backbone constituents of the sentence, such as the subject-verb-object formed ``facts''. We then construct a supergraph on top of the fact units, allowing for the benefit of sentence-level (relations among fact groups) and entity-level interactions (concepts or actions inside a fact). Experimental results on logical reasoning benchmarks and d
    
[^146]: 多任务注意力残差网络用于论述挖掘

    Multi-Task Attentive Residual Networks for Argument Mining. (arXiv:2102.12227v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2102.12227](http://arxiv.org/abs/2102.12227)

    本文提出了一种多任务注意力残差网络架构，通过利用集成方法、注意力机制和多任务学习，无需假设文档或论据结构，成功应用于多个论述挖掘任务中，成为了一种既通用又高性能的架构。

    

    本文探讨了多任务注意力残差网络在多个论述挖掘任务中的应用。我们提出了一种残差架构，利用了注意力、多任务学习，并使用集成方法，不对文档或论据结构做任何假设。我们在五个不同的用户生成评论、科学出版物和劝说性论文语料库上进行了广泛的实验评估。我们的结果表明，我们的方法是针对具有更高计算印记或特定于语料库设计的最先进架构的强有力的竞争对手，代表了通用性、性能精度和减少模型大小之间的有趣折衷。

    We explore the use of residual networks and neural attention for multiple argument mining tasks. We propose a residual architecture that exploits attention, multi-task learning, and makes use of ensemble, without any assumption on document or argument structure. We present an extensive experimental evaluation on five different corpora of user-generated comments, scientific publications, and persuasive essays. Our results show that our approach is a strong competitor against state-of-the-art architectures with a higher computational footprint or corpus-specific design, representing an interesting compromise between generality, performance accuracy and reduced model size.
    
[^147]: “你为什么不把这个任务分配给他们？”：考虑谈判的可解释任务分配和对比解释生成

    `Why didn't you allocate this task to them?' Negotiation-Aware Explicable Task Allocation and Contrastive Explanation Generation. (arXiv:2002.01640v4 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2002.01640](http://arxiv.org/abs/2002.01640)

    本文提出一种考虑谈判的任务分配系统，在任务分配过程中允许成员提出反问。通过模拟谈判，生成对比解释，该方法被证明公平且易于理解。

    

    任务分配是多智能体系统中的一个重要问题。当团队成员具有不完整的关于队友成本和整体性能指标的知识时，问题变得更加具有挑战性。本文提出了一种集中式人工智能任务分配（AITA），该系统模拟谈判，并产生考虑谈判的可解释任务分配。如果团队成员对所提议的分配不满意，我们允许他们使用对事实的反问来质疑所提出的分配。通过使用模拟谈判的一部分，我们能够提供对比解释，最小限度地提供有关其他成本的信息以反驳他们的假设。通过人类研究，我们表明（1）使用我们的方法提出的分配对大多数人来说显得公平，（2）当提出反事实情况时，生成的解释易于理解并且令人信服。最后，我们从实证的角度研究了不同类型的不完整性对解释-学习的影响。

    Task allocation is an important problem in multi-agent systems. It becomes more challenging when the team-members are humans with imperfect knowledge about their teammates' costs and the overall performance metric. In this paper, we propose a centralized Artificial Intelligence Task Allocation (AITA) that simulates a negotiation and produces a negotiation-aware explicable task allocation. If a team-member is unhappy with the proposed allocation, we allow them to question the proposed allocation using a counterfactual. By using parts of the simulated negotiation, we are able to provide contrastive explanations that provide minimum information about other's cost to refute their foil. With human studies, we show that (1) the allocation proposed using our method appears fair to the majority, and (2) when a counterfactual is raised, explanations generated are easy to comprehend and convincing. Finally, we empirically study the effect of different kinds of incompleteness on the explanation-l
    

