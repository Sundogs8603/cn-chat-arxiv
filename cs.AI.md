# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Efficient Heatmap-Guided 6-Dof Grasp Detection in Cluttered Scenes](https://arxiv.org/abs/2403.18546) | 本文提出了一种利用抓取热图引导的高效局部抓取生成方法，从全局到局部语义到点的方式推断，显著提高了抓取准确性和多样性。 |
| [^2] | [GeNet: A Graph Neural Network-based Anti-noise Task-Oriented Semantic Communication Paradigm](https://arxiv.org/abs/2403.18296) | GeNet提出了一种基于图神经网络的语义通信范式，通过将数据转换为图结构、利用编码器提取语义信息并利用解码器重建信息的方法来实现抗噪声任务导向通信。 |
| [^3] | [Evaluating GPT-4 with Vision on Detection of Radiological Findings on Chest Radiographs](https://arxiv.org/abs/2403.15528) | GPT-4V在胸部X光放射检查的放射学发现检测上尚未准备好应用于真实世界的诊断用途 |
| [^4] | [Adversarial Nibbler: An Open Red-Teaming Method for Identifying Diverse Harms in Text-to-Image Generation](https://arxiv.org/abs/2403.12075) | 批评了文本到图像生成中模型对非明显攻击的鲁棒性，提出了Adversarial Nibbler Challenge以众包多样化的提示来纠正模型的安全问题 |
| [^5] | [Efficient Pruning of Large Language Model with Adaptive Estimation Fusion](https://arxiv.org/abs/2403.10799) | 提出了一种简单而高效的剪枝方法，能够自适应地模拟每个子结构的重要性，并根据多层结构的结果自适应地融合粗粒度和细粒度的估计。 |
| [^6] | [A Short Survey on Importance Weighting for Machine Learning](https://arxiv.org/abs/2403.10175) | 重要性加权是统计学和机器学习中的基本程序，通过对目标函数或概率分布进行加权，可以保证监督学习在训练和测试分布之间差异的情况下具有统计上期望的性质 |
| [^7] | [Tell, Don't Show!: Language Guidance Eases Transfer Across Domains in Images and Videos](https://arxiv.org/abs/2403.05535) | 该论文提出了LaGTran框架，利用文本描述来引导知识转移，在处理具有挑战性的数据集上表现出显著优势。 |
| [^8] | [Towards Safe and Aligned Large Language Models for Medicine](https://arxiv.org/abs/2403.03744) | 对医学LLMs进行了首次安全评估，并探讨了如何定义医学安全和对齐性，开发了有害医学问题数据集，评估了医学LLMs的安全性和对齐性，展示了微调是一种有效的缓解策略。 |
| [^9] | [ParallelPARC: A Scalable Pipeline for Generating Natural-Language Analogies](https://arxiv.org/abs/2403.01139) | 设计了ParallelPARC流水线，利用大型语言模型生成复杂段落类比数据集，评估各种类比类型，并展示出人类在类比识别中的优势。 |
| [^10] | [Direct Alignment of Draft Model for Speculative Decoding with Chat-Fine-Tuned LLMs](https://arxiv.org/abs/2403.00858) | 通过提出的框架，我们训练了一种用于Llama 2 Chat 7B或更大模型的草案模型，实现了加速推理，仅占原始大小的1.64％。 |
| [^11] | [PiShield: A NeSy Framework for Learning with Requirements](https://arxiv.org/abs/2402.18285) | PiShield是第一个允许将需求集成到神经网络拓扑结构中的框架，无论输入如何都能确保满足这些需求，并可根据从业者需求在推断和/或训练时集成需求。 |
| [^12] | [MOMENT: A Family of Open Time-series Foundation Models](https://arxiv.org/abs/2402.03885) | MOMENT是一个开放的时间序列基础模型家族，通过解决时间序列数据的挑战，编制了一个大规模的公共时间序列数据集，并设计了一个基准测试来评估有限监督场景下模型的性能。 |
| [^13] | [Counterfactual Effect Generalization: A Combinatorial Definition](https://arxiv.org/abs/2108.04376) | 提出了一种用于干预效应外部有效性的组合定义，揭示了效应概括的两个限制，并重新审视了原始反事实公式中的多个问题。 |
| [^14] | [Can Large Language Models Write Parallel Code?.](http://arxiv.org/abs/2401.12554) | 本文研究了大型语言模型生成并行代码的能力。我们提出了一个基准测试集PCGBench，并使用新指标评估了几个最先进的语言模型在并行编程模型和计算问题类型上的性能。 |
| [^15] | [A Foundation Graph Model.](http://arxiv.org/abs/2311.03976) | 本文提出了一个基于对抗性对比学习的基础图模型FoToM，该模型通过节点和边特征排除进行图预训练，在多个领域上实现了正向迁移，并取得了显著的性能提升。 |
| [^16] | [Primacy Effect of ChatGPT.](http://arxiv.org/abs/2310.13206) | ChatGPT在选择答案时表现出初印象效应，即更倾向于选择提示中较早位置的标签作为答案。 |
| [^17] | [RealFill: Reference-Driven Generation for Authentic Image Completion.](http://arxiv.org/abs/2309.16668) | RealFill是一种个性化的生成修填模型，通过使用少量目标场景的参考图像，能够以真实、高质量、逼真的内容完成目标图像的修复。 |
| [^18] | [Convergence Guarantees for Stochastic Subgradient Methods in Nonsmooth Nonconvex Optimization.](http://arxiv.org/abs/2307.10053) | 本文研究了非平滑非凸优化中随机次梯度方法的收敛性质，并提出了一种新的框架，证明了其在单时间尺度和双时间尺度情况下的全局收敛性，包括了多种已知的SGD类型方法。对于有限和形式的目标函数，证明了这些方法能够在随机选择的步长和初始点上找到Clarke稳定点。 |
| [^19] | [Modeling Parallel Programs using Large Language Models.](http://arxiv.org/abs/2306.17281) | 本文展示了如何利用大型语言模型（LLMs）在高性能计算和科学代码的开发和分析中自动化更复杂的任务。 |
| [^20] | [Communication-minimizing Asynchronous Tensor Parallelism.](http://arxiv.org/abs/2305.13525) | 本文提出了Tensor3D，一种最小化通信消耗的三维张量计算并行化方法。它利用智能分布神经网络参数、新颖超分解方法以及通信模型，使训练速度提高了约3倍，GPU空闲时间降低了50％以上。 |
| [^21] | [A Billion-scale Foundation Model for Remote Sensing Images.](http://arxiv.org/abs/2304.05215) | 本文介绍了一个用于遥感图像的十亿级基础模型，并研究了增加模型参数数量对该模型在下游任务中的性能影响，实验显示增加模型参数数量可以显著提高性能。 |
| [^22] | [An algorithmic framework for the optimization of deep neural networks architectures and hyperparameters.](http://arxiv.org/abs/2303.12797) | 本文提出一种基于进化的有向无环图的算法框架，用于自动生成高效且灵活的深度神经网络并优化相关的超参数。此框架可用于任何能够处理混合搜索空间的元启发式算法，并在时间序列预测数据集上表现出比已有模型更好的性能。 |
| [^23] | [Checking Trustworthiness of Probabilistic Computations in a Typed Natural Deduction System.](http://arxiv.org/abs/2206.12934) | 本文介绍了一种名为TPTND的概率类型自然演算系统，该系统能够检验并推导概率计算过程的可信性，具有可检查性的优势。 |

# 详细

[^1]: 在混乱场景中高效的基于热图引导的六自由度抓取检测

    Efficient Heatmap-Guided 6-Dof Grasp Detection in Cluttered Scenes

    [https://arxiv.org/abs/2403.18546](https://arxiv.org/abs/2403.18546)

    本文提出了一种利用抓取热图引导的高效局部抓取生成方法，从全局到局部语义到点的方式推断，显著提高了抓取准确性和多样性。

    

    在机器人领域中，快速而稳健的物体抓取是至关重要的。本文指出当前大多数研究都仅利用整个观察到的点云来生成六自由度的抓取，忽略了从全局语义中挖掘的引导信息，从而限制了高质量抓取的生成和实时性能。为此，本文展示了广泛使用的热图在六自由度抓取生成效率方面被低估。因此，我们提出了一个有效的局部抓取生成器，并结合抓取热图作为引导，以全局到局部语义到点的方式进行推断。具体来说，我们应用了高斯编码和基于网格的策略来预测抓取热图以指导将局部点聚合到可抓取区域，并提供全局语义信息。此外，设计了一种新颖的非均匀锚定采样机制来提高抓取的准确性和多样性。受益于图像空间中的高效编码

    arXiv:2403.18546v1 Announce Type: cross  Abstract: Fast and robust object grasping in clutter is a crucial component of robotics. Most current works resort to the whole observed point cloud for 6-Dof grasp generation, ignoring the guidance information excavated from global semantics, thus limiting high-quality grasp generation and real-time performance. In this work, we show that the widely used heatmaps are underestimated in the efficiency of 6-Dof grasp generation. Therefore, we propose an effective local grasp generator combined with grasp heatmaps as guidance, which infers in a global-to-local semantic-to-point way. Specifically, Gaussian encoding and the grid-based strategy are applied to predict grasp heatmaps as guidance to aggregate local points into graspable regions and provide global semantic information. Further, a novel non-uniform anchor sampling mechanism is designed to improve grasp accuracy and diversity. Benefiting from the high-efficiency encoding in the image space 
    
[^2]: GeNet:一种基于图神经网络的抗噪声任务导向语义通信范式

    GeNet: A Graph Neural Network-based Anti-noise Task-Oriented Semantic Communication Paradigm

    [https://arxiv.org/abs/2403.18296](https://arxiv.org/abs/2403.18296)

    GeNet提出了一种基于图神经网络的语义通信范式，通过将数据转换为图结构、利用编码器提取语义信息并利用解码器重建信息的方法来实现抗噪声任务导向通信。

    

    传统的语义通信任务方法依赖于了解信噪比（SNR）来减轻通道噪声。然而，这些方法需要在特定的SNR条件下进行训练，需要大量时间和计算资源。在本文中，我们提出了GeNet，这是一种基于图神经网络（GNN）的语义通信范式，旨在抵抗噪声，从而促进任务导向通信（TOC）。我们提出了一种新颖的方法，首先将输入数据图像转换为图结构。然后利用基于GNN的编码器从源数据中提取语义信息。这些提取的语义信息然后通过通道传输。在接收端，使用基于GNN的解码器从源数据中重建相关的语义信息以用于TOC。通过实验评估，我们展示了GeNet在抗噪声TOC中的有效性。

    arXiv:2403.18296v1 Announce Type: cross  Abstract: Traditional approaches to semantic communication tasks rely on the knowledge of the signal-to-noise ratio (SNR) to mitigate channel noise. However, these methods necessitate training under specific SNR conditions, entailing considerable time and computational resources. In this paper, we propose GeNet, a Graph Neural Network (GNN)-based paradigm for semantic communication aimed at combating noise, thereby facilitating Task-Oriented Communication (TOC). We propose a novel approach where we first transform the input data image into graph structures. Then we leverage a GNN-based encoder to extract semantic information from the source data. This extracted semantic information is then transmitted through the channel. At the receiver's end, a GNN-based decoder is utilized to reconstruct the relevant semantic information from the source data for TOC. Through experimental evaluation, we show GeNet's effectiveness in anti-noise TOC while decoup
    
[^3]: 使用视觉评估GPT-4在胸部X光放射检查中的放射学发现检测

    Evaluating GPT-4 with Vision on Detection of Radiological Findings on Chest Radiographs

    [https://arxiv.org/abs/2403.15528](https://arxiv.org/abs/2403.15528)

    GPT-4V在胸部X光放射检查的放射学发现检测上尚未准备好应用于真实世界的诊断用途

    

    这项研究探讨了GPT-4V的应用，这是一个装备有视觉识别功能的多模态大型语言模型，用于检测来自100张胸部X光放射检查的放射学发现，并指出目前GPT-4V还不适用于解释胸部X光放射检查的实际诊断用途。

    arXiv:2403.15528v1 Announce Type: cross  Abstract: The study examines the application of GPT-4V, a multi-modal large language model equipped with visual recognition, in detecting radiological findings from a set of 100 chest radiographs and suggests that GPT-4V is currently not ready for real-world diagnostic usage in interpreting chest radiographs.
    
[^4]: Adversarial Nibbler: 一种用于识别文本到图像生成中多样化危害的开放式红队方法

    Adversarial Nibbler: An Open Red-Teaming Method for Identifying Diverse Harms in Text-to-Image Generation

    [https://arxiv.org/abs/2403.12075](https://arxiv.org/abs/2403.12075)

    批评了文本到图像生成中模型对非明显攻击的鲁棒性，提出了Adversarial Nibbler Challenge以众包多样化的提示来纠正模型的安全问题

    

    随着文本到图像（T2I）生成AI模型的崛起，评估模型对于不明显攻击的稳健性以减少生成冒犯性图像变得至关重要。通过专注于"隐性对抗"提示（触发T2I模型生成不安全图像的非明显原因），我们独立辨别出一组难以发现的安全问题，人类创造力很适合揭示这些问题。为此，我们构建了Adversarial Nibbler Challenge，这是一个红队方法，用于众包一组多样化的隐性对抗性提示。我们已汇总一套最先进的T2I模型，采用简单用户界面来识别和注释危害，并吸引广泛人群来捕捉在标准测试中可能被忽视的长尾安全问题。挑战在连续回合中进行，以实现对T2I模型中安全隐患的持续发现和分析。

    arXiv:2403.12075v1 Announce Type: cross  Abstract: With the rise of text-to-image (T2I) generative AI models reaching wide audiences, it is critical to evaluate model robustness against non-obvious attacks to mitigate the generation of offensive images. By focusing on ``implicitly adversarial'' prompts (those that trigger T2I models to generate unsafe images for non-obvious reasons), we isolate a set of difficult safety issues that human creativity is well-suited to uncover. To this end, we built the Adversarial Nibbler Challenge, a red-teaming methodology for crowdsourcing a diverse set of implicitly adversarial prompts. We have assembled a suite of state-of-the-art T2I models, employed a simple user interface to identify and annotate harms, and engaged diverse populations to capture long-tail safety issues that may be overlooked in standard testing. The challenge is run in consecutive rounds to enable a sustained discovery and analysis of safety pitfalls in T2I models.   In this pape
    
[^5]: 使用自适应估计融合高效剪枝大型语言模型

    Efficient Pruning of Large Language Model with Adaptive Estimation Fusion

    [https://arxiv.org/abs/2403.10799](https://arxiv.org/abs/2403.10799)

    提出了一种简单而高效的剪枝方法，能够自适应地模拟每个子结构的重要性，并根据多层结构的结果自适应地融合粗粒度和细粒度的估计。

    

    大型语言模型（LLMs）已经成为许多生成性下游任务中至关重要的组成部分，这导致在资源受限设备上高效部署它们成为不可避免的趋势和重大挑战。结构化剪枝是解决这一挑战的广泛应用方法。然而，当处理多个解码器层的复杂结构时，通常的方法往往采用常见的估计方法进行剪枝。这些方法导致特定下游任务精度下降。本文介绍了一种简单而有效的方法，可自适应地模拟每个子结构的重要性。同时，它可以基于复杂和多层结构的结果，自适应地融合粗粒度和细粒度的估计。我们设计的所有方面都无缝集成到端到端的剪枝框架中。与主流数据集上的最先进方法相比，我们的实验结果表明

    arXiv:2403.10799v1 Announce Type: cross  Abstract: Large language models (LLMs) have become crucial for many generative downstream tasks, leading to an inevitable trend and significant challenge to deploy them efficiently on resource-constrained devices. Structured pruning is a widely used method to address this challenge. However, when dealing with the complex structure of the multiple decoder layers, general methods often employ common estimation approaches for pruning. These approaches lead to a decline in accuracy for specific downstream tasks. In this paper, we introduce a simple yet efficient method that adaptively models the importance of each substructure. Meanwhile, it can adaptively fuse coarse-grained and finegrained estimations based on the results from complex and multilayer structures. All aspects of our design seamlessly integrate into the endto-end pruning framework. Our experimental results, compared with state-of-the-art methods on mainstream datasets, demonstrate ave
    
[^6]: 机器学习中的重要性加权简要调查

    A Short Survey on Importance Weighting for Machine Learning

    [https://arxiv.org/abs/2403.10175](https://arxiv.org/abs/2403.10175)

    重要性加权是统计学和机器学习中的基本程序，通过对目标函数或概率分布进行加权，可以保证监督学习在训练和测试分布之间差异的情况下具有统计上期望的性质

    

    重要性加权是统计学和机器学习中的一项基本程序，根据某种意义上实例的重要性对目标函数或概率分布进行加权。这一简单而有用的思想的广泛应用导致了许多重要性加权的应用。例如，据知，在关于训练和测试分布之间差异的假设下的监督学习，通过密度比的重要性加权可以保证统计上期望的性质。这项调查总结了机器学习和相关研究中重要性加权的广泛应用。

    arXiv:2403.10175v1 Announce Type: cross  Abstract: Importance weighting is a fundamental procedure in statistics and machine learning that weights the objective function or probability distribution based on the importance of the instance in some sense. The simplicity and usefulness of the idea has led to many applications of importance weighting. For example, it is known that supervised learning under an assumption about the difference between the training and test distributions, called distribution shift, can guarantee statistically desirable properties through importance weighting by their density ratio. This survey summarizes the broad applications of importance weighting in machine learning and related research.
    
[^7]: 讲述，而不是展示！：语言指导有助于在图像和视频领域之间进行转移

    Tell, Don't Show!: Language Guidance Eases Transfer Across Domains in Images and Videos

    [https://arxiv.org/abs/2403.05535](https://arxiv.org/abs/2403.05535)

    该论文提出了LaGTran框架，利用文本描述来引导知识转移，在处理具有挑战性的数据集上表现出显著优势。

    

    我们介绍了LaGTran，这是一个新颖的框架，利用即可获得或易于获取的文本描述，引导从带标签的源数据到具有域偏移的无标签目标数据的鲁棒性知识转移。受到我们观察到更富语义的文本模态具有更有利的转移特性的启发，我们设计了一个转移机制，使用源训练的文本分类器在目标文本描述上生成预测，并利用这些预测作为相应图像的监督。我们的方法以语言指导为驱动，出奇地简单易行，却在具有挑战性的数据集如GeoNet和DomainNet上显著优于以往所有方法，验证了其极其有效性。

    arXiv:2403.05535v1 Announce Type: cross  Abstract: We introduce LaGTran, a novel framework that utilizes readily available or easily acquired text descriptions to guide robust transfer of discriminative knowledge from labeled source to unlabeled target data with domain shifts. While unsupervised adaptation methods have been established to address this problem, they show limitations in handling challenging domain shifts due to their exclusive operation within the pixel-space. Motivated by our observation that semantically richer text modality has more favorable transfer properties, we devise a transfer mechanism to use a source-trained text-classifier to generate predictions on the target text descriptions, and utilize these predictions as supervision for the corresponding images. Our approach driven by language guidance is surprisingly easy and simple, yet significantly outperforms all prior approaches on challenging datasets like GeoNet and DomainNet, validating its extreme effectiven
    
[^8]: 为医药领域打造安全和对齐的大型语言模型

    Towards Safe and Aligned Large Language Models for Medicine

    [https://arxiv.org/abs/2403.03744](https://arxiv.org/abs/2403.03744)

    对医学LLMs进行了首次安全评估，并探讨了如何定义医学安全和对齐性，开发了有害医学问题数据集，评估了医学LLMs的安全性和对齐性，展示了微调是一种有效的缓解策略。

    

    大型语言模型（LLMs）的能力正在以惊人的速度进步，即使是它们的开发者也对它们的潜力和风险的深度感到困惑。尽管已经采取了初步步骤评估通用知识LLMs的安全性和对齐性，揭示了一些弱点，但据我们所知，尽管在个人健康和安全、公共健康和安全以及人权方面存在风险，医学LLMs的安全性和对齐性尚未得到评估。为此，我们进行了对医学LLMs的首次安全评估。具体而言，我们提出了医学人工智能系统的医学安全性和对齐性的定义，开发了一个有害医学问题的数据集来评估LLM的医学安全性和对齐性，评估了医学LLMs的通用安全性和对齐性，展示了微调作为一种有效的缓解策略，并讨论了更广泛的、大规模的方法。

    arXiv:2403.03744v1 Announce Type: new  Abstract: The capabilities of large language models (LLMs) have been progressing at a breathtaking speed, leaving even their own developers grappling with the depth of their potential and risks. While initial steps have been taken to evaluate the safety and alignment of general-knowledge LLMs, exposing some weaknesses, to our knowledge, the safety and alignment of medical LLMs has not been evaluated despite their risks for personal health and safety, public health and safety, and human rights. To this end, we carry out the first safety evaluation for medical LLMs. Specifically, we set forth a definition of medical safety and alignment for medical artificial intelligence systems, develop a dataset of harmful medical questions to evaluate the medical safety and alignment of an LLM, evaluate both general and medical safety and alignment of medical LLMs, demonstrate fine-tuning as an effective mitigation strategy, and discuss broader, large-scale appr
    
[^9]: ParallelPARC: 生成自然语言类比的可扩展流水线

    ParallelPARC: A Scalable Pipeline for Generating Natural-Language Analogies

    [https://arxiv.org/abs/2403.01139](https://arxiv.org/abs/2403.01139)

    设计了ParallelPARC流水线，利用大型语言模型生成复杂段落类比数据集，评估各种类比类型，并展示出人类在类比识别中的优势。

    

    Analogy-making对于人类认知至关重要，使我们能够适应新颖情境--这是当前人工智能系统仍然缺乏的能力。大多数类比数据集今天关注简单的类比（例如，词类比）；包含复杂类型类比的数据集通常是手工策划的，并且非常小。我们认为这限制了计算类比的进展。在这项工作中，我们设计了一个数据生成流水线，ParallelPARC（Parallel Paragraph Creator），利用最先进的大型语言模型（LLM）来创建基于段落的复杂类比，以及简单和具有挑战性的干扰项。我们展示了我们的流水线，并创建了ProPara-Logy，一个关于科学过程间类比的数据集。我们发布了一个由人类验证过的金标准数据集，以及一个自动生成的银标准数据集。我们在二进制和多选环境中测试了LLMs和人类对类比的识别，发现人类胜过最佳模型。

    arXiv:2403.01139v1 Announce Type: cross  Abstract: Analogy-making is central to human cognition, allowing us to adapt to novel situations -- an ability that current AI systems still lack. Most analogy datasets today focus on simple analogies (e.g., word analogies); datasets including complex types of analogies are typically manually curated and very small. We believe that this holds back progress in computational analogy. In this work, we design a data generation pipeline, ParallelPARC (Parallel Paragraph Creator) leveraging state-of-the-art Large Language Models (LLMs) to create complex, paragraph-based analogies, as well as distractors, both simple and challenging. We demonstrate our pipeline and create ProPara-Logy, a dataset of analogies between scientific processes. We publish a gold-set, validated by humans, and a silver-set, generated automatically. We test LLMs' and humans' analogy recognition in binary and multiple-choice settings, and found that humans outperform the best mod
    
[^10]: 直接与Chat-Fine-Tuned LLMs的草案模型对齐

    Direct Alignment of Draft Model for Speculative Decoding with Chat-Fine-Tuned LLMs

    [https://arxiv.org/abs/2403.00858](https://arxiv.org/abs/2403.00858)

    通过提出的框架，我们训练了一种用于Llama 2 Chat 7B或更大模型的草案模型，实现了加速推理，仅占原始大小的1.64％。

    

    文本生成与大型语言模型（LLMs）由于其自回归本质、巨大的参数数量和有限的内存带宽而被认为是内存密集型，通常导致低令牌速率。猜测解码已被提出作为LLM推理加速的解决方案。然而，在现代开源LLM系列中，例如Llama 2 7B，由于草案模型通常不可用，因此需要训练高质量的草案模型以通过猜测解码实现推理加速。在本文中，我们提出了一个简单的草案模型训练框架，用于直接与Chat-capable目标模型对齐。通过我们提出的框架，我们训练出Llama 2 Chat Drafter 115M，这是一个适用于Llama 2 Chat 7B或更大模型的草案模型，仅占原始大小的1.64％。我们的训练框架仅包括预训练、蒸馏数据集生成和使用知识蒸馏进行微调，没有额外的对齐步骤。

    arXiv:2403.00858v1 Announce Type: cross  Abstract: Text generation with Large Language Models (LLMs) is known to be memory bound due to the combination of their auto-regressive nature, huge parameter counts, and limited memory bandwidths, often resulting in low token rates. Speculative decoding has been proposed as a solution for LLM inference acceleration. However, since draft models are often unavailable in the modern open-source LLM families, e.g., for Llama 2 7B, training a high-quality draft model is required to enable inference acceleration via speculative decoding. In this paper, we propose a simple draft model training framework for direct alignment to chat-capable target models. With the proposed framework, we train Llama 2 Chat Drafter 115M, a draft model for Llama 2 Chat 7B or larger, with only 1.64\% of the original size. Our training framework only consists of pretraining, distillation dataset generation, and finetuning with knowledge distillation, with no additional align
    
[^11]: PiShield：一种适用于以需求为基础学习的NeSy框架

    PiShield: A NeSy Framework for Learning with Requirements

    [https://arxiv.org/abs/2402.18285](https://arxiv.org/abs/2402.18285)

    PiShield是第一个允许将需求集成到神经网络拓扑结构中的框架，无论输入如何都能确保满足这些需求，并可根据从业者需求在推断和/或训练时集成需求。

    

    深度学习模型在各种应用领域展现出了其优势，然而，它们往往难以满足其输出的安全需求。本文介绍了PiShield，这是第一个允许将需求集成到神经网络拓扑结构中的框架。PiShield确保满足这些需求，无论输入如何。此外，它允许根据从业者的需求在推断和/或训练时集成需求。鉴于深度学习的广泛应用，迫切需要允许在各个领域集成需求的框架。这里，我们探讨了三个应用场景：功能基因组学、自动驾驶和表格数据生成。

    arXiv:2402.18285v1 Announce Type: cross  Abstract: Deep learning models have shown their strengths in various application domains, however, they often struggle to meet safety requirements for their outputs. In this paper, we introduce PiShield, the first framework ever allowing for the integration of the requirements into the neural networks' topology. PiShield guarantees compliance with these requirements, regardless of input. Additionally, it allows for integrating requirements both at inference and/or training time, depending on the practitioners' needs. Given the widespread application of deep learning, there is a growing need for frameworks allowing for the integration of the requirements across various domains. Here, we explore three application scenarios: functional genomics, autonomous driving, and tabular data generation.
    
[^12]: MOMENT：一个开放的时间序列基础模型家族

    MOMENT: A Family of Open Time-series Foundation Models

    [https://arxiv.org/abs/2402.03885](https://arxiv.org/abs/2402.03885)

    MOMENT是一个开放的时间序列基础模型家族，通过解决时间序列数据的挑战，编制了一个大规模的公共时间序列数据集，并设计了一个基准测试来评估有限监督场景下模型的性能。

    

    我们介绍了MOMENT，一个开源的通用时间序列分析基础模型家族。在时间序列数据的预训练大模型方面存在着一些挑战，包括：（1）缺乏一个大而有凝聚力的公共时间序列存储库，以及（2）多样的时间序列特征使得多数据集的训练变得困难。此外，这些模型的实验评估标准，特别是在资源、时间和监督有限的情况下，仍处于初级阶段。（3）为解决这些挑战，我们编制了一个大而多样的公共时间序列数据集，称为时间序列堆，以系统地解决时间序列特定的挑战，以解锁大规模的多数据集预训练。最后，我们借鉴最近的工作，设计了一个基准测试来评估有限监督场景下时间序列基础模型在不同任务和数据集上的效果。在这个基准测试上的实验证明了我们的预训练模型在少量数据的情况下的有效性。

    We introduce MOMENT, a family of open-source foundation models for general-purpose time-series analysis. Pre-training large models on time-series data is challenging due to (1) the absence of a large and cohesive public time-series repository, and (2) diverse time-series characteristics which make multi-dataset training onerous. Additionally, (3) experimental benchmarks to evaluate these models, especially in scenarios with limited resources, time, and supervision, are still in their nascent stages. To address these challenges, we compile a large and diverse collection of public time-series, called the Time-series Pile, and systematically tackle time-series-specific challenges to unlock large-scale multi-dataset pre-training. Finally, we build on recent work to design a benchmark to evaluate time-series foundation models on diverse tasks and datasets in limited supervision settings. Experiments on this benchmark demonstrate the effectiveness of our pre-trained models with minimal data 
    
[^13]: 反事实效应概括：一种组合定义

    Counterfactual Effect Generalization: A Combinatorial Definition

    [https://arxiv.org/abs/2108.04376](https://arxiv.org/abs/2108.04376)

    提出了一种用于干预效应外部有效性的组合定义，揭示了效应概括的两个限制，并重新审视了原始反事实公式中的多个问题。

    

    “反事实”定义的因果效应广泛用于偏差和准确性的推导，但并非泛化性。我们提出了一种用于干预效应外部有效性（EV）的组合定义。我们首先定义了一种效应观察“背景”的概念。然后，我们根据其（可观察和不可观察的）背景集合制定了效应概括的条件。这揭示了效应概括的两个限制：（1）当效应在所有可以枚举的背景下被观察时，或者（2）当背景变得足够随机时。我们利用由此产生的组合框架重新审视了原始反事实公式中的几个问题：样本外有效性、同时估计多个效应、偏差-方差权衡、统计功效以及与当前预测和解释技术的联系。

    arXiv:2108.04376v4 Announce Type: replace-cross  Abstract: The widely used 'Counterfactual' definition of Causal Effects was derived for unbiasedness and accuracy - and not generalizability. We propose a Combinatorial definition for the External Validity (EV) of intervention effects. We first define the concept of an effect observation 'background'. We then formulate conditions for effect generalization based on their sets of (observable and unobservable) backgrounds. This reveals two limits for effect generalization: (1) when effects are observed under all their enumerable backgrounds, or, (2) when backgrounds have become sufficiently randomized. We use the resulting combinatorial framework to re-examine several issues in the original counterfactual formulation: out-of-sample validity, concurrent estimation of multiple effects, bias-variance tradeoffs, statistical power, and connections to current predictive and explaining techniques.   Methodologically, the definitions also allow us 
    
[^14]: 大型语言模型能否编写并行代码?

    Can Large Language Models Write Parallel Code?. (arXiv:2401.12554v1 [cs.DC])

    [http://arxiv.org/abs/2401.12554](http://arxiv.org/abs/2401.12554)

    本文研究了大型语言模型生成并行代码的能力。我们提出了一个基准测试集PCGBench，并使用新指标评估了几个最先进的语言模型在并行编程模型和计算问题类型上的性能。

    

    大型语言模型正变得越来越受软件开发者的欢迎。它们在多种情境下展示了对源代码的建模和生成能力，包括代码补全、摘要、翻译和查找等。然而，它们往往难以为更复杂的任务生成代码。在本文中，我们探讨了最先进的语言模型生成并行代码的能力。我们提出了一个名为PCGBench的基准测试集，其中包含420个任务，用于评估语言模型生成并行代码的能力，并对几个最先进的开源和闭源语言模型在这些任务上的性能进行评估。我们引入了一些用于比较并行代码生成性能的新指标，并使用这些指标来探究每个语言模型在不同的并行编程模型和计算问题类型上的表现。

    Large Language Models are becoming an increasingly popular tool for software development. Their ability to model and generate source code has been demonstrated in a variety of contexts, including code completion, summarization, translation, and lookup. However, they often struggle to generate code for more complex tasks. In this paper, we explore the ability of state-of-the-art language models to generate parallel code. We propose a benchmark, PCGBench, consisting of a set of 420 tasks for evaluating the ability of language models to generate parallel code, and we evaluate the performance of several state-of-the-art open- and closed-source language models on these tasks. We introduce novel metrics for comparing parallel code generation performance and use them to explore how well each LLM performs on various parallel programming models and computational problem types.
    
[^15]: 一个基础图模型

    A Foundation Graph Model. (arXiv:2311.03976v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2311.03976](http://arxiv.org/abs/2311.03976)

    本文提出了一个基于对抗性对比学习的基础图模型FoToM，该模型通过节点和边特征排除进行图预训练，在多个领域上实现了正向迁移，并取得了显著的性能提升。

    

    无监督图表示学习的主要优势是在数据或标签稀缺的情况下，可以对预训练模型进行微调。现有的方法是针对特定领域的，保持预训练和目标数据集之间的节点和边属性一致。这使得无法在其他领域进行迁移。能够在任意任务和领域上实现正向迁移的模型将成为第一个基础图模型。在这项工作中，我们使用对抗性对比学习提出了FoToM，一种基于节点和边特征排除的图预训练方法。我们使用FoToM在多个图领域上进行预训练，得到了第一个基础图模型。我们在来自多个领域的评估数据集上展示了正向迁移。在所有数据集上，性能最差时与有监督基线相当，76%的数据集在95%置信度下都显著优于有监督基线（P≤0.01），误差减少了8%至40%。

    The principal benefit of unsupervised graph representation learning is that a pre-trained model can be fine-tuned where data or labels are scarce. Existing approaches are domain specific, maintaining consistent node and edge attributes across the pre-training and target datasets. This precludes transfer to other domains. A model capable of positive transfer on arbitrary tasks and domains would represent the first foundation graph model.  In this work we use adversarial contrastive learning to present FoToM, a graph pre-training method based on node and edge feature exclusion. We use FoToM to pre-train models over multiple graph domains, producing the first foundation graph models. We demonstrate positive transfer on evaluation datasets from multiple domains, including domains not present in pre-training data. On all datasets performance is at worst on-par and on 76% significantly better than a supervised baseline ($P \leq 0.01$), with an 8 to 40% reduction in error at 95% confidence. C
    
[^16]: ChatGPT的初印象效应

    Primacy Effect of ChatGPT. (arXiv:2310.13206v1 [cs.CL])

    [http://arxiv.org/abs/2310.13206](http://arxiv.org/abs/2310.13206)

    ChatGPT在选择答案时表现出初印象效应，即更倾向于选择提示中较早位置的标签作为答案。

    

    通过在ChatGPT上进行实验和分析，我们研究了ChatGPT的初印象效应，即选择较早位置的标签作为答案的倾向。我们发现：i）ChatGPT的决策对提示中标签的顺序敏感；ii）ChatGPT更倾向于选择较早位置的标签作为答案。我们希望我们的实验和分析能为构建更可靠的基于ChatGPT的解决方案提供额外的见解。

    Instruction-tuned large language models (LLMs), such as ChatGPT, have led to promising zero-shot performance in discriminative natural language understanding (NLU) tasks. This involves querying the LLM using a prompt containing the question, and the candidate labels to choose from. The question-answering capabilities of ChatGPT arise from its pre-training on large amounts of human-written text, as well as its subsequent fine-tuning on human preferences, which motivates us to ask: Does ChatGPT also inherits humans' cognitive biases? In this paper, we study the primacy effect of ChatGPT: the tendency of selecting the labels at earlier positions as the answer. We have two main findings: i) ChatGPT's decision is sensitive to the order of labels in the prompt; ii) ChatGPT has a clearly higher chance to select the labels at earlier positions as the answer. We hope that our experiments and analyses provide additional insights into building more reliable ChatGPT-based solutions. We release the
    
[^17]: RealFill：参考驱动的真实图像修复生成方法

    RealFill: Reference-Driven Generation for Authentic Image Completion. (arXiv:2309.16668v1 [cs.CV])

    [http://arxiv.org/abs/2309.16668](http://arxiv.org/abs/2309.16668)

    RealFill是一种个性化的生成修填模型，通过使用少量目标场景的参考图像，能够以真实、高质量、逼真的内容完成目标图像的修复。

    

    最近，生成图像的进展带来了能够在未知区域生成高质量、逼真图像内容的外拓和修填模型，但这些模型产生的内容是不真实的，因为模型缺乏关于真实场景的足够背景信息。在本文中，我们提出了一种新颖的真实图像修复生成方法RealFill，它通过填充图像中缺失区域使其内容真正应在的内容。RealFill是一种个性化的生成修填模型，仅使用几张目标场景的参考图像进行个性化。这些参考图像不需要与目标图像对齐，可以通过不同的视角、光照条件、摄像机光圈或图像风格拍摄。个性化后，RealFill能够以视觉上引人注目的内容完成目标图像，并且忠实于原始场景。我们在一个全面且具挑战性的图像修复基准上对RealFill进行评估。

    Recent advances in generative imagery have brought forth outpainting and inpainting models that can produce high-quality, plausible image content in unknown regions, but the content these models hallucinate is necessarily inauthentic, since the models lack sufficient context about the true scene. In this work, we propose RealFill, a novel generative approach for image completion that fills in missing regions of an image with the content that should have been there. RealFill is a generative inpainting model that is personalized using only a few reference images of a scene. These reference images do not have to be aligned with the target image, and can be taken with drastically varying viewpoints, lighting conditions, camera apertures, or image styles. Once personalized, RealFill is able to complete a target image with visually compelling contents that are faithful to the original scene. We evaluate RealFill on a new image completion benchmark that covers a set of diverse and challenging
    
[^18]: 非平滑非凸优化中随机次梯度方法的收敛性保证

    Convergence Guarantees for Stochastic Subgradient Methods in Nonsmooth Nonconvex Optimization. (arXiv:2307.10053v1 [math.OC])

    [http://arxiv.org/abs/2307.10053](http://arxiv.org/abs/2307.10053)

    本文研究了非平滑非凸优化中随机次梯度方法的收敛性质，并提出了一种新的框架，证明了其在单时间尺度和双时间尺度情况下的全局收敛性，包括了多种已知的SGD类型方法。对于有限和形式的目标函数，证明了这些方法能够在随机选择的步长和初始点上找到Clarke稳定点。

    

    本文研究了随机梯度下降（SGD）方法及其变种在训练由非平滑激活函数构建的神经网络中的收敛性质。我们提出了一种新颖的框架，为更新动量项和变量的步长分配了不同的时间尺度。在一些温和的条件下，我们证明了我们提出的框架在单时间尺度和双时间尺度情况下的全局收敛性。我们还证明了我们提出的框架包含了很多已知的SGD类型方法，包括heavy-ball SGD、SignSGD、Lion、normalized SGD和clipped SGD。此外，当目标函数采用有限和形式时，我们基于我们提出的框架证明了这些SGD类型方法的收敛性质。特别地，在温和的假设下，我们证明了这些SGD类型方法在随机选择的步长和初始点上能够找到目标函数的Clarke稳定点。

    In this paper, we investigate the convergence properties of the stochastic gradient descent (SGD) method and its variants, especially in training neural networks built from nonsmooth activation functions. We develop a novel framework that assigns different timescales to stepsizes for updating the momentum terms and variables, respectively. Under mild conditions, we prove the global convergence of our proposed framework in both single-timescale and two-timescale cases. We show that our proposed framework encompasses a wide range of well-known SGD-type methods, including heavy-ball SGD, SignSGD, Lion, normalized SGD and clipped SGD. Furthermore, when the objective function adopts a finite-sum formulation, we prove the convergence properties for these SGD-type methods based on our proposed framework. In particular, we prove that these SGD-type methods find the Clarke stationary points of the objective function with randomly chosen stepsizes and initial points under mild assumptions. Preli
    
[^19]: 使用大型语言模型建模并行程序

    Modeling Parallel Programs using Large Language Models. (arXiv:2306.17281v1 [cs.DC])

    [http://arxiv.org/abs/2306.17281](http://arxiv.org/abs/2306.17281)

    本文展示了如何利用大型语言模型（LLMs）在高性能计算和科学代码的开发和分析中自动化更复杂的任务。

    

    随着我们进入异构计算时代，高性能计算（HPC）中的并行软件代码在复杂性和规模上不断增长。新兴的硬件和编程范式使得开发、优化和维护并行软件对开发人员来说变得繁重。缓解这些负担的一种方式是使用自动化开发和分析工具。这些工具可以为开发人员执行复杂和/或补救性的任务，提高他们的生产力并减少错误的可能性。迄今为止，用于代码开发和性能分析的这些工具在执行任务的复杂度方面受到限制。然而，随着语言建模的最新进展和现在在线上可用的大量与代码相关的数据，这些工具开始利用预测性语言模型来自动完成更复杂的任务。在本文中，我们展示了如何将大型语言模型（LLMs）应用于高性能和科学代码的特定任务中。我们训练了LLM模型

    Parallel software codes in high performance computing (HPC) continue to grow in complexity and scale as we enter the exascale era. A diverse set of emerging hardware and programming paradigms make developing, optimizing, and maintaining parallel software burdensome for developers. One way to alleviate some of these burdens is with automated development and analysis tools. Such tools can perform complex and/or remedial tasks for developers that increase their productivity and decrease the chance for error. So far, such tools for code development and performance analysis have been limited in the complexity of tasks they can perform. However, with recent advancements in language modeling, and the wealth of code related data that is now available online, these tools have started to utilize predictive language models to automate more complex tasks. In this paper, we show how large language models (LLMs) can be applied to tasks specific to high performance and scientific codes. We train LLMs
    
[^20]: 最小化通信的异步张量并行性

    Communication-minimizing Asynchronous Tensor Parallelism. (arXiv:2305.13525v1 [cs.LG])

    [http://arxiv.org/abs/2305.13525](http://arxiv.org/abs/2305.13525)

    本文提出了Tensor3D，一种最小化通信消耗的三维张量计算并行化方法。它利用智能分布神经网络参数、新颖超分解方法以及通信模型，使训练速度提高了约3倍，GPU空闲时间降低了50％以上。

    

    随着现代神经网络规模扩大到数十亿个参数，设计能够在多GPU集群上高效训练这些网络的并行算法变得至关重要。本文提出了Tensor3D，一种全新的三维（3D）张量计算并行化方法，旨在最小化大型多十亿参数模型的并行训练中由通信引起的空闲时间。首先，我们引入了一种智能的神经网络参数分布方式，消除了为满足各层数据依赖而需要的通信。然后，我们提出了一种新颖的并行训练过程超分解方法，利用它可以显著提高通信与计算的重叠度，从而减少GPU空闲时间。最后，我们提出了一种通信模型，帮助用户为给定的神经网络识别通信最优的可用硬件资源分解。 对于256 A100 GPU上的28B参数CNN，在本文的 Tensor3D 方法下，训练速度提高了约3倍，与以前的方法相比 GPU 空闲时间也降低了约50％以上。

    As state-of-the-art neural networks scale to billions of parameters, designing parallel algorithms that can train these networks efficiently on multi-GPU clusters has become critical. This paper presents Tensor3D, a novel three-dimensional (3D) approach to parallelize tensor computations, that strives to minimize the idle time incurred due to communication in parallel training of large multi-billion parameter models. First, we introduce an intelligent distribution of neural network parameters across GPUs that eliminates communication required for satisfying data dependencies of individual layers. Then, we propose a novel overdecomposition of the parallel training process, using which we achieve significant overlap of communication with computation, thereby reducing GPU idle time. Finally, we present a communication model, which helps users identify communication optimal decompositions of available hardware resources for a given neural network. For a 28B parameter CNN on 256 A100 GPUs, 
    
[^21]: 一种用于遥感图像的十亿级基础模型

    A Billion-scale Foundation Model for Remote Sensing Images. (arXiv:2304.05215v1 [cs.CV])

    [http://arxiv.org/abs/2304.05215](http://arxiv.org/abs/2304.05215)

    本文介绍了一个用于遥感图像的十亿级基础模型，并研究了增加模型参数数量对该模型在下游任务中的性能影响，实验显示增加模型参数数量可以显著提高性能。

    

    随着基础模型在视觉任务中的潜力引起了广泛关注，先对这些模型进行预训练已成为一个关键步骤。预训练基础模型的三个关键因素是预训练方法、预训练数据集的大小以及模型参数的数量。最近，遥感领域的研究主要关注预训练方法和数据集的大小，对模型参数的数量关注较少。本文通过研究增加模型参数数量对基础模型在旋转目标检测和语义分割等下游任务中性能的影响来弥补这一空白。我们使用不同数量参数（包括86M、605.26M、1.3B和2.4B）的基础模型进行预训练，以确定参数增加是否会提高下游任务的性能。据我们所知，这是第一个用于遥感图像的十亿级基础模型。我们的实验表明，增加模型参数数量可以显著提高下游任务的性能。此外，我们还介绍了一个包含10亿个遥感图像的新的预训练数据集，并向研究社区公开。

    As the potential of foundation models in visual tasks has garnered significant attention, pretraining these models before downstream tasks has become a crucial step. The three key factors in pretraining foundation models are the pretraining method, the size of the pretraining dataset, and the number of model parameters. Recently, research in the remote sensing field has focused primarily on the pretraining method and the size of the dataset, with limited emphasis on the number of model parameters. This paper addresses this gap by examining the effect of increasing the number of model parameters on the performance of foundation models in downstream tasks such as rotated object detection and semantic segmentation. We pretrained foundation models with varying numbers of parameters, including 86M, 605.26M, 1.3B, and 2.4B, to determine whether performance in downstream tasks improved with an increase in parameters. To the best of our knowledge, this is the first billion-scale foundation mod
    
[^22]: 一种用于深度神经网络架构和超参数优化的算法框架

    An algorithmic framework for the optimization of deep neural networks architectures and hyperparameters. (arXiv:2303.12797v1 [cs.NE])

    [http://arxiv.org/abs/2303.12797](http://arxiv.org/abs/2303.12797)

    本文提出一种基于进化的有向无环图的算法框架，用于自动生成高效且灵活的深度神经网络并优化相关的超参数。此框架可用于任何能够处理混合搜索空间的元启发式算法，并在时间序列预测数据集上表现出比已有模型更好的性能。

    

    本文提出一种算法框架，用于自动生成高效的深度神经网络并优化相关的超参数。该框架基于进化的有向无环图(DAG)，定义了比文献中现有的搜索空间更为灵活的搜索空间，允许混合使用传统操作，如卷积、循环和密集层，以及较为新颖的操作，如自注意力机制。基于该搜索空间，我们提出了邻域搜索算子和演化搜索算子，以优化网络的架构和超参数。这些搜索算子可与任何能够处理混合搜索空间的元启发式算法一起使用。我们在时间序列预测数据集上使用进化算法测试了我们的算法框架。结果表明，我们的框架能够找到在许多数据集上性能优于基准模型的模型。

    In this paper, we propose an algorithmic framework to automatically generate efficient deep neural networks and optimize their associated hyperparameters. The framework is based on evolving directed acyclic graphs (DAGs), defining a more flexible search space than the existing ones in the literature. It allows mixtures of different classical operations: convolutions, recurrences and dense layers, but also more newfangled operations such as self-attention. Based on this search space we propose neighbourhood and evolution search operators to optimize both the architecture and hyper-parameters of our networks. These search operators can be used with any metaheuristic capable of handling mixed search spaces. We tested our algorithmic framework with an evolutionary algorithm on a time series prediction benchmark. The results demonstrate that our framework was able to find models outperforming the established baseline on numerous datasets.
    
[^23]: 在类型化自然演算系统中检验概率计算的可信性

    Checking Trustworthiness of Probabilistic Computations in a Typed Natural Deduction System. (arXiv:2206.12934v2 [cs.LO] UPDATED)

    [http://arxiv.org/abs/2206.12934](http://arxiv.org/abs/2206.12934)

    本文介绍了一种名为TPTND的概率类型自然演算系统，该系统能够检验并推导概率计算过程的可信性，具有可检查性的优势。

    

    本文介绍了一种名为 TPTND 的概率类型自然演算系统，该系统旨在推导有关概率计算过程的可信性属性，例如当今人工智能应用程序中的那些属性。TPTND 中的推导被解释为从给定的分类分布中提取 n 个可能复杂输出样本的过程。我们将这些输出样本的可信性形式化为一种假设测试，即计算出现有的频率与预期的概率之间的距离。这个演算系统的主要优势在于能够检查这种可信性的概念。我们为推理过程中出现的项提供了计算语义，并定义了逻辑运算符以及信任运算符的引入和消解规则。我们重点介绍了系统的结构和元理论属性，尤其是能够确定哪些项演化和逻辑规则应用时，计算仍然是可信的。

    In this paper we present the probabilistic typed natural deduction calculus TPTND, designed to reason about and derive trustworthiness properties of probabilistic computational processes, like those underlying current AI applications. Derivability in TPTND is interpreted as the process of extracting $n$ samples of possibly complex outputs with a certain frequency from a given categorical distribution. We formalize trust for such outputs as a form of hypothesis testing on the distance between such frequency and the intended probability. The main advantage of the calculus is to render such notion of trustworthiness checkable. We present a computational semantics for the terms over which we reason and then the semantics of TPTND, where logical operators as well as a Trust operator are defined through introduction and elimination rules. We illustrate structural and metatheoretical properties, with particular focus on the ability to establish under which term evolutions and logical rules ap
    

