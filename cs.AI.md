# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Chain-of-Thought Reasoning is a Policy Improvement Operator.](http://arxiv.org/abs/2309.08589) | 大型语言模型SECToR通过链式思考推理成功地自学新技能， |
| [^2] | [Compositional Foundation Models for Hierarchical Planning.](http://arxiv.org/abs/2309.08587) | 本研究提出了一种基于组合式基础模型的层次规划方法，通过利用语言、视觉和动作数据的多个专家模型，解决了长期目标任务。通过符号计划、视频扩散和逆动力学模型的结合，实现了在新环境中做出有效决策的能力。 |
| [^3] | [How Transferable are Attribute Controllers on Pretrained Multilingual Translation Models?.](http://arxiv.org/abs/2309.08565) | 本文研究了如何将预训练的多语言翻译模型中的属性控制器迁移到没有监督数据的语言。通过全面分析不同数据场景下的训练和推断时控制技术，揭示了它们在零样本性能和领域鲁棒性上的相对优势和劣势。 |
| [^4] | [Deep Reinforcement Learning for Efficient and Fair Allocation of Health Care Resources.](http://arxiv.org/abs/2309.08560) | 本研究使用强化学习方法，通过整合个体患者的疾病进展和患者间的相互作用效应，来优化医疗资源的分配策略，旨在提高分配的公平性和整体患者结果。 |
| [^5] | [HINT: Healthy Influential-Noise based Training to Defend against Data Poisoning Attacks.](http://arxiv.org/abs/2309.08549) | 本论文提出了一种名为健康影响力噪声训练的高效稳健训练方法，该方法使用影响函数制造了有助于加强分类模型对抗数据污染攻击的健康噪声，并且在仅修改训练数据的子集时也能有效运行。 |
| [^6] | [When do Generative Query and Document Expansions Fail? A Comprehensive Study Across Methods, Retrievers, and Datasets.](http://arxiv.org/abs/2309.08541) | 通过对11种扩展技术、12个不同分布变化的数据集和24个检索模型的全面分析，我们发现使用大型语言模型进行查询或文档扩展的效果与检索器性能相关，对于弱模型来说扩展提高了分数，但对于强模型来说扩展通常会损害分数。 |
| [^7] | [Visual Speech Recognition for Low-resource Languages with Automatic Labels From Whisper Model.](http://arxiv.org/abs/2309.08535) | 本文提出了一种利用Whisper模型从未标注的多语言视听数据自动标注的方法，实现了在低资源语言中的视觉语音识别，并证明了该方法可以获得与人工标注相似的性能。 |
| [^8] | [Connecting Large Language Models with Evolutionary Algorithms Yields Powerful Prompt Optimizers.](http://arxiv.org/abs/2309.08532) | 本文提出了一种通过连接大型语言模型和进化算法进行提示优化的框架，名为EvoPrompt。通过利用大型语言模型的语言处理能力和进化算法的优化性能，EvoPrompt可以自动化处理需要连贯和可读性良好的提示，提高大型语言模型的性能。 |
| [^9] | [SCT: A Simple Baseline for Parameter-Efficient Fine-Tuning via Salient Channels.](http://arxiv.org/abs/2309.08513) | 本文提出了一种名为“显著通道微调”的简单而有效的方法，通过选择特征图中的部分通道进行微调，实现在低数据资源场景下低参数成本的高效微调，并在多个下游任务中优于全面微调方法。 |
| [^10] | [HealthFC: A Dataset of Health Claims for Evidence-Based Medical Fact-Checking.](http://arxiv.org/abs/2309.08503) | 本文介绍了一份新的健康声明数据集，其中包含了750个由医学专家标注的健康相关声明，并提供了来自临床研究的证据支持。该数据集可用于机器学习任务，包括证据检索、真实性预测和解释生成。 |
| [^11] | [P-ROCKET: Pruning Random Convolution Kernels for Time Series Classification.](http://arxiv.org/abs/2309.08499) | 本研究提出了一种名为P-ROCKET的方法，通过在特征选择的角度删除卷积核，从而实现对时间序列分类中的随机卷积核进行剪枝。 |
| [^12] | [Using Large Language Models for Knowledge Engineering (LLMKE): A Case Study on Wikidata.](http://arxiv.org/abs/2309.08491) | 这项工作探索了使用大型语言模型（LLMs）进行知识工程任务的应用。通过将主题和关系对转化为字符串格式，并将它们链接到相应的Wikidata QID上，开发了LLMKE流水线方法。研究发现，LLMs的知识因领域而异，并需要进一步实验以确定其在自动知识库补全和修正方面的应用条件。此外，结果还显示了LLMs在协作知识工程方面的有希望的贡献。 |
| [^13] | [XFedHunter: An Explainable Federated Learning Framework for Advanced Persistent Threat Detection in SDN.](http://arxiv.org/abs/2309.08485) | XFedHunter是一种用于SDN中检测持久性高级威胁的可解释联邦学习框架，能够通过ML预测的解释来揭示攻击者的特征。 |
| [^14] | [VulnSense: Efficient Vulnerability Detection in Ethereum Smart Contracts by Multimodal Learning with Graph Neural Network and Language Model.](http://arxiv.org/abs/2309.08474) | VulnSense框架使用多模态学习方法，通过基于图形和语言模型的深度学习，高效检测以太坊智能合约中的漏洞。与现有方法相比，该框架在准确性和效果方面具有优势。 |
| [^15] | [Explaining Search Result Stances to Opinionated People.](http://arxiv.org/abs/2309.08460) | 这项研究探讨了向有观点的人解释搜索结果立场的效果，发现立场标签和解释可以帮助用户消费更多不同的搜索结果，但没有发现系统性观点改变的证据。 |
| [^16] | [Toward responsible face datasets: modeling the distribution of a disentangled latent space for sampling face images from demographic groups.](http://arxiv.org/abs/2309.08442) | 本文提出了一种方法，通过建模和采样分解潜空间的方法来生成任意组合的人口群体，以解决现代人脸识别系统中数据集偏见导致的不公平关注问题。 |
| [^17] | [Learning by Self-Explaining.](http://arxiv.org/abs/2309.08395) | 学习通过自我解释（LSX）是一种新的学习范式，通过给予解释和批评者的反馈来改进学习者的性能。这种方法适用于图像分类等基本任务，并有潜力在人工智能研究中发挥作用。 |
| [^18] | [M$^3$Net: Multilevel, Mixed and Multistage Attention Network for Salient Object Detection.](http://arxiv.org/abs/2309.08365) | 本研究提出了M$^3$Net，一种用于显著目标检测的多级、混合和多阶段注意力网络。通过引入多尺度交互块和混合注意力块，该方法能够提高显著区域的检测性能并准确定位复杂对象的细节。 |
| [^19] | [Data Distribution Bottlenecks in Grounding Language Models to Knowledge Bases.](http://arxiv.org/abs/2309.08345) | 本文通过实验调查揭示了语言模型在与知识库进行连接时的数据分布瓶颈，包括推广到未见域、适应语言变体和在不同数据集之间的可转移性等方面。即使采用数据增强技术，先进的语言模型在多个方面表现出较差的性能。 |
| [^20] | [Let's Predict Who Will Move to a New Job.](http://arxiv.org/abs/2309.08333) | 本文讨论了如何使用机器学习来预测谁会换工作，包括数据预处理和使用多种ML算法。为了提高性能，使用了合成少数过采样技术。评估模型时使用了精度、召回率、F1-Score和准确率等指标。 |
| [^21] | [Large Intestine 3D Shape Refinement Using Point Diffusion Models for Digital Phantom Generation.](http://arxiv.org/abs/2309.08289) | 本研究利用几何深度学习和去噪扩散概率模型优化大肠的分割结果，并结合先进的表面重构模型，实现对大肠3D形状的精化恢复。 |
| [^22] | [Quantitative and Qualitative Evaluation of Reinforcement Learning Policies for Autonomous Vehicles.](http://arxiv.org/abs/2309.08254) | 本文使用强化学习算法（PPO）针对自主驾驶车辆的选择进行了优化，通过最小化时间和污染来缓解交通阻塞问题，经实证分析和定性评估证明了方法的有效性和实用性。 |
| [^23] | [A Geometric Perspective on Autoencoders.](http://arxiv.org/abs/2309.08247) | 本文从几何角度研究了自编码器框架，并提出了解决多解和畸变表示问题的几何方法。 |
| [^24] | [VERSE: Virtual-Gradient Aware Streaming Lifelong Learning with Anytime Inference.](http://arxiv.org/abs/2309.08227) | 这项研究提出了一种具有实时推理能力的流式终身学习方法，采用虚拟梯度进行连续表示学习，借助语义记忆来抑制灾难性遗忘，并在多样化的数据上进行了广泛实验。 |
| [^25] | [Using Large Language Model to Solve and Explain Physics Word Problems Approaching Human Level.](http://arxiv.org/abs/2309.08182) | 本研究证明，使用大型语言模型(如GPT3.5)可以解决和解释物理词问题，通过对物理知识进行计算和推理，实现了接近人类水平的解决率。此外，该模型还能够总结涉及的知识、生成解释，并创造新的物理词问题。 |
| [^26] | [Unveiling Invariances via Neural Network Pruning.](http://arxiv.org/abs/2309.08171) | 该论文提出了一种通过神经网络剪枝来学习捕捉数据相关的不变性的新型网络架构的框架。实验证明，这种学习的网络架构在视觉和表格数据集上都比密集神经网络表现出色，不仅效率高，而且效果好。 |
| [^27] | [To Predict or to Reject: Causal Effect Estimation with Uncertainty on Networked Data.](http://arxiv.org/abs/2309.08165) | 本文提出了一种基于不确定性的图深度核学习框架来处理网络数据上因果效应估计中的正性假设违反问题，并在实验证明了该方法的优越性。 |
| [^28] | [Investigating the Applicability of Self-Assessment Tests for Personality Measurement of Large Language Models.](http://arxiv.org/abs/2309.08163) | 研究发现，使用自我评估测试对大型语言模型的人格进行测量时，不同的提示会导致非常不同的人格得分，因此缺乏客观标准来判断哪个提示更正确。 |
| [^29] | [Find What You Want: Learning Demand-conditioned Object Attribute Space for Demand-driven Navigation.](http://arxiv.org/abs/2309.08138) | 该论文提出了一种称为需求驱动导航的方法，利用用户的需求与场景中的对象属性空间进行导航决策，并解决了在实际情况中用户无法知道对象名称或指定对象不存在的问题。 |
| [^30] | ["I'm Not Confident in Debiasing AI Systems Since I Know Too Little": Teaching AI Creators About Gender Bias Through Hands-on Tutorials.](http://arxiv.org/abs/2309.08121) | 本文通过实践教程的设计，提高了AI创作者对性别偏见的认识和知识，弥补了传统教育的不足，为未来研究和设计工作提供了指导。 |
| [^31] | [Data-Driven Goal Recognition in Transhumeral Prostheses Using Process Mining Techniques.](http://arxiv.org/abs/2309.08106) | 该研究通过使用时间序列数据和过程挖掘技术，实现了在肱上假肢中的数据驱动目标识别。实验结果表明，该方法在精确度和召回率上显著优于机器学习技术，并且在错误时表现出较低的自信度。 |
| [^32] | [Research on Joint Representation Learning Methods for Entity Neighborhood Information and Description Information.](http://arxiv.org/abs/2309.08100) | 该研究提出了一种联合表示学习模型，结合实体邻域信息和描述信息，解决了编程设计课程知识图谱中嵌入效果不佳的问题，并在实验中取得了优于其他基线模型的性能表现。 |
| [^33] | [Fast and Accurate Deep Loop Closing and Relocalization for Reliable LiDAR SLAM.](http://arxiv.org/abs/2309.08086) | 本文提出了一个名为LCR-Net的多头网络，利用新颖的特征提取和姿态感知机制来快速准确地处理循环关闭和位置再定位任务。实验结果表明，LCR-Net在候选检索、闭环点云配准和多数据集连续再定位等任务中表现优异，超过了当前最先进的方法，并具有出色的泛化能力。 |
| [^34] | [Retrieval-Augmented Text-to-Audio Generation.](http://arxiv.org/abs/2309.08051) | 这篇论文提出了一种检索增强的文本到音频生成方法，用于解决长尾文本到音频生成的问题。通过利用检索到的相关文本-音频数据作为额外条件，从而增强了模型的学习能力，在AudioCaps数据集上取得了最先进的结果。 |
| [^35] | [Padding Aware Neurons.](http://arxiv.org/abs/2309.08048) | 填充感知神经元（PANs）是一种卷积模型中常见的过滤器，它专注于对输入边界位置的特征化和识别，并且对模型性能有显著影响。 |
| [^36] | [Traveling Waves Encode the Recent Past and Enhance Sequence Learning.](http://arxiv.org/abs/2309.08045) | 本论文介绍了Wave-RNN (wRNN)模型，展示了旅行波机制如何有效地编码最近的过去，并在合成记忆任务中比波动模型表现更好。 |
| [^37] | [Towards Large-scale Building Attribute Mapping using Crowdsourced Images: Scene Text Recognition on Flickr and Problems to be Solved.](http://arxiv.org/abs/2309.08042) | 本研究使用Flickr图像和场景文本识别技术，解决了将众包街景图像应用于建筑属性映射的挑战，并发现了与此任务相关的重大问题，包括小文本区域、缺乏真实标签和建筑不匹配的问题。 |
| [^38] | [BEA: Revisiting anchor-based object detection DNN using Budding Ensemble Architecture.](http://arxiv.org/abs/2309.08036) | 本文提出了一种新型简化的集合结构BEA用于锚点目标检测模型，并通过改进置信度得分的校准与降低不确定性误差的损失函数，提高了模型准确性。 |
| [^39] | [Vision-based Analysis of Driver Activity and Driving Performance Under the Influence of Alcohol.](http://arxiv.org/abs/2309.08021) | 该论文介绍了一项研究，通过使用多种传感器，研究了急性酒精摄入对驾驶性能的影响，并通过识别酒驾行为来减少酒驾事故。 |
| [^40] | [An Empirical Evaluation of Prompting Strategies for Large Language Models in Zero-Shot Clinical Natural Language Processing.](http://arxiv.org/abs/2309.08008) | 该论文通过对五个临床自然语言处理任务的实验研究，评估了不同提示工程方法在大型语言模型上的效果，为解锁临床领域中的知识提供了指导。 |
| [^41] | [An Automated Machine Learning Approach for Detecting Anomalous Peak Patterns in Time Series Data from a Research Watershed in the Northeastern United States Critical Zone.](http://arxiv.org/abs/2309.07992) | 本文提出了一个自动化机器学习框架，用于检测美国东北地区临界地带研究流域传感器生成的时间序列数据中的异常峰值模式。通过合成生成带有标记的数据集和自动超参数优化机制，该框架克服了标记数据和选择合适的深度学习模型的挑战。 |
| [^42] | [Viewpoint Textual Inversion: Unleashing Novel View Synthesis with Pretrained 2D Diffusion Models.](http://arxiv.org/abs/2309.07986) | 本研究展示了通过预训练的2D图像扩散模型，可以从仅有2D监督的情况下提取出3D结构信息，并利用该信息进行3D视觉任务。通过观点神经文本倒置（ViewNeTI）方法，我们可以控制生成图像中对象的3D视点，有效解决新颖视图合成问题，并在单视图情况下具有良好的语义细节和逼真度。 |
| [^43] | [A Data Source for Reasoning Embodied Agents.](http://arxiv.org/abs/2309.07974) | 本研究提出了一个与体验智能体集成的新数据生成器，用于机器推理。该生成器生成的数据包括模板化的文本查询和答案，并与编码为数据库的世界状态相匹配。通过实验发现，当前模型可以回答一些关于世界状态的问题，但在其他问题上存在困难。 |
| [^44] | [TiBGL: Template-induced Brain Graph Learning for Functional Neuroimaging Analysis.](http://arxiv.org/abs/2309.07947) | TiBGL是一种模板引导的脑图学习框架，用于功能性神经影像分析。它具有判别和可解释能力，旨在通过学习功能连接数据的有用特征来改进神经疾病的诊断效率。 |
| [^45] | [Masked Generative Modeling with Enhanced Sampling Scheme.](http://arxiv.org/abs/2309.07945) | 本文提出了一种增强的采样方案 (ESS)，用于掩码非自回归生成建模。该方案能够确保样本的多样性和保真度，并由三个阶段组成：简单迭代解码、关键反向采样和关键重采样。简单迭代解码用于采样标记集，关键反向采样和关键重采样用于掩盖不真实的标记并重建被掩盖的标记，以提高采样的保真度。 |
| [^46] | [An Assessment of ChatGPT on Log Data.](http://arxiv.org/abs/2309.07938) | ChatGPT在日志数据上的性能有限，回复缺乏一致性且存在可扩展性问题。 |
| [^47] | [Landscape-Sketch-Step: An AI/ML-Based Metaheuristic for Surrogate Optimization Problems.](http://arxiv.org/abs/2309.07936) | Landscape-Sketch-Step是一种基于AI/ML的元启发式方法，结合了机器学习、随机优化和强化学习技术，用于解决成本函数评估昂贵、不可访问或禁止的代理优化问题。 |
| [^48] | [Racing Control Variable Genetic Programming for Symbolic Regression.](http://arxiv.org/abs/2309.07934) | 提出了一种称为Racing Control Variable Genetic Programming (Racing-CVGP) 的方法，它通过同时进行多个实验计划来加速符号回归过程，并克服了固定实验计划选择不佳导致发现过程延迟的限制。 |
| [^49] | [Generative AI.](http://arxiv.org/abs/2309.07930) | "生成型人工智能"指的是能够从训练数据中生成新颖有意义内容的计算技术，如文本、图像或音频。本文提供了生成型人工智能在社会技术系统中的概念，并介绍了模型、系统和应用的示例。同时，提出了当前生成型人工智能的限制，并提出了对商业与信息系统工程研究的议程，包括研究机会和挑战。 |
| [^50] | [Hierarchical Audio-Visual Information Fusion with Multi-label Joint Decoding for MER 2023.](http://arxiv.org/abs/2309.07925) | 本文提出了一个新颖的框架，用于识别离散和维度情绪，并在MER 2023数据集上取得了最先进的性能和第三的排名。 |
| [^51] | [The Rise and Potential of Large Language Model Based Agents: A Survey.](http://arxiv.org/abs/2309.07864) | 基于大型语言模型的代理的崛起和潜力：一项调查。大型语言模型被认为是构建通用人工智能代理的潜在催化剂，许多研究已经取得重要进展。 |
| [^52] | [Collectionless Artificial Intelligence.](http://arxiv.org/abs/2309.06938) | 本文提出了无集合原则的学习协议的思路，其中机器在环境交互背景中掌握认知技能，避免了数据集集中化的风险。 |
| [^53] | [Uncertainty-aware Traffic Prediction under Missing Data.](http://arxiv.org/abs/2309.06800) | 本研究提出了一种考虑不确定性的交通预测方法，可以处理缺失数据和测量不确定性，并适用于风险敏感任务和决策导向问题。 |
| [^54] | [Dynamic Spectrum Mixer for Visual Recognition.](http://arxiv.org/abs/2309.06721) | 动态频谱混合器（DSM）是一种内容自适应且计算效率高的结构，通过离散余弦变换表示令牌之间的交互，能够学习长期的空间依赖性。它还引入了动态频谱权重生成层作为频谱带选择器，以强调信息的重要程度。 |
| [^55] | [R^3: On-device Real-Time Deep Reinforcement Learning for Autonomous Robotics.](http://arxiv.org/abs/2308.15039) | R^3是一种在自主机器人中应用的基于设备的实时深度强化学习训练方法，它通过动态批量大小和回放缓冲区大小的优化，实现了在时间和算法性能之间的平衡，并有效地管理了内存和算法性能。 |
| [^56] | [MindMap: Knowledge Graph Prompting Sparks Graph of Thoughts in Large Language Models.](http://arxiv.org/abs/2308.09729) | 本论文通过使用知识图谱来激发大型语言模型，解决了整合新知识、产生幻觉和决策过程不透明等问题，并通过生成思维导图展示了模型的推理路径，实验证明这种方法可以取得显著的实证增益。 |
| [^57] | [DCNFIS: Deep Convolutional Neuro-Fuzzy Inference System.](http://arxiv.org/abs/2308.06378) | 本文介绍了一种新的深度卷积神经模糊推理系统（DCNFIS），它通过将模糊逻辑和深度学习模型相结合，实现了提高透明度而不损失准确性的目标。DCNFIS在准确性上与现有卷积神经网络相当，并且胜过了最先进的深度模糊系统。通过模糊规则提取的解释可以提高模型的可解释性。 |
| [^58] | [Transferable Graph Neural Fingerprint Models for Quick Response to Future Bio-Threats.](http://arxiv.org/abs/2308.01921) | 该论文提出了一种可转移的图神经指纹模型，用于快速应对未来的生物威胁。通过利用包含30万种候选药物和23个冠状病毒蛋白靶的COVID-19药物对接数据集，训练了高通量虚拟COVID-19药物筛选的图神经指纹模型。与传统指纹方法相比，该模型在对接得分上具有较高的预测准确性，并且提出了可转移的图神经指纹方法，能够适用于未知的靶点。 |
| [^59] | [Relation-Oriented: Toward Knowledge-Aligned Causal AI.](http://arxiv.org/abs/2307.16387) | 本研究从创新的关系导向视角出发，探讨了当前的建模范式中的观察模型与实际理解的不对齐问题，并提出了关系定义的表示学习方法作为实现关系导向建模的实践方法。 |
| [^60] | [Solving multiphysics-based inverse problems with learned surrogates and constraints.](http://arxiv.org/abs/2307.11099) | 本论文将学习代理和学习约束相结合用于解决基于多物理的反问题，通过该方法不仅改善了对流体流动性质的反演精度，而且为反演多模态数据提供了一个有效的解决方案。 |
| [^61] | [On the Constrained Time-Series Generation Problem.](http://arxiv.org/abs/2307.01717) | 这篇论文研究了约束时间序列生成问题。在实际应用中，合成时间序列被广泛用于增强历史时间序列数据集，提高机器学习算法的性能，放大稀有事件的发生，以及创建反事实情景。然而，现有的方法在满足约束方面存在问题，需要重新训练且计算代价高，或者在复杂约束条件下不切实际。 |
| [^62] | [Feature Selection: A perspective on inter-attribute cooperation.](http://arxiv.org/abs/2306.16559) | 本文综述了辅助特征间协作的过滤特征选择方法的最新研究进展，并总结了不同方法在文献中的贡献。同时提出了当前存在的问题和挑战，以确定未来有前景的研究和发展方向。 |
| [^63] | [Chinese Fine-Grained Financial Sentiment Analysis with Large Language Models.](http://arxiv.org/abs/2306.14096) | 本文提出了一个用于企业预警的新型、广泛的中文细粒度金融情感分析数据集FinChina SA，并使用现有开源大语言模型对其进行评估和实验。该数据集将成为推进真实金融情感分析任务探索的宝贵资源。 |
| [^64] | [Text-Driven Foley Sound Generation With Latent Diffusion Model.](http://arxiv.org/abs/2306.10359) | 本文提出了一种基于扩散模型的Foley音效生成系统，可进行文本条件的生成。我们通过迁移学习对系统进行微调，并引入可训练的层来改善文本嵌入，同时也改进了生成的波形。 |
| [^65] | [Simulation and Prediction of Countercurrent Spontaneous Imbibition at Early and Late Times Using Physics-Informed Neural Networks.](http://arxiv.org/abs/2306.05554) | 本文通过物理信息神经网络模型对多孔材料中的逆流自发渗透过程进行了早期和晚期的模拟和预测，并使用改变变量技术来改进模型性能。 |
| [^66] | [Exploiting Noise as a Resource for Computation and Learning in Spiking Neural Networks.](http://arxiv.org/abs/2305.16044) | 本文提出了噪声脉冲神经元网络（NSNN）和噪声驱动学习规则（NDL），展示了噪声可以作为计算和学习的资源，并为一般脉冲神经元网络提供了一个框架。研究还展示了NSNNs在图像分类和语音识别等实际任务中的适用性，表明它们是未来神经形态计算系统的潜在有力工具。 |
| [^67] | [Dynamic Masking Rate Schedules for MLM Pretraining.](http://arxiv.org/abs/2305.15096) | 本论文提出了一种动态调度掩码率的方法来改进MLM预训练的质量，通过线性降低掩码率，达到了对BERT-base和BERT-large模型分别提高0.46%和0.25%的平均GLUE准确率的效果。这种方法不仅加快了BERT-base的预训练速度，还实现了对BERT-large的帕累托改善。 |
| [^68] | [Using LLM-assisted Annotation for Corpus Linguistics: A Case Study of Local Grammar Analysis.](http://arxiv.org/abs/2305.08339) | 本文研究了使用基于大语言模型的聊天机器人自动标注文本的潜力，重点考察了从本地语法角度观察道歉言语行为构成的功能元素的程度，并比较了不同模型在注释任务中的表现，结果表明Bing聊天机器人在任务中表现优于ChatGPT和人类标注员。 |
| [^69] | [CVRecon: Rethinking 3D Geometric Feature Learning For Neural Reconstruction.](http://arxiv.org/abs/2304.14633) | 研究团队提出了一种基于代价体的3D神经重建框架CVRecon，利用丰富的几何嵌入来促进3D几何特征学习。通过引入射线上下文补偿代价体（RCCV），有效提高了视角相关信息的完整性和鲁棒性，并在各种度量方面显着提高了重建质量。 |
| [^70] | [Probe: Learning Users' Personalized Projection Bias in Intertemporal Bundle Choices.](http://arxiv.org/abs/2303.06016) | 本文提出了一种新的偏差嵌入式偏好模型——Probe，旨在解决用户在时间跨度的购物选择中的投影偏差和参照点效应，提高决策的有效性和个性化。 |
| [^71] | [Data-Centric AI: Deep Generative Differentiable Feature Selection via Discrete Subsetting as Continuous Embedding Space Optimization.](http://arxiv.org/abs/2302.13221) | 该论文提出一种将离散特征子集作为连续嵌入空间优化的深度生成可微分特征选择方法，解决了在高维小样本数据集中通用、准确和维度无关的特征选择问题。 |
| [^72] | [A Comprehensive Review and a Taxonomy of Edge Machine Learning: Requirements, Paradigms, and Techniques.](http://arxiv.org/abs/2302.08571) | 这篇论文综述了边缘机器学习的需求、范式和技术，并强调了其在保护隐私、实现低延迟的实时性能和资源优化方面的重要性。 |
| [^73] | [Guiding Pretraining in Reinforcement Learning with Large Language Models.](http://arxiv.org/abs/2302.06692) | 这项研究提出了一种使用大型语言模型在强化学习中引导预训练的方法，通过奖励代理根据语言模型建议的目标来塑造探索策略，使代理朝着人类有意义且可能有用的行为方向发展，无需人类的介入。 |
| [^74] | [A Survey on Deep Learning based Time Series Analysis with Frequency Transformation.](http://arxiv.org/abs/2302.02173) | 近期，频率变换（FT）在深度学习时间序列分析中得到广泛应用，显著提高了准确性和效率。本文系统回顾和总结了基于FT的深度学习时间序列模型的研究进展，并探讨了其优势、限制以及主要方法。 |
| [^75] | [Emerging Synergies in Causality and Deep Generative Models: A Survey.](http://arxiv.org/abs/2301.12351) | 这项综述探讨了因果性和深度生成模型之间的新兴协同作用，阐明了将因果性原则融入DGM中的方法，以及在大规模生成模型中应用因果性的研究前沿。 |
| [^76] | [BAFFLE: Backdoor Attack in Offline Reinforcement Learning.](http://arxiv.org/abs/2210.04688) | 本文研究离线增强学习中的后门攻击，通过向数据中添加扰动，使得智能体在注入触发器的观测值上采取低奖励动作，从而提出了BAFFLE方法。 |
| [^77] | [Critical Learning Periods for Multisensory Integration in Deep Networks.](http://arxiv.org/abs/2210.04643) | 对于多感官集成，神经网络在早期训练阶段接受适当相关信号至关重要，而干扰学习过程可能会永久损害技能的发展。早期瞬态动力学对最终的系统性能和学习表示具有决定性影响。 |
| [^78] | [System Fingerprint Recognition for Deepfake Audio: An Initial Dataset and Investigation.](http://arxiv.org/abs/2208.10489) | 本文提出了深度伪造音频的系统指纹识别方法，并通过收集来自中国七个供应商的语音合成系统的数据集进行了初步研究。这项研究为进一步发展系统指纹识别方法提供了基础，并在模型版权保护和数字证据取证等实际场景中具有重要应用价值。 |
| [^79] | [VQA-GNN: Reasoning with Multimodal Knowledge via Graph Neural Networks for Visual Question Answering.](http://arxiv.org/abs/2205.11501) | VQA-GNN是一种通过图神经网络在非结构化和结构化多模态知识之间进行双向融合的新的VQA模型。 |
| [^80] | [Don't Get Me Wrong: How to Apply Deep Visual Interpretations to Time Series.](http://arxiv.org/abs/2203.07861) | 该论文提出了一个针对时间序列分类和分割任务的框架，通过六个度量来评估基于梯度、传播或干扰的事后可视化解释方法。实验结果表明，这些方法对于时间序列的解释具有较高的可信度和有效性。 |
| [^81] | [Diversity in deep generative models and generative AI.](http://arxiv.org/abs/2202.09573) | 该论文介绍了一种基于核测度量化的方法，通过近似整体测度来生成多样性的对象，以解决现有生成算法中对象重复和缺乏多样性的问题。 |
| [^82] | [HAKE: A Knowledge Engine Foundation for Human Activity Understanding.](http://arxiv.org/abs/2202.06851) | 本论文提出了一个名为HAKE的知识引擎，用于人类活动理解。该引擎通过将像素映射到中间空间，并使用逻辑规则推断语义，展现出了优越的泛化能力和性能。 |
| [^83] | [Artificial Intelligence and Statistical Collusion.](http://arxiv.org/abs/2202.05946) | 本研究提出了一个可处理的模型来研究学习算法之间的战略互动，揭示了一种导致算法勾结出现的机制。通过自发耦合，算法周期性地协调行动，达到更高利润。该模型的参数可预测统计关联的出现和有利于算法勾结的市场结构，进一步展示了自发耦合如何在价格和市场份额上维持勾结，并应用于设计算法市场。 |
| [^84] | [A Deep Learning Driven Algorithmic Pipeline for Autonomous Navigation in Row-Based Crops.](http://arxiv.org/abs/2112.03816) | 本文提出了一种基于深度学习驱动的算法流水线，用于行作物自主导航。该方法通过利用低范围传感器和季节变化的信息，使用数据驱动的方法生成路径，并结合深度学习优化技术和合成图像数据，实现了稳健且成本效益的自主导航解决方案。 |
| [^85] | [MixStyle Neural Networks for Domain Generalization and Adaptation.](http://arxiv.org/abs/2107.02053) | MixStyle是一个简单的模块，用于提高神经网络对于领域转移的泛化性能。它通过在训练过程中混合两个随机实例的特征统计来合成新领域，从而实现数据增强。MixStyle易于实现，适用于各类学习范式。 |
| [^86] | [AmbiFC: Fact-Checking Ambiguous Claims with Evidence.](http://arxiv.org/abs/2104.00640) | 本研究提出了一个大规模的事实核查数据集AmbiFC，用于处理现实场景中的含糊性声明核查问题，通过细粒度的证据注释和分析，提出了一种适用于含糊性声明的软标签证据核查方法，并且在注释人员争议分析中发现了相关性。 |
| [^87] | [Constraint-Based Causal Discovery using Partial Ancestral Graphs in the presence of Cycles.](http://arxiv.org/abs/2005.00610) | 本研究证明了在涉及反馈的系统生成的观察数据中，应用Fast Causal Inference (FCI)算法可以得到正确的结果，该算法可以被用于一致地估计因果关系的存在和缺失、直接因果关系的存在和缺失、混淆因素的缺失以及因果图中特定循环的缺失。 |

# 详细

[^1]: 链式思考推理是一种策略改进操作

    Chain-of-Thought Reasoning is a Policy Improvement Operator. (arXiv:2309.08589v1 [cs.LG])

    [http://arxiv.org/abs/2309.08589](http://arxiv.org/abs/2309.08589)

    大型语言模型SECToR通过链式思考推理成功地自学新技能，

    

    大型语言模型以其令人赞叹的新能力令世界为之惊叹。然而，它们目前缺乏自我学习新技能的能力，而是依赖于接受大量由人类生成的数据的训练。我们介绍了SECToR（通过链式思考推理实现自我教育），这是一个概念验证，证明语言模型可以通过链式思考推理成功地自学新技能。受到以前在强化学习（Silver等人，2017）和人类认知（Kahneman，2011）中的相关工作的启发，SECToR首先使用链式思考推理逐渐思考问题。然后，SECToR通过微调模型生成相同的答案，这次不再使用链式思考推理。通过SECToR训练的语言模型自主学会了进行多达29位数字的加法运算，而没有任何超过6位数字的基准真实示例，仅通过初始的监督微调阶段。我们的核心假设是...

    Large language models have astounded the world with fascinating new capabilities. However, they currently lack the ability to teach themselves new skills, relying instead on being trained on large amounts of human-generated data. We introduce SECToR (Self-Education via Chain-of-Thought Reasoning), a proof-of-concept demonstration that language models can successfully teach themselves new skills using chain-of-thought reasoning. Inspired by previous work in both reinforcement learning (Silver et al., 2017) and human cognition (Kahneman, 2011), SECToR first uses chain-of-thought reasoning to slowly think its way through problems. SECToR then fine-tunes the model to generate those same answers, this time without using chain-of-thought reasoning. Language models trained via SECToR autonomously learn to add up to 29-digit numbers without any access to any ground truth examples beyond an initial supervised fine-tuning phase consisting only of numbers with 6 or fewer digits. Our central hypot
    
[^2]: 基于组合式基础模型的层次规划

    Compositional Foundation Models for Hierarchical Planning. (arXiv:2309.08587v1 [cs.LG])

    [http://arxiv.org/abs/2309.08587](http://arxiv.org/abs/2309.08587)

    本研究提出了一种基于组合式基础模型的层次规划方法，通过利用语言、视觉和动作数据的多个专家模型，解决了长期目标任务。通过符号计划、视频扩散和逆动力学模型的结合，实现了在新环境中做出有效决策的能力。

    

    在新环境中做出有效决策需要进行跨空间和时间尺度的层次推理。本文提出了一种基于组合式基础模型的层次规划方法，利用多个专家模型分别对语言、视觉和动作数据进行训练，共同解决长期目标任务。我们利用一个大型语言模型构建在环境中扎根的符号计划，并通过大型视频扩散模型来实现。生成的视频计划通过逆动力学模型与视觉-动作控制相结合。为了在此层次结构中进行有效推理，我们通过迭代改进强制保持模型的一致性。

    To make effective decisions in novel environments with long-horizon goals, it is crucial to engage in hierarchical reasoning across spatial and temporal scales. This entails planning abstract subgoal sequences, visually reasoning about the underlying plans, and executing actions in accordance with the devised plan through visual-motor control. We propose Compositional Foundation Models for Hierarchical Planning (HiP), a foundation model which leverages multiple expert foundation model trained on language, vision and action data individually jointly together to solve long-horizon tasks. We use a large language model to construct symbolic plans that are grounded in the environment through a large video diffusion model. Generated video plans are then grounded to visual-motor control, through an inverse dynamics model that infers actions from generated videos. To enable effective reasoning within this hierarchy, we enforce consistency between the models via iterative refinement. We illustr
    
[^3]: 预训练多语言翻译模型上的属性控制器能否迁移到其他语言？

    How Transferable are Attribute Controllers on Pretrained Multilingual Translation Models?. (arXiv:2309.08565v1 [cs.CL])

    [http://arxiv.org/abs/2309.08565](http://arxiv.org/abs/2309.08565)

    本文研究了如何将预训练的多语言翻译模型中的属性控制器迁移到没有监督数据的语言。通过全面分析不同数据场景下的训练和推断时控制技术，揭示了它们在零样本性能和领域鲁棒性上的相对优势和劣势。

    

    最近，将机器翻译模型定制为符合细粒度属性（如形式）已取得了巨大进展。然而，当前方法大多依赖于至少一些带有属性注释的监督数据。因此，数据稀缺仍然是将此定制能力普及到更广泛语言范围，尤其是低资源语言的一个瓶颈。鉴于最近在预训练大规模多语言翻译模型方面取得的进展，我们将它们作为对没有监督数据的语言进行属性控制能力迁移的基础。在这项工作中，我们基于预训练的NLLB-200模型对属性控制器的迁移进行了全面分析。我们研究了在各种数据场景下的训练和推断时控制技术，并揭示了它们在零样本性能和领域鲁棒性上的相对优势和劣势。我们显示出两种范式是互补的，通过一致的改进来证明。

    Customizing machine translation models to comply with fine-grained attributes such as formality has seen tremendous progress recently. However, current approaches mostly rely on at least some supervised data with attribute annotation. Data scarcity therefore remains a bottleneck to democratizing such customization possibilities to a wider range of languages, lower-resource ones in particular. Given recent progress in pretrained massively multilingual translation models, we use them as a foundation to transfer the attribute controlling capabilities to languages without supervised data. In this work, we present a comprehensive analysis of transferring attribute controllers based on a pretrained NLLB-200 model. We investigate both training- and inference-time control techniques under various data scenarios, and uncover their relative strengths and weaknesses in zero-shot performance and domain robustness. We show that both paradigms are complementary, as shown by consistent improvements o
    
[^4]: 用于高效且公平分配医疗资源的深度强化学习

    Deep Reinforcement Learning for Efficient and Fair Allocation of Health Care Resources. (arXiv:2309.08560v1 [cs.LG])

    [http://arxiv.org/abs/2309.08560](http://arxiv.org/abs/2309.08560)

    本研究使用强化学习方法，通过整合个体患者的疾病进展和患者间的相互作用效应，来优化医疗资源的分配策略，旨在提高分配的公平性和整体患者结果。

    

    医疗资源的稀缺性可能导致不可避免的配给问题。例如，通气机的供应通常有限，特别是在公共卫生紧急情况或资源有限的医疗环境中，如COVID-19大流行期间。目前，针对医疗资源分配的协议并没有普遍接受的标准，导致各国政府根据不同的标准和基于启发式协议来优先考虑患者。在本研究中，我们研究了使用强化学习来优化重症护理资源分配策略，以公平有效地配给资源。我们提出了基于变换器的深度Q网络，用于将个体患者的病情进展和患者间的相互作用效应整合到重症护理资源分配中。我们的目标是提高分配的公平性和整体患者结果。我们的实验表明，我们的方法显著减少了过度配给资源的情况。

    Scarcity of health care resources could result in the unavoidable consequence of rationing. For example, ventilators are often limited in supply, especially during public health emergencies or in resource-constrained health care settings, such as amid the pandemic of COVID-19. Currently, there is no universally accepted standard for health care resource allocation protocols, resulting in different governments prioritizing patients based on various criteria and heuristic-based protocols. In this study, we investigate the use of reinforcement learning for critical care resource allocation policy optimization to fairly and effectively ration resources. We propose a transformer-based deep Q-network to integrate the disease progression of individual patients and the interaction effects among patients during the critical care resource allocation. We aim to improve both fairness of allocation and overall patient outcomes. Our experiments demonstrate that our method significantly reduces exces
    
[^5]: 基于健康影响力噪声的训练来抵御数据污染攻击的方法

    HINT: Healthy Influential-Noise based Training to Defend against Data Poisoning Attacks. (arXiv:2309.08549v1 [cs.LG])

    [http://arxiv.org/abs/2309.08549](http://arxiv.org/abs/2309.08549)

    本论文提出了一种名为健康影响力噪声训练的高效稳健训练方法，该方法使用影响函数制造了有助于加强分类模型对抗数据污染攻击的健康噪声，并且在仅修改训练数据的子集时也能有效运行。

    

    虽然已经提出了许多防御方法来防止来自不可信数据源的潜在污染攻击，但大多数研究仅针对特定攻击进行防御，这给了攻击者许多可利用的机会。在本论文中，我们提出了一种基于影响函数的高效稳健训练方法，名为健康影响力噪声训练。通过使用影响函数，我们制造了有助于加强分类模型对抗污染攻击的健康噪声，同时不会对测试数据的泛化能力产生显著影响。此外，我们的方法可以在仅修改训练数据的子集时有效运行，而不是如几种之前的方法中那样向所有示例添加噪声。我们在两个图像数据集上进行了全面评估，并考虑不同的实际攻击场景下的最新攻击技术。我们的实证结果表明，H

    While numerous defense methods have been proposed to prohibit potential poisoning attacks from untrusted data sources, most research works only defend against specific attacks, which leaves many avenues for an adversary to exploit. In this work, we propose an efficient and robust training approach to defend against data poisoning attacks based on influence functions, named Healthy Influential-Noise based Training. Using influence functions, we craft healthy noise that helps to harden the classification model against poisoning attacks without significantly affecting the generalization ability on test data. In addition, our method can perform effectively when only a subset of the training data is modified, instead of the current method of adding noise to all examples that has been used in several previous works. We conduct comprehensive evaluations over two image datasets with state-of-the-art poisoning attacks under different realistic attack scenarios. Our empirical results show that H
    
[^6]: 生成式查询和文档扩展何时失败？方法、检索器和数据集的全面研究

    When do Generative Query and Document Expansions Fail? A Comprehensive Study Across Methods, Retrievers, and Datasets. (arXiv:2309.08541v1 [cs.IR])

    [http://arxiv.org/abs/2309.08541](http://arxiv.org/abs/2309.08541)

    通过对11种扩展技术、12个不同分布变化的数据集和24个检索模型的全面分析，我们发现使用大型语言模型进行查询或文档扩展的效果与检索器性能相关，对于弱模型来说扩展提高了分数，但对于强模型来说扩展通常会损害分数。

    

    使用大型语言模型（LM）进行查询或文档扩展可以改善信息检索中的泛化能力。然而，目前尚不清楚这些技术是否普遍有益，还是仅在特定设置下有效，例如对于特定的检索模型、数据集领域或查询类型。为了回答这个问题，我们进行了第一次对基于LM的扩展的全面分析。我们发现，检索器性能与扩展的增益之间存在强烈的负相关关系：扩展改善了较弱模型的分数，但通常会损害较强模型的分数。我们展示了这一趋势在11种扩展技术、12个具有不同分布变化的数据集和24个检索模型的一组实验中成立。通过定性错误分析，我们提出了一个假设，即尽管扩展提供了额外的信息（可能改善了召回率），但它们也增加了噪声，使得很难区分出顶级相关文档（从而引入了错误的正例）

    Using large language models (LMs) for query or document expansion can improve generalization in information retrieval. However, it is unknown whether these techniques are universally beneficial or only effective in specific settings, such as for particular retrieval models, dataset domains, or query types. To answer this, we conduct the first comprehensive analysis of LM-based expansion. We find that there exists a strong negative correlation between retriever performance and gains from expansion: expansion improves scores for weaker models, but generally harms stronger models. We show this trend holds across a set of eleven expansion techniques, twelve datasets with diverse distribution shifts, and twenty-four retrieval models. Through qualitative error analysis, we hypothesize that although expansions provide extra information (potentially improving recall), they add additional noise that makes it difficult to discern between the top relevant documents (thus introducing false positiv
    
[^7]: 用Whisper模型从自动标注中获得低资源语言的视觉语音识别

    Visual Speech Recognition for Low-resource Languages with Automatic Labels From Whisper Model. (arXiv:2309.08535v1 [cs.CV])

    [http://arxiv.org/abs/2309.08535](http://arxiv.org/abs/2309.08535)

    本文提出了一种利用Whisper模型从未标注的多语言视听数据自动标注的方法，实现了在低资源语言中的视觉语音识别，并证明了该方法可以获得与人工标注相似的性能。

    

    本文提出了一种强大的视觉语音识别(VSR)方法，适用于多种语言，特别是那些标注数据有限的低资源语言。与之前试图通过从其他语言学习的知识来提高目标语言的VSR性能的方法不同，我们探索是否可以在不依赖人工干预的情况下增加不同语言的训练数据量。为此，我们使用了一个Whisper模型，它可以进行语言识别和基于音频的语音识别。它用于过滤所需语言的数据，并从未注释的多语言视听数据池中转录标签。通过比较使用自动标签和人工标注标签训练的VSR模型的性能，我们表明即使不使用人工注释，我们也可以达到与人工注释标签相似的VSR性能。通过自动标注的过程，我们标注了大规模未标注数据。

    This paper proposes a powerful Visual Speech Recognition (VSR) method for multiple languages, especially for low-resource languages that have a limited number of labeled data. Different from previous methods that tried to improve the VSR performance for the target language by using knowledge learned from other languages, we explore whether we can increase the amount of training data itself for the different languages without human intervention. To this end, we employ a Whisper model which can conduct both language identification and audio-based speech recognition. It serves to filter data of the desired languages and transcribe labels from the unannotated, multilingual audio-visual data pool. By comparing the performances of VSR models trained on automatic labels and the human-annotated labels, we show that we can achieve similar VSR performance to that of human-annotated labels even without utilizing human annotations. Through the automated labeling process, we label large-scale unlab
    
[^8]: 通过进化算法连接大型语言模型与强大的提示优化器

    Connecting Large Language Models with Evolutionary Algorithms Yields Powerful Prompt Optimizers. (arXiv:2309.08532v1 [cs.CL])

    [http://arxiv.org/abs/2309.08532](http://arxiv.org/abs/2309.08532)

    本文提出了一种通过连接大型语言模型和进化算法进行提示优化的框架，名为EvoPrompt。通过利用大型语言模型的语言处理能力和进化算法的优化性能，EvoPrompt可以自动化处理需要连贯和可读性良好的提示，提高大型语言模型的性能。

    

    大型语言模型在各种任务中表现出色，但它们依赖于精心设计的提示，这通常需要大量的人力努力。为了自动化这个过程，本文提出了一种新颖的离散提示优化框架，称为EvoPrompt，它借鉴了进化算法的思想，因为它们表现出良好的性能和快速的收敛性。为了使进化算法能够处理需要连贯并且可读性良好的自然语言表达的离散提示，我们将大型语言模型与进化算法进行了连接。这种方法使我们可以同时利用大型语言模型的强大语言处理能力和进化算法的高效优化性能。具体而言，EvoPrompt在不使用任何梯度或参数的情况下，从一组提示中开始，并基于进化算子通过大型语言模型生成新的提示，根据开发集改进提示的种群。我们对闭源和开源的大型语言模型，包括GPT-3进行提示优化。

    Large Language Models (LLMs) excel in various tasks, but they rely on carefully crafted prompts that often demand substantial human effort. To automate this process, in this paper, we propose a novel framework for discrete prompt optimization, called EvoPrompt, which borrows the idea of evolutionary algorithms (EAs) as they exhibit good performance and fast convergence. To enable EAs to work on discrete prompts, which are natural language expressions that need to be coherent and human-readable, we connect LLMs with EAs. This approach allows us to simultaneously leverage the powerful language processing capabilities of LLMs and the efficient optimization performance of EAs. Specifically, abstaining from any gradients or parameters, EvoPrompt starts from a population of prompts and iteratively generates new prompts with LLMs based on the evolutionary operators, improving the population based on the development set. We optimize prompts for both closed- and open-source LLMs including GPT-3
    
[^9]: 通过显著通道实现参数高效微调的简单基准模型

    SCT: A Simple Baseline for Parameter-Efficient Fine-Tuning via Salient Channels. (arXiv:2309.08513v1 [cs.CV])

    [http://arxiv.org/abs/2309.08513](http://arxiv.org/abs/2309.08513)

    本文提出了一种名为“显著通道微调”的简单而有效的方法，通过选择特征图中的部分通道进行微调，实现在低数据资源场景下低参数成本的高效微调，并在多个下游任务中优于全面微调方法。

    

    预训练的视觉Transformer在各种下游任务中具有强大的表示优势。最近，已经提出了许多参数高效的微调方法，并且实验证明，仅微调额外的1%参数就能在低数据资源场景下超越全面微调。然而，这些方法在微调多样的下游任务时忽视了任务特定的信息。本文提出了一种简单而有效的方法称为“显著通道微调”（SCT），通过将模型与任务图像进行前向传播，选择特征图中的部分通道，使得我们只需要微调其中的1/8通道，从而显著降低参数成本并在VTAB-1K基准测试中的18个任务中优于全面微调。这仅增加了0.11M ViT-B参数，相比全面微调，减少了780倍。

    Pre-trained vision transformers have strong representation benefits to various downstream tasks. Recently, many parameter-efficient fine-tuning (PEFT) methods have been proposed, and their experiments demonstrate that tuning only 1% of extra parameters could surpass full fine-tuning in low-data resource scenarios. However, these methods overlook the task-specific information when fine-tuning diverse downstream tasks. In this paper, we propose a simple yet effective method called "Salient Channel Tuning" (SCT) to leverage the task-specific information by forwarding the model with the task images to select partial channels in a feature map that enables us to tune only 1/8 channels leading to significantly lower parameter costs. Experiments outperform full fine-tuning on 18 out of 19 tasks in the VTAB-1K benchmark by adding only 0.11M parameters of the ViT-B, which is 780$\times$ fewer than its full fine-tuning counterpart. Furthermore, experiments on domain generalization and few-shot le
    
[^10]: HealthFC：一份用于基于证据的医学事实检验的健康声明数据集

    HealthFC: A Dataset of Health Claims for Evidence-Based Medical Fact-Checking. (arXiv:2309.08503v1 [cs.CL])

    [http://arxiv.org/abs/2309.08503](http://arxiv.org/abs/2309.08503)

    本文介绍了一份新的健康声明数据集，其中包含了750个由医学专家标注的健康相关声明，并提供了来自临床研究的证据支持。该数据集可用于机器学习任务，包括证据检索、真实性预测和解释生成。

    

    在数字时代，通过互联网查询健康相关建议已成为一种常见做法。然而，判断在线找到的医学声明的可信度，并找到相应的证据，变得越来越具有挑战性。事实检验已经成为一种通过可靠知识来源的证据评估事实声明真实性的方法。为了推动此任务的自动化，本文介绍了一份新的数据集，包含了750个健康相关声明，在可信度方面由医学专家进行了标注，并提供了来自适当的临床研究的证据支持。我们对数据集进行了分析，突出其特点和挑战。该数据集可用于与自动事实检验相关的机器学习任务，如证据检索、真实性预测和解释生成。为此，我们提供了基于不同方法的基线模型，对它们的性能进行了研究，并讨论了研究结果。

    Seeking health-related advice on the internet has become a common practice in the digital era. Determining the trustworthiness of medical claims found online and finding appropriate evidence for this information is increasingly challenging. Fact-checking has emerged as an approach to assess the veracity of factual claims using evidence from credible knowledge sources. To help advance the automation of this task, in this paper, we introduce a novel dataset of 750 health-related claims, labeled for veracity by medical experts and backed with evidence from appropriate clinical studies. We provide an analysis of the dataset, highlighting its characteristics and challenges. The dataset can be used for Machine Learning tasks related to automated fact-checking such as evidence retrieval, veracity prediction, and explanation generation. For this purpose, we provide baseline models based on different approaches, examine their performance, and discuss the findings.
    
[^11]: P-ROCKET: 针对时间序列分类的随机卷积核剪枝

    P-ROCKET: Pruning Random Convolution Kernels for Time Series Classification. (arXiv:2309.08499v1 [cs.LG])

    [http://arxiv.org/abs/2309.08499](http://arxiv.org/abs/2309.08499)

    本研究提出了一种名为P-ROCKET的方法，通过在特征选择的角度删除卷积核，从而实现对时间序列分类中的随机卷积核进行剪枝。

    

    在最近几年，两个时间序列分类模型ROCKET和MINIROCKET因其低训练成本和最先进的准确性而受到广泛关注。ROCKET和MINIROCKET利用无需训练的随机一维卷积核，可以快速从时间序列数据中提取特征，从而实现线性分类器的高效拟合。然而，为了全面捕捉有用的特征，需要大量的随机卷积核，这对于资源受限的设备来说是不兼容的。因此，我们设计了一种启发式进化算法S-ROCKET，用于识别和剪枝冗余的卷积核。然而，进化算法本身的特性导致在S-ROCKET中评估卷积核是一个耗时的过程。本文中，与直接评估具有非显著差异的随机卷积核的S-ROCKET不同，我们从特征选择的角度删除卷积核，通过消除序列中的相关连接来实现。

    In recent years, two time series classification models, ROCKET and MINIROCKET, have attracted much attention for their low training cost and state-of-the-art accuracy. Utilizing random 1-D convolutional kernels without training, ROCKET and MINIROCKET can rapidly extract features from time series data, allowing for the efficient fitting of linear classifiers. However, to comprehensively capture useful features, a large number of random kernels are required, which is incompatible for resource-constrained devices. Therefore, a heuristic evolutionary algorithm named S-ROCKET is devised to recognize and prune redundant kernels. Nevertheless, the inherent nature of evolutionary algorithms renders the evaluation of kernels within S-ROCKET an unacceptable time-consuming process. In this paper, diverging from S-ROCKET, which directly evaluates random kernels with nonsignificant differences, we remove kernels from a feature selection perspective by eliminating associating connections in the sequ
    
[^12]: 使用大型语言模型进行知识工程（LLMKE）：以Wikidata为案例研究

    Using Large Language Models for Knowledge Engineering (LLMKE): A Case Study on Wikidata. (arXiv:2309.08491v1 [cs.CL])

    [http://arxiv.org/abs/2309.08491](http://arxiv.org/abs/2309.08491)

    这项工作探索了使用大型语言模型（LLMs）进行知识工程任务的应用。通过将主题和关系对转化为字符串格式，并将它们链接到相应的Wikidata QID上，开发了LLMKE流水线方法。研究发现，LLMs的知识因领域而异，并需要进一步实验以确定其在自动知识库补全和修正方面的应用条件。此外，结果还显示了LLMs在协作知识工程方面的有希望的贡献。

    

    在这项工作中，我们探索了在ISWC 2023 LM-KBC挑战中使用大型语言模型（LLMs）进行知识工程任务的应用。针对该任务，我们使用预训练的LLMs将来自Wikidata的主题和关系对转化为相应的字符串格式，并将它们链接到相应的Wikidata QID上。我们开发了一种使用LLMs进行知识工程的流水线（LLMKE），结合了知识探测和Wikidata实体映射。该方法在属性方面达到了0.701的宏平均F1分数，得分在1.00到0.328之间变化。这些结果表明，LLMs的知识因领域而异，需要进一步实验来确定LLMs在自动知识库（如Wikidata）补全和修正方面的应用条件。结果的调查还显示了LLMs在协作知识工程方面的有希望的贡献。LLMKE获胜

    In this work, we explore the use of Large Language Models (LLMs) for knowledge engineering tasks in the context of the ISWC 2023 LM-KBC Challenge. For this task, given subject and relation pairs sourced from Wikidata, we utilize pre-trained LLMs to produce the relevant objects in string format and link them to their respective Wikidata QIDs. We developed a pipeline using LLMs for Knowledge Engineering (LLMKE), combining knowledge probing and Wikidata entity mapping. The method achieved a macro-averaged F1-score of 0.701 across the properties, with the scores varying from 1.00 to 0.328. These results demonstrate that the knowledge of LLMs varies significantly depending on the domain and that further experimentation is required to determine the circumstances under which LLMs can be used for automatic Knowledge Base (e.g., Wikidata) completion and correction. The investigation of the results also suggests the promising contribution of LLMs in collaborative knowledge engineering. LLMKE won
    
[^13]: XFedHunter: 一种用于SDN中持久性高级威胁检测的可解释联邦学习框架

    XFedHunter: An Explainable Federated Learning Framework for Advanced Persistent Threat Detection in SDN. (arXiv:2309.08485v1 [cs.CR])

    [http://arxiv.org/abs/2309.08485](http://arxiv.org/abs/2309.08485)

    XFedHunter是一种用于SDN中检测持久性高级威胁的可解释联邦学习框架，能够通过ML预测的解释来揭示攻击者的特征。

    

    高级持久性威胁（APT）攻击是非常复杂的，采用了多种先进方法和技术，以针对组织并窃取敏感和机密信息。APT攻击包括多个阶段和一个明确定义的策略，利用黑客开发的新的创新技术和技术来规避安全软件监控。为了有效防护APT，通过机器学习（ML）预测的解释来检测和预测APT指标对于揭示潜伏在网络系统中的攻击者的特征至关重要。同时，联邦学习（FL）已经成为一种在不损害隐私的情况下构建智能应用的有希望的方法。在网络安全领域，敏感数据和高质量标签对于构建有效的机器学习模型来检测网络威胁起着关键作用。因此，本研究提出了一种名为XFedHunter的可解释联邦学习框架。

    Advanced Persistent Threat (APT) attacks are highly sophisticated and employ a multitude of advanced methods and techniques to target organizations and steal sensitive and confidential information. APT attacks consist of multiple stages and have a defined strategy, utilizing new and innovative techniques and technologies developed by hackers to evade security software monitoring. To effectively protect against APTs, detecting and predicting APT indicators with an explanation from Machine Learning (ML) prediction is crucial to reveal the characteristics of attackers lurking in the network system. Meanwhile, Federated Learning (FL) has emerged as a promising approach for building intelligent applications without compromising privacy. This is particularly important in cybersecurity, where sensitive data and high-quality labeling play a critical role in constructing effective machine learning models for detecting cyber threats. Therefore, this work proposes XFedHunter, an explainable feder
    
[^14]: VulnSense: 基于图神经网络和语言模型的多模态学习在以太坊智能合约中的高效漏洞检测

    VulnSense: Efficient Vulnerability Detection in Ethereum Smart Contracts by Multimodal Learning with Graph Neural Network and Language Model. (arXiv:2309.08474v1 [cs.CR])

    [http://arxiv.org/abs/2309.08474](http://arxiv.org/abs/2309.08474)

    VulnSense框架使用多模态学习方法，通过基于图形和语言模型的深度学习，高效检测以太坊智能合约中的漏洞。与现有方法相比，该框架在准确性和效果方面具有优势。

    

    本文介绍了VulnSense框架，一个综合方法，通过基于图形和自然语言处理（NLP）模型的多模态学习方法，高效检测以太坊智能合约中的漏洞。我们的框架结合了智能合约中的源代码、操作码序列和从字节码中提取的控制流图（CFG）等三种类型的特征。我们采用双向编码器表示转换器（BERT）、双向长短期记忆（BiLSTM）和图神经网络（GNN）模型提取和分析这些特征。我们多模态方法的最后一层是一个全连接层，用于预测以太坊智能合约中的漏洞。我们的方法克服了现有漏洞检测方法仅依赖单一特征或单一模型深度学习技术的限制，提高了准确性和效果。我们使用1,769个智能合约集合对VulnSense进行评估。

    This paper presents VulnSense framework, a comprehensive approach to efficiently detect vulnerabilities in Ethereum smart contracts using a multimodal learning approach on graph-based and natural language processing (NLP) models. Our proposed framework combines three types of features from smart contracts comprising source code, opcode sequences, and control flow graph (CFG) extracted from bytecode. We employ Bidirectional Encoder Representations from Transformers (BERT), Bidirectional Long Short-Term Memory (BiLSTM) and Graph Neural Network (GNN) models to extract and analyze these features. The final layer of our multimodal approach consists of a fully connected layer used to predict vulnerabilities in Ethereum smart contracts. Addressing limitations of existing vulnerability detection methods relying on single-feature or single-model deep learning techniques, our method surpasses accuracy and effectiveness constraints. We assess VulnSense using a collection of 1.769 smart contracts 
    
[^15]: 向有观点的人解释搜索结果立场

    Explaining Search Result Stances to Opinionated People. (arXiv:2309.08460v1 [cs.IR])

    [http://arxiv.org/abs/2309.08460](http://arxiv.org/abs/2309.08460)

    这项研究探讨了向有观点的人解释搜索结果立场的效果，发现立场标签和解释可以帮助用户消费更多不同的搜索结果，但没有发现系统性观点改变的证据。

    

    人们在形成观点之前使用网络搜索引擎找到信息，这可能导致具有不同影响水平的实际决策。搜索的认知努力可能使有观点的用户容易受到认知偏见的影响，例如确认偏见。在本文中，我们调查立场标签及其解释是否可以帮助用户消费更多不同的搜索结果。我们自动对三个主题（知识产权、校服和无神论）的搜索结果进行分类和标记，分为反对、中立和支持，并为这些标签生成解释。在一项用户研究中（N =203），我们调查了搜索结果立场偏见（平衡 vs 偏见）和解释水平（纯文本、仅标签、标签和解释）是否会影响被点击的搜索结果的多样性。我们发现立场标签和解释可以导致更多样化的搜索结果消费。然而，我们并没有发现系统性观点改变的证据。

    People use web search engines to find information before forming opinions, which can lead to practical decisions with different levels of impact. The cognitive effort of search can leave opinionated users vulnerable to cognitive biases, e.g., the confirmation bias. In this paper, we investigate whether stance labels and their explanations can help users consume more diverse search results. We automatically classify and label search results on three topics (i.e., intellectual property rights, school uniforms, and atheism) as against, neutral, and in favor, and generate explanations for these labels. In a user study (N =203), we then investigate whether search result stance bias (balanced vs biased) and the level of explanation (plain text, label only, label and explanation) influence the diversity of search results clicked. We find that stance labels and explanations lead to a more diverse search result consumption. However, we do not find evidence for systematic opinion change among us
    
[^16]: 朝着负责任的人脸数据集：对从人口群体中采样人脸图像的分解潜空间分布建模

    Toward responsible face datasets: modeling the distribution of a disentangled latent space for sampling face images from demographic groups. (arXiv:2309.08442v1 [cs.CV])

    [http://arxiv.org/abs/2309.08442](http://arxiv.org/abs/2309.08442)

    本文提出了一种方法，通过建模和采样分解潜空间的方法来生成任意组合的人口群体，以解决现代人脸识别系统中数据集偏见导致的不公平关注问题。

    

    最近，一些现代人脸识别系统被曝光出可能对特定人口群体进行歧视，并可能导致对性别和出身等各种面部属性的不公平关注。原因在于被用于训练这些模型的数据集中存在偏见和不平衡的人口统计数据。然而，采集一个各个人口统计数据都平衡的大规模数据集是不可行的。因此，本文探讨了一个替代方案，即生成一个具有平衡性和可能无偏见的合成数据集，以用于训练、正则化或评估基于深度学习的人脸识别模型。我们提出使用一个简单的方法来建模和采样一个StyleGAN潜空间的分解投影，以生成任意组合的人口群体（例如 $hispanic-female$）。我们的实验证明，我们可以有效地合成任意组合的人口群体，且这些身份与原始训练集中的身份不同。

    Recently, it has been exposed that some modern facial recognition systems could discriminate specific demographic groups and may lead to unfair attention with respect to various facial attributes such as gender and origin. The main reason are the biases inside datasets, unbalanced demographics, used to train theses models. Unfortunately, collecting a large-scale balanced dataset with respect to various demographics is impracticable.  In this paper, we investigate as an alternative the generation of a balanced and possibly bias-free synthetic dataset that could be used to train, to regularize or to evaluate deep learning-based facial recognition models. We propose to use a simple method for modeling and sampling a disentangled projection of a StyleGAN latent space to generate any combination of demographic groups (e.g. $hispanic-female$). Our experiments show that we can synthesis any combination of demographic groups effectively and the identities are different from the original traini
    
[^17]: 学习通过自我解释

    Learning by Self-Explaining. (arXiv:2309.08395v1 [cs.AI])

    [http://arxiv.org/abs/2309.08395](http://arxiv.org/abs/2309.08395)

    学习通过自我解释（LSX）是一种新的学习范式，通过给予解释和批评者的反馈来改进学习者的性能。这种方法适用于图像分类等基本任务，并有潜力在人工智能研究中发挥作用。

    

    人工智能研究长期以来一直从生物学中寻找灵感，特别是人类智能。与目前主要将解释视为模型检查手段的人工智能研究相比，从心理学中发现自我解释在代理学习过程中的好处有些被忽视了。受到这个启发，我们引入了一种新的学习范式，称为学习通过自我解释 (LSX)。其中的基本思想是，一个学习模块 (学习者) 执行一个基本任务，比如图像分类，并对其决策进行解释。随后，一个内部批评者模块基于原始任务评估这些解释的质量。最后，学习者通过批评者的反馈得到改进，并根据需要重复这个循环。背后的直觉是，如果批评者能够根据相应的解释执行相同的任务，则该解释被认为是“好”的。尽管有许多实现可能性，但本文旨在提供关于实施学习通过自我解释的一般指导原则。有待进一步的研究和实践来探索这一学习范式的潜力。

    Artificial intelligence (AI) research has a long track record of drawing inspirations from findings from biology, in particular human intelligence. In contrast to current AI research that mainly treats explanations as a means for model inspection, a somewhat neglected finding from human psychology is the benefit of self-explaining in an agents' learning process. Motivated by this, we introduce a novel learning paradigm, termed Learning by Self-Explaining (LSX). The underlying idea is that a learning module (learner) performs a base task, e.g. image classification, and provides explanations to its decisions. An internal critic module next evaluates the quality of these explanations given the original task. Finally, the learner is refined with the critic's feedback and the loop is repeated as required. The intuition behind this is that an explanation is considered "good" if the critic can perform the same task given the respective explanation. Despite many implementation possibilities th
    
[^18]: M$^3$Net：用于显著目标检测的多级、混合和多阶段注意力网络

    M$^3$Net: Multilevel, Mixed and Multistage Attention Network for Salient Object Detection. (arXiv:2309.08365v1 [cs.CV])

    [http://arxiv.org/abs/2309.08365](http://arxiv.org/abs/2309.08365)

    本研究提出了M$^3$Net，一种用于显著目标检测的多级、混合和多阶段注意力网络。通过引入多尺度交互块和混合注意力块，该方法能够提高显著区域的检测性能并准确定位复杂对象的细节。

    

    大多数现有的显著目标检测方法主要使用U-Net或特征金字塔结构，简单地聚合不同尺度的特征图，忽视了它们的独特性和相互依赖性以及它们对最终预测的贡献。为了克服这些问题，我们提出了M$^3$Net，即多级、混合和多阶段注意力网络用于显著目标检测（SOD）。首先，我们提出了多尺度交互块，创新性地引入了交叉注意力方法来实现多级特征之间的交互，允许高层特征指导低层特征学习，从而增强显著区域。其次，考虑到以前基于Transformer的SOD方法只使用全局自注意力来定位显著区域，而无法避免忽视复杂对象的细节，我们提出了混合注意力块。此块结合了全局自注意力和窗口自注意力，旨在建模上下文。

    Most existing salient object detection methods mostly use U-Net or feature pyramid structure, which simply aggregates feature maps of different scales, ignoring the uniqueness and interdependence of them and their respective contributions to the final prediction. To overcome these, we propose the M$^3$Net, i.e., the Multilevel, Mixed and Multistage attention network for Salient Object Detection (SOD). Firstly, we propose Multiscale Interaction Block which innovatively introduces the cross-attention approach to achieve the interaction between multilevel features, allowing high-level features to guide low-level feature learning and thus enhancing salient regions. Secondly, considering the fact that previous Transformer based SOD methods locate salient regions only using global self-attention while inevitably overlooking the details of complex objects, we propose the Mixed Attention Block. This block combines global self-attention and window self-attention, aiming at modeling context at b
    
[^19]: 语言模型在与知识库进行连接时的数据分布瓶颈

    Data Distribution Bottlenecks in Grounding Language Models to Knowledge Bases. (arXiv:2309.08345v1 [cs.CL])

    [http://arxiv.org/abs/2309.08345](http://arxiv.org/abs/2309.08345)

    本文通过实验调查揭示了语言模型在与知识库进行连接时的数据分布瓶颈，包括推广到未见域、适应语言变体和在不同数据集之间的可转移性等方面。即使采用数据增强技术，先进的语言模型在多个方面表现出较差的性能。

    

    语言模型（LM）已经展示了在理解和生成自然语言和形式语言方面的卓越能力。尽管取得了这些进展，但它们与大规模知识库等现实环境的整合仍然是一个欠发展的领域，影响了语义解析等应用，并且容易出现“产生虚假信息”的问题。本文通过实验调查揭示了LM在处理知识库问答（KBQA）任务时所遇到的健壮性挑战。研究覆盖了训练和推断之间数据分布不一致的场景，例如推广到未见域、适应各种语言变体和在不同数据集之间的可转移性。我们的全面实验揭示了即使在采用我们提出的数据增强技术的情况下，先进的小型和大型语言模型在多个方面表现出较差的性能。

    Language models (LMs) have already demonstrated remarkable abilities in understanding and generating both natural and formal language. Despite these advances, their integration with real-world environments such as large-scale knowledge bases (KBs) remains an underdeveloped area, affecting applications such as semantic parsing and indulging in "hallucinated" information. This paper is an experimental investigation aimed at uncovering the robustness challenges that LMs encounter when tasked with knowledge base question answering (KBQA). The investigation covers scenarios with inconsistent data distribution between training and inference, such as generalization to unseen domains, adaptation to various language variations, and transferability across different datasets. Our comprehensive experiments reveal that even when employed with our proposed data augmentation techniques, advanced small and large language models exhibit poor performance in various dimensions. While the LM is a promisin
    
[^20]: 让我们预测谁会换工作

    Let's Predict Who Will Move to a New Job. (arXiv:2309.08333v1 [cs.LG])

    [http://arxiv.org/abs/2309.08333](http://arxiv.org/abs/2309.08333)

    本文讨论了如何使用机器学习来预测谁会换工作，包括数据预处理和使用多种ML算法。为了提高性能，使用了合成少数过采样技术。评估模型时使用了精度、召回率、F1-Score和准确率等指标。

    

    任何一家公司的人力资源部门都面临着预测申请人是否会寻找新工作或者留在公司的挑战。在本文中，我们讨论了如何使用机器学习（ML）来预测谁会换工作。首先，将数据预处理成适合ML模型的格式。为了处理分类特征，应用数据编码并执行几种ML算法，包括随机森林（RF）、逻辑回归（LR）、决策树（DT）和极限梯度提升（XGBoost）。为了提高ML模型的性能，使用合成少数过采样技术（SMOTE）进行保留。使用精度、召回率、F1-Score和准确率等决策支持度量来评估模型。

    Any company's human resources department faces the challenge of predicting whether an applicant will search for a new job or stay with the company. In this paper, we discuss how machine learning (ML) is used to predict who will move to a new job. First, the data is pre-processed into a suitable format for ML models. To deal with categorical features, data encoding is applied and several MLA (ML Algorithms) are performed including Random Forest (RF), Logistic Regression (LR), Decision Tree (DT), and eXtreme Gradient Boosting (XGBoost). To improve the performance of ML models, the synthetic minority oversampling technique (SMOTE) is used to retain them. Models are assessed using decision support metrics such as precision, recall, F1-Score, and accuracy.
    
[^21]: 利用点扩散模型对大肠的3D形状进行精化以生成数字幻影

    Large Intestine 3D Shape Refinement Using Point Diffusion Models for Digital Phantom Generation. (arXiv:2309.08289v1 [cs.CV])

    [http://arxiv.org/abs/2309.08289](http://arxiv.org/abs/2309.08289)

    本研究利用几何深度学习和去噪扩散概率模型优化大肠的分割结果，并结合先进的表面重构模型，实现对大肠3D形状的精化恢复。

    

    准确建模人体器官在构建虚拟成像试验的计算仿真中起着至关重要的作用。然而，从计算机断层扫描中生成解剖学上可信的器官表面重建仍然对人体结构中的许多器官来说是个挑战。在处理大肠时，这个挑战尤为明显。在这项研究中，我们利用几何深度学习和去噪扩散概率模型的最新进展来优化大肠分割结果。首先，我们将器官表示为从3D分割掩模表面采样得到的点云。随后，我们使用分层变分自编码器获得器官形状的全局和局部潜在表示。我们在分层潜在空间中训练两个条件去噪扩散模型来进行形状精化。为了进一步提高我们的方法，我们还结合了一种先进的表面重构模型，从而实现形状的更好恢复。

    Accurate 3D modeling of human organs plays a crucial role in building computational phantoms for virtual imaging trials. However, generating anatomically plausible reconstructions of organ surfaces from computed tomography scans remains challenging for many structures in the human body. This challenge is particularly evident when dealing with the large intestine. In this study, we leverage recent advancements in geometric deep learning and denoising diffusion probabilistic models to refine the segmentation results of the large intestine. We begin by representing the organ as point clouds sampled from the surface of the 3D segmentation mask. Subsequently, we employ a hierarchical variational autoencoder to obtain global and local latent representations of the organ's shape. We train two conditional denoising diffusion models in the hierarchical latent space to perform shape refinement. To further enhance our method, we incorporate a state-of-the-art surface reconstruction model, allowin
    
[^22]: 自主驾驶车辆的强化学习策略的定量和定性评估

    Quantitative and Qualitative Evaluation of Reinforcement Learning Policies for Autonomous Vehicles. (arXiv:2309.08254v1 [cs.AI])

    [http://arxiv.org/abs/2309.08254](http://arxiv.org/abs/2309.08254)

    本文使用强化学习算法（PPO）针对自主驾驶车辆的选择进行了优化，通过最小化时间和污染来缓解交通阻塞问题，经实证分析和定性评估证明了方法的有效性和实用性。

    

    在不断变化的交通环境中优化交通动力学非常重要，特别是在自动驾驶车辆（AVs）与人驾驶车辆并存的情况下。本文提出了一种使用近端策略优化（PPO）强化学习算法来优化AVs选择的新方法。我们通过学习一种策略来最小化交通阻塞（即最小化横过米兰的环形道的时间）并减少污染。通过经验分析，我们证明了我们的方法可以减少时间和污染水平。此外，我们使用先进的驾驶舱定性评估了学到的策略，以评估其在接近真实世界条件下的性能。为了评估策略的实用性和可接受性，我们通过模拟器进行了人类参与者的评估，重点关注交通平稳性和安全感等一系列指标。总的来说，我们的研究结果表明，人驾驶车辆的感知和行车平滑性方面，我们的方法非常实用。

    Optimizing traffic dynamics in an evolving transportation landscape is crucial, particularly in scenarios where autonomous vehicles (AVs) with varying levels of autonomy coexist with human-driven cars. This paper presents a novel approach to optimizing choices of AVs using Proximal Policy Optimization (PPO), a reinforcement learning algorithm. We learned a policy to minimize traffic jams (i.e., minimize the time to cross the scenario) and to minimize pollution in a roundabout in Milan, Italy. Through empirical analysis, we demonstrate that our approach can reduce time and pollution levels. Furthermore, we qualitatively evaluate the learned policy using a cutting-edge cockpit to assess its performance in near-real-world conditions. To gauge the practicality and acceptability of the policy, we conducted evaluations with human participants using the simulator, focusing on a range of metrics like traffic smoothness and safety perception. In general, our findings show that human-driven vehi
    
[^23]: 对自编码器的几何角度的研究

    A Geometric Perspective on Autoencoders. (arXiv:2309.08247v1 [cs.LG])

    [http://arxiv.org/abs/2309.08247](http://arxiv.org/abs/2309.08247)

    本文从几何角度研究了自编码器框架，并提出了解决多解和畸变表示问题的几何方法。

    

    本文提出了自编码器框架的几何方面，尽管其重要性，但被相对较少地认识到。给定一组几乎位于某个较低维度流形上的高维数据点，自编码器同时学习流形和其坐标图。这种几何角度自然引发了一些问题，比如“有限的数据点对应于单一的流形吗？”或者“只有一个坐标图可以表示流形吗？”对这些问题的回答是否定的，这意味着给定一个数据集，有多个解的自编码器。因此，它们有时会产生具有严重畸变的潜在空间表示的错误流形。在本文中，我们介绍了解决这些问题的最近的几何方法。

    This paper presents the geometric aspect of the autoencoder framework, which, despite its importance, has been relatively less recognized. Given a set of high-dimensional data points that approximately lie on some lower-dimensional manifold, an autoencoder learns the \textit{manifold} and its \textit{coordinate chart}, simultaneously. This geometric perspective naturally raises inquiries like "Does a finite set of data points correspond to a single manifold?" or "Is there only one coordinate chart that can represent the manifold?". The responses to these questions are negative, implying that there are multiple solution autoencoders given a dataset. Consequently, they sometimes produce incorrect manifolds with severely distorted latent space representations. In this paper, we introduce recent geometric approaches that address these issues.
    
[^24]: VERSE：具有实时推理能力的虚拟梯度感知流转学习

    VERSE: Virtual-Gradient Aware Streaming Lifelong Learning with Anytime Inference. (arXiv:2309.08227v1 [cs.LG])

    [http://arxiv.org/abs/2309.08227](http://arxiv.org/abs/2309.08227)

    这项研究提出了一种具有实时推理能力的流式终身学习方法，采用虚拟梯度进行连续表示学习，借助语义记忆来抑制灾难性遗忘，并在多样化的数据上进行了广泛实验。

    

    终身学习是指在训练AI代理的同时，防止其遗忘以前获得的知识的问题。现有的方法大多关注在静态环境下的终身学习，并且缺乏在快速变化的动态环境中减轻遗忘的能力。流式终身学习是终身学习中一个具有挑战性的设置，其目标是在动态的非平稳环境中进行连续学习而不遗忘。我们引入一种新颖的终身学习方法，该方法是流式的，仅需要对数据进行一次遍历，可以以类增量的方式学习，并且可以进行即时评估（实时推理）。为了实现这些，我们提出了用于连续表示学习的虚拟梯度，以防止灾难性遗忘，并借助基于指数移动平均的语义记忆进一步提高性能。我们在多样化的数据上进行了广泛的实验。

    Lifelong learning, also referred to as continual learning, is the problem of training an AI agent continuously while also preventing it from forgetting its previously acquired knowledge. Most of the existing methods primarily focus on lifelong learning within a static environment and lack the ability to mitigate forgetting in a quickly-changing dynamic environment. Streaming lifelong learning is a challenging setting of lifelong learning with the goal of continuous learning in a dynamic non-stationary environment without forgetting. We introduce a novel approach to lifelong learning, which is streaming, requires a single pass over the data, can learn in a class-incremental manner, and can be evaluated on-the-fly (anytime inference). To accomplish these, we propose virtual gradients for continual representation learning to prevent catastrophic forgetting and leverage an exponential-moving-average-based semantic memory to further enhance performance. Extensive experiments on diverse data
    
[^25]: 使用大型语言模型解决和解释物理词问题接近人类水平

    Using Large Language Model to Solve and Explain Physics Word Problems Approaching Human Level. (arXiv:2309.08182v1 [cs.CL])

    [http://arxiv.org/abs/2309.08182](http://arxiv.org/abs/2309.08182)

    本研究证明，使用大型语言模型(如GPT3.5)可以解决和解释物理词问题，通过对物理知识进行计算和推理，实现了接近人类水平的解决率。此外，该模型还能够总结涉及的知识、生成解释，并创造新的物理词问题。

    

    我们的工作表明，基于文本预训练的大型语言模型(LLM)不仅可以解决纯数学题，还可以解决物理词问题-即基于先前的物理知识进行计算和推理的问题。我们收集并注释了第一个物理词问题数据集-PhysQA，其中包含超过1000个初中物理词问题（包括运动学、质量和密度、力学、热学和电学）。然后我们使用OpenAI的GPT3.5来生成这些问题的答案，发现GPT3.5可以在零样本学习上自动解决49.3%的问题，在少样本学习上则为73.2%。这个结果表明，通过使用类似问题及其答案作为提示，LLM可以解决接近人类水平的基础物理词问题。除了自动解决问题，GPT3.5还可以总结问题涉及的知识或主题，生成相关解释，并根据输入问题综合出新的物理词问题。

    Our work demonstrates that large language model (LLM) pre-trained on texts can not only solve pure math word problems, but also physics word problems-problems to be solved by calculation and inference based on some prior physical knowledge. We collect and annotate the first physics word problem dataset-PhysQA, which contains over 1000 junior high school physics word problems (on Kinematics, Mass&Density, Mechanics, Heat, Electricity). Then we use OpenAI' s GPT3.5 to generate the answer of these problems and found that GPT3.5 could automatically solve 49.3% of the problems on zero-shot learning and 73.2% on few-shot learning. This result show that by using similar problem and its answer as prompt, LLM could solve elementary physics word problems approaching human level. Besides automatically solving problems, GPT3.5 could also summarize the knowledge or topic examined by the problem, generate the relevant explanation, and synthesis new physics word problems according tothe input problem
    
[^26]: 通过神经网络剪枝揭示不变性

    Unveiling Invariances via Neural Network Pruning. (arXiv:2309.08171v1 [cs.LG])

    [http://arxiv.org/abs/2309.08171](http://arxiv.org/abs/2309.08171)

    该论文提出了一种通过神经网络剪枝来学习捕捉数据相关的不变性的新型网络架构的框架。实验证明，这种学习的网络架构在视觉和表格数据集上都比密集神经网络表现出色，不仅效率高，而且效果好。

    

    不变性描述了对数据底层语义没有影响的转换。保持自然不变性的神经网络具有良好的归纳偏差和出色的性能。因此，现代网络被手工设计用来处理众所周知的不变性（例如平移）。我们提出了一个框架，通过剪枝来学习捕捉数据相关的不变性的新型网络架构。我们学到的网络架构在视觉和表格数据集上都比密集神经网络在效率和效果上都表现出色。我们在3个视觉和40个表格数据集上展示了我们的框架。

    Invariance describes transformations that do not alter data's underlying semantics. Neural networks that preserve natural invariance capture good inductive biases and achieve superior performance. Hence, modern networks are handcrafted to handle well-known invariances (ex. translations). We propose a framework to learn novel network architectures that capture data-dependent invariances via pruning. Our learned architectures consistently outperform dense neural networks on both vision and tabular datasets in both efficiency and effectiveness. We demonstrate our framework on multiple deep learning models across 3 vision and 40 tabular datasets.
    
[^27]: 预测还是拒绝：网络数据上的因果效应估计与不确定性

    To Predict or to Reject: Causal Effect Estimation with Uncertainty on Networked Data. (arXiv:2309.08165v1 [cs.LG])

    [http://arxiv.org/abs/2309.08165](http://arxiv.org/abs/2309.08165)

    本文提出了一种基于不确定性的图深度核学习框架来处理网络数据上因果效应估计中的正性假设违反问题，并在实验证明了该方法的优越性。

    

    由于网络观察数据的不平衡性，对于某些个体的因果效应预测可能严重违反正性/重叠假设，导致估计不可靠。然而，关于网络数据个体级治疗效应估计的这种潜在风险在很大程度上未被充分探索。为了创建一个更可信赖的因果效应估计器，我们提出了基于不确定性感知的图深度核学习 (GraphDKL) 框架，并通过Lipschitz约束来建模预测不确定性以识别不可靠的估计。据我们所知，GraphDKL是第一个在执行图上的因果效应估计时处理正性假设违反的框架。通过大量实验证明了我们所提出的方法在网络数据上的不确定性感知因果效应估计方面的优越性。

    Due to the imbalanced nature of networked observational data, the causal effect predictions for some individuals can severely violate the positivity/overlap assumption, rendering unreliable estimations. Nevertheless, this potential risk of individual-level treatment effect estimation on networked data has been largely under-explored. To create a more trustworthy causal effect estimator, we propose the uncertainty-aware graph deep kernel learning (GraphDKL) framework with Lipschitz constraint to model the prediction uncertainty with Gaussian process and identify unreliable estimations. To the best of our knowledge, GraphDKL is the first framework to tackle the violation of positivity assumption when performing causal effect estimation with graphs. With extensive experiments, we demonstrate the superiority of our proposed method in uncertainty-aware causal effect estimation on networked data.
    
[^28]: 研究自我评估测试在大型语言模型的人格测量中的适用性

    Investigating the Applicability of Self-Assessment Tests for Personality Measurement of Large Language Models. (arXiv:2309.08163v1 [cs.CL])

    [http://arxiv.org/abs/2309.08163](http://arxiv.org/abs/2309.08163)

    研究发现，使用自我评估测试对大型语言模型的人格进行测量时，不同的提示会导致非常不同的人格得分，因此缺乏客观标准来判断哪个提示更正确。

    

    随着大型语言模型的能力不断发展，各种最近的研究试图使用用于研究人类行为的心理工具来量化它们的行为。其中一个例子是使用人格自我评估测试来衡量大型语言模型的“人格”。在本文中，我们选择了三个关于使用人格自我评估测试来量化大型语言模型的人格的研究。我们使用这三个不同论文中使用的提示来评估同一大型语言模型的人格。我们发现，这三个提示导致了非常不同的人格得分。这一简单测试揭示了大型语言模型中的人格自我评估得分取决于提示者的主观选择。由于我们不知道大型语言模型的人格得分的真实值，因为此类问题没有正确答案，所以无法声明某个提示比其他提示更正确或更不正确。然后，我们引入了人格选项顺序对称性的属性。

    As large language models (LLM) evolve in their capabilities, various recent studies have tried to quantify their behavior using psychological tools created to study human behavior. One such example is the measurement of "personality" of LLMs using personality self-assessment tests. In this paper, we take three such studies on personality measurement of LLMs that use personality self-assessment tests created to study human behavior. We use the prompts used in these three different papers to measure the personality of the same LLM. We find that all three prompts lead very different personality scores. This simple test reveals that personality self-assessment scores in LLMs depend on the subjective choice of the prompter. Since we don't know the ground truth value of personality scores for LLMs as there is no correct answer to such questions, there's no way of claiming if one prompt is more or less correct than the other. We then introduce the property of option order symmetry for persona
    
[^29]: 寻找你想要的：学习实现需求驱动导航的对象属性空间

    Find What You Want: Learning Demand-conditioned Object Attribute Space for Demand-driven Navigation. (arXiv:2309.08138v1 [cs.RO])

    [http://arxiv.org/abs/2309.08138](http://arxiv.org/abs/2309.08138)

    该论文提出了一种称为需求驱动导航的方法，利用用户的需求与场景中的对象属性空间进行导航决策，并解决了在实际情况中用户无法知道对象名称或指定对象不存在的问题。

    

    视觉对象导航（VON）的任务是使智能体能够在给定的场景中定位特定的对象。为了成功完成VON任务，必须满足两个基本条件：1）用户必须知道所需对象的名称；2）用户指定的对象必须确实存在于场景中。为了满足这些条件，模拟器可以将预定义的对象名称和位置纳入场景的元数据中。然而，在现实世界的情况下，确保始终满足这些条件往往是具有挑战性的。在陌生的环境中，人们可能不知道场景中存在哪些对象，或者他们可能错误地指定一个实际上不存在的对象。尽管存在这些挑战，人们仍然可能对一个对象有需求，这个需求可能可以通过场景中存在的其他对象以等效的方式来满足。因此，我们提出了需求驱动导航（DDN），它利用用户的需求与场景中的对象属性空间进行导航决策。

    The task of Visual Object Navigation (VON) involves an agent's ability to locate a particular object within a given scene. In order to successfully accomplish the VON task, two essential conditions must be fulfilled:1) the user must know the name of the desired object; and 2) the user-specified object must actually be present within the scene. To meet these conditions, a simulator can incorporate pre-defined object names and positions into the metadata of the scene. However, in real-world scenarios, it is often challenging to ensure that these conditions are always met. Human in an unfamiliar environment may not know which objects are present in the scene, or they may mistakenly specify an object that is not actually present. Nevertheless, despite these challenges, human may still have a demand for an object, which could potentially be fulfilled by other objects present within the scene in an equivalent manner. Hence, we propose Demand-driven Navigation (DDN), which leverages the user'
    
[^30]: 通过实践教程向AI创作者传授性别偏见领域的知识，增强他们对性别偏见的认识

    "I'm Not Confident in Debiasing AI Systems Since I Know Too Little": Teaching AI Creators About Gender Bias Through Hands-on Tutorials. (arXiv:2309.08121v1 [cs.HC])

    [http://arxiv.org/abs/2309.08121](http://arxiv.org/abs/2309.08121)

    本文通过实践教程的设计，提高了AI创作者对性别偏见的认识和知识，弥补了传统教育的不足，为未来研究和设计工作提供了指导。

    

    性别偏见在AI系统中广泛存在，给女性用户带来了糟糕的体验，产生了不公正和心理上的伤害。学校教育未能给AI创作者提供关于这个主题的教育，使他们无法有效地减少AI中的性别偏见。本文针对AI创作者设计了实践教程，提高他们对AI中性别偏见的认识，并增强他们对性别偏见来源和去偏方法的知识。通过对18名AI创作者的评估，包括AI研究人员、AI工业从业者（开发人员和产品经理）和学习过AI的学生，我们证明了我们的教程的有效性，这些教程有望弥补CS/AI课程中不足的AI性别偏见教育。根据研究结果，我们综合了设计意义和评估指标，以指导未来研究、教育和设计工作。

    Gender bias is rampant in AI systems, causing bad user experience, injustices, and mental harm to women. School curricula fail to educate AI creators on this topic, leaving them unprepared to mitigate gender bias in AI. In this paper, we designed hands-on tutorials to raise AI creators' awareness of gender bias in AI and enhance their knowledge of sources of gender bias and debiasing techniques. The tutorials were evaluated with 18 AI creators, including AI researchers, AI industrial practitioners (i.e., developers and product managers), and students who had learned AI. Their improved awareness and knowledge demonstrated the effectiveness of our tutorials, which have the potential to complement the insufficient AI gender bias education in CS/AI courses. Based on the findings, we synthesize design implications and a rubric to guide future research, education, and design efforts.
    
[^31]: 使用过程挖掘技术在肱上假肢中的数据驱动目标识别

    Data-Driven Goal Recognition in Transhumeral Prostheses Using Process Mining Techniques. (arXiv:2309.08106v1 [cs.RO])

    [http://arxiv.org/abs/2309.08106](http://arxiv.org/abs/2309.08106)

    该研究通过使用时间序列数据和过程挖掘技术，实现了在肱上假肢中的数据驱动目标识别。实验结果表明，该方法在精确度和召回率上显著优于机器学习技术，并且在错误时表现出较低的自信度。

    

    肱上假肢能够恢复手以下缺失的解剖结构。主动式假肢利用连续的传感器数据识别患者的目标姿势，并主动移动人工肢体。以往研究主要关注于如何利用静止姿势收集的数据来区分目标，而忽略了时间步长的考虑。在这个案例研究中，我们专注于使用来自肌电图电极和运动传感器的时间序列数据来顺序识别患者的目标。我们的方法是将数据转化为离散事件，并训练一个基于过程挖掘的现有目标识别系统。通过在虚拟现实环境中收集了十个受试者的数据，我们的目标识别方法证明了其有效性，相比于现有的机器学习技术，其精确度和召回率显著提高，并且在错误时不太自信。

    A transhumeral prosthesis restores missing anatomical segments below the shoulder, including the hand. Active prostheses utilize real-valued, continuous sensor data to recognize patient target poses, or goals, and proactively move the artificial limb. Previous studies have examined how well the data collected in stationary poses, without considering the time steps, can help discriminate the goals. In this case study paper, we focus on using time series data from surface electromyography electrodes and kinematic sensors to sequentially recognize patients' goals. Our approach involves transforming the data into discrete events and training an existing process mining-based goal recognition system. Results from data collected in a virtual reality setting with ten subjects demonstrate the effectiveness of our proposed goal recognition approach, which achieves significantly better precision and recall than the state-of-the-art machine learning techniques and is less confident when wrong, whi
    
[^32]: 《基于实体邻域信息和描述信息的联合表示学习方法研究》

    Research on Joint Representation Learning Methods for Entity Neighborhood Information and Description Information. (arXiv:2309.08100v1 [cs.CL])

    [http://arxiv.org/abs/2309.08100](http://arxiv.org/abs/2309.08100)

    该研究提出了一种联合表示学习模型，结合实体邻域信息和描述信息，解决了编程设计课程知识图谱中嵌入效果不佳的问题，并在实验中取得了优于其他基线模型的性能表现。

    

    为解决编程设计课程知识图谱中嵌入效果不佳的问题，提出了一种结合实体邻域信息和描述信息的联合表示学习模型。首先，采用图注意力网络获取实体邻域节点的特征，结合关系特征丰富结构信息。然后，利用BERT-WWM模型结合注意力机制获取实体描述信息的表示。最后，通过将实体邻域信息和描述信息的向量表示相结合，得到最终的实体向量表示。实验结果表明，该模型在编程设计课程的知识图谱数据集上表现出良好的性能，优于其他基线模型。

    To address the issue of poor embedding performance in the knowledge graph of a programming design course, a joint represen-tation learning model that combines entity neighborhood infor-mation and description information is proposed. Firstly, a graph at-tention network is employed to obtain the features of entity neigh-boring nodes, incorporating relationship features to enrich the structural information. Next, the BERT-WWM model is utilized in conjunction with attention mechanisms to obtain the representation of entity description information. Finally, the final entity vector representation is obtained by combining the vector representations of entity neighborhood information and description information. Experimental results demonstrate that the proposed model achieves favorable performance on the knowledge graph dataset of the pro-gramming design course, outperforming other baseline models.
    
[^33]: 快速准确的深度循环关闭和位置再定位以实现可靠的LiDAR SLAM

    Fast and Accurate Deep Loop Closing and Relocalization for Reliable LiDAR SLAM. (arXiv:2309.08086v1 [cs.RO])

    [http://arxiv.org/abs/2309.08086](http://arxiv.org/abs/2309.08086)

    本文提出了一个名为LCR-Net的多头网络，利用新颖的特征提取和姿态感知机制来快速准确地处理循环关闭和位置再定位任务。实验结果表明，LCR-Net在候选检索、闭环点云配准和多数据集连续再定位等任务中表现优异，超过了当前最先进的方法，并具有出色的泛化能力。

    

    循环关闭和位置再定位是建立可靠和稳定的长期SLAM的关键技术，用于解决姿态估计漂移和退化问题。本文首先在一个统一的框架下表述了循环关闭和位置再定位。然后，我们提出了一种新颖的多头网络LCR-Net来有效地处理这两个任务。它利用了新颖的特征提取和姿态感知机制来精确估计LiDAR扫描对之间的相似性和6自由度姿态。最后，我们将LCR-Net整合到一个SLAM系统中，在室外驾驶环境中实现了稳健准确的在线LiDAR SLAM。我们通过三种从循环关闭和位置再定位得出的设置，包括候选检索、闭环点云配准和多数据集的连续再定位，对LCR-Net进行了全面评估。结果表明，LCR-Net在这三个任务中表现出色，超过了当前最先进的方法，并展示了出色的泛化能力。

    Loop closing and relocalization are crucial techniques to establish reliable and robust long-term SLAM by addressing pose estimation drift and degeneration. This article begins by formulating loop closing and relocalization within a unified framework. Then, we propose a novel multi-head network LCR-Net to tackle both tasks effectively. It exploits novel feature extraction and pose-aware attention mechanism to precisely estimate similarities and 6-DoF poses between pairs of LiDAR scans. In the end, we integrate our LCR-Net into a SLAM system and achieve robust and accurate online LiDAR SLAM in outdoor driving environments. We thoroughly evaluate our LCR-Net through three setups derived from loop closing and relocalization, including candidate retrieval, closed-loop point cloud registration, and continuous relocalization using multiple datasets. The results demonstrate that LCR-Net excels in all three tasks, surpassing the state-of-the-art methods and exhibiting a remarkable generalizati
    
[^34]: 检索增强型文本到音频生成

    Retrieval-Augmented Text-to-Audio Generation. (arXiv:2309.08051v1 [cs.SD])

    [http://arxiv.org/abs/2309.08051](http://arxiv.org/abs/2309.08051)

    这篇论文提出了一种检索增强的文本到音频生成方法，用于解决长尾文本到音频生成的问题。通过利用检索到的相关文本-音频数据作为额外条件，从而增强了模型的学习能力，在AudioCaps数据集上取得了最先进的结果。

    

    尽管在文本到音频(TTA)生成方面取得了一些进展，我们发现状态-艺术模型，如AudioLDM，在数据集上表现出类别分布不平衡（如AudioCaps）的训练中，其生成性能存在偏差。具体而言，它们在生成常见音频类别方面表现出色，而在罕见类别方面表现不佳，从而降低了整体生成性能。我们将此问题称为长尾文本到音频生成。为解决这个问题，我们提出了一种简单的检索增强方法来进行TTA模型。具体而言，给定一个文本输入提示，我们首先使用对比语音语言预训练（CLAP）模型来检索相关的文本-音频对。然后使用检索到的音频-文本数据的特征作为额外条件来指导TTA模型的学习。我们使用我们提出的方法增强了AudioLDM，并将所得到的增强系统称为Re-AudioLDM。在AudioCaps数据集上，Re-AudioLDM实现了最先进的Frechet得分。

    Despite recent progress in text-to-audio (TTA) generation, we show that the state-of-the-art models, such as AudioLDM, trained on datasets with an imbalanced class distribution, such as AudioCaps, are biased in their generation performance. Specifically, they excel in generating common audio classes while underperforming in the rare ones, thus degrading the overall generation performance. We refer to this problem as long-tailed text-to-audio generation. To address this issue, we propose a simple retrieval-augmented approach for TTA models. Specifically, given an input text prompt, we first leverage a Contrastive Language Audio Pretraining (CLAP) model to retrieve relevant text-audio pairs. The features of the retrieved audio-text data are then used as additional conditions to guide the learning of TTA models. We enhance AudioLDM with our proposed approach and denote the resulting augmented system as Re-AudioLDM. On the AudioCaps dataset, Re-AudioLDM achieves a state-of-the-art Frechet 
    
[^35]: Padding Aware Neurons（填充感知神经元）

    Padding Aware Neurons. (arXiv:2309.08048v1 [cs.CV])

    [http://arxiv.org/abs/2309.08048](http://arxiv.org/abs/2309.08048)

    填充感知神经元（PANs）是一种卷积模型中常见的过滤器，它专注于对输入边界位置的特征化和识别，并且对模型性能有显著影响。

    

    卷积层是大多数与图像相关的模型的基本组成部分。这些层通常默认实现一种静态填充策略（如零填充），以控制内部表示的尺度，并允许以边界为中心的内核激活。在这项工作中，我们识别出填充感知神经元（PANs），这种类型的过滤器在使用静态填充训练的大多数（如果不是全部）卷积模型中都存在。PANs专注于对输入边界位置的特征化和识别，为模型引入了空间归纳偏差（例如，模式通常距离输入边界多近）。我们提出了一种通过它们的激活来识别PANs的方法，并探索了它们在几种流行的预训练模型中的存在，发现从几十个到几百个的PANs。我们讨论并说明了不同类型的PANs、它们的内核和行为。为了了解它们的相关性，我们测试了它们对模型性能的影响，并发现填充和PA对模型性能有显著影响。

    Convolutional layers are a fundamental component of most image-related models. These layers often implement by default a static padding policy (\eg zero padding), to control the scale of the internal representations, and to allow kernel activations centered on the border regions. In this work we identify Padding Aware Neurons (PANs), a type of filter that is found in most (if not all) convolutional models trained with static padding. PANs focus on the characterization and recognition of input border location, introducing a spatial inductive bias into the model (e.g., how close to the input's border a pattern typically is). We propose a method to identify PANs through their activations, and explore their presence in several popular pre-trained models, finding PANs on all models explored, from dozens to hundreds. We discuss and illustrate different types of PANs, their kernels and behaviour. To understand their relevance, we test their impact on model performance, and find padding and PA
    
[^36]: 旅行波编码最近的过去并增强序列学习

    Traveling Waves Encode the Recent Past and Enhance Sequence Learning. (arXiv:2309.08045v1 [cs.NE])

    [http://arxiv.org/abs/2309.08045](http://arxiv.org/abs/2309.08045)

    本论文介绍了Wave-RNN (wRNN)模型，展示了旅行波机制如何有效地编码最近的过去，并在合成记忆任务中比波动模型表现更好。

    

    神经活动的旅行波现象在大脑的不同区域和尺度上都有所观察到，然而，它们在计算角色上的具体作用仍存在争议。一个基于物理的假设认为，皮质层可以像波动场一样，通过沿着皮质表面传播的波动来存储顺序刺激的短期记忆。然而，由于缺乏一个简单的递归神经网络架构能够展现出这种波动，迄今为止，这个想法的计算意义一直是假设性的。在这项工作中，我们引入了一个模型来填补这个空白，我们称之为Wave-RNN (wRNN)，并展示了连通性约束和初始化在波动动力学出现中起到了关键作用。然后，我们经验证实了这样的架构的确通过一系列合成记忆任务有效地编码了最近的过去，在这些任务中，wRNN比波动模型学习更快、表现更好。

    Traveling waves of neural activity have been observed throughout the brain at a diversity of regions and scales; however, their precise computational role is still debated. One physically grounded hypothesis suggests that the cortical sheet may act like a wave-field capable of storing a short-term memory of sequential stimuli through induced waves traveling across the cortical surface. To date, however, the computational implications of this idea have remained hypothetical due to the lack of a simple recurrent neural network architecture capable of exhibiting such waves. In this work, we introduce a model to fill this gap, which we denote the Wave-RNN (wRNN), and demonstrate how both connectivity constraints and initialization play a crucial role in the emergence of wave-like dynamics. We then empirically show how such an architecture indeed efficiently encodes the recent past through a suite of synthetic memory tasks where wRNNs learn faster and perform significantly better than wave-
    
[^37]: 使用众包图像进行大规模建筑属性映射：基于Flickr的场景文本识别和问题解决

    Towards Large-scale Building Attribute Mapping using Crowdsourced Images: Scene Text Recognition on Flickr and Problems to be Solved. (arXiv:2309.08042v1 [cs.CV])

    [http://arxiv.org/abs/2309.08042](http://arxiv.org/abs/2309.08042)

    本研究使用Flickr图像和场景文本识别技术，解决了将众包街景图像应用于建筑属性映射的挑战，并发现了与此任务相关的重大问题，包括小文本区域、缺乏真实标签和建筑不匹配的问题。

    

    众包平台提供了大量包含有价值建筑信息的街景图像。本研究解决了在应用场景文本识别（STR）进行建筑属性映射时的挑战。我们使用了Flickr图像，特别是研究了建筑外墙上的文本。创建了一个柏林Flickr数据集，并使用预训练的STR模型进行文本检测和识别。对STR识别图像的子集进行手动检查，结果显示高准确性。我们研究了STR结果与建筑功能之间的相关性，并分析了在住宅建筑上识别到文本但在商业建筑上未识别到的情况。进一步调查发现了与这一任务相关的重大挑战，包括街景图像中的小文本区域，缺乏真实标签以及Flickr图像中的建筑与OpenStreetMap（OSM）中的建筑足迹不匹配。为了开发城市范围的映射，超越城市热点区域，

    Crowdsourced platforms provide huge amounts of street-view images that contain valuable building information. This work addresses the challenges in applying Scene Text Recognition (STR) in crowdsourced street-view images for building attribute mapping. We use Flickr images, particularly examining texts on building facades. A Berlin Flickr dataset is created, and pre-trained STR models are used for text detection and recognition. Manual checking on a subset of STR-recognized images demonstrates high accuracy. We examined the correlation between STR results and building functions, and analysed instances where texts were recognized on residential buildings but not on commercial ones. Further investigation revealed significant challenges associated with this task, including small text regions in street-view images, the absence of ground truth labels, and mismatches in buildings in Flickr images and building footprints in OpenStreetMap (OSM). To develop city-wide mapping beyond urban hotspo
    
[^38]: BEA: 重新审视使用Budding Ensemble Architecture的基于锚点的目标检测DNN

    BEA: Revisiting anchor-based object detection DNN using Budding Ensemble Architecture. (arXiv:2309.08036v1 [cs.CV])

    [http://arxiv.org/abs/2309.08036](http://arxiv.org/abs/2309.08036)

    本文提出了一种新型简化的集合结构BEA用于锚点目标检测模型，并通过改进置信度得分的校准与降低不确定性误差的损失函数，提高了模型准确性。

    

    本文介绍了Budding Ensemble Architecture（BEA），一种用于锚点目标检测模型的新型简化集合结构。目标检测模型在基于视觉的任务中非常重要，特别是在自主系统中。它们应该提供精确的边界框检测，并校准其预测的置信度得分，以获得更高质量的不确定性估计。然而，由于假阳性接收到高分或真阳性由于低分而被丢弃，当前的模型可能会做出错误的决策。BEA旨在解决这些问题。BEA的提出的损失函数改善了置信度得分的校准和降低了不确定性误差，从而更好地区分真阳性和假阳性，最终提高了目标检测模型的准确性。使用BEA方法和其提出的损失函数，对Base-YOLOv3和SSD模型进行了改进。BEA在KITTI数据集上训练的Base-YOLOv3结果中，精度分别提高了6%和3.7%。

    This paper introduces the Budding Ensemble Architecture (BEA), a novel reduced ensemble architecture for anchor-based object detection models. Object detection models are crucial in vision-based tasks, particularly in autonomous systems. They should provide precise bounding box detections while also calibrating their predicted confidence scores, leading to higher-quality uncertainty estimates. However, current models may make erroneous decisions due to false positives receiving high scores or true positives being discarded due to low scores. BEA aims to address these issues. The proposed loss functions in BEA improve the confidence score calibration and lower the uncertainty error, which results in a better distinction of true and false positives and, eventually, higher accuracy of the object detection models. Both Base-YOLOv3 and SSD models were enhanced using the BEA method and its proposed loss functions. The BEA on Base-YOLOv3 trained on the KITTI dataset results in a 6% and 3.7% i
    
[^39]: 基于视觉的酒驾司机行为和驾驶性能分析

    Vision-based Analysis of Driver Activity and Driving Performance Under the Influence of Alcohol. (arXiv:2309.08021v1 [cs.CV])

    [http://arxiv.org/abs/2309.08021](http://arxiv.org/abs/2309.08021)

    该论文介绍了一项研究，通过使用多种传感器，研究了急性酒精摄入对驾驶性能的影响，并通过识别酒驾行为来减少酒驾事故。

    

    美国约30%的交通事故死亡涉及酒驾，因此在美国和其他高酒驾患病率地区，防止酒驾对车辆安全至关重要。通过主动使用传感器（要求驾驶员提供呼气样本给车辆仪器或被警察拦下时），可以监测驾驶能力受损，但使用一种更被动且稳健的感知机制可能能够更广泛地应用智能系统，从而减少酒驾事故。这可以帮助在驾驶前或驾驶过程早期（在事故或被执法部门发现之前）识别出受损驾驶员。在这项研究中，我们介绍了一项使用视觉、热感、音频和化学传感器的多模态集成，以(1)在驾驶模拟器中研究急性酒精摄入对驾驶性能的影响，(2)识别酒驾行为。

    About 30% of all traffic crash fatalities in the United States involve drunk drivers, making the prevention of drunk driving paramount to vehicle safety in the US and other locations which have a high prevalence of driving while under the influence of alcohol. Driving impairment can be monitored through active use of sensors (when drivers are asked to engage in providing breath samples to a vehicle instrument or when pulled over by a police officer), but a more passive and robust mechanism of sensing may allow for wider adoption and benefit of intelligent systems that reduce drunk driving accidents. This could assist in identifying impaired drivers before they drive, or early in the driving process (before a crash or detection by law enforcement). In this research, we introduce a study which adopts a multi-modal ensemble of visual, thermal, audio, and chemical sensors to (1) examine the impact of acute alcohol administration on driving performance in a driving simulator, and (2) identi
    
[^40]: 大型语言模型在零样本临床自然语言处理中提示策略的实证评估

    An Empirical Evaluation of Prompting Strategies for Large Language Models in Zero-Shot Clinical Natural Language Processing. (arXiv:2309.08008v1 [cs.CL])

    [http://arxiv.org/abs/2309.08008](http://arxiv.org/abs/2309.08008)

    该论文通过对五个临床自然语言处理任务的实验研究，评估了不同提示工程方法在大型语言模型上的效果，为解锁临床领域中的知识提供了指导。

    

    大型语言模型（LLMs）在自然语言处理（NLP）领域表现出卓越的能力，尤其在标注数据稀缺或昂贵的领域，如临床领域。然而，要解锁这些LLMs中隐藏的临床知识，我们需要设计有效的提示，可以引导它们在没有任何特定任务训练数据的情况下执行特定的临床NLP任务。这被称为上下文学习，这是一门需要了解不同LLMs和提示工程方法的优点和缺点的艺术和科学。在本文中，我们提出了一个全面而系统的实验研究，针对五个临床NLP任务进行提示工程的评估：临床意义消歧、生物医学证据提取、共指消解、药物状态提取和药物属性提取。我们评估了最近文献中提出的提示方法，包括简单前缀、简单填空、思维链和预期提示，并介绍了一些新的提示方法。

    Large language models (LLMs) have shown remarkable capabilities in Natural Language Processing (NLP), especially in domains where labeled data is scarce or expensive, such as clinical domain. However, to unlock the clinical knowledge hidden in these LLMs, we need to design effective prompts that can guide them to perform specific clinical NLP tasks without any task-specific training data. This is known as in-context learning, which is an art and science that requires understanding the strengths and weaknesses of different LLMs and prompt engineering approaches. In this paper, we present a comprehensive and systematic experimental study on prompt engineering for five clinical NLP tasks: Clinical Sense Disambiguation, Biomedical Evidence Extraction, Coreference Resolution, Medication Status Extraction, and Medication Attribute Extraction. We assessed the prompts proposed in recent literature, including simple prefix, simple cloze, chain of thought, and anticipatory prompts, and introduce
    
[^41]: 使用自动化机器学习方法检测美国东北地区临界地带内研究流域时间序列数据的异常峰行为

    An Automated Machine Learning Approach for Detecting Anomalous Peak Patterns in Time Series Data from a Research Watershed in the Northeastern United States Critical Zone. (arXiv:2309.07992v1 [cs.LG])

    [http://arxiv.org/abs/2309.07992](http://arxiv.org/abs/2309.07992)

    本文提出了一个自动化机器学习框架，用于检测美国东北地区临界地带研究流域传感器生成的时间序列数据中的异常峰值模式。通过合成生成带有标记的数据集和自动超参数优化机制，该框架克服了标记数据和选择合适的深度学习模型的挑战。

    

    本文提出了一种自动化机器学习框架，旨在帮助水文学家检测美国东北地区临界地带研究流域传感器生成的时间序列数据中的异常情况。该框架专注于识别峰值模式异常，这可能是由于传感器故障或自然现象引起的。然而，使用分类方法进行异常检测存在挑战，例如需要标记数据作为基准和选择最适合给定任务和数据集的深度学习模型。为了解决这些挑战，我们的框架通过将合成的峰值模式注入到合成生成的时间序列数据中生成带有标记的数据集，并结合自动化的超参数优化机制。该机制从五种选择的模型中生成一个具有最佳架构和训练参数的优化模型实例，即时序卷积网络（

    This paper presents an automated machine learning framework designed to assist hydrologists in detecting anomalies in time series data generated by sensors in a research watershed in the northeastern United States critical zone. The framework specifically focuses on identifying peak-pattern anomalies, which may arise from sensor malfunctions or natural phenomena. However, the use of classification methods for anomaly detection poses challenges, such as the requirement for labeled data as ground truth and the selection of the most suitable deep learning model for the given task and dataset. To address these challenges, our framework generates labeled datasets by injecting synthetic peak patterns into synthetically generated time series data and incorporates an automated hyperparameter optimization mechanism. This mechanism generates an optimized model instance with the best architectural and training parameters from a pool of five selected models, namely Temporal Convolutional Network (
    
[^42]: 观点文本倒置：通过预训练的2D扩散模型释放新颖的视图合成

    Viewpoint Textual Inversion: Unleashing Novel View Synthesis with Pretrained 2D Diffusion Models. (arXiv:2309.07986v1 [cs.CV])

    [http://arxiv.org/abs/2309.07986](http://arxiv.org/abs/2309.07986)

    本研究展示了通过预训练的2D图像扩散模型，可以从仅有2D监督的情况下提取出3D结构信息，并利用该信息进行3D视觉任务。通过观点神经文本倒置（ViewNeTI）方法，我们可以控制生成图像中对象的3D视点，有效解决新颖视图合成问题，并在单视图情况下具有良好的语义细节和逼真度。

    

    文本到图像扩散模型可以理解对象之间的空间关系，但它们是否能够仅通过2D监督来表示世界的真实3D结构？我们证明，是的，3D知识被编码在2D图像扩散模型（如稳定扩散模型）中，我们展示了这种结构可以用于3D视觉任务。我们的方法，观点神经文本倒置（ViewNeTI），可以控制生成图像中对象的3D视点。我们训练一个小型神经映射器，用于获取相机视点参数并预测文本编码器的潜在向量；然后利用这些潜在向量来调整扩散生成过程，生成具有所需相机视点的图像。ViewNeTI自然解决了新颖视图合成（NVS）问题。通过利用被冻结的扩散模型作为先验知识，我们可以用很少的输入视图来解决NVS问题；我们甚至可以进行单视图新颖视图合成。与之前的方法相比，我们的单视图NVS预测具有良好的语义细节和逼真度。

    Text-to-image diffusion models understand spatial relationship between objects, but do they represent the true 3D structure of the world from only 2D supervision? We demonstrate that yes, 3D knowledge is encoded in 2D image diffusion models like Stable Diffusion, and we show that this structure can be exploited for 3D vision tasks. Our method, Viewpoint Neural Textual Inversion (ViewNeTI), controls the 3D viewpoint of objects in generated images from frozen diffusion models. We train a small neural mapper to take camera viewpoint parameters and predict text encoder latents; the latents then condition the diffusion generation process to produce images with the desired camera viewpoint.  ViewNeTI naturally addresses Novel View Synthesis (NVS). By leveraging the frozen diffusion model as a prior, we can solve NVS with very few input views; we can even do single-view novel view synthesis. Our single-view NVS predictions have good semantic details and photorealism compared to prior methods.
    
[^43]: 用于推理体验智能体的数据源

    A Data Source for Reasoning Embodied Agents. (arXiv:2309.07974v1 [cs.LG])

    [http://arxiv.org/abs/2309.07974](http://arxiv.org/abs/2309.07974)

    本研究提出了一个与体验智能体集成的新数据生成器，用于机器推理。该生成器生成的数据包括模板化的文本查询和答案，并与编码为数据库的世界状态相匹配。通过实验发现，当前模型可以回答一些关于世界状态的问题，但在其他问题上存在困难。

    

    最近在使用机器学习模型进行推理任务方面取得了进展，这得益于新颖的模型架构、大规模的预训练协议以及专门用于微调的推理数据集。在这项工作中，为了进一步推动这些进展，我们引入了一个与体验智能体集成的新数据生成器用于机器推理。生成的数据包括模板化的文本查询和答案，与编码为数据库的世界状态相匹配。这些世界状态是世界动态和智能体行为的结果。我们展示了几种基准模型在训练集实例化上的结果。这些基准模型包括在数据库的文本格式化表示上进行微调的预训练语言模型，以及在知识图表示的图结构Transformer上操作的模型。我们发现这些模型可以回答一些关于世界状态的问题，但在其他问题上存在困难。这些结果暗示了设计神经网络推理新的研究方向。

    Recent progress in using machine learning models for reasoning tasks has been driven by novel model architectures, large-scale pre-training protocols, and dedicated reasoning datasets for fine-tuning. In this work, to further pursue these advances, we introduce a new data generator for machine reasoning that integrates with an embodied agent. The generated data consists of templated text queries and answers, matched with world-states encoded into a database. The world-states are a result of both world dynamics and the actions of the agent. We show the results of several baseline models on instantiations of train sets. These include pre-trained language models fine-tuned on a text-formatted representation of the database, and graph-structured Transformers operating on a knowledge-graph representation of the database. We find that these models can answer some questions about the world-state, but struggle with others. These results hint at new research directions in designing neural reaso
    
[^44]: TiBGL: 模板引导的脑图学习用于功能性神经影像分析

    TiBGL: Template-induced Brain Graph Learning for Functional Neuroimaging Analysis. (arXiv:2309.07947v1 [cs.AI])

    [http://arxiv.org/abs/2309.07947](http://arxiv.org/abs/2309.07947)

    TiBGL是一种模板引导的脑图学习框架，用于功能性神经影像分析。它具有判别和可解释能力，旨在通过学习功能连接数据的有用特征来改进神经疾病的诊断效率。

    

    近年来，功能性磁共振成像已成为研究人类大脑功能连接网络的有力工具。相关研究表明，人脑的功能连接网络可以提高神经疾病诊断的效率。然而，功能性神经影像领域仍存在两个挑战限制着进展。首先，功能连接数据中存在大量噪音和冗余信息，导致性能不佳。其次，现有的脑网络模型往往偏向于分类性能或对学习模型背后的神经科学发现的解释。为了应对这些挑战，本文提出了一种新颖的脑图学习框架，称为模板引导的脑图学习（TiBGL），具有判别和可解释能力。受到与功能连接相关的医学发现的启发，TiBGL的目标是通过模板引导方法来学习功能连接数据的有用特征。

    In recent years, functional magnetic resonance imaging has emerged as a powerful tool for investigating the human brain's functional connectivity networks. Related studies demonstrate that functional connectivity networks in the human brain can help to improve the efficiency of diagnosing neurological disorders. However, there still exist two challenges that limit the progress of functional neuroimaging. Firstly, there exists an abundance of noise and redundant information in functional connectivity data, resulting in poor performance. Secondly, existing brain network models have tended to prioritize either classification performance or the interpretation of neuroscience findings behind the learned models. To deal with these challenges, this paper proposes a novel brain graph learning framework called Template-induced Brain Graph Learning (TiBGL), which has both discriminative and interpretable abilities. Motivated by the related medical findings on functional connectivites, TiBGL prop
    
[^45]: 增强采样方案的掩码非自回归生成建模

    Masked Generative Modeling with Enhanced Sampling Scheme. (arXiv:2309.07945v1 [cs.LG])

    [http://arxiv.org/abs/2309.07945](http://arxiv.org/abs/2309.07945)

    本文提出了一种增强的采样方案 (ESS)，用于掩码非自回归生成建模。该方案能够确保样本的多样性和保真度，并由三个阶段组成：简单迭代解码、关键反向采样和关键重采样。简单迭代解码用于采样标记集，关键反向采样和关键重采样用于掩盖不真实的标记并重建被掩盖的标记，以提高采样的保真度。

    

    本文提出了一种用于掩码非自回归生成建模的新型采样方案。我们分析了TimeVQVAE、MaskGIT和Token-Critic在采样过程中的局限性，并提出了增强采样方案 (ESS) 来克服这些限制。ESS明确确保了样本的多样性和保真度，由三个阶段组成：简单迭代解码、关键反向采样和关键重采样。ESS首先使用MaskGIT中提出的简单迭代解码来采样一个标记集，以确保样本的多样性。然后，标记集经过关键反向采样，掩盖导致不真实样本的标记。在此之后，关键重采样重建被掩盖的标记，直到达到最终采样步骤以确保高度保真度。关键重采样使用来自自我Token-Critic获得的置信度分数更好地衡量采样标记的真实性，而关键反向采样使用量化潜变量空间的结构。

    This paper presents a novel sampling scheme for masked non-autoregressive generative modeling. We identify the limitations of TimeVQVAE, MaskGIT, and Token-Critic in their sampling processes, and propose Enhanced Sampling Scheme (ESS) to overcome these limitations. ESS explicitly ensures both sample diversity and fidelity, and consists of three stages: Naive Iterative Decoding, Critical Reverse Sampling, and Critical Resampling. ESS starts by sampling a token set using the naive iterative decoding as proposed in MaskGIT, ensuring sample diversity. Then, the token set undergoes the critical reverse sampling, masking tokens leading to unrealistic samples. After that, critical resampling reconstructs masked tokens until the final sampling step is reached to ensure high fidelity. Critical resampling uses confidence scores obtained from a self-Token-Critic to better measure the realism of sampled tokens, while critical reverse sampling uses the structure of the quantized latent vector space
    
[^46]: ChatGPT在日志数据上的评估

    An Assessment of ChatGPT on Log Data. (arXiv:2309.07938v1 [cs.SE])

    [http://arxiv.org/abs/2309.07938](http://arxiv.org/abs/2309.07938)

    ChatGPT在日志数据上的性能有限，回复缺乏一致性且存在可扩展性问题。

    

    最近大型语言模型（LLMs）的发展，比如ChatGPT已广泛应用于各种软件工程任务中。许多论文已经报道了ChatGPT在编写代码、摘要、文本生成等方面的潜在优势和局限性的分析。然而，对于日志处理的ChatGPT的当前状态的分析却受到了很少的关注。大规模软件系统生成的日志复杂且难以理解。尽管复杂，但它们为主题专家提供了理解系统状态和诊断系统问题的关键信息。本文中，我们研究了ChatGPT在日志数据上执行几个有趣任务的当前能力，同时也试图找出其主要缺点。我们的发现表明，当前版本的ChatGPT在日志处理方面的性能有限，回复缺乏一致性且存在可扩展性问题。我们还对我们关于改进ChatGPT在日志处理中的观点进行了概述。

    Recent development of large language models (LLMs), such as ChatGPT has been widely applied to a wide range of software engineering tasks. Many papers have reported their analysis on the potential advantages and limitations of ChatGPT for writing code, summarization, text generation, etc. However, the analysis of the current state of ChatGPT for log processing has received little attention. Logs generated by large-scale software systems are complex and hard to understand. Despite their complexity, they provide crucial information for subject matter experts to understand the system status and diagnose problems of the systems. In this paper, we investigate the current capabilities of ChatGPT to perform several interesting tasks on log data, while also trying to identify its main shortcomings. Our findings show that the performance of the current version of ChatGPT for log processing is limited, with a lack of consistency in responses and scalability issues. We also outline our views on h
    
[^47]: Landscape-Sketch-Step: 一种基于AI/ML的元启发式方法解决代理优化问题

    Landscape-Sketch-Step: An AI/ML-Based Metaheuristic for Surrogate Optimization Problems. (arXiv:2309.07936v1 [cs.LG])

    [http://arxiv.org/abs/2309.07936](http://arxiv.org/abs/2309.07936)

    Landscape-Sketch-Step是一种基于AI/ML的元启发式方法，结合了机器学习、随机优化和强化学习技术，用于解决成本函数评估昂贵、不可访问或禁止的代理优化问题。

    

    本文介绍了一种新的全局优化启发式方法，用于在成本函数的评估非常昂贵、不可访问或甚至禁止的场景下进行优化。该方法称为Landscape-Sketch-Step（LSS），结合了机器学习、随机优化和强化学习技术，依赖于先前采样点的历史信息，以明智地选择应评估成本函数的参数值。与复制交换蒙特卡洛方法相比，该方法所需的成本函数评估次数与模拟退火方法相当，这在高通量计算或高性能计算任务等环境中尤为重要，因为评估要么计算成本高昂，要么需要很长时间才能完成。该方法与标准的代理优化技术也不同，因为它不构建代理模型。

    In this paper, we introduce a new heuristics for global optimization in scenarios where extensive evaluations of the cost function are expensive, inaccessible, or even prohibitive. The method, which we call Landscape-Sketch-and-Step (LSS), combines Machine Learning, Stochastic Optimization, and Reinforcement Learning techniques, relying on historical information from previously sampled points to make judicious choices of parameter values where the cost function should be evaluated at. Unlike optimization by Replica Exchange Monte Carlo methods, the number of evaluations of the cost function required in this approach is comparable to that used by Simulated Annealing, quality that is especially important in contexts like high-throughput computing or high-performance computing tasks, where evaluations are either computationally expensive or take a long time to be performed. The method also differs from standard Surrogate Optimization techniques, for it does not construct a surrogate model
    
[^48]: 使用竞速控制变量遗传编程进行符号回归

    Racing Control Variable Genetic Programming for Symbolic Regression. (arXiv:2309.07934v1 [cs.NE])

    [http://arxiv.org/abs/2309.07934](http://arxiv.org/abs/2309.07934)

    提出了一种称为Racing Control Variable Genetic Programming (Racing-CVGP) 的方法，它通过同时进行多个实验计划来加速符号回归过程，并克服了固定实验计划选择不佳导致发现过程延迟的限制。

    

    符号回归是人工智能科学中最重要的任务之一，它从实验数据中发现控制方程。基于遗传编程、蒙特卡洛树搜索或深度强化学习的流行方法可以从固定数据集中学习符号回归。尤其是在学习涉及多个变量的复杂方程时，它们需要海量的数据集和长时间的训练。最近，引入了控制变量遗传编程（CVGP），它通过从设计的控制变量实验中发现方程来加速回归过程。但是，在CVGP中实验集是先验固定的，我们观察到实验计划的次优选择会显著延迟发现过程。为了克服这个限制，我们提出了竞速控制变量遗传编程（Racing-CVGP），它同时进行多个实验计划。类似于选择好的符号方程的选择方案被用于选择实验计划。

    Symbolic regression, as one of the most crucial tasks in AI for science, discovers governing equations from experimental data. Popular approaches based on genetic programming, Monte Carlo tree search, or deep reinforcement learning learn symbolic regression from a fixed dataset. They require massive datasets and long training time especially when learning complex equations involving many variables. Recently, Control Variable Genetic Programming (CVGP) has been introduced which accelerates the regression process by discovering equations from designed control variable experiments. However, the set of experiments is fixed a-priori in CVGP and we observe that sub-optimal selection of experiment schedules delay the discovery process significantly. To overcome this limitation, we propose Racing Control Variable Genetic Programming (Racing-CVGP), which carries out multiple experiment schedules simultaneously. A selection scheme similar to that used in selecting good symbolic equations in the 
    
[^49]: 生成型人工智能

    Generative AI. (arXiv:2309.07930v1 [cs.AI])

    [http://arxiv.org/abs/2309.07930](http://arxiv.org/abs/2309.07930)

    "生成型人工智能"指的是能够从训练数据中生成新颖有意义内容的计算技术，如文本、图像或音频。本文提供了生成型人工智能在社会技术系统中的概念，并介绍了模型、系统和应用的示例。同时，提出了当前生成型人工智能的限制，并提出了对商业与信息系统工程研究的议程，包括研究机会和挑战。

    

    "生成型人工智能"一词指的是能够从训练数据中生成看似新颖有意义的内容，如文本、图像或音频的计算技术。这种技术的广泛应用，例如Dall-E 2，GPT-4和Copilot，正在彻底改变我们工作和与他人交流的方式。在本文中，我们将生成型人工智能形容为社会技术系统中的一种实体，并提供了模型、系统和应用的示例。基于此，我们介绍了当前生成型人工智能的限制，并提出了对商业与信息系统工程（BISE）研究的议程。与以往的研究不同，我们重点讨论了信息系统背景下的生成型人工智能，并在此基础上讨论了BISE社区独特的机遇和挑战，并提出了对BISE研究的有影响的方向的建议。

    The term "generative AI" refers to computational techniques that are capable of generating seemingly new, meaningful content such as text, images, or audio from training data. The widespread diffusion of this technology with examples such as Dall-E 2, GPT-4, and Copilot is currently revolutionizing the way we work and communicate with each other. In this article, we provide a conceptualization of generative AI as an entity in socio-technical systems and provide examples of models, systems, and applications. Based on that, we introduce limitations of current generative AI and provide an agenda for Business & Information Systems Engineering (BISE) research. Different from previous works, we focus on generative AI in the context of information systems, and, to this end, we discuss several opportunities and challenges that are unique to the BISE community and make suggestions for impactful directions for BISE research.
    
[^50]: MER 2023中基于多标签联合解码的分层音频-视觉信息融合

    Hierarchical Audio-Visual Information Fusion with Multi-label Joint Decoding for MER 2023. (arXiv:2309.07925v1 [eess.AS])

    [http://arxiv.org/abs/2309.07925](http://arxiv.org/abs/2309.07925)

    本文提出了一个新颖的框架，用于识别离散和维度情绪，并在MER 2023数据集上取得了最先进的性能和第三的排名。

    

    本文提出了一种用于识别离散和维度情绪的创新框架。在我们的框架中，从基础模型中提取的深层特征被用作原始视频的稳健声音和视觉表示。基于注意力引导的特征聚集的三种不同结构被设计用于深层特征融合。然后，在解码阶段，我们引入了一种联合解码结构，用于情绪分类和价值回归。还设计了基于不确定性的多任务损失来优化整个过程。最后，通过在后验概率水平上结合三种不同结构，我们获得了离散和维度情绪的最终预测结果。在多模态情感识别挑战（MER 2023）的数据集上进行测试时，所提出的框架在情绪分类和价值回归方面取得了一致的改进。我们的最终系统达到了最先进的性能并在MER-M排行榜上排名第三。

    In this paper, we propose a novel framework for recognizing both discrete and dimensional emotions. In our framework, deep features extracted from foundation models are used as robust acoustic and visual representations of raw video. Three different structures based on attention-guided feature gathering (AFG) are designed for deep feature fusion. Then, we introduce a joint decoding structure for emotion classification and valence regression in the decoding stage. A multi-task loss based on uncertainty is also designed to optimize the whole process. Finally, by combining three different structures on the posterior probability level, we obtain the final predictions of discrete and dimensional emotions. When tested on the dataset of multimodal emotion recognition challenge (MER 2023), the proposed framework yields consistent improvements in both emotion classification and valence regression. Our final system achieves state-of-the-art performance and ranks third on the leaderboard on MER-M
    
[^51]: 基于大型语言模型的代理的崛起和潜力：一项调查

    The Rise and Potential of Large Language Model Based Agents: A Survey. (arXiv:2309.07864v1 [cs.AI])

    [http://arxiv.org/abs/2309.07864](http://arxiv.org/abs/2309.07864)

    基于大型语言模型的代理的崛起和潜力：一项调查。大型语言模型被认为是构建通用人工智能代理的潜在催化剂，许多研究已经取得重要进展。

    

    长期以来，人类一直追求人工智能（AI）达到或超越人类水平的目标，而被认为是实现这一目标的有望方式的AI代理。AI代理是能感知环境、做出决策和采取行动的人工实体。自20世纪中叶以来，人们为开发智能AI代理进行了许多努力。然而，这些努力主要集中在算法或训练策略的进步上，以增强特定能力或在特定任务上的性能。实际上，社区所缺乏的是一个足够通用和强大的模型，作为设计能适应各种场景的AI代理的起点。由于展示出的多功能和显著能力，大型语言模型（LLMs）被视为人工通用智能（AGI）的潜在催化剂，为构建通用AI代理提供了希望。许多研究工作利用LLMs作为构建AI代理的基础，并且已经取得重要的进展。

    For a long time, humanity has pursued artificial intelligence (AI) equivalent to or surpassing the human level, with AI agents considered a promising vehicle for this pursuit. AI agents are artificial entities that sense their environment, make decisions, and take actions. Many efforts have been made to develop intelligent AI agents since the mid-20th century. However, these efforts have mainly focused on advancement in algorithms or training strategies to enhance specific capabilities or performance on particular tasks. Actually, what the community lacks is a sufficiently general and powerful model to serve as a starting point for designing AI agents that can adapt to diverse scenarios. Due to the versatile and remarkable capabilities they demonstrate, large language models (LLMs) are regarded as potential sparks for Artificial General Intelligence (AGI), offering hope for building general AI agents. Many research efforts have leveraged LLMs as the foundation to build AI agents and ha
    
[^52]: 无集合的人工智能

    Collectionless Artificial Intelligence. (arXiv:2309.06938v1 [cs.AI])

    [http://arxiv.org/abs/2309.06938](http://arxiv.org/abs/2309.06938)

    本文提出了无集合原则的学习协议的思路，其中机器在环境交互背景中掌握认知技能，避免了数据集集中化的风险。

    

    大体上，处理庞大数据集被认为是机器学习进展和相关领域中壮观结果的基本组成部分，对于这种数据集的集中化存在着越来越多的风险意识。本文支持一种新的学习协议思路，其中机器在真正以环境交互为中心的类人认知背景下掌握认知技能。这意味着学习协议需要遵循无集合原则，即在每个时间点，从环境中获取的数据被用于更新当前环境内部表示，并且代理不能对时间流进行记录。基本上，不能存储来自传感器的时间信息，从而促进了无集合原则的发展。

    By and large, the professional handling of huge data collections is regarded as a fundamental ingredient of the progress of machine learning and of its spectacular results in related disciplines, with a growing agreement on risks connected to the centralization of such data collections. This paper sustains the position that the time has come for thinking of new learning protocols where machines conquer cognitive skills in a truly human-like context centered on environmental interactions. This comes with specific restrictions on the learning protocol according to the collectionless principle, which states that, at each time instant, data acquired from the environment is processed with the purpose of contributing to update the current internal representation of the environment, and that the agent is not given the privilege of recording the temporal stream. Basically, there is neither permission to store the temporal information coming from the sensors, thus promoting the development of s
    
[^53]: 缺失数据下的不确定性交通预测

    Uncertainty-aware Traffic Prediction under Missing Data. (arXiv:2309.06800v1 [cs.LG])

    [http://arxiv.org/abs/2309.06800](http://arxiv.org/abs/2309.06800)

    本研究提出了一种考虑不确定性的交通预测方法，可以处理缺失数据和测量不确定性，并适用于风险敏感任务和决策导向问题。

    

    交通预测是一个重要的课题，因为它在交通领域有广泛的应用。近期，许多研究取得了很好的结果。然而，大多数研究假设预测位置有完整或至少部分的历史记录，不能扩展到无历史记录的位置。在现实场景中，由于预算限制和安装可行性问题，传感器的部署可能受限，这使得大多数当前模型不适用。虽然少数文献尝试在缺失位置上插补交通状态，但这些方法需要与传感器位置同时观测的数据，使它们不适用于预测任务。另一个缺点是缺乏对预测不确定性的测量，使得之前的工作不适用于风险敏感的任务或涉及决策的情况。为了填补这一空白，受到先前的归纳图神经网络的启发，本文提出了一种考虑不确定性的方法。

    Traffic prediction is a crucial topic because of its broad scope of applications in the transportation domain. Recently, various studies have achieved promising results. However, most studies assume the prediction locations have complete or at least partial historical records and cannot be extended to non-historical recorded locations. In real-life scenarios, the deployment of sensors could be limited due to budget limitations and installation availability, which makes most current models not applicable. Though few pieces of literature tried to impute traffic states at the missing locations, these methods need the data simultaneously observed at the locations with sensors, making them not applicable to prediction tasks. Another drawback is the lack of measurement of uncertainty in prediction, making prior works unsuitable for risk-sensitive tasks or involving decision-making. To fill the gap, inspired by the previous inductive graph neural network, this work proposed an uncertainty-awa
    
[^54]: 动态频谱混合器用于视觉识别

    Dynamic Spectrum Mixer for Visual Recognition. (arXiv:2309.06721v1 [cs.CV])

    [http://arxiv.org/abs/2309.06721](http://arxiv.org/abs/2309.06721)

    动态频谱混合器（DSM）是一种内容自适应且计算效率高的结构，通过离散余弦变换表示令牌之间的交互，能够学习长期的空间依赖性。它还引入了动态频谱权重生成层作为频谱带选择器，以强调信息的重要程度。

    

    最近，基于多层感知器（MLP）的视觉主干在几个视觉识别任务中取得了令人期待的性能。然而，现有的基于MLP的方法直接使用静态权重聚合令其无法适应不同的图像。此外，最近的研究表明，MLP-Transformer在创建远程依赖性方面表现出色，但在捕捉主要传输局部信息的高频率方面表现不佳，这使其无法应用于下游的稠密预测任务，如语义分割。为了解决这些挑战，我们提出了一种内容自适应且计算效率高的结构，称为动态频谱混合器（DSM）。DSM通过应用离散余弦变换在频域中表示令牌之间的交互，可以以对数线性复杂度学习长期的空间依赖性。此外，我们还提出了一种动态频谱权重生成层作为频谱带选择器，能够强调信息的重要程度。

    Recently, MLP-based vision backbones have achieved promising performance in several visual recognition tasks. However, the existing MLP-based methods directly aggregate tokens with static weights, leaving the adaptability to different images untouched. Moreover, Recent research demonstrates that MLP-Transformer is great at creating long-range dependencies but ineffective at catching high frequencies that primarily transmit local information, which prevents it from applying to the downstream dense prediction tasks, such as semantic segmentation. To address these challenges, we propose a content-adaptive yet computationally efficient structure, dubbed Dynamic Spectrum Mixer (DSM). The DSM represents token interactions in the frequency domain by employing the Discrete Cosine Transform, which can learn long-term spatial dependencies with log-linear complexity. Furthermore, a dynamic spectrum weight generation layer is proposed as the spectrum bands selector, which could emphasize the infor
    
[^55]: R^3: 基于设备的实时深度强化学习在自主机器人中的应用

    R^3: On-device Real-Time Deep Reinforcement Learning for Autonomous Robotics. (arXiv:2308.15039v1 [cs.RO])

    [http://arxiv.org/abs/2308.15039](http://arxiv.org/abs/2308.15039)

    R^3是一种在自主机器人中应用的基于设备的实时深度强化学习训练方法，它通过动态批量大小和回放缓冲区大小的优化，实现了在时间和算法性能之间的平衡，并有效地管理了内存和算法性能。

    

    自主机器人系统，如自动驾驶车辆和机器人搜救系统，需要在动态环境中连续适应深度强化学习(DRL)模型的高效设备上训练。本研究的基本动机是理解和应对基于设备的实时DRL的挑战，这涉及在内存约束下平衡时间和算法性能的能力，通过我们广泛的实证研究揭示。这种微妙的平衡需要共同优化DRL训练的两个关键参数--批量大小和回放缓冲区大小。配置这些参数对时间和算法性能有重要影响，然而两者都需要相当大的内存分配才能达到接近最优的性能。本文提出了R^3，一种在设备上管理时间、内存和算法性能的整体解决方案。R^3采用（i）一个以截止日期为驱动的反馈循环，带有动态批量大小，

    Autonomous robotic systems, like autonomous vehicles and robotic search and rescue, require efficient on-device training for continuous adaptation of Deep Reinforcement Learning (DRL) models in dynamic environments. This research is fundamentally motivated by the need to understand and address the challenges of on-device real-time DRL, which involves balancing timing and algorithm performance under memory constraints, as exposed through our extensive empirical studies. This intricate balance requires co-optimizing two pivotal parameters of DRL training -- batch size and replay buffer size. Configuring these parameters significantly affects timing and algorithm performance, while both (unfortunately) require substantial memory allocation to achieve near-optimal performance.  This paper presents R^3, a holistic solution for managing timing, memory, and algorithm performance in on-device real-time DRL training. R^3 employs (i) a deadline-driven feedback loop with dynamic batch sizing for 
    
[^56]: MindMap：知识图谱激发大型语言模型的思维图思考方法

    MindMap: Knowledge Graph Prompting Sparks Graph of Thoughts in Large Language Models. (arXiv:2308.09729v1 [cs.AI])

    [http://arxiv.org/abs/2308.09729](http://arxiv.org/abs/2308.09729)

    本论文通过使用知识图谱来激发大型语言模型，解决了整合新知识、产生幻觉和决策过程不透明等问题，并通过生成思维导图展示了模型的推理路径，实验证明这种方法可以取得显著的实证增益。

    

    通常，大型语言模型存在无法整合新知识、产生幻觉和决策过程不透明等限制。本文探讨了如何利用知识图谱（KG）来激发大型语言模型，以解决整合最新知识和引发模型思维路径的问题。具体来说，我们构建了一个提示管道，使大型语言模型能够理解KG输入并利用隐含知识和检索到的外部知识进行推理。此外，我们研究了引发大型语言模型执行推理和生成答案的思维导图。研究发现，生成的思维导图基于知识的本体论，展示了大型语言模型的推理路径，从而为生产环境中的推理提供了探索和评估的可能性。对三个问答数据集的实验证明，MindMap提示方法带来了显著的实证增益。

    LLMs usually exhibit limitations in their ability to incorporate new knowledge, the generation of hallucinations, and the transparency of their decision-making process. In this paper, we explore how to prompt LLMs with knowledge graphs (KG), working as a remedy to engage LLMs with up-to-date knowledge and elicit the reasoning pathways from LLMs. Specifically, we build a prompting pipeline that endows LLMs with the capability of comprehending KG inputs and inferring with a combined implicit knowledge and the retrieved external knowledge. In addition, we investigate eliciting the mind map on which LLMs perform the reasoning and generate the answers. It is identified that the produced mind map exhibits the reasoning pathways of LLMs grounded on the ontology of knowledge, hence bringing the prospects of probing and gauging LLM inference in production. The experiments on three question & answering datasets also show that MindMap prompting leads to a striking empirical gain. For instance, pr
    
[^57]: DCNFIS：深度卷积神经模糊推理系统

    DCNFIS: Deep Convolutional Neuro-Fuzzy Inference System. (arXiv:2308.06378v1 [cs.AI])

    [http://arxiv.org/abs/2308.06378](http://arxiv.org/abs/2308.06378)

    本文介绍了一种新的深度卷积神经模糊推理系统（DCNFIS），它通过将模糊逻辑和深度学习模型相结合，实现了提高透明度而不损失准确性的目标。DCNFIS在准确性上与现有卷积神经网络相当，并且胜过了最先进的深度模糊系统。通过模糊规则提取的解释可以提高模型的可解释性。

    

    在可解释的人工智能中，透明度与准确性之间存在一个著名的权衡。本文介绍了一种新的深度网络设计，通过将模糊逻辑和深度学习模型相结合，实现了提高透明度但不损失准确性的目标。我们设计了一个深度卷积神经模糊推理系统（DCNFIS），并在四个著名数据集上展示了它与三个现有卷积神经网络的相同准确性。我们进一步发现，DCNFIS在性能上胜过了最先进的深度模糊系统。然后，我们利用模糊逻辑的透明度，从DCNFIS中编码的模糊规则中提取解释，以渐变映射的形式展示。我们还利用Fashion-MNIST数据集对这些解释的特性进行了深入研究。

    A key challenge in eXplainable Artificial Intelligence is the well-known tradeoff between the transparency of an algorithm (i.e., how easily a human can directly understand the algorithm, as opposed to receiving a post-hoc explanation), and its accuracy. We report on the design of a new deep network that achieves improved transparency without sacrificing accuracy. We design a deep convolutional neuro-fuzzy inference system (DCNFIS) by hybridizing fuzzy logic and deep learning models and show that DCNFIS performs as accurately as three existing convolutional neural networks on four well-known datasets. We furthermore that DCNFIS outperforms state-of-the-art deep fuzzy systems. We then exploit the transparency of fuzzy logic by deriving explanations, in the form of saliency maps, from the fuzzy rules encoded in DCNFIS. We investigate the properties of these explanations in greater depth using the Fashion-MNIST dataset.
    
[^58]: 可转移的图神经指纹模型快速应对未来生物威胁

    Transferable Graph Neural Fingerprint Models for Quick Response to Future Bio-Threats. (arXiv:2308.01921v1 [q-bio.BM])

    [http://arxiv.org/abs/2308.01921](http://arxiv.org/abs/2308.01921)

    该论文提出了一种可转移的图神经指纹模型，用于快速应对未来的生物威胁。通过利用包含30万种候选药物和23个冠状病毒蛋白靶的COVID-19药物对接数据集，训练了高通量虚拟COVID-19药物筛选的图神经指纹模型。与传统指纹方法相比，该模型在对接得分上具有较高的预测准确性，并且提出了可转移的图神经指纹方法，能够适用于未知的靶点。

    

    基于配体结合亲和力的药物分子快速筛选是药物发现管线中的重要步骤。图神经指纹是一种用于开发高通量和高准确性分子对接代理的有希望方法。在这项研究中，我们建立了一个包含约30万种药物候选物和23个冠状病毒蛋白靶的COVID-19药物对接数据集。利用这个数据集，我们训练了图神经指纹对接模型，用于高通量虚拟COVID-19药物筛选。图神经指纹模型在对接得分上具有很高的预测准确性，对大多数对接靶点的均方误差低于0.21 kcal/mol，相比传统圆形指纹方法有显著改进。为了使神经指纹适用于未知的靶点，我们还提出了一种在多个靶点上训练的可转移的图神经指纹方法。

    Fast screening of drug molecules based on the ligand binding affinity is an important step in the drug discovery pipeline. Graph neural fingerprint is a promising method for developing molecular docking surrogates with high throughput and great fidelity. In this study, we built a COVID-19 drug docking dataset of about 300,000 drug candidates on 23 coronavirus protein targets. With this dataset, we trained graph neural fingerprint docking models for high-throughput virtual COVID-19 drug screening. The graph neural fingerprint models yield high prediction accuracy on docking scores with the mean squared error lower than $0.21$ kcal/mol for most of the docking targets, showing significant improvement over conventional circular fingerprint methods. To make the neural fingerprints transferable for unknown targets, we also propose a transferable graph neural fingerprint method trained on multiple targets. With comparable accuracy to target-specific graph neural fingerprint models, the transf
    
[^59]: Relation-Oriented: 迈向与知识对准的因果人工智能

    Relation-Oriented: Toward Knowledge-Aligned Causal AI. (arXiv:2307.16387v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2307.16387](http://arxiv.org/abs/2307.16387)

    本研究从创新的关系导向视角出发，探讨了当前的建模范式中的观察模型与实际理解的不对齐问题，并提出了关系定义的表示学习方法作为实现关系导向建模的实践方法。

    

    在机器学习中，我们自然地应用一个观察导向的原则，其中观察变量先存在并为构建关系奠定基础。虽然对于传统模型来说足够了，但是人工智能与大数据的整合暴露了观察模型与我们的实际理解之间的不对齐。相反，人类塑造了由关系定义的认知实体，使我们能够跨越时间和超维度空间制定知识，而不是被限制在观察构建中。从一种创新的关系导向的视角出发，本研究通过来自计算机视觉和健康信息学的直观例子，分析了在我们当前的建模范式中这种不对齐的根源。我们还介绍了关系定义的表示学习方法作为关系导向建模的一种实际实施，支持广泛的实验验证。

    In machine learning, we naturally apply an Observation-Oriented principle, in which observational variables preexist and set the stage for constructing relationships. While sufficient for traditional models, the integration of AI with big data exposes the misalignment between the observational models and our actual comprehension. Contrarily, humans shape cognitive entities defined by relationships, enabling us to formulate knowledge across temporal and hyper-dimensional spaces, rather than being confined to observational constructs. From an innovative Relation-Oriented perspective, this study examines the roots of this misalignment within our current modeling paradigm, illuminated by intuitive examples from computer vision and health informatics. We also introduce the relation-defined representation learning methodology as a practical implementation of Relation-Oriented modeling, supported by extensive experimental validation.
    
[^60]: 用学习的代理和约束解决基于多物理的反问题

    Solving multiphysics-based inverse problems with learned surrogates and constraints. (arXiv:2307.11099v1 [physics.geo-ph])

    [http://arxiv.org/abs/2307.11099](http://arxiv.org/abs/2307.11099)

    本论文将学习代理和学习约束相结合用于解决基于多物理的反问题，通过该方法不仅改善了对流体流动性质的反演精度，而且为反演多模态数据提供了一个有效的解决方案。

    

    在地质碳封存监测中，当多模态时变数据昂贵且数值模拟成本高昂时，解决基于多物理的反问题可能具有挑战性。我们通过将计算成本低廉的学习代理与学习约束相结合来克服这些挑战。这种组合不仅能够大大改善对重要流体流动性质（渗透率）的反演，还能为反演多模态数据（包括井测量和主动源时变地震数据）提供一个自然的平台。通过添加学习约束，我们得到了一个计算可行的反演方法，其精度仍然准确。这通过包含一个经过训练的深度神经网络（称为归一化流），使模型迭代保持在分布内，从而保证了作为代理的经过训练的傅里叶神经算子的准确性，这些算子用于代替涉及部分计算昂贵的多相流模拟。

    Solving multiphysics-based inverse problems for geological carbon storage monitoring can be challenging when multimodal time-lapse data are expensive to collect and costly to simulate numerically. We overcome these challenges by combining computationally cheap learned surrogates with learned constraints. Not only does this combination lead to vastly improved inversions for the important fluid-flow property, permeability, it also provides a natural platform for inverting multimodal data including well measurements and active-source time-lapse seismic data. By adding a learned constraint, we arrive at a computationally feasible inversion approach that remains accurate. This is accomplished by including a trained deep neural network, known as a normalizing flow, which forces the model iterates to remain in-distribution, thereby safeguarding the accuracy of trained Fourier neural operators that act as surrogates for the computationally expensive multiphase flow simulations involving partia
    
[^61]: 关于约束时间序列生成问题的研究

    On the Constrained Time-Series Generation Problem. (arXiv:2307.01717v1 [cs.LG])

    [http://arxiv.org/abs/2307.01717](http://arxiv.org/abs/2307.01717)

    这篇论文研究了约束时间序列生成问题。在实际应用中，合成时间序列被广泛用于增强历史时间序列数据集，提高机器学习算法的性能，放大稀有事件的发生，以及创建反事实情景。然而，现有的方法在满足约束方面存在问题，需要重新训练且计算代价高，或者在复杂约束条件下不切实际。

    

    合成时间序列经常在实际应用中用于增加历史时间序列数据集，以提高机器学习算法的性能，放大稀有事件的发生，并创建由时间序列描述的反事实情景。分布相似性（我们称之为真实性）以及满足一定数值约束是反事实时间序列场景生成请求中常见的要求。例如，美联储发布了给定约束时间序列的合成市场压力情景，供金融机构评估其在假设性衰退中的表现。现有的生成约束时间序列的方法通常通过对损失函数进行惩罚来强制满足约束，并拒绝不符合约束的样本。然而，如果我们改变约束条件，这些方法需要重新训练，而拒绝抽样可能在计算上是昂贵的，或者在复杂约束条件下是不切实际的。

    Synthetic time series are often used in practical applications to augment the historical time series dataset for better performance of machine learning algorithms, amplify the occurrence of rare events, and also create counterfactual scenarios described by the time series. Distributional-similarity (which we refer to as realism) as well as the satisfaction of certain numerical constraints are common requirements in counterfactual time series scenario generation requests. For instance, the US Federal Reserve publishes synthetic market stress scenarios given by the constrained time series for financial institutions to assess their performance in hypothetical recessions. Existing approaches for generating constrained time series usually penalize training loss to enforce constraints, and reject non-conforming samples. However, these approaches would require re-training if we change constraints, and rejection sampling can be computationally expensive, or impractical for complex constraints.
    
[^62]: 特征选择：对属性间协作的视角

    Feature Selection: A perspective on inter-attribute cooperation. (arXiv:2306.16559v1 [cs.LG])

    [http://arxiv.org/abs/2306.16559](http://arxiv.org/abs/2306.16559)

    本文综述了辅助特征间协作的过滤特征选择方法的最新研究进展，并总结了不同方法在文献中的贡献。同时提出了当前存在的问题和挑战，以确定未来有前景的研究和发展方向。

    

    高维数据对数据挖掘和机器学习中的学习任务构成了挑战。特征选择是处理维度缩减的一种有效技术，通常是在应用学习算法之前的重要数据处理步骤。在过去几十年中，过滤特征选择方法从简单的单变量相关性排序算法发展到更复杂的相关性-冗余权衡和基于多元依赖性的方法。这种捕捉多变量依赖的趋势旨在通过特征间的互相合作获取关于类别的独特信息。本文对辅助特征间协作的过滤特征选择方法的最新研究工作进行了全面的调查，并总结了文献中不同方法的贡献。此外，还介绍了当前存在的问题和挑战，以确定未来有前景的研究和发展方向。

    High-dimensional datasets depict a challenge for learning tasks in data mining and machine learning. Feature selection is an effective technique in dealing with dimensionality reduction. It is often an essential data processing step prior to applying a learning algorithm. Over the decades, filter feature selection methods have evolved from simple univariate relevance ranking algorithms to more sophisticated relevance-redundancy trade-offs and to multivariate dependencies-based approaches in recent years. This tendency to capture multivariate dependence aims at obtaining unique information about the class from the intercooperation among features. This paper presents a comprehensive survey of the state-of-the-art work on filter feature selection methods assisted by feature intercooperation, and summarizes the contributions of different approaches found in the literature. Furthermore, current issues and challenges are introduced to identify promising future research and development.
    
[^63]: 基于大语言模型的中文细粒度金融情感分析

    Chinese Fine-Grained Financial Sentiment Analysis with Large Language Models. (arXiv:2306.14096v1 [cs.CL])

    [http://arxiv.org/abs/2306.14096](http://arxiv.org/abs/2306.14096)

    本文提出了一个用于企业预警的新型、广泛的中文细粒度金融情感分析数据集FinChina SA，并使用现有开源大语言模型对其进行评估和实验。该数据集将成为推进真实金融情感分析任务探索的宝贵资源。

    

    金融领域实体级别的细粒度情感分析是情感分析的重要子任务，目前面临着众多挑战。其中主要挑战之一来自于缺乏专门设计用于金融文本情感分析的高质量大规模标注语料库，这限制了开发有效文本处理技术所需的数据的可用性。大语言模型（LLMs）的最新进展在自然语言处理任务中取得了显著的性能，主要集中在语言模式匹配方面。在本文中，我们提出了一个新颖的、广泛的中文细粒度金融情感分析数据集FinChina SA，用于企业预警。我们对流行的现有开源LLMs使用我们的数据集进行了全面的评估和实验。我们坚信，我们的数据集将成为推动真实世界金融情感分析任务探索的宝贵资源。

    Entity-level fine-grained sentiment analysis in the financial domain is a crucial subtask of sentiment analysis and currently faces numerous challenges. The primary challenge stems from the lack of high-quality and large-scale annotated corpora specifically designed for financial text sentiment analysis, which in turn limits the availability of data necessary for developing effective text processing techniques. Recent advancements in large language models (LLMs) have yielded remarkable performance in natural language processing tasks, primarily centered around language pattern matching. In this paper, we propose a novel and extensive Chinese fine-grained financial sentiment analysis dataset, FinChina SA, for enterprise early warning. We thoroughly evaluate and experiment with well-known existing open-source LLMs using our dataset. We firmly believe that our dataset will serve as a valuable resource to advance the exploration of real-world financial sentiment analysis tasks, which shoul
    
[^64]: 基于潜在扩散模型的文本驱动Foley音效生成

    Text-Driven Foley Sound Generation With Latent Diffusion Model. (arXiv:2306.10359v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2306.10359](http://arxiv.org/abs/2306.10359)

    本文提出了一种基于扩散模型的Foley音效生成系统，可进行文本条件的生成。我们通过迁移学习对系统进行微调，并引入可训练的层来改善文本嵌入，同时也改进了生成的波形。

    

    Foley音效生成旨在为多媒体内容生成背景音效。先前的模型通常使用大量有标签的开发集作为输入（例如，单个数字或one-hot向量）。本文提出了一种基于扩散模型的Foley音效生成系统，可进行文本条件的生成。为了缓解数据稀缺问题，我们的模型首先使用大规模数据集进行预训练，然后通过对比语言-音频配对（CLAP）技术进行迁移学习来对该任务进行微调。我们观察到，文本编码器提取的特征嵌入可以显著影响生成模型的性能。因此，我们在编码器之后引入可训练的层来改善编码器产生的文本嵌入。此外，我们通过同时生成多个候选音频片段并选择最佳片段来进一步改进生成的波形，最佳片段是根据嵌入之间相似性得分确定的。

    Foley sound generation aims to synthesise the background sound for multimedia content. Previous models usually employ a large development set with labels as input (e.g., single numbers or one-hot vector). In this work, we propose a diffusion model based system for Foley sound generation with text conditions. To alleviate the data scarcity issue, our model is initially pre-trained with large-scale datasets and fine-tuned to this task via transfer learning using the contrastive language-audio pertaining (CLAP) technique. We have observed that the feature embedding extracted by the text encoder can significantly affect the performance of the generation model. Hence, we introduce a trainable layer after the encoder to improve the text embedding produced by the encoder. In addition, we further refine the generated waveform by generating multiple candidate audio clips simultaneously and selecting the best one, which is determined in terms of the similarity score between the embedding of the 
    
[^65]: 物理信息神经网络在逆流自发渗透中的应用和预测：早期和晚期的模拟

    Simulation and Prediction of Countercurrent Spontaneous Imbibition at Early and Late Times Using Physics-Informed Neural Networks. (arXiv:2306.05554v1 [physics.comp-ph])

    [http://arxiv.org/abs/2306.05554](http://arxiv.org/abs/2306.05554)

    本文通过物理信息神经网络模型对多孔材料中的逆流自发渗透过程进行了早期和晚期的模拟和预测，并使用改变变量技术来改进模型性能。

    

    逆流自发渗透（COUCSI）是一种多孔材料中的过程，其中润湿相取代了非润湿相的位置。本文首次探讨了物理信息神经网络（PINNs）在解决早期（ET）和晚期（LT）COUCSI问题中的应用。同时，我们还研究了改变变量技术以改进PINNs的性能。我们通过改变自变量将COUCSI问题分别用XT-，XY-和Z-三种等效形式进行描述：第一个描述了饱和度作为规范化位置X和时间T的函数;第二个描述了X和Y=T^0.5作为函数的饱和度;第三个作为Z=X/T^0.5的唯一函数（仅在ET下有效）。该PINN模型使用前馈神经网络生成，并基于最小化加权损失函数进行训练，包括物理信息丢失项和与初始边界条件相对应的项。没有合成或实验数据被调用。

    Countercurrent spontaneous imbibition (COUCSI) is a process in porous materials in which a wetting phase displaces non-wetting phase. In this work, we investigate for the first time the application of Physics-Informed Neural Networks (PINNs) in solving the 1D COUCSI problem in both early (ET) and late (LT) times. Also novel, we examine the Change-of-Variables technique for improving the performance of PINNs. We formulated the COUCSI problem in three equivalent forms by changing the independent variables: XT-, XY-, and Z-formulations. The first describes saturation as function of normalized position X and time T; the second as function of X and Y=T^0.5; and the third as a sole function of Z=X/T^0.5 (valid only at ET). The PINN model was generated using a feed-forward neural network and trained based on minimizing a weighted loss function, including the physics-informed loss term and terms corresponding to the initial and boundary conditions. No synthetical or experimental data were invo
    
[^66]: 在脉冲神经网络中将噪声作为计算和学习资源

    Exploiting Noise as a Resource for Computation and Learning in Spiking Neural Networks. (arXiv:2305.16044v2 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2305.16044](http://arxiv.org/abs/2305.16044)

    本文提出了噪声脉冲神经元网络（NSNN）和噪声驱动学习规则（NDL），展示了噪声可以作为计算和学习的资源，并为一般脉冲神经元网络提供了一个框架。研究还展示了NSNNs在图像分类和语音识别等实际任务中的适用性，表明它们是未来神经形态计算系统的潜在有力工具。

    

    脉冲神经元网络是大脑非凡信息处理能力的基础，并已成为神经形态智能的支柱模型。本文介绍了噪声脉冲神经元网络（NSNN）和噪声驱动学习规则（NDL），采用带有噪声神经元动力学的脉冲神经元模型。该方法显示噪声可以作为计算和学习的资源，并理论上为一般脉冲神经元网络提供了一个框架。此外，NDL为代理梯度提供了深入的生物学合理性。通过将各种SNN架构和算法结合起来，我们展示了我们的方法表现出竞争性能，并且比确定性SNNs表现出更好的鲁棒性。此外，本文还展示了NSNNs在图像分类和语音识别等实际任务中的适用性，表明它们是未来神经形态计算系统的潜在有力工具。

    Networks of spiking neurons underpin the extraordinary information-processing capabilities of the brain and have emerged as pillar models in neuromorphic intelligence. Despite extensive research on spiking neural networks (SNNs), most are established on deterministic models. Integrating noise into SNNs leads to biophysically more realistic neural dynamics and may benefit model performance. This work presents the noisy spiking neural network (NSNN) and the noise-driven learning rule (NDL) by introducing a spiking neuron model incorporating noisy neuronal dynamics. Our approach shows how noise may act as a resource for computation and learning and theoretically provides a framework for general SNNs. Moreover, NDL provides an insightful biological rationale for surrogate gradients. By incorporating various SNN architectures and algorithms, we show that our approach exhibits competitive performance and improved robustness against challenging perturbations than deterministic SNNs. Additiona
    
[^67]: MLM预训练的动态掩码率调度

    Dynamic Masking Rate Schedules for MLM Pretraining. (arXiv:2305.15096v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.15096](http://arxiv.org/abs/2305.15096)

    本论文提出了一种动态调度掩码率的方法来改进MLM预训练的质量，通过线性降低掩码率，达到了对BERT-base和BERT-large模型分别提高0.46%和0.25%的平均GLUE准确率的效果。这种方法不仅加快了BERT-base的预训练速度，还实现了对BERT-large的帕累托改善。

    

    大多数使用掩码语言建模（MLM）目标进行训练的transformer模型使用了原始BERT模型的固定掩码率15%。我们提出了通过训练过程中动态调整掩码率来替代固定率的方法。我们发现，在预训练过程中线性降低掩码率可以比固定率基准分别提高BERT-base和BERT-large的平均GLUE准确率0.46%和0.25%。这些提升来自于接触高和低掩码率的机制，从而在两种设置中都带来了优势。我们的结果表明，掩码率调度是提高掩码语言模型质量的简单方法，可以使BERT-base的预训练速度提高1.89倍，并对BERT-large实现了帕累托改善。

    Most works on transformers trained with the Masked Language Modeling (MLM) objective use the original BERT model's fixed masking rate of 15%. We propose to instead dynamically schedule the masking rate throughout training. We find that linearly decreasing the masking rate over the course of pretraining improves average GLUE accuracy by up to 0.46% and 0.25% in BERT-base and BERT-large, respectively, compared to fixed rate baselines. These gains come from exposure to both high and low masking rate regimes, providing benefits from both settings. Our results demonstrate that masking rate scheduling is a simple way to improve the quality of masked language models, achieving up to a 1.89x speedup in pretraining for BERT-base as well as a Pareto improvement for BERT-large.
    
[^68]: 使用LLM辅助注释进行语料库语言学研究：本地语法分析案例研究

    Using LLM-assisted Annotation for Corpus Linguistics: A Case Study of Local Grammar Analysis. (arXiv:2305.08339v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.08339](http://arxiv.org/abs/2305.08339)

    本文研究了使用基于大语言模型的聊天机器人自动标注文本的潜力，重点考察了从本地语法角度观察道歉言语行为构成的功能元素的程度，并比较了不同模型在注释任务中的表现，结果表明Bing聊天机器人在任务中表现优于ChatGPT和人类标注员。

    

    基于大语言模型（LLMs）的聊天机器人在语言理解方面表现出很强的能力。本研究探索LLMs在协助基于语料库的语言学研究方面的潜力，通过将文本自动标注为特定语言信息类别。具体而言，我们研究了从本地语法的角度观察道歉言语行为构成的功能元素的程度，通过比较基于GPT-3.5的ChatGPT、基于GPT-4的Bing聊天机器人和人类编码器在注释任务中的表现。结果表明，Bing聊天机器人在任务中表现显着优于ChatGPT。与人类标注员相比，Bing聊天机器人的整体表现略低于人类标注员的表现，但已经取得了较高的F1得分:道歉标记99.95％，原因标记91.91％，道歉者标记95.35％，被道歉者标记89.74％和加强标记96.47％。这表明，在语言类别清晰且可以轻松识别的情况下，使用LLM辅助注释进行语料库语言学研究是可行的。

    Chatbots based on Large Language Models (LLMs) have shown strong capabilities in language understanding. In this study, we explore the potential of LLMs in assisting corpus-based linguistic studies through automatic annotation of texts with specific categories of linguistic information. Specifically, we examined to what extent LLMs understand the functional elements constituting the speech act of apology from a local grammar perspective, by comparing the performance of ChatGPT (powered by GPT-3.5), the Bing chatbot (powered by GPT-4), and a human coder in the annotation task. The results demonstrate that the Bing chatbot significantly outperformed ChatGPT in the task. Compared to human annotator, the overall performance of the Bing chatbot was slightly less satisfactory. However, it already achieved high F1 scores: 99.95% for the tag of APOLOGISING, 91.91% for REASON, 95.35% for APOLOGISER, 89.74% for APOLOGISEE, and 96.47% for INTENSIFIER. This suggests that it is feasible to use LLM-
    
[^69]: CVRecon: 重新思考神经重建的3D几何特征学习

    CVRecon: Rethinking 3D Geometric Feature Learning For Neural Reconstruction. (arXiv:2304.14633v1 [cs.CV])

    [http://arxiv.org/abs/2304.14633](http://arxiv.org/abs/2304.14633)

    研究团队提出了一种基于代价体的3D神经重建框架CVRecon，利用丰富的几何嵌入来促进3D几何特征学习。通过引入射线上下文补偿代价体（RCCV），有效提高了视角相关信息的完整性和鲁棒性，并在各种度量方面显着提高了重建质量。

    

    最近使用图像序列进行神经重建的进展取得了显着进展。但是，由于缺乏深度信息，现有的基于体积的技术仅沿整个相机光线复制对象表面的2D图像特征。我们认为这种复制会在空洞和遮挡空间中引入噪声，从而产生高质量的3D几何体成形方面产生挑战。受传统多视角立体方法的启发，我们提出了一种端到端的3D神经重建框架CVRecon，旨在利用代价体中丰富的几何嵌入来促进3D几何特征学习。此外，我们提出了一种新颖的3D几何特征表示法——射线上下文补偿代价体（RCCV），它具有更好的完整性和鲁棒性，可以编码视角相关信息。通过全面的实验，我们证明了我们的方法在各种度量方面显着提高了重建质量，并恢复了清晰的

    Recent advances in neural reconstruction using posed image sequences have made remarkable progress. However, due to the lack of depth information, existing volumetric-based techniques simply duplicate 2D image features of the object surface along the entire camera ray. We contend this duplication introduces noise in empty and occluded spaces, posing challenges for producing high-quality 3D geometry. Drawing inspiration from traditional multi-view stereo methods, we propose an end-to-end 3D neural reconstruction framework CVRecon, designed to exploit the rich geometric embedding in the cost volumes to facilitate 3D geometric feature learning. Furthermore, we present Ray-contextual Compensated Cost Volume (RCCV), a novel 3D geometric feature representation that encodes view-dependent information with improved integrity and robustness. Through comprehensive experiments, we demonstrate that our approach significantly improves the reconstruction quality in various metrics and recovers clear
    
[^70]: Probe：学习用户在时间跨度的捆绑选择中的个性化投影偏差

    Probe: Learning Users' Personalized Projection Bias in Intertemporal Bundle Choices. (arXiv:2303.06016v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2303.06016](http://arxiv.org/abs/2303.06016)

    本文提出了一种新的偏差嵌入式偏好模型——Probe，旨在解决用户在时间跨度的购物选择中的投影偏差和参照点效应，提高决策的有效性和个性化。

    

    时间跨度的选择需要权衡现在的成本和未来的收益。其中一种具体的选择是决定购买单个物品还是选择包含该物品的捆绑销售方式。以往的研究假设个人对这些选择中涉及的因素有准确的期望。然而，在现实中，用户对这些因素的感知往往存在偏差，导致了非理性和次优的决策。本文重点关注两种常见的偏差：投影偏差和参照点效应，并为此提出了一种新颖的偏差嵌入式偏好模型——Probe。该模型利用加权函数来捕捉用户的投影偏差，利用价值函数来考虑参照点效应，并引入行为经济学中的前景理论来组合加权和价值函数。这使得我们能够确定用户购买捆绑销售的概率，从而提高决策的有效性和个性化。

    Intertemporal choices involve making decisions that require weighing the costs in the present against the benefits in the future. One specific type of intertemporal choice is the decision between purchasing an individual item or opting for a bundle that includes that item. Previous research assumes that individuals have accurate expectations of the factors involved in these choices. However, in reality, users' perceptions of these factors are often biased, leading to irrational and suboptimal decision-making. In this work, we specifically focus on two commonly observed biases: projection bias and the reference-point effect. To address these biases, we propose a novel bias-embedded preference model called Probe. The Probe incorporates a weight function to capture users' projection bias and a value function to account for the reference-point effect, and introduce prospect theory from behavioral economics to combine the weight and value functions. This allows us to determine the probabili
    
[^71]: 数据中心人工智能：通过离散子集作为连续嵌入空间优化实现深度生成可微分特征选择

    Data-Centric AI: Deep Generative Differentiable Feature Selection via Discrete Subsetting as Continuous Embedding Space Optimization. (arXiv:2302.13221v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.13221](http://arxiv.org/abs/2302.13221)

    该论文提出一种将离散特征子集作为连续嵌入空间优化的深度生成可微分特征选择方法，解决了在高维小样本数据集中通用、准确和维度无关的特征选择问题。

    

    特征选择（FS）旨在为给定的下游任务找到最佳特征子集，例如过滤器、包装器和嵌入式方法。但在许多实际应用中，FS的标准在不同领域中变化，并且当数据是高维和小样本时，FS容易出现问题。选择的特征子集是否可以更通用、准确和维度无关？我们将这个问题泛化为一个深度可微分特征选择任务，并提出了一个新的视角：将离散特征子集作为连续嵌入空间优化。我们开发了一个通用和原则性的框架，包括深度特征子集编码器、准确性评估器、解码器和梯度上升优化器。这个框架实现了四个步骤：1) 特征-准确性训练数据准备；2) 深度特征子集嵌入；3) 梯度优化搜索；4) 特征子集重建。我们提出了新的技术洞见：将强化作为训练数据生成器、多样化的集成模型视为搜索加速器、多尺度的特征选择和逐渐增强的探索

    Feature Selection (FS), such as filter, wrapper, and embedded methods, aims to find the optimal feature subset for a given downstream task. However, in many real-world practices, 1) the criteria of FS vary across domains; 2) FS is brittle when data is a high-dimensional and small sample size. Can selected feature subsets be more generalized, accurate, and input dimensionality agnostic? We generalize this problem into a deep differentiable feature selection task and propose a new perspective: discrete feature subsetting as continuous embedding space optimization. We develop a generic and principled framework including a deep feature subset encoder, accuracy evaluator, decoder, and gradient ascent optimizer. This framework implements four steps: 1) features-accuracy training data preparation; 2) deep feature subset embedding; 3) gradient-optimized search; 4) feature subset reconstruction. We develop new technical insights: reinforcement as a training data generator, ensembles of diverse 
    
[^72]: 边缘机器学习的综述与分类：需求，范式和技术

    A Comprehensive Review and a Taxonomy of Edge Machine Learning: Requirements, Paradigms, and Techniques. (arXiv:2302.08571v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.08571](http://arxiv.org/abs/2302.08571)

    这篇论文综述了边缘机器学习的需求、范式和技术，并强调了其在保护隐私、实现低延迟的实时性能和资源优化方面的重要性。

    

    边缘计算(EC)和人工智能(AI)的结合提出了边缘AI的概念，为了保护隐私，实现低延迟的实时性能和资源优化，提供了接近最终用户环境的智能解决方案。机器学习(ML)作为近年来AI中最先进的分支，在边缘环境中展示了令人鼓舞的结果和应用。然而，边缘驱动的ML解决方案更加复杂，因为它同时考虑到边缘计算和AI领域的约束，并且期望这些解决方案在边缘ML的需求方面高效且适应性强，如数据处理，模型压缩，分布式推理和高级学习范式。尽管在学术界和工业界都受到了边缘ML的关注，但我们注意到缺乏对现有边缘ML技术的完整调查，以提供一个共同的理解。

    The union of Edge Computing (EC) and Artificial Intelligence (AI) has brought forward the Edge AI concept to provide intelligent solutions close to the end-user environment, for privacy preservation, low latency to real-time performance, and resource optimization. Machine Learning (ML), as the most advanced branch of AI in the past few years, has shown encouraging results and applications in the edge environment. Nevertheless, edge-powered ML solutions are more complex to realize due to the joint constraints from both edge computing and AI domains, and the corresponding solutions are expected to be efficient and adapted in technologies such as data processing, model compression, distributed inference, and advanced learning paradigms for Edge ML requirements. Despite the fact that a great deal of the attention garnered by Edge ML is gained in both the academic and industrial communities, we noticed the lack of a complete survey on existing Edge ML technologies to provide a common unders
    
[^73]: 使用大型语言模型在强化学习中引导预训练

    Guiding Pretraining in Reinforcement Learning with Large Language Models. (arXiv:2302.06692v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.06692](http://arxiv.org/abs/2302.06692)

    这项研究提出了一种使用大型语言模型在强化学习中引导预训练的方法，通过奖励代理根据语言模型建议的目标来塑造探索策略，使代理朝着人类有意义且可能有用的行为方向发展，无需人类的介入。

    

    强化学习算法在没有密集且形状良好的奖励函数的情况下通常很困难。通过奖励代理访问新颖状态或转换的内在动机探索方法可以解决这个限制，但在大型环境中，这些方法对下游任务的相关性有限。我们描述了一种利用文本语料库中的背景知识来塑造探索策略的方法。这种方法称为ELLM（使用LLMs进行探索），通过给代理奖励其达成由语言模型基于代理当前状态描述所提出的目标，引导代理朝着人类有意义且可能有用的行为方向发展，无需人类的介入。我们在Crafter游戏环境和Housekeep机器人模拟器中评估了ELLM，结果表明，经过ELLM训练的代理在预训练阶段有更好的常识行为覆盖率，并且通常与人类行为相匹配。

    Reinforcement learning algorithms typically struggle in the absence of a dense, well-shaped reward function. Intrinsically motivated exploration methods address this limitation by rewarding agents for visiting novel states or transitions, but these methods offer limited benefits in large environments where most discovered novelty is irrelevant for downstream tasks. We describe a method that uses background knowledge from text corpora to shape exploration. This method, called ELLM (Exploring with LLMs) rewards an agent for achieving goals suggested by a language model prompted with a description of the agent's current state. By leveraging large-scale language model pretraining, ELLM guides agents toward human-meaningful and plausibly useful behaviors without requiring a human in the loop. We evaluate ELLM in the Crafter game environment and the Housekeep robotic simulator, showing that ELLM-trained agents have better coverage of common-sense behaviors during pretraining and usually matc
    
[^74]: 基于频率变换的深度学习时间序列分析综述

    A Survey on Deep Learning based Time Series Analysis with Frequency Transformation. (arXiv:2302.02173v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.02173](http://arxiv.org/abs/2302.02173)

    近期，频率变换（FT）在深度学习时间序列分析中得到广泛应用，显著提高了准确性和效率。本文系统回顾和总结了基于FT的深度学习时间序列模型的研究进展，并探讨了其优势、限制以及主要方法。

    

    最近，频率变换（FT）越来越多地被纳入深度学习模型中，可以显著提高时间序列分析的最新准确性和效率。频率变换的优势，如高效性和全局视角，在各种时间序列任务和应用中被迅速探索和利用，展示了频率变换作为一种新的深度学习范式在时间序列分析领域的潜力。尽管这个新兴领域受到了越来越多的关注和研究，但目前还缺乏对基于频率变换的深度学习时间序列模型的系统回顾和深入分析。目前还不清楚为什么频率变换可以提升时间序列分析的效果，以及它在该领域的限制是什么。为了填补这些空白，我们提供了一份全面的综述，系统调查和总结了基于频率变换的深度学习时间序列分析的最新研究进展。具体而言，我们探讨了主要的方法。

    Recently, frequency transformation (FT) has been increasingly incorporated into deep learning models to significantly enhance state-of-the-art accuracy and efficiency in time series analysis. The advantages of FT, such as high efficiency and a global view, have been rapidly explored and exploited in various time series tasks and applications, demonstrating the promising potential of FT as a new deep learning paradigm for time series analysis. Despite the growing attention and the proliferation of research in this emerging field, there is currently a lack of a systematic review and in-depth analysis of deep learning-based time series models with FT. It is also unclear why FT can enhance time series analysis and what its limitations in the field are. To address these gaps, we present a comprehensive review that systematically investigates and summarizes the recent research advancements in deep learning-based time series analysis with FT. Specifically, we explore the primary approaches us
    
[^75]: 因果性和深度生成模型中的新兴协同作用：一项综述

    Emerging Synergies in Causality and Deep Generative Models: A Survey. (arXiv:2301.12351v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.12351](http://arxiv.org/abs/2301.12351)

    这项综述探讨了因果性和深度生成模型之间的新兴协同作用，阐明了将因果性原则融入DGM中的方法，以及在大规模生成模型中应用因果性的研究前沿。

    

    在人工智能领域，了解和建模数据生成过程（DGP）的追求至关重要。深度生成模型（DGM）在捕捉复杂数据分布方面表现出色，但通常在泛化能力和可解释性方面表现不足。而因果性则提供了一种结构化的方法来理解驱动数据生成的机制，并突显了这些过程中固有的因果效应动力学。虽然因果性在可解释性和外推能力方面表现出色，但却面临着高维空间中的复杂性。意识到它们之间的协同潜力，我们深入探讨了因果性和DGM的交汇点。我们阐明了因果性原则在DGM中的整合，探讨了使用DGM进行因果识别的方法，并对因果性在大规模生成模型中的新兴研究前沿，尤其是大型语言模型（LLM）中的生成性问题提供了见解。我们介绍了方法论，突出了开放的挑战和机会。

    In the field of artificial intelligence (AI), the quest to understand and model data-generating processes (DGPs) is of paramount importance. Deep generative models (DGMs) have proven adept in capturing complex data distributions but often fall short in generalization and interpretability. On the other hand, causality offers a structured lens to comprehend the mechanisms driving data generation and highlights the causal-effect dynamics inherent in these processes. While causality excels in interpretability and the ability to extrapolate, it grapples with intricacies of high-dimensional spaces. Recognizing the synergistic potential, we delve into the confluence of causality and DGMs. We elucidate the integration of causal principles within DGMs, investigate causal identification using DGMs, and navigate an emerging research frontier of causality in large-scale generative models, particularly generative large language models (LLMs). We offer insights into methodologies, highlight open cha
    
[^76]: BAFFLE: 离线增强学习中的后门攻击

    BAFFLE: Backdoor Attack in Offline Reinforcement Learning. (arXiv:2210.04688v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.04688](http://arxiv.org/abs/2210.04688)

    本文研究离线增强学习中的后门攻击，通过向数据中添加扰动，使得智能体在注入触发器的观测值上采取低奖励动作，从而提出了BAFFLE方法。

    

    越来越多的研究关注于强化学习（RL）方法，允许智能体通过与环境的交互中收集的试错经验进行学习。最近，离线RL成为一种流行的RL范例，因为它节省了与环境的交互。在离线RL中，数据提供者共享大规模的预先收集的数据集，其他人可以在不与环境交互的情况下训练高质量的智能体。这种范例在机器人控制、自动驾驶等关键任务中表现出有效性。然而，较少关注研究离线RL系统的安全威胁。本文关注后门攻击，其中一些扰动被添加到数据（观测值）中，使得在给定正常观测值的情况下，智能体采取高奖励的动作，在注入触发器的观测值上采取低奖励的动作。在本文中，我们提出了BAFFLE（离线增强学习中的后门攻击），这是一种方法。

    A growing body of research has focused on the Reinforcement Learning (RL) methods which allow the agent to learn from trial-and-error experiences gathered during the interaction with the environment. Recently, offline RL becomes a popular RL paradigm because it saves the interactions with environments. In offline RL, data providers share large pre-collected datasets, and others can train high-quality agents without interacting with the environments. This paradigm has demonstrated effectiveness in critical tasks like robot control, autonomous driving, etc. However, less attention is paid to investigating the security threats to the offline RL system. This paper focuses on backdoor attacks, where some perturbations are added to the data (observations) such that given normal observations, the agent takes high-rewards actions, and low-reward actions on observations injected with triggers. In this paper, we propose Baffle (Backdoor Attack for Offline Reinforcement Learning), an approach tha
    
[^77]: 多感官集成在深度网络中的关键学习期

    Critical Learning Periods for Multisensory Integration in Deep Networks. (arXiv:2210.04643v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.04643](http://arxiv.org/abs/2210.04643)

    对于多感官集成，神经网络在早期训练阶段接受适当相关信号至关重要，而干扰学习过程可能会永久损害技能的发展。早期瞬态动力学对最终的系统性能和学习表示具有决定性影响。

    

    我们展示了神经网络整合来自不同来源信息的能力在早期训练阶段接受适当相关信号的情况下至关重要。干扰学习过程可能会永久损害技能的发展，无论是在人造系统还是生物系统中，这种现象被称为关键学习期。我们展示了关键学习期源于复杂而不稳定的早期瞬态动力学，这对训练系统的最终性能和学习表示具有决定性影响。这一证据挑战了通过分析宽而浅的网络得出的认为神经网络的早期学习动态是简单的、类似于线性模型的观点。实际上，我们展示了即使是深度线性网络在多源集成方面也会出现关键学习期，而浅层网络则不会。

    We show that the ability of a neural network to integrate information from diverse sources hinges critically on being exposed to properly correlated signals during the early phases of training. Interfering with the learning process during this initial stage can permanently impair the development of a skill, both in artificial and biological systems where the phenomenon is known as a critical learning period. We show that critical periods arise from the complex and unstable early transient dynamics, which are decisive of final performance of the trained system and their learned representations. This evidence challenges the view, engendered by analysis of wide and shallow networks, that early learning dynamics of neural networks are simple, akin to those of a linear model. Indeed, we show that even deep linear networks exhibit critical learning periods for multi-source integration, while shallow networks do not. To better understand how the internal representations change according to di
    
[^78]: 深度伪造音频的系统指纹识别：初始数据集与研究

    System Fingerprint Recognition for Deepfake Audio: An Initial Dataset and Investigation. (arXiv:2208.10489v3 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2208.10489](http://arxiv.org/abs/2208.10489)

    本文提出了深度伪造音频的系统指纹识别方法，并通过收集来自中国七个供应商的语音合成系统的数据集进行了初步研究。这项研究为进一步发展系统指纹识别方法提供了基础，并在模型版权保护和数字证据取证等实际场景中具有重要应用价值。

    

    深度语音合成模型的快速发展给社会带来了重大威胁，例如恶意内容操纵。因此，许多研究出现了，旨在检测所谓的深度伪造音频。然而，现有的工作都集中在对真实音频和伪造音频进行二元检测。在模型版权保护和数字证据取证等实际场景中，需要知道生成深度伪造音频的工具或模型来解释决策。这促使我们提出一个问题：我们能识别深度伪造音频的系统指纹吗？在本文中，我们提出了第一个系统指纹识别（SFR）的深度伪造音频数据集，并进行了初步研究。我们从使用最新的深度学习技术的七个中国供应商的语音合成系统中收集了该数据集，包括清晰和压缩集。此外，为了促进系统指纹识别方法的进一步发展，我们提供了外部参考音频，以便进行评估和对比实验。

    The rapid progress of deep speech synthesis models has posed significant threats to society such as malicious content manipulation. Therefore, many studies have emerged to detect the so-called deepfake audio. However, existing works focus on the binary detection of real audio and fake audio. In real-world scenarios such as model copyright protection and digital evidence forensics, it is needed to know what tool or model generated the deepfake audio to explain the decision. This motivates us to ask: Can we recognize the system fingerprints of deepfake audio? In this paper, we present the first deepfake audio dataset for system fingerprint recognition (SFR) and conduct an initial investigation. We collected the dataset from the speech synthesis systems of seven Chinese vendors that use the latest state-of-the-art deep learning technologies, including both clean and compressed sets. In addition, to facilitate the further development of system fingerprint recognition methods, we provide ex
    
[^79]: VQA-GNN: 通过图神经网络推理多模态知识的视觉问答

    VQA-GNN: Reasoning with Multimodal Knowledge via Graph Neural Networks for Visual Question Answering. (arXiv:2205.11501v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2205.11501](http://arxiv.org/abs/2205.11501)

    VQA-GNN是一种通过图神经网络在非结构化和结构化多模态知识之间进行双向融合的新的VQA模型。

    

    视觉问答 (VQA) 需要系统通过统一非结构化（例如问题和答案的上下文 "QA上下文"）和结构化（例如QA上下文和场景的知识图 "概念图"）多模态知识来进行概念级别的推理。现有方法通常通过连接相应的视觉节点和概念节点来合并场景图和概念图，然后将QA上下文表示结合起来进行问题回答。然而，这些方法只能从非结构化知识到结构化知识进行单向融合，限制了它们捕捉多模态知识的异构联合推理的潜力。为了进行更具表达力的推理，我们提出了VQA-GNN，一种新的VQA模型，它在非结构化和结构化多模态知识之间进行双向融合，以获得统一的知识表示。具体来说，我们通过一个超链接连接场景图和概念图，实现了互连。

    Visual question answering (VQA) requires systems to perform concept-level reasoning by unifying unstructured (e.g., the context in question and answer; "QA context") and structured (e.g., knowledge graph for the QA context and scene; "concept graph") multimodal knowledge. Existing works typically combine a scene graph and a concept graph of the scene by connecting corresponding visual nodes and concept nodes, then incorporate the QA context representation to perform question answering. However, these methods only perform a unidirectional fusion from unstructured knowledge to structured knowledge, limiting their potential to capture joint reasoning over the heterogeneous modalities of knowledge. To perform more expressive reasoning, we propose VQA-GNN, a new VQA model that performs bidirectional fusion between unstructured and structured multimodal knowledge to obtain unified knowledge representations. Specifically, we inter-connect the scene graph and the concept graph through a super 
    
[^80]: 不要误会我：如何将深度视觉解释应用于时间序列

    Don't Get Me Wrong: How to Apply Deep Visual Interpretations to Time Series. (arXiv:2203.07861v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2203.07861](http://arxiv.org/abs/2203.07861)

    该论文提出了一个针对时间序列分类和分割任务的框架，通过六个度量来评估基于梯度、传播或干扰的事后可视化解释方法。实验结果表明，这些方法对于时间序列的解释具有较高的可信度和有效性。

    

    在许多应用中，正确解释和理解深度学习模型非常重要。针对图像和自然语言处理的解释性视觉解释方法允许领域专家验证和理解几乎任何深度学习模型。然而，当推广到任意时间序列时，它们在本质上更加复杂和多样化。一个可视化解释是否解释了有效的推理或捕捉了实际特征是难以判断的。因此，我们需要客观评估来获得可信的质量指标，而不是盲目信任。我们提出了一个框架，包括六个正交度量，用于针对时间序列分类和分割任务的基于梯度、传播或干扰的事后视觉解释方法。实验研究包括了常见的时间序列神经网络架构和九种可视化解释方法。我们使用UCR r等多样的数据集评估了这些可视化解释方法。

    The correct interpretation and understanding of deep learning models are essential in many applications. Explanatory visual interpretation approaches for image, and natural language processing allow domain experts to validate and understand almost any deep learning model. However, they fall short when generalizing to arbitrary time series, which is inherently less intuitive and more diverse. Whether a visualization explains valid reasoning or captures the actual features is difficult to judge. Hence, instead of blind trust, we need an objective evaluation to obtain trustworthy quality metrics. We propose a framework of six orthogonal metrics for gradient-, propagation- or perturbation-based post-hoc visual interpretation methods for time series classification and segmentation tasks. An experimental study includes popular neural network architectures for time series and nine visual interpretation methods. We evaluate the visual interpretation methods with diverse datasets from the UCR r
    
[^81]: 深度生成模型和生成人工智能中的多样性

    Diversity in deep generative models and generative AI. (arXiv:2202.09573v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2202.09573](http://arxiv.org/abs/2202.09573)

    该论文介绍了一种基于核测度量化的方法，通过近似整体测度来生成多样性的对象，以解决现有生成算法中对象重复和缺乏多样性的问题。

    

    机器学习的生成算法，如生成对抗网络（GAN）和变分自编码器（VAE），在构建与训练集中相似的对象时展现出令人印象深刻的结果。然而，生成新对象主要依赖于对训练数据集的隐藏结构的理解，然后从多维正态变量中进行采样。尤其是，每个样本都是独立的，可能会重复提出相同类型的对象。为了解决这个缺点，我们介绍了一种基于核测度量化的方法，该方法可以通过将给定目标测度近似为整体来生成新对象，并且能够避免从该分布中已经绘制的元素。这确保了生成对象的多样性。该方法在经典的机器学习基准测试上进行了测试。

    The machine learning generative algorithms such as Generative Adversarial Networks (GAN) and Variational Auto-Encoders (VAE) show impressive results when constructing objects similar to those in a training ensemble. However, the generation of new objects builds mainly on the understanding of the hidden structure of the training dataset followed by a sampling from a multi-dimensional normal variable. In particular each sample is independent from the others and can repeatedly propose same type of objects. To cure this drawback we introduce a kernel-based measure quantization method that can produce new objects from a given target measure by approximating it as a whole and even staying away from elements already drawn from that distribution. This ensures a better diversity of the produced objects. The method is tested on classic machine learning benchmarks.
    
[^82]: HAKE:人类活动理解的知识引擎基础

    HAKE: A Knowledge Engine Foundation for Human Activity Understanding. (arXiv:2202.06851v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2202.06851](http://arxiv.org/abs/2202.06851)

    本论文提出了一个名为HAKE的知识引擎，用于人类活动理解。该引擎通过将像素映射到中间空间，并使用逻辑规则推断语义，展现出了优越的泛化能力和性能。

    

    人类活动理解在人工智能领域引起了广泛的关注，涉及到健康护理和行为分析等多个应用领域。尽管深度学习取得了一些进展，但仍然面临挑战。通常，像物体识别一样的解决方案试图直接将像素映射到语义，但活动模式与物体模式非常不同，从而阻碍了成功。在这项工作中，我们提出了一种新的范例，将任务分为两个阶段：首先将像素映射到由原子活动基元构成的中间空间，然后使用可解释的逻辑规则对检测到的基元进行编程以推断语义。为了得到一个具有代表性的基元空间，我们构建了一个包含26+M个基元标签和逻辑规则的知识库，这些规则是通过人类先验知识或自动发现得到的。我们的框架，人类活动知识引擎（HAKE），在具有挑战性的基准测试上表现出了卓越的泛化能力和性能。

    Human activity understanding is of widespread interest in artificial intelligence and spans diverse applications like health care and behavior analysis. Although there have been advances in deep learning, it remains challenging. The object recognition-like solutions usually try to map pixels to semantics directly, but activity patterns are much different from object patterns, thus hindering success. In this work, we propose a novel paradigm to reformulate this task in two stages: first mapping pixels to an intermediate space spanned by atomic activity primitives, then programming detected primitives with interpretable logic rules to infer semantics. To afford a representative primitive space, we build a knowledge base including 26+ M primitive labels and logic rules from human priors or automatic discovering. Our framework, the Human Activity Knowledge Engine (HAKE), exhibits superior generalization ability and performance upon canonical methods on challenging benchmarks. Code and data
    
[^83]: 人工智能与统计勾结

    Artificial Intelligence and Statistical Collusion. (arXiv:2202.05946v4 [econ.TH] UPDATED)

    [http://arxiv.org/abs/2202.05946](http://arxiv.org/abs/2202.05946)

    本研究提出了一个可处理的模型来研究学习算法之间的战略互动，揭示了一种导致算法勾结出现的机制。通过自发耦合，算法周期性地协调行动，达到更高利润。该模型的参数可预测统计关联的出现和有利于算法勾结的市场结构，进一步展示了自发耦合如何在价格和市场份额上维持勾结，并应用于设计算法市场。

    

    我们开发了一个可处理的模型来研究学习算法之间的战略互动。我们发现了一种导致算法勾结出现的机制。我们观察到算法周期性地协调行动，这些行动比静态纳什均衡更具利润性。这种新的勾结渠道依赖于算法估计中的内生统计关联，我们称之为自发耦合。模型的参数预测了统计关联是否会出现，以及什么市场结构有助于算法勾结。我们展示了自发耦合如何维持价格和市场份额上的勾结，这与文献中的实验证据相补充。最后，我们将结果应用于设计算法市场。

    We develop a tractable model for studying strategic interactions between learning algorithms. We uncover a mechanism responsible for the emergence of algorithmic collusion. We observe that algorithms periodically coordinate on actions that are more profitable than static Nash equilibria. This novel collusive channel relies on an endogenous statistical linkage in the algorithms' estimates which we call spontaneous coupling. The model's parameters predict whether the statistical linkage will appear, and what market structures facilitate algorithmic collusion. We show that spontaneous coupling can sustain collusion in prices and market shares, complementing experimental findings in the literature. Finally, we apply our results to design algorithmic markets.
    
[^84]: 一种基于深度学习驱动的算法流水线用于行作物自主导航的研究

    A Deep Learning Driven Algorithmic Pipeline for Autonomous Navigation in Row-Based Crops. (arXiv:2112.03816v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2112.03816](http://arxiv.org/abs/2112.03816)

    本文提出了一种基于深度学习驱动的算法流水线，用于行作物自主导航。该方法通过利用低范围传感器和季节变化的信息，使用数据驱动的方法生成路径，并结合深度学习优化技术和合成图像数据，实现了稳健且成本效益的自主导航解决方案。

    

    昂贵的传感器和低效的算法流程显著影响自主机器的总体成本。然而，经济实惠的机器人解决方案对于实际应用至关重要，并且它们的财务影响构成了在大多数应用领域中采用服务机器人的基本要求。其中，在精确农业领域的研究人员力图设计出稳健且成本效益的自主平台，以提供真正的大规模竞争解决方案。在本文中，我们提出了一个完整的针对行作物自主导航的算法流水线，专门设计用于应对低范围传感器和季节变化。首先，我们基于稳健的数据驱动方法来生成适用于自治机器的可行路径，仅利用田地的占用栅格地图信息覆盖整个作物区域。此外，我们的解决方案利用了最新的深度学习优化技术和合成图像数据。

    Expensive sensors and inefficient algorithmic pipelines significantly affect the overall cost of autonomous machines. However, affordable robotic solutions are essential to practical usage, and their financial impact constitutes a fundamental requirement to employ service robotics in most fields of application. Among all, researchers in the precision agriculture domain strive to devise robust and cost-effective autonomous platforms in order to provide genuinely large-scale competitive solutions. In this article, we present a complete algorithmic pipeline for row-based crops autonomous navigation, specifically designed to cope with low-range sensors and seasonal variations. Firstly, we build on a robust data-driven methodology to generate a viable path for the autonomous machine, covering the full extension of the crop with only the occupancy grid map information of the field. Moreover, our solution leverages on latest advancement of deep learning optimization techniques and synthetic g
    
[^85]: MixStyle神经网络用于领域泛化和适应性的翻译和摘要机器人。

    MixStyle Neural Networks for Domain Generalization and Adaptation. (arXiv:2107.02053v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2107.02053](http://arxiv.org/abs/2107.02053)

    MixStyle是一个简单的模块，用于提高神经网络对于领域转移的泛化性能。它通过在训练过程中混合两个随机实例的特征统计来合成新领域，从而实现数据增强。MixStyle易于实现，适用于各类学习范式。

    

    神经网络在具有领域转移的未见数据上表现不佳，这是机器学习和人工智能中的一个长期存在的问题。为了克服这个问题，我们提出了MixStyle，这是一个简单的即插即用，无需参数的模块，可以提高领域泛化性能，而无需收集更多的数据或增加模型容量。MixStyle的设计很简单：在训练过程中，在一个前向传播中将两个随机实例的特征统计混合。这个想法是基于最新的风格转换研究发现的，特征统计捕捉到图像风格信息，而图像风格本质上定义了视觉领域。因此，混合特征统计可以被看作是在特征空间中合成新领域的一种高效方式，从而实现了数据增强。MixStyle很容易用几行代码实现，不需要修改训练目标，并且可以适用于各种学习范式，包括监督领域泛化，半监督领域自适应等。

    Neural networks do not generalize well to unseen data with domain shifts -- a longstanding problem in machine learning and AI. To overcome the problem, we propose MixStyle, a simple plug-and-play, parameter-free module that can improve domain generalization performance without the need to collect more data or increase model capacity. The design of MixStyle is simple: it mixes the feature statistics of two random instances in a single forward pass during training. The idea is grounded by the finding from recent style transfer research that feature statistics capture image style information, which essentially defines visual domains. Therefore, mixing feature statistics can be seen as an efficient way to synthesize new domains in the feature space, thus achieving data augmentation. MixStyle is easy to implement with a few lines of code, does not require modification to training objectives, and can fit a variety of learning paradigms including supervised domain generalization, semi-supervi
    
[^86]: AmbiFC: 用证据检验含糊性声明的真实性

    AmbiFC: Fact-Checking Ambiguous Claims with Evidence. (arXiv:2104.00640v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2104.00640](http://arxiv.org/abs/2104.00640)

    本研究提出了一个大规模的事实核查数据集AmbiFC，用于处理现实场景中的含糊性声明核查问题，通过细粒度的证据注释和分析，提出了一种适用于含糊性声明的软标签证据核查方法，并且在注释人员争议分析中发现了相关性。

    

    在实际场景中，自动化事实核查系统必须将声明与检索到的证据进行比较以预测真实性。检索到的证据可能无法明确支持或反驳声明，并产生各种有效解释。现有的事实核查数据集需要模型为每个声明预测单个真实性标签，并且缺乏管理此类模糊性的能力。我们提出了一个大规模的事实核查数据集AmbiFC，其中包含从完整维基百科页面中获取的经过细粒度证据注释的信息需求的现实声明。我们彻底分析了AmbiFC中涉及含糊声明引起的争议，观察到与注释人员的自我评估和专家注释的语言现象强烈相关的注释人员争议。我们引入基于证据的含糊声明的真实性核查任务，比较了三种方法，其中包含注释信号和单标签分类。

    Automated fact-checking systems in real-world scenarios must compare claims with retrieved evidence to predict the veracity. The retrieved evidence may not unambiguously support or refute the claim and yield diverse valid interpretations. Existing fact-checking datasets necessitate that models predict a single veracity label for each claim and lack the ability to manage such ambiguity. We present AmbiFC, a large-scale fact-checking dataset with realistic claims derived from real-world information needs. Our dataset contains fine-grained evidence annotations of passages from complete Wikipedia pages. We thoroughly analyze disagreements arising from ambiguous claims in AmbiFC, observing a strong correlation of annotator disagreement with their self-assessment and expert-annotated linguistic phenomena. We introduce the task of evidence-based fact-checking for ambiguous claims with soft labels, and compare three methodologies incorporating annotation signals with a single-label classificat
    
[^87]: 在循环存在的情况下，基于约束的因果推断利用部分祖先图

    Constraint-Based Causal Discovery using Partial Ancestral Graphs in the presence of Cycles. (arXiv:2005.00610v3 [math.ST] UPDATED)

    [http://arxiv.org/abs/2005.00610](http://arxiv.org/abs/2005.00610)

    本研究证明了在涉及反馈的系统生成的观察数据中，应用Fast Causal Inference (FCI)算法可以得到正确的结果，该算法可以被用于一致地估计因果关系的存在和缺失、直接因果关系的存在和缺失、混淆因素的缺失以及因果图中特定循环的缺失。

    

    虽然反馈回路在许多复杂系统中起着重要作用，但在大部分因果推断文献中忽视了它们的存在，因为通常假设系统从一开始就是非循环的。当将为非循环环境设计的因果推断算法应用于涉及反馈的系统生成的数据时，我们不会期望得到正确的结果。本研究表明，出人意料的是，快速因果推断（FCI）算法在应用于涉及反馈的系统生成的观察数据时的输出是正确的。具体而言，我们证明了对于由简单且$\sigma$-可信结构性因果模型（SCM）生成的观察数据，FCI是可靠而完整的，并且可以用于一致地估计：（i）因果关系的存在和缺失，（ii）直接因果关系的存在和缺失，（iii）混淆因素的缺失，以及（iv）因果图中特定循环的缺失。

    While feedback loops are known to play important roles in many complex systems, their existence is ignored in a large part of the causal discovery literature, as systems are typically assumed to be acyclic from the outset. When applying causal discovery algorithms designed for the acyclic setting on data generated by a system that involves feedback, one would not expect to obtain correct results. In this work, we show that -- surprisingly -- the output of the Fast Causal Inference (FCI) algorithm is correct if it is applied to observational data generated by a system that involves feedback. More specifically, we prove that for observational data generated by a simple and $\sigma$-faithful Structural Causal Model (SCM), FCI is sound and complete, and can be used to consistently estimate (i) the presence and absence of causal relations, (ii) the presence and absence of direct causal relations, (iii) the absence of confounders, and (iv) the absence of specific cycles in the causal graph o
    

