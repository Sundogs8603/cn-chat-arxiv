# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [GKD: Generalized Knowledge Distillation for Auto-regressive Sequence Models.](http://arxiv.org/abs/2306.13649) | 本文提出了广义知识蒸馏（GKD），通过从学生中采样输出序列来缓解分布不匹配，并在优化替代KL等离散度方面处理模型欠规范，达到了在摘要任务上最先进的性能。 |
| [^2] | [Offline Skill Graph (OSG): A Framework for Learning and Planning using Offline Reinforcement Learning Skills.](http://arxiv.org/abs/2306.13630) | 本论文提出了一个离线技能图（OSG）框架，用于在实际环境中解决复杂任务，它由三个模块组成，可以从先前收集的数据中学习并概括出解决长期任务的方法。 |
| [^3] | [Margin Maximization in Attention Mechanism.](http://arxiv.org/abs/2306.13596) | 这篇论文证明了，在softmax-attention模型中，通过在p或等价的W上运行梯度下降，可以收敛到一个最大边缘解，这将局部最优的标记与非最优的标记分隔开。这明确地将注意力机制形式化为标记分离机制。 |
| [^4] | [System-Level Natural Language Feedback.](http://arxiv.org/abs/2306.13588) | 本文提出了一个通用框架，用于解锁系统级别使用自然语言反馈的方法。我们展示了通过任务度量设计和语言模型提示设计，如何使用反馈在人工交互流程中形式化系统级别的设计决策，以便产生更好的模型，并展示了使用系统级别反馈和实例级别反馈的有效性。 |
| [^5] | [Creating Valid Adversarial Examples of Malware.](http://arxiv.org/abs/2306.13587) | 该论文提出了一个可以制造对恶意软件有效的对抗样本的生成器，使用强化学习和功能保护修改，可以成功地攻击梯度提升决策树（GBDT）模型，并获得53.84%的成功逃避率。 |
| [^6] | [Thoughts on Architecture.](http://arxiv.org/abs/2306.13572) | 本文讨论了“建筑”这个词从其希腊历史和应用于建筑和计算机的含义发展到如今的思维方面的路径，并提供了跨越所有三个阶段的“建筑”定义以及重新思考与认知体系结构有关的三个重要问题。 |
| [^7] | [A Survey on Multimodal Large Language Models.](http://arxiv.org/abs/2306.13549) | 本文追踪和总结了多模态大语言模型（MLLM）的最新进展，包括多模态指令调整、多模态上下文学习、多模态思维链和LLM辅助视觉推理等应用，指出了现有挑战和有前途的研究方向。 |
| [^8] | [Inferring Hierarchical Structure in Multi-Room Maze Environments.](http://arxiv.org/abs/2306.13546) | 本文提出了一个分层主动推理模型，在多房间迷宫环境中推断出世界结构，有效实现探索和导航，提高了搜索效率。 |
| [^9] | [Torsion Graph Neural Networks.](http://arxiv.org/abs/2306.13541) | 这项研究提出了一种名为TorGNN的图神经网络模型，其运用解析扭曲度量化图的局部结构，并在16种不同类型的网络链接预测任务上进行了验证。 |
| [^10] | [Exploring AI-enhanced Shared Control for an Assistive Robotic Arm.](http://arxiv.org/abs/2306.13509) | 本文研究如何将人工智能集成到机械臂的共享控制范式中，以帮助运动受损人士实现更高程度的个人自治。 |
| [^11] | [Adaptive Planning Search Algorithm for Analog Circuit Verification.](http://arxiv.org/abs/2306.13484) | 提出了一种机器学习（ML）方法用于模拟电路验证，在使用较少的仿真次数的同时提高了电路响应估计的精度，能够更好地发现最坏情况和故障。 |
| [^12] | [Incorporating Graph Information in Transformer-based AMR Parsing.](http://arxiv.org/abs/2306.13467) | 本论文介绍了一种新的模型和方法LeakDistill，它使用结构适配器将图形信息明确并入到学习的表示中，从而提高了AMR解析性能。实验表明，我们可以通过在训练时使用单词到节点对齐将图形结构信息嵌入编码器中，即使不使用其他数据，也可以通过自我知识蒸馏获得最先进的AMR解析性能。 |
| [^13] | [Lesion Detection on Leaves using Class Activation Maps.](http://arxiv.org/abs/2306.13366) | 本研究提出了一种利用ResNet-18分类器生成类激活图进行植物叶片病损检测的方法，成功预测了0.45的病损位置成功率，消除了病损注释过程的需求。 |
| [^14] | [A physics-informed AI method for calculating melting points with uncertainty control and optimal sampling.](http://arxiv.org/abs/2306.13345) | 本文提出了一种基于物理学知识和人工智能的计算熔点的方法，并演示了如何增强其准确性和控制不确定性。 |
| [^15] | [Energy Optimization for HVAC Systems in Multi-VAV Open Offices: A Deep Reinforcement Learning Approach.](http://arxiv.org/abs/2306.13333) | 本研究提出了一种基于低复杂度深度强化学习模型的多输入多输出体系结构，以最小化可控因素的数量，实现了对多变风量开放式办公室 HVAC 系统的能源优化，与传统系统相比能源消耗减少了 37%，且温度范围违规率极低 (<1%)。 |
| [^16] | [Abstractive Text Summarization for Resumes With Cutting Edge NLP Transformers and LSTM.](http://arxiv.org/abs/2306.13315) | 本研究评估了多种技术（包括LSTM、T5、Pegasus、BART和BART-Large模型）在不同数据集上对简历文本进行分类任务的表现，结果显示微调后的BART-Large模型效果最佳。 |
| [^17] | [Mutually Guided Few-shot Learning for Relational Triple Extraction.](http://arxiv.org/abs/2306.13310) | 提出了相互指导的少样本学习框架，以进行关系三元组提取，并引入了一个新的跨域少样本三元组提取任务，实现了在少样本情况下的有竞争力结果。 |
| [^18] | [Exploring Qualitative Research Using LLMs.](http://arxiv.org/abs/2306.13298) | 本研究比较了人类和LLMs在评论分类方面的理解能力，结果表明两种方法在分类上不太一致，对于分类达成一致仅约占五分之一。 |
| [^19] | [Variance-Covariance Regularization Improves Representation Learning.](http://arxiv.org/abs/2306.13292) | 提出了方差-协方差正则化方法，旨在促进学习网络特征的多样性，改善表示学习和迁移学习的性能。 |
| [^20] | [Correcting discount-factor mismatch in on-policy policy gradient methods.](http://arxiv.org/abs/2306.13284) | 该论文提出了一种改进的算法来解决策略梯度算法中折扣因子不匹配的问题。该算法适用于许多现有的梯度估计器，避免了性能下降的问题。 |
| [^21] | [FedSelect: Customized Selection of Parameters for Fine-Tuning during Personalized Federated Learning.](http://arxiv.org/abs/2306.13264) | 本文提出了一种名为FedSelect的新联邦学习框架，通过寻找最佳客户端子网络从而直接个性化客户端子网络结构和参数，同时保留了全局知识，提高了客户端性能。 |
| [^22] | [A Fast Maximum $k$-Plex Algorithm Parameterized by the Degeneracy Gap.](http://arxiv.org/abs/2306.13258) | 本文提出了一个新参数$g_k(G)$用于最大$k$-plex问题，针对其设计了一个根据$g_k(G)$参数化的精确算法，具有较高的时间复杂度，但可以在实际图中得到应用。 |
| [^23] | [Approximate Causal Effect Identification under Weak Confounding.](http://arxiv.org/abs/2306.13242) | 本文提出了一种有效的方法来在弱混淆下识别因果效应的上限和下限，并证明了这种方法的计算效率优于最先进的多项式程序。 |
| [^24] | [DiversiGATE: A Comprehensive Framework for Reliable Large Language Models.](http://arxiv.org/abs/2306.13230) | DiversiGATE是一个统一框架，汇集了多种LLM验证方法，其中包括自一致性、数学提示和WebGPT，同时提出了一个符合该框架的新模型“SelfLearner”，该模型可以从自己的输出中学习并优化性能，在实验中表现良好，GSM8K基准测试上提高了7%的性能。 |
| [^25] | [TACO: Temporal Latent Action-Driven Contrastive Loss for Visual Reinforcement Learning.](http://arxiv.org/abs/2306.13229) | 本文提出了TACO方法，一种基于时间潜在动作驱动对比损失的视觉强化学习方法，能够同时学习状态表示和动作表示，提高代理学习的效率。 |
| [^26] | [Optimal Cost-Preference Trade-off Planning with Multiple Temporal Tasks.](http://arxiv.org/abs/2306.13222) | 本文提出了一种新颖的偏好概念，可以表达对单个任务以及它们之间关系的偏好，并在此基础上提出了一种能够根据用户偏好生成Pareto最优的规划方案的高效规划框架。 |
| [^27] | [Pre or Post-Softmax Scores in Gradient-based Attribution Methods, What is Best?.](http://arxiv.org/abs/2306.13197) | 在Gradient-based Attribution Methods中，使用Pre Softmax分数或Post Softmax分数的梯度的选择有各自的优缺点，需要根据具体情况进行权衡。 |
| [^28] | [DiMSam: Diffusion Models as Samplers for Task and Motion Planning under Partial Observability.](http://arxiv.org/abs/2306.13196) | 本文提出了一种使用扩散模型作为采样器的任务和动作规划方法，在部分可观测下能够实现长周期受约束的操作计划。 |
| [^29] | [Targeted Background Removal Creates Interpretable Feature Visualizations.](http://arxiv.org/abs/2306.13178) | 通过使用背景去除技术作为训练过程，可提高特征可视化的解释性和人类可识别性。 |
| [^30] | [Amorphous Fortress: Observing Emergent Behavior in Multi-Agent FSMs.](http://arxiv.org/abs/2306.13169) | 介绍了一个名为Amorphous Fortress的系统，在这个系统中，通过 FSMS 实现了多智能体交互，并应用进化搜索算法，探索了隐含在文件中的 Emergent AI 行为。 |
| [^31] | [Anticipatory Thinking Challenges in Open Worlds: Risk Management.](http://arxiv.org/abs/2306.13157) | 研究讨论了开放环境中AI系统所面临的预判性思维的挑战，提出了面向更强大风险管理的未来研究方向。 |
| [^32] | [Rethinking the Physical Symbol Systems Hypothesis.](http://arxiv.org/abs/2306.13150) | 该论文重新思考了物理符号系统假说，并提出了两个新的假说，以弥合符号和神经方法之间的差距。 |
| [^33] | [An overview on the evaluated video retrieval tasks at TRECVID 2022.](http://arxiv.org/abs/2306.13118) | TRECVID是一种TREC风格的视频分析和检索评估方法，它旨在促进数字视频中基于内容的开发和检索信息。TRECVID 2022计划开展六个任务，有来自世界各地的35个研究组织参加。 |
| [^34] | [A Machine Learning Pressure Emulator for Hydrogen Embrittlement.](http://arxiv.org/abs/2306.13116) | 本文提出了一种物理信息的机器学习模型，用于预测管道内壁的气体压力，为管道系统监控提供了第一步。该方法具有较高保真度且优于纯数据驱动的方法。 |
| [^35] | [Human-in-the-Loop Optimization for Deep Stimulus Encoding in Visual Prostheses.](http://arxiv.org/abs/2306.13104) | 本研究提出了一种“人类介入的视觉前列腺深度刺激编码优化”的方法，通过反演前向模型、实时优化编码参数等手段，显著提高了感知质量。 |
| [^36] | [MBrain: A Multi-channel Self-Supervised Learning Framework for Brain Signals.](http://arxiv.org/abs/2306.13102) | MBrain是一种针对脑信号的多通道自监督学习框架，可解决监督学习方法需要高成本临床标签和不同测量方法之间临床模式差异的问题。 |
| [^37] | [BrainNet: Epileptic Wave Detection from SEEG with Hierarchical Graph Diffusion Learning.](http://arxiv.org/abs/2306.13101) | 本研究提出了第一个使用真实世界SEEG数据集进行癫痫波检测的数据驱动研究，通过使用分层图卷积网络技术，可以检测并分析扩散路径，从而有助于临床实践。 |
| [^38] | [Otter-Knowledge: benchmarks of multimodal knowledge graph representation learning from different sources for drug discovery.](http://arxiv.org/abs/2306.12802) | 本研究在药物发现方面使用了多模态知识图谱表示学习，获得了最先进的结果。他们整合了来自不同来源的数据，并提供了基于这些数据的预训练模型。 |
| [^39] | [OptIForest: Optimal Isolation Forest for Anomaly Detection.](http://arxiv.org/abs/2306.12703) | 本论文针对隔离森林算法中分支因子的最优取值问题，基于隔离效率提出创新算法OptIForest，该算法结构简洁、检测性能优秀，可应用于各种异常检测场景。 |
| [^40] | [Reinforcement Learning-based Virtual Fixtures for Teleoperation of Hydraulic Construction Machine.](http://arxiv.org/abs/2306.11897) | 本文提出了一种基于强化学习的方法来优化施工机器人任务性能。实验表明该方法在典型施工任务中的表现良好。 |
| [^41] | [Tourist Attractions Recommendation based on Attention Knowledge Graph Convolution Network.](http://arxiv.org/abs/2306.10946) | 本文提出了一种基于注意力知识图卷积网络的旅游景点推荐模型，通过自动语义发掘目标景点的相邻实体，根据旅客的喜好选择，预测类似景点的概率，实验中取得良好效果。 |
| [^42] | [Text-Driven Foley Sound Generation With Latent Diffusion Model.](http://arxiv.org/abs/2306.10359) | 本文提出了一种基于扩散模型的Foley音效生成系统，可进行文本条件的生成。我们通过迁移学习对系统进行微调，并引入可训练的层来改善文本嵌入，同时也改进了生成的波形。 |
| [^43] | [Human-in-the-Loop through Chain-of-Thought.](http://arxiv.org/abs/2306.07932) | 通过人在循环链中的方式，手动校正系统可以通过探究理性中子逻辑的手动校正来提高LLM的推理性能，并且基于经济理论的CAMLOP可以平衡效用和成本。 |
| [^44] | [Visually-Grounded Descriptions Improve Zero-Shot Image Classification.](http://arxiv.org/abs/2306.06077) | 本文提出了一种称为V-GLOSS的新方法，它利用现代语言模型和语义知识库生成具有视觉基础的类别描述，提高了零样本图像分类的准确性，并引入了一个带有类别描述的银标准数据集。 |
| [^45] | [Comparative Study on the Effects of Noise in ML-Based Anxiety Detection.](http://arxiv.org/abs/2306.01110) | 本研究探究了噪声如何影响基于机器学习的焦虑检测模型，并开发出在嘈杂的现实环境中具有抗干扰性和适应性的模型，以推进该领域的发展。 |
| [^46] | [Divided Attention: Unsupervised Multi-Object Discovery with Contextually Separated Slots.](http://arxiv.org/abs/2304.01430) | 该论文提出了一种新的无监督多对象发现方法，通过一种上下文分隔的槽结构来将视觉场分割为独立运动区域，并用对抗性标准来保证解码器无法重构整个光流。 |
| [^47] | [OTOV2: Automatic, Generic, User-Friendly.](http://arxiv.org/abs/2303.06862) | OTOV2是一种自动、通用且易于使用的深度学习模型压缩方法，只需训练一次即可生成性能具有竞争力的更紧凑模型，无需微调，有效简化了模型压缩过程。 |
| [^48] | [Extending the Pre-Training of BLOOM for Improved Support of Traditional Chinese: Models, Methods and Results.](http://arxiv.org/abs/2303.04715) | 本文介绍了一种名为BLOOM-zh的多语言语言模型，它扩展了BLOOM的预训练，并具有改进的繁体中文支持。BLOOM-zh在繁体中文基准测试中表现优于其前身。 |
| [^49] | [Dual RL: Unification and New Methods for Reinforcement and Imitation Learning.](http://arxiv.org/abs/2302.08560) | 这篇论文介绍了双重强化学习的概念，并在一个统一的框架下解释了几种最新深度强化学习算法及模仿学习方法。作者提出了双重模仿学习方法（DIL）直接最小化策略之间的距离，并提出了一种新的离线演员-评论家方法。 |
| [^50] | [MarioGPT: Open-Ended Text2Level Generation through Large Language Models.](http://arxiv.org/abs/2302.05981) | MarioGPT是第一个文本到超级马里奥兄弟游戏关卡的生成模型，通过大型语言模型实现开放式的、可控制的关卡生成。 |
| [^51] | [Optimizing Agent Collaboration through Heuristic Multi-Agent Planning.](http://arxiv.org/abs/2301.01246) | 提出了一种启发式多智能体规划算法，解决了涉及不同类型智能体的问题，比现有算法表现更好。 |
| [^52] | [Relightable Neural Human Assets from Multi-view Gradient Illuminations.](http://arxiv.org/abs/2212.07648) | 本文提出了一个新的三维人类数据集 UltraStage，其中包含超过 2,000 个高质量的人类资产，这些人类资产都是在多视角和多照明设置下捕获的。最新进展的神经表示法将每个示例解释为神经人类资产，可以在实时下具有灵活性地任意重照。这是第一个高质量、多样化和灵活性高的既适用于人类建模又适用于再照明的大规模人类数据集。 |
| [^53] | [Phenotype Search Trajectory Networks for Linear Genetic Programming.](http://arxiv.org/abs/2211.08516) | 研究基于遗传编程系统的表型搜索轨迹，确定更复杂表型的基因丰度较少，更难被发现，较简单表型则被过度代表容易进化。 |
| [^54] | [Bayesian Networks for the robust and unbiased prediction of depression and its symptoms utilizing speech and multimodal data.](http://arxiv.org/abs/2211.04924) | 使用贝叶斯网络及语音与多模态数据，通过捕获其条件依赖性得出预测结果，更准确地预测抑郁和其相关症状。 |
| [^55] | [On the Informativeness of Supervision Signals.](http://arxiv.org/abs/2211.01407) | 本文使用信息论比较了常用的监督信号对表示学习性能的贡献，并为在大数据时代使用硬标签提供了理论上的证明，但对于少样本学习和分布外泛化，需要使用更丰富的监督信号。 |
| [^56] | [Planning with Spatial-Temporal Abstraction from Point Clouds for Deformable Object Manipulation.](http://arxiv.org/abs/2210.15751) | 本文介绍了一种基于点云的规划框架PASTA，通过结合空间和时间抽象的概念，实现了对长期变形物体操作的有效规划。 |
| [^57] | [Large-step neural network for learning the symplectic evolution from partitioned data.](http://arxiv.org/abs/2208.14148) | 本研究使用分区的方法来训练大步神经网络，学习辛哈密顿系统的演化，有效抑制累积误差，并成功保持Jacobi积分的守恒。 |
| [^58] | [DeepGraviLens: a Multi-Modal Architecture for Classifying Gravitational Lensing Data.](http://arxiv.org/abs/2205.00701) | DeepGraviLens是一种多模态神经网络，用于分类属于不同类型的引力透镜数据，具有高精度和优于现有方法的结果。 |
| [^59] | [Exploring the Context Generalizability in Spatiotemporal Crowd Flow Prediction: Benchmark and Guideline.](http://arxiv.org/abs/2106.16046) | 本文研究了时空人群流量预测中的上下文泛化性，建立了基准，提出了通用分类法，为上下文选择和建模提供了指南。 |
| [^60] | [Open-Ended Multi-Modal Relational Reasoning for Video Question Answering.](http://arxiv.org/abs/2012.00822) | 本文介绍了一个使用开放式多模态关系推理的机器人代理，可以通过语言交互回答视频场景中的问题，并在实验中展示了较好的表现。 |
| [^61] | [Design of the Artificial: lessons from the biological roots of general intelligence.](http://arxiv.org/abs/1703.02245) | 生物系统上下文处理的进化调整通过分层架构实现的信息是构建AGI的关键。 |

# 详细

[^1]: GKD：自回归序列模型的广义知识蒸馏

    GKD: Generalized Knowledge Distillation for Auto-regressive Sequence Models. (arXiv:2306.13649v1 [cs.LG])

    [http://arxiv.org/abs/2306.13649](http://arxiv.org/abs/2306.13649)

    本文提出了广义知识蒸馏（GKD），通过从学生中采样输出序列来缓解分布不匹配，并在优化替代KL等离散度方面处理模型欠规范，达到了在摘要任务上最先进的性能。

    

    知识蒸馏通常用于压缩神经网络，以减少推理成本和内存占用。然而，当前针对自回归模型（如生成语言模型）的蒸馏方法存在两个关键问题：（1）训练期间输出序列和部署时由学生模型生成的序列之间分布不匹配，（2）模型欠规范，学生模型可能不够表达老师分布。为了解决这些问题，我们提出了广义知识蒸馏（GKD）。GKD通过在训练期间从学生中采样输出序列来缓解分布不匹配。此外，GKD通过优化替代KL等离散度来处理模型欠规范，这些离散度集中于生成可能符合老师分布的学生样本。我们证明，在摘要任务上，GKD优于常用的LLM蒸馏方法，在几个基准数据集上实现了最先进的性能。

    Knowledge distillation is commonly used for compressing neural networks to reduce their inference cost and memory footprint. However, current distillation methods for auto-regressive models, such as generative language models (LMs), suffer from two key issues: (1) distribution mismatch between output sequences during training and the sequences generated by the student during its deployment, and (2) model under-specification, where the student model may not be expressive enough to fit the teacher's distribution. To address these issues, we propose Generalized Knowledge Distillation (GKD). GKD mitigates distribution mismatch by sampling output sequences from the student during training. Furthermore, GKD handles model under-specification by optimizing alternative divergences, such as reverse KL, that focus on generating samples from the student that are likely under the teacher's distribution. We demonstrate that GKD outperforms commonly-used approaches for distilling LLMs on summarizatio
    
[^2]: 离线技能图（OSG）：使用离线强化学习技能进行学习和规划的框架。

    Offline Skill Graph (OSG): A Framework for Learning and Planning using Offline Reinforcement Learning Skills. (arXiv:2306.13630v1 [cs.RO])

    [http://arxiv.org/abs/2306.13630](http://arxiv.org/abs/2306.13630)

    本论文提出了一个离线技能图（OSG）框架，用于在实际环境中解决复杂任务，它由三个模块组成，可以从先前收集的数据中学习并概括出解决长期任务的方法。

    

    强化学习因其在竞技游戏中的成功而受到广泛关注。然而，它在日常应用中的采用受到限制（例如工业、家庭、医疗等）。本文通过介绍一个规划离线技能并在实际环境中解决复杂任务的框架来解决这个问题。我们的框架包括三个模块，共同使智能体能够从先前收集的数据中学习并概括出解决长期任务的方法。我们通过对一个需要解决复杂任务的机械臂进行测试来演示我们的方法。

    Reinforcement Learning has received wide interest due to its success in competitive games. Yet, its adoption in everyday applications is limited (e.g. industrial, home, healthcare, etc.). In this paper, we address this limitation by presenting a framework for planning over offline skills and solving complex tasks in real-world environments. Our framework is comprised of three modules that together enable the agent to learn from previously collected data and generalize over it to solve long-horizon tasks. We demonstrate our approach by testing it on a robotic arm that is required to solve complex tasks.
    
[^3]: 注意力机制中的边缘最大化

    Margin Maximization in Attention Mechanism. (arXiv:2306.13596v1 [cs.LG])

    [http://arxiv.org/abs/2306.13596](http://arxiv.org/abs/2306.13596)

    这篇论文证明了，在softmax-attention模型中，通过在p或等价的W上运行梯度下降，可以收敛到一个最大边缘解，这将局部最优的标记与非最优的标记分隔开。这明确地将注意力机制形式化为标记分离机制。

    

    注意力机制是Transformer架构的核心组件，也是大型语言模型取得惊人成功的原因之一。然而，注意力机制背后的理论原则尚不清楚，特别是它的非凸优化动力学。本文探讨了开创性的softmax-attention模型$f(\boldsymbol{X})=\langle \boldsymbol{Xv}, \texttt{softmax}(\boldsymbol{XWp})\rangle$，其中$\boldsymbol{X}$是标记序列，$(\boldsymbol{v},\boldsymbol{W},\boldsymbol{p})$是可调参数。我们证明了在$\boldsymbol{p}$或等价的$\boldsymbol{W}$上运行梯度下降会沿着方向收敛到分隔“局部最优”标记和“非最优”标记的最大边缘解。这明确地形式化了注意力作为一种标记分离机制。值得注意的是，我们的结果适用于一般数据，并使用嵌入$\boldsymbol{Xv}$和$\texttt{softmax}(\boldsymbol{XWp})$精细地表征标记的“最优性”。

    Attention mechanism is a central component of the transformer architecture which led to the phenomenal success of large language models. However, the theoretical principles underlying the attention mechanism are poorly understood, especially its nonconvex optimization dynamics. In this work, we explore the seminal softmax-attention model $f(\boldsymbol{X})=\langle \boldsymbol{Xv}, \texttt{softmax}(\boldsymbol{XWp})\rangle$, where, $\boldsymbol{X}$ is the token sequence and $(\boldsymbol{v},\boldsymbol{W},\boldsymbol{p})$ are tunable parameters. We prove that running gradient descent on $\boldsymbol{p}$, or equivalently $\boldsymbol{W}$, converges in direction to a max-margin solution that separates $\textit{locally-optimal}$ tokens from non-optimal ones. This clearly formalizes attention as a token separation mechanism. Remarkably, our results are applicable to general data and precisely characterize $\textit{optimality}$ of tokens in terms of the value embeddings $\boldsymbol{Xv}$ and
    
[^4]: 系统级自然语言反馈

    System-Level Natural Language Feedback. (arXiv:2306.13588v1 [cs.CL])

    [http://arxiv.org/abs/2306.13588](http://arxiv.org/abs/2306.13588)

    本文提出了一个通用框架，用于解锁系统级别使用自然语言反馈的方法。我们展示了通过任务度量设计和语言模型提示设计，如何使用反馈在人工交互流程中形式化系统级别的设计决策，以便产生更好的模型，并展示了使用系统级别反馈和实例级别反馈的有效性。

    

    自然语言反馈包含了丰富的用户体验信息。现有研究聚焦于实例级别的方法，即将反馈用于细化特定例子，而忽略了其系统范围的应用。本文提出了一个通用框架，用于解锁系统级别使用自然语言反馈的方法。我们展示了如何使用反馈在人工交互流程中形式化系统级别的设计决策，以便产生更好的模型。具体而言，这是通过以下两方面实现的：(i) 任务度量设计; (ii) 用于改进模型响应的语言模型提示设计。我们进行了两项案例研究，来改进搜索查询生成和对话响应生成，展示了使用系统级别反馈的有效性。我们表明系统级别反馈和实例级别反馈的组合带来了进一步的收益，并且由人类撰写的实例级别反馈导致比GPT-3.5撰写的反馈更加扎实。

    Natural language (NL) feedback contains rich information about the user experience. Existing studies focus on an instance-level approach, where feedback is used to refine specific examples, disregarding its system-wide application. This paper proposes a general framework for unlocking the system-level use of NL feedback. We show how to use feedback to formalize system-level design decisions in a human-in-the-loop-process -- in order to produce better models. In particular this is done through: (i) metric design for tasks; and (ii) language model prompt design for refining model responses. We conduct two case studies of this approach for improving search query generation and dialog response generation, demonstrating the effectiveness of the use of system-level feedback. We show the combination of system-level feedback and instance-level feedback brings further gains, and that human written instance-level feedback results in more grounded refinements than GPT-3.5 written ones, underlying
    
[^5]: 制造对恶意软件有效的对抗样本

    Creating Valid Adversarial Examples of Malware. (arXiv:2306.13587v1 [cs.CR])

    [http://arxiv.org/abs/2306.13587](http://arxiv.org/abs/2306.13587)

    该论文提出了一个可以制造对恶意软件有效的对抗样本的生成器，使用强化学习和功能保护修改，可以成功地攻击梯度提升决策树（GBDT）模型，并获得53.84%的成功逃避率。

    

    由于机器学习在许多任务中表现优异，因此成为越来越受欢迎的方法。因此，杀毒软件开发者将机器学习模型纳入其产品中。尽管这些模型改进了恶意软件检测能力，但它们也带有易受对抗攻击的劣势。我们通过强化学习算法提出了一个对抗性恶意代码示例生成器，其强化学习代理使用一组功能保护修改来创建有效的对抗示例。使用近端策略优化（PPO）算法，我们针对梯度提升决策树（GBDT）模型实现了53.84％的逃避率。之前针对GBDT分类器进行训练的PPO代理得分为11.41％的逃避率。

    Machine learning is becoming increasingly popular as a go-to approach for many tasks due to its world-class results. As a result, antivirus developers are incorporating machine learning models into their products. While these models improve malware detection capabilities, they also carry the disadvantage of being susceptible to adversarial attacks. Although this vulnerability has been demonstrated for many models in white-box settings, a black-box attack is more applicable in practice for the domain of malware detection. We present a generator of adversarial malware examples using reinforcement learning algorithms. The reinforcement learning agents utilize a set of functionality-preserving modifications, thus creating valid adversarial examples. Using the proximal policy optimization (PPO) algorithm, we achieved an evasion rate of 53.84% against the gradient-boosted decision tree (GBDT) model. The PPO agent previously trained against the GBDT classifier scored an evasion rate of 11.41%
    
[^6]: 对于“建筑”的思考

    Thoughts on Architecture. (arXiv:2306.13572v1 [cs.AI])

    [http://arxiv.org/abs/2306.13572](http://arxiv.org/abs/2306.13572)

    本文讨论了“建筑”这个词从其希腊历史和应用于建筑和计算机的含义发展到如今的思维方面的路径，并提供了跨越所有三个阶段的“建筑”定义以及重新思考与认知体系结构有关的三个重要问题。

    

    “建筑”这个词从其希腊历史和应用于建筑和计算机的含义发展到如今的思维方面。本文考虑了这一历史的教训，提出了在每个阶段引入的一组相关区分和跨越所有三个阶段的“建筑”定义，以及重新思考与认知体系结构有关的三个重要问题。

    The term architecture has evolved considerably from its original Greek roots and its application to buildings and computers to its more recent manifestation for minds. This article considers lessons from this history, in terms of a set of relevant distinctions introduced at each of these stages and a definition of architecture that spans all three, and a reconsideration of three key issues from cognitive architectures for architectures in general and cognitive architectures more particularly.
    
[^7]: 多模态大语言模型综述

    A Survey on Multimodal Large Language Models. (arXiv:2306.13549v1 [cs.CV])

    [http://arxiv.org/abs/2306.13549](http://arxiv.org/abs/2306.13549)

    本文追踪和总结了多模态大语言模型（MLLM）的最新进展，包括多模态指令调整、多模态上下文学习、多模态思维链和LLM辅助视觉推理等应用，指出了现有挑战和有前途的研究方向。

    

    多模态大语言模型（MLLM）是一种新兴的研究热点，使用强大的大语言模型作为大脑执行多模态任务。MLLM 的惊人能力，如基于图像编写故事和无OCR数学推理等，在传统方法中很少见，表明了通向人工智能的潜在路径。本文旨在追踪和总结 MLLM 的最新进展。首先，我们介绍了 MLLM 的构成，概述了相关概念。然后，讨论了关键技术和应用，包括多模态指令调整（M-IT）、多模态上下文学习（M-ICL）、多模态思维链（M-CoT）和LLM辅助视觉推理（LAVR）。最后，我们讨论了现有的挑战，并指出了有前途的研究方向。鉴于 MLLM 时代才刚刚开始，我们会不断更新这个综述，并希望能激发更多的研究。

    Multimodal Large Language Model (MLLM) recently has been a new rising research hotspot, which uses powerful Large Language Models (LLMs) as a brain to perform multimodal tasks. The surprising emergent capabilities of MLLM, such as writing stories based on images and OCR-free math reasoning, are rare in traditional methods, suggesting a potential path to artificial general intelligence. In this paper, we aim to trace and summarize the recent progress of MLLM. First of all, we present the formulation of MLLM and delineate its related concepts. Then, we discuss the key techniques and applications, including Multimodal Instruction Tuning (M-IT), Multimodal In-Context Learning (M-ICL), Multimodal Chain of Thought (M-CoT), and LLM-Aided Visual Reasoning (LAVR). Finally, we discuss existing challenges and point out promising research directions. In light of the fact that the era of MLLM has only just begun, we will keep updating this survey and hope it can inspire more research. An associated
    
[^8]: 推断多房间迷宫环境中的分层结构

    Inferring Hierarchical Structure in Multi-Room Maze Environments. (arXiv:2306.13546v1 [cs.AI])

    [http://arxiv.org/abs/2306.13546](http://arxiv.org/abs/2306.13546)

    本文提出了一个分层主动推理模型，在多房间迷宫环境中推断出世界结构，有效实现探索和导航，提高了搜索效率。

    

    认知地图通过表示环境中的空间和概念关系在促进灵活行为方面发挥了至关重要的作用。学习和推断环境的基础结构对于有效的探索和导航至关重要。本文提出了一个分层主动推理模型，解决了从基于像素的观察中推断世界结构的挑战。我们提出了一个三层分层模型，包括认知地图、客观中心、自我中心世界模型，在上下文、地点到运动的不同推理层面结合了好奇心驱动的探索和目的驱动的行为。这允许在房间结构化的小网格环境中进行有效的探索和目标导向搜索。

    Cognitive maps play a crucial role in facilitating flexible behaviour by representing spatial and conceptual relationships within an environment. The ability to learn and infer the underlying structure of the environment is crucial for effective exploration and navigation. This paper introduces a hierarchical active inference model addressing the challenge of inferring structure in the world from pixel-based observations. We propose a three-layer hierarchical model consisting of a cognitive map, an allocentric, and an egocentric world model, combining curiosity-driven exploration with goal-oriented behaviour at the different levels of reasoning from context to place to motion. This allows for efficient exploration and goal-directed search in room-structured mini-grid environments.
    
[^9]: 扭曲图神经网络

    Torsion Graph Neural Networks. (arXiv:2306.13541v1 [cs.LG])

    [http://arxiv.org/abs/2306.13541](http://arxiv.org/abs/2306.13541)

    这项研究提出了一种名为TorGNN的图神经网络模型，其运用解析扭曲度量化图的局部结构，并在16种不同类型的网络链接预测任务上进行了验证。

    

    几何深度学习（GDL）模型已经展现了非欧几里得数据分析的巨大潜力。它们被开发出来将非欧几里得数据的几何和拓扑信息整合到端到端深度学习架构中。受图神经网络（GNN）中离散黎曼曲率的成功启发，我们提出了TorGNN，一种增强了解析扭曲度的图神经网络模型。其基本思想是用基于解析扭曲度的权重公式来表征图的局部结构。数学上，解析扭曲度是一种拓扑不变量，可以区分同伦但不同胚的空间。在我们的TorGNN中，对于每个边，我们都可以找到相应的局部单纯复合体，然后计算其解析扭曲度，并进一步将其用作信息传递过程的权重。我们的TorGNN模型已在来自16种不同类型网络的链接预测任务上进行了验证。

    Geometric deep learning (GDL) models have demonstrated a great potential for the analysis of non-Euclidian data. They are developed to incorporate the geometric and topological information of non-Euclidian data into the end-to-end deep learning architectures. Motivated by the recent success of discrete Ricci curvature in graph neural network (GNNs), we propose TorGNN, an analytic Torsion enhanced Graph Neural Network model. The essential idea is to characterize graph local structures with an analytic torsion based weight formula. Mathematically, analytic torsion is a topological invariant that can distinguish spaces which are homotopy equivalent but not homeomorphic. In our TorGNN, for each edge, a corresponding local simplicial complex is identified, then the analytic torsion (for this local simplicial complex) is calculated, and further used as a weight (for this edge) in message-passing process. Our TorGNN model is validated on link prediction tasks from sixteen different types of n
    
[^10]: 探索AI增强的协作控制对于辅助机械臂的影响

    Exploring AI-enhanced Shared Control for an Assistive Robotic Arm. (arXiv:2306.13509v1 [cs.HC])

    [http://arxiv.org/abs/2306.13509](http://arxiv.org/abs/2306.13509)

    本文研究如何将人工智能集成到机械臂的共享控制范式中，以帮助运动受损人士实现更高程度的个人自治。

    

    辅助技术，特别是辅助机械臂已经成为帮助运动受损人士实现自主生活的可能性。近年来，越来越多这样的系统已经面向最终用户提供，例如Kinova Jaco机械臂。然而，它们大多需要复杂的手动控制，这可能会使用户不堪重负。因此，研究人员探索让这些机器人自主行动的方式。然而，至少对于这个特定的用户群体来说，这种方法已经被证明是徒劳的。在这里，用户希望保持控制权以实现更高程度的个人自治，但自主的机器人与此相反。在我们的研究中，我们探讨了如何将人工智能（AI）集成到共享控制范式中。特别是，我们关注了人与机器人之间界面的必要要求，以及如何在显著减少心理负担和所需的机动能力的同时保持人类的控制。

    Assistive technologies and in particular assistive robotic arms have the potential to enable people with motor impairments to live a self-determined life. More and more of these systems have become available for end users in recent years, such as the Kinova Jaco robotic arm. However, they mostly require complex manual control, which can overwhelm users. As a result, researchers have explored ways to let such robots act autonomously. However, at least for this specific group of users, such an approach has shown to be futile. Here, users want to stay in control to achieve a higher level of personal autonomy, to which an autonomous robot runs counter. In our research, we explore how Artifical Intelligence (AI) can be integrated into a shared control paradigm. In particular, we focus on the consequential requirements for the interface between human and robot and how we can keep humans in the loop while still significantly reducing the mental load and required motor skills.
    
[^11]: 一种用于模拟电路验证的自适应规划搜索算法

    Adaptive Planning Search Algorithm for Analog Circuit Verification. (arXiv:2306.13484v1 [cs.AI])

    [http://arxiv.org/abs/2306.13484](http://arxiv.org/abs/2306.13484)

    提出了一种机器学习（ML）方法用于模拟电路验证，在使用较少的仿真次数的同时提高了电路响应估计的精度，能够更好地发现最坏情况和故障。

    

    集成电路验证近年来引起了相当大的关注。由于这些电路每年都在不断增长复杂性，因此Si前验证变得越来越重要，以确保其正常功能。因此，为了减少手动验证IC所需的时间，我们提出了一种机器学习（ML）方法，该方法使用较少的仿真次数。该方法依赖于一组操作条件配置（OCC），以训练高斯过程（GP）替代模型。通过使用替代模型，我们可以提出进一步更困难的OCC。对于几个迭代重复这个过程已经在合成和真实电路上表现出更好的GP估计电路响应，提高了找到某些电路响应的最坏情况甚至使之失败的机会。因此，我们展示了这种提出的方法能够为所有电路提供更接近规格的OCC，并确定一种故障。

    Integrated circuit verification has gathered considerable interest in recent times. Since these circuits keep growing in complexity year by year, pre-Silicon (pre-SI) verification becomes ever more important, in order to ensure proper functionality. Thus, in order to reduce the time needed for manually verifying ICs, we propose a machine learning (ML) approach, which uses less simulations. This method relies on an initial evaluation set of operating condition configurations (OCCs), in order to train Gaussian process (GP) surrogate models. By using surrogate models, we can propose further, more difficult OCCs. Repeating this procedure for several iterations has shown better GP estimation of the circuit's responses, on both synthetic and real circuits, resulting in a better chance of finding the worst case, or even failures, for certain circuit responses. Thus, we show that the proposed approach is able to provide OCCs closer to the specifications for all circuits and identify a failure 
    
[^12]: 将图表信息融入基于Transformer的AMR分析

    Incorporating Graph Information in Transformer-based AMR Parsing. (arXiv:2306.13467v1 [cs.CL])

    [http://arxiv.org/abs/2306.13467](http://arxiv.org/abs/2306.13467)

    本论文介绍了一种新的模型和方法LeakDistill，它使用结构适配器将图形信息明确并入到学习的表示中，从而提高了AMR解析性能。实验表明，我们可以通过在训练时使用单词到节点对齐将图形结构信息嵌入编码器中，即使不使用其他数据，也可以通过自我知识蒸馏获得最先进的AMR解析性能。

    

    抽象意义表达（AMR）是一种语义解析形式主义，旨在提供表示给定文本的语义图表抽象。当前的方法基于自回归语言模型，例如BART或T5，通过Teacher Forcing进行微调，以从句子得到线性化版本的AMR图表。在本文中，我们提出了LeakDistill，一种探索转换器架构修改的模型和方法，使用结构适配器明确将图形信息并入到学习的表示中，以提高AMR解析性能。我们的实验表明，通过在训练时使用单词到节点对齐将图形结构信息嵌入编码器中，即使不使用其他数据，也可以通过自我知识蒸馏获得最先进的AMR解析性能。我们在\url{this http URL}上发布了代码。

    Abstract Meaning Representation (AMR) is a Semantic Parsing formalism that aims at providing a semantic graph abstraction representing a given text. Current approaches are based on autoregressive language models such as BART or T5, fine-tuned through Teacher Forcing to obtain a linearized version of the AMR graph from a sentence. In this paper, we present LeakDistill, a model and method that explores a modification to the Transformer architecture, using structural adapters to explicitly incorporate graph information into the learned representations and improve AMR parsing performance. Our experiments show how, by employing word-to-node alignment to embed graph structural information into the encoder at training time, we can obtain state-of-the-art AMR parsing through self-knowledge distillation, even without the use of additional data. We release the code at \url{this http URL}.
    
[^13]: 利用类激活图进行植物叶片病损检测

    Lesion Detection on Leaves using Class Activation Maps. (arXiv:2306.13366v1 [cs.CV])

    [http://arxiv.org/abs/2306.13366](http://arxiv.org/abs/2306.13366)

    本研究提出了一种利用ResNet-18分类器生成类激活图进行植物叶片病损检测的方法，成功预测了0.45的病损位置成功率，消除了病损注释过程的需求。

    

    植物叶片病损检测是植物病理学和农业研究中的重要任务。识别病损有助于评估植物疾病的严重程度，并制定关于疾病控制措施和治疗策略的明智决策。本研究提出了一种利用ResNet-18分类器生成类激活图进行植物叶片病损检测的方法。在测试集中，我们成功预测了0.45的病损位置成功率。本研究通过利用ResNet分类器生成的CAMs，消除了病损注释过程的需求，提出了一种新的植物叶片病损检测方法。

    Lesion detection on plant leaves is a critical task in plant pathology and agricultural research. Identifying lesions enables assessing the severity of plant diseases and making informed decisions regarding disease control measures and treatment strategies. To detect lesions, there are studies that propose well-known object detectors. However, training object detectors to detect small objects such as lesions can be problematic. In this study, we propose a method for lesion detection on plant leaves utilizing class activation maps generated by a ResNet-18 classifier. In the test set, we achieved a 0.45 success rate in predicting the locations of lesions in leaves. Our study presents a novel approach for lesion detection on plant leaves by utilizing CAMs generated by a ResNet classifier while eliminating the need for a lesion annotation process.
    
[^14]: 一种基于物理学知识的人工智能方法用于计算熔点并控制不确定性和最优采样

    A physics-informed AI method for calculating melting points with uncertainty control and optimal sampling. (arXiv:2306.13345v1 [cond-mat.mtrl-sci])

    [http://arxiv.org/abs/2306.13345](http://arxiv.org/abs/2306.13345)

    本文提出了一种基于物理学知识和人工智能的计算熔点的方法，并演示了如何增强其准确性和控制不确定性。

    

    我们提出了一种人工智能（AI）方法，通过NPT集合中的共存模拟自动计算熔点。给定原子间相互作用模型，该方法决定进行模拟的原子数量和温度，并基于收集的数据预测熔点及其不确定性，可以通过更多的数据系统地提高其准确性。我们演示了如何将固液共存演化的物理模型纳入AI方法，增强其准确性，并实现有效降低预测不确定性的最优决策。为验证我们的方法，我们将结果与大约20个文献中的熔点计算进行比较。值得注意的是，在约三分之一的情况下观察到显著偏差，突显出材料性质计算需要准确可靠的基于AI的算法的必要性。

    We present an artificial intelligence (AI) method for automatically computing the melting point based on coexistence simulations in the NPT ensemble. Given the interatomic interaction model, the method makes decisions regarding the number of atoms and temperature at which to conduct simulations, and based on the collected data predicts the melting point along with the uncertainty, which can be systematically improved with more data. We demonstrate how incorporating physical models of the solid-liquid coexistence evolution enhances the AI method's accuracy and enables optimal decision-making to effectively reduce predictive uncertainty. To validate our approach, we compare our results with approximately 20 melting point calculations from the literature. Remarkably, we observe significant deviations in about one-third of the cases, underscoring the need for accurate and reliable AI-based algorithms for materials property calculations.
    
[^15]: 多变风量开放式办公室中 HVAC 系统能源优化：一种深度强化学习方法

    Energy Optimization for HVAC Systems in Multi-VAV Open Offices: A Deep Reinforcement Learning Approach. (arXiv:2306.13333v1 [eess.SY])

    [http://arxiv.org/abs/2306.13333](http://arxiv.org/abs/2306.13333)

    本研究提出了一种基于低复杂度深度强化学习模型的多输入多输出体系结构，以最小化可控因素的数量，实现了对多变风量开放式办公室 HVAC 系统的能源优化，与传统系统相比能源消耗减少了 37%，且温度范围违规率极低 (<1%)。

    

    全球超过 32% 的能源用于商业和住宅建筑，迫切需要重新审视传统的建筑能源管理方法。由于 HVAC 系统占商业部门总能耗的约 40%，我们提出了一种基于低复杂度 DRL 模型的多输入多输出体系结构，以实现开放式办公室 HVAC 能源优化，仅使用少量可控和可访问因素。通过与真实建筑中基于现有 HVAC 计划的基线系统进行比较，评估了我们解决方案的整体能源消耗和热舒适度水平。该比较显示，我们的方法在工作时间内实现了 37% 的能源消耗节约，违规温度范围占比最低 (<1%)。训练一个性能优越的覆盖 d

    With more than 32% of the global energy used by commercial and residential buildings, there is an urgent need to revisit traditional approaches to Building Energy Management (BEM). With HVAC systems accounting for about 40% of the total energy cost in the commercial sector, we propose a low-complexity DRL-based model with multi-input multi-output architecture for the HVAC energy optimization of open-plan offices, which uses only a handful of controllable and accessible factors. The efficacy of our solution is evaluated through extensive analysis of the overall energy consumption and thermal comfort levels compared to a baseline system based on the existing HVAC schedule in a real building. This comparison shows that our method achieves 37% savings in energy consumption with minimum violation (<1%) of the desired temperature range during work hours. It takes only a total of 40 minutes for 5 epochs (about 7.75 minutes per epoch) to train a network with superior performance and covering d
    
[^16]: 利用先进的NLP变形器和LSTM进行简历的提取性文本摘要

    Abstractive Text Summarization for Resumes With Cutting Edge NLP Transformers and LSTM. (arXiv:2306.13315v1 [cs.CL])

    [http://arxiv.org/abs/2306.13315](http://arxiv.org/abs/2306.13315)

    本研究评估了多种技术（包括LSTM、T5、Pegasus、BART和BART-Large模型）在不同数据集上对简历文本进行分类任务的表现，结果显示微调后的BART-Large模型效果最佳。

    

    文本摘要是自然语言处理中的一项基本任务，旨在将大量的文本信息压缩成简洁连贯的摘要。随着内容的指数增长和高效提取关键信息的需求，文本摘要在近年来受到了极大的关注。在本研究中，评估了LSTM和预训练的T5、Pegasus、BART和BART-Large模型在开源数据集（Xsum、CNN/Daily Mail、亚马逊精美食品评论和新闻摘要）和准备的简历数据集上的表现。该简历数据集包括许多信息，如语言、教育、经验、个人信息、技能等，数据集中包括了75份简历。本研究的主要目标是对简历文本进行分类。使用简历数据集评估了各种技术，包括LSTM、预训练模型和微调模型。使用简历数据集微调的BART-Large模型表现最佳。

    Text summarization is a fundamental task in natural language processing that aims to condense large amounts of textual information into concise and coherent summaries. With the exponential growth of content and the need to extract key information efficiently, text summarization has gained significant attention in recent years. In this study, LSTM and pre-trained T5, Pegasus, BART and BART-Large model performances were evaluated on the open source dataset (Xsum, CNN/Daily Mail, Amazon Fine Food Review and News Summary) and the prepared resume dataset. This resume dataset consists of many information such as language, education, experience, personal information, skills, and this data includes 75 resumes. The primary objective of this research was to classify resume text. Various techniques such as LSTM, pre-trained models, and fine-tuned models were assessed using a dataset of resumes. The BART-Large model fine-tuned with the resume dataset gave the best performance.
    
[^17]: 相互指导的少样本学习在关系三元组提取中的应用

    Mutually Guided Few-shot Learning for Relational Triple Extraction. (arXiv:2306.13310v1 [cs.CL])

    [http://arxiv.org/abs/2306.13310](http://arxiv.org/abs/2306.13310)

    提出了相互指导的少样本学习框架，以进行关系三元组提取，并引入了一个新的跨域少样本三元组提取任务，实现了在少样本情况下的有竞争力结果。

    

    知识图谱（KGs）包含许多实体-关系-实体三元组，为下游应用提供了丰富的信息。尽管从非结构化文本中提取三元组已经广泛探索，但大部分方法需要大量标注实例。当只有少量标记数据可用时，性能将急剧下降。为了解决这个问题，我们提出了相互指导的少样本学习框架，以进行关系三元组提取（MG-FTE）。具体而言，我们的方法包含一个以实体为导向的关系原型解码器，首先对关系进行分类，以及一个以关系为导向的实体原型解码器，根据分类的关系提取实体。为了连结实体与关系，我们设计了原型层融合模块，以提高实体提取和关系分类的性能。此外，我们还引入了一个新的跨域少样本三元组提取任务。广泛的实验表明，我们的方法在少样本三元组提取任务中优于许多最先进的方法，即使只有少量标记数据可用时，也能取得有竞争力的结果。

    Knowledge graphs (KGs), containing many entity-relation-entity triples, provide rich information for downstream applications. Although extracting triples from unstructured texts has been widely explored, most of them require a large number of labeled instances. The performance will drop dramatically when only few labeled data are available. To tackle this problem, we propose the Mutually Guided Few-shot learning framework for Relational Triple Extraction (MG-FTE). Specifically, our method consists of an entity-guided relation proto-decoder to classify the relations firstly and a relation-guided entity proto-decoder to extract entities based on the classified relations. To draw the connection between entity and relation, we design a proto-level fusion module to boost the performance of both entity extraction and relation classification. Moreover, a new cross-domain few-shot triple extraction task is introduced. Extensive experiments show that our method outperforms many state-of-the-art
    
[^18]: 利用LLMs探索质性研究

    Exploring Qualitative Research Using LLMs. (arXiv:2306.13298v1 [cs.SE])

    [http://arxiv.org/abs/2306.13298](http://arxiv.org/abs/2306.13298)

    本研究比较了人类和LLMs在评论分类方面的理解能力，结果表明两种方法在分类上不太一致，对于分类达成一致仅约占五分之一。

    

    AI驱动的大语言模型（LLMs）的出现引发了有关它们在质性研究中作用的讨论。一些人认为这些是丰富人类理解的工具，而另一些人则认为它们威胁到该学科的核心价值观。本研究旨在比较人类和LLMs的理解能力。我们对小型Alexa应用程序评论进行了实验，最初由人类分析师进行分类。然后要求LLMs对这些评论进行分类，并提供每个分类背后的推理。我们将结果与人类分类和推理进行了比较。研究表明，在三分之一的情况下，人类分类和ChatGPT 3.5分类之间存在显着对齐，超过四分之一的情况下，与 GPT4的对齐略低。两个AI模型在超过一半的实例中表现出更高的对齐性。然而，在所有三种方法中达成一致的仅约占分类的五分之一。

    The advent of AI driven large language models (LLMs) have stirred discussions about their role in qualitative research. Some view these as tools to enrich human understanding, while others perceive them as threats to the core values of the discipline. This study aimed to compare and contrast the comprehension capabilities of humans and LLMs. We conducted an experiment with small sample of Alexa app reviews, initially classified by a human analyst. LLMs were then asked to classify these reviews and provide the reasoning behind each classification. We compared the results with human classification and reasoning. The research indicated a significant alignment between human and ChatGPT 3.5 classifications in one third of cases, and a slightly lower alignment with GPT4 in over a quarter of cases. The two AI models showed a higher alignment, observed in more than half of the instances. However, a consensus across all three methods was seen only in about one fifth of the classifications. In t
    
[^19]: 方差-协方差正则化改进表示学习

    Variance-Covariance Regularization Improves Representation Learning. (arXiv:2306.13292v1 [cs.LG])

    [http://arxiv.org/abs/2306.13292](http://arxiv.org/abs/2306.13292)

    提出了方差-协方差正则化方法，旨在促进学习网络特征的多样性，改善表示学习和迁移学习的性能。

    

    迁移学习已成为机器学习领域的一个关键方法，能够将从一个领域获得的知识应用于提高后续任务的性能。然而，缺乏关于这些后续任务的足够信息，强有力的迁移学习方法要求在初始预训练阶段捕获各种特征。然而，最近的研究表明，在没有足够的正则化的情况下，网络往往会集中于主要减少预训练损失函数的特征。这种趋势可能导致不充分的特征学习和目标任务的受损泛化能力。为了解决这个问题，我们提出了方差-协方差正则化（VCR）技术，旨在促进学习网络特征的多样性。借鉴最近自监督学习方法的进展，我们的方法促进了表现出高方差和高相关性的学习表示。

    Transfer learning has emerged as a key approach in the machine learning domain, enabling the application of knowledge derived from one domain to improve performance on subsequent tasks. Given the often limited information about these subsequent tasks, a strong transfer learning approach calls for the model to capture a diverse range of features during the initial pretraining stage. However, recent research suggests that, without sufficient regularization, the network tends to concentrate on features that primarily reduce the pretraining loss function. This tendency can result in inadequate feature learning and impaired generalization capability for target tasks. To address this issue, we propose Variance-Covariance Regularization (VCR), a regularization technique aimed at fostering diversity in the learned network features. Drawing inspiration from recent advancements in the self-supervised learning approach, our approach promotes learned representations that exhibit high variance and 
    
[^20]: 改正策略梯度算法中折扣因子不匹配的问题

    Correcting discount-factor mismatch in on-policy policy gradient methods. (arXiv:2306.13284v1 [cs.LG])

    [http://arxiv.org/abs/2306.13284](http://arxiv.org/abs/2306.13284)

    该论文提出了一种改进的算法来解决策略梯度算法中折扣因子不匹配的问题。该算法适用于许多现有的梯度估计器，避免了性能下降的问题。

    

    策略梯度定理提供了一种方便的策略梯度形式，包括三个因素: 动作值、动作似然梯度和折扣利润。但是，基于策略梯度定理的常用的进策略方法忽略了状态分布中的折扣因子，这是技术上的错误，在某些环境下甚至可能引发退化的学习行为。既有的解决方案通过在梯度估计中使用 $\gamma^t$ 作为因子来纠正此 discrepency。然而，这种解决方案并不被广泛采用，并且在后续状态类似于前面状态的任务中表现不佳。我们引入了一种新颖的分布校正方法来解决折扣稳态分布问题，可以插入到许多现有的梯度估计器中。我们的校正方法在方差更低的情况下避免了与 $\gamma^t$ 校正相关的性能下降。

    The policy gradient theorem gives a convenient form of the policy gradient in terms of three factors: an action value, a gradient of the action likelihood, and a state distribution involving discounting called the \emph{discounted stationary distribution}. But commonly used on-policy methods based on the policy gradient theorem ignores the discount factor in the state distribution, which is technically incorrect and may even cause degenerate learning behavior in some environments. An existing solution corrects this discrepancy by using $\gamma^t$ as a factor in the gradient estimate. However, this solution is not widely adopted and does not work well in tasks where the later states are similar to earlier states. We introduce a novel distribution correction to account for the discounted stationary distribution that can be plugged into many existing gradient estimators. Our correction circumvents the performance degradation associated with the $\gamma^t$ correction with a lower variance.
    
[^21]: FedSelect: 个性化联邦学习中参数自定义选择的细调方法

    FedSelect: Customized Selection of Parameters for Fine-Tuning during Personalized Federated Learning. (arXiv:2306.13264v1 [cs.LG])

    [http://arxiv.org/abs/2306.13264](http://arxiv.org/abs/2306.13264)

    本文提出了一种名为FedSelect的新联邦学习框架，通过寻找最佳客户端子网络从而直接个性化客户端子网络结构和参数，同时保留了全局知识，提高了客户端性能。

    

    联邦学习旨在通过在本地数据上微调客户端参数或针对本地任务个性化架构来提高客户端性能。然而，现有的方法要么在牺牲重要的全局知识的情况下进行个性化，要么在预先确定网络层以进行微调的情况下导致客户端模型中全局知识储存的不足。本文提出了一种新的联邦学习框架FedSelect，通过同时搜索并获得个性化最佳参数和用于全局聚合的其余参数，从而直接个性化客户子网络结构和参数。

    Recent advancements in federated learning (FL) seek to increase client-level performance by fine-tuning client parameters on local data or personalizing architectures for the local task. Existing methods for such personalization either prune a global model or fine-tune a global model on a local client distribution. However, these existing methods either personalize at the expense of retaining important global knowledge, or predetermine network layers for fine-tuning, resulting in suboptimal storage of global knowledge within client models. Enlightened by the lottery ticket hypothesis, we first introduce a hypothesis for finding optimal client subnetworks to locally fine-tune while leaving the rest of the parameters frozen. We then propose a novel FL framework, FedSelect, using this procedure that directly personalizes both client subnetwork structure and parameters, via the simultaneous discovery of optimal parameters for personalization and the rest of parameters for global aggregatio
    
[^22]: 根据退化间隙参数化的快速$k$-Plex算法

    A Fast Maximum $k$-Plex Algorithm Parameterized by the Degeneracy Gap. (arXiv:2306.13258v1 [cs.DS])

    [http://arxiv.org/abs/2306.13258](http://arxiv.org/abs/2306.13258)

    本文提出了一个新参数$g_k(G)$用于最大$k$-plex问题，针对其设计了一个根据$g_k(G)$参数化的精确算法，具有较高的时间复杂度，但可以在实际图中得到应用。

    

    给定一个图，$k$-plex是一个顶点集，其中每个顶点与该集合中最多$k-1$个其他顶点不相邻。最大$k$-plex问题是从给定的图中寻找最大$k$-plex，是图搜索和社区检测等应用中重要但具有挑战性的计算问题。目前，存在许多经验算法，在效率方面没有足够的理论解释。我们通过定义输入实例的一个新参数$g_k(G)$，最大$k$-plex的退化边界和大小之间的差距，并提出了一个根据$g_k(G)$参数化的精确算法，来填补这个空白。换句话说，我们设计了一个算法，其运行时间多项式复杂度与输入图的大小成正比，指数复杂度与$g_k(G)$成正比，其中$k$是一个常数。通常，实际图的$g_k(G)$很小，被$O(\log{(|V|)})$限制，这表明该算法的运行时间多项式复杂度。我们还进行了大量的实验。

    Given a graph, the $k$-plex is a vertex set in which each vertex is not adjacent to at most $k-1$ other vertices in the set. The maximum $k$-plex problem, which asks for the largest $k$-plex from a given graph, is an important but computationally challenging problem in applications like graph search and community detection. So far, there is a number of empirical algorithms without sufficient theoretical explanations on the efficiency. We try to bridge this gap by defining a novel parameter of the input instance, $g_k(G)$, the gap between the degeneracy bound and the size of maximum $k$-plex in the given graph, and presenting an exact algorithm parameterized by $g_k(G)$. In other words, we design an algorithm with running time polynomial in the size of input graph and exponential in $g_k(G)$ where $k$ is a constant. Usually, $g_k(G)$ is small and bounded by $O(\log{(|V|)})$ in real-world graphs, indicating that the algorithm runs in polynomial time. We also carry out massive experiments
    
[^23]: 弱混淆下的近似因果效应识别

    Approximate Causal Effect Identification under Weak Confounding. (arXiv:2306.13242v1 [stat.ML])

    [http://arxiv.org/abs/2306.13242](http://arxiv.org/abs/2306.13242)

    本文提出了一种有效的方法来在弱混淆下识别因果效应的上限和下限，并证明了这种方法的计算效率优于最先进的多项式程序。

    

    在只有观测数据可用时，许多研究人员研究了因果效应估计问题。针对可识别因果查询的点估计，已经开发出了正确完备的算法。对于不可识别的因果查询，研究人员开发了多项式程序，以估计因果效应的紧密界限。但对于支持大小较大的变量，优化这些多项式程序在计算上很困难。在本文中，我们分析了“弱混淆”对因果估计的影响。更具体地说，在未观测到的混淆变量的熵很小的假设下，我们提出了一种有效的线性规划方法来导出因果效应的上限和下限。我们证明了我们的界限是一致的，也就是说，当未观测混淆变量的熵趋近于零时，上限和下限之间的差异会消失。最后，我们进行了合成和真实数据模拟，以比较我们的方法与最先进的多项式程序得到的界限，并证明我们的方法在计算上更加高效，性能也可以达到类似的水平。

    Causal effect estimation has been studied by many researchers when only observational data is available. Sound and complete algorithms have been developed for pointwise estimation of identifiable causal queries. For non-identifiable causal queries, researchers developed polynomial programs to estimate tight bounds on causal effect. However, these are computationally difficult to optimize for variables with large support sizes. In this paper, we analyze the effect of "weak confounding" on causal estimands. More specifically, under the assumption that the unobserved confounders that render a query non-identifiable have small entropy, we propose an efficient linear program to derive the upper and lower bounds of the causal effect. We show that our bounds are consistent in the sense that as the entropy of unobserved confounders goes to zero, the gap between the upper and lower bound vanishes. Finally, we conduct synthetic and real data simulations to compare our bounds with the bounds obta
    
[^24]: DiversiGATE: 一个可靠的大规模语言模型全面框架

    DiversiGATE: A Comprehensive Framework for Reliable Large Language Models. (arXiv:2306.13230v1 [cs.CL])

    [http://arxiv.org/abs/2306.13230](http://arxiv.org/abs/2306.13230)

    DiversiGATE是一个统一框架，汇集了多种LLM验证方法，其中包括自一致性、数学提示和WebGPT，同时提出了一个符合该框架的新模型“SelfLearner”，该模型可以从自己的输出中学习并优化性能，在实验中表现良好，GSM8K基准测试上提高了7%的性能。

    

    本文提出了DiversiGATE，一个统一的框架，汇集LLM验证的多种方法。该框架包括两个主要组成部分：多样化和聚合，在现有的验证方法上提供了全面的视角，例如自一致性、数学提示和WebGPT。此外，本文提出了一个新颖的“SelfLearner”模型，符合DiversiGATE框架，可以从自己的输出中学习并随着时间的推移不断完善其性能，从而提高准确性。为了评估SelfLearner的有效性，我们进行了一系列严格的实验，包括对合成数据和广泛使用的算术推理基准测试GSM8K的测试。我们的结果表明，我们的方法优于传统的LLMs，在GSM8K基准测试中实现了可观的54.8%->61.8%的提高。

    In this paper, we introduce DiversiGATE, a unified framework that consolidates diverse methodologies for LLM verification. The proposed framework comprises two main components: Diversification and Aggregation which provide a holistic perspective on existing verification approaches, such as Self-Consistency, Math Prompter and WebGPT. Furthermore, we propose a novel `SelfLearner' model that conforms to the DiversiGATE framework which can learn from its own outputs and refine its performance over time, leading to improved accuracy. To evaluate the effectiveness of SelfLearner, we conducted a rigorous series of experiments, including tests on synthetic data as well as on popular arithmetic reasoning benchmarks such as GSM8K. Our results demonstrate that our approach outperforms traditional LLMs, achieving a considerable 54.8% -> 61.8% improvement on the GSM8K benchmark.
    
[^25]: TACO：基于时间潜在动作驱动对比损失的视觉强化学习

    TACO: Temporal Latent Action-Driven Contrastive Loss for Visual Reinforcement Learning. (arXiv:2306.13229v1 [cs.LG])

    [http://arxiv.org/abs/2306.13229](http://arxiv.org/abs/2306.13229)

    本文提出了TACO方法，一种基于时间潜在动作驱动对比损失的视觉强化学习方法，能够同时学习状态表示和动作表示，提高代理学习的效率。

    

    尽管在强化学习（RL）从原始像素数据中取得了最近的进展，但样本效率仍然是一个重要的障碍。先前的工作试图通过创建自监督辅助任务来解决这个挑战，旨在为未来状态预测丰富代理学习的表示与控制相关信息。然而，这些目标通常不足以学习能够表示最优策略或值函数的表示，并且它们通常考虑具有小的抽象离散动作空间的任务，因此忽视了在连续控制中动作表示学习的重要性。在本文中，我们引入了TACO：一种简单而强大的时间对比学习方法，利用它，代理可以同时获得潜在状态和动作表示。TACO通过优化重新获得观察与最近的多个先前观察的相似性，同时学习状态与动作表示。

    Despite recent progress in reinforcement learning (RL) from raw pixel data, sample inefficiency continues to present a substantial obstacle. Prior works have attempted to address this challenge by creating self-supervised auxiliary tasks, aiming to enrich the agent's learned representations with control-relevant information for future state prediction. However, these objectives are often insufficient to learn representations that can represent the optimal policy or value function, and they often consider tasks with small, abstract discrete action spaces and thus overlook the importance of action representation learning in continuous control. In this paper, we introduce TACO: Temporal Action-driven Contrastive Learning, a simple yet powerful temporal contrastive learning approach that facilitates the concurrent acquisition of latent state and action representations for agents. TACO simultaneously learns a state and an action representation by optimizing the mutual information between re
    
[^26]: 带有多个时间任务的最优成本偏好权衡规划

    Optimal Cost-Preference Trade-off Planning with Multiple Temporal Tasks. (arXiv:2306.13222v1 [cs.RO])

    [http://arxiv.org/abs/2306.13222](http://arxiv.org/abs/2306.13222)

    本文提出了一种新颖的偏好概念，可以表达对单个任务以及它们之间关系的偏好，并在此基础上提出了一种能够根据用户偏好生成Pareto最优的规划方案的高效规划框架。

    

    自主机器人在多个复杂任务的实际场景中得到越来越广泛的应用。在这些情境中，可能存在一种完成所有任务的首选方式，但它经常与最优执行存在冲突。最近的一些研究将基于偏好的规划视为研究重点，但是它们尚未将偏好的概念扩展到机器人对每个任务的行为。在本文中，我们引入了一种新颖的偏好概念，它提供了一种广义框架来表达对单个任务以及它们之间关系的偏好。然后，我们通过扩展A*搜索来进行一种遵循用户偏好和资源最优的行为之间的最优成本偏好权衡（Pareto）分析。进一步地，我们展示了一种通过多目标A*算法的改进来计算整个Pareto前沿（所有最优成本权衡的集合）的方法。我们同时提出了一种高效的规划框架，它能够根据用户的偏好生成Pareto最优的规划方案。

    Autonomous robots are increasingly utilized in realistic scenarios with multiple complex tasks. In these scenarios, there may be a preferred way of completing all of the given tasks, but it is often in conflict with optimal execution. Recent work studies preference-based planning, however, they have yet to extend the notion of preference to the behavior of the robot with respect to each task. In this work, we introduce a novel notion of preference that provides a generalized framework to express preferences over individual tasks as well as their relations. Then, we perform an optimal trade-off (Pareto) analysis between behaviors that adhere to the user's preference and the ones that are resource optimal. We introduce an efficient planning framework that generates Pareto-optimal plans given user's preference by extending A* search. Further, we show a method of computing the entire Pareto front (the set of all optimal trade-offs) via an adaptation of a multi-objective A* algorithm. We al
    
[^27]: Gradient-based Attribution Methods中Pre或Post-Softmax Scores，哪个更好？

    Pre or Post-Softmax Scores in Gradient-based Attribution Methods, What is Best?. (arXiv:2306.13197v1 [cs.LG])

    [http://arxiv.org/abs/2306.13197](http://arxiv.org/abs/2306.13197)

    在Gradient-based Attribution Methods中，使用Pre Softmax分数或Post Softmax分数的梯度的选择有各自的优缺点，需要根据具体情况进行权衡。

    

    对于工作作为分类器的神经网络的基于梯度的归因方法使用网络分数的梯度。在这里，我们讨论使用Pre Softmax分数和Post Softmax分数的梯度之间的实际差异以及它们各自的优缺点。

    Gradient based attribution methods for neural networks working as classifiers use gradients of network scores. Here we discuss the practical differences between using gradients of pre-softmax scores versus post-softmax scores, and their respective advantages and disadvantages.
    
[^28]: DiMSam:扩散模型作为部分可观测任务与动作规划中的采样器。

    DiMSam: Diffusion Models as Samplers for Task and Motion Planning under Partial Observability. (arXiv:2306.13196v1 [cs.RO])

    [http://arxiv.org/abs/2306.13196](http://arxiv.org/abs/2306.13196)

    本文提出了一种使用扩散模型作为采样器的任务和动作规划方法，在部分可观测下能够实现长周期受约束的操作计划。

    

    任务和动作规划（TAMP）方法非常有效地计划长周期自主机器人操作。但是，由于它们需要一个规划模型，因此在环境和其动态不完全了解的领域中应用它们可能非常困难。我们提出通过利用深度生成建模，特别是扩散模型来克服这些限制，学习捕获规划模型中难以设计的约束和采样器。这些学习采样器在TAMP求解器中组合和合并，以联合找到满足规划中约束的行动参数值。为了便于对环境中未知对象进行预测，我们将这些采样器定义为学习的低维潜变量嵌入的可变对象状态。我们在关节式物体操作领域评估了我们的方法，并展示了经典TAMP、生成学习和潜在嵌入的组合如何使得在部分可观测下进行长周期受约束的操作计划。

    Task and Motion Planning (TAMP) approaches are effective at planning long-horizon autonomous robot manipulation. However, because they require a planning model, it can be difficult to apply them to domains where the environment and its dynamics are not fully known. We propose to overcome these limitations by leveraging deep generative modeling, specifically diffusion models, to learn constraints and samplers that capture these difficult-to-engineer aspects of the planning model. These learned samplers are composed and combined within a TAMP solver in order to find action parameter values jointly that satisfy the constraints along a plan. To tractably make predictions for unseen objects in the environment, we define these samplers on low-dimensional learned latent embeddings of changing object state. We evaluate our approach in an articulated object manipulation domain and show how the combination of classical TAMP, generative learning, and latent embeddings enables long-horizon constra
    
[^29]: 目标背景去除创建可解释的特征可视化

    Targeted Background Removal Creates Interpretable Feature Visualizations. (arXiv:2306.13178v1 [cs.CV])

    [http://arxiv.org/abs/2306.13178](http://arxiv.org/abs/2306.13178)

    通过使用背景去除技术作为训练过程，可提高特征可视化的解释性和人类可识别性。

    

    特征可视化用于可视化黑盒机器学习模型的学习特征。我们的方法探讨了一种改变训练过程以提高可视化解释性的方法。我们认为，通过使用背景去除技术作为鲁棒性训练的形式，网络被迫学习更多人类可识别的特征，即通过将注意力集中在主要目标上而没有背景的干扰。四种不同的训练方法用于验证这个假设。第一种使用未修改的图片。第二种使用黑色背景。第三种使用高斯噪声作为背景。第四种方法采用了一种混合去除背景图像和未修改图像的方法。特征可视化的结果表明，背景去除图像相对于基线模型表现出了显著的改进。这些新结果从各自的类别中展示出易于识别的特征，而未修改数据的模型训练则不然。

    Feature visualization is used to visualize learned features for black box machine learning models. Our approach explores an altered training process to improve interpretability of the visualizations. We argue that by using background removal techniques as a form of robust training, a network is forced to learn more human recognizable features, namely, by focusing on the main object of interest without any distractions from the background. Four different training methods were used to verify this hypothesis. The first used unmodified pictures. The second used a black background. The third utilized Gaussian noise as the background. The fourth approach employed a mix of background removed images and unmodified images. The feature visualization results show that the background removed images reveal a significant improvement over the baseline model. These new results displayed easily recognizable features from their respective classes, unlike the model trained on unmodified data.
    
[^30]: 非晶堡垒：多智能体FSMs中观察出的 emergent 行为

    Amorphous Fortress: Observing Emergent Behavior in Multi-Agent FSMs. (arXiv:2306.13169v1 [cs.AI])

    [http://arxiv.org/abs/2306.13169](http://arxiv.org/abs/2306.13169)

    介绍了一个名为Amorphous Fortress的系统，在这个系统中，通过 FSMS 实现了多智能体交互，并应用进化搜索算法，探索了隐含在文件中的 Emergent AI 行为。

    

    我们介绍了一个名为Amorphous Fortress的系统——一个抽象但是具有空间的开放式人工生命模拟系统。在这个环境中，代理被表示为有限状态机（FSMs），它们可以在有限的空间内进行多智能体交互。这些代理是通过随机生成和演化FSMs来创建的，从预定义的状态和转移中进行抽样。该环境旨在探索在 Dwarf Fortress 或 The Sims 等模拟游戏中隐含的 emergent AI 行为。我们将山丘爬行者进化搜索算法应用于该环境中，探索从生成的FSMs中得到的各种深度和交互水平。

    We introduce a system called Amorphous Fortress -- an abstract, yet spatial, open-ended artificial life simulation. In this environment, the agents are represented as finite-state machines (FSMs) which allow for multi-agent interaction within a constrained space. These agents are created by randomly generating and evolving the FSMs; sampling from pre-defined states and transitions. This environment was designed to explore the emergent AI behaviors found implicitly in simulation games such as Dwarf Fortress or The Sims. We apply the hill-climber evolutionary search algorithm to this environment to explore the various levels of depth and interaction from the generated FSMs.
    
[^31]: 开放性环境中的预判性思维挑战：风险管理

    Anticipatory Thinking Challenges in Open Worlds: Risk Management. (arXiv:2306.13157v1 [cs.AI])

    [http://arxiv.org/abs/2306.13157](http://arxiv.org/abs/2306.13157)

    研究讨论了开放环境中AI系统所面临的预判性思维的挑战，提出了面向更强大风险管理的未来研究方向。

    

    预判性思维能够推动我们在日常生活中管理风险——识别和缓解风险，从带雨伞到购买汽车保险。随着人工智能系统成为日常生活的一部分，它们也开始管理风险。自主驾驶汽车行驶了数百万英里，星际争霸和围棋代理具有与人类类似的能力，隐含地管理着对手提出的风险。为了进一步提高这些任务的性能，超分布式评估可以描述模型的偏差，我们认为这是一种风险管理。然而，学习识别和缓解低频高影响的风险与训练机器学习模型所需的观察偏差是相互冲突的。星际争霸和围棋是封闭的领域，其风险已知并且缓解方案有良好的记录，适合通过重复学习来实现。对抗筛选数据集提供了困难的例子，但数据集的筛选和建立是费时的，也不具备动态性，这都是实际风险管理的障碍。

    Anticipatory thinking drives our ability to manage risk - identification and mitigation - in everyday life, from bringing an umbrella when it might rain to buying car insurance. As AI systems become part of everyday life, they too have begun to manage risk. Autonomous vehicles log millions of miles, StarCraft and Go agents have similar capabilities to humans, implicitly managing risks presented by their opponents. To further increase performance in these tasks, out-of-distribution evaluation can characterize a model's bias, what we view as a type of risk management. However, learning to identify and mitigate low-frequency, high-impact risks is at odds with the observational bias required to train machine learning models. StarCraft and Go are closed-world domains whose risks are known and mitigations well documented, ideal for learning through repetition. Adversarial filtering datasets provide difficult examples but are laborious to curate and static, both barriers to real-world risk ma
    
[^32]: 重新思考物理符号系统假说

    Rethinking the Physical Symbol Systems Hypothesis. (arXiv:2306.13150v1 [cs.AI])

    [http://arxiv.org/abs/2306.13150](http://arxiv.org/abs/2306.13150)

    该论文重新思考了物理符号系统假说，并提出了两个新的假说，以弥合符号和神经方法之间的差距。

    

    距离物理符号系统假设（PSSH）第一次被提出已经超过半个世纪了。最近通过与神经网络和认知架构的工作的证据削弱了该假设，但它尚未以任何令人满意的方式被替换。基于对计算符号——作为原子或占位符——性质的重新思考，并因此也对它们参与的系统的重新思考，引入了一种混合方法，以应对这些挑战，同时也有助于弥合符号和神经方法之间的差距，从而产生了两个新的假设，一个用来取代PSSH，另一个更直接地关注认知架构。

    It is now more than a half-century since the Physical Symbol Systems Hypothesis (PSSH) was first articulated as an empirical hypothesis. More recent evidence from work with neural networks and cognitive architectures has weakened it, but it has not yet been replaced in any satisfactory manner. Based on a rethinking of the nature of computational symbols -- as atoms or placeholders -- and thus also of the systems in which they participate, a hybrid approach is introduced that responds to these challenges while also helping to bridge the gap between symbolic and neural approaches, resulting in two new hypotheses, one that is to replace the PSSH and other focused more directly on cognitive architectures.
    
[^33]: TRECVID 2022 中评估视频检索任务的概述

    An overview on the evaluated video retrieval tasks at TRECVID 2022. (arXiv:2306.13118v1 [cs.AI])

    [http://arxiv.org/abs/2306.13118](http://arxiv.org/abs/2306.13118)

    TRECVID是一种TREC风格的视频分析和检索评估方法，它旨在促进数字视频中基于内容的开发和检索信息。TRECVID 2022计划开展六个任务，有来自世界各地的35个研究组织参加。

    

    TREC 视频检索评估（TRECVID）是一种 TREC 风格的视频分析和检索评估方法，旨在通过开放、任务驱动的评估和测量来促进数字视频中基于内容的开发和检索信息。多年来，该评估方法已经在如何有效地完成处理和如何可靠地对系统性能进行基准测试方面取得了进展。TRECVID 由美国国家标准技术研究所（NIST）和其他美国政府机构资助，以及来自世界各地的许多组织和个人贡献了重要的时间和精力。 TRECVID 2022计划开展以下六个任务：自适应视频搜索、视频文本字幕、灾难场景描述和索引、扩展视频中的活动、深度视频理解和电影摘要。总共，来自世界各地的35个研究组织报名参加了TRECVID 2022。

    The TREC Video Retrieval Evaluation (TRECVID) is a TREC-style video analysis and retrieval evaluation with the goal of promoting progress in research and development of content-based exploitation and retrieval of information from digital video via open, tasks-based evaluation supported by metrology. Over the last twenty-one years this effort has yielded a better understanding of how systems can effectively accomplish such processing and how one can reliably benchmark their performance. TRECVID has been funded by NIST (National Institute of Standards and Technology) and other US government agencies. In addition, many organizations and individuals worldwide contribute significant time and effort. TRECVID 2022 planned for the following six tasks: Ad-hoc video search, Video to text captioning, Disaster scene description and indexing, Activity in extended videos, deep video understanding, and movie summarization. In total, 35 teams from various research organizations worldwide signed up to 
    
[^34]: 一种用于氢脆的机器学习压力仿真器

    A Machine Learning Pressure Emulator for Hydrogen Embrittlement. (arXiv:2306.13116v1 [cs.LG])

    [http://arxiv.org/abs/2306.13116](http://arxiv.org/abs/2306.13116)

    本文提出了一种物理信息的机器学习模型，用于预测管道内壁的气体压力，为管道系统监控提供了第一步。该方法具有较高保真度且优于纯数据驱动的方法。

    

    将氢与天然气混合后作为氢的替代品被用于氢运输。但是，物质的氢脆性是科学家和天然气安装设计师需要避免的一个主要问题，以避免处理中的失效。本文提出了一种物理信息的机器学习模型，用于预测管道内壁的气体压力。尽管具有高保真度的结果，但目前的基于偏微分方程(PDE)的模拟器需要耗费大量时间和计算资源。使用模拟数据，我们训练了一个ML模型，用于预测管道内壁的压力，这是管道系统监控的第一步。我们发现基于物理的方法优于纯数据驱动的方法，并满足气流系统的物理限制。

    A recent alternative for hydrogen transportation as a mixture with natural gas is blending it into natural gas pipelines. However, hydrogen embrittlement of material is a major concern for scientists and gas installation designers to avoid process failures. In this paper, we propose a physics-informed machine learning model to predict the gas pressure on the pipes' inner wall. Despite its high-fidelity results, the current PDE-based simulators are time- and computationally-demanding. Using simulation data, we train an ML model to predict the pressure on the pipelines' inner walls, which is a first step for pipeline system surveillance. We found that the physics-based method outperformed the purely data-driven method and satisfy the physical constraints of the gas flow system.
    
[^35]: 人类介入的视觉前列腺深度刺激编码的优化

    Human-in-the-Loop Optimization for Deep Stimulus Encoding in Visual Prostheses. (arXiv:2306.13104v1 [q-bio.NC])

    [http://arxiv.org/abs/2306.13104](http://arxiv.org/abs/2306.13104)

    本研究提出了一种“人类介入的视觉前列腺深度刺激编码优化”的方法，通过反演前向模型、实时优化编码参数等手段，显著提高了感知质量。

    

    神经前列腺在恢复失去的感官功能和增强人类能力方面具有潜力，但当前设备产生的感觉通常似乎不自然或扭曲。植入器的确切位置和个体感知的差异导致刺激响应存在显着差异，使个性化刺激优化成为关键挑战。贝叶斯优化可用于优化具有有限噪声观察数据的患者专属刺激参数，但对于高维刺激不可行。而深度学习模型可以优化刺激编码策略，但通常假设有关患者特定变化的完美知识。在这里，我们提出了一种新颖的、实际可行的方法，克服了这两个基本局限性。首先，通过反演将电刺激映射到视觉感知的前向模型，训练深度编码器网络以为任何个体患者产生最佳刺激。其次，提出了一种优选贝叶斯优化算法，以实时优化编码参数，成功使知觉刺激更加逼真。我们提出的“人类介入的视觉前列腺深度刺激编码优化”方法在动物模型中进行了测试，相比最先进的方法显著提高了感知质量。

    Neuroprostheses show potential in restoring lost sensory function and enhancing human capabilities, but the sensations produced by current devices often seem unnatural or distorted. Exact placement of implants and differences in individual perception lead to significant variations in stimulus response, making personalized stimulus optimization a key challenge. Bayesian optimization could be used to optimize patient-specific stimulation parameters with limited noisy observations, but is not feasible for high-dimensional stimuli. Alternatively, deep learning models can optimize stimulus encoding strategies, but typically assume perfect knowledge of patient-specific variations. Here we propose a novel, practically feasible approach that overcomes both of these fundamental limitations. First, a deep encoder network is trained to produce optimal stimuli for any individual patient by inverting a forward model mapping electrical stimuli to visual percepts. Second, a preferential Bayesian opti
    
[^36]: MBrain：一种用于脑信号的多通道自监督学习框架

    MBrain: A Multi-channel Self-Supervised Learning Framework for Brain Signals. (arXiv:2306.13102v1 [eess.SP])

    [http://arxiv.org/abs/2306.13102](http://arxiv.org/abs/2306.13102)

    MBrain是一种针对脑信号的多通道自监督学习框架，可解决监督学习方法需要高成本临床标签和不同测量方法之间临床模式差异的问题。

    

    脑信号是了解人类大脑的生理活动和疾病的重要定量数据。大多数现有研究都关注监督学习方法，然而，这些方法需要高成本的临床标签。此外，侵入式（例如SEEG）和非侵入式（例如EEG）方法测量的脑信号的临床模式之间巨大的差异导致缺乏一种统一的方法。为了处理以上问题，我们提出了研究自监督学习（SSL）框架，该框架可用于预先训练SEEG或EEG数据。直观地，由神经元的发射产生的脑信号在人类大脑中传输到不同的连接结构之间。受此启发，我们提出了MBrain，以学习不同通道（即电极的接触点，对应于不同的脑区）之间的隐式空间和时间相关性，作为统一建模不同类型脑信号的基石。

    Brain signals are important quantitative data for understanding physiological activities and diseases of human brain. Most existing studies pay attention to supervised learning methods, which, however, require high-cost clinical labels. In addition, the huge difference in the clinical patterns of brain signals measured by invasive (e.g., SEEG) and non-invasive (e.g., EEG) methods leads to the lack of a unified method. To handle the above issues, we propose to study the self-supervised learning (SSL) framework for brain signals that can be applied to pre-train either SEEG or EEG data. Intuitively, brain signals, generated by the firing of neurons, are transmitted among different connecting structures in human brain. Inspired by this, we propose MBrain to learn implicit spatial and temporal correlations between different channels (i.e., contacts of the electrode, corresponding to different brain areas) as the cornerstone for uniformly modeling different types of brain signals. Specifical
    
[^37]: BrainNet：基于分层图卷积网络的SEEG癫痫波检测

    BrainNet: Epileptic Wave Detection from SEEG with Hierarchical Graph Diffusion Learning. (arXiv:2306.13101v1 [eess.SP])

    [http://arxiv.org/abs/2306.13101](http://arxiv.org/abs/2306.13101)

    本研究提出了第一个使用真实世界SEEG数据集进行癫痫波检测的数据驱动研究，通过使用分层图卷积网络技术，可以检测并分析扩散路径，从而有助于临床实践。

    

    癫痫是一种严重的神经系统疾病，影响着全球1-2％的人口。癫痫的诊断在很大程度上取决于对癫痫波的识别，即患者大脑中的无序电脑活动。现有研究已经开始使用机器学习模型通过电极链记录皮层脑电图(EEG)检测癫痫波。然而，最近开发的立体电极脑电图(SEEG)方法提供的立体信息比传统的EEG更精确，并已广泛应用于临床实践。因此，本研究提出了第一个使用真实世界SEEG数据集来检测癫痫波的数据驱动研究。在提供新机会的同时，SEEG也带来了一些挑战。在临床实践中，癫痫波活动被认为在大脑的不同区域间传播。这些传播路径，也称为癫痫发生网络，在癫痫手术的背景下被认为是关键因素。

    Epilepsy is one of the most serious neurological diseases, affecting 1-2% of the world's population. The diagnosis of epilepsy depends heavily on the recognition of epileptic waves, i.e., disordered electrical brainwave activity in the patient's brain. Existing works have begun to employ machine learning models to detect epileptic waves via cortical electroencephalogram (EEG). However, the recently developed stereoelectrocorticography (SEEG) method provides information in stereo that is more precise than conventional EEG, and has been broadly applied in clinical practice. Therefore, we propose the first data-driven study to detect epileptic waves in a real-world SEEG dataset. While offering new opportunities, SEEG also poses several challenges. In clinical practice, epileptic wave activities are considered to propagate between different regions in the brain. These propagation paths, also known as the epileptogenic network, are deemed to be a key factor in the context of epilepsy surger
    
[^38]: Otter-Knowledge：不同来源的多模态知识图谱表示学习在药物发现中的基准测试。

    Otter-Knowledge: benchmarks of multimodal knowledge graph representation learning from different sources for drug discovery. (arXiv:2306.12802v1 [cs.LG])

    [http://arxiv.org/abs/2306.12802](http://arxiv.org/abs/2306.12802)

    本研究在药物发现方面使用了多模态知识图谱表示学习，获得了最先进的结果。他们整合了来自不同来源的数据，并提供了基于这些数据的预训练模型。

    

    最近，表示学习的研究利用大量的蛋白质或分子数据库，通过无监督学习技术获得药物和蛋白质结构的知识。这些预训练表示已被证明可以显著提高后续任务的准确性，如预测药物和靶蛋白之间的亲和力。在本研究中，我们展示了通过将来自不同来源和模态的知识图谱整合到序列或SMILES表示中，可以进一步丰富表示，并在已建立的基准测试数据集上实现最先进的结果。我们提供了来自7个公共来源的预处理和整合数据，其中包括超过30M个三元组。此外，我们还提供了基于这些数据的预训练模型，以及它们在Therapeutic Data Commons (TDC)基准测试中性能报告的结果。

    Recent research in representation learning utilizes large databases of proteins or molecules to acquire knowledge of drug and protein structures through unsupervised learning techniques. These pre-trained representations have proven to significantly enhance the accuracy of subsequent tasks, such as predicting the affinity between drugs and target proteins. In this study, we demonstrate that by incorporating knowledge graphs from diverse sources and modalities into the sequences or SMILES representation, we can further enrich the representation and achieve state-of-the-art results on established benchmark datasets. We provide preprocessed and integrated data obtained from 7 public sources, which encompass over 30M triples. Additionally, we make available the pre-trained models based on this data, along with the reported outcomes of their performance on three widely-used benchmark datasets for drug-target binding affinity prediction found in the Therapeutic Data Commons (TDC) benchmarks.
    
[^39]: OptIForest: 用于异常检测的最优隔离森林算法

    OptIForest: Optimal Isolation Forest for Anomaly Detection. (arXiv:2306.12703v1 [cs.LG])

    [http://arxiv.org/abs/2306.12703](http://arxiv.org/abs/2306.12703)

    本论文针对隔离森林算法中分支因子的最优取值问题，基于隔离效率提出创新算法OptIForest，该算法结构简洁、检测性能优秀，可应用于各种异常检测场景。

    

    异常检测在诸多领域扮演着重要角色，诸如网络安全中的入侵检测、金融风险监控、人类健康监测等。根据隔离森林机制提出的一类异常检测方法由于其简洁、有效、高效而备受青睐，例如针对实际部署，iForest是最常用的检测器之一。虽然大多数隔离森林采用二进制结构，但框架LSHiForest已经证明了多叉隔离树结构可以带来更好的检测性能。然而，尚无理论工作回答关于隔离森林的最优树结构的根本和实践重要问题，即何种分支因子的隔离树结构最优。本文提出隔离效率理论来解答该问题，进而确定了一个隔离树的最优分支因子。

    Anomaly detection plays an increasingly important role in various fields for critical tasks such as intrusion detection in cybersecurity, financial risk detection, and human health monitoring. A variety of anomaly detection methods have been proposed, and a category based on the isolation forest mechanism stands out due to its simplicity, effectiveness, and efficiency, e.g., iForest is often employed as a state-of-the-art detector for real deployment. While the majority of isolation forests use the binary structure, a framework LSHiForest has demonstrated that the multi-fork isolation tree structure can lead to better detection performance. However, there is no theoretical work answering the fundamentally and practically important question on the optimal tree structure for an isolation forest with respect to the branching factor. In this paper, we establish a theory on isolation efficiency to answer the question and determine the optimal branching factor for an isolation tree. Based on
    
[^40]: 基于强化学习的液压建筑机器人远程操作虚拟装置

    Reinforcement Learning-based Virtual Fixtures for Teleoperation of Hydraulic Construction Machine. (arXiv:2306.11897v1 [cs.RO])

    [http://arxiv.org/abs/2306.11897](http://arxiv.org/abs/2306.11897)

    本文提出了一种基于强化学习的方法来优化施工机器人任务性能。实验表明该方法在典型施工任务中的表现良好。

    

    远程操纵施工设备是建筑行业的重要方面，能够实现远距离安全操纵机器人。然而，使用手柄进行关节级别的远程操作需要经过长时间的培训才能熟练掌握，同时，由于机器的多自由度特性，机器的运动只能在执行后进行验证，使得优化控制具有挑战性。针对这个问题，本研究提出了一种基于强化学习的方法来优化任务性能。通过学习获得的控制策略用于提供关节的高效控制和协调的任务指令。为了评估所提出框架的有效性，使用Brokk 170施工机进行用户研究，评估其在典型施工任务（将凿子插入钻孔中）中的表现。实验结果表明，所提出的框架具有实用性。

    The utilization of teleoperation is a crucial aspect of the construction industry, as it enables operators to control machines safely from a distance. However, remote operation of these machines at a joint level using individual joysticks necessitates extensive training for operators to achieve proficiency due to their multiple degrees of freedom. Additionally, verifying the machine resulting motion is only possible after execution, making optimal control challenging. In addressing this issue, this study proposes a reinforcement learning-based approach to optimize task performance. The control policy acquired through learning is used to provide instructions on efficiently controlling and coordinating multiple joints. To evaluate the effectiveness of the proposed framework, a user study is conducted with a Brokk 170 construction machine by assessing its performance in a typical construction task involving inserting a chisel into a borehole. The effectiveness of the proposed framework is
    
[^41]: 基于注意力知识图卷积网络的旅游景点推荐

    Tourist Attractions Recommendation based on Attention Knowledge Graph Convolution Network. (arXiv:2306.10946v1 [cs.IR] CROSS LISTED)

    [http://arxiv.org/abs/2306.10946](http://arxiv.org/abs/2306.10946)

    本文提出了一种基于注意力知识图卷积网络的旅游景点推荐模型，通过自动语义发掘目标景点的相邻实体，根据旅客的喜好选择，预测类似景点的概率，实验中取得良好效果。

    

    基于知识图谱的推荐算法在相对成熟阶段，但在特定领域的推荐仍存在问题。例如在旅游领域，选择适合的旅游景点属性流程作为推荐基础较为复杂。本文提出改进的注意力知识图卷积网络模型(Att-KGCN)，自动语义地发掘目标景点的相邻实体，利用注意力层将相对相似的位置进行聚合，并通过推理旅客喜好选择，预测类似景点的概率作为推荐系统。实验中，采用索科特拉岛-也门的旅游数据，证明了注意力知识图卷积网络在旅游领域的景点推荐效果良好。

    The recommendation algorithm based on knowledge graphs is at a relatively mature stage. However, there are still some problems in the recommendation of specific areas. For example, in the tourism field, selecting suitable tourist attraction attributes process is complicated as the recommendation basis for tourist attractions. In this paper, we propose the improved Attention Knowledge Graph Convolution Network model, named (Att-KGCN), which automatically discovers the neighboring entities of the target scenic spot semantically. The attention layer aggregates relatively similar locations and represents them with an adjacent vector. Then, according to the tourist's preferred choices, the model predicts the probability of similar spots as a recommendation system. A knowledge graph dataset of tourist attractions used based on tourism data on Socotra Island-Yemen. Through experiments, it is verified that the Attention Knowledge Graph Convolution Network has a good effect on the recommendatio
    
[^42]: 基于潜在扩散模型的文本驱动Foley音效生成

    Text-Driven Foley Sound Generation With Latent Diffusion Model. (arXiv:2306.10359v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2306.10359](http://arxiv.org/abs/2306.10359)

    本文提出了一种基于扩散模型的Foley音效生成系统，可进行文本条件的生成。我们通过迁移学习对系统进行微调，并引入可训练的层来改善文本嵌入，同时也改进了生成的波形。

    

    Foley音效生成旨在为多媒体内容生成背景音效。先前的模型通常使用大量有标签的开发集作为输入（例如，单个数字或one-hot向量）。本文提出了一种基于扩散模型的Foley音效生成系统，可进行文本条件的生成。为了缓解数据稀缺问题，我们的模型首先使用大规模数据集进行预训练，然后通过对比语言-音频配对（CLAP）技术进行迁移学习来对该任务进行微调。我们观察到，文本编码器提取的特征嵌入可以显著影响生成模型的性能。因此，我们在编码器之后引入可训练的层来改善编码器产生的文本嵌入。此外，我们通过同时生成多个候选音频片段并选择最佳片段来进一步改进生成的波形，最佳片段是根据嵌入之间相似性得分确定的。

    Foley sound generation aims to synthesise the background sound for multimedia content. Previous models usually employ a large development set with labels as input (e.g., single numbers or one-hot vector). In this work, we propose a diffusion model based system for Foley sound generation with text conditions. To alleviate the data scarcity issue, our model is initially pre-trained with large-scale datasets and fine-tuned to this task via transfer learning using the contrastive language-audio pertaining (CLAP) technique. We have observed that the feature embedding extracted by the text encoder can significantly affect the performance of the generation model. Hence, we introduce a trainable layer after the encoder to improve the text embedding produced by the encoder. In addition, we further refine the generated waveform by generating multiple candidate audio clips simultaneously and selecting the best one, which is determined in terms of the similarity score between the embedding of the 
    
[^43]: 人在循环链中。

    Human-in-the-Loop through Chain-of-Thought. (arXiv:2306.07932v1 [cs.CL])

    [http://arxiv.org/abs/2306.07932](http://arxiv.org/abs/2306.07932)

    通过人在循环链中的方式，手动校正系统可以通过探究理性中子逻辑的手动校正来提高LLM的推理性能，并且基于经济理论的CAMLOP可以平衡效用和成本。

    

    尽管强大的语言模型和思维链提示的出现使自动化变得越来越无处不在，但有时在长期或多步逻辑推理方面显示出其弱点。例如，用户在没有人类参与的情况下不总能得到复杂数学问题的理想答案。在这个背景下，我们提出了手动校正系统（MCS）——一个通过思维链提示增强的人工参与系统，探究了理性中子逻辑的手动校正如何提高LLM的推理性能。更进一步考虑到有人参与的系统不仅要提高性能，还要控制成本。因此，我们提出了基于古典经济理论的人在循环链中成本效用分析模型（CAMLOP）来分析、量化和平衡效用和相应的成本。我们使用12个数据集对MCS和CAMLOP进行了实验。

    While the emergence of powerful language models along with Chain-of-thought prompting has made automation more and more omnipresent, it sometimes demonstrates its weakness in long-term or multi-step logical reasoning. For example, users don't always get desirable answers for complex mathematical problems without human involvement. Against this background, we present the Manual Correction System (MCS) -- a human-in-the-loop system enhanced by Chain-of-Thought prompting, which explores how manual correction of sub-logics in rationales can improve LLM's reasoning performance. Moving one step forward, considering a system with human-in-the-loop involves more than having humans improve performance but also controlling the cost. Therefore, we post a Cost-utility Analysis Model for Human-in-the-Loop systems (CAMLOP) based on classical economics theory to analyze, quantify and balance the utility and the corresponding cost. We conduct experiments of MCS and CAMLOP with twelve datasets. A signi
    
[^44]: 视觉词汇描述提升零样本图像分类

    Visually-Grounded Descriptions Improve Zero-Shot Image Classification. (arXiv:2306.06077v1 [cs.CV])

    [http://arxiv.org/abs/2306.06077](http://arxiv.org/abs/2306.06077)

    本文提出了一种称为V-GLOSS的新方法，它利用现代语言模型和语义知识库生成具有视觉基础的类别描述，提高了零样本图像分类的准确性，并引入了一个带有类别描述的银标准数据集。

    

    语言视觉模型如CLIP在零样本视觉任务（例如零样本图像分类ZSIC）方面取得了显著进展。然而，生成具体和富有表现力的类别描述仍然是一个主要挑战。现有方法存在粒度和标签歧义等问题。为了解决这些挑战，我们提出了一种新方法V-GLOSS：Visual Glosses，它利用现代语言模型和语义知识库来生成具有视觉基础的类别描述。我们通过在基准ZSIC数据集（包括ImageNet和STL-10）上实现最先进的结果来展示V-GLOSS的有效性。此外，我们引入了一个由V-GLOSS生成的带有类别描述的银标准数据集，并展示其用于视觉任务的有用性。我们提供了源代码和数据集。

    Language-vision models like CLIP have made significant progress in zero-shot vision tasks, such as zero-shot image classification (ZSIC). However, generating specific and expressive class descriptions remains a major challenge. Existing approaches suffer from granularity and label ambiguity issues. To tackle these challenges, we propose V-GLOSS: Visual Glosses, a novel method leveraging modern language models and semantic knowledge bases to produce visually-grounded class descriptions. We demonstrate V-GLOSS's effectiveness by achieving state-of-the-art results on benchmark ZSIC datasets including ImageNet and STL-10. In addition, we introduce a silver dataset with class descriptions generated by V-GLOSS, and show its usefulness for vision tasks. We make available our code and dataset.
    
[^45]: 基于机器学习的焦虑检测中噪声影响的比较研究。

    Comparative Study on the Effects of Noise in ML-Based Anxiety Detection. (arXiv:2306.01110v1 [cs.LG])

    [http://arxiv.org/abs/2306.01110](http://arxiv.org/abs/2306.01110)

    本研究探究了噪声如何影响基于机器学习的焦虑检测模型，并开发出在嘈杂的现实环境中具有抗干扰性和适应性的模型，以推进该领域的发展。

    

    穿戴式健康设备正在引领一种新时代的连续和非侵入性远程监测。其中一项应用是用于焦虑检测。许多焦虑检测方面的进展发生在受控实验室环境中，但噪声阻止了这些进展推广到现实世界的条件下。本研究旨在研究噪声如何影响模型性能并开发对嘈杂的现实环境具有抗干扰性和适应日常生活中混乱的模型，从而推进该领域的发展。我们尝试研究先前的方法为何失败，并使用可穿戴负荷与情感检测（WESAD）数据集，在三类分类问题（基准值 vs. 压力 vs. 愉悦）中比较不同强度噪声对机器学习模型分类生理唤醒等级的影响。在引入噪声之前，我们基准模型的性能达到了98.7％，而Schmidt 2018年的模型仅达到了80.3％。我们讨论了可能的解决方法。

    Wearable health devices are ushering in a new age of continuous and noninvasive remote monitoring. One application of this technology is in anxiety detection. Many advancements in anxiety detection have happened in controlled lab settings, but noise prevents these advancements from generalizing to real-world conditions. We seek to progress the field by studying how noise impacts model performance and developing models that are robust to noisy, real-world conditions and, hence, attuned to the commotion of everyday life. In this study we look to investigate why and how previous methods have failed. Using the wearable stress and affect detection (WESAD) dataset, we compare the effect of various intensities of noise on machine learning models classifying levels of physiological arousal in the three-class classification problem: baseline vs. stress vs. amusement. Before introducing noise, our baseline model performance reaches 98.7%, compared to Schmidt 2018's 80.3%. We discuss potential so
    
[^46]: 分离的关注力：基于上下文分离槽的无监督多对象发现

    Divided Attention: Unsupervised Multi-Object Discovery with Contextually Separated Slots. (arXiv:2304.01430v1 [cs.CV])

    [http://arxiv.org/abs/2304.01430](http://arxiv.org/abs/2304.01430)

    该论文提出了一种新的无监督多对象发现方法，通过一种上下文分隔的槽结构来将视觉场分割为独立运动区域，并用对抗性标准来保证解码器无法重构整个光流。

    

    我们提出了一种将视觉场分割为独立运动区域的方法，不需要任何基础真值或监督。它由基于槽关注的对抗条件编码器-解码器架构组成，修改为使用图像作为上下文来解码光流，而不是尝试重构图像本身。在结果的多模式表示中，一种模式（流）将馈送给编码器以产生单独的潜在代码（槽），而另一种模式（图像）将决定解码器从槽生成第一个模式（流）。由于惯常的自编码基于最小化重构误差，并不能防止整个流被编码到一个槽中，因此我们将损失修改为基于上下文信息分离的对抗性标准。

    We introduce a method to segment the visual field into independently moving regions, trained with no ground truth or supervision. It consists of an adversarial conditional encoder-decoder architecture based on Slot Attention, modified to use the image as context to decode optical flow without attempting to reconstruct the image itself. In the resulting multi-modal representation, one modality (flow) feeds the encoder to produce separate latent codes (slots), whereas the other modality (image) conditions the decoder to generate the first (flow) from the slots. This design frees the representation from having to encode complex nuisance variability in the image due to, for instance, illumination and reflectance properties of the scene. Since customary autoencoding based on minimizing the reconstruction error does not preclude the entire flow from being encoded into a single slot, we modify the loss to an adversarial criterion based on Contextual Information Separation. The resulting min-m
    
[^47]: OTOV2: 自动化、通用化、用户友好的通用模型压缩方法

    OTOV2: Automatic, Generic, User-Friendly. (arXiv:2303.06862v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2303.06862](http://arxiv.org/abs/2303.06862)

    OTOV2是一种自动、通用且易于使用的深度学习模型压缩方法，只需训练一次即可生成性能具有竞争力的更紧凑模型，无需微调，有效简化了模型压缩过程。

    

    现有的通过结构化剪枝进行模型压缩的方法通常需要复杂的多阶段过程，每个阶段都需要大量的工程和领域知识，这阻碍了它们在更广泛的场景中的应用。我们提出了第二代 Only-Train-Once (OTOv2) 方法，它可以自动进行训练和压缩通用的深度神经网络，生成具有竞争性能的更紧凑模型，无需微调。OTOv2 自动且可插入各种深度学习应用中，用户几乎不需要进行任何工程化工作。方法上，OTOv2 提出了两个主要改进: (i) 自主性：自动利用通用深度神经网络的依赖性，将可训练的变量分成零不变组 (ZIGs)，并构建压缩模型; (ii) 双半空间投影梯度 (DHSPG)：一种用于更可靠地解决结构稀疏问题的新型优化器。

    The existing model compression methods via structured pruning typically require complicated multi-stage procedures. Each individual stage necessitates numerous engineering efforts and domain-knowledge from the end-users which prevent their wider applications onto broader scenarios. We propose the second generation of Only-Train-Once (OTOv2), which first automatically trains and compresses a general DNN only once from scratch to produce a more compact model with competitive performance without fine-tuning. OTOv2 is automatic and pluggable into various deep learning applications, and requires almost minimal engineering efforts from the users. Methodologically, OTOv2 proposes two major improvements: (i) Autonomy: automatically exploits the dependency of general DNNs, partitions the trainable variables into Zero-Invariant Groups (ZIGs), and constructs the compressed model; and (ii) Dual Half-Space Projected Gradient (DHSPG): a novel optimizer to more reliably solve structured-sparsity prob
    
[^48]: BLOOM的预训练扩展以改善对繁体中文的支持：模型、方法和结果

    Extending the Pre-Training of BLOOM for Improved Support of Traditional Chinese: Models, Methods and Results. (arXiv:2303.04715v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.04715](http://arxiv.org/abs/2303.04715)

    本文介绍了一种名为BLOOM-zh的多语言语言模型，它扩展了BLOOM的预训练，并具有改进的繁体中文支持。BLOOM-zh在繁体中文基准测试中表现优于其前身。

    

    本文介绍了一种名为BLOOM-zh的多语言语言模型，它具有改进的繁体中文支持。BLOOM-zh起源于由BigScience于2022年推出的开源BLOOM模型。我们在已发布的模型基础上，使用74亿个额外的繁体中文和英文标记进行了扩展，覆盖了各种领域，如新闻文章、书籍、百科全书、教育材料以及口语语言。为了展示BLOOM-zh的性质，我们使用现有的和新创建的基准场景来评估其性能。在大多数的繁体中文基准测试中，BLOOM-zh的性能优于其前身，同时保持了其英文能力。我们将所有模型发布给研究社区。

    In this paper we present the multilingual language model BLOOM-zh that features enhanced support for Traditional Chinese. BLOOM-zh has its origins in the open-source BLOOM models presented by BigScience in 2022. Starting from released models, we extended the pre-training of BLOOM by additional 7.4 billion tokens in Traditional Chinese and English covering a variety of domains such as news articles, books, encyclopedias, educational materials as well as spoken language. In order to show the properties of BLOOM-zh, both existing and newly created benchmark scenarios are used for evaluating the performance. BLOOM-zh outperforms its predecessor on most Traditional Chinese benchmarks while maintaining its English capability. We release all our models to the research community.
    
[^49]: 双重强化学习：强化学习和模仿学习的统一和新方法

    Dual RL: Unification and New Methods for Reinforcement and Imitation Learning. (arXiv:2302.08560v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.08560](http://arxiv.org/abs/2302.08560)

    这篇论文介绍了双重强化学习的概念，并在一个统一的框架下解释了几种最新深度强化学习算法及模仿学习方法。作者提出了双重模仿学习方法（DIL）直接最小化策略之间的距离，并提出了一种新的离线演员-评论家方法。

    

    强化学习的目标是最大化期望累积回报。研究表明，这个目标可以通过在线性约束下优化状态-动作访问分布的优化问题来表示。这个表述的对偶问题，我们称之为双重强化学习，是无约束的并且更容易优化。我们展示了几个最先进的离线和在线强化学习算法以及模仿学习可以在一个统一的框架下被视为双重强化学习方法。这种统一提供了一个共同的基础，可以研究和识别这些方法成功的构成部分，并揭示这些方法的共同缺点和改进的新见解。我们的分析表明，以前的离线模仿学习方法基于一个不现实的覆盖率假设，并最小化了学习代理和专家访问分布之间的特定f-分布。我们提出的双重模仿学习方法（DIL）直接最小化策略之间的距离。在同样的双重框架下，我们还提出了一种新的离线演员-评论家方法，对几个基准任务有效。

    The goal of reinforcement learning (RL) is to maximize the expected cumulative return. It has been shown that this objective can be represented by an optimization problem of the state-action visitation distribution under linear constraints. The dual problem of this formulation, which we refer to as dual RL, is unconstrained and easier to optimize. We show that several state-of-the-art off-policy deep reinforcement learning (RL) algorithms, under both online and offline, RL and imitation learning (IL) settings, can be viewed as dual RL approaches in a unified framework. This unification provides a common ground to study and identify the components that contribute to the success of these methods and also reveals the common shortcomings across methods with new insights for improvement. Our analysis shows that prior off-policy imitation learning methods are based on an unrealistic coverage assumption and are minimizing a particular f-divergence between the visitation distributions of the l
    
[^50]: MarioGPT: 通过大语言模型进行开放式文本关卡生成

    MarioGPT: Open-Ended Text2Level Generation through Large Language Models. (arXiv:2302.05981v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2302.05981](http://arxiv.org/abs/2302.05981)

    MarioGPT是第一个文本到超级马里奥兄弟游戏关卡的生成模型，通过大型语言模型实现开放式的、可控制的关卡生成。

    

    流程内容生成算法可以自动生成复杂数一致的环境。然而，使用流程内容生成方法生成反映特定意图和限制的有意义内容仍然具有挑战性。此外，许多流程内容生成算法缺乏以开放式方式生成内容的能力。最近，大型语言模型在许多不同领域都表现出了非常高的效率。这些训练有素的大型语言模型可以进行微调，重复使用信息并加速新任务的培训。在这项工作中，我们介绍了MarioGPT，这是一个经过优化的GPT2模型，用于生成基于瓷砖的游戏关卡，我们以超级马里奥兄弟的关卡为例。我们展示了MarioGPT不仅可以生成不同的游戏关卡，而且可以通过文本提示控制关卡生成，解决了当前PCG技术的主要挑战之一。据我们所知，MarioGPT是第一个文本到关卡模型。

    Procedural Content Generation (PCG) algorithms provide a technique to generate complex and diverse environments in an automated way. However, while generating content with PCG methods is often straightforward, generating meaningful content that reflects specific intentions and constraints remains challenging. Furthermore, many PCG algorithms lack the ability to generate content in an open-ended manner. Recently, Large Language Models (LLMs) have shown to be incredibly effective in many diverse domains. These trained LLMs can be fine-tuned, re-using information and accelerating training for new tasks. In this work, we introduce MarioGPT, a fine-tuned GPT2 model trained to generate tile-based game levels, in our case Super Mario Bros levels. We show that MarioGPT can not only generate diverse levels, but can be text-prompted for controllable level generation, addressing one of the key challenges of current PCG techniques. As far as we know, MarioGPT is the first text-to-level model. We a
    
[^51]: 启发式多智能体规划优化智能体协作

    Optimizing Agent Collaboration through Heuristic Multi-Agent Planning. (arXiv:2301.01246v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2301.01246](http://arxiv.org/abs/2301.01246)

    提出了一种启发式多智能体规划算法，解决了涉及不同类型智能体的问题，比现有算法表现更好。

    

    针对涉及到不同类型感知智能体的问题，目前解决QDec-POMDP的SOTA算法QDec-FP和QDec-FPS无法有效解决。本文提出了一种新算法，通过要求智能体采取相同的计划，以解决这个问题。在这些情况下，我们的算法比QDec-FP和QDec-FPS都表现更好。

    The SOTA algorithms for addressing QDec-POMDP issues, QDec-FP and QDec-FPS, are unable to effectively tackle problems that involve different types of sensing agents. We propose a new algorithm that addresses this issue by requiring agents to adopt the same plan if one agent is unable to take a sensing action but the other can. Our algorithm performs significantly better than both QDec-FP and QDec-FPS in these types of situations.
    
[^52]: 多视角渐变照明下的神经人类模型及其再照明

    Relightable Neural Human Assets from Multi-view Gradient Illuminations. (arXiv:2212.07648v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.07648](http://arxiv.org/abs/2212.07648)

    本文提出了一个新的三维人类数据集 UltraStage，其中包含超过 2,000 个高质量的人类资产，这些人类资产都是在多视角和多照明设置下捕获的。最新进展的神经表示法将每个示例解释为神经人类资产，可以在实时下具有灵活性地任意重照。这是第一个高质量、多样化和灵活性高的既适用于人类建模又适用于再照明的大规模人类数据集。

    

    人类建模和再照明领域是计算机视觉和计算机图形学中的两个基础性难题。高质量的数据集可以极大地促进相关研究。然而，大多数现有的人类数据集只提供在相同照明下捕获的多角度图像，虽然对于建模任务具有价值，但并不适用于再照明问题。为了推动两个领域的研究，本文提出了 UltraStage，一个新的三维人类数据集，其中包含超过 2,000 个高质量的人类资产，这些人类资产都是在多视角和多照明设置下捕获的。具体地，对于每个示例，我们提供了32个周围视角，其中一个是白光照明，另外两个是渐变照明。除了常规的多视角图像外，渐变照明还有助于恢复详细的表面法线和空间变化材质贴图，从而实现各种再照明应用。受到神经表示法的最新进展的启发，我们进一步将每个示例解释为神经人类资产，可以在实时下具有灵活性地任意重照。据我们所知，这是第一个高质量、多样化和灵活性高的既适用于人类建模又适用于再照明的大规模人类数据集。

    Human modeling and relighting are two fundamental problems in computer vision and graphics, where high-quality datasets can largely facilitate related research. However, most existing human datasets only provide multi-view human images captured under the same illumination. Although valuable for modeling tasks, they are not readily used in relighting problems. To promote research in both fields, in this paper, we present UltraStage, a new 3D human dataset that contains more than 2,000 high-quality human assets captured under both multi-view and multi-illumination settings. Specifically, for each example, we provide 32 surrounding views illuminated with one white light and two gradient illuminations. In addition to regular multi-view images, gradient illuminations help recover detailed surface normal and spatially-varying material maps, enabling various relighting applications. Inspired by recent advances in neural representation, we further interpret each example into a neural human ass
    
[^53]: 线性遗传编程的表型搜索轨迹网络

    Phenotype Search Trajectory Networks for Linear Genetic Programming. (arXiv:2211.08516v2 [q-bio.PE] UPDATED)

    [http://arxiv.org/abs/2211.08516](http://arxiv.org/abs/2211.08516)

    研究基于遗传编程系统的表型搜索轨迹，确定更复杂表型的基因丰度较少，更难被发现，较简单表型则被过度代表容易进化。

    

    基因型到表型映射将基因型变异转化成表型变异。中性是一些变异不会导致表型变化的现象。研究基因型和表型空间中的搜索轨迹，特别是通过中性变异，有助于更好地理解演化的进程及其算法行为。在本研究中，我们将基于图形的模型生成遗传编程系统的搜索轨迹，其中节点代表基因型/表型，边代表它们的变异转换。我们还定量地测量表型的特征，包括它们的基因型丰度（对中性的要求）和 Kolmogorov 复杂度。我们将这些定量指标与搜索轨迹可视化相结合，发现更复杂的表型被更少的基因型所代表，进化更难以发现。另一方面，较简单的表型则被过度代表了，更易于进化。我们的方法提供了一种探索基因型、表型和进化之间错综复杂关系的新方式。

    Genotype-to-phenotype mappings translate genotypic variations such as mutations into phenotypic changes. Neutrality is the observation that some mutations do not lead to phenotypic changes. Studying the search trajectories in genotypic and phenotypic spaces, especially through neutral mutations, helps us to better understand the progression of evolution and its algorithmic behaviour. In this study, we visualise the search trajectories of a genetic programming system as graph-based models, where nodes are genotypes/phenotypes and edges represent their mutational transitions. We also quantitatively measure the characteristics of phenotypes including their genotypic abundance (the requirement for neutrality) and Kolmogorov complexity. We connect these quantified metrics with search trajectory visualisations, and find that more complex phenotypes are under-represented by fewer genotypes and are harder for evolution to discover. Less complex phenotypes, on the other hand, are over-represent
    
[^54]: 贝叶斯网络在使用语音和多模态数据预测抑郁及其症状的鲁棒且无偏预测方面的应用

    Bayesian Networks for the robust and unbiased prediction of depression and its symptoms utilizing speech and multimodal data. (arXiv:2211.04924v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.04924](http://arxiv.org/abs/2211.04924)

    使用贝叶斯网络及语音与多模态数据，通过捕获其条件依赖性得出预测结果，更准确地预测抑郁和其相关症状。

    

    利用行为和认知信号预测重度抑郁障碍（MDD）的存在是一个非常棘手的任务。MDD的异质性临床特征意味着任何给定的语音、面部表情和/或观察到的认知模式都可能与抑郁症状的独特组合相关联。传统的判别式机器学习模型可能缺乏稳健地建模这种异质性的复杂性。然而，贝叶斯网络可能更适合这种情况。这些网络是概率图模型，通过明确捕获随机变量的条件依赖性，高效地描述了一组随机变量的联合概率分布。这个框架相比于标准的判别性建模提供了进一步的优势，可以在模型结构中融合专家意见，生成可解释的模型预测，了解预测的不确定性，并自然地处理缺失数据。本文提出了一种基于贝叶斯网络的方法，利用语音和多模态数据预测抑郁症及其相关症状。我们的方法使用一个由有和没有MDD的个体采集的语音和面部表情数据集与传统的判别式机器学习模型进行比较。结果表明，贝叶斯网络方法在准确性和鲁棒性方面优于传统方法。此外，网络结构提供了不同数据模态相互作用以更准确地预测MDD的见解。

    Predicting the presence of major depressive disorder (MDD) using behavioural and cognitive signals is a highly non-trivial task. The heterogeneous clinical profile of MDD means that any given speech, facial expression and/or observed cognitive pattern may be associated with a unique combination of depressive symptoms. Conventional discriminative machine learning models potentially lack the complexity to robustly model this heterogeneity. Bayesian networks, however, may instead be well-suited to such a scenario. These networks are probabilistic graphical models that efficiently describe the joint probability distribution over a set of random variables by explicitly capturing their conditional dependencies. This framework provides further advantages over standard discriminative modelling by offering the possibility to incorporate expert opinion in the graphical structure of the models, generating explainable model predictions, informing about the uncertainty of predictions, and naturally
    
[^55]: 关于监督信号的信息量

    On the Informativeness of Supervision Signals. (arXiv:2211.01407v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.01407](http://arxiv.org/abs/2211.01407)

    本文使用信息论比较了常用的监督信号对表示学习性能的贡献，并为在大数据时代使用硬标签提供了理论上的证明，但对于少样本学习和分布外泛化，需要使用更丰富的监督信号。

    

    监督学习通常侧重于从人类标注的训练示例中学习可转移的表示。虽然丰富的注释（如软标签）比稀疏的注释（如硬标签）提供更多信息，但它们的收集成本也更高。我们使用信息论比较了许多常用的监督信号对于表示学习性能的贡献，以及它们的能力如何受到标签数、类别、维度和噪声等因素的影响。我们的框架为在大数据时代使用硬标签提供了理论上的证明，但对于少样本学习和分布外泛化，需要使用更丰富的监督信号。

    Supervised learning typically focuses on learning transferable representations from training examples annotated by humans. While rich annotations (like soft labels) carry more information than sparse annotations (like hard labels), they are also more expensive to collect. For example, while hard labels only provide information about the closest class an object belongs to (e.g., "this is a dog"), soft labels provide information about the object's relationship with multiple classes (e.g., "this is most likely a dog, but it could also be a wolf or a coyote"). We use information theory to compare how a number of commonly-used supervision signals contribute to representation-learning performance, as well as how their capacity is affected by factors such as the number of labels, classes, dimensions, and noise. Our framework provides theoretical justification for using hard labels in the big-data regime, but richer supervision signals for few-shot learning and out-of-distribution generalizati
    
[^56]: 基于点云的变形物体操作中的时空抽象规划

    Planning with Spatial-Temporal Abstraction from Point Clouds for Deformable Object Manipulation. (arXiv:2210.15751v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2210.15751](http://arxiv.org/abs/2210.15751)

    本文介绍了一种基于点云的规划框架PASTA，通过结合空间和时间抽象的概念，实现了对长期变形物体操作的有效规划。

    

    在长期视野下有效地规划变形物体操作需要适当的空间和时间抽象。以前的方法通常要么专注于短期任务，要么做出强烈的假设，认为完整的状态信息是可用的，这阻止了它们在变形对象上的使用。在本文中，我们提出了一种名为PASTA的基于时空抽象的规划框架，它结合了空间抽象（对物体及其相互关系的推理）和时间抽象（对技能而不是低级行为的推理）。我们的框架将高维的3D观测，如点云，映射到一组潜在向量，并在潜在集表示的基础上规划技能序列。我们展示了我们的方法在现实世界中可以有效地执行具有挑战性的顺序变形物体操作任务，这需要结合多个工具使用技能，如用刀切割、用推子推动和铺展。

    Effective planning of long-horizon deformable object manipulation requires suitable abstractions at both the spatial and temporal levels. Previous methods typically either focus on short-horizon tasks or make strong assumptions that full-state information is available, which prevents their use on deformable objects. In this paper, we propose PlAnning with Spatial-Temporal Abstraction (PASTA), which incorporates both spatial abstraction (reasoning about objects and their relations to each other) and temporal abstraction (reasoning over skills instead of low-level actions). Our framework maps high-dimension 3D observations such as point clouds into a set of latent vectors and plans over skill sequences on top of the latent set representation. We show that our method can effectively perform challenging sequential deformable object manipulation tasks in the real world, which require combining multiple tool-use skills such as cutting with a knife, pushing with a pusher, and spreading the do
    
[^57]: 大步神经网络学习来自分区数据的辛演化

    Large-step neural network for learning the symplectic evolution from partitioned data. (arXiv:2208.14148v2 [astro-ph.EP] UPDATED)

    [http://arxiv.org/abs/2208.14148](http://arxiv.org/abs/2208.14148)

    本研究使用分区的方法来训练大步神经网络，学习辛哈密顿系统的演化，有效抑制累积误差，并成功保持Jacobi积分的守恒。

    

    本研究关注学习哈密顿系统，需要预测辛映射生成的坐标（q）和动量（p）变量。基于Chen＆Tao（2021）的研究，辛映射由生成函数表示。为了延长预测时间，我们将时间序列（q_i、p_i）分成几个区间，并用大步神经网络（LSNN）来逼近第一区间（即初始条件）和其余各个区间之间的生成函数。这种分区方法使我们的LSNN在预测系统演化时能有效抑制累积误差。然后，我们训练LSNN学习25000年的2：3共振柯伊伯带对象的运动。结果显示，在我们先前工作中构建的神经网络（Li等，2022）基础上，有两个显著的改进：（1）Jacobi积分的守恒，

    In this study, we focus on learning Hamiltonian systems, which involves predicting the coordinate (q) and momentum (p) variables generated by a symplectic mapping. Based on Chen & Tao (2021), the symplectic mapping is represented by a generating function. To extend the prediction time period, we develop a new learning scheme by splitting the time series (q_i, p_i) into several partitions. We then train a large-step neural network (LSNN) to approximate the generating function between the first partition (i.e. the initial condition) and each one of the remaining partitions. This partition approach makes our LSNN effectively suppress the accumulative error when predicting the system evolution. Then we train the LSNN to learn the motions of the 2:3 resonant Kuiper belt objects for a long time period of 25000 yr. The results show that there are two significant improvements over the neural network constructed in our previous work (Li et al. 2022): (1) the conservation of the Jacobi integral,
    
[^58]: DeepGraviLens：一种用于分类引力透镜数据的多模态网络架构

    DeepGraviLens: a Multi-Modal Architecture for Classifying Gravitational Lensing Data. (arXiv:2205.00701v3 [astro-ph.IM] UPDATED)

    [http://arxiv.org/abs/2205.00701](http://arxiv.org/abs/2205.00701)

    DeepGraviLens是一种多模态神经网络，用于分类属于不同类型的引力透镜数据，具有高精度和优于现有方法的结果。

    

    引力透镜是由大质量物体产生的相对论效应，会弯曲其周围的时空。这是天体物理学中一个深入研究的课题，允许验证理论相对论结果并研究一些否则不可见的微弱天体物体。近年来，机器学习方法已被应用于支持引力透镜现象的分析，通过检测与亮度变化时间序列相关的图像数据集中的透镜效应。然而，当前的方法要么仅考虑图像而忽略时间序列数据，要么在最困难的数据集上实现相对较低的准确性。本文介绍了 DeepGraviLens，这是一种新颖的多模态网络，用于分类属于一个非透镜系统类型和三个透镜系统类型的时空数据。它在准确性方面超过当前的 state-of-art 方法，提高了约 19% 到 43%，具体取决于所考虑的数据集。

    Gravitational lensing is the relativistic effect generated by massive bodies, which bend the space-time surrounding them. It is a deeply investigated topic in astrophysics and allows validating theoretical relativistic results and studying faint astrophysical objects that would not be visible otherwise. In recent years Machine Learning methods have been applied to support the analysis of the gravitational lensing phenomena by detecting lensing effects in data sets consisting of images associated with brightness variation time series. However, the state-of-art approaches either consider only images and neglect time-series data or achieve relatively low accuracy on the most difficult data sets. This paper introduces DeepGraviLens, a novel multi-modal network that classifies spatio-temporal data belonging to one non-lensed system type and three lensed system types. It surpasses the current state of the art accuracy results by $\approx$ 19% to $\approx$ 43%, depending on the considered dat
    
[^59]: 探索时空人群流量预测中的上下文泛化性：基准和指南

    Exploring the Context Generalizability in Spatiotemporal Crowd Flow Prediction: Benchmark and Guideline. (arXiv:2106.16046v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2106.16046](http://arxiv.org/abs/2106.16046)

    本文研究了时空人群流量预测中的上下文泛化性，建立了基准，提出了通用分类法，为上下文选择和建模提供了指南。

    

    上下文特征是构建时空人群流量预测（STCFP）模型的重要数据来源。然而，应用上下文的困难在于不同场景中上下文特征（例如天气、假日和兴趣点）和上下文建模技术的未知泛化性。本文建立了一个基准，由大规模时空人群流量数据、上下文数据和最先进的时空预测模型组成。我们在几个城市人群流量预测场景中进行了全面的实验研究，以定量研究不同上下文特征和建模技术的泛化性。特别地，我们基于对流行研究的广泛调查，开发了上下文建模技术的通用分类法。我们使用了数百万条记录和丰富的上下文数据，训练和测试了数百种模型以捕捉上下文泛化性。我们的研究为STCFP中的上下文选择和建模提供了指南。

    Contextual features are important data sources for building spatiotemporal crowd flow prediction (STCFP) models. However, the difficulty of applying context lies in the unknown generalizability of both contextual features (e.g., weather, holiday, and points of interests) and context modeling techniques across different scenarios. In this paper, we build a benchmark composed of large-scale spatiotemporal crowd flow data, contextual data, and state-of-the-art spatiotemporal prediction models. We conduct a comprehensive experimental study to quantitatively investigate the generalizability of different contextual features and modeling techniques in several urban crowd flow prediction scenarios (including bike flow, metro passenger flow, electric vehicle charging demand and so on). In particular, we develop a general taxonomy of context modeling techniques based on extensive investigations in prevailing research. With millions of records and rich context data, we have trained and tested hun
    
[^60]: 开放式多模态关系推理用于视频问答

    Open-Ended Multi-Modal Relational Reasoning for Video Question Answering. (arXiv:2012.00822v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2012.00822](http://arxiv.org/abs/2012.00822)

    本文介绍了一个使用开放式多模态关系推理的机器人代理，可以通过语言交互回答视频场景中的问题，并在实验中展示了较好的表现。

    

    本文介绍了一个特别设计的机器人代理，用于分析外部环境并回答参与者的问题。该代理的主要重点是在基于视频场景的语言交互中协助个人。我们提出的方法将视频识别技术和自然语言处理模型整合到机器人代理中。我们通过研究参与者和机器人代理之间出现的相关问题，探讨影响人机交互的关键因素。在方法上，我们的实验结果显示，信任和交互效率之间存在积极的关系。此外，与其他基准方法相比，我们的模型表现出2%至3%的性能提升。

    In this paper, we introduce a robotic agent specifically designed to analyze external environments and address participants' questions. The primary focus of this agent is to assist individuals using language-based interactions within video-based scenes. Our proposed method integrates video recognition technology and natural language processing models within the robotic agent. We investigate the crucial factors affecting human-robot interactions by examining pertinent issues arising between participants and robot agents. Methodologically, our experimental findings reveal a positive relationship between trust and interaction efficiency. Furthermore, our model demonstrates a 2\% to 3\% performance enhancement in comparison to other benchmark methods.
    
[^61]: 人工设计：从普适智能的生物根源中汲取的教训。

    Design of the Artificial: lessons from the biological roots of general intelligence. (arXiv:1703.02245v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/1703.02245](http://arxiv.org/abs/1703.02245)

    生物系统上下文处理的进化调整通过分层架构实现的信息是构建AGI的关键。

    

    我们对智能机器的迷恋可以追溯到古代时期，神话人物塔洛斯、亚里士多德的机械思想和亚历山大的机械机器。然而，追求人工普适智能（AGI）的探索一直备受挫折。近年来，出现了向生物启发式软件和硬件的转变，但它们单一的设计重心使得其在实现AGI上效率低下。AGI的设计需要满足哪些要求？人工设计的限制是什么？对生物系统计算的仔细审查表明，通过分层架构实现的信息的上下文处理的进化调整是构建AGI的关键。

    Our fascination with intelligent machines goes back to ancient times with the mythical automaton Talos, Aristotle's mode of mechanical thought (syllogism) and Heron of Alexandria's mechanical machines. However, the quest for Artificial General Intelligence (AGI) has been troubled with repeated failures. Recently, there has been a shift towards bio-inspired software and hardware, but their singular design focus makes them inefficient in achieving AGI. Which set of requirements have to be met in the design of AGI? What are the limits in the design of the artificial? A careful examination of computation in biological systems suggests that evolutionary tinkering of contextual processing of information enabled by a hierarchical architecture is key to building AGI.
    

