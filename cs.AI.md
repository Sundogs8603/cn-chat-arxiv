# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Rethinking Adversarial Policies: A Generalized Attack Formulation and Provable Defense in Multi-Agent RL.](http://arxiv.org/abs/2305.17342) | 本文介绍了另一种常见、现实的多智能体RL攻击设置，提出了一种模拟攻击者对代理$\alpha$控制的更一般化攻击形式。并解决了先前攻击模型中缺乏可证明防御的问题。 |
| [^2] | [Multi-label Video Classification for Underwater Ship Inspection.](http://arxiv.org/abs/2305.17338) | 该文提出了一种使用深度学习和计算机视觉的自动化视频分析系统，在水下船体检测中实现多标签视频分类。该系统利用变换器的自我注意机制来捕获连续视频帧中的时空注意。 |
| [^3] | [Benchmarking Diverse-Modal Entity Linking with Generative Models.](http://arxiv.org/abs/2305.17337) | 新方法提出了一个多模态实体链接的基准测试，并使用预训练的生成多模态模型，在平均F1分数上优于最先进的特定任务EL模型8.51分。 |
| [^4] | [MADiff: Offline Multi-agent Learning with Diffusion Models.](http://arxiv.org/abs/2305.17330) | 本论文提出了基于注意力的扩散模型MADiff，解决了多智能体问题，是第一个扩散模型应用于多智能体离线RL的框架。 |
| [^5] | [Zero-TPrune: Zero-Shot Token Pruning through Leveraging of the Attention Graph in Pre-Trained Transformers.](http://arxiv.org/abs/2305.17328) | 《Zero-TPrune》是一个考虑到令牌的重要性和相似性的零射击方法，它利用预训练Transformer模型的注意图来进行令牌剪枝，以求解在边缘设备上Transformer模型即插即用的难题。 |
| [^6] | [Kernel-SSL: Kernel KL Divergence for Self-supervised Learning.](http://arxiv.org/abs/2305.17326) | 本文提出了一种名为Kernel-SSL的自监督学习方法，将多种现有非对比学习方法建立在了再生核希尔伯特空间（RKHS）理解之上并优化了其中的均值嵌入和协方差算子，实验结果显示，在ImageNet数据集下表现显著超越最先进的方法，提高了4.6%。 |
| [^7] | [Moral Machine or Tyranny of the Majority?.](http://arxiv.org/abs/2305.17319) | 本文研究了道德机器项目中提出的线性模型聚合机制的公平性问题，特别关注在存在策略影响的情况下少数群体是否会获胜的比例。 |
| [^8] | [Radar Enlighten the Dark: Enhancing Low-Visibility Perception for Automated Vehicles with Camera-Radar Fusion.](http://arxiv.org/abs/2305.17318) | 针对低能见度的自动驾驶车辆感知问题，本文提出了一种新的基于Transformer的3D目标检测模型“REDFormer”，通过鸟瞰相机-雷达融合进行实现。该模型在nuScenes数据集上表现出优异的分类和检测准确性，且相较于现有模型更经济实用。 |
| [^9] | [Beyond Positive Scaling: How Negation Impacts Scaling Trends of Language Models.](http://arxiv.org/abs/2305.17311) | 本研究介绍了一个包含否定问题的数据集NeQA，其中语言模型表现出反向缩放、U型缩放或正向缩放，解决NeQA依赖于问答和否定理解两个子任务，其缩放趋势由这两个子任务的缩放趋势组合形成。 |
| [^10] | [Towards Cognitive Bots: Architectural Research Challenges.](http://arxiv.org/abs/2305.17308) | 研究呈现了在多个数字平台上运行的认知机器人的架构挑战，这些机器人需要具备适应性和认知能力，以适应平台的不同特性和与人类/软件代理的合作。 |
| [^11] | [Chain-of-Thought Hub: A Continuous Effort to Measure Large Language Models' Reasoning Performance.](http://arxiv.org/abs/2305.17306) | 本文介绍了一个名为 Chain-of-Thought Hub 的开源评估套件，目的是评估大型语言模型的多步推理能力。它是为了追踪LLMs进展而编制的具有挑战性的推理基准。目前的研究结果表明，模型规模与推理能力相关，而 Claude-v1.3 是迄今为止推理能力最强的LLM。 |
| [^12] | [Exploiting Large Neuroimaging Datasets to Create Connectome-Constrained Approaches for more Robust, Efficient, and Adaptable Artificial Intelligence.](http://arxiv.org/abs/2305.17300) | 该论文讨论了如何利用大型神经影像数据集改进机器学习方法，以创造更加稳健、高效和适应性强的人工智能。通过发现重复子电路和分析果蝇的航向方向电路，该论文提出了新的连接模式和模型，以探索如何进一步扩展现有的计算模型。 |
| [^13] | [Improving Stability in Decision Tree Models.](http://arxiv.org/abs/2305.17299) | 本文通过医疗应用的视角，提出了一种新的决策树距离度量，并用它来确定树的稳定水平。我们提出了一种新的培训稳定决策树的方法，并探究稳定性、预测能力和可解释性之间不可避免的权衡。 |
| [^14] | [Convex Risk Bounded Continuous-Time Trajectory Planning and Tube Design in Uncertain Nonconvex Environments.](http://arxiv.org/abs/2305.17291) | 本文提出一种针对含有不确定性障碍物的非凸环境中的轨迹规划问题的解决方案，即通过风险轮廓的概念将风险有界轨迹规划问题转化为确定性优化问题。 |
| [^15] | [Slide, Constrain, Parse, Repeat: Synchronous SlidingWindows for Document AMR Parsing.](http://arxiv.org/abs/2305.17273) | 本文提出了一种同步滑动窗口的方法来处理文档解析的序列到序列任务，利用源-目标对齐并约束解码以保证重叠窗口的同步性和一致性，在AMR 3.0的评估中展示出了高质量的性能。 |
| [^16] | [Robust Lane Detection through Self Pre-training with Masked Sequential Autoencoders and Fine-tuning with Customized PolyLoss.](http://arxiv.org/abs/2305.17271) | 本论文提出了一种鲁棒车道检测流水线，该流水线包括自预训练掩模序列自编码器和使用定制PolyLoss微调的端到端神经网络模型。掩模序列自编码器被采用以通过重构随机掩膜图像中的丢失像素为目标来预训练神经网络模型，提升了车道检测性能。 |
| [^17] | [Im-Promptu: In-Context Composition from Image Prompts.](http://arxiv.org/abs/2305.17262) | 本文研究了类比推理能否实现对可组合视觉刺激成分的上下文内组合，通过引入三个基准测试套件，提供了设计类比推理的元学习框架 Im-Promptu。使用 Im-Promptu 可以训练多个具有不同组合水平的代理，包括矢量表示、补丁表示和物体槽。 |
| [^18] | [STL: Surprisingly Tricky Logic (for System Validation).](http://arxiv.org/abs/2305.17258) | 本文通过人类实验研究了形式规范是否可被人理解和用于检查系统，并发现说明有效性、被试熟悉度和教育水平是影响验证正确性的关键因素，参与者存在确认偏差。 |
| [^19] | [Large Language Models Can be Lazy Learners: Analyze Shortcuts in In-Context Learning.](http://arxiv.org/abs/2305.17256) | 本文探讨了大型语言模型在上下文学习中利用提示中的捷径的依赖性，发现大型模型更有可能在推理过程中利用提示中的捷径，这为评估上下文学习的稳健性和检测和缓解提示中捷径的使用提供了新的视角和挑战。 |
| [^20] | [Self-Supervised Reinforcement Learning that Transfers using Random Features.](http://arxiv.org/abs/2305.17250) | 该论文提出了一种自监督增强学习方法，能够在不同奖励的任务间进行行为迁移，同时避免有模型强化学习的挑战。使用一些随机特征作为奖励，进行自监督预训练能够暗含长期环境动态模型，然后使用这些隐式模型的规划技术能够在短时间内适应问题。 |
| [^21] | [COMCAT: Towards Efficient Compression and Customization of Attention-Based Vision Models.](http://arxiv.org/abs/2305.17235) | 本文提出了一种高效的 Vision Transformer 压缩方法，在多头注意力层上进行了新的探究，相比当前最先进的剪枝方法表现更优，能够在使用更少参数的情况下提高模型精度。 |
| [^22] | [Causal Component Analysis.](http://arxiv.org/abs/2305.17225) | 本文介绍了一个中间问题：因果成分分析(CauCA)，它是独立成分分析(ICA)和因果表示学习(CRL)的泛化和特例，其目标是学习解混函数和因果机制，预设了因果图的知识。 |
| [^23] | [Do We Really Need a Large Number of Visual Prompts?.](http://arxiv.org/abs/2305.17223) | 本文研究了视觉提示调整（VPT）技术中提示数量对微调性能和自我关注操作的影响，并提出了Prompt Condensation（PC）技术，该技术可以将提示数量减少约70％，同时保持准确性。 |
| [^24] | [Federated Learning for Semantic Parsing: Task Formulation, Evaluation Setup, New Algorithms.](http://arxiv.org/abs/2305.17221) | 本文研究了基于联邦学习的语义解析任务，提出了评估设置和新算法。实验表明，新算法FedSQL和Lorar优于现有的FL算法和我们提出的设置的强基线。 |
| [^25] | [A Categorical Representation Language and Computational System for Knowledge-Based Planning.](http://arxiv.org/abs/2305.17208) | 本文提出了一种基于范畴论的世界状态表示和转换方法，可以有效处理结构化知识，并且提供了使用知识图和关系数据库来建模规划中世界状态和更新的正式语义。 |
| [^26] | [Improved Sales Forecasting using Trend and Seasonality Decomposition with LightGBM.](http://arxiv.org/abs/2305.17201) | 本文提出了一种根据趋势和季节性分量在时间序列上的独特影响指标进行时间序列分组的新方法，并采用 LightGBM 模型进行预测，在沃尔玛销售数据上实现了较高的预测精度。 |
| [^27] | [A Model-Based Solution to the Offline Multi-Agent Reinforcement Learning Coordination Problem.](http://arxiv.org/abs/2305.17198) | 提出了一个基于模型的离线多智能体强化学习方法MOMA-PPO，通过生成合成交互数据并优化智能体的政策，解决了策略一致性和策略微调两个协调问题，在具有挑战性的离线MARL场景中胜过主流的学习方法，提供了实际应用中的可行解决方案。 |
| [^28] | [A Knowledge Engineering Primer.](http://arxiv.org/abs/2305.17196) | 该文介绍了知识工程的基本概念，帮助读者了解该领域并建立直觉。 |
| [^29] | [Inferring the Future by Imagining the Past.](http://arxiv.org/abs/2305.17195) | 本文介绍了一种蒙特卡罗算法用于从情报主体的单张图像中推断出一连串复杂的历史和未来事件，并且能够在只有少数样本的情况下扩展到各种具有挑战性的推断问题。 |
| [^30] | [AI-based analysis of super-resolution microscopy: Biological discovery in the absence of ground truth.](http://arxiv.org/abs/2305.17193) | 利用弱监督学习范例对超分辨率显微镜进行分析具有发现新生物学的巨大潜力，并且可以加速探索亚细胞大分子和细胞器分子结构。 |
| [^31] | [ProGroTrack: Deep Learning-Assisted Tracking of Intracellular Protein Growth Dynamics.](http://arxiv.org/abs/2305.17183) | 本文提出了一种新的方法——ProGroTrack，在基于检测的跟踪(DBT)框架中将YOLO和ByteTrack算法相结合，成功地跟踪了细胞内蛋白质纳米结构的生长行为。其中，采用YOLOv5模型表现最佳，半监督学习有效地提高了模型性能。该方法揭示了iPAK4蛋白质纤维的两个不同生长阶段，为相关研究提供了重要数据支持。 |
| [^32] | [On the Copying Problem of Unsupervised NMT: A Training Schedule with a Language Discriminator Loss.](http://arxiv.org/abs/2305.17182) | 无监督NMT中的复制问题通常发生在远距离语种对中且会直接复制输入句子的部分作为翻译，本研究提出了一种包含语言鉴别器损失的训练计划来缓解该问题，并提高低资源语种的翻译性能。 |
| [^33] | [An Improved Model Ensembled of Different Hyper-parameter Tuned Machine Learning Algorithms for Fetal Health Prediction.](http://arxiv.org/abs/2305.17156) | 本研究提出了一种名为ETSE的机器学习集成模型，用于预测胎儿健康。该模型通过采用多种数据预处理技术和7种不同的机器学习分类器，能够提高预测准确性和性能。 |
| [^34] | [Stability of implicit neural networks for long-term forecasting in dynamical systems.](http://arxiv.org/abs/2305.17155) | 本文提出了一种基于隐式数值方案稳定性特性的神经网络，加入了硬性约束来保证其权重稳定性，取得了较好的长期预测结果。 |
| [^35] | [On convex conceptual regions in deep network representations.](http://arxiv.org/abs/2305.17154) | 本文研究了深度网络表示中概念空间的凸性对泛化能力、小样本学习和主观一致性的影响，发现近似凸性在多个应用领域中广泛存在。 |
| [^36] | [mldr.resampling: Efficient Reference Implementations of Multilabel Resampling Algorithms.](http://arxiv.org/abs/2305.17152) | mldr.resampling是一个软件包，提供11种多标签重采样方法的参考实现，旨在应对多标签学习中的不平衡情况，并具有高效性。 |
| [^37] | [Diagnostic Spatio-temporal Transformer with Faithful Encoding.](http://arxiv.org/abs/2305.17149) | 本文提出了一种诊断时空变换器（DFStrans），其利用新的位置编码和时空依赖性发现框架，能够在具有复杂时空依赖性的多元时间序列分类任务中提取可操作见解。 |
| [^38] | [Heterogeneous Value Evaluation for Large Language Models.](http://arxiv.org/abs/2305.17147) | 本文提出了一种自动对齐评估方法A2EHV，采用异质价值系统，并基于价值合理性和社会价值定向框架评估代理人行为的社会偏好，结果表明比传统对齐方法更合理。 |
| [^39] | [Ghost in the Minecraft: Generally Capable Agents for Open-World Enviroments via Large Language Models with Text-based Knowledge and Memory.](http://arxiv.org/abs/2305.17144) | 本文提出了Ghost in the Minecraft (GITM)框架，利用大型语言模型与基于文本的知识和记忆，创造了一种在Minecraft中具备通用能力的智能体，可在以文本为基础的复杂编程环境中熟练导航。 |
| [^40] | [Research on Multi-Agent Communication and Collaborative Decision-Making Based on Deep Reinforcement Learning.](http://arxiv.org/abs/2305.17141) | 本研究基于CTDE框架，提出了基于MAPPO算法的多智能体合作决策模型，并引入了基于权重调度和注意力模块的多智能体通信机制，能够有效缓解多智能体环境的不稳定性，提高多智能体在复杂环境中的协作决策能力。 |
| [^41] | [Interactive Model Expansion in an Observable Environment.](http://arxiv.org/abs/2305.17140) | 本文研究了在搜索过程中用户能否考虑部分解决方案并进行验证的问题，在可观测环境下通过交互式系统提出和完善解决方案的假设。 |
| [^42] | [A Measure-Theoretic Axiomatisation of Causality.](http://arxiv.org/abs/2305.17139) | 本文提出了一个称为"因果空间"的概念，旨在以柯尔莫戈罗夫的概率测度公理化为起点，实现对因果关系的公理化，并成功地解决了现有框架的限制。 |
| [^43] | [Integrating Generative Artificial Intelligence in Intelligent Vehicle Systems.](http://arxiv.org/abs/2305.17137) | 本文提供了关于在智能车辆系统中集成生成人工智能的全面指南，重点强调了其对语音、音频、视觉和多模态交互的应用，并提出了未来研究领域和与伦理道德相关的挑战和风险。 |
| [^44] | [Three Towers: Flexible Contrastive Learning with Pretrained Image Models.](http://arxiv.org/abs/2305.16999) | 本文提出了 3T 方法，即在视觉语言模型中引入预训练的图像分类器，从而提高对比学习的灵活性。3T 同时受益于预训练嵌入和对比训练，并在实验证明对检索任务和分类问题均取得了有竞争力的性能。 |
| [^45] | [NavGPT: Explicit Reasoning in Vision-and-Language Navigation with Large Language Models.](http://arxiv.org/abs/2305.16986) | NavGPT是基于LLM的导航智能体，可以在视觉语言导航（VLN）中，通过对文本描述进行推理，执行零-shot连续动作预测。该模型具有高级规划能力，可以将指令分解成子目标、整合常识知识以进行障碍物避免，并参考先前的步骤进行澄清。NavGPT展示了通用体现智能体发展的美好前景。 |
| [^46] | [Domain Aligned Prefix Averaging for Domain Generalization in Abstractive Summarization.](http://arxiv.org/abs/2305.16820) | 本文提出了一种轻量级、基于加权平均的领域对齐前缀平均方法（DAPA），用于抽象摘要中的领域泛化，实现了有效的源域扩展以提高性能。 |
| [^47] | [InterFormer: Interactive Local and Global Features Fusion for Automatic Speech Recognition.](http://arxiv.org/abs/2305.16342) | 本文提出了InterFormer，用于交互式局部和全局特征融合，以学习更好的ASR表示。通过组合卷积块和变形器块，以及引入BFIM和SFM模块，实现了局部和全局特征的交互和融合，取得了在公共ASR数据集上优异的性能。 |
| [^48] | [Fast Online Node Labeling for Very Large Graphs.](http://arxiv.org/abs/2305.16257) | 本文提出了一种适用于超大规模图的在线节点分类算法FastONL，它基于广义局部推送方法，能有效近似逆矩阵列并应用于一系列流行的图核，具有较低的遗憾值和每个预测的较低成本。 |
| [^49] | [On Computing Universal Plans for Partially Observable Multi-Agent Path Finding.](http://arxiv.org/abs/2305.16203) | 本文提出了一种通用计划的解决方案，能够确保多个智能体之间不发生碰撞，并使用 ASP-MAUPF 系统进行实验，对其适用性和环境依赖度进行了观察和分析。 |
| [^50] | [Exploiting Noise as a Resource for Computation and Learning in Spiking Neural Networks.](http://arxiv.org/abs/2305.16044) | 本文提出了噪声脉冲神经元网络（NSNN）和噪声驱动学习规则（NDL），展示了噪声可以作为计算和学习的资源，并为一般脉冲神经元网络提供了一个框架。研究还展示了NSNNs在图像分类和语音识别等实际任务中的适用性，表明它们是未来神经形态计算系统的潜在有力工具。 |
| [^51] | [Inverse square Levy walk emerging universally in goal-oriented tasks.](http://arxiv.org/abs/2305.15559) | 本研究证明了反平方Levy步态（称为Cauchy步态）在目标导向任务中普遍出现。 |
| [^52] | [Multi-modal Machine Learning for Vehicle Rating Predictions Using Image, Text, and Parametric Data.](http://arxiv.org/abs/2305.15218) | 本文提出了一种多模式机器学习模型，它可以同时使用图像、文本和参数数据对车辆进行评分预测，增加了数据的完整性和准确性。 |
| [^53] | [Knowledge-Design: Pushing the Limit of Protein Deign via Knowledge Refinement.](http://arxiv.org/abs/2305.15151) | 本文提出了一种知识感知模块来提炼低质量残基，引入记忆检索机制实现了超过50%的训练时间节省，并取得了较好的性能表现，是蛋白质设计领域的一次创新。 |
| [^54] | [Transferring Visual Attributes from Natural Language to Verified Image Generation.](http://arxiv.org/abs/2305.15026) | 本文提出了一种自然语言到验证图像生成(NL2VI)方法，将自然提示转化为更适合的视觉提示，通过VQA算法进行验证，使生成的图像更加准确和与自然语言相关联，并在实验中证明了该方法的优越性。 |
| [^55] | [Optimal Control of Logically Constrained Partially Observable and Multi-Agent Markov Decision Processes.](http://arxiv.org/abs/2305.14736) | 本文介绍了一个用于部分可观察和多智能体马尔可夫决策过程的最优控制理论，能够使用时间逻辑规范表达约束，并提供了一种结构化的方法来合成策略以最大化累积奖励并保证约束条件的概率足够高。同时我们还提供了对信息不对称的多智能体设置进行最优控制的框架。 |
| [^56] | [Training Transitive and Commutative Multimodal Transformers with LoReTTa.](http://arxiv.org/abs/2305.14243) | LoReTTa是一个自监督框架，可以在具有不同模态的数据集中转换。通过合成数据集的方法，显著提高了下游任务的性能。 |
| [^57] | [Text-to-SQL Error Correction with Language Models of Code.](http://arxiv.org/abs/2305.13073) | 本论文提出了一种基于从句编辑模型的文本到SQL的语言模型纠错方法，并通过新的SQL查询表示改进了语言模型的精确匹配准确率，提高了2.4-6.5，最多提高4.3个百分点。 |
| [^58] | [Road Planning for Slums via Deep Reinforcement Learning.](http://arxiv.org/abs/2305.13060) | 本文介绍了一种基于深度强化学习的方法，用于自动布局贫民窟道路。通过掩码策略优化，可使可达性提高14.3％，对现有基线方法具有明显改进。 |
| [^59] | [Adaptive action supervision in reinforcement learning from real-world multi-agent demonstrations.](http://arxiv.org/abs/2305.13030) | 本文提出了一种从多智能体场景真实世界展示中进行强化学习的自适应行动监督方法，实现了在复制和推广之间平衡的 RL 模型。 |
| [^60] | [Bridging Active Exploration and Uncertainty-Aware Deployment Using Probabilistic Ensemble Neural Network Dynamics.](http://arxiv.org/abs/2305.12240) | 本文提出了一个基于概率集成神经网络动态模型的统一机器人控制框架，用于桥接主动探索和不确定性感知。该方法在几个基准任务上表现出优异的效果。 |
| [^61] | [Post Hoc Explanations of Language Models Can Improve Language Models.](http://arxiv.org/abs/2305.11426) | 本文提出了一种新的框架AMPLIFY，利用后验解释自动化生成原因，并在多个数据集和任务上显著提高现有语言模型的性能。 |
| [^62] | [Milestones in Autonomous Driving and Intelligent Vehicles Part \uppercase\expandafter{\romannumeral1}: Control, Computing System Design, Communication, HD Map, Testing, and Human Behaviors.](http://arxiv.org/abs/2305.11239) | 本次论文总结了自动驾驶和智能车辆中关于控制、计算机系统设计、通信、高精度地图、测试和人类行为的发展情况和未来研究方向。 |
| [^63] | [Bayesian Renormalization.](http://arxiv.org/abs/2305.10491) | 本文提出了一种基于信息论的贝叶斯统计模型的重整化方法，使用Fisher度量定义了一个相关长度作为紧密相关的概率分布点之间的可分辨性(RG)尺度，在统计推断实验中，可以得到某个系统最大特异性观察数量的代理。贝叶斯重整化方法为给定系统准备一个在上述尺度上精度有限的有效模型，这个尺度可以被解释为当前实验装置可以探测到的最大能量。贝叶斯重整化提出了一种发现和表征基本物理理论的新框架。 |
| [^64] | [People Talking and AI Listening: How Stigmatizing Language in EHR Notes Affect AI Performance.](http://arxiv.org/abs/2305.10201) | 本文研究了电子病历中污名化语言对基于Transformer的深度学习模型和可解释AI(XAI)技术进行死亡预测的影响。发现临床医生所写的SL会对AI性能表现不利，尤其是在黑人患者中表现更为明显，强调了理解偏见对下游AI性能的影响的重要性，以开发更具公平和正义的医疗系统。 |
| [^65] | [ConvXAI: Delivering Heterogeneous AI Explanations via Conversations to Support Human-AI Scientific Writing.](http://arxiv.org/abs/2305.09770) | ConvXAI是一个基于对话的XAI系统，它集成了多种XAI类型，并将实际用户需求嵌入设计中，以提高实用性。 |
| [^66] | [Provable Multi-instance Deep AUC Maximization with Stochastic Pooling.](http://arxiv.org/abs/2305.08040) | 本文提出了在多实例学习中使用深度AUC最大化（DAM）的方法，并根据包含大量实例的情况下训练的计算挑战，提出了一种基于方差减少的随机池化方法，使得只需对每个包进行少量采样即可计算MIDAM模型，提高了效率和准确性。 |
| [^67] | [Autonomous GIS: the next-generation AI-powered GIS.](http://arxiv.org/abs/2305.06453) | 自主GIS是一种AI动力地理信息系统，采用大型语言模型作为推理核心，具有自动空间数据收集、分析和可视化的能力，旨在实现五个自主目标：自动生成、自组织、自验证、自执行和自生长。 |
| [^68] | [GPT-NAS: Neural Architecture Search with the Generative Pre-Trained Model.](http://arxiv.org/abs/2305.05351) | GPT-NAS使用生成式预训练模型优化神经架构搜索，通过提出近似的架构组件减小搜索空间，并明显优于其他NAS方法。 |
| [^69] | [Semantic Embedded Deep Neural Network: A Generic Approach to Boost Multi-Label Image Classification Performance.](http://arxiv.org/abs/2305.05228) | 本研究提出了一种通用的语义嵌入深度神经网络，通过空间感知的语义特征和基于通道的注意力模型来提高多标签预测的模型性能，平均相对改进达到15.27%。 |
| [^70] | [A Comprehensive Study on Dataset Distillation: Performance, Privacy, Robustness and Fairness.](http://arxiv.org/abs/2305.03355) | 本研究对当前最先进的数据集压缩方法进行了全面评估，发现其存在隐私风险并可能放大模型的不公平性，提供了大规模的基准测试框架。 |
| [^71] | [Vision Meets Definitions: Unsupervised Visual Word Sense Disambiguation Incorporating Gloss Information.](http://arxiv.org/abs/2305.01788) | 本文提出了一种无监督的视觉词义消歧方法，通过引入外部词汇知识库的词义信息来解决原来图像-文本匹配模型中的多义词问题。采用贝叶斯推断来加入词义定义，并通过与上下文相关的 GPT-3 定义生成方法，成功解决了词典外问题。 |
| [^72] | [Chronosymbolic Learning: Efficient CHC Solving with Symbolic Reasoning and Inductive Learning.](http://arxiv.org/abs/2305.01206) | Chronosymbolic Learning是一个简单而有效的框架，将符号推理和数据驱动方法相结合，用于高效地解决CHC系统。实验证明它在288个基准测试上表现出优异的结果，包括许多具有非线性整数算术的实例。 |
| [^73] | [Lightweight, Pre-trained Transformers for Remote Sensing Timeseries.](http://arxiv.org/abs/2304.14065) | 设计针对远程传感器数据的自监督学习模型和训练技术，可以得到表现更好且更小的模型。预训练的遥感时间序列Transformer（Presto）在几个遥感基准测试中实现了最先进的结果。 |
| [^74] | [Text-to-Audio Generation using Instruction-Tuned LLM and Latent Diffusion Model.](http://arxiv.org/abs/2304.13731) | 本研究提出了一种使用指令调整的LLM Flan-T5作为文本编码器和基于潜在扩散模型(LDM)的方法TANGO生成文本到音频(TTA)的新方法，在AudioCaps测试集上表现优于先进的AudioLDM。 |
| [^75] | [Fundamental Limitations of Alignment in Large Language Models.](http://arxiv.org/abs/2304.11082) | 本文通过提出一种理论方法——行为期望边界（BEB），展示了大型语言模型中对齐的基本限制，并证明任何对齐过程都无法根除不希望的行为，这对于防止恶意攻击是不安全的。 |
| [^76] | [ChatGPT4PCG Competition: Character-like Level Generation for Science Birds.](http://arxiv.org/abs/2303.15662) | 本论文介绍了举办在2023 IEEE游戏会议上的第一届ChatGPT4PCG比赛，目标是让ChatGPT生成具有高稳定性和类似角色的特质来生成具有科学鸟角色级水平的关卡。 |
| [^77] | [Posthoc Interpretation via Quantization.](http://arxiv.org/abs/2303.12659) | 本文提出了一种新的方法 PIQ，通过对分类器进行向量量化，将其表示转换为离散类特定的潜空间，从而解释分类器所做出的决策，并且通过研究发现该方法相比其他方法更容易让人理解。 |
| [^78] | [CB2: Collaborative Natural Language Interaction Research Platform.](http://arxiv.org/abs/2303.08127) | CB2是一个用于研究基于任务的合作自然语言交互的平台，在3D游戏环境中提供了后端服务器和各种工具和流程。它在可扩展的研究中展示了学习的指令跟随模型。 |
| [^79] | [Mastering Strategy Card Game (Hearthstone) with Improved Techniques.](http://arxiv.org/abs/2303.05197) | 本文将端到端策略函数和乐观平滑虚拟博弈算法应用于更加复杂的商业游戏爐石戰記，提出改进技术并在人机对战中表现出较强决策能力。 |
| [^80] | [Dynamic Prompting: A Unified Framework for Prompt Tuning.](http://arxiv.org/abs/2303.02909) | 本论文提出了一个统一的动态提示（DP）调整策略用于优化提示调整的性能，该策略可以动态地确定不同的提示变量来捕获额外的语义信息。 |
| [^81] | [Metaheuristic conditional neural network for harvesting skyrmionic metastable states.](http://arxiv.org/abs/2303.02876) | 提出了一种基于元启发式条件神经网络的方法，收集高不规则潜能能量面上的物理有趣的稳态， 并在Pd / Fe / Ir（111）系统中应用于识别自旋结构，观察了其中一些结构的有限温度自旋动力学特性和拓扑电荷与结构之间的关系。 |
| [^82] | [Inseq: An Interpretability Toolkit for Sequence Generation Models.](http://arxiv.org/abs/2302.13942) | 本文介绍了Inseq，这是一个Python工具包，旨在推广可解释性序列生成模型的分析。它为常见的解码器和编码器-解码器Transformers架构提供了提取模型内部信息和特征重要性得分的直观优化方法。作者还在机器翻译模型和GPT-2中展示了Inseq的潜力，证明其有助于推动可解释性自然语言生成的未来发展。 |
| [^83] | [A Self-Supervised Learning-based Approach to Clustering Multivariate Time-Series Data with Missing Values (SLAC-Time): An Application to TBI Phenotyping.](http://arxiv.org/abs/2302.13457) | 本文提出了一种基于自监督学习的多元时间序列数据聚类方法(SLAC-Time)，采用时间序列预测作为代理任务，不需要填补缺失值，具有更健壮的时间序列表示。 |
| [^84] | [Active Velocity Estimation using Light Curtains via Self-Supervised Multi-Armed Bandits.](http://arxiv.org/abs/2302.12597) | 本文讨论了使用成本更低、速度更快、分辨率更高的可编程光幕来估计机器人所在环境的障碍物的位置和移动方式。为了决定光幕的放置位置以准确执行此任务，我们使用了最大化信息增益和验证预测对象位置的多种策略，并通过在线学习框架组合了这些策略。我们提出了一种新颖的自监督奖励函数，以评估当前速度估计的准确性。 |
| [^85] | [Understanding Expertise through Demonstrations: A Maximum Likelihood Framework for Offline Inverse Reinforcement Learning.](http://arxiv.org/abs/2302.07457) | 通过提出的双层优化公式，我们提供了一个离线逆向强化学习的最大似然框架，该框架通过最大化奖励来估计专家的保守模型以及专家的环境动态，能够更准确地推断专业技能。 |
| [^86] | [Geometric Clifford Algebra Networks.](http://arxiv.org/abs/2302.06594) | 本文提出了基于几何代数的几何 Clifford 代数网络（GCANs），采用对称群变换建模动态系统，通过群作用层、激活和归一化方案，可以优化几何模板，提高三维刚体变换和流体动力学模拟的性能。 |
| [^87] | [Revisiting Discriminative vs. Generative Classifiers: Theory and Implications.](http://arxiv.org/abs/2302.02334) | 本文重新审视关于判别式与生成式分类器的经典主题，利用多类$\mathcal{H}$-一致性下界，证明了在温和的假设下，多类朴素贝叶斯分类器的样本要求比逻辑回归分类器多了$O(\log n)$。 |
| [^88] | [On the Robustness of Randomized Ensembles to Adversarial Perturbations.](http://arxiv.org/abs/2302.01375) | 本文对随机集成算法在对抗攻击环境中的鲁棒性进行了研究，提出了新的训练算法 BARRE，能够有效地防御强大的 $\ell_\infty$ 范围内的攻击。 |
| [^89] | [Double Permutation Equivariance for Knowledge Graph Completion.](http://arxiv.org/abs/2302.01313) | 本研究提出了双排列等变性的KG表示方法，可以使神经网络在KG中执行复杂的逻辑推理任务，并在多个归纳KG完成任务中实现了最先进的Hits@10测试准确率。双排列等变性在KG中开辟了新的研究方向。 |
| [^90] | [Knowledge Transfer from Pre-trained Language Models to Cif-based Speech Recognizers via Hierarchical Distillation.](http://arxiv.org/abs/2301.13003) | 本文提出了一种分层蒸馏技术，在声学和语言级别上将预训练语言模型（PLMs）的知识转移到基于CIF的自动语音识别（ASR）模型，相较原始模型，在AISHELL-1和LibriSpeech数据集上分别实现了15%和9%的相对误差率降低。 |
| [^91] | [Hierarchical Imitation Learning with Vector Quantized Models.](http://arxiv.org/abs/2301.12962) | 本文提出带有矢量量化模型的分层模仿学习方法，通过强化学习识别专家轨迹的子目标并建立矢量量化生成模型实现子目标级别的规划，该算法在解决复杂、长远的决策问题方面优于现有最先进方法。 |
| [^92] | [Certifiably Robust Reinforcement Learning through Model-Based Abstract Interpretation.](http://arxiv.org/abs/2301.11374) | CAROL是一个强化学习框架，它基于模型和抽象解释方法，学习出的策略具有机器可证明的对抗鲁棒性证书，在实验上表现出更好的认证性能和可比较的对抗性能。 |
| [^93] | [Automatic Intrinsic Reward Shaping for Exploration in Deep Reinforcement Learning.](http://arxiv.org/abs/2301.10886) | 本文提出了一种名为AIRS的自动内在奖励塑造探索方法，可以提供高质量的内在激励以增强强化学习中的探索性能；并开发了高效可靠的内在奖励工具包。实验表明，AIRS性能卓越，能够胜过基准方案。 |
| [^94] | [DIFFormer: Scalable (Graph) Transformers Induced by Energy Constrained Diffusion.](http://arxiv.org/abs/2301.09474) | DIFFormer是一种能量受限扩散模型，通过逐渐融合其他实例信息的演化状态，导出了一类新的神经编码器，称为DIFFormer（基于扩散的Transformer），能够揭示真实世界中复杂的数据生成过程。 |
| [^95] | [Mean-Field Control based Approximation of Multi-Agent Reinforcement Learning in Presence of a Non-decomposable Shared Global State.](http://arxiv.org/abs/2301.06889) | 本文提出了一种基于均场控制的多智能体强化学习的近似方法，即使智能体共享一个非可分全局状态，也能具有较好的适用性和近似效果。 |
| [^96] | [Define, Evaluate, and Improve Task-Oriented Cognitive Capabilities for Instruction Generation Models.](http://arxiv.org/abs/2301.05149) | 本文提出了基于任务的认知能力，设计了评估方案来比较语言模型和人类的这些能力，通过在导航指令生成问题中的应用，发现模型的语用能力仍需改进。 |
| [^97] | [InPars-v2: Large Language Models as Efficient Dataset Generators for Information Retrieval.](http://arxiv.org/abs/2301.01820) | 本文提出 InPars-v2，使用开源 LLMs 和强大再排序器生成用于信息检索中训练的合成查询-文档对，可在 BEIR 基准测试中达到最新的最好结果。 |
| [^98] | [SERENGETI: Massively Multilingual Language Models for Africa.](http://arxiv.org/abs/2212.10785) | SERENGETI是一个大规模多语言语言模型，覆盖了517种非洲语言和语言方言。在自然语言理解任务中，它的表现优于其他在非洲语言上的语言模型，能够提供有价值的语言信息。 |
| [^99] | [Lego-MT: Towards Detachable Models in Massively Multilingual Machine Translation.](http://arxiv.org/abs/2212.10551) | 本文提出了一种可拆卸的多语言机器翻译模型，Lego-MT，以解决现有多语言单体模型在参数干扰和低效推导方面的挑战。进行实验评估表明，该模型具有较高的性能，相比具有10倍规模的模型，在效率和表现方面都更具优势。 |
| [^100] | [Detoxifying Text with MaRCo: Controllable Revision with Experts and Anti-Experts.](http://arxiv.org/abs/2212.10543) | MaRCo是一种排毒算法，能够使用专家和反专家模型对文本进行可控的重写和修订，适用于消除微妙的有害信息，且在自动化指标和人类评估中均有很好的表现。 |
| [^101] | [When Not to Trust Language Models: Investigating Effectiveness and Limitations of Parametric and Non-Parametric Memories.](http://arxiv.org/abs/2212.10511) | 本文通过对10个模型和4种增强方法的实验，发现语言模型在记忆不太流行的实际知识方面存在困难，而检索增强的语言模型表现较好，提出了一种检索增强语言模型的简单有效方法。 |
| [^102] | [DOC: Improving Long Story Coherence With Detailed Outline Control.](http://arxiv.org/abs/2212.10077) | 该论文提出了一个名为 Detailed Outline Control(DOC) 的框架，通过详细大纲和详细控制器来提高生成长篇故事时的情节连贯性和大纲相关性，人类评估证实该方法在这些方面显著优于基线方法，并且更适用于交互生成设置。 |
| [^103] | [Reasoning with Language Model Prompting: A Survey.](http://arxiv.org/abs/2212.09597) | 本文提供了使用语言模型提示进行推理的前沿研究综合调查。讨论了新兴推理能力出现的潜在原因，并提供系统资源帮助初学者。 |
| [^104] | [BLOOM+1: Adding Language Support to BLOOM for Zero-Shot Prompting.](http://arxiv.org/abs/2212.09535) | 本文在BLOOM模型中应用语言适应策略，将其适应到新语言上，并在八种新语言的零样本提示表现中提升了性能。适配器微调比大模型的持续预训练更有效，提示性能主要由语言适应数据的大小确定。 |
| [^105] | [An Extensible Plug-and-Play Method for Multi-Aspect Controllable Text Generation.](http://arxiv.org/abs/2212.09387) | 本论文提出了一种基于可训练门的多方面可控文本生成方法，用于规范前缀的干预，从而实现对训练时未见过的方面组合的控制，具有良好的可扩展性和性能表现。 |
| [^106] | [On Isotropy, Contextualization and Learning Dynamics of Contrastive-based Sentence Representation Learning.](http://arxiv.org/abs/2212.09170) | 本文通过几何学角度在对比句子表示学习中发现，对比学习带来了各向同性，并驱动同一句子中标记在语义空间中收敛到相似的位置。对于语义上有意义的标记，"虚假的情境化"得到了缓解，而对于功能性标记则被增强。 |
| [^107] | [Masked Autoencoding for Scalable and Generalizable Decision Making.](http://arxiv.org/abs/2211.12740) | 本文提出了一种遮盖式决策预测 (MaskDP) 的简单可扩展的自监督预训练方法，在可扩展的增强学习和行为克隆中能够有效地从大规模多样的序列数据中学习，并且零样本转移至新任务。 |
| [^108] | [Learning Heterogeneous Agent Cooperation via Multiagent League Training.](http://arxiv.org/abs/2211.11616) | 本文提出了一种名为异质联赛训练（HLT）的通用强化学习算法，为解决异质多智能体问题，使用策略池和超网络，提高了异质智能体的合作效率。 |
| [^109] | [Scalar Invariant Networks with Zero Bias.](http://arxiv.org/abs/2211.08486) | 本文证明了在解决许多图像任务(例如图像分类)时可以忽略偏置，并且零偏置神经网络在实际图像分类任务中表现良好，同时具有标量 (乘法) 不变性，从而在改变对比度时仍能保持预测不变。 |
| [^110] | [SSL4EO-S12: A Large-Scale Multi-Modal, Multi-Temporal Dataset for Self-Supervised Learning in Earth Observation.](http://arxiv.org/abs/2211.07044) | 该论文介绍了一种名为SSL4EO-S12的大规模、全球、多模态、多季度的自监督学习地球观测数据集，证明了对该数据集进行自监督预训练可以产生准确性与监督学习相当的模型，在该领域具有很高的应用价值。 |
| [^111] | [lilGym: Natural Language Visual Reasoning with Reinforcement Learning.](http://arxiv.org/abs/2211.01994) | 本文提出了一个基于自然语言视觉推理的强化学习基准测试——lilGym，它由2661个高度组合的人类编写自然语言语句和交互式视觉环境组成，并通过注释可执行Python程序来实现精确的奖励计算。本文的实验结果和分析表明，lilGym是一个具有挑战性的开放性问题。 |
| [^112] | [Crosslingual Generalization through Multitask Finetuning.](http://arxiv.org/abs/2211.01786) | 该论文通过多任务微调实现跨语言泛化。研究表明，在英语提示下，对大型多语言模型进行英语任务的微调，可以实现对仅出现在预训练语料库中的非英语语言的任务泛化，并且使用英语提示进行多语言任务的微调进一步提高了在英语和非英语任务上的表现，从而实现了各种零-shot结果的最新水平。 |
| [^113] | [Visually-Aware Audio Captioning With Adaptive Audio-Visual Attention.](http://arxiv.org/abs/2210.16428) | 本文提出了一种自适应音频视觉关注的视觉感知音频字幕生成方法，通过利用视觉上下文来帮助解决音频字幕生成中的歧义声音问题。在AudioCaps上实验结果表明，该方法在机器翻译指标上取得了最佳结果。 |
| [^114] | [Shortest Edit Path Crossover: A Theory-driven Solution to the Permutation Problem in Evolutionary Neural Architecture Search.](http://arxiv.org/abs/2210.14016) | 本文提出了一种基于最短编辑路径的交叉操作符，用以解决黑盒神经网络结构搜索中的排列问题，并在理论上证明了其优于突变的期望改进。 |
| [^115] | [Motif-Backdoor: Rethinking the Backdoor Attack on Graph Neural Networks via Motifs.](http://arxiv.org/abs/2210.13710) | 本文提出了一种基于motif的GNN后门攻击方法，设计了一种基于motif的触发器生成器，能够提高后门攻击的隐蔽性和效果，在各种基准数据集上进行实验证明其性能优于现有方法。 |
| [^116] | [Intra-Source Style Augmentation for Improved Domain Generalization.](http://arxiv.org/abs/2210.10175) | 本论文提出了一种基于源内样式增强（ISSA）的方法，用于改进语义分割中的领域泛化。通过使用掩模噪声编码器随机化样式和内容组合，ISSA有效地增加了训练数据的多样性并减少了虚假相关性，从而在不同类型的驾驶场景语义分割中获得了高达12.4％的mIoU改进。 |
| [^117] | [STaSy: Score-based Tabular data Synthesis.](http://arxiv.org/abs/2210.04018) | 提出了一种新的基于分值的表格数据生成模型（STaSy），并采用自适应学习技术和微调策略进一步提高采样质量和多样性。 |
| [^118] | [VIMA: General Robot Manipulation with Multimodal Prompts.](http://arxiv.org/abs/2210.03094) | 本研究提出了一种新的机器人操作方式——多模态提示实现通用机器人操作。通过设计一个基于变压器的机器人代理VIMA，可以处理提示并自回归地输出电机动作，实现了各种任务类型的最新结果，并能够零样本泛化到新的对象类别，这对实现通用机器人操作具有前景。 |
| [^119] | [Nonparametric Decoding for Generative Retrieval.](http://arxiv.org/abs/2210.02068) | 本文提出了一种非参数化解码方法，通过利用上下文化词汇嵌入，解决了生成式检索模型信息容量受限的问题，在文档检索任务中具有高效性和高性能。 |
| [^120] | [CRISP: Curriculum based Sequential Neural Decoders for Polar Code Family.](http://arxiv.org/abs/2210.00313) | 该研究提出了一种新颖的基于课程的序列神经解码器CRISP，可以用于极化编码族，相比连续取消(SC)译码器，CRISP具有更高的准确性和可靠性，并可轻松地拓展至极化调整卷积（PAC）代码。 |
| [^121] | [FIGO: Enhanced Fingerprint Identification Approach Using GAN and One Shot Learning Techniques.](http://arxiv.org/abs/2208.05615) | 本文提出了一种基于GAN和单样本学习技术的FIGO指纹识别方法，通过Pix2Pix模型对低质量指纹图像进行增强，在识别环节中使用一次学习进行指纹信息分类，取得了更好的性能。 |
| [^122] | [ME-GAN: Learning Panoptic Electrocardio Representations for Multi-view ECG Synthesis Conditioned on Heart Diseases.](http://arxiv.org/abs/2207.10670) | 本文提出一种基于心脏疾病条件学习全景心电图表示的多视角ECG合成方法ME-GAN，利用新的混合归一化方法将疾病信息注入到合适位置，具有较好的生成效果和疾病识别能力。 |
| [^123] | [Masked World Models for Visual Control.](http://arxiv.org/abs/2206.14244) | 本研究提出了一种视觉模型驱动的RL框架，将视觉表示学习和动力学学习分离，使用自编码器和潜在动力学模型来准确建模机器人控制策略。 |
| [^124] | [Worldwide AI Ethics: a review of 200 guidelines and recommendations for AI governance.](http://arxiv.org/abs/2206.11922) | 本篇论文回顾了200个AI治理指南和建议，通过对这些文档内容和性质的可视化，旨在了解各机构间AI伦理原则存在的共识和相似点，为未来的法规辩论提供启示。 |
| [^125] | [Personalized Algorithmic Recourse with Preference Elicitation.](http://arxiv.org/abs/2205.13743) | 研究提出了PEAR方法，这是一个首个能够针对最终用户需求提供个性化算法补救成本的人机交互方法。该方法利用贝叶斯偏好引导的见解，通过最大化原则性信息增益度量来计算目标用户选择的预期效用，然后将偏好引导整合到强化学习框架中。该方法显著提高了算法干预的经济实用性和用户友好性。 |
| [^126] | [What's Behind the Mask: Understanding Masked Graph Modeling for Graph Autoencoders.](http://arxiv.org/abs/2205.10053) | 本文探究了 Masked Graph Modeling 在图自编码器中的有效应用，并提出了基于蒙版的图建模（MGM）作为自监督学习的一个原先的任务，证明了它的优势作用。在获得了理论及实证证据的支持后，我们提出了 MaskGAE，一种可扩展有效的自监督学习方法。 |
| [^127] | [Do Vision-Language Pretrained Models Learn Composable Primitive Concepts?.](http://arxiv.org/abs/2203.17271) | 本文研究了视觉语言预训练模型是否自动产生原始概念的表示，提出组合概念映射（CompMap）框架来研究，认为如果模型确实产生了原始概念，其激活应符合先前人类对原始概念的观察结果。 |
| [^128] | [On-the-Fly Feature Based Rapid Speaker Adaptation for Dysarthric and Elderly Speech Recognition.](http://arxiv.org/abs/2203.14593) | 本文提出了两种新形式的数据有效、基于特征的动态说话者适应方法，能够显著提高言语障碍和老年人语音识别的准确率。 |
| [^129] | [The Interpretability of LSTM Models for Predicting Oil Company Stocks: impacts of correlated features.](http://arxiv.org/abs/2201.00350) | 研究探究了相关特征对用于预测石油公司股票的LSTM模型的可解释性的影响。结果表明，添加与石油股票相关的特征并不会提高LSTM模型的可解释性，因此应谨慎依靠LSTM模型进行股票市场决策。 |
| [^130] | [Learning to acquire novel cognitive tasks with evolution, plasticity and meta-meta-learning.](http://arxiv.org/abs/2112.08588) | 本文提出了一种使用进化、可塑性和元元学习方法来学习获取新的认知任务的方法，结果验证了其有效性。 |
| [^131] | [HeterPS: Distributed Deep Learning With Reinforcement Learning Based Scheduling in Heterogeneous Environments.](http://arxiv.org/abs/2111.10635) | 这篇论文介绍了一个名为Paddle-HeterPS的分布式框架，基于强化学习的调度方法可以高效地利用多种类型的计算资源，解决了分布式深度学习训练中多层次分配计算资源的问题。 |
| [^132] | [Fingerprinting Generative Adversarial Networks.](http://arxiv.org/abs/2106.11760) | 本文提出了一种保护GAN知识产权的指纹识别方案，通过生成指纹样本并嵌入到分类器中进行版权验证，解决了前一种对分类模型的指纹识别方法在简单转移至GAN时遇到的隐蔽性和鲁棒性瓶颈，具有实际保护现代GAN模型的可行性。 |
| [^133] | [Diverse Gaussian Noise Consistency Regularization for Robustness and Uncertainty Calibration.](http://arxiv.org/abs/2104.01231) | 本研究提出了一种多样化高斯噪声一致性正则化方法，用于同时提高图像分类器的鲁棒性和准确性，与其他强大的多样化数据增强基础相比，可以将鲁棒性提高4.2-18.4％以应对未预见的噪声污染。 |
| [^134] | [The Gradient Convergence Bound of Federated Multi-Agent Reinforcement Learning with Efficient Communication.](http://arxiv.org/abs/2103.13026) | 本文提出了两种优化策略, 一种是逐步衰减本地梯度权重的衰减模式, 另一种是基于代价最小化设计的共识算法来减少模型之间的通信量, 有效解决了独立学习环境异质性和联邦学习的通信开销问题。 |
| [^135] | [On the Nature and Types of Anomalies: A Review of Deviations in Data.](http://arxiv.org/abs/2007.15634) | 本文通过广泛文献综述，提供了第一个理论上基于原则且领域无关的数据异常分类法，并呈现了异常类型和子类型的全面概述。 |

# 详细

[^1]: 重新思考对抗策略：多智能体强化学习中的广义攻击形式和可证明的防御

    Rethinking Adversarial Policies: A Generalized Attack Formulation and Provable Defense in Multi-Agent RL. (arXiv:2305.17342v1 [cs.LG])

    [http://arxiv.org/abs/2305.17342](http://arxiv.org/abs/2305.17342)

    本文介绍了另一种常见、现实的多智能体RL攻击设置，提出了一种模拟攻击者对代理$\alpha$控制的更一般化攻击形式。并解决了先前攻击模型中缺乏可证明防御的问题。

    

    大多数现有的研究研究直接扰动受害者的状态/动作或基础转移动态以展示强化学习智能体在对抗攻击下的脆弱性。然而，这样的直接操纵在实践中并不总是可行的。在本文中，我们考虑另一种常见且现实的攻击设置：在经过训练的多智能体RL的设置中，在部署期间，受害代理$\nu$被攻击者控制另一个代理$\alpha$以敌对方式行动，使用“对抗策略”对受害代理进行攻击。尽管之前的攻击模型考虑了这种设置，但他们没有考虑到攻击者可以遇到抵抗，因此只能部分控制代理$\alpha$，同时引入可察觉的“异常”行为，这些行为很容易被检测到。并且缺乏针对这些对抗策略的可证明的防御。为了解决这些问题，我们引入了一个更一般化的攻击形式，模拟了攻击者在何种程度上可以控制代理$\alpha$。

    Most existing works consider direct perturbations of victim's state/action or the underlying transition dynamics to show vulnerability of reinforcement learning agents under adversarial attacks. However, such direct manipulation may not always be feasible in practice. In this paper, we consider another common and realistic attack setup: in a multi-agent RL setting with well-trained agents, during deployment time, the victim agent $\nu$ is exploited by an attacker who controls another agent $\alpha$ to act adversarially against the victim using an \textit{adversarial policy}. Prior attack models under such setup do not consider that the attacker can confront resistance and thus can only take partial control of the agent $\alpha$, as well as introducing perceivable ``abnormal'' behaviors that are easily detectable. A provable defense against these adversarial policies is also lacking. To resolve these issues, we introduce a more general attack formulation that models to what extent the a
    
[^2]: 水下船体检测的多标签视频分类

    Multi-label Video Classification for Underwater Ship Inspection. (arXiv:2305.17338v1 [cs.CV])

    [http://arxiv.org/abs/2305.17338](http://arxiv.org/abs/2305.17338)

    该文提出了一种使用深度学习和计算机视觉的自动化视频分析系统，在水下船体检测中实现多标签视频分类。该系统利用变换器的自我注意机制来捕获连续视频帧中的时空注意。

    

    今天，船体检测，包括外部涂层的检查，缺陷的检测以及其他类型的外部降解如腐蚀和海洋生长通过远程操作车（ROVs）在水下进行。检测过程包括对视频的手动分析，这是一个耗时且劳动密集的过程。为了解决这个问题，我们提出了一种使用深度学习和计算机视觉的自动化视频分析系统，以改进现有方法所仅考虑水下船体视频检测单个帧的空间信息的不足。通过探索添加时间信息和分析基于帧的分类器的优势，我们提出了一种多标签视频分类模型，利用变换器的自我注意机制来捕获连续视频帧中的时空注意。我们的提出的方法已经展现出有前途的结果，并可作为未来水下船体检验研究和发展的基准。

    Today ship hull inspection including the examination of the external coating, detection of defects, and other types of external degradation such as corrosion and marine growth is conducted underwater by means of Remotely Operated Vehicles (ROVs). The inspection process consists of a manual video analysis which is a time-consuming and labor-intensive process. To address this, we propose an automatic video analysis system using deep learning and computer vision to improve upon existing methods that only consider spatial information on individual frames in underwater ship hull video inspection. By exploring the benefits of adding temporal information and analyzing frame-based classifiers, we propose a multi-label video classification model that exploits the self-attention mechanism of transformers to capture spatiotemporal attention in consecutive video frames. Our proposed method has demonstrated promising results and can serve as a benchmark for future research and development in underw
    
[^3]: 用生成模型进行多模态实体链接的基准测试

    Benchmarking Diverse-Modal Entity Linking with Generative Models. (arXiv:2305.17337v1 [cs.CL])

    [http://arxiv.org/abs/2305.17337](http://arxiv.org/abs/2305.17337)

    新方法提出了一个多模态实体链接的基准测试，并使用预训练的生成多模态模型，在平均F1分数上优于最先进的特定任务EL模型8.51分。

    

    实体可以用不同的格式来表达，如文本、图像或表格中的列名和单元格值。虽然现有的实体链接（EL）模型在每种模式配置上都表现出色，例如仅文本EL、视觉定位或模式链接，但为多种模式配置设计统一模型更具挑战性。为了将各种模态配置结合起来，我们从现有EL数据集构建了一个包含文本、图像和表格三种模态的多模态EL（DMEL）基准测试。为了解决DMEL任务，我们提出了一个生成多模态模型（GDMM），遵循多模态编码器-解码器范例。将\Model用丰富的语料库预训练可以在不保存整个KB进行推理的情况下为DMEL构建坚实的基础。微调GDMM可以构建更强大的DMEL基线，在平均F1分数上优于最先进的特定任务EL模型8.51分。此外，进行了广泛的错误分析，突出了将多模态实体翻译和所提出方法的优势所在。

    Entities can be expressed in diverse formats, such as texts, images, or column names and cell values in tables. While existing entity linking (EL) models work well on per modality configuration, such as text-only EL, visual grounding, or schema linking, it is more challenging to design a unified model for diverse modality configurations. To bring various modality configurations together, we constructed a benchmark for diverse-modal EL (DMEL) from existing EL datasets, covering all three modalities including text, image, and table. To approach the DMEL task, we proposed a generative diverse-modal model (GDMM) following a multimodal-encoder-decoder paradigm. Pre-training \Model with rich corpora builds a solid foundation for DMEL without storing the entire KB for inference. Fine-tuning GDMM builds a stronger DMEL baseline, outperforming state-of-the-art task-specific EL models by 8.51 F1 score on average. Additionally, extensive error analyses are conducted to highlight the challenges of
    
[^4]: MADiff：离线多智能体学习与扩散模型

    MADiff: Offline Multi-agent Learning with Diffusion Models. (arXiv:2305.17330v1 [cs.AI])

    [http://arxiv.org/abs/2305.17330](http://arxiv.org/abs/2305.17330)

    本论文提出了基于注意力的扩散模型MADiff，解决了多智能体问题，是第一个扩散模型应用于多智能体离线RL的框架。

    

    扩散模型（DM）是一种强大的生成模型，最近在包括离线强化学习在内的各种场景中取得了巨大成功，其中策略通过在在线评估中产生轨迹来进行规划学习。然而，尽管单智能体学习显示了其有效性，但仍不清楚DM如何在多智能体问题中操作，其中代理商很难在独立建模每个代理商轨迹的情况下完成团队合作。在本文中，我们提出MADiff，一种新的生成式多智能体学习框架，以解决这个问题。MADiff是通过基于注意力的扩散模型来实现对多个扩散智能体行为的复杂协调建模。据我们所知，MADiff是第一个基于扩散的多智能体离线RL框架，它既可以行为为分散的政策，又可以为集中控制器，其中包括对手建模，并可用于多智能体轨迹预测。

    Diffusion model (DM), as a powerful generative model, recently achieved huge success in various scenarios including offline reinforcement learning, where the policy learns to conduct planning by generating trajectory in the online evaluation. However, despite the effectiveness shown for single-agent learning, it remains unclear how DMs can operate in multi-agent problems, where agents can hardly complete teamwork without good coordination by independently modeling each agent's trajectories. In this paper, we propose MADiff, a novel generative multi-agent learning framework to tackle this problem. MADiff is realized with an attention-based diffusion model to model the complex coordination among behaviors of multiple diffusion agents. To the best of our knowledge, MADiff is the first diffusion-based multi-agent offline RL framework, which behaves as both a decentralized policy and a centralized controller, which includes opponent modeling and can be used for multi-agent trajectory predic
    
[^5]: 《Zero-TPrune: 基于预训练Transformers关注图的零射击令牌剪枝方法》

    Zero-TPrune: Zero-Shot Token Pruning through Leveraging of the Attention Graph in Pre-Trained Transformers. (arXiv:2305.17328v1 [cs.CV])

    [http://arxiv.org/abs/2305.17328](http://arxiv.org/abs/2305.17328)

    《Zero-TPrune》是一个考虑到令牌的重要性和相似性的零射击方法，它利用预训练Transformer模型的注意图来进行令牌剪枝，以求解在边缘设备上Transformer模型即插即用的难题。

    

    最近在边缘设备上部署Transformer模型变得越来越具有挑战性，原因是模型的体积呈指数级增长，而推理成本则随输入序列中令牌数量的平方提高。令牌剪枝是解决这一挑战的新兴解决方法之一，由于其易于在各种Transformer支持的模型上部署。然而，大多数令牌剪枝方法需要在剪枝后或期间进行计算密集型的微调过程，在许多情况下这是不可取的。最近的一些研究探讨了没有微调的即插即用的预训练Transformer的剪枝方法。但是，它们只考虑了令牌的重要性。在这项工作中，我们提出了Zero-TPrune，这是一种零射击方法，它既考虑令牌的重要性又考虑相似性来执行令牌剪枝。Zero-TPrune利用预训练Transformer模型的注意图来为令牌生成一个重要性排名并移除信息较少的令牌。注意矩阵可用于推断即插即用的模型。

    Deployment of Transformer models on the edge is increasingly challenging due to the exponentially growing model size and inference cost that scales quadratically with the number of tokens in the input sequence. Token pruning is an emerging solution to address this challenge due to its ease of deployment on various Transformer backbones. However, most token pruning methods require a computationally-expensive fine-tuning process after or during pruning, which is not desirable in many cases. Some recent works explore pruning of off-the-shelf pre-trained Transformers without fine-tuning. However, they only take the importance of tokens into consideration. In this work, we propose Zero-TPrune, the first zero-shot method that considers both the importance and similarity of tokens in performing token pruning. Zero-TPrune leverages the attention graph of pre-trained Transformer models to produce an importance rank for tokens and removes the less informative tokens. The attention matrix can be 
    
[^6]: 基于内核KL散度的自监督学习方法Kernel-SSL

    Kernel-SSL: Kernel KL Divergence for Self-supervised Learning. (arXiv:2305.17326v1 [cs.LG])

    [http://arxiv.org/abs/2305.17326](http://arxiv.org/abs/2305.17326)

    本文提出了一种名为Kernel-SSL的自监督学习方法，将多种现有非对比学习方法建立在了再生核希尔伯特空间（RKHS）理解之上并优化了其中的均值嵌入和协方差算子，实验结果显示，在ImageNet数据集下表现显著超越最先进的方法，提高了4.6%。

    

    对比学习通常将一个正锚点样本与许多负样本进行比较，来完成自监督学习（SSL）。相反，非对比学习，例如BYOL、SimSiam和Barlow Twins等方法，在没有显式使用负样本的情况下完成SSL。受对比学习现有分析的启发，我们提供了多种现有非对比学习方法的再生核希尔伯特空间（RKHS）理解。随后，我们提出了一种新的损失函数Kernel-SSL，直接优化RKHS中的均值嵌入和协方差算子。实验中，我们的方法Kernel-SSL在线性评估设置下在ImageNet数据集上大幅优于最先进的方法。具体来说，在进行100个epoch的预训练时，我们的方法比SimCLR表现提高了4.6%。

    Contrastive learning usually compares one positive anchor sample with lots of negative samples to perform Self-Supervised Learning (SSL). Alternatively, non-contrastive learning, as exemplified by methods like BYOL, SimSiam, and Barlow Twins, accomplishes SSL without the explicit use of negative samples. Inspired by the existing analysis for contrastive learning, we provide a reproducing kernel Hilbert space (RKHS) understanding of many existing non-contrastive learning methods. Subsequently, we propose a novel loss function, Kernel-SSL, which directly optimizes the mean embedding and the covariance operator within the RKHS. In experiments, our method Kernel-SSL outperforms state-of-the-art methods by a large margin on ImageNet datasets under the linear evaluation settings. Specifically, when performing 100 epochs pre-training, our method outperforms SimCLR by 4.6%.
    
[^7]: 道德机器还是多数派的暴政?

    Moral Machine or Tyranny of the Majority?. (arXiv:2305.17319v1 [cs.CY])

    [http://arxiv.org/abs/2305.17319](http://arxiv.org/abs/2305.17319)

    本文研究了道德机器项目中提出的线性模型聚合机制的公平性问题，特别关注在存在策略影响的情况下少数群体是否会获胜的比例。

    

    随着人工智能系统越来越广泛地应用于重要领域，研究人员开始询问这些系统在伦理上具有争议的情况下应该如何行动，即在这种情况下连人类本身也没有一致共识。在道德机器项目中，研究员们众包回答了关于自主车辆的"拦车"问题。随后，Noothigattu等人(2018)提出了推断线性函数来近似每个个体的偏好，并通过对整个人群的参数取平均值来聚合这些线性模型。本文主要研究了这种平均机制，在存在策略效应的公平性问题方面进行了重点讨论。我们研究了一个简单的情况，其中人口分为两组，少数派的α <0.5。为简化分析，我们考虑了群体内偏好是同质的极端情况。我们聚焦于少数群体获胜的有争议情况的比例，进行分析研究。

    With Artificial Intelligence systems increasingly applied in consequential domains, researchers have begun to ask how these systems ought to act in ethically charged situations where even humans lack consensus. In the Moral Machine project, researchers crowdsourced answers to "Trolley Problems" concerning autonomous vehicles. Subsequently, Noothigattu et al. (2018) proposed inferring linear functions that approximate each individual's preferences and aggregating these linear models by averaging parameters across the population. In this paper, we examine this averaging mechanism, focusing on fairness concerns in the presence of strategic effects. We investigate a simple setting where the population consists of two groups, with the minority constituting an {\alpha} < 0.5 share of the population. To simplify the analysis, we consider the extreme case in which within-group preferences are homogeneous. Focusing on the fraction of contested cases where the minority group prevails, we make th
    
[^8]: 雷达照亮黑暗：通过相机-雷达融合增强自动驾驶车辆的低能见度感知

    Radar Enlighten the Dark: Enhancing Low-Visibility Perception for Automated Vehicles with Camera-Radar Fusion. (arXiv:2305.17318v1 [cs.CV])

    [http://arxiv.org/abs/2305.17318](http://arxiv.org/abs/2305.17318)

    针对低能见度的自动驾驶车辆感知问题，本文提出了一种新的基于Transformer的3D目标检测模型“REDFormer”，通过鸟瞰相机-雷达融合进行实现。该模型在nuScenes数据集上表现出优异的分类和检测准确性，且相较于现有模型更经济实用。

    

    传感器融合是一种关键的增强技术，用于在不同的驾驶条件下提高自动驾驶车辆感知系统的准确性和可靠性。然而，恶劣的天气和低光照条件仍然是一个挑战，在这些条件下，传感器性能会显著下降，从而使车辆安全面临潜在风险。本文提出了一种新颖的基于Transformer的3D目标检测模型“REDFormer”，利用鸟瞰相机-雷达融合的便利和经济实用性来解决低能见度问题。在使用多雷达点云、天气信息和时间数据的nuScenes数据集上，我们的模型在分类和检测准确性方面优于最先进的模型。最后，我们对每个模型组件进行了广泛的消融研究，以了解它们对应对上述问题的贡献。

    Sensor fusion is a crucial augmentation technique for improving the accuracy and reliability of perception systems for automated vehicles under diverse driving conditions. However, adverse weather and low-light conditions remain challenging, where sensor performance degrades significantly, exposing vehicle safety to potential risks. Advanced sensors such as LiDARs can help mitigate the issue but with extremely high marginal costs. In this paper, we propose a novel transformer-based 3D object detection model "REDFormer" to tackle low visibility conditions, exploiting the power of a more practical and cost-effective solution by leveraging bird's-eye-view camera-radar fusion. Using the nuScenes dataset with multi-radar point clouds, weather information, and time-of-day data, our model outperforms state-of-the-art (SOTA) models on classification and detection accuracy. Finally, we provide extensive ablation studies of each model component on their contributions to address the above-mention
    
[^9]: 超越正向缩放：否定语对语言模型缩放趋势的影响。

    Beyond Positive Scaling: How Negation Impacts Scaling Trends of Language Models. (arXiv:2305.17311v1 [cs.CL])

    [http://arxiv.org/abs/2305.17311](http://arxiv.org/abs/2305.17311)

    本研究介绍了一个包含否定问题的数据集NeQA，其中语言模型表现出反向缩放、U型缩放或正向缩放，解决NeQA依赖于问答和否定理解两个子任务，其缩放趋势由这两个子任务的缩放趋势组合形成。

    

    已经证明，语言模型表现出正向缩放，在大小、计算或数据方面扩展模型会提高性能。在本研究中，我们引入了一个包含否定问句的数据集NeQA，其中语言模型不会表现出简单的正向缩放。我们展示了这个任务可以表现出反向缩放、U形缩放或正向缩放，并且在使用更强大的提示方法或模型族群时，这三种缩放趋势会按照这个顺序发生转变。我们假设解决NeQA依赖于两个子任务：问答（任务1）和否定理解（任务2）。我们发现任务1具有线性缩放，而任务2具有S形缩放，并具有一个紧急的转折点，将这两个缩放趋势组合起来即可得出最终的NeQA缩放趋势。我们的研究揭示并提供了一种分析语言模型复杂缩放趋势的方法。

    Language models have been shown to exhibit positive scaling, where performance improves as models are scaled up in terms of size, compute, or data. In this work, we introduce NeQA, a dataset consisting of questions with negation in which language models do not exhibit straightforward positive scaling. We show that this task can exhibit inverse scaling, U-shaped scaling, or positive scaling, and the three scaling trends shift in this order as we use more powerful prompting methods or model families. We hypothesize that solving NeQA depends on two subtasks: question answering (task 1) and negation understanding (task 2). We find that task 1 has linear scaling, while task 2 has sigmoid-shaped scaling with an emergent transition point, and composing these two scaling trends yields the final scaling trend of NeQA. Our work reveals and provides a way to analyze the complex scaling trends of language models.
    
[^10]: 朝着认知机器人：架构研究挑战

    Towards Cognitive Bots: Architectural Research Challenges. (arXiv:2305.17308v1 [cs.AI])

    [http://arxiv.org/abs/2305.17308](http://arxiv.org/abs/2305.17308)

    研究呈现了在多个数字平台上运行的认知机器人的架构挑战，这些机器人需要具备适应性和认知能力，以适应平台的不同特性和与人类/软件代理的合作。

    

    在多个虚拟数字平台上运行的软件机器人必须理解平台的功能并像人类用户一样行事。平台的功能或特点因应用平台或生命周期而异，因此需要这些机器人具备适应性。此外，这些平台上的机器人可以与人类或其他软件代理合作工作或学习特定的行为模式。然而，除了语言处理和预测之外，现今的机器人，特别是聊天机器人，远未达到复杂商业信息系统内的人类用户行为水平。它们缺乏在这种虚拟环境中感知和行动的认知能力，使得它们的开发成为人工智能研究中的挑战。在这项研究中，我们提出问题并研究了构思软件机器人架构的假设，针对开发具有复杂认知能力的机器人的显著架构研究挑战进行了调查。

    Software bots operating in multiple virtual digital platforms must understand the platforms' affordances and behave like human users. Platform affordances or features differ from one application platform to another or through a life cycle, requiring such bots to be adaptable. Moreover, bots in such platforms could cooperate with humans or other software agents for work or to learn specific behavior patterns. However, present-day bots, particularly chatbots, other than language processing and prediction, are far from reaching a human user's behavior level within complex business information systems. They lack the cognitive capabilities to sense and act in such virtual environments, rendering their development a challenge to artificial general intelligence research. In this study, we problematize and investigate assumptions in conceptualizing software bot architecture by directing attention to significant architectural research challenges in developing cognitive bots endowed with complex
    
[^11]: “Chain-of-Thought Hub: 连续测量大型语言模型推理表现的努力”

    Chain-of-Thought Hub: A Continuous Effort to Measure Large Language Models' Reasoning Performance. (arXiv:2305.17306v1 [cs.CL])

    [http://arxiv.org/abs/2305.17306](http://arxiv.org/abs/2305.17306)

    本文介绍了一个名为 Chain-of-Thought Hub 的开源评估套件，目的是评估大型语言模型的多步推理能力。它是为了追踪LLMs进展而编制的具有挑战性的推理基准。目前的研究结果表明，模型规模与推理能力相关，而 Claude-v1.3 是迄今为止推理能力最强的LLM。

    

    “随着大型语言模型（LLMs）的不断发展，它们的评估变得越来越重要但也更具挑战性。本文提出了 Chain-of-Thought Hub，这是一个开源的评估套件，旨在评估大型语言模型的多步推理能力。我们之所以对这个设置感兴趣，是因为 (1) 从 GPT 和 PaLM 模型家族的行为中，我们观察到复杂的推理很可能是一个更弱和更强的LLMs之间的关键区别； (2) 我们预见大型语言模型将成为下一代计算平台，并促进基于LLM的新应用的生态系统，这自然需要基础模型执行常常涉及语言和逻辑操作组合的复杂任务。我们的方法是编制一系列具有挑战性的推理基准，以跟踪LLMs的进展。我们目前的结果表明：(1) 模型规模显然与推理能力相关；(2) 截至2023年5月，Claude-v1.3 是迄今为止推理能力最强的LLM 。”

    As large language models (LLMs) are continuously being developed, their evaluation becomes increasingly important yet challenging. This work proposes Chain-of-Thought Hub, an open-source evaluation suite on the multi-step reasoning capabilities of large language models. We are interested in this setting for two reasons: (1) from the behavior of GPT and PaLM model family, we observe that complex reasoning is likely to be a key differentiator between weaker and stronger LLMs; (2) we envisage large language models to become the next-generation computational platform and foster an ecosystem of LLM-based new applications, this naturally requires the foundation models to perform complex tasks that often involve the composition of linguistic and logical operations. Our approach is to compile a suite of challenging reasoning benchmarks to track the progress of LLMs. Our current results show that: (1) model scale clearly correlates with reasoning capabilities; (2) As of May 2023, Claude-v1.3 an
    
[^12]: 利用大型神经影像数据集创造连接组限制方法，以实现更强大、更高效、更适应性强人工智能

    Exploiting Large Neuroimaging Datasets to Create Connectome-Constrained Approaches for more Robust, Efficient, and Adaptable Artificial Intelligence. (arXiv:2305.17300v1 [cs.NE])

    [http://arxiv.org/abs/2305.17300](http://arxiv.org/abs/2305.17300)

    该论文讨论了如何利用大型神经影像数据集改进机器学习方法，以创造更加稳健、高效和适应性强的人工智能。通过发现重复子电路和分析果蝇的航向方向电路，该论文提出了新的连接模式和模型，以探索如何进一步扩展现有的计算模型。

    

    尽管深度学习网络取得了进展，但边缘上的高效学习（实现适应性强、低复杂度的机器学习解决方案）仍然是国防和商业应用的关键需求。我们构想了使用大型神经影像数据集，包括捕获神经元和突触连接的大脑地图，来改善机器学习方法的流程。我们在该流程结构内追求了不同的方法。

    Despite the progress in deep learning networks, efficient learning at the edge (enabling adaptable, low-complexity machine learning solutions) remains a critical need for defense and commercial applications. We envision a pipeline to utilize large neuroimaging datasets, including maps of the brain which capture neuron and synapse connectivity, to improve machine learning approaches. We have pursued different approaches within this pipeline structure. First, as a demonstration of data-driven discovery, the team has developed a technique for discovery of repeated subcircuits, or motifs. These were incorporated into a neural architecture search approach to evolve network architectures. Second, we have conducted analysis of the heading direction circuit in the fruit fly, which performs fusion of visual and angular velocity features, to explore augmenting existing computational models with new insight. Our team discovered a novel pattern of connectivity, implemented a new model, and demonst
    
[^13]: 提高决策树模型的稳定性

    Improving Stability in Decision Tree Models. (arXiv:2305.17299v1 [stat.ML])

    [http://arxiv.org/abs/2305.17299](http://arxiv.org/abs/2305.17299)

    本文通过医疗应用的视角，提出了一种新的决策树距离度量，并用它来确定树的稳定水平。我们提出了一种新的培训稳定决策树的方法，并探究稳定性、预测能力和可解释性之间不可避免的权衡。

    

    由于其结构易于理解，决策树通常在需要可解释性的应用中被广泛使用。近期的工作集中于改进决策树的各个方面，包括预测能力和鲁棒性；然而，其不稳定性虽然有充分的记录，但却得到了较少的关注。本文通过实际的医疗应用的视角，提出了稳定化决策树模型的一小步。由于稳定性和可解释性在医疗领域具有重要性，我们介绍了一种新的决策树距离度量，并将其用于确定树的稳定水平。我们提出了一种新的培训稳定决策树的方法，并调查了决策树模型之间不可避免的权衡，包括在稳定性、预测能力和可解释性之间。我们通过对六个数据集的广泛定量和定性分析展示了所提议方法的价值。

    Owing to their inherently interpretable structure, decision trees are commonly used in applications where interpretability is essential. Recent work has focused on improving various aspects of decision trees, including their predictive power and robustness; however, their instability, albeit well-documented, has been addressed to a lesser extent. In this paper, we take a step towards the stabilization of decision tree models through the lens of real-world health care applications due to the relevance of stability and interpretability in this space. We introduce a new distance metric for decision trees and use it to determine a tree's level of stability. We propose a novel methodology to train stable decision trees and investigate the existence of trade-offs that are inherent to decision tree models - including between stability, predictive power, and interpretability. We demonstrate the value of the proposed methodology through an extensive quantitative and qualitative analysis of six 
    
[^14]: 不确定非凸环境中的凸风险有界连续时间轨迹规划和管道设计

    Convex Risk Bounded Continuous-Time Trajectory Planning and Tube Design in Uncertain Nonconvex Environments. (arXiv:2305.17291v1 [cs.AI])

    [http://arxiv.org/abs/2305.17291](http://arxiv.org/abs/2305.17291)

    本文提出一种针对含有不确定性障碍物的非凸环境中的轨迹规划问题的解决方案，即通过风险轮廓的概念将风险有界轨迹规划问题转化为确定性优化问题。

    

    本文针对含有具有概率位置、大小和几何形状的障碍物的不确定非凸静态和动态环境中的轨迹规划问题进行了研究。为了解决这个问题，我们提供了一种带有有界风险的轨迹规划方法，该方法寻找规划时间范围内保证有界风险的连续时间轨迹。风险被定义为与不确定障碍物碰撞的概率。现有的解决风险有界轨迹规划问题的方法要么仅限于高斯不确定性和凸障碍物，要么依赖于需要不确定性样本和时间离散化的基于采样的方法。为了解决风险有界轨迹规划问题，我们利用风险轮廓的概念将风险有界轨迹规划问题转化为确定性优化问题。风险轮廓是在不确定环境中所有具有保证有界风险的点的集合。

    In this paper, we address the trajectory planning problem in uncertain nonconvex static and dynamic environments that contain obstacles with probabilistic location, size, and geometry. To address this problem, we provide a risk bounded trajectory planning method that looks for continuous-time trajectories with guaranteed bounded risk over the planning time horizon. Risk is defined as the probability of collision with uncertain obstacles. Existing approaches to address risk bounded trajectory planning problems either are limited to Gaussian uncertainties and convex obstacles or rely on sampling-based methods that need uncertainty samples and time discretization. To address the risk bounded trajectory planning problem, we leverage the notion of risk contours to transform the risk bounded planning problem into a deterministic optimization problem. Risk contours are the set of all points in the uncertain environment with guaranteed bounded risk. The obtained deterministic optimization is, 
    
[^15]: 滑动、约束、解析、重复：适用于文档 AMR 解析的同步滑动窗口方法

    Slide, Constrain, Parse, Repeat: Synchronous SlidingWindows for Document AMR Parsing. (arXiv:2305.17273v1 [cs.CL])

    [http://arxiv.org/abs/2305.17273](http://arxiv.org/abs/2305.17273)

    本文提出了一种同步滑动窗口的方法来处理文档解析的序列到序列任务，利用源-目标对齐并约束解码以保证重叠窗口的同步性和一致性，在AMR 3.0的评估中展示出了高质量的性能。

    

    滑动窗口方法提供了一种处理超过Transformer输入窗口大小的上下文的优美方式，例如处理语言建模任务。本文将这种方法扩展到文档解析的序列到序列任务中。为此，我们利用了转移句法分析的最新进展，通过在源和目标之间实现同步滑动窗口来实现解析器。我们通过在机构化BART上扩展来开发文档级AMR的oracle和解析器，以利用源-目标对齐并约束解码以保证重叠窗口的同步性和一致性。我们使用抽象意义表示（AMR）3.0语料库评估了我们的oracle和解析器。在AMR 3.0的多句子开发集上，我们展示了我们的转移oracle仅丢失了8％的金句际链接，尽管使用滑动窗口。在实践中，这种方法也产生了一个具有可管理内存要求的高质量文档级解析器。

    The sliding window approach provides an elegant way to handle contexts of sizes larger than the Transformer's input window, for tasks like language modeling. Here we extend this approach to the sequence-to-sequence task of document parsing. For this, we exploit recent progress in transition-based parsing to implement a parser with synchronous sliding windows over source and target. We develop an oracle and a parser for document-level AMR by expanding on Structured-BART such that it leverages source-target alignments and constrains decoding to guarantee synchronicity and consistency across overlapping windows. We evaluate our oracle and parser using the Abstract Meaning Representation (AMR) parsing 3.0 corpus. On the Multi-Sentence development set of AMR 3.0, we show that our transition oracle loses only 8\% of the gold cross-sentential links despite using a sliding window. In practice, this approach also results in a high-quality document-level parser with manageable memory requirement
    
[^16]: 通过自预训练掩模序列自编码器和使用定制PolyLoss微调的方法实现鲁棒车道检测

    Robust Lane Detection through Self Pre-training with Masked Sequential Autoencoders and Fine-tuning with Customized PolyLoss. (arXiv:2305.17271v1 [cs.CV])

    [http://arxiv.org/abs/2305.17271](http://arxiv.org/abs/2305.17271)

    本论文提出了一种鲁棒车道检测流水线，该流水线包括自预训练掩模序列自编码器和使用定制PolyLoss微调的端到端神经网络模型。掩模序列自编码器被采用以通过重构随机掩膜图像中的丢失像素为目标来预训练神经网络模型，提升了车道检测性能。

    

    车道检测是车辆定位的关键，是实现自动驾驶和许多智能高级驾驶辅助系统的基础。现有的基于视觉的车道检测方法未充分利用有价值的特征和聚合的上下文信息，尤其是车道线和图像中其他区域之间的相互关系。为填补这一研究空白并提升车道检测性能，本文提出了一种流水线，其中包括使用自预训练掩模序列自编码器和使用定制PolyLoss微调的端到端神经网络模型。掩模序列自编码器被采用以通过重构随机掩模图像中的丢失像素为目标来预训练神经网络模型。然后，在细调分割阶段中，连续的图像帧被用作输入，

    Lane detection is crucial for vehicle localization which makes it the foundation for automated driving and many intelligent and advanced driving assistant systems. Available vision-based lane detection methods do not make full use of the valuable features and aggregate contextual information, especially the interrelationships between lane lines and other regions of the images in continuous frames. To fill this research gap and upgrade lane detection performance, this paper proposes a pipeline consisting of self pre-training with masked sequential autoencoders and fine-tuning with customized PolyLoss for the end-to-end neural network models using multi-continuous image frames. The masked sequential autoencoders are adopted to pre-train the neural network models with reconstructing the missing pixels from a random masked image as the objective. Then, in the fine-tuning segmentation phase where lane detection segmentation is performed, the continuous image frames are served as the inputs,
    
[^17]: Im-Promptu: 从图像提示进行上下文组合

    Im-Promptu: In-Context Composition from Image Prompts. (arXiv:2305.17262v1 [cs.CV])

    [http://arxiv.org/abs/2305.17262](http://arxiv.org/abs/2305.17262)

    本文研究了类比推理能否实现对可组合视觉刺激成分的上下文内组合，通过引入三个基准测试套件，提供了设计类比推理的元学习框架 Im-Promptu。使用 Im-Promptu 可以训练多个具有不同组合水平的代理，包括矢量表示、补丁表示和物体槽。

    

    大规模语言模型是少样本学习者，可以从少量演示中解决各种任务。这种隐含的任务理解表明，单词令牌上的注意力机制可能在类比推理中发挥作用。本文研究类比推理是否能实现对可组合视觉刺激成分的上下文内组合。首先，我们引入了三个基准测试套件，以测试视觉上下文学习器的泛化属性。我们规范化了基于类比的上下文学习器的概念，并用它来设计一个元学习框架称为 Im-Promptu。虽然语言的所需令牌粒度已经得到了充分证实，但用于实现视觉刺激内上下文泛化的适当组合粒度通常未经指定。为此，我们使用 Im-Promptu 训练多个具有不同组合水平的代理，包括矢量表示、补丁表示和物体槽。

    Large language models are few-shot learners that can solve diverse tasks from a handful of demonstrations. This implicit understanding of tasks suggests that the attention mechanisms over word tokens may play a role in analogical reasoning. In this work, we investigate whether analogical reasoning can enable in-context composition over composable elements of visual stimuli. First, we introduce a suite of three benchmarks to test the generalization properties of a visual in-context learner. We formalize the notion of an analogy-based in-context learner and use it to design a meta-learning framework called Im-Promptu. Whereas the requisite token granularity for language is well established, the appropriate compositional granularity for enabling in-context generalization in visual stimuli is usually unspecified. To this end, we use Im-Promptu to train multiple agents with different levels of compositionality, including vector representations, patch representations, and object slots. Our e
    
[^18]: STL：用于系统验证的令人惊讶的棘手逻辑

    STL: Surprisingly Tricky Logic (for System Validation). (arXiv:2305.17258v1 [cs.AI])

    [http://arxiv.org/abs/2305.17258](http://arxiv.org/abs/2305.17258)

    本文通过人类实验研究了形式规范是否可被人理解和用于检查系统，并发现说明有效性、被试熟悉度和教育水平是影响验证正确性的关键因素，参与者存在确认偏差。

    

    近年来，发展形式化方法技术以指定或学习自主系统行为的大部分工作都基于这样一种信念，即形式化说明对于检查系统时人类是可解释和有用的。尽管这种假设经常被断言，但很少被测试。我们进行了一项人类实验（N = 62），混合了之前熟悉形式化方法以及不熟悉形式化方法的人，要求他们验证一组STL约束是否能让一个代理人在网格世界的旗帜争夺环境中避免危险并完成任务。验证准确度为$45\%\pm20\%$（平均$\pm$标准偏差）。事实上的说明有效性、被试熟悉形式化方法的程度以及被试的教育水平是决定验证正确性的重要因素。参与者表现出确认偏差，从而导致对有效说明的准确性显著提高，而对无效说明的准确性则显著降低。

    Much of the recent work developing formal methods techniques to specify or learn the behavior of autonomous systems is predicated on a belief that formal specifications are interpretable and useful for humans when checking systems. Though frequently asserted, this assumption is rarely tested. We performed a human experiment (N = 62) with a mix of people who were and were not familiar with formal methods beforehand, asking them to validate whether a set of signal temporal logic (STL) constraints would keep an agent out of harm and allow it to complete a task in a gridworld capture-the-flag setting. Validation accuracy was $45\% \pm 20\%$ (mean $\pm$ standard deviation). The ground-truth validity of a specification, subjects' familiarity with formal methods, and subjects' level of education were found to be significant factors in determining validation correctness. Participants exhibited an affirmation bias, causing significantly increased accuracy on valid specifications, but significan
    
[^19]: 大型语言模型可能是懒惰的学习者：分析上下文学习中的捷径

    Large Language Models Can be Lazy Learners: Analyze Shortcuts in In-Context Learning. (arXiv:2305.17256v1 [cs.CL])

    [http://arxiv.org/abs/2305.17256](http://arxiv.org/abs/2305.17256)

    本文探讨了大型语言模型在上下文学习中利用提示中的捷径的依赖性，发现大型模型更有可能在推理过程中利用提示中的捷径，这为评估上下文学习的稳健性和检测和缓解提示中捷径的使用提供了新的视角和挑战。

    

    最近，大型语言模型（LLM）在上下文学习中展现出巨大潜力，其中LLM通过几个输入-标签对（提示）的条件来学习新任务。尽管其潜力巨大，但我们对影响最终任务性能和上下文学习稳健性的因素的理解仍然有限。本文旨在通过研究LLM对提示内捷径或假相关的依赖关系来弥补这一知识差距。通过分类和抽取任务的全面实验，我们揭示了LLM是“懒惰学习者”的事实，它往往利用提示中的捷径来获取下游任务的性能提升。此外，我们还发现一个令人惊讶的发现，即较大的模型更有可能在推理过程中利用提示中的捷径。我们的发现为评估上下文学习的稳健性和检测和缓解提示中捷径的使用提供了新的视角和挑战。

    Large language models (LLMs) have recently shown great potential for in-context learning, where LLMs learn a new task simply by conditioning on a few input-label pairs (prompts). Despite their potential, our understanding of the factors influencing end-task performance and the robustness of in-context learning remains limited. This paper aims to bridge this knowledge gap by investigating the reliance of LLMs on shortcuts or spurious correlations within prompts. Through comprehensive experiments on classification and extraction tasks, we reveal that LLMs are "lazy learners" that tend to exploit shortcuts in prompts for downstream tasks. Additionally, we uncover a surprising finding that larger models are more likely to utilize shortcuts in prompts during inference. Our findings provide a new perspective on evaluating robustness in in-context learning and pose new challenges for detecting and mitigating the use of shortcuts in prompts.
    
[^20]: 基于随机特征的自监督增强学习实现迁移

    Self-Supervised Reinforcement Learning that Transfers using Random Features. (arXiv:2305.17250v1 [cs.LG])

    [http://arxiv.org/abs/2305.17250](http://arxiv.org/abs/2305.17250)

    该论文提出了一种自监督增强学习方法，能够在不同奖励的任务间进行行为迁移，同时避免有模型强化学习的挑战。使用一些随机特征作为奖励，进行自监督预训练能够暗含长期环境动态模型，然后使用这些隐式模型的规划技术能够在短时间内适应问题。

    

    无模型强化学习算法在解决具有高维观测和长期决策方案的单任务顺序决策问题方面表现出巨大潜力，但难以横跨任务进行泛化。相比之下，有模型强化学习则学习与任务无关的世界模型，自然地实现了不同奖励函数的迁移，但由于误差的累积而难以适应复杂的环境。为了实现两者兼顾，我们提出了一种自监督增强学习方法，能够实现在具有不同奖励的任务间进行行为迁移，同时避开有模型强化学习的挑战。特别地，我们展示了模型自由强化学习的自监督预训练，用一些随机特征作为奖励，能够暗含长期环境动态模型。然后，使用这些隐式模型的规划技术（如模型预测控制）能够在短时间内适应问题。

    Model-free reinforcement learning algorithms have exhibited great potential in solving single-task sequential decision-making problems with high-dimensional observations and long horizons, but are known to be hard to generalize across tasks. Model-based RL, on the other hand, learns task-agnostic models of the world that naturally enables transfer across different reward functions, but struggles to scale to complex environments due to the compounding error. To get the best of both worlds, we propose a self-supervised reinforcement learning method that enables the transfer of behaviors across tasks with different rewards, while circumventing the challenges of model-based RL. In particular, we show self-supervised pre-training of model-free reinforcement learning with a number of random features as rewards allows implicit modeling of long-horizon environment dynamics. Then, planning techniques like model-predictive control using these implicit models enable fast adaptation to problems wi
    
[^21]: COMCAT：高效压缩和自定义注意力视觉模型

    COMCAT: Towards Efficient Compression and Customization of Attention-Based Vision Models. (arXiv:2305.17235v1 [cs.CV])

    [http://arxiv.org/abs/2305.17235](http://arxiv.org/abs/2305.17235)

    本文提出了一种高效的 Vision Transformer 压缩方法，在多头注意力层上进行了新的探究，相比当前最先进的剪枝方法表现更优，能够在使用更少参数的情况下提高模型精度。

    

    基于注意力机制的视觉模型，例如Vision Transformer（ViT）及其变体，在各种计算机视觉任务中表现出有希望的性能。然而，这些新兴的架构存在着模型尺寸大和高计算成本的问题，需要高效的模型压缩解决方案。本文探究了一种高效的压缩方法，以丰富获取紧凑的基于注意力机制的视觉模型的工具集。基于对多头注意力层的新见解，我们开发出了一种高效的ViT压缩解决方案，其表现优于最先进的剪枝方法。在ImageNet上对DeiT-small和DeiT-base模型进行压缩，我们的提议方法即使使用更少的参数，仍然能够实现比现有方法高0.45％和0.76％的top-1精度。

    Attention-based vision models, such as Vision Transformer (ViT) and its variants, have shown promising performance in various computer vision tasks. However, these emerging architectures suffer from large model sizes and high computational costs, calling for efficient model compression solutions. To date, pruning ViTs has been well studied, while other compression strategies that have been widely applied in CNN compression, e.g., model factorization, is little explored in the context of ViT compression. This paper explores an efficient method for compressing vision transformers to enrich the toolset for obtaining compact attention-based vision models. Based on the new insight on the multi-head attention layer, we develop a highly efficient ViT compression solution, which outperforms the state-of-the-art pruning methods. For compressing DeiT-small and DeiT-base models on ImageNet, our proposed approach can achieve 0.45% and 0.76% higher top-1 accuracy even with fewer parameters. Our fin
    
[^22]: 因果成分分析

    Causal Component Analysis. (arXiv:2305.17225v1 [stat.ML])

    [http://arxiv.org/abs/2305.17225](http://arxiv.org/abs/2305.17225)

    本文介绍了一个中间问题：因果成分分析(CauCA)，它是独立成分分析(ICA)和因果表示学习(CRL)的泛化和特例，其目标是学习解混函数和因果机制，预设了因果图的知识。

    

    独立成分分析(ICA)的目标是从混合观测到的变量中恢复独立的潜在变量。而因果表示学习(CRL)的目标是推断因果关系强相关性的潜在变量，以及编码它们的因果关系的未知图。我们引入了一个中间问题，称为因果成分分析(CauCA)。CauCA可以被看作是ICA的一种推广，对潜在成分之间的因果依赖建模，也是CRL的一个特例。与CRL不同的是，它预设了因果图的知识，仅关注于学习解混函数和因果机制。所有关于CauCA回收基础真相的不可能结果也适用于CRL，而可能性结果可以作为扩展CRL的基础。我们将从对潜在因果变量实施不同类型干预的多个数据集中表征CauCA的可识别性。

    Independent Component Analysis (ICA) aims to recover independent latent variables from observed mixtures thereof. Causal Representation Learning (CRL) aims instead to infer causally related (thus often statistically dependent) latent variables, together with the unknown graph encoding their causal relationships. We introduce an intermediate problem termed Causal Component Analysis (CauCA). CauCA can be viewed as a generalization of ICA, modelling the causal dependence among the latent components, and as a special case of CRL. In contrast to CRL, it presupposes knowledge of the causal graph, focusing solely on learning the unmixing function and the causal mechanisms. Any impossibility results regarding the recovery of the ground truth in CauCA also apply for CRL, while possibility results may serve as a stepping stone for extensions to CRL. We characterize CauCA identifiability from multiple datasets generated through different types of interventions on the latent causal variables. As a
    
[^23]: 我们真的需要大量的视觉提示吗？

    Do We Really Need a Large Number of Visual Prompts?. (arXiv:2305.17223v1 [cs.CV])

    [http://arxiv.org/abs/2305.17223](http://arxiv.org/abs/2305.17223)

    本文研究了视觉提示调整（VPT）技术中提示数量对微调性能和自我关注操作的影响，并提出了Prompt Condensation（PC）技术，该技术可以将提示数量减少约70％，同时保持准确性。

    

    鉴于在资源受限的边缘上适应模型的兴趣不断增加，参数高效的迁移学习已被广泛探索。在各种方法中，可视提示调整（VPT）将可学习提示加到输入空间中，与全网络参数的训练相比，显示出有竞争力的微调性能。然而，VPT增加了输入标记的数量，导致额外的计算开销。在本文中，我们分析了提示数量对视觉变换器体系结构中微调性能和自我关注操作的影响。通过理论和实证分析，我们表明添加更多提示不会导致线性性能改进。此外，我们提出了一种Prompt Condensation（PC）技术，旨在防止使用少量提示时性能下降。我们在FGVC和VTAB-1k任务上验证了我们的方法，并显示我们的方法可以将提示数量减少约70％，同时保持准确性。

    Due to increasing interest in adapting models on resource-constrained edges, parameter-efficient transfer learning has been widely explored. Among various methods, Visual Prompt Tuning (VPT), prepending learnable prompts to input space, shows competitive fine-tuning performance compared to training of full network parameters. However, VPT increases the number of input tokens, resulting in additional computational overhead. In this paper, we analyze the impact of the number of prompts on fine-tuning performance and self-attention operation in a vision transformer architecture. Through theoretical and empirical analysis we show that adding more prompts does not lead to linear performance improvement. Further, we propose a Prompt Condensation (PC) technique that aims to prevent performance degradation from using a small number of prompts. We validate our methods on FGVC and VTAB-1k tasks and show that our approach reduces the number of prompts by ~70% while maintaining accuracy.
    
[^24]: 基于联邦学习的语义解析任务：任务形式，评估设置及新算法

    Federated Learning for Semantic Parsing: Task Formulation, Evaluation Setup, New Algorithms. (arXiv:2305.17221v1 [cs.CL])

    [http://arxiv.org/abs/2305.17221](http://arxiv.org/abs/2305.17221)

    本文研究了基于联邦学习的语义解析任务，提出了评估设置和新算法。实验表明，新算法FedSQL和Lorar优于现有的FL算法和我们提出的设置的强基线。

    

    本文研究了一种新的联邦学习任务，即针对语义解析的联邦学习，多个客户端共同训练一个全局模型，而无需共享其语义分析数据。通过利用多个客户端的数据，联邦学习模式对于那些没有足够训练数据来开发一个数据饥饿的神经语义分析器的客户端尤其有益。我们提出了一种评估设置来研究这个任务，将广泛使用的单域文本到SQL数据集作为客户端来形成一个现实的异构联邦学习设置，并协同训练一个全局模型。由于我们的现实设置中客户群的异质性很高，标准的联邦学习算法会受到影响，所以我们进一步提出了一种新的机制LOss Reduction Adjusted Re-weighting (Lorar)来缓解性能下降，该机制基于客户端每轮训练损失的减少情况来调节每个客户端对于全局模型更新的贡献。我们的直觉是，损失减少的越多，客户端离全局最优解就越远，其对模型更新的贡献就应该越高。同时，我们还提出了一个针对异构文本到SQL FL设置的新的FL算法FedSQL。我们的实验表明，FedSQL和Lorar显著优于现有的FL算法和我们提出的FL设置中的强基线。

    This paper studies a new task of federated learning (FL) for semantic parsing, where multiple clients collaboratively train one global model without sharing their semantic parsing data. By leveraging data from multiple clients, the FL paradigm can be especially beneficial for clients that have little training data to develop a data-hungry neural semantic parser on their own. We propose an evaluation setup to study this task, where we re-purpose widely-used single-domain text-to-SQL datasets as clients to form a realistic heterogeneous FL setting and collaboratively train a global model. As standard FL algorithms suffer from the high client heterogeneity in our realistic setup, we further propose a novel LOss Reduction Adjusted Re-weighting (Lorar) mechanism to mitigate the performance degradation, which adjusts each client's contribution to the global model update based on its training loss reduction during each round. Our intuition is that the larger the loss reduction, the further aw
    
[^25]: 知识为基础的规划的范畴表达语言和计算系统

    A Categorical Representation Language and Computational System for Knowledge-Based Planning. (arXiv:2305.17208v1 [cs.AI])

    [http://arxiv.org/abs/2305.17208](http://arxiv.org/abs/2305.17208)

    本文提出了一种基于范畴论的世界状态表示和转换方法，可以有效处理结构化知识，并且提供了使用知识图和关系数据库来建模规划中世界状态和更新的正式语义。

    

    基于一阶逻辑的经典规划表达语言已经被广泛应用于建模和解决规划问题，但是在复杂的规划场景中往往难以捕捉到隐含的前提和影响。为了解决这个问题，我们提出了一种表示和转换规划过程中世界状态的替代方法。基于范畴论的C集和双推成重写（DPO）的概念，我们提出的表示法可以有效地处理结构化知识，这些知识支持各个层次的领域抽象。它根据用户提供的本体学表示谓词的语义，并在状态转换时保持语义的一致性。这种方法为使用知识图和关系数据库来建模规划中的世界状态和更新提供了正式的语义。在本文中，我们将我们的范畴论表示与经典规划表示进行了比较。

    Classical planning representation languages based on first-order logic have been extensively used to model and solve planning problems, but they struggle to capture implicit preconditions and effects that arise in complex planning scenarios. To address this problem, we propose an alternative approach to representing and transforming world states during planning. Based on the category-theoretic concepts of $\mathsf{C}$-sets and double-pushout rewriting (DPO), our proposed representation can effectively handle structured knowledge about world states that support domain abstractions at all levels. It formalizes the semantics of predicates according to a user-provided ontology and preserves the semantics when transitioning between world states. This method provides a formal semantics for using knowledge graphs and relational databases to model world states and updates in planning. In this paper, we compare our category-theoretic representation with the classical planning representation. We
    
[^26]: 基于 Trend 和 Seasonality 分解和 LightGBM 的销售预测改进

    Improved Sales Forecasting using Trend and Seasonality Decomposition with LightGBM. (arXiv:2305.17201v1 [cs.LG])

    [http://arxiv.org/abs/2305.17201](http://arxiv.org/abs/2305.17201)

    本文提出了一种根据趋势和季节性分量在时间序列上的独特影响指标进行时间序列分组的新方法，并采用 LightGBM 模型进行预测，在沃尔玛销售数据上实现了较高的预测精度。

    

    针对沃尔玛和亚马逊等大型零售商销售预测的难点，本文提出了一种新的方法，即根据趋势和季节性分量在时间序列上的独特影响指标进行时间序列分组，并采用 LightGBM 模型进行预测。实验结果表明，该分组方法可以提高预测精度，相较于传统时间序列模型和其他机器学习模型，MAPE（平均绝对百分比误差）在测试集上可达 4.49%。

    Retail sales forecasting presents a significant challenge for large retailers such as Walmart and Amazon, due to the vast assortment of products, geographical location heterogeneity, seasonality, and external factors including weather, local economic conditions, and geopolitical events. Various methods have been employed to tackle this challenge, including traditional time series models, machine learning models, and neural network mechanisms, but the difficulty persists. Categorizing data into relevant groups has been shown to improve sales forecast accuracy as time series from different categories may exhibit distinct patterns. In this paper, we propose a new measure to indicate the unique impacts of the trend and seasonality components on a time series and suggest grouping time series based on this measure. We apply this approach to Walmart sales data from 01/29/2011 to 05/22/2016 and generate sales forecasts from 05/23/2016 to 06/19/2016. Our experiments show that the proposed strat
    
[^27]: 离线多智能体强化学习协调问题的基于模型的解决方案

    A Model-Based Solution to the Offline Multi-Agent Reinforcement Learning Coordination Problem. (arXiv:2305.17198v1 [cs.LG])

    [http://arxiv.org/abs/2305.17198](http://arxiv.org/abs/2305.17198)

    提出了一个基于模型的离线多智能体强化学习方法MOMA-PPO，通过生成合成交互数据并优化智能体的政策，解决了策略一致性和策略微调两个协调问题，在具有挑战性的离线MARL场景中胜过主流的学习方法，提供了实际应用中的可行解决方案。

    

    训练多个智能体进行协调是一项重要问题，具有机器人技术、博弈论、经济学和社会科学等领域的应用。然而，大多数现有的多智能体强化学习方法是在线的，因此在收集新的交互数据成本高昂或危险的实际应用中不可行。虽然这些算法应该利用离线数据，但这样做会引起离线协调问题。具体而言，我们确定并形式化了策略一致性（SA）和策略微调（SFT）两个协调问题，这是当前离线多智能体强化学习算法失败的原因。为解决这个问题，我们提出了一种简单的基于模型的方法，生成合成交互数据，使智能体能够在微调策略的同时收敛于一个策略。我们提出的方法，Model-based Offline Multi-Agent Proximal Policy Optimization（MOMA-PPO），在具有挑战性的离线MARL场景中胜过主流的学习方法，证明了基于模型的方法提供了一个可行的解决方案。

    Training multiple agents to coordinate is an important problem with applications in robotics, game theory, economics, and social sciences. However, most existing Multi-Agent Reinforcement Learning (MARL) methods are online and thus impractical for real-world applications in which collecting new interactions is costly or dangerous. While these algorithms should leverage offline data when available, doing so gives rise to the offline coordination problem. Specifically, we identify and formalize the strategy agreement (SA) and the strategy fine-tuning (SFT) challenges, two coordination issues at which current offline MARL algorithms fail. To address this setback, we propose a simple model-based approach that generates synthetic interaction data and enables agents to converge on a strategy while fine-tuning their policies accordingly. Our resulting method, Model-based Offline Multi-Agent Proximal Policy Optimization (MOMA-PPO), outperforms the prevalent learning methods in challenging offl
    
[^28]: 知识工程入门

    A Knowledge Engineering Primer. (arXiv:2305.17196v1 [cs.AI])

    [http://arxiv.org/abs/2305.17196](http://arxiv.org/abs/2305.17196)

    该文介绍了知识工程的基本概念，帮助读者了解该领域并建立直觉。

    

    这篇文章的目的是以简洁而综合的方式介绍知识工程的主题，以培养读者对该领域的直觉。

    The aim of this primer is to introduce the subject of knowledge engineering in a concise but synthetic way to develop the reader's intuition about the area.
    
[^29]: 通过想象过去来推断未来

    Inferring the Future by Imagining the Past. (arXiv:2305.17195v1 [cs.AI])

    [http://arxiv.org/abs/2305.17195](http://arxiv.org/abs/2305.17195)

    本文介绍了一种蒙特卡罗算法用于从情报主体的单张图像中推断出一连串复杂的历史和未来事件，并且能够在只有少数样本的情况下扩展到各种具有挑战性的推断问题。

    

    漫画书中的单一画面能够展现人物的当前状态、来自何处、动机以及可能发生的事情，这启示了我们可以从情报主体的单张图像中推断出一连串复杂的历史和未来事件。本文基于最近的认知科学研究，提供一种蒙特卡罗算法用于进行此类推断。建立在计算机图形学中的蒙特卡罗路径追踪的基础上，我们借鉴了许多理念，大大提高了先前工作中的样本效率。这使得我们能够在只有少数样本的情况下扩展到各种具有挑战性的推断问题。它也表明了一定的认知合理性，事实上，我们呈现了在各种领域中，我们的算法能够匹配先前方法无法扩展的人类直觉的人类受试者研究。

    A single panel of a comic book can say a lot: it shows not only where characters currently are, but also where they came from, what their motivations are, and what might happen next. More generally, humans can often infer a complex sequence of past and future events from a *single snapshot image* of an intelligent agent.  Building on recent work in cognitive science, we offer a Monte Carlo algorithm for making such inferences. Drawing a connection to Monte Carlo path tracing in computer graphics, we borrow ideas that help us dramatically improve upon prior work in sample efficiency. This allows us to scale to a wide variety of challenging inference problems with only a handful of samples. It also suggests some degree of cognitive plausibility, and indeed we present human subject studies showing that our algorithm matches human intuitions in a variety of domains that previous methods could not scale to.
    
[^30]: 基于AI的超分辨显微镜分析：在没有基准的情况下进行生物发现

    AI-based analysis of super-resolution microscopy: Biological discovery in the absence of ground truth. (arXiv:2305.17193v1 [q-bio.SC])

    [http://arxiv.org/abs/2305.17193](http://arxiv.org/abs/2305.17193)

    利用弱监督学习范例对超分辨率显微镜进行分析具有发现新生物学的巨大潜力，并且可以加速探索亚细胞大分子和细胞器分子结构。

    

    超分辨显微镜的纳米级分辨率现已使荧光分子定位工具能够用于研究整个细胞结构生物学。基于机器学习的超分辨数据分析具有发现新生物学的巨大潜力，而新生物学本身没有被发现过，也没有基准。在这里，我们描述了弱监督学习范例在超分辨显微镜中的应用以及其潜力，以实现对亚细胞大分子和细胞器分子结构的加速探索。

    The nanoscale resolution of super-resolution microscopy has now enabled the use of fluorescent based molecular localization tools to study whole cell structural biology. Machine learning based analysis of super-resolution data offers tremendous potential for discovery of new biology, that by definition is not known and lacks ground truth. Herein, we describe the application of weakly supervised learning paradigms to super-resolution microscopy and its potential to enable the accelerated exploration of the molecular architecture of subcellular macromolecules and organelles.
    
[^31]: ProGroTrack: 深度学习辅助下的细胞内蛋白质增长动态跟踪

    ProGroTrack: Deep Learning-Assisted Tracking of Intracellular Protein Growth Dynamics. (arXiv:2305.17183v1 [q-bio.QM])

    [http://arxiv.org/abs/2305.17183](http://arxiv.org/abs/2305.17183)

    本文提出了一种新的方法——ProGroTrack，在基于检测的跟踪(DBT)框架中将YOLO和ByteTrack算法相结合，成功地跟踪了细胞内蛋白质纳米结构的生长行为。其中，采用YOLOv5模型表现最佳，半监督学习有效地提高了模型性能。该方法揭示了iPAK4蛋白质纤维的两个不同生长阶段，为相关研究提供了重要数据支持。

    

    准确地跟踪细胞和亚细胞结构以及它们的动态在理解生物系统的基本机制中起着关键作用。本文提出了一种新的方法——ProGroTrack，在基于检测的跟踪(DBT)框架中将You Only Look Once (YOLO) 和ByteTrack算法相结合，以跟踪细胞内蛋白质纳米结构。以iPAK4蛋白纤维为代表案例，我们对YOLOv5和YOLOv8模型进行了全面评估，结果显示YOLOv5在我们的数据集上表现优异。值得注意的是，YOLOv5x实现了0.839的mAP50和0.819的F-score。为进一步优化检测能力，我们采用半监督学习进行模型改进，在所有指标上都获得了提高。随后，我们成功地应用了这种方法来跟踪iPAK4蛋白质纤维的生长行为，揭示了它们的两个不同的生长阶段，与先前的研究结果一致。

    Accurate tracking of cellular and subcellular structures, along with their dynamics, plays a pivotal role in understanding the underlying mechanisms of biological systems. This paper presents a novel approach, ProGroTrack, that combines the You Only Look Once (YOLO) and ByteTrack algorithms within the detection-based tracking (DBT) framework to track intracellular protein nanostructures. Focusing on iPAK4 protein fibers as a representative case study, we conducted a comprehensive evaluation of YOLOv5 and YOLOv8 models, revealing the superior performance of YOLOv5 on our dataset. Notably, YOLOv5x achieved an impressive mAP50 of 0.839 and F-score of 0.819. To further optimize detection capabilities, we incorporated semi-supervised learning for model improvement, resulting in enhanced performances in all metrics. Subsequently, we successfully applied our approach to track the growth behavior of iPAK4 protein fibers, revealing their two distinct growth phases consistent with a previously r
    
[^32]: 无监督神经机器翻译的复制问题：具有语言鉴别器损失的训练计划

    On the Copying Problem of Unsupervised NMT: A Training Schedule with a Language Discriminator Loss. (arXiv:2305.17182v1 [cs.CL])

    [http://arxiv.org/abs/2305.17182](http://arxiv.org/abs/2305.17182)

    无监督NMT中的复制问题通常发生在远距离语种对中且会直接复制输入句子的部分作为翻译，本研究提出了一种包含语言鉴别器损失的训练计划来缓解该问题，并提高低资源语种的翻译性能。

    

    虽然无监督神经机器翻译已在许多语种间得到成功，但复制问题（即将输入句子的某些部分直接复制作为翻译）在远距离语种对中很常见，尤其涉及低资源语种。我们发现这个问题与在线回译（BT）期间出现的预期复制行为密切相关。在这项工作中，我们提出了一个简单但有效的训练计划，它包含了一个语言鉴别器的损失函数。该损失施加约束于中间翻译，以使翻译是所需的语言。通过在不同语言对、 包括相似和远距离、高资源和低资源语言的广泛实验中，我们发现我们的方法缓解了复制问题，从而提高了对低资源语言的翻译性能。

    Although unsupervised neural machine translation (UNMT) has achieved success in many language pairs, the copying problem, i.e., directly copying some parts of the input sentence as the translation, is common among distant language pairs, especially when low-resource languages are involved. We find this issue is closely related to an unexpected copying behavior during online back-translation (BT). In this work, we propose a simple but effective training schedule that incorporates a language discriminator loss. The loss imposes constraints on the intermediate translation so that the translation is in the desired language. By conducting extensive experiments on different language pairs, including similar and distant, high and low-resource languages, we find that our method alleviates the copying problem, thus improving the translation performance on low-resource languages.
    
[^33]: 一种改进的机器学习算法超参数调整集成模型，用于胎儿健康预测

    An Improved Model Ensembled of Different Hyper-parameter Tuned Machine Learning Algorithms for Fetal Health Prediction. (arXiv:2305.17156v1 [cs.LG])

    [http://arxiv.org/abs/2305.17156](http://arxiv.org/abs/2305.17156)

    本研究提出了一种名为ETSE的机器学习集成模型，用于预测胎儿健康。该模型通过采用多种数据预处理技术和7种不同的机器学习分类器，能够提高预测准确性和性能。

    

    胎儿健康对于孕期非常重要，因为它会影响到母亲和胎儿的健康。监测胎儿健康通常需要使用人工智能技术，可以提高诊断的准确性、效率和速度。本研究提出了一种名为ETSE的机器学习定制支持向量机和ExtraTrees集成模型，用于预测胎儿健康。该模型采用了离群值剔除、缺失值补全、数据标准化和数据抽样等预处理技术，并实现了7种机器学习分类器，包括支持向量机、XGBoost、LGBM、决策树、随机森林、ExtraTrees和K近邻。这些模型经过评估和优化，采用超参数调整进行模型性能的最优化。

    Fetal health is a critical concern during pregnancy as it can impact the well-being of both the mother and the baby. Regular monitoring and timely interventions are necessary to ensure the best possible outcomes. While there are various methods to monitor fetal health in the mother's womb, the use of artificial intelligence (AI) can improve the accuracy, efficiency, and speed of diagnosis. In this study, we propose a robust ensemble model called ensemble of tuned Support Vector Machine and ExtraTrees (ETSE) for predicting fetal health. Initially, we employed various data preprocessing techniques such as outlier rejection, missing value imputation, data standardization, and data sampling. Then, seven machine learning (ML) classifiers including Support Vector Machine (SVM), XGBoost (XGB), Light Gradient Boosting Machine (LGBM), Decision Tree (DT), Random Forest (RF), ExtraTrees (ET), and K-Neighbors were implemented. These models were evaluated and then optimized by hyperparameter tuning
    
[^34]: 动力学系统中隐式神经网络的长期预测稳定性

    Stability of implicit neural networks for long-term forecasting in dynamical systems. (arXiv:2305.17155v1 [cs.LG])

    [http://arxiv.org/abs/2305.17155](http://arxiv.org/abs/2305.17155)

    本文提出了一种基于隐式数值方案稳定性特性的神经网络，加入了硬性约束来保证其权重稳定性，取得了较好的长期预测结果。

    

    预测长时间范围内的物理信号是偏微分方程研究中最具挑战性的任务之一。为了规避传统求解器的限制，提出了许多不同的深度学习方法。它们都基于自回归方法并展示出稳定性问题。受隐式数值方案的稳定性特性启发，我们引入了一个稳定的自回归隐式神经网络。我们根据数值方案的稳定性定义，开发了一种理论来保证网络预测的稳定性。它导致我们对其权重添加了硬性约束，并在潜空间中传播动态。我们的实验结果验证了我们的稳定性，展示了在两个输运偏微分方程的长期预测上改进的结果。

    Forecasting physical signals in long time range is among the most challenging tasks in Partial Differential Equations (PDEs) research. To circumvent limitations of traditional solvers, many different Deep Learning methods have been proposed. They are all based on auto-regressive methods and exhibit stability issues. Drawing inspiration from the stability property of implicit numerical schemes, we introduce a stable auto-regressive implicit neural network. We develop a theory based on the stability definition of schemes to ensure the stability in forecasting of this network. It leads us to introduce hard constraints on its weights and propagate the dynamics in the latent space. Our experimental results validate our stability property, and show improved results at long-term forecasting for two transports PDEs.
    
[^35]: 关于深度网络表示中概念空间的凸性研究

    On convex conceptual regions in deep network representations. (arXiv:2305.17154v1 [cs.LG])

    [http://arxiv.org/abs/2305.17154](http://arxiv.org/abs/2305.17154)

    本文研究了深度网络表示中概念空间的凸性对泛化能力、小样本学习和主观一致性的影响，发现近似凸性在多个应用领域中广泛存在。

    

    人机对齐的研究旨在理解潜在空间的几何结构和与人类表征的对应关系。Gardenfors的概念空间是理解人类表征的一个重要框架。在概念空间中，对象区域的凸性被认为是促进泛化能力、小样本学习和主观一致性的重要机制。基于这些洞见，本文研究了机器学习中学习的潜在空间中概念区域的凸性。作者开发了一组用于测量采样数据中凸性的工具，并评估了最先进深度网络中的层表示中的凸性。结果表明，凸性对于基本的重新参数化是稳健的，因此作为机器学习潜在空间质量的一个重要特征是有意义的。作者发现，近似凸性在神经表示中广泛存在于多个应用领域，包括图像、音频、人类活动、文本和脑数据。

    The current study of human-machine alignment aims at understanding the geometry of latent spaces and the correspondence to human representations. G\"ardenfors' conceptual spaces is a prominent framework for understanding human representations. Convexity of object regions in conceptual spaces is argued to promote generalizability, few-shot learning, and intersubject alignment. Based on these insights, we investigate the notion of convexity of concept regions in machine-learned latent spaces. We develop a set of tools for measuring convexity in sampled data and evaluate emergent convexity in layered representations of state-of-the-art deep networks. We show that convexity is robust to basic re-parametrization, hence, meaningful as a quality of machine-learned latent spaces. We find that approximate convexity is pervasive in neural representations in multiple application domains, including models of images, audio, human activity, text, and brain data. We measure convexity separately for l
    
[^36]: mldr.resampling: 多标签重采样算法有效的参考实现

    mldr.resampling: Efficient Reference Implementations of Multilabel Resampling Algorithms. (arXiv:2305.17152v1 [cs.LG])

    [http://arxiv.org/abs/2305.17152](http://arxiv.org/abs/2305.17152)

    mldr.resampling是一个软件包，提供11种多标签重采样方法的参考实现，旨在应对多标签学习中的不平衡情况，并具有高效性。

    

    重采样算法是应对多标签学习中不平衡情况的有用方法。这些方法必须处理多标签数据中的奇异性，例如同一实例中频繁和不频繁标签的出现。这篇原创软件发表介绍了 mldr.resampling，这是一个软件包，提供了11种多标签重采样方法的参考实现，强调效率，因为这些算法通常耗时。

    Resampling algorithms are a useful approach to deal with imbalanced learning in multilabel scenarios. These methods have to deal with singularities in the multilabel data, such as the occurrence of frequent and infrequent labels in the same instance. Implementations of these methods are sometimes limited to the pseudocode provided by their authors in a paper. This Original Software Publication presents mldr.resampling, a software package that provides reference implementations for eleven multilabel resampling methods, with an emphasis on efficiency since these algorithms are usually time-consuming.
    
[^37]: 具有精确编码的诊断时空变换器

    Diagnostic Spatio-temporal Transformer with Faithful Encoding. (arXiv:2305.17149v1 [cs.LG])

    [http://arxiv.org/abs/2305.17149](http://arxiv.org/abs/2305.17149)

    本文提出了一种诊断时空变换器（DFStrans），其利用新的位置编码和时空依赖性发现框架，能够在具有复杂时空依赖性的多元时间序列分类任务中提取可操作见解。

    

    本文讨论了当基本数据生成过程具有复杂的时空依赖性时的异常诊断任务。其中关键技术挑战是从描述时间和空间指数之间高阶交互的依赖张量中提取可操作见解。我们将问题形式化为监督依赖发现，其中时空依赖性被作为多元时间序列分类的副产品进行学习。我们发现现有ST变换器中使用的时间位置编码在捕捉更高频率（短时间尺度）方面存在严重限制。我们提出了一种具有离散傅里叶变换理论保证的新的位置编码。我们还提出了一种新的时空依赖性发现框架，可以在空间和时间方向上提供易于消化的诊断信息。最后，我们在合成和真实世界数据集上证明了所提出的模型DFStrans（基于傅里叶变换的诊断时空变换器）的实用性。

    This paper addresses the task of anomaly diagnosis when the underlying data generation process has a complex spatio-temporal (ST) dependency. The key technical challenge is to extract actionable insights from the dependency tensor characterizing high-order interactions among temporal and spatial indices. We formalize the problem as supervised dependency discovery, where the ST dependency is learned as a side product of multivariate time-series classification. We show that temporal positional encoding used in existing ST transformer works has a serious limitation in capturing higher frequencies (short time scales). We propose a new positional encoding with a theoretical guarantee, based on discrete Fourier transform. We also propose a new ST dependency discovery framework, which can provide readily consumable diagnostic information in both spatial and temporal directions. Finally, we demonstrate the utility of the proposed model, DFStrans (Diagnostic Fourier-based Spatio-temporal Transf
    
[^38]: 大型语言模型的异质价值评估

    Heterogeneous Value Evaluation for Large Language Models. (arXiv:2305.17147v1 [cs.CL])

    [http://arxiv.org/abs/2305.17147](http://arxiv.org/abs/2305.17147)

    本文提出了一种自动对齐评估方法A2EHV，采用异质价值系统，并基于价值合理性和社会价值定向框架评估代理人行为的社会偏好，结果表明比传统对齐方法更合理。

    

    大型语言模型（LLM）的出现使得将它们的价值与人类价值对齐变得至关重要。当前的方法通常尝试将其与一种同质的人类价值对齐，并需要人类验证，但缺乏对对齐所需方面和深度的共识以及造成的人类偏见。在本文中，我们提出了一种自动对齐评估方法A2EHV，该方法采用异质价值系统，（1）是自动化的，以最小化单个人类偏见，并且（2）允许评估针对各种目标值的异质代理人。我们的方法基于价值合理性的概念，它代表了代理人执行最能满足目标价值行为的能力。价值合理性的量化是通过社会心理学中的社会价值定向框架进行的，该框架将价值空间分为四个类别，以评估代理人行为的社会偏好。我们评估了三个模型的价值合理性，结果表明A2EHV方法比传统对齐方法更合理。

    The emergent capabilities of Large Language Models (LLMs) have made it crucial to align their values with those of humans. Current methodologies typically attempt alignment with a homogeneous human value and requires human verification, yet lack consensus on the desired aspect and depth of alignment and resulting human biases. In this paper, we propose A2EHV, an Automated Alignment Evaluation with a Heterogeneous Value system that (1) is automated to minimize individual human biases, and (2) allows assessments against various target values to foster heterogeneous agents. Our approach pivots on the concept of value rationality, which represents the ability for agents to execute behaviors that satisfy a target value the most. The quantification of value rationality is facilitated by the Social Value Orientation framework from social psychology, which partitions the value space into four categories to assess social preferences from agents' behaviors. We evaluate the value rationality of e
    
[^39]: Minecraft中的幽灵：利用基于文本知识和记忆的大型语言模型实现开放世界环境中的通用能力智能体。

    Ghost in the Minecraft: Generally Capable Agents for Open-World Enviroments via Large Language Models with Text-based Knowledge and Memory. (arXiv:2305.17144v1 [cs.AI])

    [http://arxiv.org/abs/2305.17144](http://arxiv.org/abs/2305.17144)

    本文提出了Ghost in the Minecraft (GITM)框架，利用大型语言模型与基于文本的知识和记忆，创造了一种在Minecraft中具备通用能力的智能体，可在以文本为基础的复杂编程环境中熟练导航。

    

    近年来，Minecraft玩法吸引了大量的研究关注，成为开发能够在开放世界环境中运行的智能体的丰富平台。然而，当前的研究主要集中在特定的目标上，例如流行的“ObtainDiamond”任务，并且还没有显示出有效地推广到更广泛任务的能力。此外，“ObtainDiamond”任务的目前最高成功率只有约20％，凸显了现有方法中使用强化学习（RL）控制器的局限性。为了解决这些挑战，我们引入了Ghost in the Minecraft (GITM)，一个新颖的框架，将大型语言模型与基于文本的知识和记忆相结合，旨在创建Minecraft中的通用能力智能体。这些具备LLM中的逻辑和常识能力的智能体可以熟练地在以文本为基础的复杂编程环境中导航。

    The captivating realm of Minecraft has attracted substantial research interest in recent years, serving as a rich platform for developing intelligent agents capable of functioning in open-world environments. However, the current research landscape predominantly focuses on specific objectives, such as the popular "ObtainDiamond" task, and has not yet shown effective generalization to a broader spectrum of tasks. Furthermore, the current leading success rate for the "ObtainDiamond" task stands at around 20%, highlighting the limitations of Reinforcement Learning (RL) based controllers used in existing methods. To tackle these challenges, we introduce Ghost in the Minecraft (GITM), a novel framework integrates Large Language Models (LLMs) with text-based knowledge and memory, aiming to create Generally Capable Agents (GCAs) in Minecraft. These agents, equipped with the logic and common sense capabilities of LLMs, can skillfully navigate complex, sparse-reward environments with text-based 
    
[^40]: 基于深度强化学习的多智能体通信与协作决策研究

    Research on Multi-Agent Communication and Collaborative Decision-Making Based on Deep Reinforcement Learning. (arXiv:2305.17141v1 [cs.MA])

    [http://arxiv.org/abs/2305.17141](http://arxiv.org/abs/2305.17141)

    本研究基于CTDE框架，提出了基于MAPPO算法的多智能体合作决策模型，并引入了基于权重调度和注意力模块的多智能体通信机制，能够有效缓解多智能体环境的不稳定性，提高多智能体在复杂环境中的协作决策能力。

    

    在多智能体环境中，为了克服和缓解环境的不稳定性，主流方法是采用集中式训练分散式执行（CTDE）框架。本文基于CTDE框架，研究了基于多智能体近端策略优化（MAPPO）算法的多智能体合作决策问题。为了缓解多智能体环境的不稳定性，引入了基于权重调度和注意力模块的多智能体通信机制。不同的智能体可以通过智能体之间的信息交换来缓解由本地观测引起的不稳定性，协助智能体的协作决策。具体方法是在策略网络部分引入一个通信模块。通信模块由权重生成器、权重调度器、信息编码器、信息解码器和注意力模块组成。经过实验证明，所提出的方法可以有效地提高多智能体在复杂环境中的协作决策能力。

    In a multi-agent environment, In order to overcome and alleviate the non-stationarity of the multi-agent environment, the mainstream method is to adopt the framework of Centralized Training Decentralized Execution (CTDE). This thesis is based on the framework of CTDE, and studies the cooperative decision-making of multi-agent based on the Multi-Agent Proximal Policy Optimization (MAPPO) algorithm for multi-agent proximal policy optimization. In order to alleviate the non-stationarity of the multi-agent environment, a multi-agent communication mechanism based on weight scheduling and attention module is introduced. Different agents can alleviate the non-stationarity caused by local observations through information exchange between agents, assisting in the collaborative decision-making of agents. The specific method is to introduce a communication module in the policy network part. The communication module is composed of a weight generator, a weight scheduler, a message encoder, a messag
    
[^41]: 可观测环境中交互模型扩展

    Interactive Model Expansion in an Observable Environment. (arXiv:2305.17140v1 [cs.AI])

    [http://arxiv.org/abs/2305.17140](http://arxiv.org/abs/2305.17140)

    本文研究了在搜索过程中用户能否考虑部分解决方案并进行验证的问题，在可观测环境下通过交互式系统提出和完善解决方案的假设。

    

    许多实际问题可以理解为寻找一种状态，它扩展了固定的部分状态，即"环境"，同时满足一定的形式化规定条件。这类问题在工程、法律或经济学中都存在。本文研究了这一类问题，其中，用户在搜索开始时并不知道有关环境的某些信息。在搜索过程中，用户可以考虑某些暂定解决方案，这些方案对这些未知信息进行了暗示性假设。为确保解决方案的适宜性，这些假设必须通过对环境的观察来进行验证。此外，我们还假设，除了解决方案构成的知识外，我们还有关于环境通用定律的知识。我们正式定义了具有足够验证事实的部分解决方案，以保证完整、适当解决方案的存在性。另外，我们提出了一个交互式系统，以协助用户进行搜索过程，系统根据用户行动的观察结果提出和完善解决方案的假设。

    Many practical problems can be understood as the search for a state of affairs that extends a fixed partial state of affairs, the \emph{environment}, while satisfying certain conditions that are formally specified. Such problems are found in, e.g., engineering, law or economics.  We study this class of problems in a context where some of the relevant information about the environment is not known by the user at the start of the search. During the search, the user may consider tentative solutions that make implicit hypotheses about these unknowns. To ensure that the solution is appropriate, these hypotheses must be verified by observing the environment. Furthermore, we assume that, in addition to knowledge of what constitutes a solution, knowledge of general laws of the environment is also present. We formally define partial solutions with enough verified facts to guarantee the existence of complete and appropriate solutions.  Additionally, we propose an interactive system to assist the
    
[^42]: 因果关系的测度论公理化

    A Measure-Theoretic Axiomatisation of Causality. (arXiv:2305.17139v1 [cs.AI])

    [http://arxiv.org/abs/2305.17139](http://arxiv.org/abs/2305.17139)

    本文提出了一个称为"因果空间"的概念，旨在以柯尔莫戈罗夫的概率测度公理化为起点，实现对因果关系的公理化，并成功地解决了现有框架的限制。

    

    因果关系是许多研究领域中的核心概念，但仍然没有普遍认可的因果关系公理化。我们将因果关系视为概率理论的扩展，并作为研究在系统上干预时会发生什么的研究，并提议以柯尔莫戈罗夫的概率测度公理化作为因果关系公理化的起点。为此，我们提出了一个"因果空间"的概念，包括一个概率空间和称为"因果核"的转移概率核的集合，用来编码该空间的因果信息。我们提出的框架不仅在测度论上严格地基于，还揭示了现有框架的长期限制，例如，循环、潜在变量和随机过程。

    Causality is a central concept in a wide range of research areas, yet there is still no universally agreed axiomatisation of causality. We view causality both as an extension of probability theory and as a study of \textit{what happens when one intervenes on a system}, and argue in favour of taking Kolmogorov's measure-theoretic axiomatisation of probability as the starting point towards an axiomatisation of causality. To that end, we propose the notion of a \textit{causal space}, consisting of a probability space along with a collection of transition probability kernels, called \textit{causal kernels}, that encode the causal information of the space. Our proposed framework is not only rigorously grounded in measure theory, but it also sheds light on long-standing limitations of existing frameworks including, for example, cycles, latent variables and stochastic processes.
    
[^43]: 智能车辆系统中的生成人工智能集成

    Integrating Generative Artificial Intelligence in Intelligent Vehicle Systems. (arXiv:2305.17137v1 [cs.AI])

    [http://arxiv.org/abs/2305.17137](http://arxiv.org/abs/2305.17137)

    本文提供了关于在智能车辆系统中集成生成人工智能的全面指南，重点强调了其对语音、音频、视觉和多模态交互的应用，并提出了未来研究领域和与伦理道德相关的挑战和风险。

    

    本文旨在为研究人员和实践者提供全面指南，为生成人工智能和基础模型在智能车辆环境中的当前状态、潜在应用和未来研究方向提供洞见。随着汽车行业逐渐整合人工智能，生成人工智能技术有潜力在用户交互方面革命性地改变，提供更沉浸、直观、个性化的车内体验。我们提供生成人工智能在汽车领域中的当前应用概述，重点强调语音、音频、视觉和多模态交互。随后我们概述了关键未来研究领域，包括领域适应性、对齐、多模态集成等，以及解决与伦理道德相关的挑战和风险。通过促进协作和解决这些研究领域，生成人工智能可以成为智能车辆系统的一个重要组成部分，增强驾驶员和乘客的安全、舒适和便利性。

    This paper aims to serve as a comprehensive guide for researchers and practitioners, offering insights into the current state, potential applications, and future research directions for generative artificial intelligence and foundation models within the context of intelligent vehicles. As the automotive industry progressively integrates AI, generative artificial intelligence technologies hold the potential to revolutionize user interactions, delivering more immersive, intuitive, and personalised in-car experiences. We provide an overview of current applications of generative artificial intelligence in the automotive domain, emphasizing speech, audio, vision, and multimodal interactions. We subsequently outline critical future research areas, including domain adaptability, alignment, multimodal integration and others, as well as, address the challenges and risks associated with ethics. By fostering collaboration and addressing these research areas, generative artificial intelligence can
    
[^44]: 三塔：利用预训练图像模型进行灵活的对比学习

    Three Towers: Flexible Contrastive Learning with Pretrained Image Models. (arXiv:2305.16999v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2305.16999](http://arxiv.org/abs/2305.16999)

    本文提出了 3T 方法，即在视觉语言模型中引入预训练的图像分类器，从而提高对比学习的灵活性。3T 同时受益于预训练嵌入和对比训练，并在实验证明对检索任务和分类问题均取得了有竞争力的性能。

    

    本文提出了一种名为“三塔（3T）”的灵活方法，通过将预先训练的图像分类器纳入对比学习，改进了视觉语言模型的对比学习。与通常从头开始训练对比模型不同，最近的 LiT（Zhai 等人，2022）表明了使用预训练分类器嵌入的性能提升。但是，LiT 直接用冻结的嵌入替换图像塔，排除了对图像塔进行对比训练的任何潜在好处。通过 3T，我们提出了一种更灵活的策略，允许图像塔同时受益于预训练嵌入和对比训练。为了实现这一点，我们引入了第三个塔，其中包含冻结的预训练嵌入，并鼓励该第三个塔与主要的图像-文本塔之间的对齐。在实验证明，3T 在检索任务上始终优于 LiT 和 CLIP 风格的从头开始对比学习基线。对于分类问题，3T 在从头开始基线的基础上可靠地改善，虽然在某些数据集上表现不及 LiT，但仍然实现了有竞争力的性能。总的来说，本方法凸显了将预训练分类器注入到视觉语言模型中的有效性，并提供了一种更灵活的利用它们的方法。

    We introduce Three Towers (3T), a flexible method to improve the contrastive learning of vision-language models by incorporating pretrained image classifiers. While contrastive models are usually trained from scratch, LiT (Zhai et al., 2022) has recently shown performance gains from using pretrained classifier embeddings. However, LiT directly replaces the image tower with the frozen embeddings, excluding any potential benefits of contrastively training the image tower. With 3T, we propose a more flexible strategy that allows the image tower to benefit from both pretrained embeddings and contrastive training. To achieve this, we introduce a third tower that contains the frozen pretrained embeddings, and we encourage alignment between this third tower and the main image-text towers. Empirically, 3T consistently improves over LiT and the CLIP-style from-scratch baseline for retrieval tasks. For classification, 3T reliably improves over the from-scratch baseline, and while it underperform
    
[^45]: NavGPT: 带有大型语言模型的视觉语言导航中的显式推理

    NavGPT: Explicit Reasoning in Vision-and-Language Navigation with Large Language Models. (arXiv:2305.16986v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2305.16986](http://arxiv.org/abs/2305.16986)

    NavGPT是基于LLM的导航智能体，可以在视觉语言导航（VLN）中，通过对文本描述进行推理，执行零-shot连续动作预测。该模型具有高级规划能力，可以将指令分解成子目标、整合常识知识以进行障碍物避免，并参考先前的步骤进行澄清。NavGPT展示了通用体现智能体发展的美好前景。

    

    大型语言模型（LLM）例如ChatGPT和GPT-4以前所未有的规模进行训练，从模型的扩展中展现出显著的推理能力。这种趋势强调了使用无限语言数据训练LLM的潜力，推动了通用体现智能体的发展。本文介绍了NavGPT，这是一个纯粹基于LLM的指令跟随导航智能体，通过为视觉语言导航（VLN）执行零-shot的连续动作预测，揭示了对于在复杂的现实场景下GPT模型的推理能力。在每一步中，NavGPT将视觉观察、导航历史和未来可探索方向的文本描述作为输入，推理出智能体的当前状态，并决定如何接近目标。通过全面的实验，我们证明了NavGPT可以明确地执行导航的高级规划，包括将指令分解成子目标、整合常识知识以进行障碍物避免，并参考先前的步骤进行澄清。我们的结果表明，LLM可能成为复杂顺序决策任务中的传统流程的强有力替代品，展示了通用体现智能体发展的美好前景。

    Trained with an unprecedented scale of data, large language models (LLMs) like ChatGPT and GPT-4 exhibit the emergence of significant reasoning abilities from model scaling. Such a trend underscored the potential of training LLMs with unlimited language data, advancing the development of a universal embodied agent. In this work, we introduce the NavGPT, a purely LLM-based instruction-following navigation agent, to reveal the reasoning capability of GPT models in complex embodied scenes by performing zero-shot sequential action prediction for vision-and-language navigation (VLN). At each step, NavGPT takes the textual descriptions of visual observations, navigation history, and future explorable directions as inputs to reason the agent's current status, and makes the decision to approach the target. Through comprehensive experiments, we demonstrate NavGPT can explicitly perform high-level planning for navigation, including decomposing instruction into sub-goal, integrating commonsense k
    
[^46]: 面向抽象摘要中的领域泛化的领域对齐前缀平均方法

    Domain Aligned Prefix Averaging for Domain Generalization in Abstractive Summarization. (arXiv:2305.16820v1 [cs.CL])

    [http://arxiv.org/abs/2305.16820](http://arxiv.org/abs/2305.16820)

    本文提出了一种轻量级、基于加权平均的领域对齐前缀平均方法（DAPA），用于抽象摘要中的领域泛化，实现了有效的源域扩展以提高性能。

    

    针对于抽象摘要中的领域泛化问题，本文提出了一种轻量级，基于加权平均的领域对齐前缀平均方法（DAPA）。通过给定多个源域，我们的方法首先为每个域训练一个前缀，然后利用这些前缀生成少量目标域文档的摘要，计算所需的权重来平均源前缀。在DAPA中，前缀调整允许轻量级的微调，加权平均允许有效地添加新的源域。在四个不同的摘要领域上进行评估，DAPA表现出与基准方法相当或更好的性能，证明了其前缀平均的有效性。

    Domain generalization is hitherto an underexplored area applied in abstractive summarization. Moreover, most existing works on domain generalization have sophisticated training algorithms. In this paper, we propose a lightweight, weight averaging based, Domain Aligned Prefix Averaging approach to domain generalization for abstractive summarization. Given a number of source domains, our method first trains a prefix for each one of them. These source prefixes generate summaries for a small number of target domain documents. The similarity of the generated summaries to their corresponding documents is used for calculating weights required to average source prefixes. In DAPA, prefix tuning allows for lightweight finetuning, and weight averaging allows for the computationally efficient addition of new source domains. When evaluated on four diverse summarization domains, DAPA shows comparable or better performance against the baselines, demonstrating the effectiveness of its prefix averaging
    
[^47]: InterFormer: 混合局部和全局特征用于语音识别的交互式融合方法

    InterFormer: Interactive Local and Global Features Fusion for Automatic Speech Recognition. (arXiv:2305.16342v1 [cs.CL])

    [http://arxiv.org/abs/2305.16342](http://arxiv.org/abs/2305.16342)

    本文提出了InterFormer，用于交互式局部和全局特征融合，以学习更好的ASR表示。通过组合卷积块和变形器块，以及引入BFIM和SFM模块，实现了局部和全局特征的交互和融合，取得了在公共ASR数据集上优异的性能。

    

    对于自动语音识别（ASR）而言，局部和全局特征都是必不可少的。许多最近的方法已经证实，简单地合并局部和全局特征可以进一步提高ASR性能。然而，这些方法往往忽略了局部和全局特征之间的交互，并且它们的串行架构无法反映局部和全局特征之间的关系。为了解决这些问题，本文提出了InterFormer，用于交互式局部和全局特征融合，以学习更好的ASR表示。具体而言，我们将卷积块与变形器块以并行设计相结合。此外，我们提出了双向特征交互模块（BFIM）和选择性融合模块（SFM）来实现局部和全局特征的交互和融合。在公共ASR数据集上的大量实验表明了我们提出的InterFormer的有效性，并且相对于其他Transformer和Conformer模型具有更出色的性能。

    The local and global features are both essential for automatic speech recognition (ASR). Many recent methods have verified that simply combining local and global features can further promote ASR performance. However, these methods pay less attention to the interaction of local and global features, and their series architectures are rigid to reflect local and global relationships. To address these issues, this paper proposes InterFormer for interactive local and global features fusion to learn a better representation for ASR. Specifically, we combine the convolution block with the transformer block in a parallel design. Besides, we propose a bidirectional feature interaction module (BFIM) and a selective fusion module (SFM) to implement the interaction and fusion of local and global features, respectively. Extensive experiments on public ASR datasets demonstrate the effectiveness of our proposed InterFormer and its superior performance over the other Transformer and Conformer models.
    
[^48]: 面向超大规模图的快速在线节点分类算法

    Fast Online Node Labeling for Very Large Graphs. (arXiv:2305.16257v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2305.16257](http://arxiv.org/abs/2305.16257)

    本文提出了一种适用于超大规模图的在线节点分类算法FastONL，它基于广义局部推送方法，能有效近似逆矩阵列并应用于一系列流行的图核，具有较低的遗憾值和每个预测的较低成本。

    

    本文研究了转导学习背景下的在线节点分类问题。当前方法要么需要在$\mathcal{O}(n^3)$的时间复杂度和$\mathcal{O}(n^2)$的空间复杂度内求解图核矩阵的逆，要么需要采样大量的随机生成树，这使得这些方法难以处理大规模图。我们提出了一种基于在线松弛技术的改进算法。当适当选择参数化的图核时，我们首先证明了有效的遗憾值为$\mathcal{O}(\sqrt{n^{1+\gamma}})$。然后，我们基于该松弛提出了一种近似算法FastONL，其遗憾值为$\mathcal{O}(k\sqrt{n^{1+\gamma}})$。FastONL的关键是一种广义局部推送方法，它能有效地近似逆矩阵列并应用于一系列流行的图核。此外，每个预测的成本为$\mathcal{O}(\text{vol}({\mathcal{S}})\log 1/\epsilon)$

    This paper studies the online node classification problem under a transductive learning setting. Current methods either invert a graph kernel matrix with $\mathcal{O}(n^3)$ runtime and $\mathcal{O}(n^2)$ space complexity or sample a large volume of random spanning trees, thus are difficult to scale to large graphs. In this work, we propose an improvement based on the \textit{online relaxation} technique introduced by a series of works (Rakhlin et al.,2012; Rakhlin and Sridharan, 2015; 2017). We first prove an effective regret $\mathcal{O}(\sqrt{n^{1+\gamma}})$ when suitable parameterized graph kernels are chosen, then propose an approximate algorithm FastONL enjoying $\mathcal{O}(k\sqrt{n^{1+\gamma}})$ regret based on this relaxation. The key of FastONL is a \textit{generalized local push} method that effectively approximates inverse matrix columns and applies to a series of popular kernels. Furthermore, the per-prediction cost is $\mathcal{O}(\text{vol}({\mathcal{S}})\log 1/\epsilon)$
    
[^49]: 计算多智能体部分可观测路径规划问题的通用计划

    On Computing Universal Plans for Partially Observable Multi-Agent Path Finding. (arXiv:2305.16203v2 [cs.MA] UPDATED)

    [http://arxiv.org/abs/2305.16203](http://arxiv.org/abs/2305.16203)

    本文提出了一种通用计划的解决方案，能够确保多个智能体之间不发生碰撞，并使用 ASP-MAUPF 系统进行实验，对其适用性和环境依赖度进行了观察和分析。

    

    多智能体路径规划问题在现今广泛应用于仓库机器人、物流自动化、交通控制等领域。本文将其看作是通用规划问题，提出了通用计划（又称策略）的解决方案，并实现了一个名为 ASP-MAUPF 的系统来计算它们。该系统能够在任意二维地图和智能体目标配置下，找到一个适用于每个智能体的通用计划，以确保它们之间互不干扰。

    Multi-agent routing problems have drawn significant attention nowadays due to their broad industrial applications in, e.g., warehouse robots, logistics automation, and traffic control. Conventionally, they are modelled as classical planning problems. In this paper, we argue that it is beneficial to formulate them as universal planning problems. We therefore propose universal plans, also known as policies, as the solution concepts, and implement a system called ASP-MAUPF (Answer Set Programming for Multi-Agent Universal Plan Finding) for computing them. Given an arbitrary two-dimensional map and a profile of goals for the agents, the system finds a feasible universal plan for each agent that ensures no collision with others. We use the system to conduct some experiments, and make some observations on the types of goal profiles and environments that will have feasible policies, and how they may depend on agents' sensors. We also demonstrate how users can customize action preferences to c
    
[^50]: 在脉冲神经网络中将噪声作为计算和学习资源

    Exploiting Noise as a Resource for Computation and Learning in Spiking Neural Networks. (arXiv:2305.16044v2 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2305.16044](http://arxiv.org/abs/2305.16044)

    本文提出了噪声脉冲神经元网络（NSNN）和噪声驱动学习规则（NDL），展示了噪声可以作为计算和学习的资源，并为一般脉冲神经元网络提供了一个框架。研究还展示了NSNNs在图像分类和语音识别等实际任务中的适用性，表明它们是未来神经形态计算系统的潜在有力工具。

    

    脉冲神经元网络是大脑非凡信息处理能力的基础，并已成为神经形态智能的支柱模型。本文介绍了噪声脉冲神经元网络（NSNN）和噪声驱动学习规则（NDL），采用带有噪声神经元动力学的脉冲神经元模型。该方法显示噪声可以作为计算和学习的资源，并理论上为一般脉冲神经元网络提供了一个框架。此外，NDL为代理梯度提供了深入的生物学合理性。通过将各种SNN架构和算法结合起来，我们展示了我们的方法表现出竞争性能，并且比确定性SNNs表现出更好的鲁棒性。此外，本文还展示了NSNNs在图像分类和语音识别等实际任务中的适用性，表明它们是未来神经形态计算系统的潜在有力工具。

    Networks of spiking neurons underpin the extraordinary information-processing capabilities of the brain and have emerged as pillar models in neuromorphic intelligence. Despite extensive research on spiking neural networks (SNNs), most are established on deterministic models. Integrating noise into SNNs leads to biophysically more realistic neural dynamics and may benefit model performance. This work presents the noisy spiking neural network (NSNN) and the noise-driven learning rule (NDL) by introducing a spiking neuron model incorporating noisy neuronal dynamics. Our approach shows how noise may act as a resource for computation and learning and theoretically provides a framework for general SNNs. Moreover, NDL provides an insightful biological rationale for surrogate gradients. By incorporating various SNN architectures and algorithms, we show that our approach exhibits competitive performance and improved robustness against challenging perturbations than deterministic SNNs. Additiona
    
[^51]: 目标导向任务中的反平方Levy步态普遍出现。

    Inverse square Levy walk emerging universally in goal-oriented tasks. (arXiv:2305.15559v1 [cond-mat.stat-mech])

    [http://arxiv.org/abs/2305.15559](http://arxiv.org/abs/2305.15559)

    本研究证明了反平方Levy步态（称为Cauchy步态）在目标导向任务中普遍出现。

    

    Levy步态中，步长出现频率遵循幂律分布，可以在各种生物的迁移行为中观察到。观察到了接近于2的幂指数的Levy步态，但其原因尚不清楚。本研究旨在提出一种普遍产生反平方Levy步态（称为Cauchy步态）的模型，并确定出Cauchy步态出现条件。我们证明了，在目标导向的任务中，Cauchy步态普遍出现。我们使用术语“目标导向”，当目标明确时，但可以通过不同的方式实现，而无法确定唯一的方式。我们进行了模拟，一个代理观察到在二维空间中从概率分布生成的数据，并连续估计该概率分布的中心坐标。代理有一个概率分布模型作为数据生成分布的假设，并可以修改该模型，以使其更符合实际情况。

    The Levy walk in which the frequency of occurrence of step lengths follows a power-law distribution, can be observed in the migratory behavior of organisms at various levels. Levy walks with power exponents close to 2 are observed, and the reasons are unclear. This study aims to propose a model that universally generates inverse square Levy walks (called Cauchy walks) and to identify the conditions under which Cauchy walks appear. We demonstrate that Cauchy walks emerge universally in goal-oriented tasks. We use the term "goal-oriented" when the goal is clear, but this can be achieved in different ways, which cannot be uniquely determined. We performed a simulation in which an agent observed the data generated from a probability distribution in a two-dimensional space and successively estimated the central coordinates of that probability distribution. The agent has a model of probability distribution as a hypothesis for data-generating distribution and can modify the model such that ea
    
[^52]: 多模式机器学习在车辆评分预测中的应用：基于图像、文本和参数数据。

    Multi-modal Machine Learning for Vehicle Rating Predictions Using Image, Text, and Parametric Data. (arXiv:2305.15218v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2305.15218](http://arxiv.org/abs/2305.15218)

    本文提出了一种多模式机器学习模型，它可以同时使用图像、文本和参数数据对车辆进行评分预测，增加了数据的完整性和准确性。

    

    准确的车辆评分预测可以帮助设计和配置好的车辆。本论文提出了一种多模式学习模型，它可以同时从车辆参数、文本描述和图像中学习特征，并预测五种车辆评分，包括总分和评价分数等。

    Accurate vehicle rating prediction can facilitate designing and configuring good vehicles. This prediction allows vehicle designers and manufacturers to optimize and improve their designs in a timely manner, enhance their product performance, and effectively attract consumers. However, most of the existing data-driven methods rely on data from a single mode, e.g., text, image, or parametric data, which results in a limited and incomplete exploration of the available information. These methods lack comprehensive analyses and exploration of data from multiple modes, which probably leads to inaccurate conclusions and hinders progress in this field. To overcome this limitation, we propose a multi-modal learning model for more comprehensive and accurate vehicle rating predictions. Specifically, the model simultaneously learns features from the parametric specifications, text descriptions, and images of vehicles to predict five vehicle rating scores, including the total score, critics score,
    
[^53]: 知识设计：通过知识提炼推动蛋白质设计的极限

    Knowledge-Design: Pushing the Limit of Protein Deign via Knowledge Refinement. (arXiv:2305.15151v2 [q-bio.BM] UPDATED)

    [http://arxiv.org/abs/2305.15151](http://arxiv.org/abs/2305.15151)

    本文提出了一种知识感知模块来提炼低质量残基，引入记忆检索机制实现了超过50%的训练时间节省，并取得了较好的性能表现，是蛋白质设计领域的一次创新。

    

    最近的研究表明，在蛋白质设计中，寻找折叠为所期望结构的氨基酸序列已经取得了竞争优势。然而，大多数研究忽略了预测置信度的重要性，未能覆盖广泛的蛋白质空间，并且没有融入常见的蛋白质知识。本文提出了一种知识感知模块来提炼低质量残基，并引入了一种记忆检索机制来节省超过50%的训练时间。我们在CATH、TS50和TS500数据集上对所提出的方法进行了广泛评估，结果显示我们的知识设计方法在CATH数据集上的性能超过了先前的PiFold方法约9％。具体来说，知识设计是第一个实现了...

    Recent studies have shown competitive performance in protein design that aims to find the amino acid sequence folding into the desired structure. However, most of them disregard the importance of predictive confidence, fail to cover the vast protein space, and do not incorporate common protein knowledge. After witnessing the great success of pretrained models on diverse protein-related tasks and the fact that recovery is highly correlated with confidence, we wonder whether this knowledge can push the limits of protein design further. As a solution, we propose a knowledge-aware module that refines low-quality residues. We also introduce a memory-retrieval mechanism to save more than 50\% of the training time. We extensively evaluate our proposed method on the CATH, TS50, and TS500 datasets and our results show that our Knowledge-Design method outperforms the previous PiFold method by approximately 9\% on the CATH dataset. Specifically, Knowledge-Design is the first method that achieves 
    
[^54]: 从自然语言到可验证的图像生成：传递视觉属性

    Transferring Visual Attributes from Natural Language to Verified Image Generation. (arXiv:2305.15026v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2305.15026](http://arxiv.org/abs/2305.15026)

    本文提出了一种自然语言到验证图像生成(NL2VI)方法，将自然提示转化为更适合的视觉提示，通过VQA算法进行验证，使生成的图像更加准确和与自然语言相关联，并在实验中证明了该方法的优越性。

    

    文本到图像生成方法(T2I)在生成艺术和其他创造性产品方面得到广泛应用。视觉幻觉可能是创造力受到认可的情况下的积极因素，但这些产品不适用于需要将生成的图像与复杂自然语言相关联的情况，这些语言中包括非视觉信息以及需要准确生成的文本元素。本文针对这些现象，提出了一种自然语言到验证图像生成(NL2VI)方法，将自然提示转换为更适合图像生成的视觉提示。然后，T2I模型基于视觉提示生成图像，再使用VQA算法进行验证。实验结果表明，将自然提示与NL2VI中的图像生成方法对齐，可以显著改善生成图像在自然语言中的基础，并在图像质量和字幕评估指标上优于现有方法。

    Text to image generation methods (T2I) are widely popular in generating art and other creative artifacts. While visual hallucinations can be a positive factor in scenarios where creativity is appreciated, such artifacts are poorly suited for cases where the generated image needs to be grounded in complex natural language without explicit visual elements. In this paper, we propose to strengthen the consistency property of T2I methods in the presence of natural complex language, which often breaks the limits of T2I methods by including non-visual information, and textual elements that require knowledge for accurate generation. To address these phenomena, we propose a Natural Language to Verified Image generation approach (NL2VI) that converts a natural prompt into a visual prompt, which is more suitable for image generation. A T2I model then generates an image for the visual prompt, which is then verified with VQA algorithms. Experimentally, aligning natural prompts with image generation
    
[^55]: 逻辑约束下的部分可观察和多智能体马尔可夫决策过程的最优控制

    Optimal Control of Logically Constrained Partially Observable and Multi-Agent Markov Decision Processes. (arXiv:2305.14736v1 [cs.AI])

    [http://arxiv.org/abs/2305.14736](http://arxiv.org/abs/2305.14736)

    本文介绍了一个用于部分可观察和多智能体马尔可夫决策过程的最优控制理论，能够使用时间逻辑规范表达约束，并提供了一种结构化的方法来合成策略以最大化累积奖励并保证约束条件的概率足够高。同时我们还提供了对信息不对称的多智能体设置进行最优控制的框架。

    

    自动化系统通常会产生逻辑约束，例如来自安全、操作或法规要求，可以用时间逻辑规范表达这些约束。系统状态通常是部分可观察的，可能包含具有共同目标但不同信息结构和约束的多个智能体。在本文中，我们首先引入了一个最优控制理论，用于具有有限线性时间逻辑约束的部分可观察马尔可夫决策过程（POMDP）。我们提供了一种结构化方法，用于合成策略，同时确保满足时间逻辑约束的概率足够高时最大化累积回报。我们的方法具有关于近似奖励最优性和约束满足的保证。然后我们在此基础上构建了一个对信息不对称的具有逻辑约束的多智能体设置进行最优控制的框架。我们阐述了该方法并给出了理论保证。

    Autonomous systems often have logical constraints arising, for example, from safety, operational, or regulatory requirements. Such constraints can be expressed using temporal logic specifications. The system state is often partially observable. Moreover, it could encompass a team of multiple agents with a common objective but disparate information structures and constraints. In this paper, we first introduce an optimal control theory for partially observable Markov decision processes (POMDPs) with finite linear temporal logic constraints. We provide a structured methodology for synthesizing policies that maximize a cumulative reward while ensuring that the probability of satisfying a temporal logic constraint is sufficiently high. Our approach comes with guarantees on approximate reward optimality and constraint satisfaction. We then build on this approach to design an optimal control framework for logically constrained multi-agent settings with information asymmetry. We illustrate the
    
[^56]: 内容丰富的多模态转换器训练与 LoReTTa

    Training Transitive and Commutative Multimodal Transformers with LoReTTa. (arXiv:2305.14243v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2305.14243](http://arxiv.org/abs/2305.14243)

    LoReTTa是一个自监督框架，可以在具有不同模态的数据集中转换。通过合成数据集的方法，显著提高了下游任务的性能。

    

    实践中，收集两个匹配的形态A和B或B和C的多模态数据集很困难，获得包含三个对齐形态A、B和C的数据集更加具有挑战性。我们引入了LoReTTa以应对这个未被充分研究的问题。我们的自监督框架结合了因果掩码建模和交换律和传递性的规则，可以在不同的模态中转换。我们的实验表明，这种合成显着提高了下游任务的性能。

    Collecting a multimodal dataset with two paired modalities A and B or B and C is difficult in practice. Obtaining a dataset with three aligned modalities A, B, and C is even more challenging. For example, some public medical datasets have only genetic sequences and microscopic images for one patient, and only genetic sequences and radiological images for another - but no dataset includes both microscopic and radiological images for the same patient. This makes it difficult to integrate and combine all modalities into a large pre-trained neural network. We introduce LoReTTa (Linking mOdalities with a tRansitive and commutativE pre-Training sTrAtegy) to address this understudied problem. Our self-supervised framework combines causal masked modeling with the rules of commutativity and transitivity to transition within and between different modalities. Thus, it can model the relation A -> C with A -> B -> C. Given a dataset containing only the disjoint combinations (A, B) and (B, C), we sh
    
[^57]: 文本到SQL的语言模型纠错

    Text-to-SQL Error Correction with Language Models of Code. (arXiv:2305.13073v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.13073](http://arxiv.org/abs/2305.13073)

    本论文提出了一种基于从句编辑模型的文本到SQL的语言模型纠错方法，并通过新的SQL查询表示改进了语言模型的精确匹配准确率，提高了2.4-6.5，最多提高4.3个百分点。

    

    尽管文本到SQL解析取得了进展，但当前的语义解析器仍不够准确以实际应用。本文研究如何构建自动文本到SQL纠错模型。我们注意到单词层面的编辑缺乏上下文并且有时不明确，因此提出构建从句编辑模型。此外，虽然大多数代码语言模型没有专门预训练SQL，但它们熟悉Python等编程语言中的常见数据结构和其操作。因此，我们提出了一种新的SQL查询表示及其编辑方法，更符合代码语言模型的预训练语料库。我们的错误纠错模型提高了不同解析器的精确匹配准确率，提高了2.4-6.5，并获得了两个强基线的绝对改进最多4.3个百分点。我们的代码和数据可在https://github.com/OSU-NLP-Group/Auto-SQL-Correction 上找到。

    Despite recent progress in text-to-SQL parsing, current semantic parsers are still not accurate enough for practical use. In this paper, we investigate how to build automatic text-to-SQL error correction models. Noticing that token-level edits are out of context and sometimes ambiguous, we propose building clause-level edit models instead. Besides, while most language models of code are not specifically pre-trained for SQL, they know common data structures and their operations in programming languages such as Python. Thus, we propose a novel representation for SQL queries and their edits that adheres more closely to the pre-training corpora of language models of code. Our error correction model improves the exact set match accuracy of different parsers by 2.4-6.5 and obtains up to 4.3 point absolute improvement over two strong baselines. Our code and data are available at https://github.com/OSU-NLP-Group/Auto-SQL-Correction.
    
[^58]: 借助深度强化学习的贫民窟道路规划

    Road Planning for Slums via Deep Reinforcement Learning. (arXiv:2305.13060v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2305.13060](http://arxiv.org/abs/2305.13060)

    本文介绍了一种基于深度强化学习的方法，用于自动布局贫民窟道路。通过掩码策略优化，可使可达性提高14.3％，对现有基线方法具有明显改进。

    

    数百万贫民窟居民由于贫民窟内不足的道路基础设施而遭受城市服务无法访问的困境，而贫民窟道路规划对城市的可持续发展至关重要。现有的重组或启发式方法要么耗时，不能推广到不同的贫民窟，要么在可达性和建设成本方面产生次优的道路规划。本文提出了一种基于深度强化学习的方法，用于自动布局贫民窟道路。我们提出了一个通用图模型，用于捕获贫民窟的拓扑结构，并设计了一种新颖的图神经网络，用于选择计划道路的位置。通过掩码策略优化，我们的模型可以生成连接贫民窟地点的道路规划，以最小的建设成本。对不同国家的真实贫民窟进行大量实验验证了我们模型的有效性，可使可达性提高14.3％，对现有基线方法具有明显改进。

    Millions of slum dwellers suffer from poor accessibility to urban services due to inadequate road infrastructure within slums, and road planning for slums is critical to the sustainable development of cities. Existing re-blocking or heuristic methods are either time-consuming which cannot generalize to different slums, or yield sub-optimal road plans in terms of accessibility and construction costs. In this paper, we present a deep reinforcement learning based approach to automatically layout roads for slums. We propose a generic graph model to capture the topological structure of a slum, and devise a novel graph neural network to select locations for the planned roads. Through masked policy optimization, our model can generate road plans that connect places in a slum at minimal construction costs. Extensive experiments on real-world slums in different countries verify the effectiveness of our model, which can significantly improve accessibility by 14.3% against existing baseline metho
    
[^59]: 多智能体真实世界展示中强化学习的自适应行动监督

    Adaptive action supervision in reinforcement learning from real-world multi-agent demonstrations. (arXiv:2305.13030v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2305.13030](http://arxiv.org/abs/2305.13030)

    本文提出了一种从多智能体场景真实世界展示中进行强化学习的自适应行动监督方法，实现了在复制和推广之间平衡的 RL 模型。

    

    在各种科学和工程领域中，对真实世界生物多智能体进行建模是一个基本问题。强化学习（RL）是在网络空间中生成灵活和多样化行为的强大框架；然而，在建模真实世界生物多智能体时，在源（即真实世界数据）和目标（即 RL 的网络空间）之间存在域差异，并且源环境参数通常是未知的。在本文中，我们提出了一种从多智能体场景的真实世界展示中进行 RL 的自适应行动监督的方法。我们采用结合 RL 和监督学习的方法，通过选择基于动态时间扭曲的演示动作来在 RL 中利用未知源动态的信息。这种方法可以轻松应用于许多现有的神经网络架构，并为我们提供一个在复制和推广之间平衡的 RL 模型。

    Modeling of real-world biological multi-agents is a fundamental problem in various scientific and engineering fields. Reinforcement learning (RL) is a powerful framework to generate flexible and diverse behaviors in cyberspace; however, when modeling real-world biological multi-agents, there is a domain gap between behaviors in the source (i.e., real-world data) and the target (i.e., cyberspace for RL), and the source environment parameters are usually unknown. In this paper, we propose a method for adaptive action supervision in RL from real-world demonstrations in multi-agent scenarios. We adopt an approach that combines RL and supervised learning by selecting actions of demonstrations in RL based on the minimum distance of dynamic time warping for utilizing the information of the unknown source dynamics. This approach can be easily applied to many existing neural network architectures and provide us with an RL model balanced between reproducibility as imitation and generalization ab
    
[^60]: 基于概率集成神经网络动态学习的主动探索和不确定性感知的机器人控制

    Bridging Active Exploration and Uncertainty-Aware Deployment Using Probabilistic Ensemble Neural Network Dynamics. (arXiv:2305.12240v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2305.12240](http://arxiv.org/abs/2305.12240)

    本文提出了一个基于概率集成神经网络动态模型的统一机器人控制框架，用于桥接主动探索和不确定性感知。该方法在几个基准任务上表现出优异的效果。

    

    近年来，机器学习-based的机器人控制因其在解决实际环境中的复杂任务的能力而引起了重视。 随着机器学习算法和计算能力的进步，该方法越来越重要，以通过学习未知或部分已知的机器人动态来解决机器人控制中的挑战性问题。 主动探索是数据有效收集和最小化人类监督的关键，它使机器人指引自己到导致最高信息增益的状态。 同样，不确定性感知是机器人控制中一个不断增长的关注点，因为由所学模型提供支持的不确定动作可能导致不稳定的运动或失败。 但是，主动探索和不确定性感知已经独立研究，并且缺乏无缝集成它们的文献。 本文提出了一个统一的基于模型的强化学习框架，用于桥接机器人控制中的主动探索和不确定性感知。 该框架使用概率集成神经网络动态模型来捕获所学系统动态中的不确定性，并引导机器人在避免不确定区域的同时高效地探索状态空间。 该提出的方法在几个基准任务上表现优于其他最先进的方法，证明了统一框架的有效性。

    In recent years, learning-based control in robotics has gained significant attention due to its capability to address complex tasks in real-world environments. With the advances in machine learning algorithms and computational capabilities, this approach is becoming increasingly important for solving challenging control problems in robotics by learning unknown or partially known robot dynamics. Active exploration, in which a robot directs itself to states that yield the highest information gain, is essential for efficient data collection and minimizing human supervision. Similarly, uncertainty-aware deployment has been a growing concern in robotic control, as uncertain actions informed by the learned model can lead to unstable motions or failure. However, active exploration and uncertainty-aware deployment have been studied independently, and there is limited literature that seamlessly integrates them. This paper presents a unified model-based reinforcement learning framework that brid
    
[^61]: 后验解释可以提高语言模型的性能

    Post Hoc Explanations of Language Models Can Improve Language Models. (arXiv:2305.11426v1 [cs.CL])

    [http://arxiv.org/abs/2305.11426](http://arxiv.org/abs/2305.11426)

    本文提出了一种新的框架AMPLIFY，利用后验解释自动化生成原因，并在多个数据集和任务上显著提高现有语言模型的性能。

    

    大型语言模型在执行复杂任务方面表现出了非凡的能力。最近的研究显示，在上下文学习过程中加入人类注释的原理（例如，思维链提示）可以显著提高这些模型的性能，特别是在需要推理能力的任务上。然而，这样的原理加入在可扩展性方面存在挑战，因为这需要高度的人工参与。本文提出了一种新框架，即通过利用后验解释的上下文学习来放大模型性能，来解决上述挑战。为此，我们利用后验解释方法的结果，该方法输出称为属性分数（解释）的值，用于捕获每个输入特征对模型预测的影响。更具体地说，我们构建了自动化的自然语言原理，其中包含从属性分数中获得的信息，以便用户可以更好地理解模型的决策。实验结果表明，AMPLIFY可以在多个数据集和任务上显著提高现有语言模型的性能。

    Large Language Models (LLMs) have demonstrated remarkable capabilities in performing complex tasks. Moreover, recent research has shown that incorporating human-annotated rationales (e.g., Chain-of- Thought prompting) during in-context learning can significantly enhance the performance of these models, particularly on tasks that require reasoning capabilities. However, incorporating such rationales poses challenges in terms of scalability as this requires a high degree of human involvement. In this work, we present a novel framework, Amplifying Model Performance by Leveraging In-Context Learning with Post Hoc Explanations (AMPLIFY), which addresses the aforementioned challenges by automating the process of rationale generation. To this end, we leverage post hoc explanation methods which output attribution scores (explanations) capturing the influence of each of the input features on model predictions. More specifically, we construct automated natural language rationales that embed insi
    
[^62]: 自动驾驶和智能车辆的里程碑 Part I：控制、计算机系统设计、通信、高精度地图、测试和人类行为

    Milestones in Autonomous Driving and Intelligent Vehicles Part \uppercase\expandafter{\romannumeral1}: Control, Computing System Design, Communication, HD Map, Testing, and Human Behaviors. (arXiv:2305.11239v1 [cs.AI])

    [http://arxiv.org/abs/2305.11239](http://arxiv.org/abs/2305.11239)

    本次论文总结了自动驾驶和智能车辆中关于控制、计算机系统设计、通信、高精度地图、测试和人类行为的发展情况和未来研究方向。

    

    自动驾驶(AD)和智能车辆(IV)的兴趣正在迅速增长，因为它们带来的便捷、安全和经济效益。虽然一些调查已经回顾了这个领域的研究成果，但它们仍然限于特定的任务，并缺乏在未来的系统总结和研究方向。我们的工作分为3个独立的文章，第一部分是对AD和IV的总体技术进行调查，包括历史、总结里程碑以及提供前瞻性、伦理和未来研究方向。这是第二部分(Part I)的技术调查，用于审查IV中控制、计算机系统设计、通信、高清地图、测试和人类行为的发展情况。此外，第三部分(Part II)将审查感知和规划部分。本次调查的目的是提供关于AD和IV领域技术进展和挑战的全面和最新的概述。

    Interest in autonomous driving (AD) and intelligent vehicles (IVs) is growing at a rapid pace due to the convenience, safety, and economic benefits. Although a number of surveys have reviewed research achievements in this field, they are still limited in specific tasks and lack systematic summaries and research directions in the future. Our work is divided into 3 independent articles and the first part is a Survey of Surveys (SoS) for total technologies of AD and IVs that involves the history, summarizes the milestones, and provides the perspectives, ethics, and future research directions. This is the second part (Part \uppercase\expandafter{\romannumeral1} for this technical survey) to review the development of control, computing system design, communication, High Definition map (HD map), testing, and human behaviors in IVs. In addition, the third part (Part \uppercase\expandafter{\romannumeral2} for this technical survey) is to review the perception and planning sections. The objecti
    
[^63]: 贝叶斯重整化

    Bayesian Renormalization. (arXiv:2305.10491v1 [hep-th])

    [http://arxiv.org/abs/2305.10491](http://arxiv.org/abs/2305.10491)

    本文提出了一种基于信息论的贝叶斯统计模型的重整化方法，使用Fisher度量定义了一个相关长度作为紧密相关的概率分布点之间的可分辨性(RG)尺度，在统计推断实验中，可以得到某个系统最大特异性观察数量的代理。贝叶斯重整化方法为给定系统准备一个在上述尺度上精度有限的有效模型，这个尺度可以被解释为当前实验装置可以探测到的最大能量。贝叶斯重整化提出了一种发现和表征基本物理理论的新框架。

    

    本文提出了一种完全基于信息论的贝叶斯统计模型的重整化方法，称为贝叶斯重整化。贝叶斯重整化的主要思想是使用Fisher度量来定义一个相关长度，这个长度起到了紧密相关的概率分布点之间的可分辨性(RG)尺度。这个RG尺度可以被解释为在统计推断实验中对于一个给定系统可以得到的最大特异性观察数量的代理。贝叶斯重整化方法的作用是为给定系统准备一个在上述尺度上精度有限的有效模型。在将贝叶斯重整化方法应用于物理系统时，这个由信息论出现的RG尺度自然地被识别为当前实验装置可以探测到的最大能量，因此，贝叶斯重整化提出了一种发现和表征基本物理理论的新框架。

    In this note we present a fully information theoretic approach to renormalization inspired by Bayesian statistical inference, which we refer to as Bayesian Renormalization. The main insight of Bayesian Renormalization is that the Fisher metric defines a correlation length that plays the role of an emergent RG scale quantifying the distinguishability between nearby points in the space of probability distributions. This RG scale can be interpreted as a proxy for the maximum number of unique observations that can be made about a given system during a statistical inference experiment. The role of the Bayesian Renormalization scheme is subsequently to prepare an effective model for a given system up to a precision which is bounded by the aforementioned scale. In applications of Bayesian Renormalization to physical systems, the emergent information theoretic scale is naturally identified with the maximum energy that can be probed by current experimental apparatus, and thus Bayesian Renormali
    
[^64]: 人们交谈，AI倾听：电子病历中污名化语言对AI判断的影响

    People Talking and AI Listening: How Stigmatizing Language in EHR Notes Affect AI Performance. (arXiv:2305.10201v1 [cs.AI])

    [http://arxiv.org/abs/2305.10201](http://arxiv.org/abs/2305.10201)

    本文研究了电子病历中污名化语言对基于Transformer的深度学习模型和可解释AI(XAI)技术进行死亡预测的影响。发现临床医生所写的SL会对AI性能表现不利，尤其是在黑人患者中表现更为明显，强调了理解偏见对下游AI性能的影响的重要性，以开发更具公平和正义的医疗系统。

    

    电子病历(EHRs)是期望中的人工智能(AI)-驱动的医疗转型的重要数据来源。然而，反映在EHR笔记中的临床医师偏见可能会导致AI模型继承并放大这些偏见，从而不断加剧健康上的不平等。本研究调查了EHR笔记中污名化语言(SL)对基于Transformer的深度学习模型和可解释AI(XAI)技术进行死亡预测的影响。我们的研究发现，临床医生所写的SL不利于AI的性能表现，尤其是在黑人患者中表现更为明显，突出了SL作为AI模型发展中种族差异的一种来源。为探索一种操作上有效的缓解SL影响的方法，我们研究了临床医生协作网络中SL生成的模式，发现中央医生对AI模型中的种族差异具有更强的影响力。我们发现，删除中央临床医生撰写的SL是相对于随机选择临床医生而言，缓解SL对AI性能影响的更为有效的策略。我们的研究强调了理解反映在EHR笔记中的临床医师偏见对下游AI性能的影响的重要性，以开发更具公平和正义的医疗系统。

    Electronic health records (EHRs) serve as an essential data source for the envisioned artificial intelligence (AI)-driven transformation in healthcare. However, clinician biases reflected in EHR notes can lead to AI models inheriting and amplifying these biases, perpetuating health disparities. This study investigates the impact of stigmatizing language (SL) in EHR notes on mortality prediction using a Transformer-based deep learning model and explainable AI (XAI) techniques. Our findings demonstrate that SL written by clinicians adversely affects AI performance, particularly so for black patients, highlighting SL as a source of racial disparity in AI model development. To explore an operationally efficient way to mitigate SL's impact, we investigate patterns in the generation of SL through a clinicians' collaborative network, identifying central clinicians as having a stronger impact on racial disparity in the AI model. We find that removing SL written by central clinicians is a more 
    
[^65]: ConvXAI：通过对话提供异构的AI解释，支持人机科技写作

    ConvXAI: Delivering Heterogeneous AI Explanations via Conversations to Support Human-AI Scientific Writing. (arXiv:2305.09770v1 [cs.HC])

    [http://arxiv.org/abs/2305.09770](http://arxiv.org/abs/2305.09770)

    ConvXAI是一个基于对话的XAI系统，它集成了多种XAI类型，并将实际用户需求嵌入设计中，以提高实用性。

    

    尽管已经提出了各种各样的人工智能解释（XAI）方法来解释AI系统，但目前的方法是否对人类实用仍存在不一致的发现。为了改善XAI方法的实用性，一系列研究确定了现实世界中多样化和动态的用户需求与现有XAI方法之间的差距。虽然之前的研究设想将多种XAI方法集成到通用XAI界面（例如，基于对话或GUI的XAI系统）中以减轻这些差距，但缺少针对这些系统如何设计以满足实际用户需求的研究。在本研究中，我们提出了ConvXAI，这是一个基于对话的XAI系统，它结合了多种XAI类型，并赋予用户通过通用的XAI对话界面提出各种XAI问题的能力。特别地，我们创新地将实际用户需求（即，基于格式研究的四个原则）嵌入ConvXAI设计中，以提高实用性。

    While various AI explanation (XAI) methods have been proposed to interpret AI systems, whether the state-of-the-art XAI methods are practically useful for humans remains inconsistent findings. To improve the usefulness of XAI methods, a line of studies identifies the gaps between the diverse and dynamic real-world user needs with the status quo of XAI methods. Although prior studies envision mitigating these gaps by integrating multiple XAI methods into the universal XAI interfaces (e.g., conversational or GUI-based XAI systems), there is a lack of work investigating how these systems should be designed to meet practical user needs. In this study, we present ConvXAI, a conversational XAI system that incorporates multiple XAI types, and empowers users to request a variety of XAI questions via a universal XAI dialogue interface. Particularly, we innovatively embed practical user needs (i.e., four principles grounding on the formative study) into ConvXAI design to improve practical useful
    
[^66]: 基于随机池化的可证明多实例深度AUC最大化方法

    Provable Multi-instance Deep AUC Maximization with Stochastic Pooling. (arXiv:2305.08040v1 [cs.LG])

    [http://arxiv.org/abs/2305.08040](http://arxiv.org/abs/2305.08040)

    本文提出了在多实例学习中使用深度AUC最大化（DAM）的方法，并根据包含大量实例的情况下训练的计算挑战，提出了一种基于方差减少的随机池化方法，使得只需对每个包进行少量采样即可计算MIDAM模型，提高了效率和准确性。

    

    本文提出了一种深度AUC最大化（DAM）的新型应用，用于多实例学习（MIL），其中将单个类标签分配给一组实例（例如，患者的多个CT扫描的多个2D切片）。我们在DAM的背景下解决了MIL中被忽略但非常重要的计算挑战，即包大小过大，无法在反向传播时加载到GPU内存中，这是MIL标准池化方法所必需的。为了解决这个问题，我们提出了一种基于方差减少的随机池化方法，这种方法可以将关于汇聚预测的损失函数构造为多级组合函数。通过综合随机组合优化和非凸极小最大优化技术，我们提出了一种统一且可证明的多实例DAM（MIDAM）算法，其使用随机平滑最大池化或随机注意力池化，仅对每个包对应的实例进行少量采样来计算 sto。

    This paper considers a novel application of deep AUC maximization (DAM) for multi-instance learning (MIL), in which a single class label is assigned to a bag of instances (e.g., multiple 2D slices of a CT scan for a patient). We address a neglected yet non-negligible computational challenge of MIL in the context of DAM, i.e., bag size is too large to be loaded into {GPU} memory for backpropagation, which is required by the standard pooling methods of MIL. To tackle this challenge, we propose variance-reduced stochastic pooling methods in the spirit of stochastic optimization by formulating the loss function over the pooled prediction as a multi-level compositional function. By synthesizing techniques from stochastic compositional optimization and non-convex min-max optimization, we propose a unified and provable muli-instance DAM (MIDAM) algorithm with stochastic smoothed-max pooling or stochastic attention-based pooling, which only samples a few instances for each bag to compute a sto
    
[^67]: 自主GIS：下一代基于人工智能的GIS

    Autonomous GIS: the next-generation AI-powered GIS. (arXiv:2305.06453v1 [cs.AI])

    [http://arxiv.org/abs/2305.06453](http://arxiv.org/abs/2305.06453)

    自主GIS是一种AI动力地理信息系统，采用大型语言模型作为推理核心，具有自动空间数据收集、分析和可视化的能力，旨在实现五个自主目标：自动生成、自组织、自验证、自执行和自生长。

    

    大型语言模型（LLM）如 ChatGPT ，展示了对人类自然语言的强大理解能力，在推理、创造性写作、代码生成、翻译和信息检索等领域得到了应用与探索。我们采用LLM作为推理核心，提出了一种称之为“自主GIS”的AI动力地理信息系统（GIS），以自动空间数据收集、分析和可视化来解决空间问题。我们设想，自主GIS将需要实现五个自主目标，包括自动生成、自组织、自验证、自执行和自生长。我们引入了自主GIS的设计原则来实现这五个自主目标，从信息充分性、LLM能力和代理架构三个方面进行。我们开发了一个原型系统称为LLM-Geo ，它在Python环境中使用GPT-4 API。

    Large Language Models (LLMs), such as ChatGPT, demonstrate a strong understanding of human natural language and have been explored and applied in various fields, including reasoning, creative writing, code generation, translation, and information retrieval. By adopting LLM as the reasoning core, we propose Autonomous GIS, an AI-powered geographic information system (GIS) that leverages the LLM's general abilities in natural language understanding, reasoning and coding for addressing spatial problems with automatic spatial data collection, analysis and visualization. We envision that autonomous GIS will need to achieve five autonomous goals including self-generating, self-organizing, self-verifying, self-executing, and self-growing. We introduce the design principles of autonomous GIS to achieve these five autonomous goals from the aspects of information sufficiency, LLM ability, and agent architecture. We developed a prototype system called LLM-Geo using GPT-4 API in a Python environme
    
[^68]: GPT-NAS: 以生成式预训练模型为基础的神经架构搜索

    GPT-NAS: Neural Architecture Search with the Generative Pre-Trained Model. (arXiv:2305.05351v1 [cs.CV] CROSS LISTED)

    [http://arxiv.org/abs/2305.05351](http://arxiv.org/abs/2305.05351)

    GPT-NAS使用生成式预训练模型优化神经架构搜索，通过提出近似的架构组件减小搜索空间，并明显优于其他NAS方法。

    

    神经架构搜索(NAS)已经成为了一种自动设计最优神经网络架构的有效方法之一。虽然一些人工设计的神经网络已经在多项任务中取得了人类水平的表现，但在NAS方法中很少出现这类成果，主要原因在于神经架构的搜索空间太大了，导致NAS算法效率低下。这项工作提出了一种新的架构搜索算法，称为GPT-NAS，通过生成式预训练模型来优化神经架构。在GPT-NAS中，我们假设一个在大规模语料库上预训练的生成模型能够学习构建神经架构的基本规律。因此，GPT-NAS利用生成式预训练模型来提出合理的架构组件，从而大大减少了搜索空间，引入了搜索过程中的先验知识。广泛的实验结果表明，我们的GPT-NAS方法明显优于其他NAS方法。

    Neural Architecture Search (NAS) has emerged as one of the effective methods to design the optimal neural network architecture automatically. Although neural architectures have achieved human-level performances in several tasks, few of them are obtained from the NAS method. The main reason is the huge search space of neural architectures, making NAS algorithms inefficient. This work presents a novel architecture search algorithm, called GPT-NAS, that optimizes neural architectures by Generative Pre-Trained (GPT) model. In GPT-NAS, we assume that a generative model pre-trained on a large-scale corpus could learn the fundamental law of building neural architectures. Therefore, GPT-NAS leverages the generative pre-trained (GPT) model to propose reasonable architecture components given the basic one. Such an approach can largely reduce the search space by introducing prior knowledge in the search process. Extensive experimental results show that our GPT-NAS method significantly outperforms
    
[^69]: 语义嵌入深度神经网络：一种提升多标签图像分类性能的通用方法。

    Semantic Embedded Deep Neural Network: A Generic Approach to Boost Multi-Label Image Classification Performance. (arXiv:2305.05228v1 [cs.CV])

    [http://arxiv.org/abs/2305.05228](http://arxiv.org/abs/2305.05228)

    本研究提出了一种通用的语义嵌入深度神经网络，通过空间感知的语义特征和基于通道的注意力模型来提高多标签预测的模型性能，平均相对改进达到15.27%。

    

    精细的多标签分类模型在亚马逊生产功能中具有广泛的应用，例如基于视觉的标签预测，从时尚属性检测到品牌识别。实现这些分类任务的一个挑战是野外视觉背景信号，其中包含混淆模型的无关像素，使模型难以专注于感兴趣区域并根据该特定区域进行预测。在本文中，我们介绍了一种通用的语义嵌入深度神经网络，应用空间感知的语义特征，并结合基于通道的注意力模型来利用定位引导，以提高多标签预测的模型性能。与基线方法相比，我们观察到所有标签的AUC得分的平均相对改进为15.27%。核心实验和消融研究涉及对Instagram时尚服装的多标签时尚属性分类进行的。

    Fine-grained multi-label classification models have broad applications in Amazon production features, such as visual based label predictions ranging from fashion attribute detection to brand recognition. One challenge to achieve satisfactory performance for those classification tasks in real world is the wild visual background signal that contains irrelevant pixels which confuses model to focus onto the region of interest and make prediction upon the specific region. In this paper, we introduce a generic semantic- embedding deep neural network to apply the spatial awareness semantic feature incorporating a channel- wise attention based model to leverage the localization guidance to boost model performance for multi- label prediction. We observed an Avg.relative improvement of 15.27% in terms of AUC score across all labels compared to the baseline approach. Core experiment and ablation studies involve multi-label fashion attribute classification performed on Instagram fashion apparels' 
    
[^70]: 数据集压缩综合研究：性能、隐私、鲁棒性以及公平性

    A Comprehensive Study on Dataset Distillation: Performance, Privacy, Robustness and Fairness. (arXiv:2305.03355v1 [cs.LG])

    [http://arxiv.org/abs/2305.03355](http://arxiv.org/abs/2305.03355)

    本研究对当前最先进的数据集压缩方法进行了全面评估，发现其存在隐私风险并可能放大模型的不公平性，提供了大规模的基准测试框架。

    

    数据集压缩旨在将原始数据集的丰富特征编码成小型数据集，是一种加速神经网络训练和相关研究的有前途的方法。已经提出了不同的方法来改善压缩图像的信息性和泛化性能。然而，目前还没有从安全性角度全面分析这一技术的工作，并且对潜在风险缺乏系统理解。在本文中，我们进行了大量实验，评估了当前最先进的数据集压缩方法。我们成功使用成员推理攻击来显示仍然存在隐私风险。本文还表明，数据集压缩在模型鲁棒性方面可能会产生不同程度的影响，并在进行预测时放大类别间的模型不公平性。本研究为数据集压缩评估提供了大规模的基准测试框架。

    The aim of dataset distillation is to encode the rich features of an original dataset into a tiny dataset. It is a promising approach to accelerate neural network training and related studies. Different approaches have been proposed to improve the informativeness and generalization performance of distilled images. However, no work has comprehensively analyzed this technique from a security perspective and there is a lack of systematic understanding of potential risks. In this work, we conduct extensive experiments to evaluate current state-of-the-art dataset distillation methods. We successfully use membership inference attacks to show that privacy risks still remain. Our work also demonstrates that dataset distillation can cause varying degrees of impact on model robustness and amplify model unfairness across classes when making predictions. This work offers a large-scale benchmarking framework for dataset distillation evaluation.
    
[^71]: 视觉与定义相遇：融合词义信息的无监督视觉词义消歧

    Vision Meets Definitions: Unsupervised Visual Word Sense Disambiguation Incorporating Gloss Information. (arXiv:2305.01788v1 [cs.CL])

    [http://arxiv.org/abs/2305.01788](http://arxiv.org/abs/2305.01788)

    本文提出了一种无监督的视觉词义消歧方法，通过引入外部词汇知识库的词义信息来解决原来图像-文本匹配模型中的多义词问题。采用贝叶斯推断来加入词义定义，并通过与上下文相关的 GPT-3 定义生成方法，成功解决了词典外问题。

    

    视觉词义消歧是一项任务，旨在找到最准确地描述给定上下文中目标词正确意义的图像。以往的图像-文本匹配模型往往受到词义多义性的影响。本文介绍了一种无监督的视觉词义消歧方法，该方法使用了外部词汇知识库的词汇信息，特别是词义定义。具体而言，我们建议在没有提供答案的词义信息时，采用贝叶斯推断来加入词义定义。此外，为了改进词典外问题，我们提出了一种与上下文相关的GPT-3定义生成方法。实验结果表明，我们的基于贝叶斯推断的方法明显提高了视觉词义消歧的性能。此外，我们的上下文相关定义生成方法在词典外例子上取得了显著的性能提升，表现优于现有的定义生成方法。

    Visual Word Sense Disambiguation (VWSD) is a task to find the image that most accurately depicts the correct sense of the target word for the given context. Previously, image-text matching models often suffered from recognizing polysemous words. This paper introduces an unsupervised VWSD approach that uses gloss information of an external lexical knowledge-base, especially the sense definitions. Specifically, we suggest employing Bayesian inference to incorporate the sense definitions when sense information of the answer is not provided. In addition, to ameliorate the out-of-dictionary (OOD) issue, we propose a context-aware definition generation with GPT-3. Experimental results show that the VWSD performance significantly increased with our Bayesian inference-based approach. In addition, our context-aware definition generation achieved prominent performance improvement in OOD examples exhibiting better performance than the existing definition generation method. We will publish source 
    
[^72]: Chronosymbolic Learning: 结合符号推理与归纳学习的有效CHC求解方法

    Chronosymbolic Learning: Efficient CHC Solving with Symbolic Reasoning and Inductive Learning. (arXiv:2305.01206v1 [cs.LO])

    [http://arxiv.org/abs/2305.01206](http://arxiv.org/abs/2305.01206)

    Chronosymbolic Learning是一个简单而有效的框架，将符号推理和数据驱动方法相结合，用于高效地解决CHC系统。实验证明它在288个基准测试上表现出优异的结果，包括许多具有非线性整数算术的实例。

    

    CHC (Constrained Horn Clauses)的求解是许多验证和分析任务的基本挑战。数据驱动法在提高CHC求解效率方面显示出巨大的潜力，同时避免了手动创建和调整各种启发式方法的繁琐工作。但数据驱动的CHC求解器与基于符号推理的求解器之间存在巨大的性能差距。在这项工作中，我们开发了一个简单而有效的框架，"Chronosymbolic Learning"，它将符号信息和数值数据点统一起来，将CHC系统高效地求解。我们还展示了Chronosymbolic Learning的一个简单实例，其中包括一个数据驱动学习器和一个BMC样式的推理器。尽管该工具非常简单，但实验结果表明其效力和健壮性。它在由288个基准测试组成的数据集上胜过了最先进的CHC求解器，其中包括许多包含非线性整数算术的实例。

    Solving Constrained Horn Clauses (CHCs) is a fundamental challenge behind a wide range of verification and analysis tasks. Data-driven approaches show great promise in improving CHC solving without the painstaking manual effort of creating and tuning various heuristics. However, a large performance gap exists between data-driven CHC solvers and symbolic reasoning-based solvers. In this work, we develop a simple but effective framework, "Chronosymbolic Learning", which unifies symbolic information and numerical data points to solve a CHC system efficiently. We also present a simple instance of Chronosymbolic Learning with a data-driven learner and a BMC-styled reasoner. Despite its great simplicity, experimental results show the efficacy and robustness of our tool. It outperforms state-of-the-art CHC solvers on a dataset consisting of 288 benchmarks, including many instances with non-linear integer arithmetics.
    
[^73]: 面向遥感时序数据的轻量级预训练Transformer

    Lightweight, Pre-trained Transformers for Remote Sensing Timeseries. (arXiv:2304.14065v1 [cs.CV])

    [http://arxiv.org/abs/2304.14065](http://arxiv.org/abs/2304.14065)

    设计针对远程传感器数据的自监督学习模型和训练技术，可以得到表现更好且更小的模型。预训练的遥感时间序列Transformer（Presto）在几个遥感基准测试中实现了最先进的结果。

    

    远程传感数据的机器学习算法在社会相关应用方面具有广泛的应用，但用于训练这些算法的标签可能很难或不可能获得。这个挑战已经推动了自监督学习领域的研究，旨在通过遥感数据解锁在标记数据集较小的地理位置或应用领域中使用机器学习。我们展示了为遥感数据设计模型和自监督训练技术可以得到更小、更优秀的模型。我们介绍了Remote Sensing Transformer（Presto），它是一种基于Transformer的模型，使用新颖的自监督目标对遥感时间序列数据进行预训练。我们的实验表明，与在自然图像上训练的可比模型相比，Presto在几个遥感基准测试中实现了最先进的结果，同时需要数量级更少的参数。

    Machine learning algorithms for parsing remote sensing data have a wide range of societally relevant applications, but labels used to train these algorithms can be difficult or impossible to acquire. This challenge has spurred research into self-supervised learning for remote sensing data aiming to unlock the use of machine learning in geographies or application domains where labelled datasets are small. Current self-supervised learning approaches for remote sensing data draw significant inspiration from techniques applied to natural images. However, remote sensing data has important differences from natural images -- for example, the temporal dimension is critical for many tasks and data is collected from many complementary sensors. We show that designing models and self-supervised training techniques specifically for remote sensing data results in both smaller and more performant models. We introduce the Pretrained Remote Sensing Transformer (Presto), a transformer-based model pre-tr
    
[^74]: 使用指令调整的LLM和潜在扩散模型生成文本到音频

    Text-to-Audio Generation using Instruction-Tuned LLM and Latent Diffusion Model. (arXiv:2304.13731v1 [eess.AS])

    [http://arxiv.org/abs/2304.13731](http://arxiv.org/abs/2304.13731)

    本研究提出了一种使用指令调整的LLM Flan-T5作为文本编码器和基于潜在扩散模型(LDM)的方法TANGO生成文本到音频(TTA)的新方法，在AudioCaps测试集上表现优于先进的AudioLDM。

    

    最近的大型语言模型(LLM)的巨大规模允许许多有趣的属性，比如，基于指令和思路链的微调，在许多自然语言处理(NLP)任务中显着提高了零次和少量训练样本的性能。受到这些成功的启发，我们采用了这样一种经过指令调整的LLM Flan-T5作为文本编码器，用于文本到音频(TTA)生成任务——目标是根据其文本描述生成音频。之前关于TTA的工作要么预先训练一个联合的文本-音频编码器，要么使用一个非指令调谐的模型，如T5。因此，我们基于潜在扩散模型(LDM)的方法TANGO在AudioCaps测试集上表现出比最先进的AudioLDM更好的大多数指标，并在其余指标上持平，尽管我们使用了63倍小的数据集来训练LDM，并保持文本编码器不变。这种改进可能还归因于采用基于音频压力级的混音训练集增强。

    The immense scale of the recent large language models (LLM) allows many interesting properties, such as, instruction- and chain-of-thought-based fine-tuning, that has significantly improved zero- and few-shot performance in many natural language processing (NLP) tasks. Inspired by such successes, we adopt such an instruction-tuned LLM Flan-T5 as the text encoder for text-to-audio (TTA) generation -- a task where the goal is to generate an audio from its textual description. The prior works on TTA either pre-trained a joint text-audio encoder or used a non-instruction-tuned model, such as, T5. Consequently, our latent diffusion model (LDM)-based approach TANGO outperforms the state-of-the-art AudioLDM on most metrics and stays comparable on the rest on AudioCaps test set, despite training the LDM on a 63 times smaller dataset and keeping the text encoder frozen. This improvement might also be attributed to the adoption of audio pressure level-based sound mixing for training set augmenta
    
[^75]: 大型语言模型对齐的基本限制

    Fundamental Limitations of Alignment in Large Language Models. (arXiv:2304.11082v1 [cs.CL])

    [http://arxiv.org/abs/2304.11082](http://arxiv.org/abs/2304.11082)

    本文通过提出一种理论方法——行为期望边界（BEB），展示了大型语言模型中对齐的基本限制，并证明任何对齐过程都无法根除不希望的行为，这对于防止恶意攻击是不安全的。

    

    开发与人交互的语言模型的重要方面是对齐其行为，使其对其人类用户有用且无害。这通常通过调整模型的方式来实现，以增强所需的行为并抑制不希望的行为。在本文中，我们提出了一种名为行为期望边界(BEB)的理论方法，它允许我们正式研究大型语言模型中的几个内在特征和对齐的限制。重要的是，我们证明对于任何具有被该模型表现出的有限概率的行为，都存在可以触发模型输出此行为的提示，其概率随提示的长度增加而增加。这意味着任何减弱不希望的行为但未将其完全消除的对齐过程都无法抵御针对性攻击。此外，我们的框架提示了领先的

    An important aspect in developing language models that interact with humans is aligning their behavior to be useful and unharmful for their human users. This is usually achieved by tuning the model in a way that enhances desired behaviors and inhibits undesired ones, a process referred to as alignment. In this paper, we propose a theoretical approach called Behavior Expectation Bounds (BEB) which allows us to formally investigate several inherent characteristics and limitations of alignment in large language models. Importantly, we prove that for any behavior that has a finite probability of being exhibited by the model, there exist prompts that can trigger the model into outputting this behavior, with probability that increases with the length of the prompt. This implies that any alignment process that attenuates undesired behavior but does not remove it altogether, is not safe against adversarial prompting attacks. Furthermore, our framework hints at the mechanism by which leading al
    
[^76]: ChatGPT4PCG比赛：科学鸟角色级生成

    ChatGPT4PCG Competition: Character-like Level Generation for Science Birds. (arXiv:2303.15662v1 [cs.AI])

    [http://arxiv.org/abs/2303.15662](http://arxiv.org/abs/2303.15662)

    本论文介绍了举办在2023 IEEE游戏会议上的第一届ChatGPT4PCG比赛，目标是让ChatGPT生成具有高稳定性和类似角色的特质来生成具有科学鸟角色级水平的关卡。

    

    本文介绍了2023年IEEE游戏会议上的第一届ChatGPT4PCG比赛。本次比赛的目标是让参赛者通过创造性和提示工程技能，为ChatGPT创建有效的提示，使其能够具有高稳定性和类似角色的特质来生成具有科学鸟角色级水平的关卡。为了降低参赛门槛，我们将任务限制在生成大写英文字母。参赛作品的质量由其稳定性和与给定字符的相似性决定。给参赛者提供了一个样例提示供参考。

    This paper presents the first ChatGPT4PCG Competition at the 2023 IEEE Conference on Games. The objective of this competition is for participants to create effective prompts for ChatGPT--enabling it to generate Science Birds levels with high stability and character-like qualities--fully using their creativity as well as prompt engineering skills. ChatGPT is a conversational agent developed by OpenAI. Science Birds is selected as the competition platform because designing an Angry Birds-like level is not a trivial task due to the in-game gravity; the playability of the levels is determined by their stability. To lower the entry barrier to the competition, we limit the task to the generation of capitalized English alphabetical characters. Here, the quality of the generated levels is determined by their stability and similarity to the given characters. A sample prompt is provided to participants for their reference. An experiment is conducted to determine the effectiveness of its modified
    
[^77]: 通过量化进行的事后解释

    Posthoc Interpretation via Quantization. (arXiv:2303.12659v1 [cs.AI])

    [http://arxiv.org/abs/2303.12659](http://arxiv.org/abs/2303.12659)

    本文提出了一种新的方法 PIQ，通过对分类器进行向量量化，将其表示转换为离散类特定的潜空间，从而解释分类器所做出的决策，并且通过研究发现该方法相比其他方法更容易让人理解。

    

    本文提出了一种新的方法，称为“通过量化实现的事后解释（PIQ）”，用于解释训练分类器所做出的决策。我们的方法利用向量量化将分类器的表示转换为离散，类特定的潜空间。类特定的码本作为瓶颈，迫使解释者专注于分类器认为用于进行预测的输入数据的相关部分。我们通过定量和定性研究评估了我们的方法，并发现与文献中的几种其他解释方法相比，PIQ生成的解释更容易被参与我们用户研究的人所理解。

    In this paper, we introduce a new approach, called "Posthoc Interpretation via Quantization (PIQ)", for interpreting decisions made by trained classifiers. Our method utilizes vector quantization to transform the representations of a classifier into a discrete, class-specific latent space. The class-specific codebooks act as a bottleneck that forces the interpreter to focus on the parts of the input data deemed relevant by the classifier for making a prediction. We evaluated our method through quantitative and qualitative studies and found that PIQ generates interpretations that are more easily understood by participants to our user studies when compared to several other interpretation methods in the literature.
    
[^78]: CB2：合作自然语言交互研究平台

    CB2: Collaborative Natural Language Interaction Research Platform. (arXiv:2303.08127v1 [cs.LG])

    [http://arxiv.org/abs/2303.08127](http://arxiv.org/abs/2303.08127)

    CB2是一个用于研究基于任务的合作自然语言交互的平台，在3D游戏环境中提供了后端服务器和各种工具和流程。它在可扩展的研究中展示了学习的指令跟随模型。

    

    CB2 是一个多智能体平台，用于研究基于任务的情境下的合作自然语言交互。它包括一个 3D 游戏环境、一个后端服务器，可为人类智能体提供训练模型，以及各种工具和流程，以实现可扩展性的研究。我们在 https://cb2.ai 上展示了一个具有学习指令跟随模型的系统演示。

    CB2 is a multi-agent platform to study collaborative natural language interaction in a grounded task-oriented scenario. It includes a 3D game environment, a backend server designed to serve trained models to human agents, and various tools and processes to enable scalable studies. We deploy CB2 at https://cb2.ai as a system demonstration with a learned instruction following model.
    
[^79]: 改进技术掌握策略卡牌游戏（爐石戰記）

    Mastering Strategy Card Game (Hearthstone) with Improved Techniques. (arXiv:2303.05197v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.05197](http://arxiv.org/abs/2303.05197)

    本文将端到端策略函数和乐观平滑虚拟博弈算法应用于更加复杂的商业游戏爐石戰記，提出改进技术并在人机对战中表现出较强决策能力。

    

    策略卡牌游戏是一种著名的游戏类型，要求智能游戏玩法，并可以作为人工智能的理想测试平台。以往的研究合并了端到端策略函数和乐观平滑虚拟博弈，在《魔法与魅力：代码传说》等策略卡牌游戏中表现出有希望的性能。在本文中，我们将这些算法应用到爐石戰記上，并进一步提出了几种改进的技术，从而取得了显着的进展。为了进行机器对人的测试，我们邀请了一位在中国官方联赛中排名前十的爐石戰記播主，该地区的玩家数量估计在数百万人以上。我们的模型在所有完整游戏（包括构建卡组和对战）的五局比赛中击败了人类玩家，展现了强大的决策能力。

    Strategy card game is a well-known genre that is demanding on the intelligent game-play and can be an ideal test-bench for AI. Previous work combines an end-to-end policy function and an optimistic smooth fictitious play, which shows promising performances on the strategy card game Legend of Code and Magic. In this work, we apply such algorithms to Hearthstone, a famous commercial game that is more complicated in game rules and mechanisms. We further propose several improved techniques and consequently achieve significant progress. For a machine-vs-human test we invite a Hearthstone streamer whose best rank was top 10 of the official league in China region that is estimated to be of millions of players. Our models defeat the human player in all Best-of-5 tournaments of full games (including both deck building and battle), showing a strong capability of decision making.
    
[^80]: 动态提示：用于提示调整的统一框架

    Dynamic Prompting: A Unified Framework for Prompt Tuning. (arXiv:2303.02909v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.02909](http://arxiv.org/abs/2303.02909)

    本论文提出了一个统一的动态提示（DP）调整策略用于优化提示调整的性能，该策略可以动态地确定不同的提示变量来捕获额外的语义信息。

    

    已经证明，提示调整技术可以高效地从基础预训练模型中提取知识，包括预训练语言模型（PLMs）、预训练视觉模型和视觉语言模型 (V-L)。然而，采用固定的软提示来与所有实例连接输入，而忽略它们的固有差异，其有效性仍不确定。例如提示的位置、长度和表示在不同实例和任务中的不同变量，可以显著影响提示调整的性能。在此背景下，我们提供了一个理论分析。这个分析发现，优化提示的位置可以捕获传统前缀或后缀提示调整方法无法捕获的额外语义信息。基于我们的分析，我们提出了一个统一的动态提示 (DP) 调整策略，可以动态地确定不同的提示变量，以优化提示调整的性能。

    It has been demonstrated that the art of prompt tuning is highly effective in efficiently extracting knowledge from pretrained foundation models, encompassing pretrained language models (PLMs), vision pretrained models, and vision-language (V-L) models. However, the efficacy of employing fixed soft prompts with a predetermined position for concatenation with inputs for all instances, irrespective of their inherent disparities, remains uncertain. Variables such as the position, length, and representations of prompts across diverse instances and tasks can substantially influence the performance of prompt tuning. In this context, we provide a theoretical analysis, which reveals that optimizing the position of the prompt to encompass the input can capture additional semantic information that traditional prefix or postfix prompt tuning methods fail to capture. Building upon our analysis, we present a unified dynamic prompt (DP) tuning strategy that dynamically determines different factors o
    
[^81]: 用元启发式条件神经网络收集天然抑制态的天空rmion状态

    Metaheuristic conditional neural network for harvesting skyrmionic metastable states. (arXiv:2303.02876v2 [physics.comp-ph] UPDATED)

    [http://arxiv.org/abs/2303.02876](http://arxiv.org/abs/2303.02876)

    提出了一种基于元启发式条件神经网络的方法，收集高不规则潜能能量面上的物理有趣的稳态， 并在Pd / Fe / Ir（111）系统中应用于识别自旋结构，观察了其中一些结构的有限温度自旋动力学特性和拓扑电荷与结构之间的关系。

    

    我们提出了一种基于元启发式条件神经网络的方法，旨在识别高不规则潜能能量面上的物理有趣的稳态。为了展示这种方法的工作原理，我们使用从密度泛函理论计算的参数基础上建立的古典微观旋转哈密顿量对Pd / Fe / Ir（111）系统中的拓扑电荷$Q$值从1到$-13$的自旋结构进行了分析 。为了促进相关自旋结构的收集，我们利用了最新开发的“任意分段模型”（SAM）。并使用有限温度自旋动力学模拟进一步分析了Q值范围从$-3$到$-6$的自旋结构。我们发现，对于高达20K的温度，预测寿命长达200ps以上，当这些结构衰减时，新的拓扑旋转结构就会形成。我们还发现，自旋结构的相对稳定性与其拓扑相关。

    We present a metaheuristic conditional neural-network-based method aimed at identifying physically interesting metastable states in a potential energy surface of high rugosity. To demonstrate how this method works, we identify and analyze spin textures with topological charge $Q$ ranging from 1 to $-13$ (where antiskyrmions have $Q<0$) in the Pd/Fe/Ir(111) system, which we model using a classical atomistic spin Hamiltonian based on parameters computed from density functional theory. To facilitate the harvest of relevant spin textures, we make use of the newly developed Segment Anything Model (SAM). Spin textures with $Q$ ranging from $-3$ to $-6$ are further analyzed using finite-temperature spin-dynamics simulations. We observe that for temperatures up to around 20\,K, lifetimes longer than 200\,ps are predicted, and that when these textures decay, new topological spin textures are formed. We also find that the relative stability of the spin textures depend linearly on the topological
    
[^82]: Inseq：一个用于序列生成模型的可解释性工具包

    Inseq: An Interpretability Toolkit for Sequence Generation Models. (arXiv:2302.13942v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.13942](http://arxiv.org/abs/2302.13942)

    本文介绍了Inseq，这是一个Python工具包，旨在推广可解释性序列生成模型的分析。它为常见的解码器和编码器-解码器Transformers架构提供了提取模型内部信息和特征重要性得分的直观优化方法。作者还在机器翻译模型和GPT-2中展示了Inseq的潜力，证明其有助于推动可解释性自然语言生成的未来发展。

    

    自然语言处理领域的过去的可解释性研究主要集中在流行的分类任务上，而在生成任务中往往被忽视，部分原因是缺乏专门的工具。在本文中，我们介绍了Inseq，一个Python库，用于使序列生成模型的可解释性分析普及化。Inseq能够直观且优化地提取流行的仅解码器和编码器解码器Transformers架构的模型内部信息和特征重要性分数。我们还展示了它的潜力，通过使用它来突出机器翻译模型中的性别偏见并在GPT-2中定位事实知识。由于其支持对比特征归因等前沿技术的可扩展接口，因此Inseq可以推动可解释性自然语言生成的未来发展，集中优良实践，并实现公正和可重复的模型评估。

    Past work in natural language processing interpretability focused mainly on popular classification tasks while largely overlooking generation settings, partly due to a lack of dedicated tools. In this work, we introduce Inseq, a Python library to democratize access to interpretability analyses of sequence generation models. Inseq enables intuitive and optimized extraction of models' internal information and feature importance scores for popular decoder-only and encoder-decoder Transformers architectures. We showcase its potential by adopting it to highlight gender biases in machine translation models and locate factual knowledge inside GPT-2. Thanks to its extensible interface supporting cutting-edge techniques such as contrastive feature attribution, Inseq can drive future advances in explainable natural language generation, centralizing good practices and enabling fair and reproducible model evaluations.
    
[^83]: 基于自监督学习的方法用于聚类包含缺失值的多元时间序列数据 (SLAC-Time): 应用于TBI表型化

    A Self-Supervised Learning-based Approach to Clustering Multivariate Time-Series Data with Missing Values (SLAC-Time): An Application to TBI Phenotyping. (arXiv:2302.13457v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.13457](http://arxiv.org/abs/2302.13457)

    本文提出了一种基于自监督学习的多元时间序列数据聚类方法(SLAC-Time)，采用时间序列预测作为代理任务，不需要填补缺失值，具有更健壮的时间序列表示。

    

    自监督学习方法为聚类多元时间序列数据提供了一个很有前途的方向。然而，现实世界中的时间序列数据通常包含缺失值，而现有的方法要求在聚类之前填补缺失值，这可能会导致大量计算和噪声，从而导致无效的解释。为了解决这些挑战，我们提出了一种基于自监督学习的用于聚类包含缺失值的多元时间序列数据的方法(SLAC-Time)。SLAC-Time是一种基于Transformer的聚类方法，它使用时间序列预测作为代理任务，利用无标签数据来学习更健壮的时间序列表示。该方法同时学习神经网络参数和所学表示的聚类分配。它使用K-means方法迭代地对学习表示进行聚类，然后利用随后的聚类分配作为伪标签来更新模型参数。

    Self-supervised learning approaches provide a promising direction for clustering multivariate time-series data. However, real-world time-series data often include missing values, and the existing approaches require imputing missing values before clustering, which may cause extensive computations and noise and result in invalid interpretations. To address these challenges, we present a Self-supervised Learning-based Approach to Clustering multivariate Time-series data with missing values (SLAC-Time). SLAC-Time is a Transformer-based clustering method that uses time-series forecasting as a proxy task for leveraging unlabeled data and learning more robust time-series representations. This method jointly learns the neural network parameters and the cluster assignments of the learned representations. It iteratively clusters the learned representations with the K-means method and then utilizes the subsequent cluster assignments as pseudo-labels to update the model parameters. To evaluate our
    
[^84]: 利用光幕的主动速度估计：自监督多臂赌博机

    Active Velocity Estimation using Light Curtains via Self-Supervised Multi-Armed Bandits. (arXiv:2302.12597v3 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2302.12597](http://arxiv.org/abs/2302.12597)

    本文讨论了使用成本更低、速度更快、分辨率更高的可编程光幕来估计机器人所在环境的障碍物的位置和移动方式。为了决定光幕的放置位置以准确执行此任务，我们使用了最大化信息增益和验证预测对象位置的多种策略，并通过在线学习框架组合了这些策略。我们提出了一种新颖的自监督奖励函数，以评估当前速度估计的准确性。

    

    为了在环境中进行安全和自主的导航，机器人必须准确地估计障碍物的位置和移动方式。本文探索了使用成本更低、速度更快、分辨率更高的可编程光幕的替代方案，而非使用昂贵的传统3D传感器。我们采用基于粒子滤波器和占据栅格的概率方法，使用光幕进行部分测量并明确估计场景中3D点的位置和速度。最大的挑战是决定光幕的放置位置，以准确执行此任务。我们提出了多种光幕放置策略，通过最大化信息增益和验证预测的对象位置进行指导。然后，我们使用在线学习框架将这些策略组合起来。我们提出了一种新颖的自监督奖励函数，评估当前速度估计的准确性。

    To navigate in an environment safely and autonomously, robots must accurately estimate where obstacles are and how they move. Instead of using expensive traditional 3D sensors, we explore the use of a much cheaper, faster, and higher resolution alternative: programmable light curtains. Light curtains are a controllable depth sensor that sense only along a surface that the user selects. We adapt a probabilistic method based on particle filters and occupancy grids to explicitly estimate the position and velocity of 3D points in the scene using partial measurements made by light curtains. The central challenge is to decide where to place the light curtain to accurately perform this task. We propose multiple curtain placement strategies guided by maximizing information gain and verifying predicted object locations. Then, we combine these strategies using an online learning framework. We propose a novel self-supervised reward function that evaluates the accuracy of current velocity estimate
    
[^85]: 通过演示来理解专业技能：离线逆向强化学习的最大似然框架

    Understanding Expertise through Demonstrations: A Maximum Likelihood Framework for Offline Inverse Reinforcement Learning. (arXiv:2302.07457v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.07457](http://arxiv.org/abs/2302.07457)

    通过提出的双层优化公式，我们提供了一个离线逆向强化学习的最大似然框架，该框架通过最大化奖励来估计专家的保守模型以及专家的环境动态，能够更准确地推断专业技能。

    

    离线逆向强化学习（Offline IRL）旨在从专家代理的固定有限演示中恢复支撑观察到的操作的奖励和环境动态的结构。准确的专业执行任务的模型在安全敏感的应用中具有重要应用，例如临床决策和自动驾驶。然而，专家喜好隐含在观察到的操作中的结构与专家对环境动态的模型（即“世界”）密切相关。因此，从具有有限覆盖范围的有限数据中获得的不准确世界模型可能会导致估计的奖励的不准确性变得更加严重。为了解决这个问题，我们提出了一个双层优化公式的估计任务，其中上层是基于专家策略的保守模型的最大似然估计（下层）。策略模型是保守的，因为它在惩罚（惩罚会随着专家对世界模型的不确定性而增加）下最大化奖励。我们的实验表明，我们的方法在各种基准测试任务中提高了离线IRL方法的准确性。

    Offline inverse reinforcement learning (Offline IRL) aims to recover the structure of rewards and environment dynamics that underlie observed actions in a fixed, finite set of demonstrations from an expert agent. Accurate models of expertise in executing a task has applications in safety-sensitive applications such as clinical decision making and autonomous driving. However, the structure of an expert's preferences implicit in observed actions is closely linked to the expert's model of the environment dynamics (i.e. the ``world''). Thus, inaccurate models of the world obtained from finite data with limited coverage could compound inaccuracy in estimated rewards. To address this issue, we propose a bi-level optimization formulation of the estimation task wherein the upper level is likelihood maximization based upon a conservative model of the expert's policy (lower level). The policy model is conservative in that it maximizes reward subject to a penalty that is increasing in the uncerta
    
[^86]: 几何 Clifford 代数网络

    Geometric Clifford Algebra Networks. (arXiv:2302.06594v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.06594](http://arxiv.org/abs/2302.06594)

    本文提出了基于几何代数的几何 Clifford 代数网络（GCANs），采用对称群变换建模动态系统，通过群作用层、激活和归一化方案，可以优化几何模板，提高三维刚体变换和流体动力学模拟的性能。

    

    我们提出了基于几何（Clifford）代数的对称群变换的几何 Clifford 代数网络（GCANs）用于建模动态系统。我们首先回顾了现代（基于平面的）几何代数的精髓，该代数建立在作为 $\mathrm{Pin}(p,q,r)$ 群元素的等距映射之上。然后我们提出了群作用层的概念，它使用预定义的群作用线性组合物体变换，配合新的激活和归一化方案，这些层作为可调整的“几何模板”，可以通过梯度下降来优化。理论上的优势在三维刚体变换和大规模流体动力学模拟的建模中得到了强烈体现，表现出比传统方法显着提高的性能。

    We propose Geometric Clifford Algebra Networks (GCANs) for modeling dynamical systems. GCANs are based on symmetry group transformations using geometric (Clifford) algebras. We first review the quintessence of modern (plane-based) geometric algebra, which builds on isometries encoded as elements of the $\mathrm{Pin}(p,q,r)$ group. We then propose the concept of group action layers, which linearly combine object transformations using pre-specified group actions. Together with a new activation and normalization scheme, these layers serve as adjustable $\textit{geometric templates}$ that can be refined via gradient descent. Theoretical advantages are strongly reflected in the modeling of three-dimensional rigid body transformations as well as large-scale fluid dynamics simulations, showing significantly improved performance over traditional methods.
    
[^87]: 重新审视判别式分类器与生成式分类器：理论与应用

    Revisiting Discriminative vs. Generative Classifiers: Theory and Implications. (arXiv:2302.02334v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.02334](http://arxiv.org/abs/2302.02334)

    本文重新审视关于判别式与生成式分类器的经典主题，利用多类$\mathcal{H}$-一致性下界，证明了在温和的假设下，多类朴素贝叶斯分类器的样本要求比逻辑回归分类器多了$O(\log n)$。

    

    大规模深度模型预先在大规模标记或未标记数据上进行训练，可以有效地转移到下游任务。线性评估将预先训练的模型中的参数冻结，并单独训练一个线性分类器，这是一种有效且有吸引力的转移方法。然而，目前很少有研究线性评估中的分类器，除了默认的逻辑回归分类器。本文受到朴素贝叶斯的统计效率启发，重新审视了关于判别式与生成式分类器的经典主题。理论上，本文考虑使用代理损失而不是0-1损失进行分析，并将经典结果从二元情况推广到多类情况。我们表明，在温和的假设下，多类朴素贝叶斯需要$O(\log n)$个样本来接近其渐近误差，而相应的多类逻辑回归需要$O(n)$个样本，其中$n$是特征维度。为了证明这一点，我们提出了一个多类$\mathcal{H}$-一致性下界。

    A large-scale deep model pre-trained on massive labeled or unlabeled data transfers well to downstream tasks. Linear evaluation freezes parameters in the pre-trained model and trains a linear classifier separately, which is efficient and attractive for transfer. However, little work has investigated the classifier in linear evaluation except for the default logistic regression. Inspired by the statistical efficiency of naive Bayes, the paper revisits the classical topic on discriminative vs. generative classifiers. Theoretically, the paper considers the surrogate loss instead of the zero-one loss in analyses and generalizes the classical results from binary cases to multiclass ones. We show that, under mild assumptions, multiclass naive Bayes requires $O(\log n)$ samples to approach its asymptotic error while the corresponding multiclass logistic regression requires $O(n)$ samples, where $n$ is the feature dimension. To establish it, we present a multiclass $\mathcal{H}$-consistency bo
    
[^88]: 针对对抗扰动的随机集成算法的鲁棒性研究

    On the Robustness of Randomized Ensembles to Adversarial Perturbations. (arXiv:2302.01375v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.01375](http://arxiv.org/abs/2302.01375)

    本文对随机集成算法在对抗攻击环境中的鲁棒性进行了研究，提出了新的训练算法 BARRE，能够有效地防御强大的 $\ell_\infty$ 范围内的攻击。

    

    随机集成分类器 (Randomized ensemble classifiers, RECs) 已被证明是一种吸引人的替代传统集成方法的分类器，具有较小的计算需求。然而，最近的研究表明，现有的构造 RECs 的方法比最初声称的更脆弱，对其功效产生了重大怀疑，并引发了一些基本问题，例如：“RECs 何时有效？”，“它们的局限性是什么？”，“我们如何训练它们？”。在本文中，我们首先从理论上探索 RECs 并得出了一些基本结果，例如 RECs 的理论限制、使用它们必要且充分的条件等。在此基础上，我们提出了一种新的增强算法 (BARRE) 用于训练强鲁棒的 RECs，并在各种网络结构和数据集上进行了实证，证明了其对抗强 $\ell_\infty$ 范围内的攻击的有效性。

    Randomized ensemble classifiers (RECs), where one classifier is randomly selected during inference, have emerged as an attractive alternative to traditional ensembling methods for realizing adversarially robust classifiers with limited compute requirements. However, recent works have shown that existing methods for constructing RECs are more vulnerable than initially claimed, casting major doubts on their efficacy and prompting fundamental questions such as: "When are RECs useful?", "What are their limits?", and "How do we train them?". In this work, we first demystify RECs as we derive fundamental results regarding their theoretical limits, necessary and sufficient conditions for them to be useful, and more. Leveraging this new understanding, we propose a new boosting algorithm (BARRE) for training robust RECs, and empirically demonstrate its effectiveness at defending against strong $\ell_\infty$ norm-bounded adversaries across various network architectures and datasets. Our code can
    
[^89]: 双排列等变性在知识图谱补全中的应用

    Double Permutation Equivariance for Knowledge Graph Completion. (arXiv:2302.01313v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.01313](http://arxiv.org/abs/2302.01313)

    本研究提出了双排列等变性的KG表示方法，可以使神经网络在KG中执行复杂的逻辑推理任务，并在多个归纳KG完成任务中实现了最先进的Hits@10测试准确率。双排列等变性在KG中开辟了新的研究方向。

    

    本研究将知识图谱(KGs)形式化为一种新型的图，并称之为双交换属性图，其中节点和二元（两个节点之间的）表示必须对节点号和边（及节点）属性（关系和节点特征）的排列等变。双重排列等变的KG表示在KG中开辟了新的研究方向。我们展示了这种等变性对关系的结构表示产生的影响，从而使神经网络能够在KG中执行复杂的逻辑推理任务。最后，我们介绍了一种通用的等变表示蓝图，并测试了一种简单的基于GNN的双排列等变神经结构，在WN18RR、FB237和NELL995归纳KG完成任务中实现了最先进的Hits@10测试准确率，并能够准确执行现有方法无法执行的逻辑推理任务。

    This work provides a formalization of Knowledge Graphs (KGs) as a new class of graphs that we denote doubly exchangeable attributed graphs, where node and pairwise (joint 2-node) representations must be equivariant to permutations of both node ids and edge (& node) attributes (relations & node features). Double-permutation equivariant KG representations open a new research direction in KGs. We show that this equivariance imposes a structural representation of relations that allows neural networks to perform complex logical reasoning tasks in KGs. Finally, we introduce a general blueprint for such equivariant representations and test a simple GNN-based double-permutation equivariant neural architecture that achieve state-of-the-art Hits@10 test accuracy in the WN18RR, FB237 and NELL995 inductive KG completion tasks, and can accurately perform logical reasoning tasks that no existing methods can perform, to the best of our knowledge.
    
[^90]: 通过分层蒸馏将预训练语言模型的知识转移到基于CIF的语音识别器

    Knowledge Transfer from Pre-trained Language Models to Cif-based Speech Recognizers via Hierarchical Distillation. (arXiv:2301.13003v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.13003](http://arxiv.org/abs/2301.13003)

    本文提出了一种分层蒸馏技术，在声学和语言级别上将预训练语言模型（PLMs）的知识转移到基于CIF的自动语音识别（ASR）模型，相较原始模型，在AISHELL-1和LibriSpeech数据集上分别实现了15%和9%的相对误差率降低。

    

    大规模的预训练语言模型（PLMs）在自然语言处理任务中展现出了巨大的潜力。利用PLMs来增强自动语音识别（ASR）系统也成为了一个有前途的研究方向。然而，先前的研究受到PLMs结构不灵活和PLMs利用不充分等问题限制。为了缓解这些问题，我们提出了在连续积分和火灾（CIF）基础上用层次化知识蒸馏（HKD）。为了将PLMs的知识转移至ASR模型，HKD使用交叉模态知识蒸馏和声学级别对比损失以及语言级别的知识蒸馏和回归损失。与原始的CIF模型相比，我们的方法在AISHELL-1和LibriSpeech数据集上分别实现了15％和9％的相对误差率降低。

    Large-scale pre-trained language models (PLMs) have shown great potential in natural language processing tasks. Leveraging the capabilities of PLMs to enhance automatic speech recognition (ASR) systems has also emerged as a promising research direction. However, previous works may be limited by the inflexible structures of PLMs and the insufficient utilization of PLMs. To alleviate these problems, we propose the hierarchical knowledge distillation (HKD) on the continuous integrate-and-fire (CIF) based ASR models. To transfer knowledge from PLMs to the ASR models, HKD employs cross-modal knowledge distillation with contrastive loss at the acoustic level and knowledge distillation with regression loss at the linguistic level. Compared with the original CIF-based model, our method achieves 15% and 9% relative error rate reduction on the AISHELL-1 and LibriSpeech datasets, respectively.
    
[^91]: 带有矢量量化模型的分层模仿学习

    Hierarchical Imitation Learning with Vector Quantized Models. (arXiv:2301.12962v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2301.12962](http://arxiv.org/abs/2301.12962)

    本文提出带有矢量量化模型的分层模仿学习方法，通过强化学习识别专家轨迹的子目标并建立矢量量化生成模型实现子目标级别的规划，该算法在解决复杂、长远的决策问题方面优于现有最先进方法。

    

    实现多级抽象的行动规划能力可以使智能体有效地解决复杂任务。然而，学习低级规划模型和高级规划模型并建立它们之间的关联具有挑战性，特别是在高维输入情况下。为了解决这个问题，我们提出使用强化学习来从专家轨迹中识别子目标，通过将奖励的大小与在给定状态和选择的子目标下可预测的低级行动相联系来实现识别。我们针对所识别的子目标建立矢量量化生成模型，以执行子目标级别的规划。在实验中，该算法优于最先进方法，能够解决复杂、长远的决策问题，因为它能够规划，所以在训练集中比现有轨迹找到了更好的轨迹。

    The ability to plan actions on multiple levels of abstraction enables intelligent agents to solve complex tasks effectively. However, learning the models for both low and high-level planning from demonstrations has proven challenging, especially with higher-dimensional inputs. To address this issue, we propose to use reinforcement learning to identify subgoals in expert trajectories by associating the magnitude of the rewards with the predictability of low-level actions given the state and the chosen subgoal. We build a vector-quantized generative model for the identified subgoals to perform subgoal-level planning. In experiments, the algorithm excels at solving complex, long-horizon decision-making problems outperforming state-of-the-art. Because of its ability to plan, our algorithm can find better trajectories than the ones in the training set
    
[^92]: 可证明鲁棒性强化学习：基于模型的抽象解释方法

    Certifiably Robust Reinforcement Learning through Model-Based Abstract Interpretation. (arXiv:2301.11374v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.11374](http://arxiv.org/abs/2301.11374)

    CAROL是一个强化学习框架，它基于模型和抽象解释方法，学习出的策略具有机器可证明的对抗鲁棒性证书，在实验上表现出更好的认证性能和可比较的对抗性能。

    

    我们提出了一个强化学习框架 CAROL，其学习出的策略带有可证明的对抗鲁棒性证书。我们的方法学习了环境的模型，并在每个学习迭代中使用该模型和外部抽象解释器构建可微分的证明鲁棒性信号以引导学习，直到收敛时，该抽象解释就直接导致了可靠性证书。我们给出了一个理论分析，界定了 CAROL 的最坏情况下累积奖励。我们还在四个连续状态和动作空间的 MuJoCo 环境上对 CAROL 进行了实验评估。在这些任务中，CAROL 学习出的策略与现有强化学习算法相比，展示出显著增强的认证性能下限和可比较的对抗性能。

    We present a reinforcement learning (RL) framework in which the learned policy comes with a machine-checkable certificate of provable adversarial robustness. Our approach, called CAROL, learns a model of the environment. In each learning iteration, it uses the current version of this model and an external abstract interpreter to construct a differentiable signal for provable robustness. This signal is used to guide learning, and the abstract interpretation used to construct it directly leads to the robustness certificate returned at convergence. We give a theoretical analysis that bounds the worst-case accumulative reward of CAROL. We also experimentally evaluate CAROL on four MuJoCo environments with continuous state and action spaces. On these tasks, CAROL learns policies that, when contrasted with policies from the state-of-the-art robust RL algorithms, exhibit: (i) markedly enhanced certified performance lower bounds; and (ii) comparable performance under empirical adversarial atta
    
[^93]: 深度强化学习中的自动内在奖励塑造探索方法研究

    Automatic Intrinsic Reward Shaping for Exploration in Deep Reinforcement Learning. (arXiv:2301.10886v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.10886](http://arxiv.org/abs/2301.10886)

    本文提出了一种名为AIRS的自动内在奖励塑造探索方法，可以提供高质量的内在激励以增强强化学习中的探索性能；并开发了高效可靠的内在奖励工具包。实验表明，AIRS性能卓越，能够胜过基准方案。

    

    本文提出了一种名为AIRS的自动内在奖励塑造方法，通过智能和适应性的塑造函数，提供高质量的内在激励以增强强化学习中的探索性能。AIRS可以根据实时估计的任务回报从预定义的函数集中选择塑造函数，提供可靠的探索激励并解决偏置目标问题。此外，我们开发了一个内在奖励工具包，提供多种内在奖励方法的高效可靠实现方式。我们将AIRS应用在MiniGrid、Procgen和DeepMind控制套件的多项任务中进行测试。大量仿真结果表明，AIRS可以胜过基准方案，并具有简单的架构和卓越的性能。

    We present AIRS: Automatic Intrinsic Reward Shaping that intelligently and adaptively provides high-quality intrinsic rewards to enhance exploration in reinforcement learning (RL). More specifically, AIRS selects shaping function from a predefined set based on the estimated task return in real-time, providing reliable exploration incentives and alleviating the biased objective problem. Moreover, we develop an intrinsic reward toolkit to provide efficient and reliable implementations of diverse intrinsic reward approaches. We test AIRS on various tasks of MiniGrid, Procgen, and DeepMind Control Suite. Extensive simulation demonstrates that AIRS can outperform the benchmarking schemes and achieve superior performance with simple architecture.
    
[^94]: DIFFormer：通过受能量限制的扩散引出的可扩展（图形）Transformer

    DIFFormer: Scalable (Graph) Transformers Induced by Energy Constrained Diffusion. (arXiv:2301.09474v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.09474](http://arxiv.org/abs/2301.09474)

    DIFFormer是一种能量受限扩散模型，通过逐渐融合其他实例信息的演化状态，导出了一类新的神经编码器，称为DIFFormer（基于扩散的Transformer），能够揭示真实世界中复杂的数据生成过程。

    

    真实世界的数据生成常常涉及实例之间的复杂相互依赖，违反了标准学习范式的IID数据假设，从而对揭示几何结构以学习所需要的实例表示形成了挑战。为此，我们引入了一种能量受限扩散模型，将一批数据集中的实例编码为逐渐融合了其他实例信息的演化状态。扩散过程受限于基于合理能量函数的下降标准，该函数表征了潜在结构上实例表示的全局一致性。我们提供了严谨的理论，该理论暗示了任意实例对之间的最优扩散强度的闭合形式估计，这导致了一类新的神经编码器的产生：DIFFormer（基于扩散的Transformer），其中包含两个版本：一个简单版本具有线性复杂度，面临着禁忌的实例。

    Real-world data generation often involves complex inter-dependencies among instances, violating the IID-data hypothesis of standard learning paradigms and posing a challenge for uncovering the geometric structures for learning desired instance representations. To this end, we introduce an energy constrained diffusion model which encodes a batch of instances from a dataset into evolutionary states that progressively incorporate other instances' information by their interactions. The diffusion process is constrained by descent criteria w.r.t.~a principled energy function that characterizes the global consistency of instance representations over latent structures. We provide rigorous theory that implies closed-form optimal estimates for the pairwise diffusion strength among arbitrary instance pairs, which gives rise to a new class of neural encoders, dubbed as DIFFormer (diffusion-based Transformers), with two instantiations: a simple version with linear complexity for prohibitive instanc
    
[^95]: 基于均场控制的非可分共享全局状态下多智能体强化学习的近似方法

    Mean-Field Control based Approximation of Multi-Agent Reinforcement Learning in Presence of a Non-decomposable Shared Global State. (arXiv:2301.06889v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.06889](http://arxiv.org/abs/2301.06889)

    本文提出了一种基于均场控制的多智能体强化学习的近似方法，即使智能体共享一个非可分全局状态，也能具有较好的适用性和近似效果。

    

    均场控制是解决大规模多智能体强化学习问题的一种强大的近似工具。然而，均场控制的成功取决于一个假设，即在给定所有智能体的局部状态和行为的情况下，智能体的下一个（局部）状态会互相独立地演变。本文证明了即使在智能体共享一个全局状态的MARL场景中，MFC仍然可以作为一个好的近似工具，前提是智能体的局部状态仍具有条件独立性。我们假设全局状态是非可分的，即不能将它表示为智能体的局部状态的集合。我们将近似误差计算为$\mathcal{O}(e)$，其中$e=\frac{1}{\sqrt{N}}\left[\sqrt{|\mathcal{X}|} +\sqrt{|\mathcal{U}|}\right]$，代表智能体数量的术语为$N$，$|\mathcal{X}|, |\mathcal{U}|$ 表示状态和动作空间的大小。

    Mean Field Control (MFC) is a powerful approximation tool to solve large-scale Multi-Agent Reinforcement Learning (MARL) problems. However, the success of MFC relies on the presumption that given the local states and actions of all the agents, the next (local) states of the agents evolve conditionally independent of each other. Here we demonstrate that even in a MARL setting where agents share a common global state in addition to their local states evolving conditionally independently (thus introducing a correlation between the state transition processes of individual agents), the MFC can still be applied as a good approximation tool. The global state is assumed to be non-decomposable i.e., it cannot be expressed as a collection of local states of the agents. We compute the approximation error as $\mathcal{O}(e)$ where $e=\frac{1}{\sqrt{N}}\left[\sqrt{|\mathcal{X}|} +\sqrt{|\mathcal{U}|}\right]$. The size of the agent population is denoted by the term $N$, and $|\mathcal{X}|, |\mathcal
    
[^96]: 定义、评估和改进基于任务的认知能力对生成模型的影响

    Define, Evaluate, and Improve Task-Oriented Cognitive Capabilities for Instruction Generation Models. (arXiv:2301.05149v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.05149](http://arxiv.org/abs/2301.05149)

    本文提出了基于任务的认知能力，设计了评估方案来比较语言模型和人类的这些能力，通过在导航指令生成问题中的应用，发现模型的语用能力仍需改进。

    

    近期的工作通过为人类设计的心理测试研究了语言模型的认知能力。尽管这些研究有助于了解这些模型的一般能力，但并不能保证一个拥有足够能力通过这些测试的模型实际上会在执行实际任务时使用这些能力。在这项工作中，我们制定了基于任务的认知能力，这是一种人类式认知能力，语言模型可以利用这种能力来执行任务。这些能力包括：(i) 快速生成良好的候选话语的能力 (搜索能力)；(ii) 预测听者如何理解这些话语，并选择最合适的话语 (语用能力)。我们设计了一个评估方案，以比较语言模型与人类的这些能力。通过将此方案应用于导航指令生成问题中的各种模型的比较，我们发现它们的语用能力。

    Recent work studies the cognitive capabilities of language models through psychological tests designed for humans. While these studies are helpful for understanding the general capabilities of these models, there is no guarantee that a model possessing sufficient capabilities to pass those tests would actually use those capabilities in performing real-life tasks. In this work, we formulate task-oriented cognitive capabilities, which are human-like cognitive capabilities that language models leverage to perform tasks. These capabilities are (i) the ability to quickly generate good candidate utterances (the search capability) (ii) the ability to predict how a listener interprets those utterances and choose the most appropriate one (the pragmatic capability). We design an evaluation scheme for comparing these capabilities of a language model with those of a human. Applying this scheme to examine various models in a navigation instruction generation problem, we find that their pragmatic ca
    
[^97]: InPars-v2: 利用大型语言模型作为信息检索高效数据集生成器

    InPars-v2: Large Language Models as Efficient Dataset Generators for Information Retrieval. (arXiv:2301.01820v4 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2301.01820](http://arxiv.org/abs/2301.01820)

    本文提出 InPars-v2，使用开源 LLMs 和强大再排序器生成用于信息检索中训练的合成查询-文档对，可在 BEIR 基准测试中达到最新的最好结果。

    

    近来，InPars 提出了一种利用大型语言模型（LLMs）在信息检索任务中高效生成相关查询的方法：通过少量样本，诱导 LLM 生成与文档相关的查询，在此基础上生成合成的查询-文档对，用于训练检索器。然而，InPars 和 Promptagator 等方法依赖于 GPT-3 和 FLAN 等专有 LLMs 生成这些数据集。本文提出了 InPars-v2，该数据集生成器使用开放源代码的 LLM 和现有的强大再排序器来选择用于训练的合成查询-文档对。一个简单的 BM25 检索管道，在经过由 InPars-v2 数据微调的 monoT5 再排序器之后，便可在 BEIR 基准测试中达到最新的最好结果。为了让研究人员进一步提高我们的方法，我们开源了代码、数据和微调模型：https://github.com/zetaalphavector/inPars/tree/master/tpu。

    Recently, InPars introduced a method to efficiently use large language models (LLMs) in information retrieval tasks: via few-shot examples, an LLM is induced to generate relevant queries for documents. These synthetic query-document pairs can then be used to train a retriever. However, InPars and, more recently, Promptagator, rely on proprietary LLMs such as GPT-3 and FLAN to generate such datasets. In this work we introduce InPars-v2, a dataset generator that uses open-source LLMs and existing powerful rerankers to select synthetic query-document pairs for training. A simple BM25 retrieval pipeline followed by a monoT5 reranker finetuned on InPars-v2 data achieves new state-of-the-art results on the BEIR benchmark. To allow researchers to further improve our method, we open source the code, synthetic data, and finetuned models: https://github.com/zetaalphavector/inPars/tree/master/tpu
    
[^98]: SERENGETI：为非洲而设计的大规模多语言语言模型

    SERENGETI: Massively Multilingual Language Models for Africa. (arXiv:2212.10785v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10785](http://arxiv.org/abs/2212.10785)

    SERENGETI是一个大规模多语言语言模型，覆盖了517种非洲语言和语言方言。在自然语言理解任务中，它的表现优于其他在非洲语言上的语言模型，能够提供有价值的语言信息。

    

    多语言预训练语言模型（mPLM）在预训练期间获得有价值的语言信息，可推动特定任务的微调。目前，现有语言模型仅覆盖了大约2,000种非洲语言中的约31种。我们开发了SERENGETI，一种大规模多语言语言模型，覆盖了517种非洲语言和语言方言，以改善这种限制。我们在20个数据集上评估了我们的新型模型在八个自然语言理解任务上的表现，并将其与覆盖4-23种非洲语言的4个mPLM进行比较。SERENGETI在八个任务中的11个数据集上表现优异，实现了82.27的平均F_1。我们还进行了模型错误分析，以探究在零-shot情况下应用模型时语言系谱和语言相似性的影响。我们将向公众发布我们的研究模型。

    Multilingual pretrained language models (mPLMs) acquire valuable, generalizable linguistic information during pretraining and have advanced the state of the art on task-specific finetuning. To date, only ~31 out of ~2,000 African languages are covered in existing language models. We ameliorate this limitation by developing SERENGETI, a massively multilingual language model that covers 517 African languages and language varieties. We evaluate our novel models on eight natural language understanding tasks across 20 datasets, comparing to 4 mPLMs that cover 4-23 African languages. SERENGETI outperforms other models on 11 datasets across the eights tasks, achieving 82.27 average F_1. We also perform analyses of errors from our models, which allows us to investigate the influence of language genealogy and linguistic similarity when the models are applied under zero-shot settings. We will publicly release our models for research.\footnote{\href{https://github.com/UBC-NLP/serengeti}{https://g
    
[^99]: Lego-MT: 走向可拆卸的高度多语言机器翻译模型

    Lego-MT: Towards Detachable Models in Massively Multilingual Machine Translation. (arXiv:2212.10551v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10551](http://arxiv.org/abs/2212.10551)

    本文提出了一种可拆卸的多语言机器翻译模型，Lego-MT，以解决现有多语言单体模型在参数干扰和低效推导方面的挑战。进行实验评估表明，该模型具有较高的性能，相比具有10倍规模的模型，在效率和表现方面都更具优势。

    

    多语言神经机器翻译(MNMT)旨在构建一个适用于多个语言方向的统一模型。现有的MNMT单体模型面临两个挑战:语言之间的参数干扰和大型模型的低效推理。本文重新审视了经典的多路径结构，通过将每种语言(或语言组)分配给支持即插即用训练和推理的单独分支，开发出可拆卸模型。为了满足在统一空间中为所有语言学习表示的需要，我们提出了一种新颖的高效训练配方，以此构建一个有效的可拆卸模型，Lego-MT。为了进行公正的比较，我们从OPUS收集数据，构建了一个包括433种语言和13亿个平行数据的翻译基准。实验表明，参数为12亿的Lego-MT带来了3.2个spBLEU的平均增益。它甚至胜过了参数为120亿的M2M-100。所提出的训练配方比并行训练提速了28.2倍。

    Multilingual neural machine translation (MNMT) aims to build a unified model for many language directions. Existing monolithic models for MNMT encounter two challenges: parameter interference among languages and inefficient inference for large models. In this paper, we revisit the classic multi-way structures and develop a detachable model by assigning each language (or group of languages) to an individual branch that supports plug-and-play training and inference. To address the needs of learning representations for all languages in a unified space, we propose a novel efficient training recipe, upon which we build an effective detachable model, Lego-MT. For a fair comparison, we collect data from OPUS and build a translation benchmark covering 433 languages and 1.3B parallel data. Experiments show that Lego-MT with 1.2B parameters brings an average gain of 3.2 spBLEU. It even outperforms M2M-100 with 12B parameters. The proposed training recipe brings a 28.2$\times$ speedup over the co
    
[^100]: 用MaRCo消除有害文本：专家和反专家可控修订

    Detoxifying Text with MaRCo: Controllable Revision with Experts and Anti-Experts. (arXiv:2212.10543v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10543](http://arxiv.org/abs/2212.10543)

    MaRCo是一种排毒算法，能够使用专家和反专家模型对文本进行可控的重写和修订，适用于消除微妙的有害信息，且在自动化指标和人类评估中均有很好的表现。

    

    文本排毒具有减轻有害性的潜力，可以通过重新表述文本来消除冒犯性的含义，但微妙的有害性仍然很难处理。本文引入MaRCo，一种排毒算法，结合了可控生成和文本重写方法，使用自编码器语言模型（LM）的专家产品和反专家产品。MaRCo使用非有害LM（专家）和有害LM（反专家）下的可能性来查找候选单词以进行掩盖和可能替换。我们在几个微妙有害性和微攻击数据集上评估了我们的方法，并显示它不仅在自动度量上优于基线，而且MaRCo的重写在人类评估中更受欢迎。它对微妙的有害性情况的适用性尤其有前途，为解决日益难以捉摸的在线仇恨问题提供了一条道路。

    Text detoxification has the potential to mitigate the harms of toxicity by rephrasing text to remove offensive meaning, but subtle toxicity remains challenging to tackle. We introduce MaRCo, a detoxification algorithm that combines controllable generation and text rewriting methods using a Product of Experts with autoencoder language models (LMs). MaRCo uses likelihoods under a non-toxic LM (expert) and a toxic LM (anti-expert) to find candidate words to mask and potentially replace. We evaluate our method on several subtle toxicity and microaggressions datasets, and show that it not only outperforms baselines on automatic metrics, but MaRCo's rewrites are preferred 2.1 $\times$ more in human evaluation. Its applicability to instances of subtle toxicity is especially promising, demonstrating a path forward for addressing increasingly elusive online hate.
    
[^101]: 何时不信任语言模型：探索参数和非参数记忆的有效性和限制。

    When Not to Trust Language Models: Investigating Effectiveness and Limitations of Parametric and Non-Parametric Memories. (arXiv:2212.10511v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10511](http://arxiv.org/abs/2212.10511)

    本文通过对10个模型和4种增强方法的实验，发现语言模型在记忆不太流行的实际知识方面存在困难，而检索增强的语言模型表现较好，提出了一种检索增强语言模型的简单有效方法。

    

    尽管大型语言模型在各种任务上表现出色，但仍然难以处理需要丰富世界知识的任务，这暗示了仅依靠其参数来编码丰富的世界知识的局限性。本文旨在通过对10个模型和4种增强方法在PopQA上进行大规模知识探测实验，以了解语言模型在记忆事实知识方面的优点和局限性。我们发现，语言模型难以记忆不太流行的实际知识，并且在长尾中，扩展规模无法明显改善记忆实际知识。然后，我们展示了检索增强的语言模型在很大程度上胜过级别大得多的语言模型，而未经协助的语言模型在涉及高流行实体的问题上仍然具有竞争力。基于这些发现，我们设计了一种简单而有效的强大和高效的检索增强语言模型方法，该方法仅在需要时检索非参数记忆。

    Despite their impressive performance on diverse tasks, large language models (LMs) still struggle with tasks requiring rich world knowledge, implying the limitations of relying solely on their parameters to encode a wealth of world knowledge. This paper aims to understand LMs' strengths and limitations in memorizing factual knowledge, by conducting large-scale knowledge probing experiments of 10 models and 4 augmentation methods on PopQA, our new open-domain QA dataset with 14k questions. We find that LMs struggle with less popular factual knowledge, and that scaling fails to appreciably improve memorization of factual knowledge in the long tail. We then show that retrieval-augmented LMs largely outperform orders of magnitude larger LMs, while unassisted LMs remain competitive in questions about high-popularity entities. Based on those findings, we devise a simple, yet effective, method for powerful and efficient retrieval-augmented LMs, which retrieves non-parametric memories only whe
    
[^102]: 通过详细的大纲控制提升长篇故事连贯性

    DOC: Improving Long Story Coherence With Detailed Outline Control. (arXiv:2212.10077v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10077](http://arxiv.org/abs/2212.10077)

    该论文提出了一个名为 Detailed Outline Control(DOC) 的框架，通过详细大纲和详细控制器来提高生成长篇故事时的情节连贯性和大纲相关性，人类评估证实该方法在这些方面显著优于基线方法，并且更适用于交互生成设置。

    

    我们提出了一个称为 Detailed Outline Control(DOC)的框架，以提高生成数千字长的故事时的长程情节连贯性。DOC由两个互补组件组成：详细大纲和详细控制器。详细大纲创建一个更详细、层次化的大纲，将创造性负担从主要起草过程转移到规划阶段。详细控制器通过控制故事段落与大纲细节对齐，确保更详细的大纲在生成过程中仍然被尊重。在自动生成的故事的人类评估中，DOC在情节连贯性(22.5% 绝对增益)、大纲相关性(28.2%)和趣味性(20.7%)方面显著优于强大的Re3基线(Yang等人，2022)。人们还评价DOC在交互生成设置方面更易于控制。

    We propose the Detailed Outline Control (DOC) framework for improving long-range plot coherence when automatically generating several-thousand-word-long stories. DOC consists of two complementary components: a detailed outliner and a detailed controller. The detailed outliner creates a more detailed, hierarchically structured outline, shifting creative burden from the main drafting procedure to the planning stage. The detailed controller ensures the more detailed outline is still respected during generation by controlling story passages to align with outline details. In human evaluations of automatically generated stories, DOC substantially outperforms a strong Re3 baseline (Yang et al., 2022) on plot coherence (22.5% absolute gain), outline relevance (28.2%), and interestingness (20.7%). Humans also judged DOC to be much more controllable in an interactive generation setting.
    
[^103]: 使用语言模型提示进行推理：一项调查

    Reasoning with Language Model Prompting: A Survey. (arXiv:2212.09597v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09597](http://arxiv.org/abs/2212.09597)

    本文提供了使用语言模型提示进行推理的前沿研究综合调查。讨论了新兴推理能力出现的潜在原因，并提供系统资源帮助初学者。

    

    推理作为复杂问题解决的重要能力，可以为医疗诊断、谈判等各种实际应用提供后端支持。本文对使用语言模型提示进行推理的前沿研究进行了综合调查。我们介绍了研究成果的比较和总结，并提供了系统资源以帮助初学者。我们还讨论了新兴推理能力出现的潜在原因，并突出了未来的研究方向。资源可在 https://github.com/zjunlp/Prompt4ReasoningPapers 上获取（定期更新）。

    Reasoning, as an essential ability for complex problem-solving, can provide back-end support for various real-world applications, such as medical diagnosis, negotiation, etc. This paper provides a comprehensive survey of cutting-edge research on reasoning with language model prompting. We introduce research works with comparisons and summaries and provide systematic resources to help beginners. We also discuss the potential reasons for emerging such reasoning abilities and highlight future research directions. Resources are available at https://github.com/zjunlp/Prompt4ReasoningPapers (updated periodically).
    
[^104]: BLOOM+1：为零样本提示添加语言支持

    BLOOM+1: Adding Language Support to BLOOM for Zero-Shot Prompting. (arXiv:2212.09535v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09535](http://arxiv.org/abs/2212.09535)

    本文在BLOOM模型中应用语言适应策略，将其适应到新语言上，并在八种新语言的零样本提示表现中提升了性能。适配器微调比大模型的持续预训练更有效，提示性能主要由语言适应数据的大小确定。

    

    BLOOM模型是一个大型公开的多语言语言模型，但其预训练仅限于46种语言。为了将BLOOM的好处扩展到其他语言，而不会产生过高的成本，有必要将BLOOM适应到新的语言上。本文将现有的语言适应策略应用于BLOOM，并在资源受限的情况下对其在八种新语言的零样本提示表现进行基准测试。我们发现，语言适应对于提高新语言的零样本性能是有效的。令人惊讶的是，我们发现适配器微调比大模型的持续预训练更有效。此外，我们发现提示性能不会受到语言特定性的显着影响，如书写系统。它主要由语言适应数据的大小确定。我们还向BLOOMZ添加了新语言，这是BLOOM的多任务微调版本，能够跟随提示。

    The BLOOM model is a large publicly available multilingual language model, but its pretraining was limited to 46 languages. To extend the benefits of BLOOM to other languages without incurring prohibitively large costs, it is desirable to adapt BLOOM to new languages not seen during pretraining. In this work, we apply existing language adaptation strategies to BLOOM and benchmark its zero-shot prompting performance on eight new languages in a resource-constrained setting. We find language adaptation to be effective at improving zero-shot performance in new languages. Surprisingly, we find that adapter-based finetuning is more effective than continued pretraining for large models. In addition, we discover that prompting performance is not significantly affected by language specifics, such as the writing system. It is primarily determined by the size of the language adaptation data. We also add new languages to BLOOMZ, which is a multitask finetuned version of BLOOM capable of following 
    
[^105]: 多方面可控文本生成的可扩展即插即用方法

    An Extensible Plug-and-Play Method for Multi-Aspect Controllable Text Generation. (arXiv:2212.09387v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09387](http://arxiv.org/abs/2212.09387)

    本论文提出了一种基于可训练门的多方面可控文本生成方法，用于规范前缀的干预，从而实现对训练时未见过的方面组合的控制，具有良好的可扩展性和性能表现。

    

    最近，控制生成文本的多个方面（如情感、主题和关键词）的多方面可控文本生成引起了越来越多的关注。虽然基于参数有效调整的方法，如前缀调整，可以以即插即用的方式实现多方面控制，但多个前缀的相互干扰导致了约束的显著恶化，并限制了它们对于训练时未见过的方面组合的可扩展性。在这项工作中，我们为干扰提供了一个理论下限，并实验证明干扰随插入前缀的层数增加而增加。基于这些分析，我们提出使用可训练门来规范前缀的干预，以抑制不断增长的干扰。因此，通过简单地连接相应的插件，可以实现对训练时未见过的方面组合的控制，从而可以低成本地扩展新的约束条件。此外，我们提出了一个框架，使各种插件能够灵活集成，以对应不同的方面。实验结果表明，我们提出的方法在可控性、连贯性和多样性方面优于先前的方法。

    Recently, multi-aspect controllable text generation that controls the generated text in multiple aspects (e.g., sentiment, topic, and keywords) has attracted increasing attention. Although methods based on parameter efficient tuning like prefix-tuning could achieve multi-aspect controlling in a plug-and-play way, the mutual interference of multiple prefixes leads to significant degeneration of constraints and limits their extensibility to training-time unseen aspect combinations. In this work, we provide a theoretical lower bound for the interference and empirically found that the interference grows with the number of layers where prefixes are inserted. Based on these analyses, we propose using trainable gates to normalize the intervention of prefixes to restrain the growing interference. As a result, controlling training-time unseen combinations of aspects can be realized by simply concatenating corresponding plugins such that new constraints can be extended at a lower cost. In additi
    
[^106]: 关于对比句子表示学习的各向同性、情境化和学习动态

    On Isotropy, Contextualization and Learning Dynamics of Contrastive-based Sentence Representation Learning. (arXiv:2212.09170v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09170](http://arxiv.org/abs/2212.09170)

    本文通过几何学角度在对比句子表示学习中发现，对比学习带来了各向同性，并驱动同一句子中标记在语义空间中收敛到相似的位置。对于语义上有意义的标记，"虚假的情境化"得到了缓解，而对于功能性标记则被增强。

    

    将对比学习目标纳入句子表示学习中，在许多句子级自然语言处理任务中取得了显著的改进。本文通过各向同性、情境化和学习动态的视角来剖析对比句子表示学习的表现，旨在为未来设计句子表示学习方法提供指导。作者通过表示变换的几何学来解释对比学习的成功，并展示对比学习如何带来各向同性并导致同一句子中的标记在语义空间中收敛到相似的位置。研究还发现，对于语义上有意义的标记，"虚假的情境化"得到了缓解，而对于功能性标记则被增强。训练过程中，嵌入空间朝向原点并更好地定义了更多区域。

    Incorporating contrastive learning objectives in sentence representation learning (SRL) has yielded significant improvements on many sentence-level NLP tasks. However, it is not well understood why contrastive learning works for learning sentence-level semantics. In this paper, we aim to help guide future designs of sentence representation learning methods by taking a closer look at contrastive SRL through the lens of isotropy, contextualization and learning dynamics. We interpret its successes through the geometry of the representation shifts and show that contrastive learning brings isotropy, and drives high intra-sentence similarity: when in the same sentence, tokens converge to similar positions in the semantic space. We also find that what we formalize as "spurious contextualization" is mitigated for semantically meaningful tokens, while augmented for functional ones. We find that the embedding space is directed towards the origin during training, with more areas now better define
    
[^107]: 可扩展和可推广决策制定的遮盖自编码

    Masked Autoencoding for Scalable and Generalizable Decision Making. (arXiv:2211.12740v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.12740](http://arxiv.org/abs/2211.12740)

    本文提出了一种遮盖式决策预测 (MaskDP) 的简单可扩展的自监督预训练方法，在可扩展的增强学习和行为克隆中能够有效地从大规模多样的序列数据中学习，并且零样本转移至新任务。

    

    本文关注于学习可扩展的增强学习代理，使其能够从类似于当前大规模视觉和语言模型的大规模多样的序列数据中学习。为了实现这一目标，本文提出了一种遮盖式决策预测 (MaskDP) 的简单可扩展的自监督预训练方法，用于增强学习和行为克隆。在 MaskDP 方法中，我们利用遮挡自编码器 (MAE) 处理状态-动作轨迹，随机遮盖状态和操作标记并重建缺失的数据。通过这样做，模型需要推断出遮挡的状态和操作，并提取关于动态的信息。我们发现，遮盖不同比例的输入序列显著有助于学习一个更好的模型，能够推广到多个后续任务。在实证研究中，我们发现 MaskDP 模型获得了零样本转移到新的 BC 任务的能力，例如单一和多个目标到达任务，并且可以零样本进行连续控制。

    We are interested in learning scalable agents for reinforcement learning that can learn from large-scale, diverse sequential data similar to current large vision and language models. To this end, this paper presents masked decision prediction (MaskDP), a simple and scalable self-supervised pretraining method for reinforcement learning (RL) and behavioral cloning (BC). In our MaskDP approach, we employ a masked autoencoder (MAE) to state-action trajectories, wherein we randomly mask state and action tokens and reconstruct the missing data. By doing so, the model is required to infer masked-out states and actions and extract information about dynamics. We find that masking different proportions of the input sequence significantly helps with learning a better model that generalizes well to multiple downstream tasks. In our empirical study, we find that a MaskDP model gains the capability of zero-shot transfer to new BC tasks, such as single and multiple goal reaching, and it can zero-shot
    
[^108]: 通过多智能体联赛训练实现异质智能体的协作学习

    Learning Heterogeneous Agent Cooperation via Multiagent League Training. (arXiv:2211.11616v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.11616](http://arxiv.org/abs/2211.11616)

    本文提出了一种名为异质联赛训练（HLT）的通用强化学习算法，为解决异质多智能体问题，使用策略池和超网络，提高了异质智能体的合作效率。

    

    现实世界中的许多多智能体系统包括多种能力和功能不同的智能体。这样的异质多智能体系统具有重要的实用优势。然而，与同质系统相比，它们也带来了多智能体强化学习面临的一些挑战，如非稳态问题和策略版本迭代问题。本文提出了一种名为异质联赛训练（HLT）的通用强化学习算法，以解决异质多智能体问题。HLT跟踪代理人在训练期间探索的一组策略，收集异质策略联盟以促进未来的策略优化。此外，引入了超网络，以增加代理人的行为多样性，从而在与具有不同级别的合作技能的队友合作时进行协作。我们使用异质基准任务来证明HLT能够提高协作异质任务的成功率。

    Many multiagent systems in the real world include multiple types of agents with different abilities and functionality. Such heterogeneous multiagent systems have significant practical advantages. However, they also come with challenges compared with homogeneous systems for multiagent reinforcement learning, such as the non-stationary problem and the policy version iteration issue. This work proposes a general-purpose reinforcement learning algorithm named Heterogeneous League Training (HLT) to address heterogeneous multiagent problems. HLT keeps track of a pool of policies that agents have explored during training, gathering a league of heterogeneous policies to facilitate future policy optimization. Moreover, a hyper-network is introduced to increase the diversity of agent behaviors when collaborating with teammates having different levels of cooperation skills. We use heterogeneous benchmark tasks to demonstrate that (1) HLT promotes the success rate in cooperative heterogeneous task
    
[^109]: 零偏置标量不变网络

    Scalar Invariant Networks with Zero Bias. (arXiv:2211.08486v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.08486](http://arxiv.org/abs/2211.08486)

    本文证明了在解决许多图像任务(例如图像分类)时可以忽略偏置，并且零偏置神经网络在实际图像分类任务中表现良好，同时具有标量 (乘法) 不变性，从而在改变对比度时仍能保持预测不变。

    

    与权重一样，偏置项也是许多流行的机器学习模型(包括神经网络)可学习的参数。人们认为偏差能有效地增加神经网络表示能力来解决计算机视觉中的各种任务。然而，我们认为，如果我们从第一原理考虑图像在输入空间中的内在分布以及模型应具有的一些期望特性，则偏差可以完全忽略，以解决许多与图像相关的任务，例如图像分类任务。我们的观察结果表明，零偏置神经网络在实际图像分类任务上可能与带偏置的神经网络表现相当。此外，我们证明零偏置神经网络具有称为标量(乘法)不变性的良好属性，这使得当改变输入图像的对比度时，神经网络的预测保持不变。然后，我们将标量不变性扩展到更一般的情况…

    Just like weights, bias terms are the learnable parameters of many popular machine learning models, including neural networks. Biases are believed to effectively increase the representational power of neural networks to solve a wide range of tasks in computer vision. However, we argue that if we consider the intrinsic distribution of images in the input space as well as some desired properties a model should have from the first principles, biases can be completely ignored in addressing many image-related tasks, such as image classification. Our observation indicates that zero-bias neural networks could perform comparably to neural networks with bias at least on practical image classification tasks. In addition, we prove that zero-bias neural networks possess a nice property called scalar (multiplication) invariance, which allows the prediction of neural networks remains the same when altering the contrast of the input image. We then extend scalar invariance to more general cases that a
    
[^110]: SSL4EO-S12:自监督学习在地球观测中的大规模多模态、多时相数据集

    SSL4EO-S12: A Large-Scale Multi-Modal, Multi-Temporal Dataset for Self-Supervised Learning in Earth Observation. (arXiv:2211.07044v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.07044](http://arxiv.org/abs/2211.07044)

    该论文介绍了一种名为SSL4EO-S12的大规模、全球、多模态、多季度的自监督学习地球观测数据集，证明了对该数据集进行自监督预训练可以产生准确性与监督学习相当的模型，在该领域具有很高的应用价值。

    

    自我监督预训练有望生成表现力强的表征，而地球观测领域的大多数预训练都基于ImageNet或中等规模的标记的遥感数据集。我们分享了一个未标记的地球观测数据集SSL4EO-S12，从欧空局Sentinel-1和-2卫星任务中装配了一个大规模、全球、多模态和多季节的卫星图像语料库。对于EO应用，我们展示SSL4EO-S12在自监督预训练方面取得了成功，并成功地应用于几种方法：MoCo-v2，DINO，MAE和data2vec。结果模型的下游性能接近或超过了监督学习的准确性度量。此外，与现有数据集相比，对SSL4EO-S12的预训练表现出色。我们在https://github.com/zhu-xlab/SSL4EO-S12上公开了数据集、相关源代码和预训练模型。

    Self-supervised pre-training bears potential to generate expressive representations without human annotation. Most pre-training in Earth observation (EO) are based on ImageNet or medium-size, labeled remote sensing (RS) datasets. We share an unlabeled RS dataset SSL4EO-S12 (Self-Supervised Learning for Earth Observation - Sentinel-1/2) to assemble a large-scale, global, multimodal, and multi-seasonal corpus of satellite imagery from the ESA Sentinel-1 \& -2 satellite missions. For EO applications we demonstrate SSL4EO-S12 to succeed in self-supervised pre-training for a set of methods: MoCo-v2, DINO, MAE, and data2vec. Resulting models yield downstream performance close to, or surpassing accuracy measures of supervised learning. In addition, pre-training on SSL4EO-S12 excels compared to existing datasets. We make openly available the dataset, related source code, and pre-trained models at https://github.com/zhu-xlab/SSL4EO-S12.
    
[^111]: 基于强化学习的自然语言视觉推理：lilGym

    lilGym: Natural Language Visual Reasoning with Reinforcement Learning. (arXiv:2211.01994v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.01994](http://arxiv.org/abs/2211.01994)

    本文提出了一个基于自然语言视觉推理的强化学习基准测试——lilGym，它由2661个高度组合的人类编写自然语言语句和交互式视觉环境组成，并通过注释可执行Python程序来实现精确的奖励计算。本文的实验结果和分析表明，lilGym是一个具有挑战性的开放性问题。

    

    本文介绍了一种新的有关语言条件下强化学习在视觉环境下的基准测试——lilGym。lilGym基于2661个高度组合的人类编写的自然语言陈述，这些陈述是基于一个交互式视觉环境的。我们采用了一种新的方法，在每种可能的世界状态下，通过为所有语句注释可执行的Python程序，实现了精确的奖励计算。每个语句都与多个起始状态和奖励函数配对，以形成数千个不同难度的马尔可夫决策过程。我们使用不同的模型和学习机制进行了lilGym实验。我们的实验结果和分析表明，虽然现有的方法能够实现较高的性能，但是lilGym形成了一个具有挑战性的开放性问题。lilGym可以在 https://lil.nlp.cornell.edu/lilgym/ 上获得。

    We present lilGym, a new benchmark for language-conditioned reinforcement learning in visual environments. lilGym is based on 2,661 highly-compositional human-written natural language statements grounded in an interactive visual environment. We introduce a new approach for exact reward computation in every possible world state by annotating all statements with executable Python programs. Each statement is paired with multiple start states and reward functions to form thousands of distinct Markov Decision Processes of varying difficulty. We experiment with lilGym with different models and learning regimes. Our results and analysis show that while existing methods are able to achieve non-trivial performance, lilGym forms a challenging open problem. lilGym is available at https://lil.nlp.cornell.edu/lilgym/.
    
[^112]: 通过多任务微调实现跨语言泛化

    Crosslingual Generalization through Multitask Finetuning. (arXiv:2211.01786v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.01786](http://arxiv.org/abs/2211.01786)

    该论文通过多任务微调实现跨语言泛化。研究表明，在英语提示下，对大型多语言模型进行英语任务的微调，可以实现对仅出现在预训练语料库中的非英语语言的任务泛化，并且使用英语提示进行多语言任务的微调进一步提高了在英语和非英语任务上的表现，从而实现了各种零-shot结果的最新水平。

    

    已经证明，多任务微调可以帮助大型语言模型在零-shot场景下推广到新的任务，但目前MTF的研究集中在英语数据和模型上。我们将MTF应用于预训练的多语言BLOOM和mT5模型系列，生成了经过微调的变体BLOOMZ和mT0。我们发现，在英语提示下，对大型多语言语言模型进行英语任务的微调，可以实现对仅出现在预训练语料库中的非英语语言的任务泛化。使用英语提示进行多语言任务的微调进一步提高了在英语和非英语任务上的表现，从而实现了各种零-shot结果的最新水平。我们还研究了在英语翻译为每个数据集的语言的情况下进行多语言任务微调。我们发现，在这些机器翻译提示上训练可以在各自语言中更好地完成人写的提示。令人惊讶的是，我们发现m

    Multitask prompted finetuning (MTF) has been shown to help large language models generalize to new tasks in a zero-shot setting, but so far explorations of MTF have focused on English data and models. We apply MTF to the pretrained multilingual BLOOM and mT5 model families to produce finetuned variants called BLOOMZ and mT0. We find finetuning large multilingual language models on English tasks with English prompts allows for task generalization to non-English languages that appear only in the pretraining corpus. Finetuning on multilingual tasks with English prompts further improves performance on English and non-English tasks leading to various state-of-the-art zero-shot results. We also investigate finetuning on multilingual tasks with prompts that have been machine-translated from English to match the language of each dataset. We find training on these machine-translated prompts leads to better performance on human-written prompts in the respective languages. Surprisingly, we find m
    
[^113]: 自适应音频视觉关注的视觉感知音频字幕生成

    Visually-Aware Audio Captioning With Adaptive Audio-Visual Attention. (arXiv:2210.16428v2 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2210.16428](http://arxiv.org/abs/2210.16428)

    本文提出了一种自适应音频视觉关注的视觉感知音频字幕生成方法，通过利用视觉上下文来帮助解决音频字幕生成中的歧义声音问题。在AudioCaps上实验结果表明，该方法在机器翻译指标上取得了最佳结果。

    

    音频字幕生成旨在产生音频片段的文本描述。在现实世界中，许多对象会产生相似的声音。如何准确识别模糊的声音是音频字幕生成的主要挑战。本文受到人类固有多模态感知的启发，提出了视觉感知音频字幕生成，利用视觉信息来帮助描述模糊的声音对象。具体而言，我们引入了一个现成的视觉编码器来提取视频特征，并将其结合到音频字幕生成系统中。此外，为了更好地利用互补的音频-视觉环境，我们提出了一种自适应音频-视觉关注机制，该机制自适应地整合音频和视觉上下文，并消除潜在空间中的冗余信息。在AudioCaps上进行的实验结果表明，我们提出的方法在机器翻译指标上取得了最先进的成果。

    Audio captioning aims to generate text descriptions of audio clips. In the real world, many objects produce similar sounds. How to accurately recognize ambiguous sounds is a major challenge for audio captioning. In this work, inspired by inherent human multimodal perception, we propose visually-aware audio captioning, which makes use of visual information to help the description of ambiguous sounding objects. Specifically, we introduce an off-the-shelf visual encoder to extract video features and incorporate the visual features into an audio captioning system. Furthermore, to better exploit complementary audio-visual contexts, we propose an audio-visual attention mechanism that adaptively integrates audio and visual context and removes the redundant information in the latent space. Experimental results on AudioCaps, the largest audio captioning dataset, show that our proposed method achieves state-of-the-art results on machine translation metrics.
    
[^114]: 最短编辑路径交叉：演化神经网络结构搜索排列问题的理论驱动解决方案

    Shortest Edit Path Crossover: A Theory-driven Solution to the Permutation Problem in Evolutionary Neural Architecture Search. (arXiv:2210.14016v4 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2210.14016](http://arxiv.org/abs/2210.14016)

    本文提出了一种基于最短编辑路径的交叉操作符，用以解决黑盒神经网络结构搜索中的排列问题，并在理论上证明了其优于突变的期望改进。

    

    最近，基于种群的搜索已经成为黑盒神经网络结构搜索（NAS）中可能替代强化学习（RL）的一个选择。尽管它在实践中表现良好，但它在理论上尚未被很好地理解。特别地，虽然传统的基于种群的搜索方法如演化算法（EAs）从交叉操作中汲取了很多力量，但在NAS中很难利用它们。主要障碍被认为是排列问题：在传统的图表示中，基因型和表现型之间的映射是一对多的，导致标准交叉产生破坏性影响。本文首次提出了对黑盒NAS中突变、交叉和RL行为进行理论分析，并基于图空间中的最短编辑路径（SEP）提出了一种新的交叉操作符。理论上表明，SEP交叉可以克服排列问题，因此与突变相比，具有更好的期望改进。

    Population-based search has recently emerged as a possible alternative to Reinforcement Learning (RL) for black-box neural architecture search (NAS). It performs well in practice even though it is not theoretically well understood. In particular, whereas traditional population-based search methods such as evolutionary algorithms (EAs) draw much power from crossover operations, it is difficult to take advantage of them in NAS. The main obstacle is believed to be the permutation problem: The mapping between genotype and phenotype in traditional graph representations is many-to-one, leading to a disruptive effect of standard crossover. This paper presents the first theoretical analysis of the behaviors of mutation, crossover and RL in black-box NAS, and proposes a new crossover operator based on the shortest edit path (SEP) in graph space. The SEP crossover is shown theoretically to overcome the permutation problem, and as a result, have a better expected improvement compared to mutation,
    
[^115]: 基于子图的GNN后门攻击研究

    Motif-Backdoor: Rethinking the Backdoor Attack on Graph Neural Networks via Motifs. (arXiv:2210.13710v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.13710](http://arxiv.org/abs/2210.13710)

    本文提出了一种基于motif的GNN后门攻击方法，设计了一种基于motif的触发器生成器，能够提高后门攻击的隐蔽性和效果，在各种基准数据集上进行实验证明其性能优于现有方法。

    

    具有强大表示能力的图神经网络（GNN）已经被广泛应用于生物基因预测、社交推荐等领域。最近的研究表明，GNN容易受到后门攻击的影响，即使用恶意样本训练的模型很容易被修补后的样本欺骗。大多数的后门攻击研究使用的触发器要么是随机生成的子图（例如 erd\H{o}s-r\'enyi 后门），以减轻计算负担，要么是基于梯度的生成子图（例如图Trojan攻击），以使攻击更加有效。然而，如何理解触发器结构与后门攻击效果之间的关系却在当前文献中被忽略了。在图中，重复性和具有统计显著性的子图（motif）包含了丰富的结构信息。因此，本文从motif的角度重新思考触发器的设计，并提出一种基于motif的GNN后门攻击方法。我们设计了一种基于motif的触发器生成器，利用motif信息提高了后门攻击的隐蔽性和效果。在各种基准数据集上进行了大量实验，结果表明我们的方法在攻击成功率和隐蔽性方面均优于现有的后门攻击方法。

    Graph neural network (GNN) with a powerful representation capability has been widely applied to various areas, such as biological gene prediction, social recommendation, etc. Recent works have exposed that GNN is vulnerable to the backdoor attack, i.e., models trained with maliciously crafted training samples are easily fooled by patched samples. Most of the proposed studies launch the backdoor attack using a trigger that either is the randomly generated subgraph (e.g., erd\H{o}s-r\'enyi backdoor) for less computational burden, or the gradient-based generative subgraph (e.g., graph trojaning attack) to enable a more effective attack. However, the interpretation of how is the trigger structure and the effect of the backdoor attack related has been overlooked in the current literature. Motifs, recurrent and statistically significant sub-graphs in graphs, contain rich structure information. In this paper, we are rethinking the trigger from the perspective of motifs, and propose a motif-ba
    
[^116]: 基于源内样式增强的领域泛化改进方法

    Intra-Source Style Augmentation for Improved Domain Generalization. (arXiv:2210.10175v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2210.10175](http://arxiv.org/abs/2210.10175)

    本论文提出了一种基于源内样式增强（ISSA）的方法，用于改进语义分割中的领域泛化。通过使用掩模噪声编码器随机化样式和内容组合，ISSA有效地增加了训练数据的多样性并减少了虚假相关性，从而在不同类型的驾驶场景语义分割中获得了高达12.4％的mIoU改进。

    

    深度学习模型在应用中经常出现领域偏移，比如在自动驾驶中的泛化仍然是一个重大挑战。因此，我们提出了一种基于源内样式增强（ISSA）的方法，用于改进语义分割中的领域泛化。我们的方法基于一种新型的StyleGAN2反演掩模噪声编码器。该模型通过噪声预测学习忠实重建图像并保留其语义布局。估计噪声的随机掩蔽使我们的模型具有样式混合能力，即它可以在不影响图像语义布局的情况下改变全局外观。使用所提出的掩模噪声编码器来随机化训练集中的样式和内容组合，ISSA有效地增加了训练数据的多样性并减少了虚假相关性。结果，在不同类型的驾驶场景语义分割中，我们取得了高达12.4％的mIoU改进。

    The generalization with respect to domain shifts, as they frequently appear in applications such as autonomous driving, is one of the remaining big challenges for deep learning models. Therefore, we propose an intra-source style augmentation (ISSA) method to improve domain generalization in semantic segmentation. Our method is based on a novel masked noise encoder for StyleGAN2 inversion. The model learns to faithfully reconstruct the image preserving its semantic layout through noise prediction. Random masking of the estimated noise enables the style mixing capability of our model, i.e. it allows to alter the global appearance without affecting the semantic layout of an image. Using the proposed masked noise encoder to randomize style and content combinations in the training set, ISSA effectively increases the diversity of training data and reduces spurious correlation. As a result, we achieve up to $12.4\%$ mIoU improvements on driving-scene semantic segmentation under different type
    
[^117]: STaSy：基于分值的表格数据生成

    STaSy: Score-based Tabular data Synthesis. (arXiv:2210.04018v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.04018](http://arxiv.org/abs/2210.04018)

    提出了一种新的基于分值的表格数据生成模型（STaSy），并采用自适应学习技术和微调策略进一步提高采样质量和多样性。

    

    表格数据生成是机器学习中一个长期存在的研究主题。过去几十年中提出了许多不同的方法，从统计方法到深度生成式方法。然而，由于实际表格数据的复杂性，它并不总是成功的。在本文中，我们提出了一种名为基于分值的表格数据生成（STaSy）的新模型及其基于分值生成建模范例的训练策略。尽管基于分值的生成模型已经解决了许多生成模型中的问题，但表格数据生成仍有改进的空间。我们提出的训练策略包括自适应学习技术和微调策略，通过稳定去噪分值匹配训练进一步增加采样质量和多样性。此外，我们还从采样质量、多样性和时间三个方面进行了严格的实验研究。在o

    Tabular data synthesis is a long-standing research topic in machine learning. Many different methods have been proposed over the past decades, ranging from statistical methods to deep generative methods. However, it has not always been successful due to the complicated nature of real-world tabular data. In this paper, we present a new model named Score-based Tabular data Synthesis (STaSy) and its training strategy based on the paradigm of score-based generative modeling. Despite the fact that score-based generative models have resolved many issues in generative models, there still exists room for improvement in tabular data synthesis. Our proposed training strategy includes a self-paced learning technique and a fine-tuning strategy, which further increases the sampling quality and diversity by stabilizing the denoising score matching training. Furthermore, we also conduct rigorous experimental studies in terms of the generative task trilemma: sampling quality, diversity, and time. In o
    
[^118]: VIMA：多模态提示实现通用机器人操作

    VIMA: General Robot Manipulation with Multimodal Prompts. (arXiv:2210.03094v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2210.03094](http://arxiv.org/abs/2210.03094)

    本研究提出了一种新的机器人操作方式——多模态提示实现通用机器人操作。通过设计一个基于变压器的机器人代理VIMA，可以处理提示并自回归地输出电机动作，实现了各种任务类型的最新结果，并能够零样本泛化到新的对象类别，这对实现通用机器人操作具有前景。

    

    基于提示的学习模式已经成为自然语言处理中的成功范例，在此模式下，单个通用语言模型可以按照输入提示执行任何任务。然而，在机器人工程中，任务规范的形式多种多样，例如，模仿单次演示、遵循语言指令和达到视觉目标等。这些任务通常被认为是不同的任务，并由专门的模型来处理。我们展示了一种广泛的机器人操作任务可以通过多模态提示来表达，交错文本和视觉令牌。因此，我们开发了一个新的仿真基准，其中包含数千个程序生成的桌面任务，具有多模态提示，60万个专家轨迹以进行模仿学习，并采用四级评估协议进行系统化的广义化。我们设计了一个基于变压器的机器人代理，VIMA，该代理处理这些提示并自回归地输出电机动作。VIMA具有一套配方，实现了各种任务类型的最新结果，包括未见过的模态组合，甚至可以零样本泛化到新的对象类别。总体而言，我们的工作提出了一种有前途的方法，采用统一的基于提示的框架实现通用机器人操作。

    Prompt-based learning has emerged as a successful paradigm in natural language processing, where a single general-purpose language model can be instructed to perform any task specified by input prompts. Yet task specification in robotics comes in various forms, such as imitating one-shot demonstrations, following language instructions, and reaching visual goals. They are often considered different tasks and tackled by specialized models. We show that a wide spectrum of robot manipulation tasks can be expressed with multimodal prompts, interleaving textual and visual tokens. Accordingly, we develop a new simulation benchmark that consists of thousands of procedurally-generated tabletop tasks with multimodal prompts, 600K+ expert trajectories for imitation learning, and a four-level evaluation protocol for systematic generalization. We design a transformer-based robot agent, VIMA, that processes these prompts and outputs motor actions autoregressively. VIMA features a recipe that achieve
    
[^119]: 生成式检索的非参数化解码方法

    Nonparametric Decoding for Generative Retrieval. (arXiv:2210.02068v3 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2210.02068](http://arxiv.org/abs/2210.02068)

    本文提出了一种非参数化解码方法，通过利用上下文化词汇嵌入，解决了生成式检索模型信息容量受限的问题，在文档检索任务中具有高效性和高性能。

    

    生成式检索模型仅依赖于其模型参数中编码的信息，没有外部存储器，其信息容量受到限制并且是固定的。为了克服这一限制，我们提出了一种非参数化解码方法（Np Decoding），可以应用于现有的生成式检索模型中。Np Decoding使用非参数化的上下文化词汇嵌入（外部存储器），而不是作为解码器词汇嵌入的常规词汇嵌入。通过利用上下文化词汇嵌入，生成式检索模型能够同时利用参数空间和非参数空间。在9个数据集（8个单跳和1个多跳）的文档检索任务中的评估表明，将Np Decoding应用于生成式检索模型可以显著提高性能。我们还表明，Np Decoding具有数据和参数效率，并在零样本设置中表现出高性能。

    The generative retrieval model depends solely on the information encoded in its model parameters without external memory, its information capacity is limited and fixed. To overcome the limitation, we propose Nonparametric Decoding (Np Decoding) which can be applied to existing generative retrieval models. Np Decoding uses nonparametric contextualized vocab embeddings (external memory) rather than vanilla vocab embeddings as decoder vocab embeddings. By leveraging the contextualized vocab embeddings, the generative retrieval model is able to utilize both the parametric and nonparametric space. Evaluation over 9 datasets (8 single-hop and 1 multi-hop) in the document retrieval task shows that applying Np Decoding to generative retrieval models significantly improves the performance. We also show that Np Decoding is dataand parameter-efficient, and shows high performance in the zero-shot setting.
    
[^120]: 基于课程的序列神经解码器用于极化编码族的研究

    CRISP: Curriculum based Sequential Neural Decoders for Polar Code Family. (arXiv:2210.00313v3 [cs.IT] UPDATED)

    [http://arxiv.org/abs/2210.00313](http://arxiv.org/abs/2210.00313)

    该研究提出了一种新颖的基于课程的序列神经解码器CRISP，可以用于极化编码族，相比连续取消(SC)译码器，CRISP具有更高的准确性和可靠性，并可轻松地拓展至极化调整卷积（PAC）代码。

    

    极化编码是可靠通信的最新规范（5G）中广泛使用的最先进的编码，但在短块长度范围内设计既高效又可靠的极化译码器仍有空间。受数据驱动信道译码成功的启发，我们引入了一种新颖的基于课程的序列神经解码器，用于极化编码（CRISP）。我们设计了一种受信息理论启发的有原则的课程来训练CRISP，并表明它在Polar（32,16）和Polar（64,22）代码上优于连续取消(SC)译码器并达到接近最优的 可靠性能。所提议的课程选择对于实现CRISP的准确性增益至关重要，正如我们通过与其他课程的比较所示。值得注意的是，CRISP可以轻松地扩展到极化调整卷积（PAC）代码，其中现有SC解码器性能损失很大。

    Polar codes are widely used state-of-the-art codes for reliable communication that have recently been included in the 5th generation wireless standards (5G). However, there remains room for the design of polar decoders that are both efficient and reliable in the short blocklength regime. Motivated by recent successes of data-driven channel decoders, we introduce a novel $\textbf{C}$ur$\textbf{RI}$culum based $\textbf{S}$equential neural decoder for $\textbf{P}$olar codes (CRISP). We design a principled curriculum, guided by information-theoretic insights, to train CRISP and show that it outperforms the successive-cancellation (SC) decoder and attains near-optimal reliability performance on the Polar(32,16) and Polar(64,22) codes. The choice of the proposed curriculum is critical in achieving the accuracy gains of CRISP, as we show by comparing against other curricula. More notably, CRISP can be readily extended to Polarization-Adjusted-Convolutional (PAC) codes, where existing SC decod
    
[^121]: FIGO:使用GAN和单样本学习技术的增强指纹识别方法

    FIGO: Enhanced Fingerprint Identification Approach Using GAN and One Shot Learning Techniques. (arXiv:2208.05615v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2208.05615](http://arxiv.org/abs/2208.05615)

    本文提出了一种基于GAN和单样本学习技术的FIGO指纹识别方法，通过Pix2Pix模型对低质量指纹图像进行增强，在识别环节中使用一次学习进行指纹信息分类，取得了更好的性能。

    

    指纹证据在刑侦调查中发挥着重要作用，但自动化指纹识别仍处于早期阶段。本文提出了一种基于生成对抗网络和单样本学习技术的指纹识别方法（FIGO），包含指纹增强和指纹识别两个环节。采用Pix2Pix模型直接在指纹增强环节将低质量指纹图像转换为高像素水平指纹图像，使用一次学习技术和孪生网络架构在识别环节中进行指纹信息的分类和比对。实验结果表明，与其他方法相比，该方法取得了更好的性能。

    Fingerprint evidence plays an important role in a criminal investigation for the identification of individuals. Although various techniques have been proposed for fingerprint classification and feature extraction, automated fingerprint identification of fingerprints is still in its earliest stage. The performance of traditional \textit{Automatic Fingerprint Identification System} (AFIS) depends on the presence of valid minutiae points and still requires human expert assistance in feature extraction and identification stages. Based on this motivation, we propose a Fingerprint Identification approach based on Generative adversarial network and One-shot learning techniques (FIGO). Our solution contains two components: fingerprint enhancement tier and fingerprint identification tier. First, we propose a Pix2Pix model to transform low-quality fingerprint images to a higher level of fingerprint images pixel by pixel directly in the fingerprint enhancement tier. With the proposed enhancement 
    
[^122]: ME-GAN：基于心脏疾病条件学习全景心电图表示的多视角ECG合成

    ME-GAN: Learning Panoptic Electrocardio Representations for Multi-view ECG Synthesis Conditioned on Heart Diseases. (arXiv:2207.10670v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2207.10670](http://arxiv.org/abs/2207.10670)

    本文提出一种基于心脏疾病条件学习全景心电图表示的多视角ECG合成方法ME-GAN，利用新的混合归一化方法将疾病信息注入到合适位置，具有较好的生成效果和疾病识别能力。

    

    心电图( ECG)是一种广泛使用的非侵入性诊断工具，用于检测心脏疾病。许多研究已经设计了ECG分析模型(如分类器)来辅助诊断。作为一个上游任务，研究人员建立生成模型来合成ECG数据，这有利于提供训练样本、隐私保护和注释减少。然而，以前的ECG生成方法往往既没有合成多视图数据，也没有处理心脏疾病情况。在本文中，我们提出了一种新的以疾病为导向的多视角ECG合成生成对抗网络ME-GAN，它获得了基于心脏疾病条件的全景心电图表示，并将这些表示投影到多个标准视图上以产生ECG信号。由于心脏疾病的ECG表现通常局部化在特定的波形中，我们提出了一种新的"混合归一化"方法，以将疾病信息精确地注入到合适的位置。

    Electrocardiogram (ECG) is a widely used non-invasive diagnostic tool for heart diseases. Many studies have devised ECG analysis models (e.g., classifiers) to assist diagnosis. As an upstream task, researches have built generative models to synthesize ECG data, which are beneficial to providing training samples, privacy protection, and annotation reduction. However, previous generative methods for ECG often neither synthesized multi-view data, nor dealt with heart disease conditions. In this paper, we propose a novel disease-aware generative adversarial network for multi-view ECG synthesis called ME-GAN, which attains panoptic electrocardio representations conditioned on heart diseases and projects the representations onto multiple standard views to yield ECG signals. Since ECG manifestations of heart diseases are often localized in specific waveforms, we propose a new "mixup normalization" to inject disease information precisely into suitable locations. In addition, we propose a view 
    
[^123]: 可掩蔽世界模型用于视觉控制

    Masked World Models for Visual Control. (arXiv:2206.14244v3 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2206.14244](http://arxiv.org/abs/2206.14244)

    本研究提出了一种视觉模型驱动的RL框架，将视觉表示学习和动力学学习分离，使用自编码器和潜在动力学模型来准确建模机器人控制策略。

    

    视觉模型驱动的强化学习（RL）有潜力使机器人能够从视觉观测中实现样本有效的学习。但目前的方法通常训练一个端到端的单一模型来学习视觉表示和动力学，使得准确建模机器人与小物体之间的相互作用变得困难。本研究介绍了一种视觉模型驱动的RL框架，将视觉表示学习和动力学学习分离。具体来说，我们使用卷积层和视觉变换器（ViT）来训练自编码器，以在给定掩蔽卷积特征的情况下重构像素，并学习一个操作自编码器表示的潜在动力学模型。此外，为了编码任务相关信息，我们引入了一个辅助奖励预测目标来训练自编码器。我们使用从环境交互中收集的在线样本不断更新自编码器和动力学模型。我们证明了我们的分离策略可以有效地学习机器人控制策略。

    Visual model-based reinforcement learning (RL) has the potential to enable sample-efficient robot learning from visual observations. Yet the current approaches typically train a single model end-to-end for learning both visual representations and dynamics, making it difficult to accurately model the interaction between robots and small objects. In this work, we introduce a visual model-based RL framework that decouples visual representation learning and dynamics learning. Specifically, we train an autoencoder with convolutional layers and vision transformers (ViT) to reconstruct pixels given masked convolutional features, and learn a latent dynamics model that operates on the representations from the autoencoder. Moreover, to encode task-relevant information, we introduce an auxiliary reward prediction objective for the autoencoder. We continually update both autoencoder and dynamics model using online samples collected from environment interaction. We demonstrate that our decoupling a
    
[^124]: 《全球AI伦理：200个AI治理指南和建议的综述》

    Worldwide AI Ethics: a review of 200 guidelines and recommendations for AI governance. (arXiv:2206.11922v5 [cs.CY] UPDATED)

    [http://arxiv.org/abs/2206.11922](http://arxiv.org/abs/2206.11922)

    本篇论文回顾了200个AI治理指南和建议，通过对这些文档内容和性质的可视化，旨在了解各机构间AI伦理原则存在的共识和相似点，为未来的法规辩论提供启示。

    

    在过去的十年中，一些组织已经制定了文件，旨在规范和推动我们最近和快速发展的AI技术的指南。然而，除了一些领域的元分析和批判性评论外，这些文件中呈现的完整思想光谱尚未得到分析。在这项工作中，我们试图扩展过去研究人员所做的工作，创建一个更好的数据可视化工具，以了解各机构所倡导原则之间是否存在共识或相似之处，这可能会激发未来的法规辩论。我们还通过对200份文档样本的方法论结果进行批判性分析，提出了一些初步的想法和问题，以指导研究的连续性。

    In the last decade, several organizations have produced documents intended to standardize, in the normative sense, and promote guidance to our recent and rapid AI development. However, the full spectrum of ideas presented in these documents has not yet been analyzed, except for a few meta-analyses and critical reviews of the field. In this work, we seek to expand on the work done by past researchers and create a tool for better data visualization of the contents and nature of these documents, to understand whether there is consensus or similarity between the principles espoused by various institutions, which may inspire debates on future regulations. We also provide some preliminary thoughts and questions that could guide the continuity of the research through a critical analysis of the results acquired by our methodology into a sample size of 200 documents.
    
[^125]: 带有偏好引导的个性化算法干预研究

    Personalized Algorithmic Recourse with Preference Elicitation. (arXiv:2205.13743v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.13743](http://arxiv.org/abs/2205.13743)

    研究提出了PEAR方法，这是一个首个能够针对最终用户需求提供个性化算法补救成本的人机交互方法。该方法利用贝叶斯偏好引导的见解，通过最大化原则性信息增益度量来计算目标用户选择的预期效用，然后将偏好引导整合到强化学习框架中。该方法显著提高了算法干预的经济实用性和用户友好性。

    

    算法干预（AR）的问题是计算用户执行一系列操作以颠覆不良机器决策的过程。该过程的操作序列不应该对用户的实施提出过高的要求。然而，大多数AR方法都假设所有用户的操作成本相同，因此可能会向某些用户推荐昂贵的补救计划。为了解决这个问题，我们提出了PEAR，这是一种首个可提供个性化算法补救成本的人机交互方法，以满足任何最终用户的需求。PEAR利用贝叶斯偏好引导的见解，通过向目标用户发出选择集查询来迭代地改善对操作成本的估计值。这些查询的计算是通过最大化选择的预期效用来计算的，这是一种能够考虑成本估计和用户响应不确定性的原则性信息增益度量。PEAR将偏好引导整合到强化学习框架中，同时考虑用户实现AR任务所需达成目标的偏好，以及执行每个操作所涉及的成本。我们通过引入更具挑战性的AR任务来评估PEAR，并显示其比现有的方法找到了更为经济实用且用户友好的补救计划。

    Algorithmic Recourse (AR) is the problem of computing a sequence of actions that -- once performed by a user -- overturns an undesirable machine decision. It is paramount that the sequence of actions does not require too much effort for users to implement. Yet, most approaches to AR assume that actions cost the same for all users, and thus may recommend unfairly expensive recourse plans to certain users. Prompted by this observation, we introduce PEAR, the first human-in-the-loop approach capable of providing personalized algorithmic recourse tailored to the needs of any end-user. PEAR builds on insights from Bayesian Preference Elicitation to iteratively refine an estimate of the costs of actions by asking choice set queries to the target user. The queries themselves are computed by maximizing the Expected Utility of Selection, a principled measure of information gain accounting for uncertainty on both the cost estimate and the user's responses. PEAR integrates elicitation into a Rein
    
[^126]: 探究图自编码器中 Masked Graph Modeling 的作用

    What's Behind the Mask: Understanding Masked Graph Modeling for Graph Autoencoders. (arXiv:2205.10053v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.10053](http://arxiv.org/abs/2205.10053)

    本文探究了 Masked Graph Modeling 在图自编码器中的有效应用，并提出了基于蒙版的图建模（MGM）作为自监督学习的一个原先的任务，证明了它的优势作用。在获得了理论及实证证据的支持后，我们提出了 MaskGAE，一种可扩展有效的自监督学习方法。

    

    近年来，自监督学习的一种颇具潜力的策略被称为 Masked Autoencoding。然而，对于在图自编码器中如何实现 Masking，理论上仍然存在缺失。本文提出了 Masked Graph Autoencoder （MaskGAE），它是用于图结构数据的自监督学习框架。相较于其它普通的 GAEs，MaskGAE 采用基于蒙版的图建模（Masked Graph Modeling，MGM）作为一个原先的任务。在这个任务中，“掩蔽”一个部分边缘，以部分可视、非掩蔽的图结构，试图重构缺失的部分。我们提供了理论及实证证据，全面证明了此预测任务优势的作用，以探究 MGM 对 GAEs 的输出表示的改善作用。在理论上，我们建立了 GAEs 与对比学习的紧密关系，表明 MGM 明显改善了 GAEs 的自监督学习方案。在经验方面，我们在各种基准数据集上进行了广泛实验，并展示了 MaskGAE 在各种评估指标下始终优于最先进的 GAEs。本研究为探究 Masked Graph Modeling 在图自编码器中的重要性提供了启示，并为图表示学习提供了一种可扩展和有效的自监督学习方法。

    The last years have witnessed the emergence of a promising self-supervised learning strategy, referred to as masked autoencoding. However, there is a lack of theoretical understanding of how masking matters on graph autoencoders (GAEs). In this work, we present masked graph autoencoder (MaskGAE), a self-supervised learning framework for graph-structured data. Different from standard GAEs, MaskGAE adopts masked graph modeling (MGM) as a principled pretext task - masking a portion of edges and attempting to reconstruct the missing part with partially visible, unmasked graph structure. To understand whether MGM can help GAEs learn better representations, we provide both theoretical and empirical evidence to comprehensively justify the benefits of this pretext task. Theoretically, we establish close connections between GAEs and contrastive learning, showing that MGM significantly improves the self-supervised learning scheme of GAEs. Empirically, we conduct extensive experiments on a variet
    
[^127]: 视觉语言预训练模型是否学习到组合原始概念？

    Do Vision-Language Pretrained Models Learn Composable Primitive Concepts?. (arXiv:2203.17271v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2203.17271](http://arxiv.org/abs/2203.17271)

    本文研究了视觉语言预训练模型是否自动产生原始概念的表示，提出组合概念映射（CompMap）框架来研究，认为如果模型确实产生了原始概念，其激活应符合先前人类对原始概念的观察结果。

    

    视觉语言（VL）预训练模型在多模态推理和零样本识别任务中取得了令人瞩目的性能。许多VL模型是在互联网上无标注的图像和标题对上预训练的。本文研究了这些预训练的VL模型是否自动产生原始概念的表示，例如颜色、形状或物体部分的属性。我们提出了一个两步框架，组合概念映射（CompMap）来研究这个问题。CompMap首先请求VL模型使用文本提示生成原始概念激活，然后学习构建一个组合模型，将原始概念激活（例如黑色尾巴或红色翅膀的可能性）映射到组合概念（例如红翅黑鸟）。我们展示了可以从真实的原始概念稳定地学习到组合模型。因此，我们假设如果预训练的VL模型确实产生了原始概念，则其原始概念激活...

    Vision-language (VL) pretrained models have achieved impressive performance on multimodal reasoning and zero-shot recognition tasks. Many of these VL models are pretrained on unlabeled image and caption pairs from the internet. In this paper, we study whether representations of primitive concepts--such as colors, shapes, or the attributes of object parts--emerge automatically within these pretrained VL models. We propose a two-step framework, Compositional Concept Mapping (CompMap), to investigate this. CompMap first asks a VL model to generate primitive concept activations with text prompts, and then learns to construct a composition model that maps the primitive concept activations (e.g. the likelihood of black tail or red wing) to composite concepts (e.g. a red-winged blackbird). We show that a composition model can be reliably learn from ground truth primitive concepts. We thus hypothesize that if primitive concepts indeed emerge in a VL pretrained model, its primitive concept acti
    
[^128]: 动态特征快速说话者适应在言语障碍和老年人语音识别中的应用

    On-the-Fly Feature Based Rapid Speaker Adaptation for Dysarthric and Elderly Speech Recognition. (arXiv:2203.14593v3 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2203.14593](http://arxiv.org/abs/2203.14593)

    本文提出了两种新形式的数据有效、基于特征的动态说话者适应方法，能够显著提高言语障碍和老年人语音识别的准确率。

    

    目前，准确识别言语障碍和老年人的语音仍然是一个具有挑战性的任务。由口音或性别引起的说话者级别的异质性，与年龄和言语障碍相结合，使这些说话者之间的差异很大。说话者级别数据的稀缺限制了基于数据密集型模型的说话者适应方法的实际应用。因此，本文提出了两种新形式的数据有效、基于特征的动态说话者适应方法：方差正则化频谱基准嵌入（SVR）和谱特征驱动的f-LHUC转换。在UASpeech言语障碍和DementiaBank Pitt老年人语音语料库上进行的实验证明，所提出的动态说话者适应方法能够持续地优于基线iVector自适应混合DNN/TDNN和E2E Conformer系统，统计显著地减少WER 2.48%-2.85%（绝对值）（7.92%-8.06%相关），与离线模型基础LHUC适应分别减小1.82%（相对值）。

    Accurate recognition of dysarthric and elderly speech remain challenging tasks to date. Speaker-level heterogeneity attributed to accent or gender, when aggregated with age and speech impairment, create large diversity among these speakers. Scarcity of speaker-level data limits the practical use of data-intensive model based speaker adaptation methods. To this end, this paper proposes two novel forms of data-efficient, feature-based on-the-fly speaker adaptation methods: variance-regularized spectral basis embedding (SVR) and spectral feature driven f-LHUC transforms. Experiments conducted on UASpeech dysarthric and DementiaBank Pitt elderly speech corpora suggest the proposed on-the-fly speaker adaptation approaches consistently outperform baseline iVector adapted hybrid DNN/TDNN and E2E Conformer systems by statistically significant WER reduction of 2.48%-2.85% absolute (7.92%-8.06% relative), and offline model based LHUC adaptation by 1.82% absolute (5.63% relative) respectively.
    
[^129]: LSTM模型用于预测石油公司股票的可解释性：相关特征的影响

    The Interpretability of LSTM Models for Predicting Oil Company Stocks: impacts of correlated features. (arXiv:2201.00350v3 [q-fin.ST] UPDATED)

    [http://arxiv.org/abs/2201.00350](http://arxiv.org/abs/2201.00350)

    研究探究了相关特征对用于预测石油公司股票的LSTM模型的可解释性的影响。结果表明，添加与石油股票相关的特征并不会提高LSTM模型的可解释性，因此应谨慎依靠LSTM模型进行股票市场决策。

    

    石油公司是全球最大的公司之一，由于与黄金、原油和美元相关，其经济指标对全球经济和市场有着巨大的影响。本研究调查了相关特征对用于预测石油公司股票的长短期记忆(LSTM)模型的可解释性的影响。为了实现这一目标，我们设计了标准的LSTM网络，并使用各种相关数据集进行了训练。我们的方法旨在通过考虑影响市场的多个因素，如原油价格、黄金价格和美元，来提高股票价格预测的准确性。结果表明，添加与石油股票相关的特征并不会提高LSTM模型的可解释性。这些发现表明，虽然LSTM模型在预测股票价格方面可能是有效的，但其可解释性可能有限。在仅依靠LSTM模型进行股票市场决策时应格外谨慎。

    Oil companies are among the largest companies in the world whose economic indicators in the global stock market have a great impact on the world economy and market due to their relation to gold, crude oil, and the dollar. This study investigates the impact of correlated features on the interpretability of Long Short-Term Memory (LSTM) models for predicting oil company stocks. To achieve this, we designed a Standard Long Short-Term Memory (LSTM) network and trained it using various correlated datasets. Our approach aims to improve the accuracy of stock price prediction by considering the multiple factors affecting the market, such as crude oil prices, gold prices, and the US dollar. The results demonstrate that adding a feature correlated with oil stocks does not improve the interpretability of LSTM models. These findings suggest that while LSTM models may be effective in predicting stock prices, their interpretability may be limited. Caution should be exercised when relying solely on L
    
[^130]: 《使用进化、可塑性和元元学习学习获取新认知任务》（arXiv:2112.08588v10 [cs.NE] 已更新）

    Learning to acquire novel cognitive tasks with evolution, plasticity and meta-meta-learning. (arXiv:2112.08588v10 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2112.08588](http://arxiv.org/abs/2112.08588)

    本文提出了一种使用进化、可塑性和元元学习方法来学习获取新的认知任务的方法，结果验证了其有效性。

    

    智能的标志是能够自主地学习新的灵活的认知行为，也就是说，适当的行为不仅取决于直接的刺激（如简单的反射性刺激-反应关联），而且还取决于必须足够获取、存储和处理的上下文信息。虽然许多元学习算法可以设计出自主学习新任务的智能体，但是认知任务给典型的“学习如何学习”问题添加了另一个学习和记忆的层面。在这里，我们通过计算神经科学框架中的一系列简单的认知任务进化了神经网络，这些神经网络带有可塑的连接和神经调节。结果得到的进化网络可以通过其自身的连接自动修改来获取新的、从未在进化过程中出现过的简单认知任务，通过其进化的神经组织和可塑性系统的自发运作，只基于刺激和奖励。我们的结果强调了学习认知任务的重要性。

    A hallmark of intelligence is the ability to autonomously learn new flexible, cognitive behaviors - that is, behaviors where the appropriate action depends not just on immediate stimuli (as in simple reflexive stimulus-response associations), but on contextual information that must be adequately acquired, stored and processed. While many meta-learning algorithms can design agents that autonomously learn new tasks, cognitive tasks adds another level of learning and memory to typical ``learning-to-learn'' problems. Here we evolve neural networks, endowed with plastic connections and neuromodulation, over a sizable set of simple cognitive tasks adapted from a computational neuroscience framework. The resulting evolved networks can automatically modify their own connectivity to acquire a novel simple cognitive task, never seen during evolution, from stimuli and rewards alone, through the spontaneous operation of their evolved neural organization and plasticity system. Our results emphasize
    
[^131]: HeterPS：基于强化学习调度的异构环境下分布式深度学习

    HeterPS: Distributed Deep Learning With Reinforcement Learning Based Scheduling in Heterogeneous Environments. (arXiv:2111.10635v3 [cs.DC] UPDATED)

    [http://arxiv.org/abs/2111.10635](http://arxiv.org/abs/2111.10635)

    这篇论文介绍了一个名为Paddle-HeterPS的分布式框架，基于强化学习的调度方法可以高效地利用多种类型的计算资源，解决了分布式深度学习训练中多层次分配计算资源的问题。

    

    深度神经网络利用许多层和大量参数实现了优秀的性能。DNN模型的训练过程通常处理具有许多稀疏特征的大规模输入数据，这会产生高延迟和I/O成本，而某些层的计算成本很高。训练过程通常利用分布式计算资源来减少训练时间。此外，多种类型的计算资源，如CPU和GPU等，也可用于分布式训练过程。因此，多层次地分配计算资源对训练过程至关重要。为了通过异构计算资源高效地训练DNN模型，我们提出了一种分布式框架Paddle-Heterogeneous Parameter Server（Paddle-HeterPS），由分布式架构和基于强化学习的调度方法组成。与现有框架相比，Paddle-HeterPS的优点有三个。

    Deep neural networks (DNNs) exploit many layers and a large number of parameters to achieve excellent performance. The training process of DNN models generally handles large-scale input data with many sparse features, which incurs high Input/Output (IO) cost, while some layers are compute-intensive. The training process generally exploits distributed computing resources to reduce training time. In addition, heterogeneous computing resources, e.g., CPUs, GPUs of multiple types, are available for the distributed training process. Thus, the scheduling of multiple layers to diverse computing resources is critical for the training process. To efficiently train a DNN model using the heterogeneous computing resources, we propose a distributed framework, i.e., Paddle-Heterogeneous Parameter Server (Paddle-HeterPS), composed of a distributed architecture and a Reinforcement Learning (RL)-based scheduling method. The advantages of Paddle-HeterPS are three-fold compared with existing frameworks. 
    
[^132]: 生成对抗网络的指纹识别技术

    Fingerprinting Generative Adversarial Networks. (arXiv:2106.11760v3 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2106.11760](http://arxiv.org/abs/2106.11760)

    本文提出了一种保护GAN知识产权的指纹识别方案，通过生成指纹样本并嵌入到分类器中进行版权验证，解决了前一种对分类模型的指纹识别方法在简单转移至GAN时遇到的隐蔽性和鲁棒性瓶颈，具有实际保护现代GAN模型的可行性。

    

    生成对抗网络（GANs）已经广泛应用于各种应用场景。由于商业GAN的生产需要大量的计算和人力资源，因此迫切需要版权保护。本文提出了一种用于保护GAN知识产权的指纹识别方案。我们突破了前一种对分类模型的指纹识别方法在简单转移至GAN时所遇到的隐蔽性和鲁棒性瓶颈。具体来说，我们创造性地从目标GAN和分类器构建一个复合深度学习模型。然后，我们从这个复合模型中产生指纹样本，并将其嵌入到分类器中，以进行有效的版权验证。这种方案启发了一些具体的方法，以实际保护现代GAN模型。理论分析证明了这些方法可以满足知识产权保护所需要的不同安全要求。我们还进行了实验来证明该方案的功效。

    Generative Adversarial Networks (GANs) have been widely used in various application scenarios. Since the production of a commercial GAN requires substantial computational and human resources, the copyright protection of GANs is urgently needed. In this paper, we present the first fingerprinting scheme for the Intellectual Property (IP) protection of GANs. We break through the stealthiness and robustness bottlenecks suffered by previous fingerprinting methods for classification models being naively transferred to GANs. Specifically, we innovatively construct a composite deep learning model from the target GAN and a classifier. Then we generate fingerprint samples from this composite model, and embed them in the classifier for effective ownership verification. This scheme inspires some concrete methodologies to practically protect the modern GAN models. Theoretical analysis proves that these methods can satisfy different security requirements necessary for IP protection. We also conduct 
    
[^133]: 多样化高斯噪声一致性正则化用于鲁棒性和不确定性校准

    Diverse Gaussian Noise Consistency Regularization for Robustness and Uncertainty Calibration. (arXiv:2104.01231v6 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2104.01231](http://arxiv.org/abs/2104.01231)

    本研究提出了一种多样化高斯噪声一致性正则化方法，用于同时提高图像分类器的鲁棒性和准确性，与其他强大的多样化数据增强基础相比，可以将鲁棒性提高4.2-18.4％以应对未预见的噪声污染。

    

    当训练和测试数据分布一致时，深度神经网络可以实现高水平的预测精度。然而，在实际情况中，各种类型的损坏会导致表现严重下降，这与预期的情况有所偏差。目前只有少数方法可以在出现未预见到的领域偏移时提高泛化能力。特别是，在图像获取阶段，数字噪声污染经常出现。我们提出了一种多样化高斯噪声一致性正则化方法，用于改进图像分类器在各种污染情况下的鲁棒性，同时仍保持较高的准确性。通过本地损失景观分析，我们导出界限，以激励和理解我们的高斯噪声一致性正则化的行为。相比于对抗性训练和其他强大的多样化数据增强基础，我们的方法可以将鲁棒性提高4.2-18.4％以应对未预见的噪声污染。

    Deep neural networks achieve high prediction accuracy when the train and test distributions coincide. In practice though, various types of corruptions occur which deviate from this setup and cause severe performance degradations. Few methods have been proposed to address generalization in the presence of unforeseen domain shifts. In particular, digital noise corruptions arise commonly in practice during the image acquisition stage and present a significant challenge for current methods. In this paper, we propose a diverse Gaussian noise consistency regularization method for improving robustness of image classifiers under a variety of corruptions while still maintaining high clean accuracy. We derive bounds to motivate and understand the behavior of our Gaussian noise consistency regularization using a local loss landscape analysis. Our approach improves robustness against unforeseen noise corruptions by 4.2-18.4% over adversarial training and other strong diverse data augmentation base
    
[^134]: 有效通信下联邦多智能体强化学习的梯度收敛界限

    The Gradient Convergence Bound of Federated Multi-Agent Reinforcement Learning with Efficient Communication. (arXiv:2103.13026v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2103.13026](http://arxiv.org/abs/2103.13026)

    本文提出了两种优化策略, 一种是逐步衰减本地梯度权重的衰减模式, 另一种是基于代价最小化设计的共识算法来减少模型之间的通信量, 有效解决了独立学习环境异质性和联邦学习的通信开销问题。

    

    本文考虑联邦学习范式中多智能体协作决策的独立强化学习，但是由于独立学习环境异质性和联邦学习的通信开销问题，现有方法在训练过程中存在收敛问题。因此本文提出了两种优化策略，一种是逐步衰减本地梯度权重的衰减模式，另一种是基于代价最小化设计的共识算法来减少模型之间的通信量，理论分析和实验证明了这两种方法的有效性和优越性。

    The paper considers independent reinforcement learning (IRL) for multi-agent collaborative decision-making in the paradigm of federated learning (FL). However, FL generates excessive communication overheads between agents and a remote central server, especially when it involves a large number of agents or iterations. Besides, due to the heterogeneity of independent learning environments, multiple agents may undergo asynchronous Markov decision processes (MDPs), which will affect the training samples and the model's convergence performance. On top of the variation-aware periodic averaging (VPA) method and the policy-based deep reinforcement learning (DRL) algorithm (i.e., proximal policy optimization (PPO)), this paper proposes two advanced optimization schemes orienting to stochastic gradient descent (SGD): 1) A decay-based scheme gradually decays the weights of a model's local gradients with the progress of successive local updates, and 2) By representing the agents as a graph, a cons
    
[^135]: 关于异常的性质和类型：数据偏差的回顾

    On the Nature and Types of Anomalies: A Review of Deviations in Data. (arXiv:2007.15634v5 [cs.DB] UPDATED)

    [http://arxiv.org/abs/2007.15634](http://arxiv.org/abs/2007.15634)

    本文通过广泛文献综述，提供了第一个理论上基于原则且领域无关的数据异常分类法，并呈现了异常类型和子类型的全面概述。

    

    异常是指数据集中以某种方式不寻常且不符合一般模式的事件。异常的概念通常没有明确定义，并被认为是模糊的和依赖于具体领域的。此外，尽管在这个主题上已有约250年的出版物，但迄今尚未发表过关于不同类型的异常的综合和具体概述。通过广泛文献综述，本研究因此提供了第一个理论上基于原则且领域无关的数据异常分类法，并呈现了异常类型和子类型的全面概述。为了明确定义异常的概念及其不同的表现，该分类法运用了五个维度：数据类型、关系的基数、异常级别、数据结构和数据分布。这些基本且以数据为中心的维度自然地产生了3个大组、9种基本类型和63个异常子类型。该分类法有助于评估某个数据处理系统对异常的功能能力。

    Anomalies are occurrences in a dataset that are in some way unusual and do not fit the general patterns. The concept of the anomaly is typically ill-defined and perceived as vague and domain-dependent. Moreover, despite some 250 years of publications on the topic, no comprehensive and concrete overviews of the different types of anomalies have hitherto been published. By means of an extensive literature review this study therefore offers the first theoretically principled and domain-independent typology of data anomalies and presents a full overview of anomaly types and subtypes. To concretely define the concept of the anomaly and its different manifestations, the typology employs five dimensions: data type, cardinality of relationship, anomaly level, data structure, and data distribution. These fundamental and data-centric dimensions naturally yield 3 broad groups, 9 basic types, and 63 subtypes of anomalies. The typology facilitates the evaluation of the functional capabilities of an
    

