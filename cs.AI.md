# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [An Empirical Analysis of Diversity in Argument Summarization](https://rss.arxiv.org/abs/2402.01535) | 本研究通过实证分析，发现目前的论据摘要方法在捕捉多样性方面存在困难，并提出多样性有三个方面：意见、注释者和来源。所研究的关键点分析任务中的通用LLMs和专门的KPA模型都有互补的优势，训练数据的多样化将有助于提高泛化能力。因此，应对论证摘要中的多样性需要采用多种策略来处理主观性。 |
| [^2] | [Efficient Causal Graph Discovery Using Large Language Models](https://rss.arxiv.org/abs/2402.01207) | 提出了一个新的框架，利用大型语言模型进行高效的因果图发现，采用了广度优先搜索方法，只需要线性数量的查询，同时能轻松结合观察数据以提高性能，具有高效性和数据效率，并在真实因果图上取得了最先进的结果，展示了其在不同领域的广泛适用性潜力。 |
| [^3] | [Addressing Bias Through Ensemble Learning and Regularized Fine-Tuning](https://rss.arxiv.org/abs/2402.00910) | 本文提出了一种通过集成学习和正则化微调的方法，解决AI模型中的偏见问题。该方法可通过在小数据集和有偏的预训练模型上训练多个对抗偏见的模型，并使用集成学习得到无偏的预测结果。通过实验证明了该方法在CIFAR10和HAM10000数据集上的有效性。 |
| [^4] | [AQA-Bench: An Interactive Benchmark for Evaluating LLMs' Sequential Reasoning Ability](https://arxiv.org/abs/2402.09404) | AQA-Bench是一个交互式基准测试，用于评估大型语言模型在算法上下文中的顺序推理能力。研究发现闭源模型表现出更强的顺序推理能力，显著优于开源模型。 |
| [^5] | [Reinforcement Learning from Human Feedback with Active Queries](https://arxiv.org/abs/2402.09401) | 本文提出了一种基于主动查询的强化学习方法，用于解决与人类反馈的对齐问题。通过在强化学习过程中减少人工标注偏好数据的需求，该方法具有较低的代价，并在实验中表现出较好的性能。 |
| [^6] | [Get More with LESS: Synthesizing Recurrence with KV Cache Compression for Efficient LLM Inference](https://arxiv.org/abs/2402.09398) | 这项研究提出了一个称为LESS的方法，通过集成一个固定尺寸的缓存和基于驱逐的缓存方法，可以在大型语言模型中减小内存占用的问题，同时保持全部标记的可查询能力，并在多种任务上显示出良好的性能。 |
| [^7] | [LL-GABR: Energy Efficient Live Video Streaming Using Reinforcement Learning](https://arxiv.org/abs/2402.09392) | LL-GABR是一种使用深度强化学习的方法，通过使用感知视频质量而不是比特率建模QoE，并结合能量消耗和其他指标，实现了高效能耗的实时视频流传输。 |
| [^8] | [LlaSMol: Advancing Large Language Models for Chemistry with a Large-Scale, Comprehensive, High-Quality Instruction Tuning Dataset](https://arxiv.org/abs/2402.09391) | 本文介绍了LlaSMol，它是一种推进化学领域大规模语言模型的方法。通过使用一个大规模、全面、高质量的指令调优数据集来训练模型，LlaSMol在化学任务中表现出强大的性能，超过了GPT-4并接近于任务特定模型。 |
| [^9] | [HGOT: Hierarchical Graph of Thoughts for Retrieval-Augmented In-Context Learning in Factuality Evaluation](https://arxiv.org/abs/2402.09390) | HGOT是一种用于检索增强上下文学习中事实性评估的分层思维图方法，通过利用大型语言模型的规划能力和思维质量评估指标来提高相关段落的检索和答案选择。 |
| [^10] | [Entropy-regularized Point-based Value Iteration](https://arxiv.org/abs/2402.09388) | 在部分可观测问题领域，我们提出了一种熵正则化的基于模型的规划器，在规划和目标推理中通过鼓励策略不承诺一个单一的动作来提高鲁棒性和目标推理性能。 |
| [^11] | [Persuasion, Delegation, and Private Information in Algorithm-Assisted Decisions](https://arxiv.org/abs/2402.09384) | 一篇论文研究了在算法辅助决策中，如何设计最优的预测算法和委托规则。关键发现包括：委托的最优性与委托人是否会做出与代理人相同的决策有关、最具信息量的算法不一定是最优的、常见的算法限制会降低决策质量。 |
| [^12] | [Deep Rib Fracture Instance Segmentation and Classification from CT on the RibFrac Challenge](https://arxiv.org/abs/2402.09372) | 该论文介绍了基于RibFrac挑战赛的深度学习算法，可以从CT扫描中实现肋骨骨折的实例分割和分类。研究通过提供一个包含大量标注数据和评估指标的基准数据集，解决了肋骨骨折检测领域缺乏数据和评估的问题。MICCAI 2020挑战赛期间，七个团队的方法在实例分割和分类任务中表现出色。 |
| [^13] | [Transformers Can Achieve Length Generalization But Not Robustly](https://arxiv.org/abs/2402.09371) | Transformers在特定组合的数据格式和位置编码的情况下可以实现长度的泛化，但仍然存在脆弱性和大量方差。 |
| [^14] | [Pseudorandom Error-Correcting Codes](https://arxiv.org/abs/2402.09370) | 我们构建了一种伪随机纠错码，它对替换和删除错误具有鲁棒性，并且可以高效解码。我们还使用伪随机码提出了一种对语言模型输出进行水印处理的方案，该方案对裁剪和随机替换、删除具有恒定的鲁棒性。 |
| [^15] | [Magic-Me: Identity-Specific Video Customized Diffusion](https://arxiv.org/abs/2402.09368) | 本研究提出了一个名为视频定制扩散（VCD）的简单而有效的主题身份可控视频生成框架，通过指定的图像定义主题ID，并加强身份信息提取和逐帧相关性注入，实现了稳定且在很大程度上保持身份一致性的视频输出。 |
| [^16] | [HiRE: High Recall Approximate Top-$k$ Estimation for Efficient LLM Inference](https://arxiv.org/abs/2402.09360) | HiRE是一种用于高效的LLM推理的高召回率的近似Top-k估计方法，通过压缩方案减少了模型参数传输和延迟。 |
| [^17] | [Integrating ChatGPT into Secure Hospital Networks: A Case Study on Improving Radiology Report Analysis](https://arxiv.org/abs/2402.09358) | 本研究首次将类似于ChatGPT的基于云的人工智能应用于安全的医院模型中，用于分析放射学报告，通过对比学习方法实现了95%以上的准确率，同时提高了预测可靠性和可解释性，对于医生来说具有重要意义。 |
| [^18] | [Single-Reset Divide & Conquer Imitation Learning](https://arxiv.org/abs/2402.09355) | 本文介绍了一种名为单重置的分而治之模仿学习的扩展方法，该方法解决了在演示学习中需要重置特定状态的限制，使其可以应用于实际系统。 |
| [^19] | [Developing a Framework for Auditing Large Language Models Using Human-in-the-Loop](https://arxiv.org/abs/2402.09346) | 本文提出了一种使用人机协同的方法开发大型语言模型审计框架，通过使用不同版本的相同问题来探测模型可能存在的偏见或幻觉，实现了自动化和可扩展的审计方法。 |
| [^20] | [Mitigating Reward Hacking via Information-Theoretic Reward Modeling](https://arxiv.org/abs/2402.09345) | 本文提出了一种名为InfoRM的奖励建模框架，通过引入变分信息瓶颈目标和模型复杂度调节机制，解决了奖励作弊问题，并利用集成聚类偏差得分（ICDS）来检测奖励过度优化。 |
| [^21] | [Neural Networks asymptotic behaviours suitable for the resolution of inverse problems](https://arxiv.org/abs/2402.09338) | 本文研究了适用于解决反褶积逆问题的神经网络渐近行为，并发现使用从神经网络的渐近极限导出的高斯过程比全连接的神经网络获得更好的结果，而且观察到随着层数的增加，训练后的神经网络的准确性接近于高斯过程的准确性。其中一个高斯过程的解释与传统方法不同，提供了一种新的视角。 |
| [^22] | [AuditLLM: A Tool for Auditing Large Language Models Using Multiprobe Approach](https://arxiv.org/abs/2402.09334) | "AuditLLM"是一种能够以系统的方式评估各种LLMs的性能的工具，通过使用从单个问题生成的多个探测来对给定的LLM进行审计，从而识别模型在理解或操作方面的任何不一致性。 |
| [^23] | [ICDPO: Effectively Borrowing Alignment Capability of Others via In-context Direct Preference Optimization](https://arxiv.org/abs/2402.09320) | 本文提出一种名为ICDPO的方法，通过借用他人的对齐能力，并使用上下文学习来优化生成模型，以提高大型语言模型的性能。 |
| [^24] | [Leveraging Pre-Trained Autoencoders for Interpretable Prototype Learning of Music Audio](https://arxiv.org/abs/2402.09318) | 提出了一种基于预训练自编码器的可解释音乐音频原型学习模型PECMAE，并通过使用扩散解码器提升了重构效果。在音乐乐器分类和流派识别数据集上的实验结果表明，该模型能够保留更多关于音频特征的信息，提高分类性能。 |
| [^25] | [Embracing the black box: Heading towards foundation models for causal discovery from time series data](https://arxiv.org/abs/2402.09305) | 本文研究了基于时间序列数据进行因果发现的问题，提出了一种称为因果预训练的方法，通过以监督方式学习从多变量时间序列到潜在因果图的映射，实现了在共享动力学的情况下的监督式因果发现。 |
| [^26] | [Immediate generalisation in humans but a generalisation lag in deep neural networks$\unicode{x2014}$evidence for representational divergence?](https://arxiv.org/abs/2402.09303) | 研究对比了人类和深度神经网络在图像分类中的行为差异，发现人类具有即时概括能力，而DNNs存在滞后概括现象，这表明了表示分歧的存在。 |
| [^27] | [Learning Interpretable Policies in Hindsight-Observable POMDPs through Partially Supervised Reinforcement Learning](https://arxiv.org/abs/2402.09290) | 该论文提出了部分监督强化学习（PSRL）框架，通过融合监督和非监督学习来生成更可解释的策略，同时利用状态估计器提取出监督语义状态信息，以及捕捉潜在状态信息。 |
| [^28] | [Nutrition Facts, Drug Facts, and Model Facts: Putting AI Ethics into Practice in Gun Violence Research](https://arxiv.org/abs/2402.09286) | 通过提供一个模型事实模板，该研究旨在在枪支暴力研究中建立AI的信任和透明度，并减少对易受剥削人群数据的不信任。此模板使一般用户能够评估模型的有效性和偏见。 |
| [^29] | [Synergistic eigenanalysis of covariance and Hessian matrices for enhanced binary classification](https://arxiv.org/abs/2402.09281) | 本论文提出了一种新颖的方法，通过将训练集上计算的协方差矩阵的特征分析与深度学习模型上计算的Hessian矩阵相结合，实现了二分类任务中的最优类别可分性。该方法通过最大化类间平均距离和最小化类内方差，以及将数据投影到两个矩阵的最相关特征方向的组合空间来实现最优类别可分性。实证验证显示了该方法的有效性。 |
| [^30] | [Personalized Large Language Models](https://arxiv.org/abs/2402.09269) | 本文研究了个性化大型语言模型的方法，通过比较微调和零样本推理的方法，在主观任务中发现个性化微调能提高模型的推理能力，在情感识别和仇恨言论检测方面也获得了一致的性能提升。 |
| [^31] | [Self-Alignment for Factuality: Mitigating Hallucinations in LLMs via Self-Evaluation](https://arxiv.org/abs/2402.09267) | 本研究探索了自动校准实事性的方法，通过利用大型语言模型的自我评估能力，引导模型向实事性靠近，并改善模型的置信估计和校准。 |
| [^32] | [Machine Learning in management of precautionary closures caused by lipophilic biotoxins](https://arxiv.org/abs/2402.09266) | 本研究提出了一个机器学习模型，可以预测脂溶性生物毒素引起的预防性关闭，为淡水蛤养殖行业提供了支持。 |
| [^33] | [Computational Complexity of Preferred Subset Repairs on Data-Graphs](https://arxiv.org/abs/2402.09265) | 本论文研究了在图数据库上使用Reg-GXPath表达式作为完整性约束，计算包含数据值的优先修复问题，并提出了几种偏好准则。 |
| [^34] | [SyntaxShap: Syntax-aware Explainability Method for Text Generation](https://arxiv.org/abs/2402.09259) | 本文介绍了一种局部的、与模型无关的用于文本生成的可解释性方法SyntaxShap，其通过考虑文本数据中的语法来扩展Shapley值以解释序列到序列任务。通过采用博弈论方法，SyntaxShap只考虑由依赖树约束的联盟，与其他最新的可解释性方法相比具有良好的性能。 |
| [^35] | [Universal Machine Learning Kohn-Sham Hamiltonian for Materials](https://arxiv.org/abs/2402.09251) | 本研究提出了一种通用的电子哈密顿量模型，通过使用来自Materials Project的第一性原理DFT计算的哈密顿矩阵进行训练，可以预测整个周期表中包括复杂多元素系统在内的电子结构。 |
| [^36] | [Who Plays First? Optimizing the Order of Play in Stackelberg Games with Many Robots](https://arxiv.org/abs/2402.09246) | 本论文研究了在Stackelberg博弈中优化众多机器人的行动顺序的问题，并引入了一个高效准确的算法(B&P)来求解相关的优化问题和均衡。该算法具有广泛的实际应用。 |
| [^37] | [Learning Interpretable Concepts: Unifying Causal Representation Learning and Foundation Models](https://arxiv.org/abs/2402.09236) | 本研究将因果表示学习和基础模型相结合，研究了如何从数据中学习人类可解释的概念。实验证明了这一统一方法的实用性。 |
| [^38] | [Design and Realization of a Benchmarking Testbed for Evaluating Autonomous Platooning Algorithms](https://arxiv.org/abs/2402.09233) | 本文介绍了用于评估自主编队算法的测试平台。通过对三种算法的评估，我们发现分布式模型预测控制算法在硬件和仿真环境中的表现优于线性反馈算法。 |
| [^39] | [Is my Data in your AI Model? Membership Inference Test with Application to Face Images](https://arxiv.org/abs/2402.09225) | This paper introduces a novel approach called Membership Inference Test (MINT) to empirically assess if specific data was used during the training of AI models. Two MINT architectures based on MLP and CNN are proposed and evaluated on a challenging face recognition task, achieving promising results with up to 90% accuracy. |
| [^40] | [Spectral Filters, Dark Signals, and Attention Sinks](https://arxiv.org/abs/2402.09221) | 这项研究通过定义频谱滤波器和注意力陷阱，揭示了将中间表示投影到词汇表的解释工具对于transformer-based LLMs的重要性，并发现了预训练模型中特定频谱区域的损失对于保持低损失是可行的。 |
| [^41] | [DivaTrack: Diverse Bodies and Motions from Acceleration-Enhanced Three-Point Trackers](https://arxiv.org/abs/2402.09211) | DivaTrack是一个基于深度学习的框架，可以在多样化的身体尺寸和活动情况下优于现有方法，通过加入线性加速度从IMU提供更准确的脚部接触预测，并使用两阶段模型来提高对全身姿势的预测稳定性。 |
| [^42] | [Tell Me More! Towards Implicit User Intention Understanding of Language Model Driven Agents](https://arxiv.org/abs/2402.09205) | 该论文提出了一种面向基于语言模型的智能代理的隐式用户意图理解的方法。通过引入Intention-in-Interaction (IN3) 基准和在代理设计中融入模型专家，使得代理能够更好地与用户进行交互，并提升对用户指令的理解能力。 |
| [^43] | [Discovering Command and Control (C2) Channels on Tor and Public Networks Using Reinforcement Learning](https://arxiv.org/abs/2402.09200) | 本文使用强化学习方法在Tor和公共网络上自动发现具有韧性的指挥与控制（C2）通道，从而帮助识别和防止网络攻击。 |
| [^44] | [Ten Words Only Still Help: Improving Black-Box AI-Generated Text Detection via Proxy-Guided Efficient Re-Sampling](https://arxiv.org/abs/2402.09199) | 本文提出了一种利用代理引导的高效重采样方法来改进黑盒AI生成文本检测。通过估计单词生成概率作为伪白盒特征，选择少量代表性词汇进行多次重采样，在包含人类文本和LLM生成文本的数据集上进行了实验，取得了出色的结果。 |
| [^45] | [(Ir)rationality and Cognitive Biases in Large Language Models](https://arxiv.org/abs/2402.09193) | 本研究评估了七个大型语言模型在认知心理学任务中的表现，发现它们与人类一样存在非理性，但展示的非理性方式与人类偏见不同，同时还表现出了显著的回答不一致性。 |
| [^46] | [Leveraging the Context through Multi-Round Interactions for Jailbreaking Attacks](https://arxiv.org/abs/2402.09177) | 本研究提出了一种新的攻击形式——上下文交互攻击，通过交互式与大型语言模型（LLMs）进行问答来引出有害信息。实验结果表明该方法的有效性。 |
| [^47] | [Role-Playing Simulation Games using ChatGPT](https://arxiv.org/abs/2402.09161) | 本文展示了如何通过使用ChatGPT在角色扮演模拟游戏中提升教学质量，并提高学生对学习的兴趣。 |
| [^48] | [Into the Unknown: Self-Learning Large Language Models](https://arxiv.org/abs/2402.09147) | 本研究关注自学习大型语言模型的核心问题：如何学习未知知识。提出了一种自学习框架，通过自我评估和识别未知点来独立学习以前未知的知识。实验证明该方法对于减少幻觉评分、实现高效LLM更新以及知识交流具有重要意义。 |
| [^49] | [Advancing NLP Models with Strategic Text Augmentation: A Comprehensive Study of Augmentation Methods and Curriculum Strategies](https://arxiv.org/abs/2402.09141) | 本研究通过对多个数据集和NLP任务的全面评估，证明了特定的文本增强方法与改进的循环课程学习（MCCL）相结合时能够显著优于传统的训练方法，在NLP模型性能上取得了重要突破。 |
| [^50] | [DolphCoder: Echo-Locating Code Large Language Models with Diverse and Multi-Objective Instruction Tuning](https://arxiv.org/abs/2402.09136) | DolphCoder通过多样化的指导和自我评估提高了代码大型语言模型的生成能力，并在HumanEval和MBPP基准测试中取得了优异的性能。 |
| [^51] | [Exploring the Adversarial Capabilities of Large Language Models](https://arxiv.org/abs/2402.09132) | 本研究探索了大型语言模型的对抗能力，并发现其能够成功地制造对抗性示例以愚弄安全措施，特别是在仇恨言论检测方面具有重大影响。 |
| [^52] | [Optimal Automated Market Makers: Differentiable Economics and Strong Duality](https://arxiv.org/abs/2402.09129) | 本文研究了在多商品市场中，包括复杂捆绑行为的情况下，找到最优的自动做市商的问题，发现该问题对偶于一个最优运输问题，并且具有特定的几何约束条件。 |
| [^53] | [MPIrigen: MPI Code Generation through Domain-Specific Language Models](https://arxiv.org/abs/2402.09126) | 本文研究了使用领域特定语言模型生成MPI代码的性能，并提出了使用预训练模型MonoCoder进行MPI-based程序生成的方法。 |
| [^54] | [Stochastic Spiking Attention: Accelerating Attention with Stochastic Computing in Spiking Networks](https://arxiv.org/abs/2402.09109) | 本文提出了一种利用随机计算加速尖峰网络中的关注机制的新框架，证明该方法在CIFAR-10上能够达到高分类准确率，同时大大降低了计算能量和内存访问成本。 |
| [^55] | [Exploring Neuron Interactions and Emergence in LLMs: From the Multifractal Analysis Perspective](https://arxiv.org/abs/2402.09099) | 该论文通过多重分形分析视角，深入研究了LLMs中神经元相互作用和出现现象。通过引入自组织和多重分形分析的概念，研究了神经元相互作用的动态演化过程，尤其关注训练中的复杂行为。通过提出基于神经元的多重分形分析方法，实现了对大型模型中神经元相互作用的定量分析。 |
| [^56] | [A Digital Twin prototype for traffic sign recognition of a learning-enabled autonomous vehicle](https://arxiv.org/abs/2402.09097) | 本文介绍了一个用于学习使能的自动驾驶车辆的新型数字孪生原型，其主要目标是进行交通标志识别和车道保持。 |
| [^57] | [Play Guessing Game with LLM: Indirect Jailbreak Attack with Implicit Clues](https://arxiv.org/abs/2402.09091) | 通过提供隐含的线索，Puzzler通过绕过LLM的防御策略，在间接方式下实现了越狱攻击，成功率高达96.6%。 |
| [^58] | [Polynomial Semantics of Tractable Probabilistic Circuits](https://arxiv.org/abs/2402.09085) | 本文证明了对于二进制分布，可计算概率电路模型在某种意义上是等价的，即其中任何一个的电路都可以转化为任何其他模型的电路，只需多项式级别的增加大小。它们是可计算的边际推断模型。 |
| [^59] | [Sobolev Training for Operator Learning](https://arxiv.org/abs/2402.09084) | 本研究通过将导数信息融入损失函数来改善算子学习框架的性能，并提出了一种在不规则网格上近似导数的新框架，从而表明Sobolev训练在近似解算子方面的有效性。 |
| [^60] | [Exploiting Estimation Bias in Deep Double Q-Learning for Actor-Critic Methods](https://arxiv.org/abs/2402.09078) | 本文提出了两种创新方法，ExpD3 和 BE-TD3，用于解决和利用 Actor-Critic 方法中的估计偏差问题。实验证明这些算法在连续控制任务中比现有方法更高效。 |
| [^61] | [Solid Waste Detection in Remote Sensing Images: A Survey](https://arxiv.org/abs/2402.09066) | 本文调查了固体废物在遥感图像中的检测方法。研究者利用地球观测卫星提供的高分辨率数据，通过遥感图像实现了固体废物处置场地的识别、监测和评估。 |
| [^62] | [I can't see it but I can Fine-tune it: On Encrypted Fine-tuning of Transformers using Fully Homomorphic Encryption](https://arxiv.org/abs/2402.09059) | 本文介绍了一种使用全同态加密进行隐私保护微调的系统BlindTuner，它可以在图像分类任务中实现对Transformer模型的隐私保护训练，并在准确性上与非加密模型相当。 |
| [^63] | [Is Epistemic Uncertainty Faithfully Represented by Evidential Deep Learning Methods?](https://arxiv.org/abs/2402.09056) | 本论文提出了关于证据深度学习的新理论洞见, 高亮了在优化二阶损失函数和解释得出的认识不确定性度量上的困难性 |
| [^64] | [Comment-aided Video-Language Alignment via Contrastive Pre-training for Short-form Video Humor Detection](https://arxiv.org/abs/2402.09055) | 本文提出了一种新颖的通过对比预训练的方法，命名为CVLA，用于短视频幽默检测。CVLA不仅适用于各种模态信号，还能通过在一致的语义空间中对齐视频和语言组件产生适合的多模式表示。实验证明，CVLA显著优于现有最先进方法和几个竞争基准方法。 |
| [^65] | [L3GO: Language Agents with Chain-of-3D-Thoughts for Generating Unconventional Objects](https://arxiv.org/abs/2402.09052) | L3GO是一种使用3D思维链生成非常规对象的语言代理，能够对物体的物理和空间配置进行精确推理，并通过试错的方式在3D模拟环境中生成所需的对象。 |
| [^66] | [FGeo-DRL: Deductive Reasoning for Geometric Problems through Deep Reinforcement Learning](https://arxiv.org/abs/2402.09051) | 本文介绍了FGeo-DRL，一个用于自动执行几何演绎推理的神经符号系统。通过强化学习算法和机器学习模型，该系统能够自主学习解决几何问题的方法，实现了人类化的演绎推理。 |
| [^67] | [FGeo-TP: A Language Model-Enhanced Solver for Geometry Problems](https://arxiv.org/abs/2402.09047) | FGeo-TP是一种语言模型增强的几何问题求解器，利用语言模型预测定理序列来解决几何问题。 |
| [^68] | [Inference of Abstraction for a Unified Account of Reasoning and Learning](https://arxiv.org/abs/2402.09046) | 本文提出了一个以贝叶斯方法为基础的概率推断理论，用于推理和学习的统一理论。该理论通过将数据转化为符号知识，从而实现推理过程。我们对逻辑推理关系和MNIST数据集进行了讨论和实验证明。 |
| [^69] | [Enhancing Sequential Model Performance with Squared Sigmoid TanH (SST) Activation Under Data Constraints](https://arxiv.org/abs/2402.09034) | 该论文提出了一种平方Sigmoid TanH（SST）激活函数，用于增强在数据限制下的顺序模型学习能力。通过数学平方放大强激活和弱激活之间的差异，改善梯度流和信息过滤。在多个应用中评估了SST驱动的LSTM和GRU模型的性能。 |
| [^70] | [Review-Incorporated Model-Agnostic Profile Injection Attacks on Recommender Systems](https://arxiv.org/abs/2402.09023) | 这项研究综述了对推荐系统的review-合并的模型无关profile注入攻击。研究表明，使用文本评论生成高质量的虚假用户配置文件可以在黑盒设置下有效攻击不同的推荐系统。 |
| [^71] | [Towards better Human-Agent Alignment: Assessing Task Utility in LLM-Powered Applications](https://arxiv.org/abs/2402.09015) | 本研究引入了AgentEval框架，用于评估LLM驱动应用的任务效用。该框架通过自动提出一套针对特定应用的评估标准，简化了效用验证过程，并对应用的效用进行了全面量化分析。 |
| [^72] | [AgentLens: Visual Analysis for Agent Behaviors in LLM-based Autonomous Systems](https://arxiv.org/abs/2402.08995) | AgentLens是一个可视化分析系统，用于研究LLMAS自主系统中代理行为。它通过分层时间可视化展示LLMAS的演变，支持用户交互式地探索代理行为的细节和原因。 |
| [^73] | [CLIP-MUSED: CLIP-Guided Multi-Subject Visual Neural Information Semantic Decoding](https://arxiv.org/abs/2402.08994) | CLIP-MUSED是一种CLIP引导的多主题视觉神经信息语义解码方法，可以克服单主题解码模型推广到多个主题的挑战，并且通过使用Transformer-based特征提取器来有效建模全局神经表示。 |
| [^74] | [SafeDecoding: Defending against Jailbreak Attacks via Safety-Aware Decoding](https://arxiv.org/abs/2402.08983) | 本文提出了一种名为SafeDecoding的解决方案，通过安全感知解码策略来防御大型语言模型（LLMs）的越狱攻击。该策略可以生成对用户查询有益且无害的响应，有效缓解了LLMs安全性威胁。 |
| [^75] | [MEL: Efficient Multi-Task Evolutionary Learning for High-Dimensional Feature Selection](https://arxiv.org/abs/2402.08982) | MEL是一种高效的多任务进化学习方法，通过多任务学习中的信息共享来增强特征选择的能力和效率，解决了高维特征选择中的挑战。 |
| [^76] | [Learning-enabled Flexible Job-shop Scheduling for Scalable Smart Manufacturing](https://arxiv.org/abs/2402.08979) | 本研究提出了一种基于图的深度强化学习方法，名为异构图调度器（HGS），用于解决灵活作业车间调度问题。该方法利用局部关系知识进行调度，并采用图结构的决策框架，提高了规模泛化能力。 |
| [^77] | [Research and application of Transformer based anomaly detection model: A literature review](https://arxiv.org/abs/2402.08975) | 本文综述了基于Transformer的异常检测模型在自然语言处理领域的研究与应用，概述了Transformer及其变种在异常检测任务中的工作原理和应用场景，并提出了该领域的未来研究趋势。 |
| [^78] | [GrounDial: Human-norm Grounded Safe Dialog Response Generation](https://arxiv.org/abs/2402.08968) | GrounDial是一种基于人类准则的对话响应生成模型，通过将响应基于常识社交规则来确保响应的安全性，而无需进行微调。 |
| [^79] | [DUEL: Duplicate Elimination on Active Memory for Self-Supervised Class-Imbalanced Learning](https://arxiv.org/abs/2402.08963) | DUEL是一个用于解决类别不平衡问题的自监督学习框架，通过主动内存去重策略来增强数据的多样性，有效缓解了过拟合的问题。英文总结目前暂无法给出。 |
| [^80] | [HyCubE: Efficient Knowledge Hypergraph 3D Circular Convolutional Embedding](https://arxiv.org/abs/2402.08961) | 本论文提出了一种名为HyCubE的模型,它通过使用新颖的3D环形卷积神经网络和交替掩码堆叠策略来实现高效的n元知识超图嵌入，并通过自适应调整卷积核大小和均匀嵌入实体位置信息来提高模型性能和效率。 |
| [^81] | [Open-Vocabulary Segmentation with Unpaired Mask-Text Supervision](https://arxiv.org/abs/2402.08960) | 本文提出了一种通过使用无配对的掩码-文本监督方法来进行开放词汇分割的框架(Uni-OVSeg)，该方法通过独立的图像-掩码和图像-文本对提取二进制掩码并与实体关联。 |
| [^82] | [Towards Next-Level Post-Training Quantization of Hyper-Scale Transformers](https://arxiv.org/abs/2402.08958) | 本文提出了一种新颖的后训练量化算法，名为aespa，它在保持完整的注意力得分的同时，通过逐层量化来提高效率，解决了当前后训练量化方案的瓶颈问题。 |
| [^83] | [MUSTARD: Mastering Uniform Synthesis of Theorem and Proof Data](https://arxiv.org/abs/2402.08957) | 这项工作介绍了MUSTARD，一种掌握定理和证明数据统一合成的数据生成框架，通过三个阶段的合成，实现了高质量和多样化的问题和推理步骤的生成。 |
| [^84] | [Using Counterfactual Tasks to Evaluate the Generality of Analogical Reasoning in Large Language Models](https://arxiv.org/abs/2402.08955) | 本研究通过创建一组反事实问题，评估了大型语言模型中类比推理能力的广泛性。结果表明，尽管人类在所有问题上的表现良好，但GPT模型在反事实集上的表现显著下降。 |
| [^85] | [Premise Order Matters in Reasoning with Large Language Models](https://arxiv.org/abs/2402.08939) | 对大型语言模型（LLMs）进行推理任务时，论据的顺序非常重要，尤其是在演绎推理任务中，按照提示的真实证明顺序呈现论据可以显著提高模型的准确性。 |
| [^86] | [MaxMin-RLHF: Towards Equitable Alignment of Large Language Models with Diverse Human Preferences](https://arxiv.org/abs/2402.08925) | 这项工作提出了一种公平对齐大型语言模型与多样的人类偏好的方法，通过学习混合偏好分布并使用MaxMin对齐目标来更好地表示人类偏好。 |
| [^87] | [Enhancing ID and Text Fusion via Alternative Training in Session-based Recommendation](https://arxiv.org/abs/2402.08921) | 本论文研究在基于会话的推荐中增强ID和文本的融合效果。研究发现，通过简单融合的方法并不能始终超越最佳的单模态方法。进一步的调查表明，这可能是由于融合方法中存在的ID和文本模态不平衡问题。 |
| [^88] | [Graph Inference Acceleration by Learning MLPs on Graphs without Supervision](https://arxiv.org/abs/2402.08918) | 该论文提出了一个简单而有效的框架SimMLP，通过在图上无监督学习MLPs，提高了在延迟敏感的应用中的泛化能力。 |
| [^89] | [Tackling Negative Transfer on Graphs](https://arxiv.org/abs/2402.08907) | 图迁移学习中的负迁移现象尚未得到充分研究，本文发现在图结构数据中负迁移普遍存在，即使源图和目标图在语义上相似。我们提出了一个新的观点，对于语义相似的图，结构差异对子图嵌入的影响较小。 |
| [^90] | [DUDF: Differentiable Unsigned Distance Fields with Hyperbolic Scaling](https://arxiv.org/abs/2402.08876) | DUDF提出了一种学习无符号距离场的双曲缩放方法，通过与隐式神经表示网络集成，解决了开放表面表示的挑战，并在重建质量和训练性能方面取得显著改进。 |
| [^91] | [ScamSpot: Fighting Financial Fraud in Instagram Comments](https://arxiv.org/abs/2402.08869) | ScamSpot是一个在Instagram评论中打击金融欺诈的综合系统，包括浏览器扩展、BERT模型和REST API。通过数据注释研究和用户反馈，该系统解决了现有模型在实际应用中的不足，并公开提供给广大用户使用。 |
| [^92] | [Large Language Model with Graph Convolution for Recommendation](https://arxiv.org/abs/2402.08859) | 本论文提出了一种基于图卷积的大规模语言模型用于推荐系统，该方法充分利用了用户-物品图中的高阶关系，以提高描述的准确性和一致性。 |
| [^93] | [GhostWriter: Augmenting Collaborative Human-AI Writing Experiences Through Personalization and Agency](https://arxiv.org/abs/2402.08855) | GhostWriter是一个AI增强的写作设计探针，通过个性化和代理增强用户的写作体验。它利用大型语言模型（LLMs）隐式学习用户的写作风格，并允许用户通过手动样式编辑和批注来控制系统的写作风格。 |
| [^94] | [Hybrid Inverse Reinforcement Learning](https://arxiv.org/abs/2402.08848) | 本文提出使用混合强化学习的方法来减少逆强化学习中的不必要探索，通过在在线数据和专家数据的混合上进行训练，从而提高学习效率。 |
| [^95] | [An Embarrassingly Simple Approach for LLM with Strong ASR Capacity](https://arxiv.org/abs/2402.08846) | 本文提出了一种简单组合的LLM方法，由语音编码器、LLM和线性投影器组成，能够胜任ASR任务，并且具有清晰的设置和少量的任务特定设计。 |
| [^96] | [Intelligent Agricultural Management Considering N$_2$O Emission and Climate Variability with Uncertainties](https://arxiv.org/abs/2402.08832) | 本研究利用人工智能和机器学习技术，特别是强化学习和递归神经网络，以及概率性建模方法，开发了一种智能农业管理系统，可以提高作物产量，优化肥料和水的使用，同时减少氮肥流失和温室气体排放，特别关注氧化亚氮（N2O）排放。 |
| [^97] | [eCeLLM: Generalizing Large Language Models for E-commerce from Large-scale, High-quality Instruction Data](https://arxiv.org/abs/2402.08831) | 本文利用开源的大规模高质量指导数据集ECInstruct，通过指导调优通用语言模型，开发了一系列电子商务LLMs（eCeLLM），在电子商务中表现出了显著的优势。 |
| [^98] | [Intelligent Canvas: Enabling Design-Like Exploratory Visual Data Analysis through Rapid Prototyping, Iteration and Curation](https://arxiv.org/abs/2402.08812) | 该论文提出了一种"类似设计"的智能画布环境，通过将生成式AI组件集成到数据分析中，实现了快速原型设计、迭代和比较可视化管理。通过用户研究，论文验证了画布界面的有效性。 |
| [^99] | [Combining Insights From Multiple Large Language Models Improves Diagnostic Accuracy](https://arxiv.org/abs/2402.08806) | 本研究发现，综合多个不同的大型语言模型的响应可以提高鉴别诊断的准确性。 |
| [^100] | [ChatGPT vs LLaMA: Impact, Reliability, and Challenges in Stack Overflow Discussions](https://arxiv.org/abs/2402.08801) | 这篇论文通过对Stack Overflow问题的分析，研究了ChatGPT和LLaMA对于该平台的影响和可靠性，以及它们在长期内取代Stack Overflow的挑战。研究结果表明，LLMs在某些方面失败，并提供了对比LLMs的实证比较。 |
| [^101] | [Leveraging cough sounds to optimize chest x-ray usage in low-resource settings](https://arxiv.org/abs/2402.08789) | 通过分析咳嗽声音，我们开发了三种模型，可以在胸部X射线中预测异常结果，从而优化资源使用并提高医疗效率。 |
| [^102] | [Enhanced Deep Q-Learning for 2D Self-Driving Cars: Implementation and Evaluation on a Custom Track Environment](https://arxiv.org/abs/2402.08780) | 本研究实现了在自定义二维赛道上进行深度Q学习的自动驾驶车辆，并通过优化算法提高了DQN网络的性能。 |
| [^103] | [DNABERT-S: Learning Species-Aware DNA Embedding with Genome Foundation Models](https://arxiv.org/abs/2402.08777) | DNABERT-S是一种专门用于创建物种感知的DNA嵌入的基因组基础模型。为了提高对长读DNA序列的嵌入效果，引入了Manifold Instance Mixup (MI-Mix)对比目标方法来训练模型。 |
| [^104] | [Optimal Task Assignment and Path Planning using Conflict-Based Search with Precedence and Temporal Constraints](https://arxiv.org/abs/2402.08772) | 本文研究了任务分配和路径规划问题，并提出了一种使用基于冲突的搜索方法解决具有先决和时间约束的任务分配和路径规划问题，最大化用户定义的指标的回报。 |
| [^105] | [JAMDEC: Unsupervised Authorship Obfuscation using Constrained Decoding over Small Language Models](https://arxiv.org/abs/2402.08761) | 提出了一种无监督的作者身份混淆方法，通过使用小型语言模型实现，可以在保持原始内容和流畅性的同时混淆作者身份。 |
| [^106] | [LLM-driven Imitation of Subrational Behavior : Illusion or Reality?](https://arxiv.org/abs/2402.08755) | 本文探讨了使用LLMs生成合成人类演示的方法，然后通过模仿学习来学习亚理性代理策略，从而模拟亚理性行为，并为我们理解人类行为提供了改进的可能性。 |
| [^107] | [PRDP: Proximal Reward Difference Prediction for Large-Scale Reward Finetuning of Diffusion Models](https://arxiv.org/abs/2402.08714) | 本研究提出了PRDP方法，通过近端奖励差异预测实现了稳定的黑盒奖励微调扩散模型，能够在大规模提示数据集上进行训练，并且具有更好的训练稳定性。 |
| [^108] | [A Survey of Generative AI for De Novo Drug Design: New Frontiers in Molecule and Protein Generation](https://arxiv.org/abs/2402.08703) | 这项综述提出了一个广义方法来驱动AI药物设计，重点关注小分子和蛋白质生成两个主要主题，介绍了各种子任务和应用，并比较了顶级模型的性能。 |
| [^109] | [PRompt Optimization in Multi-Step Tasks (PROMST): Integrating Human Feedback and Preference Alignment](https://arxiv.org/abs/2402.08702) | 该论文介绍了一种在多步任务中集成人类反馈和偏好对齐的PRompt优化方法。它使用遗传算法框架，结合人类反馈自动提出优化建议并解决了复杂的提示内容分析、单步评估和任务执行偏好的挑战。 |
| [^110] | [If Turing played piano with an artificial partner](https://arxiv.org/abs/2402.08690) | 本研究调查了通过训练生成模型来生成音乐乐谱是否可以实现令人信服的社交体验，而无需优化其同步和延续能力。 |
| [^111] | [Analyzing Prompt Influence on Automated Method Generation: An Empirical Study with Copilot](https://arxiv.org/abs/2402.08430) | 本文通过系统调查八个提示特征对生成的代码的影响，包括样式、内容、正确性、复杂性、大小和与开发者代码的相似性。 |
| [^112] | [ChatCell: Facilitating Single-Cell Analysis with Natural Language](https://arxiv.org/abs/2402.08303) | ChatCell是一个利用自然语言促进单细胞分析的工具，通过词汇适应和统一序列生成，它具备深厚的专业知识和适应各种分析任务的能力。 |
| [^113] | [Investigating Out-of-Distribution Generalization of GNNs: An Architecture Perspective](https://arxiv.org/abs/2402.08228) | 这项研究从架构的角度全面调查了图的超分布推广，揭示了图自我注意机制和其他常见构建模块在超分布问题上的影响。 |
| [^114] | [Artificial intelligence and the transformation of higher education institutions](https://arxiv.org/abs/2402.08143) | 本研究采用复杂系统方法，以因果循环图的形式探讨了人工智能在典型高等教育机构中的转型。研究发现，高等教育机构受到人工智能技术进步的推动，投资于改善学生学习、研究和管理，并为此应对学术诚信问题和技术变化。 |
| [^115] | [Generalising Planning Environment Redesign](https://arxiv.org/abs/2402.07799) | 本论文提出了一种广义化的规划环境重新设计方法，该方法能够不受度量影响，并能够适应不同的目标和指标。 |
| [^116] | [Towards Unified Alignment Between Agents, Humans, and Environment](https://arxiv.org/abs/2402.07744) | 本文介绍了统一对齐原则 ($\mathbf{UA}^2$)，旨在实现智能体与人类意图、环境动态和自我约束的统一对齐，提出了引入实际特性进行概念验证研究的方法。 |
| [^117] | [Online Sequential Decision-Making with Unknown Delays](https://arxiv.org/abs/2402.07703) | 本文提出了在在线顺序决策中处理未知延迟问题的三个延迟算法族，并提供了相应的遗憾界限。 |
| [^118] | [Food Recommendation as Language Processing (F-RLP): A Personalized and Contextual Paradigm](https://arxiv.org/abs/2402.07477) | 食物推荐作为语言处理（F-RLP）是一个针对食物的个性化、情境化的框架，利用大型语言模型的能力来实现更准确、个性化的食物推荐。 |
| [^119] | [Premier-TACO: Pretraining Multitask Representation via Temporal Action-Driven Contrastive Loss](https://arxiv.org/abs/2402.06187) | Premier-TACO是一种多任务特征表示学习方法，通过预训练通用特征表示，并引入负例抽样策略来提高时序行动对比学习的计算效率，从而显著增强了对新颖动作的少样本模仿学习的效果。 |
| [^120] | [OpenToM: A Comprehensive Benchmark for Evaluating Theory-of-Mind Reasoning Capabilities of Large Language Models](https://arxiv.org/abs/2402.06044) | OpenToM是一个评估大型语言模型心理理解能力的全面基准，通过提供更长、更清晰的叙事故事、具有明确个性特征的角色、以及挑战模型对心理状态的理解能力的问题，揭示了现有模型在理解物理世界与心理世界的角色心理状态方面的优势和不足。 |
| [^121] | [Enhancing Textbook Question Answering Task with Large Language Models and Retrieval Augmented Generation](https://arxiv.org/abs/2402.05128) | 本论文通过引入检索增强生成（RAG）技术和利用迁移学习来处理长文本和提升推理能力，为教科书问答任务带来了显著的改进。 |
| [^122] | [How VADER is your AI? Towards a definition of artificial intelligence systems appropriate for regulation](https://arxiv.org/abs/2402.05048) | 本研究提出了一个评分框架，用于衡量人工智能（AI）定义在监管方面的合适性。研究旨在排除通过AI监管提案所采用的不恰当的AI定义对ICT技术、方法和非AI作品的影响，并回归到以前在其他成功技术监管中观察到的原则。 |
| [^123] | [PaDeLLM-NER: Parallel Decoding in Large Language Models for Named Entity Recognition](https://arxiv.org/abs/2402.04838) | 本研究提出了PaDeLLM-NER，一种能够在大型语言模型中实现并行解码，从而显著减少命名实体识别的生成延迟，同时保持预测质量和性能。 |
| [^124] | [MolTC: Towards Molecular Relational Modeling In Language Models](https://arxiv.org/abs/2402.03781) | 本研究提出了一种基于语言模型的多模态框架MolTC，用于分子相互作用预测，该框架能够高效地整合分子对的丰富图形信息，并通过思维链理论实现统一的分子关系学习。 |
| [^125] | [Attitudes Towards and Knowledge of Non-Consensual Synthetic Intimate Imagery in 10 Countries](https://arxiv.org/abs/2402.01721) | 本文研究了10个国家超过16,000名受访者对非自愿合成亲密图像的态度和行为；尽管社会对此仍认识不足，但这种行为被认为有害；约有2.2%的受访者表示曾受害，1.8%的受访者表示曾参与过此类行为；单靠立法行动并不足以解决问题，建议技术和平台政策的改进来减少伤害。 |
| [^126] | [Embedding Ontologies via Incoprorating Extensional and Intensional Knowledge](https://arxiv.org/abs/2402.01677) | 本文提出了一种新型本体嵌入方法EIKE，通过整合外延知识和内涵知识，在外延空间和内涵空间中表示本体，并采用基于几何的方法和预训练的语言模型对实例、概念和关系进行嵌入建模。 |
| [^127] | [Large Language Models are Null-Shot Learners](https://arxiv.org/abs/2401.08273) | 本文提出了零射击提示方法，通过利用大规模语言模型中的错误信息来指导模型进行任务，以提高任务表现。实验结果表明，在不同数据集上，包括阅读理解、算术推理和闭卷问答，模型性能有所提升。这些结果也显示出不同模型之间存在不同程度的错误信息。 |
| [^128] | [A Study of Fairness Concerns in AI-based Mobile App Reviews](https://arxiv.org/abs/2401.08097) | 本文研究了AI基于移动应用评价中的公平关注，并通过构建数据集和开发分类器的方法，成功检测出公平性评论，并识别出约92000条公平性评论。 |
| [^129] | [An Evaluation of GPT-4V and Gemini in Online VQA](https://arxiv.org/abs/2312.10637) | 该论文将在一个真实的在线问答社区的数据集上评估两个最先进的大型多模型模型（GPT-4V和Gemini），分析了它们的能力和限制，研究了不同类型的问题对模型的挑战性，并提供了零样本性能分析。 |
| [^130] | [Automated Process Planning Based on a Semantic Capability Model and SMT](https://arxiv.org/abs/2312.08801) | 该论文介绍了一种基于语义能力模型和SMT的自动化工艺规划方法。该方法旨在解决制造系统和自主机器人中的能力规范解释以及自动化工艺规划的问题。 |
| [^131] | [diff History for Neural Language Agents](https://arxiv.org/abs/2312.07540) | 本文介绍了一种名为diff历史的简单且高效的解决方案，用于将环境中的观测转换为文本提示，以便对于长期推理决策的任务中的Neural Language Models进行优化。 |
| [^132] | [Bad Students Make Great Teachers: Active Learning Accelerates Large-Scale Visual Understanding](https://arxiv.org/abs/2312.05328) | 研究提出了一种满足泛化性、扩展性和计算资源优化的主动学习方法，利用廉价的代理模型估计数据点的可学习性分数，优先选择训练更大的模型所需的数据，从而在大规模视觉理解任务中取得相同性能的同时减少了计算量。 |
| [^133] | [Algorithmic Persuasion Through Simulation](https://arxiv.org/abs/2311.18138) | 通过模拟接收者行为的贝叶斯劝导问题中，发送者设计了一个最优消息策略并设计了一个多项式时间查询算法，以优化其预期效用。 |
| [^134] | [CLOMO: Counterfactual Logical Modification with Large Language Models](https://arxiv.org/abs/2311.17438) | 本研究探索了大型语言模型的反事实推理能力，并引入了反事实逻辑修改任务和相应的评估指标。实验结果表明，大型语言模型展现出显著的逻辑能力。 |
| [^135] | [(Ir)rationality in AI: State of the Art, Research Challenges and Open Questions](https://arxiv.org/abs/2311.17165) | 这篇论文调查了人工智能中理性与非理性的概念，提出了未解问题。重点讨论了行为在某些情况下的非理性行为可能是最优的情况。已经提出了一些方法来处理非理性代理，但仍存在挑战和问题。 |
| [^136] | [Online Advertisements with LLMs: Opportunities and Challenges](https://arxiv.org/abs/2311.07601) | 本文探讨了在线广告系统中利用大型语言模型（LLM）的潜力，提出了一个LLM广告的通用框架，并讨论了基于LLM的动态创意优化的前景。 |
| [^137] | [In-context Vectors: Making In Context Learning More Effective and Controllable Through Latent Space Steering](https://arxiv.org/abs/2311.06668) | 通过潜空间操控，使用上下文向量作为替代方法来进行上下文学习，以使语言模型更有效地遵循示例演示，并通过调整向量的量级来轻松控制学习过程。 |
| [^138] | [Contrastive Deep Nonnegative Matrix Factorization for Community Detection](https://arxiv.org/abs/2311.02357) | 对比深度非负矩阵分解算法（CDNMF）通过加深NMF的信息提取能力，采用对比学习的思想构建了网络拓扑和节点属性作为对比视图，并利用去偏方法来优化社区探测的全局结构信息的学习。 |
| [^139] | [LINC: A Neurosymbolic Approach for Logical Reasoning by Combining Language Models with First-Order Logic Provers](https://arxiv.org/abs/2310.15164) | LINC是一种通过将大型语言模型作为语义解析器，将自然语言转化为一阶逻辑表达式，再通过外部定理证明器进行推理的神经符号方法，可以显著提高逻辑推理的性能。 |
| [^140] | [LongForm: Effective Instruction Tuning with Reverse Instructions](https://arxiv.org/abs/2304.08460) | 使用反向指令进行有效的指令调优，通过生成一组自然的、适用于长文本生成的指令调优数据集，我们的模型在故事/菜谱生成和长篇问答等任务上优于10倍规模更大的语言模型，而无需指令调优。 |
| [^141] | [Causal Deep Learning](https://arxiv.org/abs/2303.02186) | 因果深度学习是一种新的关于因果性的思考方式，它综合了可测试的因果知识、参数形式和时间维度，能够帮助我们解决实际问题。 |
| [^142] | [Optimal Decision Tree Policies for Markov Decision Processes](https://arxiv.org/abs/2301.13185) | 本研究研究了有限大小决策树在Markov决策过程（MDPs）中的优化，并提出了OMDTs：最优MDP决策树。通过混合整数线性规划直接最大化决策树的期望折扣回报。研究发现现有模仿学习技术的最优性差距，并发现它们表现为次优。 |
| [^143] | [Test-Time Mixup Augmentation for Data and Class-Specific Uncertainty Estimation in Deep Learning Image Classification](https://arxiv.org/abs/2212.00214) | 本文提出了一种使用测试时间混合增强来估计深度学习图像分类中的不确定性的方法，并引入了数据不确定性和类别特定不确定性来提高准确性和提供更深入的信息。 |
| [^144] | [Deep Reinforcement Learning Guided Improvement Heuristic for Job Shop Scheduling](https://arxiv.org/abs/2211.10936) | 本文提出了一种基于深度强化学习的指导下的作业车间调度改进启发式方法，采用图表示法来编码完整的解决方案，并设计了基于图神经网络的表示方案和新颖的消息传递机制，以提高性能和加快解决方案评估。 |
| [^145] | [FedMT: Federated Learning with Mixed-type Labels](https://arxiv.org/abs/2210.02042) | 本文提出了一种概念新颖的联邦学习设置，即具有混合类型标签的联邦学习，在其中不同的中心可以使用不同的标签准则。为了有效地训练具有混合类型标签的模型，作者提出了一种理论指导和模型无关的方法。 |
| [^146] | [Detecting and recognizing characters in Greek papyri with YOLOv8, DeiT and SimCLR.](http://arxiv.org/abs/2401.12513) | 该论文使用YOLOv8、DeiT和SimCLR在希腊纸草中进行字符检测和识别竞赛，在识别挑战中获得了42.2%的mAP，并在检测挑战中以51.4%的平均精度获得了亚军。 |
| [^147] | [In-context Learning with Retrieved Demonstrations for Language Models: A Survey.](http://arxiv.org/abs/2401.11624) | 本综述调查了一种名为检索示范的方法，它通过使用特定于输入查询的示范来提高语言模型的少量样本情境学习（ICL）能力。这种方法不仅提高了学习效率和可扩展性，还减少了手动示例选择中的偏见。 |
| [^148] | [Chain of History: Learning and Forecasting with LLMs for Temporal Knowledge Graph Completion.](http://arxiv.org/abs/2401.06072) | 本文提出了一种基于LLMs的新方法，将时间知识图补全任务概念化为历史事件链中的事件生成任务。通过引入高效的微调方法和结构化历史数据增强，以及整合反向知识，我们的模型在多个指标上优于现有的方法，取得了SOTA结果。 |
| [^149] | [Bringing Back the Context: Camera Trap Species Identification as Link Prediction on Multimodal Knowledge Graphs.](http://arxiv.org/abs/2401.00608) | 本研究利用相机陷阱图像的结构化上下文，提高其在物种识别任务中的泛化能力，并解决了数据稀缺和泛化能力增强的问题。 |
| [^150] | [Beyond Still Images: Robust Multi-Stream Spatiotemporal Networks.](http://arxiv.org/abs/2311.00800) | 本论文通过引入包括时间特征的多流模型，提出了一个经过视频训练的鲁棒性模型，通过在训练中包括视频和时间流，减少了图像和视频理解任务的准确性下降率。 |
| [^151] | [SoK: Pitfalls in Evaluating Black-Box Attacks.](http://arxiv.org/abs/2310.17534) | 提出了一个评估黑盒攻击的分类法，揭示了未开发的威胁空间，并展示了在某些设置上已有技术的局限性。 |
| [^152] | [Intriguing properties of generative classifiers.](http://arxiv.org/abs/2309.16779) | 生成分类器展示了记录破纪录的人类形状偏好、接近人类级别的超出分布准确性、与人类分类错误的最先进对齐以及理解某些知觉幻象的新兴特性，揭示了零样本生成模型出奇地接近人类物体识别数据。 |
| [^153] | [Transfer Learning for Bayesian Optimization on Heterogeneous Search Spaces.](http://arxiv.org/abs/2309.16597) | 本文提出了MPHD方法，通过模型预训练和神经网络在异质搜索空间上实现贝叶斯优化的迁移学习。实验证明了MPHD的有效性和在黑盒函数优化任务中的优越性能。 |
| [^154] | [Memory-Efficient Continual Learning Object Segmentation for Long Video.](http://arxiv.org/abs/2309.15274) | 提出了两种新技术，以减少在线VOS方法的内存需求，并在提高建模准确性和泛化能力的同时进行目标分割。 |
| [^155] | [Multiple Different Explanations for Image Classifiers.](http://arxiv.org/abs/2309.14309) | 这篇论文介绍了一种算法和工具，可以为图像分类器的输出计算多个解释，从而提高对分类器行为的洞察力。 |
| [^156] | [Training Data Protection with Compositional Diffusion Models.](http://arxiv.org/abs/2308.01937) | 使用分区扩散模型（CDM）训练不同的扩散模型，并在推断时任意组合它们，实现了训练数据保护和选择性遗忘，同时还可以根据用户访问权限提供定制模型。 |
| [^157] | [Implicitly Normalized Explicitly Regularized Density Estimation.](http://arxiv.org/abs/2307.13763) | 我们提出了一种新的非参数密度估计方法，基于正则化密度的 Sobolev 范数，通过适当的初始化和使用自然梯度，可以得到性能良好的解，该方法在 Anomaly Detection benchmark 中排名第二。 |
| [^158] | [Now It Sounds Like You: Learning Personalized Vocabulary On Device.](http://arxiv.org/abs/2305.03584) | 这项研究提出了一种称为“生词扩展”的技术，通过个性化的“生词适配器”来学习个性化词汇，提高了生词覆盖率并显著提高了模型准确度。 |
| [^159] | [Causal Explanations for Stochastic Sequential Multi-Agent Decision-Making.](http://arxiv.org/abs/2302.10809) | CEMA是一个用于多智能体决策因果解释的系统，使用采样反事实世界的方法可以识别和排名决策背后的显著原因。该系统还可以生成基于所选原因的对比解释，并与用户进行交互循环以确保解释的相关性和可读性。 |

# 详细

[^1]: 论论文摘要中的多样性的实证分析

    An Empirical Analysis of Diversity in Argument Summarization

    [https://rss.arxiv.org/abs/2402.01535](https://rss.arxiv.org/abs/2402.01535)

    本研究通过实证分析，发现目前的论据摘要方法在捕捉多样性方面存在困难，并提出多样性有三个方面：意见、注释者和来源。所研究的关键点分析任务中的通用LLMs和专门的KPA模型都有互补的优势，训练数据的多样化将有助于提高泛化能力。因此，应对论证摘要中的多样性需要采用多种策略来处理主观性。

    

    在在线社会讨论中，提供高水平的论据是促进参与的关键任务。目前的论据摘要方法缺失了这项任务的一个重要方面，即捕捉多样性，这对于包容多个观点是重要的。我们引入了三个方面的多样性：意见、注释者和来源。我们评估了一种名为关键点分析的流行论据摘要任务的方法，显示这些方法在(1)代表少数人共享的论点上，(2)处理来自各种来源的数据以及(3)与人工提供的主观注释相一致方面遇到了困难。我们发现，通用的LLM和专门的KPA模型都表现出了这种行为，但具有互补的优势。此外，我们观察到训练数据的多样化可能改善泛化能力。应对论证摘要中的多样性需要采用一系列策略来处理主观性。

    Presenting high-level arguments is a crucial task for fostering participation in online societal discussions. Current argument summarization approaches miss an important facet of this task -- capturing diversity -- which is important for accommodating multiple perspectives. We introduce three aspects of diversity: those of opinions, annotators, and sources. We evaluate approaches to a popular argument summarization task called Key Point Analysis, which shows how these approaches struggle to (1) represent arguments shared by few people, (2) deal with data from various sources, and (3) align with subjectivity in human-provided annotations. We find that both general-purpose LLMs and dedicated KPA models exhibit this behavior, but have complementary strengths. Further, we observe that diversification of training data may ameliorate generalization. Addressing diversity in argument summarization requires a mix of strategies to deal with subjectivity.
    
[^2]: 使用大型语言模型的高效因果图发现

    Efficient Causal Graph Discovery Using Large Language Models

    [https://rss.arxiv.org/abs/2402.01207](https://rss.arxiv.org/abs/2402.01207)

    提出了一个新的框架，利用大型语言模型进行高效的因果图发现，采用了广度优先搜索方法，只需要线性数量的查询，同时能轻松结合观察数据以提高性能，具有高效性和数据效率，并在真实因果图上取得了最先进的结果，展示了其在不同领域的广泛适用性潜力。

    

    我们提出了一个新的框架，利用LLMs进行完整的因果图发现。之前基于LLM的方法采用了成对查询的方法，但这需要二次查询的数量，对于较大的因果图来说很快变得不可行。相反，提出的框架采用了广度优先搜索（BFS）的方法，只需要线性数量的查询。我们还展示了当有所观察数据可用时，提出的方法可以轻松地进行结合以提高性能。除了更具时间和数据效率外，提出的框架在不同大小的真实因果图上取得了最先进的结果。结果证明了提出方法在发现因果关系方面的有效性和效率，展示了其在不同领域的因果图发现任务中的广泛适用性潜力。

    We propose a novel framework that leverages LLMs for full causal graph discovery. While previous LLM-based methods have used a pairwise query approach, this requires a quadratic number of queries which quickly becomes impractical for larger causal graphs. In contrast, the proposed framework uses a breadth-first search (BFS) approach which allows it to use only a linear number of queries. We also show that the proposed method can easily incorporate observational data when available, to improve performance. In addition to being more time and data-efficient, the proposed framework achieves state-of-the-art results on real-world causal graphs of varying sizes. The results demonstrate the effectiveness and efficiency of the proposed method in discovering causal relationships, showcasing its potential for broad applicability in causal graph discovery tasks across different domains.
    
[^3]: 通过集成学习和正则化微调应对偏见

    Addressing Bias Through Ensemble Learning and Regularized Fine-Tuning

    [https://rss.arxiv.org/abs/2402.00910](https://rss.arxiv.org/abs/2402.00910)

    本文提出了一种通过集成学习和正则化微调的方法，解决AI模型中的偏见问题。该方法可通过在小数据集和有偏的预训练模型上训练多个对抗偏见的模型，并使用集成学习得到无偏的预测结果。通过实验证明了该方法在CIFAR10和HAM10000数据集上的有效性。

    

    解决AI模型中的偏见对于确保公平和准确的预测至关重要。然而，获取大规模、无偏的训练数据集可能具有挑战性。本文提出了一种全面的方法，使用多种方法消除AI模型中的偏见，其中仅使用小型数据集和潜在有偏的预训练模型。我们通过数据分离、局部训练和正则化微调训练多个模型，以对抗预训练模型的偏见，得到潜在的对抗偏见模型。然后，我们采用集成学习来对所有模型进行预测，以达到无偏的预测结果。为了进一步加速我们的集成模型的推理时间，我们使用知识蒸馏来获得一个单一无偏的神经网络。通过在CIFAR10和HAM10000数据集上的实验证明了我们方法的有效性，展示了有希望的结果。这项工作为创建更无偏、可靠的AI模型的持续努力做出了贡献。

    Addressing biases in AI models is crucial for ensuring fair and accurate predictions. However, obtaining large, unbiased datasets for training can be challenging. This paper proposes a comprehensive approach using multiple methods to remove bias in AI models, with only a small dataset and a potentially biased pretrained model. We train multiple models with the counter-bias of the pre-trained model through data splitting, local training, and regularized fine-tuning, gaining potentially counter-biased models. Then, we employ ensemble learning for all models to reach unbiased predictions. To further accelerate the inference time of our ensemble model, we conclude our solution with knowledge distillation that results in a single unbiased neural network. We demonstrate the effectiveness of our approach through experiments on the CIFAR10 and HAM10000 datasets, showcasing promising results. This work contributes to the ongoing effort to create more unbiased and reliable AI models, even with l
    
[^4]: AQA-Bench：评估LLM顺序推理能力的交互式基准测试

    AQA-Bench: An Interactive Benchmark for Evaluating LLMs' Sequential Reasoning Ability

    [https://arxiv.org/abs/2402.09404](https://arxiv.org/abs/2402.09404)

    AQA-Bench是一个交互式基准测试，用于评估大型语言模型在算法上下文中的顺序推理能力。研究发现闭源模型表现出更强的顺序推理能力，显著优于开源模型。

    

    该论文介绍了一种新的基准测试AQA-Bench，用于评估大型语言模型（LLMs）在算法上下文中，如深度优先搜索（DFS）等的顺序推理能力。我们评估基准测试的关键特点在于其交互式评估协议-例如，在DFS中，每个节点的可用连接边取决于模型对该节点的遍历，因此需要LLM有效地记住已访问节点并策划后续移动的能力。我们使用三种不同的算法构建了AQA-Bench，分别是二分搜索，深度优先搜索和广度优先搜索，并评估了12种不同的LLMs的顺序推理能力。我们的调查揭示了一些有趣的发现：（1）类似GPT-4和Gemini等闭源模型通常显示出强大的顺序推理能力，明显优于开源LLMs。（2）天真地提供互操作性

    arXiv:2402.09404v1 Announce Type: cross Abstract: This paper introduces AQA-Bench, a novel benchmark to assess the sequential reasoning capabilities of large language models (LLMs) in algorithmic contexts, such as depth-first search (DFS). The key feature of our evaluation benchmark lies in its interactive evaluation protocol -- for example, in DFS, the availability of each node's connected edge is contingent upon the model's traversal to that node, thereby necessitating the LLM's ability to effectively remember visited nodes and strategize subsequent moves. We comprehensively build AQA-Bench with three different algorithms, namely binary search, depth-first search, and breadth-first search, and to evaluate the sequential reasoning ability of 12 different LLMs. Our investigations reveal several interesting findings: (1) Closed-source models like GPT-4 and Gemini generally show strong sequential reasoning ability, significantly outperforming open-source LLMs. (2) Naively providing inter
    
[^5]: 使用主动查询的人类反馈强化学习

    Reinforcement Learning from Human Feedback with Active Queries

    [https://arxiv.org/abs/2402.09401](https://arxiv.org/abs/2402.09401)

    本文提出了一种基于主动查询的强化学习方法，用于解决与人类反馈的对齐问题。通过在强化学习过程中减少人工标注偏好数据的需求，该方法具有较低的代价，并在实验中表现出较好的性能。

    

    将大型语言模型（LLM）与人类偏好进行对齐，在构建现代生成模型中发挥重要作用，这可以通过从人类反馈中进行强化学习来实现。然而，尽管当前的强化学习方法表现出优越性能，但往往需要大量的人工标注偏好数据，而这种数据收集费时费力。本文受到主动学习的成功启发，通过提出查询效率高的强化学习方法来解决这个问题。我们首先将对齐问题形式化为上下文竞争二臂强盗问题，并设计了基于主动查询的近端策略优化（APPO）算法，具有$\tilde{O}(d^2/\Delta)$的遗憾界和$\tilde{O}(d^2/\Delta^2)$的查询复杂度，其中$d$是特征空间的维度，$\Delta$是所有上下文中的次优差距。然后，我们提出了ADPO，这是我们算法的实际版本，基于直接偏好优化（DPO）并将其应用于...

    arXiv:2402.09401v1 Announce Type: cross Abstract: Aligning large language models (LLM) with human preference plays a key role in building modern generative models and can be achieved by reinforcement learning from human feedback (RLHF). Despite their superior performance, current RLHF approaches often require a large amount of human-labelled preference data, which is expensive to collect. In this paper, inspired by the success of active learning, we address this problem by proposing query-efficient RLHF methods. We first formalize the alignment problem as a contextual dueling bandit problem and design an active-query-based proximal policy optimization (APPO) algorithm with an $\tilde{O}(d^2/\Delta)$ regret bound and an $\tilde{O}(d^2/\Delta^2)$ query complexity, where $d$ is the dimension of feature space and $\Delta$ is the sub-optimality gap over all the contexts. We then propose ADPO, a practical version of our algorithm based on direct preference optimization (DPO) and apply it to 
    
[^6]: 使用KV缓存压缩合成循环以提高LLM推断的效率

    Get More with LESS: Synthesizing Recurrence with KV Cache Compression for Efficient LLM Inference

    [https://arxiv.org/abs/2402.09398](https://arxiv.org/abs/2402.09398)

    这项研究提出了一个称为LESS的方法，通过集成一个固定尺寸的缓存和基于驱逐的缓存方法，可以在大型语言模型中减小内存占用的问题，同时保持全部标记的可查询能力，并在多种任务上显示出良好的性能。

    

    许多计算因素限制了大型语言模型的广泛部署。本文关注于由键值(KV)缓存引起的内存瓶颈，这是一种计算快捷方式，在解码过程中需要存储先前的KV对。现有的KV缓存方法通过修剪或驱逐相对不重要的KV对的大片区域，显著减少缓存的内存占用，但在需要重新收集大多数前一个标记的任务中，它们的成功有限。为了缓解这个问题，我们提出了LESS，它将一个（几乎免费的）固定尺寸的缓存与基于驱逐的缓存方法简单地集成在一起，以便所有的标记可以在后续的解码步骤中查询。它能够在时间上保留信息，在多种任务上展现出合理性，我们展示了LESS可以帮助减小缓存所有内容的性能差距，有时甚至可以与其相匹配，同时具有高效性。

    arXiv:2402.09398v1 Announce Type: cross Abstract: Many computational factors limit broader deployment of large language models. In this paper, we focus on a memory bottleneck imposed by the key-value (KV) cache, a computational shortcut that requires storing previous KV pairs during decoding. While existing KV cache methods approach this problem by pruning or evicting large swaths of relatively less important KV pairs to dramatically reduce the memory footprint of the cache, they can have limited success in tasks that require recollecting a majority of previous tokens. To alleviate this issue, we propose LESS, a simple integration of a (nearly free) constant sized cache with eviction-based cache methods, such that all tokens can be queried at later decoding steps. Its ability to retain information throughout time shows merit on a variety of tasks where we demonstrate LESS can help reduce the performance gap from caching everything, sometimes even matching it, all while being efficient.
    
[^7]: LL-GABR: 使用强化学习实现高效能耗的实时视频流传输

    LL-GABR: Energy Efficient Live Video Streaming Using Reinforcement Learning

    [https://arxiv.org/abs/2402.09392](https://arxiv.org/abs/2402.09392)

    LL-GABR是一种使用深度强化学习的方法，通过使用感知视频质量而不是比特率建模QoE，并结合能量消耗和其他指标，实现了高效能耗的实时视频流传输。

    

    近年来，自适应比特率（ABR）算法在实时视频流传输方面取得了成功，通过降低延迟，提供更高比特率的视频，并将视频缓冲时间减到最小，从而提高了用户体验（QoE）。然而，这些ABR算法使用的QoE模型没有考虑到大部分实时视频流传输客户端使用的是移动设备，在移动设备上，更高的比特率不一定意味着更高的视觉感知质量。忽视感知质量会导致以更高的比特率播放视频，而并没有显著提高视觉感知质量，同时对于电池受限的移动设备来说会增加能量消耗。本文提出了一种名为LL-GABR的深度强化学习方法，该方法使用感知视频质量而不是比特率建模QoE，并将能量消耗与其他指标结合起来。

    arXiv:2402.09392v1 Announce Type: cross Abstract: Over the recent years, research and development in adaptive bitrate (ABR) algorithms for live video streaming have been successful in improving users' quality of experience (QoE) by reducing latency to near real-time levels while delivering higher bitrate videos with minimal rebuffering time. However, the QoE models used by these ABR algorithms do not take into account that a large portion of live video streaming clients use mobile devices where a higher bitrate does not necessarily translate into higher perceived quality. Ignoring perceived quality results in playing videos at higher bitrates without a significant increase in perceptual video quality and becomes a burden for battery-constrained mobile devices due to higher energy consumption. In this paper, we propose LL-GABR, a deep reinforcement learning approach that models the QoE using perceived video quality instead of bitrate and uses energy consumption along with other metrics 
    
[^8]: LlaSMol:利用大规模、全面、高质量的指令调优数据集推进化学的大规模语言模型

    LlaSMol: Advancing Large Language Models for Chemistry with a Large-Scale, Comprehensive, High-Quality Instruction Tuning Dataset

    [https://arxiv.org/abs/2402.09391](https://arxiv.org/abs/2402.09391)

    本文介绍了LlaSMol，它是一种推进化学领域大规模语言模型的方法。通过使用一个大规模、全面、高质量的指令调优数据集来训练模型，LlaSMol在化学任务中表现出强大的性能，超过了GPT-4并接近于任务特定模型。

    

    化学在药物研发和材料科学等许多领域中起着至关重要的作用。尽管诸如GPT-4之类的大型语言模型（LLM）在自然语言处理任务上展现出了非凡的能力，但现有工作表明它们在化学任务上的性能令人失望。然而，在本文中，我们展示了我们开发的LLM在一系列化学任务上可以取得非常强大的结果，在所有任务上都显著优于最先进的GPT-4，并接近SoTA任务特定模型。我们取得成功的关键是一个名为SMolInstruct的大规模、全面、高质量的指令调优数据集。它包含了14个经过精心挑选的化学任务和超过三百万个高质量样本，为训练和评估化学LLM奠定了坚实基础。基于SMolInstruct，我们对一组开源LLM进行了微调，其中，我们发现Mistral ser是最佳性能的模型。

    arXiv:2402.09391v1 Announce Type: new Abstract: Chemistry plays a crucial role in many domains, such as drug discovery and material science. While large language models (LLMs) such as GPT-4 exhibit remarkable capabilities on natural language processing tasks, existing work shows their performance on chemistry tasks is discouragingly low. In this paper, however, we demonstrate that our developed LLMs can achieve very strong results on a comprehensive set of chemistry tasks, outperforming the most advanced GPT-4 across all the tasks by a substantial margin and approaching the SoTA task-specific models. The key to our success is a large-scale, comprehensive, high-quality dataset for instruction tuning named SMolInstruct. It contains 14 meticulously selected chemistry tasks and over three million high-quality samples, laying a solid foundation for training and evaluating LLMs for chemistry. Based on SMolInstruct, we fine-tune a set of open-source LLMs, among which, we find that Mistral ser
    
[^9]: HGOT: 用于检索增强上下文学习中事实性评估的分层思维图

    HGOT: Hierarchical Graph of Thoughts for Retrieval-Augmented In-Context Learning in Factuality Evaluation

    [https://arxiv.org/abs/2402.09390](https://arxiv.org/abs/2402.09390)

    HGOT是一种用于检索增强上下文学习中事实性评估的分层思维图方法，通过利用大型语言模型的规划能力和思维质量评估指标来提高相关段落的检索和答案选择。

    

    随着大型语言模型（LLMs）在许多应用中的广泛应用，事实性和幻觉的倾向引发了重大关切。为了解决这个问题，特别是在检索增强的上下文学习中，我们引入了分层思维图（HGOT），这是一种结构化的、多层次的图形方法，旨在增强在上下文学习过程中相关段落的检索。该框架利用LLMs的逐渐规划能力，采用分而治之的策略将复杂查询分解为可处理的子查询。它通过引入最近提出的引文回忆和精确度指标来评估思维质量，将答案的可信度与思维的质量内在地联系起来，从而改进了自洽性多数投票的答案选择方法。这种方法引入了一个加权系统，在多数投票中优先考虑答案。

    arXiv:2402.09390v1 Announce Type: new Abstract: With the widespread adoption of large language models (LLMs) in numerous applications, the challenge of factuality and the propensity for hallucinations raises significant concerns. To address this issue, particularly in retrieval-augmented in-context learning, we introduce the hierarchical graph of thoughts (HGOT), a structured, multi-layered graph approach designed to enhance the retrieval of pertinent passages during in-context learning. The framework utilizes the emergent planning capabilities of LLMs, employing the divide-and-conquer strategy to break down complex queries into manageable sub-queries. It refines self-consistency majority voting for answer selection, which incorporates the recently proposed citation recall and precision metrics to assess the quality of thoughts, linking an answer's credibility intrinsically to the thought's quality. This methodology introduces a weighted system in majority voting, prioritizing answers 
    
[^10]: 熵正则化的基于点的价值迭代

    Entropy-regularized Point-based Value Iteration

    [https://arxiv.org/abs/2402.09388](https://arxiv.org/abs/2402.09388)

    在部分可观测问题领域，我们提出了一种熵正则化的基于模型的规划器，在规划和目标推理中通过鼓励策略不承诺一个单一的动作来提高鲁棒性和目标推理性能。

    

    面对模型不确定性和目标不确定性，部分可观测问题的基于模型的规划器必须适应两者。然而，这些类型的不确定性可能导致基于模型的规划器变得脆弱，因为它们依赖于精确的模型并倾向于承诺一个单一的最优行为。受到无模型设置中的结果的启发，我们提出了一种熵正则化的基于模型的规划器来解决部分可观测问题。熵正则化通过鼓励策略在规划和目标推理中尽可能不承诺一个单一的动作来促进策略的鲁棒性。我们评估了三个问题领域中熵正则化策略的鲁棒性和目标推理性能。我们的结果表明，在建模错误和目标推理准确性方面，熵正则化策略优于非熵正则化的基准策略。

    arXiv:2402.09388v1 Announce Type: new Abstract: Model-based planners for partially observable problems must accommodate both model uncertainty during planning and goal uncertainty during objective inference. However, model-based planners may be brittle under these types of uncertainty because they rely on an exact model and tend to commit to a single optimal behavior. Inspired by results in the model-free setting, we propose an entropy-regularized model-based planner for partially observable problems. Entropy regularization promotes policy robustness for planning and objective inference by encouraging policies to be no more committed to a single action than necessary. We evaluate the robustness and objective inference performance of entropy-regularized policies in three problem domains. Our results show that entropy-regularized policies outperform non-entropy-regularized baselines in terms of higher expected returns under modeling errors and higher accuracy during objective inference.
    
[^11]: 说服、委托和私有信息在算法辅助决策中的应用

    Persuasion, Delegation, and Private Information in Algorithm-Assisted Decisions

    [https://arxiv.org/abs/2402.09384](https://arxiv.org/abs/2402.09384)

    一篇论文研究了在算法辅助决策中，如何设计最优的预测算法和委托规则。关键发现包括：委托的最优性与委托人是否会做出与代理人相同的决策有关、最具信息量的算法不一定是最优的、常见的算法限制会降低决策质量。

    

    一位委托人设计了一个算法，该算法生成一个公开可见的二进制状态预测。她必须决定是根据预测直接行动还是将决策委托给一个代理人，该代理人具有私有信息但可能存在不对齐问题。我们研究了在这种环境下预测算法和委托规则的最优设计。得出了三个关键发现：(1)只有当委托人在观察到代理人的信息时会做出与代理人相同的二进制决策时，委托才是最优的。(2)提供最具信息量的算法可能并不是最优的，即使委托人可以根据算法的预测来行动。相反，最优算法可能提供更多关于一个状态的信息，并限制关于另一个状态的信息。(3)在没有完美的预测准确性的情况下，常见的对算法的限制，如保持"人机合作"或要求最大预测精度，会严重降低决策质量。

    arXiv:2402.09384v1 Announce Type: cross Abstract: A principal designs an algorithm that generates a publicly observable prediction of a binary state. She must decide whether to act directly based on the prediction or to delegate the decision to an agent with private information but potential misalignment. We study the optimal design of the prediction algorithm and the delegation rule in such environments. Three key findings emerge: (1) Delegation is optimal if and only if the principal would make the same binary decision as the agent had she observed the agent's information. (2) Providing the most informative algorithm may be suboptimal even if the principal can act on the algorithm's prediction. Instead, the optimal algorithm may provide more information about one state and restrict information about the other. (3) Common restrictions on algorithms, such as keeping a "human-in-the-loop" or requiring maximal prediction accuracy, strictly worsen decision quality in the absence of perfec
    
[^12]: 从CT图像中进行深度肋骨骨折实例分割和分类：基于RibFrac挑战赛

    Deep Rib Fracture Instance Segmentation and Classification from CT on the RibFrac Challenge

    [https://arxiv.org/abs/2402.09372](https://arxiv.org/abs/2402.09372)

    该论文介绍了基于RibFrac挑战赛的深度学习算法，可以从CT扫描中实现肋骨骨折的实例分割和分类。研究通过提供一个包含大量标注数据和评估指标的基准数据集，解决了肋骨骨折检测领域缺乏数据和评估的问题。MICCAI 2020挑战赛期间，七个团队的方法在实例分割和分类任务中表现出色。

    

    肋骨骨折是一种常见且可能严重的损伤，检测肋骨骨折在CT扫描中可能具有挑战性且耗时。虽然已经有一些努力来解决这个领域的问题，但缺少大规模标注的数据集和评估基准妨碍了深度学习算法的发展和验证。为了解决这个问题，引入了RibFrac挑战赛，提供了一个包含超过5,000个肋骨骨折实例和660个CT扫描的基准数据集，包括每个实例的体素级别实例掩码标注以及针对四个临床类别（锁闭骨折、非移位骨折、移位骨折或分段骨折）的诊断标签。该挑战包括两个任务：一个是检测（实例分割）任务，评估指标为FROC风格，另一个是分类任务，评估指标为F1风格。在MICCAI 2020挑战期间，对243个结果进行了评估，并邀请了七个团队参加挑战总结。分析结果表明，几个顶尖团队的方法在肋骨骨折实例分割和分类任务上取得了显著的性能提升。

    arXiv:2402.09372v1 Announce Type: cross Abstract: Rib fractures are a common and potentially severe injury that can be challenging and labor-intensive to detect in CT scans. While there have been efforts to address this field, the lack of large-scale annotated datasets and evaluation benchmarks has hindered the development and validation of deep learning algorithms. To address this issue, the RibFrac Challenge was introduced, providing a benchmark dataset of over 5,000 rib fractures from 660 CT scans, with voxel-level instance mask annotations and diagnosis labels for four clinical categories (buckle, nondisplaced, displaced, or segmental). The challenge includes two tracks: a detection (instance segmentation) track evaluated by an FROC-style metric and a classification track evaluated by an F1-style metric. During the MICCAI 2020 challenge period, 243 results were evaluated, and seven teams were invited to participate in the challenge summary. The analysis revealed that several top ri
    
[^13]: Transformers可以实现长度的泛化，但并不稳健

    Transformers Can Achieve Length Generalization But Not Robustly

    [https://arxiv.org/abs/2402.09371](https://arxiv.org/abs/2402.09371)

    Transformers在特定组合的数据格式和位置编码的情况下可以实现长度的泛化，但仍然存在脆弱性和大量方差。

    

    长度的泛化，即从较短的训练序列推广到较长的测试序列的能力，对于语言模型来说是一个重要的挑战。即使是处理相对简单任务的大规模Transformer也存在这个问题。在本文中，我们使用两个整数相加的任务来测试Transformer的长度泛化能力。我们展示了长度泛化的成功与数据格式和位置编码的类型密切相关。通过正确组合数据格式和位置编码，我们首次展示出标准的Transformer可以推广到输入长度的2.5倍的序列长度。然而，与内分布泛化不同，长度泛化仍然很脆弱，受到随机权重初始化和训练数据顺序等因素的显著影响，导致不同随机种子之间存在较大差异。

    arXiv:2402.09371v1 Announce Type: cross Abstract: Length generalization, defined as the ability to extrapolate from shorter training sequences to longer test ones, is a significant challenge for language models. This issue persists even with large-scale Transformers handling relatively straightforward tasks. In this paper, we test the Transformer's ability of length generalization using the task of addition of two integers. We show that the success of length generalization is intricately linked to the data format and the type of position encoding. Using the right combination of data format and position encodings, we show for the first time that standard Transformers can extrapolate to a sequence length that is 2.5x the input length. Nevertheless, unlike in-distribution generalization, length generalization remains fragile, significantly influenced by factors like random weight initialization and training data order, leading to large variances across different random seeds.
    
[^14]: 伪随机纠错码

    Pseudorandom Error-Correcting Codes

    [https://arxiv.org/abs/2402.09370](https://arxiv.org/abs/2402.09370)

    我们构建了一种伪随机纠错码，它对替换和删除错误具有鲁棒性，并且可以高效解码。我们还使用伪随机码提出了一种对语言模型输出进行水印处理的方案，该方案对裁剪和随机替换、删除具有恒定的鲁棒性。

    

    我们构建了伪随机纠错码（或简称为伪随机码），它们是具有以下特性的纠错码：对于任何计算受限的对手来说，任意多个编码词都是伪随机的。通过解码密钥，可以高效地纠正有错误的编码词。我们构建了对替换错误和删除错误具有强鲁棒性的伪随机码，其中伪随机性基于标准密码学假设。具体而言，伪随机性基于LPN问题的$2^{O(\sqrt{n})}$困难程度，或者基于LPN问题和低密度下的插入异或问题的多项式困难程度。

    arXiv:2402.09370v1 Announce Type: cross Abstract: We construct pseudorandom error-correcting codes (or simply pseudorandom codes), which are error-correcting codes with the property that any polynomial number of codewords are pseudorandom to any computationally-bounded adversary. Efficient decoding of corrupted codewords is possible with the help of a decoding key.   We build pseudorandom codes that are robust to substitution and deletion errors, where pseudorandomness rests on standard cryptographic assumptions. Specifically, pseudorandomness is based on either $2^{O(\sqrt{n})}$-hardness of LPN, or polynomial hardness of LPN and the planted XOR problem at low density.   As our primary application of pseudorandom codes, we present an undetectable watermarking scheme for outputs of language models that is robust to cropping and a constant rate of random substitutions and deletions. The watermark is undetectable in the sense that any number of samples of watermarked text are computationa
    
[^15]: Magic-Me: 特定身份视频定制扩散

    Magic-Me: Identity-Specific Video Customized Diffusion

    [https://arxiv.org/abs/2402.09368](https://arxiv.org/abs/2402.09368)

    本研究提出了一个名为视频定制扩散（VCD）的简单而有效的主题身份可控视频生成框架，通过指定的图像定义主题ID，并加强身份信息提取和逐帧相关性注入，实现了稳定且在很大程度上保持身份一致性的视频输出。

    

    在生成模型领域，为特定身份（ID）创建内容已经引起了很大的兴趣。在文本到图像生成（T2I）领域中，以主题驱动的内容生成已经取得了巨大的进展，使得图像中的ID可控。然而，将其扩展到视频生成领域还没有得到很好的探索。在这项工作中，我们提出了一个简单但有效的主题身份可控视频生成框架，称为视频定制扩散（VCD）。通过几个指定的图像定义一个特定的主题ID，VCD加强了身份信息的提取，并在初始化阶段注入逐帧相关性，从而使得视频输出在很大程度上保持了身份的一致性。为了实现这一点，我们提出了三个对于高质量身份保留至关重要的创新组件：1）使用prompt-to-segmentation对身份进行裁剪训练的ID模块，以解开ID信息和背景噪声的联系。

    arXiv:2402.09368v1 Announce Type: cross Abstract: Creating content for a specific identity (ID) has shown significant interest in the field of generative models. In the field of text-to-image generation (T2I), subject-driven content generation has achieved great progress with the ID in the images controllable. However, extending it to video generation is not well explored. In this work, we propose a simple yet effective subject identity controllable video generation framework, termed Video Custom Diffusion (VCD). With a specified subject ID defined by a few images, VCD reinforces the identity information extraction and injects frame-wise correlation at the initialization stage for stable video outputs with identity preserved to a large extent. To achieve this, we propose three novel components that are essential for high-quality ID preservation: 1) an ID module trained with the cropped identity by prompt-to-segmentation to disentangle the ID information and the background noise for mor
    
[^16]: HiRE:高召回率的高效LLM推理的近似Top-$k$估计

    HiRE: High Recall Approximate Top-$k$ Estimation for Efficient LLM Inference

    [https://arxiv.org/abs/2402.09360](https://arxiv.org/abs/2402.09360)

    HiRE是一种用于高效的LLM推理的高召回率的近似Top-k估计方法，通过压缩方案减少了模型参数传输和延迟。

    

    在加速器（GPU/TPU）上使用生成式大型语言模型（LLM）进行自回归解码往往受到内存限制，大部分时间用于将模型参数从高带宽内存（HBM）传输到缓存中。与此同时，最近的研究表明，通过适当训练模型，在前馈（FFN）层中维持质量的同时具有显著的稀疏性/冗余性（其中$k \approx 0.05$），从而提出了减少模型参数传输和延迟的方法。然而，利用这种稀疏性来改善延迟的过程受到数据依赖性的限制，通常需要进行完整的矩阵操作来识别前$k$个行/列，严重限制了潜在的收益。为了解决这些问题，我们引入了HiRE（高召回率的近似Top-k估计）。HiRE包括两个新颖的组件：（i）一种压缩方案以便廉价地估计前$k$个行/列。

    arXiv:2402.09360v1 Announce Type: cross Abstract: Autoregressive decoding with generative Large Language Models (LLMs) on accelerators (GPUs/TPUs) is often memory-bound where most of the time is spent on transferring model parameters from high bandwidth memory (HBM) to cache. On the other hand, recent works show that LLMs can maintain quality with significant sparsity/redundancy in the feedforward (FFN) layers by appropriately training the model to operate on a top-$k$ fraction of rows/columns (where $k \approx 0.05$), there by suggesting a way to reduce the transfer of model parameters, and hence latency. However, exploiting this sparsity for improving latency is hindered by the fact that identifying top rows/columns is data-dependent and is usually performed using full matrix operations, severely limiting potential gains. To address these issues, we introduce HiRE (High Recall Approximate Top-k Estimation). HiRE comprises of two novel components: (i) a compression scheme to cheaply p
    
[^17]: 将ChatGPT集成到安全医院网络中：一个关于改进放射学报告分析的案例研究

    Integrating ChatGPT into Secure Hospital Networks: A Case Study on Improving Radiology Report Analysis

    [https://arxiv.org/abs/2402.09358](https://arxiv.org/abs/2402.09358)

    本研究首次将类似于ChatGPT的基于云的人工智能应用于安全的医院模型中，用于分析放射学报告，通过对比学习方法实现了95%以上的准确率，同时提高了预测可靠性和可解释性，对于医生来说具有重要意义。

    

    本研究展示了将类似于ChatGPT的基于云的人工智能首次应用于安全模型中，用于分析放射学报告，重视患者数据隐私。通过使用独特的句子级知识蒸馏方法，通过对比学习，我们在检测异常方面达到了超过95%的准确率。该模型还准确地标记其预测中的不确定性，增强了对医生的可靠性和可解释性，并带有确定性指示器。这些进展在开发安全高效的医疗人工智能工具方面代表了重大进步，为监管最少的医院内部人工智能应用提供了有希望的未来。

    arXiv:2402.09358v1 Announce Type: new Abstract: This study demonstrates the first in-hospital adaptation of a cloud-based AI, similar to ChatGPT, into a secure model for analyzing radiology reports, prioritizing patient data privacy. By employing a unique sentence-level knowledge distillation method through contrastive learning, we achieve over 95% accuracy in detecting anomalies. The model also accurately flags uncertainties in its predictions, enhancing its reliability and interpretability for physicians with certainty indicators. These advancements represent significant progress in developing secure and efficient AI tools for healthcare, suggesting a promising future for in-hospital AI applications with minimal supervision.
    
[^18]: 单重置的分而治之模仿学习

    Single-Reset Divide & Conquer Imitation Learning

    [https://arxiv.org/abs/2402.09355](https://arxiv.org/abs/2402.09355)

    本文介绍了一种名为单重置的分而治之模仿学习的扩展方法，该方法解决了在演示学习中需要重置特定状态的限制，使其可以应用于实际系统。

    

    演示通常用于加快深度强化学习算法的学习过程。为了应对访问多个演示的困难，一些算法已经被开发出来从单个演示中学习。其中，分而治之模仿学习算法利用顺序偏差来学习一个控制策略，用于复杂机器人任务的单状态演示。最新版本DCIL-II展示了显著的样本效率。这种新方法在扩展的目标条件强化学习框架内运作，确保了从演示中提取的中间目标和后续目标之间的兼容性。然而，一个基本的限制是该系统可以被重置到演示轨迹上的特定状态，将应用限制在模拟系统中。为了解决这个问题，我们引入了一种名为单重置的扩展方法。

    arXiv:2402.09355v1 Announce Type: cross Abstract: Demonstrations are commonly used to speed up the learning process of Deep Reinforcement Learning algorithms. To cope with the difficulty of accessing multiple demonstrations, some algorithms have been developed to learn from a single demonstration. In particular, the Divide & Conquer Imitation Learning algorithms leverage a sequential bias to learn a control policy for complex robotic tasks using a single state-based demonstration. The latest version, DCIL-II demonstrates remarkable sample efficiency. This novel method operates within an extended Goal-Conditioned Reinforcement Learning framework, ensuring compatibility between intermediate and subsequent goals extracted from the demonstration. However, a fundamental limitation arises from the assumption that the system can be reset to specific states along the demonstrated trajectory, confining the application to simulated systems. In response, we introduce an extension called Single-Re
    
[^19]: 使用人机协同的方法开发大型语言模型审计框架

    Developing a Framework for Auditing Large Language Models Using Human-in-the-Loop

    [https://arxiv.org/abs/2402.09346](https://arxiv.org/abs/2402.09346)

    本文提出了一种使用人机协同的方法开发大型语言模型审计框架，通过使用不同版本的相同问题来探测模型可能存在的偏见或幻觉，实现了自动化和可扩展的审计方法。

    

    随着大型语言模型在各种用户和场景中的普及，识别使用这些模型时可能存在的问题变得至关重要，例如偏见、不一致性和幻觉。尽管对这些问题进行审计是可取的，但并不容易解决。一种有效的方法是使用不同版本的相同问题来探测语言模型，这可以暴露其知识或运行中的不一致性，从而表明可能存在偏见或幻觉。然而，要在大规模上实现这种审计方法，我们需要一种可靠且自动化的生成这些探测的方法。在本文中，我们提出了一种自动化和可扩展的解决方案，其中一种方法是使用不同的语言模型和人机协同。这种方法提供了可验证性和透明性，避免对同一语言模型的循环依赖，并增加了科学严谨性和普适性。

    arXiv:2402.09346v1 Announce Type: new Abstract: As LLMs become more pervasive across various users and scenarios, identifying potential issues when using these models becomes essential. Examples include bias, inconsistencies, and hallucination. Although auditing the LLM for these problems is desirable, it is far from being easy or solved. An effective method is to probe the LLM using different versions of the same question. This could expose inconsistencies in its knowledge or operation, indicating potential for bias or hallucination. However, to operationalize this auditing method at scale, we need an approach to create those probes reliably and automatically. In this paper we propose an automatic and scalable solution, where one uses a different LLM along with human-in-the-loop. This approach offers verifiability and transparency, while avoiding circular reliance on the same LLMs, and increasing scientific rigor and generalizability. Specifically, we present a novel methodology with 
    
[^20]: 通过信息论奖励建模来减轻奖励作弊问题

    Mitigating Reward Hacking via Information-Theoretic Reward Modeling

    [https://arxiv.org/abs/2402.09345](https://arxiv.org/abs/2402.09345)

    本文提出了一种名为InfoRM的奖励建模框架，通过引入变分信息瓶颈目标和模型复杂度调节机制，解决了奖励作弊问题，并利用集成聚类偏差得分（ICDS）来检测奖励过度优化。

    

    尽管强化学习从人类反馈（RLHF）中的成功在与人类价值观的语言模型的对齐方面，奖励作弊问题，也被称为奖励过度优化，仍然是一个关键挑战，主要源于奖励建模的局限性，即奖励模型的泛化能力和偏好数据集的不一致性。在这项工作中，我们从信息论的视角来解决这个问题，并提出了一种可推广和鲁棒的奖励建模框架，称为InfoRM，通过引入变分信息瓶颈目标来过滤出不相关的信息，并开发一种模型复杂度调节机制。值得注意的是，我们进一步发现了过度优化与潜变量空间的异常值之间的相关性，将InfoRM作为检测奖励过度优化的一种有前途的工具。受到这一发现的启发，我们提出了集成聚类偏差得分（ICDS），用于量化过优化问题。

    arXiv:2402.09345v1 Announce Type: cross Abstract: Despite the success of reinforcement learning from human feedback (RLHF) in aligning language models with human values, reward hacking, also termed reward overoptimization, remains a critical challenge, which primarily stems from limitations in reward modeling, i.e., generalizability of the reward model and inconsistency in the preference dataset. In this work, we tackle this problem from an information theoretic-perspective, and propose a generalizable and robust framework for reward modeling, namely InfoRM, by introducing a variational information bottleneck objective to filter out irrelevant information and developing a mechanism for model complexity modulation. Notably, we further identify a correlation between overoptimization and outliers in the latent space, establishing InfoRM as a promising tool for detecting reward overoptimization. Inspired by this finding, we propose the Integrated Cluster Deviation Score (ICDS), which quant
    
[^21]: 适用于逆问题解决的神经网络渐近行为的研究

    Neural Networks asymptotic behaviours suitable for the resolution of inverse problems

    [https://arxiv.org/abs/2402.09338](https://arxiv.org/abs/2402.09338)

    本文研究了适用于解决反褶积逆问题的神经网络渐近行为，并发现使用从神经网络的渐近极限导出的高斯过程比全连接的神经网络获得更好的结果，而且观察到随着层数的增加，训练后的神经网络的准确性接近于高斯过程的准确性。其中一个高斯过程的解释与传统方法不同，提供了一种新的视角。

    

    在本文中，我们对神经网络（NN）技术在反褶积逆问题中的有效性进行了研究。我们考虑到NN的渐近极限，对应于高斯过程（GPs），其中参数的非线性性丢失。利用这些结果的GPs，我们通过在格子上使用蒙特卡洛技术模拟量子谐振子来解决反褶积逆问题。我们的研究结果表明，使用全连接的NN解决反褶积逆问题的结果不如使用从NN的渐近极限导出的GPs获得的结果好。此外，我们观察到随着层数的增加，训练后的NN的准确性接近于GPs的准确性。值得注意的是，其中一个GPs的解释与文献中的传统方法不同，提供了一种新的视角。

    arXiv:2402.09338v1 Announce Type: cross Abstract: In this paper, we perform a study on the effectiveness of Neural Network (NN) techniques for deconvolution inverse problems. We consider NN's asymptotic limits, corresponding to Gaussian Processes (GPs), where parameter non-linearities are lost. Using these resulting GPs, we address the deconvolution inverse problem in the case of a quantum harmonic oscillator simulated through Monte Carlo techniques on a lattice. A scenario with a known analytical solution. Our findings indicate that solving the deconvolution inverse problem with a fully connected NN yields less performing results than those obtained using the GPs derived from NN's asymptotic limits. Furthermore, we observe the trained NN's accuracy approaching that of GPs with increasing layer width. Notably, one of these GPs defies interpretation as a probabilistic model, offering a novel perspective compared to established methods in the literature. Additionally, the NNs, in their a
    
[^22]: AuditLLM:一种使用多探测方法对大型语言模型进行审计的工具

    AuditLLM: A Tool for Auditing Large Language Models Using Multiprobe Approach

    [https://arxiv.org/abs/2402.09334](https://arxiv.org/abs/2402.09334)

    "AuditLLM"是一种能够以系统的方式评估各种LLMs的性能的工具，通过使用从单个问题生成的多个探测来对给定的LLM进行审计，从而识别模型在理解或操作方面的任何不一致性。

    

    当大型语言模型（LLMs）在各种情境中越来越广泛地被采用时，确保它们在特定应用中是相对安全、一致和可靠的变得至关重要。这可能需要对它们进行探测或审计。通过使用多次迭代的单个问题对LLMs进行探测，可以揭示它们的知识或功能的潜在不一致性。然而，目前缺乏一种能够以简单工作流程和低技术门槛进行此类审计的工具。在这个演示中，我们介绍了一种名为"AuditLLM"的新颖工具，它旨在以系统的方式评估各种LLMs的性能。AuditLLM的核心功能在于能够通过使用从单个问题生成的多个探测来对给定的LLM进行审计，从而识别模型在理解或操作方面的任何不一致性。一个相对健壮、可靠和一致的LLM应该对以不同方式或由不同人提出的问题给出语义相似的回答。

    arXiv:2402.09334v1 Announce Type: new Abstract: As Large Language Models (LLMs) gain wider adoption in various contexts, it becomes crucial to ensure they are reasonably safe, consistent, and reliable for an application at hand. This may require probing or auditing them. Probing LLMs with varied iterations of a single question could reveal potential inconsistencies in their knowledge or functionality. However, a tool for performing such audits with simple workflow and low technical threshold is lacking. In this demo, we introduce "AuditLLM," a novel tool designed to evaluate the performance of various LLMs in a methodical way. AuditLLM's core functionality lies in its ability to test a given LLM by auditing it using multiple probes generated from a single question, thereby identifying any inconsistencies in the model's understanding or operation. A reasonably robust, reliable, and consistent LLM should output semantically similar responses for a question asked differently or by differe
    
[^23]: ICDPO: 通过上下文直接偏好优化有效地借用他人的对齐能力

    ICDPO: Effectively Borrowing Alignment Capability of Others via In-context Direct Preference Optimization

    [https://arxiv.org/abs/2402.09320](https://arxiv.org/abs/2402.09320)

    本文提出一种名为ICDPO的方法，通过借用他人的对齐能力，并使用上下文学习来优化生成模型，以提高大型语言模型的性能。

    

    大型语言模型（LLM）依赖于人类偏好对齐（HPA）来确保生成安全内容。由于微调带来的巨大成本，出现了免微调的方法，通常通过外部辅助方法修改LLM解码。然而，这些方法并没有从本质上增强LLM本身。本文重新思考了DPO的推导过程，建立了基于LLM在上下文学习（ICL）之前和之后的状态的即时打分器。因此，我们提出了一种名为ICDPO的新方法。它使LLM能够通过ICL从优秀的LLM中借用HPA能力，生成由上述即时打分器估计的良好对齐的响应，从而提高最终性能。ICDPO可以通过两阶段检索器和升级的打分器进一步增强，都具有益处。大量实验证明了ICDPO的有效性。

    arXiv:2402.09320v1 Announce Type: cross Abstract: Large Language Models (LLMs) rely on Human Preference Alignment (HPA) to ensure the generation of safe content. Due to the heavy cost associated with fine-tuning, fine-tuning-free methods have emerged, typically modifying LLM decoding with external auxiliary methods. However, these methods do not essentially enhance the LLM itself. In this paper, we rethink the derivation procedures of DPO, based on which we conversely build an instant scorer using the states of the LLM before and after In-context Learning (ICL). Accordingly, we propose a novel approach called In-Context Direct Preference Optimization (ICDPO). It enables LLMs to borrow the HPA capabilities from superior LLMs with ICL, generating well-aligned responses as estimated by the aforementioned instant scorer, thereby enhancing the final performance. ICDPO can be further enhanced with a two-stage retriever and an upgraded scorer, both offering benefits. Extensive experiments sho
    
[^24]: 利用预训练自编码器进行可解释的音乐音频原型学习

    Leveraging Pre-Trained Autoencoders for Interpretable Prototype Learning of Music Audio

    [https://arxiv.org/abs/2402.09318](https://arxiv.org/abs/2402.09318)

    提出了一种基于预训练自编码器的可解释音乐音频原型学习模型PECMAE，并通过使用扩散解码器提升了重构效果。在音乐乐器分类和流派识别数据集上的实验结果表明，该模型能够保留更多关于音频特征的信息，提高分类性能。

    

    我们提出了一种基于原型学习的音乐音频分类的可解释模型PECMAE。我们的模型基于之前的方法APNet，该方法联合学习自编码器和原型网络。相反，我们提出将这两个训练过程分离，这样我们就可以利用已在更大数据上预训练的自监督自编码器（EnCodecMAE）提供更好的泛化表示。APNet使得原型可以通过最近的训练数据样本进行波形重构以实现可解释性。相反，我们探索使用扩散解码器，它允许在没有这种依赖的情况下进行重构。我们在音乐乐器分类（Medley-Solos-DB）和流派识别（GTZAN和一个更大的内部数据集）数据集上评估我们的方法，后者是一个以前未使用原型网络解决的更具挑战的任务。我们发现基于原型的模型可以保留更多关于音频特征的信息，从而提高了分类性能。

    arXiv:2402.09318v1 Announce Type: cross Abstract: We present PECMAE, an interpretable model for music audio classification based on prototype learning. Our model is based on a previous method, APNet, which jointly learns an autoencoder and a prototypical network. Instead, we propose to decouple both training processes. This enables us to leverage existing self-supervised autoencoders pre-trained on much larger data (EnCodecMAE), providing representations with better generalization. APNet allows prototypes' reconstruction to waveforms for interpretability relying on the nearest training data samples. In contrast, we explore using a diffusion decoder that allows reconstruction without such dependency. We evaluate our method on datasets for music instrument classification (Medley-Solos-DB) and genre recognition (GTZAN and a larger in-house dataset), the latter being a more challenging task not addressed with prototypical networks before. We find that the prototype-based models preserve mo
    
[^25]: embracing the black box: 朝向基于时间序列数据进行因果发现的基础模型

    Embracing the black box: Heading towards foundation models for causal discovery from time series data

    [https://arxiv.org/abs/2402.09305](https://arxiv.org/abs/2402.09305)

    本文研究了基于时间序列数据进行因果发现的问题，提出了一种称为因果预训练的方法，通过以监督方式学习从多变量时间序列到潜在因果图的映射，实现了在共享动力学的情况下的监督式因果发现。

    

    来自时间序列数据的因果发现涵盖了许多现有的解决方案，包括基于深度学习技术的方法。然而，这些方法通常不支持深度学习中最常见的范式之一：端到端学习。为了弥补这一差距，我们研究了我们所称之为因果预训练的方法。这种方法旨在以监督的方式学习从多变量时间序列到潜在因果图的直接映射。我们的实证结果表明，在训练和测试时间序列样本共享大部分动力学的情况下，监督式因果发现是可能的。更重要的是，我们发现，即使额外的数据不共享相同的动力学，因果预训练的性能也随着数据和模型规模的增加而增加。此外，我们提供了实例，证明了基于因果预训练神经网络的真实世界数据的因果发现在一定范围内是可能的。

    arXiv:2402.09305v1 Announce Type: cross Abstract: Causal discovery from time series data encompasses many existing solutions, including those based on deep learning techniques. However, these methods typically do not endorse one of the most prevalent paradigms in deep learning: End-to-end learning. To address this gap, we explore what we call Causal Pretraining. A methodology that aims to learn a direct mapping from multivariate time series to the underlying causal graphs in a supervised manner. Our empirical findings suggest that causal discovery in a supervised manner is possible, assuming that the training and test time series samples share most of their dynamics. More importantly, we found evidence that the performance of Causal Pretraining can increase with data and model size, even if the additional data do not share the same dynamics. Further, we provide examples where causal discovery for real-world data with causally pretrained neural networks is possible within limits. We arg
    
[^26]: 人类中的即时概括与深度神经网络中的滞后概括——表示分歧的证据？

    Immediate generalisation in humans but a generalisation lag in deep neural networks$\unicode{x2014}$evidence for representational divergence?

    [https://arxiv.org/abs/2402.09303](https://arxiv.org/abs/2402.09303)

    研究对比了人类和深度神经网络在图像分类中的行为差异，发现人类具有即时概括能力，而DNNs存在滞后概括现象，这表明了表示分歧的存在。

    

    近期的研究在图像分类领域中对比了人类与深度神经网络（DNNs）的许多行为比较。通常，比较研究关注的是学习过程的最终结果，通过测量和比较目标类别表示的相似性。然而，这些表示如何形成即其过程——即在获取过程中观察到的行为变化和中间阶段——往往少有直接和实证的比较。在这里，我们报告了对人类观察者和不同经典与最新技术的DNNs中可转移表示是如何被获取的的详细调查。我们开发了一个受限的监督学习环境，该环境中我们对齐了学习相关的参数，如起始点、输入模式、可用输入数据以及提供的反馈。在整个学习过程中我们评估...

    arXiv:2402.09303v1 Announce Type: cross Abstract: Recent research has seen many behavioral comparisons between humans and deep neural networks (DNNs) in the domain of image classification. Often, comparison studies focus on the end-result of the learning process by measuring and comparing the similarities in the representations of object categories once they have been formed. However, the process of how these representations emerge$\unicode{x2014}$that is, the behavioral changes and intermediate stages observed during the acquisition$\unicode{x2014}$is less often directly and empirically compared.   Here we report a detailed investigation of how transferable representations are acquired in human observers and various classic and state-of-the-art DNNs. We develop a constrained supervised learning environment in which we align learning-relevant parameters such as starting point, input modality, available input data and the feedback provided. Across the whole learning process we evaluate 
    
[^27]: 通过部分监督强化学习学习后验可观察POMDP中的可解释策略

    Learning Interpretable Policies in Hindsight-Observable POMDPs through Partially Supervised Reinforcement Learning

    [https://arxiv.org/abs/2402.09290](https://arxiv.org/abs/2402.09290)

    该论文提出了部分监督强化学习（PSRL）框架，通过融合监督和非监督学习来生成更可解释的策略，同时利用状态估计器提取出监督语义状态信息，以及捕捉潜在状态信息。

    

    深度强化学习在视频游戏、机器人控制、自主驾驶和药物发现等各个领域取得了显着的成就。但在部分可观察的领域中，常见的方法主要依赖于从高维观察（如图像）进行端到端学习，而没有明确推理真实状态。我们提出了一个替代方向，引入了部分监督强化学习（PSRL）框架。PSRL框架的核心是将监督学习和非监督学习进行融合。该方法利用状态估计器从高维观察中提取出有时在训练时完全观察到的监督语义状态信息。这样可以得到更可解释的策略，将状态预测与控制结合起来。同时，它还捕捉到一个非监督潜在表示。这两者-语义状态和潜在状态然后被融合和应用。

    arXiv:2402.09290v1 Announce Type: cross Abstract: Deep reinforcement learning has demonstrated remarkable achievements across diverse domains such as video games, robotic control, autonomous driving, and drug discovery. Common methodologies in partially-observable domains largely lean on end-to-end learning from high-dimensional observations, such as images, without explicitly reasoning about true state. We suggest an alternative direction, introducing the Partially Supervised Reinforcement Learning (PSRL) framework. At the heart of PSRL is the fusion of both supervised and unsupervised learning. The approach leverages a state estimator to distill supervised semantic state information from high-dimensional observations which are often fully observable at training time. This yields more interpretable policies that compose state predictions with control. In parallel, it captures an unsupervised latent representation. These two-the semantic state and the latent state-are then fused and ut
    
[^28]: 营养事实、药物事实和模型事实：将AI伦理应用于枪支暴力研究

    Nutrition Facts, Drug Facts, and Model Facts: Putting AI Ethics into Practice in Gun Violence Research

    [https://arxiv.org/abs/2402.09286](https://arxiv.org/abs/2402.09286)

    通过提供一个模型事实模板，该研究旨在在枪支暴力研究中建立AI的信任和透明度，并减少对易受剥削人群数据的不信任。此模板使一般用户能够评估模型的有效性和偏见。

    

    论文介绍了一个在枪支暴力研究中应用AI伦理的框架，该框架旨在减少对黑人和有色人种等易受剥削的弱势人群数据的不信任。通过提出一个模型事实模板，将准确度和人口统计学分解为标准化和最小复杂值，使一般用户能够评估模型的有效性和偏见，而不需要深入研究技术模型文档。

    arXiv:2402.09286v1 Announce Type: new Abstract: Objective: Firearm injury research necessitates using data from often-exploited vulnerable populations of Black and Brown Americans. In order to minimize distrust, this study provides a framework for establishing AI trust and transparency with the general population. Methods: We propose a Model Facts template that is easily extendable and decomposes accuracy and demographics into standardized and minimally complex values. This framework allows general users to assess the validity and biases of a model without diving into technical model documentation. Examples: We apply the Model Facts template on two previously published models, a violence risk identification model and a suicide risk prediction model. We demonstrate the ease of accessing the appropriate information when the data is structured appropriately. Discussion: The Model Facts template is limited in its current form to human based data and biases. Like nutrition facts, it also wi
    
[^29]: 提升二分类问题的协方差和Hessian矩阵的协同特征分析

    Synergistic eigenanalysis of covariance and Hessian matrices for enhanced binary classification

    [https://arxiv.org/abs/2402.09281](https://arxiv.org/abs/2402.09281)

    本论文提出了一种新颖的方法，通过将训练集上计算的协方差矩阵的特征分析与深度学习模型上计算的Hessian矩阵相结合，实现了二分类任务中的最优类别可分性。该方法通过最大化类间平均距离和最小化类内方差，以及将数据投影到两个矩阵的最相关特征方向的组合空间来实现最优类别可分性。实证验证显示了该方法的有效性。

    

    在分类问题中，协方差和Hessian矩阵分别被单独分析，但是将这些矩阵集成起来可以增强它们在提高分类性能方面的综合能力。我们提出了一种新颖的方法，将训练集上计算的协方差矩阵的特征分析与深度学习模型上计算的Hessian矩阵相结合，以实现二分类任务中的最优类别可分性。我们的方法通过形式化证明证明了它可以最大化类间平均距离并最小化类内方差。通过将数据投影到两个矩阵的最相关特征方向的组合空间中，我们按照线性判别分析（LDA）的标准实现了最优类别可分性。对神经网络和健康数据集的实证验证始终支持我们的理论框架，并且证明了我们的方法的有效性。

    arXiv:2402.09281v1 Announce Type: cross Abstract: Covariance and Hessian matrices have been analyzed separately in the literature for classification problems. However, integrating these matrices has the potential to enhance their combined power in improving classification performance. We present a novel approach that combines the eigenanalysis of a covariance matrix evaluated on a training set with a Hessian matrix evaluated on a deep learning model to achieve optimal class separability in binary classification tasks. Our approach is substantiated by formal proofs that establish its capability to maximize between-class mean distance and minimize within-class variances. By projecting data into the combined space of the most relevant eigendirections from both matrices, we achieve optimal class separability as per the linear discriminant analysis (LDA) criteria. Empirical validation across neural and health datasets consistently supports our theoretical framework and demonstrates that our
    
[^30]: 个性化的大型语言模型

    Personalized Large Language Models

    [https://arxiv.org/abs/2402.09269](https://arxiv.org/abs/2402.09269)

    本文研究了个性化大型语言模型的方法，通过比较微调和零样本推理的方法，在主观任务中发现个性化微调能提高模型的推理能力，在情感识别和仇恨言论检测方面也获得了一致的性能提升。

    

    近年来，大型语言模型（LLM）在自然语言处理（NLP）任务中取得了显著的进展。然而，它们的通用性在需要个性化回应的场景（如推荐系统和聊天机器人）中存在一定的局限性。本文研究了个性化LLM的方法，比较了微调和零样本推理方法在主观任务中的效果。结果表明，与非个性化模型相比，个性化微调改善了模型的推理能力。在情感识别和仇恨言论检测的数据集上进行的实验表明，个性化方法在不同的LLM架构上获得了一致的性能提升。这些发现强调了在主观文本理解任务中提升LLM能力的个性化的重要性。

    arXiv:2402.09269v1 Announce Type: cross Abstract: Large language models (LLMs) have significantly advanced Natural Language Processing (NLP) tasks in recent years. However, their universal nature poses limitations in scenarios requiring personalized responses, such as recommendation systems and chatbots. This paper investigates methods to personalize LLMs, comparing fine-tuning and zero-shot reasoning approaches on subjective tasks. Results demonstrate that personalized fine-tuning improves model reasoning compared to non-personalized models. Experiments on datasets for emotion recognition and hate speech detection show consistent performance gains with personalized methods across different LLM architectures. These findings underscore the importance of personalization for enhancing LLM capabilities in subjective text perception tasks.
    
[^31]: 自动校准实事性：通过自评减缓LLMs中的幻觉

    Self-Alignment for Factuality: Mitigating Hallucinations in LLMs via Self-Evaluation

    [https://arxiv.org/abs/2402.09267](https://arxiv.org/abs/2402.09267)

    本研究探索了自动校准实事性的方法，通过利用大型语言模型的自我评估能力，引导模型向实事性靠近，并改善模型的置信估计和校准。

    

    尽管显示出越来越接近人类的能力，大型语言模型（LLMs）在事实准确性方面（即“幻觉”）往往存在困难，即使它们具有相关的知识。为了解决这些幻觉问题，目前的方法通常需要高质量的人工事实性注释。在这项工作中，我们探索了自动校准实事性，即利用LLM的自我评估能力提供训练信号，将模型引导向实事性。具体而言，我们将自我评估组件Self-Eval纳入到LLM中，以仅基于其内部知识验证其自己生成的回复的实事性。此外，我们设计了自我知识调整（SK-Tuning）以提高模型的自我评估能力，改善模型的置信估计和校准。然后，我们利用这些自我注释的回复通过直接优化偏好算法对模型进行微调。

    arXiv:2402.09267v1 Announce Type: cross Abstract: Despite showing increasingly human-like abilities, large language models (LLMs) often struggle with factual inaccuracies, i.e. "hallucinations", even when they hold relevant knowledge. To address these hallucinations, current approaches typically necessitate high-quality human factuality annotations. In this work, we explore Self-Alignment for Factuality, where we leverage the self-evaluation capability of an LLM to provide training signals that steer the model towards factuality. Specifically, we incorporate Self-Eval, a self-evaluation component, to prompt an LLM to validate the factuality of its own generated responses solely based on its internal knowledge. Additionally, we design Self-Knowledge Tuning (SK-Tuning) to augment the LLM's self-evaluation ability by improving the model's confidence estimation and calibration. We then utilize these self-annotated responses to fine-tune the model via Direct Preference Optimization algorith
    
[^32]: 机器学习在管理脂溶性生物毒素引起的预防性关闭中的应用

    Machine Learning in management of precautionary closures caused by lipophilic biotoxins

    [https://arxiv.org/abs/2402.09266](https://arxiv.org/abs/2402.09266)

    本研究提出了一个机器学习模型，可以预测脂溶性生物毒素引起的预防性关闭，为淡水蛤养殖行业提供了支持。

    

    淡水蛤养殖是最重要的水产养殖行业之一。主要的风险是有害藻类水华（HABs），对人类食用构成了风险。在加利西亚，西班牙是淡水蛤的主要生产国，生产区域的开闭是由监测计划控制的。除了因有毒物质超过法定门槛而导致的关闭外，在缺乏确认取样和存在风险因素的情况下，可能会实施预防性关闭。这些决策是由没有支持或正式化基于经验的专家来做出的。因此，本研究提出了一个能够支持应用预防性关闭的预测模型。通过实现97.34%的敏感性、91.83%的准确性和0.75的kappa指数等指标，kNN算法提供了最佳结果。这使得可以创建一个能力强大的系统。

    arXiv:2402.09266v1 Announce Type: new Abstract: Mussel farming is one of the most important aquaculture industries. The main risk to mussel farming is harmful algal blooms (HABs), which pose a risk to human consumption. In Galicia, the Spanish main producer of cultivated mussels, the opening and closing of the production areas is controlled by a monitoring program. In addition to the closures resulting from the presence of toxicity exceeding the legal threshold, in the absence of a confirmatory sampling and the existence of risk factors, precautionary closures may be applied. These decisions are made by experts without the support or formalisation of the experience on which they are based. Therefore, this work proposes a predictive model capable of supporting the application of precautionary closures. Achieving sensitivity, accuracy and kappa index values of 97.34%, 91.83% and 0.75 respectively, the kNN algorithm has provided the best results. This allows the creation of a system capab
    
[^33]: 数据图上首选子集修复的计算复杂性

    Computational Complexity of Preferred Subset Repairs on Data-Graphs

    [https://arxiv.org/abs/2402.09265](https://arxiv.org/abs/2402.09265)

    本论文研究了在图数据库上使用Reg-GXPath表达式作为完整性约束，计算包含数据值的优先修复问题，并提出了几种偏好准则。

    

    数据库理论和知识表示与推理领域一直以来都存在解决不一致知识库的问题，并且特别关注结构化数据的角度。然而，随着现实领域中可用数据变得更加复杂和互相关联，自然而然地需要开发新类型的存储库、表示语言和语义以实现更合适的查询和推理方式。图数据库提供了一种有效的方法来表示半结构化数据之间的关系，并且能够高效地处理和查询这些连接。在这项工作中，我们专注于使用基于Reg-GXPath表达式的一致性概念作为完整性约束，计算包含数据值的图数据库上的优先修复问题。我们提出了基于标准子集修复语义的几种偏好准则，包括权重和多样性。

    arXiv:2402.09265v1 Announce Type: cross Abstract: The problem of repairing inconsistent knowledge bases has a long history within the communities of database theory and knowledge representation and reasoning, especially from the perspective of structured data. However, as the data available in real-world domains becomes more complex and interconnected, the need naturally arises for developing new types of repositories, representation languages, and semantics, to allow for more suitable ways to query and reason about it. Graph databases provide an effective way to represent relationships among semi-structured data, and allow processing and querying these connections efficiently. In this work, we focus on the problem of computing prioritized repairs over graph databases with data values, using a notion of consistency based on Reg-GXPath expressions as integrity constraints. We present several preference criteria based on the standard subset repair semantics, incorporating weights, multis
    
[^34]: SyntaxShap：用于文本生成的语法感知可解释性方法

    SyntaxShap: Syntax-aware Explainability Method for Text Generation

    [https://arxiv.org/abs/2402.09259](https://arxiv.org/abs/2402.09259)

    本文介绍了一种局部的、与模型无关的用于文本生成的可解释性方法SyntaxShap，其通过考虑文本数据中的语法来扩展Shapley值以解释序列到序列任务。通过采用博弈论方法，SyntaxShap只考虑由依赖树约束的联盟，与其他最新的可解释性方法相比具有良好的性能。

    

    为了在安全关键领域中利用大型语言模型的潜力，我们需要确保其预测的可解释性。然而，尽管模型可解释性受到了重要关注，但仍有一个尚未探索的领域，即使用针对文本数据量身定制的方法解释序列到序列任务。本文介绍了SyntaxShap，一种局部的、与模型无关的用于文本生成的可解释性方法，它考虑了文本数据中的语法。所提出的方法将Shapley值扩展到考虑基于解析的句法依赖关系。采用博弈论方法，SyntaxShap只考虑由依赖树约束的联盟。我们采用基于模型的评估来比较SyntaxShap及其加权形式与针对文本生成任务的最新可解释性方法，使用包括忠实度、复杂度、连贯性和解释与语义一致性的多样化指标。

    arXiv:2402.09259v1 Announce Type: cross Abstract: To harness the power of large language models in safety-critical domains we need to ensure the explainability of their predictions. However, despite the significant attention to model interpretability, there remains an unexplored domain in explaining sequence-to-sequence tasks using methods tailored for textual data. This paper introduces SyntaxShap, a local, model-agnostic explainability method for text generation that takes into consideration the syntax in the text data. The presented work extends Shapley values to account for parsing-based syntactic dependencies. Taking a game theoric approach, SyntaxShap only considers coalitions constraint by the dependency tree. We adopt a model-based evaluation to compare SyntaxShap and its weighted form to state-of-the-art explainability methods adapted to text generation tasks, using diverse metrics including faithfulness, complexity, coherency, and semantic alignment of the explanations to the
    
[^35]: 材料的通用机器学习Kohn-Sham哈密顿量

    Universal Machine Learning Kohn-Sham Hamiltonian for Materials

    [https://arxiv.org/abs/2402.09251](https://arxiv.org/abs/2402.09251)

    本研究提出了一种通用的电子哈密顿量模型，通过使用来自Materials Project的第一性原理DFT计算的哈密顿矩阵进行训练，可以预测整个周期表中包括复杂多元素系统在内的电子结构。

    

    尽管密度泛函理论(DFT)在电子结构计算中是一种普遍的计算方法，但其计算需求和可扩展性限制仍然存在。最近，利用神经网络来参数化Kohn-Sham DFT哈密顿量已经成为加速电子结构计算的有希望的途径。尽管取得了进展，但仍然存在一些挑战，如为了探索新系统而需要计算大量的DFT训练数据和建立准确的多元素材料的ML模型的复杂性。针对这些障碍，本研究介绍了一种通过对来自Materials Project的第一性原理DFT计算的哈密顿矩阵进行训练的通用电子哈密顿量模型。我们证明了它在整个周期表中预测电子结构的普适性，包括复杂的多元素系统。

    arXiv:2402.09251v1 Announce Type: cross Abstract: While density functional theory (DFT) serves as a prevalent computational approach in electronic structure calculations, its computational demands and scalability limitations persist. Recently, leveraging neural networks to parameterize the Kohn-Sham DFT Hamiltonian has emerged as a promising avenue for accelerating electronic structure computations. Despite advancements, challenges such as the necessity for computing extensive DFT training data to explore new systems and the complexity of establishing accurate ML models for multi-elemental materials still exist. Addressing these hurdles, this study introduces a universal electronic Hamiltonian model trained on Hamiltonian matrices obtained from first-principles DFT calculations of nearly all crystal structures on the Materials Project. We demonstrate its generality in predicting electronic structures across the whole periodic table, including complex multi-elemental systems. By offerin
    
[^36]: 谁先行动？优化Stackelberg博弈中众多机器人的行动顺序

    Who Plays First? Optimizing the Order of Play in Stackelberg Games with Many Robots

    [https://arxiv.org/abs/2402.09246](https://arxiv.org/abs/2402.09246)

    本论文研究了在Stackelberg博弈中优化众多机器人的行动顺序的问题，并引入了一个高效准确的算法(B&P)来求解相关的优化问题和均衡。该算法具有广泛的实际应用。

    

    我们考虑计算多智能体空间导航问题的社会最优行动顺序的问题，即智能体决策顺序，以及与之相关的N人Stackelberg轨迹博弈的均衡。我们将这个问题建模为一个混合整数优化问题，涉及到所有可能的行动顺序的Stackelberg博弈空间。为了解决这个问题，我们引入了Branch and Play (B&P)，这是一个高效且准确的算法，可以收敛到社会最优行动顺序及其Stackelberg均衡。作为B&P的一个子例程，我们提出并扩展了顺序轨迹规划，即一种流行的多智能体控制方法，以便为任何给定的行动顺序可扩展地计算有效的本地Stackelberg均衡。我们证明了B&P在协调空中交通控制、群体形成和交付车队方面的实际效用。我们发现B&P的结果是一致的。

    arXiv:2402.09246v1 Announce Type: cross Abstract: We consider the multi-agent spatial navigation problem of computing the socially optimal order of play, i.e., the sequence in which the agents commit to their decisions, and its associated equilibrium in an N-player Stackelberg trajectory game. We model this problem as a mixed-integer optimization problem over the space of all possible Stackelberg games associated with the order of play's permutations. To solve the problem, we introduce Branch and Play (B&P), an efficient and exact algorithm that provably converges to a socially optimal order of play and its Stackelberg equilibrium. As a subroutine for B&P, we employ and extend sequential trajectory planning, i.e., a popular multi-agent control approach, to scalably compute valid local Stackelberg equilibria for any given order of play. We demonstrate the practical utility of B&P to coordinate air traffic control, swarm formation, and delivery vehicle fleets. We find that B&P consistent
    
[^37]: 学习可解释概念：统一因果表示学习与基础模型

    Learning Interpretable Concepts: Unifying Causal Representation Learning and Foundation Models

    [https://arxiv.org/abs/2402.09236](https://arxiv.org/abs/2402.09236)

    本研究将因果表示学习和基础模型相结合，研究了如何从数据中学习人类可解释的概念。实验证明了这一统一方法的实用性。

    

    构建智能机器学习系统有两种广泛的方法。一种方法是构建天生可解释的模型，这是因果表示学习领域的努力方向。另一种方法是构建高性能的基础模型，然后投入努力去理解它们的工作原理。本研究将这两种方法联系起来，研究如何从数据中学习人类可解释的概念。通过结合这两个领域的思想，我们正式定义了概念的概念，并展示了它们可以从多样的数据中被可靠地恢复出来。对于合成数据和大型语言模型的实验证明了我们统一方法的实用性。

    arXiv:2402.09236v1 Announce Type: cross Abstract: To build intelligent machine learning systems, there are two broad approaches. One approach is to build inherently interpretable models, as endeavored by the growing field of causal representation learning. The other approach is to build highly-performant foundation models and then invest efforts into understanding how they work. In this work, we relate these two approaches and study how to learn human-interpretable concepts from data. Weaving together ideas from both fields, we formally define a notion of concepts and show that they can be provably recovered from diverse data. Experiments on synthetic data and large language models show the utility of our unified approach.
    
[^38]: 设计和实现用于评估自主编队算法的基准测试平台

    Design and Realization of a Benchmarking Testbed for Evaluating Autonomous Platooning Algorithms

    [https://arxiv.org/abs/2402.09233](https://arxiv.org/abs/2402.09233)

    本文介绍了用于评估自主编队算法的测试平台。通过对三种算法的评估，我们发现分布式模型预测控制算法在硬件和仿真环境中的表现优于线性反馈算法。

    

    自动车辆编队提供了近期和长期的机会，可以提高运营效率并挽救生命。过去30年中，自动驾驶领域有了快速发展，使得新技术可以减轻对人类驾驶员的负担并降低车辆排放。本文介绍了一个可以评估和基准测试1/10比例车辆上的编队算法的测试平台，并使用自带传感器的车辆进行实现。为了展示测试平台的效益，我们评估了三种算法，包括线性反馈和两种分布式模型预测控制的变体，并在典型的编队场景中比较它们的结果，其中领先车辆跟踪多次变速的参考轨迹。我们在仿真环境中验证了算法的性能，分析了编队规模增加时的性能，并发现在硬件和仿真中，分布式模型预测控制算法优于线性反馈算法。

    arXiv:2402.09233v1 Announce Type: cross Abstract: Autonomous vehicle platoons present near- and long-term opportunities to enhance operational efficiencies and save lives. The past 30 years have seen rapid development in the autonomous driving space, enabling new technologies that will alleviate the strain placed on human drivers and reduce vehicle emissions. This paper introduces a testbed for evaluating and benchmarking platooning algorithms on 1/10th scale vehicles with onboard sensors. To demonstrate the testbed's utility, we evaluate three algorithms, linear feedback and two variations of distributed model predictive control, and compare their results on a typical platooning scenario where the lead vehicle tracks a reference trajectory that changes speed multiple times. We validate our algorithms in simulation to analyze the performance as the platoon size increases, and find that the distributed model predictive control algorithms outperform linear feedback on hardware and in sim
    
[^39]: 我的数据在你的AI模型中吗？通过应用于人脸图像的成员推断测试

    Is my Data in your AI Model? Membership Inference Test with Application to Face Images

    [https://arxiv.org/abs/2402.09225](https://arxiv.org/abs/2402.09225)

    This paper introduces a novel approach called Membership Inference Test (MINT) to empirically assess if specific data was used during the training of AI models. Two MINT architectures based on MLP and CNN are proposed and evaluated on a challenging face recognition task, achieving promising results with up to 90% accuracy.

    

    这篇论文介绍了成员推断测试（MINT），一种用于经验性评估特定数据是否被用于训练人工智能（AI）模型的新方法。具体而言，我们提出了两种新颖的MINT架构，旨在学习在经过审计的模型暴露于其训练过程中使用的数据时出现的不同激活模式。第一个架构基于多层感知机（MLP）网络，第二个基于卷积神经网络（CNN）。所提出的MINT架构在具有挑战性的人脸识别任务上进行评估，考虑了三种最先进的人脸识别模型。使用六个公开可用的数据库进行实验，总共包含超过2200万张人脸图像。根据可用的AI模型测试的上下文，考虑了不同的实验场景。有希望的结果达到了90%的准确率。

    arXiv:2402.09225v1 Announce Type: cross Abstract: This paper introduces the Membership Inference Test (MINT), a novel approach that aims to empirically assess if specific data was used during the training of Artificial Intelligence (AI) models. Specifically, we propose two novel MINT architectures designed to learn the distinct activation patterns that emerge when an audited model is exposed to data used during its training process. The first architecture is based on a Multilayer Perceptron (MLP) network and the second one is based on Convolutional Neural Networks (CNNs). The proposed MINT architectures are evaluated on a challenging face recognition task, considering three state-of-the-art face recognition models. Experiments are carried out using six publicly available databases, comprising over 22 million face images in total. Also, different experimental scenarios are considered depending on the context available of the AI model to test. Promising results, up to 90% accuracy, are a
    
[^40]: 频谱滤波器、暗信号和注意力陷阱

    Spectral Filters, Dark Signals, and Attention Sinks

    [https://arxiv.org/abs/2402.09221](https://arxiv.org/abs/2402.09221)

    这项研究通过定义频谱滤波器和注意力陷阱，揭示了将中间表示投影到词汇表的解释工具对于transformer-based LLMs的重要性，并发现了预训练模型中特定频谱区域的损失对于保持低损失是可行的。

    

    arXiv:2402.09221v1 公告类型：新的 摘要：将中间表示投影到词汇表上是一种越来越流行的转换器型LLM的解释工具，也称为logit lens。我们对这种方法进行了定量扩展，并基于将词汇嵌入和解嵌矩阵的奇异向量分成波段来定义中间表示的频谱滤波器。我们发现，在频谱的尾部交换的信号负责注意力陷阱（Xiao et al. 2023），我们对此进行了解释。我们发现，尽管以层为基础抑制了嵌入频谱的相当大部分，但预训练模型的损失仍然可以保持较低，只要保持注意力陷阱即可。最后，我们发现在吸引多个令牌注意力的令牌表示在频谱的尾部具有较大的投影。

    arXiv:2402.09221v1 Announce Type: new Abstract: Projecting intermediate representations onto the vocabulary is an increasingly popular interpretation tool for transformer-based LLMs, also known as the logit lens. We propose a quantitative extension to this approach and define spectral filters on intermediate representations based on partitioning the singular vectors of the vocabulary embedding and unembedding matrices into bands. We find that the signals exchanged in the tail end of the spectrum are responsible for attention sinking (Xiao et al. 2023), of which we provide an explanation. We find that the loss of pretrained models can be kept low despite suppressing sizable parts of the embedding spectrum in a layer-dependent way, as long as attention sinking is preserved. Finally, we discover that the representation of tokens that draw attention from many tokens have large projections on the tail end of the spectrum.
    
[^41]: DivaTrack: 利用加速度增强的三点跟踪器实现多样化的身体和动作

    DivaTrack: Diverse Bodies and Motions from Acceleration-Enhanced Three-Point Trackers

    [https://arxiv.org/abs/2402.09211](https://arxiv.org/abs/2402.09211)

    DivaTrack是一个基于深度学习的框架，可以在多样化的身体尺寸和活动情况下优于现有方法，通过加入线性加速度从IMU提供更准确的脚部接触预测，并使用两阶段模型来提高对全身姿势的预测稳定性。

    

    arXiv:2402.09211v1 公告类型: 跨领域 摘要: 全身仿真是数字现实中沉浸式社交和环境交互的关键。然而，当前的设备只能提供来自头盔和两个控制器（即三点跟踪器）的六个自由度（DOF）姿势。由于这是一个高度欠约束的问题，从这些输入中推断出全身姿势是具有挑战性的，特别是当支持普通人群所代表的各种身体比例和使用情况时。在本文中，我们提出了一个名为DivaTrack的深度学习框架，在应用于多样化的身体尺寸和活动时，优于现有的方法。我们利用惯性测量单元（IMU）的线性加速度增强了稀疏的三点输入，以改善脚部接触的预测。然后，我们使用两阶段模型将低身体姿势的模糊性条件化为脚部接触和上身姿势的预测。我们进一步稳定推断出的全身姿势。

    arXiv:2402.09211v1 Announce Type: cross Abstract: Full-body avatar presence is crucial for immersive social and environmental interactions in digital reality. However, current devices only provide three six degrees of freedom (DOF) poses from the headset and two controllers (i.e. three-point trackers). Because it is a highly under-constrained problem, inferring full-body pose from these inputs is challenging, especially when supporting the full range of body proportions and use cases represented by the general population. In this paper, we propose a deep learning framework, DivaTrack, which outperforms existing methods when applied to diverse body sizes and activities. We augment the sparse three-point inputs with linear accelerations from Inertial Measurement Units (IMU) to improve foot contact prediction. We then condition the otherwise ambiguous lower-body pose with the predictions of foot contact and upper-body pose in a two-stage model. We further stabilize the inferred full-body 
    
[^42]: 告诉我更多！面向基于语言模型的智能代理的隐式用户意图理解

    Tell Me More! Towards Implicit User Intention Understanding of Language Model Driven Agents

    [https://arxiv.org/abs/2402.09205](https://arxiv.org/abs/2402.09205)

    该论文提出了一种面向基于语言模型的智能代理的隐式用户意图理解的方法。通过引入Intention-in-Interaction (IN3) 基准和在代理设计中融入模型专家，使得代理能够更好地与用户进行交互，并提升对用户指令的理解能力。

    

    当前的语言模型驱动代理常常缺乏有效的用户参与机制，考虑到用户指令中常见的模糊性，这是至关重要的。虽然这些代理在制定策略和执行任务方面表现出色，但在寻求澄清和抓住精确的用户意图方面却遇到了困难。为了填补这一差距，我们引入了Intention-in-Interaction (IN3) ，这是一个旨在通过明确的查询检查用户的隐含意图的新颖基准。接下来，我们提出将模型专家作为上游融入代理设计中，以增强用户-代理交互。利用IN3，我们经验性地训练了Mistral-Interact，这是一个强大的模型，它可以主动评估任务的模糊性，询问用户意图，并将其转化为可行的目标，然后开始下游代理任务执行。将其集成到XAgent框架中，我们对增强的代理系统进行了全面评估，以评估用户指令的理解能力。

    arXiv:2402.09205v1 Announce Type: cross Abstract: Current language model-driven agents often lack mechanisms for effective user participation, which is crucial given the vagueness commonly found in user instructions. Although adept at devising strategies and performing tasks, these agents struggle with seeking clarification and grasping precise user intentions. To bridge this gap, we introduce Intention-in-Interaction (IN3), a novel benchmark designed to inspect users' implicit intentions through explicit queries. Next, we propose the incorporation of model experts as the upstream in agent designs to enhance user-agent interaction. Employing IN3, we empirically train Mistral-Interact, a powerful model that proactively assesses task vagueness, inquires user intentions, and refines them into actionable goals before starting downstream agent task execution. Integrating it into the XAgent framework, we comprehensively evaluate the enhanced agent system regarding user instruction understand
    
[^43]: 使用强化学习在Tor和公共网络上发现指挥与控制（C2）通道

    Discovering Command and Control (C2) Channels on Tor and Public Networks Using Reinforcement Learning

    [https://arxiv.org/abs/2402.09200](https://arxiv.org/abs/2402.09200)

    本文使用强化学习方法在Tor和公共网络上自动发现具有韧性的指挥与控制（C2）通道，从而帮助识别和防止网络攻击。

    

    指挥与控制（C2）通道是许多类型的网络攻击的必要组成部分，它们使攻击者能够远程控制被恶意软件感染的计算机，并执行有害的行动，如在网络中传播恶意代码、窃取机密数据或发起分布式拒绝服务（DDoS）攻击。因此，识别这些C2通道对于减轻和防止网络攻击至关重要。然而，识别C2通道通常涉及手动过程，需要深入了解和专业技术的网络操作知识。在本文中，我们提出了一种基于强化学习的方法，通过同时使用正常（公共）网络和Tor网络来自动模拟C2攻击活动。此外，配置有效载荷大小和网络防火墙以模拟真实的攻击场景。在典型网络配置上的结果显示，强化学习代理可以自动发现具有韧性的C2通道。

    arXiv:2402.09200v1 Announce Type: cross Abstract: Command and control (C2) channels are an essential component of many types of cyber attacks, as they enable attackers to remotely control their malware-infected machines and execute harmful actions, such as propagating malicious code across networks, exfiltrating confidential data, or initiating distributed denial of service (DDoS) attacks. Identifying these C2 channels is therefore crucial in helping to mitigate and prevent cyber attacks. However, identifying C2 channels typically involves a manual process, requiring deep knowledge and expertise in cyber operations. In this paper, we propose a reinforcement learning (RL) based approach to automatically emulate C2 attack campaigns using both the normal (public) and the Tor networks. In addition, payload size and network firewalls are configured to simulate real-world attack scenarios. Results on a typical network configuration show that the RL agent can automatically discover resilient 
    
[^44]: 十个关键词仍然有用：通过代理引导的高效重采样改进黑盒AI生成文本检测

    Ten Words Only Still Help: Improving Black-Box AI-Generated Text Detection via Proxy-Guided Efficient Re-Sampling

    [https://arxiv.org/abs/2402.09199](https://arxiv.org/abs/2402.09199)

    本文提出了一种利用代理引导的高效重采样方法来改进黑盒AI生成文本检测。通过估计单词生成概率作为伪白盒特征，选择少量代表性词汇进行多次重采样，在包含人类文本和LLM生成文本的数据集上进行了实验，取得了出色的结果。

    

    随着大型语言模型（LLM）的应用日益增多，它们的滥用引发了许多不受欢迎的社会问题，如假新闻、学术不诚实和信息污染。这使得AI生成文本（AIGT）的检测非常重要。在现有方法中，白盒方法在性能和泛化性方面通常优于黑盒方法，但它们需要访问LLM的内部状态，不适用于黑盒设置。本文提出了一种通过多次重采样来估计单词生成概率作为伪白盒特征以帮助改进黑盒AIGT检测的方法。具体而言，我们设计了POGER，一种代理引导的高效重采样方法，在黑盒AIGT检测中选择一个小的代表性词汇子集（例如10个词），进行多次重采样。实验证明，这种方法在包含人类文本和七个LLM生成文本的数据集上表现出色。

    arXiv:2402.09199v1 Announce Type: cross Abstract: With the rapidly increasing application of large language models (LLMs), their abuse has caused many undesirable societal problems such as fake news, academic dishonesty, and information pollution. This makes AI-generated text (AIGT) detection of great importance. Among existing methods, white-box methods are generally superior to black-box methods in terms of performance and generalizability, but they require access to LLMs' internal states and are not applicable to black-box settings. In this paper, we propose to estimate word generation probabilities as pseudo white-box features via multiple re-sampling to help improve AIGT detection under the black-box setting. Specifically, we design POGER, a proxy-guided efficient re-sampling method, which selects a small subset of representative words (e.g., 10 words) for performing multiple re-sampling in black-box AIGT detection. Experiments on datasets containing texts from humans and seven LL
    
[^45]: (不)理性与大型语言模型中的认知偏差

    (Ir)rationality and Cognitive Biases in Large Language Models

    [https://arxiv.org/abs/2402.09193](https://arxiv.org/abs/2402.09193)

    本研究评估了七个大型语言模型在认知心理学任务中的表现，发现它们与人类一样存在非理性，但展示的非理性方式与人类偏见不同，同时还表现出了显著的回答不一致性。

    

    大型语言模型(LLMs)是否展现出理性推理？由于其训练数据所含的人类偏见，LLMs已被证实存在人类偏见；然而，其是否反映出了理性推理还不太清楚。本文通过评估七个语言模型在来自认知心理学文献的任务中回答了这个问题。我们发现，和人类一样，LLMs在这些任务中展现出了非理性。然而，LLMs展现出的这种非理性与人类的偏见不同。当LLMs给出错误答案时，它们通常会以与人类偏见不同的方式错误。除此之外，LLMs还展现出了响应的显著不一致性，这表明了额外的非理性层面。除了实验结果，本文还通过展示如何评估和比较这类模型的不同功能，对方法论作出了贡献。

    arXiv:2402.09193v1 Announce Type: cross Abstract: Do large language models (LLMs) display rational reasoning? LLMs have been shown to contain human biases due to the data they have been trained on; whether this is reflected in rational reasoning remains less clear. In this paper, we answer this question by evaluating seven language models using tasks from the cognitive psychology literature. We find that, like humans, LLMs display irrationality in these tasks. However, the way this irrationality is displayed does not reflect that shown by humans. When incorrect answers are given by LLMs to these tasks, they are often incorrect in ways that differ from human-like biases. On top of this, the LLMs reveal an additional layer of irrationality in the significant inconsistency of the responses. Aside from the experimental results, this paper seeks to make a methodological contribution by showing how we can assess and compare different capabilities of these types of models, in this case with r
    
[^46]: 借助多轮交互利用上下文进行越狱攻击

    Leveraging the Context through Multi-Round Interactions for Jailbreaking Attacks

    [https://arxiv.org/abs/2402.09177](https://arxiv.org/abs/2402.09177)

    本研究提出了一种新的攻击形式——上下文交互攻击，通过交互式与大型语言模型（LLMs）进行问答来引出有害信息。实验结果表明该方法的有效性。

    

    大型语言模型（LLMs）容易受到越狱攻击的影响，越狱攻击通过微妙地修改攻击查询来提取有害信息。随着防御机制的进化，越狱攻击直接获取有害信息变得越来越具有挑战性。本研究受到人类间接引出有害信息的实践启发，针对一种新的攻击形式——上下文交互攻击。该方法依赖于LLMs生成过程中的自回归性质。我们认为先前的上下文——攻击查询之前的信息在实现强大的越狱攻击方面起着关键作用。具体而言，我们提出了一种利用初步问答对与LLMs交互的方法。通过这样做，我们引导模型的回答朝着揭示“期望的”有害信息的方向发展。我们在四种不同的LLMs上进行了实验证明了方法的有效性。

    arXiv:2402.09177v1 Announce Type: cross Abstract: Large Language Models (LLMs) are susceptible to Jailbreaking attacks, which aim to extract harmful information by subtly modifying the attack query. As defense mechanisms evolve, directly obtaining harmful information becomes increasingly challenging for Jailbreaking attacks. In this work, inspired by human practices of indirect context to elicit harmful information, we focus on a new attack form called Contextual Interaction Attack. The idea relies on the autoregressive nature of the generation process in LLMs. We contend that the prior context--the information preceding the attack query--plays a pivotal role in enabling potent Jailbreaking attacks. Specifically, we propose an approach that leverages preliminary question-answer pairs to interact with the LLM. By doing so, we guide the responses of the model toward revealing the 'desired' harmful information. We conduct experiments on four different LLMs and demonstrate the efficacy of 
    
[^47]: 使用ChatGPT进行角色扮演模拟游戏

    Role-Playing Simulation Games using ChatGPT

    [https://arxiv.org/abs/2402.09161](https://arxiv.org/abs/2402.09161)

    本文展示了如何通过使用ChatGPT在角色扮演模拟游戏中提升教学质量，并提高学生对学习的兴趣。

    

    自从COVID-19大流行以来，教育机构开始进行数字化转型项目。这些项目的成功取决于整合新技术和理解数字素养学生的需求。"以做学习"的方法认为，当学生可以尝试和实践这些技能时，才能真正成功地学习新技能。在本文中，我们演示了如何通过在角色扮演模拟游戏场景中使用ChatGPT来增强教学质量的大型语言模型（LLM）以促进主动学习。此外，我们讨论了如何通过使用ChatGPT让学生实践真实场景来提高学生对学习的兴趣。

    arXiv:2402.09161v1 Announce Type: new Abstract: Since the COVID-19 pandemic, educational institutions have embarked on digital transformation projects. The success of these projects depends on integrating new technologies and understanding the needs of digitally literate students. The "learning by doing" approach suggests that real success in learning new skills is achieved when students can try out and practise these skills. In this article, we demonstrate how Large Language Models (LLMs) can enhance the quality of teaching by using ChatGPT in a role-playing simulation game scenario to promote active learning. Moreover, we discuss how LLMs can boost students' interest in learning by allowing them to practice real-life scenarios using ChatGPT.
    
[^48]: 未知之中：自学习大型语言模型

    Into the Unknown: Self-Learning Large Language Models

    [https://arxiv.org/abs/2402.09147](https://arxiv.org/abs/2402.09147)

    本研究关注自学习大型语言模型的核心问题：如何学习未知知识。提出了一种自学习框架，通过自我评估和识别未知点来独立学习以前未知的知识。实验证明该方法对于减少幻觉评分、实现高效LLM更新以及知识交流具有重要意义。

    

    我们解决了自学习大型语言模型（LLM）的主要问题：即如何学习自己不知道的知识。我们提出了一种自学习LLM框架，通过对自己的幻觉进行自我评估，使LLM能够独立地学习以前未知的知识。通过使用幻觉评分，我们引入了一个称为“未知点”的新概念，并提出了一种外部和三种内部方法来自动识别未知点。这有助于创建一个自学习循环，专注于未知点中的知识差距，从而减少幻觉评分。我们还开发了用于评估LLM自学习能力的评估指标。我们的实验证明，已经进行了微调或对齐的7B-Mistral模型在自学习方面表现出色。我们的自学习概念可以实现更高效的LLM更新，并为知识交流开辟新的可能性。它还可能增加公众的信任。

    arXiv:2402.09147v1 Announce Type: new Abstract: We address the main problem of self-learning LLM: the question of what to learn. We propose a self-learning LLM framework that enables an LLM to independently learn previously unknown knowledge through self-assessment of their own hallucinations. Using the hallucination score, we introduce a new concept of Points in The Unknown (PiUs), along with one extrinsic and three intrinsic methods for automatic PiUs identification. It facilitates the creation of a self-learning loop that focuses exclusively on the knowledge gap in Points in The Unknown, resulting in a reduced hallucination score. We also developed evaluation metrics for gauging an LLM's self-learning capability. Our experiments revealed that 7B-Mistral models that have been finetuned or aligned are capable of self-learning considerably well. Our self-learning concept allows more efficient LLM updates and opens new perspectives for knowledge exchange. It may also increase public tru
    
[^49]: 通过战略文本增强推进自然语言处理模型的研究：增强方法和课程策略的全面研究

    Advancing NLP Models with Strategic Text Augmentation: A Comprehensive Study of Augmentation Methods and Curriculum Strategies

    [https://arxiv.org/abs/2402.09141](https://arxiv.org/abs/2402.09141)

    本研究通过对多个数据集和NLP任务的全面评估，证明了特定的文本增强方法与改进的循环课程学习（MCCL）相结合时能够显著优于传统的训练方法，在NLP模型性能上取得了重要突破。

    

    本研究对多个数据集和自然语言处理（NLP）任务中的文本增强技术进行了全面评估，以解决这些方法缺乏可靠、普遍证据的问题。它考察了这些技术在增强训练集以提高主题分类、情感分析和冒犯语言检测等任务性能方面的有效性。研究不仅强调了增强方法，还强调了在训练过程中引入真实和增强实例的战略顺序。研究的一个重要贡献是为增强数据集开发和评估了改进的循环课程学习（MCCL），这在该领域中属于一种新颖方法。结果表明，特定的增强方法，尤其是与MCCL结合使用时，能够显著优于传统的训练方法在NLP模型性能上的表现。这些结果强调了对可靠的增强方法和战略顺序的需求。

    arXiv:2402.09141v1 Announce Type: cross Abstract: This study conducts a thorough evaluation of text augmentation techniques across a variety of datasets and natural language processing (NLP) tasks to address the lack of reliable, generalized evidence for these methods. It examines the effectiveness of these techniques in augmenting training sets to improve performance in tasks such as topic classification, sentiment analysis, and offensive language detection. The research emphasizes not only the augmentation methods, but also the strategic order in which real and augmented instances are introduced during training. A major contribution is the development and evaluation of Modified Cyclical Curriculum Learning (MCCL) for augmented datasets, which represents a novel approach in the field. Results show that specific augmentation methods, especially when integrated with MCCL, significantly outperform traditional training approaches in NLP model performance. These results underscore the need
    
[^50]: DolphCoder: 用多样化和多目标指导调整进行回声定位的代码大型语言模型

    DolphCoder: Echo-Locating Code Large Language Models with Diverse and Multi-Objective Instruction Tuning

    [https://arxiv.org/abs/2402.09136](https://arxiv.org/abs/2402.09136)

    DolphCoder通过多样化的指导和自我评估提高了代码大型语言模型的生成能力，并在HumanEval和MBPP基准测试中取得了优异的性能。

    

    Code Large Language Models (Code LLMs)在代码相关任务中表现出色。已经提出了几种指导调整方法，以提高预训练Code LLM的代码生成性能。在本文中，我们引入了一种具有自我评估的多样化指令模型（DolphCoder）用于代码生成。它学习多样化的指令目标，并结合代码评估目标来增强其代码生成能力。我们的模型在HumanEval和MBPP基准测试中取得了优异的性能，为未来的代码指令调整工作提供了新的见解。我们的主要发现是：（1）通过增加具有不同推理路径的多样化响应来增强LLMs的代码能力。 （2）提高评估代码解决方案正确性的能力也会增强其创造代码的能力。

    arXiv:2402.09136v1 Announce Type: cross Abstract: Code Large Language Models (Code LLMs) have demonstrated outstanding performance in code-related tasks. Several instruction tuning approaches have been proposed to boost the code generation performance of pre-trained Code LLMs. In this paper, we introduce a diverse instruction model (DolphCoder) with self-evaluating for code generation. It learns diverse instruction targets and combines a code evaluation objective to enhance its code generation ability. Our model achieves superior performance on the HumanEval and MBPP benchmarks, demonstrating new insights for future code instruction tuning work. Our key findings are: (1) Augmenting more diverse responses with distinct reasoning paths increases the code capability of LLMs. (2) Improving one's ability to evaluate the correctness of code solutions also enhances their ability to create it.
    
[^51]: 探索大型语言模型的对抗能力

    Exploring the Adversarial Capabilities of Large Language Models

    [https://arxiv.org/abs/2402.09132](https://arxiv.org/abs/2402.09132)

    本研究探索了大型语言模型的对抗能力，并发现其能够成功地制造对抗性示例以愚弄安全措施，特别是在仇恨言论检测方面具有重大影响。

    

    大型语言模型（LLMs）的普及引发了广泛和普遍的兴趣，因为它们具有强大的语言生成能力，为行业和研究提供了巨大的潜力。尽管以前的研究探讨了LLMs的安全性和隐私问题，但这些模型能否表现出对抗行为的程度仍然尚未完全探索。为了填补这一空白，我们研究常见的公开可用LLMs是否具有能力扰乱文本样本以愚弄安全措施，即所谓的对抗示例或攻击。更具体地说，我们调查LLMs是否本质上能够从良性样本中制造对抗性示例以愚弄现有的安全防线。我们的实验重点关注仇恨言论检测，发现LLMs成功地找到了对抗性扰动，有效地破坏了对仇恨言论检测系统的防御。我们的发现对（半）自动化安全评估和防御具有重要影响。

    arXiv:2402.09132v1 Announce Type: new Abstract: The proliferation of large language models (LLMs) has sparked widespread and general interest due to their strong language generation capabilities, offering great potential for both industry and research. While previous research delved into the security and privacy issues of LLMs, the extent to which these models can exhibit adversarial behavior remains largely unexplored. Addressing this gap, we investigate whether common publicly available LLMs have inherent capabilities to perturb text samples to fool safety measures, so-called adversarial examples resp.~attacks. More specifically, we investigate whether LLMs are inherently able to craft adversarial examples out of benign samples to fool existing safe rails. Our experiments, which focus on hate speech detection, reveal that LLMs succeed in finding adversarial perturbations, effectively undermining hate speech detection systems. Our findings carry significant implications for (semi-)aut
    
[^52]: 最优自动做市商: 可微经济学和强对偶性

    Optimal Automated Market Makers: Differentiable Economics and Strong Duality

    [https://arxiv.org/abs/2402.09129](https://arxiv.org/abs/2402.09129)

    本文研究了在多商品市场中，包括复杂捆绑行为的情况下，找到最优的自动做市商的问题，发现该问题对偶于一个最优运输问题，并且具有特定的几何约束条件。

    

    做市商的作用是同时以指定价格购买和出售商品数量，通常是金融资产如股票。自动做市商（AMM）是一种根据预定的时间表提供交易的机制；选择最佳的时间表取决于做市商的目标。现有研究主要集中在预测市场上，目的是信息收集。近期的工作则主要关注利润最大化的目标，但仅仅考虑了一种类型的商品（用衡量货币进行交易），包括逆向选择的情况。关于存在多种商品以及可能出现复杂捆绑行为的最优做市问题尚不清楚。本文表明，在多个商品存在且可能出现复杂捆绑行为的情况下，找到一个最优的做市商是一个对偶于最优运输问题的问题，并且具有特定的几何约束条件。

    arXiv:2402.09129v1 Announce Type: cross Abstract: The role of a market maker is to simultaneously offer to buy and sell quantities of goods, often a financial asset such as a share, at specified prices. An automated market maker (AMM) is a mechanism that offers to trade according to some predetermined schedule; the best choice of this schedule depends on the market maker's goals. The literature on the design of AMMs has mainly focused on prediction markets with the goal of information elicitation. More recent work motivated by DeFi has focused instead on the goal of profit maximization, but considering only a single type of good (traded with a numeraire), including under adverse selection (Milionis et al. 2022). Optimal market making in the presence of multiple goods, including the possibility of complex bundling behavior, is not well understood. In this paper, we show that finding an optimal market maker is dual to an optimal transport problem, with specific geometric constraints on t
    
[^53]: MPIrigen: 通过领域特定语言模型生成MPI代码

    MPIrigen: MPI Code Generation through Domain-Specific Language Models

    [https://arxiv.org/abs/2402.09126](https://arxiv.org/abs/2402.09126)

    本文研究了使用领域特定语言模型生成MPI代码的性能，并提出了使用预训练模型MonoCoder进行MPI-based程序生成的方法。

    

    在大规模并行计算中，高效的并行计算尤为重要，特别是在消息传递接口（MPI）集成领域。生成基于MPI的并行程序是一个具有挑战性的并行编程任务，尚未被探索。本研究首先探讨了先进的语言模型在生成基于MPI的并行程序方面的性能。发现广泛使用的模型，如GPT-3.5和PolyCoder（专门的多语言代码模型），在生成基于MPI的程序时表现出明显的性能下降，相比通用程序。相比之下，基于MPI相关编程语言C和C++预训练的领域特定模型MonoCoder的性能更好。随后，我们通过在HPCorpusMPI上对MonoCoder进行微调，引入了一个专门的MPI-based程序生成任务。

    arXiv:2402.09126v1 Announce Type: cross Abstract: The imperative need to scale computation across numerous nodes highlights the significance of efficient parallel computing, particularly in the realm of Message Passing Interface (MPI) integration. The challenging parallel programming task of generating MPI-based parallel programs has remained unexplored. This study first investigates the performance of state-of-the-art language models in generating MPI-based parallel programs. Findings reveal that widely used models such as GPT-3.5 and PolyCoder (specialized multi-lingual code models) exhibit notable performance degradation, when generating MPI-based programs compared to general-purpose programs. In contrast, domain-specific models such as MonoCoder, which are pretrained on MPI-related programming languages of C and C++, outperform larger models. Subsequently, we introduce a dedicated downstream task of MPI-based program generation by fine-tuning MonoCoder on HPCorpusMPI. We call the r
    
[^54]: 随机尖峰关注：在尖峰网络中利用随机计算加速关注机制

    Stochastic Spiking Attention: Accelerating Attention with Stochastic Computing in Spiking Networks

    [https://arxiv.org/abs/2402.09109](https://arxiv.org/abs/2402.09109)

    本文提出了一种利用随机计算加速尖峰网络中的关注机制的新框架，证明该方法在CIFAR-10上能够达到高分类准确率，同时大大降低了计算能量和内存访问成本。

    

    最近，由于尖峰神经网络（SNN）在减少计算需求和提高功耗效率方面的潜力，已将其整合到Transformer体系结构中。然而，使用尖峰信号在通用计算平台上实现关注机制仍然低效。在本文中，我们提出了一种利用随机计算（SC）来有效执行基于SNN的Transformer的点积注意力的新框架。我们证明，我们的方法能够在10个时间步内在CIFAR-10上达到高分类准确率（83.53%），这与基线人工神经网络实现的性能（83.66%）相当。我们估计，该SC方法可以导致CMOS数字ASIC设计中计算能量减少6.3倍，内存访问成本减少1.7倍。我们通过实验证实了我们的随机注意力块设计。

    arXiv:2402.09109v1 Announce Type: cross Abstract: Spiking Neural Networks (SNNs) have been recently integrated into Transformer architectures due to their potential to reduce computational demands and to improve power efficiency. Yet, the implementation of the attention mechanism using spiking signals on general-purpose computing platforms remains inefficient. In this paper, we propose a novel framework leveraging stochastic computing (SC) to effectively execute the dot-product attention for SNN-based Transformers. We demonstrate that our approach can achieve high classification accuracy ($83.53\%$) on CIFAR-10 within 10 time steps, which is comparable to the performance of a baseline artificial neural network implementation ($83.66\%$). We estimate that the proposed SC approach can lead to over $6.3\times$ reduction in computing energy and $1.7\times$ reduction in memory access costs for a digital CMOS-based ASIC design. We experimentally validate our stochastic attention block design
    
[^55]: 通过多重分形分析视角探索LLMs中的神经元相互作用和出现现象

    Exploring Neuron Interactions and Emergence in LLMs: From the Multifractal Analysis Perspective

    [https://arxiv.org/abs/2402.09099](https://arxiv.org/abs/2402.09099)

    该论文通过多重分形分析视角，深入研究了LLMs中神经元相互作用和出现现象。通过引入自组织和多重分形分析的概念，研究了神经元相互作用的动态演化过程，尤其关注训练中的复杂行为。通过提出基于神经元的多重分形分析方法，实现了对大型模型中神经元相互作用的定量分析。

    

    在以往的大型模型中，关于出现现象的研究主要集中在大型语言模型（LLMs）的功能能力如何随模型规模的扩大而增加。然而，我们的研究超越了这一传统范式，旨在通过不仅仅依赖于模型规模，而更加关注训练过程中神经元相互作用的复杂行为，加深我们对LLMs内部出现现象的理解。通过引入“自组织”和“多重分形分析”概念，我们探索了神经元相互作用在训练过程中如何动态演化，从而导致“出现现象”，这种现象反映了自然系统中简单的微观相互作用如何导致复杂的宏观行为。为了定量分析训练过程中大型模型中神经元之间不断演化的相互作用，我们提出了基于神经元的多重分形分析（NeuroMFA）。利用NeuroMFA，我们进行了一系列的实验

    arXiv:2402.09099v1 Announce Type: new Abstract: Prior studies on the emergence in large models have primarily focused on how the functional capabilities of large language models (LLMs) scale with model size. Our research, however, transcends this traditional paradigm, aiming to deepen our understanding of the emergence within LLMs by placing a special emphasis not just on the model size but more significantly on the complex behavior of neuron interactions during the training process. By introducing the concepts of "self-organization" and "multifractal analysis," we explore how neuron interactions dynamically evolve during training, leading to "emergence," mirroring the phenomenon in natural systems where simple micro-level interactions give rise to complex macro-level behaviors. To quantitatively analyze the continuously evolving interactions among neurons in large models during training, we propose the Neuron-based Multifractal Analysis (NeuroMFA). Utilizing NeuroMFA, we conduct a com
    
[^56]: 一个用于学习使能的自动驾驶车辆交通标志识别的数字孪生原型

    A Digital Twin prototype for traffic sign recognition of a learning-enabled autonomous vehicle

    [https://arxiv.org/abs/2402.09097](https://arxiv.org/abs/2402.09097)

    本文介绍了一个用于学习使能的自动驾驶车辆的新型数字孪生原型，其主要目标是进行交通标志识别和车道保持。

    

    本文介绍了一个用于学习使能的自动驾驶车辆的新型数字孪生原型。该数字孪生的主要目标是进行交通标志识别和车道保持。数字孪生架构基于共模仿和使用了Functional Mock-up Interface和SystemC Transaction Level Modeling标准。数字孪生包括四个客户端，i) 在Amesim工具中设计的车辆模型，ii) 在Prescan中开发的环境模型，iii) 在机器人操作系统中设计的车道保持控制器，以及iv) 在BIP (行为，交互，优先级)形式建模语言中开发的感知和速度控制模块。这些客户端与数字孪生平台PAVE360-VSI进行接口连接。PAVE360-VSI作为共模仿协调器，负责通过服务器进行同步、互联和数据交换。

    arXiv:2402.09097v1 Announce Type: cross Abstract: In this paper, we present a novel digital twin prototype for a learning-enabled self-driving vehicle. The primary objective of this digital twin is to perform traffic sign recognition and lane keeping. The digital twin architecture relies on co-simulation and uses the Functional Mock-up Interface and SystemC Transaction Level Modeling standards. The digital twin consists of four clients, i) a vehicle model that is designed in Amesim tool, ii) an environment model developed in Prescan, iii) a lane-keeping controller designed in Robot Operating System, and iv) a perception and speed control module developed in the formal modeling language of BIP (Behavior, Interaction, Priority). These clients interface with the digital twin platform, PAVE360-Veloce System Interconnect (PAVE360-VSI). PAVE360-VSI acts as the co-simulation orchestrator and is responsible for synchronization, interconnection, and data exchange through a server. The server es
    
[^57]: 与LLM玩猜谜游戏: 通过隐含提示的间接越狱攻击

    Play Guessing Game with LLM: Indirect Jailbreak Attack with Implicit Clues

    [https://arxiv.org/abs/2402.09091](https://arxiv.org/abs/2402.09091)

    通过提供隐含的线索，Puzzler通过绕过LLM的防御策略，在间接方式下实现了越狱攻击，成功率高达96.6%。

    

    随着LLM的发展，LLM的安全威胁越来越受到关注。许多越狱攻击已经提出来评估LLM的安全防御。目前的越狱攻击主要使用场景伪装技术。然而，它们对恶意意图的明确提及很容易被LLM识别和防御。在本文中，我们提出了一种间接越狱攻击方法，名为Puzzler，它可以通过隐含地为LLM提供一些有关原始恶意查询的提示来绕过LLM的防御策略并获取恶意响应。此外，受孙子的《孙子兵法》中“当攻无法攻，守”智慧的启发，我们采取了一种防御姿态来通过LLM收集关于原始恶意查询的线索。大量的实验结果表明，Puzzler在闭源LLM上的查询成功率为96.6%，比基准线高57.9%-82.7%。

    arXiv:2402.09091v1 Announce Type: cross Abstract: With the development of LLMs, the security threats of LLMs are getting more and more attention. Numerous jailbreak attacks have been proposed to assess the security defense of LLMs. Current jailbreak attacks primarily utilize scenario camouflage techniques. However their explicitly mention of malicious intent will be easily recognized and defended by LLMs. In this paper, we propose an indirect jailbreak attack approach, Puzzler, which can bypass the LLM's defense strategy and obtain malicious response by implicitly providing LLMs with some clues about the original malicious query. In addition, inspired by the wisdom of ''When unable to attack, defend'' from Sun Tzu's Art of War, we adopt a defensive stance to gather clues about the original malicious query through LLMs. Extensive experimental results show that Puzzler achieves a query success rate of 96.6% on closed-source LLMs, which is 57.9%-82.7% higher than baselines. Furthermore, w
    
[^58]: 可计算概率电路的多项式语义

    Polynomial Semantics of Tractable Probabilistic Circuits

    [https://arxiv.org/abs/2402.09085](https://arxiv.org/abs/2402.09085)

    本文证明了对于二进制分布，可计算概率电路模型在某种意义上是等价的，即其中任何一个的电路都可以转化为任何其他模型的电路，只需多项式级别的增加大小。它们是可计算的边际推断模型。

    

    概率电路计算代表概率分布的多线性多项式。它们是可计算的模型，能够支持高效的边际推断。然而，在文献中已经考虑了多种多项式语义（例如，网络多项式、似然多项式、生成函数、傅里叶变换和特征多项式）。这些分布的多项式编码之间的关系大部分是未知的。在本文中，我们证明对于二进制分布，这些概率电路模型在某种意义上是等价的，即其中任何一个的电路都可以转化为任何其他模型的电路，只需多项式级别的增加大小。因此，它们在相同类别的分布上都是可计算的边际推断。最后，我们探索了一种名为概率生成电路的多项式语义的自然推广，以适用于分类随机变量。

    arXiv:2402.09085v1 Announce Type: new Abstract: Probabilistic circuits compute multilinear polynomials that represent probability distributions. They are tractable models that support efficient marginal inference. However, various polynomial semantics have been considered in the literature (e.g., network polynomials, likelihood polynomials, generating functions, Fourier transforms, and characteristic polynomials). The relationships between these polynomial encodings of distributions is largely unknown. In this paper, we prove that for binary distributions, each of these probabilistic circuit models is equivalent in the sense that any circuit for one of them can be transformed into a circuit for any of the others with only a polynomial increase in size. They are therefore all tractable for marginal inference on the same class of distributions. Finally, we explore the natural extension of one such polynomial semantics, called probabilistic generating circuits, to categorical random varia
    
[^59]: Sobolev训练用于算子学习

    Sobolev Training for Operator Learning

    [https://arxiv.org/abs/2402.09084](https://arxiv.org/abs/2402.09084)

    本研究通过将导数信息融入损失函数来改善算子学习框架的性能，并提出了一种在不规则网格上近似导数的新框架，从而表明Sobolev训练在近似解算子方面的有效性。

    

    本研究调查了Sobolev训练对于改善模型性能的算子学习框架的影响。我们的研究发现，将导数信息融入损失函数可以改善训练过程，并提出了一种在算子学习中近似不规则网格上的导数的新框架。我们的发现得到了实验和理论分析的支持。这表明了Sobolev训练在近似无穷维空间中的解算子方面的有效性。

    arXiv:2402.09084v1 Announce Type: cross Abstract: This study investigates the impact of Sobolev Training on operator learning frameworks for improving model performance. Our research reveals that integrating derivative information into the loss function enhances the training process, and we propose a novel framework to approximate derivatives on irregular meshes in operator learning. Our findings are supported by both experimental evidence and theoretical analysis. This demonstrates the effectiveness of Sobolev Training in approximating the solution operators between infinite-dimensional spaces.
    
[^60]: 在 Actor-Critic 方法中利用估计偏差的深度双 Q-Learning 的探索

    Exploiting Estimation Bias in Deep Double Q-Learning for Actor-Critic Methods

    [https://arxiv.org/abs/2402.09078](https://arxiv.org/abs/2402.09078)

    本文提出了两种创新方法，ExpD3 和 BE-TD3，用于解决和利用 Actor-Critic 方法中的估计偏差问题。实验证明这些算法在连续控制任务中比现有方法更高效。

    

    本文介绍了在强化学习领域中创新的方法，重点是解决和利用连续控制任务中 Actor-Critic 方法中的估计偏差问题，使用了深度双 Q-Learning。我们提出了两种新的算法：Expectile Delayed Deep Deterministic Policy Gradient (ExpD3) 和 Bias Exploiting - Twin Delayed Deep Deterministic Policy Gradient (BE-TD3)。ExpD3 旨在通过单一的 Q 估计来减少过度估计偏差，并在计算效率和性能之间提供平衡，而 BE-TD3 则旨在在训练过程中动态选择最有利的估计偏差。我们进行了大量的实验，在各种连续控制任务中展示了我们方法的有效性。我们展示了这些算法在与 TD3 等现有方法相比，尤其是在估计偏差显著影响学习的环境中，可以匹敌或超越它们。这些结果凸显了估计偏差对学习的重要性。

    arXiv:2402.09078v1 Announce Type: cross Abstract: This paper introduces innovative methods in Reinforcement Learning (RL), focusing on addressing and exploiting estimation biases in Actor-Critic methods for continuous control tasks, using Deep Double Q-Learning. We propose two novel algorithms: Expectile Delayed Deep Deterministic Policy Gradient (ExpD3) and Bias Exploiting - Twin Delayed Deep Deterministic Policy Gradient (BE-TD3). ExpD3 aims to reduce overestimation bias with a single $Q$ estimate, offering a balance between computational efficiency and performance, while BE-TD3 is designed to dynamically select the most advantageous estimation bias during training. Our extensive experiments across various continuous control tasks demonstrate the effectiveness of our approaches. We show that these algorithms can either match or surpass existing methods like TD3, particularly in environments where estimation biases significantly impact learning. The results underline the importance of
    
[^61]: 遥感图像中的固体废物检测：一项调查

    Solid Waste Detection in Remote Sensing Images: A Survey

    [https://arxiv.org/abs/2402.09066](https://arxiv.org/abs/2402.09066)

    本文调查了固体废物在遥感图像中的检测方法。研究者利用地球观测卫星提供的高分辨率数据，通过遥感图像实现了固体废物处置场地的识别、监测和评估。

    

    识别和表征非法固体废物处置场地对环境保护至关重要，特别是应对污染和健康危害。不当管理的垃圾填埋场通过雨水渗透污染土壤和地下水，对动物和人类构成威胁。传统的填埋场辨识方法，如现场检查，耗时且昂贵。遥感技术是用于识别和监测固体废物处置场地的一种经济有效的解决方案，可以实现广泛覆盖和多次获取。地球观测（EO）卫星配备了一系列传感器和成像能力，几十年来一直提供高分辨率的数据。研究人员提出了专门的技术，利用遥感图像执行一系列任务，如废物场地检测、倾倒场监测和适宜位置评估。

    arXiv:2402.09066v1 Announce Type: cross Abstract: The detection and characterization of illegal solid waste disposal sites are essential for environmental protection, particularly for mitigating pollution and health hazards. Improperly managed landfills contaminate soil and groundwater via rainwater infiltration, posing threats to both animals and humans. Traditional landfill identification approaches, such as on-site inspections, are time-consuming and expensive. Remote sensing is a cost-effective solution for the identification and monitoring of solid waste disposal sites that enables broad coverage and repeated acquisitions over time. Earth Observation (EO) satellites, equipped with an array of sensors and imaging capabilities, have been providing high-resolution data for several decades. Researchers proposed specialized techniques that leverage remote sensing imagery to perform a range of tasks such as waste site detection, dumping site monitoring, and assessment of suitable locati
    
[^62]: 我看不见它，但我可以微调它：使用全同态加密对Transformer进行加密微调

    I can't see it but I can Fine-tune it: On Encrypted Fine-tuning of Transformers using Fully Homomorphic Encryption

    [https://arxiv.org/abs/2402.09059](https://arxiv.org/abs/2402.09059)

    本文介绍了一种使用全同态加密进行隐私保护微调的系统BlindTuner，它可以在图像分类任务中实现对Transformer模型的隐私保护训练，并在准确性上与非加密模型相当。

    

    在当前的机器学习环境中，微调预训练的Transformer模型已经成为一种重要的技术，特别是在训练数据有限的情况下。然而，当数据共享遇到障碍时，如严格的隐私法规或用户对个人信息披露的担忧，就会出现挑战。早期基于安全多方计算（SMC）和全同态加密（FHE）的隐私保护机器学习（PPML）的工作更注重隐私保护的推理而不是隐私保护的训练。为此，我们引入了BlindTuner，一种隐私保护的微调系统，可实现对Transformer模型基于全同态加密数据的训练，用于图像分类。我们进行了大量实验验证了BlindTuner的有效性，并证明其与非加密模型相比准确性相当。值得注意的是，我们的研究结果突出了一些重要的创新和贡献。

    arXiv:2402.09059v1 Announce Type: cross Abstract: In today's machine learning landscape, fine-tuning pretrained transformer models has emerged as an essential technique, particularly in scenarios where access to task-aligned training data is limited. However, challenges surface when data sharing encounters obstacles due to stringent privacy regulations or user apprehension regarding personal information disclosure. Earlier works based on secure multiparty computation (SMC) and fully homomorphic encryption (FHE) for privacy-preserving machine learning (PPML) focused more on privacy-preserving inference than privacy-preserving training. In response, we introduce BlindTuner, a privacy-preserving fine-tuning system that enables transformer training exclusively on homomorphically encrypted data for image classification. Our extensive experimentation validates BlindTuner's effectiveness by demonstrating comparable accuracy to non-encrypted models. Notably, our findings highlight a substantia
    
[^63]: 证据深度学习方法是否准确地表示认识不确定性？

    Is Epistemic Uncertainty Faithfully Represented by Evidential Deep Learning Methods?

    [https://arxiv.org/abs/2402.09056](https://arxiv.org/abs/2402.09056)

    本论文提出了关于证据深度学习的新理论洞见, 高亮了在优化二阶损失函数和解释得出的认识不确定性度量上的困难性

    

    可信的机器学习系统不仅应返回准确的预测结果，还应提供可靠的不确定性表示。贝叶斯方法常用于量化不确定性，但近年来，证据深度学习方法等替代方法也变得流行起来。后者本质上扩展了经验风险最小化（ERM），用于预测结果的二阶概率分布，从中可以提取认识（和随机）不确定性的度量。本文提供了证据深度学习的新理论洞见，强调了优化二阶损失函数以及解释结果认识不确定性度量的困难性。通过系统化的设置，涵盖了分类、回归和计数的广泛方法，这篇论文为可辨识性和收敛性问题提供了新的洞察。

    arXiv:2402.09056v1 Announce Type: new Abstract: Trustworthy ML systems should not only return accurate predictions, but also a reliable representation of their uncertainty. Bayesian methods are commonly used to quantify both aleatoric and epistemic uncertainty, but alternative approaches, such as evidential deep learning methods, have become popular in recent years. The latter group of methods in essence extends empirical risk minimization (ERM) for predicting second-order probability distributions over outcomes, from which measures of epistemic (and aleatoric) uncertainty can be extracted. This paper presents novel theoretical insights of evidential deep learning, highlighting the difficulties in optimizing second-order loss functions and interpreting the resulting epistemic uncertainty measures. With a systematic setup that covers a wide range of approaches for classification, regression and counts, it provides novel insights into issues of identifiability and convergence in second-o
    
[^64]: 通过对比预训练的方法利用评论辅助视频语言对齐用于短视频幽默检测

    Comment-aided Video-Language Alignment via Contrastive Pre-training for Short-form Video Humor Detection

    [https://arxiv.org/abs/2402.09055](https://arxiv.org/abs/2402.09055)

    本文提出了一种新颖的通过对比预训练的方法，命名为CVLA，用于短视频幽默检测。CVLA不仅适用于各种模态信号，还能通过在一致的语义空间中对齐视频和语言组件产生适合的多模式表示。实验证明，CVLA显著优于现有最先进方法和几个竞争基准方法。

    

    随着短视频在社交媒体平台上的影响力日益扩大，多模式幽默检测在情感计算中的重要性也日益增加。本文提出了一种新颖的用于短视频幽默检测的两层分层模型，命名为通过数据增强的多模式对比预训练的评论辅助视频语言对齐（CVLA）。值得注意的是，我们的CVLA不仅适用于各种模态信号，并且通过在一致的语义空间中对齐视频和语言组件，产生一个适合的多模式表示。在两个幽默检测数据集DY11k和UR-FUNNY上的实验结果表明，CVLA显著优于现有最先进方法和几个竞争基准方法。我们的数据集、代码和模型发布在https://github.com/yliu-cs/CVLA上。

    arXiv:2402.09055v1 Announce Type: cross Abstract: The growing importance of multi-modal humor detection within affective computing correlates with the expanding influence of short-form video sharing on social media platforms. In this paper, we propose a novel two-branch hierarchical model for short-form video humor detection (SVHD), named Comment-aided Video-Language Alignment (CVLA) via data-augmented multi-modal contrastive pre-training. Notably, our CVLA not only operates on raw signals across various modal channels but also yields an appropriate multi-modal representation by aligning the video and language components within a consistent semantic space. The experimental results on two humor detection datasets, including DY11k and UR-FUNNY, demonstrate that CVLA dramatically outperforms state-of-the-art and several competitive baseline approaches. Our dataset, code and model release at https://github.com/yliu-cs/CVLA.
    
[^65]: L3GO: 使用3D思维链生成非常规对象的语言代理

    L3GO: Language Agents with Chain-of-3D-Thoughts for Generating Unconventional Objects

    [https://arxiv.org/abs/2402.09052](https://arxiv.org/abs/2402.09052)

    L3GO是一种使用3D思维链生成非常规对象的语言代理，能够对物体的物理和空间配置进行精确推理，并通过试错的方式在3D模拟环境中生成所需的对象。

    

    arXiv:2402.09052v1 公告类型：新摘要：DALL-E 3和Stable Diffusion-XL等基于扩散的图像生成模型展示了在生成具有逼真和独特构造的图像方面的显著能力。然而，当指示非常规的、不属于分布范围的描述时，如“带有五条腿的椅子”，这些模型在精确推理物体的物理和空间配置方面不够鲁棒。在本文中，我们提出了一种具有3D思维链（L3GO）的语言代理，这种方法可以推理出通过当前数据驱动的扩散模型难以处理的非常规对象的基于部分的3D网格生成。更具体地说，我们使用大型语言模型作为代理，在3D模拟环境中通过试错来组成所需的对象。为了促进我们的研究，我们开发了一个新的基准测试集，非常规可行对象（UFO），以及SimpleBlenv，这是一个基于...

    arXiv:2402.09052v1 Announce Type: new Abstract: Diffusion-based image generation models such as DALL-E 3 and Stable Diffusion-XL demonstrate remarkable capabilities in generating images with realistic and unique compositions. Yet, these models are not robust in precisely reasoning about physical and spatial configurations of objects, especially when instructed with unconventional, thereby out-of-distribution descriptions, such as "a chair with five legs". In this paper, we propose a language agent with chain-of-3D-thoughts (L3GO), an inference-time approach that can reason about part-based 3D mesh generation of unconventional objects that current data-driven diffusion models struggle with. More concretely, we use large language models as agents to compose a desired object via trial-and-error within the 3D simulation environment. To facilitate our investigation, we develop a new benchmark, Unconventionally Feasible Objects (UFO), as well as SimpleBlenv, a wrapper environment built on to
    
[^66]: FGeo-DRL: 通过深度强化学习进行几何问题的演绎推理

    FGeo-DRL: Deductive Reasoning for Geometric Problems through Deep Reinforcement Learning

    [https://arxiv.org/abs/2402.09051](https://arxiv.org/abs/2402.09051)

    本文介绍了FGeo-DRL，一个用于自动执行几何演绎推理的神经符号系统。通过强化学习算法和机器学习模型，该系统能够自主学习解决几何问题的方法，实现了人类化的演绎推理。

    

    自动人类化的演绎推理一直以来都是数学和人工智能交叉学科中最具挑战性的开放问题之一。本文是我们工作系列中的第三篇。我们建立了一个名为FGeoDRL的神经符号系统，用于自动执行人类化几何演绎推理。神经部分是基于强化学习的人工智能代理，能够通过对形式化环境的反馈自主地学习解决问题的方法，无需人类监督。它利用预训练的自然语言模型建立了一个策略网络，用于定理选择，并使用蒙特卡洛树搜索进行启发式探索。符号部分是基于几何形式化理论和FormalGeo\cite{FormalGeo}的强化学习环境，将GPS模型化为马尔科夫决策过程\cite{MDP}。在这个形式化符号系统中，已知条件和

    arXiv:2402.09051v1 Announce Type: new Abstract: The human-like automatic deductive reasoning has always been one of the most challenging open problems in the interdiscipline of mathematics and artificial intelligence. This paper is the third in a series of our works. We built a neural-symbolic system, called FGeoDRL, to automatically perform human-like geometric deductive reasoning. The neural part is an AI agent based on reinforcement learning, capable of autonomously learning problem-solving methods from the feedback of a formalized environment, without the need for human supervision. It leverages a pre-trained natural language model to establish a policy network for theorem selection and employ Monte Carlo Tree Search for heuristic exploration. The symbolic part is a reinforcement learning environment based on geometry formalization theory and FormalGeo\cite{FormalGeo}, which models GPS as a Markov Decision Process\cite{MDP}. In this formal symbolic system, the known conditions and 
    
[^67]: FGeo-TP：一种语言模型增强的几何问题求解器

    FGeo-TP: A Language Model-Enhanced Solver for Geometry Problems

    [https://arxiv.org/abs/2402.09047](https://arxiv.org/abs/2402.09047)

    FGeo-TP是一种语言模型增强的几何问题求解器，利用语言模型预测定理序列来解决几何问题。

    

    应用当代人工智能技术来解决几何问题和自动演绎证明一直是数学和人工智能交叉领域的一大挑战。本文介绍了FGeo-TP（定理预测器），它利用语言模型预测解决几何问题的定理序列。我们比较了各种Transformer架构，比如BART或T5，在定理预测方面的效果。

    arXiv:2402.09047v1 Announce Type: new Abstract: The application of contemporary artificial intelligence techniques to address geometric problems and automated deductive proof has always been a grand challenge to the interdiscipline field of mathematics and artificial Intelligence. This is the fourth article in a series of our works, in our previous work, we established of a geometric formalized system known as FormalGeo. Moreover we annotated approximately 7000 geometric problems, forming the FormalGeo7k dataset. Despite the FGPS (Formal Geometry Problem Solver) can achieve interpretable algebraic equation solving and human-like deductive reasoning, it often experiences timeouts due to the complexity of the search strategy. In this paper, we introduced FGeo-TP (Theorem Predictor), which utilizes the language model to predict theorem sequences for solving geometry problems. We compared the effectiveness of various Transformer architectures, such as BART or T5, in theorem prediction, imp
    
[^68]: 推理和学习统一理论的抽象推断

    Inference of Abstraction for a Unified Account of Reasoning and Learning

    [https://arxiv.org/abs/2402.09046](https://arxiv.org/abs/2402.09046)

    本文提出了一个以贝叶斯方法为基础的概率推断理论，用于推理和学习的统一理论。该理论通过将数据转化为符号知识，从而实现推理过程。我们对逻辑推理关系和MNIST数据集进行了讨论和实验证明。

    

    在神经科学中受到贝叶斯方法的启发，我们提出了一个简单的概率推断理论，用于推理和学习的统一理论。我们通过形式逻辑中的可满足性来建模数据如何导致符号知识。推理是通过抽象，即选择性无知，从数据中推导出符号知识的过程。我们讨论了逻辑推理关系的证明基础的理论正确性。我们还讨论了基于实验证据的MNIST数据集的实验正确性。

    arXiv:2402.09046v1 Announce Type: new Abstract: Inspired by Bayesian approaches to brain function in neuroscience, we give a simple theory of probabilistic inference for a unified account of reasoning and learning. We simply model how data cause symbolic knowledge in terms of its satisfiability in formal logic. The underlying idea is that reasoning is a process of deriving symbolic knowledge from data via abstraction, i.e., selective ignorance. The logical consequence relation is discussed for its proof-based theoretical correctness. The MNIST dataset is discussed for its experiment-based empirical correctness.
    
[^69]: 使用平方Sigmoid TanH (SST)激活在数据限制下提高顺序模型性能

    Enhancing Sequential Model Performance with Squared Sigmoid TanH (SST) Activation Under Data Constraints

    [https://arxiv.org/abs/2402.09034](https://arxiv.org/abs/2402.09034)

    该论文提出了一种平方Sigmoid TanH（SST）激活函数，用于增强在数据限制下的顺序模型学习能力。通过数学平方放大强激活和弱激活之间的差异，改善梯度流和信息过滤。在多个应用中评估了SST驱动的LSTM和GRU模型的性能。

    

    激活函数通过引入非线性来使神经网络能够学习复杂的表示。虽然前馈模型通常使用修正线性单元，但是顺序模型如递归神经网络、长短时记忆（LSTM）和门控循环单元（GRU）仍然依赖于Sigmoid和TanH激活函数。然而，这些传统的激活函数常常在训练在小顺序数据集上时难以建模稀疏模式以有效捕获时间依赖性。为了解决这个限制，我们提出了特别针对在数据限制下增强顺序模型学习能力的平方Sigmoid TanH（SST）激活。SST通过数学平方来放大强激活和弱激活之间的差异，随着信号随时间传播，有助于改善梯度流和信息过滤。我们评估了使用SST的LSTM和GRU模型在不同应用中的性能。

    arXiv:2402.09034v1 Announce Type: cross Abstract: Activation functions enable neural networks to learn complex representations by introducing non-linearities. While feedforward models commonly use rectified linear units, sequential models like recurrent neural networks, long short-term memory (LSTMs) and gated recurrent units (GRUs) still rely on Sigmoid and TanH activation functions. However, these classical activation functions often struggle to model sparse patterns when trained on small sequential datasets to effectively capture temporal dependencies. To address this limitation, we propose squared Sigmoid TanH (SST) activation specifically tailored to enhance the learning capability of sequential models under data constraints. SST applies mathematical squaring to amplify differences between strong and weak activations as signals propagate over time, facilitating improved gradient flow and information filtering. We evaluate SST-powered LSTMs and GRUs for diverse applications, such a
    
[^70]: 对推荐系统的review-合并的模型无关profile注入攻击的综述

    Review-Incorporated Model-Agnostic Profile Injection Attacks on Recommender Systems

    [https://arxiv.org/abs/2402.09023](https://arxiv.org/abs/2402.09023)

    这项研究综述了对推荐系统的review-合并的模型无关profile注入攻击。研究表明，使用文本评论生成高质量的虚假用户配置文件可以在黑盒设置下有效攻击不同的推荐系统。

    

    最近的研究表明，推荐系统(RSs)对数据污染攻击非常容易受到攻击。理解攻击策略有助于提高RSs的稳健性。我们打算开发高效的攻击方法，利用有限资源生成高质量的虚假用户配置文件，实现以下目标：1）在黑盒RSs之间实现可转移性；2）在检测器中实现感知度。为了实现这些目标，我们引入产品的文本评论来提高配置文件的生成质量。具体而言，我们提出了一种名为R-Trojan的新型攻击框架，将攻击目标构建为一个优化问题，并采用定制的基于Transformer的生成对抗网络（GAN）来解决它，从而可以产生高质量的攻击配置文件。对实际数据集进行的全面实验表明，R-Trojan在黑盒设置下显著优于各种受攻击的RSs的最新攻击方法。

    arXiv:2402.09023v1 Announce Type: cross Abstract: Recent studies have shown that recommender systems (RSs) are highly vulnerable to data poisoning attacks. Understanding attack tactics helps improve the robustness of RSs. We intend to develop efficient attack methods that use limited resources to generate high-quality fake user profiles to achieve 1) transferability among black-box RSs 2) and imperceptibility among detectors. In order to achieve these goals, we introduce textual reviews of products to enhance the generation quality of the profiles. Specifically, we propose a novel attack framework named R-Trojan, which formulates the attack objectives as an optimization problem and adopts a tailored transformer-based generative adversarial network (GAN) to solve it so that high-quality attack profiles can be produced. Comprehensive experiments on real-world datasets demonstrate that R-Trojan greatly outperforms state-of-the-art attack methods on various victim RSs under black-box setti
    
[^71]: 朝着更好的人机对齐方向：评估LLM驱动应用中的任务效用

    Towards better Human-Agent Alignment: Assessing Task Utility in LLM-Powered Applications

    [https://arxiv.org/abs/2402.09015](https://arxiv.org/abs/2402.09015)

    本研究引入了AgentEval框架，用于评估LLM驱动应用的任务效用。该框架通过自动提出一套针对特定应用的评估标准，简化了效用验证过程，并对应用的效用进行了全面量化分析。

    

    大型语言模型（LLM）领域的快速发展导致了一系列应用的出现，这些应用通过协助多个代理人与人类合作，帮助人们完成日常任务。然而，目前仍存在一个重大问题，即如何评估LLM驱动应用是否真正提升用户体验和任务执行效率。这凸显了验证LLM驱动应用效用的方法的迫切需求，特别是要确保应用程序的功能与最终用户的需求相一致。我们引入了AgentEval，它提供了一个实施数学问题的估测模型，这是一个新的框架，旨在通过自动提出一套针对任何给定应用程序独特目标的评估标准，简化效用验证过程。这样可以对应用程序的效用进行全面评估，并量化其与建议标准相比的表现。我们对该框架的稳健性进行了全面的分析。

    arXiv:2402.09015v1 Announce Type: cross Abstract: The rapid development in the field of Large Language Models (LLMs) has led to a surge in applications that facilitate collaboration among multiple agents to assist humans in their daily tasks. However, a significant gap remains in assessing whether LLM-powered applications genuinely enhance user experience and task execution efficiency. This highlights the pressing need for methods to verify utility of LLM-powered applications, particularly by ensuring alignment between the application's functionality and end-user needs. We introduce AgentEval provides an implementation for the math problems}, a novel framework designed to simplify the utility verification process by automatically proposing a set of criteria tailored to the unique purpose of any given application. This allows for a comprehensive assessment, quantifying the utility of an application against the suggested criteria. We present a comprehensive analysis of the robustness of 
    
[^72]: AgentLens: LLMAS自主系统中代理行为的可视化分析

    AgentLens: Visual Analysis for Agent Behaviors in LLM-based Autonomous Systems

    [https://arxiv.org/abs/2402.08995](https://arxiv.org/abs/2402.08995)

    AgentLens是一个可视化分析系统，用于研究LLMAS自主系统中代理行为。它通过分层时间可视化展示LLMAS的演变，支持用户交互式地探索代理行为的细节和原因。

    

    最近，基于大型语言模型的自主系统(LLMAS)因其模拟人类社会复杂行为的潜力而广受关注。其中一个主要挑战是如何展示和分析LLMAS的动态事件演变。在本研究中，我们提出了一种可视化方法，用于探索LLMAS中的详细状态和代理行为。我们提出了一个通用的流程，从原始LLMAS执行事件中建立行为结构，利用行为总结算法构建整个结构的时间序列层次摘要，并使用因果关系追踪方法挖掘代理行为之间的因果关系。然后，我们开发了一个名为AgentLens的可视化分析系统，通过使用分层时间可视化来展示LLMAS的演变，并支持用户交互式地研究代理行为的详细信息和原因。包括两个使用场景和一个用户 摘要。

    arXiv:2402.08995v1 Announce Type: cross Abstract: Recently, Large Language Model based Autonomous system(LLMAS) has gained great popularity for its potential to simulate complicated behaviors of human societies. One of its main challenges is to present and analyze the dynamic events evolution of LLMAS. In this work, we present a visualization approach to explore detailed statuses and agents' behavior within LLMAS. We propose a general pipeline that establishes a behavior structure from raw LLMAS execution events, leverages a behavior summarization algorithm to construct a hierarchical summary of the entire structure in terms of time sequence, and a cause trace method to mine the causal relationship between agent behaviors. We then develop AgentLens, a visual analysis system that leverages a hierarchical temporal visualization for illustrating the evolution of LLMAS, and supports users to interactively investigate details and causes of agents' behaviors. Two usage scenarios and a user s
    
[^73]: CLIP-MUSED：CLIP引导的多主题视觉神经信息语义解码

    CLIP-MUSED: CLIP-Guided Multi-Subject Visual Neural Information Semantic Decoding

    [https://arxiv.org/abs/2402.08994](https://arxiv.org/abs/2402.08994)

    CLIP-MUSED是一种CLIP引导的多主题视觉神经信息语义解码方法，可以克服单主题解码模型推广到多个主题的挑战，并且通过使用Transformer-based特征提取器来有效建模全局神经表示。

    

    研究解码视觉神经信息面临着将单主题解码模型推广到多个主题的挑战，这是由于个体差异所导致的。此外，来自单个主题的数据有限对模型性能有着限制性影响。尽管之前的多主题解码方法取得了相当大的进展，但仍然存在一些限制，包括难以提取全局神经响应特征，模型参数随主题数量线性扩展以及对于不同主题的神经响应与各种刺激之间的关系描述不足。为了克服这些限制，我们提出了一种CLIP引导的多主题视觉神经信息语义解码（CLIP-MUSED）方法。我们的方法包括一个基于Transformer的特征提取器，用于有效地建模全局神经表示。它还包含学习得到的主题特定的tok

    arXiv:2402.08994v1 Announce Type: cross Abstract: The study of decoding visual neural information faces challenges in generalizing single-subject decoding models to multiple subjects, due to individual differences. Moreover, the limited availability of data from a single subject has a constraining impact on model performance. Although prior multi-subject decoding methods have made significant progress, they still suffer from several limitations, including difficulty in extracting global neural response features, linear scaling of model parameters with the number of subjects, and inadequate characterization of the relationship between neural responses of different subjects to various stimuli. To overcome these limitations, we propose a CLIP-guided Multi-sUbject visual neural information SEmantic Decoding (CLIP-MUSED) method. Our method consists of a Transformer-based feature extractor to effectively model global neural representations. It also incorporates learnable subject-specific tok
    
[^74]: SafeDecoding: 通过安全感知解码防御越狱攻击

    SafeDecoding: Defending against Jailbreak Attacks via Safety-Aware Decoding

    [https://arxiv.org/abs/2402.08983](https://arxiv.org/abs/2402.08983)

    本文提出了一种名为SafeDecoding的解决方案，通过安全感知解码策略来防御大型语言模型（LLMs）的越狱攻击。该策略可以生成对用户查询有益且无害的响应，有效缓解了LLMs安全性威胁。

    

    随着大型语言模型（LLMs）越来越多地应用于代码生成和聊天机器人辅助等现实应用中，人们为了使LLM的行为与人类价值观保持一致，包括安全性在内做出了大量努力。越狱攻击旨在引发LLM的非预期和不安全行为，仍然是LLM安全性的重要威胁。本文旨在通过引入SafeDecoding来防御LLM的越狱攻击，这是一种安全感知的解码策略，用于生成对用户查询有益且无害的响应。我们在开发SafeDecoding时的洞察力基于观察到，即使代表有害内容的标记的概率超过代表无害响应的标记的概率，安全免责声明仍然出现在按概率降序排序的标记中的前几个。这使我们能够通过识别安全免责声明并增强其良性影响力来减轻越狱攻击。

    arXiv:2402.08983v1 Announce Type: cross Abstract: As large language models (LLMs) become increasingly integrated into real-world applications such as code generation and chatbot assistance, extensive efforts have been made to align LLM behavior with human values, including safety. Jailbreak attacks, aiming to provoke unintended and unsafe behaviors from LLMs, remain a significant/leading LLM safety threat. In this paper, we aim to defend LLMs against jailbreak attacks by introducing SafeDecoding, a safety-aware decoding strategy for LLMs to generate helpful and harmless responses to user queries. Our insight in developing SafeDecoding is based on the observation that, even though probabilities of tokens representing harmful contents outweigh those representing harmless responses, safety disclaimers still appear among the top tokens after sorting tokens by probability in descending order. This allows us to mitigate jailbreak attacks by identifying safety disclaimers and amplifying their
    
[^75]: MEL: 高维特征选择的高效多任务进化学习

    MEL: Efficient Multi-Task Evolutionary Learning for High-Dimensional Feature Selection

    [https://arxiv.org/abs/2402.08982](https://arxiv.org/abs/2402.08982)

    MEL是一种高效的多任务进化学习方法，通过多任务学习中的信息共享来增强特征选择的能力和效率，解决了高维特征选择中的挑战。

    

    特征选择是数据挖掘中的关键步骤，通过降低数据维度来提高模型性能。然而，收集到的数据的维度越来越高，使得计算复杂度与维度数量呈指数增长。为了解决这个问题，进化计算方法因其简单性和适用性而越来越受欢迎。不幸的是，不同的进化计算方法的多样设计导致其处理不同数据的能力不尽相同，经常无法有效地利用和共享信息。在本文中，我们提出了一种名为PSO-based Multi-task Evolutionary Learning (MEL)的新方法，它利用多任务学习来解决这些挑战。通过在不同特征选择任务之间共享信息，MEL实现了增强的学习能力和效率。我们通过广泛的实验评估了MEL的有效性。

    arXiv:2402.08982v1 Announce Type: cross Abstract: Feature selection is a crucial step in data mining to enhance model performance by reducing data dimensionality. However, the increasing dimensionality of collected data exacerbates the challenge known as the "curse of dimensionality", where computation grows exponentially with the number of dimensions. To tackle this issue, evolutionary computational (EC) approaches have gained popularity due to their simplicity and applicability. Unfortunately, the diverse designs of EC methods result in varying abilities to handle different data, often underutilizing and not sharing information effectively. In this paper, we propose a novel approach called PSO-based Multi-task Evolutionary Learning (MEL) that leverages multi-task learning to address these challenges. By incorporating information sharing between different feature selection tasks, MEL achieves enhanced learning ability and efficiency. We evaluate the effectiveness of MEL through extens
    
[^76]: 学习驱动的灵活作业车间调度用于可扩展智能制造

    Learning-enabled Flexible Job-shop Scheduling for Scalable Smart Manufacturing

    [https://arxiv.org/abs/2402.08979](https://arxiv.org/abs/2402.08979)

    本研究提出了一种基于图的深度强化学习方法，名为异构图调度器（HGS），用于解决灵活作业车间调度问题。该方法利用局部关系知识进行调度，并采用图结构的决策框架，提高了规模泛化能力。

    

    在智能制造系统中，考虑到基于自动导引车辆（AGV）的生产灵活性，具有运输约束的灵活作业车间调度（FJSPT）是优化最大化生产力的解决方案的关键。最近，基于深度强化学习（DRL）的FJSPT方法在规模泛化方面遇到了挑战。这些方法在与其训练集不同规模的环境中表现不佳，导致低质量的解决方案。为了解决这个问题，我们引入了一种新颖的基于图的DRL方法，命名为异构图调度器（HGS）。我们的方法利用在操作、机器和车辆节点之间提取的局部关系知识进行调度，采用图结构的决策框架来降低编码复杂性并增强规模泛化能力。我们进行了基准数据集的性能评估，结果显示该方法在规模泛化上具有良好的表现。

    arXiv:2402.08979v1 Announce Type: cross Abstract: In smart manufacturing systems (SMSs), flexible job-shop scheduling with transportation constraints (FJSPT) is essential to optimize solutions for maximizing productivity, considering production flexibility based on automated guided vehicles (AGVs). Recent developments in deep reinforcement learning (DRL)-based methods for FJSPT have encountered a scale generalization challenge. These methods underperform when applied to environment at scales different from their training set, resulting in low-quality solutions. To address this, we introduce a novel graph-based DRL method, named the Heterogeneous Graph Scheduler (HGS). Our method leverages locally extracted relational knowledge among operations, machines, and vehicle nodes for scheduling, with a graph-structured decision-making framework that reduces encoding complexity and enhances scale generalization. Our performance evaluation, conducted with benchmark datasets, reveals that the pro
    
[^77]: 基于Transformer的异常检测模型的研究与应用: 文献综述

    Research and application of Transformer based anomaly detection model: A literature review

    [https://arxiv.org/abs/2402.08975](https://arxiv.org/abs/2402.08975)

    本文综述了基于Transformer的异常检测模型在自然语言处理领域的研究与应用，概述了Transformer及其变种在异常检测任务中的工作原理和应用场景，并提出了该领域的未来研究趋势。

    

    Transformer作为一种在自然语言处理领域中应用最广泛的先进神经网络模型之一，在异常检测领域展示了多样的应用。为了激发对基于Transformer的异常检测的研究，本综述从新的角度探索了异常检测的概念，探讨了当前异常检测面临的挑战，并详细介绍了Transformer及其变种在异常检测任务中的工作原理。此外，我们还勾勒了基于Transformer的异常检测模型的各种应用场景，并讨论了所采用的数据集和评估指标。此外，本综述强调了基于Transformer的异常检测研究中的关键挑战，并对该领域的未来研究趋势进行了全面分析。综述中收录了100多个与基于Transformer的异常检测相关的核心参考文献。

    arXiv:2402.08975v1 Announce Type: cross Abstract: Transformer, as one of the most advanced neural network models in Natural Language Processing (NLP), exhibits diverse applications in the field of anomaly detection. To inspire research on Transformer-based anomaly detection, this review offers a fresh perspective on the concept of anomaly detection. We explore the current challenges of anomaly detection and provide detailed insights into the operating principles of Transformer and its variants in anomaly detection tasks. Additionally, we delineate various application scenarios for Transformer-based anomaly detection models and discuss the datasets and evaluation metrics employed. Furthermore, this review highlights the key challenges in Transformer-based anomaly detection research and conducts a comprehensive analysis of future research trends in this domain. The review includes an extensive compilation of over 100 core references related to Transformer-based anomaly detection. To the 
    
[^78]: GrounDial：基于人类准则的对话响应生成

    GrounDial: Human-norm Grounded Safe Dialog Response Generation

    [https://arxiv.org/abs/2402.08968](https://arxiv.org/abs/2402.08968)

    GrounDial是一种基于人类准则的对话响应生成模型，通过将响应基于常识社交规则来确保响应的安全性，而无需进行微调。

    

    目前基于大型语言模型（LLM）的对话AI系统已知会生成不安全的响应，包括同意冒犯性用户输入或包含有害内容。以往的研究致力于减少毒性，通过使用手动注释的安全对话历史来对LLM进行微调。然而，依赖于额外的调整需要大量成本。为了消除该依赖，我们提出了GrounDial，它通过将响应基于常识社交规则来确保响应的安全性，而无需进行微调。GrounDial的上下文学习和遵循人类准则的解码混合方法使得响应在没有额外数据或调整的情况下在量化和质量上都更安全。

    arXiv:2402.08968v1 Announce Type: new Abstract: Current conversational AI systems based on large language models (LLMs) are known to generate unsafe responses, agreeing to offensive user input or including toxic content. Previous research aimed to alleviate the toxicity, by fine-tuning LLM with manually annotated safe dialogue histories. However, the dependency on additional tuning requires substantial costs. To remove the dependency, we propose GrounDial, where response safety is achieved by grounding responses to commonsense social rules without requiring fine-tuning. A hybrid approach of in-context learning and human-norm-guided decoding of GrounDial enables the response to be quantitatively and qualitatively safer even without additional data or tuning.
    
[^79]: DUEL: 用于自监督类别不平衡学习的主动内存去重方法

    DUEL: Duplicate Elimination on Active Memory for Self-Supervised Class-Imbalanced Learning

    [https://arxiv.org/abs/2402.08963](https://arxiv.org/abs/2402.08963)

    DUEL是一个用于解决类别不平衡问题的自监督学习框架，通过主动内存去重策略来增强数据的多样性，有效缓解了过拟合的问题。英文总结目前暂无法给出。

    

    最近的机器学习算法通常使用经过精心筛选的数据集进行开发，这往往需要大量成本和资源。另一方面，直接使用原始数据往往会导致过拟合，偏向于频繁出现的类别信息。为了高效解决类别不平衡问题，我们提出了一种在自监督预训练过程中进行主动数据过滤的新框架，命名为Duplicate Elimination (DUEL)。该框架结合了受人类工作内存启发的主动内存，并引入了区分性信息，用于衡量内存中数据的多样性，以优化特征提取器和内存。DUEL策略通过替换最常重复的数据样本来增强内存中的区分性信息，从而缓解类别不平衡问题。我们在类别不平衡环境中验证了DUEL框架的有效性，并展示了其优越的性能。

    arXiv:2402.08963v1 Announce Type: cross Abstract: Recent machine learning algorithms have been developed using well-curated datasets, which often require substantial cost and resources. On the other hand, the direct use of raw data often leads to overfitting towards frequently occurring class information. To address class imbalances cost-efficiently, we propose an active data filtering process during self-supervised pre-training in our novel framework, Duplicate Elimination (DUEL). This framework integrates an active memory inspired by human working memory and introduces distinctiveness information, which measures the diversity of the data in the memory, to optimize both the feature extractor and the memory. The DUEL policy, which replaces the most duplicated data with new samples, aims to enhance the distinctiveness information in the memory and thereby mitigate class imbalances. We validate the effectiveness of the DUEL framework in class-imbalanced environments, demonstrating its ro
    
[^80]: HyCubE: 高效的知识超图3D环形卷积嵌入

    HyCubE: Efficient Knowledge Hypergraph 3D Circular Convolutional Embedding

    [https://arxiv.org/abs/2402.08961](https://arxiv.org/abs/2402.08961)

    本论文提出了一种名为HyCubE的模型,它通过使用新颖的3D环形卷积神经网络和交替掩码堆叠策略来实现高效的n元知识超图嵌入，并通过自适应调整卷积核大小和均匀嵌入实体位置信息来提高模型性能和效率。

    

    现有的知识超图嵌入方法主要集中在提高模型性能，但它们的模型结构变得越来越复杂和冗余。此外，由于固有的复杂语义知识，知识超图嵌入模型的计算通常非常昂贵，导致效率低下。在本文中，我们提出了一种增强特征交互和提取的3D环形卷积嵌入模型HyCubE，它设计了一种新颖的3D环形卷积神经网络，并引入了交替掩码堆叠策略，实现了高效的n元知识超图嵌入。通过自适应调整3D环形卷积核的大小，并均匀嵌入实体位置信息，HyCubE在更少的参数下提高了模型性能，并在模型性能和效率之间取得了更好的权衡。此外，我们使用基于实体掩码的1-N多线性评分进行评估。

    arXiv:2402.08961v1 Announce Type: new Abstract: Existing knowledge hypergraph embedding methods mainly focused on improving model performance, but their model structures are becoming more complex and redundant. Furthermore, due to the inherent complex semantic knowledge, the computation of knowledge hypergraph embedding models is often very expensive, leading to low efficiency. In this paper, we propose a feature interaction and extraction-enhanced 3D circular convolutional embedding model, HyCubE, which designs a novel 3D circular convolutional neural network and introduces the alternate mask stack strategy to achieve efficient n-ary knowledge hypergraph embedding. By adaptively adjusting the 3D circular convolution kernel size and uniformly embedding the entity position information, HyCubE improves the model performance with fewer parameters and reaches a better trade-off between model performance and efficiency. In addition, we use 1-N multilinear scoring based on the entity mask me
    
[^81]: 使用无配对的掩码-文本监督进行开放词汇分割

    Open-Vocabulary Segmentation with Unpaired Mask-Text Supervision

    [https://arxiv.org/abs/2402.08960](https://arxiv.org/abs/2402.08960)

    本文提出了一种通过使用无配对的掩码-文本监督方法来进行开放词汇分割的框架(Uni-OVSeg)，该方法通过独立的图像-掩码和图像-文本对提取二进制掩码并与实体关联。

    

    当代尖端的开放词汇分割方法通常依赖于图像-掩码-文本三元组，然而这种受限的注释在复杂的现实场景中需要大量的人力，并且遇到了可扩展性的障碍。虽然已经提出了一些方法通过仅使用文本监督来减少注释的成本，但监督的不完整性严重限制了多样性和性能。在本文中，我们通过使用独立的图像-掩码和图像-文本对解放了掩码和文本之间的严格对应关系，这些对可以分别轻松收集。借助这种无配对的掩码-文本监督，我们提出了一种新的弱监督开放词汇分割框架(Uni-OVSeg)，它利用自信的掩码预测和文本描述中的实体。利用独立的图像-掩码和图像-文本对，我们预测了一组二进制掩码，并通过使用CLIP嵌入将它们与实体关联起来。

    arXiv:2402.08960v1 Announce Type: cross Abstract: Contemporary cutting-edge open-vocabulary segmentation approaches commonly rely on image-mask-text triplets, yet this restricted annotation is labour-intensive and encounters scalability hurdles in complex real-world scenarios. Although some methods are proposed to reduce the annotation cost with only text supervision, the incompleteness of supervision severely limits the versatility and performance. In this paper, we liberate the strict correspondence between masks and texts by using independent image-mask and image-text pairs, which can be easily collected respectively. With this unpaired mask-text supervision, we propose a new weakly-supervised open-vocabulary segmentation framework (Uni-OVSeg) that leverages confident pairs of mask predictions and entities in text descriptions. Using the independent image-mask and image-text pairs, we predict a set of binary masks and associate them with entities by resorting to the CLIP embedding s
    
[^82]: 迈向超大规模Transformer的下一级后训练量化

    Towards Next-Level Post-Training Quantization of Hyper-Scale Transformers

    [https://arxiv.org/abs/2402.08958](https://arxiv.org/abs/2402.08958)

    本文提出了一种新颖的后训练量化算法，名为aespa，它在保持完整的注意力得分的同时，通过逐层量化来提高效率，解决了当前后训练量化方案的瓶颈问题。

    

    随着生成AI模型的复杂性增加，后训练量化（PTQ）已成为在移动设备和电视等边缘设备上部署超大规模模型的有希望的解决方案。然而，现有的PTQ方案耗费大量时间和资源，这可能成为实际情况中频繁模型更新和多种超参数调整的瓶颈。作为一种成本效益的替代方案，已经提出了一次性PTQ方案。然而，它们的性能有些受限，因为它们无法考虑到Transformer中注意力模块内部层间的依赖关系，而这是一个非常重要的特性。因此，在本文中，我们提出了一种新颖的PTQ算法，它在精度和效率之间取得了平衡。所提出的算法的关键思想叫做aespa，通过在效率上进行逐层量化，同时考虑到跨层依赖以保留注意力得分。

    arXiv:2402.08958v1 Announce Type: cross Abstract: With the increasing complexity of generative AI models, post-training quantization (PTQ) has emerged as a promising solution for deploying hyper-scale models on edge devices such as mobile devices and TVs. Existing PTQ schemes, however, consume considerable time and resources, which could be a bottleneck in real situations where frequent model updates and multiple hyper-parameter tunings are required. As a cost-effective alternative, one-shot PTQ schemes have been proposed. Still, the performance is somewhat limited because they cannot consider the inter-layer dependency within the attention module, which is a very important feature of Transformers. In this paper, we thus propose a novel PTQ algorithm that balances accuracy and efficiency. The key idea of the proposed algorithm called aespa is to perform quantization layer-wise for efficiency while considering cross-layer dependency to preserve the attention score. Through extensive exp
    
[^83]: MUSTARD：掌握定理和证明数据的统一合成

    MUSTARD: Mastering Uniform Synthesis of Theorem and Proof Data

    [https://arxiv.org/abs/2402.08957](https://arxiv.org/abs/2402.08957)

    这项工作介绍了MUSTARD，一种掌握定理和证明数据统一合成的数据生成框架，通过三个阶段的合成，实现了高质量和多样化的问题和推理步骤的生成。

    

    最近，大型语言模型（LLMs）在各种任务中取得了显著进展，包括数学推理和定理证明。由于这两个任务需要严格和形式化的多步推理，它们是探索LLMs推理能力的吸引领域，但仍面临重要挑战。以前的研究如Chain-of-Thought（CoT）揭示了中间步骤指导的有效性。然而，这种逐步注释需要大量的劳动力，导致当前基准测试的训练步骤不足。为了填补这一空白，本研究引入了MUSTARD，一种数据生成框架，可以主导高质量和多样化的定理和证明数据的统一合成。MUSTARD通过三个阶段合成数据：（1）它随机选择几个数学概念作为问题的类别。（2）然后，它使用选定的概念提示生成性语言模型，以获得问题和它们的推理步骤。

    arXiv:2402.08957v1 Announce Type: new Abstract: Recent large language models (LLMs) have witnessed significant advancement in various tasks, including mathematical reasoning and theorem proving. As these two tasks require strict and formal multi-step inference, they are appealing domains for exploring the reasoning ability of LLMs but still face important challenges. Previous studies such as Chain-of-Thought (CoT) have revealed the effectiveness of intermediate steps guidance. However, such step-wise annotation requires heavy labor, leading to insufficient training steps for current benchmarks. To fill this gap, this work introduces MUSTARD, a data generation framework that masters uniform synthesis of theorem and proof data of high quality and diversity. MUSTARD synthesizes data in three stages: (1) It samples a few mathematical concept seeds as the problem category. (2) Then, it prompts a generative language model with the sampled concepts to obtain both the problems and their step-w
    
[^84]: 使用反事实任务评估大型语言模型中类比推理的广泛性

    Using Counterfactual Tasks to Evaluate the Generality of Analogical Reasoning in Large Language Models

    [https://arxiv.org/abs/2402.08955](https://arxiv.org/abs/2402.08955)

    本研究通过创建一组反事实问题，评估了大型语言模型中类比推理能力的广泛性。结果表明，尽管人类在所有问题上的表现良好，但GPT模型在反事实集上的表现显著下降。

    

    大型语言模型（LLMs）在多个推理基准测试中表现出色，包括测试类比推理能力的基准测试。然而，关于它们是否真正进行人类抽象推理，还是依赖于与训练数据中所见相似的较少通用过程的争论一直存在。本研究调查了先前声称LLMs具有类比能力的广泛性（Webb, Holyoak, & Lu, 2023）。我们利用用于评估LLMs的一组类比问题，创建了一组“反事实”变体，即测试相同的抽象推理能力，但很可能与任何预训练资料不同。我们对人类和三个GPT模型在原始问题和反事实问题上进行了测试，并发现，虽然人类的表现对所有问题保持高水平，但GPT模型在反事实集上的表现急剧下降。这项工作提供了证据。

    arXiv:2402.08955v1 Announce Type: new Abstract: Large language models (LLMs) have performed well on several reasoning benchmarks, including ones that test analogical reasoning abilities. However, it has been debated whether they are actually performing humanlike abstract reasoning or instead employing less general processes that rely on similarity to what has been seen in their training data. Here we investigate the generality of analogy-making abilities previously claimed for LLMs (Webb, Holyoak, & Lu, 2023). We take one set of analogy problems used to evaluate LLMs and create a set of "counterfactual" variants-versions that test the same abstract reasoning abilities but that are likely dissimilar from any pre-training data. We test humans and three GPT models on both the original and counterfactual problems, and show that, while the performance of humans remains high for all the problems, the GPT models' performance declines sharply on the counterfactual set. This work provides evide
    
[^85]: 论据顺序在与大型语言模型推理中起作用

    Premise Order Matters in Reasoning with Large Language Models

    [https://arxiv.org/abs/2402.08939](https://arxiv.org/abs/2402.08939)

    对大型语言模型（LLMs）进行推理任务时，论据的顺序非常重要，尤其是在演绎推理任务中，按照提示的真实证明顺序呈现论据可以显著提高模型的准确性。

    

    大型语言模型（LLMs）在各个领域都取得了惊人的推理性能。然而，在推理任务的领域中，我们发现了一个脆弱性：尽管这种顺序不会改变基本任务，但LLMs对于论据的顺序非常脆弱。特别是，我们观察到当论据顺序与中间推理步骤所需的上下文对齐时，LLMs可以达到最佳性能。例如，在演绎推理任务中，将论据按照提示的真实证明顺序呈现（而不是随机顺序）会极大地提高模型的准确性。我们首先研究了不同LLMs对演绎推理中论据顺序的影响，我们的评估结果表明，调整论据顺序可能导致性能下降超过30％。此外，我们发布了基于GSM8K的基准测试R-GSM来研究顺序效应对数学推理的影响。

    arXiv:2402.08939v1 Announce Type: new Abstract: Large language models (LLMs) have accomplished remarkable reasoning performance in various domains. However, in the domain of reasoning tasks, we discover a frailty: LLMs are surprisingly brittle to the ordering of the premises, despite the fact that such ordering does not alter the underlying task. In particular, we observe that LLMs achieve the best performance when the premise order aligns with the context required in intermediate reasoning steps. For example, in deductive reasoning tasks, presenting the premises in the same order as the ground truth proof in the prompt (as opposed to random ordering) drastically increases the model's accuracy. We first examine the effect of premise ordering on deductive reasoning on a variety of LLMs, and our evaluation shows that permuting the premise order can cause a performance drop of over 30%. In addition, we release the benchmark R-GSM, based on GSM8K, to examine the ordering effect for mathema
    
[^86]: MaxMin-RLHF:面向具有多样的人类偏好的大型语言模型的公平对齐

    MaxMin-RLHF: Towards Equitable Alignment of Large Language Models with Diverse Human Preferences

    [https://arxiv.org/abs/2402.08925](https://arxiv.org/abs/2402.08925)

    这项工作提出了一种公平对齐大型语言模型与多样的人类偏好的方法，通过学习混合偏好分布并使用MaxMin对齐目标来更好地表示人类偏好。

    

    强化学习从人类反馈中学习(RLHF)通过使用从偏好数据中派生的单一奖励模型来对齐语言模型与人类偏好一致。然而，这种方法忽视了从多个用户收集的数据中固有的人类偏好的丰富多样性。在这项工作中，我们首先推导出了使用单一奖励RLHF进行对齐的不可能性结果，从而凸显了其无法表示多样的人类偏好。为了提供一个公平的解决方案，我们通过期望最大化算法学习了一种混合偏好分布，并提出了一种受社会选择理论中的平等原则启发的MaxMin对齐目标来更好地表示多样的人类偏好。我们阐明了我们提出的方法与分布稳健优化和通用效用RL的联系，从而突显了我们提出的方法的普适性和鲁棒性。

    arXiv:2402.08925v1 Announce Type: cross Abstract: Reinforcement Learning from Human Feedback (RLHF) aligns language models to human preferences by employing a singular reward model derived from preference data. However, such an approach overlooks the rich diversity of human preferences inherent in data collected from multiple users. In this work, we first derive an impossibility result of alignment with single reward RLHF, thereby highlighting its insufficiency in representing diverse human preferences. To provide an equitable solution to the problem, we learn a mixture of preference distributions via an expectation-maximization algorithm and propose a MaxMin alignment objective for policy learning inspired by the Egalitarian principle in social choice theory to better represent diverse human preferences. We elucidate the connection of our proposed approach to distributionally robust optimization and general utility RL, thereby highlighting the generality and robustness of our proposed
    
[^87]: 通过替代训练增强ID和文本融合在基于会话的推荐中

    Enhancing ID and Text Fusion via Alternative Training in Session-based Recommendation

    [https://arxiv.org/abs/2402.08921](https://arxiv.org/abs/2402.08921)

    本论文研究在基于会话的推荐中增强ID和文本的融合效果。研究发现，通过简单融合的方法并不能始终超越最佳的单模态方法。进一步的调查表明，这可能是由于融合方法中存在的ID和文本模态不平衡问题。

    

    近年来，基于会话的推荐引起了越来越多的关注，其目标是根据用户在会话中的历史行为提供定制的建议。为了推进这个领域，已经开发了许多方法，其中基于ID的方法通常表现出有希望的性能。然而，这些方法在长尾项目方面经常面临挑战，并且忽视了其他丰富的信息形式，特别是有价值的文本语义信息。为了整合文本信息，引入了各种方法，主要是遵循一个简单的融合框架。令人惊讶的是，我们观察到融合这两种模态并不始终优于遵循简单融合框架的最佳单模态。进一步的调查揭示了简单融合中潜在的不平衡问题，其中ID占主导地位，而文本模态则未充分训练。这表明意外观察可能源于简单融合的潜在问题。

    arXiv:2402.08921v1 Announce Type: cross Abstract: Session-based recommendation has gained increasing attention in recent years, with its aim to offer tailored suggestions based on users' historical behaviors within sessions.   To advance this field, a variety of methods have been developed, with ID-based approaches typically demonstrating promising performance. However, these methods often face challenges with long-tail items and overlook other rich forms of information, notably valuable textual semantic information. To integrate text information, various methods have been introduced, mostly following a naive fusion framework. Surprisingly, we observe that fusing these two modalities does not consistently outperform the best single modality by following the naive fusion framework. Further investigation reveals an potential imbalance issue in naive fusion, where the ID dominates and text modality is undertrained. This suggests that the unexpected observation may stem from naive fusion's
    
[^88]: 通过无监督在图上学习多层感知机（MLP）加速图推理

    Graph Inference Acceleration by Learning MLPs on Graphs without Supervision

    [https://arxiv.org/abs/2402.08918](https://arxiv.org/abs/2402.08918)

    该论文提出了一个简单而有效的框架SimMLP，通过在图上无监督学习MLPs，提高了在延迟敏感的应用中的泛化能力。

    

    图神经网络（GNNs）已经在各种图学习任务中展示出了有效性，但是它们对消息传递的依赖限制了它们在延迟敏感的应用中的部署，比如金融欺诈检测。最近的研究探索了从GNNs中提取知识到多层感知机（MLPs）来加速推理。然而，这种任务特定的有监督蒸馏限制了对未见节点的泛化，而在延迟敏感的应用中这种情况很常见。为此，我们提出了一种简单而有效的框架SimMLP，用于在图上无监督学习MLPs，以增强泛化能力。SimMLP利用自监督对齐GNNs和MLPs之间的节点特征和图结构之间的精细和泛化的相关性，并提出了两种策略来减轻平凡解的风险。从理论上讲，

    arXiv:2402.08918v1 Announce Type: cross Abstract: Graph Neural Networks (GNNs) have demonstrated effectiveness in various graph learning tasks, yet their reliance on message-passing constraints their deployment in latency-sensitive applications such as financial fraud detection. Recent works have explored distilling knowledge from GNNs to Multi-Layer Perceptrons (MLPs) to accelerate inference. However, this task-specific supervised distillation limits generalization to unseen nodes, which are prevalent in latency-sensitive applications. To this end, we present \textbf{\textsc{SimMLP}}, a \textbf{\textsc{Sim}}ple yet effective framework for learning \textbf{\textsc{MLP}}s on graphs without supervision, to enhance generalization. \textsc{SimMLP} employs self-supervised alignment between GNNs and MLPs to capture the fine-grained and generalizable correlation between node features and graph structures, and proposes two strategies to alleviate the risk of trivial solutions. Theoretically, w
    
[^89]: 解决图上的负迁移问题

    Tackling Negative Transfer on Graphs

    [https://arxiv.org/abs/2402.08907](https://arxiv.org/abs/2402.08907)

    图迁移学习中的负迁移现象尚未得到充分研究，本文发现在图结构数据中负迁移普遍存在，即使源图和目标图在语义上相似。我们提出了一个新的观点，对于语义相似的图，结构差异对子图嵌入的影响较小。

    

    迁移学习旨在通过利用从其他相关任务中学到的知识来提高目标任务上的学习效果。然而，当源任务和目标任务之间关系不密切时，学习性能可能会受到不利影响，这种现象被称为负迁移。本文研究了在图迁移学习中的负迁移问题，这是一个重要但尚未深入研究的领域。我们发现，在图结构数据中，与图像或文本不同，负迁移经常发生，即使源图和目标图在语义上有相似之处。具体来说，我们发现结构差异会大大增强图中节点嵌入之间的差异。为了缓解这个问题，我们带来了一个新的观点：对于语义相似的图，尽管结构差异会导致节点嵌入的分布差异，但它们对子图嵌入的影响可能较小。基于这个观点，我们引入了tw

    arXiv:2402.08907v1 Announce Type: cross Abstract: Transfer learning aims to boost the learning on the target task leveraging knowledge learned from other relevant tasks. However, when the source and target are not closely related, the learning performance may be adversely affected, a phenomenon known as negative transfer. In this paper, we investigate the negative transfer in graph transfer learning, which is important yet underexplored. We reveal that, unlike image or text, negative transfer commonly occurs in graph-structured data, even when source and target graphs share semantic similarities. Specifically, we identify that structural differences significantly amplify the dissimilarities in the node embeddings across graphs. To mitigate this, we bring a new insight: for semantically similar graphs, although structural differences lead to significant distribution shift in node embeddings, their impact on subgraph embeddings could be marginal. Building on this insight, we introduce tw
    
[^90]: DUDF: 具有双曲缩放的可微无符号距离场

    DUDF: Differentiable Unsigned Distance Fields with Hyperbolic Scaling

    [https://arxiv.org/abs/2402.08876](https://arxiv.org/abs/2402.08876)

    DUDF提出了一种学习无符号距离场的双曲缩放方法，通过与隐式神经表示网络集成，解决了开放表面表示的挑战，并在重建质量和训练性能方面取得显著改进。

    

    最近几年，人们对训练神经网络以逼近无符号距离场（UDF）用于三维重建中表示开放表面的方法越发感兴趣。然而，UDF在零级集处是非可微的，这会导致距离和梯度的显著误差，通常导致表面的碎片化和不连续性。在本文中，我们提出了学习无符号距离场的双曲缩放，这定义了一个具有不同边界条件的新调和问题。这使我们的模型能够无缝地集成到最先进的连续可微的隐式神经表示网络中，在文献中广泛应用于表示有符号距离场。我们的方法不仅能够解决开放表面表示的挑战，还在重建质量和训练性能方面表现出显著改进。另外，该方法解锁了...

    arXiv:2402.08876v1 Announce Type: cross Abstract: In recent years, there has been a growing interest in training Neural Networks to approximate Unsigned Distance Fields (UDFs) for representing open surfaces in the context of 3D reconstruction. However, UDFs are non-differentiable at the zero level set which leads to significant errors in distances and gradients, generally resulting in fragmented and discontinuous surfaces. In this paper, we propose to learn a hyperbolic scaling of the unsigned distance field, which defines a new Eikonal problem with distinct boundary conditions. This allows our formulation to integrate seamlessly with state-of-the-art continuously differentiable implicit neural representation networks, largely applied in the literature to represent signed distance fields. Our approach not only addresses the challenge of open surface representation but also demonstrates significant improvement in reconstruction quality and training performance. Moreover, the unlocked fi
    
[^91]: ScamSpot：在Instagram评论中打击金融欺诈

    ScamSpot: Fighting Financial Fraud in Instagram Comments

    [https://arxiv.org/abs/2402.08869](https://arxiv.org/abs/2402.08869)

    ScamSpot是一个在Instagram评论中打击金融欺诈的综合系统，包括浏览器扩展、BERT模型和REST API。通过数据注释研究和用户反馈，该系统解决了现有模型在实际应用中的不足，并公开提供给广大用户使用。

    

    Instagram金融页面评论区存在着垃圾信息和欺诈信息的长期问题，每天都有新受害者。Instagram当前的垃圾邮件过滤器效果不佳，现有的研究方法主要限于理论概念，缺乏实际实现和评估结果。为了解决这个问题，我们提出了ScamSpot，一个综合的系统，包括一个浏览器扩展程序，一个经过优化的BERT模型和一个REST API。这个方法确保使用Chrome浏览器的Instagram用户可以公开访问我们的结果。此外，我们进行了数据注释研究，揭示了问题的原因和原因，并通过用户反馈和与现有模型的比较来评估系统。ScamSpot是一个开源项目，可以在https://scamspot.github.io/上公开访问。

    arXiv:2402.08869v1 Announce Type: new Abstract: The long-standing problem of spam and fraudulent messages in the comment sections of Instagram pages in the financial sector claims new victims every day. Instagram's current spam filter proves inadequate, and existing research approaches are primarily confined to theoretical concepts. Practical implementations with evaluated results are missing. To solve this problem, we propose ScamSpot, a comprehensive system that includes a browser extension, a fine-tuned BERT model and a REST API. This approach ensures public accessibility of our results for Instagram users using the Chrome browser. Furthermore, we conduct a data annotation study, shedding light on the reasons and causes of the problem and evaluate the system through user feedback and comparison with existing models. ScamSpot is an open-source project and is publicly available at https://scamspot.github.io/.
    
[^92]: 基于图卷积的大规模语言模型用于推荐系统

    Large Language Model with Graph Convolution for Recommendation

    [https://arxiv.org/abs/2402.08859](https://arxiv.org/abs/2402.08859)

    本论文提出了一种基于图卷积的大规模语言模型用于推荐系统，该方法充分利用了用户-物品图中的高阶关系，以提高描述的准确性和一致性。

    

    近年来，人们一直致力于利用文本信息来改善推荐系统中的用户画像和物品描述。然而，文本信息有时质量较低，限制了其在真实世界应用中的效果。将大规模语言模型（LLM）的知识和推理能力用于描述改进成为一种有前景的方法。然而，现有的使用原始文本提示LLM的方法忽略了用户-物品交互的结构化知识，可能导致生成不一致描述的幻觉问题。为此，我们提出了一种基于图的卷积LLM方法，以引导LLM捕捉用户-物品图中的高阶关系。为了使文本为基础的LLM适应结构化图，我们将LLM作为图处理中的聚合器，使其逐步理解基于图的信息。具体地，需要LLM进行描述改进以便更好地进行推荐。

    arXiv:2402.08859v1 Announce Type: new Abstract: In recent years, efforts have been made to use text information for better user profiling and item characterization in recommendations. However, text information can sometimes be of low quality, hindering its effectiveness for real-world applications. With knowledge and reasoning capabilities capsuled in Large Language Models (LLMs), utilizing LLMs emerges as a promising way for description improvement. However, existing ways of prompting LLMs with raw texts ignore structured knowledge of user-item interactions, which may lead to hallucination problems like inconsistent description generation. To this end, we propose a Graph-aware Convolutional LLM method to elicit LLMs to capture high-order relations in the user-item graph. To adapt text-based LLMs with structured graphs, We use the LLM as an aggregator in graph processing, allowing it to understand graph-based information step by step. Specifically, the LLM is required for description e
    
[^93]: GhostWriter:通过个性化和代理增强协作人工智能写作体验

    GhostWriter: Augmenting Collaborative Human-AI Writing Experiences Through Personalization and Agency

    [https://arxiv.org/abs/2402.08855](https://arxiv.org/abs/2402.08855)

    GhostWriter是一个AI增强的写作设计探针，通过个性化和代理增强用户的写作体验。它利用大型语言模型（LLMs）隐式学习用户的写作风格，并允许用户通过手动样式编辑和批注来控制系统的写作风格。

    

    大型语言模型（LLMs）在提供不同形式的写作辅助方面越来越流行，并且具有无处不在的应用。然而，由于个性化和控制能力有限，LLM驱动的写作系统可能会使用户感到沮丧，当用户缺乏提示工程经验时，这种情况可能加剧。我们认为设计可以解决这些挑战之一，并引入GhostWriter，这是一个AI增强的写作设计探针，用户可以通过增强的代理和个性化来进行写作。GhostWriter利用LLMs在用户编写的过程中隐式学习用户所期望的写作风格，同时允许通过手动样式编辑和批注进行显式教学。我们研究了18名参与者在两个不同的写作任务中使用GhostWriter，观察到它帮助用户编写个性化的文本生成，并通过提供多种方式控制系统的写作风格来增强用户的能力。从这项研究中，我们提出了一些见解。

    arXiv:2402.08855v1 Announce Type: cross Abstract: Large language models (LLMs) are becoming more prevalent and have found a ubiquitous use in providing different forms of writing assistance. However, LLM-powered writing systems can frustrate users due to their limited personalization and control, which can be exacerbated when users lack experience with prompt engineering. We see design as one way to address these challenges and introduce GhostWriter, an AI-enhanced writing design probe where users can exercise enhanced agency and personalization. GhostWriter leverages LLMs to learn the user's intended writing style implicitly as they write, while allowing explicit teaching moments through manual style edits and annotations. We study 18 participants who use GhostWriter on two different writing tasks, observing that it helps users craft personalized text generations and empowers them by providing multiple ways to control the system's writing style. From this study, we present insights re
    
[^94]: 混合逆强化学习

    Hybrid Inverse Reinforcement Learning

    [https://arxiv.org/abs/2402.08848](https://arxiv.org/abs/2402.08848)

    本文提出使用混合强化学习的方法来减少逆强化学习中的不必要探索，通过在在线数据和专家数据的混合上进行训练，从而提高学习效率。

    

    对于模仿学习来说，逆强化学习方法是一把双刃剑。一方面，它可以通过较少的专家演示来进行学习，并且能够比行为克隆方法更具鲁棒性地处理错误累积。另一方面，它要求学习者反复解决计算代价高昂的强化学习问题。通常情况下，这种计算往往会浪费在搜索非常不相似于专家策略的策略上。在这项工作中，我们提出使用混合强化学习-在在线数据和专家数据的混合上进行训练-以减少不必要的探索。直观上，专家数据在训练过程中将学习者专注于良好的状态，从而减少了计算强策略所需的探索量。值得注意的是，这种方法不需要将学习者重置到环境中的任意状态，这是以前在高效逆强化学习中的要求。

    arXiv:2402.08848v1 Announce Type: cross Abstract: The inverse reinforcement learning approach to imitation learning is a double-edged sword. On the one hand, it can enable learning from a smaller number of expert demonstrations with more robustness to error compounding than behavioral cloning approaches. On the other hand, it requires that the learner repeatedly solve a computationally expensive reinforcement learning (RL) problem. Often, much of this computation is wasted searching over policies very dissimilar to the expert's. In this work, we propose using hybrid RL -- training on a mixture of online and expert data -- to curtail unnecessary exploration. Intuitively, the expert data focuses the learner on good states during training, which reduces the amount of exploration required to compute a strong policy. Notably, such an approach doesn't need the ability to reset the learner to arbitrary states in the environment, a requirement of prior work in efficient inverse RL. More formal
    
[^95]: 一种具有强ASR能力的令人尴尬简单的LLM方法

    An Embarrassingly Simple Approach for LLM with Strong ASR Capacity

    [https://arxiv.org/abs/2402.08846](https://arxiv.org/abs/2402.08846)

    本文提出了一种简单组合的LLM方法，由语音编码器、LLM和线性投影器组成，能够胜任ASR任务，并且具有清晰的设置和少量的任务特定设计。

    

    在本文中，我们将重点放在解决语音处理领域中最重要的任务之一，即使用语音基本编码器和大型语言模型（LLM）进行自动语音识别（ASR）。最近的研究采用了复杂的设计，例如对语音编码器进行时间压缩，处理投影仪的模态对齐，并利用参数高效的微调方法对LLM进行调整。我们发现，并不需要精细的设计，而是一个由现成的语音编码器、LLM和唯一可训练的线性投影器组成的简单组合就能胜任ASR任务。具体而言，我们对各种LLM和语音编码器的组合进行基准测试和探索，从而得到了最佳的基于LLM的ASR系统，我们将其称为SLAM-ASR。所提出的SLAM-ASR提供了一个清晰的设置和少量的任务特定设计，只有线性投影器需要进行训练。据我们所知，SLAM-ASR取得了最佳的性能。

    arXiv:2402.08846v1 Announce Type: cross Abstract: In this paper, we focus on solving one of the most important tasks in the field of speech processing, i.e., automatic speech recognition (ASR), with speech foundation encoders and large language models (LLM). Recent works have complex designs such as compressing the output temporally for the speech encoder, tackling modal alignment for the projector, and utilizing parameter-efficient fine-tuning for the LLM. We found that delicate designs are not necessary, while an embarrassingly simple composition of off-the-shelf speech encoder, LLM, and the only trainable linear projector is competent for the ASR task. To be more specific, we benchmark and explore various combinations of LLMs and speech encoders, leading to the optimal LLM-based ASR system, which we call SLAM-ASR. The proposed SLAM-ASR provides a clean setup and little task-specific design, where only the linear projector is trained. To the best of our knowledge, SLAM-ASR achieves t
    
[^96]: 考虑N2O排放和气候变异的智能农业管理

    Intelligent Agricultural Management Considering N$_2$O Emission and Climate Variability with Uncertainties

    [https://arxiv.org/abs/2402.08832](https://arxiv.org/abs/2402.08832)

    本研究利用人工智能和机器学习技术，特别是强化学习和递归神经网络，以及概率性建模方法，开发了一种智能农业管理系统，可以提高作物产量，优化肥料和水的使用，同时减少氮肥流失和温室气体排放，特别关注氧化亚氮（N2O）排放。

    

    本研究探讨了如何利用人工智能（AI），特别是强化学习（RL），在农业中提高作物产量，优化氮肥使用和浇水，并减少硝酸盐流失和温室气体排放，重点关注土壤中的氧化亚氮（N2O）排放。面对气候变化和有限的农业知识，我们使用部分可观察的马尔可夫决策过程（POMDPs）和作物模拟器来模拟AI代理与农业环境的交互。我们采用基于递归神经网络（RNN）的Q网络对智能代理进行深度Q学习训练。同时，我们开发机器学习（ML）模型来预测N2O排放，并将这些预测整合到模拟器中。我们的研究通过概率性机器学习方法处理N2O排放估计的不确定性，并通过随机天气模型处理气候变异，提供一系列排放结果来提高预测可靠性。

    arXiv:2402.08832v1 Announce Type: cross Abstract: This study examines how artificial intelligence (AI), especially Reinforcement Learning (RL), can be used in farming to boost crop yields, fine-tune nitrogen use and watering, and reduce nitrate runoff and greenhouse gases, focusing on Nitrous Oxide (N$_2$O) emissions from soil. Facing climate change and limited agricultural knowledge, we use Partially Observable Markov Decision Processes (POMDPs) with a crop simulator to model AI agents' interactions with farming environments. We apply deep Q-learning with Recurrent Neural Network (RNN)-based Q networks for training agents on optimal actions. Also, we develop Machine Learning (ML) models to predict N$_2$O emissions, integrating these predictions into the simulator. Our research tackles uncertainties in N$_2$O emission estimates with a probabilistic ML approach and climate variability through a stochastic weather model, offering a range of emission outcomes to improve forecast reliabili
    
[^97]: eCeLLM：从大规模高质量指导数据中将大型语言模型推广到电子商务中

    eCeLLM: Generalizing Large Language Models for E-commerce from Large-scale, High-quality Instruction Data

    [https://arxiv.org/abs/2402.08831](https://arxiv.org/abs/2402.08831)

    本文利用开源的大规模高质量指导数据集ECInstruct，通过指导调优通用语言模型，开发了一系列电子商务LLMs（eCeLLM），在电子商务中表现出了显著的优势。

    

    通过在开发有效的电子商务模型方面做出巨大努力，传统的电子商务模型在通用电子商务建模上取得了有限的成功，并且在新用户和新产品上的表现不佳——这是一个典型的领域外泛化挑战。与此同时，大型语言模型(LLMs)在许多领域展示出了出色的通用建模和领域外泛化能力。为了充分发挥它们在电子商务中的作用，本文构建了ECInstruct，这是第一个面向电子商务的开源、大规模和高质量的指导数据集。利用ECInstruct，我们通过指导调优通用语言模型开发了一系列电子商务LLMs，称为eCeLLM。我们的综合实验和评估表明，eCeLLM模型在内部环境中明显优于基准模型，包括最先进的GPT-4和最先进的特定任务模型。

    arXiv:2402.08831v1 Announce Type: cross Abstract: With tremendous efforts on developing effective e-commerce models, conventional e-commerce models show limited success in generalist e-commerce modeling, and suffer from unsatisfactory performance on new users and new products - a typical out-of-domain generalization challenge. Meanwhile, large language models (LLMs) demonstrate outstanding performance in generalist modeling and out-of-domain generalizability in many fields. Toward fully unleashing their power for e-commerce, in this paper, we construct ECInstruct, the first open-sourced, large-scale, and high-quality benchmark instruction dataset for e-commerce. Leveraging ECInstruct, we develop eCeLLM, a series of e-commerce LLMs, by instruction-tuning general-purpose LLMs. Our comprehensive experiments and evaluation demonstrate that eCeLLM models substantially outperform baseline models, including the most advanced GPT-4, and the state-of-the-art task-specific models in in-domain ev
    
[^98]: 智能画布: 通过快速原型设计、迭代和管理实现类似设计的探索性可视数据分析

    Intelligent Canvas: Enabling Design-Like Exploratory Visual Data Analysis through Rapid Prototyping, Iteration and Curation

    [https://arxiv.org/abs/2402.08812](https://arxiv.org/abs/2402.08812)

    该论文提出了一种"类似设计"的智能画布环境，通过将生成式AI组件集成到数据分析中，实现了快速原型设计、迭代和比较可视化管理。通过用户研究，论文验证了画布界面的有效性。

    

    复杂数据分析通过探索性的可视分析方法来寻求意想不到的洞见，并超越逻辑的逐步处理。然而，现有的界面（如笔记本和仪表板）在可视数据分析的探索和比较方面存在一些局限性。为了解决这些问题，我们介绍了一种“类似设计”的智能画布环境，将生成式AI集成到数据分析中，提供快速原型设计、迭代和比较可视化管理。我们的两个主要贡献包括将生成式AI组件集成到画布界面中，并通过用户研究（N=10）评估了画布界面的有效性。

    arXiv:2402.08812v1 Announce Type: cross Abstract: Complex data analysis inherently seeks unexpected insights through exploratory \re{visual analysis} methods, transcending logical, step-by-step processing. However, \re{existing interfaces such as notebooks and dashboards have limitations in exploration and comparison for visual data analysis}. Addressing these limitations, we introduce a "design-like" intelligent canvas environment integrating generative AI into data analysis, offering rapid prototyping, iteration, and comparative visualization management. Our dual contributions include the integration of generative AI components into a canvas interface, and empirical findings from a user study (N=10) evaluating the effectiveness of the canvas interface.
    
[^99]: 综合多个大型语言模型的见解可以提高诊断准确性

    Combining Insights From Multiple Large Language Models Improves Diagnostic Accuracy

    [https://arxiv.org/abs/2402.08806](https://arxiv.org/abs/2402.08806)

    本研究发现，综合多个不同的大型语言模型的响应可以提高鉴别诊断的准确性。

    

    背景：大型语言模型（LLMs）如OpenAI的GPT-4或Google的PaLM 2被提议作为可行的诊断支持工具，甚至被称为“路边咨询”的替代品。然而，即使特别针对医学主题进行训练的LLMs可能在实际应用中缺乏足够的诊断准确性。方法：使用集体智慧方法和200个真实病例的临床情境数据集，我们评估并比较了通过询问单个商业LLMs（OpenAI GPT-4、Google PaLM 2、Cohere Command、Meta Llama 2）获得的鉴别诊断的准确性与通过聚合相同LLMs的响应获得的鉴别诊断的准确性。

    arXiv:2402.08806v1 Announce Type: new Abstract: Background: Large language models (LLMs) such as OpenAI's GPT-4 or Google's PaLM 2 are proposed as viable diagnostic support tools or even spoken of as replacements for "curbside consults". However, even LLMs specifically trained on medical topics may lack sufficient diagnostic accuracy for real-life applications.   Methods: Using collective intelligence methods and a dataset of 200 clinical vignettes of real-life cases, we assessed and compared the accuracy of differential diagnoses obtained by asking individual commercial LLMs (OpenAI GPT-4, Google PaLM 2, Cohere Command, Meta Llama 2) against the accuracy of differential diagnoses synthesized by aggregating responses from combinations of the same LLMs.   Results: We find that aggregating responses from multiple, various LLMs leads to more accurate differential diagnoses (average accuracy for 3 LLMs: $75.3\%\pm 1.6pp$) compared to the differential diagnoses produced by single LLMs (aver
    
[^100]: ChatGPT与LLaMA在Stack Overflow讨论中的影响，可靠性和挑战

    ChatGPT vs LLaMA: Impact, Reliability, and Challenges in Stack Overflow Discussions

    [https://arxiv.org/abs/2402.08801](https://arxiv.org/abs/2402.08801)

    这篇论文通过对Stack Overflow问题的分析，研究了ChatGPT和LLaMA对于该平台的影响和可靠性，以及它们在长期内取代Stack Overflow的挑战。研究结果表明，LLMs在某些方面失败，并提供了对比LLMs的实证比较。

    

    自2022年11月发布以来，ChatGPT已经在Stack Overflow上引起轰动，这是开发人员关于编程和软件开发问题的首选平台。ChatGPT展示了生成即时、人类般回答技术问题的能力，引起了开发者社区对人工智能生成时代下人类驱动平台演变角色的辩论。ChatGPT发布两个月后，Meta发布了它自己的大型语言模型(LLM) LLaMA。为了 (i) 测量用户对Stack Overflow的时间演进下的参与程度；(ii) 量化LLMs回答的可靠性及其在长期内取代Stack Overflow的潜力；(iii) 确定和理解LLMs失败的原因；(iv) 对比LLMs。我们进行了实证研究，分析Stack Overflow上的问题，并使用这些LLMs来回答问题。

    arXiv:2402.08801v1 Announce Type: cross Abstract: Since its release in November 2022, ChatGPT has shaken up Stack Overflow, the premier platform for developers' queries on programming and software development. Demonstrating an ability to generate instant, human-like responses to technical questions, ChatGPT has ignited debates within the developer community about the evolving role of human-driven platforms in the age of generative AI. Two months after ChatGPT's release, Meta released its answer with its own Large Language Model (LLM) called LLaMA: the race was on. We conducted an empirical study analyzing questions from Stack Overflow and using these LLMs to address them. This way, we aim to (ii) measure user engagement evolution with Stack Overflow over time; (ii) quantify the reliability of LLMs' answers and their potential to replace Stack Overflow in the long term; (iii) identify and understand why LLMs fails; and (iv) compare LLMs together. Our empirical results are unequivocal: C
    
[^101]: 在资源有限的环境中利用咳嗽声音优化胸部X射线的使用

    Leveraging cough sounds to optimize chest x-ray usage in low-resource settings

    [https://arxiv.org/abs/2402.08789](https://arxiv.org/abs/2402.08789)

    通过分析咳嗽声音，我们开发了三种模型，可以在胸部X射线中预测异常结果，从而优化资源使用并提高医疗效率。

    

    胸部X射线在急诊、诊断和呼吸系统疾病管理中是常用的工具。在资源受限的环境下，优化这一资源可以为医疗保健系统和患者节省宝贵的费用，同时改善咨询时间。我们使用印度比哈尔邦普尔尼亚基督医学中心和医院（CMCH）的137名患者的前瞻性收集的数据。每个患者在等待进行放射照相时提供了至少五个咳嗽声。我们使用声学人工智能方法分析了收集到的咳嗽声音。对每个患者的咳嗽声音进行了时间和频谱特征的交叉验证。使用标准统计方法对特征进行了总结。我们开发、测试和比较了三种模型，以预测胸部X射线的异常结果。这三种方法均能在一定程度上区分正常和异常结果。

    arXiv:2402.08789v1 Announce Type: cross Abstract: Chest X-ray is a commonly used tool during triage, diagnosis and management of respiratory diseases. In resource-constricted settings, optimizing this resource can lead to valuable cost savings for the health care system and the patients as well as to and improvement in consult time. We used prospectively-collected data from 137 patients referred for chest X-ray at the Christian Medical Center and Hospital (CMCH) in Purnia, Bihar, India. Each patient provided at least five coughs while awaiting radiography. Collected cough sounds were analyzed using acoustic AI methods. Cross-validation was done on temporal and spectral features on the cough sounds of each patient. Features were summarized using standard statistical approaches. Three models were developed, tested and compared in their capacity to predict an abnormal result in the chest X-ray. All three methods yielded models that could discriminate to some extent between normal and abno
    
[^102]: 增强的二维自动驾驶车辆的深度Q学习：在自定义赛道环境中的实现与评估

    Enhanced Deep Q-Learning for 2D Self-Driving Cars: Implementation and Evaluation on a Custom Track Environment

    [https://arxiv.org/abs/2402.08780](https://arxiv.org/abs/2402.08780)

    本研究实现了在自定义二维赛道上进行深度Q学习的自动驾驶车辆，并通过优化算法提高了DQN网络的性能。

    

    本研究项目介绍了在二维自定义赛道上实现深度Q学习网络（DQN）用于自动驾驶车辆的方法，并旨在提高DQN网络的性能。该项目包括使用Pygame开发自定义驾驶环境以及设计和实现DQN模型。算法利用汽车上安装的7个传感器收集汽车与赛道之间的距离数据。这些传感器位于车辆前方，间隔20度，能够感知前方广阔区域。我们成功实现了DQN，还实现了一个基于优先级的动作选择机制的修改版DQN，我们称之为修改版DQN。模型经过1000个回合的训练，发现代理程序平均奖励约为40，比普通DQN高约60%。

    arXiv:2402.08780v1 Announce Type: new Abstract: This research project presents the implementation of a Deep Q-Learning Network (DQN) for a self-driving car on a 2-dimensional (2D) custom track, with the objective of enhancing the DQN network's performance. It encompasses the development of a custom driving environment using Pygame on a track surrounding the University of Memphis map, as well as the design and implementation of the DQN model. The algorithm utilizes data from 7 sensors installed in the car, which measure the distance between the car and the track. These sensors are positioned in front of the vehicle, spaced 20 degrees apart, enabling them to sense a wide area ahead. We successfully implemented the DQN and also a modified version of the DQN with a priority-based action selection mechanism, which we refer to as modified DQN. The model was trained over 1000 episodes, and the average reward received by the agent was found to be around 40, which is approximately 60% higher th
    
[^103]: DNABERT-S: 学习具有基因组基础模型的物种感知DNA嵌入

    DNABERT-S: Learning Species-Aware DNA Embedding with Genome Foundation Models

    [https://arxiv.org/abs/2402.08777](https://arxiv.org/abs/2402.08777)

    DNABERT-S是一种专门用于创建物种感知的DNA嵌入的基因组基础模型。为了提高对长读DNA序列的嵌入效果，引入了Manifold Instance Mixup (MI-Mix)对比目标方法来训练模型。

    

    有效的DNA嵌入在基因组分析中仍然至关重要，特别是在缺乏用于模型微调的标记数据的情况下，尽管基因组基础模型已经取得了显著进展。一个典型的例子是宏基因组分箱，这是微生物组研究中的一个关键过程，旨在通过来自可能包含成千上万个不同的、通常没有经过表征的物种的复杂混合DNA序列的物种来对DNA序列进行分组。为了填补有效的DNA嵌入模型的缺陷，我们引入了DNABERT-S，这是一个专门用于创建物种感知的DNA嵌入的基因组基础模型。为了鼓励对易出错的长读DNA序列进行有效嵌入，我们引入了Manifold Instance Mixup(MI-Mix)，一种对比目标，它在随机选择的层次中混合DNA序列的隐藏表示，并训练模型以在输出层识别和区分这些混合比例。

    arXiv:2402.08777v1 Announce Type: cross Abstract: Effective DNA embedding remains crucial in genomic analysis, particularly in scenarios lacking labeled data for model fine-tuning, despite the significant advancements in genome foundation models. A prime example is metagenomics binning, a critical process in microbiome research that aims to group DNA sequences by their species from a complex mixture of DNA sequences derived from potentially thousands of distinct, often uncharacterized species. To fill the lack of effective DNA embedding models, we introduce DNABERT-S, a genome foundation model that specializes in creating species-aware DNA embeddings. To encourage effective embeddings to error-prone long-read DNA sequences, we introduce Manifold Instance Mixup (MI-Mix), a contrastive objective that mixes the hidden representations of DNA sequences at randomly selected layers and trains the model to recognize and differentiate these mixed proportions at the output layer. We further enha
    
[^104]: 使用基于冲突的搜索和先决和时间约束的最优任务分配和路径规划

    Optimal Task Assignment and Path Planning using Conflict-Based Search with Precedence and Temporal Constraints

    [https://arxiv.org/abs/2402.08772](https://arxiv.org/abs/2402.08772)

    本文研究了任务分配和路径规划问题，并提出了一种使用基于冲突的搜索方法解决具有先决和时间约束的任务分配和路径规划问题，最大化用户定义的指标的回报。

    

    多智能体路径规划（MAPF）问题涉及为一组智能体找到无碰撞路径，引导它们从起点到目标位置。然而，MAPF没有考虑几个实际的任务相关约束。例如，智能体可能需要在目标位置执行具有特定执行时间的动作，遵循预定的顺序和时间框架。此外，目标分配可能不是预先定义的，优化目标可能缺乏明确定义。为了将任务分配、路径规划和用户定义的目标结合成一个连贯的框架，本文研究了具有先决和时间约束的任务分配和路径规划（TAPF-PTC）问题。我们增加了基于冲突的搜索（CBS）以同时生成遵守先决和时间约束的任务分配和无碰撞路径，并最大化基于用户定义的指标的回报。

    arXiv:2402.08772v1 Announce Type: new Abstract: The Multi-Agent Path Finding (MAPF) problem entails finding collision-free paths for a set of agents, guiding them from their start to goal locations. However, MAPF does not account for several practical task-related constraints. For example, agents may need to perform actions at goal locations with specific execution times, adhering to predetermined orders and timeframes. Moreover, goal assignments may not be predefined for agents, and the optimization objective may lack an explicit definition. To incorporate task assignment, path planning, and a user-defined objective into a coherent framework, this paper examines the Task Assignment and Path Finding with Precedence and Temporal Constraints (TAPF-PTC) problem. We augment Conflict-Based Search (CBS) to simultaneously generate task assignments and collision-free paths that adhere to precedence and temporal constraints, maximizing an objective quantified by the return from a user-defined r
    
[^105]: JAMDEC：使用小型语言模型进行有约束解码的无监督作者身份混淆

    JAMDEC: Unsupervised Authorship Obfuscation using Constrained Decoding over Small Language Models

    [https://arxiv.org/abs/2402.08761](https://arxiv.org/abs/2402.08761)

    提出了一种无监督的作者身份混淆方法，通过使用小型语言模型实现，可以在保持原始内容和流畅性的同时混淆作者身份。

    

    随着增强的作者身份识别技术和在线内容的永久性，需要更强的计算方法来保护在线作者身份的隐私，例如科学论文的盲审、匿名在线评论或在心理健康论坛上的匿名互动。本文提出了一种无监督的推理时间作者身份混淆方法，以解决作者身份混淆的独特挑战：缺乏多样化的作者身份和领域的监督数据，以及在混淆作者身份的同时保持原始内容和流畅性的需要。

    arXiv:2402.08761v1 Announce Type: cross Abstract: The permanence of online content combined with the enhanced authorship identification techniques calls for stronger computational methods to protect the identity and privacy of online authorship when needed, e.g., blind reviews for scientific papers, anonymous online reviews, or anonymous interactions in the mental health forums. In this paper, we propose an unsupervised inference-time approach to authorship obfuscation to address the unique challenges of authorship obfuscation: lack of supervision data for diverse authorship and domains, and the need for a sufficient level of revision beyond simple paraphrasing to obfuscate the authorship, all the while preserving the original content and fluency.   We introduce JAMDEC, a user-controlled, inference-time algorithm for authorship obfuscation that can be in principle applied to any text and authorship. Our approach builds on small language models such as GPT2-XL in order to help avoid dis
    
[^106]: LLM驱动的模拟亚理性行为：幻觉还是现实？

    LLM-driven Imitation of Subrational Behavior : Illusion or Reality?

    [https://arxiv.org/abs/2402.08755](https://arxiv.org/abs/2402.08755)

    本文探讨了使用LLMs生成合成人类演示的方法，然后通过模仿学习来学习亚理性代理策略，从而模拟亚理性行为，并为我们理解人类行为提供了改进的可能性。

    

    建模亚理性代理，如人类或经济家庭，由于校准强化学习模型的困难或收集涉及人类主体的数据的难度而具有挑战性。现有研究强调了大型语言模型（LLMs）解决复杂推理任务和模仿人类交流的能力，而使用LLMs作为代理进行模拟显示出出现的社交行为，可能提高我们对人类行为的理解。在本文中，我们提议研究使用LLMs生成合成的人类演示，然后通过模仿学习来学习亚理性代理策略。我们假设LLMs可以用作人类的隐式计算模型，并提出了一个框架，使用从LLMs派生的合成演示来建模人类特有的亚理性行为（例如，目光短浅的行为或对风险规避的偏好）。我们进行了实验证明:

    arXiv:2402.08755v1 Announce Type: new Abstract: Modeling subrational agents, such as humans or economic households, is inherently challenging due to the difficulty in calibrating reinforcement learning models or collecting data that involves human subjects. Existing work highlights the ability of Large Language Models (LLMs) to address complex reasoning tasks and mimic human communication, while simulation using LLMs as agents shows emergent social behaviors, potentially improving our comprehension of human conduct. In this paper, we propose to investigate the use of LLMs to generate synthetic human demonstrations, which are then used to learn subrational agent policies though Imitation Learning. We make an assumption that LLMs can be used as implicit computational models of humans, and propose a framework to use synthetic demonstrations derived from LLMs to model subrational behaviors that are characteristic of humans (e.g., myopic behavior or preference for risk aversion). We experim
    
[^107]: PRDP：大规模扩散模型的近端奖励差异预测用于奖励微调

    PRDP: Proximal Reward Difference Prediction for Large-Scale Reward Finetuning of Diffusion Models

    [https://arxiv.org/abs/2402.08714](https://arxiv.org/abs/2402.08714)

    本研究提出了PRDP方法，通过近端奖励差异预测实现了稳定的黑盒奖励微调扩散模型，能够在大规模提示数据集上进行训练，并且具有更好的训练稳定性。

    

    奖励微调已成为将基础模型与下游目标对齐的一种有前途的方法。在语言领域，使用强化学习（RL）来最大化反映人类偏好的奖励已取得了显著的成功。然而，在视觉领域，现有的基于RL的奖励微调方法在大规模训练中存在不稳定性，使它们无法推广到复杂的、未知的提示。在本文中，我们提出了近端奖励差异预测（PRDP），首次在超过100K个提示的大规模提示数据集上实现了稳定的黑盒奖励微调扩散模型。我们的主要创新是奖励差异预测（RDP）目标，该目标与RL目标具有相同的最优解，同时享受更好的训练稳定性。

    arXiv:2402.08714v1 Announce Type: cross Abstract: Reward finetuning has emerged as a promising approach to aligning foundation models with downstream objectives. Remarkable success has been achieved in the language domain by using reinforcement learning (RL) to maximize rewards that reflect human preference. However, in the vision domain, existing RL-based reward finetuning methods are limited by their instability in large-scale training, rendering them incapable of generalizing to complex, unseen prompts. In this paper, we propose Proximal Reward Difference Prediction (PRDP), enabling stable black-box reward finetuning for diffusion models for the first time on large-scale prompt datasets with over 100K prompts. Our key innovation is the Reward Difference Prediction (RDP) objective that has the same optimal solution as the RL objective while enjoying better training stability. Specifically, the RDP objective is a supervised regression objective that tasks the diffusion model with pred
    
[^108]: 生成式人工智能在全新药物设计中的应用概述：分子和蛋白质生成的新领域

    A Survey of Generative AI for De Novo Drug Design: New Frontiers in Molecule and Protein Generation

    [https://arxiv.org/abs/2402.08703](https://arxiv.org/abs/2402.08703)

    这项综述提出了一个广义方法来驱动AI药物设计，重点关注小分子和蛋白质生成两个主要主题，介绍了各种子任务和应用，并比较了顶级模型的性能。

    

    人工智能（AI）驱动的方法可以极大地改进历来代价高昂的药物设计过程，各种生成模型已经在广泛使用中。特别是针对全新药物设计的生成模型，专注于从零开始创建新的生物化合物，展示了一个有前景的未来方向。该领域的快速发展，加上药物设计过程的固有复杂性，为新研究人员进入创造了一个困难的局面。在这份综述中，我们将全新药物设计分为两个主要主题：小分子和蛋白质生成。在每个主题中，我们确定了各种子任务和应用，重点介绍了重要的数据集、基准和模型架构，并对顶级模型的性能进行了比较。我们采用了广义的方法来驱动AI药物设计，允许在每个子任务中进行各种方法的微观比较和宏观比较。

    arXiv:2402.08703v1 Announce Type: cross Abstract: Artificial intelligence (AI)-driven methods can vastly improve the historically costly drug design process, with various generative models already in widespread use. Generative models for de novo drug design, in particular, focus on the creation of novel biological compounds entirely from scratch, representing a promising future direction. Rapid development in the field, combined with the inherent complexity of the drug design process, creates a difficult landscape for new researchers to enter. In this survey, we organize de novo drug design into two overarching themes: small molecule and protein generation. Within each theme, we identify a variety of subtasks and applications, highlighting important datasets, benchmarks, and model architectures and comparing the performance of top models. We take a broad approach to AI-driven drug design, allowing for both micro-level comparisons of various methods within each subtask and macro-level o
    
[^109]: PRompt Optimization in Multi-Step Tasks (PROMST): Integrating Human Feedback and Preference Alignment

    PRompt Optimization in Multi-Step Tasks (PROMST): Integrating Human Feedback and Preference Alignment

    [https://arxiv.org/abs/2402.08702](https://arxiv.org/abs/2402.08702)

    该论文介绍了一种在多步任务中集成人类反馈和偏好对齐的PRompt优化方法。它使用遗传算法框架，结合人类反馈自动提出优化建议并解决了复杂的提示内容分析、单步评估和任务执行偏好的挑战。

    

    Prompt optimization aims to find the best prompt for a language model (LLM) in multi-step tasks. This paper introduces a genetic algorithm framework that incorporates human feedback to automatically suggest prompt improvements. It addresses challenges such as complex prompt content analysis, evaluation of individual steps, and variations in task execution preferences.

    arXiv:2402.08702v1 Announce Type: cross Abstract: Prompt optimization aims to find the best prompt to a large language model (LLM) for a given task. LLMs have been successfully used to help find and improve prompt candidates for single-step tasks. However, realistic tasks for agents are multi-step and introduce new challenges: (1) Prompt content is likely to be more extensive and complex, making it more difficult for LLMs to analyze errors, (2) the impact of an individual step is difficult to evaluate, and (3) different people may have varied preferences about task execution. While humans struggle to optimize prompts, they are good at providing feedback about LLM outputs; we therefore introduce a new LLM-driven discrete prompt optimization framework that incorporates human-designed feedback rules about potential errors to automatically offer direct suggestions for improvement. Our framework is stylized as a genetic algorithm in which an LLM generates new candidate prompts from a parent
    
[^110]: 如果图灵和一个人工伙伴一起弹钢琴

    If Turing played piano with an artificial partner

    [https://arxiv.org/abs/2402.08690](https://arxiv.org/abs/2402.08690)

    本研究调查了通过训练生成模型来生成音乐乐谱是否可以实现令人信服的社交体验，而无需优化其同步和延续能力。

    

    音乐是一种天生的社交活动，允许人们分享体验并与彼此产生连接。设计实现与与另一个人一起演奏类似的社交体验的人工伙伴方面的进展很小。实现生成模型的神经网络架构，如大型语言模型，适合生成音乐乐谱。然而，社交性的音乐演奏不仅仅是演奏一个乐谱；它必须与其他音乐家的想法相协调，并正确保持时间。我们探讨了一个问题，即通过训练用于生成音乐乐谱的生成模型是否能够产生令人信服的社交体验，而不必优化其同步和延续能力。该网络是在大量数字乐谱语料库上训练的变分自动编码器，在与人类伙伴进行定时的问答任务中进行了适应。参与者与人类或人工伙伴一起弹奏钢琴。

    arXiv:2402.08690v1 Announce Type: cross Abstract: Music is an inherently social activity that allows people to share experiences and feel connected with one another. There has been little progress in designing artificial partners exhibiting a similar social experience as playing with another person. Neural network architectures that implement generative models, such as large language models, are suited for producing musical scores. Playing music socially, however, involves more than playing a score; it must complement the other musicians' ideas and keep time correctly. We addressed the question of whether a convincing social experience is made possible by a generative model trained to produce musical scores, not necessarily optimized for synchronization and continuation. The network, a variational autoencoder trained on a large corpus of digital scores, was adapted for a timed call-and-response task with a human partner. Participants played piano with a human or artificial partner-in v
    
[^111]: 分析提示对自动生成方法的影响：一个基于Copilot的实证研究

    Analyzing Prompt Influence on Automated Method Generation: An Empirical Study with Copilot

    [https://arxiv.org/abs/2402.08430](https://arxiv.org/abs/2402.08430)

    本文通过系统调查八个提示特征对生成的代码的影响，包括样式、内容、正确性、复杂性、大小和与开发者代码的相似性。

    

    arXiv:2402.08430v1 公告类型：交叉 生成型人工智能正在改变开发者与软件系统的交互方式，提供能够产生和传递新内容的服务，以满足开发者的实际需求。例如，开发者可以通过编写自然语言提示在其IDE中直接请求新代码，基于生成型人工智能的集成服务，如Copilot，会立即通过提供即可使用的代码片段来响应提示。恰当地编写提示，并在避免信息过载的同时融入有用信息，对于获取正确的代码片段可能是一个重要因素。设计好的提示的任务被称为提示工程。在本文中，我们系统地研究了八个提示特征对生成的代码的样式和内容、正确性、复杂性、大小和与开发者代码的相似性的影响。

    arXiv:2402.08430v1 Announce Type: cross Abstract: Generative AI is changing the way developers interact with software systems, providing services that can produce and deliver new content, crafted to satisfy the actual needs of developers. For instance, developers can ask for new code directly from within their IDEs by writing natural language prompts, and integrated services based on generative AI, such as Copilot, immediately respond to prompts by providing ready-to-use code snippets. Formulating the prompt appropriately, and incorporating the useful information while avoiding any information overload, can be an important factor in obtaining the right piece of code. The task of designing good prompts is known as prompt engineering. In this paper, we systematically investigate the influence of eight prompt features on the style and the content of prompts, on the level of correctness, complexity, size, and similarity to the developers' code of the generated code. We specifically conside
    
[^112]: ChatCell: 利用自然语言促进单细胞分析

    ChatCell: Facilitating Single-Cell Analysis with Natural Language

    [https://arxiv.org/abs/2402.08303](https://arxiv.org/abs/2402.08303)

    ChatCell是一个利用自然语言促进单细胞分析的工具，通过词汇适应和统一序列生成，它具备深厚的专业知识和适应各种分析任务的能力。

    

    随着大型语言模型(LLMs)的快速发展，它们在科学中的影响日益突出。LLMs在任务泛化和自由对话方面的新兴能力可以极大地推进化学和生物学等领域。然而，单细胞生物学这个构成生物体基础构件的领域仍面临一些挑战。当前方法在知识门槛和可扩展性方面存在限制，阻碍了LLMs在掌握单细胞数据方面的充分利用，影响了直接可访问和快速迭代的能力。为此，我们引入了ChatCell，通过利用词汇适应和统一序列生成，它在单细胞生物学领域获得了深厚的专业知识和适应各种分析任务的能力，标志着一种范式转变。

    As Large Language Models (LLMs) rapidly evolve, their influence in science is becoming increasingly prominent. The emerging capabilities of LLMs in task generalization and free-form dialogue can significantly advance fields like chemistry and biology. However, the field of single-cell biology, which forms the foundational building blocks of living organisms, still faces several challenges. High knowledge barriers and limited scalability in current methods restrict the full exploitation of LLMs in mastering single-cell data, impeding direct accessibility and rapid iteration. To this end, we introduce ChatCell, which signifies a paradigm shift by facilitating single-cell analysis with natural language. Leveraging vocabulary adaptation and unified sequence generation, ChatCell has acquired profound expertise in single-cell biology and the capability to accommodate a diverse range of analysis tasks. Extensive experiments further demonstrate ChatCell's robust performance and potential to de
    
[^113]: 研究GNN的超分布推广：从架构角度的视角

    Investigating Out-of-Distribution Generalization of GNNs: An Architecture Perspective

    [https://arxiv.org/abs/2402.08228](https://arxiv.org/abs/2402.08228)

    这项研究从架构的角度全面调查了图的超分布推广，揭示了图自我注意机制和其他常见构建模块在超分布问题上的影响。

    

    图神经网络（GNN）在测试数据来自于训练数据相同分布的假设下表现出了出色的性能。然而，在真实场景中，这个假设可能并不总是成立。因此，在图的上下文中，对超分布（OOD）问题的探索日益受到关注。大部分现有的研究主要集中在改进图的OOD推广的两个“模型无关”角度上：数据驱动方法和策略学习。然而，对于已知的GNN模型架构对图的OOD推广的影响的研究相对较少，这与现有的研究相互独立。在这项工作中，我们从架构的角度首次全面调查了图的OOD推广，并对现代GNN的常见构建模块进行了考察。通过大量实验，我们揭示了图自我注意机制和...

    Graph neural networks (GNNs) have exhibited remarkable performance under the assumption that test data comes from the same distribution of training data. However, in real-world scenarios, this assumption may not always be valid. Consequently, there is a growing focus on exploring the Out-of-Distribution (OOD) problem in the context of graphs. Most existing efforts have primarily concentrated on improving graph OOD generalization from two \textbf{model-agnostic} perspectives: data-driven methods and strategy-based learning. However, there has been limited attention dedicated to investigating the impact of well-known \textbf{GNN model architectures} on graph OOD generalization, which is orthogonal to existing research. In this work, we provide the first comprehensive investigation of OOD generalization on graphs from an architecture perspective, by examining the common building blocks of modern GNNs. Through extensive experiments, we reveal that both the graph self-attention mechanism an
    
[^114]: 人工智能与高等教育机构的转型

    Artificial intelligence and the transformation of higher education institutions

    [https://arxiv.org/abs/2402.08143](https://arxiv.org/abs/2402.08143)

    本研究采用复杂系统方法，以因果循环图的形式探讨了人工智能在典型高等教育机构中的转型。研究发现，高等教育机构受到人工智能技术进步的推动，投资于改善学生学习、研究和管理，并为此应对学术诚信问题和技术变化。

    

    人工智能（AI）的进步和ChatGPT等生成式AI工具的快速采用为高等教育带来了新的机遇和挑战。虽然大量的文献讨论了高等教育中的AI，但缺乏一个系统的方法来全面理解高等教育机构的AI转型。为了填补这一空白，本文采用复杂系统的方法，构建了一个因果循环图（CLD），以描述典型高等教育机构中AI转型的因果反馈机制。我们的模型考虑了推动AI转型的力量以及AI转型对典型高等教育机构价值创造的影响。本文识别和分析了几个增强和平衡的反馈循环，展示了高等教育机构在AI技术进步的推动下如何投资于改善学生学习、研究和管理。高等教育机构必须采取措施应对学术诚信问题并适应可用技术的变化。

    Artificial intelligence (AI) advances and the rapid adoption of generative AI tools like ChatGPT present new opportunities and challenges for higher education. While substantial literature discusses AI in higher education, there is a lack of a systemic approach that captures a holistic view of the AI transformation of higher education institutions (HEIs). To fill this gap, this article, taking a complex systems approach, develops a causal loop diagram (CLD) to map the causal feedback mechanisms of AI transformation in a typical HEI. Our model accounts for the forces that drive the AI transformation and the consequences of the AI transformation on value creation in a typical HEI. The article identifies and analyzes several reinforcing and balancing feedback loops, showing how, motivated by AI technology advances, the HEI invests in AI to improve student learning, research, and administration. The HEI must take measures to deal with academic integrity problems and adapt to changes in ava
    
[^115]: 广义化规划环境重新设计

    Generalising Planning Environment Redesign

    [https://arxiv.org/abs/2402.07799](https://arxiv.org/abs/2402.07799)

    本论文提出了一种广义化的规划环境重新设计方法，该方法能够不受度量影响，并能够适应不同的目标和指标。

    

    在环境设计中，一个感兴趣的方与另一个代理通过对环境进行改变来影响其决策。大部分关于规划环境重新设计的研究假设感兴趣的方的目标是促进目标和计划的识别，并在环境修改空间中搜索以找到简化这些任务并优化特定度量标准的最小一组变化。这个搜索空间通常难以处理，因此现有方法设计了度量相关的修剪技术以更高效地进行搜索。这导致方法无法在不同的目标和/或指标上进行泛化。在本文中，我们认为感兴趣的方的目标和指标不一定与识别代理的目标或计划相关。因此，为了广义化规划环境重新设计的任务，我们开发了一种通用的环境重新设计方法，该方法不受度量影响，并利用了最新的顶层研究成果。

    In Environment Design, one interested party seeks to affect another agent's decisions by applying changes to the environment. Most research on planning environment (re)design assumes the interested party's objective is to facilitate the recognition of goals and plans, and search over the space of environment modifications to find the minimal set of changes that simplify those tasks and optimise a particular metric. This search space is usually intractable, so existing approaches devise metric-dependent pruning techniques for performing search more efficiently. This results in approaches that are not able to generalise across different objectives and/or metrics. In this paper, we argue that the interested party could have objectives and metrics that are not necessarily related to recognising agents' goals or plans. Thus, to generalise the task of Planning Environment Redesign, we develop a general environment redesign approach that is metric-agnostic and leverages recent research on top
    
[^116]: 实现智能体、人类和环境之间的统一对齐

    Towards Unified Alignment Between Agents, Humans, and Environment

    [https://arxiv.org/abs/2402.07744](https://arxiv.org/abs/2402.07744)

    本文介绍了统一对齐原则 ($\mathbf{UA}^2$)，旨在实现智能体与人类意图、环境动态和自我约束的统一对齐，提出了引入实际特性进行概念验证研究的方法。

    

    基于基础模型的快速进展导致了自主智能体的繁荣，这些智能体利用基础模型的通用能力进行推理、决策和环境交互。然而，当在复杂、现实的环境中运行时，智能体的效能仍然有限。在本研究中，我们引入了统一对齐原则，即同时对齐智能体与人类意图、环境动态和自我约束（如货币预算限制）。从统一对齐 ($\mathbf{UA}^2$) 的视角出发，我们回顾了当前智能体研究的现状，并指出了现有智能体基准和方法候选中被忽视的因素。我们还通过为WebShop引入实际特性进行了概念验证研究，包括使用用户配置文件来展示意图、个性化重新排名以应对复杂的环境动态和运行时成本统计。

    The rapid progress of foundation models has led to the prosperity of autonomous agents, which leverage the universal capabilities of foundation models to conduct reasoning, decision-making, and environmental interaction. However, the efficacy of agents remains limited when operating in intricate, realistic environments. In this work, we introduce the principles of $\mathbf{U}$nified $\mathbf{A}$lignment for $\mathbf{A}$gents ($\mathbf{UA}^2$), which advocate for the simultaneous alignment of agents with human intentions, environmental dynamics, and self-constraints such as the limitation of monetary budgets. From the perspective of $\mathbf{UA}^2$, we review the current agent research and highlight the neglected factors in existing agent benchmarks and method candidates. We also conduct proof-of-concept studies by introducing realistic features to WebShop, including user profiles to demonstrate intentions, personalized reranking for complex environmental dynamics, and runtime cost stat
    
[^117]: 在线顺序决策中的未知延迟问题

    Online Sequential Decision-Making with Unknown Delays

    [https://arxiv.org/abs/2402.07703](https://arxiv.org/abs/2402.07703)

    本文提出了在在线顺序决策中处理未知延迟问题的三个延迟算法族，并提供了相应的遗憾界限。

    

    在在线顺序决策领域，我们利用在线凸优化（OCO）框架解决了具有延迟的问题，其中决策的反馈可能以未知延迟到达。与之前仅限于欧几里得范数和梯度信息的研究不同，我们提出了三个基于近似解的延迟算法族，处理不同类型的接收反馈。我们提出的算法是多功能且适用于通用范数。具体地，我们引入了一系列针对具有完整损失函数信息反馈的延迟规范化领导算法族，一系列针对具有梯度信息反馈的延迟镜像下降算法族，以及一系列针对相应决策点损失函数梯度值信息反馈的简化延迟镜像下降算法族。对于每种类型的算法，我们提供了相应的遗憾界限。

    In the field of online sequential decision-making, we address the problem with delays utilizing the framework of online convex optimization (OCO), where the feedback of a decision can arrive with an unknown delay. Unlike previous research that is limited to Euclidean norm and gradient information, we propose three families of delayed algorithms based on approximate solutions to handle different types of received feedback. Our proposed algorithms are versatile and applicable to universal norms. Specifically, we introduce a family of Follow the Delayed Regularized Leader algorithms for feedback with full information on the loss function, a family of Delayed Mirror Descent algorithms for feedback with gradient information on the loss function and a family of Simplified Delayed Mirror Descent algorithms for feedback with the value information of the loss function's gradients at corresponding decision points. For each type of algorithm, we provide corresponding regret bounds under cases of 
    
[^118]: 食物推荐作为语言处理（F-RLP）：个性化和情境化范式

    Food Recommendation as Language Processing (F-RLP): A Personalized and Contextual Paradigm

    [https://arxiv.org/abs/2402.07477](https://arxiv.org/abs/2402.07477)

    食物推荐作为语言处理（F-RLP）是一个针对食物的个性化、情境化的框架，利用大型语言模型的能力来实现更准确、个性化的食物推荐。

    

    目前最先进的基于规则和分类的食物推荐系统在实际应用和实用性方面面临着重大挑战。主要原因是大多数机器学习模型在一个几乎无限数量的类别和一个不平衡数据集中的有限样本问题上很难应对。相反，大型语言模型（LLM）作为推荐引擎的出现提供了一个有希望的途径。然而，一个通用的“作为语言处理的推荐”（RLP）方法缺乏有效的食物推荐所必需的关键组件。为了填补这一空白，我们引入了食物推荐作为语言处理（F-RLP），这是一个新颖的框架，提供了一个针对食物的定制基础设施。F-RLP利用LLMs的能力来最大化其潜力，从而为更准确、个性化的食物推荐铺平了道路。

    State-of-the-art rule-based and classification-based food recommendation systems face significant challenges in becoming practical and useful. This difficulty arises primarily because most machine learning models struggle with problems characterized by an almost infinite number of classes and a limited number of samples within an unbalanced dataset. Conversely, the emergence of Large Language Models (LLMs) as recommendation engines offers a promising avenue. However, a general-purpose Recommendation as Language Processing (RLP) approach lacks the critical components necessary for effective food recommendations. To address this gap, we introduce Food Recommendation as Language Processing (F-RLP), a novel framework that offers a food-specific, tailored infrastructure. F-RLP leverages the capabilities of LLMs to maximize their potential, thereby paving the way for more accurate, personalized food recommendations.
    
[^119]: Premier-TACO: 通过时间驱动的对比损失进行多任务表示预训练

    Premier-TACO: Pretraining Multitask Representation via Temporal Action-Driven Contrastive Loss

    [https://arxiv.org/abs/2402.06187](https://arxiv.org/abs/2402.06187)

    Premier-TACO是一种多任务特征表示学习方法，通过预训练通用特征表示，并引入负例抽样策略来提高时序行动对比学习的计算效率，从而显著增强了对新颖动作的少样本模仿学习的效果。

    

    我们提出了Premier-TACO，这是一种多任务特征表示学习方法，旨在提高顺序决策任务中少样本策略学习的效率。Premier-TACO利用一部分多任务离线数据集进行预训练通用特征表示，该特征表示捕捉了关键的环境动力学，并使用最少的专家演示进行微调。它通过引入一种新的负例抽样策略推动了时序行动对比学习（TACO）目标的发展，TACO在视觉控制任务中具有最先进的结果。这种策略在显著提高TACO的计算效率方面非常重要，使大规模多任务离线预训练成为可能。我们在包括Deepmind Control Suite、MetaWorld和LIBERO在内的各种连续控制基准测试中进行了广泛的实证评估，证明了Premier-TACO在预训练视觉表示方面的有效性，显著增强了对新颖动作的少样本模仿学习。

    We present Premier-TACO, a multitask feature representation learning approach designed to improve few-shot policy learning efficiency in sequential decision-making tasks. Premier-TACO leverages a subset of multitask offline datasets for pretraining a general feature representation, which captures critical environmental dynamics and is fine-tuned using minimal expert demonstrations. It advances the temporal action contrastive learning (TACO) objective, known for state-of-the-art results in visual control tasks, by incorporating a novel negative example sampling strategy. This strategy is crucial in significantly boosting TACO's computational efficiency, making large-scale multitask offline pretraining feasible. Our extensive empirical evaluation in a diverse set of continuous control benchmarks including Deepmind Control Suite, MetaWorld, and LIBERO demonstrate Premier-TACO's effectiveness in pretraining visual representations, significantly enhancing few-shot imitation learning of nove
    
[^120]: 开放理论-心灵（OpenToM）：评估大型语言模型的心灵理解能力的全面基准

    OpenToM: A Comprehensive Benchmark for Evaluating Theory-of-Mind Reasoning Capabilities of Large Language Models

    [https://arxiv.org/abs/2402.06044](https://arxiv.org/abs/2402.06044)

    OpenToM是一个评估大型语言模型心理理解能力的全面基准，通过提供更长、更清晰的叙事故事、具有明确个性特征的角色、以及挑战模型对心理状态的理解能力的问题，揭示了现有模型在理解物理世界与心理世界的角色心理状态方面的优势和不足。

    

    神经心理理论（N-ToM）是机器理解和跟踪他人心理状态的能力，在开发具有社交智能的代理程序中至关重要。然而，目前的N-ToM基准存在一些问题，包括模糊和人工故事的存在，缺乏个性特征和偏好，缺乏涉及角色心理心态的问题，并且提出的问题多样性有限。为了应对这些问题，我们构建了OpenToM，一个新的评估N-ToM的基准，以 (1) 更长、更清晰的叙事故事，(2) 具有明确个性特征的角色，(3) 触发角色意图的行动，以及 (4) 设计旨在挑战LLMs对建模角色在物理和心理世界的心理状态能力的问题。使用OpenToM，我们发现目前最先进的LLMs在建模物理世界的一些心理状态方面表现出色，但在跟踪角色心理状态方面存在不足。

    Neural Theory-of-Mind (N-ToM), machine's ability to understand and keep track of the mental states of others, is pivotal in developing socially intelligent agents. However, prevalent N-ToM benchmarks have several shortcomings, including the presence of ambiguous and artificial narratives, absence of personality traits and preferences, a lack of questions addressing characters' psychological mental states, and limited diversity in the questions posed. In response to these issues, we construct OpenToM, a new benchmark for assessing N-ToM with (1) longer and clearer narrative stories, (2) characters with explicit personality traits, (3) actions that are triggered by character intentions, and (4) questions designed to challenge LLMs' capabilities of modeling characters' mental states of both the physical and psychological world. Using OpenToM, we reveal that state-of-the-art LLMs thrive at modeling certain aspects of mental states in the physical world but fall short when tracking characte
    
[^121]: 用大型语言模型和检索增强生成提升教科书问答任务

    Enhancing Textbook Question Answering Task with Large Language Models and Retrieval Augmented Generation

    [https://arxiv.org/abs/2402.05128](https://arxiv.org/abs/2402.05128)

    本论文通过引入检索增强生成（RAG）技术和利用迁移学习来处理长文本和提升推理能力，为教科书问答任务带来了显著的改进。

    

    教科书问答（TQA）是人工智能中的一项具有挑战性的任务，由于上下文和多模式数据的复杂性。尽管以前的研究在任务上取得了显著的进展，但仍存在一些限制，包括模型推理能力不足和无法捕捉长文本中的上下文信息。大型语言模型（LLMs）的引入革命了人工智能领域，然而，直接应用LLMs经常会导致不准确的答案。本文提出了一种方法来处理TQA中领域外情景，即概念分布在不同课程中，该方法结合了检索增强生成（RAG）技术和迁移学习来处理长文本并提升推理能力。通过对LLM模型Llama-2进行监督微调并加入RAG，我们的架构优于基线，在验证集上的准确度提高了4.12%，在测试集上提高了9.84%。

    Textbook question answering (TQA) is a challenging task in artificial intelligence due to the complex nature of context and multimodal data. Although previous research has significantly improved the task, there are still some limitations including the models' weak reasoning and inability to capture contextual information in the lengthy context. The introduction of large language models (LLMs) has revolutionized the field of AI, however, directly applying LLMs often leads to inaccurate answers. This paper proposes a methodology that handle the out-of-domain scenario in TQA where concepts are spread across different lessons by incorporating the retrieval augmented generation (RAG) technique and utilize transfer learning to handle the long context and enhance reasoning abilities. Through supervised fine-tuning of the LLM model Llama-2 and the incorporation of RAG, our architecture outperforms the baseline, achieving a 4.12% accuracy improvement on validation set and 9.84% on test set for 
    
[^122]: 你的AI有多么VADER？面向适用于监管的人工智能系统定义的探讨

    How VADER is your AI? Towards a definition of artificial intelligence systems appropriate for regulation

    [https://arxiv.org/abs/2402.05048](https://arxiv.org/abs/2402.05048)

    本研究提出了一个评分框架，用于衡量人工智能（AI）定义在监管方面的合适性。研究旨在排除通过AI监管提案所采用的不恰当的AI定义对ICT技术、方法和非AI作品的影响，并回归到以前在其他成功技术监管中观察到的原则。

    

    人工智能（AI）推动了许多信息和通信技术（ICT）突破。然而，自图灵测试提议以来，ICT系统的范围已远远超出了AI。关键是，最近的AI监管提案采用了影响ICT技术、方法和系统的AI定义，而这些并不是AI。在某些情况下，甚至包括数学、统计和工程领域的作品也会受到影响。令人担忧的是，从西方社会到全球南方，都发现了AI定义上的错误。在本文中，我们提出了一个评分框架，用于衡量AI定义在监管方面的合适性。我们的在线、公开可用的VADER框架评分了应该作为AI定义的前提的覆盖范围，这些定义旨在（i）重现其他成功技术监管中观察到的原则，以及（ii）包括所有的AI技术和方法，同时排除非AI的作品。关于后者，我们的评分基于一种...

    Artificial intelligence (AI) has driven many information and communication technology (ICT) breakthroughs. Nonetheless, the scope of ICT systems has expanded far beyond AI since the Turing test proposal. Critically, recent AI regulation proposals adopt AI definitions affecting ICT techniques, approaches, and systems that are not AI. In some cases, even works from mathematics, statistics, and engineering would be affected. Worryingly, AI misdefinitions are observed from Western societies to the Global South. In this paper, we propose a framework to score how \textit{validated as appropriately-defined for regulation} (VADER) an AI definition is. Our online, publicly-available VADER framework scores the coverage of premises that should underlie AI definitions for regulation, which aim to (i) reproduce principles observed in other successful technology regulations, and (ii) include all AI techniques and approaches while excluding non-AI works. Regarding the latter, our score is based on a 
    
[^123]: PaDeLLM-NER：大型语言模型中的并行解码用于命名实体识别

    PaDeLLM-NER: Parallel Decoding in Large Language Models for Named Entity Recognition

    [https://arxiv.org/abs/2402.04838](https://arxiv.org/abs/2402.04838)

    本研究提出了PaDeLLM-NER，一种能够在大型语言模型中实现并行解码，从而显著减少命名实体识别的生成延迟，同时保持预测质量和性能。

    

    本研究旨在使用大型语言模型（LLMs）减少命名实体识别（NER）的生成延迟。LLMs的高延迟的主要原因是顺序解码过程，该过程自回归地生成NER的所有标签和提及，显著增加了序列长度。为此，我们引入了PaDeLLM-NER（Parallel Decoding in LLM for NE），这是一种无需额外模块或架构修改即可无缝集成到现有生成模型框架中的方法。PaDeLLM-NER允许同时解码所有提及，从而减少生成延迟。实验结果显示，PaDeLLM-NER的推理速度显著提高，对英语和中文来说比自回归方法快1.76到10.22倍。与各种数据集上的最先进性能相媲美，同时维持了预测质量。

    In this study, we aim to reduce generation latency for Named Entity Recognition (NER) with Large Language Models (LLMs). The main cause of high latency in LLMs is the sequential decoding process, which autoregressively generates all labels and mentions for NER, significantly increase the sequence length. To this end, we introduce Parallel Decoding in LLM for NE} (PaDeLLM-NER), a approach that integrates seamlessly into existing generative model frameworks without necessitating additional modules or architectural modifications. PaDeLLM-NER allows for the simultaneous decoding of all mentions, thereby reducing generation latency. Experiments reveal that PaDeLLM-NER significantly increases inference speed that is 1.76 to 10.22 times faster than the autoregressive approach for both English and Chinese. Simultaneously it maintains the quality of predictions as evidenced by the performance that is on par with the state-of-the-art across various datasets.
    
[^124]: MolTC: 在语言模型中进行分子关系建模

    MolTC: Towards Molecular Relational Modeling In Language Models

    [https://arxiv.org/abs/2402.03781](https://arxiv.org/abs/2402.03781)

    本研究提出了一种基于语言模型的多模态框架MolTC，用于分子相互作用预测，该框架能够高效地整合分子对的丰富图形信息，并通过思维链理论实现统一的分子关系学习。

    

    分子关系学习（MRL）旨在理解分子之间的相互作用，在推进生物化学研究方面起到了关键作用。最近，大型语言模型（LLMs）的采用已成为一种有效和高效的MRL方法，这些模型以其庞大的知识存储库和先进的逻辑推理能力而闻名。尽管具有潜力，但这些方法主要依赖于文本数据，因此没有充分利用分子图中固有的丰富结构信息。此外，缺乏统一的框架加剧了信息的浪费，因为它阻碍了在不同数据集之间共享学习到的相互作用理由。为了解决这些挑战，本研究提出了一种基于LLM的多模态框架，用于根据思维链（CoT）理论对分子相互作用进行预测，称为MolTC，它可以高效地整合分子对的丰富图形信息。

    Molecular Relational Learning (MRL), aiming to understand interactions between molecular pairs, plays a pivotal role in advancing biochemical research. Recently, the adoption of large language models (LLMs), known for their vast knowledge repositories and advanced logical inference capabilities, has emerged as a promising way for efficient and effective MRL. Despite their potential, these methods predominantly rely on the textual data, thus not fully harnessing the wealth of structural information inherent in molecular graphs. Moreover, the absence of a unified framework exacerbates the information underutilization, as it hinders the sharing of interaction rationale learned across diverse datasets. To address these challenges, this work proposes a novel LLM-based multi-modal framework for Molecular inTeraction prediction following Chain-of-Thought (CoT) theory, termed MolTC, which can efficiently integrate rich graphical information of molecular pairs. For achieving a unified MRL, MolT
    
[^125]: 在10个国家的非自愿合成亲密图像的态度和知识

    Attitudes Towards and Knowledge of Non-Consensual Synthetic Intimate Imagery in 10 Countries

    [https://arxiv.org/abs/2402.01721](https://arxiv.org/abs/2402.01721)

    本文研究了10个国家超过16,000名受访者对非自愿合成亲密图像的态度和行为；尽管社会对此仍认识不足，但这种行为被认为有害；约有2.2%的受访者表示曾受害，1.8%的受访者表示曾参与过此类行为；单靠立法行动并不足以解决问题，建议技术和平台政策的改进来减少伤害。

    

    深度伪造技术工具已经无处不在，"民主化"了操纵图像和视频的能力。这种技术的一个流行用途是创建性暴力内容，然后在互联网上广泛发布和共享。本文通过对10个国家的超过16,000名受访者的研究，研究了与非自愿合成亲密图像（NSII）相关的态度和行为。尽管社会对NSII的认识尚处于初级阶段，但NSII行为被认为是有害的。在普遍性方面，所有受访者中有2.2%的人表示曾受害，1.8%的人表示曾参与过这种行为。来自具有相关立法的国家的受访者也报告了参与和受害经历，这表明单靠立法行动并不足以阻止参与者的行为。减少伤害的技术考虑可能包括建议人们如何更好地监控自己在网上的存在，并执行平台政策。

    Deepfake technology tools have become ubiquitous, "democratizing" the ability to manipulate images and videos. One popular use of such technology is the creation of sexually explicit content, which can then be posted and shared widely on the internet. This article examines attitudes and behaviors related to non-consensual synthetic intimate imagery (NSII) across over 16,000 respondents in 10 countries. Despite nascent societal awareness of NSII, NSII behaviors were considered harmful. In regards to prevalence, 2.2% of all respondents indicated personal victimization, and 1.8% all of respondents indicated perpetration behaviors. Respondents from countries with relevant legislation also reported perpetration and victimization experiences, suggesting legislative action alone is not a sufficient solution to deter perpetration. Technical considerations to reduce harms may include suggestions for how individuals can better monitor their presence online, as well as enforced platform policies 
    
[^126]: 通过整合外延知识和内涵知识嵌入本体

    Embedding Ontologies via Incoprorating Extensional and Intensional Knowledge

    [https://arxiv.org/abs/2402.01677](https://arxiv.org/abs/2402.01677)

    本文提出了一种新型本体嵌入方法EIKE，通过整合外延知识和内涵知识，在外延空间和内涵空间中表示本体，并采用基于几何的方法和预训练的语言模型对实例、概念和关系进行嵌入建模。

    

    本体包含领域内丰富的知识，可以分为两个类别，即外延知识和内涵知识。外延知识提供关于本体中特定概念所属的具体实例的信息，而内涵知识详细描述了概念之间的内在属性、特征和语义关联。然而，现有的本体嵌入方法未能同时充分考虑外延知识和内涵知识。在本文中，我们提出了一种名为EIKE（Extensional and Intensional Knowledge Embedding）的新型本体嵌入方法，通过在外延空间和内涵空间中表示本体。EIKE提出了一个统一的框架，用于将实例、概念及其关系嵌入到本体中，采用基于几何的方法对外延知识进行建模，并使用预训练的语言模型对内涵知识进行建模。

    Ontologies contain rich knowledge within domain, which can be divided into two categories, namely extensional knowledge and intensional knowledge. Extensional knowledge provides information about the concrete instances that belong to specific concepts in the ontology, while intensional knowledge details inherent properties, characteristics, and semantic associations among concepts. However, existing ontology embedding approaches fail to take both extensional knowledge and intensional knowledge into fine consideration simultaneously. In this paper, we propose a novel ontology embedding approach named EIKE (Extensional and Intensional Knowledge Embedding) by representing ontologies in two spaces, called extensional space and intensional space. EIKE presents a unified framework for embedding instances, concepts and their relations in an ontology, applying a geometry-based method to model extensional knowledge and a pretrained language model to model intensional knowledge, which can captur
    
[^127]: 大规模语言模型是零射击学习器

    Large Language Models are Null-Shot Learners

    [https://arxiv.org/abs/2401.08273](https://arxiv.org/abs/2401.08273)

    本文提出了零射击提示方法，通过利用大规模语言模型中的错误信息来指导模型进行任务，以提高任务表现。实验结果表明，在不同数据集上，包括阅读理解、算术推理和闭卷问答，模型性能有所提升。这些结果也显示出不同模型之间存在不同程度的错误信息。

    

    本文提出了零射击提示方法。零射击提示利用大规模语言模型（LLMs）中的错误信息，通过指示LLMs利用从“示例”部分中获取的信息（该信息在所提供的上下文中不存在）来完成任务。虽然减少错误信息对于LLMs的日常和重要用途至关重要，但我们提出在目前的环境中，这些LLMs仍然具有错误信息，实际上可以利用错误信息来提高与标准零射击提示相比的任务表现。对八个LLMs进行实验，结果显示在大多数八个数据集（包括阅读理解、算术推理和闭卷问答）中，性能有所提升。观察到的不一致性增加相对性能在LLMs之间的差异，也可能表示每个模型中存在不同程度的错误信息。

    arXiv:2401.08273v2 Announce Type: replace-cross Abstract: This paper presents null-shot prompting. Null-shot prompting exploits hallucination in large language models (LLMs) by instructing LLMs to utilize information from the "Examples" section that never exists within the provided context to perform a task. While reducing hallucination is crucial and non-negligible for daily and critical uses of LLMs, we propose that in the current landscape in which these LLMs still hallucinate, it is possible, in fact, to exploit hallucination to increase performance in performing tasks compared to standard zero-shot prompting. Experiments with eight LLMs show improvements in performance across the majority of eight datasets, including reading comprehension, arithmetic reasoning, and closed-book question answering. The observed inconsistency in increased relative performance across the LLMs also potentially indicates a different degree of inherent hallucination in each model. These differences show 
    
[^128]: AI基于移动应用评价的公平关注研究

    A Study of Fairness Concerns in AI-based Mobile App Reviews

    [https://arxiv.org/abs/2401.08097](https://arxiv.org/abs/2401.08097)

    本文研究了AI基于移动应用评价中的公平关注，并通过构建数据集和开发分类器的方法，成功检测出公平性评论，并识别出约92000条公平性评论。

    

    公平是AI系统中必须解决的社会技术问题之一。不公平的AI系统，特别是不公平的AI基于移动应用，可能给全球很大一部分人口带来困难。本文旨在分析AI基于应用评价中的公平问题。我们首先手动构建了一个基准数据集，包括公平性和非公平性评论的统计样本。利用这个基准数据集，我们开发和评估了一组机器学习和深度学习分类器，用于区分公平性评论和非公平性评论。我们的实验结果显示，我们最佳的分类器可以以94%的精确度检测到公平性评论。然后，我们将最佳分类器应用于从108个AI基于应用收集的约950万条评论，识别出约92000条公平性评论。接下来，我们将K-means聚类技术应用于这92000条公平性评论。

    arXiv:2401.08097v2 Announce Type: replace-cross Abstract: Fairness is one of the socio-technical concerns that must be addressed in AI-based systems. Unfair AI-based systems, particularly unfair AI-based mobile apps, can pose difficulties for a significant proportion of the global population. This paper aims to analyze fairness concerns in AI-based app reviews.We first manually constructed a ground-truth dataset, including a statistical sample of fairness and non-fairness reviews. Leveraging the ground-truth dataset, we developed and evaluated a set of machine learning and deep learning classifiers that distinguish fairness reviews from non-fairness reviews. Our experiments show that our best-performing classifier can detect fairness reviews with a precision of 94%. We then applied the best-performing classifier on approximately 9.5M reviews collected from 108 AI-based apps and identified around 92K fairness reviews. Next, applying the K-means clustering technique to the 92K fairness r
    
[^129]: 在在线视觉问答中评估GPT-4V和Gemini

    An Evaluation of GPT-4V and Gemini in Online VQA

    [https://arxiv.org/abs/2312.10637](https://arxiv.org/abs/2312.10637)

    该论文将在一个真实的在线问答社区的数据集上评估两个最先进的大型多模型模型（GPT-4V和Gemini），分析了它们的能力和限制，研究了不同类型的问题对模型的挑战性，并提供了零样本性能分析。

    

    尽管大型多模型模型（LMM）的潜力备受关注，但全面评估它们的能力和限制至关重要。为了支持这一目标，我们在一个来自真实在线问答社区的新视觉问答数据集上评估了两个最先进的LMM模型，GPT-4V和Gemini。我们生成了近2000个视觉问题的七种类型的元数据，如图像类型和所需的图像处理能力，并进行了细粒度分析。我们的零样本性能分析突出了这两个模型最具挑战性的问题类型，包括与“令人困惑”的主题相关的问题，具有“识别”用户意图，具有“乐谱”图像类型或被GPT-4标记为“困难”的问题。

    arXiv:2312.10637v2 Announce Type: replace-cross Abstract: While there is much excitement about the potential of large multimodal models (LMM), a comprehensive evaluation is critical to establish their true capabilities and limitations. In support of this aim, we evaluate two state-of-the-art LMMs, GPT-4V and Gemini, on a new visual question answering dataset sourced from an authentic online question answering community. We conduct fine-grained analysis by generating seven types of metadata for nearly 2,000 visual questions, such as image type and the required image processing capabilities. Our zero-shot performance analysis highlights the types of questions that are most challenging for both models, including questions related to "puzzling" topic, with "Identification" user intention, with "Sheet Music" image type, or labeled as "hard" by GPT-4.
    
[^130]: 基于语义能力模型和SMT的自动化工艺规划

    Automated Process Planning Based on a Semantic Capability Model and SMT

    [https://arxiv.org/abs/2312.08801](https://arxiv.org/abs/2312.08801)

    该论文介绍了一种基于语义能力模型和SMT的自动化工艺规划方法。该方法旨在解决制造系统和自主机器人中的能力规范解释以及自动化工艺规划的问题。

    

    在制造系统和自主机器人的研究中，"能力"一词用于对系统功能进行机器可解释的规范。本研究领域的方法开发了捕获解释功能要求、效果和行为的所有相关信息的信息模型。这些方法旨在克服由各种类型的流程和大量不同供应商导致的异构性。然而，这些模型和相关方法并未提供自动化工艺规划的解决方案，即寻找制造某种产品或使用自主机器人完成任务所需的一系列个别能力的顺序。相反，这是AI规划方法的典型任务，但遗憾的是，创建相应的规划问题描述需要很高的工作量。在本文中，我们提出了一种将这两个主题结合的方法：

    arXiv:2312.08801v2 Announce Type: replace Abstract: In research of manufacturing systems and autonomous robots, the term capability is used for a machine-interpretable specification of a system function. Approaches in this research area develop information models that capture all information relevant to interpret the requirements, effects and behavior of functions. These approaches are intended to overcome the heterogeneity resulting from the various types of processes and from the large number of different vendors. However, these models and associated methods do not offer solutions for automated process planning, i.e. finding a sequence of individual capabilities required to manufacture a certain product or to accomplish a mission using autonomous robots. Instead, this is a typical task for AI planning approaches, which unfortunately require a high effort to create the respective planning problem descriptions. In this paper, we present an approach that combines these two topics: Start
    
[^131]: Neural Language Agents的diff历史

    diff History for Neural Language Agents

    [https://arxiv.org/abs/2312.07540](https://arxiv.org/abs/2312.07540)

    本文介绍了一种名为diff历史的简单且高效的解决方案，用于将环境中的观测转换为文本提示，以便对于长期推理决策的任务中的Neural Language Models进行优化。

    

    Neural Language Models (LMs)为通用的具体控制提供了令人兴奋的解决方案。然而，当使用基于LM的控制器时，会出现一个关键的技术问题：环境观测必须转换为文本，这与历史耦合在一起，导致冗长而冗余的文本提示。因此，LM代理的先前工作局限于具有小观测大小以及对交互历史或指示调优需求较小的限制领域。在本文中，我们引入了diff历史，这是一个简单且非常有效的解决方案。通过在用于提示LM策略的交互历史中的连续文本观测上应用Unix diff命令，我们既可以摘除冗余信息，又可以将文本输入的内容集中在环境中显著变化的方面。在需要长期推理进行决策的未解决的视频游戏NetHack中，使用diff历史调优的LM与状态匹配。

    arXiv:2312.07540v2 Announce Type: replace Abstract: Neural Language Models (LMs) offer an exciting solution for general-purpose embodied control. However, a key technical issue arises when using an LM-based controller: environment observations must be converted to text, which coupled with history, results in long and verbose textual prompts. As a result, prior work in LM agents is limited to restricted domains with small observation size as well as minimal needs for interaction history or instruction tuning. In this paper, we introduce diff history, a simple and highly effective solution to these issues. By applying the Unix diff command on consecutive text observations in the interaction histories used to prompt LM policies, we can both abstract away redundant information and focus the content of textual inputs on the salient changes in the environment. On NetHack, an unsolved video game that requires long-horizon reasoning for decision-making, LMs tuned with diff history match state-
    
[^132]: 不良学生成就了优秀教师：主动学习加速大规模视觉理解

    Bad Students Make Great Teachers: Active Learning Accelerates Large-Scale Visual Understanding

    [https://arxiv.org/abs/2312.05328](https://arxiv.org/abs/2312.05328)

    研究提出了一种满足泛化性、扩展性和计算资源优化的主动学习方法，利用廉价的代理模型估计数据点的可学习性分数，优先选择训练更大的模型所需的数据，从而在大规模视觉理解任务中取得相同性能的同时减少了计算量。

    

    幂律缩放表明使用均匀采样的大规模训练速度太慢。主动学习方法旨在通过优先学习最相关的示例来提高数据效率。尽管这些方法具有吸引力，但由于没有证明 a) 可以泛化到各种模型和任务 b) 可以扩展到大规模数据集并且 c) 在考虑数据选择开销时能节省计算资源，因此尚未被广泛采用。在这项工作中，我们提出了一种满足这三个属性的方法，利用小型廉价的代理模型来估计数据点的“可学习性”分数，用于优先训练更大的模型所需的数据。结果上，我们的模型在JFT上需要46%和51%更少的训练更新次数，并且要达到与均匀训练的视觉分类器在JFT和ALIGN上多模型的相同性能需要高达25%的更少的总计算量。最后，我们发现我们的数据优先方法能够在视觉理解和多模型任务上取得与均匀训练相当的性能，同时节省了计算资源。

    arXiv:2312.05328v3 Announce Type: replace Abstract: Power-law scaling indicates that large-scale training with uniform sampling is prohibitively slow. Active learning methods aim to increase data efficiency by prioritizing learning on the most relevant examples. Despite their appeal, these methods have yet to be widely adopted since no one algorithm has been shown to a) generalize across models and tasks b) scale to large datasets and c) yield overall FLOP savings when accounting for the overhead of data selection. In this work we propose a method which satisfies these three properties, leveraging small, cheap proxy models to estimate "learnability" scores for datapoints, which are used to prioritize data for the training of much larger models. As a result, our models require 46% and 51% fewer training updates and up to 25% less total computation to reach the same performance as uniformly trained visual classifiers on JFT and multimodal models on ALIGN. Finally, we find our data-priori
    
[^133]: 通过模拟进行算法性劝导

    Algorithmic Persuasion Through Simulation

    [https://arxiv.org/abs/2311.18138](https://arxiv.org/abs/2311.18138)

    通过模拟接收者行为的贝叶斯劝导问题中，发送者设计了一个最优消息策略并设计了一个多项式时间查询算法，以优化其预期效用。

    

    我们研究了一个贝叶斯劝导问题，其中发送者希望说服接收者采取二元行为，例如购买产品。发送者了解世界的（二元）状态，比如产品质量是高还是低，但是对接收者的信念和效用只有有限的信息。受到客户调查、用户研究和生成式人工智能的最新进展的启发，我们允许发送者通过查询模拟接收者的行为来了解更多关于接收者的信息。在固定数量的查询之后，发送者承诺一个消息策略，接收者根据收到的消息来最大化她的预期效用来采取行动。我们对发送者在任何接收者类型分布下的最优消息策略进行了表征。然后，我们设计了一个多项式时间查询算法，优化了这个贝叶斯劝导游戏中发送者的预期效用。

    arXiv:2311.18138v2 Announce Type: replace-cross Abstract: We study a Bayesian persuasion problem where a sender wants to persuade a receiver to take a binary action, such as purchasing a product. The sender is informed about the (binary) state of the world, such as whether the quality of the product is high or low, but only has limited information about the receiver's beliefs and utilities. Motivated by customer surveys, user studies, and recent advances in generative AI, we allow the sender to learn more about the receiver by querying an oracle that simulates the receiver's behavior. After a fixed number of queries, the sender commits to a messaging policy and the receiver takes the action that maximizes her expected utility given the message she receives. We characterize the sender's optimal messaging policy given any distribution over receiver types. We then design a polynomial-time querying algorithm that optimizes the sender's expected utility in this Bayesian persuasion game. We 
    
[^134]: CLOMO: 带有大型语言模型的反事实逻辑修改

    CLOMO: Counterfactual Logical Modification with Large Language Models

    [https://arxiv.org/abs/2311.17438](https://arxiv.org/abs/2311.17438)

    本研究探索了大型语言模型的反事实推理能力，并引入了反事实逻辑修改任务和相应的评估指标。实验结果表明，大型语言模型展现出显著的逻辑能力。

    

    本研究探索了大型语言模型（LLMs）的反事实推理能力。我们的主要目标是培养LLMs内的反事实思维过程，并对其有效性进行严格评估。具体而言，我们引入了一项新任务，即反事实逻辑修改（CLOMO），以及一个高质量的人工注释基准。在这个任务中，LLMs必须熟练地改变给定的论证文本，以保持预定的逻辑关系。为了有效评估生成模型的反事实能力，我们提出了一种创新的评估指标，逻辑感知的反事实分数，直接评估LLMs的自然语言输出，而不是将任务建模为多项选择问题。分析表明，所提出的自动评估指标与人类偏好很好地一致。我们的实验结果表明，尽管LLMs展示了显着的逻辑能力。

    arXiv:2311.17438v3 Announce Type: replace-cross Abstract: In this study, we delve into the realm of counterfactual reasoning capabilities of large language models (LLMs). Our primary objective is to cultivate the counterfactual thought processes within LLMs and rigorously assess these processes for their validity. Specifically, we introduce a novel task, Counterfactual Logical Modification (CLOMO), and a high-quality human-annotated benchmark. In this task, LLMs must adeptly alter a given argumentative text to uphold a predetermined logical relationship. To effectively evaluate a generation model's counterfactual capabilities, we propose an innovative evaluation metric, the LogicAware Counterfactual Score to directly evaluate the natural language output of LLMs instead of modeling the task as a multiple-choice problem. Analysis shows that the proposed automatic metric aligns well with human preference. Our experimental results show that while LLMs demonstrate a notable capacity for log
    
[^135]: (非)理性在人工智能中的应用：现状、研究挑战和未解之问

    (Ir)rationality in AI: State of the Art, Research Challenges and Open Questions

    [https://arxiv.org/abs/2311.17165](https://arxiv.org/abs/2311.17165)

    这篇论文调查了人工智能中理性与非理性的概念，提出了未解问题。重点讨论了行为在某些情况下的非理性行为可能是最优的情况。已经提出了一些方法来处理非理性代理，但仍存在挑战和问题。

    

    理性概念在人工智能领域中占据着重要地位。无论是模拟人类推理还是追求有限最优性，我们通常希望使人工智能代理尽可能理性。尽管这个概念在人工智能中非常核心，但对于什么构成理性代理并没有统一的定义。本文调查了人工智能中的理性与非理性，并提出了这个领域的未解问题。在其他领域对理性的理解对其在人工智能中的概念产生了影响，特别是经济学、哲学和心理学方面的研究。着重考虑人工智能代理的行为，我们探讨了在某些情境中非理性行为可能是最优的情况。关于处理非理性代理的方法已经得到了一些发展，包括识别和交互等方面的研究，然而，在这个领域的工作仍然存在一些挑战和问题。

    arXiv:2311.17165v2 Announce Type: replace Abstract: The concept of rationality is central to the field of artificial intelligence. Whether we are seeking to simulate human reasoning, or the goal is to achieve bounded optimality, we generally seek to make artificial agents as rational as possible. Despite the centrality of the concept within AI, there is no unified definition of what constitutes a rational agent. This article provides a survey of rationality and irrationality in artificial intelligence, and sets out the open questions in this area. The understanding of rationality in other fields has influenced its conception within artificial intelligence, in particular work in economics, philosophy and psychology. Focusing on the behaviour of artificial agents, we consider irrational behaviours that can prove to be optimal in certain scenarios. Some methods have been developed to deal with irrational agents, both in terms of identification and interaction, however work in this area re
    
[^136]: 在线广告与LLMs：机遇与挑战

    Online Advertisements with LLMs: Opportunities and Challenges

    [https://arxiv.org/abs/2311.07601](https://arxiv.org/abs/2311.07601)

    本文探讨了在线广告系统中利用大型语言模型（LLM）的潜力，提出了一个LLM广告的通用框架，并讨论了基于LLM的动态创意优化的前景。

    

    本文探讨了在在线广告系统中利用大型语言模型（LLM）的潜力。我们深入研究了这个系统必须满足的隐私、延迟、可靠性以及用户和广告商的满意度等关键要求。我们进一步介绍了一个LLM广告的通用框架，包括修改、竞标、预测和拍卖模块。我们提出了每个模块的不同设计考虑，并对其实用性和实施中的技术挑战进行了深入研究。最后，我们探讨了基于LLM的动态创意优化的前景，以显著提升广告对用户的吸引力，并讨论了它所面临的额外挑战。

    arXiv:2311.07601v2 Announce Type: replace-cross Abstract: This paper explores the potential for leveraging Large Language Models (LLM) in the realm of online advertising systems. We delve into essential requirements including privacy, latency, reliability as well as the satisfaction of users and advertisers which such a system must fulfill. We further introduce a general framework for LLM advertisement, consisting of modification, bidding, prediction, and auction modules. Different design considerations for each module is presented, with an in-depth examination of their practicality and the technical challenges inherent to their implementation. Finally, we explore the prospect of LLM-based dynamic creative optimization as a means to significantly enhance the appeal of advertisements to users and discuss its additional challenges.
    
[^137]: 在上下文向量中，通过潜空间操控使上下文学习更有效和可控

    In-context Vectors: Making In Context Learning More Effective and Controllable Through Latent Space Steering

    [https://arxiv.org/abs/2311.06668](https://arxiv.org/abs/2311.06668)

    通过潜空间操控，使用上下文向量作为替代方法来进行上下文学习，以使语言模型更有效地遵循示例演示，并通过调整向量的量级来轻松控制学习过程。

    

    大型语言模型（LLM）展示了新任务适应能力，并通过示例演示来进行上下文学习。然而，在许多情况下，上下文学习的效果有限，难以定量控制，并占用上下文窗口空间。为了克服这些限制，我们提出了一种替代方法，将上下文学习重新定义为上下文向量（ICV）。使用ICV有两个步骤。首先，我们对演示示例进行正向传递，从LLM的潜在嵌入中创建上下文向量。这个向量捕捉了关于预期任务的关键信息。对于一个新的查询，我们不是将示例添加到提示中，而是使用ICV来改变LLM的潜在状态。ICV方法有几个好处：1）它使LLM能够更有效地遵循示例演示；2）通过调整ICV的量级，它易于控制；3）

    arXiv:2311.06668v3 Announce Type: replace-cross Abstract: Large language models (LLMs) demonstrate emergent in-context learning capabilities, where they adapt to new tasks based on example demonstrations. However, in-context learning has seen limited effectiveness in many settings, is difficult to quantitatively control and takes up context window space. To overcome these limitations, we propose an alternative approach that recasts in-context learning as in-context vectors (ICV). Using ICV has two steps. We first use a forward pass on demonstration examples to create the in-context vector from the latent embedding of the LLM. This vector captures essential information about the intended task. On a new query, instead of adding demonstrations to the prompt, we shift the latent states of the LLM using the ICV. The ICV approach has several benefits: 1) it enables the LLM to more effectively follow the demonstration examples; 2) it's easy to control by adjusting the magnitude of the ICV; 3)
    
[^138]: 对比深度非负矩阵分解用于社区发现

    Contrastive Deep Nonnegative Matrix Factorization for Community Detection

    [https://arxiv.org/abs/2311.02357](https://arxiv.org/abs/2311.02357)

    对比深度非负矩阵分解算法（CDNMF）通过加深NMF的信息提取能力，采用对比学习的思想构建了网络拓扑和节点属性作为对比视图，并利用去偏方法来优化社区探测的全局结构信息的学习。

    

    最近，非负矩阵分解（NMF）被广泛应用于社区发现，因为其具有更好的可解释性。然而，现有的基于NMF的方法存在以下三个问题：1）它们直接将原始网络转换为社区成员空间，因此很难捕捉层次信息；2）它们通常只关注网络的拓扑结构，忽视了节点属性；3）它们很难学习到社区发现所需的全局结构信息。因此，我们提出了一种新的社区发现算法，名为对比深度非负矩阵分解（CDNMF）。首先，我们深化NMF以增强其信息提取能力。随后，受到对比学习的启发，我们的算法创造性地将网络拓扑和节点属性构建为两种对比视图。此外，我们使用一种去偏的方法...

    arXiv:2311.02357v2 Announce Type: replace-cross Abstract: Recently, nonnegative matrix factorization (NMF) has been widely adopted for community detection, because of its better interpretability. However, the existing NMF-based methods have the following three problems: 1) they directly transform the original network into community membership space, so it is difficult for them to capture the hierarchical information; 2) they often only pay attention to the topology of the network and ignore its node attributes; 3) it is hard for them to learn the global structure information necessary for community detection. Therefore, we propose a new community detection algorithm, named Contrastive Deep Nonnegative Matrix Factorization (CDNMF). Firstly, we deepen NMF to strengthen its capacity for information extraction. Subsequently, inspired by contrastive learning, our algorithm creatively constructs network topology and node attributes as two contrasting views. Furthermore, we utilize a debiased
    
[^139]: LINC: 通过将语言模型与一阶逻辑证明器相结合的神经符号方法进行逻辑推理

    LINC: A Neurosymbolic Approach for Logical Reasoning by Combining Language Models with First-Order Logic Provers

    [https://arxiv.org/abs/2310.15164](https://arxiv.org/abs/2310.15164)

    LINC是一种通过将大型语言模型作为语义解析器，将自然语言转化为一阶逻辑表达式，再通过外部定理证明器进行推理的神经符号方法，可以显著提高逻辑推理的性能。

    

    逻辑推理是人工智能中重要的任务，它通过从一组前提中推断结论的真值，在科学、数学和社会等领域具有广泛的潜在影响。虽然已经提出了许多基于提示的策略来使大型语言模型（LLM）更有效地进行这种推理，但它们仍然表现不尽如人意，经常在微妙和难以预测的方式下失败。在这项工作中，我们探索了将这些任务重新定义为模块化的神经符号编程，我们称之为LINC：通过神经符号计算进行逻辑推理。在LINC中，LLM充当语义解析器，将自然语言的前提和结论转化为一阶逻辑表达式。然后，将这些表达式转移到外部定理证明器中，该证明器通过符号方式进行演绎推理。利用这种方法，我们观察到了显著的性能提升。

    arXiv:2310.15164v2 Announce Type: replace-cross Abstract: Logical reasoning, i.e., deductively inferring the truth value of a conclusion from a set of premises, is an important task for artificial intelligence with wide potential impacts on science, mathematics, and society. While many prompting-based strategies have been proposed to enable Large Language Models (LLMs) to do such reasoning more effectively, they still appear unsatisfactory, often failing in subtle and unpredictable ways. In this work, we investigate the validity of instead reformulating such tasks as modular neurosymbolic programming, which we call LINC: Logical Inference via Neurosymbolic Computation. In LINC, the LLM acts as a semantic parser, translating premises and conclusions from natural language to expressions in first-order logic. These expressions are then offloaded to an external theorem prover, which symbolically performs deductive inference. Leveraging this approach, we observe significant performance gain
    
[^140]: LongForm: 使用反向指令进行有效的指令调优

    LongForm: Effective Instruction Tuning with Reverse Instructions

    [https://arxiv.org/abs/2304.08460](https://arxiv.org/abs/2304.08460)

    使用反向指令进行有效的指令调优，通过生成一组自然的、适用于长文本生成的指令调优数据集，我们的模型在故事/菜谱生成和长篇问答等任务上优于10倍规模更大的语言模型，而无需指令调优。

    

    Instruction tuning使得语言模型能够更有效地泛化，并更好地遵循用户意图。然而，获取指令数据成本高且具有挑战性。先前的工作采用了诸如昂贵的人工注释、存在对齐问题的众包数据集、以及通过LLMs生成噪声示例的方法。我们引入了LongForm-C数据集，该数据集由反向指令创建。我们使用LLMs为人类写作语料库示例使用反向指令生成指令。首先，我们从诸如C4和Wikipedia的语料库中选择了一组多样性的人类撰写文档；然后，我们使用LLMs为这些文档生成指令。这种方法提供了一个更便宜、更干净、输出自然以及适用于长文本生成的指令调优数据集。我们的模型在故事/菜谱生成和长篇问答等任务上优于10倍规模更大的语言模型，而无需指令调优。

    arXiv:2304.08460v2 Announce Type: replace-cross Abstract: Instruction tuning enables language models to more effectively generalize and better follow user intent. However, obtaining instruction data is costly and challenging. Prior work employs methods such as expensive human annotation, crowd-sourced datasets with alignment issues, and generating noisy examples via LLMs. We introduce the LongForm-C dataset, which is created by reverse instructions. We generate instructions via LLMs for human-written corpus examples using reverse instructions. First we select a diverse set of human-written documents from corpora such as C4 and Wikipedia; then we generate instructions for these documents via LLMs. This approach provides a cheaper and cleaner instruction-tuning dataset with natural output and one suitable for long text generation. Our models outperform 10x larger language models without instruction tuning on tasks such as story/recipe generation and long-form question answering. Moreover
    
[^141]: 因果深度学习

    Causal Deep Learning

    [https://arxiv.org/abs/2303.02186](https://arxiv.org/abs/2303.02186)

    因果深度学习是一种新的关于因果性的思考方式，它综合了可测试的因果知识、参数形式和时间维度，能够帮助我们解决实际问题。

    

    因果性有望真正改变我们解决许多实际问题的方式。然而，迄今为止，因果性的潜力在很大程度上仍未得到充分发挥，因为因果性常常需要无法在实践中进行测试的关键假设。为了应对这一挑战，我们提出了一种全新的关于因果性的思考方式——我们称之为因果深度学习。我们的因果深度学习框架涵盖了三个方面：（1）结构维度，它将部分可以测试的因果知识融入，而不是假设感兴趣的变量之间的因果知识是完整的或完全不存在的；（2）参数维度，它涵盖了捕捉感兴趣的变量之间关系类型的参数形式；（3）时间维度，它捕捉感兴趣的变量如何在时间上相互作用（可能有因果关系）。因果深度学习使我们能够在各种实际问题上取得进展。

    arXiv:2303.02186v2 Announce Type: replace-cross Abstract: Causality has the potential to truly transform the way we solve a large number of real-world problems. Yet, so far, its potential largely remains to be unlocked as causality often requires crucial assumptions which cannot be tested in practice. To address this challenge, we propose a new way of thinking about causality -- we call this causal deep learning. Our causal deep learning framework spans three dimensions: (1) a structural dimension, which incorporates partial yet testable causal knowledge rather than assuming either complete or no causal knowledge among the variables of interest; (2) a parametric dimension, which encompasses parametric forms that capture the type of relationships among the variables of interest; and (3) a temporal dimension, which captures exposure times or how the variables of interest interact (possibly causally) over time. Causal deep learning enables us to make progress on a variety of real-world pr
    
[^142]: Markov决策过程的最优决策树策略

    Optimal Decision Tree Policies for Markov Decision Processes

    [https://arxiv.org/abs/2301.13185](https://arxiv.org/abs/2301.13185)

    本研究研究了有限大小决策树在Markov决策过程（MDPs）中的优化，并提出了OMDTs：最优MDP决策树。通过混合整数线性规划直接最大化决策树的期望折扣回报。研究发现现有模仿学习技术的最优性差距，并发现它们表现为次优。

    

    强化学习策略的解释性对于许多实际任务至关重要，但学习这种可解释的策略是一个困难的问题。特别是像决策树和规则列表这样的基于规则的策略，由于其不可微性，很难进行优化。尽管现有技术可以学习可验证的决策树策略，但不能保证学习者生成的决策是最优的。在这项工作中，我们研究了有限大小决策树在Markov决策过程（MDPs）中的优化，并提出了OMDTs：最优MDP决策树。给定用户定义的大小限制和MDP形式，OMDT通过混合整数线性规划直接最大化决策树的期望折扣回报。通过为不同的MDP训练最优决策树策略，我们在实证上研究了现有模仿学习技术的最优性差距，并发现它们表现为次优。

    arXiv:2301.13185v2 Announce Type: replace Abstract: Interpretability of reinforcement learning policies is essential for many real-world tasks but learning such interpretable policies is a hard problem. Particularly rule-based policies such as decision trees and rules lists are difficult to optimize due to their non-differentiability. While existing techniques can learn verifiable decision tree policies there is no guarantee that the learners generate a decision that performs optimally. In this work, we study the optimization of size-limited decision trees for Markov Decision Processes (MPDs) and propose OMDTs: Optimal MDP Decision Trees. Given a user-defined size limit and MDP formulation OMDT directly maximizes the expected discounted return for the decision tree using Mixed-Integer Linear Programming. By training optimal decision tree policies for different MDPs we empirically study the optimality gap for existing imitation learning techniques and find that they perform sub-optimall
    
[^143]: 深度学习图像分类中的测试时间混合增强方法用于数据和类别特定不确定性估计

    Test-Time Mixup Augmentation for Data and Class-Specific Uncertainty Estimation in Deep Learning Image Classification

    [https://arxiv.org/abs/2212.00214](https://arxiv.org/abs/2212.00214)

    本文提出了一种使用测试时间混合增强来估计深度学习图像分类中的不确定性的方法，并引入了数据不确定性和类别特定不确定性来提高准确性和提供更深入的信息。

    

    训练的深度学习网络的不确定性估计对于优化学习效率和评估网络预测的可靠性非常有价值。本文提出了一种使用测试时间混合增强（TTMA）来估计深度学习图像分类中不确定性的方法。为了改善现有确定性不确定性区分正确和错误预测的能力，我们引入了TTMA数据不确定性（TTMA-DU），通过对测试数据进行混合增强并测量预测标签直方图的熵来衡量。除了TTMA-DU外，我们还提出了TTMA类别特定不确定性（TTMA-CSU），它捕捉到了与单个类别相关的确定性不确定性，并提供了关于训练网络内类别混淆和类别相似性的见解。我们在ISIC-18皮肤病诊断数据集和CIFAR-100真实世界图像分类数据集上验证了我们提出的方法。

    arXiv:2212.00214v3 Announce Type: replace-cross Abstract: Uncertainty estimation of trained deep learning networks is valuable for optimizing learning efficiency and evaluating the reliability of network predictions. In this paper, we propose a method for estimating uncertainty in deep learning image classification using test-time mixup augmentation (TTMA). To improve the ability to distinguish correct and incorrect predictions in existing aleatoric uncertainty, we introduce TTMA data uncertainty (TTMA-DU) by applying mixup augmentation to test data and measuring the entropy of the predicted label histogram. In addition to TTMA-DU, we propose TTMA class-specific uncertainty (TTMA-CSU), which captures aleatoric uncertainty specific to individual classes and provides insight into class confusion and class similarity within the trained network. We validate our proposed methods on the ISIC-18 skin lesion diagnosis dataset and the CIFAR-100 real-world image classification dataset. Our exper
    
[^144]: 深度强化学习指导下的作业车间调度改进启发式方法

    Deep Reinforcement Learning Guided Improvement Heuristic for Job Shop Scheduling

    [https://arxiv.org/abs/2211.10936](https://arxiv.org/abs/2211.10936)

    本文提出了一种基于深度强化学习的指导下的作业车间调度改进启发式方法，采用图表示法来编码完整的解决方案，并设计了基于图神经网络的表示方案和新颖的消息传递机制，以提高性能和加快解决方案评估。

    

    近期研究将深度强化学习（DRL）应用于解决作业车间调度问题时，主要关注的是构建启发式方法。然而，他们的性能仍远离最优，主要是因为底层图表示方案不适合对每个构建步骤中的部分解进行建模。本文提出了一种新颖的DRL指导下的作业车间调度改进启发式方法，采用图表示法来编码完整的解决方案。我们设计了一个基于图神经网络的表示方案，包含两个模块，可以有效地捕捉改进过程中遇到的动态拓扑和不同类型的节点的信息。为了在改进过程中加快解决方案评估，我们提出了一种新颖的消息传递机制，可以同时评估多个解决方案。我们证明了我们的方法的计算复杂性与问题规模呈线性关系。

    arXiv:2211.10936v3 Announce Type: replace-cross Abstract: Recent studies in using deep reinforcement learning (DRL) to solve Job-shop scheduling problems (JSSP) focus on construction heuristics. However, their performance is still far from optimality, mainly because the underlying graph representation scheme is unsuitable for modelling partial solutions at each construction step. This paper proposes a novel DRL-guided improvement heuristic for solving JSSP, where graph representation is employed to encode complete solutions. We design a Graph Neural-Network-based representation scheme, consisting of two modules to effectively capture the information of dynamic topology and different types of nodes in graphs encountered during the improvement process. To speed up solution evaluation during improvement, we present a novel message-passing mechanism that can evaluate multiple solutions simultaneously. We prove that the computational complexity of our method scales linearly with problem siz
    
[^145]: FedMT: 混合类型标签的联邦学习

    FedMT: Federated Learning with Mixed-type Labels

    [https://arxiv.org/abs/2210.02042](https://arxiv.org/abs/2210.02042)

    本文提出了一种概念新颖的联邦学习设置，即具有混合类型标签的联邦学习，在其中不同的中心可以使用不同的标签准则。为了有效地训练具有混合类型标签的模型，作者提出了一种理论指导和模型无关的方法。

    

    在联邦学习（FL）中，分类器（例如深度网络）在多个中心的数据集上进行训练，而无需在这些中心之间交换数据，从而提高了样本效率。在传统的FL设置中，通常在所有参与训练的中心中采用相同的标签准则。这个限制极大地限制了FL的适用性。例如，在疾病诊断中使用的标准很可能在临床中心之间存在差异，这与传统FL的设置不匹配。在本文中，我们考虑了一个重要但尚未充分探索的FL设置，即具有混合类型标签的FL，其中各个中心可以使用不同的标签准则，从而导致中心间标签空间的差异，并对为传统设置设计的现有FL方法提出了挑战。为了有效而高效地训练具有混合类型标签的模型，我们提出了一种基于理论指导和模型无关的方法

    arXiv:2210.02042v3 Announce Type: replace-cross Abstract: In federated learning (FL), classifiers (e.g., deep networks) are trained on datasets from multiple centers without exchanging data across them, and thus improves sample efficiency. In the classical setting of FL, the same labeling criterion is usually employed across all centers being involved in training. This constraint greatly limits the applicability of FL. For example, standards used for disease diagnosis are more likely to be different across clinical centers, which mismatches the classical FL setting. In this paper, we consider an important yet under-explored setting of FL, namely FL with mixed-type labels where different labeling criteria can be employed by various centers, leading to inter-center label space differences and challenging existing FL methods designed for the classical setting. To effectively and efficiently train models with mixed-type labels, we propose a theory-guided and model-agnostic approach that ca
    
[^146]: 使用YOLOv8、DeiT和SimCLR在希腊纸草这检测和识别字符

    Detecting and recognizing characters in Greek papyri with YOLOv8, DeiT and SimCLR. (arXiv:2401.12513v1 [cs.CV])

    [http://arxiv.org/abs/2401.12513](http://arxiv.org/abs/2401.12513)

    该论文使用YOLOv8、DeiT和SimCLR在希腊纸草中进行字符检测和识别竞赛，在识别挑战中获得了42.2%的mAP，并在检测挑战中以51.4%的平均精度获得了亚军。

    

    从纸草手稿的图像中分离和识别单个字符的能力为数字分析提供了丰富的机会。因此，“ICDAR 2023年希腊纸草上字符检测和识别竞赛”作为第17届国际文件分析和识别会议的一部分举行。本文讨论了我们在比赛中的提交。我们使用了一组YOLOv8模型来检测和分类单个字符，并采用了两种不同的方法来完善字符预测，包括基于变压器的DeiT方法和使用SimCLR自监督学习方法在大量无标签数据上训练的ResNet-50模型。我们的提交在识别挑战中获得了42.2%的mAP，并在检测挑战中以51.4%的平均精度获得了亚军。在更宽松的iou阈值为0.5的情况下，我们实现了最高的平均精度和平均.

    The capacity to isolate and recognize individual characters from facsimile images of papyrus manuscripts yields rich opportunities for digital analysis. For this reason the `ICDAR 2023 Competition on Detection and Recognition of Greek Letters on Papyri' was held as part of the 17th International Conference on Document Analysis and Recognition. This paper discusses our submission to the competition. We used an ensemble of YOLOv8 models to detect and classify individual characters and employed two different approaches for refining the character predictions, including a transformer based DeiT approach and a ResNet-50 model trained on a large corpus of unlabelled data using SimCLR, a self-supervised learning method. Our submission won the recognition challenge with a mAP of 42.2%, and was runner-up in the detection challenge with a mean average precision (mAP) of 51.4%. At the more relaxed intersection over union threshold of 0.5, we achieved the highest mean average precision and mean ave
    
[^147]: 通过检索示范进行上下文学习的语言模型：一项综述

    In-context Learning with Retrieved Demonstrations for Language Models: A Survey. (arXiv:2401.11624v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2401.11624](http://arxiv.org/abs/2401.11624)

    本综述调查了一种名为检索示范的方法，它通过使用特定于输入查询的示范来提高语言模型的少量样本情境学习（ICL）能力。这种方法不仅提高了学习效率和可扩展性，还减少了手动示例选择中的偏见。

    

    语言模型，特别是预训练的大型语言模型，已展示出卓越的能力，可以在输入上下文中进行少量样本的情境学习（ICL），并在新任务上具有适应能力。然而，模型的ICL能力对于少样本示范的选择是敏感的。最近的一项研究进展是检索针对每个输入查询定制的示范。示范检索的实现相对简单，利用现有的数据库和检索系统。这不仅提高了学习过程的效率和可扩展性，而且已经证明可以减少手动示例选择中的偏见。鉴于令人鼓舞的结果和在检索示范的ICL方面不断增长的研究，我们进行了广泛的研究综述。在这项综述中，我们讨论和比较了检索模型的不同设计选择，检索训练

    Language models, especially pre-trained large language models, have showcased remarkable abilities as few-shot in-context learners (ICL), adept at adapting to new tasks with just a few demonstrations in the input context. However, the model's ability to perform ICL is sensitive to the choice of the few-shot demonstrations. Instead of using a fixed set of demonstrations, one recent development is to retrieve demonstrations tailored to each input query. The implementation of demonstration retrieval is relatively straightforward, leveraging existing databases and retrieval systems. This not only improves the efficiency and scalability of the learning process but also has been shown to reduce biases inherent in manual example selection. In light of the encouraging results and growing research in ICL with retrieved demonstrations, we conduct an extensive review of studies in this area. In this survey, we discuss and compare different design choices for retrieval models, retrieval training p
    
[^148]: 历史链的链路预测与学习：基于LLMs的时间知识图补全

    Chain of History: Learning and Forecasting with LLMs for Temporal Knowledge Graph Completion. (arXiv:2401.06072v1 [cs.AI])

    [http://arxiv.org/abs/2401.06072](http://arxiv.org/abs/2401.06072)

    本文提出了一种基于LLMs的新方法，将时间知识图补全任务概念化为历史事件链中的事件生成任务。通过引入高效的微调方法和结构化历史数据增强，以及整合反向知识，我们的模型在多个指标上优于现有的方法，取得了SOTA结果。

    

    时间知识图补全是一项具有挑战性的任务，其通过利用已建立的时间结构知识来预测未来时间戳上缺失的事件链接。本文提出了一种新颖的方法，将时间链路预测概念化为历史事件链中的事件生成任务，利用LLMs的强大生成能力。我们采用高效的微调方法，使LLMs适应特定的图文信息和在时间线中发现的模式。此外，我们引入基于结构的历史数据增强和反向知识的整合，以增强LLMs对结构信息的意识，从而提高其推理能力。我们在多个广泛使用的数据集上进行了详尽的实验，发现我们微调的模型在多个指标上优于现有的基于嵌入的模型，取得了SOTA的结果。我们还进行了充分的消融实验。

    Temporal Knowledge Graph Completion (TKGC) is a challenging task of predicting missing event links at future timestamps by leveraging established temporal structural knowledge. Given the formidable generative capabilities inherent in LLMs (LLMs), this paper proposes a novel approach to conceptualize temporal link prediction as an event generation task within the context of a historical event chain. We employ efficient fine-tuning methods to make LLMs adapt to specific graph textual information and patterns discovered in temporal timelines. Furthermore, we introduce structure-based historical data augmentation and the integration of reverse knowledge to emphasize LLMs' awareness of structural information, thereby enhancing their reasoning capabilities. We conduct thorough experiments on multiple widely used datasets and find that our fine-tuned model outperforms existing embedding-based models on multiple metrics, achieving SOTA results. We also carry out sufficient ablation experiments
    
[^149]: 将上下文带回来：多模态知识图谱上的相机陷阱物种识别作为链接预测

    Bringing Back the Context: Camera Trap Species Identification as Link Prediction on Multimodal Knowledge Graphs. (arXiv:2401.00608v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2401.00608](http://arxiv.org/abs/2401.00608)

    本研究利用相机陷阱图像的结构化上下文，提高其在物种识别任务中的泛化能力，并解决了数据稀缺和泛化能力增强的问题。

    

    相机陷阱在动物生态学中是宝贵的工具，用于生物多样性监测和保护。然而，挑战如在新的未知位置部署时的糟糕泛化限制了它们的实际应用。图像自然与可能在不同模态下的异质上下文相关联。在这项工作中，我们利用与相机陷阱图像相关联的结构化上下文，改善在相机陷阱中物种识别这个任务的超出分布的泛化能力。例如，一张野生动物的照片可能与拍摄地点和时间以及关于动物物种的结构化生物学知识相关联。虽然现有的工作通常忽视这一点，但将这样的上下文带回来可以带来一些潜在的好处，如解决数据稀缺和增强泛化能力。然而，有效地将这样的异质上下文整合到视觉领域是一个具有挑战性的问题。

    Camera traps are valuable tools in animal ecology for biodiversity monitoring and conservation. However, challenges like poor generalization to deployment at new unseen locations limit their practical application. Images are naturally associated with heterogeneous forms of context possibly in different modalities. In this work, we leverage the structured context associated with the camera trap images to improve out-of-distribution generalization for the task of species identification in camera traps. For example, a photo of a wild animal may be associated with information about where and when it was taken, as well as structured biology knowledge about the animal species. While typically overlooked by existing work, bringing back such context offers several potential benefits for better image understanding, such as addressing data scarcity and enhancing generalization. However, effectively integrating such heterogeneous context into the visual domain is a challenging problem. To address
    
[^150]: 超越静止图像：强大的多流时空网络

    Beyond Still Images: Robust Multi-Stream Spatiotemporal Networks. (arXiv:2311.00800v1 [cs.CV])

    [http://arxiv.org/abs/2311.00800](http://arxiv.org/abs/2311.00800)

    本论文通过引入包括时间特征的多流模型，提出了一个经过视频训练的鲁棒性模型，通过在训练中包括视频和时间流，减少了图像和视频理解任务的准确性下降率。

    

    自然视觉的一个定义特征是其能够承受各种输入变化，从而创建周围环境的不变表示。虽然卷积神经网络对某些形式的空间输入变化具有韧性，但空间和时间方面的修改可以显着影响深度神经网络中视频内容的表示。受自然视觉对输入变化的韧性启发，我们使用一个简单的多流模型来探索其通过包含时间特征来处理时空变化的潜力。我们的主要目标是引入一个经过视频训练的模型，并评估其对多样的图像和视频输入的鲁棒性，特别关注时间特征在不变识别中的作用。结果表明，训练时包括视频和时间流可以将图像和视频理解任务的准确性和mAP下降率减少1.36%和3.14%。

    A defining characteristic of natural vision is its ability to withstand a variety of input alterations, resulting in the creation of an invariant representation of the surroundings. While convolutional neural networks exhibit resilience to certain forms of spatial input variation, modifications in the spatial and temporal aspects can significantly affect the representations of video content in deep neural networks. Inspired by the resilience of natural vision to input variations, we employ a simple multi-stream model to explore its potential to address spatiotemporal changes by including temporal features. Our primary goal is to introduce a video-trained model and evaluate its robustness to diverse image and video inputs, with a particular focus on exploring the role of temporal features in invariant recognition. Results show that including videos and the temporal stream during training mitigates the decline in accuracy and mAP in image and video understanding tasks by 1.36% and 3.14%,
    
[^151]: SoK：评估黑盒攻击中的陷阱

    SoK: Pitfalls in Evaluating Black-Box Attacks. (arXiv:2310.17534v1 [cs.CR])

    [http://arxiv.org/abs/2310.17534](http://arxiv.org/abs/2310.17534)

    提出了一个评估黑盒攻击的分类法，揭示了未开发的威胁空间，并展示了在某些设置上已有技术的局限性。

    

    许多研究涉及对图像分类器的黑盒攻击。然而，这些研究对对手的知识假设不同，目前的文献缺乏围绕威胁模型进行组织的连贯性。为了系统化该领域的知识，我们提出了一个关于威胁空间的分类法，涵盖了反馈粒度、交互式查询的访问和攻击者可用的辅助数据的质量和数量三个维度。我们的新分类法提供了三个关键见解。1) 尽管有广泛文献，仍存在许多未开发的威胁空间，无法通过从已知领域的技术简单地改进来解决。我们通过将基于已知领域从完整置信向量访问的技术适应到访问前k个置信得分的较少研究的设置中来证明这一点，但同时也展示了它在仅获得预测标签的更严格设置中仍然不足。

    Numerous works study black-box attacks on image classifiers. However, these works make different assumptions on the adversary's knowledge and current literature lacks a cohesive organization centered around the threat model. To systematize knowledge in this area, we propose a taxonomy over the threat space spanning the axes of feedback granularity, the access of interactive queries, and the quality and quantity of the auxiliary data available to the attacker. Our new taxonomy provides three key insights. 1) Despite extensive literature, numerous under-explored threat spaces exist, which cannot be trivially solved by adapting techniques from well-explored settings. We demonstrate this by establishing a new state-of-the-art in the less-studied setting of access to top-k confidence scores by adapting techniques from well-explored settings of accessing the complete confidence vector, but show how it still falls short of the more restrictive setting that only obtains the prediction label, h
    
[^152]: 生成分类器的有趣属性

    Intriguing properties of generative classifiers. (arXiv:2309.16779v1 [cs.CV])

    [http://arxiv.org/abs/2309.16779](http://arxiv.org/abs/2309.16779)

    生成分类器展示了记录破纪录的人类形状偏好、接近人类级别的超出分布准确性、与人类分类错误的最先进对齐以及理解某些知觉幻象的新兴特性，揭示了零样本生成模型出奇地接近人类物体识别数据。

    

    识别对象的最佳范式是判别式推理（快速但潜在容易出现快捷学习）还是使用生成模型（较慢但潜在更稳健）？我们借鉴了最新的生成模型进展，将文本到图像模型转化为分类器。这使得我们能够研究其行为，并将其与判别模型和人类心理物理数据进行比较。我们报道了生成分类器的四个有趣的新兴特性：它们显示出破纪录的人类形状偏好（对于Imagen达到99%），接近人类级别的超出分布准确性，与人类分类错误的最先进对齐以及它们理解某些知觉幻象。我们的结果表明，尽管目前模拟人类物体识别的主导范式是判别式推理，零样本生成模型出奇地接近人类物体识别数据。

    What is the best paradigm to recognize objects -- discriminative inference (fast but potentially prone to shortcut learning) or using a generative model (slow but potentially more robust)? We build on recent advances in generative modeling that turn text-to-image models into classifiers. This allows us to study their behavior and to compare them against discriminative models and human psychophysical data. We report four intriguing emergent properties of generative classifiers: they show a record-breaking human-like shape bias (99% for Imagen), near human-level out-of-distribution accuracy, state-of-the-art alignment with human classification errors, and they understand certain perceptual illusions. Our results indicate that while the current dominant paradigm for modeling human object recognition is discriminative inference, zero-shot generative models approximate human object recognition data surprisingly well.
    
[^153]: 异质搜索空间上的贝叶斯优化的迁移学习

    Transfer Learning for Bayesian Optimization on Heterogeneous Search Spaces. (arXiv:2309.16597v1 [cs.LG])

    [http://arxiv.org/abs/2309.16597](http://arxiv.org/abs/2309.16597)

    本文提出了MPHD方法，通过模型预训练和神经网络在异质搜索空间上实现贝叶斯优化的迁移学习。实验证明了MPHD的有效性和在黑盒函数优化任务中的优越性能。

    

    贝叶斯优化是一种流行的黑盒函数优化方法，它基于贝叶斯模型（通常是高斯过程）进行顺序决策。为了确保模型的质量，我们开发了迁移学习方法，通过学习来自“训练”函数的观察结果来自动设计高斯过程先验。这些训练函数通常需要与“测试”函数（待优化的黑盒函数）具有相同的定义域。在本文中，我们介绍了一种名为MPHD的模型预训练方法，它使用神经网络将特定于领域的上下文映射到分层高斯过程的规范。MPHD可以与贝叶斯优化无缝集成，实现异质搜索空间的知识迁移。我们的理论和实证结果证明了MPHD的有效性，并展示了它在具有挑战性的黑盒函数优化任务中的优越性能。

    Bayesian optimization (BO) is a popular black-box function optimization method, which makes sequential decisions based on a Bayesian model, typically a Gaussian process (GP), of the function. To ensure the quality of the model, transfer learning approaches have been developed to automatically design GP priors by learning from observations on "training" functions. These training functions are typically required to have the same domain as the "test" function (black-box function to be optimized). In this paper, we introduce MPHD, a model pre-training method on heterogeneous domains, which uses a neural net mapping from domain-specific contexts to specifications of hierarchical GPs. MPHD can be seamlessly integrated with BO to transfer knowledge across heterogeneous search spaces. Our theoretical and empirical results demonstrate the validity of MPHD and its superior performance on challenging black-box function optimization tasks.
    
[^154]: 内存高效的连续学习长视频目标分割方法

    Memory-Efficient Continual Learning Object Segmentation for Long Video. (arXiv:2309.15274v1 [cs.CV])

    [http://arxiv.org/abs/2309.15274](http://arxiv.org/abs/2309.15274)

    提出了两种新技术，以减少在线VOS方法的内存需求，并在提高建模准确性和泛化能力的同时进行目标分割。

    

    最近的半监督视频目标分割方法在利用前几帧的信息进行当前帧分割时显示出显著的目标对象分割准确性改进。特别地，这种基于记忆的方法可以帮助模型更有效地处理外观变化（表达漂移）或遮挡。理想情况下，为了达到最佳性能，在线视频目标分割（VOS）方法需要将所有或大部分前几帧（或其提取的信息）存储在内存中，并用于连续帧的在线学习。然而，对于长视频来说，这种解决方案是不可行的，因为所需的内存大小会无限增长。另一方面，在内存有限且目标对象在视频中重复发生表达漂移的情况下，这些方法可能会失败。我们提出了两种新技术来减少在线VOS方法的内存需求，同时提高建模准确性和泛化能力。

    Recent state-of-the-art semi-supervised Video Object Segmentation (VOS) methods have shown significant improvements in target object segmentation accuracy when information from preceding frames is used in undertaking segmentation on the current frame. In particular, such memory-based approaches can help a model to more effectively handle appearance changes (representation drift) or occlusions. Ideally, for maximum performance, online VOS methods would need all or most of the preceding frames (or their extracted information) to be stored in memory and be used for online learning in consecutive frames. Such a solution is not feasible for long videos, as the required memory size would grow without bound. On the other hand, these methods can fail when memory is limited and a target object experiences repeated representation drifts throughout a video.  We propose two novel techniques to reduce the memory requirement of online VOS methods while improving modeling accuracy and generalization 
    
[^155]: 图像分类器的多个不同解释

    Multiple Different Explanations for Image Classifiers. (arXiv:2309.14309v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2309.14309](http://arxiv.org/abs/2309.14309)

    这篇论文介绍了一种算法和工具，可以为图像分类器的输出计算多个解释，从而提高对分类器行为的洞察力。

    

    现有的图像分类器解释工具通常只会给出一种对于图像的解释。然而，对于许多图像来说，无论是人类还是图像分类器都接受多个解释来解释图像标签。因此，限制解释的数量只有一个严重限制了对分类器行为的洞察力。在本文中，我们描述了一种算法和工具REX，用于计算黑盒图像分类器对给定图像的输出的多个解释。我们的算法基于因果理论的可靠方法。我们分析了其理论复杂性，并提供了实验结果，显示REX在ImageNet-mini基准测试中找到的多个解释比之前的工作多7倍。

    Existing explanation tools for image classifiers usually give only one single explanation for an image. For many images, however, both humans and image classifiers accept more than one explanation for the image label. Thus, restricting the number of explanations to just one severely limits the insight into the behavior of the classifier. In this paper, we describe an algorithm and a tool, REX, for computing multiple explanations of the output of a black-box image classifier for a given image. Our algorithm uses a principled approach based on causal theory. We analyse its theoretical complexity and provide experimental results showing that REX finds multiple explanations on 7 times more images than the previous work on the ImageNet-mini benchmark.
    
[^156]: 使用组合扩散模型实现训练数据保护

    Training Data Protection with Compositional Diffusion Models. (arXiv:2308.01937v1 [cs.LG])

    [http://arxiv.org/abs/2308.01937](http://arxiv.org/abs/2308.01937)

    使用分区扩散模型（CDM）训练不同的扩散模型，并在推断时任意组合它们，实现了训练数据保护和选择性遗忘，同时还可以根据用户访问权限提供定制模型。

    

    我们引入了分区扩散模型（CDM），一种在不同数据源上训练不同扩散模型（或提示）并在推断时任意组合它们的方法。这些单独的模型可以在孤立状态下、在不同时间、在不同分布和领域上进行训练，并可以后续组合以达到与同时训练所有数据的理想模型相当的性能。此外，每个模型只包含其在训练期间接触到的数据子集的信息，可以实现多种形式的训练数据保护。特别是，CDM是第一种可以实现大规模扩散模型的选择性遗忘和持续学习的方法，并且允许根据用户访问权限提供定制模型。CDM还可以确定生成特定样本的数据子集的重要性。

    We introduce Compartmentalized Diffusion Models (CDM), a method to train different diffusion models (or prompts) on distinct data sources and arbitrarily compose them at inference time. The individual models can be trained in isolation, at different times, and on different distributions and domains and can be later composed to achieve performance comparable to a paragon model trained on all data simultaneously. Furthermore, each model only contains information about the subset of the data it was exposed to during training, enabling several forms of training data protection. In particular, CDMs are the first method to enable both selective forgetting and continual learning for large-scale diffusion models, as well as allowing serving customized models based on the user's access rights. CDMs also allow determining the importance of a subset of the data in generating particular samples.
    
[^157]: 隐式归一化显式正则化密度估计

    Implicitly Normalized Explicitly Regularized Density Estimation. (arXiv:2307.13763v1 [stat.ML])

    [http://arxiv.org/abs/2307.13763](http://arxiv.org/abs/2307.13763)

    我们提出了一种新的非参数密度估计方法，基于正则化密度的 Sobolev 范数，通过适当的初始化和使用自然梯度，可以得到性能良好的解，该方法在 Anomaly Detection benchmark 中排名第二。

    

    我们提出了一种新的非参数密度估计方法，该方法是基于正则化密度的 Sobolev 范数。这种方法与核密度估计有明显差异，可以清晰解释模型的偏差。虽然我们无法得到相关核函数的闭合解析形式，但我们证明可以通过采样进行近似。决定密度的优化问题是非凸的，标准的梯度方法效果不好。然而，我们证明在适当的初始化和使用自然梯度的情况下，可以得到性能良好的解。最后，虽然该方法提供的是非归一化的密度，无法使用对数似然进行交叉验证，但我们证明可以采用基于 Fisher 散度的分数匹配方法来解决这个问题。我们在最近的异常检测基准套件 ADBench 上评估了得到的方法，并发现它在超过15个算法中排名第二。

    We propose a new approach to non-parametric density estimation, that is based on regularizing a Sobolev norm of the density. This method is provably different from Kernel Density Estimation, and makes the bias of the model clear and interpretable. While there is no closed analytic form for the associated kernel, we show that one can approximate it using sampling. The optimization problem needed to determine the density is non-convex, and standard gradient methods do not perform well. However, we show that with an appropriate initialization and using natural gradients, one can obtain well performing solutions. Finally, while the approach provides unnormalized densities, which prevents the use of log-likelihood for cross validation, we show that one can instead adapt Fisher Divergence based Score Matching methods for this task. We evaluate the resulting method on the comprehensive recent Anomaly Detection benchmark suite, ADBench, and find that it ranks second best, among more than 15 al
    
[^158]: 现在它听起来像你了：在设备上学习个性化词汇

    Now It Sounds Like You: Learning Personalized Vocabulary On Device. (arXiv:2305.03584v1 [cs.CL])

    [http://arxiv.org/abs/2305.03584](http://arxiv.org/abs/2305.03584)

    这项研究提出了一种称为“生词扩展”的技术，通过个性化的“生词适配器”来学习个性化词汇，提高了生词覆盖率并显著提高了模型准确度。

    

    近年来，联邦学习在进行各种自然语言处理任务方面已经显示出显著进展。这项工作侧重于应用个性化联邦学习进行设备端语言建模。由于内存和延迟的限制，这些模型无法支持子单词标记或波束搜索解码的复杂性，因此决定部署封闭词汇的语言模型。然而，封闭词汇模型无法处理特定用户的生词，为了解决这个问题，我们提出了一种称为“生词扩展”的新技术，该技术提高了生词覆盖率，增加了模型的准确性，同时最大程度地减少了对内存和延迟的影响。这种方法引入了个性化的“生词适配器”，有效地从中央模型传输知识，并为个性化词汇学习单词嵌入。在一组常见的联邦学习基准测试中，生词扩展方法明显优于标准个性化联邦学习方法。

    In recent years, Federated Learning (FL) has shown significant advancements in its ability to perform various natural language processing (NLP) tasks. This work focuses on applying personalized FL for on-device language modeling. Due to limitations of memory and latency, these models cannot support the complexity of sub-word tokenization or beam search decoding, resulting in the decision to deploy a closed-vocabulary language model. However, closed-vocabulary models are unable to handle out-of-vocabulary (OOV) words belonging to specific users. To address this issue, We propose a novel technique called "OOV expansion" that improves OOV coverage and increases model accuracy while minimizing the impact on memory and latency. This method introduces a personalized "OOV adapter" that effectively transfers knowledge from a central model and learns word embedding for personalized vocabulary. OOV expansion significantly outperforms standard FL personalization methods on a set of common FL benc
    
[^159]: 随机序列多智能体决策的因果解释

    Causal Explanations for Stochastic Sequential Multi-Agent Decision-Making. (arXiv:2302.10809v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2302.10809](http://arxiv.org/abs/2302.10809)

    CEMA是一个用于多智能体决策因果解释的系统，使用采样反事实世界的方法可以识别和排名决策背后的显著原因。该系统还可以生成基于所选原因的对比解释，并与用户进行交互循环以确保解释的相关性和可读性。

    

    我们提出CEMA：用于多智能体决策的因果解释系统；用于在随机序列多智能体环境中生成关于智能体决策的因果解释。CEMA的核心是一种新颖的因果选择方法，不同于之前假设特定因果结构的方法，只需要一个可以预测环境未来状态的概率模型即可应用。我们使用该模型采样反事实世界，以识别和排名决策背后的显著原因。我们还设计了CEMA以满足社会可解释AI的要求。它可以基于所选原因生成对比解释，通过与用户的交互循环来确保对用户的相关性和可读性。我们将CEMA实现在自动驾驶的运动规划中，并在四个不同的模拟场景中进行测试。我们展示CEMA能够正确而且鲁棒地识别决策背后的相关原因，并提供相关解释。

    We present CEMA: Causal Explanations for Multi-Agent decision-making; a system to generate causal explanations for agents' decisions in stochastic sequential multi-agent environments. The core of CEMA is a novel causal selection method which, unlike prior work that assumes a specific causal structure, is applicable whenever a probabilistic model for predicting future states of the environment is available. We sample counterfactual worlds with this model which are used to identify and rank the salient causes behind decisions. We also designed CEMA to meet the requirements of social explainable AI. It can generate contrastive explanations based on selected causes and it works as an interaction loop with users to assure relevance and intelligibility for them. We implement CEMA for motion planning for autonomous driving and test it in four diverse simulated scenarios. We show that CEMA correctly and robustly identifies the relevant causes behind decisions and delivers relevant explanations
    

