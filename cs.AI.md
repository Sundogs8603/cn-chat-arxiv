# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [InterDreamer: Zero-Shot Text to 3D Dynamic Human-Object Interaction](https://arxiv.org/abs/2403.19652) | 通过解耦交互语义和动态，本文展示了在没有直接训练文本-交互对数据的情况下生成人物-物体交互的潜力。 |
| [^2] | [MagicLens: Self-Supervised Image Retrieval with Open-Ended Instructions](https://arxiv.org/abs/2403.19651) | 本研究提出了MagicLens，一系列支持开放式指令的自监督图像检索模型，核心创新在于利用文本指令使得图像检索可以检索到比视觉相似性更丰富关系的图像。 |
| [^3] | [Human-compatible driving partners through data-regularized self-play reinforcement learning](https://arxiv.org/abs/2403.19648) | 提出了Human-Regularized PPO (HR-PPO)算法，通过自我博弈训练代理，实现在封闭环境中逼真且有效的驾驶伙伴 |
| [^4] | [Sparse Feature Circuits: Discovering and Editing Interpretable Causal Graphs in Language Models](https://arxiv.org/abs/2403.19647) | 该论文介绍了一种新方法，即稀疏特征电路，可以在语言模型中发现和编辑可解释的因果图，为我们提供了对未预料机制的详细理解和包含了用于提高分类器泛化能力的SHIFT方法。 |
| [^5] | [Retrieval-Enhanced Knowledge Editing for Multi-Hop Question Answering in Language Models](https://arxiv.org/abs/2403.19631) | 提出了用于多跳问题回答的检索增强模型编辑（RAE）框架，利用互信息最大化的检索方法和修剪策略，实现了对语言模型的有效优化。 |
| [^6] | [Collaborative Interactive Evolution of Art in the Latent Space of Deep Generative Models](https://arxiv.org/abs/2403.19620) | 本研究采用创意对抗网络和演化方法在深度生成模型的潜在空间中进行协作互动演化艺术，通过自动美学和协作交互式人类评估指标评估生成的图像质量。 |
| [^7] | [Semantic Map-based Generation of Navigation Instructions](https://arxiv.org/abs/2403.19603) | 通过使用语义地图作为视觉输入，我们提出了一种新的导航说明生成方法，将问题构建为图像字幕任务，有望降低生成指令的计算复杂性。 |
| [^8] | [Situation Awareness for Driver-Centric Driving Style Adaptation](https://arxiv.org/abs/2403.19595) | 提出了一种基于情境感知的驾驶风格模型，通过不同视觉特征编码器和驾驶行为预测器的结合，能够更好地适应驾驶情境，并在实验证明其优于静态驾驶风格。 |
| [^9] | [Img2Loc: Revisiting Image Geolocalization using Multi-modality Foundation Models and Image-based Retrieval-Augmented Generation](https://arxiv.org/abs/2403.19584) | Img2Loc通过多模态基础模型和基于图像检索增强的生成重新定义图像地理定位为文本生成任务。 |
| [^10] | [Self-Improved Learning for Scalable Neural Combinatorial Optimization](https://arxiv.org/abs/2403.19561) | 提出一种新颖的自我改进学习(SIL)方法，实现神经组合优化的更好可扩展性，通过自身生成解决方案作为伪标签，设计线性复杂度的注意机制来处理大规模组合优化问题实例。 |
| [^11] | [Croissant: A Metadata Format for ML-Ready Datasets](https://arxiv.org/abs/2403.19546) | Croissant是一种面向机器学习数据集的元数据格式，使数据集更易发现、可移植和互操作，有助于解决ML数据管理和负责任AI中的重要挑战。 |
| [^12] | [Lamarckian Inheritance Improves Robot Evolution in Dynamic Environments](https://arxiv.org/abs/2403.19545) | 拉马克遗传原理在动态环境中优化机器人进化，表现出比传统达尔文模型更高的适应性和效率。 |
| [^13] | [Interpreting Key Mechanisms of Factual Recall in Transformer-Based Language Models](https://arxiv.org/abs/2403.19521) | 通过深入研究Transformer-based语言模型在事实回忆任务中的机制，我们发现了零/少次样本情况下的特定任务头、MLP层和残差流的功能，以及抗过度自信机制。 |
| [^14] | [RiEMann: Near Real-Time SE(3)-Equivariant Robot Manipulation without Point Cloud Segmentation](https://arxiv.org/abs/2403.19460) | RiEMann提出了一个近实时SE(3)等变机器人操作模仿学习框架，无需点云分割，可以从零开始学习操作任务，泛化到看不见的转换和目标对象实例，对抗视觉干扰，实时跟踪目标对象的姿势变化，同时具有可扩展的动作空间使得关节对象操作成为可能。 |
| [^15] | [NeuroLGP-SM: A Surrogate-assisted Neuroevolution Approach using Linear Genetic Programming](https://arxiv.org/abs/2403.19459) | 使用线性遗传规划作为表示，NeuroLGP-SM 提出了一种利用代理模型辅助神经进化的方法，以应对神经进化的计算挑战，同时保持良好的DNN准确性。 |
| [^16] | [Uncovering Misattributed Suicide Causes through Annotation Inconsistency Detection in Death Investigation Notes](https://arxiv.org/abs/2403.19432) | 通过自然语言处理方法检测并纠正国家暴力死亡报告系统中的注释不一致性，提高了自杀危机分类器的性能。 |
| [^17] | [The Role of Syntactic Span Preferences in Post-Hoc Explanation Disagreement](https://arxiv.org/abs/2403.19424) | 此研究从语言学角度研究了不同方法之间的解释不一致，发现在句法跨度水平上比较方法可以平滑掉标记级别的差异，提出了动态估计最重要跨度的方法，改进了选择重要标记的配置。 |
| [^18] | [Scaling up ridge regression for brain encoding in a massive individual fMRI dataset](https://arxiv.org/abs/2403.19421) | 该论文评估了不同的并行化技术，以缩短岭回归脑编码模型训练时间，并在大规模深度fMRI数据集上取得了成功。 |
| [^19] | [Fairness in Ranking: Robustness through Randomization without the Protected Attribute](https://arxiv.org/abs/2403.19419) | 提出了一种针对排名后处理的随机化方法，无需受保护属性，通过数值研究显示了方法相对于基线排名的P-公平性和相对于归一化折扣累计增益(NDCG)的有效性的稳健性。 |
| [^20] | [Tabular Learning: Encoding for Entity and Context Embeddings](https://arxiv.org/abs/2403.19405) | 挑战常用的序数编码，提出基于字符串相似性编码的表格学习方法，取得了更好的分类效果和性能提升。 |
| [^21] | [PointCloud-Text Matching: Benchmark Datasets and a Baseline](https://arxiv.org/abs/2403.19386) | 本文提出了一个新的实例级检索任务：PointCloud-Text匹配（PTM），并构建了三个新的基准数据集以解决数据稀疏、文本模糊等挑战，同时提出了RoMa方法作为PTM的基线模型。 |
| [^22] | [NIGHT -- Non-Line-of-Sight Imaging from Indirect Time of Flight Data](https://arxiv.org/abs/2403.19376) | 本文首次使用来自即插即用的间接飞行时间传感器的数据，引入了一个深度学习模型，能够将光线反射发生的表面重新构建为虚拟镜子，从而实现了获取隐藏场景深度信息的可行性。 |
| [^23] | [Breaking the Length Barrier: LLM-Enhanced CTR Prediction in Long Textual User Behaviors](https://arxiv.org/abs/2403.19347) | BAHE提出了行为聚合分层编码（BAHE）来增强LLM-based CTR建模的效率，通过解耦用户行为的编码与行为之间的交互。 |
| [^24] | [Intelligent Classification and Personalized Recommendation of E-commerce Products Based on Machine Learning](https://arxiv.org/abs/2403.19345) | 本论文比较了传统电子商务商品分类系统和个性化推荐系统的运作机制，阐述了个性化推荐系统在电子商务等领域中的重要性和应用，同时深入探讨了相关系统所面临的挑战。 |
| [^25] | [Dataverse: Open-Source ETL (Extract, Transform, Load) Pipeline for Large Language Models](https://arxiv.org/abs/2403.19340) | Dataverse是一个面向大型语言模型的开源ETL管道，提供了用户友好的设计和易于定制的处理器添加功能，旨在成为LLM开发的重要工具，并开源整个库以促进社区贡献。 |
| [^26] | [IVLMap: Instance-Aware Visual Language Grounding for Consumer Robot Navigation](https://arxiv.org/abs/2403.19336) | IVLMap为机器人导航提供了实例级和属性级语义映射能力，通过将RGBD视频数据与特定设计的自然语言地图索引相融合而实现。 |
| [^27] | [Hypergraph-based Multi-View Action Recognition using Event Cameras](https://arxiv.org/abs/2403.19316) | 提出了一个名为HyperMV的多视角事件动作识别框架，实现了将离散事件数据转换成帧状表示，并利用共享卷积网络提取视角相关特征。 |
| [^28] | [MATEval: A Multi-Agent Discussion Framework for Advancing Open-Ended Text Evaluation](https://arxiv.org/abs/2403.19305) | 提出了MATEval框架，利用多个类GPT-4的LLMs作为评估Agent，模拟人类合作讨论方法，以评估开放性文本，结合自我反思和思维链策略，并加入反馈机制，提升评估深度和广度。 |
| [^29] | [Graph Neural Networks for Treatment Effect Prediction](https://arxiv.org/abs/2403.19289) | 提出了一种图神经网络来减少治疗效果预测所需的训练集大小，有效利用电子商务数据的图结构，为治疗效果预测带来新的可能性 |
| [^30] | [Fine-Tuning Language Models with Reward Learning on Policy](https://arxiv.org/abs/2403.19279) | 提出了在策略上的奖励学习框架，使用策略样本优化奖励模型以保持其分布上的一致性 |
| [^31] | [Knowledge Boundary and Persona Dynamic Shape A Better Social Media Agent](https://arxiv.org/abs/2403.19275) | 通过个性化知识和动态角色信息构建社交媒体代理以解决代理拥有不属于其角色的知识和无法消除多样化角色信息干扰的问题。 |
| [^32] | [A Machine Learning Approach for Crop Yield and Disease Prediction Integrating Soil Nutrition and Weather Factors](https://arxiv.org/abs/2403.19273) | 本文提出了一种整合土壤营养和气象因素的机器学习方法，用于作物产量和病害预测，致力于解决孟加拉国农业中作物选择和病害预测中的挑战。 |
| [^33] | [DeepSample: DNN sampling-based testing for operational accuracy assessment](https://arxiv.org/abs/2403.19271) | 该研究基于概率采样提出了DeepSample，通过小数据集大小、可信赖的估计和误判曝光三方面的技术目标，实现了成本效益的DNN准确度评估。 |
| [^34] | [sDPO: Don't Use Your Data All at Once](https://arxiv.org/abs/2403.19270) | sDPO是对直接偏好优化方法的扩展，通过分步利用偏好数据集而非一次性使用，促进更精确对齐参考模型的使用，并训练出性能更优的最终模型，甚至胜过其他具有更多参数的流行大型语言模型。 |
| [^35] | [MineLand: Simulating Large-Scale Multi-Agent Interactions with Limited Multimodal Senses and Physical Needs](https://arxiv.org/abs/2403.19267) | MineLand模拟器引入有限多模感知和生理需求，支持多智能体在协作中填补了信息和功能限制的空白，从而促进更具动态和有效性的多智能体交互。 |
| [^36] | [Taming Lookup Tables for Efficient Image Retouching](https://arxiv.org/abs/2403.19238) | 提出了一种使用查找表进行高效边缘图像推断的ICELUT算法，无需卷积神经网络，在降低硬件推断时间和功耗的同时实现近乎最先进的性能。 |
| [^37] | [Towards Multimodal Video Paragraph Captioning Models Robust to Missing Modality](https://arxiv.org/abs/2403.19221) | 提出了一种具有 Missing-Resistant 框架的多模态视频段落字幕生成模型，能够有效整合各种可用的辅助输入，在缺失某些模态的情况下仍能保持韧性，并引入了随机省略辅助输入的数据增强策略以及用于提炼知识的正则化目标。 |
| [^38] | [Dual-Personalizing Adapter for Federated Foundation Models](https://arxiv.org/abs/2403.19211) | 提出了一种新的设置，称为测试时间个性化，不仅关注目标本地任务，还延伸到其他展示测试时间个性化的任务 |
| [^39] | [Enhancing Trust and Privacy in Distributed Networks: A Comprehensive Survey on Blockchain-based Federated Learning](https://arxiv.org/abs/2403.19178) | 本文深入研究了基于区块链的联邦学习（BCFL），突出了区块链的安全功能与联邦学习的隐私保护模式之间的协同作用。 |
| [^40] | [Rethinking Information Loss in Medical Image Segmentation with Various-sized Targets](https://arxiv.org/abs/2403.19177) | 引入了一种新型的Stagger网络（SNet），通过融合结构缓解CNN和ViTs之间的潜在特征分布差异，减少信息丢失。 |
| [^41] | [Mitigating Misleading Chain-of-Thought Reasoning with Selective Filtering](https://arxiv.org/abs/2403.19167) | 提出了一种名为选择性过滤推理器（SelF-Reasoner）的新方法，用于评估问题与候选推理链之间的蕴涵关系，以减轻具有误导性的思维链推理过程。 |
| [^42] | [STaR-GATE: Teaching Language Models to Ask Clarifying Questions](https://arxiv.org/abs/2403.19154) | 通过奖励语言模型生成有用问题来自我改进的方法，提问者通过询问角色扮演者来引出偏好，从而迭代微调以增加任务高质量响应的概率。 |
| [^43] | [Towards Understanding Dual BN In Hybrid Adversarial Training](https://arxiv.org/abs/2403.19150) | 在混合对抗训练中，分离仿射参数比分离统计数据在模型训练中发挥更重要的作用。 |
| [^44] | [GenAI Detection Tools, Adversarial Techniques and Implications for Inclusivity in Higher Education](https://arxiv.org/abs/2403.19148) | GenAI检测工具在面对通过对抗技术修改的内容时准确性显著下降，不能推荐用于确定学术诚信违规，但在支持学生学习和维护学术诚信方面可能有帮助 |
| [^45] | [QNCD: Quantization Noise Correction for Diffusion Models](https://arxiv.org/abs/2403.19140) | 研究提出了一个统一的量化噪声校正方案（QNCD），旨在减小扩散模型中的量化噪声，解决了后训练量化对采样加速的影响问题。 |
| [^46] | [Compressing Large Language Models by Streamlining the Unimportant Layer](https://arxiv.org/abs/2403.19135) | 通过观察大型语言模型中不同层对隐藏状态的影响程度，提出了LLM-Streamline方法，包括层剪枝和层替换，用于压缩模型并保持性能。 |
| [^47] | [MFORT-QA: Multi-hop Few-shot Open Rich Table Question Answering](https://arxiv.org/abs/2403.19116) | 本文介绍了MFORT-QA方法，通过Few-Shot Learning和大语言模型，实现了在表格数据中进行多跳少样本的开放式丰富问答。 |
| [^48] | [FACTOID: FACtual enTailment fOr hallucInation Detection](https://arxiv.org/abs/2403.19113) | 本文表明传统的文本蕴涵方法无法有效地发现大型语言模型生成的内容中存在的幻觉问题。 |
| [^49] | [Automated Black-box Prompt Engineering for Personalized Text-to-Image Generation](https://arxiv.org/abs/2403.19103) | PRISM是一种算法，可以自动识别人类可解释且易传递的提示，从而有效生成所需概念，仅使用黑盒访问T2I模型。 |
| [^50] | [AAPMT: AGI Assessment Through Prompt and Metric Transformer](https://arxiv.org/abs/2403.19101) | 本研究旨在开发一个模型，通过提示和度量转换器来评估通用人工智能生成图像的质量，填补当前评估方法与最先进标准之间的差距。 |
| [^51] | [Task2Morph: Differentiable Task-inspired Framework for Contact-Aware Robot Design](https://arxiv.org/abs/2403.19093) | 该论文提出了一个新颖的可微分的基于任务启发的接触感知机器人设计框架Task2Morph，通过将任务特征抽象到任务到形态的映射中，实现整体优化和映射学习。 |
| [^52] | [Improving Cancer Imaging Diagnosis with Bayesian Networks and Deep Learning: A Bayesian Deep Learning Approach](https://arxiv.org/abs/2403.19083) | 本文研究了贝叶斯深度学习模型，结合深度学习和贝叶斯网络的优势，最小化各自的劣势，并分析了其在健康产业中图像分类方面的应用。 |
| [^53] | [Enhancing Conformal Prediction Using E-Test Statistics](https://arxiv.org/abs/2403.19082) | 该论文利用E-检验统计引入BB-predictor，增强符合性预测效果。 |
| [^54] | [MVEB: Self-Supervised Learning with Multi-View Entropy Bottleneck](https://arxiv.org/abs/2403.19078) | 该工作提出了一种名为MVEB的方法，通过消除图像视图之间不共享的多余信息，实现了最小足够表示的学习，并解决了互信息计算困难的问题。 |
| [^55] | [Tiny Machine Learning: Progress and Futures](https://arxiv.org/abs/2403.19076) | TinyML是一种将深度学习模型压缩到物联网设备和微控制器中实现无处不在智能的新方法，需要共同设计算法和系统堆栈以克服硬件限制。 |
| [^56] | [Dataflow-Aware PIM-Enabled Manycore Architecture for Deep Learning Workloads](https://arxiv.org/abs/2403.19073) | 设计了一种面向数据流的PIM启用的多核体系结构以加速深度学习工作负载 |
| [^57] | [Generative Quanta Color Imaging](https://arxiv.org/abs/2403.19066) | 论文核心创新是使用神经常微分方程框架下的曝光合成模型，允许从单个观测中生成一系列曝光，以确保一致的曝光在二进制图像中进行着色，从而显著增强了着色效果。 |
| [^58] | [Towards Human-Centered Construction Robotics: An RL-Driven Companion Robot For Contextually Assisting Carpentry Workers](https://arxiv.org/abs/2403.19060) | 本文提出了一种人类中心的建筑机器人方法，通过强化学习驱动的助手机器人为木工劳动者提供环境上下文协助，推进了机器人在建筑中的应用。 |
| [^59] | [Detecting Generative Parroting through Overfitting Masked Autoencoders](https://arxiv.org/abs/2403.19050) | 本研究提出利用过拟合的遮蔽自编码器(MAE)来检测生成模型中的生成性模仿，建立了基于训练数据集损失的检测阈值，为了确保生成模型的合法使用和提升其法律合规性提供了一种新方法。 |
| [^60] | [LITA: Language Instructed Temporal-Localization Assistant](https://arxiv.org/abs/2403.19046) | 提出了一种名为LITA的语言指导的时间定位助手，通过引入时间令牌、SlowFast令牌和强调时间定位数据来改善视频中的时间定位能力 |
| [^61] | [Evaluating Large Language Models for Health-Related Text Classification Tasks with Public Social Media Data](https://arxiv.org/abs/2403.19031) | 综合实验表明，利用LLMs进行数据增强可以... |
| [^62] | [Exploiting Symmetry in Dynamics for Model-Based Reinforcement Learning with Asymmetric Rewards](https://arxiv.org/abs/2403.19024) | 本文扩展了强化学习和控制理论中对称技术的应用范围，通过利用动态对称性学习动力学模型，而不要求奖励具有相同的对称性。 |
| [^63] | [Towards LLM-RecSys Alignment with Textual ID Learning](https://arxiv.org/abs/2403.19021) | 通过提出IDGen，将每个推荐项目表示为独特、简洁、语义丰富的文本ID，从而使得基于大型语言模型的推荐更好地与自然语言生成对齐。 |
| [^64] | [ReflectSumm: A Benchmark for Course Reflection Summarization](https://arxiv.org/abs/2403.19012) | ReflectSumm是一个旨在总结学生反思性写作的数据集，可以帮助开发和评估针对现实场景的新型摘要技术，为进一步研究提供了基准。 |
| [^65] | [Cross--domain Fiber Cluster Shape Analysis for Language Performance Cognitive Score Prediction](https://arxiv.org/abs/2403.19001) | 本研究通过新颖的框架SFFormer，结合了多头交叉注意力特征融合模块，基于dMRI纤维束追踪，预测了主观语言表现，拓展了脑结构与人类认知功能的关联研究。 |
| [^66] | [Few-Shot Cross-System Anomaly Trace Classification for Microservice-based systems](https://arxiv.org/abs/2403.18998) | 提出了针对微服务系统的少样本异常跟踪分类的新框架，利用多头注意力自编码器构建系统特定的跟踪表示，并应用基于Transformer编码器的模型无关元学习进行高效分类。 |
| [^67] | [Dealing with Imbalanced Classes in Bot-IoT Dataset](https://arxiv.org/abs/2403.18989) | 提出了一种利用合成少数类过抽样技术(SMOTE)的二元分类方法，以解决Bot-IoT数据集中的类别不平衡问题。 |
| [^68] | [Robustness and Visual Explanation for Black Box Image, Video, and ECG Signal Classification with Reinforcement Learning](https://arxiv.org/abs/2403.18985) | 提出了一个通用的强化学习框架，用于从心电图信号分析到图像和视频分类的不同模型类型的对抗攻击，通过识别敏感区域并在最小程度扭曲下诱导错误分类，生成优越的定位掩模，并在鲁棒性和透明度方面取得了显著进展。 |
| [^69] | [TextCraftor: Your Text Encoder Can be Image Quality Controller](https://arxiv.org/abs/2403.18978) | 通过微调文本编码器来改进文本到图像扩散模型的性能。 |
| [^70] | ["Sorry, Come Again?" Prompting -- Enhancing Comprehension and Diminishing Hallucination with [PAUSE]-injected Optimal Paraphrasing](https://arxiv.org/abs/2403.18976) | 介绍了一种新的提示策略“Sorry, Come Again (SCA)”来避免大规模语言模型（LLMs）产生幻觉，通过进行最佳的改写和注入[PAUSE]标记来增强理解力。 |
| [^71] | [A Survey on Large Language Models from Concept to Implementation](https://arxiv.org/abs/2403.18969) | Transformer模型在改革传统任务和推进跨行业研究和开发中产生革命性影响。 |
| [^72] | [LORD: Large Models based Opposite Reward Design for Autonomous Driving](https://arxiv.org/abs/2403.18965) | LORD通过不期望的语言目标，提出了一种基于大模型的相反奖励设计，以便有效利用大型预训练模型作为零-shot奖励模型。 |
| [^73] | [Using Quantum Computing to Infer Dynamic Behaviors of Biological and Artificial Neural Networks](https://arxiv.org/abs/2403.18963) | 本研究展示了如何利用Grover和Deutsch-Josza等基础量子算法，通过一组精心构建的条件，推断生物和人工神经网络在一段时间内是否具有继续维持动态活动的潜力。 |
| [^74] | [A State-of-the-practice Release-readiness Checklist for Generative AI-based Software Products](https://arxiv.org/abs/2403.18958) | 该研究提出了一份综合性检查清单，旨在指导从业者评估生成AI软件产品的关键发布就绪方面，以提高在真实环境中的可靠性和效果。 |
| [^75] | [Random Aggregate Beamforming for Over-the-Air Federated Learning in Large-Scale Networks](https://arxiv.org/abs/2403.18946) | 本文提出了一种随机聚合波束成形的方案，通过随机抽样生成聚合器波束形成矢量，以解决大规模网络中的聚合误差最小化和设备选择最大化问题。 |
| [^76] | [Reshaping Free-Text Radiology Notes Into Structured Reports With Generative Transformers](https://arxiv.org/abs/2403.18938) | 提出了一个从自由文本放射学报告中提取信息的流程，利用自然语言处理（NLP）和基于Transformer的模型来处理自动的SR注册表填写。 |
| [^77] | [Measuring Political Bias in Large Language Models: What Is Said and How It Is Said](https://arxiv.org/abs/2403.18932) | 提出通过分析大型语言模型生成的政治议题内容和风格来测量其政治偏见，主张应该有由大型语言模型生成的政治偏见的细粒度和可解释性衡量。 |
| [^78] | [Nature-Guided Cognitive Evolution for Predicting Dissolved Oxygen Concentrations in North Temperate Lakes](https://arxiv.org/abs/2403.18923) | 提出了一种自然引导的认知进化策略，通过多层融合自适应学习和自然过程，有效预测北温带湖泊中的溶解氧浓度 |
| [^79] | [CPR: Retrieval Augmented Generation for Copyright Protection](https://arxiv.org/abs/2403.18920) | CPR是一种新的用于扩散模型的RAG方法，具有强大的版权保护保障，可以在混合私人设置中条件生成输出，同时不暴露关于检索图片的独特可识别信息。 |
| [^80] | [A Geometric Explanation of the Likelihood OOD Detection Paradox](https://arxiv.org/abs/2403.18910) | 高似然区域将不会被生成如果它们包含最小概率质量，基于此观察提出了一种通过本地固有维度估计进行离群检测的方法 |
| [^81] | [Targeted Visualization of the Backbone of Encoder LLMs](https://arxiv.org/abs/2403.18872) | 本文研究了将DeepView方法应用于自然语言处理领域，以减少编码器模型存在的风险并解释模型决策过程。 |
| [^82] | [Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification](https://arxiv.org/abs/2403.18871) | 提出了一种模板引导方法，将气胸的临床知识融入XAI方法，以过滤掉落在模板之外的不相关解释。 |
| [^83] | [Interpretable Machine Learning for Weather and Climate Prediction: A Survey](https://arxiv.org/abs/2403.18864) | 可解释的机器学习技术对于增强天气和气候建模的可信度和实用性至关重要，包括后验可解释性技术和从头设计的固有可解释模型。 |
| [^84] | [Are Colors Quanta of Light for Human Vision? A Quantum Cognition Study of Visual Perception](https://arxiv.org/abs/2403.18850) | 该研究揭示了量子测量过程中范畴感知现象的机制，认为颜色在人类视觉中可以被视为光子，为视觉感知提供了新的量子认知视角。 |
| [^85] | [The Blind Normalized Stein Variational Gradient Descent-Based Detection for Intelligent Massive Random Access](https://arxiv.org/abs/2403.18846) | 提出了一种基于盲归一化斯坦变分梯度下降的检测器，用于解决智能大规模随机接入中的前导碰撞问题，并通过开发改进Hadamard变换和设计块MHT层来提高检测性能。 |
| [^86] | [Unleashing the Power of AI. A Systematic Review of Cutting-Edge Techniques in AI-Enhanced Scientometrics, Webometrics, and Bibliometrics](https://arxiv.org/abs/2403.18838) | 分析人工智能与科学计量学、网络计量学和文献计量学的协同作用，揭示和强调人工智能算法在这些领域中的应用潜力和好处 |
| [^87] | [DeepTraderX: Challenging Conventional Trading Strategies with Deep Learning in Multi-Threaded Market Simulations](https://arxiv.org/abs/2403.18831) | DeepTraderX是一个使用深度学习的交易系统，在多线程市场模拟中表现出色，并且可以与文献中最佳策略匹敌。 |
| [^88] | [Bridging Generative Networks with the Common Model of Cognition](https://arxiv.org/abs/2403.18827) | 通过将模块重构为影子生成系统，实现了认知架构与生成神经网络的无缝连接 |
| [^89] | [ECoDepth: Effective Conditioning of Diffusion Models for Monocular Depth Estimation](https://arxiv.org/abs/2403.18807) | 通过使用预训练的ViT模型生成的全局图像先验，为单图深度估计模型提供更详细的上下文信息，并提出了一种新的使用扩散骨干且受ViT嵌入条件约束的深度估计模型。 |
| [^90] | [Many-Objective Evolutionary Influence Maximization: Balancing Spread, Budget, Fairness, and Time](https://arxiv.org/abs/2403.18755) | 通过引入多目标进化算法，本研究在最大化影响和最小化种子集大小的基础上，优化了多个IM特定目标函数，包括预算、公平性、社区和时间。 |
| [^91] | [Chinese Offensive Language Detection:Current Status and Future Directions](https://arxiv.org/abs/2403.18314) | 总体而言，这篇论文讨论了在中文中检测 offensive 语言的挑战，并强调了开发解决这一问题的特定模型和工具。 |
| [^92] | [Oh! We Freeze: Improving Quantized Knowledge Distillation via Signal Propagation Analysis for Large Language Models](https://arxiv.org/abs/2403.18159) | 通过信号传播分析，提出了一种改进大型语言模型的量化知识蒸馏方法，并提供了ov-freeze稳定KD-QAT过程的洞察。 |
| [^93] | [Predicting species occurrence patterns from partial observations](https://arxiv.org/abs/2403.18028) | 提出了一个问题，即采用卫星图像和其他物种出现信息来预测物种出现模式，并提出了一个通用模型R-Tran，可以利用部分观测数据进行预测，优于其他方法。 |
| [^94] | [Improving Pre-trained Language Model Sensitivity via Mask Specific losses: A case study on Biomedical NER](https://arxiv.org/abs/2403.18025) | 提出了Mask Specific Language Modeling（MSLM）方法来改善LM在微调过程中对目标领域知识的敏感性，通过加权领域特定术语的重要性进行学习。 |
| [^95] | [LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning](https://arxiv.org/abs/2403.17919) | 逐层重要性采样的新方法LISA在微调任务中表现出色，记忆成本低且优于传统方法。 |
| [^96] | [All-in-One: Heterogeneous Interaction Modeling for Cold-Start Rating Prediction](https://arxiv.org/abs/2403.17740) | 提出了异质交互评分网络（HIRE）框架，通过异质交互模块（HIM）来共同建模异质交互并直接推断重要特征 |
| [^97] | [UADA3D: Unsupervised Adversarial Domain Adaptation for 3D Object Detection with Sparse LiDAR and Large Domain Gaps](https://arxiv.org/abs/2403.17633) | UADA3D是一种无监督对抗领域自适应方法，能够在3D物体检测中处理稀疏LiDAR数据和大领域差距，并在自动驾驶汽车和移动机器人领域中表现出显著的改进。 |
| [^98] | [Fake or JPEG? Revealing Common Biases in Generated Image Detection Datasets](https://arxiv.org/abs/2403.17608) | 许多AI生成图像检测数据集存在与JPEG压缩和图像大小相关的偏见，去除这些偏见可以显著提高对JPEG压缩的稳健性并显著改变检测器的跨生成器性能。 |
| [^99] | [CADGL: Context-Aware Deep Graph Learning for Predicting Drug-Drug Interactions](https://arxiv.org/abs/2403.17210) | 通过CADGL框架，利用上下文感知深度图学习来预测药物-药物相互作用，解决了现有DDI预测模型在泛化、特征提取和现实应用方面的挑战 |
| [^100] | [Deciphering the Interplay between Local Differential Privacy, Average Bayesian Privacy, and Maximum Bayesian Privacy](https://arxiv.org/abs/2403.16591) | 论文探讨了本地差分隐私、贝叶斯隐私及其之间的相互关系，揭示了关于效用-隐私权衡的新见解，并提出了一个框架来突出攻击和防御策略的相互作用和效果。 |
| [^101] | [DeepMachining: Online Prediction of Machining Errors of Lathe Machines](https://arxiv.org/abs/2403.16451) | DeepMachining是一种基于深度学习的AI系统，可以在线预测车床机床加工操作的误差，通过预训练和微调模型，实现了高准确性预测，是首批使用预训练深度学习模型预测车床机床加工误差的工厂实验之一。 |
| [^102] | [Can Language Models Pretend Solvers? Logic Code Simulation with LLMs](https://arxiv.org/abs/2403.16097) | 这项研究探讨了一种新颖的任务，即逻辑代码模拟，迫使LLMs在预测逻辑程序的结果时模拟逻辑求解器，同时提出了三个研究问题以深入调查这一任务对LLMs的影响。 |
| [^103] | [Finding needles in a haystack: A Black-Box Approach to Invisible Watermark Detection](https://arxiv.org/abs/2403.15955) | 提出了一种透明水印检测的黑盒方法WMD，在无注释设置下，利用干净无水印数据集检测任意水印，效果显著优于传统方法 |
| [^104] | [X-Portrait: Expressive Portrait Animation with Hierarchical Motion Attention](https://arxiv.org/abs/2403.15931) | 这里是中文总结出的一句话要点: 该论文提出了X-Portrait，一种用于生成具有表现力和时间连贯性的肖像动画的条件扩散模型，利用控制信号实现了细粒度头部姿势和表情控制，以提高运动精度。 |
| [^105] | [WoLF: Large Language Model Framework for CXR Understanding](https://arxiv.org/abs/2403.15456) | WoLF框架提出了对于CXR的全面理解的改进，包括使用额外的健康相关数据、重构报告以提供更有组织的信息、以及改进生成答案的细致评估。 |
| [^106] | [Trust in AI: Progress, Challenges, and Future Directions](https://arxiv.org/abs/2403.14680) | 人工智能中的信任是控制其传播程度的调节器，通过增加信任和减少不信任，可以显著影响人工智能的采用速度。 |
| [^107] | [Detoxifying Large Language Models via Knowledge Editing](https://arxiv.org/abs/2403.14472) | 本文研究了使用知识编辑技术对大型语言模型进行去毒化，在构建了SafeEdit基准的基础上，提出了一种简单而有效的方法 DINM，可以通过少量调整步骤减少模型的毒性，同时对各种去毒方法的内部机制进行了深入分析。 |
| [^108] | [Adaptive-RAG: Learning to Adapt Retrieval-Augmented Large Language Models through Question Complexity](https://arxiv.org/abs/2403.14403) | 通过新颖的自适应QA框架，根据查询的复杂度动态选择适合的检索增强大型语言模型策略，提高了回答准确性。 |
| [^109] | [ROUTERBENCH: A Benchmark for Multi-LLM Routing System](https://arxiv.org/abs/2403.12031) | 提出了ROUTERBENCH，一个用于评估LLM路由系统性能的基准测试框架，包括超过405k推理结果的数据集，以支持路由策略的开发。 |
| [^110] | [Towards Unified Multi-Modal Personalization: Large Vision-Language Models for Generative Recommendation and Beyond](https://arxiv.org/abs/2403.10667) | 本文旨在建立一个统一的多模态个性化系统(UniMP)，有效利用多模态数据同时消除与任务和模态特定定制相关的复杂性。 |
| [^111] | [OpenGraph: Open-Vocabulary Hierarchical 3D Graph Representation in Large-Scale Outdoor Environments](https://arxiv.org/abs/2403.09412) | 开放图谱是针对大规模室外环境设计的开放词汇分层图结构，旨在解决现有地图受限于室内场景和VLM特征的问题，通过视觉图像提取实例和标题，并加强文字推理。 |
| [^112] | [FluoroSAM: A Language-aligned Foundation Model for X-ray Image Segmentation](https://arxiv.org/abs/2403.08059) | FluoroSAM是用于X光图像的分割的语言对齐基础模型，提供了一种在X光成像领域具有广泛适用性的自动图像分析工具。 |
| [^113] | [Classifying Objects in 3D Point Clouds Using Recurrent Neural Network: A GRU LSTM Hybrid Approach](https://arxiv.org/abs/2403.05950) | 本文提出了一种使用GRU和LSTM混合方法进行3D点云中物体分类的深度学习策略，取得了高准确率，并在对多个类别的数据集中取得优异表现。 |
| [^114] | [OpenGraph: Towards Open Graph Foundation Models](https://arxiv.org/abs/2403.01121) | 该论文旨在通过开发一个通用图基础模型，以解决现有图神经网络在泛化到与训练数据显著不同的未见图数据时遇到的困难。 |
| [^115] | [MemoNav: Working Memory Model for Visual Navigation](https://arxiv.org/abs/2402.19161) | MemoNav提出了一种用于图像目标导航的新型记忆模型，通过三种导航记忆类型和遗忘模块提高了导航性能。 |
| [^116] | [LTL learning on GPUs](https://arxiv.org/abs/2402.12373) | 实现了首个基于GPU的LTL学习器，使用新颖的枚举式程序合成，性能显著优于现有最先进的学习器，处理跟踪至少多2048倍，速度平均快46倍，并且引入了具有$O(\log n)$时间复杂度的无分支LTL semantics。 |
| [^117] | [HU at SemEval-2024 Task 8A: Can Contrastive Learning Learn Embeddings to Detect Machine-Generated Text?](https://arxiv.org/abs/2402.11815) | 提出了一种基于对比学习的单一模型，用较少的参数实现与基线相当的机器生成文本检测性能 |
| [^118] | [Syntactic Language Change in English and German: Metrics, Parsers, and Convergences](https://arxiv.org/abs/2402.11549) | 本文研究英语和德语句法语言变化趋势，使用议会辩论语料库，探讨了句法依存距离最小化及基于树图属性的15个度量标准，揭示了现代解析器在这种变化中的影响。 |
| [^119] | [Brant-2: Foundation Model for Brain Signals](https://arxiv.org/abs/2402.10251) | Brant-2是脑信号领域最大的基础模型，相比于Brant，它不仅对数据变化和建模尺度具有稳健性，还能适用于更广泛范围的脑神经数据。 |
| [^120] | [PRDP: Proximal Reward Difference Prediction for Large-Scale Reward Finetuning of Diffusion Models](https://arxiv.org/abs/2402.08714) | 本研究提出了PRDP方法，通过近端奖励差异预测实现了稳定的黑盒奖励微调扩散模型，能够在大规模提示数据集上进行训练，并且具有更好的训练稳定性。 |
| [^121] | [Re-Envisioning Command and Control](https://arxiv.org/abs/2402.07946) | 重新构想的论文提出了未来指挥与控制（C2）决策需要面对更复杂和挑战性的环境，因此提出了基于人工智能系统与人类强有力伙伴关系的未来C2的愿景。这个愿景的核心是优化C2操作流程，保持协同努力，发展自适应的集体知识系统。 |
| [^122] | [Scalable Interactive Machine Learning for Future Command and Control](https://arxiv.org/abs/2402.06501) | 未来战争将需要指挥与控制（C2）人员在复杂且潜在模糊的情况下以更短的时间内做出决策。本论文通过利用互动式机器学习方法，结合人工智能和人类智能，以提高C2运作的适应性和效率。 |
| [^123] | [COA-GPT: Generative Pre-trained Transformers for Accelerated Course of Action Development in Military Operations](https://arxiv.org/abs/2402.01786) | COA-GPT是一种利用大型语言模型快速高效生成有效行动方案的算法，它融合了军事学说和领域专业知识，并在军事游戏中的实验中展示了其快速生成战略合理COAs的优势。 |
| [^124] | [HQ-VAE: Hierarchical Discrete Representation Learning with Variational Bayes](https://arxiv.org/abs/2401.00365) | HQ-VAE提出了一种统一框架，利用变分贝叶斯在分层结构中随机学习离散表示，解决了传统VQ-VAE中的码书/层坍塌问题。 |
| [^125] | [Do Similar Entities have Similar Embeddings?](https://arxiv.org/abs/2312.10370) | 本文挑战了实体相似性在图中在嵌入空间中自然反映的主流假设，通过进行广泛的实验来衡量这种关系。 |
| [^126] | [Open Datasheets: Machine-readable Documentation for Open Datasets and Responsible AI Assessments](https://arxiv.org/abs/2312.06153) | 本文介绍了一种面向开放数据集和负责任人工智能评估的机器可读文档框架，旨在提高数据集的可理解性和可用性，简化数据集评估过程，促进更可靠的数据应用，从而培育更负责任和可信赖的人工智能系统。 |
| [^127] | [MMM: Generative Masked Motion Model](https://arxiv.org/abs/2312.03596) | MMM 提出了一种基于遮蔽运动模型的新颖运动生成范式，通过运动标记器和条件遮蔽运动变换器，在实时性能、高保真度和运动可编辑性之间取得平衡。 |
| [^128] | [TimeChat: A Time-sensitive Multimodal Large Language Model for Long Video Understanding](https://arxiv.org/abs/2312.02051) | TimeChat是一种时间敏感的多模态大型语言模型，包含时间戳感知帧编码器和滑动视频Q-Former，以实现对长视频进行强大的零-shot时间本地化和推理能力。实验结果表明，在各种视频理解任务上表现出色。 |
| [^129] | [MRFP: Learning Generalizable Semantic Segmentation from Sim-2-Real with Multi-Resolution Feature Perturbation](https://arxiv.org/abs/2311.18331) | 提出了一种新颖的多尺度特征扰动技术(MRFP)，通过随机化领域特定的细粒度特征和扰动粗粒度特征的风格来解决从仿真到真实场景语义分割的泛化挑战 |
| [^130] | [Prompt Risk Control: A Rigorous Framework for Responsible Deployment of Large Language Models](https://arxiv.org/abs/2311.13628) | 提示风险控制是一个轻量级框架，通过严格的信息风险度量族的上限选取提示，帮助减轻大型语言模型负责部署过程中产生意外糟糕响应的风险。 |
| [^131] | [PIE-NeRF: Physics-based Interactive Elastodynamics with NeRF](https://arxiv.org/abs/2311.13099) | 该研究展示了物理学模拟与 NeRF 结合，无需中间形态代理，通过 Q-GMLS 捕捉非线性动力学和大形变，实现了高质量弹性动力学生成，并适应 NeRF 密度场调整最小二乘核，从而高效合成各种高弹性材料的物理逼真动画。 |
| [^132] | [Continual Learning: Applications and the Road Forward](https://arxiv.org/abs/2311.11908) | 连续学习是机器学习的子领域，致力于让机器学习模型在新数据上不断学习，而不忘记过去学到的知识。研究揭示了内存限制场景的主导地位，并讨论了连续学习在解决模型编辑、个性化、专业化、设备端学习、快速（重新）训练和强化学习等问题中的作用。 |
| [^133] | [Enhancing Object Coherence in Layout-to-Image Synthesis](https://arxiv.org/abs/2311.10522) | 本文提出了一种新颖的扩散模型，结合全局语义融合和自相似特征增强模块，以引导布局到图像合成中的对象连贯性。 |
| [^134] | [MacGyver: Are Large Language Models Creative Problem Solvers?](https://arxiv.org/abs/2311.09682) | 通过创建MACGYVER数据集并与人类比较，研究发现大型语言模型在创意问题解决方面独具挑战性，在知识广度和可行性方面与人类存在独特差异，同时还展示了通过新的提示技术提升大型语言模型的问题解决能力潜力。 |
| [^135] | [Towards probabilistic Weather Forecasting with Conditioned Spatio-Temporal Normalizing Flows](https://arxiv.org/abs/2311.06958) | 该论文提出了一种基于条件化归一化流的概率天气预测方法，通过实验证明其能够捕捉和良好外推空间-时间相关性。 |
| [^136] | [MCAD: Multi-teacher Cross-modal Alignment Distillation for efficient image-text retrieval](https://arxiv.org/abs/2310.19654) | 提出了一种Multi-teacher Cross-modality Alignment Distillation（MCAD）技术，通过将融合的单流特征合并到双流模型的图像和文本特征中，以整合单流和双流模型的优点。 |
| [^137] | [MILL: Mutual Verification with Large Language Models for Zero-Shot Query Expansion](https://arxiv.org/abs/2310.19056) | 该论文提出了一种利用大型语言模型进行相互验证的零-shot查询扩展框架，有效解决了查询扩展中已有方法的限制和缺陷。 |
| [^138] | [To Whom are You Talking? A Deep Learning Model to Endow Social Robots with Addressee Estimation Skills](https://arxiv.org/abs/2308.10757) | 通过深度学习模型，这项研究解决了社交机器人在生态场景中理解说话者对象的问题。 |
| [^139] | [Machine Learning-Powered Combinatorial Clock Auction](https://arxiv.org/abs/2308.10226) | 本文提出了一种机器学习驱动的组合时钟拍卖，通过仅使用需求查询而不是价值查询来获取投标人的偏好信息。 |
| [^140] | [Toward a Theory of Causation for Interpreting Neural Code Models](https://arxiv.org/abs/2302.03788) | 该论文介绍了一种名为$do_{code}$的后验解释方法，用于解释神经代码模型的预测，基于因果推断，旨在实现面向编程语言的解释。 |
| [^141] | [Optimal Transport Perturbations for Safe Reinforcement Learning with Robustness Guarantees](https://arxiv.org/abs/2301.13375) | 引入了基于最优输运扰动的安全强化学习框架，通过构建最坏情况的虚拟状态转换以提升鲁棒性能和安全性。 |
| [^142] | [SOLD: Sinhala Offensive Language Dataset](https://arxiv.org/abs/2212.00851) | 本文介绍了一种新的低资源语言——僧伽罗语攻击性语言识别数据集(SOLD)，填补了目前攻击性语言识别研究局限于高资源语言的空白。 |
| [^143] | [Efficient Deep Learning-based Estimation of the Vital Signs on Smartphones](https://arxiv.org/abs/2204.08989) | 提出了一种通过深度学习的端到端解决方案，用于在智能手机上高效估计生命体征，消除了繁琐的预处理步骤。 |
| [^144] | [Max-Utility Based Arm Selection Strategy For Sequential Query Recommendations](https://arxiv.org/abs/2108.13810) | 提出一种基于最大效用的臂选择策略，以减少在序列查询推荐中的累积遗憾。 |
| [^145] | [A Systematic Evaluation of Euclidean Alignment with Deep Learning for EEG Decoding.](http://arxiv.org/abs/2401.10746) | 本研究系统评估了使用深度学习和欧几里得对齐对脑电解码的影响。结果表明，欧几里得对齐能够显著提高解码率，并且减少了收敛时间。 |
| [^146] | [A Comprehensive Study of Knowledge Editing for Large Language Models.](http://arxiv.org/abs/2401.01286) | 本研究全面研究了大型语言模型的知识编辑，旨在有效修改模型的行为，同时保持整体性能。 |
| [^147] | [A Study on the Calibration of In-context Learning.](http://arxiv.org/abs/2312.04021) | 本研究关注上下文学习（ICL），通过定制提示来调整静态语言模型（LMs），研究了在各种自然语言理解和推理任务中性能和校准之间的平衡。研究发现随着ICL示例数量的增加，模型的校准会先增加而后得到改善，而校准误差主要出现在低样本场景下。此外，微调和CoT提示等方法可能导致校准误差和不可靠的自然语言解释，提示需要针对可靠性场景开发新的方法。 |
| [^148] | [Learning to Solve Climate Sensor Placement Problems with a Transformer.](http://arxiv.org/abs/2310.12387) | 本文介绍了一种使用深度强化学习方法学习改进传感器布放策略的新方法，通过与其他方法的对比实验证明了该方法在产生高质量解决方案方面的有效性和优越性。 |
| [^149] | [Rayleigh Quotient Graph Neural Networks for Graph-level Anomaly Detection.](http://arxiv.org/abs/2310.02861) | 《Rayleigh Quotient Graph Neural Networks用于图级异常检测的研究》提出使用Rayleigh Quotient作为驱动因素，通过探索图的固有光谱特征来实现图级异常检测。 |
| [^150] | [Tightest Admissible Shortest Path.](http://arxiv.org/abs/2308.08453) | 该论文提出了一种针对加权有向图的最严格可接受的最短路径问题，利用边权不确定性进行计算成本交换，并提供了一个完整的算法来解决此问题，并保证解的质量。 |
| [^151] | [Reasoning over the Behaviour of Objects in Video-Clips for Adverb-Type Recognition.](http://arxiv.org/abs/2307.04132) | 本研究提出了一种新的框架，通过对视频片段中提取的物体行为进行推理来识别副词类型。实验结果表明，我们的方法在效果上超越了之前的最先进方法。 |
| [^152] | [The FormAI Dataset: Generative AI in Software Security Through the Lens of Formal Verification.](http://arxiv.org/abs/2307.02192) | 本文介绍了一个名为FormAI的数据集，其中包含112,000个可编译的C程序，利用动态零-shot提示技术生成。这些程序经过形式验证，标记了源代码中的漏洞，并使用多种技术来提高程序的安全性和可靠性。 |
| [^153] | [RAPGen: An Approach for Fixing Code Inefficiencies in Zero-Shot.](http://arxiv.org/abs/2306.17077) | RAPGen是一种新方法，通过在零样本情况下使用Retrieval-Augmented Prompt Generation（RAPGen）方法，即从预先构建的性能Bug修复知识库中检索提示指令并生成提示，然后在大型语言模型上生成修复方案，可以有效地解决代码低效问题。实验结果显示，在专家验证的数据集中，RAPGen在60%的情况下可以生成与开发者等效或更好的性能改进建议，其中约39%的建议完全相同。 |
| [^154] | [Targeted collapse regularized autoencoder for anomaly detection: black hole at the center.](http://arxiv.org/abs/2306.12627) | 本文提出一种在自编码器的损失函数中添加一个轻量级的约束项，用于解决传统自编码器在异常检测中的不足，并取得了良好的表现。 |
| [^155] | [What's the Problem, Linda? The Conjunction Fallacy as a Fairness Problem.](http://arxiv.org/abs/2305.09535) | 这篇论文探讨了“连接谬误”作为公平性问题在人工智能领域中的重要性，并提出了一些问题，以帮助AI研究人员和从业者避免类似情况在未来中复现。 |
| [^156] | [Self-Supervised Clustering of Multivariate Time-Series Data for Identifying TBI Physiological States.](http://arxiv.org/abs/2303.13024) | 这篇论文提出了一种新的自监督聚类算法，能够在多元时间序列数据中确定并识别对于TBI等急性疾病治疗非常重要的生理状态。研究还利用临床数据验证并解释所识别的生理状态。 |
| [^157] | [Self-Prompting Large Language Models for Zero-Shot Open-Domain QA.](http://arxiv.org/abs/2212.08635) | 本论文提出了一种自我提示框架，可以有效利用大型语言模型的参数中存储的知识和指令理解能力，以实现零样本开放域问答，并且实验证明该方法在三个广泛使用的ODQA数据集中显著优于现有的最先进方法。 |

# 详细

[^1]: InterDreamer：零样本文本到三维动态人物-物体交互

    InterDreamer: Zero-Shot Text to 3D Dynamic Human-Object Interaction

    [https://arxiv.org/abs/2403.19652](https://arxiv.org/abs/2403.19652)

    通过解耦交互语义和动态，本文展示了在没有直接训练文本-交互对数据的情况下生成人物-物体交互的潜力。

    

    arXiv:2403.19652v1 宣布类型：跨领域 摘要：在广泛的动作捕捉数据和相应的文本注释上训练的扩散模型已经显著推动了文本条件的人体运动生成。然而，将这种成功延伸到三维动态人物-物体交互（HOI）生成面临着显著挑战，主要是由于缺乏大规模交互数据和与这些交互一致的全面描述。本文采取了行动，并展示了在没有直接训练文本-交互对数据的情况下生成人物-物体交互的潜力。我们在实现这一点的关键见解是交互语义和动态可以解耦。无法通过监督训练学习交互语义，我们转而利用预训练的大型模型，将来自大型语言模型和文本到运动模型的知识相辅相成。尽管这样的知识提供了对交互语义的高级控制，但不能提供到不成对交互文本的直接学习。

    arXiv:2403.19652v1 Announce Type: cross  Abstract: Text-conditioned human motion generation has experienced significant advancements with diffusion models trained on extensive motion capture data and corresponding textual annotations. However, extending such success to 3D dynamic human-object interaction (HOI) generation faces notable challenges, primarily due to the lack of large-scale interaction data and comprehensive descriptions that align with these interactions. This paper takes the initiative and showcases the potential of generating human-object interactions without direct training on text-interaction pair data. Our key insight in achieving this is that interaction semantics and dynamics can be decoupled. Being unable to learn interaction semantics through supervised training, we instead leverage pre-trained large models, synergizing knowledge from a large language model and a text-to-motion model. While such knowledge offers high-level control over interaction semantics, it c
    
[^2]: MagicLens：自监督图像检索与开放式指令

    MagicLens: Self-Supervised Image Retrieval with Open-Ended Instructions

    [https://arxiv.org/abs/2403.19651](https://arxiv.org/abs/2403.19651)

    本研究提出了MagicLens，一系列支持开放式指令的自监督图像检索模型，核心创新在于利用文本指令使得图像检索可以检索到比视觉相似性更丰富关系的图像。

    

    图像检索，即根据参考图像查找所需图像，固有地包含难以仅使用基于图像的度量捕捉到的丰富、多方面的搜索意图。最近的工作利用文本指令允许用户更自由地表达他们的搜索意图。然而，现有工作主要集中在那些视觉上相似和/或可以用一小组预定义关系来表征的图像对上。本文的核心论点是文本指令可以使图像检索能够检索到比视觉相似性更丰富关系的图像。为了证明这一点，我们引入了MagicLens，一系列支持开放式指令的自监督图像检索模型。MagicLens建立在一个重要的新颖见解上：自然发生在同一网页上的图像对包含着大量隐式关系（例如，内部视图），我们可以通过综合指令将这些隐式关系变为显式。

    arXiv:2403.19651v1 Announce Type: cross  Abstract: Image retrieval, i.e., finding desired images given a reference image, inherently encompasses rich, multi-faceted search intents that are difficult to capture solely using image-based measures. Recent work leverages text instructions to allow users to more freely express their search intents. However, existing work primarily focuses on image pairs that are visually similar and/or can be characterized by a small set of pre-defined relations. The core thesis of this paper is that text instructions can enable retrieving images with richer relations beyond visual similarity. To show this, we introduce MagicLens, a series of self-supervised image retrieval models that support open-ended instructions. MagicLens is built on a key novel insight: image pairs that naturally occur on the same web pages contain a wide range of implicit relations (e.g., inside view of), and we can bring those implicit relations explicit by synthesizing instructions
    
[^3]: 通过数据正则化的自我博弈强化学习实现与人类兼容的驾驶伙伴

    Human-compatible driving partners through data-regularized self-play reinforcement learning

    [https://arxiv.org/abs/2403.19648](https://arxiv.org/abs/2403.19648)

    提出了Human-Regularized PPO (HR-PPO)算法，通过自我博弈训练代理，实现在封闭环境中逼真且有效的驾驶伙伴

    

    自主驾驶汽车面临的一个核心挑战是与人类进行协调。因此，在模拟环境中，将逼真的人类代理纳入自动驾驶系统的可扩展训练和评估是至关重要的。我们提出了一种名为Human-Regularized PPO (HR-PPO)的多智能体算法，其中代理通过自我博弈进行训练，对偏离人类参考策略的行为进行小幅惩罚，以构建在封闭环境中既逼真又有效的代理。

    arXiv:2403.19648v1 Announce Type: cross  Abstract: A central challenge for autonomous vehicles is coordinating with humans. Therefore, incorporating realistic human agents is essential for scalable training and evaluation of autonomous driving systems in simulation. Simulation agents are typically developed by imitating large-scale, high-quality datasets of human driving. However, pure imitation learning agents empirically have high collision rates when executed in a multi-agent closed-loop setting. To build agents that are realistic and effective in closed-loop settings, we propose Human-Regularized PPO (HR-PPO), a multi-agent algorithm where agents are trained through self-play with a small penalty for deviating from a human reference policy. In contrast to prior work, our approach is RL-first and only uses 30 minutes of imperfect human demonstrations. We evaluate agents in a large set of multi-agent traffic scenes. Results show our HR-PPO agents are highly effective in achieving goa
    
[^4]: 稀疏特征电路：在语言模型中发现和编辑可解释的因果图

    Sparse Feature Circuits: Discovering and Editing Interpretable Causal Graphs in Language Models

    [https://arxiv.org/abs/2403.19647](https://arxiv.org/abs/2403.19647)

    该论文介绍了一种新方法，即稀疏特征电路，可以在语言模型中发现和编辑可解释的因果图，为我们提供了对未预料机制的详细理解和包含了用于提高分类器泛化能力的SHIFT方法。

    

    我们介绍了用于发现和应用稀疏特征电路的方法。这些电路是人类可解释特征的因果相关子网络，用于解释语言模型行为。 在先前的工作中确定的电路由多义且难以解释的单元组成，例如注意力头或神经元，使它们不适用于许多下游应用。 相比之下，稀疏特征电路实现了对未预料机制的详细理解。 由于它们基于细粒度单元，稀疏特征电路对下游任务非常有用：我们 introduc了SHIFT，通过切除人类判断为任务不相关的特征，从而提高分类器的泛化能力。 最后，我们通过发现成千上万个稀疏特征电路来展示一个完全无监督且可扩展的可解释性管线，用于自动发现的模型行为。

    arXiv:2403.19647v1 Announce Type: cross  Abstract: We introduce methods for discovering and applying sparse feature circuits. These are causally implicated subnetworks of human-interpretable features for explaining language model behaviors. Circuits identified in prior work consist of polysemantic and difficult-to-interpret units like attention heads or neurons, rendering them unsuitable for many downstream applications. In contrast, sparse feature circuits enable detailed understanding of unanticipated mechanisms. Because they are based on fine-grained units, sparse feature circuits are useful for downstream tasks: We introduce SHIFT, where we improve the generalization of a classifier by ablating features that a human judges to be task-irrelevant. Finally, we demonstrate an entirely unsupervised and scalable interpretability pipeline by discovering thousands of sparse feature circuits for automatically discovered model behaviors.
    
[^5]: 多跳问题回答中的检索增强知识编辑在语言模型中的应用

    Retrieval-Enhanced Knowledge Editing for Multi-Hop Question Answering in Language Models

    [https://arxiv.org/abs/2403.19631](https://arxiv.org/abs/2403.19631)

    提出了用于多跳问题回答的检索增强模型编辑（RAE）框架，利用互信息最大化的检索方法和修剪策略，实现了对语言模型的有效优化。

    

    大型语言模型（LLMs）在问题回答任务中显示出高效能，但往往难以整合实时知识更新，导致可能过时或不准确的响应。当处理多跳问题时，这个问题变得更具挑战性，因为它们要求LLMs更新和整合与问题相关的多个知识片段。为了解决这个问题，我们提出了针对多跳问题回答定制的检索增强模型编辑（RAE）框架。RAE首先检索编辑后的事实，然后通过上下文学习来完善语言模型。具体而言，我们的检索方法基于互信息最大化，利用LLMs的推理能力来识别链式事实，而天真的基于相似性的搜索可能会忽略这些事实。此外，我们的框架还采用了修剪策略，从检索到的事实中消除冗余信息，这增强了编辑

    arXiv:2403.19631v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have shown proficiency in question-answering tasks but often struggle to integrate real-time knowledge updates, leading to potentially outdated or inaccurate responses. This problem becomes even more challenging when dealing with multi-hop questions since they require LLMs to update and integrate multiple knowledge pieces relevant to the questions. To tackle the problem, we propose the Retrieval-Augmented model Editing (RAE) framework tailored for multi-hop question answering. RAE first retrieves edited facts and then refines the language model through in-context learning. Specifically, our retrieval approach, based on mutual information maximization, leverages the reasoning abilities of LLMs to identify chain facts that na\"ive similarity-based searches might miss. Additionally, our framework incorporates a pruning strategy to eliminate redundant information from the retrieved facts, which enhances the edi
    
[^6]: 在深度生成模型的潜在空间中协作互动演化艺术

    Collaborative Interactive Evolution of Art in the Latent Space of Deep Generative Models

    [https://arxiv.org/abs/2403.19620](https://arxiv.org/abs/2403.19620)

    本研究采用创意对抗网络和演化方法在深度生成模型的潜在空间中进行协作互动演化艺术，通过自动美学和协作交互式人类评估指标评估生成的图像质量。

    

    生成对抗网络（GANs）在生成高质量图像方面取得了巨大成功，因此被用作生成艺术图像的主要方法之一。然而，通常图像生成过程涉及从学习的艺术表征的潜在空间中进行采样，对输出的控制很少。在这项工作中，我们首先使用已知为创意对抗网络（CANs）的架构训练GANs生成创意图像，然后，我们采用一个演化方法在模型的潜在空间内导航以发现图像。我们使用自动美学和协作交互式人类评估指标来评估生成的图像。在人类互动评估案例中，我们提出了基于多位参与者评估的协作评估。此外，我们还尝试了一种旨在提高图像质量的智能突变运算符。

    arXiv:2403.19620v1 Announce Type: cross  Abstract: Generative Adversarial Networks (GANs) have shown great success in generating high quality images and are thus used as one of the main approaches to generate art images. However, usually the image generation process involves sampling from the latent space of the learned art representations, allowing little control over the output. In this work, we first employ GANs that are trained to produce creative images using an architecture known as Creative Adversarial Networks (CANs), then, we employ an evolutionary approach to navigate within the latent space of the models to discover images. We use automatic aesthetic and collaborative interactive human evaluation metrics to assess the generated images. In the human interactive evaluation case, we propose a collaborative evaluation based on the assessments of several participants. Furthermore, we also experiment with an intelligent mutation operator that aims to improve the quality of the ima
    
[^7]: 基于语义地图的导航说明生成

    Semantic Map-based Generation of Navigation Instructions

    [https://arxiv.org/abs/2403.19603](https://arxiv.org/abs/2403.19603)

    通过使用语义地图作为视觉输入，我们提出了一种新的导航说明生成方法，将问题构建为图像字幕任务，有望降低生成指令的计算复杂性。

    

    我们对导航说明的生成很感兴趣，无论是作为自身存在的文本还是作为机器人导航任务的训练材料。在本文中，我们提出了一种新的导航说明生成方法，将问题构建为使用语义地图作为视觉输入的图像字幕任务。传统方法采用一系列全景图像来生成导航说明。语义地图将视觉细节抽象出来，将多个全景图像中的信息融合到单个自上而下的表示中，从而降低了处理输入的计算复杂性。我们提供了一个使用语义地图生成说明的基准数据集，提出了一个初始模型，并请人工主观评估生成说明的质量。我们的初步调查显示，使用语义地图生成说明而不是一系列全景图像具有潜力，但研究范围仍然广阔。

    arXiv:2403.19603v1 Announce Type: cross  Abstract: We are interested in the generation of navigation instructions, either in their own right or as training material for robotic navigation task. In this paper, we propose a new approach to navigation instruction generation by framing the problem as an image captioning task using semantic maps as visual input. Conventional approaches employ a sequence of panorama images to generate navigation instructions. Semantic maps abstract away from visual details and fuse the information in multiple panorama images into a single top-down representation, thereby reducing computational complexity to process the input. We present a benchmark dataset for instruction generation using semantic maps, propose an initial model and ask human subjects to manually assess the quality of generated instructions. Our initial investigations show promise in using semantic maps for instruction generation instead of a sequence of panorama images, but there is vast sco
    
[^8]: 面向驾驶员中心驾驶风格自适应的情境感知

    Situation Awareness for Driver-Centric Driving Style Adaptation

    [https://arxiv.org/abs/2403.19595](https://arxiv.org/abs/2403.19595)

    提出了一种基于情境感知的驾驶风格模型，通过不同视觉特征编码器和驾驶行为预测器的结合，能够更好地适应驾驶情境，并在实验证明其优于静态驾驶风格。

    

    有证据表明，自动驾驶车辆的驾驶风格对于提高乘客的接受程度和信任度至关重要。驾驶情境已被发现对人类驾驶行为有显著影响。然而，当前的驾驶风格模型仅部分地将驾驶环境信息纳入考虑，限制了代理与给定情境之间的衔接。因此，我们提出了一种基于预先训练的不同视觉特征编码器和适应于特定驾驶员驾驶风格的驾驶行为预测器的情境感知驾驶风格模型。我们的实验表明，所提出的方法明显优于静态驾驶风格，并形成了合理的情境群聚。此外，我们发现在我们的数据集上预先训练的特征编码器能够带来更精确的驾驶行为建模。相比之下，在监督和无监督下预先训练的特征编码器导致模型性能下降。

    arXiv:2403.19595v1 Announce Type: cross  Abstract: There is evidence that the driving style of an autonomous vehicle is important to increase the acceptance and trust of the passengers. The driving situation has been found to have a significant influence on human driving behavior. However, current driving style models only partially incorporate driving environment information, limiting the alignment between an agent and the given situation. Therefore, we propose a situation-aware driving style model based on different visual feature encoders pretrained on fleet data, as well as driving behavior predictors, which are adapted to the driving style of a specific driver. Our experiments show that the proposed method outperforms static driving styles significantly and forms plausible situation clusters. Furthermore, we found that feature encoders pretrained on our dataset lead to more precise driving behavior modeling. In contrast, feature encoders pretrained supervised and unsupervised on d
    
[^9]: Img2Loc: 通过多模态基础模型和基于图像检索增强的生成重新审视图像地理定位

    Img2Loc: Revisiting Image Geolocalization using Multi-modality Foundation Models and Image-based Retrieval-Augmented Generation

    [https://arxiv.org/abs/2403.19584](https://arxiv.org/abs/2403.19584)

    Img2Loc通过多模态基础模型和基于图像检索增强的生成重新定义图像地理定位为文本生成任务。

    

    从图像中定位精确位置在计算机视觉和信息检索中是一个具有挑战性的问题。传统方法通常采用分类或检索，分类方法将地球表面划分为网格单元并相应地对图像进行分类，而检索方法通过将图像与图像-位置对数据库匹配来识别位置。然而，基于分类的方法受到单元格大小的限制，不能产生精确的预测，而基于检索的系统通常搜索质量较差，对全球景观在不同尺度和聚合级别的覆盖不足。为了克服这些缺点，我们提出了Img2Loc，这是一个通过文本生成任务重新定义图像地理定位的新系统。这是通过使用像GPT4V或LLaVA这样的尖端大型多模态模型与检索增强生成来实现的。Img2Loc首先使用基于CLIP的表示来生成一张图像。

    arXiv:2403.19584v1 Announce Type: cross  Abstract: Geolocating precise locations from images presents a challenging problem in computer vision and information retrieval.Traditional methods typically employ either classification, which dividing the Earth surface into grid cells and classifying images accordingly, or retrieval, which identifying locations by matching images with a database of image-location pairs. However, classification-based approaches are limited by the cell size and cannot yield precise predictions, while retrieval-based systems usually suffer from poor search quality and inadequate coverage of the global landscape at varied scale and aggregation levels. To overcome these drawbacks, we present Img2Loc, a novel system that redefines image geolocalization as a text generation task. This is achieved using cutting-edge large multi-modality models like GPT4V or LLaVA with retrieval augmented generation. Img2Loc first employs CLIP-based representations to generate an image
    
[^10]: 自我改进学习用于可扩展神经组合优化

    Self-Improved Learning for Scalable Neural Combinatorial Optimization

    [https://arxiv.org/abs/2403.19561](https://arxiv.org/abs/2403.19561)

    提出一种新颖的自我改进学习(SIL)方法，实现神经组合优化的更好可扩展性，通过自身生成解决方案作为伪标签，设计线性复杂度的注意机制来处理大规模组合优化问题实例。

    

    end-to-end神经组合优化(NCO)方法在解决复杂组合优化问题方面表现出有希望的性能，而不需要专家设计。然而，现有方法在处理大规模问题时存在困难，限制了它们的实际适用性。为了克服这一限制，本研究提出了一种新颖的自我改进学习(SIL)方法，以实现神经组合优化的更好可扩展性。具体来说，我们开发了一种高效的自我改进机制，使模型能够在没有标记数据的情况下直接在大规模问题实例上进行训练。通过一种创新的局部重构方法，该方法可以通过自身迭代生成更好的解决方案作为伪标签，以指导有效的模型训练。此外，我们设计了一种线性复杂度的注意机制，使模型能够有效处理低计算开销的大规模组合优化问题实例。

    arXiv:2403.19561v1 Announce Type: cross  Abstract: The end-to-end neural combinatorial optimization (NCO) method shows promising performance in solving complex combinatorial optimization problems without the need for expert design. However, existing methods struggle with large-scale problems, hindering their practical applicability. To overcome this limitation, this work proposes a novel Self-Improved Learning (SIL) method for better scalability of neural combinatorial optimization. Specifically, we develop an efficient self-improved mechanism that enables direct model training on large-scale problem instances without any labeled data. Powered by an innovative local reconstruction approach, this method can iteratively generate better solutions by itself as pseudo-labels to guide efficient model training. In addition, we design a linear complexity attention mechanism for the model to efficiently handle large-scale combinatorial problem instances with low computation overhead. Comprehens
    
[^11]: Croissant：一种面向机器学习数据集的元数据格式

    Croissant: A Metadata Format for ML-Ready Datasets

    [https://arxiv.org/abs/2403.19546](https://arxiv.org/abs/2403.19546)

    Croissant是一种面向机器学习数据集的元数据格式，使数据集更易发现、可移植和互操作，有助于解决ML数据管理和负责任AI中的重要挑战。

    

    数据是机器学习（ML）的关键资源，但处理数据仍然是一个主要的摩擦点。本文介绍了Croissant，一种用于数据集的元数据格式，简化了数据被ML工具和框架使用的方式。Croissant使数据集更易发现、可移植和互操作，从而解决了ML数据管理和负责任AI中的重要挑战。Croissant已得到几个流行数据集库的支持，涵盖数十万个数据集，可以加载到最流行的ML框架中。

    arXiv:2403.19546v1 Announce Type: cross  Abstract: Data is a critical resource for Machine Learning (ML), yet working with data remains a key friction point. This paper introduces Croissant, a metadata format for datasets that simplifies how data is used by ML tools and frameworks. Croissant makes datasets more discoverable, portable and interoperable, thereby addressing significant challenges in ML data management and responsible AI. Croissant is already supported by several popular dataset repositories, spanning hundreds of thousands of datasets, ready to be loaded into the most popular ML frameworks.
    
[^12]: 拉马克遗传改善机器人在动态环境中的进化

    Lamarckian Inheritance Improves Robot Evolution in Dynamic Environments

    [https://arxiv.org/abs/2403.19545](https://arxiv.org/abs/2403.19545)

    拉马克遗传原理在动态环境中优化机器人进化，表现出比传统达尔文模型更高的适应性和效率。

    

    本研究探讨了将拉马克系统整合到进化机器人学（ER）中，通过比较其与传统达尔文模型在不同环境下的表现。通过采用拉马克原则，即机器人继承学习到的特征，同时进行达尔文学习而不继承，我们研究了在动态设置中的适应性。我们在六个不同的环境设置中进行的研究表明，拉马克系统在适应性和效率方面的表现优于达尔文系统，特别是在具有挑战性的条件下。我们的分析突出了控制器和形态进化以及环境适应之间的相互作用的关键作用，父代和子代之间的相似性，以及学习前后的新生和幸存者提供了有关特征继承有效性的见解。我们的研究结果表明，拉马克原则可能显著推动自主系统设计的进步，强调了更丰富的潜力。

    arXiv:2403.19545v1 Announce Type: cross  Abstract: This study explores the integration of Lamarckian system into evolutionary robotics (ER), comparing it with the traditional Darwinian model across various environments. By adopting Lamarckian principles, where robots inherit learned traits, alongside Darwinian learning without inheritance, we investigate adaptation in dynamic settings. Our research, conducted in six distinct environmental setups, demonstrates that Lamarckian systems outperform Darwinian ones in adaptability and efficiency, particularly in challenging conditions. Our analysis highlights the critical role of the interplay between controller \& morphological evolution and environment adaptation, with parent-offspring similarities and newborn \&survivors before and after learning providing insights into the effectiveness of trait inheritance. Our findings suggest Lamarckian principles could significantly advance autonomous system design, highlighting the potential for more
    
[^13]: 解释基于Transformer模型的语言模型在事实回忆中的关键机制

    Interpreting Key Mechanisms of Factual Recall in Transformer-Based Language Models

    [https://arxiv.org/abs/2403.19521](https://arxiv.org/abs/2403.19521)

    通过深入研究Transformer-based语言模型在事实回忆任务中的机制，我们发现了零/少次样本情况下的特定任务头、MLP层和残差流的功能，以及抗过度自信机制。

    

    本文深入探讨了Transformer-based语言模型在事实回忆任务中所采用的机制。在零次样本情况下，给定类似“法国的首都是”的提示，特定任务的注意力头会从上下文中提取主题实体，如“法国”，并将其传递给后续的MLP以回忆所需的答案，如“巴黎”。我们引入了一种新颖的分析方法，旨在将MLP的输出分解为人类可理解的组件。通过这种方法，我们量化了跟随这些特定任务头的MLP层的功能。在残差流中，它会擦除或放大来自各个头的信息。此外，它会生成一个组件，将残差流重新定向到预期答案的方向。这些零次机制也适用于少次样本情况。此外，我们观察到一种广泛存在的抗过度自信机制。

    arXiv:2403.19521v1 Announce Type: cross  Abstract: In this paper, we deeply explore the mechanisms employed by Transformer-based language models in factual recall tasks. In zero-shot scenarios, given a prompt like "The capital of France is," task-specific attention heads extract the topic entity, such as "France," from the context and pass it to subsequent MLPs to recall the required answer such as "Paris." We introduce a novel analysis method aimed at decomposing the outputs of the MLP into components understandable by humans. Through this method, we quantify the function of the MLP layer following these task-specific heads. In the residual stream, it either erases or amplifies the information originating from individual heads. Moreover, it generates a component that redirects the residual stream towards the direction of its expected answer. These zero-shot mechanisms are also employed in few-shot scenarios. Additionally, we observed a widely existent anti-overconfidence mechanism in 
    
[^14]: RiEMann: 不需要点云分割的近实时 SE(3)等变机器人操作

    RiEMann: Near Real-Time SE(3)-Equivariant Robot Manipulation without Point Cloud Segmentation

    [https://arxiv.org/abs/2403.19460](https://arxiv.org/abs/2403.19460)

    RiEMann提出了一个近实时SE(3)等变机器人操作模仿学习框架，无需点云分割，可以从零开始学习操作任务，泛化到看不见的转换和目标对象实例，对抗视觉干扰，实时跟踪目标对象的姿势变化，同时具有可扩展的动作空间使得关节对象操作成为可能。

    

    我们提出了RiEMann，一个端到端的近实时 SE(3)等变机器人操作模仿学习框架，从场景点云输入中学习。与先前依赖描述符匹配的方法不同，RiEMann直接预测对象的目标姿势进行操作，而无需进行任何对象分割。RiEMann可以从零开始学习一个操作任务，只需5到10个演示，可以泛化到看不见的SE(3)转换和目标对象的实例，抵抗干扰对象的视觉干扰，并遵循目标对象的近实时姿势变化。RiEMann的可伸缩动作空间有助于添加自定义等变动作，例如旋转水龙头的方向，这使得RiEMann可以进行关节对象操作。在模拟和现实世界的6自由度机器人操作实验中，我们测试了RiEMann 对 5类操纵任务的25种变体进行了测试。

    arXiv:2403.19460v1 Announce Type: cross  Abstract: We present RiEMann, an end-to-end near Real-time SE(3)-Equivariant Robot Manipulation imitation learning framework from scene point cloud input. Compared to previous methods that rely on descriptor field matching, RiEMann directly predicts the target poses of objects for manipulation without any object segmentation. RiEMann learns a manipulation task from scratch with 5 to 10 demonstrations, generalizes to unseen SE(3) transformations and instances of target objects, resists visual interference of distracting objects, and follows the near real-time pose change of the target object. The scalable action space of RiEMann facilitates the addition of custom equivariant actions such as the direction of turning the faucet, which makes articulated object manipulation possible for RiEMann. In simulation and real-world 6-DOF robot manipulation experiments, we test RiEMann on 5 categories of manipulation tasks with a total of 25 variants and show
    
[^15]: NeuroLGP-SM：使用线性遗传规划的辅助神经进化方法

    NeuroLGP-SM: A Surrogate-assisted Neuroevolution Approach using Linear Genetic Programming

    [https://arxiv.org/abs/2403.19459](https://arxiv.org/abs/2403.19459)

    使用线性遗传规划作为表示，NeuroLGP-SM 提出了一种利用代理模型辅助神经进化的方法，以应对神经进化的计算挑战，同时保持良好的DNN准确性。

    

    进化算法越来越被认为是一种可行的计算方法，用于在人工智能领域自动优化深度神经网络（DNNs）。这种方法延伸到DNNs的训练，即所谓的神经进化方法。然而，神经进化是一个固有的资源密集型过程，某些研究报告称为改进和训练单个DNN网络消耗了数千个GPU天。为了解决与神经进化相关的计算挑战，同时仍然获得良好的DNN准确性，代理模型出现作为一个切实可行的解决方案。尽管代理模型有潜力，但是将代理模型整合到神经进化中仍处于起步阶段，受到诸如高维数据的有效利用和神经进化中采用的表示等因素的阻碍。在这个背景下，我们通过使用基于线性遗传规划的适当表示来解决这些挑战。

    arXiv:2403.19459v1 Announce Type: cross  Abstract: Evolutionary algorithms are increasingly recognised as a viable computational approach for the automated optimisation of deep neural networks (DNNs) within artificial intelligence. This method extends to the training of DNNs, an approach known as neuroevolution. However, neuroevolution is an inherently resource-intensive process, with certain studies reporting the consumption of thousands of GPU days for refining and training a single DNN network. To address the computational challenges associated with neuroevolution while still attaining good DNN accuracy, surrogate models emerge as a pragmatic solution. Despite their potential, the integration of surrogate models into neuroevolution is still in its early stages, hindered by factors such as the effective use of high-dimensional data and the representation employed in neuroevolution. In this context, we address these challenges by employing a suitable representation based on Linear Gen
    
[^16]: 通过死因调查笔记中的注释不一致性检测揭示自杀原因的误归因

    Uncovering Misattributed Suicide Causes through Annotation Inconsistency Detection in Death Investigation Notes

    [https://arxiv.org/abs/2403.19432](https://arxiv.org/abs/2403.19432)

    通过自然语言处理方法检测并纠正国家暴力死亡报告系统中的注释不一致性，提高了自杀危机分类器的性能。

    

    数据准确性对科学研究和政策制定至关重要。国家暴力死亡报告系统（NVDRS）数据被广泛用于发现死亡的模式和原因。最近的研究表明NVDRS内存在注释不一致性，并可能影响错误的自杀原因归因。我们提出了一种经验性的自然语言处理（NLP）方法来检测注释不一致性，并采用类似交叉验证的范式来识别有问题的实例。我们分析了2003年至2020年间从NVDRS中的267,804起自杀死亡案例。结果显示，将目标州的数据纳入训练自杀危机分类器，使得在目标州测试集上的F-1分数增加了5.4％，在其他州测试集上降低了1.1％。总之，我们展示了NVDRS死因调查笔记中的注释不一致性，并确定了问题的实例。

    arXiv:2403.19432v1 Announce Type: cross  Abstract: Data accuracy is essential for scientific research and policy development. The National Violent Death Reporting System (NVDRS) data is widely used for discovering the patterns and causes of death. Recent studies suggested the annotation inconsistencies within the NVDRS and the potential impact on erroneous suicide-cause attributions. We present an empirical Natural Language Processing (NLP) approach to detect annotation inconsistencies and adopt a cross-validation-like paradigm to identify problematic instances. We analyzed 267,804 suicide death incidents between 2003 and 2020 from the NVDRS. Our results showed that incorporating the target state's data into training the suicide-crisis classifier brought an increase of 5.4% to the F-1 score on the target state's test set and a decrease of 1.1% on other states' test set. To conclude, we demonstrated the annotation inconsistencies in NVDRS's death investigation notes, identified problema
    
[^17]: 语法跨度偏好在事后解释不一致中的作用

    The Role of Syntactic Span Preferences in Post-Hoc Explanation Disagreement

    [https://arxiv.org/abs/2403.19424](https://arxiv.org/abs/2403.19424)

    此研究从语言学角度研究了不同方法之间的解释不一致，发现在句法跨度水平上比较方法可以平滑掉标记级别的差异，提出了动态估计最重要跨度的方法，改进了选择重要标记的配置。

    

    事后解释方法是增加模型透明度对用户来说是一个重要工具。不幸的是，目前用于归因标记重要性的方法经常产生不同的模式。在这项工作中，我们从语言学角度研究了方法之间不一致的潜在来源。我们发现不同的方法系统地选择不同类别的词，并且那些与其他方法和人类达成最高一致性的方法展现出类似的语言偏好。如果我们在句法跨度水平上比较方法，那么方法之间的标记级差异就会被平滑掉。通过动态估计最重要的跨度而不是依赖于固定大小为$k$的子集，我们发现方法之间的一致性更高。我们系统地调查了$k$和跨度之间的交互作用，并提出了一个用于选择重要标记的改进配置。

    arXiv:2403.19424v1 Announce Type: cross  Abstract: Post-hoc explanation methods are an important tool for increasing model transparency for users. Unfortunately, the currently used methods for attributing token importance often yield diverging patterns. In this work, we study potential sources of disagreement across methods from a linguistic perspective. We find that different methods systematically select different classes of words and that methods that agree most with other methods and with humans display similar linguistic preferences. Token-level differences between methods are smoothed out if we compare them on the syntactic span level. We also find higher agreement across methods by estimating the most important spans dynamically instead of relying on a fixed subset of size $k$. We systematically investigate the interaction between $k$ and spans and propose an improved configuration for selecting important tokens.
    
[^18]: 在大规模个体fMRI数据集中扩展岭回归进行脑编码

    Scaling up ridge regression for brain encoding in a massive individual fMRI dataset

    [https://arxiv.org/abs/2403.19421](https://arxiv.org/abs/2403.19421)

    该论文评估了不同的并行化技术，以缩短岭回归脑编码模型训练时间，并在大规模深度fMRI数据集上取得了成功。

    

    使用神经影像数据进行大脑编码是一种旨在直接从复杂刺激特征（如电影帧）预测人类大脑活动的分析方法。岭回归是一种流行的脑编码预测模型，因为它具有良好的样本外泛化性能。然而，在处理包含许多大规模深度功能磁共振成像（fMRI）数据集时，训练岭回归模型可能非常耗时，这些数据集包括许多脑活动的空间-时间样本。本文评估了不同的并行化技术，以减少在CNeuroMod Friends数据集上使用岭回归进行脑编码的训练时间，该数据集是目前可用的最大的深度fMRI资源之一。通过多线程，我们的结果表明，Intel Math Kernel库（

    arXiv:2403.19421v1 Announce Type: cross  Abstract: Brain encoding with neuroimaging data is an established analysis aimed at predicting human brain activity directly from complex stimuli features such as movie frames. Typically, these features are the latent space representation from an artificial neural network, and the stimuli are image, audio, or text inputs. Ridge regression is a popular prediction model for brain encoding due to its good out-of-sample generalization performance. However, training a ridge regression model can be highly time-consuming when dealing with large-scale deep functional magnetic resonance imaging (fMRI) datasets that include many space-time samples of brain activity. This paper evaluates different parallelization techniques to reduce the training time of brain encoding with ridge regression on the CNeuroMod Friends dataset, one of the largest deep fMRI resource currently available. With multi-threading, our results show that the Intel Math Kernel Library (
    
[^19]: 排名中的公平性：通过随机化实现抗干扰而无需受保护属性

    Fairness in Ranking: Robustness through Randomization without the Protected Attribute

    [https://arxiv.org/abs/2403.19419](https://arxiv.org/abs/2403.19419)

    提出了一种针对排名后处理的随机化方法，无需受保护属性，通过数值研究显示了方法相对于基线排名的P-公平性和相对于归一化折扣累计增益(NDCG)的有效性的稳健性。

    

    关于机器学习中的公平性，尤其是与分类问题有关的公平性，引起了极大兴趣。在涉及排名的问题中，如在线广告、推荐系统和人力资源自动化中，仍然需要进行大量公平性方面的工作。两个复杂之处在于：首先，在许多应用程序中可能无法获取受保护属性。其次，排名的公平性存在多个衡量标准，基于单个衡量标准的优化方法可能会产生相对其他衡量标准不公平的排名。在这项工作中，我们提出了一种针对排名后处理的随机化方法，不需要受保护属性的可用性。通过广泛的数值研究，我们展示了我们的方法相对于基线排名的P-公平性和相对于归一化折扣累计增益(NDCG)的效果的稳健性，改进了先前提出的方法。

    arXiv:2403.19419v1 Announce Type: cross  Abstract: There has been great interest in fairness in machine learning, especially in relation to classification problems. In ranking-related problems, such as in online advertising, recommender systems, and HR automation, much work on fairness remains to be done. Two complications arise: first, the protected attribute may not be available in many applications. Second, there are multiple measures of fairness of rankings, and optimization-based methods utilizing a single measure of fairness of rankings may produce rankings that are unfair with respect to other measures. In this work, we propose a randomized method for post-processing rankings, which do not require the availability of the protected attribute. In an extensive numerical study, we show the robustness of our methods with respect to P-Fairness and effectiveness with respect to Normalized Discounted Cumulative Gain (NDCG) from the baseline ranking, improving on previously proposed meth
    
[^20]: 表格学习：实体和上下文嵌入的编码

    Tabular Learning: Encoding for Entity and Context Embeddings

    [https://arxiv.org/abs/2403.19405](https://arxiv.org/abs/2403.19405)

    挑战常用的序数编码，提出基于字符串相似性编码的表格学习方法，取得了更好的分类效果和性能提升。

    

    本文研究了不同编码技术对实体和上下文嵌入的影响，旨在挑战常用的序数编码在表格学习中的应用。通过在多个数据集上应用不同的预处理方法和网络架构，对编码器如何影响网络学习结果进行了评估。通过保持测试、验证和训练数据的一致性，结果表明，对于分类数据，序数编码并不是最合适的编码器，无法正确预处理数据并分类目标变量。通过基于字符串相似性对特征进行编码，计算相似性矩阵作为网络输入，取得了更好的结果。这适用于实体和上下文嵌入，在多标签分类中，变换器架构在序数编码和相似性编码方面表现出更好的性能。

    arXiv:2403.19405v1 Announce Type: cross  Abstract: Examining the effect of different encoding techniques on entity and context embeddings, the goal of this work is to challenge commonly used Ordinal encoding for tabular learning. Applying different preprocessing methods and network architectures over several datasets resulted in a benchmark on how the encoders influence the learning outcome of the networks. By keeping the test, validation and training data consistent, results have shown that ordinal encoding is not the most suited encoder for categorical data in terms of preprocessing the data and thereafter, classifying the target variable correctly. A better outcome was achieved, encoding the features based on string similarities by computing a similarity matrix as input for the network. This is the case for both, entity and context embeddings, where the transformer architecture showed improved performance for Ordinal and Similarity encoding with regard to multi-label classification 
    
[^21]: PointCloud-Text匹配：基准数据集和一个基线

    PointCloud-Text Matching: Benchmark Datasets and a Baseline

    [https://arxiv.org/abs/2403.19386](https://arxiv.org/abs/2403.19386)

    本文提出了一个新的实例级检索任务：PointCloud-Text匹配（PTM），并构建了三个新的基准数据集以解决数据稀疏、文本模糊等挑战，同时提出了RoMa方法作为PTM的基线模型。

    

    在本文中，我们介绍和研究了一个新的实例级检索任务：PointCloud-Text Matching（PTM），旨在找到与给定的点云查询或文本查询匹配的确切跨模态实例。PTM可应用于各种场景，如室内/城市峡谷定位和场景检索。然而，在实践中尚无适用的、有针对性的PTM数据集。因此，我们构建了三个新的PTM基准数据集，分别为3D2T-SR、3D2T-NR和3D2T-QA。我们观察到数据具有挑战性，由于点云的稀疏、噪声或无序，以及文本的模糊、含糊或不完整，导致存在嘈杂的对应关系，使得现有的跨模态匹配方法对PTM无效。为了解决这些挑战，我们提出了一个PTM基线，命名为Robust PointCloud-Text Matching方法（RoMa）。RoMa包含两个模块：双重注意感知模块（DAP）和鲁棒负对比模块

    arXiv:2403.19386v1 Announce Type: cross  Abstract: In this paper, we present and study a new instance-level retrieval task: PointCloud-Text Matching~(PTM), which aims to find the exact cross-modal instance that matches a given point-cloud query or text query. PTM could be applied to various scenarios, such as indoor/urban-canyon localization and scene retrieval. However, there exists no suitable and targeted dataset for PTM in practice. Therefore, we construct three new PTM benchmark datasets, namely 3D2T-SR, 3D2T-NR, and 3D2T-QA. We observe that the data is challenging and with noisy correspondence due to the sparsity, noise, or disorder of point clouds and the ambiguity, vagueness, or incompleteness of texts, which make existing cross-modal matching methods ineffective for PTM. To tackle these challenges, we propose a PTM baseline, named Robust PointCloud-Text Matching method (RoMa). RoMa consists of two modules: a Dual Attention Perception module (DAP) and a Robust Negative Contrast
    
[^22]: NIGHT -- 间接飞行时间数据的非视距成像

    NIGHT -- Non-Line-of-Sight Imaging from Indirect Time of Flight Data

    [https://arxiv.org/abs/2403.19376](https://arxiv.org/abs/2403.19376)

    本文首次使用来自即插即用的间接飞行时间传感器的数据，引入了一个深度学习模型，能够将光线反射发生的表面重新构建为虚拟镜子，从而实现了获取隐藏场景深度信息的可行性。

    

    从非视角相机外部获取物体是一个非常引人注目但也极具挑战性的研究课题。最近的工作表明，利用定制的直接飞行时间传感器产生的瞬时成像数据，这个想法是可行的。在本文中，我们首次使用来自即插即用的间接飞行时间传感器的数据来解决这个问题，而不需要任何额外的硬件要求。我们引入了一个深度学习模型，能够将光线反射发生的表面重新构建为虚拟镜子。这种建模使得任务更容易处理，也有助于构建带有注释的训练数据。从获得的数据中，可以恢复隐藏场景的深度信息。我们还提供了一个首创的合成数据集用于这个任务，并展示了所提出的想法的可行性。

    arXiv:2403.19376v1 Announce Type: cross  Abstract: The acquisition of objects outside the Line-of-Sight of cameras is a very intriguing but also extremely challenging research topic. Recent works showed the feasibility of this idea exploiting transient imaging data produced by custom direct Time of Flight sensors. In this paper, for the first time, we tackle this problem using only data from an off-the-shelf indirect Time of Flight sensor without any further hardware requirement. We introduced a Deep Learning model able to re-frame the surfaces where light bounces happen as a virtual mirror. This modeling makes the task easier to handle and also facilitates the construction of annotated training data. From the obtained data it is possible to retrieve the depth information of the hidden scene. We also provide a first-in-its-kind synthetic dataset for the task and demonstrate the feasibility of the proposed idea over it.
    
[^23]: 打破长度限制：LLM增强长文本用户行为中的CTR预测

    Breaking the Length Barrier: LLM-Enhanced CTR Prediction in Long Textual User Behaviors

    [https://arxiv.org/abs/2403.19347](https://arxiv.org/abs/2403.19347)

    BAHE提出了行为聚合分层编码（BAHE）来增强LLM-based CTR建模的效率，通过解耦用户行为的编码与行为之间的交互。

    

    随着大型语言模型（LLMs）的兴起，最近的研究利用LLMs提高了点击率（CTR）预测的性能。然而，我们认为在实际应用中部署LLMs仍然存在一个关键障碍：LLMs在处理长文本用户行为时的效率。随着用户序列变得更长，当前的LLMs效率不足以在数十亿用户和项目上进行训练。为了突破LLMs的效率障碍，我们提出了行为聚合分层编码（BAHE）来增强基于LLM的CTR建模的效率。具体地，BAHE提出了一种新颖的分层架构，将用户行为的编码与行为之间的交互解耦。首先，为了防止由于重复编码相同用户行为而产生的计算冗余，BAHE利用LLM的预训练浅层来提取最粒度的原子用户行为的嵌入。

    arXiv:2403.19347v1 Announce Type: cross  Abstract: With the rise of large language models (LLMs), recent works have leveraged LLMs to improve the performance of click-through rate (CTR) prediction. However, we argue that a critical obstacle remains in deploying LLMs for practical use: the efficiency of LLMs when processing long textual user behaviors. As user sequences grow longer, the current efficiency of LLMs is inadequate for training on billions of users and items. To break through the efficiency barrier of LLMs, we propose Behavior Aggregated Hierarchical Encoding (BAHE) to enhance the efficiency of LLM-based CTR modeling. Specifically, BAHE proposes a novel hierarchical architecture that decouples the encoding of user behaviors from inter-behavior interactions. Firstly, to prevent computational redundancy from repeated encoding of identical user behaviors, BAHE employs the LLM's pre-trained shallow layers to extract embeddings of the most granular, atomic user behaviors from ext
    
[^24]: 基于机器学习的智能电子商务产品分类与个性化推荐

    Intelligent Classification and Personalized Recommendation of E-commerce Products Based on Machine Learning

    [https://arxiv.org/abs/2403.19345](https://arxiv.org/abs/2403.19345)

    本论文比较了传统电子商务商品分类系统和个性化推荐系统的运作机制，阐述了个性化推荐系统在电子商务等领域中的重要性和应用，同时深入探讨了相关系统所面临的挑战。

    

    随着互联网的迅速发展和信息的指数级增长，用户遇到了信息过载和选择困境。个性化推荐系统通过帮助用户筛选和选择符合其偏好和需求的信息，从而在缓解这一负担方面发挥着关键作用。这些系统不仅提升了用户体验和满意度，还为企业和平台提供了增加用户参与度、销售额和广告效果的机会。本文对传统电子商务商品分类系统和个性化推荐系统的运作机制进行了比较分析，阐述了个性化推荐系统在电子商务、内容信息和媒体领域的重要性和应用。此外，还深入探讨了电子商务中个性化推荐系统所面临的挑战。

    arXiv:2403.19345v1 Announce Type: cross  Abstract: With the rapid evolution of the Internet and the exponential proliferation of information, users encounter information overload and the conundrum of choice. Personalized recommendation systems play a pivotal role in alleviating this burden by aiding users in filtering and selecting information tailored to their preferences and requirements. Such systems not only enhance user experience and satisfaction but also furnish opportunities for businesses and platforms to augment user engagement, sales, and advertising efficacy.This paper undertakes a comparative analysis between the operational mechanisms of traditional e-commerce commodity classification systems and personalized recommendation systems. It delineates the significance and application of personalized recommendation systems across e-commerce, content information, and media domains. Furthermore, it delves into the challenges confronting personalized recommendation systems in e-co
    
[^25]: Dataverse：用于大型语言模型的开源ETL（抽取、转换、加载）管道

    Dataverse: Open-Source ETL (Extract, Transform, Load) Pipeline for Large Language Models

    [https://arxiv.org/abs/2403.19340](https://arxiv.org/abs/2403.19340)

    Dataverse是一个面向大型语言模型的开源ETL管道，提供了用户友好的设计和易于定制的处理器添加功能，旨在成为LLM开发的重要工具，并开源整个库以促进社区贡献。

    

    为了解决规模化数据处理所面临的挑战，我们提出了Dataverse，一个统一的面向大型语言模型（LLMs）的开源抽取-转换-加载（ETL）管道，其核心具有用户友好的设计。在Dataverse中，通过基于块的界面轻松添加自定义处理器，使用户可以方便高效地使用Dataverse构建自己的ETL管道。我们希望Dataverse将成为LLM开发的重要工具，并开放整个库以欢迎社区贡献。此外，我们提供了一个简洁的、两分钟的系统演示视频，展示其功能和实现。

    arXiv:2403.19340v1 Announce Type: cross  Abstract: To address the challenges associated with data processing at scale, we propose Dataverse, a unified open-source Extract-Transform-Load (ETL) pipeline for large language models (LLMs) with a user-friendly design at its core. Easy addition of custom processors with block-based interface in Dataverse allows users to readily and efficiently use Dataverse to build their own ETL pipeline. We hope that Dataverse will serve as a vital tool for LLM development and open source the entire library to welcome community contribution. Additionally, we provide a concise, two-minute video demonstration of our system, illustrating its capabilities and implementation.
    
[^26]: IVLMap：针对消费级机器人导航的实例感知视觉语言基础

    IVLMap: Instance-Aware Visual Language Grounding for Consumer Robot Navigation

    [https://arxiv.org/abs/2403.19336](https://arxiv.org/abs/2403.19336)

    IVLMap为机器人导航提供了实例级和属性级语义映射能力，通过将RGBD视频数据与特定设计的自然语言地图索引相融合而实现。

    

    arXiv:2403.19336v1 公告类型：跨界摘要：视觉与语言导航（VLN）是一项具有挑战性的任务，需要机器人在真实环境中使用人类自然语言提示进行导航。最近的研究旨在通过构建环境的语义空间地图表示，然后利用大型语言模型在推理方面的强大能力来推广用于引导机器人导航的代码。然而，这些方法在实例级和属性级导航任务中面临限制，因为它们无法区分同一对象的不同实例。为解决这一挑战，我们提出了一种新方法，即实例感知视觉语言地图（IVLMap），以赋予机器人实例级和属性级语义映射，其中通过将机器人代理收集的RGBD视频数据与鸟瞰视角中特别设计的自然语言地图索引融合来自动构建。

    arXiv:2403.19336v1 Announce Type: cross  Abstract: Vision-and-Language Navigation (VLN) is a challenging task that requires a robot to navigate in photo-realistic environments with human natural language promptings. Recent studies aim to handle this task by constructing the semantic spatial map representation of the environment, and then leveraging the strong ability of reasoning in large language models for generalizing code for guiding the robot navigation. However, these methods face limitations in instance-level and attribute-level navigation tasks as they cannot distinguish different instances of the same object. To address this challenge, we propose a new method, namely, Instance-aware Visual Language Map (IVLMap), to empower the robot with instance-level and attribute-level semantic mapping, where it is autonomously constructed by fusing the RGBD video data collected from the robot agent with special-designed natural language map indexing in the bird's-in-eye view. Such indexing
    
[^27]: 基于超图的多视角事件相机动作识别

    Hypergraph-based Multi-View Action Recognition using Event Cameras

    [https://arxiv.org/abs/2403.19316](https://arxiv.org/abs/2403.19316)

    提出了一个名为HyperMV的多视角事件动作识别框架，实现了将离散事件数据转换成帧状表示，并利用共享卷积网络提取视角相关特征。

    

    视频数据的动作识别是具有广泛应用的基石。单视角动作识别由于依赖单一视角而面临限制。相比之下，多视角方法从不同视角捕获互补信息以提高准确性。最近，事件相机作为创新的仿生传感器崭露头角，为基于事件的动作识别带来了进展。然而，现有作品主要关注单一视角场景，在多视角事件数据利用方面存在空白，特别是在信息不足和语义错配等挑战方面。为了弥补这一空白，我们引入了HyperMV，这是一个多视角基于事件的动作识别框架。HyperMV将离散事件数据转换成类似帧的表示，并使用共享的卷积网络提取与视角相关的特征。通过将段视为顶点并使用基于规则的方法构建超边

    arXiv:2403.19316v1 Announce Type: cross  Abstract: Action recognition from video data forms a cornerstone with wide-ranging applications. Single-view action recognition faces limitations due to its reliance on a single viewpoint. In contrast, multi-view approaches capture complementary information from various viewpoints for improved accuracy. Recently, event cameras have emerged as innovative bio-inspired sensors, leading to advancements in event-based action recognition. However, existing works predominantly focus on single-view scenarios, leaving a gap in multi-view event data exploitation, particularly in challenges like information deficit and semantic misalignment. To bridge this gap, we introduce HyperMV, a multi-view event-based action recognition framework. HyperMV converts discrete event data into frame-like representations and extracts view-related features using a shared convolutional network. By treating segments as vertices and constructing hyperedges using rule-based and
    
[^28]: MATEval：用于推进开放性文本评估的多Agent讨论框架

    MATEval: A Multi-Agent Discussion Framework for Advancing Open-Ended Text Evaluation

    [https://arxiv.org/abs/2403.19305](https://arxiv.org/abs/2403.19305)

    提出了MATEval框架，利用多个类GPT-4的LLMs作为评估Agent，模拟人类合作讨论方法，以评估开放性文本，结合自我反思和思维链策略，并加入反馈机制，提升评估深度和广度。

    

    最近生成式大型语言模型（LLMs）的进展令人瞩目，然而，这些模型生成的文本质量经常暴露出持续存在的问题。评估这些模型生成的文本质量，特别是在开放性文本中，一直是一个重大挑战。为解决这一问题，最近的研究探讨了使用LLMs作为评估者的可能性。虽然使用单个LLM作为评估Agent表现出潜力，但却存在显著的不确定性和不稳定性。为了解决这些问题，我们提出了 MATEval：一种“多Agent文本评估框架”，其中所有Agent都由像GPT-4的LLMs扮演。MATEval框架模拟人类协作讨论方法，整合多个Agent的互动来评估开放性文本。我们的框架结合了自我反思和“思维链”策略，以及反馈机制，增强了评估的深度和广度。

    arXiv:2403.19305v1 Announce Type: cross  Abstract: Recent advancements in generative Large Language Models(LLMs) have been remarkable, however, the quality of the text generated by these models often reveals persistent issues. Evaluating the quality of text generated by these models, especially in open-ended text, has consistently presented a significant challenge. Addressing this, recent work has explored the possibility of using LLMs as evaluators. While using a single LLM as an evaluation agent shows potential, it is filled with significant uncertainty and instability. To address these issues, we propose the MATEval: A "Multi-Agent Text Evaluation framework" where all agents are played by LLMs like GPT-4. The MATEval framework emulates human collaborative discussion methods, integrating multiple agents' interactions to evaluate open-ended text. Our framework incorporates self-reflection and Chain-of-Thought (CoT) strategies, along with feedback mechanisms, enhancing the depth and br
    
[^29]: 用于治疗效果预测的图神经网络

    Graph Neural Networks for Treatment Effect Prediction

    [https://arxiv.org/abs/2403.19289](https://arxiv.org/abs/2403.19289)

    提出了一种图神经网络来减少治疗效果预测所需的训练集大小，有效利用电子商务数据的图结构，为治疗效果预测带来新的可能性

    

    在电子商务中估计因果效应往往涉及昂贵的治疗分配，这在大规模设置中可能是不切实际的。利用机器学习来预测这种治疗效果而无需实际干预是减少风险的一种标准做法。然而，现有的治疗效果预测方法往往依赖于大规模实验构建的训练集，因此从根本上存在风险。在这项工作中，我们提出了一种图神经网络，以减少所需的训练集大小，依赖于电子商务数据中常见的图。具体地，我们将问题视为具有有限数量标记实例的节点回归，开发了一个类似于先前因果效应估计器的双模型神经架构，并测试了不同的消息传递层进行编码。此外，作为额外步骤，我们将模型与获取函数相结合，以引导信息传递。

    arXiv:2403.19289v1 Announce Type: cross  Abstract: Estimating causal effects in e-commerce tends to involve costly treatment assignments which can be impractical in large-scale settings. Leveraging machine learning to predict such treatment effects without actual intervention is a standard practice to diminish the risk. However, existing methods for treatment effect prediction tend to rely on training sets of substantial size, which are built from real experiments and are thus inherently risky to create. In this work we propose a graph neural network to diminish the required training set size, relying on graphs that are common in e-commerce data. Specifically, we view the problem as node regression with a restricted number of labeled instances, develop a two-model neural architecture akin to previous causal effect estimators, and test varying message-passing layers for encoding. Furthermore, as an extra step, we combine the model with an acquisition function to guide the creation of th
    
[^30]: 使用奖励学习在策略上微调语言模型

    Fine-Tuning Language Models with Reward Learning on Policy

    [https://arxiv.org/abs/2403.19279](https://arxiv.org/abs/2403.19279)

    提出了在策略上的奖励学习框架，使用策略样本优化奖励模型以保持其分布上的一致性

    

    强化学习从人类反馈（RLHF）作为一种有效的方法出现，用于使大型语言模型（LLMs）与人类偏好保持一致。RLHF包含三个步骤，即收集人类偏好、奖励学习和策略优化，通常是串行执行的。然而，（固定的）奖励模型可能会因为策略优化不断改变LLMs的数据分布而遭受不准确的离分布情况。从最新的LLMs重复收集新的偏好数据可能会缓解这个问题，但不幸的是，这会使得结果系统更加复杂和难以优化。在本文中，我们提出了在策略上的奖励学习（RLP），这是一个无监督的框架，使用策略样本来优化奖励模型以保持其分布上的一致性。具体而言，引入了一种无监督的多视图学习方法来学习策略样本的稳健表示。

    arXiv:2403.19279v1 Announce Type: cross  Abstract: Reinforcement learning from human feedback (RLHF) has emerged as an effective approach to aligning large language models (LLMs) to human preferences. RLHF contains three steps, i.e., human preference collecting, reward learning, and policy optimization, which are usually performed serially. Despite its popularity, however, (fixed) reward models may suffer from inaccurate off-distribution, since policy optimization continuously shifts LLMs' data distribution. Repeatedly collecting new preference data from the latest LLMs may alleviate this issue, which unfortunately makes the resulting system more complicated and difficult to optimize. In this paper, we propose reward learning on policy (RLP), an unsupervised framework that refines a reward model using policy samples to keep it on-distribution. Specifically, an unsupervised multi-view learning method is introduced to learn robust representations of policy samples. Meanwhile, a synthetic
    
[^31]: 知识边界与角色动态塑造更好的社交媒体代理

    Knowledge Boundary and Persona Dynamic Shape A Better Social Media Agent

    [https://arxiv.org/abs/2403.19275](https://arxiv.org/abs/2403.19275)

    通过个性化知识和动态角色信息构建社交媒体代理以解决代理拥有不属于其角色的知识和无法消除多样化角色信息干扰的问题。

    

    构建个性化和拟人化代理在社交网络模拟中具有重要意义。然而，现有作品中仍存在两个关键问题：代理拥有不属于其角色的世界知识，不能消除多样化角色信息对当前行为的干扰，从而降低了代理的个性化和拟人化。为了解决以上问题，我们基于个性化知识和动态角色信息构建社交媒体代理。对于个性化知识，我们添加外部知识源并将其与代理的角色信息匹配，从而赋予代理个性化的世界知识。对于动态角色信息，我们使用当前行为信息内部检索代理的角色信息，从而减少多样化角色信息对当前行为的干扰。

    arXiv:2403.19275v1 Announce Type: cross  Abstract: Constructing personalized and anthropomorphic agents holds significant importance in the simulation of social networks. However, there are still two key problems in existing works: the agent possesses world knowledge that does not belong to its personas, and it cannot eliminate the interference of diverse persona information on current actions, which reduces the personalization and anthropomorphism of the agent. To solve the above problems, we construct the social media agent based on personalized knowledge and dynamic persona information. For personalized knowledge, we add external knowledge sources and match them with the persona information of agents, thereby giving the agent personalized world knowledge. For dynamic persona information, we use current action information to internally retrieve the persona information of the agent, thereby reducing the interference of diverse persona information on the current action. To make the age
    
[^32]: 一种整合土壤营养和气象因素的作物产量和病害预测的机器学习方法

    A Machine Learning Approach for Crop Yield and Disease Prediction Integrating Soil Nutrition and Weather Factors

    [https://arxiv.org/abs/2403.19273](https://arxiv.org/abs/2403.19273)

    本文提出了一种整合土壤营养和气象因素的机器学习方法，用于作物产量和病害预测，致力于解决孟加拉国农业中作物选择和病害预测中的挑战。

    

    本文的主要目标是开发一个智能的农业决策支持系统，用于孟加拉国的作物选择和病害预测。该国家的经济在很大程度上依赖于农业。然而，选择生产率更高的作物以及有效控制作物病害是农民必须面对的障碍。本研究通过利用机器学习方法和实际数据集来解决这些问题。推荐的方法使用了多种数据集，涵盖作物生产、土壤条件、农业气象区域、作物病害和气象因素。这些数据集提供了关于病害趋势、作物对土壤营养需求以及农业生产历史的有见地信息。通过整合这些知识，该模型首先根据特定用户位置的土壤营养推荐主要选定作物的列表。然后，通过将来自不同数据源的信息进行整合，模型可以预测不同作物的产量和病害情况。

    arXiv:2403.19273v1 Announce Type: cross  Abstract: The development of an intelligent agricultural decision-supporting system for crop selection and disease forecasting in Bangladesh is the main objective of this work. The economy of the nation depends heavily on agriculture. However, choosing crops with better production rates and efficiently controlling crop disease are obstacles that farmers have to face. These issues are addressed in this research by utilizing machine learning methods and real-world datasets. The recommended approach uses a variety of datasets on the production of crops, soil conditions, agro-meteorological regions, crop disease, and meteorological factors. These datasets offer insightful information on disease trends, soil nutrition demand of crops, and agricultural production history. By incorporating this knowledge, the model first recommends the list of primarily selected crops based on the soil nutrition of a particular user location. Then the predictions of me
    
[^33]: DeepSample：基于DNN采样的测试用于操作准确度评估

    DeepSample: DNN sampling-based testing for operational accuracy assessment

    [https://arxiv.org/abs/2403.19271](https://arxiv.org/abs/2403.19271)

    该研究基于概率采样提出了DeepSample，通过小数据集大小、可信赖的估计和误判曝光三方面的技术目标，实现了成本效益的DNN准确度评估。

    

    Deep Neural Networks（DNN）是许多软件系统分类和回归任务的核心组件。企业为使用代表操作中预期输入的数据集测试DNN而产生高成本，因为这些需要手动标记。挑战在于尽可能选择一组代表性的测试输入集，以减少标记成本，同时足以产生无偏高置信度的预期DNN准确性估计。同时，测试人员希望尽可能暴露出尽可能多的DNN误判，以改进DNN，因此需要追求三重目标的技术：小数据集大小、可信赖的估计和误判曝光。本研究提出了DeepSample，一种基于概率采样的用于成本效益的准确度评估的DNN测试技术系列。我们研究了概率采样在何种程度和在哪些条件下有助于

    arXiv:2403.19271v1 Announce Type: cross  Abstract: Deep Neural Networks (DNN) are core components for classification and regression tasks of many software systems. Companies incur in high costs for testing DNN with datasets representative of the inputs expected in operation, as these need to be manually labelled. The challenge is to select a representative set of test inputs as small as possible to reduce the labelling cost, while sufficing to yield unbiased high-confidence estimates of the expected DNN accuracy. At the same time, testers are interested in exposing as many DNN mispredictions as possible to improve the DNN, ending up in the need for techniques pursuing a threefold aim: small dataset size, trustworthy estimates, mispredictions exposure. This study presents DeepSample, a family of DNN testing techniques for cost-effective accuracy assessment based on probabilistic sampling. We investigate whether, to what extent, and under which conditions probabilistic sampling can help 
    
[^34]: sDPO：不要一次性使用您的数据

    sDPO: Don't Use Your Data All at Once

    [https://arxiv.org/abs/2403.19270](https://arxiv.org/abs/2403.19270)

    sDPO是对直接偏好优化方法的扩展，通过分步利用偏好数据集而非一次性使用，促进更精确对齐参考模型的使用，并训练出性能更优的最终模型，甚至胜过其他具有更多参数的流行大型语言模型。

    

    随着大型语言模型（LLM）的发展，将它们与人类偏好相一致变得日益重要。我们提出了分步DPO（sDPO），这是对最近流行的直接偏好优化（DPO）进行调整的一个扩展。这种方法涉及将可用的偏好数据集分割，并以分步方式利用它们，而不是一次性使用。我们演示了这种方法促进了更精确对齐参考模型在DPO训练框架内的使用。此外，sDPO训练最终模型的性能更好，甚至胜过拥有更多参数的其他流行LLM。

    arXiv:2403.19270v1 Announce Type: cross  Abstract: As development of large language models (LLM) progresses, aligning them with human preferences has become increasingly important. We propose stepwise DPO (sDPO), an extension of the recently popularized direct preference optimization (DPO) for alignment tuning. This approach involves dividing the available preference datasets and utilizing them in a stepwise manner, rather than employing it all at once. We demonstrate that this method facilitates the use of more precisely aligned reference models within the DPO training framework. Furthermore, sDPO trains the final model to be more performant, even outperforming other popular LLMs with more parameters.
    
[^35]: MineLand：模拟具有有限多模感知和生理需求的大规模多智能体交互

    MineLand: Simulating Large-Scale Multi-Agent Interactions with Limited Multimodal Senses and Physical Needs

    [https://arxiv.org/abs/2403.19267](https://arxiv.org/abs/2403.19267)

    MineLand模拟器引入有限多模感知和生理需求，支持多智能体在协作中填补了信息和功能限制的空白，从而促进更具动态和有效性的多智能体交互。

    

    传统的多智能体仿真器通常假设拥有完美信息和无限功能，这限制了社会互动的生态有效性。我们提出了一个多智能体Minecraft模拟器MineLand，通过引入有限的多模感知和生理需求来弥合这一差距。我们的仿真器支持最多48个具有有限视觉、听觉和环境意识的智能体，迫使它们积极沟通和协作以满足食物和资源等生理需求。这促进了动态和有效的多智能体交互。我们进一步介绍了一个灵感来自多任务处理理论的AI智能体框架Alex，使智能体能够处理复杂的协调和调度。我们的实验表明，该模拟器、相应的基准测试和AI智能体框架有助于更具生态和细致的集体行为。MineLand和Alex的源代码可以在https://github.com/c中公开获取。

    arXiv:2403.19267v1 Announce Type: cross  Abstract: Conventional multi-agent simulators often assume perfect information and limitless capabilities, hindering the ecological validity of social interactions. We propose a multi-agent Minecraft simulator, MineLand, that bridges this gap by introducing limited multimodal senses and physical needs. Our simulator supports up to 48 agents with limited visual, auditory, and environmental awareness, forcing them to actively communicate and collaborate to fulfill physical needs like food and resources. This fosters dynamic and valid multi-agent interactions. We further introduce an AI agent framework, Alex, inspired by multitasking theory, enabling agents to handle intricate coordination and scheduling. Our experiments demonstrate that the simulator, the corresponding benchmark, and the AI agent framework contribute to more ecological and nuanced collective behavior. The source code of MineLand and Alex is openly available at https://github.com/c
    
[^36]: 高效图像修饰的查找表优化

    Taming Lookup Tables for Efficient Image Retouching

    [https://arxiv.org/abs/2403.19238](https://arxiv.org/abs/2403.19238)

    提出了一种使用查找表进行高效边缘图像推断的ICELUT算法，无需卷积神经网络，在降低硬件推断时间和功耗的同时实现近乎最先进的性能。

    

    高清屏幕在端设备(如终端用户相机、智能手机和电视)上的广泛应用推动了图像增强需求的显着增长。现有的增强模型通常在优化高性能方面表现出色，但在减少硬件推断时间和功耗方面存在不足，特别是对于计算和存储资源受限的端设备而言。为此，我们提出了一种图像颜色增强查找表(ICELUT)方法，该方法采用查找表进行极其高效的边缘推断，而无需使用卷积神经网络(CNN)。在训练过程中，我们利用逐点(1x1)卷积来提取颜色信息，同时使用分割全连接层来融入全局信息。然后，这两个组件都无缝转换为查找表，以便进行硬件无关的部署。ICELUT实现了接近最先进的性能，同时功耗极低。

    arXiv:2403.19238v1 Announce Type: cross  Abstract: The widespread use of high-definition screens in edge devices, such as end-user cameras, smartphones, and televisions, is spurring a significant demand for image enhancement. Existing enhancement models often optimize for high performance while falling short of reducing hardware inference time and power consumption, especially on edge devices with constrained computing and storage resources. To this end, we propose Image Color Enhancement Lookup Table (ICELUT) that adopts LUTs for extremely efficient edge inference, without any convolutional neural network (CNN). During training, we leverage pointwise (1x1) convolution to extract color information, alongside a split fully connected layer to incorporate global information. Both components are then seamlessly converted into LUTs for hardware-agnostic deployment. ICELUT achieves near-state-of-the-art performance and remarkably low power consumption. We observe that the pointwise network s
    
[^37]: 朝着对缺失模态具有鲁棒性的多模态视频段落字幕生成模型

    Towards Multimodal Video Paragraph Captioning Models Robust to Missing Modality

    [https://arxiv.org/abs/2403.19221](https://arxiv.org/abs/2403.19221)

    提出了一种具有 Missing-Resistant 框架的多模态视频段落字幕生成模型，能够有效整合各种可用的辅助输入，在缺失某些模态的情况下仍能保持韧性，并引入了随机省略辅助输入的数据增强策略以及用于提炼知识的正则化目标。

    

    视频段落字幕生成（VPC）涉及为长视频生成详细的叙述，利用支持性模态，如语音和事件边界。然而，现有模型受制于一个假设，即单一辅助模态的恒定可用性，这在真实场景的多样性和不可预测性下是不切实际的。为此，我们提出了一个具有 Missing-Resistant 框架 MR-VPC，该框架有效地利用所有可用的辅助输入，并且即使某些模态缺失也能保持韧性。在该框架下，我们提出了融合视频、语音和事件边界输入的多模态 VPC（MVPC）架构，以统一方式处理各种辅助输入。此外，为了加强模型对不完整数据的鲁棒性，我们引入了 DropAM，一种随机省略辅助输入的数据增强策略，结合 DistillAM，一种用于提炼知识的正则化目标。

    arXiv:2403.19221v1 Announce Type: cross  Abstract: Video paragraph captioning (VPC) involves generating detailed narratives for long videos, utilizing supportive modalities such as speech and event boundaries. However, the existing models are constrained by the assumption of constant availability of a single auxiliary modality, which is impractical given the diversity and unpredictable nature of real-world scenarios. To this end, we propose a Missing-Resistant framework MR-VPC that effectively harnesses all available auxiliary inputs and maintains resilience even in the absence of certain modalities. Under this framework, we propose the Multimodal VPC (MVPC) architecture integrating video, speech, and event boundary inputs in a unified manner to process various auxiliary inputs. Moreover, to fortify the model against incomplete data, we introduce DropAM, a data augmentation strategy that randomly omits auxiliary inputs, paired with DistillAM, a regularization target that distills knowl
    
[^38]: 为联邦基金会模型提供双重个性化适配器

    Dual-Personalizing Adapter for Federated Foundation Models

    [https://arxiv.org/abs/2403.19211](https://arxiv.org/abs/2403.19211)

    提出了一种新的设置，称为测试时间个性化，不仅关注目标本地任务，还延伸到其他展示测试时间个性化的任务

    

    最近，基础模型，尤其是大型语言模型（LLMs），通过微调大量的指令数据，展现出了适应各种任务的令人印象深刻的能力。值得注意的是，联邦基金会模型作为一种隐私保护方法，在分布式学习（FL）环境下通过利用许多分布式数据集进行协作微调模型，这些数据集具有非IID数据。为了减轻通信和计算开销，引入了参数高效方法以提高效率，并且一些研究将个性化方法调整为联邦基金会模型，以获得更好的用户偏好对齐。然而，现有研究中存在的一个关键缺口是在真实应用中忽略了测试时间分布转移。因此，为了弥合这一差距，我们提出了一个新的设置，称为测试时间个性化，它不仅专注于目标本地任务，还延伸到其他展示测试时间个性化的任务。

    arXiv:2403.19211v1 Announce Type: cross  Abstract: Recently, foundation models, particularly large language models (LLMs), have demonstrated an impressive ability to adapt to various tasks by fine-tuning large amounts of instruction data. Notably, federated foundation models emerge as a privacy preservation method to fine-tune models collaboratively under federated learning (FL) settings by leveraging many distributed datasets with non-IID data. To alleviate communication and computation overhead, parameter-efficient methods are introduced for efficiency, and some research adapted personalization methods to federated foundation models for better user preferences alignment. However, a critical gap in existing research is the neglect of test-time distribution shifts in real-world applications. Therefore, to bridge this gap, we propose a new setting, termed test-time personalization, which not only concentrates on the targeted local task but also extends to other tasks that exhibit test-t
    
[^39]: 在分布式网络中增强信任和隐私：基于区块链的联邦学习综述

    Enhancing Trust and Privacy in Distributed Networks: A Comprehensive Survey on Blockchain-based Federated Learning

    [https://arxiv.org/abs/2403.19178](https://arxiv.org/abs/2403.19178)

    本文深入研究了基于区块链的联邦学习（BCFL），突出了区块链的安全功能与联邦学习的隐私保护模式之间的协同作用。

    

    当集中式服务器存在单点故障风险时，像区块链这样的去中心化方法通过在多个实体之间实施共识机制提供了一个引人注目的解决方案。将分布式计算与加密技术相结合，去中心化技术引入了一种新颖的计算范式。区块链通过在网络节点之间经过共识验证和记录交易来确保安全、透明和防篡改的数据管理。联邦学习（FL）作为一种分布式机器学习框架，使参与者能够在协同训练模型的同时通过避免直接原始数据交换来保护数据隐私。尽管对去中心化方法越来越感兴趣，但它们在FL中的应用仍然尚未得到充分探讨。本文深入调查了基于区块链的FL（BCFL），重点关注区块链的安全特性与FL的隐私保护模式之间的协同作用。

    arXiv:2403.19178v1 Announce Type: cross  Abstract: While centralized servers pose a risk of being a single point of failure, decentralized approaches like blockchain offer a compelling solution by implementing a consensus mechanism among multiple entities. Merging distributed computing with cryptographic techniques, decentralized technologies introduce a novel computing paradigm. Blockchain ensures secure, transparent, and tamper-proof data management by validating and recording transactions via consensus across network nodes. Federated Learning (FL), as a distributed machine learning framework, enables participants to collaboratively train models while safeguarding data privacy by avoiding direct raw data exchange. Despite the growing interest in decentralized methods, their application in FL remains underexplored. This paper presents a thorough investigation into Blockchain-based FL (BCFL), spotlighting the synergy between blockchain's security features and FL's privacy-preserving mo
    
[^40]: 重新思考医学图像分割中各种大小目标的信息丢失问题

    Rethinking Information Loss in Medical Image Segmentation with Various-sized Targets

    [https://arxiv.org/abs/2403.19177](https://arxiv.org/abs/2403.19177)

    引入了一种新型的Stagger网络（SNet），通过融合结构缓解CNN和ViTs之间的潜在特征分布差异，减少信息丢失。

    

    医学图像分割面临着以不同大小目标为特征的挑战，要求模型有效捕捉局部和全局信息。本文引入了一种新颖的Stagger网络（SNet），提出通过精心设计的融合结构来缓解CNN和ViTs之间的潜在特征分布差异，从而减少信息丢失。

    arXiv:2403.19177v1 Announce Type: cross  Abstract: Medical image segmentation presents the challenge of segmenting various-size targets, demanding the model to effectively capture both local and global information. Despite recent efforts using CNNs and ViTs to predict annotations of different scales, these approaches often struggle to effectively balance the detection of targets across varying sizes. Simply utilizing local information from CNNs and global relationships from ViTs without considering potential significant divergence in latent feature distributions may result in substantial information loss. To address this issue, in this paper, we will introduce a novel Stagger Network (SNet) and argues that a well-designed fusion structure can mitigate the divergence in latent feature distributions between CNNs and ViTs, thereby reducing information loss. Specifically, to emphasize both global dependencies and local focus, we design a Parallel Module to bridge the semantic gap. Meanwhil
    
[^41]: 用选择性过滤减轻具有误导性的思维链推理

    Mitigating Misleading Chain-of-Thought Reasoning with Selective Filtering

    [https://arxiv.org/abs/2403.19167](https://arxiv.org/abs/2403.19167)

    提出了一种名为选择性过滤推理器（SelF-Reasoner）的新方法，用于评估问题与候选推理链之间的蕴涵关系，以减轻具有误导性的思维链推理过程。

    

    大型语言模型通过利用思维链推理技术解决复杂问题，展现了卓越的能力。然而，这种推理的效力取决于思维链的质量。为了解决这一挑战，我们提出了一种名为选择性过滤推理器（SelF-Reasoner）的新方法，该方法评估问题与候选推理链之间的蕴涵关系。当推理链展示出自信时，我们继续进行思维链推理；否则，我们选择直接预测答案。SelF-Reasoner在ScienceQA、ECQA和LastLetter任务上持续改善了经过微调的T5基线。

    arXiv:2403.19167v1 Announce Type: cross  Abstract: Large language models have manifested remarkable capabilities by leveraging chain-of-thought (CoT) reasoning techniques to solve intricate questions through step-by-step reasoning chains. Despite its success, the efficacy of such reasoning is inherently contingent upon the quality of CoT. However, flawless CoT reasoning cannot be guaranteed due to the presence of indecomposable questions and the potential for erroneous reasoning chains, particularly in the case of small-scale language models. To tackle this challenge, we propose a novel approach called the selective filtering reasoner (SelF-Reasoner) that assesses the entailment relationship between the question and the candidate reasoning chain. Then, we proceed with CoT reasoning when the reasoning chain demonstrates confidence; otherwise, we opt to predict the answer directly. SelF-Reasoner improves the fine-tuned T5 baseline consistently over the ScienceQA, ECQA, and LastLetter tas
    
[^42]: STaR-GATE: 教授语言模型询问澄清问题

    STaR-GATE: Teaching Language Models to Ask Clarifying Questions

    [https://arxiv.org/abs/2403.19154](https://arxiv.org/abs/2403.19154)

    通过奖励语言模型生成有用问题来自我改进的方法，提问者通过询问角色扮演者来引出偏好，从而迭代微调以增加任务高质量响应的概率。

    

    当提示语言模型完成任务时，用户通常会遗漏重要的细节。虽然提问可以解决这种歧义，但模型往往很难提出好问题。我们探讨了语言模型通过奖励模型生成有用问题来自我改进的能力，这是一种简单方法，我们称之为STaR-GATE。我们生成了一个包含25,500个独特人物-任务提示的合成数据集，以模拟预训练语言模型--提问者--与一个其偏好未知的角色扮演者之间的对话。通过提问，提问者从角色扮演者那里引出偏好。提问者在那些增加高质量响应概率的问题上进行迭代微调，这些问题是由具有对角色扮演者访问权限的预言者生成的。

    arXiv:2403.19154v1 Announce Type: cross  Abstract: When prompting language models to complete a task, users often leave important aspects unsaid. While asking questions could resolve this ambiguity \citep[GATE;][]{li2023eliciting}, models often struggle to ask good questions. We explore a language model's ability to self-improve \citep[STaR;][]{zelikman2022star} by rewarding the model for generating useful questions -- a simple method we dub STaR-GATE. We generate a synthetic dataset of 25,500 unique persona-task prompts to simulate conversations between a pretrained language model -- the \texttt{Questioner} -- and a \texttt{Roleplayer} whose preferences are unknown to the \texttt{Questioner}. By asking questions, the \texttt{Questioner} elicits preferences from the \texttt{Roleplayer}. The \texttt{Questioner} is iteratively finetuned on questions that increase the probability of high-quality responses to the task, which are generated by an \texttt{Oracle} with access to the \texttt{Ro
    
[^43]: 探索混合对抗训练中的双重批量归一化模型

    Towards Understanding Dual BN In Hybrid Adversarial Training

    [https://arxiv.org/abs/2403.19150](https://arxiv.org/abs/2403.19150)

    在混合对抗训练中，分离仿射参数比分离统计数据在模型训练中发挥更重要的作用。

    

    有关在对抗训练（AT）中应用批量归一化（BN）的关注日益增长，尤其是当模型同时在对抗样本和干净样本上进行训练（称为混合-AT）时。一个先前研究常见的做法是假设对抗样本和干净样本来自两个不同的领域，采用双重BN，分别用于对抗分支和干净分支。激励双重BN的一种流行观念是，估计这种混合分布的规范化统计数据是具有挑战性的，因此为规范化而将其分开可以实现更强的鲁棒性。与这一观念相反，我们发现，在模型训练中，分离统计数据的作用比分离仿射参数的作用较小。这一发现与先前的研究（Rebuffi等人，2023）一致，我们在其研究的基础上进行进一步的探讨。

    arXiv:2403.19150v1 Announce Type: cross  Abstract: There is a growing concern about applying batch normalization (BN) in adversarial training (AT), especially when the model is trained on both adversarial samples and clean samples (termed Hybrid-AT). With the assumption that adversarial and clean samples are from two different domains, a common practice in prior works is to adopt Dual BN, where BN and BN are used for adversarial and clean branches, respectively. A popular belief for motivating Dual BN is that estimating normalization statistics of this mixture distribution is challenging and thus disentangling it for normalization achieves stronger robustness. In contrast to this belief, we reveal that disentangling statistics plays a less role than disentangling affine parameters in model training. This finding aligns with prior work (Rebuffi et al., 2023), and we build upon their research for further investigations. We demonstrate that the domain gap between adversarial and clean sam
    
[^44]: GenAI检测工具，对抗技术及其对高等教育包容性的影响

    GenAI Detection Tools, Adversarial Techniques and Implications for Inclusivity in Higher Education

    [https://arxiv.org/abs/2403.19148](https://arxiv.org/abs/2403.19148)

    GenAI检测工具在面对通过对抗技术修改的内容时准确性显著下降，不能推荐用于确定学术诚信违规，但在支持学生学习和维护学术诚信方面可能有帮助

    

    本研究调查了六种主要生成式AI（GenAI）文本检测器在面对用于规避这些工具检测的技术修改的机器生成内容时的有效性（n = 805）。结果表明，检测器的准确率已经很低（39.5％），当面对被操纵的内容时，准确率显着降低（17.4％），并且一些技术在规避检测方面比其他技术更有效。 准确性限制和可能导致错误指控的情况表明，这些工具目前无法推荐用于确定是否发生了学术诚信的违规行为，突显了教育工作者在维护包容和公平评估实践方面面临的挑战。 但是，当以非惩罚性方式使用时，它们可能在支持学生学习和维护学术诚信方面发挥作用。 这些结果强调了需要综合方法的必要性

    arXiv:2403.19148v1 Announce Type: cross  Abstract: This study investigates the efficacy of six major Generative AI (GenAI) text detectors when confronted with machine-generated content that has been modified using techniques designed to evade detection by these tools (n=805). The results demonstrate that the detectors' already low accuracy rates (39.5%) show major reductions in accuracy (17.4%) when faced with manipulated content, with some techniques proving more effective than others in evading detection.   The accuracy limitations and the potential for false accusations demonstrate that these tools cannot currently be recommended for determining whether violations of academic integrity have occurred, underscoring the challenges educators face in maintaining inclusive and fair assessment practices. However, they may have a role in supporting student learning and maintaining academic integrity when used in a non-punitive manner.   These results underscore the need for a combined appro
    
[^45]: QNCD：扩散模型的量化噪声校正

    QNCD: Quantization Noise Correction for Diffusion Models

    [https://arxiv.org/abs/2403.19140](https://arxiv.org/abs/2403.19140)

    研究提出了一个统一的量化噪声校正方案（QNCD），旨在减小扩散模型中的量化噪声，解决了后训练量化对采样加速的影响问题。

    

    扩散模型在图像合成领域引起了革命，建立了质量和创造力的新基准。然而，它们在迭代去噪过程中需要的密集计算阻碍了它们的广泛采用。后训练量化（PTQ）提供了一种解决方案，可以加速采样，尽管以低比特设置极大降低了样本质量。针对这一问题，我们的研究引入了一个统一的量化噪声校正方案（QNCD），旨在减小整个采样过程中的量化噪声。我们确定了两个主要的量化挑战：内部和外部量化噪声。内部量化噪声主要由于嵌入在resblock模块中而加剧，扩展了激活量化范围，在每个单独的去噪步骤中增加了干扰。此外，外部量化噪声源自整个去噪过程中的累积量化偏差，改变了数据分布。

    arXiv:2403.19140v1 Announce Type: cross  Abstract: Diffusion models have revolutionized image synthesis, setting new benchmarks in quality and creativity. However, their widespread adoption is hindered by the intensive computation required during the iterative denoising process. Post-training quantization (PTQ) presents a solution to accelerate sampling, aibeit at the expense of sample quality, extremely in low-bit settings. Addressing this, our study introduces a unified Quantization Noise Correction Scheme (QNCD), aimed at minishing quantization noise throughout the sampling process. We identify two primary quantization challenges: intra and inter quantization noise. Intra quantization noise, mainly exacerbated by embeddings in the resblock module, extends activation quantization ranges, increasing disturbances in each single denosing step. Besides, inter quantization noise stems from cumulative quantization deviations across the entire denoising process, altering data distributions 
    
[^46]: 通过简化不重要的层压缩大型语言模型

    Compressing Large Language Models by Streamlining the Unimportant Layer

    [https://arxiv.org/abs/2403.19135](https://arxiv.org/abs/2403.19135)

    通过观察大型语言模型中不同层对隐藏状态的影响程度，提出了LLM-Streamline方法，包括层剪枝和层替换，用于压缩模型并保持性能。

    

    大型语言模型(LLM)已广泛应用于各种自然语言任务和领域，但其适用性受到模型参数的限制。因此，越来越多的人关注表现出高性能的紧凑模型。在这项研究中，我们观察到LLM的不同层对隐藏状态有不同程度的扰动，这使我们能够识别出不那么重要的层。基于这一现象，我们提出了LLM-Streamline，包括两部分：层剪枝，根据目标稀疏度移除模型中一组连续的最不重要的层；层替换，训练一个轻量级模型来替换被剪枝的层，从而缓解由剪枝造成的性能下降。在实验中，我们利用了多层感知器(MLP)和一个transformer层等结构作为轻量级模型。

    arXiv:2403.19135v1 Announce Type: cross  Abstract: Large language models (LLM) have been extensively applied in various natural language tasks and domains, but their applicability is constrained by the large number of parameters of the models. Consequently, there is an increasing emphasis on compact models that exhibit high performance. In this study, we observe that different layers in LLM have varying degrees of perturbation on the hidden states, which allows us to identify less important layers. Based on this phenomenon, we propose LLM-Streamline, which consists of two parts: layer pruning, where we remove a set of consecutive layers with the lowest importance in the model according to the target sparsity; and layer replacement, where we train a lightweight model to substitute the pruned layers, thereby mitigating the performance degradation caused by pruning. In our experiments, we utilize structures such as a multi-layer perceptron (MLP) and a transformer layer as lightweight mode
    
[^47]: MFORT-QA: 多跳少样本开放式丰富表格问答

    MFORT-QA: Multi-hop Few-shot Open Rich Table Question Answering

    [https://arxiv.org/abs/2403.19116](https://arxiv.org/abs/2403.19116)

    本文介绍了MFORT-QA方法，通过Few-Shot Learning和大语言模型，实现了在表格数据中进行多跳少样本的开放式丰富问答。

    

    在当今快节奏的行业中，专业人士每天面临着总结大量文档并从中提取关键信息的挑战。这些度量经常隐藏在表格和/或其嵌套的超链接中。为了应对这一挑战，开发了表格问答（QA）方法来提取相关信息。然而，传统的表格QA训练任务并不总是能确保提取准确答案，这些任务会向问题提供一个表格和一个或多个来自黄金单元格坐标的答案。近期大语言模型（LLM）的进展为使用提示从表格数据中提取信息开辟了新的可能性。本文介绍了Multi-hop Few-shot Open Rich Table QA（MFORT-QA）方法，该方法包括两个主要步骤。

    arXiv:2403.19116v1 Announce Type: cross  Abstract: In today's fast-paced industry, professionals face the challenge of summarizing a large number of documents and extracting vital information from them on a daily basis. These metrics are frequently hidden away in tables and/or their nested hyperlinks. To address this challenge, the approach of Table Question Answering (QA) has been developed to extract the relevant information. However, traditional Table QA training tasks that provide a table and an answer(s) from a gold cell coordinate(s) for a question may not always ensure extracting the accurate answer(s). Recent advancements in Large Language Models (LLMs) have opened up new possibilities for extracting information from tabular data using prompts. In this paper, we introduce the Multi-hop Few-shot Open Rich Table QA (MFORT-QA) approach, which consists of two major steps. The first step involves Few-Shot Learning (FSL), where relevant tables and associated contexts of hyperlinks ar
    
[^48]: FACTOID: 用于幻觉检测的事实推理（FACTOID: FACtual enTailment fOr hallucInation Detection）

    FACTOID: FACtual enTailment fOr hallucInation Detection

    [https://arxiv.org/abs/2403.19113](https://arxiv.org/abs/2403.19113)

    本文表明传统的文本蕴涵方法无法有效地发现大型语言模型生成的内容中存在的幻觉问题。

    

    大型语言模型（LLMs）的广泛应用带来了许多好处，但幻觉是一个重要的问题。为应对这一问题，检索增强生成（RAG）作为一种高度有前途的范式出现，通过在事实信息中接地来提升LLMs的输出。RAG依赖于文本蕴涵（TE）或类似方法，检查LLMs生成的文本是否被检索文档支持或反驳。本文认为传统的TE方法不适用于发现LLMs生成内容中的幻觉。例如，考虑一个关于“美国对乌克兰战争立场”的提示。AI生成的文本表示，“美国总统巴拉克·奥巴马说美国不会派兵进入乌克兰”，然而在战争期间，美国总统是乔·拜登，这与事实不符。此外，当前的TE系统无法准确注释给定的文本和识别幻觉。

    arXiv:2403.19113v1 Announce Type: cross  Abstract: The widespread adoption of Large Language Models (LLMs) has facilitated numerous benefits. However, hallucination is a significant concern. In response, Retrieval Augmented Generation (RAG) has emerged as a highly promising paradigm to improve LLM outputs by grounding them in factual information. RAG relies on textual entailment (TE) or similar methods to check if the text produced by LLMs is supported or contradicted, compared to retrieved documents. This paper argues that conventional TE methods are inadequate for spotting hallucinations in content generated by LLMs. For instance, consider a prompt about the 'USA's stance on the Ukraine war''. The AI-generated text states, ...U.S. President Barack Obama says the U.S. will not put troops in Ukraine...'' However, during the war the U.S. president is Joe Biden which contradicts factual reality. Moreover, current TE systems are unable to accurately annotate the given text and identify th
    
[^49]: 用于个性化文本到图像生成的自动化黑盒提示工程

    Automated Black-box Prompt Engineering for Personalized Text-to-Image Generation

    [https://arxiv.org/abs/2403.19103](https://arxiv.org/abs/2403.19103)

    PRISM是一种算法，可以自动识别人类可解释且易传递的提示，从而有效生成所需概念，仅使用黑盒访问T2I模型。

    

    提示工程对于控制文本到图像（T2I）生成模型的输出是有效的，但由于需要手动制作提示而导致工作繁重。这一挑战促使了自动提示生成算法的发展。然而，这些方法通常在T2I模型之间的可传递性方面遇到困难，需要对基础模型进行白盒访问，并产生非直观的提示。在这项工作中，我们介绍了PRISM，这是一种算法，可以仅使用黑盒访问T2I模型就自动识别人类可解释且易传递的提示，从而有效生成所需概念。受大型语言模型（LLM）越狱的启发，PRISM利用LLM的上下文学习能力来迭代地改进给定参考图像的候选提示分布。我们的实验展示了PRISM在为对象、样式等生成准确提示方面的多样性和有效性。

    arXiv:2403.19103v1 Announce Type: cross  Abstract: Prompt engineering is effective for controlling the output of text-to-image (T2I) generative models, but it is also laborious due to the need for manually crafted prompts. This challenge has spurred the development of algorithms for automated prompt generation. However, these methods often struggle with transferability across T2I models, require white-box access to the underlying model, and produce non-intuitive prompts. In this work, we introduce PRISM, an algorithm that automatically identifies human-interpretable and transferable prompts that can effectively generate desired concepts given only black-box access to T2I models. Inspired by large language model (LLM) jailbreaking, PRISM leverages the in-context learning ability of LLMs to iteratively refine the candidate prompts distribution for given reference images. Our experiments demonstrate the versatility and effectiveness of PRISM in generating accurate prompts for objects, sty
    
[^50]: AAPMT: 通过提示和度量转换器评估通用人工智能

    AAPMT: AGI Assessment Through Prompt and Metric Transformer

    [https://arxiv.org/abs/2403.19101](https://arxiv.org/abs/2403.19101)

    本研究旨在开发一个模型，通过提示和度量转换器来评估通用人工智能生成图像的质量，填补当前评估方法与最先进标准之间的差距。

    

    文本到图像模型的出现标志着人工智能生成图像（AGIs）发展历程中的重要里程碑，扩大了它们在设计、娱乐等各个领域的应用。尽管取得了这些突破，但AGIs的质量往往仍然不理想，突显了有效评估方法的必要性。这些方法对于评估图像与其文本描述之间的质量至关重要，并且必须准确反映人类感知。在这个领域取得了实质性进展，创新技术如BLIP和DBCNN做出了重大贡献。然而，最近的研究，包括AGIQA-3K，揭示了当前方法与最先进标准之间的显著差异。这一差距强调了更复杂和准确的评估度量的必要性。因此，我们的目标是开发一个能够为度量提供评分的模型，重点关注参数。

    arXiv:2403.19101v1 Announce Type: cross  Abstract: The emergence of text-to-image models marks a significant milestone in the evolution of AI-generated images (AGIs), expanding their use in diverse domains like design, entertainment, and more. Despite these breakthroughs, the quality of AGIs often remains suboptimal, highlighting the need for effective evaluation methods. These methods are crucial for assessing the quality of images relative to their textual descriptions, and they must accurately mirror human perception. Substantial progress has been achieved in this domain, with innovative techniques such as BLIP and DBCNN contributing significantly. However, recent studies, including AGIQA-3K, reveal a notable discrepancy between current methods and state-of-the-art (SOTA) standards. This gap emphasizes the necessity for a more sophisticated and precise evaluation metric. In response, our objective is to develop a model that could give ratings for metrics, which focuses on parameters
    
[^51]: Task2Morph：可微分的基于任务启发的接触感知机器人设计框架

    Task2Morph: Differentiable Task-inspired Framework for Contact-Aware Robot Design

    [https://arxiv.org/abs/2403.19093](https://arxiv.org/abs/2403.19093)

    该论文提出了一个新颖的可微分的基于任务启发的接触感知机器人设计框架Task2Morph，通过将任务特征抽象到任务到形态的映射中，实现整体优化和映射学习。

    

    优化适应各种任务的机器人形态和控制器是机器人设计领域中的关键问题，又称为具身智能。本文提出了一种新颖且通用的可微分任务启发式接触感知机器人设计框架Task2Morph。我们将与任务性能高度相关的任务特征抽象出来，用于构建任务到形态的映射。此外，我们将映射嵌入到一个可微分的机器人设计过程中，其中梯度信息被用于映射学习以及整体优化。实验在某一数据集上进行。

    arXiv:2403.19093v1 Announce Type: cross  Abstract: Optimizing the morphologies and the controllers that adapt to various tasks is a critical issue in the field of robot design, aka. embodied intelligence. Previous works typically model it as a joint optimization problem and use search-based methods to find the optimal solution in the morphology space. However, they ignore the implicit knowledge of task-to-morphology mapping which can directly inspire robot design. For example, flipping heavier boxes tends to require more muscular robot arms. This paper proposes a novel and general differentiable task-inspired framework for contact-aware robot design called Task2Morph. We abstract task features highly related to task performance and use them to build a task-to-morphology mapping. Further, we embed the mapping into a differentiable robot design process, where the gradient information is leveraged for both the mapping learning and the whole optimization. The experiments are conducted on t
    
[^52]: 使用贝叶斯网络和深度学习改进癌症成像诊断：一种贝叶斯深度学习方法

    Improving Cancer Imaging Diagnosis with Bayesian Networks and Deep Learning: A Bayesian Deep Learning Approach

    [https://arxiv.org/abs/2403.19083](https://arxiv.org/abs/2403.19083)

    本文研究了贝叶斯深度学习模型，结合深度学习和贝叶斯网络的优势，最小化各自的劣势，并分析了其在健康产业中图像分类方面的应用。

    

    随着人工智能应用的最新进展，利用机器学习中的理论和算法可以创建许多精确的模型来训练和预测给定的数据集。本文旨在研究深度学习和贝叶斯网络预测模型背后的理论，根据每个模型的优势和劣势，采用不同的方法构建贝叶斯深度学习模型，结合优势同时最小化劣势。最终，将分析结果贝叶斯深度学习方法在健康产业中分类图像的应用和准确性。

    arXiv:2403.19083v1 Announce Type: cross  Abstract: With recent advancements in the development of artificial intelligence applications using theories and algorithms in machine learning, many accurate models can be created to train and predict on given datasets. With the realization of the importance of imaging interpretation in cancer diagnosis, this article aims to investigate the theory behind Deep Learning and Bayesian Network prediction models. Based on the advantages and drawbacks of each model, different approaches will be used to construct a Bayesian Deep Learning Model, combining the strengths while minimizing the weaknesses. Finally, the applications and accuracy of the resulting Bayesian Deep Learning approach in the health industry in classifying images will be analyzed.
    
[^53]: 利用E-检验统计增强符合性预测

    Enhancing Conformal Prediction Using E-Test Statistics

    [https://arxiv.org/abs/2403.19082](https://arxiv.org/abs/2403.19082)

    该论文利用E-检验统计引入BB-predictor，增强符合性预测效果。

    

    符合性预测（CP）作为一种稳健的框架，能够量化机器学习（ML）模型所做预测的不确定性。与传统的点预测器不同，CP基于数据可交换性的假设生成统计上有效的预测区域，也称为预测区间。通常，构建符合性预测依赖于p值。然而，本文走上了另一条路径，利用E-检验统计的力量通过引入一个下界预测器（BB-predictor）来增强符合性预测的效力。

    arXiv:2403.19082v1 Announce Type: cross  Abstract: Conformal Prediction (CP) serves as a robust framework that quantifies uncertainty in predictions made by Machine Learning (ML) models. Unlike traditional point predictors, CP generates statistically valid prediction regions, also known as prediction intervals, based on the assumption of data exchangeability. Typically, the construction of conformal predictions hinges on p-values. This paper, however, ventures down an alternative path, harnessing the power of e-test statistics to augment the efficacy of conformal predictions by introducing a BB-predictor (bounded from the below predictor).
    
[^54]: MVEB：具有多视图熵瓶颈的自监督学习

    MVEB: Self-Supervised Learning with Multi-View Entropy Bottleneck

    [https://arxiv.org/abs/2403.19078](https://arxiv.org/abs/2403.19078)

    该工作提出了一种名为MVEB的方法，通过消除图像视图之间不共享的多余信息，实现了最小足够表示的学习，并解决了互信息计算困难的问题。

    

    自监督学习旨在学习能够有效推广到下游任务的表示。许多自监督方法将图像的两个视图视为输入和自监督信号，假定任一视图都包含相同的与任务相关信息，并且共享信息（大致）足以预测下游任务。最近的研究表明，舍弃视图之间不共享的多余信息可以改善泛化能力。因此，理想的表示对下游任务是足够的，并且包含最少的多余信息，称为最小足够表示。一个可以通过最大化表示和监督视图之间的互信息并消除多余信息来学习这种表示。然而，互信息的计算因为困难而臭名昭着。在本工作中，我们提出一种称为多视图熵瓶颈的目标。

    arXiv:2403.19078v1 Announce Type: cross  Abstract: Self-supervised learning aims to learn representation that can be effectively generalized to downstream tasks. Many self-supervised approaches regard two views of an image as both the input and the self-supervised signals, assuming that either view contains the same task-relevant information and the shared information is (approximately) sufficient for predicting downstream tasks. Recent studies show that discarding superfluous information not shared between the views can improve generalization. Hence, the ideal representation is sufficient for downstream tasks and contains minimal superfluous information, termed minimal sufficient representation. One can learn this representation by maximizing the mutual information between the representation and the supervised view while eliminating superfluous information. Nevertheless, the computation of mutual information is notoriously intractable. In this work, we propose an objective termed mult
    
[^55]: 小型机器学习：进展与未来展望

    Tiny Machine Learning: Progress and Futures

    [https://arxiv.org/abs/2403.19076](https://arxiv.org/abs/2403.19076)

    TinyML是一种将深度学习模型压缩到物联网设备和微控制器中实现无处不在智能的新方法，需要共同设计算法和系统堆栈以克服硬件限制。

    

    Tiny Machine Learning（TinyML）是机器学习的一个新领域。通过将深度学习模型压缩到数十亿个物联网设备和微控制器（MCUs）中，我们扩展了人工智能应用的范围，实现了无处不在的智能。然而，由于硬件限制，TinyML具有挑战性：有限的内存资源使得难以容纳为云和移动平台设计的深度学习模型。对于裸机设备，编译器和推断引擎支持也有限。因此，我们需要共同设计算法和系统堆栈以实现TinyML。

    arXiv:2403.19076v1 Announce Type: cross  Abstract: Tiny Machine Learning (TinyML) is a new frontier of machine learning. By squeezing deep learning models into billions of IoT devices and microcontrollers (MCUs), we expand the scope of AI applications and enable ubiquitous intelligence. However, TinyML is challenging due to hardware constraints: the tiny memory resource makes it difficult to hold deep learning models designed for cloud and mobile platforms. There is also limited compiler and inference engine support for bare-metal devices. Therefore, we need to co-design the algorithm and system stack to enable TinyML. In this review, we will first discuss the definition, challenges, and applications of TinyML. We then survey the recent progress in TinyML and deep learning on MCUs. Next, we will introduce MCUNet, showing how we can achieve ImageNet-scale AI applications on IoT devices with system-algorithm co-design. We will further extend the solution from inference to training and in
    
[^56]: 面向数据流的用于深度学习工作负载的PIM启用的多核体系结构

    Dataflow-Aware PIM-Enabled Manycore Architecture for Deep Learning Workloads

    [https://arxiv.org/abs/2403.19073](https://arxiv.org/abs/2403.19073)

    设计了一种面向数据流的PIM启用的多核体系结构以加速深度学习工作负载

    

    Processing-in-memory (PIM)已经成为深度学习(DL)工作负载的能效高性能加速的推动因素。阻变随机存取存储器(ReRAM)是实现PIM的最有前途的技术之一。然而，随着深度卷积神经网络(DNNs)的复杂度增加，我们需要设计一个多核体系结构，在单片上有多个基于ReRAM的处理元素(PEs)。现有的基于PIM的体系结构主要关注计算，而忽视通信的作用。ReRAM为基础的切片式多核体系结构通常涉及许多处理元素(PEs)，这些元素需要通过高效的片上通信基础设施相互连接。如果通信基础设施无法跟得上，简单地分配更多资源(ReRAMs)来加速计算是无效的。

    arXiv:2403.19073v1 Announce Type: cross  Abstract: Processing-in-memory (PIM) has emerged as an enabler for the energy-efficient and high-performance acceleration of deep learning (DL) workloads. Resistive random-access memory (ReRAM) is one of the most promising technologies to implement PIM. However, as the complexity of Deep convolutional neural networks (DNNs) grows, we need to design a manycore architecture with multiple ReRAM-based processing elements (PEs) on a single chip. Existing PIM-based architectures mostly focus on computation while ignoring the role of communication. ReRAM-based tiled manycore architectures often involve many Processing Elements (PEs), which need to be interconnected via an efficient on-chip communication infrastructure. Simply allocating more resources (ReRAMs) to speed up only computation is ineffective if the communication infrastructure cannot keep up with it. In this paper, we highlight the design principles of a dataflow-aware PIM-enabled manycore 
    
[^57]: 生成量子彩色成像

    Generative Quanta Color Imaging

    [https://arxiv.org/abs/2403.19066](https://arxiv.org/abs/2403.19066)

    论文核心创新是使用神经常微分方程框架下的曝光合成模型，允许从单个观测中生成一系列曝光，以确保一致的曝光在二进制图像中进行着色，从而显著增强了着色效果。

    

    arXiv:2403.19066v1 公告类型：交叉 摘要：单光子相机的惊人发展为科学和工业成像创造了前所未有的机会。然而，这些1位传感器产生的高数据吞吐量对低功耗应用来说构成了重大瓶颈。在本文中，我们探讨了从单光子相机的单个二进制帧生成彩色图像的可能性。我们明显发现，由于曝光变化的显着程度，这个问题对标准着色方法特别困难。我们论文的核心创新是一个在神经常微分方程（神经ODE）下定义的曝光合成模型，它允许我们从单个观测中生成一系列曝光。这一创新确保了在二进制图像中颜色化器采用的一致曝光，导致显著增强的着色。我们展示了该方法在单图像和突发着色中的应用。

    arXiv:2403.19066v1 Announce Type: cross  Abstract: The astonishing development of single-photon cameras has created an unprecedented opportunity for scientific and industrial imaging. However, the high data throughput generated by these 1-bit sensors creates a significant bottleneck for low-power applications. In this paper, we explore the possibility of generating a color image from a single binary frame of a single-photon camera. We evidently find this problem being particularly difficult to standard colorization approaches due to the substantial degree of exposure variation. The core innovation of our paper is an exposure synthesis model framed under a neural ordinary differential equation (Neural ODE) that allows us to generate a continuum of exposures from a single observation. This innovation ensures consistent exposure in binary images that colorizers take on, resulting in notably enhanced colorization. We demonstrate applications of the method in single-image and burst coloriza
    
[^58]: 人类中心施工机器人：基于强化学习的助手机器人为木工劳动者提供环境上下文协助

    Towards Human-Centered Construction Robotics: An RL-Driven Companion Robot For Contextually Assisting Carpentry Workers

    [https://arxiv.org/abs/2403.19060](https://arxiv.org/abs/2403.19060)

    本文提出了一种人类中心的建筑机器人方法，通过强化学习驱动的助手机器人为木工劳动者提供环境上下文协助，推进了机器人在建筑中的应用。

    

    在这个充满活力的建筑行业中，传统的机器人集成主要集中在自动化特定任务，通常忽略了建筑工作流程中人类因素的复杂性和变化性。本文提出了一种以人为本的方法，设计了一个“工作伴侣漫游器”，旨在协助建筑工人完成其现有实践，旨在增强安全性和工作流程的流畅性，同时尊重建筑劳动的技术性质。我们对在木工模板工程中部署机器人系统进行了深入研究，展示了一个原型，通过环境相关的强化学习（RL）驱动模块化框架，重点强调了在动态环境中的机动性、安全性和舒适的工人-机器人协作。我们的研究推进了机器人在建筑中的应用，倡导协作模型，其中自适应机器人支持而不是取代人类，强调了交互式的潜力。

    arXiv:2403.19060v1 Announce Type: cross  Abstract: In the dynamic construction industry, traditional robotic integration has primarily focused on automating specific tasks, often overlooking the complexity and variability of human aspects in construction workflows. This paper introduces a human-centered approach with a ``work companion rover" designed to assist construction workers within their existing practices, aiming to enhance safety and workflow fluency while respecting construction labor's skilled nature. We conduct an in-depth study on deploying a robotic system in carpentry formwork, showcasing a prototype that emphasizes mobility, safety, and comfortable worker-robot collaboration in dynamic environments through a contextual Reinforcement Learning (RL)-driven modular framework. Our research advances robotic applications in construction, advocating for collaborative models where adaptive robots support rather than replace humans, underscoring the potential for an interactive a
    
[^59]: 通过过拟合的遮蔽自编码器检测生成性模仿

    Detecting Generative Parroting through Overfitting Masked Autoencoders

    [https://arxiv.org/abs/2403.19050](https://arxiv.org/abs/2403.19050)

    本研究提出利用过拟合的遮蔽自编码器(MAE)来检测生成模型中的生成性模仿，建立了基于训练数据集损失的检测阈值，为了确保生成模型的合法使用和提升其法律合规性提供了一种新方法。

    

    生成式人工智能模型的出现彻底改变了数字内容创建的方式，然而由于生成性模仿问题，模型过于模仿其训练数据而给版权完整性带来挑战。本研究提出了一种新方法来解决这个问题，即利用一个过拟合的遮蔽自编码器(MAE)来有效地检测这种模仿样本。我们基于训练数据集上的平均损失建立一个检测阈值，从而精确定位修改后数据集中的模仿内容。初步评估表明了有希望的结果，显示了我们方法确保生成模型的合法使用并加强法律合规性方面的潜力。

    arXiv:2403.19050v1 Announce Type: cross  Abstract: The advent of generative AI models has revolutionized digital content creation, yet it introduces challenges in maintaining copyright integrity due to generative parroting, where models mimic their training data too closely. Our research presents a novel approach to tackle this issue by employing an overfitted Masked Autoencoder (MAE) to detect such parroted samples effectively. We establish a detection threshold based on the mean loss across the training dataset, allowing for the precise identification of parroted content in modified datasets. Preliminary evaluations demonstrate promising results, suggesting our method's potential to ensure ethical use and enhance the legal compliance of generative models.
    
[^60]: LITA: 语言指导的时间定位助手

    LITA: Language Instructed Temporal-Localization Assistant

    [https://arxiv.org/abs/2403.19046](https://arxiv.org/abs/2403.19046)

    提出了一种名为LITA的语言指导的时间定位助手，通过引入时间令牌、SlowFast令牌和强调时间定位数据来改善视频中的时间定位能力

    

    多模态大语言模型（LLMs）取得了巨大进展。最近的研究将这些模型扩展到视频输入，并具有有前途的指令跟随能力。然而，一项重要缺失的部分是时间定位。这些模型无法准确回答“什么时候？”的问题。我们确定了三个限制它们时间定位能力的关键方面：（i）时间表示，（ii）架构和（iii）数据。我们通过提出具有以下功能的语言指导的时间定位助手（LITA）来解决这些缺点: (1) 我们引入了时间令牌，用于编码相对于视频长度的时间戳，以更好地表示视频中的时间。(2) 我们在架构中引入了SlowFast令牌，以捕获细粒度的时间信息。(3) 我们强调LITA的时间定位数据。除了利用具有时间戳的现有视频数据集外，我们还提出一个新的

    arXiv:2403.19046v1 Announce Type: cross  Abstract: There has been tremendous progress in multimodal Large Language Models (LLMs). Recent works have extended these models to video input with promising instruction following capabilities. However, an important missing piece is temporal localization. These models cannot accurately answer the "When?" questions. We identify three key aspects that limit their temporal localization capabilities: (i) time representation, (ii) architecture, and (iii) data. We address these shortcomings by proposing Language Instructed Temporal-Localization Assistant (LITA) with the following features: (1) We introduce time tokens that encode timestamps relative to the video length to better represent time in videos. (2) We introduce SlowFast tokens in the architecture to capture temporal information at fine temporal resolution. (3) We emphasize temporal localization data for LITA. In addition to leveraging existing video datasets with timestamps, we propose a ne
    
[^61]: 使用公共社交媒体数据评估大型语言模型在健康相关文本分类任务中的表现

    Evaluating Large Language Models for Health-Related Text Classification Tasks with Public Social Media Data

    [https://arxiv.org/abs/2403.19031](https://arxiv.org/abs/2403.19031)

    综合实验表明，利用LLMs进行数据增强可以...

    

    大型语言模型（LLMs）在NLP任务中展现出卓越的成功。然而，几乎没有研究试图评估它们在基于社交媒体的健康相关自然语言处理任务中的表现，这些任务传统上很难获得高分。我们在6个文本分类任务上对一个基于支持向量机（SVMs）的监督经典机器学习模型，三个基于RoBERTa、BERTweet和SocBERT的监督预训练语言模型（PLMs），以及两个基于GPT3.5和GPT4的LLM分类器进行了基准测试。我们开发了三种利用LLMs进行文本分类的方法：将LLMs用作零次分类器，将LLMs用作注释器为监督分类器注释训练数据，以及利用LLMs进行少量示例来增加手动注释数据。我们全面的实验表明，利用LLMs进行数据增强可以...

    arXiv:2403.19031v1 Announce Type: cross  Abstract: Large language models (LLMs) have demonstrated remarkable success in NLP tasks. However, there is a paucity of studies that attempt to evaluate their performances on social media-based health-related natural language processing tasks, which have traditionally been difficult to achieve high scores in. We benchmarked one supervised classic machine learning model based on Support Vector Machines (SVMs), three supervised pretrained language models (PLMs) based on RoBERTa, BERTweet, and SocBERT, and two LLM based classifiers (GPT3.5 and GPT4), across 6 text classification tasks. We developed three approaches for leveraging LLMs for text classification: employing LLMs as zero-shot classifiers, us-ing LLMs as annotators to annotate training data for supervised classifiers, and utilizing LLMs with few-shot examples for augmentation of manually annotated data. Our comprehensive experiments demonstrate that employ-ing data augmentation using LLM
    
[^62]: 利用动态对称性进行基于模型的非对称奖励强化学习

    Exploiting Symmetry in Dynamics for Model-Based Reinforcement Learning with Asymmetric Rewards

    [https://arxiv.org/abs/2403.19024](https://arxiv.org/abs/2403.19024)

    本文扩展了强化学习和控制理论中对称技术的应用范围，通过利用动态对称性学习动力学模型，而不要求奖励具有相同的对称性。

    

    强化学习中最近的工作利用模型中的对称性来提高策略训练的采样效率。一个常用的简化假设是动力学和奖励都表现出相同的对称性。然而，在许多真实环境中，动力学模型表现出与奖励模型独立的对称性：奖励可能不满足与动力学相同的对称性。本文探讨了只假定动力学表现出对称性的情况，扩展了强化学习和控制理论学习中可应用对称技术的问题范围。我们利用卡塔恩移动框架方法引入一种学习动力学的技术，通过构造，这种动力学表现出指定的对称性。我们通过数值实验展示了所提出的方法学到了更准确的动态模型。

    arXiv:2403.19024v1 Announce Type: cross  Abstract: Recent work in reinforcement learning has leveraged symmetries in the model to improve sample efficiency in training a policy. A commonly used simplifying assumption is that the dynamics and reward both exhibit the same symmetry. However, in many real-world environments, the dynamical model exhibits symmetry independent of the reward model: the reward may not satisfy the same symmetries as the dynamics. In this paper, we investigate scenarios where only the dynamics are assumed to exhibit symmetry, extending the scope of problems in reinforcement learning and learning in control theory where symmetry techniques can be applied. We use Cartan's moving frame method to introduce a technique for learning dynamics which, by construction, exhibit specified symmetries. We demonstrate through numerical experiments that the proposed method learns a more accurate dynamical model.
    
[^63]: 朝向LLM-RecSys对齐与文本ID学习的方向

    Towards LLM-RecSys Alignment with Textual ID Learning

    [https://arxiv.org/abs/2403.19021](https://arxiv.org/abs/2403.19021)

    通过提出IDGen，将每个推荐项目表示为独特、简洁、语义丰富的文本ID，从而使得基于大型语言模型的推荐更好地与自然语言生成对齐。

    

    基于大型语言模型(LLMs)的生成式推荐已经将传统的基于排名的推荐方式转变为文本生成范例。然而，与固有操作人类词汇的标准NLP任务相反，目前生成式推荐领域的研究在如何在文本生成范式中以简洁而有意义的ID表示有效编码推荐项目方面存在困难。为了更好地对齐LLMs与推荐需求，我们提出了IDGen，使用人类语言标记将每个项目表示为独特、简洁、语义丰富、与平台无关的文本ID。这通过在基于LLM的推荐系统旁训练文本ID生成器来实现，使个性化推荐能够无缝集成到自然语言生成中。值得注意的是，由于用户历史记录以自然语言表达并与原始数据集解耦，我们的方法提出了潜在的

    arXiv:2403.19021v1 Announce Type: cross  Abstract: Generative recommendation based on Large Language Models (LLMs) have transformed the traditional ranking-based recommendation style into a text-to-text generation paradigm. However, in contrast to standard NLP tasks that inherently operate on human vocabulary, current research in generative recommendations struggles to effectively encode recommendation items within the text-to-text framework using concise yet meaningful ID representations. To better align LLMs with recommendation needs, we propose IDGen, representing each item as a unique, concise, semantically rich, platform-agnostic textual ID using human language tokens. This is achieved by training a textual ID generator alongside the LLM-based recommender, enabling seamless integration of personalized recommendations into natural language generation. Notably, as user history is expressed in natural language and decoupled from the original dataset, our approach suggests the potenti
    
[^64]: ReflectSumm: 一个用于课程反思摘要的基准数据集

    ReflectSumm: A Benchmark for Course Reflection Summarization

    [https://arxiv.org/abs/2403.19012](https://arxiv.org/abs/2403.19012)

    ReflectSumm是一个旨在总结学生反思性写作的数据集，可以帮助开发和评估针对现实场景的新型摘要技术，为进一步研究提供了基准。

    

    这篇论文介绍了ReflectSumm，一个专门设计用于总结学生反思性写作的新型摘要数据集。ReflectSumm的目标是促进开发和评估针对现实场景的新型摘要技术，这些场景具有少量训练数据，%具有潜在在意见总结领域和特别是教育领域中的影响。该数据集涵盖了各种摘要任务，并包括全面的元数据，可以探索各种研究问题并支持不同的应用。为展示其效用，我们使用多个最先进的基准进行了广泛评估。结果为促进这一领域的进一步研究提供了基准。

    arXiv:2403.19012v1 Announce Type: cross  Abstract: This paper introduces ReflectSumm, a novel summarization dataset specifically designed for summarizing students' reflective writing. The goal of ReflectSumm is to facilitate developing and evaluating novel summarization techniques tailored to real-world scenarios with little training data, %practical tasks with potential implications in the opinion summarization domain in general and the educational domain in particular. The dataset encompasses a diverse range of summarization tasks and includes comprehensive metadata, enabling the exploration of various research questions and supporting different applications. To showcase its utility, we conducted extensive evaluations using multiple state-of-the-art baselines. The results provide benchmarks for facilitating further research in this area.
    
[^65]: 跨领域的纤维簇形状分析用于语言表现认知分数预测

    Cross--domain Fiber Cluster Shape Analysis for Language Performance Cognitive Score Prediction

    [https://arxiv.org/abs/2403.19001](https://arxiv.org/abs/2403.19001)

    本研究通过新颖的框架SFFormer，结合了多头交叉注意力特征融合模块，基于dMRI纤维束追踪，预测了主观语言表现，拓展了脑结构与人类认知功能的关联研究。

    

    形状在计算机图形学中扮演重要角色，提供了有关对象形态和功能的信息特征。脑成像中的形状分析可帮助解释人脑结构和功能的相关性。本研究调查了大脑的3D白质连接的形状及其与人类认知功能的潜在预测关系。我们使用扩散磁共振成像（dMRI）纤维束追踪将大脑连接重建为3D点序列。为了描述每个连接，我们提取了12个形状描述符以及传统的dMRI连接和组织微结构特征。我们引入了一种新颖的框架，形状融合纤维簇变换器（SFFormer），利用多头交叉注意力特征融合模块基于dMRI纤维束追踪来预测特定个体的语言表现。我们在一个大型数据集上评估了该方法的性能。

    arXiv:2403.19001v1 Announce Type: cross  Abstract: Shape plays an important role in computer graphics, offering informative features to convey an object's morphology and functionality. Shape analysis in brain imaging can help interpret structural and functionality correlations of the human brain. In this work, we investigate the shape of the brain's 3D white matter connections and its potential predictive relationship to human cognitive function. We reconstruct brain connections as sequences of 3D points using diffusion magnetic resonance imaging (dMRI) tractography. To describe each connection, we extract 12 shape descriptors in addition to traditional dMRI connectivity and tissue microstructure features. We introduce a novel framework, Shape--fused Fiber Cluster Transformer (SFFormer), that leverages a multi-head cross-attention feature fusion module to predict subject-specific language performance based on dMRI tractography. We assess the performance of the method on a large dataset
    
[^66]: 微服务系统的少样本跨系统异常跟踪分类

    Few-Shot Cross-System Anomaly Trace Classification for Microservice-based systems

    [https://arxiv.org/abs/2403.18998](https://arxiv.org/abs/2403.18998)

    提出了针对微服务系统的少样本异常跟踪分类的新框架，利用多头注意力自编码器构建系统特定的跟踪表示，并应用基于Transformer编码器的模型无关元学习进行高效分类。

    

    微服务系统（MSS）由于其复杂和动态的特性可能在各种故障类别中出现故障。为了有效处理故障，AIOps工具利用基于跟踪的异常检测和根本原因分析。本文提出了一个新颖的框架，用于微服务系统的少样本异常跟踪分类。我们的框架包括两个主要组成部分：（1）多头注意力自编码器用于构建系统特定的跟踪表示，从而实现（2）基于Transformer编码器的模型无关元学习，以进行有效和高效的少样本异常跟踪分类。该框架在两个代表性的MSS，Trainticket和OnlineBoutique上进行了评估，使用开放数据集。结果表明，我们的框架能够调整学到的知识，以对新的、未见的新颖故障类别的异常跟踪进行分类，无论是在最初训练的同一系统内，还是在其他系统中。

    arXiv:2403.18998v1 Announce Type: cross  Abstract: Microservice-based systems (MSS) may experience failures in various fault categories due to their complex and dynamic nature. To effectively handle failures, AIOps tools utilize trace-based anomaly detection and root cause analysis. In this paper, we propose a novel framework for few-shot abnormal trace classification for MSS. Our framework comprises two main components: (1) Multi-Head Attention Autoencoder for constructing system-specific trace representations, which enables (2) Transformer Encoder-based Model-Agnostic Meta-Learning to perform effective and efficient few-shot learning for abnormal trace classification. The proposed framework is evaluated on two representative MSS, Trainticket and OnlineBoutique, with open datasets. The results show that our framework can adapt the learned knowledge to classify new, unseen abnormal traces of novel fault categories both within the same system it was initially trained on and even in the 
    
[^67]: 处理Bot-IoT数据集中的不平衡类问题

    Dealing with Imbalanced Classes in Bot-IoT Dataset

    [https://arxiv.org/abs/2403.18989](https://arxiv.org/abs/2403.18989)

    提出了一种利用合成少数类过抽样技术(SMOTE)的二元分类方法，以解决Bot-IoT数据集中的类别不平衡问题。

    

    随着物联网(IoT)设备的广泛使用，网络入侵检测系统(NIDS)在检测和保护物联网网络中各种类型的攻击中发挥着重要作用。为了评估NIDS在物联网网络中的鲁棒性，现有工作提出了一个现实的物联网网络中的僵尸网络数据集(Bot-IoT数据集)，并将其应用于基于机器学习的异常检测。该数据集包含不平衡的正常数据包和攻击数据包，因为正常数据包的数量远小于攻击数据包的数量。不平衡数据的性质可能会使辨识少数类别变得困难。在本论文中，为了解决Bot-IoT数据集中的类别不平衡问题，我们提出了一种利用合成少数类过抽样技术(SMOTE)的二元分类方法。所提出的分类器旨在检测攻击数据包并使用SMOTE算法克服类别不平衡问题。

    arXiv:2403.18989v1 Announce Type: cross  Abstract: With the rapidly spreading usage of Internet of Things (IoT) devices, a network intrusion detection system (NIDS) plays an important role in detecting and protecting various types of attacks in the IoT network. To evaluate the robustness of the NIDS in the IoT network, the existing work proposed a realistic botnet dataset in the IoT network (Bot-IoT dataset) and applied it to machine learning-based anomaly detection. This dataset contains imbalanced normal and attack packets because the number of normal packets is much smaller than that of attack ones. The nature of imbalanced data may make it difficult to identify the minority class correctly. In this thesis, to address the class imbalance problem in the Bot-IoT dataset, we propose a binary classification method with synthetic minority over-sampling techniques (SMOTE). The proposed classifier aims to detect attack packets and overcome the class imbalance problem using the SMOTE algori
    
[^68]: 强化学习用于黑盒图像、视频和心电图信号分类的鲁棒性和视觉解释

    Robustness and Visual Explanation for Black Box Image, Video, and ECG Signal Classification with Reinforcement Learning

    [https://arxiv.org/abs/2403.18985](https://arxiv.org/abs/2403.18985)

    提出了一个通用的强化学习框架，用于从心电图信号分析到图像和视频分类的不同模型类型的对抗攻击，通过识别敏感区域并在最小程度扭曲下诱导错误分类，生成优越的定位掩模，并在鲁棒性和透明度方面取得了显著进展。

    

    我们提出了一个通用的强化学习（RL）框架，针对从心电图信号分析（1D）、图像分类（2D）到视频分类（3D）等不同模型类型进行对抗攻击的优化。该框架专注于识别敏感区域并在最小程度扭曲和各种扭曲类型下诱导错误分类。新颖的RL方法在所有三个应用中优于最先进的方法，证明了其效率。我们的RL方法生成了优越的定位掩模，增强了图像分类和心电图分析模型的可解释性。对于心电图分析等应用，我们的平台突出了临床医生关注的关键心电图片段，同时确保对流行扭曲的韧性。这一全面的工具旨在通过对抗性训练和透明度提高各种应用和数据类型的韧性。

    arXiv:2403.18985v1 Announce Type: cross  Abstract: We present a generic Reinforcement Learning (RL) framework optimized for crafting adversarial attacks on different model types spanning from ECG signal analysis (1D), image classification (2D), and video classification (3D). The framework focuses on identifying sensitive regions and inducing misclassifications with minimal distortions and various distortion types. The novel RL method outperforms state-of-the-art methods for all three applications, proving its efficiency. Our RL approach produces superior localization masks, enhancing interpretability for image classification and ECG analysis models. For applications such as ECG analysis, our platform highlights critical ECG segments for clinicians while ensuring resilience against prevalent distortions. This comprehensive tool aims to bolster both resilience with adversarial training and transparency across varied applications and data types.
    
[^69]: TextCraftor：您的文本编码器可以成为图像质量控制器

    TextCraftor: Your Text Encoder Can be Image Quality Controller

    [https://arxiv.org/abs/2403.18978](https://arxiv.org/abs/2403.18978)

    通过微调文本编码器来改进文本到图像扩散模型的性能。

    

    基于扩散的文本到图像生成模型，如稳定扩散，已经彻底改变了内容生成领域，使得在诸如图像编辑和视频合成等领域取得了重大进展。尽管这些模型具有强大的功能，但它们并非没有局限性。合成与输入文本相契合的图像仍然具有挑战性，并且需要多次运行以精心设计的提示才能实现令人满意的结果。为了减轻这些局限性，许多研究努力对预训练的扩散模型，即UNet，进行微调，利用各种技术。然而，在这些努力中，一个关键问题，即对文本到图像扩散模型训练进行微调以改善文本到图像扩散模型性能是否可能和可行，仍然大多未被探讨。我们的研究结果显示，与其替换CLIP文本编码器，更好的方法是微调文本编码器以提升文本到图像扩散模型的性能。

    arXiv:2403.18978v1 Announce Type: cross  Abstract: Diffusion-based text-to-image generative models, e.g., Stable Diffusion, have revolutionized the field of content generation, enabling significant advancements in areas like image editing and video synthesis. Despite their formidable capabilities, these models are not without their limitations. It is still challenging to synthesize an image that aligns well with the input text, and multiple runs with carefully crafted prompts are required to achieve satisfactory results. To mitigate these limitations, numerous studies have endeavored to fine-tune the pre-trained diffusion models, i.e., UNet, utilizing various technologies. Yet, amidst these efforts, a pivotal question of text-to-image diffusion model training has remained largely unexplored: Is it possible and feasible to fine-tune the text encoder to improve the performance of text-to-image diffusion models? Our findings reveal that, instead of replacing the CLIP text encoder used in 
    
[^70]: "对不起，再次来吗？提示——通过注入[PAUSE]优化改写来增强理解力和减少幻觉"

    "Sorry, Come Again?" Prompting -- Enhancing Comprehension and Diminishing Hallucination with [PAUSE]-injected Optimal Paraphrasing

    [https://arxiv.org/abs/2403.18976](https://arxiv.org/abs/2403.18976)

    介绍了一种新的提示策略“Sorry, Come Again (SCA)”来避免大规模语言模型（LLMs）产生幻觉，通过进行最佳的改写和注入[PAUSE]标记来增强理解力。

    

    Hallucination已经成为当代大规模语言模型（LLMs）中最脆弱的方面。本文介绍了Sorry, Come Again (SCA)提示，旨在通过：(i) 最佳的改写和(ii) 注入[PAUSE]标记来延迟LLMs的生成，以避免LLM产生幻觉。首先，我们对21个LLMs的提示的语言细微差别进行了深入分析：正式性、可读性和具体性，并阐明了这些差别是如何导致产生幻觉的。提示的可读性、正式性或具体性较低会给LLMs带来理解挑战，类似于人类所面临的挑战。在这种情况下，LLM倾向于根据其想象力（联想记忆）推测和生成内容来填补这些信息缺失。尽管这些猜测偶尔可能与事实信息一致，但其准确性并不保证，经常导致幻觉。

    arXiv:2403.18976v1 Announce Type: cross  Abstract: Hallucination has emerged as the most vulnerable aspect of contemporary Large Language Models (LLMs). In this paper, we introduce the Sorry, Come Again (SCA) prompting, aimed to avoid LLM hallucinations by enhancing comprehension through: (i) optimal paraphrasing and (ii) injecting [PAUSE] tokens to delay LLM generation. First, we provide an in-depth analysis of linguistic nuances: formality, readability, and concreteness of prompts for 21 LLMs, and elucidate how these nuances contribute to hallucinated generation. Prompts with lower readability, formality, or concreteness pose comprehension challenges for LLMs, similar to those faced by humans. In such scenarios, an LLM tends to speculate and generate content based on its imagination (associative memory) to fill these information gaps. Although these speculations may occasionally align with factual information, their accuracy is not assured, often resulting in hallucination. Recent st
    
[^71]: 从概念到实现的大型语言模型综述

    A Survey on Large Language Models from Concept to Implementation

    [https://arxiv.org/abs/2403.18969](https://arxiv.org/abs/2403.18969)

    Transformer模型在改革传统任务和推进跨行业研究和开发中产生革命性影响。

    

    最近基于Transformer架构构建的大型语言模型(LLMs)的发展极大拓宽了自然语言处理(NLP)应用的范围，超越了最初在聊天机器人技术中的应用。本文研究了这些模型的多方面应用，着重介绍了GPT系列。这项探索聚焦于人工智能(AI)驱动工具在改革传统编码和问题解决等任务上的革命性影响，同时在跨越不同行业的研究和开发中开辟新路径。从代码解释和图像描述到促进交互式系统的搭建和推进计算领域，Transformer模型体现了深度学习、数据分析和神经网络设计的协同作用。本综述深入探讨了Transformer模型的最新研究，突出了

    arXiv:2403.18969v1 Announce Type: cross  Abstract: Recent advancements in Large Language Models (LLMs), particularly those built on Transformer architectures, have significantly broadened the scope of natural language processing (NLP) applications, transcending their initial use in chatbot technology. This paper investigates the multifaceted applications of these models, with an emphasis on the GPT series. This exploration focuses on the transformative impact of artificial intelligence (AI) driven tools in revolutionizing traditional tasks like coding and problem-solving, while also paving new paths in research and development across diverse industries. From code interpretation and image captioning to facilitating the construction of interactive systems and advancing computational domains, Transformer models exemplify a synergy of deep learning, data analysis, and neural network design. This survey provides an in-depth look at the latest research in Transformer models, highlighting the
    
[^72]: LORD：基于大模型的相反奖励设计用于自动驾驶

    LORD: Large Models based Opposite Reward Design for Autonomous Driving

    [https://arxiv.org/abs/2403.18965](https://arxiv.org/abs/2403.18965)

    LORD通过不期望的语言目标，提出了一种基于大模型的相反奖励设计，以便有效利用大型预训练模型作为零-shot奖励模型。

    

    强化学习（RL）驱动的自动驾驶已经成为一种有希望的替代数据驱动模仿学习方法的选择。然而，为RL制定有效的奖励函数面临挑战，因为要在不同场景中定义和量化良好的驾驶行为的复杂性。最近，大型预训练模型作为零-shot奖励模型，为指定具有期望语言目标的任务引起了重要关注。然而，对于自动驾驶的期望语言目标，如“安全驾驶”，对于预训练模型来说是模糊且难以理解的。另一方面，不期望的语言目标，比如“碰撞”，更加具体且可跟踪。在这项工作中，我们引入了LORD，这是一种新颖的基于大模型的相反奖励设计，通过不期望的语言目标来实现对大型预训练模型的有效使用，作为零-shot奖励模型。通过大量实验，我们提出的框架显示

    arXiv:2403.18965v1 Announce Type: cross  Abstract: Reinforcement learning (RL) based autonomous driving has emerged as a promising alternative to data-driven imitation learning approaches. However, crafting effective reward functions for RL poses challenges due to the complexity of defining and quantifying good driving behaviors across diverse scenarios. Recently, large pretrained models have gained significant attention as zero-shot reward models for tasks specified with desired linguistic goals. However, the desired linguistic goals for autonomous driving such as "drive safely" are ambiguous and incomprehensible by pretrained models. On the other hand, undesired linguistic goals like "collision" are more concrete and tractable. In this work, we introduce LORD, a novel large models based opposite reward design through undesired linguistic goals to enable the efficient use of large pretrained models as zero-shot reward models. Through extensive experiments, our proposed framework shows
    
[^73]: 使用量子计算推断生物和人工神经网络的动态行为

    Using Quantum Computing to Infer Dynamic Behaviors of Biological and Artificial Neural Networks

    [https://arxiv.org/abs/2403.18963](https://arxiv.org/abs/2403.18963)

    本研究展示了如何利用Grover和Deutsch-Josza等基础量子算法，通过一组精心构建的条件，推断生物和人工神经网络在一段时间内是否具有继续维持动态活动的潜力。

    

    新问题类别的探索是量子计算研究的一个活跃领域。一个基本上完全未被探讨的主题是使用量子算法和计算来探索和询问神经网络的功能动态。这是将量子计算应用于生物和人工神经网络建模和仿真的尚未成熟的主题的一个组成部分。在本研究中，我们展示了如何通过精心构建的一组条件来使用两个基础量子算法，Grover和Deutsch-Josza，以使输出测量具有一种解释，保证我们能够推断一个简单的神经网络表示（适用于生物和人工网络）在一段时间后是否有可能继续维持动态活动。或者这些动态保证会停止，要么是通过'癫痫'动态，要么是静止状态。

    arXiv:2403.18963v1 Announce Type: cross  Abstract: The exploration of new problem classes for quantum computation is an active area of research. An essentially completely unexplored topic is the use of quantum algorithms and computing to explore and ask questions \textit{about} the functional dynamics of neural networks. This is a component of the still-nascent topic of applying quantum computing to the modeling and simulations of biological and artificial neural networks. In this work, we show how a carefully constructed set of conditions can use two foundational quantum algorithms, Grover and Deutsch-Josza, in such a way that the output measurements admit an interpretation that guarantees we can infer if a simple representation of a neural network (which applies to both biological and artificial networks) after some period of time has the potential to continue sustaining dynamic activity. Or whether the dynamics are guaranteed to stop either through 'epileptic' dynamics or quiescence
    
[^74]: 一份针对生成AI软件产品的最新发布就绪检查清单实践

    A State-of-the-practice Release-readiness Checklist for Generative AI-based Software Products

    [https://arxiv.org/abs/2403.18958](https://arxiv.org/abs/2403.18958)

    该研究提出了一份综合性检查清单，旨在指导从业者评估生成AI软件产品的关键发布就绪方面，以提高在真实环境中的可靠性和效果。

    

    本文调查了将大型语言模型(LLMs)集成到软件产品中的复杂性，重点关注确定其发布就绪性所遇到的挑战。我们对灰色文献的系统回顾确定了部署LLMs时遇到的常见挑战，从预训练和微调到用户体验等方面。该研究引入了一份全面的检查清单，旨在指导从业者评估关键的发布就绪方面，比如性能、监控和部署策略，旨在提高LLM应用在现实环境中的可靠性和效果。

    arXiv:2403.18958v1 Announce Type: cross  Abstract: This paper investigates the complexities of integrating Large Language Models (LLMs) into software products, with a focus on the challenges encountered for determining their readiness for release. Our systematic review of grey literature identifies common challenges in deploying LLMs, ranging from pre-training and fine-tuning to user experience considerations. The study introduces a comprehensive checklist designed to guide practitioners in evaluating key release readiness aspects such as performance, monitoring, and deployment strategies, aiming to enhance the reliability and effectiveness of LLM-based applications in real-world settings.
    
[^75]: 面向大规模网络的随机聚合波束成形用于空中联邦学习

    Random Aggregate Beamforming for Over-the-Air Federated Learning in Large-Scale Networks

    [https://arxiv.org/abs/2403.18946](https://arxiv.org/abs/2403.18946)

    本文提出了一种随机聚合波束成形的方案，通过随机抽样生成聚合器波束形成矢量，以解决大规模网络中的聚合误差最小化和设备选择最大化问题。

    

    目前，部署普遍人工智能（AI）应用于网络边缘的趋势日益明显。作为一种有望实现安全边缘智能的框架，联邦学习（FL）受到了广泛关注，空中计算（AirComp）已经被集成以进一步提高通信效率。本文考虑了联合设备选择和聚合波束成形设计，其目标是最小化聚合误差并最大化选定设备的数量。这导致了一个组合问题，在大规模网络中尤其难以解决。为了以一种经济有效的方式解决问题，我们提出了一种基于随机聚合波束成形的方案，该方案通过随机抽样生成聚合波束形成矢量，而非优化。该方案的实施不需要进行信道估计。

    arXiv:2403.18946v1 Announce Type: cross  Abstract: At present, there is a trend to deploy ubiquitous artificial intelligence (AI) applications at the edge of the network. As a promising framework that enables secure edge intelligence, federated learning (FL) has received widespread attention, and over-the-air computing (AirComp) has been integrated to further improve the communication efficiency. In this paper, we consider a joint device selection and aggregate beamforming design with the objectives of minimizing the aggregate error and maximizing the number of selected devices. This yields a combinatorial problem, which is difficult to solve especially in large-scale networks. To tackle the problems in a cost-effective manner, we propose a random aggregate beamforming-based scheme, which generates the aggregator beamforming vector via random sampling rather than optimization. The implementation of the proposed scheme does not require the channel estimation. We additionally use asympto
    
[^76]: 将自由文本放射学笔记转变为具有生成变换器的结构化报告

    Reshaping Free-Text Radiology Notes Into Structured Reports With Generative Transformers

    [https://arxiv.org/abs/2403.18938](https://arxiv.org/abs/2403.18938)

    提出了一个从自由文本放射学报告中提取信息的流程，利用自然语言处理（NLP）和基于Transformer的模型来处理自动的SR注册表填写。

    

    背景：放射学报告通常以自由文本格式编写，使临床信息难以提取和使用。 最近，各种医学学会推荐采用结构化报告（SR），由于其提供的优势（如标准化、完整性和信息检索），结构化报告（SR）的采用得到了推荐。 我们提出了一个从自由文本放射学报告中提取信息的流程，与一个国家介入和医学放射学会提出的参考SR注册表项目相匹配，重点放在对具有淋巴瘤的患者进行CT分期上。

    arXiv:2403.18938v1 Announce Type: cross  Abstract: BACKGROUND: Radiology reports are typically written in a free-text format, making clinical information difficult to extract and use. Recently the adoption of structured reporting (SR) has been recommended by various medical societies thanks to the advantages it offers, e.g. standardization, completeness and information retrieval. We propose a pipeline to extract information from free-text radiology reports, that fits with the items of the reference SR registry proposed by a national society of interventional and medical radiology, focusing on CT staging of patients with lymphoma. METHODS: Our work aims to leverage the potential of Natural Language Processing (NLP) and Transformer-based models to deal with automatic SR registry filling. With the availability of 174 radiology reports, we investigate a rule-free generative Question Answering approach based on a domain-specific version of T5 (IT5). Two strategies (batch-truncation and ex-p
    
[^77]: 在大型语言模型中测量政治偏见：言论内容和表达方式分析

    Measuring Political Bias in Large Language Models: What Is Said and How It Is Said

    [https://arxiv.org/abs/2403.18932](https://arxiv.org/abs/2403.18932)

    提出通过分析大型语言模型生成的政治议题内容和风格来测量其政治偏见，主张应该有由大型语言模型生成的政治偏见的细粒度和可解释性衡量。

    

    我们提出通过分析大型语言模型生成的政治议题内容和风格来测量其政治偏见。现有的基准和测量方法关注性别和种族偏见，但是大型语言模型中存在政治偏见，可能导致下游应用中的极化和其他危害。为了向用户提供透明度，我们主张应该有由大型语言模型生成的政治偏见的细粒度和可解释性测量。我们提出的测量方法既考虑了生殖权利和气候变化等不同政治议题的内容（生成物的实质），也考虑了这种偏见的风格（词汇的极性）。我们测量了十一个开源大型语言模型的政治偏见，并展示了我们提出的框架在扩展到其他主题时既易于扩展又具有可解释性。

    arXiv:2403.18932v1 Announce Type: cross  Abstract: We propose to measure political bias in LLMs by analyzing both the content and style of their generated content regarding political issues. Existing benchmarks and measures focus on gender and racial biases. However, political bias exists in LLMs and can lead to polarization and other harms in downstream applications. In order to provide transparency to users, we advocate that there should be fine-grained and explainable measures of political biases generated by LLMs. Our proposed measure looks at different political issues such as reproductive rights and climate change, at both the content (the substance of the generation) and the style (the lexical polarity) of such bias. We measured the political bias in eleven open-sourced LLMs and showed that our proposed framework is easily scalable to other topics and is explainable.
    
[^78]: 自然引导的认知进化用于预测北温带湖泊中的溶解氧浓度

    Nature-Guided Cognitive Evolution for Predicting Dissolved Oxygen Concentrations in North Temperate Lakes

    [https://arxiv.org/abs/2403.18923](https://arxiv.org/abs/2403.18923)

    提出了一种自然引导的认知进化策略，通过多层融合自适应学习和自然过程，有效预测北温带湖泊中的溶解氧浓度

    

    预测北温带湖泊中的溶解氧（DO）浓度需要对不同生态系统中的物候模式进行全面研究，这凸显了选择物候特征和特征交互的重要性。基于过程的模型受部分过程知识限制或特征表示过于简化，而机器学习模型在有效选择不同湖泊类型和任务的相关特征交互方面面临挑战，尤其是在DO数据收集不频繁的情况下。在本文中，我们提出了一种自然引导的认知进化（NGCE）策略，这代表了自适应学习与自然过程多层融合。具体来说，我们利用代谢过程为基础的模型生成模拟DO标签。利用这些模拟标签，我们实施了一个多种群认知进化搜索，模型反映自然有机体，适应性地

    arXiv:2403.18923v1 Announce Type: cross  Abstract: Predicting dissolved oxygen (DO) concentrations in north temperate lakes requires a comprehensive study of phenological patterns across various ecosystems, which highlights the significance of selecting phenological features and feature interactions. Process-based models are limited by partial process knowledge or oversimplified feature representations, while machine learning models face challenges in efficiently selecting relevant feature interactions for different lake types and tasks, especially under the infrequent nature of DO data collection. In this paper, we propose a Nature-Guided Cognitive Evolution (NGCE) strategy, which represents a multi-level fusion of adaptive learning with natural processes. Specifically, we utilize metabolic process-based models to generate simulated DO labels. Using these simulated labels, we implement a multi-population cognitive evolutionary search, where models, mirroring natural organisms, adaptiv
    
[^79]: CPR：检索增强生成用于版权保护

    CPR: Retrieval Augmented Generation for Copyright Protection

    [https://arxiv.org/abs/2403.18920](https://arxiv.org/abs/2403.18920)

    CPR是一种新的用于扩散模型的RAG方法，具有强大的版权保护保障，可以在混合私人设置中条件生成输出，同时不暴露关于检索图片的独特可识别信息。

    

    检索增强生成（RAG）正日益成为一种灵活且强大的技术，使模型能够适应私人用户数据而无需训练，处理信用归因，并允许规模化的高效机器遗忘。然而，图像生成的RAG技术可能导致模型输出中的部分检索样本被复制。为了减少泄漏检索集中包含的私人信息的风险，我们引入了带有检索的受版权保护生成（CPR），这是一种新的用于扩散模型的RAG方法，在混合私人设置中提供了强大的版权保护保证。CPR允许将扩散模型的输出条件设置为一组检索到的图像，同时还保证不会在生成的输出中暴露关于这些示例的独特可识别信息。特别是通过从合并它们的扩散概率分布进行抽样来实现这一点。

    arXiv:2403.18920v1 Announce Type: cross  Abstract: Retrieval Augmented Generation (RAG) is emerging as a flexible and robust technique to adapt models to private users data without training, to handle credit attribution, and to allow efficient machine unlearning at scale. However, RAG techniques for image generation may lead to parts of the retrieved samples being copied in the model's output. To reduce risks of leaking private information contained in the retrieved set, we introduce Copy-Protected generation with Retrieval (CPR), a new method for RAG with strong copyright protection guarantees in a mixed-private setting for diffusion models.CPR allows to condition the output of diffusion models on a set of retrieved images, while also guaranteeing that unique identifiable information about those example is not exposed in the generated outputs. In particular, it does so by sampling from a mixture of public (safe) distribution and private (user) distribution by merging their diffusion s
    
[^80]: 对离群数据检测悖论的似然几何解释

    A Geometric Explanation of the Likelihood OOD Detection Paradox

    [https://arxiv.org/abs/2403.18910](https://arxiv.org/abs/2403.18910)

    高似然区域将不会被生成如果它们包含最小概率质量，基于此观察提出了一种通过本地固有维度估计进行离群检测的方法

    

    基于似然的深度生成模型(DGMs)通常表现出令人困惑的行为：当在相对复杂的数据集上训练时，它们会给来自更简单来源的离群数据赋予更高的似然值。更使人感到神秘的是，尽管具有更高的似然值，但这些DGMs从未生成过离群样本。这个双管齐下的悖论尚未得到最终解释，使得基于似然的离群检测不可靠。我们的主要观察是，如果高似然区域中包含了最小概率质量，那么这些区域将不会被生成。我们演示了在围绕低维流形数据的地方可能出现大密度但低概率质量的看似矛盾情况。我们还展示了通过本地固有维度(LID)估计可以识别这种场景，并提出了一种通过预训练的DGM获得的似然和LID估计相配对的离群检测方法。

    arXiv:2403.18910v1 Announce Type: cross  Abstract: Likelihood-based deep generative models (DGMs) commonly exhibit a puzzling behaviour: when trained on a relatively complex dataset, they assign higher likelihood values to out-of-distribution (OOD) data from simpler sources. Adding to the mystery, OOD samples are never generated by these DGMs despite having higher likelihoods. This two-pronged paradox has yet to be conclusively explained, making likelihood-based OOD detection unreliable. Our primary observation is that high-likelihood regions will not be generated if they contain minimal probability mass. We demonstrate how this seeming contradiction of large densities yet low probability mass can occur around data confined to low-dimensional manifolds. We also show that this scenario can be identified through local intrinsic dimension (LID) estimation, and propose a method for OOD detection which pairs the likelihoods and LID estimates obtained from a pre-trained DGM. Our method can b
    
[^81]: 编码器LLMs骨干的定向可视化

    Targeted Visualization of the Backbone of Encoder LLMs

    [https://arxiv.org/abs/2403.18872](https://arxiv.org/abs/2403.18872)

    本文研究了将DeepView方法应用于自然语言处理领域，以减少编码器模型存在的风险并解释模型决策过程。

    

    基于注意力机制的大型语言模型(LLMs)是自然语言处理(NLP)中的最新技术。其中最常见的两种架构是编码器，如BERT，和解码器，如GPT模型。尽管编码器模型取得了成功，但它们也存在一些风险，包括偏见问题或易受对抗性攻击的影响，这表明了需要可解释的AI来检测这些问题。虽然目前存在各种关注预测单个输入的局部可解释性方法，但基于降维的用于分类检查的全局方法，并且在其他领域出现并超越仅在嵌入空间中使用t-SNE的方法，在NLP中并不十分广泛传播。为了缩小这一差距，我们研究了DeepView方法在NLP领域的应用，该方法用于在二维中可视化决策函数的一部分以及数据集。

    arXiv:2403.18872v1 Announce Type: cross  Abstract: Attention based Large Language Models (LLMs) are the state-of-the-art in natural language processing (NLP). The two most common architectures are encoders such as BERT, and decoders like the GPT models. Despite the success of encoder models, on which we focus in this work, they also bear several risks, including issues with bias or their susceptibility for adversarial attacks, signifying the necessity for explainable AI to detect such issues. While there does exist various local explainability methods focusing on the prediction of single inputs, global methods based on dimensionality reduction for classification inspection, which have emerged in other domains and that go further than just using t-SNE in the embedding space, are not widely spread in NLP.   To reduce this gap, we investigate the application of DeepView, a method for visualizing a part of the decision function together with a data set in two dimensions, to the NLP domain.
    
[^82]: 通过临床领域知识衍生的模板提高了后续AI解释在气胸分类中的应用

    Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification

    [https://arxiv.org/abs/2403.18871](https://arxiv.org/abs/2403.18871)

    提出了一种模板引导方法，将气胸的临床知识融入XAI方法，以过滤掉落在模板之外的不相关解释。

    

    气胸是一种急性胸部疾病，由于肺部和胸壁之间异常积聚气体引起。为了解决深度学习模型常见的不透明问题，引入了可解释人工智能（XAI）方法来勾画深度学习模型进行气胸诊断相关区域。然而，这些解释有时会偏离实际病变区域，突显了进一步改进的必要性。我们提出了一种模板引导方法，将气胸的临床知识融入XAI方法生成的模型解释中，从而提高这些解释的质量。利用放射科医生创建的一种病变划分，我们的方法首先生成代表可能发生气胸区域的模板。然后将此模板叠加到模型解释上，以过滤掉落在模板之外的不相关解释。

    arXiv:2403.18871v1 Announce Type: cross  Abstract: Background: Pneumothorax is an acute thoracic disease caused by abnormal air collection between the lungs and chest wall. To address the opaqueness often associated with deep learning (DL) models, explainable artificial intelligence (XAI) methods have been introduced to outline regions related to pneumothorax diagnoses made by DL models. However, these explanations sometimes diverge from actual lesion areas, highlighting the need for further improvement. Method: We propose a template-guided approach to incorporate the clinical knowledge of pneumothorax into model explanations generated by XAI methods, thereby enhancing the quality of these explanations. Utilizing one lesion delineation created by radiologists, our approach first generates a template that represents potential areas of pneumothorax occurrence. This template is then superimposed on model explanations to filter out extraneous explanations that fall outside the template's b
    
[^83]: 可解释的机器学习用于天气和气候预测：一项调查

    Interpretable Machine Learning for Weather and Climate Prediction: A Survey

    [https://arxiv.org/abs/2403.18864](https://arxiv.org/abs/2403.18864)

    可解释的机器学习技术对于增强天气和气候建模的可信度和实用性至关重要，包括后验可解释性技术和从头设计的固有可解释模型。

    

    最近，先进的机器学习模型在天气和气候预测方面取得了高预测准确性。然而，这些复杂模型通常缺乏固有的透明度和可解释性，表现为“黑匣子”，阻碍了用户信任，也限制了进一步的模型改进。因此，可解释的机器学习技术在增强天气和气候建模的可信度和实用性方面变得至关重要。在本调查中，我们审查了应用于气象预测的当前可解释的机器学习方法。我们将方法分类为两个主要范例：1）后验可解释性技术，解释预训练模型的方法，如基于扰动、基于博弈论和基于梯度的归因方法。2）从头开始设计固有可解释模型的方法，使用树集成和可解释神经网络等架构。我们总结了每种技术如何提供对预测模型内部的见解。

    arXiv:2403.18864v1 Announce Type: cross  Abstract: Advanced machine learning models have recently achieved high predictive accuracy for weather and climate prediction. However, these complex models often lack inherent transparency and interpretability, acting as "black boxes" that impede user trust and hinder further model improvements. As such, interpretable machine learning techniques have become crucial in enhancing the credibility and utility of weather and climate modeling. In this survey, we review current interpretable machine learning approaches applied to meteorological predictions. We categorize methods into two major paradigms: 1) Post-hoc interpretability techniques that explain pre-trained models, such as perturbation-based, game theory based, and gradient-based attribution methods. 2) Designing inherently interpretable models from scratch using architectures like tree ensembles and explainable neural networks. We summarize how each technique provides insights into the pre
    
[^84]: 人类视觉中颜色是否是光子？视觉知觉的量子认知研究

    Are Colors Quanta of Light for Human Vision? A Quantum Cognition Study of Visual Perception

    [https://arxiv.org/abs/2403.18850](https://arxiv.org/abs/2403.18850)

    该研究揭示了量子测量过程中范畴感知现象的机制，认为颜色在人类视觉中可以被视为光子，为视觉感知提供了新的量子认知视角。

    

    我们研究了量子测量过程中范畴感知的现象。该现象的机制在于被感知的扩散刺激被认为属于不同类别，而被感知的收缩刺激被认为属于相同类别。我们展示了，由于纯态之间的距离与密度态之间的距离的确定方式自然不同，因此范畴感知现象根植于量子测量过程的结构中。我们将研究结果应用于颜色的视觉感知情况，并认为可以将颜色视为人类视觉感知中的光子，类似于光频物理测量中的光子。在我们的方法中，我们将知觉看作是现有物理现实、刺激以及被感知者所期望的现实之间的复杂相遇。

    arXiv:2403.18850v1 Announce Type: cross  Abstract: We study the phenomenon of categorical perception within the quantum measurement process. The mechanism underlying this phenomenon consists in dilating stimuli being perceived to belong to different categories and contracting stimuli being perceived to belong to the same category. We show that, due to the naturally different way in determining the distance between pure states compared to the distance between density states, the phenomenon of categorical perception is rooted in the structure of the quantum measurement process itself. We apply our findings to the situation of visual perception of colors and argue that it is possible to consider colors as light quanta for human visual perception in a similar way as photons are light quanta for physical measurements of light frequencies. In our approach we see perception as a complex encounter between the existing physical reality, the stimuli, and the reality expected by the perciever, re
    
[^85]: 基于盲归一化斯坦变分梯度下降的智能大规模随机接入检测

    The Blind Normalized Stein Variational Gradient Descent-Based Detection for Intelligent Massive Random Access

    [https://arxiv.org/abs/2403.18846](https://arxiv.org/abs/2403.18846)

    提出了一种基于盲归一化斯坦变分梯度下降的检测器，用于解决智能大规模随机接入中的前导碰撞问题，并通过开发改进Hadamard变换和设计块MHT层来提高检测性能。

    

    缺乏高效的前导检测算法仍然是解决实际通信场景中智能大规模随机接入(RA)中前导碰撞问题的挑战。为解决这一问题，我们提出了一种新颖的基于最大似然估计(MLE)模型的早期前导检测方案，在授予式RA流程的第一步。提出了一种新颖的基于盲归一化斯坦变分梯度下降(SVGD)的检测器，以获得MLE模型的近似解。首先，通过探索Hadamard变换和小波变换之间的关系，开发了一种新的改进Hadamard变换(MHT)，使用二阶导数滤波器将高频分离出重要部分。接下来，为了消除SVGD检测器中的噪声并减轻梯度消失问题，设计了基于MHT的块MHT层，该层基于MHT、缩放层、软阈值层构建。

    arXiv:2403.18846v1 Announce Type: cross  Abstract: The lack of an efficient preamble detection algorithm remains a challenge for solving preamble collision problems in intelligent massive random access (RA) in practical communication scenarios. To solve this problem, we present a novel early preamble detection scheme based on a maximum likelihood estimation (MLE) model at the first step of the grant-based RA procedure. A novel blind normalized Stein variational gradient descent (SVGD)-based detector is proposed to obtain an approximate solution to the MLE model. First, by exploring the relationship between the Hadamard transform and wavelet transform, a new modified Hadamard transform (MHT) is developed to separate high-frequencies from important components using the second-order derivative filter. Next, to eliminate noise and mitigate the vanishing gradients problem in the SVGD-based detectors, the block MHT layer is designed based on the MHT, scaling layer, soft-thresholding layer, i
    
[^86]: 发挥人工智能的力量。人工智能增强的科学计量学、网络计量学和文献计量学的前沿技术系统综述

    Unleashing the Power of AI. A Systematic Review of Cutting-Edge Techniques in AI-Enhanced Scientometrics, Webometrics, and Bibliometrics

    [https://arxiv.org/abs/2403.18838](https://arxiv.org/abs/2403.18838)

    分析人工智能与科学计量学、网络计量学和文献计量学的协同作用，揭示和强调人工智能算法在这些领域中的应用潜力和好处

    

    arXiv:2403.18838v1 公告类型：交叉摘要：目的：本研究旨在分析人工智能与科学计量学、网络计量学和文献计量学的协同作用，以揭示和强调人工智能算法在这些领域中的应用潜力和好处。方法/设计：通过进行系统文献综述，我们的目标是探索人工智能在革新衡量和分析学术交流方法、识别新兴研究趋势以及评估科学出版物影响方面的潜力。为实现这一目标，我们在诸如ProQuest、IEEE Explore、EBSCO、Web of Science和Scopus等知名数据库上实施了综合搜索策略。我们的搜索范围涵盖了2000年1月1日至2022年9月间发表的文章，总共审阅了61篇相关文章。

    arXiv:2403.18838v1 Announce Type: cross  Abstract: Purpose: The study aims to analyze the synergy of Artificial Intelligence (AI), with scientometrics, webometrics, and bibliometrics to unlock and to emphasize the potential of the applications and benefits of AI algorithms in these fields.   Design/methodology/approach: By conducting a systematic literature review, our aim is to explore the potential of AI in revolutionizing the methods used to measure and analyze scholarly communication, identify emerging research trends, and evaluate the impact of scientific publications. To achieve this, we implemented a comprehensive search strategy across reputable databases such as ProQuest, IEEE Explore, EBSCO, Web of Science, and Scopus. Our search encompassed articles published from January 1, 2000, to September 2022, resulting in a thorough review of 61 relevant articles.   Findings: (i) Regarding scientometrics, the application of AI yields various distinct advantages, such as conducting ana
    
[^87]: DeepTraderX: 使用深度学习挑战传统交易策略在多线程市场模拟中的表现

    DeepTraderX: Challenging Conventional Trading Strategies with Deep Learning in Multi-Threaded Market Simulations

    [https://arxiv.org/abs/2403.18831](https://arxiv.org/abs/2403.18831)

    DeepTraderX是一个使用深度学习的交易系统，在多线程市场模拟中表现出色，并且可以与文献中最佳策略匹敌。

    

    在这篇论文中，我们介绍了DeepTraderX（DTX），这是一个简单基于深度学习的交易系统，并展示了它在多线程市场模拟中的表现。在大约500个模拟市场交易日中，DTX仅通过观察其他策略产生的价格进行学习。通过这样做，它成功地创建了一种从市场数据到要为某个资产下达的报价（买入或卖出订单）的映射关系。DTX在历史Level-2市场数据（即特定可交易资产的限价订单簿）上进行训练，处理每个时间步骤$T$的市场状态$S$，以确定市场订单的价格$P$。训练和测试中使用的市场数据是基于真实历史股票市场数据生成的独特市场时间表。DTX经过了与文献中最佳策略的大量测试，其结果经过了统计分析验证。我们的发现强调了DTX与最佳策略匹敌的能力。

    arXiv:2403.18831v1 Announce Type: cross  Abstract: In this paper, we introduce DeepTraderX (DTX), a simple Deep Learning-based trader, and present results that demonstrate its performance in a multi-threaded market simulation. In a total of about 500 simulated market days, DTX has learned solely by watching the prices that other strategies produce. By doing this, it has successfully created a mapping from market data to quotes, either bid or ask orders, to place for an asset. Trained on historical Level-2 market data, i.e., the Limit Order Book (LOB) for specific tradable assets, DTX processes the market state $S$ at each timestep $T$ to determine a price $P$ for market orders. The market data used in both training and testing was generated from unique market schedules based on real historic stock market data. DTX was tested extensively against the best strategies in the literature, with its results validated by statistical analysis. Our findings underscore DTX's capability to rival, a
    
[^88]: 将生成网络与认知共同模型相结合

    Bridging Generative Networks with the Common Model of Cognition

    [https://arxiv.org/abs/2403.18827](https://arxiv.org/abs/2403.18827)

    通过将模块重构为影子生成系统，实现了认知架构与生成神经网络的无缝连接

    

    本文提出了一个理论框架，将认知共同模型调整为人工智能领域中的大型生成网络模型。通过将共同模型中的模块重构为周边的影子生成系统，这些影子生成系统辅助处理高层推理，从而实现认知架构与生成神经网络的无缝连接。

    arXiv:2403.18827v1 Announce Type: new  Abstract: This article presents a theoretical framework for adapting the Common Model of Cognition to large generative network models within the field of artificial intelligence. This can be accomplished by restructuring modules within the Common Model into shadow production systems that are peripheral to a central production system, which handles higher-level reasoning based on the shadow productions' output. Implementing this novel structure within the Common Model allows for a seamless connection between cognitive architectures and generative neural networks.
    
[^89]: ECoDepth: 有效调整扩散模型以用于单目深度估计

    ECoDepth: Effective Conditioning of Diffusion Models for Monocular Depth Estimation

    [https://arxiv.org/abs/2403.18807](https://arxiv.org/abs/2403.18807)

    通过使用预训练的ViT模型生成的全局图像先验，为单图深度估计模型提供更详细的上下文信息，并提出了一种新的使用扩散骨干且受ViT嵌入条件约束的深度估计模型。

    

    在缺乏视差线索的情况下，基于学习的单图深度估计（SIDE）模型严重依赖图像中的阴影和上下文线索。我们从已有研究的启发中探讨使用从预训练的ViT模型生成的全局图像先验，以提供更详细的上下文信息。基于这一想法，我们提出了一种新的使用扩散骨干的SIDE模型，其受到ViT嵌入的条件约束。

    arXiv:2403.18807v1 Announce Type: cross  Abstract: In the absence of parallax cues, a learning-based single image depth estimation (SIDE) model relies heavily on shading and contextual cues in the image. While this simplicity is attractive, it is necessary to train such models on large and varied datasets, which are difficult to capture. It has been shown that using embeddings from pre-trained foundational models, such as CLIP, improves zero shot transfer in several applications. Taking inspiration from this, in our paper we explore the use of global image priors generated from a pre-trained ViT model to provide more detailed contextual information. We argue that the embedding vector from a ViT model, pre-trained on a large dataset, captures greater relevant information for SIDE than the usual route of generating pseudo image captions, followed by CLIP based text embeddings. Based on this idea, we propose a new SIDE model using a diffusion backbone which is conditioned on ViT embedding
    
[^90]: 多目标进化影响最大化：平衡传播、预算、公平性和时间

    Many-Objective Evolutionary Influence Maximization: Balancing Spread, Budget, Fairness, and Time

    [https://arxiv.org/abs/2403.18755](https://arxiv.org/abs/2403.18755)

    通过引入多目标进化算法，本研究在最大化影响和最小化种子集大小的基础上，优化了多个IM特定目标函数，包括预算、公平性、社区和时间。

    

    影响最大化（IM）问题旨在发现图中可以最大程度传播信息传播的节点集。这个问题被称为NP难题，通常通过最大化影响（传播）以及选择性优化第二个目标（例如最小化种子集大小或最大化影响公平性）来研究。然而，在许多实际场景中，IM问题的多个方面必须同时进行优化。在这项工作中，我们提出了一个第一个案例研究，在此基础上优化了几个IM特定目标函数，即预算、公平性、社区和时间，同时最大化传播影响并最小化种子集大小。为此，我们引入了MOEIM（用于影响最大化的多目标进化算法），这是一个基于NSGA-II的多目标进化算法（MOEA），结合了具有图感知性的算子和智能初始化。我们通过...

    arXiv:2403.18755v1 Announce Type: cross  Abstract: The Influence Maximization (IM) problem seeks to discover the set of nodes in a graph that can spread the information propagation at most. This problem is known to be NP-hard, and it is usually studied by maximizing the influence (spread) and, optionally, optimizing a second objective, such as minimizing the seed set size or maximizing the influence fairness. However, in many practical scenarios multiple aspects of the IM problem must be optimized at the same time. In this work, we propose a first case study where several IM-specific objective functions, namely budget, fairness, communities, and time, are optimized on top of the maximization of influence and minimization of the seed set size. To this aim, we introduce MOEIM (Many-Objective Evolutionary Algorithm for Influence Maximization) a Multi-Objective Evolutionary Algorithm (MOEA) based on NSGA-II incorporating graph-aware operators and a smart initialization. We compare MOEIM in
    
[^91]: 中国 offensive 语言检测：现状与未来方向

    Chinese Offensive Language Detection:Current Status and Future Directions

    [https://arxiv.org/abs/2403.18314](https://arxiv.org/abs/2403.18314)

    总体而言，这篇论文讨论了在中文中检测 offensive 语言的挑战，并强调了开发解决这一问题的特定模型和工具。

    

    虽然社交媒体平台正在做出相当大的努力监测和规范用户生成内容，但在数字空间中，恶意语言（如仇恨言论或网络欺凌）的普遍存在仍然是一个重要挑战。鉴于维护文明和尊重的在线环境的重要性，迫切需要能够实时检测恶意言论的自动系统。然而，为了开发处理汉语等语言的有效系统，面临着重大挑战，因为这些语言的复杂和微妙性使得自动处理变得困难。本文全面总结了中国 offensive 语言检测情况，审查了当前的基准和方法，并重点介绍了用于解决在这种复杂语言中检测恶意语言的独特挑战的特定模型和工具。

    arXiv:2403.18314v1 Announce Type: cross  Abstract: Despite the considerable efforts being made to monitor and regulate user-generated content on social media platforms, the pervasiveness of offensive language, such as hate speech or cyberbullying, in the digital space remains a significant challenge. Given the importance of maintaining a civilized and respectful online environment, there is an urgent and growing need for automatic systems capable of detecting offensive speech in real time. However, developing effective systems for processing languages such as Chinese presents a significant challenge, owing to the language's complex and nuanced nature, which makes it difficult to process automatically. This paper provides a comprehensive overview of offensive language detection in Chinese, examining current benchmarks and approaches and highlighting specific models and tools for addressing the unique challenges of detecting offensive language in this complex language. The primary object
    
[^92]: 噢！我们冷冻：通过信号传播分析改进大型语言模型的量化知识蒸馏

    Oh! We Freeze: Improving Quantized Knowledge Distillation via Signal Propagation Analysis for Large Language Models

    [https://arxiv.org/abs/2403.18159](https://arxiv.org/abs/2403.18159)

    通过信号传播分析，提出了一种改进大型语言模型的量化知识蒸馏方法，并提供了ov-freeze稳定KD-QAT过程的洞察。

    

    大型生成模型，如大型语言模型（LLMs）和扩散模型分别在NLP和计算机视觉领域引起了革命。然而，它们的推理速度慢，计算和内存需求高，这使得在边缘设备上部署它们变得具有挑战性。在这项研究中，我们提出了一种轻量级的量化感知微调技术，使用知识蒸馏（KD-QAT）来改善使用常用数据集改进4位重量量化的LLMs的性能，以实现流行的语言使用案例，在设备聊天应用中。为了改进这种微调范式，作为主要贡献，我们通过经验研究训练过程中的梯度传播，提供对KD-QAT稳定性的洞察，以更好地理解基于KD-QAT的方法对低位量化误差的脆弱性。根据我们的见解，我们提出了ov-freeze，一种稳定KD-QAT过程的简单技术。最后，我们进行了实验

    arXiv:2403.18159v1 Announce Type: cross  Abstract: Large generative models, such as large language models (LLMs) and diffusion models have as revolutionized the fields of NLP and computer vision respectively. However, their slow inference, high computation and memory requirement makes it challenging to deploy them on edge devices. In this study, we propose a light-weight quantization aware fine tuning technique using knowledge distillation (KD-QAT) to improve the performance of 4-bit weight quantized LLMs using commonly available datasets to realize a popular language use case, on device chat applications. To improve this paradigm of finetuning, as main contributions, we provide insights into stability of KD-QAT by empirically studying the gradient propagation during training to better understand the vulnerabilities of KD-QAT based approaches to low-bit quantization errors. Based on our insights, we propose ov-freeze, a simple technique to stabilize the KD-QAT process. Finally, we expe
    
[^93]: 从部分观测预测物种出现模式

    Predicting species occurrence patterns from partial observations

    [https://arxiv.org/abs/2403.18028](https://arxiv.org/abs/2403.18028)

    提出了一个问题，即采用卫星图像和其他物种出现信息来预测物种出现模式，并提出了一个通用模型R-Tran，可以利用部分观测数据进行预测，优于其他方法。

    

    为了应对生物多样性和气候危机，我们需要了解物种分布的位置以及这些模式如何变化。然而，大多数物种的观测数据仍然非常有限，可用数据的量在不同分类群之间差异很大。我们提出了一个问题，即在给定卫星图像和其他物种出现信息的情况下预测物种出现模式。为了在此任务上评估算法，我们介绍了SatButterfly数据集，其中包含了蝴蝶的卫星图像、环境数据和观测数据，旨在与现有的鸟类观测数据集SatBird配对。为了解决这一任务，我们提出了一个通用模型R-Tran，用于预测物种出现模式，可以在任何地方使用部分观测数据。我们发现，R-Tran在预测物种遭遇率方面优于其他方法。

    arXiv:2403.18028v1 Announce Type: cross  Abstract: To address the interlinked biodiversity and climate crises, we need an understanding of where species occur and how these patterns are changing. However, observational data on most species remains very limited, and the amount of data available varies greatly between taxonomic groups. We introduce the problem of predicting species occurrence patterns given (a) satellite imagery, and (b) known information on the occurrence of other species. To evaluate algorithms on this task, we introduce SatButterfly, a dataset of satellite images, environmental data and observational data for butterflies, which is designed to pair with the existing SatBird dataset of bird observational data. To address this task, we propose a general model, R-Tran, for predicting species occurrence patterns that enables the use of partial observational data wherever found. We find that R-Tran outperforms other methods in predicting species encounter rates with partial
    
[^94]: 通过特定掩码损失改善预训练语言模型的敏感性：以生物医学实体识别为例

    Improving Pre-trained Language Model Sensitivity via Mask Specific losses: A case study on Biomedical NER

    [https://arxiv.org/abs/2403.18025](https://arxiv.org/abs/2403.18025)

    提出了Mask Specific Language Modeling（MSLM）方法来改善LM在微调过程中对目标领域知识的敏感性，通过加权领域特定术语的重要性进行学习。

    

    将语言模型（LMs）调整到新领域通常通过在特定领域数据上微调预训练LM（PLM）来实现。微调将新知识引入LM，使它能够理解和有效执行目标域任务。然而，微调可能会无意中变得不够敏感，如果它忽视了源域和目标域之间的广泛差异（例如在词义上）。为了解决微调不敏感的问题，我们提出了Mask Specific Language Modeling（MSLM），一种通过在微调过程中适当加权领域特定术语（DS-terms）的重要性来有效获取目标领域知识的方法。MSLM同时屏蔽DS术语和通用词，然后通过确保LM受到更大惩罚来学习特定于掩码的损失。

    arXiv:2403.18025v1 Announce Type: cross  Abstract: Adapting language models (LMs) to novel domains is often achieved through fine-tuning a pre-trained LM (PLM) on domain-specific data. Fine-tuning introduces new knowledge into an LM, enabling it to comprehend and efficiently perform a target domain task. Fine-tuning can however be inadvertently insensitive if it ignores the wide array of disparities (e.g in word meaning) between source and target domains. For instance, words such as chronic and pressure may be treated lightly in social conversations, however, clinically, these words are usually an expression of concern. To address insensitive fine-tuning, we propose Mask Specific Language Modeling (MSLM), an approach that efficiently acquires target domain knowledge by appropriately weighting the importance of domain-specific terms (DS-terms) during fine-tuning. MSLM jointly masks DS-terms and generic words, then learns mask-specific losses by ensuring LMs incur larger penalties for in
    
[^95]: LISA：用于高效内存大型语言模型微调的逐层重要性采样

    LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning

    [https://arxiv.org/abs/2403.17919](https://arxiv.org/abs/2403.17919)

    逐层重要性采样的新方法LISA在微调任务中表现出色，记忆成本低且优于传统方法。

    

    机器学习领域自大型语言模型（LLMs）首次出现以来取得了令人瞩目的进展，然而它们巨大的内存消耗已成为大规模训练的主要障碍。虽然已经提出了诸如低秩调整（LoRA）之类的参数高效微调技术来缓解这一问题，但在大多数大规模微调设置中，它们的性能仍无法与完整参数训练相匹配。为弥补这一不足，我们研究了LoRA在微调任务中的逐层特性，并观察到不同层之间权重范数的异常偏斜。利用这一关键观察，我们发现了一个令人惊讶简单的训练策略，在记忆成本低于LoRA的情况下，在广泛的设置中优于LoRA和完整参数训练。我们将其命名为Layerwise Importance Sampled AdamW（LISA），这是LoRA的一个有希望的替代方案，应用了

    arXiv:2403.17919v1 Announce Type: cross  Abstract: The machine learning community has witnessed impressive advancements since the first appearance of large language models (LLMs), yet their huge memory consumption has become a major roadblock to large-scale training. Parameter Efficient Fine-Tuning techniques such as Low-Rank Adaptation (LoRA) have been proposed to alleviate this problem, but their performance still fails to match full parameter training in most large-scale fine-tuning settings. Attempting to complement this deficiency, we investigate layerwise properties of LoRA on fine-tuning tasks and observe an uncommon skewness of weight norms across different layers. Utilizing this key observation, a surprisingly simple training strategy is discovered, which outperforms both LoRA and full parameter training in a wide range of settings with memory costs as low as LoRA. We name it Layerwise Importance Sampled AdamW (LISA), a promising alternative for LoRA, which applies the idea of
    
[^96]: 一体化：异质交互建模用于冷启动评分预测

    All-in-One: Heterogeneous Interaction Modeling for Cold-Start Rating Prediction

    [https://arxiv.org/abs/2403.17740](https://arxiv.org/abs/2403.17740)

    提出了异质交互评分网络（HIRE）框架，通过异质交互模块（HIM）来共同建模异质交互并直接推断重要特征

    

    冷启动评分预测是推荐系统中一个基本问题，已得到广泛研究。许多方法已经被提出，利用现有数据之间的显式关系，例如协同过滤、社交推荐和异构信息网络，以缓解冷启动用户和物品的数据不足问题。然而，基于不同角色之间的数据构建的显式关系可能不可靠且无关，从而限制了特定推荐任务的性能上限。受此启发，本文提出了一个灵活的框架，名为异质交互评分网络（HIRE）。HIRE不仅仅依赖于预先定义的交互模式或手动构建的异构信息网络。相反，我们设计了一个异质交互模块（HIM），来共同建模异质交互并直接推断重要特征。

    arXiv:2403.17740v1 Announce Type: cross  Abstract: Cold-start rating prediction is a fundamental problem in recommender systems that has been extensively studied. Many methods have been proposed that exploit explicit relations among existing data, such as collaborative filtering, social recommendations and heterogeneous information network, to alleviate the data insufficiency issue for cold-start users and items. However, the explicit relations constructed based on data between different roles may be unreliable and irrelevant, which limits the performance ceiling of the specific recommendation task. Motivated by this, in this paper, we propose a flexible framework dubbed heterogeneous interaction rating network (HIRE). HIRE dose not solely rely on the pre-defined interaction pattern or the manually constructed heterogeneous information network. Instead, we devise a Heterogeneous Interaction Module (HIM) to jointly model the heterogeneous interactions and directly infer the important in
    
[^97]: UADA3D：面向稀疏LiDAR和大领域差距的无监督对抗领域自适应在3D物体检测中的应用

    UADA3D: Unsupervised Adversarial Domain Adaptation for 3D Object Detection with Sparse LiDAR and Large Domain Gaps

    [https://arxiv.org/abs/2403.17633](https://arxiv.org/abs/2403.17633)

    UADA3D是一种无监督对抗领域自适应方法，能够在3D物体检测中处理稀疏LiDAR数据和大领域差距，并在自动驾驶汽车和移动机器人领域中表现出显著的改进。

    

    在这项研究中，我们解决了现有无监督领域适应方法在基于LiDAR的3D物体检测中的一个问题，这些方法主要集中在适应已建立的高密度自动驾驶数据集之间的转变。我们专注于更稀疏的点云，捕捉来自不同视角的场景：不仅来自道路上的车辆，还来自人行道上的移动机器人，遭遇着明显不同的环境条件和传感器配置。我们引入了无监督对抗领域自适应3D物体检测（UADA3D）。UADA3D不依赖于预训练的源模型或师生架构。相反，它使用对抗方法直接学习域不变特征。我们展示了它在各种适应场景中的有效性，在自动驾驶汽车和移动机器人领域均显示出显著的改进。我们的代码是开源的，很快将会提供。

    arXiv:2403.17633v1 Announce Type: cross  Abstract: In this study, we address a gap in existing unsupervised domain adaptation approaches on LiDAR-based 3D object detection, which have predominantly concentrated on adapting between established, high-density autonomous driving datasets. We focus on sparser point clouds, capturing scenarios from different perspectives: not just from vehicles on the road but also from mobile robots on sidewalks, which encounter significantly different environmental conditions and sensor configurations. We introduce Unsupervised Adversarial Domain Adaptation for 3D Object Detection (UADA3D). UADA3D does not depend on pre-trained source models or teacher-student architectures. Instead, it uses an adversarial approach to directly learn domain-invariant features. We demonstrate its efficacy in various adaptation scenarios, showing significant improvements in both self-driving car and mobile robot domains. Our code is open-source and will be available soon.
    
[^98]: 伪造还是JPEG？揭示生成图像检测数据集中的常见偏见

    Fake or JPEG? Revealing Common Biases in Generated Image Detection Datasets

    [https://arxiv.org/abs/2403.17608](https://arxiv.org/abs/2403.17608)

    许多AI生成图像检测数据集存在与JPEG压缩和图像大小相关的偏见，去除这些偏见可以显著提高对JPEG压缩的稳健性并显著改变检测器的跨生成器性能。

    

    生成图像模型的广泛应用凸显了检测人造内容的迫切需求，这是打击广泛操纵和误导的关键一步。因此，许多检测器和相关数据集已经出现。然而，许多这些数据集不经意地引入了不良偏见，从而影响了检测器的效果和评估。本文强调了许多用于AI生成图像检测的数据集包含与JPEG压缩和图像大小有关的偏见。使用GenImage数据集，我们证明检测器确实从这些不受欢迎的因素中学习。此外，我们展示去除这些命名偏见会显著增加针对JPEG压缩的鲁棒性，并显著改变评估检测器的跨生成器性能。具体来说，对于ResNet50和S

    arXiv:2403.17608v1 Announce Type: cross  Abstract: The widespread adoption of generative image models has highlighted the urgent need to detect artificial content, which is a crucial step in combating widespread manipulation and misinformation. Consequently, numerous detectors and associated datasets have emerged. However, many of these datasets inadvertently introduce undesirable biases, thereby impacting the effectiveness and evaluation of detectors. In this paper, we emphasize that many datasets for AI-generated image detection contain biases related to JPEG compression and image size. Using the GenImage dataset, we demonstrate that detectors indeed learn from these undesired factors. Furthermore, we show that removing the named biases substantially increases robustness to JPEG compression and significantly alters the cross-generator performance of evaluated detectors. Specifically, it leads to more than 11 percentage points increase in cross-generator performance for ResNet50 and S
    
[^99]: CADGL: 上下文感知深度图学习用于预测药物-药物相互作用

    CADGL: Context-Aware Deep Graph Learning for Predicting Drug-Drug Interactions

    [https://arxiv.org/abs/2403.17210](https://arxiv.org/abs/2403.17210)

    通过CADGL框架，利用上下文感知深度图学习来预测药物-药物相互作用，解决了现有DDI预测模型在泛化、特征提取和现实应用方面的挑战

    

    药物-药物相互作用（DDIs）的研究是药物开发过程中的一个关键元素。DDIs发生在一个药物的性质受其他药物包含的影响时。检测有利的DDIs有可能为在实际设置中应用的创新药物的创造和推进铺平道路。然而，现有的DDI预测模型在极端情况下的泛化、稳健特征提取以及现实应用可能性方面持续面临挑战。我们旨在通过利用上下文感知深度图学习的有效性，引入一种名为CADGL的新颖框架来应对这些挑战。基于定制的变分图自编码器（VGAE），我们利用两个上下文预处理器从两个不同视角：局部邻域和分子上下文，在异质图结构中提取特征，捕获关键的结构和生理化学信息。

    arXiv:2403.17210v1 Announce Type: cross  Abstract: Examining Drug-Drug Interactions (DDIs) is a pivotal element in the process of drug development. DDIs occur when one drug's properties are affected by the inclusion of other drugs. Detecting favorable DDIs has the potential to pave the way for creating and advancing innovative medications applicable in practical settings. However, existing DDI prediction models continue to face challenges related to generalization in extreme cases, robust feature extraction, and real-life application possibilities. We aim to address these challenges by leveraging the effectiveness of context-aware deep graph learning by introducing a novel framework named CADGL. Based on a customized variational graph autoencoder (VGAE), we capture critical structural and physio-chemical information using two context preprocessors for feature extraction from two different perspectives: local neighborhood and molecular context, in a heterogeneous graphical structure. Ou
    
[^100]: 揭示本地差分隐私、平均贝叶斯隐私和最大贝叶斯隐私之间的相互作用

    Deciphering the Interplay between Local Differential Privacy, Average Bayesian Privacy, and Maximum Bayesian Privacy

    [https://arxiv.org/abs/2403.16591](https://arxiv.org/abs/2403.16591)

    论文探讨了本地差分隐私、贝叶斯隐私及其之间的相互关系，揭示了关于效用-隐私权衡的新见解，并提出了一个框架来突出攻击和防御策略的相互作用和效果。

    

    机器学习的迅速发展导致了隐私定义的多样化，由于对隐私构成的威胁，包括本地差分隐私（LDP）的概念。虽然被广泛接受并在许多领域中被利用，但这种传统的隐私测量方法仍然存在一定限制，从无法防止推断披露到缺乏对对手背景知识的考虑。在这项全面研究中，我们引入贝叶斯隐私并深入探讨本地差分隐私和其贝叶斯对应物之间错综复杂的关系，揭示了关于效用-隐私权衡的新见解。我们引入了一个框架，概括了攻击和防御策略，突出它们之间的相互作用和效果。我们的理论贡献基于平均贝叶斯隐私（ABP）和最大贝叶斯隐私之间的严格定义和关系。

    arXiv:2403.16591v1 Announce Type: cross  Abstract: The swift evolution of machine learning has led to emergence of various definitions of privacy due to the threats it poses to privacy, including the concept of local differential privacy (LDP). Although widely embraced and utilized across numerous domains, this conventional approach to measure privacy still exhibits certain limitations, spanning from failure to prevent inferential disclosure to lack of consideration for the adversary's background knowledge. In this comprehensive study, we introduce Bayesian privacy and delve into the intricate relationship between local differential privacy and its Bayesian counterparts, unveiling novel insights into utility-privacy trade-offs. We introduce a framework that encapsulates both attack and defense strategies, highlighting their interplay and effectiveness. Our theoretical contributions are anchored in the rigorous definitions and relationships between Average Bayesian Privacy (ABP) and Max
    
[^101]: DeepMachining: 铣床机床加工误差在线预测

    DeepMachining: Online Prediction of Machining Errors of Lathe Machines

    [https://arxiv.org/abs/2403.16451](https://arxiv.org/abs/2403.16451)

    DeepMachining是一种基于深度学习的AI系统，可以在线预测车床机床加工操作的误差，通过预训练和微调模型，实现了高准确性预测，是首批使用预训练深度学习模型预测车床机床加工误差的工厂实验之一。

    

    我们描述了DeepMachining，这是一种基于深度学习的人工智能系统，用于在线预测车床加工操作的加工误差。我们基于工厂的制造数据构建并评估了DeepMachining。具体来说，我们首先对特定车床机床操作预训练深度学习模型，以学习加工状态的显著特征。然后，我们微调预训练模型以适应特定加工任务。我们展示了DeepMachining在涉及不同工件和刀具的多个任务中实现了高预测准确性。据我们所知，这项工作是使用预训练深度学习模型预测车床机床加工误差的首批工厂实验之一。

    arXiv:2403.16451v1 Announce Type: cross  Abstract: We describe DeepMachining, a deep learning-based AI system for online prediction of machining errors of lathe machine operations. We have built and evaluated DeepMachining based on manufacturing data from factories. Specifically, we first pretrain a deep learning model for a given lathe machine's operations to learn the salient features of machining states. Then, we fine-tune the pretrained model to adapt to specific machining tasks. We demonstrate that DeepMachining achieves high prediction accuracy for multiple tasks that involve different workpieces and cutting tools. To the best of our knowledge, this work is one of the first factory experiments using pre-trained deep-learning models to predict machining errors of lathe machines.
    
[^102]: 语言模型能够模拟求解器吗？LLMs的逻辑代码模拟

    Can Language Models Pretend Solvers? Logic Code Simulation with LLMs

    [https://arxiv.org/abs/2403.16097](https://arxiv.org/abs/2403.16097)

    这项研究探讨了一种新颖的任务，即逻辑代码模拟，迫使LLMs在预测逻辑程序的结果时模拟逻辑求解器，同时提出了三个研究问题以深入调查这一任务对LLMs的影响。

    

    基于Transformer的大型语言模型(LLMs)在解决逻辑问题方面展示了重要潜力。利用LLMs在代码相关活动中的卓越能力，最近提出了几种利用逻辑求解器进行逻辑推理的框架。虽然现有研究主要集中在将LLMs视为自然语言逻辑求解器或翻译器，但它们作为逻辑代码解释器和执行器的角色受到了较少关注。本研究深入探讨了一个新颖的方面，即逻辑代码模拟，它迫使LLMs在预测逻辑程序的结果时模拟逻辑求解器。为进一步研究这一新颖任务，我们制定了三个研究问题：LLMs能否有效地模拟逻辑代码的输出？逻辑代码模拟伴随着哪些优势？以及存在哪些缺陷？为了回答这些问题，我们整理了三个针对逻辑代码模拟的新颖数据集。

    arXiv:2403.16097v1 Announce Type: new  Abstract: Transformer-based large language models (LLMs) have demonstrated significant potential in addressing logic problems. capitalizing on the great capabilities of LLMs for code-related activities, several frameworks leveraging logical solvers for logic reasoning have been proposed recently. While existing research predominantly focuses on viewing LLMs as natural language logic solvers or translators, their roles as logic code interpreters and executors have received limited attention. This study delves into a novel aspect, namely logic code simulation, which forces LLMs to emulate logical solvers in predicting the results of logical programs. To further investigate this novel task, we formulate our three research questions: Can LLMs efficiently simulate the outputs of logic codes? What strength arises along with logic code simulation? And what pitfalls? To address these inquiries, we curate three novel datasets tailored for the logic code si
    
[^103]: 在干草堆中寻找针: 一种透明水印检测的黑盒方法

    Finding needles in a haystack: A Black-Box Approach to Invisible Watermark Detection

    [https://arxiv.org/abs/2403.15955](https://arxiv.org/abs/2403.15955)

    提出了一种透明水印检测的黑盒方法WMD，在无注释设置下，利用干净无水印数据集检测任意水印，效果显著优于传统方法

    

    在本文中，我们提出了WaterMark Detection（WMD），这是第一个在黑盒和无注释设置下进行透明水印检测的方法。WMD能够利用一个干净的无水印数据集作为参考，在不依赖特定解码方法或对水印技术的事先了解的情况下，检测给定参考数据集中的任意水印。我们使用偏移学习的基础开发了WMD，干净的无水印数据集使我们能够仅分离出参考数据集中带水印样本的影响。我们进行了全面的评估，证明了WMD的有效性，明显优于仅产生约0.5的AUC得分的简单检测方法。相比之下，WMD在大多数单水印数据集中持续获得令人印象深刻的检测AUC得分，超过0.9，并在更具挑战性的多水印场景中的各种数据集和水印方法中超过0.7。

    arXiv:2403.15955v1 Announce Type: cross  Abstract: In this paper, we propose WaterMark Detection (WMD), the first invisible watermark detection method under a black-box and annotation-free setting. WMD is capable of detecting arbitrary watermarks within a given reference dataset using a clean non-watermarked dataset as a reference, without relying on specific decoding methods or prior knowledge of the watermarking techniques. We develop WMD using foundations of offset learning, where a clean non-watermarked dataset enables us to isolate the influence of only watermarked samples in the reference dataset. Our comprehensive evaluations demonstrate the effectiveness of WMD, significantly outperforming naive detection methods, which only yield AUC scores around 0.5. In contrast, WMD consistently achieves impressive detection AUC scores, surpassing 0.9 in most single-watermark datasets and exceeding 0.7 in more challenging multi-watermark scenarios across diverse datasets and watermarking me
    
[^104]: X-Portrait: 具有分层动作注意力的表现性肖像动画

    X-Portrait: Expressive Portrait Animation with Hierarchical Motion Attention

    [https://arxiv.org/abs/2403.15931](https://arxiv.org/abs/2403.15931)

    这里是中文总结出的一句话要点: 该论文提出了X-Portrait，一种用于生成具有表现力和时间连贯性的肖像动画的条件扩散模型，利用控制信号实现了细粒度头部姿势和表情控制，以提高运动精度。

    

    我们提出了X-Portrait，这是一种创新的条件扩散模型，专门用于生成具有表现力和时间连贯性的肖像动画。具体而言，我们旨在基于单个肖像作为外观参考，并利用来自驱动视频的运动来为其添加动画，捕捉具有高度动态性和微妙面部表情以及广泛范围头部运动。在其核心部分，我们利用了预先训练的扩散模型的生成先验作为渲染骨架，同时在ControlNet框架内通过新颖的控制信号实现了细粒度头部姿势和表情控制。与传统的粗糙显式控制（如面部标志点）不同，我们的运动控制模块学会直接从原始驱动RGB输入中解读动态。通过有效增强对眼神等小尺度细微差异的运动关注的基于补丁的局部控制模块，进一步提高了运动精度。

    arXiv:2403.15931v1 Announce Type: cross  Abstract: We propose X-Portrait, an innovative conditional diffusion model tailored for generating expressive and temporally coherent portrait animation. Specifically, given a single portrait as appearance reference, we aim to animate it with motion derived from a driving video, capturing both highly dynamic and subtle facial expressions along with wide-range head movements. As its core, we leverage the generative prior of a pre-trained diffusion model as the rendering backbone, while achieve fine-grained head pose and expression control with novel controlling signals within the framework of ControlNet. In contrast to conventional coarse explicit controls such as facial landmarks, our motion control module is learned to interpret the dynamics directly from the original driving RGB inputs. The motion accuracy is further enhanced with a patch-based local control module that effectively enhance the motion attention to small-scale nuances like eyeba
    
[^105]: WoLF: 用于胸部X线图理解的大型语言模型框架

    WoLF: Large Language Model Framework for CXR Understanding

    [https://arxiv.org/abs/2403.15456](https://arxiv.org/abs/2403.15456)

    WoLF框架提出了对于CXR的全面理解的改进，包括使用额外的健康相关数据、重构报告以提供更有组织的信息、以及改进生成答案的细致评估。

    

    通过现代视觉语言模型(VLMs)取得了对胸部X线图(CXR)理解方面的显着方法进展，展示了令人印象深刻的视觉问答(VQA)和CXR报告生成能力。然而，现有的CXR理解框架仍存在几个程序上的缺陷。(1)以往的方法仅使用CXR报告，这对于全面的视觉问答(VQA)来说是不够的，特别是当需要额外的健康相关数据如用药历史和先前的诊断时。(2)以往的方法使用未经处理的CXR报告，这些报告往往结构随意。虽然现代语言模型可以理解各种文本格式，但为了提供更清晰、有组织的基于解剖学的信息，重构报告可能会增强它们的实用性。(3)目前用于CXR-VQA的评估方法主要强调语言正确性，缺乏对生成答案的微妙评估能力。

    arXiv:2403.15456v1 Announce Type: new  Abstract: Significant methodological strides have been made toward Chest X-ray (CXR) understanding via modern vision-language models (VLMs), demonstrating impressive Visual Question Answering (VQA) and CXR report generation abilities. However, existing CXR understanding frameworks still possess several procedural caveats. (1) Previous methods solely use CXR reports, which are insufficient for comprehensive Visual Question Answering (VQA), especially when additional health-related data like medication history and prior diagnoses are needed. (2) Previous methods use raw CXR reports, which are often arbitrarily structured. While modern language models can understand various text formats, restructuring reports for clearer, organized anatomy-based information could enhance their usefulness. (3) Current evaluation methods for CXR-VQA primarily emphasize linguistic correctness, lacking the capability to offer nuanced assessments of the generated answers.
    
[^106]: 人工智能中的信任: 进展、挑战和未来方向

    Trust in AI: Progress, Challenges, and Future Directions

    [https://arxiv.org/abs/2403.14680](https://arxiv.org/abs/2403.14680)

    人工智能中的信任是控制其传播程度的调节器，通过增加信任和减少不信任，可以显著影响人工智能的采用速度。

    

    人工智能系统在我们日常生活中的广泛应用通过各种应用、服务和产品，说明了来自用户角度对人工智能的信任/不信任的重要性。与其他技术相比，由人工智能驱动的系统不仅作为一些有益工具广泛渗透到我们的生活中，而且还会成为代表我们的替代性代理人，或者会影响人类思维、决策和行动的操纵性心智。近来，各种研究已经关注了人工智能中信任/不信任的不同维度及其相关考虑因素。在这篇系统性文献综述中，在对当前人工智能文献中对信任的概念化之后，我们将调查

    arXiv:2403.14680v1 Announce Type: cross  Abstract: The increasing use of artificial intelligence (AI) systems in our daily life through various applications, services, and products explains the significance of trust/distrust in AI from a user perspective. AI-driven systems (as opposed to other technologies) have ubiquitously diffused in our life not only as some beneficial tools to be used by human agents but also are going to be substitutive agents on our behalf, or manipulative minds that would influence human thought, decision, and agency. Trust/distrust in AI plays the role of a regulator and could significantly control the level of this diffusion, as trust can increase, and distrust may reduce the rate of adoption of AI. Recently, varieties of studies have paid attention to the variant dimension of trust/distrust in AI, and its relevant considerations. In this systematic literature review, after conceptualization of trust in the current AI literature review, we will investigate tr
    
[^107]: 通过知识编辑实现对大型语言模型的去毒化

    Detoxifying Large Language Models via Knowledge Editing

    [https://arxiv.org/abs/2403.14472](https://arxiv.org/abs/2403.14472)

    本文研究了使用知识编辑技术对大型语言模型进行去毒化，在构建了SafeEdit基准的基础上，提出了一种简单而有效的方法 DINM，可以通过少量调整步骤减少模型的毒性，同时对各种去毒方法的内部机制进行了深入分析。

    

    本文研究了使用知识编辑技术来对大型语言模型（LLMs）进行去毒化。我们构建了一个名为SafeEdit的基准，涵盖了九种不安全类别，具有各种强大的攻击提示，并配备了全面的度量标准进行系统评估。我们进行了实验，比较了知识编辑方法与之前的基准线，结果表明知识编辑有潜力在对LLMs进行去毒化时，在对一般性能的影响相对有限。然后，我们提出了一个简单但有效的基准线，称为通过术中神经监测去毒化（DINM），通过仅一次实例的少量调整步骤减少LLMs的毒性。我们进一步对各种去毒方法的内部机制进行了深入分析，表明先前的方法如SFT和DPO可能仅抑制有毒参数的激活，而DINM则减轻有毒参数的毒性。

    arXiv:2403.14472v1 Announce Type: cross  Abstract: This paper investigates using knowledge editing techniques to detoxify Large Language Models (LLMs). We construct a benchmark, SafeEdit, which covers nine unsafe categories with various powerful attack prompts and equips comprehensive metrics for systematic evaluation. We conduct experiments to compare knowledge editing approaches with previous baselines, indicating that knowledge editing has the potential to efficiently detoxify LLMs with limited impact on general performance. Then, we propose a simple yet effective baseline, dubbed Detoxifying with Intraoperative Neural Monitoring (DINM), to diminish the toxicity of LLMs within a few tuning steps via only one instance. We further provide an in-depth analysis of the internal mechanism for various detoxify approaches, demonstrating that previous methods like SFT and DPO may merely suppress the activations of toxic parameters, while DINM mitigates the toxicity of the toxic parameters to
    
[^108]: 自适应检索增强大型语言模型：通过问题复杂度学习调适

    Adaptive-RAG: Learning to Adapt Retrieval-Augmented Large Language Models through Question Complexity

    [https://arxiv.org/abs/2403.14403](https://arxiv.org/abs/2403.14403)

    通过新颖的自适应QA框架，根据查询的复杂度动态选择适合的检索增强大型语言模型策略，提高了回答准确性。

    

    检索增强大型语言模型（LLMs）将外部知识库中的非参数知识纳入LLMs，已成为提高多种任务中回答准确性的有希望方法，如问答（QA）。然而，尽管有各种方法处理不同复杂度的查询，但它们要么处理简单查询时产生不必要的计算开销，要么未能充分解决复杂的多步查询；然而，并非所有用户请求都只能划分为简单或复杂类别中的一种。在这项研究中，我们提出了一种新颖的自适应QA框架，该框架可以动态选择从最简单到最复杂的（检索增强）LLMs策略，这取决于查询的复杂度。此外，这个选择过程是通过一个分类器实现的，该分类器是一个较小的LM，训练以预测传入查询的复杂度级别。

    arXiv:2403.14403v1 Announce Type: cross  Abstract: Retrieval-Augmented Large Language Models (LLMs), which incorporate the non-parametric knowledge from external knowledge bases into LLMs, have emerged as a promising approach to enhancing response accuracy in several tasks, such as Question-Answering (QA). However, even though there are various approaches dealing with queries of different complexities, they either handle simple queries with unnecessary computational overhead or fail to adequately address complex multi-step queries; yet, not all user requests fall into only one of the simple or complex categories. In this work, we propose a novel adaptive QA framework, that can dynamically select the most suitable strategy for (retrieval-augmented) LLMs from the simplest to the most sophisticated ones based on the query complexity. Also, this selection process is operationalized with a classifier, which is a smaller LM trained to predict the complexity level of incoming queries with aut
    
[^109]: ROUTERBENCH：用于多LLM路由系统的基准测试

    ROUTERBENCH: A Benchmark for Multi-LLM Routing System

    [https://arxiv.org/abs/2403.12031](https://arxiv.org/abs/2403.12031)

    提出了ROUTERBENCH，一个用于评估LLM路由系统性能的基准测试框架，包括超过405k推理结果的数据集，以支持路由策略的开发。

    

    随着大型语言模型（LLMs）的应用范围不断扩大，对有效的服务解决方案的需求变得日益关键。尽管LLMs具有多样性，但没有单一模型可以最优地解决所有任务和应用，特别是在平衡性能和成本之间。为了弥补这一限制，发展了LLM路由系统，这些系统结合了各种模型的优势，以克服单个LLMs的约束。然而，缺乏用于评估LLM路由器性能的标准化基准测试，阻碍了这一领域的进展。为弥合这一差距，我们提出了ROUTERBENCH，这是一个新颖的评估框架，旨在系统评估LLM路由系统的功效，以及一个包括来自代表性LLMs的超过405k推理结果的全面数据集，以支持路由策略的开发。我们进一步提出了一个LLM路由的理论框架，以及...

    arXiv:2403.12031v1 Announce Type: cross  Abstract: As the range of applications for Large Language Models (LLMs) continues to grow, the demand for effective serving solutions becomes increasingly critical. Despite the versatility of LLMs, no single model can optimally address all tasks and applications, particularly when balancing performance with cost. This limitation has led to the development of LLM routing systems, which combine the strengths of various models to overcome the constraints of individual LLMs. Yet, the absence of a standardized benchmark for evaluating the performance of LLM routers hinders progress in this area. To bridge this gap, we present ROUTERBENCH, a novel evaluation framework designed to systematically assess the efficacy of LLM routing systems, along with a comprehensive dataset comprising over 405k inference outcomes from representative LLMs to support the development of routing strategies. We further propose a theoretical framework for LLM routing, and del
    
[^110]: 通向统一多模式个性化：大型视觉语言模型用于生成推荐和更多领域

    Towards Unified Multi-Modal Personalization: Large Vision-Language Models for Generative Recommendation and Beyond

    [https://arxiv.org/abs/2403.10667](https://arxiv.org/abs/2403.10667)

    本文旨在建立一个统一的多模态个性化系统(UniMP)，有效利用多模态数据同时消除与任务和模态特定定制相关的复杂性。

    

    开发一个能够有效利用异构资源并满足各种个性化需求的通用模型一直是社区渴望的目标。我们日常的选择，尤其是在时尚和零售等领域，很大程度上受多模态数据的影响，比如图片和文本描述。这些模态不仅提供直观的指导，还迎合个性化用户偏好。然而，当前主流的个性化方法主要聚焦于基于ID或文本的推荐问题，未能理解涵盖各种任务或模态的信息。本文的目标是建立一个统一的多模态个性化系统(UniMP)，能够有效利用多模态数据，同时消除与任务和模态特定定制相关的复杂性。我们认为基础生成建模的进展提供了

    arXiv:2403.10667v1 Announce Type: cross  Abstract: Developing a universal model that can effectively harness heterogeneous resources and respond to a wide range of personalized needs has been a longstanding community aspiration. Our daily choices, especially in domains like fashion and retail, are substantially shaped by multi-modal data, such as pictures and textual descriptions. These modalities not only offer intuitive guidance but also cater to personalized user preferences. However, the predominant personalization approaches mainly focus on the ID or text-based recommendation problem, failing to comprehend the information spanning various tasks or modalities. In this paper, our goal is to establish a Unified paradigm for Multi-modal Personalization systems (UniMP), which effectively leverages multi-modal data while eliminating the complexities associated with task- and modality-specific customization. We argue that the advancements in foundational generative modeling have provided
    
[^111]: 开放图谱：大规模室外环境中的开放词汇分层3D图表示

    OpenGraph: Open-Vocabulary Hierarchical 3D Graph Representation in Large-Scale Outdoor Environments

    [https://arxiv.org/abs/2403.09412](https://arxiv.org/abs/2403.09412)

    开放图谱是针对大规模室外环境设计的开放词汇分层图结构，旨在解决现有地图受限于室内场景和VLM特征的问题，通过视觉图像提取实例和标题，并加强文字推理。

    

    具有复杂语义的环境地图对于促进机器人和人类之间的无缝交互至关重要，使它们能够有效地执行各种任务。开放词汇地图，由视觉-语言模型（VLM）驱动，具有固有优势，包括多模态检索和开放类别。然而，现有的开放词汇地图受限于封闭的室内场景和VLM特征，从而降低了它们的可用性和推理能力。此外，缺乏拓扑关系进一步使得对特定实例的准确查询变得复杂。在这项工作中，我们提出了OpenGraph，这是一种为大规模室外环境设计的开放词汇分层图结构表示。OpenGraph首先利用2D基础模型从视觉图像中提取实例及其标题，并对标题进行特征编码以增强文字推理。随后，3D进

    arXiv:2403.09412v1 Announce Type: cross  Abstract: Environment maps endowed with sophisticated semantics are pivotal for facilitating seamless interaction between robots and humans, enabling them to effectively carry out various tasks. Open-vocabulary maps, powered by Visual-Language models (VLMs), possess inherent advantages, including multimodal retrieval and open-set classes. However, existing open-vocabulary maps are constrained to closed indoor scenarios and VLM features, thereby diminishing their usability and inference capabilities. Moreover, the absence of topological relationships further complicates the accurate querying of specific instances. In this work, we propose OpenGraph, a representation of open-vocabulary hierarchical graph structure designed for large-scale outdoor environments. OpenGraph initially extracts instances and their captions from visual images using 2D foundation models, encoding the captions with features to enhance textual reasoning. Subsequently, 3D in
    
[^112]: FluoroSAM: 用于X光图像分割的语言对齐基础模型

    FluoroSAM: A Language-aligned Foundation Model for X-ray Image Segmentation

    [https://arxiv.org/abs/2403.08059](https://arxiv.org/abs/2403.08059)

    FluoroSAM是用于X光图像的分割的语言对齐基础模型，提供了一种在X光成像领域具有广泛适用性的自动图像分析工具。

    

    自动X光图像分割将加速诊断和介入精准医学领域的研究和发展。先前的研究已经提出了适用于解决特定图像分析问题的特定任务模型，但这些模型的效用受限于特定任务领域，要拓展到更广泛的应用则需要额外的数据、标签和重新训练工作。最近，基础模型（FMs） - 训练在大量高度变化数据上的机器学习模型因此使得广泛适用性成为可能 - 已经成为自动图像分析的有希望的工具。现有的用于医学图像分析的FMs聚焦于对象被明显可见边界清晰定义的场景和模式，如内窥镜手术工具分割。相比之下，X光成像通常没有提供这种清晰的边界或结构先验。在X光图像形成期间，复杂的三维

    arXiv:2403.08059v1 Announce Type: cross  Abstract: Automated X-ray image segmentation would accelerate research and development in diagnostic and interventional precision medicine. Prior efforts have contributed task-specific models capable of solving specific image analysis problems, but the utility of these models is restricted to their particular task domain, and expanding to broader use requires additional data, labels, and retraining efforts. Recently, foundation models (FMs) -- machine learning models trained on large amounts of highly variable data thus enabling broad applicability -- have emerged as promising tools for automated image analysis. Existing FMs for medical image analysis focus on scenarios and modalities where objects are clearly defined by visually apparent boundaries, such as surgical tool segmentation in endoscopy. X-ray imaging, by contrast, does not generally offer such clearly delineated boundaries or structure priors. During X-ray image formation, complex 3D
    
[^113]: 使用循环神经网络在3D点云中对物体进行分类：一种GRU LSTM混合方法

    Classifying Objects in 3D Point Clouds Using Recurrent Neural Network: A GRU LSTM Hybrid Approach

    [https://arxiv.org/abs/2403.05950](https://arxiv.org/abs/2403.05950)

    本文提出了一种使用GRU和LSTM混合方法进行3D点云中物体分类的深度学习策略，取得了高准确率，并在对多个类别的数据集中取得优异表现。

    

    在自主导航和增强/虚拟现实场景等多个应用中，准确对3D点云中的物体进行分类是一个重要问题，已成为研究热点。本文提出了一种用于增强现实中的3D物体分类的深度学习策略。该方法是GRU和LSTM的组合。LSTM网络能够很好地学习长期依赖关系，但由于门数量较多，训练时间较长；另一方面，GRU网络性能较弱于LSTM，但其训练速度远高于LSTM，这是由于其门数量较少。该方法利用了这两种网络的速度和准确性的组合。提出的方法在包含八个类别（未标记、人造地形、自然地形、高植被、低植被、建筑、硬景观）的4,499,0641个点数据集中实现了0.99的准确率。

    arXiv:2403.05950v1 Announce Type: cross  Abstract: Accurate classification of objects in 3D point clouds is a significant problem in several applications, such as autonomous navigation and augmented/virtual reality scenarios, which has become a research hot spot. In this paper, we presented a deep learning strategy for 3D object classification in augmented reality. The proposed approach is a combination of the GRU and LSTM. LSTM networks learn longer dependencies well, but due to the number of gates, it takes longer to train; on the other hand, GRU networks have a weaker performance than LSTM, but their training speed is much higher than GRU, which is The speed is due to its fewer gates. The proposed approach used the combination of speed and accuracy of these two networks. The proposed approach achieved an accuracy of 0.99 in the 4,499,0641 points dataset, which includes eight classes (unlabeled, man-made terrain, natural terrain, high vegetation, low vegetation, buildings, hardscape,
    
[^114]: OpenGraph: 迈向开放图基础模型

    OpenGraph: Towards Open Graph Foundation Models

    [https://arxiv.org/abs/2403.01121](https://arxiv.org/abs/2403.01121)

    该论文旨在通过开发一个通用图基础模型，以解决现有图神经网络在泛化到与训练数据显著不同的未见图数据时遇到的困难。

    

    arXiv:2403.01121v1 公告类型: 跨交互   摘要: 图学习已成为解释和利用各领域的关系数据的不可或缺部分，从推荐系统到社交网络分析。在这种背景下，各种GNN已经成为编码图的结构信息的有希望的方法论，通过有效地捕捉图的潜在结构，这些GNN已经展示出在增强图学习任务性能方面的巨大潜力，例如链接预测和节点分类。然而，尽管取得了成功，一个显著的挑战仍然存在: 这些先进方法通常在将显著不同于训练实例的未见图数据泛化时遇到困难。在这项工作中，我们的目标是通过开发一个通用图基础模型来推进图学习范式。该模型旨在理解多样图数据中存在的复杂拓扑模式，使其在零-shot情况下表现出色。

    arXiv:2403.01121v1 Announce Type: cross  Abstract: Graph learning has become indispensable for interpreting and harnessing relational data in diverse fields, ranging from recommendation systems to social network analysis. In this context, a variety of GNNs have emerged as promising methodologies for encoding the structural information of graphs. By effectively capturing the graph's underlying structure, these GNNs have shown great potential in enhancing performance in graph learning tasks, such as link prediction and node classification. However, despite their successes, a significant challenge persists: these advanced methods often face difficulties in generalizing to unseen graph data that significantly differs from the training instances. In this work, our aim is to advance the graph learning paradigm by developing a general graph foundation model. This model is designed to understand the complex topological patterns present in diverse graph data, enabling it to excel in zero-shot g
    
[^115]: MemoNav：视觉导航的工作记忆模型

    MemoNav: Working Memory Model for Visual Navigation

    [https://arxiv.org/abs/2402.19161](https://arxiv.org/abs/2402.19161)

    MemoNav提出了一种用于图像目标导航的新型记忆模型，通过三种导航记忆类型和遗忘模块提高了导航性能。

    

    图像目标导航是一项具有挑战性的任务，需要一个agent在陌生环境中导航到由图像指示的目标。现有方法利用不同的场景记忆存在着效率低下的探索问题，因为它们利用了所有历史观察结果进行决策，而没有考虑与目标相关的部分。为了解决这一限制，我们提出了MemoNav，一种新颖的用于图像目标导航的记忆模型，它利用了类似工作记忆的流程来提高导航性能。具体来说，我们采用了三种导航记忆类型。地图上的节点特征存储在短期记忆（STM）中，因为这些特征是动态更新的。然后，一个遗忘模块保留信息量大的STM部分以提高效率。我们还引入了长期记忆（LTM）来学习全局场景表示，逐渐聚合STM特征。随后，一个图注意力模块对重新...

    arXiv:2402.19161v1 Announce Type: cross  Abstract: Image-goal navigation is a challenging task that requires an agent to navigate to a goal indicated by an image in unfamiliar environments. Existing methods utilizing diverse scene memories suffer from inefficient exploration since they use all historical observations for decision-making without considering the goal-relevant fraction. To address this limitation, we present MemoNav, a novel memory model for image-goal navigation, which utilizes a working memory-inspired pipeline to improve navigation performance. Specifically, we employ three types of navigation memory. The node features on a map are stored in the short-term memory (STM), as these features are dynamically updated. A forgetting module then retains the informative STM fraction to increase efficiency. We also introduce long-term memory (LTM) to learn global scene representations by progressively aggregating STM features. Subsequently, a graph attention module encodes the re
    
[^116]: 基于GPU的LTL学习

    LTL learning on GPUs

    [https://arxiv.org/abs/2402.12373](https://arxiv.org/abs/2402.12373)

    实现了首个基于GPU的LTL学习器，使用新颖的枚举式程序合成，性能显著优于现有最先进的学习器，处理跟踪至少多2048倍，速度平均快46倍，并且引入了具有$O(\log n)$时间复杂度的无分支LTL semantics。

    

    线性时序逻辑（LTL）在工业验证中被广泛使用。LTL公式可以从跟踪中学习。扩展LTL公式学习是一个待解决的问题。我们实现了第一种基于GPU的LTL学习器，使用了一种新颖的枚举式程序合成。该学习器是完备和正确的。我们的基准测试表明，它处理的跟踪至少比现有最先进的学习器多2048倍，平均至少快46倍。这是通过诸多方法实现的，包括具有$O(\log n)$时间复杂度的新型无分支LTL语义，其中$n$是跟踪长度，而以前的实现是$O(n^2)$或更糟（假设按位布尔运算和按2的幂移位具有单位成本——这是对现代处理器的现实假设）。

    arXiv:2402.12373v1 Announce Type: cross  Abstract: Linear temporal logic (LTL) is widely used in industrial verification. LTL formulae can be learned from traces. Scaling LTL formula learning is an open problem. We implement the first GPU-based LTL learner using a novel form of enumerative program synthesis. The learner is sound and complete. Our benchmarks indicate that it handles traces at least 2048 times more numerous, and on average at least 46 times faster than existing state-of-the-art learners. This is achieved with, among others, novel branch-free LTL semantics that has $O(\log n)$ time complexity, where $n$ is trace length, while previous implementations are $O(n^2)$ or worse (assuming bitwise boolean operations and shifts by powers of 2 have unit costs -- a realistic assumption on modern processors).
    
[^117]: HU在SemEval-2024任务8A中的表现：对比学习能否学习嵌入以检测机器生成的文本？

    HU at SemEval-2024 Task 8A: Can Contrastive Learning Learn Embeddings to Detect Machine-Generated Text?

    [https://arxiv.org/abs/2402.11815](https://arxiv.org/abs/2402.11815)

    提出了一种基于对比学习的单一模型，用较少的参数实现与基线相当的机器生成文本检测性能

    

    这篇论文描述了我们为SemEval-2024任务8“多生成器、多领域和多语言黑匣子机器生成文本检测”开发的系统。由于大型语言模型（LLM）在虚假文本生成、网络钓鱼、考试作弊甚至抄袭版权材料中的使用，机器生成文本一直是主要关注的问题之一。许多系统已经被开发用于检测机器生成的文本。然而，这些系统中的大部分依赖于文本生成模型，这是一个在实际场景中不切实际的限制，因为通常不可能知道用户用于文本生成的具体模型。在这项工作中，我们提出了基于对比学习的单一模型，其使用基线参数的大约40%（149M比355M），但在测试数据集上表现出了可比的性能（在137个参与者中排名第21）。我们的关键发现是，即使没有多个模型的集成，

    arXiv:2402.11815v1 Announce Type: cross  Abstract: This paper describes our system developed for SemEval-2024 Task 8, "Multigenerator, Multidomain, and Multilingual Black-Box Machine-Generated Text Detection." Machine-generated texts have been one of the main concerns due to the use of large language models (LLM) in fake text generation, phishing, cheating in exams, or even plagiarizing copyright materials. A lot of systems have been developed to detect machine-generated text. Nonetheless, the majority of these systems rely on the text-generating model, a limitation that is impractical in real-world scenarios, as it's often impossible to know which specific model the user has used for text generation. In this work, we propose a single model based on contrastive learning, which uses ~40% of the baseline's parameters (149M vs. 355M) but shows a comparable performance on the test dataset (21st out of 137 participants). Our key finding is that even without an ensemble of multiple models, a
    
[^118]: 英语和德语的句法语言变化：度量、解析器和趋同

    Syntactic Language Change in English and German: Metrics, Parsers, and Convergences

    [https://arxiv.org/abs/2402.11549](https://arxiv.org/abs/2402.11549)

    本文研究英语和德语句法语言变化趋势，使用议会辩论语料库，探讨了句法依存距离最小化及基于树图属性的15个度量标准，揭示了现代解析器在这种变化中的影响。

    

    许多研究表明，人类语言往往会优化语言结构以降低复杂性，增加交流效率。句法依存距离衡量了相关词汇之间的线性距离，通常被认为是语言处理困难和工作记忆负荷的关键指标。本文研究了英语和德语句法语言变化的历时趋势，使用了过去大约160年间的议会辩论语料库。我们基于5个依存句法解析器的观察结果，包括广泛使用的Stanford CoreNLP以及其他4个更新的替代方案。我们的句法语言变化分析超越了线性依存距离，探讨了与依存距离最小化（DDM）相关的15个度量标准，或者基于树图属性，比如树高和度变异。尽管我们有证据表明，最近基于现代树库训练的解析器并未受到重大影响。

    arXiv:2402.11549v1 Announce Type: cross  Abstract: Many studies have shown that human languages tend to optimize for lower complexity and increased communication efficiency. Syntactic dependency distance, which measures the linear distance between dependent words, is often considered a key indicator of language processing difficulty and working memory load. The current paper looks at diachronic trends in syntactic language change in both English and German, using corpora of parliamentary debates from the last c. 160 years. We base our observations on five dependency parsers, including the widely used Stanford CoreNLP as well as 4 newer alternatives. Our analysis of syntactic language change goes beyond linear dependency distance and explores 15 metrics relevant to dependency distance minimization (DDM) and/or based on tree graph properties, such as the tree height and degree variance. Even though we have evidence that recent parsers trained on modern treebanks are not heavily affected 
    
[^119]: Brant-2：脑信号基础模型

    Brant-2: Foundation Model for Brain Signals

    [https://arxiv.org/abs/2402.10251](https://arxiv.org/abs/2402.10251)

    Brant-2是脑信号领域最大的基础模型，相比于Brant，它不仅对数据变化和建模尺度具有稳健性，还能适用于更广泛范围的脑神经数据。

    

    基础模型受益于在大量未标记数据上进行预训练，并且在少量标记数据的情况下能够在各种应用中表现出色。这种模型在分析脑信号方面特别有效，因为这一领域涵盖了众多应用场景，并且进行大规模注释是成本高昂的。在这项工作中，我们提出了脑信号领域最大的基础模型，Brant-2。与用于颅内神经信号的基础模型Brant相比，Brant-2不仅对数据变化和建模尺度表现出稳健性，而且可以应用于更广泛范围的脑神经数据。通过在大量任务上进行实验，我们展示了Brant-2对脑信号中各种应用场景的适应性。进一步分析揭示了Brant-2的可扩展性，验证了每个组件的有效性，并展示了我们模型保持的能力。

    arXiv:2402.10251v1 Announce Type: cross  Abstract: Foundational models benefit from pre-training on large amounts of unlabeled data and enable strong performance in a wide variety of applications with a small amount of labeled data. Such models can be particularly effective in analyzing brain signals, as this field encompasses numerous application scenarios, and it is costly to perform large-scale annotation. In this work, we present the largest foundation model in brain signals, Brant-2. Compared to Brant, a foundation model designed for intracranial neural signals, Brant-2 not only exhibits robustness towards data variations and modeling scales but also can be applied to a broader range of brain neural data. By experimenting on an extensive range of tasks, we demonstrate that Brant-2 is adaptive to various application scenarios in brain signals. Further analyses reveal the scalability of the Brant-2, validate each component's effectiveness, and showcase our model's ability to maintai
    
[^120]: PRDP：大规模扩散模型的近端奖励差异预测用于奖励微调

    PRDP: Proximal Reward Difference Prediction for Large-Scale Reward Finetuning of Diffusion Models

    [https://arxiv.org/abs/2402.08714](https://arxiv.org/abs/2402.08714)

    本研究提出了PRDP方法，通过近端奖励差异预测实现了稳定的黑盒奖励微调扩散模型，能够在大规模提示数据集上进行训练，并且具有更好的训练稳定性。

    

    奖励微调已成为将基础模型与下游目标对齐的一种有前途的方法。在语言领域，使用强化学习（RL）来最大化反映人类偏好的奖励已取得了显著的成功。然而，在视觉领域，现有的基于RL的奖励微调方法在大规模训练中存在不稳定性，使它们无法推广到复杂的、未知的提示。在本文中，我们提出了近端奖励差异预测（PRDP），首次在超过100K个提示的大规模提示数据集上实现了稳定的黑盒奖励微调扩散模型。我们的主要创新是奖励差异预测（RDP）目标，该目标与RL目标具有相同的最优解，同时享受更好的训练稳定性。

    arXiv:2402.08714v1 Announce Type: cross Abstract: Reward finetuning has emerged as a promising approach to aligning foundation models with downstream objectives. Remarkable success has been achieved in the language domain by using reinforcement learning (RL) to maximize rewards that reflect human preference. However, in the vision domain, existing RL-based reward finetuning methods are limited by their instability in large-scale training, rendering them incapable of generalizing to complex, unseen prompts. In this paper, we propose Proximal Reward Difference Prediction (PRDP), enabling stable black-box reward finetuning for diffusion models for the first time on large-scale prompt datasets with over 100K prompts. Our key innovation is the Reward Difference Prediction (RDP) objective that has the same optimal solution as the RL objective while enjoying better training stability. Specifically, the RDP objective is a supervised regression objective that tasks the diffusion model with pred
    
[^121]: 重新构想指挥与控制

    Re-Envisioning Command and Control

    [https://arxiv.org/abs/2402.07946](https://arxiv.org/abs/2402.07946)

    重新构想的论文提出了未来指挥与控制（C2）决策需要面对更复杂和挑战性的环境，因此提出了基于人工智能系统与人类强有力伙伴关系的未来C2的愿景。这个愿景的核心是优化C2操作流程，保持协同努力，发展自适应的集体知识系统。

    

    未来的战争将要求在更复杂、快节奏、不结构化和极具挑战性的环境中进行指挥与控制（C2）决策。C2将因被拒绝、退化、间歇和有限的通信以及需要考虑到多个作战领域中的许多数据流而变得更加复杂。然而，当前的C2实践——源自工业时代而非新兴的智能时代——是线性的且耗时。而且，这些方法可能无法在未来战场上与对手保持优势。为了应对这些挑战，我们提出了一种基于人工智能（AI）系统与人类之间强有力伙伴关系的未来C2愿景。这个未来愿景体现在三个运营影响上：优化C2操作流程，保持协同努力，以及发展自适应的集体知识系统。本文阐述了所设想的未来指挥与控制的愿景。

    Future warfare will require Command and Control (C2) decision-making to occur in more complex, fast-paced, ill-structured, and demanding conditions. C2 will be further complicated by operational challenges such as Denied, Degraded, Intermittent, and Limited (DDIL) communications and the need to account for many data streams, potentially across multiple domains of operation. Yet, current C2 practices -- which stem from the industrial era rather than the emerging intelligence era -- are linear and time-consuming. Critically, these approaches may fail to maintain overmatch against adversaries on the future battlefield. To address these challenges, we propose a vision for future C2 based on robust partnerships between humans and artificial intelligence (AI) systems. This future vision is encapsulated in three operational impacts: streamlining the C2 operations process, maintaining unity of effort, and developing adaptive collective knowledge systems. This paper illustrates the envisaged fu
    
[^122]: 可扩展互动式机器学习用于未来指挥与控制

    Scalable Interactive Machine Learning for Future Command and Control

    [https://arxiv.org/abs/2402.06501](https://arxiv.org/abs/2402.06501)

    未来战争将需要指挥与控制（C2）人员在复杂且潜在模糊的情况下以更短的时间内做出决策。本论文通过利用互动式机器学习方法，结合人工智能和人类智能，以提高C2运作的适应性和效率。

    

    未来战争将需要指挥与控制（C2）人员在复杂且潜在模糊的情况下以更短的时间内做出决策。鉴于需要强大的决策过程和决策支持工具，人工智能和人类智能的集成具有革命性地改变C2运作流程的潜力，以确保在快速变化的操作环境中的适应性和效率。我们提议利用最近在互动式机器学习方面取得的突破，人类可以与机器学习算法合作以指导机器学习算法的行为。本文确定了目前科技发展中存在的几个差距，未来的工作应该解决这些差距，以扩展这些方法在复杂的C2环境中发挥作用。特别是，我们描述了三个研究重点领域，共同旨在实现可扩展的互动式机器学习（SIML）：1）开发人工智能与人类交互算法以实现协同规划。

    Future warfare will require Command and Control (C2) personnel to make decisions at shrinking timescales in complex and potentially ill-defined situations. Given the need for robust decision-making processes and decision-support tools, integration of artificial and human intelligence holds the potential to revolutionize the C2 operations process to ensure adaptability and efficiency in rapidly changing operational environments. We propose to leverage recent promising breakthroughs in interactive machine learning, in which humans can cooperate with machine learning algorithms to guide machine learning algorithm behavior. This paper identifies several gaps in state-of-the-art science and technology that future work should address to extend these approaches to function in complex C2 contexts. In particular, we describe three research focus areas that together, aim to enable scalable interactive machine learning (SIML): 1) developing human-AI interaction algorithms to enable planning in co
    
[^123]: COA-GPT：用于军事行动中加速行动方案开发的生成式预训练变压器

    COA-GPT: Generative Pre-trained Transformers for Accelerated Course of Action Development in Military Operations

    [https://arxiv.org/abs/2402.01786](https://arxiv.org/abs/2402.01786)

    COA-GPT是一种利用大型语言模型快速高效生成有效行动方案的算法，它融合了军事学说和领域专业知识，并在军事游戏中的实验中展示了其快速生成战略合理COAs的优势。

    

    军事行动中行动方案（COAs）的开发传统上是一个耗时且复杂的过程。针对这一挑战，本研究介绍了COA-GPT，一种利用大型语言模型（LLMs）快速高效生成有效COAs的新算法。COA-GPT通过上下文学习将军事学说和领域专业知识融入到LLMs中，允许指挥官输入任务信息（包括文本和图像格式），并获得与战略对齐的COAs以供审查和批准。独特的是，COA-GPT不仅加速了COA的开发，在几秒钟内生成初始COAs，还能根据指挥官的反馈实时精细化改进。本研究在《星际争霸II》游戏的军事相关场景中评估了COA-GPT，将其性能与最先进的强化学习算法进行了比较。我们的结果表明COA-GPT在更快生成战略合理的COAs方面具有优势。

    The development of Courses of Action (COAs) in military operations is traditionally a time-consuming and intricate process. Addressing this challenge, this study introduces COA-GPT, a novel algorithm employing Large Language Models (LLMs) for rapid and efficient generation of valid COAs. COA-GPT incorporates military doctrine and domain expertise to LLMs through in-context learning, allowing commanders to input mission information - in both text and image formats - and receive strategically aligned COAs for review and approval. Uniquely, COA-GPT not only accelerates COA development, producing initial COAs within seconds, but also facilitates real-time refinement based on commander feedback. This work evaluates COA-GPT in a military-relevant scenario within a militarized version of the StarCraft II game, comparing its performance against state-of-the-art reinforcement learning algorithms. Our results demonstrate COA-GPT's superiority in generating strategically sound COAs more swiftly, 
    
[^124]: HQ-VAE：具有变分贝叶斯的分层离散表示学习

    HQ-VAE: Hierarchical Discrete Representation Learning with Variational Bayes

    [https://arxiv.org/abs/2401.00365](https://arxiv.org/abs/2401.00365)

    HQ-VAE提出了一种统一框架，利用变分贝叶斯在分层结构中随机学习离散表示，解决了传统VQ-VAE中的码书/层坍塌问题。

    

    向量量化（VQ）是一种确定性学习具有离散码书表示的特征的技术。通常通过变分自动编码模型 VQ-VAE 来执行，可以进一步扩展到分层结构以进行高保真重建。然而，VQ-VAE 的这种分层扩展经常受到码书/层坍塌问题的困扰，其中码书未被有效地用来表达数据，从而降低重建精度。为了缓解这个问题，我们提出了一个新颖的统一框架，在变分贝叶斯框架的基础上随机学习分层离散表示，称为分层量化变分自动编码器（HQ-VAE）。

    arXiv:2401.00365v2 Announce Type: replace-cross  Abstract: Vector quantization (VQ) is a technique to deterministically learn features with discrete codebook representations. It is commonly performed with a variational autoencoding model, VQ-VAE, which can be further extended to hierarchical structures for making high-fidelity reconstructions. However, such hierarchical extensions of VQ-VAE often suffer from the codebook/layer collapse issue, where the codebook is not efficiently used to express the data, and hence degrades reconstruction accuracy. To mitigate this problem, we propose a novel unified framework to stochastically learn hierarchical discrete representation on the basis of the variational Bayes framework, called hierarchically quantized variational autoencoder (HQ-VAE). HQ-VAE naturally generalizes the hierarchical variants of VQ-VAE, such as VQ-VAE-2 and residual-quantized VAE (RQ-VAE), and provides them with a Bayesian training scheme. Our comprehensive experiments on im
    
[^125]: 相似的实体是否具有相似的嵌入？

    Do Similar Entities have Similar Embeddings?

    [https://arxiv.org/abs/2312.10370](https://arxiv.org/abs/2312.10370)

    本文挑战了实体相似性在图中在嵌入空间中自然反映的主流假设，通过进行广泛的实验来衡量这种关系。

    

    为了进行链接预测而开发的知识图嵌入模型（KGEMs）学习知识图中实体的向量表示，即嵌入。一个普遍的默认假设是KGE实体相似性假设，即这些KGEMs在它们的嵌入空间中保留图的结构，即将相似的实体放在图中彼此靠近。这种理想的性质使得KGEMs在推荐系统或药物再利用等下游任务中被广泛使用。然而，实体的相似性与嵌入空间中的相似性之间的关系很少被正式评估。通常，KGEMs是基于其唯一的链接预测能力进行评估的，使用类似Hits@K或Mean Rank的排名指标。本文质疑了图中的实体相似性在嵌入空间中天然反映这一流行假设。因此，我们进行了大量实验来衡量

    arXiv:2312.10370v2 Announce Type: replace  Abstract: Knowledge graph embedding models (KGEMs) developed for link prediction learn vector representations for entities in a knowledge graph, known as embeddings. A common tacit assumption is the KGE entity similarity assumption, which states that these KGEMs retain the graph's structure within their embedding space, \textit{i.e.}, position similar entities within the graph close to one another. This desirable property make KGEMs widely used in downstream tasks such as recommender systems or drug repurposing. Yet, the relation of entity similarity and similarity in the embedding space has rarely been formally evaluated. Typically, KGEMs are assessed based on their sole link prediction capabilities, using ranked-based metrics such as Hits@K or Mean Rank. This paper challenges the prevailing assumption that entity similarity in the graph is inherently mirrored in the embedding space. Therefore, we conduct extensive experiments to measure the 
    
[^126]: 开放数据表：面向开放数据集和负责任人工智能评估的机器可读文档

    Open Datasheets: Machine-readable Documentation for Open Datasets and Responsible AI Assessments

    [https://arxiv.org/abs/2312.06153](https://arxiv.org/abs/2312.06153)

    本文介绍了一种面向开放数据集和负责任人工智能评估的机器可读文档框架，旨在提高数据集的可理解性和可用性，简化数据集评估过程，促进更可靠的数据应用，从而培育更负责任和可信赖的人工智能系统。

    

    本文介绍了一种无代码的、面向开放数据集的机器可读文档框架，重点关注负责任人工智能（RAI）考虑因素。该框架旨在提高开放数据集的可理解性和可用性，促进更容易地发现和使用数据集，更好地理解内容和上下文，以及评估数据集的质量和准确性。所提出的框架旨在简化数据集的评估，帮助研究人员、数据科学家和其他开放数据用户快速识别符合其需求和组织政策或法规的数据集。论文还讨论了框架的实施，并提出了最大化其潜力的建议。预期该框架将增强在研究和决策中使用的数据的质量和可靠性，促进更负责任、可信赖的人工智能系统的发展。

    arXiv:2312.06153v2 Announce Type: replace-cross  Abstract: This paper introduces a no-code, machine-readable documentation framework for open datasets, with a focus on responsible AI (RAI) considerations. The framework aims to improve comprehensibility, and usability of open datasets, facilitating easier discovery and use, better understanding of content and context, and evaluation of dataset quality and accuracy. The proposed framework is designed to streamline the evaluation of datasets, helping researchers, data scientists, and other open data users quickly identify datasets that meet their needs and organizational policies or regulations. The paper also discusses the implementation of the framework and provides recommendations to maximize its potential. The framework is expected to enhance the quality and reliability of data used in research and decision-making, fostering the development of more responsible and trustworthy AI systems.
    
[^127]: MMM：生成式遮蔽运动模型

    MMM: Generative Masked Motion Model

    [https://arxiv.org/abs/2312.03596](https://arxiv.org/abs/2312.03596)

    MMM 提出了一种基于遮蔽运动模型的新颖运动生成范式，通过运动标记器和条件遮蔽运动变换器，在实时性能、高保真度和运动可编辑性之间取得平衡。

    

    最近在使用扩散和自回归模型进行文本到运动生成方面取得了一些进展，显示出了良好的结果。然而，这些模型往往在实时性能、高保真度和运动可编辑性之间存在权衡。为了解决这一问题，我们引入了MMM，一种基于遮蔽运动模型的新颖而简单的运动生成范式。MMM由两个关键组件组成：（1）运动标记器，将3D人体运动转化为潜在空间中的一系列离散标记，以及（2）条件遮蔽运动变换器，学习预测在预先计算的文本标记的条件下随机遮蔽的运动标记。通过在所有方向上关注运动和文本标记，MMM明确地捕获了运动标记之间的固有依赖关系以及运动和文本标记之间的语义映射。在推断过程中，这允许对与fi高度一致的多个运动标记进行并行和迭代解码。

    arXiv:2312.03596v2 Announce Type: replace-cross  Abstract: Recent advances in text-to-motion generation using diffusion and autoregressive models have shown promising results. However, these models often suffer from a trade-off between real-time performance, high fidelity, and motion editability. To address this gap, we introduce MMM, a novel yet simple motion generation paradigm based on Masked Motion Model. MMM consists of two key components: (1) a motion tokenizer that transforms 3D human motion into a sequence of discrete tokens in latent space, and (2) a conditional masked motion transformer that learns to predict randomly masked motion tokens, conditioned on the pre-computed text tokens. By attending to motion and text tokens in all directions, MMM explicitly captures inherent dependency among motion tokens and semantic mapping between motion and text tokens. During inference, this allows parallel and iterative decoding of multiple motion tokens that are highly consistent with fi
    
[^128]: TimeChat：一种面向长视频理解的时间敏感多模态大型语言模型

    TimeChat: A Time-sensitive Multimodal Large Language Model for Long Video Understanding

    [https://arxiv.org/abs/2312.02051](https://arxiv.org/abs/2312.02051)

    TimeChat是一种时间敏感的多模态大型语言模型，包含时间戳感知帧编码器和滑动视频Q-Former，以实现对长视频进行强大的零-shot时间本地化和推理能力。实验结果表明，在各种视频理解任务上表现出色。

    

    这项工作提出了TimeChat，一种专门为长视频理解设计的时间敏感多模态大型语言模型。 我们的模型包含两个关键的架构贡献：(1)一个时间戳感知帧编码器，将视觉内容与每帧的时间戳绑定在一起；(2)一个滑动视频Q-Former，生成各种长度的视频令牌序列，以适应不同持续时间的视频。此外，我们构建了一个指令调优数据集，涵盖6个任务和总计125K个实例，以进一步提升TimeChat在遵循指令方面的性能。在各种视频理解任务上的实验结果，如密集字幕生成、时间定位和精彩片段检测，展示了TimeChat强大的零-shot时间本地化和推理能力。例如，它在YouCook2上实现了+9.2的F1分数和+2.8的CIDEr，在QVHighlights上实现了+5.8的HIT@1，在Cha上实现了+27.5的R@1（IoU=0.5）。

    arXiv:2312.02051v2 Announce Type: replace-cross  Abstract: This work proposes TimeChat, a time-sensitive multimodal large language model specifically designed for long video understanding. Our model incorporates two key architectural contributions: (1) a timestamp-aware frame encoder that binds visual content with the timestamp of each frame, and (2) a sliding video Q-Former that produces a video token sequence of varying lengths to accommodate videos of various durations. Additionally, we construct an instruction-tuning dataset, encompassing 6 tasks and a total of 125K instances, to further enhance TimeChat's instruction-following performance. Experiment results across various video understanding tasks, such as dense captioning, temporal grounding, and highlight detection, demonstrate TimeChat's strong zero-shot temporal localization and reasoning capabilities. For example, it achieves +9.2 F1 score and +2.8 CIDEr on YouCook2, +5.8 HIT@1 on QVHighlights, and +27.5 R@1 (IoU=0.5) on Cha
    
[^129]: 从 Sim-2-Real 学习可推广的多尺度特征扰动语义分割（MRFP）

    MRFP: Learning Generalizable Semantic Segmentation from Sim-2-Real with Multi-Resolution Feature Perturbation

    [https://arxiv.org/abs/2311.18331](https://arxiv.org/abs/2311.18331)

    提出了一种新颖的多尺度特征扰动技术(MRFP)，通过随机化领域特定的细粒度特征和扰动粗粒度特征的风格来解决从仿真到真实场景语义分割的泛化挑战

    

    深度神经网络在源领域上展现了出色的性能，但由于训练过程中缺乏风格多样性，仅使用单一源领域数据来提高在未知目标领域上的性能仍然是一项具有挑战性的任务。在生成仿真数据成为获取大规模风格多样的真实世界数据的可行替代方案，因为这是一个费力和资金密集型的过程。然而，仿真数据与真实世界数据之间的大量领域特定不一致性对语义分割造成了显著的泛化挑战。在这项工作中，为了缓解这个问题，我们提出了一种新颖的多尺度特征扰动（MRFP）技术，用于使领域特定的细粒度特征随机化，并扰动粗糙特征的风格。我们在各种都市场景分割数据集上的实验结果清楚地表明，随着样式信息的扰动

    arXiv:2311.18331v2 Announce Type: replace-cross  Abstract: Deep neural networks have shown exemplary performance on semantic scene understanding tasks on source domains, but due to the absence of style diversity during training, enhancing performance on unseen target domains using only single source domain data remains a challenging task. Generation of simulated data is a feasible alternative to retrieving large style-diverse real-world datasets as it is a cumbersome and budget-intensive process. However, the large domain-specfic inconsistencies between simulated and real-world data pose a significant generalization challenge in semantic segmentation. In this work, to alleviate this problem, we propose a novel MultiResolution Feature Perturbation (MRFP) technique to randomize domain-specific fine-grained features and perturb style of coarse features. Our experimental results on various urban-scene segmentation datasets clearly indicate that, along with the perturbation of style-informa
    
[^130]: 提示风险控制：大型语言模型负责部署的严格框架

    Prompt Risk Control: A Rigorous Framework for Responsible Deployment of Large Language Models

    [https://arxiv.org/abs/2311.13628](https://arxiv.org/abs/2311.13628)

    提示风险控制是一个轻量级框架，通过严格的信息风险度量族的上限选取提示，帮助减轻大型语言模型负责部署过程中产生意外糟糕响应的风险。

    

    大型语言模型能力的爆炸式增长引发了对如何最好地提示模型执行特定任务的兴趣浪潮。选择一个基于验证集上平均性能的提示可能很诱人，但这可能导致生成出乎意料的糟糕响应，尤其是对于处境最困难的用户。为了减轻这一可能性，我们提出提示风险控制，这是一个轻量级框架，根据信息风险度量族的严格上限选择提示。我们提供了用于产生多种度量上限的方法，包括衡量最坏情况响应和用户群体生成质量不均衡的量，此外，我们扩展了基础统计界定技术，以适应部署中分布变化可能性的情况。在开放式聊天、医学问题等应用上的实验表明了我们方法的有效性。

    arXiv:2311.13628v2 Announce Type: replace-cross  Abstract: The recent explosion in the capabilities of large language models has led to a wave of interest in how best to prompt a model to perform a given task. While it may be tempting to simply choose a prompt based on average performance on a validation set, this can lead to a deployment where unexpectedly poor responses are generated, especially for the worst-off users. To mitigate this prospect, we propose Prompt Risk Control, a lightweight framework for selecting a prompt based on rigorous upper bounds on families of informative risk measures. We offer methods for producing bounds on a diverse set of metrics, including quantities that measure worst-case responses and disparities in generation quality across the population of users. In addition, we extend the underlying statistical bounding techniques to accommodate the possibility of distribution shifts in deployment. Experiments on applications such as open-ended chat, medical que
    
[^131]: PIE-NeRF: 使用 NeRF 进行基于物理的交互弹性动力学

    PIE-NeRF: Physics-based Interactive Elastodynamics with NeRF

    [https://arxiv.org/abs/2311.13099](https://arxiv.org/abs/2311.13099)

    该研究展示了物理学模拟与 NeRF 结合，无需中间形态代理，通过 Q-GMLS 捕捉非线性动力学和大形变，实现了高质量弹性动力学生成，并适应 NeRF 密度场调整最小二乘核，从而高效合成各种高弹性材料的物理逼真动画。

    

    我们展示了物理学模拟与 NeRF 可以无缝集成，用于生成真实物体的高质量弹性动力学。与现有方法不同，我们以无网格的方式离散化非线性超弹性，避免了中间辅助形态代理物如四面体网格或体素网格的必要性。采用二次广义移动最小二乘（Q-GMLS）来捕捉隐式模型上的非线性动态和大形变。这种无网格集成使复杂和共维度形状的多功能模拟成为可能。我们根据 NeRF 密度场自适应地放置最小二乘核，显著降低非线性模拟的复杂性。因此，可以方便地使用我们的方法以交互速率合成各种高弹性材料的物理逼真动画。有关更多信息，请访问我们的项目页面https://fytalo

    arXiv:2311.13099v2 Announce Type: replace-cross  Abstract: We show that physics-based simulations can be seamlessly integrated with NeRF to generate high-quality elastodynamics of real-world objects. Unlike existing methods, we discretize nonlinear hyperelasticity in a meshless way, obviating the necessity for intermediate auxiliary shape proxies like a tetrahedral mesh or voxel grid. A quadratic generalized moving least square (Q-GMLS) is employed to capture nonlinear dynamics and large deformation on the implicit model. Such meshless integration enables versatile simulations of complex and codimensional shapes. We adaptively place the least-square kernels according to the NeRF density field to significantly reduce the complexity of the nonlinear simulation. As a result, physically realistic animations can be conveniently synthesized using our method for a wide range of hyperelastic materials at an interactive rate. For more information, please visit our project page at https://fytalo
    
[^132]: 连续学习：应用与未来路径

    Continual Learning: Applications and the Road Forward

    [https://arxiv.org/abs/2311.11908](https://arxiv.org/abs/2311.11908)

    连续学习是机器学习的子领域，致力于让机器学习模型在新数据上不断学习，而不忘记过去学到的知识。研究揭示了内存限制场景的主导地位，并讨论了连续学习在解决模型编辑、个性化、专业化、设备端学习、快速（重新）训练和强化学习等问题中的作用。

    

    连续学习是机器学习的一个子领域，旨在使机器学习模型能够在新数据上不断学习，通过积累知识而不遗忘过去所学。本研究退一步思考，并提出问题：“为什么首先要关注连续学习？”。我们通过审视近期在四个主要机器学习会议上发表的连续学习论文来铺垫，展示了受内存限制的场景主导了该领域。然后，我们讨论了机器学习中的五个未解问题，尽管乍看起来可能与连续学习无关，但我们展示了连续学习将必然成为它们解决方案的一部分。这些问题包括模型编辑、个性化和专业化、设备端学习、更快的（重新）训练和强化学习。最后，通过比较这些未解问题的期望和当前的假设

    arXiv:2311.11908v3 Announce Type: replace-cross  Abstract: Continual learning is a subfield of machine learning, which aims to allow machine learning models to continuously learn on new data, by accumulating knowledge without forgetting what was learned in the past. In this work, we take a step back, and ask: "Why should one care about continual learning in the first place?". We set the stage by examining recent continual learning papers published at four major machine learning conferences, and show that memory-constrained settings dominate the field. Then, we discuss five open problems in machine learning, and even though they might seem unrelated to continual learning at first sight, we show that continual learning will inevitably be part of their solution. These problems are model editing, personalization and specialization, on-device learning, faster (re-)training and reinforcement learning. Finally, by comparing the desiderata from these unsolved problems and the current assumptio
    
[^133]: 提升布局到图像合成中的对象连贯性

    Enhancing Object Coherence in Layout-to-Image Synthesis

    [https://arxiv.org/abs/2311.10522](https://arxiv.org/abs/2311.10522)

    本文提出了一种新颖的扩散模型，结合全局语义融合和自相似特征增强模块，以引导布局到图像合成中的对象连贯性。

    

    布局到图像合成是一种新兴的条件图像生成技术。它旨在生成复杂场景，用户可以对场景中的对象布局进行精细控制。然而，控制对象连贯性，包括语义连贯性（例如，猫是否看向花朵）和物理连贯性（例如，手和球拍不应错位）仍然具有挑战性。在本文中，我们提出了一种新颖的扩散模型，配备了有效的全局语义融合（GSF）和自相似特征增强模块，以引导该任务的对象连贯性。对于语义连贯性，我们认为图像标题包含丰富信息，可以定义图像中对象之间的语义关系。与其简单地使用标题和生成图像之间的跨注意力，我们提出了一种能同时处理高度相关布局限制和语义连贯性的方法，从而使

    arXiv:2311.10522v4 Announce Type: replace-cross  Abstract: Layout-to-image synthesis is an emerging technique in conditional image generation. It aims to generate complex scenes, where users require fine control over the layout of the objects in a scene. However, it remains challenging to control the object coherence, including semantic coherence (e.g., the cat looks at the flowers or not) and physical coherence (e.g., the hand and the racket should not be misaligned). In this paper, we propose a novel diffusion model with effective global semantic fusion (GSF) and self-similarity feature enhancement modules to guide the object coherence for this task. For semantic coherence, we argue that the image caption contains rich information for defining the semantic relationship within the objects in the images. Instead of simply employing cross-attention between captions and generated images, which addresses the highly relevant layout restriction and semantic coherence separately and thus lea
    
[^134]: MacGyver：大型语言模型是否是创意问题解决者？

    MacGyver: Are Large Language Models Creative Problem Solvers?

    [https://arxiv.org/abs/2311.09682](https://arxiv.org/abs/2311.09682)

    通过创建MACGYVER数据集并与人类比较，研究发现大型语言模型在创意问题解决方面独具挑战性，在知识广度和可行性方面与人类存在独特差异，同时还展示了通过新的提示技术提升大型语言模型的问题解决能力潜力。

    

    我们在一个全新的约束设置中探究了现代大型语言模型的创意问题解决能力。为此，我们创建了MACGYVER，这是一个自动生成的数据集，包含超过1600个特意设计的现实世界问题，旨在引发物体的创新使用，并需要超越常规思维。我们随后向大型语言模型和人类展示我们的数据集，以比较和对比它们的问题解决能力。MACGYVER对这两个群体都具有挑战性，但以独特和互补的方式呈现。例如，人类擅长熟悉的任务，但在特定领域知识上有困难，导致更高的差异。相比之下，大型语言模型暴露于各种专业知识，尝试更广泛的问题，但在提出物理上不可行的行动时失败。最后，我们对大型语言模型进行了详细的错误分析，并展示了通过新的提示技术提高它们的问题解决能力的潜力。

    arXiv:2311.09682v2 Announce Type: replace-cross  Abstract: We explore the creative problem-solving capabilities of modern LLMs in a novel constrained setting. To this end, we create MACGYVER, an automatically generated dataset consisting of over 1,600 real-world problems deliberately designed to trigger innovative usage of objects and necessitate out-of-the-box thinking. We then present our collection to both LLMs and humans to compare and contrast their problem-solving abilities. MACGYVER is challenging for both groups, but in unique and complementary ways. For instance, humans excel in tasks they are familiar with but struggle with domain-specific knowledge, leading to a higher variance. In contrast, LLMs, exposed to a variety of specialized knowledge, attempt broader problems but fail by proposing physically-infeasible actions. Finally, we provide a detailed error analysis of LLMs, and demonstrate the potential of enhancing their problem-solving ability with novel prompting techniqu
    
[^135]: 基于条件化空间-时间归一化流的概率天气预测

    Towards probabilistic Weather Forecasting with Conditioned Spatio-Temporal Normalizing Flows

    [https://arxiv.org/abs/2311.06958](https://arxiv.org/abs/2311.06958)

    该论文提出了一种基于条件化归一化流的概率天气预测方法，通过实验证明其能够捕捉和良好外推空间-时间相关性。

    

    生成式归一化流能够建模多模态空间分布，已经成功地模拟了时间相关性。由于其训练稳定性、可逆性以及在采样和推断方面的高效性，这些模型比其他类型的生成模型提供了几项好处。这使它们成为随机空间-时间预测问题的合适候选者，在许多科学领域中都普遍存在，如地球科学、天体物理学或分子科学。本文介绍了用于随机空间-时间建模的条件化归一化流。该方法在从ERA5数据集进行的日温度和小时等压图预测任务上进行了评估。实验表明，我们的方法能够捕捉空间-时间相关性，并能够在训练期间使用的时间范围之外进行良好的外推。

    arXiv:2311.06958v2 Announce Type: replace-cross  Abstract: Generative normalizing flows are able to model multimodal spatial distributions, and they have been shown to model temporal correlations successfully as well. These models provide several benefits over other types of generative models due to their training stability, invertibility and efficiency in sampling and inference. This makes them a suitable candidate for stochastic spatio-temporal prediction problems, which are omnipresent in many fields of sciences, such as earth sciences, astrophysics or molecular sciences. In this paper, we present conditional normalizing flows for stochastic spatio-temporal modelling. The method is evaluated on the task of daily temperature and hourly geopotential map prediction from ERA5 datasets. Experiments show that our method is able to capture spatio-temporal correlations and extrapolates well beyond the time horizon used during training.
    
[^136]: MCAD: 多教师跨模态对齐蒸馏用于高效图像-文本检索

    MCAD: Multi-teacher Cross-modal Alignment Distillation for efficient image-text retrieval

    [https://arxiv.org/abs/2310.19654](https://arxiv.org/abs/2310.19654)

    提出了一种Multi-teacher Cross-modality Alignment Distillation（MCAD）技术，通过将融合的单流特征合并到双流模型的图像和文本特征中，以整合单流和双流模型的优点。

    

    由于大规模视觉-语言预训练（VLP）模型的成功以及图像-文本检索在工业领域的广泛应用，现在迫切需要减小模型大小并简化它们在移动设备上的部署。 图像-文本检索中通常使用单流和双流模型结构，目的是缩小文本和视觉模态之间的语义差距。 虽然单流模型使用深度特征融合实现更准确的跨模态对齐，但双流模型更适用于离线索引和快速推理。我们提出了一种多教师跨模态对齐蒸馏（MCAD）技术，以整合单流和双流模型的优点。 通过将融合的单流特征合并到双流模型的图像和文本特征中，我们构建了新的修改后的教师相似性分布和特征。 然后，我们进行了分布

    arXiv:2310.19654v2 Announce Type: replace-cross  Abstract: Due to the success of large-scale visual-language pretraining (VLP) models and the widespread use of image-text retrieval in industry areas, it is now critically necessary to reduce the model size and streamline their mobile-device deployment. Single- and dual-stream model structures are commonly used in image-text retrieval with the goal of closing the semantic gap between textual and visual modalities. While single-stream models use deep feature fusion to achieve more accurate cross-model alignment, dual-stream models are better at offline indexing and fast inference.We propose a Multi-teacher Cross-modality Alignment Distillation (MCAD) technique to integrate the advantages of single- and dual-stream models. By incorporating the fused single-stream features into the image and text features of the dual-stream model, we formulate new modified teacher similarity distributions and features. Then, we conduct both distribution and
    
[^137]: MILL：大型语言模型进行零-shot查询扩展的相互验证

    MILL: Mutual Verification with Large Language Models for Zero-Shot Query Expansion

    [https://arxiv.org/abs/2310.19056](https://arxiv.org/abs/2310.19056)

    该论文提出了一种利用大型语言模型进行相互验证的零-shot查询扩展框架，有效解决了查询扩展中已有方法的限制和缺陷。

    

    论文提出了一种新颖的零shot查询扩展框架，利用大型语言模型进行相互验证。具体来说，首先设计了一种查询-查询-文档生成方法，利用LLMs的零-shot推理能力生成多样化的子查询和相应的文档。然后，一个相互验证过程协同生成和检索的文档以实现最佳扩展。我们提出的方法完全是零-shot的。

    arXiv:2310.19056v3 Announce Type: replace-cross  Abstract: Query expansion, pivotal in search engines, enhances the representation of user information needs with additional terms. While existing methods expand queries using retrieved or generated contextual documents, each approach has notable limitations. Retrieval-based methods often fail to accurately capture search intent, particularly with brief or ambiguous queries. Generation-based methods, utilizing large language models (LLMs), generally lack corpus-specific knowledge and entail high fine-tuning costs. To address these gaps, we propose a novel zero-shot query expansion framework utilizing LLMs for mutual verification. Specifically, we first design a query-query-document generation method, leveraging LLMs' zero-shot reasoning ability to produce diverse sub-queries and corresponding documents. Then, a mutual verification process synergizes generated and retrieved documents for optimal expansion. Our proposed method is fully zero
    
[^138]: 谁在与你交谈？一种赋予社交机器人定位能力的深度学习模型

    To Whom are You Talking? A Deep Learning Model to Endow Social Robots with Addressee Estimation Skills

    [https://arxiv.org/abs/2308.10757](https://arxiv.org/abs/2308.10757)

    通过深度学习模型，这项研究解决了社交机器人在生态场景中理解说话者对象的问题。

    

    交流塑造了我们的社交世界。为了让机器人被视为社交的，并被纳入我们的社交环境中，理解驱使人际交流的一些动态是至关重要的。在这项工作中，我们解决了定位对象的问题，即理解话语的对象，通过解释和利用说话者的非语言身体信号。我们通过实现一个混合深度学习模型来做到这一点，该模型由卷积层和LSTM单元组成，以描绘说话者脸部的图像和说话者身体姿势的2D向量作为输入。我们的实现选择是为了开发一个在社交机器人上可以部署并能在生态场景中高效的模型。我们展示了我们的模型能够从机器人的自我中心观点解决定位对象的问题。

    arXiv:2308.10757v2 Announce Type: replace-cross  Abstract: Communicating shapes our social word. For a robot to be considered social and being consequently integrated in our social environment it is fundamental to understand some of the dynamics that rule human-human communication. In this work, we tackle the problem of Addressee Estimation, the ability to understand an utterance's addressee, by interpreting and exploiting non-verbal bodily cues from the speaker. We do so by implementing an hybrid deep learning model composed of convolutional layers and LSTM cells taking as input images portraying the face of the speaker and 2D vectors of the speaker's body posture. Our implementation choices were guided by the aim to develop a model that could be deployed on social robots and be efficient in ecological scenarios. We demonstrate that our model is able to solve the Addressee Estimation problem in terms of addressee localisation in space, from a robot ego-centric point of view.
    
[^139]: 机器学习驱动的组合时钟拍卖

    Machine Learning-Powered Combinatorial Clock Auction

    [https://arxiv.org/abs/2308.10226](https://arxiv.org/abs/2308.10226)

    本文提出了一种机器学习驱动的组合时钟拍卖，通过仅使用需求查询而不是价值查询来获取投标人的偏好信息。

    

    我们研究了迭代组合拍卖（ICA）的设计。在这个领域中的主要挑战在于束空间随着物品数量呈指数增长。为了解决这个问题，最近有几篇论文提出了基于机器学习（ML）的偏好调查算法，旨在仅从投标人那里获取最重要的信息。然而，从实际角度看，这些先前工作的主要缺点是通过价值查询（即，“对于捆绑包$\{A,B\}$，您的价值是多少？”）引出投标人的偏好。在大多数实际ICA领域中，价值查询被认为是不切实际的，因为它们给投标人带来了不切实际的高认知负担，这就是为什么它们在实践中不被使用的原因。在本文中，我们通过设计一个机器学习驱动的组合时钟拍卖来解决这一缺点，该拍卖只通过需求查询（即，“在价格$p$下，您对捆绑包$\{A,B\}$的需求有多少？”）从投标人那里引起信息。

    arXiv:2308.10226v2 Announce Type: replace-cross  Abstract: We study the design of iterative combinatorial auctions (ICAs). The main challenge in this domain is that the bundle space grows exponentially in the number of items. To address this, several papers have recently proposed machine learning (ML)-based preference elicitation algorithms that aim to elicit only the most important information from bidders. However, from a practical point of view, the main shortcoming of this prior work is that those designs elicit bidders' preferences via value queries (i.e., ``What is your value for the bundle $\{A,B\}$?''). In most real-world ICA domains, value queries are considered impractical, since they impose an unrealistically high cognitive burden on bidders, which is why they are not used in practice. In this paper, we address this shortcoming by designing an ML-powered combinatorial clock auction that elicits information from the bidders only via demand queries (i.e., ``At prices $p$, what
    
[^140]: 面向解释神经代码模型的因果论理论

    Toward a Theory of Causation for Interpreting Neural Code Models

    [https://arxiv.org/abs/2302.03788](https://arxiv.org/abs/2302.03788)

    该论文介绍了一种名为$do_{code}$的后验解释方法，用于解释神经代码模型的预测，基于因果推断，旨在实现面向编程语言的解释。

    

    Neural Language Models of Code，或者称为神经代码模型（NCMs），正在迅速从研究原型发展为商业开发者工具。因此，理解这些模型的能力和局限性变得至关重要。然而，这些模型的能力通常是使用自动化指标来衡量的，这些指标通常只能揭示它们真实性能的一部分。一般来说，NCMs的性能似乎很有前途，但目前关于这些模型如何做出决策仍有很多未知。因此，本文介绍了一种名为$do_{code}$的后验解释方法，该方法专门针对NCMs，能够解释模型的预测。$do_{code}$基于因果推断，以实现面向编程语言的解释。虽然$do_{code}$的理论基础可扩展到探索不同的模型属性，但我们提供了一个具体的实例，旨在减少影响...

    arXiv:2302.03788v2 Announce Type: replace-cross  Abstract: Neural Language Models of Code, or Neural Code Models (NCMs), are rapidly progressing from research prototypes to commercial developer tools. As such, understanding the capabilities and limitations of such models is becoming critical. However, the abilities of these models are typically measured using automated metrics that often only reveal a portion of their real-world performance. While, in general, the performance of NCMs appears promising, currently much is unknown about how such models arrive at decisions. To this end, this paper introduces $do_{code}$, a post hoc interpretability method specific to NCMs that is capable of explaining model predictions. $do_{code}$ is based upon causal inference to enable programming language-oriented explanations. While the theoretical underpinnings of $do_{code}$ are extensible to exploring different model properties, we provide a concrete instantiation that aims to mitigate the impact o
    
[^141]: 使用带有鲁棒性保证的最优输运扰动进行安全强化学习

    Optimal Transport Perturbations for Safe Reinforcement Learning with Robustness Guarantees

    [https://arxiv.org/abs/2301.13375](https://arxiv.org/abs/2301.13375)

    引入了基于最优输运扰动的安全强化学习框架，通过构建最坏情况的虚拟状态转换以提升鲁棒性能和安全性。

    

    基于最优输运成本不确定性集，引入了一个安全强化学习框架，通过应用最优输运扰动来构建最坏情况的虚拟状态转换，提供了一种有效的实现方法。在连续控制任务的实验中，我们的方法展示了鲁棒性能，并显著提高了部署时的安全性。

    arXiv:2301.13375v2 Announce Type: replace-cross  Abstract: Robustness and safety are critical for the trustworthy deployment of deep reinforcement learning. Real-world decision making applications require algorithms that can guarantee robust performance and safety in the presence of general environment disturbances, while making limited assumptions on the data collection process during training. In order to accomplish this goal, we introduce a safe reinforcement learning framework that incorporates robustness through the use of an optimal transport cost uncertainty set. We provide an efficient implementation based on applying Optimal Transport Perturbations to construct worst-case virtual state transitions, which does not impact data collection during training and does not require detailed simulator access. In experiments on continuous control tasks with safety constraints, our approach demonstrates robust performance while significantly improving safety at deployment time compared to 
    
[^142]: SOLD：僧伽罗语攻击性语言数据集

    SOLD: Sinhala Offensive Language Dataset

    [https://arxiv.org/abs/2212.00851](https://arxiv.org/abs/2212.00851)

    本文介绍了一种新的低资源语言——僧伽罗语攻击性语言识别数据集(SOLD)，填补了目前攻击性语言识别研究局限于高资源语言的空白。

    

    在线攻击性内容的普遍存在，比如仇恨言论和网络欺凌，已成为全球性现象。这引起了人工智能（AI）和自然语言处理（NLP）社区的兴趣，促使开发各种系统，能够自动检测潜在有害内容。然而，除了少数几个例外情况外，大多数关于这一主题的数据集都处理英语和少数其他高资源语言。因此，攻击性语言识别研究一直局限于这些语言。本文通过处理僧伽罗语攻击性语言识别来填补这一空白，僧伽罗语是斯里兰卡有超过1700万人口使用的低资源印欧语言。我们介绍了僧伽罗语攻击性语言数据集（SOLD），并在该数据集上展示了多个实验。

    arXiv:2212.00851v2 Announce Type: replace-cross  Abstract: The widespread of offensive content online, such as hate speech and cyber-bullying, is a global phenomenon. This has sparked interest in the artificial intelligence (AI) and natural language processing (NLP) communities, motivating the development of various systems trained to detect potentially harmful content automatically. These systems require annotated datasets to train the machine learning (ML) models. However, with a few notable exceptions, most datasets on this topic have dealt with English and a few other high-resource languages. As a result, the research in offensive language identification has been limited to these languages. This paper addresses this gap by tackling offensive language identification in Sinhala, a low-resource Indo-Aryan language spoken by over 17 million people in Sri Lanka. We introduce the Sinhala Offensive Language Dataset (SOLD) and present multiple experiments on this dataset. SOLD is a manuall
    
[^143]: 在智能手机上高效基于深度学习的生命体征估计

    Efficient Deep Learning-based Estimation of the Vital Signs on Smartphones

    [https://arxiv.org/abs/2204.08989](https://arxiv.org/abs/2204.08989)

    提出了一种通过深度学习的端到端解决方案，用于在智能手机上高效估计生命体征，消除了繁琐的预处理步骤。

    

    随着智能手机在我们的日常生活中的日益普及，这些设备已经能够执行许多复杂的任务。针对对生命体征的持续监测需求，特别是针对老年人或患有某些类型疾病的人群，开发能够使用智能手机估计生命体征的算法引起了全球研究人员的关注。研究人员已经在探索使用可以在智能手机上运行的算法来估计生命体征，例如心率、血氧饱和度水平和呼吸率。然而，许多这些算法需要多个预处理步骤，这可能会引入一些实现开销或需要设计几个手工阶段才能获得最佳结果。为了解决这个问题，本研究提出了一种新颖的基于深度学习的移动设备生命体征估计的端到端解决方案，消除了对预处理的需求。

    arXiv:2204.08989v3 Announce Type: replace-cross  Abstract: With the increasing use of smartphones in our daily lives, these devices have become capable of performing many complex tasks. Concerning the need for continuous monitoring of vital signs, especially for the elderly or those with certain types of diseases, the development of algorithms that can estimate vital signs using smartphones has attracted researchers worldwide. In particular, researchers have been exploring ways to estimate vital signs, such as heart rate, oxygen saturation levels, and respiratory rate, using algorithms that can be run on smartphones. However, many of these algorithms require multiple pre-processing steps that might introduce some implementation overheads or require the design of a couple of hand-crafted stages to obtain an optimal result. To address this issue, this research proposes a novel end-to-end solution to mobile-based vital sign estimation using deep learning that eliminates the need for pre-p
    
[^144]: 基于最大效用的序列查询推荐中的臂选择策略

    Max-Utility Based Arm Selection Strategy For Sequential Query Recommendations

    [https://arxiv.org/abs/2108.13810](https://arxiv.org/abs/2108.13810)

    提出一种基于最大效用的臂选择策略，以减少在序列查询推荐中的累积遗憾。

    

    我们考虑在闭环交互式学习设置中的查询推荐问题，例如在线信息收集和探索分析。该问题可以自然地使用多臂老虎机（MAB）框架来建模，其中有可数个臂。标准的可数臂MAB算法从选择一个随机的候选臂集开始，然后在这个候选集合上应用标准的MAB算法，例如UCB。我们展示了这样的选择策略通常会导致更高的累积遗憾，为此，我们提出了一种基于臂的最大效用的选择策略。我们展示了在诸如在线信息收集这样的任务中，其中采用了序列查询推荐，查询序列是相关的，并且通过选择相对于当前执行查询具有最大效用的查询，可以将潜在最佳查询的数量减少到一个可管理的大小。

    arXiv:2108.13810v1 Announce Type: cross  Abstract: We consider the query recommendation problem in closed loop interactive learning settings like online information gathering and exploratory analytics. The problem can be naturally modelled using the Multi-Armed Bandits (MAB) framework with countably many arms. The standard MAB algorithms for countably many arms begin with selecting a random set of candidate arms and then applying standard MAB algorithms, e.g., UCB, on this candidate set downstream. We show that such a selection strategy often results in higher cumulative regret and to this end, we propose a selection strategy based on the maximum utility of the arms. We show that in tasks like online information gathering, where sequential query recommendations are employed, the sequences of queries are correlated and the number of potentially optimal queries can be reduced to a manageable size by selecting queries with maximum utility with respect to the currently executing query. Our
    
[^145]: 利用深度学习对脑电解码中的欧几里得对齐进行系统评估

    A Systematic Evaluation of Euclidean Alignment with Deep Learning for EEG Decoding. (arXiv:2401.10746v1 [eess.SP])

    [http://arxiv.org/abs/2401.10746](http://arxiv.org/abs/2401.10746)

    本研究系统评估了使用深度学习和欧几里得对齐对脑电解码的影响。结果表明，欧几里得对齐能够显著提高解码率，并且减少了收敛时间。

    

    脑电图（EEG）信号经常用于各种脑机接口（BCI）任务。尽管深度学习（DL）技术显示出有希望的结果，但它们受到大量数据要求的限制。通过利用来自多个受试者的数据，迁移学习能够更有效地训练DL模型。一种越来越受欢迎的技术是欧几里得对齐（EA），因为它易于使用、计算复杂度低并且与深度学习模型兼容。然而，很少有研究评估其对共享和个体DL模型的训练效果的影响。在这项工作中，我们系统地评估了EA与DL相结合在解码BCI信号中的效果。我们使用EA来训练来自多个受试者的共享模型，并评估其对新受试者的可迁移性。我们的实验结果表明，它将目标受试者的解码率提高了4.33％，并且收敛时间缩短了超过70％。我们还为个体模型进行了训练。

    Electroencephalography (EEG) signals are frequently used for various Brain-Computer Interface (BCI) tasks. While Deep Learning (DL) techniques have shown promising results, they are hindered by the substantial data requirements. By leveraging data from multiple subjects, transfer learning enables more effective training of DL models. A technique that is gaining popularity is Euclidean Alignment (EA) due to its ease of use, low computational complexity, and compatibility with Deep Learning models. However, few studies evaluate its impact on the training performance of shared and individual DL models. In this work, we systematically evaluate the effect of EA combined with DL for decoding BCI signals. We used EA to train shared models with data from multiple subjects and evaluated its transferability to new subjects. Our experimental results show that it improves decoding in the target subject by 4.33% and decreases convergence time by more than 70%. We also trained individual models for 
    
[^146]: 大型语言模型的知识编辑全面研究

    A Comprehensive Study of Knowledge Editing for Large Language Models. (arXiv:2401.01286v1 [cs.CL])

    [http://arxiv.org/abs/2401.01286](http://arxiv.org/abs/2401.01286)

    本研究全面研究了大型语言模型的知识编辑，旨在有效修改模型的行为，同时保持整体性能。

    

    大型语言模型(LLM)在理解和生成与人类交流紧密相似的文本方面展现出了非凡的能力。然而，其主要限制在于训练过程中的显著计算需求，这是由于其广泛的参数化造成的。这一挑战在于世界的动态性，需要频繁更新LLM以修正过时的信息或集成新知识，从而确保其持续的相关性。许多应用需要在训练后进行持续的模型调整，以解决缺陷或不良行为。近年来，对于LLM的知识编辑技术的兴趣越来越高，在特定领域内有效地修改LLM的行为，同时保持整体性能在各种输入中的表现。本文首先定义了知识编辑的目标和挑战，然后综述了现有的知识编辑方法和技术，并讨论了其应用和未来发展的方向。

    Large Language Models (LLMs) have shown extraordinary capabilities in understanding and generating text that closely mirrors human communication. However, a primary limitation lies in the significant computational demands during training, arising from their extensive parameterization. This challenge is further intensified by the dynamic nature of the world, necessitating frequent updates to LLMs to correct outdated information or integrate new knowledge, thereby ensuring their continued relevance. Note that many applications demand continual model adjustments post-training to address deficiencies or undesirable behaviors. There is an increasing interest in efficient, lightweight methods for on-the-fly model modifications. To this end, recent years have seen a burgeoning in the techniques of knowledge editing for LLMs, which aim to efficiently modify LLMs' behaviors within specific domains while preserving overall performance across various inputs. In this paper, we first define the kno
    
[^147]: 关于上下文学习的校准研究

    A Study on the Calibration of In-context Learning. (arXiv:2312.04021v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.04021](http://arxiv.org/abs/2312.04021)

    本研究关注上下文学习（ICL），通过定制提示来调整静态语言模型（LMs），研究了在各种自然语言理解和推理任务中性能和校准之间的平衡。研究发现随着ICL示例数量的增加，模型的校准会先增加而后得到改善，而校准误差主要出现在低样本场景下。此外，微调和CoT提示等方法可能导致校准误差和不可靠的自然语言解释，提示需要针对可靠性场景开发新的方法。

    

    准确的不确定性量化对于语言模型（LMs）的安全部署至关重要，以前的研究已经证明了现代LMs校准性的改进。我们的研究重点是上下文学习（ICL），一种通过定制提示来调整静态LMs的常见方法，并研究在广泛的自然语言理解和推理任务中性能和校准之间的平衡。通过全面的实验，我们观察到，随着ICL示例数量的增加，模型最初会出现增加的校准误差，然后才能实现更好的校准，而校准误差往往在低样本场景下出现。此外，我们发现以提高可用性为目标的方法，如微调和CoT提示，可能导致校准误差和不可靠的自然语言解释，这表明在期望模型可靠性的场景中可能需要新的方法。

    Accurate uncertainty quantification is crucial for the safe deployment of language models (LMs), and prior research has demonstrated improvements in the calibration of modern LMs. Our study focuses on in-context learning (ICL), a prevalent method for adapting static LMs through tailored prompts, and examines the balance between performance and calibration across a broad spectrum of natural language understanding and reasoning tasks. Through comprehensive experiments, we observe that, with an increasing number of ICL examples, models initially exhibit increased miscalibration before achieving better calibration and miscalibration tends to arise in low-shot settings. Moreover, we find that methods aimed at improving usability, such as fine-tuning and chain-of-thought (CoT) prompting, can lead to miscalibration and unreliable natural language explanations, suggesting that new methods may be required for scenarios where models are expected to be reliable.
    
[^148]: 使用Transformer学习解决气候传感器布放问题

    Learning to Solve Climate Sensor Placement Problems with a Transformer. (arXiv:2310.12387v1 [cs.LG])

    [http://arxiv.org/abs/2310.12387](http://arxiv.org/abs/2310.12387)

    本文介绍了一种使用深度强化学习方法学习改进传感器布放策略的新方法，通过与其他方法的对比实验证明了该方法在产生高质量解决方案方面的有效性和优越性。

    

    由于其NP难性质，环境监测和灾害管理中的传感器布放优化是一个具有挑战性的问题。传统的传感器布放方法包括精确、近似或启发式方法，其中启发式方法是最常用的。然而，启发式方法受到专家直觉和经验的限制。深度学习（DL）已经成为自动生成启发式算法的一种有前景的方法。本文介绍了一种新颖的传感器布放方法，重点是使用深度强化学习（RL）方法学习改进的启发式算法。我们的方法利用了一个强化学习公式来学习改进的启发式算法，通过演员-评论家算法训练策略网络。我们通过进行全面的实验将我们的方法与几种最先进的方法进行比较，证明了我们提出的方法在产生高质量解决方案方面的有效性和优越性。我们的工作提出了一种有前景的方法，用于解决气候传感器布放问题。

    The optimal placement of sensors for environmental monitoring and disaster management is a challenging problem due to its NP-hard nature. Traditional methods for sensor placement involve exact, approximation, or heuristic approaches, with the latter being the most widely used. However, heuristic methods are limited by expert intuition and experience. Deep learning (DL) has emerged as a promising approach for generating heuristic algorithms automatically. In this paper, we introduce a novel sensor placement approach focused on learning improvement heuristics using deep reinforcement learning (RL) methods. Our approach leverages an RL formulation for learning improvement heuristics, driven by an actor-critic algorithm for training the policy network. We compare our method with several state-of-the-art approaches by conducting comprehensive experiments, demonstrating the effectiveness and superiority of our proposed approach in producing high-quality solutions. Our work presents a promisi
    
[^149]: Rayleigh Quotient Graph Neural Networks用于图级异常检测的研究

    Rayleigh Quotient Graph Neural Networks for Graph-level Anomaly Detection. (arXiv:2310.02861v1 [cs.LG])

    [http://arxiv.org/abs/2310.02861](http://arxiv.org/abs/2310.02861)

    《Rayleigh Quotient Graph Neural Networks用于图级异常检测的研究》提出使用Rayleigh Quotient作为驱动因素，通过探索图的固有光谱特征来实现图级异常检测。

    

    图级异常检测在癌症诊断和酶预测等领域中广泛应用。然而，现有方法无法捕捉到图异常的潜在属性，导致框架设计不可解释和性能不令人满意。在本文中，我们退一步重新研究了异常和正常图之间的光谱差异。我们的主要观察表明，这两个类之间的累计光谱能量存在显著差异。此外，我们证明了图信号的累计光谱能量可以用其瑞利商表示，这表明瑞利商是图异常属性的一个驱动因素。受此启发，我们提出了Rayleigh Quotient Graph Neural Network（RQGNN），这是第一个用于图级异常检测的光谱GNN，为探索异常图的固有光谱特征提供了新的视角。

    Graph-level anomaly detection has gained significant attention as it finds many applications in various domains, such as cancer diagnosis and enzyme prediction. However, existing methods fail to capture the underlying properties of graph anomalies, resulting in unexplainable framework design and unsatisfying performance. In this paper, we take a step back and re-investigate the spectral differences between anomalous and normal graphs. Our main observation shows a significant disparity in the accumulated spectral energy between these two classes. Moreover, we prove that the accumulated spectral energy of the graph signal can be represented by its Rayleigh Quotient, indicating that the Rayleigh Quotient is a driving factor behind the anomalous properties of graphs. Motivated by this, we propose Rayleigh Quotient Graph Neural Network (RQGNN), the first spectral GNN for graph-level anomaly detection, providing a new perspective on exploring the inherent spectral features of anomalous graph
    
[^150]: 最严格可接受的最短路径

    Tightest Admissible Shortest Path. (arXiv:2308.08453v1 [cs.DS])

    [http://arxiv.org/abs/2308.08453](http://arxiv.org/abs/2308.08453)

    该论文提出了一种针对加权有向图的最严格可接受的最短路径问题，利用边权不确定性进行计算成本交换，并提供了一个完整的算法来解决此问题，并保证解的质量。

    

    图中的最短路径问题对于人工智能来说是基础性的。几乎所有问题的变种和相关算法都忽略了边权计算时间及其与权重不确定性的常见关系。这意味着考虑这些因素可能会在相关应用中带来性能提升。最近，提出了一种针对加权有向图的推广框架，可以多次计算（估计）边权，随着精度的增加和运行时间的增加。我们在此框架上引入了寻找最严格可接受的最短路径（TASP）的问题；这是将最短路径问题推广到有界不确定性的情况，其中可以通过计算成本来交换边权的不确定性。我们提出了一个完整的算法来解决TASP，并保证了解的质量。实证评估支持这种方法的有效性。

    The shortest path problem in graphs is fundamental to AI. Nearly all variants of the problem and relevant algorithms that solve them ignore edge-weight computation time and its common relation to weight uncertainty. This implies that taking these factors into consideration can potentially lead to a performance boost in relevant applications. Recently, a generalized framework for weighted directed graphs was suggested, where edge-weight can be computed (estimated) multiple times, at increasing accuracy and run-time expense. We build on this framework to introduce the problem of finding the tightest admissible shortest path (TASP); a path with the tightest suboptimality bound on the optimal cost. This is a generalization of the shortest path problem to bounded uncertainty, where edge-weight uncertainty can be traded for computational cost. We present a complete algorithm for solving TASP, with guarantees on solution quality. Empirical evaluation supports the effectiveness of this approac
    
[^151]: 对视频片段中物体行为的推理用于副词类型识别

    Reasoning over the Behaviour of Objects in Video-Clips for Adverb-Type Recognition. (arXiv:2307.04132v1 [cs.CV])

    [http://arxiv.org/abs/2307.04132](http://arxiv.org/abs/2307.04132)

    本研究提出了一种新的框架，通过对视频片段中提取的物体行为进行推理来识别副词类型。实验结果表明，我们的方法在效果上超越了之前的最先进方法。

    

    本研究根据对描述场景序列的副词最佳识别方法为基础，提出了一种新的框架，通过对从原始视频片段中提取的物体行为进行推理来识别片段对应的副词类型。与之前针对常规场景副词识别的方法不同的是，我们的方法适用于视频片段的行动类型未知的更一般的问题设置。具体而言，我们提出了一个新的流程，从原始视频片段中提取了可以人类理解的物体行为事实，并提出了基于符号和转换器的推理方法，对这些提取出的事实进行操作以识别副词类型。实验结果表明，我们提出的方法在性能上优于之前的最先进方法。此外，为了支持符号视频处理的工作，我们还发布了视频领域相关的资源。

    In this work, following the intuition that adverbs describing scene-sequences are best identified by reasoning over high-level concepts of object-behavior, we propose the design of a new framework that reasons over object-behaviours extracted from raw-video-clips to recognize the clip's corresponding adverb-types. Importantly, while previous works for general scene adverb-recognition assume knowledge of the clips underlying action-types, our method is directly applicable in the more general problem setting where the action-type of a video-clip is unknown. Specifically, we propose a novel pipeline that extracts human-interpretable object-behaviour-facts from raw video clips and propose novel symbolic and transformer based reasoning methods that operate over these extracted facts to identify adverb-types. Experiment results demonstrate that our proposed methods perform favourably against the previous state-of-the-art. Additionally, to support efforts in symbolic video-processing, we rele
    
[^152]: FormAI数据集：以形式验证为视角的软件安全生成AI

    The FormAI Dataset: Generative AI in Software Security Through the Lens of Formal Verification. (arXiv:2307.02192v2 [cs.DB] UPDATED)

    [http://arxiv.org/abs/2307.02192](http://arxiv.org/abs/2307.02192)

    本文介绍了一个名为FormAI的数据集，其中包含112,000个可编译的C程序，利用动态零-shot提示技术生成。这些程序经过形式验证，标记了源代码中的漏洞，并使用多种技术来提高程序的安全性和可靠性。

    

    本文介绍了FormAI数据集，这是一个包含112,000个具有漏洞分类的AI生成的可编译和独立的C程序的大型集合。我们引入了一种动态零-shot提示技术，用于生成利用大型语言模型（LLMs）的多样化程序。该数据集由GPT-3.5-turbo生成，并包含具有不同复杂度的程序。有些程序处理复杂任务，如网络管理、桌面游戏或加密，而其他程序处理简单任务，如字符串操作。每个程序都用源代码中找到的漏洞进行标记，指示类型、行号和漏洞函数名。这是通过使用高效的基于SMT的有界模型检查器（ESBMC）的形式验证方法实现的。该方法使用模型检查、抽象解释、约束编程和可满足性模理论来推理程序中的安全性/安全属性。这种方法确定了和验证了程序的安全性和可靠性。

    This paper presents the FormAI dataset, a large collection of 112, 000 AI-generated compilable and independent C programs with vulnerability classification. We introduce a dynamic zero-shot prompting technique constructed to spawn diverse programs utilizing Large Language Models (LLMs). The dataset is generated by GPT-3.5-turbo and comprises programs with varying levels of complexity. Some programs handle complicated tasks like network management, table games, or encryption, while others deal with simpler tasks like string manipulation. Every program is labeled with the vulnerabilities found within the source code, indicating the type, line number, and vulnerable function name. This is accomplished by employing a formal verification method using the Efficient SMT-based Bounded Model Checker (ESBMC), which uses model checking, abstract interpretation, constraint programming, and satisfiability modulo theories to reason over safety/security properties in programs. This approach definitiv
    
[^153]: RAPGen: 一种解决零样本代码低效问题的方法

    RAPGen: An Approach for Fixing Code Inefficiencies in Zero-Shot. (arXiv:2306.17077v1 [cs.SE])

    [http://arxiv.org/abs/2306.17077](http://arxiv.org/abs/2306.17077)

    RAPGen是一种新方法，通过在零样本情况下使用Retrieval-Augmented Prompt Generation（RAPGen）方法，即从预先构建的性能Bug修复知识库中检索提示指令并生成提示，然后在大型语言模型上生成修复方案，可以有效地解决代码低效问题。实验结果显示，在专家验证的数据集中，RAPGen在60%的情况下可以生成与开发者等效或更好的性能改进建议，其中约39%的建议完全相同。

    

    性能Bug是一种即使在经过充分测试的商业产品中也可能出现的非功能性问题。修复这些性能Bug是一个重要但具有挑战性的问题。在这项工作中，我们解决了这个挑战，并提出了一种名为Retrieval-Augmented Prompt Generation（RAPGen）的新方法。给定一个存在性能问题的代码片段，RAPGen首先从预先构建的之前性能Bug修复知识库中检索一个提示指令，然后使用检索到的指令生成一个提示。然后，它在零样本情况下使用这个提示在大型语言模型（如Codex）上生成一个修复方案。我们将我们的方法与各种提示变体和现有方法在性能Bug修复任务中进行了比较。我们的评估结果显示，RAPGen在60%的情况下可以生成与开发者等效或更好的性能改进建议，在经过专家验证的过去C#开发者所做的性能更改数据集中有约39%的建议完全相同。

    Performance bugs are non-functional bugs that can even manifest in well-tested commercial products. Fixing these performance bugs is an important yet challenging problem. In this work, we address this challenge and present a new approach called Retrieval-Augmented Prompt Generation (RAPGen). Given a code snippet with a performance issue, RAPGen first retrieves a prompt instruction from a pre-constructed knowledge-base of previous performance bug fixes and then generates a prompt using the retrieved instruction. It then uses this prompt on a Large Language Model (such as Codex) in zero-shot to generate a fix. We compare our approach with the various prompt variations and state of the art methods in the task of performance bug fixing. Our evaluation shows that RAPGen can generate performance improvement suggestions equivalent or better than a developer in ~60% of the cases, getting ~39% of them verbatim, in an expert-verified dataset of past performance changes made by C# developers.
    
[^154]: 针对异常检测的目标塌缩正则化自编码器：中心的黑洞

    Targeted collapse regularized autoencoder for anomaly detection: black hole at the center. (arXiv:2306.12627v1 [cs.LG])

    [http://arxiv.org/abs/2306.12627](http://arxiv.org/abs/2306.12627)

    本文提出一种在自编码器的损失函数中添加一个轻量级的约束项，用于解决传统自编码器在异常检测中的不足，并取得了良好的表现。

    

    自编码器已广泛用于最近的异常检测技术开发中。它们的应用前提是在正常训练数据上训练自编码器后，异常输入将表现出显著的重构误差。因此，这使得正常和异常样本之间有了明显的区别。然而，在实践中观察到，自编码器可以一定程度上泛化到正常类之外，并在一些异常样本上实现较小的重构误差。为了改善性能，各种技术提出了其他组件和更复杂的训练程序。在这项工作中，我们提出了一个非常简单的替代方法：不是添加神经网络组件、涉及计算和繁琐的训练，而是通过在潜在空间中调节表示的范数，用一个计算简单的项来补充重构损失。我们方法的简单性最小化了复杂性。

    Autoencoders have been extensively used in the development of recent anomaly detection techniques. The premise of their application is based on the notion that after training the autoencoder on normal training data, anomalous inputs will exhibit a significant reconstruction error. Consequently, this enables a clear differentiation between normal and anomalous samples. In practice, however, it is observed that autoencoders can generalize beyond the normal class and achieve a small reconstruction error on some of the anomalous samples. To improve the performance, various techniques propose additional components and more sophisticated training procedures. In this work, we propose a remarkably straightforward alternative: instead of adding neural network components, involved computations, and cumbersome training, we complement the reconstruction loss with a computationally light term that regulates the norm of representations in the latent space. The simplicity of our approach minimizes th
    
[^155]: 《琳达，出了什么问题？》“连接谬误”作为公平性问题的探讨

    What's the Problem, Linda? The Conjunction Fallacy as a Fairness Problem. (arXiv:2305.09535v1 [cs.AI])

    [http://arxiv.org/abs/2305.09535](http://arxiv.org/abs/2305.09535)

    这篇论文探讨了“连接谬误”作为公平性问题在人工智能领域中的重要性，并提出了一些问题，以帮助AI研究人员和从业者避免类似情况在未来中复现。

    

    人工智能领域正在专注于创建尽可能接近人类智能的自动决策系统。这一努力推动人工智能研究人员探索心理学等认知领域。 Daniel Kahneman和已故的Amos Tversky在有偏见的人类决策制定方面的工作，包括对连接谬误的研究，因此进行了第二次复兴。 在连接谬误下，决策制定者会违反基本概率法则，认为连词比其中一个部分更有可能。通过一系列与琳达问题最为著名的实验，它已被证明是经得起时间考验的。虽然这种跨学科的努力受到欢迎，但我们担心，人工智能研究人员忽略了琳达问题所捕捉到的驱动力：琳达必须被刻板地描述为一个女性。 在本文中，我们重新审视琳达问题，并将其形式化为AI中的公平性问题。我们认为连接谬误是偏见数据集如何导致偏见结果的明显例子，从而延续和放大现有的系统性偏见。我们提出了一组问题供AI研究人员和从业人员使用，以避免类似情况在未来发生。

    The field of Artificial Intelligence (AI) is focusing on creating automated decision-making (ADM) systems that operate as close as possible to human-like intelligence. This effort has pushed AI researchers into exploring cognitive fields like psychology. The work of Daniel Kahneman and the late Amos Tversky on biased human decision-making, including the study of the conjunction fallacy, has experienced a second revival because of this. Under the conjunction fallacy a human decision-maker will go against basic probability laws and rank as more likely a conjunction over one of its parts. It has been proven overtime through a set of experiments with the Linda Problem being the most famous one. Although this interdisciplinary effort is welcomed, we fear that AI researchers ignore the driving force behind the conjunction fallacy as captured by the Linda Problem: the fact that Linda must be stereotypically described as a woman. In this paper we revisit the Linda Problem and formulate it as a
    
[^156]: 用于识别TBI生理状态的多元时间序列数据的自监督聚类

    Self-Supervised Clustering of Multivariate Time-Series Data for Identifying TBI Physiological States. (arXiv:2303.13024v1 [cs.LG])

    [http://arxiv.org/abs/2303.13024](http://arxiv.org/abs/2303.13024)

    这篇论文提出了一种新的自监督聚类算法，能够在多元时间序列数据中确定并识别对于TBI等急性疾病治疗非常重要的生理状态。研究还利用临床数据验证并解释所识别的生理状态。

    

    对于具有缺失值的多元时间序列数据确定临床相关的生理状态非常重要，这对于提供急性疾病（如颅脑损伤、呼吸衰竭和心力衰竭）的适当治疗至关重要。利用非时间序列聚类或数据插值和聚合技术可能导致有价值信息的丢失和偏见分析。在本研究中，我们应用了基于自监督的SLAC-Time算法，避免了插值或聚合，从而更有效地表示急性患者状态。通过使用SLAC-Time来聚类大型研究数据集中的数据，我们确定了三种不同的TBI生理状态及其具体特征。我们采用了各种聚类评估指标，并结合临床领域专家的意见来验证和解释所识别的生理状态。此外，我们发现了特定临床事件和生理状态之间的关系。

    Determining clinically relevant physiological states from multivariate time series data with missing values is essential for providing appropriate treatment for acute conditions such as Traumatic Brain Injury (TBI), respiratory failure, and heart failure. Utilizing non-temporal clustering or data imputation and aggregation techniques may lead to loss of valuable information and biased analyses. In our study, we apply the SLAC-Time algorithm, an innovative self-supervision-based approach that maintains data integrity by avoiding imputation or aggregation, offering a more useful representation of acute patient states. By using SLAC-Time to cluster data in a large research dataset, we identified three distinct TBI physiological states and their specific feature profiles. We employed various clustering evaluation metrics and incorporated input from a clinical domain expert to validate and interpret the identified physiological states. Further, we discovered how specific clinical events and
    
[^157]: 自我提示的大型语言模型用于零样本开放域问答

    Self-Prompting Large Language Models for Zero-Shot Open-Domain QA. (arXiv:2212.08635v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.08635](http://arxiv.org/abs/2212.08635)

    本论文提出了一种自我提示框架，可以有效利用大型语言模型的参数中存储的知识和指令理解能力，以实现零样本开放域问答，并且实验证明该方法在三个广泛使用的ODQA数据集中显著优于现有的最先进方法。

    

    开放域问答目标在于回答关于事实的问题，而无需提供特定的背景文档。在零样本设置下，由于没有数据来训练类似检索器-阅读器的定制模型，因此此任务更加具有挑战性。最近，像GPT-3这样的大型语言模型已经通过直接提示方法在零样本开放域问答中展示了其强大的能力，但是这些方法仍然远远不能充分发挥LLM的强大功能，而只是以隐式方式调用它们而已。本文提出了一个自我提示框架，以明确利用LLM参数中存储的大量知识和其强大的指令理解能力。具体而言，我们逐步提示LLM生成多个伪QA对，并从头开始生成背景段落和解释，然后使用生成的元素进行上下文学习。实验结果表明，我们的方案在三个广泛使用的ODQA数据集上显著超过了先前的SOTA方法。

    Open-Domain Question Answering (ODQA) aims at answering factoid questions without explicitly providing specific background documents. In a zero-shot setting, this task is more challenging since no data is available to train customized models like Retriever-Readers. Recently, Large Language Models (LLMs) like GPT-3 have shown their power in zero-shot ODQA with direct prompting methods, but these methods are still far from releasing the full powerfulness of LLMs only in an implicitly invoking way. In this paper, we propose a Self-Prompting framework to explicitly utilize the massive knowledge stored in the parameters of LLMs and their strong instruction understanding abilities. Concretely, we prompt LLMs step by step to generate multiple pseudo QA pairs with background passages and explanations from scratch and then use those generated elements for in-context learning. Experimental results show our method surpasses previous SOTA methods significantly on three widely-used ODQA datasets, a
    

