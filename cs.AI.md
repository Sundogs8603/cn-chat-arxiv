# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Anatomy of an AI-powered malicious social botnet.](http://arxiv.org/abs/2307.16336) | 本文通过案例研究揭示了使用AI语言模型生成人类内容的Twitter机器人网络。这些机器人账号构成了一个密集的虚假人物群集，宣传可疑网站并传播有害评论。 |
| [^2] | [Representing and Reasoning with Multi-Stakeholder Qualitative Preference Queries.](http://arxiv.org/abs/2307.16307) | 这篇论文提供了第一个关于利用定性偏好进行多利益相关者推理的形式化方法，并介绍了一种查询语言和多种查询的替代语义，还提供了一个通过模型检验回答查询的算法。 |
| [^3] | [Implementing Edge Based Object Detection For Microplastic Debris.](http://arxiv.org/abs/2307.16289) | 本论文研究了微塑料废弃物的边缘检测实现，提出了采用计算机视觉和机器人附件的方法来增强手动分拣操作和检测的解决方案。 |
| [^4] | [Towards Learned Predictability of Storage Systems.](http://arxiv.org/abs/2307.16288) | 本论文探索了实现存储系统学习预测性的方法，通过提前检测缓慢的IO请求和预测设备故障，以构建具有低尾延迟和高可用性的存储系统。 |
| [^5] | [Predicting delays in Indian lower courts using AutoML and Decision Forests.](http://arxiv.org/abs/2307.16285) | 本文使用AutoML和决策森林构建了一个分类模型，通过案件信息预测印度下级法院的延迟。最佳模型的准确率为81.4％，该研究证明了基于相关数据点的AI模型在预测印度法院延迟方面的可行性。 |
| [^6] | [Recent Advances in Hierarchical Multi-label Text Classification: A Survey.](http://arxiv.org/abs/2307.16265) | 这篇论文调查了分层多标签文本分类的最新进展，包括数据集、方法、评估指标、学习策略和挑战，同时提供了未来研究方向。 |
| [^7] | [DRL4Route: A Deep Reinforcement Learning Framework for Pick-up and Delivery Route Prediction.](http://arxiv.org/abs/2307.16246) | DRL4Route是一种用于接送路线预测的深度强化学习框架，结合了深度学习模型的行为学习能力和强化学习的非可微分目标优化能力，解决了训练和测试标准不匹配的问题。 |
| [^8] | [Synaptic Plasticity Models and Bio-Inspired Unsupervised Deep Learning: A Survey.](http://arxiv.org/abs/2307.16236) | 本综述调查了一系列生物启发的突触可塑性模型在深度学习中的应用，并与脉冲神经网络中的可塑性模型进行了联系。生物启发深度学习代表了一个令人兴奋的研究方向，旨在推动当前技术的发展以及对智能的理解。 |
| [^9] | [Spiking Neural Networks and Bio-Inspired Supervised Deep Learning: A Survey.](http://arxiv.org/abs/2307.16235) | 这篇综述文章回顾了基于生物学启发的人工智能方法，介绍了脉冲神经网络模型，并讨论了脉冲神经网络训练的挑战以及生物启发的深度学习方法。 |
| [^10] | [Robust Electric Vehicle Balancing of Autonomous Mobility-On-Demand System: A Multi-Agent Reinforcement Learning Approach.](http://arxiv.org/abs/2307.16228) | 本文提出了一种基于多智能体强化学习的方法来解决电动车在自主移动出行系统中的平衡问题，并考虑了车辆供应和需求的不确定性。 |
| [^11] | [Text Analysis Using Deep Neural Networks in Digital Humanities and Information Science.](http://arxiv.org/abs/2307.16217) | 本论文研究了在数字人文研究中使用深度神经网络进行文本分析的挑战，包括训练数据的可用性和领域适应的需求。 |
| [^12] | [Question Answering with Deep Neural Networks for Semi-Structured Heterogeneous Genealogical Knowledge Graphs.](http://arxiv.org/abs/2307.16214) | 本研究提出一种用于家族谱问答的深度神经网络方法，该方法将家族谱数据表示为知识图并与非结构化文本结合，使用Transformer模型进行训练。这种方法解决了家族谱领域中模型无法处理图结构和缺乏训练数据集的问题。 |
| [^13] | [Robust Multi-Agent Reinforcement Learning with State Uncertainty.](http://arxiv.org/abs/2307.16212) | 本论文研究了在多智能体强化学习中状态不确定性的问题。通过引入状态扰动对手，将该问题建模为马尔可夫博弈，并提出了鲁棒均衡作为解决概念。 |
| [^14] | [Rethinking Uncertainly Missing and Ambiguous Visual Modality in Multi-Modal Entity Alignment.](http://arxiv.org/abs/2307.16210) | 在多模态实体对齐中，现有的方法忽视了视觉图像的不完整性和模糊性，本文通过分析表明模型在面对不完整性时容易出现过拟合和性能下降的问题。 |
| [^15] | [Around the GLOBE: Numerical Aggregation Question-Answering on Heterogeneous Genealogical Knowledge Graphs with Deep Neural Networks.](http://arxiv.org/abs/2307.16208) | 本文介绍了一种在异构家谱知识图谱上进行数字聚合问答的方法，在基因谱领域提出了自然语言问题并获得准确答案的能力还未被充分研究。 |
| [^16] | [Synthesizing Event-centric Knowledge Graphs of Daily Activities Using Virtual Space.](http://arxiv.org/abs/2307.16206) | 这项研究提出了使用虚拟空间合成以事件为中心的知识图谱的日常活动的方法，并指出了在理解日常生活的意图和上下文方面的困难和挑战。 |
| [^17] | [Shuffled Differentially Private Federated Learning for Time Series Data Analytics.](http://arxiv.org/abs/2307.16196) | 该论文介绍了一种针对时间序列数据的隐私保护联邦学习算法，通过使用局部差分隐私和洗牌技术，有效实现了在保护隐私的同时提高模型准确性。实验结果表明该方法在时间序列数据分析中具有良好的应用价值。 |
| [^18] | [ESP: Exploiting Symmetry Prior for Multi-Agent Reinforcement Learning.](http://arxiv.org/abs/2307.16186) | 本文提出了一种利用对称性先验知识的框架来解决多Agent强化学习中的数据效率问题，通过将数据增强和一致性损失集成到现有方法中，能够提高模型训练效率，并且泛化性能良好。 |
| [^19] | [Data-Driven Modeling with Experimental Augmentation for the Modulation Strategy of the Dual-Active-Bridge Converter.](http://arxiv.org/abs/2307.16173) | 本文介绍了一种基于实验增强的数据驱动建模方法，该方法通过结合仿真数据和实验数据来减轻模型差异，并在实践中提高准确性。 |
| [^20] | [HierVST: Hierarchical Adaptive Zero-shot Voice Style Transfer.](http://arxiv.org/abs/2307.16171) | HierVST是一个层次自适应的零样本语音风格转换模型，通过利用层次变分推断和自监督表示训练，该模型能够适应新的语音风格并逐步转换语音。实验结果表明，在零样本VST场景中，HierVST的性能优于其他VST模型。 |
| [^21] | [An Effective LSTM-DDPM Scheme for Energy Theft Detection and Forecasting in Smart Grid.](http://arxiv.org/abs/2307.16149) | 这篇论文提出了一种利用LSTM和DDPM相结合的方案来解决智能电网系统中的能量盗窃检测和预测问题。通过重构和预测误差，系统能够准确识别能量盗窃的实例，并在实验中表现出较好的性能。 |
| [^22] | [Fully $1\times1$ Convolutional Network for Lightweight Image Super-Resolution.](http://arxiv.org/abs/2307.16140) | 本论文提出了一种全卷积轻量级图像超分辨率网络，通过融合$3\times3$和$1\times1$卷积核的优点，以及引入无参数的空间平移操作，在保持计算效率的同时提高了网络的表示能力。 |
| [^23] | [User-Controlled Knowledge Fusion in Large Language Models: Balancing Creativity and Hallucination.](http://arxiv.org/abs/2307.16139) | 本文提出了一种用户可控的机制，用于调节大型语言模型在生成回应时创造力和对外部知识的忠诚度之间的平衡。这种机制通过在训练过程中引入数值标记，并使用自动化过程计算标记的程度，从而实现用户对模型的依赖程度的控制。 |
| [^24] | [Uncertainty-Encoded Multi-Modal Fusion for Robust Object Detection in Autonomous Driving.](http://arxiv.org/abs/2307.16121) | 本文提出了一种名为UMoE的方法，它将单模态的不确定性纳入了LiDAR-相机融合中，通过使用专家网络和门控网络来处理和分析多模态融合结果，以实现自动驾驶中稳健的目标检测。 |
| [^25] | [AI Increases Global Access to Reliable Flood Forecasts.](http://arxiv.org/abs/2307.16104) | 本研究开发了一个人工智能模型，可以准确预测未经测量流域的极端水文事件，从而提高了全球洪水预警的覆盖范围。 |
| [^26] | [PD-SEG: Population Disaggregation Using Deep Segmentation Networks For Improved Built Settlement Mask.](http://arxiv.org/abs/2307.16084) | 通过使用深度分割网络和卫星图像，PD-SEG实现了准确的人口统计，改进了以往在发展中国家准确度不高的情况。 |
| [^27] | [EnrichEvent: Enriching Social Data with Contextual Information for Emerging Event Extraction.](http://arxiv.org/abs/2307.16082) | 本文提出了一个利用词汇、语义和上下文表示的框架，旨在解决现有事件检测方法在识别新兴社交事件方面的局限性，并提供了对社交数据进行丰富的上下文化处理的方法。 |
| [^28] | [Marrying Dialogue Systems with Data Visualization: Interactive Data Visualization Generation from Natural Language Conversations.](http://arxiv.org/abs/2307.16013) | 本研究结合了对话系统与数据可视化，通过用户和系统之间的交互来生成数据可视化。研究首先构建了一个基准数据集，然后提出了一种多重方法来实现此任务。 |
| [^29] | [RoCar: A Relationship Network-based Evaluation Method to Large Language Models.](http://arxiv.org/abs/2307.15997) | RoCar是一种利用关系网络构建任务图并生成自然语言评估任务的方法，用于评估大型语言模型的推理和记忆能力。该方法通过极大的随机性确保了评估的公平性。 |
| [^30] | [UPFL: Unsupervised Personalized Federated Learning towards New Clients.](http://arxiv.org/abs/2307.15994) | 本文提出了一种无监督个性化联邦学习方法UPFL，解决了联邦学习中新客户加入时的个性化模型问题。 |
| [^31] | [Ultrasound Image Reconstruction with Denoising Diffusion Restoration Models.](http://arxiv.org/abs/2307.15990) | 本论文提出了一种利用去噪扩散恢复模型进行超声图像重建的方法，并在合成和PICMUS数据上进行了实验验证。实验结果显示，该方法可以从单个平面波中实现与DAS和最先进方法相媲美甚至更好的图像质量。 |
| [^32] | [Freespace Optical Flow Modeling for Automated Driving.](http://arxiv.org/abs/2307.15989) | 本论文提出了一种在碰撞自由空间中建模光流的策略，充分利用了三维驾驶环境中的几何信息，通过对多个数据集进行广泛的实验，实现了光流的明确表示和光流分量与垂直坐标之间的二次关系。 |
| [^33] | [You Can Backdoor Personalized Federated Learning.](http://arxiv.org/abs/2307.15971) | 该论文研究了后门攻击对个性化联邦学习的影响，并揭示了部分模型共享的个性化联邦学习方法容易受到后门攻击。研究者提出了三种后门攻击方法，并验证了它们的有效性。 |
| [^34] | [Graph Condensation for Inductive Node Representation Learning.](http://arxiv.org/abs/2307.15967) | 本论文提出了一种映射感知的图形压缩方法（MCond），通过学习节点之间的映射关系，实现了在合成图中高效地处理未知数据的能力。 |
| [^35] | [The effect of network topologies on fully decentralized learning: a preliminary investigation.](http://arxiv.org/abs/2307.15947) | 本研究通过分析不同网络拓扑结构对分布式学习模型性能的影响，揭示了节点连接性和网络属性在知识传播过程中的不同作用。结果表明，高连接性可能导致更好的模型性能。 |
| [^36] | [A Theory for Emergence of Complex Skills in Language Models.](http://arxiv.org/abs/2307.15936) | 本文提出了一个统计框架，通过分析语言模型的交叉熵损失与基本语言任务的能力之间的关系，揭示了语言模型中复杂技能产生的机制。研究结果表明，通过扩展定律，预训练模型能够高效学习，并表现出违反通常泛化理论的能力。 |
| [^37] | [ATESA-B{\AE}RT: A Heterogeneous Ensemble Learning Model for Aspect-Based Sentiment Analysis.](http://arxiv.org/abs/2307.15920) | ATESA-B{\AE}RT是一个基于方面的情感分析的异构集成学习模型，通过将问题分为方面词提取和方面词情感分析两个子任务，并使用\textit{argmax}多类别分类算法进行分析，提高了在方面级别上的粒度，改进了当前解决方案在多方面数据上的性能问题。 |
| [^38] | [Opportunistic Air Quality Monitoring and Forecasting with Expandable Graph Neural Networks.](http://arxiv.org/abs/2307.15916) | 提出了一种可扩展的图神经网络模型，能够处理不同空间结构的已有和新增基础设施收集的环境空气质量数据，并嵌入到任何空气质量预测模型中应用于具有演变空间结构的场景。 |
| [^39] | [Moisesdb: A dataset for source separation beyond 4-stems.](http://arxiv.org/abs/2307.15913) | 本文介绍了MoisesDB数据集，该数据集用于音乐源分离。它包含240首来自45位艺术家的曲目，涵盖了十二种音乐流派。该数据集具有两级层次分类法，超越了使用四个音频源的限制，有助于构建和评估细粒度的源分离系统。研究还提供了基线结果和分析，对于不同分离细粒度的开源分离模型的评估。 |
| [^40] | [Reinforcement Learning Under Probabilistic Spatio-Temporal Constraints with Time Windows.](http://arxiv.org/abs/2307.15910) | 我们提出了一种自动机理论方法来解决具有时间窗口的复杂时空约束下的强化学习问题，该方法能在整个学习过程中始终保持所需约束满足的概率。 |
| [^41] | [UniBriVL: Robust Universal Representation and Generation of Audio Driven Diffusion Models.](http://arxiv.org/abs/2307.15898) | 本文提出了一种名为UniBriVL的新型通用语言表示学习方法，该方法实现了音频驱动的扩散模型的生成。它能够稳健地学习语言表示，并捕捉到音频和图像之间的关联。实验结果表明UniBriVL在下游任务中表现出良好的效果，能够从音频中选择合适的图像。 |
| [^42] | [A new Gradient TD Algorithm with only One Step-size: Convergence Rate Analysis using $L$-$\lambda$ Smoothness.](http://arxiv.org/abs/2307.15892) | 本论文提出了一种新的梯度时序差分算法，只使用一个步长参数，并证明收敛速度至少为$O(1/t)$。 |
| [^43] | [Recent neutrino oscillation result with the IceCube experiment.](http://arxiv.org/abs/2307.15855) | 冰立方实验使用卷积神经网络重建了中微子相互作用，取得了物理灵敏度的进展，并展示了中微子振荡的最新结果。 |
| [^44] | [Dimensionless Policies based on the Buckingham $\pi$ Theorem: Is it a good way to Generalize Numerical Results?.](http://arxiv.org/abs/2307.15852) | 通过使用无量纲变量和制度的概念，我们可以将数值生成的最优控制法则推广到量纲相似的系统，这对于推广解决更复杂的高维问题的策略具有潜在意义。 |
| [^45] | [Comprehensive Algorithm Portfolio Evaluation using Item Response Theory.](http://arxiv.org/abs/2307.15850) | 本文提出了一种改进的基于IRT的框架，用于评估算法组合在数据集仓库中的性能，同时获取算法一致性和异常性等特征。该框架通过对传统IRT模型进行倒转和重新解释来实现，不需要额外的数据集特征计算。 |
| [^46] | [Primitive Skill-based Robot Learning from Human Evaluative Feedback.](http://arxiv.org/abs/2307.15801) | 基于人类评价反馈的原始技能导向机器人学习框架（SEED）结合了从人类反馈中进行强化学习（RLHF）和基于原始技能的强化学习，有效解决了稀疏奖励和长时程任务复杂性问题，并提高了学习效率和安全性。 |
| [^47] | [Summaries, Highlights, and Action items: Design, implementation and evaluation of an LLM-powered meeting recap system.](http://arxiv.org/abs/2307.15793) | 这项研究设计、实现和评估了一种基于LLM的会议总结系统，通过减少个人会议负担和增加会议输出的清晰度和一致性，提高了会议体验。 |
| [^48] | [SAFE: Saliency-Aware Counterfactual Explanations for DNN-based Automated Driving Systems.](http://arxiv.org/abs/2307.15786) | 本文提出了一种基于显著性图的方法，来生成更具信息性的CF解释，用于解释DNN自动驾驶系统的决策过程。 |
| [^49] | [LLM-Rec: Personalized Recommendation via Prompting Large Language Models.](http://arxiv.org/abs/2307.15780) | 本文通过引导大型语言模型进行个性化推荐的研究，提出了四种不同的引导策略，并通过实验证明了这些策略的有效性。这一发现强调了在个性化内容推荐中，采用多样的引导和输入增强技术可以提高大型语言模型的推荐性能。 |
| [^50] | [Spherical and Hyperbolic Toric Topology-Based Codes On Graph Embedding for Ising MRF Models: Classical and Quantum Topology Machine Learning.](http://arxiv.org/abs/2307.15778) | 本论文介绍了在图嵌入中应用信息几何来描述Ising模型的基态，通过利用球面和双曲面拓扑上的编码，建立了机器学习和纠错编码之间的联系，并通过优化纠错码和发展嵌入方法提出了一种新的编码方法。 |
| [^51] | [Select and Augment: Enhanced Dense Retrieval Knowledge Graph Augmentation.](http://arxiv.org/abs/2307.15776) | 本文提出了一种选择和增强的方法来改进文本增强的知识图谱嵌入，通过多任务框架选择相关的文本描述，并对知识图谱嵌入进行对齐或增强。 |
| [^52] | [The Hydra Effect: Emergent Self-repair in Language Model Computations.](http://arxiv.org/abs/2307.15771) | 本研究通过因果分析探究了语言模型计算的内部结构，发现了Hydra效应和晚期MLP层的平衡功能，并分析了它们在语言模型中的影响。 |
| [^53] | [CHATREPORT: Democratizing Sustainability Disclosure Analysis through LLM-based Tools.](http://arxiv.org/abs/2307.15770) | 本论文介绍了一种名为ChatReport的基于LLM的系统，它通过实现可追溯的答案和解决领域专家参与低效性的问题，旨在通过自动分析企业可持续性报告，实现可持续性披露分析民主化。 |
| [^54] | [Lessons in Reproducibility: Insights from NLP Studies in Materials Science.](http://arxiv.org/abs/2307.15759) | 这两篇论文对于材料科学领域的NLP研究提供了重要的可再现性分析，其中包括了详尽的工作流程、整洁的代码库和清晰的模型评估指导，为未来的材料科学出版物树立了良好的标准。 |
| [^55] | [AI for Anticipatory Action: Moving Beyond Climate Forecasting.](http://arxiv.org/abs/2307.15727) | AI用于预测行动从气候预测向预测行动转变，利用机器学习模型的强大能力，在评估气候对特定人口的影响方面填补了方法论上的差距，以推进对气候变化最脆弱人口的灾害响应。 |
| [^56] | [Curiosity-Driven Reinforcement Learning based Low-Level Flight Control.](http://arxiv.org/abs/2307.15724) | 本文提出了一种基于好奇心驱动的算法，通过从里程数据生成适当的电机速度来实现自主学习以控制飞行。通过该算法，四旋翼飞行器可以在控制偏航方向朝向目标位置的同时通过障碍物，该算法基于预测误差的新的好奇心方法。 |
| [^57] | [Agent-Based Model: Simulating a Virus Expansion Based on the Acceptance of Containment Measures.](http://arxiv.org/abs/2307.15723) | 该论文提出了一种基于代理模型的方法来模拟病毒扩展，并结合个体特征和人口行为，以评估遏制措施的影响。 |
| [^58] | [Utilizing Large Language Models for Natural Interface to Pharmacology Databases.](http://arxiv.org/abs/2307.15717) | 该论文介绍了一种利用大型语言模型的自然语言界面，旨在与药理学数据库中的结构化信息进行交互，具有广泛的应用价值。 |
| [^59] | [Improving Primary Healthcare Workflow Using Extreme Summarization of Scientific Literature Based on Generative AI.](http://arxiv.org/abs/2307.15715) | 本研究利用生成式人工智能技术对科学论文的摘要进行极端摘要化，旨在帮助初级保健专业人员减轻认知负荷，从而提高其工作效率和减少心理负担。 |
| [^60] | [Multiple Instance Learning Framework with Masked Hard Instance Mining for Whole Slide Image Classification.](http://arxiv.org/abs/2307.15254) | 这篇论文提出了一种带有掩码困难实例挖掘的多示例学习框架，用于全切片图像分类。该框架通过使用共享学习结构和一致性约束来探索潜在的难以分类的实例，并通过动量教师隐式挖掘这些实例来训练学生模型，从而提高分类性能。 |
| [^61] | [Information Gained Subgroup Discovery in Datasets.](http://arxiv.org/abs/2307.15089) | 该论文研究了在数据集中通过信息提升的方法进行子群发现。具体针对肺癌治疗，在保持或提高治疗效果的同时减少副作用对于改善患者的生活质量非常重要，临床指南虽然提供了治疗建议，但仍未将治疗结果纳入考量。 |
| [^62] | [Argument Attribution Explanations in Quantitative Bipolar Argumentation Frameworks.](http://arxiv.org/abs/2307.13582) | 本文提出了一个新的“论证归因解释（AAEs）”理论，用于确定论证对“主题论证”产生的影响，在定量双极论证框架（QBAFs）中填补了解释定量推理结果的空白。 |
| [^63] | [Graph Neural Networks For Mapping Variables Between Programs -- Extended Version.](http://arxiv.org/abs/2307.13014) | 本文提出了使用图神经网络(GNNs)基于程序的抽象语法树(ASTs)来映射变量集，以解决程序比较、分析、修复和克隆检测等任务。在初学者编程作业中进行的实验证明了变量映射的有效性。 |
| [^64] | [Applying QNLP to sentiment analysis in finance.](http://arxiv.org/abs/2307.11788) | 本论文研究了在金融行业中应用量子自然语言处理(QNLP)进行情感分析的实际适用性。利用一种新颖的数据生成方法，我们发现量子增强的长短期记忆(QLSTM)可以更快地训练，并且在软件实现方面接近古典结果。 |
| [^65] | [ESMC: Entire Space Multi-Task Model for Post-Click Conversion Rate via Parameter Constraint.](http://arxiv.org/abs/2307.09193) | 该论文提出了ESMC模型，通过参数约束来解决大规模在线推荐系统中点击后转化率估计中的样本选择偏差和数据稀疏性问题。此外，通过扩展决策路径，该模型可以更好地捕捉用户的决策意图，并提高推荐性能。 |
| [^66] | [Multi-Stage Cable Routing through Hierarchical Imitation Learning.](http://arxiv.org/abs/2307.08927) | 本研究探讨了多阶段电缆布线任务中的层次化模仿学习方法，解决了处理可变形物体、视觉感知闭环和扩展行为的挑战。成功控制器需要能够从失败中恢复，并通过选择纠正低级控制器的缺陷。 |
| [^67] | [DeepIPCv2: LiDAR-powered Robust Environmental Perception and Navigational Control for Autonomous Vehicle.](http://arxiv.org/abs/2307.06647) | DeepIPCv2是一种利用LiDAR传感器感知环境的自动驾驶模型，通过使用点云作为感知输入，在各种条件下实现了更强大的驾驶性能。 |
| [^68] | [GP-guided MPPI for Efficient Navigation in Complex Unknown Cluttered Environments.](http://arxiv.org/abs/2307.04019) | 本研究提出了一种GP引导的MPPI方法用于在复杂未知杂乱环境中进行高效导航。该方法利用局部感知模型和在线学习技术，通过构建不确定性表面，识别并推荐最优子目标给局部的MPPI规划器。最终实现了满足要求的最优控制序列。 |
| [^69] | [Offline Reinforcement Learning with Imbalanced Datasets.](http://arxiv.org/abs/2307.02752) | 本文提出了一种在不平衡数据集中的新型离线强化学习方法，通过将CQL与回溯过程相结合来提取策略，从而有效地解决了不平衡数据集带来的挑战。 |
| [^70] | [Scalable Neural Contextual Bandit for Recommender Systems.](http://arxiv.org/abs/2306.14834) | 本研究提出了一种可扩展的神经上下文Bandit算法，通过设计Epistemic Neural Recommendation (ENR)网络结构，实现了大规模的Thompson抽样，显著提高了推荐系统的点击率和用户评分。 |
| [^71] | [G-NM: A Group of Numerical Time Series Prediction Models.](http://arxiv.org/abs/2306.11667) | G-NM是一组集合了传统和现代模型的数字时间序列预测模型，旨在提高对复杂自然现象中的模式和趋势的预测能力。 |
| [^72] | [Enlighten-anything:When Segment Anything Model Meets Low-light Image Enhancement.](http://arxiv.org/abs/2306.10286) | 本文提出了Enlighten-anything，在低光图像增强中将分段模型与SAM融合，实现了良好视觉感知的融合图像。 |
| [^73] | [Hexatagging: Projective Dependency Parsing as Tagging.](http://arxiv.org/abs/2306.05477) | 六边形标注器是一种新颖的依存分析器，可以在训练时实现完全并行化，具有线性时间复杂度和空间复杂度。使用预训练语言模型的特征进行预测。在 Penn Treebank 测试集上取得了最先进的性能。 |
| [^74] | [Take the Hint: Improving Arabic Diacritization with Partially-Diacritized Text.](http://arxiv.org/abs/2306.03557) | 本文提出了一个名为2SDiac的多源模型，可以在输入中使用可选音标来确定所有预测的输出，然后通过引入Guided Learning的训练策略，利用随机掩蔽和给定的输入音标提升标记的正确性。实验表明，该方法在非标记文本上表现良好，并实现了最先进的结果。 |
| [^75] | [From Robustness to Explainability and Back Again.](http://arxiv.org/abs/2306.03048) | 本文介绍了一种解决形式解释可扩展性限制的新算法，通过回答鲁棒性查询来计算解释，并建立了形式解释复杂性和鲁棒性复杂性之间的直接关系。 |
| [^76] | [A Survey on ChatGPT: AI-Generated Contents, Challenges, and Solutions.](http://arxiv.org/abs/2305.18339) | 本论文探讨了AI生成内容的工作原理、安全与隐私威胁、现状和未来挑战，并提供了针对这些问题的最新解决方案。 |
| [^77] | [Optimization's Neglected Normative Commitments.](http://arxiv.org/abs/2305.17465) | 本文描述了使用优化的规范选择和假设，并指出了可能被忽视的包括任务遗漏、决策边界问题以及多个代理的目标冲突在内的六个问题。 |
| [^78] | [Science in the Era of ChatGPT, Large Language Models and Generative AI: Challenges for Research Ethics and How to Respond.](http://arxiv.org/abs/2305.15299) | 这篇论文回顾了生成AI对科学研究所带来的认识论挑战、伦理和诚信风险，并提出了十项建议，以在AI时代促进更负责任的研究进行。 |
| [^79] | [Flying Adversarial Patches: Manipulating the Behavior of Deep Learning-based Autonomous Multirotors.](http://arxiv.org/abs/2305.12859) | 该论文介绍了一种称为飞行对抗贴片的方法，利用神经网络的弱点，通过在飞行中携带的图像来操纵自主多旋翼的行为，实现对受害多旋翼的完全控制。 |
| [^80] | [SelfzCoT: a Self-Prompt Zero-shot CoT from Semantic-level to Code-level for a Better Utilization of LLMs.](http://arxiv.org/abs/2305.11461) | 本文提出了 SelfzCoT 自动自我生成的零样本编码，通过使用LLMs和代码级别的自我提示，在六个零样本算术推理任务中实现了巨大的准确度提升。同时，修改的零样本编码 MzCoT 在推理任务中也取得了显著的表现。 |
| [^81] | [On Strategies in Synthesis Over Finite Traces.](http://arxiv.org/abs/2305.08319) | 本研究显示，相较于终止自动机，在LTLf模型检查中使用非终止自动机会更加困难。 |
| [^82] | [Are Large Language Models Ready for Healthcare? A Comparative Study on Clinical Language Understanding.](http://arxiv.org/abs/2304.05368) | 本研究全面评估了大型语言模型在临床语言理解任务上的表现，并引入自问自答提示策略来提高LLMs在医疗保健相关任务中的效果。 |
| [^83] | [ChatGPT for Shaping the Future of Dentistry: The Potential of Multi-Modal Large Language Model.](http://arxiv.org/abs/2304.03086) | 本文讨论了利用LLMs在牙科临床领域实现自动化和跨模态诊断的可能性，介绍了利用跨模态编码器进行高级自然语言推理的多模态LLM AI系统，展示了其在牙科临床中的巨大潜力。 |
| [^84] | [Interpretable Motion Planner for Urban Driving via Hierarchical Imitation Learning.](http://arxiv.org/abs/2303.13986) | 本文提出一种基于分层模仿学习的运动规划方法，包括高层行为规划和低层轨迹规划。通过在仿真和实际驾驶中的测试，证明了该方法在城市自动驾驶中具有出色的性能。 |
| [^85] | [ICICLE: Interpretable Class Incremental Continual Learning.](http://arxiv.org/abs/2303.07811) | ICICLE提出了一种基于样本的可解释的类增量连续学习方法，通过采用原型部分化方法来解决解释性概念漂移的问题，实验结果表明其在不需要样本的情况下表现优于现有的方法。 |
| [^86] | [A Hybrid Architecture for Out of Domain Intent Detection and Intent Discovery.](http://arxiv.org/abs/2303.04134) | 本研究提出了一种混合架构来解决任务导向型对话系统中领域外意图检测和意图发现的问题。通过使用变分自编码器和无监督聚类方法，可以准确识别和区分已知和未知的意图，并发现潜藏在领域外输入中的不同未知意图。 |
| [^87] | [TopSpark: A Timestep Optimization Methodology for Energy-Efficient Spiking Neural Networks on Autonomous Mobile Agents.](http://arxiv.org/abs/2303.01826) | TopSpark提出了一种时间步长优化方法，用于提高自主移动机器人上脉冲神经网络的能量效率。该方法消除了固定时间步长的限制，使得SNNs能够在训练和推断阶段都实现更高的能量效率，并且能够在运行时进行高效的在线学习。 |
| [^88] | [Understanding the Diffusion Objective as a Weighted Integral of ELBOs.](http://arxiv.org/abs/2303.00848) | 本文深入理解了扩散目标，并揭示了加权损失和ELBO目标之间的直接关系。 |
| [^89] | [Get Your Act Together: A Comparative View on Transparency in the AI Act and Technology.](http://arxiv.org/abs/2302.10766) | 该论文比较了欧盟提出的《人工智能法案》和可解释AI（XAI）对于透明度和解释性的基本定义，强调了将这些定义对齐的重要性，以确保技术实践符合法规。 |
| [^90] | [Arena-Rosnav 2.0: A Development and Benchmarking Platform for Robot Navigation in Highly Dynamic Environments.](http://arxiv.org/abs/2302.10023) | Arena-Rosnav 2.0是一个用于开发和基准测试机器人导航方法的平台，它提供了统一的API和更真实的模拟，通过用户研究和集成最新的导航方法验证了其可行性。 |
| [^91] | [Referential communication in heterogeneous communities of pre-trained visual deep networks.](http://arxiv.org/abs/2302.08913) | 异构视觉深度网络社区中的预训练网络可以自我监督地开发出共享协议，以指代一组目标中的目标对象，并可用于沟通不同粒度的未知对象类别。 |
| [^92] | [Designing Data: Proactive Data Collection and Iteration for Machine Learning.](http://arxiv.org/abs/2301.10319) | 这篇论文介绍了一种设计数据的迭代方法，将人机交互概念与机器学习技术相结合，以解决机器学习应用中数据收集缺乏多样性导致的失败问题。通过预收集计划、收集监控和数据熟悉度等步骤，该方法可以提高模型的泛化能力并在跨组交叉群体上取得更好的结果。 |
| [^93] | [SpArX: Sparse Argumentative Explanations for Neural Networks.](http://arxiv.org/abs/2301.09559) | 该论文提出了一种稀疏的神经网络论证解释方法SpArX，通过利用多层感知器和定量论证框架之间的关系，可以为神经网络的决策过程提供更忠实和深入的解释。 |
| [^94] | [ACQ: Improving Generative Data-free Quantization Via Attention Correction.](http://arxiv.org/abs/2301.07266) | 本论文提出了ACQ方法，通过修正合成样本的注意力，改进了生成式无数据量化方法。通过建立注意力中心位置的条件生成器，实现了类内关注度的均一化。 |
| [^95] | [MEAformer: Multi-modal Entity Alignment Transformer for Meta Modality Hybrid.](http://arxiv.org/abs/2212.14454) | 该论文提出了一种适用于元模态混合的多模式实体对齐变压器方法，通过动态预测模态之间的相互关联系数以进行实体级特征聚合，进一步提出了一种模态感知的硬实体重播策略，用于解决模糊实体细节的问题。该模型在多个训练场景中实现了SOTA性能并有效提高了MMEA的鲁棒性。 |
| [^96] | [Enhancing Task Bot Engagement with Synthesized Open-Domain Dialog.](http://arxiv.org/abs/2212.10008) | 本论文提出了一种通过合成开放领域对话来增强任务机器人的参与度的框架，并介绍了一种统一模型PivotBot，该模型能够无缝切换任务导向对话和开放领域对话，在处理融合任务方面具有优越能力。 |
| [^97] | [The European AI Liability Directives -- Critique of a Half-Hearted Approach and Lessons for the Future.](http://arxiv.org/abs/2211.13960) | 这篇论文对欧洲AI责任指令的提案进行了详细研究，发现其代表了一个半心态的方法，并提出了三个创新贡献。 |
| [^98] | [How to Boost Face Recognition with StyleGAN?.](http://arxiv.org/abs/2210.10090) | 本文介绍了如何利用StyleGAN来提升人脸识别的效果，包括针对身份有限的数据问题进行的改进以及通过生成模型进行数据扩增的方法。在实验中，我们使用了大规模的无标签数据集，证明了这种方法的有效性。 |
| [^99] | [Patching Weak Convolutional Neural Network Models through Modularization and Composition.](http://arxiv.org/abs/2209.06116) | 本文提出了一种通过压缩模块化和组合来修补卷积神经网络模型的弱点的方法，该方法无需重新训练整个模型，并在多个基准数据集上实现了与最先进方法相当甚至更好的结果。 |
| [^100] | [SAFARI: Versatile and Efficient Evaluations for Robustness of Interpretability.](http://arxiv.org/abs/2208.09418) | 本文提出了一种名为SAFARI的方法，用于评估深度学习的解释可靠性。该方法针对现有技术无法解决的几个挑战，通过引入两种黑盒评估方法，即最坏情况解释差异和一般情况下的鲁棒性的概率概念，来解决现有度量不全面、XAI技术异质性和误解罕见性等问题。使用遗传算法和子集模拟进行评估。 |
| [^101] | [Causal Discovery and Knowledge Injection for Contestable Neural Networks.](http://arxiv.org/abs/2205.09787) | 本研究提出了一种可以进行双向互动的方法，通过允许神经网络展示其所学因果图，并允许人类修改因果图后重新注入机器中，从而提供了一种调试神经网络的方式，实验结果显示该方法可以显著改善预测性能。 |
| [^102] | [Exploring the Benefits of Teams in Multiagent Learning.](http://arxiv.org/abs/2205.02328) | 本文提出了一种基于组织心理学和人工智能早期工作的新模型，用于多智能体强化学习中的团队，通过复杂社交困境的验证，发现分成团队的智能体能够发展合作的政策，能够更好地协调和学习团队内的新兴角色，并获得更高的奖励。 |
| [^103] | [Explainability in Process Outcome Prediction: Guidelines to Obtain Interpretable and Faithful Models.](http://arxiv.org/abs/2203.16073) | 本文介绍了在过程结果预测中应用解释性模型的指南，并通过对事件、案例和控制流的分析，通过实验评估了不同模型的解释性能力。 |
| [^104] | [BoMD: Bag of Multi-label Descriptors for Noisy Chest X-ray Classification.](http://arxiv.org/abs/2203.01937) | 本文提出了一种适用于多标签、嘈杂CXR学习的方法，使用基于袋的多标签描述符平滑地重新标记数据集中的样本，并进行训练以提高模型性能。 |
| [^105] | [Reasoning Through Memorization: Nearest Neighbor Knowledge Graph Embeddings.](http://arxiv.org/abs/2201.05575) | 本文提出了一种新的知识图嵌入方法kNN-KGE，它通过预训练语言模型和最近邻的线性插值，允许罕见或新出现的实体被明确地记忆，而不是隐藏在模型参数中。实验结果显示，该方法能够改善链接预测结果并在低资源环境中表现出更好的性能。 |
| [^106] | [Deep Exploration for Recommendation Systems.](http://arxiv.org/abs/2109.12509) | 本文提出了一种深度探索方法以解决推荐系统中奖励稀少时的问题，并在高保真度的工业级模拟器下进行了实验，证明了该算法相比现有算法有很大的提升。 |
| [^107] | [Reverse Engineering of Generative Models: Inferring Model Hyperparameters from Generated Images.](http://arxiv.org/abs/2106.07873) | 本研究提出了一种逆向工程生成模型的方法，通过分析生成的图像来推断模型的超参数，以识别和理解生成模型的潜在滥用。通过指纹估计网络和解析网络，我们能够从生成的图像中预测生成模型的网络架构和训练损失函数。 |

# 详细

[^1]: AI助力的恶意社交机器人网络解剖

    Anatomy of an AI-powered malicious social botnet. (arXiv:2307.16336v1 [cs.CY])

    [http://arxiv.org/abs/2307.16336](http://arxiv.org/abs/2307.16336)

    本文通过案例研究揭示了使用AI语言模型生成人类内容的Twitter机器人网络。这些机器人账号构成了一个密集的虚假人物群集，宣传可疑网站并传播有害评论。

    

    大型语言模型（LLM）在生成各种主题上的逼真文本方面表现出令人印象深刻的能力。有人担心它们可能被用于生成带有欺骗意图的虚假内容，尽管迄今为止的证据仍是片面的。本文通过一个关于Twitter机器人网络的案例研究，阐述了似乎采用ChatGPT生成类似人类内容的机器人网络。通过启发式方法，我们识别出1140个账号，并通过手动注释对其进行验证。这些账号形成了一个密集的虚假人物群集，表现出类似的行为，包括发布机器生成的内容和盗用图片，并通过回复和转发来互相交流。ChatGPT生成的内容宣传可疑网站并传播有害评论。虽然AI机器人网络中的账号可以通过它们的协调模式进行检测，但目前最先进的LLM内容分类器无法将它们与野外的人类账号区分开来。这些发现突显了恶意社交机器人网络的威胁。

    Large language models (LLMs) exhibit impressive capabilities in generating realistic text across diverse subjects. Concerns have been raised that they could be utilized to produce fake content with a deceptive intention, although evidence thus far remains anecdotal. This paper presents a case study about a Twitter botnet that appears to employ ChatGPT to generate human-like content. Through heuristics, we identify 1,140 accounts and validate them via manual annotation. These accounts form a dense cluster of fake personas that exhibit similar behaviors, including posting machine-generated content and stolen images, and engage with each other through replies and retweets. ChatGPT-generated content promotes suspicious websites and spreads harmful comments. While the accounts in the AI botnet can be detected through their coordination patterns, current state-of-the-art LLM content classifiers fail to discriminate between them and human accounts in the wild. These findings highlight the thr
    
[^2]: 代表和推理多利益相关者的定性偏好查询

    Representing and Reasoning with Multi-Stakeholder Qualitative Preference Queries. (arXiv:2307.16307v1 [cs.AI])

    [http://arxiv.org/abs/2307.16307](http://arxiv.org/abs/2307.16307)

    这篇论文提供了第一个关于利用定性偏好进行多利益相关者推理的形式化方法，并介绍了一种查询语言和多种查询的替代语义，还提供了一个通过模型检验回答查询的算法。

    

    许多决策场景，如公共政策，医疗保健，商业和灾难响应，需要顾及多个利益相关者的偏好。在利益相关者用定性偏好语言（如CP-net，CI-net，TCP-net，CP-Theory）表达其偏好的情况下，我们提供了第一个关于用多利益相关者的定性偏好进行推理的形式化方法。我们引入了一种查询语言，用于对满足指定条件的结果集进行查询，例如$\mlangpref{\psi_1}{\psi_2}{A}$（读作由利益相关者组合$A$优选于满足$\psi_2$的结果所组成的满足$\psi_1$的结果集）。受实际应用场景的启发，我们引入并分析了几种查询的替代语义，并研究了它们之间的相互关系。我们提供了一个经过验证正确的算法，使用模型检验来回答多利益相关者的定性偏好查询。

    Many decision-making scenarios, e.g., public policy, healthcare, business, and disaster response, require accommodating the preferences of multiple stakeholders. We offer the first formal treatment of reasoning with multi-stakeholder qualitative preferences in a setting where stakeholders express their preferences in a qualitative preference language, e.g., CP-net, CI-net, TCP-net, CP-Theory. We introduce a query language for expressing queries against such preferences over sets of outcomes that satisfy specified criteria, e.g., $\mlangpref{\psi_1}{\psi_2}{A}$ (read loosely as the set of outcomes satisfying $\psi_1$ that are preferred over outcomes satisfying $\psi_2$ by a set of stakeholders $A$). Motivated by practical application scenarios, we introduce and analyze several alternative semantics for such queries, and examine their interrelationships. We provide a provably correct algorithm for answering multi-stakeholder qualitative preference queries using model checking in alternat
    
[^3]: 在微塑料废弃物的边缘检测实现中

    Implementing Edge Based Object Detection For Microplastic Debris. (arXiv:2307.16289v1 [cs.CV])

    [http://arxiv.org/abs/2307.16289](http://arxiv.org/abs/2307.16289)

    本论文研究了微塑料废弃物的边缘检测实现，提出了采用计算机视觉和机器人附件的方法来增强手动分拣操作和检测的解决方案。

    

    塑料已经成为我们日常活动中不可或缺的一部分，由于其不可分解的性质和更便宜的生产价格，它成为了问题的根源。随之而来的问题是如何应对或减轻其处置或缺乏适当处理后的后果，这会导致废物在某些地方积聚，并扰乱植物和动物的生态系统。随着塑料废弃物水平的不断上升，并且废物在垃圾填埋场和更危险的天然水体中积累，需要迅速采取行动来阻止或停止这种流动。虽然手动分拣操作和检测可以提供解决方案，但可以借助与机器人附件关联的高度先进的计算机图像来增强它们。本报告的主要关注应用是备受关注的计算机视觉和开放视觉，它们因其对互联网的轻度依赖性和传输信息的能力而获得了新颖性。

    Plastic has imbibed itself as an indispensable part of our day to day activities, becoming a source of problems due to its non-biodegradable nature and cheaper production prices. With these problems, comes the challenge of mitigating and responding to the aftereffects of disposal or the lack of proper disposal which leads to waste concentrating in locations and disturbing ecosystems for both plants and animals. As plastic debris levels continue to rise with the accumulation of waste in garbage patches in landfills and more hazardously in natural water bodies, swift action is necessary to plug or cease this flow. While manual sorting operations and detection can offer a solution, they can be augmented using highly advanced computer imagery linked with robotic appendages for removing wastes. The primary application of focus in this report are the much-discussed Computer Vision and Open Vision which have gained novelty for their light dependence on internet and ability to relay informatio
    
[^4]: 实现存储系统学习预测性的探索

    Towards Learned Predictability of Storage Systems. (arXiv:2307.16288v1 [cs.DB])

    [http://arxiv.org/abs/2307.16288](http://arxiv.org/abs/2307.16288)

    本论文探索了实现存储系统学习预测性的方法，通过提前检测缓慢的IO请求和预测设备故障，以构建具有低尾延迟和高可用性的存储系统。

    

    随着云计算和大数据技术的快速发展，存储系统已成为数据中心的基本构建单元，结合了闪存固态硬盘和非易失性内存等硬件创新，以及RAID和分布式文件系统等软件基础设施。尽管存储的受欢迎程度和兴趣不断增长，但由于性能不稳定性和硬件故障的普遍存在，设计和实现可靠的存储系统仍然具有挑战性。积极预测能极大增强存储系统的可靠性。预测有两个维度：性能和故障。理想情况下，通过提前检测缓慢的IO请求，并在设备真正发生故障之前预测故障，我们可以构建具有特别低尾延迟和高可用性的存储系统。尽管它的重要性得到了广泛认可，但存储系统中的这种积极预测却特别困难。

    With the rapid development of cloud computing and big data technologies, storage systems have become a fundamental building block of datacenters, incorporating hardware innovations such as flash solid state drives and non-volatile memories, as well as software infrastructures such as RAID and distributed file systems. Despite the growing popularity and interests in storage, designing and implementing reliable storage systems remains challenging, due to their performance instability and prevailing hardware failures.  Proactive prediction greatly strengthens the reliability of storage systems. There are two dimensions of prediction: performance and failure. Ideally, through detecting in advance the slow IO requests, and predicting device failures before they really happen, we can build storage systems with especially low tail latency and high availability. While its importance is well recognized, such proactive prediction in storage systems, on the other hand, is particularly difficult. 
    
[^5]: 使用AutoML和决策森林预测印度下级法院的延迟

    Predicting delays in Indian lower courts using AutoML and Decision Forests. (arXiv:2307.16285v1 [cs.LG])

    [http://arxiv.org/abs/2307.16285](http://arxiv.org/abs/2307.16285)

    本文使用AutoML和决策森林构建了一个分类模型，通过案件信息预测印度下级法院的延迟。最佳模型的准确率为81.4％，该研究证明了基于相关数据点的AI模型在预测印度法院延迟方面的可行性。

    

    本文提出了一个分类模型，根据案件在提交时可得到的信息,来预测印度下级法院的延迟。该模型建立在2010年提交的420万个法院案件及其在10年期间的结果的数据集上。数据集来自印度的7000多个下级法院。作者采用AutoML开发了一个多类别分类模型，覆盖了所有等待期，并使用二进制决策森林分类器提高了延迟分类的预测准确性。最佳模型的准确率达到81.4％，精确度、召回率和F1分别为0.81。研究证明了基于相关数据点（如辖区、法院、法官、主题和相关方）的AI模型在预测印度法院延迟方面的可行性。本文还讨论了相关文献的结果，并提出了改进和未来研究的方向。作者已提供数据集和Python代码文件。

    This paper presents a classification model that predicts delays in Indian lower courts based on case information available at filing. The model is built on a dataset of 4.2 million court cases filed in 2010 and their outcomes over a 10-year period. The data set is drawn from 7000+ lower courts in India. The authors employed AutoML to develop a multi-class classification model over all periods of pendency and then used binary decision forest classifiers to improve predictive accuracy for the classification of delays. The best model achieved an accuracy of 81.4%, and the precision, recall, and F1 were found to be 0.81. The study demonstrates the feasibility of AI models for predicting delays in Indian courts, based on relevant data points such as jurisdiction, court, judge, subject, and the parties involved. The paper also discusses the results in light of relevant literature and suggests areas for improvement and future research. The authors have made the dataset and Python code files u
    
[^6]: 分层多标签文本分类的最新进展：一项调查

    Recent Advances in Hierarchical Multi-label Text Classification: A Survey. (arXiv:2307.16265v1 [cs.CL])

    [http://arxiv.org/abs/2307.16265](http://arxiv.org/abs/2307.16265)

    这篇论文调查了分层多标签文本分类的最新进展，包括数据集、方法、评估指标、学习策略和挑战，同时提供了未来研究方向。

    

    分层多标签文本分类旨在将输入的文本分为多个标签，其中标签之间具有结构和层次关系。它是许多现实世界应用中的重要任务，例如科学文献归档。本文调查了分层多标签文本分类的最新进展，包括开源数据集、主要方法、评估指标、学习策略和当前的挑战。还列举了几个未来研究方向，供研究者进一步改进这个领域。

    Hierarchical multi-label text classification aims to classify the input text into multiple labels, among which the labels are structured and hierarchical. It is a vital task in many real world applications, e.g. scientific literature archiving. In this paper, we survey the recent progress of hierarchical multi-label text classification, including the open sourced data sets, the main methods, evaluation metrics, learning strategies and the current challenges. A few future research directions are also listed for community to further improve this field.
    
[^7]: DRL4Route:一种用于接送路线预测的深度强化学习框架

    DRL4Route: A Deep Reinforcement Learning Framework for Pick-up and Delivery Route Prediction. (arXiv:2307.16246v1 [cs.LG])

    [http://arxiv.org/abs/2307.16246](http://arxiv.org/abs/2307.16246)

    DRL4Route是一种用于接送路线预测的深度强化学习框架，结合了深度学习模型的行为学习能力和强化学习的非可微分目标优化能力，解决了训练和测试标准不匹配的问题。

    

    近年来，接送路线预测(PDRP)在预测工人的未来服务路线方面受到越来越多的关注。基于监督学习的深度神经网络由于能够从大量历史数据中捕捉工人行为模式的强大能力而成为该任务的主导模型。虽然有着很大的潜力，但它们未能将不可微分的测试标准引入到训练过程中，导致训练和测试标准不匹配。这在实际系统中使用时极大地削减了它们的性能。为了解决上述问题，我们首次尝试将强化学习(RL)推广到路线预测任务中，从而产生了一种名为DRL4Route的新型RL框架。它结合了先前深度学习模型的行为学习能力和强化学习的非可微分目标优化能力。DRL4Route可以作为插件使用。

    Pick-up and Delivery Route Prediction (PDRP), which aims to estimate the future service route of a worker given his current task pool, has received rising attention in recent years. Deep neural networks based on supervised learning have emerged as the dominant model for the task because of their powerful ability to capture workers' behavior patterns from massive historical data. Though promising, they fail to introduce the non-differentiable test criteria into the training process, leading to a mismatch in training and test criteria. Which considerably trims down their performance when applied in practical systems. To tackle the above issue, we present the first attempt to generalize Reinforcement Learning (RL) to the route prediction task, leading to a novel RL-based framework called DRL4Route. It combines the behavior-learning abilities of previous deep learning models with the non-differentiable objective optimization ability of reinforcement learning. DRL4Route can serve as a plug-
    
[^8]: 突触可塑性模型和生物启发的无监督深度学习：一项综述

    Synaptic Plasticity Models and Bio-Inspired Unsupervised Deep Learning: A Survey. (arXiv:2307.16236v1 [cs.NE])

    [http://arxiv.org/abs/2307.16236](http://arxiv.org/abs/2307.16236)

    本综述调查了一系列生物启发的突触可塑性模型在深度学习中的应用，并与脉冲神经网络中的可塑性模型进行了联系。生物启发深度学习代表了一个令人兴奋的研究方向，旨在推动当前技术的发展以及对智能的理解。

    

    最近出现的基于深度学习的技术在人工智能领域的各种任务中取得了出色的结果。然而，这些技术面临着对抗输入的鲁棒性、生态影响以及需要大量训练数据的挑战。作为回应，研究人员越来越关注生物学基础机制，这是由于生物大脑所展示的令人印象深刻的能力所吸引。本综述探讨了一系列这些生物启发模型的突触可塑性模型，在深度学习场景中的应用，并与脉冲神经网络中的可塑性模型进行了联系。总的来说，生物启发深度学习代表了一个令人兴奋的研究方向，旨在推动不仅当前技术的发展，而且还有对智能的理解。

    Recently emerged technologies based on Deep Learning (DL) achieved outstanding results on a variety of tasks in the field of Artificial Intelligence (AI). However, these encounter several challenges related to robustness to adversarial inputs, ecological impact, and the necessity of huge amounts of training data. In response, researchers are focusing more and more interest on biologically grounded mechanisms, which are appealing due to the impressive capabilities exhibited by biological brains. This survey explores a range of these biologically inspired models of synaptic plasticity, their application in DL scenarios, and the connections with models of plasticity in Spiking Neural Networks (SNNs). Overall, Bio-Inspired Deep Learning (BIDL) represents an exciting research direction, aiming at advancing not only our current technologies but also our understanding of intelligence.
    
[^9]: 脉冲神经网络和仿生监督深度学习：综述

    Spiking Neural Networks and Bio-Inspired Supervised Deep Learning: A Survey. (arXiv:2307.16235v1 [cs.NE])

    [http://arxiv.org/abs/2307.16235](http://arxiv.org/abs/2307.16235)

    这篇综述文章回顾了基于生物学启发的人工智能方法，介绍了脉冲神经网络模型，并讨论了脉冲神经网络训练的挑战以及生物启发的深度学习方法。

    

    长期以来，生物学和神经科学领域一直是计算机科学家寻求发展人工智能技术的重要灵感来源。本综述旨在全面回顾最近用于人工智能的仿生方法。首先介绍了生物神经元的计算原理和突触可塑性，然后详细介绍了脉冲神经网络模型，并强调了与脉冲神经网络训练相关的主要挑战，传统的反向传播优化方法无法直接应用。因此，我们讨论了最近提出的与反向传播不同的仿生训练方法，适用于传统网络和脉冲网络。生物启发的深度学习方法旨在推动当前模型的计算能力和生物可行性的进步。

    For a long time, biology and neuroscience fields have been a great source of inspiration for computer scientists, towards the development of Artificial Intelligence (AI) technologies. This survey aims at providing a comprehensive review of recent biologically-inspired approaches for AI. After introducing the main principles of computation and synaptic plasticity in biological neurons, we provide a thorough presentation of Spiking Neural Network (SNN) models, and we highlight the main challenges related to SNN training, where traditional backprop-based optimization is not directly applicable. Therefore, we discuss recent bio-inspired training methods, which pose themselves as alternatives to backprop, both for traditional and spiking networks. Bio-Inspired Deep Learning (BIDL) approaches towards advancing the computational capabilities and biological plausibility of current models.
    
[^10]: 自主移动出行系统中电动车平衡的鲁棒性：一种多智能体强化学习方法

    Robust Electric Vehicle Balancing of Autonomous Mobility-On-Demand System: A Multi-Agent Reinforcement Learning Approach. (arXiv:2307.16228v1 [cs.MA])

    [http://arxiv.org/abs/2307.16228](http://arxiv.org/abs/2307.16228)

    本文提出了一种基于多智能体强化学习的方法来解决电动车在自主移动出行系统中的平衡问题，并考虑了车辆供应和需求的不确定性。

    

    由于其经济和社会效益，电动自动驾驶车辆（EAV）正在未来的自主移动出行（AMoD）系统中引起关注。然而，EAV的独特充电模式（长时间充电、高充电频率、无法预测的充电行为等）使得准确预测EAV供应在E-AMoD系统中变得具有挑战性。此外，移动需求的预测不确定性使得在供应和需求不确定性下设计一个集成的车辆平衡解决方案成为紧迫且具有挑战性的任务。尽管基于强化学习的E-AMoD平衡算法取得了成功，但在EV供应或移动需求下的状态不确定性仍未被探索。在这项工作中，我们设计了一个基于多智能体强化学习（MARL）的框架，用于E-AMoD系统中的EAV平衡，其中包含对抗性智能体，用于模拟可能破坏车辆平衡解决方案的EAV供应和移动需求的不确定性。然后，我们提出了一个鲁棒的E-AMoD解决方案。

    Electric autonomous vehicles (EAVs) are getting attention in future autonomous mobility-on-demand (AMoD) systems due to their economic and societal benefits. However, EAVs' unique charging patterns (long charging time, high charging frequency, unpredictable charging behaviors, etc.) make it challenging to accurately predict the EAVs supply in E-AMoD systems. Furthermore, the mobility demand's prediction uncertainty makes it an urgent and challenging task to design an integrated vehicle balancing solution under supply and demand uncertainties. Despite the success of reinforcement learning-based E-AMoD balancing algorithms, state uncertainties under the EV supply or mobility demand remain unexplored. In this work, we design a multi-agent reinforcement learning (MARL)-based framework for EAVs balancing in E-AMoD systems, with adversarial agents to model both the EAVs supply and mobility demand uncertainties that may undermine the vehicle balancing solutions. We then propose a robust E-AMo
    
[^11]: 数字人文和信息科学中使用深度神经网络进行文本分析

    Text Analysis Using Deep Neural Networks in Digital Humanities and Information Science. (arXiv:2307.16217v1 [cs.LG])

    [http://arxiv.org/abs/2307.16217](http://arxiv.org/abs/2307.16217)

    本论文研究了在数字人文研究中使用深度神经网络进行文本分析的挑战，包括训练数据的可用性和领域适应的需求。

    

    结合计算技术和人文学科是一项持续进行的努力，旨在使文本、图像、音频、视频和其他艺术品等资源在数字化时代易于获得、可搜索和可分析。在近年来，深度神经网络（DNN）在自动文本分析和自然语言处理（NLP）领域占据主导地位，有时呈现出超人类的表现。DNN是解决数字人文研究中与NLP相关的许多任务（例如拼写检查、语言检测、实体提取、作者检测、问答等）的最先进的机器学习算法。这些有监督算法从大量的“正确”和“错误”示例中学习模式，并将其应用于新的示例。然而，在数字人文研究中使用DNN分析文本资源存在两个主要挑战：（不）可用的训练数据和领域适应的需求。本文通过分析多个使用案例来探讨这些挑战。

    Combining computational technologies and humanities is an ongoing effort aimed at making resources such as texts, images, audio, video, and other artifacts digitally available, searchable, and analyzable. In recent years, deep neural networks (DNN) dominate the field of automatic text analysis and natural language processing (NLP), in some cases presenting a super-human performance. DNNs are the state-of-the-art machine learning algorithms solving many NLP tasks that are relevant for Digital Humanities (DH) research, such as spell checking, language detection, entity extraction, author detection, question answering, and other tasks. These supervised algorithms learn patterns from a large number of "right" and "wrong" examples and apply them to new examples. However, using DNNs for analyzing the text resources in DH research presents two main challenges: (un)availability of training data and a need for domain adaptation. This paper explores these challenges by analyzing multiple use-cas
    
[^12]: 用于半结构异构家族谱知识图的深度神经网络问答

    Question Answering with Deep Neural Networks for Semi-Structured Heterogeneous Genealogical Knowledge Graphs. (arXiv:2307.16214v1 [cs.CL])

    [http://arxiv.org/abs/2307.16214](http://arxiv.org/abs/2307.16214)

    本研究提出一种用于家族谱问答的深度神经网络方法，该方法将家族谱数据表示为知识图并与非结构化文本结合，使用Transformer模型进行训练。这种方法解决了家族谱领域中模型无法处理图结构和缺乏训练数据集的问题。

    

    随着用户生成的家族谱越来越流行，新的家族谱信息系统得到了开发。最先进的自然语言问答算法使用基于自注意力网络的深度神经网络（DNN）架构。然而，其中一些模型使用基于序列的输入，不适合处理基于图的结构，而基于图的DNN模型则依赖于在家族谱领域中不存在的高度全面的知识图。此外，这些有监督的DNN模型需要在家族谱领域中缺乏的训练数据集。本研究提出了一种用于家族谱问答的端到端方法：1）将家族谱数据表示为知识图，2）将其转换为文本，3）与非结构化文本结合，4）训练基于Transformer的问答模型。为了评估需要专门方法的必要性，对比了微调模式下的模型与使用我们提出的方法的模型。

    With the rising popularity of user-generated genealogical family trees, new genealogical information systems have been developed. State-of-the-art natural question answering algorithms use deep neural network (DNN) architecture based on self-attention networks. However, some of these models use sequence-based inputs and are not suitable to work with graph-based structure, while graph-based DNN models rely on high levels of comprehensiveness of knowledge graphs that is nonexistent in the genealogical domain. Moreover, these supervised DNN models require training datasets that are absent in the genealogical domain. This study proposes an end-to-end approach for question answering using genealogical family trees by: 1) representing genealogical data as knowledge graphs, 2) converting them to texts, 3) combining them with unstructured texts, and 4) training a trans-former-based question answering model. To evaluate the need for a dedicated approach, a comparison between the fine-tuned mode
    
[^13]: 具有状态不确定性的鲁棒多智能体强化学习

    Robust Multi-Agent Reinforcement Learning with State Uncertainty. (arXiv:2307.16212v1 [cs.LG])

    [http://arxiv.org/abs/2307.16212](http://arxiv.org/abs/2307.16212)

    本论文研究了在多智能体强化学习中状态不确定性的问题。通过引入状态扰动对手，将该问题建模为马尔可夫博弈，并提出了鲁棒均衡作为解决概念。

    

    在真实世界的多智能体强化学习（MARL）应用中，由于测量不准确或恶意攻击等原因，智能体可能无法获得完美的状态信息，这给智能体的策略的鲁棒性带来了挑战。虽然鲁棒性在MARL部署中变得越来越重要，但很少有先前的工作研究了MARL中的状态不确定性，无论是在问题的表述还是算法设计方面。受到这个鲁棒性问题及缺乏相应研究的启发，我们在本工作中研究了具有状态不确定性的MARL问题。我们首次将该问题建模为具有状态扰动对手的马尔可夫博弈（MG-SPA），通过引入一组状态扰动对手到马尔可夫博弈中。然后，我们引入鲁棒均衡（RE）作为MG-SPA的解决概念。我们进行了对MG-SPA的基本分析，例如给出了满足鲁棒均衡的条件。

    In real-world multi-agent reinforcement learning (MARL) applications, agents may not have perfect state information (e.g., due to inaccurate measurement or malicious attacks), which challenges the robustness of agents' policies. Though robustness is getting important in MARL deployment, little prior work has studied state uncertainties in MARL, neither in problem formulation nor algorithm design. Motivated by this robustness issue and the lack of corresponding studies, we study the problem of MARL with state uncertainty in this work. We provide the first attempt to the theoretical and empirical analysis of this challenging problem. We first model the problem as a Markov Game with state perturbation adversaries (MG-SPA) by introducing a set of state perturbation adversaries into a Markov Game. We then introduce robust equilibrium (RE) as the solution concept of an MG-SPA. We conduct a fundamental analysis regarding MG-SPA such as giving conditions under which such a robust equilibrium e
    
[^14]: 重新思考多模态实体对齐中的不确定性缺失和模糊的视觉模态

    Rethinking Uncertainly Missing and Ambiguous Visual Modality in Multi-Modal Entity Alignment. (arXiv:2307.16210v1 [cs.AI])

    [http://arxiv.org/abs/2307.16210](http://arxiv.org/abs/2307.16210)

    在多模态实体对齐中，现有的方法忽视了视觉图像的不完整性和模糊性，本文通过分析表明模型在面对不完整性时容易出现过拟合和性能下降的问题。

    

    作为实体对齐（EA）的重要扩展，多模态实体对齐（MMEA）旨在通过利用相关的视觉信息来识别跨不同知识图谱（KGs）之间的相同实体。然而，现有的MMEA方法主要集中在多模态实体特征的融合范式上，而忽视了缺失和内在模糊性的视觉图像所带来的挑战。本文对视觉模态不完整性进行了进一步分析，在我们提出的MMEA-UMVM数据集上对最新的MMEA模型进行了基准测试，该数据集包含涵盖双语和单语对齐KGs的类型，并采用标准（非迭代）和迭代训练范式来评估模型性能。我们的研究表明，在面对模态不完整性时，模型很容易过拟合模态噪声，并在高缺失模态的情况下出现性能振荡或下降。这证明了增加视觉不确定性的问题。

    As a crucial extension of entity alignment (EA), multi-modal entity alignment (MMEA) aims to identify identical entities across disparate knowledge graphs (KGs) by exploiting associated visual information. However, existing MMEA approaches primarily concentrate on the fusion paradigm of multi-modal entity features, while neglecting the challenges presented by the pervasive phenomenon of missing and intrinsic ambiguity of visual images. In this paper, we present a further analysis of visual modality incompleteness, benchmarking latest MMEA models on our proposed dataset MMEA-UMVM, where the types of alignment KGs covering bilingual and monolingual, with standard (non-iterative) and iterative training paradigms to evaluate the model performance. Our research indicates that, in the face of modality incompleteness, models succumb to overfitting the modality noise, and exhibit performance oscillations or declines at high rates of missing modality. This proves that the inclusion of additiona
    
[^15]: 在异构家谱知识图谱上使用深度神经网络进行数字聚合问答的GLOBE方法

    Around the GLOBE: Numerical Aggregation Question-Answering on Heterogeneous Genealogical Knowledge Graphs with Deep Neural Networks. (arXiv:2307.16208v1 [cs.CL])

    [http://arxiv.org/abs/2307.16208](http://arxiv.org/abs/2307.16208)

    本文介绍了一种在异构家谱知识图谱上进行数字聚合问答的方法，在基因谱领域提出了自然语言问题并获得准确答案的能力还未被充分研究。

    

    文章介绍了一种在异构家谱知识图谱上进行数字聚合问答的方法，该方法利用深度神经网络实现自然语言问题与精确答案之间的转换。目前，在基因谱领域，提出自然语言问题并获得准确答案的能力还未被充分研究，而研究者在人文和社会科学等领域可以从这种能力中受益匪浅。

    One of the key AI tools for textual corpora exploration is natural language question-answering (QA). Unlike keyword-based search engines, QA algorithms receive and process natural language questions and produce precise answers to these questions, rather than long lists of documents that need to be manually scanned by the users. State-of-the-art QA algorithms based on DNNs were successfully employed in various domains. However, QA in the genealogical domain is still underexplored, while researchers in this field (and other fields in humanities and social sciences) can highly benefit from the ability to ask questions in natural language, receive concrete answers and gain insights hidden within large corpora. While some research has been recently conducted for factual QA in the genealogical domain, to the best of our knowledge, there is no previous research on the more challenging task of numerical aggregation QA (i.e., answering questions combining aggregation functions, e.g., count, ave
    
[^16]: 使用虚拟空间合成以事件为中心的知识图谱的日常活动

    Synthesizing Event-centric Knowledge Graphs of Daily Activities Using Virtual Space. (arXiv:2307.16206v1 [cs.AI])

    [http://arxiv.org/abs/2307.16206](http://arxiv.org/abs/2307.16206)

    这项研究提出了使用虚拟空间合成以事件为中心的知识图谱的日常活动的方法，并指出了在理解日常生活的意图和上下文方面的困难和挑战。

    

    人工智能（AI）预计将体现在能够理解家庭环境中日常生活的各种情境信息，以支持各种情况下的人类行为和决策的软件代理、机器人和网络物理系统中。场景图和知识图（KG）构建技术对于满足这一期望的基于知识的实体问答受到了很多关注。然而，在一个物理空间中收集和管理各种实验条件下的日常活动的真实数据是相当昂贵的，而且开发出理解意图和上下文的人工智能也很困难。未来，预计将结合来自可以轻松修改条件的虚拟空间和条件难以改变的物理空间的数据来分析日常生活活动。然而，关于使用虚拟空间构建日常活动的知识图谱及其应用的研究尚未进展。

    Artificial intelligence (AI) is expected to be embodied in software agents, robots, and cyber-physical systems that can understand the various contextual information of daily life in the home environment to support human behavior and decision making in various situations. Scene graph and knowledge graph (KG) construction technologies have attracted much attention for knowledge-based embodied question answering meeting this expectation. However, collecting and managing real data on daily activities under various experimental conditions in a physical space are quite costly, and developing AI that understands the intentions and contexts is difficult. In the future, data from both virtual spaces, where conditions can be easily modified, and physical spaces, where conditions are difficult to change, are expected to be combined to analyze daily living activities. However, studies on the KG construction of daily activities using virtual space and their application have yet to progress. The po
    
[^17]: 洗牌式差分隐私联邦学习在时间序列数据分析中的应用

    Shuffled Differentially Private Federated Learning for Time Series Data Analytics. (arXiv:2307.16196v1 [cs.LG])

    [http://arxiv.org/abs/2307.16196](http://arxiv.org/abs/2307.16196)

    该论文介绍了一种针对时间序列数据的隐私保护联邦学习算法，通过使用局部差分隐私和洗牌技术，有效实现了在保护隐私的同时提高模型准确性。实验结果表明该方法在时间序列数据分析中具有良好的应用价值。

    

    可信任的联邦学习旨在在确保客户隐私的同时实现最优性能。现有的隐私保护联邦学习方法主要针对图像数据，缺乏时间序列数据的应用，而时间序列数据有许多重要的应用，如机器健康监测、人体活动识别等。此外，对时间序列数据分析模型进行保护性噪音处理可能会严重干扰时态相关的学习，导致精度下降更大。为解决这些问题，我们开发了一种适用于时间序列数据的隐私保护联邦学习算法。具体而言，我们采用了局部差分隐私将隐私保护信任边界扩展到客户端。我们还结合了洗牌技术，实现了对隐私增强，在减小因局部差分隐私而导致的精度下降方面起到了缓解作用。我们在五个时间序列数据集上进行了大量实验。评估结果显示，我们的算法在时间序列数据上取得了良好效果。

    Trustworthy federated learning aims to achieve optimal performance while ensuring clients' privacy. Existing privacy-preserving federated learning approaches are mostly tailored for image data, lacking applications for time series data, which have many important applications, like machine health monitoring, human activity recognition, etc. Furthermore, protective noising on a time series data analytics model can significantly interfere with temporal-dependent learning, leading to a greater decline in accuracy. To address these issues, we develop a privacy-preserving federated learning algorithm for time series data. Specifically, we employ local differential privacy to extend the privacy protection trust boundary to the clients. We also incorporate shuffle techniques to achieve a privacy amplification, mitigating the accuracy decline caused by leveraging local differential privacy. Extensive experiments were conducted on five time series datasets. The evaluation results reveal that our
    
[^18]: ESP:利用对称性先验知识进行多Agent强化学习

    ESP: Exploiting Symmetry Prior for Multi-Agent Reinforcement Learning. (arXiv:2307.16186v1 [cs.MA])

    [http://arxiv.org/abs/2307.16186](http://arxiv.org/abs/2307.16186)

    本文提出了一种利用对称性先验知识的框架来解决多Agent强化学习中的数据效率问题，通过将数据增强和一致性损失集成到现有方法中，能够提高模型训练效率，并且泛化性能良好。

    

    近年来，多Agent强化学习（MARL）取得了令人期待的成果。然而，大多数现有的强化学习方法需要大量的数据进行模型训练。此外，数据高效的强化学习要求构建强大的归纳偏差，在当前的MARL方法中被忽视了。受多Agent系统中对称现象的启发，本文提出了一种框架，通过将数据增强和精心设计的一致性损失集成到现有的MARL方法中，来利用先验知识。此外，所提出的框架是模型无关的，可以应用于大多数当前的MARL算法。对多个具有挑战性的任务进行了实验测试，证明了所提出的框架的有效性。此外，将所提出的框架应用于一个物理多机器人实验平台，展示了它的优越性。

    Multi-agent reinforcement learning (MARL) has achieved promising results in recent years. However, most existing reinforcement learning methods require a large amount of data for model training. In addition, data-efficient reinforcement learning requires the construction of strong inductive biases, which are ignored in the current MARL approaches. Inspired by the symmetry phenomenon in multi-agent systems, this paper proposes a framework for exploiting prior knowledge by integrating data augmentation and a well-designed consistency loss into the existing MARL methods. In addition, the proposed framework is model-agnostic and can be applied to most of the current MARL algorithms. Experimental tests on multiple challenging tasks demonstrate the effectiveness of the proposed framework. Moreover, the proposed framework is applied to a physical multi-robot testbed to show its superiority.
    
[^19]: 基于实验增强的数据驱动建模方法用于双有源桥变换器的调制策略

    Data-Driven Modeling with Experimental Augmentation for the Modulation Strategy of the Dual-Active-Bridge Converter. (arXiv:2307.16173v1 [eess.SY])

    [http://arxiv.org/abs/2307.16173](http://arxiv.org/abs/2307.16173)

    本文介绍了一种基于实验增强的数据驱动建模方法，该方法通过结合仿真数据和实验数据来减轻模型差异，并在实践中提高准确性。

    

    对于电力转换器的性能建模，主流方法基本上是基于知识的，由于人力负担重和建模精度低而受困。最近出现的数据驱动技术通过从仿真数据中自动建模极大地减轻了对人的依赖。然而，由于未建模的寄生元件、不足的热磁模型、不可预测的环境条件等原因，模型的差异可能会发生。这些仅基于仿真的不准确的数据驱动模型无法代表实际世界中的实际性能，阻碍了它们在电力转换器建模中的应用。为了减轻模型差异并在实践中提高准确性，本文提出了一种新的基于实验增强的数据驱动建模方法(D2EA)，结合了仿真数据和实验数据。在D2EA中，仿真数据旨在建立基本的功能景观，实验数据则专注于匹配实际世界中的实际性能。实例化了D2EA方法

    For the performance modeling of power converters, the mainstream approaches are essentially knowledge-based, suffering from heavy manpower burden and low modeling accuracy. Recent emerging data-driven techniques greatly relieve human reliance by automatic modeling from simulation data. However, model discrepancy may occur due to unmodeled parasitics, deficient thermal and magnetic models, unpredictable ambient conditions, etc. These inaccurate data-driven models based on pure simulation cannot represent the practical performance in physical world, hindering their applications in power converter modeling. To alleviate model discrepancy and improve accuracy in practice, this paper proposes a novel data-driven modeling with experimental augmentation (D2EA), leveraging both simulation data and experimental data. In D2EA, simulation data aims to establish basic functional landscape, and experimental data focuses on matching actual performance in real world. The D2EA approach is instantiated
    
[^20]: HierVST: 分层自适应零样本语音风格转换

    HierVST: Hierarchical Adaptive Zero-shot Voice Style Transfer. (arXiv:2307.16171v1 [cs.SD])

    [http://arxiv.org/abs/2307.16171](http://arxiv.org/abs/2307.16171)

    HierVST是一个层次自适应的零样本语音风格转换模型，通过利用层次变分推断和自监督表示训练，该模型能够适应新的语音风格并逐步转换语音。实验结果表明，在零样本VST场景中，HierVST的性能优于其他VST模型。

    

    尽管语音风格转换（VST）领域取得了快速的进展，但最近的零样本VST系统仍然缺乏将新型说话者的语音风格转换的能力。本文提出了HierVST，一种层次自适应的端到端零样本VST模型。在没有任何文本转录的情况下，我们只使用语音数据集通过利用层次变分推断和自监督表示来训练模型。此外，我们采用了一种分层自适应生成器，以顺序方式生成音高表示和波形音频。此外，我们利用无条件生成来提高声纹相对声学能力。通过分层自适应结构，该模型可以适应新的语音风格并逐步转换语音。实验结果表明，我们的方法在零样本VST场景中优于其他VST模型。音频样本可在 \url{https://hiervst.github.io/} 获取。

    Despite rapid progress in the voice style transfer (VST) field, recent zero-shot VST systems still lack the ability to transfer the voice style of a novel speaker. In this paper, we present HierVST, a hierarchical adaptive end-to-end zero-shot VST model. Without any text transcripts, we only use the speech dataset to train the model by utilizing hierarchical variational inference and self-supervised representation. In addition, we adopt a hierarchical adaptive generator that generates the pitch representation and waveform audio sequentially. Moreover, we utilize unconditional generation to improve the speaker-relative acoustic capacity in the acoustic representation. With a hierarchical adaptive structure, the model can adapt to a novel voice style and convert speech progressively. The experimental results demonstrate that our method outperforms other VST models in zero-shot VST scenarios. Audio samples are available at \url{https://hiervst.github.io/}.
    
[^21]: 智能电网中一种有效的用于能量盗窃检测和预测的LSTM-DDPM方案

    An Effective LSTM-DDPM Scheme for Energy Theft Detection and Forecasting in Smart Grid. (arXiv:2307.16149v1 [cs.LG])

    [http://arxiv.org/abs/2307.16149](http://arxiv.org/abs/2307.16149)

    这篇论文提出了一种利用LSTM和DDPM相结合的方案来解决智能电网系统中的能量盗窃检测和预测问题。通过重构和预测误差，系统能够准确识别能量盗窃的实例，并在实验中表现出较好的性能。

    

    能量盗窃检测（ETD）和能量消耗预测（ECF）是智能电网系统中两个相互关联的挑战。共同解决这些问题对于确保系统安全至关重要。本论文解决了智能电网系统中的ETD和ECF的相互关联挑战。所提出的解决方案结合了长短期记忆（LSTM）和去噪扩散概率模型（DDPM），用于生成输入重构和预测。通过利用重构和预测误差，系统能够识别能量盗窃的实例，基于重构误差和预测误差的方法相互补充，可以检测不同类型的攻击。通过在真实和合成数据集上进行大量实验，所提出的方案在ETD和ECF问题上表现优于基准方法。集成方法显著提升了ETD性能，能够准确检测到基准方法未能检测到的能量盗窃攻击。该研究提供了一种可行的解决方案来解决智能电网系统中ETD和ECF的挑战。

    Energy theft detection (ETD) and energy consumption forecasting (ECF) are two interconnected challenges in smart grid systems. Addressing these issues collectively is crucial for ensuring system security. This paper addresses the interconnected challenges of ETD and ECF in smart grid systems. The proposed solution combines long short-term memory (LSTM) and a denoising diffusion probabilistic model (DDPM) to generate input reconstruction and forecasting. By leveraging the reconstruction and forecasting errors, the system identifies instances of energy theft, with the methods based on reconstruction error and forecasting error complementing each other in detecting different types of attacks. Through extensive experiments on real-world and synthetic datasets, the proposed scheme outperforms baseline methods in ETD and ECF problems. The ensemble method significantly enhances ETD performance, accurately detecting energy theft attacks that baseline methods fail to detect. The research offers
    
[^22]: 全卷积轻量级图像超分辨率网络

    Fully $1\times1$ Convolutional Network for Lightweight Image Super-Resolution. (arXiv:2307.16140v1 [cs.CV])

    [http://arxiv.org/abs/2307.16140](http://arxiv.org/abs/2307.16140)

    本论文提出了一种全卷积轻量级图像超分辨率网络，通过融合$3\times3$和$1\times1$卷积核的优点，以及引入无参数的空间平移操作，在保持计算效率的同时提高了网络的表示能力。

    

    深度模型在单图像超分辨率任务中取得了显著的进展，特别是使用了大卷积核（$3\times3$或更大）的大型模型。然而，这些模型的高计算复杂度限制了其在实时、资源受限的环境中的部署。相反，$1\times1$卷积具有较高的计算效率，但在聚合局部空间表示方面表现不佳，这是SISR模型的一个重要能力。为了解决这种对立，我们提出了融合$3\times3$和$1\times1$卷积核优点的轻量级SISR网络，名为Shift-Conv-based Network (SCNet)。通过引入一个无参数的空间平移操作，在保持计算效率的同时，赋予了全卷积轻量级网络强大的表示能力。大量实验证明了网络的有效性。

    Deep models have achieved significant process on single image super-resolution (SISR) tasks, in particular large models with large kernel ($3\times3$ or more). However, the heavy computational footprint of such models prevents their deployment in real-time, resource-constrained environments. Conversely, $1\times1$ convolutions bring substantial computational efficiency, but struggle with aggregating local spatial representations, an essential capability to SISR models. In response to this dichotomy, we propose to harmonize the merits of both $3\times3$ and $1\times1$ kernels, and exploit a great potential for lightweight SISR tasks. Specifically, we propose a simple yet effective fully $1\times1$ convolutional network, named Shift-Conv-based Network (SCNet). By incorporating a parameter-free spatial-shift operation, it equips the fully $1\times1$ convolutional network with powerful representation capability while impressive computational efficiency. Extensive experiments demonstrate th
    
[^23]: 用户可控的大型语言模型中的知识融合：平衡创造力和幻觉

    User-Controlled Knowledge Fusion in Large Language Models: Balancing Creativity and Hallucination. (arXiv:2307.16139v1 [cs.CL])

    [http://arxiv.org/abs/2307.16139](http://arxiv.org/abs/2307.16139)

    本文提出了一种用户可控的机制，用于调节大型语言模型在生成回应时创造力和对外部知识的忠诚度之间的平衡。这种机制通过在训练过程中引入数值标记，并使用自动化过程计算标记的程度，从而实现用户对模型的依赖程度的控制。

    

    在现代对话系统中，使用大型语言模型（LLMs）由于其生成多样、相关且有创造性的回应能力而呈指数增长。尽管LLMs具有这些优点，但在创造力和对外部知识的忠诚度之间取得平衡仍然是一个关键挑战。本文提出了一种创新的用户可控机制，用于调节LLM在想象能力和与事实信息的一致性之间的平衡。我们的方法在LLM的训练的微调阶段中引入一个表示生成回应中对参考知识忠诚度程度的数值标记。这个程度是通过自动化过程计算的，该过程使用ROUGE分数衡量词汇重叠，使用Sentence-BERT嵌入衡量语义相似性，以及LLM的自我评估分数。在模型推理过程中，用户可以操作这个数值标记，从而控制LLM对外部知识的依赖程度。

    In modern dialogue systems, the use of Large Language Models (LLMs) has grown exponentially due to their capacity to generate diverse, relevant, and creative responses. Despite their strengths, striking a balance between the LLMs' creativity and their faithfulness to external knowledge remains a key challenge. This paper presents an innovative user-controllable mechanism that modulates the balance between an LLM's imaginative capabilities and its adherence to factual information. Our approach incorporates a numerical tag during the fine-tuning phase of the LLM's training, representing the degree of faithfulness to the reference knowledge in the generated responses. This degree is computed through an automated process that measures lexical overlap using ROUGE scores, semantic similarity using Sentence-BERT embeddings, and an LLM's self-evaluation score. During model inference, users can manipulate this numerical tag, thus controlling the degree of the LLM's reliance on external knowledg
    
[^24]: 自动驾驶中的稳健目标检测的不确定性编码多模态融合

    Uncertainty-Encoded Multi-Modal Fusion for Robust Object Detection in Autonomous Driving. (arXiv:2307.16121v1 [cs.CV])

    [http://arxiv.org/abs/2307.16121](http://arxiv.org/abs/2307.16121)

    本文提出了一种名为UMoE的方法，它将单模态的不确定性纳入了LiDAR-相机融合中，通过使用专家网络和门控网络来处理和分析多模态融合结果，以实现自动驾驶中稳健的目标检测。

    

    多模态融合在自动驾驶感知的目标检测中显示了初步的有 promising 结果。然而，许多现有的融合方案没有考虑到每个融合输入的质量，并且可能会受到一个或多个传感器的不利条件的影响。虽然预测不确定性已经被应用于在运行时表征单模态目标检测性能，但将不确定性纳入多模态融合仍然缺乏有效的解决方案，主要是由于不确定性的跨模态不可比较性和对各种不利条件的不同敏感性。为了弥补这个差距，本文提出了一种名为 Uncertainty-Encoded Mixture-of-Experts（UMoE）的方法，它明确地将单模态的不确定性纳入了LiDAR-相机融合中。UMoE使用单独的专家网络来处理每个传感器的检测结果以及编码的不确定性。然后，由一个门控网络分析专家网络的输出以确定融合权重。所提出的UMoE模块可以被应用于不同的自动驾驶场景中。

    Multi-modal fusion has shown initial promising results for object detection of autonomous driving perception. However, many existing fusion schemes do not consider the quality of each fusion input and may suffer from adverse conditions on one or more sensors. While predictive uncertainty has been applied to characterize single-modal object detection performance at run time, incorporating uncertainties into the multi-modal fusion still lacks effective solutions due primarily to the uncertainty's cross-modal incomparability and distinct sensitivities to various adverse conditions. To fill this gap, this paper proposes Uncertainty-Encoded Mixture-of-Experts (UMoE) that explicitly incorporates single-modal uncertainties into LiDAR-camera fusion. UMoE uses individual expert network to process each sensor's detection result together with encoded uncertainty. Then, the expert networks' outputs are analyzed by a gating network to determine the fusion weights. The proposed UMoE module can be in
    
[^25]: 人工智能提高了全球可靠洪水预警的覆盖范围

    AI Increases Global Access to Reliable Flood Forecasts. (arXiv:2307.16104v1 [cs.LG])

    [http://arxiv.org/abs/2307.16104](http://arxiv.org/abs/2307.16104)

    本研究开发了一个人工智能模型，可以准确预测未经测量流域的极端水文事件，从而提高了全球洪水预警的覆盖范围。

    

    洪水是最常见和影响最大的自然灾害之一，对发展中国家尤其具有不对称的影响，这些国家往往缺乏密集的水流监测网络。准确及时的预警对于减轻洪水风险至关重要，但准确的水文模拟模型通常需要根据每个应用的流域中的长时间数据记录进行校准。我们开发了一个人工智能（AI）模型，可以预测7天内的极端水文事件。该模型在所有大洲、前导时间和重现期中均明显优于当前最先进的全球水文模型（Copernicus应急管理服务全球洪水意识系统）。AI在未经测量的流域中的预测尤其有效，这很重要，因为全球只有百分之几的流域具有流量观测站，而发展中国家的未经测量的流域数量占比很高，对人类特别脆弱。

    Floods are one of the most common and impactful natural disasters, with a disproportionate impact in developing countries that often lack dense streamflow monitoring networks. Accurate and timely warnings are critical for mitigating flood risks, but accurate hydrological simulation models typically must be calibrated to long data records in each watershed where they are applied. We developed an Artificial Intelligence (AI) model to predict extreme hydrological events at timescales up to 7 days in advance. This model significantly outperforms current state of the art global hydrology models (the Copernicus Emergency Management Service Global Flood Awareness System) across all continents, lead times, and return periods. AI is especially effective at forecasting in ungauged basins, which is important because only a few percent of the world's watersheds have stream gauges, with a disproportionate number of ungauged basins in developing countries that are especially vulnerable to the human 
    
[^26]: PD-SEG: 使用深度分割网络进行人口分解，以改进建筑住区掩模

    PD-SEG: Population Disaggregation Using Deep Segmentation Networks For Improved Built Settlement Mask. (arXiv:2307.16084v1 [cs.CV])

    [http://arxiv.org/abs/2307.16084](http://arxiv.org/abs/2307.16084)

    通过使用深度分割网络和卫星图像，PD-SEG实现了准确的人口统计，改进了以往在发展中国家准确度不高的情况。

    

    任何涉及资源开发和规划倡议的政策层决策过程和学术研究都依赖于准确的人口密度统计数据。WorldPop和Meta提供的最先进数据集对于像巴基斯坦这样的发展中国家并不能实现这一目标；它们算法的输入提供了错误的估计，无法捕捉到空间和土地利用动态。为了精确估计30米×30米分辨率下的人口数量，我们使用准确的建筑住区掩模，该掩模是使用深度分割网络和卫星图像获得的，并且还使用了兴趣点(POI)数据来排除非居民区域。

    Any policy-level decision-making procedure and academic research involving the optimum use of resources for development and planning initiatives depends on accurate population density statistics. The current cutting-edge datasets offered by WorldPop and Meta do not succeed in achieving this aim for developing nations like Pakistan; the inputs to their algorithms provide flawed estimates that fail to capture the spatial and land-use dynamics. In order to precisely estimate population counts at a resolution of 30 meters by 30 meters, we use an accurate built settlement mask obtained using deep segmentation networks and satellite imagery. The Points of Interest (POI) data is also used to exclude non-residential areas.
    
[^27]: EnrichEvent: 使用上下文信息为新出现的事件提供丰富的社交数据

    EnrichEvent: Enriching Social Data with Contextual Information for Emerging Event Extraction. (arXiv:2307.16082v1 [cs.CL])

    [http://arxiv.org/abs/2307.16082](http://arxiv.org/abs/2307.16082)

    本文提出了一个利用词汇、语义和上下文表示的框架，旨在解决现有事件检测方法在识别新兴社交事件方面的局限性，并提供了对社交数据进行丰富的上下文化处理的方法。

    

    社交平台已成为传播和讨论真实事件信息的关键平台，为及早发现有新闻价值的事件提供了良好的机会。然而，现有的大多数事件检测方法仅利用关键词突发性或网络结构来检测热点事件。因此，对于事件和社交数据的复杂性而言，它们往往无法在达到趋势状态之前识别出新出现的社交事件。社交数据，例如推文，具有拼写错误、不完整性、歧义性和语言不规范性，以及意见方面的变化。此外，利用有限的上下文知识来学习事件的演变特征对于机器学习模型几乎是不可行的。为了解决这些问题，本文提出了一个利用流式社交数据的词汇、语义和上下文表示的框架。

    Social platforms have emerged as a crucial platform for disseminating and discussing information about real-life events, which offers an excellent opportunity for early detection of newsworthy events. However, most existing approaches for event detection solely exploit keyword burstiness or network structures to detect hot events. Thus, they often fail to identify emerging social events before reaching a trending state regarding the challenging nature of events and social data. Social data, e.g., tweets, is characterized by misspellings, incompleteness, ambiguity, and irregular language, as well as variation in aspects of opinions. Moreover, learning the evolving characteristics of the events utilizing limited contextual knowledge is almost infeasible for machine learning models. To address these problems, in this paper, we propose a framework that exploits the lexical, semantic, and contextual representations of streaming social data. In particular, we leverage contextual knowledge to
    
[^28]: 将对话系统与数据可视化结合：从自然语言对话中生成交互式数据可视化

    Marrying Dialogue Systems with Data Visualization: Interactive Data Visualization Generation from Natural Language Conversations. (arXiv:2307.16013v1 [cs.AI])

    [http://arxiv.org/abs/2307.16013](http://arxiv.org/abs/2307.16013)

    本研究结合了对话系统与数据可视化，通过用户和系统之间的交互来生成数据可视化。研究首先构建了一个基准数据集，然后提出了一种多重方法来实现此任务。

    

    数据可视化已经成为市场上流行的工具，因为它能有效地展示大量的数据见解。为了降低使用数据可视化的门槛，研究界已经开始研究自动数据可视化任务，如自然语言问题到可视化转换（正式称为文本到可视化）。然而，文本到可视化假设自然语言问题已经有一个良好的组织并且用一个句子来表达。然而，在现实世界中，复杂的数据可视化需要通过可视化系统和用户之间的连续交互来完成。在本文中，我们提出了一个新的任务，称为CoVis，即对话式文本到可视化，旨在通过用户和系统之间的多个交互来构建数据可视化。因为这个任务在文献中还没有被研究，所以我们首先建立了一个名为Dial-NVBench的基准数据集，包括用户的一系列查询和系统的回应的对话会话。然后，我们提出了一个多重的方法

    Data visualization (DV) has become the prevailing tool in the market due to its effectiveness into illustrating insights in vast amounts of data. To lower the barrier of using DVs, automatic DV tasks, such as natural language question (NLQ) to visualization translation (formally called text-to-vis), have been investigated in the research community. However, text-to-vis assumes the NLQ to be well-organized and expressed in a single sentence. However, in real-world settings, complex DV is needed through consecutive exchanges between the DV system and the users. In this paper, we propose a new task named CoVis, short for Conversational text-to-Visualization, aiming at constructing DVs through a series of interactions between users and the system. Since it is the task which has not been studied in the literature, we first build a benchmark dataset named Dial-NVBench, including dialogue sessions with a sequence of queries from a user and responses from the system. Then, we propose a multi-m
    
[^29]: RoCar:一种基于关系网络的大型语言模型评估方法

    RoCar: A Relationship Network-based Evaluation Method to Large Language Models. (arXiv:2307.15997v1 [cs.CL])

    [http://arxiv.org/abs/2307.15997](http://arxiv.org/abs/2307.15997)

    RoCar是一种利用关系网络构建任务图并生成自然语言评估任务的方法，用于评估大型语言模型的推理和记忆能力。该方法通过极大的随机性确保了评估的公平性。

    

    大型语言模型（LLMs）受到越来越多的关注。然而，由于其能力的复杂性，如何合理评估LLMs的能力仍然是一个需要解决的任务。我们提出了RoCar方法，利用定义的基本模式随机构建一个任务图，并基于任务图生成自然语言评估任务，分别评估LLMs的推理和记忆能力。由于任务构建过程的极大随机性，可以确保被测试的LLMs中没有一个直接学习了评估任务，从而保证了评估方法的公平性。

    Large language models (LLMs) have received increasing attention. However, due to the complexity of its capabilities, how to rationally evaluate the capabilities of LLMs is still a task to be solved. We propose the RoCar method, which utilizes the defined basic schemas to randomly construct a task graph and generates natural language evaluation tasks based on the task graph to evaluate the reasoning and memory abilities of LLMs respectively. Due to the very large randomness of the task construction process, it is possible to ensure that none of the LLMs to be tested has directly learned the evaluation tasks, guaranteeing the fairness of the evaluation method.
    
[^30]: UPFL：面向新客户的无监督个性化联邦学习

    UPFL: Unsupervised Personalized Federated Learning towards New Clients. (arXiv:2307.15994v1 [cs.LG])

    [http://arxiv.org/abs/2307.15994](http://arxiv.org/abs/2307.15994)

    本文提出了一种无监督个性化联邦学习方法UPFL，解决了联邦学习中新客户加入时的个性化模型问题。

    

    个性化联邦学习作为解决数据异质性挑战的一种有效方法，已经引起了广泛关注。本文针对联邦学习中一个相对未被探索的问题进行研究。当联邦模型被训练和部署后，一个未标记的新客户加入时，为新客户提供个性化模型成为一项极具挑战性的任务。为了解决这个问题，我们将自适应风险最小化技术扩展到无监督个性化联邦学习的场景，并提出了我们的方法FedTTA。我们进一步通过两种简单且有效的优化策略改进了FedTTA：使用代理正则化增强自适应模型的训练，并通过熵提前停止自适应。此外，我们还提出了一种专为FedTTA设计的知识蒸馏损失，以解决设备异质性问题。对比11个基准方法在5个数据集上的广泛实验表明了我们提出方法的有效性。

    Personalized federated learning has gained significant attention as a promising approach to address the challenge of data heterogeneity. In this paper, we address a relatively unexplored problem in federated learning. When a federated model has been trained and deployed, and an unlabeled new client joins, providing a personalized model for the new client becomes a highly challenging task. To address this challenge, we extend the adaptive risk minimization technique into the unsupervised personalized federated learning setting and propose our method, FedTTA. We further improve FedTTA with two simple yet effective optimization strategies: enhancing the training of the adaptation model with proxy regularization and early-stopping the adaptation through entropy. Moreover, we propose a knowledge distillation loss specifically designed for FedTTA to address the device heterogeneity. Extensive experiments on five datasets against eleven baselines demonstrate the effectiveness of our proposed 
    
[^31]: 利用去噪扩散重建模型进行超声图像重建

    Ultrasound Image Reconstruction with Denoising Diffusion Restoration Models. (arXiv:2307.15990v1 [cs.CV])

    [http://arxiv.org/abs/2307.15990](http://arxiv.org/abs/2307.15990)

    本论文提出了一种利用去噪扩散恢复模型进行超声图像重建的方法，并在合成和PICMUS数据上进行了实验验证。实验结果显示，该方法可以从单个平面波中实现与DAS和最先进方法相媲美甚至更好的图像质量。

    

    超声图像重建可以近似看作是一个线性逆问题，传统上通过使用$l_1$或$l_2$范数或基于小波的项进行惩罚优化来解决。然而，这种正则化函数往往难以平衡稀疏性和平滑性。一种有前景的替代方法是使用学习先验使先前的知识更接近实际情况。在本文中，我们依靠学习先验的框架中的去噪扩散恢复模型(DDRM)对超声逆问题模型进行了两种改进，即DRUS和WDRUS。我们在合成和PICMUS数据上的实验表明，我们的方法从单个平面波中可以实现与DAS和最先进方法相媲美甚至更好的图像质量。代码可在以下链接获取: https://github.com/Yuxin-Zhang-Jasmine/DRUS-v1.

    Ultrasound image reconstruction can be approximately cast as a linear inverse problem that has traditionally been solved with penalized optimization using the $l_1$ or $l_2$ norm, or wavelet-based terms. However, such regularization functions often struggle to balance the sparsity and the smoothness. A promising alternative is using learned priors to make the prior knowledge closer to reality. In this paper, we rely on learned priors under the framework of Denoising Diffusion Restoration Models (DDRM), initially conceived for restoration tasks with natural images. We propose and test two adaptions of DDRM to ultrasound inverse problem models, DRUS and WDRUS. Our experiments on synthetic and PICMUS data show that from a single plane wave our method can achieve image quality comparable to or better than DAS and state-of-the-art methods. The code is available at: https://github.com/Yuxin-Zhang-Jasmine/DRUS-v1.
    
[^32]: 自动驾驶的自由空间光流建模

    Freespace Optical Flow Modeling for Automated Driving. (arXiv:2307.15989v1 [cs.RO])

    [http://arxiv.org/abs/2307.15989](http://arxiv.org/abs/2307.15989)

    本论文提出了一种在碰撞自由空间中建模光流的策略，充分利用了三维驾驶环境中的几何信息，通过对多个数据集进行广泛的实验，实现了光流的明确表示和光流分量与垂直坐标之间的二次关系。

    

    光流和视差是自主驾驶感知中两个信息丰富的视觉特征。它们已广泛应用于各种应用，如障碍物和车道检测。"U-V-Disparity"的概念在文献中得到了广泛探讨，而光流的对应概念却受到了相对较少的关注。传统的运动分析算法通过匹配两个连续视频帧之间的对应点来估计光流，这限制了对环境信息和几何约束的充分利用。因此，我们提出了一种新的策略，在智能车辆的碰撞自由空间（也称为可通行区域或简称为自由空间）中建模光流，充分利用三维驾驶环境中的几何信息。我们提供了光流的明确表示，并推导出光流分量与垂直坐标之间的二次关系。通过对多个数据集进行广泛的实验。

    Optical flow and disparity are two informative visual features for autonomous driving perception. They have been used for a variety of applications, such as obstacle and lane detection. The concept of "U-V-Disparity" has been widely explored in the literature, while its counterpart in optical flow has received relatively little attention. Traditional motion analysis algorithms estimate optical flow by matching correspondences between two successive video frames, which limits the full utilization of environmental information and geometric constraints. Therefore, we propose a novel strategy to model optical flow in the collision-free space (also referred to as drivable area or simply freespace) for intelligent vehicles, with the full utilization of geometry information in a 3D driving environment. We provide explicit representations of optical flow and deduce the quadratic relationship between the optical flow component and the vertical coordinate. Through extensive experiments on severa
    
[^33]: 你可以通过后门攻击个性化联邦学习

    You Can Backdoor Personalized Federated Learning. (arXiv:2307.15971v1 [cs.CR])

    [http://arxiv.org/abs/2307.15971](http://arxiv.org/abs/2307.15971)

    该论文研究了后门攻击对个性化联邦学习的影响，并揭示了部分模型共享的个性化联邦学习方法容易受到后门攻击。研究者提出了三种后门攻击方法，并验证了它们的有效性。

    

    后门攻击对联邦学习系统的安全性构成重大威胁。然而，现有研究主要关注通用FL场景中的后门攻击和防御，即所有客户端合作训练一个全局模型。本文中，我们揭示了部分模型共享的个性化联邦学习方法仍然容易受到后门攻击的问题。我们提出了三种后门攻击方法：BapFL，BapFL+和Gen-BapFL，并经验证明它们可以有效攻击个性化联邦学习方法。

    Backdoor attacks pose a significant threat to the security of federated learning systems. However, existing research primarily focuses on backdoor attacks and defenses within the generic FL scenario, where all clients collaborate to train a single global model. \citet{qin2023revisiting} conduct the first study of backdoor attacks in the personalized federated learning (pFL) scenario, where each client constructs a personalized model based on its local data. Notably, the study demonstrates that pFL methods with partial model-sharing can significantly boost robustness against backdoor attacks. In this paper, we whistleblow that pFL methods with partial model-sharing are still vulnerable to backdoor attacks in the absence of any defense. We propose three backdoor attack methods: BapFL, BapFL+, and Gen-BapFL, and we empirically demonstrate that they can effectively attack the pFL methods. Specifically, the key principle of BapFL lies in maintaining clean local parameters while implanting t
    
[^34]: 图形压缩方法用于归纳节点表示学习

    Graph Condensation for Inductive Node Representation Learning. (arXiv:2307.15967v1 [cs.LG])

    [http://arxiv.org/abs/2307.15967](http://arxiv.org/abs/2307.15967)

    本论文提出了一种映射感知的图形压缩方法（MCond），通过学习节点之间的映射关系，实现了在合成图中高效地处理未知数据的能力。

    

    大规模图引导网络面临着计算挑战，限制了它们在不同应用中的有效性。为了解决这个问题，图形压缩作为一种有希望的技术出现了，它通过构建一个小的合成图来高效地训练图引导网络并保持性能。然而，由于节点之间的拓扑结构，图形压缩仅限于压缩观察到的训练节点及其对应的结构，因此缺乏有效处理未知数据的能力。因此，在推理阶段仍需要原始大图来对归纳节点进行消息传递，导致计算需求巨大。为了解决这个问题，我们提出了映射感知的图形压缩（MCond）方法，明确学习从原始节点到合成节点的一对多节点映射，以无缝地将新节点整合到合成图中。

    Graph neural networks (GNNs) encounter significant computational challenges when handling large-scale graphs, which severely restricts their efficacy across diverse applications. To address this limitation, graph condensation has emerged as a promising technique, which constructs a small synthetic graph for efficiently training GNNs while retaining performance. However, due to the topology structure among nodes, graph condensation is limited to condensing only the observed training nodes and their corresponding structure, thus lacking the ability to effectively handle the unseen data. Consequently, the original large graph is still required in the inference stage to perform message passing to inductive nodes, resulting in substantial computational demands. To overcome this issue, we propose mapping-aware graph condensation (MCond), explicitly learning the one-to-many node mapping from original nodes to synthetic nodes to seamlessly integrate new nodes into the synthetic graph for induc
    
[^35]: 网络拓扑对完全分布式学习的影响：初步调查

    The effect of network topologies on fully decentralized learning: a preliminary investigation. (arXiv:2307.15947v1 [cs.LG])

    [http://arxiv.org/abs/2307.15947](http://arxiv.org/abs/2307.15947)

    本研究通过分析不同网络拓扑结构对分布式学习模型性能的影响，揭示了节点连接性和网络属性在知识传播过程中的不同作用。结果表明，高连接性可能导致更好的模型性能。

    

    在分布式机器学习系统中，数据通常被分割在多个设备或节点之间，每个节点使用自己的数据训练本地模型。然后，这些本地模型被共享和合并，以创建一个可以在新数据上进行准确预测的全局模型。本文开始探索连接节点的网络拓扑对通过节点之间的直接协作训练的机器学习模型性能的影响。我们研究不同类型的拓扑结构如何影响“知识传播”，即节点能够将其他节点的数据中学习到的模式知识融入到本地模型中的能力。具体而言，我们强调了更或者更少连接的节点（中心节点和叶节点）以及宏观网络属性（主要是度分布和模块化）在这个过程中的不同作用。我们展示了，虽然已知弱连接能够保证知识传播，但具有更高的连接性可能会产生更好的模型性能。

    In a decentralized machine learning system, data is typically partitioned among multiple devices or nodes, each of which trains a local model using its own data. These local models are then shared and combined to create a global model that can make accurate predictions on new data. In this paper, we start exploring the role of the network topology connecting nodes on the performance of a Machine Learning model trained through direct collaboration between nodes. We investigate how different types of topologies impact the "spreading of knowledge", i.e., the ability of nodes to incorporate in their local model the knowledge derived by learning patterns in data available in other nodes across the networks. Specifically, we highlight the different roles in this process of more or less connected nodes (hubs and leaves), as well as that of macroscopic network properties (primarily, degree distribution and modularity). Among others, we show that, while it is known that even weak connectivity a
    
[^36]: 语言模型中复杂技能产生的理论

    A Theory for Emergence of Complex Skills in Language Models. (arXiv:2307.15936v1 [cs.LG])

    [http://arxiv.org/abs/2307.15936](http://arxiv.org/abs/2307.15936)

    本文提出了一个统计框架，通过分析语言模型的交叉熵损失与基本语言任务的能力之间的关系，揭示了语言模型中复杂技能产生的机制。研究结果表明，通过扩展定律，预训练模型能够高效学习，并表现出违反通常泛化理论的能力。

    

    当语言模型的参数集合和训练语料库扩大时，新的技能将在 AI 产品中出现的主要驱动因素。这种现象尚不为人所理解，并且通过对基于梯度训练的数学分析提供机械解释似乎很困难。本文采用不同的方法，使用著名的（和经验性的）LLM扩展定律和简单的统计框架来分析出现。贡献包括：（a）一个统计框架将LLM的交叉熵损失与语言任务基本技能的能力相关联。（b）数学分析表明，扩展定律意味着强烈的归纳偏见，使预训练模型能够学习得非常高效。我们非正式地称之为“弹弓泛化”，因为表面上看，它似乎提供了在技能水平上违反通常泛化理论的能力。（c）弹弓泛化的一个关键例子，即在执行任务时的能力。

    A major driver of AI products today is the fact that new skills emerge in language models when their parameter set and training corpora are scaled up. This phenomenon is poorly understood, and a mechanistic explanation via mathematical analysis of gradient-based training seems difficult. The current paper takes a different approach, analysing emergence using the famous (and empirical) Scaling Laws of LLMs and a simple statistical framework. Contributions include: (a) A statistical framework that relates cross-entropy loss of LLMs to competence on the basic skills that underlie language tasks. (b) Mathematical analysis showing that the Scaling Laws imply a strong form of inductive bias that allows the pre-trained model to learn very efficiently. We informally call this {\em slingshot generalization} since naively viewed it appears to give competence levels at skills that violate usual generalization theory. (c) A key example of slingshot generalization, that competence at executing task
    
[^37]: ATESA-B{\AE}RT: 一个用于基于方面的情感分析的异构集成学习模型

    ATESA-B{\AE}RT: A Heterogeneous Ensemble Learning Model for Aspect-Based Sentiment Analysis. (arXiv:2307.15920v1 [cs.CL])

    [http://arxiv.org/abs/2307.15920](http://arxiv.org/abs/2307.15920)

    ATESA-B{\AE}RT是一个基于方面的情感分析的异构集成学习模型，通过将问题分为方面词提取和方面词情感分析两个子任务，并使用\textit{argmax}多类别分类算法进行分析，提高了在方面级别上的粒度，改进了当前解决方案在多方面数据上的性能问题。

    

    随着在线评论数量的增加，情感分析模型的发展成为了确定消费者对不同产品和服务的意见的可能。到目前为止，情感分析已被证明是确定评论整体极性的有效工具。为了提高在方面级别上的粒度，更好地理解服务或产品，基于方面的情感分析任务首先旨在识别方面，然后确定用户对它们的意见。这项任务的复杂性在于同一评论可能会呈现多个方面，每个方面具有自己的极性。目前的解决方案在这种数据上表现不佳。我们通过提出ATESA-B{\AE}RT，一个用于基于方面的情感分析的异构集成学习模型来解决这个问题。首先，我们将问题分为两个子任务，即方面词提取和方面词情感分析。其次，我们使用\textit{argmax}多类别分类算法来对方面词进行分类。

    The increasing volume of online reviews has made possible the development of sentiment analysis models for determining the opinion of customers regarding different products and services. Until now, sentiment analysis has proven to be an effective tool for determining the overall polarity of reviews. To improve the granularity at the aspect level for a better understanding of the service or product, the task of aspect-based sentiment analysis aims to first identify aspects and then determine the user's opinion about them. The complexity of this task lies in the fact that the same review can present multiple aspects, each with its own polarity. Current solutions have poor performance on such data. We address this problem by proposing ATESA-B{\AE}RT, a heterogeneous ensemble learning model for Aspect-Based Sentiment Analysis. Firstly, we divide our problem into two sub-tasks, i.e., Aspect Term Extraction and Aspect Term Sentiment Analysis. Secondly, we use the \textit{argmax} multi-class 
    
[^38]: 机会主义环境空气质量监测和预测与可扩展的图神经网络

    Opportunistic Air Quality Monitoring and Forecasting with Expandable Graph Neural Networks. (arXiv:2307.15916v1 [cs.LG])

    [http://arxiv.org/abs/2307.15916](http://arxiv.org/abs/2307.15916)

    提出了一种可扩展的图神经网络模型，能够处理不同空间结构的已有和新增基础设施收集的环境空气质量数据，并嵌入到任何空气质量预测模型中应用于具有演变空间结构的场景。

    

    近年来，环境空气质量监测和预测已成为热门研究课题。由于城市地区已建立了健全的数据收集设施，基于数据驱动的空气质量预测方法引起了广泛关注。通常由国家研究机构或科技巨头部署的固定基础设施往往无法满足不同个性化场景的需求，例如在没有任何现有基础设施的区域进行预测。因此，规模较小的研究机构或有限预算的公司不得不寻求定制解决方案，通过引入更灵活的数据收集基础设施。在本文中，我们提出了一种可扩展的图注意力网络 (EGAT) 模型，它可以处理已有和新增基础设施收集的数据，同时适应不同的空间结构。此外，我们的提议可以嵌入任何空气质量预测模型，适用于具有演变空间结构的场景。

    Air Quality Monitoring and Forecasting has been a popular research topic in recent years. Recently, data-driven approaches for air quality forecasting have garnered significant attention, owing to the availability of well-established data collection facilities in urban areas. Fixed infrastructures, typically deployed by national institutes or tech giants, often fall short in meeting the requirements of diverse personalized scenarios, e.g., forecasting in areas without any existing infrastructure. Consequently, smaller institutes or companies with limited budgets are compelled to seek tailored solutions by introducing more flexible infrastructures for data collection. In this paper, we propose an expandable graph attention network (EGAT) model, which digests data collected from existing and newly-added infrastructures, with different spatial structures. Additionally, our proposal can be embedded into any air quality forecasting models, to apply to the scenarios with evolving spatial str
    
[^39]: Moisesdb: 一份超越四个音频源的分离数据集

    Moisesdb: A dataset for source separation beyond 4-stems. (arXiv:2307.15913v1 [cs.SD])

    [http://arxiv.org/abs/2307.15913](http://arxiv.org/abs/2307.15913)

    本文介绍了MoisesDB数据集，该数据集用于音乐源分离。它包含240首来自45位艺术家的曲目，涵盖了十二种音乐流派。该数据集具有两级层次分类法，超越了使用四个音频源的限制，有助于构建和评估细粒度的源分离系统。研究还提供了基线结果和分析，对于不同分离细粒度的开源分离模型的评估。

    

    本文介绍了用于音乐源分离的MoisesDB数据集。该数据集包含来自45位艺术家的240首曲目，涵盖了十二种音乐流派。对于每首歌曲，我们提供了其个别音频源，以两级层次分类法进行组织。这将有助于构建和评估细粒度的源分离系统，超越使用四个音频源（鼓、贝斯、其他和人声）由于缺乏数据而导致的限制。为了便于使用该数据集，我们发布了一个易于使用的Python库，以下载、处理和使用MoisesDB。此外，本文还提供了针对不同分离细粒度（四个、五个和六个音频源）的开源分离模型的基线结果，并对其进行了讨论。

    In this paper, we introduce the MoisesDB dataset for musical source separation. It consists of 240 tracks from 45 artists, covering twelve musical genres. For each song, we provide its individual audio sources, organized in a two-level hierarchical taxonomy of stems. This will facilitate building and evaluating fine-grained source separation systems that go beyond the limitation of using four stems (drums, bass, other, and vocals) due to lack of data. To facilitate the adoption of this dataset, we publish an easy-to-use Python library to download, process and use MoisesDB. Alongside a thorough documentation and analysis of the dataset contents, this work provides baseline results for open-source separation models for varying separation granularities (four, five, and six stems), and discuss their results.
    
[^40]: 在具有时间窗口的概率时空约束下的强化学习

    Reinforcement Learning Under Probabilistic Spatio-Temporal Constraints with Time Windows. (arXiv:2307.15910v1 [cs.AI])

    [http://arxiv.org/abs/2307.15910](http://arxiv.org/abs/2307.15910)

    我们提出了一种自动机理论方法来解决具有时间窗口的复杂时空约束下的强化学习问题，该方法能在整个学习过程中始终保持所需约束满足的概率。

    

    我们提出了一种自动机理论方法来解决具有时间窗口的复杂时空约束下的强化学习（RL）问题。该问题使用有界时态逻辑约束下的马尔可夫决策过程进行建模。与现有的RL方法可以最终学习到满足这些约束的最优策略不同，我们提出的方法在整个学习过程中始终保持所需约束满足的概率。这是通过将有界时态逻辑约束转化为总自动机，并基于关于转移概率的先前可用信息（即每个转移概率的上界和下界）避免“不安全”动作来实现的。我们在结果中提供了约束满足概率的理论保证。我们还在一个场景中提供了数值结果，该场景中，机器人在探索环境，发现高回报区域的同时，还需要执行一些周期性的拾取和交付任务

    We propose an automata-theoretic approach for reinforcement learning (RL) under complex spatio-temporal constraints with time windows. The problem is formulated using a Markov decision process under a bounded temporal logic constraint. Different from existing RL methods that can eventually learn optimal policies satisfying such constraints, our proposed approach enforces a desired probability of constraint satisfaction throughout learning. This is achieved by translating the bounded temporal logic constraint into a total automaton and avoiding "unsafe" actions based on the available prior information regarding the transition probabilities, i.e., a pair of upper and lower bounds for each transition probability. We provide theoretical guarantees on the resulting probability of constraint satisfaction. We also provide numerical results in a scenario where a robot explores the environment to discover high-reward regions while fulfilling some periodic pick-up and delivery tasks that are enc
    
[^41]: UniBriVL: 强大的音频驱动扩散模型的通用表示和生成

    UniBriVL: Robust Universal Representation and Generation of Audio Driven Diffusion Models. (arXiv:2307.15898v1 [cs.SD])

    [http://arxiv.org/abs/2307.15898](http://arxiv.org/abs/2307.15898)

    本文提出了一种名为UniBriVL的新型通用语言表示学习方法，该方法实现了音频驱动的扩散模型的生成。它能够稳健地学习语言表示，并捕捉到音频和图像之间的关联。实验结果表明UniBriVL在下游任务中表现出良好的效果，能够从音频中选择合适的图像。

    

    多模态大型模型因其在各种性能和下游任务中的优势而被认为是至关重要的。这些模型的发展对于未来实现通用人工智能至关重要。在本文中，我们提出了一种新颖的通用语言表示学习方法，称为UniBriVL，它基于Bridging-Vision-and-Language（BriVL）。通用BriVL将音频、图像和文本嵌入到一个共享空间中，实现了各种多模态应用的实现。我们的方法解决了稳健的语言（包括文本和音频）表示学习的主要挑战，并有效地捕捉到音频和图像之间的关联。此外，我们展示了从UniBriVL生成的图像的定性评估，这突出了我们的方法在从音频中创建图像方面的潜力。总体而言，我们的实验结果证明了UniBriVL在下游任务中的有效性以及其从音频中选择适当图像的能力。

    Multimodal large models have been recognized for their advantages in various performance and downstream tasks. The development of these models is crucial towards achieving general artificial intelligence in the future. In this paper, we propose a novel universal language representation learning method called UniBriVL, which is based on Bridging-Vision-and-Language (BriVL). Universal BriVL embeds audio, image, and text into a shared space, enabling the realization of various multimodal applications. Our approach addresses major challenges in robust language (both text and audio) representation learning and effectively captures the correlation between audio and image. Additionally, we demonstrate the qualitative evaluation of the generated images from UniBriVL, which serves to highlight the potential of our approach in creating images from audio. Overall, our experimental results demonstrate the efficacy of UniBriVL in downstream tasks and its ability to choose appropriate images from au
    
[^42]: 仅使用一个步长的新型梯度时序差分算法：通过$L$-$\lambda$平滑性进行收敛速率分析

    A new Gradient TD Algorithm with only One Step-size: Convergence Rate Analysis using $L$-$\lambda$ Smoothness. (arXiv:2307.15892v1 [cs.LG])

    [http://arxiv.org/abs/2307.15892](http://arxiv.org/abs/2307.15892)

    本论文提出了一种新的梯度时序差分算法，只使用一个步长参数，并证明收敛速度至少为$O(1/t)$。

    

    梯度时序差分（GTD）算法是第一个具有收敛保证的离策略学习线性函数逼近算法，其复杂度为$O(d)$（$d$是特征数量）。本文提出了一种名为Impression GTD的全新单时间尺度GTD算法，用于最小化期望td更新（NEU）目标，并只有一个步长参数。我们证明这种新算法的收敛速度至少与$O(1/t)$一样快。

    Gradient Temporal Difference (GTD) algorithms (Sutton et al., 2008, 2009) are the first $O(d)$ ($d$ is the number features) algorithms that have convergence guarantees for off-policy learning with linear function approximation. Liu et al. (2015) and Dalal et. al. (2018) proved the convergence rates of GTD, GTD2 and TDC are $O(t^{-\alpha/2})$ for some $\alpha \in (0,1)$. This bound is tight (Dalal et al., 2020), and slower than $O(1/\sqrt{t})$. GTD algorithms also have two step-size parameters, which are difficult to tune. In literature, there is a "single-time-scale" formulation of GTD. However, this formulation still has two step-size parameters.  This paper presents a truly single-time-scale GTD algorithm for minimizing the Norm of Expected td Update (NEU) objective, and it has only one step-size parameter. We prove that the new algorithm, called Impression GTD, converges at least as fast as $O(1/t)$. Furthermore, based on a generalization of the expected smoothness (Gower et al. 201
    
[^43]: 冰立方实验中最近的中微子振荡结果

    Recent neutrino oscillation result with the IceCube experiment. (arXiv:2307.15855v1 [hep-ex])

    [http://arxiv.org/abs/2307.15855](http://arxiv.org/abs/2307.15855)

    冰立方实验使用卷积神经网络重建了中微子相互作用，取得了物理灵敏度的进展，并展示了中微子振荡的最新结果。

    

    冰立方南极中微子观测站是一个仪器化的切伦科夫探测器，覆盖了南极的一个立方公里的冰。冰立方的主要科学目标是探测来自天体源的TeV中微子发射。在冰立方阵列的下方中心，有一个名为DeepCore的子探测器，该子探测器具有较高密度的配置，可以降低冰立方的能量阈值，并观测到GeV尺度的中微子，为大气中微子振荡研究打开了窗口。最近，在DeepCore探测器中使用卷积神经网络重建中微子相互作用，取得了物理灵敏度的进展。本文介绍了使用CNN重建的中微子样本进行大气μ中微子消失分析的最新冰立方结果，并与现有的全球测量结果进行了比较。

    The IceCube South Pole Neutrino Observatory is a Cherenkov detector instrumented in a cubic kilometer of ice at the South Pole. IceCube's primary scientific goal is the detection of TeV neutrino emissions from astrophysical sources. At the lower center of the IceCube array, there is a subdetector called DeepCore, which has a denser configuration that makes it possible to lower the energy threshold of IceCube and observe GeV-scale neutrinos, opening the window to atmospheric neutrino oscillations studies. Advances in physics sensitivity have recently been achieved by employing Convolutional Neural Networks to reconstruct neutrino interactions in the DeepCore detector. In this contribution, the recent IceCube result from the atmospheric muon neutrino disappearance analysis using the CNN-reconstructed neutrino sample is presented and compared to the existing worldwide measurements.
    
[^44]: 基于巴克汉姆π定理的无量纲策略：是推广数值结果的好方法吗？

    Dimensionless Policies based on the Buckingham $\pi$ Theorem: Is it a good way to Generalize Numerical Results?. (arXiv:2307.15852v1 [math.OC])

    [http://arxiv.org/abs/2307.15852](http://arxiv.org/abs/2307.15852)

    通过使用无量纲变量和制度的概念，我们可以将数值生成的最优控制法则推广到量纲相似的系统，这对于推广解决更复杂的高维问题的策略具有潜在意义。

    

    如果上下文环境和定义运动控制问题的变量列表是在量纲上相似的话，是可以的。我们在这里展示了通过使用无量纲变量修改问题的形式，可以将数值生成的最优控制法则重新应用于在量纲上相似的子空间系统。我们通过对受扭矩限制的倒立摆经典运动控制问题进行数值生成的最优控制器的展示来证明这一点。我们还讨论了制度的概念，即上下文变量空间中的一个区域，可以帮助放宽量纲相似性的条件。此外，我们还讨论了将上下文特定策略的输入和输出进行量纲缩放与在分析方程中用新的系统参数替代量纲相似系统的等价性。尚需进一步研究此方法是否也适用于推广更复杂的高维问题的策略。

    Yes if the context, the list of variables defining the motion control problem, is dimensionally similar. Here we show that by modifying the problem formulation using dimensionless variables, we can re-use the optimal control law generated numerically for a specific system to a sub-space of dimensionally similar systems. This is demonstrated, with numerically generated optimal controllers, for the classic motion control problem of swinging-up a torque-limited inverted pendulum. We also discuss the concept of regime, a region in the space of context variables, that can help relax the condition on dimensional similarity. Futhermore, we discuss how applying dimensionnal scaling of the input and output of a context-specific policy is equivalent to substituing the new systems parameters in an analytical equation for dimentionnaly similar systems. It remains to be seen if this approach can also help generalizing policies for more complex high-dimensional problems.
    
[^45]: 使用项目反应理论对综合算法组合进行评估

    Comprehensive Algorithm Portfolio Evaluation using Item Response Theory. (arXiv:2307.15850v1 [stat.ML])

    [http://arxiv.org/abs/2307.15850](http://arxiv.org/abs/2307.15850)

    本文提出了一种改进的基于IRT的框架，用于评估算法组合在数据集仓库中的性能，同时获取算法一致性和异常性等特征。该框架通过对传统IRT模型进行倒转和重新解释来实现，不需要额外的数据集特征计算。

    

    项目反应理论（IRT）被提出用于教育心理测量学领域，用于评估学生能力、测试题难度和区分度。最近，IRT已被应用于评估单个分类数据集上的机器学习算法性能，其中学生现在是一个算法，而测试题是算法要对观察结果进行分类。本文提出了一种改进的基于IRT的框架，用于评估一个算法组合在一个数据集仓库中的表现，同时获取算法一致性和异常性等更丰富的特征，这些特征描述了算法性能的重要方面。这些特征是通过对传统IRT模型进行新颖的倒转和重新解释而得到的，而不需要额外的数据集特征计算。我们对不同应用的算法组合在该框架上进行了测试，证明了其广泛适用性。

    Item Response Theory (IRT) has been proposed within the field of Educational Psychometrics to assess student ability as well as test question difficulty and discrimination power. More recently, IRT has been applied to evaluate machine learning algorithm performance on a single classification dataset, where the student is now an algorithm, and the test question is an observation to be classified by the algorithm. In this paper we present a modified IRT-based framework for evaluating a portfolio of algorithms across a repository of datasets, while simultaneously eliciting a richer suite of characteristics such as algorithm consistency and anomalousness - that describe important aspects of algorithm performance. These characteristics arise from a novel inversion and reinterpretation of the traditional IRT model without requiring additional dataset feature computations. We test this framework on algorithm portfolios for a wide range of applications, demonstrating the broad applicability 
    
[^46]: 基于人类评价反馈的原始技能导向机器人学习

    Primitive Skill-based Robot Learning from Human Evaluative Feedback. (arXiv:2307.15801v1 [cs.RO])

    [http://arxiv.org/abs/2307.15801](http://arxiv.org/abs/2307.15801)

    基于人类评价反馈的原始技能导向机器人学习框架（SEED）结合了从人类反馈中进行强化学习（RLHF）和基于原始技能的强化学习，有效解决了稀疏奖励和长时程任务复杂性问题，并提高了学习效率和安全性。

    

    强化学习算法在处理真实环境中的长时程机器人操作任务时面临着样本效率和安全性问题。为了克服这些挑战，我们提出了一种新的框架，SEED，它结合了两种方法：从人类反馈中进行强化学习（RLHF）和基于原始技能的强化学习。这两种方法在解决稀疏奖励问题和长时程任务中的复杂性方面特别有效。通过结合它们，SEED减少了在真实环境中通过强化学习训练机器人操作所需的人力投入，并提高了安全性。此外，参数化技能提供了对代理的高级意图的清晰视图，允许人类在执行之前评估技能选择。这个特性使得训练过程更安全、更高效。为了评估SEED的性能，我们在五个操作任务上进行了大量实验证明。

    Reinforcement learning (RL) algorithms face significant challenges when dealing with long-horizon robot manipulation tasks in real-world environments due to sample inefficiency and safety issues. To overcome these challenges, we propose a novel framework, SEED, which leverages two approaches: reinforcement learning from human feedback (RLHF) and primitive skill-based reinforcement learning. Both approaches are particularly effective in addressing sparse reward issues and the complexities involved in long-horizon tasks. By combining them, SEED reduces the human effort required in RLHF and increases safety in training robot manipulation with RL in real-world settings. Additionally, parameterized skills provide a clear view of the agent's high-level intentions, allowing humans to evaluate skill choices before they are executed. This feature makes the training process even safer and more efficient. To evaluate the performance of SEED, we conducted extensive experiments on five manipulation
    
[^47]: 概要、亮点和行动项目：设计、实现和评估基于LLM的会议总结系统

    Summaries, Highlights, and Action items: Design, implementation and evaluation of an LLM-powered meeting recap system. (arXiv:2307.15793v1 [cs.HC])

    [http://arxiv.org/abs/2307.15793](http://arxiv.org/abs/2307.15793)

    这项研究设计、实现和评估了一种基于LLM的会议总结系统，通过减少个人会议负担和增加会议输出的清晰度和一致性，提高了会议体验。

    

    会议在工作协调中发挥着关键的基础设施作用。近年来，由于向混合和远程工作的转变，越来越多的会议正在转移到在线计算机媒体空间。这导致了新的问题（例如在更不吸引人的会议上花费更多的时间）和新的机会（例如自动转录/字幕和总结支持）。最近的大型语言模型（LLMs）在对话总结方面取得了进展，通过减少个人的会议负担和增加会议输出的清晰度和一致性，有可能提高会议体验。尽管存在这种潜力，但由于长篇转录和无法根据用户的上下文捕捉到多样的总结需求，它们面临着技术限制。为了填补这些差距，我们设计、实现并在上下文中评估了一种会议总结系统。我们首先构思了两个明显的总结表示方式——重要亮点和结构化的分级会议纪要视图。我们开发了一个系统来实现这些表示方法。

    Meetings play a critical infrastructural role in the coordination of work. In recent years, due to shift to hybrid and remote work, more meetings are moving to online Computer Mediated Spaces. This has led to new problems (e.g. more time spent in less engaging meetings) and new opportunities (e.g. automated transcription/captioning and recap support). Recent advances in large language models (LLMs) for dialog summarization have the potential to improve the experience of meetings by reducing individuals' meeting load and increasing the clarity and alignment of meeting outputs. Despite this potential, they face technological limitation due to long transcripts and inability to capture diverse recap needs based on user's context. To address these gaps, we design, implement and evaluate in-context a meeting recap system. We first conceptualize two salient recap representations -- important highlights, and a structured, hierarchical minutes view. We develop a system to operationalize the rep
    
[^48]: SAFE: 基于显著性的DNN自动驾驶系统的对抗性解释

    SAFE: Saliency-Aware Counterfactual Explanations for DNN-based Automated Driving Systems. (arXiv:2307.15786v1 [cs.LG])

    [http://arxiv.org/abs/2307.15786](http://arxiv.org/abs/2307.15786)

    本文提出了一种基于显著性图的方法，来生成更具信息性的CF解释，用于解释DNN自动驾驶系统的决策过程。

    

    CF解释器识别出在输入中最少的修改将模型的输出改变为其补集。换句话说，CF解释器计算出越过模型决策边界所需的最小修改。目前的深度生成CF模型通常与用户选择的特征一起工作，而不是关注黑盒模型的判别特征。因此，这样的CF示例可能不一定位于决策边界附近，从而违背了CF的定义。为了解决这个问题，本文提出了一种新颖的方法，利用显著图生成更具信息性的CF解释。

    A CF explainer identifies the minimum modifications in the input that would alter the model's output to its complement. In other words, a CF explainer computes the minimum modifications required to cross the model's decision boundary. Current deep generative CF models often work with user-selected features rather than focusing on the discriminative features of the black-box model. Consequently, such CF examples may not necessarily lie near the decision boundary, thereby contradicting the definition of CFs. To address this issue, we propose in this paper a novel approach that leverages saliency maps to generate more informative CF explanations. Source codes are available at: https://github.com/Amir-Samadi//Saliency_Aware_CF.
    
[^49]: LLM-Rec: 通过引导大型语言模型进行个性化推荐

    LLM-Rec: Personalized Recommendation via Prompting Large Language Models. (arXiv:2307.15780v1 [cs.CL])

    [http://arxiv.org/abs/2307.15780](http://arxiv.org/abs/2307.15780)

    本文通过引导大型语言模型进行个性化推荐的研究，提出了四种不同的引导策略，并通过实验证明了这些策略的有效性。这一发现强调了在个性化内容推荐中，采用多样的引导和输入增强技术可以提高大型语言模型的推荐性能。

    

    本文通过输入增强技术，研究了多种不同的引导策略，以提高大型语言模型（LLM）在个性化内容推荐方面的性能。我们提出的方法名为LLM-Rec，包括四种不同的引导策略：（1）基础引导，（2）推荐驱动引导，（3）参与引导引导，和（4）推荐驱动+参与引导引导。实验证明，将原始内容描述与LLM生成的增强输入文本结合起来，采用这些引导策略可以提高推荐性能。这一发现强调了在个性化内容推荐中，通过引入多样的引导和输入增强技术来提升大型语言模型的推荐能力的重要性。

    We investigate various prompting strategies for enhancing personalized content recommendation performance with large language models (LLMs) through input augmentation. Our proposed approach, termed LLM-Rec, encompasses four distinct prompting strategies: (1) basic prompting, (2) recommendation-driven prompting, (3) engagement-guided prompting, and (4) recommendation-driven + engagement-guided prompting. Our empirical experiments show that combining the original content description with the augmented input text generated by LLM using these prompting strategies leads to improved recommendation performance. This finding highlights the importance of incorporating diverse prompts and input augmentation techniques to enhance the recommendation capabilities with large language models for personalized content recommendation.
    
[^50]: 在图嵌入中基于球面和双曲面拓扑的编码应用于Ising MRF模型：经典和量子拓扑机器学习

    Spherical and Hyperbolic Toric Topology-Based Codes On Graph Embedding for Ising MRF Models: Classical and Quantum Topology Machine Learning. (arXiv:2307.15778v1 [cs.IT])

    [http://arxiv.org/abs/2307.15778](http://arxiv.org/abs/2307.15778)

    本论文介绍了在图嵌入中应用信息几何来描述Ising模型的基态，通过利用球面和双曲面拓扑上的编码，建立了机器学习和纠错编码之间的联系，并通过优化纠错码和发展嵌入方法提出了一种新的编码方法。

    

    本文介绍了将信息几何应用于描述Ising模型的基态的方法。通过利用托里克和球面拓扑上的循环和准循环码的奇偶检验矩阵来实现。该方法建立了机器学习和纠错编码之间的联系，特别是在自同构和准循环码循环矩阵的尺寸方面。这种方法对基于捕获集的嵌入方法的发展具有影响。利用统计物理学和数字几何学来优化纠错码，从而导致这些嵌入和稀疏因子化方法的出现。本文通过演示长距离领域的最新DNN架构（ChordMixer，Mega，Mega-chunk，CDIL，...）与特定类型（Cage-graph，Repeat Accumulate）的区块和卷积LDPC码等价的方式，建立了DNN架构和纠错编码之间的直接联系。

    The paper introduces the application of information geometry to describe the ground states of Ising models. This is achieved by utilizing parity-check matrices of cyclic and quasi-cyclic codes on toric and spherical topologies. The approach establishes a connection between machine learning and error-correcting coding, specifically in terms of automorphism and the size of the circulant of the quasi-cyclic code. This proposed approach has implications for the development of new embedding methods based on trapping sets. Statistical physics and number geometry are utilized to optimize error-correcting codes, leading to these embedding and sparse factorization methods. The paper establishes a direct connection between DNN architecture and error-correcting coding by demonstrating how state-of-the-art DNN architectures (ChordMixer, Mega, Mega-chunk, CDIL, ...) from the long-range arena can be equivalent to specific types (Cage-graph, Repeat Accumulate) of block and convolutional LDPC codes. Q
    
[^51]: 选择和增强：增强稠密检索知识图谱增强

    Select and Augment: Enhanced Dense Retrieval Knowledge Graph Augmentation. (arXiv:2307.15776v1 [cs.CL])

    [http://arxiv.org/abs/2307.15776](http://arxiv.org/abs/2307.15776)

    本文提出了一种选择和增强的方法来改进文本增强的知识图谱嵌入，通过多任务框架选择相关的文本描述，并对知识图谱嵌入进行对齐或增强。

    

    在自然语言处理社区中，将文本信息注入知识图谱（KG）实体表示已经成为一个值得探索的领域，以提高KG相关任务的性能。常用的外部知识增强KG嵌入的方法包括语义丰富的依赖解析特征、一组相关关键词，以及来自外部语料库（如维基百科）的完整文本描述。尽管这种创新（文本增强的KG嵌入）取得了一定的进展，但本文提出这种方法可以进一步改进。我们不再使用单一文本描述（因为文本的固有语义歧义无法充分表示一个实体），而是提出了一个多任务框架，既能选择与KG实体相关的一组文本描述，又能将KG嵌入与文本描述进行对齐或增强。与之前将形式化实体描述插入知识库的方法不同，这一方法是提供了对KG嵌入进行增强和对齐的新途径。

    Injecting textual information into knowledge graph (KG) entity representations has been a worthwhile expedition in terms of improving performance in KG oriented tasks within the NLP community. External knowledge often adopted to enhance KG embeddings ranges from semantically rich lexical dependency parsed features to a set of relevant key words to entire text descriptions supplied from an external corpus such as wikipedia and many more. Despite the gains this innovation (Text-enhanced KG embeddings) has made, the proposal in this work suggests that it can be improved even further. Instead of using a single text description (which would not sufficiently represent an entity because of the inherent lexical ambiguity of text), we propose a multi-task framework that jointly selects a set of text descriptions relevant to KG entities as well as align or augment KG embeddings with text descriptions. Different from prior work that plugs formal entity descriptions declared in knowledge bases, th
    
[^52]: Hydra效应：语言模型计算中的自适应自修复机制

    The Hydra Effect: Emergent Self-repair in Language Model Computations. (arXiv:2307.15771v1 [cs.LG])

    [http://arxiv.org/abs/2307.15771](http://arxiv.org/abs/2307.15771)

    本研究通过因果分析探究了语言模型计算的内部结构，发现了Hydra效应和晚期MLP层的平衡功能，并分析了它们在语言模型中的影响。

    

    本研究使用因果分析探究语言模型计算的内部结构，并展示了两种模式：（1）一种自适应计算形式，即语言模型中的某一自注意层被删减后另一层进行补偿（我们称之为Hydra效应）；（2）在后期多层感知机层中存在的平衡功能，用于调节最大似然令牌。我们的删减研究表明，语言模型层之间通常相对松散耦合（对一层的删减只会影响一小部分下游层）。令人惊讶的是，即使在没有任何形式的随机失活的语言模型中，这些效应仍然存在。我们在事实回忆的背景下分析了这些效应，并考虑了它们对语言模型的电路层面归因的影响。

    We investigate the internal structure of language model computations using causal analysis and demonstrate two motifs: (1) a form of adaptive computation where ablations of one attention layer of a language model cause another layer to compensate (which we term the Hydra effect) and (2) a counterbalancing function of late MLP layers that act to downregulate the maximum-likelihood token. Our ablation studies demonstrate that language model layers are typically relatively loosely coupled (ablations to one layer only affect a small number of downstream layers). Surprisingly, these effects occur even in language models trained without any form of dropout. We analyse these effects in the context of factual recall and consider their implications for circuit-level attribution in language models.
    
[^53]: CHATREPORT：通过基于LLM工具实现可持续性披露分析的民主化

    CHATREPORT: Democratizing Sustainability Disclosure Analysis through LLM-based Tools. (arXiv:2307.15770v1 [cs.CL])

    [http://arxiv.org/abs/2307.15770](http://arxiv.org/abs/2307.15770)

    本论文介绍了一种名为ChatReport的基于LLM的系统，它通过实现可追溯的答案和解决领域专家参与低效性的问题，旨在通过自动分析企业可持续性报告，实现可持续性披露分析民主化。

    

    面对气候变化，公司真的在朝着更可持续经营迈出实质性的步伐吗？一个全面的答案可以在企业可持续性报告的密集信息中找到。然而，这些报告的数量和复杂性使人工分析成本非常高昂。因此，只有少数的机构拥有资源能够大规模分析这些报告，这导致可持续性报告缺乏透明度。通过基于LLM自动分析工具赋能利益相关者可能是实现可持续性报告分析民主化的一种有希望的方式。然而，开发这样的工具面临挑战，主要原因是LLM的幻觉问题和将领域专家引入AI开发过程的低效性。在本文中，我们介绍了ChatReport，这是一种基于LLM的新型系统，用于自动化分析企业可持续性报告，通过使答案可追溯来减少幻觉的危害，并解决领域专家参与AI开发过程的低效性。

    In the face of climate change, are companies really taking substantial steps toward more sustainable operations? A comprehensive answer lies in the dense, information-rich landscape of corporate sustainability reports. However, the sheer volume and complexity of these reports make human analysis very costly. Therefore, only a few entities worldwide have the resources to analyze these reports at scale, which leads to a lack of transparency in sustainability reporting. Empowering stakeholders with LLM-based automatic analysis tools can be a promising way to democratize sustainability report analysis. However, developing such tools is challenging due to (1) the hallucination of LLMs and (2) the inefficiency of bringing domain experts into the AI development loop. In this paper, we ChatReport, a novel LLM-based system to automate the analysis of corporate sustainability reports, addressing existing challenges by (1) making the answers traceable to reduce the harm of hallucination and (2) a
    
[^54]: 可再现性探究：从材料科学中的NLP研究中获得的见解

    Lessons in Reproducibility: Insights from NLP Studies in Materials Science. (arXiv:2307.15759v1 [physics.chem-ph])

    [http://arxiv.org/abs/2307.15759](http://arxiv.org/abs/2307.15759)

    这两篇论文对于材料科学领域的NLP研究提供了重要的可再现性分析，其中包括了详尽的工作流程、整洁的代码库和清晰的模型评估指导，为未来的材料科学出版物树立了良好的标准。

    

    自然语言处理（NLP）作为人工智能中的基石领域，越来越多地被应用于材料科学文献领域。本研究对该领域中的两项开创性研究：“机器学习和编码的氧化物材料合成参数”（Kim等人）和“无监督的词嵌入从材料科学文献中提取潜在知识”（Tshitoyan等人）进行了可再现性分析。我们的研究旨在从可再现性的角度理解这些研究，认识到它们对材料信息学领域的重要影响，而不是批评它们。我们的研究表明，这两篇论文提供了详尽的工作流程、整洁且有良好文档的代码库，以及清晰的模型评估指导。这使得成功复制他们的结果并部分重现他们的发现变得更加容易。通过这样做，它们为未来的材料科学出版物树立了值得称赞的标准。

    Natural Language Processing (NLP), a cornerstone field within artificial intelligence, has been increasingly utilized in the field of materials science literature. Our study conducts a reproducibility analysis of two pioneering works within this domain: "Machine-learned and codified synthesis parameters of oxide materials" by Kim et al., and "Unsupervised word embeddings capture latent knowledge from materials science literature" by Tshitoyan et al. We aim to comprehend these studies from a reproducibility perspective, acknowledging their significant influence on the field of materials informatics, rather than critiquing them. Our study indicates that both papers offered thorough workflows, tidy and well-documented codebases, and clear guidance for model evaluation. This makes it easier to replicate their results successfully and partially reproduce their findings. In doing so, they set commendable standards for future materials science publications to aspire to. However, our analysis 
    
[^55]: AI用于预测行动：超越气候预测

    AI for Anticipatory Action: Moving Beyond Climate Forecasting. (arXiv:2307.15727v1 [cs.LG])

    [http://arxiv.org/abs/2307.15727](http://arxiv.org/abs/2307.15727)

    AI用于预测行动从气候预测向预测行动转变，利用机器学习模型的强大能力，在评估气候对特定人口的影响方面填补了方法论上的差距，以推进对气候变化最脆弱人口的灾害响应。

    

    灾害应对机构正从气候预测范式转向预测行动范式：不仅评估气候将如何，而且评估气候对特定人口的影响，从而实现主动响应和资源分配。机器学习模型在气候预测方面变得异常强大，但在促进预测行动方面仍存在方法论上的差距。本文综述了预测行动的概述，回顾了机器学习的相关应用，识别了共同面临的挑战，并突出了机器学习在推进对气候变化最脆弱人口的灾害响应方面的独特贡献。

    Disaster response agencies have been shifting from a paradigm of climate forecasting towards one of anticipatory action: assessing not just what the climate will be, but how it will impact specific populations, thereby enabling proactive response and resource allocation. Machine learning models are becoming exceptionally powerful at climate forecasting, but methodological gaps remain in terms of facilitating anticipatory action. Here we provide an overview of anticipatory action, review relevant applications of machine learning, identify common challenges, and highlight areas where machine learning can uniquely contribute to advancing disaster response for populations most vulnerable to climate change.
    
[^56]: 基于好奇心驱动的强化学习低级飞行控制

    Curiosity-Driven Reinforcement Learning based Low-Level Flight Control. (arXiv:2307.15724v1 [cs.LG])

    [http://arxiv.org/abs/2307.15724](http://arxiv.org/abs/2307.15724)

    本文提出了一种基于好奇心驱动的算法，通过从里程数据生成适当的电机速度来实现自主学习以控制飞行。通过该算法，四旋翼飞行器可以在控制偏航方向朝向目标位置的同时通过障碍物，该算法基于预测误差的新的好奇心方法。

    

    好奇心是许多有智能的自然生物的主要动机之一，通过具有可衡量智能水平的探索来实现更有效的学习。它使人类和许多动物能够通过寻找让他们感到惊讶的状态来高效地探索，以便学习更多他们所不知道的内容。因此，在保持好奇心的同时，他们能够学得更好。在机器学习领域，好奇心通常被结合到基于强化学习的算法中，作为一种内在的奖励。本研究提出了一种基于好奇心驱动的算法，通过从里程数据生成适当的电机速度来实现自主学习以控制飞行。通过我们提出的算法，四旋翼飞行器可以在控制偏航方向朝向所需位置的同时通过障碍物。为了实现这一目标，我们还提出了一种基于预测误差的新的好奇心方法。我们通过使用在线策略、离线策略和在线策略加噪音的测试来验证我们的算法。

    Curiosity is one of the main motives in many of the natural creatures with measurable levels of intelligence for exploration and, as a result, more efficient learning. It makes it possible for humans and many animals to explore efficiently by searching for being in states that make them surprised with the goal of learning more about what they do not know. As a result, while being curious, they learn better. In the machine learning literature, curiosity is mostly combined with reinforcement learning-based algorithms as an intrinsic reward. This work proposes an algorithm based on the drive of curiosity for autonomous learning to control by generating proper motor speeds from odometry data. The quadcopter controlled by our proposed algorithm can pass through obstacles while controlling the Yaw direction of the quad-copter toward the desired location. To achieve that, we also propose a new curiosity approach based on prediction error. We ran tests using on-policy, off-policy, on-policy pl
    
[^57]: 基于接受遏制措施的病毒扩展的代理模型模拟

    Agent-Based Model: Simulating a Virus Expansion Based on the Acceptance of Containment Measures. (arXiv:2307.15723v1 [cs.AI])

    [http://arxiv.org/abs/2307.15723](http://arxiv.org/abs/2307.15723)

    该论文提出了一种基于代理模型的方法来模拟病毒扩展，并结合个体特征和人口行为，以评估遏制措施的影响。

    

    隔离性流行病模型根据个体的疾病状态将其分类，如SEIRD模型（易感-暴露-感染-康复-死亡）。这些模型确定了影响爆发规模的参数，如传染和康复率。然而，它们没有考虑个体特征或人口行为，这对评估缓解策略（如COVID-19中的口罩使用或HIV中的避孕套分发）至关重要。此外，研究强调公民团结、人际信任和政府信誉在解释国家之间传染率差异方面的作用。代理建模（ABM）通过模拟个体组成部分、其行为和环境内的相互作用提供了研究复杂系统的有价值方法。ABM为分析社会现象提供了有用的工具。在这项研究中，我们提出了一种将适应的SEIRD模型与决策模型相结合的ABM架构，以模拟病毒的扩展。

    Compartmental epidemiological models categorize individuals based on their disease status, such as the SEIRD model (Susceptible-Exposed-Infected-Recovered-Dead). These models determine the parameters that influence the magnitude of an outbreak, such as contagion and recovery rates. However, they don't account for individual characteristics or population actions, which are crucial for assessing mitigation strategies like mask usage in COVID-19 or condom distribution in HIV. Additionally, studies highlight the role of citizen solidarity, interpersonal trust, and government credibility in explaining differences in contagion rates between countries. Agent-Based Modeling (ABM) offers a valuable approach to study complex systems by simulating individual components, their actions, and interactions within an environment. ABM provides a useful tool for analyzing social phenomena. In this study, we propose an ABM architecture that combines an adapted SEIRD model with a decision-making model for 
    
[^58]: 利用大型语言模型进行药理学数据库的自然界面

    Utilizing Large Language Models for Natural Interface to Pharmacology Databases. (arXiv:2307.15717v1 [cs.CL])

    [http://arxiv.org/abs/2307.15717](http://arxiv.org/abs/2307.15717)

    该论文介绍了一种利用大型语言模型的自然语言界面，旨在与药理学数据库中的结构化信息进行交互，具有广泛的应用价值。

    

    药物开发过程需要药理学家进行各种任务，如查阅文献，提出假设，设计实验和解释结果。每个阶段都需要访问和查询大量信息。在本文中，我们介绍了一种基于大型语言模型（LLM）的自然语言界面，旨在与存储在数据库中的结构化信息进行交互。我们的实验证明了所提出框架的可行性和有效性。该框架可以推广到查询各种药物数据和知识库。

    The drug development process necessitates that pharmacologists undertake various tasks, such as reviewing literature, formulating hypotheses, designing experiments, and interpreting results. Each stage requires accessing and querying vast amounts of information. In this abstract, we introduce a Large Language Model (LLM)-based Natural Language Interface designed to interact with structured information stored in databases. Our experiments demonstrate the feasibility and effectiveness of the proposed framework. This framework can generalize to query a wide range of pharmaceutical data and knowledge bases.
    
[^59]: 使用基于生成式人工智能的极端摘要化科学文献来改进初级医疗保健工作流程

    Improving Primary Healthcare Workflow Using Extreme Summarization of Scientific Literature Based on Generative AI. (arXiv:2307.15715v1 [cs.CL])

    [http://arxiv.org/abs/2307.15715](http://arxiv.org/abs/2307.15715)

    本研究利用生成式人工智能技术对科学论文的摘要进行极端摘要化，旨在帮助初级保健专业人员减轻认知负荷，从而提高其工作效率和减少心理负担。

    

    初级保健专业人员在指导以证据为基础的实践方面，如何跟上最新的科学文献一直是一个挑战。为了解决这个问题，我们使用基于大规模语言模型的生成式人工智能技术来对科学论文的摘要进行总结。我们的目标是研究生成式人工智能在减少从业者认知负荷方面的潜力，从而探索其减轻心理努力和负担的能力。研究参与者接受与预防保健和行为改变相关的两个案例，模拟对新的科学文献进行搜索。研究包括来自斯洛文尼亚和美国的113名大学生，被随机分成三个不同的研究组。第一组被分配阅读完整的摘要，第二组被分配阅读由人工智能生成的短摘要，第三组有选择性地阅读。

    Primary care professionals struggle to keep up to date with the latest scientific literature critical in guiding evidence-based practice related to their daily work. To help solve the above-mentioned problem, we employed generative artificial intelligence techniques based on large-scale language models to summarize abstracts of scientific papers. Our objective is to investigate the potential of generative artificial intelligence in diminishing the cognitive load experienced by practitioners, thus exploring its ability to alleviate mental effort and burden. The study participants were provided with two use cases related to preventive care and behavior change, simulating a search for new scientific literature. The study included 113 university students from Slovenia and the United States randomized into three distinct study groups. The first group was assigned to the full abstracts. The second group was assigned to the short abstracts generated by AI. The third group had the option to se
    
[^60]: 带有掩码困难实例挖掘的多示例学习框架用于全切片图像分类

    Multiple Instance Learning Framework with Masked Hard Instance Mining for Whole Slide Image Classification. (arXiv:2307.15254v1 [cs.CV])

    [http://arxiv.org/abs/2307.15254](http://arxiv.org/abs/2307.15254)

    这篇论文提出了一种带有掩码困难实例挖掘的多示例学习框架，用于全切片图像分类。该框架通过使用共享学习结构和一致性约束来探索潜在的难以分类的实例，并通过动量教师隐式挖掘这些实例来训练学生模型，从而提高分类性能。

    

    全切片图像（WSI）分类通常被形式化为多示例学习（MIL）问题。由于阳性组织仅占了吉比像素WSI的一小部分，现有的MIL方法直观地侧重于通过注意力机制识别显著实例。然而，这导致偏向易于分类的实例，忽视了难以分类的实例。一些文献揭示了困难示例对于准确建模边界是有益的。通过将这一思想应用到实例级别，我们详细阐述了一种新的MIL框架，即带有掩码困难实例挖掘的MIL（MHIM-MIL），它使用一个共享学习结构（教师-学生）和一致性约束来探索潜在的困难实例。使用基于注意力分数的多个实例掩码策略，MHIM-MIL采用动量教师来隐式挖掘用于训练学生模型的困难实例，学生模型可以是任何基于注意力的MIL模型。这个反直觉的策略对于提高分类性能是至关重要的。

    The whole slide image (WSI) classification is often formulated as a multiple instance learning (MIL) problem. Since the positive tissue is only a small fraction of the gigapixel WSI,existing MIL methods intuitively focus on identifying salient instances via attention mechanisms. However, this leads to a bias towards easy-to-classify instances while neglecting hard-to-classify instances.Some literature has revealed that hard examples are beneficial for modeling a discriminative boundary accurately.By applying such an idea at the instance level,we elaborate a novel MIL framework with masked hard instance mining (MHIM-MIL), which uses a Siamese structure (Teacher-Student) with a consistency constraint to explore the potential hard instances. With several instance masking strategies based on attention scores, MHIM-MIL employs a momentum teacher to implicitly mine hard instances for training the student model, which can be any attention-based MIL model.This counter-intuitive strategy essent
    
[^61]: 数据集中的信息提升子群发现

    Information Gained Subgroup Discovery in Datasets. (arXiv:2307.15089v1 [cs.LG])

    [http://arxiv.org/abs/2307.15089](http://arxiv.org/abs/2307.15089)

    该论文研究了在数据集中通过信息提升的方法进行子群发现。具体针对肺癌治疗，在保持或提高治疗效果的同时减少副作用对于改善患者的生活质量非常重要，临床指南虽然提供了治疗建议，但仍未将治疗结果纳入考量。

    

    肺癌是癌症死亡的主要原因。预计2023年将有超过238,340例新的肺癌患者，其中有超过127,070例死亡。选择正确的治疗方案是提高存活率和改善患者生活质量的重要因素。癌症治疗可能引发副作用，这些毒副反应会引起不同的健康问题，影响患者的生活质量。因此，在保持或提高治疗效果的同时减少治疗副作用是临床角度要追求的重要目标。另一方面，临床指南包括癌症治疗建议的一般知识，以协助临床医生。尽管他们根据癌症疾病方面和个体患者特征提供治疗建议，但并未提供基于治疗结果的统计分析。因此，需要对临床指南与治疗结果进行比较。

    Lung cancer is the leading cause of cancer death. More than 238,340 new cases of lung cancer patients are expected in 2023, with an estimation of more than 127,070 deaths. Choosing the correct treatment is an important element to enhance the probability of survival and to improve patient's quality of life. Cancer treatments might provoke secondary effects. These toxicities cause different health problems that impact the patient's quality of life. Hence, reducing treatments toxicities while maintaining or improving their effectivenes is an important goal that aims to be pursued from the clinical perspective. On the other hand, clinical guidelines include general knowledge about cancer treatment recommendations to assist clinicians. Although they provide treatment recommendations based on cancer disease aspects and individual patient features, a statistical analysis taking into account treatment outcomes is not provided here. Therefore, the comparison between clinical guidelines with tre
    
[^62]: 在定量双极论证框架中的论证归因解释

    Argument Attribution Explanations in Quantitative Bipolar Argumentation Frameworks. (arXiv:2307.13582v1 [cs.AI])

    [http://arxiv.org/abs/2307.13582](http://arxiv.org/abs/2307.13582)

    本文提出了一个新的“论证归因解释（AAEs）”理论，用于确定论证对“主题论证”产生的影响，在定量双极论证框架（QBAFs）中填补了解释定量推理结果的空白。

    

    近年来，有几个人提倡论证性可解释人工智能，越来越多的人对论证框架（AFs）的推理结果进行解释产生了兴趣。虽然关于用辩论/争论/对话的扩展语义精神定性地解释AFs的推理结果的研究成果很多，但是在渐进语义下解释AFs的定量推理结果却没有得到太多关注，尽管在应用中广泛使用。本文通过将机器学习中的特征归因精神引入定量双极论证框架（QBAFs）的背景中，提出了一个新的“论证归因解释（AAEs）”理论，用于确定论证对“主题论证”产生的影响，而特征归因则用于确定特征对机器学习模型输出的影响。

    Argumentative explainable AI has been advocated by several in recent years, with an increasing interest on explaining the reasoning outcomes of Argumentation Frameworks (AFs). While there is a considerable body of research on qualitatively explaining the reasoning outcomes of AFs with debates/disputes/dialogues in the spirit of \emph{extension-based semantics}, explaining the quantitative reasoning outcomes of AFs under \emph{gradual semantics} has not received much attention, despite widespread use in applications. In this paper, we contribute to filling this gap by proposing a novel theory of \emph{Argument Attribution Explanations (AAEs)} by incorporating the spirit of feature attribution from machine learning in the context of Quantitative Bipolar Argumentation Frameworks (QBAFs): whereas feature attribution is used to determine the influence of features towards outputs of machine learning models, AAEs are used to determine the influence of arguments towards \emph{topic argument}s 
    
[^63]: 用于程序之间变量映射的图神经网络——扩展版本

    Graph Neural Networks For Mapping Variables Between Programs -- Extended Version. (arXiv:2307.13014v1 [cs.SE])

    [http://arxiv.org/abs/2307.13014](http://arxiv.org/abs/2307.13014)

    本文提出了使用图神经网络(GNNs)基于程序的抽象语法树(ASTs)来映射变量集，以解决程序比较、分析、修复和克隆检测等任务。在初学者编程作业中进行的实验证明了变量映射的有效性。

    

    自动程序分析是计算机科学中许多领域的关键研究领域，特别是形式方法和人工智能。由于程序等价问题的不可判定性，比较两个程序非常具有挑战性。通常，为了比较两个程序，需要对两个程序的变量集之间建立关系。因此，在诸如程序等价性、程序分析、程序修复和克隆检测等任务上，映射两个程序之间的变量是非常有用的。在这项工作中，我们提出使用图神经网络(GNNs)基于两个程序的抽象语法树(ASTs)来映射变量集。为了展示变量映射的优势，我们在程序修复任务中提供了这些映射的三个用例，以修复初学者编程作业中常见的和经常发生的错误。实验结果基于一个包含4166对错误/修正程序的数据集。

    Automated program analysis is a pivotal research domain in many areas of Computer Science -- Formal Methods and Artificial Intelligence, in particular. Due to the undecidability of the problem of program equivalence, comparing two programs is highly challenging. Typically, in order to compare two programs, a relation between both programs' sets of variables is required. Thus, mapping variables between two programs is useful for a panoply of tasks such as program equivalence, program analysis, program repair, and clone detection. In this work, we propose using graph neural networks (GNNs) to map the set of variables between two programs based on both programs' abstract syntax trees (ASTs). To demonstrate the strength of variable mappings, we present three use-cases of these mappings on the task of program repair to fix well-studied and recurrent bugs among novice programmers in introductory programming assignments (IPAs). Experimental results on a dataset of 4166 pairs of incorrect/corr
    
[^64]: 在金融行业中应用量子自然语言处理(QNLP)进行情感分析

    Applying QNLP to sentiment analysis in finance. (arXiv:2307.11788v1 [cs.CL])

    [http://arxiv.org/abs/2307.11788](http://arxiv.org/abs/2307.11788)

    本论文研究了在金融行业中应用量子自然语言处理(QNLP)进行情感分析的实际适用性。利用一种新颖的数据生成方法，我们发现量子增强的长短期记忆(QLSTM)可以更快地训练，并且在软件实现方面接近古典结果。

    

    作为一个领域，即使是最微小的质量改进也能产生巨大价值的应用领域，金融是早期量子优势的有前途的候选者。在迅速发展的量子自然语言处理(QNLP)领域中，我们探索了DisCoCat和量子增强的长短期记忆(QNLP)这两种中心方法在金融情感分析问题中的实际适用性。利用一种新颖的基于ChatGPT的数据生成方法，我们进行了一个包含1000多个真实句子的案例研究，发现QLSTM的训练速度比DisCoCat快得多，并且在可用的软件实现中也接近古典结果。

    As an application domain where the slightest qualitative improvements can yield immense value, finance is a promising candidate for early quantum advantage. Focusing on the rapidly advancing field of Quantum Natural Language Processing (QNLP), we explore the practical applicability of the two central approaches DisCoCat and Quantum-Enhanced Long Short-Term Memory (QLSTM) to the problem of sentiment analysis in finance. Utilizing a novel ChatGPT-based data generation approach, we conduct a case study with more than 1000 realistic sentences and find that QLSTMs can be trained substantially faster than DisCoCat while also achieving close to classical results for their available software implementations.
    
[^65]: ESMC:整个空间多任务模型通过参数约束用于点击后转化率

    ESMC: Entire Space Multi-Task Model for Post-Click Conversion Rate via Parameter Constraint. (arXiv:2307.09193v1 [cs.AI])

    [http://arxiv.org/abs/2307.09193](http://arxiv.org/abs/2307.09193)

    该论文提出了ESMC模型，通过参数约束来解决大规模在线推荐系统中点击后转化率估计中的样本选择偏差和数据稀疏性问题。此外，通过扩展决策路径，该模型可以更好地捕捉用户的决策意图，并提高推荐性能。

    

    大规模在线推荐系统在互联网上广泛使用，负责点击率（CTR）和点击后转化率（CVR）的估计。然而，传统的CVR估计器存在着样本选择偏差和数据稀疏性问题。通过追踪“曝光_点击_购买”这个决策路径，提出了整个空间模型来解决这两个问题。此外，一些研究者观察到在点击和购买之间存在购买相关行为，可以更好地了解用户的决策意图并提高推荐性能。因此，决策路径已扩展为“曝光_点击_店内动作_购买”，并且可以通过条件概率方法建模。然而，我们观察到条件概率的链式法则并不总是成立。我们报告了概率空间混淆（PSC）问题，并推导了地面实况与估计数学间的差异。

    Large-scale online recommender system spreads all over the Internet being in charge of two basic tasks: Click-Through Rate (CTR) and Post-Click Conversion Rate (CVR) estimations. However, traditional CVR estimators suffer from well-known Sample Selection Bias and Data Sparsity issues. Entire space models were proposed to address the two issues via tracing the decision-making path of "exposure_click_purchase". Further, some researchers observed that there are purchase-related behaviors between click and purchase, which can better draw the user's decision-making intention and improve the recommendation performance. Thus, the decision-making path has been extended to "exposure_click_in-shop action_purchase" and can be modeled with conditional probability approach. Nevertheless, we observe that the chain rule of conditional probability does not always hold. We report Probability Space Confusion (PSC) issue and give a derivation of difference between ground-truth and estimation mathematical
    
[^66]: 多阶段电缆布线的层次化模仿学习

    Multi-Stage Cable Routing through Hierarchical Imitation Learning. (arXiv:2307.08927v3 [cs.RO] CROSS LISTED)

    [http://arxiv.org/abs/2307.08927](http://arxiv.org/abs/2307.08927)

    本研究探讨了多阶段电缆布线任务中的层次化模仿学习方法，解决了处理可变形物体、视觉感知闭环和扩展行为的挑战。成功控制器需要能够从失败中恢复，并通过选择纠正低级控制器的缺陷。

    

    我们研究了学习如何执行多阶段机器人操作任务的问题，应用于电缆布线，其中机器人必须通过一系列夹子来布线。这个设置代表了复杂多阶段机器人操作场景的挑战：处理可变形物体，对视觉感知闭环，处理由多个步骤组成的扩展行为，必须成功执行才能完成整个任务。在这种设置中，为每个阶段学习成功率足够高的单个基元是不切实际的：如果每个阶段必须成功完成并且有较大的失败概率，整个任务成功完成的概率变得微不足道。因此，这样的多阶段任务的成功控制器必须能够从失败中恢复，并通过聪明地选择从而纠正低级控制器的缺陷。

    We study the problem of learning to perform multi-stage robotic manipulation tasks, with applications to cable routing, where the robot must route a cable through a series of clips. This setting presents challenges representative of complex multi-stage robotic manipulation scenarios: handling deformable objects, closing the loop on visual perception, and handling extended behaviors consisting of multiple steps that must be executed successfully to complete the entire task. In such settings, learning individual primitives for each stage that succeed with a high enough rate to perform a complete temporally extended task is impractical: if each stage must be completed successfully and has a non-negligible probability of failure, the likelihood of successful completion of the entire task becomes negligible. Therefore, successful controllers for such multi-stage tasks must be able to recover from failure and compensate for imperfections in low-level controllers by smartly choosing which con
    
[^67]: DeepIPCv2：利用LiDAR强化自动驾驶环境感知与导航控制

    DeepIPCv2: LiDAR-powered Robust Environmental Perception and Navigational Control for Autonomous Vehicle. (arXiv:2307.06647v1 [cs.RO])

    [http://arxiv.org/abs/2307.06647](http://arxiv.org/abs/2307.06647)

    DeepIPCv2是一种利用LiDAR传感器感知环境的自动驾驶模型，通过使用点云作为感知输入，在各种条件下实现了更强大的驾驶性能。

    

    我们提出了DeepIPCv2，一种利用LiDAR传感器感知环境的自动驾驶模型，以实现更强大的驾驶性能，特别是在光照条件较差的情况下。DeepIPCv2使用一组LiDAR点云作为其主要感知输入。由于点云不受光照变化的影响，它们可以提供清晰的环境观察，无论条件如何。这使得感知模块能够提供更好的场景理解和稳定的特征，从而支持控制模块准确估计导航控制。为了评估其性能，我们通过部署该模型来预测一组驾驶记录并在三种不同条件下进行真实自动驾驶的测试。我们还进行了消融和比较研究，以证明其性能。基于实验结果，DeepIPCv2在所有条件下均显示出强大的驾驶性能。

    We present DeepIPCv2, an autonomous driving model that perceives the environment using a LiDAR sensor for more robust drivability, especially when driving under poor illumination conditions. DeepIPCv2 takes a set of LiDAR point clouds for its main perception input. As point clouds are not affected by illumination changes, they can provide a clear observation of the surroundings no matter what the condition is. This results in a better scene understanding and stable features provided by the perception module to support the controller module in estimating navigational control properly. To evaluate its performance, we conduct several tests by deploying the model to predict a set of driving records and perform real automated driving under three different conditions. We also conduct ablation and comparative studies with some recent models to justify its performance. Based on the experimental results, DeepIPCv2 shows a robust performance by achieving the best drivability in all conditions. C
    
[^68]: GP引导的MPPI在复杂未知杂乱环境中的高效导航

    GP-guided MPPI for Efficient Navigation in Complex Unknown Cluttered Environments. (arXiv:2307.04019v1 [cs.RO])

    [http://arxiv.org/abs/2307.04019](http://arxiv.org/abs/2307.04019)

    本研究提出了一种GP引导的MPPI方法用于在复杂未知杂乱环境中进行高效导航。该方法利用局部感知模型和在线学习技术，通过构建不确定性表面，识别并推荐最优子目标给局部的MPPI规划器。最终实现了满足要求的最优控制序列。

    

    在具有有限感知能力的未知杂乱环境中进行机器人导航对机器人学来说是一个重大挑战。局部轨迹优化方法，如模型预测路径积分（MPPI），是解决这一挑战的一种有希望的方法。然而，在遇到具有挑战性的环境条件或在计划范围之外导航时，需要全局引导来确保有效的导航。本研究提出了GP-MPPI，一种基于在线学习的控制策略，它将MPPI与基于稀疏高斯过程（SGP）的局部感知模型相结合。关键思想是利用SGP的学习能力构建一个方差（不确定性）表面，使机器人能够了解周围的可导航空间，识别一组建议的子目标，并最终推荐最小化预定义成本函数的最优子目标给局部的MPPI规划器。之后，MPPI计算出满足要求的最优控制序列。

    Robotic navigation in unknown, cluttered environments with limited sensing capabilities poses significant challenges in robotics. Local trajectory optimization methods, such as Model Predictive Path Intergal (MPPI), are a promising solution to this challenge. However, global guidance is required to ensure effective navigation, especially when encountering challenging environmental conditions or navigating beyond the planning horizon. This study presents the GP-MPPI, an online learning-based control strategy that integrates MPPI with a local perception model based on Sparse Gaussian Process (SGP). The key idea is to leverage the learning capability of SGP to construct a variance (uncertainty) surface, which enables the robot to learn about the navigable space surrounding it, identify a set of suggested subgoals, and ultimately recommend the optimal subgoal that minimizes a predefined cost function to the local MPPI planner. Afterward, MPPI computes the optimal control sequence that sati
    
[^69]: 在不平衡数据集中的离线强化学习

    Offline Reinforcement Learning with Imbalanced Datasets. (arXiv:2307.02752v1 [cs.LG])

    [http://arxiv.org/abs/2307.02752](http://arxiv.org/abs/2307.02752)

    本文提出了一种在不平衡数据集中的新型离线强化学习方法，通过将CQL与回溯过程相结合来提取策略，从而有效地解决了不平衡数据集带来的挑战。

    

    当前离线强化学习（RL）研究中对基准的普遍使用导致了对实际数据集分布不平衡的忽视。由于探索或安全考虑的挑战，实际离线RL数据集在状态空间上通常是不平衡的。我们在本文中具体说明了离线RL中不平衡数据集的特性，其中状态覆盖率遵循一个由偏态策略所特征化的幂律分布。理论上和实证上，我们证明了基于分布约束的典型离线RL方法，如保守Q学习（CQL），在不平衡数据集下提取策略是无效的。受自然智能的启发，我们提出了一种新的离线RL方法，该方法利用CQL的增强与回溯过程相结合，以回忆以往相关经验，有效地缓解不平衡数据集带来的挑战。我们在多个任务上评估了我们的方法。

    The prevalent use of benchmarks in current offline reinforcement learning (RL) research has led to a neglect of the imbalance of real-world dataset distributions in the development of models. The real-world offline RL dataset is often imbalanced over the state space due to the challenge of exploration or safety considerations. In this paper, we specify properties of imbalanced datasets in offline RL, where the state coverage follows a power law distribution characterized by skewed policies. Theoretically and empirically, we show that typically offline RL methods based on distributional constraints, such as conservative Q-learning (CQL), are ineffective in extracting policies under the imbalanced dataset. Inspired by natural intelligence, we propose a novel offline RL method that utilizes the augmentation of CQL with a retrieval process to recall past related experiences, effectively alleviating the challenges posed by imbalanced datasets. We evaluate our method on several tasks in the 
    
[^70]: 可扩展的神经上下文推荐系统中的Bandit算法

    Scalable Neural Contextual Bandit for Recommender Systems. (arXiv:2306.14834v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2306.14834](http://arxiv.org/abs/2306.14834)

    本研究提出了一种可扩展的神经上下文Bandit算法，通过设计Epistemic Neural Recommendation (ENR)网络结构，实现了大规模的Thompson抽样，显著提高了推荐系统的点击率和用户评分。

    

    高质量的推荐系统应通过与用户的有效和探索性互动提供创新和相关内容。然而，许多现有推荐系统中基于监督学习的神经网络仅利用已识别的用户兴趣，对于有效发现未知用户偏好存在不足。尽管神经上下文Bandit算法在通过神经网络实现在线探索方面取得了一些进展，但他们对计算的要求较高，限制了它在实际推荐系统中的广泛应用。在本研究中，我们提出了一种可扩展的样本效率高的神经上下文Bandit算法用于推荐系统。为此，我们设计了一种认知神经网络架构，Epistemic Neural Recommendation (ENR)，它能够在大规模上实现Thompson抽样。通过两个不同的真实任务的大规模实验，ENR显著提高了点击率和用户评分。

    High-quality recommender systems ought to deliver both innovative and relevant content through effective and exploratory interactions with users. Yet, supervised learning-based neural networks, which form the backbone of many existing recommender systems, only leverage recognized user interests, falling short when it comes to efficiently uncovering unknown user preferences. While there has been some progress with neural contextual bandit algorithms towards enabling online exploration through neural networks, their onerous computational demands hinder widespread adoption in real-world recommender systems. In this work, we propose a scalable sample-efficient neural contextual bandit algorithm for recommender systems. To do this, we design an epistemic neural network architecture, Epistemic Neural Recommendation (ENR), that enables Thompson sampling at a large scale. In two distinct large-scale experiments with real-world tasks, ENR significantly boosts click-through rates and user rating
    
[^71]: G-NM：一组数字时间序列预测模型

    G-NM: A Group of Numerical Time Series Prediction Models. (arXiv:2306.11667v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.11667](http://arxiv.org/abs/2306.11667)

    G-NM是一组集合了传统和现代模型的数字时间序列预测模型，旨在提高对复杂自然现象中的模式和趋势的预测能力。

    

    本研究聚焦于开发和实施一个综合的数字时间序列预测模型集合，统称为数字时间序列预测模型组（G-NM）。该集合包括传统模型如自回归综合移动平均（ARIMA）、Holt-Winters方法和支持向量回归（SVR），以及现代神经网络模型，如循环神经网络（RNN）和长短期记忆（LSTM）。G-NM明确构建以增强我们对复杂自然现象中固有模式和趋势的预测能力。通过利用与这些事件相关的时间序列数据，G-NM便于对此类现象在延长时间段内进行预测。本研究的主要目标是推进我们对此类事件的理解，并大幅提高预测准确性。G-NM包括线性和非线性依赖关系，以及季节性趋势。

    In this study, we focus on the development and implementation of a comprehensive ensemble of numerical time series forecasting models, collectively referred to as the Group of Numerical Time Series Prediction Model (G-NM). This inclusive set comprises traditional models such as Autoregressive Integrated Moving Average (ARIMA), Holt-Winters' method, and Support Vector Regression (SVR), in addition to modern neural network models including Recurrent Neural Network (RNN) and Long Short-Term Memory (LSTM). G-NM is explicitly constructed to augment our predictive capabilities related to patterns and trends inherent in complex natural phenomena. By utilizing time series data relevant to these events, G-NM facilitates the prediction of such phenomena over extended periods. The primary objective of this research is to both advance our understanding of such occurrences and to significantly enhance the accuracy of our forecasts. G-NM encapsulates both linear and non-linear dependencies, seasonal
    
[^72]: Enlighten-anything: 当分段模型遇见低光图像增强

    Enlighten-anything:When Segment Anything Model Meets Low-light Image Enhancement. (arXiv:2306.10286v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2306.10286](http://arxiv.org/abs/2306.10286)

    本文提出了Enlighten-anything，在低光图像增强中将分段模型与SAM融合，实现了良好视觉感知的融合图像。

    

    图像恢复是一项低级别视觉任务，大多数CNN方法都是作为黑盒子设计的，缺乏透明度和固有美学。许多无监督方法忽略了低光场景中可见信息的退化，这会严重影响补充信息的聚合，并使融合算法无法在极端情况下产生令人满意的融合结果。本文提出了Enlighten-anything，能够将SAM分段的语义意图与低光图像增强相结合，获得具有良好视觉感知的融合图像。无监督学习的泛化能力得到了极大提高，对LOL数据集的实验表明，我们的方法在PSNR上比基线提高了3dB，在SSIM上提高了8。 SAM的零样本学习为无监督低光增强提供了有力的帮助。Enlighten-anything的源代码可以从 https://github.com/zhangbaijin/enlighten-any 获得。

    Image restoration is a low-level visual task, and most CNN methods are designed as black boxes, lacking transparency and intrinsic aesthetics. Many unsupervised approaches ignore the degradation of visible information in low-light scenes, which will seriously affect the aggregation of complementary information and also make the fusion algorithm unable to produce satisfactory fusion results under extreme conditions. In this paper, we propose Enlighten-anything, which is able to enhance and fuse the semantic intent of SAM segmentation with low-light images to obtain fused images with good visual perception. The generalization ability of unsupervised learning is greatly improved, and experiments on LOL dataset are conducted to show that our method improves 3db in PSNR over baseline and 8 in SSIM. zero-shot learning of SAM introduces a powerful aid for unsupervised low-light enhancement. The source code of Enlighten-anything can be obtained from https://github.com/zhangbaijin/enlighten-any
    
[^73]: 六边形标注：将投影依存句法分析作为标注

    Hexatagging: Projective Dependency Parsing as Tagging. (arXiv:2306.05477v1 [cs.CL])

    [http://arxiv.org/abs/2306.05477](http://arxiv.org/abs/2306.05477)

    六边形标注器是一种新颖的依存分析器，可以在训练时实现完全并行化，具有线性时间复杂度和空间复杂度。使用预训练语言模型的特征进行预测。在 Penn Treebank 测试集上取得了最先进的性能。

    

    我们介绍了一种新颖的依存分析器——六边形标注器，它通过将句子中的单词标记为来自可能标记有限集合中的元素来构建依存树。与许多处理依存性分析的方法不同，我们的方法在训练时是完全可并行化的，即用于构建依存分析所需的结构构建操作可以相互并行预测。此外，确切解码的时间和空间复杂度都是线性的。此外，我们导出了一种概率依存分析器，它使用预训练语言模型的特征来预测六边标记，而不需要专为此任务明确设计的定制体系结构。尽管我们的方法具有通用性和简单性，但在 Penn Treebank 测试集上，我们实现了 96.4 LAS 和 97.4 UAS 的最先进性能。此外，我们的分析器的线性时间复杂度和并行性显著提高了计算效率，速度提高了大约十倍。

    We introduce a novel dependency parser, the hexatagger, that constructs dependency trees by tagging the words in a sentence with elements from a finite set of possible tags. In contrast to many approaches to dependency parsing, our approach is fully parallelizable at training time, i.e., the structure-building actions needed to build a dependency parse can be predicted in parallel to each other. Additionally, exact decoding is linear in time and space complexity. Furthermore, we derive a probabilistic dependency parser that predicts hexatags using no more than a linear model with features from a pretrained language model, i.e., we forsake a bespoke architecture explicitly designed for the task. Despite the generality and simplicity of our approach, we achieve state-of-the-art performance of 96.4 LAS and 97.4 UAS on the Penn Treebank test set. Additionally, our parser's linear time complexity and parallelism significantly improve computational efficiency, with a roughly 10-times speed-u
    
[^74]: 利用部分标注的文本提升阿拉伯语音标注的准确性

    Take the Hint: Improving Arabic Diacritization with Partially-Diacritized Text. (arXiv:2306.03557v1 [cs.CL])

    [http://arxiv.org/abs/2306.03557](http://arxiv.org/abs/2306.03557)

    本文提出了一个名为2SDiac的多源模型，可以在输入中使用可选音标来确定所有预测的输出，然后通过引入Guided Learning的训练策略，利用随机掩蔽和给定的输入音标提升标记的正确性。实验表明，该方法在非标记文本上表现良好，并实现了最先进的结果。

    

    自动化的阿拉伯语音标注在很多应用场景中都非常有用，比如对于语言学习者来说，标注可以提供阅读支持，而对于语音合成这样的下游任务，标注准确性对于发音预测也非常重要。之前的研究大多数专注于处理没有音标的原始文本的模型，但是通过给人类提供选定的或部分标注的敏感词汇，可以使得生产系统的准确性更高。本文提出了一个名为2SDiac的多源模型，可以有效地支持输入中的可选音标以确定所有预测的输出。此外，本文还引入了一种称为Guided Learning的训练策略，可以利用给定的输入音标和不同等级的随机掩蔽来提升标注的正确性。我们展示了测试期间提供的标注能够影响更多的输出位置，实验结果还表明，我们的方法可以在非标记文本上表现出优异的效果，并且可以在减少60%的参数数目的情况下实现最先进的结果。

    Automatic Arabic diacritization is useful in many applications, ranging from reading support for language learners to accurate pronunciation predictor for downstream tasks like speech synthesis. While most of the previous works focused on models that operate on raw non-diacritized text, production systems can gain accuracy by first letting humans partly annotate ambiguous words. In this paper, we propose 2SDiac, a multi-source model that can effectively support optional diacritics in input to inform all predictions. We also introduce Guided Learning, a training scheme to leverage given diacritics in input with different levels of random masking. We show that the provided hints during test affect more output positions than those annotated. Moreover, experiments on two common benchmarks show that our approach i) greatly outperforms the baseline also when evaluated on non-diacritized text; and ii) achieves state-of-the-art results while reducing the parameter count by over 60%.
    
[^75]: 从鲁棒性到可解释性再到鲁棒性。(arXiv:2306.03048v2 [cs.AI] 已更新)

    From Robustness to Explainability and Back Again. (arXiv:2306.03048v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2306.03048](http://arxiv.org/abs/2306.03048)

    本文介绍了一种解决形式解释可扩展性限制的新算法，通过回答鲁棒性查询来计算解释，并建立了形式解释复杂性和鲁棒性复杂性之间的直接关系。

    

    与可解释的人工智能（XAI）的临时方法相比，形式解释提供了严密性的重要保证。然而，形式解释在某些分类器家族中的可扩展性差，其中最重要的是神经网络。因此，人们担心形式解释是否可以作为其他方法的补充，以提供可信赖的人工智能。本文解决了形式解释可扩展性的限制，并提出了用于计算形式解释的新算法。这种新算法通过回答一系列鲁棒性查询来计算解释，并且这些查询的数量最多与特征数量成线性关系。因此，所提出的算法在实际复杂性和鲁棒性的复杂性之间建立了直接关系。更重要的是，本文推广了形式解释的定义，从而允许使用其他方法来改进解释的可扩展性。

    In contrast with ad-hoc methods for eXplainable Artificial Intelligence (XAI), formal explainability offers important guarantees of rigor. However, formal explainability is hindered by poor scalability for some families of classifiers, the most significant being neural networks. As a result, there are concerns as to whether formal explainability might serve to complement other approaches in delivering trustworthy AI. This paper addresses the limitation of scalability of formal explainability, and proposes novel algorithms for computing formal explanations. The novel algorithm computes explanations by answering instead a number of robustness queries, and such that the number of such queries is at most linear on the number of features. Consequently, the proposed algorithm establishes a direct relationship between the practical complexity of formal explainability and that of robustness. More importantly, the paper generalizes the definition of formal explanation, thereby allowing the use 
    
[^76]: ChatGPT：AI生成内容的挑战与解决方案综述

    A Survey on ChatGPT: AI-Generated Contents, Challenges, and Solutions. (arXiv:2305.18339v1 [cs.CY])

    [http://arxiv.org/abs/2305.18339](http://arxiv.org/abs/2305.18339)

    本论文探讨了AI生成内容的工作原理、安全与隐私威胁、现状和未来挑战，并提供了针对这些问题的最新解决方案。

    

    随着大型人工智能模型比如ChatGPT的普及使用，AI生成内容（AIGC）日益受到关注，正在引领内容创作和知识表示方式实现范式转变。AIGC利用生成式大型AI算法来辅助或替代人类，根据用户提供的提示以更快的速度和更低的成本创建大规模、高质量和类人的内容。尽管在AIGC方面取得了显著进展，但安全、隐私、伦理和法律挑战仍需解决。本文深入调查了AIGC范式的工作原理、安全和隐私威胁、最新解决方案和未来挑战。具体而言，我们首先探讨了AIGC的技术实现、总体架构，并讨论了其工作模式和关键特征。然后，我们调查了针对AIGC的安全和隐私威胁分类法，并强调了GPT和AIGC技术的伦理和社会影响。接下来，我们全面回顾了现有的解决方案，以解决已确定的挑战，并讨论了AIGC领域未来的研究方向。最后，我们总结了我们的发现，并提出了一些未来发展AIGC的潜在研究方向。

    With the widespread use of large artificial intelligence (AI) models such as ChatGPT, AI-generated content (AIGC) has garnered increasing attention and is leading a paradigm shift in content creation and knowledge representation. AIGC uses generative large AI algorithms to assist or replace humans in creating massive, high-quality, and human-like content at a faster pace and lower cost, based on user-provided prompts. Despite the recent significant progress in AIGC, security, privacy, ethical, and legal challenges still need to be addressed. This paper presents an in-depth survey of working principles, security and privacy threats, state-of-the-art solutions, and future challenges of the AIGC paradigm. Specifically, we first explore the enabling technologies, general architecture of AIGC, and discuss its working modes and key characteristics. Then, we investigate the taxonomy of security and privacy threats to AIGC and highlight the ethical and societal implications of GPT and AIGC tec
    
[^77]: 优化的忽视规范承诺

    Optimization's Neglected Normative Commitments. (arXiv:2305.17465v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2305.17465](http://arxiv.org/abs/2305.17465)

    本文描述了使用优化的规范选择和假设，并指出了可能被忽视的包括任务遗漏、决策边界问题以及多个代理的目标冲突在内的六个问题。

    

    优化被提供作为解决涉及不确定性和利益冲突的复杂实际决策的客观方法。它驱动着商业策略和公共政策，并且越来越多地成为复杂机器学习系统的核心。优化依赖于将现实世界抽象为一系列决策、目标和约束来处理可能涉及高风险的决策。本文从建模过程和一系列实际案例中提取，描述了使用优化时必然涉及的规范选择和假设。然后，它识别出可能被忽视的六个新问题：1）给定的值设置错误可能导致优化忽略某些任务，或者错误将其纳入约束或目标的一部分；2）问题的决策边界错误可能导致错误的模块化假设和反馈循环；3）未能考虑到多个代理的分歧目标可能导致冲突的结果。

    Optimization is offered as an objective approach to resolving complex, real-world decisions involving uncertainty and conflicting interests. It drives business strategies as well as public policies and, increasingly, lies at the heart of sophisticated machine learning systems. A paradigm used to approach potentially high-stakes decisions, optimization relies on abstracting the real world to a set of decision(s), objective(s) and constraint(s). Drawing from the modeling process and a range of actual cases, this paper describes the normative choices and assumptions that are necessarily part of using optimization. It then identifies six emergent problems that may be neglected: 1) Misspecified values can yield optimizations that omit certain imperatives altogether or incorporate them incorrectly as a constraint or as part of the objective, 2) Problematic decision boundaries can lead to faulty modularity assumptions and feedback loops, 3) Failing to account for multiple agents' divergent go
    
[^78]: 在ChatGPT、大型语言模型和生成AI时代的科学：研究伦理的挑战及应对方法

    Science in the Era of ChatGPT, Large Language Models and Generative AI: Challenges for Research Ethics and How to Respond. (arXiv:2305.15299v2 [cs.CY] UPDATED)

    [http://arxiv.org/abs/2305.15299](http://arxiv.org/abs/2305.15299)

    这篇论文回顾了生成AI对科学研究所带来的认识论挑战、伦理和诚信风险，并提出了十项建议，以在AI时代促进更负责任的研究进行。

    

    人工智能的大型语言模型（如ChatGPT）在科学研究中具有显著但有争议的应用。本文回顾了生成AI时代科学研究的认识论挑战、伦理和诚信风险，并旨在为高质量的研究伦理审查奠定新的及时基础。对AI语言模型作为研究工具和研究对象的角色进行了详细审查，并讨论了对科学家、参与者和评审人员的伦理影响。讨论了研究伦理审查的新兴实践，并给出了十项建议，为在AI时代更负责任的研究进行回应。

    Large language models of artificial intelligence (AI), such as ChatGPT, find remarkable but controversial applicability in science and research. This paper reviews epistemological challenges, ethical and integrity risks in science conduct in the advent of generative AI. This is with the aim to lay new timely foundations for a high-quality research ethics review. The role of AI language models as a research instrument and subject is scrutinized along with ethical implications for scientists, participants and reviewers. New emerging practices for research ethics review are discussed, concluding with ten recommendations that shape a response for a more responsible research conduct in the era of AI.
    
[^79]: 飞行对抗贴片：操纵基于深度学习的自主多旋翼行为

    Flying Adversarial Patches: Manipulating the Behavior of Deep Learning-based Autonomous Multirotors. (arXiv:2305.12859v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2305.12859](http://arxiv.org/abs/2305.12859)

    该论文介绍了一种称为飞行对抗贴片的方法，利用神经网络的弱点，通过在飞行中携带的图像来操纵自主多旋翼的行为，实现对受害多旋翼的完全控制。

    

    自主飞行机器人，如多旋翼，通常依靠神经网络根据摄像头图像进行预测。如果将这些深度学习（DL）模型应用于训练领域之外的输入图像，可能会得到出人意料的结果。对抗攻击利用了这个缺陷，例如通过计算小图像，即所谓的对抗贴片，将其放置在环境中，以操纵神经网络的预测。我们引入了飞行对抗贴片，其中一个图像被安装在另一个飞行机器人上，因此可以放置在受害多旋翼的任何视野中。为了有效攻击，我们比较了同时优化对抗贴片及其在输入图像中的位置的三种方法。我们对公开可用的用于自主多旋翼的DL模型和数据集进行了实证验证。最终，我们的攻击多旋翼能够完全控制受害多旋翼的运动。

    Autonomous flying robots, e.g. multirotors, often rely on a neural network that makes predictions based on a camera image. These deep learning (DL) models can compute surprising results if applied to input images outside the training domain. Adversarial attacks exploit this fault, for example, by computing small images, so-called adversarial patches, that can be placed in the environment to manipulate the neural network's prediction. We introduce flying adversarial patches, where an image is mounted on another flying robot and therefore can be placed anywhere in the field of view of a victim multirotor. For an effective attack, we compare three methods that simultaneously optimize the adversarial patch and its position in the input image. We perform an empirical validation on a publicly available DL model and dataset for autonomous multirotors. Ultimately, our attacking multirotor would be able to gain full control over the motions of the victim multirotor.
    
[^80]: 自动自我生成的零样本编码从语义级别到代码级别的 SelfzCoT，更好地利用LLMs

    SelfzCoT: a Self-Prompt Zero-shot CoT from Semantic-level to Code-level for a Better Utilization of LLMs. (arXiv:2305.11461v1 [cs.AI])

    [http://arxiv.org/abs/2305.11461](http://arxiv.org/abs/2305.11461)

    本文提出了 SelfzCoT 自动自我生成的零样本编码，通过使用LLMs和代码级别的自我提示，在六个零样本算术推理任务中实现了巨大的准确度提升。同时，修改的零样本编码 MzCoT 在推理任务中也取得了显著的表现。

    

    本文通过 SelfzCoT 自动自我生成的零样本编码，研究了如何更好地利用LLMs。具体地，我们将 SelfzCoT 应用于零样本算术推理任务，其准确性从GSM8K的40.50%提高至82.34%，MultiArith从79.3%提高至94.7%，ADDSUB从74.70%提高至94.10%，SingleEq从78.70%提高至91.30%，AQUA从31.90%提高至82.33%，SVAMP从63.70%提高至79.70%。总的来说，使用前两个持久路径激活到LLM，特别是代码级别的自我提示，使 SelfzCoT 在所有六个零样本算术推理任务上实现了巨大的改进。此外，我们修改的零样本编码 MzCoT 在推理任务中也取得了显著的表现。在GSM8K中，MzCoT的准确性从40.50%提高至76.32%，MultiArith从79.3%提高至96.97%，ADDSUB从74.70%提高至92.39%，SingleEq从78.70%提高至94.60%，AQUA从31.90%提高至79.90%，SVAMP从63.70%提高至81.50%。

    This paper show a work on better use of LLMs with SelfzCoT a self-prompt zero-shot CoT. Specifically, on the zero-shot arithmetic reasoning tasks, the accuracy of the proposed SelfzCoT is improved with GSM8K from 40.50% to 82.34%, with MultiArith from 79.3% to 94.7%, with ADDSUB from 74.70% to 94.10%, with SingleEq from 78.70% to 91.30%, with AQUA from 31.90% to 82.33%, and with SVAMP from 63.70% to 79.70%. Totally, using the first two lasting path activations to LLM and particularly, the code-level self-prompt, the SelfzCoT has a huge improvement on all six zero-shot arithmetic reasoning tasks. Additionally, our modified zero-shot CoT (MzCoT) also achieves remarkable performance in the reasoning tasks. The accuracy of the proposed MzCoT is enhanced with GSM8K from 40.50% to 76.32%, with MultiArith from 79.3% to 96.97%, with ADDSUB from 74.70% to 92.39%, with SingleEq from 78.70% to 94.60%, with AQUA from 31.90% to 79.90%, and with SVAMP from 63.70% to 81.50%. Notably, SelfzCoT has the
    
[^81]: 关于有限轨迹上综合策略的策略研究

    On Strategies in Synthesis Over Finite Traces. (arXiv:2305.08319v2 [cs.FL] UPDATED)

    [http://arxiv.org/abs/2305.08319](http://arxiv.org/abs/2305.08319)

    本研究显示，相较于终止自动机，在LTLf模型检查中使用非终止自动机会更加困难。

    

    该论文研究了LTLf（线性时序逻辑中的有限轨迹）的综合方法运用于验证策略的正确性的有效性。然而LTLf模型检查并不简单，由LTLf综合生成的策略可以用到有限但无界长度或无限长度的终止和非终止自动机中。本研究阐述了非终止自动机与终止自动机在模型检查中的区别，论文主要贡献是显示出LTLf模型检查中使用非终止自动机比终止自动机指数级更难。

    The innovations in reactive synthesis from {\em Linear Temporal Logics over finite traces} (LTLf) will be amplified by the ability to verify the correctness of the strategies generated by LTLf synthesis tools. This motivates our work on {\em LTLf model checking}. LTLf model checking, however, is not straightforward. The strategies generated by LTLf synthesis may be represented using {\em terminating} transducers or {\em non-terminating} transducers where executions are of finite-but-unbounded length or infinite length, respectively. For synthesis, there is no evidence that one type of transducer is better than the other since they both demonstrate the same complexity and similar algorithms.  In this work, we show that for model checking, the two types of transducers are fundamentally different. Our central result is that LTLf model checking of non-terminating transducers is \emph{exponentially harder} than that of terminating transducers. We show that the problems are EXPSPACE-complete
    
[^82]: 大型语言模型在医疗保健领域中准备就绪了吗？临床语言理解的比较研究。

    Are Large Language Models Ready for Healthcare? A Comparative Study on Clinical Language Understanding. (arXiv:2304.05368v1 [cs.CL])

    [http://arxiv.org/abs/2304.05368](http://arxiv.org/abs/2304.05368)

    本研究全面评估了大型语言模型在临床语言理解任务上的表现，并引入自问自答提示策略来提高LLMs在医疗保健相关任务中的效果。

    

    大型语言模型（LLMs）在各个领域取得了显著的进展，包括医疗保健领域。然而，临床语言理解任务的专业性质带来了独特的挑战和限制，需要进一步研究。在本研究中，我们对最先进的LLMs——GPT-3.5、GPT-4和Bard进行了全面评估，该评估范围涵盖了各种任务，包括命名实体识别、关系提取、自然语言推理、语义文本相似性、文档分类和问答。我们还引入了一种新的提示策略——自问自答提示（SQP），旨在通过引发与相关临床场景相关的信息性问题和答案，定制化提高LLMs的性能。我们的评估强调了任务特定的学习策略和提示技术对于提高LLMs在医疗保健相关任务中的有效性的重要性。

    Large language models (LLMs) have made significant progress in various domains, including healthcare. However, the specialized nature of clinical language understanding tasks presents unique challenges and limitations that warrant further investigation. In this study, we conduct a comprehensive evaluation of state-of-the-art LLMs, namely GPT-3.5, GPT-4, and Bard, within the realm of clinical language understanding tasks. These tasks span a diverse range, including named entity recognition, relation extraction, natural language inference, semantic textual similarity, document classification, and question-answering. We also introduce a novel prompting strategy, self-questioning prompting (SQP), tailored to enhance LLMs' performance by eliciting informative questions and answers pertinent to the clinical scenarios at hand. Our evaluation underscores the significance of task-specific learning strategies and prompting techniques for improving LLMs' effectiveness in healthcare-related tasks.
    
[^83]: ChatGPT塑造牙科未来：多模态大语言模型的潜力

    ChatGPT for Shaping the Future of Dentistry: The Potential of Multi-Modal Large Language Model. (arXiv:2304.03086v1 [cs.CL])

    [http://arxiv.org/abs/2304.03086](http://arxiv.org/abs/2304.03086)

    本文讨论了利用LLMs在牙科临床领域实现自动化和跨模态诊断的可能性，介绍了利用跨模态编码器进行高级自然语言推理的多模态LLM AI系统，展示了其在牙科临床中的巨大潜力。

    

    ChatGPT是OpenAI开发的Generative Pretrained Transformer 4（GPT-4）的精简和对话变体，具有数十亿个参数的里程碑式大语言模型之一。事实上，LLMs在自然语言处理任务中展现出的印象深刻能力引起了研究人员和实践者的极大兴趣，对各个领域产生了深远的影响。本文主要讨论LLMs在牙科领域的未来应用。我们介绍了两种主要的LLM部署方法，包括自动牙科诊断和跨模态牙科诊断，并探讨了它们的潜在应用。特别地，配备跨模态编码器，单个LLM可以管理多源数据并进行高级自然语言推理，以执行复杂的临床操作。通过一个案例来展示针对牙科临床应用的完全自动化的多模态LLM AI系统的潜力。虽然LLMs在提供巨大的潜力方面取得了显著的进展，

    The ChatGPT, as a lite and conversational variant of Generative Pretrained Transformer 4 (GPT-4) developed by OpenAI, is one of the milestone Large Language Models (LLMs) with billions of parameters. LLMs, in fact, have stirred up a lot of interest among researchers and practitioners by their impressive skills in natural language processing tasks, which have a profound impact on a wide range of fields. This paper mainly discusses the future applications of LLMs in dentistry. We introduce two primary LLM deployment methods in dentistry, including automated dental diagnosis and cross-modal dental diagnosis, and examine their potential applications. Especially, equipped with a cross-modal encoder, a single LLM can manage multi-source data and conduct advanced natural language reasoning to perform complex clinical operations. A use case is presented to demonstrate the potential of a fully automatic Multi-Modal LLM AI system for dentistry clinical application. While LLMs offer significant p
    
[^84]: 基于分层模仿学习的城市自动驾驶可解释式运动规划器

    Interpretable Motion Planner for Urban Driving via Hierarchical Imitation Learning. (arXiv:2303.13986v1 [cs.RO])

    [http://arxiv.org/abs/2303.13986](http://arxiv.org/abs/2303.13986)

    本文提出一种基于分层模仿学习的运动规划方法，包括高层行为规划和低层轨迹规划。通过在仿真和实际驾驶中的测试，证明了该方法在城市自动驾驶中具有出色的性能。

    

    基于学习的方法在自动驾驶的决策和规划模块上取得了令人瞩目的性能，但神经网络的可靠性和稳定性仍然存在挑战。本文提出了一种分层模仿学习方法，包括高层次的基于网格的行为规划器和低层次的轨迹规划器，不仅是一种个体的数据驱动驾驶策略，而且还可以轻松地嵌入基于规则的架构中。我们在闭环仿真和实际驾驶中评估了我们的方法，并证明神经网络规划器在复杂的城市自动驾驶场景中具有出色的性能。

    Learning-based approaches have achieved impressive performance for autonomous driving and an increasing number of data-driven works are being studied in the decision-making and planning module. However, the reliability and the stability of the neural network is still full of challenges. In this paper, we introduce a hierarchical imitation method including a high-level grid-based behavior planner and a low-level trajectory planner, which is not only an individual data-driven driving policy and can also be easily embedded into the rule-based architecture. We evaluate our method both in closed-loop simulation and real world driving, and demonstrate the neural network planner has outstanding performance in complex urban autonomous driving scenarios.
    
[^85]: ICICLE: 可解释的类增量连续学习方法

    ICICLE: Interpretable Class Incremental Continual Learning. (arXiv:2303.07811v1 [cs.LG])

    [http://arxiv.org/abs/2303.07811](http://arxiv.org/abs/2303.07811)

    ICICLE提出了一种基于样本的可解释的类增量连续学习方法，通过采用原型部分化方法来解决解释性概念漂移的问题，实验结果表明其在不需要样本的情况下表现优于现有的方法。

    

    连续学习能够增量学习新任务而不忘记之前学习的内容，从而促进新旧任务之间的正向知识转移。然而，连续学习对解释性提出了新的挑战，因为模型预测背后的原理可能会随着时间而改变，导致解释性概念漂移。本文通过提出基于样本的 Interpretable Class-InCremental LEarning (ICICLE) 方法，采用原型部分化方法，解决了这个问题。它包括三个关键的创新点：解释性正则化、以微粒粒度为基础的原型初始化策略以及针对原型部分的任务时效偏差补偿。我们的实验结果表明，ICICLE减少了解释性概念漂移，并且在不需要样本的情况下表现优于现有的方法。

    Continual learning enables incremental learning of new tasks without forgetting those previously learned, resulting in positive knowledge transfer that can enhance performance on both new and old tasks. However, continual learning poses new challenges for interpretability, as the rationale behind model predictions may change over time, leading to interpretability concept drift. We address this problem by proposing Interpretable Class-InCremental LEarning (ICICLE), an exemplar-free approach that adopts a prototypical part-based approach. It consists of three crucial novelties: interpretability regularization that distills previously learned concepts while preserving user-friendly positive reasoning; proximity-based prototype initialization strategy dedicated to the fine-grained setting; and task-recency bias compensation devoted to prototypical parts. Our experimental results demonstrate that ICICLE reduces the interpretability concept drift and outperforms the existing exemplar-free me
    
[^86]: 一种用于领域外意图检测和意图发现的混合架构

    A Hybrid Architecture for Out of Domain Intent Detection and Intent Discovery. (arXiv:2303.04134v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.04134](http://arxiv.org/abs/2303.04134)

    本研究提出了一种混合架构来解决任务导向型对话系统中领域外意图检测和意图发现的问题。通过使用变分自编码器和无监督聚类方法，可以准确识别和区分已知和未知的意图，并发现潜藏在领域外输入中的不同未知意图。

    

    意图检测是任务导向型对话系统中自然语言理解（NLU）模块的任务之一。领域外（OOS）和领域外（OOD）的输入可能会给这些系统带来问题。另一方面，训练任务导向型对话系统中意图检测模型需要标记的数据集。创建标记数据集耗时且需要人力资源。本文旨在解决上述问题。将识别OOD/OOS输入的任务命名为OOD/OOS意图检测。同时，发现新的意图并对OOD输入进行伪标记，则被称为意图发现。在OOD意图检测部分，我们利用变分自编码器来区分已知意图和未知意图，独立于输入数据分布。之后，使用无监督聚类方法来发现OOD/OOS输入中不同的未知意图。我们还对OOD/OOS表示应用非线性降维。

    Intent Detection is one of the tasks of the Natural Language Understanding (NLU) unit in task-oriented dialogue systems. Out of Scope (OOS) and Out of Domain (OOD) inputs may run these systems into a problem. On the other side, a labeled dataset is needed to train a model for Intent Detection in task-oriented dialogue systems. The creation of a labeled dataset is time-consuming and needs human resources. The purpose of this article is to address mentioned problems. The task of identifying OOD/OOS inputs is named OOD/OOS Intent Detection. Also, discovering new intents and pseudo-labeling of OOD inputs is well known by Intent Discovery. In OOD intent detection part, we make use of a Variational Autoencoder to distinguish between known and unknown intents independent of input data distribution. After that, an unsupervised clustering method is used to discover different unknown intents underlying OOD/OOS inputs. We also apply a non-linear dimensionality reduction on OOD/OOS representations
    
[^87]: TopSpark:一种用于自主移动机器人上的节能脉冲神经网络的时间步长优化方法

    TopSpark: A Timestep Optimization Methodology for Energy-Efficient Spiking Neural Networks on Autonomous Mobile Agents. (arXiv:2303.01826v2 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2303.01826](http://arxiv.org/abs/2303.01826)

    TopSpark提出了一种时间步长优化方法，用于提高自主移动机器人上脉冲神经网络的能量效率。该方法消除了固定时间步长的限制，使得SNNs能够在训练和推断阶段都实现更高的能量效率，并且能够在运行时进行高效的在线学习。

    

    自主移动机器人需要低功耗/高效能的机器学习算法来完成基于机器学习的任务，并能够适应多样化的环境，因为移动机器人通常由电池供电。脉冲神经网络（SNNs）可以实现这些要求，因为它们通过稀疏计算和具有生物启发式学习机制的高效在线学习，提供低功耗/高效能的处理。最近的研究表明，通过减少每个神经元处理一个脉冲序列（时间步长）的计算时间，可以优化SNNs的能量消耗。然而，现有技术依赖于大量的设计搜索来确定只能进行推断的固定时间步长设置，从而阻碍了SNNs在训练和推断阶段实现进一步的能量效率提高。这些技术还限制了SNNs在运行时进行高效的在线学习。为了解决这个问题，我们提出了TopSpark方法

    Autonomous mobile agents require low-power/energy-efficient machine learning (ML) algorithms to complete their ML-based tasks while adapting to diverse environments, as mobile agents are usually powered by batteries. These requirements can be fulfilled by Spiking Neural Networks (SNNs) as they offer low power/energy processing due to their sparse computations and efficient online learning with bio-inspired learning mechanisms for adapting to different environments. Recent works studied that the energy consumption of SNNs can be optimized by reducing the computation time of each neuron for processing a sequence of spikes (timestep). However, state-of-the-art techniques rely on intensive design searches to determine fixed timestep settings for only inference, thereby hindering the SNNs from achieving further energy efficiency gains in both training and inference. These techniques also restrict the SNNs from performing efficient online learning at run time. Toward this, we propose TopSpar
    
[^88]: 以ELBOs的加权积分理解扩散目标

    Understanding the Diffusion Objective as a Weighted Integral of ELBOs. (arXiv:2303.00848v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.00848](http://arxiv.org/abs/2303.00848)

    本文深入理解了扩散目标，并揭示了加权损失和ELBO目标之间的直接关系。

    

    文献中的扩散模型采用不同的目标进行优化，并且这些目标都是加权损失的特例，其中加权函数指定每个噪声级别的权重。均匀加权对应于最大似然的原则性近似ELBO的最大化。但是实际上，由于更好的样本质量，目前的扩散模型使用非均匀加权。本文揭示了加权损失（带有任何加权）和ELBO目标之间的直接关系。我们展示了加权损失可以被写成一种ELBOs的加权积分形式，其中每个噪声级别都有一个ELBO。如果权重函数是单调的，那么加权损失是一种基于似然的目标：它在简单的数据增强下（即高斯噪声扰动）下最大化ELBO。我们的主要贡献是更深入地理解了扩散目标，但我们还进行了一些比较单调和非单调权重的实验。

    Diffusion models in the literature are optimized with various objectives that are special cases of a weighted loss, where the weighting function specifies the weight per noise level. Uniform weighting corresponds to maximizing the ELBO, a principled approximation of maximum likelihood. In current practice diffusion models are optimized with non-uniform weighting due to better results in terms of sample quality. In this work we expose a direct relationship between the weighted loss (with any weighting) and the ELBO objective.  We show that the weighted loss can be written as a weighted integral of ELBOs, with one ELBO per noise level. If the weighting function is monotonic, then the weighted loss is a likelihood-based objective: it maximizes the ELBO under simple data augmentation, namely Gaussian noise perturbation. Our main contribution is a deeper theoretical understanding of the diffusion objective, but we also performed some experiments comparing monotonic with non-monotonic weight
    
[^89]: 让你的行为井然有序：AI法案和技术透明度的比较视角

    Get Your Act Together: A Comparative View on Transparency in the AI Act and Technology. (arXiv:2302.10766v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2302.10766](http://arxiv.org/abs/2302.10766)

    该论文比较了欧盟提出的《人工智能法案》和可解释AI（XAI）对于透明度和解释性的基本定义，强调了将这些定义对齐的重要性，以确保技术实践符合法规。

    

    欧盟提出了《人工智能法案》，引入了基于风险的比例方法来规范人工智能，其中详细要求透明度和可解释性。虽然可解释AI（XAI）领域可以解决这些要求中的许多问题，但在透明度和可解释性的具体定义上，XAI与该法案存在基本差异。为了实现这种对齐，我们首先概述了XAI和欧洲法规是如何看待透明度的基本定义的，特别是AI法案和相关的通用数据保护条例（GDPR）。然后我们进行了比较，旨在确定改善领域之间对齐的主要要点：澄清透明度的范围，XAI的法律地位，监管问题。

    The European Union has proposed the Artificial Intelligence Act which introduces a proportional risk-based approach to AI regulation including detailed requirements for transparency and explainability. Many of these requirements may be addressed in practice by the field of explainable AI (XAI), however, there are fundamental differences between XAI and the Act regarding what transparency and explainability are. These basic definitions should be aligned to assure that regulation continually translates into appropriate technical practices. To facilitate this alignment, we first give an overview of how XAI and European regulation view basic definitions of transparency with a particular focus on the AI Act and the related General Data Protection Regulation (GDPR). We then present a comparison of XAI and regulatory approaches to identify the main points that would improve alignment between the fields: clarification of the scope of transparency, the legal status of XAI, oversight issues in c
    
[^90]: Arena-Rosnav 2.0：用于在高度动态环境中的机器人导航开发和基准测试的平台

    Arena-Rosnav 2.0: A Development and Benchmarking Platform for Robot Navigation in Highly Dynamic Environments. (arXiv:2302.10023v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2302.10023](http://arxiv.org/abs/2302.10023)

    Arena-Rosnav 2.0是一个用于开发和基准测试机器人导航方法的平台，它提供了统一的API和更真实的模拟，通过用户研究和集成最新的导航方法验证了其可行性。

    

    在本文中，我们在之前的工作基础上推出了Arena-Rosnav 2.0，这是我们之前的作品Arena-Bench和Arena-Rosnav的扩展版，增加了多种附加模块用于开发和基准测试机器人导航方法。该平台进行了根本重构，并提供了统一的API，用于添加额外的功能，如规划算法、模拟器或评估功能。我们增加了更加真实的模拟和行人行为，并提供了深入的文档以降低入门门槛。我们通过首先进行用户研究来评估我们的系统，在该研究中，我们要求有经验的研究者和新的从业者和学生测试我们的系统。反馈大多数是积极的，很多参与者正在将我们的系统用于其他研究项目。最后，我们通过整合两个新的模拟器和各种最先进的导航方法和基准测试验证了我们系统的可行性。

    Following up on our previous works, in this paper, we present Arena-Rosnav 2.0 an extension to our previous works Arena-Bench and Arena-Rosnav, which adds a variety of additional modules for developing and benchmarking robotic navigation approaches. The platform is fundamentally restructured and provides unified APIs to add additional functionalities such as planning algorithms, simulators, or evaluation functionalities. We have included more realistic simulation and pedestrian behavior and provide a profound documentation to lower the entry barrier. We evaluated our system by first, conducting a user study in which we asked experienced researchers as well as new practitioners and students to test our system. The feedback was mostly positive and a high number of participants are utilizing our system for other research endeavors. Finally, we demonstrate the feasibility of our system by integrating two new simulators and a variety of state of the art navigation approaches and benchmark t
    
[^91]: 异构视觉深度网络社区中的指代性沟通

    Referential communication in heterogeneous communities of pre-trained visual deep networks. (arXiv:2302.08913v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.08913](http://arxiv.org/abs/2302.08913)

    异构视觉深度网络社区中的预训练网络可以自我监督地开发出共享协议，以指代一组目标中的目标对象，并可用于沟通不同粒度的未知对象类别。

    

    随着大型预训练图像处理神经网络被嵌入自动驾驶汽车或机器人等自主代理中，一个问题出现了：在它们具有不同架构和训练方式的情况下，这些系统如何相互之间进行沟通以了解周围的世界。作为朝着这个方向的第一步，我们系统地探索了在一组异构最先进的预训练视觉网络社区中进行"指代性沟通"的任务，结果表明它们可以自我监督地发展一种共享协议来指代一组候选目标中的目标对象。在某种程度上，这种共享协议也可以用来沟通不同粒度的先前未见过的对象类别。此外，一个最初不属于现有社区的视觉网络可以轻松地学习到社区的协议。最后，我们定性和定量地研究了这种新产生的协议的属性，提供了一些证据。

    As large pre-trained image-processing neural networks are being embedded in autonomous agents such as self-driving cars or robots, the question arises of how such systems can communicate with each other about the surrounding world, despite their different architectures and training regimes. As a first step in this direction, we systematically explore the task of \textit{referential communication} in a community of heterogeneous state-of-the-art pre-trained visual networks, showing that they can develop, in a self-supervised way, a shared protocol to refer to a target object among a set of candidates. This shared protocol can also be used, to some extent, to communicate about previously unseen object categories of different granularity. Moreover, a visual network that was not initially part of an existing community can learn the community's protocol with remarkable ease. Finally, we study, both qualitatively and quantitatively, the properties of the emergent protocol, providing some evi
    
[^92]: 设计数据：针对机器学习的主动数据收集和迭代

    Designing Data: Proactive Data Collection and Iteration for Machine Learning. (arXiv:2301.10319v2 [cs.HC] UPDATED)

    [http://arxiv.org/abs/2301.10319](http://arxiv.org/abs/2301.10319)

    这篇论文介绍了一种设计数据的迭代方法，将人机交互概念与机器学习技术相结合，以解决机器学习应用中数据收集缺乏多样性导致的失败问题。通过预收集计划、收集监控和数据熟悉度等步骤，该方法可以提高模型的泛化能力并在跨组交叉群体上取得更好的结果。

    

    数据收集的缺乏多样性导致机器学习应用中的严重失败。虽然机器学习开发人员可以进行数据后处理，但这需要耗费大量时间并很少全面。因此，需要新的方法来跟踪和管理数据收集、迭代和模型训练，以评估数据集是否反映了真实世界的变异。我们提出了设计数据的迭代方法，将人机交互概念与机器学习技术相结合。我们的过程包括（1）预收集计划，主动促使并记录预期的数据分布；（2）收集监控，系统性地鼓励采样多样性；（3）数据熟悉度，使用密度估计方法识别模型对其不熟悉的样本。我们将设计数据应用于数据收集和建模任务。我们发现在跨组交叉群体训练的模型上，“设计”数据集的泛化能力优于大小相似但针对性较低的数据集的模型。

    Lack of diversity in data collection has caused significant failures in machine learning (ML) applications. While ML developers perform post-collection interventions, these are time intensive and rarely comprehensive. Thus, new methods to track & manage data collection, iteration, and model training are necessary for evaluating whether datasets reflect real world variability. We present designing data, an iterative approach to data collection connecting HCI concepts with ML techniques. Our process includes (1) Pre-Collection Planning, to reflexively prompt and document expected data distributions; (2) Collection Monitoring, to systematically encourage sampling diversity; and (3) Data Familiarity, to identify samples that are unfamiliar to a model using density estimation. We apply designing data to a data collection and modeling task. We find models trained on ''designed'' datasets generalize better across intersectional groups than those trained on similarly sized but less targeted da
    
[^93]: SpArX: 稀疏的神经网络论证解释

    SpArX: Sparse Argumentative Explanations for Neural Networks. (arXiv:2301.09559v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2301.09559](http://arxiv.org/abs/2301.09559)

    该论文提出了一种稀疏的神经网络论证解释方法SpArX，通过利用多层感知器和定量论证框架之间的关系，可以为神经网络的决策过程提供更忠实和深入的解释。

    

    神经网络在人工智能中有各种应用，但解释它们的决策仍然具有挑战性。现有方法通常关注解释改变单个输入如何影响神经网络的输出。然而，一个与神经网络的输入输出行为一致的解释未必忠实于其实际机制。在本文中，我们利用多层感知器和定量论证框架之间的关系，为多层感知器的机制创建了论证性解释。我们的SpArX方法首先将多层感知器稀疏化，同时保持尽可能多的原始结构。然后将稀疏的多层感知器转化为等效的定量论证框架，以揭示多层感知器的潜在决策过程，产生全局和/或局部解释。我们通过实验证明，SpArX比现有方法可以给出更忠实的解释，同时提供更深入的洞察实际推理过程。

    Neural networks (NNs) have various applications in AI, but explaining their decisions remains challenging. Existing approaches often focus on explaining how changing individual inputs affects NNs' outputs. However, an explanation that is consistent with the input-output behaviour of an NN is not necessarily faithful to the actual mechanics thereof. In this paper, we exploit relationships between multi-layer perceptrons (MLPs) and quantitative argumentation frameworks (QAFs) to create argumentative explanations for the mechanics of MLPs. Our SpArX method first sparsifies the MLP while maintaining as much of the original structure as possible. It then translates the sparse MLP into an equivalent QAF to shed light on the underlying decision process of the MLP, producing global and/or local explanations. We demonstrate experimentally that SpArX can give more faithful explanations than existing approaches, while simultaneously providing deeper insights into the actual reasoning process of M
    
[^94]: ACQ: 借助注意力修正改进生成式无数据量化方法

    ACQ: Improving Generative Data-free Quantization Via Attention Correction. (arXiv:2301.07266v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2301.07266](http://arxiv.org/abs/2301.07266)

    本论文提出了ACQ方法，通过修正合成样本的注意力，改进了生成式无数据量化方法。通过建立注意力中心位置的条件生成器，实现了类内关注度的均一化。

    

    无数据量化旨在实现模型量化而不访问任何真实样本。在涉及数据隐私的应用场景中具有重要意义。通过生成器将噪声向量转化为合成样本是一种常用的无数据量化方法，称为生成式无数据量化。然而，合成样本和真实样本之间存在注意力差异，这一点经常被忽视，限制了量化性能。ACQ是本文提出的修正合成样本注意力的方法。该方法建立了一个基于注意力中心位置的条件生成器，旨在实现类内关注度的均一化。

    Data-free quantization aims to achieve model quantization without accessing any authentic sample. It is significant in an application-oriented context involving data privacy. Converting noise vectors into synthetic samples through a generator is a popular data-free quantization method, which is called generative data-free quantization. However, there is a difference in attention between synthetic samples and authentic samples. This is always ignored and restricts the quantization performance. First, since synthetic samples of the same class are prone to have homogenous attention, the quantized network can only learn limited modes of attention. Second, synthetic samples in eval mode and training mode exhibit different attention. Hence, the batch-normalization statistics matching tends to be inaccurate. ACQ is proposed in this paper to fix the attention of synthetic samples. An attention center position-condition generator is established regarding the homogenization of intra-class attent
    
[^95]: MEAformer: 多模式实体对齐变压器用于元模态混合

    MEAformer: Multi-modal Entity Alignment Transformer for Meta Modality Hybrid. (arXiv:2212.14454v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2212.14454](http://arxiv.org/abs/2212.14454)

    该论文提出了一种适用于元模态混合的多模式实体对齐变压器方法，通过动态预测模态之间的相互关联系数以进行实体级特征聚合，进一步提出了一种模态感知的硬实体重播策略，用于解决模糊实体细节的问题。该模型在多个训练场景中实现了SOTA性能并有效提高了MMEA的鲁棒性。

    

    作为实体对齐（EA）的一个重要变体，多模式实体对齐（MMEA）旨在发现不同知识图谱（KGs）中具有相关图像的相同实体。 我们注意到，当前的MMEA算法都全局采用KG级模态融合策略进行多模式实体表示，但忽略了个体实体的模态偏好变化，从而削弱了对模态（例如模糊图像和关系）中潜在噪声的鲁棒性。在本文中，我们提出了MEAformer，一种适用于元模态混合的多模式实体对齐变压器方法，该方法动态预测模态之间的相互关联系数以进行实体级特征聚合。进一步提出了一种模态感知的硬实体重播策略，用于解决模糊实体细节的问题。实验结果表明，我们的模型不仅在多个训练场景（包括有监督、无监督、迭代和低资源设置）中实现了SOTA性能，而且通过利用模态偏好变化有效提高了MMEA的鲁棒性。

    As an important variant of entity alignment (EA), multi-modal entity alignment (MMEA) aims to discover identical entities across different knowledge graphs (KGs) with relevant images attached. We noticed that current MMEA algorithms all globally adopt the KG-level modality fusion strategies for multi-modal entity representation but ignore the variation in modality preferences for individual entities, hurting the robustness to potential noise involved in modalities (e.g., blurry images and relations). In this paper, we present MEAformer, a multi-modal entity alignment transformer approach for meta modality hybrid, which dynamically predicts the mutual correlation coefficients among modalities for entity-level feature aggregation. A modal-aware hard entity replay strategy is further proposed for addressing vague entity details. Experimental results show that our model not only achieves SOTA performance on multiple training scenarios including supervised, unsupervised, iterative, and low 
    
[^96]: 通过合成开放领域对话来增强任务机器人的参与度

    Enhancing Task Bot Engagement with Synthesized Open-Domain Dialog. (arXiv:2212.10008v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10008](http://arxiv.org/abs/2212.10008)

    本论文提出了一种通过合成开放领域对话来增强任务机器人的参与度的框架，并介绍了一种统一模型PivotBot，该模型能够无缝切换任务导向对话和开放领域对话，在处理融合任务方面具有优越能力。

    

    已经进行了许多努力来构建适用于不同类型对话的对话系统，如任务导向对话（TOD）和开放领域对话（ODD）。为了更好地模仿人类级别的对话，通常需要融合各种对话模式，并建立一个可以有效处理TOD和ODD，并访问不同知识源的系统。为了解决融合任务缺乏可用数据的问题，我们提出了一个框架，用于自动生成在不同环境中结合了知识为基础的ODD和TOD的对话。此外，我们介绍了一个统一模型PivotBot，能够适当地采用TOD和ODD模式，并访问不同的知识源，以便有效地处理融合任务。评估结果表明，所提出的模型在TOD和ODD任务之间无缝切换的能力优于其他模型。

    Many efforts have been made to construct dialog systems for different types of conversations, such as task-oriented dialog (TOD) and open-domain dialog (ODD). To better mimic human-level conversations that usually fuse various dialog modes, it is essential to build a system that can effectively handle both TOD and ODD and access different knowledge sources. To address the lack of available data for the fused task, we propose a framework for automatically generating dialogues that combine knowledge-grounded ODDs and TODs in various settings. Additionally, we introduce a unified model PivotBot that is capable of appropriately adopting TOD and ODD modes and accessing different knowledge sources in order to effectively tackle the fused task. Evaluation results demonstrate the superior ability of the proposed model to switch seamlessly between TOD and ODD tasks.
    
[^97]: 欧洲人工智能责任指令——对半心态方法的批评和未来经验教训的研究

    The European AI Liability Directives -- Critique of a Half-Hearted Approach and Lessons for the Future. (arXiv:2211.13960v6 [cs.CY] UPDATED)

    [http://arxiv.org/abs/2211.13960](http://arxiv.org/abs/2211.13960)

    这篇论文对欧洲AI责任指令的提案进行了详细研究，发现其代表了一个半心态的方法，并提出了三个创新贡献。

    

    随着ChatGPT等人工智能系统征服世界，全球AI系统的最佳责任框架仍然是一个未解决的问题。2022年9月，欧洲委员会提出了两项关于AI责任的提案，概述了欧洲的方法：一项新的AI责任指令和对产品责任指令的修订。它们构成了欧盟AI监管的最终基石。关键是，责任提案和欧盟AI法案是相互联系的：后者不包含任何受影响人员的个人权利，前者缺乏关于AI开发和部署的具体、实质性规则。综合起来，这些法案可能会在AI监管领域引发布鲁塞尔效应，对美国和其他国家产生重大影响。本文提出了三个新的贡献。首先，它详细研究了委员会的提案，并表明，虽然朝着正确方向迈出了步伐，但最终代表着半心态的方法：如果通过改正方案，

    As ChatGPT et al. conquer the world, the optimal liability framework for AI systems remains an unsolved problem across the globe. In a much-anticipated move, the European Commission advanced two proposals outlining the European approach to AI liability in September 2022: a novel AI Liability Directive and a revision of the Product Liability Directive. They constitute the final cornerstone of EU AI regulation. Crucially, the liability proposals and the EU AI Act are inherently intertwined: the latter does not contain any individual rights of affected persons, and the former lack specific, substantive rules on AI development and deployment. Taken together, these acts may well trigger a Brussels Effect in AI regulation, with significant consequences for the US and beyond.  This paper makes three novel contributions. First, it examines in detail the Commission proposals and shows that, while making steps in the right direction, they ultimately represent a half-hearted approach: if enacted 
    
[^98]: 如何通过StyleGAN提升人脸识别？

    How to Boost Face Recognition with StyleGAN?. (arXiv:2210.10090v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2210.10090](http://arxiv.org/abs/2210.10090)

    本文介绍了如何利用StyleGAN来提升人脸识别的效果，包括针对身份有限的数据问题进行的改进以及通过生成模型进行数据扩增的方法。在实验中，我们使用了大规模的无标签数据集，证明了这种方法的有效性。

    

    最先进的人脸识别系统需要大量的标注训练数据。由于人脸识别应用中隐私的优先级，数据限制在名人网络爬虫上，其中存在身份有限的问题。另一方面，自监督革命激发了将相关技术应用于人脸识别的研究。最流行的实用技巧之一是通过从生成模型中绘制样本来增加数据集，同时保留身份信息。我们表明，基于对StyleGAN进行微调的pSp编码器的简单方法能够提高最先进的人脸识别技术，并与对合成人脸身份进行训练相比表现更好。我们还收集了具有可控族裔构成的大规模无标签数据集--AfricanFaceSet-5M（包含500万张不同人的图像）和AsianFaceSet-3M（包含300万张不同人的图像）--并展示了在每个数据集上进行预训练。

    State-of-the-art face recognition systems require vast amounts of labeled training data. Given the priority of privacy in face recognition applications, the data is limited to celebrity web crawls, which have issues such as limited numbers of identities. On the other hand, self-supervised revolution in the industry motivates research on the adaptation of related techniques to facial recognition. One of the most popular practical tricks is to augment the dataset by the samples drawn from generative models while preserving the identity. We show that a simple approach based on fine-tuning pSp encoder for StyleGAN allows us to improve upon the state-of-the-art facial recognition and performs better compared to training on synthetic face identities. We also collect large-scale unlabeled datasets with controllable ethnic constitution -AfricanFaceSet-5M (5 million images of different people) and AsianFaceSet-3M (3 million images of different people) -- and we show that pretraining on each o
    
[^99]: 通过模块化和组合来修补卷积神经网络模型的弱点

    Patching Weak Convolutional Neural Network Models through Modularization and Composition. (arXiv:2209.06116v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.06116](http://arxiv.org/abs/2209.06116)

    本文提出了一种通过压缩模块化和组合来修补卷积神经网络模型的弱点的方法，该方法无需重新训练整个模型，并在多个基准数据集上实现了与最先进方法相当甚至更好的结果。

    

    尽管深度神经网络在许多应用程序中取得了巨大成功，但在实践中并不总是具有鲁棒性。本文关注的是修补卷积神经网络模型的弱点，而不是通过昂贵的重新训练整个模型来改进它。我们提出了一种压缩模块化方法CNNSplitter，它将具有$N$类分类任务的强CNN模型分解为$N$个较小的CNN模块。每个模块是一个子模型，包含强模型的部分卷积核。为了修补在目标类别（TC）上表现不佳的弱CNN模型，我们将其与从强CNN模型中获得的相应模块相结合。这样，弱CNN模型识别TC的能力可以大大提高，而无需重新训练整个模型。我们在几个基准数据集上展示了我们提出的方法的有效性，并表明它实现了与最先进方法相当甚至更好的结果。

    Despite great success in many applications, deep neural networks are not always robust in practice. For instance, a convolutional neuron network (CNN) model for classification tasks often performs unsatisfactorily in classifying some particular classes of objects. In this work, we are concerned with patching the weak part of a CNN model instead of improving it through the costly retraining of the entire model. Inspired by the fundamental concepts of modularization and composition in software engineering, we propose a compressed modularization approach, CNNSplitter, which decomposes a strong CNN model for $N$-class classification into $N$ smaller CNN modules. Each module is a sub-model containing a part of the convolution kernels of the strong model. To patch a weak CNN model that performs unsatisfactorily on a target class (TC), we compose the weak CNN model with the corresponding module obtained from a strong CNN model. The ability of the weak CNN model to recognize the TC can thus be
    
[^100]: SAFARI：鲁棒性可解释性评估的多功能高效方法

    SAFARI: Versatile and Efficient Evaluations for Robustness of Interpretability. (arXiv:2208.09418v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2208.09418](http://arxiv.org/abs/2208.09418)

    本文提出了一种名为SAFARI的方法，用于评估深度学习的解释可靠性。该方法针对现有技术无法解决的几个挑战，通过引入两种黑盒评估方法，即最坏情况解释差异和一般情况下的鲁棒性的概率概念，来解决现有度量不全面、XAI技术异质性和误解罕见性等问题。使用遗传算法和子集模拟进行评估。

    

    深度学习的可解释性是建立可信赖的人工智能的一道障碍。尽管可解释人工智能（XAI）社区做出了巨大的努力，但解释缺乏鲁棒性——无法区分的输入扰动可能会导致不同的解释结果。因此，针对给定的XAI方法评估深度学习可解释性的鲁棒性至关重要。本文识别了现有技术无法共同应对的几个挑战：i)现有指标不全面；ii)XAI技术高度异质；iii)误解通常是罕见事件。为了解决这些挑战，我们引入了两种黑盒评估方法，分别涉及最坏情况解释差异和一般情况下的鲁棒性的概率概念。使用具有定制适应度函数的遗传算法（GA）来解决约束优化，以实现高效的最坏情况评估。使用专门用于估计罕见事件概率的子集模拟（SS）来进行整体评估。

    Interpretability of Deep Learning (DL) is a barrier to trustworthy AI. Despite great efforts made by the Explainable AI (XAI) community, explanations lack robustness -- indistinguishable input perturbations may lead to different XAI results. Thus, it is vital to assess how robust DL interpretability is, given an XAI method. In this paper, we identify several challenges that the state-of-the-art is unable to cope with collectively: i) existing metrics are not comprehensive; ii) XAI techniques are highly heterogeneous; iii) misinterpretations are normally rare events. To tackle these challenges, we introduce two black-box evaluation methods, concerning the worst-case interpretation discrepancy and a probabilistic notion of how robust in general, respectively. Genetic Algorithm (GA) with bespoke fitness function is used to solve constrained optimisation for efficient worst-case evaluation. Subset Simulation (SS), dedicated to estimate rare event probabilities, is used for evaluating overa
    
[^101]: 可争议神经网络的因果发现与知识注入

    Causal Discovery and Knowledge Injection for Contestable Neural Networks. (arXiv:2205.09787v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.09787](http://arxiv.org/abs/2205.09787)

    本研究提出了一种可以进行双向互动的方法，通过允许神经网络展示其所学因果图，并允许人类修改因果图后重新注入机器中，从而提供了一种调试神经网络的方式，实验结果显示该方法可以显著改善预测性能。

    

    神经网络在解决机器学习任务方面表现出色，但它们是否学习到了相关的因果关系尚不清楚，而它们的黑箱特性使得模型构建者难以理解和调试。我们提出了一种新颖的方法来解决这些问题，通过允许神经网络驱动的机器展示其所学因果图，并允许人类修改因果图后重新注入机器中，实现双向互动。所学模型保证符合因果图并遵循专家知识，其中部分知识也可以事先给定。通过对模型行为进行可视化并实现知识注入，我们的方法允许从数据中发现因果结构并支撑预测的从业者进行调试。在真实和合成表格数据上的实验表明，我们的方法可以改进预测性能高达2.4倍。

    Neural networks have proven to be effective at solving machine learning tasks but it is unclear whether they learn any relevant causal relationships, while their black-box nature makes it difficult for modellers to understand and debug them. We propose a novel method overcoming these issues by allowing a two-way interaction whereby neural-network-empowered machines can expose the underpinning learnt causal graphs and humans can contest the machines by modifying the causal graphs before re-injecting them into the machines. The learnt models are guaranteed to conform to the graphs and adhere to expert knowledge, some of which can also be given up-front. By building a window into the model behaviour and enabling knowledge injection, our method allows practitioners to debug networks based on the causal structure discovered from the data and underpinning the predictions. Experiments with real and synthetic tabular data show that our method improves predictive performance up to 2.4x while pr
    
[^102]: 探索多智能体学习中团队的益处

    Exploring the Benefits of Teams in Multiagent Learning. (arXiv:2205.02328v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2205.02328](http://arxiv.org/abs/2205.02328)

    本文提出了一种基于组织心理学和人工智能早期工作的新模型，用于多智能体强化学习中的团队，通过复杂社交困境的验证，发现分成团队的智能体能够发展合作的政策，能够更好地协调和学习团队内的新兴角色，并获得更高的奖励。

    

    对于需要合作的问题，许多多智能体系统实施解决方案，既可以是个体智能体之间，也可以是整个人口之间，以达到共同目标。多智能体团队主要在冲突时进行研究；然而，组织心理学（OP）强调团队在人口中的合作和协调学习上的益处。在本文中，我们提出了一种受OP和人工智能中关于团队的早期工作启发的强化学习（RL）智能体的新模型。我们使用近期多智能体RL中流行的复杂社交困境验证我们的模型，并发现即使有不合作的激励，分成团队的智能体仍然能够发展出合作和互助的政策。此外，智能体能够更好地协调和学习团队内的新兴角色，并获得比所有智能体利益一致时更高的奖励。

    For problems requiring cooperation, many multiagent systems implement solutions among either individual agents or across an entire population towards a common goal. Multiagent teams are primarily studied when in conflict; however, organizational psychology (OP) highlights the benefits of teams among human populations for learning how to coordinate and cooperate. In this paper, we propose a new model of multiagent teams for reinforcement learning (RL) agents inspired by OP and early work on teams in artificial intelligence. We validate our model using complex social dilemmas that are popular in recent multiagent RL and find that agents divided into teams develop cooperative pro-social policies despite incentives to not cooperate. Furthermore, agents are better able to coordinate and learn emergent roles within their teams and achieve higher rewards compared to when the interests of all agents are aligned.
    
[^103]: 解释性在过程结果预测中的应用：获得可解释和可信模型的指南

    Explainability in Process Outcome Prediction: Guidelines to Obtain Interpretable and Faithful Models. (arXiv:2203.16073v5 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2203.16073](http://arxiv.org/abs/2203.16073)

    本文介绍了在过程结果预测中应用解释性模型的指南，并通过对事件、案例和控制流的分析，通过实验评估了不同模型的解释性能力。

    

    尽管在预测性过程监控领域已经开始采用可解释人工智能领域的模型，但评估仍主要基于性能指标，并未考虑解释的可操作性和影响。本文通过解释的可解释性和可信度来定义过程结果预测领域的可解释性。我们通过事件、案例和控制流的角度进行分析这些特性，这是典型的基于过程的分析方法。我们在十三个真实事件日志上对七个分类器进行了基准测试，其中包含一系列透明和非透明的机器学习和深度学习模型，并补充了解释性技术。接下来，本文提供了一套名为X-MOP的指南，使用户能够根据个人需求选择最合适的解释性模型。

    Although a recent shift has been made in the field of predictive process monitoring to use models from the explainable artificial intelligence field, the evaluation still occurs mainly through performance-based metrics, thus not accounting for the actionability and implications of the explanations. In this paper, we define explainability through the interpretability of the explanations and the faithfulness of the explainability model in the field of process outcome prediction. The introduced properties are analysed along the event, case, and control flow perspective which are typical for a process-based analysis. This allows comparing inherently created explanations with post-hoc explanations. We benchmark seven classifiers on thirteen real-life events logs, and these cover a range of transparent and non-transparent machine learning and deep learning models, further complemented with explainability techniques. Next, this paper contributes a set of guidelines named X-MOP which allows se
    
[^104]: BoMD：适用于嘈杂X光分类的多标签描述符包

    BoMD: Bag of Multi-label Descriptors for Noisy Chest X-ray Classification. (arXiv:2203.01937v3 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2203.01937](http://arxiv.org/abs/2203.01937)

    本文提出了一种适用于多标签、嘈杂CXR学习的方法，使用基于袋的多标签描述符平滑地重新标记数据集中的样本，并进行训练以提高模型性能。

    

    深度学习方法在医学图像问题的分类精度方面表现出色，这在很大程度上归功于具有清洁标签的大规模数据集的可用性。然而，考虑到这种手动注释的高成本，新的医学图像分类问题可能需要依赖于从放射学报告中提取的机器生成的嘈杂标签。事实上，许多胸部X光分类器已经从带有嘈杂标签的数据集中建模，但它们的训练过程通常不具有噪声标签样本的鲁棒性，导致次优模型。此外，CXR数据集大多是多标记的，因此当前设计用于多类问题的嘈杂标签学习方法不能轻松地进行调整。本文提出了一种新方法，用于嘈杂多标签CXR学习，其中检测并平滑地重新标记数据集中的样本，然后用于训练常见的多标签分类器。该方法优化了一个基于袋的多标签表示方法，以便有效地使用从放射学报告中提取的信息。

    Deep learning methods have shown outstanding classification accuracy in medical imaging problems, which is largely attributed to the availability of large-scale datasets manually annotated with clean labels. However, given the high cost of such manual annotation, new medical imaging classification problems may need to rely on machine-generated noisy labels extracted from radiology reports. Indeed, many Chest X-ray (CXR) classifiers have already been modelled from datasets with noisy labels, but their training procedure is in general not robust to noisy-label samples, leading to sub-optimal models. Furthermore, CXR datasets are mostly multi-label, so current noisy-label learning methods designed for multi-class problems cannot be easily adapted. In this paper, we propose a new method designed for the noisy multi-label CXR learning, which detects and smoothly re-labels samples from the dataset, which is then used to train common multi-label classifiers. The proposed method optimises a ba
    
[^105]: 通过记忆推理：最近邻知识图嵌入

    Reasoning Through Memorization: Nearest Neighbor Knowledge Graph Embeddings. (arXiv:2201.05575v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2201.05575](http://arxiv.org/abs/2201.05575)

    本文提出了一种新的知识图嵌入方法kNN-KGE，它通过预训练语言模型和最近邻的线性插值，允许罕见或新出现的实体被明确地记忆，而不是隐藏在模型参数中。实验结果显示，该方法能够改善链接预测结果并在低资源环境中表现出更好的性能。

    

    以往的知识图嵌入方法通常将实体映射到表示，并利用评分函数预测目标实体，但它们通常难以推理出罕见或新出现的未知实体。在本文中，我们提出了一种新的知识图嵌入方法kNN-KGE，它利用预训练语言模型，并通过线性插值将其实体分布与k个最近邻相结合。我们根据知识存储中实体嵌入空间中的距离计算最近邻。我们的方法可以明确地记忆罕见或新出现的实体，而不是隐藏在模型参数中。实验结果表明，我们的方法可以改善归纳和传递式链接预测结果，并在只有少量三元组的低资源环境中表现出更好的性能，而这可能更容易通过明确的记忆进行推理。

    Previous knowledge graph embedding approaches usually map entities to representations and utilize score functions to predict the target entities, yet they typically struggle to reason rare or emerging unseen entities. In this paper, we propose kNN-KGE, a new knowledge graph embedding approach with pre-trained language models, by linearly interpolating its entity distribution with k-nearest neighbors. We compute the nearest neighbors based on the distance in the entity embedding space from the knowledge store. Our approach can allow rare or emerging entities to be memorized explicitly rather than implicitly in model parameters. Experimental results demonstrate that our approach can improve inductive and transductive link prediction results and yield better performance for low-resource settings with only a few triples, which might be easier to reason via explicit memory. Code is available at https://github.com/zjunlp/KNN-KG.
    
[^106]: 推荐系统的深度探索

    Deep Exploration for Recommendation Systems. (arXiv:2109.12509v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2109.12509](http://arxiv.org/abs/2109.12509)

    本文提出了一种深度探索方法以解决推荐系统中奖励稀少时的问题，并在高保真度的工业级模拟器下进行了实验，证明了该算法相比现有算法有很大的提升。

    

    现代推荐系统应从延迟反馈中探索和学习。过去的研究往往侧重于从用户对单个推荐的响应中学习。这些工作利用了监督学习和强化学习的方法，但放弃了学习用户之后的行为。在过去的工作中，虽然致力于从随后的行为中学习，但缺乏有效的方法来引导并获取有意义的延迟反馈。当奖励较少时，通过引导探索有意义的延迟反馈变得特别具有挑战性。为了解决这个问题，我们为推荐系统开发了深度探索方法。具体而言，我们将推荐系统形式化为一个序列决策问题，并证明了深度探索方法在单步探索方面的优势。我们的实验是在高保真度的工业级模拟器下进行的，并且证明了该算法相比现有算法有很大的提升。

    Modern recommendation systems ought to benefit by probing for and learning from delayed feedback. Research has tended to focus on learning from a user's response to a single recommendation. Such work, which leverages methods of supervised and bandit learning, forgoes learning from the user's subsequent behavior. Where past work has aimed to learn from subsequent behavior, there has been a lack of effective methods for probing to elicit informative delayed feedback. Effective exploration through probing for delayed feedback becomes particularly challenging when rewards are sparse. To address this, we develop deep exploration methods for recommendation systems. In particular, we formulate recommendation as a sequential decision problem and demonstrate benefits of deep exploration over single-step exploration. Our experiments are carried out with high-fidelity industrial-grade simulators and establish large improvements over existing algorithms.
    
[^107]: 从生成的图像中推断生成模型的超参数：生成模型的逆向工程

    Reverse Engineering of Generative Models: Inferring Model Hyperparameters from Generated Images. (arXiv:2106.07873v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2106.07873](http://arxiv.org/abs/2106.07873)

    本研究提出了一种逆向工程生成模型的方法，通过分析生成的图像来推断模型的超参数，以识别和理解生成模型的潜在滥用。通过指纹估计网络和解析网络，我们能够从生成的图像中预测生成模型的网络架构和训练损失函数。

    

    最先进的生成模型能够合成逼真的图像，令人难以区分是真实照片还是生成的图像。识别和理解篡改媒体对于缓解生成模型潜在滥用的社会关切至关重要。我们提出了对生成模型进行逆向工程的方法，从这些模型生成的图像中推断模型的超参数。我们定义了一个新颖的问题，即“模型解析”，通过分析生成的图像来估计生成模型的网络架构和训练损失函数，这对人类而言似乎是不可能的任务。为了解决这个问题，我们提出了一个框架，包括两个组成部分：指纹估计网络（FEN），通过训练带有四个约束的指纹估计网络来估计生成模型的指纹，以鼓励指纹具有期望的特性；解析网络（PN），从估计的指纹中预测网络架构和损失函数。为了评估我们的方法，我们收集了一些生成模型的图像，并对其进行了推断。

    State-of-the-art (SOTA) Generative Models (GMs) can synthesize photo-realistic images that are hard for humans to distinguish from genuine photos. Identifying and understanding manipulated media are crucial to mitigate the social concerns on the potential misuse of GMs. We propose to perform reverse engineering of GMs to infer model hyperparameters from the images generated by these models. We define a novel problem, ``model parsing", as estimating GM network architectures and training loss functions by examining their generated images -- a task seemingly impossible for human beings. To tackle this problem, we propose a framework with two components: a Fingerprint Estimation Network (FEN), which estimates a GM fingerprint from a generated image by training with four constraints to encourage the fingerprint to have desired properties, and a Parsing Network (PN), which predicts network architecture and loss functions from the estimated fingerprints. To evaluate our approach, we collect a
    

