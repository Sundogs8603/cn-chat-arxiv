# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Retro-fallback: retrosynthetic planning in an uncertain world.](http://arxiv.org/abs/2310.09270) | 本文针对逆合成任务在实验室执行可行性的不确定性问题，通过引入随机过程的表述，提出了一种名为 Retro-fallback 的贪婪算法，该算法能够最大化实验室可执行的合成计划的概率。 |
| [^2] | [Table-GPT: Table-tuned GPT for Diverse Table Tasks.](http://arxiv.org/abs/2310.09263) | 本文提出了一种新的"表格调优"范式，通过使用从真实表格中合成的多样化表格任务作为训练数据，对语言模型进行训练/微调，以提高其理解表格和执行表格任务的能力。 |
| [^3] | [It's an Alignment, Not a Trade-off: Revisiting Bias and Variance in Deep Models.](http://arxiv.org/abs/2310.09250) | 在基于深度学习的分类模型集合中，对于正确分类的样本点，偏差和方差在样本级别上是对齐的。 |
| [^4] | [Augmented Computational Design: Methodical Application of Artificial Intelligence in Generative Design.](http://arxiv.org/abs/2310.09243) | 本论文介绍了在生成设计中应用人工智能的方法论反思，探讨了如何通过人工智能来增强决策过程，实现复杂设计空间的映射和导航。 |
| [^5] | [Evaluating Machine Perception of Indigeneity: An Analysis of ChatGPT's Perceptions of Indigenous Roles in Diverse Scenarios.](http://arxiv.org/abs/2310.09237) | 本文调查了ChatGPT等大型语言模型在模拟土著人在不同角色下表现的情境时的自认偏见。研究结果揭示了技术对土著人相关社会偏见的感知和潜在放大，对土著人在重要计算中的影响具有重要意义。 |
| [^6] | [Fast & Efficient Learning of Bayesian Networks from Data: Knowledge Discovery and Causality.](http://arxiv.org/abs/2310.09222) | 本论文提出了两个新算法FSBN和SSBN，它们利用局部搜索和条件独立性测试从数据中学习贝叶斯网络的因果结构。实验结果表明，这两个算法在降低计算成本的同时保持了高质量的归纳，提供了可解释性和适应性。 |
| [^7] | ["Kelly is a Warm Person, Joseph is a Role Model": Gender Biases in LLM-Generated Reference Letters.](http://arxiv.org/abs/2310.09219) | 本文对LLM生成的推荐信中的性别偏见进行了细致的研究，并设计了评估方法来展现通过语言风格和词汇内容来体现的性别偏见。 |
| [^8] | [Multinational AGI Consortium (MAGIC): A Proposal for International Coordination on AI.](http://arxiv.org/abs/2310.09217) | 本文提出了一个跨国人工智能协会（MAGIC），旨在通过全球禁令减轻先进人工智能（AI）对人类存在的风险，同时允许狭义AI模型的发展。 |
| [^9] | [SiamAF: Learning Shared Information from ECG and PPG Signals for Robust Atrial Fibrillation Detection.](http://arxiv.org/abs/2310.09203) | 提出了一种名为SiamAF的新方法，利用心电图和光电脉搏图信号的共享信息，通过Siamese网络和联合学习实现强健的心房颤动（AF）检测。 |
| [^10] | [Tikuna: An Ethereum Blockchain Network Security Monitoring System.](http://arxiv.org/abs/2310.09193) | Tikuna是一个开源工具，用于监测和检测以太坊区块链P2P网络上的潜在攻击。它采用无监督的LSTM方法，通过收集数据和分析网络行为，显著降低了攻击风险。 |
| [^11] | [Does Graph Distillation See Like Vision Dataset Counterpart?.](http://arxiv.org/abs/2310.09192) | 本文研究了图压缩方法中对结构信息的忽视问题，并提出了一种新的结构广播图数据集压缩方案（SGDD），该方案能够保留原始图的结构信息，并在跨架构泛化和特定任务中取得了优秀的性能。 |
| [^12] | [PRIOR: Personalized Prior for Reactivating the Information Overlooked in Federated Learning.](http://arxiv.org/abs/2310.09183) | 本研究提出了一种名为PRIOR的个性化先验方案，用于解决个性化联邦学习中由于全局模型忽视特定信息而导致的不完整信息问题。该方案使用带Bregman散度的PFL框架将个性化先验与本地目标函数解耦，以提高适应性和性能。 |
| [^13] | [mnmDTW: An extension to Dynamic Time Warping for Camera-based Movement Error Localization.](http://arxiv.org/abs/2310.09170) | mnmDTW是一种用于基于摄像头的运动误差定位的动态时间规整拓展方法。通过计算每个身体部位之间的距离，该方法能够更精确地测量运动的准确性，从而清楚地显示、识别和定位运动错误。 |
| [^14] | [Quantum Machine Learning in Climate Change and Sustainability: a Review.](http://arxiv.org/abs/2310.09162) | 量子机器学习在解决气候变化和可持续发展问题方面具有潜力，可以应用于能源系统、气候数据预测、气候监测和危险事件预测等领域。该综述调查了目前将量子机器学习应用于这些问题的现有研究，并讨论了挑战、局限以及潜在机会和未来工作。 |
| [^15] | [Learning To Teach Large Language Models Logical Reasoning.](http://arxiv.org/abs/2310.09158) | 本文通过深入调查和研究，探索了大型语言模型（LLMs）在逻辑推理中的能力，并提出了多种策略来赋予LLMs逻辑推理能力，使其能够生成更具逻辑一致性的答案。 |
| [^16] | [Lincoln AI Computing Survey (LAICS) Update.](http://arxiv.org/abs/2310.09145) | 这篇论文是AI加速器和处理器调查的更新，涵盖过去四年的内容。通过收集并总结目前已公开宣布的商用加速器的性能和功耗数据，并将其绘制在散点图上，从而分析了趋势和市场细分，并包括了新增加的加速器的简要描述。 |
| [^17] | [The Consensus Game: Language Model Generation via Equilibrium Search.](http://arxiv.org/abs/2310.09139) | 这篇论文介绍了一种新的语言模型解码方法，将其视为规范化的不完美信息序列信号博弈，并通过找到近似均衡点得到了一个解码算法。这种方法可以应用于问答和其他文本生成任务中。 |
| [^18] | [HierarchicalContrast: A Coarse-to-Fine Contrastive Learning Framework for Cross-Domain Zero-Shot Slot Filling.](http://arxiv.org/abs/2310.09135) | 本研究提出了一种用于零样本插槽填充的Hierarchical Contrastive Learning Framework (HiCL)，通过粗粒度到细粒度的对比学习，学习语句令牌之间的深层语义关系，并提出了一种新的迭代标签集语义推理方法，来提高在未见插槽上的泛化能力。 |
| [^19] | [Split-and-Denoise: Protect large language model inference with local differential privacy.](http://arxiv.org/abs/2310.09130) | 本文提出了一种名为SnD的创新框架，用于保护大型语言模型推断阶段的隐私。该方法通过在客户端上执行令牌嵌入层和引入噪声来优化隐私-效用权衡，无需修改模型参数。 |
| [^20] | [Timestamp-supervised Wearable-based Activity Segmentation and Recognition with Contrastive Learning and Order-Preserving Optimal Transport.](http://arxiv.org/abs/2310.09114) | 本论文提出了一种基于时间戳监督的可穿戴活动分割和识别方法，通过仅需要每个活动段中的单个注释样本来解决由于稀疏标注导致的识别和分割问题之间的差距。 |
| [^21] | [GLoRE: Evaluating Logical Reasoning of Large Language Models.](http://arxiv.org/abs/2310.09107) | 本论文介绍了GLoRE，一个评估大型语言模型逻辑推理能力的基准，实验结果表明开放式LLM模型的逻辑推理能力需要提高。研究提出了一种自一致性探测方法和微调方法来改进ChatGPT和开放式LLM的性能。 |
| [^22] | [Privacy-Preserving Encrypted Low-Dose CT Denoising.](http://arxiv.org/abs/2310.09101) | 本论文提出了一种隐私保护的加密低剂量CT去噪方法，通过使用同态加密对私有数据进行加密，避免了将数据暴露给服务器的风险，实现了隐私保护的云服务。 |
| [^23] | [Insightful analysis of historical sources at scales beyond human capabilities using unsupervised Machine Learning and XAI.](http://arxiv.org/abs/2310.09091) | 本研究使用创新的机器学习技术对大规模历史文献进行分析，并重点研究了“Sacrobosco Collection”中知识的演变。通过这一研究，我们得出了一些重要的历史洞察。 |
| [^24] | [Dialect Transfer for Swiss German Speech Translation.](http://arxiv.org/abs/2310.09088) | 本文研究了瑞士德语言翻译系统建设中的挑战，着重探讨了方言多样性和瑞士德语与标准德语之间的差异对系统性能的影响。 |
| [^25] | [ImageManip: Image-based Robotic Manipulation with Affordance-guided Next View Selection.](http://arxiv.org/abs/2310.09069) | ImageManip是一个基于图像的机器人操纵框架，通过捕捉目标物体多个视角和推断深度信息，克服了使用三维点云数据进行操控的挑战。 |
| [^26] | [DATT: Deep Adaptive Trajectory Tracking for Quadrotor Control.](http://arxiv.org/abs/2310.09053) | DATT是一种用于四旋翼控制的深度自适应轨迹跟踪方法，能够在现实世界中精确跟踪任意可能不可行的轨迹，并能够在存在大干扰的情况下使用L1自适应控制进行增强，优于竞争方法。 |
| [^27] | [SAI: Solving AI Tasks with Systematic Artificial Intelligence in Communication Network.](http://arxiv.org/abs/2310.09049) | SAI是一个框架，利用大型语言模型和JSON格式的意图输入来解决复杂的人工智能任务，在智能移动网络中具有重要的应用潜力。 |
| [^28] | [KCTS: Knowledge-Constrained Tree Search Decoding with Token-Level Hallucination Detection.](http://arxiv.org/abs/2310.09044) | 提出了一种名为KCTS的知识约束树搜索解码方法，利用知识分类器和MCTS指导冻结的LM生成与参考知识对齐的文本，同时引入了一种新颖的令牌级幻觉检测方法RIPA。 |
| [^29] | [Optimal Scheduling of Electric Vehicle Charging with Deep Reinforcement Learning considering End Users Flexibility.](http://arxiv.org/abs/2310.09040) | 本研究使用深度强化学习方法，针对时间段电价计划，通过优化调度电动车充电过程来降低用户家庭的成本。 |
| [^30] | [Subspace Adaptation Prior for Few-Shot Learning.](http://arxiv.org/abs/2310.09028) | 提出了少样本学习的子空间适应先验算法，通过同时学习初始化参数和参数子空间，可以基于任务分布决定使用梯度下降调整哪些操作子集，从而提高学习效率并降低过拟合风险。 |
| [^31] | [A Spatial-Temporal Dual-Mode Mixed Flow Network for Panoramic Video Salient Object Detection.](http://arxiv.org/abs/2310.09016) | 本文提出了一种名为STDMMF-Net的时空双模混合流网络，用于全景视频显著目标检测。通过设计与应用交叉层注意力模块、交叉层权重模块和双模态注意力模块，该网络能够克服传统2D视频显著目标检测在全景视频中的困难，提高检测准确性和融合效率。 |
| [^32] | [CodeChain: Towards Modular Code Generation Through Chain of Self-revisions with Representative Sub-modules.](http://arxiv.org/abs/2310.08992) | CodeChain是一种通过代表性子模块的自我修订链路引导模块化代码生成的新框架，旨在解决大型语言模型在解决复杂编程任务方面的挑战。 |
| [^33] | [Reroute Prediction Service.](http://arxiv.org/abs/2310.08988) | 该论文介绍了一种新颖的数据分析和机器学习系统，旨在通过积极支持重新规划决策来减少航班延误。该系统使用历史重新规划数据和天气数据预测未来几天是否会发布重新规划建议，以减少影响航线的因素。 |
| [^34] | [Big data-driven prediction of airspace congestion.](http://arxiv.org/abs/2310.08982) | 本文提出了一种基于大数据的航空领域拥堵预测系统，可以准确预测国家空域系统（NAS）内特定空域部门的飞机数量。 |
| [^35] | [Multi-Purpose NLP Chatbot : Design, Methodology & Conclusion.](http://arxiv.org/abs/2310.08977) | 该研究论文主要分析了聊天机器人技术的历史、困难和前景，提出了一种灵活的聊天机器人系统，利用强化学习策略改善用户交互和对话体验，并通过情感分析和自然语言处理来确定用户情绪。 |
| [^36] | [ChatKBQA: A Generate-then-Retrieve Framework for Knowledge Base Question Answering with Fine-tuned Large Language Models.](http://arxiv.org/abs/2310.08975) | ChatKBQA是一个基于精调大型语言模型的生成-检索框架，用于改进知识库问答的效率和准确性，实验结果显示在多个数据集上取得了新的最好表现。 |
| [^37] | [Making Multimodal Generation Easier: When Diffusion Models Meet LLMs.](http://arxiv.org/abs/2310.08949) | EasyGen是一个有效的模型，它通过结合扩散模型和大型语言模型（LLMs）的能力，实现了更容易的多模态生成。相比现有的模型，EasyGen使用了一个名为BiDiffuser的双向条件扩散模型， 提供了更高效的模态交互，并且不仅能够生成文本回复，还能够促进文本到图像的生成。 |
| [^38] | [Federated Class-Incremental Learning with Prompting.](http://arxiv.org/abs/2310.08948) | 本文提出了一种名为FCILPT的方法，用于解决联邦增量学习中的灾难性遗忘问题，该方法能够处理非独立和同分布数据分布情况，并保护数据隐私。 |
| [^39] | [Embarrassingly Simple Text Watermarks.](http://arxiv.org/abs/2310.08920) | 我们提出了一种极其简单但非常有效的文本水印方法Easymark，它可以在不改变文本含义的情况下注入水印，并且能够高度可信地检测出文本是否由采用该方法的系统生成。这种方法不需要访问大型语言模型，并且具有更高的检测准确度和BLEU分数。 |
| [^40] | [Relation-aware Ensemble Learning for Knowledge Graph Embedding.](http://arxiv.org/abs/2310.08917) | 本论文提出了一种关系感知集成学习方法，用于知识图谱嵌入任务，并通过分割搜索合并的算法在搜索关系感知集成权重方面取得了显著性能提升。 |
| [^41] | [Dynamic Sparse No Training: Training-Free Fine-tuning for Sparse LLMs.](http://arxiv.org/abs/2310.08915) | 这篇论文介绍了一种名为动态稀疏无训练的微调方法，可以在不进行昂贵的反向传播和权重更新的情况下更新稀疏的大型语言模型，以此来减小将其部署到设备上时面临的挑战。 |
| [^42] | [Community Membership Hiding as Counterfactual Graph Search via Deep Reinforcement Learning.](http://arxiv.org/abs/2310.08909) | 这项研究通过深度强化学习的方式解决了社区成员隐藏的挑战，通过战略地改变网络图的结构属性，防止节点被社区检测算法识别出来，并验证了方法的有效性。 |
| [^43] | [Welfare Diplomacy: Benchmarking Language Model Cooperation.](http://arxiv.org/abs/2310.08901) | 这项研究提出了福利外交这一通用和变种的零和游戏，目的是衡量和强化语言模型的合作能力，并发现使用最先进模型的基准智能体在达到高社会福利时存在可利用性问题。 |
| [^44] | [A Hybrid Transfer Learning Assisted Decision Support System for Accurate Prediction of Alzheimer Disease.](http://arxiv.org/abs/2310.08888) | 本研究提出了一种混合迁移学习辅助决策支持系统，通过识别四个预测阿尔茨海默病的不同类别，实现了对该疾病的准确预测，加权准确率达到了98.91%。 |
| [^45] | [METRA: Scalable Unsupervised RL with Metric-Aware Abstraction.](http://arxiv.org/abs/2310.08887) | METRA提出了一种新的无监督强化学习目标，旨在使其在复杂的高维环境中可扩展。这个目标解决了纯探索方法在大状态空间环境中的困难以及互信息技能学习方法中缺乏激励而无法探索环境的问题。 |
| [^46] | [Adaptivity and Modularity for Efficient Generalization Over Task Complexity.](http://arxiv.org/abs/2310.08866) | 引入一种新的任务来评估变压器在处理不同难度示例的问题上的泛化能力，并提出使用自适应和模块化计算机制的变压器架构，该架构在泛化到更高数量的计算时显示出更高的准确性和更公平的计算资源分配。 |
| [^47] | [Adam-family Methods with Decoupled Weight Decay in Deep Learning.](http://arxiv.org/abs/2310.08858) | 本文研究了一类广泛的Adam-family方法在训练非光滑神经网络中的收敛性质，提出了一种使用分离权重衰减的新框架，并证明了其收敛性。该框架包含了许多已知的Adam-family方法，并对这些方法在训练非光滑神经网络时提供了收敛性保证。 |
| [^48] | [Path To Gain Functional Transparency In Artificial Intelligence With Meaningful Explainability.](http://arxiv.org/abs/2310.08849) | 本论文提出了一个面向用户的合规设计，用于实现透明系统中的功能透明性，并强调了跨学科合作的重要性。 |
| [^49] | [A Case-Based Persistent Memory for a Large Language Model.](http://arxiv.org/abs/2310.08842) | 本论文讨论了案例推理研究者对深度学习和大型语言模型的忽视，以及将这些技术应用于大型语言模型的持久性记忆中，进一步推动人工通用智能的发展。 |
| [^50] | [Leveraging Optimal Transport for Enhanced Offline Reinforcement Learning in Surgical Robotic Environments.](http://arxiv.org/abs/2310.08841) | 本论文介绍了一种利用最优输运奖励标签的算法，可以在离线情况下分配奖励给轨迹，从而减少对资源密集型实时交互的需求。 |
| [^51] | [Large Language Models as Source Planner for Personalized Knowledge-grounded Dialogue.](http://arxiv.org/abs/2310.08840) | 本研究提出了SAFARI框架，利用大型语言模型作为个性化知识驱动对话系统的源计划器，使得多个知识源的依赖关系能够被整合，并能生成一致的回应。 |
| [^52] | [A Framework for Few-Shot Policy Transfer through Observation Mapping and Behavior Cloning.](http://arxiv.org/abs/2310.08836) | 本文提出了一个通过观察映射和行为克隆进行少样本策略转移的框架，通过使用生成对抗网络和循环一致性损失来映射源领域和目标领域之间的观察，并利用这个映射来克隆源任务的成功策略。 |
| [^53] | [Urban Drone Navigation: Autoencoder Learning Fusion for Aerodynamics.](http://arxiv.org/abs/2310.08830) | 本文提出了一种将多目标强化学习与卷积自动编码器相结合的方法，用于改进城市无人机在紧急搜索和救援中的导航能力。该方法通过利用城市布局图像数据，使无人机能够自主决策导航、优化路径并抵抗风效应，并在复杂的城市环境中提高了救援操作。 |
| [^54] | [Distance-rank Aware Sequential Reward Learning for Inverse Reinforcement Learning with Sub-optimal Demonstrations.](http://arxiv.org/abs/2310.08823) | 提出了Distance-rank感知顺序奖励学习（DRASRL）框架，旨在解决逆强化学习中轨迹排名模糊和奖励模糊的问题。 |
| [^55] | [Exploring the relationship between response time sequence in scale answering process and severity of insomnia: a machine learning approach.](http://arxiv.org/abs/2310.08817) | 该研究发现量表答题过程中的反应时间与失眠严重程度之间存在关系，并开发了一种机器学习模型，可以根据反应时间数据预测参与者是否存在失眠。 |
| [^56] | [DexCatch: Learning to Catch Arbitrary Objects with Dexterous Hands.](http://arxiv.org/abs/2310.08809) | 本论文提出了一种稳定约束强化学习算法（SCRL），用于学习用灵巧的手捕捉多样化的物体。该算法在基线方法上取得了很大的优势，并且在未见过的物体上表现出了强大的零-shot迁移性能。 |
| [^57] | [Advancing Perception in Artificial Intelligence through Principles of Cognitive Science.](http://arxiv.org/abs/2310.08803) | 通过研究认知科学，我们可以提供新的视角来改善人工智能的性能和效率，本篇综述研究主要关注感知的认知功能，通过比较认知科学和人工智能的各个过程，回顾了各个子学科的主要理论。 |
| [^58] | [DDMT: Denoising Diffusion Mask Transformer Models for Multivariate Time Series Anomaly Detection.](http://arxiv.org/abs/2310.08800) | 本论文提出了一种名为DDMT的新框架，用于解决多变量时间序列异常检测中的噪声和弱身份映射问题。通过引入自适应动态邻居掩膜机制(ADNM)以及集成Transformer和去噪扩散模型，该框架可以有效地检测时间序列数据中的异常情况。 |
| [^59] | [A Comparative Analysis of Task-Agnostic Distillation Methods for Compressing Transformer Language Models.](http://arxiv.org/abs/2310.08797) | 本研究比较了用于压缩Transformer语言模型的几种任务不可知蒸馏方法，并发现基于MiniLMv2的MHA转移是最佳选择。 |
| [^60] | [Mitigating Bias for Question Answering Models by Tracking Bias Influence.](http://arxiv.org/abs/2310.08795) | 本论文提出了一种名为BMBI的方法来减轻多选问题回答模型的偏见。通过观察一个查询实例对另一个实例的影响，测量查询实例的偏见程度，并将其作为优化目标，形成一个多任务学习设置。同时引入新的偏见评估指标以量化偏见。 |
| [^61] | [Price of Stability in Quality-Aware Federated Learning.](http://arxiv.org/abs/2310.08790) | 本论文提出了一种质量感知的联邦学习方案，研究了标签噪声对系统性能的影响，并设计了一种游戏模型来理解客户端的行为。研究结果表明均衡结果的全局模型准确度低于社会最优解，并提出了一种高效算法来计算。 |
| [^62] | [DeltaSpace: A Semantic-aligned Feature Space for Flexible Text-guided Image Editing.](http://arxiv.org/abs/2310.08785) | 本文提出了一种名为DeltaSpace的特征空间，用于灵活文本引导图像编辑。在DeltaSpace的基础上，通过一种称为DeltaEdit的新颖框架，将CLIP视觉特征差异映射到潜在空间方向，并从CLIP预测潜在空间方向，解决了训练和推理灵活性的挑战。 |
| [^63] | [Selectivity Drives Productivity: Efficient Dataset Pruning for Enhanced Transfer Learning.](http://arxiv.org/abs/2310.08782) | 本论文提出了一种解决迁移学习中数据集修剪的方法，通过集成数据集修剪和迁移学习的观点，发现现有的方法不适用于迁移学习范式，并提出了标签映射和特征映射这两种新的数据集修剪方法。 |
| [^64] | ["Im not Racist but...": Discovering Bias in the Internal Knowledge of Large Language Models.](http://arxiv.org/abs/2310.08780) | 本文介绍了一种纯提示式的方法，用于揭示大型语言模型中隐藏的刻板印象，通过动态生成内部刻板印象的知识表示，我们能够识别这些模型中存在的偏见。这项工作在推进透明度和促进自然语言处理系统的公平性方面做出了贡献。 |
| [^65] | [Examining the Potential and Pitfalls of ChatGPT in Science and Engineering Problem-Solving.](http://arxiv.org/abs/2310.08773) | ChatGPT被用于解决物理问题，发现在解决明确规定的问题时准确率较高，但在解决未明确规定的问题时准确率较低。错误解的分析揭示了三种失败模式，并探讨了如何利用LLM增强的教材提升STEM教育。这些观察结果对于AI的优势和局限性也有贡献。 |
| [^66] | [Stabilizing Subject Transfer in EEG Classification with Divergence Estimation.](http://arxiv.org/abs/2310.08762) | 本研究在EEG分类中使用新的正则化技术减少了在未见测试对象上的性能下降。通过设计正则化惩罚和发散估计算法，我们成功地在模型训练中强制执行了统计关系，并在大量计算实验中验证了我们的方法的有效性。 |
| [^67] | [CompA: Addressing the Gap in Compositional Reasoning in Audio-Language Models.](http://arxiv.org/abs/2310.08753) | CompA提出了由两个专家注释的音频-语言模型组合推理基准数据集，用于评估ALMs在理解音频中声音事件的顺序和属性绑定方面的表现。 |
| [^68] | [Constrained Bayesian Optimization with Adaptive Active Learning of Unknown Constraints.](http://arxiv.org/abs/2310.08751) | 本文探讨了约束贝叶斯优化的理论和实际问题，提出了一种带有自适应主动学习未知约束的方法，在处理复杂约束场景时具有理论保证。 |
| [^69] | [Development and Validation of a Deep Learning-Based Microsatellite Instability Predictor from Prostate Cancer Whole-Slide Images.](http://arxiv.org/abs/2310.08743) | 本研究开发和验证了一种基于深度学习的微卫星不稳定性预测器，可以从前列腺癌全切片图像中预测MSI状态，有助于识别最有可能受益于免疫治疗的患者。 |
| [^70] | [Real-Time Event Detection with Random Forests and Temporal Convolutional Networks for More Sustainable Petroleum Industry.](http://arxiv.org/abs/2310.08737) | 通过随机森林和时态卷积网络，本论文提出了一种实时检测不希望事件的方法，可以有效地分类事件类型并预测其出现的概率，为生产过程中的故障事件管理提供更有效的解决方案。 |
| [^71] | [A Simple Way to Incorporate Novelty Detection in World Models.](http://arxiv.org/abs/2310.08731) | 本文提出了一个简单的方法，通过利用世界模型幻觉状态和真实观察状态的不匹配性作为异常分数，将新颖性检测纳入世界模型强化学习代理中。在新环境中与传统方法相比，我们的工作具有优势。 |
| [^72] | [Transformer Choice Net: A Transformer Neural Network for Choice Prediction.](http://arxiv.org/abs/2310.08716) | 本论文介绍了一种适用于预测多个选择的Transformer神经网络架构，通过考虑顾客和项目的特征，以及上下文信息（如可选项的范围和定制需求），解决了离散选择模型在顾客选择多个项目时的挑战。 |
| [^73] | [Toward Joint Language Modeling for Speech Units and Text.](http://arxiv.org/abs/2310.08715) | 本文研究了联合语言建模中语音单元和文本的混合方法，并通过口语理解任务评估了模型的性能，结果表明混合语言模型优于仅使用语音的基线模型。 |
| [^74] | [ELDEN: Exploration via Local Dependencies.](http://arxiv.org/abs/2310.08702) | 在具有复杂依赖关系的环境中，我们提出了ELDEN，一种新的内在奖励，通过使用代理对实体之间的相互影响的不确定性，鼓励有效地探索状态空间。 |
| [^75] | [Virtual Augmented Reality for Atari Reinforcement Learning.](http://arxiv.org/abs/2310.08683) | 本文研究了使用最先进的图像分割模型提高Atari强化学习智能体性能的方法 |
| [^76] | [Can GPT models be Financial Analysts? An Evaluation of ChatGPT and GPT-4 on mock CFA Exams.](http://arxiv.org/abs/2310.08678) | 本研究评估了ChatGPT和GPT-4在金融分析上的能力，发现它们在模拟CFA考试中具有一定的表现，为将来进一步提升大型语言模型在金融推理方面的能力提供了启示。 |
| [^77] | [GDL-DS: A Benchmark for Geometric Deep Learning under Distribution Shifts.](http://arxiv.org/abs/2310.08677) | GDL-DS是一个基准测试，用于评估几何深度学习模型在具有分布转换的场景中的性能。它包括多个科学领域的评估数据集，并研究了不同级别的超出分布特征的信息访问。 |
| [^78] | [Learning RL-Policies for Joint Beamforming Without Exploration: A Batch Constrained Off-Policy Approach.](http://arxiv.org/abs/2310.08660) | 本研究提出了一种批量约束的离策略方法，用于解决联合波束成形的参数优化问题。通过使用深度强化学习技术，克服了传统方法中计算复杂度高和无法准确建模的难题。 |
| [^79] | [LoftQ: LoRA-Fine-Tuning-Aware Quantization for Large Language Models.](http://arxiv.org/abs/2310.08659) | 本论文提出了LoftQ：一种针对大型语言模型的LoRA精调感知量化框架。该框架同时对LLM进行量化，并为LoRA精调找到适当的低秩初始化，以缓解量化模型和全精度模型之间的差异，并显著提高了下游任务的泛化能力。 |
| [^80] | [Analyzing Textual Data for Fatality Classification in Afghanistan's Armed Conflicts: A BERT Approach.](http://arxiv.org/abs/2310.08653) | 这项研究利用BERT模型分析阿富汗武装冲突的文本数据，通过对事件的描述进行分类，判断其是否致命。模型在测试中表现出色。 |
| [^81] | [Electrical Grid Anomaly Detection via Tensor Decomposition.](http://arxiv.org/abs/2310.08650) | 本论文提出了一种通过非负张量分解实现电网异常检测的方法。与之前的降维方法不同，该方法能够更准确地对SCADA系统进行建模，并检测出其中的异常行为。 |
| [^82] | [A Mass-Conserving-Perceptron for Machine Learning-Based Modeling of Geoscientific Systems.](http://arxiv.org/abs/2310.08644) | 这篇论文提出了一种质量保持感知器（MCP）用于将物理-概念模型和机器学习模型结合起来建模地球科学系统，通过利用机器学习技术从数据中学习物理过程的功能性和质量保持性。 |
| [^83] | [The Impact of Explanations on Fairness in Human-AI Decision-Making: Protected vs Proxy Features.](http://arxiv.org/abs/2310.08617) | 论文研究了解释对AI决策公平性的影响。结果发现，解释有助于人们检测直接偏见，但对间接偏见的发现能力有限。 |
| [^84] | [Safe Deep Policy Adaptation.](http://arxiv.org/abs/2310.08602) | 该论文提出了SafeDPA，一种新颖的强化学习和控制框架，用于同时解决策略适应和安全强化学习的问题。SafeDPA在仿真环境中联合学习自适应策略和动力学模型，并使用少量真实数据进行微调。在真实世界部署过程中，通过引入基于控制屏障函数的安全过滤器，确保了SafeDPA的安全性。 |
| [^85] | [Domain Generalization for Medical Image Analysis: A Survey.](http://arxiv.org/abs/2310.08598) | 本综述详细回顾了针对医学图像分析的领域泛化研究，探讨了在DL模型在真实世界应用中遇到的挑战，以及如何解决分布漂移问题和实现稳健性。同时，考虑了领域泛化技术对整个MedIA工作流程的操作影响。 |
| [^86] | [Deep Reinforcement Learning for Autonomous Vehicle Intersection Navigation.](http://arxiv.org/abs/2310.08595) | 本研究通过使用基于TD3算法的单智能体方法，在CARLA模拟平台中展示了在复杂T型路口导航中稳定收敛和改进安全性能，并在行程延误、碰撞减少和总体成本等方面优于先前的方法。 |
| [^87] | [Can We Edit Multimodal Large Language Models?.](http://arxiv.org/abs/2310.08475) | 本文提出了编辑多模式大型语言模型（MLLMs）的挑战，并构建了一个新的基准用于评估和比较不同编辑方法的效果。实验结果表明，编辑多模式LLMs仍然存在困难，但这项工作为NLP社区提供了宝贵的见解。 |
| [^88] | [Effects of Human Adversarial and Affable Samples on BERT Generalizability.](http://arxiv.org/abs/2310.08008) | 本研究研究了对BERT模型的广义性影响，发现在固定大小的训练样本上，有10-30\%的人为对抗实例可以显著提高文本分类和关系抽取任务的精度和F1值。 |
| [^89] | [Synthetic Data Generation with Large Language Models for Text Classification: Potential and Limitations.](http://arxiv.org/abs/2310.07849) | 本研究旨在探讨使用大型语言模型生成合成数据在文本分类模型训练中的潜力和限制。研究结果发现，主观性会负面影响模型在合成数据上的性能。这对于理解和利用合成数据的有效性具有重要的启示作用。 |
| [^90] | [Generative Modeling with Phase Stochastic Bridges.](http://arxiv.org/abs/2310.07805) | 通过在相位空间中构建路径测度，我们提出了一种新颖的生成建模框架，可以在动力传播的早期阶段生成逼真的数据点，并利用额外的速度信息实现高效的数据生成。 |
| [^91] | [Mini-DALLE3: Interactive Text to Image by Prompting Large Language Models.](http://arxiv.org/abs/2310.07653) | 这里是中文总结出的一句话要点：在本论文中，通过引入交互式文本生成图像（iT2I）的新任务，提出了Mini-DALLE3模型，通过与大型语言模型的交互，用户可以实现更好质量的图像生成、编辑和优化。 |
| [^92] | [Linear Latent World Models in Simple Transformers: A Case Study on Othello-GPT.](http://arxiv.org/abs/2310.07582) | 本研究通过案例研究奥赛罗-GPT，发现其具有线性表示对立棋子的世界模型，并揭示了线性世界表示和因果决策之间的相互作用及其与层深度和模型复杂度的依赖关系。 |
| [^93] | [Target-oriented Proactive Dialogue Systems with Personalization: Problem Formulation and Dataset Curation.](http://arxiv.org/abs/2310.07397) | 这项工作提出了一个自动数据集筛选框架，并构建了一个大规模的个性化面向目标对话数据集，名为TopDial。该数据集质量高，有助于探索个性化目标导向的对话。 |
| [^94] | [On the Impact of Cross-Domain Data on German Language Models.](http://arxiv.org/abs/2310.07321) | 本研究通过对德语语言模型进行实验，发现将数据多样性置于数据质量之上的交叉领域数据集训练方法，可以显著提高模型的性能，并超过了之前的最先进模型。 |
| [^95] | [State of the Art on Diffusion Models for Visual Computing.](http://arxiv.org/abs/2310.07204) | 这篇论文旨在介绍最新的视觉计算领域中扩散模型的发展和应用，涵盖了生成人工智能的核心概念和实现细节，并总结了个人化、条件约束和反演等重要方面。 |
| [^96] | [Sparse Finetuning for Inference Acceleration of Large Language Models.](http://arxiv.org/abs/2310.06927) | 本论文研究了大型语言模型的准确稀疏微调问题，提出了基于L2范数的蒸馏方法SquareHead，可以在高稀疏性下实现准确的恢复；同时展示了稀疏语言模型的实际效率，可在CPU和GPU运行时实现加速，并且观察到在受内存限制的模型中，稀疏性也可用于减少内存带宽。 |
| [^97] | [DANet: Enhancing Small Object Detection through an Efficient Deformable Attention Network.](http://arxiv.org/abs/2310.05768) | 通过结合Faster R-CNN与特征金字塔网络、使用可变形网络以及引入卷积块注意力模块等方法，我们提出的DANet模型能够高效准确地检测制造业环境中的小物体，包括微小且复杂的特征。 |
| [^98] | [ViTs are Everywhere: A Comprehensive Study Showcasing Vision Transformers in Different Domain.](http://arxiv.org/abs/2310.05664) | 这项综合研究展示了视觉Transformer在不同领域中的应用，通过与卷积神经网络的比较，证明了其在视觉问题上的优越性和潜力。 |
| [^99] | [Universal Multi-modal Entity Alignment via Iteratively Fusing Modality Similarity Paths.](http://arxiv.org/abs/2310.05364) | 本研究提出了一种通过迭代融合模态相似路径实现通用的多模态实体对齐方法。通过统一建模和有效信息融合，解决了现有方法中模态建模不一致和低效以及模态融合效果不佳的问题。 |
| [^100] | [Are Personalized Stochastic Parrots More Dangerous? Evaluating Persona Biases in Dialogue Systems.](http://arxiv.org/abs/2310.05280) | 这项研究评估了对话系统中的人格偏见对社交偏见的影响，并建立了一个综合评估框架来衡量不同人格采用下的偏见程度。 |
| [^101] | [Text2NKG: Fine-Grained N-ary Relation Extraction for N-ary relational Knowledge Graph Construction.](http://arxiv.org/abs/2310.05185) | Text2NKG是一种用于构建N元关系知识图的细粒度N元关系抽取框架，支持多种NKG模式，具有高灵活性和实用性。 |
| [^102] | [Label-free Node Classification on Graphs with Large Language Models (LLMS).](http://arxiv.org/abs/2310.04668) | 本文介绍了一种使用大型语言模型（LLMs）对图中节点进行无标签分类的方法，即LLM-GNN。它利用LLMs对一小部分节点进行注释，然后通过对LLMs的注释进行训练，使得GNN能够对其余大部分节点进行预测。这种方法充分发挥了GNNs和LLMs的优势，同时解决了它们在处理结构化数据方面的限制。 |
| [^103] | [Human Mobility Question Answering (Vision Paper).](http://arxiv.org/abs/2310.04443) | 本文提出了一项新的任务，即人类移动问题回答（MobQA），旨在让智能系统从移动数据中学习并回答相关问题，填补了关于利用人类移动数据进行问题回答系统的研究空白，并为移动推荐系统的研究带来了新的范式变革。 |
| [^104] | [SmoothLLM: Defending Large Language Models Against Jailbreaking Attacks.](http://arxiv.org/abs/2310.03684) | SmoothLLM是第一个用于减轻大型语言模型上越狱攻击的算法，通过在输入提示上随机扰动并汇总预测结果来检测对抗性输入，将攻击成功率降低至不到一个百分点，并提供了可证明的保证。 |
| [^105] | [LanguageMPC: Large Language Models as Decision Makers for Autonomous Driving.](http://arxiv.org/abs/2310.03026) | 本文研究将大型语言模型（LLMs）作为复杂自动驾驶场景的决策组件，通过认知路径和算法来实现全面推理和可执行驾驶指令的转化。实验证明，LLMs能够在单车任务和复杂驾驶行为中表现出优越性能，这是因为其具有常识推理能力。 |
| [^106] | [A UMLS-Augmented Framework for Improving Factuality in Large Language Models within Healthcare.](http://arxiv.org/abs/2310.02778) | 该论文提出了一个基于UMLS的增强型大型语言模型框架，旨在改善医疗保健领域中模型生成内容的事实性。通过自动评估和医生评估，研究人员验证了该框架的有效性。 |
| [^107] | [MagicDrive: Street View Generation with Diverse 3D Geometry Control.](http://arxiv.org/abs/2310.02601) | MagicDrive是一个新颖的街景生成框架，通过提供多样化的三维几何控制，包括相机姿态、道路地图和三维边界框，以及文本描述，实现了高保真度的街景合成，并捕捉了细致的三维几何信息。 |
| [^108] | [Towards End-to-End Embodied Decision Making via Multi-modal Large Language Model: Explorations with GPT4-Vision and Beyond.](http://arxiv.org/abs/2310.02071) | 本研究通过探索多模态大型语言模型在代理的具身决策中的应用潜力，提出了一个新的评估基准PCA-EVAL，并引入了一个多代理协作框架HOLMES，以提高决策能力。研究发现GPT4-Vision模型在端到端的具身决策中表现最佳。 |
| [^109] | [Human-AI Interactions and Societal Pitfalls.](http://arxiv.org/abs/2309.10448) | 本研究研究了人工智能与人类互动中面临的同质化和偏见问题，提出了改善人工智能与人类互动的解决办法，实现个性化输出而不牺牲生产力。 |
| [^110] | [Answering Layer 3 queries with DiscoSCMs.](http://arxiv.org/abs/2309.09323) | 本文介绍了DiscoSCMs，一种用于解决因果查询的模型。它通过扩展结构因果模型和潜在结果框架来解决一致性规则引发的退化问题，并在分析个性化激励场景中的潜在结果时展示了其有效性。通过引入独立潜在噪声条件，可以提高解决Layer 3查询的准确性和可解释性。 |
| [^111] | [MusiLingo: Bridging Music and Text with Pre-trained Language Models for Music Captioning and Query Response.](http://arxiv.org/abs/2309.08730) | MusiLingo是一个利用预训练的语言模型将音乐和文本相结合的系统，可以生成音乐字幕和回答音乐相关的查询。通过使用投影层对齐音乐表示，该系统成功地将音乐音频和文本环境联系起来，同时使用了一个新的数据集来推动领域的进展。 |
| [^112] | [Efficient Reinforcement Learning for Jumping Monopods.](http://arxiv.org/abs/2309.07038) | 本论文研究了如何通过在强化学习框架中注入物理知识来解决跳跃式单脚机器人的控制问题，这样可以大幅减少学习时间并且能够学习和修正可能出现的错误。 |
| [^113] | [Pure Monte Carlo Counterfactual Regret Minimization.](http://arxiv.org/abs/2309.03084) | 纯蒙特卡洛反事实遗憾最小化算法（PCFR）是一种结合了反事实遗憾最小化（CFR）和虚拟游戏（FP）概念的新算法，能够与各种CFR变体相结合，包括蒙特卡洛CFR（MCCFR）。PCFR具有更好的性能和较快的收敛速度，同时降低了时间和空间复杂度。 |
| [^114] | [ReLLa: Retrieval-enhanced Large Language Models for Lifelong Sequential Behavior Comprehension in Recommendation.](http://arxiv.org/abs/2308.11131) | 本论文提出了一种名为ReLLa的检索增强大型语言模型框架，用于零样本和小样本推荐任务。通过语义用户行为检索（SUBR）来提取上下文中的有用信息，以改善LLMs的推荐性能。 |
| [^115] | [MM-Vet: Evaluating Large Multimodal Models for Integrated Capabilities.](http://arxiv.org/abs/2308.02490) | MM-Vet是一个评估标准，用于评估大型多模态模型在复杂任务上的综合能力。该标准解决了如何结构化和评估复杂多模态任务、设计适用于不同问题和回答类型的评估指标以及如何提供模型洞察的问题。通过整合不同的核心视觉-语言能力，MM-Vet展示了有趣的能力和解决复杂任务的方法。 |
| [^116] | [AutoML4ETC: Automated Neural Architecture Search for Real-World Encrypted Traffic Classification.](http://arxiv.org/abs/2308.02182) | AutoML4ETC是一个自动设计高效且高性能神经架构的工具，用于加密流量分类。其通过定义新颖的搜索空间和使用不同的搜索策略，在多个数据集上优于当前最先进的加密流量分类器。 |
| [^117] | [On the learning Dynamics of Attention Networks.](http://arxiv.org/abs/2307.13421) | 本研究分析了软注意力、硬注意力和潜变量边际似然（LVML）注意力三种注意力模型的学习动态，发现了它们在所选择的片段聚合方式上的显著差异，并解释了分类模型在梯度下降下的演化对最终结果的影响。 |
| [^118] | [Espaloma-0.3.0: Machine-learned molecular mechanics force field for the simulation of protein-ligand systems and beyond.](http://arxiv.org/abs/2307.07085) | Espaloma-0.3.0是一个用于蛋白质-配体系统模拟的机器学习分子力学力场，通过能量和力的拟合纳入量子化学数据进行训练，具有灵活性和可扩展性。 |
| [^119] | [Evade ChatGPT Detectors via A Single Space.](http://arxiv.org/abs/2307.02599) | 本研究发现，当前的ChatGPT检测器不能有效区分人类生成和AI生成内容之间的差异，而一个额外的空格成为了规避检测的关键因素。 |
| [^120] | [Graph Neural Networks based Log Anomaly Detection and Explanation.](http://arxiv.org/abs/2307.00527) | 提出了一种基于图神经网络的无监督日志异常检测方法，该方法将事件日志转换为带属性、有向和加权的图，并利用图神经网络进行图级别的异常检测。引入了一种新的图神经网络模型OCDiGCN来检测一组带属性、有向和加权的图中的图级别异常，并提供对异常的解释能力。 |
| [^121] | [Precursor-of-Anomaly Detection for Irregular Time Series.](http://arxiv.org/abs/2306.15489) | 本文提出了一种新型异常检测方法，称为前体-异常检测（PoA检测）。与传统的异常检测不同，PoA检测旨在在异常发生之前检测到未来的异常。通过使用基于神经控制微分方程的神经网络和多任务学习算法，我们在17个基准线和3个数据集上进行实验证明了我们的方法的有效性。 |
| [^122] | [SIMF: Semantics-aware Interactive Motion Forecasting for Autonomous Driving.](http://arxiv.org/abs/2306.14941) | 本文提出了一种名为SIMF的方法，用于自动驾驶车辆中语义感知的交互式运动预测。该方法通过实现基于语义的行为体选择和注意力机制提取全局编码，能够捕捉空间信息和语义信息，并优选相关的行为体进行运动预测。 |
| [^123] | [A physics-informed AI method for calculating melting points with uncertainty control and optimal sampling.](http://arxiv.org/abs/2306.13345) | 本文提出了一种基于物理学知识和人工智能的计算熔点的方法，并演示了如何增强其准确性和控制不确定性。 |
| [^124] | [A Universal Semantic-Geometric Representation for Robotic Manipulation.](http://arxiv.org/abs/2306.10474) | 这篇论文提出了一种通用的机器人感知模块，称为语义几何表示（SGR），该模块结合了大规模预训练的2D模型的丰富语义信息和3D空间推理的优势，能够在各种模拟和真实世界的机器人操纵任务中胜过最先进的方法。 |
| [^125] | [Time Series Continuous Modeling for Imputation and Forecasting with Implicit Neural Representations.](http://arxiv.org/abs/2306.05880) | 该论文提出了基于INR的时间序列连续建模方法，解决了处理缺失数据、不规则采样和多传感器不对准观测等重复建模问题，并在预测和插值任务中取得了最新的性能表现，具有很好的泛化能力。 |
| [^126] | [Seizing Serendipity: Exploiting the Value of Past Success in Off-Policy Actor-Critic.](http://arxiv.org/abs/2306.02865) | 该论文提出了 BEE 操作符，通过充分利用过去的成功经验，并保持探索乐观性，解决了离线策略演员-评论家中 Q 值高估与低估问题，提高了策略学习和样本效率。 |
| [^127] | [Language-Conditioned Imitation Learning with Base Skill Priors under Unstructured Data.](http://arxiv.org/abs/2305.19075) | 本文提出了一种结合基础技能先验和模仿学习的基于语言条件的通用方法，在非结构化数据下，以增强算法在适应不熟悉的环境方面的泛化能力。在零-shot设置下，在模拟和真实环境中测试，提高了CALVIN基准测试的得分。 |
| [^128] | [Bottleneck Structure in Learned Features: Low-Dimension vs Regularity Tradeoff.](http://arxiv.org/abs/2305.19008) | 本研究揭示了深度学习神经网路学习输入低维度表示和最小化特征映射中的复杂性/不规则性之间的权衡，控制了规律性，并利用理论工具证明了瓶颈结构的存在。 |
| [^129] | [The student becomes the master: Matching GPT3 on Scientific Factual Error Correction.](http://arxiv.org/abs/2305.14707) | 本文提出了一种不需要验证者且不做领域假设的主张校正系统，能够显著提高科学事实错误校正任务的性能，并通过使用LLM的提示方法和主张感知的解码过程来提高校正质量。 |
| [^130] | [Biomedical Named Entity Recognition via Dictionary-based Synonym Generalization.](http://arxiv.org/abs/2305.13066) | 本研究提出了一种基于词典的方法来解决生物医学命名实体识别中的同义词泛化问题，通过引入同义词距离和噪声扰动正则化项，实现了对输入文本中的生物医学概念的识别。 |
| [^131] | [Affective Reasoning at Utterance Level in Conversations: A Causal Discovery Approach.](http://arxiv.org/abs/2305.02615) | 本文提出了一种新的会话情感因果发现方法（CACD），并通过设计公共骨架和生成替代隐含原因解决了因果模型的不确定性和隐含原因的不可观察性的问题。这种方法可以在变长会话中发现因果关系。 |
| [^132] | [ReelFramer: Co-creating News Reels on Social Media with Generative AI.](http://arxiv.org/abs/2304.09653) | ReelFramer使用生成式人工智能与社交媒体共同创作新闻片段。它可以帮助记者探索一个故事的多种叙事框架，并生成脚本、角色板和故事板。用户研究发现该系统大大减轻了将一篇书面报道转化为新闻片段的负担。 |
| [^133] | [A New Policy Iteration Algorithm For Reinforcement Learning in Zero-Sum Markov Games.](http://arxiv.org/abs/2303.09716) | 本文提出了一种适用于零和马尔可夫博弈的简单但有效的策略迭代算法。 |
| [^134] | [Kernel Density Bayesian Inverse Reinforcement Learning.](http://arxiv.org/abs/2303.06827) | KD-BIRL是一种核密度贝叶斯逆强化学习方法，通过直接逼近似然函数来学习代理的奖励函数，克服了学习点估计的缺点，并适用于复杂和无限环境。 |
| [^135] | [Can ChatGPT Assess Human Personalities? A General Evaluation Framework.](http://arxiv.org/abs/2303.01248) | 本文提出了一个通用的评估框架，用于通过LLMs基于MBTI测试评估人类个性。该框架通过设计无偏倚的提示、灵活查询和正确性评估的方式，使LLMs能够灵活评估不同群体的个性特点。 |
| [^136] | [Orca: A Few-shot Benchmark for Chinese Conversational Machine Reading Comprehension.](http://arxiv.org/abs/2302.13619) | Orca是中文对话机器阅读理解的第一个基准，提供了零样本/少样本设置来评估模型对多样领域的泛化能力，并通过提供与回答相关的段落来更合理地评估模型的理解能力。 |
| [^137] | [Modularity-based approach for tracking communities in dynamic social networks.](http://arxiv.org/abs/2302.12759) | 本文引入了一个基于模块化的框架，用于跟踪动态社交网络中的社区，通过识别每个社区的一系列重要事件，无需预定义阈值，从而实现更准确、更鲁棒的跟踪。 |
| [^138] | [Knowledge is a Region in Weight Space for Fine-tuned Language Models.](http://arxiv.org/abs/2302.04863) | 研究探讨了不同模型在权重空间中的位置与性能的关联，发现微调语言模型在权重空间中有明确定义的区域，且这些区域中的模型表现出高性能。此外，通过绕过这些区域，可以得到性能相当甚至更好的新模型。 |
| [^139] | [Domain Adaptation via Alignment of Operation Profile for Remaining Useful Lifetime Prediction.](http://arxiv.org/abs/2302.01704) | 该论文提出了两种基于对不同操作剖面的不同阶段进行考虑的对抗性领域自适应框架的剩余寿命预测的方法。 |
| [^140] | [Open-World Multi-Task Control Through Goal-Aware Representation Learning and Adaptive Horizon Prediction.](http://arxiv.org/abs/2301.10034) | 该论文提出了一种解决多任务控制中面临的开放世界挑战的新方法，即通过Goal-Sensitive Backbone鼓励出现与目标相关的视觉状态表示，并通过自适应视野预测模块来减轻非静态动态引起的学习不确定性。 |
| [^141] | [Smart tutor to provide feedback in programming courses.](http://arxiv.org/abs/2301.09918) | 这项研究通过开发一种基于AI的智能导师，用于回答学生的编程问题，并提供准确和有帮助的答案。 |
| [^142] | [Learning from Guided Play: Improving Exploration for Adversarial Imitation Learning with Simple Auxiliary Tasks.](http://arxiv.org/abs/2301.00051) | 本研究提出了从引导式游戏学习（LfGP）的框架，通过引入多个辅助任务和主任务的专家演示，提升对抗性模仿学习（AIL）中的探索能力，并解决了传统AIL在学习操作任务时可能陷入次优解的问题。 |
| [^143] | [Visual Dexterity: In-hand Dexterous Manipulation from Depth.](http://arxiv.org/abs/2211.11744) | 通过使用深度相机的读数，我们提出了一种通用物体重新定向控制器，可以实时、动态地重新定向复杂和新颖的物体形状，中位数重新定向时间接近于七秒。该控制器经过强化学习在仿真环境中训练，并在实际世界中对未用于训练的新物体形状进行了评估。 |
| [^144] | [ViNL: Visual Navigation and Locomotion Over Obstacles.](http://arxiv.org/abs/2210.14791) | ViNL是通过视觉导航和足球术在未知室内环境中实现机器人导航和足球术运动的方法。它包括无模型的视觉导航策略和视觉运动策略，通过端到端训练实现，并能够避免踩到小障碍物。ViNL能够实现高效且稳定的导航和足球术运动，无需环境先验知识。 |
| [^145] | [A Generalist Framework for Panoptic Segmentation of Images and Videos.](http://arxiv.org/abs/2210.06366) | 这个论文提出了一个通用框架，用于图像和视频的全景分割。他们将全景分割问题定义为离散数据生成问题，并提出了一个简单的扩散模型来建模全景掩码。他们的方法能够在流式设置中建模视频，并自动学习跟踪对象实例，并在实验中展现出与最先进的专家方法竞争的能力。 |
| [^146] | [Efficiently Enhancing Zero-Shot Performance of Instruction Following Model via Retrieval of Soft Prompt.](http://arxiv.org/abs/2210.03029) | 通过检索软提示有效辅助硬提示，在增加少量参数的情况下提高了指令跟随模型在零样本任务上的表现效率。 |
| [^147] | [Benchmarking Augmentation Methods for Learning Robust Navigation Agents: the Winning Entry of the 2021 iGibson Challenge.](http://arxiv.org/abs/2109.10493) | 本研究基于2021年iGibson挑战赛的获胜参赛作品，旨在评估不同的增强技术对智能体在动态环境中的性能改进效果。研究表明，在训练过程中添加动态障碍物可以显著提高测试时的泛化能力，并且与图像增强技术相结合可以进一步提高成功率。此外，该方法对模拟器之间的迁移也更加鲁棒。 |
| [^148] | [Success Weighted by Completion Time: A Dynamics-Aware Evaluation Criteria for Embodied Navigation.](http://arxiv.org/abs/2103.08022) | 我们提出了一种以完成时间为权重的成功度量（SCT），用于评估移动机器人导航性能，并设计了针对单轮小车动态模型的算法RRT*-Unicycle。该指标可以准确衡量代理模拟最快导航行为的程度。 |
| [^149] | [Stylized innovation: generating timelines by interrogating incrementally available randomised dictionaries.](http://arxiv.org/abs/1806.07722) | 该论文通过设计和生成合成创新网络词典，研究了新符号发现在增加词汇的过程中的表现，并探讨了创新过程的整体统计和行为。 |

# 详细

[^1]: Retro-fallback: 面向不确定世界的逆合成规划

    Retro-fallback: retrosynthetic planning in an uncertain world. (arXiv:2310.09270v1 [cs.AI])

    [http://arxiv.org/abs/2310.09270](http://arxiv.org/abs/2310.09270)

    本文针对逆合成任务在实验室执行可行性的不确定性问题，通过引入随机过程的表述，提出了一种名为 Retro-fallback 的贪婪算法，该算法能够最大化实验室可执行的合成计划的概率。

    

    逆合成是通过提出一系列化学反应从更简单、可购买的分子创建所需分子的任务。虽然先前的研究提出了一些算法来寻找一系列度量指标（例如最短路径、最低成本）的最优解，但这些研究通常忽视了我们对可能反应空间的不完全了解，这意味着算法生成的计划可能在实验室中无法实施。在本文中，我们提出了一种基于随机过程的逆合成新颖表述，以考虑这种不确定性。然后，我们提出了一种新颖的贪婪算法称为 Retro-fallback，最大化至少有一种合成计划能在实验室中执行的概率。使用仿真基准测试，我们证明 Retro-fallback 通常生成比流行的 MCTS 和 retro* 算法更好的一组合成计划。

    Retrosynthesis is the task of proposing a series of chemical reactions to create a desired molecule from simpler, buyable molecules. While previous works have proposed algorithms to find optimal solutions for a range of metrics (e.g. shortest, lowest-cost), these works generally overlook the fact that we have imperfect knowledge of the space of possible reactions, meaning plans created by the algorithm may not work in a laboratory. In this paper we propose a novel formulation of retrosynthesis in terms of stochastic processes to account for this uncertainty. We then propose a novel greedy algorithm called retro-fallback which maximizes the probability that at least one synthesis plan can be executed in the lab. Using in-silico benchmarks we demonstrate that retro-fallback generally produces better sets of synthesis plans than the popular MCTS and retro* algorithms.
    
[^2]: Table-GPT: 针对多样表格任务的表格调优GPT

    Table-GPT: Table-tuned GPT for Diverse Table Tasks. (arXiv:2310.09263v1 [cs.CL])

    [http://arxiv.org/abs/2310.09263](http://arxiv.org/abs/2310.09263)

    本文提出了一种新的"表格调优"范式，通过使用从真实表格中合成的多样化表格任务作为训练数据，对语言模型进行训练/微调，以提高其理解表格和执行表格任务的能力。

    

    语言模型，如GPT-3.5和ChatGPT，展现出了遵循多种人类指令和执行各种任务的非凡能力。然而，当使用一系列基本的表格理解任务来探究语言模型时，我们观察到现今的语言模型在许多涉及表格的任务上仍然不够优秀，可能是因为它们主要在\emph{一维}自然语言文本上进行预训练，而关系表是\emph{二维}对象。在本文中，我们提出了一种新的“\emph{表格调优}”范式，即通过使用从真实表格中合成的多样化表格任务作为训练数据，继续对GPT-3.5和ChatGPT这样的语言模型进行训练/微调，从而提高语言模型理解表格和执行表格任务的能力。我们展示了我们的Table-GPT模型表现出更好的\emph{表格理解}能力，在广泛的表格任务上始终优于普通的GPT-3.5和ChatGPT。

    Language models, such as GPT-3.5 and ChatGPT, demonstrate remarkable abilities to follow diverse human instructions and perform a wide range of tasks. However, when probing language models using a range of basic table-understanding tasks, we observe that today's language models are still sub-optimal in many table-related tasks, likely because they are pre-trained predominantly on \emph{one-dimensional} natural-language texts, whereas relational tables are \emph{two-dimensional} objects.  In this work, we propose a new "\emph{table-tuning}" paradigm, where we continue to train/fine-tune language models like GPT-3.5 and ChatGPT, using diverse table-tasks synthesized from real tables as training data, with the goal of enhancing language models' ability to understand tables and perform table tasks. We show that our resulting Table-GPT models demonstrate (1) better \emph{table-understanding} capabilities, by consistently outperforming the vanilla GPT-3.5 and ChatGPT, on a wide-range of tabl
    
[^3]: 它是一种对齐，而不是权衡：重新审视深度模型中的偏差和方差

    It's an Alignment, Not a Trade-off: Revisiting Bias and Variance in Deep Models. (arXiv:2310.09250v1 [cs.LG])

    [http://arxiv.org/abs/2310.09250](http://arxiv.org/abs/2310.09250)

    在基于深度学习的分类模型集合中，对于正确分类的样本点，偏差和方差在样本级别上是对齐的。

    

    传统的机器学习智慧认为泛化误差可以分解为偏差和方差，并且这两个术语之间存在着"权衡"。然而，在本文中，我们展示了在基于深度学习的分类模型集合中，偏差和方差在样本级别上是"对齐"的，其中对于正确分类的样本点，均方偏差大约等于方差。我们提供了经验证据来证实这一现象在各种深度学习模型和数据集中存在。此外，我们从校准和神经崩溃的两个理论视角研究了该现象。首先，我们理论上证明在模型良好校准的假设下，我们可以观察到偏差-方差的对齐。其次，在神经崩溃理论提供的图景下，我们展示了偏差和方差之间的近似相关性。

    Classical wisdom in machine learning holds that the generalization error can be decomposed into bias and variance, and these two terms exhibit a \emph{trade-off}. However, in this paper, we show that for an ensemble of deep learning based classification models, bias and variance are \emph{aligned} at a sample level, where squared bias is approximately \emph{equal} to variance for correctly classified sample points. We present empirical evidence confirming this phenomenon in a variety of deep learning models and datasets. Moreover, we study this phenomenon from two theoretical perspectives: calibration and neural collapse. We first show theoretically that under the assumption that the models are well calibrated, we can observe the bias-variance alignment. Second, starting from the picture provided by the neural collapse theory, we show an approximate correlation between bias and variance.
    
[^4]: 增强计算设计：在生成设计中系统应用人工智能的方法论

    Augmented Computational Design: Methodical Application of Artificial Intelligence in Generative Design. (arXiv:2310.09243v1 [cs.AI])

    [http://arxiv.org/abs/2310.09243](http://arxiv.org/abs/2310.09243)

    本论文介绍了在生成设计中应用人工智能的方法论反思，探讨了如何通过人工智能来增强决策过程，实现复杂设计空间的映射和导航。

    

    本章节介绍了关于在生成设计中应用人工智能的必要性和实用性的方法论反思。具体而言，本章节讨论了如何通过人工智能增强生成设计过程，以在处理数百或数千个小决策的同时实现一些感兴趣的结果或性能指标。性能为基础的生成设计范式的核心在于在这些选择和后果之间建立统计或仿真驱动的关联，以在复杂决策空间中进行映射和导航。本章节将讨论人工智能在增强建筑设计中决策过程的有前途的方向，以实现复杂设计空间的映射和导航。

    This chapter presents methodological reflections on the necessity and utility of artificial intelligence in generative design. Specifically, the chapter discusses how generative design processes can be augmented by AI to deliver in terms of a few outcomes of interest or performance indicators while dealing with hundreds or thousands of small decisions. The core of the performance-based generative design paradigm is about making statistical or simulation-driven associations between these choices and consequences for mapping and navigating such a complex decision space. This chapter will discuss promising directions in Artificial Intelligence for augmenting decision-making processes in architectural design for mapping and navigating complex design spaces.
    
[^5]: 评估机器对土著人认知的研究: 对ChatGPT在不同情境中对土著角色认知的分析

    Evaluating Machine Perception of Indigeneity: An Analysis of ChatGPT's Perceptions of Indigenous Roles in Diverse Scenarios. (arXiv:2310.09237v1 [cs.AI])

    [http://arxiv.org/abs/2310.09237](http://arxiv.org/abs/2310.09237)

    本文调查了ChatGPT等大型语言模型在模拟土著人在不同角色下表现的情境时的自认偏见。研究结果揭示了技术对土著人相关社会偏见的感知和潜在放大，对土著人在重要计算中的影响具有重要意义。

    

    大型语言模型（LLMs），如ChatGPT，是基于大量数据训练的工具，反映了多样化社会印象。本文旨在调查LLMs在模拟土著人在不同角色下表现的情境时的自认偏见。通过生成和分析多个情境，本研究为我们提供了一种独特的视角，了解技术如何感知和潜在放大与土著人相关的社会偏见。研究结果揭示了土著人在重要计算中的广泛影响。

    Large Language Models (LLMs), like ChatGPT, are fundamentally tools trained on vast data, reflecting diverse societal impressions. This paper aims to investigate LLMs' self-perceived bias concerning indigeneity when simulating scenarios of indigenous people performing various roles. Through generating and analyzing multiple scenarios, this work offers a unique perspective on how technology perceives and potentially amplifies societal biases related to indigeneity in social computing. The findings offer insights into the broader implications of indigeneity in critical computing.
    
[^6]: 从数据中快速和高效地学习贝叶斯网络：知识发现与因果关系

    Fast & Efficient Learning of Bayesian Networks from Data: Knowledge Discovery and Causality. (arXiv:2310.09222v1 [cs.LG])

    [http://arxiv.org/abs/2310.09222](http://arxiv.org/abs/2310.09222)

    本论文提出了两个新算法FSBN和SSBN，它们利用局部搜索和条件独立性测试从数据中学习贝叶斯网络的因果结构。实验结果表明，这两个算法在降低计算成本的同时保持了高质量的归纳，提供了可解释性和适应性。

    

    结构学习对贝叶斯网络（BNs）至关重要，它可以揭示因果关系，并能在不确定性下进行知识发现、预测、推理和决策。基于PC算法的两个新算法FSBN和SSBN，采用局部搜索策略和条件独立性测试，从数据中学习因果网络结构。它们利用d-分离来推断额外的拓扑信息，优先考虑条件集，并高效地终止搜索。FSBN实现了高达52%的计算成本减少，而SSBN在200个节点的网络中超过了它，减少了72%的计算成本。由于智能策略，SSBN展示了进一步的效率提升。实验研究表明，这两个算法在显著降低计算成本的同时，与PC算法的归纳质量相匹配。这使得它们在减轻计算负担的同时提供了可解释性和适应性，使它们具有很高的价值。

    Structure learning is essential for Bayesian networks (BNs) as it uncovers causal relationships, and enables knowledge discovery, predictions, inferences, and decision-making under uncertainty. Two novel algorithms, FSBN and SSBN, based on the PC algorithm, employ local search strategy and conditional independence tests to learn the causal network structure from data. They incorporate d-separation to infer additional topology information, prioritize conditioning sets, and terminate the search immediately and efficiently. FSBN achieves up to 52% computation cost reduction, while SSBN surpasses it with a remarkable 72% reduction for a 200-node network. SSBN demonstrates further efficiency gains due to its intelligent strategy. Experimental studies show that both algorithms match the induction quality of the PC algorithm while significantly reducing computation costs. This enables them to offer interpretability and adaptability while reducing the computational burden, making them valuable
    
[^7]: "凯利是一个温暖的人，约瑟夫是一个榜样": LLM生成的推荐信中的性别偏见

    "Kelly is a Warm Person, Joseph is a Role Model": Gender Biases in LLM-Generated Reference Letters. (arXiv:2310.09219v1 [cs.CL])

    [http://arxiv.org/abs/2310.09219](http://arxiv.org/abs/2310.09219)

    本文对LLM生成的推荐信中的性别偏见进行了细致的研究，并设计了评估方法来展现通过语言风格和词汇内容来体现的性别偏见。

    

    随着生成语言模型的进步，用户已经开始使用大型语言模型（LLM）来协助撰写各种类型的内容，包括推荐信等职业文件。尽管它们的方便性，但这些应用引入了前所未有的公平问题。由于生成的推荐信可能被用户直接在职业或学术场景中使用，它们有可能造成直接的社会伤害，如降低女性申请者的成功率。因此，对于未来的缓解和监控，全面研究此类实际应用情况中的公平问题和相关伤害势在必行。在本文中，我们对LLM生成的推荐信中的性别偏见进行了批判性的研究。受社会科学研究结果的启发，我们设计了评估方法，通过两个维度来展现LLM生成的信件中的性别偏见：语言风格的偏见和词汇内容的偏见。此外，我们还研究了推荐信中性别偏见的程度。

    As generative language models advance, users have started to utilize Large Language Models (LLMs) to assist in writing various types of content, including professional documents such as recommendation letters. Despite their convenience, these applications introduce unprecedented fairness concerns. As generated reference letters might be directly utilized by users in professional or academic scenarios, they have the potential to cause direct social harms, such as lowering success rates for female applicants. Therefore, it is imminent and necessary to comprehensively study fairness issues and associated harms in such real-world use cases for future mitigation and monitoring. In this paper, we critically examine gender bias in LLM-generated reference letters. Inspired by findings in social science, we design evaluation methods to manifest gender biases in LLM-generated letters through 2 dimensions: biases in language style and biases in lexical content. Furthermore, we investigate the ext
    
[^8]: 跨国人工智能协会（MAGIC）：关于人工智能国际协调的提案

    Multinational AGI Consortium (MAGIC): A Proposal for International Coordination on AI. (arXiv:2310.09217v1 [cs.AI])

    [http://arxiv.org/abs/2310.09217](http://arxiv.org/abs/2310.09217)

    本文提出了一个跨国人工智能协会（MAGIC），旨在通过全球禁令减轻先进人工智能（AI）对人类存在的风险，同时允许狭义AI模型的发展。

    

    本文提出了一个跨国人工智能协会（MAGIC），旨在减轻先进人工智能（AI）对人类存在的风险。MAGIC将成为全球唯一被允许开发先进AI的机构，并通过其签约成员对其他所有先进AI开发实施全球禁令进行强制执行。MAGIC将是一个独家的、注重安全的、高度安全的机构，由成员国共同支持，并以公平分配的原则来获得利益。MAGIC将允许狭义AI模型迅速发展，同时大大减少通用系统中的不匹配、流窜、突破或失控的可能性。我们不讨论实施禁令的政治可行性，也不讨论实施禁止高容量AGI训练的具体立法策略和规则。相反，我们提出了一个积极的未来愿景，即MAGIC作为全球治理机制，可以为长期的发展奠定基础。

    This paper proposes a Multinational Artificial General Intelligence Consortium (MAGIC) to mitigate existential risks from advanced artificial intelligence (AI). MAGIC would be the only institution in the world permitted to develop advanced AI, enforced through a global moratorium by its signatory members on all other advanced AI development. MAGIC would be exclusive, safety-focused, highly secure, and collectively supported by member states, with benefits distributed equitably among signatories. MAGIC would allow narrow AI models to flourish while significantly reducing the possibility of misaligned, rogue, breakout, or runaway outcomes of general-purpose systems. We do not address the political feasibility of implementing a moratorium or address the specific legislative strategies and rules needed to enforce a ban on high-capacity AGI training runs. Instead, we propose one positive vision of the future, where MAGIC, as a global governance regime, can lay the groundwork for long-term, 
    
[^9]: SiamAF: 学习心电图和光电脉搏图信号的共享信息用于强健的心房颤动检测

    SiamAF: Learning Shared Information from ECG and PPG Signals for Robust Atrial Fibrillation Detection. (arXiv:2310.09203v1 [cs.LG])

    [http://arxiv.org/abs/2310.09203](http://arxiv.org/abs/2310.09203)

    提出了一种名为SiamAF的新方法，利用心电图和光电脉搏图信号的共享信息，通过Siamese网络和联合学习实现强健的心房颤动（AF）检测。

    

    心房颤动（AF）是最常见的心脏心律失常类型，与中风、心力衰竭和其他心血管并发症的风险增加有关，但可以临床上无声。佩戴式设备进行被动性的AF监测可能有助于减少与AF相关的不良临床结果。在嘈杂的佩戴式数据中检测AF面临重大挑战，引发了各种不同的深度学习技术。先前的深度学习模型从单一形态学习，要么是心电图（ECG），要么是光电脉搏图（PPG）信号。然而，深度学习模型往往难以学习可泛化的特征，并依赖于更容易受到噪声损坏的特征，在某些场景中导致次优的性能，特别是在低质量信号的情况下。鉴于佩戴式设备和床边监护仪上ECG和PPG信号配对的日益丰富，我们提出了一种新的方法SiamAF，利用一种新颖的Siamese网络结构和联合学习的方法。

    Atrial fibrillation (AF) is the most common type of cardiac arrhythmia. It is associated with an increased risk of stroke, heart failure, and other cardiovascular complications, but can be clinically silent. Passive AF monitoring with wearables may help reduce adverse clinical outcomes related to AF. Detecting AF in noisy wearable data poses a significant challenge, leading to the emergence of various deep learning techniques. Previous deep learning models learn from a single modality, either electrocardiogram (ECG) or photoplethysmography (PPG) signals. However, deep learning models often struggle to learn generalizable features and rely on features that are more susceptible to corruption from noise, leading to sub-optimal performances in certain scenarios, especially with low-quality signals. Given the increasing availability of ECG and PPG signal pairs from wearables and bedside monitors, we propose a new approach, SiamAF, leveraging a novel Siamese network architecture and joint le
    
[^10]: Tikuna: 一种以太坊区块链网络安全监测系统

    Tikuna: An Ethereum Blockchain Network Security Monitoring System. (arXiv:2310.09193v1 [cs.CR])

    [http://arxiv.org/abs/2310.09193](http://arxiv.org/abs/2310.09193)

    Tikuna是一个开源工具，用于监测和检测以太坊区块链P2P网络上的潜在攻击。它采用无监督的LSTM方法，通过收集数据和分析网络行为，显著降低了攻击风险。

    

    随着区块链在许多行业中的影响逐渐扩大，区块链安全正在变得越来越重要。本文侧重于保护区块链的最底层层级，特别是允许节点进行通信和共享信息的P2P网络。P2P网络层可能容易遭受分布式拒绝服务（DDoS）、日食攻击或Sybil攻击等多种攻击。这一层面易受传统P2P网络中的威胁，因此需要通过收集数据并从网络行为中提取洞察来降低这些风险。我们介绍了Tikuna，这是一种针对以太坊区块链P2P网络进行早期监测和检测潜在攻击的开源工具。Tikuna采用基于循环神经网络（RNN）的无监督长短期记忆（LSTM）方法来检测攻击并警报用户。实证结果表明，所提出的方法显著降低了攻击风险。

    Blockchain security is becoming increasingly relevant in today's cyberspace as it extends its influence in many industries. This paper focuses on protecting the lowest level layer in the blockchain, particularly the P2P network that allows the nodes to communicate and share information. The P2P network layer may be vulnerable to several families of attacks, such as Distributed Denial of Service (DDoS), eclipse attacks, or Sybil attacks. This layer is prone to threats inherited from traditional P2P networks, and it must be analyzed and understood by collecting data and extracting insights from the network behavior to reduce those risks. We introduce Tikuna, an open-source tool for monitoring and detecting potential attacks on the Ethereum blockchain P2P network, at an early stage. Tikuna employs an unsupervised Long Short-Term Memory (LSTM) method based on Recurrent Neural Network (RNN) to detect attacks and alert users. Empirical results indicate that the proposed approach significantl
    
[^11]: 图状压缩：是否看起来像视觉数据集？(arXiv:2310.09192v1 [cs.LG])

    Does Graph Distillation See Like Vision Dataset Counterpart?. (arXiv:2310.09192v1 [cs.LG])

    [http://arxiv.org/abs/2310.09192](http://arxiv.org/abs/2310.09192)

    本文研究了图压缩方法中对结构信息的忽视问题，并提出了一种新的结构广播图数据集压缩方案（SGDD），该方案能够保留原始图的结构信息，并在跨架构泛化和特定任务中取得了优秀的性能。

    

    在图表示学习中，对大规模图进行训练取得了显著的结果，但其成本和存储引起了越来越多的关注。现有的图压缩方法主要关注优化压缩图的特征矩阵，而忽视了原始图的结构信息的影响。为了调查结构信息的影响，我们从谱域进行分析，并经验性地确定了先前工作中的重要的拉普拉斯能量分布（LED）的偏移。这种偏移导致在跨架构泛化和特定任务（包括异常检测和链接预测）中的性能较差。在本文中，我们提出了一种新颖的结构广播图数据集压缩（SGDD）方案，将原始结构信息广播到合成图的生成过程中，显式地防止忽视原始结构信息。从理论上讲，SGDD生成的合成图具有保留原始图的结构信息的能力。

    Training on large-scale graphs has achieved remarkable results in graph representation learning, but its cost and storage have attracted increasing concerns. Existing graph condensation methods primarily focus on optimizing the feature matrices of condensed graphs while overlooking the impact of the structure information from the original graphs. To investigate the impact of the structure information, we conduct analysis from the spectral domain and empirically identify substantial Laplacian Energy Distribution (LED) shifts in previous works. Such shifts lead to poor performance in cross-architecture generalization and specific tasks, including anomaly detection and link prediction. In this paper, we propose a novel Structure-broadcasting Graph Dataset Distillation (SGDD) scheme for broadcasting the original structure information to the generation of the synthetic one, which explicitly prevents overlooking the original structure information. Theoretically, the synthetic graphs by SGDD 
    
[^12]: PRIOR: 个性化先验用于重新激活联邦学习中被忽视的信息

    PRIOR: Personalized Prior for Reactivating the Information Overlooked in Federated Learning. (arXiv:2310.09183v1 [cs.LG])

    [http://arxiv.org/abs/2310.09183](http://arxiv.org/abs/2310.09183)

    本研究提出了一种名为PRIOR的个性化先验方案，用于解决个性化联邦学习中由于全局模型忽视特定信息而导致的不完整信息问题。该方案使用带Bregman散度的PFL框架将个性化先验与本地目标函数解耦，以提高适应性和性能。

    

    传统的联邦学习（FL）通过在保护隐私的前提下训练机器学习模型，而异质数据特性降低了局部模型的性能。个性化联邦学习（PFL）通过从全局模型中合成个性化模型来解决这个问题，在本地数据上进行训练。然而，这样的全局模型可能忽视了客户端被采样的特定信息。本文提出了一种新的方案，通过将个性化先验知识注入到每个客户端的全局模型中，试图减轻PFL中引入的不完整信息问题。我们提出的方法的核心是一种框架，即带Bregman散度（pFedBreD）的PFL，通过在个性化场景中使用Bregman散度正则化的本地目标函数，使个性化先验与之解耦，具有更强的适应性。我们还放松了镜像下降（RMD），以显式地提取先验知识，提供可选择的策略。

    Classical federated learning (FL) enables training machine learning models without sharing data for privacy preservation, but heterogeneous data characteristic degrades the performance of the localized model. Personalized FL (PFL) addresses this by synthesizing personalized models from a global model via training on local data. Such a global model may overlook the specific information that the clients have been sampled. In this paper, we propose a novel scheme to inject personalized prior knowledge into the global model in each client, which attempts to mitigate the introduced incomplete information problem in PFL. At the heart of our proposed approach is a framework, the PFL with Bregman Divergence (pFedBreD), decoupling the personalized prior from the local objective function regularized by Bregman divergence for greater adaptability in personalized scenarios. We also relax the mirror descent (RMD) to extract the prior explicitly to provide optional strategies. Additionally, our pFed
    
[^13]: mnmDTW:一种用于基于摄像头的运动误差定位的动态时间规整拓展

    mnmDTW: An extension to Dynamic Time Warping for Camera-based Movement Error Localization. (arXiv:2310.09170v1 [cs.CV])

    [http://arxiv.org/abs/2310.09170](http://arxiv.org/abs/2310.09170)

    mnmDTW是一种用于基于摄像头的运动误差定位的动态时间规整拓展方法。通过计算每个身体部位之间的距离，该方法能够更精确地测量运动的准确性，从而清楚地显示、识别和定位运动错误。

    

    在这个概念验证中，我们使用计算机视觉方法从运动视频中提取姿势信息。然后，我们使用一种修改后的动态时间规整(DTW)来计算与黄金标准运动执行之间的偏差。具体而言，我们计算每个身体部位之间的距离，以获得更精确的运动准确性测量。我们可以通过这个度量指标清楚地看到、识别和定位运动错误。

    In this proof of concept, we use Computer Vision (CV) methods to extract pose information out of exercise videos. We then employ a modified version of Dynamic Time Warping (DTW) to calculate the deviation from a gold standard execution of the exercise. Specifically, we calculate the distance between each body part individually to get a more precise measure for exercise accuracy. We can show that exercise mistakes are clearly visible, identifiable and localizable through this metric.
    
[^14]: 量子机器学习在气候变化和可持续发展中的应用：一项综述

    Quantum Machine Learning in Climate Change and Sustainability: a Review. (arXiv:2310.09162v1 [cs.LG])

    [http://arxiv.org/abs/2310.09162](http://arxiv.org/abs/2310.09162)

    量子机器学习在解决气候变化和可持续发展问题方面具有潜力，可以应用于能源系统、气候数据预测、气候监测和危险事件预测等领域。该综述调查了目前将量子机器学习应用于这些问题的现有研究，并讨论了挑战、局限以及潜在机会和未来工作。

    

    气候变化及其对全球可持续发展的影响是关键挑战，需要结合尖端技术和科学见解的创新解决方案。量子机器学习（QML）已经成为一种有前景的范式，利用量子计算的力量来解决包括气候变化和可持续发展在内的复杂问题。本研究调查了将量子机器学习应用于解决气候变化和可持续发展问题的现有文献。我们回顾了有潜力加速减碳的QML方法，包括能源系统、气候数据预测、气候监测和危险事件预测。我们讨论了量子机器学习方法的挑战和目前的局限，并概述了在气候变化研究这一重要领域利用基于QML的方法的潜在机会和未来工作。

    Climate change and its impact on global sustainability are critical challenges, demanding innovative solutions that combine cutting-edge technologies and scientific insights. Quantum machine learning (QML) has emerged as a promising paradigm that harnesses the power of quantum computing to address complex problems in various domains including climate change and sustainability. In this work, we survey existing literature that applies quantum machine learning to solve climate change and sustainability-related problems. We review promising QML methodologies that have the potential to accelerate decarbonization including energy systems, climate data forecasting, climate monitoring, and hazardous events predictions. We discuss the challenges and current limitations of quantum machine learning approaches and provide an overview of potential opportunities and future work to leverage QML-based methods in the important area of climate change research.
    
[^15]: 学习如何教大型语言模型逻辑推理

    Learning To Teach Large Language Models Logical Reasoning. (arXiv:2310.09158v1 [cs.AI])

    [http://arxiv.org/abs/2310.09158](http://arxiv.org/abs/2310.09158)

    本文通过深入调查和研究，探索了大型语言模型（LLMs）在逻辑推理中的能力，并提出了多种策略来赋予LLMs逻辑推理能力，使其能够生成更具逻辑一致性的答案。

    

    大型语言模型（LLMs）因其在语言生成和强大的泛化能力方面的出色表现而受到学术界和工业界的广泛关注。然而，由于其固有问题（如幻觉），目前的LLMs在实际推理任务中仍然输出不可靠的内容。为了更好地解决这个问题，在本文中，我们进行了深入研究，系统地探索了LLMs在逻辑推理中的能力。更具体地说，我们首先研究了LLMs在不同任务（包括事件关系提取和演绎推理）中在逻辑推理方面的不足之处。我们的研究表明，LLMs在解决需要严格推理的任务时并不是很好的推理者，会产生反事实的答案，这要求我们不断改进。因此，我们全面探索了不同的策略，赋予LLMs逻辑推理能力，从而使其能够生成更具逻辑一致性的答案。

    Large language models (LLMs) have gained enormous attention from both academia and industry, due to their exceptional ability in language generation and extremely powerful generalization. However, current LLMs still output unreliable content in practical reasoning tasks due to their inherent issues (e.g., hallucination). To better disentangle this problem, in this paper, we conduct an in-depth investigation to systematically explore the capability of LLMs in logical reasoning. More in detail, we first investigate the deficiency of LLMs in logical reasoning on different tasks, including event relation extraction and deductive reasoning. Our study demonstrates that LLMs are not good reasoners in solving tasks with rigorous reasoning and will produce counterfactual answers, which require us to iteratively refine. Therefore, we comprehensively explore different strategies to endow LLMs with logical reasoning ability, and thus enable them to generate more logically consistent answers across
    
[^16]: Lincoln AI计算调查（LAICS）更新。

    Lincoln AI Computing Survey (LAICS) Update. (arXiv:2310.09145v1 [cs.AI])

    [http://arxiv.org/abs/2310.09145](http://arxiv.org/abs/2310.09145)

    这篇论文是AI加速器和处理器调查的更新，涵盖过去四年的内容。通过收集并总结目前已公开宣布的商用加速器的性能和功耗数据，并将其绘制在散点图上，从而分析了趋势和市场细分，并包括了新增加的加速器的简要描述。

    

    本文是AI加速器和处理器调查的更新，涵盖过去四年的内容，现在称为Lincoln AI计算调查 - LAICS（发音为“lace”）。与往年一样，本文收集并总结了目前已公开宣布的商用加速器的峰值性能和峰值功耗数据。将性能和功耗数值绘制在散点图上，并再次讨论和分析了该图上的趋势的多个维度和观察结果。在散点图上突出显示了市场细分，并包括每个细分的缩放图。最后，还包括了对本年度调查中新增加的每个加速器的简要描述。

    This paper is an update of the survey of AI accelerators and processors from past four years, which is now called the Lincoln AI Computing Survey - LAICS (pronounced "lace"). As in past years, this paper collects and summarizes the current commercial accelerators that have been publicly announced with peak performance and peak power consumption numbers. The performance and power values are plotted on a scatter graph, and a number of dimensions and observations from the trends on this plot are again discussed and analyzed. Market segments are highlighted on the scatter plot, and zoomed plots of each segment are also included. Finally, a brief description of each of the new accelerators that have been added in the survey this year is included.
    
[^17]: 共识游戏：通过均衡搜索生成语言模型

    The Consensus Game: Language Model Generation via Equilibrium Search. (arXiv:2310.09139v1 [cs.GT])

    [http://arxiv.org/abs/2310.09139](http://arxiv.org/abs/2310.09139)

    这篇论文介绍了一种新的语言模型解码方法，将其视为规范化的不完美信息序列信号博弈，并通过找到近似均衡点得到了一个解码算法。这种方法可以应用于问答和其他文本生成任务中。

    

    当应用于问答和其他文本生成任务时，语言模型（LMs）可以通过生成式查询（通过从其输出分布中抽样答案）或判别式查询（通过使用它们对一组候选输出进行评分或排序）进行查询。这些过程有时会产生非常不同的预测。我们如何调和互不相容的评分过程以获得连贯的LM预测呢？我们引入一种新的、无需训练的、博弈论过程用于语言模型解码。我们的方法将语言模型解码视为一种规范化的不完美信息序列信号博弈 - 称为共识游戏 - 在该博弈中，一个生成器试图用自然语言句子传达一个抽象的正确性参数给一个判别器。我们开发了计算程序来找到这个博弈的近似均衡点，从而得到了一个我们称之为EQUILIBRIUM-RANKING的解码算法。应用于大量任务（包括阅读理解，常识）

    When applied to question answering and other text generation tasks, language models (LMs) may be queried generatively (by sampling answers from their output distribution) or discriminatively (by using them to score or rank a set of candidate outputs). These procedures sometimes yield very different predictions. How do we reconcile mutually incompatible scoring procedures to obtain coherent LM predictions? We introduce a new, a training-free, game-theoretic procedure for language model decoding. Our approach casts language model decoding as a regularized imperfect-information sequential signaling game - which we term the CONSENSUS GAME - in which a GENERATOR seeks to communicate an abstract correctness parameter using natural language sentences to a DISCRIMINATOR. We develop computational procedures for finding approximate equilibria of this game, resulting in a decoding algorithm we call EQUILIBRIUM-RANKING. Applied to a large number of tasks (including reading comprehension, commonsen
    
[^18]: HierarchicalContrast: 一种用于跨领域零样本插槽填充的粗粒度到细粒度对比学习框架

    HierarchicalContrast: A Coarse-to-Fine Contrastive Learning Framework for Cross-Domain Zero-Shot Slot Filling. (arXiv:2310.09135v1 [cs.AI])

    [http://arxiv.org/abs/2310.09135](http://arxiv.org/abs/2310.09135)

    本研究提出了一种用于零样本插槽填充的Hierarchical Contrastive Learning Framework (HiCL)，通过粗粒度到细粒度的对比学习，学习语句令牌之间的深层语义关系，并提出了一种新的迭代标签集语义推理方法，来提高在未见插槽上的泛化能力。

    

    在面向任务的对话场景中，跨领域零样本插槽填充在利用源领域知识来学习具有高泛化能力的模型方面起着重要作用，在未知目标领域中，由于缺少带注释的数据，其性能往往不理想。然而，现有的零样本插槽填充方法在目标领域中的泛化能力有限，它们只能在已见插槽上有效地进行知识转移，对未见插槽的表现较差。为了缓解这个问题，我们提出了一种新颖的Hierarchical Contrastive Learning Framework (HiCL)用于零样本插槽填充。具体来说，我们提出了一种基于高斯分布嵌入的粗粒度到细粒度对比学习方法，通过优化间隔和内部标记分布的距离，学习语句令牌之间的深层语义关系。这鼓励HiCL在训练阶段泛化到未见的插槽类型。此外，我们提出了一种新的迭代标签集语义推理方法，来对标签进行公正的推断。

    In task-oriented dialogue scenarios, cross-domain zero-shot slot filling plays a vital role in leveraging source domain knowledge to learn a model with high generalization ability in unknown target domain where annotated data is unavailable. However, the existing state-of-the-art zero-shot slot filling methods have limited generalization ability in target domain, they only show effective knowledge transfer on seen slots and perform poorly on unseen slots. To alleviate this issue, we present a novel Hierarchical Contrastive Learning Framework (HiCL) for zero-shot slot filling. Specifically, we propose a coarseto fine-grained contrastive learning based on Gaussian-distributed embedding to learn the generalized deep semantic relations between utterance-tokens, by optimizing inter- and intra-token distribution distance. This encourages HiCL to generalize to the slot types unseen at training phase. Furthermore, we present a new iterative label set semantics inference method to unbiasedly 
    
[^19]: 使用本地差分隐私保护大型语言模型推断：拆分与去噪

    Split-and-Denoise: Protect large language model inference with local differential privacy. (arXiv:2310.09130v1 [cs.AI])

    [http://arxiv.org/abs/2310.09130](http://arxiv.org/abs/2310.09130)

    本文提出了一种名为SnD的创新框架，用于保护大型语言模型推断阶段的隐私。该方法通过在客户端上执行令牌嵌入层和引入噪声来优化隐私-效用权衡，无需修改模型参数。

    

    大型语言模型（LLMs）通过捕捉向量空间中的隐藏语义，展示了在自然语言理解方面的强大能力。这一过程丰富了文本嵌入的价值，从而促进了作为服务（EaaS）的嵌入模型商业模式。然而，直接将文本传输到服务器面临着较大的隐私泄露风险，这是一个尚未得到有效解决的问题。为了缓解这个问题，我们引入了Split-N-Denoise（SnD），一种创新的框架，通过在客户端上以最小的计算成本执行令牌嵌入层来拆分模型。这使得客户端能够在将嵌入传输到服务器之前引入噪声，并随后接收和去噪后的扰动输出嵌入用于下游任务。我们的方法专为LLMs的推断阶段设计，不需要修改模型参数。广泛的实验证明了SnD在各种LLM中优化隐私-效用权衡方面的有效性。

    Large Language Models (LLMs) shows powerful capability in natural language understanding by capturing hidden semantics in vector space. This process enriches the value of the text embeddings for various downstream tasks, thereby fostering the Embedding-as-a-Service (EaaS) business model. However, the direct transmission of text to servers poses a largely unaddressed risk of privacy leakage. To mitigate this issue, we introduce Split-N-Denoise (SnD), an innovative framework that split the model to execute the token embedding layer on the client side at minimal computational cost. This allows the client to introduce noise prior to transmitting the embeddings to the server, and subsequently receive and denoise the perturbed output embeddings for downstream tasks. Our approach is designed for the inference stage of LLMs and requires no modifications to the model parameters. Extensive experiments demonstrate SnD's effectiveness in optimizing the privacy-utility tradeoff across various LLM a
    
[^20]: 基于时间戳监督的可穿戴活动分割和识别方法：对比学习和保序最优传输

    Timestamp-supervised Wearable-based Activity Segmentation and Recognition with Contrastive Learning and Order-Preserving Optimal Transport. (arXiv:2310.09114v1 [cs.CV])

    [http://arxiv.org/abs/2310.09114](http://arxiv.org/abs/2310.09114)

    本论文提出了一种基于时间戳监督的可穿戴活动分割和识别方法，通过仅需要每个活动段中的单个注释样本来解决由于稀疏标注导致的识别和分割问题之间的差距。

    

    可穿戴活动识别是普遍应用于无处不在和移动计算应用中的有用技术之一。滑动窗口方案被广泛采用，但存在多类窗口问题。为解决这些问题，我们提出一种新颖的基于时间戳监督的联合活动分割和识别方法，只需每个活动段中的单个注释样本。然而，稀疏标注的有限信息加剧了识别和分割任务之间的差距，导致模型性能不佳。

    Human activity recognition (HAR) with wearables is one of the serviceable technologies in ubiquitous and mobile computing applications. The sliding-window scheme is widely adopted while suffering from the multi-class windows problem. As a result, there is a growing focus on joint segmentation and recognition with deep-learning methods, aiming at simultaneously dealing with HAR and time-series segmentation issues. However, obtaining the full activity annotations of wearable data sequences is resource-intensive or time-consuming, while unsupervised methods yield poor performance. To address these challenges, we propose a novel method for joint activity segmentation and recognition with timestamp supervision, in which only a single annotated sample is needed in each activity segment. However, the limited information of sparse annotations exacerbates the gap between recognition and segmentation tasks, leading to sub-optimal model performance. Therefore, the prototypes are estimated by clas
    
[^21]: GLoRE: 评估大型语言模型的逻辑推理能力

    GLoRE: Evaluating Logical Reasoning of Large Language Models. (arXiv:2310.09107v1 [cs.CL])

    [http://arxiv.org/abs/2310.09107](http://arxiv.org/abs/2310.09107)

    本论文介绍了GLoRE，一个评估大型语言模型逻辑推理能力的基准，实验结果表明开放式LLM模型的逻辑推理能力需要提高。研究提出了一种自一致性探测方法和微调方法来改进ChatGPT和开放式LLM的性能。

    

    最近，包括GPT-4和新兴社区模型在内的大型语言模型(LLMs)展示了显著的通用语言理解能力。然而，对这些LLMs的逻辑推理能力进行评估的尝试还很少，而这是自然语言理解的一个重要方面。为了鼓励进一步研究，我们引入了GLoRE，一个精心组织的通用逻辑推理评估基准，包含了12个覆盖三种不同类型任务的数据集。我们的实验结果显示，与人类和监督微调的性能相比，开放式LLM模型的逻辑推理能力需要进一步提高；ChatGPT和GPT-4展示了较强的逻辑推理能力，GPT-4大幅超过了ChatGPT。我们提出了一种自一致性探测方法来提高ChatGPT的准确性，以及一种微调方法来提高开放式LLM的性能。

    Recently, large language models (LLMs), including notable models such as GPT-4 and burgeoning community models, have showcased significant general language understanding abilities. However, there has been a scarcity of attempts to assess the logical reasoning capacities of these LLMs, an essential facet of natural language understanding. To encourage further investigation in this area, we introduce GLoRE, a meticulously assembled General Logical Reasoning Evaluation benchmark comprised of 12 datasets that span three different types of tasks. Our experimental results show that compared to the performance of human and supervised fine-tuning, the logical reasoning capabilities of open LLM models necessitate additional improvement; ChatGPT and GPT-4 show a strong capability of logical reasoning, with GPT-4 surpassing ChatGPT by a large margin. We propose a self-consistency probing method to enhance the accuracy of ChatGPT and a fine-tuned method to boost the performance of an open LLM. We 
    
[^22]: 隐私保护的加密低剂量CT去噪

    Privacy-Preserving Encrypted Low-Dose CT Denoising. (arXiv:2310.09101v1 [cs.CR])

    [http://arxiv.org/abs/2310.09101](http://arxiv.org/abs/2310.09101)

    本论文提出了一种隐私保护的加密低剂量CT去噪方法，通过使用同态加密对私有数据进行加密，避免了将数据暴露给服务器的风险，实现了隐私保护的云服务。

    

    深度学习在断层成像中取得了显著的进展，特别是在低剂量计算机断层扫描（LDCT）去噪方面。最近的一个趋势是使用服务器训练具有大量自我收集的私有数据的强大模型，并为用户提供应用编程接口（API），如Chat-GPT。为了避免模型泄漏，用户需要将其数据上传到服务器模型，但这种方式引起了公众对于隐私泄露风险的关注，尤其是对于医疗数据。因此，为了减轻相关担忧，本文提出在加密领域直接对LDCT进行去噪，以实现对云服务的隐私保护，而不将私有数据暴露给服务器。为此，我们采用同态加密来加密私有的LDCT数据，然后将其传输给使用明文LDCT训练的服务器模型进行进一步的去噪处理。然而，由于深度学习中传统的操作（如卷积和线性变换）需要明文数据，因此在加密领域进行低剂量CT去噪仍然存在挑战。

    Deep learning (DL) has made significant advancements in tomographic imaging, particularly in low-dose computed tomography (LDCT) denoising. A recent trend involves servers training powerful models with large amounts of self-collected private data and providing application programming interfaces (APIs) for users, such as Chat-GPT. To avoid model leakage, users are required to upload their data to the server model, but this way raises public concerns about the potential risk of privacy disclosure, especially for medical data. Hence, to alleviate related concerns, in this paper, we propose to directly denoise LDCT in the encrypted domain to achieve privacy-preserving cloud services without exposing private data to the server. To this end, we employ homomorphic encryption to encrypt private LDCT data, which is then transferred to the server model trained with plaintext LDCT for further denoising. However, since traditional operations, such as convolution and linear transformation, in DL me
    
[^23]: 无监督机器学习和XAI在超越人类能力的规模上洞察历史来源的分析

    Insightful analysis of historical sources at scales beyond human capabilities using unsupervised Machine Learning and XAI. (arXiv:2310.09091v1 [cs.LG])

    [http://arxiv.org/abs/2310.09091](http://arxiv.org/abs/2310.09091)

    本研究使用创新的机器学习技术对大规模历史文献进行分析，并重点研究了“Sacrobosco Collection”中知识的演变。通过这一研究，我们得出了一些重要的历史洞察。

    

    历史资料丰富，但如何将人类知识的演变和传播进行整合，无论是时间上还是空间上的，都是一个具有挑战性的问题，目前只能进行有限的选择性研究。巨大的历史资料量使得全面研究成为不可能，因为人类专家的数量有限。然而，随着大量历史资料以数字形式可获得，AI辅助历史分析有了希望。在这项工作中，我们采用创新的机器学习技术对大规模历史文献进行分析，实现了深入的历史洞察。我们的研究重点是“Sacrobosco Collection”中的知识演变，这是一个包含359个早期现代印刷版天文学教科书的数字化收藏品，这些教科书在1472年至1650年间在欧洲大学使用，大约有76,000页，其中许多包含天文和计算表格。通过机器学习分析这一收藏品，我们发现了一些重要的洞察。

    Historical materials are abundant. Yet, piecing together how human knowledge has evolved and spread both diachronically and synchronically remains a challenge that can so far only be very selectively addressed. The vast volume of materials precludes comprehensive studies, given the restricted number of human specialists. However, as large amounts of historical materials are now available in digital form there is a promising opportunity for AI-assisted historical analysis. In this work, we take a pivotal step towards analyzing vast historical corpora by employing innovative machine learning (ML) techniques, enabling in-depth historical insights on a grand scale. Our study centers on the evolution of knowledge within the `Sacrobosco Collection' -- a digitized collection of 359 early modern printed editions of textbooks on astronomy used at European universities between 1472 and 1650 -- roughly 76,000 pages, many of which contain astronomic, computational tables. An ML based analysis of t
    
[^24]: 瑞士德语言传输的方言转换

    Dialect Transfer for Swiss German Speech Translation. (arXiv:2310.09088v1 [cs.CL])

    [http://arxiv.org/abs/2310.09088](http://arxiv.org/abs/2310.09088)

    本文研究了瑞士德语言翻译系统建设中的挑战，着重探讨了方言多样性和瑞士德语与标准德语之间的差异对系统性能的影响。

    

    本文探讨了在建立瑞士德语言翻译系统中的挑战，特别关注方言多样性以及瑞士德语和标准德语之间的差异的影响。瑞士德语是一种口语语言，没有正式的书写系统，包括许多不同的方言，是一种资源匮乏的语言，只有大约500万使用者。这项研究围绕两个关键的研究问题进行：在训练瑞士德语言翻译模型时，方言的包含和排除如何影响特定方言的性能，以及瑞士德语和标准德语之间的差异如何影响系统的性能？我们表明方言多样性和语言差异给瑞士德语言翻译带来了重大挑战，这与经验研究得出的语言学假设相一致。

    This paper investigates the challenges in building Swiss German speech translation systems, specifically focusing on the impact of dialect diversity and differences between Swiss German and Standard German. Swiss German is a spoken language with no formal writing system, it comprises many diverse dialects and is a low-resource language with only around 5 million speakers. The study is guided by two key research questions: how does the inclusion and exclusion of dialects during the training of speech translation models for Swiss German impact the performance on specific dialects, and how do the differences between Swiss German and Standard German impact the performance of the systems? We show that dialect diversity and linguistic differences pose significant challenges to Swiss German speech translation, which is in line with linguistic hypotheses derived from empirical investigations.
    
[^25]: ImageManip: 基于图像的带有可供识别引导的下一个视图选择的机器人操控

    ImageManip: Image-based Robotic Manipulation with Affordance-guided Next View Selection. (arXiv:2310.09069v1 [cs.RO])

    [http://arxiv.org/abs/2310.09069](http://arxiv.org/abs/2310.09069)

    ImageManip是一个基于图像的机器人操纵框架，通过捕捉目标物体多个视角和推断深度信息，克服了使用三维点云数据进行操控的挑战。

    

    在未来家庭助手机器人领域，三维关节物体操控对于使机器人与环境进行交互至关重要。许多现有的研究使用三维点云作为操纵策略的主要输入。然而，这种方法由于数据稀疏性和获取点云数据的显著成本而面临挑战，这可能限制了实际应用性。相反，RGB图像利用成本效益高的设备提供高分辨率的观察，但缺乏三维空间几何信息。为了克服这些限制，我们提出了一种新颖的基于图像的机器人操纵框架。该框架旨在捕捉目标物体的多个视角，并推断深度信息以补充其几何形状。初始阶段，系统使用一个手上有眼的RGB摄像头捕捉目标物体的整体视图。它预测初始深度图和粗略可供识别图。可供识别图指示了可行动的区域。

    In the realm of future home-assistant robots, 3D articulated object manipulation is essential for enabling robots to interact with their environment. Many existing studies make use of 3D point clouds as the primary input for manipulation policies. However, this approach encounters challenges due to data sparsity and the significant cost associated with acquiring point cloud data, which can limit its practicality. In contrast, RGB images offer high-resolution observations using cost effective devices but lack spatial 3D geometric information. To overcome these limitations, we present a novel image-based robotic manipulation framework. This framework is designed to capture multiple perspectives of the target object and infer depth information to complement its geometry. Initially, the system employs an eye-on-hand RGB camera to capture an overall view of the target object. It predicts the initial depth map and a coarse affordance map. The affordance map indicates actionable areas on the 
    
[^26]: DATT：用于四旋翼控制的深度自适应轨迹跟踪

    DATT: Deep Adaptive Trajectory Tracking for Quadrotor Control. (arXiv:2310.09053v1 [cs.RO])

    [http://arxiv.org/abs/2310.09053](http://arxiv.org/abs/2310.09053)

    DATT是一种用于四旋翼控制的深度自适应轨迹跟踪方法，能够在现实世界中精确跟踪任意可能不可行的轨迹，并能够在存在大干扰的情况下使用L1自适应控制进行增强，优于竞争方法。

    

    由于未知的非线性动力学、轨迹不可行性和执行限制，对于四旋翼的精确任意轨迹跟踪是具有挑战性的。为了解决这些挑战，我们提出了深度自适应轨迹跟踪（DATT），一种基于学习的方法，能够在现实世界中，精确地跟踪任意可能不可行的轨迹，并在存在大干扰的情况下进行控制。DATT基于一种在仿真中使用强化学习训练的新颖前馈-反馈自适应控制结构。当在真实硬件上部署时，DATT通过在闭环中使用L1自适应控制的干扰估计器进行增强，而无需进行任何微调。DATT在具有不稳定风场的可行平滑和不可行轨迹上，明显优于竞争自适应非线性和模型预测控制器，包括基线完全失效的挑战性场景。此外，DATT可以在在线情况下高效运行，推理时间不到3.2毫秒，仅为一/四分之一的基准测试时间。

    Precise arbitrary trajectory tracking for quadrotors is challenging due to unknown nonlinear dynamics, trajectory infeasibility, and actuation limits. To tackle these challenges, we present Deep Adaptive Trajectory Tracking (DATT), a learning-based approach that can precisely track arbitrary, potentially infeasible trajectories in the presence of large disturbances in the real world. DATT builds on a novel feedforward-feedback-adaptive control structure trained in simulation using reinforcement learning. When deployed on real hardware, DATT is augmented with a disturbance estimator using L1 adaptive control in closed-loop, without any fine-tuning. DATT significantly outperforms competitive adaptive nonlinear and model predictive controllers for both feasible smooth and infeasible trajectories in unsteady wind fields, including challenging scenarios where baselines completely fail. Moreover, DATT can efficiently run online with an inference time less than 3.2 ms, less than 1/4 of the ad
    
[^27]: SAI: 在通信网络中利用系统人工智能来解决人工智能任务

    SAI: Solving AI Tasks with Systematic Artificial Intelligence in Communication Network. (arXiv:2310.09049v1 [cs.AI])

    [http://arxiv.org/abs/2310.09049](http://arxiv.org/abs/2310.09049)

    SAI是一个框架，利用大型语言模型和JSON格式的意图输入来解决复杂的人工智能任务，在智能移动网络中具有重要的应用潜力。

    

    在人工智能的快速发展中，解决复杂的人工智能任务是智能移动网络中的一项关键技术。尽管在智能移动网络中专用的人工智能模型表现良好，但它们无法处理复杂的人工智能任务。为了解决这个挑战，我们提出了系统人工智能（SAI），这是一个框架，通过利用大型语言模型（LLMs）和以JSON格式的意图为基础的输入来连接自设计的模型库和数据库，来解决人工智能任务。具体而言，我们首先设计了一个多输入组件，同时集成大型语言模型（LLMs）和以JSON格式的意图为基础的输入，以满足不同用户的多样意图需求。此外，我们引入了一个基于模型卡片的模型库模块，该模块利用模型卡片在不同模块之间进行模型组合的配对匹配。模型卡片包含相应模型的名称和所需的性能指标。

    In the rapid development of artificial intelligence, solving complex AI tasks is a crucial technology in intelligent mobile networks. Despite the good performance of specialized AI models in intelligent mobile networks, they are unable to handle complicated AI tasks. To address this challenge, we propose Systematic Artificial Intelligence (SAI), which is a framework designed to solve AI tasks by leveraging Large Language Models (LLMs) and JSON-format intent-based input to connect self-designed model library and database. Specifically, we first design a multi-input component, which simultaneously integrates Large Language Models (LLMs) and JSON-format intent-based inputs to fulfill the diverse intent requirements of different users. In addition, we introduce a model library module based on model cards which employ model cards to pairwise match between different modules for model composition. Model cards contain the corresponding model's name and the required performance metrics. Then wh
    
[^28]: KCTS：带有令牌级幻觉检测的知识约束树搜索解码

    KCTS: Knowledge-Constrained Tree Search Decoding with Token-Level Hallucination Detection. (arXiv:2310.09044v1 [cs.CL])

    [http://arxiv.org/abs/2310.09044](http://arxiv.org/abs/2310.09044)

    提出了一种名为KCTS的知识约束树搜索解码方法，利用知识分类器和MCTS指导冻结的LM生成与参考知识对齐的文本，同时引入了一种新颖的令牌级幻觉检测方法RIPA。

    

    大型语言模型（LLM）展示了卓越的人类级自然语言生成能力。然而，它们产生错误信息的潜力，即所谓的幻觉问题，对其部署构成重大风险。解决这个问题的一种常见方法是检索相关知识，并使用输入中的知识对LLM进行精细调节。不幸的是，这种方法会引起高训练成本，并可能对多任务模型造成灾难性遗忘。为了克服这些局限性，我们提出了一种称为KCTS（知识约束树搜索）的知识约束解码方法，它使用知识分类器得分和MCTS（蒙特卡罗树搜索）来指导冻结的LM在每个解码步骤中生成与参考知识对齐的文本。为了将序列级知识分类器适应令牌级指导，我们还提出了一种新颖的令牌级幻觉检测方法，称为RIPA（奖励拐点近似）。

    Large Language Models (LLMs) have demonstrated remarkable human-level natural language generation capabilities. However, their potential to generate misinformation, often called the hallucination problem, poses a significant risk to their deployment. A common approach to address this issue is to retrieve relevant knowledge and fine-tune the LLM with the knowledge in its input. Unfortunately, this method incurs high training costs and may cause catastrophic forgetting for multi-tasking models. To overcome these limitations, we propose a knowledge-constrained decoding method called KCTS (Knowledge-Constrained Tree Search), which guides a frozen LM to generate text aligned with the reference knowledge at each decoding step using a knowledge classifier score and MCTS (Monte-Carlo Tree Search). To adapt the sequence-level knowledge classifier to token-level guidance, we also propose a novel token-level hallucination detection method called RIPA (Reward Inflection Point Approximation). Our e
    
[^29]: 考虑终端用户灵活性的深度强化学习电动车充电优化调度

    Optimal Scheduling of Electric Vehicle Charging with Deep Reinforcement Learning considering End Users Flexibility. (arXiv:2310.09040v1 [cs.LG])

    [http://arxiv.org/abs/2310.09040](http://arxiv.org/abs/2310.09040)

    本研究使用深度强化学习方法，针对时间段电价计划，通过优化调度电动车充电过程来降低用户家庭的成本。

    

    分布式能源资源（特别是电动汽车）的快速增长预计在未来十年内将大幅增加对现有电力分配网络的压力，增加了对更高系统可靠性和灵活性的需求。为了避免不必要的网络投资并增加对分配网络的可控性，网络运营商开展需求响应（DR）计划，以鼓励终端用户在回报经济或其他利益的前提下转移其用电消耗。人工智能（AI）方法在住宅负荷调度应用领域处于研究前沿，主要由于其高精度性、高计算速度和较低对于正在开发的模型的物理特性的依赖性。本研究的目标是在时间段电价计划下，利用深度强化学习方法确定用户家庭电动车减少成本的充电策略。

    The rapid growth of decentralized energy resources and especially Electric Vehicles (EV), that are expected to increase sharply over the next decade, will put further stress on existing power distribution networks, increasing the need for higher system reliability and flexibility. In an attempt to avoid unnecessary network investments and to increase the controllability over distribution networks, network operators develop demand response (DR) programs that incentivize end users to shift their consumption in return for financial or other benefits. Artificial intelligence (AI) methods are in the research forefront for residential load scheduling applications, mainly due to their high accuracy, high computational speed and lower dependence on the physical characteristics of the models under development. The aim of this work is to identify households' EV cost-reducing charging policy under a Time-of-Use tariff scheme, with the use of Deep Reinforcement Learning, and more specifically Deep
    
[^30]: 少样本学习的子空间适应先验

    Subspace Adaptation Prior for Few-Shot Learning. (arXiv:2310.09028v1 [cs.LG])

    [http://arxiv.org/abs/2310.09028](http://arxiv.org/abs/2310.09028)

    提出了少样本学习的子空间适应先验算法，通过同时学习初始化参数和参数子空间，可以基于任务分布决定使用梯度下降调整哪些操作子集，从而提高学习效率并降低过拟合风险。

    

    梯度基于的元学习技术旨在从一系列训练任务中提取有用的先验知识，以便使用梯度下降更高效地学习新任务。尽管这些方法在各种情况下取得了成功，但它们通常在学习新任务时适应可训练层的所有参数。这忽略了对于给定任务分布来说可能更高效的学习策略，并且可能容易过拟合，特别是在少样本学习中，其中必须从有限数量的示例中学习任务。为了解决这些问题，我们提出了子空间适应先验(SAP)，这是一种新颖的基于梯度的元学习算法，它同时学习良好的初始化参数(先验知识)和参数子空间，以操作子集的形式表示应该是可适应的。通过这种方式，SAP可以根据潜在的任务分布学习应该使用梯度下降调整的操作子集，同时降低过拟合的风险。

    Gradient-based meta-learning techniques aim to distill useful prior knowledge from a set of training tasks such that new tasks can be learned more efficiently with gradient descent. While these methods have achieved successes in various scenarios, they commonly adapt all parameters of trainable layers when learning new tasks. This neglects potentially more efficient learning strategies for a given task distribution and may be susceptible to overfitting, especially in few-shot learning where tasks must be learned from a limited number of examples. To address these issues, we propose Subspace Adaptation Prior (SAP), a novel gradient-based meta-learning algorithm that jointly learns good initialization parameters (prior knowledge) and layer-wise parameter subspaces in the form of operation subsets that should be adaptable. In this way, SAP can learn which operation subsets to adjust with gradient descent based on the underlying task distribution, simultaneously decreasing the risk of over
    
[^31]: 一种用于全景视频显著目标检测的时空双模混合流网络

    A Spatial-Temporal Dual-Mode Mixed Flow Network for Panoramic Video Salient Object Detection. (arXiv:2310.09016v1 [cs.CV])

    [http://arxiv.org/abs/2310.09016](http://arxiv.org/abs/2310.09016)

    本文提出了一种名为STDMMF-Net的时空双模混合流网络，用于全景视频显著目标检测。通过设计与应用交叉层注意力模块、交叉层权重模块和双模态注意力模块，该网络能够克服传统2D视频显著目标检测在全景视频中的困难，提高检测准确性和融合效率。

    

    全景视频中的显著目标检测仍处于初步探索阶段。将2D视频显著目标检测方法间接应用于全景视频中的显著目标检测面临许多挑战，如检测精度低、模型复杂度高和泛化性能差等。为了克服这些障碍，我们设计了一个交叉层注意力模块（ILA）、交叉层权重模块（ILW）和双模态注意力模块（BMA）。基于这些模块，我们提出了一种利用全景视频的空间流和相应光流进行显著目标检测的时空双模混合流网络（STDMMF-Net）。首先，ILA模块计算了相邻层级特征之间的注意力，以提高从空间流中提取显著目标特征的准确性。然后，ILW模块量化了每个层级特征中包含的显著目标信息，以提高融合效率。

    Salient object detection (SOD) in panoramic video is still in the initial exploration stage. The indirect application of 2D video SOD method to the detection of salient objects in panoramic video has many unmet challenges, such as low detection accuracy, high model complexity, and poor generalization performance. To overcome these hurdles, we design an Inter-Layer Attention (ILA) module, an Inter-Layer weight (ILW) module, and a Bi-Modal Attention (BMA) module. Based on these modules, we propose a Spatial-Temporal Dual-Mode Mixed Flow Network (STDMMF-Net) that exploits the spatial flow of panoramic video and the corresponding optical flow for SOD. First, the ILA module calculates the attention between adjacent level features of consecutive frames of panoramic video to improve the accuracy of extracting salient object features from the spatial flow. Then, the ILW module quantifies the salient object information contained in the features of each level to improve the fusion efficiency of 
    
[^32]: CodeChain: 通过代表性子模块的自我修订链路实现模块化代码生成

    CodeChain: Towards Modular Code Generation Through Chain of Self-revisions with Representative Sub-modules. (arXiv:2310.08992v1 [cs.AI])

    [http://arxiv.org/abs/2310.08992](http://arxiv.org/abs/2310.08992)

    CodeChain是一种通过代表性子模块的自我修订链路引导模块化代码生成的新框架，旨在解决大型语言模型在解决复杂编程任务方面的挑战。

    

    大型语言模型（LLM）已经在解决简单编程任务方面非常熟练，比如在HumanEval或MBPP基准测试中的任务。然而，对于更复杂和具有竞争性的编程任务，这些模型仍然面临挑战，可能是因为它们倾向于生成作为整体代码块而不是将其分解为逻辑子任务和子模块。另一方面，有经验的程序员本能地编写具有抽象概念的模块化代码来解决复杂任务，通常会重复使用之前开发的模块。为了解决这一差距，我们提出了CodeChain，一种通过代表性子模块的自我修订链路引导模块化代码生成的新框架。具体而言，CodeChain首先通过链式思考提示指导LLM生成模块化代码。然后，它通过迭代两个步骤实施自我修订链路：1）额外...

    Large Language Models (LLMs) have already become quite proficient at solving simpler programming tasks like those in HumanEval or MBPP benchmarks. However, solving more complex and competitive programming tasks is still quite challenging for these models - possibly due to their tendency to generate solutions as monolithic code blocks instead of decomposing them into logical sub-tasks and sub-modules. On the other hand, experienced programmers instinctively write modularized code with abstraction for solving complex tasks, often reusing previously developed modules. To address this gap, we propose CodeChain, a novel framework for inference that elicits modularized code generation through a chain of self-revisions, each being guided by some representative sub-modules generated in previous iterations. Concretely, CodeChain first instructs the LLM to generate modularized codes through chain-of-thought prompting. Then it applies a chain of self-revisions by iterating the two steps: 1) extra
    
[^33]: 路线重新规划预测服务

    Reroute Prediction Service. (arXiv:2310.08988v1 [cs.LG])

    [http://arxiv.org/abs/2310.08988](http://arxiv.org/abs/2310.08988)

    该论文介绍了一种新颖的数据分析和机器学习系统，旨在通过积极支持重新规划决策来减少航班延误。该系统使用历史重新规划数据和天气数据预测未来几天是否会发布重新规划建议，以减少影响航线的因素。

    

    仅在2019年，美国国家航空空间系统的延误成本就估计为330亿美元，这是过去几年增长趋势的峰值。为了解决这种巨大的低效率问题，我们设计和开发了一种新的数据分析和机器学习系统，旨在通过积极支持重新规划决策来减少延误。该系统在未来几天的时间范围内，预测某个空中管制区域或某个指定的咨询标识是否会发布重新规划建议，从而可能影响相关路线。为了提供这些预测，该系统使用从FAA提供的系统范围信息管理（SWIM）数据服务和美国国家环境预测中心（NCEP）提供的天气数据收集的历史重新规划数据。这些数据量庞大，包含许多以高速率流式传输的不相关和噪声数据。系统持续处理进入的原始数据。

    The cost of delays was estimated as 33 billion US dollars only in 2019 for the US National Airspace System, a peak value following a growth trend in past years. Aiming to address this huge inefficiency, we designed and developed a novel Data Analytics and Machine Learning system, which aims at reducing delays by proactively supporting re-routing decisions.  Given a time interval up to a few days in the future, the system predicts if a reroute advisory for a certain Air Route Traffic Control Center or for a certain advisory identifier will be issued, which may impact the pertinent routes. To deliver such predictions, the system uses historical reroute data, collected from the System Wide Information Management (SWIM) data services provided by the FAA, and weather data, provided by the US National Centers for Environmental Prediction (NCEP). The data is huge in volume, and has many items streamed at high velocity, uncorrelated and noisy. The system continuously processes the incoming raw
    
[^34]: 基于大数据的航空领域拥堵预测

    Big data-driven prediction of airspace congestion. (arXiv:2310.08982v1 [cs.AI])

    [http://arxiv.org/abs/2310.08982](http://arxiv.org/abs/2310.08982)

    本文提出了一种基于大数据的航空领域拥堵预测系统，可以准确预测国家空域系统（NAS）内特定空域部门的飞机数量。

    

    国际上的航空导航服务提供商一直在努力开发一种更好的方法来测量和预测特定空域内的飞机数量，也称为空域密度。精确测量和预测空域密度对于更好地管理空域至关重要，无论是战略上还是战术上，都能实现更高级别的自动化，从而减轻空中交通管制员的工作负担。尽管以前的方法在某种程度上已经能够解决这个问题，但在处理不断增长的庞大的空中交通数据时，数据管理和查询处理仍然是一个挑战，特别是在使用线性预测模型的情况下。在本文中，我们提出了一种新颖的数据管理和预测系统，可以准确预测国家空域系统（NAS）内特定空域部门的飞机数量。

    Air Navigation Service Providers (ANSP) worldwide have been making a considerable effort for the development of a better method to measure and predict aircraft counts within a particular airspace, also referred to as airspace density. An accurate measurement and prediction of airspace density is crucial for a better managed airspace, both strategically and tactically, yielding a higher level of automation and thereby reducing the air traffic controller's workload. Although the prior approaches have been able to address the problem to some extent, data management and query processing of ever-increasing vast volume of air traffic data at high rates, for various analytics purposes such as predicting aircraft counts, still remains a challenge especially when only linear prediction models are used.  In this paper, we present a novel data management and prediction system that accurately predicts aircraft counts for a particular airspace sector within the National Airspace System (NAS). The i
    
[^35]: 多功能自然语言处理聊天机器人：设计，方法和结论

    Multi-Purpose NLP Chatbot : Design, Methodology & Conclusion. (arXiv:2310.08977v1 [cs.AI])

    [http://arxiv.org/abs/2310.08977](http://arxiv.org/abs/2310.08977)

    该研究论文主要分析了聊天机器人技术的历史、困难和前景，提出了一种灵活的聊天机器人系统，利用强化学习策略改善用户交互和对话体验，并通过情感分析和自然语言处理来确定用户情绪。

    

    本研究论文主要关注聊天机器人技术的历史、困难和前景，并对当前聊天机器人技术环境进行了彻底分析。该论文提出了一种非常灵活的聊天机器人系统，利用强化学习策略改善用户交互和对话体验。此外，该系统还利用情感分析和自然语言处理来确定用户情绪。由于其出色的特点，包括语音对话、多语言支持[12]、咨询技能、离线功能和快速帮助功能，聊天机器人在许多领域都是一种有价值的工具。本研究还探讨了聊天机器人技术开发的复杂性，以及推动这些发展的原因及其对各个行业的深远影响。根据研究，有三个关键因素非常重要：1）即使没有明确的个人资料信息，聊天机器人系统也能够适应用户的需求。

    With a major focus on its history, difficulties, and promise, this research paper provides a thorough analysis of the chatbot technology environment as it exists today. It provides a very flexible chatbot system that makes use of reinforcement learning strategies to improve user interactions and conversational experiences. Additionally, this system makes use of sentiment analysis and natural language processing to determine user moods. The chatbot is a valuable tool across many fields thanks to its amazing characteristics, which include voice-to-voice conversation, multilingual support [12], advising skills, offline functioning, and quick help features. The complexity of chatbot technology development is also explored in this study, along with the causes that have propelled these developments and their far-reaching effects on a range of sectors. According to the study, three crucial elements are crucial: 1) Even without explicit profile information, the chatbot system is built to adept
    
[^36]: ChatKBQA: 一个基于精调大型语言模型的生成-检索框架用于知识库问答

    ChatKBQA: A Generate-then-Retrieve Framework for Knowledge Base Question Answering with Fine-tuned Large Language Models. (arXiv:2310.08975v1 [cs.CL])

    [http://arxiv.org/abs/2310.08975](http://arxiv.org/abs/2310.08975)

    ChatKBQA是一个基于精调大型语言模型的生成-检索框架，用于改进知识库问答的效率和准确性，实验结果显示在多个数据集上取得了新的最好表现。

    

    知识库问答（KBQA）旨在通过大规模知识库（KB）获取自然语言问题的答案，通常分为两个研究组成部分：知识检索和语义解析。然而，仍然存在三个核心挑战，包括低效的知识检索、检索错误对语义解析的不利影响以及之前的KBQA方法的复杂性。在大型语言模型（LLM）时代，我们介绍了ChatKBQA，这是一个新颖的基于精调开源LLMs（如Llama-2、ChatGLM2和Baichuan2）构建的生成-检索KBQA框架。ChatKBQA提议首先使用精调的LLMs生成逻辑形式，然后通过无监督检索方法检索和替换实体和关系，从而更直观地改进了生成和检索。实验结果表明，ChatKBQA在标准KBQA数据集WebQSP和ComplexWebQuestions (CWQ)上取得了新的最先进性能。

    Knowledge Base Question Answering (KBQA) aims to derive answers to natural language questions over large-scale knowledge bases (KBs), which are generally divided into two research components: knowledge retrieval and semantic parsing. However, three core challenges remain, including inefficient knowledge retrieval, retrieval errors adversely affecting semantic parsing, and the complexity of previous KBQA methods. In the era of large language models (LLMs), we introduce ChatKBQA, a novel generate-then-retrieve KBQA framework built on fine-tuning open-source LLMs such as Llama-2, ChatGLM2 and Baichuan2. ChatKBQA proposes generating the logical form with fine-tuned LLMs first, then retrieving and replacing entities and relations through an unsupervised retrieval method, which improves both generation and retrieval more straightforwardly. Experimental results reveal that ChatKBQA achieves new state-of-the-art performance on standard KBQA datasets, WebQSP, and ComplexWebQuestions (CWQ). This
    
[^37]: Easier Multimodal Generation: Diffusion Models Meet LLMs

    Making Multimodal Generation Easier: When Diffusion Models Meet LLMs. (arXiv:2310.08949v1 [cs.AI])

    [http://arxiv.org/abs/2310.08949](http://arxiv.org/abs/2310.08949)

    EasyGen是一个有效的模型，它通过结合扩散模型和大型语言模型（LLMs）的能力，实现了更容易的多模态生成。相比现有的模型，EasyGen使用了一个名为BiDiffuser的双向条件扩散模型， 提供了更高效的模态交互，并且不仅能够生成文本回复，还能够促进文本到图像的生成。

    

    我们提出了EasyGen，一个有效的模型，通过利用扩散模型和大型语言模型（LLMs）的能力，增强了多模态理解和生成。不同于现有的主要依赖于编码器如CLIP或ImageBind，并且需要大量训练数据来桥接模态之间差距的多模态模型，EasyGen基于一个名为BiDiffuser的双向条件扩散模型构建，促进了更高效的模态交互。EasyGen通过简单的投影层将BiDiffuser和LLM进行集成，处理图像到文本的生成。与大多数现有的限于生成文本回复的多模态模型不同，EasyGen还可以通过利用LLM创建文本描述，并由BiDiffuser解释生成适当的视觉回复来促进文本到图像的生成。广泛的定量和定性实验证明了EasyGen的有效性，其训练可以...

    We present EasyGen, an efficient model designed to enhance multimodal understanding and generation by harnessing the capabilities of diffusion models and large language models (LLMs). Unlike existing multimodal models that predominately depend on encoders like CLIP or ImageBind and need ample amounts of training data to bridge the gap between modalities, EasyGen is built upon a bidirectional conditional diffusion model named BiDiffuser, which promotes more efficient interactions between modalities. EasyGen handles image-to-text generation by integrating BiDiffuser and an LLM via a simple projection layer. Unlike most existing multimodal models that are limited to generating text responses, EasyGen can also facilitate text-to-image generation by leveraging the LLM to create textual descriptions, which can be interpreted by BiDiffuser to generate appropriate visual responses. Extensive quantitative and qualitative experiments demonstrate the effectiveness of EasyGen, whose training can b
    
[^38]: 具有提示的联邦增量学习

    Federated Class-Incremental Learning with Prompting. (arXiv:2310.08948v1 [cs.CV])

    [http://arxiv.org/abs/2310.08948](http://arxiv.org/abs/2310.08948)

    本文提出了一种名为FCILPT的方法，用于解决联邦增量学习中的灾难性遗忘问题，该方法能够处理非独立和同分布数据分布情况，并保护数据隐私。

    

    随着Web技术的发展，使用存储在不同客户端上的数据变得越来越常见。同时，由于在让模型从分布在各个客户端上的数据中学习时能够保护数据隐私，联邦学习引起了广泛关注。然而，大多数现有的工作都假设客户端的数据是固定的。在现实场景中，这种假设很可能不成立，因为数据可能不断生成，新的类别也可能出现。因此，我们专注于实际且具有挑战性的联邦增量学习（FCIL）问题。对于FCIL，由于新类别的出现和客户端数据分布的非独立和同分布性质（non-iid），局部和全局模型可能会对旧类别发生灾难性遗忘。在本文中，我们提出了一种新颖的方法，称为具有提示的联邦增量学习（FCILPT）。

    As Web technology continues to develop, it has become increasingly common to use data stored on different clients. At the same time, federated learning has received widespread attention due to its ability to protect data privacy when let models learn from data which is distributed across various clients. However, most existing works assume that the client's data are fixed. In real-world scenarios, such an assumption is most likely not true as data may be continuously generated and new classes may also appear. To this end, we focus on the practical and challenging federated class-incremental learning (FCIL) problem. For FCIL, the local and global models may suffer from catastrophic forgetting on old classes caused by the arrival of new classes and the data distributions of clients are non-independent and identically distributed (non-iid).  In this paper, we propose a novel method called Federated Class-Incremental Learning with PrompTing (FCILPT). Given the privacy and limited memory, F
    
[^39]: 羞人简单的文字水印

    Embarrassingly Simple Text Watermarks. (arXiv:2310.08920v1 [cs.LG])

    [http://arxiv.org/abs/2310.08920](http://arxiv.org/abs/2310.08920)

    我们提出了一种极其简单但非常有效的文本水印方法Easymark，它可以在不改变文本含义的情况下注入水印，并且能够高度可信地检测出文本是否由采用该方法的系统生成。这种方法不需要访问大型语言模型，并且具有更高的检测准确度和BLEU分数。

    

    我们提出了Easymark，这是一种极其简单但非常有效的水印方法。随着大型语言模型（LLM）的出现，文本水印变得越来越重要。LLM可以生成与人类写作的文本无法区分的文本，这对文本的可信度是一个严重的问题。Easymark是这个问题的一个简单而有效的解决方案。Easymark可以在不改变文本含义的情况下注入水印，而验证器可以高度可信地检测出文本是否由采用Easymark的系统生成。Easymark非常容易实现，只需要几行代码。Easymark不需要访问LLMs，因此当LLM提供者不提供带水印的LLM时，可以在用户端实施。尽管它很简单，但它能够实现比最先进的文本水印方法更高的检测准确度和BLEU分数。我们还证明了完美水印的不可能定理。

    We propose Easymark, a family of embarrassingly simple yet effective watermarks. Text watermarking is becoming increasingly important with the advent of Large Language Models (LLM). LLMs can generate texts that cannot be distinguished from human-written texts. This is a serious problem for the credibility of the text. Easymark is a simple yet effective solution to this problem. Easymark can inject a watermark without changing the meaning of the text at all while a validator can detect if a text was generated from a system that adopted Easymark or not with high credibility. Easymark is extremely easy to implement so that it only requires a few lines of code. Easymark does not require access to LLMs, so it can be implemented on the user-side when the LLM providers do not offer watermarked LLMs. In spite of its simplicity, it achieves higher detection accuracy and BLEU scores than the state-of-the-art text watermarking methods. We also prove the impossibility theorem of perfect watermarki
    
[^40]: 知识图谱嵌入的关系感知集成学习

    Relation-aware Ensemble Learning for Knowledge Graph Embedding. (arXiv:2310.08917v1 [cs.LG])

    [http://arxiv.org/abs/2310.08917](http://arxiv.org/abs/2310.08917)

    本论文提出了一种关系感知集成学习方法，用于知识图谱嵌入任务，并通过分割搜索合并的算法在搜索关系感知集成权重方面取得了显著性能提升。

    

    知识图谱嵌入是自然语言处理中的基础任务，已经提出了各种方法来探索不同方式的语义模式。本文提出了一种关系感知集成学习方法，通过利用现有方法来学习一个集成模型。然而，使用关系感知集成探索这些语义会导致比一般集成方法更大的搜索空间。为了解决这个问题，我们提出了一个分割搜索合并的算法RelEns-DSC，它独立地搜索关系感知集成的权重。该算法具有与一般集成方法相同的计算成本，但性能更好。在基准数据集上的实验结果表明了所提方法在高效搜索关系感知集成权重和达到最先进的嵌入性能方面的有效性。代码公开在https://github.com/LARS-research/RelEns。

    Knowledge graph (KG) embedding is a fundamental task in natural language processing, and various methods have been proposed to explore semantic patterns in distinctive ways. In this paper, we propose to learn an ensemble by leveraging existing methods in a relation-aware manner. However, exploring these semantics using relation-aware ensemble leads to a much larger search space than general ensemble methods. To address this issue, we propose a divide-search-combine algorithm RelEns-DSC that searches the relation-wise ensemble weights independently. This algorithm has the same computation cost as general ensemble methods but with much better performance. Experimental results on benchmark datasets demonstrate the effectiveness of the proposed method in efficiently searching relation-aware ensemble weights and achieving state-of-the-art embedding performance. The code is public at https://github.com/LARS-research/RelEns.
    
[^41]: 动态稀疏无训练：针对稀疏LLMs的无训练微调

    Dynamic Sparse No Training: Training-Free Fine-tuning for Sparse LLMs. (arXiv:2310.08915v1 [cs.AI])

    [http://arxiv.org/abs/2310.08915](http://arxiv.org/abs/2310.08915)

    这篇论文介绍了一种名为动态稀疏无训练的微调方法，可以在不进行昂贵的反向传播和权重更新的情况下更新稀疏的大型语言模型，以此来减小将其部署到设备上时面临的挑战。

    

    越来越庞大的大语言模型(LLMs)虽然为即将到来的人工通用智能开辟了潜在路径，但很遗憾，在其在设备上部署的道路上存在令人望而生畏的障碍。作为在减少模型复杂性方面最成熟的预-LLMs方法之一，网络修剪似乎在LLMs时代落后，主要是由于在庞大的模型参数和训练数据中需要昂贵的微调(或重新训练)。为了弥合产业与学术界之间的差距，我们引入了动态稀疏无训练(DSnoT)，这是一种无训练微调方法，它在不进行昂贵的反向传播和任何权重更新的情况下略微更新稀疏LLMs。受动态稀疏训练的启发，DSnoT通过在稀疏LLMs之上执行迭代的权重修剪和生长的方式，最小化了稠密和稀疏LLMs之间的重构误差。为了实现这个目的，DSnoT特别考虑了预期的减少情况。

    The ever-increasing large language models (LLMs), though opening a potential path for the upcoming artificial general intelligence, sadly drops a daunting obstacle on the way towards their on-device deployment. As one of the most well-established pre-LLMs approaches in reducing model complexity, network pruning appears to lag behind in the era of LLMs, due mostly to its costly fine-tuning (or re-training) necessity under the massive volumes of model parameter and training data. To close this industry-academia gap, we introduce Dynamic Sparse No Training (DSnoT), a training-free fine-tuning approach that slightly updates sparse LLMs without the expensive backpropagation and any weight updates. Inspired by the Dynamic Sparse Training, DSnoT minimizes the reconstruction error between the dense and sparse LLMs, in the fashion of performing iterative weight pruning-and-growing on top of sparse LLMs. To accomplish this purpose, DSnoT particularly takes into account the anticipated reduction 
    
[^42]: 通过深度强化学习将社区成员隐藏作为反事实图搜索

    Community Membership Hiding as Counterfactual Graph Search via Deep Reinforcement Learning. (arXiv:2310.08909v1 [cs.SI])

    [http://arxiv.org/abs/2310.08909](http://arxiv.org/abs/2310.08909)

    这项研究通过深度强化学习的方式解决了社区成员隐藏的挑战，通过战略地改变网络图的结构属性，防止节点被社区检测算法识别出来，并验证了方法的有效性。

    

    社区检测是社交媒体平台发现彼此紧密联系的用户群体的有用工具，他们共享共同的兴趣。然而，这种功能往往会以可能暴露个人隐私为代价，无意中透露他们的品味或偏好。因此，一些用户可能希望保护他们的匿名性，并出于各种原因选择退出社区检测，例如与政治或宗教组织的关联。在这项研究中，我们解决了社区成员隐藏的挑战，它涉及战略性地改变网络图的结构属性，以防止一个或多个节点被给定的社区检测算法识别出来。我们通过制定一个受限的反事实图目标，并通过深度强化学习来解决这个问题。我们通过两个不同的任务来验证我们方法的有效性：节点和社区欺骗。

    Community detection techniques are useful tools for social media platforms to discover tightly connected groups of users who share common interests. However, this functionality often comes at the expense of potentially exposing individuals to privacy breaches by inadvertently revealing their tastes or preferences. Therefore, some users may wish to safeguard their anonymity and opt out of community detection for various reasons, such as affiliation with political or religious organizations.  In this study, we address the challenge of community membership hiding, which involves strategically altering the structural properties of a network graph to prevent one or more nodes from being identified by a given community detection algorithm. We tackle this problem by formulating it as a constrained counterfactual graph objective, and we solve it via deep reinforcement learning. We validate the effectiveness of our method through two distinct tasks: node and community deception. Extensive exper
    
[^43]: 福利外交：基准化语言模型的合作能力

    Welfare Diplomacy: Benchmarking Language Model Cooperation. (arXiv:2310.08901v1 [cs.MA])

    [http://arxiv.org/abs/2310.08901](http://arxiv.org/abs/2310.08901)

    这项研究提出了福利外交这一通用和变种的零和游戏，目的是衡量和强化语言模型的合作能力，并发现使用最先进模型的基准智能体在达到高社会福利时存在可利用性问题。

    

    随着人工智能系统的能力不断增长和广泛部署，对于衡量它们合作能力的强大基准是必要的。遗憾的是，大多数多智能体基准要么是零和游戏，要么是纯粹合作的，给予了非常有限的机会进行这种测量。我们引入了零和游戏Diplomacy的一个通用和变种——福利外交，在其中玩家必须平衡军事征服和国内福利的投资。我们认为福利外交可以更清晰地评估并提供更强大的合作能力的培训激励。我们的贡献有：（1）提出福利外交的规则并通过开源Diplomacy引擎实现它们；（2）使用零样本指导的语言模型构建基准智能体；以及（3）进行实验，发现使用最先进模型的基准智能体可以达到很高的社会福利，但是存在被利用的问题。我们的工作旨在通过人工智能的福利外交促进社会的安全。

    The growing capabilities and increasingly widespread deployment of AI systems necessitate robust benchmarks for measuring their cooperative capabilities. Unfortunately, most multi-agent benchmarks are either zero-sum or purely cooperative, providing limited opportunities for such measurements. We introduce a general-sum variant of the zero-sum board game Diplomacy -- called Welfare Diplomacy -- in which players must balance investing in military conquest and domestic welfare. We argue that Welfare Diplomacy facilitates both a clearer assessment of and stronger training incentives for cooperative capabilities. Our contributions are: (1) proposing the Welfare Diplomacy rules and implementing them via an open-source Diplomacy engine; (2) constructing baseline agents using zero-shot prompted language models; and (3) conducting experiments where we find that baselines using state-of-the-art models attain high social welfare but are exploitable. Our work aims to promote societal safety by ai
    
[^44]: 一种混合迁移学习辅助决策支持系统用于准确预测阿尔茨海默病

    A Hybrid Transfer Learning Assisted Decision Support System for Accurate Prediction of Alzheimer Disease. (arXiv:2310.08888v1 [cs.CV])

    [http://arxiv.org/abs/2310.08888](http://arxiv.org/abs/2310.08888)

    本研究提出了一种混合迁移学习辅助决策支持系统，通过识别四个预测阿尔茨海默病的不同类别，实现了对该疾病的准确预测，加权准确率达到了98.91%。

    

    阿尔茨海默病(AD)是老年人最常见的长期疾病。近年来，深度学习在医学影像领域变得流行，并取得了很多成功。它已成为查看医学影像的最有效方法。在检测AD方面，深度神经模型比一般的机器学习更准确和有效。本研究通过识别预测AD的四个不同类别，为该疾病的更全面理解和检测做出了贡献，其中加权准确率高达98.91%。本研究提出了一种独特的策略，通过集成平均模型和五种不同的迁移学习模型的组合，改善了数据不平衡的分类问题的准确率。EfficientNetB0+Resnet152(effnet+res152)和InceptionV3+EfficientNetB0+Resnet50(incep+effnet+res50)模型进行了微调，并达到了多类别A的最高加权准确率。

    Alzheimer's disease (AD) is the most common long-term illness in elderly people. In recent years, deep learning has become popular in the area of medical imaging and has had a lot of success there. It has become the most effective way to look at medical images. When it comes to detecting AD, the deep neural model is more accurate and effective than general machine learning. Our research contributes to the development of a more comprehensive understanding and detection of the disease by identifying four distinct classes that are predictive of AD with a high weighted accuracy of 98.91%. A unique strategy has been proposed to improve the accuracy of the imbalance dataset classification problem via the combination of ensemble averaging models and five different transfer learning models in this study. EfficientNetB0+Resnet152(effnet+res152) and InceptionV3+EfficientNetB0+Resnet50(incep+effnet+res50) models have been fine-tuned and have reached the highest weighted accuracy for multi-class A
    
[^45]: METRA:具有度量感知抽象的可扩展无监督强化学习

    METRA: Scalable Unsupervised RL with Metric-Aware Abstraction. (arXiv:2310.08887v1 [cs.LG])

    [http://arxiv.org/abs/2310.08887](http://arxiv.org/abs/2310.08887)

    METRA提出了一种新的无监督强化学习目标，旨在使其在复杂的高维环境中可扩展。这个目标解决了纯探索方法在大状态空间环境中的困难以及互信息技能学习方法中缺乏激励而无法探索环境的问题。

    

    无监督预训练策略在自然语言处理和计算机视觉领域证明了其高效性。同样，无监督强化学习（RL）有望发现各种潜在有用的行为，可以加速学习各种下游任务。然而，尽管之前的尝试，使无监督RL真正可扩展仍然是一个重大的挑战：在具有大状态空间的复杂环境中，纯探索方法可能会面临困难，因为覆盖每个可能的转换是不可行的；而互信息技能学习方法可能由于缺乏激励而完全无法探索环境。为了使无监督RL在复杂的高维环境中可扩展，我们提出了一种新的无监督RL目标，称为度量感知抽象（METRA）。

    Unsupervised pre-training strategies have proven to be highly effective in natural language processing and computer vision. Likewise, unsupervised reinforcement learning (RL) holds the promise of discovering a variety of potentially useful behaviors that can accelerate the learning of a wide array of downstream tasks. Previous unsupervised RL approaches have mainly focused on pure exploration and mutual information skill learning. However, despite the previous attempts, making unsupervised RL truly scalable still remains a major open challenge: pure exploration approaches might struggle in complex environments with large state spaces, where covering every possible transition is infeasible, and mutual information skill learning approaches might completely fail to explore the environment due to the lack of incentives. To make unsupervised RL scalable to complex, high-dimensional environments, we propose a novel unsupervised RL objective, which we call Metric-Aware Abstraction (METRA). Ou
    
[^46]: 强适应性和模块化用于有效地在任务复杂性上进行泛化

    Adaptivity and Modularity for Efficient Generalization Over Task Complexity. (arXiv:2310.08866v1 [cs.LG])

    [http://arxiv.org/abs/2310.08866](http://arxiv.org/abs/2310.08866)

    引入一种新的任务来评估变压器在处理不同难度示例的问题上的泛化能力，并提出使用自适应和模块化计算机制的变压器架构，该架构在泛化到更高数量的计算时显示出更高的准确性和更公平的计算资源分配。

    

    变压器是否能够在需要处理不同难度示例的问题上进行有效的泛化？我们引入了一个新的任务，旨在评估对不同复杂度的泛化，并提出的结果表明标准的变压器在解决这些任务时面临挑战。这些任务是由Zhang等人在2021年提出的指针值检索的变体。我们研究了变压器中自适应和模块化计算机制的使用如何促进学习需要在顺序计算步骤数量（即计算图的深度）上进行泛化的任务。基于我们的观察，我们提出了一种基于变压器的架构称为Hyper-UT，它结合了来自超网络的动态函数生成和来自通用变压器的自适应深度。该模型在泛化到更高数量的计算时显示出更高的准确性和更公平的计算资源分配。

    Can transformers generalize efficiently on problems that require dealing with examples with different levels of difficulty? We introduce a new task tailored to assess generalization over different complexities and present results that indicate that standard transformers face challenges in solving these tasks. These tasks are variations of pointer value retrieval previously introduced by Zhang et al. (2021). We investigate how the use of a mechanism for adaptive and modular computation in transformers facilitates the learning of tasks that demand generalization over the number of sequential computation steps (i.e., the depth of the computation graph). Based on our observations, we propose a transformer-based architecture called Hyper-UT, which combines dynamic function generation from hyper networks with adaptive depth from Universal Transformers. This model demonstrates higher accuracy and a fairer allocation of computational resources when generalizing to higher numbers of computation
    
[^47]: 使用分离权重衰减的Adam-family方法在深度学习中

    Adam-family Methods with Decoupled Weight Decay in Deep Learning. (arXiv:2310.08858v1 [math.OC])

    [http://arxiv.org/abs/2310.08858](http://arxiv.org/abs/2310.08858)

    本文研究了一类广泛的Adam-family方法在训练非光滑神经网络中的收敛性质，提出了一种使用分离权重衰减的新框架，并证明了其收敛性。该框架包含了许多已知的Adam-family方法，并对这些方法在训练非光滑神经网络时提供了收敛性保证。

    

    本文研究了一类广泛的Adam-family方法在最小化二次正则化非光滑非凸优化问题中的收敛性质，特别是在训练具有权重衰减的非光滑神经网络的情况下。受到AdamW方法的启发，我们提出了一种使用分离权重衰减的Adam-family方法的新框架。在我们的框架内，随机子梯度的一阶和二阶矩估计分别独立于权重衰减项进行更新。在合理的假设下，并且在更新主要优化变量时采用非递减步长，我们证明了我们提出的框架的收敛性质。此外，我们还展示了我们提出的框架包含了许多众所周知的Adam-family方法，从而为这些方法在训练非光滑神经网络时提供了收敛性保证。更重要的是，我们还展示了我们提出的框架渐近近似了一类次优点。

    In this paper, we investigate the convergence properties of a wide class of Adam-family methods for minimizing quadratically regularized nonsmooth nonconvex optimization problems, especially in the context of training nonsmooth neural networks with weight decay. Motivated by the AdamW method, we propose a novel framework for Adam-family methods with decoupled weight decay. Within our framework, the estimators for the first-order and second-order moments of stochastic subgradients are updated independently of the weight decay term. Under mild assumptions and with non-diminishing stepsizes for updating the primary optimization variables, we establish the convergence properties of our proposed framework. In addition, we show that our proposed framework encompasses a wide variety of well-known Adam-family methods, hence offering convergence guarantees for these methods in the training of nonsmooth neural networks. More importantly, we show that our proposed framework asymptotically approxi
    
[^48]: 实现人工智能功能透明性的路径与有意义的可解释性

    Path To Gain Functional Transparency In Artificial Intelligence With Meaningful Explainability. (arXiv:2310.08849v1 [cs.AI])

    [http://arxiv.org/abs/2310.08849](http://arxiv.org/abs/2310.08849)

    本论文提出了一个面向用户的合规设计，用于实现透明系统中的功能透明性，并强调了跨学科合作的重要性。

    

    人工智能（AI）正在快速融入我们日常生活的各个方面，影响着诸如定向广告和配对算法等领域的决策过程。随着AI系统变得越来越复杂，确保其透明性和可解释性变得至关重要。功能透明性是算法决策系统的一个基本方面，它使利益相关者能够理解这些系统的内在运作，并能够评估其公正性和准确性。然而，实现功能透明性面临着重大挑战，需要加以解决。在本文中，我们提出了一种面向用户的合规设计，用于透明系统中的透明功能。我们强调，开发透明和可解释的人工智能系统是一项复杂而跨学科的努力，需要计算机科学、人工智能、伦理学、法律和社会的研究人员之间的合作。

    Artificial Intelligence (AI) is rapidly integrating into various aspects of our daily lives, influencing decision-making processes in areas such as targeted advertising and matchmaking algorithms. As AI systems become increasingly sophisticated, ensuring their transparency and explainability becomes crucial. Functional transparency is a fundamental aspect of algorithmic decision-making systems, allowing stakeholders to comprehend the inner workings of these systems and enabling them to evaluate their fairness and accuracy. However, achieving functional transparency poses significant challenges that need to be addressed. In this paper, we propose a design for user-centered compliant-by-design transparency in transparent systems. We emphasize that the development of transparent and explainable AI systems is a complex and multidisciplinary endeavor, necessitating collaboration among researchers from diverse fields such as computer science, artificial intelligence, ethics, law, and social 
    
[^49]: 一种用于大型语言模型的基于案例的持久性记忆

    A Case-Based Persistent Memory for a Large Language Model. (arXiv:2310.08842v1 [cs.AI])

    [http://arxiv.org/abs/2310.08842](http://arxiv.org/abs/2310.08842)

    本论文讨论了案例推理研究者对深度学习和大型语言模型的忽视，以及将这些技术应用于大型语言模型的持久性记忆中，进一步推动人工通用智能的发展。

    

    案例推理作为一种问题解决方法可以使用任何合适的计算技术。本论文指出，案例推理的研究者在近期的深度学习和大型语言模型方面有所忽视。近期人工智能突破的潜在技术发展与案例推理有着强烈的协同作用，可以用于为大型语言模型提供持久性记忆，对实现人工通用智能有所进展。

    Case-based reasoning (CBR) as a methodology for problem-solving can use any appropriate computational technique. This position paper argues that CBR researchers have somewhat overlooked recent developments in deep learning and large language models (LLMs). The underlying technical developments that have enabled the recent breakthroughs in AI have strong synergies with CBR and could be used to provide a persistent memory for LLMs to make progress towards Artificial General Intelligence.
    
[^50]: 在外科机器人环境中利用最优输运增强离线强化学习

    Leveraging Optimal Transport for Enhanced Offline Reinforcement Learning in Surgical Robotic Environments. (arXiv:2310.08841v1 [cs.AI])

    [http://arxiv.org/abs/2310.08841](http://arxiv.org/abs/2310.08841)

    本论文介绍了一种利用最优输运奖励标签的算法，可以在离线情况下分配奖励给轨迹，从而减少对资源密集型实时交互的需求。

    

    大多数强化学习方法通常在主动学习环境中进行研究，代理直接与环境互动，观察行动结果，并通过试错学习。然而，允许部分训练代理与真实物理系统交互会带来显著的挑战，包括高成本、安全风险和需要持续监督。离线强化学习通过利用现有数据集并减少对资源密集型实时交互的需求来解决这些成本和安全问题。然而，一个重要的挑战在于需要精心注释这些数据集的奖励。在本文中，我们介绍了一种创新的算法，即最优输运奖励（OTR）标签，用于对离线轨迹分配奖励，使用少量高质量的专家演示。OTR的核心原理是利用最优输运计算无标签轨迹与专家演示之间的最优对齐方式。

    Most Reinforcement Learning (RL) methods are traditionally studied in an active learning setting, where agents directly interact with their environments, observe action outcomes, and learn through trial and error. However, allowing partially trained agents to interact with real physical systems poses significant challenges, including high costs, safety risks, and the need for constant supervision. Offline RL addresses these cost and safety concerns by leveraging existing datasets and reducing the need for resource-intensive real-time interactions. Nevertheless, a substantial challenge lies in the demand for these datasets to be meticulously annotated with rewards. In this paper, we introduce Optimal Transport Reward (OTR) labelling, an innovative algorithm designed to assign rewards to offline trajectories, using a small number of high-quality expert demonstrations. The core principle of OTR involves employing Optimal Transport (OT) to calculate an optimal alignment between an unlabele
    
[^51]: 大型语言模型作为个性化知识驱动对话的源计划器

    Large Language Models as Source Planner for Personalized Knowledge-grounded Dialogue. (arXiv:2310.08840v1 [cs.CL])

    [http://arxiv.org/abs/2310.08840](http://arxiv.org/abs/2310.08840)

    本研究提出了SAFARI框架，利用大型语言模型作为个性化知识驱动对话系统的源计划器，使得多个知识源的依赖关系能够被整合，并能生成一致的回应。

    

    开放域对话系统通常需要不同的知识源来生成更具信息性和证据性的回应。然而，现有的知识驱动对话系统要么专注于单一知识源，要么忽视了多个知识源之间的依赖关系，可能导致生成不一致甚至矛盾的回应。为了整合多个知识源和它们之间的依赖关系，我们提出了SAFARI，这是一个新颖的框架，利用了大型语言模型在监督和非监督设置下的出色能力来规划、理解和整合。具体而言，SAFARI将知识的基础分解为多个源和回应生成，从而方便地扩展到各种知识源，包括不使用任何源的可能性。为了研究这个问题，我们构建了一个个性化的、知识驱动的对话数据集。

    Open-domain dialogue system usually requires different sources of knowledge to generate more informative and evidential responses. However, existing knowledge-grounded dialogue systems either focus on a single knowledge source or overlook the dependency between multiple sources of knowledge, which may result in generating inconsistent or even paradoxical responses. To incorporate multiple knowledge sources and dependencies between them, we propose SAFARI, a novel framework that leverages the exceptional capabilities of large language models (LLMs) in planning, understanding, and incorporating under both supervised and unsupervised settings. Specifically, SAFARI decouples the knowledge grounding into multiple sources and response generation, which allows easy extension to various knowledge sources including the possibility of not using any sources. To study the problem, we construct a personalized knowledge-grounded dialogue dataset \textit{\textbf{K}nowledge \textbf{B}ehind \textbf{P}e
    
[^52]: 通过观察映射和行为克隆进行少样本策略转移的框架

    A Framework for Few-Shot Policy Transfer through Observation Mapping and Behavior Cloning. (arXiv:2310.08836v1 [cs.RO])

    [http://arxiv.org/abs/2310.08836](http://arxiv.org/abs/2310.08836)

    本文提出了一个通过观察映射和行为克隆进行少样本策略转移的框架，通过使用生成对抗网络和循环一致性损失来映射源领域和目标领域之间的观察，并利用这个映射来克隆源任务的成功策略。

    

    尽管强化学习在机器人应用中取得了一些进展，但由于昂贵的交互成本，许多任务仍然难以解决。迁移学习通过将在源领域学到的知识转移到目标领域，有助于减少目标领域的训练时间。Sim2Real迁移有助于将在模拟机器人领域学到的知识转移到物理目标领域。知识迁移减少了在交互成本高的物理世界中训练任务所需的时间。然而，大多数现有方法假设两个领域的任务结构和物理属性完全对应。本文提出了一个通过观察映射和行为克隆进行少样本策略转移的框架。我们使用生成对抗网络（GANs）和循环一致性损失来映射源领域和目标领域之间的观察，并且后续使用这个学到的映射来克隆源任务的成功策略。

    Despite recent progress in Reinforcement Learning for robotics applications, many tasks remain prohibitively difficult to solve because of the expensive interaction cost. Transfer learning helps reduce the training time in the target domain by transferring knowledge learned in a source domain. Sim2Real transfer helps transfer knowledge from a simulated robotic domain to a physical target domain. Knowledge transfer reduces the time required to train a task in the physical world, where the cost of interactions is high. However, most existing approaches assume exact correspondence in the task structure and the physical properties of the two domains. This work proposes a framework for Few-Shot Policy Transfer between two domains through Observation Mapping and Behavior Cloning. We use Generative Adversarial Networks (GANs) along with a cycle-consistency loss to map the observations between the source and target domains and later use this learned mapping to clone the successful source task 
    
[^53]: 城市无人机导航：自动编码器学习与空气动力学融合

    Urban Drone Navigation: Autoencoder Learning Fusion for Aerodynamics. (arXiv:2310.08830v1 [cs.RO])

    [http://arxiv.org/abs/2310.08830](http://arxiv.org/abs/2310.08830)

    本文提出了一种将多目标强化学习与卷积自动编码器相结合的方法，用于改进城市无人机在紧急搜索和救援中的导航能力。该方法通过利用城市布局图像数据，使无人机能够自主决策导航、优化路径并抵抗风效应，并在复杂的城市环境中提高了救援操作。

    

    由于在动态环境中以及存在建筑物和风等障碍物的挑战，无人机对于城市紧急搜索和救援（SAR）至关重要。本文提出了一种将多目标强化学习（MORL）与卷积自动编码器相结合的方法，以改进城市SAR中的无人机导航。该方法利用MORL实现多个目标，并利用自动编码器进行成本效益的风模拟。通过利用城市布局的图像数据，无人机可以自主做出导航决策，优化路径，并抵消传统传感器无法解决的风效应。在纽约市模型上进行测试，该方法提高了无人机在复杂城市环境中的SAR操作。

    Drones are vital for urban emergency search and rescue (SAR) due to the challenges of navigating dynamic environments with obstacles like buildings and wind. This paper presents a method that combines multi-objective reinforcement learning (MORL) with a convolutional autoencoder to improve drone navigation in urban SAR. The approach uses MORL to achieve multiple goals and the autoencoder for cost-effective wind simulations. By utilizing imagery data of urban layouts, the drone can autonomously make navigation decisions, optimize paths, and counteract wind effects without traditional sensors. Tested on a New York City model, this method enhances drone SAR operations in complex urban settings.
    
[^54]: Distance-rank感知顺序奖励学习用于具有次优演示的逆强化学习

    Distance-rank Aware Sequential Reward Learning for Inverse Reinforcement Learning with Sub-optimal Demonstrations. (arXiv:2310.08823v1 [cs.LG])

    [http://arxiv.org/abs/2310.08823](http://arxiv.org/abs/2310.08823)

    提出了Distance-rank感知顺序奖励学习（DRASRL）框架，旨在解决逆强化学习中轨迹排名模糊和奖励模糊的问题。

    

    逆强化学习（IRL）旨在基于收集到的专家演示明确推断出潜在的奖励函数。考虑到获取专家演示可能是昂贵的，当前IRL技术的重点是使用从次优演示中导出的奖励函数学习一个优于演示者的策略。然而，现有的IRL算法主要解决了在学习奖励函数时的轨迹排名模糊的挑战，却忽视了在进一步消除奖励模糊性方面，考虑轨迹之间的回报差异程度的关键作用。此外，需要注意的是，单个转换的奖励受到轨迹中的上下文信息的重要影响。为了解决这些问题，我们引入了Distance-rank感知顺序奖励学习（DRASRL）框架。与现有方法不同，DRASRL同时考虑了轨迹的排名和回报之间的差异度。

    Inverse reinforcement learning (IRL) aims to explicitly infer an underlying reward function based on collected expert demonstrations. Considering that obtaining expert demonstrations can be costly, the focus of current IRL techniques is on learning a better-than-demonstrator policy using a reward function derived from sub-optimal demonstrations. However, existing IRL algorithms primarily tackle the challenge of trajectory ranking ambiguity when learning the reward function. They overlook the crucial role of considering the degree of difference between trajectories in terms of their returns, which is essential for further removing reward ambiguity. Additionally, it is important to note that the reward of a single transition is heavily influenced by the context information within the trajectory. To address these issues, we introduce the Distance-rank Aware Sequential Reward Learning (DRASRL) framework. Unlike existing approaches, DRASRL takes into account both the ranking of trajectories
    
[^55]: 探索量表答题过程中反应时间序列与失眠严重程度之间的关系：一种机器学习方法

    Exploring the relationship between response time sequence in scale answering process and severity of insomnia: a machine learning approach. (arXiv:2310.08817v1 [cs.LG])

    [http://arxiv.org/abs/2310.08817](http://arxiv.org/abs/2310.08817)

    该研究发现量表答题过程中的反应时间与失眠严重程度之间存在关系，并开发了一种机器学习模型，可以根据反应时间数据预测参与者是否存在失眠。

    

    本研究旨在调查失眠与反应时间之间的关系，并利用反应时间数据开发一种机器学习模型来预测参与者是否存在失眠。通过设计一个移动应用程序，从2729名参与者那里收集到量表测试和反应时间数据。研究发现失眠症状的参与者与非失眠症状的参与者在总反应时间上存在显著差异（p <0.001）。在个体问题水平上观察到特定失眠方面的严重程度和反应时间之间的相关性。该机器学习模型在基于反应时间数据预测失眠症状方面表现出较高的预测准确度（0.743）。

    Objectives: The study aims to investigate the relationship between insomnia and response time. Additionally, it aims to develop a machine learning model to predict the presence of insomnia in participants using response time data. Methods: A mobile application was designed to administer scale tests and collect response time data from 2729 participants. The relationship between symptom severity and response time was explored, and a machine learning model was developed to predict the presence of insomnia. Results: The result revealed a statistically significant difference (p<.001) in the total response time between participants with or without insomnia symptoms. A correlation was observed between the severity of specific insomnia aspects and response times at the individual questions level. The machine learning model demonstrated a high predictive accuracy of 0.743 in predicting insomnia symptoms based on response time data. Conclusions: These findings highlight the potential utility of 
    
[^56]: DexCatch: 学习用灵巧的手捕捉任意物体

    DexCatch: Learning to Catch Arbitrary Objects with Dexterous Hands. (arXiv:2310.08809v1 [cs.RO])

    [http://arxiv.org/abs/2310.08809](http://arxiv.org/abs/2310.08809)

    本论文提出了一种稳定约束强化学习算法（SCRL），用于学习用灵巧的手捕捉多样化的物体。该算法在基线方法上取得了很大的优势，并且在未见过的物体上表现出了强大的零-shot迁移性能。

    

    在机器人领域中，实现类似于人类灵巧操纵的能力仍然是一个关键的研究领域。现有的研究主要集中在提高拿取和放置任务的成功率上。与拿取和放置相比，抛接行为有潜力在无需将物体运送到目的地的情况下提高拿取速度。然而，动态的灵巧操纵由于大量的动态接触而面临着稳定控制的重大挑战。在本文中，我们提出了一种稳定约束强化学习（SCRL）算法，用于学习用灵巧的手捕捉多样化的物体。该算法在基线方法上取得了很大的优势，并且学习到的策略在未见过的物体上表现出了强大的零-shot迁移性能。值得注意的是，即使手中的物体面向侧面非常不稳定，由于缺乏来自手掌的支撑，我们的方法仍然可以在最具挑战的任务中取得很高的成功率。我们还展示了学到的行为的视频演示和合作结果。

    Achieving human-like dexterous manipulation remains a crucial area of research in robotics. Current research focuses on improving the success rate of pick-and-place tasks. Compared with pick-and-place, throw-catching behavior has the potential to increase picking speed without transporting objects to their destination. However, dynamic dexterous manipulation poses a major challenge for stable control due to a large number of dynamic contacts. In this paper, we propose a Stability-Constrained Reinforcement Learning (SCRL) algorithm to learn to catch diverse objects with dexterous hands. The SCRL algorithm outperforms baselines by a large margin, and the learned policies show strong zero-shot transfer performance on unseen objects. Remarkably, even though the object in a hand facing sideward is extremely unstable due to the lack of support from the palm, our method can still achieve a high level of success in the most challenging task. Video demonstrations of learned behaviors and the co
    
[^57]: 通过认知科学原理推动人工智能中的感知研究

    Advancing Perception in Artificial Intelligence through Principles of Cognitive Science. (arXiv:2310.08803v1 [cs.AI])

    [http://arxiv.org/abs/2310.08803](http://arxiv.org/abs/2310.08803)

    通过研究认知科学，我们可以提供新的视角来改善人工智能的性能和效率，本篇综述研究主要关注感知的认知功能，通过比较认知科学和人工智能的各个过程，回顾了各个子学科的主要理论。

    

    尽管人工智能在迅猛发展中取得了许多成就，但在性能和资源效率方面仍存在问题和局限。由于人工智能研究人员将很大一部分性能标准基准定为人类智能，以认知科学为灵感的人工智能是一个有前途的研究领域。研究认知科学可以为构建人工智能研究的基本模块提供新的视角，从而改善性能和效率。本综述研究主要关注感知的认知功能，即接收来自周围环境的信号作为输入，并对其进行处理以理解环境的过程。特别是，我们通过认知科学和人工智能的视角研究和比较其各个过程。通过这项研究，我们回顾了当前认知科学（特别是神经科学、心理学和语言学）各个子学科的所有主要理论。

    Although artificial intelligence (AI) has achieved many feats at a rapid pace, there still exist open problems and fundamental shortcomings related to performance and resource efficiency. Since AI researchers benchmark a significant proportion of performance standards through human intelligence, cognitive sciences-inspired AI is a promising domain of research. Studying cognitive science can provide a fresh perspective to building fundamental blocks in AI research, which can lead to improved performance and efficiency. In this review paper, we focus on the cognitive functions of perception, which is the process of taking signals from one's surroundings as input, and processing them to understand the environment. Particularly, we study and compare its various processes through the lens of both cognitive sciences and AI. Through this study, we review all current major theories from various sub-disciplines of cognitive science (specifically neuroscience, psychology and linguistics), and dr
    
[^58]: DDMT: 用于多变量时间序列异常检测的去噪扩散掩膜Transformer模型

    DDMT: Denoising Diffusion Mask Transformer Models for Multivariate Time Series Anomaly Detection. (arXiv:2310.08800v1 [cs.LG])

    [http://arxiv.org/abs/2310.08800](http://arxiv.org/abs/2310.08800)

    本论文提出了一种名为DDMT的新框架，用于解决多变量时间序列异常检测中的噪声和弱身份映射问题。通过引入自适应动态邻居掩膜机制(ADNM)以及集成Transformer和去噪扩散模型，该框架可以有效地检测时间序列数据中的异常情况。

    

    多变量时间序列中的异常检测已经成为时间序列研究中的一个重要挑战，在欺诈检测、故障诊断和系统状态估计等各个领域具有重要的研究影响。近年来，基于重建的模型在检测时间序列数据中的异常方面显示出了很大的潜力。然而，由于数据规模和维度的快速增加，时间序列重建过程中的噪声和弱身份映射问题越来越突出。为了解决这个问题，我们引入了一种新的自适应动态邻居掩膜机制(ADNM)，将其与Transformer和去噪扩散模型相结合，创建了一种名为Denoising Diffusion Mask Transformer (DDMT) 的新框架，用于多变量时间序列异常检测。ADNM模块用于减轻数据重建过程中输入和输出特征之间的信息泄漏问题，从而缓解了弱身份映射问题。

    Anomaly detection in multivariate time series has emerged as a crucial challenge in time series research, with significant research implications in various fields such as fraud detection, fault diagnosis, and system state estimation. Reconstruction-based models have shown promising potential in recent years for detecting anomalies in time series data. However, due to the rapid increase in data scale and dimensionality, the issues of noise and Weak Identity Mapping (WIM) during time series reconstruction have become increasingly pronounced. To address this, we introduce a novel Adaptive Dynamic Neighbor Mask (ADNM) mechanism and integrate it with the Transformer and Denoising Diffusion Model, creating a new framework for multivariate time series anomaly detection, named Denoising Diffusion Mask Transformer (DDMT). The ADNM module is introduced to mitigate information leakage between input and output features during data reconstruction, thereby alleviating the problem of WIM during recon
    
[^59]: 对于压缩Transformer语言模型的任务不可知蒸馏方法的比较分析

    A Comparative Analysis of Task-Agnostic Distillation Methods for Compressing Transformer Language Models. (arXiv:2310.08797v1 [cs.CL])

    [http://arxiv.org/abs/2310.08797](http://arxiv.org/abs/2310.08797)

    本研究比较了用于压缩Transformer语言模型的几种任务不可知蒸馏方法，并发现基于MiniLMv2的MHA转移是最佳选择。

    

    大型语言模型已经成为现代自然语言处理(NLP)中至关重要的组件，在各种任务中实现了最先进的性能。然而，由于昂贵的推断成本，它们在实际部署中常常效率低下。知识蒸馏是一种提高其效率并保持大部分效能的有希望的技术。在本文中，我们重现、比较和分析了几种代表性的、用于Transformer语言模型任务不可知(通用)蒸馏的方法。我们研究了输出分布(OD)转移、隐藏状态(HS)转移以及基于MiniLMv2的多头注意力(MHA)转移等多种蒸馏方法在各种学生架构下的有效性，包括单语(英语)和多语设置。总体而言，我们发现基于MiniLMv2的MHA转移通常是蒸馏的最佳选择，并解释了潜在的原因。

    Large language models have become a vital component in modern NLP, achieving state of the art performance in a variety of tasks. However, they are often inefficient for real-world deployment due to their expensive inference costs. Knowledge distillation is a promising technique to improve their efficiency while retaining most of their effectiveness. In this paper, we reproduce, compare and analyze several representative methods for task-agnostic (general-purpose) distillation of Transformer language models. Our target of study includes Output Distribution (OD) transfer, Hidden State (HS) transfer with various layer mapping strategies, and Multi-Head Attention (MHA) transfer based on MiniLMv2. Through our extensive experiments, we study the effectiveness of each method for various student architectures in both monolingual (English) and multilingual settings. Overall, we show that MHA transfer based on MiniLMv2 is generally the best option for distillation and explain the potential reaso
    
[^60]: 通过追踪偏见影响来减轻问题回答模型的偏见

    Mitigating Bias for Question Answering Models by Tracking Bias Influence. (arXiv:2310.08795v1 [cs.CL])

    [http://arxiv.org/abs/2310.08795](http://arxiv.org/abs/2310.08795)

    本论文提出了一种名为BMBI的方法来减轻多选问题回答模型的偏见。通过观察一个查询实例对另一个实例的影响，测量查询实例的偏见程度，并将其作为优化目标，形成一个多任务学习设置。同时引入新的偏见评估指标以量化偏见。

    

    已经证明各种NLP任务的模型存在刻板印象，而问题回答（QA）模型中的偏见尤其有害，因为输出的答案可能直接被最终用户使用。已经有数据集用于评估QA模型中的偏见，但是对于QA模型的偏见缓解技术仍处于探索阶段。本工作中，我们提出了一种名为BMBI的方法，用于缓解多选问题回答模型的偏见。基于一个直觉，即如果一个模型从一个有偏见的例子中学到了东西，它可能更容易出现偏见，我们通过观察一个查询实例对另一个实例的影响来衡量查询实例的偏见程度。如果受到影响的实例更偏见，我们认为查询实例是有偏见的。我们使用检测到的偏见程度作为优化目标，形成一个多任务学习设置，除了原来的QA任务。我们还引入了一种新的偏见评估指标，以全面而敏感的方式量化偏见。我们展示了我们的方法可以应用于减轻QA模型的偏见。

    Models of various NLP tasks have been shown to exhibit stereotypes, and the bias in the question answering (QA) models is especially harmful as the output answers might be directly consumed by the end users. There have been datasets to evaluate bias in QA models, while bias mitigation technique for the QA models is still under-explored. In this work, we propose BMBI, an approach to mitigate the bias of multiple-choice QA models. Based on the intuition that a model would lean to be more biased if it learns from a biased example, we measure the bias level of a query instance by observing its influence on another instance. If the influenced instance is more biased, we derive that the query instance is biased. We then use the bias level detected as an optimization objective to form a multi-task learning setting in addition to the original QA task. We further introduce a new bias evaluation metric to quantify bias in a comprehensive and sensitive way. We show that our method could be applie
    
[^61]: 质量感知联邦学习中的稳定成本

    Price of Stability in Quality-Aware Federated Learning. (arXiv:2310.08790v1 [cs.LG])

    [http://arxiv.org/abs/2310.08790](http://arxiv.org/abs/2310.08790)

    本论文提出了一种质量感知的联邦学习方案，研究了标签噪声对系统性能的影响，并设计了一种游戏模型来理解客户端的行为。研究结果表明均衡结果的全局模型准确度低于社会最优解，并提出了一种高效算法来计算。

    

    联邦学习是一种分布式机器学习方案，可以使客户端在不交换本地数据的情况下训练一个共享的全局模型。标签噪声的存在会严重影响联邦学习的性能，一些现有研究已经关注了用于标签去噪的算法设计。然而，它们忽视了一个重要问题，即由于自利性和对联邦学习性能的异质估值，客户端可能不会应用昂贵的标签去噪策略。为了填补这一空白，我们将客户端之间的互动建模为一种新颖的标签去噪博弈，并确定其均衡状态。我们还分析了稳定成本，该成本用来衡量均衡结果与社会最优解之间的系统性能差异（例如，全局模型准确度、社会福利）。我们证明了均衡结果的全局模型准确度始终低于社会最优解。我们进一步设计了一种高效算法来计算。

    Federated Learning (FL) is a distributed machine learning scheme that enables clients to train a shared global model without exchanging local data. The presence of label noise can severely degrade the FL performance, and some existing studies have focused on algorithm design for label denoising. However, they ignored the important issue that clients may not apply costly label denoising strategies due to them being self-interested and having heterogeneous valuations on the FL performance. To fill this gap, we model the clients' interactions as a novel label denoising game and characterize its equilibrium. We also analyze the price of stability, which quantifies the difference in the system performance (e.g., global model accuracy, social welfare) between the equilibrium outcome and the socially optimal solution. We prove that the equilibrium outcome always leads to a lower global model accuracy than the socially optimal solution does. We further design an efficient algorithm to compute 
    
[^62]: DeltaSpace:一种用于灵活文本引导图像编辑的语义对齐特征空间

    DeltaSpace: A Semantic-aligned Feature Space for Flexible Text-guided Image Editing. (arXiv:2310.08785v1 [cs.CV])

    [http://arxiv.org/abs/2310.08785](http://arxiv.org/abs/2310.08785)

    本文提出了一种名为DeltaSpace的特征空间，用于灵活文本引导图像编辑。在DeltaSpace的基础上，通过一种称为DeltaEdit的新颖框架，将CLIP视觉特征差异映射到潜在空间方向，并从CLIP预测潜在空间方向，解决了训练和推理灵活性的挑战。

    

    文本引导图像编辑面临着训练和推理灵活性的重大挑战。许多文献通过收集大量标注的图像-文本对来从头开始训练文本条件生成模型，这既昂贵又低效。然后，一些利用预训练的视觉语言模型的方法出现了，以避免数据收集，但它们仍然受到基于每个文本提示的优化或推理时的超参数调整的限制。为了解决这些问题，我们调查和确定了一个特定的空间，称为CLIP DeltaSpace，在这个空间中，两个图像的CLIP视觉特征差异与其对应的文本描述的CLIP文本特征差异在语义上是对齐的。基于DeltaSpace，我们提出了一个新颖的框架DeltaEdit，在训练阶段将CLIP视觉特征差异映射到生成模型的潜在空间方向，并从CLIP预测潜在空间方向。

    Text-guided image editing faces significant challenges to training and inference flexibility. Much literature collects large amounts of annotated image-text pairs to train text-conditioned generative models from scratch, which is expensive and not efficient. After that, some approaches that leverage pre-trained vision-language models are put forward to avoid data collection, but they are also limited by either per text-prompt optimization or inference-time hyper-parameters tuning. To address these issues, we investigate and identify a specific space, referred to as CLIP DeltaSpace, where the CLIP visual feature difference of two images is semantically aligned with the CLIP textual feature difference of their corresponding text descriptions. Based on DeltaSpace, we propose a novel framework called DeltaEdit, which maps the CLIP visual feature differences to the latent space directions of a generative model during the training phase, and predicts the latent space directions from the CLIP
    
[^63]: 选择性驱动生产力：增强迁移学习的高效数据集修剪

    Selectivity Drives Productivity: Efficient Dataset Pruning for Enhanced Transfer Learning. (arXiv:2310.08782v1 [cs.LG])

    [http://arxiv.org/abs/2310.08782](http://arxiv.org/abs/2310.08782)

    本论文提出了一种解决迁移学习中数据集修剪的方法，通过集成数据集修剪和迁移学习的观点，发现现有的方法不适用于迁移学习范式，并提出了标签映射和特征映射这两种新的数据集修剪方法。

    

    大规模数据通常被认为是深度学习应用的必要条件，但同时也会带来巨大的计算和基础设施成本。因此，数据集修剪（DP）作为一种有效的方法出现，通过识别和删除冗余的训练样本来提高数据效率，而不会影响性能。在这项工作中，我们旨在解决迁移学习中的DP问题，即如何在下游目标任务中提高预训练效率和完整微调准确性的同时修剪源数据集。据我们所知，迁移学习的DP问题仍然未解决，因为先前的研究主要将DP和迁移学习视为独立的问题。相反，我们建立了一个统一的视角，将DP与迁移学习相结合，并发现现有的DP方法不适用于迁移学习范式。然后，我们提出了两种新的DP方法，即标签映射和特征映射，用于监督和自监督的预训练设置。

    Massive data is often considered essential for deep learning applications, but it also incurs significant computational and infrastructural costs. Therefore, dataset pruning (DP) has emerged as an effective way to improve data efficiency by identifying and removing redundant training samples without sacrificing performance. In this work, we aim to address the problem of DP for transfer learning, i.e., how to prune a source dataset for improved pretraining efficiency and lossless finetuning accuracy on downstream target tasks. To our best knowledge, the problem of DP for transfer learning remains open, as previous studies have primarily addressed DP and transfer learning as separate problems. By contrast, we establish a unified viewpoint to integrate DP with transfer learning and find that existing DP methods are not suitable for the transfer learning paradigm. We then propose two new DP methods, label mapping and feature mapping, for supervised and self-supervised pretraining settings 
    
[^64]: “我不是种族主义者，但是……”：揭示大型语言模型内部知识中的偏见

    "Im not Racist but...": Discovering Bias in the Internal Knowledge of Large Language Models. (arXiv:2310.08780v1 [cs.CL])

    [http://arxiv.org/abs/2310.08780](http://arxiv.org/abs/2310.08780)

    本文介绍了一种纯提示式的方法，用于揭示大型语言模型中隐藏的刻板印象，通过动态生成内部刻板印象的知识表示，我们能够识别这些模型中存在的偏见。这项工作在推进透明度和促进自然语言处理系统的公平性方面做出了贡献。

    

    大型语言模型（LLM）因其在不断扩展的自然语言处理任务中的出色表现而受到了极大关注。然而，这些模型被证明存在内在的社会偏见或刻板印象，这可能会对它们在许多下游应用中的性能产生不利影响。本文提出了一种全新的纯提示式方法，用于揭示任意LLM中隐藏的刻板印象。我们的方法动态生成了内部刻板印象的知识表示，从而能够识别LLM内部知识中编码的偏见。通过揭示LLM中存在的偏见并提供一种系统性的分析方法，我们的工作在推进透明度和促进自然语言处理系统的公平性方面做出了贡献。

    Large language models (LLMs) have garnered significant attention for their remarkable performance in a continuously expanding set of natural language processing tasks. However, these models have been shown to harbor inherent societal biases, or stereotypes, which can adversely affect their performance in their many downstream applications. In this paper, we introduce a novel, purely prompt-based approach to uncover hidden stereotypes within any arbitrary LLM. Our approach dynamically generates a knowledge representation of internal stereotypes, enabling the identification of biases encoded within the LLM's internal knowledge. By illuminating the biases present in LLMs and offering a systematic methodology for their analysis, our work contributes to advancing transparency and promoting fairness in natural language processing systems.
    
[^65]: 探究ChatGPT在科学与工程问题解决中的潜力与困境

    Examining the Potential and Pitfalls of ChatGPT in Science and Engineering Problem-Solving. (arXiv:2310.08773v1 [cs.AI])

    [http://arxiv.org/abs/2310.08773](http://arxiv.org/abs/2310.08773)

    ChatGPT被用于解决物理问题，发现在解决明确规定的问题时准确率较高，但在解决未明确规定的问题时准确率较低。错误解的分析揭示了三种失败模式，并探讨了如何利用LLM增强的教材提升STEM教育。这些观察结果对于AI的优势和局限性也有贡献。

    

    该研究探索了OpenAI的ChatGPT在解决不同类型的物理问题上的能力。使用ChatGPT（具有GPT-4）来解决了来自大学级工程物理课程的40个问题。这些问题范围从有明确规定的问题（提供了解决问题所需的所有数据）到未明确规定的现实世界问题（未提供所有必要数据）不等。我们的研究结果表明，ChatGPT可以成功解决62.5％的有明确规定的问题，但对于未明确规定的问题，其准确率下降到8.3％。对模型的错误解的分析揭示了三种不同的失败模式：1）无法构建准确的物理世界模型，2）无法对缺失数据做出合理的假设，以及3）计算错误。该研究为如何利用LLM增强的教学材料来提升STEM教育提供了启示。这些观察结果还对AI的优势和局限性的广泛讨论作出了贡献。

    The study explores the capabilities of OpenAI's ChatGPT in solving different types of physics problems. ChatGPT (with GPT-4) was queried to solve a total of 40 problems from a college-level engineering physics course. These problems ranged from well-specified problems, where all data required for solving the problem was provided, to under-specified, real-world problems where not all necessary data were given. Our findings show that ChatGPT could successfully solve 62.5\% of the well-specified problems, but its accuracy drops to 8.3\% for under-specified problems. Analysis of the model's incorrect solutions revealed three distinct failure modes: 1) failure to construct accurate models of the physical world, 2) failure to make reasonable assumptions about missing data, and 3) calculation errors. The study offers implications for how to leverage LLM-augmented instructional materials to enhance STEM education. The insights also contribute to the broader discourse on AI's strengths and limi
    
[^66]: EEG分类中采用发散估计稳定主体迁移

    Stabilizing Subject Transfer in EEG Classification with Divergence Estimation. (arXiv:2310.08762v1 [cs.LG])

    [http://arxiv.org/abs/2310.08762](http://arxiv.org/abs/2310.08762)

    本研究在EEG分类中使用新的正则化技术减少了在未见测试对象上的性能下降。通过设计正则化惩罚和发散估计算法，我们成功地在模型训练中强制执行了统计关系，并在大量计算实验中验证了我们的方法的有效性。

    

    电encephalogram(EEG)数据的分类模型在未见测试对象上的表现大幅下降。我们通过新的正则化技术减少性能下降问题。我们提出了几个图模型来描述EEG分类任务。从每个模型中，我们确定了在理想的训练场景下（具有无限数据和全局最优模型），应该成立但在实践中可能不成立的统计关系。我们设计了正则化惩罚来强制执行这些关系。首先，我们确定了适用作为代理数量的合适的发散（如互信息和Wasserstein-1），可以用来测量统计独立和相关关系。其次，我们提供了使用二次神经网络模型在训练过程中高效估计这些数量的算法。我们使用大型基准EEG数据集进行了大量的计算实验，比较了我们的方法与其他方法。

    Classification models for electroencephalogram (EEG) data show a large decrease in performance when evaluated on unseen test sub jects. We reduce this performance decrease using new regularization techniques during model training. We propose several graphical models to describe an EEG classification task. From each model, we identify statistical relationships that should hold true in an idealized training scenario (with infinite data and a globally-optimal model) but that may not hold in practice. We design regularization penalties to enforce these relationships in two stages. First, we identify suitable proxy quantities (divergences such as Mutual Information and Wasserstein-1) that can be used to measure statistical independence and dependence relationships. Second, we provide algorithms to efficiently estimate these quantities during training using secondary neural network models. We conduct extensive computational experiments using a large benchmark EEG dataset, comparing our propo
    
[^67]: CompA: 解决音频-语言模型中的组合推理差距

    CompA: Addressing the Gap in Compositional Reasoning in Audio-Language Models. (arXiv:2310.08753v1 [cs.SD])

    [http://arxiv.org/abs/2310.08753](http://arxiv.org/abs/2310.08753)

    CompA提出了由两个专家注释的音频-语言模型组合推理基准数据集，用于评估ALMs在理解音频中声音事件的顺序和属性绑定方面的表现。

    

    音频的基本特性是其组合性。使用对比方法（例如CLAP）训练的音频-语言模型（ALMs）能够学习音频和语言模态之间的共享表示，从而在许多下游应用中提高性能，包括零样本音频分类、音频检索等。然而，这些模型在有效执行组合推理方面的能力还很少被探索，需要进一步的研究。本文提出了CompA，这是一个由两个专家注释的基准数据集，其中大多数是真实世界的音频样本，用于评估ALMs的组合推理能力。我们的CompA-order评估ALMs在理解音频中声音事件的顺序或发生时的表现如何，而CompA-attribute评估声音事件的属性绑定。每个基准数据集中的实例包含两个音频-标题对，其中两个音频具有相同的声音事件，但组合方式不同。

    A fundamental characteristic of audio is its compositional nature. Audio-language models (ALMs) trained using a contrastive approach (e.g., CLAP) that learns a shared representation between audio and language modalities have improved performance in many downstream applications, including zero-shot audio classification, audio retrieval, etc. However, the ability of these models to effectively perform compositional reasoning remains largely unexplored and necessitates additional research. In this paper, we propose CompA, a collection of two expert-annotated benchmarks with a majority of real-world audio samples, to evaluate compositional reasoning in ALMs. Our proposed CompA-order evaluates how well an ALM understands the order or occurrence of acoustic events in audio, and CompA-attribute evaluates attribute binding of acoustic events. An instance from either benchmark consists of two audio-caption pairs, where both audios have the same acoustic events but with different compositions. A
    
[^68]: 带有自适应主动学习未知约束的约束贝叶斯优化

    Constrained Bayesian Optimization with Adaptive Active Learning of Unknown Constraints. (arXiv:2310.08751v1 [cs.LG])

    [http://arxiv.org/abs/2310.08751](http://arxiv.org/abs/2310.08751)

    本文探讨了约束贝叶斯优化的理论和实际问题，提出了一种带有自适应主动学习未知约束的方法，在处理复杂约束场景时具有理论保证。

    

    在现实世界中，如科学实验设计、医学治疗设计和工业过程优化等领域，优化目标在约束条件下的情况是常见的，其中目标和约束都是黑盒函数。处理这些复杂场景的一种常用方法是贝叶斯优化（BO）。在理论行为方面，BO在无约束设置下相对较为理解，其原则已经被广泛探索和验证。然而，对于约束贝叶斯优化（CBO）来说，现有框架往往依赖于启发式方法或近似方法，没有同样程度的理论保证。在本文中，我们深入研究了约束贝叶斯优化的理论和实际问题，其中目标和约束可以独立评估且受到噪声的影响。通过认识到目标和约束都可以帮助识别高置信度的兴趣区域，

    Optimizing objectives under constraints, where both the objectives and constraints are black box functions, is a common scenario in real-world applications such as scientific experimental design, design of medical therapies, and industrial process optimization. One popular approach to handling these complex scenarios is Bayesian Optimization (BO). In terms of theoretical behavior, BO is relatively well understood in the unconstrained setting, where its principles have been well explored and validated. However, when it comes to constrained Bayesian optimization (CBO), the existing framework often relies on heuristics or approximations without the same level of theoretical guarantees.  In this paper, we delve into the theoretical and practical aspects of constrained Bayesian optimization, where the objective and constraints can be independently evaluated and are subject to noise. By recognizing that both the objective and constraints can help identify high-confidence regions of interest 
    
[^69]: 基于深度学习的微卫星不稳定性预测器的开发和验证，来自于前列腺癌全切片图像

    Development and Validation of a Deep Learning-Based Microsatellite Instability Predictor from Prostate Cancer Whole-Slide Images. (arXiv:2310.08743v1 [cs.CV])

    [http://arxiv.org/abs/2310.08743](http://arxiv.org/abs/2310.08743)

    本研究开发和验证了一种基于深度学习的微卫星不稳定性预测器，可以从前列腺癌全切片图像中预测MSI状态，有助于识别最有可能受益于免疫治疗的患者。

    

    微卫星不稳定性高（MSI-H）是免疫检查点抑制剂疗法的一种肿瘤不可知标志物。然而，在前列腺癌中，由于低患病率和检测成本较高，MSI状态通常不进行常规测试。因此，从血液染色剂靛蓝和伊红（H&E）染色的全切片图像（WSIs）中预测MSI状态，可以识别出最有可能受益于确认测试并有资格接受免疫治疗的前列腺癌患者。分析了连续转诊至我们机构的前列腺癌患者的去匿名记录中的前列腺活检和手术切除标本。通过下一代测序确定了他们的MSI状态。在截止日期之前的患者分为算法开发集（n=4015, MSI-H 1.8%）和配对验证集（n=173, MSI-H 19.7%），每个样本由两个连续的切片组成，一个内部染色和扫描，另一个在外部某个地点。截止日期之后的患者形成了时间验证集。

    Microsatellite instability-high (MSI-H) is a tumor agnostic biomarker for immune checkpoint inhibitor therapy. However, MSI status is not routinely tested in prostate cancer, in part due to low prevalence and assay cost. As such, prediction of MSI status from hematoxylin and eosin (H&E) stained whole-slide images (WSIs) could identify prostate cancer patients most likely to benefit from confirmatory testing and becoming eligible for immunotherapy. Prostate biopsies and surgical resections from de-identified records of consecutive prostate cancer patients referred to our institution were analyzed. Their MSI status was determined by next generation sequencing. Patients before a cutoff date were split into an algorithm development set (n=4015, MSI-H 1.8%) and a paired validation set (n=173, MSI-H 19.7%) that consisted of two serial sections from each sample, one stained and scanned internally and the other at an external site. Patients after the cutoff date formed the temporal validation 
    
[^70]: 利用随机森林和时态卷积网络实现石油产业更可持续的实时事件检测

    Real-Time Event Detection with Random Forests and Temporal Convolutional Networks for More Sustainable Petroleum Industry. (arXiv:2310.08737v1 [cs.AI])

    [http://arxiv.org/abs/2310.08737](http://arxiv.org/abs/2310.08737)

    通过随机森林和时态卷积网络，本论文提出了一种实时检测不希望事件的方法，可以有效地分类事件类型并预测其出现的概率，为生产过程中的故障事件管理提供更有效的解决方案。

    

    石油产业对现代社会至关重要，但生产过程复杂且风险高。在生产过程中，由于不希望的生产事件导致的事故或故障可能会造成严重的环境和经济损失。以往的研究已经调研了机器学习方法用于不希望事件的检测，但对于实时事件概率的预测并没有得到充分解决，而这一点非常重要，因为及早干预是预计事件发生时的重要措施。本文提出了两种机器学习方法，随机森林和时态卷积网络，用于实时检测不希望的事件。结果表明我们的方法可以有效地对事件类型进行分类并预测其出现的概率，解决了以往研究中发现的挑战，为生产过程中的故障事件管理提供更有效的解决方案。

    The petroleum industry is crucial for modern society, but the production process is complex and risky. During the production, accidents or failures, resulting from undesired production events, can cause severe environmental and economic damage. Previous studies have investigated machine learning (ML) methods for undesired event detection. However, the prediction of event probability in real-time was insufficiently addressed, which is essential since it is important to undertake early intervention when an event is expected to happen. This paper proposes two ML approaches, random forests and temporal convolutional networks, to detect undesired events in real-time. Results show that our approaches can effectively classify event types and predict the probability of their appearance, addressing the challenges uncovered in previous studies and providing a more effective solution for failure event management during the production.
    
[^71]: 一个简单的方法在世界模型中实现新颖性检测

    A Simple Way to Incorporate Novelty Detection in World Models. (arXiv:2310.08731v1 [cs.AI])

    [http://arxiv.org/abs/2310.08731](http://arxiv.org/abs/2310.08731)

    本文提出了一个简单的方法，通过利用世界模型幻觉状态和真实观察状态的不匹配性作为异常分数，将新颖性检测纳入世界模型强化学习代理中。在新环境中与传统方法相比，我们的工作具有优势。

    

    使用世界模型进行强化学习已经取得了显著的成功。然而，当世界机制或属性发生突然变化时，代理的性能和可靠性可能会显著下降。我们将视觉属性或状态转换的突变称为“新颖性”。在生成的世界模型框架中实施新颖性检测是保护部署时代理的关键任务。在本文中，我们提出了一种简单的边界方法，用于将新颖性检测纳入世界模型强化学习代理中，通过利用世界模型幻觉状态和真实观察状态的不匹配性作为异常分数。首先，我们提供了与序列决策相关的新颖性检测本体论，然后我们提供了在代理在世界模型中学习的转换分布中检测新颖性的有效方法。最后，我们展示了我们的工作在新环境中与传统方法相比的优势。

    Reinforcement learning (RL) using world models has found significant recent successes. However, when a sudden change to world mechanics or properties occurs then agent performance and reliability can dramatically decline. We refer to the sudden change in visual properties or state transitions as {\em novelties}. Implementing novelty detection within generated world model frameworks is a crucial task for protecting the agent when deployed. In this paper, we propose straightforward bounding approaches to incorporate novelty detection into world model RL agents, by utilizing the misalignment of the world model's hallucinated states and the true observed states as an anomaly score. We first provide an ontology of novelty detection relevant to sequential decision making, then we provide effective approaches to detecting novelties in a distribution of transitions learned by an agent in a world model. Finally, we show the advantage of our work in a novel environment compared to traditional ma
    
[^72]: Transformer Choice Net: 一种用于选择预测的Transformer神经网络

    Transformer Choice Net: A Transformer Neural Network for Choice Prediction. (arXiv:2310.08716v1 [cs.LG])

    [http://arxiv.org/abs/2310.08716](http://arxiv.org/abs/2310.08716)

    本论文介绍了一种适用于预测多个选择的Transformer神经网络架构，通过考虑顾客和项目的特征，以及上下文信息（如可选项的范围和定制需求），解决了离散选择模型在顾客选择多个项目时的挑战。

    

    在市场营销、经济学和运筹学中，离散选择模型，如多项式逻辑模型、Probit模型或混合逻辑模型广泛使用：给定一组可选项，顾客被模拟为选择其中之一以最大化（潜在的）效用函数。然而，将这些模型推广到顾客选择多个项目的情况（如电子商务购物）却存在问题。虽然可以建立合理的顾客行为模型，但由于项目子集的组合爆炸，对于这些模型的估计变得非常具有挑战性。在本文中，我们开发了一种有助于预测多个选择的Transformer神经网络架构，即Transformer Choice Net。事实证明，Transformer网络对于这个任务特别适用，因为它们不仅考虑了顾客和项目的特征，还考虑了上下文，即可选项的范围以及定制化需求。

    Discrete-choice models, such as Multinomial Logit, Probit, or Mixed-Logit, are widely used in Marketing, Economics, and Operations Research: given a set of alternatives, the customer is modeled as choosing one of the alternatives to maximize a (latent) utility function. However, extending such models to situations where the customer chooses more than one item (such as in e-commerce shopping) has proven problematic. While one can construct reasonable models of the customer's behavior, estimating such models becomes very challenging because of the combinatorial explosion in the number of possible subsets of items. In this paper we develop a transformer neural network architecture, the Transformer Choice Net, that is suitable for predicting multiple choices. Transformer networks turn out to be especially suitable for this task as they take into account not only the features of the customer and the items but also the context, which in this case could be the assortment as well as the custom
    
[^73]: 迈向语音单元和文本的联合语言建模

    Toward Joint Language Modeling for Speech Units and Text. (arXiv:2310.08715v1 [cs.CL])

    [http://arxiv.org/abs/2310.08715](http://arxiv.org/abs/2310.08715)

    本文研究了联合语言建模中语音单元和文本的混合方法，并通过口语理解任务评估了模型的性能，结果表明混合语言模型优于仅使用语音的基线模型。

    

    语音和文本是人类语言的两种主要形式。研究界多年来一直在关注将语音映射到文本或者反之亦然。然而，在语言建模领域，很少有人尝试联合建模这两者。基于此，我们探索了语音单元和文本的联合语言建模。具体而言，我们比较了不同的语音分词工具，将连续的语音信号转化为离散的单元，并使用不同的方法构建混合的语音-文本数据。我们引入了自动指标来评估联合语言建模的语音和文本融合效果。我们还使用不同的模态（语音或文本）在下游的口语理解任务上对联合语言模型进行了微调，并测试其性能以评估模型对共享表示的学习能力。我们的结果表明，在使用我们提出的混合技术将语音单元和文本混合的情况下，联合语言模型在口语理解任务上优于仅使用语音的基线模型，并展示了零-shot的跨模态迁移能力。

    Speech and text are two major forms of human language. The research community has been focusing on mapping speech to text or vice versa for many years. However, in the field of language modeling, very little effort has been made to model them jointly. In light of this, we explore joint language modeling for speech units and text. Specifically, we compare different speech tokenizers to transform continuous speech signals into discrete units and use different methods to construct mixed speech-text data. We introduce automatic metrics to evaluate how well the joint LM mixes speech and text. We also fine-tune the LM on downstream spoken language understanding (SLU) tasks with different modalities (speech or text) and test its performance to assess the model's learning of shared representations. Our results show that by mixing speech units and text with our proposed mixing techniques, the joint LM improves over a speech-only baseline on SLU tasks and shows zero-shot cross-modal transferabil
    
[^74]: ELDEN: 基于本地依赖的探索

    ELDEN: Exploration via Local Dependencies. (arXiv:2310.08702v1 [cs.LG])

    [http://arxiv.org/abs/2310.08702](http://arxiv.org/abs/2310.08702)

    在具有复杂依赖关系的环境中，我们提出了ELDEN，一种新的内在奖励，通过使用代理对实体之间的相互影响的不确定性，鼓励有效地探索状态空间。

    

    对于具有大状态空间和稀疏奖励的任务，强化学习一直面临着困难。在这些任务中，代理需要有效地探索状态空间，直到找到奖励。为了解决这个问题，社区提出了使用内在奖励来增强奖励函数的方法，内在奖励是一种鼓励代理访问有趣状态的奖励信号。在本文中，我们提出了一种新的方式来定义具有因式状态空间和复杂依赖关系的环境中的有趣状态，其中代理的动作可能会改变一个实体的值，进而可能影响另一个实体的值。我们的观点是，在这些环境中，探索有趣状态的关键是代理不确定实体（如代理或物体）是否相互影响，而不仅仅是如何相互影响。我们提出了"ELDEN: 基于本地依赖的探索"，这是一种新颖的内在奖励，促进了对新的相互作用的发现。

    Tasks with large state space and sparse rewards present a longstanding challenge to reinforcement learning. In these tasks, an agent needs to explore the state space efficiently until it finds a reward. To deal with this problem, the community has proposed to augment the reward function with intrinsic reward, a bonus signal that encourages the agent to visit interesting states. In this work, we propose a new way of defining interesting states for environments with factored state spaces and complex chained dependencies, where an agent's actions may change the value of one entity that, in order, may affect the value of another entity. Our insight is that, in these environments, interesting states for exploration are states where the agent is uncertain whether (as opposed to how) entities such as the agent or objects have some influence on each other. We present ELDEN, Exploration via Local DepENdencies, a novel intrinsic reward that encourages the discovery of new interactions between en
    
[^75]: Atari强化学习的虚拟增强现实技术

    Virtual Augmented Reality for Atari Reinforcement Learning. (arXiv:2310.08683v1 [cs.LG])

    [http://arxiv.org/abs/2310.08683](http://arxiv.org/abs/2310.08683)

    本文研究了使用最先进的图像分割模型提高Atari强化学习智能体性能的方法

    

    强化学习在游戏领域取得了重大突破，尤其是谷歌DeepMind的AlphaGo击败了人类围棋冠军柯洁。这一胜利也得益于Atari学习环境(ALE)，ALE在RL研究中具有重要意义，促进了AlphaGo和其他RL算法的发展。当前的Atari视频游戏RL研究中，RL智能体对环境的感知基于Atari视频游戏屏幕的原始像素数据，且图像预处理很少。相反，最先进的ML研究在增强图像感知方面取得了突破，其中一个显著的例子是Meta Research的“任何物体”的分割模型(SAM)，它是一个能够在没有训练的情况下分割图像的基础模型。本文探讨一个新颖的方法论问题：像SAM这样的最先进图像分割模型能否提高RL智能体在玩Atari视频游戏时的性能。

    Reinforcement Learning (RL) has achieved significant milestones in the gaming domain, most notably Google DeepMind's AlphaGo defeating human Go champion Ken Jie. This victory was also made possible through the Atari Learning Environment (ALE): The ALE has been foundational in RL research, facilitating significant RL algorithm developments such as AlphaGo and others. In current Atari video game RL research, RL agents' perceptions of its environment is based on raw pixel data from the Atari video game screen with minimal image preprocessing. Contrarily, cutting-edge ML research, external to the Atari video game RL research domain, is focusing on enhancing image perception. A notable example is Meta Research's "Segment Anything Model" (SAM), a foundation model capable of segmenting images without prior training (zero-shot). This paper addresses a novel methodical question: Can state-of-the-art image segmentation models such as SAM improve the performance of RL agents playing Atari video g
    
[^76]: GPT模型能成为金融分析师吗？对模拟CFA考试中的ChatGPT和GPT-4进行评估

    Can GPT models be Financial Analysts? An Evaluation of ChatGPT and GPT-4 on mock CFA Exams. (arXiv:2310.08678v1 [cs.CL])

    [http://arxiv.org/abs/2310.08678](http://arxiv.org/abs/2310.08678)

    本研究评估了ChatGPT和GPT-4在金融分析上的能力，发现它们在模拟CFA考试中具有一定的表现，为将来进一步提升大型语言模型在金融推理方面的能力提供了启示。

    

    大型语言模型（LLM）在各种自然语言处理（NLP）任务中展现了出色的性能，通常能与甚至超越最先进的任务特定模型。本研究旨在评估LLM在金融推理能力方面的表现。我们利用特许金融分析师（CFA）考试的模拟题目对ChatGPT和GPT-4在金融分析中进行全面评估，考虑了零样本（ZS）、思路链（CoT）和少样本（FS）场景。我们对模型的性能和局限性进行了深入分析，并评估它们通过CFA考试的可能性。最后，我们提出了提高LLM在金融领域应用性的潜在策略和改进。在这个视角下，我们希望该研究为未来的研究继续通过严格评估来提升LLM在金融推理方面的能力铺平道路。

    Large Language Models (LLMs) have demonstrated remarkable performance on a wide range of Natural Language Processing (NLP) tasks, often matching or even beating state-of-the-art task-specific models. This study aims at assessing the financial reasoning capabilities of LLMs. We leverage mock exam questions of the Chartered Financial Analyst (CFA) Program to conduct a comprehensive evaluation of ChatGPT and GPT-4 in financial analysis, considering Zero-Shot (ZS), Chain-of-Thought (CoT), and Few-Shot (FS) scenarios. We present an in-depth analysis of the models' performance and limitations, and estimate whether they would have a chance at passing the CFA exams. Finally, we outline insights into potential strategies and improvements to enhance the applicability of LLMs in finance. In this perspective, we hope this work paves the way for future studies to continue enhancing LLMs for financial reasoning through rigorous evaluation.
    
[^77]: GDL-DS: 分布转换下几何深度学习的基准测试

    GDL-DS: A Benchmark for Geometric Deep Learning under Distribution Shifts. (arXiv:2310.08677v1 [cs.LG])

    [http://arxiv.org/abs/2310.08677](http://arxiv.org/abs/2310.08677)

    GDL-DS是一个基准测试，用于评估几何深度学习模型在具有分布转换的场景中的性能。它包括多个科学领域的评估数据集，并研究了不同级别的超出分布特征的信息访问。

    

    几何深度学习(GDL)在各个科学领域引起了广泛关注，主要是因为其擅长对具有复杂几何结构的数据进行建模。然而，很少有研究探索其在处理分布转换问题上的能力，这是许多相关应用中常见的挑战。为了弥补这一空白，我们提出了GDL-DS，这是一个全面的基准测试，旨在评估GDL模型在具有分布转换的场景中的性能。我们的评估数据集涵盖了从粒子物理学和材料科学到生物化学的不同科学领域，并包括各种分布转换，包括条件、协变和概念转换。此外，我们研究了来自超出分布的测试数据的信息访问的三个级别，包括没有超出分布的信息、只有带标签的超出分布特征和带有少数标签的超出分布特征。总体而言，我们的基准测试涉及30个不同的实验设置，并评估3种信息访问水平。

    Geometric deep learning (GDL) has gained significant attention in various scientific fields, chiefly for its proficiency in modeling data with intricate geometric structures. Yet, very few works have delved into its capability of tackling the distribution shift problem, a prevalent challenge in many relevant applications. To bridge this gap, we propose GDL-DS, a comprehensive benchmark designed for evaluating the performance of GDL models in scenarios with distribution shifts. Our evaluation datasets cover diverse scientific domains from particle physics and materials science to biochemistry, and encapsulate a broad spectrum of distribution shifts including conditional, covariate, and concept shifts. Furthermore, we study three levels of information access from the out-of-distribution (OOD) testing data, including no OOD information, only OOD features without labels, and OOD features with a few labels. Overall, our benchmark results in 30 different experiment settings, and evaluates 3 
    
[^78]: 在不探索的情况下学习联合波束成形的RL策略：一种批量约束的离策略方法

    Learning RL-Policies for Joint Beamforming Without Exploration: A Batch Constrained Off-Policy Approach. (arXiv:2310.08660v1 [cs.LG])

    [http://arxiv.org/abs/2310.08660](http://arxiv.org/abs/2310.08660)

    本研究提出了一种批量约束的离策略方法，用于解决联合波束成形的参数优化问题。通过使用深度强化学习技术，克服了传统方法中计算复杂度高和无法准确建模的难题。

    

    在这个项目中，我们考虑了网络参数优化的问题，以实现速率最大化。我们将其构建为功率控制、波束成形和干扰消除的联合优化问题。我们考虑了多个基站与多个用户设备通信的情况。由于穷举搜索的指数计算复杂度，我们使用深度强化学习（RL）技术来解决该非凸优化问题。现代通信系统以其难以准确建模的行为而臭名昭著。这限制了我们使用基于RL的算法，因为需要与环境进行交互以便代理能够高效地探索和学习。此外，由于失败的高成本，将算法部署在现实世界中进行探索和学习是不明智的。与先前提出的基于RL的解决方案（如基于深度Q网络（DQN）的控制）相比，我们提出采用一种离策略方法

    In this project, we consider the problem of network parameter optimization for rate maximization. We frame this as a joint optimization problem of power control, beam forming, and interference cancellation. We consider the setting where multiple Base Stations (BSs) are communicating with multiple user equipments (UEs). Because of the exponential computational complexity of brute force search, we instead solve this non-convex optimization problem using deep reinforcement learning (RL) techniques. The modern communication systems are notorious for their difficulty in exactly modeling their behaviour. This limits us in using RL based algorithms as interaction with the environment is needed for the agent to explore and learn efficiently. Further, it is ill advised to deploy the algorithm in real world for exploration and learning because of the high cost of failure. In contrast to the previous RL-based solutions proposed, such as deep-Q network (DQN) based control, we propose taking an off
    
[^79]: LoftQ: LoRA-Fine-Tuning-Aware Quantization for Large Language Models

    LoftQ: LoRA-Fine-Tuning-Aware Quantization for Large Language Models. (arXiv:2310.08659v1 [cs.CL])

    [http://arxiv.org/abs/2310.08659](http://arxiv.org/abs/2310.08659)

    本论文提出了LoftQ：一种针对大型语言模型的LoRA精调感知量化框架。该框架同时对LLM进行量化，并为LoRA精调找到适当的低秩初始化，以缓解量化模型和全精度模型之间的差异，并显著提高了下游任务的泛化能力。

    

    量化是为大型语言模型提供服务的不可或缺的技术，并最近被应用于LoRA精调中。本文关注在预训练模型上同时应用量化和LoRA精调的场景。在这种情况下，常常观察到完整精调和量化加LoRA精调方法之间在下游任务表现上存在一致的差距。为了解决这个问题，我们提出了LoftQ（LoRA-Fine-Tuning-aware Quantization）——一种新的量化框架，用于同时对LLM进行量化，并找到适当的低秩初始化来进行LoRA精调。这种初始化减轻了量化模型和全精度模型之间的差异，并显著提高了下游任务的泛化能力。我们在自然语言理解、问答、摘要和自然语言生成任务上评估了我们的方法。实验证明，我们的方法非常有效，在性能上优于现有的方法。

    Quantization is an indispensable technique for serving Large Language Models (LLMs) and has recently found its way into LoRA fine-tuning. In this work we focus on the scenario where quantization and LoRA fine-tuning are applied together on a pre-trained model. In such cases it is common to observe a consistent gap in the performance on downstream tasks between full fine-tuning and quantization plus LoRA fine-tuning approach. In response, we propose LoftQ (LoRA-Fine-Tuning-aware Quantization), a novel quantization framework that simultaneously quantizes an LLM and finds a proper low-rank initialization for LoRA fine-tuning. Such an initialization alleviates the discrepancy between the quantized and full-precision model and significantly improves the generalization in downstream tasks. We evaluate our method on natural language understanding, question answering, summarization, and natural language generation tasks. Experiments show that our method is highly effective and outperforms exis
    
[^80]: 在阿富汗武装冲突中通过文本数据进行死亡分类的分析：一种BERT方法。

    Analyzing Textual Data for Fatality Classification in Afghanistan's Armed Conflicts: A BERT Approach. (arXiv:2310.08653v1 [cs.LG])

    [http://arxiv.org/abs/2310.08653](http://arxiv.org/abs/2310.08653)

    这项研究利用BERT模型分析阿富汗武装冲突的文本数据，通过对事件的描述进行分类，判断其是否致命。模型在测试中表现出色。

    

    阿富汗在历史上经历了许多武装冲突，尤其是在过去的20年中；这些事件对人类生活产生了重大影响，包括军事人员和平民，可能导致死亡。在这项研究中，我们旨在利用最先进的机器学习技术，根据由武装冲突位置和事件数据项目（ACLED）数据集提供的文本描述，对阿富汗武装冲突的结果进行分类，判断其是否致命。该数据集包含从2021年8月至2023年3月在阿富汗发生的武装冲突的详细描述。提出的方法利用了BERT（双向编码器转换器的双向编码器表示），这是自然语言处理中的先进语言表示模型。分类器利用事件的原始文本描述来估计事件导致死亡的可能性。该模型在测试集上取得了令人印象深刻的性能。

    Afghanistan has witnessed many armed conflicts throughout history, especially in the past 20 years; these events have had a significant impact on human lives, including military and civilians, with potential fatalities. In this research, we aim to leverage state-of-the-art machine learning techniques to classify the outcomes of Afghanistan armed conflicts to either fatal or non-fatal based on their textual descriptions provided by the Armed Conflict Location & Event Data Project (ACLED) dataset. The dataset contains comprehensive descriptions of armed conflicts in Afghanistan that took place from August 2021 to March 2023. The proposed approach leverages the power of BERT (Bidirectional Encoder Representations from Transformers), a cutting-edge language representation model in natural language processing. The classifier utilizes the raw textual description of an event to estimate the likelihood of the event resulting in a fatality. The model achieved impressive performance on the test 
    
[^81]: 通过张量分解实现电网异常检测

    Electrical Grid Anomaly Detection via Tensor Decomposition. (arXiv:2310.08650v1 [cs.LG])

    [http://arxiv.org/abs/2310.08650](http://arxiv.org/abs/2310.08650)

    本论文提出了一种通过非负张量分解实现电网异常检测的方法。与之前的降维方法不同，该方法能够更准确地对SCADA系统进行建模，并检测出其中的异常行为。

    

    监控与数据采集系统（SCADA）经常作为电网分站的神经系统。这些系统实现了实时监控、数据采集、设备控制，并确保分站及其连接设备的平稳高效运行。之前的研究已经证明，基于降维的方法，如主成分分析（PCA），可以准确识别SCADA系统中的异常。虽然非负矩阵分解（NMF）并没有专门应用于SCADA，但它在无线传感器网络中检测异常方面表现出了良好的结果。这些无监督方法通过对正常或预期行为进行建模，识别偏离预期行为的事件，从而检测未知类型的攻击或异常。然而，这些方法没有对SCADA系统中自然存在的复杂多维交互进行建模。相比之下，非负张量分解方法能够对SCADA系统进行更准确的建模和异常检测。

    Supervisory Control and Data Acquisition (SCADA) systems often serve as the nervous system for substations within power grids. These systems facilitate real-time monitoring, data acquisition, control of equipment, and ensure smooth and efficient operation of the substation and its connected devices. Previous work has shown that dimensionality reduction-based approaches, such as Principal Component Analysis (PCA), can be used for accurate identification of anomalies in SCADA systems. While not specifically applied to SCADA, non-negative matrix factorization (NMF) has shown strong results at detecting anomalies in wireless sensor networks. These unsupervised approaches model the normal or expected behavior and detect the unseen types of attacks or anomalies by identifying the events that deviate from the expected behavior. These approaches; however, do not model the complex and multi-dimensional interactions that are naturally present in SCADA systems. Differently, non-negative tensor de
    
[^82]: 机器学习模型地球科学系统建模中的质量保持感知器

    A Mass-Conserving-Perceptron for Machine Learning-Based Modeling of Geoscientific Systems. (arXiv:2310.08644v1 [cs.LG])

    [http://arxiv.org/abs/2310.08644](http://arxiv.org/abs/2310.08644)

    这篇论文提出了一种质量保持感知器（MCP）用于将物理-概念模型和机器学习模型结合起来建模地球科学系统，通过利用机器学习技术从数据中学习物理过程的功能性和质量保持性。

    

    虽然数十年来致力于构建用于预测地球科学系统时间序列演化的物理-概念 (PC) 模型，但最近的研究表明，基于机器学习 (ML) 的门控循环神经网络技术可以用于开发更准确的模型。然而，从ML基础模型中提取物理理解的困难使得其在增强对系统结构和功能的科学知识方面的应用变得复杂。在这里，我们提出了一个理解物理性的质量保持感知器 (MCP) 作为弥合PC模型和ML模型的方法。MCP利用PC模型和GRNNs背后的有向图结构的内在同构性，以可解释的方式明确表示物理过程的质量保持性质，同时利用现有数据和现成的ML技术直接学习这种过程的功能性（可解释性）。

    Although decades of effort have been devoted to building Physical-Conceptual (PC) models for predicting the time-series evolution of geoscientific systems, recent work shows that Machine Learning (ML) based Gated Recurrent Neural Network technology can be used to develop models that are much more accurate. However, the difficulty of extracting physical understanding from ML-based models complicates their utility for enhancing scientific knowledge regarding system structure and function. Here, we propose a physically-interpretable Mass Conserving Perceptron (MCP) as a way to bridge the gap between PC-based and ML-based modeling approaches. The MCP exploits the inherent isomorphism between the directed graph structures underlying both PC models and GRNNs to explicitly represent the mass-conserving nature of physical processes while enabling the functional nature of such processes to be directly learned (in an interpretable manner) from available data using off-the-shelf ML technology. As
    
[^83]: AI决策中解释对公平性的影响：受保护特征 vs 代理特征

    The Impact of Explanations on Fairness in Human-AI Decision-Making: Protected vs Proxy Features. (arXiv:2310.08617v1 [cs.AI])

    [http://arxiv.org/abs/2310.08617](http://arxiv.org/abs/2310.08617)

    论文研究了解释对AI决策公平性的影响。结果发现，解释有助于人们检测直接偏见，但对间接偏见的发现能力有限。

    

    已知AI系统可能会放大现实世界数据中的偏见。解释可能有助于人工智能团队解决这些偏见，从而实现更公平的决策。通常，解释侧重于突出的输入特征。如果模型对某个受保护的群体存在偏见，则解释可能包括显示这种偏见的特征，但当偏见通过代理特征实现时，这个代理特征与受保护特征之间的关系可能对人类而言不太清晰。在这项工作中，我们研究受保护特征和代理特征对参与者对模型公平性和提高人口平衡能力的感知的影响。此外，我们还研究了不同处理方式（解释、模型偏见披露和代理相关性披露）对公平感知和平等性的影响。我们发现，解释有助于人们检测直接偏见，但无法发现间接偏见。此外，无论偏见类型如何，解释倾向于增加对模型偏见的认同度。

    AI systems have been known to amplify biases in real world data. Explanations may help human-AI teams address these biases for fairer decision-making. Typically, explanations focus on salient input features. If a model is biased against some protected group, explanations may include features that demonstrate this bias, but when biases are realized through proxy features, the relationship between this proxy feature and the protected one may be less clear to a human. In this work, we study the effect of the presence of protected and proxy features on participants' perception of model fairness and their ability to improve demographic parity over an AI alone. Further, we examine how different treatments -- explanations, model bias disclosure and proxy correlation disclosure -- affect fairness perception and parity. We find that explanations help people detect direct biases but not indirect biases. Additionally, regardless of bias type, explanations tend to increase agreement with model bia
    
[^84]: 安全深度策略适应

    Safe Deep Policy Adaptation. (arXiv:2310.08602v1 [cs.RO])

    [http://arxiv.org/abs/2310.08602](http://arxiv.org/abs/2310.08602)

    该论文提出了SafeDPA，一种新颖的强化学习和控制框架，用于同时解决策略适应和安全强化学习的问题。SafeDPA在仿真环境中联合学习自适应策略和动力学模型，并使用少量真实数据进行微调。在真实世界部署过程中，通过引入基于控制屏障函数的安全过滤器，确保了SafeDPA的安全性。

    

    自主和人工智能的一个重要目标是使自主机器人能够在动态和不确定的环境中快速适应。经典的自适应控制和安全控制提供了稳定性和安全性保证，但仅限于特定的系统类别。相比之下，基于强化学习（RL）的策略适应提供了通用性和泛化性，但同时也带来了安全性和稳健性的挑战。我们提出了SafeDPA，一种新颖的RL和控制框架，同时解决了策略适应和安全强化学习的问题。SafeDPA在仿真环境中联合学习自适应策略和动力学模型，预测环境配置，并使用少量真实数据对动力学模型进行微调。在RL策略之上引入基于控制屏障函数（CBF）的安全过滤器，以确保在真实世界部署过程中的安全性。我们提供了SafeDPA的理论安全性保证，并展示了SafeDPA对学习误差的稳健性。

    A critical goal of autonomy and artificial intelligence is enabling autonomous robots to rapidly adapt in dynamic and uncertain environments. Classic adaptive control and safe control provide stability and safety guarantees but are limited to specific system classes. In contrast, policy adaptation based on reinforcement learning (RL) offers versatility and generalizability but presents safety and robustness challenges. We propose SafeDPA, a novel RL and control framework that simultaneously tackles the problems of policy adaptation and safe reinforcement learning. SafeDPA jointly learns adaptive policy and dynamics models in simulation, predicts environment configurations, and fine-tunes dynamics models with few-shot real-world data. A safety filter based on the Control Barrier Function (CBF) on top of the RL policy is introduced to ensure safety during real-world deployment. We provide theoretical safety guarantees of SafeDPA and show the robustness of SafeDPA against learning errors 
    
[^85]: 医学图像分析的领域泛化：综述

    Domain Generalization for Medical Image Analysis: A Survey. (arXiv:2310.08598v1 [eess.IV])

    [http://arxiv.org/abs/2310.08598](http://arxiv.org/abs/2310.08598)

    本综述详细回顾了针对医学图像分析的领域泛化研究，探讨了在DL模型在真实世界应用中遇到的挑战，以及如何解决分布漂移问题和实现稳健性。同时，考虑了领域泛化技术对整个MedIA工作流程的操作影响。

    

    医学图像分析（MedIA）已成为医学和保健领域的重要工具，在疾病诊断、预后和治疗规划方面起到了很大的作用，深度学习（DL）的最新成功为其进展做出了重要贡献。然而，MedIA的DL模型在现实世界中的部署仍然具有挑战性，在训练和测试样本之间的分布差异下很难泛化，这被称为分布漂移问题。研究人员致力于开发各种DL方法，使其能够适应并在未知和超出分布的数据分布上稳健地运行。本文综合评述了专门针对MedIA的领域泛化研究。我们提供了领域泛化技术在更大范围MedIA系统内的交互方式的整体视图，不仅仅考虑方法学，还考虑了对整个MedIA工作流程的操作影响。具体而言，我们将领域泛化方法分为数据层次的方法…

    Medical Image Analysis (MedIA) has become an essential tool in medicine and healthcare, aiding in disease diagnosis, prognosis, and treatment planning, and recent successes in deep learning (DL) have made significant contributions to its advances. However, DL models for MedIA remain challenging to deploy in real-world situations, failing for generalization under the distributional gap between training and testing samples, known as a distribution shift problem. Researchers have dedicated their efforts to developing various DL methods to adapt and perform robustly on unknown and out-of-distribution data distributions. This paper comprehensively reviews domain generalization studies specifically tailored for MedIA. We provide a holistic view of how domain generalization techniques interact within the broader MedIA system, going beyond methodologies to consider the operational implications on the entire MedIA workflow. Specifically, we categorize domain generalization methods into data-lev
    
[^86]: 自主驾驶车辆交叉路口导航的深度强化学习

    Deep Reinforcement Learning for Autonomous Vehicle Intersection Navigation. (arXiv:2310.08595v1 [cs.RO])

    [http://arxiv.org/abs/2310.08595](http://arxiv.org/abs/2310.08595)

    本研究通过使用基于TD3算法的单智能体方法，在CARLA模拟平台中展示了在复杂T型路口导航中稳定收敛和改进安全性能，并在行程延误、碰撞减少和总体成本等方面优于先前的方法。

    

    本文探讨了在密集交通场景中，自主驾驶车辆（AVs）在复杂T型路口导航中面临的挑战。强化学习算法已经成为一种有希望的方法，可以通过实时地使AVs做出安全高效的决策来应对这些挑战。在本文中，我们使用一种基于双延迟深度确定性策略梯度（TD3）强化学习算法的低成本、单智能体方法来解决在T型路口上的高效安全导航问题。我们展示了当我们在CARLA模拟平台上对我们的TD3方法进行训练和测试时，该方法呈现出稳定的收敛性和改进的安全性能，适用于各种交通密度。我们的结果表明，所提出的方法使AV能够有效地导航T型路口，在行程延误、碰撞减少和总体成本方面优于先前的方法。本研究对强化学习在自主驾驶车辆领域的应用贡献了新的知识。

    In this paper, we explore the challenges associated with navigating complex T-intersections in dense traffic scenarios for autonomous vehicles (AVs). Reinforcement learning algorithms have emerged as a promising approach to address these challenges by enabling AVs to make safe and efficient decisions in real-time. Here, we address the problem of efficiently and safely navigating T-intersections using a lower-cost, single-agent approach based on the Twin Delayed Deep Deterministic Policy Gradient (TD3) reinforcement learning algorithm. We show that our TD3-based method, when trained and tested in the CARLA simulation platform, demonstrates stable convergence and improved safety performance in various traffic densities. Our results reveal that the proposed approach enables the AV to effectively navigate T-intersections, outperforming previous methods in terms of travel delays, collision minimization, and overall cost. This study contributes to the growing body of knowledge on reinforceme
    
[^87]: 我们能编辑多模式大型语言模型吗？

    Can We Edit Multimodal Large Language Models?. (arXiv:2310.08475v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.08475](http://arxiv.org/abs/2310.08475)

    本文提出了编辑多模式大型语言模型（MLLMs）的挑战，并构建了一个新的基准用于评估和比较不同编辑方法的效果。实验结果表明，编辑多模式LLMs仍然存在困难，但这项工作为NLP社区提供了宝贵的见解。

    

    本文关注编辑多模式大型语言模型（MLLMs）。与编辑单模式LLMs相比，多模式模型的编辑更具挑战性，需要更高级别的审查和慎重考虑。为了促进这一领域的研究，我们构建了一个新的基准，称为MMEdit，用于编辑多模式LLMs，并建立了一套创新的度量标准进行评估。我们进行了包括各种模型编辑基线的综合实验，并分析了编辑多模式LLMs的不同组件的影响。根据经验，我们发现之前的基线在某种程度上可以实现编辑多模式LLMs，但效果仍然不理想，表明这个任务可能存在的困难。我们希望我们的工作能为NLP社区提供见解。代码和数据集可在https://github.com/zjunlp/EasyEdit获取。

    In this paper, we focus on editing Multimodal Large Language Models (MLLMs). Compared to editing single-modal LLMs, multimodal model editing is more challenging, which demands a higher level of scrutiny and careful consideration in the editing process. To facilitate research in this area, we construct a new benchmark, dubbed MMEdit, for editing multimodal LLMs and establishing a suite of innovative metrics for evaluation. We conduct comprehensive experiments involving various model editing baselines and analyze the impact of editing different components for multimodal LLMs. Empirically, we notice that previous baselines can implement editing multimodal LLMs to some extent, but the effect is still barely satisfactory, indicating the potential difficulty of this task. We hope that our work can provide the NLP community with insights. Code and dataset are available in https://github.com/zjunlp/EasyEdit.
    
[^88]: BERT广义性的影响：人为对抗样本和友好样本的效果

    Effects of Human Adversarial and Affable Samples on BERT Generalizability. (arXiv:2310.08008v1 [cs.AI])

    [http://arxiv.org/abs/2310.08008](http://arxiv.org/abs/2310.08008)

    本研究研究了对BERT模型的广义性影响，发现在固定大小的训练样本上，有10-30\%的人为对抗实例可以显著提高文本分类和关系抽取任务的精度和F1值。

    

    基于BERT的模型在领先榜上表现强劲，但在需要泛化的实际场景中表现较差。有限的训练数据被认为是机器学习泛化能力的主要障碍。本文研究训练数据质量对模型泛化能力的影响，而不是数量。我们考虑了训练数据的两个特征：人为对抗样本（具有看似微小差异但具有不同标签的样本对）和人为友好样本（具有微小差异但具有相同标签的样本对）。我们发现，在固定大小的训练样本上，以10-30\%的人为对抗实例为经验，可以提高文本分类和关系抽取任务的精度和F1值最多20个百分点。超过此范围的增加对模型性能无显著影响。

    BERT-based models have had strong performance on leaderboards, yet have been demonstrably worse in real-world settings requiring generalization. Limited quantities of training data is considered a key impediment to achieving generalizability in machine learning. In this paper, we examine the impact of training \textit{data quality}, not quantity, on a model's generalizability. We consider two characteristics of training data: the portion of human-adversarial (h-adversarial), i.e., sample pairs with seemingly minor differences but different ground-truth labels, and human-affable (h-affable) training samples, i.e., sample pairs with minor differences but the same ground-truth label. We find that for a fixed size of training samples, as a rule of thumb, having 10-30\% h-adversarial instances improves the precision, and therefore F1, by up to 20 points in the tasks of text classification and relation extraction. Increasing h-adversarials beyond this range can result in performance plateaus
    
[^89]: 使用大型语言模型生成合成数据用于文本分类：潜力和限制

    Synthetic Data Generation with Large Language Models for Text Classification: Potential and Limitations. (arXiv:2310.07849v1 [cs.CL])

    [http://arxiv.org/abs/2310.07849](http://arxiv.org/abs/2310.07849)

    本研究旨在探讨使用大型语言模型生成合成数据在文本分类模型训练中的潜力和限制。研究结果发现，主观性会负面影响模型在合成数据上的性能。这对于理解和利用合成数据的有效性具有重要的启示作用。

    

    收集和整理高质量的训练数据对于开发具有卓越性能的文本分类模型至关重要，但往往伴随着巨大的成本和时间投入。研究人员最近开始探索使用大型语言模型（LLMs）生成合成数据集作为一种替代方法。然而，LLM生成的合成数据在支持模型训练方面的有效性在不同的分类任务中是不一致的。为了更好地了解调节LLM生成的合成数据有效性的因素，本研究探讨了在分类的主观性如何影响在合成数据上训练的模型的性能。我们的研究结果表明，主观性在任务层面和实例层面上都与在合成数据上训练的模型的性能呈负相关。最后，我们讨论了我们的工作对于利用LLM来生成合成数据在潜力和限制方面的影响。

    The collection and curation of high-quality training data is crucial for developing text classification models with superior performance, but it is often associated with significant costs and time investment. Researchers have recently explored using large language models (LLMs) to generate synthetic datasets as an alternative approach. However, the effectiveness of the LLM-generated synthetic data in supporting model training is inconsistent across different classification tasks. To better understand factors that moderate the effectiveness of the LLM-generated synthetic data, in this study, we look into how the performance of models trained on these synthetic data may vary with the subjectivity of classification. Our results indicate that subjectivity, at both the task level and instance level, is negatively associated with the performance of the model trained on synthetic data. We conclude by discussing the implications of our work on the potential and limitations of leveraging LLM fo
    
[^90]: 具有相位随机桥的生成建模

    Generative Modeling with Phase Stochastic Bridges. (arXiv:2310.07805v1 [cs.LG])

    [http://arxiv.org/abs/2310.07805](http://arxiv.org/abs/2310.07805)

    通过在相位空间中构建路径测度，我们提出了一种新颖的生成建模框架，可以在动力传播的早期阶段生成逼真的数据点，并利用额外的速度信息实现高效的数据生成。

    

    扩散模型（DMs）是用于连续输入的最先进的生成模型。DMs通过在输入空间（即位置空间）中构建随机微分方程（SDE），并使用神经网络进行反演来工作。在这项工作中，我们介绍了一种基于相位空间动力学的新型生成建模框架，其中相位空间被定义为一个包括位置和速度的增强空间。利用随机最优控制的洞察力，我们构建了相位空间中的路径测度，实现了高效的采样。与DMs相比，我们的框架在动力传播的早期阶段就能够生成逼真的数据点。这种早期预测为通过沿轨迹利用额外的速度信息实现高效的数据生成奠定了基础。在标准图像生成基准测试中，我们的模型在小函数评估数量的范围内表现出优秀的性能。

    Diffusion models (DMs) represent state-of-the-art generative models for continuous inputs. DMs work by constructing a Stochastic Differential Equation (SDE) in the input space (ie, position space), and using a neural network to reverse it. In this work, we introduce a novel generative modeling framework grounded in \textbf{phase space dynamics}, where a phase space is defined as {an augmented space encompassing both position and velocity.} Leveraging insights from Stochastic Optimal Control, we construct a path measure in the phase space that enables efficient sampling. {In contrast to DMs, our framework demonstrates the capability to generate realistic data points at an early stage of dynamics propagation.} This early prediction sets the stage for efficient data generation by leveraging additional velocity information along the trajectory. On standard image generation benchmarks, our model yields favorable performance over baselines in the regime of small Number of Function Evaluation
    
[^91]: 这里是翻译过的论文标题：Mini-DALLE3：通过提示大型语言模型进行交互式文本生成图像

    Mini-DALLE3: Interactive Text to Image by Prompting Large Language Models. (arXiv:2310.07653v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2310.07653](http://arxiv.org/abs/2310.07653)

    这里是中文总结出的一句话要点：在本论文中，通过引入交互式文本生成图像（iT2I）的新任务，提出了Mini-DALLE3模型，通过与大型语言模型的交互，用户可以实现更好质量的图像生成、编辑和优化。

    

    人工智能内容生成的革命在繁盛的文本生成图像（T2I）扩散模型中得到了快速推进。在仅仅两年的发展中，最先进的模型能够以前所未有的高质量、多样性和创造力生成图像。然而，目前普遍存在的一个限制是使用自然语言描述与这些流行的T2I模型，如稳定扩散（Stable Diffusion）进行有效的交流。这通常使得获取一个有吸引力的图像变得困难，除非在复杂的提示工程中具有专业知识，包括复杂的单词组合、魔法标签和注释。受最近发布的DALLE3的启发，DALLE3是一个直接内置于ChatGPT中以人类语言进行对话的T2I模型，我们重新审视现有的T2I系统，努力实现人类意图的对齐，并引入了一项新任务 - 交互式文本生成图像（iT2I），在这个任务中，人们可以与语言模型进行交互，交替生成/编辑/优化高质量的图像并进行问答，以获得更强大的图像。

    The revolution of artificial intelligence content generation has been rapidly accelerated with the booming text-to-image (T2I) diffusion models. Within just two years of development, it was unprecedentedly of high-quality, diversity, and creativity that the state-of-the-art models could generate. However, a prevalent limitation persists in the effective communication with these popular T2I models, such as Stable Diffusion, using natural language descriptions. This typically makes an engaging image hard to obtain without expertise in prompt engineering with complex word compositions, magic tags, and annotations. Inspired by the recently released DALLE3 - a T2I model directly built-in ChatGPT that talks human language, we revisit the existing T2I systems endeavoring to align human intent and introduce a new task - interactive text to image (iT2I), where people can interact with LLM for interleaved high-quality image generation/edit/refinement and question answering with stronger images a
    
[^92]: 简单变压器中的线性潜在世界模型: 奥赛罗-GPT案例研究

    Linear Latent World Models in Simple Transformers: A Case Study on Othello-GPT. (arXiv:2310.07582v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.07582](http://arxiv.org/abs/2310.07582)

    本研究通过案例研究奥赛罗-GPT，发现其具有线性表示对立棋子的世界模型，并揭示了线性世界表示和因果决策之间的相互作用及其与层深度和模型复杂度的依赖关系。

    

    基础模型在决策和逻辑推理方面表现出显著的能力。然而，关于它们对世界的真正理解与纯粹的随机模仿相对的讨论持续存在。本文详细研究了在奥赛罗中训练的简单变压器，扩展了先前的研究，以增强对奥赛罗-GPT新兴世界模型的理解。研究发现，奥赛罗-GPT包含了对立棋子的线性表示，这一因素在驱动其决策过程中起到因果性的作用。本文进一步阐明了线性世界表示与因果决策之间的相互作用，以及它们对层深度和模型复杂度的依赖关系。我们已经将代码公开。

    Foundation models exhibit significant capabilities in decision-making and logical deductions. Nonetheless, a continuing discourse persists regarding their genuine understanding of the world as opposed to mere stochastic mimicry. This paper meticulously examines a simple transformer trained for Othello, extending prior research to enhance comprehension of the emergent world model of Othello-GPT. The investigation reveals that Othello-GPT encapsulates a linear representation of opposing pieces, a factor that causally steers its decision-making process. This paper further elucidates the interplay between the linear world representation and causal decision-making, and their dependence on layer depth and model complexity. We have made the code public.
    
[^93]: 面向目标的个性化主动对话系统：问题形式化与数据集筛选

    Target-oriented Proactive Dialogue Systems with Personalization: Problem Formulation and Dataset Curation. (arXiv:2310.07397v1 [cs.CL])

    [http://arxiv.org/abs/2310.07397](http://arxiv.org/abs/2310.07397)

    这项工作提出了一个自动数据集筛选框架，并构建了一个大规模的个性化面向目标对话数据集，名为TopDial。该数据集质量高，有助于探索个性化目标导向的对话。

    

    面向目标的对话系统旨在主动引导对话朝向预定的目标或达成特定的系统目标，在对话完成过程中考虑个性化。然而，需要高质量的数据集，从零开始构建需要大量人力。为了解决这个问题，我们提出了一个使用角色扮演方法的自动数据集筛选框架。基于这个框架，我们构建了一个大规模的个性化面向目标对话数据集，名为TopDial，包含约18K个多轮对话。实验结果表明，该数据集具有很高的质量，可以用于探索个性化目标导向的对话。

    Target-oriented dialogue systems, designed to proactively steer conversations toward predefined targets or accomplish specific system-side goals, are an exciting area in conversational AI. In this work, by formulating a <dialogue act, topic> pair as the conversation target, we explore a novel problem of personalized target-oriented dialogue by considering personalization during the target accomplishment process. However, there remains an emergent need for high-quality datasets, and building one from scratch requires tremendous human effort. To address this, we propose an automatic dataset curation framework using a role-playing approach. Based on this framework, we construct a large-scale personalized target-oriented dialogue dataset, TopDial, which comprises about 18K multi-turn dialogues. The experimental results show that this dataset is of high quality and could contribute to exploring personalized target-oriented dialogue.
    
[^94]: 关于交叉领域数据对德语语言模型的影响

    On the Impact of Cross-Domain Data on German Language Models. (arXiv:2310.07321v1 [cs.CL])

    [http://arxiv.org/abs/2310.07321](http://arxiv.org/abs/2310.07321)

    本研究通过对德语语言模型进行实验，发现将数据多样性置于数据质量之上的交叉领域数据集训练方法，可以显著提高模型的性能，并超过了之前的最先进模型。

    

    传统上，大型语言模型要么在通用网络抓取数据上训练，要么在特定领域的数据上。然而，生成型大型语言模型的最近成功突显了交叉领域数据集的好处。为了考察数据多样性高于质量的重要性，我们提出了一个包含五个领域文本的德语数据集，以及一个旨在包含高质量数据的数据集。通过在这两个数据集上训练参数范围从122M到750M的一系列模型，我们对多个下游任务进行了全面评估。我们的研究结果表明，使用交叉领域数据集训练的模型优于仅使用质量数据训练的模型，在先前最先进结果上提出了高达4.45%的改进。这些模型可在https://huggingface.co/ikim-uk-essen上找到。

    Traditionally, large language models have been either trained on general web crawls or domain-specific data. However, recent successes of generative large language models, have shed light on the benefits of cross-domain datasets. To examine the significance of prioritizing data diversity over quality, we present a German dataset comprising texts from five domains, along with another dataset aimed at containing high-quality data. Through training a series of models ranging between 122M and 750M parameters on both datasets, we conduct a comprehensive benchmark on multiple downstream tasks. Our findings demonstrate that the models trained on the cross-domain dataset outperform those trained on quality data alone, leading to improvements up to $4.45\%$ over the previous state-of-the-art. The models are available at https://huggingface.co/ikim-uk-essen
    
[^95]: 视觉计算扩散模型的最新进展

    State of the Art on Diffusion Models for Visual Computing. (arXiv:2310.07204v1 [cs.AI])

    [http://arxiv.org/abs/2310.07204](http://arxiv.org/abs/2310.07204)

    这篇论文旨在介绍最新的视觉计算领域中扩散模型的发展和应用，涵盖了生成人工智能的核心概念和实现细节，并总结了个人化、条件约束和反演等重要方面。

    

    随着生成人工智能的出现，视觉计算领域正在迅速发展，它为图像、视频和3D场景的生成、编辑和重建提供了前所未有的能力。在这些领域中，扩散模型是生成人工智能的首选架构。仅在过去一年中，基于扩散的工具和应用的文献数量呈指数增长，并且涉及计算机图形学、计算机视觉和人工智能社区的相关论文每天都在arXiv上发表。这个领域的快速增长使得跟上所有最新发展变得困难。这份最新技术报告（STAR）的目标是介绍扩散模型的基本数学概念、稳定扩散模型的实现细节和设计选择，以及概述这些生成人工智能工具的重要方面，包括个性化、条件约束、反演等。

    The field of visual computing is rapidly advancing due to the emergence of generative artificial intelligence (AI), which unlocks unprecedented capabilities for the generation, editing, and reconstruction of images, videos, and 3D scenes. In these domains, diffusion models are the generative AI architecture of choice. Within the last year alone, the literature on diffusion-based tools and applications has seen exponential growth and relevant papers are published across the computer graphics, computer vision, and AI communities with new works appearing daily on arXiv. This rapid growth of the field makes it difficult to keep up with all recent developments. The goal of this state-of-the-art report (STAR) is to introduce the basic mathematical concepts of diffusion models, implementation details and design choices of the popular Stable Diffusion model, as well as overview important aspects of these generative AI tools, including personalization, conditioning, inversion, among others. Mor
    
[^96]: 大型语言模型稀疏微调的推理加速

    Sparse Finetuning for Inference Acceleration of Large Language Models. (arXiv:2310.06927v1 [cs.CL])

    [http://arxiv.org/abs/2310.06927](http://arxiv.org/abs/2310.06927)

    本论文研究了大型语言模型的准确稀疏微调问题，提出了基于L2范数的蒸馏方法SquareHead，可以在高稀疏性下实现准确的恢复；同时展示了稀疏语言模型的实际效率，可在CPU和GPU运行时实现加速，并且观察到在受内存限制的模型中，稀疏性也可用于减少内存带宽。

    

    我们考虑在训练过的大型语言模型上进行精确的稀疏微调，即在专门任务上对预训练的语言模型进行微调，同时在权重上引入稀疏性。在准确性方面，我们观察到基于损失的标准微调可能无法恢复准确性，特别是在高稀疏情况下。为了解决这个问题，我们对蒸馏类型的损失进行了详细研究，确定了一种基于L2范数的蒸馏方法，我们称之为SquareHead，即使在更高的稀疏性下，它也能实现准确的恢复，适用于所有模型类型。在实际效率方面，我们展示了稀疏语言模型可以通过利用稀疏性在CPU和GPU运行时实现加速。虽然标准方法是利用稀疏性进行计算减少，但我们观察到，在受内存限制的语言模型中，稀疏性也可以用于减少内存带宽。我们展示了由于稀疏性导致的速度提升以及恢复准确性的端到端结果，应用于T5 (语言翻译)任务中。

    We consider the problem of accurate sparse finetuning of large language models (LLMs), that is, finetuning pretrained LLMs on specialized tasks, while inducing sparsity in their weights. On the accuracy side, we observe that standard loss-based finetuning may fail to recover accuracy, especially at high sparsities. To address this, we perform a detailed study of distillation-type losses, determining an L2-based distillation approach we term SquareHead which enables accurate recovery even at higher sparsities, across all model types. On the practical efficiency side, we show that sparse LLMs can be executed with speedups by taking advantage of sparsity, for both CPU and GPU runtimes. While the standard approach is to leverage sparsity for computational reduction, we observe that in the case of memory-bound LLMs sparsity can also be leveraged for reducing memory bandwidth. We exhibit end-to-end results showing speedups due to sparsity, while recovering accuracy, on T5 (language translati
    
[^97]: DANet：通过高效的可变形注意力网络提高小目标检测能力

    DANet: Enhancing Small Object Detection through an Efficient Deformable Attention Network. (arXiv:2310.05768v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2310.05768](http://arxiv.org/abs/2310.05768)

    通过结合Faster R-CNN与特征金字塔网络、使用可变形网络以及引入卷积块注意力模块等方法，我们提出的DANet模型能够高效准确地检测制造业环境中的小物体，包括微小且复杂的特征。

    

    高效准确地检测制造业环境中的小物体（如缺陷和裂纹）对于确保产品质量和安全至关重要。为解决这个问题，我们提出了一种综合策略，通过将Faster R-CNN与先进方法结合起来。通过将Faster R-CNN与特征金字塔网络相结合，我们使模型能够高效处理制造环境中固有的多尺度特征。此外，我们使用了可变形网络，可以根据缺陷的几何变化进行变形，并精确检测微小而复杂的特征。然后，我们在基础的ResNet50网络的每个块中加入了一种称为卷积块注意力模块的注意力机制，以选择性地强调信息丰富的特征并压制不太有用的特征。然后我们采用了RoI Align来替代RoI Pooling进行更精细的感兴趣区域对齐，最后集成Focal Loss来有效处理类别不平衡。

    Efficient and accurate detection of small objects in manufacturing settings, such as defects and cracks, is crucial for ensuring product quality and safety. To address this issue, we proposed a comprehensive strategy by synergizing Faster R-CNN with cutting-edge methods. By combining Faster R-CNN with Feature Pyramid Network, we enable the model to efficiently handle multi-scale features intrinsic to manufacturing environments. Additionally, Deformable Net is used that contorts and conforms to the geometric variations of defects, bringing precision in detecting even the minuscule and complex features. Then, we incorporated an attention mechanism called Convolutional Block Attention Module in each block of our base ResNet50 network to selectively emphasize informative features and suppress less useful ones. After that we incorporated RoI Align, replacing RoI Pooling for finer region-of-interest alignment and finally the integration of Focal Loss effectively handles class imbalance, cruc
    
[^98]: ViTs无处不在：展示不同领域中的视觉Transformer的综合研究

    ViTs are Everywhere: A Comprehensive Study Showcasing Vision Transformers in Different Domain. (arXiv:2310.05664v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2310.05664](http://arxiv.org/abs/2310.05664)

    这项综合研究展示了视觉Transformer在不同领域中的应用，通过与卷积神经网络的比较，证明了其在视觉问题上的优越性和潜力。

    

    Transformer设计是自然语言处理任务的事实标准。Transformer设计在自然语言处理中的成功最近引起了计算机视觉领域研究人员的兴趣。与卷积神经网络（CNN）相比，视觉Transformer（ViTs）正在成为许多视觉问题的流行和主导解决方案。基于Transformer的模型在多种视觉基准中表现优异，超过了卷积神经网络（CNN）和循环神经网络等其他类型网络。本工作通过将各种视觉Transformer模型划分为不同任务并研究其优势和缺点，对其进行评估。ViTs能够克服卷积神经网络（CNN）可能遇到的一些困难。本调查的目标是展示ViTs在计算机视觉中的首次应用。在第一阶段，我们对适用ViTs的各种计算机视觉应用进行分类，包括图像分类、目标识别、图像分割、视频Transformer等。

    Transformer design is the de facto standard for natural language processing tasks. The success of the transformer design in natural language processing has lately piqued the interest of researchers in the domain of computer vision. When compared to Convolutional Neural Networks (CNNs), Vision Transformers (ViTs) are becoming more popular and dominant solutions for many vision problems. Transformer-based models outperform other types of networks, such as convolutional and recurrent neural networks, in a range of visual benchmarks. We evaluate various vision transformer models in this work by dividing them into distinct jobs and examining their benefits and drawbacks. ViTs can overcome several possible difficulties with convolutional neural networks (CNNs). The goal of this survey is to show the first use of ViTs in CV. In the first phase, we categorize various CV applications where ViTs are appropriate. Image classification, object identification, image segmentation, video transformer, 
    
[^99]: 通过迭代地融合模态相似路径实现通用的多模态实体对齐

    Universal Multi-modal Entity Alignment via Iteratively Fusing Modality Similarity Paths. (arXiv:2310.05364v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.05364](http://arxiv.org/abs/2310.05364)

    本研究提出了一种通过迭代融合模态相似路径实现通用的多模态实体对齐方法。通过统一建模和有效信息融合，解决了现有方法中模态建模不一致和低效以及模态融合效果不佳的问题。

    

    实体对齐的目标是从多个知识图谱中确定等价的实体对，并创建一个更全面和统一的知识图谱。大多数实体对齐方法主要关注知识图谱的结构模态，缺乏对多模态信息的探索。少数多模态实体对齐方法在这个领域做出了不错的尝试。然而，它们存在两个缺点：(1)模态建模不一致且低效，为每个模态设计复杂和独立的模型；(2)由于实体对齐中模态的异构性，模态融合效果不佳。为了解决这些挑战，我们提出了PathFusion，它包括两个主要部分：(1) MSP，一个统一的建模方法，通过构建连接实体和模态节点以表示多个模态的路径，简化了对齐过程；(2) IRF，一种迭代融合方法，使用路径作为信息载体，有效地将不同模态的信息结合起来。

    The objective of Entity Alignment (EA) is to identify equivalent entity pairs from multiple Knowledge Graphs (KGs) and create a more comprehensive and unified KG. The majority of EA methods have primarily focused on the structural modality of KGs, lacking exploration of multi-modal information. A few multi-modal EA methods have made good attempts in this field. Still, they have two shortcomings: (1) inconsistent and inefficient modality modeling that designs complex and distinct models for each modality; (2) ineffective modality fusion due to the heterogeneous nature of modalities in EA. To tackle these challenges, we propose PathFusion, consisting of two main components: (1) MSP, a unified modeling approach that simplifies the alignment process by constructing paths connecting entities and modality nodes to represent multiple modalities; (2) IRF, an iterative fusion method that effectively combines information from different modalities using the path as an information carrier. Experim
    
[^100]: 个性化随机鹦鹉更危险吗？评估对话系统中的人格偏见

    Are Personalized Stochastic Parrots More Dangerous? Evaluating Persona Biases in Dialogue Systems. (arXiv:2310.05280v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.05280](http://arxiv.org/abs/2310.05280)

    这项研究评估了对话系统中的人格偏见对社交偏见的影响，并建立了一个综合评估框架来衡量不同人格采用下的偏见程度。

    

    最近大型语言模型的发展使其能够按照自由形式的指令进行操作，包括在对话中模仿通用或特定人口群体的人格。通用人格指的是来自某一人口群体的个体（例如亚洲人），而特定人格可以是历史人物的实际姓名。虽然采用人格使对话系统更具吸引力和亲和力，但也存在潜在风险，可能通过与用户的交互而加剧社会偏见，进一步造成社会伤害。在本文中，我们系统地研究“人格偏见”，我们将其定义为有害对话模型行为对不同人格采用的敏感性。我们将人格偏见分为有害表达和有害认同两类，同时建立了一个全面的评估框架，以衡量五个方面的人格偏见：冒犯性、有毒延续、关怀、刻板印象的认同以及

    Recent advancements in Large Language Models empower them to follow freeform instructions, including imitating generic or specific demographic personas in conversations. Generic personas refer to an individual from a demographic group (e.g. an Asian person), whereas specific personas can be actual names of historical figures. While the adoption of personas allows dialogue systems to be more engaging and approachable to users, it also carries the potential risk of exacerbating social biases in model responses, further causing societal harms through interactions with users. In this paper, we systematically study "persona biases", which we define to be the sensitivity of harmful dialogue model behaviors to different persona adoptions. We categorize persona biases into biases in harmful expression and harmful agreement, as well as establish a comprehensive evaluation framework to measure persona biases in five aspects: Offensiveness, Toxic Continuation, Regard, Stereotype Agreement, and To
    
[^101]: Text2NKG: 面向N元关系知识图构建的细粒度N元关系抽取

    Text2NKG: Fine-Grained N-ary Relation Extraction for N-ary relational Knowledge Graph Construction. (arXiv:2310.05185v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2310.05185](http://arxiv.org/abs/2310.05185)

    Text2NKG是一种用于构建N元关系知识图的细粒度N元关系抽取框架，支持多种NKG模式，具有高灵活性和实用性。

    

    除了传统的二元关系事实外，N元关系知识图(NKGs)由包含两个以上实体的N元关系事实组成，更接近于具有广泛应用的真实世界事实。然而，NKG的构建仍然严重依赖于人工劳动，并且N元关系抽取仍然停留在粗粒度水平，通常是在单一模式和固定的实体数量上操作。为了解决这些限制，我们提出了Text2NKG，一种新颖的面向N元关系知识图构建的细粒度N元关系抽取框架。我们引入了一种跨度元组分类方法，并采用异构排序合并来实现不同度的细粒度N元关系抽取。此外，Text2NKG支持四种典型的NKG模式：超关系模式、基于事件的模式、基于角色的模式和超图模式，具有较高的灵活性和实用性。实验结果表明，Text2NKG的表现优于传统的N元关系抽取方法。

    Beyond traditional binary relational facts, n-ary relational knowledge graphs (NKGs) are comprised of n-ary relational facts containing more than two entities, which are closer to real-world facts with broader applications. However, the construction of NKGs still significantly relies on manual labor, and n-ary relation extraction still remains at a course-grained level, which is always in a single schema and fixed arity of entities. To address these restrictions, we propose Text2NKG, a novel fine-grained n-ary relation extraction framework for n-ary relational knowledge graph construction. We introduce a span-tuple classification approach with hetero-ordered merging to accomplish fine-grained n-ary relation extraction in different arity. Furthermore, Text2NKG supports four typical NKG schemas: hyper-relational schema, event-based schema, role-based schema, and hypergraph-based schema, with high flexibility and practicality. Experimental results demonstrate that Text2NKG outperforms the
    
[^102]: 使用大型语言模型（LLMS）对图中的节点进行无标签分类

    Label-free Node Classification on Graphs with Large Language Models (LLMS). (arXiv:2310.04668v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.04668](http://arxiv.org/abs/2310.04668)

    本文介绍了一种使用大型语言模型（LLMs）对图中节点进行无标签分类的方法，即LLM-GNN。它利用LLMs对一小部分节点进行注释，然后通过对LLMs的注释进行训练，使得GNN能够对其余大部分节点进行预测。这种方法充分发挥了GNNs和LLMs的优势，同时解决了它们在处理结构化数据方面的限制。

    

    近年来，图神经网络（Graph Neural Networks，GNNs）在节点分类方面取得了显著的进展。然而，为了确保良好的性能，它们需要大量高质量的标签。相比之下，大型语言模型（Large Language Models，LLMs）在文本属性图上展现出了令人印象深刻的零样学习能力。然而，它们在高效处理结构化数据方面面临挑战，并且推理成本较高。鉴于这些观察结果，本文引入了一种基于LLMs的无标签图节点分类方法，命名为LLM-GNN。它集成了GNNs和LLMs的优势，同时减轻了它们的限制。具体而言，LLMs被用来注释一小部分节点，然后通过对LLMs的注释进行训练，使GNNs能够预测其余大部分节点。LLM-GNN的实现面临一个独特的挑战：我们如何主动选择要由LLMs注释的节点，从而增强GNN的训练？我们如何利用LLMs来优化结构化数据的处理？

    In recent years, there have been remarkable advancements in node classification achieved by Graph Neural Networks (GNNs). However, they necessitate abundant high-quality labels to ensure promising performance. In contrast, Large Language Models (LLMs) exhibit impressive zero-shot proficiency on text-attributed graphs. Yet, they face challenges in efficiently processing structural data and suffer from high inference costs. In light of these observations, this work introduces a label-free node classification on graphs with LLMs pipeline, LLM-GNN. It amalgamates the strengths of both GNNs and LLMs while mitigating their limitations. Specifically, LLMs are leveraged to annotate a small portion of nodes and then GNNs are trained on LLMs' annotations to make predictions for the remaining large portion of nodes. The implementation of LLM-GNN faces a unique challenge: how can we actively select nodes for LLMs to annotate and consequently enhance the GNN training? How can we leverage LLMs to ob
    
[^103]: 人类移动问题回答（展望论文）

    Human Mobility Question Answering (Vision Paper). (arXiv:2310.04443v1 [cs.CL])

    [http://arxiv.org/abs/2310.04443](http://arxiv.org/abs/2310.04443)

    本文提出了一项新的任务，即人类移动问题回答（MobQA），旨在让智能系统从移动数据中学习并回答相关问题，填补了关于利用人类移动数据进行问题回答系统的研究空白，并为移动推荐系统的研究带来了新的范式变革。

    

    问答系统已经引起了人工智能界的广泛关注，因为它们可以根据给定的知识源（例如视觉问答中的图像）学习回答问题。然而，关于利用人类移动数据进行问题回答系统的研究尚未被探索。挖掘人类移动数据对于智能城市规划、疫情管理和个性化推荐系统等各种应用至关重要。本文旨在填补这一空白，引入一项新的任务，即人类移动问题回答（MobQA）。该任务旨在让智能系统从移动数据中学习并回答相关问题。该任务为移动预测研究带来了新的范式变革，并进一步促进了人类移动推荐系统的研究。为了更好地支持这个新的研究课题，这篇展望论文还提出了一个数据集的初步设计和一个潜在的深度学习模型。

    Question answering (QA) systems have attracted much attention from the artificial intelligence community as they can learn to answer questions based on the given knowledge source (e.g., images in visual question answering). However, the research into question answering systems with human mobility data remains unexplored. Mining human mobility data is crucial for various applications such as smart city planning, pandemic management, and personalised recommendation system. In this paper, we aim to tackle this gap and introduce a novel task, that is, human mobility question answering (MobQA). The aim of the task is to let the intelligent system learn from mobility data and answer related questions. This task presents a new paradigm change in mobility prediction research and further facilitates the research of human mobility recommendation systems. To better support this novel research topic, this vision paper also proposes an initial design of the dataset and a potential deep learning mod
    
[^104]: SmoothLLM：防御大型语言模型免受越狱攻击

    SmoothLLM: Defending Large Language Models Against Jailbreaking Attacks. (arXiv:2310.03684v1 [cs.LG])

    [http://arxiv.org/abs/2310.03684](http://arxiv.org/abs/2310.03684)

    SmoothLLM是第一个用于减轻大型语言模型上越狱攻击的算法，通过在输入提示上随机扰动并汇总预测结果来检测对抗性输入，将攻击成功率降低至不到一个百分点，并提供了可证明的保证。

    

    尽管努力将大型语言模型（LLM）与人类价值观保持一致，但广泛使用的LLM（如GPT、Llama、Claude和PaLM）仍然容易受到越狱攻击，即对目标LLM进行欺骗，以生成不合适的内容。为了解决这个漏洞，我们提出了SmoothLLM，这是第一个旨在减轻LLM上的越狱攻击的算法。基于我们的发现，对抗性生成的提示对字符级别的改变很脆弱，我们的防御首先随机扰动给定输入提示的多个副本，然后汇总相应的预测结果来检测对抗性输入。SmoothLLM将众多热门LLM的攻击成功率降低至不到一个百分点，避免了不必要的保守性，并对攻击缓解提供了可证明的保证。此外，我们的防御使用的查询数量比现有的攻击方法少得多，并且与任何LLM兼容。

    Despite efforts to align large language models (LLMs) with human values, widely-used LLMs such as GPT, Llama, Claude, and PaLM are susceptible to jailbreaking attacks, wherein an adversary fools a targeted LLM into generating objectionable content. To address this vulnerability, we propose SmoothLLM, the first algorithm designed to mitigate jailbreaking attacks on LLMs. Based on our finding that adversarially-generated prompts are brittle to character-level changes, our defense first randomly perturbs multiple copies of a given input prompt, and then aggregates the corresponding predictions to detect adversarial inputs. SmoothLLM reduces the attack success rate on numerous popular LLMs to below one percentage point, avoids unnecessary conservatism, and admits provable guarantees on attack mitigation. Moreover, our defense uses exponentially fewer queries than existing attacks and is compatible with any LLM.
    
[^105]: LanguageMPC：基于大型语言模型的自动驾驶决策者

    LanguageMPC: Large Language Models as Decision Makers for Autonomous Driving. (arXiv:2310.03026v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2310.03026](http://arxiv.org/abs/2310.03026)

    本文研究将大型语言模型（LLMs）作为复杂自动驾驶场景的决策组件，通过认知路径和算法来实现全面推理和可执行驾驶指令的转化。实验证明，LLMs能够在单车任务和复杂驾驶行为中表现出优越性能，这是因为其具有常识推理能力。

    

    现有基于学习的自动驾驶系统在理解高级信息、推广罕见事件和提供可解释性方面面临挑战。为解决这些问题，本研究将大型语言模型（LLMs）作为复杂自动驾驶场景的决策组件，需要人类常识理解。我们设计了认知路径，使LLMs能够进行全面推理，并开发了将LLM决策转化为可执行驾驶指令的算法。通过这种方式，LLM决策通过引导参数矩阵适应与低级控制器无缝集成。大量实验表明，我们提出的方法不仅在单车任务中始终超越基线方法，而且还能处理复杂的驾驶行为，甚至多车协调，这要归功于LLMs的常识推理能力。本文介绍了将LLMs作为有效决策者的初步步骤。

    Existing learning-based autonomous driving (AD) systems face challenges in comprehending high-level information, generalizing to rare events, and providing interpretability. To address these problems, this work employs Large Language Models (LLMs) as a decision-making component for complex AD scenarios that require human commonsense understanding. We devise cognitive pathways to enable comprehensive reasoning with LLMs, and develop algorithms for translating LLM decisions into actionable driving commands. Through this approach, LLM decisions are seamlessly integrated with low-level controllers by guided parameter matrix adaptation. Extensive experiments demonstrate that our proposed method not only consistently surpasses baseline approaches in single-vehicle tasks, but also helps handle complex driving behaviors even multi-vehicle coordination, thanks to the commonsense reasoning capabilities of LLMs. This paper presents an initial step toward leveraging LLMs as effective decision-make
    
[^106]: 一个增强的 UMLS 框架，用于改善大型语言模型在医疗保健中的事实性

    A UMLS-Augmented Framework for Improving Factuality in Large Language Models within Healthcare. (arXiv:2310.02778v1 [cs.CL])

    [http://arxiv.org/abs/2310.02778](http://arxiv.org/abs/2310.02778)

    该论文提出了一个基于UMLS的增强型大型语言模型框架，旨在改善医疗保健领域中模型生成内容的事实性。通过自动评估和医生评估，研究人员验证了该框架的有效性。

    

    大型语言模型（LLM）展示了强大的文本生成能力，为医疗保健领域带来了前所未有的创新。然而，将LLMs应用于真实临床场景面临重大挑战，因为这些模型可能生成与已建立医学事实偏离的内容，甚至可能表现出潜在的偏见。在我们的研究中，我们开发了一个基于统一医学语言系统（UMLS）的增强型LLM框架，旨在更好地服务医疗保健社区。我们采用LLaMa2-13b-chat和ChatGPT-3.5作为基准模型，并使用ROUGE分数和BERT分数在LiveQA测试集的104个问题上进行自动评估。此外，我们根据事实性、完整性、可读性和相关性四个维度建立了医生评估标准。ChatGPT-3.5用于医生评估，针对LiveQA测试集的20个问题。多位住院医师进行评估。

    Large language models (LLMs) have demonstrated powerful text generation capabilities, bringing unprecedented innovation to the healthcare field. While LLMs hold immense promise for applications in healthcare, applying them to real clinical scenarios presents significant challenges, as these models may generate content that deviates from established medical facts and even exhibit potential biases. In our research, we develop an augmented LLM framework based on the Unified Medical Language System (UMLS), aiming to better serve the healthcare community. We employ LLaMa2-13b-chat and ChatGPT-3.5 as our benchmark models, and conduct automatic evaluations using the ROUGE Score and BERTScore on 104 questions from the LiveQA test set. Additionally, we establish criteria for physician-evaluation based on four dimensions: Factuality, Completeness, Readability and Relevancy. ChatGPT-3.5 is used for physician evaluation with 20 questions on the LiveQA test set. Multiple resident physicians conduct
    
[^107]: MagicDrive: 多样化的三维几何控制下的街景生成

    MagicDrive: Street View Generation with Diverse 3D Geometry Control. (arXiv:2310.02601v1 [cs.CV])

    [http://arxiv.org/abs/2310.02601](http://arxiv.org/abs/2310.02601)

    MagicDrive是一个新颖的街景生成框架，通过提供多样化的三维几何控制，包括相机姿态、道路地图和三维边界框，以及文本描述，实现了高保真度的街景合成，并捕捉了细致的三维几何信息。

    

    最近扩散模型的进展显著提高了具有2D控制的数据合成。然而，在街景生成中精确的三维控制在三维感知任务中至关重要，但仍然难以实现。具体来说，使用鸟瞰图作为主要条件常常导致几何控制（如高度）方面的挑战，影响物体形状、遮挡模式和道路表面高程等对感知数据合成至关重要的因素，特别是对于三维物体检测任务而言。在本文中，我们介绍了MagicDrive，这是一个新颖的街景生成框架，提供了多样化的三维几何控制，包括相机姿态、道路地图和三维边界框，以及通过定制的编码策略实现的文本描述。此外，我们的设计还采用了跨视图注意力模块，确保多个相机视图之间的一致性。通过MagicDrive，我们实现了高保真度的街景合成，捕捉到了精细的三维几何信息。

    Recent advancements in diffusion models have significantly enhanced the data synthesis with 2D control. Yet, precise 3D control in street view generation, crucial for 3D perception tasks, remains elusive. Specifically, utilizing Bird's-Eye View (BEV) as the primary condition often leads to challenges in geometry control (e.g., height), affecting the representation of object shapes, occlusion patterns, and road surface elevations, all of which are essential to perception data synthesis, especially for 3D object detection tasks. In this paper, we introduce MagicDrive, a novel street view generation framework offering diverse 3D geometry controls, including camera poses, road maps, and 3D bounding boxes, together with textual descriptions, achieved through tailored encoding strategies. Besides, our design incorporates a cross-view attention module, ensuring consistency across multiple camera views. With MagicDrive, we achieve high-fidelity street-view synthesis that captures nuanced 3D ge
    
[^108]: 通过多模态大型语言模型实现端到端的具身决策

    Towards End-to-End Embodied Decision Making via Multi-modal Large Language Model: Explorations with GPT4-Vision and Beyond. (arXiv:2310.02071v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2310.02071](http://arxiv.org/abs/2310.02071)

    本研究通过探索多模态大型语言模型在代理的具身决策中的应用潜力，提出了一个新的评估基准PCA-EVAL，并引入了一个多代理协作框架HOLMES，以提高决策能力。研究发现GPT4-Vision模型在端到端的具身决策中表现最佳。

    

    本研究探索了多模态大型语言模型（MLLMs）在改进代理的具身决策过程中的潜力。尽管由于其先进的推理能力和广泛的世界知识，大型语言模型（LLMs）被广泛使用，但像GPT4-Vision这样的MLLM提供了增强的视觉理解和推理能力。我们研究了最先进的MLLMs能否以端到端的方式处理具身决策，并且LLMs和MLLMs之间的协作是否能增强决策能力。为了回答这些问题，我们引入了一个名为PCA-EVAL的新基准，该基准从感知、认知和行动的角度评估具身决策。此外，我们提出了HOLMES，一个多代理协作框架，允许LLMs利用MLLMs和APIs获取多模态信息以进行明智的决策。我们在我们的基准上比较了端到端的具身决策和HOLMES，并发现GPT4-Vision模型的性能最优。

    In this study, we explore the potential of Multimodal Large Language Models (MLLMs) in improving embodied decision-making processes for agents. While Large Language Models (LLMs) have been widely used due to their advanced reasoning skills and vast world knowledge, MLLMs like GPT4-Vision offer enhanced visual understanding and reasoning capabilities. We investigate whether state-of-the-art MLLMs can handle embodied decision-making in an end-to-end manner and whether collaborations between LLMs and MLLMs can enhance decision-making. To address these questions, we introduce a new benchmark called PCA-EVAL, which evaluates embodied decision-making from the perspectives of Perception, Cognition, and Action. Additionally, we propose HOLMES, a multi-agent cooperation framework that allows LLMs to leverage MLLMs and APIs to gather multimodal information for informed decision-making. We compare end-to-end embodied decision-making and HOLMES on our benchmark and find that the GPT4-Vision model 
    
[^109]: 人工智能与人类互动以及社会陷阱

    Human-AI Interactions and Societal Pitfalls. (arXiv:2309.10448v1 [cs.AI])

    [http://arxiv.org/abs/2309.10448](http://arxiv.org/abs/2309.10448)

    本研究研究了人工智能与人类互动中面临的同质化和偏见问题，提出了改善人工智能与人类互动的解决办法，实现个性化输出而不牺牲生产力。

    

    当与生成式人工智能（AI）合作时，用户可能会看到生产力的提升，但AI生成的内容可能不完全符合他们的偏好。为了研究这种影响，我们引入了一个贝叶斯框架，其中异质用户选择与AI共享多少信息，面临输出保真度和通信成本之间的权衡。我们展示了这些个体决策与AI训练之间的相互作用可能导致社会挑战。输出可能变得更加同质化，特别是当AI在AI生成的内容上进行训练时。而任何AI的偏见可能成为社会偏见。解决同质化和偏见问题的办法是改进人工智能与人类的互动，实现个性化输出而不牺牲生产力。

    When working with generative artificial intelligence (AI), users may see productivity gains, but the AI-generated content may not match their preferences exactly. To study this effect, we introduce a Bayesian framework in which heterogeneous users choose how much information to share with the AI, facing a trade-off between output fidelity and communication cost. We show that the interplay between these individual-level decisions and AI training may lead to societal challenges. Outputs may become more homogenized, especially when the AI is trained on AI-generated content. And any AI bias may become societal bias. A solution to the homogenization and bias issues is to improve human-AI interactions, enabling personalized outputs without sacrificing productivity.
    
[^110]: 用DiscoSCMs回答Layer 3查询

    Answering Layer 3 queries with DiscoSCMs. (arXiv:2309.09323v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2309.09323](http://arxiv.org/abs/2309.09323)

    本文介绍了DiscoSCMs，一种用于解决因果查询的模型。它通过扩展结构因果模型和潜在结果框架来解决一致性规则引发的退化问题，并在分析个性化激励场景中的潜在结果时展示了其有效性。通过引入独立潜在噪声条件，可以提高解决Layer 3查询的准确性和可解释性。

    

    在当代因果推断研究中，解决Pearl因果层次（PCH）下的关联、干预和反事实的因果查询是一个核心任务。本文针对一致性规则引发的退化问题，引入了分布一致性结构因果模型（DiscoSCMs），扩展了结构因果模型（SCM）和潜在结果框架。以个性化激励场景中潜在结果的相关模式$P(y_x, y'_{x'})$为案例研究。尽管反事实不再退化，但仍无法确定。因此，将独立潜在噪声条件纳入DiscoSCM。发现通过适应分布的嵌入式推断，可以极大地提高解决Layer 3查询的准确性和可解释性。

    Addressing causal queries across the Pearl Causal Hierarchy (PCH) (i.e., associational, interventional and counterfactual), which is formalized as \Layer{} Valuations, is a central task in contemporary causal inference research. Counterfactual questions, in particular, pose a significant challenge as they often necessitate a complete knowledge of structural equations. This paper identifies \textbf{the degeneracy problem} caused by the consistency rule. To tackle this, the \textit{Distribution-consistency Structural Causal Models} (DiscoSCMs) is introduced, which extends both the structural causal models (SCM) and the potential outcome framework. The correlation pattern of potential outcomes in personalized incentive scenarios, described by $P(y_x, y'_{x'})$, is used as a case study for elucidation. Although counterfactuals are no longer degenerate, they remain indeterminable. As a result, the condition of independent potential noise is incorporated into DiscoSCM. It is found that by ad
    
[^111]: MusiLingo：利用预训练的语言模型将音乐和文本相结合，实现音乐字幕和查询响应

    MusiLingo: Bridging Music and Text with Pre-trained Language Models for Music Captioning and Query Response. (arXiv:2309.08730v1 [eess.AS])

    [http://arxiv.org/abs/2309.08730](http://arxiv.org/abs/2309.08730)

    MusiLingo是一个利用预训练的语言模型将音乐和文本相结合的系统，可以生成音乐字幕和回答音乐相关的查询。通过使用投影层对齐音乐表示，该系统成功地将音乐音频和文本环境联系起来，同时使用了一个新的数据集来推动领域的进展。

    

    大型语言模型（LLM）已经在多模态应用中展现出巨大潜力，然而文本和音乐领域的融合仍相对未被探索。为了解决这一问题，我们提出了MusiLingo，这是一个用于音乐字幕生成和音乐相关查询响应的新系统。MusiLingo使用一个投影层来对齐预训练的冻结音乐音频模型MERT和冻结的LLaMA语言模型的音乐表示，实现音乐音频和文本环境之间的桥梁。我们在一个大规模的音乐字幕数据集上进行训练，并使用指导性数据进行微调。由于高质量的音乐问答数据集稀缺，我们从MusicCaps创建了MusicInstruct（MI）数据集，专为开放式音乐查询而设计。实证评估证明了它在生成音乐字幕和组织音乐相关问答对方面的竞争性表现。我们引入的数据集在之前的数据集的基础上取得了显著进展。

    Large Language Models (LLMs) have shown immense potential in multimodal applications, yet the convergence of textual and musical domains remains relatively unexplored. To address this gap, we present MusiLingo, a novel system for music caption generation and music-related query responses. MusiLingo employs a single projection layer to align music representations from the pre-trained frozen music audio model MERT with the frozen LLaMA language model, bridging the gap between music audio and textual contexts. We train it on an extensive music caption dataset and fine-tune it with instructional data. Due to the scarcity of high-quality music Q&A datasets, we created the MusicInstruct (MI) dataset from MusicCaps, tailored for open-ended music inquiries. Empirical evaluations demonstrate its competitive performance in generating music captions and composing music-related Q&A pairs. Our introduced dataset enables notable advancements beyond previous ones.
    
[^112]: 高效强化学习用于跳跃式单脚机器人

    Efficient Reinforcement Learning for Jumping Monopods. (arXiv:2309.07038v1 [cs.RO])

    [http://arxiv.org/abs/2309.07038](http://arxiv.org/abs/2309.07038)

    本论文研究了如何通过在强化学习框架中注入物理知识来解决跳跃式单脚机器人的控制问题，这样可以大幅减少学习时间并且能够学习和修正可能出现的错误。

    

    在这项工作中，我们考虑了一个复杂的控制问题，即使单脚机器人能够跳到任何方向，其脚下的地形可能是不平的，我们要使它达到目标位置。这是一个更大类别问题的模板，使用标准的基于优化的技术解决这些问题非常具有挑战性和计算开销。强化学习 (RL) 可能是一个有趣的替代方案，但完全从零开始学习的端到端方法是不切实际的。本文提出的解决方案是在 RL 框架中注入物理知识来指导学习过程。这种方法带来了广泛的好处，如大幅减少学习时间，并且能够学习和修正执行运动的低级控制器可能出现的错误。我们通过与基于优化和端到端 RL 方法的比较，证明了我们方法的优势。

    In this work, we consider the complex control problem of making a monopod reach a target with a jump. The monopod can jump in any direction and the terrain underneath its foot can be uneven. This is a template of a much larger class of problems, which are extremely challenging and computationally expensive to solve using standard optimisation-based techniques. Reinforcement Learning (RL) could be an interesting alternative, but the application of an end-to-end approach in which the controller must learn everything from scratch, is impractical. The solution advocated in this paper is to guide the learning process within an RL framework by injecting physical knowledge. This expedient brings to widespread benefits, such as a drastic reduction of the learning time, and the ability to learn and compensate for possible errors in the low-level controller executing the motion. We demonstrate the advantage of our approach with respect to both optimization-based and end-to-end RL approaches.
    
[^113]: 纯蒙特卡洛反事实遗憾最小化

    Pure Monte Carlo Counterfactual Regret Minimization. (arXiv:2309.03084v1 [cs.AI])

    [http://arxiv.org/abs/2309.03084](http://arxiv.org/abs/2309.03084)

    纯蒙特卡洛反事实遗憾最小化算法（PCFR）是一种结合了反事实遗憾最小化（CFR）和虚拟游戏（FP）概念的新算法，能够与各种CFR变体相结合，包括蒙特卡洛CFR（MCCFR）。PCFR具有更好的性能和较快的收敛速度，同时降低了时间和空间复杂度。

    

    反事实遗憾最小化（CFR）及其变体是目前解决大规模不完全信息博弈的最佳算法。本文在CFR的基础上提出了一种名为纯CFR（PCFR）的新算法，以实现更好的性能。PCFR可以看作是CFR和虚拟游戏（FP）的结合，继承了CFR的反事实遗憾（值）的概念，并在下一次迭代中使用最佳响应策略而不是遗憾匹配策略。我们的理论证明了PCFR可以实现Blackwell可达性，使PCFR能够与包括蒙特卡洛CFR（MCCFR）在内的任何CFR变体相结合。由此产生的纯MCCFR（PMCCFR）可以大大降低时间和空间复杂度。特别地，PMCCFR的收敛速度至少比MCCFR快三倍。此外，由于PMCCFR不通过严格被支配策略的路径，我们开发了一种新的启动算法，受到了严格被支配策略的启示。

    Counterfactual Regret Minimization (CFR) and its variants are the best algorithms so far for solving large-scale incomplete information games. Building upon CFR, this paper proposes a new algorithm named Pure CFR (PCFR) for achieving better performance. PCFR can be seen as a combination of CFR and Fictitious Play (FP), inheriting the concept of counterfactual regret (value) from CFR, and using the best response strategy instead of the regret matching strategy for the next iteration. Our theoretical proof that PCFR can achieve Blackwell approachability enables PCFR's ability to combine with any CFR variant including Monte Carlo CFR (MCCFR). The resultant Pure MCCFR (PMCCFR) can significantly reduce time and space complexity. Particularly, the convergence speed of PMCCFR is at least three times more than that of MCCFR. In addition, since PMCCFR does not pass through the path of strictly dominated strategies, we developed a new warm-start algorithm inspired by the strictly dominated strat
    
[^114]: ReLLa: 基于检索增强的大型语言模型的推荐系统中的生命周期序列行为理解

    ReLLa: Retrieval-enhanced Large Language Models for Lifelong Sequential Behavior Comprehension in Recommendation. (arXiv:2308.11131v1 [cs.IR])

    [http://arxiv.org/abs/2308.11131](http://arxiv.org/abs/2308.11131)

    本论文提出了一种名为ReLLa的检索增强大型语言模型框架，用于零样本和小样本推荐任务。通过语义用户行为检索（SUBR）来提取上下文中的有用信息，以改善LLMs的推荐性能。

    

    随着大型语言模型（LLMs）在自然语言处理（NLP）领域取得了显著突破，基于LLM的推荐系统引起了广泛关注并被积极探索。本文专注于适应和增强纯大型语言模型以用于零样本和小样本推荐任务。首先，我们针对推荐领域中LLMs无法从长用户行为序列的文本上下文中提取有用信息的问题，提出并定义了生命周期序列行为理解问题。为了解决这个问题并提高LLMs的推荐性能，我们提出了一种新的框架，即检索增强的大型语言模型（ReLLa）。针对零样本推荐，我们执行语义用户行为检索（SUBR）来提高数据的利用率。

    With large language models (LLMs) achieving remarkable breakthroughs in natural language processing (NLP) domains, LLM-enhanced recommender systems have received much attention and have been actively explored currently. In this paper, we focus on adapting and empowering a pure large language model for zero-shot and few-shot recommendation tasks. First and foremost, we identify and formulate the lifelong sequential behavior incomprehension problem for LLMs in recommendation domains, i.e., LLMs fail to extract useful information from a textual context of long user behavior sequence, even if the length of context is far from reaching the context limitation of LLMs. To address such an issue and improve the recommendation performance of LLMs, we propose a novel framework, namely Retrieval-enhanced Large Language models (ReLLa) for recommendation tasks in both zero-shot and few-shot settings. For zero-shot recommendation, we perform semantic user behavior retrieval (SUBR) to improve the data
    
[^115]: MM-Vet: 评估大型多模态模型的综合能力

    MM-Vet: Evaluating Large Multimodal Models for Integrated Capabilities. (arXiv:2308.02490v1 [cs.AI])

    [http://arxiv.org/abs/2308.02490](http://arxiv.org/abs/2308.02490)

    MM-Vet是一个评估标准，用于评估大型多模态模型在复杂任务上的综合能力。该标准解决了如何结构化和评估复杂多模态任务、设计适用于不同问题和回答类型的评估指标以及如何提供模型洞察的问题。通过整合不同的核心视觉-语言能力，MM-Vet展示了有趣的能力和解决复杂任务的方法。

    

    我们提出了MM-Vet，一个评估标准，用于检查在复杂多模态任务上的大型多模态模型（LMM）的表现。最近的LMM展示了各种有趣的能力，例如解决书写在黑板上的数学问题，推理新闻图片中的事件和名人，以及解释视觉笑话。快速的模型进步给评估标准的开发带来了挑战。问题包括：（1）如何系统地构建和评估复杂的多模态任务；（2）如何设计适用于不同类型问题和回答的评估指标；（3）如何给出超出简单性能排名的模型洞察。为此，我们提出了MM-Vet，基于这样一个洞察：解决复杂任务的有趣能力通常通过一种通才模型能够整合不同的核心视觉-语言（VL）能力来实现。MM-Vet定义了6个核心VL能力，并检查了从这些能力组合中得出的16种有趣的整合方式。

    We propose MM-Vet, an evaluation benchmark that examines large multimodal models (LMMs) on complicated multimodal tasks. Recent LMMs have shown various intriguing abilities, such as solving math problems written on the blackboard, reasoning about events and celebrities in news images, and explaining visual jokes. Rapid model advancements pose challenges to evaluation benchmark development. Problems include: (1) How to systematically structure and evaluate the complicated multimodal tasks; (2) How to design evaluation metrics that work well across question and answer types; and (3) How to give model insights beyond a simple performance ranking. To this end, we present MM-Vet, designed based on the insight that the intriguing ability to solve complicated tasks is often achieved by a generalist model being able to integrate different core vision-language (VL) capabilities. MM-Vet defines 6 core VL capabilities and examines the 16 integrations of interest derived from the capability combin
    
[^116]: AutoML4ETC: 自动化神经架构搜索实现现实世界加密流量分类

    AutoML4ETC: Automated Neural Architecture Search for Real-World Encrypted Traffic Classification. (arXiv:2308.02182v1 [cs.NI])

    [http://arxiv.org/abs/2308.02182](http://arxiv.org/abs/2308.02182)

    AutoML4ETC是一个自动设计高效且高性能神经架构的工具，用于加密流量分类。其通过定义新颖的搜索空间和使用不同的搜索策略，在多个数据集上优于当前最先进的加密流量分类器。

    

    在实验环境中，深度学习（DL）已成功应用于加密网络流量分类。然而，在实际应用中，DL分类器的性能随时间不可避免地下降。仅仅对新数据集进行模型重新训练只能部分提高其性能。手动调整模型架构以满足新数据集上的性能期望耗时且需要领域专业知识。本文提出了一种新颖的工具AutoML4ETC，用于自动设计高效且高性能的神经架构以进行加密流量分类。我们定义了一个新颖而强大的搜索空间，专门针对使用数据包头字节进行近实时加密流量分类。通过在搜索空间上使用不同的搜索策略，我们展示了AutoML4ETC生成的神经架构在多个数据集上均优于当前最先进的加密流量分类器，包括公共基准数据集。

    Deep learning (DL) has been successfully applied to encrypted network traffic classification in experimental settings. However, in production use, it has been shown that a DL classifier's performance inevitably decays over time. Re-training the model on newer datasets has been shown to only partially improve its performance. Manually re-tuning the model architecture to meet the performance expectations on newer datasets is time-consuming and requires domain expertise. We propose AutoML4ETC, a novel tool to automatically design efficient and high-performing neural architectures for encrypted traffic classification. We define a novel, powerful search space tailored specifically for the near real-time classification of encrypted traffic using packet header bytes. We show that with different search strategies over our search space, AutoML4ETC generates neural architectures that outperform the state-of-the-art encrypted traffic classifiers on several datasets, including public benchmark dat
    
[^117]: 关于注意力网络学习动态的研究

    On the learning Dynamics of Attention Networks. (arXiv:2307.13421v1 [cs.LG])

    [http://arxiv.org/abs/2307.13421](http://arxiv.org/abs/2307.13421)

    本研究分析了软注意力、硬注意力和潜变量边际似然（LVML）注意力三种注意力模型的学习动态，发现了它们在所选择的片段聚合方式上的显著差异，并解释了分类模型在梯度下降下的演化对最终结果的影响。

    

    注意力模型通常通过优化三个标准损失函数之一来学习，分别称为软注意力、硬注意力和潜变量边际似然（LVML）注意力。这三种范式都是为了达到相同的目标，即找到两个模型：一个“焦点”模型，用于“选择”输入中的正确“片段”，和一个“分类”模型，用于将选定的片段处理成目标标签。然而，它们在所选择的片段聚合方式上存在显著差异，导致了不同的动态和最终结果。我们观察到使用这些范式学习的模型具有独特的特征，并将其解释为在焦点模型固定时，分类模型在梯度下降下的演化所致。我们还在一个简单的设置中分析了这些范式，并推导出梯度流下参数轨迹的闭式表达式。在软注意力损失下，焦点模型在初始化阶段快速改善。

    Attention models are typically learned by optimizing one of three standard loss functions that are variously called -- soft attention, hard attention, and latent variable marginal likelihood (LVML) attention. All three paradigms are motivated by the same goal of finding two models -- a `focus' model that `selects' the right \textit{segment} of the input and a `classification' model that processes the selected segment into the target label. However, they differ significantly in the way the selected segments are aggregated, resulting in distinct dynamics and final results. We observe a unique signature of models learned using these paradigms and explain this as a consequence of the evolution of the classification model under gradient descent when the focus model is fixed. We also analyze these paradigms in a simple setting and derive closed-form expressions for the parameter trajectory under gradient flow. With the soft attention loss, the focus model improves quickly at initialization a
    
[^118]: Espaloma-0.3.0: 用于蛋白质-配体系统模拟的机器学习分子力学力场及其扩展

    Espaloma-0.3.0: Machine-learned molecular mechanics force field for the simulation of protein-ligand systems and beyond. (arXiv:2307.07085v1 [physics.chem-ph])

    [http://arxiv.org/abs/2307.07085](http://arxiv.org/abs/2307.07085)

    Espaloma-0.3.0是一个用于蛋白质-配体系统模拟的机器学习分子力学力场，通过能量和力的拟合纳入量子化学数据进行训练，具有灵活性和可扩展性。

    

    分子力学（MM）力场是通过简单的一对一和多项式项来表征分子系统能量景观的模型。传统上，它们依赖于人工专家策划、不灵活且难以扩展的离散化化学参数赋值规则，即原子或价态类型。最近，人们对使用图神经网络替代此过程，并使参数化方案能够直接从量子化学计算或凝聚相数据中以端到端的可微分方式进行学习表示出了巨大兴趣。在本文中，我们通过将能量和力的适应性拟合直接纳入训练过程，扩展了Espaloma的端到端可微分力场构建方法。基于OpenMM SPICE数据集，我们策划了一个包含与生物分子建模广泛相关的化学空间的数据集，涵盖小分子、蛋白质和RNA。最终得到了一个适用于蛋白质-配体系统模拟的机器学习分子力学力场。

    Molecular mechanics (MM) force fields -- the models that characterize the energy landscape of molecular systems via simple pairwise and polynomial terms -- have traditionally relied on human expert-curated, inflexible, and poorly extensible discrete chemical parameter assignment rules, namely atom or valence types. Recently, there has been significant interest in using graph neural networks to replace this process, while enabling the parametrization scheme to be learned in an end-to-end differentiable manner directly from quantum chemical calculations or condensed-phase data. In this paper, we extend the Espaloma end-to-end differentiable force field construction approach by incorporating both energy and force fitting directly to quantum chemical data into the training process. Building on the OpenMM SPICE dataset, we curate a dataset containing chemical spaces highly relevant to the broad interest of biomolecular modeling, covering small molecules, proteins, and RNA. The resulting for
    
[^119]: 通过一个空格绕过ChatGPT检测器

    Evade ChatGPT Detectors via A Single Space. (arXiv:2307.02599v1 [cs.CL])

    [http://arxiv.org/abs/2307.02599](http://arxiv.org/abs/2307.02599)

    本研究发现，当前的ChatGPT检测器不能有效区分人类生成和AI生成内容之间的差异，而一个额外的空格成为了规避检测的关键因素。

    

    ChatGPT带来了革命性的社会价值，但也引发了人们对于AI生成内容滥用的担忧。因此，一个重要问题是如何检测出内容是由ChatGPT生成还是人类生成的。现有的检测器是建立在人类生成和AI生成内容之间存在分布差距的假设上的。这些差距通常是通过统计信息或分类器来识别的。我们的研究质疑了检测器中的分布差距假设。我们发现检测器不能有效地区分人类生成和AI生成内容之间的语义和风格差距。相反，"微小的差异"，如额外的一个空格，在检测中变得至关重要。基于这一发现，我们提出了SpaceInfi策略来规避检测。实验证明了这种策略在多个基准和检测器上的有效性。我们还对为什么SpaceInfi能成功规避检测提供了理论解释。

    ChatGPT brings revolutionary social value but also raises concerns about the misuse of AI-generated content. Consequently, an important question is how to detect whether content is generated by ChatGPT or by human. Existing detectors are built upon the assumption that there are distributional gaps between human-generated and AI-generated content. These gaps are typically identified using statistical information or classifiers. Our research challenges the distributional gap assumption in detectors. We find that detectors do not effectively discriminate the semantic and stylistic gaps between human-generated and AI-generated content. Instead, the "subtle differences", such as an extra space, become crucial for detection. Based on this discovery, we propose the SpaceInfi strategy to evade detection. Experiments demonstrate the effectiveness of this strategy across multiple benchmarks and detectors. We also provide a theoretical explanation for why SpaceInfi is successful in evading perple
    
[^120]: 基于图神经网络的日志异常检测与解释

    Graph Neural Networks based Log Anomaly Detection and Explanation. (arXiv:2307.00527v2 [cs.SE] UPDATED)

    [http://arxiv.org/abs/2307.00527](http://arxiv.org/abs/2307.00527)

    提出了一种基于图神经网络的无监督日志异常检测方法，该方法将事件日志转换为带属性、有向和加权的图，并利用图神经网络进行图级别的异常检测。引入了一种新的图神经网络模型OCDiGCN来检测一组带属性、有向和加权的图中的图级别异常，并提供对异常的解释能力。

    

    事件日志被广泛用于记录高科技系统的状态，因此日志异常检测对于监控这些系统非常重要。大多数现有的日志异常检测方法将日志事件计数矩阵或日志事件序列作为输入，利用日志事件之间的定量和/或顺序关系来检测异常。然而，仅考虑定量或顺序关系可能导致检测准确性较低。为了缓解这个问题，我们提出了一种基于图的无监督日志异常检测方法，称为Logs2Graphs，它首先将事件日志转换为带属性、有向和加权的图，然后利用图神经网络进行图级别的异常检测。具体而言，我们提出了一种全新的图神经网络模型One-Class Digraph Inception Convolutional Networks（OCDiGCN），用于在一组带属性、有向和加权的图中检测图级别的异常。通过将图表示与属性表示耦合起来，在图级别上进行异常检测的同时提供了对异常的解释能力。

    Event logs are widely used to record the status of high-tech systems, making log anomaly detection important for monitoring those systems. Most existing log anomaly detection methods take a log event count matrix or log event sequences as input, exploiting quantitative and/or sequential relationships between log events to detect anomalies. Unfortunately, only considering quantitative or sequential relationships may result in low detection accuracy. To alleviate this problem, we propose a graph-based method for unsupervised log anomaly detection, dubbed Logs2Graphs, which first converts event logs into attributed, directed, and weighted graphs, and then leverages graph neural networks to perform graph-level anomaly detection. Specifically, we introduce One-Class Digraph Inception Convolutional Networks, abbreviated as OCDiGCN, a novel graph neural network model for detecting graph-level anomalies in a collection of attributed, directed, and weighted graphs. By coupling the graph represe
    
[^121]: 针对不规则时间序列的异常检测的前体

    Precursor-of-Anomaly Detection for Irregular Time Series. (arXiv:2306.15489v1 [cs.AI])

    [http://arxiv.org/abs/2306.15489](http://arxiv.org/abs/2306.15489)

    本文提出了一种新型异常检测方法，称为前体-异常检测（PoA检测）。与传统的异常检测不同，PoA检测旨在在异常发生之前检测到未来的异常。通过使用基于神经控制微分方程的神经网络和多任务学习算法，我们在17个基准线和3个数据集上进行实验证明了我们的方法的有效性。

    

    异常检测是一个重要领域，旨在识别意外的模式或数据点，并与许多现实世界的问题密切相关，尤其是在金融、制造、网络安全等应用中。虽然异常检测在各个领域已经被广泛研究，但在异常发生之前检测到未来的异常仍然是一个未开发的领域。在本文中，我们提出了一种新型的异常检测方法，称为“前体-异常”（PoA）检测。与传统的异常检测不同，传统的异常检测侧重于确定给定时间序列观测值是否为异常，而PoA检测旨在在异常发生之前检测到未来的异常。为了同时解决这两个问题，我们提出了一种基于神经控制微分方程的神经网络及其多任务学习算法。我们使用17个基准线和3个数据集进行实验，包括规则和不规则时间序列，并证明了我们的方法的有效性。

    Anomaly detection is an important field that aims to identify unexpected patterns or data points, and it is closely related to many real-world problems, particularly to applications in finance, manufacturing, cyber security, and so on. While anomaly detection has been studied extensively in various fields, detecting future anomalies before they occur remains an unexplored territory. In this paper, we present a novel type of anomaly detection, called \emph{\textbf{P}recursor-of-\textbf{A}nomaly} (PoA) detection. Unlike conventional anomaly detection, which focuses on determining whether a given time series observation is an anomaly or not, PoA detection aims to detect future anomalies before they happen. To solve both problems at the same time, we present a neural controlled differential equation-based neural network and its multi-task learning algorithm. We conduct experiments using 17 baselines and 3 datasets, including regular and irregular time series, and demonstrate that our prese
    
[^122]: SIMF: 自动驾驶的语义感知交互式运动预测

    SIMF: Semantics-aware Interactive Motion Forecasting for Autonomous Driving. (arXiv:2306.14941v1 [cs.CV])

    [http://arxiv.org/abs/2306.14941](http://arxiv.org/abs/2306.14941)

    本文提出了一种名为SIMF的方法，用于自动驾驶车辆中语义感知的交互式运动预测。该方法通过实现基于语义的行为体选择和注意力机制提取全局编码，能够捕捉空间信息和语义信息，并优选相关的行为体进行运动预测。

    

    自动驾驶车辆需要对周围多个行为体（行人和车辆）进行运动预测，以做出最优导航决策。现有的方法主要关注如何利用这些行为体的位置和速度，并未能捕捉到场景中的语义信息。此外，为了减少与场景中行为体数量增加相关的计算复杂度，一些方法利用欧氏距离来剪枝远离的行为体。然而，仅仅基于距离的度量无法选择相关的行为体并准确进行预测。为了解决这些问题，我们提出了一种称为SIMF的方法，用于捕捉空间信息以及语义信息，并优选相关的行为体进行运动预测。具体而言，我们通过实现一种基于语义的行为体选择方法，将其通过注意力机制传递，以提取全局编码。

    Autonomous vehicles require motion forecasting of their surrounding multi-agents (pedestrians and vehicles) to make optimal decisions for navigation. The existing methods focus on techniques to utilize the positions and velocities of these agents and fail to capture semantic information from the scene. Moreover, to mitigate the increase in computational complexity associated with the number of agents in the scene, some works leverage Euclidean distance to prune far-away agents. However, distance-based metric alone is insufficient to select relevant agents and accurately perform their predictions. To resolve these issues, we propose Semantics-aware Interactive Motion Forecasting (SIMF) method to capture semantics along with spatial information, and optimally select relevant agents for motion prediction. Specifically, we achieve this by implementing a semantic-aware selection of relevant agents from the scene and passing them through an attention mechanism to extract global encodings. Th
    
[^123]: 一种基于物理学知识的人工智能方法用于计算熔点并控制不确定性和最优采样

    A physics-informed AI method for calculating melting points with uncertainty control and optimal sampling. (arXiv:2306.13345v1 [cond-mat.mtrl-sci])

    [http://arxiv.org/abs/2306.13345](http://arxiv.org/abs/2306.13345)

    本文提出了一种基于物理学知识和人工智能的计算熔点的方法，并演示了如何增强其准确性和控制不确定性。

    

    我们提出了一种人工智能（AI）方法，通过NPT集合中的共存模拟自动计算熔点。给定原子间相互作用模型，该方法决定进行模拟的原子数量和温度，并基于收集的数据预测熔点及其不确定性，可以通过更多的数据系统地提高其准确性。我们演示了如何将固液共存演化的物理模型纳入AI方法，增强其准确性，并实现有效降低预测不确定性的最优决策。为验证我们的方法，我们将结果与大约20个文献中的熔点计算进行比较。值得注意的是，在约三分之一的情况下观察到显著偏差，突显出材料性质计算需要准确可靠的基于AI的算法的必要性。

    We present an artificial intelligence (AI) method for automatically computing the melting point based on coexistence simulations in the NPT ensemble. Given the interatomic interaction model, the method makes decisions regarding the number of atoms and temperature at which to conduct simulations, and based on the collected data predicts the melting point along with the uncertainty, which can be systematically improved with more data. We demonstrate how incorporating physical models of the solid-liquid coexistence evolution enhances the AI method's accuracy and enables optimal decision-making to effectively reduce predictive uncertainty. To validate our approach, we compare our results with approximately 20 melting point calculations from the literature. Remarkably, we observe significant deviations in about one-third of the cases, underscoring the need for accurate and reliable AI-based algorithms for materials property calculations.
    
[^124]: 机器人操纵的通用语义几何表示

    A Universal Semantic-Geometric Representation for Robotic Manipulation. (arXiv:2306.10474v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2306.10474](http://arxiv.org/abs/2306.10474)

    这篇论文提出了一种通用的机器人感知模块，称为语义几何表示（SGR），该模块结合了大规模预训练的2D模型的丰富语义信息和3D空间推理的优势，能够在各种模拟和真实世界的机器人操纵任务中胜过最先进的方法。

    

    机器人在感知和与世界互动时 heavily relies 传感器，特别是RGB和深度相机。RGB相机记录了具有丰富语义信息的2D图像，但缺乏精确的空间信息。另一方面，深度相机提供了关键的3D几何数据，但捕捉到的语义有限。因此，整合两种模态对于学习机器人感知和控制的表示是至关重要的。然而，当前的研究主要集中在其中一种模态上，并忽略了结合两者的好处。为此，我们提出了$\textbf{语义几何表示} (\textbf{SGR})$，这是一个用于机器人的通用感知模块，它利用了大规模预训练的2D模型的丰富语义信息，并承继了3D空间推理的优点。我们的实验表明，SGR使机器人能够成功完成各种模拟和真实世界的机器人操纵任务，胜过了最先进的方法。

    Robots rely heavily on sensors, especially RGB and depth cameras, to perceive and interact with the world. RGB cameras record 2D images with rich semantic information while missing precise spatial information. On the other side, depth cameras offer critical 3D geometry data but capture limited semantics. Therefore, integrating both modalities is crucial for learning representations for robotic perception and control. However, current research predominantly focuses on only one of these modalities, neglecting the benefits of incorporating both. To this end, we present $\textbf{Semantic-Geometric Representation} (\textbf{SGR})$, a universal perception module for robotics that leverages the rich semantic information of large-scale pre-trained 2D models and inherits the merits of 3D spatial reasoning. Our experiments demonstrate that SGR empowers the agent to successfully complete a diverse range of simulated and real-world robotic manipulation tasks, outperforming state-of-the-art methods 
    
[^125]: 基于Implicit Neural Representations的时间序列连续建模用于插值和预测

    Time Series Continuous Modeling for Imputation and Forecasting with Implicit Neural Representations. (arXiv:2306.05880v1 [cs.LG])

    [http://arxiv.org/abs/2306.05880](http://arxiv.org/abs/2306.05880)

    该论文提出了基于INR的时间序列连续建模方法，解决了处理缺失数据、不规则采样和多传感器不对准观测等重复建模问题，并在预测和插值任务中取得了最新的性能表现，具有很好的泛化能力。

    

    尽管时间序列建模已被广泛探索，但在面对真实世界的数据时仍面临重大挑战。我们提出了一种新颖的建模方法，利用Implicit Neural Representations (INR)。该方法使我们能够有效地捕捉时间序列的连续性，并提供了自然的解决方案，以处理缺失数据、处理不规则采样或来自多个传感器的不对准观测等重复建模问题。通过引入条件调制INR参数并利用元学习技术，我们解决了模型泛化到未见样本和时间窗口移位的问题。通过大量实验，我们的模型展示了在预测和插值任务中领先的性能，同时在处理许多竞争模型无法处理的各种具有挑战性的场景方面展现了灵活性。

    Although widely explored, time series modeling continues to encounter significant challenges when confronted with real-world data. We propose a novel modeling approach leveraging Implicit Neural Representations (INR). This approach enables us to effectively capture the continuous aspect of time series and provides a natural solution to recurring modeling issues such as handling missing data, dealing with irregular sampling, or unaligned observations from multiple sensors. By introducing conditional modulation of INR parameters and leveraging meta-learning techniques, we address the issue of generalization to both unseen samples and time window shifts. Through extensive experimentation, our model demonstrates state-of-the-art performance in forecasting and imputation tasks, while exhibiting flexibility in handling a wide range of challenging scenarios that competing models cannot.
    
[^126]: 抓住意外收获：在离线策略演员-评论家中利用过去成功的价值(arXiv:2306.02865v2 [cs.LG]已更新)

    Seizing Serendipity: Exploiting the Value of Past Success in Off-Policy Actor-Critic. (arXiv:2306.02865v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.02865](http://arxiv.org/abs/2306.02865)

    该论文提出了 BEE 操作符，通过充分利用过去的成功经验，并保持探索乐观性，解决了离线策略演员-评论家中 Q 值高估与低估问题，提高了策略学习和样本效率。

    

    学习高质量的 Q 值函数在许多现代离线深度强化学习 (RL) 算法的成功中起着关键作用。之前的研究集中解决采用函数逼近器和离线学习所导致的值过高的问题。与这种普遍观点不同，我们观察到 Q 值在 RL 训练过程的后期实际上被低估了，主要是由于贝尔曼更新中，当前策略使用比回放缓冲区中更优的动作样本差。我们假设这个长期被忽视的现象可能阻碍了策略学习，降低了样本效率。我们的想法是在保持探索乐观性的同时，结合充分利用过去成功的经验。我们提出了混合利用和探索 (BEE) 操作符，这是一种简单而有效的方法，使用历史上表现最佳的动作和当前策略生成的动作来更新 Q 值。

    Learning high-quality Q-value functions plays a key role in the success of many modern off-policy deep reinforcement learning (RL) algorithms. Previous works focus on addressing the value overestimation issue, an outcome of adopting function approximators and off-policy learning. Deviating from the common viewpoint, we observe that Q-values are indeed underestimated in the latter stage of the RL training process, primarily related to the use of inferior actions from the current policy in Bellman updates as compared to the more optimal action samples in the replay buffer. We hypothesize that this long-neglected phenomenon potentially hinders policy learning and reduces sample efficiency. Our insight to address this issue is to incorporate sufficient exploitation of past successes while maintaining exploration optimism. We propose the Blended Exploitation and Exploration (BEE) operator, a simple yet effective approach that updates Q-value using both historical best-performing actions and
    
[^127]: 基于语言条件的模仿学习与基础技能先验下的非结构化数据应用

    Language-Conditioned Imitation Learning with Base Skill Priors under Unstructured Data. (arXiv:2305.19075v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2305.19075](http://arxiv.org/abs/2305.19075)

    本文提出了一种结合基础技能先验和模仿学习的基于语言条件的通用方法，在非结构化数据下，以增强算法在适应不熟悉的环境方面的泛化能力。在零-shot设置下，在模拟和真实环境中测试，提高了CALVIN基准测试的得分。

    

    在语言条件下的机器人操作越来越受到关注，旨在开发能够理解和执行复杂任务的机器人，以实现机器人根据语言指令操作物体的目标。虽然语言条件方法在熟悉的环境中处理任务表现出了令人印象深刻的能力，但在适应不熟悉的环境设置方面遇到了限制。在本文中，我们提出了一个通用的、基于语言条件的方法，结合了基础技能先验和模仿学习在非结构化数据下，以增强算法在适应不熟悉的环境方面的泛化能力。我们在模拟和真实环境中使用零-shot设置来评估我们模型的性能。在模拟环境中，所提出的方法在CALVIN基准测试方面超过了以前报告的得分，特别是在具有挑战性的零-shot多环境设置中。完成任务的平均长度为...

    The growing interest in language-conditioned robot manipulation aims to develop robots capable of understanding and executing complex tasks, with the objective of enabling robots to interpret language commands and manipulate objects accordingly. While language-conditioned approaches demonstrate impressive capabilities for addressing tasks in familiar environments, they encounter limitations in adapting to unfamiliar environment settings. In this study, we propose a general-purpose, language-conditioned approach that combines base skill priors and imitation learning under unstructured data to enhance the algorithm's generalization in adapting to unfamiliar environments. We assess our model's performance in both simulated and real-world environments using a zero-shot setting. In the simulated environment, the proposed approach surpasses previously reported scores for CALVIN benchmark, especially in the challenging Zero-Shot Multi-Environment setting. The average completed task length, in
    
[^128]: 学习特征中的瓶颈结构：低维度与规律性的权衡

    Bottleneck Structure in Learned Features: Low-Dimension vs Regularity Tradeoff. (arXiv:2305.19008v1 [cs.LG])

    [http://arxiv.org/abs/2305.19008](http://arxiv.org/abs/2305.19008)

    本研究揭示了深度学习神经网路学习输入低维度表示和最小化特征映射中的复杂性/不规则性之间的权衡，控制了规律性，并利用理论工具证明了瓶颈结构的存在。

    

    先前研究表明，具有大深度$L$和$L_{2}$正则化的DNN偏向于学习输入的低维表示，可以解释为最小化学习函数$f$的秩$R^{(0)}(f)$的概念，其被推测为瓶颈秩。我们计算了这个结果的有限深度修正，揭示了一个度量$R^{(1)}$的规律性，它控制了雅可比矩阵$\left|Jf(x)\right|_{+}$的伪行列式并在组合和加法下是次可加的。这使得网络可以在学习低维表示和最小化特征映射中的复杂性/不规则性之间保持平衡，从而学习“正确”的内部尺寸。我们还展示了大学习速率如何控制学习函数的规律性。最后，我们使用这些理论工具证明了瓶颈结构在$L\to\infty$时在学习特征中的猜想：对于大深度，几乎所有的隐藏表示都集中在...

    Previous work has shown that DNNs with large depth $L$ and $L_{2}$-regularization are biased towards learning low-dimensional representations of the inputs, which can be interpreted as minimizing a notion of rank $R^{(0)}(f)$ of the learned function $f$, conjectured to be the Bottleneck rank. We compute finite depth corrections to this result, revealing a measure $R^{(1)}$ of regularity which bounds the pseudo-determinant of the Jacobian $\left|Jf(x)\right|_{+}$ and is subadditive under composition and addition. This formalizes a balance between learning low-dimensional representations and minimizing complexity/irregularity in the feature maps, allowing the network to learn the `right' inner dimension. We also show how large learning rates also control the regularity of the learned function. Finally, we use these theoretical tools to prove the conjectured bottleneck structure in the learned features as $L\to\infty$: for large depths, almost all hidden representations concentrates aroun
    
[^129]: 学生超越了大师：基于GPT-3的科学事实错误校正方法的匹配

    The student becomes the master: Matching GPT3 on Scientific Factual Error Correction. (arXiv:2305.14707v1 [cs.CL])

    [http://arxiv.org/abs/2305.14707](http://arxiv.org/abs/2305.14707)

    本文提出了一种不需要验证者且不做领域假设的主张校正系统，能够显著提高科学事实错误校正任务的性能，并通过使用LLM的提示方法和主张感知的解码过程来提高校正质量。

    

    由于创建错误校正数据集的成本极高，大多数事实主张校正方法依赖于强大的验证模型来指导校正过程。这导致在科学事实校正等领域性能显著下降，因为好的验证模型并不总是存在。在本研究中，我们介绍了一种不做领域假设且不需要验证者的主张校正系统，但能够比现有方法提高一个数量级的性能 - 在SciFact数据集上实现94％的修正准确性，在SciFact-Open数据集上实现62.5％的修正准确性，分别比下一个最好的方法高出0.5％和1.50％。我们的方法利用LLMs中的提示功能，在训练期间创建一个丰富注释的数据集，可用于完全监督的训练和正则化。我们还使用主张感知的解码过程来提高纠正主张的质量。我们的方法与用于创建数据集的LLM相竞争，证明了利用基于LLM的训练提高科学主张校正任务性能的可能性。

    Due to the prohibitively high cost of creating error correction datasets, most Factual Claim Correction methods rely on a powerful verification model to guide the correction process. This leads to a significant drop in performance in domains like Scientific Claim Correction, where good verification models do not always exist. In this work, we introduce a claim correction system that makes no domain assumptions and does not require a verifier but is able to outperform existing methods by an order of magnitude -- achieving 94% correction accuracy on the SciFact dataset, and 62.5% on the SciFact-Open dataset, compared to the next best methods 0.5% and 1.50% respectively. Our method leverages the power of prompting with LLMs during training to create a richly annotated dataset that can be used for fully supervised training and regularization. We additionally use a claim-aware decoding procedure to improve the quality of corrected claims. Our method is competitive with the very LLM that was
    
[^130]: 基于词典的同义词泛化的生物医学命名实体识别

    Biomedical Named Entity Recognition via Dictionary-based Synonym Generalization. (arXiv:2305.13066v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.13066](http://arxiv.org/abs/2305.13066)

    本研究提出了一种基于词典的方法来解决生物医学命名实体识别中的同义词泛化问题，通过引入同义词距离和噪声扰动正则化项，实现了对输入文本中的生物医学概念的识别。

    

    生物医学命名实体识别是生物医学自然语言处理中的核心任务之一。为了解决这个任务，已经提出了许多有监督/间接有监督的方法。尽管这些方法取得了显著的成功，但不可避免地需要大量的人力工作。为了减轻人力劳动的需求，已经提出了基于词典的方法，仅根据给定的词典提取命名实体。然而，现有的基于词典的方法的一个缺点是，它们难以识别给定词典中未列出的概念同义词，我们将其称为同义词泛化问题。在本研究中，我们提出了一种新颖的同义词泛化（SynGen）框架，通过基于跨度的预测识别输入文本中包含的生物医学概念。具体而言，SynGen引入了两个正则化项，即（1）同义词距离正则化项；和（2）噪声扰动正则化项，以最小化

    Biomedical named entity recognition is one of the core tasks in biomedical natural language processing (BioNLP). To tackle this task, numerous supervised/distantly supervised approaches have been proposed. Despite their remarkable success, these approaches inescapably demand laborious human effort. To alleviate the need of human effort, dictionary-based approaches have been proposed to extract named entities simply based on a given dictionary. However, one downside of existing dictionary-based approaches is that they are challenged to identify concept synonyms that are not listed in the given dictionary, which we refer as the synonym generalization problem. In this study, we propose a novel Synonym Generalization (SynGen) framework that recognizes the biomedical concepts contained in the input text using span-based predictions. In particular, SynGen introduces two regularization terms, namely, (1) a synonym distance regularizer; and (2) a noise perturbation regularizer, to minimize the
    
[^131]: 会话中的情感推理：因果发现方法的应用

    Affective Reasoning at Utterance Level in Conversations: A Causal Discovery Approach. (arXiv:2305.02615v1 [cs.CL])

    [http://arxiv.org/abs/2305.02615](http://arxiv.org/abs/2305.02615)

    本文提出了一种新的会话情感因果发现方法（CACD），并通过设计公共骨架和生成替代隐含原因解决了因果模型的不确定性和隐含原因的不可观察性的问题。这种方法可以在变长会话中发现因果关系。

    

    情感推理任务是包括会话中的情感识别、情感-原因对抽取和情感-原因跨度识别在内的一组新兴的基于情感的任务。现有的方法在假设表面关系时忽略了基本的因果模型，因为骨架的不确定性和隐含原因的不可观察性。本文解决了上述两个问题，并进一步提出了会话情感因果发现（CACD）方法。这是一种新颖的因果发现方法，展示了如何通过设计公共骨架和生成替代隐含原因来发现会话中的因果关系。CACD包含两个步骤：（i）为变长会话中的所有话语建立一个中心化的单一图节点因果骨架；（ii）因果自编码器（CAE）通过生成隐含原因和已知显式原因来修正骨架，从而产生因果表示。

    The affective reasoning task is a set of emerging affect-based tasks in conversation, including Emotion Recognition in Conversation (ERC),Emotion-Cause Pair Extraction (ECPE), and Emotion-Cause Span Recognition (ECSR). Existing methods make various assumptions on the apparent relationship while neglecting the essential causal model due to the nonuniqueness of skeletons and unobservability of implicit causes. This paper settled down the above two problems and further proposed Conversational Affective Causal Discovery (CACD). It is a novel causal discovery method showing how to discover causal relationships in a conversation via designing a common skeleton and generating a substitute for implicit causes. CACD contains two steps: (i) building a common centering one graph node causal skeleton for all utterances in variable-length conversations; (ii) Causal Auto-Encoder (CAE) correcting the skeleton to yield causal representation through generated implicit causes and known explicit causes. 
    
[^132]: ReelFramer：使用生成式人工智能与社交媒体共同创作新闻片段

    ReelFramer: Co-creating News Reels on Social Media with Generative AI. (arXiv:2304.09653v1 [cs.HC])

    [http://arxiv.org/abs/2304.09653](http://arxiv.org/abs/2304.09653)

    ReelFramer使用生成式人工智能与社交媒体共同创作新闻片段。它可以帮助记者探索一个故事的多种叙事框架，并生成脚本、角色板和故事板。用户研究发现该系统大大减轻了将一篇书面报道转化为新闻片段的负担。

    

    社交媒体上的短视频是许多年轻人发现和消费内容的主要方式。新闻机构希望通过新闻片段接触受众，但目前难以将传统的新闻报道格式转化为与平台风格相匹配的短小有趣视频。有多种方法可以围绕新闻事件构建片段式叙事，而选定其中一种则是具有挑战性的。不同的新闻故事需要不同的叙述框架，并需要在娱乐性和信息量之间达到不同的平衡。本文提出了一种名为ReelFramer的系统，利用文本和图像生成来帮助记者探索一个故事的多种叙事框架，然后生成他们可以编辑和迭代的脚本、角色板和故事板。在一项由五名新闻相关领域的研究生参与的用户研究中，我们发现该系统大大减轻了将一篇书面报道转化为新闻片段的负担，并探索叙事框架以找到正确的框架过程是非常有意义的。

    Short videos on social media are a prime way many young people find and consume content. News outlets would like to reach audiences through news reels, but currently struggle to translate traditional journalistic formats into the short, entertaining videos that match the style of the platform. There are many ways to frame a reel-style narrative around a news story, and selecting one is a challenge. Different news stories call for different framings, and require a different trade-off between entertainment and information. We present a system called ReelFramer that uses text and image generation to help journalists explore multiple narrative framings for a story, then generate scripts, character boards and storyboards they can edit and iterate on. A user study of five graduate students in journalism-related fields found the system greatly eased the burden of transforming a written story into a reel, and that exploring framings to find the right one was a rewarding process.
    
[^133]: 零和马尔可夫博弈中强化学习的新政策迭代算法

    A New Policy Iteration Algorithm For Reinforcement Learning in Zero-Sum Markov Games. (arXiv:2303.09716v1 [cs.LG])

    [http://arxiv.org/abs/2303.09716](http://arxiv.org/abs/2303.09716)

    本文提出了一种适用于零和马尔可夫博弈的简单但有效的策略迭代算法。

    

    许多基于模型的强化学习算法可以被视为具有两个阶段: 学习阶段和规划阶段。在标准MDPs情况下，可以使用价值迭代或策略迭代来解决学习问题。但在零和马尔可夫博弈的情况下，没有有效的策略迭代算法，以前的尝试都有局限性。本文提出了一种简单的策略迭代变体，能够有效地解决这个问题。

    Many model-based reinforcement learning (RL) algorithms can be viewed as having two phases that are iteratively implemented: a learning phase where the model is approximately learned and a planning phase where the learned model is used to derive a policy. In the case of standard MDPs, the learning problem can be solved using either value iteration or policy iteration. However, in the case of zero-sum Markov games, there is no efficient policy iteration algorithm; e.g., it has been shown in Hansen et al. (2013) that one has to solve Omega(1/(1-alpha)) MDPs, where alpha is the discount factor, to implement the only known convergent version of policy iteration. Another algorithm for Markov zero-sum games, called naive policy iteration, is easy to implement but is only provably convergent under very restrictive assumptions. Prior attempts to fix naive policy iteration algorithm have several limitations. Here, we show that a simple variant of naive policy iteration for games converges, and 
    
[^134]: 核密度贝叶斯逆强化学习

    Kernel Density Bayesian Inverse Reinforcement Learning. (arXiv:2303.06827v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.06827](http://arxiv.org/abs/2303.06827)

    KD-BIRL是一种核密度贝叶斯逆强化学习方法，通过直接逼近似然函数来学习代理的奖励函数，克服了学习点估计的缺点，并适用于复杂和无限环境。

    

    逆强化学习（IRL）是一种通过观察代理行为来推断其奖励函数的强大框架，但学习奖励函数的点估计可能会误导，因为可能有多个函数能够很好地描述代理的行为。贝叶斯逆强化学习采用贝叶斯方法模拟候选奖励函数的分布，克服了学习点估计的缺点。然而，一些贝叶斯逆强化学习算法使用Q值函数代替似然函数。由此得到的后验计算量大，理论保证少，并且Q值函数通常对似然函数的逼近效果较差。我们引入了核密度贝叶斯逆强化学习（KD-BIRL），该方法使用条件核密度估计直接逼近似然函数，提供了一个高效的框架，在经过改进的奖励函数参数化下，适用于具有复杂和无限的环境。

    Inverse reinforcement learning~(IRL) is a powerful framework to infer an agent's reward function by observing its behavior, but IRL algorithms that learn point estimates of the reward function can be misleading because there may be several functions that describe an agent's behavior equally well. A Bayesian approach to IRL models a distribution over candidate reward functions, alleviating the shortcomings of learning a point estimate. However, several Bayesian IRL algorithms use a $Q$-value function in place of the likelihood function. The resulting posterior is computationally intensive to calculate, has few theoretical guarantees, and the $Q$-value function is often a poor approximation for the likelihood. We introduce kernel density Bayesian IRL (KD-BIRL), which uses conditional kernel density estimation to directly approximate the likelihood, providing an efficient framework that, with a modified reward function parameterization, is applicable to environments with complex and infin
    
[^135]: ChatGPT能评估人类个性吗？一个通用评估框架。

    Can ChatGPT Assess Human Personalities? A General Evaluation Framework. (arXiv:2303.01248v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.01248](http://arxiv.org/abs/2303.01248)

    本文提出了一个通用的评估框架，用于通过LLMs基于MBTI测试评估人类个性。该框架通过设计无偏倚的提示、灵活查询和正确性评估的方式，使LLMs能够灵活评估不同群体的个性特点。

    

    大型语言模型（LLMs）尤其是ChatGPT在各个领域都取得了令人印象深刻的成果，但它们潜在的人类化心理特征尚未得到深入探索。现有的研究主要集中在研究LLMs的虚拟个性，而很少探索通过LLMs分析人类个性的可能性。本文提出了一个通用的评估框架，用于基于迈尔斯·布里格斯人格类型指标（MBTI）测试评估LLMs的人类个性。具体而言，我们首先通过随机排列MBTI问题中的选项来设计无偏倚的提示，采用平均测试结果来鼓励更客观的答案生成。然后，我们建议替换问题陈述中的主语，实现对LLMs上不同主体的灵活查询和评估。最后，我们以正确性评估的方式重新构建问题指令，以便促使LLMs生成更清晰的回应。该提出的框架使LLMs能够灵活评估不同群体的个性特点。

    Large Language Models (LLMs) especially ChatGPT have produced impressive results in various areas, but their potential human-like psychology is still largely unexplored. Existing works study the virtual personalities of LLMs but rarely explore the possibility of analyzing human personalities via LLMs. This paper presents a generic evaluation framework for LLMs to assess human personalities based on Myers Briggs Type Indicator (MBTI) tests. Specifically, we first devise unbiased prompts by randomly permuting options in MBTI questions and adopt the average testing result to encourage more impartial answer generation. Then, we propose to replace the subject in question statements to enable flexible queries and assessments on different subjects from LLMs. Finally, we re-formulate the question instructions in a manner of correctness evaluation to facilitate LLMs to generate clearer responses. The proposed framework enables LLMs to flexibly assess personalities of different groups of people.
    
[^136]: Orca: 一种用于中文对话机器阅读理解的少样本测试基准

    Orca: A Few-shot Benchmark for Chinese Conversational Machine Reading Comprehension. (arXiv:2302.13619v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.13619](http://arxiv.org/abs/2302.13619)

    Orca是中文对话机器阅读理解的第一个基准，提供了零样本/少样本设置来评估模型对多样领域的泛化能力，并通过提供与回答相关的段落来更合理地评估模型的理解能力。

    

    对话机器阅读理解（CMRC）任务旨在回答对话中的问题，由于其广泛应用，近年来已成为热门研究课题。然而，现有的CMRC基准在每个对话中分配一个静态段落，与真实场景不一致。因此，很难合理评估模型对真实场景的理解能力。为此，我们提出了第一个中文CMRC基准Orca，并进一步提供了零样本/少样本设置，以评估模型对多样领域的泛化能力。我们收集了831个热门话题驱动的对话，共计4,742轮。每个对话的每个轮次都会分配一个与回答有关的段落，旨在更合理地评估模型的理解能力。对话的主题来自社交媒体平台，涵盖33个领域，力争与真实场景保持一致。重要的是，Orca中的答案都是经过良好注释的自然回答。

    The conversational machine reading comprehension (CMRC) task aims to answer questions in conversations, which has been a hot research topic in recent years because of its wide applications. However, existing CMRC benchmarks in which each conversation is assigned a static passage are inconsistent with real scenarios. Thus, model's comprehension ability towards real scenarios are hard to evaluate reasonably. To this end, we propose the first Chinese CMRC benchmark Orca and further provide zero-shot/few-shot settings to evaluate model's generalization ability towards diverse domains. We collect 831 hot-topic driven conversations with 4,742 turns in total. Each turn of a conversation is assigned with a response-related passage, aiming to evaluate model's comprehension ability more reasonably. The topics of conversations are collected from social media platform and cover 33 domains, trying to be consistent with real scenarios. Importantly, answers in Orca are all well-annotated natural resp
    
[^137]: 基于模块化的方法用于跟踪动态社交网络中的社区

    Modularity-based approach for tracking communities in dynamic social networks. (arXiv:2302.12759v2 [cs.SI] UPDATED)

    [http://arxiv.org/abs/2302.12759](http://arxiv.org/abs/2302.12759)

    本文引入了一个基于模块化的框架，用于跟踪动态社交网络中的社区，通过识别每个社区的一系列重要事件，无需预定义阈值，从而实现更准确、更鲁棒的跟踪。

    

    社区检测是解析在线社交网络复杂动态的关键任务。这些网络的出现极大地增加了用户之间交互的数量和速度，为研究人员提供了探索和分析社交群体的基本结构的前所未有的机会。尽管对于实际社交网络中用户组的演变越来越感兴趣，但目前的社区检测工作主要集中在静态网络内的社区。在本文中，我们引入了一种在动态网络中跟踪社区随时间变化的新框架，为每个社区识别了一系列重要事件。我们的框架采用了基于模块化的策略，不需要预定义的阈值，从而更准确、更鲁棒地跟踪动态社区。通过在嵌入事件的合成网络上进行大量实验证实了我们框架的有效性。

    Community detection is a crucial task to unravel the intricate dynamics of online social networks. The emergence of these networks has dramatically increased the volume and speed of interactions among users, presenting researchers with unprecedented opportunities to explore and analyze the underlying structure of social communities. Despite a growing interest in tracking the evolution of groups of users in real-world social networks, the predominant focus of community detection efforts has been on communities within static networks. In this paper, we introduce a novel framework for tracking communities over time in a dynamic network, where a series of significant events is identified for each community. Our framework adopts a modularity-based strategy and does not require a predefined threshold, leading to a more accurate and robust tracking of dynamic communities. We validated the efficacy of our framework through extensive experiments on synthetic networks featuring embedded events. 
    
[^138]: 知识是微调语言模型中权重空间的一个区域

    Knowledge is a Region in Weight Space for Fine-tuned Language Models. (arXiv:2302.04863v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.04863](http://arxiv.org/abs/2302.04863)

    研究探讨了不同模型在权重空间中的位置与性能的关联，发现微调语言模型在权重空间中有明确定义的区域，且这些区域中的模型表现出高性能。此外，通过绕过这些区域，可以得到性能相当甚至更好的新模型。

    

    神经网络研究一直专注于理解单个模型在单个数据集上的训练结果。然而，对于不同模型之间的关系，特别是那些在不同数据集上进行训练或测试的模型之间的关系，我们了解甚少。我们通过研究不同模型的权重空间和潜在的损失地形之间的相互关系来解决这个问题。具体而言，我们证明了为高性能而进行微调优化的模型存在于权重空间中定义明确的区域中，反之亦然——任何在这些区域中的模型都表现出高性能。值得注意的是，我们展示了在相同数据集上进行微调的语言模型在权重空间中形成一个紧密的聚类，而在相同基础任务下从不同数据集进行微调的模型则形成一个较松散的聚类。此外，绕过模型之间的区域会生成性能相当甚至更好的新模型，甚至在进行微调的情况下也是如此。

    Research on neural networks has focused on understanding a single model trained on a single dataset. However, relatively little is known about the relationships between different models, particularly those trained or tested on different datasets. We address this by studying how the weight space and the underlying loss landscape of different models are interconnected.  Specifically, we demonstrate that finetuned models that were optimized for high performance, reside in well-defined regions in weight space, and vice versa -- that any model that resides anywhere in those regions also exhibits high performance. Notably, we show that language models that have been finetuned on the same dataset form a tight cluster in the weight space, while models finetuned on different datasets from the same underlying task form a looser cluster. Moreover, traversing around the region between the models leads to new models that perform comparably or even better than models obtained via finetuning, even on
    
[^139]: 基于操作剖面对剩余寿命预测的领域自适应方法

    Domain Adaptation via Alignment of Operation Profile for Remaining Useful Lifetime Prediction. (arXiv:2302.01704v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2302.01704](http://arxiv.org/abs/2302.01704)

    该论文提出了两种基于对不同操作剖面的不同阶段进行考虑的对抗性领域自适应框架的剩余寿命预测的方法。

    

    有效的预测和健康管理依赖于剩余寿命准确的预测。数据驱动的剩余寿命预测技术严重依赖于可用的失效时间轨迹的代表性。因此，当应用于与训练数据中的不同操作条件相比较的车队中的新单元的数据时，这些方法可能表现不佳。这也被称为领域漂移。领域自适应方法旨在通过提取领域不变特征来解决领域漂移问题。然而，领域自适应方法没有区分不同的操作阶段，如稳态或瞬态。这可能导致由于不同操作阶段的欠表示或过表示而导致的不对齐。本文基于对不同操作剖面的不同阶段进行考虑的对抗性领域自适应框架，提出了两种新型的剩余寿命预测的领域自适应方法。

    Effective Prognostics and Health Management (PHM) relies on accurate prediction of the Remaining Useful Life (RUL). Data-driven RUL prediction techniques rely heavily on the representativeness of the available time-to-failure trajectories. Therefore, these methods may not perform well when applied to data from new units of a fleet that follow different operating conditions than those they were trained on. This is also known as domain shifts. Domain adaptation (DA) methods aim to address the domain shift problem by extracting domain invariant features. However, DA methods do not distinguish between the different phases of operation, such as steady states or transient phases. This can result in misalignment due to under- or over-representation of different operation phases. This paper proposes two novel DA approaches for RUL prediction based on an adversarial domain adaptation framework that considers the different phases of the operation profiles separately. The proposed methodologies a
    
[^140]: 通过目标感知表示学习和自适应视野预测的开放世界多任务控制

    Open-World Multi-Task Control Through Goal-Aware Representation Learning and Adaptive Horizon Prediction. (arXiv:2301.10034v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2301.10034](http://arxiv.org/abs/2301.10034)

    该论文提出了一种解决多任务控制中面临的开放世界挑战的新方法，即通过Goal-Sensitive Backbone鼓励出现与目标相关的视觉状态表示，并通过自适应视野预测模块来减轻非静态动态引起的学习不确定性。

    

    本文研究在Minecraft中学习目标条件下控制策略的问题，提出Goal-Sensitive Backbone（GSB）使政策鼓励出现与目标相关的视觉状态表示，并通过自适应视野预测模块减轻因非静态动态引起的学习不确定性。实验结果表明，我们的方法在20个Minecraft任务中表现显著优于迄今为止最好的基线，其中许多任务的表现是基线的两倍。

    We study the problem of learning goal-conditioned policies in Minecraft, a popular, widely accessible yet challenging open-ended environment for developing human-level multi-task agents. We first identify two main challenges of learning such policies: 1) the indistinguishability of tasks from the state distribution, due to the vast scene diversity, and 2) the non-stationary nature of environment dynamics caused by partial observability. To tackle the first challenge, we propose Goal-Sensitive Backbone (GSB) for the policy to encourage the emergence of goal-relevant visual state representations. To tackle the second challenge, the policy is further fueled by an adaptive horizon prediction module that helps alleviate the learning uncertainty brought by the non-stationary dynamics. Experiments on 20 Minecraft tasks show that our method significantly outperforms the best baseline so far; in many of them, we double the performance. Our ablation and exploratory studies then explain how our a
    
[^141]: 编程课程中提供反馈的智能导师

    Smart tutor to provide feedback in programming courses. (arXiv:2301.09918v2 [cs.CY] UPDATED)

    [http://arxiv.org/abs/2301.09918](http://arxiv.org/abs/2301.09918)

    这项研究通过开发一种基于AI的智能导师，用于回答学生的编程问题，并提供准确和有帮助的答案。

    

    人工智能（AI）随着时间推移越来越受欢迎，可以完成过去难以完成的任务。AI在许多领域中使用，但在教育环境之外并不常见。教育环境中使用AI来自定义内容或为学生提供个性化反馈。然而，在编程教学中使用AI仍然需要探索，因为在这个领域中，我们通常只能找到评估工具来评分学生的作业，而找不到很多工具来帮助学生在创建程序的过程中提供反馈。在这项工作中，我们提出了一种基于AI的智能导师，用于回答学生的编程问题。这个工具在URJC的大学生中进行了整个课程的测试。尽管这个工具仍处于初步阶段，但它对学生的问题提供了准确和有帮助的回答。

    Artificial Intelligence (AI) is becoming more and more popular as time passes, allowing to perform tasks that were difficult to do in the past. From predictions to customization, AI is being used in many areas, not being educational environments outside this situation. AI is being used in educational settings to customize contents or to provide personalized feedback to the students, among others. In this scenario, AI in programming teaching is something that still has to be explored, since in this area we usually find assessment tools that allow grading the students work, but we can not find many tools aimed towards providing feedback to the students in the process of creating their program. In this work we present an AI based intelligent tutor that answers students programming questions. The tool has been tested by university students at the URJC along a whole course. Even if the tool is still in its preliminary phase, it helped the students with their questions, providing accurate an
    
[^142]: 从引导式游戏学习中提升对抗性模仿学习中的探索能力

    Learning from Guided Play: Improving Exploration for Adversarial Imitation Learning with Simple Auxiliary Tasks. (arXiv:2301.00051v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.00051](http://arxiv.org/abs/2301.00051)

    本研究提出了从引导式游戏学习（LfGP）的框架，通过引入多个辅助任务和主任务的专家演示，提升对抗性模仿学习（AIL）中的探索能力，并解决了传统AIL在学习操作任务时可能陷入次优解的问题。

    

    对抗性模仿学习（AIL）已成为减少监督模仿学习的分布偏移的流行替代方法。然而，在在线强化学习阶段，AIL需要有效的探索。在这项工作中，我们展示了标准的、天真的探索方法，如果使用AIL学习的策略与专家分布足够匹配但没有完全学会所需的任务，可能会表现为一个次优的局部最大值。这对于操作任务来说可能尤为灾难，因为专家和非专家的状态-动作对之间的差别通常是微妙的。我们提出了从引导游戏中学习（LfGP）的框架，其中我们利用了多个探索性辅助任务的专家演示，除了一个主任务。这些辅助任务的添加强制代理人探索标准AIL可能学会忽视的状态和动作。此外，这种特定的公式允许辅助任务的可重复使用性

    Adversarial imitation learning (AIL) has become a popular alternative to supervised imitation learning that reduces the distribution shift suffered by the latter. However, AIL requires effective exploration during an online reinforcement learning phase. In this work, we show that the standard, naive approach to exploration can manifest as a suboptimal local maximum if a policy learned with AIL sufficiently matches the expert distribution without fully learning the desired task. This can be particularly catastrophic for manipulation tasks, where the difference between an expert and a non-expert state-action pair is often subtle. We present Learning from Guided Play (LfGP), a framework in which we leverage expert demonstrations of multiple exploratory, auxiliary tasks in addition to a main task. The addition of these auxiliary tasks forces the agent to explore states and actions that standard AIL may learn to ignore. Additionally, this particular formulation allows for the reusability of
    
[^143]: 通过深度感知实现手持灵巧操作

    Visual Dexterity: In-hand Dexterous Manipulation from Depth. (arXiv:2211.11744v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2211.11744](http://arxiv.org/abs/2211.11744)

    通过使用深度相机的读数，我们提出了一种通用物体重新定向控制器，可以实时、动态地重新定向复杂和新颖的物体形状，中位数重新定向时间接近于七秒。该控制器经过强化学习在仿真环境中训练，并在实际世界中对未用于训练的新物体形状进行了评估。

    

    手持物体的重新定向对于执行许多灵巧操作任务非常必要，例如在当前机器人无法触及的结构不太完善的环境中使用工具。之前的研究建立了重新定向系统，假设以下情况之一或多种情况同时存在：仅重新定向具有简单形状的特定物体、重新定向范围有限、慢速或准静态操作、仅模拟结果、需要专用且昂贵的传感器套件以及其他不适用于实际部署的限制。我们提出了一种不做这些假设的通用物体重新定向控制器。它使用来自单个普通深度摄像机的读数，以实时方式通过任意旋转动态重新定向复杂且新颖的物体形状，中位数重新定向时间接近于七秒。该控制器经过强化学习在仿真环境中进行训练，并在未用于训练的新物体形状上在实际世界中进行评估，包括 ...

    In-hand object reorientation is necessary for performing many dexterous manipulation tasks, such as tool use in less structured environments that remain beyond the reach of current robots. Prior works built reorientation systems assuming one or many of the following: reorienting only specific objects with simple shapes, limited range of reorientation, slow or quasistatic manipulation, simulation-only results, the need for specialized and costly sensor suites, and other constraints which make the system infeasible for real-world deployment. We present a general object reorientation controller that does not make these assumptions. It uses readings from a single commodity depth camera to dynamically reorient complex and new object shapes by any rotation in real-time, with the median reorientation time being close to seven seconds. The controller is trained using reinforcement learning in simulation and evaluated in the real world on new object shapes not used for training, including the m
    
[^144]: ViNL：通过视觉导航和足球术行走避免障碍物

    ViNL: Visual Navigation and Locomotion Over Obstacles. (arXiv:2210.14791v3 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2210.14791](http://arxiv.org/abs/2210.14791)

    ViNL是通过视觉导航和足球术在未知室内环境中实现机器人导航和足球术运动的方法。它包括无模型的视觉导航策略和视觉运动策略，通过端到端训练实现，并能够避免踩到小障碍物。ViNL能够实现高效且稳定的导航和足球术运动，无需环境先验知识。

    

    我们提出了一种名为ViNL（Visual Navigation and Locomotion）的方法，它使四足机器人能够在路径上跨过小障碍物（例如鞋子、玩具、电缆），类似于人和宠物在行走时抬起脚步超过物体。ViNL包括：（1）一个视觉导航策略，输出线性和角速度命令，指导机器人在陌生的室内环境中达到目标坐标；（2）一个视觉运动策略，通过控制机器人的关节，避免踩到障碍物，并按照提供的速度命令移动。这两个策略都是完全“无模型”的，即通过端到端训练的传感器到行动神经网络进行训练。这两者在两个完全不同的模拟器中独立训练，然后通过将导航器的速度命令输入到定位器中协同部署，完全“零训练”。虽然之前的研究已经开发出了用于视觉导航的学习方法，但通常需要模型先验和/或人工特征工程。ViNL与这些方法不同，能够在没有环境先验知识的情况下，在未知的室内环境中实现高效且稳定的导航和足球术运动。

    We present Visual Navigation and Locomotion over obstacles (ViNL), which enables a quadrupedal robot to navigate unseen apartments while stepping over small obstacles that lie in its path (e.g., shoes, toys, cables), similar to how humans and pets lift their feet over objects as they walk. ViNL consists of: (1) a visual navigation policy that outputs linear and angular velocity commands that guides the robot to a goal coordinate in unfamiliar indoor environments; and (2) a visual locomotion policy that controls the robot's joints to avoid stepping on obstacles while following provided velocity commands. Both the policies are entirely "model-free", i.e. sensors-to-actions neural networks trained end-to-end. The two are trained independently in two entirely different simulators and then seamlessly co-deployed by feeding the velocity commands from the navigator to the locomotor, entirely "zero-shot" (without any co-training). While prior works have developed learning methods for visual na
    
[^145]: 图像和视频的全景分割的通用框架

    A Generalist Framework for Panoptic Segmentation of Images and Videos. (arXiv:2210.06366v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2210.06366](http://arxiv.org/abs/2210.06366)

    这个论文提出了一个通用框架，用于图像和视频的全景分割。他们将全景分割问题定义为离散数据生成问题，并提出了一个简单的扩散模型来建模全景掩码。他们的方法能够在流式设置中建模视频，并自动学习跟踪对象实例，并在实验中展现出与最先进的专家方法竞争的能力。

    

    全景分割为图像的每个像素分配语义和实例ID标签。由于实例ID的排列也是有效的解决方案，该任务需要学习高维度的一对多映射。因此，最先进的方法使用定制的架构和任务特定的损失函数。我们将全景分割问题定义为离散数据生成问题，不依赖任务的归纳偏差。我们提出了一个扩散模型来建模全景掩码，具有简单的架构和通用的损失函数。通过将过去的预测作为条件信号添加，我们的方法能够在流式设置中建模视频，并自动学习跟踪对象实例。通过大量实验证明，我们的简单方法在类似的设置下能够与最先进的专家方法竞争。

    Panoptic segmentation assigns semantic and instance ID labels to every pixel of an image. As permutations of instance IDs are also valid solutions, the task requires learning of high-dimensional one-to-many mapping. As a result, state-of-the-art approaches use customized architectures and task-specific loss functions. We formulate panoptic segmentation as a discrete data generation problem, without relying on inductive bias of the task. A diffusion model is proposed to model panoptic masks, with a simple architecture and generic loss function. By simply adding past predictions as a conditioning signal, our method is capable of modeling video (in a streaming setting) and thereby learns to track object instances automatically. With extensive experiments, we demonstrate that our simple approach can perform competitively to state-of-the-art specialist methods in similar settings.
    
[^146]: 通过检索软提示增强指令跟随模型的零样本表现效率

    Efficiently Enhancing Zero-Shot Performance of Instruction Following Model via Retrieval of Soft Prompt. (arXiv:2210.03029v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.03029](http://arxiv.org/abs/2210.03029)

    通过检索软提示有效辅助硬提示，在增加少量参数的情况下提高了指令跟随模型在零样本任务上的表现效率。

    

    提升指令跟随模型的零样本表现效率需要大量计算，要么通过扩展训练数据集的总数，要么增加模型的大小。在这项工作中，我们通过提示微调获取软提示，探索了如何通过检索软提示有效辅助硬提示来进行零样本任务泛化。具体而言，我们通过提示微调为每个提示训练软提示嵌入，存储与提示嵌入映射的训练实例样本，并在推理过程中检索最接近查询实例的训练实例对应的提示嵌入。虽然只增加了0.007%的额外参数，检索软提示提高了T0在未见任务上的性能，在11个数据集中有10个表现优于T0，并且将T0在BIG-bench基准测试中的平均准确率提高了2.39个百分点。此外，我们还报告了一个有意思的发现，即检索在相似答案选择格式上训练的源嵌入比提示嵌入更重要。

    Enhancing the zero-shot performance of instruction-following models requires heavy computation, either by scaling the total number of training datasets or the model size. In this work, we explore how retrieval of soft prompts obtained through prompt tuning can efficiently assist hard prompts in zero-shot task generalization. Specifically, we train soft prompt embeddings for each prompt through prompt tuning, store the samples of the training instances mapped with the prompt embeddings, and retrieve the corresponding prompt embedding of the training instance closest to the query instance during inference. While only adding 0.007% additional parameters, retrieval of soft prompt enhances the performance of T0 on unseen tasks by outperforming it on 10 out of 11 datasets as well as improving the mean accuracy of T0 on BIG-bench benchmark by 2.39% points. Also, we report an interesting finding that retrieving source embeddings trained on similar answer choice formats is more important than t
    
[^147]: 基准测试学习鲁棒导航智能体的增强方法：2021年iGibson挑战赛的获胜参赛作品

    Benchmarking Augmentation Methods for Learning Robust Navigation Agents: the Winning Entry of the 2021 iGibson Challenge. (arXiv:2109.10493v3 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2109.10493](http://arxiv.org/abs/2109.10493)

    本研究基于2021年iGibson挑战赛的获胜参赛作品，旨在评估不同的增强技术对智能体在动态环境中的性能改进效果。研究表明，在训练过程中添加动态障碍物可以显著提高测试时的泛化能力，并且与图像增强技术相结合可以进一步提高成功率。此外，该方法对模拟器之间的迁移也更加鲁棒。

    

    近年来，深度强化学习和可扩展的逼真仿真技术的进步已经使得在各种视觉任务中，包括导航方面的具体AI愈发成熟。然而，尽管在教导体验化智能体在静态环境中导航方面取得了令人印象深刻的进展，但在包含移动行人或可移动障碍物的更动态的环境中的进展较少。该研究旨在评估不同增强技术对在这些具有挑战性环境中提高智能体性能的效果。我们发现，在训练过程中向场景中添加多个动态障碍物可显著提高智能体在测试时的泛化能力，成功率远高于基准智能体。我们还发现，可以将该方法与图像增强技术相结合，进一步提高成功率。此外，我们还展示了该方法在从一种模拟器转移到另一种模拟器时比图像增强方法更具鲁棒性。最后，我们证明了这种方法可以有效地提高智能体在复杂环境中的导航能力。

    Recent advances in deep reinforcement learning and scalable photorealistic simulation have led to increasingly mature embodied AI for various visual tasks, including navigation. However, while impressive progress has been made for teaching embodied agents to navigate static environments, much less progress has been made on more dynamic environments that may include moving pedestrians or movable obstacles. In this study, we aim to benchmark different augmentation techniques for improving the agent's performance in these challenging environments. We show that adding several dynamic obstacles into the scene during training confers significant improvements in test-time generalization, achieving much higher success rates than baseline agents. We find that this approach can also be combined with image augmentation methods to achieve even higher success rates. Additionally, we show that this approach is also more robust to sim-to-sim transfer than image augmentation methods. Finally, we demon
    
[^148]: 以完成时间为权重的成功度量：一种针对行动导航的动态感知评估标准

    Success Weighted by Completion Time: A Dynamics-Aware Evaluation Criteria for Embodied Navigation. (arXiv:2103.08022v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2103.08022](http://arxiv.org/abs/2103.08022)

    我们提出了一种以完成时间为权重的成功度量（SCT），用于评估移动机器人导航性能，并设计了针对单轮小车动态模型的算法RRT*-Unicycle。该指标可以准确衡量代理模拟最快导航行为的程度。

    

    我们提出了以完成时间为权重的成功度量（SCT），这是一种评估移动机器人导航性能的新指标。许多与导航相关的研究使用以路径长度为权重的成功度量（SPL）作为评估代理到达目标位置路径的主要方法，但是SPL在评估具有复杂动态特性的代理时存在局限性。相比之下，SCT明确考虑了代理的动态模型，并旨在准确捕捉代理模拟其动态所允许的最快导航行为的程度。虽然一些行动导航作品使用点转动力学模型，但我们专注于使用单轮小车动态模型来设计我们的代理，这更好地展示了流行的移动机器人平台（例如LoCoBot，TurtleBot，Fetch等）的动态模型。我们还提出了一种针对单轮小车动力学的RRT*-Unicycle算法，该算法估计从起始位姿到目标位置的最快无碰撞路径和完成时间。

    We present Success weighted by Completion Time (SCT), a new metric for evaluating navigation performance for mobile robots. Several related works on navigation have used Success weighted by Path Length (SPL) as the primary method of evaluating the path an agent makes to a goal location, but SPL is limited in its ability to properly evaluate agents with complex dynamics. In contrast, SCT explicitly takes the agent's dynamics model into consideration, and aims to accurately capture how well the agent has approximated the fastest navigation behavior afforded by its dynamics. While several embodied navigation works use point-turn dynamics, we focus on unicycle-cart dynamics for our agent, which better exemplifies the dynamics model of popular mobile robotics platforms (e.g., LoCoBot, TurtleBot, Fetch, etc.). We also present RRT*-Unicycle, an algorithm for unicycle dynamics that estimates the fastest collision-free path and completion time from a starting pose to a goal location in an envir
    
[^149]: 创新风格化：通过逐步可用随机化词典进行时间轴生成

    Stylized innovation: generating timelines by interrogating incrementally available randomised dictionaries. (arXiv:1806.07722v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/1806.07722](http://arxiv.org/abs/1806.07722)

    该论文通过设计和生成合成创新网络词典，研究了新符号发现在增加词汇的过程中的表现，并探讨了创新过程的整体统计和行为。

    

    理解创新的一个关键挑战是它是一个动态、持续的过程，可能高度依赖于文化、经济或运气等瞬息万变的因素。这意味着对真实世界过程的任何分析必然是历史性的，因此可能为时已晚，但也无法确定创新之间的连接结构或属性是什么。在这里，我尝试通过设计和生成一组合成创新网络“词典”，用于承载样本创新时间轴，探测这些过程的整体统计和行为，并确定它们对结构或生成算法的依赖程度。因此，受到Fink、Reeves、Palma和Farr（2017）关于语言、美食和技术创新的工作的启发，我研究了新符号发现如何以额外的“词汇”词典中的单词增加的方式呈现。

    A key challenge when trying to understand innovation is that it is a dynamic, ongoing process, which can be highly contingent on ephemeral factors such as culture, economics, or luck. This means that any analysis of the real-world process must necessarily be historical - and thus probably too late to be most useful - but also cannot be sure what the properties of the web of connections between innovations is or was. Here I try to address this by designing and generating a set of synthetic innovation web "dictionaries" that can be used to host sampled innovation timelines, probe the overall statistics and behaviours of these processes, and determine the degree of their reliance on the structure or generating algorithm. Thus, inspired by the work of Fink, Reeves, Palma and Farr (2017) on innovation in language, gastronomy, and technology, I study how new symbol discovery manifests itself in terms of additional "word" vocabulary being available from dictionaries generated from a finite nu
    

