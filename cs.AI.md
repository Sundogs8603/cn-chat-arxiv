# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Sight Beyond Text: Multi-Modal Training Enhances LLMs in Truthfulness and Ethics.](http://arxiv.org/abs/2309.07120) | 多模态训练的MLLM在纯NLP任务中表现出卓越的真实性和伦理对齐能力，这得益于视觉指导调优和优秀的指导质量。 |
| [^2] | [Characterizing Speed Performance of Multi-Agent Reinforcement Learning.](http://arxiv.org/abs/2309.07108) | 本文对多智能体强化学习（MARL）的速度性能进行了特征化研究。作者通过引入分类法，提出了三种最先进的MARL算法作为目标基准，以解决目前优化奖励的算法在训练时间速度性能方面的不足。 |
| [^3] | [Comparing Llama-2 and GPT-3 LLMs for HPC kernels generation.](http://arxiv.org/abs/2309.07103) | 本研究评估了Llama-2和GPT-3在生成HPC核心方面的性能，并发现Llama-2在准确性方面具有竞争力。同时，通过使用GitHub Copilot生成的代码更可靠，而Llama-2生成的代码更可靠。 |
| [^4] | [Mitigating Group Bias in Federated Learning for Heterogeneous Devices.](http://arxiv.org/abs/2309.07085) | 本文提出了一种在分布式边缘应用中减轻联邦学习中群体偏见的方法，该方法可以通过计算跨域群体重要性来减轻全局模型的偏见，并保持隐私和资源利用效率。 |
| [^5] | [A Comprehensive Analysis of the Role of Artificial Intelligence and Machine Learning in Modern Digital Forensics and Incident Response.](http://arxiv.org/abs/2309.07064) | 本研究全面分析了人工智能和机器学习在现代数字取证和事故响应中的作用，探讨了相关技术的应用及其对取证调查的影响。 |
| [^6] | [Large Language Models for Compiler Optimization.](http://arxiv.org/abs/2309.07062) | 本论文研究了将大型语言模型应用于代码优化的新颖方法，以7B参数的transformer模型为例，通过预测指令计数和生成优化代码等辅助学习任务，显著提高了模型的优化性能。在大量测试程序上的评估中，该方法相对编译器的优化效果提高了3.0%，并展现出令人惊喜的强大代码推理能力。 |
| [^7] | [Deep Quantum Graph Dreaming: Deciphering Neural Network Insights into Quantum Experiments.](http://arxiv.org/abs/2309.07056) | 本文使用了一种名为“梦境”的可解释人工智能技术，探索神经网络对量子光学实验的学习，发现网络可以改变量子系统的属性分布，并揭示了神经网络的学习策略。 |
| [^8] | [Pearl's and Jeffrey's Update as Modes of Learning in Probabilistic Programming.](http://arxiv.org/abs/2309.07053) | 本文澄清了在随机编程中使用的学习模式Pearl和Jeffrey的更新机制之间的关系，并指出Jeffrey的更新规则是通过变分推理得到的。 |
| [^9] | [UnifiedGesture: A Unified Gesture Synthesis Model for Multiple Skeletons.](http://arxiv.org/abs/2309.07051) | UnifiedGesture 是一种训练在多个具有不同骨架的手势数据集上的基于扩散模型的语音驱动手势合成方法，通过重新定位网络和扩散模型架构来统一手势表示并捕捉语音和手势之间的相关性。 |
| [^10] | [Efficient Reinforcement Learning for Jumping Monopods.](http://arxiv.org/abs/2309.07038) | 本论文研究了如何通过在强化学习框架中注入物理知识来解决跳跃式单脚机器人的控制问题，这样可以大幅减少学习时间并且能够学习和修正可能出现的错误。 |
| [^11] | [How (Not) to Use Sociodemographic Information for Subjective NLP Tasks.](http://arxiv.org/abs/2309.07034) | 该论文研究了如何使用社会人口统计信息在主观NLP任务中，发现社会人口提示技术在某些任务上有效，但也存在一些限制和挑战。 |
| [^12] | [R\'esum\'e Parsing as Hierarchical Sequence Labeling: An Empirical Study.](http://arxiv.org/abs/2309.07015) | 本研究将简历解析问题作为分层序列标注任务，提出了同时解决行和标记两个任务的模型架构，并构建了多语言的高质量简历解析语料库。实验结果表明，所提出模型在信息提取任务中优于先前工作中的方法。进一步分析了模型性能和资源效率，并描述了模型在生产环境中的权衡。 |
| [^13] | [Dynamic Analysis of Corporate ESG Reports: A Model of Evolutionary Trends.](http://arxiv.org/abs/2309.07001) | 本研究通过开发一个动态框架，利用来自技术公司的21世纪ESG报告的丰富数据，揭示了ESG观点的演化趋势。 |
| [^14] | [MASTERKEY: Practical Backdoor Attack Against Speaker Verification Systems.](http://arxiv.org/abs/2309.06981) | 这项工作提出了一种名为MASTERKEY的后门攻击，针对说话人验证系统。与以往攻击不同，在实际环境下攻击者对目标用户没有任何了解。通过嵌入说话人特征和语义信息，以及集成信道失真，我们的攻击可以成功破坏多个流行的SV模型，达到100％的攻击成功率。 |
| [^15] | [DNNShifter: An Efficient DNN Pruning System for Edge Computing.](http://arxiv.org/abs/2309.06973) | DNNShifter是一种高效的边缘计算DNN剪枝系统，通过快速推导出合适的模型变体来提供高推理准确性，适应系统和网络条件变化的工作负载需求。 |
| [^16] | [Setting the Right Expectations: Algorithmic Recourse Over Time.](http://arxiv.org/abs/2309.06969) | 这项研究关注算法补救措施中忽视的关键要素 - 不断变化的环境对补救效果的影响。研究发现，在时间推移和个体间竞争的情况下，初始的补救建议可能变得不可靠，因此需要考虑时间变化来确保补救的有效性。 |
| [^17] | [Towards Reliable Dermatology Evaluation Benchmarks.](http://arxiv.org/abs/2309.06961) | 本论文提出了一种资源高效的数据清理协议，以提高数字皮肤科模型性能评估的可信度。协议结合现有算法，并在多个皮肤科医生的确认下，删除了无关样本和近似重复样本，估计了标签错误的百分比，并提供了修订后的数据集文件列表。这项工作为数字皮肤科中更可靠的性能评估铺平了道路。 |
| [^18] | [PhantomSound: Black-Box, Query-Efficient Audio Adversarial Attack via Split-Second Phoneme Injection.](http://arxiv.org/abs/2309.06960) | 本文介绍了一种名为PhantomSound的黑盒、查询高效的音频对抗攻击方法，通过分秒级音素注入，能够实时攻击不同语音助手的语音转文字API，并且成功绕过了多种活体检测机制。 |
| [^19] | [Implicit Neural Multiple Description for DNA-based data storage.](http://arxiv.org/abs/2309.06956) | 本论文提出了一种基于DNA的数据存储方法，采用隐式神经多描述技术编码数据。通过创新的压缩方案和神经网络，有效地解决了DNA存储中的错误问题，并在性能上超过了传统的MDC方法。 |
| [^20] | [DEFormer: DCT-driven Enhancement Transformer for Low-light Image and Dark Vision.](http://arxiv.org/abs/2309.06941) | 该论文提出了一种新的DCT驱动增强Transformer（DEFormer），可以在低光图像中恢复丢失的细节，通过引入频率作为新的线索，通过可学习的频率分支（LFB）和基于曲率的频率增强（CFE）来实现。此外，还提出了交叉域融合（CDF）来减少领域之间的差异，DEFormer还可以作为暗部检测的预处理，有效提高了性能。 |
| [^21] | [Collectionless Artificial Intelligence.](http://arxiv.org/abs/2309.06938) | 本文提出了无集合原则的学习协议的思路，其中机器在环境交互背景中掌握认知技能，避免了数据集集中化的风险。 |
| [^22] | [Continual Learning with Dirichlet Generative-based Rehearsal.](http://arxiv.org/abs/2309.06917) | 该论文提出了一种新颖的基于狄利克雷生成的回顾策略，用于解决连续学习中伪样本生成的挑战。 |
| [^23] | [Towards the TopMost: A Topic Modeling System Toolkit.](http://arxiv.org/abs/2309.06908) | 本文提出了一个名为TopMost的主题建模系统工具包，通过涵盖更广泛的主题建模场景和具有高度凝聚力和解耦模块化设计的特点，可以促进主题模型的研究和应用。 |
| [^24] | [OWL Reasoners still useable in 2023.](http://arxiv.org/abs/2309.06888) | 该研究系统综述了100多个OWL推理器/系统，并分析了它们在2023年是否仍可用。研究结果提供了一个包含95个独立OWL推理器和使用OWL推理器的系统的全面列表。 |
| [^25] | [Gpachov at CheckThat! 2023: A Diverse Multi-Approach Ensemble for Subjectivity Detection in News Articles.](http://arxiv.org/abs/2309.06844) | Gpachov团队在CLEF-2023 CheckThat！实验室任务2中构建了一种多样的多方法集成解决方案，通过微调句子嵌入编码模型、样本高效的少样本学习模型和多语言转换器等方法结合得到了0.77的宏F1分数，并在英语子任务中获得第二名。 |
| [^26] | [On the Local Quadratic Stability of T-S Fuzzy Systems in the Vicinity of the Origin.](http://arxiv.org/abs/2309.06841) | 本文介绍了一种新的局部稳定性条件，该条件基于线性矩阵不等式和二次Lyapunov函数，并结合了原点附近的非线性系统的线性结构，相比于现有方法更为准确和有效。同时，本文还提出了局部指数稳定性的必要和充分条件，并讨论了模糊Lyapunov方法的局限性。 |
| [^27] | [SAMUS: Adapting Segment Anything Model for Clinically-Friendly and Generalizable Ultrasound Image Segmentation.](http://arxiv.org/abs/2309.06824) | 本文提出了SAMUS，一个专为超声图像分割量身定制的通用模型，通过引入并行CNN分支和适配器来改善SAM在医学图像分割中的性能和泛化能力。 |
| [^28] | [Comparative Analysis of Contextual Relation Extraction based on Deep Learning Models.](http://arxiv.org/abs/2309.06814) | 本文比较分析了基于深度学习模型的上下文关系提取方法。现有技术无法高效预测由多于两个关系和未指定实体组成的句子中的复杂关系。研究采用深度学习技术从多个句子的语境中识别语义关系。现有机器学习模型在二元关系中表现较好，但随着关系数量的增加，预测准确率降低。 |
| [^29] | [Leveraging SE(3) Equivariance for Learning 3D Geometric Shape Assembly.](http://arxiv.org/abs/2309.06810) | 该论文提出了利用SE(3)等变性来进行3D几何形状组装，并考虑了多部件关联的表示，进一步提升了组装效果。 |
| [^30] | [Bayesian uncertainty-weighted loss for improved generalisability on polyp segmentation task.](http://arxiv.org/abs/2309.06807) | 本研究采用贝叶斯不确定性加权损失来改善多中心息分割任务的泛化能力，避免因外观、仪器级别和采集质量的变异导致的不公平模型，并展示了该方法在挑战性的多中心数据集上具有潜在的改进能力。 |
| [^31] | [FedDIP: Federated Learning with Extreme Dynamic Pruning and Incremental Regularization.](http://arxiv.org/abs/2309.06805) | FedDIP是一个结合了动态模型修剪和增量正则化的联邦学习框架，通过消除冗余信息交换和实现极端稀疏模型来显著提高性能。 |
| [^32] | [Defensive Alliances in Signed Networks.](http://arxiv.org/abs/2309.06801) | 这项研究探讨了在签名网络中的防御联盟问题，提出了一种量化的群体结构，并通过考虑智能体之间的喜好和厌恶关系，在联盟形成中引入了新的因素。 |
| [^33] | [Uncertainty-aware Traffic Prediction under Missing Data.](http://arxiv.org/abs/2309.06800) | 本研究提出了一种考虑不确定性的交通预测方法，可以处理缺失数据和测量不确定性，并适用于风险敏感任务和决策导向问题。 |
| [^34] | [When Geoscience Meets Foundation Models: Towards General Geoscience Artificial Intelligence System.](http://arxiv.org/abs/2309.06799) | 地球科学基础模型通过整合大量跨学科数据来模拟和理解地球系统动态，具有广阔的应用前景和创新潜力，但仍面临验证和核实、规模性、可解释性、知识表示和社会偏差等挑战。 |
| [^35] | [Cognitive Mirage: A Review of Hallucinations in Large Language Models.](http://arxiv.org/abs/2309.06794) | 这篇论文综述了大规模语言模型中幻觉的现象，并提出了幻觉的分类、理论分析、检测方法和改进方法，同时还设想了未来的研究方向。 |
| [^36] | [Fundamental Limits of Deep Learning-Based Binary Classifiers Trained with Hinge Loss.](http://arxiv.org/abs/2309.06774) | 本文揭示了基于Hinge Loss训练的深度学习二分类器的基本测试性能限制。 |
| [^37] | [Enhancing Keyphrase Generation by BART Finetuning with Splitting and Shuffling.](http://arxiv.org/abs/2309.06726) | 本文提出了关注关键短语的BART模型(Keyphrase-Focused BART)，通过拆分和重排的方式来增强关键短语生成的性能。在不出现的关键短语生成任务中，该模型在两个关键短语生成基准数据集上取得了新的最佳得分。 |
| [^38] | [Dynamic Spectrum Mixer for Visual Recognition.](http://arxiv.org/abs/2309.06721) | 动态频谱混合器（DSM）是一种内容自适应且计算效率高的结构，通过离散余弦变换表示令牌之间的交互，能够学习长期的空间依赖性。它还引入了动态频谱权重生成层作为频谱带选择器，以强调信息的重要程度。 |
| [^39] | [TrafficGPT: Viewing, Processing and Interacting with Traffic Foundation Models.](http://arxiv.org/abs/2309.06719) | TrafficGPT是ChatGPT和交通基础模型的融合，通过提供查看、分析和交互能力，增强了语言模型在解决复杂交通问题和提供有见地建议方面的能力。 |
| [^40] | [Tackling the Non-IID Issue in Heterogeneous Federated Learning by Gradient Harmonization.](http://arxiv.org/abs/2309.06692) | 本研究通过梯度协调方法解决了异构联邦学习中的非独立同分布问题，提出了FedGH，通过减轻本地漂移来增强性能。实验证明，在多个基准和非独立同分布场景下，FedGH始终能够显著提升联邦学习的性能。 |
| [^41] | [Self-Refined Large Language Model as Automated Reward Function Designer for Deep Reinforcement Learning in Robotics.](http://arxiv.org/abs/2309.06687) | 提出一种自我改进机制的大型语言模型（LLM）框架用于自动化奖励函数设计，在深度强化学习中展现了潜在的应用价值。 |
| [^42] | [Attention Loss Adjusted Prioritized Experience Replay.](http://arxiv.org/abs/2309.06684) | 本文提出了一种改进的Attention Loss Adjusted Prioritized Experience Replay (ALAP)算法，通过结合改进的自注意力网络和双采样机制，调节重要性采样权重，消除了先进的经验回放算法中的估计误差。在OPENAI gym环境中的测试和对比研究验证了该算法的优势和效率。 |
| [^43] | [A plug-and-play synthetic data deep learning for undersampled magnetic resonance image reconstruction.](http://arxiv.org/abs/2309.06681) | 本文提出了一种基于插拔式深度学习方法的欠采样MRI重建方法，可以有效适应不同的采样设置，并在不同的欠采样模式和采样率下提供了良好而稳健的加速图像重建性能。 |
| [^44] | [SHARM: Segmented Head Anatomical Reference Models.](http://arxiv.org/abs/2309.06677) | 本研究提出了一种分段头部解剖参考模型（SHARM），用于可靠地分割人头部解剖组织，并针对非脑组织的重要性填补了目前研究中的空白。 |
| [^45] | [Quantum Data Center: Perspectives.](http://arxiv.org/abs/2309.06641) | 本文提出了量子数据中心(QDC)的概念，它是现有经典数据中心的量子版本，通过结合量子随机访问存储器(QRAM)和量子网络，QDC可以提供客户在效率、安全性和精度方面的显著优势，对于量子计算、通信和传感领域具有重要意义。该研究探讨了硬件实现和特定应用方面的潜在科学和商业机会，并展示了QDC在机器学习和大数据行业等领域的潜在影响。 |
| [^46] | [The Relational Bottleneck as an Inductive Bias for Efficient Abstraction.](http://arxiv.org/abs/2309.06629) | 本文介绍了一种新的归纳偏好方法——关系瓶颈，用于有效地诱导抽象概念的模型，强调了其在人类思维和大脑中抽象概念习得中的潜力。 |
| [^47] | [A Reinforcement Learning Approach for Robotic Unloading from Visual Observations.](http://arxiv.org/abs/2309.06621) | 本文提出了一种基于强化学习的机器人从视觉观察中卸货的方法，通过使用RGB-D图像作为输入并采用高层决策模块与经典运动控制相结合的层次化控制器结构，实现了无需标注数据的学习过程，并通过实验证明了该方法的改进学习性能。 |
| [^48] | [Hybrid Algorithm Selection and Hyperparameter Tuning on Distributed Machine Learning Resources: A Hierarchical Agent-based Approach.](http://arxiv.org/abs/2309.06604) | 本文提出了一种基于代理的层级机器学习平台，用于选择分布式组织的机器学习算法并同时调整其超参数。该方法具有可伸缩性、灵活性和鲁棒性，并支持自动化和协同的功能。 |
| [^49] | [Rank2Tell: A Multimodal Driving Dataset for Joint Importance Ranking and Reasoning.](http://arxiv.org/abs/2309.06597) | Rank2Tell是一个多模态驾驶数据集，用于联合重要性排序和推理，为研究人员提供了复杂交通情景中各种重要对象的密集注释和独特属性。 |
| [^50] | [Do Generative Large Language Models need billions of parameters?.](http://arxiv.org/abs/2309.06589) | 本文研究了生成大语言模型的规模、性能和计算资源之间的权衡，并提出了新方法来减少参数数量，从而创建更高效、紧凑的模型，为AI语言建模的可持续和可访问的未来做出了贡献。 |
| [^51] | [Can humans help BERT gain "confidence"?.](http://arxiv.org/abs/2309.06580) | 本论文研究了如何将苏黎世认知语料库的认知特征与BERT模型集成，证明了脑电图和眼动特征可以提高自然语言处理模型的性能，并开发了一个用于基准测试的词-EEG词典。 |
| [^52] | [Can Large Language Models Discern Evidence for Scientific Hypotheses? Case Studies in the Social Sciences.](http://arxiv.org/abs/2309.06578) | 本文研究了大型语言模型（LLMs）根据科学摘要文本的能力，来辨别支持或反驳特定假设的证据。通过社区驱动的注释建立了一个新的数据集，针对社会科学中的科学假设证据任务。与其他基准进行了性能比较，并为未来研究提供了机会。 |
| [^53] | [Circle Feature Graphormer: Can Circle Features Stimulate Graph Transformer?.](http://arxiv.org/abs/2309.06574) | 本文介绍了一种新的圆形特征图转换器（CFG），用于丢失链路预测任务，并实现了改进的图自注意机制。实验结果表明，CFG在ogbl-citation2数据集上取得了最先进的性能。 |
| [^54] | [High Fidelity Fast Simulation of Human in the Loop Human in the Plant (HIL-HIP) Systems.](http://arxiv.org/abs/2309.06558) | 本文研究了人在循环人在工厂系统中无线网络的时间变异性对模拟的影响，提出了一种分段线性时间不变模拟（PLIS）方法，实现了超过2.1倍的加速。 |
| [^55] | [Unsupervised Bias Detection in College Student Newspapers.](http://arxiv.org/abs/2309.06557) | 本文提出了一个几乎没有人为影响的流程，用于从大学报纸档案中获取并检测偏见。该方法通过比较大型语言模型摘要的情感与原文来计算偏见，不需要大量标记数据，为客观理解学生报纸来源中的偏见提供了方法。 |
| [^56] | [Offline Prompt Evaluation and Optimization with Inverse Reinforcement Learning.](http://arxiv.org/abs/2309.06553) | 这项工作介绍了一种基于离线逆向强化学习的提示评估与优化方法，通过利用离线数据集和逆向强化学习，预测提示性能、提高成本效益、生成易读的结果。 |
| [^57] | [Synthetic Text Generation using Hypergraph Representations.](http://arxiv.org/abs/2309.06550) | 本论文提出了一种使用超图表示生成合成文本的方法，首先将文档分解为语义框架，然后使用此中间稀疏格式生成文本。通过扰动框架内容，包括拓扑分析挖掘新的超边以及包含层次结构和时间动态的复杂多元关系，我们的解决方案生成的文档在样式、情感、格式、构成和事实上是多样的、连贯的和变化的。 |
| [^58] | [Hierarchical Multi-Task Learning Framework for Session-based Recommendations.](http://arxiv.org/abs/2309.06533) | 本文提出了一种面向会话推荐的层次化多任务学习框架HierSRec，通过在预测任务之间设置层次结构，并利用辅助任务的输出来提供更丰富的输入特征和更高的预测可解释性，进一步增强了预测准确性和可泛化性。 |
| [^59] | [Minimum Bayes' Risk Decoding for System Combination of Grammatical Error Correction Systems.](http://arxiv.org/abs/2309.06520) | 本文提出了一个用于语法错误修正系统系统组合的最小贝叶斯风险解码方法，并通过实验证明了其有效性。 |
| [^60] | [AGIBench: A Multi-granularity, Multimodal, Human-referenced, Auto-scoring Benchmark for Large Language Models.](http://arxiv.org/abs/2309.06495) | AGIBench是一个用于大型语言模型的多粒度、多模态、人工参考、自动评分的基准，通过标记问题的属性来评估语言模型的问题解决能力和智能程度。 |
| [^61] | [Stochastic LLMs do not Understand Language: Towards Symbolic, Explainable and Ontologically Based LLMs.](http://arxiv.org/abs/2309.05918) | 随机LLMs无法理解语言的原因是它们无法提供可以依赖的事实信息，它们存储的语言知识埋藏在无意义的微特征中，并在某些语言上下文中无法进行正确推理。本文建议在符号化方法中应用有效的自下而上策略 |
| [^62] | [Memory Injections: Correcting Multi-Hop Reasoning Failures during Inference in Transformer-Based Language Models.](http://arxiv.org/abs/2309.05605) | 本文提出了一种通过向Transformer-Based语言模型的LLM注意力头部定向注入内存来纠正多跳推理错误的方法，从而提高了模型在处理多跳推理问题时的表现。 |
| [^63] | [NExT-GPT: Any-to-Any Multimodal LLM.](http://arxiv.org/abs/2309.05519) | NExT-GPT是一个任何到任何的多模态语言模型系统，通过连接多模态适配器和不同扩散解码器，能够接受和生成任意组合的文本、图像、视频和音频内容。 |
| [^64] | [Can you text what is happening? Integrating pre-trained language encoders into trajectory prediction models for autonomous driving.](http://arxiv.org/abs/2309.05282) | 本研究提出了将预训练语言编码器整合到自动驾驶的轨迹预测模型中的新方法。通过基于文本的场景表示和经典的栅格化图像表示相结合，得到了描述性的场景嵌入，并在实验中验证了显著的性能改进。 |
| [^65] | [Physics-Informed Neural Networks for an optimal counterdiabatic quantum computation.](http://arxiv.org/abs/2309.04434) | 本研究提出了一种利用物理信息神经网络（PINNs）解决量子电路反对角（CD）协议优化问题的方法，通过嵌入物理信息到神经网络中，并利用最小作用量原理和厄米特性条件来获取最适当的反对角项，从而提供了一种可靠的替代方案，摆脱了以往依赖于经典数值逼近的约束。 |
| [^66] | [Online Submodular Maximization via Online Convex Optimization.](http://arxiv.org/abs/2309.04339) | 本论文研究了在线设置下的一般性子模最大化问题，并将一类大型子模函数归约到在线凸优化问题中。这种归约方式可在组合优化中实现次线性遗憾，并且适用于许多不同版本的在线学习问题。 |
| [^67] | [Interactive Hyperparameter Optimization in Multi-Objective Problems via Preference Learning.](http://arxiv.org/abs/2309.03581) | 本文提出了一个以人为中心的交互式超参数优化方法，通过应用偏好学习来解决多目标机器学习中的问题。 |
| [^68] | [ChatRule: Mining Logical Rules with Large Language Models for Knowledge Graph Reasoning.](http://arxiv.org/abs/2309.01538) | 本论文提出了一个框架ChatRule，利用大型语言模型挖掘知识图谱中的逻辑规则。该框架通过充分利用知识图谱的语义和结构信息，能够提高推理性能并提供可解释的结果。 |
| [^69] | [MultiWay-Adapater: Adapting large-scale multi-modal models for scalable image-text retrieval.](http://arxiv.org/abs/2309.01516) | 多途径适配器是一个创新的框架，利用"对齐增强器"加深模态对齐，实现高可转移性，可有效减少调整参数的时间并提高零样本图像-文本检索性能。 |
| [^70] | [Elucidating the Exposure Bias in Diffusion Models.](http://arxiv.org/abs/2308.15321) | 本文系统地研究了扩散模型中的曝光偏差问题，并提出了一种名为Epsilon Scaling的免训练方法来减轻这一问题。实验结果验证了该方法的有效性。 |
| [^71] | [A Parallel Ensemble of Metaheuristic Solvers for the Traveling Salesman Problem.](http://arxiv.org/abs/2308.07347) | 这篇论文研究了并行集合中旅行商问题的元启发式求解器。通过将不同求解器结合使用，能够超越单个求解器的性能表现。 |
| [^72] | [Optimizing Offensive Gameplan in the National Basketball Association with Machine Learning.](http://arxiv.org/abs/2308.06851) | 本文研究了如何用机器学习优化国家篮球协会的进攻战术规划。通过建立模型，采用特定的特征进行评估和分析，可以帮助决策者确定战术执行的具体细节。 |
| [^73] | [Developmental Bootstrapping of AIs.](http://arxiv.org/abs/2308.04586) | 传统的符号AI方法和深度学习AI方法无法满足创建强大和可信赖的AI的挑战，然而，发展脱靴法通过模仿人类儿童的能力发展过程，为创建稳健可靠的AI提供了希望。 |
| [^74] | [MSAC: Multiple Speech Attribute Control Method for Speech Emotion Recognition.](http://arxiv.org/abs/2308.04025) | 本研究针对语音情感识别(SER)提出了MSAC方法，通过构建新颖的CNN-based SER模型和多语音属性控制方法MSAC，实现了对情感的更精细控制和捕捉，从而提升了SER的可靠性和效果。 |
| [^75] | [Of Models and Tin Men -- a behavioural economics study of principal-agent problems in AI alignment using large-language models.](http://arxiv.org/abs/2307.11137) | 本研究基于行为经济学角度，对使用大语言模型进行AI对齐中的委托-代理问题进行研究，发现现实世界中的AI安全问题不仅涉及设计者与代理之间的冲突，还涉及到多个代理之间的信息不对称与效用函数之间的错位。 |
| [^76] | [Human Body Digital Twin: A Master Plan.](http://arxiv.org/abs/2307.09225) | 人体数字孪生技术在医疗保健和健康领域具有巨大潜力，该论文提出了一个五级发展路线图，涵盖了可穿戴设备、数据收集、数据分析和决策系统等组成部分的开发，并强调了支持、安全、成本和伦理问题的重要性。 |
| [^77] | [RL4CO: an Extensive Reinforcement Learning for Combinatorial Optimization Benchmark.](http://arxiv.org/abs/2306.17100) | RL4CO是一个用于组合优化的广泛强化学习基准测试，着重于可扩展性和泛化能力的评估，并展示了一些最新方法在样本效率和适应不同数据分布方面的表现相对较差，强调了对神经CO求解器性能的平衡评估的重要性。 |
| [^78] | [Gradient-Informed Quality Diversity for the Illumination of Discrete Spaces.](http://arxiv.org/abs/2306.05138) | 本文提出了具有Gradient-Informed Discrete Emitter (ME-GIDE)的Map-Elites方法，利用梯度信息优化离散空间的搜索，相对于传统的质量多样性算法在离散问题中具有更好的性能。 |
| [^79] | [Do Language Models Know When They're Hallucinating References?.](http://arxiv.org/abs/2305.18248) | 本研究针对大型语言模型中的“幻觉”参考文献进行了研究，通过简单的搜索引擎查询可可靠地识别这些幻觉。并且通过对同一语言模型进行黑盒查询来进行分类，揭示了幻觉参考文献的性质。 |
| [^80] | [Does ChatGPT have Theory of Mind?.](http://arxiv.org/abs/2305.14020) | 本文研究了ChatGPT在心智理论方面的能力。通过对比不同版本的ChatGPT在几个经典问题上的表现，发现ChatGPT-4比随机答案给出了更多正确答案，尽管这些答案往往基于错误的假设或无效的推理。 |
| [^81] | [Deep Visual-Genetic Biometrics for Taxonomic Classification of Rare Species.](http://arxiv.org/abs/2305.06695) | 本文提出了一种利用对齐的视觉-遗传推理空间来提高少量图像数据珍稀物种分类的方法，该方法通过深度嵌入模型实现对齐，适用于提高稀有物种的长尾识别，并且可以显著有益于仅基于视觉的稀有物种识别。 |
| [^82] | [Transformer-based model for monocular visual odometry: a video understanding approach.](http://arxiv.org/abs/2305.06121) | 本文提出了一种基于Transformer模型的TSformer-VO方法，将单目视觉里程计作为一项视频理解任务并通过时空自注意机制从视频片段中提取特征，以实现端到端的运动估计，达到了最新成果。 |
| [^83] | [LaCViT: A Label-aware Contrastive Training Framework for Vision Transformers.](http://arxiv.org/abs/2303.18013) | LaCViT是一种针对视觉Transformer预训练表示空间的各向等性不足问题，提高其表示空间等性的面向标签的对比训练框架，经过实验证明其在五个标准图像分类数据集中具有卓越的性能。 |
| [^84] | [The Quality-Diversity Transformer: Generating Behavior-Conditioned Trajectories with Decision Transformers.](http://arxiv.org/abs/2303.16207) | 该论文提出了一种基于质量多样性算法和 Transformer 的方法，通过两种机制以实现质量一致的生成行为条件下的轨迹。 |
| [^85] | [Your Diffusion Model is Secretly a Zero-Shot Classifier.](http://arxiv.org/abs/2303.16203) | 扩散模型的密度估计可以被用作零样本分类，作者的生成式分类方法在各种基准测试中取得强大的结果，并具有更强的多模式关系推理能力。 |
| [^86] | ["Correct answers" from the psychology of artificial intelligence.](http://arxiv.org/abs/2302.07267) | 本文使用OpenAI的GPT3.5模型重新复制了Many Labs 2复制项目中的14项研究，其中8项研究的结果被成功复制。然而，对于剩下的6项研究，GPT3.5以极其预定的方式回答了调查问题，导致无法分析这些研究。 |
| [^87] | [DWRSeg: Rethinking Efficient Acquisition of Multi-scale Contextual Information for Real-time Semantic Segmentation.](http://arxiv.org/abs/2212.01173) | DWRSeg重新思考了实时语义分割中获取多尺度上下文信息的方法，提出了一种高效的多尺度特征提取方法，通过将原始单步方法分解为区域残余化和语义残余化两个步骤，简化了多速率深度空洞卷积的角色，并提高了特征提取的效率。 |
| [^88] | [Pathway to Future Symbiotic Creativity.](http://arxiv.org/abs/2209.02388) | 本文提出了人机共生艺术创作的发展路径，从模仿人类艺术家逐渐发展为具备独立创作能力的机器艺术家。在这条路径上，需要机器理解人类的心理状态，并通过沉浸式环境和元宇宙的发展实现双向沟通，以实现共生艺术创作。 |
| [^89] | [Towards Visual Affordance Learning: A Benchmark for Affordance Segmentation and Recognition.](http://arxiv.org/abs/2203.14092) | 该论文介绍了一个大规模的多视角RGBD视觉可管理学习数据集，其中包含了37个对象类别的47210个图像，并且每个图像都带有15个视觉可管理类别的注释。 |

# 详细

[^1]: 超越文本视野：多模态训练提升了在真实性和伦理道德方面的MLLM

    Sight Beyond Text: Multi-Modal Training Enhances LLMs in Truthfulness and Ethics. (arXiv:2309.07120v1 [cs.CL])

    [http://arxiv.org/abs/2309.07120](http://arxiv.org/abs/2309.07120)

    多模态训练的MLLM在纯NLP任务中表现出卓越的真实性和伦理对齐能力，这得益于视觉指导调优和优秀的指导质量。

    

    多模态大语言模型（MLLM）基于大型语言模型（LLM）进行训练，具备理解多模态输入和生成文本响应的增强能力。虽然它们在多模态任务中表现出色，但对MLLM的纯NLP能力常常低估并未经测试。本研究中，我们采用了新颖的方法，揭示了MLLM的一个引人注目的特性——初步结果表明，视觉指导调优，一种将LLM转换为MLLM的流行策略，出乎意料地帮助模型在纯NLP环境中取得了提高真实性和伦理对齐的效果。例如，经过视觉指导调优的LLaMA2 7B模型在TruthfulQA-mc和伦理道德基准上超过了经过超过一百万人工标注的LLaMA2-chat 7B模型的性能。进一步的分析表明，这种改进的对齐可以归因于视觉-文本数据固有的优秀指导质量。

    Multi-modal large language models (MLLMs) are trained based on large language models (LLM), with an enhanced capability to comprehend multi-modal inputs and generate textual responses. While they excel in multi-modal tasks, the pure NLP abilities of MLLMs are often underestimated and left untested. In this study, we get out of the box and unveil an intriguing characteristic of MLLMs -- our preliminary results suggest that visual instruction tuning, a prevailing strategy for transitioning LLMs into MLLMs, unexpectedly and interestingly helps models attain both improved truthfulness and ethical alignment in the pure NLP context. For example, a visual-instruction-tuned LLaMA2 7B model surpasses the performance of the LLaMA2-chat 7B model, fine-tuned with over one million human annotations, on TruthfulQA-mc and Ethics benchmarks. Further analysis reveals that the improved alignment can be attributed to the superior instruction quality inherent to visual-text data. In releasing our code at 
    
[^2]: 多智能体强化学习的速度性能特征化

    Characterizing Speed Performance of Multi-Agent Reinforcement Learning. (arXiv:2309.07108v1 [cs.LG])

    [http://arxiv.org/abs/2309.07108](http://arxiv.org/abs/2309.07108)

    本文对多智能体强化学习（MARL）的速度性能进行了特征化研究。作者通过引入分类法，提出了三种最先进的MARL算法作为目标基准，以解决目前优化奖励的算法在训练时间速度性能方面的不足。

    

    多智能体强化学习（MARL）在大规模人工智能系统和大数据应用（如智能电网、监控等）取得了显著成功。现有的MARL算法的进展主要集中在通过引入各种机制来改进智能体之间的合作以提高奖励。然而，这些优化通常会在计算和内存方面产生较大负担，从而导致端到端训练时间的速度性能不佳。在本研究中，我们分析了速度性能（即延迟受限吞吐量）作为MARL实现的关键指标。具体而言，我们首先从加速的角度引入了一个MARL算法的分类法，包括（1）训练方案和（2）通信方法。利用我们的分类法，我们确定了三种最先进的MARL算法—多智能体深度确定性策略梯度（MADDPG）、面向目标的多智能体通信与合作（ToM2C）和网络多智能体RL（NeurComm）—作为目标基准。

    Multi-Agent Reinforcement Learning (MARL) has achieved significant success in large-scale AI systems and big-data applications such as smart grids, surveillance, etc. Existing advancements in MARL algorithms focus on improving the rewards obtained by introducing various mechanisms for inter-agent cooperation. However, these optimizations are usually compute- and memory-intensive, thus leading to suboptimal speed performance in end-to-end training time. In this work, we analyze the speed performance (i.e., latency-bounded throughput) as the key metric in MARL implementations. Specifically, we first introduce a taxonomy of MARL algorithms from an acceleration perspective categorized by (1) training scheme and (2) communication method. Using our taxonomy, we identify three state-of-the-art MARL algorithms - Multi-Agent Deep Deterministic Policy Gradient (MADDPG), Target-oriented Multi-agent Communication and Cooperation (ToM2C), and Networked Multi-Agent RL (NeurComm) - as target benchmar
    
[^3]: 比较Llama-2和GPT-3在HPC核心生成方面的效果

    Comparing Llama-2 and GPT-3 LLMs for HPC kernels generation. (arXiv:2309.07103v1 [cs.SE])

    [http://arxiv.org/abs/2309.07103](http://arxiv.org/abs/2309.07103)

    本研究评估了Llama-2和GPT-3在生成HPC核心方面的性能，并发现Llama-2在准确性方面具有竞争力。同时，通过使用GitHub Copilot生成的代码更可靠，而Llama-2生成的代码更可靠。

    

    我们评估了开源Llama-2模型在不同并行编程模型和语言上生成著名高性能计算核心（如AXPY，GEMV，GEMM）的使用。我们基于我们之前的工作，使用基于OpenAI Codex的简单提示通过GitHub Copilot生成类似的核心。我们的目标是通过使用类似的指标比较Llama-2和我们原始的GPT-3基准的准确性。Llama-2具有简化的模型，显示出有竞争力甚至更高的准确性。我们还报告了这些基础大型语言模型之间的差异，因为生成式人工智能继续重新定义人机交互。总体而言，Copilot生成的代码更可靠但优化程度较低，而Llama-2生成的代码则更可靠。

    We evaluate the use of the open-source Llama-2 model for generating well-known, high-performance computing kernels (e.g., AXPY, GEMV, GEMM) on different parallel programming models and languages (e.g., C++: OpenMP, OpenMP Offload, OpenACC, CUDA, HIP; Fortran: OpenMP, OpenMP Offload, OpenACC; Python: numpy, Numba, pyCUDA, cuPy; and Julia: Threads, CUDA.jl, AMDGPU.jl). We built upon our previous work that is based on the OpenAI Codex, which is a descendant of GPT-3, to generate similar kernels with simple prompts via GitHub Copilot. Our goal is to compare the accuracy of Llama-2 and our original GPT-3 baseline by using a similar metric. Llama-2 has a simplified model that shows competitive or even superior accuracy. We also report on the differences between these foundational large language models as generative AI continues to redefine human-computer interactions. Overall, Copilot generates codes that are more reliable but less optimized, whereas codes generated by Llama-2 are less relia
    
[^4]: 在异构设备上减轻联邦学习中的群体偏见

    Mitigating Group Bias in Federated Learning for Heterogeneous Devices. (arXiv:2309.07085v1 [cs.LG])

    [http://arxiv.org/abs/2309.07085](http://arxiv.org/abs/2309.07085)

    本文提出了一种在分布式边缘应用中减轻联邦学习中群体偏见的方法，该方法可以通过计算跨域群体重要性来减轻全局模型的偏见，并保持隐私和资源利用效率。

    

    联邦学习正在分布式边缘应用中崭露头角作为一种保护隐私的模型训练方法。然而，大多数边缘部署是异构的，即它们的感知能力和环境在部署中各不相同。这种边缘异构违反了本地数据在客户端之间独立且分布相同 (IID) 的特性，产生了有偏见的全局模型，即对特定社区或群体做出不公平的决策和歧视。现有的偏见缓解技术只关注非IID数据中由标签异构引起的偏见，并没有考虑由特征异构导致的领域变化，也没有解决全局群体公平的问题。我们的工作提出了一种在保护隐私和不增加资源利用开销的情况下，减少群体偏见的联邦学习框架。我们的主要思想是利用平均条件概率来计算跨域群体重要性。

    Federated Learning is emerging as a privacy-preserving model training approach in distributed edge applications. As such, most edge deployments are heterogeneous in nature i.e., their sensing capabilities and environments vary across deployments. This edge heterogeneity violates the independence and identical distribution (IID) property of local data across clients and produces biased global models i.e. models that contribute to unfair decision-making and discrimination against a particular community or a group. Existing bias mitigation techniques only focus on bias generated from label heterogeneity in non-IID data without accounting for domain variations due to feature heterogeneity and do not address global group-fairness property.  Our work proposes a group-fair FL framework that minimizes group-bias while preserving privacy and without resource utilization overhead. Our main idea is to leverage average conditional probabilities to compute a cross-domain group \textit{importance we
    
[^5]: 现代数字取证与事故响应中人工智能和机器学习的全面分析

    A Comprehensive Analysis of the Role of Artificial Intelligence and Machine Learning in Modern Digital Forensics and Incident Response. (arXiv:2309.07064v1 [cs.CR])

    [http://arxiv.org/abs/2309.07064](http://arxiv.org/abs/2309.07064)

    本研究全面分析了人工智能和机器学习在现代数字取证和事故响应中的作用，探讨了相关技术的应用及其对取证调查的影响。

    

    在动态的数字取证领域，人工智能（AI）和机器学习（ML）的整合作为一项变革性技术，有望提高数字取证调查的效率和精度。然而，AI和ML在数字取证中的应用仍处于初级阶段。因此，本文旨在进行深入而全面的分析，超越简单的调研和回顾。研究的目标是密切关注AI和ML技术在数字取证和事故响应中的应用方式。本研究探讨了跨领域的前沿研究倡议，包括数据收集和恢复、复杂的网络犯罪时间线重建、强大的大数据分析、模式识别、保护证据链条和组织响应性策略等。这项努力深入挖掘了AI驱动方法对数字取证的关键方面产生的微妙影响。

    In the dynamic landscape of digital forensics, the integration of Artificial Intelligence (AI) and Machine Learning (ML) stands as a transformative technology, poised to amplify the efficiency and precision of digital forensics investigations. However, the use of ML and AI in digital forensics is still in its nascent stages. As a result, this paper gives a thorough and in-depth analysis that goes beyond a simple survey and review. The goal is to look closely at how AI and ML techniques are used in digital forensics and incident response. This research explores cutting-edge research initiatives that cross domains such as data collection and recovery, the intricate reconstruction of cybercrime timelines, robust big data analysis, pattern recognition, safeguarding the chain of custody, and orchestrating responsive strategies to hacking incidents. This endeavour digs far beneath the surface to unearth the intricate ways AI-driven methodologies are shaping these crucial facets of digital fo
    
[^6]: 用于编译优化的大型语言模型

    Large Language Models for Compiler Optimization. (arXiv:2309.07062v1 [cs.PL])

    [http://arxiv.org/abs/2309.07062](http://arxiv.org/abs/2309.07062)

    本论文研究了将大型语言模型应用于代码优化的新颖方法，以7B参数的transformer模型为例，通过预测指令计数和生成优化代码等辅助学习任务，显著提高了模型的优化性能。在大量测试程序上的评估中，该方法相对编译器的优化效果提高了3.0%，并展现出令人惊喜的强大代码推理能力。

    

    我们探索了将大型语言模型应用于代码优化的新颖方法。我们展示了一个从头开始训练的7B参数的transformer模型，用于优化LLVM汇编的代码大小。该模型以未优化的汇编作为输入，并输出一组最佳优化程序的编译器选项。在训练过程中，我们要求模型预测优化前后的指令计数和优化后的代码本身。这些辅助学习任务显著提高了模型的优化性能，并提高了模型的理解深度。我们在一套大型测试程序上进行了评估。我们的方法在减少指令计数方面比编译器提高了3.0%，超过了需要数千次编译的两个最先进的基准方法。此外，该模型显示出令人惊讶的强大的代码推理能力，91%的时间生成可编译的代码，并70%的时间能完美模拟编译器的输出。

    We explore the novel application of Large Language Models to code optimization. We present a 7B-parameter transformer model trained from scratch to optimize LLVM assembly for code size. The model takes as input unoptimized assembly and outputs a list of compiler options to best optimize the program. Crucially, during training, we ask the model to predict the instruction counts before and after optimization, and the optimized code itself. These auxiliary learning tasks significantly improve the optimization performance of the model and improve the model's depth of understanding.  We evaluate on a large suite of test programs. Our approach achieves a 3.0% improvement in reducing instruction counts over the compiler, outperforming two state-of-the-art baselines that require thousands of compilations. Furthermore, the model shows surprisingly strong code reasoning abilities, generating compilable code 91% of the time and perfectly emulating the output of the compiler 70% of the time.
    
[^7]: 深度量子图像模拟：解析神经网络对量子实验的见解

    Deep Quantum Graph Dreaming: Deciphering Neural Network Insights into Quantum Experiments. (arXiv:2309.07056v1 [quant-ph])

    [http://arxiv.org/abs/2309.07056](http://arxiv.org/abs/2309.07056)

    本文使用了一种名为“梦境”的可解释人工智能技术，探索神经网络对量子光学实验的学习，发现网络可以改变量子系统的属性分布，并揭示了神经网络的学习策略。

    

    尽管神经网络在促进新的科学发现方面很有前景，但其逻辑背后的不透明性给解释其发现的挑战带来了困难。在本文中，我们使用一种名为“inception”或“深度梦境”的可解释人工智能（XAI）技术，该技术被发明用于计算机视觉的机器学习。我们使用这种技术来探索神经网络对量子光学实验的学习。我们的故事从对量子系统属性进行深度神经网络训练开始。经过训练后，我们“反转”神经网络--实际上是询问它如何想象具有特定属性的量子系统，以及如何连续修改量子系统以改变属性。我们发现网络可以改变量子系统的初始属性分布，我们可以概念化神经网络的学习策略。有趣的是，在较浅层，神经网络识别简单的属性，而在较深层次上...（内容省略）

    Despite their promise to facilitate new scientific discoveries, the opaqueness of neural networks presents a challenge in interpreting the logic behind their findings. Here, we use a eXplainable-AI (XAI) technique called $inception$ or $deep$ $dreaming$, which has been invented in machine learning for computer vision. We use this techniques to explore what neural networks learn about quantum optics experiments. Our story begins by training a deep neural networks on the properties of quantum systems. Once trained, we "invert" the neural network -- effectively asking how it imagines a quantum system with a specific property, and how it would continuously modify the quantum system to change a property. We find that the network can shift the initial distribution of properties of the quantum system, and we can conceptualize the learned strategies of the neural network. Interestingly, we find that, in the first layers, the neural network identifies simple properties, while in the deeper ones
    
[^8]: 随机编程中的学习模式：Pearl和Jeffrey的更新

    Pearl's and Jeffrey's Update as Modes of Learning in Probabilistic Programming. (arXiv:2309.07053v1 [cs.LO])

    [http://arxiv.org/abs/2309.07053](http://arxiv.org/abs/2309.07053)

    本文澄清了在随机编程中使用的学习模式Pearl和Jeffrey的更新机制之间的关系，并指出Jeffrey的更新规则是通过变分推理得到的。

    

    根据新证据更新概率分布的概念是统计学和机器学习的核心。Pearl和Jeffrey的规则是两种自然的更新机制，它们导致不同的结果，但相似性和差异仍然神秘。本文通过概率程序和采样语义的分别描述，以及关于Pearl和Jeffrey的不同似然度的概念，阐明了它们之间的关系。此外，还展示了Jeffrey的更新规则是通过变分推理得到的。从分类概率理论的角度来看，这相当于对多重集合函子在分布单子范畴中的行为进行分析。

    The concept of updating a probability distribution in the light of new evidence lies at the heart of statistics and machine learning. Pearl's and Jeffrey's rule are two natural update mechanisms which lead to different outcomes, yet the similarities and differences remain mysterious. This paper clarifies their relationship in several ways: via separate descriptions of the two update mechanisms in terms of probabilistic programs and sampling semantics, and via different notions of likelihood (for Pearl and for Jeffrey). Moreover, it is shown that Jeffrey's update rule arises via variational inference. In terms of categorical probability theory, this amounts to an analysis of the situation in terms of the behaviour of the multiset functor, extended to the Kleisli category of the distribution monad.
    
[^9]: UnifiedGesture: 多个骨架的统一手势合成模型

    UnifiedGesture: A Unified Gesture Synthesis Model for Multiple Skeletons. (arXiv:2309.07051v1 [cs.HC])

    [http://arxiv.org/abs/2309.07051](http://arxiv.org/abs/2309.07051)

    UnifiedGesture 是一种训练在多个具有不同骨架的手势数据集上的基于扩散模型的语音驱动手势合成方法，通过重新定位网络和扩散模型架构来统一手势表示并捕捉语音和手势之间的相关性。

    

    自动共语手势生成在计算机动画中引起了很大关注。先前的工作设计了个别数据集上的网络结构，导致了数据量的不足和在不同动作捕捉标准之间的泛化能力不强。此外，由于语言和手势之间的弱相关性，这是一个具有挑战性的任务。为了解决这些问题，我们提出了UnifiedGesture，一种基于扩散模型的语音驱动手势合成方法，该方法在具有不同骨架的多个手势数据集上进行训练。具体来说，我们首先提出一个重新定位网络，学习不同动作捕捉标准的潜在同胚图，统一各种手势的表示并扩展数据集。然后，我们基于扩散模型架构捕捉语音和手势之间的相关性，使用跨局部注意力和自注意力生成更好的与语音匹配和更加逼真的手势。为了进一步对齐语音和手势并增加两者的一致性，我们引入了一个新的多层注意力机制以及一个姿势稳定化模块。

    The automatic co-speech gesture generation draws much attention in computer animation. Previous works designed network structures on individual datasets, which resulted in a lack of data volume and generalizability across different motion capture standards. In addition, it is a challenging task due to the weak correlation between speech and gestures. To address these problems, we present UnifiedGesture, a novel diffusion model-based speech-driven gesture synthesis approach, trained on multiple gesture datasets with different skeletons. Specifically, we first present a retargeting network to learn latent homeomorphic graphs for different motion capture standards, unifying the representations of various gestures while extending the dataset. We then capture the correlation between speech and gestures based on a diffusion model architecture using cross-local attention and self-attention to generate better speech-matched and realistic gestures. To further align speech and gesture and increa
    
[^10]: 高效强化学习用于跳跃式单脚机器人

    Efficient Reinforcement Learning for Jumping Monopods. (arXiv:2309.07038v1 [cs.RO])

    [http://arxiv.org/abs/2309.07038](http://arxiv.org/abs/2309.07038)

    本论文研究了如何通过在强化学习框架中注入物理知识来解决跳跃式单脚机器人的控制问题，这样可以大幅减少学习时间并且能够学习和修正可能出现的错误。

    

    在这项工作中，我们考虑了一个复杂的控制问题，即使单脚机器人能够跳到任何方向，其脚下的地形可能是不平的，我们要使它达到目标位置。这是一个更大类别问题的模板，使用标准的基于优化的技术解决这些问题非常具有挑战性和计算开销。强化学习 (RL) 可能是一个有趣的替代方案，但完全从零开始学习的端到端方法是不切实际的。本文提出的解决方案是在 RL 框架中注入物理知识来指导学习过程。这种方法带来了广泛的好处，如大幅减少学习时间，并且能够学习和修正执行运动的低级控制器可能出现的错误。我们通过与基于优化和端到端 RL 方法的比较，证明了我们方法的优势。

    In this work, we consider the complex control problem of making a monopod reach a target with a jump. The monopod can jump in any direction and the terrain underneath its foot can be uneven. This is a template of a much larger class of problems, which are extremely challenging and computationally expensive to solve using standard optimisation-based techniques. Reinforcement Learning (RL) could be an interesting alternative, but the application of an end-to-end approach in which the controller must learn everything from scratch, is impractical. The solution advocated in this paper is to guide the learning process within an RL framework by injecting physical knowledge. This expedient brings to widespread benefits, such as a drastic reduction of the learning time, and the ability to learn and compensate for possible errors in the low-level controller executing the motion. We demonstrate the advantage of our approach with respect to both optimization-based and end-to-end RL approaches.
    
[^11]: 如何（不）在主观NLP任务中使用社会人口统计信息

    How (Not) to Use Sociodemographic Information for Subjective NLP Tasks. (arXiv:2309.07034v1 [cs.CL])

    [http://arxiv.org/abs/2309.07034](http://arxiv.org/abs/2309.07034)

    该论文研究了如何使用社会人口统计信息在主观NLP任务中，发现社会人口提示技术在某些任务上有效，但也存在一些限制和挑战。

    

    注释者的社会人口背景（即性别，年龄，教育背景等个体组成）对其在主观NLP任务中的决策有很大影响，比如仇恨言论检测。通常，异质的背景会导致高度分歧。为了建模这种差异，最近的研究探索了社会人口提示技术，这种技术将基于提示的模型的输出引导到具有特定社会人口特征的人类可能给出的答案。然而，现有的NLP文献对这种技术的效果存在分歧 - 它仍然不清楚它能在哪些任务和场景中有帮助，并且评估仅限于特定任务。我们通过展示迄今为止最大和最全面的社会人口提示研究来填补这一研究空白。具体来说，我们评估了七个数据集和六个经过指导调整的模型家族中的几个提示形式。我们发现，尽管社会人口提示对某些任务有效，但也存在一些限制和挑战。

    Annotators' sociodemographic backgrounds (i.e., the individual compositions of their gender, age, educational background, etc.) have a strong impact on their decisions when working on subjective NLP tasks, such as hate speech detection. Often, heterogeneous backgrounds result in high disagreements. To model this variation, recent work has explored sociodemographic prompting, a technique, which steers the output of prompt-based models towards answers that humans with specific sociodemographic profiles would give. However, the available NLP literature disagrees on the efficacy of this technique -- it remains unclear, for which tasks and scenarios it can help and evaluations are limited to specific tasks only. We address this research gap by presenting the largest and most comprehensive study of sociodemographic prompting today. Concretely, we evaluate several prompt formulations across seven datasets and six instruction-tuned model families. We find that (1) while sociodemographic prompt
    
[^12]: 简历解析作为分层序列标注的实证研究

    R\'esum\'e Parsing as Hierarchical Sequence Labeling: An Empirical Study. (arXiv:2309.07015v1 [cs.CL])

    [http://arxiv.org/abs/2309.07015](http://arxiv.org/abs/2309.07015)

    本研究将简历解析问题作为分层序列标注任务，提出了同时解决行和标记两个任务的模型架构，并构建了多语言的高质量简历解析语料库。实验结果表明，所提出模型在信息提取任务中优于先前工作中的方法。进一步分析了模型性能和资源效率，并描述了模型在生产环境中的权衡。

    

    从简历中提取信息通常被形式化为一个两阶段的问题，即首先将文档分段，然后对每个段落进行单独处理以提取目标实体。我们将整个问题分为两个级别的序列标注任务，即行和标记，并研究了同时解决这两个任务的模型架构。我们构建了英语、法语、中文、西班牙语、德语、葡萄牙语和瑞典语的高质量简历解析语料库。基于这些语料库，我们提出了实验结果，证明了所提出模型在信息提取任务中的有效性，优于先前工作中的方法。我们对所提出的架构进行了消融研究。我们还分析了模型的性能和资源效率，并描述了在生产环境中进行模型部署时的权衡。

    Extracting information from r\'esum\'es is typically formulated as a two-stage problem, where the document is first segmented into sections and then each section is processed individually to extract the target entities. Instead, we cast the whole problem as sequence labeling in two levels -- lines and tokens -- and study model architectures for solving both tasks simultaneously. We build high-quality r\'esum\'e parsing corpora in English, French, Chinese, Spanish, German, Portuguese, and Swedish. Based on these corpora, we present experimental results that demonstrate the effectiveness of the proposed models for the information extraction task, outperforming approaches introduced in previous work. We conduct an ablation study of the proposed architectures. We also analyze both model performance and resource efficiency, and describe the trade-offs for model deployment in the context of a production environment.
    
[^13]: 企业ESG报告的动态分析：一个演化趋势模型

    Dynamic Analysis of Corporate ESG Reports: A Model of Evolutionary Trends. (arXiv:2309.07001v1 [cs.CE])

    [http://arxiv.org/abs/2309.07001](http://arxiv.org/abs/2309.07001)

    本研究通过开发一个动态框架，利用来自技术公司的21世纪ESG报告的丰富数据，揭示了ESG观点的演化趋势。

    

    环境、社会和治理(ESG)报告被全球公认为可持续企业发展的基石。本研究旨在绘制全球市场中公司ESG主题的变化格局。我们开发了一个动态框架，用于分析个别类别、多个类别和与特定可持续性指数保持一致的ESG战略管理。这些分析过程的输出构成了ESG战略模型的基础。通过将分析性关键词纳入提出的框架，利用来自技术公司的21世纪ESG报告的丰富收集，我们的实验阐明了ESG观点的变化。因此，这项工作提供了一种经验方法，揭示了近年来ESG主题的并行演化。

    Environmental, social, and governance (ESG) reports are globally recognized as a keystone in sustainable enterprise development. This study aims to map the changing landscape of ESG topics within firms in the global market. A dynamic framework is developed to analyze ESG strategic management for individual classes, across multiple classes, and in alignment with a specific sustainability index. The output of these analytical processes forms the foundation of an ESG strategic model. Utilizing a rich collection of 21st-century ESG reports from technology companies, our experiment elucidates the changes in ESG perspectives by incorporating analytical keywords into the proposed framework. This work thus provides an empirical method that reveals the concurrent evolution of ESG topics over recent years.
    
[^14]: MASTERKEY: 对说话人验证系统的实际后门攻击

    MASTERKEY: Practical Backdoor Attack Against Speaker Verification Systems. (arXiv:2309.06981v1 [cs.CR])

    [http://arxiv.org/abs/2309.06981](http://arxiv.org/abs/2309.06981)

    这项工作提出了一种名为MASTERKEY的后门攻击，针对说话人验证系统。与以往攻击不同，在实际环境下攻击者对目标用户没有任何了解。通过嵌入说话人特征和语义信息，以及集成信道失真，我们的攻击可以成功破坏多个流行的SV模型，达到100％的攻击成功率。

    

    说话人验证（SV）广泛应用于移动系统中，通过使用用户的语音特征来认证合法用户。在这项工作中，我们提出了一种名为MASTERKEY的后门攻击，以破坏SV模型。与以往的攻击不同，我们关注的是在攻击者对目标用户没有任何了解的实际环境下进行攻击。为了设计MASTERKEY，我们调查了现有的针对未见目标的中毒攻击的局限性。然后，我们优化了一个通用的后门，可以攻击任意目标。接下来，我们将说话人的特征和语义信息嵌入到后门中，使其不可察觉。最后，我们估计了信道失真，并将其集成到后门中。我们验证了我们的攻击对6个流行的SV模型。具体而言，我们中毒了共计53个模型，并使用我们的触发器攻击了16,430个注册说话人，其中包括在53个中毒模型中注册的310个目标说话人。我们的攻击成功率达到100％。

    Speaker Verification (SV) is widely deployed in mobile systems to authenticate legitimate users by using their voice traits. In this work, we propose a backdoor attack MASTERKEY, to compromise the SV models. Different from previous attacks, we focus on a real-world practical setting where the attacker possesses no knowledge of the intended victim. To design MASTERKEY, we investigate the limitation of existing poisoning attacks against unseen targets. Then, we optimize a universal backdoor that is capable of attacking arbitrary targets. Next, we embed the speaker's characteristics and semantics information into the backdoor, making it imperceptible. Finally, we estimate the channel distortion and integrate it into the backdoor. We validate our attack on 6 popular SV models. Specifically, we poison a total of 53 models and use our trigger to attack 16,430 enrolled speakers, composed of 310 target speakers enrolled in 53 poisoned models. Our attack achieves 100% attack success rate with a
    
[^15]: DNNShifter: 一种高效的边缘计算DNN剪枝系统

    DNNShifter: An Efficient DNN Pruning System for Edge Computing. (arXiv:2309.06973v1 [cs.LG])

    [http://arxiv.org/abs/2309.06973](http://arxiv.org/abs/2309.06973)

    DNNShifter是一种高效的边缘计算DNN剪枝系统，通过快速推导出合适的模型变体来提供高推理准确性，适应系统和网络条件变化的工作负载需求。

    

    深度神经网络（DNN）是许多机器学习应用的基础。生产质量的DNN模型通过训练数百万个DNN参数来实现高推理准确性，但这占用了大量的计算资源。这对于在网络的极端边缘处工作的资源（如具有有限计算和内存资源的移动和嵌入式设备）构成挑战。为了解决这个问题，需要对模型进行剪枝，以创建轻量级、更适合这些设备的变体。现有的剪枝方法无法在不引入显著时间成本和负担的情况下提供与未剪枝模型相似的质量模型，或者只限于离线使用场景。我们的工作通过保持原始模型的准确性，快速推导出适合的模型变体。模型变体可以在系统和网络条件发生变化以匹配工作负载需求时快速切换。本文介绍了DNNShifter，一种端到端的DNN训练、空间剪枝和模型切换系统。

    Deep neural networks (DNNs) underpin many machine learning applications. Production quality DNN models achieve high inference accuracy by training millions of DNN parameters which has a significant resource footprint. This presents a challenge for resources operating at the extreme edge of the network, such as mobile and embedded devices that have limited computational and memory resources. To address this, models are pruned to create lightweight, more suitable variants for these devices. Existing pruning methods are unable to provide similar quality models compared to their unpruned counterparts without significant time costs and overheads or are limited to offline use cases. Our work rapidly derives suitable model variants while maintaining the accuracy of the original model. The model variants can be swapped quickly when system and network conditions change to match workload demand. This paper presents DNNShifter, an end-to-end DNN training, spatial pruning, and model switching syst
    
[^16]: 设定正确的期望：随时间变化的算法补救措施

    Setting the Right Expectations: Algorithmic Recourse Over Time. (arXiv:2309.06969v1 [cs.LG])

    [http://arxiv.org/abs/2309.06969](http://arxiv.org/abs/2309.06969)

    这项研究关注算法补救措施中忽视的关键要素 - 不断变化的环境对补救效果的影响。研究发现，在时间推移和个体间竞争的情况下，初始的补救建议可能变得不可靠，因此需要考虑时间变化来确保补救的有效性。

    

    算法系统经常被用于协助高风险决策。鉴于此，算法补救措施，即个体应能够针对算法系统产生的不良结果采取行动，受到越来越多的关注。迄今为止，关于算法补救措施的大部分文献主要关注如何为单个个体提供补救，而忽略了一个关键要素：不断变化的环境的影响。忽视这些对补救措施的影响是一个重大的疏忽，因为几乎所有情况下，补救措施都包括个体首次做出不利尝试，然后在以后的某个时间点提供一次或多次尝试的机会 - 当时环境可能已经发生了变化。这可能会产生虚假的期望，因为初始的补救建议随时间的推移可能变得不太可靠，原因是模型漂移和个体之间对有利结果的竞争导致的。在这项工作中，我们提出了一种考虑时间变化的算法补救措施的方法。

    Algorithmic systems are often called upon to assist in high-stakes decision making. In light of this, algorithmic recourse, the principle wherein individuals should be able to take action against an undesirable outcome made by an algorithmic system, is receiving growing attention. The bulk of the literature on algorithmic recourse to-date focuses primarily on how to provide recourse to a single individual, overlooking a critical element: the effects of a continuously changing context. Disregarding these effects on recourse is a significant oversight, since, in almost all cases, recourse consists of an individual making a first, unfavorable attempt, and then being given an opportunity to make one or several attempts at a later date - when the context might have changed. This can create false expectations, as initial recourse recommendations may become less reliable over time due to model drift and competition for access to the favorable outcome between individuals.  In this work we prop
    
[^17]: 朝着可靠的皮肤科评估基准的发展

    Towards Reliable Dermatology Evaluation Benchmarks. (arXiv:2309.06961v1 [cs.CV])

    [http://arxiv.org/abs/2309.06961](http://arxiv.org/abs/2309.06961)

    本论文提出了一种资源高效的数据清理协议，以提高数字皮肤科模型性能评估的可信度。协议结合现有算法，并在多个皮肤科医生的确认下，删除了无关样本和近似重复样本，估计了标签错误的百分比，并提供了修订后的数据集文件列表。这项工作为数字皮肤科中更可靠的性能评估铺平了道路。

    

    数字皮肤科评估基准数据集无意间包含的不准确性降低了模型性能估计的信任度。我们提出了一种资源高效的数据清理协议，用于识别之前的策划中遗漏的问题。该协议利用现有的算法清理策略，并在直观的停止准则的终止下进行确认过程。基于多个皮肤科医生的确认，我们删除了无关样本和近似重复样本，并估计了由国际皮肤成像协作组推广的六个皮肤科图像数据集中标签错误的百分比，以用于模型评估。除了本文，我们还公布了每个数据集的修订文件列表，应该用于模型评估。我们的工作为数字皮肤科中更可靠的性能评估铺平了道路。

    Benchmark datasets for digital dermatology unwittingly contain inaccuracies that reduce trust in model performance estimates. We propose a resource-efficient data cleaning protocol to identify issues that escaped previous curation. The protocol leverages an existing algorithmic cleaning strategy and is followed by a confirmation process terminated by an intuitive stopping criterion. Based on confirmation by multiple dermatologists, we remove irrelevant samples and near duplicates and estimate the percentage of label errors in six dermatology image datasets for model evaluation promoted by the International Skin Imaging Collaboration. Along with this paper, we publish revised file lists for each dataset which should be used for model evaluation. Our work paves the way for more trustworthy performance assessment in digital dermatology.
    
[^18]: PhantomSound: 黑盒、查询高效的音频对抗攻击：通过分秒级音素注入

    PhantomSound: Black-Box, Query-Efficient Audio Adversarial Attack via Split-Second Phoneme Injection. (arXiv:2309.06960v1 [cs.CR])

    [http://arxiv.org/abs/2309.06960](http://arxiv.org/abs/2309.06960)

    本文介绍了一种名为PhantomSound的黑盒、查询高效的音频对抗攻击方法，通过分秒级音素注入，能够实时攻击不同语音助手的语音转文字API，并且成功绕过了多种活体检测机制。

    

    本文提出PhantomSound，一种针对语音助手的查询高效黑盒攻击。现有的语音助手黑盒对抗攻击方法要么采用替换模型，要么利用中间模型输出来估计用于制作对抗性音频样本的梯度。然而，这些攻击方法需要大量的查询和冗长的训练阶段。PhantomSound利用基于决策的攻击来生成有效的对抗性音频，并通过优化梯度估计来减少查询数量。在实验中，我们针对4种不同的语音转文字API，在3种现实场景下进行攻击，以展示实时攻击的影响。结果显示，PhantomSound在攻击5种流行的商用语音可控设备方面具有实用性和鲁棒性，并且能够以超过95%的成功率绕过3种活体检测机制。基准结果显示，PhantomSound可以生成对抗性音频。

    In this paper, we propose PhantomSound, a query-efficient black-box attack toward voice assistants. Existing black-box adversarial attacks on voice assistants either apply substitution models or leverage the intermediate model output to estimate the gradients for crafting adversarial audio samples. However, these attack approaches require a significant amount of queries with a lengthy training stage. PhantomSound leverages the decision-based attack to produce effective adversarial audios, and reduces the number of queries by optimizing the gradient estimation. In the experiments, we perform our attack against 4 different speech-to-text APIs under 3 real-world scenarios to demonstrate the real-time attack impact. The results show that PhantomSound is practical and robust in attacking 5 popular commercial voice controllable devices over the air, and is able to bypass 3 liveness detection mechanisms with >95% success rate. The benchmark result shows that PhantomSound can generate adversar
    
[^19]: 基于DNA的数据存储的隐式神经多描述方法

    Implicit Neural Multiple Description for DNA-based data storage. (arXiv:2309.06956v1 [eess.IV])

    [http://arxiv.org/abs/2309.06956](http://arxiv.org/abs/2309.06956)

    本论文提出了一种基于DNA的数据存储方法，采用隐式神经多描述技术编码数据。通过创新的压缩方案和神经网络，有效地解决了DNA存储中的错误问题，并在性能上超过了传统的MDC方法。

    

    DNA由于其卓越的存储密度和长期稳定性，基于其固有的生物分子结构，展示出作为数据存储解决方案的巨大潜力。然而，开发这种新型介质面临着一系列挑战，特别是处理存储和生物操作引起的错误。这些挑战进一步受限于DNA序列的结构约束和成本考虑。为了应对这些限制，我们首创了一种新型的压缩方案和一种利用神经网络进行DNA数据存储的尖端多描述编码（MDC）技术。我们的MDC方法引入了一种创新的将数据编码成DNA的方法，特别设计来有效地抵抗错误。值得注意的是，我们的新压缩方案在DNA数据存储方面超过了经典图像压缩方法。此外，我们的方法表现出优于依赖自动编码器的传统MDC方法的特点。

    DNA exhibits remarkable potential as a data storage solution due to its impressive storage density and long-term stability, stemming from its inherent biomolecular structure. However, developing this novel medium comes with its own set of challenges, particularly in addressing errors arising from storage and biological manipulations. These challenges are further conditioned by the structural constraints of DNA sequences and cost considerations. In response to these limitations, we have pioneered a novel compression scheme and a cutting-edge Multiple Description Coding (MDC) technique utilizing neural networks for DNA data storage. Our MDC method introduces an innovative approach to encoding data into DNA, specifically designed to withstand errors effectively. Notably, our new compression scheme overperforms classic image compression methods for DNA-data storage. Furthermore, our approach exhibits superiority over conventional MDC methods reliant on auto-encoders. Its distinctive streng
    
[^20]: DEFormer: 用于低光图像和暗视觉的DCT驱动增强Transformer

    DEFormer: DCT-driven Enhancement Transformer for Low-light Image and Dark Vision. (arXiv:2309.06941v1 [cs.CV])

    [http://arxiv.org/abs/2309.06941](http://arxiv.org/abs/2309.06941)

    该论文提出了一种新的DCT驱动增强Transformer（DEFormer），可以在低光图像中恢复丢失的细节，通过引入频率作为新的线索，通过可学习的频率分支（LFB）和基于曲率的频率增强（CFE）来实现。此外，还提出了交叉域融合（CDF）来减少领域之间的差异，DEFormer还可以作为暗部检测的预处理，有效提高了性能。

    

    低光图像增强的目标是恢复图像的颜色和细节，对于自动驾驶中的高级视觉任务非常重要。然而，仅依靠RGB领域很难恢复暗区域的丢失细节。本文将频率作为网络的新线索，并提出了一种新颖的DCT驱动增强Transformer（DEFormer）。首先，我们提出了一个可学习的频率分支（LFB）用于频率增强，包括DCT处理和基于曲率的频率增强（CFE）。CFE计算每个通道的曲率以表示不同频率带的细节丰富度，然后我们将频率特征划分为更丰富纹理的频率带。此外，我们提出了一个交叉域融合（CDF）来减少RGB领域和频率领域之间的差异。我们还将DEFormer作为暗部检测的预处理，DEFormer有效提高了性能。

    The goal of low-light image enhancement is to restore the color and details of the image and is of great significance for high-level visual tasks in autonomous driving. However, it is difficult to restore the lost details in the dark area by relying only on the RGB domain. In this paper we introduce frequency as a new clue into the network and propose a novel DCT-driven enhancement transformer (DEFormer). First, we propose a learnable frequency branch (LFB) for frequency enhancement contains DCT processing and curvature-based frequency enhancement (CFE). CFE calculates the curvature of each channel to represent the detail richness of different frequency bands, then we divides the frequency features, which focuses on frequency bands with richer textures. In addition, we propose a cross domain fusion (CDF) for reducing the differences between the RGB domain and the frequency domain. We also adopt DEFormer as a preprocessing in dark detection, DEFormer effectively improves the performance
    
[^21]: 无集合的人工智能

    Collectionless Artificial Intelligence. (arXiv:2309.06938v1 [cs.AI])

    [http://arxiv.org/abs/2309.06938](http://arxiv.org/abs/2309.06938)

    本文提出了无集合原则的学习协议的思路，其中机器在环境交互背景中掌握认知技能，避免了数据集集中化的风险。

    

    大体上，处理庞大数据集被认为是机器学习进展和相关领域中壮观结果的基本组成部分，对于这种数据集的集中化存在着越来越多的风险意识。本文支持一种新的学习协议思路，其中机器在真正以环境交互为中心的类人认知背景下掌握认知技能。这意味着学习协议需要遵循无集合原则，即在每个时间点，从环境中获取的数据被用于更新当前环境内部表示，并且代理不能对时间流进行记录。基本上，不能存储来自传感器的时间信息，从而促进了无集合原则的发展。

    By and large, the professional handling of huge data collections is regarded as a fundamental ingredient of the progress of machine learning and of its spectacular results in related disciplines, with a growing agreement on risks connected to the centralization of such data collections. This paper sustains the position that the time has come for thinking of new learning protocols where machines conquer cognitive skills in a truly human-like context centered on environmental interactions. This comes with specific restrictions on the learning protocol according to the collectionless principle, which states that, at each time instant, data acquired from the environment is processed with the purpose of contributing to update the current internal representation of the environment, and that the agent is not given the privilege of recording the temporal stream. Basically, there is neither permission to store the temporal information coming from the sensors, thus promoting the development of s
    
[^22]: 使用狄利克雷生成基础的回顾的连续学习

    Continual Learning with Dirichlet Generative-based Rehearsal. (arXiv:2309.06917v1 [cs.CL])

    [http://arxiv.org/abs/2309.06917](http://arxiv.org/abs/2309.06917)

    该论文提出了一种新颖的基于狄利克雷生成的回顾策略，用于解决连续学习中伪样本生成的挑战。

    

    最近在面向任务的数据驱动对话系统（ToDs）方面的进展由于计算约束和耗时问题而困扰着增量学习。连续学习（CL）试图通过避免密集的预训练来解决这个问题，但它面临着灾难性遗忘（CF）的问题。虽然基于生成的回顾CL方法取得了显著进展，但生成能准确反映底层任务特定分布的伪样本仍然是一个挑战。在本文中，我们提出了狄利克雷连续学习（DCL），这是一种新颖的基于生成的回顾策略用于CL。与传统上在条件变分自动编码器（CVAE）中使用的高斯潜变量不同，DCL利用狄利克雷分布的灵活性和多样性来建模潜变量先验。这使得它能够高效地捕捉先前任务的句级特征，并有效地指导伪样本的生成。此外还引入了Jensen-苏彻利散度作为训练目标，以进一步提高DCL的性能。

    Recent advancements in data-driven task-oriented dialogue systems (ToDs) struggle with incremental learning due to computational constraints and time-consuming issues. Continual Learning (CL) attempts to solve this by avoiding intensive pre-training, but it faces the problem of catastrophic forgetting (CF). While generative-based rehearsal CL methods have made significant strides, generating pseudo samples that accurately reflect the underlying task-specific distribution is still a challenge. In this paper, we present Dirichlet Continual Learning (DCL), a novel generative-based rehearsal strategy for CL. Unlike the traditionally used Gaussian latent variable in the Conditional Variational Autoencoder (CVAE), DCL leverages the flexibility and versatility of the Dirichlet distribution to model the latent prior variable. This enables it to efficiently capture sentence-level features of previous tasks and effectively guide the generation of pseudo samples. In addition, we introduce Jensen-
    
[^23]: 走向TopMost：一个主题建模系统工具包

    Towards the TopMost: A Topic Modeling System Toolkit. (arXiv:2309.06908v1 [cs.CL])

    [http://arxiv.org/abs/2309.06908](http://arxiv.org/abs/2309.06908)

    本文提出了一个名为TopMost的主题建模系统工具包，通过涵盖更广泛的主题建模场景和具有高度凝聚力和解耦模块化设计的特点，可以促进主题模型的研究和应用。

    

    主题模型已经在过去几十年中被提出，并且具有各种应用，在神经变分推断的推动下近期得到了更新。然而，这些主题模型采用完全不同的数据集、实现和评估设置，这阻碍了它们的快速利用和公平比较。这严重阻碍了主题模型的研究进展。为了解决这些问题，本文提出了一个主题建模系统工具包（TopMost）。与现有的工具包相比，TopMost通过涵盖更广泛的主题建模场景，包括数据集预处理、模型训练、测试和评估的完整生命周期，脱颖而出。TopMost的高度凝聚力和解耦模块化设计可以快速利用，公平比较，并灵活扩展不同的主题模型，这可以促进主题模型的研究和应用。我们的代码、教程和文档可在https://github.com/bobxwu/topmost 上获得。

    Topic models have been proposed for decades with various applications and recently refreshed by the neural variational inference. However, these topic models adopt totally distinct dataset, implementation, and evaluation settings, which hinders their quick utilization and fair comparisons. This greatly hinders the research progress of topic models. To address these issues, in this paper we propose a Topic Modeling System Toolkit (TopMost). Compared to existing toolkits, TopMost stands out by covering a wider range of topic modeling scenarios including complete lifecycles with dataset pre-processing, model training, testing, and evaluations. The highly cohesive and decoupled modular design of TopMost enables quick utilization, fair comparisons, and flexible extensions of different topic models. This can facilitate the research and applications of topic models. Our code, tutorials, and documentation are available at https://github.com/bobxwu/topmost.
    
[^24]: 2023年仍可使用的OWL推理器

    OWL Reasoners still useable in 2023. (arXiv:2309.06888v1 [cs.AI])

    [http://arxiv.org/abs/2309.06888](http://arxiv.org/abs/2309.06888)

    该研究系统综述了100多个OWL推理器/系统，并分析了它们在2023年是否仍可用。研究结果提供了一个包含95个独立OWL推理器和使用OWL推理器的系统的全面列表。

    

    在一项系统文献和软件综述中，分析了超过100个OWL推理器/系统，以确定它们是否在2023年仍然可用。这在这个范围内是首次完成的。OWL推理器在知识组织和管理中仍发挥着重要作用，但最近的综合调查/研究已有超过8年的时间。该研究的结果是一个包含95个独立的OWL推理器和使用OWL推理器的系统的全面列表。针对每个项目，收集了项目页面、源代码库和相关文档的信息。原始研究数据在Github仓库中提供，供任何人使用。

    In a systematic literature and software review over 100 OWL reasoners/systems were analyzed to see if they would still be usable in 2023. This has never been done in this capacity. OWL reasoners still play an important role in knowledge organisation and management, but the last comprehensive surveys/studies are more than 8 years old. The result of this work is a comprehensive list of 95 standalone OWL reasoners and systems using an OWL reasoner. For each item, information on project pages, source code repositories and related documentation was gathered. The raw research data is provided in a Github repository for anyone to use.
    
[^25]: Gpachov在CheckThat！2023中：一种多样的多方法集成用于新闻文章主观性检测

    Gpachov at CheckThat! 2023: A Diverse Multi-Approach Ensemble for Subjectivity Detection in News Articles. (arXiv:2309.06844v1 [cs.CL])

    [http://arxiv.org/abs/2309.06844](http://arxiv.org/abs/2309.06844)

    Gpachov团队在CLEF-2023 CheckThat！实验室任务2中构建了一种多样的多方法集成解决方案，通过微调句子嵌入编码模型、样本高效的少样本学习模型和多语言转换器等方法结合得到了0.77的宏F1分数，并在英语子任务中获得第二名。

    

    社交网络的广泛使用导致了互联网上的主观、误导甚至虚假信息的出现。因此，主观性检测在确保信息客观性和质量方面扮演着重要角色。本文介绍了Gpachov团队针对CLEF-2023 CheckThat！实验室任务2的主观性检测构建的解决方案。文章探索了三个不同的研究方向。第一个方向基于微调句子嵌入编码模型和降维。第二个方向探索了一种样本高效的少样本学习模型。第三个方向评估了在经过修改的数据集上微调多语言转换器，使用了多种语言的数据。最后，将这三种方法以简单的多数投票集成，结果在测试集上达到了0.77的宏F1，并在英语子任务上取得了第二名。

    The wide-spread use of social networks has given rise to subjective, misleading, and even false information on the Internet. Thus, subjectivity detection can play an important role in ensuring the objectiveness and the quality of a piece of information. This paper presents the solution built by the Gpachov team for the CLEF-2023 CheckThat! lab Task~2 on subjectivity detection. Three different research directions are explored. The first one is based on fine-tuning a sentence embeddings encoder model and dimensionality reduction. The second one explores a sample-efficient few-shot learning model. The third one evaluates fine-tuning a multilingual transformer on an altered dataset, using data from multiple languages. Finally, the three approaches are combined in a simple majority voting ensemble, resulting in 0.77 macro F1 on the test set and achieving 2nd place on the English subtask.
    
[^26]: 关于T-S模糊系统在原点附近的局部二次稳定性的研究

    On the Local Quadratic Stability of T-S Fuzzy Systems in the Vicinity of the Origin. (arXiv:2309.06841v1 [eess.SY])

    [http://arxiv.org/abs/2309.06841](http://arxiv.org/abs/2309.06841)

    本文介绍了一种新的局部稳定性条件，该条件基于线性矩阵不等式和二次Lyapunov函数，并结合了原点附近的非线性系统的线性结构，相比于现有方法更为准确和有效。同时，本文还提出了局部指数稳定性的必要和充分条件，并讨论了模糊Lyapunov方法的局限性。

    

    本文的主要目标是引入新的局部稳定性条件，用于连续时间的Takagi-Sugeno（T-S）模糊系统。这些稳定性条件基于线性矩阵不等式（LMIs）和二次Lyapunov函数。此外，它们结合了原点处的隶属函数信息，并有效利用了原点附近的非线性系统的线性结构。因此，与文献中使用模糊Lyapunov函数的现有方法相比，提出的条件证明了更少的保守性。此外，我们证明了提出的方法提供了T-S模糊系统局部指数稳定性的必要和充分条件。本文还讨论了模糊Lyapunov方法的固有限制。为了演示理论结果，我们提供了详细的示例，阐明了核心概念，并验证了所提方法的有效性。

    The main goal of this paper is to introduce new local stability conditions for continuous-time Takagi-Sugeno (T-S) fuzzy systems. These stability conditions are based on linear matrix inequalities (LMIs) in combination with quadratic Lyapunov functions. Moreover, they integrate information on the membership functions at the origin and effectively leverage the linear structure of the underlying nonlinear system in the vicinity of the origin. As a result, the proposed conditions are proved to be less conservative compared to existing methods using fuzzy Lyapunov functions in the literature. Moreover, we establish that the proposed methods offer necessary and sufficient conditions for the local exponential stability of T-S fuzzy systems. The paper also includes discussions on the inherent limitations associated with fuzzy Lyapunov approaches. To demonstrate the theoretical results, we provide comprehensive examples that elucidate the core concepts and validate the efficacy of the proposed
    
[^27]: SAMUS：为临床友好和泛化性超声图像分割调整的任意分割模型

    SAMUS: Adapting Segment Anything Model for Clinically-Friendly and Generalizable Ultrasound Image Segmentation. (arXiv:2309.06824v1 [cs.CV])

    [http://arxiv.org/abs/2309.06824](http://arxiv.org/abs/2309.06824)

    本文提出了SAMUS，一个专为超声图像分割量身定制的通用模型，通过引入并行CNN分支和适配器来改善SAM在医学图像分割中的性能和泛化能力。

    

    任意分割模型（SAM）是一种卓越的通用图像分割模型，在医学图像分割领域引起了相当大的关注。尽管SAM在自然图像上表现出色，但在处理医学图像时，特别是涉及低对比度、模糊边界、复杂形状和小尺寸对象的图像时，SAM面临着显著的性能下降和有限的泛化能力。本文提出SAMUS，这是一个专为超声图像分割量身定制的通用模型。与以前基于SAM的通用模型不同，SAMUS追求的不仅是更好的泛化能力，还有更低的部署成本，使其更适合临床应用。具体而言，在SAM的基础上，引入了一个并行CNN分支，通过跨分支注意力将局部特征注入ViT编码器，从而实现更好的医学图像分割。然后，开发了一个位置适配器和一个特征适配器来调整SAM的输

    Segment anything model (SAM), an eminent universal image segmentation model, has recently gathered considerable attention within the domain of medical image segmentation. Despite the remarkable performance of SAM on natural images, it grapples with significant performance degradation and limited generalization when confronted with medical images, particularly with those involving objects of low contrast, faint boundaries, intricate shapes, and diminutive sizes. In this paper, we propose SAMUS, a universal model tailored for ultrasound image segmentation. In contrast to previous SAM-based universal models, SAMUS pursues not only better generalization but also lower deployment cost, rendering it more suitable for clinical applications. Specifically, based on SAM, a parallel CNN branch is introduced to inject local features into the ViT encoder through cross-branch attention for better medical image segmentation. Then, a position adapter and a feature adapter are developed to adapt SAM fr
    
[^28]: 基于深度学习模型的上下文关系提取的比较分析

    Comparative Analysis of Contextual Relation Extraction based on Deep Learning Models. (arXiv:2309.06814v1 [cs.CL])

    [http://arxiv.org/abs/2309.06814](http://arxiv.org/abs/2309.06814)

    本文比较分析了基于深度学习模型的上下文关系提取方法。现有技术无法高效预测由多于两个关系和未指定实体组成的句子中的复杂关系。研究采用深度学习技术从多个句子的语境中识别语义关系。现有机器学习模型在二元关系中表现较好，但随着关系数量的增加，预测准确率降低。

    

    上下文关系提取主要用于借助本体构建知识图谱，在语义搜索、查询回答和文本蕴涵等方面起到重要作用。关系提取识别原始文本中的实体及其之间的关系。在生物医药行业中，高效准确的上下文关系提取系统对于创建领域知识至关重要。现有的机器学习和自然语言处理技术无法高效地从由多于两个关系和未指定实体组成的句子中预测复杂关系。本研究使用深度学习技术，从多个句子的语境中识别出适当的语义关系。尽管关系提取中使用了各种机器学习模型，但它们只对二元关系（即在句子中完全发生在两个实体之间的关系）提供更好的结果。机器学习模型的预测准确率会随着关系的数量增加而降低。

    Contextual Relation Extraction (CRE) is mainly used for constructing a knowledge graph with a help of ontology. It performs various tasks such as semantic search, query answering, and textual entailment. Relation extraction identifies the entities from raw texts and the relations among them. An efficient and accurate CRE system is essential for creating domain knowledge in the biomedical industry. Existing Machine Learning and Natural Language Processing (NLP) techniques are not suitable to predict complex relations from sentences that consist of more than two relations and unspecified entities efficiently. In this work, deep learning techniques have been used to identify the appropriate semantic relation based on the context from multiple sentences. Even though various machine learning models have been used for relation extraction, they provide better results only for binary relations, i.e., relations occurred exactly between the two entities in a sentence. Machine learning models are
    
[^29]: 利用SE(3)等变性学习3D几何形状组装

    Leveraging SE(3) Equivariance for Learning 3D Geometric Shape Assembly. (arXiv:2309.06810v1 [cs.CV])

    [http://arxiv.org/abs/2309.06810](http://arxiv.org/abs/2309.06810)

    该论文提出了利用SE(3)等变性来进行3D几何形状组装，并考虑了多部件关联的表示，进一步提升了组装效果。

    

    形状组装旨在将部件（或碎片）重新组装成完整的物体，这是我们日常生活中的常见任务。与语义部件组装（例如，将椅子的语义部件如腿组装成整个椅子）不同，几何部件组装（例如，将碗碎片组装成完整的碗）是计算机视觉和机器人技术中的一项新兴任务。这个任务不关注部件的语义信息，而是关注部件的几何信息。由于断裂部件的几何和姿态空间都异常庞大，对部件表示进行形状姿态解缠是有益的。在这篇论文中，我们提出利用SE（3）等变性来进行形状姿态解缠。此外，以往的视觉和机器人工作只考虑单个对象的SE（3）等变性表示，而我们更进一步提出利用SE（3）等变性来考虑多部件关联的表示，从而进一步提升了...

    Shape assembly aims to reassemble parts (or fragments) into a complete object, which is a common task in our daily life. Different from the semantic part assembly (e.g., assembling a chair's semantic parts like legs into a whole chair), geometric part assembly (e.g., assembling bowl fragments into a complete bowl) is an emerging task in computer vision and robotics. Instead of semantic information, this task focuses on geometric information of parts. As the both geometric and pose space of fractured parts are exceptionally large, shape pose disentanglement of part representations is beneficial to geometric shape assembly. In our paper, we propose to leverage SE(3) equivariance for such shape pose disentanglement. Moreover, while previous works in vision and robotics only consider SE(3) equivariance for the representations of single objects, we move a step forward and propose leveraging SE(3) equivariance for representations considering multi-part correlations, which further boosts the 
    
[^30]: 贝叶斯不确定性加权损失用于改进息识别任务的泛化能力

    Bayesian uncertainty-weighted loss for improved generalisability on polyp segmentation task. (arXiv:2309.06807v1 [cs.CV])

    [http://arxiv.org/abs/2309.06807](http://arxiv.org/abs/2309.06807)

    本研究采用贝叶斯不确定性加权损失来改善多中心息分割任务的泛化能力，避免因外观、仪器级别和采集质量的变异导致的不公平模型，并展示了该方法在挑战性的多中心数据集上具有潜在的改进能力。

    

    尽管先前的研究已经提出了一些息识别的方法，但大多数这些方法没有在多中心的数据集上进行严格评估。由于不同中心息的外观变异、内窥镜仪器等级的差异和采集质量的不同，导致这些方法在内部测试数据上表现良好，而在外部测试或代表性样本上表现不佳。不公平的模型对临床应用具有严重的影响，并且对临床应用构成了重大挑战。我们采用一种隐式偏差减轻方法，利用贝叶斯认识不确定性，在训练过程中鼓励模型专注于代表性样本区域。我们在具有不同中心和图像模式的具有挑战性的多中心息分割数据集（PolypGen）上展示了这种方法改善泛化能力的潜力，而不会牺牲最先进的性能。

    While several previous studies have devised methods for segmentation of polyps, most of these methods are not rigorously assessed on multi-center datasets. Variability due to appearance of polyps from one center to another, difference in endoscopic instrument grades, and acquisition quality result in methods with good performance on in-distribution test data, and poor performance on out-of-distribution or underrepresented samples. Unfair models have serious implications and pose a critical challenge to clinical applications. We adapt an implicit bias mitigation method which leverages Bayesian epistemic uncertainties during training to encourage the model to focus on underrepresented sample regions. We demonstrate the potential of this approach to improve generalisability without sacrificing state-of-the-art performance on a challenging multi-center polyp segmentation dataset (PolypGen) with different centers and image modalities.
    
[^31]: FedDIP: 采用极端动态修剪和增量正则化的联邦学习

    FedDIP: Federated Learning with Extreme Dynamic Pruning and Incremental Regularization. (arXiv:2309.06805v1 [cs.LG])

    [http://arxiv.org/abs/2309.06805](http://arxiv.org/abs/2309.06805)

    FedDIP是一个结合了动态模型修剪和增量正则化的联邦学习框架，通过消除冗余信息交换和实现极端稀疏模型来显著提高性能。

    

    联邦学习（FL）已成功应用于大规模深度神经网络（DNN）的分布式训练和推理。然而，DNN具有极大的参数数量，因此在分布式节点之间交换这些参数和管理内存方面面临着重大挑战。尽管最近的DNN压缩方法（例如稀疏化、修剪）解决了这些挑战，但它们并未全面考虑在保持高精度水平的同时自适应地控制参数交换的减少。因此，我们提出了一种新颖的FL框架（称为FedDIP），它结合了（i）动态模型修剪和误差反馈来消除冗余信息交换，从而显著提高性能，以及（ii）增量正则化，可以实现“极端”稀疏模型。我们提供了FedDIP的收敛性分析，并对其进行了全面的性能和比较评估。

    Federated Learning (FL) has been successfully adopted for distributed training and inference of large-scale Deep Neural Networks (DNNs). However, DNNs are characterized by an extremely large number of parameters, thus, yielding significant challenges in exchanging these parameters among distributed nodes and managing the memory. Although recent DNN compression methods (e.g., sparsification, pruning) tackle such challenges, they do not holistically consider an adaptively controlled reduction of parameter exchange while maintaining high accuracy levels. We, therefore, contribute with a novel FL framework (coined FedDIP), which combines (i) dynamic model pruning with error feedback to eliminate redundant information exchange, which contributes to significant performance improvement, with (ii) incremental regularization that can achieve \textit{extreme} sparsity of models. We provide convergence analysis of FedDIP and report on a comprehensive performance and comparative assessment against
    
[^32]: 签名网络中的防御联盟

    Defensive Alliances in Signed Networks. (arXiv:2309.06801v1 [cs.CC])

    [http://arxiv.org/abs/2309.06801](http://arxiv.org/abs/2309.06801)

    这项研究探讨了在签名网络中的防御联盟问题，提出了一种量化的群体结构，并通过考虑智能体之间的喜好和厌恶关系，在联盟形成中引入了新的因素。

    

    社交网络和多智能体系统的分析是人工智能中的一个核心主题。某些研究方向涉及寻找能够共同合作实现特定目标的智能体群体。为此，文献中引入了不同概念的图与网络中的集群或社区。其中，防御联盟是一种量化的群体结构。然而，迄今为止，关于联盟的所有研究都忽视了一个在形成联盟中非常直观的方面，即假设智能体在态度方面对其他智能体有预设，他们喜欢和他们喜欢的智能体一起在某个群体（联盟）中，因此愿意相互帮助实现共同的目标，可能会对不喜欢的群体外的智能体进行对抗。签名网络在心理学文献中被引入以模拟智能体之间的喜欢和厌恶关系，这扩展了现有研究的范围。

    The analysis of (social) networks and multi-agent systems is a central theme in Artificial Intelligence. Some line of research deals with finding groups of agents that could work together to achieve a certain goal. To this end, different notions of so-called clusters or communities have been introduced in the literature of graphs and networks. Among these, defensive alliance is a kind of quantitative group structure. However, all studies on the alliance so for have ignored one aspect that is central to the formation of alliances on a very intuitive level, assuming that the agents are preconditioned concerning their attitude towards other agents: they prefer to be in some group (alliance) together with the agents they like, so that they are happy to help each other towards their common aim, possibly then working against the agents outside of their group that they dislike. Signed networks were introduced in the psychology literature to model liking and disliking between agents, generaliz
    
[^33]: 缺失数据下的不确定性交通预测

    Uncertainty-aware Traffic Prediction under Missing Data. (arXiv:2309.06800v1 [cs.LG])

    [http://arxiv.org/abs/2309.06800](http://arxiv.org/abs/2309.06800)

    本研究提出了一种考虑不确定性的交通预测方法，可以处理缺失数据和测量不确定性，并适用于风险敏感任务和决策导向问题。

    

    交通预测是一个重要的课题，因为它在交通领域有广泛的应用。近期，许多研究取得了很好的结果。然而，大多数研究假设预测位置有完整或至少部分的历史记录，不能扩展到无历史记录的位置。在现实场景中，由于预算限制和安装可行性问题，传感器的部署可能受限，这使得大多数当前模型不适用。虽然少数文献尝试在缺失位置上插补交通状态，但这些方法需要与传感器位置同时观测的数据，使它们不适用于预测任务。另一个缺点是缺乏对预测不确定性的测量，使得之前的工作不适用于风险敏感的任务或涉及决策的情况。为了填补这一空白，受到先前的归纳图神经网络的启发，本文提出了一种考虑不确定性的方法。

    Traffic prediction is a crucial topic because of its broad scope of applications in the transportation domain. Recently, various studies have achieved promising results. However, most studies assume the prediction locations have complete or at least partial historical records and cannot be extended to non-historical recorded locations. In real-life scenarios, the deployment of sensors could be limited due to budget limitations and installation availability, which makes most current models not applicable. Though few pieces of literature tried to impute traffic states at the missing locations, these methods need the data simultaneously observed at the locations with sensors, making them not applicable to prediction tasks. Another drawback is the lack of measurement of uncertainty in prediction, making prior works unsuitable for risk-sensitive tasks or involving decision-making. To fill the gap, inspired by the previous inductive graph neural network, this work proposed an uncertainty-awa
    
[^34]: 当地球科学遇见基础模型：走向通用地球科学人工智能系统

    When Geoscience Meets Foundation Models: Towards General Geoscience Artificial Intelligence System. (arXiv:2309.06799v1 [cs.AI])

    [http://arxiv.org/abs/2309.06799](http://arxiv.org/abs/2309.06799)

    地球科学基础模型通过整合大量跨学科数据来模拟和理解地球系统动态，具有广阔的应用前景和创新潜力，但仍面临验证和核实、规模性、可解释性、知识表示和社会偏差等挑战。

    

    地球科学基础模型通过整合大量跨学科数据来模拟和理解地球系统动态，代表了地球科学领域的一种革命性方法。作为一种数据中心的人工智能范式，它们从百万亿字节的结构化和非结构化数据中揭示出洞察力。灵活的任务规范、多样化的输入和输出以及多模态的知识表示使得综合分析成为可能。至关重要的是，地球科学模型的可扩展性和可推广性允许解决与地球系统相互作用相关的多种预测、模拟和决策挑战。领域专家和计算机科学家之间的合作推动了这些宝贵工具在理解我们地球的过去、现在和未来方面的创新。然而，验证和核实、规模性、可解释性、知识表示和社会偏差仍然面临挑战。展望未来，增强验证和核实、规模性、解释性、知识表示和社会偏差方面的能力，将有助于推动地球科学人工智能系统的发展。

    Geoscience foundation models represent a revolutionary approach in the field of Earth sciences by integrating massive cross-disciplinary data to simulate and understand the Earth systems dynamics. As a data-centric artificial intelligence (AI) paradigm, they uncover insights from petabytes of structured and unstructured data. Flexible task specification, diverse inputs and outputs and multi-modal knowledge representation enable comprehensive analysis infeasible with individual data sources. Critically, the scalability and generalizability of geoscience models allow for tackling diverse prediction, simulation, and decision challenges related to Earth systems interactions. Collaboration between domain experts and computer scientists leads to innovations in these invaluable tools for understanding the past, present, and future of our planet. However, challenges remain in validation and verification, scale, interpretability, knowledge representation, and social bias. Going forward, enhanci
    
[^35]: 认知幻觉：大规模语言模型中幻觉现象的综述

    Cognitive Mirage: A Review of Hallucinations in Large Language Models. (arXiv:2309.06794v1 [cs.CL])

    [http://arxiv.org/abs/2309.06794](http://arxiv.org/abs/2309.06794)

    这篇论文综述了大规模语言模型中幻觉的现象，并提出了幻觉的分类、理论分析、检测方法和改进方法，同时还设想了未来的研究方向。

    

    随着人工智能领域中大规模语言模型的发展，文本生成系统容易受到一种令人担忧的现象，即幻觉。在本研究中，我们总结了最近关于大规模语言模型中幻觉的引人注目的见解。我们提出了一种针对各种文本生成任务的幻觉的新分类体系，从而提供了理论性的洞见、检测方法和改进方法。基于此，我们提出了未来的研究方向。我们的贡献有三个方面：（1）我们为出现在文本生成任务中的幻觉提供了详细和完整的分类体系；（2）我们对大规模语言模型中的幻觉进行了理论分析，并提供了现有的检测和改进方法；（3）我们提出了几个未来可以发展的研究方向。由于幻觉受到了学术界的广泛关注，我们将维护与相关研究进展的更新。

    As large language models continue to develop in the field of AI, text generation systems are susceptible to a worrisome phenomenon known as hallucination. In this study, we summarize recent compelling insights into hallucinations in LLMs. We present a novel taxonomy of hallucinations from various text generation tasks, thus provide theoretical insights, detection methods and improvement approaches. Based on this, future research directions are proposed. Our contribution are threefold: (1) We provide a detailed and complete taxonomy for hallucinations appearing in text generation tasks; (2) We provide theoretical analyses of hallucinations in LLMs and provide existing detection and improvement methods; (3) We propose several research directions that can be developed in the future. As hallucinations garner significant attention from the community, we will maintain updates on relevant research progress.
    
[^36]: 基于Hinge Loss训练的深度学习二分类器的基本限制

    Fundamental Limits of Deep Learning-Based Binary Classifiers Trained with Hinge Loss. (arXiv:2309.06774v1 [cs.LG])

    [http://arxiv.org/abs/2309.06774](http://arxiv.org/abs/2309.06774)

    本文揭示了基于Hinge Loss训练的深度学习二分类器的基本测试性能限制。

    

    深度学习在化学、计算机科学、电子工程、数学、医学、神经科学和物理学等多个领域取得了重大突破，但对于为什么和如何获得经验成功的全面理解仍然基本难以把握。为了解决这一根本问题并揭示深度学习背后的奥秘，已经在建立统一理论的方向上取得了重大创新。这些创新包括优化、泛化和近似等基础性进展。然而，迄今为止还没有一个工作提供了一种方法来量化深度学习算法在解决模式分类问题时的测试性能。为了在一定程度上克服这个基本挑战，本文揭示了基于Hinge Loss训练的深度学习二分类器的基本测试性能限制。

    Although deep learning (DL) has led to several breakthroughs in many disciplines as diverse as chemistry, computer science, electrical engineering, mathematics, medicine, neuroscience, and physics, a comprehensive understanding of why and how DL is empirically successful remains fundamentally elusive. To attack this fundamental problem and unravel the mysteries behind DL's empirical successes, significant innovations toward a unified theory of DL have been made. These innovations encompass nearly fundamental advances in optimization, generalization, and approximation. Despite these advances, however, no work to date has offered a way to quantify the testing performance of a DL-based algorithm employed to solve a pattern classification problem. To overcome this fundamental challenge in part, this paper exposes the fundamental testing performance limits of DL-based binary classifiers trained with hinge loss. For binary classifiers that are based on deep rectified linear unit (ReLU) feedf
    
[^37]: 通过拆分和重排BART微调来增强关键短语生成

    Enhancing Keyphrase Generation by BART Finetuning with Splitting and Shuffling. (arXiv:2309.06726v1 [cs.CL])

    [http://arxiv.org/abs/2309.06726](http://arxiv.org/abs/2309.06726)

    本文提出了关注关键短语的BART模型(Keyphrase-Focused BART)，通过拆分和重排的方式来增强关键短语生成的性能。在不出现的关键短语生成任务中，该模型在两个关键短语生成基准数据集上取得了新的最佳得分。

    

    关键短语生成是一项识别最佳代表给定文本主题或主题的短语集的任务。关键短语分为出现和不在出现的关键短语。最近利用序列到序列模型的方法在不出现的关键短语生成上显示出了效果。然而，由于找到不出现的关键短语的难度，性能仍然有限。在本文中，我们提出了关注关键短语的BART模型(Keyphrase-Focused BART)，利用了出现和不出现关键短语生成之间的差异，并对出现和不出现关键短语分别进行了两个独立BART模型的微调。我们进一步展示了关键短语的重排和候选关键短语排序的有效方法。对于不出现的关键短语，在五个关键短语生成基准数据集中，我们的关注关键短语的BART在F1@5上取得了新的最佳得分。

    Keyphrase generation is a task of identifying a set of phrases that best repre-sent the main topics or themes of a given text. Keyphrases are dividend int pre-sent and absent keyphrases. Recent approaches utilizing sequence-to-sequence models show effectiveness on absent keyphrase generation. However, the per-formance is still limited due to the hardness of finding absent keyphrases. In this paper, we propose Keyphrase-Focused BART, which exploits the differ-ences between present and absent keyphrase generations, and performs fine-tuning of two separate BART models for present and absent keyphrases. We further show effective approaches of shuffling keyphrases and candidate keyphrase ranking. For absent keyphrases, our Keyphrase-Focused BART achieved new state-of-the-art score on F1@5 in two out of five keyphrase gen-eration benchmark datasets.
    
[^38]: 动态频谱混合器用于视觉识别

    Dynamic Spectrum Mixer for Visual Recognition. (arXiv:2309.06721v1 [cs.CV])

    [http://arxiv.org/abs/2309.06721](http://arxiv.org/abs/2309.06721)

    动态频谱混合器（DSM）是一种内容自适应且计算效率高的结构，通过离散余弦变换表示令牌之间的交互，能够学习长期的空间依赖性。它还引入了动态频谱权重生成层作为频谱带选择器，以强调信息的重要程度。

    

    最近，基于多层感知器（MLP）的视觉主干在几个视觉识别任务中取得了令人期待的性能。然而，现有的基于MLP的方法直接使用静态权重聚合令其无法适应不同的图像。此外，最近的研究表明，MLP-Transformer在创建远程依赖性方面表现出色，但在捕捉主要传输局部信息的高频率方面表现不佳，这使其无法应用于下游的稠密预测任务，如语义分割。为了解决这些挑战，我们提出了一种内容自适应且计算效率高的结构，称为动态频谱混合器（DSM）。DSM通过应用离散余弦变换在频域中表示令牌之间的交互，可以以对数线性复杂度学习长期的空间依赖性。此外，我们还提出了一种动态频谱权重生成层作为频谱带选择器，能够强调信息的重要程度。

    Recently, MLP-based vision backbones have achieved promising performance in several visual recognition tasks. However, the existing MLP-based methods directly aggregate tokens with static weights, leaving the adaptability to different images untouched. Moreover, Recent research demonstrates that MLP-Transformer is great at creating long-range dependencies but ineffective at catching high frequencies that primarily transmit local information, which prevents it from applying to the downstream dense prediction tasks, such as semantic segmentation. To address these challenges, we propose a content-adaptive yet computationally efficient structure, dubbed Dynamic Spectrum Mixer (DSM). The DSM represents token interactions in the frequency domain by employing the Discrete Cosine Transform, which can learn long-term spatial dependencies with log-linear complexity. Furthermore, a dynamic spectrum weight generation layer is proposed as the spectrum bands selector, which could emphasize the infor
    
[^39]: TrafficGPT：查看、处理和与交通基础模型交互

    TrafficGPT: Viewing, Processing and Interacting with Traffic Foundation Models. (arXiv:2309.06719v1 [cs.AI])

    [http://arxiv.org/abs/2309.06719](http://arxiv.org/abs/2309.06719)

    TrafficGPT是ChatGPT和交通基础模型的融合，通过提供查看、分析和交互能力，增强了语言模型在解决复杂交通问题和提供有见地建议方面的能力。

    

    随着ChatGPT向公众推广，大型语言模型展示出了令人称奇的常识、推理和规划能力，经常提供有见地的指导。这些能力为它们在城市交通管理和控制中的应用带来了巨大的希望。然而，语言模型在处理交通问题，尤其是处理数值数据和与模拟交互方面面临困难，限制了它们在解决交通相关挑战方面的潜力。与此同时，专门的交通基础模型存在，但通常只用于特定任务，输入输出交互有限。将这些模型与语言模型相结合，可以增强它们处理复杂的交通相关问题和提供有见地建议的能力。为了弥合这一差距，我们提出了TrafficGPT，它是ChatGPT和交通基础模型的融合。这种整合产生了以下关键增强：1）赋予ChatGPT查看、分析、处理数字数据和与交通模拟交互的能力。

    With the promotion of chatgpt to the public, Large language models indeed showcase remarkable common sense, reasoning, and planning skills, frequently providing insightful guidance. These capabilities hold significant promise for their application in urban traffic management and control. However, LLMs struggle with addressing traffic issues, especially processing numerical data and interacting with simulations, limiting their potential in solving traffic-related challenges. In parallel, specialized traffic foundation models exist but are typically designed for specific tasks with limited input-output interactions. Combining these models with LLMs presents an opportunity to enhance their capacity for tackling complex traffic-related problems and providing insightful suggestions. To bridge this gap, we present TrafficGPT, a fusion of ChatGPT and traffic foundation models. This integration yields the following key enhancements: 1) empowering ChatGPT with the capacity to view, analyze, pro
    
[^40]: 解决异构联邦学习中非独立同分布问题的梯度协调方法

    Tackling the Non-IID Issue in Heterogeneous Federated Learning by Gradient Harmonization. (arXiv:2309.06692v1 [cs.LG])

    [http://arxiv.org/abs/2309.06692](http://arxiv.org/abs/2309.06692)

    本研究通过梯度协调方法解决了异构联邦学习中的非独立同分布问题，提出了FedGH，通过减轻本地漂移来增强性能。实验证明，在多个基准和非独立同分布场景下，FedGH始终能够显著提升联邦学习的性能。

    

    联邦学习是一种保护隐私的范式，用于从分散的客户端协作训练全局模型。然而，联邦学习的性能受到非独立同分布的数据和设备异构性的影响。在本研究中，我们通过服务器端的梯度冲突视角重新思考这个关键挑战。具体而言，我们首先调查了多个客户端之间的梯度冲突现象，并揭示了更强的异构性会导致更严重的梯度冲突。为了解决这个问题，我们提出了FedGH，一种简单而有效的方法，通过梯度协调来减轻本地漂移。这种技术将一个梯度向量投影到与其他冲突客户端对之间的正交平面上。广泛的实验表明，FedGH在不同基准和非独立同分布场景下始终能够显著提升多个最先进的联邦学习基线。值得注意的是，FedGH在特定场景中取得了更显著的改进。

    Federated learning (FL) is a privacy-preserving paradigm for collaboratively training a global model from decentralized clients. However, the performance of FL is hindered by non-independent and identically distributed (non-IID) data and device heterogeneity. In this work, we revisit this key challenge through the lens of gradient conflicts on the server side. Specifically, we first investigate the gradient conflict phenomenon among multiple clients and reveal that stronger heterogeneity leads to more severe gradient conflicts. To tackle this issue, we propose FedGH, a simple yet effective method that mitigates local drifts through Gradient Harmonization. This technique projects one gradient vector onto the orthogonal plane of the other within conflicting client pairs. Extensive experiments demonstrate that FedGH consistently enhances multiple state-of-the-art FL baselines across diverse benchmarks and non-IID scenarios. Notably, FedGH yields more significant improvements in scenarios 
    
[^41]: 用于机器人深度强化学习的自我改进型大型语言模型作为自动化奖励函数设计师

    Self-Refined Large Language Model as Automated Reward Function Designer for Deep Reinforcement Learning in Robotics. (arXiv:2309.06687v1 [cs.RO])

    [http://arxiv.org/abs/2309.06687](http://arxiv.org/abs/2309.06687)

    提出一种自我改进机制的大型语言模型（LLM）框架用于自动化奖励函数设计，在深度强化学习中展现了潜在的应用价值。

    

    虽然深度强化学习在众多机器人应用中取得了显著的成功，但设计高性能的奖励函数仍然是一项具有挑战性的任务，通常需要大量的人工输入。最近，广泛采用大型语言模型（LLM）来解决需要深入常识知识的任务，如推理和规划。意识到奖励函数设计与这种知识本质上是相关的，LLM在这个背景下提供了很大的潜力。受此启发，我们在这项工作中提出了一种新颖的LLM框架，具有自我改进机制，用于自动化奖励函数设计。该框架以自然语言输入为基础，由LLM制定一个初始的奖励函数。然后，评估奖励函数的性能，并将结果呈现给LLM以指导其自我改进的过程。通过多种连续机器人任务的实验验证了我们提出的框架的性能。

    Although Deep Reinforcement Learning (DRL) has achieved notable success in numerous robotic applications, designing a high-performing reward function remains a challenging task that often requires substantial manual input. Recently, Large Language Models (LLMs) have been extensively adopted to address tasks demanding in-depth common-sense knowledge, such as reasoning and planning. Recognizing that reward function design is also inherently linked to such knowledge, LLM offers a promising potential in this context. Motivated by this, we propose in this work a novel LLM framework with a self-refinement mechanism for automated reward function design. The framework commences with the LLM formulating an initial reward function based on natural language inputs. Then, the performance of the reward function is assessed, and the results are presented back to the LLM for guiding its self-refinement process. We examine the performance of our proposed framework through a variety of continuous robot
    
[^42]: 改进的Attention Loss Adjusted Prioritized Experience Replay算法

    Attention Loss Adjusted Prioritized Experience Replay. (arXiv:2309.06684v1 [cs.LG])

    [http://arxiv.org/abs/2309.06684](http://arxiv.org/abs/2309.06684)

    本文提出了一种改进的Attention Loss Adjusted Prioritized Experience Replay (ALAP)算法，通过结合改进的自注意力网络和双采样机制，调节重要性采样权重，消除了先进的经验回放算法中的估计误差。在OPENAI gym环境中的测试和对比研究验证了该算法的优势和效率。

    

    先进的经验回放算法(Prioritized Experience Replay, PER)通过选择具有更多知识量的经验样本来改善神经网络的训练速度。然而，PER中使用的非均匀采样不可避免地使状态-动作空间分布偏移，并带来Q值函数的估计误差。本文提出了一种Attention Loss Adjusted Prioritized (ALAP) Experience Replay算法，该算法将改进的自注意力网络和双采样机制结合起来，以适应能够调节重要性采样权重的超参数，从而消除因PER引起的估计误差。为了验证该算法的有效性和通用性，我们在OPENAI gym环境中对基于值函数、基于策略梯度和多主体强化学习算法进行了测试，并进行了对比研究，验证了所提出的训练框架的优势和效率。

    Prioritized Experience Replay (PER) is a technical means of deep reinforcement learning by selecting experience samples with more knowledge quantity to improve the training rate of neural network. However, the non-uniform sampling used in PER inevitably shifts the state-action space distribution and brings the estimation error of Q-value function. In this paper, an Attention Loss Adjusted Prioritized (ALAP) Experience Replay algorithm is proposed, which integrates the improved Self-Attention network with Double-Sampling mechanism to fit the hyperparameter that can regulate the importance sampling weights to eliminate the estimation error caused by PER. In order to verify the effectiveness and generality of the algorithm, the ALAP is tested with value-function based, policy-gradient based and multi-agent reinforcement learning algorithms in OPENAI gym, and comparison studies verify the advantage and efficiency of the proposed training framework.
    
[^43]: 基于插拔式合成数据的深度学习方法用于欠采样磁共振图像重建

    A plug-and-play synthetic data deep learning for undersampled magnetic resonance image reconstruction. (arXiv:2309.06681v1 [eess.IV])

    [http://arxiv.org/abs/2309.06681](http://arxiv.org/abs/2309.06681)

    本文提出了一种基于插拔式深度学习方法的欠采样MRI重建方法，可以有效适应不同的采样设置，并在不同的欠采样模式和采样率下提供了良好而稳健的加速图像重建性能。

    

    磁共振成像（MRI）在现代医学诊断中起着重要作用，但扫描时间较长。当前的深度学习方法在图像去混叠方面表现良好，可以根据特定的k空间欠采样场景进行定制化。但是当采样设置发生变化时，配置不同的深度网络非常麻烦。本文提出了一种基于插拔式深度学习方法的欠采样MRI重建方法，可以有效适应不同的采样设置。具体来说，首先通过一个在合成数据上训练的深度去噪网络学习图像去混叠先验知识，然后将学习到的深度去噪网络插入到迭代算法中进行图像重建。通过对体内数据的结果验证，该方法在不同的欠采样模式和采样率下提供了良好而稳健的加速图像重建性能，从视觉和定量指标上均得到了证明。

    Magnetic resonance imaging (MRI) plays an important role in modern medical diagnostic but suffers from prolonged scan time. Current deep learning methods for undersampled MRI reconstruction exhibit good performance in image de-aliasing which can be tailored to the specific kspace undersampling scenario. But it is very troublesome to configure different deep networks when the sampling setting changes. In this work, we propose a deep plug-and-play method for undersampled MRI reconstruction, which effectively adapts to different sampling settings. Specifically, the image de-aliasing prior is first learned by a deep denoiser trained to remove general white Gaussian noise from synthetic data. Then the learned deep denoiser is plugged into an iterative algorithm for image reconstruction. Results on in vivo data demonstrate that the proposed method provides nice and robust accelerated image reconstruction performance under different undersampling patterns and sampling rates, both visually and
    
[^44]: SHARM: 分段头部解剖参考模型

    SHARM: Segmented Head Anatomical Reference Models. (arXiv:2309.06677v1 [cs.CV])

    [http://arxiv.org/abs/2309.06677](http://arxiv.org/abs/2309.06677)

    本研究提出了一种分段头部解剖参考模型（SHARM），用于可靠地分割人头部解剖组织，并针对非脑组织的重要性填补了目前研究中的空白。

    

    可靠地分割人头部解剖组织是脑图绘制、手术计划和相关计算模拟研究等多种临床应用的重要步骤。分割是基于通过对医学成像模式中的不同组织进行标记来识别不同解剖结构。大脑结构的分割在医学视角下已经有了一些显著的贡献；然而，由于解剖复杂性和使用标准医学成像协议观察困难，非脑组织的兴趣较小。缺乏整个头部分割方法和大型人类头部分割数据集的可用性限制了变异性研究，特别是在计算电脑评估电脑的脑刺激（神经调节）、人体对电磁场的保护以及脑电图方面，非脑组织非常重要。为了填补这一空白，本研究提供了一种分段头部解剖参考模型（SHARM）。

    Reliable segmentation of anatomical tissues of human head is a major step in several clinical applications such as brain mapping, surgery planning and associated computational simulation studies. Segmentation is based on identifying different anatomical structures through labeling different tissues through medical imaging modalities. The segmentation of brain structures is commonly feasible with several remarkable contributions mainly for medical perspective; however, non-brain tissues are of less interest due to anatomical complexity and difficulties to be observed using standard medical imaging protocols. The lack of whole head segmentation methods and unavailability of large human head segmented datasets limiting the variability studies, especially in the computational evaluation of electrical brain stimulation (neuromodulation), human protection from electromagnetic field, and electroencephalography where non-brain tissues are of great importance.  To fill this gap, this study prov
    
[^45]: 量子数据中心: 展望

    Quantum Data Center: Perspectives. (arXiv:2309.06641v1 [quant-ph])

    [http://arxiv.org/abs/2309.06641](http://arxiv.org/abs/2309.06641)

    本文提出了量子数据中心(QDC)的概念，它是现有经典数据中心的量子版本，通过结合量子随机访问存储器(QRAM)和量子网络，QDC可以提供客户在效率、安全性和精度方面的显著优势，对于量子计算、通信和传感领域具有重要意义。该研究探讨了硬件实现和特定应用方面的潜在科学和商业机会，并展示了QDC在机器学习和大数据行业等领域的潜在影响。

    

    量子版本的数据中心可能在量子时代具有重要意义。本文介绍了量子数据中心(QDC)，这是现有经典数据中心的量子版本，特别强调了量子随机访问存储器(QRAM)和量子网络的结合。我们认为QDC将为客户提供在效率、安全性和精度方面的显著好处，并对量子计算、通信和传感方面具有帮助。通过硬件实现和可能的特定应用，我们研究了这一新颖研究方向的潜在科学和商业机会。我们展示了QDC在商业和科学领域的潜在影响，尤其是机器学习和大数据行业。

    A quantum version of data centers might be significant in the quantum era. In this paper, we introduce Quantum Data Center (QDC), a quantum version of existing classical data centers, with a specific emphasis on combining Quantum Random Access Memory (QRAM) and quantum networks. We argue that QDC will provide significant benefits to customers in terms of efficiency, security, and precision, and will be helpful for quantum computing, communication, and sensing. We investigate potential scientific and business opportunities along this novel research direction through hardware realization and possible specific applications. We show the possible impacts of QDCs in business and science, especially the machine learning and big data industries.
    
[^46]: 作为有效抽象的归纳偏好的关系瓶颈

    The Relational Bottleneck as an Inductive Bias for Efficient Abstraction. (arXiv:2309.06629v1 [cs.AI])

    [http://arxiv.org/abs/2309.06629](http://arxiv.org/abs/2309.06629)

    本文介绍了一种新的归纳偏好方法——关系瓶颈，用于有效地诱导抽象概念的模型，强调了其在人类思维和大脑中抽象概念习得中的潜力。

    

    认知科学的一个核心挑战是解释如何从有限经验中获取抽象概念。这一努力常常被描述为经验主义和天赋主义方法之间的二分法，最近主要体现在有关深度神经网络和符号认知模型的争论中。在这里，我们强调了一种最近兴起的工作线路，该线路通过利用我们称之为关系瓶颈的归纳偏好，提出了这些方法的一种新的调和方式。我们回顾了一系列采用这种方法在数据有效的方式下诱导出抽象的模型，强调了它们作为人类思维和大脑中抽象概念习得的候选模型的潜力。

    A central challenge for cognitive science is to explain how abstract concepts are acquired from limited experience. This effort has often been framed in terms of a dichotomy between empiricist and nativist approaches, most recently embodied by debates concerning deep neural networks and symbolic cognitive models. Here, we highlight a recently emerging line of work that suggests a novel reconciliation of these approaches, by exploiting an inductive bias that we term the relational bottleneck. We review a family of models that employ this approach to induce abstractions in a data-efficient manner, emphasizing their potential as candidate models for the acquisition of abstract concepts in the human mind and brain.
    
[^47]: 一种基于强化学习的机器人从视觉观察中卸货的方法

    A Reinforcement Learning Approach for Robotic Unloading from Visual Observations. (arXiv:2309.06621v1 [cs.RO])

    [http://arxiv.org/abs/2309.06621](http://arxiv.org/abs/2309.06621)

    本文提出了一种基于强化学习的机器人从视觉观察中卸货的方法，通过使用RGB-D图像作为输入并采用高层决策模块与经典运动控制相结合的层次化控制器结构，实现了无需标注数据的学习过程，并通过实验证明了该方法的改进学习性能。

    

    本文针对机器人从视觉观察中的卸货问题进行研究，其中机器人需要使用RGB-D图像作为主要输入来自主地卸下一堆包裹。尽管监督学习和模仿学习在这类任务中取得了不错的结果，但它们严重依赖于标注数据，而在现实场景中获得这些数据是具有挑战性的。我们的研究旨在开发一个样本高效的控制器框架，该框架可以在学习过程中无需标注数据来学习卸货任务。为了解决这个挑战，我们提出了一个层次化的控制器结构，将高层决策模块与经典运动控制相结合。高层模块使用深度强化学习进行训练，我们在其中融入了安全偏见机制，并设计了一个适合这个任务的奖励函数。我们的实验证明，这两个元素在实现改进的学习性能方面起到了至关重要的作用。

    In this work, we focus on a robotic unloading problem from visual observations, where robots are required to autonomously unload stacks of parcels using RGB-D images as their primary input source. While supervised and imitation learning have accomplished good results in these types of tasks, they heavily rely on labeled data, which are challenging to obtain in realistic scenarios. Our study aims to develop a sample efficient controller framework that can learn unloading tasks without the need for labeled data during the learning process. To tackle this challenge, we propose a hierarchical controller structure that combines a high-level decision-making module with classical motion control. The high-level module is trained using Deep Reinforcement Learning (DRL), wherein we incorporate a safety bias mechanism and design a reward function tailored to this task. Our experiments demonstrate that both these elements play a crucial role in achieving improved learning performance. Furthermore,
    
[^48]: 分布式机器学习资源上的混合算法选择和超参数调整: 一种基于层级代理的方法

    Hybrid Algorithm Selection and Hyperparameter Tuning on Distributed Machine Learning Resources: A Hierarchical Agent-based Approach. (arXiv:2309.06604v1 [cs.LG])

    [http://arxiv.org/abs/2309.06604](http://arxiv.org/abs/2309.06604)

    本文提出了一种基于代理的层级机器学习平台，用于选择分布式组织的机器学习算法并同时调整其超参数。该方法具有可伸缩性、灵活性和鲁棒性，并支持自动化和协同的功能。

    

    算法选择和超参数调整是学术界和应用机器学习中关键的步骤。然而，由于机器学习资源数量的大幅增加、多样性和分布性，这些步骤变得越来越复杂。当将多智能体系统应用于机器学习平台的设计时，会带来可伸缩性、灵活性和鲁棒性等多个独特特性。本文提出了一种完全自动和协同的基于代理的机制，用于选择分布式组织的机器学习算法，并同时调整其超参数。我们的方法基于现有的基于代理的层级机器学习平台，并通过增强其查询结构来支持上述功能，而不限于特定的学习、选择和调整机制。我们进行了理论评估、形式验证和分析。

    Algorithm selection and hyperparameter tuning are critical steps in both academic and applied machine learning. On the other hand, these steps are becoming ever increasingly delicate due to the extensive rise in the number, diversity, and distributedness of machine learning resources. Multi-agent systems, when applied to the design of machine learning platforms, bring about several distinctive characteristics such as scalability, flexibility, and robustness, just to name a few. This paper proposes a fully automatic and collaborative agent-based mechanism for selecting distributedly organized machine learning algorithms and simultaneously tuning their hyperparameters. Our method builds upon an existing agent-based hierarchical machine-learning platform and augments its query structure to support the aforementioned functionalities without being limited to specific learning, selection, and tuning mechanisms. We have conducted theoretical assessments, formal verification, and analytical st
    
[^49]: Rank2Tell: 一个用于联合重要性排序和推理的多模态驾驶数据集

    Rank2Tell: A Multimodal Driving Dataset for Joint Importance Ranking and Reasoning. (arXiv:2309.06597v1 [cs.CV])

    [http://arxiv.org/abs/2309.06597](http://arxiv.org/abs/2309.06597)

    Rank2Tell是一个多模态驾驶数据集，用于联合重要性排序和推理，为研究人员提供了复杂交通情景中各种重要对象的密集注释和独特属性。

    

    商用自动驾驶车辆（AVs）和先进驾驶辅助系统（ADAS）的广泛应用可能在很大程度上取决于社会对它们的接受程度，而对骑车人来说，它们被视为可信和可解释性是至关重要的。一般来说，这个任务是具有挑战性的，因为现代自主系统软件严重依赖于黑盒人工智能模型。为了实现这个目标，本文介绍了一种新的数据集，Rank2Tell，这是一个用于重要性级别排序和原因解释的多模态驾驶数据集。使用各种闭合和开放式视觉问答，该数据集提供了复杂交通情景中各种重要对象的各种语义、空间、时间和关系属性的密集注释。数据集的密集注释和独特属性使其成为从事视觉场景理解和相关领域研究的研究人员的宝贵资源。此外，我们还介绍了一个联合模型，用于联合表示和推理重要性和原因。

    The widespread adoption of commercial autonomous vehicles (AVs) and advanced driver assistance systems (ADAS) may largely depend on their acceptance by society, for which their perceived trustworthiness and interpretability to riders are crucial. In general, this task is challenging because modern autonomous systems software relies heavily on black-box artificial intelligence models. Towards this goal, this paper introduces a novel dataset, Rank2Tell, a multi-modal ego-centric dataset for Ranking the importance level and Telling the reason for the importance. Using various close and open-ended visual question answering, the dataset provides dense annotations of various semantic, spatial, temporal, and relational attributes of various important objects in complex traffic scenarios. The dense annotations and unique attributes of the dataset make it a valuable resource for researchers working on visual scene understanding and related fields. Further, we introduce a joint model for joint i
    
[^50]: 生成大语言模型是否需要数十亿个参数？

    Do Generative Large Language Models need billions of parameters?. (arXiv:2309.06589v1 [cs.CL])

    [http://arxiv.org/abs/2309.06589](http://arxiv.org/abs/2309.06589)

    本文研究了生成大语言模型的规模、性能和计算资源之间的权衡，并提出了新方法来减少参数数量，从而创建更高效、紧凑的模型，为AI语言建模的可持续和可访问的未来做出了贡献。

    

    本文提出了用于开发高效大语言模型(LLMs)的新系统和方法。它探讨了模型大小、性能和计算资源之间的权衡，旨在最大化这些人工智能系统的效率。研究探索了允许模型的不同部分共享参数的新方法，从而减少所需的独立参数总数。这种方法确保了模型既紧凑又不损失学习和表示复杂语言结构的能力。本研究为创建更高效、更有效的LLMs提供了宝贵的见解和工具，为AI语言建模的可持续和可访问的未来做出了贡献。

    This paper presents novel systems and methodologies for the development of efficient large language models (LLMs). It explores the trade-offs between model size, performance, and computational resources, with the aim of maximizing the efficiency of these AI systems. The research explores novel methods that allow different parts of the model to share parameters, reducing the total number of unique parameters required. This approach ensures that the model remains compact without sacrificing its ability to learn and represent complex language structures. This study provides valuable insights and tools for creating more efficient and effective LLMs, contributing to a more sustainable and accessible future for AI language modeling.
    
[^51]: 人类能帮助BERT获得“信心”吗？

    Can humans help BERT gain "confidence"?. (arXiv:2309.06580v1 [cs.CL])

    [http://arxiv.org/abs/2309.06580](http://arxiv.org/abs/2309.06580)

    本论文研究了如何将苏黎世认知语料库的认知特征与BERT模型集成，证明了脑电图和眼动特征可以提高自然语言处理模型的性能，并开发了一个用于基准测试的词-EEG词典。

    

    过去十年中，人工智能的进步为跨学科研究开辟了多种途径。由于人工智能的灵感来自大脑神经元的工作原理，将这两个领域结合起来，并利用认知数据来训练AI模型似乎是非常实际的。这不仅有助于更深入地理解技术，还有助于理解大脑。在本论文中，我进行了新颖的实验，将苏黎世认知语料库（ZuCo）的认知特征与基于变压器的编码器模型BERT集成。我展示了来自ZuCo的脑电图（EEG）和眼动特征如何帮助提高自然语言处理模型的性能。我利用一个鲁棒性检查流水线确认了性能的提升，并生成了一个单词-EEG词典，用于在没有任何认知特征的外部数据集上进行基准测试。此外，我分析了内部工作机制。

    The advancements in artificial intelligence over the last decade have opened a multitude of avenues for interdisciplinary research. Since the idea of artificial intelligence was inspired by the working of neurons in the brain, it seems pretty practical to combine the two fields and take the help of cognitive data to train AI models. Not only it will help to get a deeper understanding of the technology, but of the brain as well. In this thesis, I conduct novel experiments to integrate cognitive features from the Zurich Cognitive Corpus (ZuCo) (Hollenstein et al., 2018) with a transformer-based encoder model called BERT. I show how EEG and eye-tracking features from ZuCo can help to increase the performance of the NLP model. I confirm the performance increase with the help of a robustness-checking pipeline and derive a word-EEG lexicon to use in benchmarking on an external dataset that does not have any cognitive features associated with it. Further, I analyze the internal working mechan
    
[^52]: 大型语言模型能否辨别科学假设的证据？社会科学案例研究。

    Can Large Language Models Discern Evidence for Scientific Hypotheses? Case Studies in the Social Sciences. (arXiv:2309.06578v1 [cs.CL])

    [http://arxiv.org/abs/2309.06578](http://arxiv.org/abs/2309.06578)

    本文研究了大型语言模型（LLMs）根据科学摘要文本的能力，来辨别支持或反驳特定假设的证据。通过社区驱动的注释建立了一个新的数据集，针对社会科学中的科学假设证据任务。与其他基准进行了性能比较，并为未来研究提供了机会。

    

    假设的制定和测试是经验性研究的核心。一个强有力的假设是基于现有证据的最佳猜测，并且是基于相关文献的全面视图进行启发的。然而，随着每年科学文章数量的指数增长，对于给定假设相关证据的手动汇总和综合是一项挑战。我们的工作探索了当前大型语言模型（LLMs）根据科学摘要文本中的证据，能否辨别支持或反驳特定假设的能力。我们共享了一个新颖的数据集，用于社会科学中使用社区驱动的研究注释的科学假设证据任务。我们将LLMs的性能与几个最先进的基准进行比较，并指出未来研究的机会。该数据集可在https://github.com/Sai90000/ScientificHypothesisEvidencing.git上获得。

    Hypothesis formulation and testing are central to empirical research. A strong hypothesis is a best guess based on existing evidence and informed by a comprehensive view of relevant literature. However, with exponential increase in the number of scientific articles published annually, manual aggregation and synthesis of evidence related to a given hypothesis is a challenge. Our work explores the ability of current large language models (LLMs) to discern evidence in support or refute of specific hypotheses based on the text of scientific abstracts. We share a novel dataset for the task of scientific hypothesis evidencing using community-driven annotations of studies in the social sciences. We compare the performance of LLMs to several state-of-the-art benchmarks and highlight opportunities for future research in this area. The dataset is available at https://github.com/Sai90000/ScientificHypothesisEvidencing.git
    
[^53]: Circle Feature Graphormer: 能够刺激图转换器的圆形特征吗？

    Circle Feature Graphormer: Can Circle Features Stimulate Graph Transformer?. (arXiv:2309.06574v1 [cs.SI])

    [http://arxiv.org/abs/2309.06574](http://arxiv.org/abs/2309.06574)

    本文介绍了一种新的圆形特征图转换器（CFG），用于丢失链路预测任务，并实现了改进的图自注意机制。实验结果表明，CFG在ogbl-citation2数据集上取得了最先进的性能。

    

    在本文中，我们介绍了两种用于ogbl-citation2中丢失链路预测任务的本地图特征。我们将这些特征定义为圆形特征，借鉴了朋友圈的概念。我们提出了上述特征的详细计算公式。首先，我们将第一个圆形特征定义为常见图中的改进振荡特征，它来自于二分图。其次，我们将第二个圆形特征定义为桥梁，它表示不同朋友圈中两个节点的重要性。此外，我们首次将上述特征作为偏置来增强图转换器神经网络，从而改进了图自注意机制。我们基于SIEG网络实现了一个基于圆形特征的图转换器（CFG）模型，它利用双塔结构来捕捉全局和局部结构特征。实验结果表明，CFG在ogbl-citation2数据集上达到了最先进的性能。

    In this paper, we introduce two local graph features for missing link prediction tasks on ogbl-citation2. We define the features as Circle Features, which are borrowed from the concept of circle of friends. We propose the detailed computing formulas for the above features. Firstly, we define the first circle feature as modified swing for common graph, which comes from bipartite graph. Secondly, we define the second circle feature as bridge, which indicates the importance of two nodes for different circle of friends. In addition, we firstly propose the above features as bias to enhance graph transformer neural network, such that graph self-attention mechanism can be improved. We implement a Circled Feature aware Graph transformer (CFG) model based on SIEG network, which utilizes a double tower structure to capture both global and local structure features. Experimental results show that CFG achieves the state-of-the-art performance on dataset ogbl-citation2.
    
[^54]: 人在循环人在工厂系统的高保真快速模拟（HIL-HIP）。

    High Fidelity Fast Simulation of Human in the Loop Human in the Plant (HIL-HIP) Systems. (arXiv:2309.06558v1 [eess.SY])

    [http://arxiv.org/abs/2309.06558](http://arxiv.org/abs/2309.06558)

    本文研究了人在循环人在工厂系统中无线网络的时间变异性对模拟的影响，提出了一种分段线性时间不变模拟（PLIS）方法，实现了超过2.1倍的加速。

    

    在人在循环，人在工厂（HIL-HIP）物理系统中，无线移动网络的时间变异性引起了非线性模拟，导致模拟减速。通过在时间间隔内推导一系列分段线性时间不变模拟（PLIS），来处理时间变异性，并在时间域中将它们连接起来。本文对无线网络控制的HIL-HIP系统中时间变化的组件进行了形式分析，评估了模拟精度和加速度的权衡。我们为人工胰腺无线网络系统开发了一个准确的模拟框架，用于控制1型糖尿病患者的血糖，具有与心理应激和进食模式相关的时间变异属性。PLIS方法相比非线性系统模拟实现了超过2.1倍的加速。

    Non-linearities in simulation arise from the time variance in wireless mobile networks when integrated with human in the loop, human in the plant (HIL-HIP) physical systems under dynamic contexts, leading to simulation slowdown. Time variance is handled by deriving a series of piece wise linear time invariant simulations (PLIS) in intervals, which are then concatenated in time domain. In this paper, we conduct a formal analysis of the impact of discretizing time-varying components in wireless network-controlled HIL-HIP systems on simulation accuracy and speedup, and evaluate trade-offs with reliable guarantees. We develop an accurate simulation framework for an artificial pancreas wireless network system that controls blood glucose in Type 1 Diabetes patients with time varying properties such as physiological changes associated with psychological stress and meal patterns. PLIS approach achieves accurate simulation with greater than 2.1 times speedup than a non-linear system simulation 
    
[^55]: 在大学学生报纸中无监督检测偏见

    Unsupervised Bias Detection in College Student Newspapers. (arXiv:2309.06557v1 [cs.CL])

    [http://arxiv.org/abs/2309.06557](http://arxiv.org/abs/2309.06557)

    本文提出了一个几乎没有人为影响的流程，用于从大学报纸档案中获取并检测偏见。该方法通过比较大型语言模型摘要的情感与原文来计算偏见，不需要大量标记数据，为客观理解学生报纸来源中的偏见提供了方法。

    

    本文提出了一个几乎没有人为影响的流程，用于从大学报纸档案中获取并检测偏见。该文介绍了一个从自动化工具无法获取数据的复杂档案网站上获取数据的框架，并生成了一个包含23,154个条目的14个学生报纸数据集。通过将大型语言模型摘要的情感与原文进行比较，还可以通过关键字查询来计算偏见。这种方法的优势在于它比重构偏见更少比较，并且比生成关键字情绪需要更少的标记数据。通过在政治性词汇以及控制词上计算结果，展示了如何得出结论。该完整方法有助于在假设和分类较少的情况下提取细致入微的见解，为客观理解学生报纸来源中的偏见铺平了道路。

    This paper presents a pipeline with minimal human influence for scraping and detecting bias on college newspaper archives. This paper introduces a framework for scraping complex archive sites that automated tools fail to grab data from, and subsequently generates a dataset of 14 student papers with 23,154 entries. This data can also then be queried by keyword to calculate bias by comparing the sentiment of a large language model summary to the original article. The advantages of this approach are that it is less comparative than reconstruction bias and requires less labelled data than generating keyword sentiment. Results are calculated on politically charged words as well as control words to show how conclusions can be drawn. The complete method facilitates the extraction of nuanced insights with minimal assumptions and categorizations, paving the way for a more objective understanding of bias within student newspaper sources.
    
[^56]: 离线逆向强化学习下的提示评估与优化

    Offline Prompt Evaluation and Optimization with Inverse Reinforcement Learning. (arXiv:2309.06553v1 [cs.CL])

    [http://arxiv.org/abs/2309.06553](http://arxiv.org/abs/2309.06553)

    这项工作介绍了一种基于离线逆向强化学习的提示评估与优化方法，通过利用离线数据集和逆向强化学习，预测提示性能、提高成本效益、生成易读的结果。

    

    最近，像ChatGPT这样的大型语言模型（LLM）的发展取得了显著的性能，通过利用人类专业知识。然而，充分揭示LLMs在复杂任务中的潜力需要在自然语言提示的广阔搜索空间中进行导航。虽然提示工程显示出潜力，但试错尝试中所需的人工设计提示和相关成本带来了重大挑战。关键是，提示优化的效率取决于昂贵的提示评估过程。本工作介绍了Prompt-OIRL，这是一种基于离线逆向强化学习的方法，旨在弥合有效提示评估和可负担性之间的差距。我们的方法利用专家评估的离线数据集，运用逆向强化学习获得一个针对离线、查询依赖型提示评估的奖励模型。Prompt-OIRL的优点是多方面的：它预测提示的性能，成本高效，生成易读的结果。

    The recent advances in the development of Large Language Models (LLMs) like ChatGPT have achieved remarkable performance by leveraging human expertise. Yet, fully eliciting LLMs' potential for complex tasks requires navigating the vast search space of natural language prompts. While prompt engineering has shown promise, the requisite human-crafted prompts in trial-and-error attempts and the associated costs pose significant challenges. Crucially, the efficiency of prompt optimization hinges on the costly procedure of prompt evaluation. This work introduces Prompt-OIRL, an approach rooted in offline inverse reinforcement learning that seeks to bridge the gap between effective prompt evaluation and affordability. Our method draws on offline datasets from expert evaluations, employing Inverse-RL to derive a reward model for offline, query-dependent prompt evaluations. The advantages of Prompt-OIRL are manifold: it predicts prompt performance, is cost-efficient, produces human-readable res
    
[^57]: 使用超图表示生成合成文本

    Synthetic Text Generation using Hypergraph Representations. (arXiv:2309.06550v1 [cs.CL])

    [http://arxiv.org/abs/2309.06550](http://arxiv.org/abs/2309.06550)

    本论文提出了一种使用超图表示生成合成文本的方法，首先将文档分解为语义框架，然后使用此中间稀疏格式生成文本。通过扰动框架内容，包括拓扑分析挖掘新的超边以及包含层次结构和时间动态的复杂多元关系，我们的解决方案生成的文档在样式、情感、格式、构成和事实上是多样的、连贯的和变化的。

    

    生成文档的合成变体通常被视为文本到文本的转换。我们提出了一种基于LLM的替代方法，该方法首先将文档分解为语义框架，然后使用此中间稀疏格式生成文本。这些框架使用超图进行建模，可以以恰当的方式扰动框架内容。具体而言，通过拓扑分析挖掘新的超边，包括层次结构和时间动态的复杂多元关系。我们展示了我们的解决方案生成的文档在样式、情感、格式、构成和事实上是多样的、连贯的和变化的。

    Generating synthetic variants of a document is often posed as text-to-text transformation. We propose an alternate LLM based method that first decomposes a document into semantic frames and then generates text using this interim sparse format. The frames are modeled using a hypergraph, which allows perturbing the frame contents in a principled manner. Specifically, new hyperedges are mined through topological analysis and complex polyadic relationships including hierarchy and temporal dynamics are accommodated. We show that our solution generates documents that are diverse, coherent and vary in style, sentiment, format, composition and facts.
    
[^58]: 面向会话推荐的层次化多任务学习框架

    Hierarchical Multi-Task Learning Framework for Session-based Recommendations. (arXiv:2309.06533v1 [cs.IR])

    [http://arxiv.org/abs/2309.06533](http://arxiv.org/abs/2309.06533)

    本文提出了一种面向会话推荐的层次化多任务学习框架HierSRec，通过在预测任务之间设置层次结构，并利用辅助任务的输出来提供更丰富的输入特征和更高的预测可解释性，进一步增强了预测准确性和可泛化性。

    

    虽然会话推荐系统（SBRS）已经表现出卓越的推荐性能，但多任务学习（MTL）已经被SBRS采用以进一步提高其预测准确性和可泛化性。层次化多任务学习（H-MTL）在预测任务之间设置了层次结构，并将辅助任务的输出馈送给主任务。与现有的MTL框架相比，这种层次结构为主任务提供了更丰富的输入特征和更高的预测可解释性。然而，H-MTL框架在SBRS中尚未进行研究。在本文中，我们提出了HierSRec，将H-MTL架构纳入SBRS中。HierSRec使用元数据感知Transformer对给定会话进行编码，并使用会话编码进行下一类别预测（即辅助任务）。接下来，HierSRec使用类别预测结果和会话编码进行下一个物品预测（即主任务）。为了可扩展的推断，HierSRec创建了一个紧凑的候选物品集合。

    While session-based recommender systems (SBRSs) have shown superior recommendation performance, multi-task learning (MTL) has been adopted by SBRSs to enhance their prediction accuracy and generalizability further. Hierarchical MTL (H-MTL) sets a hierarchical structure between prediction tasks and feeds outputs from auxiliary tasks to main tasks. This hierarchy leads to richer input features for main tasks and higher interpretability of predictions, compared to existing MTL frameworks. However, the H-MTL framework has not been investigated in SBRSs yet. In this paper, we propose HierSRec which incorporates the H-MTL architecture into SBRSs. HierSRec encodes a given session with a metadata-aware Transformer and performs next-category prediction (i.e., auxiliary task) with the session encoding. Next, HierSRec conducts next-item prediction (i.e., main task) with the category prediction result and session encoding. For scalable inference, HierSRec creates a compact set of candidate items (
    
[^59]: 语法错误修正系统的系统组合的最小贝叶斯风险解码方法

    Minimum Bayes' Risk Decoding for System Combination of Grammatical Error Correction Systems. (arXiv:2309.06520v1 [cs.CL])

    [http://arxiv.org/abs/2309.06520](http://arxiv.org/abs/2309.06520)

    本文提出了一个用于语法错误修正系统系统组合的最小贝叶斯风险解码方法，并通过实验证明了其有效性。

    

    对于序列到序列的任务来说，将各个系统的输出进行组合是一项具有挑战性的工作。同时，解码准则与评估准则之间通常存在不匹配。最小贝叶斯风险（MBR）解码可以用于以更好地与最终评估准则对齐的方式组合系统的输出。本文研究了在语法错误修正（GEC）系统中的MBR解码，该系统通常以编辑次数和相关的F分数来评估性能。因此，我们提出了一种与这种准则直接相关的新颖MBR损失函数。此外，文中还描述了一种扩展候选句子集合的方法。该方法基于当前的最大投票组合方案，以及个体编辑级别的选择。在三个流行的GEC数据集和最先进的GEC系统上进行的实验证明了所提出的MBR方法的有效性。此外，论文还突出了MBR解码中不同奖励指标的变化对结果的影响。

    For sequence-to-sequence tasks it is challenging to combine individual system outputs. Further, there is also often a mismatch between the decoding criterion and the one used for assessment. Minimum Bayes' Risk (MBR) decoding can be used to combine system outputs in a manner that encourages better alignment with the final assessment criterion. This paper examines MBR decoding for Grammatical Error Correction (GEC) systems, where performance is usually evaluated in terms of edits and an associated F-score. Hence, we propose a novel MBR loss function directly linked to this form of criterion. Furthermore, an approach to expand the possible set of candidate sentences is described. This builds on a current max-voting combination scheme, as well as individual edit-level selection. Experiments on three popular GEC datasets and with state-of-the-art GEC systems demonstrate the efficacy of the proposed MBR approach. Additionally, the paper highlights how varying reward metrics within the MBR d
    
[^60]: AGIBench: 用于大型语言模型的多粒度、多模态、人工参考、自动评分基准

    AGIBench: A Multi-granularity, Multimodal, Human-referenced, Auto-scoring Benchmark for Large Language Models. (arXiv:2309.06495v1 [cs.CL])

    [http://arxiv.org/abs/2309.06495](http://arxiv.org/abs/2309.06495)

    AGIBench是一个用于大型语言模型的多粒度、多模态、人工参考、自动评分的基准，通过标记问题的属性来评估语言模型的问题解决能力和智能程度。

    

    大型语言模型（LLM）如ChatGPT展示了惊人的智能。如何评估LLM的问题解决能力和智能程度是一个热点但具有挑战性的问题。首先，问题解决能力与不同的能力分支（如理解）和大规模的知识类别（如数学）交织在一起。第二，问题的输入是多模态的，可能涉及文本和图像。第三，LLM的响应格式多样，因此对结果提取和评估提出了巨大挑战。在本文中，我们提出了AGIBench--一种用于LLM的多粒度、多模态、人工参考和自动评分的基准方法。与混合问题集合不同，AGIBench专注于三个典型的能力分支，并采用四元组<能力分支、知识、难度、模态>来标记每个问题的属性。首先，它支持多粒度的基准化，例如每个问题、每个能力分支、每个知识类别的基准化。

    Large language models (LLMs) like ChatGPT have revealed amazing intelligence. How to evaluate the question-solving abilities of LLMs and their degrees of intelligence is a hot-spot but challenging issue. First, the question-solving abilities are interlaced with different ability branches like understanding and massive knowledge categories like mathematics. Second, the inputs of questions are multimodal that may involve text and images. Third, the response format of LLMs is diverse and thus poses great challenges for result extraction and evaluation. In this paper, we propose AGIBench -- a multi-granularity, multimodal, human-referenced, and auto-scoring benchmarking methodology for LLMs. Instead of a collection of blended questions, AGIBench focuses on three typical ability branches and adopts a four-tuple <ability branch, knowledge, difficulty, modal> to label the attributes of each question. First, it supports multi-granularity benchmarking, e.g., per-question, per-ability branch, pe
    
[^61]: 随机LLMs无法理解语言：走向符号化、可解释性和本体论基于的LLMs

    Stochastic LLMs do not Understand Language: Towards Symbolic, Explainable and Ontologically Based LLMs. (arXiv:2309.05918v1 [cs.CL])

    [http://arxiv.org/abs/2309.05918](http://arxiv.org/abs/2309.05918)

    随机LLMs无法理解语言的原因是它们无法提供可以依赖的事实信息，它们存储的语言知识埋藏在无意义的微特征中，并在某些语言上下文中无法进行正确推理。本文建议在符号化方法中应用有效的自下而上策略

    

    在我们看来，围绕数据驱动的大型语言模型（LLMs）相对成功的狂热是有些误导的，原因如下：（i）LLMs不能依赖于事实信息，因为对于LLMs来说，摄入的所有文本（事实或非事实）都是平等的；（ii）由于它们的亚符号性质，这些模型对语言的任何“知识”都将永远埋藏在数十亿个微特征（权重）中，其中没有一个本身是有意义的；以及（iii）LLMs在几种语言上下文中常常无法进行正确推理（如名词复合词、共谓词、量词范围模糊和意向性上下文）。我们相信，数据驱动的大型语言模型（LLMs）的相对成功不是符号与亚符号之辩的反映，而是在规模上应用自下而上的逆向工程语言的成功策略的反映。在本文中，我们建议将有效的自下而上策略应用于符号化方法中

    In our opinion the exuberance surrounding the relative success of data-driven large language models (LLMs) is slightly misguided and for several reasons (i) LLMs cannot be relied upon for factual information since for LLMs all ingested text (factual or non-factual) was created equal; (ii) due to their subsymbolic na-ture, whatever 'knowledge' these models acquire about language will always be buried in billions of microfeatures (weights), none of which is meaningful on its own; and (iii) LLMs will often fail to make the correct inferences in several linguistic contexts (e.g., nominal compounds, copredication, quantifier scope ambi-guities, intensional contexts. Since we believe the relative success of data-driven large language models (LLMs) is not a reflection on the symbolic vs. subsymbol-ic debate but a reflection on applying the successful strategy of a bottom-up reverse engineering of language at scale, we suggest in this paper applying the effective bottom-up strategy in a symbol
    
[^62]: 内存注入：在Transformer-Based语言模型中纠正多跳推理错误

    Memory Injections: Correcting Multi-Hop Reasoning Failures during Inference in Transformer-Based Language Models. (arXiv:2309.05605v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2309.05605](http://arxiv.org/abs/2309.05605)

    本文提出了一种通过向Transformer-Based语言模型的LLM注意力头部定向注入内存来纠正多跳推理错误的方法，从而提高了模型在处理多跳推理问题时的表现。

    

    回答多跳推理问题需要从多个信息源中检索和综合信息。大语言模型(LLMs)往往难以保持一致的推理能力。本文提出了一种通过在LLM注意力头部进行定向内存注入来确定和纠正多跳推理错误的方法。首先，我们分析了GPT-2模型在单跳和多跳提示下各层的激活情况。然后，我们提出了一种机制，允许用户在推理过程中向关键LLM位置注入相关的提示特定信息，我们将其称为“记忆”。通过在推理过程中使LLM能够整合额外的相关信息，我们提高了多跳提示生成的质量。我们实证表明，将简单、高效且定向的记忆注入到关键注意力层中往往能够提高多跳任务中所需下一个标记的概率，提高了达到424%。

    Answering multi-hop reasoning questions requires retrieving and synthesizing information from diverse sources. Large Language Models (LLMs) struggle to perform such reasoning consistently. Here we propose an approach to pinpoint and rectify multi-hop reasoning failures through targeted memory injections on LLM attention heads. First, we analyze the per-layer activations of GPT-2 models in response to single and multi-hop prompts. We then propose a mechanism that allows users to inject pertinent prompt-specific information, which we refer to as "memories," at critical LLM locations during inference. By thus enabling the LLM to incorporate additional relevant information during inference, we enhance the quality of multi-hop prompt completions. We show empirically that a simple, efficient, and targeted memory injection into a key attention layer can often increase the probability of the desired next token in multi-hop tasks, by up to 424%.
    
[^63]: NExT-GPT: 任何到任何的多模态语言模型

    NExT-GPT: Any-to-Any Multimodal LLM. (arXiv:2309.05519v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2309.05519](http://arxiv.org/abs/2309.05519)

    NExT-GPT是一个任何到任何的多模态语言模型系统，通过连接多模态适配器和不同扩散解码器，能够接受和生成任意组合的文本、图像、视频和音频内容。

    

    最近，多模态大型语言模型（MM-LLM）取得了令人振奋的进展，但它们主要存在一个限制，即只能在输入端进行多模态理解，无法以多种模式生成内容。由于我们人类总是通过各种模态感知世界和与人交流，因此开发能够接受和传递任何模态内容的任何到任何的MM-LLM系统对于实现人级AI至关重要。为了填补这一空白，我们提出了一个端到端的通用任何到任何的多模态语言模型系统，NExT-GPT。我们通过连接一个含有多模态适配器和不同扩散解码器的LLM，使得NExT-GPT能够以任意的文本、图像、视频和音频的组合进行输入和输出。通过利用现有训练有素的高性能编码器和解码器，NExT-GPT仅通过调整某些投影层的少量参数（1%）进行调优，这不仅有利于低成本训练，还有助于方便的扩展性。

    While recently Multimodal Large Language Models (MM-LLMs) have made exciting strides, they mostly fall prey to the limitation of only input-side multimodal understanding, without the ability to produce content in multiple modalities. As we humans always perceive the world and communicate with people through various modalities, developing any-to-any MM-LLMs capable of accepting and delivering content in any modality becomes essential to human-level AI. To fill the gap, we present an end-to-end general-purpose any-to-any MM-LLM system, NExT-GPT. We connect an LLM with multimodal adaptors and different diffusion decoders, enabling NExT-GPT to perceive inputs and generate outputs in arbitrary combinations of text, images, videos, and audio. By leveraging the existing well-trained highly-performing encoders and decoders, NExT-GPT is tuned with only a small amount of parameter (1%) of certain projection layers, which not only benefits low-cost training and also facilitates convenient expansi
    
[^64]: 可以通过短信传输发生的事情吗？将预训练语言编码器整合到自动驾驶的轨迹预测模型中

    Can you text what is happening? Integrating pre-trained language encoders into trajectory prediction models for autonomous driving. (arXiv:2309.05282v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2309.05282](http://arxiv.org/abs/2309.05282)

    本研究提出了将预训练语言编码器整合到自动驾驶的轨迹预测模型中的新方法。通过基于文本的场景表示和经典的栅格化图像表示相结合，得到了描述性的场景嵌入，并在实验中验证了显著的性能改进。

    

    在自动驾驶任务中，场景理解是预测周围交通参与者未来行为的第一步。然而，如何表示给定的场景并提取其特征仍然是开放的研究问题。本研究提出了一种新颖的基于文本的交通场景表示，并通过预训练的语言编码器进行处理。首先，我们展示了基于文本的表示与传统的栅格化图像表示相结合，可以得到描述性的场景嵌入。其次，我们在nuScenes数据集上对我们的预测进行了基准测试，并与基准模型相比，显示出显著的改进。第三，我们通过消融研究证明，文本和栅格化图像的联合编码器胜过单独的编码器，确认了两种表示具有互补的优势。

    In autonomous driving tasks, scene understanding is the first step towards predicting the future behavior of the surrounding traffic participants. Yet, how to represent a given scene and extract its features are still open research questions. In this study, we propose a novel text-based representation of traffic scenes and process it with a pre-trained language encoder.  First, we show that text-based representations, combined with classical rasterized image representations, lead to descriptive scene embeddings. Second, we benchmark our predictions on the nuScenes dataset and show significant improvements compared to baselines. Third, we show in an ablation study that a joint encoder of text and rasterized images outperforms the individual encoders confirming that both representations have their complementary strengths.
    
[^65]: 用物理信息神经网络进行最优反对角量子计算的研究

    Physics-Informed Neural Networks for an optimal counterdiabatic quantum computation. (arXiv:2309.04434v1 [quant-ph] CROSS LISTED)

    [http://arxiv.org/abs/2309.04434](http://arxiv.org/abs/2309.04434)

    本研究提出了一种利用物理信息神经网络（PINNs）解决量子电路反对角（CD）协议优化问题的方法，通过嵌入物理信息到神经网络中，并利用最小作用量原理和厄米特性条件来获取最适当的反对角项，从而提供了一种可靠的替代方案，摆脱了以往依赖于经典数值逼近的约束。

    

    我们引入了一种新的方法，利用物理信息神经网络（PINNs）的优势来解决由$N_{Q}$比特系统组成的量子电路中的反对角（CD）协议优化的问题。主要目标是利用受物理启发的深度学习技术精确地解决量子系统中不同物理可观测量的时间演化。为了实现这个目标，我们将必要的物理信息嵌入到底层神经网络中，以有效地解决这个问题。特别地，我们对所有物理可观测量施加厄米特性条件，并利用最小作用量原理，保证基于物理学的最适当反对角项的获取。所提出的方法提供了一个可靠的替代选择来解决CD驱动问题，摆脱了以往依赖于经典数值逼近的约束。

    We introduce a novel methodology that leverages the strength of Physics-Informed Neural Networks (PINNs) to address the counterdiabatic (CD) protocol in the optimization of quantum circuits comprised of systems with $N_{Q}$ qubits. The primary objective is to utilize physics-inspired deep learning techniques to accurately solve the time evolution of the different physical observables within the quantum system. To accomplish this objective, we embed the necessary physical information into an underlying neural network to effectively tackle the problem. In particular, we impose the hermiticity condition on all physical observables and make use of the principle of least action, guaranteeing the acquisition of the most appropriate counterdiabatic terms based on the underlying physics. The proposed approach offers a dependable alternative to address the CD driving problem, free from the constraints typically encountered in previous methodologies relying on classical numerical approximations.
    
[^66]: 通过在线凸优化实现在线子模最大化

    Online Submodular Maximization via Online Convex Optimization. (arXiv:2309.04339v1 [cs.LG])

    [http://arxiv.org/abs/2309.04339](http://arxiv.org/abs/2309.04339)

    本论文研究了在线设置下的一般性子模最大化问题，并将一类大型子模函数归约到在线凸优化问题中。这种归约方式可在组合优化中实现次线性遗憾，并且适用于许多不同版本的在线学习问题。

    

    我们研究了在线设置下的一般性子模最大化问题在一般性模性约束下。我们证明了在线优化一类大型子模函数，即加权阈值势函数，可以归约到在线凸优化(OCO)问题。这是因为这个类别的函数可以进行凹松弛;因此，结合适当的舍入方案，OCO策略可以在组合设置中实现次线性遗憾。我们还展示了我们的简化方式可以应用在许多不同版本的在线学习问题中，包括动态遗憾、强盗和乐观学习等设置。

    We study monotone submodular maximization under general matroid constraints in the online setting. We prove that online optimization of a large class of submodular functions, namely, weighted threshold potential functions, reduces to online convex optimization (OCO). This is precisely because functions in this class admit a concave relaxation; as a result, OCO policies, coupled with an appropriate rounding scheme, can be used to achieve sublinear regret in the combinatorial setting. We show that our reduction extends to many different versions of the online learning problem, including the dynamic regret, bandit, and optimistic-learning settings.
    
[^67]: 通过偏好学习在多目标问题中进行交互式超参数优化

    Interactive Hyperparameter Optimization in Multi-Objective Problems via Preference Learning. (arXiv:2309.03581v1 [cs.LG])

    [http://arxiv.org/abs/2309.03581](http://arxiv.org/abs/2309.03581)

    本文提出了一个以人为中心的交互式超参数优化方法，通过应用偏好学习来解决多目标机器学习中的问题。

    

    超参数优化对于发挥机器学习的潜力至关重要。在实践中，用户通常对多目标问题感兴趣，即优化可能存在冲突的目标，比如准确性和能耗。为了解决这个问题，绝大多数多目标机器学习算法将一组非支配的机器学习模型的帕累托前沿返回给用户。然而，优化这种算法的超参数并不容易，因为评估一个超参数配置涉及评估得到的帕累托前沿的质量。在文献中，已有一些指标可以通过量化不同属性（如体积、与参考点的接近程度）来评估帕累托前沿的质量（例如超体积、R2）。然而，对于用户来说，选择导致期望的帕累托前沿的指标可能是一项困难的任务。在本文中，我们提出了一个以人为中心的交互式超参数优化方法，针对多目标机器学习应用偏好学习。

    Hyperparameter optimization (HPO) is important to leverage the full potential of machine learning (ML). In practice, users are often interested in multi-objective (MO) problems, i.e., optimizing potentially conflicting objectives, like accuracy and energy consumption. To tackle this, the vast majority of MO-ML algorithms return a Pareto front of non-dominated machine learning models to the user. Optimizing the hyperparameters of such algorithms is non-trivial as evaluating a hyperparameter configuration entails evaluating the quality of the resulting Pareto front. In literature, there are known indicators that assess the quality of a Pareto front (e.g., hypervolume, R2) by quantifying different properties (e.g., volume, proximity to a reference point). However, choosing the indicator that leads to the desired Pareto front might be a hard task for a user. In this paper, we propose a human-centered interactive HPO approach tailored towards multi-objective ML leveraging preference learnin
    
[^68]: ChatRule：利用大型语言模型挖掘知识图谱推理中的逻辑规则

    ChatRule: Mining Logical Rules with Large Language Models for Knowledge Graph Reasoning. (arXiv:2309.01538v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2309.01538](http://arxiv.org/abs/2309.01538)

    本论文提出了一个框架ChatRule，利用大型语言模型挖掘知识图谱中的逻辑规则。该框架通过充分利用知识图谱的语义和结构信息，能够提高推理性能并提供可解释的结果。

    

    逻辑规则对于发现关系之间的逻辑连接至关重要，可以提高推理性能并提供可解释的知识图谱结果。尽管已经有许多努力在知识图谱上挖掘有意义的逻辑规则，但现有方法在规则空间上搜索计算密集且缺乏可伸缩性，尤其是对于大规模知识图谱。此外，它们常常忽视了关系的语义，而这对于揭示逻辑连接至关重要。最近，大型语言模型（LLMs）在自然语言处理领域和各种应用中展现出了令人瞩目的性能，归功于它们的新能力和泛化能力。在本文中，我们提出了一个新颖的框架ChatRule，利用大型语言模型挖掘知识图谱中的逻辑规则。具体而言，该框架以基于LLM的规则生成器为初始，充分利用了知识图谱的语义和结构信息。

    Logical rules are essential for uncovering the logical connections between relations, which could improve the reasoning performance and provide interpretable results on knowledge graphs (KGs). Although there have been many efforts to mine meaningful logical rules over KGs, existing methods suffer from the computationally intensive searches over the rule space and a lack of scalability for large-scale KGs. Besides, they often ignore the semantics of relations which is crucial for uncovering logical connections. Recently, large language models (LLMs) have shown impressive performance in the field of natural language processing and various applications, owing to their emergent ability and generalizability. In this paper, we propose a novel framework, ChatRule, unleashing the power of large language models for mining logical rules over knowledge graphs. Specifically, the framework is initiated with an LLM-based rule generator, leveraging both the semantic and structural information of KGs 
    
[^69]: 多途径适配器：为可扩展的图像-文本检索调整大规模多模态模型

    MultiWay-Adapater: Adapting large-scale multi-modal models for scalable image-text retrieval. (arXiv:2309.01516v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2309.01516](http://arxiv.org/abs/2309.01516)

    多途径适配器是一个创新的框架，利用"对齐增强器"加深模态对齐，实现高可转移性，可有效减少调整参数的时间并提高零样本图像-文本检索性能。

    

    随着大规模多模态模型（LMMs）的规模不断增加，将这些预训练模型调整到专门的任务上已成为一个计算和内存密集的挑战。传统的微调方法需要为每个新任务进行孤立、穷举的重新调整，限制了模型的多功能性。此外，当前的高效调整技术经常忽视模态对齐，仅关注新任务的知识提取。为了解决这些问题，我们引入了多途径适配器，这是一个创新的框架，它包含了一个“对齐增强器”，可以加深模态对齐，实现高度的可转移性而无需调整预训练参数。我们的方法仅向LMMs添加了不到1.25%的额外参数，以BEiT-3模型为例。与完全微调的模型相比，我们的方法在零样本图像-文本检索性能上具有优势，同时缩短了高达57%的微调时间。我们的方法提供了一种资源高效和高效的方法。

    As the size of Large Multi-Modal Models (LMMs) increases consistently, the adaptation of these pre-trained models to specialized tasks has become a computationally and memory-intensive challenge. Traditional fine-tuning methods require isolated, exhaustive retuning for each new task, limiting the models' versatility. Moreover, current efficient adaptation techniques often overlook modality alignment, focusing only on the knowledge extraction of new tasks. To tackle these issues, we introduce Multiway-Adapter, an innovative framework incorporating an 'Alignment Enhancer' to deepen modality alignment, enabling high transferability without tuning pre-trained parameters. Our method adds fewer than 1.25\% of additional parameters to LMMs, exemplified by the BEiT-3 model in our study. This leads to superior zero-shot image-text retrieval performance compared to fully fine-tuned models, while achieving up to a 57\% reduction in fine-tuning time. Our approach offers a resource-efficient and ef
    
[^70]: 阐明扩散模型中的曝光偏差问题

    Elucidating the Exposure Bias in Diffusion Models. (arXiv:2308.15321v1 [cs.LG])

    [http://arxiv.org/abs/2308.15321](http://arxiv.org/abs/2308.15321)

    本文系统地研究了扩散模型中的曝光偏差问题，并提出了一种名为Epsilon Scaling的免训练方法来减轻这一问题。实验结果验证了该方法的有效性。

    

    扩散模型展示了令人印象深刻的生成能力，但它们的“曝光偏差”问题，即训练和采样之间的输入不匹配，缺乏深入探索。本文通过首先对采样分布进行分析建模，然后将每个采样步骤的预测误差归因为曝光偏差问题的根本原因，系统地研究了扩散模型中的曝光偏差问题。此外，我们讨论了解决这个问题的潜在方法，并提出了一个直观的度量标准。除了阐明曝光偏差问题，我们提出了一种简单但有效的免训练方法，称为Epsilon Scaling，以减轻曝光偏差。我们展示了Epsilon Scaling通过缩小网络输出（Epsilon）明确地将采样轨迹移近训练阶段学习到的向量场，从而减轻了训练和采样之间的输入不匹配。在各种扩散框架上进行了实验。

    Diffusion models have demonstrated impressive generative capabilities, but their 'exposure bias' problem, described as the input mismatch between training and sampling, lacks in-depth exploration. In this paper, we systematically investigate the exposure bias problem in diffusion models by first analytically modelling the sampling distribution, based on which we then attribute the prediction error at each sampling step as the root cause of the exposure bias issue. Furthermore, we discuss potential solutions to this issue and propose an intuitive metric for it. Along with the elucidation of exposure bias, we propose a simple, yet effective, training-free method called Epsilon Scaling to alleviate the exposure bias. We show that Epsilon Scaling explicitly moves the sampling trajectory closer to the vector field learned in the training phase by scaling down the network output (Epsilon), mitigating the input mismatch between training and sampling. Experiments on various diffusion framework
    
[^71]: 针对旅行商问题的并行元启发式求解器的集合

    A Parallel Ensemble of Metaheuristic Solvers for the Traveling Salesman Problem. (arXiv:2308.07347v1 [cs.AI])

    [http://arxiv.org/abs/2308.07347](http://arxiv.org/abs/2308.07347)

    这篇论文研究了并行集合中旅行商问题的元启发式求解器。通过将不同求解器结合使用，能够超越单个求解器的性能表现。

    

    旅行商问题（TSP）是文献中研究较多的NP-hard问题之一。最先进的近似TSP求解器是Lin-Kernighan-Helsgaun（LKH）启发式算法和Edge Assembly交叉算法（EAX）。最近的研究表明，带有重启机制的EAX在广泛的TSP实例中表现优秀。然而，这项研究仅限于涉及2000个城市的问题。我们研究了从2000到85900个城市的问题。我们发现求解器的性能因问题类型而异。然而，将这些求解器结合在一起，以集合的方式使用，我们能够超越单独求解器的性能。我们认为集合式设置是利用丰富的计算资源的有效方式。除了EAX和LKH，我们还使用了EAX和混合遗传算法（MGA）的多个版本的混合算法。MGA和EAX的混合已经被证明可以解决一些困难的问题。我们发现混合版本的集合胜过了最先进的求解器。

    The travelling salesman problem (TSP) is one of the well-studied NP-hard problems in the literature. The state-of-the art inexact TSP solvers are the Lin-Kernighan-Helsgaun (LKH) heuristic and Edge Assembly crossover (EAX). A recent study suggests that EAX with restart mechanisms perform well on a wide range of TSP instances. However, this study is limited to 2,000 city problems. We study for problems ranging from 2,000 to 85,900. We see that the performance of the solver varies with the type of the problem. However, combining these solvers in an ensemble setup, we are able to outperform the individual solver's performance. We see the ensemble setup as an efficient way to make use of the abundance of compute resources. In addition to EAX and LKH, we use several versions of the hybrid of EAX and Mixing Genetic Algorithm (MGA). A hybrid of MGA and EAX is known to solve some hard problems. We see that the ensemble of the hybrid version outperforms the state-of-the-art solvers on problems 
    
[^72]: 用机器学习优化国家篮球协会的进攻战术规划

    Optimizing Offensive Gameplan in the National Basketball Association with Machine Learning. (arXiv:2308.06851v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2308.06851](http://arxiv.org/abs/2308.06851)

    本文研究了如何用机器学习优化国家篮球协会的进攻战术规划。通过建立模型，采用特定的特征进行评估和分析，可以帮助决策者确定战术执行的具体细节。

    

    在NBA发生的分析革命中，特定的指标和公式的发展为球队、教练和球员提供了一种新的看待比赛的方式。然而，一个问题出现了，我们如何验证这些指标呢？一种方法可能是简单地凭眼球推测（尝试许多不同的战术计划）和/或试错法-一种估计性的昂贵方法。另一种方法是尝试用机器学习技术对已有指标进行建模，并使用一组独特的特征来模拟。这种方法的关键在于，通过选择这些特征，我们可以尝试评估这些特征的组合效果，而不是单独分析简单的指标评估。如果我们有一个准确的模型，它可以帮助我们确定战术执行的具体细节。在本文中，统计指标ORTG（Dean Oliver开发的进攻评分）发现与不同的NBA比赛类型存在相关性，通过使用线性回归方法进行建模。

    Throughout the analytical revolution that has occurred in the NBA, the development of specific metrics and formulas has given teams, coaches, and players a new way to see the game. However - the question arises - how can we verify any metrics? One method would simply be eyeball approximation (trying out many different gameplans) and/or trial and error - an estimation-based and costly approach. Another approach is to try to model already existing metrics with a unique set of features using machine learning techniques. The key to this approach is that with these features that are selected, we can try to gauge the effectiveness of these features combined, rather than using individual analysis in simple metric evaluation. If we have an accurate model, it can particularly help us determine the specifics of gameplan execution. In this paper, the statistic ORTG (Offensive Rating, developed by Dean Oliver) was found to have a correlation with different NBA playtypes using both a linear regress
    
[^73]: AIs的发展脱靴法

    Developmental Bootstrapping of AIs. (arXiv:2308.04586v1 [cs.AI])

    [http://arxiv.org/abs/2308.04586](http://arxiv.org/abs/2308.04586)

    传统的符号AI方法和深度学习AI方法无法满足创建强大和可信赖的AI的挑战，然而，发展脱靴法通过模仿人类儿童的能力发展过程，为创建稳健可靠的AI提供了希望。

    

    尽管当前一些AI在封闭的世界，如棋盘游戏中超越了人类能力，但它们在混乱的现实世界中的表现有限。它们会犯奇怪的错误而且没有意识到。它们很难受到指导，不能运用常识，缺乏好奇心。它们不能成为良好的合作者。传统手动构建的符号AI方法构建的系统和使用生成和深度学习AI方法(包括大规模语言模型)构建的系统都无法应对这些挑战。它们不适合创建强大和可信赖的AI。尽管此方法不属于主流的AI方法，但发展脱靴法显示出希望。在发展脱靴法中，AI像人类儿童一样发展能力。它们从先天能力开始。像人类一样，它们与环境互动，并从互动中学习。它们通过自我发展的能力逐步扩展先天能力。它们互动并逐渐将所学应用于实际操作。

    Although some current AIs surpass human abilities especially in closed worlds such as board games, their performance in the messy real world is limited. They make strange mistakes and do not notice them. They cannot be instructed easily, fail to use common sense, and lack curiosity. They do not make good collaborators. Neither systems built using the traditional manually-constructed symbolic AI approach nor systems built using generative and deep learning AI approaches including large language models (LLMs) can meet the challenges. They are not well suited for creating robust and trustworthy AIs. Although it is outside of mainstream AI approaches, developmental bootstrapping shows promise. In developmental bootstrapping, AIs develop competences like human children do. They start with innate competences. Like humans, they interact with the environment and learn from their interactions. They incrementally extend their innate competences with self-developed competences. They interact and 
    
[^74]: MSAC：用于语音情感识别的多语音属性控制方法

    MSAC: Multiple Speech Attribute Control Method for Speech Emotion Recognition. (arXiv:2308.04025v1 [cs.SD])

    [http://arxiv.org/abs/2308.04025](http://arxiv.org/abs/2308.04025)

    本研究针对语音情感识别(SER)提出了MSAC方法，通过构建新颖的CNN-based SER模型和多语音属性控制方法MSAC，实现了对情感的更精细控制和捕捉，从而提升了SER的可靠性和效果。

    

    尽管取得了显著进展，但由于情感属性的复杂性和歧义性，尤其是在自然环境下，语音情感识别（SER）仍然具有挑战性。而当前的研究主要关注识别和泛化能力，本文首次探索了SER方法的可靠性，并研究了如何通过各种语音属性的数据分布来建模语音情感。具体来说，我们首先构建了一种新颖的基于CNN的SER模型，采用了加性边界最大化软件最大化损失函数，扩大了不同类别特征之间的距离，从而增强了它们的区分能力。其次，我们提出了一种新颖的多语音属性控制方法MSAC，以明确控制语音属性，使模型受情感无关属性的影响较小，并捕捉到更细粒度的情感相关特征。第三，我们首次尝试测试和分析了所提出的SER工作流程的可靠性。

    Despite significant progress, speech emotion recognition (SER) remains challenging due to inherent complexity and ambiguity of the emotion attribute, particularly in wild world. Whereas current studies primarily focus on recognition and generalization capabilities, this work pioneers an exploration into the reliability of SER methods and investigates how to model the speech emotion from the aspect of data distribution across various speech attributes. Specifically, we first build a novel CNN-based SER model which adopts additive margin softmax loss to expand the distance between features of different classes, thereby enhancing their discrimination. Second, a novel multiple speech attribute control method MSAC is proposed to explicitly control speech attributes, enabling the model to be less affected by emotion-agnostic attributes and capture more fine-grained emotion-related features. Third, we make a first attempt to test and analyze the reliability of the proposed SER workflow using 
    
[^75]: 模型与锡人之间——使用大语言模型研究AI对齐中的委托-代理问题的行为经济学研究

    Of Models and Tin Men -- a behavioural economics study of principal-agent problems in AI alignment using large-language models. (arXiv:2307.11137v1 [cs.AI])

    [http://arxiv.org/abs/2307.11137](http://arxiv.org/abs/2307.11137)

    本研究基于行为经济学角度，对使用大语言模型进行AI对齐中的委托-代理问题进行研究，发现现实世界中的AI安全问题不仅涉及设计者与代理之间的冲突，还涉及到多个代理之间的信息不对称与效用函数之间的错位。

    

    AI对齐通常被描述为一个设计者与人工智能代理之间的相互作用，设计者试图确保代理的行为与其目的一致，并且风险仅仅是由于设计者意图中的效用函数与代理的内部效用函数之间的意外错位而导致的冲突。然而，随着使用大语言模型（LLM）实例化的代理的出现，这种描述不能捕捉到AI安全的核心方面，因为现实世界中设计者与代理之间并没有一对一的对应关系，而且许多代理，无论是人工智能还是人类，都具有多样的价值观。因此，AI安全具有经济方面的问题，委托-代理问题可能会出现。

    AI Alignment is often presented as an interaction between a single designer and an artificial agent in which the designer attempts to ensure the agent's behavior is consistent with its purpose, and risks arise solely because of conflicts caused by inadvertent misalignment between the utility function intended by the designer and the resulting internal utility function of the agent. With the advent of agents instantiated with large-language models (LLMs), which are typically pre-trained, we argue this does not capture the essential aspects of AI safety because in the real world there is not a one-to-one correspondence between designer and agent, and the many agents, both artificial and human, have heterogeneous values. Therefore, there is an economic aspect to AI safety and the principal-agent problem is likely to arise. In a principal-agent problem conflict arises because of information asymmetry together with inherent misalignment between the utility of the agent and its principal, an
    
[^76]: 人体数字孪生: 一个总体规划

    Human Body Digital Twin: A Master Plan. (arXiv:2307.09225v1 [cs.AI])

    [http://arxiv.org/abs/2307.09225](http://arxiv.org/abs/2307.09225)

    人体数字孪生技术在医疗保健和健康领域具有巨大潜力，该论文提出了一个五级发展路线图，涵盖了可穿戴设备、数据收集、数据分析和决策系统等组成部分的开发，并强调了支持、安全、成本和伦理问题的重要性。

    

    人体数字孪生具有改变医疗保健和健康的潜力，但其负责和有效的实施需要考虑各种因素。本文概述了当前状态和未来前景，并提出了一个五级发展路线图。路线图涵盖了各种组成部分的发展，如可穿戴设备、数据收集、数据分析和决策系统。本文还强调了必须解决的支持、安全、成本和伦理问题，以确保人体数字孪生的负责和有效实施。所提出的路线图为指导未来发展提供了框架，并为探索人体数字孪生的未来提供了独特的视角，促进了这一快速发展领域中的新学科研究和创新解决方案。

    The human body DT has the potential to revolutionize healthcare and wellness, but its responsible and effective implementation requires consideration of various factors. This article presents a comprehensive overview of the current status and future prospects of the human body DT and proposes a five-level roadmap for its development. The roadmap covers the development of various components, such as wearable devices, data collection, data analysis, and decision-making systems. The article also highlights the necessary support, security, cost, and ethical considerations that must be addressed in order to ensure responsible and effective implementation of the human body DT. The proposed roadmap provides a framework for guiding future development and offers a unique perspective on the future of the human body DT, facilitating new interdisciplinary research and innovative solutions in this rapidly evolving field.
    
[^77]: RL4CO: 用于组合优化的广泛强化学习基准测试

    RL4CO: an Extensive Reinforcement Learning for Combinatorial Optimization Benchmark. (arXiv:2306.17100v1 [cs.LG])

    [http://arxiv.org/abs/2306.17100](http://arxiv.org/abs/2306.17100)

    RL4CO是一个用于组合优化的广泛强化学习基准测试，着重于可扩展性和泛化能力的评估，并展示了一些最新方法在样本效率和适应不同数据分布方面的表现相对较差，强调了对神经CO求解器性能的平衡评估的重要性。

    

    我们引入了RL4CO，这是一个广泛的强化学习（RL）用于组合优化（CO）的基准测试。RL4CO采用最先进的软件库和最佳实践，如模块化和配置管理，以便研究人员可以轻松修改神经网络架构、环境和算法。与现有的专注于特定任务（如旅行推销员问题）进行性能评估的方法不同，我们强调可扩展性和泛化能力对于各种优化任务的重要性。我们还系统地评估了各种模型在样本效率、零-shot泛化和适应不同数据分布方面的表现。我们的实验结果表明，一些最新的最先进方法在使用这些新指标进行评估时落后于之前的方法，这表明有必要更加平衡地评估神经CO求解器的性能。我们希望RL4CO能够为研究人员提供一个综合性的基准测试工具，以进一步推动强化学习在组合优化领域的研究。

    We introduce RL4CO, an extensive reinforcement learning (RL) for combinatorial optimization (CO) benchmark. RL4CO employs state-of-the-art software libraries as well as best practices in implementation, such as modularity and configuration management, to be efficient and easily modifiable by researchers for adaptations of neural network architecture, environments, and algorithms. Contrary to the existing focus on specific tasks like the traveling salesman problem (TSP) for performance assessment, we underline the importance of scalability and generalization capabilities for diverse optimization tasks. We also systematically benchmark sample efficiency, zero-shot generalization, and adaptability to changes in data distributions of various models. Our experiments show that some recent state-of-the-art methods fall behind their predecessors when evaluated using these new metrics, suggesting the necessity for a more balanced view of the performance of neural CO solvers. We hope RL4CO will 
    
[^78]: 离散空间的梯度信息质量多样性算法

    Gradient-Informed Quality Diversity for the Illumination of Discrete Spaces. (arXiv:2306.05138v1 [cs.AI])

    [http://arxiv.org/abs/2306.05138](http://arxiv.org/abs/2306.05138)

    本文提出了具有Gradient-Informed Discrete Emitter (ME-GIDE)的Map-Elites方法，利用梯度信息优化离散空间的搜索，相对于传统的质量多样性算法在离散问题中具有更好的性能。

    

    质量多样性算法旨在搜索大量各异且性能优越的解集，而不是一组局部最优解。尽管早期的质量多样性算法将目标和描述符函数视为黑盒函数，但引入了新工具以利用梯度信息，加速搜索并提高这些算法在连续输入空间上的整体性能。然而，广泛的应用涉及离散空间，例如药物发现或图像生成。探索这些空间具有挑战性，因为它们的组合规模很大，并且不能像连续空间那样使用梯度。我们使用具有梯度信息的离散发射器的 Map-Elites（ME-GIDE）扩展了对离散搜索空间的 QD 优化，该方法利用目标和描述符函数相对于其离散输入的梯度信息来提出梯度信息选择的解集。我们在一些离散基准问题上评估了 ME-GIDE，证明它优于将搜索空间视为黑盒的经典质量多样性算法。

    Quality Diversity (QD) algorithms have been proposed to search for a large collection of both diverse and high-performing solutions instead of a single set of local optima. While early QD algorithms view the objective and descriptor functions as black-box functions, novel tools have been introduced to use gradient information to accelerate the search and improve overall performance of those algorithms over continuous input spaces. However a broad range of applications involve discrete spaces, such as drug discovery or image generation. Exploring those spaces is challenging as they are combinatorially large and gradients cannot be used in the same manner as in continuous spaces. We introduce map-elites with a Gradient-Informed Discrete Emitter (ME-GIDE), which extends QD optimisation with differentiable functions over discrete search spaces. ME-GIDE leverages the gradient information of the objective and descriptor functions with respect to its discrete inputs to propose gradient-inform
    
[^79]: 语言模型知道自己在产生“幻觉”参考文献吗？

    Do Language Models Know When They're Hallucinating References?. (arXiv:2305.18248v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.18248](http://arxiv.org/abs/2305.18248)

    本研究针对大型语言模型中的“幻觉”参考文献进行了研究，通过简单的搜索引擎查询可可靠地识别这些幻觉。并且通过对同一语言模型进行黑盒查询来进行分类，揭示了幻觉参考文献的性质。

    

    目前最先进的语言模型以其“幻觉”参考文献而闻名。这些虚构的文章和书名引起了危害，对它们的使用造成了障碍，并引起了公众的反弹。尽管其他类型的语言模型幻觉也很重要，但我们将幻觉参考文献提出作为大型语言模型(LLMs)中幻觉研究的“果蝇”，因为它们特别容易研究。我们展示了简单的搜索引擎查询可可靠地识别此类幻觉，从而便于评估。为了开始剖析幻觉语言模型参考文献的性质，我们尝试使用对同一语言模型的黑盒查询来对其进行分类，而不借助任何外部资源。我们将“直接”查询的一致性检查与“间接”查询的一致性检查进行了比较，后者询问了附加的细节，如作品的作者。

    State-of-the-art language models (LMs) are famous for "hallucinating" references. These fabricated article and book titles lead to harms, obstacles to their use, and public backlash. While other types of LM hallucinations are also important, we propose hallucinated references as the "drosophila" of research on hallucination in large language models (LLMs), as they are particularly easy to study. We show that simple search engine queries reliably identify such hallucinations, which facilitates evaluation. To begin to dissect the nature of hallucinated LM references, we attempt to classify them using black-box queries to the same LM, without consulting any external resources. Consistency checks done with "direct" queries about whether the generated reference title is real (inspired by Kadavath et al. 2022, Lin et al. 2022, Manakul et al. 2023) are compared to consistency checks with "indirect" queries which ask for ancillary details such as the authors of the work. These consistency chec
    
[^80]: ChatGPT是否具有心智理论？

    Does ChatGPT have Theory of Mind?. (arXiv:2305.14020v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.14020](http://arxiv.org/abs/2305.14020)

    本文研究了ChatGPT在心智理论方面的能力。通过对比不同版本的ChatGPT在几个经典问题上的表现，发现ChatGPT-4比随机答案给出了更多正确答案，尽管这些答案往往基于错误的假设或无效的推理。

    

    心智理论（ToM）是理解人类思维和决策的能力，这种能力在人与人之间的社交互动中起着至关重要的作用，包括语言交流。本文探讨了最近ChatGPT系列中的大型语言模型在多大程度上具备ToM。我们对两个版本的ChatGPT提出了六个经典问题，这些问题涉及人类推理和决策中的偏见，并在多种提示策略下对结果进行了比较。虽然关于ChatGPT-3的结果有些不确定，但ChatGPT-4被证明比预期更经常给出正确答案，尽管正确答案往往是基于错误的假设或无效的推理得出的。

    Theory of Mind (ToM) is the ability to understand human thinking and decision-making, an ability that plays a crucial role in social interaction between people, including linguistic communication. This paper investigates to what extent recent Large Language Models in the ChatGPT tradition possess ToM. We posed six well-known problems that address biases in human reasoning and decision making to two versions of ChatGPT and we compared the results under a range of prompting strategies. While the results concerning ChatGPT-3 were somewhat inconclusive, ChatGPT-4 was shown to arrive at the correct answers more often than would be expected based on chance, although correct answers were often arrived at on the basis of false assumptions or invalid reasoning.
    
[^81]: 深度视觉和遗传生物测定用于少量图像数据珍稀物种分类

    Deep Visual-Genetic Biometrics for Taxonomic Classification of Rare Species. (arXiv:2305.06695v1 [cs.CV])

    [http://arxiv.org/abs/2305.06695](http://arxiv.org/abs/2305.06695)

    本文提出了一种利用对齐的视觉-遗传推理空间来提高少量图像数据珍稀物种分类的方法，该方法通过深度嵌入模型实现对齐，适用于提高稀有物种的长尾识别，并且可以显著有益于仅基于视觉的稀有物种识别。

    

    在生物应用中，视觉和遗传生物测定通常用于识别物种和个体。然而，在计算上增强少量图像数据稀有类别的视觉分类方面，该领域尚未进行尝试。因此，本文提出了对齐的视觉-遗传推理空间，旨在隐式编码跨域关联以提高性能。我们首次证明了这种对齐可以通过深度嵌入模型实现，并且该方法直接适用于提高稀有物种的长尾识别（LTR）。我们通过应用于32个物种、超过30,000个浮游有孔虫壳的显微图像并与独立的遗传数据样本一起使用来实验室展现了该概念的效力。最重要的是，对从业者而言，我们展示了视觉-遗传对齐可以显著有益于仅基于视觉的稀有物种识别。

    Visual as well as genetic biometrics are routinely employed to identify species and individuals in biological applications. However, no attempts have been made in this domain to computationally enhance visual classification of rare classes with little image data via genetics. In this paper, we thus propose aligned visual-genetic inference spaces with the aim to implicitly encode cross-domain associations for improved performance. We demonstrate for the first time that such alignment can be achieved via deep embedding models and that the approach is directly applicable to boosting long-tailed recognition (LTR) particularly for rare species. We experimentally demonstrate the efficacy of the concept via application to microscopic imagery of 30k+ planktic foraminifer shells across 32 species when used together with independent genetic data samples. Most importantly for practitioners, we show that visual-genetic alignment can significantly benefit visual-only recognition of the rarest speci
    
[^82]: 基于Transformer模型的单目视觉里程计：一种视频理解方法

    Transformer-based model for monocular visual odometry: a video understanding approach. (arXiv:2305.06121v1 [cs.CV])

    [http://arxiv.org/abs/2305.06121](http://arxiv.org/abs/2305.06121)

    本文提出了一种基于Transformer模型的TSformer-VO方法，将单目视觉里程计作为一项视频理解任务并通过时空自注意机制从视频片段中提取特征，以实现端到端的运动估计，达到了最新成果。

    

    在移动机器人和自主车辆中，给定单个摄像机图像估计摄像机姿势是一项传统任务。这个问题称为单目视觉里程计，通常依赖于需要针对特定场景进行工程化的几何方法。经过适当训练和足够的数据可用性，深度学习方法已被证明是具有普适性的。Transformer架构已统治了自然语言处理和计算机视觉任务的最前沿，例如图像和视频理解。本文将单目视觉里程计作为一项视频理解任务进行处理，以估计6-DoF摄像机的姿势，提出了基于时空自注意机制的TSformer-VO模型，以端到端的方式从视频片段中提取特征并估计运动，与几何和深度学习方法相比，我们的方法在KITTI数据集上取得了有竞争力的最新成果。

    Estimating the camera pose given images of a single camera is a traditional task in mobile robots and autonomous vehicles. This problem is called monocular visual odometry and it often relies on geometric approaches that require engineering effort for a specific scenario. Deep learning methods have shown to be generalizable after proper training and a considerable amount of available data. Transformer-based architectures have dominated the state-of-the-art in natural language processing and computer vision tasks, such as image and video understanding. In this work, we deal with the monocular visual odometry as a video understanding task to estimate the 6-DoF camera's pose. We contribute by presenting the TSformer-VO model based on spatio-temporal self-attention mechanisms to extract features from clips and estimate the motions in an end-to-end manner. Our approach achieved competitive state-of-the-art performance compared with geometry-based and deep learning-based methods on the KITTI
    
[^83]: LaCViT：一种面向标签的对比训练框架，提高视觉Transformer的表示空间的等性

    LaCViT: A Label-aware Contrastive Training Framework for Vision Transformers. (arXiv:2303.18013v1 [cs.CV])

    [http://arxiv.org/abs/2303.18013](http://arxiv.org/abs/2303.18013)

    LaCViT是一种针对视觉Transformer预训练表示空间的各向等性不足问题，提高其表示空间等性的面向标签的对比训练框架，经过实验证明其在五个标准图像分类数据集中具有卓越的性能。

    

    视觉 Transformer 已经在处理计算机视觉任务时表现出了惊人的效果，这是由于其模拟长时间的特征依赖能力。通过使用大规模的训练数据和各种自监督信号（例如，遮蔽随机块），视觉 Transformer 在 ImageNet-1k 和 CIFAR-10 等几个基准数据集上提供了最先进的性能。然而，这些基于通用大规模图像语料库预训练的视觉Transformer只能产生各向异性表示空间，限制了它们在目标下游任务中的通用性和可转移性。在本文中，我们提出了一种简单而有效的面向标签的对比训练框架 LaCViT，它提高了视觉Transformer预训练表示空间的等性，从而实现了更有效的转移学习。通过对五个标准图像分类数据集的实验，我们证明了LaCViT训练的模型在各种图像分类任务中都具有卓越的性能。

    Vision Transformers have been incredibly effective when tackling computer vision tasks due to their ability to model long feature dependencies. By using large-scale training data and various self-supervised signals (e.g., masked random patches), vision transformers provide state-of-the-art performance on several benchmarking datasets, such as ImageNet-1k and CIFAR-10. However, these vision transformers pretrained over general large-scale image corpora could only produce an anisotropic representation space, limiting their generalizability and transferability to the target downstream tasks. In this paper, we propose a simple and effective Label-aware Contrastive Training framework LaCViT, which improves the isotropy of the pretrained representation space for vision transformers, thereby enabling more effective transfer learning amongst a wide range of image classification tasks. Through experimentation over five standard image classification datasets, we demonstrate that LaCViT-trained m
    
[^84]: 质量多样性变形器：基于决策Transformer生成行为条件下的轨迹

    The Quality-Diversity Transformer: Generating Behavior-Conditioned Trajectories with Decision Transformers. (arXiv:2303.16207v1 [cs.NE])

    [http://arxiv.org/abs/2303.16207](http://arxiv.org/abs/2303.16207)

    该论文提出了一种基于质量多样性算法和 Transformer 的方法，通过两种机制以实现质量一致的生成行为条件下的轨迹。

    

    在神经进化计算的背景下，质量多样性算法通过依赖行为空间的定义来生成各种不同和高效的策略集合，取得了很好的效果。然而，在不确定的环境中，会有两个问题出现。第一，策略可能缺乏鲁棒性和可重复性，即在略微不同的情况下，多个 episodes 往往会导致非常不同的行为结果。第二，由于策略集的离散性，解决方案的变化是不连续的。本文提出了一种新的方法来实现基于行为条件下的轨迹生成，其基于两个机制：首先是 MAP-Elites Low-Spread (ME-LS)，它限制了选择那些在行为空间上最一致的解决方案。其次是质量多样性变形器 (QDT)，它是基于 Transformer 的。

    In the context of neuroevolution, Quality-Diversity algorithms have proven effective in generating repertoires of diverse and efficient policies by relying on the definition of a behavior space. A natural goal induced by the creation of such a repertoire is trying to achieve behaviors on demand, which can be done by running the corresponding policy from the repertoire. However, in uncertain environments, two problems arise. First, policies can lack robustness and repeatability, meaning that multiple episodes under slightly different conditions often result in very different behaviors. Second, due to the discrete nature of the repertoire, solutions vary discontinuously. Here we present a new approach to achieve behavior-conditioned trajectory generation based on two mechanisms: First, MAP-Elites Low-Spread (ME-LS), which constrains the selection of solutions to those that are the most consistent in the behavior space. Second, the Quality-Diversity Transformer (QDT), a Transformer-based 
    
[^85]: 您的扩散模型暗中是一种零样本分类器。

    Your Diffusion Model is Secretly a Zero-Shot Classifier. (arXiv:2303.16203v1 [cs.LG])

    [http://arxiv.org/abs/2303.16203](http://arxiv.org/abs/2303.16203)

    扩散模型的密度估计可以被用作零样本分类，作者的生成式分类方法在各种基准测试中取得强大的结果，并具有更强的多模式关系推理能力。

    

    最近大规模的文本到图像扩散模型极大地增强了我们的基于文本生成图像的能力。这些模型可以为大量提示生成逼真的图像，并展示出令人印象深刻的组合泛化能力。几乎所有的用例到目前为止都只关注抽样，然而，扩散模型还可以提供有用于图像生成之外的条件密度估计。在本文中，我们展示了类似于Stable Diffusion的大规模文本到图像扩散模型的密度估计可以被利用来执行零样本分类，而无需额外的训练。我们的生成式分类方法在各种基准测试中取得了强大的结果，并优于从扩散模型中提取知识的替代方法。我们还发现，我们基于扩散的方法比竞争性的对比方法具有更强的多模式关系推理能力。最后，我们评估了我们方法的可解释性，并呈现了定性结果，证明它学习了有意义的图像-文本对齐。

    The recent wave of large-scale text-to-image diffusion models has dramatically increased our text-based image generation abilities. These models can generate realistic images for a staggering variety of prompts and exhibit impressive compositional generalization abilities. Almost all use cases thus far have solely focused on sampling; however, diffusion models can also provide conditional density estimates, which are useful for tasks beyond image generation. In this paper, we show that the density estimates from large-scale text-to-image diffusion models like Stable Diffusion can be leveraged to perform zero-shot classification without any additional training. Our generative approach to classification attains strong results on a variety of benchmarks and outperforms alternative methods of extracting knowledge from diffusion models. We also find that our diffusion-based approach has stronger multimodal relational reasoning abilities than competing contrastive approaches. Finally, we eva
    
[^86]: 人工智能心理学中的“正确答案”

    "Correct answers" from the psychology of artificial intelligence. (arXiv:2302.07267v3 [cs.HC] UPDATED)

    [http://arxiv.org/abs/2302.07267](http://arxiv.org/abs/2302.07267)

    本文使用OpenAI的GPT3.5模型重新复制了Many Labs 2复制项目中的14项研究，其中8项研究的结果被成功复制。然而，对于剩下的6项研究，GPT3.5以极其预定的方式回答了调查问题，导致无法分析这些研究。

    This paper replicates 14 studies from the Many Labs 2 replication project with OpenAI's text-davinci-003 model, and successfully replicates the results of 8 studies. However, for the remaining 6 studies, GPT3.5 answered survey questions in an extremely predetermined way, making it impossible to analyze these studies.

    大型语言模型的能力已经大大增强。这种AI系统的一个提出的应用是支持社会和认知科学中的数据收集，目前完美的实验控制是不可行的，而大规模、代表性数据集的收集通常是昂贵的。在本文中，我们使用OpenAI的text-davinci-003模型（俗称GPT3.5）重新复制了Many Labs 2复制项目中的14项研究。我们通过将每项研究的调查作为文本输入，从GPT3.5的默认设置中收集了响应。在我们可以分析的八项研究中，我们的GPT样本复制了原始结果的37.5%以及Many Labs 2结果的37.5%。出乎意料的是，我们无法像预先注册的计划那样分析剩下的六项研究。这是因为对于这六项研究中的每一项，GPT3.5以极其预定的方式回答了调查问题（无论是因变量还是条件变量）：一个未知的

    Large Language Models have vastly grown in capabilities. One proposed application of such AI systems is to support data collection in the social and cognitive sciences, where perfect experimental control is currently unfeasible and the collection of large, representative datasets is generally expensive. In this paper, we re-replicate 14 studies from the Many Labs 2 replication project with OpenAI's text-davinci-003 model, colloquially known as GPT3.5. We collected responses from the default setting of GPT3.5 by inputting each study's survey as text. Among the eight studies we could analyse, our GPT sample replicated 37.5% of the original results as well as 37.5% of the Many Labs 2 results. Unexpectedly, we could not analyse the remaining six studies as we had planned in our pre-registration. This was because for each of these six studies, GPT3.5 answered at least one of the survey questions (either a dependent variable or a condition variable) in an extremely predetermined way: an unex
    
[^87]: DWRSeg:重新思考实时语义分割中多尺度上下文信息的高效获取方式

    DWRSeg: Rethinking Efficient Acquisition of Multi-scale Contextual Information for Real-time Semantic Segmentation. (arXiv:2212.01173v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.01173](http://arxiv.org/abs/2212.01173)

    DWRSeg重新思考了实时语义分割中获取多尺度上下文信息的方法，提出了一种高效的多尺度特征提取方法，通过将原始单步方法分解为区域残余化和语义残余化两个步骤，简化了多速率深度空洞卷积的角色，并提高了特征提取的效率。

    

    目前许多方法直接采用多速率的深度空洞卷积来同时从一个输入特征映射中捕获多尺度的上下文信息，从而提高实时语义分割的特征提取效率。然而，这种设计可能由于不合理的结构和超参数而导致难以访问多尺度的上下文信息。为了降低获取多尺度上下文信息的难度，我们提出了一种高效的多尺度特征提取方法，将原始的单步方法分解为两个步骤：区域残余化和语义残余化。在这种方法中，多速率的深度空洞卷积在特征提取方面扮演了更简单的角色：在第二步中，根据第一步提供的每个简洁的区域形式特征映射，对每个期望的感受野进行简单的基于语义的形态滤波，以提高其效率。

    Many current works directly adopt multi-rate depth-wise dilated convolutions to capture multi-scale contextual information simultaneously from one input feature map, thus improving the feature extraction efficiency for real-time semantic segmentation. However, this design may lead to difficult access to multi-scale contextual information because of the unreasonable structure and hyperparameters. To lower the difficulty of drawing multi-scale contextual information, we propose a highly efficient multi-scale feature extraction method, which decomposes the original single-step method into two steps, Region Residualization-Semantic Residualization.In this method, the multi-rate depth-wise dilated convolutions take a simpler role in feature extraction: performing simple semantic-based morphological filtering with one desired receptive field in the second step based on each concise feature map of region form provided by the first step, to improve their efficiency. Moreover, the dilation rate
    
[^88]: 未来共生创造的路径

    Pathway to Future Symbiotic Creativity. (arXiv:2209.02388v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2209.02388](http://arxiv.org/abs/2209.02388)

    本文提出了人机共生艺术创作的发展路径，从模仿人类艺术家逐渐发展为具备独立创作能力的机器艺术家。在这条路径上，需要机器理解人类的心理状态，并通过沉浸式环境和元宇宙的发展实现双向沟通，以实现共生艺术创作。

    

    本报告提出了我们对人机共生艺术创作发展路径的全面观点。我们提出了一个创造系统的分类，其中包括5个层级，展示了创造力从模仿人类艺术家（图灵艺术家）逐渐发展为具备独立创作能力的机器艺术家的路径。我们首先概述了图灵艺术家的局限性，然后重点关注了顶层的两级系统，机器艺术家，强调了机器与人类在艺术创作中的交流。在艺术创作中，机器需要理解人类的心理状态，包括欲望、欣赏和情感，而人类也需要理解机器的创造能力和局限性。沉浸式环境的快速发展以及进一步演变成元宇宙的新概念，为艺术家与艺术表现环境之间的双向沟通提供了前所未有的灵活性，实现了共生艺术创作。通过研究最新的...

    This report presents a comprehensive view of our vision on the development path of the human-machine symbiotic art creation. We propose a classification of the creative system with a hierarchy of 5 classes, showing the pathway of creativity evolving from a mimic-human artist (Turing Artists) to a Machine artist in its own right. We begin with an overview of the limitations of the Turing Artists then focus on the top two-level systems, Machine Artists, emphasizing machine-human communication in art creation. In art creation, it is necessary for machines to understand humans' mental states, including desires, appreciation, and emotions, humans also need to understand machines' creative capabilities and limitations. The rapid development of immersive environment and further evolution into the new concept of metaverse enable symbiotic art creation through unprecedented flexibility of bi-directional communication between artists and art manifestation environments. By examining the latest se
    
[^89]: 向视觉可管理学习迈进：一个用于可管理分割和识别的基准。 (arXiv:2203.14092v2 [cs.CV] UPDATED)

    Towards Visual Affordance Learning: A Benchmark for Affordance Segmentation and Recognition. (arXiv:2203.14092v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2203.14092](http://arxiv.org/abs/2203.14092)

    该论文介绍了一个大规模的多视角RGBD视觉可管理学习数据集，其中包含了37个对象类别的47210个图像，并且每个图像都带有15个视觉可管理类别的注释。

    

    对于计算机视觉中的识别、检测和分割任务，对象的物理和纹理属性已得到广泛研究。许多数据集，如大规模的ImageNet，已经被提出用于使用数据饥饿的深度神经网络进行特征学习和手工特征提取。为了智能地与对象进行交互，机器人和智能机器需要除了传统的物理/纹理属性之外的推理能力，以及理解/学习被称为视觉可管理的视觉提示，用于可管理的识别、检测和分割。到目前为止，还没有公开可用的用于视觉可管理理解和学习的大规模数据集。在本文中，我们介绍了一个大规模的多视角RGBD视觉可管理学习数据集，这是一个包含37个对象类别的47210个RGBD图像的基准，每个图像都带有15个视觉可管理类别的注释。据我们所知，这是有史以来第一个也是最大的多视角RGBD视觉可管理学习数据集。

    The physical and textural attributes of objects have been widely studied for recognition, detection and segmentation tasks in computer vision.~A number of datasets, such as large scale ImageNet, have been proposed for feature learning using data hungry deep neural networks and for hand-crafted feature extraction. To intelligently interact with objects, robots and intelligent machines need the ability to infer beyond the traditional physical/textural attributes, and understand/learn visual cues, called visual affordances, for affordance recognition, detection and segmentation. To date there is no publicly available large dataset for visual affordance understanding and learning. In this paper, we introduce a large scale multi-view RGBD visual affordance learning dataset, a benchmark of 47210 RGBD images from 37 object categories, annotated with 15 visual affordance categories. To the best of our knowledge, this is the first ever and the largest multi-view RGBD visual affordance learning 
    

