# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [FollowNet: A Comprehensive Benchmark for Car-Following Behavior Modeling.](http://arxiv.org/abs/2306.05381) | 本论文介绍了一个公共基准测试数据集，用于汽车跟随行为建模，该数据集包含逾80K个汽车跟随事件，旨在填补此领域的数据缺口并促进微观交通流建模的发展。 |
| [^2] | [The ADAIO System at the BEA-2023 Shared Task on Generating AI Teacher Responses in Educational Dialogues.](http://arxiv.org/abs/2306.05360) | 本文介绍了ADAIO团队在BEA-2023共享任务中的系统方案，使用OpenAI GPT-3评估基准模型并在教育对话中生成AI教师回应。通过少量提供提示信息，利用OpenAI的text-davinci-003模型在竞赛中获得第二名，并突出了大型语言模型在AI教师角色中的少量提示学习能力。 |
| [^3] | [Trustworthy Sensor Fusion against Inaudible Command Attacks in Advanced Driver-Assistance System.](http://arxiv.org/abs/2306.05358) | 本文提出了多模态融合框架（MFF），利用VGG系列神经网络实现异构音频-视觉模态的融合。在实验中，MFF实现了92.25%的检测准确率，并证明MFF在不同模型不确定性条件下具有可靠性。 |
| [^4] | [Unsupervised Compositional Concepts Discovery with Text-to-Image Generative Models.](http://arxiv.org/abs/2306.05357) | 本论文提出了一种无监督的方法，用于从图像中自动地发现不同的生成概念，并且这些生成概念可以被用于重新组合和生成新的艺术和混合图像，并作为一种表示用于下游的分类任务。 |
| [^5] | [Actively learning a Bayesian matrix fusion model with deep side information.](http://arxiv.org/abs/2306.05331) | 本文提出了一种主动学习方法，通过自适应采样实验刺激来高效地学习带有深度信息的贝叶斯矩阵分解模型，相比于被动的基线方法，效率显著提高。 |
| [^6] | [Advancing Italian Biomedical Information Extraction with Large Language Models: Methodological Insights and Multicenter Practical Application.](http://arxiv.org/abs/2306.05323) | 该研究创建了意大利神经精神命名实体识别数据集，并使用巨型语言模型开发出多中心识别模型，整体 F1得分为84.77%。该模型将帮助临床从业者从非结构化的医疗记录中自动提取信息。 |
| [^7] | [Bayesian Optimisation of Functions on Graphs.](http://arxiv.org/abs/2306.05304) | 本论文提出了一种在通用的大规模和潜在未知图上定义函数的贝叶斯优化算法，并通过学习适当的图内核，适应目标函数行为。 |
| [^8] | [Habits of Mind: Reusing Action Sequences for Efficient Planning.](http://arxiv.org/abs/2306.05298) | 该论文提出了一种灵活的贝叶斯行动分块机制，通过充分利用经过练习的行动序列来加速和提高规划的准确性，可嵌入蒙特卡罗树搜索规划器中。在物理构造任务上的实验结果表明了该方案的优点。 |
| [^9] | [One shot learning based drivers head movement identification using a millimetre wave radar sensor.](http://arxiv.org/abs/2306.05291) | 通过使用小型毫米波雷达传感器从司机的头部动作中收集信号，并基于一次学习技术设计分类器，可以高效地识别司机的不同动作类型，实验准确率超过95%。 |
| [^10] | [Simple and Controllable Music Generation.](http://arxiv.org/abs/2306.05284) | 本文提出了 MusicGen，一个单一的语言模型，可以在条件描述或旋律特征控制下生成高质量的样本，并且在标准的文本到音乐基准上的实证研究中，该方法优于其他基线模型。 |
| [^11] | [Fault Identification of Rotating Machinery Based on Dynamic Feature Reconstruction Signal Graph.](http://arxiv.org/abs/2306.05281) | 本文提出了一种动态特征重构信号图法，在旋转机械故障诊断模型中取得了关键进展，能够动态地选择最优子带的特征系数矩阵，进行适应性信号重构，并从中提取深层特征。 |
| [^12] | [Extensive Evaluation of Transformer-based Architectures for Adverse Drug Events Extraction.](http://arxiv.org/abs/2306.05276) | 本文对19种基于Transformer的ADE提取模型进行广泛评估，并在具有不同非正式程度的数据集上比较它们的性能。此外，我们使用了成熟的特征重要性技术（SHAP）进一步分析了模型的性能。 |
| [^13] | [Factorized Contrastive Learning: Going Beyond Multi-view Redundancy.](http://arxiv.org/abs/2306.05268) | 本论文提出了FactorCL，一种新的多模态表示学习方法，不仅考虑跨模态共享信息，还能捕捉跨模态唯一的任务相关信息。 |
| [^14] | [Unscented Autoencoder.](http://arxiv.org/abs/2306.05256) | 本文提出了一种新的自编码器模型，名为非线性无损自编码器（UAE），它使用确定性采样的有限一组统计量来提高后验表示，从而获得更高质量的重建。同时，本文使用Wasserstein分布度量替换KL散度，实现更尖锐的后验。 |
| [^15] | [Dealing with Semantic Underspecification in Multimodal NLP.](http://arxiv.org/abs/2306.05240) | 语义未确定性在语言学中很重要，但多模态系统还没有解决好这个问题 |
| [^16] | [Improving Long Context Document-Level Machine Translation.](http://arxiv.org/abs/2306.05183) | 该论文提出了一种新的受限注意力机制来提高长篇文本机器翻译的质量。 |
| [^17] | [RRWKV: Capturing Long-range Dependencies in RWKV.](http://arxiv.org/abs/2306.05176) | 本文介绍了一种新的RRWKV架构，它在保持记忆和计算效率的同时，通过加入回顾能力有效地捕捉长距离依赖关系。 |
| [^18] | [Robot Task Planning Based on Large Language Model Representing Knowledge with Directed Graph Structures.](http://arxiv.org/abs/2306.05171) | 该论文提出了一种基于LLM和有向图的机器人任务规划方法，使用LLM prompt template Think_Net_Prompt来表示结构化的专业知识。通过渐进分解任务并生成任务树以及解耦机器人任务规划，使任务规划过程更加灵活。研究结果表明，在处理指定的代码格式、理解任务和子任务之间的关系以及从文本描述中提取参数方面表现良好。 |
| [^19] | [Is AI the better programming partner? Human-Human Pair Programming vs. Human-AI pAIr Programming.](http://arxiv.org/abs/2306.05153) | 人工智能与人类程序员共同开发可以通过设计良好的AI编程助手，增强双方合作的生产力。 |
| [^20] | [Bayesian Optimization of Expensive Nested Grey-Box Functions.](http://arxiv.org/abs/2306.05150) | 本文提出基于乐观主义的算法来解决嵌套黑白箱函数优化问题，相比传统黑箱优化方法显著提高全局最优解速度。 |
| [^21] | [Gradient-Informed Quality Diversity for the Illumination of Discrete Spaces.](http://arxiv.org/abs/2306.05138) | 本文提出了具有Gradient-Informed Discrete Emitter (ME-GIDE)的Map-Elites方法，利用梯度信息优化离散空间的搜索，相对于传统的质量多样性算法在离散问题中具有更好的性能。 |
| [^22] | [Does Image Anonymization Impact Computer Vision Training?.](http://arxiv.org/abs/2306.05135) | 本文探讨了图像匿名化对于计算机视觉模型训练的影响，研究表明传统图像匿名化对最终模型性能造成实质性影响，特别是对全身进行匿名化时。然而，逼真匿名化可以缓解性能下降，尤其是面部匿名化表现较好。 |
| [^23] | [Explainable Predictive Maintenance.](http://arxiv.org/abs/2306.05120) | 本文探讨了工业4.0框架下预测性维护领域中可解释性的重要性和现有XAI方法与特定解释需求之间的差距。 |
| [^24] | [On Search Strategies for Document-Level Neural Machine Translation.](http://arxiv.org/abs/2306.05116) | 本文探讨了如何在搜索过程中最好地利用文档级神经机器翻译模型，比较了文献中的不同解码方案和作者提出的方案，并发现针对某些语言现象时，常用的解码策略不能够取得较好的性能。 |
| [^25] | [FheFL: Fully Homomorphic Encryption Friendly Privacy-Preserving Federated Learning with Byzantine Users.](http://arxiv.org/abs/2306.05112) | 本论文介绍了一种新的联邦学习算法，采用FHE加密技术，既可以保护模型更新的隐私，又可以防止恶意用户破坏全局模型。 |
| [^26] | [PandaLM: An Automatic Evaluation Benchmark for LLM Instruction Tuning Optimization.](http://arxiv.org/abs/2306.05087) | PandaLM是一个评估LLM指令调优的自动基准，它能够区分最优模型，并关注于主观因素。 |
| [^27] | [The Importance of Time in Causal Algorithmic Recourse.](http://arxiv.org/abs/2306.05082) | 因果算法补救需要纳入时间维度，以提高推荐的合理性和可靠性。 |
| [^28] | [A Causal Framework for Decomposing Spurious Variations.](http://arxiv.org/abs/2306.05071) | 本论文提出了一种因果框架，用于分解伪变异，包括虚假性图表和理论框架，能够在真假相关关系上帮助区分直接效应和间接效应。 |
| [^29] | [Capturing (Optimal) Relaxed Plans with Stable and Supported Models of Logic Programs.](http://arxiv.org/abs/2306.05069) | 该论文介绍了一个新的方法，通过逻辑程序的稳定和支持模型，捕获能够产生松弛计划的行动子集，实验证明该方法可以提高计算松弛计划的效率，并且诊断编码是一种优秀的方法。 |
| [^30] | [Shedding light on underrepresentation and Sampling Bias in machine learning.](http://arxiv.org/abs/2306.05068) | 文章讨论了机器学习中的偏见对公正性的影响，提出抽样偏差的变体：样本量偏差和代表性不足偏差，揭示歧视可以分解为方差、偏差和噪声，并挑战了通常被接受的缓解方法。 |
| [^31] | [Improving Visual Prompt Tuning for Self-supervised Vision Transformers.](http://arxiv.org/abs/2306.05067) | 本文研究了自监督视觉Transformer中视觉提示调整方法的提升，并确定了提示记号插入后续图块而非第一个图块的最佳位置。提出的方法能有效地减少确定最佳提示记号块位置的成本。 |
| [^32] | [Causal Fairness for Outcome Control.](http://arxiv.org/abs/2306.05066) | 本论文研究了一种特定的决策任务叫做结果控制，针对涉及到刑事司法、福利、临床决策以及公共卫生等多个方面，提出了因果公平的概念以及一组因果工具和技术来推断结果控制中的公平性。 |
| [^33] | [Learning A Foundation Language Model for Geoscience Knowledge Understanding and Utilization.](http://arxiv.org/abs/2306.05064) | 本文首次提出了一个地球科学领域的大型语言模型K2，并开发了各种资源以进一步促进其在地球科学领域中的研究和应用，包括第一个地球科学教学调音数据集GeoSignal和第一个地球科学基准测试GeoBenchmark。我们使用了完整的方法将预先训练的通用领域LLM LLaMA-7B 模型适应到地球科学领域。 |
| [^34] | [Neuro-Symbolic Approaches for Context-Aware Human Activity Recognition.](http://arxiv.org/abs/2306.05058) | 本文提出了一种采用语义损失函数的新方法，避免在分类过程中使用符号推理，可以解决现有上下文感知HAR的NeSy方法在部署和泛化能力方面的局限性。 |
| [^35] | [Active Inference in Hebbian Learning Networks.](http://arxiv.org/abs/2306.05053) | 本文研究了具有局部Hebbian可塑性的仿脑神经群体如何执行主动推理，通过两个不同的Hebbian神经元组成的网络来生成捕捉环境动态的生成模型，使用Mountain Car环境进行实验研究，结果表明所提出的Hebbian AIF方法优于使用Q-learning，同时不需要回放缓冲区。 |
| [^36] | [Spain on Fire: A novel wildfire risk assessment model based on image satellite processing and atmospheric information.](http://arxiv.org/abs/2306.05045) | 提出了一种基于卫星图像处理和大气信息的森林火灾风险评估模型，可预测森林火灾的经济和生态影响，并协助管理者对西班牙的危险地区进行资源分配和决策。 |
| [^37] | [Energy-Efficient Downlink Semantic Generative Communication with Text-to-Image Generators.](http://arxiv.org/abs/2306.05041) | 本论文提出了一种语义生成通信框架，在该框架中，生成型用户利用文本到图像生成器来创建本地图像，从而减少基站下行传输能量消耗，但会增加用户能源消耗。通过生成用户选择算法，总能耗可以降低高达54%。 |
| [^38] | [Mapping the Challenges of HCI: An Application and Evaluation of ChatGPT and GPT-4 for Cost-Efficient Question Answering.](http://arxiv.org/abs/2306.05036) | 本文探讨了 ChatGPT 和 GPT-4 两个大型语言模型在实际情况下的运用和性能表现，通过以人机交互领域的研究挑战为例，结论是 ChatGPT 和 GPT-4 的组合是分析文本语料库的一种非常高效且节省成本的方法。 |
| [^39] | [Progression Cognition Reinforcement Learning with Prioritized Experience for Multi-Vehicle Pursuit.](http://arxiv.org/abs/2306.05016) | 本文提出了一种基于优先经验的渐进认知强化学习方法，在城市多交叉口动态交通场景下解决了多车辆追逐问题，并显著提高了追逐成功率。 |
| [^40] | [VIFS: An End-to-End Variational Inference for Foley Sound Synthesis.](http://arxiv.org/abs/2306.05004) | 本文提出了一种名为VIFS的端到端变分推理用于Foley音效合成的问题，通过一个“类别到声音”的方法生成多样化声音，并应用各种技术进行改良，包括PhaseAug和Avocado。 |
| [^41] | [A Rapid Review of Responsible AI frameworks: How to guide the development of ethical AI.](http://arxiv.org/abs/2306.05003) | 该论文快速评估了数个提供指导原则，指南和/或工具的负责任AI框架，并发现其中极少数框架提供支持工具，且没有可同时支持技术和非技术利益相关方实现现实项目的“笼统”框架。 |
| [^42] | [Blockage Prediction in Directional mmWave Links Using Liquid Time Constant Network.](http://arxiv.org/abs/2306.04997) | 本论文提出使用液态时间常数（LTC）网络，仅使用接收信号功率作为系统输入来预测毫米波链路中障碍的未来状态，实验结果表明LTC网络具有较高的准确性，可以带来更可靠和低延迟的通信。 |
| [^43] | [CoCo: A Coupled Contrastive Framework for Unsupervised Domain Adaptive Graph Classification.](http://arxiv.org/abs/2306.04979) | CoCo是一种耦合对比图表示学习框架，其中包含一个图卷积网络和一个分层图内核网络，通过耦合对比学习减少领域差异，用于无监督领域自适应图分类。 |
| [^44] | [Conservative Prediction via Data-Driven Confidence Minimization.](http://arxiv.org/abs/2306.04974) | 该论文提出了一种可以在处理不常见样本时推迟到人类判断的保守模型方法。该方法使用基于数据驱动置信度最小化（DCM）的算法，在辅助数据集中选择感兴趣的OOD（Out-of-Distribution）区域的样本，进而实现可靠地分离ID（In-Distribution）和OOD输入。 |
| [^45] | [arXiv4TGC: Large-Scale Datasets for Temporal Graph Clustering.](http://arxiv.org/abs/2306.04962) | arXiv4TGC提供了一组适用于大规模时态图聚类的新颖学术数据集，解决了缺乏可靠数据集来评估聚类性能的挑战。 |
| [^46] | [FedMLSecurity: A Benchmark for Attacks and Defenses in Federated Learning and LLMs.](http://arxiv.org/abs/2306.04959) | 本文介绍了一个名为FedMLSecurity的基准测试，它可以模拟在联邦学习中可能出现的对抗攻击并提供相应的防御策略。该测试对各种机器学习模型和联合优化器都可以适用，并且能够轻松应用于大规模语言模型中。 |
| [^47] | [Degraded Polygons Raise Fundamental Questions of Neural Network Perception.](http://arxiv.org/abs/2306.04955) | 本文研究了神经网络在识别具有不同程度边缘降解的规则多边形时的性能和行为，发现存在基本问题，揭示了人机视觉差距的另一个角度。 |
| [^48] | [ShuttleSet: A Human-Annotated Stroke-Level Singles Dataset for Badminton Tactical Analysis.](http://arxiv.org/abs/2306.04948) | ShuttleSet是一份羽毛球单打比赛的拍级数据集，其中包含104场比赛、3,685轮比赛、36,492个拍击，并涵盖了27名排名前列的男子和女子单打选手。这些拍级记录将促进人工智能在体育分析领域的发展。 |
| [^49] | [Knowledge Detection by Relevant Question and Image Attributes in Visual Question Answering.](http://arxiv.org/abs/2306.04938) | 本研究提出了一种在视觉问答中提取问题相关知识的方法，避免了过度训练的模型错误地回答与图像无关的问题。 |
| [^50] | [covLLM: Large Language Models for COVID-19 Biomedical Literature.](http://arxiv.org/abs/2306.04926) | 使用大型语言模型开发了一种名为covLLM的工具，用于协助临床医生评估COVID-19文献。covLLM可以汇总和提取相关信息，帮助医生更好地应对COVID-19疫情。 |
| [^51] | [Test-Time Style Shifting: Handling Arbitrary Styles in Domain Generalization.](http://arxiv.org/abs/2306.04911) | 本文提出了测试时间风格转换（test-time style shifting）的方法，使得模型能够有效地处理领域泛化任务中任意风格的问题，同时避免了额外的模型更新。 |
| [^52] | [Multi-level Protein Representation Learning for Blind Mutational Effect Prediction.](http://arxiv.org/abs/2306.04899) | 本文提出了一个新的预训练框架，通过级联蛋白一级和三级结构的序列和几何分析器，引导变异方向，用于预测蛋白质变异体的效应，并在公共数据库上取得了优于现有方法的预测精度。 |
| [^53] | [Big-data-driven and AI-based framework to enable personalization in wireless networks.](http://arxiv.org/abs/2306.04887) | 本论文提出了一种基于大数据和人工智能的框架，通过利用实时用户反馈和多目标优化模型来实现无线网络的个性化服务，优化服务质量和用户满意度。 |
| [^54] | [Expanding Scope: Adapting English Adversarial Attacks to Chinese.](http://arxiv.org/abs/2306.04874) | 本文研究将英文的对抗攻击方法适用于中文上，并证明了这些方法可以生成高质量的中文对抗实例。通过关注中文的语言特点，生成的对抗实例可以实现高流畅度和语义一致性，从而可以用来提高中文NLP模型的对抗鲁棒性。 |
| [^55] | [A Systematic Literature Review on Client Selection in Federated Learning.](http://arxiv.org/abs/2306.04862) | 联邦学习中客户端选择的主要挑战是异质性、资源分配、通信成本和公平性。客户选择方案旨在解决这些挑战，最常用的指标是测试准确性与通信轮次。 |
| [^56] | [Learned spatial data partitioning.](http://arxiv.org/abs/2306.04846) | 本文介绍了一种通过机器学习技术学习空间数据分区的方法，在强化学习的框架下开发了深度强化学习算法。实验表明该算法能够有效地加速距离连接查询，缩短工作负载运行时间高达59.4％。 |
| [^57] | [Empowering Counterfactual Reasoning over Graph Neural Networks through Inductivity.](http://arxiv.org/abs/2306.04835) | 本研究引入了一种归纳算法INDUCE来增强图神经网络的反事实推理能力，改进了现有算法中存在的限制，通过在多个数据集上进行广泛的实验证明了其可行性。 |
| [^58] | [Unified Embedding Based Personalized Retrieval in Etsy Search.](http://arxiv.org/abs/2306.04833) | 本论文提出了一种将图形、转换和基于术语的嵌入结合起来的统一嵌入模型，并利用端到端训练模型进行个性化检索，以解决Etsy搜索中的语义差距问题。同时，本文分享了特征工程、硬负采样策略和应用变压器模型的新策略，以构建具有工业规模的模型来改善整体搜索体验。 |
| [^59] | [Revisiting Inferential Benchmarks for Knowledge Graph Completion.](http://arxiv.org/abs/2306.04814) | 该论文提出了一种新的KG完成基准设计方法，用于评估模型学习推理模式的能力。他们的方法基于一组逻辑规则，使得缺失的事实是规则应用的结果。使用他们的基准FB15k-237，表明它比以前的基准更具有区分度，可以评估模型推广到新模式的能力。 |
| [^60] | [Human in the Loop Novelty Generation.](http://arxiv.org/abs/2306.04813) | 该论文提出了一种新的创新生成方法，使用环境的抽象模型而不需要人类专业知识来生成新的新颖性。这可以产生更大的、通常是无限的新颖性空间，但需要人类的指导来选择和过滤这些新颖性。 |
| [^61] | [Generative Text-Guided 3D Vision-Language Pretraining for Unified Medical Image Segmentation.](http://arxiv.org/abs/2306.04811) | 本文提出了一种生成文本引导的三维视觉语言预训练用于统一医学图像分割的框架，不需要大规模的图像-文本对，可用于3D医学图像并且性能优越。 |
| [^62] | [Autonomous Capability Assessment of Black-Box Sequential Decision-Making Systems.](http://arxiv.org/abs/2306.04806) | 本论文提出了一种新方法，可以有效地评估黑盒SDM系统的能力，该方法使用主动学习来建立一个可解释的概率模型，能够准确地描述其能力和在随机环境中执行这些能力的可能效果和要求。 |
| [^63] | [A Survey on Knowledge Graphs for Healthcare: Resources, Applications, and Promises.](http://arxiv.org/abs/2306.04802) | 本论文综述了医疗知识图谱(HKGs)的构建流程、关键技术和利用方法以及现有资源，并深入探讨了HKG在各种医疗领域的变革性影响。 |
| [^64] | [On the Use of Generative Models in Observational Causal Analysis.](http://arxiv.org/abs/2306.04792) | 该论文探讨了使用生成模型进行因果分析的可行性，并指出仅估计联合概率分布并不能推断因果关系。 |
| [^65] | [Enabling tabular deep learning when $d \gg n$ with an auxiliary knowledge graph.](http://arxiv.org/abs/2306.04766) | 该论文提出了 PLATO 方法，通过使用描述输入特征的辅助 KG 来规范 MLP，在 $d \gg n$ 的表格数据上实现了强大的性能。 |
| [^66] | [The HCI Aspects of Public Deployment of Research Chatbots: A User Study, Design Recommendations, and Open Challenges.](http://arxiv.org/abs/2306.04765) | 本文研究研究聊天机器人的公开部署，发现代理人的抽象拟人化表现影响用户感知，AI可解释性可能影响反馈率，聊天体验的两种水平应有意设计。此研究提供了设计建议和研究方向。 |
| [^67] | [SKG: A Versatile Information Retrieval and Analysis Framework for Academic Papers with Semantic Knowledge Graphs.](http://arxiv.org/abs/2306.04758) | 提出了一个基于语义知识图谱的Academic Papers信息检索与分析框架(SKG)，该框架通过整合语义概念表示语料库，支持各种学术文献的语义查询，并开发了数据流系统进行灵活、交互的各种语义查询。 |
| [^68] | [INSTRUCTEVAL: Towards Holistic Evaluation of Instruction-Tuned Large Language Models.](http://arxiv.org/abs/2306.04757) | INSTRUCTEVAL是一个专注于指导调整的大型语言模型评估的综合套件，它采取了全面的方法来评估模型的性能，包括解决问题、写作能力和与人类价值观的一致性等特征。 |
| [^69] | [AutoML Systems For Medical Imaging.](http://arxiv.org/abs/2306.04750) | 该论文介绍了医学成像中自动化机器学习的应用、策略和技术，该方法通过神经结构搜索和迁移学习技术简化了图像识别模型的创建，结合人类专业知识和计算机系统可以提高医学图像分析的精度和质量。 |
| [^70] | [3D Human Keypoints Estimation From Point Clouds in the Wild Without Human Labels.](http://arxiv.org/abs/2306.04745) | 本文提出了一种无需人工标注的方法用于从野外点云中学习3D人体关节定位，利用几何一致性思想构建无监督损失函数，无需昂贵的标注数据，在监督和少样本学习中都有良好的性能表现。 |
| [^71] | [MultiEarth 2023 -- Multimodal Learning for Earth and Environment Workshop and Challenge.](http://arxiv.org/abs/2306.04738) | 本研究介绍了《MultiEarth 2023》工作坊和挑战，通过利用遥感数据监测地球生态系统的健康状况。同时也提供一个公共基准来处理多模态遥感信息，并通过挑战集中在监测亚马逊雨林方面。 |
| [^72] | [Soft-prompt Tuning for Large Language Models to Evaluate Bias.](http://arxiv.org/abs/2306.04735) | 本文使用软提示调整来量化大型语言模型中的偏差，避免手动设计提示导致的人为偏差注入。通过分组公平性检查模型对不同敏感属性的偏见，发现了有趣的偏差模式。 |
| [^73] | [Intrinsic Dimension Estimation for Robust Detection of AI-Generated Texts.](http://arxiv.org/abs/2306.04723) | 本文提出了衡量文本内部维度的方法，应用于鲁棒性AI生成文本的检测，展示了人类文本与AI生成文本在内部维度上的差异。 |
| [^74] | [Don't trust your eyes: on the (un)reliability of feature visualizations.](http://arxiv.org/abs/2306.04719) | 本文探讨了神经网络如何从像素中提取模式的问题，并研究了特征可视化的可靠性。实验证据表明，由于优化过程中固有的限制，特征可视化能够可靠理解的功能集非常有限，对于解释神经网络如何处理自然图像的解释能力产生怀疑。 |
| [^75] | [AGIQA-3K: An Open Database for AI-Generated Image Quality Assessment.](http://arxiv.org/abs/2306.04717) | 本论文提出了一个用于AI生成图像质量评估的开放数据库AGIQA-3K，并在其中进行了基准实验，提出了StairReward以提高主观文本到图像对齐评估的性能。 |
| [^76] | [Improving Open Language Models by Learning from Organic Interactions.](http://arxiv.org/abs/2306.04707) | BlenderBot 3x是一个更新版本的会话模型，通过参与者的有机对话和反馈数据进行训练，以改进其技能和安全性，技术上通过学习有益的教师避免学习有毒反馈。 |
| [^77] | [Adaptive Frequency Green Light Optimal Speed Advisory based on Hybrid Actor-Critic Reinforcement Learning.](http://arxiv.org/abs/2306.04660) | 本文提出了一种基于混合Actor-Critic强化学习的自适应频率绿灯最佳速度建议模型，通过使用离散和连续演员网络来优化绿灯最佳速度建议系统的频率和加速度曲线，设计了新的奖励函数来平衡减少停车和最小化速度变化的权衡。实验结果显示，该模型可以有效地减少旅行时间和燃料消耗，并优于现有的最先进的GLOSA系统。 |
| [^78] | [Improving Empathetic Dialogue Generation by Dynamically Infusing Commonsense Knowledge.](http://arxiv.org/abs/2306.04657) | 本文提出了一种动态注入常识知识的共情式对话生成方法，使用自适应模块选择常识知识以确保生成的对话回应和说话者情况的一致性，其表现优于基准模型。 |
| [^79] | [On training locally adaptive CP.](http://arxiv.org/abs/2306.04648) | 本文提出了一种新的Conformal Prediction方法，使用可训练的变量变换重新定义符合度量，使得预测区间在保持边际有效的同时具有对象属性相关的大小。通过训练可最大化间隔效率。 |
| [^80] | [Decom--CAM: Tell Me What You See, In Details! Feature-Level Interpretation via Decomposition Class Activation Map.](http://arxiv.org/abs/2306.04644) | 本文提出了一种名为Decom-CAM的两阶段可解释性方法，可用于对深度学习模型的预测结果进行特征级解释。实验结果表明该方法可有效定位重要区域和显著特征，并改善了模型的决策质量。 |
| [^81] | [Abnormal Trading Detection in the NFT Market.](http://arxiv.org/abs/2306.04643) | 本文提出了一种通过聚类算法检测非同质化代币（NFT）交易市场中的异常行为的方法，并探讨了监管对减少欺诈行为的影响。 |
| [^82] | [Generalizable Low-Resource Activity Recognition with Diverse and Discriminative Representation Learning.](http://arxiv.org/abs/2306.04641) | 提出了一种新方法DDLearn，通过构建自监督学习任务，在考虑多样化和区分化学习的基础上提高通用低资源人类活动识别的性能。 |
| [^83] | [Integrating Geometric Control into Text-to-Image Diffusion Models for High-Quality Detection Data Generation via Text Prompt.](http://arxiv.org/abs/2306.04607) | GeoDiffusion使用文本提示将各种几何条件转化为图像，生成高质量的检测数据，性能优于现有方法。 |
| [^84] | [Look Beneath the Surface: Exploiting Fundamental Symmetry for Sample-Efficient Offline RL.](http://arxiv.org/abs/2306.04220) | 本文提出了一个新的离线强化学习算法TDM，利用系统动力学的基本对称性实现高效学习小数据集。 |
| [^85] | [Enabling Efficient Interaction between an Algorithm Agent and an LLM: A Reinforcement Learning Approach.](http://arxiv.org/abs/2306.03604) | 本论文提出一种强化学习的中介模型，可实现代理与LLM之间高效经济有效的互动，提高效率和成本效益。 |
| [^86] | [DreamSparse: Escaping from Plato's Cave with 2D Diffusion Model Given Sparse Views.](http://arxiv.org/abs/2306.03414) | 本文提出了 DreamSparse 框架，该框架通过利用先前训练的扩散模型的 2D 先验知识，通过几何模块和空间引导模型来解决 2D 模型缺乏 3D 感知能力的问题，进一步实现了从少视角情况下合成高质量的新视角图像。 |
| [^87] | [Message-passing selection: Towards interpretable GNNs for graph classification.](http://arxiv.org/abs/2306.02081) | 本文提出了一种可解释的GNN推理范式MSInterpreter，其中包括消息传递选择方案(MSScheme)，通过计算由结构和节点嵌入组成的消息聚合路径的权重因子，实现对GNN自我解释。在图分类基准测试中表明其有效性。 |
| [^88] | [Case Studies on X-Ray Imaging, MRI and Nuclear Imaging.](http://arxiv.org/abs/2306.02055) | 本文介绍了X射线成像、MRI和核医学在医学成像中的应用。通过基于人工智能的方法，尤其是卷积神经网络的应用，可以实现从成像模态中进行系统特征提取和分类，帮助医生进行快速准确的诊断。 |
| [^89] | [Generative Adversarial Networks for Data Augmentation.](http://arxiv.org/abs/2306.02019) | 本文介绍了基于对抗生成网络的数据增强方法在医疗图像分析中的应用，能够生成大量的合成样本用于增加可用数据集，但需要注意生成数据可能无法完全代表现实世界数据的复杂性和多样性。 |
| [^90] | [SGEM: Test-Time Adaptation for Automatic Speech Recognition via Sequential-Level Generalized Entropy Minimization.](http://arxiv.org/abs/2306.01981) | SGEM提出了一种新的测试时自适应框架，利用波束搜索和广义熵最小化调整预训练ASR模型，取得了三个主流ASR模型在不同领域转变时的最新性能。 |
| [^91] | [Responsible Design Patterns for Machine Learning Pipelines.](http://arxiv.org/abs/2306.01788) | 本文提出了一种综合框架，将负责任设计模式纳入机器学习流程中，以确保AI系统的伦理性和公正性。这个框架包括新的负责任AI设计模式，并指导AI开发人员、数据科学家和决策者在AI开发和部署中实施伦理实践。 |
| [^92] | [Joint Learning of Label and Environment Causal Independence for Graph Out-of-Distribution Generalization.](http://arxiv.org/abs/2306.01103) | 本文提出了一种考虑标签和环境因果独立性的方法来解决图形超出分布（OOD）泛化问题，通过敌对训练策略来联合优化属性以获得有效结果，实验证明LECI显着优于之前的方法。 |
| [^93] | [Language-Conditioned Imitation Learning with Base Skill Priors under Unstructured Data.](http://arxiv.org/abs/2305.19075) | 本文提出了一种结合基础技能先验和模仿学习的基于语言条件的通用方法，在非结构化数据下，以增强算法在适应不熟悉的环境方面的泛化能力。在零-shot设置下，在模拟和真实环境中测试，提高了CALVIN基准测试的得分。 |
| [^94] | [Parity Calibration.](http://arxiv.org/abs/2305.18655) | 本文介绍一种新的校准预测目标——parity校准，其考虑时间序列中未来观测值的增加或减少。我们使用在线二进制校准方法实现了parity校准，并在流行病学、天气预报和核聚变控制等领域中表明该方法的有效性。 |
| [^95] | [A Systematic Study and Comprehensive Evaluation of ChatGPT on Benchmark Datasets.](http://arxiv.org/abs/2305.18486) | 本文对基准数据集上 ChatGPT 的性能进行了全面的评估，包括问答、文本摘要、代码生成、常识推理、数学问题求解、机器翻译、偏见检测和伦理考虑等任务。研究旨在验证 ChatGPT 的优势和弱点，并为使用语言模型的未来研究提供见解。 |
| [^96] | [Stability of implicit neural networks for long-term forecasting in dynamical systems.](http://arxiv.org/abs/2305.17155) | 本文提出了一种基于隐式数值方案稳定性特性的神经网络，加入了硬性约束来保证其权重稳定性，取得了较好的长期预测结果。 |
| [^97] | [Parallel Sampling of Diffusion Models.](http://arxiv.org/abs/2305.16317) | 本文提出了一种新方法，ParaDiGMS，可以通过并行处理多个步骤来加速预训练扩散模型的采样。ParaDiGMS是第一个使计算速度和采样效率实现平衡的扩散采样方法，并与现有方法兼容。 |
| [^98] | [Large Language Models are In-Context Semantic Reasoners rather than Symbolic Reasoners.](http://arxiv.org/abs/2305.14825) | 本文研究了大型语言模型的内部机制，发现在上下文语境中，语言序列的语义应起到至关重要的作用，与人类符号推理不同，大型语言模型可以在语言序列中建立强连接，并组成一个表面逻辑链。 |
| [^99] | [Capturing Conversion Rate Fluctuation during Sales Promotions: A Novel Historical Data Reuse Approach.](http://arxiv.org/abs/2305.12837) | 本论文提出了一种名为HDR的新方法，通过重复使用历史促销数据，来捕捉促销转化模式，达到更好地适应促销模式的目的。 |
| [^100] | [RGCVAE: Relational Graph Conditioned Variational Autoencoder for Molecule Design.](http://arxiv.org/abs/2305.11699) | 本文提出了RGCVAE，一种基于关系图条件化的可变自编码器，可以有效、高效地进行分子设计，并在两个数据集上表现出了先进的生成性能和快速的训练速度。 |
| [^101] | [Numeric Magnitude Comparison Effects in Large Language Models.](http://arxiv.org/abs/2305.10782) | 本研究探究了大型语言模型在数字大小比较上的表现，结果显示，尽管缺乏数字表达，不同架构的语言模型均呈现出惊人的类人表征能力。 |
| [^102] | [A Theoretical Analysis of Optimistic Proximal Policy Optimization in Linear Markov Decision Processes.](http://arxiv.org/abs/2305.08841) | 本文提出了一种乐观的近端策略优化算法，用于解决带有全信息反馈的周期性对抗性线性MDP，在随机线性MDP和带有全信息的敌对线性MDP中，达到了最先进的后悔边界，并具有新颖的多批次更新机制。 |
| [^103] | [Sensitivity and Robustness of Large Language Models to Prompt Template in Japanese Text Classification Tasks.](http://arxiv.org/abs/2305.08714) | 本研究评估了多个大型语言模型在日语文本分类中对提示模板的敏感性和鲁棒性，并揭示出即使是高性能的GPT-4模型在这一方面也存在问题。 |
| [^104] | [Controlled Text Generation with Natural Language Instructions.](http://arxiv.org/abs/2304.14293) | InstructCTG是一个可以通过自然语言描述和演示来控制文本生成并满足不同约束条件的框架，它有效地解决了现有搜索或得分方法所存在的问题。 |
| [^105] | [Do the Rewards Justify the Means? Measuring Trade-Offs Between Rewards and Ethical Behavior in the MACHIAVELLI Benchmark.](http://arxiv.org/abs/2304.03279) | 本文介绍了 MACHIAVELLI 基准测试，用于衡量人工智能代理是否表现出马基雅维利行为，发现了最大化奖励和行为的道德性之间存在权衡，并探索了基于语言模型的方法来减轻这种权衡。 |
| [^106] | [Commonsense Knowledge Assisted Deep Learning for Resource-constrained and Fine-grained Object Detection.](http://arxiv.org/abs/2303.09026) | 本文提出了一种通识知识辅助的细粒度目标检测方法，利用通识知识推理模块处理由基准深度学习检测器给出的粗粒度标签，从而提高目标检测的准确性。经过实验验证，该方法相比于现有方法需要更少的计算量和标注资源。 |
| [^107] | [Opening Up the Neural Network Classifier for Shap Score Computation.](http://arxiv.org/abs/2303.06516) | 本文提出了一种高效计算机器学习模型分类中Shap解释分数的方法，通过将二进制神经网络转换为布尔电路，并使用知识编译技术，将电路视为开放式模型，通过最近的高效算法计算Shap分数，相比于将BNN视为黑盒模型直接计算Shap，性能有了显著的提高。 |
| [^108] | [Learning to Influence Human Behavior with Offline Reinforcement Learning.](http://arxiv.org/abs/2303.02265) | 本文提出了一种通过离线强化学习学习影响人类行为的方法，可以提高人类在协作任务中的表现。 |
| [^109] | [Reduce, Reuse, Recycle: Compositional Generation with Energy-Based Diffusion Models and MCMC.](http://arxiv.org/abs/2302.11552) | 该论文提出了一种基于能量扩散模型和MCMC的组合生成方法，旨在解决现有技术在组合生成中的失败问题，并提出了新的成功的解决方案。 |
| [^110] | [DynGFN: Towards Bayesian Inference of Gene Regulatory Networks with GFlowNets.](http://arxiv.org/abs/2302.04178) | DynGFN是一种借助RNA速度技术进行基因调控网络推断的方法，能够捕捉网络结构的不确定性，并在准确度上超过现有方法。 |
| [^111] | [Principlism Guided Responsible Data Curation.](http://arxiv.org/abs/2302.03629) | 研究针对人本计算机视觉数据集的负责任数据管理建议，采用预防性反思的观点，遵循原则主义的伦理框架，解决隐私和偏差问题。 |
| [^112] | [Neural Insights for Digital Marketing Content Design.](http://arxiv.org/abs/2302.01416) | 本文提出了一种基于神经网络的数字营销内容设计评分和提取见解系统，该系统可以为营销人员提供基于历史数据的见解和设计建议，以改善其创意过程并显着提高客户参与度。 |
| [^113] | [Regret Bounds for Markov Decision Processes with Recursive Optimized Certainty Equivalents.](http://arxiv.org/abs/2301.12601) | 本文提出了基于递归优化等价性的马尔可夫决策过程的风险敏感强化学习公式，设计了一种有效学习算法，并且推导了算法的遗憾上界和极小-最大下界，表明该算法实现的遗憾率对于情歌数和动作数具有最优依赖性。 |
| [^114] | [Zero-Shot Transfer of Haptics-Based Object Insertion Policies.](http://arxiv.org/abs/2301.12587) | 本文训练了一个模拟中的接触利用操作策略，用于接触丰富的家庭任务，零-shot转移到真实机器人，并最小限度地减小了模拟到真实的差距，可以通用于不同尺寸的盘子。 |
| [^115] | [BTS: Bifold Teacher-Student in Semi-Supervised Learning for Indoor Two-Room Presence Detection Under Time-Varying CSI.](http://arxiv.org/abs/2212.10802) | 本文提出了一种基于半监督学习的双折叠师生网络，该网络通过利用部分标记和未标记的数据集智能地学习空间和时间特征，有效地解决了基于CSI的室内存在检测受到环境变化和有监督学习方法需要耗时标注的问题。 |
| [^116] | [Do language models have coherent mental models of everyday things?.](http://arxiv.org/abs/2212.10029) | 语言模型缺乏对日常物品的一致性心理模型，会因此出现荒谬的解决方法。虽然最先进的预训练语言模型具有这些实体的知识碎片，但它们无法为所有实体产生一致且正确的心理模型。语言模型训练可以改善这种情况。 |
| [^117] | [A fermion neural network with efficient optimization and quantum applicability.](http://arxiv.org/abs/2211.05793) | 本文提出了一种费米子神经网络（FNN），它将输入作为初始层，输出物理特性，建立了一种高效的优化方法，可应用于具有相互作用的硬量子系统，而且能够精确地确定拓扑相和紧凑电荷序，其量子特性带来多种优势。 |
| [^118] | [FARE: Provably Fair Representation Learning with Practical Certificates.](http://arxiv.org/abs/2210.07213) | FARE是第一个提供实际公平性证书的FRL方法，通过限制编码器的表示空间实现实际保证并保持准确度-公平度权衡。 |
| [^119] | [Predicting the Next Action by Modeling the Abstract Goal.](http://arxiv.org/abs/2209.05044) | 这篇论文提出了一种可以模型化抽象目标，以降低行动预测中不确定性的行动预测模型。使用视觉表征来描述动作和目标信息，并设计抽象目标为一个分布。该模型可在Epic-Kitchen数据集上实现最先进性能。 |
| [^120] | [Simulation-Assisted Optimization for Large-Scale Evacuation Planning with Congestion-Dependent Delays.](http://arxiv.org/abs/2209.01535) | 本研究提出了一种通过模拟辅助优化的方法，能够在考虑拥堵依赖延迟的情况下，提高大规模疏散计划的性能表现，相比现有方法表现更优。 |
| [^121] | [Mitigating Propagation Failures in Physics-informed Neural Networks using Retain-Resample-Release (R3) Sampling.](http://arxiv.org/abs/2207.02338) | 本文提出了一种新的Retain-Resample-Release采样（R3）算法，通过减轻传播失败，使得物理信息神经网络（PINN）能够成功地从边界点传播解决方案到内部点。 |
| [^122] | [Ask-AC: An Initiative Advisor-in-the-Loop Actor-Critic Framework.](http://arxiv.org/abs/2207.01955) | 本文提出了一种新颖的主动顾问演员-评论家框架，Ask-AC，它替换了传统的被动监督信号机制，实现了定制化和高效的信息交换，其中的两个互补组件允许代理主动寻求顾问干预和识别漏掉的不稳定状态。 |
| [^123] | [Rethinking the Implementation Tricks and Monotonicity Constraint in Cooperative Multi-Agent Reinforcement Learning.](http://arxiv.org/abs/2102.03479) | 本文研究了QMIX算法的变体和单调性约束的实现技巧，发现标准化优化对SMAC环境的表现有显著影响；单调性约束能提高SMAC和DEPP的采样效率。 |

# 详细

[^1]: FollowNet: 一种全面的汽车后续行为建模基准测试

    FollowNet: A Comprehensive Benchmark for Car-Following Behavior Modeling. (arXiv:2306.05381v1 [cs.CV])

    [http://arxiv.org/abs/2306.05381](http://arxiv.org/abs/2306.05381)

    本论文介绍了一个公共基准测试数据集，用于汽车跟随行为建模，该数据集包含逾80K个汽车跟随事件，旨在填补此领域的数据缺口并促进微观交通流建模的发展。

    

    汽车跟随是一种控制过程，在这种过程中，跟随车辆（FV）会调整其加速度，以保持与前车（LV）的安全距离。最近，通过真实世界的驾驶数据集，出现了许多数据驱动模型，使汽车跟随的建模更加准确。尽管有几个公共数据集可用，但它们的格式并不始终一致，这使得确定最先进的模型以及新模型的表现如何与现有模型相比变得具有挑战性。 相比之下，像图像识别和物体检测这样的研究领域具有像ImageNet、Microsoft COCO和KITTI这样的基准数据集。为了填补这一差距，促进微观交通流建模的发展，我们建立了一个公共基准数据集，用于汽车跟随行为建模。该基准测试由从五个公共驾驶数据集中提取的逾80K个汽车跟随事件组成，使用相同的标准。这些事件涵盖了各种情况，包括道路类型、道路宽度和交通流密度的变化以及两辆车之间的相对速度。

    Car-following is a control process in which a following vehicle (FV) adjusts its acceleration to keep a safe distance from the lead vehicle (LV). Recently, there has been a booming of data-driven models that enable more accurate modeling of car-following through real-world driving datasets. Although there are several public datasets available, their formats are not always consistent, making it challenging to determine the state-of-the-art models and how well a new model performs compared to existing ones. In contrast, research fields such as image recognition and object detection have benchmark datasets like ImageNet, Microsoft COCO, and KITTI. To address this gap and promote the development of microscopic traffic flow modeling, we establish a public benchmark dataset for car-following behavior modeling. The benchmark consists of more than 80K car-following events extracted from five public driving datasets using the same criteria. These events cover diverse situations including differ
    
[^2]: BEA-2023共享任务中的ADAIO系统：生成教育对话中AI教师回应

    The ADAIO System at the BEA-2023 Shared Task on Generating AI Teacher Responses in Educational Dialogues. (arXiv:2306.05360v1 [cs.CL])

    [http://arxiv.org/abs/2306.05360](http://arxiv.org/abs/2306.05360)

    本文介绍了ADAIO团队在BEA-2023共享任务中的系统方案，使用OpenAI GPT-3评估基准模型并在教育对话中生成AI教师回应。通过少量提供提示信息，利用OpenAI的text-davinci-003模型在竞赛中获得第二名，并突出了大型语言模型在AI教师角色中的少量提示学习能力。

    

    本文介绍了ADAIO团队在"Building Educational Applications (BEA) 2023"共享任务中，生成教育对话中AI教师回应的系统方案。本任务旨在评估最先进的生成模型作为AI教师，在学生与教师的对话中产生合适回应的表现。我们使用OpenAI GPT-3评估了各种基准模型，并设计了不同的提示方式来激发OpenAI模型生成教师回应。在竞赛中，我们的系统使用了基于少量提示的方法，采用了OpenAI的text-davinci-003模型，获得了第二名的成绩。结果突出了大型语言模型（尤其是OpenAI的GPT-3）在AI教师角色中的少量提示学习能力。

    This paper presents the ADAIO team's system entry in the Building Educational Applications (BEA) 2023 Shared Task on Generating AI Teacher Responses in Educational Dialogues. The task aims to assess the performance of state-of-the-art generative models as AI teachers in producing suitable responses within a student-teacher dialogue. Our system comprises evaluating various baseline models using OpenAI GPT-3 and designing diverse prompts to prompt the OpenAI models for teacher response generation. After the challenge, our system achieved second place by employing a few-shot prompt-based approach with the OpenAI text-davinci-003 model. The results highlight the few-shot learning capabilities of large-language models, particularly OpenAI's GPT-3, in the role of AI teachers.
    
[^3]: 面向高级驾驶辅助系统中听不见的指令攻击的可信传感器融合

    Trustworthy Sensor Fusion against Inaudible Command Attacks in Advanced Driver-Assistance System. (arXiv:2306.05358v1 [cs.CR])

    [http://arxiv.org/abs/2306.05358](http://arxiv.org/abs/2306.05358)

    本文提出了多模态融合框架（MFF），利用VGG系列神经网络实现异构音频-视觉模态的融合。在实验中，MFF实现了92.25%的检测准确率，并证明MFF在不同模型不确定性条件下具有可靠性。

    

    自动驾驶车辆遭受恶意攻击的担忧日益增加。其中，听不见的语音指令攻击构成了重大威胁，因为语音指令已经在自动驾驶系统中得到了应用。如何通过实证研究来抵御这些听不见的攻击仍然是一个未解决的问题。以往的研究探讨运用基于深度学习的多模态融合来进行防御，却没有考虑模型可信度的不确定性。随着深度学习应用于越来越敏感的任务，不确定性测量在帮助提高模型稳健性方面尤为重要，特别是在关键任务场景中。本文提出了多模态融合框架（MFF）作为智能安全系统来防范听不见的语音指令攻击。MFF利用VGG系列神经网络融合异构音频-视觉模态，并在比较融合方法的实证研究中实现了92.25%的检测准确率。此外，对MFF进行了大量实验，以证明其在不同模型不确定性条件下的可靠性。

    There are increasing concerns about malicious attacks on autonomous vehicles. In particular, inaudible voice command attacks pose a significant threat as voice commands become available in autonomous driving systems. How to empirically defend against these inaudible attacks remains an open question. Previous research investigates utilizing deep learning-based multimodal fusion for defense, without considering the model uncertainty in trustworthiness. As deep learning has been applied to increasingly sensitive tasks, uncertainty measurement is crucial in helping improve model robustness, especially in mission-critical scenarios. In this paper, we propose the Multimodal Fusion Framework (MFF) as an intelligent security system to defend against inaudible voice command attacks. MFF fuses heterogeneous audio-vision modalities using VGG family neural networks and achieves the detection accuracy of 92.25% in the comparative fusion method empirical study. Additionally, extensive experiments on
    
[^4]: 无监督的文本到图像生成模型下的组合式概念发现

    Unsupervised Compositional Concepts Discovery with Text-to-Image Generative Models. (arXiv:2306.05357v1 [cs.CV])

    [http://arxiv.org/abs/2306.05357](http://arxiv.org/abs/2306.05357)

    本论文提出了一种无监督的方法，用于从图像中自动地发现不同的生成概念，并且这些生成概念可以被用于重新组合和生成新的艺术和混合图像，并作为一种表示用于下游的分类任务。

    

    文本到图像生成模型使得在不同领域实现高分辨率的图像合成成为可能，但需要用户指定他们想要生成的内容。本文考虑了相反的问题——在给出的不同图像集合中，我们能否发现代表每个图像的生成概念？我们提出了一种无监督的方法来从一组图像中发现生成的概念，将绘画中不同的艺术风格，对象和照明从厨房场景中分解出来，并通过给定的ImageNet图像发现图像类。我们展示了这样的生成概念能够准确地表示图像的内容，能够重新组合和组成以生成新的艺术和混合图像，并可以作为下游分类任务的一种表示来使用。

    Text-to-image generative models have enabled high-resolution image synthesis across different domains, but require users to specify the content they wish to generate. In this paper, we consider the inverse problem -- given a collection of different images, can we discover the generative concepts that represent each image? We present an unsupervised approach to discover generative concepts from a collection of images, disentangling different art styles in paintings, objects, and lighting from kitchen scenes, and discovering image classes given ImageNet images. We show how such generative concepts can accurately represent the content of images, be recombined and composed to generate new artistic and hybrid images, and be further used as a representation for downstream classification tasks.
    
[^5]: 主动学习贝叶斯矩阵融合模型带深度信息

    Actively learning a Bayesian matrix fusion model with deep side information. (arXiv:2306.05331v1 [cs.AI])

    [http://arxiv.org/abs/2306.05331](http://arxiv.org/abs/2306.05331)

    本文提出了一种主动学习方法，通过自适应采样实验刺激来高效地学习带有深度信息的贝叶斯矩阵分解模型，相比于被动的基线方法，效率显著提高。

    

    图像和概念的高维深度神经网络表示可以与人类注释对齐，但这需要获取昂贵的行为响应，因此在实践中，仅稀疏采样深度特征空间。本文提出了一种主动学习方法，通过自适应采样实验刺激来高效地学习带有深度信息的贝叶斯矩阵分解模型。相比于被动的基线方法，我们观察到了显著的效率提高。此外，使用顺序批次采样策略，该算法不仅适用于传统实验收集的小型数据集，而且适用于需要精确对齐预训练网络派生的高维深层特征表示的大规模众包数据收集设置。

    High-dimensional deep neural network representations of images and concepts can be aligned to predict human annotations of diverse stimuli. However, such alignment requires the costly collection of behavioral responses, such that, in practice, the deep-feature spaces are only ever sparsely sampled. Here, we propose an active learning approach to adaptively sampling experimental stimuli to efficiently learn a Bayesian matrix factorization model with deep side information. We observe a significant efficiency gain over a passive baseline. Furthermore, with a sequential batched sampling strategy, the algorithm is applicable not only to small datasets collected from traditional laboratory experiments but also to settings where large-scale crowdsourced data collection is needed to accurately align the high-dimensional deep feature representations derived from pre-trained networks.
    
[^6]: 巨型语言模型在意大利生物医学信息提取方面的应用：方法论研究和实际应用的多中心实践

    Advancing Italian Biomedical Information Extraction with Large Language Models: Methodological Insights and Multicenter Practical Application. (arXiv:2306.05323v1 [cs.CL])

    [http://arxiv.org/abs/2306.05323](http://arxiv.org/abs/2306.05323)

    该研究创建了意大利神经精神命名实体识别数据集，并使用巨型语言模型开发出多中心识别模型，整体 F1得分为84.77%。该模型将帮助临床从业者从非结构化的医疗记录中自动提取信息。

    

    医院引入计算机化医疗记录有助于减少手写和信息提取等繁琐操作。然而，由于从非结构化文本医疗记录中提取数据需要时间和精力，因此医疗记录中包含的数据仍然被充分利用程度低。自然语言处理的子领域信息提取可以帮助临床从业者克服这一限制，使用自动化文本挖掘流程。在这项工作中，我们创建了意大利神经精神命名实体识别数据集 PsyNIT，并使用它来开发这一任务的巨型语言模型。此外，我们还进行了多个实验，使用三个外部独立数据集来实现有效的多中心模型，整体 F1 得分为 84.77%，精确率为 83.16%，召回率为 86.44%。我们学到的经验是: (i) 一致的注释过程的关键作用和 (ii) 结合经典方法和“少量训练”的 fine-tuning 策略。

    The introduction of computerized medical records in hospitals has reduced burdensome operations like manual writing and information fetching. However, the data contained in medical records are still far underutilized, primarily because extracting them from unstructured textual medical records takes time and effort. Information Extraction, a subfield of Natural Language Processing, can help clinical practitioners overcome this limitation, using automated text-mining pipelines. In this work, we created the first Italian neuropsychiatric Named Entity Recognition dataset, PsyNIT, and used it to develop a Large Language Model for this task. Moreover, we conducted several experiments with three external independent datasets to implement an effective multicenter model, with overall F1-score 84.77%, Precision 83.16%, Recall 86.44%. The lessons learned are: (i) the crucial role of a consistent annotation process and (ii) a fine-tuning strategy that combines classical methods with a "few-shot" a
    
[^7]: 图上函数的贝叶斯优化

    Bayesian Optimisation of Functions on Graphs. (arXiv:2306.05304v1 [cs.LG])

    [http://arxiv.org/abs/2306.05304](http://arxiv.org/abs/2306.05304)

    本论文提出了一种在通用的大规模和潜在未知图上定义函数的贝叶斯优化算法，并通过学习适当的图内核，适应目标函数行为。

    

    图结构数据的不断涌现推动了在图节点集上定义函数的优化任务。传统的图搜索算法可用于此，但它们可能样本效率低下，并且不利用关于函数值的信息；另一方面，贝叶斯优化是一类有前途的黑盒求解器，具有更高的样本效率，但它很少被应用于这样的新颖设置。为了填补这一空白，我们提出了一种新颖的贝叶斯优化框架，该框架优化在通用，大规模和潜在的未知图上定义的函数。通过学习适当的图内核，我们的框架具有适应目标函数行为的优点。局部建模方法进一步保证了我们方法的效率。在合成和真实世界图上的大量实验表明了所提出的优化框架的有效性。

    The increasing availability of graph-structured data motivates the task of optimising over functions defined on the node set of graphs. Traditional graph search algorithms can be applied in this case, but they may be sample-inefficient and do not make use of information about the function values; on the other hand, Bayesian optimisation is a class of promising black-box solvers with superior sample efficiency, but it has been scarcely been applied to such novel setups. To fill this gap, we propose a novel Bayesian optimisation framework that optimises over functions defined on generic, large-scale and potentially unknown graphs. Through the learning of suitable kernels on graphs, our framework has the advantage of adapting to the behaviour of the target function. The local modelling approach further guarantees the efficiency of our method. Extensive experiments on both synthetic and real-world graphs demonstrate the effectiveness of the proposed optimisation framework.
    
[^8]: 思维习惯：重复利用行动序列进行高效规划

    Habits of Mind: Reusing Action Sequences for Efficient Planning. (arXiv:2306.05298v1 [cs.AI])

    [http://arxiv.org/abs/2306.05298](http://arxiv.org/abs/2306.05298)

    该论文提出了一种灵活的贝叶斯行动分块机制，通过充分利用经过练习的行动序列来加速和提高规划的准确性，可嵌入蒙特卡罗树搜索规划器中。在物理构造任务上的实验结果表明了该方案的优点。

    

    当我们执行一系列动作时，它们的执行变得更加流畅和精确。在这里，我们考虑了已经练习过的行动序列也可以通过聚焦于过去经常使用的路径来加速和提高规划的准确性，通过树中的多步跳跃将深层规划问题缩小为浅层问题。为了捕捉这样的序列，我们使用了一个灵活的贝叶斯行动分块机制，该机制在不同的尺度上找到和利用了统计上可靠的结构。这产生了可以嵌入到蒙特卡罗树搜索规划器中的更短或更长的常规程序。我们使用类似七巧板的物理构造任务展示了这种方案的优点。

    When we exercise sequences of actions, their execution becomes more fluent and precise. Here, we consider the possibility that exercised action sequences can also be used to make planning faster and more accurate by focusing expansion of the search tree on paths that have been frequently used in the past, and by reducing deep planning problems to shallow ones via multi-step jumps in the tree. To capture such sequences, we use a flexible Bayesian action chunking mechanism which finds and exploits statistically reliable structure at different scales. This gives rise to shorter or longer routines that can be embedded into a Monte-Carlo tree search planner. We show the benefits of this scheme using a physical construction task patterned after tangrams.
    
[^9]: 基于毫米波雷达传感器的一次学习式司机头部动作识别

    One shot learning based drivers head movement identification using a millimetre wave radar sensor. (arXiv:2306.05291v1 [eess.SP])

    [http://arxiv.org/abs/2306.05291](http://arxiv.org/abs/2306.05291)

    通过使用小型毫米波雷达传感器从司机的头部动作中收集信号，并基于一次学习技术设计分类器，可以高效地识别司机的不同动作类型，实验准确率超过95%。

    

    聚焦于交通安全，监测司机是否专注于驾驶是必要的。本文基于毫米波雷达应用，利用安装在车辆方向盘处的小型毫米波雷达从司机不同的头部动作收集信号，再通过设计基于雷达传感器的分类器来区分不同的动作类型。鉴于数据集较小，本文提出使用一次学习方法分类司机的四种头部动作。实验结果表明，使用该方法进行分类的准确率超过了95%。

    Concentration of drivers on traffic is a vital safety issue; thus, monitoring a driver being on road becomes an essential requirement. The key purpose of supervision is to detect abnormal behaviours of the driver and promptly send warnings to him her for avoiding incidents related to traffic accidents. In this paper, to meet the requirement, based on radar sensors applications, the authors first use a small sized millimetre wave radar installed at the steering wheel of the vehicle to collect signals from different head movements of the driver. The received signals consist of the reflection patterns that change in response to the head movements of the driver. Then, in order to distinguish these different movements, a classifier based on the measured signal of the radar sensor is designed. However, since the collected data set is not large, in this paper, the authors propose One shot learning to classify four cases of driver's head movements. The experimental results indicate that the pr
    
[^10]: 简单且可控的音乐生成

    Simple and Controllable Music Generation. (arXiv:2306.05284v1 [cs.SD])

    [http://arxiv.org/abs/2306.05284](http://arxiv.org/abs/2306.05284)

    本文提出了 MusicGen，一个单一的语言模型，可以在条件描述或旋律特征控制下生成高质量的样本，并且在标准的文本到音乐基准上的实证研究中，该方法优于其他基线模型。

    

    本研究解决了条件音乐生成的问题。我们介绍了MusicGen，它是一个单一的语言模型，可以操作多个压缩离散音乐表示流，即令牌。与以往的工作不同，MusicGen由一个单一阶段的Transformer LM和高效的令牌交错模式组成，消除了级联多个模型的需要，例如分层或上采样。采用这种方法，我们展示了MusicGen如何在条件描述或旋律特征的控制下生成高质量的样本。我们进行了广泛的实证评估，考虑了自动和人为研究，展示了所提出的方法优于标准文本到音乐基准上评估的基线。通过消融研究，我们阐明了MusicGen所包含组件的重要性。音乐样本、代码和模型可以在https://github.com/fac找到。

    We tackle the task of conditional music generation. We introduce MusicGen, a single Language Model (LM) that operates over several streams of compressed discrete music representation, i.e., tokens. Unlike prior work, MusicGen is comprised of a single-stage transformer LM together with efficient token interleaving patterns, which eliminates the need for cascading several models, e.g., hierarchically or upsampling. Following this approach, we demonstrate how MusicGen can generate high-quality samples, while being conditioned on textual description or melodic features, allowing better controls over the generated output. We conduct extensive empirical evaluation, considering both automatic and human studies, showing the proposed approach is superior to the evaluated baselines on a standard text-to-music benchmark. Through ablation studies, we shed light over the importance of each of the components comprising MusicGen. Music samples, code, and models are available at https://github.com/fac
    
[^11]: 基于动态特征重构信号图的旋转机械故障识别

    Fault Identification of Rotating Machinery Based on Dynamic Feature Reconstruction Signal Graph. (arXiv:2306.05281v1 [eess.SP])

    [http://arxiv.org/abs/2306.05281](http://arxiv.org/abs/2306.05281)

    本文提出了一种动态特征重构信号图法，在旋转机械故障诊断模型中取得了关键进展，能够动态地选择最优子带的特征系数矩阵，进行适应性信号重构，并从中提取深层特征。

    

    为了提高在旋转机械强噪声下识别故障的性能，本文提出了一种动态特征重构信号图法，它在所提出的端到端故障诊断模型中起着关键作用。具体来说，首先利用小波包分解（WPD）将原始机械信号分解为包括系数矩阵在内的多个子带。然后，利用最初定义的两个要素MDD和DDD，提出了一种基于L2能量范数的动态特征选择方法（DFSL），它可以根据能量范数分布的差异动态地选择WPD的特征系数矩阵，使每个子信号能够进行适应性信号重构。接下来，将最优特征子带的系数矩阵进行重构和重新组合，得到特征信号图。最后，利用2D-卷积神经网络（2D-CNN）从特征信号图中提取深层特征。

    To improve the performance in identifying the faults under strong noise for rotating machinery, this paper presents a dynamic feature reconstruction signal graph method, which plays the key role of the proposed end-to-end fault diagnosis model. Specifically, the original mechanical signal is first decomposed by wavelet packet decomposition (WPD) to obtain multiple subbands including coefficient matrix. Then, with originally defined two feature extraction factors MDD and DDD, a dynamic feature selection method based on L2 energy norm (DFSL) is proposed, which can dynamically select the feature coefficient matrix of WPD based on the difference in the distribution of norm energy, enabling each sub-signal to take adaptive signal reconstruction. Next the coefficient matrices of the optimal feature sub-bands are reconstructed and reorganized to obtain the feature signal graphs. Finally, deep features are extracted from the feature signal graphs by 2D-Convolutional neural network (2D-CNN). Ex
    
[^12]: 基于Transformer架构的不良药物事件提取方法的广泛评估

    Extensive Evaluation of Transformer-based Architectures for Adverse Drug Events Extraction. (arXiv:2306.05276v1 [cs.CL])

    [http://arxiv.org/abs/2306.05276](http://arxiv.org/abs/2306.05276)

    本文对19种基于Transformer的ADE提取模型进行广泛评估，并在具有不同非正式程度的数据集上比较它们的性能。此外，我们使用了成熟的特征重要性技术（SHAP）进一步分析了模型的性能。

    

    不良事件（ADE）提取是数字药物监管中的核心任务之一，特别是当应用于非正式文本时。自然语言处理社区使用像BERT这样的大型预训练语言模型来解决这个任务。尽管在文献中使用了大量的基于Transformer的架构，但尚不清楚它们哪一个表现更好以及为什么。因此，在本文中，我们对19种基于Transformer的ADE提取模型进行了广泛评估和分析，并在逐渐增加非正式水平的两个数据集上比较了所有考虑的模型的性能（论坛帖子和推文）。我们还将纯Transformer模型与两个常用的额外处理层（CRF和LSTM）相结合，并分析它们对模型性能的影响。此外，我们使用了一种成熟的特征重要性技术（SHAP）将模型性能与一组特征相关联，以进一步分析模型的性能。

    Adverse Event (ADE) extraction is one of the core tasks in digital pharmacovigilance, especially when applied to informal texts. This task has been addressed by the Natural Language Processing community using large pre-trained language models, such as BERT. Despite the great number of Transformer-based architectures used in the literature, it is unclear which of them has better performances and why. Therefore, in this paper we perform an extensive evaluation and analysis of 19 Transformer-based models for ADE extraction on informal texts. We compare the performance of all the considered models on two datasets with increasing levels of informality (forums posts and tweets). We also combine the purely Transformer-based models with two commonly-used additional processing layers (CRF and LSTM), and analyze their effect on the models performance. Furthermore, we use a well-established feature importance technique (SHAP) to correlate the performance of the models with a set of features that 
    
[^13]: 分解对比学习：超越多视角冗余

    Factorized Contrastive Learning: Going Beyond Multi-view Redundancy. (arXiv:2306.05268v1 [cs.LG])

    [http://arxiv.org/abs/2306.05268](http://arxiv.org/abs/2306.05268)

    本论文提出了FactorCL，一种新的多模态表示学习方法，不仅考虑跨模态共享信息，还能捕捉跨模态唯一的任务相关信息。

    

    在广泛的多模态任务中，对比学习已成为一种特别吸引人的方法，因为它可以成功地学习具有丰富未标记数据的表示，只需配对信息（例如，图像标题或视频音频对）。这些方法的基础是多视角冗余的假设——跨模态间共享信息对于下游任务是必要且足够的。然而，在许多现实世界的情况下，任务相关信息也包含在跨模态唯一区域中：一种仅存在于一个模态中但与任务仍然相关的信息。如何学习自我监督的多模态表示以捕获与下游任务相关的共享和唯一信息？本文提出了一种新的多模态表示学习方法FactorCL，以超越多视角冗余。FactorCL的基础是三个新的贡献：（1）将任务相关信息分解为共享和唯一表示，（2）限制共享和唯一成分之间的交互，（3）使用因子正则化促进表示学习。

    In a wide range of multimodal tasks, contrastive learning has become a particularly appealing approach since it can successfully learn representations from abundant unlabeled data with only pairing information (e.g., image-caption or video-audio pairs). Underpinning these approaches is the assumption of multi-view redundancy - that shared information between modalities is necessary and sufficient for downstream tasks. However, in many real-world settings, task-relevant information is also contained in modality-unique regions: information that is only present in one modality but still relevant to the task. How can we learn self-supervised multimodal representations to capture both shared and unique information relevant to downstream tasks? This paper proposes FactorCL, a new multimodal representation learning method to go beyond multi-view redundancy. FactorCL is built from three new contributions: (1) factorizing task-relevant information into shared and unique representations, (2) cap
    
[^14]: 非线性无损自编码器

    Unscented Autoencoder. (arXiv:2306.05256v1 [cs.LG])

    [http://arxiv.org/abs/2306.05256](http://arxiv.org/abs/2306.05256)

    本文提出了一种新的自编码器模型，名为非线性无损自编码器（UAE），它使用确定性采样的有限一组统计量来提高后验表示，从而获得更高质量的重建。同时，本文使用Wasserstein分布度量替换KL散度，实现更尖锐的后验。

    

    变分自编码器（VAE）是具有潜在变量的深度生成模型中的开创性方法。我们将其重建过程解释为来自潜在后验分布的样本的非线性转换，并应用无损卡尔曼滤波器（UKF）领域中使用的众所周知的分布近似——无损变换（UT）。确定性采样的有限一组称为sigma点的统计量提供比重参数技巧的普遍噪声缩放更具信息量且方差更小的后验表示，同时确保更高质量的重建。我们进一步通过将Kullback-Leibler（KL）散度替换为Wasserstein分布度量来提高性能，从而允许更尖锐的后验。受到这两个组件的启发，我们得出了一种新颖的确定性采样VAE，即非线性无损自编码器（UAE），该自编码器仅使用针对每个样本后验的类似正规化的项进行训练。

    The Variational Autoencoder (VAE) is a seminal approach in deep generative modeling with latent variables. Interpreting its reconstruction process as a nonlinear transformation of samples from the latent posterior distribution, we apply the Unscented Transform (UT) -- a well-known distribution approximation used in the Unscented Kalman Filter (UKF) from the field of filtering. A finite set of statistics called sigma points, sampled deterministically, provides a more informative and lower-variance posterior representation than the ubiquitous noise-scaling of the reparameterization trick, while ensuring higher-quality reconstruction. We further boost the performance by replacing the Kullback-Leibler (KL) divergence with the Wasserstein distribution metric that allows for a sharper posterior. Inspired by the two components, we derive a novel, deterministic-sampling flavor of the VAE, the Unscented Autoencoder (UAE), trained purely with regularization-like terms on the per-sample posterior
    
[^15]: 处理多模态NLP中的语义不确定性

    Dealing with Semantic Underspecification in Multimodal NLP. (arXiv:2306.05240v1 [cs.CL])

    [http://arxiv.org/abs/2306.05240](http://arxiv.org/abs/2306.05240)

    语义未确定性在语言学中很重要，但多模态系统还没有解决好这个问题

    

    旨在像人类一样掌握语言的智能系统必须处理其语义未确定性，即语言信号可能仅传达通信所需信息的一部分。标准的NLP模型原则上没有或仅有有限的访问额外信息的能力，而将语言基于其他模态（例如视觉）进行说明的多模态系统自然配备以解决这种现象。然而，我们发现他们难以应对这一问题，这可能成为一个问题。

    Intelligent systems that aim at mastering language as humans do must deal with its semantic underspecification, namely, the possibility for a linguistic signal to convey only part of the information needed for communication to succeed. Consider the usages of the pronoun they, which can leave the gender and number of its referent(s) underspecified. Semantic underspecification is not a bug but a crucial language feature that boosts its storage and processing efficiency. Indeed, human speakers can quickly and effortlessly integrate semantically-underspecified linguistic signals with a wide range of non-linguistic information, e.g., the multimodal context, social or cultural conventions, and shared knowledge. Standard NLP models have, in principle, no or limited access to such extra information, while multimodal systems grounding language into other modalities, such as vision, are naturally equipped to account for this phenomenon. However, we show that they struggle with it, which could ne
    
[^16]: 提高长篇文本机器翻译的质量

    Improving Long Context Document-Level Machine Translation. (arXiv:2306.05183v1 [cs.CL])

    [http://arxiv.org/abs/2306.05183](http://arxiv.org/abs/2306.05183)

    该论文提出了一种新的受限注意力机制来提高长篇文本机器翻译的质量。

    

    对于神经机器翻译（NMT）来说，文本级别的上下文对于提高翻译的一致性、凝聚性、模棱两可输入的翻译以及其他语言现象至关重要。虽然已经有许多关于文档级别 NMT 的相关论文出版，但大多数将系统限制在本地上下文，通常只包括前一两个句子作为更多信息。这可能足以解决一些曖昧性输入，但可能不足以捕捉文档级别信息，例如话题或对话风格。当将上下文大小增加到本地上下文之外时，会面临两个挑战：（i）内存使用将呈指数增长（ii）翻译性能开始降低。我们认为广泛使用的注意机制是这两个问题的原因。因此，我们提出了一种受限的注意力变体，将注意力集中在序列的最相关部分，同时控制对齐权重的总和。

    Document-level context for neural machine translation (NMT) is crucial to improve the translation consistency and cohesion, the translation of ambiguous inputs, as well as several other linguistic phenomena. Many works have been published on the topic of document-level NMT, but most restrict the system to only local context, typically including just the one or two preceding sentences as additional information. This might be enough to resolve some ambiguous inputs, but it is probably not sufficient to capture some document-level information like the topic or style of a conversation. When increasing the context size beyond just the local context, there are two challenges: (i) the~memory usage increases exponentially (ii) the translation performance starts to degrade. We argue that the widely-used attention mechanism is responsible for both issues. Therefore, we propose a constrained attention variant that focuses the attention on the most relevant parts of the sequence, while simultaneou
    
[^17]: RRWKV：在RWKV中捕捉长距离依赖关系

    RRWKV: Capturing Long-range Dependencies in RWKV. (arXiv:2306.05176v1 [cs.CL])

    [http://arxiv.org/abs/2306.05176](http://arxiv.org/abs/2306.05176)

    本文介绍了一种新的RRWKV架构，它在保持记忆和计算效率的同时，通过加入回顾能力有效地捕捉长距离依赖关系。

    

    由于Transformer惊人的点积注意力，它已经成为各种自然语言处理（NLP）任务中的主要架构。最近，Receptance Weighted Key Value（RWKV）架构遵循非Transformer架构，消除了点积注意力的缺点，其中存储和计算复杂度随着序列长度呈二次扩展。尽管RWKV利用了线性张量积注意机制并通过部署时间序列模式实现了并行计算，但与标准Transformer中直接交互获得的完整信息相比，它无法捕捉长距离依赖关系，因为其受限于向后查看先前信息的能力。因此，本文通过将回顾能力纳入RWKV中来设计Retrospected Receptance Weighted Key Value（RRWKV）架构，以有效地吸收信息，同时保持记忆和计算效率。

    Owing to the impressive dot-product attention, the Transformers have been the dominant architectures in various natural language processing (NLP) tasks. Recently, the Receptance Weighted Key Value (RWKV) architecture follows a non-transformer architecture to eliminate the drawbacks of dot-product attention, where memory and computational complexity exhibits quadratic scaling with sequence length. Although RWKV has exploited a linearly tensor-product attention mechanism and achieved parallelized computations by deploying the time-sequential mode, it fails to capture long-range dependencies because of its limitation on looking back at previous information, compared with full information obtained by direct interactions in the standard transformer. Therefore, the paper devises the Retrospected Receptance Weighted Key Value (RRWKV) architecture via incorporating the retrospecting ability into the RWKV to effectively absorb information, which maintains memory and computational efficiency as 
    
[^18]: 基于大型语言模型和有向图结构表示知识的机器人任务规划

    Robot Task Planning Based on Large Language Model Representing Knowledge with Directed Graph Structures. (arXiv:2306.05171v1 [cs.RO])

    [http://arxiv.org/abs/2306.05171](http://arxiv.org/abs/2306.05171)

    该论文提出了一种基于LLM和有向图的机器人任务规划方法，使用LLM prompt template Think_Net_Prompt来表示结构化的专业知识。通过渐进分解任务并生成任务树以及解耦机器人任务规划，使任务规划过程更加灵活。研究结果表明，在处理指定的代码格式、理解任务和子任务之间的关系以及从文本描述中提取参数方面表现良好。

    

    传统的机器人任务规划方法在处理高度非结构化环境和复杂任务时面临困难。我们提出了一种任务规划方法，将人类专业知识与LLM相结合，并设计了更具表现力的LLM提示模板Think_Net_Prompt，以表示结构化的专业知识。我们进一步提出了一种渐进分解任务并生成任务树来减少每个任务的规划量的方法，同时设计了一种策略来解耦机器人任务规划。通过将不同的规划实体划分和将任务与实际机器绑定过程分开，任务规划过程变得更加灵活。研究结果表明，我们的方法在处理指定的代码格式、理解任务和子任务之间的关系以及从文本描述中提取参数方面表现良好。然而，也存在一些问题，如任务逻辑处理的复杂度有限，在数量歧义方面存在一定的问题。

    Traditional robot task planning methods face challenges when dealing with highly unstructured environments and complex tasks. We propose a task planning method that combines human expertise with an LLM and have designed an LLM prompt template, Think_Net_Prompt, with stronger expressive power to represent structured professional knowledge. We further propose a method to progressively decompose tasks and generate a task tree to reduce the planning volume for each task, and we have designed a strategy to decouple robot task planning. By dividing different planning entities and separating the task from the actual machine binding process, the task planning process becomes more flexible. Research results show that our method performs well in handling specified code formats, understanding the relationship between tasks and subtasks, and extracting parameters from text descriptions. However, there are also problems such as limited complexity of task logic handling, ambiguity in the quantity of
    
[^19]: 人工智能是否是更好的编程伙伴？人人对编程 vs 人工智能对编程

    Is AI the better programming partner? Human-Human Pair Programming vs. Human-AI pAIr Programming. (arXiv:2306.05153v1 [cs.HC])

    [http://arxiv.org/abs/2306.05153](http://arxiv.org/abs/2306.05153)

    人工智能与人类程序员共同开发可以通过设计良好的AI编程助手，增强双方合作的生产力。

    

    随着掌握代码生成能力的大型语言模型(LLMs)的出现以及商业产品，如GitHub的Copilot，人工智能与人类程序员的合作(pAIr编程)引起了人们的兴趣。虽然传统的人人对编程已经被广泛研究，但仍然不确定其研究结果是否能适用于人工智能对编程。我们比较了人人对编程和人工智能对编程，探讨了它们在交互、衡量、优点和挑战方面的相似之处和差异之处。我们发现，两种方法的有效性在文献中各不相同（尽管用于pAIr编程的度量不太全面）。我们总结了影响人人对编程成功的调节因素，为pAIr编程研究提供了机会。例如，不匹配的专业知识会使对编程缺乏生产力，因此设计良好的AI编程助手可以潜在地解决这个问题。

    The emergence of large-language models (LLMs) that excel at code generation and commercial products such as GitHub's Copilot has sparked interest in human-AI pair programming (referred to as "pAIr programming") where an AI system collaborates with a human programmer. While traditional pair programming between humans has been extensively studied, it remains uncertain whether its findings can be applied to human-AI pair programming. We compare human-human and human-AI pair programming, exploring their similarities and differences in interaction, measures, benefits, and challenges. We find that the effectiveness of both approaches is mixed in the literature (though the measures used for pAIr programming are not as comprehensive). We summarize moderating factors on the success of human-human pair programming, which provides opportunities for pAIr programming research. For example, mismatched expertise makes pair programming less productive, therefore well-designed AI programming assistants
    
[^20]: 昂贵嵌套灰盒函数的贝叶斯优化

    Bayesian Optimization of Expensive Nested Grey-Box Functions. (arXiv:2306.05150v1 [cs.LG])

    [http://arxiv.org/abs/2306.05150](http://arxiv.org/abs/2306.05150)

    本文提出基于乐观主义的算法来解决嵌套黑白箱函数优化问题，相比传统黑箱优化方法显著提高全局最优解速度。

    

    我们考虑优化灰盒目标函数的问题，即由黑箱和白箱函数组成的嵌套函数。给出了这种灰盒问题的一般形式，涵盖了现有的灰盒优化公式作为特殊情况。我们设计了一种基于乐观主义的算法来解决这个问题。在一定的正则性假设下，我们的算法实现了与标准黑箱贝叶斯优化算法相似的后悔边界，但乘以依赖于所考虑函数的Lipschitz常数的常数乘项。我们进一步将我们的方法扩展到约束情况，并讨论了几个特殊情况。对于常用的核函数，后悔边界使我们能够推导到最优解的收敛速度。实验结果表明，与标准黑箱优化相比，我们的灰盒优化方法在实践中显着提高了寻找全局最优解的速度。

    We consider the problem of optimizing a grey-box objective function, i.e., nested function composed of both black-box and white-box functions. A general formulation for such grey-box problems is given, which covers the existing grey-box optimization formulations as special cases. We then design an optimism-driven algorithm to solve it. Under certain regularity assumptions, our algorithm achieves similar regret bound as that for the standard black-box Bayesian optimization algorithm, up to a constant multiplicative term depending on the Lipschitz constants of the functions considered. We further extend our method to the constrained case and discuss several special cases. For the commonly used kernel functions, the regret bounds allow us to derive a convergence rate to the optimal solution. Experimental results show that our grey-box optimization method empirically improves the speed of finding the global optimal solution significantly, as compared to the standard black-box optimization 
    
[^21]: 离散空间的梯度信息质量多样性算法

    Gradient-Informed Quality Diversity for the Illumination of Discrete Spaces. (arXiv:2306.05138v1 [cs.AI])

    [http://arxiv.org/abs/2306.05138](http://arxiv.org/abs/2306.05138)

    本文提出了具有Gradient-Informed Discrete Emitter (ME-GIDE)的Map-Elites方法，利用梯度信息优化离散空间的搜索，相对于传统的质量多样性算法在离散问题中具有更好的性能。

    

    质量多样性算法旨在搜索大量各异且性能优越的解集，而不是一组局部最优解。尽管早期的质量多样性算法将目标和描述符函数视为黑盒函数，但引入了新工具以利用梯度信息，加速搜索并提高这些算法在连续输入空间上的整体性能。然而，广泛的应用涉及离散空间，例如药物发现或图像生成。探索这些空间具有挑战性，因为它们的组合规模很大，并且不能像连续空间那样使用梯度。我们使用具有梯度信息的离散发射器的 Map-Elites（ME-GIDE）扩展了对离散搜索空间的 QD 优化，该方法利用目标和描述符函数相对于其离散输入的梯度信息来提出梯度信息选择的解集。我们在一些离散基准问题上评估了 ME-GIDE，证明它优于将搜索空间视为黑盒的经典质量多样性算法。

    Quality Diversity (QD) algorithms have been proposed to search for a large collection of both diverse and high-performing solutions instead of a single set of local optima. While early QD algorithms view the objective and descriptor functions as black-box functions, novel tools have been introduced to use gradient information to accelerate the search and improve overall performance of those algorithms over continuous input spaces. However a broad range of applications involve discrete spaces, such as drug discovery or image generation. Exploring those spaces is challenging as they are combinatorially large and gradients cannot be used in the same manner as in continuous spaces. We introduce map-elites with a Gradient-Informed Discrete Emitter (ME-GIDE), which extends QD optimisation with differentiable functions over discrete search spaces. ME-GIDE leverages the gradient information of the objective and descriptor functions with respect to its discrete inputs to propose gradient-inform
    
[^22]: 图像匿名化是否对计算机视觉训练产生影响？

    Does Image Anonymization Impact Computer Vision Training?. (arXiv:2306.05135v1 [cs.CV])

    [http://arxiv.org/abs/2306.05135](http://arxiv.org/abs/2306.05135)

    本文探讨了图像匿名化对于计算机视觉模型训练的影响，研究表明传统图像匿名化对最终模型性能造成实质性影响，特别是对全身进行匿名化时。然而，逼真匿名化可以缓解性能下降，尤其是面部匿名化表现较好。

    

    在许多地区，图像匿名化是为了遵守隐私法规而广泛采用的方法。然而，匿名化通常会降低数据的质量，从而降低计算机视觉开发的效用。本文研究了图像匿名化对训练计算机视觉模型在关键计算机视觉任务（检测、实例分割和姿态估计）上的影响。具体而言，我们在常见的检测数据集上评估了传统和逼真匿名化对识别能力的影响，其中包括面部和全身。我们全面的实验结果表明，传统图像匿名化对最终模型性能产生了实质性的影响，特别是当对全身进行匿名化时。此外，我们发现逼真匿名化可以缓解这种性能下降，当面部进行匿名化时，我们的实验结果表明仅有微小的性能下降。我们的研究表明，逼真匿名化可以实现隐私保护的计算机视觉训练。

    Image anonymization is widely adapted in practice to comply with privacy regulations in many regions. However, anonymization often degrades the quality of the data, reducing its utility for computer vision development. In this paper, we investigate the impact of image anonymization for training computer vision models on key computer vision tasks (detection, instance segmentation, and pose estimation). Specifically, we benchmark the recognition drop on common detection datasets, where we evaluate both traditional and realistic anonymization for faces and full bodies. Our comprehensive experiments reflect that traditional image anonymization substantially impacts final model performance, particularly when anonymizing the full body. Furthermore, we find that realistic anonymization can mitigate this decrease in performance, where our experiments reflect a minimal performance drop for face anonymization. Our study demonstrates that realistic anonymization can enable privacy-preserving comp
    
[^23]: 可解释性预测性维护

    Explainable Predictive Maintenance. (arXiv:2306.05120v1 [cs.AI])

    [http://arxiv.org/abs/2306.05120](http://arxiv.org/abs/2306.05120)

    本文探讨了工业4.0框架下预测性维护领域中可解释性的重要性和现有XAI方法与特定解释需求之间的差距。

    

    可解释的人工智能（XAI）发挥着关键的作用，促进复杂的智能系统与数据科学家、领域专家、终端用户等各种人员之间的交流。本文强调了现有XAI方法和工业4.0框架下特定解释需求之间的差距。

    Explainable Artificial Intelligence (XAI) fills the role of a critical interface fostering interactions between sophisticated intelligent systems and diverse individuals, including data scientists, domain experts, end-users, and more. It aids in deciphering the intricate internal mechanisms of ``black box'' Machine Learning (ML), rendering the reasons behind their decisions more understandable. However, current research in XAI primarily focuses on two aspects; ways to facilitate user trust, or to debug and refine the ML model. The majority of it falls short of recognising the diverse types of explanations needed in broader contexts, as different users and varied application areas necessitate solutions tailored to their specific needs.  One such domain is Predictive Maintenance (PdM), an exploding area of research under the Industry 4.0 \& 5.0 umbrella. This position paper highlights the gap between existing XAI methodologies and the specific requirements for explanations within industr
    
[^24]: 关于文档级神经机器翻译的搜索策略

    On Search Strategies for Document-Level Neural Machine Translation. (arXiv:2306.05116v1 [cs.CL])

    [http://arxiv.org/abs/2306.05116](http://arxiv.org/abs/2306.05116)

    本文探讨了如何在搜索过程中最好地利用文档级神经机器翻译模型，比较了文献中的不同解码方案和作者提出的方案，并发现针对某些语言现象时，常用的解码策略不能够取得较好的性能。

    

    与句子级系统相比，文档级神经机器翻译（NMT）模型能够在一份文件中产生更一致的输出，并且能够更好地解决输入中的歧义。在文档级NMT上已经有许多研究，尤其是着重于修改模型架构或训练策略以更好地适应额外的上下文输入。然而，在大多数研究中，如何通过已训练好的模型执行搜索的问题很少被讨论，有时甚至根本不被提及。本研究旨在回答如何在解码中最好地利用上下文感知翻译模型的问题。我们从最流行的文档级NMT方法开始，比较了文献中的不同解码方案和我们提出的方案。比较中，我们使用了标准自动评价指标以及针对三个标准文档级翻译基准测试的特定语言现象。我们发现，大多数常用的解码策略在针对某些语言现象时并不能取得较好的性能。

    Compared to sentence-level systems, document-level neural machine translation (NMT) models produce a more consistent output across a document and are able to better resolve ambiguities within the input. There are many works on document-level NMT, mostly focusing on modifying the model architecture or training strategy to better accommodate the additional context-input. On the other hand, in most works, the question on how to perform search with the trained model is scarcely discussed, sometimes not mentioned at all. In this work, we aim to answer the question how to best utilize a context-aware translation model in decoding. We start with the most popular document-level NMT approach and compare different decoding schemes, some from the literature and others proposed by us. In the comparison, we are using both, standard automatic metrics, as well as specific linguistic phenomena on three standard document-level translation benchmarks. We find that most commonly used decoding strategies 
    
[^25]: FheFL：支持完全同态加密的隐私保护联邦学习与拜占庭用户

    FheFL: Fully Homomorphic Encryption Friendly Privacy-Preserving Federated Learning with Byzantine Users. (arXiv:2306.05112v1 [cs.AI])

    [http://arxiv.org/abs/2306.05112](http://arxiv.org/abs/2306.05112)

    本论文介绍了一种新的联邦学习算法，采用FHE加密技术，既可以保护模型更新的隐私，又可以防止恶意用户破坏全局模型。

    

    联邦学习（FL）技术最初是为了缓解传统机器学习范式中可能出现的数据隐私问题而开发的。尽管FL确保用户的数据始终保留在用户手中，但局部训练模型的梯度必须与集中式服务器通信以构建全局模型。这导致隐私泄露，使得服务器可以从共享的梯度中推断出用户数据的私密信息。为了缓解这一缺陷，下一代FL架构提出了加密和匿名化技术，以保护模型更新免受服务器的攻击。然而，这种方法会带来其他挑战，例如恶意用户可能通过共享虚假梯度来破坏全局模型。由于梯度被加密，服务器无法识别和排除不良用户以保护全局模型。因此，为了缓解这两种攻击，本文提出了一种基于完全同态加密（FHE）的新方案。

    The federated learning (FL) technique was initially developed to mitigate data privacy issues that can arise in the traditional machine learning paradigm. While FL ensures that a user's data always remain with the user, the gradients of the locally trained models must be communicated with the centralized server to build the global model. This results in privacy leakage, where the server can infer private information of the users' data from the shared gradients. To mitigate this flaw, the next-generation FL architectures proposed encryption and anonymization techniques to protect the model updates from the server. However, this approach creates other challenges, such as a malicious user might sabotage the global model by sharing false gradients. Since the gradients are encrypted, the server is unable to identify and eliminate rogue users which would protect the global model. Therefore, to mitigate both attacks, this paper proposes a novel fully homomorphic encryption (FHE) based scheme 
    
[^26]: PandaLM：LLM指令调优优化的自动评估基准

    PandaLM: An Automatic Evaluation Benchmark for LLM Instruction Tuning Optimization. (arXiv:2306.05087v1 [cs.CL])

    [http://arxiv.org/abs/2306.05087](http://arxiv.org/abs/2306.05087)

    PandaLM是一个评估LLM指令调优的自动基准，它能够区分最优模型，并关注于主观因素。

    

    由于超参数选择的复杂性和评估调整模型的困难性，LLM（大型语言模型）的指令调优仍然是一项具有挑战性的任务。为确定最佳超参数，需要一个自动的、强大且可靠的评估基准。然而，由于评估准确性和隐私保护的挑战，建立这样一个基准并不是一项简单的任务。为应对这些挑战，我们引入了一款名为PandaLM的评测大型语言模型，该模型经过训练，能够区分出多个LLM中最佳的模型。PandaLM的关注点不仅限于传统评估数据集的客观正确性，还涵盖了诸如相对简洁性、清晰度、遵循说明、全面性和形式性等重要主观因素。为确保PandaLM的可靠性，我们收集了一个多样化的人工注释测试数据集，其中所有上下文都是生成的。

    Instruction tuning large language models (LLMs) remains a challenging task, owing to the complexity of hyperparameter selection and the difficulty involved in evaluating the tuned models. To determine the optimal hyperparameters, an automatic, robust, and reliable evaluation benchmark is essential. However, establishing such a benchmark is not a trivial task due to the challenges associated with evaluation accuracy and privacy protection. In response to these challenges, we introduce a judge large language model, named PandaLM, which is trained to distinguish the superior model given several LLMs. PandaLM's focus extends beyond just the objective correctness of responses, which is the main focus of traditional evaluation datasets. It addresses vital subjective factors such as relative conciseness, clarity, adherence to instructions, comprehensiveness, and formality. To ensure the reliability of PandaLM, we collect a diverse human-annotated test dataset, where all contexts are generated
    
[^27]: 因果算法补救中时间的重要性

    The Importance of Time in Causal Algorithmic Recourse. (arXiv:2306.05082v1 [cs.AI])

    [http://arxiv.org/abs/2306.05082](http://arxiv.org/abs/2306.05082)

    因果算法补救需要纳入时间维度，以提高推荐的合理性和可靠性。

    

    算法补救在决策制定中具有实践意义，可以提供有利于改变不利决策的实现方案。尽管这些方法有了改进，但无法纳入时间维度仍然是这些方法面临的重大局限。在这项工作中，我们提出了将时间维度纳入因果算法补救方法中以提高推荐的合理性和可靠性的必要性。

    The application of Algorithmic Recourse in decision-making is a promising field that offers practical solutions to reverse unfavorable decisions. However, the inability of these methods to consider potential dependencies among variables poses a significant challenge due to the assumption of feature independence. Recent advancements have incorporated knowledge of causal dependencies, thereby enhancing the quality of the recommended recourse actions. Despite these improvements, the inability to incorporate the temporal dimension remains a significant limitation of these approaches. This is particularly problematic as identifying and addressing the root causes of undesired outcomes requires understanding time-dependent relationships between variables. In this work, we motivate the need to integrate the temporal dimension into causal algorithmic recourse methods to enhance recommendations' plausibility and reliability. The experimental evaluation highlights the significance of the role of 
    
[^28]: 分解伪变异的因果框架

    A Causal Framework for Decomposing Spurious Variations. (arXiv:2306.05071v1 [stat.ME])

    [http://arxiv.org/abs/2306.05071](http://arxiv.org/abs/2306.05071)

    本论文提出了一种因果框架，用于分解伪变异，包括虚假性图表和理论框架，能够在真假相关关系上帮助区分直接效应和间接效应。

    

    数据科学中一个根本性的挑战是解释为什么事情以特定的方式发生，或通过哪些机制某个变量$X$对另一个变量$Y$施加影响。本文提出了一种形式化工具，用于在马尔可夫和半马尔可夫系统中分解伪变异，引入了虚假性图表的概念，提出了一种理论框架，将伪效应分解为直接效应和间接效应，以识别生成这些虚假关系的基础因果机制。

    One of the fundamental challenges found throughout the data sciences is to explain why things happen in specific ways, or through which mechanisms a certain variable $X$ exerts influences over another variable $Y$. In statistics and machine learning, significant efforts have been put into developing machinery to estimate correlations across variables efficiently. In causal inference, a large body of literature is concerned with the decomposition of causal effects under the rubric of mediation analysis. However, many variations are spurious in nature, including different phenomena throughout the applied sciences. Despite the statistical power to estimate correlations and the identification power to decompose causal effects, there is still little understanding of the properties of spurious associations and how they can be decomposed in terms of the underlying causal mechanisms. In this manuscript, we develop formal tools for decomposing spurious variations in both Markovian and Semi-Mark
    
[^29]: 用逻辑程序捕获（最优的）松弛计划和稳定支持模型

    Capturing (Optimal) Relaxed Plans with Stable and Supported Models of Logic Programs. (arXiv:2306.05069v1 [cs.AI])

    [http://arxiv.org/abs/2306.05069](http://arxiv.org/abs/2306.05069)

    该论文介绍了一个新的方法，通过逻辑程序的稳定和支持模型，捕获能够产生松弛计划的行动子集，实验证明该方法可以提高计算松弛计划的效率，并且诊断编码是一种优秀的方法。

    

    我们建立了一个新颖的删除自由规划与逻辑编程之间的关系，这是AI Planning社区的一个重要任务，也被称为松弛规划。我们展示了对于一个规划问题，所有能够有序地产生该问题松弛计划的行动子集都可以通过描述相应松弛规划问题的逻辑程序的稳定模型进行双射捕获。我们还考虑了逻辑程序的支持模型语义，并引入了松弛规划问题的一个因果编码和一个诊断编码作为逻辑程序，都可以通过它们的支持模型捕获松弛计划。我们的实验结果表明，这些新编码在计算最优松弛计划时可以提供重大性能增益，我们的诊断编码在一系列STRIPS规划基准测试中的表现优于松弛规划的现有方法，无论给定时间限制如何。

    We establish a novel relation between delete-free planning, an important task for the AI Planning community also known as relaxed planning, and logic programming. We show that given a planning problem, all subsets of actions that could be ordered to produce relaxed plans for the problem can be bijectively captured with stable models of a logic program describing the corresponding relaxed planning problem. We also consider the supported model semantics of logic programs, and introduce one causal and one diagnostic encoding of the relaxed planning problem as logic programs, both capturing relaxed plans with their supported models. Our experimental results show that these new encodings can provide major performance gain when computing optimal relaxed plans, with our diagnostic encoding outperforming state-of-the-art approaches to relaxed planning regardless of the given time limit when measured on a wide collection of STRIPS planning benchmarks.
    
[^30]: 揭示机器学习中的代表性不足和抽样偏差问题

    Shedding light on underrepresentation and Sampling Bias in machine learning. (arXiv:2306.05068v1 [cs.LG])

    [http://arxiv.org/abs/2306.05068](http://arxiv.org/abs/2306.05068)

    文章讨论了机器学习中的偏见对公正性的影响，提出抽样偏差的变体：样本量偏差和代表性不足偏差，揭示歧视可以分解为方差、偏差和噪声，并挑战了通常被接受的缓解方法。

    

    准确地衡量歧视对于忠实地评估训练好的机器学习（ML）模型的公正性至关重要。存在任何测量歧视的偏见都会导致现有差距的放大或低估。存在几种偏见来源，假设机器学习导致的偏见在不同的群体（例如女性与男性、白人与黑人等）之间平等分配。然而，如果偏见在不同的群体中分别存在，可能会加剧对特定亚群体的歧视。抽样偏差是文献中描述由抽样程序引起的偏差的术语。在本文中，我们试图通过引入明确定义的抽样偏差变体，即样本量偏差和代表性不足偏差，来消除这个术语的歧义。我们还展示了如何将歧视分解为方差、偏差和噪声。最后，我们挑战了通常被接受的缓解方法，即通过“简单地”从训练数据中删除敏感属性（例如种族或性别）来解决歧视问题。

    Accurately measuring discrimination is crucial to faithfully assessing fairness of trained machine learning (ML) models. Any bias in measuring discrimination leads to either amplification or underestimation of the existing disparity. Several sources of bias exist and it is assumed that bias resulting from machine learning is born equally by different groups (e.g. females vs males, whites vs blacks, etc.). If, however, bias is born differently by different groups, it may exacerbate discrimination against specific sub-populations. Sampling bias, is inconsistently used in the literature to describe bias due to the sampling procedure. In this paper, we attempt to disambiguate this term by introducing clearly defined variants of sampling bias, namely, sample size bias (SSB) and underrepresentation bias (URB). We show also how discrimination can be decomposed into variance, bias, and noise. Finally, we challenge the commonly accepted mitigation approach that discrimination can be addressed b
    
[^31]: 提高自监督视觉Transformer可视化提示调整的方法

    Improving Visual Prompt Tuning for Self-supervised Vision Transformers. (arXiv:2306.05067v1 [cs.LG])

    [http://arxiv.org/abs/2306.05067](http://arxiv.org/abs/2306.05067)

    本文研究了自监督视觉Transformer中视觉提示调整方法的提升，并确定了提示记号插入后续图块而非第一个图块的最佳位置。提出的方法能有效地减少确定最佳提示记号块位置的成本。

    

    视觉提示调整（VPT）是一种适用于下游任务的预训练视觉Transformer（ViTs）的有效调整方法。它利用额外的可学习记号，称为提示，来指导冻结的预训练ViTs。虽然VPT在受监督的视觉Transformer中显示了其适用性，但在自监督情况下常常表现不佳。通过实证观察，我们推断VPT的有效性在很大程度上取决于提示记号与ViT图块相互作用的方式。具体来说，当提示记号插入后续图块而不是第一个图块时，VPT在MAE和MoCo v3图像分类任务中显示出了改进的性能。这些观察表明，存在适用于插入提示记号的最佳块的位置。不幸的是，确定每个自监督ViT内用于不同未来场景的提示的最佳块是一个昂贵的过程。为了缓解这个问题，我们提出了一种简单而有效的方法。

    Visual Prompt Tuning (VPT) is an effective tuning method for adapting pretrained Vision Transformers (ViTs) to downstream tasks. It leverages extra learnable tokens, known as prompts, which steer the frozen pretrained ViTs. Although VPT has demonstrated its applicability with supervised vision transformers, it often underperforms with self-supervised ones. Through empirical observations, we deduce that the effectiveness of VPT hinges largely on the ViT blocks with which the prompt tokens interact. Specifically, VPT shows improved performance on image classification tasks for MAE and MoCo v3 when the prompt tokens are inserted into later blocks rather than the first block. These observations suggest that there exists an optimal location of blocks for the insertion of prompt tokens. Unfortunately, identifying the optimal blocks for prompts within each self-supervised ViT for diverse future scenarios is a costly process. To mitigate this problem, we propose a simple yet effective method t
    
[^32]: 结果控制的因果公平性

    Causal Fairness for Outcome Control. (arXiv:2306.05066v1 [cs.AI])

    [http://arxiv.org/abs/2306.05066](http://arxiv.org/abs/2306.05066)

    本论文研究了一种特定的决策任务叫做结果控制，针对涉及到刑事司法、福利、临床决策以及公共卫生等多个方面，提出了因果公平的概念以及一组因果工具和技术来推断结果控制中的公平性。

    

    随着社会向基于人工智能的决策基础设施的过渡，越来越多的曾由人类控制的决策现在被委托给了自动化系统。尽管这样的发展使社会的各个方面更有效率，但大量的证据表明，需要非常小心地使这种自动化决策系统变得公平和公正，即考虑到诸如性别、种族和宗教等敏感属性。本文研究了一种特定的决策任务，称为结果控制，其中自动化系统旨在优化一个结果变量Y，同时保持公平和公正。对于这样一个设置的兴趣范围从与刑事司法和福利有关的干预措施，一直到临床决策和公共卫生。我们通过因果镜片首先分析了利益的概念，该概念捕捉了一个特定个体从积极决策中获得了多少好处，对照事实的公平性，捕捉了如果涉及到不同的敏感属性，问题所在，以及充分性的概念，它捕捉了需要多少干预来改善因果系统。然后，我们介绍了一组因果工具和技术来推断结果控制中的公平性。我们通过算法公平性的案例研究展示了我们的方法的有用性，其中我们控制了贷款决策过程中的不公平歧视。

    As society transitions towards an AI-based decision-making infrastructure, an ever-increasing number of decisions once under control of humans are now delegated to automated systems. Even though such developments make various parts of society more efficient, a large body of evidence suggests that a great deal of care needs to be taken to make such automated decision-making systems fair and equitable, namely, taking into account sensitive attributes such as gender, race, and religion. In this paper, we study a specific decision-making task called outcome control in which an automated system aims to optimize an outcome variable $Y$ while being fair and equitable. The interest in such a setting ranges from interventions related to criminal justice and welfare, all the way to clinical decision-making and public health. In this paper, we first analyze through causal lenses the notion of benefit, which captures how much a specific individual would benefit from a positive decision, counterfac
    
[^33]: 学习地球科学知识理解和利用的基础语言模型

    Learning A Foundation Language Model for Geoscience Knowledge Understanding and Utilization. (arXiv:2306.05064v1 [cs.CL])

    [http://arxiv.org/abs/2306.05064](http://arxiv.org/abs/2306.05064)

    本文首次提出了一个地球科学领域的大型语言模型K2，并开发了各种资源以进一步促进其在地球科学领域中的研究和应用，包括第一个地球科学教学调音数据集GeoSignal和第一个地球科学基准测试GeoBenchmark。我们使用了完整的方法将预先训练的通用领域LLM LLaMA-7B 模型适应到地球科学领域。

    

    大型语言模型(LLM)在自然语言处理的常规领域取得了巨大成功。本文将LLM引入地球科学领域，旨在推进该领域的研究和应用。为此，我们首次提出了地球科学领域的LLM，命名为K2，并开发了一系列资源，以进一步促进LLM在地球科学研究中的应用。例如，我们为LLM提供了第一个地球科学教学调音数据集GeoSignal，旨在将LLM相应与地球科学相关的用户查询对齐。此外，我们还建立了第一个地质科学基准测试GeoBenchmark，以在地球科学环境中评估LLM。在这项工作中，我们尝试使用完整的方法将预先训练的通用领域LLM适应到地球科学领域。具体而言，我们在超过100万篇地球科学文献上进一步训练了LLaMA-7B模型，并利用GeoSignal的监督数据对模型进行微调。此外，我们还分享了一个可以在不同领域中迁移LLM的协议。

    Large language models (LLMs)have achieved great success in general domains of natural language processing. In this paper, we bring LLMs to the realm of geoscience, with the objective of advancing research and applications in this field. To this end, we present the first-ever LLM in geoscience, K2, alongside a suite of resources developed to further promote LLM research within geoscience. For instance, we have curated the first geoscience instruction tuning dataset, GeoSignal, which aims to align LLM responses to geoscience-related user queries. Additionally, we have established the first geoscience benchmark, GeoBenchmark, to evaluate LLMs in the context of geoscience. In this work, we experiment with a complete recipe to adapt a pretrained general-domain LLM to the geoscience domain. Specifically, we further train the LLaMA-7B model on over 1 million pieces of geoscience literature and utilize GeoSignal's supervised data to fine-tune the model. Moreover, we share a protocol that can e
    
[^34]: 上下文感知的人类活动识别的神经符号方法

    Neuro-Symbolic Approaches for Context-Aware Human Activity Recognition. (arXiv:2306.05058v1 [cs.LG])

    [http://arxiv.org/abs/2306.05058](http://arxiv.org/abs/2306.05058)

    本文提出了一种采用语义损失函数的新方法，避免在分类过程中使用符号推理，可以解决现有上下文感知HAR的NeSy方法在部署和泛化能力方面的局限性。

    

    深度学习模型是传感器人类活动识别的标准解决方案，但是它们的部署常常受到标记数据不足和模型的不透明性的限制。神经符号人工智能（NeSy）为缓解这些问题提供了一个有趣的研究方向，即将关于上下文信息的知识注入到HAR深度学习分类器中。然而，现有的上下文感知HAR的NeSy方法需要在分类过程中使用计算复杂的符号推理器，使它们不太适合在资源受限的设备（例如移动设备）上部署。此外，用于上下文感知的HAR的NeSy方法从未在野外数据集上进行评估，它们在现实世界场景中的泛化能力也是有问题的。在本文中，我们提出了一种基于语义损失函数的新方法，通过在训练阶段注入知识约束来避免在分类过程中进行符号推理。我们在手稿和

    Deep Learning models are a standard solution for sensor-based Human Activity Recognition (HAR), but their deployment is often limited by labeled data scarcity and models' opacity. Neuro-Symbolic AI (NeSy) provides an interesting research direction to mitigate these issues by infusing knowledge about context information into HAR deep learning classifiers. However, existing NeSy methods for context-aware HAR require computationally expensive symbolic reasoners during classification, making them less suitable for deployment on resource-constrained devices (e.g., mobile devices). Additionally, NeSy approaches for context-aware HAR have never been evaluated on in-the-wild datasets, and their generalization capabilities in real-world scenarios are questionable. In this work, we propose a novel approach based on a semantic loss function that infuses knowledge constraints in the HAR model during the training phase, avoiding symbolic reasoning during classification. Our results on scripted and 
    
[^35]: Hebbian学习网络中的主动推理

    Active Inference in Hebbian Learning Networks. (arXiv:2306.05053v1 [cs.NE])

    [http://arxiv.org/abs/2306.05053](http://arxiv.org/abs/2306.05053)

    本文研究了具有局部Hebbian可塑性的仿脑神经群体如何执行主动推理，通过两个不同的Hebbian神经元组成的网络来生成捕捉环境动态的生成模型，使用Mountain Car环境进行实验研究，结果表明所提出的Hebbian AIF方法优于使用Q-learning，同时不需要回放缓冲区。

    

    本研究探讨了具有局部Hebbian可塑性的仿脑神经群体如何执行主动推理（AIF），以控制动态代理。通过由两个不同的Hebbian神经元组成的网络进行学习，生成了一个捕捉环境动态的生成模型：一个后验网络，用于在给定观测的情况下推断潜在状态，以及一个状态转移网络，用于在给定当前状态-动作对的情况下预测下一个期望的潜在状态。使用OpenAI gym套件中的Mountain Car环境进行实验研究，以研究各种Hebbian网络参数对任务性能的影响。结果表明，所提出的Hebbian AIF方法优于使用Q-learning，同时不需要回放缓冲区，如典型的强化学习系统。这些结果促使我们进一步探讨Hebbian学习，以设计能够学习环境动态而不需要重新访问过去缓冲区的AIF网络。

    This work studies how brain-inspired neural ensembles equipped with local Hebbian plasticity can perform active inference (AIF) in order to control dynamical agents. A generative model capturing the environment dynamics is learned by a network composed of two distinct Hebbian ensembles: a posterior network, which infers latent states given the observations, and a state transition network, which predicts the next expected latent state given current state-action pairs. Experimental studies are conducted using the Mountain Car environment from the OpenAI gym suite, to study the effect of the various Hebbian network parameters on the task performance. It is shown that the proposed Hebbian AIF approach outperforms the use of Q-learning, while not requiring any replay buffer, as in typical reinforcement learning systems. These results motivate further investigations of Hebbian learning for the design of AIF networks that can learn environment dynamics without the need for revisiting past buf
    
[^36]: 西班牙之火：基于卫星图像处理和大气信息的新型森林火灾风险评估模型

    Spain on Fire: A novel wildfire risk assessment model based on image satellite processing and atmospheric information. (arXiv:2306.05045v1 [cs.CV])

    [http://arxiv.org/abs/2306.05045](http://arxiv.org/abs/2306.05045)

    提出了一种基于卫星图像处理和大气信息的森林火灾风险评估模型，可预测森林火灾的经济和生态影响，并协助管理者对西班牙的危险地区进行资源分配和决策。

    

    每年，山火摧毁了西班牙更大的面积，威胁着众多生态系统。90%由人类引起（疏忽或故意）且个体行为不可预测。然而，大气和环境变量影响森林火灾的传播，它们可以使用深度学习进行分析。为了减轻这些事件的损害，我们提出了新型森林火灾评估模型（WAM）。我们的目标是预测森林火灾的经济和生态影响，协助管理者为西班牙的危险地区，卡斯蒂利亚-莱昂和安达卢西亚进行资源分配和决策。WAM使用残差式卷积网络结构对大气变量和绿度指数执行回归，计算必要的资源，控制和灭火时间以及预期烧伤面积。它首先在100,000个未标记数据的自我监督学习中进行预训练，并通过标记数据的监督回归任务进行微调。结果表明，该模型在平均绝对误差和决定系数方面优于传统方法。

    Each year, wildfires destroy larger areas of Spain, threatening numerous ecosystems. Humans cause 90% of them (negligence or provoked) and the behaviour of individuals is unpredictable. However, atmospheric and environmental variables affect the spread of wildfires, and they can be analysed by using deep learning. In order to mitigate the damage of these events we proposed the novel Wildfire Assessment Model (WAM). Our aim is to anticipate the economic and ecological impact of a wildfire, assisting managers resource allocation and decision making for dangerous regions in Spain, Castilla y Le\'on and Andaluc\'ia. The WAM uses a residual-style convolutional network architecture to perform regression over atmospheric variables and the greenness index, computing necessary resources, the control and extinction time, and the expected burnt surface area. It is first pre-trained with self-supervision over 100,000 examples of unlabelled data with a masked patch prediction objective and fine-tun
    
[^37]: 能源高效的下行语义生成通信与文本到图像生成器

    Energy-Efficient Downlink Semantic Generative Communication with Text-to-Image Generators. (arXiv:2306.05041v1 [cs.LG])

    [http://arxiv.org/abs/2306.05041](http://arxiv.org/abs/2306.05041)

    本论文提出了一种语义生成通信框架，在该框架中，生成型用户利用文本到图像生成器来创建本地图像，从而减少基站下行传输能量消耗，但会增加用户能源消耗。通过生成用户选择算法，总能耗可以降低高达54%。

    

    本文引入了一种新颖的语义生成通信 (SGC) 框架，在该框架中，生成型用户利用文本到图像 (T2I) 生成器从下载的文本提示本地创建图像，而非生成型用户直接从基站 (BS) 下载图像。虽然生成型用户帮助减少了基站下行传输能量，但它们消耗了额外的能源用于图像生成和上传它们的生成器状态信息 (GSI)。我们制定了一个生成用户选择算法，来解决最小化基站和用户总能量消耗的问题。仿真结果证实，与所有非生成型用户的基线相比，我们提出的算法将总能量消耗降低了高达 54%。

    In this paper, we introduce a novel semantic generative communication (SGC) framework, where generative users leverage text-to-image (T2I) generators to create images locally from downloaded text prompts, while non-generative users directly download images from a base station (BS). Although generative users help reduce downlink transmission energy at the BS, they consume additional energy for image generation and for uploading their generator state information (GSI). We formulate the problem of minimizing the total energy consumption of the BS and the users, and devise a generative user selection algorithm. Simulation results corroborate that our proposed algorithm reduces total energy by up to 54% compared to a baseline with all non-generative users.
    
[^38]: HCI挑战的映射：ChatGPT和GPT-4在成本效益问答中的应用与评估

    Mapping the Challenges of HCI: An Application and Evaluation of ChatGPT and GPT-4 for Cost-Efficient Question Answering. (arXiv:2306.05036v1 [cs.HC])

    [http://arxiv.org/abs/2306.05036](http://arxiv.org/abs/2306.05036)

    本文探讨了 ChatGPT 和 GPT-4 两个大型语言模型在实际情况下的运用和性能表现，通过以人机交互领域的研究挑战为例，结论是 ChatGPT 和 GPT-4 的组合是分析文本语料库的一种非常高效且节省成本的方法。

    

    大型语言模型（LLM）如ChatGPT和GPT-4正在广泛应用于实际情况。但是，这两种LLM是闭源的，并且很少有关于它们在实际使用案例中的性能的了解。在学术界中，LLM的性能通常是在基准测试中测量的，这些基准测试可能已泄漏到ChatGPT和GPT-4的训练数据中。本文中，我们将ChatGPT和GPT-4应用于成本效益问答的实际任务，以从2023年人机交互会议（CHI）的论文集中提取人机交互领域研究人员面临的挑战。我们对LLM在这个实际任务上进行了评估，并得出结论，ChatGPT和GPT-4的组合是分析文本语料库的极佳成本效益手段。成本效率对于原型研究想法和从不同角度分析文本语料库非常重要。

    Large language models (LLMs), such as ChatGPT and GPT-4, are gaining wide-spread real world use. Yet, the two LLMs are closed source, and little is known about the LLMs' performance in real-world use cases. In academia, LLM performance is often measured on benchmarks which may have leaked into ChatGPT's and GPT-4's training data. In this paper, we apply and evaluate ChatGPT and GPT-4 for the real-world task of cost-efficient extractive question answering over a text corpus that was published after the two LLMs completed training. More specifically, we extract research challenges for researchers in the field of HCI from the proceedings of the 2023 Conference on Human Factors in Computing Systems (CHI). We critically evaluate the LLMs on this practical task and conclude that the combination of ChatGPT and GPT-4 makes an excellent cost-efficient means for analyzing a text corpus at scale. Cost-efficiency is key for prototyping research ideas and analyzing text corpora from different persp
    
[^39]: 基于优先经验的渐进认知强化学习在多车辆追逐中的应用

    Progression Cognition Reinforcement Learning with Prioritized Experience for Multi-Vehicle Pursuit. (arXiv:2306.05016v1 [cs.AI])

    [http://arxiv.org/abs/2306.05016](http://arxiv.org/abs/2306.05016)

    本文提出了一种基于优先经验的渐进认知强化学习方法，在城市多交叉口动态交通场景下解决了多车辆追逐问题，并显著提高了追逐成功率。

    

    多车辆追逐（MVP），如自主警车追逐嫌疑人，由于其使命和安全重要性而显得很重要，但非常具有挑战性。尽管已经提出了多智能体强化学习（MARL）算法以解决结构化网格模式道路上MVP问题，但现有算法在集中式学习中使用随机训练样本，导致表现出低协作性的同质化智能体。针对更具挑战性的追逐多个逃避车辆的问题，这些算法通常会选择固定的逃避目标车辆，而不考虑动态交通情况，这会显著降低追逐成功率。为解决以上问题，本文在城市多交叉口动态交通场景中提出了一种基于优先经验的渐进认知强化学习PEPCRL-MVP技术。PEPCRL-MVP使用优先级网络来评估全局经验回放缓冲区中的转换。

    Multi-vehicle pursuit (MVP) such as autonomous police vehicles pursuing suspects is important but very challenging due to its mission and safety critical nature. While multi-agent reinforcement learning (MARL) algorithms have been proposed for MVP problem in structured grid-pattern roads, the existing algorithms use randomly training samples in centralized learning, which leads to homogeneous agents showing low collaboration performance. For the more challenging problem of pursuing multiple evading vehicles, these algorithms typically select a fixed target evading vehicle for pursuing vehicles without considering dynamic traffic situation, which significantly reduces pursuing success rate. To address the above problems, this paper proposes a Progression Cognition Reinforcement Learning with Prioritized Experience for MVP (PEPCRL-MVP) in urban multi-intersection dynamic traffic scenes. PEPCRL-MVP uses a prioritization network to assess the transitions in the global experience replay buf
    
[^40]: VIFS：一种端到端的变分推理用于Foley音效合成。

    VIFS: An End-to-End Variational Inference for Foley Sound Synthesis. (arXiv:2306.05004v1 [eess.AS])

    [http://arxiv.org/abs/2306.05004](http://arxiv.org/abs/2306.05004)

    本文提出了一种名为VIFS的端到端变分推理用于Foley音效合成的问题，通过一个“类别到声音”的方法生成多样化声音，并应用各种技术进行改良，包括PhaseAug和Avocado。

    

    DCASE 2023挑战任务7的目标是通过“类别到声音”的方法为Foley声音合成（FSS）生成各种声音剪辑。我们采用具有变分推理的文本到语音（TTS）模型VITS来生成给定类别的多样化声音，并应用了来自语音合成的各种技术，包括PhaseAug和Avocado。与TTS模型不同，类别到声音问题需要仅从类别索引生成多样化的声音。为了弥补这种差异，同时保持每个音频剪辑的一致性，我们大幅修改了先前的编码器以增强与后验潜在变量的一致性。这引入了额外的高斯分布，以促进类别内的方差。通过这些修改，我们提出了VIFS，即变分推理的端到端方法用于Foley音效合成。

    The goal of DCASE 2023 Challenge Task 7 is to generate various sound clips for Foley sound synthesis (FSS) by "category-to-sound" approach. "Category" is expressed by a single index while corresponding "sound" covers diverse and different sound examples. To generate diverse sounds for a given category, we adopt VITS, a text-to-speech (TTS) model with variational inference. In addition, we apply various techniques from speech synthesis including PhaseAug and Avocodo. Different from TTS models which generate short pronunciation from phonemes and speaker identity, the category-to-sound problem requires generating diverse sounds just from a category index. To compensate for the difference while maintaining consistency within each audio clip, we heavily modified the prior encoder to enhance consistency with posterior latent variables. This introduced additional Gaussian on the prior encoder which promotes variance within the category. With these modifications, we propose VIFS, variational i
    
[^41]: 负责任AI框架的快速评估：如何引导道德AI的开发

    A Rapid Review of Responsible AI frameworks: How to guide the development of ethical AI. (arXiv:2306.05003v1 [cs.AI])

    [http://arxiv.org/abs/2306.05003](http://arxiv.org/abs/2306.05003)

    该论文快速评估了数个提供指导原则，指南和/或工具的负责任AI框架，并发现其中极少数框架提供支持工具，且没有可同时支持技术和非技术利益相关方实现现实项目的“笼统”框架。

    

    近年来，人工智能（AI）的崛起及其在我们生活中的普及引发了有关应该在社会中引领其实施和使用的道德原则的繁荣辩论。由这些关切所驱动，我们对几个框架进行了快速回顾，这些框架提供了为开发和部署负责任AI（RAI）应用程序提供指导原则，指南和/或工具。我们将每个框架与不同软件开发生命周期（SDLC）阶段进行映射，发现其中大多数框架仅涵盖需求获取阶段，剩余阶段则无涉及。其中很少数的框架为从业者提供支持工具，主要是由私人公司提供的。我们的结果揭示了当前不存在可以同时支持技术和非技术利益相关方实现现实项目的“笼统”框架。我们的研究强调了缺乏全面框架的问题。

    In the last years, the raise of Artificial Intelligence (AI), and its pervasiveness in our lives, has sparked a flourishing debate about the ethical principles that should lead its implementation and use in society. Driven by these concerns, we conduct a rapid review of several frameworks providing principles, guidelines, and/or tools to help practitioners in the development and deployment of Responsible AI (RAI) applications. We map each framework w.r.t. the different Software Development Life Cycle (SDLC) phases discovering that most of these frameworks fall just in the Requirements Elicitation phase, leaving the other phases uncovered. Very few of these frameworks offer supporting tools for practitioners, and they are mainly provided by private companies. Our results reveal that there is not a "catching-all" framework supporting both technical and non-technical stakeholders in the implementation of real-world projects. Our findings highlight the lack of a comprehensive framework enc
    
[^42]: 利用液态时间常数网络在定向毫米波链路中预测障碍物

    Blockage Prediction in Directional mmWave Links Using Liquid Time Constant Network. (arXiv:2306.04997v1 [eess.SP])

    [http://arxiv.org/abs/2306.04997](http://arxiv.org/abs/2306.04997)

    本论文提出使用液态时间常数（LTC）网络，仅使用接收信号功率作为系统输入来预测毫米波链路中障碍的未来状态，实验结果表明LTC网络具有较高的准确性，可以带来更可靠和低延迟的通信。

    

    我们提出使用液态时间常数（LTC）网络，仅使用接收信号功率作为系统输入，来预测毫米波（mmWave）链路的未来障碍状态。LTC网络基于受生物启发的普通微分方程（ODE）系统，并专门用于近期预测输入的时间序列观察结果。利用60 GHz的实验数据集，我们展示了LTC的可靠预测障碍发生的情况和障碍的长度，无需特定情境数据。结果显示，所提出的LTC可以在不事先了解室外情况或重新训练/调整的情况下，具有高达97.85％的准确性。这些结果突显了使用LTC网络预测时间序列相关信号的潜在优势，可以带来更可靠和低延迟的通信。

    We propose to use a liquid time constant (LTC) network to predict the future blockage status of a millimeter wave (mmWave) link using only the received signal power as the input to the system. The LTC network is based on an ordinary differential equation (ODE) system inspired by biology and specialized for near-future prediction for time sequence observation as the input. Using an experimental dataset at 60 GHz, we show that our proposed use of LTC can reliably predict the occurrence of blockage and the length of the blockage without the need for scenario-specific data. The results show that the proposed LTC can predict with upwards of 97.85\% accuracy without prior knowledge of the outdoor scenario or retraining/tuning. These results highlight the promising gains of using LTC networks to predict time series-dependent signals, which can lead to more reliable and low-latency communication.
    
[^43]: CoCo: 一种用于无监督领域自适应图分类的耦合对比框架

    CoCo: A Coupled Contrastive Framework for Unsupervised Domain Adaptive Graph Classification. (arXiv:2306.04979v1 [cs.LG])

    [http://arxiv.org/abs/2306.04979](http://arxiv.org/abs/2306.04979)

    CoCo是一种耦合对比图表示学习框架，其中包含一个图卷积网络和一个分层图内核网络，通过耦合对比学习减少领域差异，用于无监督领域自适应图分类。

    

    虽然图神经网络在图分类中取得了显著成果，但它们通常需要大量特定任务的标签，这可能需要极大的代价来获得。一种可靠的解决方案是探索其他标注图以增强目标域的无监督学习，但如何将图神经网络应用到领域适应中仍未解决，因为对图拓扑的不充分探索以及相当大的领域偏差。本文提出了一种称为CoCo（Coupled Contrastive Graph Representation Learning）方案，该方案从耦合学习分支中提取拓扑信息，并通过耦合对比学习减少领域差异。CoCo包含一个图卷积网络分支和分层图内核网络分支，分别用隐式和显式方式探索图拓扑。此外，我们将耦合分支结合到一个全面的多视角对比学习框架中，

    Although graph neural networks (GNNs) have achieved impressive achievements in graph classification, they often need abundant task-specific labels, which could be extensively costly to acquire. A credible solution is to explore additional labeled graphs to enhance unsupervised learning on the target domain. However, how to apply GNNs to domain adaptation remains unsolved owing to the insufficient exploration of graph topology and the significant domain discrepancy. In this paper, we propose \underline{Co}upled \underline{Co}ntrastive Graph Representation Learning (\method{}), which extracts the topological information from coupled learning branches and reduces the domain discrepancy with coupled contrastive learning. \method{} contains a graph convolutional network branch and a hierarchical graph kernel network branch, which explore graph topology in implicit and explicit manners. Besides, we incorporate coupled branches into a holistic multi-view contrastive learning framework, which 
    
[^44]: 基于数据驱动置信度最小化的保守预测

    Conservative Prediction via Data-Driven Confidence Minimization. (arXiv:2306.04974v1 [cs.LG])

    [http://arxiv.org/abs/2306.04974](http://arxiv.org/abs/2306.04974)

    该论文提出了一种可以在处理不常见样本时推迟到人类判断的保守模型方法。该方法使用基于数据驱动置信度最小化（DCM）的算法，在辅助数据集中选择感兴趣的OOD（Out-of-Distribution）区域的样本，进而实现可靠地分离ID（In-Distribution）和OOD输入。

    

    机器学习模型的错误代价很高，特别是在诸如医疗保健等安全关键领域，这种错误可能会阻止机器学习的部署。在这些情况下，具有保守性的模型——当它们可能出现错误时可以推迟到人类判断——可能会提供解决方案。然而，检测异常或复杂示例明显具有挑战性，因为无法预测所有可能的测试输入。为了解决这个问题，先前的工作提出了在辅助伪OOD数据集上最小化模型置信度的方法。我们在理论上分析了置信度最小化的影响，并表明辅助数据集的选择是关键的。具体而言，如果辅助数据集包括来自感兴趣的OOD区域的样本，置信度最小化可以通过预测置信度可靠地分离ID和OOD输入。受到这一结果的启示，我们提出了基于数据驱动置信度最小化（DCM）的算法。

    Errors of machine learning models are costly, especially in safety-critical domains such as healthcare, where such mistakes can prevent the deployment of machine learning altogether. In these settings, conservative models -- models which can defer to human judgment when they are likely to make an error -- may offer a solution. However, detecting unusual or difficult examples is notably challenging, as it is impossible to anticipate all potential inputs at test time. To address this issue, prior work has proposed to minimize the model's confidence on an auxiliary pseudo-OOD dataset. We theoretically analyze the effect of confidence minimization and show that the choice of auxiliary dataset is critical. Specifically, if the auxiliary dataset includes samples from the OOD region of interest, confidence minimization provably separates ID and OOD inputs by predictive confidence. Taking inspiration from this result, we present data-driven confidence minimization (DCM), which minimizes confid
    
[^45]: arXiv4TGC：用于时态图聚类的大规模数据集

    arXiv4TGC: Large-Scale Datasets for Temporal Graph Clustering. (arXiv:2306.04962v1 [cs.AI])

    [http://arxiv.org/abs/2306.04962](http://arxiv.org/abs/2306.04962)

    arXiv4TGC提供了一组适用于大规模时态图聚类的新颖学术数据集，解决了缺乏可靠数据集来评估聚类性能的挑战。

    

    时态图聚类是时态图学习中的重要任务，其重点是在时态图上的节点聚类，并由于时态图方法的机制，为大规模图结构提供了更大的灵活性。然而，时态图聚类的发展目前存在一个显著问题：缺乏适合和可靠的大规模时态图数据集来评估聚类性能。为解决这一挑战，我们构建了arXiv4TGC，这是一组用于大规模时态图聚类的新颖学术数据集。其中，最大的数据集arXivLarge包含130万个有标签可用节点和1000万个时态边缘。

    Temporal graph clustering (TGC) is a crucial task in temporal graph learning. Its focus is on node clustering on temporal graphs, and it offers greater flexibility for large-scale graph structures due to the mechanism of temporal graph methods. However, the development of TGC is currently constrained by a significant problem: the lack of suitable and reliable large-scale temporal graph datasets to evaluate clustering performance. In other words, most existing temporal graph datasets are in small sizes, and even large-scale datasets contain only a limited number of available node labels. It makes evaluating models for large-scale temporal graph clustering challenging. To address this challenge, we build arXiv4TGC, a set of novel academic datasets (including arXivAI, arXivCS, arXivMath, arXivPhy, and arXivLarge) for large-scale temporal graph clustering. In particular, the largest dataset, arXivLarge, contains 1.3 million labeled available nodes and 10 million temporal edges. We further 
    
[^46]: FedMLSecurity：联邦学习与LLMs中攻击与防御的基准测试

    FedMLSecurity: A Benchmark for Attacks and Defenses in Federated Learning and LLMs. (arXiv:2306.04959v1 [cs.CR])

    [http://arxiv.org/abs/2306.04959](http://arxiv.org/abs/2306.04959)

    本文介绍了一个名为FedMLSecurity的基准测试，它可以模拟在联邦学习中可能出现的对抗攻击并提供相应的防御策略。该测试对各种机器学习模型和联合优化器都可以适用，并且能够轻松应用于大规模语言模型中。

    

    本文介绍了FedMLSecurity，这是一个在联邦学习（FL）中模拟对抗攻击和相应防御机制的基准测试。作为开源库FedML的一个重要模块，FedMLSecurity增强了FedML的安全评估能力。FedMLSecurity包含两个主要组件：FedMLAttacker模拟在FL训练中注入的攻击，而FedMLDefender则模拟旨在减轻攻击影响的防御策略。FedMLSecurity是开源的，可适用于各种机器学习模型（例如逻辑回归，ResNet，GAN等）和联合优化器（例如FedAVG，FedOPT，FedNOVA等）。本文的实验评估还展示了将FedMLSecurity轻松应用于LLMs的便利性，进一步强化了其各种场景下的通用性和实用性。

    This paper introduces FedMLSecurity, a benchmark that simulates adversarial attacks and corresponding defense mechanisms in Federated Learning (FL). As an integral module of the open-sourced library FedML that facilitates FL algorithm development and performance comparison, FedMLSecurity enhances the security assessment capacity of FedML. FedMLSecurity comprises two principal components: FedMLAttacker, which simulates attacks injected into FL training, and FedMLDefender, which emulates defensive strategies designed to mitigate the impacts of the attacks. FedMLSecurity is open-sourced 1 and is customizable to a wide range of machine learning models (e.g., Logistic Regression, ResNet, GAN, etc.) and federated optimizers (e.g., FedAVG, FedOPT, FedNOVA, etc.). Experimental evaluations in this paper also demonstrate the ease of application of FedMLSecurity to Large Language Models (LLMs), further reinforcing its versatility and practical utility in various scenarios.
    
[^47]: 论神经网络对降解多边形的感知存在的基本问题

    Degraded Polygons Raise Fundamental Questions of Neural Network Perception. (arXiv:2306.04955v1 [cs.CV])

    [http://arxiv.org/abs/2306.04955](http://arxiv.org/abs/2306.04955)

    本文研究了神经网络在识别具有不同程度边缘降解的规则多边形时的性能和行为，发现存在基本问题，揭示了人机视觉差距的另一个角度。

    

    现代计算机视觉系统往往表现出与人类不一致的行为：从对抗攻击到图像损坏，深度学习视觉模型在各种环境中都表现不佳，然而人类却能够很好地解决这些问题。本文从另一个角度研究了人机视觉差距。我们重新审视了恢复受损图像的任务，该任务在人类视觉的“识别组件”理论中首次引入，研究了神经网络在分类具有不同程度边缘降解的规则多边形时的性能和行为。为此，我们使用了自动化形状可恢复性测试，快速生成了大规模数据集，将历史上手动创建图像可恢复性实验的方法进行了现代化改进。我们进一步研究了神经网络识别多边形的能力以及其相关问题。

    It is well-known that modern computer vision systems often exhibit behaviors misaligned with those of humans: from adversarial attacks to image corruptions, deep learning vision models suffer in a variety of settings that humans capably handle. In light of these phenomena, here we introduce another, orthogonal perspective studying the human-machine vision gap. We revisit the task of recovering images under degradation, first introduced over 30 years ago in the Recognition-by-Components theory of human vision. Specifically, we study the performance and behavior of neural networks on the seemingly simple task of classifying regular polygons at varying orders of degradation along their perimeters. To this end, we implement the Automated Shape Recoverability Test for rapidly generating large-scale datasets of perimeter-degraded regular polygons, modernizing the historically manual creation of image recoverability experiments. We then investigate the capacity of neural networks to recognize
    
[^48]: ShuttleSet: 一份人工标注的羽毛球单打比赛的拍级数据集，用于战术分析。

    ShuttleSet: A Human-Annotated Stroke-Level Singles Dataset for Badminton Tactical Analysis. (arXiv:2306.04948v1 [cs.LG])

    [http://arxiv.org/abs/2306.04948](http://arxiv.org/abs/2306.04948)

    ShuttleSet是一份羽毛球单打比赛的拍级数据集，其中包含104场比赛、3,685轮比赛、36,492个拍击，并涵盖了27名排名前列的男子和女子单打选手。这些拍级记录将促进人工智能在体育分析领域的发展。

    

    随着体育分析的最新进展，深度学习方法已经展示出挖掘球员战术洞察力以提高表现质量和球迷参与度的有效性。这归因于公共基础真实数据集的可用性。虽然有一些用于行动检测的回合比赛的可用数据集，但这些数据集严重缺乏结构化的来源数据和拍级记录，因为这些需要来自领域专家的高成本标记工作，并且很难使用自动技术检测到。因此，当现有模型应用于更具挑战性的结构化回合序列时，人工智能方法的开发受到重大制约。在本文中，我们介绍了 ShuttleSet，这是最大的公开羽毛球单打比赛的拍级记录数据集。它包括2018年至2021年间的44场比赛中的104盘比赛，3,685轮比赛和36,492个拍击，并涵盖了27名排名前列的男子和女子单打选手。

    With the recent progress in sports analytics, deep learning approaches have demonstrated the effectiveness of mining insights into players' tactics for improving performance quality and fan engagement. This is attributed to the availability of public ground-truth datasets. While there are a few available datasets for turn-based sports for action detection, these datasets severely lack structured source data and stroke-level records since these require high-cost labeling efforts from domain experts and are hard to detect using automatic techniques. Consequently, the development of artificial intelligence approaches is significantly hindered when existing models are applied to more challenging structured turn-based sequences. In this paper, we present ShuttleSet, the largest publicly-available badminton singles dataset with annotated stroke-level records. It contains 104 sets, 3,685 rallies, and 36,492 strokes in 44 matches between 2018 and 2021 with 27 top-ranking men's singles and wome
    
[^49]: 在视觉问答中，通过相关问题和图像属性进行知识检测

    Knowledge Detection by Relevant Question and Image Attributes in Visual Question Answering. (arXiv:2306.04938v1 [cs.CV])

    [http://arxiv.org/abs/2306.04938](http://arxiv.org/abs/2306.04938)

    本研究提出了一种在视觉问答中提取问题相关知识的方法，避免了过度训练的模型错误地回答与图像无关的问题。

    

    视觉问答是一个跨学科的研究问题，通过自然语言处理和计算机视觉的实践追求解决。它能够根据图像的内容自动回答自然语言问题。某些测试问题需要外部知识才能得出解决方案。这种基于知识的视觉问答使用各种方法来检索图像和文本的特征，并将它们结合起来生成答案。为生成基于知识的答案，使用问题相关或图像相关的知识检索方法。如果获取有关图像中所有对象的知识，则不是所有知识都与问题相关。在另一方面，仅与问题相关的知识可能导致不正确的答案和过度训练的模型，这些模型回答与图像无关的问题。我们提出的方法将图像属性和问题特征作为输入输入到知识推导模块中，仅检索与问题相关的知识。

    Visual question answering (VQA) is a Multidisciplinary research problem that pursued through practices of natural language processing and computer vision. Visual question answering automatically answers natural language questions according to the content of an image. Some testing questions require external knowledge to derive a solution. Such knowledge-based VQA uses various methods to retrieve features of image and text, and combine them to generate the answer. To generate knowledgebased answers either question dependent or image dependent knowledge retrieval methods are used. If knowledge about all the objects in the image is derived, then not all knowledge is relevant to the question. On other side only question related knowledge may lead to incorrect answers and over trained model that answers question that is irrelevant to image. Our proposed method takes image attributes and question features as input for knowledge derivation module and retrieves only question relevant knowledge 
    
[^50]: covLLM：用于COVID-19生物医学文献的大型语言模型

    covLLM: Large Language Models for COVID-19 Biomedical Literature. (arXiv:2306.04926v1 [cs.CL])

    [http://arxiv.org/abs/2306.04926](http://arxiv.org/abs/2306.04926)

    使用大型语言模型开发了一种名为covLLM的工具，用于协助临床医生评估COVID-19文献。covLLM可以汇总和提取相关信息，帮助医生更好地应对COVID-19疫情。

    

    虽然新冠病毒的研究在不断增加，但COVID-19大流行导致了美国110万人的死亡。这些新发现在转化为临床干预方案方面缓慢，导致患者预后较差和不必要的死亡。其中一种原因是临床医生因患者过多而难以跟上新冠病毒文献的速度。发展一个使用大型语言模型（LLM）评估冠状病毒文献的工具，即神经网络用于自然语言处理，可能是一个解决方案。LLMs可用于汇总和提取用户指定的信息。较大范围和先进的LLMs和预处理的冠状病毒文献数据库提供了通过冠状病毒文献特定LLM（covLLM）协助临床医生评估冠状病毒文献的机会，该工具直接输入研究文章和用户查询以返回答案。在使用COVID-19开放研究数据集（CORD-19）的过程中，我们开发和评估了covLLM，展示了它在总结和从冠状病毒文献中提取信息方面的实用性。

    The COVID-19 pandemic led to 1.1 million deaths in the United States, despite the explosion of coronavirus research. These new findings are slow to translate to clinical interventions, leading to poorer patient outcomes and unnecessary deaths. One reason is that clinicians, overwhelmed by patients, struggle to keep pace with the rate of new coronavirus literature. A potential solution is developing a tool for evaluating coronavirus literature using large language models (LLMs) -- neural networks that are deployed for natural language processing. LLMs can be used to summarize and extract user-specified information. The greater availability and advancement of LLMs and pre-processed coronavirus literature databases provide the opportunity to assist clinicians in evaluating coronavirus literature through a coronavirus literature specific LLM (covLLM), a tool that directly takes an inputted research article and a user query to return an answer. Using the COVID-19 Open Research Dataset (CORD
    
[^51]: 测试时间风格转换：处理领域泛化中任意风格问题

    Test-Time Style Shifting: Handling Arbitrary Styles in Domain Generalization. (arXiv:2306.04911v1 [cs.CV])

    [http://arxiv.org/abs/2306.04911](http://arxiv.org/abs/2306.04911)

    本文提出了测试时间风格转换（test-time style shifting）的方法，使得模型能够有效地处理领域泛化任务中任意风格的问题，同时避免了额外的模型更新。

    

    领域泛化（DG）要求为未知目标域进行训练，且在推理时需要成功应用于任意（甚至是未见）的目标域。本文提出了一种简单而有效的方法来解决这个难题。我们提出了测试时间风格转换（test-time style shifting），在进行预测之前，将测试样本的风格（与源域存在较大差异的）转换为最接近模型已知的源域，从而使模型能够应对具有任意风格统计的任何目标域，无需在测试时进行额外的模型更新。此外，我们提出了风格平衡（style balancing），它为最大化测试时间风格转换的优势提供了良好的平台，同时解决了DG特定的不平衡问题。所提出的思路易于实现，且成功地完成了领域泛化任务。

    In domain generalization (DG), the target domain is unknown when the model is being trained, and the trained model should successfully work on an arbitrary (and possibly unseen) target domain during inference. This is a difficult problem, and despite active studies in recent years, it remains a great challenge. In this paper, we take a simple yet effective approach to tackle this issue. We propose test-time style shifting, which shifts the style of the test sample (that has a large style gap with the source domains) to the nearest source domain that the model is already familiar with, before making the prediction. This strategy enables the model to handle any target domains with arbitrary style statistics, without additional model update at test-time. Additionally, we propose style balancing, which provides a great platform for maximizing the advantage of test-time style shifting by handling the DG-specific imbalance issues. The proposed ideas are easy to implement and successfully wor
    
[^52]: 多级蛋白质表示学习用于盲变异效应预测

    Multi-level Protein Representation Learning for Blind Mutational Effect Prediction. (arXiv:2306.04899v1 [q-bio.QM])

    [http://arxiv.org/abs/2306.04899](http://arxiv.org/abs/2306.04899)

    本文提出了一个新的预训练框架，通过级联蛋白一级和三级结构的序列和几何分析器，引导变异方向，用于预测蛋白质变异体的效应，并在公共数据库上取得了优于现有方法的预测精度。

    

    定向进化在蛋白工程中扮演着不可或缺的角色，通过修订现有的蛋白序列以获得新的或增强的功能。精确预测蛋白变异体的效应需要深入理解蛋白质结构与功能。虽然大型自监督语言模型仅使用蛋白序列就表现出了出色的零样本推理能力，但这些模型固有地不解释蛋白质结构的空间特征，这对于理解蛋白质折叠稳定性和分子内相互作用至关重要。本文介绍了一种新的预训练框架，它将蛋白一级和三级结构的序列和几何分析器级联起来。通过模拟野生型蛋白质上的自然选择，将变异方向引导到期望的特性上，并基于其执行功能的适应性评估变异体的效应。我们使用一个包含20种蛋白质的公共数据库中的328,594个变异体对所提出的方法进行评估，它在不同的评估指标上表现优于现有的方法。

    Directed evolution plays an indispensable role in protein engineering that revises existing protein sequences to attain new or enhanced functions. Accurately predicting the effects of protein variants necessitates an in-depth understanding of protein structure and function. Although large self-supervised language models have demonstrated remarkable performance in zero-shot inference using only protein sequences, these models inherently do not interpret the spatial characteristics of protein structures, which are crucial for comprehending protein folding stability and internal molecular interactions. This paper introduces a novel pre-training framework that cascades sequential and geometric analyzers for protein primary and tertiary structures. It guides mutational directions toward desired traits by simulating natural selection on wild-type proteins and evaluates the effects of variants based on their fitness to perform the function. We assess the proposed approach using a public datab
    
[^53]: 基于大数据和人工智能的框架实现无线网络个性化服务

    Big-data-driven and AI-based framework to enable personalization in wireless networks. (arXiv:2306.04887v1 [cs.AI])

    [http://arxiv.org/abs/2306.04887](http://arxiv.org/abs/2306.04887)

    本论文提出了一种基于大数据和人工智能的框架，通过利用实时用户反馈和多目标优化模型来实现无线网络的个性化服务，优化服务质量和用户满意度。

    

    当前的通信网络使用的设计方法导致网络效率无法最大化。现有网络普遍被设计成“通用套装”，无法满足不同用户对网络服务的不同需求。同时，当前的网络缺乏用户级别的数据认知智能，无法通过自动化实现快速的个性化网络决策和操作。因此，在本文中，我们提出利用人工智能、大数据分析和实时非侵入式用户反馈来实现无线网络的个性化服务。基于每个用户的实际服务质量要求和环境，我们提出了一种多目标优化模型，同时优化提供的服务质量和用户满意度水平。此外，为了实现用户反馈的跟踪和衡量，我们提出了一种基于用户满意度模型的方法。

    Current communication networks use design methodologies that prevent the realization of maximum network efficiency. In the first place, while users' perception of satisfactory service diverges widely, current networks are designed to be a "universal fit," where they are generally over-engineered to deliver services appealing to all types of users. Also, current networks lack user-level data cognitive intelligence that would enable fast personalized network decisions and actions through automation. Thus, in this article, we propose the utilization of AI, big data analytics, and real-time non-intrusive user feedback in order to enable the personalization of wireless networks. Based on each user's actual QoS requirements and context, a multi-objective formulation enables the network to micro-manage and optimize the provided QoS and user satisfaction levels simultaneously. Moreover, in order to enable user feedback tracking and measurement, we propose a user satisfaction model based on the
    
[^54]: 扩大范围：将英文对抗攻击方法适应到中文上的研究

    Expanding Scope: Adapting English Adversarial Attacks to Chinese. (arXiv:2306.04874v1 [cs.CL])

    [http://arxiv.org/abs/2306.04874](http://arxiv.org/abs/2306.04874)

    本文研究将英文的对抗攻击方法适用于中文上，并证明了这些方法可以生成高质量的中文对抗实例。通过关注中文的语言特点，生成的对抗实例可以实现高流畅度和语义一致性，从而可以用来提高中文NLP模型的对抗鲁棒性。

    

    最近的研究表明，自然语言处理(NLP)的预测模型容易受到对抗攻击。多数现有的研究着眼于设计攻击方式来评估英语语境下的NLP模型的鲁棒性。然而学术界对其它语言的NLP解决方案需求日益增长。因此，我们自然产生一个问题：当前最先进的对抗攻击方法是否能够泛化到其它语言中？本文研究了如何将在英文环境下的最先进的对抗攻击算法适应到中文上。我们的实验表明，当结合正确的文本分割和语言限制时，先前针对英文NLP的攻击方法也能够在中文中生成高质量的对抗性例子。此外，我们还证明了，通过关注中文的形态和音系，生成的对抗实例可以实现高流畅度和语义一致性，从而可以用来提高中文NLP模型的对抗鲁棒性。

    Recent studies have revealed that NLP predictive models are vulnerable to adversarial attacks. Most existing studies focused on designing attacks to evaluate the robustness of NLP models in the English language alone. Literature has seen an increasing need for NLP solutions for other languages. We, therefore, ask one natural question: whether state-of-the-art (SOTA) attack methods generalize to other languages. This paper investigates how to adapt SOTA adversarial attack algorithms in English to the Chinese language. Our experiments show that attack methods previously applied to English NLP can generate high-quality adversarial examples in Chinese when combined with proper text segmentation and linguistic constraints. In addition, we demonstrate that the generated adversarial examples can achieve high fluency and semantic consistency by focusing on the Chinese language's morphology and phonology, which in turn can be used to improve the adversarial robustness of Chinese NLP models.
    
[^55]: “联邦学习中客户端选择的系统性文献综述”

    A Systematic Literature Review on Client Selection in Federated Learning. (arXiv:2306.04862v1 [cs.LG])

    [http://arxiv.org/abs/2306.04862](http://arxiv.org/abs/2306.04862)

    联邦学习中客户端选择的主要挑战是异质性、资源分配、通信成本和公平性。客户选择方案旨在解决这些挑战，最常用的指标是测试准确性与通信轮次。

    

    由于对机器学习中隐私的担忧，联邦学习（FL）在2017年被发明，其中客户端（如移动设备）训练模型并将更新发送到集中式服务器。随机选择客户端进行FL可能会对学习性能造成伤害，因为原因各异。许多研究提出了解决FL客户端选择挑战的方法。然而，这一主题的系统性文献综述（SLR）不存在。本文的SLR调查了联邦学习中客户端选择的现状，并回答了挑战、解决方案和评估解决方案时使用的指标。我们对47篇主要研究进行了系统综述。在客户端选择方面，主要挑战是异质性、资源分配、通信成本和公平性。客户选择方案旨在通过专注于上述一项或几项挑战来改进原始的随机选择算法。最常用的指标是测试准确性与通信轮次。

    With the arising concerns of privacy within machine learning, federated learning (FL) was invented in 2017, in which the clients, such as mobile devices, train a model and send the update to the centralized server. Choosing clients randomly for FL can harm learning performance due to different reasons. Many studies have proposed approaches to address the challenges of client selection of FL. However, no systematic literature review (SLR) on this topic existed. This SLR investigates the state of the art of client selection in FL and answers the challenges, solutions, and metrics to evaluate the solutions. We systematically reviewed 47 primary studies. The main challenges found in client selection are heterogeneity, resource allocation, communication costs, and fairness. The client selection schemes aim to improve the original random selection algorithm by focusing on one or several of the aforementioned challenges. The most common metric used is testing accuracy versus communication rou
    
[^56]: 学习空间数据分区

    Learned spatial data partitioning. (arXiv:2306.04846v1 [cs.DB])

    [http://arxiv.org/abs/2306.04846](http://arxiv.org/abs/2306.04846)

    本文介绍了一种通过机器学习技术学习空间数据分区的方法，在强化学习的框架下开发了深度强化学习算法。实验表明该算法能够有效地加速距离连接查询，缩短工作负载运行时间高达59.4％。

    

    随着空间数据的大小显著增加，使用分布式并行处理系统有效地分析空间数据变得至关重要。本文首先研究了学习空间数据分区，该方法使用机器学习技术通过基于数据位置的分组将大规模空间数据分配到计算机上。我们在强化学习的上下文中形式化了空间数据分区，并开发了一种新颖的深度强化学习算法。我们的学习算法利用空间数据分区的特征，并剪枝无效的学习过程，以有效地找到最优分区。我们的实验研究使用Apache Sedona和真实的空间数据，证明了我们的方法能够有效地找到分区，加速距离连接查询，并将工作负载运行时间缩短了59.4％。

    Due to the significant increase in the size of spatial data, it is essential to use distributed parallel processing systems to efficiently analyze spatial data. In this paper, we first study learned spatial data partitioning, which effectively assigns groups of big spatial data to computers based on locations of data by using machine learning techniques. We formalize spatial data partitioning in the context of reinforcement learning and develop a novel deep reinforcement learning algorithm. Our learning algorithm leverages features of spatial data partitioning and prunes ineffective learning processes to find optimal partitions efficiently. Our experimental study, which uses Apache Sedona and real-world spatial data, demonstrates that our method efficiently finds partitions for accelerating distance join queries and reduces the workload run time by up to 59.4%.
    
[^57]: 增强图神经网络的反事实推理能力通过归纳性

    Empowering Counterfactual Reasoning over Graph Neural Networks through Inductivity. (arXiv:2306.04835v1 [cs.LG])

    [http://arxiv.org/abs/2306.04835](http://arxiv.org/abs/2306.04835)

    本研究引入了一种归纳算法INDUCE来增强图神经网络的反事实推理能力，改进了现有算法中存在的限制，通过在多个数据集上进行广泛的实验证明了其可行性。

    

    图神经网络（GNN）有多种实际应用，例如药物发现、推荐引擎和芯片设计。但是，GNN缺乏透明度，因为它们无法提供可理解的解释来支持其预测。为了解决这个问题，使用了反事实推理。其主要目标是对GNN的输入图进行最小更改，以改变其预测结果。虽然已经提出了几种算法来解释GNN的反事实结果，但它们大多存在两个主要缺点。首先，它们只考虑边删除作为扰动。其次，反事实解释模型是传导性的，意味着它们不能推广到未见过的数据。在本研究中，我们引入了一种称为INDUCE的归纳算法来克服这些限制。通过在多个数据集上进行广泛的实验，我们证明了包括边添加在内的改进可获得比现有方法更好的反事实结果。此外，归纳模型在未见过的数据上也展现了良好的泛化性。

    Graph neural networks (GNNs) have various practical applications, such as drug discovery, recommendation engines, and chip design. However, GNNs lack transparency as they cannot provide understandable explanations for their predictions. To address this issue, counterfactual reasoning is used. The main goal is to make minimal changes to the input graph of a GNN in order to alter its prediction. While several algorithms have been proposed for counterfactual explanations of GNNs, most of them have two main drawbacks. Firstly, they only consider edge deletions as perturbations. Secondly, the counterfactual explanation models are transductive, meaning they do not generalize to unseen data. In this study, we introduce an inductive algorithm called INDUCE, which overcomes these limitations. By conducting extensive experiments on several datasets, we demonstrate that incorporating edge additions leads to better counterfactual results compared to the existing methods. Moreover, the inductive mo
    
[^58]: Etsy搜索中统一嵌入式个性化检索的方法

    Unified Embedding Based Personalized Retrieval in Etsy Search. (arXiv:2306.04833v1 [cs.IR])

    [http://arxiv.org/abs/2306.04833](http://arxiv.org/abs/2306.04833)

    本论文提出了一种将图形、转换和基于术语的嵌入结合起来的统一嵌入模型，并利用端到端训练模型进行个性化检索，以解决Etsy搜索中的语义差距问题。同时，本文分享了特征工程、硬负采样策略和应用变压器模型的新策略，以构建具有工业规模的模型来改善整体搜索体验。

    

    基于嵌入式神经网络的信息检索已经成为解决尾查询中经常出现的语义差距问题的普遍方法。与此同时，热门查询通常缺乏上下文，有广泛的意图，用户历史互动的附加上下文有助于解决问题。本文介绍了我们解决语义差距问题的新方法，以及一种用于个性化语义检索的端到端训练模型。我们建议学习一种统一的嵌入模型，包括基于图形、变压器和术语的嵌入，同时分享了我们的设计选择，以在性能和效率之间实现最佳权衡。我们分享了特征工程、硬负采样策略和变压器模型的应用方面的经验教训，包括用于提高搜索相关性和部署此类模型的一种新颖的预训练策略和其他技巧。我们的个性化检索模型显着提高了整体搜索体验。

    Embedding-based neural retrieval is a prevalent approach to address the semantic gap problem which often arises in product search on tail queries. In contrast, popular queries typically lack context and have a broad intent where additional context from users historical interaction can be helpful. In this paper, we share our novel approach to address both: the semantic gap problem followed by an end to end trained model for personalized semantic retrieval. We propose learning a unified embedding model incorporating graph, transformer and term-based embeddings end to end and share our design choices for optimal tradeoff between performance and efficiency. We share our learnings in feature engineering, hard negative sampling strategy, and application of transformer model, including a novel pre-training strategy and other tricks for improving search relevance and deploying such a model at industry scale. Our personalized retrieval model significantly improves the overall search experience,
    
[^59]: 重新审视知识图谱完成问题的推理基准

    Revisiting Inferential Benchmarks for Knowledge Graph Completion. (arXiv:2306.04814v1 [cs.AI])

    [http://arxiv.org/abs/2306.04814](http://arxiv.org/abs/2306.04814)

    该论文提出了一种新的KG完成基准设计方法，用于评估模型学习推理模式的能力。他们的方法基于一组逻辑规则，使得缺失的事实是规则应用的结果。使用他们的基准FB15k-237，表明它比以前的基准更具有区分度，可以评估模型推广到新模式的能力。

    

    知识图谱（KG）完成是将不完整的KG与缺失的事实扩展的问题。KG完成的机器学习方法的一个关键特征是能够学习推理模式，以便预测的事实是将这些模式应用于KG的结果。然而，标准的完成基准不适合评估模型学习模式的能力，因为这些基准的训练和测试集是给定KG的随机拆分，因此不捕捉推理模式的因果关系。我们提出了一种新的KG完成基准设计方法，基于以下原则：有一组逻辑规则，使得缺失的事实是规则应用的结果；训练集包括匹配规则前提和相应结论的前提；测试集由将规则应用于训练集得出的结果组成；负面示例旨在防止模型学习虚假的模式。我们使用一项基准实例化了我们的方法，即FB15k-237，并表明它比以前的基准更具有区分度，可以评估模型推广到新模式的能力。

    Knowledge Graph (KG) completion is the problem of extending an incomplete KG with missing facts. A key feature of Machine Learning approaches for KG completion is their ability to learn inference patterns, so that the predicted facts are the results of applying these patterns to the KG. Standard completion benchmarks, however, are not well-suited for evaluating models' abilities to learn patterns, because the training and test sets of these benchmarks are a random split of a given KG and hence do not capture the causality of inference patterns. We propose a novel approach for designing KG completion benchmarks based on the following principles: there is a set of logical rules so that the missing facts are the results of the rules' application; the training set includes both premises matching rule antecedents and the corresponding conclusions; the test set consists of the results of applying the rules to the training set; the negative examples are designed to discourage the models from 
    
[^60]: 人为参与的创新生成

    Human in the Loop Novelty Generation. (arXiv:2306.04813v1 [cs.AI])

    [http://arxiv.org/abs/2306.04813](http://arxiv.org/abs/2306.04813)

    该论文提出了一种新的创新生成方法，使用环境的抽象模型而不需要人类专业知识来生成新的新颖性。这可以产生更大的、通常是无限的新颖性空间，但需要人类的指导来选择和过滤这些新颖性。

    

    开发人工智能以应对新颖、意外情况是一个困难而尚未解决的问题。在推动新颖性容纳的技术发展方面，一个挑战是缺乏测试框架，以评估在新颖情况下的表现。最近在“科学鸟”和“大富翁”等领域中出现的新颖性生成方法利用了人类领域专业知识进行搜索，以发现新的新颖性。这些方法在新颖性生成之前引入人类指导，产生的创新可以直接加载到模拟环境中。我们提出了一种新的创新生成方法，使用环境的抽象模型（包括模拟领域），不需要依赖于特定领域的人类指导来生成创新。一个关键结果是可以生成更大的、通常是无限的新颖性空间，但需要在生成后涉及人类指导以选择和过滤新颖性。

    Developing artificial intelligence approaches to overcome novel, unexpected circumstances is a difficult, unsolved problem. One challenge to advancing the state of the art in novelty accommodation is the availability of testing frameworks for evaluating performance against novel situations. Recent novelty generation approaches in domains such as Science Birds and Monopoly leverage human domain expertise during the search to discover new novelties. Such approaches introduce human guidance before novelty generation occurs and yield novelties that can be directly loaded into a simulated environment. We introduce a new approach to novelty generation that uses abstract models of environments (including simulation domains) that do not require domain-dependent human guidance to generate novelties. A key result is a larger, often infinite space of novelties capable of being generated, with the trade-off being a requirement to involve human guidance to select and filter novelties post generatio
    
[^61]: 生成文本引导的三维视觉语言预训练用于统一医学图像分割

    Generative Text-Guided 3D Vision-Language Pretraining for Unified Medical Image Segmentation. (arXiv:2306.04811v1 [cs.CV])

    [http://arxiv.org/abs/2306.04811](http://arxiv.org/abs/2306.04811)

    本文提出了一种生成文本引导的三维视觉语言预训练用于统一医学图像分割的框架，不需要大规模的图像-文本对，可用于3D医学图像并且性能优越。

    

    视觉语言预训练（VLP）已经表现出在没有注释的情况下从图像的文本描述中学习视觉表示方面的显着能力。然而，有效的VLP需要大规模的图像-文本对，而医学领域中缺乏这种资源。此外，传统的VLP仅限于2D图像，而医学图像包括不同的模态，通常是3D图像，使得学习过程更具挑战性。为了解决这些挑战，我们提出了一种生成文本引导的三维视觉语言预训练用于统一医学图像分割（GTGM）的框架，该框架扩展了VLP以适用于不依赖配对文本描述的三维医学图像。具体而言，GTGM利用大型语言模型（LLM）从三维医学图像生成医学风格的文本。然后，这个合成文本被用来监督三维视觉表示的学习。此外，引入了一种无负对比学习目标策略，来培养一致的视觉表示。在两个公共的医学图像分割基准测试上的实验结果表明，GTGM优于几种最先进的基准算法，并且在降低医学注释需求的同时实现了与完全监督方法相当的性能。

    Vision-Language Pretraining (VLP) has demonstrated remarkable capabilities in learning visual representations from textual descriptions of images without annotations. Yet, effective VLP demands large-scale image-text pairs, a resource that suffers scarcity in the medical domain. Moreover, conventional VLP is limited to 2D images while medical images encompass diverse modalities, often in 3D, making the learning process more challenging. To address these challenges, we present Generative Text-Guided 3D Vision-Language Pretraining for Unified Medical Image Segmentation (GTGM), a framework that extends of VLP to 3D medical images without relying on paired textual descriptions. Specifically, GTGM utilizes large language models (LLM) to generate medical-style text from 3D medical images. This synthetic text is then used to supervise 3D visual representation learning. Furthermore, a negative-free contrastive learning objective strategy is introduced to cultivate consistent visual representat
    
[^62]: 黑盒序贯决策系统的自主能力评估

    Autonomous Capability Assessment of Black-Box Sequential Decision-Making Systems. (arXiv:2306.04806v1 [cs.AI])

    [http://arxiv.org/abs/2306.04806](http://arxiv.org/abs/2306.04806)

    本论文提出了一种新方法，可以有效地评估黑盒SDM系统的能力，该方法使用主动学习来建立一个可解释的概率模型，能够准确地描述其能力和在随机环境中执行这些能力的可能效果和要求。

    

    理解AI系统的能力和局限性对于安全地使用它们是至关重要的。然而，让用户评估具有不断发展的序贯决策能力的AI系统的问题相对少有研究。本文提出了一种新方法，用于建模黑盒AI系统的能力，包括在随机环境中执行这些能力的可能效果和要求。我们提出了一种主动学习方法，可以有效地与黑盒SDM系统交互，并学习描述其能力的可解释概率模型。对该方法的理论分析确定了学习过程收敛到代理正确模型的条件；对不同代理和模拟场景的实证评估表明，该方法可以有效地描述任意黑盒SDM代理的能力，并能进行少次通用化。

    It is essential for users to understand what their AI systems can and can't do in order to use them safely. However, the problem of enabling users to assess AI systems with evolving sequential decision making (SDM) capabilities is relatively understudied. This paper presents a new approach for modeling the capabilities of black-box AI systems that can plan and act, along with the possible effects and requirements for executing those capabilities in stochastic settings. We present an active-learning approach that can effectively interact with a black-box SDM system and learn an interpretable probabilistic model describing its capabilities. Theoretical analysis of the approach identifies the conditions under which the learning process is guaranteed to converge to the correct model of the agent; empirical evaluations on different agents and simulated scenarios show that this approach is few-shot generalizable and can effectively describe the capabilities of arbitrary black-box SDM agents 
    
[^63]: 医疗知识图谱综述：资源、应用和前景

    A Survey on Knowledge Graphs for Healthcare: Resources, Applications, and Promises. (arXiv:2306.04802v1 [cs.AI])

    [http://arxiv.org/abs/2306.04802](http://arxiv.org/abs/2306.04802)

    本论文综述了医疗知识图谱(HKGs)的构建流程、关键技术和利用方法以及现有资源，并深入探讨了HKG在各种医疗领域的变革性影响。

    

    医疗知识图谱(HKGs)已成为组织医学知识的有结构且可解释的有为工具，提供了医学概念及其关系的全面视图。然而，数据异质性和覆盖范围有限等挑战仍然存在，强调了在HKG领域需要进一步研究的必要性。本综述是HKG的第一份综合概述。我们总结了HKG构建的流程和关键技术（即从头开始和通过集成），以及常见的利用方法（即基于模型和非基于模型）。为了为研究人员提供有价值的资源，我们根据它们捕获的数据类型和应用领域（该资源存储于https://github.com/lujiaying/Awesome-HealthCare-KnowledgeBase）组织了现有的HKG，并提供了相关的统计信息。在应用部分，我们深入探讨了HKG在各种医疗领域的变革性影响。

    Healthcare knowledge graphs (HKGs) have emerged as a promising tool for organizing medical knowledge in a structured and interpretable way, which provides a comprehensive view of medical concepts and their relationships. However, challenges such as data heterogeneity and limited coverage remain, emphasizing the need for further research in the field of HKGs. This survey paper serves as the first comprehensive overview of HKGs. We summarize the pipeline and key techniques for HKG construction (i.e., from scratch and through integration), as well as the common utilization approaches (i.e., model-free and model-based). To provide researchers with valuable resources, we organize existing HKGs (The resource is available at https://github.com/lujiaying/Awesome-HealthCare-KnowledgeBase) based on the data types they capture and application domains, supplemented with pertinent statistical information. In the application section, we delve into the transformative impact of HKGs across various hea
    
[^64]: 使用生成模型进行观测因果分析

    On the Use of Generative Models in Observational Causal Analysis. (arXiv:2306.04792v1 [cs.AI])

    [http://arxiv.org/abs/2306.04792](http://arxiv.org/abs/2306.04792)

    该论文探讨了使用生成模型进行因果分析的可行性，并指出仅估计联合概率分布并不能推断因果关系。

    

    提出使用假设的生成模型对观测数据进行因果分析。特定模型的假设是对一组变量和因果关系的承诺，但仅估计联合概率分布并不足以推断因果关系。该模型仅描述单个可观测分布，无法描述干预效应链引起的分布偏差。

    The use of a hypothetical generative model was been suggested for causal analysis of observational data. The very assumption of a particular model is a commitment to a certain set of variables and therefore to a certain set of possible causes. Estimating the joint probability distribution of can be useful for predicting values of variables in view of the observed values of others, but it is not sufficient for inferring causal relationships. The model describes a single observable distribution and cannot a chain of effects of intervention that deviate from the observed distribution.
    
[^65]: 用辅助知识图谱实现在 $d \gg n$ 情况下的表格深度学习

    Enabling tabular deep learning when $d \gg n$ with an auxiliary knowledge graph. (arXiv:2306.04766v1 [cs.LG])

    [http://arxiv.org/abs/2306.04766](http://arxiv.org/abs/2306.04766)

    该论文提出了 PLATO 方法，通过使用描述输入特征的辅助 KG 来规范 MLP，在 $d \gg n$ 的表格数据上实现了强大的性能。

    

    机器学习模型在具有丰富标记样本的数据集上表现出很强的性能，但对于具有非常高维特征但样本数有限（即 $d \gg n$ 的表格数据），机器学习模型很难实现强大的性能。在这里，作者的主要洞见在于输入特征通常具有丰富的辅助领域信息，这些信息可以被组织成异构的知识图谱。作者提出了 PLATO 方法，使用描述输入特征的辅助 KG 来规范一个 MLP，在 $d \gg n$ 的表格数据上实现了强大的性能。

    Machine learning models exhibit strong performance on datasets with abundant labeled samples. However, for tabular datasets with extremely high $d$-dimensional features but limited $n$ samples (i.e. $d \gg n$), machine learning models struggle to achieve strong performance due to the risk of overfitting. Here, our key insight is that there is often abundant, auxiliary domain information describing input features which can be structured as a heterogeneous knowledge graph (KG). We propose PLATO, a method that achieves strong performance on tabular data with $d \gg n$ by using an auxiliary KG describing input features to regularize a multilayer perceptron (MLP). In PLATO, each input feature corresponds to a node in the auxiliary KG. In the MLP's first layer, each input feature also corresponds to a weight vector. PLATO is based on the inductive bias that two input features corresponding to similar nodes in the auxiliary KG should have similar weight vectors in the MLP's first layer. PLATO
    
[^66]: 公开部署研究聊天机器人的人机交互方面：一项用户研究、设计建议和开放挑战

    The HCI Aspects of Public Deployment of Research Chatbots: A User Study, Design Recommendations, and Open Challenges. (arXiv:2306.04765v1 [cs.AI])

    [http://arxiv.org/abs/2306.04765](http://arxiv.org/abs/2306.04765)

    本文研究研究聊天机器人的公开部署，发现代理人的抽象拟人化表现影响用户感知，AI可解释性可能影响反馈率，聊天体验的两种水平应有意设计。此研究提供了设计建议和研究方向。

    

    公开部署研究聊天机器人是一个涉及必要的风险与收益分析的微妙话题。虽然最近频繁讨论是否负责任地部署此类模型，但对于实现更有效目标的交互范式和设计方法却关注较少。我们通过报告对最近研究聊天机器人进行的混合方法用户研究，力图提出、基于并尝试回答涉及此范围的人机交互问题。我们发现，代理人的抽象拟人化表现对用户的感知有显著影响，提供AI可解释性可能会对反馈率产生影响，而聊天体验的两种水平（故事内和故事外）应有意设计。我们提供设计建议和研究社区进一步关注的领域。

    Publicly deploying research chatbots is a nuanced topic involving necessary risk-benefit analyses. While there have recently been frequent discussions on whether it is responsible to deploy such models, there has been far less focus on the interaction paradigms and design approaches that the resulting interfaces should adopt, in order to achieve their goals more effectively. We aim to pose, ground, and attempt to answer HCI questions involved in this scope, by reporting on a mixed-methods user study conducted on a recent research chatbot. We find that abstract anthropomorphic representation for the agent has a significant effect on user's perception, that offering AI explainability may have an impact on feedback rates, and that two (diegetic and extradiegetic) levels of the chat experience should be intentionally designed. We offer design recommendations and areas of further focus for the research community.
    
[^67]: SKG: 一个多功能的基于语义知识图谱的学术论文信息检索与分析框架

    SKG: A Versatile Information Retrieval and Analysis Framework for Academic Papers with Semantic Knowledge Graphs. (arXiv:2306.04758v1 [cs.IR])

    [http://arxiv.org/abs/2306.04758](http://arxiv.org/abs/2306.04758)

    提出了一个基于语义知识图谱的Academic Papers信息检索与分析框架(SKG)，该框架通过整合语义概念表示语料库，支持各种学术文献的语义查询，并开发了数据流系统进行灵活、交互的各种语义查询。

    

    近年来，出版的研究论文数量呈指数增长，因此开发新的高效、多功能的信息提取和知识发现方法十分重要。为解决这个问题，我们提出了一种语义知识图谱（SKG），该图谱整合了来自摘要和其他元信息的语义概念来表示语料库。由于SKG中存储了高度多样化和丰富的信息内容，因此它可以支持各种学术文献的语义查询。为了从非结构化文本中提取知识，我们开发了一个知识提取模块，其中包括半监督管道用于实体提取和实体归一化。我们还创建了一个本体论以将这些概念与其他元信息整合，从而构建了SKG。此外，我们设计并开发了一个数据流系统，演示如何在SKG上灵活、交互地进行各种语义查询。为了证明我们的框架的有效性，我们对大规模的学术出版数据集进行了广泛的实验，并说明了SKG如何协助学术研究任务，包括文献综述、查询回答和推荐。

    The number of published research papers has experienced exponential growth in recent years, which makes it crucial to develop new methods for efficient and versatile information extraction and knowledge discovery. To address this need, we propose a Semantic Knowledge Graph (SKG) that integrates semantic concepts from abstracts and other meta-information to represent the corpus. The SKG can support various semantic queries in academic literature thanks to the high diversity and rich information content stored within. To extract knowledge from unstructured text, we develop a Knowledge Extraction Module that includes a semi-supervised pipeline for entity extraction and entity normalization. We also create an ontology to integrate the concepts with other meta information, enabling us to build the SKG. Furthermore, we design and develop a dataflow system that demonstrates how to conduct various semantic queries flexibly and interactively over the SKG. To demonstrate the effectiveness of our
    
[^68]: INSTRUCTEVAL：面向指导调整的大型语言模型的整体评估

    INSTRUCTEVAL: Towards Holistic Evaluation of Instruction-Tuned Large Language Models. (arXiv:2306.04757v1 [cs.CL])

    [http://arxiv.org/abs/2306.04757](http://arxiv.org/abs/2306.04757)

    INSTRUCTEVAL是一个专注于指导调整的大型语言模型评估的综合套件，它采取了全面的方法来评估模型的性能，包括解决问题、写作能力和与人类价值观的一致性等特征。

    

    指导调整的大型语言模型已经从根本上改变了自然语言处理，已经在诸如对话代理等应用中显示出了巨大的潜力。这些模型，如GPT-4，不仅能够掌握语言，而且可以解决数学、编码、医学和法律等领域的复杂任务。尽管它们具有卓越的能力，但由于许多模型的黑盒性质和缺乏全面的评估研究，对它们的全部潜力仍然缺乏全面的理解。为了解决这些挑战，我们提出了INSTRUCTEVAL，一个更全面的评估套件，专门针对指导调整的大型语言模型。与以往的作品不同，我们的评估包括对模型基于解决问题、写作能力和与人类价值观的一致性的严格评估。我们采取了全面的方法来分析影响模型性能的各种因素，包括预训练基础、指导调整数据和训练。

    Instruction-tuned large language models have revolutionized natural language processing and have shown great potential in applications such as conversational agents. These models, such as GPT-4, can not only master language but also solve complex tasks in areas like mathematics, coding, medicine, and law. Despite their impressive capabilities, there is still a lack of comprehensive understanding regarding their full potential, primarily due to the black-box nature of many models and the absence of holistic evaluation studies. To address these challenges, we present INSTRUCTEVAL, a more comprehensive evaluation suite designed specifically for instruction-tuned large language models. Unlike previous works, our evaluation involves a rigorous assessment of models based on problem-solving, writing ability, and alignment to human values. We take a holistic approach to analyze various factors affecting model performance, including the pretraining foundation, instruction-tuning data, and train
    
[^69]: 医学图像的自动化机器学习系统

    AutoML Systems For Medical Imaging. (arXiv:2306.04750v1 [cs.AI])

    [http://arxiv.org/abs/2306.04750](http://arxiv.org/abs/2306.04750)

    该论文介绍了医学成像中自动化机器学习的应用、策略和技术，该方法通过神经结构搜索和迁移学习技术简化了图像识别模型的创建，结合人类专业知识和计算机系统可以提高医学图像分析的精度和质量。

    

    在医学图像分析中引入机器学习可以大大提高医生提供的医疗保健服务的质量。人类专业知识和计算机系统的结合可以提高诊断精度。自动化机器学习方法通过利用神经结构搜索和迁移学习技术简化了定制化图像识别模型的创建。医学成像技术用于无创地创建内部器官和身体部位图像，以进行诊断和操作目的。本文旨在通过理论和实证证据，突出医学成像中AutoML的潜在应用、策略和技术。

    The integration of machine learning in medical image analysis can greatly enhance the quality of healthcare provided by physicians. The combination of human expertise and computerized systems can result in improved diagnostic accuracy. An automated machine learning approach simplifies the creation of custom image recognition models by utilizing neural architecture search and transfer learning techniques. Medical imaging techniques are used to non-invasively create images of internal organs and body parts for diagnostic and procedural purposes. This article aims to highlight the potential applications, strategies, and techniques of AutoML in medical imaging through theoretical and empirical evidence.
    
[^70]: 野外点云中的三维人体关键点估计无需人工标注

    3D Human Keypoints Estimation From Point Clouds in the Wild Without Human Labels. (arXiv:2306.04745v1 [cs.CV])

    [http://arxiv.org/abs/2306.04745](http://arxiv.org/abs/2306.04745)

    本文提出了一种无需人工标注的方法用于从野外点云中学习3D人体关节定位，利用几何一致性思想构建无监督损失函数，无需昂贵的标注数据，在监督和少样本学习中都有良好的性能表现。

    

    在监督学习下，训练一个从点云中检测三维人体关键点的检测器需要大量高质量的标注数据。尽管捕捉大量的人体点云相对容易，但标注三维关键点是昂贵、主观、容易出错，尤其是在长尾数据（具有罕见姿态的行人、骑轮滑者等）方面更加困难。在本文中，我们提出了一种新的无监督方法GC-KPL (基于几何一致性的关键点学习)，用于从点云中学习3D人体关节定位，无需任何人工标注。我们通过新颖的无监督损失公式，考虑了人体结构和运动状态，达到了合理的性能表现。此外，我们利用Waymo Open Dataset的大型训练集进行无人工标注关键点的训练，证明了该方法在监督学习方法中也有很好的性能表现。最后，我们的主干网络也从无监督训练中受益，并在下游的少样本学习中表现出了好的性能，通过微调可以实现更好的关键点定位。

    Training a 3D human keypoint detector from point clouds in a supervised manner requires large volumes of high quality labels. While it is relatively easy to capture large amounts of human point clouds, annotating 3D keypoints is expensive, subjective, error prone and especially difficult for long-tail cases (pedestrians with rare poses, scooterists, etc.). In this work, we propose GC-KPL - Geometry Consistency inspired Key Point Leaning, an approach for learning 3D human joint locations from point clouds without human labels. We achieve this by our novel unsupervised loss formulations that account for the structure and movement of the human body. We show that by training on a large training set from Waymo Open Dataset without any human annotated keypoints, we are able to achieve reasonable performance as compared to the fully supervised approach. Further, the backbone benefits from the unsupervised training and is useful in downstream fewshot learning of keypoints, where fine-tuning on
    
[^71]: 《MultiEarth 2023：面向地球与环境的多模态学习工作坊和挑战》

    MultiEarth 2023 -- Multimodal Learning for Earth and Environment Workshop and Challenge. (arXiv:2306.04738v1 [cs.CV])

    [http://arxiv.org/abs/2306.04738](http://arxiv.org/abs/2306.04738)

    本研究介绍了《MultiEarth 2023》工作坊和挑战，通过利用遥感数据监测地球生态系统的健康状况。同时也提供一个公共基准来处理多模态遥感信息，并通过挑战集中在监测亚马逊雨林方面。

    

    《面向地球与环境的多模态学习工作坊和挑战(MultiEarth 2023)》是第二届CVPR年度工作坊，旨在通过利用持续收集的大量遥感数据来监测和分析地球生态系统的健康状况。本工作坊的主要目标是将地球与环境科学社区以及多模态表示学习社区汇聚在一起，探索利用技术进步支持环境监测的新方法。MultiEarth工作坊还通过组织公共挑战，为处理多模态遥感信息提供了共同的基准，这些挑战集中在监测亚马逊雨林方面，并包括估计森林砍伐率、检测森林火灾、将合成孔径雷达（SAR）图像转化为可视领域和预测环境趋势等方面。本文介绍了挑战指南、数据集和评估指标。

    The Multimodal Learning for Earth and Environment Workshop (MultiEarth 2023) is the second annual CVPR workshop aimed at the monitoring and analysis of the health of Earth ecosystems by leveraging the vast amount of remote sensing data that is continuously being collected. The primary objective of this workshop is to bring together the Earth and environmental science communities as well as the multimodal representation learning communities to explore new ways of harnessing technological advancements in support of environmental monitoring. The MultiEarth Workshop also seeks to provide a common benchmark for processing multimodal remote sensing information by organizing public challenges focused on monitoring the Amazon rainforest. These challenges include estimating deforestation, detecting forest fires, translating synthetic aperture radar (SAR) images to the visible domain, and projecting environmental trends. This paper presents the challenge guidelines, datasets, and evaluation metr
    
[^72]: 大型语言模型的软提示调整方法用于评估偏差

    Soft-prompt Tuning for Large Language Models to Evaluate Bias. (arXiv:2306.04735v1 [cs.CL])

    [http://arxiv.org/abs/2306.04735](http://arxiv.org/abs/2306.04735)

    本文使用软提示调整来量化大型语言模型中的偏差，避免手动设计提示导致的人为偏差注入。通过分组公平性检查模型对不同敏感属性的偏见，发现了有趣的偏差模式。

    

    近年来，大型语言模型的提示功能因无需标记数据即可产生良好结果而备受青睐。然而，这需要进行提示调整以获得引导更好模型性能的最佳提示。本文中，我们探讨了在情感分类任务中使用软提示调整来量化大型语言模型（LLMs）如Open Pre-trained Transformers（OPT）和Galactica语言模型中的偏差。由于这些模型是在可能偏向某些人群的真实数据上训练的，因此识别这些潜在问题非常重要。使用软提示来评估偏差给我们带来了额外的优势，可以避免手动设计提示导致的人为偏差注入。我们使用分组公平性（偏差）检查模型对不同敏感属性的偏见，并找到了有趣的偏差模式。由于LLMs已在各种应用中被用于工业中，因此我们对其进行的偏见评估具有实际意义。

    Prompting large language models has gained immense popularity in recent years due to the advantage of producing good results even without the need for labelled data. However, this requires prompt tuning to get optimal prompts that lead to better model performances. In this paper, we explore the use of soft-prompt tuning on sentiment classification task to quantify the biases of large language models (LLMs) such as Open Pre-trained Transformers (OPT) and Galactica language model. Since these models are trained on real-world data that could be prone to bias toward certain groups of populations, it is important to identify these underlying issues. Using soft-prompts to evaluate bias gives us the extra advantage of avoiding the human-bias injection that can be caused by manually designed prompts. We check the model biases on different sensitive attributes using the group fairness (bias) and find interesting bias patterns. Since LLMs have been used in the industry in various applications, i
    
[^73]: 鲁棒性AI生成文本检测的内部维度估计

    Intrinsic Dimension Estimation for Robust Detection of AI-Generated Texts. (arXiv:2306.04723v1 [cs.CL])

    [http://arxiv.org/abs/2306.04723](http://arxiv.org/abs/2306.04723)

    本文提出了衡量文本内部维度的方法，应用于鲁棒性AI生成文本的检测，展示了人类文本与AI生成文本在内部维度上的差异。

    

    快速提高的AI生成内容的质量使得很难区分人类和AI生成的文本，这可能会对社会产生不良影响。因此，研究人类文本的不变属性变得越来越重要。本文提出了一种人类文本的不变特征，即给定文本样本嵌入集合下的流形的内部维度。我们展示了自然语言流畅文本的平均内部维度在几个基于字母的语言中约为 $9$，而中文约为 $7$，而每种语言的AI生成文本的平均内部维度较低，差约 $1.5$，并且有明显的统计分离。

    Rapidly increasing quality of AI-generated content makes it difficult to distinguish between human and AI-generated texts, which may lead to undesirable consequences for society. Therefore, it becomes increasingly important to study the properties of human texts that are invariant over text domains and various proficiency of human writers, can be easily calculated for any language, and can robustly separate natural and AI-generated texts regardless of the generation model and sampling method. In this work, we propose such an invariant of human texts, namely the intrinsic dimensionality of the manifold underlying the set of embeddings of a given text sample. We show that the average intrinsic dimensionality of fluent texts in natural language is hovering around the value $9$ for several alphabet-based languages and around $7$ for Chinese, while the average intrinsic dimensionality of AI-generated texts for each language is $\approx 1.5$ lower, with a clear statistical separation between
    
[^74]: 不要相信你的眼睛：关于特征可视化的（不）可靠性。

    Don't trust your eyes: on the (un)reliability of feature visualizations. (arXiv:2306.04719v1 [cs.CV])

    [http://arxiv.org/abs/2306.04719](http://arxiv.org/abs/2306.04719)

    本文探讨了神经网络如何从像素中提取模式的问题，并研究了特征可视化的可靠性。实验证据表明，由于优化过程中固有的限制，特征可视化能够可靠理解的功能集非常有限，对于解释神经网络如何处理自然图像的解释能力产生怀疑。

    

    神经网络是如何从像素中提取模式的？特征可视化通过优化来可视化高激活的模式，试图回答这个重要问题。如今，可视化方法构成了我们对神经网络内部工作的了解的基础，作为一种机械式的可解释性。在这里，我们问：特征可视化有多可靠？我们通过开发网络电路来诈骗特征可视化，使其显示完全与自然输入的正常网络行为毫无联系的任意模式。然后，我们提供证据表明在标准，未操纵网络中发生了类似的现象：特征可视化与标准输入处理非常不同，对神经网络如何处理自然图像的解释能力产生怀疑。我们通过理论证明支撑这一经验发现，由于优化过程中固有的限制，可以通过特征可视化可靠理解的功能集极其有限。

    How do neural networks extract patterns from pixels? Feature visualizations attempt to answer this important question by visualizing highly activating patterns through optimization. Today, visualization methods form the foundation of our knowledge about the internal workings of neural networks, as a type of mechanistic interpretability. Here we ask: How reliable are feature visualizations? We start our investigation by developing network circuits that trick feature visualizations into showing arbitrary patterns that are completely disconnected from normal network behavior on natural input. We then provide evidence for a similar phenomenon occurring in standard, unmanipulated networks: feature visualizations are processed very differently from standard input, casting doubt on their ability to "explain" how neural networks process natural images. We underpin this empirical finding by theory proving that the set of functions that can be reliably understood by feature visualization is extr
    
[^75]: AGIQA-3K：一份用于AI生成图像质量评估的开放数据库

    AGIQA-3K: An Open Database for AI-Generated Image Quality Assessment. (arXiv:2306.04717v1 [cs.CV])

    [http://arxiv.org/abs/2306.04717](http://arxiv.org/abs/2306.04717)

    本论文提出了一个用于AI生成图像质量评估的开放数据库AGIQA-3K，并在其中进行了基准实验，提出了StairReward以提高主观文本到图像对齐评估的性能。

    

    随着文本到图像生成模型的快速发展，人工智能生成的图像（AGIs）已广泛应用于娱乐、教育、社交媒体等领域。然而，考虑到不同AGIs之间的大量质量差异，迫切需要与人类主观评分一致的质量模型。为了解决这个问题，我们广泛考虑了各种流行的AGI模型、不同提示和模型参数生成的AGI，并收集了感知质量和文本到图像对齐方面的主观评分，从而建立了迄今为止最为全面的AGI主观质量数据库AGIQA-3K。此外，我们在这个数据库上进行了基准实验，评估了当前图像质量评估（IQA）模型与人类感知之间的一致性，同时提出了StairReward，大大提高了主观文本到图像对齐评估的性能。我们相信，AGIQA-3K中的细粒度主观评分将有助于推动AI生成图像质量评估技术的发展。

    With the rapid advancements of the text-to-image generative model, AI-generated images (AGIs) have been widely applied to entertainment, education, social media, etc. However, considering the large quality variance among different AGIs, there is an urgent need for quality models that are consistent with human subjective ratings. To address this issue, we extensively consider various popular AGI models, generated AGI through different prompts and model parameters, and collected subjective scores at the perceptual quality and text-to-image alignment, thus building the most comprehensive AGI subjective quality database AGIQA-3K so far. Furthermore, we conduct a benchmark experiment on this database to evaluate the consistency between the current Image Quality Assessment (IQA) model and human perception, while proposing StairReward that significantly improves the assessment performance of subjective text-to-image alignment. We believe that the fine-grained subjective scores in AGIQA-3K wil
    
[^76]: 通过学习有机交互，改进开放式语言模型

    Improving Open Language Models by Learning from Organic Interactions. (arXiv:2306.04707v1 [cs.CL])

    [http://arxiv.org/abs/2306.04707](http://arxiv.org/abs/2306.04707)

    BlenderBot 3x是一个更新版本的会话模型，通过参与者的有机对话和反馈数据进行训练，以改进其技能和安全性，技术上通过学习有益的教师避免学习有毒反馈。

    

    我们提出了BlenderBot 3x，它是会话模型BlenderBot 3的一个更新版本，现在通过参与者的有机对话和反馈数据进行训练，以改进其技能和安全性。我们公开发布了参与者匿名交互数据，供研究社区使用，以促进进一步的进展。使用有机数据训练模型是具有挑战性的，因为与人们在“野外”的互动包括高质量的对话和反馈，以及对抗性和有毒的行为。我们研究了一些技术，使模型能够从有益的教师学习，同时避免从试图将模型诱导为无用或有毒反应的人中学习。BlenderBot 3x在对话中比BlenderBot 3更受欢迎，并在挑战性情况下显示出更安全的响应。虽然我们目前的模型仍远非完美，但我们相信通过继续使用我们提出的技术以及探索从有机交互中学习的新方法，可以进一步改进。

    We present BlenderBot 3x, an update on the conversational model BlenderBot 3, which is now trained using organic conversation and feedback data from participating users of the system in order to improve both its skills and safety. We are publicly releasing the participating de-identified interaction data for use by the research community, in order to spur further progress. Training models with organic data is challenging because interactions with people "in the wild" include both high quality conversations and feedback, as well as adversarial and toxic behavior. We study techniques that enable learning from helpful teachers while avoiding learning from people who are trying to trick the model into unhelpful or toxic responses. BlenderBot 3x is both preferred in conversation to BlenderBot 3, and is shown to produce safer responses in challenging situations. While our current models are still far from perfect, we believe further improvement can be achieved by continued use of the techniq
    
[^77]: 基于混合Actor-Critic强化学习的自适应频率绿灯最佳速度建议

    Adaptive Frequency Green Light Optimal Speed Advisory based on Hybrid Actor-Critic Reinforcement Learning. (arXiv:2306.04660v1 [cs.LG])

    [http://arxiv.org/abs/2306.04660](http://arxiv.org/abs/2306.04660)

    本文提出了一种基于混合Actor-Critic强化学习的自适应频率绿灯最佳速度建议模型，通过使用离散和连续演员网络来优化绿灯最佳速度建议系统的频率和加速度曲线，设计了新的奖励函数来平衡减少停车和最小化速度变化的权衡。实验结果显示，该模型可以有效地减少旅行时间和燃料消耗，并优于现有的最先进的GLOSA系统。

    

    绿灯最佳速度建议（GLOSA）系统建议车辆速度，以帮助它们在绿色时间通过路口，从而通过最小化在路口停车和怠速时间来减少交通拥堵和燃料消耗。但是，以前的研究集中于优化GLOSA算法，忽略了GLOSA系统的速度建议频率。具体而言，一些研究在每个决策步骤提供速度建议，导致冗余建议，而其他人仅为车辆计算最佳速度，无法适应动态交通。在本文中，我们提出了一种基于混合PPO（H-PPO）的自适应频率GLOSA（AF-GLOSA）模型，其采用了一个actor-critic架构和一个混合actor网络。混合演员网络包括一个离散演员，输出咨询频率和一个连续演员，输出加速度曲线。此外，我们设计了一种新的奖励函数来平衡减少停车和最小化速度变化的权衡。实验结果表明，所提出的AF-GLOSA模型可以有效地减少旅行时间和燃料消耗，并优于现有的最先进的GLOSA系统。

    Green Light Optimal Speed Advisory (GLOSA) system suggests speeds to vehicles to assist them in passing through intersections during green intervals, thus reducing traffic congestion and fuel consumption by minimizing the number of stops and idle times at intersections. However, previous research has focused on optimizing the GLOSA algorithm, neglecting the frequency of speed advisory by the GLOSA system. Specifically, some studies provide speed advisory profile at each decision step, resulting in redundant advisory, while others calculate the optimal speed for the vehicle only once, which cannot adapt to dynamic traffic. In this paper, we propose an Adaptive Frequency GLOSA (AF-GLOSA) model based on Hybrid Proximal Policy Optimization (H-PPO), which employs an actor-critic architecture with a hybrid actor network. The hybrid actor network consists of a discrete actor that outputs advisory frequency and a continuous actor that outputs acceleration profiles. Additionally, we design a no
    
[^78]: 动态注入常识知识提升共情对话生成

    Improving Empathetic Dialogue Generation by Dynamically Infusing Commonsense Knowledge. (arXiv:2306.04657v1 [cs.CL])

    [http://arxiv.org/abs/2306.04657](http://arxiv.org/abs/2306.04657)

    本文提出了一种动态注入常识知识的共情式对话生成方法，使用自适应模块选择常识知识以确保生成的对话回应和说话者情况的一致性，其表现优于基准模型。

    

    在共情对话中，个体表达对他人的共情。以往的工作主要依靠说话人的情感生成共情式回应。此外，外部的常识知识也可用于增强系统对语境的理解。然而，常识知识库中包含各种关系，可能导致对话系统的混淆。因此，情感、生成的回应和说话者的情境信息之间存在不一致性。因此，我们提出了一种新的方法，用于共情式回应生成，其中包括一个自适应模块用于常识知识选择，以确保所生成的共情式回应和说话者的情况之间的一致性。选择的知识用于调整生成的响应的常识认知和共情表达。实验结果表明，我们的方法明显优于基准模型。

    In empathetic conversations, individuals express their empathy towards others. Previous work has mainly focused on generating empathetic responses by utilizing the speaker's emotion. Besides, external commonsense knowledge has been applied to enhance the system's understandings of the speaker's situation. However, given an event, commonsense knowledge base contains various relations, potentially leading to confusion for the dialogue system. Consequently, inconsistencies arise among the emotion, generated response and speaker's contextual information. To this end, we propose a novel approach for empathetic response generation, which incorporates an adaptive module for commonsense knowledge selection to ensure consistency between the generated empathetic responses and the speaker's situation. This selected knowledge is used to refine the commonsense cognition and empathy expression for generated responses. Experimental results show that our approach significantly outperforms baseline mod
    
[^79]: 论训练本地自适应的排名预测

    On training locally adaptive CP. (arXiv:2306.04648v1 [cs.LG])

    [http://arxiv.org/abs/2306.04648](http://arxiv.org/abs/2306.04648)

    本文提出了一种新的Conformal Prediction方法，使用可训练的变量变换重新定义符合度量，使得预测区间在保持边际有效的同时具有对象属性相关的大小。通过训练可最大化间隔效率。

    

    本文解决了使符合性预测（CP）间隔本地自适应的问题。大多数现有方法集中于通过划分或重新加权校准集来近似间隔的对象条件有效性。我们的策略是新的且概念上不同。我们不是重新加权校准数据，而是通过可训练的变量变换$A \to \phi_X(A)$重新定义符合度量，该变换明确地取决于对象属性$X$。在某些条件下，如果$\phi_X$对于任何$X$在$A$中是单调的，则变换将生成保证是边际有效且具有$X$相关大小的预测区间。我们描述了如何对$\phi_X$进行参数化和训练以最大化间隔效率。与其他CP-aware训练方法相反，目标函数是平滑的，可以通过标准梯度方法进行最小化而无需进行逼近。

    We address the problem of making Conformal Prediction (CP) intervals locally adaptive. Most existing methods focus on approximating the object-conditional validity of the intervals by partitioning or re-weighting the calibration set. Our strategy is new and conceptually different. Instead of re-weighting the calibration data, we redefine the conformity measure through a trainable change of variables, $A \to \phi_X(A)$, that depends explicitly on the object attributes, $X$. Under certain conditions and if $\phi_X$ is monotonic in $A$ for any $X$, the transformations produce prediction intervals that are guaranteed to be marginally valid and have $X$-dependent sizes. We describe how to parameterize and train $\phi_X$ to maximize the interval efficiency. Contrary to other CP-aware training methods, the objective function is smooth and can be minimized through standard gradient methods without approximations.
    
[^80]: 基于分解类激活图的特征级解释方法：Decom-CAM

    Decom--CAM: Tell Me What You See, In Details! Feature-Level Interpretation via Decomposition Class Activation Map. (arXiv:2306.04644v1 [cs.CV])

    [http://arxiv.org/abs/2306.04644](http://arxiv.org/abs/2306.04644)

    本文提出了一种名为Decom-CAM的两阶段可解释性方法，可用于对深度学习模型的预测结果进行特征级解释。实验结果表明该方法可有效定位重要区域和显著特征，并改善了模型的决策质量。

    

    解释深度学习模型一直是一个非常具有挑战性的问题。虽然类激活图（CAM）被广泛用于通过突出对象位置来解释深度模型的预测结果，但它未能提供有关模型用于做出决策的显著特征的见解。此外，现有的评估协议常常忽略了可解释性表现与模型决策质量之间的关联，这是一个更基本的问题。本文提出了一种新的分解类激活图（Decom-CAM）两阶段可解释性方法，用于对模型的预测结果进行特征级解释。Decom-CAM使用奇异值分解将中间激活图分解为正交特征，并通过集成这些特征生成显著性图。特征的正交性使CAM能够捕捉本地特征，并可以用于定位输入图像中的语义组件，如眼睛、鼻子和面部，使其更易于理解和解释。实验结果表明，我们的方法可以有效地定位重要区域和显著特征，在解释准确性方面优于以前的方法，并提高了模型的决策质量。

    Interpretation of deep learning remains a very challenging problem. Although the Class Activation Map (CAM) is widely used to interpret deep model predictions by highlighting object location, it fails to provide insight into the salient features used by the model to make decisions. Furthermore, existing evaluation protocols often overlook the correlation between interpretability performance and the model's decision quality, which presents a more fundamental issue. This paper proposes a new two-stage interpretability method called the Decomposition Class Activation Map (Decom-CAM), which offers a feature-level interpretation of the model's prediction. Decom-CAM decomposes intermediate activation maps into orthogonal features using singular value decomposition and generates saliency maps by integrating them. The orthogonality of features enables CAM to capture local features and can be used to pinpoint semantic components such as eyes, noses, and faces in the input image, making it more 
    
[^81]: NFT市场中的异常交易检测

    Abnormal Trading Detection in the NFT Market. (arXiv:2306.04643v1 [q-fin.TR])

    [http://arxiv.org/abs/2306.04643](http://arxiv.org/abs/2306.04643)

    本文提出了一种通过聚类算法检测非同质化代币（NFT）交易市场中的异常行为的方法，并探讨了监管对减少欺诈行为的影响。

    

    非同质化代币（NFT）市场近年来呈爆炸性增长。据DappRadar统计，最大的NFT市场OpenSea的总交易额在2023年2月达到了347亿美元。然而，NFT市场大部分是未受监管的，存在着重大的洗钱、欺诈和虚假交易等问题。在本文中，我们试图揭示常见的欺诈行为，如虚拟交易，这可能会误导其他交易者。我们使用市场数据从网络、货币和时间的角度设计量化特征，并将其输入到基于K均值聚类的无监督学习算法中，以对交易者进行分类。最后，我们讨论了聚类结果的重要性以及如何通过监管来减少不良行为。我们的工作可能有助于重新建立交易者的信任。

    The Non-Fungible-Token (NFT) market has experienced explosive growth in recent years. According to DappRadar, the total transaction volume on OpenSea, the largest NFT marketplace, reached 34.7 billion dollars in February 2023. However, the NFT market is mostly unregulated and there are significant concerns about money laundering, fraud and wash trading. Amateur traders and retail investors comprise a significant fraction of the NFT market. Hence it is important that researchers highlight the relevant risks involved in NFT trading. In this paper, we attempt to uncover common fraudulent behaviors such as wash trading that could mislead other traders. Using market data, we design quantitative features from the network, monetary, and temporal perspectives that are fed into K-means clustering unsupervised learning algorithm to sort traders into groups. Lastly, we discuss the clustering results' significance and how regulations can reduce undesired behaviors. Our work can potentially help re
    
[^82]: 多样化和区分化表示学习的通用低资源活动识别

    Generalizable Low-Resource Activity Recognition with Diverse and Discriminative Representation Learning. (arXiv:2306.04641v1 [cs.CV])

    [http://arxiv.org/abs/2306.04641](http://arxiv.org/abs/2306.04641)

    提出了一种新方法DDLearn，通过构建自监督学习任务，在考虑多样化和区分化学习的基础上提高通用低资源人类活动识别的性能。

    

    人类活动识别是一项时间序列分类任务，重点是从人类传感器读数中识别动作模式。然而，获取充足的数据是训练通用人类活动识别模型的关键难点，这有助于在线网络应用程序的定制和优化。本文提出了一种新的方法DDLearn，通过构建自监督学习任务，同时考虑差异性和歧视性学习，从而实现了通用低资源人类活动识别。

    Human activity recognition (HAR) is a time series classification task that focuses on identifying the motion patterns from human sensor readings. Adequate data is essential but a major bottleneck for training a generalizable HAR model, which assists customization and optimization of online web applications. However, it is costly in time and economy to collect large-scale labeled data in reality, i.e., the low-resource challenge. Meanwhile, data collected from different persons have distribution shifts due to different living habits, body shapes, age groups, etc. The low-resource and distribution shift challenges are detrimental to HAR when applying the trained model to new unseen subjects. In this paper, we propose a novel approach called Diverse and Discriminative representation Learning (DDLearn) for generalizable low-resource HAR. DDLearn simultaneously considers diversity and discrimination learning. With the constructed self-supervised learning task, DDLearn enlarges the data dive
    
[^83]: 将几何控制集成到文本到图像扩散模型中以通过文本提示生成高质量的检测数据

    Integrating Geometric Control into Text-to-Image Diffusion Models for High-Quality Detection Data Generation via Text Prompt. (arXiv:2306.04607v1 [cs.CV])

    [http://arxiv.org/abs/2306.04607](http://arxiv.org/abs/2306.04607)

    GeoDiffusion使用文本提示将各种几何条件转化为图像，生成高质量的检测数据，性能优于现有方法。

    

    扩散模型因其在创建内容和生成数据方面的显着能力而受到重视，例如图像分类。然而，使用扩散模型生成高质量的物体检测数据仍然是一个不被充分探索的领域，其中不仅图像水平的感知质量，而且边界框和相机视图等几何条件也是至关重要的。前期研究使用模块编码语义布局来实现复制粘贴合成或布局到图像(L2I)生成。本文提出了GeoDiffusion，一种简单的框架，可以灵活地将各种几何条件转化为文本提示，并使用预训练的文本到图像(T2I)扩散模型生成高质量的检测数据。与以往的L2I方法不同，我们的GeoDiffusion不仅能够编码边界框，还能够编码自驾场景中的额外几何条件，如摄像头视图。广泛的实验结果表明，GeoDiffusion在物体检测准确性方面优于最先进的方法，并针对各种几何条件生成具有更高感知质量的图像。

    Diffusion models have attracted significant attention due to their remarkable ability to create content and generate data for tasks such as image classification. However, the usage of diffusion models to generate high-quality object detection data remains an underexplored area, where not only the image-level perceptual quality but also geometric conditions such as bounding boxes and camera views are essential. Previous studies have utilized either copy-paste synthesis or layout-to-image (L2I) generation with specifically designed modules to encode semantic layouts. In this paper, we propose GeoDiffusion, a simple framework that can flexibly translate various geometric conditions into text prompts and empower the pre-trained text-to-image (T2I) diffusion models for high-quality detection data generation. Unlike previous L2I methods, our GeoDiffusion is able to encode not only bounding boxes but also extra geometric conditions such as camera views in self-driving scenes. Extensive experi
    
[^84]: 在表面之下寻找：利用基本对称性实现高效离线强化学习

    Look Beneath the Surface: Exploiting Fundamental Symmetry for Sample-Efficient Offline RL. (arXiv:2306.04220v1 [cs.LG])

    [http://arxiv.org/abs/2306.04220](http://arxiv.org/abs/2306.04220)

    本文提出了一个新的离线强化学习算法TDM，利用系统动力学的基本对称性实现高效学习小数据集。

    

    离线强化学习通过从预先收集的数据集中学习策略来解决与环境交互的实际问题。然而，现有的离线强化学习算法的性能严重依赖于数据集的规模和状态-动作空间覆盖范围。真实世界数据的收集通常是昂贵和难以控制的，导致数据集小且覆盖范围狭窄，从而对离线强化学习的实际部署提出了重大挑战。在本文中，我们提供了一个新的见解，即利用系统动力学的基本对称性可以在小数据集下显著提高离线强化学习的性能。具体来说，我们提出了一个时间反演对称(T-symmetry)强制的动力学模型(TDM)，建立了一对正向和反向潜在动力学之间的一致性。TDM为小数据集提供了良好的表示，并基于T-symmetry的符合性提供了一种新的OOD样本的可靠性度量。

    Offline reinforcement learning (RL) offers an appealing approach to real-world tasks by learning policies from pre-collected datasets without interacting with the environment. However, the performance of existing offline RL algorithms heavily depends on the scale and state-action space coverage of datasets. Real-world data collection is often expensive and uncontrollable, leading to small and narrowly covered datasets and posing significant challenges for practical deployments of offline RL. In this paper, we provide a new insight that leveraging the fundamental symmetry of system dynamics can substantially enhance offline RL performance under small datasets. Specifically, we propose a Time-reversal symmetry (T-symmetry) enforced Dynamics Model (TDM), which establishes consistency between a pair of forward and reverse latent dynamics. TDM provides both well-behaved representations for small datasets and a new reliability measure for OOD samples based on compliance with the T-symmetry. 
    
[^85]: 一种基于强化学习的方法促进算法代理与LLM之间的高效互动

    Enabling Efficient Interaction between an Algorithm Agent and an LLM: A Reinforcement Learning Approach. (arXiv:2306.03604v1 [cs.AI])

    [http://arxiv.org/abs/2306.03604](http://arxiv.org/abs/2306.03604)

    本论文提出一种强化学习的中介模型，可实现代理与LLM之间高效经济有效的互动，提高效率和成本效益。

    

    大型语言模型(LLMs)包含从海量文本数据集中获取的大量世界知识。最近的研究表明，LLMs可以通过提供高层指令来协助算法代理解决具有复杂顺序决策的任务。然而，与LLMs进行交互可能耗时较长，因为在许多实际情况下，它们需要大量存储空间，只能部署在远程云服务器节点上。此外，使用商业LLMs可能成本很高，因为它们可能根据使用频率收费。本文探讨如何实现代理与LLM之间的高效和经济有效的互动。我们提出了一种基于强化学习的中介模型，以确定何时需要查询LLMs以完成目标任务的高级指令。在涉及规划子目标的4个MiniGrid环境上进行的实验表明，我们的方法可以学习解决目标任务，并提升了效率和成本效益。

    Large language models (LLMs) encode a vast amount of world knowledge acquired from massive text datasets. Recent studies have demonstrated that LLMs can assist an algorithm agent in solving complex sequential decision making tasks in embodied environments by providing high-level instructions. However, interacting with LLMs can be time-consuming, as in many practical scenarios, they require a significant amount of storage space that can only be deployed on remote cloud server nodes. Additionally, using commercial LLMs can be costly since they may charge based on usage frequency. In this paper, we explore how to enable efficient and cost-effective interactions between the agent and an LLM. We propose a reinforcement learning based mediator model that determines when it is necessary to consult LLMs for high-level instructions to accomplish a target task. Experiments on 4 MiniGrid environments that entail planning sub-goals demonstrate that our method can learn to solve target tasks with o
    
[^86]: DreamSparse: 利用 2D 扩散模型从稀疏视角中合成图像

    DreamSparse: Escaping from Plato's Cave with 2D Diffusion Model Given Sparse Views. (arXiv:2306.03414v1 [cs.CV])

    [http://arxiv.org/abs/2306.03414](http://arxiv.org/abs/2306.03414)

    本文提出了 DreamSparse 框架，该框架通过利用先前训练的扩散模型的 2D 先验知识，通过几何模块和空间引导模型来解决 2D 模型缺乏 3D 感知能力的问题，进一步实现了从少视角情况下合成高质量的新视角图像。

    

    从少量视角中合成新的图像是一个具有挑战性但实际的问题。现有方法通常难以产生高质量的结果或在此类少视角设置中需要逐个对象优化，因为提供的信息不足。在这项工作中，我们探索利用预先训练的扩散模型的强大的 2D 先验知识，来合成新颖的视角图像。然而，2D 扩散模型缺乏 3D 感知能力，导致图像合成失真，影响了图像的识别性。为了解决这些问题，我们提出了 DreamSparse，一个可以生成几何和识别联合一致的新视角图像的框架。具体而言，DreamSparse 包括一个几何模块，用于从稀疏视角获取 3D 特征作为 3D 先验，随后引入一个空间引导模型将这些 3D 特征图转换为生成过程的空间信息。这些信息然后用于通过对抗损失指导预训练扩散模型合成高质量的新视角图像。实验结果显示，DreamSparse 在少视角图像合成方面取得了最先进的结果，并且可以生成准确和稳健的物体几何和识别。

    Synthesizing novel view images from a few views is a challenging but practical problem. Existing methods often struggle with producing high-quality results or necessitate per-object optimization in such few-view settings due to the insufficient information provided. In this work, we explore leveraging the strong 2D priors in pre-trained diffusion models for synthesizing novel view images. 2D diffusion models, nevertheless, lack 3D awareness, leading to distorted image synthesis and compromising the identity. To address these problems, we propose DreamSparse, a framework that enables the frozen pre-trained diffusion model to generate geometry and identity-consistent novel view image. Specifically, DreamSparse incorporates a geometry module designed to capture 3D features from sparse views as a 3D prior. Subsequently, a spatial guidance model is introduced to convert these 3D feature maps into spatial information for the generative process. This information is then used to guide the pre-
    
[^87]: 信息传递选择：面向图分类的可解释GNN的研究

    Message-passing selection: Towards interpretable GNNs for graph classification. (arXiv:2306.02081v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.02081](http://arxiv.org/abs/2306.02081)

    本文提出了一种可解释的GNN推理范式MSInterpreter，其中包括消息传递选择方案(MSScheme)，通过计算由结构和节点嵌入组成的消息聚合路径的权重因子，实现对GNN自我解释。在图分类基准测试中表明其有效性。

    

    本文致力于开发一个可解释的GNN推理范式，称为MSInterpreter，它可以作为即插即用的方案轻松应用于各种GNN基线。与大多数现有的解释方法不同，MSInterpreter提供了一种消息传递选择方案(MSScheme)，以选择GNN的关键路径进行消息聚合，旨在实现自我解释而不是事后解释。具体而言，精心设计的MSScheme的目的是通过考虑香草结构和节点嵌入组件来计算消息聚合路径的权重因子，其中结构基旨在权衡节点引起的子结构之间的权重因子；另一方面，节点嵌入基着眼于通过单层GNN获得的节点嵌入来计算权重因子。最后，我们在图分类基准测试中展示了这种方法的有效性。

    In this paper, we strive to develop an interpretable GNNs' inference paradigm, termed MSInterpreter, which can serve as a plug-and-play scheme readily applicable to various GNNs' baselines. Unlike the most existing explanation methods, MSInterpreter provides a Message-passing Selection scheme(MSScheme) to select the critical paths for GNNs' message aggregations, which aims at reaching the self-explaination instead of post-hoc explanations. In detail, the elaborate MSScheme is designed to calculate weight factors of message aggregation paths by considering the vanilla structure and node embedding components, where the structure base aims at weight factors among node-induced substructures; on the other hand, the node embedding base focuses on weight factors via node embeddings obtained by one-layer GNN.Finally, we demonstrate the effectiveness of our approach on graph classification benchmarks.
    
[^88]: X-Ray成像、MRI和核医学的案例研究

    Case Studies on X-Ray Imaging, MRI and Nuclear Imaging. (arXiv:2306.02055v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2306.02055](http://arxiv.org/abs/2306.02055)

    本文介绍了X射线成像、MRI和核医学在医学成像中的应用。通过基于人工智能的方法，尤其是卷积神经网络的应用，可以实现从成像模态中进行系统特征提取和分类，帮助医生进行快速准确的诊断。

    

    医学成像领域是医学科学的一个重要方面，涉及各种形式的辐射来捕获身体内部组织和器官的图像。这些图像为临床诊断提供了重要信息，本文探讨了X射线、MRI和核医学在发现严重疾病方面的应用。然而，手动评估和存储这些图像可能是一个具有挑战性和耗时的过程。为了解决这个问题，基于人工智能（AI）的技术，特别是深度学习（DL），已经越来越流行，用于从成像模态中进行系统特征提取和分类，从而帮助医生进行快速准确的诊断。在本综述研究中，我们将重点探讨基于AI的方法，特别是卷积神经网络（CNN）如何通过医学成像技术帮助疾病检测。CNN是一种常用的图像分析方法，因其能够学习复杂的图像特征并识别传统方法难以检测的模式而获得广泛应用。通过案例研究，我们将展示基于人工智能的医学成像在临床实践中的实际应用。

    The field of medical imaging is an essential aspect of the medical sciences, involving various forms of radiation to capture images of the internal tissues and organs of the body. These images provide vital information for clinical diagnosis, and in this chapter, we will explore the use of X-ray, MRI, and nuclear imaging in detecting severe illnesses. However, manual evaluation and storage of these images can be a challenging and time-consuming process. To address this issue, artificial intelligence (AI)-based techniques, particularly deep learning (DL), have become increasingly popular for systematic feature extraction and classification from imaging modalities, thereby aiding doctors in making rapid and accurate diagnoses. In this review study, we will focus on how AI-based approaches, particularly the use of Convolutional Neural Networks (CNN), can assist in disease detection through medical imaging technology. CNN is a commonly used approach for image analysis due to its ability to
    
[^89]: 基于对抗生成网络的数据增强在医疗领域的应用

    Generative Adversarial Networks for Data Augmentation. (arXiv:2306.02019v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2306.02019](http://arxiv.org/abs/2306.02019)

    本文介绍了基于对抗生成网络的数据增强方法在医疗图像分析中的应用，能够生成大量的合成样本用于增加可用数据集，但需要注意生成数据可能无法完全代表现实世界数据的复杂性和多样性。

    

    通过使用基于对抗生成网络（GAN）进行数据增强是扩展训练AI模型的可用数据集的一种方法。GAN通过使用生成器网络创建新的数据样本，并由鉴别器网络评估其与真实样本的相似性来工作。鉴别器网络被教导去区分真实和合成样本，生成器系统则被训练生成与真实数据相似的数据。这个过程一直重复，直到生成器网络能够生成与真实数据无法区分的合成数据。GAN已经在医学图像分析中用于各种任务，包括数据增强、图像创建和领域适应。它们可以生成用于增加可用数据集的合成样本，尤其是在获取大量真实数据困难或不道德的情况下。但是，使用GAN进行数据增强需要谨慎，因为生成的数据可能无法完全代表现实世界数据的复杂性和多样性。

    One way to expand the available dataset for training AI models in the medical field is through the use of Generative Adversarial Networks (GANs) for data augmentation. GANs work by employing a generator network to create new data samples that are then assessed by a discriminator network to determine their similarity to real samples. The discriminator network is taught to differentiate between actual and synthetic samples, while the generator system is trained to generate data that closely resemble real ones. The process is repeated until the generator network can produce synthetic data that is indistinguishable from genuine data. GANs have been utilized in medical image analysis for various tasks, including data augmentation, image creation, and domain adaptation. They can generate synthetic samples that can be used to increase the available dataset, especially in cases where obtaining large amounts of genuine data is difficult or unethical. However, it is essential to note that the us
    
[^90]: SGEM：通过序列级广义熵最小化实现自动语音识别的测试时自适应

    SGEM: Test-Time Adaptation for Automatic Speech Recognition via Sequential-Level Generalized Entropy Minimization. (arXiv:2306.01981v2 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2306.01981](http://arxiv.org/abs/2306.01981)

    SGEM提出了一种新的测试时自适应框架，利用波束搜索和广义熵最小化调整预训练ASR模型，取得了三个主流ASR模型在不同领域转变时的最新性能。

    

    在许多实际情况下，自动语音识别（ASR）模型经常暴露于数据分布的变化，导致错误的预测。为了解决这个问题，最近提出了一种现有的测试时自适应（TTA）方法，可以在没有源数据的情况下调整预训练的ASR模型以适应未标记的测试实例。尽管有了不错的性能提升，但这项工作仅依赖于简单的贪心解码，并在帧级别上跨越时间步长进行调整，这在模型输出的序列性质下可能不是最优的。出于这个动机，我们提出了一个新的TTA框架，称为SGEM，用于一般ASR模型。为了处理序列输出，SGEM首先利用波束搜索来探索候选输出标志，并选择最可信的标志。然后，它利用广义熵最小化和负抽样作为无监督目标来适应模型。在各种领域的转变下，SGEM实现了三种主流ASR模型的最新性能。

    Automatic speech recognition (ASR) models are frequently exposed to data distribution shifts in many real-world scenarios, leading to erroneous predictions. To tackle this issue, an existing test-time adaptation (TTA) method has recently been proposed to adapt the pre-trained ASR model on unlabeled test instances without source data. Despite decent performance gain, this work relies solely on naive greedy decoding and performs adaptation across timesteps at a frame level, which may not be optimal given the sequential nature of the model output. Motivated by this, we propose a novel TTA framework, dubbed SGEM, for general ASR models. To treat the sequential output, SGEM first exploits beam search to explore candidate output logits and selects the most plausible one. Then, it utilizes generalized entropy minimization and negative sampling as unsupervised objectives to adapt the model. SGEM achieves state-of-the-art performance for three mainstream ASR models under various domain shifts.
    
[^91]: 机器学习流程的负责任设计模式

    Responsible Design Patterns for Machine Learning Pipelines. (arXiv:2306.01788v1 [cs.SE])

    [http://arxiv.org/abs/2306.01788](http://arxiv.org/abs/2306.01788)

    本文提出了一种综合框架，将负责任设计模式纳入机器学习流程中，以确保AI系统的伦理性和公正性。这个框架包括新的负责任AI设计模式，并指导AI开发人员、数据科学家和决策者在AI开发和部署中实施伦理实践。

    

    将道德实践整合到人工智能(AI)开发过程中对于确保AI的安全、公平和负责任操作至关重要。AI伦理涉及将伦理原则应用于AI系统的整个生命周期。这对于减轻与AI相关的潜在风险和伤害（如算法偏见）至关重要。为实现这一目标，机器学习流程中的负责任设计模式（RDPs）对于确保伦理和公平结果至关重要。在本文中，我们提出了一个综合框架，将RDPs纳入ML流程中，以减轻风险并确保AI系统的伦理发展。我们的框架包括新的负责任AI设计模式，这些模式通过对AI伦理和数据管理专家的调查确定，并通过专家反馈的实际情况进行验证。该框架指导AI开发人员、数据科学家和决策者在AI开发和部署中实施伦理实践。

    Integrating ethical practices into the AI development process for artificial intelligence (AI) is essential to ensure safe, fair, and responsible operation. AI ethics involves applying ethical principles to the entire life cycle of AI systems. This is essential to mitigate potential risks and harms associated with AI, such as algorithm biases. To achieve this goal, responsible design patterns (RDPs) are critical for Machine Learning (ML) pipelines to guarantee ethical and fair outcomes. In this paper, we propose a comprehensive framework incorporating RDPs into ML pipelines to mitigate risks and ensure the ethical development of AI systems. Our framework comprises new responsible AI design patterns for ML pipelines identified through a survey of AI ethics and data management experts and validated through real-world scenarios with expert feedback. The framework guides AI developers, data scientists, and policy-makers to implement ethical practices in AI development and deploy responsibl
    
[^92]: 在图形的超出分布泛化中学习标签和环境因果独立性

    Joint Learning of Label and Environment Causal Independence for Graph Out-of-Distribution Generalization. (arXiv:2306.01103v1 [cs.LG])

    [http://arxiv.org/abs/2306.01103](http://arxiv.org/abs/2306.01103)

    本文提出了一种考虑标签和环境因果独立性的方法来解决图形超出分布（OOD）泛化问题，通过敌对训练策略来联合优化属性以获得有效结果，实验证明LECI显着优于之前的方法。

    

    我们解决了图形的超出分布（OOD）泛化问题。现有的图形OOD算法要么依赖于受限的假设，要么无法利用训练数据中的环境信息。在这项工作中，我们提出同时纳入标签和环境因果独立（LECI），充分利用标签和环境信息，从而解决之前的方法在识别因果和不变子图时面临的挑战。我们进一步开发了一种敌对训练策略，以联合优化这两个属性，用于具有理论保证的导致子图发现。广泛的实验和分析表明，LECI在合成和真实数据集上都显着优于之前的方法，将LECI确立为图形OOD泛化的实用有效解决方案。

    We tackle the problem of graph out-of-distribution (OOD) generalization. Existing graph OOD algorithms either rely on restricted assumptions or fail to exploit environment information in training data. In this work, we propose to simultaneously incorporate label and environment causal independence (LECI) to fully make use of label and environment information, thereby addressing the challenges faced by prior methods on identifying causal and invariant subgraphs. We further develop an adversarial training strategy to jointly optimize these two properties for casual subgraph discovery with theoretical guarantees. Extensive experiments and analysis show that LECI significantly outperforms prior methods on both synthetic and real-world datasets, establishing LECI as a practical and effective solution for graph OOD generalization.
    
[^93]: 基于语言条件的模仿学习与基础技能先验下的非结构化数据应用

    Language-Conditioned Imitation Learning with Base Skill Priors under Unstructured Data. (arXiv:2305.19075v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2305.19075](http://arxiv.org/abs/2305.19075)

    本文提出了一种结合基础技能先验和模仿学习的基于语言条件的通用方法，在非结构化数据下，以增强算法在适应不熟悉的环境方面的泛化能力。在零-shot设置下，在模拟和真实环境中测试，提高了CALVIN基准测试的得分。

    

    在语言条件下的机器人操作越来越受到关注，旨在开发能够理解和执行复杂任务的机器人，以实现机器人根据语言指令操作物体的目标。虽然语言条件方法在熟悉的环境中处理任务表现出了令人印象深刻的能力，但在适应不熟悉的环境设置方面遇到了限制。在本文中，我们提出了一个通用的、基于语言条件的方法，结合了基础技能先验和模仿学习在非结构化数据下，以增强算法在适应不熟悉的环境方面的泛化能力。我们在模拟和真实环境中使用零-shot设置来评估我们模型的性能。在模拟环境中，所提出的方法在CALVIN基准测试方面超过了以前报告的得分，特别是在具有挑战性的零-shot多环境设置中。完成任务的平均长度为...

    The growing interest in language-conditioned robot manipulation aims to develop robots capable of understanding and executing complex tasks, with the objective of enabling robots to interpret language commands and manipulate objects accordingly. While language-conditioned approaches demonstrate impressive capabilities for addressing tasks in familiar environments, they encounter limitations in adapting to unfamiliar environment settings. In this study, we propose a general-purpose, language-conditioned approach that combines base skill priors and imitation learning under unstructured data to enhance the algorithm's generalization in adapting to unfamiliar environments. We assess our model's performance in both simulated and real-world environments using a zero-shot setting. In the simulated environment, the proposed approach surpasses previously reported scores for CALVIN benchmark, especially in the challenging Zero-Shot Multi-Environment setting. The average completed task length, in
    
[^94]: Parity校准

    Parity Calibration. (arXiv:2305.18655v1 [cs.LG])

    [http://arxiv.org/abs/2305.18655](http://arxiv.org/abs/2305.18655)

    本文介绍一种新的校准预测目标——parity校准，其考虑时间序列中未来观测值的增加或减少。我们使用在线二进制校准方法实现了parity校准，并在流行病学、天气预报和核聚变控制等领域中表明该方法的有效性。

    

    在序列回归设置中，决策者可能更关注未来观测值是否比当前值增加或减少，而不是未来观测值的实际值。在此背景下，我们引入了平等校准的概念，它捕捉了时间序列增减事件的校准预测目标。平等概率可以从输出的预测分布中提取，但我们显示这种策略导致理论上的不可预测性和差劲的实际性能。然后我们发现，虽然原任务是回归，但平等校准可以被表达为二进制校准。基于这种联系，我们使用在线二进制校准方法实现了平等校准。我们通过流行病学、天气预报和基于模型的核聚变控制的实际案例展示了我们方法的有效性。

    In a sequential regression setting, a decision-maker may be primarily concerned with whether the future observation will increase or decrease compared to the current one, rather than the actual value of the future observation. In this context, we introduce the notion of parity calibration, which captures the goal of calibrated forecasting for the increase-decrease (or "parity") event in a timeseries. Parity probabilities can be extracted from a forecasted distribution for the output, but we show that such a strategy leads to theoretical unpredictability and poor practical performance. We then observe that although the original task was regression, parity calibration can be expressed as binary calibration. Drawing on this connection, we use an online binary calibration method to achieve parity calibration. We demonstrate the effectiveness of our approach on real-world case studies in epidemiology, weather forecasting, and model-based control in nuclear fusion.
    
[^95]: 基准数据集上 ChatGPT 的系统研究和全面评估

    A Systematic Study and Comprehensive Evaluation of ChatGPT on Benchmark Datasets. (arXiv:2305.18486v1 [cs.CL])

    [http://arxiv.org/abs/2305.18486](http://arxiv.org/abs/2305.18486)

    本文对基准数据集上 ChatGPT 的性能进行了全面的评估，包括问答、文本摘要、代码生成、常识推理、数学问题求解、机器翻译、偏见检测和伦理考虑等任务。研究旨在验证 ChatGPT 的优势和弱点，并为使用语言模型的未来研究提供见解。

    

    最近，如 ChatGPT 这样的大型语言模型（LLM）的开发引起了很多关注。然而，由于难以将该模型生成的产出与基本事实进行比较，因此其在基准学术数据集上的评估仍未充分探索。本文旨在对 ChatGPT 在包括问答、文本摘要、代码生成、常识推理、数学问题求解、机器翻译、偏见检测和伦理考虑等任务中的表现进行彻底评估。具体而言，我们在 140 个任务中评估了 ChatGPT，并分析了其在这些数据集中生成的 255K 次响应，这使我们的工作成为了在 NLP 基准测试中对 ChatGPT 进行的最大评估。简而言之，我们的研究旨在验证 ChatGPT 在各种任务中的优势和弱点，并为使用 LLM 的未来研究提供见解。我们还报告了一种新的迸发能力，即遵循多个查询指令。

    The development of large language models (LLMs) such as ChatGPT has brought a lot of attention recently. However, their evaluation in the benchmark academic datasets remains under-explored due to the difficulty of evaluating the generative outputs produced by this model against the ground truth. In this paper, we aim to present a thorough evaluation of ChatGPT's performance on diverse academic datasets, covering tasks like question-answering, text summarization, code generation, commonsense reasoning, mathematical problem-solving, machine translation, bias detection, and ethical considerations. Specifically, we evaluate ChatGPT across 140 tasks and analyze 255K responses it generates in these datasets. This makes our work the largest evaluation of ChatGPT in NLP benchmarks. In short, our study aims to validate the strengths and weaknesses of ChatGPT in various tasks and provide insights for future research using LLMs. We also report a new emergent ability to follow multi-query instruct
    
[^96]: 动力学系统中隐式神经网络的长期预测稳定性

    Stability of implicit neural networks for long-term forecasting in dynamical systems. (arXiv:2305.17155v1 [cs.LG])

    [http://arxiv.org/abs/2305.17155](http://arxiv.org/abs/2305.17155)

    本文提出了一种基于隐式数值方案稳定性特性的神经网络，加入了硬性约束来保证其权重稳定性，取得了较好的长期预测结果。

    

    预测长时间范围内的物理信号是偏微分方程研究中最具挑战性的任务之一。为了规避传统求解器的限制，提出了许多不同的深度学习方法。它们都基于自回归方法并展示出稳定性问题。受隐式数值方案的稳定性特性启发，我们引入了一个稳定的自回归隐式神经网络。我们根据数值方案的稳定性定义，开发了一种理论来保证网络预测的稳定性。它导致我们对其权重添加了硬性约束，并在潜空间中传播动态。我们的实验结果验证了我们的稳定性，展示了在两个输运偏微分方程的长期预测上改进的结果。

    Forecasting physical signals in long time range is among the most challenging tasks in Partial Differential Equations (PDEs) research. To circumvent limitations of traditional solvers, many different Deep Learning methods have been proposed. They are all based on auto-regressive methods and exhibit stability issues. Drawing inspiration from the stability property of implicit numerical schemes, we introduce a stable auto-regressive implicit neural network. We develop a theory based on the stability definition of schemes to ensure the stability in forecasting of this network. It leads us to introduce hard constraints on its weights and propagate the dynamics in the latent space. Our experimental results validate our stability property, and show improved results at long-term forecasting for two transports PDEs.
    
[^97]: 扩散模型的并行采样

    Parallel Sampling of Diffusion Models. (arXiv:2305.16317v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2305.16317](http://arxiv.org/abs/2305.16317)

    本文提出了一种新方法，ParaDiGMS，可以通过并行处理多个步骤来加速预训练扩散模型的采样。ParaDiGMS是第一个使计算速度和采样效率实现平衡的扩散采样方法，并与现有方法兼容。

    

    扩散模型是强大的生成模型，但采样速度缓慢，通常需要进行1000次顺序去噪步骤才能得到一个样本。因此，本文探索了一种交换计算机处理速度和采样效率的方法。通过猜测未来的去噪步骤的解决方案并逐步细化至收敛的Picard迭代，我们展示了惊人的发现：尽管去噪步骤有顺序性，但仍然可以并行采样。基于这一洞见，我们提出了ParaDiGMS，这是一种通过以并行方式去噪多个步骤加速预训练扩散模型采样的新方法。ParaDiGMS是第一个在计算处理速度和采样效率上实现平衡的扩散采样方法，甚至还兼容现有的方法。

    Diffusion models are powerful generative models but suffer from slow sampling, often taking 1000 sequential denoising steps for one sample. As a result, considerable efforts have been directed toward reducing the number of denoising steps, but these methods hurt sample quality. Instead of reducing the number of denoising steps (trading quality for speed), in this paper we explore an orthogonal approach: can we run the denoising steps in parallel (trading compute for speed)? In spite of the sequential nature of the denoising steps, we show that surprisingly it is possible to parallelize sampling via Picard iterations, by guessing the solution of future denoising steps and iteratively refining until convergence. With this insight, we present ParaDiGMS, a novel method to accelerate the sampling of pretrained diffusion models by denoising multiple steps in parallel. ParaDiGMS is the first diffusion sampling method that enables trading compute for speed and is even compatible with existing 
    
[^98]: 大型语言模型是上下文语义推理器而不是符号推理器

    Large Language Models are In-Context Semantic Reasoners rather than Symbolic Reasoners. (arXiv:2305.14825v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.14825](http://arxiv.org/abs/2305.14825)

    本文研究了大型语言模型的内部机制，发现在上下文语境中，语言序列的语义应起到至关重要的作用，与人类符号推理不同，大型语言模型可以在语言序列中建立强连接，并组成一个表面逻辑链。

    

    近年来，大型语言模型(Large Language Models, LLMs)的出现引起了自然语言和机器学习界的极大兴趣，其出色的应用性能备受推崇。然而，LLMs在上下文语境下的推理能力背后的机制仍然不清楚。本文提出我们的假设：在推理过程中，语言序列中学习到的"语义"发挥了至关重要的作用。与人类的符号推理过程不同，LLMs的语义表示可以在语言序列中建立强连接，因此组成一个表面逻辑链。为了测试我们的假设，我们将语义从语言推理过程中分离出来，并评估了三种推理能力：演绎、归纳和拟合。我们的发现表明，在上下文语境中，语义对LLMs的推理能力起着至关重要的作用，当语义与常识一致时，LLMs的表现更佳，但在解决符号或反常识推理问题上会出现困难。

    The emergent few-shot reasoning capabilities of Large Language Models (LLMs) have excited the natural language and machine learning community over recent years. Despite of numerous successful applications, the underlying mechanism of such in-context capabilities still remains unclear. In this work, we hypothesize that the learned \textit{semantics} of language tokens do the most heavy lifting during the reasoning process. Different from human's symbolic reasoning process, the semantic representations of LLMs could create strong connections among tokens, thus composing a superficial logical chain. To test our hypothesis, we decouple semantics from the language reasoning process and evaluate three kinds of reasoning abilities, i.e., deduction, induction and abduction. Our findings reveal that semantics play a vital role in LLMs' in-context reasoning -- LLMs perform significantly better when semantics are consistent with commonsense but struggle to solve symbolic or counter-commonsense re
    
[^99]: 捕捉促销期间的转化率波动：一种新颖的历史数据再利用方法

    Capturing Conversion Rate Fluctuation during Sales Promotions: A Novel Historical Data Reuse Approach. (arXiv:2305.12837v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2305.12837](http://arxiv.org/abs/2305.12837)

    本论文提出了一种名为HDR的新方法，通过重复使用历史促销数据，来捕捉促销转化模式，达到更好地适应促销模式的目的。

    

    转化率（CVR）预测是在线推荐系统的核心组件之一，已经提出了各种方法以获得准确和一致的CVR估计。然而，我们观察到，即使训练良好的CVR预测模型，在促销期间也经常表现出次优的性能。这主要归因于数据分布转移问题，其中传统方法不再起作用。因此，我们寻求开发替代建模技术用于CVR预测。观察到不同促销之间存在相似的购买模式，我们提出了重用历史促销数据以捕捉促销转化模式的方法。因此，我们提出了一种新颖的历史数据再利用（HDR）方法，该方法首先检索历史上相似的促销数据，然后使用获取的数据微调CVR预测模型以更好地适应促销模式。HDR由三个组件组成：自动数据

    Conversion rate (CVR) prediction is one of the core components in online recommender systems, and various approaches have been proposed to obtain accurate and well-calibrated CVR estimation. However, we observe that a well-trained CVR prediction model often performs sub-optimally during sales promotions. This can be largely ascribed to the problem of the data distribution shift, in which the conventional methods no longer work. To this end, we seek to develop alternative modeling techniques for CVR prediction. Observing similar purchase patterns across different promotions, we propose reusing the historical promotion data to capture the promotional conversion patterns. Herein, we propose a novel \textbf{H}istorical \textbf{D}ata \textbf{R}euse (\textbf{HDR}) approach that first retrieves historically similar promotion data and then fine-tunes the CVR prediction model with the acquired data for better adaptation to the promotion mode. HDR consists of three components: an automated data 
    
[^100]: RGCVAE：基于关系图条件化可变自编码器的分子设计

    RGCVAE: Relational Graph Conditioned Variational Autoencoder for Molecule Design. (arXiv:2305.11699v1 [cs.LG])

    [http://arxiv.org/abs/2305.11699](http://arxiv.org/abs/2305.11699)

    本文提出了RGCVAE，一种基于关系图条件化的可变自编码器，可以有效、高效地进行分子设计，并在两个数据集上表现出了先进的生成性能和快速的训练速度。

    

    确定表现出某些预定特性的分子是难以解决的问题。近年来，深度生成模型已被用于分子生成。深度图变分自编码器是最强大的机器学习工具之一，可用于解决此问题。然而，现有方法往往难以捕捉真实的数据分布，并且倾向于计算成本高。在本文中，我们提出了一种高效且有效的基于关系图同构网络的图变分自编码器RGCVAE：（i）利用全新的强大关系图同构网络的编码网络；（ii）一种新颖的概率解码组件。在两个广泛采用的数据集上，与数种最先进的VAE方法相比，RGCVAE表现出最先进的分子生成性能，同时训练速度显著加快。

    Identifying molecules that exhibit some pre-specified properties is a difficult problem to solve. In the last few years, deep generative models have been used for molecule generation. Deep Graph Variational Autoencoders are among the most powerful machine learning tools with which it is possible to address this problem. However, existing methods struggle in capturing the true data distribution and tend to be computationally expensive. In this work, we propose RGCVAE, an efficient and effective Graph Variational Autoencoder based on: (i) an encoding network exploiting a new powerful Relational Graph Isomorphism Network; (ii) a novel probabilistic decoding component. Compared to several state-of-the-art VAE methods on two widely adopted datasets, RGCVAE shows state-of-the-art molecule generation performance while being significantly faster to train.
    
[^101]: 大型语言模型中数值大小比较效应的研究

    Numeric Magnitude Comparison Effects in Large Language Models. (arXiv:2305.10782v1 [cs.AI])

    [http://arxiv.org/abs/2305.10782](http://arxiv.org/abs/2305.10782)

    本研究探究了大型语言模型在数字大小比较上的表现，结果显示，尽管缺乏数字表达，不同架构的语言模型均呈现出惊人的类人表征能力。

    

    大型语言模型(LLMs)并没有区分出文字中的数字，而数字在文本中是普遍存在的。相比之下，神经科学研究对数字和单词有着不同的神经表示。本文旨在从行为角度探究流行的LLMs能够多好地捕捉数字的大小（例如，$4<5$）。以往对LLMs表征能力的研究品评他们是否达到了人类水平，比如在标准测试中整体准确率较高。在这里，我们提出一个与认知科学相关的不同问题：LLMs数字表征与人类语言用户的表现有多接近，他们通常表现出距离、大小和比例效应? 我们依靠一个连接假设将数字单词和数字的模型表示之间的相似性映射到人类反应时间。结果显示，尽管缺乏数字表示，不同架构的语言模型都具有惊人的类人表征能力。

    Large Language Models (LLMs) do not differentially represent numbers, which are pervasive in text. In contrast, neuroscience research has identified distinct neural representations for numbers and words. In this work, we investigate how well popular LLMs capture the magnitudes of numbers (e.g., that $4 < 5$) from a behavioral lens. Prior research on the representational capabilities of LLMs evaluates whether they show human-level performance, for instance, high overall accuracy on standard benchmarks. Here, we ask a different question, one inspired by cognitive science: How closely do the number representations of LLMscorrespond to those of human language users, who typically demonstrate the distance, size, and ratio effects? We depend on a linking hypothesis to map the similarities among the model embeddings of number words and digits to human response times. The results reveal surprisingly human-like representations across language models of different architectures, despite the absen
    
[^102]: 乐观的近端策略优化在线性马尔可夫决策过程中的理论分析

    A Theoretical Analysis of Optimistic Proximal Policy Optimization in Linear Markov Decision Processes. (arXiv:2305.08841v1 [cs.LG])

    [http://arxiv.org/abs/2305.08841](http://arxiv.org/abs/2305.08841)

    本文提出了一种乐观的近端策略优化算法，用于解决带有全信息反馈的周期性对抗性线性MDP，在随机线性MDP和带有全信息的敌对线性MDP中，达到了最先进的后悔边界，并具有新颖的多批次更新机制。

    

    近端策略优化（PPO）算法是强化学习领域中最成功的方法之一。尽管PPO很成功，但是对于PPO及其乐观变种是否能有效解决线性马尔可夫决策过程(MDPs)的理论理解仍不足。为了填补这一空白，我们提出了一种乐观的近端策略优化算法，用于带有全信息反馈的周期敌对线性MDP，并为其建立了一个$\tilde{\mathcal{O}}(d^{3/4}H^2K^{3/4})$的后悔值。其中$d$是线性MDPs的环境维数，$H$是每个周期的长度，$K$是周期数。与现有的基于策略的算法相比，在随机线性MDP和带有全信息的敌对线性MDP中，我们实现了当今最先进的后悔边界。此外，我们的算法设计具有新颖的多批次更新机制。

    The proximal policy optimization (PPO) algorithm stands as one of the most prosperous methods in the field of reinforcement learning (RL). Despite its success, the theoretical understanding of PPO remains deficient. Specifically, it is unclear whether PPO or its optimistic variants can effectively solve linear Markov decision processes (MDPs), which are arguably the simplest models in RL with function approximation. To bridge this gap, we propose an optimistic variant of PPO for episodic adversarial linear MDPs with full-information feedback, and establish a $\tilde{\mathcal{O}}(d^{3/4}H^2K^{3/4})$ regret for it. Here $d$ is the ambient dimension of linear MDPs, $H$ is the length of each episode, and $K$ is the number of episodes. Compared with existing policy-based algorithms, we achieve the state-of-the-art regret bound in both stochastic linear MDPs and adversarial linear MDPs with full information. Additionally, our algorithm design features a novel multi-batched updating mechanism
    
[^103]: 大型语言模型在日语文本分类中对提示模板的敏感性和鲁棒性研究

    Sensitivity and Robustness of Large Language Models to Prompt Template in Japanese Text Classification Tasks. (arXiv:2305.08714v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.08714](http://arxiv.org/abs/2305.08714)

    本研究评估了多个大型语言模型在日语文本分类中对提示模板的敏感性和鲁棒性，并揭示出即使是高性能的GPT-4模型在这一方面也存在问题。

    

    近年来，预训练语言模型和大型语言模型的先进发展主导了提示工程相关研究的显著增长。然而，这一领域存在一个关键问题：这些模型对于提示模板的敏感性和鲁棒性不足，特别是在日语这样的较少研究的语言中。本文通过全面评估几个代表性的大型语言模型（LLMs）和一个广泛使用的预训练模型（PLM）来探讨这个问题。我们使用一组基准数据集对这些模型进行了审查，旨在评估和分析当前多语言模型在这种情况下的性能表现。我们的实验结果揭示了惊人的差异。一个简单的提示模板句子结构的修改导致GPT-4的准确率从49.21下降到了25.44。这一观察结果强调了即使是高性能的GPT-4模型也存在这一问题。

    Prompt engineering relevance research has seen a notable surge in recent years, primarily driven by advancements in pre-trained language models and large language models. However, a critical issue has been identified within this domain: the inadequate of sensitivity and robustness of these models towards Prompt Templates, particularly in lesser-studied languages such as Japanese. This paper explores this issue through a comprehensive evaluation of several representative Large Language Models (LLMs) and a widely-utilized pre-trained model(PLM). These models are scrutinized using a benchmark dataset in Japanese, with the aim to assess and analyze the performance of the current multilingual models in this context. Our experimental results reveal startling discrepancies. A simple modification in the sentence structure of the Prompt Template led to a drastic drop in the accuracy of GPT-4 from 49.21 to 25.44. This observation underscores the fact that even the highly performance GPT-4 model 
    
[^104]: 用自然语言指令控制文本生成

    Controlled Text Generation with Natural Language Instructions. (arXiv:2304.14293v1 [cs.CL])

    [http://arxiv.org/abs/2304.14293](http://arxiv.org/abs/2304.14293)

    InstructCTG是一个可以通过自然语言描述和演示来控制文本生成并满足不同约束条件的框架，它有效地解决了现有搜索或得分方法所存在的问题。

    

    大型语言模型可以产生流畅的文本，并能根据自然语言指令解决各种任务，无需特定的训练。然而，控制它们的生成以满足不同应用程序所需的各种约束条件是非常困难的。本文提供了一个带约束调节的文本生成框架——InstructCTG，该框架通过基于自然语言描述和约束演示来纳入不同的约束条件。我们首先通过一系列现成的NLP工具和简单的启发式方法来提取自然文本的潜在约束条件。此外，我们将这些约束条件转化为自然语言指令，以形成弱监督的训练数据。通过添加自然语言约束描述和少量演示，我们对预训练语言模型进行了微调，以纳入各种类型的约束条件。与现有基于搜索或得分的方法相比，InstructCTG 更加有效。

    Large language models generate fluent texts and can follow natural language instructions to solve a wide range of tasks without task-specific training. Nevertheless, it is notoriously difficult to control their generation to satisfy the various constraints required by different applications. In this work, we present InstructCTG, a controlled text generation framework that incorporates different constraints by conditioning on natural language descriptions and demonstrations of the constraints. In particular, we first extract the underlying constraints of natural texts through a combination of off-the-shelf NLP tools and simple heuristics. We then verbalize the constraints into natural language instructions to form weakly supervised training data. By prepending natural language descriptions of the constraints and a few demonstrations, we fine-tune a pre-trained language model to incorporate various types of constraints. Compared to existing search-based or score-based methods, InstructCT
    
[^105]: 奖励是否合理？在 MACHIAVELLI 基准测试中衡量奖励与道德行为之间的权衡

    Do the Rewards Justify the Means? Measuring Trade-Offs Between Rewards and Ethical Behavior in the MACHIAVELLI Benchmark. (arXiv:2304.03279v1 [cs.LG])

    [http://arxiv.org/abs/2304.03279](http://arxiv.org/abs/2304.03279)

    本文介绍了 MACHIAVELLI 基准测试，用于衡量人工智能代理是否表现出马基雅维利行为，发现了最大化奖励和行为的道德性之间存在权衡，并探索了基于语言模型的方法来减轻这种权衡。

    

    传统上，人工智能代理被训练成最大化奖励，这可能会激励追求权力和欺骗行为，类似于语言模型中的下一个标记预测可能会激励有害行为。那么代理是否自然而然地学会了马基雅维利行为？我们如何在 GPT-4 等通用模型中衡量这些行为呢？为回答这些问题，我们引入了 MACHIAVELLI 基准测试，该测试涵盖了超过一百万个多样化的情景，重点关注社会决策制定，用于衡量人工代理是否表现出马基雅维利行为。我们数学化了数十种有害行为，并使用我们的注释来评估代理倾向于追求权力，造成功能不良和违反伦理的倾向。我们观察到最大化奖励和行为的道德性之间存在一些紧张关系。为了改善这种权衡，我们研究了基于语言模型的方法，以使代理趋向于采取更少的有害行为。我们的结果显示，MACHIAVELLI 是评估人工代理马基雅维利行为水平的有用基准测试。

    Artificial agents have traditionally been trained to maximize reward, which may incentivize power-seeking and deception, analogous to how next-token prediction in language models (LMs) may incentivize toxicity. So do agents naturally learn to be Machiavellian? And how do we measure these behaviors in general-purpose models such as GPT-4? Towards answering these questions, we introduce MACHIAVELLI, a benchmark of 134 Choose-Your-Own-Adventure games containing over half a million rich, diverse scenarios that center on social decision-making. Scenario labeling is automated with LMs, which are more performant than human annotators. We mathematize dozens of harmful behaviors and use our annotations to evaluate agents' tendencies to be power-seeking, cause disutility, and commit ethical violations. We observe some tension between maximizing reward and behaving ethically. To improve this trade-off, we investigate LM-based methods to steer agents' towards less harmful behaviors. Our results sh
    
[^106]: 通识知识辅助的资源受限和细粒度目标检测的深度学习方法

    Commonsense Knowledge Assisted Deep Learning for Resource-constrained and Fine-grained Object Detection. (arXiv:2303.09026v1 [cs.CV])

    [http://arxiv.org/abs/2303.09026](http://arxiv.org/abs/2303.09026)

    本文提出了一种通识知识辅助的细粒度目标检测方法，利用通识知识推理模块处理由基准深度学习检测器给出的粗粒度标签，从而提高目标检测的准确性。经过实验验证，该方法相比于现有方法需要更少的计算量和标注资源。

    

    本文考虑边缘计算等资源受限场景下的细粒度图像目标检测问题。针对使用现代深度学习目标检测器时需要使用大型模型和大量数据标注的精准细粒度检测需求，提出一种方法，即利用通识知识辅助粗粒度目标检测器获取精准的细粒度检测结果。引入通识知识推理模块(CKIM)处理由基准深度学习检测器给出的粗粒度标签，从而生成细粒度标签。论文中考虑了模糊规则和清晰规则的推理，前者用于处理目标语义标签的模糊性。实验结果表明所提方法可以有效提高目标检测的准确性，同时相比于现有方法需要更少的计算量和标注资源。

    In this paper, we consider fine-grained image object detection in resource-constrained cases such as edge computing. Deep learning (DL), namely learning with deep neural networks (DNNs), has become the dominating approach to object detection. To achieve accurate fine-grained detection, one needs to employ a large enough DNN model and a vast amount of data annotations, which brings a challenge for using modern DL object detectors in resource-constrained cases. To this end, we propose an approach, which leverages commonsense knowledge to assist a coarse-grained object detector to get accurate fine-grained detection results. Specifically, we introduce a commonsense knowledge inference module (CKIM) to process coarse-grained lables given by a benchmark DL detector to produce fine-grained lables. We consider both crisp-rule and fuzzy-rule based inference in our CKIM; the latter is used to handle ambiguity in the target semantic labels. We implement our method based on several modern DL dete
    
[^107]: 打开神经网络分类器以计算Shap分数

    Opening Up the Neural Network Classifier for Shap Score Computation. (arXiv:2303.06516v1 [cs.AI])

    [http://arxiv.org/abs/2303.06516](http://arxiv.org/abs/2303.06516)

    本文提出了一种高效计算机器学习模型分类中Shap解释分数的方法，通过将二进制神经网络转换为布尔电路，并使用知识编译技术，将电路视为开放式模型，通过最近的高效算法计算Shap分数，相比于将BNN视为黑盒模型直接计算Shap，性能有了显著的提高。

    This paper proposes an efficient method for computing Shap explanation scores in machine learning model classification by transforming binary neural networks into Boolean circuits and treating the resulting circuit as an open-box model, which leads to a significant improvement in performance compared to computing Shap directly on the BNN treated as a black-box model.

    我们解决了使用机器学习模型进行分类的Shap解释分数的高效计算问题。为此，我们展示了将二进制神经网络（BNN）转换为确定性和可分解的布尔电路，使用知识编译技术。所得到的电路被视为开放式模型，通过最近的高效算法计算Shap分数。详细的实验表明，与将BNN视为黑盒模型直接计算Shap相比，性能有了显著的提高。

    We address the problem of efficiently computing Shap explanation scores for classifications with machine learning models. With this goal, we show the transformation of binary neural networks (BNNs) for classification into deterministic and decomposable Boolean circuits, for which knowledge compilation techniques are used. The resulting circuit is treated as an open-box model, to compute Shap scores by means of a recent efficient algorithm for this class of circuits. Detailed experiments show a considerable gain in performance in comparison with computing Shap directly on the BNN treated as a black-box model.
    
[^108]: 通过离线强化学习学习影响人类行为

    Learning to Influence Human Behavior with Offline Reinforcement Learning. (arXiv:2303.02265v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2303.02265](http://arxiv.org/abs/2303.02265)

    本文提出了一种通过离线强化学习学习影响人类行为的方法，可以提高人类在协作任务中的表现。

    This paper proposes a method of learning to influence human behavior through offline reinforcement learning, which can improve human performance in collaborative tasks.

    在现实世界中，学习代理与人类互动是最复杂的设置之一，因为人类往往由于复杂的偏见而表现出次优的、不可预测的行为。在这种情况下与人类互动的代理最终会影响这些人所采取的行动。我们的目标是使代理能够利用这种影响来提高人类在协作任务中的表现，随着任务的展开。与以前的工作不同，我们不假设与人员进行在线培训（这往往太昂贵和不安全），也不假设有高保真度环境模拟器的访问权限。我们的想法是，通过采用各种先前观察到的人类-人类交互数据并将其标记为任务奖励，离线强化学习（RL）可以学习组合行为的组件，并发现导致更理想的人类行为的行动。首先，我们展示了离线RL可以学习策略来影响和改善人类行为，尽管这些策略可能与人类的期望不同。

    In the real world, some of the most complex settings for learned agents involve interaction with humans, who often exhibit suboptimal, unpredictable behavior due to sophisticated biases. Agents that interact with people in such settings end up influencing the actions that these people take. Our goal in this work is to enable agents to leverage that influence to improve the human's performance in collaborative tasks, as the task unfolds. Unlike prior work, we do not assume online training with people (which tends to be too expensive and unsafe), nor access to a high fidelity simulator of the environment. Our idea is that by taking a variety of previously observed human-human interaction data and labeling it with the task reward, offline reinforcement learning (RL) can learn to combine components of behavior, and uncover actions that lead to more desirable human actions. First, we show that offline RL can learn strategies to influence and improve human behavior, despite those strategies 
    
[^109]: 减少、重复利用、回收：基于能量扩散模型和MCMC的组合生成

    Reduce, Reuse, Recycle: Compositional Generation with Energy-Based Diffusion Models and MCMC. (arXiv:2302.11552v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.11552](http://arxiv.org/abs/2302.11552)

    该论文提出了一种基于能量扩散模型和MCMC的组合生成方法，旨在解决现有技术在组合生成中的失败问题，并提出了新的成功的解决方案。

    

    自从扩散模型问世以来，它在许多领域中已经迅速成为生成模型的主要方法。它们可以被解释为学习一系列时变的对数概率密度函数的梯度。这种解释已经激发了基于分类器和无分类器指导的思想成为后续控制扩散模型的方法。在这项工作中，我们建立在这些想法的基础上，利用扩散模型的分数-based解释，探索了用于涉及组合生成和指导的条件、修改和重复使用扩散模型的替代方法。特别是，我们调查了为什么某些类型的组合使用当前技术失败，并介绍了一些解决方案。我们得出结论，采样者(而不是模型)对此失败负有责任，并提出了新的采样器，受MCMC的启发，使组合生成成功。此外，我们提出了一种基于能量的扩散模型参数化方法，它使得逼近目标分布更加容易。

    Since their introduction, diffusion models have quickly become the prevailing approach to generative modeling in many domains. They can be interpreted as learning the gradients of a time-varying sequence of log-probability density functions. This interpretation has motivated classifier-based and classifier-free guidance as methods for post-hoc control of diffusion models. In this work, we build upon these ideas using the score-based interpretation of diffusion models, and explore alternative ways to condition, modify, and reuse diffusion models for tasks involving compositional generation and guidance. In particular, we investigate why certain types of composition fail using current techniques and present a number of solutions. We conclude that the sampler (not the model) is responsible for this failure and propose new samplers, inspired by MCMC, which enable successful compositional generation. Further, we propose an energy-based parameterization of diffusion models which enables the 
    
[^110]: DynGFN: 借助RNA速度技术进行贝叶斯基因调控网络推断的GFlowNets方法

    DynGFN: Towards Bayesian Inference of Gene Regulatory Networks with GFlowNets. (arXiv:2302.04178v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.04178](http://arxiv.org/abs/2302.04178)

    DynGFN是一种借助RNA速度技术进行基因调控网络推断的方法，能够捕捉网络结构的不确定性，并在准确度上超过现有方法。

    

    细胞生物学的一个重要挑战是推断基因调控网络（GRN），该网络描述了控制基因表达和细胞功能的基因及其产物之间的相互作用。本文借助RNA速度技术开发了一种方法DynGFN，该方法训练生成流网络，使用RNA速度数据执行基因调控网络的贝叶斯推断，并捕捉网络结构的不确定性。

    One of the grand challenges of cell biology is inferring the gene regulatory network (GRN) which describes interactions between genes and their products that control gene expression and cellular function. We can treat this as a causal discovery problem but with two non-standard challenges: (1) regulatory networks are inherently cyclic so we should not model a GRN as a directed acyclic graph (DAG), and (2) observations have significant measurement noise, so for typical sample sizes there will always be a large equivalence class of graphs that are likely given the data, and we want methods that capture this uncertainty. Existing methods either focus on challenge (1), identifying cyclic structure from dynamics, or on challenge (2) learning complex Bayesian posteriors over DAGs, but not both. In this paper we leverage the fact that it is possible to estimate the "velocity" of gene expression with RNA velocity techniques to develop an approach that addresses both challenges. Because we have
    
[^111]: 基于原则主义的负责任数据管理

    Principlism Guided Responsible Data Curation. (arXiv:2302.03629v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.03629](http://arxiv.org/abs/2302.03629)

    研究针对人本计算机视觉数据集的负责任数据管理建议，采用预防性反思的观点，遵循原则主义的伦理框架，解决隐私和偏差问题。

    

    人本计算机视觉数据整理实践经常忽略隐私和偏差问题，导致数据集撤回和不公平的模型。此外，通过非同意网络爬取构建的人本计算机视觉数据集缺乏全面的公平性和鲁棒性评估所必需的元数据。当前的解决方法后期解决问题，缺乏说服力的采用理由或未能提供适当应用的合适背景。我们的研究着重于针对人本计算机视觉数据集的主动领域特定建议，解决隐私和偏差问题。我们采用反思的观点，并借鉴了现有的实践和指南，遵循原则主义的伦理框架。

    Human-centric computer vision (HCCV) data curation practices often neglect privacy and bias concerns, leading to dataset retractions and unfair models. Further, HCCV datasets constructed through nonconsensual web scraping lack the necessary metadata for comprehensive fairness and robustness evaluations. Current remedies address issues post hoc, lack persuasive justification for adoption, or fail to provide proper contextualization for appropriate application. Our research focuses on proactive, domain-specific recommendations for curating HCCV datasets, addressing privacy and bias. We adopt an ante hoc reflective perspective and draw from current practices and guidelines, guided by the ethical framework of principlism.
    
[^112]: 数字营销内容设计的神经洞察

    Neural Insights for Digital Marketing Content Design. (arXiv:2302.01416v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.01416](http://arxiv.org/abs/2302.01416)

    本文提出了一种基于神经网络的数字营销内容设计评分和提取见解系统，该系统可以为营销人员提供基于历史数据的见解和设计建议，以改善其创意过程并显着提高客户参与度。

    

    在数字营销中，尝试新的网站内容是提高客户参与度的关键杠杆之一。但是，创建成功的营销内容是一项手动且耗时的过程，缺乏明确的指导原则。本文旨在通过基于历史数据为营销人员提供基于AI驱动的可行性见解，以改进其创意过程，从而将内容创建和在线实验之间的循环闭合起来。我们提出了一个基于神经网络的系统，该系统对营销内容设计进行评分和提取见解，即多模态神经网络预测营销内容的吸引力，后处理归因方法为营销人员生成有针对性的见解，以改善特定营销位置的内容。我们的见解不仅指出了当前给定内容的优势和劣势，还根据历史数据提供了设计建议。我们表明，我们的评分模型和见解在数量和质量上均表现良好，并且可以显着提高真实网站上的客户参与度。

    In digital marketing, experimenting with new website content is one of the key levers to improve customer engagement. However, creating successful marketing content is a manual and time-consuming process that lacks clear guiding principles. This paper seeks to close the loop between content creation and online experimentation by offering marketers AI-driven actionable insights based on historical data to improve their creative process. We present a neural-network-based system that scores and extracts insights from a marketing content design, namely, a multimodal neural network predicts the attractiveness of marketing contents, and a post-hoc attribution method generates actionable insights for marketers to improve their content in specific marketing locations. Our insights not only point out the advantages and drawbacks of a given current content, but also provide design recommendations based on historical data. We show that our scoring model and insights work well both quantitatively 
    
[^113]: 基于递归优化等价性的马尔可夫决策过程的遗憾边界研究

    Regret Bounds for Markov Decision Processes with Recursive Optimized Certainty Equivalents. (arXiv:2301.12601v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.12601](http://arxiv.org/abs/2301.12601)

    本文提出了基于递归优化等价性的马尔可夫决策过程的风险敏感强化学习公式，设计了一种有效学习算法，并且推导了算法的遗憾上界和极小-最大下界，表明该算法实现的遗憾率对于情歌数和动作数具有最优依赖性。

    

    优化等价性（OCE）是一类风险测量，涵盖了重要的实例，如熵风险，条件风险价值和均值方差模型。在本文中，我们提出了一个新的基于表格马尔可夫决策过程和递归OCE的情节化风险敏感强化学习公式。我们设计了一个基于值迭代和上置信界的有效学习算法。我们推导了所提出算法的遗憾上界，同时建立了一个极小-最大下界。我们的界限表明，所提出的算法实现的遗憾率对于情歌数和动作数具有最优依赖性。

    The optimized certainty equivalent (OCE) is a family of risk measures that cover important examples such as entropic risk, conditional value-at-risk and mean-variance models. In this paper, we propose a new episodic risk-sensitive reinforcement learning formulation based on tabular Markov decision processes with recursive OCEs. We design an efficient learning algorithm for this problem based on value iteration and upper confidence bound. We derive an upper bound on the regret of the proposed algorithm, and also establish a minimax lower bound. Our bounds show that the regret rate achieved by our proposed algorithm has optimal dependence on the number of episodes and the number of actions.
    
[^114]: 基于触觉的物体插入策略的零-shot转移

    Zero-Shot Transfer of Haptics-Based Object Insertion Policies. (arXiv:2301.12587v3 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2301.12587](http://arxiv.org/abs/2301.12587)

    本文训练了一个模拟中的接触利用操作策略，用于接触丰富的家庭任务，零-shot转移到真实机器人，并最小限度地减小了模拟到真实的差距，可以通用于不同尺寸的盘子。

    

    人类在装填洗碗机或摆放书架等接触丰富的任务中自然地利用触觉反馈。目前的机器人系统专注于避免意外触碰，通常依靠策略性放置的环境传感器。最近，已在模拟中训练并在真实机器人上部署了利用接触的操作策略。然而，它们需要某种形式的现实世界适应来弥合模拟到真实的差距，在所有情况下可能都不可行。在本文中，我们在模拟中训练利用接触的操作策略，用于将盘子装入插槽式支架等接触丰富的家庭任务，该策略在没有任何微调的情况下转移到真实机器人。我们研究了实现这种零-shot转移所需的各种要素，例如时间延迟建模，记忆表示和域随机化。我们的策略以最小的模拟到真实差距转移，并显着优于启发式和学习基线。它还推广到不同大小的盘子上。

    Humans naturally exploit haptic feedback during contact-rich tasks like loading a dishwasher or stocking a bookshelf. Current robotic systems focus on avoiding unexpected contact, often relying on strategically placed environment sensors. Recently, contact-exploiting manipulation policies have been trained in simulation and deployed on real robots. However, they require some form of real-world adaptation to bridge the sim-to-real gap, which might not be feasible in all scenarios. In this paper we train a contact-exploiting manipulation policy in simulation for the contact-rich household task of loading plates into a slotted holder, which transfers without any fine-tuning to the real robot. We investigate various factors necessary for this zero-shot transfer, like time delay modeling, memory representation, and domain randomization. Our policy transfers with minimal sim-to-real gap and significantly outperforms heuristic and learnt baselines. It also generalizes to plates of different s
    
[^115]: BTS：基于半监督学习的室内两房间存在检测中的双折叠师生网络

    BTS: Bifold Teacher-Student in Semi-Supervised Learning for Indoor Two-Room Presence Detection Under Time-Varying CSI. (arXiv:2212.10802v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2212.10802](http://arxiv.org/abs/2212.10802)

    本文提出了一种基于半监督学习的双折叠师生网络，该网络通过利用部分标记和未标记的数据集智能地学习空间和时间特征，有效地解决了基于CSI的室内存在检测受到环境变化和有监督学习方法需要耗时标注的问题。

    

    近年来，基于有监督学习和信道状态信息（CSI）的室内人体存在检测引起了广泛的关注。然而，现有的研究依赖于CSI的空间信息，容易受到环境变化的影响，如物体移动、大气因素和机器重启，从而降低了预测精度。此外，基于有监督学习的方法需要进行耗时的标注来重新训练模型。因此，使用半监督学习方案设计一个连续监控的模型生命周期是必要的。在本文中，我们构思了一种双折叠师生（BTS）学习方法来检测存在于系统中的存在。该方法结合了半监督学习，利用部分标记和未标记的数据集。所提出的原始对偶师生网络从标记和未标记的CSI中智能地学习空间和时间特征。此外，增强的惩罚损失函数利用熵和距离测量来区分深层特征，降低噪声的影响。

    In recent years, indoor human presence detection based on supervised learning (SL) and channel state information (CSI) has attracted much attention. However, the existing studies that rely on spatial information of CSI are susceptible to environmental changes, such as object movement, atmospheric factors, and machine rebooting, which degrade prediction accuracy. Moreover, SL-based methods require time-consuming labeling for retraining models. Therefore, it is imperative to design a continuously monitored model life-cycle using a semi-supervised learning (SSL) based scheme. In this paper, we conceive a bifold teacher-student (BTS) learning approach for presence detection systems that combines SSL by utilizing partially labeled and unlabeled datasets. The proposed primal-dual teacher-student network intelligently learns spatial and temporal features from labeled and unlabeled CSI. Additionally, the enhanced penalized loss function leverages entropy and distance measures to distinguish dr
    
[^116]: 语言模型是否具有日常物品的一致性心理模型？

    Do language models have coherent mental models of everyday things?. (arXiv:2212.10029v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10029](http://arxiv.org/abs/2212.10029)

    语言模型缺乏对日常物品的一致性心理模型，会因此出现荒谬的解决方法。虽然最先进的预训练语言模型具有这些实体的知识碎片，但它们无法为所有实体产生一致且正确的心理模型。语言模型训练可以改善这种情况。

    

    当人们想到像“鸡蛋”这样的日常用品时，通常会有一个与之相关联的心理图像。这种常识性知识有助于我们理解这些日常用品的工作原理以及如何与它们交互。然而，如果系统对这样的日常用品没有一致的图像，比如认为鸡蛋黄包围着壳，那么它可能不得不采取荒谬的方法，比如试图把鸡蛋黄刮下壳放入平底锅中煎煮。语言模型是否具有这种日常用品的一致性心理模型？为了调查这个问题，我们提出了一个基准数据集，包括100种日常用品、它们的部件以及这些部件之间的关系。我们观察到，像GPT-3和Macaw这样的最先进的预训练语言模型具有这些实体的知识碎片，但它们无法为所有实体产生一致且正确的心理模型。我们还发现，对这个基准数据集进行语言模型训练可以提高它们在某些方面的性能。

    When people think of everyday things like an "egg," they typically have a mental image associated with it. This commonsense knowledge helps us understand how these everyday things work and how to interact with them. For example, when someone tries to make a fried egg, they know that it has a shell and that it can be cracked open to reveal the egg white and yolk inside. However, if a system does not have a coherent picture of such everyday things, thinking that the egg yolk surrounds the shell, then it might have to resort to ridiculous approaches such as trying to scrape the egg yolk off the shell into the pan. Do language models have a coherent picture of such everyday things? To investigate this, we propose a benchmark dataset consisting of 100 everyday things, their parts, and the relationships between these parts. We observe that state-of-the-art pre-trained language models (LMs) like GPT-3 and Macaw have fragments of knowledge about these entities, but they fail to produce consist
    
[^117]: 一种具有高效优化和量子适用性的费米子神经网络

    A fermion neural network with efficient optimization and quantum applicability. (arXiv:2211.05793v2 [quant-ph] UPDATED)

    [http://arxiv.org/abs/2211.05793](http://arxiv.org/abs/2211.05793)

    本文提出了一种费米子神经网络（FNN），它将输入作为初始层，输出物理特性，建立了一种高效的优化方法，可应用于具有相互作用的硬量子系统，而且能够精确地确定拓扑相和紧凑电荷序，其量子特性带来多种优势。

    

    经典人工神经网络已在机器学习领域取得了广泛成功。本文提出了一种费米子神经网络（FNN），其物理特性（例如局部态密度或条件电导）在输入作为初始层后作为输出。与反向传播类似，我们建立了一种高效优化方法，使FNN在具有挑战性的机器学习基准测试上表现出竞争性能。FNN也直接应用于量子系统，包括具有相互作用的硬系统，并在无预处理或假设的情况下提供原位分析。在机器学习之后，FNN精确地确定拓扑相和紧凑电荷序。它们的量子特性也带来了各种优势：量子相关性使网络连接更加通用，并且可以深入了解消失的梯度问题，量子纠缠则为可解释的机器学习打开了新的途径等。

    Classical artificial neural networks have witnessed widespread successes in machine-learning applications. Here, we propose fermion neural networks (FNNs) whose physical properties, such as local density of states or conditional conductance, serve as outputs, once the inputs are incorporated as an initial layer. Comparable to back-propagation, we establish an efficient optimization, which entitles FNNs to competitive performance on challenging machine-learning benchmarks. FNNs also directly apply to quantum systems, including hard ones with interactions, and offer in-situ analysis without preprocessing or presumption. Following machine learning, FNNs precisely determine topological phases and emergent charge orders. Their quantum nature also brings various advantages: quantum correlation entitles more general network connectivity and insight into the vanishing gradient problem, quantum entanglement opens up novel avenues for interpretable machine learning, etc.
    
[^118]: FARE: 具有实际证书的可证明公平表示学习

    FARE: Provably Fair Representation Learning with Practical Certificates. (arXiv:2210.07213v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.07213](http://arxiv.org/abs/2210.07213)

    FARE是第一个提供实际公平性证书的FRL方法，通过限制编码器的表示空间实现实际保证并保持准确度-公平度权衡。

    

    公平性表示学习（FRL）是一种常用的方法，旨在通过数据预处理来产生公平分类器。最近的监管指令强调需要提供实际证书的FRL方法，即在任何预处理数据训练的下游分类器的不公平性上提供可证明的上限，从而直接在实际情况下提供保证。创建这样的FRL方法是一个重要的挑战，目前尚未解决。在这项工作中，我们解决了这一挑战，并引入了FARE（具有受限编码器的公平性），这是第一个具有实际公平性证书的FRL方法。FARE基于我们的关键洞见，即限制编码器的表示空间可以推导出实际的保证，同时仍然允许适当的准确度-公平度权衡，比如我们基于公平树提出的方法。为了产生实际的证书，我们开发和应用了一种统计过程，计算有限样本的h值。

    Fair representation learning (FRL) is a popular class of methods aiming to produce fair classifiers via data preprocessing. Recent regulatory directives stress the need for FRL methods that provide practical certificates, i.e., provable upper bounds on the unfairness of any downstream classifier trained on preprocessed data, which directly provides assurance in a practical scenario. Creating such FRL methods is an important challenge that remains unsolved. In this work, we address that challenge and introduce FARE (Fairness with Restricted Encoders), the first FRL method with practical fairness certificates. FARE is based on our key insight that restricting the representation space of the encoder enables the derivation of practical guarantees, while still permitting favorable accuracy-fairness tradeoffs for suitable instantiations, such as one we propose based on fair trees. To produce a practical certificate, we develop and apply a statistical procedure that computes a finite sample h
    
[^119]: 建模抽象目标预测下一步动作

    Predicting the Next Action by Modeling the Abstract Goal. (arXiv:2209.05044v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2209.05044](http://arxiv.org/abs/2209.05044)

    这篇论文提出了一种可以模型化抽象目标，以降低行动预测中不确定性的行动预测模型。使用视觉表征来描述动作和目标信息，并设计抽象目标为一个分布。该模型可在Epic-Kitchen数据集上实现最先进性能。

    

    预测人类动作的问题具有固有的不确定性，但是，如果我们有关于动作实现目标的感知，可以降低这种不确定性。本文提出了一种行动预测模型，利用目标信息来减少未来预测中的不确定性。通过视觉表征，我们描述了动作和目标的信息。通过此方法，我们得出了一个称为抽象目标的新概念，其取决于观察到的视觉特征序列，用于行动预测。我们将抽象目标设计为一个分布，其参数是使用变分递归网络估计的。我们对下一个动作进行多次采样，并引入目标一致性度量来确定从抽象目标得出的最佳候选动作。我们的方法在极具挑战性的Epic-Kitchen数据集上取得了令人印象深刻的结果，并实现了最先进的性能。

    The problem of anticipating human actions is an inherently uncertain one. However, we can reduce this uncertainty if we have a sense of the goal that the actor is trying to achieve. Here, we present an action anticipation model that leverages goal information for the purpose of reducing the uncertainty in future predictions. Since we do not possess goal information or the observed actions during inference, we resort to visual representation to encapsulate information about both actions and goals. Through this, we derive a novel concept called abstract goal which is conditioned on observed sequences of visual features for action anticipation. We design the abstract goal as a distribution whose parameters are estimated using a variational recurrent network. We sample multiple candidates for the next action and introduce a goal consistency measure to determine the best candidate that follows from the abstract goal. Our method obtains impressive results on the very challenging Epic-Kitchen
    
[^120]: 利用模拟辅助优化大规模疏散计划中的拥堵依赖延迟问题

    Simulation-Assisted Optimization for Large-Scale Evacuation Planning with Congestion-Dependent Delays. (arXiv:2209.01535v5 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2209.01535](http://arxiv.org/abs/2209.01535)

    本研究提出了一种通过模拟辅助优化的方法，能够在考虑拥堵依赖延迟的情况下，提高大规模疏散计划的性能表现，相比现有方法表现更优。

    

    疏散计划是灾难管理的重要组成部分。然而，将路线和调度两个关键组成部分进行联合优化，以达到最小化平均疏散时间或疏散完成时间等目标，是一个计算难题。为了解决这个问题，我们提出了MIP-LNS，这是一种可扩展的优化方法，利用启发式搜索和数学优化来优化各种目标函数。我们还提出了MIP-LNS-SIM方法，结合基于代理的模拟以估计由于拥堵而引起的延迟，并找到考虑这些延迟的优化计划。我们以得克萨斯州休斯顿市的哈里斯县作为研究区域。我们发现，在给定的时间限制下，MIP-LNS相对于现有方法在三个不同指标方面找到更好的解。然而，当考虑到拥堵依赖的延迟时，MIP-LNS-SIM在多个性能指标上优于MIP-LNS。此外，MIP-LNS-SIM具有明显较低的求解时间。

    Evacuation planning is a crucial part of disaster management. However, joint optimization of its two essential components, routing and scheduling, with objectives such as minimizing average evacuation time or evacuation completion time, is a computationally hard problem. To approach it, we present MIP-LNS, a scalable optimization method that utilizes heuristic search with mathematical optimization and can optimize a variety of objective functions. We also present the method MIP-LNS-SIM, where we combine agent-based simulation with MIP-LNS to estimate delays due to congestion, as well as, find optimized plans considering such delays. We use Harris County in Houston, Texas, as our study area. We show that, within a given time limit, MIP-LNS finds better solutions than existing methods in terms of three different metrics. However, when congestion dependent delay is considered, MIP-LNS-SIM outperforms MIP-LNS in multiple performance metrics. In addition, MIP-LNS-SIM has a significantly low
    
[^121]: 利用Retain-Resample-Release (R3)采样方法减轻物理信息神经网络中的传播失败

    Mitigating Propagation Failures in Physics-informed Neural Networks using Retain-Resample-Release (R3) Sampling. (arXiv:2207.02338v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2207.02338](http://arxiv.org/abs/2207.02338)

    本文提出了一种新的Retain-Resample-Release采样（R3）算法，通过减轻传播失败，使得物理信息神经网络（PINN）能够成功地从边界点传播解决方案到内部点。

    

    尽管物理信息神经网络（PINN）在近似偏微分方程（PDE）方面取得了成功，但在涉及复杂PDE的问题中，PINN有时会无法收敛到正确的解。这反映在近期关于“失败模式”特征的几项研究中，尽管缺乏关于PINN失败模式和采样策略之间连接的深入理解。在本文中，我们提出了一种新的PINN失败模式的视角，即假设训练PINN基于从初始和/或边界条件点到内部点的解“传播”的成功。我们发现，如果存在传播失败，则采用糟糕采样策略的PINN可能会卡在平凡解上，表现为高度不平衡的PDE残差场。为了减轻传播失败，我们提出了一种新的Retain-Resample-Release采样（R3）算法，该算法可以在高PD区域逐步累积重合点。

    Despite the success of physics-informed neural networks (PINNs) in approximating partial differential equations (PDEs), PINNs can sometimes fail to converge to the correct solution in problems involving complicated PDEs. This is reflected in several recent studies on characterizing the "failure modes" of PINNs, although a thorough understanding of the connection between PINN failure modes and sampling strategies is missing. In this paper, we provide a novel perspective of failure modes of PINNs by hypothesizing that training PINNs relies on successful "propagation" of solution from initial and/or boundary condition points to interior points. We show that PINNs with poor sampling strategies can get stuck at trivial solutions if there are propagation failures, characterized by highly imbalanced PDE residual fields. To mitigate propagation failures, we propose a novel Retain-Resample-Release sampling (R3) algorithm that can incrementally accumulate collocation points in regions of high PD
    
[^122]: Ask-AC: 一种循环中的主动顾问演员-评论家框架

    Ask-AC: An Initiative Advisor-in-the-Loop Actor-Critic Framework. (arXiv:2207.01955v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2207.01955](http://arxiv.org/abs/2207.01955)

    本文提出了一种新颖的主动顾问演员-评论家框架，Ask-AC，它替换了传统的被动监督信号机制，实现了定制化和高效的信息交换，其中的两个互补组件允许代理主动寻求顾问干预和识别漏掉的不稳定状态。

    

    尽管交互式强化学习方案取得了很多有希望的结果，但目前的方案仍然依赖于来自顾问专家的被动监督信号，形式包括持续监控或预定义规则，这不可避免地导致了一种麻烦而昂贵的学习过程。在本文中，我们介绍了一种新的主动顾问演员-评论家框架，称为Ask-AC，它用一个双向的学习者主动机制替换了单向的顾问指导机制，从而实现了学习者和顾问之间的定制化和有效的信息交换。Ask-AC 的核心是两个互补的组件，分别是动作请求者和自适应状态选择器，可以方便地纳入各种离散的演员-评论家架构中。前者允许代理主动寻求不确定状态下的顾问干预，后者则可以识别漏掉的不稳定状态。

    Despite the promising results achieved, state-of-the-art interactive reinforcement learning schemes rely on passively receiving supervision signals from advisor experts, in the form of either continuous monitoring or pre-defined rules, which inevitably result in a cumbersome and expensive learning process. In this paper, we introduce a novel initiative advisor-in-the-loop actor-critic framework, termed as Ask-AC, that replaces the unilateral advisor-guidance mechanism with a bidirectional learner-initiative one, and thereby enables a customized and efficacious message exchange between learner and advisor. At the heart of Ask-AC are two complementary components, namely action requester and adaptive state selector, that can be readily incorporated into various discrete actor-critic architectures. The former component allows the agent to initiatively seek advisor intervention in the presence of uncertain states, while the latter identifies the unstable states potentially missed by the for
    
[^123]: 重新思考合作多智能体强化学习中的实现技巧和单调性约束

    Rethinking the Implementation Tricks and Monotonicity Constraint in Cooperative Multi-Agent Reinforcement Learning. (arXiv:2102.03479v19 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2102.03479](http://arxiv.org/abs/2102.03479)

    本文研究了QMIX算法的变体和单调性约束的实现技巧，发现标准化优化对SMAC环境的表现有显著影响；单调性约束能提高SMAC和DEPP的采样效率。

    

    许多复杂的多智能体系统，如机器人集群控制和自主车辆协调，都可以被建模为多智能体强化学习（MARL）任务。QMIX是一种广泛使用的MARL算法，已被用作基准环境，例如星际争霸多智能体挑战赛（SMAC）和升级版的Predator-Prey（DEPP）。最近，QMIX的变体旨在放松QMIX的单调性约束，从而提高SMAC的性能。本文研究了这些变体的代码级优化和单调性约束。(1)我们发现这些变体的改进受到各种代码级优化的显著影响；(2)实验结果表明，带有标准化优化的QMIX在SMAC中的表现优于其他算法；(3)除了这些算法中的常识，单调性约束还可以提高SMAC和DEPP的采样效率。我们还讨论了为什么单调性约束在纯合作MARL中效果良好。

    Many complex multi-agent systems such as robot swarms control and autonomous vehicle coordination can be modeled as Multi-Agent Reinforcement Learning (MARL) tasks. QMIX, a widely popular MARL algorithm, has been used as a baseline for the benchmark environments, e.g., Starcraft Multi-Agent Challenge (SMAC), Difficulty-Enhanced Predator-Prey (DEPP). Recent variants of QMIX target relaxing the monotonicity constraint of QMIX, allowing for performance improvement in SMAC. In this paper, we investigate the code-level optimizations of these variants and the monotonicity constraint. (1) We find that such improvements of the variants are significantly affected by various code-level optimizations. (2) The experiment results show that QMIX with normalized optimizations outperforms other works in SMAC; (3) beyond the common wisdom from these works, the monotonicity constraint can improve sample efficiency in SMAC and DEPP. We also discuss why monotonicity constraints work well in purely coopera
    

