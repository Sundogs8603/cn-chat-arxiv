# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [VisualGPTScore: Visio-Linguistic Reasoning with Multimodal Generative Pre-Training Scores.](http://arxiv.org/abs/2306.01879) | 我们提出了VisualGPTScore方法，能够使用多模态生成分数捕捉文本标题可能性，并在图像条件语言模型上进行计算，具备组合推理能力。 |
| [^2] | [Probabilistic Adaptation of Text-to-Video Models.](http://arxiv.org/abs/2306.01872) | 本论文针对将大型预先训练好的文本到视频模型适应于具有有限领域特定数据的任务，提出了一种基于概率自适应的方法，名为Video Adapter，通过利用大型预先训练的视频扩散模型的分数函数作为概率先验，来指导生成任务特定小型视频模型。实验结果表明，该方法具有优异性能。 |
| [^3] | [No Bidding, No Regret: Pairwise-Feedback Mechanisms for Digital Goods and Data Auctions.](http://arxiv.org/abs/2306.01860) | 本文提出了针对重复拍卖设置的对偶反馈机制，使用成对比较来从竞标者那里获取信息，避免了之前的学习出价问题，该机制被证明为渐近诚实、个体理性、福利和收益最大化的且适用于任何需要定制生产的商品拍卖场景。 |
| [^4] | [Spatially Resolved Gene Expression Prediction from H&E Histology Images via Bi-modal Contrastive Learning.](http://arxiv.org/abs/2306.01859) | 本文提出了BLEEP框架，通过对比学习构建联合嵌入空间，能够从H&E染色组织学图像中生成空间分辨率的基因表达谱地图，具有很高的有效性。 |
| [^5] | [5IDER: Unified Query Rewriting for Steering, Intent Carryover, Disfluencies, Entity Carryover and Repair.](http://arxiv.org/abs/2306.01855) | 本文介绍了一种非自回归的查询重写体系结构，该体系不仅可以处理对话引导、意图携带、语法中断、实体携带和修复这五个任务，还可以处理它们的复杂组合。 |
| [^6] | [Unifying (Machine) Vision via Counterfactual World Modeling.](http://arxiv.org/abs/2306.01828) | Counterfactual World Modeling (CWM)是一个用于构建统一视觉基础模型的框架，通过解决阻碍基础模型在视觉领域应用的问题，使模型能够处理多种任务，无需昂贵的任务特定标记数据集。 |
| [^7] | [Comparative Analysis of Widely use Object-Oriented Languages.](http://arxiv.org/abs/2306.01819) | 本文提出了一个全面的框架来评估广泛使用的面向对象编程语言，以基于它们的技术和环境特征进行比较。 |
| [^8] | [Beta Thalassemia Carriers detection empowered federated Learning.](http://arxiv.org/abs/2306.01818) | 本论文介绍了一种使用联邦学习技术的方法，快速、便宜、无需移动设备地检测Beta地中海贫血携带者。 |
| [^9] | [Heart Diseases Prediction Using Block-chain and Machine Learning.](http://arxiv.org/abs/2306.01817) | 本文研究了使用区块链和机器学习算法预测心脏疾病，并解决了现有架构下数据存储和传输的不安全性问题，有望优化心脏专业人士对于心脏病早期诊断的能力。 |
| [^10] | [Prediction of Citrus Diseases Using Machine Learning And Deep Learning: Classifier, Models SLR.](http://arxiv.org/abs/2306.01816) | 本文讨论了预测柑橘病害的方法，介绍了使用机器学习和深度学习的分类器和模型，并探讨了相关防治策略。 |
| [^11] | [Adversarial Attack Based on Prediction-Correction.](http://arxiv.org/abs/2306.01809) | 本论文介绍了一种基于预测-校正的对抗攻击方法，该方法能够有效对抗深度神经网络中的梯度攻击，并具有较好的可扩展性。 |
| [^12] | [Word Embeddings for Banking Industry.](http://arxiv.org/abs/2306.01807) | 本文研究了面向银行业的词嵌入，发现其比广泛可用的词嵌入更能捕捉银行特定语义和词相关性，因此可作为NL任务的一个良好独立来源或者补充。 |
| [^13] | [Cook-Gen: Robust Generative Modeling of Cooking Actions from Recipes.](http://arxiv.org/abs/2306.01805) | 本文研究了使用生成AI方法来扩展当前的食品计算模型，将烹饪行为纳入考虑，以实现更全面的健康食谱推荐。 |
| [^14] | [Extracting Reward Functions from Diffusion Models.](http://arxiv.org/abs/2306.01804) | 本论文提出了一种从两个Diffusion模型中提取奖励函数的实用学习算法，可以在导航环境中找到正确的奖励函数，并以此控制Diffusion模型学习足够复杂的任务。 |
| [^15] | [The ethical ambiguity of AI data enrichment: Measuring gaps in research ethics norms and practices.](http://arxiv.org/abs/2306.01800) | 本研究探讨了AI研究和数据增强的研究伦理规范存在的差距，建议改进和增强AI研究和数据增强的伦理实践。 |
| [^16] | [Exploring EFL students' prompt engineering in human-AI story writing: an Activity Theory perspective.](http://arxiv.org/abs/2306.01798) | 本研究应用活动理论分析了香港中学生在短篇故事创作中利用生成式人工智能工具的方式和目的，发现其中缺乏目的意识、克服创作障碍以及发展、扩展和改进故事为主要目的。同时，学生活动系统的共同特征也被研究确定。 |
| [^17] | [AI and the creative realm: A short review of current and future applications.](http://arxiv.org/abs/2306.01795) | 本文探讨了AI在创意领域中的应用，包括艺术、语言和算法，同时也考虑了AI与创造力的哲学意义和潜在的伦理问题。 |
| [^18] | [Task Relation-aware Continual User Representation Learning.](http://arxiv.org/abs/2306.01792) | 本文提出了一种新的持续用户表示学习方法TERACON，它能够学习通用的用户表示，而不是为每个任务学习任务特定的用户表示，具有很强的实用性和学习能力。 |
| [^19] | [Responsible Design Patterns for Machine Learning Pipelines.](http://arxiv.org/abs/2306.01788) | 本文提出了一种综合框架，将负责任设计模式纳入机器学习流程中，以确保AI系统的伦理性和公正性。这个框架包括新的负责任AI设计模式，并指导AI开发人员、数据科学家和决策者在AI开发和部署中实施伦理实践。 |
| [^20] | [Evaluating GPT's Programming Capability through CodeWars' Katas.](http://arxiv.org/abs/2306.01784) | 本文在Codewars上对GPT-3.5和GPT-4模型的编程能力进行了评估，发现它们在3 kyu级别以上的问题上遇到困难。作者提出了一个综合考虑问题难度和所需时间的编程问题复杂度度量，并强调AI模型需要验证和创造性思维能力。 |
| [^21] | [Conceptual Design Generation Using Large Language Models.](http://arxiv.org/abs/2306.01779) | 本文利用大型语言模型生成解决方案，并将其与众包解决方案进行比较。专家评估表明，LLM生成的解决方案具有更高的可行性和有用性，众包的解决方案更加具有创意性。 |
| [^22] | [RE-centric Recommendations for the Development of Trustworthy(er) Autonomous Systems.](http://arxiv.org/abs/2306.01774) | 本研究发现目前AI系统开发中缺少要求工程（RE）这一环节且伦理指南术语和原则覆盖的不一致性，为解决该问题我们制定了一个术语表并研究了伦理AI开发框架在执行RE方面的适用性。 |
| [^23] | [ProcessGPT: Transforming Business Process Management with Generative Artificial Intelligence.](http://arxiv.org/abs/2306.01771) | ProcessGPT是一种使用GPT技术的新型技术，可在需要时生成新的业务流程模型，可用于决策辅助，具有潜在的增强数据中心和知识密集型流程的能力。 |
| [^24] | [Towards a Technology-Driven Adaptive Decision Support System for Integrated Pavement and Maintenance strategies (TDADSS-IPM): focus on risk assessment framework for climate change adaptation.](http://arxiv.org/abs/2306.01769) | 本研究提出了一种名为TDADSS-IPM的自适应路面和养护战略决策支持系统，旨在提供完整的风险评估模型，以实现对气候条件下道路情况的实际了解，以便于进行适当的管理和维护。 |
| [^25] | [Optimization for truss design using Bayesian optimization.](http://arxiv.org/abs/2306.01763) | 本文提出了利用贝叶斯优化算法进行桁架设计优化的方法，通过迭代评估候选设计并更新概率模型的方式优化桁架结构，该方法在优化复杂系统方面表现出有效性。 |
| [^26] | [Pre-trained transformer for adversarial purification.](http://arxiv.org/abs/2306.01762) | 本文提出了一个快速防御对抗性攻击的方案RaPiD（Rapid Plug-in Defender），通过预训练的Transformer微调来提纯对抗样本，使其逼近清洁数据分布，实验结果表明，在有限数据情况下，该方法优于最先进的方法。 |
| [^27] | [Distinguishing Human Generated Text From ChatGPT Generated Text Using Machine Learning.](http://arxiv.org/abs/2306.01761) | 本文提出了一种机器学习方法，可以识别出由ChatGPT生成的文本，并以11种算法进行了分类对比分析，在测试中取得了77%的准确度。 |
| [^28] | [Nonparametric Identification and Estimation of Earnings Dynamics using a Hidden Markov Model: Evidence from the PSID.](http://arxiv.org/abs/2306.01760) | 本研究使用隐马尔科夫模型揭示了收入持续性的复杂本质，并证实了收入具有非线性持续性、条件偏斜性和条件峰度等特征，并发现了ARCH效应以及非高斯瞬时性成分所产生的明显分布不对称性影响。 |
| [^29] | [Training Priors Predict Text-To-Image Model Performance.](http://arxiv.org/abs/2306.01755) | 本文测试了文本到图像模型对于训练先验的依赖程度，发现模型能够更好地生成与训练数据中出现频率更高的三元组对齐的图像，但这也会降低其生成以翻转三元组为基础的图像质量。 |
| [^30] | [Transformer-based Vulnerability Detection in Code at EditTime: Zero-shot, Few-shot, or Fine-tuning?.](http://arxiv.org/abs/2306.01754) | 本研究使用深度学习在编辑代码的同时检测漏洞，可以高精度、低延迟地检测超过250种漏洞类型的复杂漏洞代码模式，使软件开发人员能够在引入潜在漏洞到代码库之前修复它们。 |
| [^31] | [Preconditioned Visual Language Inference with Weak Supervision.](http://arxiv.org/abs/2306.01753) | 本文提出了一个名为PVLIR的预处理视觉语言推理和合理化任务，结果揭示了当前最先进的视觉语言模型在此项任务上的缺陷，并提出了改进这些模型的挑战。 |
| [^32] | [A Survey of Explainable AI and Proposal for a Discipline of Explanation Engineering.](http://arxiv.org/abs/2306.01750) | 本文深入探讨了可解释人工智能领域，并提出了一种有前景的学科：“解释工程学”，该学科包括一种系统化方法，用于设计各种可解释人工智能系统。 |
| [^33] | [An Application of Neutrosophic Sets to Decision Making.](http://arxiv.org/abs/2306.01746) | 本文探讨了一种使用中性集进行决策制定的新方法，采用中性三元组代替二进制元素来解决某些或所有元素的模糊/定性特征存在疑虑的情况 |
| [^34] | [Biomarker Discovery with Quantum Neural Networks: A Case-study in CTLA4-Activation Pathways.](http://arxiv.org/abs/2306.01745) | 该论文介绍了一种利用量子神经网络的模型，可以用于发现与CLTA4通路相关的新生物标志物，并且该模型经济实用。 |
| [^35] | [Disproving XAI Myths with Formal Methods -- Initial Results.](http://arxiv.org/abs/2306.01744) | 论文介绍了XAI中最严重的一些误解，并展示了如何使用形式化方法来打破这些谬见和开发更实用的替代方案。 |
| [^36] | [Comparative study on Judgment Text Classification for Transformer Based Models.](http://arxiv.org/abs/2306.01739) | 本研究对6个不同的基于自我注意力的Transformer模型进行了比较研究，并针对4种激活函数进行了调整，以用于判决文本分类。该方法可以帮助在法律诉讼中进行引用和先例参考。 |
| [^37] | [Differentially Private Episodic Reinforcement Learning with Heavy-tailed Rewards.](http://arxiv.org/abs/2306.01121) | 本研究针对重尾奖励的有限步骤表格马尔可夫决策过程问题探讨了差分隐私限制下的两种框架，即价值迭代和策略优化，同时考虑了联合差分隐私和本地差分隐私模型，并为两种情况提供了遗憾上限。 |
| [^38] | [STEVE-1: A Generative Model for Text-to-Behavior in Minecraft.](http://arxiv.org/abs/2306.00937) | STEVE-1 是一种新的生成模型，能够在Minecraft中跟随各种短期开放型文本和视觉指令。STEVE-1利用预先训练的模型和最佳实践，通过自监督的行为克隆和回顾重新标记来微调，避免了昂贵的人工注释。 |
| [^39] | [Uncertainty-Aware Unlikelihood Learning Improves Generative Aspect Sentiment Quad Prediction.](http://arxiv.org/abs/2306.00418) | 本文提出了一种新的方法来控制标记级的生成、提高原始学习和减少错误，其中包括蒙特卡洛dropout、边缘非似然学习和最小化熵。在四个公共数据集上的广泛实验表明，该方法有效地提高了情感四元组预测的性能。 |
| [^40] | [BetaZero: Belief-State Planning for Long-Horizon POMDPs using Learned Approximations.](http://arxiv.org/abs/2306.00249) | 本文提出了一种叫做BetaZero的方法，它是一种使用学习近似算法的置信状态规划算法，可以用于解决长时间跨度的POMDP问题。 |
| [^41] | [The Canadian Cropland Dataset: A New Land Cover Dataset for Multitemporal Deep Learning Classification in Agriculture.](http://arxiv.org/abs/2306.00114) | 该论文提出了一个时间补丁数据集，包含了加拿大农田的多时相遥感影像。该数据集是手动经过确认和筛选的高分辨率地理参考图像，覆盖四个农作物生产年度和五个月份。这个数据集可以用于提高土地覆盖分类的准确性。 |
| [^42] | [AI Imagery and the Overton Window.](http://arxiv.org/abs/2306.00080) | 基于人工智能的文本到图像生成技术的快速增长让手工艺术品和AI生成图像区分日渐困难。然而提高人类生活和工作标准以及利用一群人来充实另一群人之间寻求平衡是关键。该领域面临着被AI基础设施接管的风险，同时存在身份盗窃、数据洗白等问题。 |
| [^43] | [Traffic Prediction using Artificial Intelligence: Review of Recent Advances and Emerging Opportunities.](http://arxiv.org/abs/2305.19591) | 该论文综述了交通预测方法的发展，重点介绍了基于人工智能的交通预测方法在多元交通时间序列模型研究方面的进展和机遇。 |
| [^44] | [Spotlight Attention: Robust Object-Centric Learning With a Spatial Locality Prior.](http://arxiv.org/abs/2305.19550) | 该论文提出了一个新的目标中心学习方法，通过加入空间局部性先验来提高模型的鲁棒性，使模型在合成和真实数据上实现了显著的物体分割改进，并且对模型超参数不太敏感。 |
| [^45] | [Criteria Tell You More than Ratings: Criteria Preference-Aware Light Graph Convolution for Effective Multi-Criteria Recommendation.](http://arxiv.org/abs/2305.18885) | 本文提出了一种面向多准则推荐的标准偏好感知轻量图卷积网络，该方法结合了MC扩展图，可以准确地捕捉用户的标准偏好，并进一步将用户对各个标准的偏好合并到最终的推荐列表中。 |
| [^46] | [A Systematic Study and Comprehensive Evaluation of ChatGPT on Benchmark Datasets.](http://arxiv.org/abs/2305.18486) | 本文对基准数据集上 ChatGPT 的性能进行了全面的评估，包括问答、文本摘要、代码生成、常识推理、数学问题求解、机器翻译、偏见检测和伦理考虑等任务。研究旨在验证 ChatGPT 的优势和弱点，并为使用语言模型的未来研究提供见解。 |
| [^47] | [Beyond the Meta: Leveraging Game Design Parameters for Patch-Agnostic Esport Analytics.](http://arxiv.org/abs/2305.18477) | 本论文提出了一种新的跨版本的电子竞技分析方法，通过利用游戏设计参数并利用聚类技术创建角色表征形式来解决传统方法短寿命的问题。以Dota 2为例验证了这种方法，取得了显著的性能提升。 |
| [^48] | [Continual Task Allocation in Meta-Policy Network via Sparse Prompting.](http://arxiv.org/abs/2305.18444) | 本文提出的CoTASP可以通过学习过完备字典来生成稀疏掩码作为提示，从而从元策略网络中提取与每个任务相关的子网络，实现了快速适应新任务，同时保留了之前任务的共同知识。 |
| [^49] | [In-Context Analogical Reasoning with Pre-Trained Language Models.](http://arxiv.org/abs/2305.17626) | 本研究提出了一种基于语言模型的情境类比推理方法，通过将问题的感知特征编码成语言形式，能够实现高效的零-shot关系推理，超越传统方法和人类水平。 |
| [^50] | [Detecting Edit Failures In Large Language Models: An Improved Specificity Benchmark.](http://arxiv.org/abs/2305.17553) | 该论文探讨了大型语言模型编辑技术的现状，发现现有的特异性基准测试难以检测到不良副作用，并提出了一个改进的基准测试，该测试可以检测到动态组件，并通过基于KL散度的指标扩展了特异性的衡量方式。研究发现最近的模型编辑技术特异性较低，强调了改进特异性基准测试的重要性。 |
| [^51] | [Modeling Dynamic Environments with Scene Graph Memory.](http://arxiv.org/abs/2305.17537) | 本论文提出了一种新的场景图记忆状态表示，结合节点边缘预测器（NEP）的神经网络架构，能够帮助具有行动能力的AI代理在部分可观察动态场景中高效搜索。 |
| [^52] | [Answering Unanswered Questions through Semantic Reformulations in Spoken QA.](http://arxiv.org/abs/2305.17393) | 本研究提出了语义问答重构模型 (SURF)，通过三个基于语言学的操作来重写口语问答中存在的词汇、命题、句法和特异性等问题，提高了回答率，能够帮助语音助手更好地回答未回答的问题。 |
| [^53] | [Convex Risk Bounded Continuous-Time Trajectory Planning and Tube Design in Uncertain Nonconvex Environments.](http://arxiv.org/abs/2305.17291) | 本文提出一种针对含有不确定性障碍物的非凸环境中的轨迹规划问题的解决方案，即通过风险轮廓的概念将风险有界轨迹规划问题转化为确定性优化问题。 |
| [^54] | [On the Copying Problem of Unsupervised NMT: A Training Schedule with a Language Discriminator Loss.](http://arxiv.org/abs/2305.17182) | 无监督NMT中的复制问题通常发生在远距离语种对中且会直接复制输入句子的部分作为翻译，本研究提出了一种包含语言鉴别器损失的训练计划来缓解该问题，并提高低资源语种的翻译性能。 |
| [^55] | [Trust-Aware Resilient Control and Coordination of Connected and Automated Vehicles.](http://arxiv.org/abs/2305.16818) | 本文提出了一种基于信任框架的鲁棒控制和协调方案，从恶意代理的角度识别关键对抗目标，有效避免碰撞和交通堵塞。同时提出了一种使用信任框架的攻击检测和缓解措施。 |
| [^56] | [NLP Reproducibility For All: Understanding Experiences of Beginners.](http://arxiv.org/abs/2305.16579) | 通过对93名NLP初学者的调查，发现研究作者提供完整文档、更好的代码实践和更易于获取的数据文件是初学者成功复现最近NLP论文结果的关键，建议NLP研究人员注重这些方面，更好地支持初学者。 |
| [^57] | [Scan and Snap: Understanding Training Dynamics and Token Composition in 1-layer Transformer.](http://arxiv.org/abs/2305.16380) | 本文分析了1层Transformer在下一个标记预测任务中的SGD训练动态，证明了自我关注层充当了“区分性扫描算法”，从而逐步关注到相关标记并排除不相关的标记，总结相关信息在编码表示中。同时研究了标记频率、上下文和初始化自我关注层等对Transformer性能的影响。 |
| [^58] | [Exploiting Noise as a Resource for Computation and Learning in Spiking Neural Networks.](http://arxiv.org/abs/2305.16044) | 本文提出了噪声脉冲神经元网络（NSNN）和噪声驱动学习规则（NDL），展示了噪声可以作为计算和学习的资源，并为一般脉冲神经元网络提供了一个框架。研究还展示了NSNNs在图像分类和语音识别等实际任务中的适用性，表明它们是未来神经形态计算系统的潜在有力工具。 |
| [^59] | [Exponential Smoothing for Off-Policy Learning.](http://arxiv.org/abs/2305.15877) | 本文研究了离线学习中最小化风险的倒数倾向评分(IPS)的平滑正则化，推导出了可处理、可扩展、可解释的学习证明，并确定了在何种情况下不需要正则化IPS。 |
| [^60] | [Theoretically Principled Federated Learning for Balancing Privacy and Utility.](http://arxiv.org/abs/2305.15148) | 本文提出基于扭曲模型参数的保护机制的通用学习框架，用于实现联合学习中隐私保护和数据效用的平衡。算法可以在每个通信轮中实现个性化的效用-隐私折衷，我们在理论上证明了算法的次线性性质，该算法可以提高隐私保护的联合学习效力。 |
| [^61] | [Graph Meets LLM: A Novel Approach to Collaborative Filtering for Robust Conversational Understanding.](http://arxiv.org/abs/2305.14449) | 一种协同过滤新方法用于稳健对话理解，在历史用户-实体交互的基础上，利用多跳客户亲和力丰富每个用户的索引，并使用有限内存BFGS算法调整每个索引的权重，实验结果显示其明显优于最先进的个性化查询重写方法。 |
| [^62] | [XRoute Environment: A Novel Reinforcement Learning Environment for Routing.](http://arxiv.org/abs/2305.13823) | XRoute环境是一种基于强化学习的新型路由环境，允许代理在端到端路由框架中选择和路由网络，具有挑战性且易于使用，并支持分布式部署和多实例实验。 |
| [^63] | [Unsupervised Visible-Infrared Person ReID by Collaborative Learning with Neighbor-Guided Label Refinement.](http://arxiv.org/abs/2305.12711) | 本论文提出了一个双重最优传输标签分配(DOTLA)框架，以同时将一个模态中生成的标签分配给其对应的模态，实现无监督可见-红外人员再识别。在相应模态中邻居样本的指导下，还提出了一个跨模态邻居一致性引导的标签精炼和正则化模块，进一步提高了算法的精度和鲁棒性。 |
| [^64] | [Efficient Bilateral Cross-Modality Cluster Matching for Unsupervised Visible-Infrared Person ReID.](http://arxiv.org/abs/2305.12673) | 该文提出了一种通过匹配跨模态聚类来减少模态差异的双向聚类匹配学习框架，同时提出了模态特定和模态不可知对比学习框架来共同对齐特征。 |
| [^65] | [Large Language Models can be Guided to Evade AI-Generated Text Detection.](http://arxiv.org/abs/2305.10847) | 本文揭示了大型语言模型可以通过精心设计的提示语来有效规避现有的文本检测系统，证明了这些检测器的脆弱性。 |
| [^66] | [Incremental Causal Graph Learning for Online Unsupervised Root Cause Analysis.](http://arxiv.org/abs/2305.10638) | 本文提出了CORAL，一种用于在线无监督根本原因分析的新框架，可以自动触发该过程并增量更新模型，包括三个主要部分：触发点检测，增量因果图学习和基于网络传播的根本原因定位。 |
| [^67] | [People Talking and AI Listening: How Stigmatizing Language in EHR Notes Affect AI Performance.](http://arxiv.org/abs/2305.10201) | 本文研究了电子病历中污名化语言对基于Transformer的深度学习模型和可解释AI(XAI)技术进行死亡预测的影响。发现临床医生所写的SL会对AI性能表现不利，尤其是在黑人患者中表现更为明显，强调了理解偏见对下游AI性能的影响的重要性，以开发更具公平和正义的医疗系统。 |
| [^68] | [Off-Policy Evaluation for Large Action Spaces via Conjunct Effect Modeling.](http://arxiv.org/abs/2305.08062) | 本研究提出了一个称为OffCEM的估计器，用于对大离散动作空间下上下文匹配策略进行离线策略评估。该估计器通过基于模型的奖励估计来处理残余因果效应，并在新的本地正确性条件下保持无偏性。结果表明，OffCEM在合成和实际大动作空间数据集上优于现有方法。 |
| [^69] | [ACTC: Active Threshold Calibration for Cold-Start Knowledge Graph Completion.](http://arxiv.org/abs/2305.06395) | 本文提出了一种名为ACTC的方法，在冷启动知识图谱补全时进行主动阈值校准，可以有效地利用有限的标记元组来找到每个关系的最佳阈值，同时也结合未标记元组进行了实验。 |
| [^70] | [RLocator: Reinforcement Learning for Bug Localization.](http://arxiv.org/abs/2305.05586) | 本文提出了一种基于强化学习的Bug定位方法RLocator，相较于其他最先进的Bug定位技术具有更优越的性能。 |
| [^71] | [Data Efficient Training with Imbalanced Label Sample Distribution for Fashion Detection.](http://arxiv.org/abs/2305.04379) | 本文提出了一种最先进的加权目标函数，用于提高多标签分类中深度神经网络（DNN）针对长尾数据分布的性能，并通过对时尚服装的图像属性分类的实验，取得了良好的性能。 |
| [^72] | [Few-shot Domain-Adaptive Visually-fused Event Detection from Text.](http://arxiv.org/abs/2305.03517) | 本文提出了一种基于视觉融合和领域自适应的事件检测方法，可以用少量标记数据训练并且适应于新领域。 |
| [^73] | [SI-LSTM: Speaker Hybrid Long-short Term Memory and Cross Modal Attention for Emotion Recognition in Conversation.](http://arxiv.org/abs/2305.03506) | SI-LSTM是一种用于对话情感识别的循环结构，可以追踪不同说话人的情感状态，从而增强对话情感学习。 |
| [^74] | [Neuro-symbolic model for cantilever beams damage detection.](http://arxiv.org/abs/2305.03063) | 本文提出了一种神经符号模型用于悬臂梁损伤检测，该模型通过将卷积网络的处理能力与逻辑查询交互控制相结合，不仅能够准确检测损伤，而且还能够提供解释和定位，使其在操作条件下更可靠和可信。 |
| [^75] | [Clinical Note Generation from Doctor-Patient Conversations using Large Language Models: Insights from MEDIQA-Chat.](http://arxiv.org/abs/2305.02220) | 本文介绍了使用大型语言模型从医生-患者对话中自动生成临床笔记的研究，采用少样本上下文学习法所生成笔记表现优秀，且可与人工编写的笔记媲美。 |
| [^76] | [Finding Neurons in a Haystack: Case Studies with Sparse Probing.](http://arxiv.org/abs/2305.01610) | 本文通过训练$k$-稀疏线性分类器以预测输入特征是否存在，研究了大型语言模型（LLM）内部神经元激活的表示方式；对不同层次的神经元网络的研究表明，早期层利用神经元的稀疏组合来表示多种特征，中间层有特定的神经元表示高级上下文特征，增加规模使特征表示更加稀疏化。 |
| [^77] | [Model-agnostic Measure of Generalization Difficulty.](http://arxiv.org/abs/2305.01034) | 该论文提出了第一个无特定模型的、量化机器学习测试泛化难度的方法——归纳偏差复杂度度量。该方法量化了在任务上良好泛化所需的总信息量与数据提供的信息量之差，通常需要在许多维度上泛化的任务比涉及更少维度但要求更多细节的任务要困难得多。 |
| [^78] | [Impact of Position Bias on Language Models in Token Classification.](http://arxiv.org/abs/2304.13567) | 研究了语言模型在token分类任务中的位置偏差问题，通过实验表明在具体任务中，BERT、ERNIE、ELECTRA等编码器以及GPT2和BLOOM等解码器的平均性能下降了3%和9%。 |
| [^79] | [Safe reinforcement learning with self-improving hard constraints for multi-energy management systems.](http://arxiv.org/abs/2304.08897) | 本论文提出了一种安全强化学习方法，能够实现多能源管理系统中的最优控制，在保证硬约束的前提下减少工程工作，降低建模偏差，并避免潜在的不安全行为。 |
| [^80] | [Context-Dependent Embedding Utterance Representations for Emotion Recognition in Conversations.](http://arxiv.org/abs/2304.08216) | 本论文利用预训练变换器语言模型的上下文依赖性嵌入话语表示，从而在对话情绪识别中取得了非常良好的效果。 |
| [^81] | [To Asymmetry and Beyond: Structured Pruning of Sequence to Sequence Models for Improved Inference Efficiency.](http://arxiv.org/abs/2304.02721) | 本论文研究了模型大小、结构化剪枝、推断效率和摘要准确性之间的关系，发现使用不对称剪枝可在不大损失模型准确性的情况下，提高推断效率约3倍。 |
| [^82] | [AutoRL Hyperparameter Landscapes.](http://arxiv.org/abs/2304.02396) | 本文提出了一种方法，在训练期间多次建立和分析AutoRL超参数的景观，证明代表算法（DQN和SAC）在不同环境下的超参数景观会随时间而变化。 |
| [^83] | [Transformer and Snowball Graph Convolution Learning for Biomedical Graph Classification.](http://arxiv.org/abs/2303.16132) | 本文介绍了一种新型Transformer和Snowball编码网络（TSEN），它将Transformer架构和图雪球连接引入GNNs。TSEN通过雪球编码层将图雪球连接与图Transformer结合起来，增强了捕捉多尺度信息和全局模式以学习整个图特征的能力。 |
| [^84] | [Linking generative semi-supervised learning and generative open-set recognition.](http://arxiv.org/abs/2303.11702) | 本研究旨在探究生成半监督学习和生成开放集识别之间的关系。SSL-GANs和OSR-GANs方法的相似性在于都要求生成器在互补空间中产生样本，并通过正则化来推广开放空间。研究结果表明SSL优化边缘-GAN在结合SSL-OSR任务方面树立新的标准，但在某些OSR任务中OSR优化的ARP-GAN仍然略优于SSL-GAN。 |
| [^85] | [The Science of Detecting LLM-Generated Texts.](http://arxiv.org/abs/2303.07205) | 本文综述了现有大型语言模型生成文本检测技术并提出了关键考虑因素，如开发全面评估指标和开源 LLM 所构成的威胁。 |
| [^86] | [Tactile-Filter: Interactive Tactile Perception for Part Mating.](http://arxiv.org/abs/2303.06034) | 本文提出了一种基于视觉的触觉传感器进行零部件装配任务的交互式感知方法，并设计了一个二维粒子滤波器，用于自动搜索新的触觉观察，以最大化其精度。 |
| [^87] | [Neural Vector Fields: Implicit Representation by Explicit Learning.](http://arxiv.org/abs/2303.04341) | 该论文提出了一种新的三维表示方法——神经向量场，结合显式学习和隐式函数表示，可以操纵网格并打破分辨率和拓扑限制。 |
| [^88] | [LIDA: A Tool for Automatic Generation of Grammar-Agnostic Visualizations and Infographics using Large Language Models.](http://arxiv.org/abs/2303.02927) | LIDA是一种使用大型语言模型和图像生成模型自动生成与语法无关的可视化和信息图表的工具。 |
| [^89] | ["An Adapt-or-Die Type of Situation": Perception, Adoption, and Use of Text-To-Image-Generation AI by Game Industry Professionals.](http://arxiv.org/abs/2302.12601) | TTIG模型是创造性人工智能的最新补充，可以根据文本描述生成图像。研究发现，专业人士对于TTIG应用和认知等方面存在12个主要问题。这项研究为支持TTIG的可持续采用提供了重要见解。 |
| [^90] | [Equivariant Polynomials for Graph Neural Networks.](http://arxiv.org/abs/2302.11556) | 本文提出了一种基于等变多项式的表达能力层次结构，可以更好的指导GNN的模型改进。通过定义一个具体的基底，全面刻画了所有等变图多项式。此外，我们设计和分析了新的GNN架构，在多个基准数据集上超越了现有的最先进的模型。 |
| [^91] | [Reduce, Reuse, Recycle: Compositional Generation with Energy-Based Diffusion Models and MCMC.](http://arxiv.org/abs/2302.11552) | 该论文提出了一种基于能量扩散模型和MCMC的组合生成方法，旨在解决现有技术在组合生成中的失败问题，并提出了新的成功的解决方案。 |
| [^92] | [Efficient Exploration via Epistemic-Risk-Seeking Policy Optimization.](http://arxiv.org/abs/2302.09339) | 本文提出了一种基于认知风险的新型目标函数，将不确定性转化为价值，鼓励智能体探索未知领域。该方法可以在深度强化学中实现高效探索，即使在函数逼近下也具有保证。 |
| [^93] | [Byzantine-Robust Learning on Heterogeneous Data via Gradient Splitting.](http://arxiv.org/abs/2302.06079) | 这篇论文提出了一种缓解目前健壮算法在非IID环境下表现下降的方法，名为GAS，该方法能够成功将现有的健壮算法用于非IID的数据，并且在真实数据集上有效。 |
| [^94] | [Multispectral Contrastive Learning with Viewmaker Networks.](http://arxiv.org/abs/2302.05757) | 本文研究将对比学习方法应用于各种遥感数据集。通过使用Viewmaker网络，本文发现该方法可以在不耗费大量时间和领域知识的情况下成功产生视图，并在四个多光谱成像问题上实现优于基于裁剪和反射的对比学习方法的表现。 |
| [^95] | [Controllability-Aware Unsupervised Skill Discovery.](http://arxiv.org/abs/2302.05103) | 本文提出了一种新的可控性感知的无监督技能发现方法，通过联合训练的距离函数降低简单易实现技能的奖励，逐步学习更具挑战性的技能。 |
| [^96] | [Cooperative Open-ended Learning Framework for Zero-shot Coordination.](http://arxiv.org/abs/2302.04831) | 该论文提出了一个COLE框架，通过构建合作游戏的开放式目标，从图论的角度评估和确定每个策略的协作能力，以有效地解决零样本协调中的合作不兼容性问题。 |
| [^97] | [Predictable MDP Abstraction for Unsupervised Model-Based RL.](http://arxiv.org/abs/2302.03921) | 该论文提出了可预测的MDP抽象方法，通过无监督学习将原始MDP转换为学习行动空间，使模型学习变得更加准确和稳定，在多项任务上得到了验证。 |
| [^98] | [ANTM: An Aligned Neural Topic Model for Exploring Evolving Topics.](http://arxiv.org/abs/2302.01501) | ANTM是一种对齐的神经主题模型，它利用重叠滑动窗口算法来维护演变主题的时间连续性，并通过对语义相似的文档进行对齐来捕捉出现和消退的趋势。实验证明ANTM在主题连贯性和多样性方面优于传统动态主题模型。 |
| [^99] | [Anti-unification and Generalization: A Survey.](http://arxiv.org/abs/2302.00277) | 反升级或概括是归纳推理中使用的基本操作，是定理证明的双重操作之一。该调查报告对反升级的研究和应用进行了系统归纳和总结。 |
| [^100] | [Adaptive Computation with Elastic Input Sequence.](http://arxiv.org/abs/2301.13195) | 本文介绍了一种名为AdaTape的新方法，通过自适应磁带符号，允许神经网络进行动态计算，能够实现适应不同类型信息的自适应计算，在图像分类、语言建模和程序综合等多个任务中都表现出更好的性能。 |
| [^101] | [Alignment with human representations supports robust few-shot learning.](http://arxiv.org/abs/2301.11990) | 论文提出少样本学习的表现与人类表征的一致性存在U形关系，并通过计算机视觉模型的实验进行了验证。高度对齐的模型更加鲁棒，对数据的利用更加有效，但与人类对齐并非必要条件。 |
| [^102] | [Automatic Intrinsic Reward Shaping for Exploration in Deep Reinforcement Learning.](http://arxiv.org/abs/2301.10886) | 本文提出了一种名为AIRS的自动内在奖励塑造探索方法，可以提供高质量的内在激励以增强强化学习中的探索性能；并开发了高效可靠的内在奖励工具包。实验表明，AIRS性能卓越，能够胜过基准方案。 |
| [^103] | [ExaRanker: Explanation-Augmented Neural Ranker.](http://arxiv.org/abs/2301.10521) | 本文提出了一个名为ExaRanker的解释增强型神经排序模型，使用大型语言模型增强检索数据集，可在输出相关度标签与解释时提高性能。 |
| [^104] | [Pre-computed memory or on-the-fly encoding? A hybrid approach to retrieval augmentation makes the most of your compute.](http://arxiv.org/abs/2301.10448) | 本文提出了一种检索增强的混合方法，LUMEN，它预先计算大部分检索表示，并使用一个实时编码器进行完成编码，相较于纯内存和FiD，LUMEN在多个问答任务中具有更好的性能，且成本更低。 |
| [^105] | [A vision-based autonomous UAV inspection framework for unknown tunnel construction sites with dynamic obstacles.](http://arxiv.org/abs/2301.08422) | 本文提出了一种基于视觉的无人机视检测框架，用于动态隧道环境而无需使用先前的地图，通过分层规划方案将检测问题分解成不同层次，实现了最大化的自主水平。 |
| [^106] | [Evolve Path Tracer: Early Detection of Malicious Addresses in Cryptocurrency.](http://arxiv.org/abs/2301.05412) | 本文提出了演化路径追踪器，通过提出资产转移路径和相应的路径图表征早期交易模式，并使用演化路径编码器 LSTM 和演化路径图 GCN 在演化结构设置下编码资产转移路径和路径图，以及分层生存预测器进一步预测目标地址是否会成为恶意地址，成功实现了加密货币中恶意地址的早期检测。 |
| [^107] | [Towards Disentangling Relevance and Bias in Unbiased Learning to Rank.](http://arxiv.org/abs/2212.13937) | 该论文描述了在无偏学习排序中解离关联性和偏差性的重要性，并提出了对解决这个问题的三种方法。 |
| [^108] | [Z-ICL: Zero-Shot In-Context Learning with Pseudo-Demonstrations.](http://arxiv.org/abs/2212.09865) | 本文提出了一种新的零样本上下文学习方法Z-ICL，通过构建基于原始文本的伪演示，显著提升了模型的零样本性能水平，同时支持未来优化伪演示提高上下文学习表现而无需标记数据。 |
| [^109] | [NusaCrowd: Open Source Initiative for Indonesian NLP Resources.](http://arxiv.org/abs/2212.09648) | NusaCrowd是一个印尼自然语言处理资源的开源倡议，已汇集137个数据集和118个数据加载程序，为印尼语和印度尼西亚本地语言的自然语言处理研究提供了多种实验手段。 |
| [^110] | [APOLLO: A Simple Approach for Adaptive Pretraining of Language Models for Logical Reasoning.](http://arxiv.org/abs/2212.09282) | 本文提出了APOLLO，一种适应性预训练语言模型，通过选择特定的Wikipedia子集进行预训练，并使用两个自监督损失函数，成功地提高了模型的逻辑推理能力。 |
| [^111] | [Graph Learning and Its Applications: A Holistic Survey.](http://arxiv.org/abs/2212.08966) | 本文全面综述了图学习的发展历程和应用场景，重点介绍了表示学习在文本、图像、化学和生物等领域中的显著性能，同时指出了对以前有价值的工作进行调查的需求。 |
| [^112] | [FiDO: Fusion-in-Decoder optimized for stronger performance and faster inference.](http://arxiv.org/abs/2212.08153) | 这项研究提出了一种名为FiDO的解码器融合模型，通过两个简单的更改，有效缓解了内存带宽约束，加快了模型的推理速度，大大提高了模型性能，达到了领先水平。 |
| [^113] | [Refining Generative Process with Discriminator Guidance in Score-based Diffusion Models.](http://arxiv.org/abs/2211.17091) | 本文提出了“鉴别器引导”方法，通过在评分训练之后训练鉴别器，使模型评估更加准确，从而改善预训练扩散模型的样本生成。在 ImageNet 256x256 数据集上实现了 FID 1.83 和召回率 0.64 的最新结果，类似于验证数据的 FID 和召回率。 |
| [^114] | [Arbitrarily Large Labelled Random Satisfiability Formulas for Machine Learning Training.](http://arxiv.org/abs/2211.15368) | 本论文展示了一种基于概率方法的生成任意尺寸的正确标记的随机公式的方法，这一方法可以用于解决目前困难且常用于深度学习模型的组合问题。 |
| [^115] | [Diffusion Denoising Process for Perceptron Bias in Out-of-distribution Detection.](http://arxiv.org/abs/2211.11255) | 本文针对深度学习中的异常检测问题，提出了一种新的方法——使用扩散模型作为非对称插值的方法来增强输入并减轻过度自信的问题，从而提高判别器模型在异常检测方面的性能。 |
| [^116] | [Causal Counterfactuals for Improving the Robustness of Reinforcement Learning.](http://arxiv.org/abs/2211.05551) | 本文提出了CausalCF，它是第一个完整的因果RL解决方案，能够通过因果反事实推断提高RL系统的鲁棒性，并已在机器人抓取和操纵任务中得到应用。 |
| [^117] | [Leveraging Statistical Shape Priors in GAN-based ECG Synthesis.](http://arxiv.org/abs/2211.02626) | 本文提出了一种基于统计形状先验知识和GAN的ECG信号生成方法，能够解决ECG信号的复杂动力学问题。使用来自MIT-BIH心律失常数据库的数据进行实验验证，生成的信号比现有最先进的基于GAN的生成基线更为逼真，对于提高ECG训练数据集质量具有重要意义，可提高ECG分类算法的性能。 |
| [^118] | [Construction of Hierarchical Neural Architecture Search Spaces based on Context-free Grammars.](http://arxiv.org/abs/2211.01842) | 本研究基于无上下文文法提出了一个统一的搜索空间设计框架，可以生成表达力强大的分层搜索空间，实现了对整个体系结构的搜索并促进结构的规律性。 |
| [^119] | [Fair and Optimal Classification via Post-Processing.](http://arxiv.org/abs/2211.01528) | 本文提出了一个后处理算法，通过评分函数推导公平分类器，达到公平对待不同群体的目的。 |
| [^120] | [Investigating Massive Multilingual Pre-Trained Machine Translation Models for Clinical Domain via Transfer Learning.](http://arxiv.org/abs/2210.06068) | 本研究探讨了大规模多语言预训练语言模型（MMPLM）是否可以通过转移学习在临床领域机器翻译中成功应用于完全未知的语言对。实验结果表明，fine-tune过的MMPLM在临床领域机器翻译任务中表现良好。 |
| [^121] | [Optimality Guarantees for Particle Belief Approximation of POMDPs.](http://arxiv.org/abs/2210.05015) | 该论文提出了一般理论来限定POMDP与其相应的有限样本粒子信念MDP(PB-MDP)逼近之间的误差，并将任何采样MDP算法适应到POMDP中，从而提高了解决具有大的或连续状态空间的POMDP的性能和鲁棒性。 |
| [^122] | [UCEpic: Unifying Aspect Planning and Lexical Constraints for Generating Explanations in Recommendation.](http://arxiv.org/abs/2209.13885) | UCEpic通过将方面规划和词汇约束统一考虑，提出了一种插入式生成的个性化解释型推荐模型，显著提高了解释的流畅性、连贯性和匹配能力。 |
| [^123] | [Mitigating Off-Policy Bias in Actor-Critic Methods with One-Step Q-learning: A Novel Correction Approach.](http://arxiv.org/abs/2208.00755) | 本文提出一种新的策略相似度量来缓解离策略学习中的偏差问题，提供了一种自适应的、可扩展的解决方案。 |
| [^124] | [Meta Optimal Transport.](http://arxiv.org/abs/2206.05262) | 本文提出了一种新的方法，利用过去问题的知识和信息来迅速预测和解决新问题，重复地解决不同度量之间的类似OT问题，从而改善最优输运问题的计算时间。 |
| [^125] | [Action Noise in Off-Policy Deep Reinforcement Learning: Impact on Exploration and Performance.](http://arxiv.org/abs/2206.03787) | 本文研究了动作噪声类型、噪声比例和减少规模因子对深度强化学习离线学习中策略性能和探索效果的影响，提出了一种更具鲁棒性的状态空间覆盖度量。 |
| [^126] | [Hierarchies of Reward Machines.](http://arxiv.org/abs/2205.15752) | 本文提出了一种奖励状态机（RM）的层次化结构（HRM），利用它可以将任务进一步抽象为多个子任务，每个子任务都可以独立解决；使用 HRM 可以帮助加快收敛速度且在学习中是可行的。 |
| [^127] | [Fair Labeled Clustering.](http://arxiv.org/abs/2205.14358) | 本文提出了解决公平标记聚类问题的算法，考虑了下游应用和团体公平性的实现。 |
| [^128] | [Formalizing Preferences Over Runtime Distributions.](http://arxiv.org/abs/2205.13028) | 本文形式化了偏好运行时分布，提出了一种基于效用理论的替代方案来描述算法的评分函数，这些函数与随时间的推移和消费时间的分布有关。 |
| [^129] | [CLIP-Dissect: Automatic Description of Neuron Representations in Deep Vision Networks.](http://arxiv.org/abs/2204.10965) | CLIP-Dissect是一种用于自动描述视觉网络中神经元功能的新技术，它可以无需任何标记数据或人类示例即将内部神经元标记为无需任何标记数据或人类示例的开放概念，并比现有方法提供了更准确的描述。此外，它具有灵活性、高效性和可扩展性。 |
| [^130] | [Stealing and Evading Malware Classifiers and Antivirus at Low False Positive Conditions.](http://arxiv.org/abs/2204.06241) | 本研究尝试针对恶意软件分类器和防病毒产品进行了模型窃取攻击，并提出了一种新的神经网络体系结构和模型窃取攻击方法。最终实现了高达99%的代理模型与目标模型的一致性。 |
| [^131] | [A Multilingual Perspective Towards the Evaluation of Attribution Methods in Natural Language Inference.](http://arxiv.org/abs/2204.05428) | 该论文提出了一种基于多语言的评价方法，以评估自然语言推理任务中归因方法的忠实度和可信度，并且通过高亮的解释扩充了XNLI数据集，研究结果表明在可信度和可信度方面表现最佳的归因方法有所不同。 |
| [^132] | [A Set Membership Approach to Discovering Feature Relevance and Explaining Neural Classifier Decisions.](http://arxiv.org/abs/2204.02241) | 该论文提出一种基于集合成员关系的方法来发现神经分类器所需的特征，并解释其决策。方法能够标识贡献每个特征对神经网络分类器所做出的预测，并解释分类器处理输入分布变化时的行为。 |
| [^133] | [Machine Learning Testing in an ADAS Case Study Using Simulation-Integrated Bio-Inspired Search-Based Testing.](http://arxiv.org/abs/2203.12026) | 本文提出一种基于仿真集成的生物启发式搜索测试方法Deeper，用于生成用于测试基于深度神经网络的车道保持系统的故障发现测试场景，通过实证评估和与竞赛中的其他工具的比较展示了其性能的提高。 |
| [^134] | [Discovering Personalized Semantics for Soft Attributes in Recommender Systems using Concept Activation Vectors.](http://arxiv.org/abs/2202.02830) | 我们使用概念激活向量来把用户描述商品的属性的语义表达出来，以改进推荐系统的效果。 |
| [^135] | [Surrogate-assisted distributed swarm optimisation for computationally expensive geoscientific models.](http://arxiv.org/abs/2201.06843) | 本文利用代理模型辅助的分布式群体优化方法，解决了计算昂贵的地质科学模型优化问题，在基准优化问题和Badlands风貌演化模型中都取得了非常有希望的结果。 |
| [^136] | [Rawlsian Fairness in Online Bipartite Matching: Two-sided, Group, and Individual.](http://arxiv.org/abs/2201.06021) | 本文提出了一种通用的在线匹配算法，它为在线二分匹配平台中的两个双方同时提供公平性保证，而以降低操作者利润为代价。 |
| [^137] | [Probabilistic Fair Clustering.](http://arxiv.org/abs/2006.10916) | 本文提出了一种通过概率分配获得组成员身份的不完美知识的公平聚类算法，并在这种更一般的设置中给出了逼近比保证。 |

# 详细

[^1]: VisualGPTScore: 多模态生成预训练分数的视觉语义推理。

    VisualGPTScore: Visio-Linguistic Reasoning with Multimodal Generative Pre-Training Scores. (arXiv:2306.01879v1 [cs.CV])

    [http://arxiv.org/abs/2306.01879](http://arxiv.org/abs/2306.01879)

    我们提出了VisualGPTScore方法，能够使用多模态生成分数捕捉文本标题可能性，并在图像条件语言模型上进行计算，具备组合推理能力。

    

    本文提出了一种名为 VisualGPTScore 的方法，使用多模态生成分数来捕捉文本标题可能性，并使用图像条件语言模型在图像上运算。与传统观点认为的VLM只是无意义的单词袋模型不同，我们的 VisualGPTScore 在 ARO 和 Crepe 等最近提出的图像文本检索基准测试中展现了顶尖的性能，证明了其具备组合推理能力。

    Vision-language models (VLMs) discriminatively pre-trained with contrastive image-text matching losses such as $P(\text{match}|\text{text}, \text{image})$ have been criticized for lacking compositional understanding. This means they might output similar scores even if the original caption is rearranged into a different semantic statement. To address this, we propose to use the ${\bf V}$isual ${\bf G}$enerative ${\bf P}$re-${\bf T}$raining Score (${\bf VisualGPTScore}$) of $P(\text{text}|\text{image})$, a $\textit{multimodal generative}$ score that captures the likelihood of a text caption conditioned on an image using an image-conditioned language model. Contrary to the belief that VLMs are mere bag-of-words models, our off-the-shelf VisualGPTScore demonstrates top-tier performance on recently proposed image-text retrieval benchmarks like ARO and Crepe that assess compositional reasoning. Furthermore, we factorize VisualGPTScore into a product of the $\textit{marginal}$ P(text) and the
    
[^2]: 文本到视频模型的概率自适应研究

    Probabilistic Adaptation of Text-to-Video Models. (arXiv:2306.01872v1 [cs.AI])

    [http://arxiv.org/abs/2306.01872](http://arxiv.org/abs/2306.01872)

    本论文针对将大型预先训练好的文本到视频模型适应于具有有限领域特定数据的任务，提出了一种基于概率自适应的方法，名为Video Adapter，通过利用大型预先训练的视频扩散模型的分数函数作为概率先验，来指导生成任务特定小型视频模型。实验结果表明，该方法具有优异性能。

    

    在互联网规模的数据集上训练的大型文本到视频模型已经表现出从任意文本描述生成高保真视频的出色能力，但将这些模型适应于具有有限领域特定数据的任务，例如动画或机器人视频，会带来重大的计算挑战，因为微调预先训练好的大模型可能代价高昂。在获得灵感于小型可修改组件（例如提示语、前缀调整）如何使大型语言模型适应执行新任务而无需访问模型权重的情况下，我们探索了如何在不进行微调的情况下将大型预先训练好的文本到视频模型适应于各种下游领域和任务。在回答这个问题的同时，我们提出了Video Adapter，利用大型预先训练的视频扩散模型的分数函数作为概率先验来指导任务特定小型视频模型的生成。我们的实验表明，Video Adapter能够集成具有复杂结构的任务特定模型，并能够适应多种视频领域和任务，与其他方法相比具有优异性能。

    Large text-to-video models trained on internet-scale data have demonstrated exceptional capabilities in generating high-fidelity videos from arbitrary textual descriptions. However, adapting these models to tasks with limited domain-specific data, such as animation or robotics videos, poses a significant computational challenge, since finetuning a pretrained large model can be prohibitively expensive. Inspired by how a small modifiable component (e.g., prompts, prefix-tuning) can adapt a large language model to perform new tasks without requiring access to the model weights, we investigate how to adapt a large pretrained text-to-video model to a variety of downstream domains and tasks without finetuning. In answering this question, we propose Video Adapter, which leverages the score function of a large pretrained video diffusion model as a probabilistic prior to guide the generation of a task-specific small video model. Our experiments show that Video Adapter is capable of incorporatin
    
[^3]: 无竞标，无遗憾：针对数字商品和数据拍卖的对偶反馈机制。

    No Bidding, No Regret: Pairwise-Feedback Mechanisms for Digital Goods and Data Auctions. (arXiv:2306.01860v1 [cs.GT])

    [http://arxiv.org/abs/2306.01860](http://arxiv.org/abs/2306.01860)

    本文提出了针对重复拍卖设置的对偶反馈机制，使用成对比较来从竞标者那里获取信息，避免了之前的学习出价问题，该机制被证明为渐近诚实、个体理性、福利和收益最大化的且适用于任何需要定制生产的商品拍卖场景。

    

    随着数据和 AI 生成数字商品（如个性化书面内容和艺术品）的需求增长，需要有效定价和反馈机制来考虑不确定的效用和昂贵的生产成本。为了解决这些问题，本研究提出了一种新颖的机制设计，适用于一个通用的重复拍卖设置，其中售出商品的效用在销售后揭示。该机制的新颖之处在于使用成对比较来从竞标者那里获取信息，相对于指定数量值来说对人类更容易理解。我们的机制使用 epsilon-greedy 策略选择分配，并且依赖于已分配商品的实现效用和任意值之间的成对比较，避免了以前的学习出价问题。我们证明了该机制是渐近诚实、个体理性、福利和收益最大化的。该机制适用范围广泛，适用于任何需要定制生产、没有固定价格的商品或服务的场景。

    The growing demand for data and AI-generated digital goods, such as personalized written content and artwork, necessitates effective pricing and feedback mechanisms that account for uncertain utility and costly production. Motivated by these developments, this study presents a novel mechanism design addressing a general repeated-auction setting where the utility derived from a sold good is revealed post-sale. The mechanism's novelty lies in using pairwise comparisons for eliciting information from the bidder, arguably easier for humans than assigning a numerical value. Our mechanism chooses allocations using an epsilon-greedy strategy and relies on pairwise comparisons between realized utility from allocated goods and an arbitrary value, avoiding the learning-to-bid problem explored in previous work. We prove this mechanism to be asymptotically truthful, individually rational, and welfare and revenue maximizing. The mechanism's relevance is broad, applying to any setting with made-to-o
    
[^4]: 基于双模式对比学习的H&E组织学图像基因表达预测

    Spatially Resolved Gene Expression Prediction from H&E Histology Images via Bi-modal Contrastive Learning. (arXiv:2306.01859v1 [cs.CV])

    [http://arxiv.org/abs/2306.01859](http://arxiv.org/abs/2306.01859)

    本文提出了BLEEP框架，通过对比学习构建联合嵌入空间，能够从H&E染色组织学图像中生成空间分辨率的基因表达谱地图，具有很高的有效性。

    

    组织学成像是医学诊断和研究的重要工具，能够在微观水平上检查组织结构和组成。了解组织结构的基本分子机制对揭示疾病机制和开发有效治疗方法至关重要。基因表达谱提供了深入了解组织结构背后分子过程的视角，但这一过程耗时且昂贵。在本研究中，我们提出了一种名为BLEEP（Bi-modaL Embedding for Expression Prediction）的双模式嵌入框架，能够从全幅苏木精-伊红（H&E）染色组织学图像中生成空间分辨率的基因表达谱图，并通过对比学习框架在微米分辨率下使用成对的图像和表达谱来构建低维联合嵌入空间的。通过这个框架，可用周围图像的背景上下文推断出任何查询图像补丁的基因表达，从而实现了空间分辨率的基因表达谱地图的生成。我们在四种不同组织类型上展示了BLEEP的有效性，在性能上达到了与最先进的方法竞争的水平。

    Histology imaging is an important tool in medical diagnosis and research, enabling the examination of tissue structure and composition at the microscopic level. Understanding the underlying molecular mechanisms of tissue architecture is critical in uncovering disease mechanisms and developing effective treatments. Gene expression profiling provides insight into the molecular processes underlying tissue architecture, but the process can be time-consuming and expensive. In this study, we present BLEEP (Bi-modaL Embedding for Expression Prediction), a bi-modal embedding framework capable of generating spatially resolved gene expression profiles of whole-slide Hematoxylin and eosin (H&E) stained histology images. BLEEP uses a contrastive learning framework to construct a low-dimensional joint embedding space from a reference dataset using paired image and expression profiles at micrometer resolution. With this framework, the gene expression of any query image patch can be imputed using the
    
[^5]: 5IDER: 统一查询重写技术用于对话引导、意图携带、语言中断、实体携带及修复

    5IDER: Unified Query Rewriting for Steering, Intent Carryover, Disfluencies, Entity Carryover and Repair. (arXiv:2306.01855v1 [cs.CL])

    [http://arxiv.org/abs/2306.01855](http://arxiv.org/abs/2306.01855)

    本文介绍了一种非自回归的查询重写体系结构，该体系不仅可以处理对话引导、意图携带、语法中断、实体携带和修复这五个任务，还可以处理它们的复杂组合。

    

    提供语音助手导航多轮对话的能力是一个具有挑战性的问题。 处理多轮互动需要系统理解各种会话用例，如对话引导、意图携带、语言中断、实体携带和修复。 这个问题的复杂性加剧了这些用例混合在一起的事实，通常同时在自然语言中出现。本文提出了一种非自回归的查询重写体系结构，可以处理五个任务以及这些用例的复杂组合。我们证明了我们提出的模型与基线方法具有相当的单任务性能，并且在用例组合方面甚至优于经过调优的T5模型，尽管在参数上小15倍，在延迟上快25倍。

    Providing voice assistants the ability to navigate multi-turn conversations is a challenging problem. Handling multi-turn interactions requires the system to understand various conversational use-cases, such as steering, intent carryover, disfluencies, entity carryover, and repair. The complexity of this problem is compounded by the fact that these use-cases mix with each other, often appearing simultaneously in natural language. This work proposes a non-autoregressive query rewriting architecture that can handle not only the five aforementioned tasks, but also complex compositions of these use-cases. We show that our proposed model has competitive single task performance compared to the baseline approach, and even outperforms a fine-tuned T5 model in use-case compositions, despite being 15 times smaller in parameters and 25 times faster in latency.
    
[^6]: 基于反事实世界建模实现机器视觉的统一化

    Unifying (Machine) Vision via Counterfactual World Modeling. (arXiv:2306.01828v1 [cs.CV])

    [http://arxiv.org/abs/2306.01828](http://arxiv.org/abs/2306.01828)

    Counterfactual World Modeling (CWM)是一个用于构建统一视觉基础模型的框架，通过解决阻碍基础模型在视觉领域应用的问题，使模型能够处理多种任务，无需昂贵的任务特定标记数据集。

    

    机器视觉领域中的主要方法为不同的任务使用不同的体系结构，并在昂贵的任务特定标记数据集上进行训练。这种复杂性抑制了机器人等领域中的进展，其中强健的任务通用感知仍然是一个瓶颈。相比之下，自然语言的“基础模型”已经证明了大型预训练神经网络如何提供广泛的零样本解决方案，应用于表面上不同的任务。在这里，我们介绍了一种“反事实世界建模”框架，用于构建视觉基础模型：一个统一的无监督网络，可以提示执行各种视觉计算。CWM具有两个关键组成部分，解决了阻碍将基础模型概念应用于视觉的核心问题。第一个是结构化掩模，这是遮蔽预测方法的推广，鼓励预测模型捕捉视觉数据中的低维结构。从而分解了下游任务的关键特征。第二个是反事实学习，其中视觉编码器学习创建具有与输入控制偏差的数据。这鼓励模型获得精确的，结构化的视觉世界表示，为新任务提供支持。我们的实验结果表明，CWM能够处理一系列任务，从预测3D对象的属性到检测和定位图像中的新颖对象。

    Leading approaches in machine vision employ different architectures for different tasks, trained on costly task-specific labeled datasets. This complexity has held back progress in areas, such as robotics, where robust task-general perception remains a bottleneck. In contrast, "foundation models" of natural language have shown how large pre-trained neural networks can provide zero-shot solutions to a broad spectrum of apparently distinct tasks. Here we introduce Counterfactual World Modeling (CWM), a framework for constructing a visual foundation model: a unified, unsupervised network that can be prompted to perform a wide variety of visual computations. CWM has two key components, which resolve the core issues that have hindered application of the foundation model concept to vision. The first is structured masking, a generalization of masked prediction methods that encourages a prediction model to capture the low-dimensional structure in visual data. The model thereby factors the key 
    
[^7]: 广泛使用的面向对象编程语言的比较分析

    Comparative Analysis of Widely use Object-Oriented Languages. (arXiv:2306.01819v1 [cs.PL])

    [http://arxiv.org/abs/2306.01819](http://arxiv.org/abs/2306.01819)

    本文提出了一个全面的框架来评估广泛使用的面向对象编程语言，以基于它们的技术和环境特征进行比较。

    

    编程是计算机科学学科的重要组成部分。编程环境不仅在迅速增长，而且也在不断变化，编程语言也在不断演进。在计算机科学专业中，学习面向对象编程范式是必修课程，因此选择用哪种语言来教授面向对象原理非常重要。由于大量面向对象编程语言，非常难以选择哪一种应该是教授面向对象原理的首选编程语言。许多研究已经显示出哪种语言应该是教授面向对象概念的首选语言，但是还没有一种方法来比较和评估这些语言。在本文中，我们提出了一个全面的框架来评估广泛使用的面向对象编程语言。这些语言是基于它们的技术和环境特征进行评估的。

    Programming is an integral part of computer science discipline. Every day the programming environment is not only rapidly growing but also changing and languages are constantly evolving. Learning of object-oriented paradigm is compulsory in every computer science major so the choice of language to teach object-oriented principles is very important. Due to large pool of object-oriented languages, it is difficult to choose which should be the first programming language in order to teach object-oriented principles. Many studies shown which should be the first language to tech object-oriented concepts but there is no method to compare and evaluate these languages. In this article we proposed a comprehensive framework to evaluate the widely used object-oriented languages. The languages are evaluated basis of their technical and environmental features.
    
[^8]: Beta地中海贫血携带者检测的联邦学习方法

    Beta Thalassemia Carriers detection empowered federated Learning. (arXiv:2306.01818v1 [cs.LG])

    [http://arxiv.org/abs/2306.01818](http://arxiv.org/abs/2306.01818)

    本论文介绍了一种使用联邦学习技术的方法，快速、便宜、无需移动设备地检测Beta地中海贫血携带者。

    

    地中海贫血是一组遗传性血液疾病，当携带输氧至身体各处的红细胞中的蛋白质血红蛋白不足时会发生。如果父母双方都携带地中海贫血基因，孩子患病的几率会增加。确诊和治疗地中海贫血是防止其传递给下一代的关键。目前的血液检测方法对于检测Beta地中海贫血携带者过于昂贵、耗时，且需要大量的筛查设备。高效液相色谱是标准的检测方法，但也存在成本高、时间长、需要特殊设备等问题。因此，寻找一种快速、便宜的检测Beta地中海贫血携带者的方法是至关重要的。

    Thalassemia is a group of inherited blood disorders that happen when hemoglobin, the protein in red blood cells that carries oxygen, is not made enough. It is found all over the body and is needed for survival. If both parents have thalassemia, a child's chance of getting it increases. Genetic counselling and early diagnosis are essential for treating thalassemia and stopping it from being passed on to future generations. It may be hard for healthcare professionals to differentiate between people with thalassemia carriers and those without. The current blood tests for beta thalassemia carriers are too expensive, take too long, and require too much screening equipment. The World Health Organization says there is a high death rate for people with thalassemia. Therefore, it is essential to find thalassemia carriers to act quickly. High-performance liquid chromatography (HPLC), the standard test method, has problems such as cost, time, and equipment needs. So, there must be a quick and che
    
[^9]: 使用区块链和机器学习预测心脏疾病

    Heart Diseases Prediction Using Block-chain and Machine Learning. (arXiv:2306.01817v1 [cs.LG])

    [http://arxiv.org/abs/2306.01817](http://arxiv.org/abs/2306.01817)

    本文研究了使用区块链和机器学习算法预测心脏疾病，并解决了现有架构下数据存储和传输的不安全性问题，有望优化心脏专业人士对于心脏病早期诊断的能力。

    

    全球大部分人死于心脏疾病。其主要原因是医疗部门尚未建立安全的数据存储和传输基础设施。由于患者数据中的冗余性，心脏专业人士很难早期预测疾病。这种快速增加的死亡率可以通过监测和消除早期出现的一些关键因素（例如血压、胆固醇水平、体重和吸烟成瘾）来控制。在医疗部门中，心脏专业人士（Cp）可以使用先进的系统来监控患者数据，其中区块链是最可靠的提供者之一，提供了新的处理疾病的方法。本文使用了一种机器学习（ML）算法，称为正弦余弦支持向量机（Sine-Cosine SVM）。

    Most people around the globe are dying due to heart disease. The main reason behind the rapid increase in the death rate due to heart disease is that there is no infrastructure developed for the healthcare department that can provide a secure way of data storage and transmission. Due to redundancy in the patient data, it is difficult for cardiac Professionals to predict the disease early on. This rapid increase in the death rate due to heart disease can be controlled by monitoring and eliminating some of the key attributes in the early stages such as blood pressure, cholesterol level, body weight, and addiction to smoking. Patient data can be monitored by cardiac Professionals (Cp) by using the advanced framework in the healthcare departments. Blockchain is the world's most reliable provider. The use of advanced systems in the healthcare departments providing new ways of dealing with diseases has been developed as well. In this article Machine Learning (ML) algorithm known as a sine-co
    
[^10]: 使用机器学习和深度学习预测柑橘病害：分类器、模型和SLR

    Prediction of Citrus Diseases Using Machine Learning And Deep Learning: Classifier, Models SLR. (arXiv:2306.01816v1 [cs.LG])

    [http://arxiv.org/abs/2306.01816](http://arxiv.org/abs/2306.01816)

    本文讨论了预测柑橘病害的方法，介绍了使用机器学习和深度学习的分类器和模型，并探讨了相关防治策略。

    

    多年以来，柑橘病害一直是全球柑橘种植业的主要问题，它们会显著降低水果的质量。最危险的柑橘病害包括柑橘溃疡病、柑橘黄龙病、柑橘黑斑病、柑橘叶蛾，这些病害可导致全球柑橘产业出现显著经济损失，防治策略包括化学治疗等。柑橘病害分布在全球所有柑橘种植地区，影响柑橘树根、柑橘树叶、柑橘等水果。柑橘病害的存在对经济因素产生高度影响，同时也会产生低品质水果，增加病害管理费用。卫生和定期监测可以有效管理某些柑橘病害，但其他病害可能需要更加密集的治疗，例如化学或生物控制方法。

    Citrus diseases have been major issues for citrus growing worldwide for many years they can lead significantly reduce fruit quality. the most harmful citrus diseases are citrus canker, citrus greening, citrus black spot, citrus leaf miner which can have significant economic losses of citrus industry in worldwide prevention and management strategies like chemical treatments. Citrus diseases existing in all over the world where citrus is growing its effects the citrus tree root, citrus tree leaf, citrus tree orange etc. Existing of citrus diseases is highly impact on economic factor that can also produce low quality fruits and increased the rate for diseases management. Sanitation and routine monitoring can be effective in managing certain citrus diseases, but others may require more intensive treatments like chemical or biological control methods.
    
[^11]: 基于预测-校正的对抗攻击

    Adversarial Attack Based on Prediction-Correction. (arXiv:2306.01809v1 [cs.CR])

    [http://arxiv.org/abs/2306.01809](http://arxiv.org/abs/2306.01809)

    本论文介绍了一种基于预测-校正的对抗攻击方法，该方法能够有效对抗深度神经网络中的梯度攻击，并具有较好的可扩展性。

    

    深度神经网络(DNNs)容易受到对抗样本的攻击，攻击者将微小的扰动添加到原本的样本中。现有攻击方法中，添加的扰动主要由损失函数对输入的梯度决定。本文首次研究了梯度攻击与求解普通微分方程 (ODE) 数值方法之间的密切关系。受ODE数值解的启发，提出了基于预测-校正(PC)的新型对抗攻击。在我们提出的PC-based攻击中，可以先选择一些现有的攻击方法生成一个预测的样本，然后将预测样本和当前样本组合在一起，以确定所添加的扰动。所提出的方法具有良好的可扩展性，能够轻松应用于所有可用的梯度攻击。广泛的实验证明，与最先进的梯度对抗攻击相比，我们的方法可以更有效地比较进行压缩和加速计算。

    Deep neural networks (DNNs) are vulnerable to adversarial examples obtained by adding small perturbations to original examples. The added perturbations in existing attacks are mainly determined by the gradient of the loss function with respect to the inputs. In this paper, the close relationship between gradient-based attacks and the numerical methods for solving ordinary differential equation (ODE) is studied for the first time. Inspired by the numerical solution of ODE, a new prediction-correction (PC) based adversarial attack is proposed. In our proposed PC-based attack, some existing attack can be selected to produce a predicted example first, and then the predicted example and the current example are combined together to determine the added perturbations. The proposed method possesses good extensibility and can be applied to all available gradient-based attacks easily. Extensive experiments demonstrate that compared with the state-of-the-art gradient-based adversarial attacks, our
    
[^12]: 面向银行业的词嵌入

    Word Embeddings for Banking Industry. (arXiv:2306.01807v1 [cs.CL])

    [http://arxiv.org/abs/2306.01807](http://arxiv.org/abs/2306.01807)

    本文研究了面向银行业的词嵌入，发现其比广泛可用的词嵌入更能捕捉银行特定语义和词相关性，因此可作为NL任务的一个良好独立来源或者补充。

    

    自然语言处理（NLP）应用广泛，从情感分析到文本分类。从静态词嵌入（如Word2Vec或GloVe）到上下文模型提取的静态词表征（如BERT或ELMo），从这些NLP任务中，从业人员往往依赖于这些广泛可用的词嵌入。这些词嵌入是从大量文本构建而成，因此可能已经捕捉了不同上下文中大部分词汇。但是，它们能多好地捕捉特定领域的语义和词相关性？本文通过创建一种银行特定的词嵌入并将其与其他来源的词嵌入（如GloVe和BERT）进行评估，探讨了这个想法。不出所料，从银行特定语料库构建的嵌入更能捕捉银行特定语义和词相关性。该发现表明，面向银行业的词嵌入在执行NL任务时可以作为一个良好的独立来源或者作为其他可广泛获得的嵌入的补充。

    Applications of Natural Language Processing (NLP) are plentiful, from sentiment analysis to text classification. Practitioners rely on static word embeddings (e.g. Word2Vec or GloVe) or static word representation from contextual models (e.g. BERT or ELMo) to perform many of these NLP tasks. These widely available word embeddings are built from large amount of text, so they are likely to have captured most of the vocabulary in different context. However, how well would they capture domain-specific semantics and word relatedness? This paper explores this idea by creating a bank-specific word embeddings and evaluates them against other sources of word embeddings such as GloVe and BERT. Not surprising that embeddings built from bank-specific corpora does a better job of capturing the bank-specific semantics and word relatedness. This finding suggests that bank-specific word embeddings could be a good stand-alone source or a complement to other widely available embeddings when performing NL
    
[^13]: Cook-Gen：从食谱中生成健康烹饪动作的鲁棒性建模

    Cook-Gen: Robust Generative Modeling of Cooking Actions from Recipes. (arXiv:2306.01805v1 [cs.CL])

    [http://arxiv.org/abs/2306.01805](http://arxiv.org/abs/2306.01805)

    本文研究了使用生成AI方法来扩展当前的食品计算模型，将烹饪行为纳入考虑，以实现更全面的健康食谱推荐。

    

    随着人们越来越关注自己的饮食选择，食品计算模型在帮助人们保持健康饮食习惯方面变得越来越流行。例如，食品推荐系统分析食谱指令以评估营养成分并提供食谱推荐。而生成AI方法（如自回归大语言模型）的成功应用可以让我们更全面地理解食谱，从而实现更为健康全面的食谱推荐。本研究探讨使用生成AI方法来扩展当前的食品计算模型，从而将烹饪行为（例如加盐、煎肉、煮蔬菜等）纳入考虑。烹饪行为由于其不规则的数据模式而难以使用统计学习方法进行建模。

    As people become more aware of their food choices, food computation models have become increasingly popular in assisting people in maintaining healthy eating habits. For example, food recommendation systems analyze recipe instructions to assess nutritional contents and provide recipe recommendations. The recent and remarkable successes of generative AI methods, such as auto-regressive large language models, can lead to robust methods for a more comprehensive understanding of recipes for healthy food recommendations beyond surface-level nutrition content assessments. In this study, we explore the use of generative AI methods to extend current food computation models, primarily involving the analysis of nutrition and ingredients, to also incorporate cooking actions (e.g., add salt, fry the meat, boil the vegetables, etc.). Cooking actions are notoriously hard to model using statistical learning methods due to irregular data patterns - significantly varying natural language descriptions f
    
[^14]: 从Diffusion模型中提取奖励函数

    Extracting Reward Functions from Diffusion Models. (arXiv:2306.01804v1 [cs.LG])

    [http://arxiv.org/abs/2306.01804](http://arxiv.org/abs/2306.01804)

    本论文提出了一种从两个Diffusion模型中提取奖励函数的实用学习算法，可以在导航环境中找到正确的奖励函数，并以此控制Diffusion模型学习足够复杂的任务。

    

    Diffusion模型在图像生成方面取得了显著成果，也被用于学习序列决策任务中的高性能策略。我们考虑通过比较建模低奖励行为和建模高奖励行为的决策传播模型来提取奖励函数的问题；这与逆强化学习相关。我们设计了一种实用的学习算法，通过将神经网络参数化的奖励函数的梯度与两个Diffusion模型的输出差异对齐来提取奖励函数。我们的方法可以在导航环境中找到正确的奖励函数，并且表明可以通过控制Diffusion模型来学习足够复杂的任务。

    Diffusion models have achieved remarkable results in image generation, and have similarly been used to learn high-performing policies in sequential decision-making tasks. Decision-making diffusion models can be trained on lower-quality data, and then be steered with a reward function to generate near-optimal trajectories. We consider the problem of extracting a reward function by comparing a decision-making diffusion model that models low-reward behavior and one that models high-reward behavior; a setting related to inverse reinforcement learning. We first define the notion of a relative reward function of two diffusion models and show conditions under which it exists and is unique. We then devise a practical learning algorithm for extracting it by aligning the gradients of a reward function -- parametrized by a neural network -- to the difference in outputs of both diffusion models. Our method finds correct reward functions in navigation environments, and we demonstrate that steering 
    
[^15]: AI数据增强的伦理歧义：研究伦理规范和实践中存在的差距的衡量

    The ethical ambiguity of AI data enrichment: Measuring gaps in research ethics norms and practices. (arXiv:2306.01800v1 [cs.CY])

    [http://arxiv.org/abs/2306.01800](http://arxiv.org/abs/2306.01800)

    本研究探讨了AI研究和数据增强的研究伦理规范存在的差距，建议改进和增强AI研究和数据增强的伦理实践。

    

    人工智能研究的技术进步建立在计算机科学、统计学和数学等领域的突破之上。然而，在过去的十年中，人工智能研究人员越来越多地借鉴社会科学，转向人类互动来解决模型开发的挑战。向众包工人支付费用以生成或筛选数据，也就是数据增强，在许多人工智能研究领域已经成为必不可少的手段，例如自然语言处理和从人类反馈中进行强化学习。其他经常与众包工人互动的领域，如心理学，已经制定了常见的治理要求和规范，以确保研究在伦理上得到了实施。本研究探讨了AI研究和数据增强的相关研究伦理要求和规范的开展程度和程度。我们关注两个领先的会议ICLR和NeurIPS以及期刊出版社Springer所采取的方法。通过对这三个来源的1,468篇论文的纵向分析，我们确定了研究伦理规范存在的差距，并提出了改进和增强AI研究和数据增强的伦理实践的建议。

    The technical progression of artificial intelligence (AI) research has been built on breakthroughs in fields such as computer science, statistics, and mathematics. However, in the past decade AI researchers have increasingly looked to the social sciences, turning to human interactions to solve the challenges of model development. Paying crowdsourcing workers to generate or curate data, or data enrichment, has become indispensable for many areas of AI research, from natural language processing to reinforcement learning from human feedback (RLHF). Other fields that routinely interact with crowdsourcing workers, such as Psychology, have developed common governance requirements and norms to ensure research is undertaken ethically. This study explores how, and to what extent, comparable research ethics requirements and norms have developed for AI research and data enrichment. We focus on the approach taken by two leading conferences: ICLR and NeurIPS, and journal publisher Springer. In a lo
    
[^16]: 以活动理论视角探究外语英语学习者在人工智能写作中的提示工程

    Exploring EFL students' prompt engineering in human-AI story writing: an Activity Theory perspective. (arXiv:2306.01798v1 [cs.CY])

    [http://arxiv.org/abs/2306.01798](http://arxiv.org/abs/2306.01798)

    本研究应用活动理论分析了香港中学生在短篇故事创作中利用生成式人工智能工具的方式和目的，发现其中缺乏目的意识、克服创作障碍以及发展、扩展和改进故事为主要目的。同时，学生活动系统的共同特征也被研究确定。

    

    本研究应用活动理论探究了香港中学生在短篇故事创作中如何利用生成式人工智能工具。研究收集并分析了学生的生成式人工智能工具、短篇故事和有关提示目的的书面反思。研究确定了学生提示生成式人工智能工具的三个主要目的：缺乏目的意识、克服创作障碍以及发展、扩展和改进故事。研究还确定了学生活动系统的共同特征，包括他们的生成式人工智能工具的复杂性、故事的质量以及所在学校的整体学术成就水平。

    This study applies Activity Theory to investigate how English as a foreign language (EFL) students prompt generative artificial intelligence (AI) tools during short story writing. Sixty-seven Hong Kong secondary school students created generative-AI tools using open-source language models and wrote short stories with them. The study collected and analyzed the students' generative-AI tools, short stories, and written reflections on their conditions or purposes for prompting. The research identified three main themes regarding the purposes for which students prompt generative-AI tools during short story writing: a lack of awareness of purposes, overcoming writer's block, and developing, expanding, and improving the story. The study also identified common characteristics of students' activity systems, including the sophistication of their generative-AI tools, the quality of their stories, and their school's overall academic achievement level, for their prompting of generative-AI tools for
    
[^17]: AI与创意领域: 当前和未来应用的简要评论。

    AI and the creative realm: A short review of current and future applications. (arXiv:2306.01795v1 [cs.AI])

    [http://arxiv.org/abs/2306.01795](http://arxiv.org/abs/2306.01795)

    本文探讨了AI在创意领域中的应用，包括艺术、语言和算法，同时也考虑了AI与创造力的哲学意义和潜在的伦理问题。

    

    本研究探讨了创造力与人工智能（AI）的概念及其最近的整合。虽然传统上认为AI无法产生新思想或创造艺术，但更复杂的AI模型的开发和人机交互工具的普及为AI在艺术创作中带来了新的可能性。本研究调查了AI在创意背景下的各种应用，区分了所使用的艺术类型、语言和算法。它还考虑了AI和创造力的哲学意义，质疑意识是否可以在机器中研究，以及AI的潜在兴趣和决策能力。总体而言，我们旨在引发对AI在创意背景下使用和伦理影响的反思。

    This study explores the concept of creativity and artificial intelligence (AI) and their recent integration. While AI has traditionally been perceived as incapable of generating new ideas or creating art, the development of more sophisticated AI models and the proliferation of human-computer interaction tools have opened up new possibilities for AI in artistic creation. This study investigates the various applications of AI in a creative context, differentiating between the type of art, language, and algorithms used. It also considers the philosophical implications of AI and creativity, questioning whether consciousness can be researched in machines and AI's potential interests and decision-making capabilities. Overall, we aim to stimulate a reflection on AI's use and ethical implications in creative contexts.
    
[^18]: 任务关系感知的持续用户表示学习

    Task Relation-aware Continual User Representation Learning. (arXiv:2306.01792v1 [cs.IR])

    [http://arxiv.org/abs/2306.01792](http://arxiv.org/abs/2306.01792)

    本文提出了一种新的持续用户表示学习方法TERACON，它能够学习通用的用户表示，而不是为每个任务学习任务特定的用户表示，具有很强的实用性和学习能力。

    

    用户建模是基于其过去行为学习将用户表示为低维表示空间的方法，它受到了工业界提供个性化服务的兴趣激增。以往的用户建模工作主要集中在学习为单一任务而设计的任务特定用户表示上。然而，由于为每个任务学习任务特定用户表示是不可行的，因此最近的研究引入了通用用户表示的概念，即与多种任务相关的更广义用户表示。尽管这些方法非常有效，但由于数据需求、灾难性遗忘以及为持续添加的任务提供有限的学习能力，现有的学习通用用户表示的方法在实际应用中是不切实际的。本文提出了一种新颖的持续用户表示学习方法TERACON，其学习能力不受任务数量限制。

    User modeling, which learns to represent users into a low-dimensional representation space based on their past behaviors, got a surge of interest from the industry for providing personalized services to users. Previous efforts in user modeling mainly focus on learning a task-specific user representation that is designed for a single task. However, since learning task-specific user representations for every task is infeasible, recent studies introduce the concept of universal user representation, which is a more generalized representation of a user that is relevant to a variety of tasks. Despite their effectiveness, existing approaches for learning universal user representations are impractical in real-world applications due to the data requirement, catastrophic forgetting and the limited learning capability for continually added tasks. In this paper, we propose a novel continual user representation learning method, called TERACON, whose learning capability is not limited as the number 
    
[^19]: 机器学习流程的负责任设计模式

    Responsible Design Patterns for Machine Learning Pipelines. (arXiv:2306.01788v1 [cs.SE])

    [http://arxiv.org/abs/2306.01788](http://arxiv.org/abs/2306.01788)

    本文提出了一种综合框架，将负责任设计模式纳入机器学习流程中，以确保AI系统的伦理性和公正性。这个框架包括新的负责任AI设计模式，并指导AI开发人员、数据科学家和决策者在AI开发和部署中实施伦理实践。

    

    将道德实践整合到人工智能(AI)开发过程中对于确保AI的安全、公平和负责任操作至关重要。AI伦理涉及将伦理原则应用于AI系统的整个生命周期。这对于减轻与AI相关的潜在风险和伤害（如算法偏见）至关重要。为实现这一目标，机器学习流程中的负责任设计模式（RDPs）对于确保伦理和公平结果至关重要。在本文中，我们提出了一个综合框架，将RDPs纳入ML流程中，以减轻风险并确保AI系统的伦理发展。我们的框架包括新的负责任AI设计模式，这些模式通过对AI伦理和数据管理专家的调查确定，并通过专家反馈的实际情况进行验证。该框架指导AI开发人员、数据科学家和决策者在AI开发和部署中实施伦理实践。

    Integrating ethical practices into the AI development process for artificial intelligence (AI) is essential to ensure safe, fair, and responsible operation. AI ethics involves applying ethical principles to the entire life cycle of AI systems. This is essential to mitigate potential risks and harms associated with AI, such as algorithm biases. To achieve this goal, responsible design patterns (RDPs) are critical for Machine Learning (ML) pipelines to guarantee ethical and fair outcomes. In this paper, we propose a comprehensive framework incorporating RDPs into ML pipelines to mitigate risks and ensure the ethical development of AI systems. Our framework comprises new responsible AI design patterns for ML pipelines identified through a survey of AI ethics and data management experts and validated through real-world scenarios with expert feedback. The framework guides AI developers, data scientists, and policy-makers to implement ethical practices in AI development and deploy responsibl
    
[^20]: 通过Codewars编程问题评估GPT模型的编程能力

    Evaluating GPT's Programming Capability through CodeWars' Katas. (arXiv:2306.01784v1 [cs.AI])

    [http://arxiv.org/abs/2306.01784](http://arxiv.org/abs/2306.01784)

    本文在Codewars上对GPT-3.5和GPT-4模型的编程能力进行了评估，发现它们在3 kyu级别以上的问题上遇到困难。作者提出了一个综合考虑问题难度和所需时间的编程问题复杂度度量，并强调AI模型需要验证和创造性思维能力。

    

    在人工智能领域，理解面向编程的模型的能力和局限性至关重要。本文提出了一种新颖的方法，通过对来自Codewars的不同难度级别的编程问题进行评估，评估生成预训练转换器（GPT）模型的编程能力，特别是GPT-3.5和GPT-4。实验揭示了一个显著的边界，即超过3kyu级别，这些GPT模型难以提供解决方案。这些发现引发了一个考虑问题难度和解决方案所需时间的编程问题复杂度度量提议。研究强调了在人工智能模型中需要验证和创造性思维能力，以更好地模拟人类解决问题的技巧。未来的工作旨在完善这个所提议的复杂度度量、增强AI模型的这些建议能力，并开发一个衡量编程问题难度的客观标准。

    In the burgeoning field of artificial intelligence (AI), understanding the capabilities and limitations of programming-oriented models is crucial. This paper presents a novel evaluation of the programming proficiency of Generative Pretrained Transformer (GPT) models, specifically GPT-3.5 and GPT-4, against coding problems of varying difficulty levels drawn from Codewars. The experiments reveal a distinct boundary at the 3kyu level, beyond which these GPT models struggle to provide solutions. These findings led to the proposal of a measure for coding problem complexity that incorporates both problem difficulty and the time required for solution. The research emphasizes the need for validation and creative thinking capabilities in AI models to better emulate human problem-solving techniques. Future work aims to refine this proposed complexity measure, enhance AI models with these suggested capabilities, and develop an objective measure for programming problem difficulty. The results of t
    
[^21]: 基于大型语言模型的概念设计生成

    Conceptual Design Generation Using Large Language Models. (arXiv:2306.01779v1 [cs.CL])

    [http://arxiv.org/abs/2306.01779](http://arxiv.org/abs/2306.01779)

    本文利用大型语言模型生成解决方案，并将其与众包解决方案进行比较。专家评估表明，LLM生成的解决方案具有更高的可行性和有用性，众包的解决方案更加具有创意性。

    

    概念生成是概念设计阶段的创造性步骤，在这个阶段中，设计师经常尝试通过头脑风暴、思维导图或众包设计思路来补充他们自己对领域的知识。自然语言处理（NLP）和机器学习（ML）的最新进展已经导致了大型语言模型（LLM）的兴起，这些模型能够从文本提示中生成看似创造性的输出。这些模型的成功应用跨足了艺术、娱乐和其他创作工作等各个领域。本文利用LLMs为一组12个设计问题生成解决方案，并将其与众包解决方案基准进行比较。我们通过多个角度评估生成和众包设计解决方案之间的差异，包括人工专家评估和计算指标。专家评估表明，LLM生成的解决方案平均可行性和有用性更高，而众包的解决方案更加具有创意性。

    Concept generation is a creative step in the conceptual design phase, where designers often turn to brainstorming, mindmapping, or crowdsourcing design ideas to complement their own knowledge of the domain. Recent advances in natural language processing (NLP) and machine learning (ML) have led to the rise of Large Language Models (LLMs) capable of generating seemingly creative outputs from textual prompts. The success of these models has led to their integration and application across a variety of domains, including art, entertainment, and other creative work. In this paper, we leverage LLMs to generate solutions for a set of 12 design problems and compare them to a baseline of crowdsourced solutions. We evaluate the differences between generated and crowdsourced design solutions through multiple perspectives, including human expert evaluations and computational metrics. Expert evaluations indicate that the LLM-generated solutions have higher average feasibility and usefulness while th
    
[^22]: 面向可信自动系统开发的RE中心化建议

    RE-centric Recommendations for the Development of Trustworthy(er) Autonomous Systems. (arXiv:2306.01774v1 [cs.CY])

    [http://arxiv.org/abs/2306.01774](http://arxiv.org/abs/2306.01774)

    本研究发现目前AI系统开发中缺少要求工程（RE）这一环节且伦理指南术语和原则覆盖的不一致性，为解决该问题我们制定了一个术语表并研究了伦理AI开发框架在执行RE方面的适用性。

    

    在欧盟内开发和实施人工智能系统时符合欧盟AI法案（AIA）指南将很快是强制性的。然而，从行动指南方面，实践者缺乏在AI系统开发期间实施伦理的可操作说明。对不同伦理指南的文献综述揭示了所涉及原则和术语描述的不一致性。此外，要在AI开发过程的早期阶段培养信任的要求工程（RE）被证明在许多支持道德和可信AI开发的框架中缺失。这种不协调的措辞加上缺乏具体的开发实践使可信AI开发更加困难。为解决此问题，我们制定了一个术语表，用于比较主要伦理AI指南中使用的术语和伦理AI原则的覆盖范围。然后，我们研究了伦理AI开发框架在执行RE方面的适用性。

    Complying with the EU AI Act (AIA) guidelines while developing and implementing AI systems will soon be mandatory within the EU. However, practitioners lack actionable instructions to operationalise ethics during AI systems development. A literature review of different ethical guidelines revealed inconsistencies in the principles addressed and the terminology used to describe them. Furthermore, requirements engineering (RE), which is identified to foster trustworthiness in the AI development process from the early stages was observed to be absent in a lot of frameworks that support the development of ethical and trustworthy AI. This incongruous phrasing combined with a lack of concrete development practices makes trustworthy AI development harder. To address this concern, we formulated a comparison table for the terminology used and the coverage of the ethical AI principles in major ethical AI guidelines. We then examined the applicability of ethical AI development frameworks for perfo
    
[^23]: ProcessGPT: 用生成人工智能转变业务流程管理

    ProcessGPT: Transforming Business Process Management with Generative Artificial Intelligence. (arXiv:2306.01771v1 [cs.AI])

    [http://arxiv.org/abs/2306.01771](http://arxiv.org/abs/2306.01771)

    ProcessGPT是一种使用GPT技术的新型技术，可在需要时生成新的业务流程模型，可用于决策辅助，具有潜在的增强数据中心和知识密集型流程的能力。

    

    生成预训练转换器（GPT）是一种最先进的机器学习模型，通过自然语言处理（NLP）生成类人文本。GPT通过大量文本数据进行训练，并使用深度学习技术学习数据中的模式和关系，使其能够生成连贯和上下文适当的文本。本文提出使用GPT技术在需要时生成新的流程模型。我们介绍了ProcessGPT作为一种新技术，它有潜力增强数据中心和知识密集型流程的决策。ProcessGPT可通过在大型业务流程数据集上训练生成预训练转换器模型来设计。然后，可以对特定流程域进行微调并根据上下文和用户输入对其进行流程流程的生成和决策。该模型可以与NLP和机器学习技术集成以提供洞察和建议。

    Generative Pre-trained Transformer (GPT) is a state-of-the-art machine learning model capable of generating human-like text through natural language processing (NLP). GPT is trained on massive amounts of text data and uses deep learning techniques to learn patterns and relationships within the data, enabling it to generate coherent and contextually appropriate text. This position paper proposes using GPT technology to generate new process models when/if needed. We introduce ProcessGPT as a new technology that has the potential to enhance decision-making in data-centric and knowledge-intensive processes. ProcessGPT can be designed by training a generative pre-trained transformer model on a large dataset of business process data. This model can then be fine-tuned on specific process domains and trained to generate process flows and make decisions based on context and user input. The model can be integrated with NLP and machine learning techniques to provide insights and recommendations f
    
[^24]: 基于技术的路面和养护战略自适应决策支持系统：气候变化适应风险评估框架的焦点

    Towards a Technology-Driven Adaptive Decision Support System for Integrated Pavement and Maintenance strategies (TDADSS-IPM): focus on risk assessment framework for climate change adaptation. (arXiv:2306.01769v1 [cs.AI])

    [http://arxiv.org/abs/2306.01769](http://arxiv.org/abs/2306.01769)

    本研究提出了一种名为TDADSS-IPM的自适应路面和养护战略决策支持系统，旨在提供完整的风险评估模型，以实现对气候条件下道路情况的实际了解，以便于进行适当的管理和维护。

    

    过去，用于路面和养护战略的决策支持系统一般被设计成局部最优系统。由于工业4.0时代的大数据应用尚未出现，因此这些DSS最初并未被设计为适应不确定性来源，导致决策不够灵活。本文由于公路资产对气候现象的脆弱性，采取了具有远见的措施，引入了一种名为TDADSS-IPM（基于技术的自适应路面和养护战略决策支持系统）的综合系统。作为这种DSS的一部分，通过贝叶斯信念网络，构建了一种自下而上的风险评估模型，以了解丹麦道路由于气候条件的实际状况。这种模型填补了知识领域的空白，开发了一个平台，可以随着时间的推移进行培训，并在实际事件中进行实时应用。

    Decision Support Systems for pavement and maintenance strategies have traditionally been designed as silos led to local optimum systems. Moreover, since big data usage didn't exist as result of Industry 4.0 as of today, DSSs were not initially designed adaptive to the sources of uncertainties led to rigid decisions. Motivated by the vulnerability of the road assets to the climate phenomena, this paper takes a visionary step towards introducing a Technology-Driven Adaptive Decision Support System for Integrated Pavement and Maintenance activities called TDADSS-IPM. As part of such DSS, a bottom-up risk assessment model is met via Bayesian Belief Networks (BBN) to realize the actual condition of the Danish roads due to weather condition. Such model fills the gaps in the knowledge domain and develops a platform that can be trained over time, and applied in real-time to the actual event.
    
[^25]: 基于贝叶斯优化的桁架设计优化

    Optimization for truss design using Bayesian optimization. (arXiv:2306.01763v1 [stat.AP])

    [http://arxiv.org/abs/2306.01763](http://arxiv.org/abs/2306.01763)

    本文提出了利用贝叶斯优化算法进行桁架设计优化的方法，通过迭代评估候选设计并更新概率模型的方式优化桁架结构，该方法在优化复杂系统方面表现出有效性。

    

    本文提出了一种利用计算机辅助有限元分析进行机械桁架几何优化的方法。桁架的形状是确定其承载能力的主要因素。在给定的参数空间中，我们旨在找到最大化承载能力且不会产生应力的外壳参数。我们选择贝叶斯优化作为我们的优化框架，以解决这种昂贵计算的设计评估问题。通过利用贝叶斯优化算法，桁架设计涉及迭代评估一组候选桁架设计，并基于结果更新设计空间的概率模型。该模型用于预测每个候选设计的性能，下一个候选设计是基于模型对性能改进的预测。我们的结果表明，概率模型有助于评估桁架设计空间，并且贝叶斯优化是优化复杂系统的有效方法。

    In this work, geometry optimization of mechanical truss using computer-aided finite element analysis is presented. The shape of the truss is a dominant factor in determining the capacity of load it can bear. At a given parameter space, our goal is to find the parameters of a hull that maximize the load-bearing capacity and also don't yield to the induced stress. We rely on finite element analysis, which is a computationally costly design analysis tool for design evaluation. For such expensive to-evaluate functions, we chose Bayesian optimization as our optimization framework which has empirically proven sample efficient than other simulation-based optimization methods.  By utilizing Bayesian optimization algorithms, the truss design involves iteratively evaluating a set of candidate truss designs and updating a probabilistic model of the design space based on the results. The model is used to predict the performance of each candidate design, and the next candidate design is selected ba
    
[^26]: 预训练Transformer用于对抗性样本提纯

    Pre-trained transformer for adversarial purification. (arXiv:2306.01762v1 [cs.CR])

    [http://arxiv.org/abs/2306.01762](http://arxiv.org/abs/2306.01762)

    本文提出了一个快速防御对抗性攻击的方案RaPiD（Rapid Plug-in Defender），通过预训练的Transformer微调来提纯对抗样本，使其逼近清洁数据分布，实验结果表明，在有限数据情况下，该方法优于最先进的方法。

    

    随着越来越多的深度神经网络被部署为各种日常服务，它们的可靠性至关重要。深度神经网络容易受到对抗性攻击的影响，其中逃避攻击是最普遍的一种。最近的研究通常通过对抗训练或利用大量清洁数据的知识来增强其健壮性。然而，在实际应用中，重新训练和部署模型需要大量的计算资源，对在线服务造成重大损失。此外，当检测到某种攻击的对抗性例子时，服务提供者只能获得有限的对抗性样本，而大量的清洁数据可能无法获取。针对这些问题，我们提出了一种新的方案，名为RaPiD（Rapid Plug-in Defender），旨在快速防御具有少量干净和对抗性示例限制的原始服务模型的某种攻击。受到预训练模型提供转移学习良好初始化的通用趋势的启发，我们建议通过微调预先训练的Transformer来提纯对抗性样本。预训练的Transformer作为正则化器，鼓励提纯后的对抗性样本接近清晰数据的分布。实验结果表明，RaPiD在防御各种具有限数据的攻击方面优于最先进的方法。

    With more and more deep neural networks being deployed as various daily services, their reliability is essential. It's frightening that deep neural networks are vulnerable and sensitive to adversarial attacks, the most common one of which for the services is evasion-based. Recent works usually strengthen the robustness by adversarial training or leveraging the knowledge of an amount of clean data. However, in practical terms, retraining and redeploying the model need a large computational budget, leading to heavy losses to the online service. In addition, when adversarial examples of a certain attack are detected, only limited adversarial examples are available for the service provider, while much clean data may not be accessible. Given the mentioned problems, we propose a new scenario, RaPiD (Rapid Plug-in Defender), which is to rapidly defend against a certain attack for the frozen original service model with limitations of few clean and adversarial examples. Motivated by the general
    
[^27]: 使用机器学习区分人类生成文本和ChatGPT生成文本

    Distinguishing Human Generated Text From ChatGPT Generated Text Using Machine Learning. (arXiv:2306.01761v1 [cs.CL])

    [http://arxiv.org/abs/2306.01761](http://arxiv.org/abs/2306.01761)

    本文提出了一种机器学习方法，可以识别出由ChatGPT生成的文本，并以11种算法进行了分类对比分析，在测试中取得了77%的准确度。

    

    ChatGPT是预训练大语言模型家族中的一员，是一种对话人工智能。这种文本生成模型通过监督学习和强化学习进行微调，可以生成看似由自然智能撰写的文本文件。虽然这种生成模型有很多优点，但也存在一些合理的担忧。本文提出了一种基于机器学习的解决方案，可以识别出ChatGPT生成的文本与人类编写的文本，以及在分类过程中共计11种机器学习和深度学习算法的对比分析。我们在一个Kaggle数据集上测试了所提出的模型，该数据集包含10,000个文本，其中5,204个文本是人类从新闻和社交媒体上收集的写作。在由GPT-3.5生成的语料库上，所提出的算法呈现出77%的准确度。

    ChatGPT is a conversational artificial intelligence that is a member of the generative pre-trained transformer of the large language model family. This text generative model was fine-tuned by both supervised learning and reinforcement learning so that it can produce text documents that seem to be written by natural intelligence. Although there are numerous advantages of this generative model, it comes with some reasonable concerns as well. This paper presents a machine learning-based solution that can identify the ChatGPT delivered text from the human written text along with the comparative analysis of a total of 11 machine learning and deep learning algorithms in the classification process. We have tested the proposed model on a Kaggle dataset consisting of 10,000 texts out of which 5,204 texts were written by humans and collected from news and social media. On the corpus generated by GPT-3.5, the proposed algorithm presents an accuracy of 77%.
    
[^28]: 非参数模型揭示收入动态演化：基于PSID数据的隐马尔科夫模型研究 (arXiv:2306.01760v1 [stat.AP])

    Nonparametric Identification and Estimation of Earnings Dynamics using a Hidden Markov Model: Evidence from the PSID. (arXiv:2306.01760v1 [stat.AP])

    [http://arxiv.org/abs/2306.01760](http://arxiv.org/abs/2306.01760)

    本研究使用隐马尔科夫模型揭示了收入持续性的复杂本质，并证实了收入具有非线性持续性、条件偏斜性和条件峰度等特征，并发现了ARCH效应以及非高斯瞬时性成分所产生的明显分布不对称性影响。

    

    本文提出了一种隐马尔科夫模型，以揭示收入持续性的复杂本质。所提出的模型假定对数收入残差包括持久性和瞬时性两个部分，均遵循马尔科夫过程。通过对线性算子进行谱分解实现非参数识别，并引入改进的随机EM算法进行模型估计。将该框架应用于收入动态研究（PSID）数据集中，我们发现收入过程呈现非线性持续性、条件偏斜性和条件峰度。此外，瞬时性成分具有非高斯性质，在高收入家庭面临负冲击或低收入家庭遭遇正冲击时会产生明显的不对称分布影响。我们的实证研究还发现，在2至8年的时间范围内，收入具有ARCH效应。

    This paper presents a hidden Markov model designed to investigate the complex nature of earnings persistence. The proposed model assumes that the residuals of log-earnings consist of a persistent component and a transitory component, both following general Markov processes. Nonparametric identification is achieved through spectral decomposition of linear operators, and a modified stochastic EM algorithm is introduced for model estimation. Applying the framework to the Panel Study of Income Dynamics (PSID) dataset, we find that the earnings process displays nonlinear persistence, conditional skewness, and conditional kurtosis. Additionally, the transitory component is found to possess non-Gaussian properties, resulting in a significantly asymmetric distributional impact when high-earning households face negative shocks or low-earning households encounter positive shocks. Our empirical findings also reveal the presence of ARCH effects in earnings at horizons ranging from 2 to 8 years, fu
    
[^29]: 训练先验影响文本到图像模型性能

    Training Priors Predict Text-To-Image Model Performance. (arXiv:2306.01755v1 [cs.CV])

    [http://arxiv.org/abs/2306.01755](http://arxiv.org/abs/2306.01755)

    本文测试了文本到图像模型对于训练先验的依赖程度，发现模型能够更好地生成与训练数据中出现频率更高的三元组对齐的图像，但这也会降低其生成以翻转三元组为基础的图像质量。

    

    文本到图像的模型能够生成一些关系，比如“宇航员骑马”，但却不能生成由相同基本部分组成的其他关系，比如“马骑宇航员”。这些失败通常被视为模型依赖训练先验而不是构建新颖的图像组合的证据。本文直接在稳定扩散2.1文本到图像模型上进行了测试。通过观察组成这些提示的主语-谓语-宾语 (SVO) 三元组（例如，“宇航员”，“骑”，“马”），我们发现，SVO三元组在训练数据中出现的次数越多，该模型就能生成与该三元组对齐的图像就越好。在这里，通过对齐，我们的意思是每个术语在生成的图像中以正确的关系出现。然而，这种增加的频率也会减少模型能够生成与翻转三元组对齐的图像的能力。例如，如果“宇航员骑马”在训练数据中频繁出现，那么“马骑宇航员”的对齐质量就会降低。

    Text-to-image models can often generate some relations, i.e., "astronaut riding horse", but fail to generate other relations composed of the same basic parts, i.e., "horse riding astronaut". These failures are often taken as evidence that the models rely on training priors rather than constructing novel images compositionally. This paper tests this intuition directly on the stablediffusion 2.1 text-to-image model. By looking at the subject-verb-object (SVO) triads that form the backbone of these prompts (e.g., "astronaut", "ride", "horse"), we find that the more often an SVO triad appears in the training data, the better the model can generate an image aligned with that triad. Here, by aligned we mean that each of the terms appears in the generated image in the proper relation to each other. However, this increased frequency also diminishes how well the model can generate an image aligned with the flipped triad. For example, if "astronaut riding horse" appears frequently in the trainin
    
[^30]: 基于Transformer的代码编辑时漏洞检测：零样本、小样本还是微调？

    Transformer-based Vulnerability Detection in Code at EditTime: Zero-shot, Few-shot, or Fine-tuning?. (arXiv:2306.01754v1 [cs.CR])

    [http://arxiv.org/abs/2306.01754](http://arxiv.org/abs/2306.01754)

    本研究使用深度学习在编辑代码的同时检测漏洞，可以高精度、低延迟地检测超过250种漏洞类型的复杂漏洞代码模式，使软件开发人员能够在引入潜在漏洞到代码库之前修复它们。

    

    软件漏洞会给企业带来重大损失。尽管针对软件漏洞检测方法的研究和开发已经进行了广泛的努力，但未发现的漏洞仍会对软件所有者和用户造成风险。许多当前的漏洞检测方法要求代码片段能够在尝试检测之前编译和构建。不幸的是，这会在注入漏洞到删除漏洞的时间之间引入很长的延迟，这可能会大大增加修复漏洞的成本。本文利用深度学习在包含250多种漏洞类型的大型数据集上学习复杂的漏洞代码模式，并在代码编辑时检测漏洞。我们讨论了训练Transformer的神经网络的方法，它在零样本、小样本和微调设置中实现了最先进的性能。我们的实验表明，我们的系统可以高精度、低延迟地检测漏洞，使软件开发人员能够在引入潜在漏洞到代码库之前修复它们。

    Software vulnerabilities bear enterprises significant costs. Despite extensive efforts in research and development of software vulnerability detection methods, uncaught vulnerabilities continue to put software owners and users at risk. Many current vulnerability detection methods require that code snippets can compile and build before attempting detection. This, unfortunately, introduces a long latency between the time a vulnerability is injected to the time it is removed, which can substantially increases the cost of fixing a vulnerability. We recognize that the current advances in machine learning can be used to detect vulnerable code patterns on syntactically incomplete code snippets as the developer is writing the code at EditTime. In this paper we present a practical system that leverages deep learning on a large-scale data set of vulnerable code patterns to learn complex manifestations of more than 250 vulnerability types and detect vulnerable code patterns at EditTime. We discus
    
[^31]: 弱监督下的预处理视觉语言推理

    Preconditioned Visual Language Inference with Weak Supervision. (arXiv:2306.01753v1 [cs.CL])

    [http://arxiv.org/abs/2306.01753](http://arxiv.org/abs/2306.01753)

    本文提出了一个名为PVLIR的预处理视觉语言推理和合理化任务，结果揭示了当前最先进的视觉语言模型在此项任务上的缺陷，并提出了改进这些模型的挑战。

    

    人类可以通过提取每种情境下相关的前提条件来推断物体的可供性。例如，看到一张破碎杯子的照片，我们可以推断这个前提条件阻止了杯子用于饮用。自然语言处理领域研究中，模型明确获取上下文前提条件来推理常识。但是，目前最先进的视觉语言模型是否能够提取这样的前提条件并推断物体的可供性尚不清楚。本文提出了一个名为PVLIR的预处理视觉语言推理和合理化任务，并开发了三个策略的学习资源来检索该任务的弱监督信号，并制定了经过人工验证的测试集进行评估。我们的结果揭示了最先进的视觉语言模型在这项任务上的缺陷，并绘制了未来改进这些模型面临的挑战的路线图。

    Humans can infer the affordance of objects by extracting related contextual preconditions for each scenario. For example, upon seeing an image of a broken cup, we can infer that this precondition prevents the cup from being used for drinking. Reasoning with preconditions of commonsense is studied in NLP where the model explicitly gets the contextual precondition. However, it is unclear if SOTA visual language models (VLMs) can extract such preconditions and infer the affordance of objects with them. In this work, we introduce the task of preconditioned visual language inference and rationalization (PVLIR). We propose a learning resource based on three strategies to retrieve weak supervision signals for the task and develop a human-verified test set for evaluation. Our results reveal the shortcomings of SOTA VLM models in the task and draw a road map to address the challenges ahead in improving them.
    
[^32]: 可解释人工智能综述及对解释工程学科的提议

    A Survey of Explainable AI and Proposal for a Discipline of Explanation Engineering. (arXiv:2306.01750v1 [cs.AI])

    [http://arxiv.org/abs/2306.01750](http://arxiv.org/abs/2306.01750)

    本文深入探讨了可解释人工智能领域，并提出了一种有前景的学科：“解释工程学”，该学科包括一种系统化方法，用于设计各种可解释人工智能系统。

    

    本篇综述深入探讨可解释人工智能领域。在介绍文章的范围后，我们首先讨论“解释”的真正含义。然后，我们进一步讨论现有的可解释人工智能方法，并建立了最受欢迎方法的分类法。接下来，我们还研究了这些以及其他可解释人工智能技术在金融、自动驾驶、医疗保健和制造等四个主要领域的应用。最后，我们引入了一种有前景的学科，“解释工程学”，其中包括一种系统化方法，用于设计各种可解释人工智能系统。

    In this survey paper, we deep dive into the field of Explainable Artificial Intelligence (XAI). After introducing the scope of this paper, we start by discussing what an "explanation" really is. We then move on to discuss some of the existing approaches to XAI and build a taxonomy of the most popular methods. Next, we also look at a few applications of these and other XAI techniques in four primary domains: finance, autonomous driving, healthcare and manufacturing. We end by introducing a promising discipline, "Explanation Engineering," which includes a systematic approach for designing explainability into AI systems.
    
[^33]: 中性集应用于决策制定的研究

    An Application of Neutrosophic Sets to Decision Making. (arXiv:2306.01746v1 [cs.AI])

    [http://arxiv.org/abs/2306.01746](http://arxiv.org/abs/2306.01746)

    本文探讨了一种使用中性集进行决策制定的新方法，采用中性三元组代替二进制元素来解决某些或所有元素的模糊/定性特征存在疑虑的情况

    

    Maji等人在2002年提出了一种使用软集作为工具的参数化决策制定方法，并将它们的表格形式表示为二进制矩阵。然而，在某些情况下，用于描述全集元素特征的某些或所有参数具有模糊的质地时，他们的方法并不总是给出最佳的决策制定解决方案。为了解决这个问题，我们在早期的研究中修改了Maji等人的方法，通过将相应的软集的表格形式中的二进制元素替换为灰色数字或三角形模糊数字。在本文中，为了更有效地解决决策制定人对分配给某些或所有元素的模糊/定性特征的正确性存在疑虑的情况，我们将表格形式的二进制元素替换为中性三元组。我们的新的、中性决策制定方法是通过一个有关选择新PL的应用来说明的。

    Maji et al. introduced in 2002 a method of parametric decision making using soft sets as tools and representing their tabular form as a binary matrix. In cases, however, where some or all of the parameters used for the characterization of the elements of the universal set are of fuzzy texture, their method does not give always the best decision making solution. In order to tackle this problem, we modified in earlier works the method of Maji et al. by replacing the binary elements in the tabular form of the corresponding soft set either by grey numbers or by triangular fuzzy numbers. In this work, in order to tackle more efficiently cases in which the decision maker has doubts about the correctness of the fuzzy/qualitative characterizations assigned to some or all of the elements of the universal set, we replace the binary elements of the tabular form by neutrosophic triplets. Our new, neutrosophic decision making method is illustrated by an application concerning the choice of a new pl
    
[^34]: 利用量子神经网络进行生物标志物的发现：以CTLA4激活通路的案例研究为例

    Biomarker Discovery with Quantum Neural Networks: A Case-study in CTLA4-Activation Pathways. (arXiv:2306.01745v1 [q-bio.QM])

    [http://arxiv.org/abs/2306.01745](http://arxiv.org/abs/2306.01745)

    该论文介绍了一种利用量子神经网络的模型，可以用于发现与CLTA4通路相关的新生物标志物，并且该模型经济实用。

    

    生物标志物的发现是一项具有挑战性的任务，由于搜索空间庞大。量子计算和量子人工智能（量子AI）可以用于解决生物标志物发现任务的计算问题。我们提出了一种量子神经网络（QNNs）架构，用于发现输入激活通路的生物标志物。最大相关性，最小冗余（mRMR）标准用于评分生物标志物候选集。由于神经解决方案可以在受限硬件上交付，所以我们提出的模型是经济的。我们在与CTLA4相关的四条激活通路上展示了证明概念，包括（1）CTLA4激活独立，（2）CTLA4-CD8A-CD8B共同激活，（3）CTLA4-CD2共同激活，以及（4）CTLA4-CD2-CD48-CD53-CD58-CD84共同激活。该模型指出与CLTA4相关通路的突变激活有新的生物标志物，包括20个基因：CLIC4，CPE，ETS2，FAM107A，GPR116，HYOU1，LCN2，MACF1，MT1G，NAPA，NDUFS5，PAK1，PFN1，PGAP

    Biomarker discovery is a challenging task due to the massive search space. Quantum computing and quantum Artificial Intelligence (quantum AI) can be used to address the computational problem of biomarker discovery tasks. We propose a Quantum Neural Networks (QNNs) architecture to discover biomarkers for input activation pathways. The Maximum Relevance, Minimum Redundancy (mRMR) criteria is used to score biomarker candidate sets. Our proposed model is economical since the neural solution can be delivered on constrained hardware. We demonstrate the proof of concept on four activation pathways associated with CTLA4, including (1) CTLA4-activation stand-alone, (2) CTLA4-CD8A-CD8B co-activation, (3) CTLA4-CD2 co-activation, and (4) CTLA4-CD2-CD48-CD53-CD58-CD84 co-activation. The model indicates new biomarkers associated with the mutational activation of CLTA4-associated pathways, including 20 genes: CLIC4, CPE, ETS2, FAM107A, GPR116, HYOU1, LCN2, MACF1, MT1G, NAPA, NDUFS5, PAK1, PFN1, PGAP
    
[^35]: 用形式化方法打破XAI神话-初步结果

    Disproving XAI Myths with Formal Methods -- Initial Results. (arXiv:2306.01744v1 [cs.AI])

    [http://arxiv.org/abs/2306.01744](http://arxiv.org/abs/2306.01744)

    论文介绍了XAI中最严重的一些误解，并展示了如何使用形式化方法来打破这些谬见和开发更实用的替代方案。

    

    近年来，机器学习（ML）的进展既令人印象深刻又深远。然而，ML模型的部署仍然受到人们对最佳表现的ML模型如何进行预测的信任缺乏的影响。在高风险或安全关键领域使用ML模型时，缺乏信任的问题更加严重。可解释的人工智能（XAI）是为提供可信赖AI而进行的不断努力的核心。不幸的是，XAI充斥着关键误解，这些误解助长了不信任而不是建立信任。本文详细介绍了XAI中最明显的一些误解，并展示了如何使用形式化方法来推翻这些误解，以及设计实际有效的替代方案。

    The advances in Machine Learning (ML) in recent years have been both impressive and far-reaching. However, the deployment of ML models is still impaired by a lack of trust in how the best-performing ML models make predictions. The issue of lack of trust is even more acute in the uses of ML models in high-risk or safety-critical domains. eXplainable artificial intelligence (XAI) is at the core of ongoing efforts for delivering trustworthy AI. Unfortunately, XAI is riddled with critical misconceptions, that foster distrust instead of building trust. This paper details some of the most visible misconceptions in XAI, and shows how formal methods have been used, both to disprove those misconceptions, but also to devise practically effective alternatives.
    
[^36]: 基于 Transformer 模型的裁判文本分类比较研究

    Comparative study on Judgment Text Classification for Transformer Based Models. (arXiv:2306.01739v1 [cs.CL])

    [http://arxiv.org/abs/2306.01739](http://arxiv.org/abs/2306.01739)

    本研究对6个不同的基于自我注意力的Transformer模型进行了比较研究，并针对4种激活函数进行了调整，以用于判决文本分类。该方法可以帮助在法律诉讼中进行引用和先例参考。

    

    本研究利用各种自然语言处理模型，通过从判决文书中提取和摘要文本来预测特定判决的获胜者。这些文档在法律诉讼中非常有用。其中一个优点是，这些文档可用于引用和先例参考，这使得使用者可以更有力地为其案件辩护。当涉及到案例先例时，必须参考大量文档，以收集与该案件有关的法律要点。然而，由于文档的复杂词汇结构和文档大小，审查这些文档需要花费很长时间进行分析。本文涉及在4种不同激活函数下调整 6 种自我注意力的基于 Transformer 的模型，并研究它们在训练了 200 个判决上的表现，以及根据不同基准参数评估其结果。

    This work involves the usage of various NLP models to predict the winner of a particular judgment by the means of text extraction and summarization from a judgment document. These documents are useful when it comes to legal proceedings. One such advantage is that these can be used for citations and precedence reference in Lawsuits and cases which makes a strong argument for their case by the ones using it. When it comes to precedence, it is necessary to refer to an ample number of documents in order to collect legal points with respect to the case. However, reviewing these documents takes a long time to analyze due to the complex word structure and the size of the document. This work involves the comparative study of 6 different self-attention-based transformer models and how they perform when they are being tweaked in 4 different activation functions. These models which are trained with 200 judgement contexts and their results are being judged based on different benchmark parameters. 
    
[^37]: 带有重尾奖励的差分隐私式情节强化学习

    Differentially Private Episodic Reinforcement Learning with Heavy-tailed Rewards. (arXiv:2306.01121v1 [cs.LG])

    [http://arxiv.org/abs/2306.01121](http://arxiv.org/abs/2306.01121)

    本研究针对重尾奖励的有限步骤表格马尔可夫决策过程问题探讨了差分隐私限制下的两种框架，即价值迭代和策略优化，同时考虑了联合差分隐私和本地差分隐私模型，并为两种情况提供了遗憾上限。

    

    本文研究了差分隐私(DP)限制下的重尾奖励的（有限步骤表格）马尔可夫决策过程(MDP)问题。与先前的私有强化学习研究通常假设奖励来自一些有界或次高斯分布以确保DP相比，我们考虑奖励分布只有有限的$(1+v)$阶矩的情况，$v \in (0,1]$。通过使用奖励的健壮均值估计器，我们首先提出了两种针对重尾MDP的框架，即一个用于价值迭代，另一个用于策略优化。在每个框架下，我们考虑了联合差分隐私(JDP)和本地差分隐私(LDP)模型。基于我们的框架，我们为JDP和LDP情况提供了遗憾上限，并表明分布的矩和隐私预算都对遗憾有重要影响。最后，我们建立了遗憾最小化的下限。

    In this paper, we study the problem of (finite horizon tabular) Markov decision processes (MDPs) with heavy-tailed rewards under the constraint of differential privacy (DP). Compared with the previous studies for private reinforcement learning that typically assume rewards are sampled from some bounded or sub-Gaussian distributions to ensure DP, we consider the setting where reward distributions have only finite $(1+v)$-th moments with some $v \in (0,1]$. By resorting to robust mean estimators for rewards, we first propose two frameworks for heavy-tailed MDPs, i.e., one is for value iteration and another is for policy optimization. Under each framework, we consider both joint differential privacy (JDP) and local differential privacy (LDP) models. Based on our frameworks, we provide regret upper bounds for both JDP and LDP cases and show that the moment of distribution and privacy budget both have significant impacts on regrets. Finally, we establish a lower bound of regret minimization
    
[^38]: STEVE-1: 一个用于Minecraft中文本-行为生成的生成模型

    STEVE-1: A Generative Model for Text-to-Behavior in Minecraft. (arXiv:2306.00937v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2306.00937](http://arxiv.org/abs/2306.00937)

    STEVE-1 是一种新的生成模型，能够在Minecraft中跟随各种短期开放型文本和视觉指令。STEVE-1利用预先训练的模型和最佳实践，通过自监督的行为克隆和回顾重新标记来微调，避免了昂贵的人工注释。

    

    建立对文本指令做出响应的AI模型对于连续性决策任务来说是具有挑战性的。本文介绍了一种名为STEVE-1的Minecraft指令调整型视频预训练模型，展示了DALL-E 2中使用的unCLIP方法也对创建指令跟随连续决策代理非常有效。STEVE-1分为两个步骤进行训练：首先是将预先训练的VPT模型适应MineCLIP的潜在空间中的指令，然后训练一个先验模型以从文本预测潜在代码。这使我们能够通过自监督的行为克隆和回顾重新标记来微调VPT，避免需要昂贵的人工文本注释。通过利用VPT和MineCLIP等预先训练的模型，并采用文本条件的图像生成的最佳实践，STEVE-1的训练成本仅为60美元，并且可以在Minecraft中遵循各种短期开放型文本和视觉指令。STEVE-1为开放的指令跟随连续决策代理设定了一个新的标准。

    Constructing AI models that respond to text instructions is challenging, especially for sequential decision-making tasks. This work introduces an instruction-tuned Video Pretraining (VPT) model for Minecraft called STEVE-1, demonstrating that the unCLIP approach, utilized in DALL-E 2, is also effective for creating instruction-following sequential decision-making agents. STEVE-1 is trained in two steps: adapting the pretrained VPT model to follow commands in MineCLIP's latent space, then training a prior to predict latent codes from text. This allows us to finetune VPT through self-supervised behavioral cloning and hindsight relabeling, bypassing the need for costly human text annotations. By leveraging pretrained models like VPT and MineCLIP and employing best practices from text-conditioned image generation, STEVE-1 costs just $60 to train and can follow a wide range of short-horizon open-ended text and visual instructions in Minecraft. STEVE-1 sets a new bar for open-ended instructi
    
[^39]: “不确定性感知的非似然学习提高生成式情感四元组预测”

    Uncertainty-Aware Unlikelihood Learning Improves Generative Aspect Sentiment Quad Prediction. (arXiv:2306.00418v1 [cs.CL])

    [http://arxiv.org/abs/2306.00418](http://arxiv.org/abs/2306.00418)

    本文提出了一种新的方法来控制标记级的生成、提高原始学习和减少错误，其中包括蒙特卡洛dropout、边缘非似然学习和最小化熵。在四个公共数据集上的广泛实验表明，该方法有效地提高了情感四元组预测的性能。

    

    最近，基于方面的情感分析领域广泛关注了情感四元组预测。现有的研究通过预训练的生成式语言模型提取出四元组，将原始句子转化为模板化的目标序列。然而，以前的研究只关注生成什么，而忽略了不需要生成的内容。我们认为考虑负样本也会带来潜在的好处。本文提出了一种模板无关的方法来控制标记级的生成，同时提高原始学习和减少错误。具体来说，我们引入了蒙特卡洛dropout来理解预训练语言模型的内置不确定性，获取噪声和错误信息。我们进一步提出边缘非似然学习来抑制不确定性感知的错误标记。最后，我们引入了最小化熵来平衡边缘非似然学习的影响。在四个公共数据集上的广泛实验表明，我们提出的方法在提高情感四元组预测的性能方面是有效的。

    Recently, aspect sentiment quad prediction has received widespread attention in the field of aspect-based sentiment analysis. Existing studies extract quadruplets via pre-trained generative language models to paraphrase the original sentence into a templated target sequence. However, previous works only focus on what to generate but ignore what not to generate. We argue that considering the negative samples also leads to potential benefits. In this work, we propose a template-agnostic method to control the token-level generation, which boosts original learning and reduces mistakes simultaneously. Specifically, we introduce Monte Carlo dropout to understand the built-in uncertainty of pre-trained language models, acquiring the noises and errors. We further propose marginalized unlikelihood learning to suppress the uncertainty-aware mistake tokens. Finally, we introduce minimization entropy to balance the effects of marginalized unlikelihood learning. Extensive experiments on four public
    
[^40]: BetaZero：基于学习的近似算法的置信状态规划用于长时间跨度的POMDPs

    BetaZero: Belief-State Planning for Long-Horizon POMDPs using Learned Approximations. (arXiv:2306.00249v1 [cs.AI])

    [http://arxiv.org/abs/2306.00249](http://arxiv.org/abs/2306.00249)

    本文提出了一种叫做BetaZero的方法，它是一种使用学习近似算法的置信状态规划算法，可以用于解决长时间跨度的POMDP问题。

    

    实际的规划问题，包括自动驾驶、碳储存和资源勘探等可持续能源应用，最近被建模为部分观测马尔可夫决策过程（POMDPs）并使用近似方法解决。为了在实践中解决高维度POMDPs，最先进的方法使用了问题特定的启发式算法进行在线规划，以减少规划时间跨度并使问题易于解决。最近成功地在完全可观察的领域中找到了用于替换启发式算法的学习近似算法。关键洞见是将在线蒙特卡罗树搜索与离线神经网络近似相结合，以优化策略和值函数。本文将这一洞见应用到了部分观察域，并提出了BetaZero，一种适用于POMDP的置信状态规划算法。

    Real-world planning problems$\unicode{x2014}$including autonomous driving and sustainable energy applications like carbon storage and resource exploration$\unicode{x2014}$have recently been modeled as partially observable Markov decision processes (POMDPs) and solved using approximate methods. To solve high-dimensional POMDPs in practice, state-of-the-art methods use online planning with problem-specific heuristics to reduce planning horizons and make the problems tractable. Algorithms that learn approximations to replace heuristics have recently found success in large-scale problems in the fully observable domain. The key insight is the combination of online Monte Carlo tree search with offline neural network approximations of the optimal policy and value function. In this work, we bring this insight to partially observed domains and propose BetaZero, a belief-state planning algorithm for POMDPs. BetaZero learns offline approximations based on accurate belief models to enable online d
    
[^41]: 加拿大农田数据集：用于农业多时相深度学习分类的新地表覆盖数据集

    The Canadian Cropland Dataset: A New Land Cover Dataset for Multitemporal Deep Learning Classification in Agriculture. (arXiv:2306.00114v1 [cs.CV])

    [http://arxiv.org/abs/2306.00114](http://arxiv.org/abs/2306.00114)

    该论文提出了一个时间补丁数据集，包含了加拿大农田的多时相遥感影像。该数据集是手动经过确认和筛选的高分辨率地理参考图像，覆盖四个农作物生产年度和五个月份。这个数据集可以用于提高土地覆盖分类的准确性。

    

    利用遥感监测土地覆盖是研究环境变化和通过粮食产量预测确保全球粮食安全的关键。尤其是，多时相遥感影像提供了关于场景动态的相关信息，已经被证明可以带来更好的土地覆盖分类结果。然而，由于难以获取可靠、细粒度和高质量的注释样本支持他们的假设，很少有研究受益于高空间和时间分辨率数据。因此，我们介绍了一个加拿大农田的时间补丁数据集，其中包含了来自10个农作物类别的78,536个手动经过确认和筛选的高分辨率(10米/像素，640 x 640米)地理参考图像，覆盖了四个农作物生产年度(2017-2020)和五个月份(六月-十月)。每个实例都包含12个光谱波段、一张RGB图像和额外的植被指数计算。

    Monitoring land cover using remote sensing is vital for studying environmental changes and ensuring global food security through crop yield forecasting. Specifically, multitemporal remote sensing imagery provides relevant information about the dynamics of a scene, which has proven to lead to better land cover classification results. Nevertheless, few studies have benefited from high spatial and temporal resolution data due to the difficulty of accessing reliable, fine-grained and high-quality annotated samples to support their hypotheses. Therefore, we introduce a temporal patch-based dataset of Canadian croplands, enriched with labels retrieved from the Canadian Annual Crop Inventory. The dataset contains 78,536 manually verified and curated high-resolution (10 m/pixel, 640 x 640 m) geo-referenced images from 10 crop classes collected over four crop production years (2017-2020) and five months (June-October). Each instance contains 12 spectral bands, an RGB image, and additional veget
    
[^42]: AI图像和Overton Window

    AI Imagery and the Overton Window. (arXiv:2306.00080v1 [cs.CY])

    [http://arxiv.org/abs/2306.00080](http://arxiv.org/abs/2306.00080)

    基于人工智能的文本到图像生成技术的快速增长让手工艺术品和AI生成图像区分日渐困难。然而提高人类生活和工作标准以及利用一群人来充实另一群人之间寻求平衡是关键。该领域面临着被AI基础设施接管的风险，同时存在身份盗窃、数据洗白等问题。

    

    基于人工智能的文本到图像生成在过去一年中在视觉综合和美学形象的生产方面取得了重大进步，到了区分手工艺术品和AI生成的图像愈发困难的地步。例如稳态扩散、Midjourney等生成模型有望在技术和伦理方面影响几个主要行业。在提高人类生活和工作标准以及利用一群人来充实另一群人之间寻求平衡是讨论的复杂和关键部分。由于这种技术的快速增长、模型运行方式和灰色法律的存在，包括视频游戏行业在内的视觉和艺术领域面临被AI基础设施所有者接管的风险。该文章是一篇文献综述，探讨了当今AI开发者和用户面临的问题，包括身份盗窃、数据洗白等。

    AI-based text-to-image generation has undergone a significant leap in the production of visually comprehensive and aesthetic imagery over the past year, to the point where differentiating between a man-made piece of art and an AI-generated image is becoming more difficult. Generative Models such as Stable Diffusion, Midjourney and others are expected to affect several major industries in technological and ethical aspects. Striking the balance between raising human standard of life and work vs exploiting one group of people to enrich another is a complex and crucial part of the discussion. Due to the rapid growth of this technology, the way in which its models operate, and gray area legalities, visual and artistic domains - including the video game industry, are at risk of being taken over from creators by AI infrastructure owners. This paper is a literature review examining the concerns facing both AI developers and users today, including identity theft, data laundering and more. It di
    
[^43]: 基于人工智能的交通预测：近期进展与新机遇综述

    Traffic Prediction using Artificial Intelligence: Review of Recent Advances and Emerging Opportunities. (arXiv:2305.19591v1 [cs.LG])

    [http://arxiv.org/abs/2305.19591](http://arxiv.org/abs/2305.19591)

    该论文综述了交通预测方法的发展，重点介绍了基于人工智能的交通预测方法在多元交通时间序列模型研究方面的进展和机遇。

    

    交通预测在缓解全球性的交通拥堵问题中起着关键作用，其负面影响包括额外旅行时间的损失和燃料消耗的增加。将新兴技术融入交通系统可以显著改善交通预测，并带来新的研究问题。为了了解交通预测中的开放性研究挑战，本综述旨在提供交通预测方法的综合概述。具体而言，我们侧重于基于人工智能（AI）的交通预测方法在多变量交通时间序列建模方面的近期进展和新的研究机遇，这是由于近年来这类方法在交通预测中具有潜在的成功和潜力。

    Traffic prediction plays a crucial role in alleviating traffic congestion which represents a critical problem globally, resulting in negative consequences such as lost hours of additional travel time and increased fuel consumption. Integrating emerging technologies into transportation systems provides opportunities for improving traffic prediction significantly and brings about new research problems. In order to lay the foundation for understanding the open research challenges in traffic prediction, this survey aims to provide a comprehensive overview of traffic prediction methodologies. Specifically, we focus on the recent advances and emerging research opportunities in Artificial Intelligence (AI)-based traffic prediction methods, due to their recent success and potential in traffic prediction, with an emphasis on multivariate traffic time series modeling. We first provide a list and explanation of the various data types and resources used in the literature. Next, the essential data 
    
[^44]: Spotlight Attention: 具备空间局部性先验的鲁棒目标中心学习

    Spotlight Attention: Robust Object-Centric Learning With a Spatial Locality Prior. (arXiv:2305.19550v1 [cs.CV])

    [http://arxiv.org/abs/2305.19550](http://arxiv.org/abs/2305.19550)

    该论文提出了一个新的目标中心学习方法，通过加入空间局部性先验来提高模型的鲁棒性，使模型在合成和真实数据上实现了显著的物体分割改进，并且对模型超参数不太敏感。

    

    目标中心视觉的目的是构建场景中物体的显式表示。这种表示是通过一组可互换的模块(称为slot或对象文件)获得的，它们竞争图像的局部补丁。该竞争具有弱感性偏差，以保持空间连续性;因此，一个slot可能会宣称在整个图像中散布的补丁。与此相反，人类视觉的感性偏差很强，到了注意力经典用聚光灯比喻的程度。我们将空间局部性先验融入现代目标中心视觉模型，从而在合成和真实数据集中获得显着的物体分割改进。类似于人类视觉注意力，图像内容和空间约束的组合产生了具有鲁棒性的无监督目标中心学习，包括对模型超参数不太敏感。

    The aim of object-centric vision is to construct an explicit representation of the objects in a scene. This representation is obtained via a set of interchangeable modules called \emph{slots} or \emph{object files} that compete for local patches of an image. The competition has a weak inductive bias to preserve spatial continuity; consequently, one slot may claim patches scattered diffusely throughout the image. In contrast, the inductive bias of human vision is strong, to the degree that attention has classically been described with a spotlight metaphor. We incorporate a spatial-locality prior into state-of-the-art object-centric vision models and obtain significant improvements in segmenting objects in both synthetic and real-world datasets. Similar to human visual attention, the combination of image content and spatial constraints yield robust unsupervised object-centric learning, including less sensitivity to model hyperparameters.
    
[^45]: 标准比评分更重要：面向多准则推荐的标准偏好感知轻量图卷积网络

    Criteria Tell You More than Ratings: Criteria Preference-Aware Light Graph Convolution for Effective Multi-Criteria Recommendation. (arXiv:2305.18885v2 [cs.SI] UPDATED)

    [http://arxiv.org/abs/2305.18885](http://arxiv.org/abs/2305.18885)

    本文提出了一种面向多准则推荐的标准偏好感知轻量图卷积网络，该方法结合了MC扩展图，可以准确地捕捉用户的标准偏好，并进一步将用户对各个标准的偏好合并到最终的推荐列表中。

    

    多准则推荐系统现在在广泛的电子商务领域中利用多准则 (MC) 评分信息，而深度学习中的图神经网络 (GNN) 已经被广泛应用于各种推荐系统的开发中。在这种情况下，本文首次尝试使用GNN辅助设计MC推荐系统。具体而言，我们提出了一种新颖的标准偏好感知轻量图卷积方法(CPA-LGC),可以准确捕捉用户的标准偏好以及复杂高阶连接中的协作信号。本文在MC扩展图上构建了一个能够将用户-物品MC评分转换为扩展二分图的MC扩展图，再进一步将标准重要性编码到图卷积过程中，并引入了一种新的标准偏好感知聚合方法来将用户对不同标准的偏好合并到最终的推荐列表中。

    The multi-criteria (MC) recommender system, which leverages MC rating information in a wide range of e-commerce areas, is ubiquitous nowadays. Surprisingly, although graph neural networks (GNNs) have been widely applied to develop various recommender systems due to GNN's high expressive capability in learning graph representations, it has been still unexplored how to design MC recommender systems with GNNs. In light of this, we make the first attempt towards designing a GNN-aided MC recommender system. Specifically, rather than straightforwardly adopting existing GNN-based recommendation methods, we devise a novel criteria preference-aware light graph convolution CPA-LGC method, which is capable of precisely capturing the criteria preference of users as well as the collaborative signal in complex high-order connectivities. To this end, we first construct an MC expansion graph that transforms user--item MC ratings into an expanded bipartite graph to potentially learn from the collaborat
    
[^46]: 基准数据集上 ChatGPT 的系统研究和全面评估

    A Systematic Study and Comprehensive Evaluation of ChatGPT on Benchmark Datasets. (arXiv:2305.18486v1 [cs.CL])

    [http://arxiv.org/abs/2305.18486](http://arxiv.org/abs/2305.18486)

    本文对基准数据集上 ChatGPT 的性能进行了全面的评估，包括问答、文本摘要、代码生成、常识推理、数学问题求解、机器翻译、偏见检测和伦理考虑等任务。研究旨在验证 ChatGPT 的优势和弱点，并为使用语言模型的未来研究提供见解。

    

    最近，如 ChatGPT 这样的大型语言模型（LLM）的开发引起了很多关注。然而，由于难以将该模型生成的产出与基本事实进行比较，因此其在基准学术数据集上的评估仍未充分探索。本文旨在对 ChatGPT 在包括问答、文本摘要、代码生成、常识推理、数学问题求解、机器翻译、偏见检测和伦理考虑等任务中的表现进行彻底评估。具体而言，我们在 140 个任务中评估了 ChatGPT，并分析了其在这些数据集中生成的 255K 次响应，这使我们的工作成为了在 NLP 基准测试中对 ChatGPT 进行的最大评估。简而言之，我们的研究旨在验证 ChatGPT 在各种任务中的优势和弱点，并为使用 LLM 的未来研究提供见解。我们还报告了一种新的迸发能力，即遵循多个查询指令。

    The development of large language models (LLMs) such as ChatGPT has brought a lot of attention recently. However, their evaluation in the benchmark academic datasets remains under-explored due to the difficulty of evaluating the generative outputs produced by this model against the ground truth. In this paper, we aim to present a thorough evaluation of ChatGPT's performance on diverse academic datasets, covering tasks like question-answering, text summarization, code generation, commonsense reasoning, mathematical problem-solving, machine translation, bias detection, and ethical considerations. Specifically, we evaluate ChatGPT across 140 tasks and analyze 255K responses it generates in these datasets. This makes our work the largest evaluation of ChatGPT in NLP benchmarks. In short, our study aims to validate the strengths and weaknesses of ChatGPT in various tasks and provide insights for future research using LLMs. We also report a new emergent ability to follow multi-query instruct
    
[^47]: 超越元数据：利用游戏设计参数进行跨版本电子竞技分析

    Beyond the Meta: Leveraging Game Design Parameters for Patch-Agnostic Esport Analytics. (arXiv:2305.18477v1 [cs.LG])

    [http://arxiv.org/abs/2305.18477](http://arxiv.org/abs/2305.18477)

    本论文提出了一种新的跨版本的电子竞技分析方法，通过利用游戏设计参数并利用聚类技术创建角色表征形式来解决传统方法短寿命的问题。以Dota 2为例验证了这种方法，取得了显著的性能提升。

    

    电子竞技游戏是全球游戏市场的重要组成部分，并且是增长最快的游戏细分领域。这导致了电子竞技分析的领域产生，其使用游戏提取的遥测数据来为玩家、教练、播音员和其他利益相关者提供信息。与传统的体育比赛相比，电子竞技游戏的机制和规则经常发生快速变化。由于游戏参数的频繁更改，电子竞技分析模型的使用寿命可能很短，这在文献中很大程度上被忽略了。本文提取游戏设计信息（即补丁说明），利用聚类技术提出了一种新的角色表征形式。以Dota 2游戏中击杀次数的预测为案例，利用这种创新的角色表征技术训练了一个神经网络模型。然后将此模型的性能与包括常规技术在内的两个不同基线进行了评估。这个模型不仅达到了显著的表现水平，还克服了电子竞技游戏中版本更迭的困境。

    Esport games comprise a sizeable fraction of the global games market, and is the fastest growing segment in games. This has given rise to the domain of esports analytics, which uses telemetry data from games to inform players, coaches, broadcasters and other stakeholders. Compared to traditional sports, esport titles change rapidly, in terms of mechanics as well as rules. Due to these frequent changes to the parameters of the game, esport analytics models can have a short life-spam, a problem which is largely ignored within the literature. This paper extracts information from game design (i.e. patch notes) and utilises clustering techniques to propose a new form of character representation. As a case study, a neural network model is trained to predict the number of kills in a Dota 2 match utilising this novel character representation technique. The performance of this model is then evaluated against two distinct baselines, including conventional techniques. Not only did the model signi
    
[^48]: 基于稀疏提示的元策略网络中的持续任务分配

    Continual Task Allocation in Meta-Policy Network via Sparse Prompting. (arXiv:2305.18444v1 [cs.LG])

    [http://arxiv.org/abs/2305.18444](http://arxiv.org/abs/2305.18444)

    本文提出的CoTASP可以通过学习过完备字典来生成稀疏掩码作为提示，从而从元策略网络中提取与每个任务相关的子网络，实现了快速适应新任务，同时保留了之前任务的共同知识。

    

    如何通过不断学习一系列任务来训练一个具有一般化能力的元策略，是当前强化学习面临的挑战。本文提出了一种名为“连续任务分配的稀疏提示（CoTASP）”的解决方案，通过学习过完备字典来生成稀疏掩码作为提示，从元策略网络中提取与每个任务相关的子网络。通过交替优化子网络和提示，CoTASP更新了元策略，通过训练特定于任务的策略来实现。然后更新字典，以使优化后的提示与任务嵌入相匹配，从而捕捉其语义相关性。因此，相关任务通过相似的提示在元策略网络中共享更多的神经元，而跨任务干扰导致遗忘被有效地约束。给定经过训练的元策略和更新后的字典，我们可以通过推导相应的提示来迅速适应新任务，从而从元策略中提取相关的子网络。我们在一组导航任务上评估了CoTASP，并展示了它在任务完成度、样本效率和泛化能力方面优于现有的基线方法。

    How to train a generalizable meta-policy by continually learning a sequence of tasks? It is a natural human skill yet challenging to achieve by current reinforcement learning: the agent is expected to quickly adapt to new tasks (plasticity) meanwhile retaining the common knowledge from previous tasks (stability). We address it by "Continual Task Allocation via Sparse Prompting (CoTASP)", which learns over-complete dictionaries to produce sparse masks as prompts extracting a sub-network for each task from a meta-policy network. By optimizing the sub-network and prompts alternatively, CoTASP updates the meta-policy via training a task-specific policy. The dictionary is then updated to align the optimized prompts with tasks' embedding, thereby capturing their semantic correlations. Hence, relevant tasks share more neurons in the meta-policy network via similar prompts while cross-task interference causing forgetting is effectively restrained. Given a trained meta-policy with updated dicti
    
[^49]: 基于预先训练语言模型的情境类比推理研究

    In-Context Analogical Reasoning with Pre-Trained Language Models. (arXiv:2305.17626v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2305.17626](http://arxiv.org/abs/2305.17626)

    本研究提出了一种基于语言模型的情境类比推理方法，通过将问题的感知特征编码成语言形式，能够实现高效的零-shot关系推理，超越传统方法和人类水平。

    

    类比推理是人类认知的基本能力之一，可以通过将新的情况与过去的经验关联来进行抽象推理。虽然它被认为对于AI系统的强大推理至关重要，但传统方法需要进行大量的训练和/或固化特定的领域知识才能应用于基准任务中。受到认知科学研究发现人类语言与类比制作之间的联系的启发，我们探索使用直观的基于语言的抽象来支持人工智能系统中的类比。具体而言，我们使用大型预先训练的语言模型（PLMs）对视觉Raven的渐进矩阵（RPM）进行类比推理。通过将问题的感知特征简单地编码成语言形式，我们发现PLMs表现出了惊人的零-shot关系推理能力，超过了人类表现并接近于受监督的基于视觉的方法。我们探索了不同的编码方法，以变化抽象的水平。

    Analogical reasoning is a fundamental capacity of human cognition that allows us to reason abstractly about novel situations by relating them to past experiences. While it is thought to be essential for robust reasoning in AI systems, conventional approaches require significant training and/or hard-coding of domain knowledge to be applied to benchmark tasks. Inspired by cognitive science research that has found connections between human language and analogy-making, we explore the use of intuitive language-based abstractions to support analogy in AI systems. Specifically, we apply large pre-trained language models (PLMs) to visual Raven's Progressive Matrices (RPM), a common relational reasoning test. By simply encoding the perceptual features of the problem into language form, we find that PLMs exhibit a striking capacity for zero-shot relational reasoning, exceeding human performance and nearing supervised vision-based methods. We explore different encodings that vary the level of abs
    
[^50]: 检测大型语言模型编辑失败：一个改进的特异性基准测试

    Detecting Edit Failures In Large Language Models: An Improved Specificity Benchmark. (arXiv:2305.17553v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.17553](http://arxiv.org/abs/2305.17553)

    该论文探讨了大型语言模型编辑技术的现状，发现现有的特异性基准测试难以检测到不良副作用，并提出了一个改进的基准测试，该测试可以检测到动态组件，并通过基于KL散度的指标扩展了特异性的衡量方式。研究发现最近的模型编辑技术特异性较低，强调了改进特异性基准测试的重要性。

    

    最近的模型编辑技术承诺在LLM训练过程中减轻记忆错误或过时关联的问题。然而，我们展示了这些技术可能会引入大量未被现有特异性基准测试检测到的不良副作用。我们扩展了现有的CounterFact基准测试以包括动态组件，并将我们的基准测试称为CounterFact+。此外，我们通过一个基于KL散度的本质指标扩展了用于衡量特异性的指标。我们使用这个改进的基准测试来评估最近的模型编辑技术，发现它们的特异性较低。我们的发现凸显了需要改进特异性基准测试以识别和预防不良副作用的重要性。

    Recent model editing techniques promise to mitigate the problem of memorizing false or outdated associations during LLM training. However, we show that these techniques can introduce large unwanted side effects which are not detected by existing specificity benchmarks. We extend the existing CounterFact benchmark to include a dynamic component and dub our benchmark CounterFact+. Additionally, we extend the metrics used for measuring specificity by a principled KL divergence-based metric. We use this improved benchmark to evaluate recent model editing techniques and find that they suffer from low specificity. Our findings highlight the need for improved specificity benchmarks that identify and prevent unwanted side effects.
    
[^51]: 使用场景图记忆建模动态环境

    Modeling Dynamic Environments with Scene Graph Memory. (arXiv:2305.17537v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2305.17537](http://arxiv.org/abs/2305.17537)

    本论文提出了一种新的场景图记忆状态表示，结合节点边缘预测器（NEP）的神经网络架构，能够帮助具有行动能力的AI代理在部分可观察动态场景中高效搜索。

    

    在大型环境中，如居室等，寻找物品的具有行动能力的AI代理需要基于部分信息预测物品位置来做出有效决策。我们将其形式化为一种新类型的链路预测问题：部分可观察动态图上的链路预测。我们的图表达了一个场景，其中房间和物品是节点，在边缘中编码它们之间的关系；在每个时间步骤上，代理人仅知道更改图的部分。这种部分可观测性对于现有的链路预测方法构成了挑战，我们进行了解决。我们提出了一种新颖的状态表示 - 场景图记忆（SGM） - 其中包括代理人的累积观察集合，以及一种名为节点边缘预测器（NEP）的神经网络架构，该架构从SGM中提取信息以进行高效搜索。我们在动态房屋模拟器中评估了我们的方法，这是一个新的基准，它按照语义模式创建不同的动态图形。

    Embodied AI agents that search for objects in large environments such as households often need to make efficient decisions by predicting object locations based on partial information. We pose this as a new type of link prediction problem: link prediction on partially observable dynamic graphs. Our graph is a representation of a scene in which rooms and objects are nodes, and their relationships are encoded in the edges; only parts of the changing graph are known to the agent at each timestep. This partial observability poses a challenge to existing link prediction approaches, which we address. We propose a novel state representation -- Scene Graph Memory (SGM) -- with captures the agent's accumulated set of observations, as well as a neural net architecture called a Node Edge Predictor (NEP) that extracts information from the SGM to search efficiently. We evaluate our method in the Dynamic House Simulator, a new benchmark that creates diverse dynamic graphs following the semantic patte
    
[^52]: 在口语问答中通过语义重构来回答未回答的问题

    Answering Unanswered Questions through Semantic Reformulations in Spoken QA. (arXiv:2305.17393v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.17393](http://arxiv.org/abs/2305.17393)

    本研究提出了语义问答重构模型 (SURF)，通过三个基于语言学的操作来重写口语问答中存在的词汇、命题、句法和特异性等问题，提高了回答率，能够帮助语音助手更好地回答未回答的问题。

    

    口语问答是语音助手的一个重要功能，通常由多个问答系统支持。用户通过自然语音询问问题，可能包含不流畅、错误和非正式的语法或措辞。这是问答系统的一个主要挑战，导致未回答的问题或无关的答案，并导致用户体验差。我们分析了未成功回答的问答请求，以确定核心挑战：词汇差距、命题类型、复杂的句法结构和高特异性。我们提出了一个语义问答重构模型 (SURF)，提供三个基于语言学的操作 (修复、句法重塑、概括) 来重写问题以便于回答。离线评估来自领先语音助手的 100 万个未回答的问题，结果显示 SURF 显著提高了回答率：高达 24% 的问题获得了相关答案 (75%)。实时部署显示出对数百万有未回答的问题的客户产生了积极的影响。

    Spoken Question Answering (QA) is a key feature of voice assistants, usually backed by multiple QA systems. Users ask questions via spontaneous speech which can contain disfluencies, errors, and informal syntax or phrasing. This is a major challenge in QA, causing unanswered questions or irrelevant answers, and leading to bad user experiences. We analyze failed QA requests to identify core challenges: lexical gaps, proposition types, complex syntactic structure, and high specificity. We propose a Semantic Question Reformulation (SURF) model offering three linguistically-grounded operations (repair, syntactic reshaping, generalization) to rewrite questions to facilitate answering. Offline evaluation on 1M unanswered questions from a leading voice assistant shows that SURF significantly improves answer rates: up to 24% of previously unanswered questions obtain relevant answers (75%). Live deployment shows positive impact for millions of customers with unanswered questions; explicit relev
    
[^53]: 不确定非凸环境中的凸风险有界连续时间轨迹规划和管道设计

    Convex Risk Bounded Continuous-Time Trajectory Planning and Tube Design in Uncertain Nonconvex Environments. (arXiv:2305.17291v1 [cs.AI])

    [http://arxiv.org/abs/2305.17291](http://arxiv.org/abs/2305.17291)

    本文提出一种针对含有不确定性障碍物的非凸环境中的轨迹规划问题的解决方案，即通过风险轮廓的概念将风险有界轨迹规划问题转化为确定性优化问题。

    

    本文针对含有具有概率位置、大小和几何形状的障碍物的不确定非凸静态和动态环境中的轨迹规划问题进行了研究。为了解决这个问题，我们提供了一种带有有界风险的轨迹规划方法，该方法寻找规划时间范围内保证有界风险的连续时间轨迹。风险被定义为与不确定障碍物碰撞的概率。现有的解决风险有界轨迹规划问题的方法要么仅限于高斯不确定性和凸障碍物，要么依赖于需要不确定性样本和时间离散化的基于采样的方法。为了解决风险有界轨迹规划问题，我们利用风险轮廓的概念将风险有界轨迹规划问题转化为确定性优化问题。风险轮廓是在不确定环境中所有具有保证有界风险的点的集合。

    In this paper, we address the trajectory planning problem in uncertain nonconvex static and dynamic environments that contain obstacles with probabilistic location, size, and geometry. To address this problem, we provide a risk bounded trajectory planning method that looks for continuous-time trajectories with guaranteed bounded risk over the planning time horizon. Risk is defined as the probability of collision with uncertain obstacles. Existing approaches to address risk bounded trajectory planning problems either are limited to Gaussian uncertainties and convex obstacles or rely on sampling-based methods that need uncertainty samples and time discretization. To address the risk bounded trajectory planning problem, we leverage the notion of risk contours to transform the risk bounded planning problem into a deterministic optimization problem. Risk contours are the set of all points in the uncertain environment with guaranteed bounded risk. The obtained deterministic optimization is, 
    
[^54]: 无监督神经机器翻译的复制问题：具有语言鉴别器损失的训练计划

    On the Copying Problem of Unsupervised NMT: A Training Schedule with a Language Discriminator Loss. (arXiv:2305.17182v1 [cs.CL])

    [http://arxiv.org/abs/2305.17182](http://arxiv.org/abs/2305.17182)

    无监督NMT中的复制问题通常发生在远距离语种对中且会直接复制输入句子的部分作为翻译，本研究提出了一种包含语言鉴别器损失的训练计划来缓解该问题，并提高低资源语种的翻译性能。

    

    虽然无监督神经机器翻译已在许多语种间得到成功，但复制问题（即将输入句子的某些部分直接复制作为翻译）在远距离语种对中很常见，尤其涉及低资源语种。我们发现这个问题与在线回译（BT）期间出现的预期复制行为密切相关。在这项工作中，我们提出了一个简单但有效的训练计划，它包含了一个语言鉴别器的损失函数。该损失施加约束于中间翻译，以使翻译是所需的语言。通过在不同语言对、 包括相似和远距离、高资源和低资源语言的广泛实验中，我们发现我们的方法缓解了复制问题，从而提高了对低资源语言的翻译性能。

    Although unsupervised neural machine translation (UNMT) has achieved success in many language pairs, the copying problem, i.e., directly copying some parts of the input sentence as the translation, is common among distant language pairs, especially when low-resource languages are involved. We find this issue is closely related to an unexpected copying behavior during online back-translation (BT). In this work, we propose a simple but effective training schedule that incorporates a language discriminator loss. The loss imposes constraints on the intermediate translation so that the translation is in the desired language. By conducting extensive experiments on different language pairs, including similar and distant, high and low-resource languages, we find that our method alleviates the copying problem, thus improving the translation performance on low-resource languages.
    
[^55]: 基于信任感知的连接和自主车辆的鲁棒控制与协调

    Trust-Aware Resilient Control and Coordination of Connected and Automated Vehicles. (arXiv:2305.16818v1 [cs.MA])

    [http://arxiv.org/abs/2305.16818](http://arxiv.org/abs/2305.16818)

    本文提出了一种基于信任框架的鲁棒控制和协调方案，从恶意代理的角度识别关键对抗目标，有效避免碰撞和交通堵塞。同时提出了一种使用信任框架的攻击检测和缓解措施。

    

    安全对于网络连接和自主车辆（CAV）等物理系统至关重要，这些车辆通过协作安全地通过道路网络。本文从不配合/恶意代理人的角度识别关键对抗性目标（如碰撞和交通堵塞），利用信任框架提出了鲁棒的控制与协调方案，以缓解恶意代理带来的影响并保证安全协调。我们使用 Sybil 攻击验证了建议的框架，同时提出了一种使用信任框架的攻击检测和缓解措施。

    Security is crucial for cyber-physical systems, such as a network of Connected and Automated Vehicles (CAVs) cooperating to navigate through a road network safely. In this paper, we tackle the security of a cooperating network of CAVs in conflict areas by identifying the critical adversarial objectives from the point of view of uncooperative/malicious agents from our preliminary study, which are (i) safety violations resulting in collisions, and (ii) traffic jams. We utilize a trust framework (and our work doesn't depend on the specific choice of trust/reputation framework) to propose a resilient control and coordination framework that mitigates the effects of such agents and guarantees safe coordination. A class of attacks that can be used to achieve the adversarial objectives is Sybil attacks, which we use to validate our proposed framework through simulation studies. Besides that, we propose an attack detection and mitigation scheme using the trust framework. The simulation results 
    
[^56]: 人人可复现的NLP研究：初学者的需求调查

    NLP Reproducibility For All: Understanding Experiences of Beginners. (arXiv:2305.16579v1 [cs.CL])

    [http://arxiv.org/abs/2305.16579](http://arxiv.org/abs/2305.16579)

    通过对93名NLP初学者的调查，发现研究作者提供完整文档、更好的代码实践和更易于获取的数据文件是初学者成功复现最近NLP论文结果的关键，建议NLP研究人员注重这些方面，更好地支持初学者。

    

    随着自然语言处理（NLP）近年来异常火爆，越来越多的人急于进入该领域，但目前的研究复现努力是否足以让这些初学者应用最新的进展还不清楚。为了了解初学者的需求，我们在一个介绍性的NLP课程中开展了一项研究，让学生复现最近NLP论文的结果。令人惊讶的是，我们发现他们的编程技能和对研究论文的理解对完成练习的付出仅有限的影响，相比之下，研究作者的可访问性努力是成功的关键，包括完整的文档、更好的编码实践和更容易获取的数据文件。前进时，我们建议NLP研究人员密切关注这些开源工作的简单方面，并使用初学者的反馈见解提供可操作的想法以更好地支持他们。

    As natural language processing (NLP) has recently seen an unprecedented level of excitement, and more people are eager to enter the field, it is unclear whether current research reproducibility efforts are sufficient for this group of beginners to apply the latest developments. To understand their needs, we conducted a study with 93 students in an introductory NLP course, where students reproduced the results of recent NLP papers. Surprisingly, we find that their programming skill and comprehension of research papers have a limited impact on their effort spent completing the exercise. Instead, we find accessibility efforts by research authors to be the key to success, including complete documentation, better coding practice, and easier access to data files. Going forward, we recommend that NLP researchers pay close attention to these simple aspects of open-sourcing their work, and use insights from beginners' feedback to provide actionable ideas on how to better support them.
    
[^57]: 扫描与拍照：理解1层Transformer中的训练动态和标记组成

    Scan and Snap: Understanding Training Dynamics and Token Composition in 1-layer Transformer. (arXiv:2305.16380v1 [cs.CL])

    [http://arxiv.org/abs/2305.16380](http://arxiv.org/abs/2305.16380)

    本文分析了1层Transformer在下一个标记预测任务中的SGD训练动态，证明了自我关注层充当了“区分性扫描算法”，从而逐步关注到相关标记并排除不相关的标记，总结相关信息在编码表示中。同时研究了标记频率、上下文和初始化自我关注层等对Transformer性能的影响。

    

    Transformer架构在多个研究领域表现出了惊人的性能，并成为许多神经网络模型的基础。然而，我们对其如何工作的理解仍然有限。特别是，通过简单的预测性损失，表示如何从梯度训练动态中出现仍然是一个谜。在本文中，针对具有一个自我关注层和一个解码器层的1层Transformer，我们以数学严谨的方式分析其在下一个标记预测任务中的SGD训练动态。我们打开了自我关注层组合输入标记的动态过程的黑盒子，并揭示了底层归纳偏差的本质。具体而言，在没有位置编码、长输入序列和解码器层学习速度快于自我关注层的假设下，我们证明了自我关注层充当了“区分性扫描算法”：从均匀注意力开始，它逐渐关注到相关标记，排除不相关的标记，直到所有相关信息被扫描并总结在编码表示中。我们的分析还显示了标记频率和上下文如何影响注意权重，以及自我关注层初始化如何影响收敛速度。

    Transformer architecture has shown impressive performance in multiple research domains and has become the backbone of many neural network models. However, there is limited understanding on how it works. In particular, with a simple predictive loss, how the representation emerges from the gradient \emph{training dynamics} remains a mystery. In this paper, for 1-layer transformer with one self-attention layer plus one decoder layer, we analyze its SGD training dynamics for the task of next token prediction in a mathematically rigorous manner. We open the black box of the dynamic process of how the self-attention layer combines input tokens, and reveal the nature of underlying inductive bias. More specifically, with the assumption (a) no positional encoding, (b) long input sequence, and (c) the decoder layer learns faster than the self-attention layer, we prove that self-attention acts as a \emph{discriminative scanning algorithm}: starting from uniform attention, it gradually attends mor
    
[^58]: 在脉冲神经网络中将噪声作为计算和学习资源

    Exploiting Noise as a Resource for Computation and Learning in Spiking Neural Networks. (arXiv:2305.16044v2 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2305.16044](http://arxiv.org/abs/2305.16044)

    本文提出了噪声脉冲神经元网络（NSNN）和噪声驱动学习规则（NDL），展示了噪声可以作为计算和学习的资源，并为一般脉冲神经元网络提供了一个框架。研究还展示了NSNNs在图像分类和语音识别等实际任务中的适用性，表明它们是未来神经形态计算系统的潜在有力工具。

    

    脉冲神经元网络是大脑非凡信息处理能力的基础，并已成为神经形态智能的支柱模型。本文介绍了噪声脉冲神经元网络（NSNN）和噪声驱动学习规则（NDL），采用带有噪声神经元动力学的脉冲神经元模型。该方法显示噪声可以作为计算和学习的资源，并理论上为一般脉冲神经元网络提供了一个框架。此外，NDL为代理梯度提供了深入的生物学合理性。通过将各种SNN架构和算法结合起来，我们展示了我们的方法表现出竞争性能，并且比确定性SNNs表现出更好的鲁棒性。此外，本文还展示了NSNNs在图像分类和语音识别等实际任务中的适用性，表明它们是未来神经形态计算系统的潜在有力工具。

    Networks of spiking neurons underpin the extraordinary information-processing capabilities of the brain and have emerged as pillar models in neuromorphic intelligence. Despite extensive research on spiking neural networks (SNNs), most are established on deterministic models. Integrating noise into SNNs leads to biophysically more realistic neural dynamics and may benefit model performance. This work presents the noisy spiking neural network (NSNN) and the noise-driven learning rule (NDL) by introducing a spiking neuron model incorporating noisy neuronal dynamics. Our approach shows how noise may act as a resource for computation and learning and theoretically provides a framework for general SNNs. Moreover, NDL provides an insightful biological rationale for surrogate gradients. By incorporating various SNN architectures and algorithms, we show that our approach exhibits competitive performance and improved robustness against challenging perturbations than deterministic SNNs. Additiona
    
[^59]: 指数平滑用于离线策略学习

    Exponential Smoothing for Off-Policy Learning. (arXiv:2305.15877v1 [cs.LG])

    [http://arxiv.org/abs/2305.15877](http://arxiv.org/abs/2305.15877)

    本文研究了离线学习中最小化风险的倒数倾向评分(IPS)的平滑正则化，推导出了可处理、可扩展、可解释的学习证明，并确定了在何种情况下不需要正则化IPS。

    

    离线策略学习旨在通过最小化风险的倒数倾向评分（IPS）来寻找改进的策略，通常使用记录的赌博数据。在本文中，我们研究了IPS的平滑正则化，推导出了一个双向PAC-Bayes泛化界限。该界限是可处理的、可扩展的、可解释的并提供了学习证明。我们通过一系列学习任务展示了我们方法的相关性和有利的性能。由于我们的界限适用于标准IPS，因此我们能够提供关于何时正则化IPS有用的见解。即，我们确定了不需要正则化的情况。这与在实践中，剪辑IPS常常比OPL中的标准IPS表现更好的信念相反。

    Off-policy learning (OPL) aims at finding improved policies from logged bandit data, often by minimizing the inverse propensity scoring (IPS) estimator of the risk. In this work, we investigate a smooth regularization for IPS, for which we derive a two-sided PAC-Bayes generalization bound. The bound is tractable, scalable, interpretable and provides learning certificates. In particular, it is also valid for standard IPS without making the assumption that the importance weights are bounded. We demonstrate the relevance of our approach and its favorable performance through a set of learning tasks. Since our bound holds for standard IPS, we are able to provide insight into when regularizing IPS is useful. Namely, we identify cases where regularization might not be needed. This goes against the belief that, in practice, clipped IPS often enjoys favorable performance than standard IPS in OPL.
    
[^60]: 理论指导的联合学习实现了隐私保护和数据效用的平衡

    Theoretically Principled Federated Learning for Balancing Privacy and Utility. (arXiv:2305.15148v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2305.15148](http://arxiv.org/abs/2305.15148)

    本文提出基于扭曲模型参数的保护机制的通用学习框架，用于实现联合学习中隐私保护和数据效用的平衡。算法可以在每个通信轮中实现个性化的效用-隐私折衷，我们在理论上证明了算法的次线性性质，该算法可以提高隐私保护的联合学习效力。

    

    我们提出了一种保护机制的通用学习框架，通过扭曲模型参数来保护隐私，实现隐私和效用之间的平衡。该算法适用于任意将扭曲映射到实值的隐私测量。在联合学习中，它可以为每个模型参数，每个客户端，在每个通信轮中实现个性化的效用-隐私折衷。这种自适应和细粒度的保护可以提高保护隐私的联合学习的效力。从理论上讲，我们证明了算法保护超参数的效用损失与最优保护超参数的效用损失之间的差距是总迭代次数的次线性。我们的算法次线性的特点表明，当迭代次数趋近于无穷大时，算法性能和最优性能之间的平均差距趋近于零。此外，我们提供了收敛性证明。

    We propose a general learning framework for the protection mechanisms that protects privacy via distorting model parameters, which facilitates the trade-off between privacy and utility. The algorithm is applicable to arbitrary privacy measurements that maps from the distortion to a real value. It can achieve personalized utility-privacy trade-off for each model parameter, on each client, at each communication round in federated learning. Such adaptive and fine-grained protection can improve the effectiveness of privacy-preserved federated learning.  Theoretically, we show that gap between the utility loss of the protection hyperparameter output by our algorithm and that of the optimal protection hyperparameter is sub-linear in the total number of iterations. The sublinearity of our algorithm indicates that the average gap between the performance of our algorithm and that of the optimal performance goes to zero when the number of iterations goes to infinity. Further, we provide the conv
    
[^61]: 图谱遇见LLM：一种用于稳健对话理解的协同过滤新方法

    Graph Meets LLM: A Novel Approach to Collaborative Filtering for Robust Conversational Understanding. (arXiv:2305.14449v1 [cs.AI])

    [http://arxiv.org/abs/2305.14449](http://arxiv.org/abs/2305.14449)

    一种协同过滤新方法用于稳健对话理解，在历史用户-实体交互的基础上，利用多跳客户亲和力丰富每个用户的索引，并使用有限内存BFGS算法调整每个索引的权重，实验结果显示其明显优于最先进的个性化查询重写方法。

    

    会话式人工智能系统（例如Alexa，Siri，Google Assistant等）需要理解存在缺陷的查询以确保稳健的会话理解并减少用户摩擦。这些有缺陷的查询通常是由用户的歧义和错误，自动语音识别（ASR）和自然语言理解（NLU）中的错误引起的。个性化查询重写（个性化QR）旨在减少身体和尾部用户查询流量中的缺陷，通常依赖于与对话式人工智能的过去成功的用户交互的索引。本文提出我们的“协同查询重写”方法，专注于重写用户历史中没有出现过的新型用户交互。该方法构建了一个“用户反馈交互图”（FIG），由历史用户-实体交互组成，并利用多跳客户亲和力来丰富每个用户的索引（即协同用户索引），从而帮助覆盖未来未曾见过的存在缺陷的查询。为了防止这些新的丰富索引被噪声反馈交互所支配，我们采用了有限内存BFGS（LLM）算法和回退方案来调整每个索引的权重。实验结果表明，我们的方法明显优于最先进的个性化QR方法，并在未看到的用户交互上取得了近乎完美的性能。

    Conversational AI systems (e.g. Alexa, Siri, Google Assistant, etc.) need to understand queries with defects to ensure robust conversational understanding and reduce user frictions. The defective queries are often induced by user ambiguities and mistakes, or errors in the automatic speech recognition (ASR) and natural language understanding (NLU).  Personalized query rewriting (personalized QR) targets reducing defects in the torso and tail user query traffic, and it typically relies on an index of past successful user interactions with the conversational AI. This paper presents our "Collaborative Query Rewriting" approach that focuses on rewriting novel user interactions unseen in the user history. This approach builds a "user Feedback Interaction Graph" (FIG) consisting of historical user-entity interactions, and leverages multi-hop customer affinity to enrich each user's index (i.e. the Collaborative User Index) that would help cover future unseen defective queries. To counteract th
    
[^62]: XRoute环境：一种基于强化学习的新型路由环境

    XRoute Environment: A Novel Reinforcement Learning Environment for Routing. (arXiv:2305.13823v1 [cs.AI])

    [http://arxiv.org/abs/2305.13823](http://arxiv.org/abs/2305.13823)

    XRoute环境是一种基于强化学习的新型路由环境，允许代理在端到端路由框架中选择和路由网络，具有挑战性且易于使用，并支持分布式部署和多实例实验。

    

    路由是现代设计自动化流程中至关重要且耗时的阶段，强化学习领域的巨大进展使得可以利用这些方法来改善路由质量和效率。然而，最近研究中基于强化学习的方法解决的路由问题规模太小，无法在商业EDA工具中使用。我们介绍了XRoute环境，这是一种新的强化学习环境，其中代理被训练在先进的端到端路由框架中选择和路由网络。这个环境可以快速安全且可重复地测试新算法和想法，并且具有挑战性，易于使用，定制和添加其他场景，并且在一个宽松的开源许可下提供支持分布式部署和多实例实验。我们提出了两个学习任务并构建了一个完整芯片测试。

    Routing is a crucial and time-consuming stage in modern design automation flow for advanced technology nodes. Great progress in the field of reinforcement learning makes it possible to use those approaches to improve the routing quality and efficiency. However, the scale of the routing problems solved by reinforcement learning-based methods in recent studies is too small for these methods to be used in commercial EDA tools. We introduce the XRoute Environment, a new reinforcement learning environment where agents are trained to select and route nets in an advanced, end-to-end routing framework. Novel algorithms and ideas can be quickly tested in a safe and reproducible manner in it. The resulting environment is challenging, easy to use, customize and add additional scenarios, and it is available under a permissive open-source license. In addition, it provides support for distributed deployment and multi-instance experiments. We propose two tasks for learning and build a full-chip test 
    
[^63]: 通过邻居引导的标签精炼协同学习实现无监督可见-红外人员再识别

    Unsupervised Visible-Infrared Person ReID by Collaborative Learning with Neighbor-Guided Label Refinement. (arXiv:2305.12711v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2305.12711](http://arxiv.org/abs/2305.12711)

    本论文提出了一个双重最优传输标签分配(DOTLA)框架，以同时将一个模态中生成的标签分配给其对应的模态，实现无监督可见-红外人员再识别。在相应模态中邻居样本的指导下，还提出了一个跨模态邻居一致性引导的标签精炼和正则化模块，进一步提高了算法的精度和鲁棒性。

    

    无监督学习可见-红外人员再识别(USL-VI-ReID)旨在从未标记的跨模态数据集中学习模态不变特征，这在视频监控系统等实际应用中至关重要。解决跨模态数据关联问题对于进一步进行异质联合学习非常关键。针对这个问题，我们提出了一个双重最优传输标签分配(DOTLA)框架，同时将一个模态中生成的标签分配给其对应的模态。所提出的DOTLA机制formulate了一种相互增强和高效的跨模态数据关联解决方案，可以有效地减少一些不足和噪声标签关联的副作用。此外，我们还提出了一个跨模态邻居一致性引导的标签精炼和正则化模块，在相应模态中邻居样本的指导下消除由不准确的监督信号带来的负面影响。在两个基准数据集上的大量实验证明，所提出的USL-VI-ReID模型与现有的无监督方法甚至一些有监督方法相比，实现了最先进的性能。

    Unsupervised learning visible-infrared person re-identification (USL-VI-ReID) aims at learning modality-invariant features from unlabeled cross-modality dataset, which is crucial for practical applications in video surveillance systems. The key to essentially address the USL-VI-ReID task is to solve the cross-modality data association problem for further heterogeneous joint learning. To address this issue, we propose a Dual Optimal Transport Label Assignment (DOTLA) framework to simultaneously assign the generated labels from one modality to its counterpart modality. The proposed DOTLA mechanism formulates a mutual reinforcement and efficient solution to cross-modality data association, which could effectively reduce the side-effects of some insufficient and noisy label associations. Besides, we further propose a cross-modality neighbor consistency guided label refinement and regularization module, to eliminate the negative effects brought by the inaccurate supervised signals, under th
    
[^64]: 高效的双边跨模态聚类匹配用于无监督可见光-红外人物识别

    Efficient Bilateral Cross-Modality Cluster Matching for Unsupervised Visible-Infrared Person ReID. (arXiv:2305.12673v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2305.12673](http://arxiv.org/abs/2305.12673)

    该文提出了一种通过匹配跨模态聚类来减少模态差异的双向聚类匹配学习框架，同时提出了模态特定和模态不可知对比学习框架来共同对齐特征。

    

    无监督的可见光-红外人物识别（USL-VI-ReID）旨在在没有注释的情况下匹配来自不同模态的行人图像中相同身份的样本。本文针对没有很好探索跨模态聚类关系的问题，提出了一种新颖的双向聚类匹配学习框架，通过匹配跨模态聚类来减少模态差异。我们通过在二分图中优化最大匹配问题设计了一个多对多双边跨模态聚类匹配（MBCCM）算法。然后，匹配的成对聚类在模型训练期间利用共享的可见光和红外伪标签。在这样的监督信号下，提出了一种模态特定和模态不可知（MSMA）对比学习框架，以在聚类级别上共同对齐特征。同时，跨模态的模态特定和模态不可知特征也被考虑进去。

    Unsupervised visible-infrared person re-identification (USL-VI-ReID) aims to match pedestrian images of the same identity from different modalities without annotations. Existing works mainly focus on alleviating the modality gap by aligning instance-level features of the unlabeled samples. However, the relationships between cross-modality clusters are not well explored. To this end, we propose a novel bilateral cluster matching-based learning framework to reduce the modality gap by matching cross-modality clusters. Specifically, we design a Many-to-many Bilateral Cross-Modality Cluster Matching (MBCCM) algorithm through optimizing the maximum matching problem in a bipartite graph. Then, the matched pairwise clusters utilize shared visible and infrared pseudo-labels during the model training. Under such a supervisory signal, a Modality-Specific and Modality-Agnostic (MSMA) contrastive learning framework is proposed to align features jointly at a cluster-level. Meanwhile, the cross-modal
    
[^65]: 大型语言模型可以被引导来规避AI生成的文本检测

    Large Language Models can be Guided to Evade AI-Generated Text Detection. (arXiv:2305.10847v1 [cs.CL])

    [http://arxiv.org/abs/2305.10847](http://arxiv.org/abs/2305.10847)

    本文揭示了大型语言模型可以通过精心设计的提示语来有效规避现有的文本检测系统，证明了这些检测器的脆弱性。

    

    大型语言模型在包括论文写作和问答等多个任务中展现出了出色的表现。然而，必须解决这些模型潜在的误用问题，否则可能导致抄袭和垃圾信息等不良后果。本研究揭示，通过精心设计的提示语，LLMs可以有效地规避检测系统。我们提出了一种新颖的基于替换的上下文示例优化方法（SICO），用于自动生成这种提示语。在三个现实任务中，LLMs可能被误用，在SICO的帮助下，ChatGPT成功地规避了六项现有的检测器，平均导致0.54的AUC下降。令人惊讶的是，在大多数情况下，这些检测器的表现甚至比随机分类器还要差。这些结果坚定地揭示了现有检测器的脆弱性。

    Large Language Models (LLMs) have demonstrated exceptional performance in a variety of tasks, including essay writing and question answering. However, it is crucial to address the potential misuse of these models, which can lead to detrimental outcomes such as plagiarism and spamming. Recently, several detectors have been proposed, including fine-tuned classifiers and various statistical methods. In this study, we reveal that with the aid of carefully crafted prompts, LLMs can effectively evade these detection systems. We propose a novel Substitution-based In-Context example Optimization method (SICO) to automatically generate such prompts. On three real-world tasks where LLMs can be misused, SICO successfully enables ChatGPT to evade six existing detectors, causing a significant 0.54 AUC drop on average. Surprisingly, in most cases these detectors perform even worse than random classifiers. These results firmly reveal the vulnerability of existing detectors. Finally, the strong perfor
    
[^66]: 增量因果图学习进行在线无监督根本原因分析

    Incremental Causal Graph Learning for Online Unsupervised Root Cause Analysis. (arXiv:2305.10638v1 [cs.LG])

    [http://arxiv.org/abs/2305.10638](http://arxiv.org/abs/2305.10638)

    本文提出了CORAL，一种用于在线无监督根本原因分析的新框架，可以自动触发该过程并增量更新模型，包括三个主要部分：触发点检测，增量因果图学习和基于网络传播的根本原因定位。

    

    根本原因分析（RCA）的任务是分析系统监控数据，以识别系统故障/失效的根本原因。有效的RCA可以大大加速系统故障恢复，并减轻系统损失或财务损失。然而，以前的研究大多集中在开发离线RCA算法上，这通常需要手动启动RCA过程，需要大量时间和数据来训练稳健的模型，然后需要从头开始重新训练新的系统故障。在本文中，我们提出了CORAL，一种新颖的在线RCA框架，可以自动触发RCA过程并增量更新RCA模型。CORAL包括触发点检测、增量解缠因果图学习和基于网络传播的根本原因定位。触发点检测组件旨在自动检测系统状态转换并进行准实时检测。为此，我们开发了一种基于m的在线触发点检测方法。

    The task of root cause analysis (RCA) is to identify the root causes of system faults/failures by analyzing system monitoring data. Efficient RCA can greatly accelerate system failure recovery and mitigate system damages or financial losses. However, previous research has mostly focused on developing offline RCA algorithms, which often require manually initiating the RCA process, a significant amount of time and data to train a robust model, and then being retrained from scratch for a new system fault.  In this paper, we propose CORAL, a novel online RCA framework that can automatically trigger the RCA process and incrementally update the RCA model. CORAL consists of Trigger Point Detection, Incremental Disentangled Causal Graph Learning, and Network Propagation-based Root Cause Localization. The Trigger Point Detection component aims to detect system state transitions automatically and in near-real-time. To achieve this, we develop an online trigger point detection approach based on m
    
[^67]: 人们交谈，AI倾听：电子病历中污名化语言对AI判断的影响

    People Talking and AI Listening: How Stigmatizing Language in EHR Notes Affect AI Performance. (arXiv:2305.10201v1 [cs.AI])

    [http://arxiv.org/abs/2305.10201](http://arxiv.org/abs/2305.10201)

    本文研究了电子病历中污名化语言对基于Transformer的深度学习模型和可解释AI(XAI)技术进行死亡预测的影响。发现临床医生所写的SL会对AI性能表现不利，尤其是在黑人患者中表现更为明显，强调了理解偏见对下游AI性能的影响的重要性，以开发更具公平和正义的医疗系统。

    

    电子病历(EHRs)是期望中的人工智能(AI)-驱动的医疗转型的重要数据来源。然而，反映在EHR笔记中的临床医师偏见可能会导致AI模型继承并放大这些偏见，从而不断加剧健康上的不平等。本研究调查了EHR笔记中污名化语言(SL)对基于Transformer的深度学习模型和可解释AI(XAI)技术进行死亡预测的影响。我们的研究发现，临床医生所写的SL不利于AI的性能表现，尤其是在黑人患者中表现更为明显，突出了SL作为AI模型发展中种族差异的一种来源。为探索一种操作上有效的缓解SL影响的方法，我们研究了临床医生协作网络中SL生成的模式，发现中央医生对AI模型中的种族差异具有更强的影响力。我们发现，删除中央临床医生撰写的SL是相对于随机选择临床医生而言，缓解SL对AI性能影响的更为有效的策略。我们的研究强调了理解反映在EHR笔记中的临床医师偏见对下游AI性能的影响的重要性，以开发更具公平和正义的医疗系统。

    Electronic health records (EHRs) serve as an essential data source for the envisioned artificial intelligence (AI)-driven transformation in healthcare. However, clinician biases reflected in EHR notes can lead to AI models inheriting and amplifying these biases, perpetuating health disparities. This study investigates the impact of stigmatizing language (SL) in EHR notes on mortality prediction using a Transformer-based deep learning model and explainable AI (XAI) techniques. Our findings demonstrate that SL written by clinicians adversely affects AI performance, particularly so for black patients, highlighting SL as a source of racial disparity in AI model development. To explore an operationally efficient way to mitigate SL's impact, we investigate patterns in the generation of SL through a clinicians' collaborative network, identifying central clinicians as having a stronger impact on racial disparity in the AI model. We find that removing SL written by central clinicians is a more 
    
[^68]: 基于连词效应建模的大动作空间离线策略评估

    Off-Policy Evaluation for Large Action Spaces via Conjunct Effect Modeling. (arXiv:2305.08062v1 [stat.ML])

    [http://arxiv.org/abs/2305.08062](http://arxiv.org/abs/2305.08062)

    本研究提出了一个称为OffCEM的估计器，用于对大离散动作空间下上下文匹配策略进行离线策略评估。该估计器通过基于模型的奖励估计来处理残余因果效应，并在新的本地正确性条件下保持无偏性。结果表明，OffCEM在合成和实际大动作空间数据集上优于现有方法。

    

    本文讨论了对于传统重要性加权方法方巨的大离散动作空间下的上下文匹配策略的离线策略评估（OPE）问题。为了解决方巨问题，我们提出了一个新的估计器OffCEM，该方法基于连词效应模型（CEM），这是一种新的因果效应分解方法，可以将效应分为群集效应和残差效应。OffCEM仅对行动群集应用重要性加权，通过基于模型的奖励估计来处理残余因果效应。我们表明，在新的本地正确性条件下，该估计器是无偏的，该条件仅要求残差效应模型保留每个群集中行动的相对期望奖励差异。为了充分利用CEM和本地正确性，我们还提出了一种新的两步过程，用于执行基于模型的估计，第一步最小化偏差，第二步最小化方差。我们发现，所得到的OPE估计器OffCEM在合成和实际大动作空间数据集上都明显优于现有的最先进方法。

    We study off-policy evaluation (OPE) of contextual bandit policies for large discrete action spaces where conventional importance-weighting approaches suffer from excessive variance. To circumvent this variance issue, we propose a new estimator, called OffCEM, that is based on the conjunct effect model (CEM), a novel decomposition of the causal effect into a cluster effect and a residual effect. OffCEM applies importance weighting only to action clusters and addresses the residual causal effect through model-based reward estimation. We show that the proposed estimator is unbiased under a new condition, called local correctness, which only requires that the residual-effect model preserves the relative expected reward differences of the actions within each cluster. To best leverage the CEM and local correctness, we also propose a new two-step procedure for performing model-based estimation that minimizes bias in the first step and variance in the second step. We find that the resulting O
    
[^69]: ACTC: 冷启动知识图谱补全的主动阈值校准

    ACTC: Active Threshold Calibration for Cold-Start Knowledge Graph Completion. (arXiv:2305.06395v1 [cs.LG])

    [http://arxiv.org/abs/2305.06395](http://arxiv.org/abs/2305.06395)

    本文提出了一种名为ACTC的方法，在冷启动知识图谱补全时进行主动阈值校准，可以有效地利用有限的标记元组来找到每个关系的最佳阈值，同时也结合未标记元组进行了实验。

    

    自监督的知识图谱补全(KGC)依赖于估计得分模型(实体，关系，实体)-元组，例如，通过嵌入初始知识图。通过调整预测阈值(使用手动注释的示例)，可以改善预测质量。本文尝试首次针对KGC进行冷启动校准，在此过程中初始没有注释的示例，并且只能选择有限数量的元组进行注释。我们的新方法ACTC基于有限的注释元组有效地找到好的每个关系的阈值。除了一些注释的元组外，ACTC还利用Logistic回归或高斯过程分类器估计的未标记元组的正确性。我们还通过密度和随机选择等不同方法选择候选元组进行注释。我们使用五个评分模型和一个oracle注释进行实验。

    Self-supervised knowledge-graph completion (KGC) relies on estimating a scoring model over (entity, relation, entity)-tuples, for example, by embedding an initial knowledge graph. Prediction quality can be improved by calibrating the scoring model, typically by adjusting the prediction thresholds using manually annotated examples. In this paper, we attempt for the first time cold-start calibration for KGC, where no annotated examples exist initially for calibration, and only a limited number of tuples can be selected for annotation. Our new method ACTC finds good per-relation thresholds efficiently based on a limited set of annotated tuples. Additionally to a few annotated tuples, ACTC also leverages unlabeled tuples by estimating their correctness with Logistic Regression or Gaussian Process classifiers. We also experiment with different methods for selecting candidate tuples for annotation: density-based and random selection. Experiments with five scoring models and an oracle annotat
    
[^70]: RLocator: 利用强化学习进行Bug定位

    RLocator: Reinforcement Learning for Bug Localization. (arXiv:2305.05586v1 [cs.SE])

    [http://arxiv.org/abs/2305.05586](http://arxiv.org/abs/2305.05586)

    本文提出了一种基于强化学习的Bug定位方法RLocator，相较于其他最先进的Bug定位技术具有更优越的性能。

    

    软件开发者在他们的项目中花费了大量的时间来修复Bugs。为了简化这个过程，提出了Bug定位方法来确定哪些源代码文件可能是负责特定Bug的源头。之前的工作提出了几种基于相似性的机器学习技术，用于Bug定位。尽管这些技术取得了显著进展，但它们并没有直接优化评估指标。相反，在训练和测试阶段使用了不同的度量标准，这会对检索任务的模型性能产生负面影响。在本文中，我们提出了一种基于强化学习的Bug定位方法RLocator。我们使用马尔可夫决策过程（MDP）来优化评估指标，从而对Bug定位问题进行公式化。我们提出了该技术，并基于六种高度流行的Apache项目的8,316个Bug报告的基准数据集进行了实验评估。我们的评估表明，RLocator相较于其他最先进的Bug定位技术具有更优越的性能。

    Software developers spend a significant portion of time fixing bugs in their projects. To streamline this process, bug localization approaches have been proposed to identify the source code files that are likely responsible for a particular bug. Prior work proposed several similarity-based machine-learning techniques for bug localization. Despite significant advances in these techniques, they do not directly optimize the evaluation measures. Instead, they use different metrics in the training and testing phases, which can negatively impact the model performance in retrieval tasks. In this paper, we propose RLocator, a Reinforcement Learning-based (RL) bug localization approach. We formulate the bug localization problem using a Markov Decision Process (MDP) to optimize the evaluation measures directly. We present the technique and experimentally evaluate it based on a benchmark dataset of 8,316 bug reports from six highly popular Apache projects. Our evaluation shows that RLocator achie
    
[^71]: 针对时尚检测的不平衡标签样本分布的数据高效训练

    Data Efficient Training with Imbalanced Label Sample Distribution for Fashion Detection. (arXiv:2305.04379v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2305.04379](http://arxiv.org/abs/2305.04379)

    本文提出了一种最先进的加权目标函数，用于提高多标签分类中深度神经网络（DNN）针对长尾数据分布的性能，并通过对时尚服装的图像属性分类的实验，取得了良好的性能。

    

    多标签分类模型在电子商务中有广泛的应用，包括基于视觉的标签预测以及基于语言的情感分类。实现这些任务的一个主要难点是数据分布的显著不平衡。为了解决这个问题，本文探索了更多的数据高效模型训练技术，并提出了一种最先进的加权目标函数，用于提高多标签分类中深度神经网络（DNN）针对长尾数据分布的性能。我们的实验涉及时尚服装的基于图像的属性分类，并且结果表明，新的加权目标函数相较于传统方法具有良好的性能。

    Multi-label classification models have a wide range of applications in E-commerce, including visual-based label predictions and language-based sentiment classifications. A major challenge in achieving satisfactory performance for these tasks in the real world is the notable imbalance in data distribution. For instance, in fashion attribute detection, there may be only six 'puff sleeve' clothes among 1000 products in most E-commerce fashion catalogs. To address this issue, we explore more data-efficient model training techniques rather than acquiring a huge amount of annotations to collect sufficient samples, which is neither economic nor scalable. In this paper, we propose a state-of-the-art weighted objective function to boost the performance of deep neural networks (DNNs) for multi-label classification with long-tailed data distribution. Our experiments involve image-based attribute classification of fashion apparels, and the results demonstrate favorable performance for the new weig
    
[^72]: 从文本中实现少样本领域自适应视觉融合事件检测

    Few-shot Domain-Adaptive Visually-fused Event Detection from Text. (arXiv:2305.03517v1 [cs.CL])

    [http://arxiv.org/abs/2305.03517](http://arxiv.org/abs/2305.03517)

    本文提出了一种基于视觉融合和领域自适应的事件检测方法，可以用少量标记数据训练并且适应于新领域。

    

    近年来，将辅助模态如图像整合到事件检测模型中已经引起人们的越来越多的关注。自然语言描述情境的复杂性促使研究人员利用相关的视觉上下文来提高事件检测的性能。然而，目前这个领域的方法在数据稀缺性方面存在问题，需要许多标记好的文本-图像对来训练模型。此外，在推断时无法获得视觉上下文的限制也会对这些模型的性能产生负面影响，使其在实际场景中难以应用。本文提出了一种新颖的领域自适应视觉融合事件检测方法，可以用很少的标记图像-文本配对数据点进行训练。具体来说，我们引入了一种称为视觉想象器的方法，它可以在没有视觉上下文的情况下从文本中合成图像，并且可以根据需要定制到特定的领域。通过这种方法，我们的方法消除了需要大量标记数据的需求，并且只需少量的标记图像-文本对就可以适应于新领域。我们在基准数据集上评估了我们的方法，并显示其优于现有的最先进的领域自适应事件检测方法。

    Incorporating auxiliary modalities such as images into event detection models has attracted increasing interest over the last few years. The complexity of natural language in describing situations has motivated researchers to leverage the related visual context to improve event detection performance. However, current approaches in this area suffer from data scarcity, where a large amount of labelled text-image pairs are required for model training. Furthermore, limited access to the visual context at inference time negatively impacts the performance of such models, which makes them practically ineffective in real-world scenarios. In this paper, we present a novel domain-adaptive visually-fused event detection approach that can be trained on a few labelled image-text paired data points. Specifically, we introduce a visual imaginator method that synthesises images from text in the absence of visual context. Moreover, the imaginator can be customised to a specific domain. In doing so, our
    
[^73]: SI-LSTM: 用于对话情感识别的说话人混合长短期记忆和跨模态注意力机制

    SI-LSTM: Speaker Hybrid Long-short Term Memory and Cross Modal Attention for Emotion Recognition in Conversation. (arXiv:2305.03506v1 [cs.CL])

    [http://arxiv.org/abs/2305.03506](http://arxiv.org/abs/2305.03506)

    SI-LSTM是一种用于对话情感识别的循环结构，可以追踪不同说话人的情感状态，从而增强对话情感学习。

    

    跨模态的对话情感识别对于智能医疗、对话人工智能和聊天历史观点挖掘等应用至关重要。本文提出了一种基于说话人信息增强长短期记忆（SI-LSTM）的循环结构，可以追踪不同说话人的情感状态，从而增强对话情感学习。

    Emotion Recognition in Conversation~(ERC) across modalities is of vital importance for a variety of applications, including intelligent healthcare, artificial intelligence for conversation, and opinion mining over chat history. The crux of ERC is to model both cross-modality and cross-time interactions throughout the conversation. Previous methods have made progress in learning the time series information of conversation while lacking the ability to trace down the different emotional states of each speaker in a conversation. In this paper, we propose a recurrent structure called Speaker Information Enhanced Long-Short Term Memory (SI-LSTM) for the ERC task, where the emotional states of the distinct speaker can be tracked in a sequential way to enhance the learning of the emotion in conversation. Further, to improve the learning of multimodal features in ERC, we utilize a cross-modal attention component to fuse the features between different modalities and model the interaction of the 
    
[^74]: 悬臂梁损伤检测的神经符号模型

    Neuro-symbolic model for cantilever beams damage detection. (arXiv:2305.03063v1 [cs.LG])

    [http://arxiv.org/abs/2305.03063](http://arxiv.org/abs/2305.03063)

    本文提出了一种神经符号模型用于悬臂梁损伤检测，该模型通过将卷积网络的处理能力与逻辑查询交互控制相结合，不仅能够准确检测损伤，而且还能够提供解释和定位，使其在操作条件下更可靠和可信。

    

    在过去的十年中，损伤检测方法迅速从先进的信号处理方法转变为机器学习，尤其是深度学习模型，以准确地、非侵入性地估计梁结构状态。但随着深度学习模型达到巅峰表现，人们也观察到了它们适用性的限制和易受攻击的弱点。其中最重要的一个原因是深度学习系统内在可解释性的缺失，由于知识编码在张量值中而没有包含逻辑约束。本文提出了一种神经符号模型，基于新颖的认知架构，将卷积网络的处理能力与直接将实际逻辑包含到模型中的查询交互控制结合起来，用于悬臂梁损伤检测。该混合判别模型不仅能够精确地检测损伤，而且能够提供损伤的解释和定位，使其在操作条件下更可靠和可信。

    In the last decade, damage detection approaches swiftly changed from advanced signal processing methods to machine learning and especially deep learning models, to accurately and non-intrusively estimate the state of the beam structures. But as the deep learning models reached their peak performances, also their limitations in applicability and vulnerabilities were observed. One of the most important reason for the lack of trustworthiness in operational conditions is the absence of intrinsic explainability of the deep learning system, due to the encoding of the knowledge in tensor values and without the inclusion of logical constraints. In this paper, we propose a neuro-symbolic model for the detection of damages in cantilever beams based on a novel cognitive architecture in which we join the processing power of convolutional networks with the interactive control offered by queries realized through the inclusion of real logic directly into the model. The hybrid discriminative model is 
    
[^75]: 利用大型语言模型从医生-患者对话中生成临床笔记：来自MEDIQA-Chat的见解

    Clinical Note Generation from Doctor-Patient Conversations using Large Language Models: Insights from MEDIQA-Chat. (arXiv:2305.02220v1 [cs.CL])

    [http://arxiv.org/abs/2305.02220](http://arxiv.org/abs/2305.02220)

    本文介绍了使用大型语言模型从医生-患者对话中自动生成临床笔记的研究，采用少样本上下文学习法所生成笔记表现优秀，且可与人工编写的笔记媲美。

    

    本文描述了我们在MEDIQA-Chat 2023共享任务中提交的自动临床笔记生成方案。我们报告了两种方法的结果：第一种是在共享任务数据上微调预训练语言模型（PLM），第二种是使用大型语言模型（LLM）的少样本上下文学习（ICL）。两种方法都取得了高性能，如通过自动度量标准（例如ROUGE，BERTScore）测量，并分别在所有提交的方案中排名第二和第一。专家审核表明，通过基于ICL的方法使用GPT-4生成的笔记与人工编写的笔记一样受欢迎，这使得它成为从医生-患者对话中自动生成笔记的有前途的路径。

    This paper describes our submission to the MEDIQA-Chat 2023 shared task for automatic clinical note generation from doctor-patient conversations. We report results for two approaches: the first fine-tunes a pre-trained language model (PLM) on the shared task data, and the second uses few-shot in-context learning (ICL) with a large language model (LLM). Both achieve high performance as measured by automatic metrics (e.g. ROUGE, BERTScore) and ranked second and first, respectively, of all submissions to the shared task. Expert human scrutiny indicates that notes generated via the ICL-based approach with GPT-4 are preferred about as often as human-written notes, making it a promising path toward automated note generation from doctor-patient conversations.
    
[^76]: 在稀疏探测中寻找海量神经元: 实例研究

    Finding Neurons in a Haystack: Case Studies with Sparse Probing. (arXiv:2305.01610v1 [cs.LG])

    [http://arxiv.org/abs/2305.01610](http://arxiv.org/abs/2305.01610)

    本文通过训练$k$-稀疏线性分类器以预测输入特征是否存在，研究了大型语言模型（LLM）内部神经元激活的表示方式；对不同层次的神经元网络的研究表明，早期层利用神经元的稀疏组合来表示多种特征，中间层有特定的神经元表示高级上下文特征，增加规模使特征表示更加稀疏化。

    

    尽管大型语言模型(LLM)的应用和部署迅速增加，但这些模型的内部计算仍然不透明且难以理解。本文旨在了解高级可解释特征在LLM内部神经元激活中的表示方式。我们使用$k$-稀疏线性分类器(探针)来训练这些内部激活值，并预测输入的特征是否存在；通过改变$k$值，我们研究了学习表示的稀疏性以及随着模型规模的变化而变化的情况。当$k=1$时，我们定位某个特定特征非常相关的单个神经元，并进行了大量案例研究，以说明LLM的一般性质。特别是，我们展示了早期层利用神经元的稀疏组合来表示许多特征，中间层似乎具有专门的神经元来表示更高级的上下文特征，而增加的规模则导致表示稀疏性增加。

    Despite rapid adoption and deployment of large language models (LLMs), the internal computations of these models remain opaque and poorly understood. In this work, we seek to understand how high-level human-interpretable features are represented within the internal neuron activations of LLMs. We train $k$-sparse linear classifiers (probes) on these internal activations to predict the presence of features in the input; by varying the value of $k$ we study the sparsity of learned representations and how this varies with model scale. With $k=1$, we localize individual neurons which are highly relevant for a particular feature, and perform a number of case studies to illustrate general properties of LLMs. In particular, we show that early layers make use of sparse combinations of neurons to represent many features in superposition, that middle layers have seemingly dedicated neurons to represent higher-level contextual features, and that increasing scale causes representational sparsity to
    
[^77]: 无特定模型泛化难度度量

    Model-agnostic Measure of Generalization Difficulty. (arXiv:2305.01034v1 [cs.LG])

    [http://arxiv.org/abs/2305.01034](http://arxiv.org/abs/2305.01034)

    该论文提出了第一个无特定模型的、量化机器学习测试泛化难度的方法——归纳偏差复杂度度量。该方法量化了在任务上良好泛化所需的总信息量与数据提供的信息量之差，通常需要在许多维度上泛化的任务比涉及更少维度但要求更多细节的任务要困难得多。

    

    机器学习算法的度量是其可以执行的任务难度，足够困难的任务是强大机器学习模型的关键驱动因素。然而，量化机器学习测试的泛化难度一直是具有挑战性的。我们提出了据我们所知的第一个对任务固有泛化难度的无特定模型的度量。我们的归纳偏差复杂度度量量化了在任务上良好泛化所需的总信息量与数据提供的信息量之差。通过测量适合训练数据的假设在任务中泛化的分数占据的容积，来实现这一点。它与模型必须泛化的空间的内在维数成指数比例，但仅在每个维度的分辨率上呈多项式比例，表明需要在许多维度上泛化的任务比涉及更少维度的更多细节的任务要困难得多。

    The measure of a machine learning algorithm is the difficulty of the tasks it can perform, and sufficiently difficult tasks are critical drivers of strong machine learning models. However, quantifying the generalization difficulty of machine learning benchmarks has remained challenging. We propose what is to our knowledge the first model-agnostic measure of the inherent generalization difficulty of tasks. Our inductive bias complexity measure quantifies the total information required to generalize well on a task minus the information provided by the data. It does so by measuring the fractional volume occupied by hypotheses that generalize on a task given that they fit the training data. It scales exponentially with the intrinsic dimensionality of the space over which the model must generalize but only polynomially in resolution per dimension, showing that tasks which require generalizing over many dimensions are drastically more difficult than tasks involving more detail in fewer dimen
    
[^78]: 位置偏差对token分类中的语言模型的影响

    Impact of Position Bias on Language Models in Token Classification. (arXiv:2304.13567v1 [cs.CL])

    [http://arxiv.org/abs/2304.13567](http://arxiv.org/abs/2304.13567)

    研究了语言模型在token分类任务中的位置偏差问题，通过实验表明在具体任务中，BERT、ERNIE、ELECTRA等编码器以及GPT2和BLOOM等解码器的平均性能下降了3%和9%。

    

    语言模型在自然语言处理任务中表现出了最先进的性能。命名实体识别(NER)或词性标注等下游任务已知存在数据不平衡问题，特别是在正负示例的比例和类不平衡方面。本文研究了语言模型的另一个特定问题，即token分类任务中正示例的位置偏差。因此，我们对基于Token分类基准测试的语言模型的性能进行了深入的位置偏差评估。我们的研究包括CoNLL03和OntoNote5.0用于NER，English Tree Bank UD_en和TweeBank用于POS标记。我们提出了一种评估方法，以研究Transformer模型中的位置偏差。我们发现像BERT、ERNIE、ELECTRA这样的编码器和像GPT2 和BLOOM这样的解码器平均性能下降了3%和9%。

    Language Models (LMs) have shown state-of-the-art performance in Natural Language Processing (NLP) tasks. Downstream tasks such as Named Entity Recognition (NER) or Part-of-Speech (POS) tagging are known to suffer from data imbalance issues, specifically in terms of the ratio of positive to negative examples, and class imbalance. In this paper, we investigate an additional specific issue for language models, namely the position bias of positive examples in token classification tasks. Therefore, we conduct an in-depth evaluation of the impact of position bias on the performance of LMs when fine-tuned on Token Classification benchmarks. Our study includes CoNLL03 and OntoNote5.0 for NER, English Tree Bank UD_en and TweeBank for POS tagging. We propose an evaluation approach to investigate position bias in Transformer models. We show that encoders like BERT, ERNIE, ELECTRA, and decoders such as GPT2 and BLOOM can suffer from this bias with an average drop of 3\% and 9\% in their performan
    
[^79]: 带有自我改进硬约束的多能源管理系统的安全强化学习

    Safe reinforcement learning with self-improving hard constraints for multi-energy management systems. (arXiv:2304.08897v1 [eess.SY])

    [http://arxiv.org/abs/2304.08897](http://arxiv.org/abs/2304.08897)

    本论文提出了一种安全强化学习方法，能够实现多能源管理系统中的最优控制，在保证硬约束的前提下减少工程工作，降低建模偏差，并避免潜在的不安全行为。

    

    带有硬约束保证的安全强化学习是多能源管理系统中最有前途的最优控制方向。它只需要在环境特定的约束函数本身上预先而不是完整的模型（即植物，干扰和噪声模型，以及未包括在植物模型中的状态的预测模型 - 例如需求，天气和价格预测）。因此，可减少项目特定的前期和持续的工程工作，仍可以学习更好地表示基础系统动态，并使建模偏差最小化（无基于模型的目标函数）。然而，即使仅约束函数本身有时也不总是容易提供准确的先验（例如能量平衡约束需要详细确定所有能量输入和输出），从而导致潜在的不安全行为。在本文中，我们提出了两个新的进展：（I）将Optlayer和SafeFallback方法结合起来，命名为O

    Safe reinforcement learning (RL) with hard constraint guarantees is a promising optimal control direction for multi-energy management systems. It only requires the environment-specific constraint functions itself a prior and not a complete model (i.e. plant, disturbance and noise models, and prediction models for states not included in the plant model - e.g. demand, weather, and price forecasts). The project-specific upfront and ongoing engineering efforts are therefore still reduced, better representations of the underlying system dynamics can still be learned and modeling bias is kept to a minimum (no model-based objective function). However, even the constraint functions alone are not always trivial to accurately provide in advance (e.g. an energy balance constraint requires the detailed determination of all energy inputs and outputs), leading to potentially unsafe behavior. In this paper, we present two novel advancements: (I) combining the Optlayer and SafeFallback method, named O
    
[^80]: 上下文依赖性嵌入话语表示在对话情绪识别中的应用

    Context-Dependent Embedding Utterance Representations for Emotion Recognition in Conversations. (arXiv:2304.08216v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2304.08216](http://arxiv.org/abs/2304.08216)

    本论文利用预训练变换器语言模型的上下文依赖性嵌入话语表示，从而在对话情绪识别中取得了非常良好的效果。

    

    随着对话代理变得越来越普遍，对话情绪识别（ERC）越来越重要。识别情感对于有效的交流至关重要，是开发有效并且具有共情能力的对话代理的重要组成部分。对话背景的知识和理解对于识别交流者的情感非常有价值。因此，我们利用对话背景来进行ERC，即关注先前的对话回合。通常，建模对话上下文的方法是产生每个话语的上下文无关表示，然后对这些话语进行上下文模型处理。本文提出了利用预训练变换器语言模型的上下文依赖性嵌入话语表示。在我们的方法中，我们将对话背景追加到话语中，然后将其馈入基于变换器的模型中，该模型将产生相应的上下文嵌入表示。我们在三个公共数据集上评估了我们的方法，并证明在与上下文无关方法和最先进的模型相比中具有很好的效果。

    Emotion Recognition in Conversations (ERC) has been gaining increasing importance as conversational agents become more and more common. Recognizing emotions is key for effective communication, being a crucial component in the development of effective and empathetic conversational agents. Knowledge and understanding of the conversational context are extremely valuable for identifying the emotions of the interlocutor. We thus approach Emotion Recognition in Conversations leveraging the conversational context, i.e., taking into attention previous conversational turns. The usual approach to model the conversational context has been to produce context-independent representations of each utterance and subsequently perform contextual modeling of these. Here we propose context-dependent embedding representations of each utterance by leveraging the contextual representational power of pre-trained transformer language models. In our approach, we feed the conversational context appended to the ut
    
[^81]: 超越不对称性：结构剪枝提高序列到序列模型的推断效率

    To Asymmetry and Beyond: Structured Pruning of Sequence to Sequence Models for Improved Inference Efficiency. (arXiv:2304.02721v1 [cs.CL])

    [http://arxiv.org/abs/2304.02721](http://arxiv.org/abs/2304.02721)

    本论文研究了模型大小、结构化剪枝、推断效率和摘要准确性之间的关系，发现使用不对称剪枝可在不大损失模型准确性的情况下，提高推断效率约3倍。

    

    序列到序列语言模型可以用于生成连贯，相关和简洁的抽象摘要。但是，模型大小可能使得在延迟敏感或 Web 规模的实现中部署变得困难。本文研究了模型大小、结构化剪枝、推断效率和广泛使用的摘要数据集上的摘要准确性之间的关系。我们表明，模型准确性与编码器大小有关，而推理效率与解码器有关。使用不对称剪枝可导致推断延迟的近3倍提高，Rouge-2的损失约为1点。此外，我们发现，平均性能降低和不对称性的作用在模型大小和数据集变化方面是一致的。

    Sequence-to-sequence language models can be used to produce abstractive summaries which are coherent, relevant, and concise. Still, model sizes can make deployment in latency-sensitive or web-scale implementations difficult. This paper studies the relationship between model size, structured pruning, inference efficiency, and summarization accuracy on widely used summarization datasets. We show that model accuracy is tied to the encoder size while inference efficiency is connected to the decoder. Using asymmetric pruning can lead to nearly 3x improvement in inference latency with ~1 point loss in Rouge-2. Moreover, we find both the average degradation and the role of asymmetry to be consistent across model sizes and variations in datasets.
    
[^82]: AutoRL超参数景观

    AutoRL Hyperparameter Landscapes. (arXiv:2304.02396v1 [cs.LG])

    [http://arxiv.org/abs/2304.02396](http://arxiv.org/abs/2304.02396)

    本文提出了一种方法，在训练期间多次建立和分析AutoRL超参数的景观，证明代表算法（DQN和SAC）在不同环境下的超参数景观会随时间而变化。

    

    强化学习（RL）在取得令人瞩目成果的同时，其超参数对性能的影响限制了其应用范围。这经常使得在实践中难以获得良好的结果。自动化RL（AutoRL）解决了这个难题，但有关超参数优化（HPO）方法在搜索最佳配置时所遍历的超参数景观动态变化的信息很少。鉴于现有AutoRL方法动态调整超参数配置的情况，我们提出了一种方法，在训练期间不仅在一个时间点，而且在多个时间点上建立和分析这些超参数景观。针对关于这种动态AutoRL方法合法性的一个重要开放问题，我们提供了充分的证据，表明在不同种类的环境（Cartpole和Pendulum）中，来自RL文献的代表算法（DQN和SAC）的超参数景观会随时间而强烈变化。

    Although Reinforcement Learning (RL) has shown to be capable of producing impressive results, its use is limited by the impact of its hyperparameters on performance. This often makes it difficult to achieve good results in practice. Automated RL (AutoRL) addresses this difficulty, yet little is known about the dynamics of the hyperparameter landscapes that hyperparameter optimization (HPO) methods traverse in search of optimal configurations. In view of existing AutoRL approaches dynamically adjusting hyperparameter configurations, we propose an approach to build and analyze these hyperparameter landscapes not just for one point in time but at multiple points in time throughout training. Addressing an important open question on the legitimacy of such dynamic AutoRL approaches, we provide thorough empirical evidence that the hyperparameter landscapes strongly vary over time across representative algorithms from RL literature (DQN and SAC) in different kinds of environments (Cartpole and
    
[^83]: Transformer和Snowball图卷积学习用于生物医学图分类

    Transformer and Snowball Graph Convolution Learning for Biomedical Graph Classification. (arXiv:2303.16132v1 [cs.LG])

    [http://arxiv.org/abs/2303.16132](http://arxiv.org/abs/2303.16132)

    本文介绍了一种新型Transformer和Snowball编码网络（TSEN），它将Transformer架构和图雪球连接引入GNNs。TSEN通过雪球编码层将图雪球连接与图Transformer结合起来，增强了捕捉多尺度信息和全局模式以学习整个图特征的能力。

    

    图或网络已被广泛用于描述和建模生物医学中的复杂系统。深度学习方法，尤其是图神经网络（GNNs），已被开发用于学习和预测这种结构化数据。在本文中，我们提出了一种用于生物医学图分类的新型Transformer和Snowball编码网络（TSEN），它将Transformer架构和图雪球连接引入GNNs，以学习整个图的表示。

    Graph or network has been widely used for describing and modeling complex systems in biomedicine. Deep learning methods, especially graph neural networks (GNNs), have been developed to learn and predict with such structured data. In this paper, we proposed a novel transformer and snowball encoding networks (TSEN) for biomedical graph classification, which introduced transformer architecture with graph snowball connection into GNNs for learning whole-graph representation. TSEN combined graph snowball connection with graph transformer by snowball encoding layers, which enhanced the power to capture multi-scale information and global patterns to learn the whole-graph features. On the other hand, TSEN also used snowball graph convolution as position embedding in transformer structure, which was a simple yet effective method for capturing local patterns naturally. Results of experiments using four graph classification datasets demonstrated that TSEN outperformed the state-of-the-art typical
    
[^84]: 连接生成半监督学习和生成开放集识别

    Linking generative semi-supervised learning and generative open-set recognition. (arXiv:2303.11702v1 [cs.CV])

    [http://arxiv.org/abs/2303.11702](http://arxiv.org/abs/2303.11702)

    本研究旨在探究生成半监督学习和生成开放集识别之间的关系。SSL-GANs和OSR-GANs方法的相似性在于都要求生成器在互补空间中产生样本，并通过正则化来推广开放空间。研究结果表明SSL优化边缘-GAN在结合SSL-OSR任务方面树立新的标准，但在某些OSR任务中OSR优化的ARP-GAN仍然略优于SSL-GAN。

    

    本研究在生成对抗网络（GANs）的背景下，探究了半监督学习（SSL）和开放集识别（OSR）之间的关系。尽管以前没有正式将SSL和OSR联系起来的研究，但它们各自的方法有惊人的相似之处。具体而言，SSL-GAN和OSR-GAN要求生成器在互补空间中产生样本。随后，通过对生成样本进行正则化，SSL和OSR分类器都可以完全识别开放空间。为了证明SSL和OSR之间的关联，我们在理论上和实验上比较了最先进的SSL-GAN方法和最先进的OSR-GAN方法。结果表明，文献基础更加牢固的SSL优化边缘-GAN在结合SSL-OSR任务方面树立新的标准，并在某些一般的OSR实验中取得了新的最先进的结果。然而，OSR优化的对抗性互惠点（ARP）-GAN在一些OSR任务中仍然略优于SSL-GAN。

    This study investigates the relationship between semi-supervised learning (SSL) and open-set recognition (OSR) in the context of generative adversarial networks (GANs). Although no previous study has formally linked SSL and OSR, their respective methods share striking similarities. Specifically, SSL-GANs and OSR-GANs require generator to produce samples in the complementary space. Subsequently, by regularising networks with generated samples, both SSL and OSR classifiers generalize the open space. To demonstrate the connection between SSL and OSR, we theoretically and experimentally compare state-of-the-art SSL-GAN methods with state-of-the-art OSR-GAN methods. Our results indicate that the SSL optimised margin-GANs, which have a stronger foundation in literature, set the new standard for the combined SSL-OSR task and achieves new state-of-other art results in certain general OSR experiments. However, the OSR optimised adversarial reciprocal point (ARP)-GANs still slightly out-performe
    
[^85]: 检测大型语言模型生成文字的科学

    The Science of Detecting LLM-Generated Texts. (arXiv:2303.07205v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.07205](http://arxiv.org/abs/2303.07205)

    本文综述了现有大型语言模型生成文本检测技术并提出了关键考虑因素，如开发全面评估指标和开源 LLM 所构成的威胁。

    

    大型语言模型 (LLMs) 的出现导致了高度复杂且几乎难以区分出是否为人类创作的 LLM 生成文字。但是，这也引发了对此类文字潜在误用的担忧，例如传播错误信息和在教育系统中造成混乱。尽管已提出许多检测方法，但关于其成就和挑战的全面理解仍然缺乏。本文旨在概述现有的 LLM 生成文本检测技术，并增强对语言生成模型的控制和监管。此外，我们强调未来研究的重要考虑因素，包括开发全面评估指标和开源 LLM 所构成的威胁，以推动 LLM 生成文本检测领域的进展。

    The emergence of large language models (LLMs) has resulted in the production of LLM-generated texts that is highly sophisticated and almost indistinguishable from texts written by humans. However, this has also sparked concerns about the potential misuse of such texts, such as spreading misinformation and causing disruptions in the education system. Although many detection approaches have been proposed, a comprehensive understanding of the achievements and challenges is still lacking. This survey aims to provide an overview of existing LLM-generated text detection techniques and enhance the control and regulation of language generation models. Furthermore, we emphasize crucial considerations for future research, including the development of comprehensive evaluation metrics and the threat posed by open-source LLMs, to drive progress in the area of LLM-generated text detection.
    
[^86]: Tactile-Filter: 用于零部件装配的交互式触觉感知

    Tactile-Filter: Interactive Tactile Perception for Part Mating. (arXiv:2303.06034v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2303.06034](http://arxiv.org/abs/2303.06034)

    本文提出了一种基于视觉的触觉传感器进行零部件装配任务的交互式感知方法，并设计了一个二维粒子滤波器，用于自动搜索新的触觉观察，以最大化其精度。

    

    人类依赖触感和触觉传感器来完成很多巧妙的操作。我们的触觉传感器可以提供关于接触形式以及任何交互中物体的几何信息。出于这个动机，基于视觉的触觉传感器被广泛应用于各种机器人感知和控制任务。本论文提出了一种使用基于视觉的触觉传感器进行零部件装配任务的交互式感知方法，其中机器人可以使用触觉传感器和粒子滤波器的反馈机制，逐步改进其对零部件（销子和孔）的拟合估计，本论文通过训练一个深度神经网络，还设计了一个二维粒子滤波器，来实现机器人自动搜索新的触觉观察，以最大化其精度。

    Humans rely on touch and tactile sensing for a lot of dexterous manipulation tasks. Our tactile sensing provides us with a lot of information regarding contact formations as well as geometric information about objects during any interaction. With this motivation, vision-based tactile sensors are being widely used for various robotic perception and control tasks. In this paper, we present a method for interactive perception using vision-based tactile sensors for a part mating task, where a robot can use tactile sensors and a feedback mechanism using a particle filter to incrementally improve its estimate of objects (pegs and holes) that fit together. To do this, we first train a deep neural network that makes use of tactile images to predict the probabilistic correspondence between arbitrarily shaped objects that fit together. The trained model is used to design a particle filter which is used twofold. First, given one partial (or non-unique) observation of the hole, it incrementally im
    
[^87]: 神经向量场：显式学习的隐式表示

    Neural Vector Fields: Implicit Representation by Explicit Learning. (arXiv:2303.04341v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2303.04341](http://arxiv.org/abs/2303.04341)

    该论文提出了一种新的三维表示方法——神经向量场，结合显式学习和隐式函数表示，可以操纵网格并打破分辨率和拓扑限制。

    

    深度神经网络在三维表面重建中被广泛应用，并可进一步分为两类：通过移动顶点明确传递的明确变形和将三维表面隐式表示为签名或未签名距离函数的方法。利用显式学习过程和隐式函数的强大表示能力，我们提出了一种新的3D表示方法——神经向量场（NVF）。它不仅采用显式学习过程直接操纵网格，还利用未签名距离函数（UDF）的隐式表示方式打破了分辨率和拓扑障碍。

    Deep neural networks (DNNs) are widely applied for nowadays 3D surface reconstruction tasks and such methods can be further divided into two categories, which respectively warp templates explicitly by moving vertices or represent 3D surfaces implicitly as signed or unsigned distance functions. Taking advantage of both advanced explicit learning process and powerful representation ability of implicit functions, we propose a novel 3D representation method, Neural Vector Fields (NVF). It not only adopts the explicit learning process to manipulate meshes directly, but also leverages the implicit representation of unsigned distance functions (UDFs) to break the barriers in resolution and topology. Specifically, our method first predicts the displacements from queries towards the surface and models the shapes as \textit{Vector Fields}. Rather than relying on network differentiation to obtain direction fields as most existing UDF-based methods, the produced vector fields encode the distance a
    
[^88]: LIDA：一种利用大型语言模型自动生成与语法无关的可视化与信息图表的工具

    LIDA: A Tool for Automatic Generation of Grammar-Agnostic Visualizations and Infographics using Large Language Models. (arXiv:2303.02927v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2303.02927](http://arxiv.org/abs/2303.02927)

    LIDA是一种使用大型语言模型和图像生成模型自动生成与语法无关的可视化和信息图表的工具。

    

    支持用户自动创建可视化的系统必须解决多个子任务——理解数据的语义、列举相关的可视化目标以及生成可视化规范。本文将可视化生成视为一个多阶段生成问题，并认为基于大型语言模型（LLM）（例如ChatGPT/GPT-4）和图像生成模型（IGM）的良好编配的管道适合解决这些任务。我们提出了LIDA，一种新型的用于生成与语法无关的可视化和信息图表的工具。LIDA由4个模块组成：SUMMARIZER将数据转换为富但紧凑的自然语言摘要、GOAL EXPLORER在给定数据的情况下列举可视化目标、VISGENERATOR生成、改进、执行和过滤可视化代码，以及INFOGRAPHER使用IGM生成数据忠实的风格化图形。LIDA提供了一个Python API和混合用户界面（直接操作和多模态文本输入），供用户指定数据和问题。我们的实验评估表明，LIDA能够有效地生成有意义且美观的可视化效果。

    Systems that support users in the automatic creation of visualizations must address several subtasks - understand the semantics of data, enumerate relevant visualization goals and generate visualization specifications. In this work, we pose visualization generation as a multi-stage generation problem and argue that well-orchestrated pipelines based on large language models (LLMs) such as ChatGPT/GPT-4 and image generation models (IGMs) are suitable to addressing these tasks. We present LIDA, a novel tool for generating grammar-agnostic visualizations and infographics. LIDA comprises of 4 modules - A SUMMARIZER that converts data into a rich but compact natural language summary, a GOAL EXPLORER that enumerates visualization goals given the data, a VISGENERATOR that generates, refines, executes and filters visualization code and an INFOGRAPHER module that yields data-faithful stylized graphics using IGMs. LIDA provides a python api, and a hybrid user interface (direct manipulation and mu
    
[^89]: "一种适应或灭亡的局面": 游戏行业专业人士对文本生成图像人工智能的感知、采用和使用。

    "An Adapt-or-Die Type of Situation": Perception, Adoption, and Use of Text-To-Image-Generation AI by Game Industry Professionals. (arXiv:2302.12601v3 [cs.HC] UPDATED)

    [http://arxiv.org/abs/2302.12601](http://arxiv.org/abs/2302.12601)

    TTIG模型是创造性人工智能的最新补充，可以根据文本描述生成图像。研究发现，专业人士对于TTIG应用和认知等方面存在12个主要问题。这项研究为支持TTIG的可持续采用提供了重要见解。

    

    文本生成图像(TTIG)模型是创造性人工智能的最新补充。这些模型可根据文本描述生成图像，开始与专业创作者的作品竞争并引发了有关创作工作、失业和版权等重要影响的讨论。为了支持TTIG的可持续采用，我们必须提供专业人士感知、采用和使用TTIG的丰富、可靠和透明的见解。然而，公共辩论浅薄、狭窄且缺乏透明度，学术工作则集中于研究TTIG在一般艺术家人群中的使用，但没有研究特定行业的专业人士的感知和态度。在本文中，我们对芬兰游戏行业进行了一项定性的探索性访谈研究，研究了TTIG的应用。通过对14个游戏专业人士进行的半结构化访谈的模板分析，我们揭示了12个总体主题，结构化成49个子主题，探讨了TTIG的应用和认知等方面的问题。

    Text-to-image generation (TTIG) models, a recent addition to creative AI, can generate images based on a text description. These models have begun to rival the work of professional creatives, and sparked discussions on the future of creative work, loss of jobs, and copyright issues, amongst other important implications. To support the sustainable adoption of TTIG, we must provide rich, reliable and transparent insights into how professionals perceive, adopt and use TTIG. Crucially though, the public debate is shallow, narrow and lacking transparency, while academic work has focused on studying the use of TTIG in a general artist population, but not on the perceptions and attitudes of professionals in a specific industry. In this paper, we contribute a qualitative, exploratory interview study on TTIG in the Finnish videogame industry. Through a Template Analysis on semi-structured interviews with 14 game professionals, we reveal 12 overarching themes, structured into 49 sub-themes on pr
    
[^90]: 图神经网络的等变多项式

    Equivariant Polynomials for Graph Neural Networks. (arXiv:2302.11556v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.11556](http://arxiv.org/abs/2302.11556)

    本文提出了一种基于等变多项式的表达能力层次结构，可以更好的指导GNN的模型改进。通过定义一个具体的基底，全面刻画了所有等变图多项式。此外，我们设计和分析了新的GNN架构，在多个基准数据集上超越了现有的最先进的模型。

    

    图神经网络(GNN)在其表达能力上存在一定限制。最近的重要工作(Xu等，2019；Morris等，2019b)引入了Weisfeiler-Lehman(WL)层次结构作为表达能力的度量标准。虽然这个层次结构推动了GNN分析和架构发展上的显著进展，但它存在着一些显著的限制。其中包括一个复杂的定义，缺乏指导模型改进的直接指导以及一个过于粗糙无法研究当前GNN的WL层次结构。本文介绍了一种基于GNN能够计算特定次数的等变多项式的表达能力层次结构的替代方法。首先，我们通过引入一个具体的基底，显著推广了以前的结果，提供了所有等变图多项式的全面刻画。每个基底元素对应于一个特定的多图，其在某些图数据输入上的计算对应于一个张量收缩问题。其次，我们利用这些等变多项式来定义新的表达能力度量标准，扩展了WL层次结构。我们的度量标准更易于计算，并提供了更精细的信息，可以指导模型改进。最后，我们通过设计和分析新的GNN架构来证明我们方法的有用性，在多个基准数据集上超越了现有的最先进模型。

    Graph Neural Networks (GNN) are inherently limited in their expressive power. Recent seminal works (Xu et al., 2019; Morris et al., 2019b) introduced the Weisfeiler-Lehman (WL) hierarchy as a measure of expressive power. Although this hierarchy has propelled significant advances in GNN analysis and architecture developments, it suffers from several significant limitations. These include a complex definition that lacks direct guidance for model improvement and a WL hierarchy that is too coarse to study current GNNs. This paper introduces an alternative expressive power hierarchy based on the ability of GNNs to calculate equivariant polynomials of a certain degree. As a first step, we provide a full characterization of all equivariant graph polynomials by introducing a concrete basis, significantly generalizing previous results. Each basis element corresponds to a specific multi-graph, and its computation over some graph data input corresponds to a tensor contraction problem. Second, we 
    
[^91]: 减少、重复利用、回收：基于能量扩散模型和MCMC的组合生成

    Reduce, Reuse, Recycle: Compositional Generation with Energy-Based Diffusion Models and MCMC. (arXiv:2302.11552v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.11552](http://arxiv.org/abs/2302.11552)

    该论文提出了一种基于能量扩散模型和MCMC的组合生成方法，旨在解决现有技术在组合生成中的失败问题，并提出了新的成功的解决方案。

    

    自从扩散模型问世以来，它在许多领域中已经迅速成为生成模型的主要方法。它们可以被解释为学习一系列时变的对数概率密度函数的梯度。这种解释已经激发了基于分类器和无分类器指导的思想成为后续控制扩散模型的方法。在这项工作中，我们建立在这些想法的基础上，利用扩散模型的分数-based解释，探索了用于涉及组合生成和指导的条件、修改和重复使用扩散模型的替代方法。特别是，我们调查了为什么某些类型的组合使用当前技术失败，并介绍了一些解决方案。我们得出结论，采样者(而不是模型)对此失败负有责任，并提出了新的采样器，受MCMC的启发，使组合生成成功。此外，我们提出了一种基于能量的扩散模型参数化方法，它使得逼近目标分布更加容易。

    Since their introduction, diffusion models have quickly become the prevailing approach to generative modeling in many domains. They can be interpreted as learning the gradients of a time-varying sequence of log-probability density functions. This interpretation has motivated classifier-based and classifier-free guidance as methods for post-hoc control of diffusion models. In this work, we build upon these ideas using the score-based interpretation of diffusion models, and explore alternative ways to condition, modify, and reuse diffusion models for tasks involving compositional generation and guidance. In particular, we investigate why certain types of composition fail using current techniques and present a number of solutions. We conclude that the sampler (not the model) is responsible for this failure and propose new samplers, inspired by MCMC, which enable successful compositional generation. Further, we propose an energy-based parameterization of diffusion models which enables the 
    
[^92]: 通过认知风险导向策略优化的高效探索

    Efficient Exploration via Epistemic-Risk-Seeking Policy Optimization. (arXiv:2302.09339v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.09339](http://arxiv.org/abs/2302.09339)

    本文提出了一种基于认知风险的新型目标函数，将不确定性转化为价值，鼓励智能体探索未知领域。该方法可以在深度强化学中实现高效探索，即使在函数逼近下也具有保证。

    

    在深度强化学习中，探索仍然是一个关键的挑战。在表格设置中，乐观主义是一种众所周知的启发式方法，具有理论保证，但如何将该原则最好地转化到涉及在线随机梯度和深度网络函数逼近器的深度强化学习中，尚未充分理解。本文提出了一种新的可微乐观目标，当优化时，产生一种可证明有效探索的策略，即使在函数逼近下也具有保证。我们的新目标是一种零和二人博弈，源于赋予代理一个认知风险导向效用函数，将不确定性转化为价值，并鼓励代理人探索不确定状态。我们证明了这个游戏的解决方案最小化了悔恨的一个上界，其中“玩家”各自尝试最小化特定悔恨分解的一个组成部分。我们推导了一种新的无模型算法

    Exploration remains a key challenge in deep reinforcement learning (RL). Optimism in the face of uncertainty is a well-known heuristic with theoretical guarantees in the tabular setting, but how best to translate the principle to deep reinforcement learning, which involves online stochastic gradients and deep network function approximators, is not fully understood. In this paper we propose a new, differentiable optimistic objective that when optimized yields a policy that provably explores efficiently, with guarantees even under function approximation. Our new objective is a zero-sum two-player game derived from endowing the agent with an epistemic-risk-seeking utility function, which converts uncertainty into value and encourages the agent to explore uncertain states. We show that the solution to this game minimizes an upper bound on the regret, with the 'players' each attempting to minimize one component of a particular regret decomposition. We derive a new model-free algorithm which
    
[^93]: 通过梯度分割实现对异构数据的拜占庭容错学习

    Byzantine-Robust Learning on Heterogeneous Data via Gradient Splitting. (arXiv:2302.06079v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.06079](http://arxiv.org/abs/2302.06079)

    这篇论文提出了一种缓解目前健壮算法在非IID环境下表现下降的方法，名为GAS，该方法能够成功将现有的健壮算法用于非IID的数据，并且在真实数据集上有效。

    

    联邦学习对拜占庭攻击具有 vulnerabilities，即攻击者可以向中央服务器发送任意梯度以破坏全局模型的收敛和性能。一些健壮的聚合规则（AGRs）已被提出来以抵御对抗拜占庭攻击。但是，当数据不服从独立同分布（non-IID）时，拜占庭客户端仍然可以规避健壮的 AGRs。本文首先揭示了当前健壮 AGRs 在非IID环境下表现下降的根本原因：维度灾难和梯度异质性。为了解决这个问题，我们提出了 GAS，一种缩短方法，可以成功地将现有的健壮 AGRs 适应于非IID环境。当现有健壮 AGRs 与 GAS 组合时，我们还提供了详细的收敛分析。各种真实数据集上的实验证明了我们提出的 GAS 的有效性。实现代码可在 https://github.com/Y 中找到。

    Federated learning has exhibited vulnerabilities to Byzantine attacks, where the Byzantine attackers can send arbitrary gradients to a central server to destroy the convergence and performance of the global model. A wealth of robust AGgregation Rules (AGRs) have been proposed to defend against Byzantine attacks. However, Byzantine clients can still circumvent robust AGRs when data is non-Identically and Independently Distributed (non-IID). In this paper, we first reveal the root causes of performance degradation of current robust AGRs in non-IID settings: the curse of dimensionality and gradient heterogeneity. In order to address this issue, we propose GAS, a \shorten approach that can successfully adapt existing robust AGRs to non-IID settings. We also provide a detailed convergence analysis when the existing robust AGRs are combined with GAS. Experiments on various real-world datasets verify the efficacy of our proposed GAS. The implementation code is provided in https://github.com/Y
    
[^94]: 多光谱对比学习与Viewmaker网络

    Multispectral Contrastive Learning with Viewmaker Networks. (arXiv:2302.05757v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.05757](http://arxiv.org/abs/2302.05757)

    本文研究将对比学习方法应用于各种遥感数据集。通过使用Viewmaker网络，本文发现该方法可以在不耗费大量时间和领域知识的情况下成功产生视图，并在四个多光谱成像问题上实现优于基于裁剪和反射的对比学习方法的表现。

    

    对比学习方法已广泛应用于各领域和模态，通过训练模型识别数据点的相似“视图”。然而，专业的科学模态对这种范式 pose challenge，因为为每个科学仪器识别好的视图是复杂和耗时的。在这篇论文中，我们专注于将对比学习方法应用于各种遥感数据集。我们展示了Viewmaker网络，这是一种最近提出的生成视图的方法，很有前途地能够在不需要大量领域知识和试错的情况下在这一领域内产生视图。我们将Viewmaker应用于四个多光谱成像问题，每个问题具有不同的格式，发现在下游分类任务的评估中，在每种情况下Viewmaker都可以优于基于裁剪和反射的对比学习方法。这进一步证明了领域不可知的方法可以使对比学习扩展到实际的科学应用规模。

    Contrastive learning methods have been applied to a range of domains and modalities by training models to identify similar "views" of data points. However, specialized scientific modalities pose a challenge for this paradigm, as identifying good views for each scientific instrument is complex and time-intensive. In this paper, we focus on applying contrastive learning approaches to a variety of remote sensing datasets. We show that Viewmaker networks, a recently proposed method for generating views, are promising for producing views in this setting without requiring extensive domain knowledge and trial and error. We apply Viewmaker to four multispectral imaging problems, each with a different format, finding that Viewmaker can outperform croppingand reflection-based methods for contrastive learning in every case when evaluated on downstream classification tasks. This provides additional evidence that domain-agnostic methods can empower contrastive learning to scale to real-world scie
    
[^95]: 可控性感知的无监督技能发现

    Controllability-Aware Unsupervised Skill Discovery. (arXiv:2302.05103v3 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2302.05103](http://arxiv.org/abs/2302.05103)

    本文提出了一种新的可控性感知的无监督技能发现方法，通过联合训练的距离函数降低简单易实现技能的奖励，逐步学习更具挑战性的技能。

    

    智能代理的关键能力之一是在没有外部监督的情况下发现有用的技能。然而，目前的无监督技能发现方法往往只能获得简单、易学的技能，因为缺乏发现更复杂、有挑战性行为的动机。我们引入了一种新的无监督技能发现方法，可控性感知技能发现（CSD），它可以在没有监督的情况下主动寻找复杂、难以控制的技能。CSD的关键组成部分是可控性感知距离函数，它给当前技能实现更难的状态转换分配更大的值。与距离最大化的技能发现结合起来，CSD在训练过程中逐步学习更具挑战性的技能，因为我们联合训练的距离函数降低了简单易实现技能的奖励。我们在六个机器人操作和运动环境中的实验结果表明，CSD可以发现各种不同的复杂技能，胜过现有的无监督技能发现方法。

    One of the key capabilities of intelligent agents is the ability to discover useful skills without external supervision. However, the current unsupervised skill discovery methods are often limited to acquiring simple, easy-to-learn skills due to the lack of incentives to discover more complex, challenging behaviors. We introduce a novel unsupervised skill discovery method, Controllability-aware Skill Discovery (CSD), which actively seeks complex, hard-to-control skills without supervision. The key component of CSD is a controllability-aware distance function, which assigns larger values to state transitions that are harder to achieve with the current skills. Combined with distance-maximizing skill discovery, CSD progressively learns more challenging skills over the course of training as our jointly trained distance function reduces rewards for easy-to-achieve skills. Our experimental results in six robotic manipulation and locomotion environments demonstrate that CSD can discover diver
    
[^96]: 零样本协同合作学习框架的合作开放式学习

    Cooperative Open-ended Learning Framework for Zero-shot Coordination. (arXiv:2302.04831v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2302.04831](http://arxiv.org/abs/2302.04831)

    该论文提出了一个COLE框架，通过构建合作游戏的开放式目标，从图论的角度评估和确定每个策略的协作能力，以有效地解决零样本协调中的合作不兼容性问题。

    

    协作人工智能中的零样本协调仍然是一个重大挑战，有效地协调一系列看不见的合作伙伴。先前的算法试图通过优化种群中的固定目标来改善策略或行为的多样性来解决这一挑战。然而，这些方法可能导致学习损失和与种群中某些策略无法合作，即合作不兼容性。为了解决这个问题，我们提出了合作开放式学习（COLE）框架，该框架从图论的角度构建了协作游戏的开放式目标，以评估和确定每个策略的协作能力。我们进一步明确了框架并提出了一种实用的算法，该算法利用了博弈论和图论的知识。此外，对算法的学习过程进行的分析显示，它可以有效地克服学习困难。

    Zero-shot coordination in cooperative artificial intelligence (AI) remains a significant challenge, which means effectively coordinating with a wide range of unseen partners. Previous algorithms have attempted to address this challenge by optimizing fixed objectives within a population to improve strategy or behaviour diversity. However, these approaches can result in a loss of learning and an inability to cooperate with certain strategies within the population, known as cooperative incompatibility. To address this issue, we propose the Cooperative Open-ended LEarning (COLE) framework, which constructs open-ended objectives in cooperative games with two players from the perspective of graph theory to assess and identify the cooperative ability of each strategy. We further specify the framework and propose a practical algorithm that leverages knowledge from game theory and graph theory. Furthermore, an analysis of the learning process of the algorithm shows that it can efficiently overc
    
[^97]: 可预测的MDP抽象用于无监督的基于模型的强化学习

    Predictable MDP Abstraction for Unsupervised Model-Based RL. (arXiv:2302.03921v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.03921](http://arxiv.org/abs/2302.03921)

    该论文提出了可预测的MDP抽象方法，通过无监督学习将原始MDP转换为学习行动空间，使模型学习变得更加准确和稳定，在多项任务上得到了验证。

    

    模型化强化学习（RL）的一个关键组件是一个能预测行动结果的动态模型。预测模型中的错误会降低模型化控制器的性能，复杂的马尔可夫决策过程（MDPs）可能会带来极其困难的预测问题。为了缓解这个问题，我们提出了可预测的MDP抽象（PMA）：不是在原始MDP上训练预测模型，而是在一个转换后的具有学习行动空间的MDP上训练模型，该行动空间只允许可预测、易建模的行动，同时尽可能地覆盖原始状态-行动空间。结果是，模型学习变得更加容易和准确，这允许鲁棒、稳定的基于模型的规划或基于模型的RL。这种转换是以无监督的方式学习的，在用户指定任何任务之前。随后，下游任务可以以零-shot方式通过模型化控制解决，而无需额外的环境交互。我们从理论上证明了方法的有效性，并在多个任务上进行了实验验证。

    A key component of model-based reinforcement learning (RL) is a dynamics model that predicts the outcomes of actions. Errors in this predictive model can degrade the performance of model-based controllers, and complex Markov decision processes (MDPs) can present exceptionally difficult prediction problems. To mitigate this issue, we propose predictable MDP abstraction (PMA): instead of training a predictive model on the original MDP, we train a model on a transformed MDP with a learned action space that only permits predictable, easy-to-model actions, while covering the original state-action space as much as possible. As a result, model learning becomes easier and more accurate, which allows robust, stable model-based planning or model-based RL. This transformation is learned in an unsupervised manner, before any task is specified by the user. Downstream tasks can then be solved with model-based control in a zero-shot fashion, without additional environment interactions. We theoretical
    
[^98]: ANTM: 一种对齐的神经主题模型，用于探索演变的主题

    ANTM: An Aligned Neural Topic Model for Exploring Evolving Topics. (arXiv:2302.01501v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2302.01501](http://arxiv.org/abs/2302.01501)

    ANTM是一种对齐的神经主题模型，它利用重叠滑动窗口算法来维护演变主题的时间连续性，并通过对语义相似的文档进行对齐来捕捉出现和消退的趋势。实验证明ANTM在主题连贯性和多样性方面优于传统动态主题模型。

    

    本文提出了一种称为对齐神经主题模型（ANTM）的动态主题模型算法家族，它结合了新颖的数据挖掘算法，提供了一个模块化框架，用于发现演变的主题。ANTM利用先进的预训练大型语言模型从文档中提取时间感知特征，并使用重叠滑动窗口算法进行顺序文档聚类，从而维护了演变主题的时间连续性。这种重叠滑动窗口算法在每个时间框架内标识不同数量的主题，并在时间段内对语义相似的文档聚类进行对齐。这个过程捕捉了不同时期出现和消退的趋势，并允许更具可解释性的演变主题表示。针对四个不同数据集的实验表明，ANTM在主题连贯性和多样性指标方面优于概率动态主题模型。此外，它改善了动态主题建模的可扩展性和灵活性。

    This paper presents an algorithmic family of dynamic topic models called Aligned Neural Topic Models (ANTM), which combine novel data mining algorithms to provide a modular framework for discovering evolving topics. ANTM maintains the temporal continuity of evolving topics by extracting time-aware features from documents using advanced pre-trained Large Language Models (LLMs) and employing an overlapping sliding window algorithm for sequential document clustering. This overlapping sliding window algorithm identifies a different number of topics within each time frame and aligns semantically similar document clusters across time periods. This process captures emerging and fading trends across different periods and allows for a more interpretable representation of evolving topics. Experiments on four distinct datasets show that ANTM outperforms probabilistic dynamic topic models in terms of topic coherence and diversity metrics. Moreover, it improves the scalability and flexibility of dy
    
[^99]: 反升级与概括：一份调查报告

    Anti-unification and Generalization: A Survey. (arXiv:2302.00277v3 [cs.LO] UPDATED)

    [http://arxiv.org/abs/2302.00277](http://arxiv.org/abs/2302.00277)

    反升级或概括是归纳推理中使用的基本操作，是定理证明的双重操作之一。该调查报告对反升级的研究和应用进行了系统归纳和总结。

    

    反升级（AU）又称概括，是归纳推理中使用的基本操作，是定理证明基础上的双重操作之一。 AI和相关社区对AU的兴趣日益增长，但没有系统研究该概念，也没有现有工作的调查，调查往往会采用特定于应用的方法，而这些方法可能已经被现有方法覆盖。我们提供了第一份有关AU研究及其应用的调查报告，以及一种将现有和未来发展分类的通用框架。

    Anti-unification (AU), also known as generalization, is a fundamental operation used for inductive inference and is the dual operation to unification, an operation at the foundation of theorem proving. Interest in AU from the AI and related communities is growing, but without a systematic study of the concept, nor surveys of existing work, investigations7 often resort to developing application-specific methods that may be covered by existing approaches. We provide the first survey of AU research and its applications, together with a general framework for categorizing existing and future developments.
    
[^100]: 弹性输入序列的自适应计算

    Adaptive Computation with Elastic Input Sequence. (arXiv:2301.13195v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.13195](http://arxiv.org/abs/2301.13195)

    本文介绍了一种名为AdaTape的新方法，通过自适应磁带符号，允许神经网络进行动态计算，能够实现适应不同类型信息的自适应计算，在图像分类、语言建模和程序综合等多个任务中都表现出更好的性能。

    

    人类有能力在解决问题时适应不同类型的信息、不同的处理方法和不同的时间花费。然而，大部分标准神经网络无论样本的性质或难度都有固定的函数类型和计算预算。自适应计算是一种强大的范式，因为它不仅赋予从业者灵活性，而且还可以作为解决某些具有挑战性的问题的强大归纳偏差。在本文中，我们介绍了一种名为AdaTape的新方法，通过自适应磁带符号，允许神经网络进行动态计算。AdaTape利用弹性输入序列，通过装备带有动态读写磁带的架构来实现。具体来说，我们使用来自磁带库的磁带符号来自适应生成输入序列，这些符号可训练或从输入数据中派生。我们研究了获得动态序列计算所需的挑战和要求，以及AdaTape的性质。我们的实验表明，AdaTape能够学习自适应计算策略，从而在几个基准任务（包括图像分类、语言建模和程序综合）上实现更好的性能。

    Humans have the ability to adapt the type of information they use, the procedure they employ, and the amount of time they spend when solving problems. However, most standard neural networks have a fixed function type and computation budget regardless of the sample's nature or difficulty. Adaptivity is a powerful paradigm as it not only imbues practitioners with flexibility pertaining to the downstream usage of these models but can also serve as a powerful inductive bias for solving certain challenging classes of problems. In this work, we introduce a new approach called AdaTape, which allows for dynamic computation in neural networks through adaptive tape tokens. AdaTape utilizes an elastic input sequence by equipping an architecture with a dynamic read-and-write tape. Specifically, we adaptively generate input sequences using tape tokens obtained from a tape bank which can be either trainable or derived from input data. We examine the challenges and requirements to obtain dynamic sequ
    
[^101]: 与人类表征的一致性支持鲁棒的少样本学习

    Alignment with human representations supports robust few-shot learning. (arXiv:2301.11990v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.11990](http://arxiv.org/abs/2301.11990)

    论文提出少样本学习的表现与人类表征的一致性存在U形关系，并通过计算机视觉模型的实验进行了验证。高度对齐的模型更加鲁棒，对数据的利用更加有效，但与人类对齐并非必要条件。

    

    我们是否应该关心AI系统是否具有与人类相似的世界表征？我们提供了一个信息论分析，建议在少样本学习任务的表现度与人类表征的一致性之间应该存在一个U形关系。我们通过对491个计算机视觉模型的性能分析验证了这个预测的可行性，并且表明高度对齐的模型更加鲁棒于对抗攻击和域偏移。我们的结果表明，与人类对齐往往是模型有效利用有限数据、鲁棒性 以及泛化能力的充分但不必要条件。

    Should we care whether AI systems have representations of the world that are similar to those of humans? We provide an information-theoretic analysis that suggests that there should be a U-shaped relationship between the degree of representational alignment with humans and performance on few-shot learning tasks. We confirm this prediction empirically, finding such a relationship in an analysis of the performance of 491 computer vision models. We also show that highly-aligned models are more robust to both adversarial attacks and domain shifts. Our results suggest that human-alignment is often a sufficient, but not necessary, condition for models to make effective use of limited data, be robust, and generalize well.
    
[^102]: 深度强化学习中的自动内在奖励塑造探索方法研究

    Automatic Intrinsic Reward Shaping for Exploration in Deep Reinforcement Learning. (arXiv:2301.10886v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.10886](http://arxiv.org/abs/2301.10886)

    本文提出了一种名为AIRS的自动内在奖励塑造探索方法，可以提供高质量的内在激励以增强强化学习中的探索性能；并开发了高效可靠的内在奖励工具包。实验表明，AIRS性能卓越，能够胜过基准方案。

    

    本文提出了一种名为AIRS的自动内在奖励塑造方法，通过智能和适应性的塑造函数，提供高质量的内在激励以增强强化学习中的探索性能。AIRS可以根据实时估计的任务回报从预定义的函数集中选择塑造函数，提供可靠的探索激励并解决偏置目标问题。此外，我们开发了一个内在奖励工具包，提供多种内在奖励方法的高效可靠实现方式。我们将AIRS应用在MiniGrid、Procgen和DeepMind控制套件的多项任务中进行测试。大量仿真结果表明，AIRS可以胜过基准方案，并具有简单的架构和卓越的性能。

    We present AIRS: Automatic Intrinsic Reward Shaping that intelligently and adaptively provides high-quality intrinsic rewards to enhance exploration in reinforcement learning (RL). More specifically, AIRS selects shaping function from a predefined set based on the estimated task return in real-time, providing reliable exploration incentives and alleviating the biased objective problem. Moreover, we develop an intrinsic reward toolkit to provide efficient and reliable implementations of diverse intrinsic reward approaches. We test AIRS on various tasks of MiniGrid, Procgen, and DeepMind Control Suite. Extensive simulation demonstrates that AIRS can outperform the benchmarking schemes and achieve superior performance with simple architecture.
    
[^103]: ExaRanker: 解释增强型神经排序模型

    ExaRanker: Explanation-Augmented Neural Ranker. (arXiv:2301.10521v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.10521](http://arxiv.org/abs/2301.10521)

    本文提出了一个名为ExaRanker的解释增强型神经排序模型，使用大型语言模型增强检索数据集，可在输出相关度标签与解释时提高性能。

    

    最近的研究表明，让大型语言模型在输出答案前生成解释是提高各种推理任务性能的有效策略。本文提出神经排序模型也受益于解释。我们使用GPT-3.5等语言模型来增强具有解释的检索数据集，并训练一个序列到序列的排序模型，以输出给定查询-文档对的相关度标签和解释。我们的模型被称为ExaRanker，在使用合成解释的几千个样本进行微调后，性能与无解释的3倍样本微调的模型相当。此外，ExaRanker模型在排序过程中没有额外的计算成本，并允许根据需要请求解释。

    Recent work has shown that inducing a large language model (LLM) to generate explanations prior to outputting an answer is an effective strategy to improve performance on a wide range of reasoning tasks. In this work, we show that neural rankers also benefit from explanations. We use LLMs such as GPT-3.5 to augment retrieval datasets with explanations and train a sequence-to-sequence ranking model to output a relevance label and an explanation for a given query-document pair. Our model, dubbed ExaRanker, finetuned on a few thousand examples with synthetic explanations performs on par with models finetuned on 3x more examples without explanations. Furthermore, the ExaRanker model incurs no additional computational cost during ranking and allows explanations to be requested on demand.
    
[^104]: 预计算内存或实时编码？一种检索增强的混合方法使计算资源得到最大利用

    Pre-computed memory or on-the-fly encoding? A hybrid approach to retrieval augmentation makes the most of your compute. (arXiv:2301.10448v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.10448](http://arxiv.org/abs/2301.10448)

    本文提出了一种检索增强的混合方法，LUMEN，它预先计算大部分检索表示，并使用一个实时编码器进行完成编码，相较于纯内存和FiD，LUMEN在多个问答任务中具有更好的性能，且成本更低。

    

    检索增强语言模型，如解码器中的Fusion，具有强大的能力，在各种知识密集型任务中设置了最新的技术水平。然而，由于需要对大量检索到的段落进行编码，它们也非常昂贵。一些工作通过将文本语料库预编码为内存，并直接检索密集表示来避免这种成本。但是，预编码内存会导致严重的质量惩罚，因为内存表示未针对当前输入进行调整。我们提出了LUMEN，它是这两个极端之间的混合体，预先计算大部分检索表示，并使用实时编码器完成编码，该实时编码器是基于问题进行条件化的，并为任务进行了微调。我们表明，在多个问答任务中，LUMEN明显优于纯内存，同时比FiD便宜得多，并且在给定的计算资源预算下，LUMEN的效果优于两者。此外，当模型规模增大时，LUMEN相对于FiD的优势也增加。

    Retrieval-augmented language models such as Fusion-in-Decoder are powerful, setting the state of the art on a variety of knowledge-intensive tasks. However, they are also expensive, due to the need to encode a large number of retrieved passages. Some work avoids this cost by pre-encoding a text corpus into a memory and retrieving dense representations directly. However, pre-encoding memory incurs a severe quality penalty as the memory representations are not conditioned on the current input. We propose LUMEN, a hybrid between these two extremes, pre-computing the majority of the retrieval representation and completing the encoding on the fly using a live encoder that is conditioned on the question and fine-tuned for the task. We show that LUMEN significantly outperforms pure memory on multiple question-answering tasks while being much cheaper than FiD, and outperforms both for any given compute budget. Moreover, the advantage of LUMEN over FiD increases with model size.
    
[^105]: 一种用于未知隧道建设场地的基于视觉的自主无人机视检测框架（更新版）

    A vision-based autonomous UAV inspection framework for unknown tunnel construction sites with dynamic obstacles. (arXiv:2301.08422v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2301.08422](http://arxiv.org/abs/2301.08422)

    本文提出了一种基于视觉的无人机视检测框架，用于动态隧道环境而无需使用先前的地图，通过分层规划方案将检测问题分解成不同层次，实现了最大化的自主水平。

    

    基于钻炸法的隧道建设需要对挖掘前部位进行三维测量以评估压碎位置。为了考虑检测和测量任务的安全、成本和效益，部署轻便的自主机器人，如无人机（UAV），变得更加必要和普遍。大多数先前的工作都使用先前的地图进行检验视点的确定并没有考虑动态障碍物。为了最大限度地增加自主水平，本文提出了一种基于视觉的无人机视检测框架，用于动态隧道环境而无需使用先前的地图。我们的方法利用分层规划方案将检测问题分解成不同层次。高层决策者首先确定机器人的任务并生成目标点。然后，中层路径规划器找到途径点路径并优化免碰撞静态轨迹。最后，静态轨迹将输入低层控制器以实现控制。

    Tunnel construction using the drill-and-blast method requires the 3D measurement of the excavation front to evaluate underbreak locations. Considering the inspection and measurement task's safety, cost, and efficiency, deploying lightweight autonomous robots, such as unmanned aerial vehicles (UAV), becomes more necessary and popular. Most of the previous works use a prior map for inspection viewpoint determination and do not consider dynamic obstacles. To maximally increase the level of autonomy, this paper proposes a vision-based UAV inspection framework for dynamic tunnel environments without using a prior map. Our approach utilizes a hierarchical planning scheme, decomposing the inspection problem into different levels. The high-level decision maker first determines the task for the robot and generates the target point. Then, the mid-level path planner finds the waypoint path and optimizes the collision-free static trajectory. Finally, the static trajectory will be fed into the low-
    
[^106]: 演化路径追踪器: 加密货币中恶意地址的早期检测

    Evolve Path Tracer: Early Detection of Malicious Addresses in Cryptocurrency. (arXiv:2301.05412v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2301.05412](http://arxiv.org/abs/2301.05412)

    本文提出了演化路径追踪器，通过提出资产转移路径和相应的路径图表征早期交易模式，并使用演化路径编码器 LSTM 和演化路径图 GCN 在演化结构设置下编码资产转移路径和路径图，以及分层生存预测器进一步预测目标地址是否会成为恶意地址，成功实现了加密货币中恶意地址的早期检测。

    

    随着加密货币的不断增长，检测欺诈行为和相关的恶意地址引起了重要的研究努力。然而，大部分现有研究仍然依赖于完整的历史交易记录或完整的地址交易网络，因此不能满足早期恶意地址检测的要求，这在现有研究中很少讨论。为了在早期发现恶意地址的欺诈行为，我们提出了演化路径追踪器，它由演化路径编码器 LSTM、演化路径图 GCN 和分层生存预测器组成。具体而言，除了一般的地址特征外，我们提出资产转移路径和相应的路径图以表征早期交易模式。此外，由于交易模式在早期阶段正在快速变化，我们提出了演化路径编码器 LSTM 和演化路径图 GCN 在演化结构设置下编码资产转移路径和路径图。分层生存预测器进一步预测目标地址是否会成为恶意地址。两个真实世界数据集的大量实验表明，演化路径追踪器在早期检测恶意地址方面优于现有的最新方法。

    With the ever-increasing boom of Cryptocurrency, detecting fraudulent behaviors and associated malicious addresses draws significant research effort. However, most existing studies still rely on the full history features or full-fledged address transaction networks, thus cannot meet the requirements of early malicious address detection, which is urgent but seldom discussed by existing studies. To detect fraud behaviors of malicious addresses in the early stage, we present Evolve Path Tracer, which consists of Evolve Path Encoder LSTM, Evolve Path Graph GCN, and Hierarchical Survival Predictor. Specifically, in addition to the general address features, we propose asset transfer paths and corresponding path graphs to characterize early transaction patterns. Further, since the transaction patterns are changing rapidly during the early stage, we propose Evolve Path Encoder LSTM and Evolve Path Graph GCN to encode asset transfer path and path graph under an evolving structure setting. Hiera
    
[^107]: 在无偏学习排序中解离关联性和偏差性的追求

    Towards Disentangling Relevance and Bias in Unbiased Learning to Rank. (arXiv:2212.13937v4 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2212.13937](http://arxiv.org/abs/2212.13937)

    该论文描述了在无偏学习排序中解离关联性和偏差性的重要性，并提出了对解决这个问题的三种方法。

    

    无偏学习排序(ULTR)研究的问题在于从隐含的用户反馈数据（如点击）中减轻各种偏差性的影响，并且最近受到了相当大的关注。一种用于实际应用的流行ULTR方法是使用双塔结构，其中将点击建模分解为一个具有常规输入特征的关联塔和一个具有偏差相关输入（如文件位置）的偏差塔。成功的分解将允许关联塔免受偏差的影响。在这项工作中，我们发现了现有ULTR方法忽略的一个关键问题——通过底层真实关联性，偏差塔可能会与关联塔混淆。特别是，位置是由记录策略（即以前的生产模型）确定的，它将具有关联信息。我们给出了理论分析和实证结果，以展示由于这种相关性对于关联塔的负面影响。然后，我们提出了三种方法来解决这个问题。

    Unbiased learning to rank (ULTR) studies the problem of mitigating various biases from implicit user feedback data such as clicks, and has been receiving considerable attention recently. A popular ULTR approach for real-world applications uses a two-tower architecture, where click modeling is factorized into a relevance tower with regular input features, and a bias tower with bias-relevant inputs such as the position of a document. A successful factorization will allow the relevance tower to be exempt from biases. In this work, we identify a critical issue that existing ULTR methods ignored - the bias tower can be confounded with the relevance tower via the underlying true relevance. In particular, the positions were determined by the logging policy, i.e., the previous production model, which would possess relevance information. We give both theoretical analysis and empirical results to show the negative effects on relevance tower due to such a correlation. We then propose three method
    
[^108]: Z-ICL: 使用伪样本进行零样本视角下的上下文学习

    Z-ICL: Zero-Shot In-Context Learning with Pseudo-Demonstrations. (arXiv:2212.09865v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09865](http://arxiv.org/abs/2212.09865)

    本文提出了一种新的零样本上下文学习方法Z-ICL，通过构建基于原始文本的伪演示，显著提升了模型的零样本性能水平，同时支持未来优化伪演示提高上下文学习表现而无需标记数据。

    

    虽然大型语言模型可以进行零样本和少样本学习，但当没有提供演示时，性能会显著下降。本文提出了一种新的零样本方法Z-ICL，在给定测试输入的情况下，使用原始文本语料库构建伪演示。具体地，伪演示是通过 (1) 从语料库中找到与测试输入最相近的邻居，并将它们与随机任务标签配对，以及 (2) 应用一组技术来减少模型从生成的演示中直接复制的数量来构建的。在九个分类数据集上的评估表明，Z-ICL 的表现显著优于以前的零样本方法，并在少样本设置中与使用有标记训练数据的上下文学习方法相当。总的来说，Z-ICL 提供了一个显著更高的模型零样本性能水平估计，并支持未来努力发展更好的伪演示来提高上下文学习而无需任何有标记数据。

    Although large language models can be prompted for both zero- and few-shot learning, performance drops significantly when no demonstrations are available. In this paper, we introduce Z-ICL, a new zero-shot method that closes the gap by constructing pseudo-demonstrations for a given test input using a raw text corpus. Concretely, pseudo-demonstrations are constructed by (1) finding the nearest neighbors to the test input from the corpus and pairing them with random task labels, and (2) applying a set of techniques to reduce the amount of direct copying the model does from the resulting demonstrations. Evaluation on nine classification datasets shows that Z-ICL outperforms previous zero-shot methods by a significant margin, and is on par with in-context learning with labeled training data in the few-shot setting. Overall, Z-ICL provides a significantly higher estimate of the zero-shot performance levels of a model, and supports future efforts to develop better pseudo-demonstrations that 
    
[^109]: NusaCrowd：印尼自然语言处理资源的开源倡议

    NusaCrowd: Open Source Initiative for Indonesian NLP Resources. (arXiv:2212.09648v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09648](http://arxiv.org/abs/2212.09648)

    NusaCrowd是一个印尼自然语言处理资源的开源倡议，已汇集137个数据集和118个数据加载程序，为印尼语和印度尼西亚本地语言的自然语言处理研究提供了多种实验手段。

    

    我们提出了NusaCrowd，这是一个协作倡议，旨在收集和统一印尼语言的现有资源，包括开放以前非公开的资源。通过该倡议，我们汇集了137个数据集和118个标准化数据加载程序。数据集的质量已经经过手动和自动评估，它们的价值通过多个实验得到了证明。NusaCrowd的数据收集使得可以创建印尼语和印度尼西亚本地语言的零样本自然语言理解和生成基准，进一步推动了印尼语和印度尼西亚本地语言的多语言自动语音识别基准的创建。我们的工作致力于推进对在使用广泛的语言的自然语言处理（NLP）研究的发展，从而使之受到更多关注。

    We present NusaCrowd, a collaborative initiative to collect and unify existing resources for Indonesian languages, including opening access to previously non-public resources. Through this initiative, we have brought together 137 datasets and 118 standardized data loaders. The quality of the datasets has been assessed manually and automatically, and their value is demonstrated through multiple experiments. NusaCrowd's data collection enables the creation of the first zero-shot benchmarks for natural language understanding and generation in Indonesian and the local languages of Indonesia. Furthermore, NusaCrowd brings the creation of the first multilingual automatic speech recognition benchmark in Indonesian and the local languages of Indonesia. Our work strives to advance natural language processing (NLP) research for languages that are under-represented despite being widely spoken.
    
[^110]: APOLLO：面向逻辑推理的语言模型自适应预训练的简单方法

    APOLLO: A Simple Approach for Adaptive Pretraining of Language Models for Logical Reasoning. (arXiv:2212.09282v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09282](http://arxiv.org/abs/2212.09282)

    本文提出了APOLLO，一种适应性预训练语言模型，通过选择特定的Wikipedia子集进行预训练，并使用两个自监督损失函数，成功地提高了模型的逻辑推理能力。

    

    文本的逻辑推理是一种重要的能力，需要理解文本中存在的信息、它们的相互联系，然后通过它们来推断新的结论。本文提出了APOLLO，一种适应性预训练语言模型，具有改进的逻辑推理能力。我们选择了Wikipedia的子集进行预训练，基于一组逻辑推理关键词。我们使用两个自监督损失函数：修改过的掩码语言建模损失只对可能需要更多推理而不仅仅是基本语言理解的特定词性的单词进行掩码，以及句子级分类损失，教导模型区分逻辑上连接和不连接的句子。我们的实验表明，APOLLO在多个逻辑推理数据集上优于最先进的语言模型，而不损失其在其他语言任务上的性能。

    Logical reasoning of text is an important ability that requires understanding the information present in the text, their interconnections, and then reasoning through them to infer new conclusions. Prior works on improving the logical reasoning ability of language models require complex processing of training data (e.g., aligning symbolic knowledge to text), yielding task-specific data augmentation solutions that restrict the learning of general logical reasoning skills. In this work, we propose APOLLO, an adaptively pretrained language model that has improved logical reasoning abilities. We select a subset of Wikipedia, based on a set of logical inference keywords, for continued pretraining of a language model. We use two self-supervised loss functions: a modified masked language modeling loss where only specific parts-of-speech words, that would likely require more reasoning than basic language understanding, are masked, and a sentence-level classification loss that teaches the model 
    
[^111]: 图学习及其应用：一篇全面的综述

    Graph Learning and Its Applications: A Holistic Survey. (arXiv:2212.08966v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2212.08966](http://arxiv.org/abs/2212.08966)

    本文全面综述了图学习的发展历程和应用场景，重点介绍了表示学习在文本、图像、化学和生物等领域中的显著性能，同时指出了对以前有价值的工作进行调查的需求。

    This paper provides a comprehensive survey of the development and application scenarios of graph learning, with a focus on the remarkable performance of representation learning in various fields such as text, image, chemistry, and biology. It also points out the need to investigate previous valuable works.

    图学习是一种广泛应用的领域，旨在学习节点之间的复杂关系和图的拓扑结构。这些关系使得图与传统的表格数据相比具有独特性，因为节点依赖于非欧几里得空间，并包含丰富的信息可供利用。随着表示学习的出现，图学习在文本、图像、化学和生物等各种场景中取得了显著的性能。由于其广泛的应用前景，图学习吸引了学术界的大量关注。尽管已经有许多工作提出了解决图学习中不同问题的方法，但需要对以前有价值的工作进行调查。虽然一些研究人员已经意识到了这一现象，并在图学习方面完成了令人印象深刻的调查，但他们未能以更连贯的方式连接相关的目标、方法和应用。

    Graph learning is a prevalent domain that endeavors to learn the intricate relationships among nodes and the topological structure of graphs. These relationships endow graphs with uniqueness compared to conventional tabular data, as nodes rely on non-Euclidean space and encompass rich information to exploit. Over the years, graph learning has transcended from graph theory to graph data mining. With the advent of representation learning, it has attained remarkable performance in diverse scenarios, including text, image, chemistry, and biology. Owing to its extensive application prospects, graph learning attracts copious attention from the academic community. Despite numerous works proposed to tackle different problems in graph learning, there is a demand to survey previous valuable works. While some researchers have perceived this phenomenon and accomplished impressive surveys on graph learning, they failed to connect related objectives, methods, and applications in a more coherent way.
    
[^112]: FiDO：针对更强的性能和更快的推理进行优化的解码器融合模型

    FiDO: Fusion-in-Decoder optimized for stronger performance and faster inference. (arXiv:2212.08153v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.08153](http://arxiv.org/abs/2212.08153)

    这项研究提出了一种名为FiDO的解码器融合模型，通过两个简单的更改，有效缓解了内存带宽约束，加快了模型的推理速度，大大提高了模型性能，达到了领先水平。

    

    Fusion-in-Decoder (FiD)是一种强大的检索增强语言模型，在许多知识密集型NLP任务上树立了业界标杆。但是，FiD所使用的架构是通过对标准T5模型做最小修改而选择的，我们的分析表明这对于一个检索增强模型来说是高度不优化的。特别地，FiD将大部分FLOPs分配给了编码器，而大多数推理时间是由于解码器中的内存带宽限制。我们提出了两个简单的更改，以缓解内存带宽约束，并使推理速度提高7倍。这使我们能够以适度的成本使用更大的解码器。我们将经过上述修改的FiD称为FiDO，并展示它在广泛的推理预算范围内比现有的FiD模型显著地提高了性能。例如，FiDO-Large-XXL比FiD-Base进行更快的推理，并实现了比FiD-Large更好的性能。

    Fusion-in-Decoder (FiD) is a powerful retrieval-augmented language model that sets the state-of-the-art on many knowledge-intensive NLP tasks. However, the architecture used for FiD was chosen by making minimal modifications to a standard T5 model, which our analysis shows to be highly suboptimal for a retrieval-augmented model. In particular, FiD allocates the bulk of FLOPs to the encoder, while the majority of inference time results from memory bandwidth constraints in the decoder. We propose two simple changes to the FiD architecture to alleviate memory bandwidth constraints, and speed up inference by 7x. This allows us to use a much larger decoder at modest cost. We denote FiD with the above modifications as FiDO, and show that it strongly improves performance over existing FiD models for a wide range of inference budgets. For example, FiDO-Large-XXL performs faster inference than FiD-Base and achieves better performance than FiD-Large.
    
[^113]: 利用鉴别器引导在基于评分的扩散模型中完善生成过程

    Refining Generative Process with Discriminator Guidance in Score-based Diffusion Models. (arXiv:2211.17091v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.17091](http://arxiv.org/abs/2211.17091)

    本文提出了“鉴别器引导”方法，通过在评分训练之后训练鉴别器，使模型评估更加准确，从而改善预训练扩散模型的样本生成。在 ImageNet 256x256 数据集上实现了 FID 1.83 和召回率 0.64 的最新结果，类似于验证数据的 FID 和召回率。

    

    本文提出的“鉴别器引导”方法旨在改善预训练扩散模型的样本生成。该方法引入了一个鉴别器，明确地监督去噪样本路径是否真实。与 GAN 不同的是，我们的方法不需要联合训练评分和鉴别器网络。相反，在评分训练之后训练鉴别器，使鉴别器训练稳定且快速收敛。在样本生成中，我们向预训练的评分添加一个辅助项以欺骗鉴别器。该项将模型评分矫正为最优鉴别器处的数据评分，这意味着鉴别器以补充的方式帮助更好地评估分数。使用我们的算法，在 ImageNet 256x256 上实现了 FID 1.83 和召回率 0.64 的最新结果，类似于验证数据的 FID（1.68）和召回率（0.66）。我们在 https://github.com/alsdudrla10/DG 上公开了代码。

    The proposed method, Discriminator Guidance, aims to improve sample generation of pre-trained diffusion models. The approach introduces a discriminator that gives explicit supervision to a denoising sample path whether it is realistic or not. Unlike GANs, our approach does not require joint training of score and discriminator networks. Instead, we train the discriminator after score training, making discriminator training stable and fast to converge. In sample generation, we add an auxiliary term to the pre-trained score to deceive the discriminator. This term corrects the model score to the data score at the optimal discriminator, which implies that the discriminator helps better score estimation in a complementary way. Using our algorithm, we achive state-of-the-art results on ImageNet 256x256 with FID 1.83 and recall 0.64, similar to the validation data's FID (1.68) and recall (0.66). We release the code at https://github.com/alsdudrla10/DG.
    
[^114]: 用于机器学习训练的任意大的标记随机可满足性公式

    Arbitrarily Large Labelled Random Satisfiability Formulas for Machine Learning Training. (arXiv:2211.15368v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2211.15368](http://arxiv.org/abs/2211.15368)

    本论文展示了一种基于概率方法的生成任意尺寸的正确标记的随机公式的方法，这一方法可以用于解决目前困难且常用于深度学习模型的组合问题。

    

    将深度学习应用于解决现实中困难的组合问题具有巨大的潜力。这方向的研究集中在布尔可满足性（SAT）问题上，这是由于它的理论核心性和实际重要性。但是，一个主要的障碍是，训练集仅限于比实际感兴趣的公式小数个数量级的随机公式，这引发了对泛化的严重担忧，因为标记越来越大的随机公式变得不可解。通过基本思想中的概率方法，我们完全消除了这个障碍：我们展示了如何生成任意所需尺寸的正确标记的随机公式，而无需解决底层决策问题。此外，通过改变简单标量参数的变化，我们生成的公式的分类任务的困难程度是可调的。这打开了一个全新的复杂程度。

    Applying deep learning to solve real-life instances of hard combinatorial problems has tremendous potential. Research in this direction has focused on the Boolean satisfiability (SAT) problem, both because of its theoretical centrality and practical importance. A major roadblock faced, though, is that training sets are restricted to random formulas of size several orders of magnitude smaller than formulas of practical interest, raising serious concerns about generalization. This is because labeling random formulas of increasing size rapidly becomes intractable. By exploiting the probabilistic method in a fundamental way, we remove this roadblock entirely: we show how to generate correctly labeled random formulas of any desired size, without having to solve the underlying decision problem. Moreover, the difficulty of the classification task for the formulas produced by our generator is tunable by varying a simple scalar parameter. This opens up an entirely new level of sophistication fo
    
[^115]: 基于扩散去噪过程的感知器偏置在异常检测中的应用

    Diffusion Denoising Process for Perceptron Bias in Out-of-distribution Detection. (arXiv:2211.11255v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.11255](http://arxiv.org/abs/2211.11255)

    本文针对深度学习中的异常检测问题，提出了一种新的方法——使用扩散模型作为非对称插值的方法来增强输入并减轻过度自信的问题，从而提高判别器模型在异常检测方面的性能。

    

    异常检测对于保证深度学习模型的可靠性和安全性至关重要。目前，判别器模型在这方面的表现超过其他方法。然而，判别器模型使用的特征提取过程容易丢失关键信息，留下不良情况和恶意攻击的空间。在本文中，我们引入了一个新的感知器偏置假设，它表明判别器模型对输入的某些特征更为敏感，导致过度自信的问题。为了解决这个问题，我们提出了一个新的框架，它结合了判别器和生成模型，并将扩散模型(DMs)集成到OOD检测中。我们证明了扩散去噪过程(DDP)作为一种新形式的非对称插值，很适合增强输入并减轻过度自信的问题。在DDP下，OOD数据的判别器模型特征表现为尖锐的变化，我们利用范数...

    Out-of-distribution (OOD) detection is a crucial task for ensuring the reliability and safety of deep learning. Currently, discriminator models outperform other methods in this regard. However, the feature extraction process used by discriminator models suffers from the loss of critical information, leaving room for bad cases and malicious attacks. In this paper, we introduce a new perceptron bias assumption that suggests discriminator models are more sensitive to certain features of the input, leading to the overconfidence problem. To address this issue, we propose a novel framework that combines discriminator and generation models and integrates diffusion models (DMs) into OOD detection. We demonstrate that the diffusion denoising process (DDP) of DMs serves as a novel form of asymmetric interpolation, which is well-suited to enhance the input and mitigate the overconfidence problem. The discriminator model features of OOD data exhibit sharp changes under DDP, and we utilize the norm
    
[^116]: 用因果反事实推断提高强化学习的鲁棒性

    Causal Counterfactuals for Improving the Robustness of Reinforcement Learning. (arXiv:2211.05551v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.05551](http://arxiv.org/abs/2211.05551)

    本文提出了CausalCF，它是第一个完整的因果RL解决方案，能够通过因果反事实推断提高RL系统的鲁棒性，并已在机器人抓取和操纵任务中得到应用。

    

    强化学习在各种机器人应用中被使用。强化学习使代理能够通过与环境交互自主地学习任务。任务越重要，对RL系统的鲁棒性的需求就越高。因果RL将RL和因果推断相结合，使RL更加鲁棒。因果RL代理使用因果表示来捕捉可以从一个任务转移到另一个任务的不变因果机制。目前，因果RL的研究有限，现有的解决方案通常不完整或不适用于实际应用。在这项工作中，我们提出了CausalCF，这是第一个完整的因果RL解决方案，结合了Causal Curiosity和CoPhy的思想。Causal Curiosity提供了一种使用干预的方法，并修改了CoPhy，使RL代理能够执行反事实推断。Causal Curiosity已应用于CausalWorld中的机器人抓取和操纵任务。CausalWorld提供了一个真实的仿真环境。

    Reinforcement learning (RL) is used in various robotic applications. RL enables agents to learn tasks autonomously by interacting with the environment. The more critical the tasks are, the higher the demand for the robustness of the RL systems. Causal RL combines RL and causal inference to make RL more robust. Causal RL agents use a causal representation to capture the invariant causal mechanisms that can be transferred from one task to another. Currently, there is limited research in Causal RL, and existing solutions are usually not complete or feasible for real-world applications. In this work, we propose CausalCF, the first complete Causal RL solution incorporating ideas from Causal Curiosity and CoPhy. Causal Curiosity provides an approach for using interventions, and CoPhy is modified to enable the RL agent to perform counterfactuals. Causal Curiosity has been applied to robotic grasping and manipulation tasks in CausalWorld. CausalWorld provides a realistic simulation environment
    
[^117]: 基于GAN的心电图合成中利用统计形状先验知识的方法研究

    Leveraging Statistical Shape Priors in GAN-based ECG Synthesis. (arXiv:2211.02626v2 [eess.SP] UPDATED)

    [http://arxiv.org/abs/2211.02626](http://arxiv.org/abs/2211.02626)

    本文提出了一种基于统计形状先验知识和GAN的ECG信号生成方法，能够解决ECG信号的复杂动力学问题。使用来自MIT-BIH心律失常数据库的数据进行实验验证，生成的信号比现有最先进的基于GAN的生成基线更为逼真，对于提高ECG训练数据集质量具有重要意义，可提高ECG分类算法的性能。

    

    在紧急情况下进行心电图(ECG)数据收集是具有挑战性的,因此心电图数据合成是应对高度不平衡的ECG训练数据集的有效解决方案。本文提出了一种新颖的方法，利用生成对抗网络(GAN)和统计ECG数据建模来生成ECG信号。我们的方法利用ECG动态的先验知识来合成逼真的信号，解决了ECG信号的复杂动力学问题。为了验证我们的方法，我们对来自MIT-BIH心律失常数据库的ECG信号进行了实验。结果表明，我们的方法将ECG信号的时间和幅度变化建模为2-D形状，相比现有最先进的基于GAN的生成基线，生成的信号更逼真。我们提出的方法对于提高ECG训练数据集的质量有重要意义，最终可以提高ECG分类算法的性能。

    Electrocardiogram (ECG) data collection during emergency situations is challenging, making ECG data generation an efficient solution for dealing with highly imbalanced ECG training datasets. In this paper, we propose a novel approach for ECG signal generation using Generative Adversarial Networks (GANs) and statistical ECG data modeling. Our approach leverages prior knowledge about ECG dynamics to synthesize realistic signals, addressing the complex dynamics of ECG signals. To validate our approach, we conducted experiments using ECG signals from the MIT-BIH arrhythmia database. Our results demonstrate that our approach, which models temporal and amplitude variations of ECG signals as 2-D shapes, generates more realistic signals compared to state-of-the-art GAN based generation baselines. Our proposed approach has significant implications for improving the quality of ECG training datasets, which can ultimately lead to better performance of ECG classification algorithms. This research c
    
[^118]: 基于无上下文文法的分层神经架构搜索空间构建

    Construction of Hierarchical Neural Architecture Search Spaces based on Context-free Grammars. (arXiv:2211.01842v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.01842](http://arxiv.org/abs/2211.01842)

    本研究基于无上下文文法提出了一个统一的搜索空间设计框架，可以生成表达力强大的分层搜索空间，实现了对整个体系结构的搜索并促进结构的规律性。

    

    从简单的构建块中发现神经结构是神经架构搜索(NAS)的一个长期目标。分层搜索空间是实现这一目标的一个有前途的步骤，但缺乏统一的搜索空间设计框架，并且通常仅搜索一些限定方面的架构。在本研究中，我们介绍了一个基于无上下文文法的统一搜索空间设计框架，它可以自然而紧凑地生成表达力强大的分层搜索空间，比文献中常见的空间大几个数量级。通过增强和利用它们的属性，我们有效地实现了对整个体系结构的搜索，并促进了结构的规律性。此外，我们提出了一种高效的分层核设计用于贝叶斯优化搜索策略，以高效搜索如此庞大的空间。我们展示了我们搜索空间设计框架的多样性，并表明我们的搜索策略可以优于现有的NAS方法。

    The discovery of neural architectures from simple building blocks is a long-standing goal of Neural Architecture Search (NAS). Hierarchical search spaces are a promising step towards this goal but lack a unifying search space design framework and typically only search over some limited aspect of architectures. In this work, we introduce a unifying search space design framework based on context-free grammars that can naturally and compactly generate expressive hierarchical search spaces that are 100s of orders of magnitude larger than common spaces from the literature. By enhancing and using their properties, we effectively enable search over the complete architecture and can foster regularity. Further, we propose an efficient hierarchical kernel design for a Bayesian Optimization search strategy to efficiently search over such huge spaces. We demonstrate the versatility of our search space design framework and show that our search strategy can be superior to existing NAS approaches. Co
    
[^119]: 通过后处理实现公平和最优分类

    Fair and Optimal Classification via Post-Processing. (arXiv:2211.01528v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.01528](http://arxiv.org/abs/2211.01528)

    本文提出了一个后处理算法，通过评分函数推导公平分类器，达到公平对待不同群体的目的。

    

    为了减轻机器学习模型所呈现的偏见，公平性标准可以整合到训练过程中，以确保在所有人口统计学中实现公平对待，然而这往往是以模型表现为代价的。因此，了解这种权衡是公平算法设计的基础。本文在最普遍的多组、多类别和嘈杂设置下，完整地表征了公平、达摩尔平等在分类问题中的内在权衡。具体而言，我们表明，通过随机化和属性感知公平分类器实现的最小错误率是由沃瑟斯坦重心问题的最优值给出的。在实践方面，我们的发现可以产生一个简单的后处理算法，从评分函数中推导出公平分类器，并在评分为贝叶斯最优时得到最优公平分类器。我们为我们的算法提供了次优性分析和样本复杂性，并展示了它的有效性。

    To mitigate the bias exhibited by machine learning models, fairness criteria can be integrated into the training process to ensure fair treatment across all demographics, but it often comes at the expense of model performance. Understanding such tradeoffs, therefore, underlies the design of fair algorithms. To this end, this paper provides a complete characterization of the inherent tradeoff of demographic parity on classification problems, under the most general multi-group, multi-class, and noisy setting. Specifically, we show that the minimum error rate achievable by randomized and attribute-aware fair classifiers is given by the optimal value of a Wasserstein-barycenter problem. On the practical side, our findings lead to a simple post-processing algorithm that derives fair classifiers from score functions, which yields the optimal fair classifier when the score is Bayes optimal. We provide suboptimality analysis and sample complexity for our algorithm, and demonstrate its effectiv
    
[^120]: 基于转移学习的大规模多语言预训练机器翻译模型在临床领域的应用研究

    Investigating Massive Multilingual Pre-Trained Machine Translation Models for Clinical Domain via Transfer Learning. (arXiv:2210.06068v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.06068](http://arxiv.org/abs/2210.06068)

    本研究探讨了大规模多语言预训练语言模型（MMPLM）是否可以通过转移学习在临床领域机器翻译中成功应用于完全未知的语言对。实验结果表明，fine-tune过的MMPLM在临床领域机器翻译任务中表现良好。

    

    近年来，大规模多语言预训练语言模型（MMPLM）展示了它们在下游任务上表现出的超能力和预知能力。本研究探讨了MMPLM在临床领域机器翻译（MT）中是否可以通过转移学习用于完全未知的语言对。我们使用Meta-AI的MMPLM“wmt21-dense-24-wide-en-X和X-en（WMT21fb）”，这些模型预先训练了7种语言对和14个翻译方向，包括英语到捷克语、德语、豪萨语、冰岛语、日语、俄语和汉语以及相反的方向。我们对这些MMPLM进行fine-tune，针对它们原始的预训练语料库中\textit{完全不存在}的英文-\textit{西班牙语}语言对，显式和隐式地进行fine-tune。我们为此 fine-tune 做好经过仔细对齐的\textit{临床}领域数据，这与它们原始的混合领域知识不同。我们的实验结果表明，fine-tune过的MMPLM在临床领域机器翻译任务中表现良好。

    Massively multilingual pre-trained language models (MMPLMs) are developed in recent years demonstrating superpowers and the pre-knowledge they acquire for downstream tasks. This work investigates whether MMPLMs can be applied to clinical domain machine translation (MT) towards entirely unseen languages via transfer learning. We carry out an experimental investigation using Meta-AI's MMPLMs ``wmt21-dense-24-wide-en-X and X-en (WMT21fb)'' which were pre-trained on 7 language pairs and 14 translation directions including English to Czech, German, Hausa, Icelandic, Japanese, Russian, and Chinese, and the opposite direction. We fine-tune these MMPLMs towards English-\textit{Spanish} language pair which \textit{did not exist at all} in their original pre-trained corpora both implicitly and explicitly. We prepare carefully aligned \textit{clinical} domain data for this fine-tuning, which is different from their original mixed domain knowledge. Our experimental result shows that the fine-tunin
    
[^121]: 粒子信念近似POMDP的最优性保证

    Optimality Guarantees for Particle Belief Approximation of POMDPs. (arXiv:2210.05015v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2210.05015](http://arxiv.org/abs/2210.05015)

    该论文提出了一般理论来限定POMDP与其相应的有限样本粒子信念MDP(PB-MDP)逼近之间的误差，并将任何采样MDP算法适应到POMDP中，从而提高了解决具有大的或连续状态空间的POMDP的性能和鲁棒性。

    

    部分可观察马尔可夫决策过程(POMDP)提供了现实决策和控制问题的灵活表示。然而，POMDP的求解非常困难，特别是当状态和观测空间是连续或混合的时候，这在物理系统中经常发生。尽管最近使用观测似然权重策划的在线采样POMDP算法表现出了实用的有效性，但先前并没有提出一般理论来刻画这些算法使用的粒子滤波技术的逼近误差。我们的主要贡献是限定任何POMDP与其相应的有限样本粒子信念MDP(PB-MDP)逼近之间的误差。这种PB-MDP和POMDP之间的基础桥梁使得我们能够通过解决相应的粒子信念MDP将任何采样MDP算法适应到POMDP中，从而将MDP算法的收敛保证扩展到POMDP中。在实践中，这可以提高在解决具有大的或连续状态空间的POMDP时的性能和鲁棒性。

    Partially observable Markov decision processes (POMDPs) provide a flexible representation for real-world decision and control problems. However, POMDPs are notoriously difficult to solve, especially when the state and observation spaces are continuous or hybrid, which is often the case for physical systems. While recent online sampling-based POMDP algorithms that plan with observation likelihood weighting have shown practical effectiveness, a general theory characterizing the approximation error of the particle filtering techniques that these algorithms use has not previously been proposed. Our main contribution is bounding the error between any POMDP and its corresponding finite sample particle belief MDP (PB-MDP) approximation. This fundamental bridge between PB-MDPs and POMDPs allows us to adapt any sampling-based MDP algorithm to a POMDP by solving the corresponding particle belief MDP, thereby extending the convergence guarantees of the MDP algorithm to the POMDP. Practically, thi
    
[^122]: UCEpic：统一考虑方面规划和词汇约束，生成解释型推荐

    UCEpic: Unifying Aspect Planning and Lexical Constraints for Generating Explanations in Recommendation. (arXiv:2209.13885v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2209.13885](http://arxiv.org/abs/2209.13885)

    UCEpic通过将方面规划和词汇约束统一考虑，提出了一种插入式生成的个性化解释型推荐模型，显著提高了解释的流畅性、连贯性和匹配能力。

    

    为了对解释型推荐进行个性化自然语言生成，本文提出了一种将方面规划和词汇约束统一考虑的模型UCEpic，通过插入式生成的方式生成高质量个性化的推荐结果解释。通过在模型的预训练和个性化推荐生成过程中引入词汇约束，可以显著提高生成解释的流畅性、连贯性和匹配能力。实验结果表明，UCEpic方法在两个基准数据集上显著优于现有最先进方法。

    Personalized natural language generation for explainable recommendations plays a key role in justifying why a recommendation might match a user's interests. Existing models usually control the generation process by aspect planning. While promising, these aspect-planning methods struggle to generate specific information correctly, which prevents generated explanations from being convincing. In this paper, we claim that introducing lexical constraints can alleviate the above issues. We propose a model, UCEpic, that generates high-quality personalized explanations for recommendation results by unifying aspect planning and lexical constraints in an insertion-based generation manner.  Methodologically, to ensure text generation quality and robustness to various lexical constraints, we pre-train a non-personalized text generator via our proposed robust insertion process. Then, to obtain personalized explanations under this framework of insertion-based generation, we design a method of incorp
    
[^123]: 使用单步 Q-learning 缓解 Actor-Critic 方法中的离策略偏差：一种新的纠正方法。

    Mitigating Off-Policy Bias in Actor-Critic Methods with One-Step Q-learning: A Novel Correction Approach. (arXiv:2208.00755v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2208.00755](http://arxiv.org/abs/2208.00755)

    本文提出一种新的策略相似度量来缓解离策略学习中的偏差问题，提供了一种自适应的、可扩展的解决方案。

    

    相较于基于策略的对比方法，离策略无模型深度强化学习可以通过重复使用以前收集的数据来提高数据使用效率。然而，当代理的策略和收集到的数据的基本分布之间的偏差增加时，离策略学习变得具有挑战性。尽管已经研究了重要性采样和离策略策略梯度技术来补偿这种偏差，但它们通常需要一系列长轨迹，并导致额外的问题，如消失/爆炸梯度或抛弃许多有用的经验，最终增加了计算复杂性。此外，它们对连续动作域或由确定性深度神经网络逼近的策略的泛化受到严格限制。为了克服这些限制，我们引入了一种新的策略相似度量来缓解连续控制中这种偏差的影响。我们的方法提供了一种自适应的、可扩展的解决方案，用于减轻 Actor-Critic 方法中离政策偏差的影响。

    Compared to on-policy counterparts, off-policy model-free deep reinforcement learning can improve data efficiency by repeatedly using the previously gathered data. However, off-policy learning becomes challenging when the discrepancy between the underlying distributions of the agent's policy and collected data increases. Although the well-studied importance sampling and off-policy policy gradient techniques were proposed to compensate for this discrepancy, they usually require a collection of long trajectories and induce additional problems such as vanishing/exploding gradients or discarding many useful experiences, which eventually increases the computational complexity. Moreover, their generalization to either continuous action domains or policies approximated by deterministic deep neural networks is strictly limited. To overcome these limitations, we introduce a novel policy similarity measure to mitigate the effects of such discrepancy in continuous control. Our method offers an ad
    
[^124]: 元最优输运

    Meta Optimal Transport. (arXiv:2206.05262v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.05262](http://arxiv.org/abs/2206.05262)

    本文提出了一种新的方法，利用过去问题的知识和信息来迅速预测和解决新问题，重复地解决不同度量之间的类似OT问题，从而改善最优输运问题的计算时间。

    

    我们研究了使用分摊优化来预测最优输运（OT）地图的方法，我们称之为元OT。这有助于通过利用过去问题的知识和信息来迅速预测和解决新问题，从而重复地解决不同度量之间的类似OT问题。否则，标准方法会忽略过去解决方案的知识，从头开始次优地重新解决每个问题。我们在灰度图像、球形数据、分类标签和颜色调色板之间实例化元OT模型，并使用它们来改善标准OT求解器的计算时间。我们的源代码可在此http URL找到。

    We study the use of amortized optimization to predict optimal transport (OT) maps from the input measures, which we call Meta OT. This helps repeatedly solve similar OT problems between different measures by leveraging the knowledge and information present from past problems to rapidly predict and solve new problems. Otherwise, standard methods ignore the knowledge of the past solutions and suboptimally re-solve each problem from scratch. We instantiate Meta OT models in discrete and continuous settings between grayscale images, spherical data, classification labels, and color palettes and use them to improve the computational time of standard OT solvers. Our source code is available at this http URL
    
[^125]: 强化学习中动作噪声对探索和性能的影响

    Action Noise in Off-Policy Deep Reinforcement Learning: Impact on Exploration and Performance. (arXiv:2206.03787v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.03787](http://arxiv.org/abs/2206.03787)

    本文研究了动作噪声类型、噪声比例和减少规模因子对深度强化学习离线学习中策略性能和探索效果的影响，提出了一种更具鲁棒性的状态空间覆盖度量。

    

    许多深度强化学习算法依赖于简单的探索形式，如连续控制领域常用的加性动作噪声。通常，在培训期间保持动作噪声的比例不变。本文侧重于连续控制的离线深度强化学习中的动作噪声。我们分析了噪声类型、噪声比例和减少规模因子的影响。我们考虑了两种最常见的动作噪声类型，高斯噪声和 Ornstein-Uhlenbeck 噪声，并通过系统地改变噪声类型和比例参数进行了大量实验研究，并通过测量策略的预期回报和探索期间的状态空间覆盖等有趣的变量来评估结果。对于后者，我们提出了一种新的状态空间覆盖度量X_𝒰rel，该方法对估计引起的估计误差具有更强的鲁棒性。

    Many Deep Reinforcement Learning (D-RL) algorithms rely on simple forms of exploration such as the additive action noise often used in continuous control domains. Typically, the scaling factor of this action noise is chosen as a hyper-parameter and is kept constant during training. In this paper, we focus on action noise in off-policy deep reinforcement learning for continuous control. We analyze how the learned policy is impacted by the noise type, noise scale, and impact scaling factor reduction schedule. We consider the two most prominent types of action noise, Gaussian and Ornstein-Uhlenbeck noise, and perform a vast experimental campaign by systematically varying the noise type and scale parameter, and by measuring variables of interest like the expected return of the policy and the state-space coverage during exploration. For the latter, we propose a novel state-space coverage measure $\operatorname{X}_{\mathcal{U}\text{rel}}$ that is more robust to estimation artifacts caused by
    
[^126]: 奖励状态机的层次化结构

    Hierarchies of Reward Machines. (arXiv:2205.15752v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.15752](http://arxiv.org/abs/2205.15752)

    本文提出了一种奖励状态机（RM）的层次化结构（HRM），利用它可以将任务进一步抽象为多个子任务，每个子任务都可以独立解决；使用 HRM 可以帮助加快收敛速度且在学习中是可行的。

    

    奖励状态机（RM）是一种新的形式化工具，用于通过一个有限状态机来表示强化学习任务的奖励函数，其边缘使用高级事件编码任务的子目标。 RM的结构使得将一个任务分解成简单和独立可解的子任务成为可能，这有助于处理长期规划和/或奖励稀疏的任务。我们提出了一种形式化工具，通过赋予RM调用其他RM的能力，从而组合一个RM的层次结构（HRM）来进一步抽象子任务结构。我们利用HRM通过将对RM的每个调用视为单独可解的子任务来使用选项框架，并描述了一种基于课程的方法来从代理观察到的轨迹中学习HRM。我们的实验表明，利用手工制作的HRM比扁平的HRM收敛更快，并且在等价的扁平表示不可行的情况下，学习HRM是可行的。

    Reward machines (RMs) are a recent formalism for representing the reward function of a reinforcement learning task through a finite-state machine whose edges encode subgoals of the task using high-level events. The structure of RMs enables the decomposition of a task into simpler and independently solvable subtasks that help tackle long-horizon and/or sparse reward tasks. We propose a formalism for further abstracting the subtask structure by endowing an RM with the ability to call other RMs, thus composing a hierarchy of RMs (HRM). We exploit HRMs by treating each call to an RM as an independently solvable subtask using the options framework, and describe a curriculum-based method to learn HRMs from traces observed by the agent. Our experiments reveal that exploiting a handcrafted HRM leads to faster convergence than with a flat HRM, and that learning an HRM is feasible in cases where its equivalent flat representation is not.
    
[^127]: 公平标记聚类

    Fair Labeled Clustering. (arXiv:2205.14358v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.14358](http://arxiv.org/abs/2205.14358)

    本文提出了解决公平标记聚类问题的算法，考虑了下游应用和团体公平性的实现。

    

    针对聚类中的公平性问题，已经出现了许多基于不同公平性概念的算法。目前最常见的公平概念是团体公平性，即每个聚类中都要保证团体比例的合理性。本文在这个方向上进行了扩展，考虑了聚类任务的下游应用以及在该应用中如何实现团体公平性。我们具体研究了一种常见情况，即决策者运行聚类算法，检查每个聚类的中心并为相应的聚类确定一个适当的结果（标签），例如招聘中的“录用”或“拒绝”。在这种情况下，为了确保团体公平性，我们希望每个标签都有符合比例的团体代表，但不一定要求每个聚类都具有两个团体的平衡性。我们提出了解决此类问题的算法。

    Numerous algorithms have been produced for the fundamental problem of clustering under many different notions of fairness. Perhaps the most common family of notions currently studied is group fairness, in which proportional group representation is ensured in every cluster. We extend this direction by considering the downstream application of clustering and how group fairness should be ensured for such a setting. Specifically, we consider a common setting in which a decision-maker runs a clustering algorithm, inspects the center of each cluster, and decides an appropriate outcome (label) for its corresponding cluster. In hiring for example, there could be two outcomes, positive (hire) or negative (reject), and each cluster would be assigned one of these two outcomes. To ensure group fairness in such a setting, we would desire proportional group representation in every label but not necessarily in every cluster as is done in group fair clustering. We provide algorithms for such problems 
    
[^128]: 形式化运行时分布上的偏好

    Formalizing Preferences Over Runtime Distributions. (arXiv:2205.13028v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2205.13028](http://arxiv.org/abs/2205.13028)

    本文形式化了偏好运行时分布，提出了一种基于效用理论的替代方案来描述算法的评分函数，这些函数与随时间的推移和消费时间的分布有关。

    

    在解决计算问题时，我们通常需要在能够返回正确结果的算法之间进行选择，但这些算法的运行时分布不同（例如SAT求解器，排序算法）。本文旨在通过形式化运行时分布上的偏好为这些选择奠定理论基础。我们往往希望选择预期运行时间最短的算法。然而，这样的偏好将完全受到算法在坏输入上表现如何而影响，而在实践中，我们通常愿意在长时间的运行没有结束之前将其切断。我们提出了一个基于效用理论的可替代方案，用于描述算法偏好的评分函数。这些函数取决于随着时间的推移，问题解决的价值如何下降以及消费时间的分布。我们提出了一些真实的效用函数示例，并展示了一些优势决策算法的选择过程，并对这些函数进行了实验评估。

    When trying to solve a computational problem, we are often faced with a choice between algorithms that are guaranteed to return the right answer but differ in their runtime distributions (e.g., SAT solvers, sorting algorithms). This paper aims to lay theoretical foundations for such choices by formalizing preferences over runtime distributions. It might seem that we should simply prefer the algorithm that minimizes expected runtime. However, such preferences would be driven by exactly how slow our algorithm is on bad inputs, whereas in practice we are typically willing to cut off occasional, sufficiently long runs before they finish. We propose a principled alternative, taking a utility-theoretic approach to characterize the scoring functions that describe preferences over algorithms. These functions depend on the way our value for solving our problem decreases with time and on the distribution from which captimes are drawn. We describe examples of realistic utility functions and show 
    
[^129]: CLIP-Dissect：深度视觉网络中神经元表示的自动描述

    CLIP-Dissect: Automatic Description of Neuron Representations in Deep Vision Networks. (arXiv:2204.10965v4 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2204.10965](http://arxiv.org/abs/2204.10965)

    CLIP-Dissect是一种用于自动描述视觉网络中神经元功能的新技术，它可以无需任何标记数据或人类示例即将内部神经元标记为无需任何标记数据或人类示例的开放概念，并比现有方法提供了更准确的描述。此外，它具有灵活性、高效性和可扩展性。

    

    本文提出了一种新技术CLIP-Dissect，可以自动描述视觉网络中单个隐藏神经元的功能。CLIP-Dissect利用了最近在多模态视觉/语言模型方面的进展，将内部神经元标记为无需任何标记数据或人类示例的开放概念。我们证明了CLIP-Dissect提供了比现有方法更准确的描述，其中包括具备“地面真相”（ground-truth）的最后一层神经元以及具备定性好的隐藏层神经元。此外，该方法非常灵活：它与模型无关，可以轻松处理新概念，可以扩展以利用未来更好的多模态模型。最后，CLIP-Dissect计算效率高，可以在短短4分钟内标记ResNet-50的五层所有神经元，比现有方法快10倍以上。我们的代码可在https://github.com/Trustworthy-ML-Lab/CLIP-dissect 上找到。

    In this paper, we propose CLIP-Dissect, a new technique to automatically describe the function of individual hidden neurons inside vision networks. CLIP-Dissect leverages recent advances in multimodal vision/language models to label internal neurons with open-ended concepts without the need for any labeled data or human examples. We show that CLIP-Dissect provides more accurate descriptions than existing methods for last layer neurons where the ground-truth is available as well as qualitatively good descriptions for hidden layer neurons. In addition, our method is very flexible: it is model agnostic, can easily handle new concepts and can be extended to take advantage of better multimodal models in the future. Finally CLIP-Dissect is computationally efficient and can label all neurons from five layers of ResNet-50 in just 4 minutes, which is more than 10 times faster than existing methods. Our code is available at https://github.com/Trustworthy-ML-Lab/CLIP-dissect.
    
[^130]: 在低误报率条件下窃取和逃避恶意软件分类器和防病毒软件

    Stealing and Evading Malware Classifiers and Antivirus at Low False Positive Conditions. (arXiv:2204.06241v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2204.06241](http://arxiv.org/abs/2204.06241)

    本研究尝试针对恶意软件分类器和防病毒产品进行了模型窃取攻击，并提出了一种新的神经网络体系结构和模型窃取攻击方法。最终实现了高达99%的代理模型与目标模型的一致性。

    

    模型窃取攻击已成功用于许多机器学习领域，但对于执行恶意软件检测的模型，这些攻击的工作原理尚不清楚。恶意软件检测和安全领域具有独特的条件，特别是对低误报率有着极强的要求。本研究评估了针对公开可用的独立机器学习恶意软件分类器和防病毒产品的主动学习模型窃取攻击。本研究提出了一种新的神经网络体系结构用于代理模型（dualFFNN），并设计了一种新的模型窃取攻击方法，该攻击方法将转移学习和主动学习结合起来用于代理创建（FFNN-TL）。

    Model stealing attacks have been successfully used in many machine learning domains, but there is little understanding of how these attacks work against models that perform malware detection. Malware detection and, in general, security domains have unique conditions. In particular, there are very strong requirements for low false positive rates (FPR). Antivirus products (AVs) that use machine learning are very complex systems to steal, malware binaries continually change, and the whole environment is adversarial by nature. This study evaluates active learning model stealing attacks against publicly available stand-alone machine learning malware classifiers and also against antivirus products. The study proposes a new neural network architecture for surrogate models (dualFFNN) and a new model stealing attack that combines transfer and active learning for surrogate creation (FFNN-TL). We achieved good surrogates of the stand-alone classifiers with up to 99\% agreement with the target mod
    
[^131]: 自然语言推理中归因方法评估的多语言视角

    A Multilingual Perspective Towards the Evaluation of Attribution Methods in Natural Language Inference. (arXiv:2204.05428v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2204.05428](http://arxiv.org/abs/2204.05428)

    该论文提出了一种基于多语言的评价方法，以评估自然语言推理任务中归因方法的忠实度和可信度，并且通过高亮的解释扩充了XNLI数据集，研究结果表明在可信度和可信度方面表现最佳的归因方法有所不同。

    

    大多数归因方法的评估集中在英语语言上。在这项工作中，我们提出了一种多语言方法，用于评估自然语言推理（NLI）任务的归因方法的忠实度和可信度。首先，我们引入了一种基于单词对齐的新型跨语言策略来衡量忠实度，排除了删减评估的缺点。然后，我们对归因方法进行了全面的评估，考虑了不同的输出机制和聚合方法。最后，我们通过基于高亮的解释扩充了XNLI数据集，提供了一个带有高亮的多语言NLI数据集，以支持未来的ExNLP研究。我们的研究结果表明，性能最佳的归因方法对于可信度和可信度的表现是不同的。

    Most evaluations of attribution methods focus on the English language. In this work, we present a multilingual approach for evaluating attribution methods for the Natural Language Inference (NLI) task in terms of faithfulness and plausibility. First, we introduce a novel cross-lingual strategy to measure faithfulness based on word alignments, which eliminates the drawbacks of erasure-based evaluations.We then perform a comprehensive evaluation of attribution methods, considering different output mechanisms and aggregation methods. Finally, we augment the XNLI dataset with highlight-based explanations, providing a multilingual NLI dataset with highlights, to support future exNLP studies. Our results show that attribution methods performing best for plausibility and faithfulness are different.
    
[^132]: 一种基于集合成员关系的方法来发现特征相关性并解释神经分类器的决策

    A Set Membership Approach to Discovering Feature Relevance and Explaining Neural Classifier Decisions. (arXiv:2204.02241v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2204.02241](http://arxiv.org/abs/2204.02241)

    该论文提出一种基于集合成员关系的方法来发现神经分类器所需的特征，并解释其决策。方法能够标识贡献每个特征对神经网络分类器所做出的预测，并解释分类器处理输入分布变化时的行为。

    

    神经分类器是提供模式类别决策的非线性系统。对于给定的问题，神经分类器的输出构成了某个未知函数的输出的近似，该函数将模式数据映射到其相应的类别。然而，由于缺乏该函数的知识以及神经分类器的复杂性，尤其是对于深度学习体系结构，往往无法获得有关如何进行具体预测的信息。因此，这些强大的学习系统被认为是黑匣子，在关键的应用中使用它们往往被认为是不合适的。本文提出了一种新的方案来解决这个问题，通过基于集合成员分析，我们把输入模式分成子集，以关联不同的输出基类。这种关联是通过计算将分类器决策引导到替代类别所需的最小输入摄动来推断的。我们的方法可以用于发现哪些特征被认为是相关的，并量化其对预测的贡献。此外，我们展示了如何使用我们的方法来解释分类器在处理输入分布变化时的行为。标准的图像分类数据集上的实验结果显示了我们的方法在发现相关输入特征和解释由深度神经网络体系结构做出的分类决策方面的有效性。

    Neural classifiers are non linear systems providing decisions on the classes of patterns, for a given problem they have learned. The output computed by a classifier for each pattern constitutes an approximation of the output of some unknown function, mapping pattern data to their respective classes. The lack of knowledge of such a function along with the complexity of neural classifiers, especially when these are deep learning architectures, do not permit to obtain information on how specific predictions have been made. Hence, these powerful learning systems are considered as black boxes and in critical applications their use tends to be considered inappropriate. Gaining insight on such a black box operation constitutes a one way approach in interpreting operation of neural classifiers and assessing the validity of their decisions. In this paper we tackle this problem introducing a novel methodology for discovering which features are considered relevant by a trained neural classifier a
    
[^133]: 一种基于仿真集成的生物启发式搜索测试方法在ADAS案例研究中的应用

    Machine Learning Testing in an ADAS Case Study Using Simulation-Integrated Bio-Inspired Search-Based Testing. (arXiv:2203.12026v3 [cs.SE] UPDATED)

    [http://arxiv.org/abs/2203.12026](http://arxiv.org/abs/2203.12026)

    本文提出一种基于仿真集成的生物启发式搜索测试方法Deeper，用于生成用于测试基于深度神经网络的车道保持系统的故障发现测试场景，通过实证评估和与竞赛中的其他工具的比较展示了其性能的提高。

    

    本文介绍Deeper的扩展版本，它是一种基于搜索实现的仿真集成测试解决方案，用于生成用于测试基于深度神经网络的车道保持系统的故障发现测试场景。在新版本中，我们利用了一组新的生物启发式搜索算法-遗传算法（GA）、（μ+λ）和（μ，λ）进化策略（ES）以及粒子群优化（PSO），这些算法利用质量种子种群以及为建模测试场景使用的特定领域交叉和突变操作。为了展示Deeper中新测试生成器的能力，我们进行了实证评估，并与SBST 2021的五个参赛工具的结果进行了比较。我们的评估结果表明，在新版本中，Deeper中的新测试生成器不仅在以前的版本上有了很大提升，而且...

    This paper presents an extended version of Deeper, a search-based simulation-integrated test solution that generates failure-revealing test scenarios for testing a deep neural network-based lane-keeping system. In the newly proposed version, we utilize a new set of bio-inspired search algorithms, genetic algorithm (GA), $({\mu}+{\lambda})$ and $({\mu},{\lambda})$ evolution strategies (ES), and particle swarm optimization (PSO), that leverage a quality population seed and domain-specific cross-over and mutation operations tailored for the presentation model used for modeling the test scenarios. In order to demonstrate the capabilities of the new test generators within Deeper, we carry out an empirical evaluation and comparison with regard to the results of five participating tools in the cyber-physical systems testing competition at SBST 2021. Our evaluation shows the newly proposed test generators in Deeper not only represent a considerable improvement on the previous version but also 
    
[^134]: 使用概念激活向量在推荐系统中发现软属性的个性化语义

    Discovering Personalized Semantics for Soft Attributes in Recommender Systems using Concept Activation Vectors. (arXiv:2202.02830v3 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2202.02830](http://arxiv.org/abs/2202.02830)

    我们使用概念激活向量来把用户描述商品的属性的语义表达出来，以改进推荐系统的效果。

    

    交互式推荐系统已经成为一种有前途的范例，以克服传统推荐系统所使用的原始用户反馈的局限性（例如点击、项目消费、评分）。它们允许用户以更丰富的方式表达意图、偏好、约束和上下文，通常使用自然语言（包括分类搜索和对话）。然而，需要更多的研究来找到使用这些反馈的最有效方法。一个挑战是从经常用于描述所需项目的开放式术语或属性中推断用户的语义意图，并使用它来改进推荐结果。利用最近在机器学习中开发的模型可解释性方法——概念激活向量（CAVs），我们开发了一个框架，在推荐系统中学习一种表示，捕捉这些属性的语义，并将它们连接到用户的偏好和行为中。我们方法的一个新功能是它能够区分

    Interactive recommender systems have emerged as a promising paradigm to overcome the limitations of the primitive user feedback used by traditional recommender systems (e.g., clicks, item consumption, ratings). They allow users to express intent, preferences, constraints, and contexts in a richer fashion, often using natural language (including faceted search and dialogue). Yet more research is needed to find the most effective ways to use this feedback. One challenge is inferring a user's semantic intent from the open-ended terms or attributes often used to describe a desired item, and using it to refine recommendation results. Leveraging concept activation vectors (CAVs) [26], a recently developed approach for model interpretability in machine learning, we develop a framework to learn a representation that captures the semantics of such attributes and connects them to user preferences and behaviors in recommender systems. One novel feature of our approach is its ability to distinguis
    
[^135]: 用代理模型辅助的分布式群体优化方法来处理计算昂贵的地质科学模型

    Surrogate-assisted distributed swarm optimisation for computationally expensive geoscientific models. (arXiv:2201.06843v2 [cs.DC] UPDATED)

    [http://arxiv.org/abs/2201.06843](http://arxiv.org/abs/2201.06843)

    本文利用代理模型辅助的分布式群体优化方法，解决了计算昂贵的地质科学模型优化问题，在基准优化问题和Badlands风貌演化模型中都取得了非常有希望的结果。

    

    进化算法提供无梯度优化方法，对于难以获取梯度的模型（如地质科学风貌演化模型）有益。但是，这些模型有时计算成本很高，即使是并行计算的分布式群体优化也很吃力。我们可以采用代理模型辅助优化等高效策略来解决这些挑战，但是实施代理模型的进程间通信来进行模型训练是困难的。在本文中，我们实现了分布式群体优化中代理模型评估适应值的方法，采用并行计算架构。我们首先将该框架应用于一组基准优化问题，并将其应用于具有风貌演化模型的地质科学模型。我们的结果对于基准函数和Badlands风貌演化模型都表现出非常有希望的结果。我们获得了计算时间的缩短

    Evolutionary algorithms provide gradient-free optimisation which is beneficial for models that have difficulty in obtaining gradients; for instance, geoscientific landscape evolution models. However, such models are at times computationally expensive and even distributed swarm-based optimisation with parallel computing struggles. We can incorporate efficient strategies such as surrogate-assisted optimisation to address the challenges; however, implementing inter-process communication for surrogate-based model training is difficult. In this paper, we implement surrogate-based estimation of fitness evaluation in distributed swarm optimisation over a parallel computing architecture. We first test the framework on a set of benchmark optimisation problems and then apply it to a geoscientific model that features a landscape evolution model. Our results demonstrate very promising results for benchmark functions and the Badlands landscape evolution model. We obtain a reduction in computational
    
[^136]: 在线二分匹配中的Rawlsian公平性：双侧、群体和个人。

    Rawlsian Fairness in Online Bipartite Matching: Two-sided, Group, and Individual. (arXiv:2201.06021v3 [cs.GT] UPDATED)

    [http://arxiv.org/abs/2201.06021](http://arxiv.org/abs/2201.06021)

    本文提出了一种通用的在线匹配算法，它为在线二分匹配平台中的两个双方同时提供公平性保证，而以降低操作者利润为代价。

    

    在线二分匹配平台是普遍存在的，被广泛应用于众包和拼车等重要领域。平台由三个实体组成：两个需要匹配的双方，以及一个决定匹配的平台操作者。传统上，对于这种平台的算法设计关注的是操作者的（预期）利润。然而，随着公平性变得越来越重要，同时忽略市场中任意一方的公平性保证的现有算法已经无法满足要求。本文将现有工作推广到同时为市场中的双方提供公平性保证，以计算最坏情况下操作者利润的降低为代价。我们考虑组和个人Rawlsian公平性标准。此外，我们的算法具有理论保证，并具有可以调整的参数。

    Online bipartite-matching platforms are ubiquitous and find applications in important areas such as crowdsourcing and ridesharing. In the most general form, the platform consists of three entities: two sides to be matched and a platform operator that decides the matching. The design of algorithms for such platforms has traditionally focused on the operator's (expected) profit. Since fairness has become an important consideration that was ignored in the existing algorithms a collection of online matching algorithms have been developed that give a fair treatment guarantee for one side of the market at the expense of a drop in the operator's profit. In this paper, we generalize the existing work to offer fair treatment guarantees to both sides of the market simultaneously, at a calculated worst case drop to operator profit. We consider group and individual Rawlsian fairness criteria. Moreover, our algorithms have theoretical guarantees and have adjustable parameters that can be tuned as d
    
[^137]: 概率公平聚类

    Probabilistic Fair Clustering. (arXiv:2006.10916v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2006.10916](http://arxiv.org/abs/2006.10916)

    本文提出了一种通过概率分配获得组成员身份的不完美知识的公平聚类算法，并在这种更一般的设置中给出了逼近比保证。

    

    在聚类问题中，一个中央决策者被赋予了一个顶点的完整度量图，并且必须提供顶点的聚类，以最小化某些客观函数。在公平聚类问题中，顶点被赋予了颜色（例如，属于一个组的成员资格），有效聚类的特征也可能包括颜色在该聚类中的表示。之前的公平聚类工作假设完全知道组成员身份。在本文中，我们通过假设通过概率分配来获得组成员身份的不完美知识，对以前的工作进行了推广。我们在这种更一般的设置中提出了聚类算法，并给出了逼近比担保。我们还解决了“度量成员身份”的问题，其中不同的组具有顺序和距离的概念。使用我们提出的算法以及基线进行实验，以验证我们的方法，并在不确定地知道组成员身份时揭示微妙的担忧。

    In clustering problems, a central decision-maker is given a complete metric graph over vertices and must provide a clustering of vertices that minimizes some objective function. In fair clustering problems, vertices are endowed with a color (e.g., membership in a group), and the features of a valid clustering might also include the representation of colors in that clustering. Prior work in fair clustering assumes complete knowledge of group membership. In this paper, we generalize prior work by assuming imperfect knowledge of group membership through probabilistic assignments. We present clustering algorithms in this more general setting with approximation ratio guarantees. We also address the problem of "metric membership", where different groups have a notion of order and distance. Experiments are conducted using our proposed algorithms as well as baselines to validate our approach and also surface nuanced concerns when group membership is not known deterministically.
    

