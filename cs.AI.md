# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [FlightScope: A Deep Comprehensive Assessment of Aircraft Detection Algorithms in Satellite Imagery](https://arxiv.org/abs/2404.02877) | 本研究对卫星图像中识别飞机的任务自定义的一套先进对象检测算法进行了全面评估和比较，发现YOLOv5是在不同成像条件下展现高精度和适应性的最优模型。 |
| [^2] | [Unbiased Learning to Rank Meets Reality: Lessons from Baidu's Large-Scale Search Dataset](https://arxiv.org/abs/2404.02543) | 本研究从百度搜索引擎发布的大规模搜索数据集出发，探讨了无偏向学习排序技术在实际搜索引擎中的表现，发现与排名损失和查询-文档特征选择相比，ULTR技术并未带来明显的性能改进。 |
| [^3] | [Addressing Loss of Plasticity and Catastrophic Forgetting in Continual Learning](https://arxiv.org/abs/2404.00781) | 本文提出了一种新方法，即基于效用的扰动梯度下降（UPGD），通过在梯度更新中应用不同大小的扰动，保护有用单元以防遗忘，同时恢复不太有用单元的可塑性。 |
| [^4] | [Facilitating Reinforcement Learning for Process Control Using Transfer Learning: Perspectives](https://arxiv.org/abs/2404.00247) | 本文从迁移学习的角度探讨了如何将其与强化学习相结合，为过程控制带来新的可能性。 |
| [^5] | [Attention-based Shape-Deformation Networks for Artifact-Free Geometry Reconstruction of Lumbar Spine from MR Images](https://arxiv.org/abs/2404.00231) | 这项工作提出了TransDeformer，使用注意力机制实现了对腰椎轮廓的高空间准确性重建，并跨患者实现了网格对应，为医学参数测量提供了可靠性，还设计了变体用于错误估计。 |
| [^6] | [NUMTEMP: A real-world benchmark to verify claims with statistical and temporal expressions](https://arxiv.org/abs/2403.17169) | NUMTEMP是一个真实世界基准，专注于验证复杂的数字论点，量化了现有解决方案的局限性，并提供了一种解决真实世界数字论点验证挑战的方法。 |
| [^7] | [Towards Learning Contrast Kinetics with Multi-Condition Latent Diffusion Models](https://arxiv.org/abs/2403.13890) | 提出了一个多条件潜在扩散模型来学习对比动力学，以减少对静脉内对比剂的依赖性。 |
| [^8] | [Reverse Training to Nurse the Reversal Curse](https://arxiv.org/abs/2403.13799) | 该研究提出了一种称为逆向训练的替代训练方案，通过在正向和逆向方向上训练语言模型并保留选定子串，成功解决了大型语言模型面临的逆转诅咒问题。 |
| [^9] | [Correcting misinformation on social media with a large language model](https://arxiv.org/abs/2403.11169) | 提出了一种名为MUSE的大型语言模型，通过访问最新信息并评估可信度，以解决社交媒体上误信息纠正的难题。 |
| [^10] | [Exploiting the Margin: How Capitalism Fuels AI at the Expense of Minoritized Groups](https://arxiv.org/abs/2403.06332) | 人工智能在深化社会不平等方面起着关键作用，通过剥削边缘群体，特别是通过机制如零工经济劳工的滥用、有偏见的面部识别技术和对这些社群施加的不成比例的心理健康负担，加剧了现有的不平等。 |
| [^11] | [LitSim: Conflict-aware Policy for Long-term Interactive Traffic Simulation](https://arxiv.org/abs/2403.04299) | LitSim提出了一种长期交互式仿真方法，重播日志以获得逼真场景，当出现不真实冲突时进行干预，从而提高仿真逼真度并避免碰撞 |
| [^12] | [Towards Safe and Aligned Large Language Models for Medicine](https://arxiv.org/abs/2403.03744) | 对医学LLMs进行了首次安全评估，并探讨了如何定义医学安全和对齐性，开发了有害医学问题数据集，评估了医学LLMs的安全性和对齐性，展示了微调是一种有效的缓解策略。 |
| [^13] | [Brilla AI: AI Contestant for the National Science and Maths Quiz](https://arxiv.org/abs/2403.01699) | 人工智能参赛者Brilla AI在全国科学与数学竞赛中表现优秀，为缺乏合格教师的非洲提供了学习支持。 |
| [^14] | [FusionVision: A comprehensive approach of 3D object reconstruction and segmentation from RGB-D cameras using YOLO and fast segment anything](https://arxiv.org/abs/2403.00175) | FusionVision提出了一种综合方法，将YOLO和快速分割任何物体的技术整合到RGB-D相机处理中，实现了对3D物体的鲁棒分割 |
| [^15] | [Measuring and Controlling Persona Drift in Language Model Dialogs](https://arxiv.org/abs/2402.10962) | 提出了一种量化基准来测量语言模型对话中的“人设”漂移，并提出了一种称为split-softmax的轻量级方法来对抗注意力衰减和“人设”漂移 |
| [^16] | [Large Language Models as Zero-shot Dialogue State Tracker through Function Calling](https://arxiv.org/abs/2402.10466) | 本研究提出了一种通过函数调用将大型语言模型用于零-shot对话状态追踪的新方法，能够在任务导向对话中取得出色的性能，适应不同领域而无需大量数据收集或模型调整。 |
| [^17] | [Model Collapse Demystified: The Case of Regression](https://arxiv.org/abs/2402.07712) | 本研究在核回归的简化环境中解析了模型崩溃现象，并发现了模型能够处理虚假数据与性能完全崩溃之间的交叉点。通过提出基于自适应正则化的策略，成功缓解了模型崩溃问题。这些发现通过实验证实。 |
| [^18] | [Doing Experiments and Revising Rules with Natural Language and Probabilistic Reasoning](https://arxiv.org/abs/2402.06025) | 本论文建立了一个计算模型来模拟人们通过实验主动推断隐藏规则的过程，并发现显式假设、概率规则和在线更新的组合可以解释人们在类似Zendo任务上的表现。 |
| [^19] | [RGI-Net: 3D Room Geometry Inference from Room Impulse Responses in the Absence of First-order Echoes](https://arxiv.org/abs/2309.01513) | RGI-Net通过深度神经网络学习和利用房间脉冲响应中高阶反射之间的关系，实现在没有传统假设的情况下推断房间几何信息。 |
| [^20] | [Next Visit Diagnosis Prediction via Medical Code-Centric Multimodal Contrastive EHR Modelling with Hierarchical Regularisation.](http://arxiv.org/abs/2401.11648) | 通过医学代码中心的多模态对比EHR建模预测下次就诊诊断，并通过分层正则化提高性能。 |
| [^21] | [Thousands of AI Authors on the Future of AI.](http://arxiv.org/abs/2401.02843) | 数千位AI作者对未来AI的预测显示，到2028年，AI系统有50%的几率实现多个里程碑，包括自主构建全新的付款处理网站、创作一首与知名音乐家的新歌难以区分的歌曲，并自主下载和调整大型语言模型。同时，无需辅助的机器在各种任务上胜过人类的几率估计为10%到2047年为50%。 |
| [^22] | [An Example of Evolutionary Computation + Large Language Model Beating Human: Design of Efficient Guided Local Search.](http://arxiv.org/abs/2401.02051) | 使用进化计算和大语言模型的算法进化框架，自动设计了高效的引导局部搜索算法来解决旅行商问题，在实验中表现优于人工设计的算法，标志着自动算法设计的新时代出现。 |
| [^23] | [Iterative Preference Learning from Human Feedback: Bridging Theory and Practice for RLHF under KL-Constraint.](http://arxiv.org/abs/2312.11456) | 该论文研究了在KL约束下的反馈强化学习的理论框架，并提出了有效的算法和实践。实证评估表明，该框架在大型语言模型的对齐实验中表现出良好的效果。 |
| [^24] | [AI Alignment: A Comprehensive Survey.](http://arxiv.org/abs/2310.19852) | 本篇论文主要介绍了AI对齐的概念、方法和实践。研究围绕四个关键目标：健壮性、可解释性、可控性和道德性展开，并将其分为前向对齐和后向对齐两个部分。 AI对齐是为了构建符合人类意图和价值观的AI系统，并减轻由于系统不对齐带来的潜在风险。 |
| [^25] | [Probabilistic Sampling of Balanced K-Means using Adiabatic Quantum Computing.](http://arxiv.org/abs/2310.12153) | 该论文研究了使用绝热量子计算的平衡K-Means聚类的概率采样方法，通过利用非最优解来计算校准后验概率，实现在D-Wave AQC上识别模糊解决方案和数据点的目标。 |
| [^26] | [Efficient Algorithms for the CCA Family: Unconstrained Objectives with Unbiased Gradients.](http://arxiv.org/abs/2310.01012) | 本论文提出了一个新颖的无约束目标，通过应用随机梯度下降（SGD）到CCA目标，实现了一系列快速算法，包括随机PLS、随机CCA和深度CCA。这些方法在各种基准测试中表现出比先前最先进方法更快的收敛速度和更高的相关性恢复。 |
| [^27] | [The Relational Bottleneck as an Inductive Bias for Efficient Abstraction.](http://arxiv.org/abs/2309.06629) | 本文介绍了一种新的归纳偏好方法——关系瓶颈，用于有效地诱导抽象概念的模型，强调了其在人类思维和大脑中抽象概念习得中的潜力。 |
| [^28] | [Response: Emergent analogical reasoning in large language models.](http://arxiv.org/abs/2308.16118) | 该论文回应了关于大型语言模型中紧急类比推理的主张，并通过提供字符串类比的反例来反驳。在测试中，GPT-3无法解决最简单的类比问题。为了加强零点推理等人类推理的主张，需要发展出排除数据记忆的方法。 |
| [^29] | [Retroformer: Retrospective Large Language Agents with Policy Gradient Optimization.](http://arxiv.org/abs/2308.02151) | 本文介绍了一种通过策略梯度优化的回顾性大型语言代理框架，该框架通过学习环境反馈来调整语言代理的提示，从而优化其性能。这种代理能够从多个环境和任务中学习奖励，并通过总结以前任务的根本原因来改进语言代理提示。 |
| [^30] | [Enhancing Super-Resolution Networks through Realistic Thick-Slice CT Simulation.](http://arxiv.org/abs/2307.10182) | 本研究通过开发一种创新的模拟算法，成功生成与实际图像非常相似的厚切片CT图像，并证明该方法在峰值信噪比和均方根误差方面明显优于其他模拟方法。 |
| [^31] | [Offline Policy Evaluation for Reinforcement Learning with Adaptively Collected Data.](http://arxiv.org/abs/2306.14063) | 本论文提出了一种自适应采集数据的离线强化学习策略评估方法，为表格MDPs推导出高概率、实例相关的误差边界，并实现了自适应设置下的极小值最优离线学习。 |
| [^32] | [AnyPredict: Foundation Model for Tabular Prediction.](http://arxiv.org/abs/2305.12081) | 本文提出了一种名为 AnyPredict 的表格预测基础模型，使用数据引擎整合领域内和广泛的领域外数据集，以克服模式不匹配和预测目标异质性等方面的障碍。 |

# 详细

[^1]: FlightScope: 卫星图像中飞行器检测算法的深度全面评估

    FlightScope: A Deep Comprehensive Assessment of Aircraft Detection Algorithms in Satellite Imagery

    [https://arxiv.org/abs/2404.02877](https://arxiv.org/abs/2404.02877)

    本研究对卫星图像中识别飞机的任务自定义的一套先进对象检测算法进行了全面评估和比较，发现YOLOv5是在不同成像条件下展现高精度和适应性的最优模型。

    

    arXiv:2404.02877v1 公告类型：跨领域 摘要：在遥感卫星图像中进行对象检测对于许多领域，如生物物理学和环境监测至关重要。尽管深度学习算法不断发展，但它们大多在常见的基于地面拍摄的照片上实施和测试。本文对一套针对在卫星图像中识别飞机这一任务定制的先进对象检测算法进行了批判性评估和比较。利用大型HRPlanesV2数据集，以及与GDIT数据集的严格验证，该研究涵盖了一系列方法，包括YOLO版本5和8、Faster RCNN、CenterNet、RetinaNet、RTMDet和DETR，均是从头开始训练的。这项全面的训练和验证研究揭示了YOLOv5作为识别遥感数据中的飞机这一特定案例的卓越模型，展示了其在不同成像条件下的高精度和适应性。

    arXiv:2404.02877v1 Announce Type: cross  Abstract: Object detection in remotely sensed satellite pictures is fundamental in many fields such as biophysical, and environmental monitoring. While deep learning algorithms are constantly evolving, they have been mostly implemented and tested on popular ground-based taken photos. This paper critically evaluates and compares a suite of advanced object detection algorithms customized for the task of identifying aircraft within satellite imagery. Using the large HRPlanesV2 dataset, together with a rigorous validation with the GDIT dataset, this research encompasses an array of methodologies including YOLO versions 5 and 8, Faster RCNN, CenterNet, RetinaNet, RTMDet, and DETR, all trained from scratch. This exhaustive training and validation study reveal YOLOv5 as the preeminent model for the specific case of identifying airplanes from remote sensing data, showcasing high precision and adaptability across diverse imaging conditions. This research
    
[^2]: 无偏向学习排序遇到现实：百度大规模搜索数据集的经验教训

    Unbiased Learning to Rank Meets Reality: Lessons from Baidu's Large-Scale Search Dataset

    [https://arxiv.org/abs/2404.02543](https://arxiv.org/abs/2404.02543)

    本研究从百度搜索引擎发布的大规模搜索数据集出发，探讨了无偏向学习排序技术在实际搜索引擎中的表现，发现与排名损失和查询-文档特征选择相比，ULTR技术并未带来明显的性能改进。

    

    无偏向学习排序（ULTR）是一个用于学习用户点击数据的成熟框架，而这些数据往往受收集数据的排名者的偏见影响。虽然在理论上得到证明并在模拟中进行了广泛测试，但ULTR技术缺乏经验验证，尤其是在现代搜索引擎中。百度搜索引擎发布的WSDM Cup 2023数据集为评估主要ULTR技术在真实世界中的表现提供了难得的机会。尽管在WSDM Cup 2023期间有多次提交，以及随后的NTCIR ULTRE-2任务，但目前还不清楚观察到的改进是否源自应用ULTR或其他学习技术。我们重新审视并扩展了现有实验。我们发现，无偏向学习排序技术并不能明显提升性能，尤其是与排名损失和查询-文档特征选择带来的明显差异相比。

    arXiv:2404.02543v1 Announce Type: cross  Abstract: Unbiased learning-to-rank (ULTR) is a well-established framework for learning from user clicks, which are often biased by the ranker collecting the data. While theoretically justified and extensively tested in simulation, ULTR techniques lack empirical validation, especially on modern search engines. The dataset released for the WSDM Cup 2023, collected from Baidu's search engine, offers a rare opportunity to assess the real-world performance of prominent ULTR techniques. Despite multiple submissions during the WSDM Cup 2023 and the subsequent NTCIR ULTRE-2 task, it remains unclear whether the observed improvements stem from applying ULTR or other learning techniques. We revisit and extend the available experiments. We find that unbiased learning-to-rank techniques do not bring clear performance improvements, especially compared to the stark differences brought by the choice of ranking loss and query-document features. Our experiments 
    
[^3]: 处理连续学习中的可塑性丧失和灾难性遗忘

    Addressing Loss of Plasticity and Catastrophic Forgetting in Continual Learning

    [https://arxiv.org/abs/2404.00781](https://arxiv.org/abs/2404.00781)

    本文提出了一种新方法，即基于效用的扰动梯度下降（UPGD），通过在梯度更新中应用不同大小的扰动，保护有用单元以防遗忘，同时恢复不太有用单元的可塑性。

    

    深度表示学习方法在连续学习中存在困难，既遭受有用单元的灾难性遗忘，又因僵化和无用单元导致可塑性丢失。虽然许多方法分别解决这两个问题，但目前只有少数方法能同时处理这两个问题。本文引入了基于效用的扰动梯度下降（UPGD）作为一种用于表示持续学习的新方法。UPGD结合了梯度更新和扰动，它对更有用的单元应用较小的修改，保护它们免受遗忘，对不太有用的单元应用较大的修改，恢复它们的可塑性。

    arXiv:2404.00781v1 Announce Type: cross  Abstract: Deep representation learning methods struggle with continual learning, suffering from both catastrophic forgetting of useful units and loss of plasticity, often due to rigid and unuseful units. While many methods address these two issues separately, only a few currently deal with both simultaneously. In this paper, we introduce Utility-based Perturbed Gradient Descent (UPGD) as a novel approach for the continual learning of representations. UPGD combines gradient updates with perturbations, where it applies smaller modifications to more useful units, protecting them from forgetting, and larger modifications to less useful units, rejuvenating their plasticity. We use a challenging streaming learning setup where continual learning problems have hundreds of non-stationarities and unknown task boundaries. We show that many existing methods suffer from at least one of the issues, predominantly manifested by their decreasing accuracy over ta
    
[^4]: 利用迁移学习促进过程控制的强化学习：观点

    Facilitating Reinforcement Learning for Process Control Using Transfer Learning: Perspectives

    [https://arxiv.org/abs/2404.00247](https://arxiv.org/abs/2404.00247)

    本文从迁移学习的角度探讨了如何将其与强化学习相结合，为过程控制带来新的可能性。

    

    本文从迁移学习的角度，为过程控制中的深度强化学习（DRL）提供了深入见解。我们分析了在过程工业领域应用DRL所面临的挑战，以及引入迁移学习的必要性。此外，我们为未来研究方向提供了建议和展望，探讨了如何将迁移学习与DRL结合起来加强过程控制。

    arXiv:2404.00247v1 Announce Type: cross  Abstract: This paper provides insights into deep reinforcement learning (DRL) for process control from the perspective of transfer learning. We analyze the challenges of applying DRL in the field of process industries and the necessity of introducing transfer learning. Furthermore, recommendations and prospects are provided for future research directions on how transfer learning can be integrated with DRL to empower process control.
    
[^5]: 基于注意力机制的形状变形网络用于无伪影几何重构骨盆腰椎MR图像

    Attention-based Shape-Deformation Networks for Artifact-Free Geometry Reconstruction of Lumbar Spine from MR Images

    [https://arxiv.org/abs/2404.00231](https://arxiv.org/abs/2404.00231)

    这项工作提出了TransDeformer，使用注意力机制实现了对腰椎轮廓的高空间准确性重建，并跨患者实现了网格对应，为医学参数测量提供了可靠性，还设计了变体用于错误估计。

    

    腰椎椎间盘退变，是腰椎间盘渐进性结构性磨损，被认为在腰部疼痛中发挥重要作用，这是一个重要的全球健康关注焦点。从MR图像中自动重建腰椎几何形状，将使医学参数的快速测量成为可能，以评估腰椎状态，从而确定合适的治疗方案。现有的基于图像分割的技术通常会生成错误的分割或不适合医学参数测量的无结构点云。在这项工作中，我们提出了TransDeformer：一种新颖的基于注意力机制的深度学习方法，以高空间准确度和患者间网格对应的方式重建腰椎轮廓，并且我们还提出了一种TransDeformer的变种用于错误估计。特别是，我们设计了新的注意力模块和新的注意力公式，将图像特征和标记化的轮廓特征集成起来，用于预测...

    arXiv:2404.00231v1 Announce Type: cross  Abstract: Lumbar disc degeneration, a progressive structural wear and tear of lumbar intervertebral disc, is regarded as an essential role on low back pain, a significant global health concern. Automated lumbar spine geometry reconstruction from MR images will enable fast measurement of medical parameters to evaluate the lumbar status, in order to determine a suitable treatment. Existing image segmentation-based techniques often generate erroneous segments or unstructured point clouds, unsuitable for medical parameter measurement. In this work, we present TransDeformer: a novel attention-based deep learning approach that reconstructs the contours of the lumbar spine with high spatial accuracy and mesh correspondence across patients, and we also present a variant of TransDeformer for error estimation. Specially, we devise new attention modules with a new attention formula, which integrates image features and tokenized contour features to predict 
    
[^6]: NUMTEMP：一个用于验证带有统计和时间表达式的论点的真实世界基准

    NUMTEMP: A real-world benchmark to verify claims with statistical and temporal expressions

    [https://arxiv.org/abs/2403.17169](https://arxiv.org/abs/2403.17169)

    NUMTEMP是一个真实世界基准，专注于验证复杂的数字论点，量化了现有解决方案的局限性，并提供了一种解决真实世界数字论点验证挑战的方法。

    

    自动事实检查在数字时代应对不断增长的错误信息方面引起了极大兴趣。现有系统主要专注于维基百科上的合成论点，并且在真实世界论点上也取得了显著进展。在本文中，我们发布了Numtemp，一个多样化、多领域的数据集，专门关注数字论点，包括时间、统计和多样化方面的细粒度元数据，并且具有不泄露的证据收集。这解决了验证真实世界数字论点的挑战，这些论点复杂，往往缺乏精确信息，这是现有作品主要关注合成论点未解决的问题。我们评估并量化了现有解决方案在验证数字论点任务中的局限性。我们还评估了基于论点分解的方法、基于数字理解的模型，我们的最佳基线实现了58.32的宏F1分数。这证明了Numtemp的关键价值。

    arXiv:2403.17169v1 Announce Type: cross  Abstract: Automated fact checking has gained immense interest to tackle the growing misinformation in the digital era. Existing systems primarily focus on synthetic claims on Wikipedia, and noteworthy progress has also been made on real-world claims. In this work, we release Numtemp, a diverse, multi-domain dataset focused exclusively on numerical claims, encompassing temporal, statistical and diverse aspects with fine-grained metadata and an evidence collection without leakage. This addresses the challenge of verifying real-world numerical claims, which are complex and often lack precise information, not addressed by existing works that mainly focus on synthetic claims. We evaluate and quantify the limitations of existing solutions for the task of verifying numerical claims. We also evaluate claim decomposition based methods, numerical understanding based models and our best baselines achieves a macro-F1 of 58.32. This demonstrates that Numtemp
    
[^7]: 以多条件潜在扩散模型学习对比动力学

    Towards Learning Contrast Kinetics with Multi-Condition Latent Diffusion Models

    [https://arxiv.org/abs/2403.13890](https://arxiv.org/abs/2403.13890)

    提出了一个多条件潜在扩散模型来学习对比动力学，以减少对静脉内对比剂的依赖性。

    

    动态对比增强磁共振成像中的对比剂可以定位肿瘤并观察其对比动力学，这对于癌症表征和治疗决策至关重要。然而，对比剂的使用不仅与不良健康风险相关，而且对于怀孕患者、肾功能障碍患者或其他不良反应患者存在限制。由于对比剂摄取是病灶恶性、癌症复发风险和治疗反应的关键生物标志物，因此减少静脉内对比剂的依赖性变得至关重要。为此，我们提出了一个能够进行DCE-MRI时间序列的获取时间条件图像合成的多条件潜在扩散模型。为了评估医学图像合成，我们还提出并验证了基于生物标志物变异性的Fr\'echet放射组学距离作为图像质量度量。

    arXiv:2403.13890v1 Announce Type: cross  Abstract: Contrast agents in dynamic contrast enhanced magnetic resonance imaging allow to localize tumors and observe their contrast kinetics, which is essential for cancer characterization and respective treatment decision-making. However, contrast agent administration is not only associated with adverse health risks, but also restricted for patients during pregnancy, and for those with kidney malfunction, or other adverse reactions. With contrast uptake as key biomarker for lesion malignancy, cancer recurrence risk, and treatment response, it becomes pivotal to reduce the dependency on intravenous contrast agent administration. To this end, we propose a multi-conditional latent diffusion model capable of acquisition time-conditioned image synthesis of DCE-MRI temporal sequences. To evaluate medical image synthesis, we additionally propose and validate the Fr\'echet radiomics distance as an image quality measure based on biomarker variability 
    
[^8]: 逆向训练以消除逆转诅咒

    Reverse Training to Nurse the Reversal Curse

    [https://arxiv.org/abs/2403.13799](https://arxiv.org/abs/2403.13799)

    该研究提出了一种称为逆向训练的替代训练方案，通过在正向和逆向方向上训练语言模型并保留选定子串，成功解决了大型语言模型面临的逆转诅咒问题。

    

    大型语言模型（LLMs）存在一个令人惊讶的失败现象：当训练模型以"A具有特征B"为基础时，它们无法泛化到"B是A的特征"，这被称为逆转诅咒。即使在使用数万亿令牌进行训练时，由于齐夫定律的存在，这个问题仍然存在，这意味着即使我们在整个互联网上进行训练，该问题仍然会出现。本研究提出了一种名为逆向训练的替代训练方案，在其中所有单词被使用两次，从而使可用令牌数量加倍。该LLM在正向和逆向方向上进行训练，通过颠倒训练字符串来颠倒训练过程，同时保留（即不颠倒）选定的子串，如实体。我们展示了数据匹配的逆向训练模型在标准任务上比标准模型表现更优秀，并且计算匹配的逆向训练模型在逆转任务上表现出远远优于标准模型的性能，有助于解决逆转诅咒问题。

    arXiv:2403.13799v1 Announce Type: new  Abstract: Large language models (LLMs) have a surprising failure: when trained on "A has a feature B", they do not generalize to "B is a feature of A", which is termed the Reversal Curse. Even when training with trillions of tokens this issue still appears due to Zipf's law - hence even if we train on the entire internet. This work proposes an alternative training scheme, called reverse training, whereby all words are used twice, doubling the amount of available tokens. The LLM is trained in both forward and reverse directions by reversing the training strings while preserving (i.e., not reversing) chosen substrings, such as entities. We show that data-matched reverse-trained models provide superior performance to standard models on standard tasks, and compute-matched reverse-trained models provide far superior performance on reversal tasks, helping resolve the reversal curse issue.
    
[^9]: 使用大型语言模型纠正社交媒体上的错误信息

    Correcting misinformation on social media with a large language model

    [https://arxiv.org/abs/2403.11169](https://arxiv.org/abs/2403.11169)

    提出了一种名为MUSE的大型语言模型，通过访问最新信息并评估可信度，以解决社交媒体上误信息纠正的难题。

    

    误信息会破坏公众对科学和民主的信任，特别是在社交媒体上，不准确信息会迅速传播。专家和普通人通过手动识别和解释不准确信息已经被证明是有效的纠正误信息的方法。然而，这种方法很难扩展，这是一个担忧，因为大型语言模型（LLMs）等技术使误信息更容易生成。LLMs还具有多功能能力，可以加速纠正误信息；然而，它们由于缺乏最新信息、倾向于生成似是而非的内容和引用以及无法处理多模态信息而面临困难。为了解决这些问题，我们提出了MUSE，这是一个带有最新信息访问和可信度评估的LLM。通过检索上下文证据和反驳，MUSE可以提供准确可信的解释和参考。它还描述

    arXiv:2403.11169v1 Announce Type: cross  Abstract: Misinformation undermines public trust in science and democracy, particularly on social media where inaccuracies can spread rapidly. Experts and laypeople have shown to be effective in correcting misinformation by manually identifying and explaining inaccuracies. Nevertheless, this approach is difficult to scale, a concern as technologies like large language models (LLMs) make misinformation easier to produce. LLMs also have versatile capabilities that could accelerate misinformation correction; however, they struggle due to a lack of recent information, a tendency to produce plausible but false content and references, and limitations in addressing multimodal information. To address these issues, we propose MUSE, an LLM augmented with access to and credibility evaluation of up-to-date information. By retrieving contextual evidence and refutations, MUSE can provide accurate and trustworthy explanations and references. It also describes 
    
[^10]: 利用利润空间：资本主义如何以剥削少数群体为代价推动人工智能

    Exploiting the Margin: How Capitalism Fuels AI at the Expense of Minoritized Groups

    [https://arxiv.org/abs/2403.06332](https://arxiv.org/abs/2403.06332)

    人工智能在深化社会不平等方面起着关键作用，通过剥削边缘群体，特别是通过机制如零工经济劳工的滥用、有偏见的面部识别技术和对这些社群施加的不成比例的心理健康负担，加剧了现有的不平等。

    

    这篇文章探讨了资本主义、种族压迫和人工智能之间复杂的关系，揭示了这些元素如何共同加深社会不平等。通过追溯历史上对边缘社群的剥削，该研究表明人工智能技术不仅反映了社会偏见，而且加剧了种族差异。

    arXiv:2403.06332v1 Announce Type: cross  Abstract: This article investigates the complex nexus of capitalism, racial oppression, and artificial intelligence (AI), revealing how these elements coalesce to deepen social inequities. By tracing the historical exploitation of marginalized communities through capitalist practices, the study demonstrates how AI technologies not only reflect but also amplify societal biases, particularly in exacerbating racial disparities. Through a focused analysis, the paper presents how AI's development and application exploit marginalized groups via mechanisms such as gig economy labor abuses, biased facial recognition technologies, and the disproportionate mental health burdens placed on these communities. These examples underscore the critical role of AI in reinforcing and intensifying existing inequalities. Concluding that unregulated AI significantly threatens to compound current oppressions, the article calls for a concerted effort towards responsible
    
[^11]: LitSim：长期交互式交通仿真的冲突感知策略

    LitSim: Conflict-aware Policy for Long-term Interactive Traffic Simulation

    [https://arxiv.org/abs/2403.04299](https://arxiv.org/abs/2403.04299)

    LitSim提出了一种长期交互式仿真方法，重播日志以获得逼真场景，当出现不真实冲突时进行干预，从而提高仿真逼真度并避免碰撞

    

    模拟对于评估自动驾驶系统的性能至关重要，因为与在道路测试相比，模拟具有效率和成本优势。需要真实的多智能体行为（例如交互式和长期行为）来缩小模拟与现实之间的差距。现有工作在实现这一目标方面存在以下缺点：（1）日志重播提供了逼真的场景，但由于缺乏动态交互而导致了不真实的碰撞，以及（2）基于模型和基于学习的解决方案鼓励交互，但在长时间范围内往往偏离真实世界的数据。在这项工作中，我们提出了LitSim，一种长期交互式仿真方法，旨在最大程度地增加逼真性，同时避免不真实的碰撞。具体而言，我们为大多数情况重播日志，只有在LitSim预测到不真实冲突时才进行干预。然后我们鼓励智能体之间的交互并解决冲突，从而减少

    arXiv:2403.04299v1 Announce Type: cross  Abstract: Simulation is pivotal in evaluating the performance of autonomous driving systems due to the advantages in efficiency and cost compared to on-road testing. Realistic multi-agent behavior~(e.g., interactive and long-term) is needed to narrow the gap between the simulation and the reality. The existing work has the following shortcomings in achieving this goal:~(1) log replay offers realistic scenarios but leads to unrealistic collisions due to lacking dynamic interactions, and~(2) model-based and learning-based solutions encourage interactions but often deviate from real-world data in long horizons. In this work, we propose LitSim, a long-term interactive simulation approach that maximizes realism while avoiding unrealistic collisions. Specifically, we replay the log for most scenarios and intervene only when LitSim predicts unrealistic conflicts. We then encourage interactions among the agents and resolve the conflicts, thereby reducin
    
[^12]: 为医药领域打造安全和对齐的大型语言模型

    Towards Safe and Aligned Large Language Models for Medicine

    [https://arxiv.org/abs/2403.03744](https://arxiv.org/abs/2403.03744)

    对医学LLMs进行了首次安全评估，并探讨了如何定义医学安全和对齐性，开发了有害医学问题数据集，评估了医学LLMs的安全性和对齐性，展示了微调是一种有效的缓解策略。

    

    大型语言模型（LLMs）的能力正在以惊人的速度进步，即使是它们的开发者也对它们的潜力和风险的深度感到困惑。尽管已经采取了初步步骤评估通用知识LLMs的安全性和对齐性，揭示了一些弱点，但据我们所知，尽管在个人健康和安全、公共健康和安全以及人权方面存在风险，医学LLMs的安全性和对齐性尚未得到评估。为此，我们进行了对医学LLMs的首次安全评估。具体而言，我们提出了医学人工智能系统的医学安全性和对齐性的定义，开发了一个有害医学问题的数据集来评估LLM的医学安全性和对齐性，评估了医学LLMs的通用安全性和对齐性，展示了微调作为一种有效的缓解策略，并讨论了更广泛的、大规模的方法。

    arXiv:2403.03744v1 Announce Type: new  Abstract: The capabilities of large language models (LLMs) have been progressing at a breathtaking speed, leaving even their own developers grappling with the depth of their potential and risks. While initial steps have been taken to evaluate the safety and alignment of general-knowledge LLMs, exposing some weaknesses, to our knowledge, the safety and alignment of medical LLMs has not been evaluated despite their risks for personal health and safety, public health and safety, and human rights. To this end, we carry out the first safety evaluation for medical LLMs. Specifically, we set forth a definition of medical safety and alignment for medical artificial intelligence systems, develop a dataset of harmful medical questions to evaluate the medical safety and alignment of an LLM, evaluate both general and medical safety and alignment of medical LLMs, demonstrate fine-tuning as an effective mitigation strategy, and discuss broader, large-scale appr
    
[^13]: Brilla AI: 全国科学与数学竞赛的人工智能参赛者

    Brilla AI: AI Contestant for the National Science and Maths Quiz

    [https://arxiv.org/abs/2403.01699](https://arxiv.org/abs/2403.01699)

    人工智能参赛者Brilla AI在全国科学与数学竞赛中表现优秀，为缺乏合格教师的非洲提供了学习支持。

    

    非洲大陆缺乏足够的合格教师，这阻碍了提供足够的学习支持。人工智能有可能增强有限数量教师的努力，从而带来更好的学习成果。本文描述并评估了NSMQ AI Grand Challenge的首要成果，该挑战提出了一个强大的现实基准，用于评估此类人工智能：“建立一个人工智能，参加加纳的全国科学与数学竞赛（NSMQ），并获胜——在比赛的所有轮次和阶段中表现优于最优秀的参赛者”。NSMQ是加纳的高中学生每年举行的现场科学与数学竞赛，3队2名学生通过回答生物学、化学、物理和数学问题在5轮比赛中竞争，逐渐晋级至最终冠军的队伍。在本研究中，我们建立了Brilla AI，一个参加NSMQ竞赛的人工智能选手。

    arXiv:2403.01699v1 Announce Type: cross  Abstract: The African continent lacks enough qualified teachers which hampers the provision of adequate learning support. An AI could potentially augment the efforts of the limited number of teachers, leading to better learning outcomes. Towards that end, this work describes and evaluates the first key output for the NSMQ AI Grand Challenge, which proposes a robust, real-world benchmark for such an AI: "Build an AI to compete live in Ghana's National Science and Maths Quiz (NSMQ) competition and win - performing better than the best contestants in all rounds and stages of the competition". The NSMQ is an annual live science and mathematics competition for senior secondary school students in Ghana in which 3 teams of 2 students compete by answering questions across biology, chemistry, physics, and math in 5 rounds over 5 progressive stages until a winning team is crowned for that year. In this work, we built Brilla AI, an AI contestant that we de
    
[^14]: FusionVision：使用YOLO和快速分割任意物体的综合方法进行从RGB-D相机重建和分割的3D对象

    FusionVision: A comprehensive approach of 3D object reconstruction and segmentation from RGB-D cameras using YOLO and fast segment anything

    [https://arxiv.org/abs/2403.00175](https://arxiv.org/abs/2403.00175)

    FusionVision提出了一种综合方法，将YOLO和快速分割任何物体的技术整合到RGB-D相机处理中，实现了对3D物体的鲁棒分割

    

    在计算机视觉领域，将先进技术整合到RGB-D相机输入处理中构成了重大挑战，因为环境条件的多样性和物体外观的变化带来了固有的复杂性。因此，本文介绍了FusionVision，一种为在RGB-D图像中鲁棒地进行3D物体分割而调整的详尽管道。传统计算机视觉系统在同时捕捉精确的物体边界并在深度图上实现高精度物体检测方面存在局限，因为它们主要是为RGB摄像机提出的。为了解决这一挑战，FusionVision采用了综合方法，通过将最先进的物体检测技术与先进的实例分割方法相结合。这些组件的整合使得能够对从彩色RGB和深度D信道获得的信息进行全面统一的解释

    arXiv:2403.00175v1 Announce Type: cross  Abstract: In the realm of computer vision, the integration of advanced techniques into the processing of RGB-D camera inputs poses a significant challenge, given the inherent complexities arising from diverse environmental conditions and varying object appearances. Therefore, this paper introduces FusionVision, an exhaustive pipeline adapted for the robust 3D segmentation of objects in RGB-D imagery. Traditional computer vision systems face limitations in simultaneously capturing precise object boundaries and achieving high-precision object detection on depth map as they are mainly proposed for RGB cameras. To address this challenge, FusionVision adopts an integrated approach by merging state-of-the-art object detection techniques, with advanced instance segmentation methods. The integration of these components enables a holistic (unified analysis of information obtained from both color \textit{RGB} and depth \textit{D} channels) interpretation 
    
[^15]: 在语言模型对话中测量和控制“人设”漂移

    Measuring and Controlling Persona Drift in Language Model Dialogs

    [https://arxiv.org/abs/2402.10962](https://arxiv.org/abs/2402.10962)

    提出了一种量化基准来测量语言模型对话中的“人设”漂移，并提出了一种称为split-softmax的轻量级方法来对抗注意力衰减和“人设”漂移

    

    提示是定制语言模型聊天机器人的标准工具，使其能够承担特定的“人设”。在使用提示时的一个隐含假设是，它们将是稳定的，因此聊天机器人将在整个对话过程中继续根据规定的“人设”生成文本。我们提出了一个量化基准来测试这一假设，通过两个个性化聊天机器人之间的自我对话来评估“人设”的稳定性。我们对流行模型如LLaMA2-chat-70B进行测试，发现在八轮对话中存在显著的“人设”漂移。对这一现象的实证和理论分析表明，由于长对话中的注意力衰减，变压器注意力机制起到了一定作用。为了对抗注意力衰减和“人设”漂移，我们提出了一种称为split-softmax的轻量级方法，与两个强基线方法相比表现优异。

    arXiv:2402.10962v1 Announce Type: cross  Abstract: Prompting is a standard tool for customizing language-model chatbots, enabling them to take on a specific "persona". An implicit assumption in the use of prompts is that they will be stable, so the chatbot will continue to generate text according to the stipulated persona for the duration of a conversation. We propose a quantitative benchmark to test this assumption, evaluating persona stability via self-chats between two personalized chatbots. Testing popular models like LLaMA2-chat-70B, we reveal a significant persona drift within eight rounds of conversations. An empirical and theoretical analysis of this phenomenon suggests the transformer attention mechanism plays a role, due to attention decay over long exchanges. To combat attention decay and persona drift, we propose a lightweight method called split-softmax, which compares favorably against two strong baselines.
    
[^16]: 将大型语言模型作为零-shot对话状态追踪器通过函数调用

    Large Language Models as Zero-shot Dialogue State Tracker through Function Calling

    [https://arxiv.org/abs/2402.10466](https://arxiv.org/abs/2402.10466)

    本研究提出了一种通过函数调用将大型语言模型用于零-shot对话状态追踪的新方法，能够在任务导向对话中取得出色的性能，适应不同领域而无需大量数据收集或模型调整。

    

    大型语言模型（LLMs）在会话系统中日益普遍，这是因为它们在一般情境中具有先进的理解和生成能力。然而，在需要不仅进行响应生成还需要在特定任务和领域内进行有效对话状态追踪（DST）的任务导向对话（TOD）中，它们的有效性仍不尽人意。在这项工作中，我们提出了一种通过函数调用解决LLMs中的DST的新方法FnCTOD。这种方法改进了零-shot DST，使其能够适应各种领域，而无需进行大量数据收集或模型调整。我们的实验结果表明，我们的方法在使用开源或专有LLMs时都取得了出色的性能：通过上下文提示，使得各种7B或13B参数模型超越了之前由ChatGPT实现的最新技术成果（SOTA）的水平，并提高了ChatGPT的性能，击败了

    arXiv:2402.10466v1 Announce Type: cross  Abstract: Large language models (LLMs) are increasingly prevalent in conversational systems due to their advanced understanding and generative capabilities in general contexts. However, their effectiveness in task-oriented dialogues (TOD), which requires not only response generation but also effective dialogue state tracking (DST) within specific tasks and domains, remains less satisfying. In this work, we propose a novel approach FnCTOD for solving DST with LLMs through function calling. This method improves zero-shot DST, allowing adaptation to diverse domains without extensive data collection or model tuning. Our experimental results demonstrate that our approach achieves exceptional performance with both modestly sized open-source and also proprietary LLMs: with in-context prompting it enables various 7B or 13B parameter models to surpass the previous state-of-the-art (SOTA) achieved by ChatGPT, and improves ChatGPT's performance beating the
    
[^17]: 模型崩溃解密：回归案例研究

    Model Collapse Demystified: The Case of Regression

    [https://arxiv.org/abs/2402.07712](https://arxiv.org/abs/2402.07712)

    本研究在核回归的简化环境中解析了模型崩溃现象，并发现了模型能够处理虚假数据与性能完全崩溃之间的交叉点。通过提出基于自适应正则化的策略，成功缓解了模型崩溃问题。这些发现通过实验证实。

    

    在像ChatGPT这样的大型语言模型的时代，"模型崩溃"现象指的是模型在递归地训练自身上一代又一代生成的数据时，其性能逐渐降低，最终变得完全无用，即模型崩溃。在这项工作中，我们在核回归的简化环境中研究了这一现象，并获得了结果，显示模型能够处理虚假数据与模型性能完全崩溃之间存在明显的交叉点。在多项式衰减的光谱和源条件下，我们获得了修改后的缩放定律，展示了从快速到缓慢速率的新交叉现象。我们还提出了基于自适应正则化的简单策略来缓解模型崩溃。我们的理论结果通过实验证实。

    In the era of large language models like ChatGPT, the phenomenon of "model collapse" refers to the situation whereby as a model is trained recursively on data generated from previous generations of itself over time, its performance degrades until the model eventually becomes completely useless, i.e the model collapses. In this work, we study this phenomenon in the simplified setting of kernel regression and obtain results which show a clear crossover between where the model can cope with fake data, and a regime where the model's performance completely collapses. Under polynomial decaying spectral and source conditions, we obtain modified scaling laws which exhibit new crossover phenomena from fast to slow rates. We also propose a simple strategy based on adaptive regularization to mitigate model collapse. Our theoretical results are validated with experiments.
    
[^18]: 用自然语言和概率推理进行实验与修订规则

    Doing Experiments and Revising Rules with Natural Language and Probabilistic Reasoning

    [https://arxiv.org/abs/2402.06025](https://arxiv.org/abs/2402.06025)

    本论文建立了一个计算模型来模拟人们通过实验主动推断隐藏规则的过程，并发现显式假设、概率规则和在线更新的组合可以解释人们在类似Zendo任务上的表现。

    

    我们建立了一个计算模型，模拟人们通过实验主动推断隐藏规则的过程。该模型的基本原理是，即使规则是确定性的，学习者也会考虑更广泛的模糊概率规则，并用自然语言表示，根据近似贝叶斯原则在每次实验后在线更新自己的假设。在同一框架下，我们还根据信息论准则建立了实验设计模型。我们发现，这三个原则的组合——显式假设、概率规则和在线更新——可以解释人们在类似Zendo任务上的表现，而去掉其中任何一个组件都使得模型无法解释数据。

    We build a computational model of how humans actively infer hidden rules by doing experiments. The basic principles behind the model is that, even if the rule is deterministic, the learner considers a broader space of fuzzy probabilistic rules, which it represents in natural language, and updates its hypotheses online after each experiment according to approximately Bayesian principles. In the same framework we also model experiment design according to information-theoretic criteria. We find that the combination of these three principles -- explicit hypotheses, probabilistic rules, and online updates -- can explain human performance on a Zendo-style task, and that removing any of these components leaves the model unable to account for the data.
    
[^19]: RGI-Net：在没有一阶回声的情况下从房间脉冲响应中推断3D房间几何

    RGI-Net: 3D Room Geometry Inference from Room Impulse Responses in the Absence of First-order Echoes

    [https://arxiv.org/abs/2309.01513](https://arxiv.org/abs/2309.01513)

    RGI-Net通过深度神经网络学习和利用房间脉冲响应中高阶反射之间的关系，实现在没有传统假设的情况下推断房间几何信息。

    

    房间几何是实现逼真的3D音频渲染的重要先验信息。为此，利用房间脉冲响应中到达时间（TOA）或到达时间差（TDOA）信息发展了各种房间几何推断（RGI）方法。然而，传统的RGI技术提出了一些假设，如凸房间形状、已知墙壁数量和一阶反射的可见性。在这项工作中，我们引入了深度神经网络（DNN）RGI-Net，它可以在没有上述假设的情况下估计房间几何。RGI-Net学习并利用房间脉冲响应（RIRs）中的高阶反射之间的复杂关系，因此可以在形状为非凸形或RIRs中缺少一阶反射的情况下估计房间形状。该网络采用从装有圆形麦克风的紧凑音频设备测量的RIRs。

    arXiv:2309.01513v2 Announce Type: replace-cross  Abstract: Room geometry is important prior information for implementing realistic 3D audio rendering. For this reason, various room geometry inference (RGI) methods have been developed by utilizing the time of arrival (TOA) or time difference of arrival (TDOA) information in room impulse responses. However, the conventional RGI technique poses several assumptions, such as convex room shapes, the number of walls known in priori, and the visibility of first-order reflections. In this work, we introduce the deep neural network (DNN), RGI-Net, which can estimate room geometries without the aforementioned assumptions. RGI-Net learns and exploits complex relationships between high-order reflections in room impulse responses (RIRs) and, thus, can estimate room shapes even when the shape is non-convex or first-order reflections are missing in the RIRs. The network takes RIRs measured from a compact audio device equipped with a circular microphon
    
[^20]: 通过具有分层正则化的医学代码中心的多模态对比EHR建模预测下次就诊诊断

    Next Visit Diagnosis Prediction via Medical Code-Centric Multimodal Contrastive EHR Modelling with Hierarchical Regularisation. (arXiv:2401.11648v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2401.11648](http://arxiv.org/abs/2401.11648)

    通过医学代码中心的多模态对比EHR建模预测下次就诊诊断，并通过分层正则化提高性能。

    

    在医疗保健中，利用电子健康记录（EHR）预测下次就诊的诊断是一项必要的任务，对于制定医疗保健提供者和患者的主动未来计划至关重要。然而，之前的许多研究并没有充分解决EHR数据固有的异构和分层特征，必然导致次优的性能。为此，我们提出了NECHO，一种新颖的医学代码中心的多模态对比EHR学习框架，其中包括分层正则化。首先，我们使用定制的网络设计和一对双模态对比损失融合涵盖医学代码、人口统计数据和临床笔记的多方面信息，所有这些都围绕着医学代码表现。我们还使用医学本体中的父级信息来规范特定模态的编码器，以学习EHR数据的层次结构。对MIMIC-III数据进行的一系列实验证明了我们方法的有效性。

    Predicting next visit diagnosis using Electronic Health Records (EHR) is an essential task in healthcare, critical for devising proactive future plans for both healthcare providers and patients. Nonetheless, many preceding studies have not sufficiently addressed the heterogeneous and hierarchical characteristics inherent in EHR data, inevitably leading to sub-optimal performance. To this end, we propose NECHO, a novel medical code-centric multimodal contrastive EHR learning framework with hierarchical regularisation. First, we integrate multifaceted information encompassing medical codes, demographics, and clinical notes using a tailored network design and a pair of bimodal contrastive losses, all of which pivot around a medical code representation. We also regularise modality-specific encoders using a parental level information in medical ontology to learn hierarchical structure of EHR data. A series of experiments on MIMIC-III data demonstrates effectiveness of our approach.
    
[^21]: 数千位AI作者对未来AI的预测

    Thousands of AI Authors on the Future of AI. (arXiv:2401.02843v1 [cs.CY])

    [http://arxiv.org/abs/2401.02843](http://arxiv.org/abs/2401.02843)

    数千位AI作者对未来AI的预测显示，到2028年，AI系统有50%的几率实现多个里程碑，包括自主构建全新的付款处理网站、创作一首与知名音乐家的新歌难以区分的歌曲，并自主下载和调整大型语言模型。同时，无需辅助的机器在各种任务上胜过人类的几率估计为10%到2047年为50%。

    

    在迄今为止最大规模的调查中，2778名在顶级人工智能（AI）会议上发表过论文的研究人员对AI进展的速度、高级AI系统的性质和影响进行了预测。总体预测显示，到2028年，AI系统至少有50%的几率实现多个里程碑，包括自主构建一个全新的付款处理网站、创作一首可以与知名音乐家的新歌难以区分的歌曲，并自主下载和调整大型语言模型。如果科学持续不受干扰，2027年无需辅助的机器在各种任务上胜过人类的几率估计为10%，到2047年为50%。后者的估计比我们一年前进行的类似调查[Grace et al., 2022]提前了13年。然而，所有人类职业完全可自动化的几率预计要到2037年达到10%，到2116年才达到50%（与2022年调查中的2164年相比）。

    In the largest survey of its kind, 2,778 researchers who had published in top-tier artificial intelligence (AI) venues gave predictions on the pace of AI progress and the nature and impacts of advanced AI systems The aggregate forecasts give at least a 50% chance of AI systems achieving several milestones by 2028, including autonomously constructing a payment processing site from scratch, creating a song indistinguishable from a new song by a popular musician, and autonomously downloading and fine-tuning a large language model. If science continues undisrupted, the chance of unaided machines outperforming humans in every possible task was estimated at 10% by 2027, and 50% by 2047. The latter estimate is 13 years earlier than that reached in a similar survey we conducted only one year earlier [Grace et al., 2022]. However, the chance of all human occupations becoming fully automatable was forecast to reach 10% by 2037, and 50% as late as 2116 (compared to 2164 in the 2022 survey).  Most
    
[^22]: 进化计算与大语言模型击败人类：高效引导局部搜索设计的例子

    An Example of Evolutionary Computation + Large Language Model Beating Human: Design of Efficient Guided Local Search. (arXiv:2401.02051v1 [cs.NE])

    [http://arxiv.org/abs/2401.02051](http://arxiv.org/abs/2401.02051)

    使用进化计算和大语言模型的算法进化框架，自动设计了高效的引导局部搜索算法来解决旅行商问题，在实验中表现优于人工设计的算法，标志着自动算法设计的新时代出现。

    

    对人类专家来说，设计高效算法通常非常繁琐。最近，我们提出了一种新颖的算法进化与大语言模型（AEL）框架，用于自动算法设计。AEL将大语言模型的能力与进化计算的范式相结合，实现自动设计、组合和修改算法。在本文中，我们使用AEL来设计引导局部搜索（GLS）的引导算法，以解决著名的旅行商问题（TSP）。AEL自动演化出优秀的GLS算法，在两天内实现，只需要极少的人力投入和无需模型训练。在1,000个TSP20-TSP100实例和TSPLib实例上的实验结果表明，AEL设计的GLS算法在相同的迭代预算下优于最先进的人工设计的GLS算法。在1,000次迭代中，它在TSP20和TSP50上达到0%间隙，在TSP100上达到0.032%间隙。我们的发现标志着自动算法设计的新时代的出现。

    It is often very tedious for human experts to design efficient algorithms. Recently, we have proposed a novel Algorithm Evolution using Large Language Model (AEL) framework for automatic algorithm design. AEL combines the power of a large language model and the paradigm of evolutionary computation to design, combine, and modify algorithms automatically. In this paper, we use AEL to design the guide algorithm for guided local search (GLS) to solve the well-known traveling salesman problem (TSP). AEL automatically evolves elite GLS algorithms in two days, with minimal human effort and no model training. Experimental results on 1,000 TSP20-TSP100 instances and TSPLib instances show that AEL-designed GLS outperforms state-of-the-art human-designed GLS with the same iteration budget. It achieves a 0% gap on TSP20 and TSP50 and a 0.032% gap on TSP100 in 1,000 iterations. Our findings mark the emergence of a new era in automatic algorithm design.
    
[^23]: 人类反馈的迭代偏好学习：在KL约束下将理论与实践联系起来的RLHF

    Iterative Preference Learning from Human Feedback: Bridging Theory and Practice for RLHF under KL-Constraint. (arXiv:2312.11456v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2312.11456](http://arxiv.org/abs/2312.11456)

    该论文研究了在KL约束下的反馈强化学习的理论框架，并提出了有效的算法和实践。实证评估表明，该框架在大型语言模型的对齐实验中表现出良好的效果。

    

    本文研究了生成模型与强化学习从人类反馈中的对齐过程的理论框架。我们考虑了一个标准的数学表达式，即反向KL正则化的上下文多臂赌博机用于RLHF。尽管它被广泛应用于实际应用，但对这个公式的严格理论分析仍然很开放。我们研究了它在离线、在线和混合三种不同场景下的行为，并提出了具有有限样本理论保证的高效算法。朝着实际应用的方向，我们的框架通过对信息理论策略改进预言的稳健近似，自然地产生了几种新颖的RLHF算法。这包括在线场景中的迭代版本的直接偏好优化(DPO)算法，以及离线情景下的多步拒绝抽样策略。我们对大型语言模型的真实对齐实验进行了实证评估。

    This paper studies the theoretical framework of the alignment process of generative models with Reinforcement Learning from Human Feedback (RLHF). We consider a standard mathematical formulation, the reverse-KL regularized contextual bandit for RLHF. Despite its widespread practical application, a rigorous theoretical analysis of this formulation remains open. We investigate its behavior in three distinct settings -- offline, online, and hybrid -- and propose efficient algorithms with finite-sample theoretical guarantees.  Moving towards practical applications, our framework, with a robust approximation of the information-theoretical policy improvement oracle, naturally gives rise to several novel RLHF algorithms. This includes an iterative version of the Direct Preference Optimization (DPO) algorithm for online settings, and a multi-step rejection sampling strategy for offline scenarios. Our empirical evaluations on real-world alignment experiment of large language model demonstrate t
    
[^24]: AI对齐: 一项全面调查

    AI Alignment: A Comprehensive Survey. (arXiv:2310.19852v1 [cs.AI])

    [http://arxiv.org/abs/2310.19852](http://arxiv.org/abs/2310.19852)

    本篇论文主要介绍了AI对齐的概念、方法和实践。研究围绕四个关键目标：健壮性、可解释性、可控性和道德性展开，并将其分为前向对齐和后向对齐两个部分。 AI对齐是为了构建符合人类意图和价值观的AI系统，并减轻由于系统不对齐带来的潜在风险。

    

    AI对齐旨在构建符合人类意图和价值观的AI系统。随着拥有超人类能力的AI系统的出现，错误对齐系统所带来的潜在大规模风险变得明显。数百名AI专家和公众人物都对AI风险表达了关注，认为减轻AI带来的灭绝风险应该成为全球的优先事项，与大规模社会风险如大流行病和核战争并列。鉴于AI对齐领域缺乏最新的系统调查，本文深入探讨对齐研究的核心概念、方法论和实践。首先，我们确定了四个目标原则作为AI对齐的关键目标：健壮性、可解释性、可控性和道德性（RICE）。我们概述了当前对齐研究的现状，并将其分解为两个关键组成部分：前向对齐和后向对齐。前者旨在使AI系统与人类意图对齐。

    AI alignment aims to build AI systems that are in accordance with human intentions and values. With the emergence of AI systems possessing superhuman capabilities, the potential large-scale risks associated with misaligned systems become apparent. Hundreds of AI experts and public figures have expressed their concerns about AI risks, arguing that mitigating the risk of extinction from AI should be a global priority, alongside other societal-scale risks such as pandemics and nuclear war. Motivated by the lack of an up-to-date systematic survey on AI alignment, in this paper, we delve into the core concepts, methodology, and practice of alignment research. To begin with, we identify four principles as the key objectives of AI alignment: Robustness, Interpretability, Controllability, and Ethicality (RICE). We outline the landscape of current alignment research and decompose them into two key components: forward alignment and backward alignment. The former aims to make AI systems aligned v
    
[^25]: 使用绝热量子计算的平衡K-Means的概率采样

    Probabilistic Sampling of Balanced K-Means using Adiabatic Quantum Computing. (arXiv:2310.12153v1 [cs.LG])

    [http://arxiv.org/abs/2310.12153](http://arxiv.org/abs/2310.12153)

    该论文研究了使用绝热量子计算的平衡K-Means聚类的概率采样方法，通过利用非最优解来计算校准后验概率，实现在D-Wave AQC上识别模糊解决方案和数据点的目标。

    

    绝热量子计算（AQC）是一种有望用于离散且通常为NP困难优化问题的量子计算方法。目前的AQC允许实现感兴趣的问题，这促使了为许多机器学习和计算机视觉任务开发量子表示的发展。尽管需要从噪声AQC进行多次测量，但当前方法仅利用最佳测量，丢弃了其他测量中包含的信息。在这项工作中，我们探讨了利用这些信息进行概率平衡k-means聚类的潜力。我们提出了使用非最优解来计算校准后验概率的方法，计算成本很低。这使我们能够识别模糊的解决方案和数据点，我们在D-Wave AQC上使用合成和真实数据进行了验证。

    Adiabatic quantum computing (AQC) is a promising quantum computing approach for discrete and often NP-hard optimization problems. Current AQCs allow to implement problems of research interest, which has sparked the development of quantum representations for many machine learning and computer vision tasks. Despite requiring multiple measurements from the noisy AQC, current approaches only utilize the best measurement, discarding information contained in the remaining ones. In this work, we explore the potential of using this information for probabilistic balanced k-means clustering. Instead of discarding non-optimal solutions, we propose to use them to compute calibrated posterior probabilities with little additional compute cost. This allows us to identify ambiguous solutions and data points, which we demonstrate on a D-Wave AQC on synthetic and real data.
    
[^26]: CCA家族的高效算法：无约束目标与无偏梯度

    Efficient Algorithms for the CCA Family: Unconstrained Objectives with Unbiased Gradients. (arXiv:2310.01012v1 [cs.LG])

    [http://arxiv.org/abs/2310.01012](http://arxiv.org/abs/2310.01012)

    本论文提出了一个新颖的无约束目标，通过应用随机梯度下降（SGD）到CCA目标，实现了一系列快速算法，包括随机PLS、随机CCA和深度CCA。这些方法在各种基准测试中表现出比先前最先进方法更快的收敛速度和更高的相关性恢复。

    

    典型相关分析（CCA）方法在多视角学习中具有基础性作用。正则化线性CCA方法可以看作是偏最小二乘（PLS）的推广，并与广义特征值问题（GEP）框架统一。然而，这些线性方法的传统算法在大规模数据上计算上是不可行的。深度CCA的扩展显示出很大的潜力，但目前的训练过程缓慢且复杂。我们首先提出了一个描述GEPs的顶级子空间的新颖无约束目标。我们的核心贡献是一系列快速算法，用随机梯度下降（SGD）应用于相应的CCA目标，从而获得随机PLS、随机CCA和深度CCA。这些方法在所有标准CCA和深度CCA基准测试中显示出比先前最先进方法更快的收敛速度和更高的相关性恢复。这样的速度使我们能够首次进行大规模生物数据的PLS分析。

    The Canonical Correlation Analysis (CCA) family of methods is foundational in multi-view learning. Regularised linear CCA methods can be seen to generalise Partial Least Squares (PLS) and unified with a Generalized Eigenvalue Problem (GEP) framework. However, classical algorithms for these linear methods are computationally infeasible for large-scale data. Extensions to Deep CCA show great promise, but current training procedures are slow and complicated. First we propose a novel unconstrained objective that characterizes the top subspace of GEPs. Our core contribution is a family of fast algorithms for stochastic PLS, stochastic CCA, and Deep CCA, simply obtained by applying stochastic gradient descent (SGD) to the corresponding CCA objectives. These methods show far faster convergence and recover higher correlations than the previous state-of-the-art on all standard CCA and Deep CCA benchmarks. This speed allows us to perform a first-of-its-kind PLS analysis of an extremely large bio
    
[^27]: 作为有效抽象的归纳偏好的关系瓶颈

    The Relational Bottleneck as an Inductive Bias for Efficient Abstraction. (arXiv:2309.06629v1 [cs.AI])

    [http://arxiv.org/abs/2309.06629](http://arxiv.org/abs/2309.06629)

    本文介绍了一种新的归纳偏好方法——关系瓶颈，用于有效地诱导抽象概念的模型，强调了其在人类思维和大脑中抽象概念习得中的潜力。

    

    认知科学的一个核心挑战是解释如何从有限经验中获取抽象概念。这一努力常常被描述为经验主义和天赋主义方法之间的二分法，最近主要体现在有关深度神经网络和符号认知模型的争论中。在这里，我们强调了一种最近兴起的工作线路，该线路通过利用我们称之为关系瓶颈的归纳偏好，提出了这些方法的一种新的调和方式。我们回顾了一系列采用这种方法在数据有效的方式下诱导出抽象的模型，强调了它们作为人类思维和大脑中抽象概念习得的候选模型的潜力。

    A central challenge for cognitive science is to explain how abstract concepts are acquired from limited experience. This effort has often been framed in terms of a dichotomy between empiricist and nativist approaches, most recently embodied by debates concerning deep neural networks and symbolic cognitive models. Here, we highlight a recently emerging line of work that suggests a novel reconciliation of these approaches, by exploiting an inductive bias that we term the relational bottleneck. We review a family of models that employ this approach to induce abstractions in a data-efficient manner, emphasizing their potential as candidate models for the acquisition of abstract concepts in the human mind and brain.
    
[^28]: 回应：大型语言模型中的紧急类比推理

    Response: Emergent analogical reasoning in large language models. (arXiv:2308.16118v1 [cs.CL])

    [http://arxiv.org/abs/2308.16118](http://arxiv.org/abs/2308.16118)

    该论文回应了关于大型语言模型中紧急类比推理的主张，并通过提供字符串类比的反例来反驳。在测试中，GPT-3无法解决最简单的类比问题。为了加强零点推理等人类推理的主张，需要发展出排除数据记忆的方法。

    

    在最近的《自然人类行为》论文中，“大型语言模型中的紧急类比推理”（Webb，Holyoak和Lu，2023），作者们认为“像GPT-3这样的大型语言模型已经获得了发现广泛类比问题的零点解的紧急能力”。在本回应中，我们提供了一些字符串类比的反例。在我们的测试中，GPT-3甚至无法解决原始论文中提出的最简单的变体问题。零点推理是一个需要非常充分证据支持的非凡主张。在我们的实验中，我们没有看到这样的证据。为了加强像零点推理这样类似人类推理的主张，重要的是该领域开发出能够排除数据记忆的方法。

    In their recent Nature Human Behaviour paper, "Emergent analogical reasoning in large language models," (Webb, Holyoak, and Lu, 2023) the authors argue that "large language models such as GPT-3 have acquired an emergent ability to find zero-shot solutions to a broad range of analogy problems." In this response, we provide counterexamples of the letter string analogies. In our tests, GPT-3 fails to solve even the easiest variants of the problems presented in the original paper. Zero-shot reasoning is an extraordinary claim that requires extraordinary evidence. We do not see that evidence in our experiments. To strengthen claims of humanlike reasoning such as zero-shot reasoning, it is important that the field develop approaches that rule out data memorization.
    
[^29]: Retroformer：使用策略梯度优化的回顾性大型语言代理

    Retroformer: Retrospective Large Language Agents with Policy Gradient Optimization. (arXiv:2308.02151v1 [cs.CL])

    [http://arxiv.org/abs/2308.02151](http://arxiv.org/abs/2308.02151)

    本文介绍了一种通过策略梯度优化的回顾性大型语言代理框架，该框架通过学习环境反馈来调整语言代理的提示，从而优化其性能。这种代理能够从多个环境和任务中学习奖励，并通过总结以前任务的根本原因来改进语言代理提示。

    

    最近几个月，出现了一个强大的新趋势，即将大型语言模型（LLMs）增强成能够自主完成目标导向多步骤任务的语言代理，而不仅仅是回答人类用户的查询。然而，大多数现有的语言代理没有使用环境特定的奖励进行优化。尽管一些代理通过口头反馈实现了迭代改进，但它们不能以与基于梯度的奖励学习相兼容的方式进行推理和规划。本文提出了一个原则性的框架，通过学习回顾模型，通过策略梯度自动调整语言代理的提示，从环境反馈中优化代理的工作。具体而言，我们提出的代理架构通过学习多个环境和任务的奖励来微调预训练语言模型，从而通过总结以前任务的根本原因来改进语言代理提示。

    Recent months have seen the emergence of a powerful new trend in which large language models (LLMs) are augmented to become autonomous language agents capable of performing objective oriented multi-step tasks on their own, rather than merely responding to queries from human users. Most existing language agents, however, are not optimized using environment-specific rewards. Although some agents enable iterative refinement through verbal feedback, they do not reason and plan in ways that are compatible with gradient-based learning from rewards. This paper introduces a principled framework for reinforcing large language agents by learning a retrospective model, which automatically tunes the language agent prompts from environment feedback through policy gradient. Specifically, our proposed agent architecture learns from rewards across multiple environments and tasks, for fine-tuning a pre-trained language model which refines the language agent prompt by summarizing the root cause of prior
    
[^30]: 通过真实厚切片CT模拟改进超分辨网络

    Enhancing Super-Resolution Networks through Realistic Thick-Slice CT Simulation. (arXiv:2307.10182v1 [eess.IV])

    [http://arxiv.org/abs/2307.10182](http://arxiv.org/abs/2307.10182)

    本研究通过开发一种创新的模拟算法，成功生成与实际图像非常相似的厚切片CT图像，并证明该方法在峰值信噪比和均方根误差方面明显优于其他模拟方法。

    

    该研究旨在开发和评估一种创新的模拟算法，用于生成与AAPM-Mayo's 2016低剂量CT大挑战数据集中的实际图像密切相似的厚切片CT图像。提出的方法使用峰值信噪比（PSNR）和均方根误差（RMSE）指标进行评估，假设我们的模拟将产生与真实图像更一致的图像。我们提出的方法在PSNR和RMSE方面显示出显著的改进，最高PSNR值为D45和B30重建核分别为49.7369±2.5223和48.5801±7.3271。提出的方法还以0.0068±0.0020和0.0108±0.0099的RMSE值注册最低的误差，表明其分布更接近于真实的厚切片图像。

    This study aims to develop and evaluate an innovative simulation algorithm for generating thick-slice CT images that closely resemble actual images in the AAPM-Mayo's 2016 Low Dose CT Grand Challenge dataset. The proposed method was evaluated using Peak Signal-to-Noise Ratio (PSNR) and Root Mean Square Error (RMSE) metrics, with the hypothesis that our simulation would produce images more congruent with their real counterparts. Our proposed method demonstrated substantial enhancements in terms of both PSNR and RMSE over other simulation methods. The highest PSNR values were obtained with the proposed method, yielding 49.7369 $\pm$ 2.5223 and 48.5801 $\pm$ 7.3271 for D45 and B30 reconstruction kernels, respectively. The proposed method also registered the lowest RMSE with values of 0.0068 $\pm$ 0.0020 and 0.0108 $\pm$ 0.0099 for D45 and B30, respectively, indicating a distribution more closely aligned with the authentic thick-slice image. Further validation of the proposed simulation al
    
[^31]: 自适应采集数据的离线强化学习策略评估

    Offline Policy Evaluation for Reinforcement Learning with Adaptively Collected Data. (arXiv:2306.14063v1 [cs.LG])

    [http://arxiv.org/abs/2306.14063](http://arxiv.org/abs/2306.14063)

    本论文提出了一种自适应采集数据的离线强化学习策略评估方法，为表格MDPs推导出高概率、实例相关的误差边界，并实现了自适应设置下的极小值最优离线学习。

    

    发展离线RL方法样本复杂度的理论保证是实现数据需求量较大的RL算法实际可行的重要步骤。目前，大多数结果依赖于关于数据分布的不现实的假设，即包括一个由单一记录策略收集的i.i.d.轨迹集。我们考虑一个更一般的设置，即数据集可以是自适应收集的。我们为表格MDPs中的TMIS离线策略评估（OPE）估计器在这个广义设置中开发理论，推导其估计误差的高概率、实例相关边界。我们还回收了自适应设置下的极小值最优离线学习。最后，我们进行模拟，以经验分析这些估计器在自适应和非自适应模式下的行为。

    Developing theoretical guarantees on the sample complexity of offline RL methods is an important step towards making data-hungry RL algorithms practically viable. Currently, most results hinge on unrealistic assumptions about the data distribution -- namely that it comprises a set of i.i.d. trajectories collected by a single logging policy. We consider a more general setting where the dataset may have been gathered adaptively. We develop theory for the TMIS Offline Policy Evaluation (OPE) estimator in this generalized setting for tabular MDPs, deriving high-probability, instance-dependent bounds on its estimation error. We also recover minimax-optimal offline learning in the adaptive setting. Finally, we conduct simulations to empirically analyze the behavior of these estimators under adaptive and non-adaptive regimes.
    
[^32]: AnyPredict: 表格预测的基础模型

    AnyPredict: Foundation Model for Tabular Prediction. (arXiv:2305.12081v1 [cs.LG])

    [http://arxiv.org/abs/2305.12081](http://arxiv.org/abs/2305.12081)

    本文提出了一种名为 AnyPredict 的表格预测基础模型，使用数据引擎整合领域内和广泛的领域外数据集，以克服模式不匹配和预测目标异质性等方面的障碍。

    

    基础模型是在大规模数据上预先训练的模型，可以在许多下游任务中表现良好。它们在自然语言处理和计算机视觉方面取得了显著的成功。然而，这种模型在表格预测任务中的使用受到限制，主要问题包括 (1) 缺乏大规模和多样化的带有标准标签的表格数据集，以及 (2) 不同领域之间的模式不匹配和预测目标的异质性。本文提出了一种方法，用于构建基于 AnyPredict 的表格预测基础模型的大规模训练数据，包括领域内和广泛的领域外数据集。该方法使用数据引擎，利用大型语言模型 (LLM) 来整合表格样本，克服了不同模式表格之间的障碍，并使用“学习，注释和审计”流程将领域外数据与目标任务对齐。扩展的训练数据使预训练的 AnyPredict 能够支持每个表格领域。

    Foundation models are pre-trained on massive data to perform well across many downstream tasks. They have demonstrated significant success in natural language processing and computer vision. Nonetheless, the use of such models in tabular prediction tasks has been limited, with the main hurdles consisting of (1) the lack of large-scale and diverse tabular datasets with standardized labels and (2) the schema mismatch and predictive target heterogeneity across domains.  This paper proposes a method for building training data at scale for tabular prediction foundation models (AnyPredict) using both in-domain and a wide range of out-domain datasets. The method uses a data engine that leverages large language models (LLMs) to consolidate tabular samples to overcome the barrier across tables with varying schema and align out-domain data with the target task using a ``learn, annotate, and audit'' pipeline. The expanded training data enables the pre-trained AnyPredict to support every tabular d
    

