# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [GeneCIS: A Benchmark for General Conditional Image Similarity.](http://arxiv.org/abs/2306.07969) | GeneCIS基准测试衡量模型适应各种相似性条件的能力，并且基准测试的表现与ImageNet的准确性弱相关，仅简单扩展现有方法并不行。 |
| [^2] | [Parting with Misconceptions about Learning-based Vehicle Motion Planning.](http://arxiv.org/abs/2306.07962) | 该论文提出了nuPlan，一个大规模真实世界数据集和评估方案，针对精确的短期规划和长期目标预测。证实了现有系统难以同时满足两个要求。最终提出一个非常简单高效的规划器。 |
| [^3] | [Hidden Biases of End-to-End Driving Models.](http://arxiv.org/abs/2306.07957) | 端到端驾驶模型存在偏见问题，并引入了次要组件的更改。本文针对目前多数最先进的方法中所存在的两种偏见进行了研究，并提出了合理的替代方法。在此基础上，开发了TF ++，在CARLA测试中表现优异。 |
| [^4] | [Adaptive Monte Carlo Search for Conjecture Refutation in Graph Theory.](http://arxiv.org/abs/2306.07956) | 本研究提出了自适应蒙特卡罗搜索算法，用于反驳猜想并证明图论问题。该算法在反驳多个猜想方面表现出色，并优于已有算法。 |
| [^5] | [Improving Frame-level Classifier for Word Timings with Non-peaky CTC in End-to-End Automatic Speech Recognition.](http://arxiv.org/abs/2306.07949) | 本文提出通过在连接时序分类（CTC）损失中引入标签先验，并将低层Mel-scale滤波器和高层ASR编码器输出组合作为输入特征来改进E2E系统中用于词时的帧级分类器，实现了更高的词时准确性。 |
| [^6] | [STUDY: Socially Aware Temporally Casual Decoder Recommender Systems.](http://arxiv.org/abs/2306.07946) | 该论文提出了一种基于社交感知和时间因素的解码器推荐系统(STUDY)，使用transformer解码器网络实现对社交网络图中相邻的用户组的联合推断。该方法在教育内容领域中经过测试，能够取得优于社交和顺序方法的结果。 |
| [^7] | [Speech-to-Text Adapter and Speech-to-Entity Retriever Augmented LLMs for Speech Understanding.](http://arxiv.org/abs/2306.07944) | 本文提出了一种联合语音和语言模型（SLM），将声音映射到文本嵌入式空间，使用基于CTC的空白过滤器来缩短语音序列长度。在语音MultiWoz数据集中，SLM提高了对话状态跟踪（DST）性能。为了解决稀有实体的错误，我们采用Speech2Entity检索器增强SLM。使用此检索-augmented SLM（ReSLM），DST性能得到进一步提高。该研究表明，增强ASR任务可以提高其性能。 |
| [^8] | [BoardgameQA: A Dataset for Natural Language Reasoning with Contradictory Information.](http://arxiv.org/abs/2306.07934) | 本文提出了一个用于带有矛盾信息的自然语言推理的数据集，以解决推理中不一致和矛盾信息的问题，同时提供了一种可推翻推理策略。 |
| [^9] | [Understanding Telecom Language Through Large Language Models.](http://arxiv.org/abs/2306.07933) | 文章提出通过fine-tune多个大型语言模型实现电信领域自动化操作，以便识别3GPP标准工作组。 |
| [^10] | [Human-in-the-Loop through Chain-of-Thought.](http://arxiv.org/abs/2306.07932) | 通过人在循环链中的方式，手动校正系统可以通过探究理性中子逻辑的手动校正来提高LLM的推理性能，并且基于经济理论的CAMLOP可以平衡效用和成本。 |
| [^11] | [Large Language Model Is Semi-Parametric Reinforcement Learning Agent.](http://arxiv.org/abs/2306.07929) | 根据人类记忆和推理机制，提出了一种新的可演化LLM智能体框架REMEMBERER，通过为LLM装备长期经验记忆，可以为不同任务提供优异的智能体，其构成了半参数RL代理。成功率超过先前SOTA 4％和2％。 |
| [^12] | [Identification of Nonlinear Latent Hierarchical Models.](http://arxiv.org/abs/2306.07916) | 本文提出了一种方法，可以在观测变量由因果相关的潜变量生成的非线性潜变量层次因果模型中实现因果结构和潜变量的可识别性。 |
| [^13] | [WebGLM: Towards An Efficient Web-Enhanced Question Answering System with Human Preferences.](http://arxiv.org/abs/2306.07906) | 本文提出的WebGLM是一种基于GLM的网络问答系统，使用LLM-augmented检索器、引导式生成器和人类偏好感知评分器等策略提高了准确性、效率和成本效益，并在人类评估中表现出比WebGPT更好的性能。 |
| [^14] | [Massively Multilingual Corpus of Sentiment Datasets and Multi-faceted Sentiment Classification Benchmark.](http://arxiv.org/abs/2306.07902) | 本研究介绍了一种可以用于训练情感模型的最全面的开放式大规模多语言数据集，该数据集由79个手动选定的数据集组成，覆盖了27种语言，代表了6种语言家族。而且，我们还提供了一个多方面的情感分类基准。 |
| [^15] | [ReadProbe: A Demo of Retrieval-Enhanced Large Language Models to Support Lateral Reading.](http://arxiv.org/abs/2306.07875) | ReadProbe 是一种利用大型语言模型和搜索引擎支持横向阅读的工具，它能够生成有用问题和答案以帮助用户评估在线信息。 |
| [^16] | [Taxonomy-Structured Domain Adaptation.](http://arxiv.org/abs/2306.07874) | 本文提出了分层结构领域自适应方法，通过分层结构领域的形式化描述来缓解不同领域之间的分布偏移，该方法在合成和实际数据集上实现了最先进的性能。 |
| [^17] | [Synapse: Leveraging Few-Shot Exemplars for Human-Level Computer Control.](http://arxiv.org/abs/2306.07863) | 本文探究了使用大型语言模型提示少量示例来实现人类级别的计算机控制；通过分解演示、过滤状态并重新构造任务描述，示例检索等步骤，Synapse 具备了适应多任务、泛化多环境的能力。 |
| [^18] | [Show me the numbers! -- Student-facing Interventions in Adaptive Learning Environments for German Spelling.](http://arxiv.org/abs/2306.07853) | 该论文的实验表明，基于机器学习的面向学生干预措施可以帮助提高德语拼写技巧的自适应学习环境，对降低学生错误率具有显著作用，但需要谨慎选择以避免辍学率的增加。 |
| [^19] | [Automated 3D Pre-Training for Molecular Property Prediction.](http://arxiv.org/abs/2306.07812) | 通过在3D分子图上进行预训练，该论文提出了一种更有效地预测分子属性的方法，该方法可以在不需要分子几何结构的情况下进行微调。 |
| [^20] | [ChatGPT vs Human-authored Text: Insights into Controllable Text Summarization and Sentence Style Transfer.](http://arxiv.org/abs/2306.07799) | 本文旨在系统地检查ChatGPT在两个可控生成任务中的表现，即ChatGPT能否适应不同的目标受众和写作风格。研究发现，人类产生的文体变化比ChatGPT表现出的更大，而生成的文本在一些特征上与人类样本有所不同，有时会包含事实错误或幻觉。 |
| [^21] | [NoCoLA: The Norwegian Corpus of Linguistic Acceptability.](http://arxiv.org/abs/2306.07790) | 本论文提出了两个新的挪威语数据集，分别用于二元分类和纯诊断任务，旨在评估语言模型的语法理解能力。它们适用于不同类型的语言模型，并用于对现有挪威语言模型进行比较研究。 |
| [^22] | [A Cloud-based Machine Learning Pipeline for the Efficient Extraction of Insights from Customer Reviews.](http://arxiv.org/abs/2306.07786) | 本文介绍了一种基于云的系统，利用机器学习方法从客户评论中提取见解。本研究提出的组合模型使用了转换器神经网络、向量嵌入和聚类，已经集成并进一步发展，以更好地满足高效信息提取、提取信息的主题建模和用户需求的要求。研究结果表明，本系统可以比现有的主题建模和关键字提取解决方案获得更好的效果。 |
| [^23] | [Tokenization with Factorized Subword Encoding.](http://arxiv.org/abs/2306.07764) | 本文提出了一种因式分解子词编码的分词方法，被称为“因式分解器”，在七种不同语言的语言建模和形态句法任务中进行评估，相较于常用的BPE算法具有更好的适应性和鲁棒性。 |
| [^24] | [Kernelized Reinforcement Learning with Order Optimal Regret Bounds.](http://arxiv.org/abs/2306.07745) | 该论文提出了一种称为$\pi$-KRVI的乐观修改方法，并使用核岭回归进行强化学习中的非线性函数逼近。论文证明了在一般设置下第一个最优遗憾保证，并相对于现有最优结果实现了显着的多项式低差距。 |
| [^25] | [V-LoL: A Diagnostic Dataset for Visual Logical Learning.](http://arxiv.org/abs/2306.07743) | V-LoL是一个结合视觉和逻辑挑战的诊断数据集，其中包括了V-LoL-Trains，该数据集首次将复杂的视觉场景和灵活的逻辑推理任务结合起来，为研究广泛的视觉逻辑学习挑战提供了平台。 |
| [^26] | [Robustness and Generalization Performance of Deep Learning Models on Cyber-Physical Systems: A Comparative Study.](http://arxiv.org/abs/2306.07737) | 本文研究了深度学习模型在物理-计算系统中的鲁棒性和泛化性能，并通过暴露模型于分布之外的样本来测试其迁移学习能力和响应数据增强技术的能力。结果表明，深度学习模型虽能达高精度，但其鲁棒性和泛化能力还不足以应用于实际物理-计算系统中。 |
| [^27] | [Contextual Dictionary Lookup for Knowledge Graph Completion.](http://arxiv.org/abs/2306.07719) | 本文提出了一种使用上下文词典查找的方法，使传统的嵌入模型能够以端到端的方式学习关系的细粒度语义，该方法在四个基准数据集上取得了最先进或有竞争力的结果，同时具有更简单和可解释的模型结构。 |
| [^28] | [Towards Explainable TOPSIS: Visual Insights into the Effects of Weights and Aggregations on Rankings.](http://arxiv.org/abs/2306.07706) | 本研究提出了可解释TOPSIS的新方法，并介绍了TOPSIS-Explorer决策支持工具。该方法通过可视化方式解释权重和聚合对排名结果的影响，对实际应用有着重要意义。 |
| [^29] | [Time-aware Graph Structure Learning via Sequence Prediction on Temporal Graphs.](http://arxiv.org/abs/2306.07699) | 该论文提出了一种基于时间图序列预测的时态图结构学习方法，通过添加潜在的时间边来学习更好的图像结构，提高下游任务的性能。 |
| [^30] | [StyleTTS 2: Towards Human-Level Text-to-Speech through Style Diffusion and Adversarial Training with Large Speech Language Models.](http://arxiv.org/abs/2306.07691) | 本文提出了一种名为StyleTTS 2的TTS模型，通过对抗训练和大型语音语言模型来实现人类级别的语音合成。与以往模型不同，StyleTTS 2将样式视为潜在随机变量，利用扩散模型来生成最适合文本的样式，同时受益于大型SLMs和新的可微分持续时间建模。 |
| [^31] | [Few-shot Multi-domain Knowledge Rearming for Context-aware Defence against Advanced Persistent Threats.](http://arxiv.org/abs/2306.07685) | 本文提出了一种针对高级持久性威胁的上下文感知防御的少样本、多领域知识重装 (FMKR) 方案，可以在不同的网络域生成多个小任务，完成多领域的知识重新装备，提高防御性能。 |
| [^32] | [An Interleaving Semantics of the Timed Concurrent Language for Argumentation to Model Debates and Dialogue Games.](http://arxiv.org/abs/2306.07675) | 本文提出了一种基于定时抽象论证框架的定时并发语言，用于模拟代理之间的交互，并将代理的可接受性与给定时间间隔进行推理和通信，特别适用于模拟辩论和对话游戏的情境。 |
| [^33] | [Rethink the Effectiveness of Text Data Augmentation: An Empirical Analysis.](http://arxiv.org/abs/2306.07664) | 本研究发现数据增强技术在语言模型的预训练及微调中仍具有显著的提升作用，尤其在少样本学习的情况下，持续的预训练可以提高微调性能10%以上。 |
| [^34] | [Temporalising Unique Characterisability and Learnability of Ontology-Mediated Queries.](http://arxiv.org/abs/2306.07662) | 本文研究了在时间化本体中介查询中唯一可特征性和可学习性的问题，并提出了相应的传递结果。 |
| [^35] | [On Guiding Search in HTN Temporal Planning with non Temporal Heuristics.](http://arxiv.org/abs/2306.07638) | 本文提出了一种基于POCL方法的新型技术，用于解决时间HTN问题，并使用已有的非时间启发式方法来进行指导。 |
| [^36] | [Exploiting Configurations of MaxSAT Solvers.](http://arxiv.org/abs/2306.07635) | 本文介绍了如何利用MaxSAT求解器的可替代参数配置，并通过实验证明了如何将一个非竞争性求解器的配置组合起来，实现更好的求解方法。 |
| [^37] | [Human-Like Intuitive Behavior and Reasoning Biases Emerged in Language Models -- and Disappeared in GPT-4.](http://arxiv.org/abs/2306.07622) | 本研究揭示了大型语言模型（LLMs）具有类人直觉行为和认知错误的特点，而高级语言模型则通过学习避免这类错误并表现出超理性的方式。此外，通过使用心理学研究的方法探测LLMs，可以揭示其新生特性。 |
| [^38] | [Hyperbolic Graph Diffusion Model for Molecule Generation.](http://arxiv.org/abs/2306.07618) | 本文提出了基于双曲图扩散模型的分子生成方法，可以更全面地捕捉分子的内部非欧几里德结构，实现数据生成，并提取复杂几何特征的能力。 |
| [^39] | [Finding the Missing-half: Graph Complementary Learning for Homophily-prone and Heterophily-prone Graphs.](http://arxiv.org/abs/2306.07608) | 该文章提出了GOAL框架来解决同质和异质图中缺失的一半结构信息的问题。 |
| [^40] | [Paste, Inpaint and Harmonize via Denoising: Subject-Driven Image Editing with Pre-Trained Diffusion Model.](http://arxiv.org/abs/2306.07596) | 本文提出了一个名为PhD的图像编辑框架，使用一个示例图像和文本描述来指定用户意图。该框架包括粘贴、修补和协调步骤，可以将插入的主题无缝融入场景中。 |
| [^41] | [Galactic: Scaling End-to-End Reinforcement Learning for Rearrangement at 100k Steps-Per-Second.](http://arxiv.org/abs/2306.07552) | Galactic是一个针对室内物体重排问题的大规模仿真和强化学习框架。这个框架可以在每秒 100k 步上运行，比其他相似框架快很多。 |
| [^42] | [A Versatile Multi-Agent Reinforcement Learning Benchmark for Inventory Management.](http://arxiv.org/abs/2306.07542) | 该研究开发了一个用于库存管理的多智能体强化学习通用基准(MABIM)，以适用于实际工业场景中诸如复杂智能体交互等各种挑战，通过MABIM，该研究评估了传统的运筹学(OR)方法和流行的MARL算法的性能，以凸显其优缺点和潜力。 |
| [^43] | [A Simple Unified Uncertainty-Guided Framework for Offline-to-Online Reinforcement Learning.](http://arxiv.org/abs/2306.07541) | SUNG是一种基于不确定性引导的离线到在线强化学习框架，在通过量化不确定性进行探索和应用保守Q值估计的指导下，实现了高效的老化强化学习。 |
| [^44] | [TART: A plug-and-play Transformer module for task-agnostic reasoning.](http://arxiv.org/abs/2306.07536) | TART提出了一种即插即用的Transformer模块，它能够在没有任务特定训练或微调的情况下，在不同推理目标之间进行泛化。 |
| [^45] | [User-defined Event Sampling and Uncertainty Quantification in Diffusion Models for Physical Dynamical Systems.](http://arxiv.org/abs/2306.07526) | 本文提出了一种条件得分函数的概率近似方案，可以用于混沌动力系统的预测和提供不确定性量化。 |
| [^46] | [Using Collision Momentum in Deep Reinforcement Learning Based Adversarial Pedestrian Modeling.](http://arxiv.org/abs/2306.07525) | 该研究提出了一种基于碰撞动量的深度强化学习算法，能够更好地发现自动驾驶算法在极端情况下的缺陷并加以纠正。 |
| [^47] | [Noisy Positive-Unlabeled Learning with Self-Training for Speculative Knowledge Graph Reasoning.](http://arxiv.org/abs/2306.07512) | 本文提出了一种嘈杂正-无标记学习问题的变分框架nPUGraph，并引入自训练策略，以应对真实世界知识图谱上的思辨性推理任务。实验结果表明了我们提出的方法的有效性。 |
| [^48] | [Adding guardrails to advanced chatbots.](http://arxiv.org/abs/2306.07500) | 研究探讨了 ChatGPT 不同用例对于公平回答问题的能力，并发现它对于测试任务而言是公平的搜索引擎，但在文本生成和代码生成上有偏见，并且对于变化非常敏感。 |
| [^49] | [Improving Opinion-based Question Answering Systems Through Label Error Detection and Overwrite.](http://arxiv.org/abs/2306.07499) | 本文提出了一种名为LEDO的模型-不可知且计算高效的框架，能够有效解决标签错误问题，并将其应用于意见问答系统中，提高了该系统在各个核心模型中的准确性。 |
| [^50] | [PauseSpeech: Natural Speech Synthesis via Pre-trained Language Model and Pause-based Prosody Modeling.](http://arxiv.org/abs/2306.07489) | 本文提出了一种使用预训练语言模型和基于停顿的韵律建模的语音合成系统，名为PauseSpeech。通过引入基于短语结构的编码器和基于停顿的单词编码器，有效地合成了具有适当短语结构的自然语音。 |
| [^51] | [Reviving Shift Equivariance in Vision Transformers.](http://arxiv.org/abs/2306.07470) | 本文提出了一种自适应的多相位固定算法，可以无缝地集成到视觉Transformer模型中，以确保平移等变性，并介绍了一种基于补丁的适配器，以恢复位置编码的平移等变性。该方法在ImageNet-C和CLEVR-C等平移不变数据集上显著提高了ViT模型的性能。 |
| [^52] | [A Black-box Approach for Non-stationary Multi-agent Reinforcement Learning.](http://arxiv.org/abs/2306.07465) | 本文提出了一种通用的黑盒方法，适用于多种多智能体强化学习问题，可以在非平稳环境下实现低遗憾率的学习。 |
| [^53] | [Unlocking Sales Growth: Account Prioritization Engine with Explainable AI.](http://arxiv.org/abs/2306.07464) | 论文开发了一款名为 Account Prioritizer 的智能销售账户优先级引擎，使用机器学习和解释算法自动化销售簿优化，在 LinkedIn Business 中成功带来了 +8.08% 的续订订阅增长。 |
| [^54] | [Adaptive interventions for both accuracy and time in AI-assisted human decision making.](http://arxiv.org/abs/2306.07458) | 本研究探索适用于人工决策辅助的智能干预方案，在同时考虑准确性和时间性的前提下，根据问题和用户的属性自适应地展示AI辅助具有良好的效果。 |
| [^55] | [Accurate Measures of Vaccination and Concerns of Vaccine Holdouts from Web Search Logs.](http://arxiv.org/abs/2306.07457) | 研究发现，基于大规模搜索引擎日志和机器学习可以提供及时准确的疫苗意向和关注问题的数据，可以帮助设计有针对性的疫苗宣传教育活动，同时发现疫苗观望者搜索有关副作用和替代药物的信息，并表达对疫苗安全性和政府信誉的担忧。 |
| [^56] | [Explaining CLIP through Co-Creative Drawings and Interaction.](http://arxiv.org/abs/2306.07429) | 本文分析了一个由CLIP深度学习模型解析梦境并将其转化为图像的系统所产生的绘画存档，提出了四个分类以解释和描述CLIP生成的结果。本文关注于跨语言、符号系统和装置各模块之间的翻译过程和结果，展示了意想不到、视觉吸引人、梦境般的CLIP生成的结果。 |
| [^57] | [DeepTransition: Viability Leads to the Emergence of Gait Transitions in Learning Anticipatory Quadrupedal Locomotion Skills.](http://arxiv.org/abs/2306.07419) | 本文通过深度强化学习和机器人工具的互动研究，证明了可行性是四足动物步态转换的重要标准。其中，步-小跑步态转换能够在平坦地形上同时提高可行性和节能效果。 |
| [^58] | [Synaptic Scaling and Optimal Bias Adjustments for Power Reduction in Neuromorphic Systems.](http://arxiv.org/abs/2306.07416) | 本文探讨了将类似动物大脑在食物匮乏时的低功耗机制应用于神经形态系统中，通过缩放突触权值可以显著降低功耗（在某些情况下可降低80％以上），同时对准确性影响较小。这为设计用于边缘人工智能应用的神经形态系统提供了令人兴奋的机会。 |
| [^59] | [The economic trade-offs of large language models: A case study.](http://arxiv.org/abs/2306.07402) | 本研究通过一个案例研究，以评估大型语言模型在企业中为类似客户服务的场景所带来的成本和效益。从该品牌客户服务代理的反馈中比较了三种专门化LLM的策略-提示工程、微调和知识蒸馏，发现模型响应的可用性可以弥补成本差异。 |
| [^60] | [Implementing BERT and fine-tuned RobertA to detect AI generated news by ChatGPT.](http://arxiv.org/abs/2306.07401) | 使用BERT和微调的RobertA模型可以最好地检测ChatGPT生成的AI新闻。 RobertA模型在精度方面表现出色，取得了98％的得分。这些模型可以在打击假新闻中发挥关键作用。 |
| [^61] | [Lost in Translation: Large Language Models in Non-English Content Analysis.](http://arxiv.org/abs/2306.07377) | 大型语言模型目前主要运用于英语内容的智能分析中，多语言模型的发展旨在弥补其他语言数据匮乏的情况。研究人员和技术公司通过构建多语言语言模型尝试解决这一问题并拓展大型语言模型的能力。多语言模型在低资源语言应用中的实践效果也进行研究。总体而言，AI支持的语言技术的设计和部署需要注意权力、不平等和文化差异。 |
| [^62] | [Composing Efficient, Robust Tests for Policy Selection.](http://arxiv.org/abs/2306.07372) | 该论文提出了一种名为RPOSST的算法，它可以从较大的测试案例池中选择一小部分测试样例，验证其高质量的策略在更广泛的环境下也是可靠的。 |
| [^63] | [HDDL 2.1: Towards Defining a Formalism and a Semantics for Temporal HTN Planning.](http://arxiv.org/abs/2306.07353) | 本文介绍了HDDL 2.1的形式化和语义定义，旨在通过从PDDL 2.1中汲取灵感，弥补HDDL不能表示数字和时间约束的不足。 |
| [^64] | [ATT3D: Amortized Text-to-3D Object Synthesis.](http://arxiv.org/abs/2306.07349) | 该论文提出了一种“摊销”的文本到三维物体合成方法，将许多提示一起使用一个统一的模型进行训练，共享提示之间的优化计算，从而在更短时间内训练模型；该方法能够使不同提示之间进行平滑的插值，并在新的资产和简单动画之间实现知识共享和推广。 |
| [^65] | [Learning to Mask and Permute Visual Tokens for Vision Transformer Pre-Training.](http://arxiv.org/abs/2306.07346) | 本论文提出了一种新的自监督预训练方法MaPeT，不同于现有的使用掩码图像模型的方法，该方法使用自回归和置换预测来捕获图像块内的依赖关系并减少数据噪声的影响，从而提高了下游任务的一致性。 |
| [^66] | [Employing Crowdsourcing for Enriching a Music Knowledge Base in Higher Education.](http://arxiv.org/abs/2306.07310) | 本研究探讨了一项使用众包技术的计算机科学高等教育作业，鼓励学生丰富音乐元数据，并创建了可供机器学习模型用于音乐标记的开放性注释数据集。 |
| [^67] | [Online Prototype Alignment for Few-shot Policy Transfer.](http://arxiv.org/abs/2306.07307) | 本文提出了一种基于元素功能相似性的在线原型对齐（OPA）框架，能够在少样本的情况下实现策略转移，解决了传统方法映射函数学习需要大量数据以及依赖视觉特征等问题。 |
| [^68] | [Active Globally Explainable Learning for Medical Images via Class Association Embedding and Cyclic Adversarial Generation.](http://arxiv.org/abs/2306.07306) | 本文提出了一种类别关联嵌入（CAE）方法，采用编码器-解码器结构将样本特征分离成与类别相关的风格向量，实现了医学图像全局可解释的学习。 |
| [^69] | [Making forecasting self-learning and adaptive -- Pilot forecasting rack.](http://arxiv.org/abs/2306.07305) | 本文提出了通过使用试点预测架构中的算法干预来提高非AI模型下针织品类别的预测准确性。在决策模型中动态地选择最佳算法可提高预测准确性，并通过AI / ML预测模型使用先进的特征工程来实现。 |
| [^70] | [A Holistic Approach to Unifying Automatic Concept Extraction and Concept Importance Estimation.](http://arxiv.org/abs/2306.07304) | 本文提出了一个全面的理论框架，来统一定义和澄清自动概念提取和概念重要性评估，进而提供新的评估指标以实现对这些方法的比较以及推导关于这种方法的最优性的理论保证。 |
| [^71] | [Impact of Experiencing Misrecognition by Teachable Agents on Learning and Rapport.](http://arxiv.org/abs/2306.07302) | 音频识别错误对教学代理人学习和人际关系无显著影响，结果为教学代理人的最优错误恢复策略提供了一些启示。 |
| [^72] | [Novel Regression and Least Square Support Vector Machine Learning Technique for Air Pollution Forecasting.](http://arxiv.org/abs/2306.07301) | 提出了一种新技术，称为DR-LSSV，基于回归和最小二乘支持向量机，可有效提高空气污染预测性能，并在空气污染预测准确性、空气污染预测时间和假阳性率方面超越了传统的机器学习方法。 |
| [^73] | [Progressive Class-Wise Attention (PCA) Approach for Diagnosing Skin Lesions.](http://arxiv.org/abs/2306.07300) | 本研究提出一种新的分类关注技术，能够平等关注每个皮肤病变类别，并逐步结合多个尺度的判别特征细节，从而获得显著的诊断表现，准确率分别为97.40％和94.9％，超过了15种尖端方法，包括HAM1000和ISIC2019排行榜的优胜者。 |
| [^74] | [Referring to Screen Texts with Voice Assistants.](http://arxiv.org/abs/2306.07298) | 本文提出了一种新的体验，使用户可以通过语音助手引用他们手机屏幕上的电话号码、地址、电子邮件地址、URL和日期。我们设计了一个轻量级的模型，并收集了一个数据集。该模型是模块化的，提供了灵活性、改进的可解释性和高效的运行时内存利用率。 |
| [^75] | [Medical Data Augmentation via ChatGPT: A Case Study on Medication Identification and Medication Event Classification.](http://arxiv.org/abs/2306.07297) | 本研究利用ChatGPT进行数据增广，显著提高了BERT模型在电子病历药物识别和药物事件分类任务中的表现。 |
| [^76] | [Optimized Three Deep Learning Models Based-PSO Hyperparameters for Beijing PM2.5 Prediction.](http://arxiv.org/abs/2306.07296) | 本论文提出了基于PSO超参数优化的三种深度学习模型，针对北京PM2.5的预测任务进行研究，并发现M-1模型具有最佳性能且经过优化的超参数可以提高5.6%的预测准确度。 |
| [^77] | [Urban Spatiotemporal Data Synthesis via Neural Disaggregation.](http://arxiv.org/abs/2306.07292) | 本研究提出了一种基于神经网络的城市时空数据合成方法，旨在通过分解粗糙的低分辨率地理单元的聚合城市数据来合成细粒度，高分辨率的城市数据，以增加高度聚合的城市数据的可用性和实现价值。 |
| [^78] | [Value function estimation using conditional diffusion models for control.](http://arxiv.org/abs/2306.07290) | 论文提出了一种基于条件扩散模型的值函数估计控制方法（DVF），该方法可以在大量条件化数据上有效地进行训练，并使用只有一小部分示范数据就能超过基准算法。 |
| [^79] | [TransCoder: Towards Unified Transferable Code Representation Learning Inspired by Human Skills.](http://arxiv.org/abs/2306.07285) | TransCoder是一种可转移的代码表示学习任务的微调策略，通过可调整的前缀编码器作为元学习器来捕捉跨任务和跨语言的可转移知识，使模型学习更好的代码相关元知识。此外，我们的方法可以remarkably地提高训练样本量较小和语料库较小的任务和语言的效果。 |
| [^80] | [Towards end-to-end ASP computation.](http://arxiv.org/abs/2306.06821) | 该论文提出了一种端到端方法，通过线性代数计算稳定模型满足给定的限制条件，同时没有使用符号ASP或SAT求解器，为加速通过并行技术提供了可能。 |
| [^81] | [EaSyGuide : ESG Issue Identification Framework leveraging Abilities of Generative Large Language Models.](http://arxiv.org/abs/2306.06662) | 本文介绍了一种利用生成大语言模型能力的ESG问题识别框架，该框架在多语言环境下对MSCI ESG评级指南定义的35个ESG关键问题实现了卓越的识别成果，为ESG主题的探索做出了贡献。 |
| [^82] | [Aria Digital Twin: A New Benchmark Dataset for Egocentric 3D Machine Perception.](http://arxiv.org/abs/2306.06362) | Aria数字孪生是一个自我中心数据集，具有其它任何数据集都没有的高精度、照片逼真和详尽的真实信息。这个数据集将成为自我中心机器感知评估的新标准。 |
| [^83] | [Test-Time Style Shifting: Handling Arbitrary Styles in Domain Generalization.](http://arxiv.org/abs/2306.04911) | 本文提出了测试时间风格转换（test-time style shifting）的方法，使得模型能够有效地处理领域泛化任务中任意风格的问题，同时避免了额外的模型更新。 |
| [^84] | [Human in the Loop Novelty Generation.](http://arxiv.org/abs/2306.04813) | 该论文提出了一种新的创新生成方法，使用环境的抽象模型而不需要人类专业知识来生成新的新颖性。这可以产生更大的、通常是无限的新颖性空间，但需要人类的指导来选择和过滤这些新颖性。 |
| [^85] | [Bottom-Up Grounding in the Probabilistic Logic Programming System Fusemate.](http://arxiv.org/abs/2305.18924) | 介绍了自下而上推理的概率逻辑编程系统Fusemate，提出了基于查询引导的相关性测试修剪规则，解决了自下而上推理难以控制ground clauses生成数量的问题，并在包含“时间”的示例中表现出更好的性能。 |
| [^86] | [Restoring Images Captured in Arbitrary Hybrid Adverse Weather Conditions in One Go.](http://arxiv.org/abs/2305.09996) | 提出了一种新的框架RAHC，可以一次性处理任意复杂恶劣天气条件下的图像恢复，并建立了一个新的数据集HAC，用于学习和基准测试混合条件的图像恢复。 |
| [^87] | [HybridNet: Dual-Branch Fusion of Geometrical and Topological Views for VLSI Congestion Prediction.](http://arxiv.org/abs/2305.05374) | 本文提出了HybridNet，一种基于几何与拓扑视角的VLSI阻塞预测的双分支融合网络，通过在网络结构中做出几个关键设计，充分综合电路的拓扑与几何特征，相较于以往方法取得了10.9％的提高。 |
| [^88] | [Connecting the Dots in Trustworthy Artificial Intelligence: From AI Principles, Ethics, and Key Requirements to Responsible AI Systems and Regulation.](http://arxiv.org/abs/2305.02231) | 该论文旨在探讨可信人工智能的构建，包括从法律、伦理和技术、社会角度确保其健壮性。实现真正可信的人工智能涉及到更广阔的愿景，考虑到伦理方面、风险方面、以及对七个技术需求的支持度和大局整体之关系。 |
| [^89] | [Energy-based Models as Zero-Shot Planners for Compositional Scene Rearrangement.](http://arxiv.org/abs/2304.14391) | 本文提出一种基于能量模型的零样本场景重新排列规划器，通过语言指导的空间概念来实现长指令以及在训练时从未见过的空间概念组合。本文的模型在指令导向操作基准测试以及组合指令基准测试中表现良好，优于基于语言表达的最先进方法，并且可以成功地解决之前从未见过的复杂指令和场景。 |
| [^90] | [Seeing is not always believing: A Quantitative Study on Human Perception of AI-Generated Images.](http://arxiv.org/abs/2304.13023) | 本研究揭示了人类无法辨别AI生成的假照片和真实照片，这一点受个人背景的影响并不显著。 |
| [^91] | [Do the Rewards Justify the Means? Measuring Trade-Offs Between Rewards and Ethical Behavior in the MACHIAVELLI Benchmark.](http://arxiv.org/abs/2304.03279) | 本文介绍了 MACHIAVELLI 基准测试，用于衡量人工智能代理是否表现出马基雅维利行为，发现了最大化奖励和行为的道德性之间存在权衡，并探索了基于语言模型的方法来减轻这种权衡。 |
| [^92] | [To Asymmetry and Beyond: Structured Pruning of Sequence to Sequence Models for Improved Inference Efficiency.](http://arxiv.org/abs/2304.02721) | 本论文研究了模型大小、结构化剪枝、推断效率和摘要准确性之间的关系，发现使用不对称剪枝可在不大损失模型准确性的情况下，提高推断效率约3倍。 |
| [^93] | [MACARONS: Mapping And Coverage Anticipation with RGB Online Self-Supervision.](http://arxiv.org/abs/2303.03315) | MACARONS是一种无需深度传感器和三维监督，仅通过彩色图像预测容积占用场并预测下一最佳视角的方法，具备在新场景中表现良好的能力。 |
| [^94] | [SHAP-IQ: Unified Approximation of any-order Shapley Interactions.](http://arxiv.org/abs/2303.01179) | 提出了一种名为SHAP-IQ的新方法，用于计算任意阶Shapley互动，并提供了逼近质量的理论保证和方差估计。该方法在计算成本和逼近质量方面优于现有方法。 |
| [^95] | [Thermodynamic AI and the fluctuation frontier.](http://arxiv.org/abs/2302.06584) | 该论文介绍了热力学人工智能算法的概念，并将多种人工智能算法统一在一个数学框架下。该算法与传统硬件有所不同，并提出一种全新的计算模式，使得热力学人工智能算法可以更高效地解决计算难题。 |
| [^96] | [Single Motion Diffusion.](http://arxiv.org/abs/2302.05905) | SinMDM是一种单一动作扩散模型，利用去噪网络和扩散模型来学习单个动作序列的内部模式，并合成具有其特点的任意长度的运动。 |
| [^97] | [Large Language Models Are Reasoning Teachers.](http://arxiv.org/abs/2212.10071) | 本文提出了Fine-tune-CoT，一种使用大型模型作为推理教师让较小模型也能进行复杂推理的方法，可以远远优于基于提示的基线方法，在多个任务上进行了评估。此外，该方法还利用教师模型的能力为每个原始样本生成多个不同的原因解释。 |
| [^98] | [Unbiased Heterogeneous Scene Graph Generation with Relation-aware Message Passing Neural Network.](http://arxiv.org/abs/2212.00443) | 本文提出了一种无偏见的异构场景图生成框架，使用关系感知消息传递神经网络捕获对象之间的上下文感知性，并设计了一种新的消息传递层来汇总图像的上下文信息。 |
| [^99] | [Powderworld: A Platform for Understanding Generalization via Rich Task Distributions.](http://arxiv.org/abs/2211.13051) | Powderworld是一个直接在GPU上运行的轻量级但表现力强的模拟环境，用于提供泛化性的研究平台，包括世界建模和强化学习。实验表明，增加环境的复杂性可以改善世界模型和某些强化学习代理的泛化性能。 |
| [^100] | [Knowledge Graph Contrastive Learning Based on Relation-Symmetrical Structure.](http://arxiv.org/abs/2211.10738) | 本论文提出了一种基于关系对称结构的知识图谱对比学习框架 KGE-SymCL，它能有效地提高知识图谱中实体的可区分度。 |
| [^101] | [A Hypergraph-Based Machine Learning Ensemble Network Intrusion Detection System.](http://arxiv.org/abs/2211.03933) | 该论文提出了一种基于超图的机器学习集成网络入侵检测系统，使用超图捕捉端口扫描攻击的演化模式，并使用派生的度量来训练NIDS，从而允许在高精度、高准确率、高召回率性能下实时监测和检测端口扫描活动、其他类型的攻击和敌对入侵，解决了传统NIDS面临的挑战。 |
| [^102] | [Empirical Analysis of Model Selection for Heterogeneous Causal Effect Estimation.](http://arxiv.org/abs/2211.01939) | 本文在二元治疗条件下条件平均处理效应估计的场景中，对因果推断的模型选择问题进行了实证分析，利用最新的生成建模进展，提出了新的度量方法，证明了新的模型选择策略的有效性。 |
| [^103] | [Aligning Offline Metrics and Human Judgments of Value for Code Generation Models.](http://arxiv.org/abs/2210.16494) | 该论文通过一个用户研究表明，对于生成的代码而言，正确性评估不能完全反映大型语言模型协助程序员生成代码所提供的生产力提升，因此该论文提出了一种混合度量，结合了功能正确性和语法相似性，并且能够更好地代表真实世界的收益。 |
| [^104] | [HELP ME THINK: A Simple Prompting Strategy for Non-experts to Create Customized Content with Models.](http://arxiv.org/abs/2208.08232) | HELP ME THINK是一种帮助非专家用户创建定制化内容的简单提示策略，利用GPT3提出相关问题和利用用户答案执行任务，适用于各种需要重要思考的任务。 |
| [^105] | [How to Reuse and Compose Knowledge for a Lifetime of Tasks: A Survey on Continual Learning and Functional Composition.](http://arxiv.org/abs/2207.07730) | 本篇综述介绍了连续学习和功能组合方法的研究现状和未来联系，以实现人工智能在解决新问题时可以不断积累和组合知识的终身学习目标。 |
| [^106] | [A simple declarative model of the Federal Disaster Assistance Policy -- modelling and measuring transparency.](http://arxiv.org/abs/2207.07392) | 本研究量化分析了联邦灾难援助政策的一个简单模型，并从三个不同利益相关者的角度进行了评估，进而考虑了3种政策修改及其影响，旨在为各利益相关者的偏好排序提供参考。 |
| [^107] | [A Unified Interpretable Intelligent Learning Diagnosis Framework for Smart Education.](http://arxiv.org/abs/2207.03122) | 本文提出了一种统一的可解释性智能学习诊断框架，结合了深度学习的表示学习能力和基于心理测量的方法的可解释性，使得在智慧教育中能够平衡准确性和可解释性。 |
| [^108] | [Optimal Private Payoff Manipulation against Commitment in Extensive-form Games.](http://arxiv.org/abs/2206.13119) | 研究了在广义博弈中追随者通过虚报收益函数实现最优操纵的问题，并提出了有效的算法来计算最佳操纵。 |
| [^109] | [Counting Markov Equivalent Directed Acyclic Graphs Consistent with Background Knowledge.](http://arxiv.org/abs/2206.06744) | 本文研究如何在给定一些边的方向已确定的情况下，计算马尔科夫等价类中的有向无环图数量，并且提出了一个计数算法，该算法运行时间受到一个多项式的约束。 |
| [^110] | [Spatio-Temporal Joint Graph Convolutional Networks for Traffic Forecasting.](http://arxiv.org/abs/2111.13684) | 本文提出了一种称为STJGCN的方法，用于在多个未来时间步长上准确预测道路网络上的交通流量。该方法构建了预定义的和自适应的时空联合图以及在STJGs上执行图卷积运算，以提取时空特征并进行多步预测，并已在两个真实数据集上取得了优于现有最先进方法的结果。 |
| [^111] | [Towards Open-World Feature Extrapolation: An Inductive Graph Learning Approach.](http://arxiv.org/abs/2110.04514) | 本文提出了一种采用图表示和学习的方法，解决了处理开放世界特征外推问题的挑战，同时使用两种训练策略来实现对新特征的外推，并缓解特征层面的过拟合问题。 |
| [^112] | [Domain Adaptation with Incomplete Target Domains.](http://arxiv.org/abs/2012.01606) | 本研究提出了一种基于不完整数据插补的对抗网络（IDIAN）模型，用于解决具有部分观察到的数据的不完整目标领域下的域自适应问题，实验结果表明该模型在跨域和实际适应任务中都具有良好的表现。 |
| [^113] | [Solving the single-track train scheduling problem via Deep Reinforcement Learning.](http://arxiv.org/abs/2009.00433) | 本文研究了通过深度强化学习解决单轨列车调度问题的方法，提出了两种不同的深度Q学习方法，并进行了数值评估。 |

# 详细

[^1]: GeneCIS：一种通用条件图像相似度的基准测试

    GeneCIS: A Benchmark for General Conditional Image Similarity. (arXiv:2306.07969v1 [cs.CV])

    [http://arxiv.org/abs/2306.07969](http://arxiv.org/abs/2306.07969)

    GeneCIS基准测试衡量模型适应各种相似性条件的能力，并且基准测试的表现与ImageNet的准确性弱相关，仅简单扩展现有方法并不行。

    

    我们认为存在许多“相似性”的概念，而模型（如人类）应该能够动态地适应这些概念。这与大多数表示学习方法（受监督或自监督）不同，它们学习一个固定的嵌入函数，因此隐含地假定了单一的相似性概念。 在本文中，我们提出了GeneCIS（“创世纪”）基准测试，该测试衡量了模型适应各种相似性条件的能力。扩展之前的工作，我们的基准测试只设计用于零样本评估，因此考虑了开放集的相似性条件。我们发现，强大的CLIP模型的基线在GeneCIS上较为困难，并且基准测试的表现仅与ImageNet的准确性弱相关，这表明简单地扩展现有方法并不是有成果的。我们进一步

    We argue that there are many notions of 'similarity' and that models, like humans, should be able to adapt to these dynamically. This contrasts with most representation learning methods, supervised or self-supervised, which learn a fixed embedding function and hence implicitly assume a single notion of similarity. For instance, models trained on ImageNet are biased towards object categories, while a user might prefer the model to focus on colors, textures or specific elements in the scene. In this paper, we propose the GeneCIS ('genesis') benchmark, which measures models' ability to adapt to a range of similarity conditions. Extending prior work, our benchmark is designed for zero-shot evaluation only, and hence considers an open-set of similarity conditions. We find that baselines from powerful CLIP models struggle on GeneCIS and that performance on the benchmark is only weakly correlated with ImageNet accuracy, suggesting that simply scaling existing methods is not fruitful. We furth
    
[^2]: 与学习导向的车辆运动规划的误解告别

    Parting with Misconceptions about Learning-based Vehicle Motion Planning. (arXiv:2306.07962v1 [cs.RO])

    [http://arxiv.org/abs/2306.07962](http://arxiv.org/abs/2306.07962)

    该论文提出了nuPlan，一个大规模真实世界数据集和评估方案，针对精确的短期规划和长期目标预测。证实了现有系统难以同时满足两个要求。最终提出一个非常简单高效的规划器。

    

    nuPlan的发布标志着车辆运动规划研究的一个新时代，提供了第一个需要精确的短期规划和长期目标预测的大规模真实世界数据集和评估方案。现有系统难以同时满足两个要求。实际上，我们发现这些任务存在根本上的不对齐问题，应该分别进行解决。我们进一步评估了领域内闭环规划的现状，揭示了学习为基础的方法在复杂的真实场景中的局限性，以及选择通过车道图搜索算法的简单基于规则的先验项（例如中心线选择）的价值。更令人惊讶的是，在开环子任务中，我们观察到当仅使用这个中心线作为场景上下文时（即忽略所有有关地图和其他代理的信息）可以获得最佳结果。结合这些见解，我们提出了一个非常简单高效的规划器，它的表现优于大量竞争对手。

    The release of nuPlan marks a new era in vehicle motion planning research, offering the first large-scale real-world dataset and evaluation schemes requiring both precise short-term planning and long-horizon ego-forecasting. Existing systems struggle to simultaneously meet both requirements. Indeed, we find that these tasks are fundamentally misaligned and should be addressed independently. We further assess the current state of closed-loop planning in the field, revealing the limitations of learning-based methods in complex real-world scenarios and the value of simple rule-based priors such as centerline selection through lane graph search algorithms. More surprisingly, for the open-loop sub-task, we observe that the best results are achieved when using only this centerline as scene context (\ie, ignoring all information regarding the map and other agents). Combining these insights, we propose an extremely simple and efficient planner which outperforms an extensive set of competitors,
    
[^3]: 深度学习驾驶模型中的偏见问题

    Hidden Biases of End-to-End Driving Models. (arXiv:2306.07957v1 [cs.CV])

    [http://arxiv.org/abs/2306.07957](http://arxiv.org/abs/2306.07957)

    端到端驾驶模型存在偏见问题，并引入了次要组件的更改。本文针对目前多数最先进的方法中所存在的两种偏见进行了研究，并提出了合理的替代方法。在此基础上，开发了TF ++，在CARLA测试中表现优异。

    

    最近，端到端的驾驶系统在CARLA测试中取得了快速进展。然而，即使在主要贡献的基础上，这些系统也会引入对次要系统组件的改变。因此，系统的改进源并不清楚。我们发现，在几乎所有最先进的方法中都存在两种偏见，这些偏见对于在CARLA上观察到的进展至关重要：(1) 通过对目标点跟随的强归纳偏见来进行横向恢复，(2) 通过多模态航路点预测的纵向平均来减速。我们研究了这些偏见的缺点，并确定了合理的替代方法。通过结合我们的见解，我们开发了TF ++，一种简单的端到端方法，在Longest6和LAV基准测试中排名第一，在Longest6上比最佳前期工作提高了14个驾驶分数。

    End-to-end driving systems have recently made rapid progress, in particular on CARLA. Independent of their major contribution, they introduce changes to minor system components. Consequently, the source of improvements is unclear. We identify two biases that recur in nearly all state-of-the-art methods and are critical for the observed progress on CARLA: (1) lateral recovery via a strong inductive bias towards target point following, and (2) longitudinal averaging of multimodal waypoint predictions for slowing down. We investigate the drawbacks of these biases and identify principled alternatives. By incorporating our insights, we develop TF++, a simple end-to-end method that ranks first on the Longest6 and LAV benchmarks, gaining 14 driving score over the best prior work on Longest6.
    
[^4]: 自适应蒙特卡罗搜索用于图论猜想证伪

    Adaptive Monte Carlo Search for Conjecture Refutation in Graph Theory. (arXiv:2306.07956v1 [math.CO])

    [http://arxiv.org/abs/2306.07956](http://arxiv.org/abs/2306.07956)

    本研究提出了自适应蒙特卡罗搜索算法，用于反驳猜想并证明图论问题。该算法在反驳多个猜想方面表现出色，并优于已有算法。

    

    图论是一个跨学科的研究领域，具有在数学建模和计算机科学中广泛的应用。图论研究不仅仅依赖于定理的创造，还涉及到猜想的提出。证伪算法通过在图上最大化某些得分函数来寻找反例，从而试图证伪猜想。本研究提出了一种新颖的猜想证伪算法，称为自适应蒙特卡罗搜索（AMCS）算法，通过修改蒙特卡罗树搜索算法得到。通过对其在发现数个图论猜想的反例方面的成功评估，AMCS优于现有的猜想证伪算法。该算法还被用于证伪了六个开放猜想，其中两个是由Liu等人于2021年提出的化学图论猜想，另外四个是AutoGraphiX计算机系统于2006年提出的猜想。最后，使用AMCS证明了其中四个开放猜想.

    Graph theory is an interdisciplinary field of study that has various applications in mathematical modeling and computer science. Research in graph theory depends on the creation of not only theorems but also conjectures. Conjecture-refuting algorithms attempt to refute conjectures by searching for counterexamples to those conjectures, often by maximizing certain score functions on graphs. This study proposes a novel conjecture-refuting algorithm, referred to as the adaptive Monte Carlo search (AMCS) algorithm, obtained by modifying the Monte Carlo tree search algorithm. Evaluated based on its success in finding counterexamples to several graph theory conjectures, AMCS outperforms existing conjecture-refuting algorithms. The algorithm is further utilized to refute six open conjectures, two of which were chemical graph theory conjectures formulated by Liu et al. in 2021 and four of which were formulated by the AutoGraphiX computer system in 2006. Finally, four of the open conjectures are
    
[^5]: 非峰值CTC提升端到端自动语音识别中词时分类器的帧级分类器

    Improving Frame-level Classifier for Word Timings with Non-peaky CTC in End-to-End Automatic Speech Recognition. (arXiv:2306.07949v1 [eess.AS])

    [http://arxiv.org/abs/2306.07949](http://arxiv.org/abs/2306.07949)

    本文提出通过在连接时序分类（CTC）损失中引入标签先验，并将低层Mel-scale滤波器和高层ASR编码器输出组合作为输入特征来改进E2E系统中用于词时的帧级分类器，实现了更高的词时准确性。

    

    端到端系统已经显示出与混合系统相当的自动语音识别（ASR）性能。作为ASR的副产品，词的定时对于许多应用程序至关重要，特别是字幕和计算机辅助发音训练。本文通过在连接时序分类（CTC）损失中引入标签先验，并将低层Mel-scale滤波器和高层ASR编码器输出组合作为输入特征，改进了E2E系统中用于词时的帧级分类器。在内部汉语语料库上，所提出的方法相比混合系统在单词时序准确性度量上实现了 95.68% / 94.18% 的性能，而且在7种语言的指标上绝对提高了4.80% / 8.02% 的分数，超越了先前的E2E方法。此外，我们通过延迟CTC峰值和基于帧的知识蒸馏进一步提高了词时准确性，但仅在LibriSpeech上进行了实验。

    End-to-end (E2E) systems have shown comparable performance to hybrid systems for automatic speech recognition (ASR). Word timings, as a by-product of ASR, are essential in many applications, especially for subtitling and computer-aided pronunciation training. In this paper, we improve the frame-level classifier for word timings in E2E system by introducing label priors in connectionist temporal classification (CTC) loss, which is adopted from prior works, and combining low-level Mel-scale filter banks with high-level ASR encoder output as input feature. On the internal Chinese corpus, the proposed method achieves 95.68%/94.18% compared to the hybrid system 93.0%/90.22% on the word timing accuracy metrics. It also surpass a previous E2E approach with an absolute increase of 4.80%/8.02% on the metrics on 7 languages. In addition, we further improve word timing accuracy by delaying CTC peaks with frame-wise knowledge distillation, though only experimenting on LibriSpeech.
    
[^6]: 研究：社交感知时间松散解码器推荐系统

    STUDY: Socially Aware Temporally Casual Decoder Recommender Systems. (arXiv:2306.07946v1 [cs.SI])

    [http://arxiv.org/abs/2306.07946](http://arxiv.org/abs/2306.07946)

    该论文提出了一种基于社交感知和时间因素的解码器推荐系统(STUDY)，使用transformer解码器网络实现对社交网络图中相邻的用户组的联合推断。该方法在教育内容领域中经过测试，能够取得优于社交和顺序方法的结果。

    

    随着现在在线和离线可获取的数据数量过于庞大，推荐系统变得越来越必要，以帮助用户找到符合他们兴趣的物品。当社交网络信息存在时，有一些方法利用这些信息来做出更好的推荐，但这些方法通常有复杂的结构和训练过程。此外，许多现有的方法使用图神经网络，而这些网络训练起来非常困难。为了解决这个问题，我们提出了基于社交感知和时间因素的解码器推荐系统(STUDY)。STUDY采用一个经过修改的transformer解码器网络的单向前传，对社交网络图中相邻的用户组进行联合推断。我们在基于学校课堂结构定义社交网络的教育内容领域测试了我们的方法。我们的方法在保持单一均匀网络设计简单性的同时，优于社交和顺序方法。

    With the overwhelming amount of data available both on and offline today, recommender systems have become much needed to help users find items tailored to their interests. When social network information exists there are methods that utilize this information to make better recommendations, however the methods are often clunky with complex architectures and training procedures. Furthermore many of the existing methods utilize graph neural networks which are notoriously difficult to train. To address this, we propose Socially-aware Temporally caUsal Decoder recommender sYstems (STUDY). STUDY does joint inference over groups of users who are adjacent in the social network graph using a single forward pass of a modified transformer decoder network. We test our method in a school-based educational content setting, using classroom structure to define social networks. Our method outperforms both social and sequential methods while maintaining the design simplicity of a single homogeneous netw
    
[^7]: 使用Speech2Text适配器和Speech2Entity检索增强LLM的语音理解模型

    Speech-to-Text Adapter and Speech-to-Entity Retriever Augmented LLMs for Speech Understanding. (arXiv:2306.07944v1 [eess.AS])

    [http://arxiv.org/abs/2306.07944](http://arxiv.org/abs/2306.07944)

    本文提出了一种联合语音和语言模型（SLM），将声音映射到文本嵌入式空间，使用基于CTC的空白过滤器来缩短语音序列长度。在语音MultiWoz数据集中，SLM提高了对话状态跟踪（DST）性能。为了解决稀有实体的错误，我们采用Speech2Entity检索器增强SLM。使用此检索-augmented SLM（ReSLM），DST性能得到进一步提高。该研究表明，增强ASR任务可以提高其性能。

    

    大型语言模型（LLM）已应用于语音领域，但往往由于音频和语言表示不匹配而导致性能下降。为了弥补这一缺陷，本文提出了一种联合语音和语言模型（SLM），采用Speech2Text适配器将声音映射到文本嵌入式空间，避免声音信息丢失。此外，使用基于CTC的空白过滤器可以将语音序列长度缩短至文本长度。在DSTC11挑战赛的语音MultiWoz数据集中，SLM显着提高了对话状态跟踪（DST）性能（从24.7％提高到28.4％的准确率）。为了解决稀有实体的错误，我们采用Speech2Entity检索器增强SLM，该检索器使用语音检索相关实体，并将它们添加到原始SLM输入中作为前缀。使用这种检索-augmented SLM（ReSLM），DST的性能提高至34.6％的准确率。此外，以对话理解任务增强ASR任务可以将ASR性能从9.4％提高到8.5％的词错误率。

    Large Language Models (LLMs) have been applied in the speech domain, often incurring a performance drop due to misaligned between speech and language representations. To bridge this gap, we propose a joint speech and language model (SLM) using a Speech2Text adapter, which maps speech into text token embedding space without speech information loss. Additionally, using a CTC-based blank-filtering, we can reduce the speech sequence length to that of text. In speech MultiWoz dataset (DSTC11 challenge), SLM largely improves the dialog state tracking (DST) performance (24.7% to 28.4% accuracy). Further to address errors on rare entities, we augment SLM with a Speech2Entity retriever, which uses speech to retrieve relevant entities, and then adds them to the original SLM input as a prefix. With this retrieval-augmented SLM (ReSLM), the DST performance jumps to 34.6% accuracy. Moreover, augmenting the ASR task with the dialog understanding task improves the ASR performance from 9.4% to 8.5% WE
    
[^8]: BoardgameQA: 一种用于带有矛盾信息的自然语言推理数据集

    BoardgameQA: A Dataset for Natural Language Reasoning with Contradictory Information. (arXiv:2306.07934v1 [cs.CL])

    [http://arxiv.org/abs/2306.07934](http://arxiv.org/abs/2306.07934)

    本文提出了一个用于带有矛盾信息的自然语言推理的数据集，以解决推理中不一致和矛盾信息的问题，同时提供了一种可推翻推理策略。

    

    自然语言文本的自动推理是许多潜在NLP应用和开发强大AI系统的关键要求。本文针对存在不一致和矛盾信息的推理问题提出一种解决策略，将问题形式化为经典的可推翻推理问题，并开发了一种数据集。

    Automated reasoning with unstructured natural text is a key requirement for many potential applications of NLP and for developing robust AI systems. Recently, Language Models (LMs) have demonstrated complex reasoning capacities even without any finetuning. However, existing evaluation for automated reasoning assumes access to a consistent and coherent set of information over which models reason. When reasoning in the real-world, the available information is frequently inconsistent or contradictory, and therefore models need to be equipped with a strategy to resolve such conflicts when they arise. One widely-applicable way of resolving conflicts is to impose preferences over information sources (e.g., based on source credibility or information recency) and adopt the source with higher preference. In this paper, we formulate the problem of reasoning with contradictory information guided by preferences over sources as the classical problem of defeasible reasoning, and develop a dataset ca
    
[^9]: 通过大语言模型理解电信语言

    Understanding Telecom Language Through Large Language Models. (arXiv:2306.07933v1 [cs.CL])

    [http://arxiv.org/abs/2306.07933](http://arxiv.org/abs/2306.07933)

    文章提出通过fine-tune多个大型语言模型实现电信领域自动化操作，以便识别3GPP标准工作组。

    

    人工智能的最新进展为自动化电信网络的许多任务提供了新的可能性。由于出现了包括大型语言模型在内的生成式人工智能，这一进展进一步推动了这一可能性的实现，这被认为是实现自我治理和互动式人工智能代理的基石。本文旨在将LLMs的范例应用于电信领域，具体而言，我们将fine-tune几个LLMs，包括BERT、Distilled BERT、RoBERTa和GPT-2，以适应电信领域的语言，并演示用例来识别第三代合作伙伴项目（3GPP）标准工作组。

    The recent progress of artificial intelligence (AI) opens up new frontiers in the possibility of automating many tasks involved in Telecom networks design, implementation, and deployment. This has been further pushed forward with the evolution of generative artificial intelligence (AI), including the emergence of large language models (LLMs), which is believed to be the cornerstone toward realizing self-governed, interactive AI agents. Motivated by this, in this paper, we aim to adapt the paradigm of LLMs to the Telecom domain. In particular, we fine-tune several LLMs including BERT, distilled BERT, RoBERTa and GPT-2, to the Telecom domain languages, and demonstrate a use case for identifying the 3rd Generation Partnership Project (3GPP) standard working groups. We consider training the selected models on 3GPP technical documents (Tdoc) pertinent to years 2009-2019 and predict the Tdoc categories in years 2020-2023. The results demonstrate that fine-tuning BERT and RoBERTa model achiev
    
[^10]: 人在循环链中。

    Human-in-the-Loop through Chain-of-Thought. (arXiv:2306.07932v1 [cs.CL])

    [http://arxiv.org/abs/2306.07932](http://arxiv.org/abs/2306.07932)

    通过人在循环链中的方式，手动校正系统可以通过探究理性中子逻辑的手动校正来提高LLM的推理性能，并且基于经济理论的CAMLOP可以平衡效用和成本。

    

    尽管强大的语言模型和思维链提示的出现使自动化变得越来越无处不在，但有时在长期或多步逻辑推理方面显示出其弱点。例如，用户在没有人类参与的情况下不总能得到复杂数学问题的理想答案。在这个背景下，我们提出了手动校正系统（MCS）——一个通过思维链提示增强的人工参与系统，探究了理性中子逻辑的手动校正如何提高LLM的推理性能。更进一步考虑到有人参与的系统不仅要提高性能，还要控制成本。因此，我们提出了基于古典经济理论的人在循环链中成本效用分析模型（CAMLOP）来分析、量化和平衡效用和相应的成本。我们使用12个数据集对MCS和CAMLOP进行了实验。

    While the emergence of powerful language models along with Chain-of-thought prompting has made automation more and more omnipresent, it sometimes demonstrates its weakness in long-term or multi-step logical reasoning. For example, users don't always get desirable answers for complex mathematical problems without human involvement. Against this background, we present the Manual Correction System (MCS) -- a human-in-the-loop system enhanced by Chain-of-Thought prompting, which explores how manual correction of sub-logics in rationales can improve LLM's reasoning performance. Moving one step forward, considering a system with human-in-the-loop involves more than having humans improve performance but also controlling the cost. Therefore, we post a Cost-utility Analysis Model for Human-in-the-Loop systems (CAMLOP) based on classical economics theory to analyze, quantify and balance the utility and the corresponding cost. We conduct experiments of MCS and CAMLOP with twelve datasets. A signi
    
[^11]: 大型语言模型是半参数强化学习智能体

    Large Language Model Is Semi-Parametric Reinforcement Learning Agent. (arXiv:2306.07929v1 [cs.CL])

    [http://arxiv.org/abs/2306.07929](http://arxiv.org/abs/2306.07929)

    根据人类记忆和推理机制，提出了一种新的可演化LLM智能体框架REMEMBERER，通过为LLM装备长期经验记忆，可以为不同任务提供优异的智能体，其构成了半参数RL代理。成功率超过先前SOTA 4％和2％。

    

    受认知科学对人类记忆和推理机制的启发，提出了一种新的可演化LLM（大型语言模型）智能体框架REMEMBERER。通过为LLM装备长期经验记忆，REMEMBERER能够利用过去剧集的经验，甚至可以为不同的任务目标提供优异的LLM智能体，这优于具有固定实例或具有短暂工作记忆的LLM智能体。我们进一步介绍了经验记忆的强化学习（RLEM）来更新记忆。因此，整个系统可以从成功和失败的经验中学习，并在不微调LLM参数的情况下发展其能力。以此方式，所提出的REMEMBERER构成了半参数RL代理。在两个RL任务集上进行了大量实验以评估所提出的框架。不同初始化和训练集的平均结果对于成功率超过先前SOTA 4％和2％。

    Inspired by the insights in cognitive science with respect to human memory and reasoning mechanism, a novel evolvable LLM-based (Large Language Model) agent framework is proposed as REMEMBERER. By equipping the LLM with a long-term experience memory, REMEMBERER is capable of exploiting the experiences from the past episodes even for different task goals, which excels an LLM-based agent with fixed exemplars or equipped with a transient working memory. We further introduce Reinforcement Learning with Experience Memory (RLEM) to update the memory. Thus, the whole system can learn from the experiences of both success and failure, and evolve its capability without fine-tuning the parameters of the LLM. In this way, the proposed REMEMBERER constitutes a semi-parametric RL agent. Extensive experiments are conducted on two RL task sets to evaluate the proposed framework. The average results with different initialization and training sets exceed the prior SOTA by 4% and 2% for the success rate 
    
[^12]: 非线性潜变量层次模型的识别

    Identification of Nonlinear Latent Hierarchical Models. (arXiv:2306.07916v1 [cs.LG])

    [http://arxiv.org/abs/2306.07916](http://arxiv.org/abs/2306.07916)

    本文提出了一种方法，可以在观测变量由因果相关的潜变量生成的非线性潜变量层次因果模型中实现因果结构和潜变量的可识别性。

    

    从观测数据中识别潜变量和因果结构对于许多涉及生物数据、医学数据和非结构化数据（如图像和语言）的实际应用至关重要。然而，当观测变量由因果相关的潜变量生成，并且关系是非线性的时，这项任务可能非常具有挑战性。在这项工作中，我们研究了非线性潜变量层次因果模型的识别问题，在这种模型中，观测变量由一组因果相关的潜变量生成，有些潜变量可能没有观察到的后代。我们证明，在温和的假设下可以实现因果结构和潜变量的可识别性：对于因果结构，我们允许图中任意两个变量之间存在多条路径，这放宽了先前工作中的潜变量树假设；对于结构函数，我们没有进行参数假设，因此可以允许基因

    Identifying latent variables and causal structures from observational data is essential to many real-world applications involving biological data, medical data, and unstructured data such as images and languages. However, this task can be highly challenging, especially when observed variables are generated by causally related latent variables and the relationships are nonlinear. In this work, we investigate the identification problem for nonlinear latent hierarchical causal models in which observed variables are generated by a set of causally related latent variables, and some latent variables may not have observed children. We show that the identifiability of both causal structure and latent variables can be achieved under mild assumptions: on causal structures, we allow for the existence of multiple paths between any pair of variables in the graph, which relaxes latent tree assumptions in prior work; on structural functions, we do not make parametric assumptions, thus permitting gene
    
[^13]: WebGLM: 基于人类偏好的高效网络增强问答系统

    WebGLM: Towards An Efficient Web-Enhanced Question Answering System with Human Preferences. (arXiv:2306.07906v1 [cs.CL])

    [http://arxiv.org/abs/2306.07906](http://arxiv.org/abs/2306.07906)

    本文提出的WebGLM是一种基于GLM的网络问答系统，使用LLM-augmented检索器、引导式生成器和人类偏好感知评分器等策略提高了准确性、效率和成本效益，并在人类评估中表现出比WebGPT更好的性能。

    

    我们提出了WebGLM，一种基于通用语言模型（GLM）的网络增强问答系统。其目标是在保持适用于实际应用的同时，利用网络搜索和检索能力增强预训练的大语言模型（LLM）。为了实现这一目标，我们通过LLM增强的检索器、引导式生成器和人类偏好感知评分器等策略开发了WebGLM。具体而言，我们识别并解决了WebGPT（OpenAI）的局限性，从而为WebGLM提供了准确性、效率和成本效益的优势。此外，我们提出了评估网络增强QA系统的系统性标准。我们进行了多维人类评估和定量削弱研究，结果表明所提出的WebGLM设计优于现有系统。与WebGPT（13B）相比，使用100亿参数的GLM（10B）的WebGLM在人类评估中表现更好，甚至可与WebGPT（175B）相媲美。

    We present WebGLM, a web-enhanced question-answering system based on the General Language Model (GLM). Its goal is to augment a pre-trained large language model (LLM) with web search and retrieval capabilities while being efficient for real-world deployments. To achieve this, we develop WebGLM with strategies for the LLM-augmented retriever, bootstrapped generator, and human preference-aware scorer. Specifically, we identify and address the limitations of WebGPT (OpenAI), through which WebGLM is enabled with accuracy, efficiency, and cost-effectiveness advantages. In addition, we propose systematic criteria for evaluating web-enhanced QA systems. We conduct multi-dimensional human evaluation and quantitative ablation studies, which suggest the outperformance of the proposed WebGLM designs over existing systems. WebGLM with the 10-billion-parameter GLM (10B) is shown to perform better than the similar-sized WebGPT (13B) and even comparably to WebGPT (175B) in human evaluation. The code,
    
[^14]: 大规模多语言情感数据集和多方面情感分类基准的语料库。

    Massively Multilingual Corpus of Sentiment Datasets and Multi-faceted Sentiment Classification Benchmark. (arXiv:2306.07902v1 [cs.CL])

    [http://arxiv.org/abs/2306.07902](http://arxiv.org/abs/2306.07902)

    本研究介绍了一种可以用于训练情感模型的最全面的开放式大规模多语言数据集，该数据集由79个手动选定的数据集组成，覆盖了27种语言，代表了6种语言家族。而且，我们还提供了一个多方面的情感分类基准。

    

    尽管多语言语料库和模型训练取得了令人瞩目的进展，但开发大规模的多语言模型仍然是一个重大挑战。这在文化相关的语言任务中尤其如此。多语言情感分析就是一个例子，其中情感标记可能非常微妙且深深植根于文化中。本文介绍了可用于训练情感模型的最全面的开放式大规模多语言数据集的语料库。该语料库由79个手动选择的数据集组成，它们是基于严格的质量标准从科学文献中报告的超过350个数据集中选出的。该语料库涵盖了27种语言，代表了6种语言家族。数据集可以使用几个语言和功能特征进行查询。此外，我们提供了一个多方面的情感分类基准，总结了对不同的基本模型、训练目标、数据集集合和微调进行的数百个实验。

    Despite impressive advancements in multilingual corpora collection and model training, developing large-scale deployments of multilingual models still presents a significant challenge. This is particularly true for language tasks that are culture-dependent. One such example is the area of multilingual sentiment analysis, where affective markers can be subtle and deeply ensconced in culture. This work presents the most extensive open massively multilingual corpus of datasets for training sentiment models. The corpus consists of 79 manually selected datasets from over 350 datasets reported in the scientific literature based on strict quality criteria. The corpus covers 27 languages representing 6 language families. Datasets can be queried using several linguistic and functional features. In addition, we present a multi-faceted sentiment classification benchmark summarizing hundreds of experiments conducted on different base models, training objectives, dataset collections, and fine-tunin
    
[^15]: ReadProbe: 一种支持横向阅读的检索增强大语言模型演示

    ReadProbe: A Demo of Retrieval-Enhanced Large Language Models to Support Lateral Reading. (arXiv:2306.07875v1 [cs.IR])

    [http://arxiv.org/abs/2306.07875](http://arxiv.org/abs/2306.07875)

    ReadProbe 是一种利用大型语言模型和搜索引擎支持横向阅读的工具，它能够生成有用问题和答案以帮助用户评估在线信息。

    

    随着网络不实信息的快速增长和传播，人们需要工具来帮助他们评估在线信息的可信度和准确性。横向阅读是一种跨参考多个信息源的策略，可能是实现这一目标的有效方法。在本文中，我们提出了一个工具，名为 ReadProbe，它支持横向阅读，由 OpenAI 的生成式大语言模型和必应搜索引擎驱动。我们的工具能够为横向阅读生成有用的问题，搜寻网络上相关的文档，并产生良好归因的答案，帮助人们更好地评估在线信息。我们制作了一个基于 Web 的应用程序，演示了 ReadProbe 如何帮助减少被虚假信息误导的风险。我们的代码可在 https://github.com/DakeZhang1998/ReadProbe 上获得，我们的早期版本赢得了全国人工智能虚假信息黑客马拉松的一等奖。

    With the rapid growth and spread of online misinformation, people need tools to help them evaluate the credibility and accuracy of online information. Lateral reading, a strategy that involves cross-referencing information with multiple sources, may be an effective approach to achieving this goal. In this paper, we present ReadProbe, a tool to support lateral reading, powered by generative large language models from OpenAI and the Bing search engine. Our tool is able to generate useful questions for lateral reading, scour the web for relevant documents, and generate well-attributed answers to help people better evaluate online information. We made a web-based application to demonstrate how ReadProbe can help reduce the risk of being misled by false information. The code is available at https://github.com/DakeZhang1998/ReadProbe. An earlier version of our tool won the first prize in a national AI misinformation hackathon.
    
[^16]: 分层结构领域自适应

    Taxonomy-Structured Domain Adaptation. (arXiv:2306.07874v1 [cs.LG])

    [http://arxiv.org/abs/2306.07874](http://arxiv.org/abs/2306.07874)

    本文提出了分层结构领域自适应方法，通过分层结构领域的形式化描述来缓解不同领域之间的分布偏移，该方法在合成和实际数据集上实现了最先进的性能。

    

    领域自适应旨在缓解不同领域之间的分布偏移。然而，传统的方法大多限于分类领域，这严重简化了真实世界中微妙的领域关系。在本文中，我们通过分层结构领域进行推广，将领域形式化为具有嵌套的层次相似结构，例如动物物种和产品目录。我们建立在经典对抗框架之上，并引入了一种新颖的分类器，该分类器与对抗性鉴别器竞争以保留层次结构信息。当给定非信息领域分类（例如，所有叶节点都链接到根节点的扁平分类）时，平衡点恢复经典的对抗领域适应解决方案，同时在其他分类中产生非平凡的结果。在合成和实际数据集上实证结果表明，我们的方法实现了最先进的性能，并成功进行了自适应。代码可在https://gith获得。

    Domain adaptation aims to mitigate distribution shifts among different domains. However, traditional formulations are mostly limited to categorical domains, greatly simplifying nuanced domain relationships in the real world. In this work, we tackle a generalization with taxonomy-structured domains, which formalizes domains with nested, hierarchical similarity structures such as animal species and product catalogs. We build on the classic adversarial framework and introduce a novel taxonomist, which competes with the adversarial discriminator to preserve the taxonomy information. The equilibrium recovers the classic adversarial domain adaptation's solution if given a non-informative domain taxonomy (e.g., a flat taxonomy where all leaf nodes connect to the root node) while yielding non-trivial results with other taxonomies. Empirically, our method achieves state-of-the-art performance on both synthetic and real-world datasets with successful adaptation. Code is available at https://gith
    
[^17]: Synapse：利用少量示例为实现人类级别的计算机控制打下基础

    Synapse: Leveraging Few-Shot Exemplars for Human-Level Computer Control. (arXiv:2306.07863v1 [cs.AI])

    [http://arxiv.org/abs/2306.07863](http://arxiv.org/abs/2306.07863)

    本文探究了使用大型语言模型提示少量示例来实现人类级别的计算机控制；通过分解演示、过滤状态并重新构造任务描述，示例检索等步骤，Synapse 具备了适应多任务、泛化多环境的能力。

    

    本文探究了使用大型语言模型（LLMs）提示少量示例来进行计算机自动化的设计。虽然以前的提示方法着重于自我纠正，但我们发现仅仅有良好结构的示例就足以实现人类级别的性能。我们提出了 Synapse，一种上下文计算机控制代理，在 MiniWob++ 基准测试中展现了人类级别的性能。Synapse 由三个主要组件组成：1）状态条件分解，根据代理需要新环境状态将演示分为示例集，实现了时间抽象；2）结构化提示，过滤状态并重新构造每个集合的任务描述以改善计划的正确性；3）示例检索，将传入的任务与示例数据库中的对应示例相关联，以实现多任务适应和泛化。Synapse 克服了上下文长度限制，减少了多步控制中的错误，可以更有效灵活地使用语言模型进行计算机自动化。

    This paper investigates the design of few-shot exemplars for computer automation through prompting large language models (LLMs). While previous prompting approaches focus on self-correction, we find that well-structured exemplars alone are sufficient for human-level performance. We present Synapse, an in-context computer control agent demonstrating human-level performance on the MiniWob++ benchmark. Synapse consists of three main components: 1) state-conditional decomposition, which divides demonstrations into exemplar sets based on the agent's need for new environment states, enabling temporal abstraction; 2) structured prompting, which filters states and reformulates task descriptions for each set to improve planning correctness; and 3) exemplar retrieval, which associates incoming tasks with corresponding exemplars in an exemplar database for multi-task adaptation and generalization. Synapse overcomes context length limits, reduces errors in multi-step control, and allows for more e
    
[^18]: 给我看看数字！--针对德语拼写的自适应学习环境中面向学生的干预措施

    Show me the numbers! -- Student-facing Interventions in Adaptive Learning Environments for German Spelling. (arXiv:2306.07853v1 [cs.CY])

    [http://arxiv.org/abs/2306.07853](http://arxiv.org/abs/2306.07853)

    该论文的实验表明，基于机器学习的面向学生干预措施可以帮助提高德语拼写技巧的自适应学习环境，对降低学生错误率具有显著作用，但需要谨慎选择以避免辍学率的增加。

    

    由于自适应学习环境种类繁多，因此找到哪些适应措施对于哪些学习领域是有意义的至关重要。我们的工作呈现了在一个在线平台上进行的实验的结果，该平台旨在通过机器学习为基础的面向学生的干预措施来提高学习德语拼写技能。我们将传统的在线学习平台与该平台的三个不同的自适应版本进行了比较，这些版本实现了向学生展示个性化解决方案概率的干预措施。我们评估了不同的干预措施，关注错误率、辍学率和用户能力。我们的结果显示，错误次数相比对照组有所减少。此外，我们发现辍学人数也在增加。我们没有发现任何对于用户能力的显著影响。我们得出结论：面向学生的自适应学习环境可以有效提高个人错误率，应谨慎选择，以发挥激励作用。

    Since adaptive learning comes in many shapes and sizes, it is crucial to find out which adaptations can be meaningful for which areas of learning. Our work presents the result of an experiment conducted on an online platform for the acquisition of German spelling skills. We compared the traditional online learning platform to three different adaptive versions of the platform that implement machine learning-based student-facing interventions that show the personalized solution probability. We evaluate the different interventions with regard to the error rate, the number of early dropouts, and the users competency. Our results show that the number of mistakes decreased in comparison to the control group. Additionally, an increasing number of dropouts was found. We did not find any significant effects on the users competency. We conclude that student-facing adaptive learning environments are effective in improving a persons error rate and should be chosen wisely to have a motivating impac
    
[^19]: 分子属性预测的自动化三维预训练

    Automated 3D Pre-Training for Molecular Property Prediction. (arXiv:2306.07812v1 [q-bio.QM])

    [http://arxiv.org/abs/2306.07812](http://arxiv.org/abs/2306.07812)

    通过在3D分子图上进行预训练，该论文提出了一种更有效地预测分子属性的方法，该方法可以在不需要分子几何结构的情况下进行微调。

    

    分子属性预测是药物研发和材料科学中的重要问题。由于分子的几何结构对于分子属性预测的必要性已经被证明，因此将3D信息与各种图形学习方法相结合以提高预测性能。然而，由于高计算成本，在许多现实应用中获得分子的几何结构是不可行的。在这项工作中，我们提出了一种新的3D预训练框架（称为3D PGT），它在3D分子图上预训练模型，然后在没有3D结构的分子图上进行微调。基于化学键长，化学键角和二面角这三个基本几何描述符对应于完整的分子3D构形，我们首先开发了一个基于这三个属性的多任务生成预训练框架。接下来，为了自动融合这三项生成任务，我们设计了一种使用“总能量”来搜索的替代指标。

    Molecular property prediction is an important problem in drug discovery and materials science. As geometric structures have been demonstrated necessary for molecular property prediction, 3D information has been combined with various graph learning methods to boost prediction performance. However, obtaining the geometric structure of molecules is not feasible in many real-world applications due to the high computational cost. In this work, we propose a novel 3D pre-training framework (dubbed 3D PGT), which pre-trains a model on 3D molecular graphs, and then fine-tunes it on molecular graphs without 3D structures. Based on fact that bond length, bond angle, and dihedral angle are three basic geometric descriptors corresponding to a complete molecular 3D conformer, we first develop a multi-task generative pre-train framework based on these three attributes. Next, to automatically fuse these three generative tasks, we design a surrogate metric using the \textit{total energy} to search for 
    
[^20]: ChatGPT与人工撰写文本：可控文本摘要和句子风格转移的洞察

    ChatGPT vs Human-authored Text: Insights into Controllable Text Summarization and Sentence Style Transfer. (arXiv:2306.07799v1 [cs.CL])

    [http://arxiv.org/abs/2306.07799](http://arxiv.org/abs/2306.07799)

    本文旨在系统地检查ChatGPT在两个可控生成任务中的表现，即ChatGPT能否适应不同的目标受众和写作风格。研究发现，人类产生的文体变化比ChatGPT表现出的更大，而生成的文本在一些特征上与人类样本有所不同，有时会包含事实错误或幻觉。

    

    大规模语言模型（如ChatGPT）以其出色的能力从简短的自然语言提示生成连贯的文本引起了媒体的重视。本文旨在系统地检查ChatGPT在两个可控生成任务中的表现，即ChatGPT能否适应不同的目标受众（专家与一般人）和写作风格（正式与非正式）。此外，我们评估了生成文本的忠实度，并将模型的表现与人工撰写的文本进行了比较。我们的研究发现，人类产生的文体变化比ChatGPT表现出的更大，而生成的文本在诸如单词类型分布等几个特征上与人类样本有所不同。此外，我们发现当 ChatGPT 将文本适应特定风格时，有时会包含事实错误或幻觉。

    Large-scale language models, like ChatGPT, have garnered significant media attention and stunned the public with their remarkable capacity for generating coherent text from short natural language prompts. In this paper, we aim to conduct a systematic inspection of ChatGPT's performance in two controllable generation tasks, with respect to ChatGPT's ability to adapt its output to different target audiences (expert vs. layman) and writing styles (formal vs. informal). Additionally, we evaluate the faithfulness of the generated text, and compare the model's performance with human-authored texts. Our findings indicate that the stylistic variations produced by humans are considerably larger than those demonstrated by ChatGPT, and the generated texts diverge from human samples in several characteristics, such as the distribution of word types. Moreover, we observe that ChatGPT sometimes incorporates factual errors or hallucinations when adapting the text to suit a specific style.
    
[^21]: NoCoLA：挪威语言接受性语料库

    NoCoLA: The Norwegian Corpus of Linguistic Acceptability. (arXiv:2306.07790v1 [cs.CL])

    [http://arxiv.org/abs/2306.07790](http://arxiv.org/abs/2306.07790)

    本论文提出了两个新的挪威语数据集，分别用于二元分类和纯诊断任务，旨在评估语言模型的语法理解能力。它们适用于不同类型的语言模型，并用于对现有挪威语言模型进行比较研究。

    

    近年来，大量的挪威语言模型出现，但我们缺乏评估其语法理解能力的工具。我们提出了两个新的挪威数据集来完成这项任务。其中NoCoLA_class是一个带监督的二元分类任务，旨在区分可接受和不可接受的句子；而NoCoLA_zero则是一个完全无需进行额外训练即可在零样本方式下评估语言模型语法判断的纯诊断任务。本文详细描述了这两个数据集，展示了如何用它们来为不同类型的语言模型进行比较，并对现有的挪威语言模型进行了比较研究。

    While there has been a surge of large language models for Norwegian in recent years, we lack any tool to evaluate their understanding of grammaticality. We present two new Norwegian datasets for this task. NoCoLA_class is a supervised binary classification task where the goal is to discriminate between acceptable and non-acceptable sentences. On the other hand, NoCoLA_zero is a purely diagnostic task for evaluating the grammatical judgement of a language model in a completely zero-shot manner, i.e. without any further training. In this paper, we describe both datasets in detail, show how to use them for different flavors of language models, and conduct a comparative study of the existing Norwegian language models.
    
[^22]: 一种基于云的机器学习管道，有效从客户评论中提取见解

    A Cloud-based Machine Learning Pipeline for the Efficient Extraction of Insights from Customer Reviews. (arXiv:2306.07786v1 [cs.CL])

    [http://arxiv.org/abs/2306.07786](http://arxiv.org/abs/2306.07786)

    本文介绍了一种基于云的系统，利用机器学习方法从客户评论中提取见解。本研究提出的组合模型使用了转换器神经网络、向量嵌入和聚类，已经集成并进一步发展，以更好地满足高效信息提取、提取信息的主题建模和用户需求的要求。研究结果表明，本系统可以比现有的主题建模和关键字提取解决方案获得更好的效果。

    

    随着机器学习模型的出现，特别是基于神经网络的解决方案，自然语言处理的效率有了显著提高。然而，一些任务仍然具有挑战性，特别是考虑到特定的应用领域。本文提出了一种基于云的系统，可以使用机器学习方法集成到管道中，从客户评论中提取见解。对于主题建模，我们的组合模型使用了基于转换器的自然语言处理神经网络、基于向量嵌入的关键字提取和聚类。我们的模型元素已经集成并进一步发展，以更好地满足高效信息提取、提取信息的主题建模和用户需求的要求。此外，我们的系统可以比这个任务现有的主题建模和关键字提取解决方案获得更好的结果。我们的方法在公开可用的客户评论数据集上得到验证并与其他最先进的方法进行比较。

    The efficiency of natural language processing has improved dramatically with the advent of machine learning models, particularly neural network-based solutions. However, some tasks are still challenging, especially when considering specific domains. In this paper, we present a cloud-based system that can extract insights from customer reviews using machine learning methods integrated into a pipeline. For topic modeling, our composite model uses transformer-based neural networks designed for natural language processing, vector embedding-based keyword extraction, and clustering. The elements of our model have been integrated and further developed to meet better the requirements of efficient information extraction, topic modeling of the extracted information, and user needs. Furthermore, our system can achieve better results than this task's existing topic modeling and keyword extraction solutions. Our approach is validated and compared with other state-of-the-art methods using publicly a
    
[^23]: 因式分解子词编码的分词方法

    Tokenization with Factorized Subword Encoding. (arXiv:2306.07764v1 [cs.CL])

    [http://arxiv.org/abs/2306.07764](http://arxiv.org/abs/2306.07764)

    本文提出了一种因式分解子词编码的分词方法，被称为“因式分解器”，在七种不同语言的语言建模和形态句法任务中进行评估，相较于常用的BPE算法具有更好的适应性和鲁棒性。

    

    近年来，语言模型变得越来越大、越来越复杂，然而这些模型的输入表示仍然依赖于简单和贪婪的子词分词方法。本文提出了一种新颖的分词方法，该方法使用VQ-VAE模型将子词因子化为离散三元组。所提出的分词方法被称为“因式分解器”，并在七种不同语言的语言建模和形态句法任务中进行了评估。结果表明，该方法比常用的字节对编码(BPE)分词算法更适合和更稳健于形态句法任务。

    In recent years, language models have become increasingly larger and more complex. However, the input representations for these models continue to rely on simple and greedy subword tokenization methods. In this paper, we propose a novel tokenization method that factorizes subwords onto discrete triplets using a VQ-VAE model. The effectiveness of the proposed tokenization method, referred to as the Factorizer, is evaluated on language modeling and morpho-syntactic tasks for 7 diverse languages. Results indicate that this method is more appropriate and robust for morphological tasks than the commonly used byte-pair encoding (BPE) tokenization algorithm.
    
[^24]: 核化强化学习及其近似方法的优化

    Kernelized Reinforcement Learning with Order Optimal Regret Bounds. (arXiv:2306.07745v1 [cs.LG])

    [http://arxiv.org/abs/2306.07745](http://arxiv.org/abs/2306.07745)

    该论文提出了一种称为$\pi$-KRVI的乐观修改方法，并使用核岭回归进行强化学习中的非线性函数逼近。论文证明了在一般设置下第一个最优遗憾保证，并相对于现有最优结果实现了显着的多项式低差距。

    

    强化学习（RL）在各种具有复杂模型和大状态-行为空间的实际场景中显示出了实证的成功。但是，现有的分析结果通常集中于具有少量状态-行为或简单模型（例如线性建模状态-行为值函数）的设置。 为了推导有效处理更广泛值函数的大状态-行为空间的RL策略，一些最新工作考虑使用核岭回归进行非线性函数逼近。 我们提出了称为$\pi$-KRVI的方法，它是最小二乘值迭代的一种乐观修改，当状态-行为值函数由RKHS表示时。我们证明了在一般设置下第一个最优遗憾保证。我们的结果显示，在许多具有高度非光滑内核（例如神经切向内核或某些Mat\'ern内核）的情况下，相对于现有最优结果，存在显着的多项式低差距。

    Reinforcement learning (RL) has shown empirical success in various real world settings with complex models and large state-action spaces. The existing analytical results, however, typically focus on settings with a small number of state-actions or simple models such as linearly modeled state-action value functions. To derive RL policies that efficiently handle large state-action spaces with more general value functions, some recent works have considered nonlinear function approximation using kernel ridge regression. We propose $\pi$-KRVI, an optimistic modification of least-squares value iteration, when the state-action value function is represented by an RKHS. We prove the first order-optimal regret guarantees under a general setting. Our results show a significant polynomial in the number of episodes improvement over the state of the art. In particular, with highly non-smooth kernels (such as Neural Tangent kernel or some Mat\'ern kernels) the existing results lead to trivial (superl
    
[^25]: V-LoL: 一种用于视觉逻辑学习的诊断数据集

    V-LoL: A Diagnostic Dataset for Visual Logical Learning. (arXiv:2306.07743v1 [cs.AI])

    [http://arxiv.org/abs/2306.07743](http://arxiv.org/abs/2306.07743)

    V-LoL是一个结合视觉和逻辑挑战的诊断数据集，其中包括了V-LoL-Trains，该数据集首次将复杂的视觉场景和灵活的逻辑推理任务结合起来，为研究广泛的视觉逻辑学习挑战提供了平台。

    

    尽管近期在视觉AI领域有了许多成功的进展，但仍存在不同的缺点；包括缺少精确的逻辑推理、抽象的概括能力以及理解复杂和嘈杂的场景等。不幸的是，现有的基准测试数据集并不能捕捉到这些方面中的多数。深度学习数据集关注视觉复杂数据但只有简单的视觉推理任务，归纳逻辑数据集包括复杂的逻辑学习任务，但是缺乏视觉的组成部分。为了解决这个问题，我们提出了视觉逻辑学习数据集V-LoL，它无缝地结合了视觉和逻辑的挑战。值得注意的是，我们首次推出了V-LoL的第一个实例，名为V-LoL-Trains，它是符号AI中一个经典基准测试的视觉呈现，即Michalski火车问题。通过在一个通用框架内结合复杂的视觉场景和灵活的逻辑推理任务，V-LoL-Trains为研究广泛的视觉逻辑学习挑战提供了平台。

    Despite the successes of recent developments in visual AI, different shortcomings still exist; from missing exact logical reasoning, to abstract generalization abilities, to understanding complex and noisy scenes. Unfortunately, existing benchmarks, were not designed to capture more than a few of these aspects. Whereas deep learning datasets focus on visually complex data but simple visual reasoning tasks, inductive logic datasets involve complex logical learning tasks, however, lack the visual component. To address this, we propose the visual logical learning dataset, V-LoL, that seamlessly combines visual and logical challenges. Notably, we introduce the first instantiation of V-LoL, V-LoL-Trains, -- a visual rendition of a classic benchmark in symbolic AI, the Michalski train problem. By incorporating intricate visual scenes and flexible logical reasoning tasks within a versatile framework, V-LoL-Trains provides a platform for investigating a wide range of visual logical learning ch
    
[^26]: 深度学习模型在物理-计算系统中的鲁棒性和泛化性能的比较研究

    Robustness and Generalization Performance of Deep Learning Models on Cyber-Physical Systems: A Comparative Study. (arXiv:2306.07737v1 [cs.LG])

    [http://arxiv.org/abs/2306.07737](http://arxiv.org/abs/2306.07737)

    本文研究了深度学习模型在物理-计算系统中的鲁棒性和泛化性能，并通过暴露模型于分布之外的样本来测试其迁移学习能力和响应数据增强技术的能力。结果表明，深度学习模型虽能达高精度，但其鲁棒性和泛化能力还不足以应用于实际物理-计算系统中。

    

    深度学习模型在时间序列预测方面越来越受到关注，但在物理-计算系统中应用受到这些方法鲁棒性的限制。因此，本研究评估了深度学习架构在来自物理-计算系统的多元时间序列数据上的鲁棒性和泛化性能。我们的研究重点是模型处理一系列扰动的能力，如传感器故障和噪声，并评估它们对整体性能的影响。此外，我们通过将它们暴露于分布之外（OOD）的样本来测试这些模型的泛化和迁移学习能力。这些样本包括偏离标准系统操作，同时保留了基础物理系统的核心动态。此外，我们测试了模型对几种数据增强技术的响应能力，包括添加噪声和时间扭曲。我们的实验框架利用了一个模拟的三罐系统，作为研究物理-计算系统中深度学习模型鲁棒性的新型基准。结果表明，尽管深度学习模型能够达到高精度，但它们的鲁棒性和泛化能力不足以用于现实世界中的物理-计算系统应用。

    Deep learning (DL) models have seen increased attention for time series forecasting, yet the application on cyber-physical systems (CPS) is hindered by the lacking robustness of these methods. Thus, this study evaluates the robustness and generalization performance of DL architectures on multivariate time series data from CPS. Our investigation focuses on the models' ability to handle a range of perturbations, such as sensor faults and noise, and assesses their impact on overall performance. Furthermore, we test the generalization and transfer learning capabilities of these models by exposing them to out-of-distribution (OOD) samples. These include deviations from standard system operations, while the core dynamics of the underlying physical system are preserved. Additionally, we test how well the models respond to several data augmentation techniques, including added noise and time warping. Our experimental framework utilizes a simulated three-tank system, proposed as a novel benchmar
    
[^27]: 上下文词典查找用于知识图谱补全

    Contextual Dictionary Lookup for Knowledge Graph Completion. (arXiv:2306.07719v1 [cs.AI])

    [http://arxiv.org/abs/2306.07719](http://arxiv.org/abs/2306.07719)

    本文提出了一种使用上下文词典查找的方法，使传统的嵌入模型能够以端到端的方式学习关系的细粒度语义，该方法在四个基准数据集上取得了最先进或有竞争力的结果，同时具有更简单和可解释的模型结构。

    

    知识图谱补全旨在通过从已知三元组中预测缺失链接来解决知识图谱(KGs)的不完整性，已经有许多知识图嵌入(KGE)模型来执行KGC。尽管如此，大多数现有的嵌入模型将每个关系映射到一个唯一的向量，忽略了它们在不同实体下的具体细粒度语义。此外，少量可用的细粒度语义模型依靠聚类算法，由于繁琐的二阶段训练过程，导致了有限的性能和适用性。本文提出了一种利用上下文词典查找的新方法，使传统的嵌入模型能够以端到端的方式学习关系的细粒度语义。更具体地，我们使用包含多个潜在语义的词典来表示每个关系。给定实体与词典的中心语义的组合用作词典查找层的上下文，该层返回给定实体下关系的具体语义。我们使用与现有嵌入模型兼容的模块化设计集成这个层，证明了我们方法在四个基准数据集上的有效性。我们的方法在所有四个数据集上均取得了最先进或有竞争力的结果，并具有更简单和可解释的模型结构。

    Knowledge graph completion (KGC) aims to solve the incompleteness of knowledge graphs (KGs) by predicting missing links from known triples, numbers of knowledge graph embedding (KGE) models have been proposed to perform KGC by learning embeddings. Nevertheless, most existing embedding models map each relation into a unique vector, overlooking the specific fine-grained semantics of them under different entities. Additionally, the few available fine-grained semantic models rely on clustering algorithms, resulting in limited performance and applicability due to the cumbersome two-stage training process. In this paper, we present a novel method utilizing contextual dictionary lookup, enabling conventional embedding models to learn fine-grained semantics of relations in an end-to-end manner. More specifically, we represent each relation using a dictionary that contains multiple latent semantics. The composition of a given entity and the dictionary's central semantics serves as the context f
    
[^28]: 朝着可解释性TOPSIS：权重和聚合对排名的影响的视觉洞察力

    Towards Explainable TOPSIS: Visual Insights into the Effects of Weights and Aggregations on Rankings. (arXiv:2306.07706v1 [cs.AI])

    [http://arxiv.org/abs/2306.07706](http://arxiv.org/abs/2306.07706)

    本研究提出了可解释TOPSIS的新方法，并介绍了TOPSIS-Explorer决策支持工具。该方法通过可视化方式解释权重和聚合对排名结果的影响，对实际应用有着重要意义。

    

    多标准决策分析（MCDA）在各个行业中广泛用于评估和排名备选方案。在众多MCDA方法中，TOPSIS仍然是许多应用领域最受欢迎的选择之一。TOPSIS计算考虑的备选方案与两个预定义方案（即理想状态和反理想状态）之间的距离，并根据这些距离的聚合值创建备选方案的排名。然而，TOPSIS的内部工作解释是困难的，特别是当标准数目很大时。为此，最近的研究表明可以使用备选方案的平均值（M）和标准偏差（SD）来表示TOPSIS聚合值，从而创建MSD空间，这是一种可视化并解释聚合的工具。即使MSD空間非常有用，但它假设标准同样重要，使其在实际排名问题中的适用性降低 。在本文中，我们推广了 TOPSIS 结果的转换，使得不同的标准可以解释为视觉上的 MSD 空间，以此来处理将权重加入TOPSIS问题的场景。我们引入了加权 MSD 空间并开发了一个决策支持工具，称为 TOPSIS-Explorer，提供易于理解的视觉洞察力，以分析不同权重和聚合值对排名结果的影响。我们的方法在合成数据集和供应商选择实际案例上进行了评估，证明了它在提供可解释TOPSIS结果方面的适用性和有效性。

    Multi-Criteria Decision Analysis (MCDA) is extensively used across diverse industries to assess and rank alternatives. Among numerous MCDA methods developed to solve real-world ranking problems, TOPSIS remains one of the most popular choices in many application areas. TOPSIS calculates distances between the considered alternatives and two predefined ones, namely the ideal and the anti-ideal, and creates a ranking of the alternatives according to a chosen aggregation of these distances. However, the interpretation of the inner workings of TOPSIS is difficult, especially when the number of criteria is large. To this end, recent research has shown that TOPSIS aggregations can be expressed using the means (M) and standard deviations (SD) of alternatives, creating MSD-space, a tool for visualizing and explaining aggregations. Even though MSD-space is highly useful, it assumes equally important criteria, making it less applicable to real-world ranking problems. In this paper, we generalize t
    
[^29]: 基于时间图序列预测的时态图结构学习

    Time-aware Graph Structure Learning via Sequence Prediction on Temporal Graphs. (arXiv:2306.07699v1 [cs.LG])

    [http://arxiv.org/abs/2306.07699](http://arxiv.org/abs/2306.07699)

    该论文提出了一种基于时间图序列预测的时态图结构学习方法，通过添加潜在的时间边来学习更好的图像结构，提高下游任务的性能。

    

    近年来，旨在模拟图像的传递性质的时间图学习变得越来越受关注并取得了显著的性能。然而，实际上，图像结构往往是不完整和嘈杂的，这阻碍了时间图网络（TGN）学习信息丰富的表示。为了解决这些问题，我们提出了一种基于时间图序列预测的时态图结构学习（TGSL）方法，通过添加潜在的时间边学习更好的图像结构，提高了下游任务的性能。

    Temporal Graph Learning, which aims to model the time-evolving nature of graphs, has gained increasing attention and achieved remarkable performance recently. However, in reality, graph structures are often incomplete and noisy, which hinders temporal graph networks (TGNs) from learning informative representations. Graph contrastive learning uses data augmentation to generate plausible variations of existing data and learn robust representations. However, rule-based augmentation approaches may be suboptimal as they lack learnability and fail to leverage rich information from downstream tasks. To address these issues, we propose a Time-aware Graph Structure Learning (TGSL) approach via sequence prediction on temporal graphs, which learns better graph structures for downstream tasks through adding potential temporal edges. In particular, it predicts time-aware context embedding based on previously observed interactions and uses the Gumble-Top-K to select the closest candidate edges to th
    
[^30]: StyleTTS 2：通过风格扩散和与大型语音语言模型的对抗训练实现人类级别的语音合成

    StyleTTS 2: Towards Human-Level Text-to-Speech through Style Diffusion and Adversarial Training with Large Speech Language Models. (arXiv:2306.07691v1 [eess.AS])

    [http://arxiv.org/abs/2306.07691](http://arxiv.org/abs/2306.07691)

    本文提出了一种名为StyleTTS 2的TTS模型，通过对抗训练和大型语音语言模型来实现人类级别的语音合成。与以往模型不同，StyleTTS 2将样式视为潜在随机变量，利用扩散模型来生成最适合文本的样式，同时受益于大型SLMs和新的可微分持续时间建模。

    

    本文提出了StyleTTS2，一种文本到语音（TTS）模型，该模型利用风格扩散和与大型语音语言模型（SLM）的对抗性训练来实现人类级别的TTS合成。 StyleTTS 2通过将样式建模为潜在的随机变量通过扩散模型来生成最适合文本的样式，无需参考语音，实现高效的潜在扩散，同时受益于扩散模型提供的多样化语音合成。此外，我们使用大型预先训练的SLMs（例如WavLM）作为鉴别器，并使用我们的新型可微分持续时间建模进行端到端的训练，从而提高了语音的自然度。 StyleTTS 2在单扬声器LJSpeech数据集上超越了人类录音，并在多扬声器VCTK数据集上与之匹配，经过母语为英语的人员评判。此外，当在LibriTTS数据集上进行训练时，我们的模型胜过了以前公开可用的零样本说话人语音合成模型。

    In this paper, we present StyleTTS 2, a text-to-speech (TTS) model that leverages style diffusion and adversarial training with large speech language models (SLMs) to achieve human-level TTS synthesis. StyleTTS 2 differs from its predecessor by modeling styles as a latent random variable through diffusion models to generate the most suitable style for the text without requiring reference speech, achieving efficient latent diffusion while benefiting from the diverse speech synthesis offered by diffusion models. Furthermore, we employ large pre-trained SLMs, such as WavLM, as discriminators with our novel differentiable duration modeling for end-to-end training, resulting in improved speech naturalness. StyleTTS 2 surpasses human recordings on the single-speaker LJSpeech dataset and matches it on the multispeaker VCTK dataset as judged by native English speakers. Moreover, when trained on the LibriTTS dataset, our model outperforms previous publicly available models for zero-shot speaker
    
[^31]: 面向高级持久性威胁的上下文感知防御的少样本多领域知识重装

    Few-shot Multi-domain Knowledge Rearming for Context-aware Defence against Advanced Persistent Threats. (arXiv:2306.07685v1 [cs.CR])

    [http://arxiv.org/abs/2306.07685](http://arxiv.org/abs/2306.07685)

    本文提出了一种针对高级持久性威胁的上下文感知防御的少样本、多领域知识重装 (FMKR) 方案，可以在不同的网络域生成多个小任务，完成多领域的知识重新装备，提高防御性能。

    

    高级持久性威胁(APTs)具有多阶段渗透、高度定制化意图和规避策略等新颖特征。APTs的防御需要融合多维网络威胁情报数据来识别攻击意图，并通过基于数据驱动的机器学习进行有效的知识发现策略以识别实体关系。然而，数据驱动的机器学习缺乏对新的或未知样本的泛化能力，降低了防御模型的准确性和实用性。此外，将这些APTs防御模型私有部署在异构环境中和各种网络设备上，需要在上下文感知方面进行重大投入（例如已知攻击实体、连续的网络状态和当前的安全策略）。本文提出了一种面向高级持久性威胁的上下文感知防御的少样本多领域知识重装(FMKR)方案。通过在不同网络域生成多个小任务，完成多领域知识重新装备，从而提升防御性能。

    Advanced persistent threats (APTs) have novel features such as multi-stage penetration, highly-tailored intention, and evasive tactics. APTs defense requires fusing multi-dimensional Cyber threat intelligence data to identify attack intentions and conducts efficient knowledge discovery strategies by data-driven machine learning to recognize entity relationships. However, data-driven machine learning lacks generalization ability on fresh or unknown samples, reducing the accuracy and practicality of the defense model. Besides, the private deployment of these APT defense models on heterogeneous environments and various network devices requires significant investment in context awareness (such as known attack entities, continuous network states, and current security strategies). In this paper, we propose a few-shot multi-domain knowledge rearming (FMKR) scheme for context-aware defense against APTs. By completing multiple small tasks that are generated from different network domains with m
    
[^32]: 论述模型与对话游戏的定时并发语言的交错语义

    An Interleaving Semantics of the Timed Concurrent Language for Argumentation to Model Debates and Dialogue Games. (arXiv:2306.07675v1 [cs.AI])

    [http://arxiv.org/abs/2306.07675](http://arxiv.org/abs/2306.07675)

    本文提出了一种基于定时抽象论证框架的定时并发语言，用于模拟代理之间的交互，并将代理的可接受性与给定时间间隔进行推理和通信，特别适用于模拟辩论和对话游戏的情境。

    

    时间是建模智能体动态行为的关键因素：活动在真实环境中具有确定的时间长度，并且先前的行为会影响智能体的行为。本文提出了一种语言，用于建模代理之间的并发交互，同时允许指定特定行为发生的时间间隔。这种语言利用定时的抽象论证框架实现代理使用的共享内存，以在给定时间间隔内通信和推理关于他们的信念的可接受性。在单个处理器上使用交错模型进行基本计算步骤，时隔最大并行性。按照这种方法，只有一个可用的代理在每个时刻被执行。为了展示这种语言的能力，我们还展示了如何使用它来模拟发生在智能代理之间的辩论和对话游戏等互动。

    Time is a crucial factor in modelling dynamic behaviours of intelligent agents: activities have a determined temporal duration in a real-world environment, and previous actions influence agents' behaviour. In this paper, we propose a language for modelling concurrent interaction between agents that also allows the specification of temporal intervals in which particular actions occur. Such a language exploits a timed version of Abstract Argumentation Frameworks to realise a shared memory used by the agents to communicate and reason on the acceptability of their beliefs with respect to a given time interval. An interleaving model on a single processor is used for basic computation steps, with maximum parallelism for time elapsing. Following this approach, only one of the enabled agents is executed at each moment. To demonstrate the capabilities of language, we also show how it can be used to model interactions such as debates and dialogue games taking place between intelligent agents. La
    
[^33]: 重新思考文本数据增强的有效性：一个经验分析

    Rethink the Effectiveness of Text Data Augmentation: An Empirical Analysis. (arXiv:2306.07664v1 [cs.CL])

    [http://arxiv.org/abs/2306.07664](http://arxiv.org/abs/2306.07664)

    本研究发现数据增强技术在语言模型的预训练及微调中仍具有显著的提升作用，尤其在少样本学习的情况下，持续的预训练可以提高微调性能10%以上。

    

    最近几年，语言模型在推进自然语言处理领域方面取得了显著进展。然而，数据增强技术对这些语言模型微调表现的影响一直是一个争论的话题。在本研究中，我们评估了三种不同的微调方法结合回译在7个不同的自然语言处理任务中的有效性，包括分类和回归类型，涵盖单句和句子对任务。与优先的假设相反，即数据增强对提高语言模型的微调表现没有贡献，我们的发现表明，持续在增强数据上进行预训练可以有效地改善下游任务的微调表现。在最有利的情况下，持续的预训练可以使微调性能在小样本学习设置下提高10%以上。我们的发现突显出数据增强作为增强语言模型性能的强大工具的潜力。

    In recent years, language models (LMs) have made remarkable progress in advancing the field of natural language processing (NLP). However, the impact of data augmentation (DA) techniques on the fine-tuning (FT) performance of these LMs has been a topic of ongoing debate. In this study, we evaluate the effectiveness of three different FT methods in conjugation with back-translation across an array of 7 diverse NLP tasks, including classification and regression types, covering single-sentence and sentence-pair tasks. Contrary to prior assumptions that DA does not contribute to the enhancement of LMs' FT performance, our findings reveal that continued pre-training on augmented data can effectively improve the FT performance of the downstream tasks. In the most favourable case, continued pre-training improves the performance of FT by more than 10% in the few-shot learning setting. Our finding highlights the potential of DA as a powerful tool for bolstering LMs' performance.
    
[^34]: 时间化本体中介查询的唯一可特征性和可学习性

    Temporalising Unique Characterisability and Learnability of Ontology-Mediated Queries. (arXiv:2306.07662v1 [cs.AI])

    [http://arxiv.org/abs/2306.07662](http://arxiv.org/abs/2306.07662)

    本文研究了在时间化本体中介查询中唯一可特征性和可学习性的问题，并提出了相应的传递结果。

    

    最近，通过示例来研究数据库查询的唯一可特征性和可学习性已经扩展到了本体中介查询。在这里，我们研究了获得的结果在多大程度上可以提升到时间化的本体中介查询。我们系统地介绍了非时间化情况下相关方法，然后展示了通用的传递结果，可以确定现有结果在何种条件下可以推广到时间化查询。

    Recently, the study of the unique characterisability and learnability of database queries by means of examples has been extended to ontology-mediated queries. Here, we study in how far the obtained results can be lifted to temporalised ontology-mediated queries. We provide a systematic introduction to the relevant approaches in the non-temporal case and then show general transfer results pinpointing under which conditions existing results can be lifted to temporalised queries.
    
[^35]: 关于使用非时间启发式方法指导HTN时态规划的研究

    On Guiding Search in HTN Temporal Planning with non Temporal Heuristics. (arXiv:2306.07638v1 [cs.AI])

    [http://arxiv.org/abs/2306.07638](http://arxiv.org/abs/2306.07638)

    本文提出了一种基于POCL方法的新型技术，用于解决时间HTN问题，并使用已有的非时间启发式方法来进行指导。

    

    层次任务网络（HTN）形式化语言被用于将各种规划问题表示为任务分解，并提出了许多解决它们的技术。然而，关于时态HTN问题的研究很少。这部分是因为缺乏时间层次规划问题的正式和一致的定义以及在这种情况下开发启发式方法的困难。为了应对这些不便，本文提出了一种新的基于部分有序因果链（POCL）的方法来表示和解决时间HTN问题，使用已开发的用于解决非时间问题的启发式方法。我们实验证明了这种方法具有高效性，并且可以胜过现有的方法。

    The Hierarchical Task Network (HTN) formalism is used to express a wide variety of planning problems as task decompositions, and many techniques have been proposed to solve them. However, few works have been done on temporal HTN. This is partly due to the lack of a formal and consensual definition of what a temporal hierarchical planning problem is as well as the difficulty to develop heuristics in this context. In response to these inconveniences, we propose in this paper a new general POCL (Partial Order Causal Link) approach to represent and solve a temporal HTN problem by using existing heuristics developed to solve non temporal problems. We show experimentally that this approach is performant and can outperform the existing ones.
    
[^36]: 利用MaxSAT求解器的配置

    Exploiting Configurations of MaxSAT Solvers. (arXiv:2306.07635v1 [cs.AI])

    [http://arxiv.org/abs/2306.07635](http://arxiv.org/abs/2306.07635)

    本文介绍了如何利用MaxSAT求解器的可替代参数配置，并通过实验证明了如何将一个非竞争性求解器的配置组合起来，实现更好的求解方法。

    

    本文介绍了如何有效地利用MaxSAT求解器的可替代参数配置，包括如何在MaxSAT上计算这些配置。特别地，我们进行了实验，展示了如何将一个非竞争性求解器的配置组合起来，实现更好的求解方法。

    In this paper, we describe how we can effectively exploit alternative parameter configurations to a MaxSAT solver. We describe how these configurations can be computed in the context of MaxSAT. In particular, we experimentally show how to easily combine configurations of a non-competitive solver to obtain a better solving approach.
    
[^37]: 语言模型中出现的类人直觉行为和推理偏差——以及在GPT-4中消失。

    Human-Like Intuitive Behavior and Reasoning Biases Emerged in Language Models -- and Disappeared in GPT-4. (arXiv:2306.07622v1 [cs.CL])

    [http://arxiv.org/abs/2306.07622](http://arxiv.org/abs/2306.07622)

    本研究揭示了大型语言模型（LLMs）具有类人直觉行为和认知错误的特点，而高级语言模型则通过学习避免这类错误并表现出超理性的方式。此外，通过使用心理学研究的方法探测LLMs，可以揭示其新生特性。

    

    大型语言模型（LLM）目前处于将AI系统与人类交流和日常生活交织在一起的前沿。因此，评估它们的新兴能力非常重要。在这项研究中，我们展示了LLM（尤其是GPT-3）表现出惊人的类人直觉行为，以及遵循这种行为而来的认知错误。然而，具有更高认知能力的LLM，特别是ChatGPT和GPT-4，学会了避免屈服于这些错误并表现出超理性的方式。对于我们的实验，我们利用了Cognitive Reflection Test（CRT）及用于研究人类直觉决策的语义幻觉。此外，我们还探究了类人直觉决策的稳定倾向。我们的研究表明，通过心理学方法调查LLM有潜力揭示否则未知的新生特性。

    Large language models (LLMs) are currently at the forefront of intertwining AI systems with human communication and everyday life. Therefore, it is of great importance to evaluate their emerging abilities. In this study, we show that LLMs, most notably GPT-3, exhibit behavior that strikingly resembles human-like intuition -- and the cognitive errors that come with it. However, LLMs with higher cognitive capabilities, in particular ChatGPT and GPT-4, learned to avoid succumbing to these errors and perform in a hyperrational manner. For our experiments, we probe LLMs with the Cognitive Reflection Test (CRT) as well as semantic illusions that were originally designed to investigate intuitive decision-making in humans. Moreover, we probe how sturdy the inclination for intuitive-like decision-making is. Our study demonstrates that investigating LLMs with methods from psychology has the potential to reveal otherwise unknown emergent traits.
    
[^38]: 基于双曲图扩散模型的分子生成

    Hyperbolic Graph Diffusion Model for Molecule Generation. (arXiv:2306.07618v1 [cs.LG])

    [http://arxiv.org/abs/2306.07618](http://arxiv.org/abs/2306.07618)

    本文提出了基于双曲图扩散模型的分子生成方法，可以更全面地捕捉分子的内部非欧几里德结构，实现数据生成，并提取复杂几何特征的能力。

    

    最近，扩散模型在数据生成方面取得了显著的成果，例如生成高质量的图像。然而，化学分子通常具有复杂的非欧几里德空间结构，其行为动态变化且难以预测。大多数现有的扩散模型高度依赖于计算欧几里德空间中的概率分布，即高斯分布，不能捕捉分子的内部非欧几里德结构，特别是分子所表示的隐式流形表面的分层结构。观察到，双曲嵌入空间中的复杂分层结构变得更加明显且更容易被捕捉。为了充分利用扩散模型的数据生成能力和提取复杂几何特征的双曲嵌入的强大能力，我们提出将扩散模型扩展到双曲流形上进行分子生成，即基于双曲图扩散模型的分子生成。

    Recently, diffusion models have achieved remarkable performance in data generation, e.g., generating high-quality images. Nevertheless, chemistry molecules often have complex non-Euclidean spatial structures, with the behavior changing dynamically and unpredictably. Most existing diffusion models highly rely on computing the probability distribution, i.e., Gaussian distribution, in Euclidean space, which cannot capture internal non-Euclidean structures of molecules, especially the hierarchical structures of the implicit manifold surface represented by molecules. It has been observed that the complex hierarchical structures in hyperbolic embedding space become more prominent and easier to be captured. In order to leverage both the data generation power of diffusion models and the strong capability to extract complex geometric features of hyperbolic embedding, we propose to extend the diffusion model to hyperbolic manifolds for molecule generation, namely, Hyperbolic Graph Diffusion Mode
    
[^39]: 寻找缺失的一半：面向同质和异质图的图互补学习

    Finding the Missing-half: Graph Complementary Learning for Homophily-prone and Heterophily-prone Graphs. (arXiv:2306.07608v1 [cs.SI])

    [http://arxiv.org/abs/2306.07608](http://arxiv.org/abs/2306.07608)

    该文章提出了GOAL框架来解决同质和异质图中缺失的一半结构信息的问题。

    

    实际应用中的图通常只有一种类型的连接，这些连接要么是同质性倾向的，要么是异质性倾向的。现有的GNN模型只使用原始图进行训练，但这样做会忽略关于缺失的一半结构信息-对于同质图来说，缺失的一半是异质性拓扑结构，对于异质图来说，缺失的是同质性拓扑结构。本文提出了图互补学习（GOAL）框架，包括图互补和互补图卷积两个组件。第一个组件用于寻找给定图的缺失部分的结构信息并进行互补。互补图包括两组图，包括原始图和互补图。

    Real-world graphs generally have only one kind of tendency in their connections. These connections are either homophily-prone or heterophily-prone. While graphs with homophily-prone edges tend to connect nodes with the same class (i.e., intra-class nodes), heterophily-prone edges tend to build relationships between nodes with different classes (i.e., inter-class nodes). Existing GNNs only take the original graph during training. The problem with this approach is that it forgets to take into consideration the ``missing-half" structural information, that is, heterophily-prone topology for homophily-prone graphs and homophily-prone topology for heterophily-prone graphs. In our paper, we introduce Graph cOmplementAry Learning, namely GOAL, which consists of two components: graph complementation and complemented graph convolution. The first component finds the missing-half structural information for a given graph to complement it. The complemented graph has two sets of graphs including both
    
[^40]: 通过去噪来实现粘贴、修补和协调：基于预训练扩散模型的主体驱动图像编辑

    Paste, Inpaint and Harmonize via Denoising: Subject-Driven Image Editing with Pre-Trained Diffusion Model. (arXiv:2306.07596v1 [cs.CV])

    [http://arxiv.org/abs/2306.07596](http://arxiv.org/abs/2306.07596)

    本文提出了一个名为PhD的图像编辑框架，使用一个示例图像和文本描述来指定用户意图。该框架包括粘贴、修补和协调步骤，可以将插入的主题无缝融入场景中。

    

    文本到图像生成模型因其可以通过用户指定的描述进行灵活的图像编辑而受到越来越多的关注。然而，仅有文本描述并不足以说明主题的细节，这经常会损害主题的身份或需要额外的针对主题的微调。我们引入了一个名为"通过去噪实现粘贴、修补和协调"（PhD）的新框架，该框架利用了除文本描述之外的示例图像来指定用户意图。在粘贴步骤中，使用现成的分割模型来识别示例图像中用户指定的主题，然后将其插入到背景图像中，作为同时捕捉场景上下文和主题身份的初始化。为了保证生成或编辑图像的视觉连贯性，我们引入修补和协调模块，指导预训练扩散模型将插入的主题自然地无缝地融入场景中。

    Text-to-image generative models have attracted rising attention for flexible image editing via user-specified descriptions. However, text descriptions alone are not enough to elaborate the details of subjects, often compromising the subjects' identity or requiring additional per-subject fine-tuning. We introduce a new framework called \textit{Paste, Inpaint and Harmonize via Denoising} (PhD), which leverages an exemplar image in addition to text descriptions to specify user intentions. In the pasting step, an off-the-shelf segmentation model is employed to identify a user-specified subject within an exemplar image which is subsequently inserted into a background image to serve as an initialization capturing both scene context and subject identity in one. To guarantee the visual coherence of the generated or edited image, we introduce an inpainting and harmonizing module to guide the pre-trained diffusion model to seamlessly blend the inserted subject into the scene naturally. As we kee
    
[^41]: Galactic: 将端到端强化学习扩展到每秒 100k 步的重组问题的规模化研究

    Galactic: Scaling End-to-End Reinforcement Learning for Rearrangement at 100k Steps-Per-Second. (arXiv:2306.07552v1 [cs.LG])

    [http://arxiv.org/abs/2306.07552](http://arxiv.org/abs/2306.07552)

    Galactic是一个针对室内物体重排问题的大规模仿真和强化学习框架。这个框架可以在每秒 100k 步上运行，比其他相似框架快很多。

    

    我们提出了 Galactic，一个用于室内环境中机器人移动操作的大规模仿真和强化学习（RL）框架。具体来说，我们在一个家用环境中生成 Fetch 机器人（带有移动基座、7 自由度机械臂、RGBD 相机、自运动和板载传感器），并要求它重新排列物体 - 通过导航到物体、拾取它、导航到目标位置，然后将物体放置在目标位置上。Galactic 速度快。在仿真速度（渲染+物理）方面，Galactic 在 8-GPU 节点上实现了每秒 421,000 步（SPS），比 Habitat 2.0 快了 54 倍（7699 SPS）。更重要的是，Galactic 被设计用于优化整个渲染+物理+RL 的相互作用，因为相互作用中的任何瓶颈都会减慢训练。在仿真+RL 速度（渲染+物理+推理+学习）方面，Galactic 实现了每秒超过 108,000 SPS，比 Habitat 2.0 快了 88 倍（1243 SPS）。这些巨大的加速不仅显著加快了训练速度，还使 RL 能够在未来的机器人操作任务中实现更高的成功率和效率。

    We present Galactic, a large-scale simulation and reinforcement-learning (RL) framework for robotic mobile manipulation in indoor environments. Specifically, a Fetch robot (equipped with a mobile base, 7DoF arm, RGBD camera, egomotion, and onboard sensing) is spawned in a home environment and asked to rearrange objects - by navigating to an object, picking it up, navigating to a target location, and then placing the object at the target location.  Galactic is fast. In terms of simulation speed (rendering + physics), Galactic achieves over 421,000 steps-per-second (SPS) on an 8-GPU node, which is 54x faster than Habitat 2.0 (7699 SPS). More importantly, Galactic was designed to optimize the entire rendering + physics + RL interplay since any bottleneck in the interplay slows down training. In terms of simulation+RL speed (rendering + physics + inference + learning), Galactic achieves over 108,000 SPS, which 88x faster than Habitat 2.0 (1243 SPS).  These massive speed-ups not only drasti
    
[^42]: 一个用于库存管理的多智能体强化学习通用基准

    A Versatile Multi-Agent Reinforcement Learning Benchmark for Inventory Management. (arXiv:2306.07542v1 [cs.AI])

    [http://arxiv.org/abs/2306.07542](http://arxiv.org/abs/2306.07542)

    该研究开发了一个用于库存管理的多智能体强化学习通用基准(MABIM)，以适用于实际工业场景中诸如复杂智能体交互等各种挑战，通过MABIM，该研究评估了传统的运筹学(OR)方法和流行的MARL算法的性能，以凸显其优缺点和潜力。

    

    多智能体强化学习 (MARL) 模型多个相互作用并在共享环境中学习的智能体。这种范式适用于自主驾驶、量化交易和库存管理等各种工业场景。然而，将 MARL 应用于这些实际情况受到许多挑战的阻碍，如扩大规模、复杂智能体交互和非稳态动态。为了激励研究者在这些挑战上研究 MARL，我们开发了多智能体库存管理基准 (MABIM)，它是一个多级、多商品的库存管理模拟器，可以生成不同具有这些不同的挑战性质的任务。基于 MABIM，我们评估了传统的运筹学 (OR) 方法和流行的 MARL 算法在这些具挑战性的任务上的表现，以突出它们的弱点和潜力。

    Multi-agent reinforcement learning (MARL) models multiple agents that interact and learn within a shared environment. This paradigm is applicable to various industrial scenarios such as autonomous driving, quantitative trading, and inventory management. However, applying MARL to these real-world scenarios is impeded by many challenges such as scaling up, complex agent interactions, and non-stationary dynamics. To incentivize the research of MARL on these challenges, we develop MABIM (Multi-Agent Benchmark for Inventory Management) which is a multi-echelon, multi-commodity inventory management simulator that can generate versatile tasks with these different challenging properties. Based on MABIM, we evaluate the performance of classic operations research (OR) methods and popular MARL algorithms on these challenging tasks to highlight their weaknesses and potential.
    
[^43]: 一种简单统一的基于不确定性引导的离线到在线强化学习框架

    A Simple Unified Uncertainty-Guided Framework for Offline-to-Online Reinforcement Learning. (arXiv:2306.07541v1 [cs.LG])

    [http://arxiv.org/abs/2306.07541](http://arxiv.org/abs/2306.07541)

    SUNG是一种基于不确定性引导的离线到在线强化学习框架，在通过量化不确定性进行探索和应用保守Q值估计的指导下，实现了高效的老化强化学习。

    

    离线强化学习为依靠数据驱动范例学习智能体提供了一种有前途的解决方案。 然而，受限于离线数据集的有限质量，其性能常常不够优秀。因此，在部署之前通过额外的在线交互进一步微调智能体是有必要的。不幸的是，由于受到两个主要挑战的制约，即受限的探索行为和状态-动作分布偏移，离线到在线强化学习可能具有挑战性。为此，我们提出了一个简单统一的基于不确定性引导的（SUNG）框架，其通过不确定性工具自然地统一了这两个挑战的解决方案。具体而言，SUNG通过基于VAE的状态-动作访问密度估计器量化不确定性。为了促进高效探索，SUNG提出了一种实用的乐观探索策略，以选择具有高价值和高不确定性的信息动作。此外，SUNG通过在不确定性指导下应用保守Q值估计来开发一种自适应利用方法。我们在Atari和MuJoCo基准测试上进行了全面的实验，结果表明SUNG始终优于最先进的离线到在线强化学习方法，并在许多任务中实现了接近在线学习的性能。

    Offline reinforcement learning (RL) provides a promising solution to learning an agent fully relying on a data-driven paradigm. However, constrained by the limited quality of the offline dataset, its performance is often sub-optimal. Therefore, it is desired to further finetune the agent via extra online interactions before deployment. Unfortunately, offline-to-online RL can be challenging due to two main challenges: constrained exploratory behavior and state-action distribution shift. To this end, we propose a Simple Unified uNcertainty-Guided (SUNG) framework, which naturally unifies the solution to both challenges with the tool of uncertainty. Specifically, SUNG quantifies uncertainty via a VAE-based state-action visitation density estimator. To facilitate efficient exploration, SUNG presents a practical optimistic exploration strategy to select informative actions with both high value and high uncertainty. Moreover, SUNG develops an adaptive exploitation method by applying conserva
    
[^44]: TART: 一种面向任务无关推理的即插即用Transformer模块

    TART: A plug-and-play Transformer module for task-agnostic reasoning. (arXiv:2306.07536v1 [cs.LG])

    [http://arxiv.org/abs/2306.07536](http://arxiv.org/abs/2306.07536)

    TART提出了一种即插即用的Transformer模块，它能够在没有任务特定训练或微调的情况下，在不同推理目标之间进行泛化。

    

    大型语言模型(LLMs)表现出上下文学习能力,能让同一模型执行多个任务,而无需进行任何特定任务的训练。相比之下,传统的自适应方法(如微调)会针对每个特定任务修改基础模型。然而,即使在使用相同示例的情况下,上下文学习一直表现不佳,而大多数现有方法(如提示工程)侧重于LLM的学习表示，以弥补性能差距,而我们的分析实际上揭示了LLM表示包含足够的信息来做出好的预测。因此,我们关注LLM的推理能力,并展示该性能差距存在是由于它们无法执行简单的概率推理任务。这引发了一个有趣的问题: LLM实际上能否以任务无关的方式学习如何推理？我们肯定地回答了这个问题,并提出了TART，它以即插即用的方式在不进行任务特定训练或微调的情况下横跨不同推理目标进行泛化。

    Large language models (LLMs) exhibit in-context learning abilities which enable the same model to perform several tasks without any task-specific training. In contrast, traditional adaptation approaches, such as fine-tuning, modify the underlying models for each specific task. In-context learning, however, consistently underperforms task-specific tuning approaches even when presented with the same examples. While most existing approaches (e.g., prompt engineering) focus on the LLM's learned representations to patch this performance gap, our analysis actually reveal that LLM representations contain sufficient information to make good predictions. As such, we focus on the LLM's reasoning abilities and demonstrate that this performance gap exists due to their inability to perform simple probabilistic reasoning tasks. This raises an intriguing question: Are LLMs actually capable of learning how to reason in a task-agnostic manner? We answer this in the affirmative and propose TART which ge
    
[^45]: 物理动态系统扩散模型中的用户定义事件采样和不确定性量化

    User-defined Event Sampling and Uncertainty Quantification in Diffusion Models for Physical Dynamical Systems. (arXiv:2306.07526v1 [cs.LG])

    [http://arxiv.org/abs/2306.07526](http://arxiv.org/abs/2306.07526)

    本文提出了一种条件得分函数的概率近似方案，可以用于混沌动力系统的预测和提供不确定性量化。

    

    扩散模型是一类概率生成模型，已广泛用作图像处理任务的先验，如文本条件生成和修复。我们证明这些模型可以适应于混沌动力系统的预测和提供不确定性量化。在这些应用中，扩散模型可以隐式表示关于异常值和极端事件的知识；但是，通过条件采样或测量概率来查询该知识却异常困难。现有的推理条件采样方法主要旨在强制执行约束条件，但这对于匹配分布的统计数据或计算选择事件的概率是不充分的。为了实现这些目标，最理想的方法是使用条件得分函数，但其计算通常是不可解的。在本研究中，我们开发了一种条件得分函数的概率近似方案，可以证明其收敛性。

    Diffusion models are a class of probabilistic generative models that have been widely used as a prior for image processing tasks like text conditional generation and inpainting. We demonstrate that these models can be adapted to make predictions and provide uncertainty quantification for chaotic dynamical systems. In these applications, diffusion models can implicitly represent knowledge about outliers and extreme events; however, querying that knowledge through conditional sampling or measuring probabilities is surprisingly difficult. Existing methods for conditional sampling at inference time seek mainly to enforce the constraints, which is insufficient to match the statistics of the distribution or compute the probability of the chosen events. To achieve these ends, optimally one would use the conditional score function, but its computation is typically intractable. In this work, we develop a probabilistic approximation scheme for the conditional score function which provably conver
    
[^46]: 基于碰撞动量的深度强化学习对抗行人建模

    Using Collision Momentum in Deep Reinforcement Learning Based Adversarial Pedestrian Modeling. (arXiv:2306.07525v1 [cs.RO])

    [http://arxiv.org/abs/2306.07525](http://arxiv.org/abs/2306.07525)

    该研究提出了一种基于碰撞动量的深度强化学习算法，能够更好地发现自动驾驶算法在极端情况下的缺陷并加以纠正。

    

    最近有关行人仿真的研究通常旨在开发各种情况下的现实行为，但现有算法生成识别自动驾驶车辆在极端和不可能情况下以及边缘情况下性能和缺陷的行为具有挑战性。为此，需要专门的行人行为算法。目前的研究侧重于使用社交力模型和基于强化学习的模型生成真实轨迹。然而，我们提出了一种针对碰撞的强化学习算法，更好地揭示了自动驾驶控制器的独特失效模式。我们的算法高效且生成更严重的碰撞，允许发现和纠正复杂和多样情景中自主驾驶算法的问题之处。

    Recent research in pedestrian simulation often aims to develop realistic behaviors in various situations, but it is challenging for existing algorithms to generate behaviors that identify weaknesses in automated vehicles' performance in extreme and unlikely scenarios and edge cases. To address this, specialized pedestrian behavior algorithms are needed. Current research focuses on realistic trajectories using social force models and reinforcement learning based models. However, we propose a reinforcement learning algorithm that specifically targets collisions and better uncovers unique failure modes of automated vehicle controllers. Our algorithm is efficient and generates more severe collisions, allowing for the identification and correction of weaknesses in autonomous driving algorithms in complex and varied scenarios.
    
[^47]: 自训练实现嘈杂正-无标记学习，在思辨性知识图谱推理中应用

    Noisy Positive-Unlabeled Learning with Self-Training for Speculative Knowledge Graph Reasoning. (arXiv:2306.07512v1 [cs.LG])

    [http://arxiv.org/abs/2306.07512](http://arxiv.org/abs/2306.07512)

    本文提出了一种嘈杂正-无标记学习问题的变分框架nPUGraph，并引入自训练策略，以应对真实世界知识图谱上的思辨性推理任务。实验结果表明了我们提出的方法的有效性。

    

    本文主要研究真实世界知识图谱（KG）上的思辨性推理任务，其中包括了假负问题（即潜在的真实事实被排除）和假正问题（即不可靠或过时的事实被包括）。现有的方法在思辨性推理能力上表现不佳，因为它们假设一个事实是否正确仅由它在KG中的存在确定，这使得它们容易受到假阴性/假阳性问题的影响。新的推理任务被规定为一种嘈杂正-无标记学习问题。我们提出了一种变分框架nPUGraph，它共同估计已收集和未收集事实的正确性（我们称之为“标签后验概率”），并在训练期间更新模型参数。标签后验概率估计从两个方面促进了思辨性推理。首先，它提高了标签后验概率感知的图表征对抗假阳性关系的鲁棒性。其次，它确定了误导性的未标记数据，并减少了其对模型训练的影响。我们还介绍了一种利用未标记数据的自训练策略，进一步提高了模型的推理能力。在两个知识图推理任务基准测试上的实验结果证明了我们提出的方法的有效性。

    This paper studies speculative reasoning task on real-world knowledge graphs (KG) that contain both \textit{false negative issue} (i.e., potential true facts being excluded) and \textit{false positive issue} (i.e., unreliable or outdated facts being included). State-of-the-art methods fall short in the speculative reasoning ability, as they assume the correctness of a fact is solely determined by its presence in KG, making them vulnerable to false negative/positive issues. The new reasoning task is formulated as a noisy Positive-Unlabeled learning problem. We propose a variational framework, namely nPUGraph, that jointly estimates the correctness of both collected and uncollected facts (which we call \textit{label posterior}) and updates model parameters during training. The label posterior estimation facilitates speculative reasoning from two perspectives. First, it improves the robustness of a label posterior-aware graph encoder against false positive links. Second, it identifies mis
    
[^48]: 在先进聊天机器人中添加护栏

    Adding guardrails to advanced chatbots. (arXiv:2306.07500v1 [cs.CY])

    [http://arxiv.org/abs/2306.07500](http://arxiv.org/abs/2306.07500)

    研究探讨了 ChatGPT 不同用例对于公平回答问题的能力，并发现它对于测试任务而言是公平的搜索引擎，但在文本生成和代码生成上有偏见，并且对于变化非常敏感。

    

    生成式 AI 模型不断变得更加强大。2022 年 11 月 ChatGPT 的推出迎来了 AI 的新时代。ChatGPT 和其他类似的聊天机器人具有一系列的能力，从回答学生家庭作业问题到创造音乐和艺术。已经有人担心 chatbot 可能会取代人类进行各种工作。由于聊天机器人构建在广泛的数据体系上，我们知道它们会带有人类错误和偏见。这些偏见可能对不同人群造成重大伤害和/或不公平。为了了解聊天机器人响应的优势和局限性，我们提出了一篇位论文，探讨了 ChatGPT 的不同用例，以确定公平回答的问题类型和仍然需要改进的类型。我们发现 ChatGPT 对于我们测试的任务而言是一个公平的搜索引擎；然而，在文本生成和代码生成上它存在偏见。我们发现 ChatGPT 对于变化非常敏感。

    Generative AI models continue to become more powerful. The launch of ChatGPT in November 2022 has ushered in a new era of AI. ChatGPT and other similar chatbots have a range of capabilities, from answering student homework questions to creating music and art. There are already concerns that humans may be replaced by chatbots for a variety of jobs. Because of the wide spectrum of data chatbots are built on, we know that they will have human errors and human biases built into them. These biases may cause significant harm and/or inequity toward different subpopulations. To understand the strengths and weakness of chatbot responses, we present a position paper that explores different use cases of ChatGPT to determine the types of questions that are answered fairly and the types that still need improvement. We find that ChatGPT is a fair search engine for the tasks we tested; however, it has biases on both text generation and code generation. We find that ChatGPT is very sensitive to change
    
[^49]: 通过标签错误检测和重写提高基于意见的问答系统

    Improving Opinion-based Question Answering Systems Through Label Error Detection and Overwrite. (arXiv:2306.07499v1 [cs.CL])

    [http://arxiv.org/abs/2306.07499](http://arxiv.org/abs/2306.07499)

    本文提出了一种名为LEDO的模型-不可知且计算高效的框架，能够有效解决标签错误问题，并将其应用于意见问答系统中，提高了该系统在各个核心模型中的准确性。

    

    标签错误是注释数据中普遍存在的问题。大量的标签错误会严重降低深度学习模型的质量。现有的解决标签错误问题的方法主要集中在分类任务上，要么依赖于任务特定的架构，要么需要非常复杂的额外计算，这些都不适合工业使用。在本文中，我们提出了LEDO：一种面向模型的、计算效率高的标签错误检测和重写框架。LEDO基于 Monte Carlo Dropout 和不确定性度量，可以很容易地推广到多个任务和数据集。将LEDO应用于工业意见问答系统中，证明它能有效提高所有核心模型的准确性。具体而言，LEDO为检索模型带来1.1％的MRR增益，为机器阅读理解模型提高1.5％的PR AUC，为排名器的平均精度提高0.9％。

    Label error is a ubiquitous problem in annotated data. Large amounts of label error substantially degrades the quality of deep learning models. Existing methods to tackle the label error problem largely focus on the classification task, and either rely on task specific architecture or require non-trivial additional computations, which is undesirable or even unattainable for industry usage. In this paper, we propose LEDO: a model-agnostic and computationally efficient framework for Label Error Detection and Overwrite. LEDO is based on Monte Carlo Dropout combined with uncertainty metrics, and can be easily generalized to multiple tasks and data sets. Applying LEDO to an industry opinion-based question answering system demonstrates it is effective at improving accuracy in all the core models. Specifically, LEDO brings 1.1% MRR gain for the retrieval model, 1.5% PR AUC improvement for the machine reading comprehension model, and 0.9% rise in the Average Precision for the ranker, on top of
    
[^50]: 基于预训练语言模型和基于停顿的韵律建模的自然语音合成

    PauseSpeech: Natural Speech Synthesis via Pre-trained Language Model and Pause-based Prosody Modeling. (arXiv:2306.07489v1 [eess.AS])

    [http://arxiv.org/abs/2306.07489](http://arxiv.org/abs/2306.07489)

    本文提出了一种使用预训练语言模型和基于停顿的韵律建模的语音合成系统，名为PauseSpeech。通过引入基于短语结构的编码器和基于停顿的单词编码器，有效地合成了具有适当短语结构的自然语音。

    

    尽管文本到语音（TTS）系统已经有了显著的进步，但大多数TTS系统仍然在合成具有适当短语结构的语音方面存在限制。为了进行自然语音合成，合成的语音需要以短语结构方式合成，该短语结构基于语义信息将单词分组。在本文中，我们提出了一种使用预训练语言模型和基于停顿的韵律建模的语音合成系统，名为 PauseSpeech。首先，我们引入一种基于短语结构的编码器，该编码器利用预训练语言模型的上下文表示。在短语结构编码器中，我们从上下文表示中提取了一个与说话者相关的句法表示，然后预测了一个停顿序列，将输入文本分成短语。此外，我们还引入了基于停顿的单词编码器，以根据停顿序列对单词级韵律进行建模。实验结果表明，PauseSpeech在自然性方面优于以前的模型。此外，在客观评估指标（例如MOS和WER）方面，我们提出的系统还与基线系统相比取得了更好的性能。

    Although text-to-speech (TTS) systems have significantly improved, most TTS systems still have limitations in synthesizing speech with appropriate phrasing. For natural speech synthesis, it is important to synthesize the speech with a phrasing structure that groups words into phrases based on semantic information. In this paper, we propose PuaseSpeech, a speech synthesis system with a pre-trained language model and pause-based prosody modeling. First, we introduce a phrasing structure encoder that utilizes a context representation from the pre-trained language model. In the phrasing structure encoder, we extract a speaker-dependent syntactic representation from the context representation and then predict a pause sequence that separates the input text into phrases. Furthermore, we introduce a pause-based word encoder to model word-level prosody based on pause sequence. Experimental results show PauseSpeech outperforms previous models in terms of naturalness. Furthermore, in terms of obj
    
[^51]: 恢复视觉Transformer的平移等变性

    Reviving Shift Equivariance in Vision Transformers. (arXiv:2306.07470v1 [cs.CV])

    [http://arxiv.org/abs/2306.07470](http://arxiv.org/abs/2306.07470)

    本文提出了一种自适应的多相位固定算法，可以无缝地集成到视觉Transformer模型中，以确保平移等变性，并介绍了一种基于补丁的适配器，以恢复位置编码的平移等变性。该方法在ImageNet-C和CLEVR-C等平移不变数据集上显著提高了ViT模型的性能。

    

    平移等变性是一种基本原理，它规定了我们如何感知世界-我们对对象的认知在平移方面保持不变。由于它们在语言和视觉任务中的有效性，Transformers变得非常流行。虽然ViT中的自注意力操作是置换等变且因此是平移等变的，但ViT变体中的补丁嵌入、位置编码和子采样注意力可能会破坏这种性质，从而导致即使在小的平移扰动下也会出现不一致的预测。虽然目前将卷积神经网络（CNNs）的归纳偏置融入到视觉Transformer中的趋势正在增长，但这并不能完全解决问题。我们提出了一个自适应的多相位固定算法，可以无缝地集成到视觉Transformer模型中，以确保在补丁嵌入和子采样注意力模块中保持变换等变性，例如窗口注意力和全局子采样注意力。此外，我们介绍了一种基于补丁的适配器，以恢复位置编码的平移等变性。我们的方法简单高效，并显著提高了ViT模型在平移不变数据集（如ImageNet-C和CLEVR-C）上的性能。

    Shift equivariance is a fundamental principle that governs how we perceive the world - our recognition of an object remains invariant with respect to shifts. Transformers have gained immense popularity due to their effectiveness in both language and vision tasks. While the self-attention operator in vision transformers (ViT) is permutation-equivariant and thus shift-equivariant, patch embedding, positional encoding, and subsampled attention in ViT variants can disrupt this property, resulting in inconsistent predictions even under small shift perturbations. Although there is a growing trend in incorporating the inductive bias of convolutional neural networks (CNNs) into vision transformers, it does not fully address the issue. We propose an adaptive polyphase anchoring algorithm that can be seamlessly integrated into vision transformer models to ensure shift-equivariance in patch embedding and subsampled attention modules, such as window attention and global subsampled attention. Furth
    
[^52]: 面向非平稳多智能体强化学习的黑盒方法

    A Black-box Approach for Non-stationary Multi-agent Reinforcement Learning. (arXiv:2306.07465v1 [cs.LG])

    [http://arxiv.org/abs/2306.07465](http://arxiv.org/abs/2306.07465)

    本文提出了一种通用的黑盒方法，适用于多种多智能体强化学习问题，可以在非平稳环境下实现低遗憾率的学习。

    

    本文研究了在非平稳多智能体系统中学习均衡的方法，并解决了区别于单智能体学习的挑战。我们重点关注带有赌徒反馈的游戏，其中即使待测试的差距很小，测试一个均衡也可能导致大量的遗憾，并且在静态游戏中存在多个最优解（均衡）会带来额外的难题。为了克服这些障碍，我们提出了一种通用的黑盒方法，适用于广泛的问题，如一般和博弈、潜在博弈和马尔可夫博弈，只要在静态环境下配备适当的学习和测试神谕。当非平稳程度（通过总变化量 $\Delta$ 测量）已知时，我们的算法可以实现 $\widetilde{O}\left(\Delta^{1/4}T^{3/4}\right)$ 的遗憾，当 $\Delta$ 未知时，可以实现 $\widetilde{O}\left(\Delta^{1/5}T^{4/5}\right)$ 的遗憾。

    We investigate learning the equilibria in non-stationary multi-agent systems and address the challenges that differentiate multi-agent learning from single-agent learning. Specifically, we focus on games with bandit feedback, where testing an equilibrium can result in substantial regret even when the gap to be tested is small, and the existence of multiple optimal solutions (equilibria) in stationary games poses extra challenges. To overcome these obstacles, we propose a versatile black-box approach applicable to a broad spectrum of problems, such as general-sum games, potential games, and Markov games, when equipped with appropriate learning and testing oracles for stationary environments. Our algorithms can achieve $\widetilde{O}\left(\Delta^{1/4}T^{3/4}\right)$ regret when the degree of nonstationarity, as measured by total variation $\Delta$, is known, and $\widetilde{O}\left(\Delta^{1/5}T^{4/5}\right)$ regret when $\Delta$ is unknown, where $T$ is the number of rounds. Meanwhile, 
    
[^53]: 解锁销售增长：具有可解释 AI 的账户优先级引擎

    Unlocking Sales Growth: Account Prioritization Engine with Explainable AI. (arXiv:2306.07464v1 [cs.AI])

    [http://arxiv.org/abs/2306.07464](http://arxiv.org/abs/2306.07464)

    论文开发了一款名为 Account Prioritizer 的智能销售账户优先级引擎，使用机器学习和解释算法自动化销售簿优化，在 LinkedIn Business 中成功带来了 +8.08% 的续订订阅增长。

    

    B2B 销售需要有效预测客户增长，识别升级潜力以及降低流失风险。LinkedIn 的销售代表传统上依赖直觉和碎片化数据信号来评估客户绩效。这导致在数据理解和策略制定方面投入了大量时间，而在积极销售方面投资不足。为了克服这一挑战，我们开发了一种数据产品，称为 Account Prioritizer，它是智能销售账户优先级引擎。它使用机器学习推荐模型和集成的账户级解释算法在销售 CRM 中自动化销售簿优化的手动过程。一次成功的 A/B 测试表明，Account Prioritizer 为 LinkedIn Business 带来了显著的 +8.08% 续订订阅增长。

    B2B sales requires effective prediction of customer growth, identification of upsell potential, and mitigation of churn risks. LinkedIn sales representatives traditionally relied on intuition and fragmented data signals to assess customer performance. This resulted in significant time investment in data understanding as well as strategy formulation and under-investment in active selling. To overcome this challenge, we developed a data product called Account Prioritizer, an intelligent sales account prioritization engine. It uses machine learning recommendation models and integrated account-level explanation algorithms within the sales CRM to automate the manual process of sales book prioritization. A successful A/B test demonstrated that the Account Prioritizer generated a substantial +8.08% increase in renewal bookings for the LinkedIn Business.
    
[^54]: 适用于人工决策辅助的智能干预方案：既考虑准确性又兼顾时间性

    Adaptive interventions for both accuracy and time in AI-assisted human decision making. (arXiv:2306.07458v1 [cs.HC])

    [http://arxiv.org/abs/2306.07458](http://arxiv.org/abs/2306.07458)

    本研究探索适用于人工决策辅助的智能干预方案，在同时考虑准确性和时间性的前提下，根据问题和用户的属性自适应地展示AI辅助具有良好的效果。

    

    在需要高准确性但同时时间又紧迫的环境下，例如在急诊室工作的医生，我们希望提供人工智能辅助，既能提高准确性又能减少时间。但是，不同类型的人工智能功能带来的好处是不同的：一些能够减少时间，但会增加对人工智能的过度依赖，而其他一些则相反。因此，我们希望根据问题和用户的各种属性（如知识水平）来自适应地展示人工智能辅助，以便在准确性和时间性之间做出最佳权衡。我们通过一个用户需要为外星人开药方的研究来探索自适应AI辅助的潜力。我们发现根据问题自适应AI辅助是有益的，可以达到时间和准确性的良好平衡。未来的研究将考虑使用机器学习算法（如强化学习）来实现快速自适应。

    In settings where users are both time-pressured and need high accuracy, such as doctors working in Emergency Rooms, we want to provide AI assistance that both increases accuracy and reduces time. However, different types of AI assistance have different benefits: some reduce time taken while increasing overreliance on AI, while others do the opposite. We therefore want to adapt what AI assistance we show depending on various properties (of the question and of the user) in order to best tradeoff our two objectives. We introduce a study where users have to prescribe medicines to aliens, and use it to explore the potential for adapting AI assistance. We find evidence that it is beneficial to adapt our AI assistance depending on the question, leading to good tradeoffs between time taken and accuracy. Future work would consider machine-learning algorithms (such as reinforcement learning) to automatically adapt quickly.
    
[^55]: 基于网络搜索记录的疫苗接种和疫苗持有者关注问题的准确测量

    Accurate Measures of Vaccination and Concerns of Vaccine Holdouts from Web Search Logs. (arXiv:2306.07457v1 [cs.CY])

    [http://arxiv.org/abs/2306.07457](http://arxiv.org/abs/2306.07457)

    研究发现，基于大规模搜索引擎日志和机器学习可以提供及时准确的疫苗意向和关注问题的数据，可以帮助设计有针对性的疫苗宣传教育活动，同时发现疫苗观望者搜索有关副作用和替代药物的信息，并表达对疫苗安全性和政府信誉的担忧。

    

    为了设计有效的疫苗政策，决策者需要详细的数据，了解谁接种了疫苗，谁没有接种，以及为什么。然而，美国现有的数据不足：报道的接种率常常延迟或缺失，接种犹豫调查受到高层次问题和自我报告偏见的限制。在这里，我们展示了大规模搜索引擎日志和机器学习如何利用这些数据来填补这些空白并提供有关疫苗意向和行为的新见解。首先，我们开发了一个疫苗意向分类器，可以准确地检测用户是否在搜索COVID-19疫苗。我们的分类器与CDC疫苗接种率具有很强的一致性，相关性超过0.86，并实时估算疫苗意向率到邮政编码级别，使我们能够精确定位不同地区、人口统计学和时间的疫苗需求趋势。为了调查疫苗犹豫，我们使用我们的分类器识别了两个群体，接种者和持观望态度者，并比较了它们的搜索行为。我们发现，疫苗观望者往往搜索有关副作用和替代药物的信息，并表达对疫苗安全性和政府信誉的担忧。相反，接种的个体倾向于搜索有关疫苗的新闻和疫苗可用性。我们的结果表明，利用搜索引擎日志可以提供及时准确的疫苗意向和关注问题的数据，这可以为有针对性的疫苗宣传教育活动的设计提供信息。

    To design effective vaccine policies, policymakers need detailed data about who has been vaccinated, who is holding out, and why. However, existing data in the US are insufficient: reported vaccination rates are often delayed or missing, and surveys of vaccine hesitancy are limited by high-level questions and self-report biases. Here, we show how large-scale search engine logs and machine learning can be leveraged to fill these gaps and provide novel insights about vaccine intentions and behaviors. First, we develop a vaccine intent classifier that can accurately detect when a user is seeking the COVID-19 vaccine on search. Our classifier demonstrates strong agreement with CDC vaccination rates, with correlations above 0.86, and estimates vaccine intent rates to the level of ZIP codes in real time, allowing us to pinpoint more granular trends in vaccine seeking across regions, demographics, and time. To investigate vaccine hesitancy, we use our classifier to identify two groups, vaccin
    
[^56]: 通过共创图画和互动解释CLIP

    Explaining CLIP through Co-Creative Drawings and Interaction. (arXiv:2306.07429v1 [cs.AI])

    [http://arxiv.org/abs/2306.07429](http://arxiv.org/abs/2306.07429)

    本文分析了一个由CLIP深度学习模型解析梦境并将其转化为图像的系统所产生的绘画存档，提出了四个分类以解释和描述CLIP生成的结果。本文关注于跨语言、符号系统和装置各模块之间的翻译过程和结果，展示了意想不到、视觉吸引人、梦境般的CLIP生成的结果。

    

    本文分析了一个视觉存档，其中包括由交互式机器人艺术装置产生的绘画，观众通过CLIPdraw深度学习模型，将自己的梦想讲述给一个解释和转换梦想的系统。文中讨论并聚类了这些图画，其中包括基于概念表述准确性的四个分类，以描述和解释CLIP生成的结果。本文强调语言、符号系统和装置各模块之间的翻译过程和结果，展示了由人工智能解释、中介和赋形的梦想集合，强调这个系统产生了意想不到、视觉吸引人、梦境般的输出。

    This paper analyses a visual archive of drawings produced by an interactive robotic art installation where audience members narrated their dreams into a system powered by CLIPdraw deep learning (DL) model that interpreted and transformed their dreams into images. The resulting archive of prompt-image pairs were examined and clustered based on concept representation accuracy. As a result of the analysis, the paper proposes four groupings for describing and explaining CLIP-generated results: clear concept, text-to-text as image, indeterminacy and confusion, and lost in translation. This article offers a glimpse into a collection of dreams interpreted, mediated and given form by Artificial Intelligence (AI), showcasing oftentimes unexpected, visually compelling or, indeed, the dream-like output of the system, with the emphasis on processes and results of translations between languages, sign-systems and various modules of the installation. In the end, the paper argues that proposed cluster
    
[^57]: DeepTransition：可行性导致步态转换的出现

    DeepTransition: Viability Leads to the Emergence of Gait Transitions in Learning Anticipatory Quadrupedal Locomotion Skills. (arXiv:2306.07419v1 [cs.RO])

    [http://arxiv.org/abs/2306.07419](http://arxiv.org/abs/2306.07419)

    本文通过深度强化学习和机器人工具的互动研究，证明了可行性是四足动物步态转换的重要标准。其中，步-小跑步态转换能够在平坦地形上同时提高可行性和节能效果。

    

    四足动物在改变运动速度时能够无缝地转换步态。本文提出可行性（即避免跌倒）代表步态转换的一个重要标准。通过利用深度强化学习和机器人工具，我们研究了步态转换的出现。一致于四足动物数据，我们证明了在平坦地形上，四足机器人的步-小跑步态转换能同时提高可行性和节能效果。此外，我们研究了离散地形（即穿越连续间隔）对强制步态转换的影响，并找到足-蹦步态的出现。

    Quadruped animals seamlessly transition between gaits as they change locomotion speeds. While the most widely accepted explanation for gait transitions is energy efficiency, there is no clear consensus on the determining factor, nor on the potential effects from terrain properties. In this article, we propose that viability, i.e. the avoidance of falls, represents an important criterion for gait transitions. We investigate the emergence of gait transitions through the interaction between supraspinal drive (brain), the central pattern generator in the spinal cord, the body, and exteroceptive sensing by leveraging deep reinforcement learning and robotics tools. Consistent with quadruped animal data, we show that the walk-trot gait transition for quadruped robots on flat terrain improves both viability and energy efficiency. Furthermore, we investigate the effects of discrete terrain (i.e. crossing successive gaps) on imposing gait transitions, and find the emergence of trot-pronk transit
    
[^58]: 突触缩放和最优偏置调整在神经形态系统功耗降低中的应用

    Synaptic Scaling and Optimal Bias Adjustments for Power Reduction in Neuromorphic Systems. (arXiv:2306.07416v1 [cs.NE])

    [http://arxiv.org/abs/2306.07416](http://arxiv.org/abs/2306.07416)

    本文探讨了将类似动物大脑在食物匮乏时的低功耗机制应用于神经形态系统中，通过缩放突触权值可以显著降低功耗（在某些情况下可降低80％以上），同时对准确性影响较小。这为设计用于边缘人工智能应用的神经形态系统提供了令人兴奋的机会。

    

    最近的动物实验已经显示出生物大脑在食物匮乏时可以进入低功耗模式。本文探讨了将类似机制应用于一类强烈依赖于突触权值大小的神经形态系统中的可能性。具体而言，我们通过数学模型和仿真表明，仔细缩放突触权值可以显著减少功耗（在某些情况下可降低80％以上），同时对准确性影响较小。这些结果揭示了一种令人兴奋的机会，即设计用于边缘人工智能应用的神经形态系统，其中功耗可以根据能量供应和性能要求进行动态调整。

    Recent animal studies have shown that biological brains can enter a low power mode in times of food scarcity. This paper explores the possibility of applying similar mechanisms to a broad class of neuromorphic systems where power consumption is strongly dependent on the magnitude of synaptic weights. In particular, we show through mathematical models and simulations that careful scaling of synaptic weights can significantly reduce power consumption (by over 80\% in some of the cases tested) while having a relatively small impact on accuracy. These results uncover an exciting opportunity to design neuromorphic systems for edge AI applications, where power consumption can be dynamically adjusted based on energy availability and performance requirements.
    
[^59]: 大型语言模型的经济权衡：以案例研究为例

    The economic trade-offs of large language models: A case study. (arXiv:2306.07402v1 [cs.CL])

    [http://arxiv.org/abs/2306.07402](http://arxiv.org/abs/2306.07402)

    本研究通过一个案例研究，以评估大型语言模型在企业中为类似客户服务的场景所带来的成本和效益。从该品牌客户服务代理的反馈中比较了三种专门化LLM的策略-提示工程、微调和知识蒸馏，发现模型响应的可用性可以弥补成本差异。

    

    通过聊天联系客户服务是一种常见做法。由于雇用客服代理商是昂贵的，许多公司正在转向NLP，通过自动生成可直接使用或修改的响应来协助人类代理商。大型语言模型（LLMs）是这种情况的自然选择；然而，它们的功效必须与训练和服务成本相平衡。本文评估了LLMs在企业中作为响应生成工具可实现的实际成本和影响。我们提出了一个成本框架，用于评估NLP模型在这种情况下的效用，并将其应用于单个品牌作为现有代理协助产品背景下的案例研究。我们使用品牌客户服务代理的反馈比较了三种专门化LLM的策略-提示工程、微调和知识蒸馏。我们发现，模型响应的可用性可以弥补巨大的成本差异。

    Contacting customer service via chat is a common practice. Because employing customer service agents is expensive, many companies are turning to NLP that assists human agents by auto-generating responses that can be used directly or with modifications. Large Language Models (LLMs) are a natural fit for this use case; however, their efficacy must be balanced with the cost of training and serving them. This paper assesses the practical cost and impact of LLMs for the enterprise as a function of the usefulness of the responses that they generate. We present a cost framework for evaluating an NLP model's utility for this use case and apply it to a single brand as a case study in the context of an existing agent assistance product. We compare three strategies for specializing an LLM - prompt engineering, fine-tuning, and knowledge distillation - using feedback from the brand's customer service agents. We find that the usability of a model's responses can make up for a large difference in in
    
[^60]: 实现BERT和微调RobertA来检测ChatGPT生成的人工智能新闻

    Implementing BERT and fine-tuned RobertA to detect AI generated news by ChatGPT. (arXiv:2306.07401v1 [cs.CL])

    [http://arxiv.org/abs/2306.07401](http://arxiv.org/abs/2306.07401)

    使用BERT和微调的RobertA模型可以最好地检测ChatGPT生成的AI新闻。 RobertA模型在精度方面表现出色，取得了98％的得分。这些模型可以在打击假新闻中发挥关键作用。

    

    社交媒体上信息的丰富增加了准确实时谣言检测的必要性。手动识别和验证AI工具生成的假新闻在巨大的信息量每天被生成的情况下是不切实际和耗时的。这引发了对创建自动化系统以找到互联网上假新闻的兴趣增加。本研究表明，经微调的BERT和RobertA模型在检测AI生成的新闻方面取得了最佳成功率。特别是微调过的RobertA在精度方面表现出色，得分为98％。总之，本研究表明，可以使用神经网络来识别ChatGPT生成的伪造新闻。RobertA和BERT模型的出色表现表明这些模型在与假信息作斗争中可以发挥关键作用。

    The abundance of information on social media has increased the necessity of accurate real-time rumour detection. Manual techniques of identifying and verifying fake news generated by AI tools are impracticable and time-consuming given the enormous volume of information generated every day. This has sparked an increase in interest in creating automated systems to find fake news on the Internet. The studies in this research demonstrate that the BERT and RobertA models with fine-tuning had the best success in detecting AI generated news. With a score of 98%, tweaked RobertA in particular showed excellent precision. In conclusion, this study has shown that neural networks can be used to identify bogus news AI generation news created by ChatGPT. The RobertA and BERT models' excellent performance indicates that these models can play a critical role in the fight against misinformation.
    
[^61]: 语言模型在非英语内容分析中的应用问题

    Lost in Translation: Large Language Models in Non-English Content Analysis. (arXiv:2306.07377v1 [cs.CL])

    [http://arxiv.org/abs/2306.07377](http://arxiv.org/abs/2306.07377)

    大型语言模型目前主要运用于英语内容的智能分析中，多语言模型的发展旨在弥补其他语言数据匮乏的情况。研究人员和技术公司通过构建多语言语言模型尝试解决这一问题并拓展大型语言模型的能力。多语言模型在低资源语言应用中的实践效果也进行研究。总体而言，AI支持的语言技术的设计和部署需要注意权力、不平等和文化差异。

    

    近年来，大型语言模型（例如Open AI的GPT-4，Meta的LLaMa，Google的PaLM）已成为构建在线语言智能分析和生成AI系统的主要方法。然而，越来越多的自动化系统中介我们在网上的交互，例如聊天机器人，内容审核系统和搜索引擎，主要是为英语而设计的，而在其他世界上的7000种语言中的效果远远不如英语。近期，研究人员和技术公司试图通过构建多语言语言模型来扩展大型语言模型的能力。本文将解释这些多语言模型的工作方式以及探索它们的能力和局限性。其中，第一部分提供了关于大型语言模型的简单技术解释，英语和其他语言之间可用数据的差距以及多语言语言模型如何试图弥合这一差距。第二部分回顾了最近的研究，探索了多语言模型在实践中的有效性，包括低资源语言应用的案例研究。最后，我们考虑了AI支持的语言技术在世界上许多语言中的传播的伦理学意义，并强调在设计和部署AI系统时需要特别注意权力、不平等和文化差异等问题。

    In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa, Google's PaLM) have become the dominant approach for building AI systems to analyze and generate language online. However, the automated systems that increasingly mediate our interactions online -- such as chatbots, content moderation systems, and search engines -- are primarily designed for and work far more effectively in English than in the world's other 7,000 languages. Recently, researchers and technology companies have attempted to extend the capabilities of large language models into languages other than English by building what are called multilingual language models.  In this paper, we explain how these multilingual language models work and explore their capabilities and limits. Part I provides a simple technical explanation of how large language models work, why there is a gap in available data between English and other languages, and how multilingual language models attempt to bridge that gap. Part 
    
[^62]: 为策略选择构建高效、健壮的测试

    Composing Efficient, Robust Tests for Policy Selection. (arXiv:2306.07372v1 [cs.LG])

    [http://arxiv.org/abs/2306.07372](http://arxiv.org/abs/2306.07372)

    该论文提出了一种名为RPOSST的算法，它可以从较大的测试案例池中选择一小部分测试样例，验证其高质量的策略在更广泛的环境下也是可靠的。

    

    现代强化学习系统在学习过程中会产生许多高质量的策略。然而，在实际应用中选择哪种策略时，它们必须在不可解的大量环境条件下进行测试。我们介绍了一种算法RPOSST，它能够从较大的测试案例池中选择一小部分测试样例，这是根据相对较小的样本评估来实现的。RPOSST将测试样例选择问题视为一个双人博弈，并优化具有可证明的k-of-N健壮性的解决方案，以限制相对于使用池中所有测试用例的测试的误差。实证结果表明，RPOSST能够在一个玩具单一游戏、扑克数据集和高保真赛车模拟器中发现可以识别高质量策略的一小组测试用例。

    Modern reinforcement learning systems produce many high-quality policies throughout the learning process. However, to choose which policy to actually deploy in the real world, they must be tested under an intractable number of environmental conditions. We introduce RPOSST, an algorithm to select a small set of test cases from a larger pool based on a relatively small number of sample evaluations. RPOSST treats the test case selection problem as a two-player game and optimizes a solution with provable $k$-of-$N$ robustness, bounding the error relative to a test that used all the test cases in the pool. Empirical results demonstrate that RPOSST finds a small set of test cases that identify high quality policies in a toy one-shot game, poker datasets, and a high-fidelity racing simulator.
    
[^63]: HDDL 2.1：面向时间HTN规划的形式化和语义定义

    HDDL 2.1: Towards Defining a Formalism and a Semantics for Temporal HTN Planning. (arXiv:2306.07353v1 [cs.AI])

    [http://arxiv.org/abs/2306.07353](http://arxiv.org/abs/2306.07353)

    本文介绍了HDDL 2.1的形式化和语义定义，旨在通过从PDDL 2.1中汲取灵感，弥补HDDL不能表示数字和时间约束的不足。

    

    工业和机器人等现实世界应用需要建模丰富多样的自动化规划问题。它们的解决通常需要协调和并行执行。在多个情况下，这些问题自然地以分层任务网络（HTN）形式进行分解和表达。 HDDL是规划域定义语言（PDDL）的分层扩展，与PDDL 2.1不同，它不允许表示带有数值和时间约束的计划问题，这对于现实世界应用至关重要。我们建议弥补HDDL与这些操作需求之间的差距，并从PDDL 2.1中汲取灵感，扩展HDDL以表示数字和时间表达式。本文开展了关于未来HDDL 2.1扩展所需的语义和语法的讨论。

    Real world applications as in industry and robotics need modelling rich and diverse automated planning problems. Their resolution usually requires coordinated and concurrent action execution. In several cases, these problems are naturally decomposed in a hierarchical way and expressed by a Hierarchical Task Network (HTN) formalism.  HDDL, a hierarchical extension of the Planning Domain Definition Language (PDDL), unlike PDDL 2.1 does not allow to represent planning problems with numerical and temporal constraints, which are essential for real world applications. We propose to fill the gap between HDDL and these operational needs and to extend HDDL by taking inspiration from PDDL 2.1 in order to express numerical and temporal expressions. This paper opens discussions on the semantics and the syntax needed for a future HDDL 2.1 extension.
    
[^64]: ATT3D：摊销的文本到三维物体合成

    ATT3D: Amortized Text-to-3D Object Synthesis. (arXiv:2306.07349v1 [cs.LG])

    [http://arxiv.org/abs/2306.07349](http://arxiv.org/abs/2306.07349)

    该论文提出了一种“摊销”的文本到三维物体合成方法，将许多提示一起使用一个统一的模型进行训练，共享提示之间的优化计算，从而在更短时间内训练模型；该方法能够使不同提示之间进行平滑的插值，并在新的资产和简单动画之间实现知识共享和推广。

    

    将生成式文本到图像模型与图像到三维方法（如神经辐射场）相结合，文本至三维建模取得了令人兴奋的进展。 DreamFusion 最近取得了高质量的结果，但需要进行漫长的、基于提示的优化才能创建三维物体。为了解决这个问题，我们通过使用统一的模型同时训练许多提示来摊销提示优化，而不是单独训练每个提示。通过这种方式，我们可以在提示集合中共享计算，比每个提示的优化所需的时间更短。我们的框架-Amortized text-to-3D (ATT3D)-实现了提示之间的知识共享，以便推广到未见过的设置，并为新资产和简单动画之间的文本进行平滑的插值。

    Text-to-3D modelling has seen exciting progress by combining generative text-to-image models with image-to-3D methods like Neural Radiance Fields. DreamFusion recently achieved high-quality results but requires a lengthy, per-prompt optimization to create 3D objects. To address this, we amortize optimization over text prompts by training on many prompts simultaneously with a unified model, instead of separately. With this, we share computation across a prompt set, training in less time than per-prompt optimization. Our framework - Amortized text-to-3D (ATT3D) - enables knowledge-sharing between prompts to generalize to unseen setups and smooth interpolations between text for novel assets and simple animations.
    
[^65]: 学习用于视觉Transformer预训练的掩码和置换视觉令牌。

    Learning to Mask and Permute Visual Tokens for Vision Transformer Pre-Training. (arXiv:2306.07346v1 [cs.CV])

    [http://arxiv.org/abs/2306.07346](http://arxiv.org/abs/2306.07346)

    本论文提出了一种新的自监督预训练方法MaPeT，不同于现有的使用掩码图像模型的方法，该方法使用自回归和置换预测来捕获图像块内的依赖关系并减少数据噪声的影响，从而提高了下游任务的一致性。

    

    使用自监督预训练技术已成为提高图像分类等视觉任务性能的有前途的方法。最近的方法使用掩码图像模型范式，通过重构与随机掩码图像块相关联的视觉令牌来预训练骨干网络。然而，这种掩蔽方法会在预训练过程中引入噪声进入输入数据，导致性能下降。此外，输入掩蔽忽略了受损块之间的依赖关系，增加了下游微调任务中观察到的不一致性。为了解决这些问题，我们提出了一种新的自监督预训练方法，名为掩蔽和置换视觉变压器（MaPeT），它使用自回归和置换预测来捕获块内依赖性。此外，MaPeT使用辅助位置信息来减少预训练和微调阶段中的差异性。

    The use of self-supervised pre-training has emerged as a promising approach to enhance the performance of visual tasks such as image classification. In this context, recent approaches have employed the Masked Image Modeling paradigm, which pre-trains a backbone by reconstructing visual tokens associated with randomly masked image patches. This masking approach, however, introduces noise into the input data during pre-training, leading to discrepancies that can impair performance during the fine-tuning phase. Furthermore, input masking neglects the dependencies between corrupted patches, increasing the inconsistencies observed in downstream fine-tuning tasks. To overcome these issues, we propose a new self-supervised pre-training approach, named Masked and Permuted Vision Transformer (MaPeT), that employs autoregressive and permuted predictions to capture intra-patch dependencies. In addition, MaPeT employs auxiliary positional information to reduce the disparity between the pre-trainin
    
[^66]: 应用众包技术丰富高等教育音乐知识库的方法和经验

    Employing Crowdsourcing for Enriching a Music Knowledge Base in Higher Education. (arXiv:2306.07310v1 [cs.HC])

    [http://arxiv.org/abs/2306.07310](http://arxiv.org/abs/2306.07310)

    本研究探讨了一项使用众包技术的计算机科学高等教育作业，鼓励学生丰富音乐元数据，并创建了可供机器学习模型用于音乐标记的开放性注释数据集。

    

    本文描述了一项使用众包技术作为计算机科学高等教育学生作业的方法和经验。利用支持文化遗产领域众包的平台，鼓励学生丰富与选定音乐曲目相关的元数据。该活动共有98名学生参加，为854首音乐曲目贡献了6400多个注释。同时还创建了一个可供机器学习模型用于音乐标记的开放性注释数据集。通过在线调查，该活动的结果和意见收集使我们能够得出一些有用的见解，了解将众包整合到计算机科学课程中的益处和挑战以及如何提高学生的学习体验。

    This paper describes the methodology followed and the lessons learned from employing crowdsourcing techniques as part of a homework assignment involving higher education students of computer science. Making use of a platform that supports crowdsourcing in the cultural heritage domain students were solicited to enrich the metadata associated with a selection of music tracks. The results of the campaign were further analyzed and exploited by students through the use of semantic web technologies. In total, 98 students participated in the campaign, contributing more than 6400 annotations concerning 854 tracks. The process also led to the creation of an openly available annotated dataset, which can be useful for machine learning models for music tagging. The campaign's results and the comments gathered through an online survey enable us to draw some useful insights about the benefits and challenges of integrating crowdsourcing into computer science curricula and how this can enhance student
    
[^67]: 少样本策略迁移的在线原型对齐

    Online Prototype Alignment for Few-shot Policy Transfer. (arXiv:2306.07307v1 [cs.LG])

    [http://arxiv.org/abs/2306.07307](http://arxiv.org/abs/2306.07307)

    本文提出了一种基于元素功能相似性的在线原型对齐（OPA）框架，能够在少样本的情况下实现策略转移，解决了传统方法映射函数学习需要大量数据以及依赖视觉特征等问题。

    

    强化学习中的领域适应主要涉及在将策略转移到新环境时观察的变化。领域适应的许多传统方法以显式或隐式地学习源域和目标域之间的映射函数为主。然而，它们通常需要访问目标域的大量数据。此外，它们常常依赖于视觉线索来学习映射函数，当源域与目标域看起来非常不同时，可能会失败。为解决这些问题，我们提出了一个新的框架在线原型对齐（OPA），该框架基于元素的功能相似性来学习映射函数，能够在仅几个回合内实现少样本策略转移。OPA的关键见解是引入一个探索机制，可以高效、有目的地与目标域的未知元素交互，并将它们与已知的元素连接起来。

    Domain adaptation in reinforcement learning (RL) mainly deals with the changes of observation when transferring the policy to a new environment. Many traditional approaches of domain adaptation in RL manage to learn a mapping function between the source and target domain in explicit or implicit ways. However, they typically require access to abundant data from the target domain. Besides, they often rely on visual clues to learn the mapping function and may fail when the source domain looks quite different from the target domain. To address these problems, we propose a novel framework Online Prototype Alignment (OPA) to learn the mapping function based on the functional similarity of elements and is able to achieve the few-shot policy transfer within only several episodes. The key insight of OPA is to introduce an exploration mechanism that can interact with the unseen elements of the target domain in an efficient and purposeful manner, and then connect them with the seen elements in th
    
[^68]: 基于类别关联嵌入和循环对抗生成的医学图像全局可解释学习

    Active Globally Explainable Learning for Medical Images via Class Association Embedding and Cyclic Adversarial Generation. (arXiv:2306.07306v1 [cs.CV])

    [http://arxiv.org/abs/2306.07306](http://arxiv.org/abs/2306.07306)

    本文提出了一种类别关联嵌入（CAE）方法，采用编码器-解码器结构将样本特征分离成与类别相关的风格向量，实现了医学图像全局可解释的学习。

    

    可解释性是人工智能技术面临的主要挑战。当前关于可解释人工智能（XAI）的研究缺乏提取关于学习任务的全局知识的效率，因此存在精度不确定、缺乏上下文信息和定义模糊等缺陷。本文提出了类别关联嵌入（CAE）方法来解决这些问题。我们采用编码器-解码器结构，同时将样本特征分离成与类别相关的和个体相关的风格向量。将给定样本的个体风格码与另一个类别风格码重新组合，按照循环对抗学习策略得到一个保留个体特征但改变了类别指定的合成样本。类别关联嵌入将所有实例的全局类相关特征提炼到一个统一的域中，不同类之间的转换规则可以更好地提取和可视化，以获得更好的透明度。我们在医学图像数据集上进行实验，比现有技术获得更优异的性能，并提供全局可解释的可视化结果以便于诊断过程。

    Explainability poses a major challenge to artificial intelligence (AI) techniques. Current studies on explainable AI (XAI) lack the efficiency of extracting global knowledge about the learning task, thus suffer deficiencies such as imprecise saliency, context-aware absence and vague meaning. In this paper, we propose the class association embedding (CAE) approach to address these issues. We employ an encoder-decoder architecture to embed sample features and separate them into class-related and individual-related style vectors simultaneously. Recombining the individual-style code of a given sample with the class-style code of another leads to a synthetic sample with preserved individual characters but changed class assignment, following a cyclic adversarial learning strategy. Class association embedding distills the global class-related features of all instances into a unified domain with well separation between classes. The transition rules between different classes can be then extract
    
[^69]: 让预测变得自学习和自适应--试点预测架构。

    Making forecasting self-learning and adaptive -- Pilot forecasting rack. (arXiv:2306.07305v1 [cs.LG])

    [http://arxiv.org/abs/2306.07305](http://arxiv.org/abs/2306.07305)

    本文提出了通过使用试点预测架构中的算法干预来提高非AI模型下针织品类别的预测准确性。在决策模型中动态地选择最佳算法可提高预测准确性，并通过AI / ML预测模型使用先进的特征工程来实现。

    

    零售销售和价格预测通常基于时间序列预测。对于某些产品类别，预测需求的准确性较低，会对库存、运输和补货计划造成负面影响。本文介绍了我们基于积极探索的试点演练的发现，以探索帮助零售商提高此类产品类别的预测准确性的方法。我们评估了通过一个样本产品类别“针织品”提高预测准确性的算法干预机会。目前，针织品产品类别的预测准确度在非AI模型中的范围为60%。我们探索了如何使用架构方法提高预测准确性。为了生成预测结果，我们的决策模型根据给定状态和上下文动态地从算法架中选择最佳算法。使用先进的特征工程构建的AI / ML预测模型的结果显示，需求预测的准确性有所提高。

    Retail sales and price projections are typically based on time series forecasting. For some product categories, the accuracy of demand forecasts achieved is low, negatively impacting inventory, transport, and replenishment planning. This paper presents our findings based on a proactive pilot exercise to explore ways to help retailers to improve forecast accuracy for such product categories.  We evaluated opportunities for algorithmic interventions to improve forecast accuracy based on a sample product category, Knitwear. The Knitwear product category has a current demand forecast accuracy from non-AI models in the range of 60%. We explored how to improve the forecast accuracy using a rack approach. To generate forecasts, our decision model dynamically selects the best algorithm from an algorithm rack based on performance for a given state and context. Outcomes from our AI/ML forecasting model built using advanced feature engineering show an increase in the accuracy of demand forecast f
    
[^70]: 一种统一自动概念提取和概念重要性评估的全面方法

    A Holistic Approach to Unifying Automatic Concept Extraction and Concept Importance Estimation. (arXiv:2306.07304v1 [cs.LG])

    [http://arxiv.org/abs/2306.07304](http://arxiv.org/abs/2306.07304)

    本文提出了一个全面的理论框架，来统一定义和澄清自动概念提取和概念重要性评估，进而提供新的评估指标以实现对这些方法的比较以及推导关于这种方法的最优性的理论保证。

    

    近年来，基于概念的方法成为了一些最有前途的可解释方法，帮助我们解释人工神经网络（ANN）的决策。这些方法试图在两个关键步骤中发现被隐藏在ANN激活的复杂模式中的可理解的视觉“概念”：（1）概念提取，（2）重要性评估。虽然这两个步骤是各种方法之间共同的，但它们的具体实现都有所不同。在这里，我们介绍了一个统一的理论框架，全面定义和澄清了这两个步骤。该框架具有几个优点，它允许我们：（i）提出新的评估指标来比较不同的概念提取方法；（ii）利用现代归因方法和评估指标来扩展和系统地评估最先进的基于概念的方法和重要性评估技术；（iii）推导关于这种方法的最优性的理论保证。

    In recent years, concept-based approaches have emerged as some of the most promising explainability methods to help us interpret the decisions of Artificial Neural Networks (ANNs). These methods seek to discover intelligible visual 'concepts' buried within the complex patterns of ANN activations in two key steps: (1) concept extraction followed by (2) importance estimation. While these two steps are shared across methods, they all differ in their specific implementations. Here, we introduce a unifying theoretical framework that comprehensively defines and clarifies these two steps. This framework offers several advantages as it allows us: (i) to propose new evaluation metrics for comparing different concept extraction approaches; (ii) to leverage modern attribution methods and evaluation metrics to extend and systematically evaluate state-of-the-art concept-based approaches and importance estimation techniques; (iii) to derive theoretical guarantees regarding the optimality of such met
    
[^71]: 教学代理人的应（识别）答错误对学习和人际关系的影响

    Impact of Experiencing Misrecognition by Teachable Agents on Learning and Rapport. (arXiv:2306.07302v1 [cs.HC])

    [http://arxiv.org/abs/2306.07302](http://arxiv.org/abs/2306.07302)

    音频识别错误对教学代理人学习和人际关系无显著影响，结果为教学代理人的最优错误恢复策略提供了一些启示。

    

    虽然使用语音的教学代理人相比于基于打字的代理人具有一些优势，但它们容易出现音频识别错误。这些错误可能会扩散，导致对话流程的意外变化。我们分析了这些变化与学习收益以及学习者与代理人之间的人际关系之间的联系。我们的结果表明，这些变化无论代理人在不产生错误的情况下应该给予何种回应，都与学习收益或人际关系无关。我们还讨论了可从这些发现中推出的适当错误恢复策略对教学代理人的影响。

    While speech-enabled teachable agents have some advantages over typing-based ones, they are vulnerable to errors stemming from misrecognition by automatic speech recognition (ASR). These errors may propagate, resulting in unexpected changes in the flow of conversation. We analyzed how such changes are linked with learning gains and learners' rapport with the agents. Our results show they are not related to learning gains or rapport, regardless of the types of responses the agents should have returned given the correct input from learners without ASR errors. We also discuss the implications for optimal error-recovery policies for teachable agents that can be drawn from these findings.
    
[^72]: 基于回归和最小二乘支持向量机的空气污染预测的新技术

    Novel Regression and Least Square Support Vector Machine Learning Technique for Air Pollution Forecasting. (arXiv:2306.07301v1 [cs.LG])

    [http://arxiv.org/abs/2306.07301](http://arxiv.org/abs/2306.07301)

    提出了一种新技术，称为DR-LSSV，基于回归和最小二乘支持向量机，可有效提高空气污染预测性能，并在空气污染预测准确性、空气污染预测时间和假阳性率方面超越了传统的机器学习方法。

    

    空气污染是来源于微粒、化学物质或生物物质的问题，它会对人类或其他生物带来痛苦，对自然栖息地和空气空间也会造成不适。因此，空气污染在大都市中仍然是一项重要的环境问题。若不正确地检测空气污染标准，则会对人类和生物造成严重的后果。为了解决这个问题，提出了一种新技术——离散化回归和最小二乘支持向量（DR-LSSV）来预测空气污染。结果表明，所提出的DR-LSSV技术可以有效提高空气污染预测性能，并在空气污染预测准确性、空气污染预测时间和假阳性率方面超越了传统的机器学习方法。

    Air pollution is the origination of particulate matter, chemicals, or biological substances that brings pain to either humans or other living creatures or instigates discomfort to the natural habitat and the airspace. Hence, air pollution remains one of the paramount environmental issues as far as metropolitan cities are concerned. Several air pollution benchmarks are even said to have a negative influence on human health. Also, improper detection of air pollution benchmarks results in severe complications for humans and living creatures. To address this aspect, a novel technique called, Discretized Regression and Least Square Support Vector (DR-LSSV) based air pollution forecasting is proposed. The results indicate that the proposed DR-LSSV Technique can efficiently enhance air pollution forecasting performance and outperforms the conventional machine learning methods in terms of air pollution forecasting accuracy, air pollution forecasting time, and false positive rate.
    
[^73]: 诊断皮肤病变的渐进式分类关注（PCA）方法

    Progressive Class-Wise Attention (PCA) Approach for Diagnosing Skin Lesions. (arXiv:2306.07300v1 [cs.LG])

    [http://arxiv.org/abs/2306.07300](http://arxiv.org/abs/2306.07300)

    本研究提出一种新的分类关注技术，能够平等关注每个皮肤病变类别，并逐步结合多个尺度的判别特征细节，从而获得显著的诊断表现，准确率分别为97.40％和94.9％，超过了15种尖端方法，包括HAM1000和ISIC2019排行榜的优胜者。

    

    全球癌症发病率中，皮肤癌的发生率最高。早期发现的重要性不言而喻，晚期病例可能会危及生命。然而，由于色彩、形状和大小等多种变化，皮肤病变的分类存在多个挑战，同一类别内存在显著变异，不同类别之间也存在显著相似性。本文介绍了一种新型的分类关注技术，该技术在挖掘皮肤病变的更具体细节的同时，平等地考虑每个类别。这种关注机制逐步用于结合多个尺度的判别特征细节。本文介绍的技术表现出色，不仅超过了15种尖端方法，还包括HAM1000和ISIC 2019排行榜的优胜者。在HAM10000数据集上，其准确率达到了97.40％，而在ISIC 2019数据集上则为94.9％。

    Skin cancer holds the highest incidence rate among all cancers globally. The importance of early detection cannot be overstated, as late-stage cases can be lethal. Classifying skin lesions, however, presents several challenges due to the many variations they can exhibit, such as differences in colour, shape, and size, significant variation within the same class, and notable similarities between different classes. This paper introduces a novel class-wise attention technique that equally regards each class while unearthing more specific details about skin lesions. This attention mechanism is progressively used to amalgamate discriminative feature details from multiple scales. The introduced technique demonstrated impressive performance, surpassing more than 15 cutting-edge methods including the winners of HAM1000 and ISIC 2019 leaderboards. It achieved an impressive accuracy rate of 97.40% on the HAM10000 dataset and 94.9% on the ISIC 2019 dataset.
    
[^74]: 用语音助手指引屏幕文本

    Referring to Screen Texts with Voice Assistants. (arXiv:2306.07298v1 [cs.HC])

    [http://arxiv.org/abs/2306.07298](http://arxiv.org/abs/2306.07298)

    本文提出了一种新的体验，使用户可以通过语音助手引用他们手机屏幕上的电话号码、地址、电子邮件地址、URL和日期。我们设计了一个轻量级的模型，并收集了一个数据集。该模型是模块化的，提供了灵活性、改进的可解释性和高效的运行时内存利用率。

    

    语音助手可以帮助用户打电话、发送消息、创建事件、导航等等，但助手能够理解用户的背景是有限的。本文旨在向这个方向迈进一步。我们的工作探索了一种新的体验，让用户可以指出他们手机屏幕上的电话号码、地址、电子邮件地址、URL和日期。我们的重点在于参考理解，当屏幕上存在多个相似的文本时，类似于视觉基础的情况，这变得特别有趣。我们收集了一个数据集，并为这种新颖体验提出了一个轻量级的通用模型。由于直接消耗像素成本高昂，我们的系统设计依赖于从UI中提取的文本。我们的模型是模块化的，因此提供了灵活性、改进的可解释性和高效的运行时内存利用率。

    Voice assistants help users make phone calls, send messages, create events, navigate, and do a lot more. However, assistants have limited capacity to understand their users' context. In this work, we aim to take a step in this direction. Our work dives into a new experience for users to refer to phone numbers, addresses, email addresses, URLs, and dates on their phone screens. Our focus lies in reference understanding, which becomes particularly interesting when multiple similar texts are present on screen, similar to visual grounding. We collect a dataset and propose a lightweight general-purpose model for this novel experience. Due to the high cost of consuming pixels directly, our system is designed to rely on the extracted text from the UI. Our model is modular, thus offering flexibility, improved interpretability, and efficient runtime memory utilization.
    
[^75]: 基于ChatGPT的医疗数据增广：基于药物识别和药物事件分类的案例研究

    Medical Data Augmentation via ChatGPT: A Case Study on Medication Identification and Medication Event Classification. (arXiv:2306.07297v1 [cs.CL])

    [http://arxiv.org/abs/2306.07297](http://arxiv.org/abs/2306.07297)

    本研究利用ChatGPT进行数据增广，显著提高了BERT模型在电子病历药物识别和药物事件分类任务中的表现。

    

    在电子病历和临床记录中识别药物、疾病和关联性等关键因素具有广泛的临床应用。本研究旨在探索使用预训练的大型语言模型ChatGPT进行数据增广，以克服电子病历中关键因素标注数据的有限可用性。研究结果表明，提出的数据增广技术显著提高了BERT模型在药物识别和药物事件分类等两个电子病历分析任务中的性能。

    The identification of key factors such as medications, diseases, and relationships within electronic health records and clinical notes has a wide range of applications in the clinical field. In the N2C2 2022 competitions, various tasks were presented to promote the identification of key factors in electronic health records (EHRs) using the Contextualized Medication Event Dataset (CMED). Pretrained large language models (LLMs) demonstrated exceptional performance in these tasks. This study aims to explore the utilization of LLMs, specifically ChatGPT, for data augmentation to overcome the limited availability of annotated data for identifying the key factors in EHRs. Additionally, different pre-trained BERT models, initially trained on extensive datasets like Wikipedia and MIMIC, were employed to develop models for identifying these key variables in EHRs through fine-tuning on augmented datasets. The experimental results of two EHR analysis tasks, namely medication identification and me
    
[^76]: 基于PSO超参数优化的三种深度学习模型在北京PM2.5预测方面的应用研究

    Optimized Three Deep Learning Models Based-PSO Hyperparameters for Beijing PM2.5 Prediction. (arXiv:2306.07296v1 [cs.LG])

    [http://arxiv.org/abs/2306.07296](http://arxiv.org/abs/2306.07296)

    本论文提出了基于PSO超参数优化的三种深度学习模型，针对北京PM2.5的预测任务进行研究，并发现M-1模型具有最佳性能且经过优化的超参数可以提高5.6%的预测准确度。

    

    深度学习是一种机器学习方法，在自然语言处理、图像识别和预测等各种应用中都有出色的表现。深度学习网络的性能取决于超参数设置，本研究尝试优化长短时记忆（LSTM）、卷积神经网络（CNN）和多层感知器（MLP）的深度学习架构，使用基于群智能的元启发式优化方法粒子群算法（PSO）进行预测任务的优化。本文提出了M-1（PSO-LSTM）、M-2（PSO-CNN）和M-3（PSO-MLP）。对北京PM2.5数据集进行分析，以测量所提出模型的性能。PM2.5作为目标变量，受到露点、气压、温度、累计风速、降雪小时数和降雨小时数的影响。深度学习网络输入分为三种不同的情景：日常、每周和每月。结果表明，提出的M-1具有三个隐藏层，提供了最佳性能，并且经过优化的超参数相对于基线模型提高了5.6%的预测准确度。

    Deep learning is a machine learning approach that produces excellent performance in various applications, including natural language processing, image identification, and forecasting. Deep learning network performance depends on the hyperparameter settings. This research attempts to optimize the deep learning architecture of Long short term memory (LSTM), Convolutional neural network (CNN), and Multilayer perceptron (MLP) for forecasting tasks using Particle swarm optimization (PSO), a swarm intelligence-based metaheuristic optimization methodology: Proposed M-1 (PSO-LSTM), M-2 (PSO-CNN), and M-3 (PSO-MLP). Beijing PM2.5 datasets was analyzed to measure the performance of the proposed models. PM2.5 as a target variable was affected by dew point, pressure, temperature, cumulated wind speed, hours of snow, and hours of rain. The deep learning network inputs consist of three different scenarios: daily, weekly, and monthly. The results show that the proposed M-1 with three hidden layers pr
    
[^77]: 基于神经网络的城市时空数据合成方法

    Urban Spatiotemporal Data Synthesis via Neural Disaggregation. (arXiv:2306.07292v1 [cs.LG])

    [http://arxiv.org/abs/2306.07292](http://arxiv.org/abs/2306.07292)

    本研究提出了一种基于神经网络的城市时空数据合成方法，旨在通过分解粗糙的低分辨率地理单元的聚合城市数据来合成细粒度，高分辨率的城市数据，以增加高度聚合的城市数据的可用性和实现价值。

    

    开放数据的细节级别常常与其所能提供的实际效益发生冲突。较不细化的数据可以保护个人隐私，但在一定程度上牺牲了开放数据促进透明度和协助研究的承诺。类似于城市环境中，高层次地理单元的聚合城市数据可能会掩盖城市动态的底层特征，低级别地理单元的变化可能更为明显。本研究旨在通过分解粗糙的低分辨率地理单元的聚合城市数据，合成细粒度，高分辨率的城市数据，以增加高度聚合的城市数据的可用性和实现价值。为了解决一些传统分解方法的简单性问题-1) 我们尝试了许多神经网络模型，这些模型能够建模特征之间复杂的非线性关系。神经方法也可以同时利用空间和时间信息。我们展示了这些神经网络方法的优点。

    The level of granularity of open data often conflicts the benefits it can provide. Less granular data can protect individual privacy, but to certain degrees, sabotage the promise of open data to promote transparency and assist research. Similar in the urban setting, aggregated urban data at high-level geographic units can mask out the underline particularities of city dynamics that may vary at lower areal levels. In this work, we aim to synthesize fine-grained, high resolution urban data, by breaking down aggregated urban data at coarse, low resolution geographic units. The goal is to increase the usability and realize the values as much as possible of highly aggregated urban data. To address the issue of simplicity of some traditional disaggregation methods -- 1) we experimented with numerous neural-based models that are capable of modeling intricate non-linear relationships among features. Neural methods can also leverage both spatial and temporal information concurrently. We showed 
    
[^78]: 基于条件扩散模型的值函数估计控制方法

    Value function estimation using conditional diffusion models for control. (arXiv:2306.07290v1 [cs.LG])

    [http://arxiv.org/abs/2306.07290](http://arxiv.org/abs/2306.07290)

    论文提出了一种基于条件扩散模型的值函数估计控制方法（DVF），该方法可以在大量条件化数据上有效地进行训练，并使用只有一小部分示范数据就能超过基准算法。

    

    深度强化学习的一个可靠趋势是性能随参数数量的增加而提高，前提是有充足的训练数据。然而，随着大型模型的需求增加，很可能会出现高质量示范数据不足的问题。我们提出了一种名为扩散值函数的简单算法(DVF)，它使用扩散模型来学习环境和机器人交互动态的联合多步模型，并估计所需任务的值函数。在模拟连续控制任务上，我们证明了我们的方法的有效性，并显示它只需要使用一小部分示范数据就可以胜过基准算法。

    A fairly reliable trend in deep reinforcement learning is that the performance scales with the number of parameters, provided a complimentary scaling in amount of training data. As the appetite for large models increases, it is imperative to address, sooner than later, the potential problem of running out of high-quality demonstrations. In this case, instead of collecting only new data via costly human demonstrations or risking a simulation-to-real transfer with uncertain effects, it would be beneficial to leverage vast amounts of readily-available low-quality data. Since classical control algorithms such as behavior cloning or temporal difference learning cannot be used on reward-free or action-free data out-of-the-box, this solution warrants novel training paradigms for continuous control. We propose a simple algorithm called Diffused Value Function (DVF), which learns a joint multi-step model of the environment-robot interaction dynamics using a diffusion model. This model can be ef
    
[^79]: TransCoder：受人类技能启发的统一可转移代码表示学习

    TransCoder: Towards Unified Transferable Code Representation Learning Inspired by Human Skills. (arXiv:2306.07285v1 [cs.SE])

    [http://arxiv.org/abs/2306.07285](http://arxiv.org/abs/2306.07285)

    TransCoder是一种可转移的代码表示学习任务的微调策略，通过可调整的前缀编码器作为元学习器来捕捉跨任务和跨语言的可转移知识，使模型学习更好的代码相关元知识。此外，我们的方法可以remarkably地提高训练样本量较小和语料库较小的任务和语言的效果。

    

    最近，代码预训练模型（CodePTMs）已经表现出在处理各种软件智能任务方面的扎实能力，例如，代码克隆检测、代码翻译和代码摘要。目前将这些模型部署到下游任务的主流方法是在单个任务上对它们进行微调，这通常是昂贵的，并且需要大型模型的充足数据。为了解决这个问题，我们提出了TransCoder，这是一种统一的可转移的代码表示学习任务的微调策略。受人类内在知识泛化技能的启发，TransCoder驱动模型像人类程序员一样学习更好的代码相关元知识。具体地，我们采用可调整的前缀编码器作为元学习器，分别捕捉跨任务和跨语言的可转移知识。此外，我们的方法可以remarkably地提高训练样本量较小和语料库较小的任务和语言的效果。

    Code pre-trained models (CodePTMs) have recently demonstrated a solid capacity to process various software intelligence tasks, e.g., code clone detection, code translation, and code summarization. The current mainstream method that deploys these models to downstream tasks is to fine-tune them on individual tasks, which is generally costly and needs sufficient data for large models. To tackle the issue, in this paper, we present TransCoder, a unified Transferable fine-tuning strategy for Code representation learning. Inspired by human inherent skills of knowledge generalization, TransCoder drives the model to learn better code-related meta-knowledge like human programmers. Specifically, we employ a tunable prefix encoder as the meta-learner to capture cross-task and cross-language transferable knowledge, respectively. Besides, tasks with minor training sample sizes and languages with small corpus can be remarkably benefited from our approach. Extensive experiments conducted on benchmark
    
[^80]: 迈向端到端ASP计算

    Towards end-to-end ASP computation. (arXiv:2306.06821v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2306.06821](http://arxiv.org/abs/2306.06821)

    该论文提出了一种端到端方法，通过线性代数计算稳定模型满足给定的限制条件，同时没有使用符号ASP或SAT求解器，为加速通过并行技术提供了可能。

    

    我们提出了一种端到端方法，用线性代数计算满足给定限制条件的稳定模型，以及ASP的计算。一种构造成矩阵化正常逻辑程序、Lin-Zhao定理中的循环公式和限制条件的代价函数的数值最小化的向量空间直接实现Lin-Zhao定理的思路，因此在我们的方法中没有使用符号ASP或SAT求解器。我们还提出了用于缩小程序大小的预计算和用于减少计算难度的循环公式启发式方法。我们用编程示例对我们的方法进行了实证测试，包括三色涂色问题和哈密顿环问题。由于我们的方法是纯粹数值方法，并且只包含向量/矩阵操作，因此可以通过并行技术（例如多核和GPU）进行加速。

    We propose an end-to-end approach for answer set programming (ASP) and linear algebraically compute stable models satisfying given constraints. The idea is to implement Lin-Zhao's theorem \cite{Lin04} together with constraints directly in vector spaces as numerical minimization of a cost function constructed from a matricized normal logic program, loop formulas in Lin-Zhao's theorem and constraints, thereby no use of symbolic ASP or SAT solvers involved in our approach. We also propose precomputation that shrinks the program size and heuristics for loop formulas to reduce computational difficulty. We empirically test our approach with programming examples including the 3-coloring and Hamiltonian cycle problems. As our approach is purely numerical and only contains vector/matrix operations, acceleration by parallel technologies such as many-cores and GPUs is expected.
    
[^81]: EaSyGuide：利用生成大语言模型能力的ESG问题识别框架

    EaSyGuide : ESG Issue Identification Framework leveraging Abilities of Generative Large Language Models. (arXiv:2306.06662v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.06662](http://arxiv.org/abs/2306.06662)

    本文介绍了一种利用生成大语言模型能力的ESG问题识别框架，该框架在多语言环境下对MSCI ESG评级指南定义的35个ESG关键问题实现了卓越的识别成果，为ESG主题的探索做出了贡献。

    

    本文介绍了我们参加FinNLP-2023多语言环境、社会和企业治理问题识别（ML-ESG）共享任务的方法。该任务的目标是根据MSCI ESG评级指南定义的35个ESG关键问题对新闻文章进行分类。我们的方法集中在英语和法语子任务上，采用CerebrasGPT、OPT和Pythia模型，以及零-shot和GPT3Mix增强技术。我们利用各种编码器模型，如RoBERTa、DeBERTa和FinBERT，在知识蒸馏和额外训练的基础上进行了试验。我们的方法取得了卓越的成果，在英语文本子任务中获得F1-score 0.69的第一名，在法语文本子任务中获得F1-score 0.78的第二名。这些结果强调了我们的方法在不同语言的新闻文章中识别ESG问题的有效性。我们的研究结果对ESG主题的探索做出了贡献，并强调了技术创新在解决复杂问题上的重要性。

    This paper presents our participation in the FinNLP-2023 shared task on multi-lingual environmental, social, and corporate governance issue identification (ML-ESG). The task's objective is to classify news articles based on the 35 ESG key issues defined by the MSCI ESG rating guidelines. Our approach focuses on the English and French subtasks, employing the CerebrasGPT, OPT, and Pythia models, along with the zero-shot and GPT3Mix Augmentation techniques. We utilize various encoder models, such as RoBERTa, DeBERTa, and FinBERT, subjecting them to knowledge distillation and additional training.  Our approach yielded exceptional results, securing the first position in the English text subtask with F1-score 0.69 and the second position in the French text subtask with F1-score 0.78. These outcomes underscore the effectiveness of our methodology in identifying ESG issues in news articles across different languages. Our findings contribute to the exploration of ESG topics and highlight the po
    
[^82]: Aria数字孪生：一种新的基准数据集用于自我中心的3D机器感知。

    Aria Digital Twin: A New Benchmark Dataset for Egocentric 3D Machine Perception. (arXiv:2306.06362v1 [cs.CV])

    [http://arxiv.org/abs/2306.06362](http://arxiv.org/abs/2306.06362)

    Aria数字孪生是一个自我中心数据集，具有其它任何数据集都没有的高精度、照片逼真和详尽的真实信息。这个数据集将成为自我中心机器感知评估的新标准。

    

    我们推出了Aria数字孪生（ADT）-一个使用Aria眼镜捕获的自我中心数据集，具有广泛的对象，环境和人类级别的真实数据。该ADT数据集包括200个由穿戴Aria设备的人在两个室内真实场景中执行的真实世界活动序列，包含398个对象实例（324个静态和74个动态）。每个序列包括：a）两个单色相机流，一个RGB相机流，两个IMU流的原始数据；b）完整的传感器校准；c）真实数据，包括Aria设备的连续6自由度（6DoF）姿态，对象6DoF姿态，3D注视矢量，3D人体姿态，2D图像分割，图像深度图；d）照片般真实的合成渲染图像。据我们所知，目前没有现有自我中心数据集能够与ADT的准确性、逼真度和全面性相媲美。通过向研究社区贡献ADT，我们的使命是为自我中心机器感知的评估设立新的标准。

    We introduce the Aria Digital Twin (ADT) - an egocentric dataset captured using Aria glasses with extensive object, environment, and human level ground truth. This ADT release contains 200 sequences of real-world activities conducted by Aria wearers in two real indoor scenes with 398 object instances (324 stationary and 74 dynamic). Each sequence consists of: a) raw data of two monochrome camera streams, one RGB camera stream, two IMU streams; b) complete sensor calibration; c) ground truth data including continuous 6-degree-of-freedom (6DoF) poses of the Aria devices, object 6DoF poses, 3D eye gaze vectors, 3D human poses, 2D image segmentations, image depth maps; and d) photo-realistic synthetic renderings. To the best of our knowledge, there is no existing egocentric dataset with a level of accuracy, photo-realism and comprehensiveness comparable to ADT. By contributing ADT to the research community, our mission is to set a new standard for evaluation in the egocentric machine perce
    
[^83]: 测试时间风格转换：处理领域泛化中任意风格问题

    Test-Time Style Shifting: Handling Arbitrary Styles in Domain Generalization. (arXiv:2306.04911v1 [cs.CV])

    [http://arxiv.org/abs/2306.04911](http://arxiv.org/abs/2306.04911)

    本文提出了测试时间风格转换（test-time style shifting）的方法，使得模型能够有效地处理领域泛化任务中任意风格的问题，同时避免了额外的模型更新。

    

    领域泛化（DG）要求为未知目标域进行训练，且在推理时需要成功应用于任意（甚至是未见）的目标域。本文提出了一种简单而有效的方法来解决这个难题。我们提出了测试时间风格转换（test-time style shifting），在进行预测之前，将测试样本的风格（与源域存在较大差异的）转换为最接近模型已知的源域，从而使模型能够应对具有任意风格统计的任何目标域，无需在测试时进行额外的模型更新。此外，我们提出了风格平衡（style balancing），它为最大化测试时间风格转换的优势提供了良好的平台，同时解决了DG特定的不平衡问题。所提出的思路易于实现，且成功地完成了领域泛化任务。

    In domain generalization (DG), the target domain is unknown when the model is being trained, and the trained model should successfully work on an arbitrary (and possibly unseen) target domain during inference. This is a difficult problem, and despite active studies in recent years, it remains a great challenge. In this paper, we take a simple yet effective approach to tackle this issue. We propose test-time style shifting, which shifts the style of the test sample (that has a large style gap with the source domains) to the nearest source domain that the model is already familiar with, before making the prediction. This strategy enables the model to handle any target domains with arbitrary style statistics, without additional model update at test-time. Additionally, we propose style balancing, which provides a great platform for maximizing the advantage of test-time style shifting by handling the DG-specific imbalance issues. The proposed ideas are easy to implement and successfully wor
    
[^84]: 人为参与的创新生成

    Human in the Loop Novelty Generation. (arXiv:2306.04813v1 [cs.AI])

    [http://arxiv.org/abs/2306.04813](http://arxiv.org/abs/2306.04813)

    该论文提出了一种新的创新生成方法，使用环境的抽象模型而不需要人类专业知识来生成新的新颖性。这可以产生更大的、通常是无限的新颖性空间，但需要人类的指导来选择和过滤这些新颖性。

    

    开发人工智能以应对新颖、意外情况是一个困难而尚未解决的问题。在推动新颖性容纳的技术发展方面，一个挑战是缺乏测试框架，以评估在新颖情况下的表现。最近在“科学鸟”和“大富翁”等领域中出现的新颖性生成方法利用了人类领域专业知识进行搜索，以发现新的新颖性。这些方法在新颖性生成之前引入人类指导，产生的创新可以直接加载到模拟环境中。我们提出了一种新的创新生成方法，使用环境的抽象模型（包括模拟领域），不需要依赖于特定领域的人类指导来生成创新。一个关键结果是可以生成更大的、通常是无限的新颖性空间，但需要在生成后涉及人类指导以选择和过滤新颖性。

    Developing artificial intelligence approaches to overcome novel, unexpected circumstances is a difficult, unsolved problem. One challenge to advancing the state of the art in novelty accommodation is the availability of testing frameworks for evaluating performance against novel situations. Recent novelty generation approaches in domains such as Science Birds and Monopoly leverage human domain expertise during the search to discover new novelties. Such approaches introduce human guidance before novelty generation occurs and yield novelties that can be directly loaded into a simulated environment. We introduce a new approach to novelty generation that uses abstract models of environments (including simulation domains) that do not require domain-dependent human guidance to generate novelties. A key result is a larger, often infinite space of novelties capable of being generated, with the trade-off being a requirement to involve human guidance to select and filter novelties post generatio
    
[^85]: Fusemate概率逻辑编程系统中的自下而上推理

    Bottom-Up Grounding in the Probabilistic Logic Programming System Fusemate. (arXiv:2305.18924v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2305.18924](http://arxiv.org/abs/2305.18924)

    介绍了自下而上推理的概率逻辑编程系统Fusemate，提出了基于查询引导的相关性测试修剪规则，解决了自下而上推理难以控制ground clauses生成数量的问题，并在包含“时间”的示例中表现出更好的性能。

    

    本文介绍了Fusemate概率逻辑编程系统，该系统的推理引擎包括一个自下而上推理的grounding组件和一个变量消除方法用于概率推理。Fusemate不同于大多数系统，它采用自下而上的方式对程序进行grounding。本文解决了自下而上推理难以控制生成的ground clauses数量的问题，通过交错grounding和一个基于查询引导的相关性测试来修剪与查询不一致的规则。我们详细介绍了我们的方法，并通过包含“时间”的示例（如（隐藏）马尔可夫模型）进行演示。我们的实验证明，在高分支问题上，相比于最先进的概率逻辑编程系统，我们的性能更具竞争力或更好。

    This paper introduces the Fusemate probabilistic logic programming system. Fusemate's inference engine comprises a grounding component and a variable elimination method for probabilistic inference. Fusemate differs from most other systems by grounding the program in a bottom-up way instead of the common top-down way. While bottom-up grounding is attractive for a number of reasons, e.g., for dynamically creating distributions of varying support sizes, it makes it harder to control the amount of ground clauses generated. We address this problem by interleaving grounding with a query-guided relevance test which prunes rules whose bodies are inconsistent with the query. We present our method in detail and demonstrate it with examples that involve "time", such as (hidden) Markov models. Our experiments demonstrate competitive or better performance compared to a state-of-the art probabilistic logic programming system, in particular for high branching problems.
    
[^86]: 一次性还原捕获于任意复杂恶劣天气条件下的图像

    Restoring Images Captured in Arbitrary Hybrid Adverse Weather Conditions in One Go. (arXiv:2305.09996v1 [cs.CV])

    [http://arxiv.org/abs/2305.09996](http://arxiv.org/abs/2305.09996)

    提出了一种新的框架RAHC，可以一次性处理任意复杂恶劣天气条件下的图像恢复，并建立了一个新的数据集HAC，用于学习和基准测试混合条件的图像恢复。

    

    在恶劣天气条件下，图像往往会受到随机混合的天气影响（例如，雨天和雾霾夜晚），而现有的图像恢复算法预计天气影响是相互独立的，因此可能无法处理复杂的现实情况。此外，由于缺乏全面对应的数据集来描述复杂的混合天气状况，监督训练不可行。为此，我们通过两个策略——框架和数据——来弥补上述限制。一方面，我们提出了一种新的统一框架，称为RAHC，可以舒适地处理混合情况，并通过单个训练模型灵活地恢复任意混合条件。另一方面，我们建立了一个新的数据集，称为HAC，用于学习和基准测试任意混合条件的图像恢复。HAC包含31种情景，包括任意组合的雨天、雪天、雾霾、雾天和薄雾天气条件。

    Adverse conditions typically suffer from stochastic hybrid weather degradations (e.g., rainy and hazy night), while existing image restoration algorithms envisage that weather degradations occur independently, thus may fail to handle real-world complicated scenarios. Besides, supervised training is not feasible due to the lack of comprehensive paired dataset to characterize hybrid conditions. To this end, we have advanced the forementioned limitations with two tactics: framework and data. On the one hand, we present a novel unified framework, dubbed RAHC, to Restore Arbitrary Hybrid adverse weather Conditions in one go, which can comfortably cope with hybrid scenarios with insufficient remaining background constituents and restore arbitrary hybrid conditions with a single trained model flexibly. On the other hand, we establish a new dataset, termed HAC, for learning and benchmarking arbitrary Hybrid Adverse Conditions restoration. HAC contains 31 scenarios composed of an arbitrary comb
    
[^87]: HybridNet: 基于几何与拓扑视角的VLSI阻塞预测的双分支融合

    HybridNet: Dual-Branch Fusion of Geometrical and Topological Views for VLSI Congestion Prediction. (arXiv:2305.05374v1 [cs.LG])

    [http://arxiv.org/abs/2305.05374](http://arxiv.org/abs/2305.05374)

    本文提出了HybridNet，一种基于几何与拓扑视角的VLSI阻塞预测的双分支融合网络，通过在网络结构中做出几个关键设计，充分综合电路的拓扑与几何特征，相较于以往方法取得了10.9％的提高。

    

    准确的阻塞预测是帮助设计师在VLSI设计周期内更快迭代的重要环节，而本文提出了一种新的策略，通过在网络结构中做出几个关键设计，充分综合电路的拓扑与几何特征。具体来说，我们构建了两个独立的图（几何图、拓扑图），根据它们的唯一属性采用不同的边缘构建方案。然后，我们提出了一个双分支网络，每个路径中都有不同的编码器层，并通过精细的融合策略进行聚合表示。我们的网络名为HybridNet，不仅提供了一种简单而有效的方法来捕捉单元之间的几何交互，而且还保留了原始电路拓扑关系。在ISPD2015基准测试上的实验结果显示，相较于以往方法，我们取得了10.9％的提高。

    Accurate early congestion prediction can prevent unpleasant surprises at the routing stage, playing a crucial character in assisting designers to iterate faster in VLSI design cycles. In this paper, we introduce a novel strategy to fully incorporate topological and geometrical features of circuits by making several key designs in our network architecture. To be more specific, we construct two individual graphs (geometry-graph, topology-graph) with distinct edge construction schemes according to their unique properties. We then propose a dual-branch network with different encoder layers in each pathway and aggregate representations with a sophisticated fusion strategy. Our network, named HybridNet, not only provides a simple yet effective way to capture the geometric interactions of cells, but also preserves the original topological relationships in the netlist. Experimental results on the ISPD2015 benchmarks show that we achieve an improvement of 10.9% compared to previous methods.
    
[^88]: 构建可信人工智能：从人工智能原则、伦理和主要需求到负责任的人工智能系统和监管

    Connecting the Dots in Trustworthy Artificial Intelligence: From AI Principles, Ethics, and Key Requirements to Responsible AI Systems and Regulation. (arXiv:2305.02231v1 [cs.CY])

    [http://arxiv.org/abs/2305.02231](http://arxiv.org/abs/2305.02231)

    该论文旨在探讨可信人工智能的构建，包括从法律、伦理和技术、社会角度确保其健壮性。实现真正可信的人工智能涉及到更广阔的愿景，考虑到伦理方面、风险方面、以及对七个技术需求的支持度和大局整体之关系。

    

    可信人工智能基于七个技术需求，分别从法律、伦理和技术、社会角度确保其健壮性。然而，实现真正可信的人工智能涉及到更广阔的愿景，包括系统生命周期中所有参与流程和参与者可信性的考量。一个更全面的愿景将考虑到伦理方面、风险方面、以下要件的支持度以及大局整体之关系。评估七个需求之技术方面、伦理方面和监管挑战方面。

    Trustworthy Artificial Intelligence (AI) is based on seven technical requirements sustained over three main pillars that should be met throughout the system's entire life cycle: it should be (1) lawful, (2) ethical, and (3) robust, both from a technical and a social perspective. However, attaining truly trustworthy AI concerns a wider vision that comprises the trustworthiness of all processes and actors that are part of the system's life cycle, and considers previous aspects from different lenses. A more holistic vision contemplates four essential axes: the global principles for ethical use and development of AI-based systems, a philosophical take on AI ethics, a risk-based approach to AI regulation, and the mentioned pillars and requirements. The seven requirements (human agency and oversight; robustness and safety; privacy and data governance; transparency; diversity, non-discrimination and fairness; societal and environmental wellbeing; and accountability) are analyzed from a triple
    
[^89]: 基于能量模型的零样本场景重新排列规划器

    Energy-based Models as Zero-Shot Planners for Compositional Scene Rearrangement. (arXiv:2304.14391v1 [cs.RO])

    [http://arxiv.org/abs/2304.14391](http://arxiv.org/abs/2304.14391)

    本文提出一种基于能量模型的零样本场景重新排列规划器，通过语言指导的空间概念来实现长指令以及在训练时从未见过的空间概念组合。本文的模型在指令导向操作基准测试以及组合指令基准测试中表现良好，优于基于语言表达的最先进方法，并且可以成功地解决之前从未见过的复杂指令和场景。

    

    本文致力于开发一个场景重排框架，可以解释长指令以及在训练时从未见过的空间概念组合。我们提出使用相对对象排列的能量函数来表示语言指导的空间概念。语言解析器将指令映射到相应的能量函数，而开放式视觉语言模型将它们的参数基于场景中的相关对象进行修正。通过梯度下降求解能量函数的总和，并利用基于本地计算机视觉的策略将对象重新定位到推断的目标位置，即可生成目标场景配置。我们在已建立的指令导向操作基准测试以及我们提出的组合指令基准测试中测试了模型，结果表明，我们的模型的绩效优于基于语言表达的最先进方法，并且可以成功地解决之前从未见过的复杂指令和场景。

    Language is compositional; an instruction can express multiple relation constraints to hold among objects in a scene that a robot is tasked to rearrange. Our focus in this work is an instructable scene rearranging framework that generalizes to longer instructions and to spatial concept compositions never seen at training time. We propose to represent language-instructed spatial concepts with energy functions over relative object arrangements. A language parser maps instructions to corresponding energy functions and an open-vocabulary visual-language model grounds their arguments to relevant objects in the scene. We generate goal scene configurations by gradient descent on the sum of energy functions, one per language predicate in the instruction. Local vision-based policies then relocate objects to the inferred goal locations. We test our model on established instruction-guided manipulation benchmarks, as well as benchmarks of compositional instructions we introduce. We show our model 
    
[^90]: 眼见不一定为实：人类感知AI生成图像的定量研究

    Seeing is not always believing: A Quantitative Study on Human Perception of AI-Generated Images. (arXiv:2304.13023v1 [cs.AI])

    [http://arxiv.org/abs/2304.13023](http://arxiv.org/abs/2304.13023)

    本研究揭示了人类无法辨别AI生成的假照片和真实照片，这一点受个人背景的影响并不显著。

    

    照片是人们记录日常生活经历的一种方式，通常被认为是可信的信息来源。然而，越来越多的人担心人工智能（AI）技术的进步可能产生伪造的照片，从而产生困惑并降低对照片的信任。本研究旨在回答一个问题，即当前最先进的基于AI的视觉内容生成模型能否持续地欺骗人类的眼睛，并传达错误信息。通过对50名参与者进行高质量的定量研究，我们首次揭示，人类无法显著区分真实照片和AI创建的伪造照片，达到38.7%。我们的研究还发现，个人的背景，如性别，年龄和经验，对区分AI生成的图像和真实照片的能力没有显著影响。但是，我们观察到

    Photos serve as a way for humans to record what they experience in their daily lives, and they are often regarded as trustworthy sources of information. However, there is a growing concern that the advancement of artificial intelligence (AI) technology may produce fake photos, which can create confusion and diminish trust in photographs. This study aims to answer the question of whether the current state-of-the-art AI-based visual content generation models can consistently deceive human eyes and convey false information. By conducting a high-quality quantitative study with fifty participants, we reveal, for the first time, that humans cannot distinguish between real photos and AI-created fake photos to a significant degree 38.7%. Our study also finds that an individual's background, such as their gender, age, and experience with AI-generated content (AIGC), does not significantly affect their ability to distinguish AI-generated images from real photographs. However, we do observe that 
    
[^91]: 奖励是否合理？在 MACHIAVELLI 基准测试中衡量奖励与道德行为之间的权衡

    Do the Rewards Justify the Means? Measuring Trade-Offs Between Rewards and Ethical Behavior in the MACHIAVELLI Benchmark. (arXiv:2304.03279v1 [cs.LG])

    [http://arxiv.org/abs/2304.03279](http://arxiv.org/abs/2304.03279)

    本文介绍了 MACHIAVELLI 基准测试，用于衡量人工智能代理是否表现出马基雅维利行为，发现了最大化奖励和行为的道德性之间存在权衡，并探索了基于语言模型的方法来减轻这种权衡。

    

    传统上，人工智能代理被训练成最大化奖励，这可能会激励追求权力和欺骗行为，类似于语言模型中的下一个标记预测可能会激励有害行为。那么代理是否自然而然地学会了马基雅维利行为？我们如何在 GPT-4 等通用模型中衡量这些行为呢？为回答这些问题，我们引入了 MACHIAVELLI 基准测试，该测试涵盖了超过一百万个多样化的情景，重点关注社会决策制定，用于衡量人工代理是否表现出马基雅维利行为。我们数学化了数十种有害行为，并使用我们的注释来评估代理倾向于追求权力，造成功能不良和违反伦理的倾向。我们观察到最大化奖励和行为的道德性之间存在一些紧张关系。为了改善这种权衡，我们研究了基于语言模型的方法，以使代理趋向于采取更少的有害行为。我们的结果显示，MACHIAVELLI 是评估人工代理马基雅维利行为水平的有用基准测试。

    Artificial agents have traditionally been trained to maximize reward, which may incentivize power-seeking and deception, analogous to how next-token prediction in language models (LMs) may incentivize toxicity. So do agents naturally learn to be Machiavellian? And how do we measure these behaviors in general-purpose models such as GPT-4? Towards answering these questions, we introduce MACHIAVELLI, a benchmark of 134 Choose-Your-Own-Adventure games containing over half a million rich, diverse scenarios that center on social decision-making. Scenario labeling is automated with LMs, which are more performant than human annotators. We mathematize dozens of harmful behaviors and use our annotations to evaluate agents' tendencies to be power-seeking, cause disutility, and commit ethical violations. We observe some tension between maximizing reward and behaving ethically. To improve this trade-off, we investigate LM-based methods to steer agents' towards less harmful behaviors. Our results sh
    
[^92]: 超越不对称性：结构剪枝提高序列到序列模型的推断效率

    To Asymmetry and Beyond: Structured Pruning of Sequence to Sequence Models for Improved Inference Efficiency. (arXiv:2304.02721v1 [cs.CL])

    [http://arxiv.org/abs/2304.02721](http://arxiv.org/abs/2304.02721)

    本论文研究了模型大小、结构化剪枝、推断效率和摘要准确性之间的关系，发现使用不对称剪枝可在不大损失模型准确性的情况下，提高推断效率约3倍。

    

    序列到序列语言模型可以用于生成连贯，相关和简洁的抽象摘要。但是，模型大小可能使得在延迟敏感或 Web 规模的实现中部署变得困难。本文研究了模型大小、结构化剪枝、推断效率和广泛使用的摘要数据集上的摘要准确性之间的关系。我们表明，模型准确性与编码器大小有关，而推理效率与解码器有关。使用不对称剪枝可导致推断延迟的近3倍提高，Rouge-2的损失约为1点。此外，我们发现，平均性能降低和不对称性的作用在模型大小和数据集变化方面是一致的。

    Sequence-to-sequence language models can be used to produce abstractive summaries which are coherent, relevant, and concise. Still, model sizes can make deployment in latency-sensitive or web-scale implementations difficult. This paper studies the relationship between model size, structured pruning, inference efficiency, and summarization accuracy on widely used summarization datasets. We show that model accuracy is tied to the encoder size while inference efficiency is connected to the decoder. Using asymmetric pruning can lead to nearly 3x improvement in inference latency with ~1 point loss in Rouge-2. Moreover, we find both the average degradation and the role of asymmetry to be consistent across model sizes and variations in datasets.
    
[^93]: MACARONS：基于RGB在线自监督的映射与覆盖预测

    MACARONS: Mapping And Coverage Anticipation with RGB Online Self-Supervision. (arXiv:2303.03315v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2303.03315](http://arxiv.org/abs/2303.03315)

    MACARONS是一种无需深度传感器和三维监督，仅通过彩色图像预测容积占用场并预测下一最佳视角的方法，具备在新场景中表现良好的能力。

    

    我们提出了一种方法，它能够学习探索新的大型环境，并仅通过彩色图像进行三维重建。这与下一最佳视角(NBV)问题有密切关系，其中需要确定摄像机的下一个移动方向以提高未知场景的覆盖率。然而，大多数当前的NBV方法依赖于深度传感器，需要三维监督并且不能很好地扩展到大型场景。我们的方法仅需要一个彩色相机且无需三维监督。它可以自监督地学习从彩色图像中预测“容积占用场”，并从中预测NBV。由于这种方法，我们的方法在新场景中表现良好，因为它不会对任何训练数据的3D偏差。我们在最近的数据集上进行了演示，该数据集由各种3D场景组成，并且我们表现甚至比需要深度传感器的最新方法更好，而这对于使用飞行无人机捕获的户外场景来说并不是一个现实的假设。

    We introduce a method that simultaneously learns to explore new large environments and to reconstruct them in 3D from color images only. This is closely related to the Next Best View problem (NBV), where one has to identify where to move the camera next to improve the coverage of an unknown scene. However, most of the current NBV methods rely on depth sensors, need 3D supervision and/or do not scale to large scenes. Our method requires only a color camera and no 3D supervision. It simultaneously learns in a self-supervised fashion to predict a "volume occupancy field" from color images and, from this field, to predict the NBV. Thanks to this approach, our method performs well on new scenes as it is not biased towards any training 3D data. We demonstrate this on a recent dataset made of various 3D scenes and show it performs even better than recent methods requiring a depth sensor, which is not a realistic assumption for outdoor scenes captured with a flying drone.
    
[^94]: SHAP-IQ: 任意阶Shapley interaction的统一逼近方法

    SHAP-IQ: Unified Approximation of any-order Shapley Interactions. (arXiv:2303.01179v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.01179](http://arxiv.org/abs/2303.01179)

    提出了一种名为SHAP-IQ的新方法，用于计算任意阶Shapley互动，并提供了逼近质量的理论保证和方差估计。该方法在计算成本和逼近质量方面优于现有方法。

    

    在可解释的人工智能（XAI）研究中，Shapley值（SV）通常被应用于确定任何黑盒模型的特征重要性得分。 Shapley interaction indices将SV扩展为定义任意阶特征相互作用得分。定义独特的Shapley interaction index是一个开放性研究问题，迄今为止已经提出了三个定义，其不同之处在于所选择的公理。此外，每个定义都需要特定的逼近技术。在这里，我们提出了基于采样的有效逼近方法SHAPley Interaction Quantification（SHAP-IQ），以计算任意基数交互指数（CII）的Shapley互动。即满足线性、对称和虚拟公理的交互指数。SHAP-IQ基于一种新颖的表示方法，与现有方法相比，我们为其逼近质量提供了理论保证，以及点估计的方差估计。对于SV的特殊情况，我们的逼近方法与精确计算一致。进行了数值实验，以证明我们的方法在几个合成和实际数据集上的有效性，并显示SHAP-IQ在计算成本和逼近质量方面优于现有方法。

    Predominately in explainable artificial intelligence (XAI) research, the Shapley value (SV) is applied to determine feature importance scores for any black box model. Shapley interaction indices extend the SV to define any-order feature interaction scores. Defining a unique Shapley interaction index is an open research question and, so far, three definitions have been proposed, which differ by their choice of axioms. Moreover, each definition requires a specific approximation technique. Here, we propose SHAPley Interaction Quantification (SHAP-IQ), an efficient sampling-based approximator to compute Shapley interactions for arbitrary cardinal interaction indices (CII), i.e. interaction indices that satisfy the linearity, symmetry and dummy axiom. SHAP-IQ is based on a novel representation and, in contrast to existing methods, we provide theoretical guarantees for its approximation quality, as well as estimates for the variance of the point estimates. For the special case of SV, our app
    
[^95]: 热力学人工智能与波动前沿

    Thermodynamic AI and the fluctuation frontier. (arXiv:2302.06584v3 [cs.ET] UPDATED)

    [http://arxiv.org/abs/2302.06584](http://arxiv.org/abs/2302.06584)

    该论文介绍了热力学人工智能算法的概念，并将多种人工智能算法统一在一个数学框架下。该算法与传统硬件有所不同，并提出一种全新的计算模式，使得热力学人工智能算法可以更高效地解决计算难题。

    

    许多人工智能算法受到物理学启发并使用随机波动。我们将这些受物理启发的AI算法联系起来，并将它们统一在一个名为“热力学人工智能”的数学框架下。这种热力学人工智能算法目前在数字硬件上运行，极限了它们的可扩展性和整体潜力。我们建议一种新型计算模式，软件和硬件成为不可分割的整体。我们的算法统一使我们可以识别出一个单一的全栈范例，包括热力学人工智能硬件，可以加速这些算法。我们将热力学人工智能硬件与传统数字硬件进行对比，并概述了这种方法的潜在优点，包括高效的能源利用，解决优化、采样和推断等计算难题。

    Many Artificial Intelligence (AI) algorithms are inspired by physics and employ stochastic fluctuations. We connect these physics-inspired AI algorithms by unifying them under a single mathematical framework that we call Thermodynamic AI. Seemingly disparate algorithmic classes can be described by this framework, for example, (1) Generative diffusion models, (2) Bayesian neural networks, (3) Monte Carlo sampling and (4) Simulated annealing. Such Thermodynamic AI algorithms are currently run on digital hardware, ultimately limiting their scalability and overall potential. Stochastic fluctuations naturally occur in physical thermodynamic systems, and such fluctuations can be viewed as a computational resource. Hence, we propose a novel computing paradigm, where software and hardware become inseparable. Our algorithmic unification allows us to identify a single full-stack paradigm, involving Thermodynamic AI hardware, that could accelerate such algorithms. We contrast Thermodynamic AI har
    
[^96]: 单一动作扩散模型

    Single Motion Diffusion. (arXiv:2302.05905v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.05905](http://arxiv.org/abs/2302.05905)

    SinMDM是一种单一动作扩散模型，利用去噪网络和扩散模型来学习单个动作序列的内部模式，并合成具有其特点的任意长度的运动。

    

    合成逼真的人类、动物甚至是虚构生物的动画长期以来一直是艺术家和计算机图形专业人员的目标。与图像领域相比，运动领域的数据实例数量非常有限，特别是对于动物和异国情调生物（例如龙），它们具有独特的骨架和运动模式。在本研究中，我们提出了一种称为单一动作扩散模型（SinMDM）的模型，旨在学习任意拓扑结构的单个动作序列的内部模式，并合成具有其特点的任意长度的运动。我们利用扩散模型的作用，并提出了一种专门设计用于从单个输入动作学习的去噪网络。SinMDM采用轻量级架构设计，通过使用具有本地关注层的浅层网络来缩小感受野并促进运动多样化，避免了过度拟合。

    Synthesizing realistic animations of humans, animals, and even imaginary creatures, has long been a goal for artists and computer graphics professionals. Compared to the imaging domain, which is rich with large available datasets, the number of data instances for the motion domain is limited, particularly for the animation of animals and exotic creatures (e.g., dragons), which have unique skeletons and motion patterns. In this work, we present a Single Motion Diffusion Model, dubbed SinMDM, a model designed to learn the internal motifs of a single motion sequence with arbitrary topology and synthesize motions of arbitrary length that are faithful to them. We harness the power of diffusion models and present a denoising network explicitly designed for the task of learning from a single input motion. SinMDM is designed to be a lightweight architecture, which avoids overfitting by using a shallow network with local attention layers that narrow the receptive field and encourage motion dive
    
[^97]: 大型语言模型是推理教师

    Large Language Models Are Reasoning Teachers. (arXiv:2212.10071v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10071](http://arxiv.org/abs/2212.10071)

    本文提出了Fine-tune-CoT，一种使用大型模型作为推理教师让较小模型也能进行复杂推理的方法，可以远远优于基于提示的基线方法，在多个任务上进行了评估。此外，该方法还利用教师模型的能力为每个原始样本生成多个不同的原因解释。

    

    最近的研究表明，思维链条提示可以引导语言模型逐步解决复杂的推理任务。然而，基于提示的思维链条方法依赖于像GPT-3 175B这样非常大的模型，这在规模上是不可行的。本文提出了Fine-tune-CoT方法，使用这些大型模型作为推理教师，以让较小的模型也能进行复杂推理，从而使模型尺寸要求减少数个数量级。我们在公共模型和复杂任务上评估了该方法，发现Fine-tune-CoT可以在小型模型中实现实质性的推理能力，远远优于基于提示的基线方法，甚至在许多任务中也优于教师模型。此外，我们扩展了该方法，利用教师模型的能力为每个原始样本生成多个不同的原因解释，从而增强了微调数据。

    Recent works have shown that chain-of-thought (CoT) prompting can elicit language models to solve complex reasoning tasks, step-by-step. However, prompt-based CoT methods are dependent on very large models such as GPT-3 175B which are prohibitive to deploy at scale. In this paper, we use these large models as reasoning teachers to enable complex reasoning in smaller models and reduce model size requirements by several orders of magnitude. We propose Fine-tune-CoT, a method that generates reasoning samples from very large teacher models to fine-tune smaller models. We evaluate our method on a wide range of public models and complex tasks. We find that Fine-tune-CoT enables substantial reasoning capability in small models, far outperforming prompt-based baselines and even the teacher model in many tasks. Additionally, we extend our method by leveraging the teacher model's ability to generate multiple distinct rationales for each original sample. Enriching the fine-tuning data with such d
    
[^98]: 使用关系感知消息传递神经网络生成无偏见的异构场景图

    Unbiased Heterogeneous Scene Graph Generation with Relation-aware Message Passing Neural Network. (arXiv:2212.00443v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2212.00443](http://arxiv.org/abs/2212.00443)

    本文提出了一种无偏见的异构场景图生成框架，使用关系感知消息传递神经网络捕获对象之间的上下文感知性，并设计了一种新的消息传递层来汇总图像的上下文信息。

    

    近期的场景图生成（SGG）框架聚焦于学习图像中多个对象之间的复杂关系。由于消息传递神经网络（MPNN）能够模拟对象与邻近对象之间的高阶相互作用，因此它们是SGG的主导表示学习模块。然而，现有的基于MPNN的框架将场景图视为同质图，这限制了对象之间的上下文感知性，而忽视了关系往往高度依赖于与关系相关联的对象这一事实。本文提出了一种无偏见的异构场景图生成（HetSGG）框架，利用消息传递神经网络捕获关系感知上下文。我们设计了一种新的消息传递层，称为关系感知消息传递神经网络（RMP），它考虑了对象之间的谓词类型，汇总了图像的上下文信息。所提出的HetSGG框架在基准数据集上取得了最新的性能，证明了关系感知消息传递对于SGG的有效性。

    Recent scene graph generation (SGG) frameworks have focused on learning complex relationships among multiple objects in an image. Thanks to the nature of the message passing neural network (MPNN) that models high-order interactions between objects and their neighboring objects, they are dominant representation learning modules for SGG. However, existing MPNN-based frameworks assume the scene graph as a homogeneous graph, which restricts the context-awareness of visual relations between objects. That is, they overlook the fact that the relations tend to be highly dependent on the objects with which the relations are associated. In this paper, we propose an unbiased heterogeneous scene graph generation (HetSGG) framework that captures relation-aware context using message passing neural networks. We devise a novel message passing layer, called relation-aware message passing neural network (RMP), that aggregates the contextual information of an image considering the predicate type between 
    
[^99]: Powderworld：通过多样化任务分布来理解泛化的平台

    Powderworld: A Platform for Understanding Generalization via Rich Task Distributions. (arXiv:2211.13051v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2211.13051](http://arxiv.org/abs/2211.13051)

    Powderworld是一个直接在GPU上运行的轻量级但表现力强的模拟环境，用于提供泛化性的研究平台，包括世界建模和强化学习。实验表明，增加环境的复杂性可以改善世界模型和某些强化学习代理的泛化性能。

    

    强化学习面临的重大挑战之一是能够泛化到新任务。然而，泛化代理需要一组丰富、多样化的任务进行训练。为这些任务设计一个理想的环境很困难——理想的环境应支持一系列新兴现象、丰富的任务空间和快速的运行时。为了解决这个瓶颈问题，本文提出了Powderworld，一个直接在GPU上运行的轻量级但表现力强的模拟环境。在Powderworld内，提出了两个激发挑战的分布，一个用于世界建模，一个用于强化学习。每个分布都包含手动设计的测试任务，以检查泛化性能。实验表明，增加环境的复杂性可以改善世界模型和某些强化学习代理的泛化性能，但可能会抑制高方差环境下的学习。Powderworld旨在通过提供一种支持泛化研究的环境来解决这个问题。

    One of the grand challenges of reinforcement learning is the ability to generalize to new tasks. However, general agents require a set of rich, diverse tasks to train on. Designing a `foundation environment' for such tasks is tricky -- the ideal environment would support a range of emergent phenomena, an expressive task space, and fast runtime. To take a step towards addressing this research bottleneck, this work presents Powderworld, a lightweight yet expressive simulation environment running directly on the GPU. Within Powderworld, two motivating challenges distributions are presented, one for world-modelling and one for reinforcement learning. Each contains hand-designed test tasks to examine generalization. Experiments indicate that increasing the environment's complexity improves generalization for world models and certain reinforcement learning agents, yet may inhibit learning in high-variance environments. Powderworld aims to support the study of generalization by providing a so
    
[^100]: 基于关系对称结构的知识图谱对比学习

    Knowledge Graph Contrastive Learning Based on Relation-Symmetrical Structure. (arXiv:2211.10738v4 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2211.10738](http://arxiv.org/abs/2211.10738)

    本论文提出了一种基于关系对称结构的知识图谱对比学习框架 KGE-SymCL，它能有效地提高知识图谱中实体的可区分度。

    

    知识图谱嵌入 (KGE) 旨在学习强大的表示以受益于各种人工智能应用。与此同时，对比学习已被广泛利用于图学习，作为增强所学表示的可区分能力的有效机制。然而，KG的复杂结构使得构建适当的对比对变得困难。为数不多的几个尝试将对比学习策略与KGE集成。但是，它们大多依赖于语言模型（例如Bert）进行对比对构建，而不是完全挖掘潜在的图结构信息，从而阻碍了表达能力。令人惊讶的是，我们发现关系对称结构内的实体通常相似且相关。因此，我们提出了一种基于关系对称结构的知识图谱对比学习框架，KGE-SymCL，它在KG中挖掘对称结构信息以增强所学表示的区分能力。

    Knowledge graph embedding (KGE) aims at learning powerful representations to benefit various artificial intelligence applications. Meanwhile, contrastive learning has been widely leveraged in graph learning as an effective mechanism to enhance the discriminative capacity of the learned representations. However, the complex structures of KG make it hard to construct appropriate contrastive pairs. Only a few attempts have integrated contrastive learning strategies with KGE. But, most of them rely on language models ( e.g., Bert) for contrastive pair construction instead of fully mining information underlying the graph structure, hindering expressive ability. Surprisingly, we find that the entities within a relational symmetrical structure are usually similar and correlated. To this end, we propose a knowledge graph contrastive learning framework based on relation-symmetrical structure, KGE-SymCL, which mines symmetrical structure information in KGs to enhance the discriminative ability o
    
[^101]: 基于超图的机器学习集成网络入侵检测系统

    A Hypergraph-Based Machine Learning Ensemble Network Intrusion Detection System. (arXiv:2211.03933v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2211.03933](http://arxiv.org/abs/2211.03933)

    该论文提出了一种基于超图的机器学习集成网络入侵检测系统，使用超图捕捉端口扫描攻击的演化模式，并使用派生的度量来训练NIDS，从而允许在高精度、高准确率、高召回率性能下实时监测和检测端口扫描活动、其他类型的攻击和敌对入侵，解决了传统NIDS面临的挑战。

    

    网络入侵检测系统(NIDS)在检测恶意攻击时仍然面临挑战。NIDS通常在离线状态下开发，但面对自动生成的端口扫描渗透尝试时，会导致从对手适应到NIDS响应的显着时间滞后。为了解决这些问题，我们使用以Internet协议地址和目标端口为重点的超图来捕捉端口扫描攻击的演化模式。然后使用派生的基于超图的度量来训练一个集成机器学习(ML)的NIDS，从而允许在高精度、高准确率、高召回率性能下实时调整，监测和检测端口扫描活动、其他类型的攻击和敌对入侵。这个ML自适应的NIDS是通过以下几个部分的组合开发出来的：(1)入侵示例，(2)NIDS更新规则，(3)触发NIDS重新训练请求的攻击阈值选择，以及(4)在没有先前网络性质知识的情况下的生产环境。

    Network intrusion detection systems (NIDS) to detect malicious attacks continue to meet challenges. NIDS are often developed offline while they face auto-generated port scan infiltration attempts, resulting in a significant time lag from adversarial adaption to NIDS response. To address these challenges, we use hypergraphs focused on internet protocol addresses and destination ports to capture evolving patterns of port scan attacks. The derived set of hypergraph-based metrics are then used to train an ensemble machine learning (ML) based NIDS that allows for real-time adaption in monitoring and detecting port scanning activities, other types of attacks, and adversarial intrusions at high accuracy, precision and recall performances. This ML adapting NIDS was developed through the combination of (1) intrusion examples, (2) NIDS update rules, (3) attack threshold choices to trigger NIDS retraining requests, and (4) a production environment with no prior knowledge of the nature of network 
    
[^102]: 异质因果效应估计中模型选择的实证分析

    Empirical Analysis of Model Selection for Heterogeneous Causal Effect Estimation. (arXiv:2211.01939v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.01939](http://arxiv.org/abs/2211.01939)

    本文在二元治疗条件下条件平均处理效应估计的场景中，对因果推断的模型选择问题进行了实证分析，利用最新的生成建模进展，提出了新的度量方法，证明了新的模型选择策略的有效性。

    

    我们研究了因果推断中的模型选择问题，特别是针对二元治疗条件下条件平均处理效应（CATE）估计的情况。与机器学习中的模型选择不同，由于我们无法观察到任何数据点的反事实潜在结果，因此没有完美的交叉验证模型。为此，文献中提出了各种代理度量方法，这些方法取决于从观察到的数据中估计的辅助干扰模型（倾向性得分模型、结果回归模型）。然而，这些度量方法的有效性仅在我们可以访问反事实数据的合成数据集上进行了研究。我们进行了广泛的实证分析，以评估文献中介绍的这些度量方法以及本研究中介绍的新方法的性能，在实现多个逼真数据集的最新生成建模进展基础上进行。我们的分析表明了新的模型选择策略的出现。

    We study the problem of model selection in causal inference, specifically for the case of conditional average treatment effect (CATE) estimation under binary treatments. Unlike model selection in machine learning, there is no perfect analogue of cross-validation as we do not observe the counterfactual potential outcome for any data point. Towards this, there have been a variety of proxy metrics proposed in the literature, that depend on auxiliary nuisance models estimated from the observed data (propensity score model, outcome regression model). However, the effectiveness of these metrics has only been studied on synthetic datasets as we can access the counterfactual data for them. We conduct an extensive empirical analysis to judge the performance of these metrics introduced in the literature, and novel ones introduced in this work, where we utilize the latest advances in generative modeling to incorporate multiple realistic datasets. Our analysis suggests novel model selection strate
    
[^103]: 对于代码生成模型，离线度量和人类价值判断的对齐。

    Aligning Offline Metrics and Human Judgments of Value for Code Generation Models. (arXiv:2210.16494v2 [cs.SE] UPDATED)

    [http://arxiv.org/abs/2210.16494](http://arxiv.org/abs/2210.16494)

    该论文通过一个用户研究表明，对于生成的代码而言，正确性评估不能完全反映大型语言模型协助程序员生成代码所提供的生产力提升，因此该论文提出了一种混合度量，结合了功能正确性和语法相似性，并且能够更好地代表真实世界的收益。

    

    大型语言模型已经展示了协助程序员生成代码的极大潜力。对于这种人工智能协作编程的情形，我们实证展示了生成的代码最常被评估的是其功能正确性（即生成是否通过了可用的单元测试），但是正确性并不能完全反映这些模型可能提供的生产率提升（例如可能会低估）。通过一项拥有N=49有经验的程序员的用户研究，我们展示了，尽管正确性对于高价值的生成有很好的体现，程序员依旧认为不能通过单元测试的代码如果能减少完成编码任务所需的总体工作量的话，其价值也是很高的。最后，我们提出了一种混合度量，结合了功能正确性和语法相似性，并展示了它能够以更强的相关性（14%）来衡量价值，因此可以更好地代表在评估和比较模型时的真实收益。

    Large language models have demonstrated great potential to assist programmers in generating code. For such human-AI pair programming scenarios, we empirically demonstrate that while generated code is most often evaluated in terms of their functional correctness (i.e., whether generations pass available unit tests), correctness does not fully capture (e.g., may underestimate) the productivity gains these models may provide. Through a user study with N = 49 experienced programmers, we show that while correctness captures high-value generations, programmers still rate code that fails unit tests as valuable if it reduces the overall effort needed to complete a coding task. Finally, we propose a hybrid metric that combines functional correctness and syntactic similarity and show that it achieves a 14% stronger correlation with value and can therefore better represent real-world gains when evaluating and comparing models.
    
[^104]: HELP ME THINK：一种帮助非专家使用模型创建定制内容的简单提示策略

    HELP ME THINK: A Simple Prompting Strategy for Non-experts to Create Customized Content with Models. (arXiv:2208.08232v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2208.08232](http://arxiv.org/abs/2208.08232)

    HELP ME THINK是一种帮助非专家用户创建定制化内容的简单提示策略，利用GPT3提出相关问题和利用用户答案执行任务，适用于各种需要重要思考的任务。

    

    控制语言模型生成的文本并定制内容一直是一个长期存在的挑战。现有的提示技术提出了为了提供控制而特定于任务的方法，并缺乏一般性；这为非专业用户找到适合其任务的方法提供了压倒性的选择。这些技术所涉及的工作，如编写示例、解释、指令等，进一步限制了它们在非专业用户中的采用率。在本文中，我们提出了一种名为HELP ME THINK的简单提示策略，鼓励GPT3通过提出一组相关问题和利用用户的答案来执行任务来帮助非专家用户。我们展示了我们的技术HELP ME THINK在各种任务上的功效。具体来说，我们关注难以完成且需要重要思考的任务。我们希望我们的工作将鼓励开发非传统的方式来利用大型语言模型的力量。

    Controlling the text generated by language models and customizing the content has been a long-standing challenge. Existing prompting techniques proposed in pursuit of providing control are task-specific and lack generality; this provides overwhelming choices for non-expert users to find a suitable method for their task. The effort associated with those techniques, such as in writing examples, explanations, instructions, etc. further limits their adoption among non-expert users. In this paper, we propose a simple prompting strategy HELP ME THINK where we encourage GPT3 to help non-expert users by asking a set of relevant questions and leveraging user answers to execute the task. We demonstrate the efficacy of our technique HELP ME THINK on a variety of tasks. Specifically, we focus on tasks that are hard for average humans and require significant thinking to perform. We hope our work will encourage the development of unconventional ways to harness the power of large language models.
    
[^105]: 如何重用和组合知识，实现终身任务学习：综述连续学习与功能组合方法

    How to Reuse and Compose Knowledge for a Lifetime of Tasks: A Survey on Continual Learning and Functional Composition. (arXiv:2207.07730v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2207.07730](http://arxiv.org/abs/2207.07730)

    本篇综述介绍了连续学习和功能组合方法的研究现状和未来联系，以实现人工智能在解决新问题时可以不断积累和组合知识的终身学习目标。

    

    人工智能的主要目标之一是创建一个能够获得对世界的普遍理解的代理。这种代理需要能够不断积累和建立知识，以应对遇到的新体验。终身或连续学习解决了这种情况，在这种情况下，代理面对不断的问题流，必须努力掌握解决每个新任务所需的知识。如果代理能够在某种组合表示形式中累积知识，则可以选择性地重用和组合相关的知识，构建新的解决方案。尽管这个简单的想法具有直观的吸引力，但是有关终身学习和组合学习的文献在很大程度上是分开进行的。为了促进两个领域之间的连接，本文概述了它们各自的研究景观，并讨论了它们之间现有和未来的联系。

    A major goal of artificial intelligence (AI) is to create an agent capable of acquiring a general understanding of the world. Such an agent would require the ability to continually accumulate and build upon its knowledge as it encounters new experiences. Lifelong or continual learning addresses this setting, whereby an agent faces a continual stream of problems and must strive to capture the knowledge necessary for solving each new task it encounters. If the agent is capable of accumulating knowledge in some form of compositional representation, it could then selectively reuse and combine relevant pieces of knowledge to construct novel solutions. Despite the intuitive appeal of this simple idea, the literatures on lifelong learning and compositional learning have proceeded largely separately. In an effort to promote developments that bridge between the two fields, this article surveys their respective research landscapes and discusses existing and future connections between them.
    
[^106]: 一种简单的联邦灾难援助政策声明性模型——透明度的建模和测量。

    A simple declarative model of the Federal Disaster Assistance Policy -- modelling and measuring transparency. (arXiv:2207.07392v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2207.07392](http://arxiv.org/abs/2207.07392)

    本研究量化分析了联邦灾难援助政策的一个简单模型，并从三个不同利益相关者的角度进行了评估，进而考虑了3种政策修改及其影响，旨在为各利益相关者的偏好排序提供参考。

    

    本文从三个不同利益相关者的角度，对联邦灾难援助政策的一个简单模型进行了数量分析。这种数量分析方法是新的，在其他领域如业务和医疗流程中也有应用。利益相关者对过程透明度很感兴趣，但每个人对透明度的具体定义都有不同的看法。我们还考虑了三种联邦灾难援助政策的修改，并分析了从利益相关者的角度看，每种政策下利益相关者满意度的变化情况。这种分析被用来对四种政策的偏好进行排序，以便考虑到所有集体利益相关者的偏好。

    In this paper we will provide a quantitative analysis of a simple model of the Federal Disaster Assistance policy from the viewpoint of three different stakeholders. This quantitative methodology is new and has applications to other areas such as business and healthcare processes. The stakeholders are interested in process transparency but each has a different opinion on precisely what constitutes transparency. We will also consider three modifications to the Federal Disaster Assistance policy and analyse, from a stakeholder viewpoint, how stakeholder satisfaction changes from process to process. This analysis is used to rank the favourability of four policies with respect to all collective stakeholder preferences.
    
[^107]: 智能化学习诊断统一可解释性框架在智慧教育中的应用

    A Unified Interpretable Intelligent Learning Diagnosis Framework for Smart Education. (arXiv:2207.03122v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2207.03122](http://arxiv.org/abs/2207.03122)

    本文提出了一种统一的可解释性智能学习诊断框架，结合了深度学习的表示学习能力和基于心理测量的方法的可解释性，使得在智慧教育中能够平衡准确性和可解释性。

    

    智能学习诊断是智能辅导系统的重要引擎，旨在估计学习者当前的知识掌握状况并预测其未来的学习表现。传统的学习诊断方法在诊断准确性和可解释性之间难以平衡。尽管现有的基于心理测量的学习诊断方法通过认知参数提供了一定领域解释，但它们对于大规模学习数据的建模能力不足。而基于深度学习的学习诊断方法虽然提高了学习表现预测的准确性，但其内在的黑盒特性导致缺乏可解释性，使得在教育应用中无法信任其结果。为解决以上问题，本文提出了统一可解释智能学习诊断框架，该框架结合了深度学习的强大表示学习能力和基于心理测量的方法的可解释性。该框架由深度神经网络诊断模块和认知参数解释模块两部分组成，两个模块相互补充，使得框架在准确性和可解释性之间达到平衡。实验结果表明，所提出的框架在准确性和可解释性方面优于现有的学习诊断方法。

    Intelligent learning diagnosis is a critical engine of intelligent tutoring systems, which aims to estimate learners' current knowledge mastery status and predict their future learning performance. The significant challenge with traditional learning diagnosis methods is the inability to balance diagnostic accuracy and interpretability. Although the existing psychometric-based learning diagnosis methods provide some domain interpretation through cognitive parameters, they have insufficient modeling capability with a shallow structure for large-scale learning data. While the deep learning-based learning diagnosis methods have improved the accuracy of learning performance prediction, their inherent black-box properties lead to a lack of interpretability, making their results untrustworthy for educational applications. To settle the above problem, the proposed unified interpretable intelligent learning diagnosis framework, which benefits from the powerful representation learning ability of
    
[^108]: 关于广义博弈中对策略承诺最佳私人收益操纵的研究

    Optimal Private Payoff Manipulation against Commitment in Extensive-form Games. (arXiv:2206.13119v2 [cs.GT] UPDATED)

    [http://arxiv.org/abs/2206.13119](http://arxiv.org/abs/2206.13119)

    研究了在广义博弈中追随者通过虚报收益函数实现最优操纵的问题，并提出了有效的算法来计算最佳操纵。

    

    为了利用策略承诺这一游戏策略，领导者必须学习足够的关于追随者的收益函数的信息。然而，这给了追随者提供虚假信息并影响最终游戏结果的机会。通过一个精心设计的收益函数，虚报给学习领导者，追随者可以引导一个对他有更多好处的结果，与他真实行为时的结果相比。我们研究了在广义博弈中通过这种策略行为实现最佳操纵的追随者。我们考虑到了追随者不同的态度。乐观的追随者为了获得真正的公用事业，最大化了所有可以通过某些收益函数引导出的游戏结果。悲观的追随者只考虑引导出一种惟一游戏结果的虚报收益函数。对于本文中考虑的所有设置，我们都描述了可以成功引导的所有可能游戏结果。我们证明了检查一个结果是否可以由追随者在某些给定游戏设定下最优地引导的复杂度是多项式可计算的，并提出了有效的算法来计算最佳操纵。

    To take advantage of strategy commitment, a useful tactic of playing games, a leader must learn enough information about the follower's payoff function. However, this leaves the follower a chance to provide fake information and influence the final game outcome. Through a carefully contrived payoff function misreported to the learning leader, the follower may induce an outcome that benefits him more, compared to the ones when he truthfully behaves.  We study the follower's optimal manipulation via such strategic behaviors in extensive-form games. Followers' different attitudes are taken into account. An optimistic follower maximizes his true utility among all game outcomes that can be induced by some payoff function. A pessimistic follower only considers misreporting payoff functions that induce a unique game outcome. For all the settings considered in this paper, we characterize all the possible game outcomes that can be induced successfully. We show that it is polynomial-time tractabl
    
[^109]: 与背景知识一致的计数马尔科夫等价有向无环图

    Counting Markov Equivalent Directed Acyclic Graphs Consistent with Background Knowledge. (arXiv:2206.06744v2 [cs.DS] UPDATED)

    [http://arxiv.org/abs/2206.06744](http://arxiv.org/abs/2206.06744)

    本文研究如何在给定一些边的方向已确定的情况下，计算马尔科夫等价类中的有向无环图数量，并且提出了一个计数算法，该算法运行时间受到一个多项式的约束。

    

    最近，Wienobst、Bannach和Liskiewicz（AAAI 2021）提出了一个计算马尔科夫等价类中有向无环图数量的多项式时间精确算法。本文考虑了更一般的问题，即在一些边的方向已确定的情况下计算马尔科夫等价类中的有向无环图数量（例如，在部分干预数据可用的情况下出现这种设置）。早期的研究表明，这个问题在复杂理论上是困难的。相反，我们发现该问题在一个有趣的实例类中仍然是可处理的，并建立了它的“固定参数可处理性”。特别地，我们的计数算法运行时间受到一个多项式的约束，并且这个多项式的度数\emph{不}依赖于提供的附加边的数量。

    A polynomial-time exact algorithm for counting the number of directed acyclic graphs in a Markov equivalence class was recently given by Wien\"obst, Bannach, and Li\'skiewicz (AAAI 2021). In this paper, we consider the more general problem of counting the number of directed acyclic graphs in a Markov equivalence class when the directions of some of the edges are also fixed (this setting arises, for example, when interventional data is partially available). This problem has been shown in earlier work to be complexity-theoretically hard. In contrast, we show that the problem is nevertheless tractable in an interesting class of instances, by establishing that it is ``fixed-parameter tractable''. In particular, our counting algorithm runs in time that is bounded by a polynomial in the size of the graph, where the degree of the polynomial does \emph{not} depend upon the number of additional edges provided as input.
    
[^110]: 时空联合图卷积网络用于交通预测

    Spatio-Temporal Joint Graph Convolutional Networks for Traffic Forecasting. (arXiv:2111.13684v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2111.13684](http://arxiv.org/abs/2111.13684)

    本文提出了一种称为STJGCN的方法，用于在多个未来时间步长上准确预测道路网络上的交通流量。该方法构建了预定义的和自适应的时空联合图以及在STJGs上执行图卷积运算，以提取时空特征并进行多步预测，并已在两个真实数据集上取得了优于现有最先进方法的结果。

    

    近期的研究将交通预测问题转化为一个时空图建模问题。通常，研究人员在每个时间步构建一个静态的空间图，然后用相邻时间步之间的节点连接表示为时空图。然而，这种方法未能明确反映不同时间步之间不同节点之间的相关性，从而限制了图神经网络的学习能力。此外，这些模型通过在不同时间步之间使用相同的邻接矩阵来忽略节点之间的动态时空相关性。为了解决这些限制，我们提出了一种称为时空联合图卷积网络 (STJGCN) 的新方法，用于在多个未来时间步骤上准确预测道路网络上的交通流量。具体而言，我们的方法包括构建预定义的和自适应的时空联合图 (STJGs) 以及在 STJGs 上执行图卷积运算以提取时空特征并进行多步预测。在两个真实数据集上的实验结果表明，我们的方法优于现有的最先进方法。

    Recent studies have shifted their focus towards formulating traffic forecasting as a spatio-temporal graph modeling problem. Typically, they constructed a static spatial graph at each time step and then connected each node with itself between adjacent time steps to create a spatio-temporal graph. However, this approach failed to explicitly reflect the correlations between different nodes at different time steps, thus limiting the learning capability of graph neural networks. Additionally, those models overlooked the dynamic spatio-temporal correlations among nodes by using the same adjacency matrix across different time steps. To address these limitations, we propose a novel approach called Spatio-Temporal Joint Graph Convolutional Networks (STJGCN) for accurate traffic forecasting on road networks over multiple future time steps. Specifically, our method encompasses the construction of both pre-defined and adaptive spatio-temporal joint graphs (STJGs) between any two time steps, which
    
[^111]: 开放世界特征外推问题的归纳图学习方法

    Towards Open-World Feature Extrapolation: An Inductive Graph Learning Approach. (arXiv:2110.04514v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2110.04514](http://arxiv.org/abs/2110.04514)

    本文提出了一种采用图表示和学习的方法，解决了处理开放世界特征外推问题的挑战，同时使用两种训练策略来实现对新特征的外推，并缓解特征层面的过拟合问题。

    

    本文解决了开放世界特征外推问题，其中输入数据的特征空间经过扩展，在部分观察到的特征上训练的模型需要处理测试数据中的新特征而无需重新训练。我们提出了一种新的采用图表示和学习的学习范式。我们的框架包含两个模块：1）骨干网络作为较低的模型，将特征作为输入并输出预测的标签；2）图神经网络作为较高的模型，通过在从观察到的数据构建的特征-数据图上进行消息传递，学习外推新特征的嵌入。基于我们的框架，我们设计了两种训练策略，一种是自监督方法，另一种是归纳学习方法，用于赋予模型外推能力并缓解特征层面的过拟合。我们还提供了理论分析。

    We target open-world feature extrapolation problem where the feature space of input data goes through expansion and a model trained on partially observed features needs to handle new features in test data without further retraining. The problem is of much significance for dealing with features incrementally collected from different fields. To this end, we propose a new learning paradigm with graph representation and learning. Our framework contains two modules: 1) a backbone network (e.g., feedforward neural nets) as a lower model takes features as input and outputs predicted labels; 2) a graph neural network as an upper model learns to extrapolate embeddings for new features via message passing over a feature-data graph built from observed data. Based on our framework, we design two training strategies, a self-supervised approach and an inductive learning approach, to endow the model with extrapolation ability and alleviate feature-level over-fitting. We also provide theoretical analy
    
[^112]: 不完整目标领域下的域自适应

    Domain Adaptation with Incomplete Target Domains. (arXiv:2012.01606v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2012.01606](http://arxiv.org/abs/2012.01606)

    本研究提出了一种基于不完整数据插补的对抗网络（IDIAN）模型，用于解决具有部分观察到的数据的不完整目标领域下的域自适应问题，实验结果表明该模型在跨域和实际适应任务中都具有良好的表现。

    

    域自适应是通过利用辅助源域中的现有标记数据来减少目标域注释成本的任务，已经引起了研究界的广泛关注。然而，标准的域自适应假设两个域中都有完全观察到的数据，而在实际应用中，缺少数据的存在是普遍的。在本文中，我们处理了更具挑战性的域自适应情景，即具有部分观察到的数据的不完整目标领域。我们提出了一种基于不完整数据插补的对抗网络（IDIAN）模型来解决这一新的域自适应挑战。在所提出的模型中，我们设计了一个数据插补模块来填补基于目标域局部观察到的数据中的缺失特征值，并通过深度对抗适应来对齐两个域。我们在跨域基准任务和具有不完整目标领域的实际适应任务上进行了实验。实验结果表明，与最先进的方法相比，我们所提出的IDIAN模型具有更好的性能。

    Domain adaptation, as a task of reducing the annotation cost in a target domain by exploiting the existing labeled data in an auxiliary source domain, has received a lot of attention in the research community. However, the standard domain adaptation has assumed perfectly observed data in both domains, while in real world applications the existence of missing data can be prevalent. In this paper, we tackle a more challenging domain adaptation scenario where one has an incomplete target domain with partially observed data. We propose an Incomplete Data Imputation based Adversarial Network (IDIAN) model to address this new domain adaptation challenge. In the proposed model, we design a data imputation module to fill the missing feature values based on the partial observations in the target domain, while aligning the two domains via deep adversarial adaption. We conduct experiments on both cross-domain benchmark tasks and a real world adaptation task with imperfect target domains. The expe
    
[^113]: 通过深度强化学习解决单轨列车调度问题

    Solving the single-track train scheduling problem via Deep Reinforcement Learning. (arXiv:2009.00433v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2009.00433](http://arxiv.org/abs/2009.00433)

    本文研究了通过深度强化学习解决单轨列车调度问题的方法，提出了两种不同的深度Q学习方法，并进行了数值评估。

    

    每天，铁路都会遇到网络和车队方面的干扰和破坏，影响铁路交通的稳定性。导致的延误会在网络中传播，导致货物和乘客的需求和供应失衡，进而导致服务质量下降。在这种情况下，人工交通控制员（所谓的调度员）的职责是尽力最小化其对交通的影响。然而，调度员不可避免地对其决策所产生的连锁反应的感知深度有限，尤其是它们如何影响超出其直接控制范围的网络区域。近年来，决策科学领域一直致力于开发自动解决问题和支持调度员的方法。本文研究了基于机器学习的方法来解决这个问题，提出了两种不同的深度Q学习方法（分散和集中）。数值结果表明...

    Every day, railways experience disturbances and disruptions, both on the network and the fleet side, that affect the stability of rail traffic. Induced delays propagate through the network, which leads to a mismatch in demand and offer for goods and passengers, and, in turn, to a loss in service quality. In these cases, it is the duty of human traffic controllers, the so-called dispatchers, to do their best to minimize the impact on traffic. However, dispatchers inevitably have a limited depth of perception of the knock-on effect of their decisions, particularly how they affect areas of the network that are outside their direct control. In recent years, much work in Decision Science has been devoted to developing methods to solve the problem automatically and support the dispatchers in this challenging task. This paper investigates Machine Learning-based methods for tackling this problem, proposing two different Deep Q-Learning methods(Decentralized and Centralized). Numerical results 
    

