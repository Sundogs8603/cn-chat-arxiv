# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Fisher-Weighted Merge of Contrastive Learning Models in Sequential Recommendation.](http://arxiv.org/abs/2307.05476) | 本文首次将Fisher合并方法应用于序列推荐中，通过合并多个模型的参数来改善整体性能，从而解决了实际挑战，具有推动最新技术的潜力。 |
| [^2] | [Bio-Inspired Night Image Enhancement Based on Contrast Enhancement and Denoising.](http://arxiv.org/abs/2307.05447) | 本文提出了一种基于对比度增强和降噪的生物启发式夜间图像增强算法，能够将低照度的夜间图像转换为更亮、更清晰的图像，同时能够抑制噪声。实验证明，该算法相对于其他算法具有明显优势。 |
| [^3] | [ISLTranslate: Dataset for Translating Indian Sign Language.](http://arxiv.org/abs/2307.05440) | ISLTranslate是一个包含31k个ISL-英语句子/短语对的最大连续印度手语翻译数据集，该数据集帮助开发手语翻译系统，解决印度手语资源匮乏的问题。 |
| [^4] | [Using BOLD-fMRI to Compute the Respiration Volume per Time (RTV) and Respiration Variation (RV) with Convolutional Neural Networks (CNN) in the Human Connectome Development Cohort.](http://arxiv.org/abs/2307.05426) | 该研究提出了一种使用卷积神经网络（CNN）和BOLD-fMRI计算人类连接组发展队列中呼吸体积与时间（RTV）和呼吸变异（RV）的方法。实验结果表明，CNN可以从静息状态的BOLD信号中捕捉有信息的特征，并重建真实的呼吸时序。这种方法可以降低fMRI研究的成本，并减轻参与者的负担。 |
| [^5] | [3D detection of roof sections from a single satellite image and application to LOD2-building reconstruction.](http://arxiv.org/abs/2307.05409) | 提出了一种名为KIBS的方法，通过使用仅一张卫星图像作为输入，采用全深度学习方法对建筑物的屋顶部分进行三维检测，实现了城市的3D重建。 |
| [^6] | [Domain-Agnostic Neural Architecture for Class Incremental Continual Learning in Document Processing Platform.](http://arxiv.org/abs/2307.05399) | 在文档处理平台中，我们提出了一种领域无关的神经架构，能够在每个类别的示例单独呈现时训练高性能分类器，无需使用记忆缓冲区，并在实验中取得了超越参考方法的结果。 |
| [^7] | [Handwritten Text Recognition Using Convolutional Neural Network.](http://arxiv.org/abs/2307.05396) | 这篇论文介绍了使用卷积神经网络进行手写文本识别的技术，并讨论了OCR和智能字符识别的概念和应用。 |
| [^8] | [Learned Kernels for Interpretable and Efficient PPG Signal Quality Assessment and Artifact Segmentation.](http://arxiv.org/abs/2307.05385) | 本文提出了一种通过学习核技术，具有解释性且参数较少的方法来评估和分割PPG信号的质量和伪影，与现有的深度神经网络方法相比有着类似甚至更好的性能。 |
| [^9] | [Protecting the Future: Neonatal Seizure Detection with Spatial-Temporal Modeling.](http://arxiv.org/abs/2307.05382) | 本文提出了一种名为STATENet的深度学习框架，通过精心设计在时空和模型层面上解决了新生儿癫痫检测中的独特挑战，实验证明了该框架能显著提高癫痫检测性能。 |
| [^10] | [Emotion Analysis on EEG Signal Using Machine Learning and Neural Network.](http://arxiv.org/abs/2307.05375) | 本研究利用机器学习和神经网络对EEG信号进行情绪分析，通过高效的信号处理技术提取特征和提高准确性，并使用支持向量机和K最近邻算法在DEAP Dataset上进行了情感状态的分类和测试。 |
| [^11] | [Classification of sleep stages from EEG, EOG and EMG signals by SSNet.](http://arxiv.org/abs/2307.05373) | 本研究提出了一个基于深度学习的SSNet框架，通过从EEG、EOG和EMG信号中提取特征，并将其输入到全连接层进行分类，成功实现了睡眠阶段的分类，并在两个公共数据集上获得了高准确度和Kappa系数的结果。 |
| [^12] | [A Physics-Informed Low-Shot Learning For sEMG-Based Estimation of Muscle Force and Joint Kinematics.](http://arxiv.org/abs/2307.05361) | 本文提出了一种基于物理信息的低样本学习方法，用于基于sEMG的肌肉力和关节运动学估计。该方法将拉格朗日运动方程和反动力学肌肉模型整合到生成对抗网络中，实现对小样本数据的结构化特征解码和外推估计。 |
| [^13] | [Unmasking the giant: A comprehensive evaluation of ChatGPT's proficiency in coding algorithms and data structures.](http://arxiv.org/abs/2307.05360) | 本文全面评估了ChatGPT在编码算法和数据结构方面的能力，基于最大的编码挑战目录，重点关注Python编程语言和数据结构算法两个基础主题。总结测试中ChatGPT的代码解决问题的准确性、代码质量和运行时错误的性质。 |
| [^14] | [Combating Data Imbalances in Federated Semi-supervised Learning with Dual Regulators.](http://arxiv.org/abs/2307.05358) | 本文提出了一种带有双调节器的新型联邦半监督学习框架FedDure，解决了数据分布不平衡的问题。通过粗调节器和细调节器对本地模型的更新进行规范，以及学习适应性加权方案，适应不同的数据分布。 |
| [^15] | [Over-the-Air Computation in OFDM Systems with Imperfect Channel State Information.](http://arxiv.org/abs/2307.05357) | 本文研究了在具有不完美信道状态信息的OFDM系统中的空中计算（AirComp），提出了针对最大努力计算任务和误差约束计算任务的优化方法，以最小化计算均方误差和计算失效概率。 |
| [^16] | [Unbiased Pain Assessment through Wearables and EHR Data: Multi-attribute Fairness Loss-based CNN Approach.](http://arxiv.org/abs/2307.05333) | 本文提出了一种基于多属性公平损失的CNN模型，通过考虑患者数据中的敏感属性，公平预测疼痛状态，致力于减少差异。 |
| [^17] | [The Value of Chess Squares.](http://arxiv.org/abs/2307.05330) | 本研究通过引入边际估值对国际象棋棋盘上的棋子和棋盘进行评价，提供了关于马、象和兵的有价值的见解。 |
| [^18] | [ProgGP: From GuitarPro Tablature Neural Generation To Progressive Metal Production.](http://arxiv.org/abs/2307.05328) | 本研究通过使用GuitarPro格式作为输入和输出的符号表示，利用173首渐进金属歌曲的自定义数据集，通过人工智能合作创作出渐进金属作品，并通过定量和定性分析验证了生成音乐的有效性。最终，将AI生成的音乐制作成完整的渐进金属歌曲，展示了模型的价值。 |
| [^19] | [Automatic Generation of Semantic Parts for Face Image Synthesis.](http://arxiv.org/abs/2307.05317) | 本文提出了一种网络架构，用于自动操作或生成语义分割掩膜中物体类别的形状，特别是人脸。该模型可以将分割掩膜嵌入到潜空间中，使每个类别嵌入可以独立编辑，从而实现对图像布局的自动操作。 |
| [^20] | [Masked Vision and Language Pre-training with Unimodal and Multimodal Contrastive Losses for Medical Visual Question Answering.](http://arxiv.org/abs/2307.05314) | 本文提出了一种使用单模态和多模态对比损失进行医学视觉问答的自监督预训练方法，在医学VQA任务中取得了最先进的性能。 |
| [^21] | [Unleashing Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration.](http://arxiv.org/abs/2307.05300) | 本论文提出了单人表现提示（SPP）的概念，通过与多个角色进行多轮自我协作，将单个语言模型转化为认知协同者，从而增强其在复杂任务中的问题解决能力和整体性能。 |
| [^22] | [On the Need for a Language Describing Distribution Shifts: Illustrations on Tabular Datasets.](http://arxiv.org/abs/2307.05284) | 该论文通过对表格数据集中的自然偏移进行研究，发现$Y|X$-偏移最为普遍。为了推动研究人员开发描述数据分布偏移的精细语言，作者构建了WhyShift实验平台，并讨论了$Y|X$-偏移对算法的影响。 |
| [^23] | [U-CREAT: Unsupervised Case Retrieval using Events extrAcTion.](http://arxiv.org/abs/2307.05260) | U-CREAT是一个无监督案例检索系统，通过使用事件提取实现了更高的性能和更快的检索速度，适用于实时案例检索系统。 |
| [^24] | [Integrated Planning in Hospitals: A Review.](http://arxiv.org/abs/2307.05258) | 本文综述了医院综合规划的运筹学和管理科学文献，强调了综合规划多个资源的潜力，并提供了关于不确定性建模和使用现实数据等方面的分析。 |
| [^25] | [Towards exploring adversarial learning for anomaly detection in complex driving scenes.](http://arxiv.org/abs/2307.05256) | 本文探索了对复杂驾驶场景中的异常检测使用对抗学习的性能，并分析了名为伯克利DeepDrive的数据集上的结果。 |
| [^26] | [Score Function Gradient Estimation to Widen the Applicability of Decision-Focused Learning.](http://arxiv.org/abs/2307.05213) | 本研究采用评分函数梯度估计方法，通过预测参数分布来计算决策焦点模型的更新，以扩大决策焦点学习的适用性。 |
| [^27] | [Contextual Pre-Planning on Reward Machine Abstractions for Enhanced Transfer in Deep Reinforcement Learning.](http://arxiv.org/abs/2307.05209) | 我们提出了一种使用奖励机器抽象来表示当前任务，并在迁移学习中提升DRL代理的性能的方法，实验表明该方法能够提高样本效率并在多个领域中进行少样本迁移。 |
| [^28] | [Differentially Private Statistical Inference through $\beta$-Divergence One Posterior Sampling.](http://arxiv.org/abs/2307.05194) | 通过对数据生成过程和模型之间的$\beta$-分解进行后验采样，我们提出了$\beta$D-Bayes，一种能够实现差分机器学习的方法。 |
| [^29] | [Co-Attention Gated Vision-Language Embedding for Visual Question Localized-Answering in Robotic Surgery.](http://arxiv.org/abs/2307.05182) | 这项研究提出了一种用于机器人手术中视觉问答定位的共同关注门控视觉-语言嵌入方法，可以为医学生和初级外科医生提供学习和理解手术视频的帮助。 |
| [^30] | [Enriching Verbal Feedback from Usability Testing: Automatic Linking of Thinking-Aloud Recordings and Stimulus using Eye Tracking and Mouse Data.](http://arxiv.org/abs/2307.05171) | 本文提出了一种自动分析口头协议的方法，并通过眼动和鼠标追踪测试了口头反馈和刺激之间的链接。这种方法可以将用户反馈与刺激的特定区域相关联，用于专家审核特定网页元素的反馈或可视化反馈给出的网页部分。 |
| [^31] | [Neural Quantile Optimization for Edge-Cloud Computing.](http://arxiv.org/abs/2307.05170) | 这项研究提出了一种神经分位数优化的方法，用于边缘云计算网络中找到最佳的流量分配方案。通过引入Gumbel-softmax采样网络，可以有效地解决优化问题并显著优于随机策略。 |
| [^32] | [SuryaKiran at MEDIQA-Sum 2023: Leveraging LoRA for Clinical Dialogue Summarization.](http://arxiv.org/abs/2307.05162) | 本研究展示了一种名为LoRA的参数高效细调方法在临床对话摘要中的评估结果，并证明LoRA与对大型语言模型进行端到端细调效果相当。 |
| [^33] | [On the Effectiveness of Speech Self-supervised Learning for Music.](http://arxiv.org/abs/2307.05161) | 本研究探索了语音自我监督学习在音乐信息检索中的有效性。通过对两个与语音相关的模型进行自我监督学习适应，并在多个MIR任务上进行系统评估，结果显示在音乐数据上训练可以提高MIR任务的性能。 |
| [^34] | [Stable Normative Explanations: From Argumentation to Deontic Logic.](http://arxiv.org/abs/2307.05156) | 本文研究了如何在形式论证的背景下表达稳定解释概念，并探讨了这种重建的德义含义。其中的重要贡献是展示了如何基于论证邻域结构构建德义逻辑的解释概念。 |
| [^35] | [A Modal Logic for Explaining some Graph Neural Networks.](http://arxiv.org/abs/2307.05150) | 本文提出了一种模态逻辑，通过线性不等式中的计数模态来解释图神经网络。作者证明了可将公式转化为等价的GNN，同时也证明了可将GNN转化为公式。作者还证明了可满足性问题是可判定的，并讨论了一些PSPACE中的变体。 |
| [^36] | [TIAM -- A Metric for Evaluating Alignment in Text-to-Image Generation.](http://arxiv.org/abs/2307.05134) | 本文提出了一种评估文本到图像生成中对齐性的新度量方法TIAM，该方法基于提示模板，可以更好地描述生成图像与提示中内容的对齐程度，包括对象类型、数量和颜色。研究结果表明，图像质量可以有很大的变化。 |
| [^37] | [A Deep Dive into Perturbations as Evaluation Technique for Time Series XAI.](http://arxiv.org/abs/2307.05104) | 本研究深入探讨了使用扰动作为评估从时间序列模型中提取的归因的方法。通过对多种XAI技术的应用和在多个数据集上进行验证，结果表明扰动分析可以有效评估归因的质量，并为其优点和局限性提供了洞察力。 |
| [^38] | [ATWM: Defense against adversarial malware based on adversarial training.](http://arxiv.org/abs/2307.05095) | 本文提出了一种基于对抗训练的对抗恶意软件防御方法，通过预处理降低简单的对抗样本的防御难度，并通过对抗训练提高模型的对抗防御能力。 |
| [^39] | [OntoChatGPT Information System: Ontology-Driven Structured Prompts for ChatGPT Meta-Learning.](http://arxiv.org/abs/2307.05082) | 本研究提出了一种利用本体驱动的结构化提示系统与ChatGPT进行元学习相互结合的方法。通过在康复领域的应用实现了该技术，并展示了该方法的多功能性和适用性。 |
| [^40] | [Uni-Removal: A Semi-Supervised Framework for Simultaneously Addressing Multiple Degradations in Real-World Images.](http://arxiv.org/abs/2307.05075) | 本文提出了Uni-Removal，这是一个半监督框架，用于解决实际图像中的多个退化问题。通过知识传递和域适应两个阶段的训练，该框架可以使用统一模型和参数来处理不同类型的退化，并取得有希望的结果 |
| [^41] | [Retrieval-augmented GPT-3.5-based Text-to-SQL Framework with Sample-aware Prompting and Dynamic Revision Chain.](http://arxiv.org/abs/2307.05074) | 本文提出了一种基于检索增强的GPT-3.5文本到SQL框架，采用了样本感知引导和动态修订链的方法，以应对现有方法在处理语义差距较大的检索示例时面临的挑战。 |
| [^42] | [Aggregating Credences into Beliefs: Agenda Conditions for Impossibility Results.](http://arxiv.org/abs/2307.05072) | 本文研究了二值化信念聚合的议程条件，证明了路径连接和甚至可否性是产生组织结果的必要条件，并探讨了不同条件下的寡头统治现象。 |
| [^43] | [Mining for Unknown Unknowns.](http://arxiv.org/abs/2307.05071) | 本论文使用形式概念分析（FCA）框架，旨在系统地挖掘和寻找未知未知，从而避免潜在的重大收益或损失。 |
| [^44] | [Cognitive Bias and Belief Revision.](http://arxiv.org/abs/2307.05069) | 本文介绍了在信念修正框架下对确认偏差、框架偏差和锚定偏差的形式化描述，并应用于三种常见的信念修正方法。研究结果发现这些偏差对于追踪真相是有影响的，并通过计算机模拟评估了其在随机情境下的性能。 |
| [^45] | [A Theory of Bounded Inductive Rationality.](http://arxiv.org/abs/2307.05068) | 本论文的主要贡献是提出了一个不假设逻辑全知性的理性决策理论，该理论可用于解决在现实环境中存在计算复杂性和无法对自身进行全面分析的决策问题。 |
| [^46] | [Exploiting Asymmetry in Logic Puzzles: Using ZDDs for Symbolic Model Checking Dynamic Epistemic Logic.](http://arxiv.org/abs/2307.05067) | 通过使用ZDDs替代BDDs，可以显著减少模型检查多代理系统的内存使用。 |
| [^47] | [Tableaux for the Logic of Strategically Knowing How.](http://arxiv.org/abs/2307.05066) | 本文提出了战略性知道如何逻辑的表格法，并证明了其完备性和正确性。此外，还证明了该逻辑的可满足性问题可以在PSPACE中解决。 |
| [^48] | [System of Spheres-based Two Level Credibility-limited Revisions.](http://arxiv.org/abs/2307.05062) | 本文提出了基于球体系统的两级可信度限制修正操作符的构造，并对这些操作符进行了公理化刻画。 |
| [^49] | [On Imperfect Recall in Multi-Agent Influence Diagrams.](http://arxiv.org/abs/2307.05059) | 本论文研究了多智能体影响图中的记忆缺失问题，提出了利用混合策略和两种类型的相关均衡来解决带有健忘和疏忽智能体的方法，并分析了关键决策问题的计算复杂性和可计算的情况。 |
| [^50] | [Strengthening Consistency Results in Modal Logic.](http://arxiv.org/abs/2307.05053) | 本文提出了通用理论来解决模态逻辑中一致性结果的问题，通过提供一种标准的背景知识模块来进行范畴决策。这些结果和方法有助于阐明认识论中的问题，并且可以解决与判断、推理和决策中模态相关的问题。 |
| [^51] | [Towards Understanding In-Context Learning with Contrastive Demonstrations and Saliency Maps.](http://arxiv.org/abs/2307.05052) | 本研究探索了对比演示和显著性图在上下文学习中的作用，并发现改变标签对显著性有显著影响，尤其对于更大的语言模型更为明显。在情感分析任务中，将表达情感的术语改为中性词并不像改变标签那样具有显著影响。另外，补充解释在提高上下文学习方面是有效的。 |
| [^52] | [Epistemic Syllogistic: First Steps.](http://arxiv.org/abs/2307.05043) | 本文介绍了认识主义三段论的几种变体，集中在包含非平凡但自然表达式的de re解释上。主要贡献是提出了这些逻辑的几个公理化，并给出了完备性证明。 |
| [^53] | [Neural-Symbolic Recommendation with Graph-Enhanced Information.](http://arxiv.org/abs/2307.05036) | 本研究结合了图神经网络和命题逻辑操作的优势，构建了一个具有全局隐式推理能力和局部显式逻辑推理能力的神经符号推荐模型。 |
| [^54] | [Unleashing the Potential of Regularization Strategies in Learning with Noisy Labels.](http://arxiv.org/abs/2307.05025) | 我们研究表明，结合交叉熵损失和正则化策略（如学习率衰减、模型权重平均和数据增强）的简单基准方法可以超过最先进方法，证明了正则化策略的组合在学习嘈杂标签问题中的潜力。 |
| [^55] | [Feature Activation Map: Visual Explanation of Deep Learning Models for Image Classification.](http://arxiv.org/abs/2307.05017) | 本文提出了一种名为特征激活映射（FAM）的解释工具，可以解释没有FC层的深度学习模型作为分类器，使其更加可解释、透明和可信。 |
| [^56] | [Control as Probabilistic Inference as an Emergent Communication Mechanism in Multi-Agent Reinforcement Learning.](http://arxiv.org/abs/2307.05004) | 本文提出了一种将控制与概率推理结合的新颖的通信机制，应用于多智能体强化学习中。智能体通过推理控制其动作，并通过消息进行通信，从而实现协作任务。 |
| [^57] | [Selective Sampling and Imitation Learning via Online Regression.](http://arxiv.org/abs/2307.04998) | 本论文提出了一种通过在线回归实现选择性采样和模仿学习的方法，解决了在只有噪声专家反馈的情况下的问题。算法不需要大量样本即可成功，并取得了最佳的回归和查询次数界限。 |
| [^58] | [Empowering recommender systems using automatically generated Knowledge Graphs and Reinforcement Learning.](http://arxiv.org/abs/2307.04996) | 本文介绍了两种基于知识图谱的方法，一种使用强化学习，另一种使用XGBoost算法，用于个性化文章推荐。这些方法利用自动生成的知识图谱，并在一个大型跨国金融服务公司的客户中进行了实证研究。 |
| [^59] | [Monotone deep Boltzmann machines.](http://arxiv.org/abs/2307.04990) | 在这项工作中，我们提出了一种新的限制模型，即单调DBM，它允许每一层具有任意的自连接，但通过一种方式限制了权重，以保证存在和全局唯一的均场不动点。 |
| [^60] | [Epidemic Modeling with Generative Agents.](http://arxiv.org/abs/2307.04986) | 本研究利用生成型智能体在流行病模型中模拟了人类行为，通过模拟实验展示了智能体的行为与真实世界相似，并成功实现了流行病曲线的平坦化。该研究创造了改进动态系统建模的潜力，为表示人类思维、推理和决策提供了一种途径。 |
| [^61] | [Secrets of RLHF in Large Language Models Part I: PPO.](http://arxiv.org/abs/2307.04964) | 本论文研究了大型语言模型中RLHF的秘密，重点关注了奖励模型、PPO和进程监督等技术路径，探索如何解决RLHF的稳定训练问题。 |
| [^62] | [Intrinsically motivated graph exploration using network theories of human curiosity.](http://arxiv.org/abs/2307.04962) | 在这项工作中，我们通过应用人类好奇心的两个理论，发展了一种内在驱动的图探索方法。我们利用图神经网络的强化学习将拓扑特征作为奖励，从而实现了对图结构数据的探索。在多类合成生成图上进行的实验证明，我们的方法不仅可以推广到更大的环境，还可以进行更长的探索步行。同时，我们的方法比传统的贪婪评估方法更高效。 |
| [^63] | [Reinforcement Learning with Non-Cumulative Objective.](http://arxiv.org/abs/2307.04957) | 本文研究了最优控制和强化学习中非累积目标的挑战，并提出了修改现有算法的方法来优化这些目标。研究结果表明，在贝尔曼最优性方程中使用广义运算可以更好地处理非累积目标。 |
| [^64] | [Learning to Solve Constraint Satisfaction Problems with Recurrent Transformer.](http://arxiv.org/abs/2307.04895) | 循环Transformer是一种可行的方法来学习解决约束满足问题。相比于类似的方法，循环Transformer具有明显的优势，可以处理视觉输入，成功解决符号基础问题，并实现样本高效学习和半监督学习。 |
| [^65] | [Choosing Well Your Opponents: How to Guide the Synthesis of Programmatic Strategies.](http://arxiv.org/abs/2307.04893) | 这篇论文介绍了一种名为2L的算法，该算法能够提供引导合成程序化策略的参考策略，通过在实验中的表现和在MicroRTS锦标赛中的胜利，证明了2L算法相对于其他学习算法的优势。 |
| [^66] | [Measuring and Mitigating Interference in Reinforcement Learning.](http://arxiv.org/abs/2307.04887) | 本文提供了一种衡量强化学习中干扰的新方法，并且提出了一类在线感知算法来减轻干扰，这些算法在经典控制环境中提高了稳定性和性能。 |
| [^67] | [Fed-CPrompt: Contrastive Prompt for Rehearsal-Free Federated Continual Learning.](http://arxiv.org/abs/2307.04869) | 本文提出了一种名为Fed-CPrompt的方法，用于解决无重复学习的联邦持续学习中的遗忘问题。该方法通过异步提示学习和对比持续损失处理异步任务到达和异构数据分布，并在实验证明其在该领域取得了最先进的性能。 |
| [^68] | [Automated Detection of Gait Events and Travel Distance Using Waist-worn Accelerometers Across a Typical Range of Walking and Running Speeds.](http://arxiv.org/abs/2307.04866) | 该论文研究了使用腰部佩戴的加速计自动检测步态事件和行走距离的方法，通过分析市售智能手机加速计数据，实现了从广泛的步态速度范围中提取步态特征，可用于对Duchenne肌肉萎缩患儿和典型发育正常患者的评估。 |
| [^69] | [SHAP@k:Efficient and Probably Approximately Correct (PAC) Identification of Top-k Features.](http://arxiv.org/abs/2307.04850) | 本文提出了SHAP@k框架，旨在通过提高样本效率来解决Top-k特征识别问题，通过将问题转化为Explore-m问题并利用多臂赌博机的技术来实现。 |
| [^70] | [SigOpt Mulch: An Intelligent System for AutoML of Gradient Boosted Trees.](http://arxiv.org/abs/2307.04849) | SigOpt Mulch是一种智能系统，用于自动化调整梯度提升树模型的超参数。与其他现有系统不同，SigOpt Mulch是“模型感知型”的，能够针对GBTs进行更优化的性能调整，并且无需领域知识，帮助实现自动化实验。 |
| [^71] | [Dynamics of Temporal Difference Reinforcement Learning.](http://arxiv.org/abs/2307.04841) | 我们使用统计物理学的概念，研究了时间差分学习在线性函数逼近器下的典型学习曲线。我们发现由于子采样可能的轨迹空间而产生的随机半梯度噪声会导致值误差出现显著的平台。 |
| [^72] | [Amplifying Limitations, Harms and Risks of Large Language Models.](http://arxiv.org/abs/2307.04821) | 本文旨在扩大人工智能（AI）和大型语言模型（LLMs）的限制、伤害和风险，并指出当前关于AI的夸大炒作和误解。这有助于消除一些对AI技术的错误认识，并提醒人们注意由于这些限制而产生的实际伤害。 |
| [^73] | [S2vNTM: Semi-supervised vMF Neural Topic Modeling.](http://arxiv.org/abs/2307.04804) | S2vNTM是一种半监督的vMF神经主题建模方法，通过利用关键词的模式来识别潜在的主题，并优化主题关键词集的质量，提高了分类准确度，并且速度至少比基线模型快两倍。 |
| [^74] | [Applying human-centered AI in developing effective human-AI teaming: A perspective of human-AI joint cognitive systems.](http://arxiv.org/abs/2307.03913) | 本研究介绍了将人工智能与人类团队协作作为一种新的发展范式的方法，强调有效的人工智能与人类团队需要充分利用双方的独特能力，同时克服挑战和限制，提高联合表现。同时，该研究指出现有研究往往未考虑到动态、适应性和协作团队环境中人工智能的功能，呼吁加强关于人工智能与人类团队协作的研究。 |
| [^75] | [QI2 -- an Interactive Tool for Data Quality Assurance.](http://arxiv.org/abs/2307.03419) | 本文介绍了一种用于数据质量保证的交互工具QI2，该工具支持对多个数据质量方面的验证和定量数据质量要求的验证。通过在MNIST数据集上进行演示，展示了该方法的应用和优势。 |
| [^76] | [A Survey on Evaluation of Large Language Models.](http://arxiv.org/abs/2307.03109) | 本文综述了大型语言模型（LLMs）的评估方法，关注三个关键维度：评估什么、在哪里评估以及如何评估。评估任务包括自然语言处理、推理、医学应用、伦理学、教育、自然和社会科学、代理应用等多个领域。本文为社会层面对LLMs潜在风险的理解提供了重要参考。 |
| [^77] | [RecallM: An Architecture for Temporal Context Understanding and Question Answering.](http://arxiv.org/abs/2307.02738) | 本文介绍了一种名为RecallM的架构，用于创建可适应和可更新的长期记忆，以提升大型语言模型聊天机器人的时间理解能力。 |
| [^78] | [Defining data science: a new field of inquiry.](http://arxiv.org/abs/2306.16177) | 数据科学是一种新的研究范式，具有潜力和应用广泛性，在40多个学科、数百个研究领域和成千上万个应用中出现。然而，由于其起步阶段，目前存在许多定义的冗余和不一致性的问题。 |
| [^79] | [BayesFlow: Amortized Bayesian Workflows With Neural Networks.](http://arxiv.org/abs/2306.16015) | BayesFlow是一个Python库，提供了使用神经网络进行摊还贝叶斯推断的功能，用户可以在模型仿真上训练定制的神经网络，并将其用于任何后续应用。这种摊还贝叶斯推断能够快速准确地进行推断，并实现了对不可计算后验分布的近似。 |
| [^80] | [TrustGuard: GNN-based Robust and Explainable Trust Evaluation with Dynamicity Support.](http://arxiv.org/abs/2306.13339) | TrustGuard是一种基于GNN的信任评估模型，支持信任动态性，抗击鲁棒并提供解释能力，它的实验结果在准确性、鲁棒性和可解释性方面都优于其他方法。 |
| [^81] | [Are Large Language Models Really Good Logical Reasoners? A Comprehensive Evaluation From Deductive, Inductive and Abductive Views.](http://arxiv.org/abs/2306.09841) | 本文评估了大型语言模型的逻辑推理能力，选择了15个典型数据集，考虑了演绎、归纳、阿布达斯和混合推理形式，并选择了三个代表性的LLMs进行零样本、一次和三次的设置下评估。提出精细级别的评估方法。 |
| [^82] | [Smooth Monotonic Networks.](http://arxiv.org/abs/2306.01147) | 本文提出了一种新的神经网络模块--平滑min-max(SMM)网络，相比于传统的min-max(MM)神经网络结构简单易用，在单调建模方面表现优异。 |
| [^83] | [GPT4Graph: Can Large Language Models Understand Graph Structured Data ? An Empirical Evaluation and Benchmarking.](http://arxiv.org/abs/2305.15066) | 本文通过实证评估与基准测试，研究了大型语言模型（LLM）在理解图结构化数据方面的能力。我们发现目前的语言模型在这一领域存在一些限制，并提出了一些潜在的改进空间。 |
| [^84] | [Improving Code Example Recommendations on Informal Documentation Using BERT and Query-Aware LSH: A Comparative Study.](http://arxiv.org/abs/2305.03017) | 本研究使用BERT和Query-Aware LSH提高非正式文档中代码示例推荐的质量，重点关注于Stack Overflow上的Java编程语言。研究使用BERT将代码示例转换为数值向量。 |
| [^85] | [Qualitative Failures of Image Generation Models and Their Application in Detecting Deepfakes.](http://arxiv.org/abs/2304.06470) | 研究调查了图像生成模型的质量失误及其应用于检测Deepfakes，识别了五种定性缺陷。这些发现有助于改进模型并制定检测Deepfakes的策略。 |
| [^86] | [I2I: Initializing Adapters with Improvised Knowledge.](http://arxiv.org/abs/2304.02168) | 本文提出了一种称为ImprovisetoInitialize(I2I)的连续学习算法，通过提取先前学习的任务适配器的知识来为即将到来的任务初始化适配器。这使得从一个任务到另一个任务的知识传递更加高效。 |
| [^87] | [Joint Behavior and Common Belief.](http://arxiv.org/abs/2303.07185) | 这篇论文展示了即使没有共同信念，仍然可以发生自然的联合行为。并且提出了两种共同信念的变体，其中一种被证明在某种程度上是联合行为的必要且充分条件，并更容易实现。 |
| [^88] | [Distortion-Disentangled Contrastive Learning.](http://arxiv.org/abs/2303.05066) | 扭曲-解缠对比学习是一种自监督学习方法，通过使用单个损失函数提取失真不变表示并过滤掉失真变体表示，实现了可靠的性能，同时减少了对批次大小的依赖。该方法还解决了对宝贵的失真变体表示进行解缠和利用的问题，以及对增强策略的敏感性。 |
| [^89] | [SAINE: Scientific Annotation and Inference Engine of Scientific Research.](http://arxiv.org/abs/2302.14468) | SAINE是一个基于开源软件的科学注释和推理引擎，可提供更准确的分类，并在学术出版物领域有应用。用户研究表明，该系统能帮助我们更好地理解分类过程，促进透明度和科学研究的理解。愿意与科学界合作和收集反馈。 |
| [^90] | [Hierarchical Classification of Research Fields in the "Web of Science" Using Deep Learning.](http://arxiv.org/abs/2302.00390) | 本文提出了一个使用深度学习进行层次分类的系统，可以自动将学术出版物通过抽象进行分类，实现了对研究活动在不同层次结构中的全面分类，并允许跨学科和跨领域的单标签和多标签分类。 |
| [^91] | [Exploring Image Augmentations for Siamese Representation Learning with Chest X-Rays.](http://arxiv.org/abs/2301.12636) | 本研究系统地评估了不同的增强方法对学习到的胸部 X 光片异常检测的孪生表示的质量和鲁棒性的影响。结果显示，我们找到了一组能够产生良好泛化效果的鲁棒表示的增强方法。 |
| [^92] | [Adapting Neural Link Predictors for Complex Query Answering.](http://arxiv.org/abs/2301.12313) | 本文提出通过训练一个参数高效的分数适应模型来重新校准神经链接预测分数以解决神经链接预测器在复杂查询回答中的问题。 |
| [^93] | [ClimaX: A foundation model for weather and climate.](http://arxiv.org/abs/2301.10343) | ClimaX是一种灵活且可推广的深度学习模型，用于天气和气候科学，可以使用不同数据集进行训练。 |
| [^94] | [Collective Privacy Recovery: Data-sharing Coordination via Decentralized Artificial Intelligence.](http://arxiv.org/abs/2301.05995) | 本文研究了集体隐私恢复的问题，通过分散式人工智能实现数据共享的协同。研究发现，数据共享协调可以实现对隐私的显著恢复，并带来双赢效果。 |
| [^95] | [Distributed Pruning Towards Tiny Neural Networks in Federated Learning.](http://arxiv.org/abs/2212.01977) | 该论文提出了FedTiny，一个用于联邦学习的分布式剪枝框架，可以为内存和计算受限的设备生成专门的小型模型。在这里，作者引入了自适应的批归一化选择模块来解决剪枝中的偏差问题。 |
| [^96] | [Adversarial Cheap Talk.](http://arxiv.org/abs/2211.11030) | 本文提出了一种新型对抗性设置，在其中对手只能将信息附加到受害者的观察中，从而产生最小的影响范围，并提出对抗性廉价交流（ACT）算法进行对手训练。在高度受限的情况下，使用ACT训练的对手仍会对受害者的训练和测试表现产生显著影响，揭示了强化学习算法中的一种新的攻击向量。 |
| [^97] | [Forming Trees with Treeformers.](http://arxiv.org/abs/2207.06960) | 本文介绍了一种Treeformer模块，它借鉴了CKY算法，通过学习组合运算符和汇聚函数来构建短语和句子的层次编码，从而将层次结构纳入Transformer模型中。实验证明，这种模块在组合泛化和各种自然语言任务中取得了显著的改进。 |
| [^98] | [BTPK-based interpretable method for NER tasks based on Talmudic Public Announcement Logic.](http://arxiv.org/abs/2201.09523) | 本文提出了一种基于Talmudic Public Announcement Logic的新颖解释性方法BTPK，用于帮助用户理解命名实体识别任务的内部逻辑，同时能够捕捉句子中的语义信息和上下文依赖关系。 |
| [^99] | [Isotuning With Applications To Scale-Free Online Learning.](http://arxiv.org/abs/2112.14586) | 我们提出了一种用于无标度在线学习的等调节技术，该技术具有快速、自适应、随时随地和无标度的特点，并可以自动适应遗憾的速率。同时，我们还引入了在线校正的方法来改进算法的性能。 |
| [^100] | [Responsive parallelized architecture for deploying deep learning models in production environments.](http://arxiv.org/abs/2112.08933) | 本研究设计和提出了一个可响应的并行化架构，用于在实时生产环境中部署深度学习模型。采用层次化细化的标签注意力网络预测CV实体，并使用多个深度学习模型并行预测。通过选择轻量级微型Web框架和使用微服务来部署大型深度学习模型管道，达到在少于700毫秒的时间内解析普通CV的目的。 |
| [^101] | [The Less Intelligent the Elements, the More Intelligent the Whole. Or, Possibly Not?.](http://arxiv.org/abs/2012.12689) | 我们探讨了个体智能是否对于集体智能的产生是必要的，以及怎样的个体智能有利于更大的集体智能。在Lotka-Volterra模型中，我们发现了一些个体行为，特别是掠食者的行为，有利于与其他种群共存，但如果猎物和掠食者都足够智能以推断彼此的行为，共存将伴随着两个种群的无限增长。 |

# 详细

[^1]: 序列推荐中对比学习模型的Fisher加权合并

    Fisher-Weighted Merge of Contrastive Learning Models in Sequential Recommendation. (arXiv:2307.05476v1 [cs.IR])

    [http://arxiv.org/abs/2307.05476](http://arxiv.org/abs/2307.05476)

    本文首次将Fisher合并方法应用于序列推荐中，通过合并多个模型的参数来改善整体性能，从而解决了实际挑战，具有推动最新技术的潜力。

    

    随着在线平台和服务的指数增长，推荐系统已成为根据用户偏好识别相关物品的必备工具。序列推荐的领域旨在捕捉用户随时间变化的偏好。为了解决动态偏好，已提出了各种对比学习方法来应对推荐系统中由于有限的用户-物品交互而导致的数据稀疏性挑战。在本文中，我们首次将Fisher合并方法应用于序列推荐中，解决并解决了与之相关的实际挑战。这种方法通过合并多个模型的参数来确保鲁棒微调，从而改善整体性能。通过大量实验，我们证明了我们提出的方法的有效性，并突出了它们在序列学习和推荐系统中推动最新技术的潜力。

    Along with the exponential growth of online platforms and services, recommendation systems have become essential for identifying relevant items based on user preferences. The domain of sequential recommendation aims to capture evolving user preferences over time. To address dynamic preference, various contrastive learning methods have been proposed to target data sparsity, a challenge in recommendation systems due to the limited user-item interactions. In this paper, we are the first to apply the Fisher-Merging method to Sequential Recommendation, addressing and resolving practical challenges associated with it. This approach ensures robust fine-tuning by merging the parameters of multiple models, resulting in improved overall performance. Through extensive experiments, we demonstrate the effectiveness of our proposed methods, highlighting their potential to advance the state-of-the-art in sequential learning and recommendation systems.
    
[^2]: 基于对比度增强和降噪的生物启发式夜间图像增强

    Bio-Inspired Night Image Enhancement Based on Contrast Enhancement and Denoising. (arXiv:2307.05447v1 [cs.CV])

    [http://arxiv.org/abs/2307.05447](http://arxiv.org/abs/2307.05447)

    本文提出了一种基于对比度增强和降噪的生物启发式夜间图像增强算法，能够将低照度的夜间图像转换为更亮、更清晰的图像，同时能够抑制噪声。实验证明，该算法相对于其他算法具有明显优势。

    

    由于在许多智能监控系统中夜间目标检测和识别的准确性较低，夜间图像的质量至关重要。与相应的白天图像相比，夜间图像的特点是亮度低、对比度低和噪声高。本文提出了一种基于生物启发的图像增强算法，用于将低照度图像转换为更亮、更清晰的图像。与现有的生物启发式算法不同，所提出的方法不使用任何训练序列，而是依赖于一系列对比度增强和降噪算法的链条，而不使用任何形式的递归函数。我们的方法可以大大提高夜间图像的亮度和对比度，并抑制噪声。然后我们对真实实验和模拟实验进行了测试。两个结果都显示了提出的算法相对于对比度对、Meylan和Retinex的优势。

    Due to the low accuracy of object detection and recognition in many intelligent surveillance systems at nighttime, the quality of night images is crucial. Compared with the corresponding daytime image, nighttime image is characterized as low brightness, low contrast and high noise. In this paper, a bio-inspired image enhancement algorithm is proposed to convert a low illuminance image to a brighter and clear one. Different from existing bio-inspired algorithm, the proposed method doesn't use any training sequences, we depend on a novel chain of contrast enhancement and denoising algorithms without using any forms of recursive functions. Our method can largely improve the brightness and contrast of night images, besides, suppress noise. Then we implement on real experiment, and simulation experiment to test our algorithms. Both results show the advantages of proposed algorithm over contrast pair, Meylan and Retinex.
    
[^3]: ISLTranslate: 翻译印度手语的数据集

    ISLTranslate: Dataset for Translating Indian Sign Language. (arXiv:2307.05440v1 [cs.CL])

    [http://arxiv.org/abs/2307.05440](http://arxiv.org/abs/2307.05440)

    ISLTranslate是一个包含31k个ISL-英语句子/短语对的最大连续印度手语翻译数据集，该数据集帮助开发手语翻译系统，解决印度手语资源匮乏的问题。

    

    手语是全球许多听障人士的主要通信方式。最近，为了弥补听障社区与其他人群之间的沟通差距，提出了几个手语翻译数据集，以便开发统计手语翻译系统。然而，印度手语的资源匮乏。本资源论文介绍了ISLTranslate，一个用于连续印度手语（ISL）的翻译数据集，包含31k个ISL-英语句子/短语对。据我们所知，这是连续印度手语最大的翻译数据集。我们对数据集进行了详细分析。为了验证现有的端到端手语到口语翻译系统的性能，我们使用基于Transformer模型的ISL翻译对创建的数据集进行了基准测试。

    Sign languages are the primary means of communication for many hard-of-hearing people worldwide. Recently, to bridge the communication gap between the hard-of-hearing community and the rest of the population, several sign language translation datasets have been proposed to enable the development of statistical sign language translation systems. However, there is a dearth of sign language resources for the Indian sign language. This resource paper introduces ISLTranslate, a translation dataset for continuous Indian Sign Language (ISL) consisting of 31k ISL-English sentence/phrase pairs. To the best of our knowledge, it is the largest translation dataset for continuous Indian Sign Language. We provide a detailed analysis of the dataset. To validate the performance of existing end-to-end Sign language to spoken language translation systems, we benchmark the created dataset with a transformer-based model for ISL translation.
    
[^4]: 使用卷积神经网络（CNN）和BOLD-fMRI计算人类连接组发展队列中的呼吸体积与时间（RTV）和呼吸变异（RV）

    Using BOLD-fMRI to Compute the Respiration Volume per Time (RTV) and Respiration Variation (RV) with Convolutional Neural Networks (CNN) in the Human Connectome Development Cohort. (arXiv:2307.05426v1 [eess.SP])

    [http://arxiv.org/abs/2307.05426](http://arxiv.org/abs/2307.05426)

    该研究提出了一种使用卷积神经网络（CNN）和BOLD-fMRI计算人类连接组发展队列中呼吸体积与时间（RTV）和呼吸变异（RV）的方法。实验结果表明，CNN可以从静息状态的BOLD信号中捕捉有信息的特征，并重建真实的呼吸时序。这种方法可以降低fMRI研究的成本，并减轻参与者的负担。

    

    在许多fMRI研究中，呼吸信号不可用或质量不可接受。因此，无法直接从BOLD信号中去除低频呼吸变化。本研究提出了一种一维CNN模型，用于重建两个呼吸测量指标，RV和RVT。结果表明，CNN可以从静息状态的BOLD信号中捕捉有信息的特征，并重建真实的RV和RVT时序。预计这种方法的应用将降低fMRI研究的成本，减少复杂性，并减轻参与者的负担，因为他们不需要佩戴呼吸贝洛斯。

    In many fMRI studies, respiratory signals are unavailable or do not have acceptable quality. Consequently, the direct removal of low-frequency respiratory variations from BOLD signals is not possible. This study proposes a one-dimensional CNN model for reconstruction of two respiratory measures, RV and RVT. Results show that a CNN can capture informative features from resting BOLD signals and reconstruct realistic RV and RVT timeseries. It is expected that application of the proposed method will lower the cost of fMRI studies, reduce complexity, and decrease the burden on participants as they will not be required to wear a respiratory bellows.
    
[^5]: 单张卫星图像中屋顶部分的三维检测及其在LOD2建筑重建中的应用

    3D detection of roof sections from a single satellite image and application to LOD2-building reconstruction. (arXiv:2307.05409v1 [cs.CV])

    [http://arxiv.org/abs/2307.05409](http://arxiv.org/abs/2307.05409)

    提出了一种名为KIBS的方法，通过使用仅一张卫星图像作为输入，采用全深度学习方法对建筑物的屋顶部分进行三维检测，实现了城市的3D重建。

    

    从卫星光栅图像中重建城市区域的3D模型一直以来都是学术研究和工业研究的长期挑战。目前能够达到LOD2级别的方法主要基于几何学的过程，并且需要立体图像和/或激光雷达数据作为输入。本文提出了一种用于城市3D重建的方法，称为KIBS（通过分割进行关键点推理），它包括两个新颖的特点：i）一种用于屋顶部分的3D检测的全面深度学习方法，以及ii）仅使用一张（非正交的）卫星光栅图像作为模型输入。这是通过两个步骤实现的：i）通过Mask R-CNN模型对建筑物屋顶部分进行2D分割，并在RGB卫星光栅图像中混合这些分割像素，ii）通过另一个相同的Mask R-CNN模型通过全景分割推断出屋顶部分角点的高度到地面的距离，从而实现完整的3D重建。

    Reconstructing urban areas in 3D out of satellite raster images has been a long-standing and challenging goal of both academical and industrial research. The rare methods today achieving this objective at a Level Of Details $2$ rely on procedural approaches based on geometry, and need stereo images and/or LIDAR data as input. We here propose a method for urban 3D reconstruction named KIBS(\textit{Keypoints Inference By Segmentation}), which comprises two novel features: i) a full deep learning approach for the 3D detection of the roof sections, and ii) only one single (non-orthogonal) satellite raster image as model input. This is achieved in two steps: i) by a Mask R-CNN model performing a 2D segmentation of the buildings' roof sections, and after blending these latter segmented pixels within the RGB satellite raster image, ii) by another identical Mask R-CNN model inferring the heights-to-ground of the roof sections' corners via panoptic segmentation, unto full 3D reconstruction of t
    
[^6]: 在文档处理平台中用于类增量连续学习的领域无关神经架构

    Domain-Agnostic Neural Architecture for Class Incremental Continual Learning in Document Processing Platform. (arXiv:2307.05399v1 [cs.LG])

    [http://arxiv.org/abs/2307.05399](http://arxiv.org/abs/2307.05399)

    在文档处理平台中，我们提出了一种领域无关的神经架构，能够在每个类别的示例单独呈现时训练高性能分类器，无需使用记忆缓冲区，并在实验中取得了超越参考方法的结果。

    

    复杂系统中的生产部署要求机器学习架构对多个任务高效可用。特别需要注意的是分类问题，其中数据以流式方式到达，并且每个类别单独呈现。最近的随机梯度学习方法在这种设置中表现不佳，或者存在诸如内存缓冲区的限制，不能在现实场景中使用。因此，我们提出了一种基于专家混合模型的全可微架构，可以在每个类别的示例单独呈现时训练高性能分类器。我们进行了详尽的实验证明了其在各个领域的适用性和在线在生产环境中学习的能力。所提出的技术在没有记忆缓冲区的情况下达到了SOTA结果，并明显优于参考方法。

    Production deployments in complex systems require ML architectures to be highly efficient and usable against multiple tasks. Particularly demanding are classification problems in which data arrives in a streaming fashion and each class is presented separately. Recent methods with stochastic gradient learning have been shown to struggle in such setups or have limitations like memory buffers, and being restricted to specific domains that disable its usage in real-world scenarios. For this reason, we present a fully differentiable architecture based on the Mixture of Experts model, that enables the training of high-performance classifiers when examples from each class are presented separately. We conducted exhaustive experiments that proved its applicability in various domains and ability to learn online in production environments. The proposed technique achieves SOTA results without a memory buffer and clearly outperforms the reference methods.
    
[^7]: 使用卷积神经网络的手写文本识别

    Handwritten Text Recognition Using Convolutional Neural Network. (arXiv:2307.05396v1 [cs.CV])

    [http://arxiv.org/abs/2307.05396](http://arxiv.org/abs/2307.05396)

    这篇论文介绍了使用卷积神经网络进行手写文本识别的技术，并讨论了OCR和智能字符识别的概念和应用。

    

    OCR（光学字符识别）是一种技术，通过仅仅扫描文档，以电子速度全面识别手写和打印字符的字母数字识别。最近，对视觉数据的理解被称为智能字符识别（ICR）。智能字符识别（ICR）是可以将手写或打印字符的扫描转换为ASCII文本的OCR模块。ASCII数据是电子通信中数据编码的标准格式。ASCII为字母、数字、符号、空格和其他字符分配标准数值。更技术性地说，OCR是使用电子设备将二维文本信息转换为机器编码文本的过程。任何包含文字的机器书写或手写物体都可以通过扫描仪或只是文字的图片来识别。

    OCR (Optical Character Recognition) is a technology that offers comprehensive alphanumeric recognition of handwritten and printed characters at electronic speed by merely scanning the document. Recently, the understanding of visual data has been termed Intelligent Character Recognition (ICR). Intelligent Character Recognition (ICR) is the OCR module that can convert scans of handwritten or printed characters into ASCII text. ASCII data is the standard format for data encoding in electronic communication. ASCII assigns standard numeric values to letters, numeral, symbols, white-spaces and other characters. In more technical terms, OCR is the process of using an electronic device to transform 2-Dimensional textual information into machine-encoded text. Anything that contains text both machine written or handwritten can be scanned either through a scanner or just simply a picture of the text is enough for the recognition system to distinguish the text. The goal of this papers is to show t
    
[^8]: 学习核技术用于可解释和高效的PPG信号质量评估和伪影分割

    Learned Kernels for Interpretable and Efficient PPG Signal Quality Assessment and Artifact Segmentation. (arXiv:2307.05385v1 [eess.SP])

    [http://arxiv.org/abs/2307.05385](http://arxiv.org/abs/2307.05385)

    本文提出了一种通过学习核技术，具有解释性且参数较少的方法来评估和分割PPG信号的质量和伪影，与现有的深度神经网络方法相比有着类似甚至更好的性能。

    

    光电容抗(PPG)提供了一种低成本、非侵入性的方法来持续监测各种心血管参数。PPG信号由可穿戴设备产生，常常包含由外部因素(如人体运动)引起的大型伪影。为了确保对生理参数进行稳健和准确的提取，信号的损坏区域需要被正确地识别和处理。之前的方法依靠手工特征检测器或信号度量，结果性能不佳，或依靠深度神经网络(DNN)等机器学习技术，缺乏可解释性，计算和内存密集。在这项工作中，我们提出了一种新的方法，学习一小组可解释的卷积核，其性能与现有技术DNN方法相似，甚至更好，而参数数量比DNN方法少几个数量级。这项工作实现了高效、稳健和可解释的PPG信号质量评估和伪影分割。

    Photoplethysmography (PPG) provides a low-cost, non-invasive method to continuously monitor various cardiovascular parameters. PPG signals are generated by wearable devices and frequently contain large artifacts caused by external factors, such as motion of the human subject. In order to ensure robust and accurate extraction of physiological parameters, corrupted areas of the signal need to be identified and handled appropriately. Previous methodology relied either on handcrafted feature detectors or signal metrics which yield sub-optimal performance, or relied on machine learning techniques such as deep neural networks (DNN) which lack interpretability and are computationally and memory intensive. In this work, we present a novel method to learn a small set of interpretable convolutional kernels that has performance similar to -- and often better than -- the state-of-the-art DNN approach with several orders of magnitude fewer parameters. This work allows for efficient, robust, and int
    
[^9]: 保护未来: 基于时空建模的新生儿癫痫发作检测

    Protecting the Future: Neonatal Seizure Detection with Spatial-Temporal Modeling. (arXiv:2307.05382v1 [eess.SP])

    [http://arxiv.org/abs/2307.05382](http://arxiv.org/abs/2307.05382)

    本文提出了一种名为STATENet的深度学习框架，通过精心设计在时空和模型层面上解决了新生儿癫痫检测中的独特挑战，实验证明了该框架能显著提高癫痫检测性能。

    

    在新生儿重症监护病房，及时检测具有电脑脑电图（EEG）的新生儿的癫痫发作是一项常见但能拯救生命的实践。然而，实时监测需要人力大量投入，因此需要自动化的新生儿癫痫发作检测解决方案。此外，当前针对成人癫痫监测的自动化方法通常会因为以下原因而失败：（i）人脑中癫痫发作起始位置的动态变化；（ii）新生儿脑电图的不同电极配置以及（iii）不同受试对象之间的巨大分布变化。本文提出了一种名为STATENet的深度学习框架，通过精心设计在时空和模型层面上解决了独特的挑战。对真实的大规模新生儿脑电图数据集的实验表明，我们的框架在癫痫检测性能上取得了显著优势。

    A timely detection of seizures for newborn infants with electroencephalogram (EEG) has been a common yet life-saving practice in the Neonatal Intensive Care Unit (NICU). However, it requires great human efforts for real-time monitoring, which calls for automated solutions to neonatal seizure detection. Moreover, the current automated methods focusing on adult epilepsy monitoring often fail due to (i) dynamic seizure onset location in human brains; (ii) different montages on neonates and (iii) huge distribution shift among different subjects. In this paper, we propose a deep learning framework, namely STATENet, to address the exclusive challenges with exquisite designs at the temporal, spatial and model levels. The experiments over the real-world large-scale neonatal EEG dataset illustrate that our framework achieves significantly better seizure detection performance.
    
[^10]: 使用机器学习和神经网络对EEG信号进行情绪分析

    Emotion Analysis on EEG Signal Using Machine Learning and Neural Network. (arXiv:2307.05375v1 [eess.SP])

    [http://arxiv.org/abs/2307.05375](http://arxiv.org/abs/2307.05375)

    本研究利用机器学习和神经网络对EEG信号进行情绪分析，通过高效的信号处理技术提取特征和提高准确性，并使用支持向量机和K最近邻算法在DEAP Dataset上进行了情感状态的分类和测试。

    

    情绪对一个人的思考和与他人互动有着显著影响。它连接着一个人的感受和其行为，可以说它在某种程度上影响着一个人的生活决策。由于情绪的模式和反应因人而异，对其进行研究需要采用适用于广泛人群的有效方法。为了提取特征和提高准确性，情绪识别使用脑电波或EEG信号需要实施高效的信号处理技术。多种人机交互技术的方法一直在进行中，近年来，研究者们在利用脑信号自动理解情绪方面取得了巨大成功。在我们的研究中，我们使用支持向量机（SVM）和K最近邻（KNN）对从一个广为人知的公开数据集DEAP Dataset收集到的EEG信号进行了几种情感状态的分类和测试。

    Emotion has a significant influence on how one thinks and interacts with others. It serves as a link between how a person feels and the actions one takes, or it could be said that it influences one's life decisions on occasion. Since the patterns of emotions and their reflections vary from person to person, their inquiry must be based on approaches that are effective over a wide range of population regions. To extract features and enhance accuracy, emotion recognition using brain waves or EEG signals requires the implementation of efficient signal processing techniques. Various approaches to human-machine interaction technologies have been ongoing for a long time, and in recent years, researchers have had great success in automatically understanding emotion using brain signals. In our research, several emotional states were classified and tested on EEG signals collected from a well-known publicly available dataset, the DEAP Dataset, using SVM (Support Vector Machine), KNN (K-Nearest Ne
    
[^11]: 通过SSNet从EEG、EOG和EMG信号中分类睡眠阶段 (arXiv:2307.05373v1 [eess.SP])

    Classification of sleep stages from EEG, EOG and EMG signals by SSNet. (arXiv:2307.05373v1 [eess.SP])

    [http://arxiv.org/abs/2307.05373](http://arxiv.org/abs/2307.05373)

    本研究提出了一个基于深度学习的SSNet框架，通过从EEG、EOG和EMG信号中提取特征，并将其输入到全连接层进行分类，成功实现了睡眠阶段的分类，并在两个公共数据集上获得了高准确度和Kappa系数的结果。

    

    睡眠阶段的分类在诊断睡眠相关疾病，包括睡眠呼吸障碍(SDB)疾病中起着重要作用。在本研究中，我们提出了一个端到端的深度学习架构，命名为SSNet，它包括基于卷积神经网络（CNN）和长短时记忆（LSTM）的两个深度学习网络。两个深度学习网络从电眼图（EOG）、脑电图（EEG）和肌电图（EMG）信号的组合中提取特征，因为每个信号具有不同的特征，有助于睡眠阶段的分类。两个深度学习网络产生的特征被连接起来传递到全连接层用于分类。我们提出的模型在使用两个公共数据集Sleep-EDF Expanded dataset和ISRUC-Sleep dataset进行评估。睡眠-EDF Expanded数据集的三种睡眠阶段分类的准确性和Kappa系数分别为96.36%和93.40%。

    Classification of sleep stages plays an essential role in diagnosing sleep-related diseases including Sleep Disorder Breathing (SDB) disease. In this study, we propose an end-to-end deep learning architecture, named SSNet, which comprises of two deep learning networks based on Convolutional Neuron Networks (CNN) and Long Short Term Memory (LSTM). Both deep learning networks extract features from the combination of Electrooculogram (EOG), Electroencephalogram (EEG), and Electromyogram (EMG) signals, as each signal has distinct features that help in the classification of sleep stages. The features produced by the two-deep learning networks are concatenated to pass to the fully connected layer for the classification. The performance of our proposed model is evaluated by using two public datasets Sleep-EDF Expanded dataset and ISRUC-Sleep dataset. The accuracy and Kappa coefficient are 96.36% and 93.40% respectively, for classifying three classes of sleep stages using Sleep-EDF Expanded da
    
[^12]: 通过物理信息的低样本学习对基于sEMG的肌肉力和关节运动学进行估计

    A Physics-Informed Low-Shot Learning For sEMG-Based Estimation of Muscle Force and Joint Kinematics. (arXiv:2307.05361v1 [eess.SP])

    [http://arxiv.org/abs/2307.05361](http://arxiv.org/abs/2307.05361)

    本文提出了一种基于物理信息的低样本学习方法，用于基于sEMG的肌肉力和关节运动学估计。该方法将拉格朗日运动方程和反动力学肌肉模型整合到生成对抗网络中，实现对小样本数据的结构化特征解码和外推估计。

    

    面向基于表面肌电图（sEMG）的肌肉力和关节运动学估计，是实时生物力学分析中神经肌肉刺激、肌肉动力学和动力学之间动态相互作用的关键。深度神经网络（DNN）的最新进展表明，它们有潜力以全自动和可重复的方式改进生物力学分析。然而，生物力学分析的小样本性质和物理可解释性限制了DNN的应用。本文提出了一种新颖的物理信息低样本学习方法，用于基于sEMG的肌肉力和关节运动学估计。该方法将拉格朗日运动方程和反动力学肌肉模型无缝地整合到生成对抗网络（GAN）框架中，以实现对小样本数据的结构化特征解码和外推估计。具体而言，引入拉格朗日运动方程到生成模型中，以限制高层结构化解码过程。

    Muscle force and joint kinematics estimation from surface electromyography (sEMG) are essential for real-time biomechanical analysis of the dynamic interplay among neural muscle stimulation, muscle dynamics, and kinetics. Recent advances in deep neural networks (DNNs) have shown the potential to improve biomechanical analysis in a fully automated and reproducible manner. However, the small sample nature and physical interpretability of biomechanical analysis limit the applications of DNNs. This paper presents a novel physics-informed low-shot learning method for sEMG-based estimation of muscle force and joint kinematics. This method seamlessly integrates Lagrange's equation of motion and inverse dynamic muscle model into the generative adversarial network (GAN) framework for structured feature decoding and extrapolated estimation from the small sample data. Specifically, Lagrange's equation of motion is introduced into the generative model to restrain the structured decoding of the hig
    
[^13]: 揭开巨人的真面目：对ChatGPT在编码算法和数据结构方面的熟练程度进行全面评估

    Unmasking the giant: A comprehensive evaluation of ChatGPT's proficiency in coding algorithms and data structures. (arXiv:2307.05360v1 [cs.SE])

    [http://arxiv.org/abs/2307.05360](http://arxiv.org/abs/2307.05360)

    本文全面评估了ChatGPT在编码算法和数据结构方面的能力，基于最大的编码挑战目录，重点关注Python编程语言和数据结构算法两个基础主题。总结测试中ChatGPT的代码解决问题的准确性、代码质量和运行时错误的性质。

    

    大型语言模型(LLMs)的转变性影响深刻地重塑了人工智能(AI)技术领域。值得注意的是，ChatGPT在这些模型中有着独特之处，展示出卓越的多轮对话性能，并在多种语言中展示出对编码的熟练程度。在本文中，我们根据迄今为止最大的编码挑战目录对ChatGPT的编码能力进行了全面评估。我们的重点是Python编程语言，以及集中在数据结构和算法上的问题，这两个主题是计算机科学的基础。我们评估ChatGPT解决所提交问题的能力，评估其代码质量以及代码引发的运行时错误的性质。当ChatGPT的代码成功执行但未能解决手头问题时，我们会研究通过的测试案例中的模式，以了解ChatGPT代码中的错误之处。

    The transformative influence of Large Language Models (LLMs) is profoundly reshaping the Artificial Intelligence (AI) technology domain. Notably, ChatGPT distinguishes itself within these models, demonstrating remarkable performance in multi-turn conversations and exhibiting code proficiency across an array of languages. In this paper, we carry out a comprehensive evaluation of ChatGPT's coding capabilities based on what is to date the largest catalog of coding challenges. Our focus is on the python programming language and problems centered on data structures and algorithms, two topics at the very foundations of Computer Science. We evaluate ChatGPT for its ability to generate correct solutions to the problems fed to it, its code quality, and nature of run-time errors thrown by its code. Where ChatGPT code successfully executes, but fails to solve the problem at hand, we look into patterns in the test cases passed in order to gain some insights into how wrong ChatGPT code is in these 
    
[^14]: 使用双调节器解决联邦半监督学习中的数据不平衡问题

    Combating Data Imbalances in Federated Semi-supervised Learning with Dual Regulators. (arXiv:2307.05358v1 [cs.LG])

    [http://arxiv.org/abs/2307.05358](http://arxiv.org/abs/2307.05358)

    本文提出了一种带有双调节器的新型联邦半监督学习框架FedDure，解决了数据分布不平衡的问题。通过粗调节器和细调节器对本地模型的更新进行规范，以及学习适应性加权方案，适应不同的数据分布。

    

    联邦学习已经成为一种从分散异构数据中学习的流行方法。由于分散客户端上标签稀缺，联邦半监督学习（FSSL）出现以从少量标记数据中训练模型。现有的FSSL方法假设客户端之间的标签数据独立且具有相同分布，并且在客户端内部标记和未标记数据之间具有一致的类别分布。本文研究了FSSL的更实际和具有挑战性的情况，即数据分布不仅在客户端之间不同，在客户端内部标记和未标记数据之间也不同。为了解决这个挑战，本文提出了一种带有双调节器的新型FSSL框架，FedDure。FedDure通过粗调节器（C-reg）和细调节器（F-reg）解除了以前的假设：C-reg通过跟踪标记数据分布的学习效果来规范本地模型的更新；F-reg学习一个适应性加权方案，以适应客户端内不同的数据分布。

    Federated learning has become a popular method to learn from decentralized heterogeneous data. Federated semi-supervised learning (FSSL) emerges to train models from a small fraction of labeled data due to label scarcity on decentralized clients. Existing FSSL methods assume independent and identically distributed (IID) labeled data across clients and consistent class distribution between labeled and unlabeled data within a client. This work studies a more practical and challenging scenario of FSSL, where data distribution is different not only across clients but also within a client between labeled and unlabeled data. To address this challenge, we propose a novel FSSL framework with dual regulators, FedDure.} FedDure lifts the previous assumption with a coarse-grained regulator (C-reg) and a fine-grained regulator (F-reg): C-reg regularizes the updating of the local model by tracking the learning effect on labeled data distribution; F-reg learns an adaptive weighting scheme tailored f
    
[^15]: 在具有不完美信道状态信息的OFDM系统中的空中计算

    Over-the-Air Computation in OFDM Systems with Imperfect Channel State Information. (arXiv:2307.05357v1 [eess.SP])

    [http://arxiv.org/abs/2307.05357](http://arxiv.org/abs/2307.05357)

    本文研究了在具有不完美信道状态信息的OFDM系统中的空中计算（AirComp），提出了针对最大努力计算任务和误差约束计算任务的优化方法，以最小化计算均方误差和计算失效概率。

    

    本文研究了在具有不完美信道状态信息的正交频分复用（OFDM）系统中的空中计算（AirComp）。在该系统中，多个单天线无线设备（WDs）同时向多天线接入点（AP）发送未编码信号，用于在多个子载波上进行分布式功能计算。我们考虑了两种情景，即最大努力计算任务和误差约束计算任务，目标分别是最小化多个子载波上的平均计算均方误差（MSE）和计算失效概率。为此，我们联合优化了WDs的发送系数和AP的接收波束形成向量，同时考虑了单个WD的最大发送功率限制。首先，针对AP仅具有一个接收天线的特殊情况，我们提出了使用Lagr的半闭式全局最优解来解决这两个问题。

    This paper studies the over-the-air computation (AirComp) in an orthogonal frequency division multiplexing (OFDM) system with imperfect channel state information (CSI), in which multiple single-antenna wireless devices (WDs) simultaneously send uncoded signals to a multi-antenna access point (AP) for distributed functional computation over multiple subcarriers. In particular, we consider two scenarios with best-effort and error-constrained computation tasks, with the objectives of minimizing the average computation mean squared error (MSE) and the computation outage probability over the multiple subcarriers, respectively. Towards this end, we jointly optimize the transmit coefficients at the WDs and the receive beamforming vectors at the AP over subcarriers, subject to the maximum transmit power constraints at individual WDs. First, for the special case with a single receive antenna at the AP, we propose the semi-closed-form globally optimal solutions to the two problems using the Lagr
    
[^16]: 通过可穿戴设备和电子健康记录数据进行无偏见的疼痛评估：基于多属性公平损失的CNN方法

    Unbiased Pain Assessment through Wearables and EHR Data: Multi-attribute Fairness Loss-based CNN Approach. (arXiv:2307.05333v1 [eess.SP])

    [http://arxiv.org/abs/2307.05333](http://arxiv.org/abs/2307.05333)

    本文提出了一种基于多属性公平损失的CNN模型，通过考虑患者数据中的敏感属性，公平预测疼痛状态，致力于减少差异。

    

    多样化的健康数据（物联网、电子健康记录和临床调查）与可扩展的适应性人工智能相结合，已经实现了对疼痛状态的身体、行为和心理社交指标的发现。尽管以技术进步改变医疗系统的热情和承诺，但临床疼痛评估中的人工智能应用受到了问题本身的多样性和个性化以及公平性等其他挑战的阻碍。研究表明，许多人工智能（如机器学习或深度学习）模型显示出偏见，并歧视特定人群（如基于性别或种族），这引起了医疗专业人员对人工智能适应性的怀疑。在本文中，我们提出了一种基于多属性公平损失的CNN模型，旨在考虑数据中包含的任何敏感属性，并公平预测患者的疼痛状态，同时尽量减少差异。

    The combination of diverse health data (IoT, EHR, and clinical surveys) and scalable-adaptable Artificial Intelligence (AI), has enabled the discovery of physical, behavioral, and psycho-social indicators of pain status. Despite the hype and promise to fundamentally alter the healthcare system with technological advancements, much AI adoption in clinical pain evaluation has been hampered by the heterogeneity of the problem itself and other challenges, such as personalization and fairness. Studies have revealed that many AI (i.e., machine learning or deep learning) models display biases and discriminate against specific population segments (such as those based on gender or ethnicity), which breeds skepticism among medical professionals about AI adaptability. In this paper, we propose a Multi-attribute Fairness Loss (MAFL) based CNN model that aims to account for any sensitive attributes included in the data and fairly predict patients' pain status while attempting to minimize the discre
    
[^17]: 棋盘上的棋子价值。 (arXiv:2307.05330v1 [cs.AI])

    The Value of Chess Squares. (arXiv:2307.05330v1 [cs.AI])

    [http://arxiv.org/abs/2307.05330](http://arxiv.org/abs/2307.05330)

    本研究通过引入边际估值对国际象棋棋盘上的棋子和棋盘进行评价，提供了关于马、象和兵的有价值的见解。

    

    我们的研究的主要目标是评估棋盘上棋子的价值，并确定棋子在棋盘上的摆放位置。随着国际象棋人工智能的出现，我们能够准确评估国际象棋局面的价值。传统方法对棋子赋予固定的价值$(\symking=\infty, \symqueen=9, \symrook=5, \symbishop=3, \symknight=3, \sympawn=1)$。我们通过引入棋子和棋盘方面的边际估值来改进这种分析。我们通过研究马和象的位置，并提供有关兵的价值的宝贵见解来演示我们的方法。值得注意的是，尼姆佐维奇是倡导兵的结构和价值的先驱之一。最后，我们提出了未来研究的潜在方向。

    Valuing chess squares and determining the placement of pieces on the board are the main objectives of our study. With the emergence of chess AI, it has become possible to accurately assess the worth of positions in a game of chess. The conventional approach assigns fixed values to pieces $(\symking=\infty, \symqueen=9, \symrook=5, \symbishop=3, \symknight=3, \sympawn=1)$. We enhance this analysis by introducing marginal valuations for both pieces and squares. We demonstrate our method by examining the positioning of Knights and Bishops, and also provide valuable insights into the valuation of pawns. Notably, Nimzowitsch was among the pioneers in advocating for the significance of Pawn structure and valuation. Finally, we conclude by suggesting potential avenues for future research.
    
[^18]: ProgGP: 从GuitarPro吉他指法生成到渐进式金属制作的研究

    ProgGP: From GuitarPro Tablature Neural Generation To Progressive Metal Production. (arXiv:2307.05328v1 [cs.SD])

    [http://arxiv.org/abs/2307.05328](http://arxiv.org/abs/2307.05328)

    本研究通过使用GuitarPro格式作为输入和输出的符号表示，利用173首渐进金属歌曲的自定义数据集，通过人工智能合作创作出渐进金属作品，并通过定量和定性分析验证了生成音乐的有效性。最终，将AI生成的音乐制作成完整的渐进金属歌曲，展示了模型的价值。

    

    在符号音乐生成领域的最新研究中，使用基于GuitarPro格式的分词作为输入和输出的符号表示，支持吉他表达属性，已经显示出价值。我们通过在ProgGP上对预训练的Transformer模型进行微调，扩展了这项工作，这是一个包含173首渐进金属歌曲的自定义数据集，目的是通过人工智能合作创造出该流派的作品。我们的模型能够生成多个吉他、贝斯吉他、鼓、钢琴和管弦乐部分。我们通过计算音乐学范式的数量分析和实践研究范式的质性分析相结合的混合方法来检验生成音乐的有效性。最后，我们通过将其用作工具，由人类金属音乐制作人基于AI生成的音乐进行全面制作和混音，展示了该模型的价值。

    Recent work in the field of symbolic music generation has shown value in using a tokenization based on the GuitarPro format, a symbolic representation supporting guitar expressive attributes, as an input and output representation. We extend this work by fine-tuning a pre-trained Transformer model on ProgGP, a custom dataset of 173 progressive metal songs, for the purposes of creating compositions from that genre through a human-AI partnership. Our model is able to generate multiple guitar, bass guitar, drums, piano and orchestral parts. We examine the validity of the generated music using a mixed methods approach by combining quantitative analyses following a computational musicology paradigm and qualitative analyses following a practice-based research paradigm. Finally, we demonstrate the value of the model by using it as a tool to create a progressive metal song, fully produced and mixed by a human metal producer based on AI-generated music.
    
[^19]: 自动生成面部图像合成的语义部件

    Automatic Generation of Semantic Parts for Face Image Synthesis. (arXiv:2307.05317v1 [cs.CV])

    [http://arxiv.org/abs/2307.05317](http://arxiv.org/abs/2307.05317)

    本文提出了一种网络架构，用于自动操作或生成语义分割掩膜中物体类别的形状，特别是人脸。该模型可以将分割掩膜嵌入到潜空间中，使每个类别嵌入可以独立编辑，从而实现对图像布局的自动操作。

    

    语义图像合成（SIS）指的是在给定定义物体类别空间布局的语义分割掩膜的情况下生成逼真图像的问题。大部分文献中的方法除了生成图像的质量外，还致力于解决如何增加样式（例如纹理）上的生成多样性的问题。然而，它们都忽略了另一个特征，即通过掩膜提供的布局可以进行操作的可能性。目前，唯一的实现方式是通过图形用户界面手动操作。在本文中，我们描述了一种网络架构，用于自动操作或生成语义分割掩膜中物体类别的形状，特别关注人脸。我们提出的模型允许将分割掩膜按类别嵌入到潜空间中，其中每个类别嵌入可以独立编辑。然后，一个双向LSTM块和一个卷积解码器输出一个新的、局部的图像。

    Semantic image synthesis (SIS) refers to the problem of generating realistic imagery given a semantic segmentation mask that defines the spatial layout of object classes. Most of the approaches in the literature, other than the quality of the generated images, put effort in finding solutions to increase the generation diversity in terms of style i.e. texture. However, they all neglect a different feature, which is the possibility of manipulating the layout provided by the mask. Currently, the only way to do so is manually by means of graphical users interfaces. In this paper, we describe a network architecture to address the problem of automatically manipulating or generating the shape of object classes in semantic segmentation masks, with specific focus on human faces. Our proposed model allows embedding the mask class-wise into a latent space where each class embedding can be independently edited. Then, a bi-directional LSTM block and a convolutional decoder output a new, locally man
    
[^20]: 使用单模态和多模态对比损失进行医学视觉问答的视觉与语言预训练

    Masked Vision and Language Pre-training with Unimodal and Multimodal Contrastive Losses for Medical Visual Question Answering. (arXiv:2307.05314v1 [cs.CV])

    [http://arxiv.org/abs/2307.05314](http://arxiv.org/abs/2307.05314)

    本文提出了一种使用单模态和多模态对比损失进行医学视觉问答的自监督预训练方法，在医学VQA任务中取得了最先进的性能。

    

    医学视觉问答(VQA)是一项具有挑战性的任务，需要通过考虑视觉和语言信息来回答给定医学图像的临床问题。然而，由于医学VQA训练数据规模较小，预训练微调范式已成为改善模型泛化性能的常用解决方案。本文提出了一种新的自监督方法，利用医学图像字幕数据集，通过采用单模态和多模态对比损失以及掩码语言建模和图像文本匹配作为预训练目标，学习输入图像和文本的单模态和多模态特征表示。然后将预训练模型迁移到下游医学VQA任务。所提出的方法在三个公开可用的医学VQA数据集上取得了最先进的性能，分别提高了2.2％，14.7％和1.7％的准确性。

    Medical visual question answering (VQA) is a challenging task that requires answering clinical questions of a given medical image, by taking consider of both visual and language information. However, due to the small scale of training data for medical VQA, pre-training fine-tuning paradigms have been a commonly used solution to improve model generalization performance. In this paper, we present a novel self-supervised approach that learns unimodal and multimodal feature representations of input images and text using medical image caption datasets, by leveraging both unimodal and multimodal contrastive losses, along with masked language modeling and image text matching as pretraining objectives. The pre-trained model is then transferred to downstream medical VQA tasks. The proposed approach achieves state-of-the-art (SOTA) performance on three publicly available medical VQA datasets with significant accuracy improvements of 2.2%, 14.7%, and 1.7% respectively. Besides, we conduct a compr
    
[^21]: 在大型语言模型中释放认知协同：通过多人格自我协作实现任务解决代理

    Unleashing Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration. (arXiv:2307.05300v1 [cs.AI])

    [http://arxiv.org/abs/2307.05300](http://arxiv.org/abs/2307.05300)

    本论文提出了单人表现提示（SPP）的概念，通过与多个角色进行多轮自我协作，将单个语言模型转化为认知协同者，从而增强其在复杂任务中的问题解决能力和整体性能。

    

    人类智慧依赖于认知协同的概念，即在不同认知过程之间进行协作和信息整合，以获得比个体认知过程更出色的结果。尽管大型语言模型（LLM）作为通用任务解决代理表现出了令人期待的性能，但它们在需要丰富领域知识和复杂推理的任务上仍然面临困难。在这项工作中，我们提出了单人表现提示（SPP）的概念，通过与多个角色进行多轮自我协作，将单个LLM转化为认知协同者。认知协同者指的是一个智能代理，与多个智慧合作，结合他们的个体优势和知识，从而增强复杂任务的问题解决能力和整体性能。通过根据任务输入动态识别和模拟不同的角色，SPP释放了LLM中认知协同的潜力。

    Human intelligence thrives on the concept of cognitive synergy, where collaboration and information integration among different cognitive processes yield superior outcomes compared to individual cognitive processes in isolation. Although Large Language Models (LLMs) have demonstrated promising performance as general task-solving agents, they still struggle with tasks that require intensive domain knowledge and complex reasoning. In this work, we propose Solo Performance Prompting (SPP), which transforms a single LLM into a cognitive synergist by engaging in multi-turn self-collaboration with multiple personas. A cognitive synergist refers to an intelligent agent that collaborates with multiple minds, combining their individual strengths and knowledge, to enhance problem-solving and overall performance in complex tasks. By dynamically identifying and simulating different personas based on task inputs, SPP unleashes the potential of cognitive synergy in LLMs. We have discovered that assi
    
[^22]: 关于需要描述分布偏移的语言：基于表格数据集的案例分析

    On the Need for a Language Describing Distribution Shifts: Illustrations on Tabular Datasets. (arXiv:2307.05284v1 [cs.LG])

    [http://arxiv.org/abs/2307.05284](http://arxiv.org/abs/2307.05284)

    该论文通过对表格数据集中的自然偏移进行研究，发现$Y|X$-偏移最为普遍。为了推动研究人员开发描述数据分布偏移的精细语言，作者构建了WhyShift实验平台，并讨论了$Y|X$-偏移对算法的影响。

    

    不同的分布偏移需要不同的算法和操作干预。方法研究必须以其所涉及的具体偏移为基础。尽管新兴的基准数据为实证研究提供了有希望的基础，但它们隐含地关注协变量偏移，并且实证发现的有效性取决于偏移类型，例如，当$Y|X$分布发生变化时，之前关于算法性能的观察可能无效。我们对5个表格数据集中的自然偏移进行了深入研究，通过对86,000个模型配置进行实验，发现$Y|X$-偏移最为普遍。为了鼓励研究人员开发一种精细的描述数据分布偏移的语言，我们构建了WhyShift，一个由策划的真实世界偏移测试平台，在其中我们对我们基准性能的偏移类型进行了表征。由于$Y|X$-偏移在表格设置中很常见，我们确定了受到最大$Y|X$-偏移影响的协变量区域，并讨论了对算法的影响。

    Different distribution shifts require different algorithmic and operational interventions. Methodological research must be grounded by the specific shifts they address. Although nascent benchmarks provide a promising empirical foundation, they implicitly focus on covariate shifts, and the validity of empirical findings depends on the type of shift, e.g., previous observations on algorithmic performance can fail to be valid when the $Y|X$ distribution changes. We conduct a thorough investigation of natural shifts in 5 tabular datasets over 86,000 model configurations, and find that $Y|X$-shifts are most prevalent. To encourage researchers to develop a refined language for distribution shifts, we build WhyShift, an empirical testbed of curated real-world shifts where we characterize the type of shift we benchmark performance over. Since $Y|X$-shifts are prevalent in tabular settings, we identify covariate regions that suffer the biggest $Y|X$-shifts and discuss implications for algorithm
    
[^23]: U-CREAT: 无监督事件提取的无监督案例检索系统

    U-CREAT: Unsupervised Case Retrieval using Events extrAcTion. (arXiv:2307.05260v1 [cs.IR])

    [http://arxiv.org/abs/2307.05260](http://arxiv.org/abs/2307.05260)

    U-CREAT是一个无监督案例检索系统，通过使用事件提取实现了更高的性能和更快的检索速度，适用于实时案例检索系统。

    

    在法律领域，先前案例检索的任务是自动引用与给定查询案例相关（基于事实和先例）的先前法律案例。为了进一步推动先前案例检索研究，本文提出了一个新的大型基准（以英文为主）用于先前案例检索任务：IL-PCR（印度法律先前案例检索）语料库。考虑到案例相关性的复杂性和法律文档的长度，BM25仍然是排名引用先前文档的强大基准。在这项工作中，我们探索了事件在法律案例检索中的作用，并提出一种基于无监督检索方法的管道系统U-CREAT（无监督事件提取的无监督案例检索系统）。我们发现，所提出的无监督检索方法与BM25相比显著提高了性能，并且使检索速度大大加快，使其适用于实时案例检索系统。我们的系统具有通用性，我们证明它适用于两个不同的法律体系（印度）。

    The task of Prior Case Retrieval (PCR) in the legal domain is about automatically citing relevant (based on facts and precedence) prior legal cases in a given query case. To further promote research in PCR, in this paper, we propose a new large benchmark (in English) for the PCR task: IL-PCR (Indian Legal Prior Case Retrieval) corpus. Given the complex nature of case relevance and the long size of legal documents, BM25 remains a strong baseline for ranking the cited prior documents. In this work, we explore the role of events in legal case retrieval and propose an unsupervised retrieval method-based pipeline U-CREAT (Unsupervised Case Retrieval using Events Extraction). We find that the proposed unsupervised retrieval method significantly increases performance compared to BM25 and makes retrieval faster by a considerable margin, making it applicable to real-time case retrieval systems. Our proposed system is generic, we show that it generalizes across two different legal systems (India
    
[^24]: 医院中的综合规划：一项综述

    Integrated Planning in Hospitals: A Review. (arXiv:2307.05258v1 [cs.AI])

    [http://arxiv.org/abs/2307.05258](http://arxiv.org/abs/2307.05258)

    本文综述了医院综合规划的运筹学和管理科学文献，强调了综合规划多个资源的潜力，并提供了关于不确定性建模和使用现实数据等方面的分析。

    

    1950年以来，高效规划医院稀缺资源是一项具有挑战性的任务，为此，已经开发了大量的运筹学和管理科学方法。尽管高效规划单一资源如手术室、床位或特定类型的医护人员已经能够带来巨大的效益，但综合规划多个资源被证明具有更大的潜力，在过去几十年的文献中已经提出了大量的综合规划方法。本文首次提供了关于医院不同资源综合规划的运筹学和管理科学文献的综述。我们收集了相关文献，并对不同方面进行分析，如不确定性建模和使用现实数据。几个交叉比较揭示了一些有趣的洞察，例如建模和求解之间的关系。

    Efficient planning of scarce resources in hospitals is a challenging task for which a large variety of Operations Research and Management Science approaches have been developed since the 1950s. While efficient planning of single resources such as operating rooms, beds, or specific types of staff can already lead to enormous efficiency gains, integrated planning of several resources has been shown to hold even greater potential, and a large number of integrated planning approaches have been presented in the literature over the past decades.  This paper provides the first literature review that focuses specifically on the Operations Research and Management Science literature related to integrated planning of different resources in hospitals. We collect the relevant literature and analyze it regarding different aspects such as uncertainty modeling and the use of real-life data. Several cross comparisons reveal interesting insights concerning, e.g., relations between the modeling and solut
    
[^25]: 探索对复杂驾驶场景中的异常检测的对抗学习

    Towards exploring adversarial learning for anomaly detection in complex driving scenes. (arXiv:2307.05256v1 [cs.CV])

    [http://arxiv.org/abs/2307.05256](http://arxiv.org/abs/2307.05256)

    本文探索了对复杂驾驶场景中的异常检测使用对抗学习的性能，并分析了名为伯克利DeepDrive的数据集上的结果。

    

    自动驾驶等自主系统执行各种安全关键功能。这些系统中的许多利用人工智能技术来感知环境。但是这些感知组件无法进行正式验证，因为基于人工智能的组件的准确性高度依赖于训练数据的质量。因此，基于机器学习的异常检测技术，用于识别不属于训练数据的数据，可以作为在开发和运行时安全度量指标使用。对抗学习是机器学习的一个子领域，在简单数据集上已经证明了它对图像和视频中异常的检测能力，取得了令人印象深刻的结果。因此，本研究探讨并深入分析了这些技术在名为伯克利DeepDrive的高度复杂驾驶场景数据集上的性能。

    One of the many Autonomous Systems (ASs), such as autonomous driving cars, performs various safety-critical functions. Many of these autonomous systems take advantage of Artificial Intelligence (AI) techniques to perceive their environment. But these perceiving components could not be formally verified, since, the accuracy of such AI-based components has a high dependency on the quality of training data. So Machine learning (ML) based anomaly detection, a technique to identify data that does not belong to the training data could be used as a safety measuring indicator during the development and operational time of such AI-based components. Adversarial learning, a sub-field of machine learning has proven its ability to detect anomalies in images and videos with impressive results on simple data sets. Therefore, in this work, we investigate and provide insight into the performance of such techniques on a highly complex driving scenes dataset called Berkeley DeepDrive.
    
[^26]: 评分函数梯度估计以扩大决策焦点学习的适用性

    Score Function Gradient Estimation to Widen the Applicability of Decision-Focused Learning. (arXiv:2307.05213v1 [cs.LG])

    [http://arxiv.org/abs/2307.05213](http://arxiv.org/abs/2307.05213)

    本研究采用评分函数梯度估计方法，通过预测参数分布来计算决策焦点模型的更新，以扩大决策焦点学习的适用性。

    

    许多现实世界的优化问题都包含需要在解决之前进行预测的未知参数。为了训练涉及的预测机器学习（ML）模型，通常采用的方法是专注于最大化预测准确性。然而，这种方法并不总是导致下游任务损失的最小化。决策焦点学习（DFL）是一种最近提出的范式，其目标是通过直接最小化任务损失来训练ML模型。然而，最先进的DFL方法受到它们对优化问题结构的假设（例如，问题是线性的）以及只能预测出现在目标函数中的参数的限制。在这项工作中，我们通过相反地预测参数的分布，并采用评分函数梯度估计（SFGE）来计算决策焦点模型的更新，从而扩大DFL的适用性。我们的实验...

    Many real-world optimization problems contain unknown parameters that must be predicted prior to solving. To train the predictive machine learning (ML) models involved, the commonly adopted approach focuses on maximizing predictive accuracy. However, this approach does not always lead to the minimization of the downstream task loss. Decision-focused learning (DFL) is a recently proposed paradigm whose goal is to train the ML model by directly minimizing the task loss. However, state-of-the-art DFL methods are limited by the assumptions they make about the structure of the optimization problem (e.g., that the problem is linear) and by the fact that can only predict parameters that appear in the objective function. In this work, we address these limitations by instead predicting \textit{distributions} over parameters and adopting score function gradient estimation (SFGE) to compute decision-focused updates to the predictive model, thereby widening the applicability of DFL. Our experiment
    
[^27]: 强化学习中基于奖励机器抽象的上下文预规划以增强迁移学习

    Contextual Pre-Planning on Reward Machine Abstractions for Enhanced Transfer in Deep Reinforcement Learning. (arXiv:2307.05209v1 [cs.AI])

    [http://arxiv.org/abs/2307.05209](http://arxiv.org/abs/2307.05209)

    我们提出了一种使用奖励机器抽象来表示当前任务，并在迁移学习中提升DRL代理的性能的方法，实验表明该方法能够提高样本效率并在多个领域中进行少样本迁移。

    

    最近的研究表明，深度强化学习（DRL）代理倾向于过拟合训练任务，并且无法适应轻微的环境变化。为了在转移到未见任务时加快学习，我们提出了一种使用奖励机器（RM）来表示当前任务的新方法，奖励机器是基于当前任务的奖励和动态生成子任务的状态机抽象。我们的方法为代理提供了当前抽象状态的符号表示，并奖励它们达成这些转换。这些表示在任务之间共享，使代理能够利用先前遇到的符号和转换的知识，从而增强迁移能力。我们的实证评估表明，我们的表示在各种领域中提高了样本效率和少样本迁移。

    Recent studies show that deep reinforcement learning (DRL) agents tend to overfit to the task on which they were trained and fail to adapt to minor environment changes. To expedite learning when transferring to unseen tasks, we propose a novel approach to representing the current task using reward machines (RM), state machine abstractions that induce subtasks based on the current task's rewards and dynamics. Our method provides agents with symbolic representations of optimal transitions from their current abstract state and rewards them for achieving these transitions. These representations are shared across tasks, allowing agents to exploit knowledge of previously encountered symbols and transitions, thus enhancing transfer. Our empirical evaluation shows that our representations improve sample efficiency and few-shot transfer in a variety of domains.
    
[^28]: 通过$\beta$-分解一后验采样实现差分计算机学习

    Differentially Private Statistical Inference through $\beta$-Divergence One Posterior Sampling. (arXiv:2307.05194v1 [stat.ML])

    [http://arxiv.org/abs/2307.05194](http://arxiv.org/abs/2307.05194)

    通过对数据生成过程和模型之间的$\beta$-分解进行后验采样，我们提出了$\beta$D-Bayes，一种能够实现差分机器学习的方法。

    

    差分私密性确保了包含敏感数据的统计分析结果可以在不损害任何个体隐私的情况下进行发布。实现这种保证通常需要在参数估计或估计过程中直接注入噪音。而采样来自贝叶斯后验分布已被证明是指数机制的一种特殊情况，可以产生一致且高效的私密估计，而不会改变数据生成过程。然而，当前方法的应用受到较强的边界假设的限制，这些假设对于基本模型（如简单的线性回归器）并不成立。为了改善这一点，我们提出了$\beta$D-Bayes，一种从广义后验中进行后验采样的方案，目标是最小化模型与数据生成过程之间的$\beta$-分解。这提供了私密估计的方法。

    Differential privacy guarantees allow the results of a statistical analysis involving sensitive data to be released without compromising the privacy of any individual taking part. Achieving such guarantees generally requires the injection of noise, either directly into parameter estimates or into the estimation process. Instead of artificially introducing perturbations, sampling from Bayesian posterior distributions has been shown to be a special case of the exponential mechanism, producing consistent, and efficient private estimates without altering the data generative process. The application of current approaches has, however, been limited by their strong bounding assumptions which do not hold for basic models, such as simple linear regressors. To ameliorate this, we propose $\beta$D-Bayes, a posterior sampling scheme from a generalised posterior targeting the minimisation of the $\beta$-divergence between the model and the data generating process. This provides private estimation t
    
[^29]: Co-Attention Gated Vision-Language Embedding for Visual Question Localized-Answering in Robotic Surgery（用于机器人手术中视觉问答定位的共同关注门控视觉-语言嵌入）

    Co-Attention Gated Vision-Language Embedding for Visual Question Localized-Answering in Robotic Surgery. (arXiv:2307.05182v1 [cs.CV])

    [http://arxiv.org/abs/2307.05182](http://arxiv.org/abs/2307.05182)

    这项研究提出了一种用于机器人手术中视觉问答定位的共同关注门控视觉-语言嵌入方法，可以为医学生和初级外科医生提供学习和理解手术视频的帮助。

    

    医学生和初级外科医生在学习手术时通常依赖于高级外科医生和专家回答他们的问题。然而，专家们经常忙于临床和学术工作，没有多少时间提供指导。与此同时，现有的基于深度学习的外科视觉问答系统只能提供简单答案，而没有答案的位置信息。此外，在这类任务中，视觉语言嵌入仍然是一个较少探索的领域。因此，一种外科视觉问答定位系统对于医学生和初级外科医生从录制的手术视频中学习和理解是有帮助的。我们提出了一种适用于外科场景的端到端Transformer与共同关注门控视觉-语言（CAT-ViL）的VQLA方法，它不需要通过检测模型进行特征提取。CAT-ViL嵌入模块的设计旨在融合来自视觉和文本来源的异构特征。

    Medical students and junior surgeons often rely on senior surgeons and specialists to answer their questions when learning surgery. However, experts are often busy with clinical and academic work, and have little time to give guidance. Meanwhile, existing deep learning (DL)-based surgical Visual Question Answering (VQA) systems can only provide simple answers without the location of the answers. In addition, vision-language (ViL) embedding is still a less explored research in these kinds of tasks. Therefore, a surgical Visual Question Localized-Answering (VQLA) system would be helpful for medical students and junior surgeons to learn and understand from recorded surgical videos. We propose an end-to-end Transformer with Co-Attention gaTed Vision-Language (CAT-ViL) for VQLA in surgical scenarios, which does not require feature extraction through detection models. The CAT-ViL embedding module is designed to fuse heterogeneous features from visual and textual sources. The fused embedding 
    
[^30]: 提升可用性测试的口头反馈：利用眼动和鼠标数据自动连接口头记录和刺激

    Enriching Verbal Feedback from Usability Testing: Automatic Linking of Thinking-Aloud Recordings and Stimulus using Eye Tracking and Mouse Data. (arXiv:2307.05171v1 [cs.HC])

    [http://arxiv.org/abs/2307.05171](http://arxiv.org/abs/2307.05171)

    本文提出了一种自动分析口头协议的方法，并通过眼动和鼠标追踪测试了口头反馈和刺激之间的链接。这种方法可以将用户反馈与刺激的特定区域相关联，用于专家审核特定网页元素的反馈或可视化反馈给出的网页部分。

    

    口头思考方法是一种重要且常用的可用性优化工具。然而，分析口头数据可能耗费时间。在本文中，我们提出了一种自动分析口头协议并测试了利用眼动和鼠标追踪链接口头反馈和刺激之间的方法。获得的数据 - 用户反馈与刺激的特定区域相关联 - 可以用于让专家审核特定网页元素的反馈或者可视化反馈给出的网页部分。具体而言，我们测试参与者是否会注视或指向他们口头表达的网页内容。在测试过程中，参与者被要求口头表达对三个网站的意见。口头回应以及眼动和鼠标移动均被记录下来。我们比较了命中率，即以视线注视或鼠标指向的口头提到的感兴趣区域（AOIs）的百分比。

    The think aloud method is an important and commonly used tool for usability optimization. However, analyzing think aloud data could be time consuming. In this paper, we put forth an automatic analysis of verbal protocols and test the link between spoken feedback and the stimulus using eye tracking and mouse tracking. The gained data - user feedback linked to a specific area of the stimulus - could be used to let an expert review the feedback on specific web page elements or to visualize on which parts of the web page the feedback was given. Specifically, we test if participants fixate on or point with the mouse to the content of the webpage that they are verbalizing. During the testing, participants were shown three websites and asked to verbally give their opinion. The verbal responses, along with the eye and cursor movements were recorded. We compared the hit rate, defined as the percentage of verbally mentioned areas of interest (AOIs) that were fixated with gaze or pointed to with 
    
[^31]: 边缘云计算的神经分位数优化

    Neural Quantile Optimization for Edge-Cloud Computing. (arXiv:2307.05170v1 [cs.NI])

    [http://arxiv.org/abs/2307.05170](http://arxiv.org/abs/2307.05170)

    这项研究提出了一种神经分位数优化的方法，用于边缘云计算网络中找到最佳的流量分配方案。通过引入Gumbel-softmax采样网络，可以有效地解决优化问题并显著优于随机策略。

    

    我们寻求边缘云计算网络的最佳流量分配方案，以满足约束条件并最小化基于突发计费的成本。首先，对于固定的网络拓扑，我们提出了一族整数规划问题，其中包含描述各种流量需求的随机参数。然后，为了克服问题离散特征带来的困难，我们将Gumbel-softmax重参数化方法推广为一个无约束连续优化问题，作为离散问题的正则化延续。最后，我们引入Gumbel-softmax采样网络，通过无监督学习来解决优化问题。网络结构反映了边缘云计算的拓扑结构，并被训练为使得无约束连续优化问题的成本函数期望最小化。训练好的网络作为一个高效的流量分配方案采样器，在可行性方面明显优于随机策略。

    We seek the best traffic allocation scheme for the edge-cloud computing network that satisfies constraints and minimizes the cost based on burstable billing. First, for a fixed network topology, we formulate a family of integer programming problems with random parameters describing the various traffic demands. Then, to overcome the difficulty caused by the discrete feature of the problem, we generalize the Gumbel-softmax reparameterization method to induce an unconstrained continuous optimization problem as a regularized continuation of the discrete problem. Finally, we introduce the Gumbel-softmax sampling network to solve the optimization problems via unsupervised learning. The network structure reflects the edge-cloud computing topology and is trained to minimize the expectation of the cost function for unconstrained continuous optimization problems. The trained network works as an efficient traffic allocation scheme sampler, remarkably outperforming the random strategy in feasibili
    
[^32]: SuryaKiran在MEDIQA-Sum 2023中的应用：利用LoRA进行临床对话摘要

    SuryaKiran at MEDIQA-Sum 2023: Leveraging LoRA for Clinical Dialogue Summarization. (arXiv:2307.05162v1 [cs.CL])

    [http://arxiv.org/abs/2307.05162](http://arxiv.org/abs/2307.05162)

    本研究展示了一种名为LoRA的参数高效细调方法在临床对话摘要中的评估结果，并证明LoRA与对大型语言模型进行端到端细调效果相当。

    

    细调大型语言模型有助于改善特定领域用例的结果。对大型语言模型进行端到端的细调耗费时间和资源，并具有高存储需求以存储细调后的大型语言模型。参数高效细调（PEFT）方法通过保持大型语言模型为固定基准并添加额外层来解决时间和资源挑战，PEFT方法进行细调。本文展示了一个名为低秩适应（LoRA）的PEFT方法在临床对话摘要中的评估结果。评估结果显示，LoRA与对大型语言模型进行端到端细调的效果相当。本文还介绍了解决ImageCLEFmedical的Subtask A和B所进行的评估。

    Finetuning Large Language Models helps improve the results for domain-specific use cases. End-to-end finetuning of large language models is time and resource intensive and has high storage requirements to store the finetuned version of the large language model. Parameter Efficient Fine Tuning (PEFT) methods address the time and resource challenges by keeping the large language model as a fixed base and add additional layers, which the PEFT methods finetune. This paper demonstrates the evaluation results for one such PEFT method Low Rank Adaptation (LoRA), for Clinical Dialogue Summarization. The evaluation results show that LoRA works at par with end-to-end finetuning for a large language model. The paper presents the evaluations done for solving both the Subtask A and B from ImageCLEFmedical {https://www.imageclef.org/2023/medical}
    
[^33]: 关于语音自我监督学习在音乐中的有效性研究

    On the Effectiveness of Speech Self-supervised Learning for Music. (arXiv:2307.05161v1 [cs.SD])

    [http://arxiv.org/abs/2307.05161](http://arxiv.org/abs/2307.05161)

    本研究探索了语音自我监督学习在音乐信息检索中的有效性。通过对两个与语音相关的模型进行自我监督学习适应，并在多个MIR任务上进行系统评估，结果显示在音乐数据上训练可以提高MIR任务的性能。

    

    自我监督学习（SSL）已经在各种语音和自然语言处理应用中显示出有希望的结果。然而，它在音乐信息检索（MIR）中的有效性仍然很少被探索。虽然以前的在音乐记录上预训练的SSL模型可能主要是闭源的，但最近的语音模型如wav2vec2.0在音乐建模方面显示出了潜力。然而，对于将语音SSL模型应用于音乐记录的有效性的研究还很有限。我们探索了两个独特的与语音相关的模型在音乐中的自我监督学习适应，分别是data2vec1.0和Hubert，并将它们分别称为music2vec和musicHuBERT。我们使用不同的预训练配置下训练了12个具有95M参数的SSL模型，并系统评估了13个不同的MIR任务的表现。我们的研究结果表明，在音乐数据上训练通常可以提高MIR任务的性能，即使使用设计为语音模型的训练范式。

    Self-supervised learning (SSL) has shown promising results in various speech and natural language processing applications. However, its efficacy in music information retrieval (MIR) still remains largely unexplored. While previous SSL models pre-trained on music recordings may have been mostly closed-sourced, recent speech models such as wav2vec2.0 have shown promise in music modelling. Nevertheless, research exploring the effectiveness of applying speech SSL models to music recordings has been limited. We explore the music adaption of SSL with two distinctive speech-related models, data2vec1.0 and Hubert, and refer to them as music2vec and musicHuBERT, respectively. We train $12$ SSL models with 95M parameters under various pre-training configurations and systematically evaluate the MIR task performances with 13 different MIR tasks. Our findings suggest that training with music data can generally improve performance on MIR tasks, even when models are trained using paradigms designed f
    
[^34]: 稳定规范解释：从论证到德义逻辑

    Stable Normative Explanations: From Argumentation to Deontic Logic. (arXiv:2307.05156v1 [cs.AI])

    [http://arxiv.org/abs/2307.05156](http://arxiv.org/abs/2307.05156)

    本文研究了如何在形式论证的背景下表达稳定解释概念，并探讨了这种重建的德义含义。其中的重要贡献是展示了如何基于论证邻域结构构建德义逻辑的解释概念。

    

    本文研究了如何在形式论证的背景下表达在可侵犯逻辑中已经发展的稳定解释概念。在此基础上，我们讨论了这种重建的德义含义，并展示了如何基于论证邻域结构构建德义逻辑的解释概念。此外，该文还提供了一些直接的复杂性结果。

    This paper examines how a notion of stable explanation developed elsewhere in Defeasible Logic can be expressed in the context of formal argumentation. With this done, we discuss the deontic meaning of this reconstruction and show how to build from argumentation neighborhood structures for deontic logic where this notion of explanation can be characterised. Some direct complexity results are offered.
    
[^35]: 用于解释一些图神经网络的模态逻辑

    A Modal Logic for Explaining some Graph Neural Networks. (arXiv:2307.05150v1 [cs.AI])

    [http://arxiv.org/abs/2307.05150](http://arxiv.org/abs/2307.05150)

    本文提出了一种模态逻辑，通过线性不等式中的计数模态来解释图神经网络。作者证明了可将公式转化为等价的GNN，同时也证明了可将GNN转化为公式。作者还证明了可满足性问题是可判定的，并讨论了一些PSPACE中的变体。

    

    在本文中，我们提出了一种模态逻辑，其中计数模态出现在线性不等式中。我们展示了每个公式可以转化为一个等价的图神经网络（GNN）。我们还展示了每个GNN可以转化为一个公式。我们证明了可满足性问题是可判定的。我们还讨论了一些PSPACE中的变体。

    In this paper, we propose a modal logic in which counting modalities appear in linear inequalities. We show that each formula can be transformed into an equivalent graph neural network (GNN). We also show that each GNN can be transformed into a formula. We show that the satisfiability problem is decidable. We also discuss some variants that are in PSPACE.
    
[^36]: TIAM -- 一种评估文本到图像生成中对齐性的度量方法

    TIAM -- A Metric for Evaluating Alignment in Text-to-Image Generation. (arXiv:2307.05134v1 [cs.CV])

    [http://arxiv.org/abs/2307.05134](http://arxiv.org/abs/2307.05134)

    本文提出了一种评估文本到图像生成中对齐性的新度量方法TIAM，该方法基于提示模板，可以更好地描述生成图像与提示中内容的对齐程度，包括对象类型、数量和颜色。研究结果表明，图像质量可以有很大的变化。

    

    合成图像生成的进展使得评估其质量变得至关重要。尽管已经提出了几种用于评估图像渲染的度量方法，但对于基于提示生成图像的文本到图像（T2I）模型而言，考虑到生成图像与提示中重要内容之间的相似程度等额外因素至关重要。此外，虽然生成的图像通常是从随机起始点开始的，但通常不考虑这一影响。本文提出了一种基于提示模板的新度量方法，用于研究提示中指定的内容与生成的图像之间的对齐性。它允许我们更好地描述对齐性，包括指定对象的类型、数量和颜色。我们对几个最近的T2I模型进行了研究，并获得了一个有趣的额外结果，即图像质量可以大幅度变化。

    The progress in the generation of synthetic images has made it crucial to assess their quality. While several metrics have been proposed to assess the rendering of images, it is crucial for Text-to-Image (T2I) models, which generate images based on a prompt, to consider additional aspects such as to which extent the generated image matches the important content of the prompt. Moreover, although the generated images usually result from a random starting point, the influence of this one is generally not considered. In this article, we propose a new metric based on prompt templates to study the alignment between the content specified in the prompt and the corresponding generated images. It allows us to better characterize the alignment in terms of the type of the specified objects, their number, and their color. We conducted a study on several recent T2I models about various aspects. An additional interesting result we obtained with our approach is that image quality can vary drastically 
    
[^37]: 对扰动作为时序XAI评估技术的深入探究

    A Deep Dive into Perturbations as Evaluation Technique for Time Series XAI. (arXiv:2307.05104v1 [cs.LG])

    [http://arxiv.org/abs/2307.05104](http://arxiv.org/abs/2307.05104)

    本研究深入探讨了使用扰动作为评估从时间序列模型中提取的归因的方法。通过对多种XAI技术的应用和在多个数据集上进行验证，结果表明扰动分析可以有效评估归因的质量，并为其优点和局限性提供了洞察力。

    

    可解释的人工智能（XAI）近年来引起了极大的关注，因为对机器学习模型透明度和可解释性的需求增加了。特别是，在金融、医疗和气候科学领域，对时间序列数据的XAI变得越来越重要。然而，评估解释质量，如XAI技术提供的归因，仍然具有挑战性。本文对使用扰动来评估从时间序列模型中提取的归因进行了深入分析。扰动分析包括系统地修改输入数据，并评估对XAI方法生成的归因的影响。我们将这种方法应用于几种最先进的XAI技术，并在三个时间序列分类数据集上评估它们的性能。我们的结果表明，扰动分析方法可以有效评估归因的质量，并洞察力地揭示出其优点和局限性。

    Explainable Artificial Intelligence (XAI) has gained significant attention recently as the demand for transparency and interpretability of machine learning models has increased. In particular, XAI for time series data has become increasingly important in finance, healthcare, and climate science. However, evaluating the quality of explanations, such as attributions provided by XAI techniques, remains challenging. This paper provides an in-depth analysis of using perturbations to evaluate attributions extracted from time series models. A perturbation analysis involves systematically modifying the input data and evaluating the impact on the attributions generated by the XAI method. We apply this approach to several state-of-the-art XAI techniques and evaluate their performance on three time series classification datasets. Our results demonstrate that the perturbation analysis approach can effectively evaluate the quality of attributions and provide insights into the strengths and limitati
    
[^38]: ATWM：基于对抗训练的对抗恶意软件防御方法

    ATWM: Defense against adversarial malware based on adversarial training. (arXiv:2307.05095v1 [cs.CR])

    [http://arxiv.org/abs/2307.05095](http://arxiv.org/abs/2307.05095)

    本文提出了一种基于对抗训练的对抗恶意软件防御方法，通过预处理降低简单的对抗样本的防御难度，并通过对抗训练提高模型的对抗防御能力。

    

    深度学习技术在图像领域取得了巨大的成就。为了抵御恶意软件攻击，研究人员提出了许多基于深度学习的Windows恶意软件检测模型。然而，深度学习模型容易受到对抗样本攻击。恶意软件可以生成具有相同恶意功能的对抗性恶意软件，以攻击恶意软件检测模型并逃避其检测。目前，已经提出了许多对抗性防御研究，但现有的对抗性防御研究都是基于图像样本，不能直接应用于恶意软件样本。因此，本文提出了一种基于对抗训练的对抗恶意软件防御方法。该方法通过预处理来防御简单的对抗样本，以降低对抗训练的难度。此外，该方法通过对抗训练提高了模型的对抗防御能力。我们在两组数据集中使用了三种攻击方法进行了实验证明。

    Deep learning technology has made great achievements in the field of image. In order to defend against malware attacks, researchers have proposed many Windows malware detection models based on deep learning. However, deep learning models are vulnerable to adversarial example attacks. Malware can generate adversarial malware with the same malicious function to attack the malware detection model and evade detection of the model. Currently, many adversarial defense studies have been proposed, but existing adversarial defense studies are based on image sample and cannot be directly applied to malware sample. Therefore, this paper proposes an adversarial malware defense method based on adversarial training. This method uses preprocessing to defend simple adversarial examples to reduce the difficulty of adversarial training. Moreover, this method improves the adversarial defense capability of the model through adversarial training. We experimented with three attack methods in two sets of dat
    
[^39]: OntoChatGPT信息系统：本体驱动的ChatGPT元学习结构化提示

    OntoChatGPT Information System: Ontology-Driven Structured Prompts for ChatGPT Meta-Learning. (arXiv:2307.05082v1 [cs.AI])

    [http://arxiv.org/abs/2307.05082](http://arxiv.org/abs/2307.05082)

    本研究提出了一种利用本体驱动的结构化提示系统与ChatGPT进行元学习相互结合的方法。通过在康复领域的应用实现了该技术，并展示了该方法的多功能性和适用性。

    

    本研究提出了一种综合方法，用于将本体驱动的结构化提示系统与ChatGPT（一种广泛使用的大型语言模型）相互结合。研究开发了形式模型（信息和功能两个方面），并建立了将本体驱动的提示与ChatGPT的元学习能力相结合的方法论基础。得到的三重结构包括方法论基础、先进的信息技术和OntoChatGPT系统，共同提高了聊天机器人系统的效能和性能。通过在康复领域中采用乌克兰语实现了该技术。通过应用所提出的方法论，OntoChatGPT系统可以有效地提取上下文中的实体，并对其进行分类，并生成相关的回答。研究强调了该方法论的多功能性，强调其不仅适用于ChatGPT，还适用于其他聊天机器人系统。

    This research presents a comprehensive methodology for utilizing an ontology-driven structured prompts system in interplay with ChatGPT, a widely used large language model (LLM). The study develops formal models, both information and functional, and establishes the methodological foundations for integrating ontology-driven prompts with ChatGPT's meta-learning capabilities. The resulting productive triad comprises the methodological foundations, advanced information technology, and the OntoChatGPT system, which collectively enhance the effectiveness and performance of chatbot systems. The implementation of this technology is demonstrated using the Ukrainian language within the domain of rehabilitation. By applying the proposed methodology, the OntoChatGPT system effectively extracts entities from contexts, classifies them, and generates relevant responses. The study highlights the versatility of the methodology, emphasizing its applicability not only to ChatGPT but also to other chatbot
    
[^40]: Uni-Removal: 一个用于同时解决实际图像中多种退化问题的半监督框架

    Uni-Removal: A Semi-Supervised Framework for Simultaneously Addressing Multiple Degradations in Real-World Images. (arXiv:2307.05075v1 [cs.CV])

    [http://arxiv.org/abs/2307.05075](http://arxiv.org/abs/2307.05075)

    本文提出了Uni-Removal，这是一个半监督框架，用于解决实际图像中的多个退化问题。通过知识传递和域适应两个阶段的训练，该框架可以使用统一模型和参数来处理不同类型的退化，并取得有希望的结果

    

    从实际图像中去除多种退化，如雾、雨和模糊，是一个具有挑战性和不适定问题。最近提出了能够处理不同退化的统一模型，并取得了有希望的结果。然而，这些方法主要集中在合成图像上，并且在应用于实际图像时性能显著下降。在本文中，我们引入了Uni-Removal，这是一个两阶段半监督框架，用于使用统一模型和参数解决实际图像中多种退化问题。在知识传递阶段，Uni-Removal利用监督多教师和学生架构，在知识传递阶段中促进从预训练的专门处理不同退化 类型的教师网络中学习。引入了多粒度对比损失来增强来自特征和图像空间的学习。在域适应阶段，通过引入对抗训练进行无监督微调。

    Removing multiple degradations, such as haze, rain, and blur, from real-world images poses a challenging and illposed problem. Recently, unified models that can handle different degradations have been proposed and yield promising results. However, these approaches focus on synthetic images and experience a significant performance drop when applied to realworld images. In this paper, we introduce Uni-Removal, a twostage semi-supervised framework for addressing the removal of multiple degradations in real-world images using a unified model and parameters. In the knowledge transfer stage, Uni-Removal leverages a supervised multi-teacher and student architecture in the knowledge transfer stage to facilitate learning from pretrained teacher networks specialized in different degradation types. A multi-grained contrastive loss is introduced to enhance learning from feature and image spaces. In the domain adaptation stage, unsupervised fine-tuning is performed by incorporating an adversarial d
    
[^41]: 采用样本感知引导和动态修订链的基于检索增强的GPT-3.5文本到SQL框架

    Retrieval-augmented GPT-3.5-based Text-to-SQL Framework with Sample-aware Prompting and Dynamic Revision Chain. (arXiv:2307.05074v1 [cs.IR])

    [http://arxiv.org/abs/2307.05074](http://arxiv.org/abs/2307.05074)

    本文提出了一种基于检索增强的GPT-3.5文本到SQL框架，采用了样本感知引导和动态修订链的方法，以应对现有方法在处理语义差距较大的检索示例时面临的挑战。

    

    文本到SQL旨在为给定的自然语言问题生成SQL查询，从而帮助用户查询数据库。最近出现了一种基于大型语言模型（LLMs）的提示学习方法，该方法设计提示以引导LLMs理解输入问题并生成相应的SQL。然而，它面临着严格的SQL语法要求的挑战。现有工作使用一系列示例（即问题-SQL对）来提示LLMs生成SQL，但固定的提示几乎无法处理检索出的示例与输入问题之间的语义差距较大的情况。在本文中，我们提出了一种基于检索增强的提示方法，用于基于LLM的文本到SQL框架，包括样本感知提示和动态修订链。我们的方法包括样本感知示例，其中包括SQL运算符的组合和与给定问题相关的细粒度信息。

    Text-to-SQL aims at generating SQL queries for the given natural language questions and thus helping users to query databases. Prompt learning with large language models (LLMs) has emerged as a recent approach, which designs prompts to lead LLMs to understand the input question and generate the corresponding SQL. However, it faces challenges with strict SQL syntax requirements. Existing work prompts the LLMs with a list of demonstration examples (i.e. question-SQL pairs) to generate SQL, but the fixed prompts can hardly handle the scenario where the semantic gap between the retrieved demonstration and the input question is large. In this paper, we propose a retrieval-augmented prompting method for a LLM-based Text-to-SQL framework, involving sample-aware prompting and a dynamic revision chain. Our approach incorporates sample-aware demonstrations, which include the composition of SQL operators and fine-grained information related to the given question. To retrieve questions sharing sim
    
[^42]: 将准确度聚合到信念中：不可能结果的议程条件

    Aggregating Credences into Beliefs: Agenda Conditions for Impossibility Results. (arXiv:2307.05072v1 [cs.AI])

    [http://arxiv.org/abs/2307.05072](http://arxiv.org/abs/2307.05072)

    本文研究了二值化信念聚合的议程条件，证明了路径连接和甚至可否性是产生组织结果的必要条件，并探讨了不同条件下的寡头统治现象。

    

    二值化信念聚合解决了如何理性地将个体的概率信念聚合成集体的二值信念。类似于判断聚合理论的发展，制定公理要求，证明不可能定理，并确定不可能定理的确切议程条件是二值化信念聚合中的自然而重要的研究课题。在我们以前的不可能定理研究基础上，我们使用议程理论方法推广结果，并确定议程中问题之间逻辑连接所需的必要和充分层次，以导致不可能定理的产生。我们证明：（1）路径连接和甚至可否性构成了组织结果的确切议程条件，即满足逐个命题独立性和集体信念的推理封闭性的二值化信念聚合在较小条件下会导致寡头统治；（2）否定连接...

    Binarizing belief aggregation addresses how to rationally aggregate individual probabilistic beliefs into collective binary beliefs. Similar to the development of judgment aggregation theory, formulating axiomatic requirements, proving impossibility theorems, and identifying exact agenda conditions of impossibility theorems are natural and important research topics in binarizing belief aggregation. Building on our previous research on impossibility theorems, we use an agenda-theoretic approach to generalize the results and to determine the necessary and sufficient level of logical interconnection between the issues in an agenda for the impossibility theorems to arise. We demonstrate that (1) path-connectedness and even-negatability constitute the exact agenda condition for the oligarchy result stating that binarizing belief aggregation satisfying proposition-wise independence and deductive closure of collective beliefs yields the oligarchies under minor conditions; (2) negation-connect
    
[^43]: 对未知未知的挖掘

    Mining for Unknown Unknowns. (arXiv:2307.05071v1 [cs.AI])

    [http://arxiv.org/abs/2307.05071](http://arxiv.org/abs/2307.05071)

    本论文使用形式概念分析（FCA）框架，旨在系统地挖掘和寻找未知未知，从而避免潜在的重大收益或损失。

    

    未知未知是缺乏事前描述的未来相关的偶发事件。尽管有许多回顾性的报告显示，如果此类情况事前被发现，可以实现或避免显著收益或损失，但获取未知未知仍然是难以捉摸的，无论是在实践上还是在概念上。本文使用形式概念分析（FCA） - 一种越来越多地应用于挖掘和组织数据的格论子领域 - 引入了一个简单的框架，以系统地打破思维定势，指导对未知未知的搜索。

    Unknown unknowns are future relevant contingencies that lack an ex ante description. While there are numerous retrospective accounts showing that significant gains or losses might have been achieved or avoided had such contingencies been previously uncovered, getting hold of unknown unknowns still remains elusive, both in practice and conceptually. Using Formal Concept Analysis (FCA) - a subfield of lattice theory which is increasingly applied for mining and organizing data - this paper introduces a simple framework to systematically think out of the box and direct the search for unknown unknowns.
    
[^44]: 认知偏差与信念修正

    Cognitive Bias and Belief Revision. (arXiv:2307.05069v1 [cs.LO])

    [http://arxiv.org/abs/2307.05069](http://arxiv.org/abs/2307.05069)

    本文介绍了在信念修正框架下对确认偏差、框架偏差和锚定偏差的形式化描述，并应用于三种常见的信念修正方法。研究结果发现这些偏差对于追踪真相是有影响的，并通过计算机模拟评估了其在随机情境下的性能。

    

    本文在信念修正的框架下，对三种认知偏差进行了形式化的描述：确认偏差、框架偏差和锚定偏差。我们将其解释为对迭代修正过程的限制，并将其应用于三种知名的信念修正方法：条件修正、词典式修正和最小修正。我们研究了受偏差信念修正方法在追踪真相方面的可靠性，并通过计算机模拟评估了偏差信念修正在随机情境下的性能。

    In this paper we formalise three types of cognitive bias within the framework of belief revision: confirmation bias, framing bias, and anchoring bias. We interpret them generally, as restrictions on the process of iterated revision, and we apply them to three well-known belief revision methods: conditioning, lexicographic revision, and minimal revision. We investigate the reliability of biased belief revision methods in truth tracking. We also run computer simulations to assess the performance of biased belief revision in random scenarios.
    
[^45]: 有界归纳理性的理论

    A Theory of Bounded Inductive Rationality. (arXiv:2307.05068v1 [cs.AI])

    [http://arxiv.org/abs/2307.05068](http://arxiv.org/abs/2307.05068)

    本论文的主要贡献是提出了一个不假设逻辑全知性的理性决策理论，该理论可用于解决在现实环境中存在计算复杂性和无法对自身进行全面分析的决策问题。

    

    理性选择的主流理论假设逻辑全知性，即当面临决策问题时，一个智能体可以执行所有相关计算，并确定所有相关的逻辑/数学命题的真值。然而，这种假设在某些情况下是不现实的，例如我们对圆周率的远程小数提供赌注，或者智能体面临计算复杂的规划问题时。此外，逻辑全知性的假设在环境中包含智能体自身描述的情况下会产生矛盾。重要的是，博弈理论研究的战略互动是决策问题，这种情况下一个理性智能体由其环境（其他玩家）预测。本文中，我们提出了一个不假设逻辑全知性的理性决策理论。我们考虑反复面临决策问题的智能体（包括对圆周率小数赌注的问题以及与其他智能体对战的游戏）。本文的主要贡献是...

    The dominant theories of rational choice assume logical omniscience. That is, they assume that when facing a decision problem, an agent can perform all relevant computations and determine the truth value of all relevant logical/mathematical claims. This assumption is unrealistic when, for example, we offer bets on remote digits of pi or when an agent faces a computationally intractable planning problem. Furthermore, the assumption of logical omniscience creates contradictions in cases where the environment can contain descriptions of the agent itself. Importantly, strategic interactions as studied in game theory are decision problems in which a rational agent is predicted by its environment (the other players). In this paper, we develop a theory of rational decision making that does not assume logical omniscience. We consider agents who repeatedly face decision problems (including ones like betting on digits of pi or games against other agents). The main contribution of this paper is t
    
[^46]: 利用逻辑难题中的不对称性：使用ZDDs对符号模型检查动态认知逻辑

    Exploiting Asymmetry in Logic Puzzles: Using ZDDs for Symbolic Model Checking Dynamic Epistemic Logic. (arXiv:2307.05067v1 [cs.LO])

    [http://arxiv.org/abs/2307.05067](http://arxiv.org/abs/2307.05067)

    通过使用ZDDs替代BDDs，可以显著减少模型检查多代理系统的内存使用。

    

    二进制决策图（BDDs）被广泛用于缓解模型检查中的状态爆炸问题。BDDs的一种变体是零减压决策图（ZDDs），它省略了必须为假的变量，而不是省略不重要的变量。我们使用ZDDs来符号化编码用于动态认知逻辑中的Kripke模型，该框架用于推理关于多代理系统中知识和信息动态的问题。我们比较了不同ZDD变体在文献中的三个著名示例（温水孩子问题，和积谜以及就餐加密成员问题）对内存使用的影响。我们的实现基于现有的模型检查程序SMCDEL和CUDD库。结果表明，使用合适的ZDD变体替换BDDs可以显著减少内存使用。这表明ZDDs是对于模型检查多代理系统的有用工具。

    Binary decision diagrams (BDDs) are widely used to mitigate the state-explosion problem in model checking. A variation of BDDs are Zero-suppressed Decision Diagrams (ZDDs) which omit variables that must be false, instead of omitting variables that do not matter. We use ZDDs to symbolically encode Kripke models used in Dynamic Epistemic Logic, a framework to reason about knowledge and information dynamics in multi-agent systems. We compare the memory usage of different ZDD variants for three well-known examples from the literature: the Muddy Children, the Sum and Product puzzle and the Dining Cryptographers. Our implementation is based on the existing model checker SMCDEL and the CUDD library. Our results show that replacing BDDs with the right variant of ZDDs can significantly reduce memory usage. This suggests that ZDDs are a useful tool for model checking multi-agent systems.
    
[^47]: 战略性知道的逻辑的表格法

    Tableaux for the Logic of Strategically Knowing How. (arXiv:2307.05066v1 [cs.LO])

    [http://arxiv.org/abs/2307.05066](http://arxiv.org/abs/2307.05066)

    本文提出了战略性知道如何逻辑的表格法，并证明了其完备性和正确性。此外，还证明了该逻辑的可满足性问题可以在PSPACE中解决。

    

    目标导向的知道如何逻辑将标准的认知逻辑延伸，加入了一个知道如何的操作符。这个知道如何的操作符被解释为存在一种策略，使得代理知道该策略可以确保 p。本文提出了适用于战略性知道如何逻辑的多代理版本的表格法，并证明了该表格法的完备性和正确性。本文还证明了该逻辑的可满足性问题可以在PSPACE中解决。

    The logic of goal-directed knowing-how extends the standard epistemic logic with an operator of knowing-how. The knowing-how operator is interpreted as that there exists a strategy such that the agent knows that the strategy can make sure that p. This paper presents a tableau procedure for the multi-agent version of the logic of strategically knowing-how and shows the soundness and completeness of this tableau procedure. This paper also shows that the satisfiability problem of the logic can be decided in PSPACE.
    
[^48]: 基于球体系统的两级可信度限制修正方法

    System of Spheres-based Two Level Credibility-limited Revisions. (arXiv:2307.05062v1 [cs.LO])

    [http://arxiv.org/abs/2307.05062](http://arxiv.org/abs/2307.05062)

    本文提出了基于球体系统的两级可信度限制修正操作符的构造，并对这些操作符进行了公理化刻画。

    

    两级可信度限制修正是一种非优先级修正操作。在进行两级可信度限制修正时，考虑两个层级的可信度和一个层级的不可信度。当通过最高层级可信度的句子进行修正时，操作符的行为类似于标准的修正；如果句子处于第二级可信度，则修正结果与通过否定该句子进行标准收缩的结果一致；如果句子不可信，则原始信念集保持不变。本文提出了一种基于Grove的球体系统的两级可信度限制修正操作符的构造，并对这些操作符进行了公理化刻画。

    Two level credibility-limited revision is a non-prioritized revision operation. When revising by a two level credibility-limited revision, two levels of credibility and one level of incredibility are considered. When revising by a sentence at the highest level of credibility, the operator behaves as a standard revision, if the sentence is at the second level of credibility, then the outcome of the revision process coincides with a standard contraction by the negation of that sentence. If the sentence is not credible, then the original belief set remains unchanged. In this paper, we propose a construction for two level credibility-limited revision operators based on Grove's systems of spheres and present an axiomatic characterization for these operators.
    
[^49]: 关于多智能体影响图中的记忆缺失问题

    On Imperfect Recall in Multi-Agent Influence Diagrams. (arXiv:2307.05059v1 [cs.GT])

    [http://arxiv.org/abs/2307.05059](http://arxiv.org/abs/2307.05059)

    本论文研究了多智能体影响图中的记忆缺失问题，提出了利用混合策略和两种类型的相关均衡来解决带有健忘和疏忽智能体的方法，并分析了关键决策问题的计算复杂性和可计算的情况。

    

    多智能体影响图（MAIDs）是一种基于贝叶斯网络的流行博弈论模型。在某些情况下，MAIDs相比扩展博弈表示法具有显著优势。以往的研究假设智能体采用行为策略，为每个决策设置独立的条件概率分布来选择动作。然而，在存在记忆缺失的情况下，行为策略的纳什均衡可能不存在。我们通过展示如何利用混合策略和两种类型的相关均衡来解决带有健忘和疏忽智能体的MAIDs。我们还分析了MAIDs中关键决策问题的计算复杂性，并探索了可计算的情况。最后，我们描述了将MAIDs应用于马尔可夫博弈和团队情境的情况，这些情境中的记忆缺失通常是不可避免的。

    Multi-agent influence diagrams (MAIDs) are a popular game-theoretic model based on Bayesian networks. In some settings, MAIDs offer significant advantages over extensive-form game representations. Previous work on MAIDs has assumed that agents employ behavioural policies, which set independent conditional probability distributions over actions for each of their decisions. In settings with imperfect recall, however, a Nash equilibrium in behavioural policies may not exist. We overcome this by showing how to solve MAIDs with forgetful and absent-minded agents using mixed policies and two types of correlated equilibrium. We also analyse the computational complexity of key decision problems in MAIDs, and explore tractable cases. Finally, we describe applications of MAIDs to Markov games and team situations, where imperfect recall is often unavoidable.
    
[^50]: 强化模态逻辑中的一致性结果

    Strengthening Consistency Results in Modal Logic. (arXiv:2307.05053v1 [math.LO])

    [http://arxiv.org/abs/2307.05053](http://arxiv.org/abs/2307.05053)

    本文提出了通用理论来解决模态逻辑中一致性结果的问题，通过提供一种标准的背景知识模块来进行范畴决策。这些结果和方法有助于阐明认识论中的问题，并且可以解决与判断、推理和决策中模态相关的问题。

    

    模态逻辑中一个基本问题是给定的理论是否一致。但一致于什么？解决这个问题的一种典型方法是确定一组背景知识公理（比如S4、D等），然后展示与该理论相一致的假设与这些背景公理相一致。但确定具体的背景公理的选择和划分，至少有时候，仅仅是传统的一种做法。本文引入了对命题模态逻辑的**通用理论**，以更加稳健的方式解决一致性结果问题。通用理论作为背景知识的构建模块，为一致性的范畴决策提供了一个标准。我们认为本文的结果和方法有助于阐明认识论中的问题，并且具有足够的范围和能力来解决与判断、推理和决策中模态相关的问题。

    A fundamental question asked in modal logic is whether a given theory is consistent. But consistent with what? A typical way to address this question identifies a choice of background knowledge axioms (say, S4, D, etc.) and then shows the assumptions codified by the theory in question to be consistent with those background axioms. But determining the specific choice and division of background axioms is, at least sometimes, little more than tradition. This paper introduces **generic theories** for propositional modal logic to address consistency results in a more robust way. As building blocks for background knowledge, generic theories provide a standard for categorical determinations of consistency. We argue that the results and methods of this paper help to elucidate problems in epistemology and enjoy sufficient scope and power to have purchase on problems bearing on modalities in judgement, inference, and decision making.
    
[^51]: 探索对比演示和显著性图在上下文学习中的作用

    Towards Understanding In-Context Learning with Contrastive Demonstrations and Saliency Maps. (arXiv:2307.05052v1 [cs.CL])

    [http://arxiv.org/abs/2307.05052](http://arxiv.org/abs/2307.05052)

    本研究探索了对比演示和显著性图在上下文学习中的作用，并发现改变标签对显著性有显著影响，尤其对于更大的语言模型更为明显。在情感分析任务中，将表达情感的术语改为中性词并不像改变标签那样具有显著影响。另外，补充解释在提高上下文学习方面是有效的。

    

    本文研究了在大型语言模型的上下文学习(ICL)性能中，各种演示组件的作用。具体而言，我们探讨了标签、输入分布和补充解释等因素的影响，特别是在这些因素被修改或扰动时的影响。我们基于之前的工作，这些工作对于这些元素如何影响ICL给出了不一致的结果。为了探究这些问题，我们采用了可解释的自然语言处理(XNLP)方法，并利用对比演示的显著性图进行定性和定量分析。我们的研究结果表明，改变标签对显著性有显著影响，尤其对于更大的语言模型更为明显。我们对输入分布进行了粒度级别的分析，发现在情感分析任务中，将表达情感的术语改为中性词并不像改变标签那样具有显著影响。最后，我们发现补充解释在提高ICL方面的效果是存在的。

    We investigate the role of various demonstration components in the in-context learning (ICL) performance of large language models (LLMs). Specifically, we explore the impacts of ground-truth labels, input distribution, and complementary explanations, particularly when these are altered or perturbed. We build on previous work, which offers mixed findings on how these elements influence ICL. To probe these questions, we employ explainable NLP (XNLP) methods and utilize saliency maps of contrastive demonstrations for both qualitative and quantitative analysis. Our findings reveal that flipping ground-truth labels significantly affects the saliency, though it's more noticeable in larger LLMs. Our analysis of the input distribution at a granular level reveals that changing sentiment-indicative terms in a sentiment analysis task to neutral ones does not have as substantial an impact as altering ground-truth labels. Finally, we find that the effectiveness of complementary explanations in boos
    
[^52]: 认识主义三段论：第一步

    Epistemic Syllogistic: First Steps. (arXiv:2307.05043v1 [cs.AI])

    [http://arxiv.org/abs/2307.05043](http://arxiv.org/abs/2307.05043)

    本文介绍了认识主义三段论的几种变体，集中在包含非平凡但自然表达式的de re解释上。主要贡献是提出了这些逻辑的几个公理化，并给出了完备性证明。

    

    亚里士多德关于模态三段论的讨论常被视为容易出错的，由于历史和哲学的兴趣而受到了很大的关注。然而，从当代的角度来看，它们也引入了一阶模态逻辑的自然片段，值得进行全面的技术分析。在本文中，我们借鉴自然逻辑计划的灵感，提出并研究了认识背景下的几种变体模态三段论，从而创造了“认识主义三段论”这个术语。具体而言，我们集中在涉及非平凡但自然表达式的认识主义三段论的de re解释上，例如“被认知为A的所有事物也被认知为非B”。我们探索了认识主义必然三段论及其扩展，以适应更复杂的术语。我们的主要贡献包括这些逻辑的几个公理化，附带证明的完备性可能是独立的利益所在。

    Aristotle's discussions on modal syllogistic have often been viewed as error-prone and have garnered significant attention in the literature due to historical and philosophical interests. However, from a contemporary standpoint, they also introduced natural fragments of first-order modal logic, warranting a comprehensive technical analysis. In this paper, drawing inspiration from the natural logic program, we propose and examine several variants of modal syllogistic within the epistemic context, thereby coining the term Epistemic Syllogistic. Specifically, we concentrate on the de re interpretation of epistemic syllogisms containing non-trivial yet natural expressions such as "all things known to be A are also known to be not B." We explore the epistemic apodeictic syllogistic and its extensions, which accommodate more complex terms. Our main contributions include several axiomatizations of these logics, with completeness proofs that may be of independent interest.
    
[^53]: 具有图增强信息的神经符号推荐系统

    Neural-Symbolic Recommendation with Graph-Enhanced Information. (arXiv:2307.05036v1 [cs.AI])

    [http://arxiv.org/abs/2307.05036](http://arxiv.org/abs/2307.05036)

    本研究结合了图神经网络和命题逻辑操作的优势，构建了一个具有全局隐式推理能力和局部显式逻辑推理能力的神经符号推荐模型。

    

    推荐系统不仅是一个从数据中归纳统计的问题，也是一个需要推理能力的认知任务。最先进的图神经网络在推荐系统中被广泛使用，因为它们能够从图结构数据中捕捉到隐式结构信息。然而，像大多数神经网络算法一样，它们只从感知的角度学习匹配模式。一些研究者使用用户行为进行逻辑推理，从认知推理的角度实现推荐预测，但这种推理是局部的，忽视了全局范围内的隐式信息。在这项工作中，我们结合了图神经网络和命题逻辑操作的优势，构建了一个具有全局隐式推理能力和局部显式逻辑推理能力的神经符号推荐模型。我们首先基于相邻交互原则构建了一个物品-物品图，并使用图神经网络对其进行学习和推理。然后，我们引入了命题逻辑操作，使模型能够从全局范围内进行推理。最后，我们通过实验证明了该模型的有效性和准确性。

    The recommendation system is not only a problem of inductive statistics from data but also a cognitive task that requires reasoning ability. The most advanced graph neural networks have been widely used in recommendation systems because they can capture implicit structured information from graph-structured data. However, like most neural network algorithms, they only learn matching patterns from a perception perspective. Some researchers use user behavior for logic reasoning to achieve recommendation prediction from the perspective of cognitive reasoning, but this kind of reasoning is a local one and ignores implicit information on a global scale. In this work, we combine the advantages of graph neural networks and propositional logic operations to construct a neuro-symbolic recommendation model with both global implicit reasoning ability and local explicit logic reasoning ability. We first build an item-item graph based on the principle of adjacent interaction and use graph neural net
    
[^54]: 发挥正则化策略在具有嘈杂标签的学习中的潜力

    Unleashing the Potential of Regularization Strategies in Learning with Noisy Labels. (arXiv:2307.05025v1 [cs.LG])

    [http://arxiv.org/abs/2307.05025](http://arxiv.org/abs/2307.05025)

    我们研究表明，结合交叉熵损失和正则化策略（如学习率衰减、模型权重平均和数据增强）的简单基准方法可以超过最先进方法，证明了正则化策略的组合在学习嘈杂标签问题中的潜力。

    

    近年来，对于学习嘈杂标签的研究主要集中在设计新算法，以实现对嘈杂训练标签的鲁棒性，并在干净数据上进行泛化。这些算法通常包括复杂的技术，如噪声建模、标签校正和协同训练。在本研究中，我们展示了使用交叉熵损失和常用的正则化策略（如学习率衰减、模型权重平均和数据增强）的简单基准方法可以超过最先进方法。我们的发现表明，采用正则化策略的组合比复杂的算法更有效地应对学习嘈杂标签的挑战。虽然一些正则化策略在之前的学习嘈杂标签研究中已被使用，但它们的全部潜力尚未得到充分探索。我们的结果鼓励重新评估学习嘈杂标签的基准，并促使重新考虑该领域的研究重点。

    In recent years, research on learning with noisy labels has focused on devising novel algorithms that can achieve robustness to noisy training labels while generalizing to clean data. These algorithms often incorporate sophisticated techniques, such as noise modeling, label correction, and co-training. In this study, we demonstrate that a simple baseline using cross-entropy loss, combined with widely used regularization strategies like learning rate decay, model weights average, and data augmentations, can outperform state-of-the-art methods. Our findings suggest that employing a combination of regularization strategies can be more effective than intricate algorithms in tackling the challenges of learning with noisy labels. While some of these regularization strategies have been utilized in previous noisy label learning research, their full potential has not been thoroughly explored. Our results encourage a reevaluation of benchmarks for learning with noisy labels and prompt reconsider
    
[^55]: 特征激活映射：用于图像分类的深度学习模型可视解释

    Feature Activation Map: Visual Explanation of Deep Learning Models for Image Classification. (arXiv:2307.05017v1 [cs.CV])

    [http://arxiv.org/abs/2307.05017](http://arxiv.org/abs/2307.05017)

    本文提出了一种名为特征激活映射（FAM）的解释工具，可以解释没有FC层的深度学习模型作为分类器，使其更加可解释、透明和可信。

    

    通过可视化图像上的判别区域，可以理解和解释卷积神经网络（CNN）的决策。为此，提出了基于类激活映射（CAM）的方法作为强大的解释工具，使深度学习模型的预测更加可解释、透明和可信。然而，所有基于CAM的方法（如CAM、Grad-CAM和Relevance-CAM）只能用于解释具有全连接（FC）层作为分类器的CNN模型。值得注意的是，许多深度学习模型在没有FC层的情况下对图像进行分类，例如小样本学习图像分类、对比学习图像分类和图像检索任务。在这项工作中，提出了一种名为特征激活映射（FAM）的事后解释工具，可以解释没有FC层的深度学习模型作为分类器。在所提出的FAM算法中，通过两个图像嵌入之间的相似度得到通道权重的贡献。

    Decisions made by convolutional neural networks(CNN) can be understood and explained by visualizing discriminative regions on images. To this end, Class Activation Map (CAM) based methods were proposed as powerful interpretation tools, making the prediction of deep learning models more explainable, transparent, and trustworthy. However, all the CAM-based methods (e.g., CAM, Grad-CAM, and Relevance-CAM) can only be used for interpreting CNN models with fully-connected (FC) layers as a classifier. It is worth noting that many deep learning models classify images without FC layers, e.g., few-shot learning image classification, contrastive learning image classification, and image retrieval tasks. In this work, a post-hoc interpretation tool named feature activation map (FAM) is proposed, which can interpret deep learning models without FC layers as a classifier. In the proposed FAM algorithm, the channel-wise contribution weights are derived from the similarity scores between two image emb
    
[^56]: 多智能体强化学习中的控制作为概率推理的新兴通信机制

    Control as Probabilistic Inference as an Emergent Communication Mechanism in Multi-Agent Reinforcement Learning. (arXiv:2307.05004v1 [cs.AI])

    [http://arxiv.org/abs/2307.05004](http://arxiv.org/abs/2307.05004)

    本文提出了一种将控制与概率推理结合的新颖的通信机制，应用于多智能体强化学习中。智能体通过推理控制其动作，并通过消息进行通信，从而实现协作任务。

    

    本文提出了一种新型的生成概率模型，将新兴通信和多智能体强化学习进行了整合。智能体通过概率推理进行动作规划，称为控制作为推理，并使用潜在变量和根据规划的动作进行估计的消息进行通信。通过这些消息，每个智能体可以发送关于其动作的信息，并了解另一个智能体的动作信息。因此，智能体根据估计的消息来改变其动作，以实现协作任务。这种消息的推理可以被视为通信，并且可以通过Metropolis-Hasting命名游戏来进行形式化。通过在网格世界环境中的实验，我们展示了提出的概率图模型可以推断出有意义的消息，以实现协作任务。

    This paper proposes a generative probabilistic model integrating emergent communication and multi-agent reinforcement learning. The agents plan their actions by probabilistic inference, called control as inference, and communicate using messages that are latent variables and estimated based on the planned actions. Through these messages, each agent can send information about its actions and know information about the actions of another agent. Therefore, the agents change their actions according to the estimated messages to achieve cooperative tasks. This inference of messages can be considered as communication, and this procedure can be formulated by the Metropolis-Hasting naming game. Through experiments in the grid world environment, we show that the proposed PGM can infer meaningful messages to achieve the cooperative task.
    
[^57]: 通过在线回归进行选择性采样和模仿学习

    Selective Sampling and Imitation Learning via Online Regression. (arXiv:2307.04998v1 [cs.LG])

    [http://arxiv.org/abs/2307.04998](http://arxiv.org/abs/2307.04998)

    本论文提出了一种通过在线回归实现选择性采样和模仿学习的方法，解决了在只有噪声专家反馈的情况下的问题。算法不需要大量样本即可成功，并取得了最佳的回归和查询次数界限。

    

    我们考虑通过主动查询嘈杂的专家来进行模仿学习（IL）的问题。虽然模仿学习在实践中取得了成功，但大部分先前的工作都假设可以获得无噪声的专家反馈，而这在许多应用中是不切实际的。实际上，当只能获得嘈杂的专家反馈时，依赖纯离线数据的算法（非交互式IL）被证明需要大量的样本才能成功。相反，在这项工作中，我们提供了一种交互式IL算法，它使用选择性采样来主动查询嘈杂的专家反馈。我们的贡献有两个方面：首先，我们提供了一种适用于通用函数类和多个动作的新选择性采样算法，并获得了迄今为止最好的回归和查询次数界限。其次，我们将这个分析扩展到了具有嘈杂专家反馈的IL问题，并提供了一种新的IL算法来进行有限查询。

    We consider the problem of Imitation Learning (IL) by actively querying noisy expert for feedback. While imitation learning has been empirically successful, much of prior work assumes access to noiseless expert feedback which is not practical in many applications. In fact, when one only has access to noisy expert feedback, algorithms that rely on purely offline data (non-interactive IL) can be shown to need a prohibitively large number of samples to be successful. In contrast, in this work, we provide an interactive algorithm for IL that uses selective sampling to actively query the noisy expert for feedback. Our contributions are twofold: First, we provide a new selective sampling algorithm that works with general function classes and multiple actions, and obtains the best-known bounds for the regret and the number of queries. Next, we extend this analysis to the problem of IL with noisy expert feedback and provide a new IL algorithm that makes limited queries.  Our algorithm for sele
    
[^58]: 利用自动生成的知识图谱和强化学习增强推荐系统

    Empowering recommender systems using automatically generated Knowledge Graphs and Reinforcement Learning. (arXiv:2307.04996v1 [cs.IR])

    [http://arxiv.org/abs/2307.04996](http://arxiv.org/abs/2307.04996)

    本文介绍了两种基于知识图谱的方法，一种使用强化学习，另一种使用XGBoost算法，用于个性化文章推荐。这些方法利用自动生成的知识图谱，并在一个大型跨国金融服务公司的客户中进行了实证研究。

    

    个性化推荐在直接营销中越来越重要，激发了通过知识图谱（KG）应用来提升客户体验的研究动机。例如，在金融服务领域，公司可以通过向客户提供相关金融文章来培养关系，促进客户参与和促进知情的金融决策。尽管一些方法专注于基于KG的推荐系统以改进内容，但在本研究中，我们专注于可解释的基于KG的推荐系统来进行决策。为此，我们提出了两种基于知识图谱的个性化文章推荐方法，用于一家大型跨国金融服务公司的一组客户。第一种方法使用强化学习，第二种方法使用XGBoost算法来向客户推荐文章。这两种方法都利用从结构化（表格数据）和非结构化数据（大量文本数据）生成的KG。

    Personalized recommendations have a growing importance in direct marketing, which motivates research to enhance customer experiences by knowledge graph (KG) applications. For example, in financial services, companies may benefit from providing relevant financial articles to their customers to cultivate relationships, foster client engagement and promote informed financial decisions. While several approaches center on KG-based recommender systems for improved content, in this study we focus on interpretable KG-based recommender systems for decision making.To this end, we present two knowledge graph-based approaches for personalized article recommendations for a set of customers of a large multinational financial services company. The first approach employs Reinforcement Learning and the second approach uses the XGBoost algorithm for recommending articles to the customers. Both approaches make use of a KG generated from both structured (tabular data) and unstructured data (a large body o
    
[^59]: 单调的深度Boltzmann机器

    Monotone deep Boltzmann machines. (arXiv:2307.04990v1 [cs.LG])

    [http://arxiv.org/abs/2307.04990](http://arxiv.org/abs/2307.04990)

    在这项工作中，我们提出了一种新的限制模型，即单调DBM，它允许每一层具有任意的自连接，但通过一种方式限制了权重，以保证存在和全局唯一的均场不动点。

    

    深度Boltzmann机器(DBMs)是最早研究的"深度"学习方法之一，它是由一个描述网络中所有变量/节点的可能性的成对能量函数所控制的多层概率模型。在实际应用中，为了实现更高效的推理，DBMs通常会受到一些限制，例如通过"限制性" Boltzmann机器(RBM)架构（不允许层间连接）。在这项工作中，我们重新审视了通用的DBM方法，并提出了一个问题：是否存在其他可能的设计限制，以实现高效的（近似）推理？具体地，我们开发了一种新的限制模型，即单调DBM，它允许每一层具有任意的自连接，但通过一种方式限制了权重，以保证存在和全局唯一的均场不动点。为此，我们利用了最近提出的单调深度均衡模型的工具，并展示了一个特定的...

    Deep Boltzmann machines (DBMs), one of the first ``deep'' learning methods ever studied, are multi-layered probabilistic models governed by a pairwise energy function that describes the likelihood of all variables/nodes in the network. In practice, DBMs are often constrained, i.e., via the \emph{restricted} Boltzmann machine (RBM) architecture (which does not permit intra-layer connections), in order to allow for more efficient inference. In this work, we revisit the generic DBM approach, and ask the question: are there other possible restrictions to their design that would enable efficient (approximate) inference? In particular, we develop a new class of restricted model, the monotone DBM, which allows for arbitrary self-connection in each layer, but restricts the \emph{weights} in a manner that guarantees the existence and global uniqueness of a mean-field fixed point. To do this, we leverage tools from the recently-proposed monotone Deep Equilibrium model and show that a particular 
    
[^60]: 用生成型智能体进行流行病建模

    Epidemic Modeling with Generative Agents. (arXiv:2307.04986v1 [cs.AI])

    [http://arxiv.org/abs/2307.04986](http://arxiv.org/abs/2307.04986)

    本研究利用生成型智能体在流行病模型中模拟了人类行为，通过模拟实验展示了智能体的行为与真实世界相似，并成功实现了流行病曲线的平坦化。该研究创造了改进动态系统建模的潜力，为表示人类思维、推理和决策提供了一种途径。

    

    本研究提供了一种新的个体层面建模范式，以解决将人类行为纳入流行病模型的重大挑战。通过在基于智能体的流行病模型中利用生成型人工智能，每个智能体都能够通过连接到大型语言模型（如ChatGPT）进行自主推理和决策。通过各种模拟实验，我们呈现了令人信服的证据，表明生成型智能体模仿了现实世界的行为，如生病时进行隔离，病例增加时进行自我隔离。总体而言，智能体展示了类似于近期流行病观察到的多次波动，然后是一段流行期。此外，智能体成功地使流行病曲线平坦化。该研究提供了一种改进动态系统建模的潜力，通过提供一种表示人类大脑、推理和决策的方法。

    This study offers a new paradigm of individual-level modeling to address the grand challenge of incorporating human behavior in epidemic models. Using generative artificial intelligence in an agent-based epidemic model, each agent is empowered to make its own reasonings and decisions via connecting to a large language model such as ChatGPT. Through various simulation experiments, we present compelling evidence that generative agents mimic real-world behaviors such as quarantining when sick and self-isolation when cases rise. Collectively, the agents demonstrate patterns akin to multiple waves observed in recent pandemics followed by an endemic period. Moreover, the agents successfully flatten the epidemic curve. This study creates potential to improve dynamic system modeling by offering a way to represent human brain, reasoning, and decision making.
    
[^61]: 大型语言模型中RLHF的秘密 第一部分：PPO

    Secrets of RLHF in Large Language Models Part I: PPO. (arXiv:2307.04964v1 [cs.CL])

    [http://arxiv.org/abs/2307.04964](http://arxiv.org/abs/2307.04964)

    本论文研究了大型语言模型中RLHF的秘密，重点关注了奖励模型、PPO和进程监督等技术路径，探索如何解决RLHF的稳定训练问题。

    

    大型语言模型（LLMs）为推动人工通用智能的进展提供了蓝图。其主要目标是成为以人为中心的（有益、诚实和无害）助手。与人类的对齐具有至关重要的意义，强化学习与人类反馈（RLHF）成为支撑这一追求的关键技术范式。当前的技术路线通常包括用于衡量人类偏好的奖励模型、用于优化策略模型输出的近端策略优化（PPO）以及用于改善逐步推理能力的进程监督。然而，由于奖励设计、环境交互和代理训练的挑战，再加上大型语言模型的试验成本巨大，对于AI研究人员来说，激励技术对齐和LLMs的安全着陆存在重大障碍。RLHF的稳定训练仍然是一个难题。

    Large language models (LLMs) have formulated a blueprint for the advancement of artificial general intelligence. Its primary objective is to function as a human-centric (helpful, honest, and harmless) assistant. Alignment with humans assumes paramount significance, and reinforcement learning with human feedback (RLHF) emerges as the pivotal technological paradigm underpinning this pursuit. Current technical routes usually include \textbf{reward models} to measure human preferences, \textbf{Proximal Policy Optimization} (PPO) to optimize policy model outputs, and \textbf{process supervision} to improve step-by-step reasoning capabilities. However, due to the challenges of reward design, environment interaction, and agent training, coupled with huge trial and error cost of large language models, there is a significant barrier for AI researchers to motivate the development of technical alignment and safe landing of LLMs. The stable training of RLHF has still been a puzzle. In the first re
    
[^62]: 利用人类好奇心的网络理论进行内在驱动的图探索

    Intrinsically motivated graph exploration using network theories of human curiosity. (arXiv:2307.04962v1 [cs.LG])

    [http://arxiv.org/abs/2307.04962](http://arxiv.org/abs/2307.04962)

    在这项工作中，我们通过应用人类好奇心的两个理论，发展了一种内在驱动的图探索方法。我们利用图神经网络的强化学习将拓扑特征作为奖励，从而实现了对图结构数据的探索。在多类合成生成图上进行的实验证明，我们的方法不仅可以推广到更大的环境，还可以进行更长的探索步行。同时，我们的方法比传统的贪婪评估方法更高效。

    

    内在驱动的探索在强化学习中已被证明具有用途，即使没有额外的外在奖励。当环境自然表示为图时，如何最好地引导探索仍是一个未解决的问题。在这项工作中，我们提出了一种新的方法，通过人类好奇心的两个理论：信息差理论和压缩进展理论，来激励对图结构数据进行探索。这些理论将好奇心视为对环境中访问节点所引发的子图的拓扑特征进行优化的内在动机。我们将这些提出的特征作为基于图神经网络的强化学习的奖励。在多个类别的合成生成图上，我们发现训练代理可以推广到更大的环境和比训练过程中更长的探索性步行。我们的方法的计算效率高于相关拓扑属性的贪婪评估。所提出的内在动机产生的奖励在多类合成生成图生成上推广良好，并且在训练期间能够在更大的环境中进行更长的探索步行。

    Intrinsically motivated exploration has proven useful for reinforcement learning, even without additional extrinsic rewards. When the environment is naturally represented as a graph, how to guide exploration best remains an open question. In this work, we propose a novel approach for exploring graph-structured data motivated by two theories of human curiosity: the information gap theory and the compression progress theory. The theories view curiosity as an intrinsic motivation to optimize for topological features of subgraphs induced by the visited nodes in the environment. We use these proposed features as rewards for graph neural-network-based reinforcement learning. On multiple classes of synthetically generated graphs, we find that trained agents generalize to larger environments and to longer exploratory walks than are seen during training. Our method computes more efficiently than the greedy evaluation of the relevant topological properties. The proposed intrinsic motivations bea
    
[^63]: 非累积目标的强化学习

    Reinforcement Learning with Non-Cumulative Objective. (arXiv:2307.04957v1 [cs.LG])

    [http://arxiv.org/abs/2307.04957](http://arxiv.org/abs/2307.04957)

    本文研究了最优控制和强化学习中非累积目标的挑战，并提出了修改现有算法的方法来优化这些目标。研究结果表明，在贝尔曼最优性方程中使用广义运算可以更好地处理非累积目标。

    

    在强化学习中，目标几乎总是定义为沿过程中奖励的\emph{累积}函数。然而，在许多最优控制和强化学习问题中，尤其是在通信和网络领域中，目标并不自然地表达为奖励的求和。本文中，我们认识到各种问题中非累积目标的普遍存在，并提出了修改现有算法以优化这些目标的方法。具体来说，我们深入研究了许多最优控制和强化学习算法的基本构建模块：贝尔曼最优性方程。为了优化非累积目标，我们用与目标相对应的广义运算替换了贝尔曼更新规则中的原始求和运算。此外，我们提供了广义运算形式的足够条件以及对马尔可夫决策的假设。

    In reinforcement learning, the objective is almost always defined as a \emph{cumulative} function over the rewards along the process. However, there are many optimal control and reinforcement learning problems in various application fields, especially in communications and networking, where the objectives are not naturally expressed as summations of the rewards. In this paper, we recognize the prevalence of non-cumulative objectives in various problems, and propose a modification to existing algorithms for optimizing such objectives. Specifically, we dive into the fundamental building block for many optimal control and reinforcement learning algorithms: the Bellman optimality equation. To optimize a non-cumulative objective, we replace the original summation operation in the Bellman update rule with a generalized operation corresponding to the objective. Furthermore, we provide sufficient conditions on the form of the generalized operation as well as assumptions on the Markov decision 
    
[^64]: 使用循环Transformer学习解决约束满足问题

    Learning to Solve Constraint Satisfaction Problems with Recurrent Transformer. (arXiv:2307.04895v1 [cs.AI])

    [http://arxiv.org/abs/2307.04895](http://arxiv.org/abs/2307.04895)

    循环Transformer是一种可行的方法来学习解决约束满足问题。相比于类似的方法，循环Transformer具有明显的优势，可以处理视觉输入，成功解决符号基础问题，并实现样本高效学习和半监督学习。

    

    约束满足问题（CSPs）是关于找到满足给定约束条件的变量值的问题。我们展示了使用增加循环性质的Transformer来学习以端到端的方式解决CSPs是可行的方法，相比于Graph神经网络、SATNet和一些神经符号模型等最先进的方法具有明显的优势。由于Transformer可以处理视觉输入的能力，提出的循环Transformer可以直接应用于视觉约束推理问题，并成功解决符号基础问题。我们还展示了如何利用离散约束的演绎知识来实现Transformer的归纳学习，从而实现CSPs的样本高效学习和半监督学习。

    Constraint satisfaction problems (CSPs) are about finding values of variables that satisfy the given constraints. We show that Transformer extended with recurrence is a viable approach to learning to solve CSPs in an end-to-end manner, having clear advantages over state-of-the-art methods such as Graph Neural Networks, SATNet, and some neuro-symbolic models. With the ability of Transformer to handle visual input, the proposed Recurrent Transformer can straightforwardly be applied to visual constraint reasoning problems while successfully addressing the symbol grounding problem. We also show how to leverage deductive knowledge of discrete constraints in the Transformer's inductive learning to achieve sample-efficient learning and semi-supervised learning for CSPs.
    
[^65]: 选择好对手：如何指导程序化策略的合成

    Choosing Well Your Opponents: How to Guide the Synthesis of Programmatic Strategies. (arXiv:2307.04893v1 [cs.LG])

    [http://arxiv.org/abs/2307.04893](http://arxiv.org/abs/2307.04893)

    这篇论文介绍了一种名为2L的算法，该算法能够提供引导合成程序化策略的参考策略，通过在实验中的表现和在MicroRTS锦标赛中的胜利，证明了2L算法相对于其他学习算法的优势。

    

    本论文介绍了一种名为Local Learner (2L)的算法，用于提供一组参考策略，以指导在两人零和博弈中搜索程序化策略。之前的学习算法，如迭代最佳响应算法(IBR)，虚构游戏算法(FP)和双正交算法(DO)，计算复杂度较高或会漏掉指导搜索算法的重要信息。2L主动选择一组参考策略以提高搜索信号。我们通过在三个游戏中引导局部搜索算法来实证我们的方法优势，其中包括MicroRTS，一个具有挑战性的实时战略游戏。结果表明，2L学习到的参考策略提供了比IBR，FP和DO更强的搜索信号。我们还模拟了一场MicroRTS锦标赛，其中使用2L合成器的表现超过了两个最新MicroRTS比赛的胜者，这些胜者均为人类编程员编写的程序化策略。

    This paper introduces Local Learner (2L), an algorithm for providing a set of reference strategies to guide the search for programmatic strategies in two-player zero-sum games. Previous learning algorithms, such as Iterated Best Response (IBR), Fictitious Play (FP), and Double-Oracle (DO), can be computationally expensive or miss important information for guiding search algorithms. 2L actively selects a set of reference strategies to improve the search signal. We empirically demonstrate the advantages of our approach while guiding a local search algorithm for synthesizing strategies in three games, including MicroRTS, a challenging real-time strategy game. Results show that 2L learns reference strategies that provide a stronger search signal than IBR, FP, and DO. We also simulate a tournament of MicroRTS, where a synthesizer using 2L outperformed the winners of the two latest MicroRTS competitions, which were programmatic strategies written by human programmers.
    
[^66]: 测量和缓解强化学习中的干扰

    Measuring and Mitigating Interference in Reinforcement Learning. (arXiv:2307.04887v1 [cs.LG])

    [http://arxiv.org/abs/2307.04887](http://arxiv.org/abs/2307.04887)

    本文提供了一种衡量强化学习中干扰的新方法，并且提出了一类在线感知算法来减轻干扰，这些算法在经典控制环境中提高了稳定性和性能。

    

    灾难性干扰在许多基于网络的学习系统中很常见，并且存在许多减轻干扰的建议。在克服干扰之前，我们必须更好地理解它。在这项工作中，我们为Fitted Q-Iteration和DQN等基于值的强化学习方法提供了干扰的定义和新型度量。我们系统地评估了我们的干扰度量，在各种网络架构上显示出它与控制性能的不稳定性相关。我们的新干扰度量使我们能够提出关于常用深度学习架构的新科学问题，并研究减轻干扰的学习算法。最后，我们概述了一类我们称为在线感知算法的算法，旨在减轻干扰，并且根据我们的度量显示它们减少了干扰，并在几个经典的控制环境中提高了稳定性和性能。

    Catastrophic interference is common in many network-based learning systems, and many proposals exist for mitigating it. Before overcoming interference we must understand it better. In this work, we provide a definition and novel measure of interference for value-based reinforcement learning methods such as Fitted Q-Iteration and DQN. We systematically evaluate our measure of interference, showing that it correlates with instability in control performance, across a variety of network architectures. Our new interference measure allows us to ask novel scientific questions about commonly used deep learning architectures and study learning algorithms which mitigate interference. Lastly, we outline a class of algorithms which we call online-aware that are designed to mitigate interference, and show they do reduce interference according to our measure and that they improve stability and performance in several classic control environments.
    
[^67]: Fed-CPrompt: 无重复学习的联邦持续学习的对比提示

    Fed-CPrompt: Contrastive Prompt for Rehearsal-Free Federated Continual Learning. (arXiv:2307.04869v1 [cs.LG])

    [http://arxiv.org/abs/2307.04869](http://arxiv.org/abs/2307.04869)

    本文提出了一种名为Fed-CPrompt的方法，用于解决无重复学习的联邦持续学习中的遗忘问题。该方法通过异步提示学习和对比持续损失处理异步任务到达和异构数据分布，并在实验证明其在该领域取得了最先进的性能。

    

    联邦持续学习（FCL）从分布在客户端上的机密数据集中逐步学习任务。本文着重研究无重复学习的FCL，在学习新任务时存在因无法访问历史任务数据而导致严重遗忘的问题。为解决此问题，我们提出了基于提示学习技术的Fed-CPrompt，以一种高效的通信方式获得任务特定的提示。Fed-CPrompt引入了两个关键组件，异步提示学习和对比持续损失，以分别处理FCL中的异步任务到达和异构数据分布。大量实验证明了Fed-CPrompt在实现最先进的无重复学习FCL性能方面的有效性。

    Federated continual learning (FCL) learns incremental tasks over time from confidential datasets distributed across clients. This paper focuses on rehearsal-free FCL, which has severe forgetting issues when learning new tasks due to the lack of access to historical task data. To address this issue, we propose Fed-CPrompt based on prompt learning techniques to obtain task-specific prompts in a communication-efficient way. Fed-CPrompt introduces two key components, asynchronous prompt learning, and contrastive continual loss, to handle asynchronous task arrival and heterogeneous data distributions in FCL, respectively. Extensive experiments demonstrate the effectiveness of Fed-CPrompt in achieving SOTA rehearsal-free FCL performance.
    
[^68]: 使用腰部佩戴的加速计在典型的行走和跑步速度范围内自动检测步态事件和行走距离

    Automated Detection of Gait Events and Travel Distance Using Waist-worn Accelerometers Across a Typical Range of Walking and Running Speeds. (arXiv:2307.04866v1 [eess.SP])

    [http://arxiv.org/abs/2307.04866](http://arxiv.org/abs/2307.04866)

    该论文研究了使用腰部佩戴的加速计自动检测步态事件和行走距离的方法，通过分析市售智能手机加速计数据，实现了从广泛的步态速度范围中提取步态特征，可用于对Duchenne肌肉萎缩患儿和典型发育正常患者的评估。

    

    背景：估计步态（CFs）的时间空间临床特征，如步数和长度、步长、步频、步速和行走距离等，在使用可穿戴式加速计进行基于社区的移动性评估中是一个重要的组成部分。然而，由于设备复杂性和可用性、成本和分析方法学引起的挑战限制了此类工具的广泛应用。研究问题：能否使用市售智能手机的加速计数据来提取Duchenne肌肉萎缩（DMD）患儿和典型发育正常（TDs）患者在广泛步态速度范围内的步态CFs，并使用机器学习（ML）方法。方法：15名DMD患儿和15名TDs被要求在10MRW、25MRW、100MRW、6MWT和FW评估中以一系列步态速度进行监督性临床测试，同时佩戴手机基础加速计。

    Background: Estimation of temporospatial clinical features of gait (CFs), such as step count and length, step duration, step frequency, gait speed and distance traveled is an important component of community-based mobility evaluation using wearable accelerometers. However, challenges arising from device complexity and availability, cost and analytical methodology have limited widespread application of such tools. Research Question: Can accelerometer data from commercially-available smartphones be used to extract gait CFs across a broad range of attainable gait velocities in children with Duchenne muscular dystrophy (DMD) and typically developing controls (TDs) using machine learning (ML)-based methods Methods: Fifteen children with DMD and 15 TDs underwent supervised clinical testing across a range of gait speeds using 10 or 25m run/walk (10MRW, 25MRW), 100m run/walk (100MRW), 6-minute walk (6MWT) and free-walk (FW) evaluations while wearing a mobile phone-based accelerometer at the wa
    
[^69]: SHAP@k：高效且可能近似正确（PAC）地识别Top-k特征

    SHAP@k:Efficient and Probably Approximately Correct (PAC) Identification of Top-k Features. (arXiv:2307.04850v1 [cs.LG])

    [http://arxiv.org/abs/2307.04850](http://arxiv.org/abs/2307.04850)

    本文提出了SHAP@k框架，旨在通过提高样本效率来解决Top-k特征识别问题，通过将问题转化为Explore-m问题并利用多臂赌博机的技术来实现。

    

    SHAP框架通过计算特征重要性提供了一种解释模型预测的方法。受金融应用的启发，我们引入了Top-k识别问题（TkIP），其目标是识别具有最高SHAP值的k个特征。虽然任何计算带有不确定性估计的SHAP值的方法（如KernelSHAP和SamplingSHAP）都可以轻松适应TkIP的解决，但这样做会导致样本效率低下。我们的工作目标是在解决TkIP的背景下提高现有方法的样本效率。我们的关键洞察是TkIP可以作为一个Explore-m问题进行建模，该问题与多臂赌博机（MAB）相关的问题已经得到了深入研究。这种联系使我们能够通过利用MAB文献中的两种技术来提高样本效率：（1）更好的停止条件（停止采样），识别PAC（可能近似正确）保证已经满足；（2）一种贪婪采样方案。

    The SHAP framework provides a principled method to explain the predictions of a model by computing feature importance. Motivated by applications in finance, we introduce the Top-k Identification Problem (TkIP), where the objective is to identify the k features with the highest SHAP values. While any method to compute SHAP values with uncertainty estimates (such as KernelSHAP and SamplingSHAP) can be trivially adapted to solve TkIP, doing so is highly sample inefficient. The goal of our work is to improve the sample efficiency of existing methods in the context of solving TkIP. Our key insight is that TkIP can be framed as an Explore-m problem--a well-studied problem related to multi-armed bandits (MAB). This connection enables us to improve sample efficiency by leveraging two techniques from the MAB literature: (1) a better stopping-condition (to stop sampling) that identifies when PAC (Probably Approximately Correct) guarantees have been met and (2) a greedy sampling scheme that judic
    
[^70]: SigOpt Mulch: 一种自动学习梯度提升树的智能系统

    SigOpt Mulch: An Intelligent System for AutoML of Gradient Boosted Trees. (arXiv:2307.04849v1 [cs.LG])

    [http://arxiv.org/abs/2307.04849](http://arxiv.org/abs/2307.04849)

    SigOpt Mulch是一种智能系统，用于自动化调整梯度提升树模型的超参数。与其他现有系统不同，SigOpt Mulch是“模型感知型”的，能够针对GBTs进行更优化的性能调整，并且无需领域知识，帮助实现自动化实验。

    

    梯度提升树(GBTs)是研究人员、机器学习(ML)实践者和数据科学家普遍使用的模型，因为它们具有稳健的性能、可解释的行为和易于使用的特点。训练GBTs的一个关键挑战是调整超参数。在实践中，选择这些超参数通常是手动完成的。最近，ML社区提倡通过黑盒优化来调整超参数，并开发了最先进的系统来实现这一目标。然而，将这些系统应用于调整GBTs存在两个缺点。首先，这些系统不具备“模型感知性”，而是设计用于“通用”模型，这导致了优化性能的显著降低。其次，使用这些系统需要“领域知识”，比如超参数搜索空间的选择，这与黑盒优化旨在提供的自动实验相悖。在本文中，我们介绍了SigOpt Mulch

    Gradient boosted trees (GBTs) are ubiquitous models used by researchers, machine learning (ML) practitioners, and data scientists because of their robust performance, interpretable behavior, and ease-of-use. One critical challenge in training GBTs is the tuning of their hyperparameters. In practice, selecting these hyperparameters is often done manually. Recently, the ML community has advocated for tuning hyperparameters through black-box optimization and developed state-of-the-art systems to do so. However, applying such systems to tune GBTs suffers from two drawbacks. First, these systems are not \textit{model-aware}, rather they are designed to apply to a \textit{generic} model; this leaves significant optimization performance on the table. Second, using these systems requires \textit{domain knowledge} such as the choice of hyperparameter search space, which is an antithesis to the automatic experimentation that black-box optimization aims to provide. In this paper, we present SigOp
    
[^71]: 时间差分强化学习的动态

    Dynamics of Temporal Difference Reinforcement Learning. (arXiv:2307.04841v1 [stat.ML])

    [http://arxiv.org/abs/2307.04841](http://arxiv.org/abs/2307.04841)

    我们使用统计物理学的概念，研究了时间差分学习在线性函数逼近器下的典型学习曲线。我们发现由于子采样可能的轨迹空间而产生的随机半梯度噪声会导致值误差出现显著的平台。

    

    强化学习在需要学习在反馈有限的环境中行动的多个应用中取得了成功。然而，尽管有这种经验上的成功，仍然没有对强化学习模型的参数和用于表示状态的特征如何相互作用控制学习动态的理论理解。在这项工作中，我们使用统计物理学的概念，研究线性函数逼近器下时间差分学习价值函数的典型学习曲线。我们的理论是在一个高斯等效假设下推导出来的，其中对随机轨迹的平均值被替换为时态相关的高斯特征平均值，并且我们在小规模马尔可夫决策过程上验证了我们的假设。我们发现，由于对可能的轨迹空间进行子采样而产生的随机半梯度噪声导致值误差出现显著的平台，这与传统的梯度下降不同。

    Reinforcement learning has been successful across several applications in which agents have to learn to act in environments with sparse feedback. However, despite this empirical success there is still a lack of theoretical understanding of how the parameters of reinforcement learning models and the features used to represent states interact to control the dynamics of learning. In this work, we use concepts from statistical physics, to study the typical case learning curves for temporal difference learning of a value function with linear function approximators. Our theory is derived under a Gaussian equivalence hypothesis where averages over the random trajectories are replaced with temporally correlated Gaussian feature averages and we validate our assumptions on small scale Markov Decision Processes. We find that the stochastic semi-gradient noise due to subsampling the space of possible episodes leads to significant plateaus in the value error, unlike in traditional gradient descent 
    
[^72]: 扩大大型语言模型的限制、伤害和风险

    Amplifying Limitations, Harms and Risks of Large Language Models. (arXiv:2307.04821v1 [cs.CL])

    [http://arxiv.org/abs/2307.04821](http://arxiv.org/abs/2307.04821)

    本文旨在扩大人工智能（AI）和大型语言模型（LLMs）的限制、伤害和风险，并指出当前关于AI的夸大炒作和误解。这有助于消除一些对AI技术的错误认识，并提醒人们注意由于这些限制而产生的实际伤害。

    

    我们在这篇文章中试图通过一个小小的举动来抵制人工智能（AI）及其能力所带来的指数级增长的炒作，以及由此带来的科幻情景的分散注意力。这也有助于那些在该领域之外的人了解一些AI技术的局限性。在当前流行话语的背景下，AI默认为意味着基础和大型语言模型（LLMs），如用于创建ChatGPT的模型。这本身就是对研究领域多样性、深度和容量的曲解，而真正代表AI领域的是研究、研究人员和技术的多样性。AI作为一门研究领域，至少从20世纪50年代以来就存在于软件构件中。我们试图突出一些LLMs的局限性，并在此过程中强调由于这些局限性已经出现并将继续出现的伤害。

    We present this article as a small gesture in an attempt to counter what appears to be exponentially growing hype around Artificial Intelligence (AI) and its capabilities, and the distraction provided by the associated talk of science-fiction scenarios that might arise if AI should become sentient and super-intelligent. It may also help those outside of the field to become more informed about some of the limitations of AI technology. In the current context of popular discourse AI defaults to mean foundation and large language models (LLMs) such as those used to create ChatGPT. This in itself is a misrepresentation of the diversity, depth and volume of research, researchers, and technology that truly represents the field of AI. AI being a field of research that has existed in software artefacts since at least the 1950's. We set out to highlight a number of limitations of LLMs, and in so doing highlight that harms have already arisen and will continue to arise due to these limitations. A
    
[^73]: S2vNTM: 半监督vMF神经主题建模

    S2vNTM: Semi-supervised vMF Neural Topic Modeling. (arXiv:2307.04804v1 [cs.CL])

    [http://arxiv.org/abs/2307.04804](http://arxiv.org/abs/2307.04804)

    S2vNTM是一种半监督的vMF神经主题建模方法，通过利用关键词的模式来识别潜在的主题，并优化主题关键词集的质量，提高了分类准确度，并且速度至少比基线模型快两倍。

    

    基于语言模型的方法对于文本分类来说是一种强大的技术。然而，这些模型存在一些缺点：（1）很难整合人类知识，比如关键词；（2）训练模型需要大量资源；（3）依赖大规模文本数据进行预训练。本文中，我们提出了半监督vMF神经主题建模（S2vNTM）来克服这些困难。S2vNTM将一些种子关键词作为主题的输入。S2vNTM利用关键词的模式来识别潜在的主题，并优化主题关键词集的质量。在各种数据集上，S2vNTM在提供有限关键词的情况下，在分类准确度方面优于现有的半监督主题建模方法。S2vNTM至少比基线模型快两倍。

    Language model based methods are powerful techniques for text classification. However, the models have several shortcomings. (1) It is difficult to integrate human knowledge such as keywords. (2) It needs a lot of resources to train the models. (3) It relied on large text data to pretrain. In this paper, we propose Semi-Supervised vMF Neural Topic Modeling (S2vNTM) to overcome these difficulties. S2vNTM takes a few seed keywords as input for topics. S2vNTM leverages the pattern of keywords to identify potential topics, as well as optimize the quality of topics' keywords sets. Across a variety of datasets, S2vNTM outperforms existing semi-supervised topic modeling methods in classification accuracy with limited keywords provided. S2vNTM is at least twice as fast as baselines.
    
[^74]: 在发展有效的人工智能与人类团队协作中应用以人为中心的人工智能：以人工智能-人类共同认知系统的视角

    Applying human-centered AI in developing effective human-AI teaming: A perspective of human-AI joint cognitive systems. (arXiv:2307.03913v1 [cs.AI])

    [http://arxiv.org/abs/2307.03913](http://arxiv.org/abs/2307.03913)

    本研究介绍了将人工智能与人类团队协作作为一种新的发展范式的方法，强调有效的人工智能与人类团队需要充分利用双方的独特能力，同时克服挑战和限制，提高联合表现。同时，该研究指出现有研究往往未考虑到动态、适应性和协作团队环境中人工智能的功能，呼吁加强关于人工智能与人类团队协作的研究。

    

    研究和应用已将人工智能与人类团队协作作为一种新的范式来发展人工智能系统。人工智能与人类团队协作认识到人工智能将作为一名队友而不仅仅是工具与人类协作。有效的人工智能与人类团队需要能够充分利用人类和人工智能的独特能力，同时克服每个成员的已知挑战和限制，增强人类能力，并将联合性能提高到任何实体之上。2023年全国人工智能研究和战略计划更新认识到，主要关注人工智能系统独立性能的研究计划往往未考虑到人工智能在动态、适应性和协作团队环境中必须提供的功能，并呼吁进一步研究人工智能与人类团队协作。然而，人们对于人工智能是否能作为人类的队友存在争议。主要的关注点在于采用"协作"范式是否与人类的认知过程相矛盾。

    Research and application have used human-AI teaming (HAT) as a new paradigm to develop AI systems. HAT recognizes that AI will function as a teammate instead of simply a tool in collaboration with humans. Effective human-AI teams need to be capable of taking advantage of the unique abilities of both humans and AI while overcoming the known challenges and limitations of each member, augmenting human capabilities, and raising joint performance beyond that of either entity. The National AI Research and Strategic Plan 2023 update has recognized that research programs focusing primarily on the independent performance of AI systems generally fail to consider the functionality that AI must provide within the context of dynamic, adaptive, and collaborative teams and calls for further research on human-AI teaming and collaboration. However, there has been debate about whether AI can work as a teammate with humans. The primary concern is that adopting the "teaming" paradigm contradicts the human
    
[^75]: QI2 -- 一个用于数据质量保证的交互工具

    QI2 -- an Interactive Tool for Data Quality Assurance. (arXiv:2307.03419v1 [cs.CY])

    [http://arxiv.org/abs/2307.03419](http://arxiv.org/abs/2307.03419)

    本文介绍了一种用于数据质量保证的交互工具QI2，该工具支持对多个数据质量方面的验证和定量数据质量要求的验证。通过在MNIST数据集上进行演示，展示了该方法的应用和优势。

    

    高数据质量的重要性随着机器学习系统和大数据的增长影响和分布而增加。此外，欧洲委员会计划的AI法案为数据质量定义了具有挑战性的法律要求，特别是对于市场推出与安全相关的机器学习系统。本文介绍了一种支持多个数据质量方面的数据质量保证过程的新方法。这种方法可以验证定量数据质量要求。通过小例子数据集介绍和解释了该概念和优势。如何应用该方法在基于手写数字的知名MNIST数据集上进行了演示。

    The importance of high data quality is increasing with the growing impact and distribution of ML systems and big data. Also the planned AI Act from the European commission defines challenging legal requirements for data quality especially for the market introduction of safety relevant ML systems. In this paper we introduce a novel approach that supports the data quality assurance process of multiple data quality aspects. This approach enables the verification of quantitative data quality requirements. The concept and benefits are introduced and explained on small example data sets. How the method is applied is demonstrated on the well known MNIST data set based an handwritten digits.
    
[^76]: 对大型语言模型评估的调查

    A Survey on Evaluation of Large Language Models. (arXiv:2307.03109v1 [cs.CL])

    [http://arxiv.org/abs/2307.03109](http://arxiv.org/abs/2307.03109)

    本文综述了大型语言模型（LLMs）的评估方法，关注三个关键维度：评估什么、在哪里评估以及如何评估。评估任务包括自然语言处理、推理、医学应用、伦理学、教育、自然和社会科学、代理应用等多个领域。本文为社会层面对LLMs潜在风险的理解提供了重要参考。

    

    大型语言模型（LLMs）由于在各种应用中表现出的前所未有的性能而在学术界和工业界越来越受欢迎。随着LLMs在研究和日常使用中继续发挥着重要作用，它们的评估变得越来越关键，不仅在任务水平上，而且在社会层面上，以更好地了解它们的潜在风险。在过去的几年里，已经做出了相当大的努力来从不同的角度来研究LLMs。本文综述了LLMs的这些评估方法，重点关注三个关键维度：评估什么、在哪里评估以及如何评估。首先，我们从评估任务的角度提供了一个概述，涵盖了一般的自然语言处理任务、推理、医学应用、伦理学、教育、自然科学和社会科学、代理应用和其他领域。其次，我们通过深入探讨评估方法和基准答案来回答“在哪里”和“如何”这两个问题。

    Large language models (LLMs) are gaining increasing popularity in both academia and industry, owing to their unprecedented performance in various applications. As LLMs continue to play a vital role in both research and daily use, their evaluation becomes increasingly critical, not only at the task level, but also at the society level for better understanding of their potential risks. Over the past years, significant efforts have been made to examine LLMs from various perspectives. This paper presents a comprehensive review of these evaluation methods for LLMs, focusing on three key dimensions: what to evaluate, where to evaluate, and how to evaluate. Firstly, we provide an overview from the perspective of evaluation tasks, encompassing general natural language processing tasks, reasoning, medical usage, ethics, educations, natural and social sciences, agent applications, and other areas. Secondly, we answer the `where' and `how' questions by diving into the evaluation methods and bench
    
[^77]: RecallM:一种用于时间上下文理解和问题回答的架构

    RecallM: An Architecture for Temporal Context Understanding and Question Answering. (arXiv:2307.02738v1 [cs.AI])

    [http://arxiv.org/abs/2307.02738](http://arxiv.org/abs/2307.02738)

    本文介绍了一种名为RecallM的架构，用于创建可适应和可更新的长期记忆，以提升大型语言模型聊天机器人的时间理解能力。

    

    用于大型语言模型（LLM）聊天机器人的理想长期记忆机制将为连续学习、复杂推理和学习序列和时间依赖关系打下基础。创建这种类型的记忆机制是一个极具挑战性的问题。在本文中，我们探索了不同方法实现长期记忆的效果。我们提出了一种新的架构，专注于为AGI系统创建可适应和可更新的长期记忆。我们通过各种实验展示了RecallM架构的好处，特别是它提供的改进的时间理解能力。

    The ideal long-term memory mechanism for Large Language Model (LLM) based chatbots, would lay the foundation for continual learning, complex reasoning and allow sequential and temporal dependencies to be learnt. Creating this type of memory mechanism is an extremely challenging problem. In this paper we explore different methods of achieving the effect of long-term memory. We propose a new architecture focused on creating adaptable and updatable long-term memory for AGI systems. We demonstrate through various experiments the benefits of the RecallM architecture, particularly the improved temporal understanding it provides.
    
[^78]: 定义数据科学：一种新的研究范式

    Defining data science: a new field of inquiry. (arXiv:2306.16177v1 [cs.LG])

    [http://arxiv.org/abs/2306.16177](http://arxiv.org/abs/2306.16177)

    数据科学是一种新的研究范式，具有潜力和应用广泛性，在40多个学科、数百个研究领域和成千上万个应用中出现。然而，由于其起步阶段，目前存在许多定义的冗余和不一致性的问题。

    

    数据科学不是一门科学，而是一种研究范式。它的力量、范围和规模将超越科学，成为促使知识发现并改变世界的重要手段。我们尚未理解和定义它，这对于实现其潜力和管理其风险至关重要。现代数据科学处于起步阶段。自1962年以来缓慢发展，并且自2000年以来发展迅速，它是一种根本性的新的研究领域，是21世纪最活跃、最强大和发展最快的创新之一。由于其价值、力量和适用性，它正在40多个学科、数百个研究领域和成千上万个应用中出现。数以百万计的数据科学出版物中包含了无数关于数据科学和数据科学问题解决的定义。由于其起步阶段，许多定义是独立的、应用特定的、相互不完整的、冗余的或不一致的，因此数据科学也是如此。本研究通过提出解决数据科学多重定义挑战的方法来解决这个问题。

    Data science is not a science. It is a research paradigm. Its power, scope, and scale will surpass science, our most powerful research paradigm, to enable knowledge discovery and change our world. We have yet to understand and define it, vital to realizing its potential and managing its risks. Modern data science is in its infancy. Emerging slowly since 1962 and rapidly since 2000, it is a fundamentally new field of inquiry, one of the most active, powerful, and rapidly evolving 21st century innovations. Due to its value, power, and applicability, it is emerging in 40+ disciplines, hundreds of research areas, and thousands of applications. Millions of data science publications contain myriad definitions of data science and data science problem solving. Due to its infancy, many definitions are independent, application-specific, mutually incomplete, redundant, or inconsistent, hence so is data science. This research addresses this data science multiple definitions challenge by proposing 
    
[^79]: BayesFlow: 使用神经网络的摊还贝叶斯工作流

    BayesFlow: Amortized Bayesian Workflows With Neural Networks. (arXiv:2306.16015v1 [cs.LG])

    [http://arxiv.org/abs/2306.16015](http://arxiv.org/abs/2306.16015)

    BayesFlow是一个Python库，提供了使用神经网络进行摊还贝叶斯推断的功能，用户可以在模型仿真上训练定制的神经网络，并将其用于任何后续应用。这种摊还贝叶斯推断能够快速准确地进行推断，并实现了对不可计算后验分布的近似。

    

    现代贝叶斯推断涉及一系列计算技术，用于估计、验证和从概率模型中得出结论，作为数据分析中有原则的工作流的一部分。贝叶斯工作流中的典型问题包括近似不可计算后验分布以适应不同的模型类型，以及通过复杂性和预测性能比较同一过程的竞争模型。本文介绍了Python库BayesFlow，用于基于仿真训练已建立的神经网络架构，用于摊还数据压缩和推断。在BayesFlow中实现的摊还贝叶斯推断使用户能够在模型仿真上训练定制的神经网络，并将这些网络重用于模型的任何后续应用。由于训练好的网络可以几乎即时地执行推断，因此前期的神经网络训练很快就能够摊还。

    Modern Bayesian inference involves a mixture of computational techniques for estimating, validating, and drawing conclusions from probabilistic models as part of principled workflows for data analysis. Typical problems in Bayesian workflows are the approximation of intractable posterior distributions for diverse model types and the comparison of competing models of the same process in terms of their complexity and predictive performance. This manuscript introduces the Python library BayesFlow for simulation-based training of established neural network architectures for amortized data compression and inference. Amortized Bayesian inference, as implemented in BayesFlow, enables users to train custom neural networks on model simulations and re-use these networks for any subsequent application of the models. Since the trained networks can perform inference almost instantaneously, the upfront neural network training is quickly amortized.
    
[^80]: TrustGuard: 基于GNN的动态支持鲁棒且可解释的信任评估

    TrustGuard: GNN-based Robust and Explainable Trust Evaluation with Dynamicity Support. (arXiv:2306.13339v1 [cs.LG])

    [http://arxiv.org/abs/2306.13339](http://arxiv.org/abs/2306.13339)

    TrustGuard是一种基于GNN的信任评估模型，支持信任动态性，抗击鲁棒并提供解释能力，它的实验结果在准确性、鲁棒性和可解释性方面都优于其他方法。

    

    信任评估评估实体之间的信任关系并促进决策。机器学习由于其学习能力而表现出巨大的潜力，因此对信任评估具有重要意义。近年来，作为一种新的机器学习范 paradigm，图神经网络（GNN）在处理图形数据方面表现出优越性。这激发了研究人员探索将其用于信任评估，因为实体之间的信任关系可以建模为图形。但是，使用GNN的当前信任评估方法未能完全满足信任的动态性，忽略了攻击对信任评估的不利影响，并且无法提供令人信服的评估结果解释。为解决这些问题，在本文中，我们提出了TrustGuard ：一种支持信任动态性、抗击鲁棒且通过可视化提供解释的精确信任评估模型。具体而言，TrustGuard 设计了一个由动态感知节点嵌入层、图卷积层、注意机制层和信任预测层组成的分层架构。为了评估提出的模型的有效性，我们对真实数据集进行了实验，并将TrustGuard与其他最先进的方法进行了比较。实验结果表明，TrustGuard 在准确性、鲁棒性和可解释性方面均优于其他方法。

    Trust evaluation assesses trust relationships between entities and facilitates decision-making. Machine Learning (ML) shows great potential for trust evaluation owing to its learning capabilities. In recent years, Graph Neural Networks (GNNs), as a new ML paradigm, have demonstrated superiority in dealing with graph data. This has motivated researchers to explore their use in trust evaluation, as trust relationships among entities can be modeled as a graph. However, current trust evaluation methods that employ GNNs fail to fully satisfy the dynamicity nature of trust, overlook the adverse effects of attacks on trust evaluation, and cannot provide convincing explanations on evaluation results. To address these problems, in this paper, we propose TrustGuard, a GNN-based accurate trust evaluation model that supports trust dynamicity, is robust against typical attacks, and provides explanations through visualization. Specifically, TrustGuard is designed with a layered architecture that con
    
[^81]: 大型语言模型真的是良好的逻辑推理者吗？基于演绎、归纳和阿布达斯观点的全面评估。

    Are Large Language Models Really Good Logical Reasoners? A Comprehensive Evaluation From Deductive, Inductive and Abductive Views. (arXiv:2306.09841v1 [cs.CL])

    [http://arxiv.org/abs/2306.09841](http://arxiv.org/abs/2306.09841)

    本文评估了大型语言模型的逻辑推理能力，选择了15个典型数据集，考虑了演绎、归纳、阿布达斯和混合推理形式，并选择了三个代表性的LLMs进行零样本、一次和三次的设置下评估。提出精细级别的评估方法。

    

    大型语言模型(LLMs)在各种自然语言任务中取得了巨大成功。对LLMs的具体推理能力进行评估，如多语言推理和数学推理，引起了广泛关注。然而，作为关键推理视角之一，逻辑推理能力还没有得到彻底评估。本文旨在填补这些差距并提供全面的评估。首先，为了进行系统化评估，本文选择了15个典型的逻辑推理数据集，并将它们组织成演绎、归纳、阿布达斯和混合形式的推理设置。考虑评估的全面性，我们选择了三个代表性的LLMs（text-davinci-003，ChatGPT和BARD），并在零样本、一次和三次的设置下对所有选择的数据集进行评估。其次，与以往仅依赖简单指标（如准确性）的评估不同，我们提出了从目标推理角度进行的精细级别评估。

    Large Language Models (LLMs) have achieved great success in various natural language tasks. It has aroused much interest in evaluating the specific reasoning capability of LLMs, such as multilingual reasoning and mathematical reasoning. However, as one of the key reasoning perspectives, logical reasoning capability has not yet been thoroughly evaluated. In this work, we aim to bridge those gaps and provide comprehensive evaluations. Firstly, to offer systematic evaluations, this paper selects fifteen typical logical reasoning datasets and organizes them into deductive, inductive, abductive and mixed-form reasoning settings. Considering the comprehensiveness of evaluations, we include three representative LLMs (i.e., text-davinci-003, ChatGPT and BARD) and evaluate them on all selected datasets under zero-shot, one-shot and three-shot settings. Secondly, different from previous evaluations relying only on simple metrics (e.g., accuracy), we propose fine-level evaluations from objective 
    
[^82]: 平滑单调网络

    Smooth Monotonic Networks. (arXiv:2306.01147v1 [cs.LG])

    [http://arxiv.org/abs/2306.01147](http://arxiv.org/abs/2306.01147)

    本文提出了一种新的神经网络模块--平滑min-max(SMM)网络，相比于传统的min-max(MM)神经网络结构简单易用，在单调建模方面表现优异。

    

    单调性约束是统计建模中的强力正则化工具。它们可以在计算机支持的决策制定中支持公平性，并增加数据驱动科学模型的可信度。经典的min-max(MM)神经网络结构确保了单调性，但由于梯度消失而往往在训练过程中陷入不良局部最优。我们提出了对MM网络的简单修改，使用严格递增的平滑非线性函数来缓解这个问题。得到的平滑min-max(SMM)网络模块继承了MM架构的渐近逼近性质。它可以嵌入到更大的端到端深度学习系统中进行训练。在单调建模的神经网络方面，SMM模块要简单得多，计算需求也要少得多。尽管如此，在我们的实验中，它在泛化性能方面与替代神经和非神经方法相比表现得更为优异。

    Monotonicity constraints are powerful regularizers in statistical modelling. They can support fairness in computer supported decision making and increase plausibility in data-driven scientific models. The seminal min-max (MM) neural network architecture ensures monotonicity, but often gets stuck in undesired local optima during training because of vanishing gradients. We propose a simple modification of the MM network using strictly-increasing smooth non-linearities that alleviates this problem. The resulting smooth min-max (SMM) network module inherits the asymptotic approximation properties from the MM architecture. It can be used within larger deep learning systems trained end-to-end. The SMM module is considerably simpler and less computationally demanding than state-of-the-art neural networks for monotonic modelling. Still, in our experiments, it compared favorably to alternative neural and non-neural approaches in terms of generalization performance.
    
[^83]: GPT4Graph：大型语言模型能否理解图结构化数据？一项实证评估与基准测试

    GPT4Graph: Can Large Language Models Understand Graph Structured Data ? An Empirical Evaluation and Benchmarking. (arXiv:2305.15066v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2305.15066](http://arxiv.org/abs/2305.15066)

    本文通过实证评估与基准测试，研究了大型语言模型（LLM）在理解图结构化数据方面的能力。我们发现目前的语言模型在这一领域存在一些限制，并提出了一些潜在的改进空间。

    

    大型语言模型（LLM）如ChatGPT已成为人工通用智能（AGI）中不可或缺的工具，在各种自然语言处理任务中表现出色。现实世界中，图数据无处不在，是AGI的重要组成部分，在社交网络分析、生物信息学和推荐系统领域流行。大型语言模型的训练语料库通常包括一些算法组件，使它们能够在一些与图数据相关的问题上取得一定的效果。然而，目前对它们在更广泛的图结构化数据上的表现还缺乏研究。在本研究中，我们进行了深入调查，评估LLMs在理解图数据方面的能力，涵盖了多个结构和语义相关的任务。我们的分析包括10个不同的任务，用于评估LLMs在图理解方面的能力。通过我们的研究，我们不仅揭示了语言模型在图数据理解方面的当前限制，还发现了一些潜在的改进空间。

    Large language models~(LLM) like ChatGPT have become indispensable to artificial general intelligence~(AGI), demonstrating excellent performance in various natural language processing tasks. In the real world, graph data is ubiquitous and an essential part of AGI and prevails in domains like social network analysis, bioinformatics and recommender systems. The training corpus of large language models often includes some algorithmic components, which allows them to achieve certain effects on some graph data-related problems. However, there is still little research on their performance on a broader range of graph-structured data. In this study, we conduct an extensive investigation to assess the proficiency of LLMs in comprehending graph data, employing a diverse range of structural and semantic-related tasks. Our analysis encompasses 10 distinct tasks that evaluate the LLMs' capabilities in graph understanding. Through our study, we not only uncover the current limitations of language mo
    
[^84]: 使用BERT和Query-Aware LSH提高非正式文档中代码示例推荐：一项比较研究

    Improving Code Example Recommendations on Informal Documentation Using BERT and Query-Aware LSH: A Comparative Study. (arXiv:2305.03017v1 [cs.SE])

    [http://arxiv.org/abs/2305.03017](http://arxiv.org/abs/2305.03017)

    本研究使用BERT和Query-Aware LSH提高非正式文档中代码示例推荐的质量，重点关注于Stack Overflow上的Java编程语言。研究使用BERT将代码示例转换为数值向量。

    

    过去和最近一直在进行代码示例推荐的研究，以帮助开发人员完成软件开发任务。由于开发人员经常花费大量时间在互联网上寻找相关的代码示例，利用开源项目和非正式文档。为了找到有用的代码示例，非正式文档（如Stack Overflow讨论和论坛）可以非常宝贵。我们的研究重点是Stack Overflow，它是软件开发人员讨论不同主题的流行资源。为了提高推荐代码示例的质量，我们收集并推荐了Java编程语言中最佳的代码示例。我们采用了BERT来进行处理，它是一个大型语言模型（LLM），可以有效地从文本数据中提取语义信息。我们的第一步是使用BERT将代码示例转换为数值向量。

    The study of code example recommendation has been conducted extensively in the past and recently in order to assist developers in their software development tasks. This is because developers often spend significant time searching for relevant code examples on the internet, utilizing open-source projects and informal documentation. For finding useful code examples, informal documentation, such as Stack Overflow discussions and forums, can be invaluable. We have focused our research on Stack Overflow, which is a popular resource for discussing different topics among software developers. For increasing the quality of the recommended code examples, we have collected and recommended the best code examples in the Java programming language. We have utilized BERT in our approach, which is a Large Language Model (LLM) for text representation that can effectively extract semantic information from textual data. Our first step involved using BERT to convert code examples into numerical vectors. Su
    
[^85]: 图像生成模型的定性失败及其在检测Deepfakes中的应用

    Qualitative Failures of Image Generation Models and Their Application in Detecting Deepfakes. (arXiv:2304.06470v1 [cs.CV])

    [http://arxiv.org/abs/2304.06470](http://arxiv.org/abs/2304.06470)

    研究调查了图像生成模型的质量失误及其应用于检测Deepfakes，识别了五种定性缺陷。这些发现有助于改进模型并制定检测Deepfakes的策略。

    

    图像和视频生成模型创造出逼真的影像的能力已经达到了前所未有的高度，这使得在许多情况下很难区分真实和伪造的图像。然而，尽管取得了进展，但生成图像的质量和真实世界中的图像之间仍存在差距。为了解决这个问题，我们回顾了大量学术论文和社交媒体内容，以确定图像生成模型的定性缺陷，并将其分类为五类。通过了解这些失败，我们可以确定这些模型需要改进的领域，并制定检测Deepfakes的策略。今天社会中Deepfakes的普遍存在是一个严重的问题，我们的研究发现可以帮助减轻它们的负面影响。

    The ability of image and video generation models to create photorealistic images has reached unprecedented heights, making it difficult to distinguish between real and fake images in many cases. However, despite this progress, a gap remains between the quality of generated images and those found in the real world. To address this, we have reviewed a vast body of literature from both academic publications and social media to identify qualitative shortcomings in image generation models, which we have classified into five categories. By understanding these failures, we can identify areas where these models need improvement, as well as develop strategies for detecting deep fakes. The prevalence of deep fakes in today's society is a serious concern, and our findings can help mitigate their negative impact.
    
[^86]: I2I: 用改进的知识初始化转接器

    I2I: Initializing Adapters with Improvised Knowledge. (arXiv:2304.02168v1 [cs.CL])

    [http://arxiv.org/abs/2304.02168](http://arxiv.org/abs/2304.02168)

    本文提出了一种称为ImprovisetoInitialize(I2I)的连续学习算法，通过提取先前学习的任务适配器的知识来为即将到来的任务初始化适配器。这使得从一个任务到另一个任务的知识传递更加高效。

    

    转接器是延续学习中解决灾难性遗忘问题的一种有前途的解决方案。然而，为每个新任务训练独立的适配器模块错失了跨任务知识转移的机会。我们提出了一种称为 Improvise to Initialize (I2I) 的连续学习算法，通过提取先前学习的任务适配器的知识，为即将到来的任务初始化适配器。我们通过对视觉问答任务序列进行实验，评估了 I2I 在 CLiMB，一个多模态的连续学习基准上的表现。使用 I2I 训练的适配器始终比独立训练的适配器具有更好的任务精度，证明了我们的算法促进了任务适配器之间的知识转移，并且相对于先进的 AdapterFusion，I2I 也能实现更好的跨任务知识转移而不产生相关的参数成本。

    Adapters present a promising solution to the catastrophic forgetting problem in continual learning. However, training independent Adapter modules for every new task misses an opportunity for cross-task knowledge transfer. We propose Improvise to Initialize (I2I), a continual learning algorithm that initializes Adapters for incoming tasks by distilling knowledge from previously-learned tasks' Adapters. We evaluate I2I on CLiMB, a multimodal continual learning benchmark, by conducting experiments on sequences of visual question answering tasks. Adapters trained with I2I consistently achieve better task accuracy than independently-trained Adapters, demonstrating that our algorithm facilitates knowledge transfer between task Adapters. I2I also results in better cross-task knowledge transfer than the state-of-the-art AdapterFusion without incurring the associated parametric cost.
    
[^87]: 联合行为和共同信念

    Joint Behavior and Common Belief. (arXiv:2303.07185v2 [cs.MA] UPDATED)

    [http://arxiv.org/abs/2303.07185](http://arxiv.org/abs/2303.07185)

    这篇论文展示了即使没有共同信念，仍然可以发生自然的联合行为。并且提出了两种共同信念的变体，其中一种被证明在某种程度上是联合行为的必要且充分条件，并更容易实现。

    

    在过去的25年中，共同信念被广泛认为是联合行为的必要条件。但这并不完全正确。我们通过示例展示了即使没有共同信念，仍然可以发生自然的联合行为。然后我们提出了两种可以导致联合行为的共同信念的变体，即使没有实现标准的共同信念，其中一种被证明在某种程度上是联合行为的必要且充分条件。这些观察结果具有重要意义，因为众所周知，实际上很难实现共同信念，而这些变体更容易实现。

    For over 25 years, common belief has been widely viewed as necessary for joint behavior. But this is not quite correct. We show by example that what can naturally be thought of as joint behavior can occur without common belief. We then present two variants of common belief that can lead to joint behavior, even without standard common belief ever being achieved, and show that one of them, action-stamped common belief, is in a sense necessary and sufficient for joint behavior. These observations are significant because, as is well known, common belief is quite difficult to achieve in practice, whereas these variants are more easily achievable.
    
[^88]: 扭曲-解缠对比学习

    Distortion-Disentangled Contrastive Learning. (arXiv:2303.05066v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2303.05066](http://arxiv.org/abs/2303.05066)

    扭曲-解缠对比学习是一种自监督学习方法，通过使用单个损失函数提取失真不变表示并过滤掉失真变体表示，实现了可靠的性能，同时减少了对批次大小的依赖。该方法还解决了对宝贵的失真变体表示进行解缠和利用的问题，以及对增强策略的敏感性。

    

    自监督学习以其在表示学习和各种下游计算机视觉任务中的显著性能而闻名。最近，正对对比学习（POCL）在无需构建正负训练集的情况下实现了可靠的性能。它通过降低对批次大小的依赖来减少内存需求。POCL方法通常使用单个损失函数提取失真不变表示（DIR），该表示描述了受不同失真影响的正对表示的接近程度。这个损失函数隐式地使模型能够滤除或忽略受不同失真影响的失真变体表示（DVR）。然而，现有的POCL方法没有明确强制执行有价值的DVR的解缠和利用。此外，这些POCL方法对增强策略很敏感。为了解决这些限制，我们提出了一种新颖的方法

    Self-supervised learning is well known for its remarkable performance in representation learning and various downstream computer vision tasks. Recently, Positive-pair-Only Contrastive Learning (POCL) has achieved reliable performance without the need to construct positive-negative training sets. It reduces memory requirements by lessening the dependency on the batch size. The POCL method typically uses a single loss function to extract the distortion invariant representation (DIR) which describes the proximity of positive-pair representations affected by different distortions. This loss function implicitly enables the model to filter out or ignore the distortion variant representation (DVR) affected by different distortions. However, existing POCL methods do not explicitly enforce the disentanglement and exploitation of the actually valuable DVR. In addition, these POCL methods have been observed to be sensitive to augmentation strategies. To address these limitations, we propose a nov
    
[^89]: SAINE: 科学研究的科学注释与推理引擎

    SAINE: Scientific Annotation and Inference Engine of Scientific Research. (arXiv:2302.14468v2 [cs.DL] UPDATED)

    [http://arxiv.org/abs/2302.14468](http://arxiv.org/abs/2302.14468)

    SAINE是一个基于开源软件的科学注释和推理引擎，可提供更准确的分类，并在学术出版物领域有应用。用户研究表明，该系统能帮助我们更好地理解分类过程，促进透明度和科学研究的理解。愿意与科学界合作和收集反馈。

    

    我们提出了SAINE，一种基于一组标准开源软件（如Label Studio和MLflow）的科学注释和推理引擎。我们展示了我们的注释引擎可以有助于更准确地进行分类的进一步发展。基于我们之前关于层次学科分类的工作，我们在了解学术出版物领域中使用SAINE进行应用。我们的注释结果的用户研究表明，在我们系统的帮助下收集到的用户输入能够帮助我们更好地理解分类过程。我们相信我们的工作将有助于促进更大的透明度和更好地理解科学研究。我们的注释和推理引擎还可以进一步支持下游元科学项目。我们欢迎科学界在这些项目上进行合作和反馈。演示视频可以在https://youtu.be/yToO-G9YQK4中访问。实时演示网站可在https://app.heartex上访问。

    We present SAINE, an Scientific Annotation and Inference ENgine based on a set of standard open-source software, such as Label Studio and MLflow. We show that our annotation engine can benefit the further development of a more accurate classification. Based on our previous work on hierarchical discipline classifications, we demonstrate its application using SAINE in understanding the space for scholarly publications. The user study of our annotation results shows that user input collected with the help of our system can help us better understand the classification process. We believe that our work will help to foster greater transparency and better understand scientific research. Our annotation and inference engine can further support the downstream meta-science projects. We welcome collaboration and feedback from the scientific community on these projects. The demonstration video can be accessed from https://youtu.be/yToO-G9YQK4. A live demo website is available at https://app.heartex
    
[^90]: 使用深度学习在"Web of Science"中对研究领域进行层次分类

    Hierarchical Classification of Research Fields in the "Web of Science" Using Deep Learning. (arXiv:2302.00390v2 [cs.DL] UPDATED)

    [http://arxiv.org/abs/2302.00390](http://arxiv.org/abs/2302.00390)

    本文提出了一个使用深度学习进行层次分类的系统，可以自动将学术出版物通过抽象进行分类，实现了对研究活动在不同层次结构中的全面分类，并允许跨学科和跨领域的单标签和多标签分类。

    

    本文提出了一个层次分类系统，通过使用抽象将学术出版物自动分类到三级层次标签集（学科、领域、子领域）中，以多类别设置进行分类。该系统可以通过文章的知识生产和引用的影响，对研究活动在所述层次结构中进行全面的分类，并允许这些活动被归为多个类别。该分类系统在Microsoft Academic Graph (版本2018-05-17)的160 million份摘要片段中区分了44个学科、718个领域和1,485个子领域。我们以模块化和分布式方式进行批量训练，以解决和允许跨学科和跨领域的单标签和多标签分类。总共，我们在所有考虑的模型（卷积神经网络，循环神经网络，变形器）中进行了3,140次实验。分类准确率> 90％。

    This paper presents a hierarchical classification system that automatically categorizes a scholarly publication using its abstract into a three-tier hierarchical label set (discipline, field, subfield) in a multi-class setting. This system enables a holistic categorization of research activities in the mentioned hierarchy in terms of knowledge production through articles and impact through citations, permitting those activities to fall into multiple categories. The classification system distinguishes 44 disciplines, 718 fields and 1,485 subfields among 160 million abstract snippets in Microsoft Academic Graph (version 2018-05-17). We used batch training in a modularized and distributed fashion to address and allow for interdisciplinary and interfield classifications in single-label and multi-label settings. In total, we have conducted 3,140 experiments in all considered models (Convolutional Neural Networks, Recurrent Neural Networks, Transformers). The classification accuracy is > 90%
    
[^91]: 探究用于胸部 X 光片的孪生表示学习的图像增强方法

    Exploring Image Augmentations for Siamese Representation Learning with Chest X-Rays. (arXiv:2301.12636v2 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2301.12636](http://arxiv.org/abs/2301.12636)

    本研究系统地评估了不同的增强方法对学习到的胸部 X 光片异常检测的孪生表示的质量和鲁棒性的影响。结果显示，我们找到了一组能够产生良好泛化效果的鲁棒表示的增强方法。

    

    图像增强对于有效的自监督学习技术的视觉表示学习至关重要。虽然自然图像的增强策略已经得到了广泛研究，但医学图像与自然图像有很大的不同。因此，我们不清楚在孪生表示学习中常用的增强策略是否适用于医学图像，以及适用的程度。为了解决这个挑战，在本研究中，我们系统地评估了各种增强方法对学习到的表示的质量和鲁棒性的影响。我们在三个大型数据集（MIMIC-CXR、CheXpert 和 VinDR-CXR）上训练和评估了用于胸部 X 光片异常检测的孪生网络。我们通过线性探测、微调、零样本迁移和数据效率的实验来研究学习到的表示的有效性。最后，我们确定了一组增强方法，可以得到具有良好泛化能力的鲁棒表示。

    Image augmentations are quintessential for effective visual representation learning across self-supervised learning techniques. While augmentation strategies for natural imaging have been studied extensively, medical images are vastly different from their natural counterparts. Thus, it is unknown whether common augmentation strategies employed in Siamese representation learning generalize to medical images and to what extent. To address this challenge, in this study, we systematically assess the effect of various augmentations on the quality and robustness of the learned representations. We train and evaluate Siamese Networks for abnormality detection on chest X-Rays across three large datasets (MIMIC-CXR, CheXpert and VinDR-CXR). We investigate the efficacy of the learned representations through experiments involving linear probing, fine-tuning, zero-shot transfer, and data efficiency. Finally, we identify a set of augmentations that yield robust representations that generalize well t
    
[^92]: 用于复杂查询回答的神经链接预测器的调整

    Adapting Neural Link Predictors for Complex Query Answering. (arXiv:2301.12313v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.12313](http://arxiv.org/abs/2301.12313)

    本文提出通过训练一个参数高效的分数适应模型来重新校准神经链接预测分数以解决神经链接预测器在复杂查询回答中的问题。

    

    在不完整知识图谱上回答复杂查询是一项具有挑战性的任务，模型需要在缺失知识的情况下回答复杂逻辑查询。最近，Arakelyan等人（2021）；Minervini等人（2022）表明，神经链接预测器也可以用于回答复杂查询：他们的连续查询分解（CQD）方法通过将复杂查询分解为原子子查询，使用神经链接预测器回答并通过t-范数来聚合其分数，以对每个复杂查询的答案进行排序。然而，CQD不处理否定并且仅使用原子训练查询的训练信号：在回答复杂查询期间，神经链接预测分数没有通过模糊逻辑t-范数进行校准以相互作用。在这项工作中，我们提出通过训练一个参数高效的分数适应模型来重新校准神经链接预测分数以解决这个问题：这个新组件通过反向传播法在复杂查询上进行训练。

    Answering complex queries on incomplete knowledge graphs is a challenging task where a model needs to answer complex logical queries in the presence of missing knowledge. Recently, Arakelyan et al. (2021); Minervini et al. (2022) showed that neural link predictors could also be used for answering complex queries: their Continuous Query Decomposition (CQD) method works by decomposing complex queries into atomic sub-queries, answers them using neural link predictors and aggregates their scores via t-norms for ranking the answers to each complex query. However, CQD does not handle negations and only uses the training signal from atomic training queries: neural link prediction scores are not calibrated to interact together via fuzzy logic t-norms during complex query answering. In this work, we propose to address this problem by training a parameter-efficient score adaptation model to re-calibrate neural link prediction scores: this new component is trained on complex queries by back-propa
    
[^93]: ClimaX:一种用于天气和气候的基础模型

    ClimaX: A foundation model for weather and climate. (arXiv:2301.10343v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.10343](http://arxiv.org/abs/2301.10343)

    ClimaX是一种灵活且可推广的深度学习模型，用于天气和气候科学，可以使用不同数据集进行训练。

    

    目前大多数先进的天气和气候模型都是基于物理信息的数值模型。这些方法旨在模拟非线性动力学和多变量之间的复杂相互作用，这些相互作用很难近似。此外，许多这样的数值模型在模拟细粒度空间和时间分辨率的大气现象时计算量很大。最近的基于机器学习的数据驱动方法通过使用深度神经网络学习数据驱动的功能映射来直接解决下游预测或投射任务。然而，这些网络是使用为特定时空任务策划和同质化的气候数据集进行训练的，因此缺乏数值模型的普遍性。我们开发并演示了ClimaX，这是一个灵活且可推广的深度学习模型，可用于天气和气候科学，并可以使用跨越不同数据集的异构数据进行训练。

    Most state-of-the-art approaches for weather and climate modeling are based on physics-informed numerical models of the atmosphere. These approaches aim to model the non-linear dynamics and complex interactions between multiple variables, which are challenging to approximate. Additionally, many such numerical models are computationally intensive, especially when modeling the atmospheric phenomenon at a fine-grained spatial and temporal resolution. Recent data-driven approaches based on machine learning instead aim to directly solve a downstream forecasting or projection task by learning a data-driven functional mapping using deep neural networks. However, these networks are trained using curated and homogeneous climate datasets for specific spatiotemporal tasks, and thus lack the generality of numerical models. We develop and demonstrate ClimaX, a flexible and generalizable deep learning model for weather and climate science that can be trained using heterogeneous datasets spanning dif
    
[^94]: 集体隐私恢复：通过分散式人工智能进行数据共享协同

    Collective Privacy Recovery: Data-sharing Coordination via Decentralized Artificial Intelligence. (arXiv:2301.05995v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2301.05995](http://arxiv.org/abs/2301.05995)

    本文研究了集体隐私恢复的问题，通过分散式人工智能实现数据共享的协同。研究发现，数据共享协调可以实现对隐私的显著恢复，并带来双赢效果。

    

    集体隐私损失变成了一个巨大的问题，对个人自由和民主构成了紧急威胁。但是，我们是否准备好将个人数据视为稀缺资源，并根据“尽可能少，尽可能多”的原则共享数据？我们假设，如果一个个体群体（数据集体）协调共享最少数据，以满足在线服务的所需质量，将会产生显著的隐私恢复。在这里，我们展示了如何使用去中心化人工智能自动化和扩展复杂的集体隐私恢复安排。为此，我们首次在一个严谨的高度逼真的实验中比较了态度、内在、奖励和协调数据共享，并利用因果推断和聚类分析方法区分了预测隐私和五个关键数据共享行为的标准。令人惊讶的是，数据共享协调对所有人来说都是双赢的：隐私得到显著恢复。

    Collective privacy loss becomes a colossal problem, an emergency for personal freedoms and democracy. But, are we prepared to handle personal data as scarce resource and collectively share data under the doctrine: as little as possible, as much as necessary? We hypothesize a significant privacy recovery if a population of individuals, the data collective, coordinates to share minimum data for running online services with the required quality. Here we show how to automate and scale-up complex collective arrangements for privacy recovery using decentralized artificial intelligence. For this, we compare for first time attitudinal, intrinsic, rewarded and coordinated data sharing in a rigorous living-lab experiment of high realism involving >27,000 real data disclosures. Using causal inference and cluster analysis, we differentiate criteria predicting privacy and five key data-sharing behaviors. Strikingly, data-sharing coordination proves to be a win-win for all: remarkable privacy recove
    
[^95]: 在联邦学习中实现小型神经网络的分布式剪枝

    Distributed Pruning Towards Tiny Neural Networks in Federated Learning. (arXiv:2212.01977v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.01977](http://arxiv.org/abs/2212.01977)

    该论文提出了FedTiny，一个用于联邦学习的分布式剪枝框架，可以为内存和计算受限的设备生成专门的小型模型。在这里，作者引入了自适应的批归一化选择模块来解决剪枝中的偏差问题。

    

    神经网络剪枝是减小深度神经网络大小和复杂度的重要技术，使得在资源有限的设备上可以进行大规模模型。然而，现有的剪枝方法过于依赖训练数据来指导剪枝策略，使得它们对于联邦学习中的分布式和保密数据集效果不好。此外，内存和计算密集型的剪枝过程在资源受限的设备上变得不可行。为了解决这些挑战，我们提出了FedTiny，这是一个用于联邦学习的分布式剪枝框架，可以为内存和计算受限的设备生成专门的小型模型。我们在FedTiny中引入了两个关键模块，以适应稀疏和廉价的局部计算部署场景，自适应地搜索粗剪枝和细剪枝的专用模型。首先，设计了一个自适应的批归一化选择模块，来减轻剪枝中由异质性引起的偏差。

    Neural network pruning is an essential technique for reducing the size and complexity of deep neural networks, enabling large-scale models on devices with limited resources. However, existing pruning approaches heavily rely on training data for guiding the pruning strategies, making them ineffective for federated learning over distributed and confidential datasets. Additionally, the memory- and computation-intensive pruning process becomes infeasible for recourse-constrained devices in federated learning. To address these challenges, we propose FedTiny, a distributed pruning framework for federated learning that generates specialized tiny models for memory- and computing-constrained devices. We introduce two key modules in FedTiny to adaptively search coarse- and finer-pruned specialized models to fit deployment scenarios with sparse and cheap local computation. First, an adaptive batch normalization selection module is designed to mitigate biases in pruning caused by the heterogeneity
    
[^96]: 对抗性廉价交流

    Adversarial Cheap Talk. (arXiv:2211.11030v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.11030](http://arxiv.org/abs/2211.11030)

    本文提出了一种新型对抗性设置，在其中对手只能将信息附加到受害者的观察中，从而产生最小的影响范围，并提出对抗性廉价交流（ACT）算法进行对手训练。在高度受限的情况下，使用ACT训练的对手仍会对受害者的训练和测试表现产生显著影响，揭示了强化学习算法中的一种新的攻击向量。

    

    强化学习中的对抗性攻击通常假定攻击者可以高度特权地访问受害者的参数、环境或数据。本文提出了一种称为廉价交流MDP的新型对抗性设置，其中对手只能将确定性信息附加到受害者的观察中，从而产生最小的影响范围。对手不能掩盖地面事实，影响基本环境动态或奖励信号，引入不稳定性，增加随机性，看到受害者的动作或访问他们的参数。此外，我们提出了一种简单的元学习算法，称为对抗性廉价交流（ACT），在这种设置中对对手进行训练。我们证明，即使在高度受限的情况下，使用ACT训练的对手仍会显着影响受害者的训练和测试表现。影响训练时间表现揭示了一种新的攻击向量，并为现有强化学习算法的成功和失败模式提供了见解。

    Adversarial attacks in reinforcement learning (RL) often assume highly-privileged access to the victim's parameters, environment, or data. Instead, this paper proposes a novel adversarial setting called a Cheap Talk MDP in which an Adversary can merely append deterministic messages to the Victim's observation, resulting in a minimal range of influence. The Adversary cannot occlude ground truth, influence underlying environment dynamics or reward signals, introduce non-stationarity, add stochasticity, see the Victim's actions, or access their parameters. Additionally, we present a simple meta-learning algorithm called Adversarial Cheap Talk (ACT) to train Adversaries in this setting. We demonstrate that an Adversary trained with ACT still significantly influences the Victim's training and testing performance, despite the highly constrained setting. Affecting train-time performance reveals a new attack vector and provides insight into the success and failure modes of existing RL algorith
    
[^97]: 用Treeformers生成树结构

    Forming Trees with Treeformers. (arXiv:2207.06960v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2207.06960](http://arxiv.org/abs/2207.06960)

    本文介绍了一种Treeformer模块，它借鉴了CKY算法，通过学习组合运算符和汇聚函数来构建短语和句子的层次编码，从而将层次结构纳入Transformer模型中。实验证明，这种模块在组合泛化和各种自然语言任务中取得了显著的改进。

    

    人类语言具有嵌套的层次结构，使我们能够从较小的片段中构建复杂的句子。然而，许多最先进的神经网络模型（如Transformers）在其架构中没有明确的层次结构，即它们对层次结构没有归纳偏差。此外，已知Transformers在需要这种结构的组合泛化任务上表现不佳。在本文中，我们引入了Treeformer，这是一个通用的编码器模块，受到CKY算法的启发，它学习了一个组合运算符和汇聚函数，用于构建短语和句子的层次编码。我们的大量实验表明，将层次结构纳入Transformer模型中的好处，并且在组合泛化以及机器翻译、抽象摘要和各种自然语言理解任务等下游任务中取得了显著的改进。

    Human language is known to exhibit a nested, hierarchical structure, allowing us to form complex sentences out of smaller pieces. However, many state-of-the-art neural networks models such as Transformers have no explicit hierarchical structure in its architecture -- that is, they don't have an inductive bias toward hierarchical structure. Additionally, Transformers are known to perform poorly on compositional generalization tasks which require such structures. In this paper, we introduce Treeformer, a general-purpose encoder module inspired by the CKY algorithm which learns a composition operator and pooling function to construct hierarchical encodings for phrases and sentences. Our extensive experiments demonstrate the benefits of incorporating hierarchical structure into the Transformer and show significant improvements in compositional generalization as well as in downstream tasks such as machine translation, abstractive summarization, and various natural language understanding tas
    
[^98]: 基于Talmudic Public Announcement Logic的BTPK解释性命名实体识别方法

    BTPK-based interpretable method for NER tasks based on Talmudic Public Announcement Logic. (arXiv:2201.09523v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2201.09523](http://arxiv.org/abs/2201.09523)

    本文提出了一种基于Talmudic Public Announcement Logic的新颖解释性方法BTPK，用于帮助用户理解命名实体识别任务的内部逻辑，同时能够捕捉句子中的语义信息和上下文依赖关系。

    

    作为自然语言处理(NLP)中的一项基本任务，命名实体识别(NER)是NLP下游任务（如信息提取、句法分析、机器翻译等）的重要基础工具。当前的命名实体识别模型对用户来说是黑盒操作，用户没有依据来确定哪个命名实体更有意义。因此，一种用户友好的可解释性识别过程对许多人来说非常有用。本文提出了一种新颖的解释性方法BTPK（Binary Talmudic Public Announcement Logic模型），以帮助用户理解基于Talmudic Public Announcement Logic的命名实体识别任务的内部识别逻辑。BTPK模型还可以捕捉输入句子中的语义信息，即句子的上下文依赖关系。我们观察到BTPK的公共公告呈现了BRNNs的内部决策逻辑，并从中获得解释。

    As one of the basic tasks in natural language processing (NLP), named entity recognition (NER) is an important basic tool for downstream tasks of NLP, such as information extraction, syntactic analysis, machine translation and so on. The internal operation logic of current name entity recognition model is black-box to the user, so the user has no basis to determine which name entity makes more sense. Therefore, a user-friendly explainable recognition process would be very useful for many people. In this paper, we propose a novel interpretable method, BTPK (Binary Talmudic Public Announcement Logic model), to help users understand the internal recognition logic of the name entity recognition tasks based on Talmudic Public Announcement Logic. BTPK model can also capture the semantic information in the input sentences, that is, the context dependency of the sentence. We observed the public announcement of BTPK presents the inner decision logic of BRNNs, and the explanations obtained from 
    
[^99]: 使用于无标度在线学习的等调节技术

    Isotuning With Applications To Scale-Free Online Learning. (arXiv:2112.14586v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2112.14586](http://arxiv.org/abs/2112.14586)

    我们提出了一种用于无标度在线学习的等调节技术，该技术具有快速、自适应、随时随地和无标度的特点，并可以自动适应遗憾的速率。同时，我们还引入了在线校正的方法来改进算法的性能。

    

    我们扩展和结合了文献中的几种方法，设计了快速、自适应、随时随地和无标度的在线学习算法。无标度的遗憾界限必须与最大损失成线性关系，不论是对于大损失还是对于非常小的损失。自适应的遗憾界限表明算法可以利用简单的数据并可能具有常数遗憾。我们致力于开发尽可能少依赖参数的快速算法，特别是它们应该是随时可用的，因此不依赖于时间范围。我们的第一个和主要工具是等调节技术，它是平衡遗憾权衡的思想的推广。我们开发了一套工具来轻松设计和分析这样的学习速度，并展示它们能够自动适应遗憾的速率（无论是常数、$O(\log T)$、$O(\sqrt{T})$等），并且在同样的观察量上比在事后选择的最优学习速度高出2倍。第二个工具是在线校正，它使我们能够获得...

    We extend and combine several tools of the literature to design fast, adaptive, anytime and scale-free online learning algorithms. Scale-free regret bounds must scale linearly with the maximum loss, both toward large losses and toward very small losses. Adaptive regret bounds demonstrate that an algorithm can take advantage of easy data and potentially have constant regret. We seek to develop fast algorithms that depend on as few parameters as possible, in particular they should be anytime and thus not depend on the time horizon. Our first and main tool, isotuning, is a generalization of the idea of balancing the trade-off of the regret. We develop a set of tools to design and analyze such learning rates easily and show that they adapts automatically to the rate of the regret (whether constant, $O(\log T)$, $O(\sqrt{T})$, etc.) within a factor 2 of the optimal learning rate in hindsight for the same observed quantities. The second tool is an online correction, which allows us to obtain
    
[^100]: 可响应的并行化架构用于在生产环境中部署深度学习模型

    Responsive parallelized architecture for deploying deep learning models in production environments. (arXiv:2112.08933v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2112.08933](http://arxiv.org/abs/2112.08933)

    本研究设计和提出了一个可响应的并行化架构，用于在实时生产环境中部署深度学习模型。采用层次化细化的标签注意力网络预测CV实体，并使用多个深度学习模型并行预测。通过选择轻量级微型Web框架和使用微服务来部署大型深度学习模型管道，达到在少于700毫秒的时间内解析普通CV的目的。

    

    招聘人员可以通过查看求职者的简历(CV)文档轻松筛选候选人。无结构的文档CV包含候选人的作品集和命名实体列表的详细信息。本研究的主要目标是设计和提出一个面向Web的、高度响应的计算管道，使用层次化细化的标签注意力网络系统地预测CV实体。使用专门用于命名实体识别的深度学习模型在大型数据集上进行训练，以预测相关字段。本文提出了一种在并行中使用一定数量的深度学习模型并实时预测的最佳策略。我们采用分析层次处理算法选择了一个轻量级的微型Web框架，并专注于一种有助于在生产就绪环境中使用微服务部署大型深度学习模型管道的方法。部署的模型和提出的架构有助于在少于700毫秒的时间内解析普通CV。

    Recruiters can easily shortlist candidates for jobs via viewing their curriculum vitae (CV) document. Unstructured document CV beholds candidate's portfolio and named entities listing details. The main aim of this study is to design and propose a web oriented, highly responsive, computational pipeline that systematically predicts CV entities using hierarchically-refined label attention networks. Deep learning models specialized for named entity recognition were trained on large dataset to predict relevant fields. The article suggests an optimal strategy to use a number of deep learning models in parallel and predict in real time. We demonstrate selection of light weight micro web framework using Analytical Hierarchy Processing algorithm and focus on an approach useful to deploy large deep learning model-based pipelines in production ready environments using microservices. Deployed models and architecture proposed helped in parsing normal CV in less than 700 milliseconds for sequential 
    
[^101]: 元素越笨，整体越聪明。或者，可能并非如此？

    The Less Intelligent the Elements, the More Intelligent the Whole. Or, Possibly Not?. (arXiv:2012.12689v2 [eess.SY] UPDATED)

    [http://arxiv.org/abs/2012.12689](http://arxiv.org/abs/2012.12689)

    我们探讨了个体智能是否对于集体智能的产生是必要的，以及怎样的个体智能有利于更大的集体智能。在Lotka-Volterra模型中，我们发现了一些个体行为，特别是掠食者的行为，有利于与其他种群共存，但如果猎物和掠食者都足够智能以推断彼此的行为，共存将伴随着两个种群的无限增长。

    

    我们探讨了大脑中的神经元与社会中的人类之间的利维坦类比，问自己是否个体智能对于集体智能的产生是必要的，更重要的是，怎样的个体智能有利于更大的集体智能。首先，我们回顾了连接主义认知科学、基于代理的建模、群体心理学、经济学和物理学的不同洞见。随后，我们将这些洞见应用于Lotka-Volterra模型中导致掠食者和猎物要么共存要么全球灭绝的智能类型和程度。我们发现几个个体行为 - 尤其是掠食者的行为 - 有利于共存，最终在一个平衡点周围产生震荡。然而，我们也发现，如果猎物和掠食者都足够智能以推断彼此的行为，共存就会伴随着两个种群的无限增长。由于Lotka-Volterra模型是不稳定的，我们提出了一些未来的研究方向来解决这个问题。

    We explore a Leviathan analogy between neurons in a brain and human beings in society, asking ourselves whether individual intelligence is necessary for collective intelligence to emerge and, most importantly, what sort of individual intelligence is conducive of greater collective intelligence. We first review disparate insights from connectionist cognitive science, agent-based modeling, group psychology, economics and physics. Subsequently, we apply these insights to the sort and degrees of intelligence that in the Lotka-Volterra model lead to either co-existence or global extinction of predators and preys.  We find several individual behaviors -- particularly of predators -- that are conducive to co-existence, eventually with oscillations around an equilibrium. However, we also find that if both preys and predators are sufficiently intelligent to extrapolate one other's behavior, co-existence comes along with indefinite growth of both populations. Since the Lotka-Volterra model is al
    

