# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [A Quantum Probability Driven Framework for Joint Multi-Modal Sarcasm, Sentiment and Emotion Analysis.](http://arxiv.org/abs/2306.03650) | 本篇论文提出了一种使用量子概率驱动的框架，用于联合多模态讽刺、情感和情绪分析，解决了传统概率的兼容性假设和现有方法的不足问题。 |
| [^2] | [On Manipulating Signals of User-Item Graph: A Jacobi Polynomial-based Graph Collaborative Filtering.](http://arxiv.org/abs/2306.03624) | 本文提出了一种基于Jacobi多项式和频率分解策略的协同过滤方法JGCF，在四个真实世界数据集上进行了大量实验，并表现出优异的性能。 |
| [^3] | [BioBLP: A Modular Framework for Learning on Multimodal Biomedical Knowledge Graphs.](http://arxiv.org/abs/2306.03606) | BioBLP是一个用于生物医学知识图谱的多模态学习的模块化框架，可以编码不同模态的属性数据并支持实体的缺少属性，并提出有效的预训练策略以减少所需的训练时间。 |
| [^4] | [Enabling Efficient Interaction between an Algorithm Agent and an LLM: A Reinforcement Learning Approach.](http://arxiv.org/abs/2306.03604) | 本论文提出一种强化学习的中介模型，可实现代理与LLM之间高效经济有效的互动，提高效率和成本效益。 |
| [^5] | [TestLab: An Intelligent Automated Software Testing Framework.](http://arxiv.org/abs/2306.03602) | TestLab是一个智能化的自动化软件测试框架，通过收集一组测试方法并使用人工智能自动化这些方法，从开发人员到最终用户的不同范围对软件系统进行连续测试，并提供了三个模块来识别漏洞和增强传统的自动化软件测试。 |
| [^6] | [The Creative Frontier of Generative AI: Managing the Novelty-Usefulness Tradeoff.](http://arxiv.org/abs/2306.03601) | 本文探讨了生成AI系统中创新和实用性的平衡问题。过分注重创新性可能导致幻觉，而过度关注实用性可能导致记忆化。作者提出一个包含多种要素的框架来解决这些挑战，以旨在在特定领域内生成创新且实用的内容。 |
| [^7] | [Language acquisition: do children and language models follow similar learning stages?.](http://arxiv.org/abs/2306.03586) | 研究比较了深度语言模型和儿童的学习轨迹，发现它们都遵循将音韵作为起点逐步习得语法和语义的模式，而且都表现出对于某些语言结构有临界期的学习情况，但人类和机器学习还是存在重要差异。 |
| [^8] | [RDFC-GAN: RGB-Depth Fusion CycleGAN for Indoor Depth Completion.](http://arxiv.org/abs/2306.03584) | RDFC-GAN使用两个分支结构生成精确的深度图像，它通过解决室内环境中普遍缺失的大面积深度值问题，克服了现有方法的不足，可用于各种室内深度完成任务。 |
| [^9] | [L-C2ST: Local Diagnostics for Posterior Approximations in Simulation-Based Inference.](http://arxiv.org/abs/2306.03580) | 本文提出了一种名为 L-C2ST 的基于本地诊断实现模拟推断中后验近似的新方法，其可以在任何给定的观测下本地评估后验估计器，有效地解决了目前评估后验估计器限制解决方法的问题。 |
| [^10] | [Range-Restricted Interpolation through Clausal Tableaux.](http://arxiv.org/abs/2306.03572) | 通过Clausal Tableaux证明系统实现可行的范围限制插值算法。 |
| [^11] | [CIN++: Enhancing Topological Message Passing.](http://arxiv.org/abs/2306.03561) | CIN++是一种拓扑信息传递方案，通过考虑底层复合体中环之间的相互作用来解决图神经网络在表达能力、处理长程交互和建模高阶结构等方面的局限性。 |
| [^12] | [Take the Hint: Improving Arabic Diacritization with Partially-Diacritized Text.](http://arxiv.org/abs/2306.03557) | 本文提出了一个名为2SDiac的多源模型，可以在输入中使用可选音标来确定所有预测的输出，然后通过引入Guided Learning的训练策略，利用随机掩蔽和给定的输入音标提升标记的正确性。实验表明，该方法在非标记文本上表现良好，并实现了最先进的结果。 |
| [^13] | [An Approach to Solving the Abstraction and Reasoning Corpus (ARC) Challenge.](http://arxiv.org/abs/2306.03553) | 该研究利用GPT4训练一个多代理系统，结合视觉问答工具，可以解决大部分ARC挑战。 |
| [^14] | [State Regularized Policy Optimization on Data with Dynamics Shift.](http://arxiv.org/abs/2306.03552) | 本文提出了一种叫做 SRPO (状态规范化策略优化) 的算法，该算法利用训练数据中的稳态分布来规范新环境中的策略，在处理具有不同动态的多个环境时表现优异。 |
| [^15] | [Scalable Concept Extraction in Industry 4.0.](http://arxiv.org/abs/2306.03551) | 本文探讨了将概念提取方法应用于工业4.0场景，并改进了可扩展性，提出了具有可解释性的新概念重要性计算程序，将局部特征与整体图像联系起来。 |
| [^16] | [SDR-GAIN: A High Real-Time Occluded Pedestrian Pose Completion Method for Autonomous Driving.](http://arxiv.org/abs/2306.03538) | SDR-GAIN是一种用于解决行人姿态中部分遮挡问题的关键点补全方法，它通过对不完整的关键点进行降维，统一特征分布，并使用GAN框架的两种生成模型来完成姿态的补全。该方法的实验表明性能优于基本的GAIN框架。 |
| [^17] | [On Pitfalls of Test-Time Adaptation.](http://arxiv.org/abs/2306.03536) | 这篇论文介绍了测试时间适应（TTA）最近被认为是解决在分布转移情况下鲁棒性挑战的一种很有前途的方法，提出了测试时间适应基准TTAB，并发现了之前方法中的三个常见缺陷。 |
| [^18] | [A Belief Model for Conflicting and Uncertain Evidence -- Connecting Dempster-Shafer Theory and the Topology of Evidence.](http://arxiv.org/abs/2306.03532) | 本文提出了一种基于Dempster-Shafer理论和证据拓扑模型的信念模型，可以更为普适地计算代理人的不同标准下的信念程度。 |
| [^19] | [Expanding Explainability Horizons: A Unified Concept-Based System for Local, Global, and Misclassification Explanations.](http://arxiv.org/abs/2306.03531) | 本文提出了一种新的统一的基于概念的系统，旨在解决当前基于概念的可解释性方法不足的局部、全局和错误分类解释问题，该系统可以自动学习、评分和提取局部和全局概念。 |
| [^20] | [BackpropTools: A Fast, Portable Deep Reinforcement Learning Library for Continuous Control.](http://arxiv.org/abs/2306.03530) | BackpropTools是一款快速、可移植的连续控制深度强化学习库，它通过模板元编程提供紧密集成的可组合组件，并在异构平台集合上无缝使用，同时在连续控制问题的深度RL代理高效可扩展训练方面具有优势。由于其可移植性和实时保证，它成为了在嵌入式设备上部署学来的策略的有价值的工具。 |
| [^21] | [Adversarial Attacks and Defenses for Semantic Communication in Vehicular Metaverses.](http://arxiv.org/abs/2306.03528) | 本文提出了一种层级式SemCom实现的车载虚拟现实框架，可以显著缓解车载虚拟现实应用程序的通信资源压力，并阐述了该框架中SemCom模块的安全风险和可行的防御方法。 |
| [^22] | [Inconsistency Handling in Prioritized Databases with Universal Constraints: Complexity Analysis and Links with Active Integrity Constraints.](http://arxiv.org/abs/2306.03523) | 本文研究解决了具有全局约束的不一致数据库的修复和查询问题，通过对称差分修复并指定首选修复行动，扩展了现有的最优修复概念，并且研究了修复概念的计算属性，同时澄清了与主动完整性约束框架中引入的修复概念之间的关系。 |
| [^23] | [Logic Diffusion for Knowledge Graph Reasoning.](http://arxiv.org/abs/2306.03515) | 该篇论文提出了一种名为逻辑扩散（LoD）的插件模块，解决了现有推理模型受训练样本限制、表现不够强的问题。LoD通过关系扩散、随机游走子逻辑采样和梯度自适应等方式实现了对未见查询的发现和不同模式之间的动态平衡，并配备了特殊的损失函数以实现稳健的逻辑扩散。 |
| [^24] | [Mega-TTS: Zero-Shot Text-to-Speech at Scale with Intrinsic Inductive Bias.](http://arxiv.org/abs/2306.03509) | Mega-TTS是一种在大规模野外数据上训练的零样本TTS系统。它将语音分解成几个属性并分别使用具有适当归纳偏差的模块进行建模，包括使用频谱图作为中间特征、多说话人模型同时建模音色和韵律以及使用基于transformer的语言模型来模拟内容。实验结果表明，它在语音质量和说话人相似度指标方面显着优于先前的工作。 |
| [^25] | [Subgraph Networks Based Contrastive Learning.](http://arxiv.org/abs/2306.03506) | 本文提出了一种新的对比学习框架，名为基于子图网络的对比学习(SGNCL)，通过应用子图网络生成策略以产生增强视图，并探究了子结构相互作用对图形表示的影响。 |
| [^26] | [Applying Standards to Advance Upstream & Downstream Ethics in Large Language Models.](http://arxiv.org/abs/2306.03503) | 本文探讨如何为AI生成的内容制定安全保障，分析LLMs的内容生成机制，确定了四个关键领域，提出了新的分发和销售LLM生成内容的企业的标准。 |
| [^27] | [Russo-Ukrainian War: Prediction and explanation of Twitter suspension.](http://arxiv.org/abs/2306.03502) | 本研究分析了Twitter封禁机制，揭示了存在的政策违规、宣传、垃圾邮件等问题，并发现拥有更多粉丝的账户更可能被封禁。这些发现可以让Twitter和其他社交网络改进其内容过滤机制。 |
| [^28] | [Transition role of entangled data in quantum machine learning.](http://arxiv.org/abs/2306.03481) | 本研究证明了纠缠数据对量子机器学习的性能具有双重效应，有助于减少预测误差和减小训练数据大小，为量子机器学习模型设计提供了指南。 |
| [^29] | [GSHOT: Few-shot Generative Modeling of Labeled Graphs.](http://arxiv.org/abs/2306.03480) | GSHOT是一个用于少样本标记图生成建模的元学习框架，通过学习从类似的辅助图数据集中转移元知识，从而快速适应未见过的图数据集。 |
| [^30] | [Phonetically-Grounded Language Generation: The Case of Tongue Twisters.](http://arxiv.org/abs/2306.03457) | 本文介绍了针对绕口令生成的基于音韵学的语言生成任务，提供了TwistList数据集和TwisterMisters基准系统，并验证了预训练模型在没有任务特定数据和显式音韵知识的情况下的良好性能。 |
| [^31] | [GRAFENNE: Learning on Graphs with Heterogeneous and Dynamic Feature Sets.](http://arxiv.org/abs/2306.03447) | GRAFENNE是一种新的图神经网络框架，通过在原图上进行异构转化，将节点和特征解耦，解决了现有方法普遍存在的特征静态、转移误差等问题，并且能适用于未知节点和特征。 |
| [^32] | [MetaGait: Learning to Learn an Omni Sample Adaptive Representation for Gait Recognition.](http://arxiv.org/abs/2306.03445) | 本文开发了MetaGait技术来学习全样本自适应表示，通过注入元知识到校准网络中，从全尺度、全维度和全过程的角度改善了模型的适应性。 |
| [^33] | [Large Language Models of Code Fail at Completing Code with Potential Bugs.](http://arxiv.org/abs/2306.03438) | 本研究探讨了存在漏洞的代码补全问题，设计了两个数据集并发现这些漏洞显著降低了Code-LLMs的生成性能。 |
| [^34] | [I'm Afraid I Can't Do That: Predicting Prompt Refusal in Black-Box Generative Language Models.](http://arxiv.org/abs/2306.03423) | 本文研究了生成语言模型的拒绝行为，并发现这种行为不是完全二元的。作者对ChatGPT进行的实验表明，在微调过程中的偏见来自于个别工程师和公司政策，并影响模型选择拒绝哪些提示。 |
| [^35] | [DreamSparse: Escaping from Plato's Cave with 2D Diffusion Model Given Sparse Views.](http://arxiv.org/abs/2306.03414) | 本文提出了 DreamSparse 框架，该框架通过利用先前训练的扩散模型的 2D 先验知识，通过几何模块和空间引导模型来解决 2D 模型缺乏 3D 感知能力的问题，进一步实现了从少视角情况下合成高质量的新视角图像。 |
| [^36] | [Generate-then-Retrieve: Intent-Aware FAQ Retrieval in Product Search.](http://arxiv.org/abs/2306.03411) | 本研究提出了一种意图感知FAQ检索系统，它集成在商品搜索中，可以通过意图分类器和重构模型，提高了检索的精度和效率。 |
| [^37] | [Rigorous Runtime Analysis of MOEA/D for Solving Multi-Objective Minimum Weight Base Problems.](http://arxiv.org/abs/2306.03409) | 该论文提出了一种适用于多目标问题的进化算法MOEA/D，并且给出了针对该算法的严格运行时分析，证明在相应条件下MOEA/D的时间复杂度在oracle模型中可以以期望的固定多项式时间完成。在随机的实例中进行的实验结果证明了理论分析的正确性。 |
| [^38] | [Agents Explore the Environment Beyond Good Actions to Improve Their Model for Better Decisions.](http://arxiv.org/abs/2306.03408) | 通过探索未被访问的决策树状态和引入随机性，MuZero智能体改进了树搜索规划和模型预测之间的不一致性，提高了决策能力。 |
| [^39] | [Deep neural networks architectures from the perspective of manifold learning.](http://arxiv.org/abs/2306.03406) | 本文从几何学和拓扑学的角度，使用拓扑数据分析和持久同调分形维度对神经网络体系结构进行全面比较和描述，旨在为可解释和可解释的人工智能的发展做出贡献。 |
| [^40] | [SGAT4PASS: Spherical Geometry-Aware Transformer for PAnoramic Semantic Segmentation.](http://arxiv.org/abs/2306.03403) | 本论文提出了SGAT4PASS，一种面向球面几何意识的全景语义分割Transformer，通过加入球面几何感知的约束，能更好地捕捉全景图像的3D属性，从而提高分割性能。 |
| [^41] | [G-CAME: Gaussian-Class Activation Mapping Explainer for Object Detectors.](http://arxiv.org/abs/2306.03400) | G-CAME 提出了一种面向目标检测的高斯类激活映射解释器，通过使用激活映射与高斯核生成显著性图来突出显示图像中与预测框相关的重要区域，具有很短时间解释对象等优点。 |
| [^42] | [ColdNAS: Search to Modulate for User Cold-Start Recommendation.](http://arxiv.org/abs/2306.03387) | 本研究提出了一个调节框架ColdNAS来解决用户冷启动问题，通过神经架构搜索寻找适当的调节结构，包括函数和位置。 |
| [^43] | [VR.net: A Real-world Dataset for Virtual Reality Motion Sickness Research.](http://arxiv.org/abs/2306.03381) | VR.net是一个用于虚拟现实晕动研究的现实世界数据集，在10个不同风格的游戏中提供了大约12小时的游戏玩法视频，以及与晕动相关的标签。可以用于风险因素检测和晕动水平预测等应用程序。 |
| [^44] | [Identifying Shared Decodable Concepts in the Human Brain Using Image-Language Foundation Models.](http://arxiv.org/abs/2306.03375) | 该论文介绍了一种数据驱动的方法，利用预训练的多模态表示方法探索人脑中关于视觉概念的高度细分的语义网络，从而识别共享的可解码概念，以推断是否存在专门用于重要语义概念的脑区域。 |
| [^45] | [Bridging the Gap Between Multi-Step and One-Shot Trajectory Prediction via Self-Supervision.](http://arxiv.org/abs/2306.03367) | 本论文通过中间阶段方法，结合多模态轨迹以及自监督机制，解决了多步和单步预测之间的差距，并在INTERACTION数据集上获得有竞争力的结果。 |
| [^46] | [Boosting Offline Reinforcement Learning with Action Preference Query.](http://arxiv.org/abs/2306.03362) | 本文提出了一种名为Offline-with-Action-Preferences（OAP）的无交互训练方案，通过查询先前收集的和学习到的行动之间的偏好，来帮助解决错误估计问题，从而获得对未见数据更精确的评估。 |
| [^47] | [$\textit{WHAT}$, $\textit{WHEN}$, and $\textit{HOW}$ to Ground: Designing User Persona-Aware Conversational Agents for Engaging Dialogue.](http://arxiv.org/abs/2306.03361) | 本文提出了一种针对商业环境的、能够平衡对话流畅性和趋向于理解对话系统的个性化开放领域对话系统方法，通过加权数据集混合、负角色信息增强方法，以及设计个性化对话数据集，解决了 $\textit{WHAT}$、$\textit{WHEN}$和$\textit{HOW}$ 等问题，同时提高了对话系统响应的可控性和解释性。 |
| [^48] | [Vid2Act: Activate Offline Videos for Visual RL.](http://arxiv.org/abs/2306.03360) | Vid2Act是一种基于模型的强化学习方法，它通过使用世界模型来传输领域相关的动态和策略，从而显著提高了样本效率。 |
| [^49] | [Is AI Changing the Rules of Academic Misconduct? An In-depth Look at Students' Perceptions of 'AI-giarism'.](http://arxiv.org/abs/2306.03358) | 这项开创性研究调查了学生对“AI-giarism”的认知，提出了初始概念化的AI-giarism工具，有助于应对不断发展的AI技术带来的学术不端行为，同时还挑战了传统的学术不端行为定义。 |
| [^50] | [Simulation-Based Counterfactual Causal Discovery on Real World Driver Behaviour.](http://arxiv.org/abs/2306.03354) | 本文提出了基于仿真的反事实因果发现方法，通过重新定义问题和使用反事实仿真来解决因果关系非稳态问题和干预限制，在真实驾驶行为中得到了评估。 |
| [^51] | [Stabilizing Contrastive RL: Techniques for Offline Goal Reaching.](http://arxiv.org/abs/2306.03346) | 本文提出了一种稳定的对比强化学习方法，通过浅而宽的结构，结合谨慎的权重初始化和数据增强等实验方法，在具有挑战性的仿真基准测试中显著提高了性能，并演示了对比方法可以解决现实世界的机器人任务。 |
| [^52] | [Inference-Time Intervention: Eliciting Truthful Answers from a Language Model.](http://arxiv.org/abs/2306.03341) | 本研究提出推理时间干预（ITI）技术，通过在推理过程中跨越有限数量的注意力头，显着提高大型语言模型的真实性。在TruthfulQA基准上，ITI使LLaMA模型的真实性从32.5%提高到65.1%。ITI是一种最小程度的干扰，计算廉价，且数据效率高。 |
| [^53] | [Few Shot Rationale Generation using Self-Training with Dual Teachers.](http://arxiv.org/abs/2306.03315) | 本文提出了一种双教师学习框架，利用标记和未标记的数据，通过自我训练来改进少样本模型，实现同时生成任务标签和原理的效果；此外还提出了一种新的损失函数Masked Label Regularization，可以明确地强制解释明确地条件化。 |
| [^54] | [Multi-Agent Collaboration: Harnessing the Power of Intelligent LLM Agents.](http://arxiv.org/abs/2306.03314) | 本文提出了一种新的框架，利用多智能体系统发挥大型语言模型的能力，解决循环问题、安全风险、可扩展性、系统评估以及道德考虑等挑战，提供一个结合大型语言模型和多智能体系统优势的方式，更高效和有效地处理复杂任务。 |
| [^55] | [A Scalable and Adaptive System to Infer the Industry Sectors of Companies: Prompt + Model Tuning of Generative Language Models.](http://arxiv.org/abs/2306.03313) | 本文介绍了一个板块推断系统，可以帮助主题型私募股权基金的投资专业人士推断公司所在的行业板块。该系统建立在中型生成式语言模型上，通过Prompt+模型微调程序进行微调，并具有良好的可扩展性和适应性。 |
| [^56] | [Learning Embeddings for Sequential Tasks Using Population of Agents.](http://arxiv.org/abs/2306.03311) | 该研究基于代理人群体提出了一个信息理论框架，用于在强化学习任务中学习固定维度的嵌入，可以通过观察代理在一小组任务上的表现，来预测其在测试任务上的表现，并且可以从给定的任务选项中选择具有所需特征的任务。 |
| [^57] | [LIBERO: Benchmarking Knowledge Transfer for Lifelong Robot Learning.](http://arxiv.org/abs/2306.03310) | 该论文介绍了一个生命周期机器人学习基准测试——LIBERO。这是一个新颖的机器人操作终身学习基准测试，强调了LLDM中的五个关键研究主题，希望它能够加速构建可以在其生命周期内学习和适应的通用代理的进展。 |
| [^58] | [Towards Fairness in Personalized Ads Using Impression Variance Aware Reinforcement Learning.](http://arxiv.org/abs/2306.03293) | 本文提出了一个名为VRS的框架，通过印象方差感知的方式对广告进行重新排序，以实现更公平的个性化广告结果。 |
| [^59] | [Survival Instinct in Offline Reinforcement Learning.](http://arxiv.org/abs/2306.03286) | 离线强化学习算法即使使用错误的奖励标签，也能产生良好的表现和安全的策略，这种鲁棒性属性是由离线强化学习算法的悲观主义和常见数据收集实践中的偏见之间相互作用的结果，赋予了代理生存本能。 |
| [^60] | [Efficient automatic design of robots.](http://arxiv.org/abs/2306.03263) | 本论文首次使用进化计算和人工神经网络，能够在单个消费者级计算机上数秒内优化机器人结构以达到所需行为，为自动化设计复杂系统开辟了新的可能性。 |
| [^61] | [Understanding the Effectiveness of Early Weight Averaging for Training Large Language Models.](http://arxiv.org/abs/2306.03241) | 本文研究了使用早期权重平均化方法来提高大型语言模型质量的有效性，证明该方法可以加速收敛且测试和零样本泛化效果显著，同时有效缓解了训练中的损失波动问题。 |
| [^62] | [A Study of Global and Episodic Bonuses for Exploration in Contextual MDPs.](http://arxiv.org/abs/2306.03236) | 本研究探讨了利用全局和情境奖励进行探索的研究，发现情境奖励在共享结构很少的情况下更有效，而全局奖励则在共享结构更多的情况下更有效，并开发了一个框架以更好地理解共享结构。 |
| [^63] | [Unified Information Dynamic Analysis of Quantum Decision-Making and Search Algorithms: Computational Intelligence Measure.](http://arxiv.org/abs/2306.03233) | 本文从信息理论的角度考虑了量子算法的演变，通过基于状态叠加、量子纠缠和干涉的QAG存储信息，最小化经典和量子信息之间的差距，并将此作为QA计算智能测量的终止准则。 |
| [^64] | [Adversarial alignment: Breaking the trade-off between the strength of an attack and its relevance to human perception.](http://arxiv.org/abs/2306.03229) | 对抗攻击已成为深度神经网络的弱点, 而对抗对齐是一种新的挑战，需要考虑更多。 |
| [^65] | [Structural Re-weighting Improves Graph Domain Adaptation.](http://arxiv.org/abs/2306.03221) | 本文提出了一种名为结构重加权（StruRW）的新方法，用于解决当前图领域自适应（GDA）方法无法处理的条件结构偏移（CSS）问题，并在多个领域得到验证。 |
| [^66] | [Risk-Aware Reward Shaping of Reinforcement Learning Agents for Autonomous Driving.](http://arxiv.org/abs/2306.03220) | 本研究针对自动驾驶中RL代理的安全性问题，提出了一种增加风险感知的奖励形成方法来提高其训练和测试性能。该方法通过额外的重塑奖励项来鼓励探索并惩罚风险驾驶行为，证明其在各种RL代理中具有优势。 |
| [^67] | [NLU on Data Diets: Dynamic Data Subset Selection for NLP Classification Tasks.](http://arxiv.org/abs/2306.03208) | 本研究提出一种动态数据修剪的方法，通过定期对不重要的示例进行打分和抛弃，减少了微调大型语言模型的成本，并且在GLUE基准测试和四个联合NLU数据集上表现更好。 |
| [^68] | [Lumos in the Night Sky: AI-enabled Visual Tool for Exploring Night-Time Light Patterns.](http://arxiv.org/abs/2306.03195) | 夜Pulse是一个交互式工具，可用于夜间光（NTL）数据的可视化和分析。它可以通过图像分割、聚类和变化模式检测来识别城市发展和扩展模式，并回答有关人口因素、城市边界和异常差异的问题。 |
| [^69] | [Flipping Coins to Estimate Pseudocounts for Exploration in Reinforcement Learning.](http://arxiv.org/abs/2306.03186) | 研究提出了利用硬币翻转来推导状态的访问计数，并将其作为强化学习探索奖励，相比以往的方法在多个具有挑战性的任务上表现更好。 |
| [^70] | [Infusing Lattice Symmetry Priors in Attention Mechanisms for Sample-Efficient Abstract Geometric Reasoning.](http://arxiv.org/abs/2306.03175) | LatFormer是一种将格点对称先验融入到注意力掩码中的模型，能够用卷积网络生成软掩码来调整注意力权重。该模型在合成几何推理中取得了较好效果。 |
| [^71] | [Decoding Nature with Nature's Tools: Heterotic Line Bundle Models of Particle Physics with Genetic Algorithms and Quantum Annealing.](http://arxiv.org/abs/2306.03147) | 本文使用遗传算法和量子退火技术来解决弦理论中的复杂模型的优化问题，成功地找到了以往未能发现的解决方案，为弦场论的潜在发展提供了新的视角和可能性。 |
| [^72] | [Transferring Annotator- and Instance-dependent Transition Matrix for Learning from Crowds.](http://arxiv.org/abs/2306.03116) | 本文提出了一个高效的方法来估算特定注释者和特定实例的转移矩阵以及真实标签比例，解决了从众包中学习的标签噪声问题，并在实验中证明了方法的优越性。 |
| [^73] | [AutoExp: A multidisciplinary, multi-sensor framework to evaluate human activities in self-driving cars.](http://arxiv.org/abs/2306.03115) | 本文提出一个多学科、多传感器框架，用于评估自动驾驶汽车中乘客的活动，并在最近实际条件下捕获真实数据来创建数据集。 |
| [^74] | [Synthesizing Affective Neurophysiological Signals Using Generative Models: A Review Paper.](http://arxiv.org/abs/2306.03112) | 本文综述了使用生成模型合成神经生理信号来解决公共情感数据集稀缺性的问题。通过对领域中使用的不同生成模型进行全面分析，我们提供了有关生成模型在情感识别系统应用的优势、挑战和有前途的未来方向的深入见解。 |
| [^75] | [SwinRDM: Integrate SwinRNN with Diffusion Model towards High-Resolution and High-Quality Weather Forecasting.](http://arxiv.org/abs/2306.03110) | SwinRDM是一种将SwinRNN与扩散模型结合的数据驱动模型，它具有更优越的预报准确性以及在预测极端天气事件方面的巨大潜力。 |
| [^76] | [Guided scenarios with simulated expert personae: a remarkable strategy to perform cognitive work.](http://arxiv.org/abs/2306.03104) | 通过模拟人格的团队、提供语境、提示与引导，能够以模仿专家人格来进行认知工作。 |
| [^77] | [Rethinking Model Evaluation as Narrowing the Socio-Technical Gap.](http://arxiv.org/abs/2306.03100) | 针对同质化的模型，模型评估需要提供有效的评估，以判断特定模型是否在下游使用场景中可以满足多少人类需求，并且应该根据真实的社会需求来开发评估模型，并拥抱多样化的评估方法。 |
| [^78] | [Seeing Seeds Beyond Weeds: Green Teaming Generative AI for Beneficial Uses.](http://arxiv.org/abs/2306.03097) | 本文介绍了“绿色团队”的概念，旨在用来通过绕过GM内容过滤器设计有益用例。实际应用包括使用ChatGPT进行自杀支持培训以及使用Codex进行有缺陷的解决方案培训。 |
| [^79] | [Nonparametric Iterative Machine Teaching.](http://arxiv.org/abs/2306.03007) | 本文提出了解决非参数目标模型的迭代机器教学问题的方法，包括随机和贪心泛函教学算法。 |
| [^80] | [Time Interpret: a Unified Model Interpretability Library for Time Series.](http://arxiv.org/abs/2306.02968) | Time Interpret是一个基于Captum的模型解释库，专门用于解释时间序列数据，并实现了多种特征归因方法。此外，它还提供了各种PyTorch模型和数据集，以及一组用于评估特征归因的方法。 |
| [^81] | [Action-Evolution Petri Nets: a Framework for Modeling and Solving Dynamic Task Assignment Problems.](http://arxiv.org/abs/2306.02910) | 本文提出了一种新的建模和解决动态任务分配问题的框架—行动演变Petri网格。它提供了一种统一的建模技术，可以表示动态任务分配问题的所有要素。而且，该模型是可执行的，并且可以用于强化学习，以学习接近最优的分配策略。 |
| [^82] | [Seizing Serendipity: Exploiting the Value of Past Success in Off-Policy Actor-Critic.](http://arxiv.org/abs/2306.02865) | 该论文提出了 BEE 操作符，通过充分利用过去的成功经验，并保持探索乐观性，解决了离线策略演员-评论家中 Q 值高估与低估问题，提高了策略学习和样本效率。 |
| [^83] | [Towards Better Explanations for Object Detection.](http://arxiv.org/abs/2306.02744) | 该论文提出了一种名为D-CLOSE的方法，用于解释任何目标检测模型的决策，通过使用多个分割级别和一种组合它们的过程，可以提供更好的质量和更少的噪音解释。 |
| [^84] | [Predicting malaria dynamics in Burundi using deep Learning Models.](http://arxiv.org/abs/2306.02685) | 该论文利用机器学习方法建立疟疾预测模型，成功预测了布隆迪疟疾时空动态，为疟疾防治和干预设计提供了重要依据。 |
| [^85] | [Cycle Consistency Driven Object Discovery.](http://arxiv.org/abs/2306.02204) | 该方法通过循环一致性目标的引入，明确优化场景中每个物体应映射到不同槽位的约束，从而实现了在完全无监督的情况下有效地学习发现物体。在实验中表现出了优于现有方法的性能。 |
| [^86] | [MultiLegalPile: A 689GB Multilingual Legal Corpus.](http://arxiv.org/abs/2306.02069) | MultiLegalPile是一个689GB的多语言法律语料库，包含来自17个司法管辖区的24种语言的不同法律数据源，允许在公平使用下针对预训练NLP模型。该语料库为多语言模型的预训练提供了新的最佳表现，并在LexGLUE上表现最佳。 |
| [^87] | [A Comprehensive Survey on Deep Learning for Relation Extraction: Recent Advances and New Frontiers.](http://arxiv.org/abs/2306.02051) | 本文综述了深度学习在关系抽取领域的应用进展，提出了新的分类法，讨论了面临的挑战和应对的技术，并展望了未来的发展方向。 |
| [^88] | [Responsible Design Patterns for Machine Learning Pipelines.](http://arxiv.org/abs/2306.01788) | 本文提出了一种综合框架，将负责任设计模式纳入机器学习流程中，以确保AI系统的伦理性和公正性。这个框架包括新的负责任AI设计模式，并指导AI开发人员、数据科学家和决策者在AI开发和部署中实施伦理实践。 |
| [^89] | [A Vitual-Force Based Swarm Algorithm for Balanced Circular Bin Packing Problems.](http://arxiv.org/abs/2306.01021) | 本文描述了一种基于虚拟力系统的群智能算法，用以解决平衡圆形装箱问题，并在各种基准测试中得到验证，具有很好的解决效果。 |
| [^90] | [Analysis of ChatGPT on Source Code.](http://arxiv.org/abs/2306.00597) | 本论文探讨了大型语言模型 ChatGPT 在源代码分析中的应用，其将为程序员提供准确和高效的帮助，并在代码创建、文档编写、缺陷检测和代码重构等方面具有潜在的应用前景。 |
| [^91] | [Make Your Pre-trained Model Reversible: From Parameter to Memory Efficient Fine-Tuning.](http://arxiv.org/abs/2306.00477) | 本研究尝试实现在预训练语言模型中运用可逆模型实现高效的微调，并发现在初始化微调时保留PLM的起点非常重要。 |
| [^92] | [MERT: Acoustic Music Understanding Model with Large-Scale Self-supervised Training.](http://arxiv.org/abs/2306.00107) | 提出了一个带有大规模自监督训练的音乐理解模型MERT，利用了教师模型并采用了一种优于传统的语音和音频方法的组合方式。 |
| [^93] | [Criteria Tell You More than Ratings: Criteria Preference-Aware Light Graph Convolution for Effective Multi-Criteria Recommendation.](http://arxiv.org/abs/2305.18885) | 本文提出了一种面向多准则推荐的标准偏好感知轻量图卷积网络，该方法结合了MC扩展图，可以准确地捕捉用户的标准偏好，并进一步将用户对各个标准的偏好合并到最终的推荐列表中。 |
| [^94] | [What We Know So Far: Artificial Intelligence in African Healthcare.](http://arxiv.org/abs/2305.18302) | 本文综述了人工智能算法在非洲医疗保健领域中的应用情况和如何利用人工智能在低资源环境下改善非洲医疗保健的可访问性，并讨论了采用人工智能面临的一些重要挑战和机遇。需要政府、私营部门、医疗保健提供者和国际组织协调一致地努力，创建可持续的人工智能解决方案，满足非洲医疗保健系统独特的需求。 |
| [^95] | [InDL: A New Datasets and Benchmark for In-Diagram Logic Interpreting based on Visual Illusion.](http://arxiv.org/abs/2305.17716) | 本文提出了一个基于视错觉的独特数据集InDL，用于测试和评估深度学习模型的图中逻辑解释能力。利用几何光学视错觉，建立可比性框架用于阐明模型可能存在的缺陷和提供改进模型的洞察力。 |
| [^96] | [Do GPTs Produce Less Literal Translations?.](http://arxiv.org/abs/2305.16806) | 本研究比较了GPT和NMT生成翻译的文字积极度差异，发现GPT翻译更不准确，但在MT质量评估指标上表现出相似或更好的分数。 |
| [^97] | [ChipGPT: How far are we from natural language hardware design.](http://arxiv.org/abs/2305.14019) | 这篇论文介绍了ChipGPT，一个自动化设计环境，它利用大型语言模型从自然语言规范生成硬件逻辑设计，并展示了与人工设计性能相媲美的结果，且可节省超过75％的编码时间。 |
| [^98] | [Efficient Multi-Scale Attention Module with Cross-Spatial Learning.](http://arxiv.org/abs/2305.13563) | 本文提出了一种高效的多尺度注意力模块，重塑部分通道为批处理维度并将通道分组，以增加空间语义分布性，同时通过交叉维度交互聚合两个并行分支的输出特征。实验表明EMA可以高效地优化性能，比之前的最新方法更好。 |
| [^99] | [Physics Inspired Approaches Towards Understanding Gaussian Processes.](http://arxiv.org/abs/2305.10748) | 本文利用物理学方法分析了高斯过程模型的损失景观，提出了考虑更广泛的ν使得性能更佳的优化方法，同时提供了一种用于评估GP集成效果的方法和基于损失领域的物理属性的投票方法。 |
| [^100] | [Bridging the Gap: Enhancing the Utility of Synthetic Data via Post-Processing Techniques.](http://arxiv.org/abs/2305.10118) | 本文介绍了一种利用生成对抗网络生成合成数据集，并通过三种新颖的后处理技术改进合成数据集质量和多样性的方法。作者称其为Gap Filler (GaFi)流程并在真实图像上进行评估。 |
| [^101] | [Cold PAWS: Unsupervised class discovery and the cold-start problem.](http://arxiv.org/abs/2305.10071) | 本文提出了一种新方法，通过结合自我监督、聚类和流形学习技术，解决冷启动或无监督选择标记问题，并在多个公共数据集上进行了测试，获得了更好的性能。 |
| [^102] | [Seeing is Believing: Brain-Inspired Modular Training for Mechanistic Interpretability.](http://arxiv.org/abs/2305.08746) | BIMT方法使得神经网络更加模块化和可诠释，并且能够直接展示模块化结构，为许多简单任务提供了有用的信息，并可以补充当前的机理解释策略。 |
| [^103] | [Provable Multi-instance Deep AUC Maximization with Stochastic Pooling.](http://arxiv.org/abs/2305.08040) | 本文提出了在多实例学习中使用深度AUC最大化（DAM）的方法，并根据包含大量实例的情况下训练的计算挑战，提出了一种基于方差减少的随机池化方法，使得只需对每个包进行少量采样即可计算MIDAM模型，提高了效率和准确性。 |
| [^104] | [Semantic Embedded Deep Neural Network: A Generic Approach to Boost Multi-Label Image Classification Performance.](http://arxiv.org/abs/2305.05228) | 本研究提出了一种通用的语义嵌入深度神经网络，通过空间感知的语义特征和基于通道的注意力模型来提高多标签预测的模型性能，平均相对改进达到15.27%。 |
| [^105] | [FishRecGAN: An End to End GAN Based Network for Fisheye Rectification and Calibration.](http://arxiv.org/abs/2305.05222) | FishRecGAN提供了一种端到端的深度学习方法，以矫正鱼眼图像并同时校准相机内参和畸变参数。其快速校正网络具有良好的分辨率和鲁棒性，适用于摄像机型监控设备中的恒定标定，并使用大量合成数据集进行训练和验证，表现出了高分辨率的鲁棒性和显著的峰值信噪比。 |
| [^106] | [Data Efficient Training with Imbalanced Label Sample Distribution for Fashion Detection.](http://arxiv.org/abs/2305.04379) | 本文提出了一种最先进的加权目标函数，用于提高多标签分类中深度神经网络（DNN）针对长尾数据分布的性能，并通过对时尚服装的图像属性分类的实验，取得了良好的性能。 |
| [^107] | [SI-LSTM: Speaker Hybrid Long-short Term Memory and Cross Modal Attention for Emotion Recognition in Conversation.](http://arxiv.org/abs/2305.03506) | SI-LSTM是一种用于对话情感识别的循环结构，可以追踪不同说话人的情感状态，从而增强对话情感学习。 |
| [^108] | [An Evidential Real-Time Multi-Mode Fault Diagnosis Approach Based on Broad Learning System.](http://arxiv.org/abs/2305.00169) | 本文提出了一种基于证据推理算法和广义学习系统的实时多模态故障诊断方法，该方法在更新模型参数和计算效率方面具有优势，并且在基准数据集上取得了比现有方法更好的故障诊断性能。 |
| [^109] | [ImageCaptioner$^2$: Image Captioner for Image Captioning Bias Amplification Assessment.](http://arxiv.org/abs/2304.04874) | 本文提出了一种新的图像字幕生成器 ImageCaptioner$^2$ ，用于针对图像字幕偏差放大进行评估。 |
| [^110] | [oBERTa: Improving Sparse Transfer Learning via improved initialization, distillation, and pruning regimes.](http://arxiv.org/abs/2303.17612) | oBERTa是一组易于使用的语言模型，通过改进初始化、蒸馏、剪枝等技术，可以在不需要模型压缩方面的专业知识的情况下提高稀疏迁移学习的效率和准确性。 |
| [^111] | [What Makes Data Suitable for a Locally Connected Neural Network? A Necessary and Sufficient Condition Based on Quantum Entanglement.](http://arxiv.org/abs/2303.11249) | 本文通过采用量子物理学的理论工具，提出了一种判定数据适合于局部连接神经网络的必要且充分条件，并导出了一种相应的预处理方法。 |
| [^112] | [Graph Neural Rough Differential Equations for Traffic Forecasting.](http://arxiv.org/abs/2303.10909) | 本文提出一种基于图神经粗糙微分方程的交通预测方法(STG-NRDE)，通过两个NRDE进行时空处理并组合起来构成一个框架。实验结果表明，在6个基准数据集和27个基线模型上表现最佳。 |
| [^113] | [Active hypothesis testing in unknown environments using recurrent neural networks and model free reinforcement learning.](http://arxiv.org/abs/2303.10623) | 该论文提出了一种基于深度强化学习和监督学习的方法，用于在完全未知的环境中进行主动顺序假设检验，该方法在有限和无限时间问题中表现出与Chernoff检验相当甚至更好的性能。 |
| [^114] | [LIDA: A Tool for Automatic Generation of Grammar-Agnostic Visualizations and Infographics using Large Language Models.](http://arxiv.org/abs/2303.02927) | LIDA是一种使用大型语言模型和图像生成模型自动生成与语法无关的可视化和信息图表的工具。 |
| [^115] | [Federated Virtual Learning on Heterogeneous Data with Local-global Distillation.](http://arxiv.org/abs/2303.02278) | 该论文提出了一种名为FedLGD的新方法，通过本地和全局数据集的蒸馏组合来创建一个更小的合成数据集，以解决联邦学习中处理异构数据时的性能问题，同时使用迭代分布匹配来处理同步和类别不平衡问题。 |
| [^116] | [Learning machines for health and beyond.](http://arxiv.org/abs/2303.01513) | 适用于建立预测模型的机器学习技术在医疗领域和其他领域具有广泛应用。模型的维护和监控很关键，因为模型的性能与数据的变化和传输有关。 |
| [^117] | [Diffusion Models and Semi-Supervised Learners Benefit Mutually with Few Labels.](http://arxiv.org/abs/2302.10586) | 本文介绍了一种名为双伪训练（DPT）的训练策略，该策略结合了强大的半监督学习器和扩散模型来进一步推进半监督生成和分类任务。实验结果表明，DPT在各种情况下都能实现半监督生成和分类任务的SOTA性能，特别是在每个类别只有一个或两个标签的情况下，超过了其他一些模型。 |
| [^118] | [Adap-$\tau$: Adaptively Modulating Embedding Magnitude for Recommendation.](http://arxiv.org/abs/2302.04775) | 本研究提出了一种自适应归一化方案Adap-$\tau$，通过动态调节每个用户-每个物品对的嵌入幅度，实现了理想的推荐性能，方法在四个真实世界的数据集上都超过了基准方法。 |
| [^119] | [Adversarial Example Does Good: Preventing Painting Imitation from Diffusion Models via Adversarial Examples.](http://arxiv.org/abs/2302.04578) | 该论文提出了一种利用对抗样本来保护人类创造的艺术品，对抗侵权者利用未经授权的绘画训练DMs生成类似风格的新颖绘画的方法。 |
| [^120] | [A Theory of Link Prediction via Relational Weisfeiler-Leman.](http://arxiv.org/abs/2302.02209) | 本文提出了一种基于关系Weisfeiler-Leman算法的理论，为知识图谱中的图神经网络提供了理论解释，并对各种模型的表达能力进行了表征，并解释了一些广泛采用的实际设计选择的优点。 |
| [^121] | [Deep Reinforcement Learning for Online Error Detection in Cyber-Physical Systems.](http://arxiv.org/abs/2302.01567) | 本文提出了一种基于深度强化学习（DRL）的新型在线错误检测方法。 |
| [^122] | [Large Language Models Can Be Easily Distracted by Irrelevant Context.](http://arxiv.org/abs/2302.00093) | 本文研究了大型语言模型对无关上下文的干扰性。他们使用一个带有无关信息的算术推理数据集GSM-IC来衡量这种可干扰性。研究发现当包含无关信息时，模型性能会急剧下降，但使用自我一致性进行解码并添加一个指令可以缓解这一缺陷。 |
| [^123] | [Toward Efficient Gradient-Based Value Estimation.](http://arxiv.org/abs/2301.13757) | 本研究研究了梯度为基础的值估计方法慢的根本原因，并提出了一种低复杂度的方法以解决损失函数带来的不良影响，该方法在效率上比剩余梯度方法更快，几乎具有相同的计算复杂度，并且在经典问题上与TD具有竞争力。 |
| [^124] | [Overcoming Simplicity Bias in Deep Networks using a Feature Sieve.](http://arxiv.org/abs/2301.13293) | 提出了一种特征筛选方法，通过抑制网络较低层易计算虚假特征，使得更高层的网络提取和利用更丰富、更有意义的特征表示，从而克服了深度神经网络中的简单偏差。 |
| [^125] | [AutoPEFT: Automatic Configuration Search for Parameter-Efficient Fine-Tuning.](http://arxiv.org/abs/2301.12132) | AutoPEFT是一个自动化的PEFT（参数高效微调）配置搜索方法，它能够自动地找到最佳的PEFT模块和体系结构，以优化任务的性能和参数效率。在典型的NLP任务中，AutoPEFT表现出比手动设计更好的性能。 |
| [^126] | [Direct Parameterization of Lipschitz-Bounded Deep Networks.](http://arxiv.org/abs/2301.11526) | 本文提出了一种直接参数化的深度神经网络，其具有拉普拉斯界限，通过标准梯度方法进行训练，避免了计算密集型的投影或障碍项。 |
| [^127] | [Abstracting Imperfect Information Away from Two-Player Zero-Sum Games.](http://arxiv.org/abs/2301.09159) | 通过正则化均衡，可以将两人零和博弈中的不完美信息抽象出来并作为完全信息问题处理。 |
| [^128] | [Human-in-the-loop Embodied Intelligence with Interactive Simulation Environment for Surgical Robot Learning.](http://arxiv.org/abs/2301.00452) | 本文介绍了一种基于交互式模拟环境的人机协同体现智能机器人学习的新平台，以及人类专家指导下机器人学习表现的提高和人体示范对手术机器人控制策略的影响。 |
| [^129] | [HiTSKT: A Hierarchical Transformer Model for Session-Aware Knowledge Tracing.](http://arxiv.org/abs/2212.12139) | HiTSKT是一种分层Transformer模型，用于会话感知知识追踪，能够捕捉学生不同会话之间的关系，并学习技能级别表示，相对于现有技术基线模型表现优异。 |
| [^130] | [Benchmarking Spatial Relationships in Text-to-Image Generation.](http://arxiv.org/abs/2212.10015) | 本文研究了文本到图像生成中模型生成正确空间关系的能力，并提出了一个评估指标VISOR以衡量生成图像的准确性。实验发现当前T2I模型尽管可以生成高度逼真的图像，但其空间上准确的图像能力仍然不足，特别是在空间谓词和场景关系理解方面。 |
| [^131] | [Can In-context Learners Learn a Reasoning Concept from Demonstrations?.](http://arxiv.org/abs/2212.01692) | 本文介绍了一种概念性少样本学习方法，以帮助在场学习者学习新技能。通过选择与预测示例共享可能信息的演示，这个方法可以在模型记忆独立的情况下区分模型的在场学习能力。 |
| [^132] | [SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models.](http://arxiv.org/abs/2211.10438) | SmoothQuant是一种训练无需的通用后训练量化（PTQ）解决方案，可以在保持精度的情况下实现大型语言模型的8位权重、8位激活（W8A8）量化。SmoothQuant通过数学等效转换将量化难度从激活移到权重，使得所有矩阵乘法的权重和激活的INT8量化成为可能，具有最高1.56倍加速和2倍内存减少的效果。 |
| [^133] | [Empirical Study on Optimizer Selection for Out-of-Distribution Generalization.](http://arxiv.org/abs/2211.08583) | 本实证研究通过测试不同分布偏移下超过20,000个模型的表现，发现自适应优化器（如Adam和Adagrad）及可以减少时间相关特征的优化器具有更好的分布外泛化性能。 |
| [^134] | [Can Querying for Bias Leak Protected Attributes? Achieving Privacy With Smooth Sensitivity.](http://arxiv.org/abs/2211.02139) | 本文论证了查询公平指标可能会泄露受保护属性，提出了解决方案以保护隐私。 |
| [^135] | [I Prefer not to Say: Protecting User Consent in Models with Optional Personal Data.](http://arxiv.org/abs/2210.13954) | 该论文研究了个人可以选择与决策系统共享可选个人信息的机器学习模型，并提出了保护用户同意的PUC概念，为用户隐私保护提供了有力的解决方案。 |
| [^136] | [Improving Medical Predictions by Irregular Multimodal Electronic Health Records Modeling.](http://arxiv.org/abs/2210.12156) | 本文利用门控机制和时间注意力机制分别建模不规则时间序列和临床笔记表征，进而通过交替注意力机制整合多模态信息，从而改进医疗预测。 |
| [^137] | [Surgical Fine-Tuning Improves Adaptation to Distribution Shifts.](http://arxiv.org/abs/2210.11466) | 本研究表明，选择性地微调预训练模型的子集层（手术微调）在适应分布偏移的任务中效果更好，在真实数据中得到了验证，还在理论上证明在理想环境下，手术微调可以优于全层微调。 |
| [^138] | [Controllable Dialogue Simulation with In-Context Learning.](http://arxiv.org/abs/2210.04185) | 本文提出了一种基于上下文学习的对话模拟方法，通过少量带注释的示例自动创建大量对话数据，比众包更加成本效益和节省时间，实验证明在低资源环境下使用模拟对话训练模型可以获得更好的性能。 |
| [^139] | [Less is More: Task-aware Layer-wise Distillation for Language Model Compression.](http://arxiv.org/abs/2210.01351) | 本文提出了一种新的面向任务的分层蒸馏方法（TED），通过设计任务感知的滤波器来对齐学生和教师的隐藏表示，选择有用的知识，减少知识差距，使学生模型更好地适应目标任务，实现了比最先进方法更少的参数下可比或更好的性能。 |
| [^140] | [MLink: Linking Black-Box Models from Multiple Domains for Collaborative Inference.](http://arxiv.org/abs/2209.13883) | 本文提出了新的学习任务：模型链接，旨在通过学习不同黑盒模型输出空间之间映射的模型链接，把它们连接起来。提出了支持链接不同黑盒机器学习模型的设计，解决了分布差异挑战，开发了一个调度算法，并在多个实验数据集上实现了高效的推理结果。 |
| [^141] | [InFi: End-to-End Learning to Filter Input for Resource-Efficiency in Mobile-Centric Inference.](http://arxiv.org/abs/2209.13873) | 本研究提出了一个端到端可学习的输入过滤框架，通过对推理模型和输入过滤器的假设复杂性进行理论比较，从而了解优化潜力。该框架减少冗余，降低推理成本，并在f值、推理速度和内存占用方面超越其他方法。 |
| [^142] | [Learning to predict 3D rotational dynamics from images of a rigid body with unknown mass distribution.](http://arxiv.org/abs/2209.11355) | 该研究提出了一种基于物理知识的神经网络模型，通过多级预测流程，从刚体图像序列中预测3D旋转动力学，解决了标准深度学习方法无法揭示体内质量分布影响的问题。 |
| [^143] | [Predicting the Next Action by Modeling the Abstract Goal.](http://arxiv.org/abs/2209.05044) | 这篇论文提出了一种可以模型化抽象目标，以降低行动预测中不确定性的行动预测模型。使用视觉表征来描述动作和目标信息，并设计抽象目标为一个分布。该模型可在Epic-Kitchen数据集上实现最先进性能。 |
| [^144] | [Individual fairness under Varied Notions of Group Fairness in Bipartite Matching -- One Framework to Approximate Them Al.](http://arxiv.org/abs/2208.09951) | 本文研究在满足群体和个体公平性约束的情况下分配物品给平台的问题，并提出了一种近似框架，可以用来近似文献中提出的群体公平性概念，同时实现个体公平性。 |
| [^145] | [When are Post-hoc Conceptual Explanations Identifiable?.](http://arxiv.org/abs/2206.13872) | 本论文提出了可识别的概念发现方法，可以恢复出多个已知的概念，以确保解释的可靠性。对于具有依赖关系的概念，提出了两种新的方法，利用图像生成过程的功能组合性质。该方法明显优于现有方法。 |
| [^146] | [Global Context Vision Transformers.](http://arxiv.org/abs/2206.09959) | 提出了全局上下文视觉Transformer (GC ViT) 架构，利用全局上下文自注意力模块和标准的局部自注意力对长距离和短距离空间相互作用进行有效而高效的建模，同时解决了ViTs中缺乏归纳偏差的问题，在图像分类、目标检测和语义分割任务中表现出最先进的结果。 |
| [^147] | [I Know What You Trained Last Summer: A Survey on Stealing Machine Learning Models and Defences.](http://arxiv.org/abs/2206.08451) | 随着机器学习即服务（MLaaS）的普及，用户可以使用最复杂的机器学习模型的预测，但也危及了MLaaS提供商的知识产权，攻击者可以创建一个具备相同行为的模型副本，本文针对模型窃取的攻击和相应的对策进行了综合调查。 |
| [^148] | [Human Mobility Prediction with Causal and Spatial-constrained Multi-task Network.](http://arxiv.org/abs/2206.05731) | 本文提出了一种基于因果和空间约束的多任务网络，名为CSLSL，用于人类流动的预测，并且在实验中取得了比现有基线模型更好的准确性和可解释性。 |
| [^149] | [Neuro-Symbolic Learning of Answer Set Programs from Raw Data.](http://arxiv.org/abs/2205.12735) | 本文提出了一种神经符号归纳学习器（NSIL）的方法，它训练一个通用的神经网络来从原始数据中提取潜在的概念，并学习将潜在概念映射到目标标签的符号知识。 |
| [^150] | [Covariance Matrix Adaptation MAP-Annealing.](http://arxiv.org/abs/2205.10752) | 本文提出了一种新的质量多样性算法——协方差矩阵自适应MAP退火（CMA-MAE），用于解决过早地放弃目标以进行探索、难以探索平坦目标以及低分辨率档案性能差等问题，实现了最先进的性能和鲁棒性。 |
| [^151] | [A Principles-based Ethics Assurance Argument Pattern for AI and Autonomous Systems.](http://arxiv.org/abs/2203.15370) | 本文介绍了一种基于原则的伦理保证论证模式，用于确保特定的AI/AS在运行时在伦理上是可接受的。该模式采用了公正、行善、不伤害、尊重人的自主权、透明度等伦理原则，缩写为PRAISE。 |
| [^152] | [Learning Intuitive Policies Using Action Features.](http://arxiv.org/abs/2201.12658) | 本论文研究了网络体系结构对多智能体协作中学习算法利用动作特征和观测特征之间语义关系的影响，发现联合处理观察特征和动作特征的特征表示的注意力机制架构可以学习直觉策略，并且这样的代理与人类协作而无需接受人类数据训练。 |
| [^153] | [Deep Serial Number: Computational Watermarking for DNN Intellectual Property Protection.](http://arxiv.org/abs/2011.08960) | 本文提出了一种名为 Deep Serial Number (DSN) 的水印算法用于深度神经网络的知识产权保护。该算法在DNN中实现序列号嵌入，只有输入有效序列号的情况下，DNN才能正确工作。 |

# 详细

[^1]: 量子概率驱动下的联合多模态讽刺、情感和情绪分析框架

    A Quantum Probability Driven Framework for Joint Multi-Modal Sarcasm, Sentiment and Emotion Analysis. (arXiv:2306.03650v1 [cs.CL])

    [http://arxiv.org/abs/2306.03650](http://arxiv.org/abs/2306.03650)

    本篇论文提出了一种使用量子概率驱动的框架，用于联合多模态讽刺、情感和情绪分析，解决了传统概率的兼容性假设和现有方法的不足问题。

    

    讽刺、情感和情绪是人类对外部事件产生的三种典型自发情感反应，它们与彼此耦合。这些事件可以用多种表达方式表达，例如多模态对话。联合分析人类的多模态讽刺、情感和情绪是一个重要而具有挑战性的主题，因为它是一个涉及跨模态交互和跨情感相关性的复杂认知过程。从概率论的角度来看，跨情感相关性意味着对讽刺、情感和情绪的判断是不兼容的。然而，这种现象由于经典概率理论的兼容性假设和现有方法的不足而无法被充分建模。考虑到量子概率在建模人类认知方面的最近成功，尤其是上下文不相容决策，我们提出了基于量子概率的框架来解决这个问题。

    Sarcasm, sentiment, and emotion are three typical kinds of spontaneous affective responses of humans to external events and they are tightly intertwined with each other. Such events may be expressed in multiple modalities (e.g., linguistic, visual and acoustic), e.g., multi-modal conversations. Joint analysis of humans' multi-modal sarcasm, sentiment, and emotion is an important yet challenging topic, as it is a complex cognitive process involving both cross-modality interaction and cross-affection correlation. From the probability theory perspective, cross-affection correlation also means that the judgments on sarcasm, sentiment, and emotion are incompatible. However, this exposed phenomenon cannot be sufficiently modelled by classical probability theory due to its assumption of compatibility. Neither do the existing approaches take it into consideration. In view of the recent success of quantum probability (QP) in modeling human cognition, particularly contextual incompatible decisio
    
[^2]: 关于用户-物品图信号处理的研究：基于Jacobi多项式的图协同过滤

    On Manipulating Signals of User-Item Graph: A Jacobi Polynomial-based Graph Collaborative Filtering. (arXiv:2306.03624v1 [cs.IR])

    [http://arxiv.org/abs/2306.03624](http://arxiv.org/abs/2306.03624)

    本文提出了一种基于Jacobi多项式和频率分解策略的协同过滤方法JGCF，在四个真实世界数据集上进行了大量实验，并表现出优异的性能。

    

    协同过滤是推荐系统中的重要研究方向，旨在利用用户-物品交互信息进行推荐。图协同过滤由于其在利用用户-物品二分图中的高阶信息进行更好的推荐方面的有效性而引起越来越多的关注。最近的研究表明，图神经网络对于协同过滤的成功归因于其低通滤波效应。然而，当前的研究缺乏对不同信号分量如何影响推荐以及如何设计策略以正确使用它们的研究。为此，从谱变换的角度出发，我们分析了一个图滤波器应考虑的重要因素以实现更好的性能。基于这些发现，我们设计了JGCF，一种基于Jacobi多项式和频率分解策略的协同过滤方法，该方法高效且有效。在四个广泛使用的真实世界数据集上进行的大量实验表明，所提出的方法优于现有的图协同过滤方法。

    Collaborative filtering (CF) is an important research direction in recommender systems that aims to make recommendations given the information on user-item interactions. Graph CF has attracted more and more attention in recent years due to its effectiveness in leveraging high-order information in the user-item bipartite graph for better recommendations. Specifically, recent studies show the success of graph neural networks (GNN) for CF is attributed to its low-pass filtering effects. However, current researches lack a study of how different signal components contributes to recommendations, and how to design strategies to properly use them well. To this end, from the view of spectral transformation, we analyze the important factors that a graph filter should consider to achieve better performance. Based on the discoveries, we design JGCF, an efficient and effective method for CF based on Jacobi polynomial bases and frequency decomposition strategies. Extensive experiments on four widely
    
[^3]: BioBLP：用于学习多模态生物医学知识图谱的模块化框架

    BioBLP: A Modular Framework for Learning on Multimodal Biomedical Knowledge Graphs. (arXiv:2306.03606v1 [cs.AI])

    [http://arxiv.org/abs/2306.03606](http://arxiv.org/abs/2306.03606)

    BioBLP是一个用于生物医学知识图谱的多模态学习的模块化框架，可以编码不同模态的属性数据并支持实体的缺少属性，并提出有效的预训练策略以减少所需的训练时间。

    

    知识图谱是表示生物医学实体之间复杂关系的重要工具。已经提出了一些方法来学习嵌入，可以用于预测这些图谱中的新链路。一些方法忽略了生物医学知识图谱中与实体相关的有价值的属性数据，如蛋白质序列或分子图。其他方法则包含此类数据，但假设实体可以用相同的数据模态表示。然而生物医学知识图谱中实体常常表现出异质模态，这是其在该领域中表示的关键。我们提出了一个用于学习带有实体属性的知识图谱嵌入的模块化框架，其允许对不同模态的属性数据进行编码，同时支持缺少属性的实体。此外，我们还提出了一种有效的预训练策略，以减少所需的训练时间。我们使用包含多模态实体数据的生物医学知识图谱进行模型训练。

    Knowledge graphs (KGs) are an important tool for representing complex relationships between entities in the biomedical domain. Several methods have been proposed for learning embeddings that can be used to predict new links in such graphs. Some methods ignore valuable attribute data associated with entities in biomedical KGs, such as protein sequences, or molecular graphs. Other works incorporate such data, but assume that entities can be represented with the same data modality. This is not always the case for biomedical KGs, where entities exhibit heterogeneous modalities that are central to their representation in the subject domain.  We propose a modular framework for learning embeddings in KGs with entity attributes, that allows encoding attribute data of different modalities while also supporting entities with missing attributes. We additionally propose an efficient pretraining strategy for reducing the required training runtime. We train models using a biomedical KG containing ap
    
[^4]: 一种基于强化学习的方法促进算法代理与LLM之间的高效互动

    Enabling Efficient Interaction between an Algorithm Agent and an LLM: A Reinforcement Learning Approach. (arXiv:2306.03604v1 [cs.AI])

    [http://arxiv.org/abs/2306.03604](http://arxiv.org/abs/2306.03604)

    本论文提出一种强化学习的中介模型，可实现代理与LLM之间高效经济有效的互动，提高效率和成本效益。

    

    大型语言模型(LLMs)包含从海量文本数据集中获取的大量世界知识。最近的研究表明，LLMs可以通过提供高层指令来协助算法代理解决具有复杂顺序决策的任务。然而，与LLMs进行交互可能耗时较长，因为在许多实际情况下，它们需要大量存储空间，只能部署在远程云服务器节点上。此外，使用商业LLMs可能成本很高，因为它们可能根据使用频率收费。本文探讨如何实现代理与LLM之间的高效和经济有效的互动。我们提出了一种基于强化学习的中介模型，以确定何时需要查询LLMs以完成目标任务的高级指令。在涉及规划子目标的4个MiniGrid环境上进行的实验表明，我们的方法可以学习解决目标任务，并提升了效率和成本效益。

    Large language models (LLMs) encode a vast amount of world knowledge acquired from massive text datasets. Recent studies have demonstrated that LLMs can assist an algorithm agent in solving complex sequential decision making tasks in embodied environments by providing high-level instructions. However, interacting with LLMs can be time-consuming, as in many practical scenarios, they require a significant amount of storage space that can only be deployed on remote cloud server nodes. Additionally, using commercial LLMs can be costly since they may charge based on usage frequency. In this paper, we explore how to enable efficient and cost-effective interactions between the agent and an LLM. We propose a reinforcement learning based mediator model that determines when it is necessary to consult LLMs for high-level instructions to accomplish a target task. Experiments on 4 MiniGrid environments that entail planning sub-goals demonstrate that our method can learn to solve target tasks with o
    
[^5]: TestLab：一种智能化的自动化软件测试框架

    TestLab: An Intelligent Automated Software Testing Framework. (arXiv:2306.03602v1 [cs.SE])

    [http://arxiv.org/abs/2306.03602](http://arxiv.org/abs/2306.03602)

    TestLab是一个智能化的自动化软件测试框架，通过收集一组测试方法并使用人工智能自动化这些方法，从开发人员到最终用户的不同范围对软件系统进行连续测试，并提供了三个模块来识别漏洞和增强传统的自动化软件测试。

    

    软件系统的普及已成为现代生活的一部分。软件使用量显著增加，导致软件的规模和复杂性增长。因此，软件开发变得更加耗时。为了加速开发周期，测试阶段经常被忽略，导致部署有缺陷的系统，可能对用户的日常活动产生重大影响。本文介绍了TestLab，一种智能化的自动化软件测试框架，试图收集一组测试方法并使用人工智能自动化这些方法，从不同的角度和不同范围（从开发人员到最终用户）对软件系统进行连续测试。该工具由三个模块组成，每个模块都有不同的用途。前两个模块旨在从不同的角度识别漏洞，而第三个模块通过自动化增强传统的自动化软件测试。

    The prevalence of software systems has become an integral part of modern-day living. Software usage has increased significantly, leading to its growth in both size and complexity. Consequently, software development is becoming a more time-consuming process. In an attempt to accelerate the development cycle, the testing phase is often neglected, leading to the deployment of flawed systems that can have significant implications on the users daily activities. This work presents TestLab, an intelligent automated software testing framework that attempts to gather a set of testing methods and automate them using Artificial Intelligence to allow continuous testing of software systems at multiple levels from different scopes, ranging from developers to end-users. The tool consists of three modules, each serving a distinct purpose. The first two modules aim to identify vulnerabilities from different perspectives, while the third module enhances traditional automated software testing by automati
    
[^6]: 生成AI的创造性新领域：平衡创新和实用性的权衡

    The Creative Frontier of Generative AI: Managing the Novelty-Usefulness Tradeoff. (arXiv:2306.03601v1 [cs.AI])

    [http://arxiv.org/abs/2306.03601](http://arxiv.org/abs/2306.03601)

    本文探讨了生成AI系统中创新和实用性的平衡问题。过分注重创新性可能导致幻觉，而过度关注实用性可能导致记忆化。作者提出一个包含多种要素的框架来解决这些挑战，以旨在在特定领域内生成创新且实用的内容。

    

    本文从人类创造力文献中获得灵感，探讨了生成人工智能（AI）系统中创新和实用性的最佳平衡。我们认为过分强调任一方面都会导致一些限制，如幻觉和记忆化。当模型将创新性置于实用性之上时，会出现包含随机不准确或错误信息的AI响应，称为幻觉。过度关注实用性则可能导致AI模型复制其训练数据的内容，即记忆化，可能会限制创造力。为了应对这些挑战，我们提出了一个框架，包括特定领域的分析、数据和转移学习、用户偏好和定制、自定义评价指标以及协作机制。我们的方法旨在在特定领域内生成既新颖又实用的内容，同时考虑各种上下文的独特要求。

    In this paper, drawing inspiration from the human creativity literature, we explore the optimal balance between novelty and usefulness in generative Artificial Intelligence (AI) systems. We posit that overemphasizing either aspect can lead to limitations such as hallucinations and memorization. Hallucinations, characterized by AI responses containing random inaccuracies or falsehoods, emerge when models prioritize novelty over usefulness. Memorization, where AI models reproduce content from their training data, results from an excessive focus on usefulness, potentially limiting creativity. To address these challenges, we propose a framework that includes domain-specific analysis, data and transfer learning, user preferences and customization, custom evaluation metrics, and collaboration mechanisms. Our approach aims to generate content that is both novel and useful within specific domains, while considering the unique requirements of various contexts.
    
[^7]: 语言习得：儿童和语言模型是否遵循相似的学习阶段？

    Language acquisition: do children and language models follow similar learning stages?. (arXiv:2306.03586v1 [cs.CL])

    [http://arxiv.org/abs/2306.03586](http://arxiv.org/abs/2306.03586)

    研究比较了深度语言模型和儿童的学习轨迹，发现它们都遵循将音韵作为起点逐步习得语法和语义的模式，而且都表现出对于某些语言结构有临界期的学习情况，但人类和机器学习还是存在重要差异。

    

    在语言习得过程中，儿童会按照典型的学习阶段顺序学习语言，首先学习发音分类，然后发展词汇，最终掌握越来越复杂的句法结构。然而，导致这种学习轨迹的计算原则仍然大部分未知。为了研究这一问题，我们比较了深度语言模型的学习轨迹和儿童的学习轨迹。具体而言，我们测试了GPT-2在训练过程中是否展现出与18个月至6岁儿童相似的语言习得阶段。通过从BLiMP、Zorro和BIG-Bench数据集中获取96个评估数据集，我们训练48个GPT-2模型，并在每个训练步骤中评估它们的句法和语义能力。然后将这些评估与54个儿童的语言产生过程行为进行比较。我们的分析揭示出了三个主要发现。首先，与儿童一样，语言模型倾向于首先习得音韵信息，然后逐渐学习使用正确的语法和语义生成单词和句子。其次，语言模型表现出对某些语言结构的学习有临界期，类似于儿童。最后，虽然总体上的学习轨迹相似，但也存在儿童和模型之间的重要差异，这可能指向了人类和机器学习之间的根本差异。

    During language acquisition, children follow a typical sequence of learning stages, whereby they first learn to categorize phonemes before they develop their lexicon and eventually master increasingly complex syntactic structures. However, the computational principles that lead to this learning trajectory remain largely unknown. To investigate this, we here compare the learning trajectories of deep language models to those of children. Specifically, we test whether, during its training, GPT-2 exhibits stages of language acquisition comparable to those observed in children aged between 18 months and 6 years. For this, we train 48 GPT-2 models from scratch and evaluate their syntactic and semantic abilities at each training step, using 96 probes curated from the BLiMP, Zorro and BIG-Bench benchmarks. We then compare these evaluations with the behavior of 54 children during language production. Our analyses reveal three main findings. First, similarly to children, the language models tend
    
[^8]: RDFC-GAN:室内深度完形补全的RGB-Depth融合CycleGAN(arXiv:2306.03584v1 [cs.CV])

    RDFC-GAN: RGB-Depth Fusion CycleGAN for Indoor Depth Completion. (arXiv:2306.03584v1 [cs.CV])

    [http://arxiv.org/abs/2306.03584](http://arxiv.org/abs/2306.03584)

    RDFC-GAN使用两个分支结构生成精确的深度图像，它通过解决室内环境中普遍缺失的大面积深度值问题，克服了现有方法的不足，可用于各种室内深度完成任务。

    

    室内深度传感器捕捉的原始深度图像通常具有大量缺失深度值的范围，导致了很多带下游视觉任务的不完整的深度图，因此已经提出了越来越多的深度完成方法。为了解决这些问题，设计了一种名为RDFC-GAN的新颖的双支端到端融合网络，它需要一对RGB和不完整深度图像作为输入来预测一个密集的和完成的深度图。

    The raw depth image captured by indoor depth sensors usually has an extensive range of missing depth values due to inherent limitations such as the inability to perceive transparent objects and the limited distance range. The incomplete depth map with missing values burdens many downstream vision tasks, and a rising number of depth completion methods have been proposed to alleviate this issue. While most existing methods can generate accurate dense depth maps from sparse and uniformly sampled depth maps, they are not suitable for complementing large contiguous regions of missing depth values, which is common and critical in images captured in indoor environments. To overcome these challenges, we design a novel two-branch end-to-end fusion network named RDFC-GAN, which takes a pair of RGB and incomplete depth images as input to predict a dense and completed depth map. The first branch employs an encoder-decoder structure, by adhering to the Manhattan world assumption and utilizing norma
    
[^9]: L-C2ST: 基于本地诊断实现模拟推断中后验近似

    L-C2ST: Local Diagnostics for Posterior Approximations in Simulation-Based Inference. (arXiv:2306.03580v1 [stat.ML])

    [http://arxiv.org/abs/2306.03580](http://arxiv.org/abs/2306.03580)

    本文提出了一种名为 L-C2ST 的基于本地诊断实现模拟推断中后验近似的新方法，其可以在任何给定的观测下本地评估后验估计器，有效地解决了目前评估后验估计器限制解决方法的问题。

    

    最近许多模拟推断（SBI）的工作都依赖于深度生成模型来近似复杂、高维度的后验分布。然而，评估这些近似是否可信仍是一个挑战。大多数方法仅在观测空间期望下评估后验估计器。这限制了它们的可解释性，并不能足够地确定哪些观测结果可以信任这些近似或应该改进。我们基于著名的分类器两样本检验 (C2ST)，引入 L-C2ST，一个新方法，允许在任何给定的观测下本地评估后验估计器。它提供有理论基础和易于解释的，如图示诊断。与 C2ST 不同的是，L-C2ST 不需要访问真实后验的样本。对于基于归一化流的后验估计器，L-C2ST 可以专门提供更好的统计功率，同时计算效率更高。

    Many recent works in simulation-based inference (SBI) rely on deep generative models to approximate complex, high-dimensional posterior distributions. However, evaluating whether or not these approximations can be trusted remains a challenge. Most approaches evaluate the posterior estimator only in expectation over the observation space. This limits their interpretability and is not sufficient to identify for which observations the approximation can be trusted or should be improved. Building upon the well-known classifier two-sample test (C2ST), we introduce L-C2ST, a new method that allows for a local evaluation of the posterior estimator at any given observation. It offers theoretically grounded and easy to interpret - e.g. graphical - diagnostics, and unlike C2ST, does not require access to samples from the true posterior. In the case of normalizing flow-based posterior estimators, L-C2ST can be specialized to offer better statistical power, while being computationally more efficien
    
[^10]: 通过Clausal Tableaux实现范围限制插值

    Range-Restricted Interpolation through Clausal Tableaux. (arXiv:2306.03572v1 [cs.LO])

    [http://arxiv.org/abs/2306.03572](http://arxiv.org/abs/2306.03572)

    通过Clausal Tableaux证明系统实现可行的范围限制插值算法。

    

    本文展示了如何通过一阶逻辑的Clausal Tableaux证明系统，从输入到输出传递变化的范围限制和Horn性质。本文的重点是将证明结构的操作与高度优化的一阶证明器结合起来，实现可行的实现方法。主要应用于查询合成和插值重构。

    We show how variations of range-restriction and also the Horn property can be passed from inputs to outputs of Craig interpolation in first-order logic. The proof system is clausal tableaux, which stems from first-order ATP. Our results are induced by a restriction of the clausal tableau structure, which can be achieved in general by a proof transformation, also if the source proof is by resolution/paramodulation. Primarily addressed applications are query synthesis and reformulation with interpolation. Our methodical approach combines operations on proof structures with the immediate perspective of feasible implementation through incorporating highly optimized first-order provers.
    
[^11]: CIN++：增强拓扑信息传递

    CIN++: Enhancing Topological Message Passing. (arXiv:2306.03561v1 [cs.LG])

    [http://arxiv.org/abs/2306.03561](http://arxiv.org/abs/2306.03561)

    CIN++是一种拓扑信息传递方案，通过考虑底层复合体中环之间的相互作用来解决图神经网络在表达能力、处理长程交互和建模高阶结构等方面的局限性。

    

    图神经网络已经在学习图结构化数据方面获得了显着的成功。然而，它们在表达能力上存在显著的局限性，难以处理长程交互，并缺乏对建模高阶结构和群体相互作用的基本方法。细胞同构网络最近通过基于细胞复合体的信息传递方案解决了大部分这些挑战。尽管具有优势，但CIN仅使用边界和上部信息，而没有考虑底层复合体中存在的环之间的直接相互作用。考虑到这些相互作用可能对学习许多真实复杂现象的表示非常重要，如超分子组装的动力学、脑内神经活动和基因调控过程。因此本文提出了CIN++，这是CIN引入的拓扑信息传递方案的一种增强版。我们的信息传递方案考虑了环之间的相互作用。

    Graph Neural Networks (GNNs) have demonstrated remarkable success in learning from graph-structured data. However, they face significant limitations in expressive power, struggling with long-range interactions and lacking a principled approach to modeling higher-order structures and group interactions. Cellular Isomorphism Networks (CINs) recently addressed most of these challenges with a message passing scheme based on cell complexes. Despite their advantages, CINs make use only of boundary and upper messages which do not consider a direct interaction between the rings present in the underlying complex. Accounting for these interactions might be crucial for learning representations of many real-world complex phenomena such as the dynamics of supramolecular assemblies, neural activity within the brain, and gene regulation processes. In this work, we propose CIN++, an enhancement of the topological message passing scheme introduced in CINs. Our message passing scheme accounts for the af
    
[^12]: 利用部分标注的文本提升阿拉伯语音标注的准确性

    Take the Hint: Improving Arabic Diacritization with Partially-Diacritized Text. (arXiv:2306.03557v1 [cs.CL])

    [http://arxiv.org/abs/2306.03557](http://arxiv.org/abs/2306.03557)

    本文提出了一个名为2SDiac的多源模型，可以在输入中使用可选音标来确定所有预测的输出，然后通过引入Guided Learning的训练策略，利用随机掩蔽和给定的输入音标提升标记的正确性。实验表明，该方法在非标记文本上表现良好，并实现了最先进的结果。

    

    自动化的阿拉伯语音标注在很多应用场景中都非常有用，比如对于语言学习者来说，标注可以提供阅读支持，而对于语音合成这样的下游任务，标注准确性对于发音预测也非常重要。之前的研究大多数专注于处理没有音标的原始文本的模型，但是通过给人类提供选定的或部分标注的敏感词汇，可以使得生产系统的准确性更高。本文提出了一个名为2SDiac的多源模型，可以有效地支持输入中的可选音标以确定所有预测的输出。此外，本文还引入了一种称为Guided Learning的训练策略，可以利用给定的输入音标和不同等级的随机掩蔽来提升标注的正确性。我们展示了测试期间提供的标注能够影响更多的输出位置，实验结果还表明，我们的方法可以在非标记文本上表现出优异的效果，并且可以在减少60%的参数数目的情况下实现最先进的结果。

    Automatic Arabic diacritization is useful in many applications, ranging from reading support for language learners to accurate pronunciation predictor for downstream tasks like speech synthesis. While most of the previous works focused on models that operate on raw non-diacritized text, production systems can gain accuracy by first letting humans partly annotate ambiguous words. In this paper, we propose 2SDiac, a multi-source model that can effectively support optional diacritics in input to inform all predictions. We also introduce Guided Learning, a training scheme to leverage given diacritics in input with different levels of random masking. We show that the provided hints during test affect more output positions than those annotated. Moreover, experiments on two common benchmarks show that our approach i) greatly outperforms the baseline also when evaluated on non-diacritized text; and ii) achieves state-of-the-art results while reducing the parameter count by over 60%.
    
[^13]: 解决抽象推理语料库（ARC）挑战的方法

    An Approach to Solving the Abstraction and Reasoning Corpus (ARC) Challenge. (arXiv:2306.03553v1 [cs.AI])

    [http://arxiv.org/abs/2306.03553](http://arxiv.org/abs/2306.03553)

    该研究利用GPT4训练一个多代理系统，结合视觉问答工具，可以解决大部分ARC挑战。

    

    我们利用大型语言模型（LLMs），特别是GPT4，将其编程用于执行任意任务。在这里，我们通过文本给予该模型一些人类先验知识，以及一些解决ARC任务的典型过程，并要求其生成i）输入输出关系的广泛描述，ii）输入输出映射的详细步骤，iii）使用详细步骤对测试输入进行操作并得出测试输出。目前的GPT3.5 / GPT4提示解决了4个测试的小ARC挑战中的2个（那些拥有8x8及以下小网格的挑战）。通过对提示进行微调，使其更具体地为用例服务，它可以解决更多问题。我们推测，当被扩展成为一个多代理系统，并使用过去的记忆以及通过视觉问答工具来解释图片时，我们实际上可能能够解决大部分ARC挑战。

    We utilise the power of Large Language Models (LLMs), in particular GPT4, to be prompt engineered into performing an arbitrary task. Here, we give the model some human priors via text, along with some typical procedures for solving the ARC tasks, and ask it to generate the i) broad description of the input-output relation, ii) detailed steps of the input-output mapping, iii) use the detailed steps to perform manipulation on the test input and derive the test output. The current GPT3.5/GPT4 prompt solves 2 out of 4 tested small ARC challenges (those with small grids of 8x8 and below). With tweaks to the prompt to make it more specific for the use case, it can solve more. We posit that when scaled to a multi-agent system with usage of past memory and equipped with an image interpretation tool via Visual Question Answering, we may actually be able to solve the majority of the ARC challenge
    
[^14]: 数据中动态偏移的状态规范化策略优化

    State Regularized Policy Optimization on Data with Dynamics Shift. (arXiv:2306.03552v1 [cs.LG])

    [http://arxiv.org/abs/2306.03552](http://arxiv.org/abs/2306.03552)

    本文提出了一种叫做 SRPO (状态规范化策略优化) 的算法，该算法利用训练数据中的稳态分布来规范新环境中的策略，在处理具有不同动态的多个环境时表现优异。

    

    在许多实际场景中，强化学习算法使用的数据受到动态偏移的影响，即具有不同的环境动态。目前的大多数方法通过训练上下文编码器来识别环境参数来解决这个问题。根据其环境参数将带有动态漂移的数据分开以训练相应的策略。然而，这些方法可能会出现样本效率低下的问题，因为数据是“特定场景”使用的，针对某个环境训练的策略不能从收集在其他具有不同动态的所有其他环境中的数据中受益。本文发现，在许多具有相似结构和不同动态的环境中，最优策略具有类似的稳态分布。我们利用这种特性，并从具有动态漂移的数据中学习稳态分布，以实现高效的数据重用。这种分布用于规范新环境中训练的策略，导致了 SRPO（状态规范化策略优化）算法的出现。实验结果表明，SRPO 在具有动态偏移的任务上显著优于现有的方法。

    In many real-world scenarios, Reinforcement Learning (RL) algorithms are trained on data with dynamics shift, i.e., with different underlying environment dynamics. A majority of current methods address such issue by training context encoders to identify environment parameters. Data with dynamics shift are separated according to their environment parameters to train the corresponding policy. However, these methods can be sample inefficient as data are used \textit{ad hoc}, and policies trained for one dynamics cannot benefit from data collected in all other environments with different dynamics. In this paper, we find that in many environments with similar structures and different dynamics, optimal policies have similar stationary state distributions. We exploit such property and learn the stationary state distribution from data with dynamics shift for efficient data reuse. Such distribution is used to regularize the policy trained in a new environment, leading to the SRPO (\textbf{S}tat
    
[^15]: 工业4.0中可扩展的概念抽取

    Scalable Concept Extraction in Industry 4.0. (arXiv:2306.03551v1 [cs.AI])

    [http://arxiv.org/abs/2306.03551](http://arxiv.org/abs/2306.03551)

    本文探讨了将概念提取方法应用于工业4.0场景，并改进了可扩展性，提出了具有可解释性的新概念重要性计算程序，将局部特征与整体图像联系起来。

    

    工业4.0正在利用数字技术和机器学习技术来连接和优化制造过程。这一概念的核心在于将原始数据转化为可靠的数据驱动决策的人类可理解的知识。卷积神经网络（CNN）在处理图像数据方面发挥了重要作用，但是它们的“黑盒子”本质使得它们的预测过程难以理解。在这个背景下，解释性人工智能（XAI）领域的最新进展提出了概念的提取和定位，即视觉线索如何介入CNN的预测过程。本文探讨了将概念提取（CE）方法应用于工业4.0场景的问题。为此，我们修改了最近开发的技术“使用本地聚合描述符提取概念”（ECLAD），并改进了其可扩展性。具体而言，我们提出了一种新的概念重要性计算程序，利用加权平均来将局部特征与整体图像联系起来，改善ECLAD的性能。

    The industry 4.0 is leveraging digital technologies and machine learning techniques to connect and optimize manufacturing processes. Central to this idea is the ability to transform raw data into human understandable knowledge for reliable data-driven decision-making. Convolutional Neural Networks (CNNs) have been instrumental in processing image data, yet, their ``black box'' nature complicates the understanding of their prediction process. In this context, recent advances in the field of eXplainable Artificial Intelligence (XAI) have proposed the extraction and localization of concepts, or which visual cues intervene on the prediction process of CNNs. This paper tackles the application of concept extraction (CE) methods to industry 4.0 scenarios. To this end, we modify a recently developed technique, ``Extracting Concepts with Local Aggregated Descriptors'' (ECLAD), improving its scalability. Specifically, we propose a novel procedure for calculating concept importance, utilizing a w
    
[^16]: SDR-GAIN：一种用于自动驾驶的高实时遮挡行人姿态完成方法

    SDR-GAIN: A High Real-Time Occluded Pedestrian Pose Completion Method for Autonomous Driving. (arXiv:2306.03538v1 [cs.CV])

    [http://arxiv.org/abs/2306.03538](http://arxiv.org/abs/2306.03538)

    SDR-GAIN是一种用于解决行人姿态中部分遮挡问题的关键点补全方法，它通过对不完整的关键点进行降维，统一特征分布，并使用GAN框架的两种生成模型来完成姿态的补全。该方法的实验表明性能优于基本的GAIN框架。

    

    为了缓解基于人体姿态关键点的行人检测算法中部分遮挡带来的挑战，我们提出了一种称为分离和降维基于生成对抗性补全网络(SDR-GAIN)的新型行人姿势关键点补全方法。首先，我们利用OpenPose在图像中估计行人的姿态。然后，我们对由于遮挡或其他因素而不完整的行人头部和躯干关键点进行维度缩减，以增强特征并进一步统一特征分布。最后，我们引入了基于生成对抗网络(GAN)框架的两种生成模型，这些模型融合了Huber损失、残差结构和L1正则化来生成部分遮挡行人不完整头部和躯干姿态关键点的缺失部分，从而实现了姿态补全。我们在MS COCO和JAAD数据集上的实验表明，SDR-GAIN的性能优于基本的GAIN框架。

    To mitigate the challenges arising from partial occlusion in human pose keypoint based pedestrian detection methods , we present a novel pedestrian pose keypoint completion method called the separation and dimensionality reduction-based generative adversarial imputation networks (SDR-GAIN) . Firstly, we utilize OpenPose to estimate pedestrian poses in images. Then, we isolate the head and torso keypoints of pedestrians with incomplete keypoints due to occlusion or other factors and perform dimensionality reduction to enhance features and further unify feature distribution. Finally, we introduce two generative models based on the generative adversarial networks (GAN) framework, which incorporate Huber loss, residual structure, and L1 regularization to generate missing parts of the incomplete head and torso pose keypoints of partially occluded pedestrians, resulting in pose completion. Our experiments on MS COCO and JAAD datasets demonstrate that SDR-GAIN outperforms basic GAIN framework
    
[^17]: 浅谈测试时间适应的陷阱

    On Pitfalls of Test-Time Adaptation. (arXiv:2306.03536v1 [cs.LG])

    [http://arxiv.org/abs/2306.03536](http://arxiv.org/abs/2306.03536)

    这篇论文介绍了测试时间适应（TTA）最近被认为是解决在分布转移情况下鲁棒性挑战的一种很有前途的方法，提出了测试时间适应基准TTAB，并发现了之前方法中的三个常见缺陷。

    

    测试时间适应（TTA）最近被认为是解决在分布转移情况下鲁棒性挑战的一种很有前途的方法。然而，之前文献中缺乏一致的设置和系统性研究，这妨碍了现有方法的彻底评估。为了解决这个问题，我们提出了TTAB，一个测试时间适应基准，包括十种最先进的算法，多种不同的分布转移情况和两种评估协议。通过大量实验，我们的基准揭示了之前工作中的三个常见缺陷。首先，由于在线批次依赖性，选择适当的超参数，特别是模型选择，非常困难。其次，TTA的有效性因被适应的模型的质量和属性而有很大差异。第三，即使在最佳算法条件下，现有方法也不能解决所有常见类型的分布转移情况。我们的发现强调了未来研究测试时间适应技术及其一致和全面的评估协议的重要性。

    Test-Time Adaptation (TTA) has recently emerged as a promising approach for tackling the robustness challenge under distribution shifts. However, the lack of consistent settings and systematic studies in prior literature hinders thorough assessments of existing methods. To address this issue, we present TTAB, a test-time adaptation benchmark that encompasses ten state-of-the-art algorithms, a diverse array of distribution shifts, and two evaluation protocols. Through extensive experiments, our benchmark reveals three common pitfalls in prior efforts. First, selecting appropriate hyper-parameters, especially for model selection, is exceedingly difficult due to online batch dependency. Second, the effectiveness of TTA varies greatly depending on the quality and properties of the model being adapted. Third, even under optimal algorithmic conditions, none of the existing methods are capable of addressing all common types of distribution shifts. Our findings underscore the need for future r
    
[^18]: 冲突和不确定证据的信念模型——连接Dempster-Shafer理论和证据拓扑学

    A Belief Model for Conflicting and Uncertain Evidence -- Connecting Dempster-Shafer Theory and the Topology of Evidence. (arXiv:2306.03532v1 [cs.AI])

    [http://arxiv.org/abs/2306.03532](http://arxiv.org/abs/2306.03532)

    本文提出了一种基于Dempster-Shafer理论和证据拓扑模型的信念模型，可以更为普适地计算代理人的不同标准下的信念程度。

    

    在信息融合、决策和其他人工智能挑战的背景下，需要根据证据计算合理的信念。在现实生活中，这些证据可能不一致、不完整或不确定，使证据融合的问题非常复杂。在本文中，我们提出了一种基于可能不一致、不完整和不确定证据的测量信念程度的新模型，通过结合Dempster-Shafer理论和证据拓扑模型的工具。我们的信念模型比前述方法更为普适，它在两个重要方面比前述方法更优：（1）当适当的约束被施加时，它可以重现它们；（2）它足够灵活，可以根据代理人的证据要求计算信念的不同标准。后者的创新使得使用我们的模型的用户能够在代理人具有不同的正当化标准的情况下，基于同样的证据计算代理人的（可能）不同的信念程度。

    One problem to solve in the context of information fusion, decision-making, and other artificial intelligence challenges is to compute justified beliefs based on evidence. In real-life examples, this evidence may be inconsistent, incomplete, or uncertain, making the problem of evidence fusion highly non-trivial. In this paper, we propose a new model for measuring degrees of beliefs based on possibly inconsistent, incomplete, and uncertain evidence, by combining tools from Dempster-Shafer Theory and Topological Models of Evidence. Our belief model is more general than the aforementioned approaches in two important ways: (1) it can reproduce them when appropriate constraints are imposed, and, more notably, (2) it is flexible enough to compute beliefs according to various standards that represent agents' evidential demands. The latter novelty allows the users of our model to employ it to compute an agent's (possibly) distinct degrees of belief, based on the same evidence, in situations wh
    
[^19]: 拓展可解释性视野：一种统一的基于概念的系统用于局部、全局和错误分类解释。

    Expanding Explainability Horizons: A Unified Concept-Based System for Local, Global, and Misclassification Explanations. (arXiv:2306.03531v1 [cs.CV])

    [http://arxiv.org/abs/2306.03531](http://arxiv.org/abs/2306.03531)

    本文提出了一种新的统一的基于概念的系统，旨在解决当前基于概念的可解释性方法不足的局部、全局和错误分类解释问题，该系统可以自动学习、评分和提取局部和全局概念。

    

    近年来，智能模型的可解释性越来越受到关注。在各种可解释性方法中，基于概念的技术以利用一组人类可理解的概念为特点，而不是关注于单个像素。然而，很少有方法能够同时提供局部和全局解释，并能解释错误分类情况。为了解决这些挑战，我们提出了一种简单而有效的方法。我们提出一个统一的基于概念的系统，将多个超像素图像输入网络中，使其能够更好地学习目标对象以及目标概念的表示。该方法可以自动学习、评分和提取局部和全局概念。我们的实验证明，除了提高性能外，该模型还可以深入了解预测，并阐明错误分类。

    Explainability of intelligent models has been garnering increasing attention in recent years. Of the various explainability approaches, concept-based techniques are notable for utilizing a set of human-meaningful concepts instead of focusing on individual pixels. However, there is a scarcity of methods that consistently provide both local and global explanations. Moreover, most of the methods have no offer to explain misclassification cases. To address these challenges, our study follows a straightforward yet effective approach. We propose a unified concept-based system, which inputs a number of super-pixelated images into the networks, allowing them to learn better representations of the target's objects as well as the target's concepts. This method automatically learns, scores, and extracts local and global concepts. Our experiments revealed that, in addition to enhancing performance, the models could provide deeper insights into predictions and elucidate false classifications.
    
[^20]: BackpropTools: 一款快速、可移植的连续控制深度强化学习库

    BackpropTools: A Fast, Portable Deep Reinforcement Learning Library for Continuous Control. (arXiv:2306.03530v1 [cs.LG])

    [http://arxiv.org/abs/2306.03530](http://arxiv.org/abs/2306.03530)

    BackpropTools是一款快速、可移植的连续控制深度强化学习库，它通过模板元编程提供紧密集成的可组合组件，并在异构平台集合上无缝使用，同时在连续控制问题的深度RL代理高效可扩展训练方面具有优势。由于其可移植性和实时保证，它成为了在嵌入式设备上部署学来的策略的有价值的工具。

    

    深度强化学习在许多领域中已被证明可以产生出具有能力的代理和控制策略，但常常受到训练时间过长的困扰。此外，在连续控制问题的情况下，现有深度学习库的实时性和可移植性的缺乏限制了学习策略在实际嵌入式设备上的应用。为了解决这些问题，我们提出了BackpropTools，一种依赖性-free、header-only、pure C++的深度监督和强化学习库。利用最近C++标准的模板元编程能力，我们提供了可以由编译器紧密集成的可组合组件。其新颖的架构允许BackpropTools在异构平台集合上无缝使用，从HPC集群、工作站和笔记本电脑到智能手机、智能手表和微控制器。具体来说，由于RL算法与模拟环境的紧密集成，BackpropTools在连续控制问题的深度RL代理的高效可扩展训练方面具有优势。此外，它的可移植性和实时保证使其成为在嵌入式设备上部署学来的策略的有价值的工具。

    Deep Reinforcement Learning (RL) has been demonstrated to yield capable agents and control policies in several domains but is commonly plagued by prohibitively long training times. Additionally, in the case of continuous control problems, the applicability of learned policies on real-world embedded devices is limited due to the lack of real-time guarantees and portability of existing deep learning libraries. To address these challenges, we present BackpropTools, a dependency-free, header-only, pure C++ library for deep supervised and reinforcement learning. Leveraging the template meta-programming capabilities of recent C++ standards, we provide composable components that can be tightly integrated by the compiler. Its novel architecture allows BackpropTools to be used seamlessly on a heterogeneous set of platforms, from HPC clusters over workstations and laptops to smartphones, smartwatches, and microcontrollers. Specifically, due to the tight integration of the RL algorithms with simu
    
[^21]: 在车载虚拟现实中进行语义通信的对抗攻击和防御

    Adversarial Attacks and Defenses for Semantic Communication in Vehicular Metaverses. (arXiv:2306.03528v1 [cs.CR])

    [http://arxiv.org/abs/2306.03528](http://arxiv.org/abs/2306.03528)

    本文提出了一种层级式SemCom实现的车载虚拟现实框架，可以显著缓解车载虚拟现实应用程序的通信资源压力，并阐述了该框架中SemCom模块的安全风险和可行的防御方法。

    

    对于车载虚拟现实，优化从车上用户的沉浸式体验和服务质量是最终目标之一。语义通信（SemCom）被引入为一种革命性范例，可以显著缓解车载虚拟现实应用程序的通信资源压力，从而实现该目标。SemCom实现了高质量和超高效的车载通信，甚至在车辆之间的数据流量飞速增长时仍能如此。在本文中，我们提出了一个层级式SemCom实现的车载虚拟现实框架，包括全局虚拟现实、本地虚拟现实、SemCom模块和资源池。从分布角度考虑用户的服务质量，本文探讨了该框架的潜在安全漏洞。为了达到这个目的，本研究强调了该框架的SemCom模块的特定安全风险，并提供了一种可行的防御方法。

    For vehicular metaverses, one of the ultimate user-centric goals is to optimize the immersive experience and Quality of Service (QoS) for users on board. Semantic Communication (SemCom) has been introduced as a revolutionary paradigm that significantly eases communication resource pressure for vehicular metaverse applications to achieve this goal. SemCom enables high-quality and ultra-efficient vehicular communication, even with explosively increasing data traffic among vehicles. In this article, we propose a hierarchical SemCom-enabled vehicular metaverses framework consisting of the global metaverse, local metaverses, SemCom module, and resource pool. The global and local metaverses are brand-new concepts from the metaverse's distribution standpoint. Considering the QoS of users, this article explores the potential security vulnerabilities of the proposed framework. To that purpose, this study highlights a specific security risk to the framework's SemCom module and offers a viable de
    
[^22]: 具有全局约束的优先数据库中的不一致性处理：复杂度分析和与主动完整性约束的联系(arXiv:2306.03523v1 [cs.DB])

    Inconsistency Handling in Prioritized Databases with Universal Constraints: Complexity Analysis and Links with Active Integrity Constraints. (arXiv:2306.03523v1 [cs.DB])

    [http://arxiv.org/abs/2306.03523](http://arxiv.org/abs/2306.03523)

    本文研究解决了具有全局约束的不一致数据库的修复和查询问题，通过对称差分修复并指定首选修复行动，扩展了现有的最优修复概念，并且研究了修复概念的计算属性，同时澄清了与主动完整性约束框架中引入的修复概念之间的关系。

    

    本文重新审视了带有全局约束的不一致数据库的修复和查询问题。采用对称差分修复，即通过删除和添加事实来恢复一致性，并假设通过对（否定）事实的二元优先关系来指定首选修复行动。我们的第一个贡献是展示如何适当地将现有的最优修复概念（仅对基于事实删除的简单拒绝约束和修复定义）扩展到我们更丰富的设置中。接下来，我们研究了所得到的修复概念的计算属性，特别是修复检查和容忍不一致查询的数据复杂性。最后，我们澄清了优先数据库的最优修复与在主动完整性约束框架中引入的修复概念之间的关系。特别地，我们表明在我们的设置中的帕累托最优修复对应于 founded、grounded 和 just。

    This paper revisits the problem of repairing and querying inconsistent databases equipped with universal constraints. We adopt symmetric difference repairs, in which both deletions and additions of facts can be used to restore consistency, and suppose that preferred repair actions are specified via a binary priority relation over (negated) facts. Our first contribution is to show how existing notions of optimal repairs, defined for simpler denial constraints and repairs solely based on fact deletion, can be suitably extended to our richer setting. We next study the computational properties of the resulting repair notions, in particular, the data complexity of repair checking and inconsistency-tolerant query answering. Finally, we clarify the relationship between optimal repairs of prioritized databases and repair notions introduced in the framework of active integrity constraints. In particular, we show that Pareto-optimal repairs in our setting correspond to founded, grounded and just
    
[^23]: 知识图谱推理的逻辑扩散

    Logic Diffusion for Knowledge Graph Reasoning. (arXiv:2306.03515v1 [cs.LG])

    [http://arxiv.org/abs/2306.03515](http://arxiv.org/abs/2306.03515)

    该篇论文提出了一种名为逻辑扩散（LoD）的插件模块，解决了现有推理模型受训练样本限制、表现不够强的问题。LoD通过关系扩散、随机游走子逻辑采样和梯度自适应等方式实现了对未见查询的发现和不同模式之间的动态平衡，并配备了特殊的损失函数以实现稳健的逻辑扩散。

    

    最近的研究集中于回答一阶逻辑查询，通过多跳逻辑预测来探索知识图谱推理。然而，现有的推理模型受到训练样本所围绕的逻辑范式的限制，导致在未见逻辑推理上表现还不够强。为了解决这些问题，我们提出了一个名为逻辑扩散（LoD）的插件模块，能够从周围环境中发现未见查询，并实现不同模式之间的动态平衡。LoD的基本思想是关系扩散和随机游走子逻辑采样以及一种特殊的训练机制——梯度自适应。此外，LoD还配备了一种新颖的损失函数，以进一步在训练或测试集中应对嘈杂数据时实现稳健的逻辑扩散。在四个公共数据集上的大量实验证明，带有LoD的主流知识图谱推理模型优于最先进的模型。此外，我们的消融研究证明了逻辑扩散在克服现有推理模型的局限性和实现更好的未见逻辑推理方面的潜力。

    Most recent works focus on answering first order logical queries to explore the knowledge graph reasoning via multi-hop logic predictions. However, existing reasoning models are limited by the circumscribed logical paradigms of training samples, which leads to a weak generalization of unseen logic. To address these issues, we propose a plug-in module called Logic Diffusion (LoD) to discover unseen queries from surroundings and achieves dynamical equilibrium between different kinds of patterns. The basic idea of LoD is relation diffusion and sampling sub-logic by random walking as well as a special training mechanism called gradient adaption. Besides, LoD is accompanied by a novel loss function to further achieve the robust logical diffusion when facing noisy data in training or testing sets. Extensive experiments on four public datasets demonstrate the superiority of mainstream knowledge graph reasoning models with LoD over state-of-the-art. Moreover, our ablation study proves the gene
    
[^24]: Mega-TTS：具有内在归纳偏差的规模零样本TTS

    Mega-TTS: Zero-Shot Text-to-Speech at Scale with Intrinsic Inductive Bias. (arXiv:2306.03509v1 [eess.AS])

    [http://arxiv.org/abs/2306.03509](http://arxiv.org/abs/2306.03509)

    Mega-TTS是一种在大规模野外数据上训练的零样本TTS系统。它将语音分解成几个属性并分别使用具有适当归纳偏差的模块进行建模，包括使用频谱图作为中间特征、多说话人模型同时建模音色和韵律以及使用基于transformer的语言模型来模拟内容。实验结果表明，它在语音质量和说话人相似度指标方面显着优于先前的工作。

    

    将文本转语音扩展到大规模和混杂的数据集中已被证明在实现音色和语音风格通用性方面非常有效，特别是在零样本TTS中更是如此。然而，先前的工作通常使用音频编解码将语音编码成潜变量，并使用自回归语言模型或扩散模型来生成它，这忽略了语音的内在性质，可能导致结果劣质或不可控制。从这个角度出发，我们认为语音可以分解成几个属性（例如内容，音色，韵律和相位），每个属性都应该使用具有适当归纳偏差的模块进行建模。因此，我们精心设计了一种新的大规模零样本TTS系统Mega-TTS，使用大规模野外数据进行训练，并以不同的方式对不同的属性进行建模：1）我们仍然选择使用频谱图作为中间特征，而不是使用音频编解码编码的潜变量。频谱图非常好地分离了相位和其他属性。相位可以在训练中被适当地忽略，并在推理中添加回来以获得自然的语音。2）我们使用了一个多说话人模型同时建模音色和韵律，并避免过度拟合于特定说话人。3）我们使用了基于transformer的语言模型来模拟内容，它可以受益于现有的预训练技术，并处理文本的长程依赖。实验结果表明，我们的Mega-TTS在语音质量和说话人相似度指标方面显着优于先前的工作。

    Scaling text-to-speech to a large and wild dataset has been proven to be highly effective in achieving timbre and speech style generalization, particularly in zero-shot TTS. However, previous works usually encode speech into latent using audio codec and use autoregressive language models or diffusion models to generate it, which ignores the intrinsic nature of speech and may lead to inferior or uncontrollable results. We argue that speech can be decomposed into several attributes (e.g., content, timbre, prosody, and phase) and each of them should be modeled using a module with appropriate inductive biases. From this perspective, we carefully design a novel and large zero-shot TTS system called Mega-TTS, which is trained with large-scale wild data and models different attributes in different ways: 1) Instead of using latent encoded by audio codec as the intermediate feature, we still choose spectrogram as it separates the phase and other attributes very well. Phase can be appropriately 
    
[^25]: 基于子图网络的对比学习

    Subgraph Networks Based Contrastive Learning. (arXiv:2306.03506v1 [cs.LG])

    [http://arxiv.org/abs/2306.03506](http://arxiv.org/abs/2306.03506)

    本文提出了一种新的对比学习框架，名为基于子图网络的对比学习(SGNCL)，通过应用子图网络生成策略以产生增强视图，并探究了子结构相互作用对图形表示的影响。

    

    图对比学习(GCL)是一种自监督学习方法，可解决注释数据稀缺的问题。 它在未注释的图形中挖掘显式特征以生成下游任务的有利图形表示。大多数现有的GCL方法侧重于图形增强策略和相互信息估计操作的设计。 然而，这些方法没有考虑子图中存在的相互作用。为了探索子结构相互作用对图形表示的影响，我们提出了一种名为subgraph network-based contrastive learning (SGNCL)的新框架。SGNCL应用子图网络生成策略以产生增强视图。该策略将原始图转换为具有拓扑和属性特征的边到节点映射网络。单次增强视图是

    Graph contrastive learning (GCL), as a self-supervised learning method, can solve the problem of annotated data scarcity. It mines explicit features in unannotated graphs to generate favorable graph representations for downstream tasks. Most existing GCL methods focus on the design of graph augmentation strategies and mutual information estimation operations. Graph augmentation produces augmented views by graph perturbations. These views preserve a locally similar structure and exploit explicit features. However, these methods have not considered the interaction existing in subgraphs. To explore the impact of substructure interactions on graph representations, we propose a novel framework called subgraph network-based contrastive learning (SGNCL). SGNCL applies a subgraph network generation strategy to produce augmented views. This strategy converts the original graph into an Edge-to-Node mapping network with both topological and attribute features. The single-shot augmented view is a 
    
[^26]: 应用标准促进大型语言模型上下游伦理

    Applying Standards to Advance Upstream & Downstream Ethics in Large Language Models. (arXiv:2306.03503v1 [cs.CY])

    [http://arxiv.org/abs/2306.03503](http://arxiv.org/abs/2306.03503)

    本文探讨如何为AI生成的内容制定安全保障，分析LLMs的内容生成机制，确定了四个关键领域，提出了新的分发和销售LLM生成内容的企业的标准。

    

    本文探讨AI所有者如何借鉴其他内容创作行业的行为准则和伦理标准，为AI生成的内容制定安全保障。它深入研究了大型语言模型（LLMs）的伦理意识现状。通过分析LLMs的内容生成机制，确定了四个关键领域（上下游和用户提示/回答），在这些领域可以有效地应用保障措施。随后，对这四个领域进行了比较分析，包括在成本、有效性和与行业惯例的一致性方面评估现有的伦理保障措施。本文的主要观点是，现有的与IT相关的伦理准则虽然适用于传统的IT工程领域，但不足以应对基于LLMs内容生成所带来的挑战。我们借鉴新闻业内已有的实践，为分发和销售LLM生成内容的企业提出了潜在的标准。

    This paper explores how AI-owners can develop safeguards for AI-generated content by drawing from established codes of conduct and ethical standards in other content-creation industries. It delves into the current state of ethical awareness on Large Language Models (LLMs). By dissecting the mechanism of content generation by LLMs, four key areas (upstream/downstream and at user prompt/answer), where safeguards could be effectively applied, are identified. A comparative analysis of these four areas follows and includes an evaluation of the existing ethical safeguards in terms of cost, effectiveness, and alignment with established industry practices. The paper's key argument is that existing IT-related ethical codes, while adequate for traditional IT engineering, are inadequate for the challenges posed by LLM-based content generation. Drawing from established practices within journalism, we propose potential standards for businesses involved in distributing and selling LLM-generated cont
    
[^27]: 俄乌战争：预测和解释Twitter的封禁

    Russo-Ukrainian War: Prediction and explanation of Twitter suspension. (arXiv:2306.03502v1 [cs.SI])

    [http://arxiv.org/abs/2306.03502](http://arxiv.org/abs/2306.03502)

    本研究分析了Twitter封禁机制，揭示了存在的政策违规、宣传、垃圾邮件等问题，并发现拥有更多粉丝的账户更可能被封禁。这些发现可以让Twitter和其他社交网络改进其内容过滤机制。

    

    2022年2月24日，俄罗斯入侵乌克兰，开始了现在已知的俄乌战争，并在社交媒体上引发了在线话语。Twitter作为最受欢迎的社交网络之一，以其开放和民主的特点，在其庞大的用户群中实现了透明的讨论。不幸的是，这往往会导致Twitter的政策违规、宣传、滥用行为、侵犯公民权利，因此导致用户账户被封禁和删除。本研究着重探讨了Twitter的封禁机制，并分析了可能导致账户被封禁的共享内容和用户账户的特征。为此，我们利用Twitter API获得了包含107.7M条推文的数据集，来自980万用户。我们提取了被封禁账户的共享内容类别，并通过提取文本嵌入和余弦相似性聚类来解释其特征。我们的研究结果揭示了一些滥用Twitter政策标准的骗子活动、垃圾邮件和宣传活动。此外，我们发现相对于粉丝数较少的账户，拥有更多粉丝的账户更有可能被封禁。这些发现可以为Twitter和其他社交网络改进其内容过滤机制，最小化有害内容的传播提供有用的参考。

    On 24 February 2022, Russia invaded Ukraine, starting what is now known as the Russo-Ukrainian War, initiating an online discourse on social media. Twitter as one of the most popular SNs, with an open and democratic character, enables a transparent discussion among its large user base. Unfortunately, this often leads to Twitter's policy violations, propaganda, abusive actions, civil integrity violation, and consequently to user accounts' suspension and deletion. This study focuses on the Twitter suspension mechanism and the analysis of shared content and features of the user accounts that may lead to this. Toward this goal, we have obtained a dataset containing 107.7M tweets, originating from 9.8 million users, using Twitter API. We extract the categories of shared content of the suspended accounts and explain their characteristics, through the extraction of text embeddings in junction with cosine similarity clustering. Our results reveal scam campaigns taking advantage of trending top
    
[^28]: 量子机器学习中纠缠数据的转换作用

    Transition role of entangled data in quantum machine learning. (arXiv:2306.03481v1 [quant-ph])

    [http://arxiv.org/abs/2306.03481](http://arxiv.org/abs/2306.03481)

    本研究证明了纠缠数据对量子机器学习的性能具有双重效应，有助于减少预测误差和减小训练数据大小，为量子机器学习模型设计提供了指南。

    

    纠缠作为增强量子计算的资源，已经在学习量子动力学中得到了应用。将纠缠融入到量子机器学习模型的操作或测量中，可以显著降低训练数据大小，同时在达到指定预测误差阈值时取得了更优的结果。然而，关于纠缠程度对模型性能的影响，目前仍缺乏分析性理解。本研究通过在学习量子动力学中使用纠缠数据，建立了量子不免费午餐定理。与以往发现的结果相反，我们证明了纠缠数据对预测误差的影响呈现出双重效应，取决于允许的测量次数。在有充分的测量次数的情况下，增加训练数据的纠缠度可以持续降低预测误差，或减少达到给定误差阈值所需的训练数据大小。本研究阐明了纠缠数据在量子机器学习中的关键转换作用，并提供了改进性能的量子机器学习模型设计指南。

    Entanglement serves as the resource to empower quantum computing. Recent progress has highlighted its positive impact on learning quantum dynamics, wherein the integration of entanglement into quantum operations or measurements of quantum machine learning (QML) models leads to substantial reductions in training data size, surpassing a specified prediction error threshold. However, an analytical understanding of how the entanglement degree in data affects model performance remains elusive. In this study, we address this knowledge gap by establishing a quantum no-free-lunch (NFL) theorem for learning quantum dynamics using entangled data. Contrary to previous findings, we prove that the impact of entangled data on prediction error exhibits a dual effect, depending on the number of permitted measurements. With a sufficient number of measurements, increasing the entanglement of training data consistently reduces the prediction error or decreases the required size of the training data to ac
    
[^29]: GSHOT: 少样本标记图生成建模

    GSHOT: Few-shot Generative Modeling of Labeled Graphs. (arXiv:2306.03480v1 [cs.LG])

    [http://arxiv.org/abs/2306.03480](http://arxiv.org/abs/2306.03480)

    GSHOT是一个用于少样本标记图生成建模的元学习框架，通过学习从类似的辅助图数据集中转移元知识，从而快速适应未见过的图数据集。

    

    近年来，深度图生成建模因其直接学习潜在隐藏图分布的惊人能力而受到极大关注。尽管这些技术最初取得了成功，但像许多现有的深度生成方法一样，需要大量的训练样本才能学习一个好的模型。不幸的是，在罕见疾病的药物发现等场景中，可能不总是有足够的训练样本可用。同时，最近少样本学习的进展为训练数据有限的应用打开了大门。本文介绍了少样本图生成建模这一迄今未曾探索的范式。为此，我们开发了GSHOT，一个基于元学习的框架，用于少样本标记图生成建模。GSHOT学习从类似的辅助图数据集中转移元知识。利用这些先前的经验，GSHOT通过自适应的自我调整快速适应未见过的图数据集。

    Deep graph generative modeling has gained enormous attraction in recent years due to its impressive ability to directly learn the underlying hidden graph distribution. Despite their initial success, these techniques, like much of the existing deep generative methods, require a large number of training samples to learn a good model. Unfortunately, large number of training samples may not always be available in scenarios such as drug discovery for rare diseases. At the same time, recent advances in few-shot learning have opened door to applications where available training data is limited. In this work, we introduce the hitherto unexplored paradigm of few-shot graph generative modeling. Towards this, we develop GSHOT, a meta-learning based framework for few-shot labeled graph generative modeling. GSHOT learns to transfer meta-knowledge from similar auxiliary graph datasets. Utilizing these prior experiences, GSHOT quickly adapts to an unseen graph dataset through self-paced fine-tuning. 
    
[^30]: 基于音韵学的语言生成：以绕口令为例

    Phonetically-Grounded Language Generation: The Case of Tongue Twisters. (arXiv:2306.03457v1 [cs.CL])

    [http://arxiv.org/abs/2306.03457](http://arxiv.org/abs/2306.03457)

    本文介绍了针对绕口令生成的基于音韵学的语言生成任务，提供了TwistList数据集和TwisterMisters基准系统，并验证了预训练模型在没有任务特定数据和显式音韵知识的情况下的良好性能。

    

    先前的音韵学语言生成主要集中在词歌和诗歌等领域。本文介绍了围绕绕口令生成展开的工作，绕口令需要在保持语义正确性的同时，最大化音频重叠并保持语法正确。我们提供了TwistList，一个包含超过2.1K人工编写的绕口令的大型注释数据集。此外，我们针对绕口令生成提出了一些基准系统(TwisterMisters)，包括需要和不需要在域内数据上进行训练的模型。我们使用自动和人工评估的结果来证明现有主流预训练模型在此任务中性能优良，即使在没有任务特定训练数据和显式音韵知识的情况下。我们发现，绕口令生成的任务是有挑战性的。

    Previous work in phonetically-grounded language generation has mainly focused on domains such as lyrics and poetry. In this paper, we present work on the generation of tongue twisters - a form of language that is required to be phonetically conditioned to maximise sound overlap, whilst maintaining semantic consistency with an input topic, and still being grammatically correct. We present \textbf{TwistList}, a large annotated dataset of tongue twisters, consisting of 2.1K+ human-authored examples. We additionally present several benchmark systems (referred to as TwisterMisters) for the proposed task of tongue twister generation, including models that both do and do not require training on in-domain data. We present the results of automatic and human evaluation to demonstrate the performance of existing mainstream pre-trained models in this task with limited (or no) task specific training and data, and no explicit phonetic knowledge. We find that the task of tongue twister generation is 
    
[^31]: GRAFENNE：在具有异质和动态特征集的图上进行学习

    GRAFENNE: Learning on Graphs with Heterogeneous and Dynamic Feature Sets. (arXiv:2306.03447v1 [cs.LG])

    [http://arxiv.org/abs/2306.03447](http://arxiv.org/abs/2306.03447)

    GRAFENNE是一种新的图神经网络框架，通过在原图上进行异构转化，将节点和特征解耦，解决了现有方法普遍存在的特征静态、转移误差等问题，并且能适用于未知节点和特征。

    

    图神经网络（GNN）通常基于对图中每个节点的静态特征集的假设来构建。然而在实践中这一假设经常被违反，现有方法通过特征插补部分解决了这个问题，但是这些方法存在特征集均一、转移误差、无法适应动态特征等局限。本文提出了一种新的GNN框架GRAFENNE来应对这些限制，通过在原图上进行异构转化，将节点和特征解耦，通过精心设计的信息传递方法使得模型参数大小与特征数量无关，能够适用于未知节点和特征。我们证明了GRAFENNE在Weisfeil方程性能上至少与现有的信息传递GNN一样具有表现力。

    Graph neural networks (GNNs), in general, are built on the assumption of a static set of features characterizing each node in a graph. This assumption is often violated in practice. Existing methods partly address this issue through feature imputation. However, these techniques (i) assume uniformity of feature set across nodes, (ii) are transductive by nature, and (iii) fail to work when features are added or removed over time. In this work, we address these limitations through a novel GNN framework called GRAFENNE. GRAFENNE performs a novel allotropic transformation on the original graph, wherein the nodes and features are decoupled through a bipartite encoding. Through a carefully chosen message passing framework on the allotropic transformation, we make the model parameter size independent of the number of features and thereby inductive to both unseen nodes and features. We prove that GRAFENNE is at least as expressive as any of the existing message-passing GNNs in terms of Weisfeil
    
[^32]: MetaGait：学习学习步态识别的全样本自适应表示

    MetaGait: Learning to Learn an Omni Sample Adaptive Representation for Gait Recognition. (arXiv:2306.03445v1 [cs.CV])

    [http://arxiv.org/abs/2306.03445](http://arxiv.org/abs/2306.03445)

    本文开发了MetaGait技术来学习全样本自适应表示，通过注入元知识到校准网络中，从全尺度、全维度和全过程的角度改善了模型的适应性。

    

    步态识别旨在通过个体的行走模式识别其身份，近年来受到越来越多的研究关注。然而，步态识别仍面临着轮廓的有限二进制视觉线索和众多尺度不同的协变量之间的冲突，这给模型的适应性带来了挑战。本文通过开发一种新的MetaGait技术来解决这一冲突，该技术学习学习全样本自适应表示。为实现这一目标，MetaGait将元知识注入到注意机制的校准网络中，从全样本自适应性的全尺度、全维度和全过程的角度改善了模型的适应性。具体而言，我们跨越整个过程利用了元知识，分别提出了Meta Triple Attention和Meta Temporal Pooling来自适应地捕捉空间/通道/时间维度的全尺度依赖关系。

    Gait recognition, which aims at identifying individuals by their walking patterns, has recently drawn increasing research attention. However, gait recognition still suffers from the conflicts between the limited binary visual clues of the silhouette and numerous covariates with diverse scales, which brings challenges to the model's adaptiveness. In this paper, we address this conflict by developing a novel MetaGait that learns to learn an omni sample adaptive representation. Towards this goal, MetaGait injects meta-knowledge, which could guide the model to perceive sample-specific properties, into the calibration network of the attention mechanism to improve the adaptiveness from the omni-scale, omni-dimension, and omni-process perspectives. Specifically, we leverage the meta-knowledge across the entire process, where Meta Triple Attention and Meta Temporal Pooling are presented respectively to adaptively capture omni-scale dependency from spatial/channel/temporal dimensions simultaneo
    
[^33]: 代码大语言模型在填写可能存在漏洞的代码时存在失败问题

    Large Language Models of Code Fail at Completing Code with Potential Bugs. (arXiv:2306.03438v1 [cs.LG])

    [http://arxiv.org/abs/2306.03438](http://arxiv.org/abs/2306.03438)

    本研究探讨了存在漏洞的代码补全问题，设计了两个数据集并发现这些漏洞显著降低了Code-LLMs的生成性能。

    

    最近，代码大语言模型（Code-LLMs）在代码补全方面取得了巨大进展，这是编程辅助和代码智能的基本功能。然而，大多数现有的研究忽略了在生成过程中代码上下文中可能存在的漏洞问题，在软件开发中这是不可避免的。因此，我们引入并研究了存在漏洞的代码补全问题，受实时代码建议的现实场景启发，代码上下文中包含可能的漏洞-反模式，这些反模式可以成为完成程序中的漏洞。为了系统地研究任务，我们引入了两个数据集：一个是从语义改变操作中派生的合成漏洞数据集（buggy-HumanEval），另一个是从用户提交的编程问题中派生的现实漏洞数据集（buggy-FixEval）。我们发现，可能存在漏洞的情况显著降低了高性能Code-LLMs的生成性能。例如，CodeGen-2B-mono在测试数据集上的通过率

    Large language models of code (Code-LLMs) have recently brought tremendous advances to code completion, a fundamental feature of programming assistance and code intelligence. However, most existing works ignore the possible presence of bugs in the code context for generation, which are inevitable in software development. Therefore, we introduce and study the buggy-code completion problem, inspired by the realistic scenario of real-time code suggestion where the code context contains potential bugs -- anti-patterns that can become bugs in the completed program. To systematically study the task, we introduce two datasets: one with synthetic bugs derived from semantics-altering operator changes (buggy-HumanEval) and one with realistic bugs derived from user submissions to coding problems (buggy-FixEval). We find that the presence of potential bugs significantly degrades the generation performance of the high-performing Code-LLMs. For instance, the passing rates of CodeGen-2B-mono on test 
    
[^34]: 我害怕我做不到：预测黑匣子生成语言模型中的提示拒绝行为

    I'm Afraid I Can't Do That: Predicting Prompt Refusal in Black-Box Generative Language Models. (arXiv:2306.03423v1 [cs.AI])

    [http://arxiv.org/abs/2306.03423](http://arxiv.org/abs/2306.03423)

    本文研究了生成语言模型的拒绝行为，并发现这种行为不是完全二元的。作者对ChatGPT进行的实验表明，在微调过程中的偏见来自于个别工程师和公司政策，并影响模型选择拒绝哪些提示。

    

    自从OpenAI的ChatGPT发布以来，生成语言模型引起了广泛关注。增加的使用量凸显了生成模型的广泛实用性，但同时也揭示了一些嵌入式偏见。其中一些是由预训练语料库引起的；但是，针对生成模型的额外偏见来自于主观微调以避免生成有害内容。微调偏见可能来自个别工程师和公司政策，并影响模型选择拒绝哪些提示。本实验使用黑盒攻击，对ChatGPT的拒绝行为进行了表征。我们首先使用各种攻击性和良性提示（n = 1,730）查询ChatGPT，然后手动标记每个响应是否履行或拒绝。响应的手动检查表明，拒绝不是完全二元的，并且在连续的范围内；因此，我们将几种不同类型的响应映射到履行或拒绝的二元值中。使用了小型手动标记的数据集。

    Since the release of OpenAI's ChatGPT, generative language models have attracted extensive public attention. The increased usage has highlighted generative models' broad utility, but also revealed several forms of embedded bias. Some is induced by the pre-training corpus; but additional bias specific to generative models arises from the use of subjective fine-tuning to avoid generating harmful content. Fine-tuning bias may come from individual engineers and company policies, and affects which prompts the model chooses to refuse. In this experiment, we characterize ChatGPT's refusal behavior using a black-box attack. We first query ChatGPT with a variety of offensive and benign prompts (n=1,730), then manually label each response as compliance or refusal. Manual examination of responses reveals that refusal is not cleanly binary, and lies on a continuum; as such, we map several different kinds of responses to a binary of compliance or refusal. The small manually-labeled dataset is used 
    
[^35]: DreamSparse: 利用 2D 扩散模型从稀疏视角中合成图像

    DreamSparse: Escaping from Plato's Cave with 2D Diffusion Model Given Sparse Views. (arXiv:2306.03414v1 [cs.CV])

    [http://arxiv.org/abs/2306.03414](http://arxiv.org/abs/2306.03414)

    本文提出了 DreamSparse 框架，该框架通过利用先前训练的扩散模型的 2D 先验知识，通过几何模块和空间引导模型来解决 2D 模型缺乏 3D 感知能力的问题，进一步实现了从少视角情况下合成高质量的新视角图像。

    

    从少量视角中合成新的图像是一个具有挑战性但实际的问题。现有方法通常难以产生高质量的结果或在此类少视角设置中需要逐个对象优化，因为提供的信息不足。在这项工作中，我们探索利用预先训练的扩散模型的强大的 2D 先验知识，来合成新颖的视角图像。然而，2D 扩散模型缺乏 3D 感知能力，导致图像合成失真，影响了图像的识别性。为了解决这些问题，我们提出了 DreamSparse，一个可以生成几何和识别联合一致的新视角图像的框架。具体而言，DreamSparse 包括一个几何模块，用于从稀疏视角获取 3D 特征作为 3D 先验，随后引入一个空间引导模型将这些 3D 特征图转换为生成过程的空间信息。这些信息然后用于通过对抗损失指导预训练扩散模型合成高质量的新视角图像。实验结果显示，DreamSparse 在少视角图像合成方面取得了最先进的结果，并且可以生成准确和稳健的物体几何和识别。

    Synthesizing novel view images from a few views is a challenging but practical problem. Existing methods often struggle with producing high-quality results or necessitate per-object optimization in such few-view settings due to the insufficient information provided. In this work, we explore leveraging the strong 2D priors in pre-trained diffusion models for synthesizing novel view images. 2D diffusion models, nevertheless, lack 3D awareness, leading to distorted image synthesis and compromising the identity. To address these problems, we propose DreamSparse, a framework that enables the frozen pre-trained diffusion model to generate geometry and identity-consistent novel view image. Specifically, DreamSparse incorporates a geometry module designed to capture 3D features from sparse views as a 3D prior. Subsequently, a spatial guidance model is introduced to convert these 3D feature maps into spatial information for the generative process. This information is then used to guide the pre-
    
[^36]: 商品搜索中的意图感知FAQ检索：生成-检索方法

    Generate-then-Retrieve: Intent-Aware FAQ Retrieval in Product Search. (arXiv:2306.03411v1 [cs.CL])

    [http://arxiv.org/abs/2306.03411](http://arxiv.org/abs/2306.03411)

    本研究提出了一种意图感知FAQ检索系统，它集成在商品搜索中，可以通过意图分类器和重构模型，提高了检索的精度和效率。

    

    与商品搜索引擎交互的客户越来越多地制定信息查询请求。常问问题（FAQ）检索旨在通过问题意图来检索用户查询的常见问题-答案对。将FAQ检索与商品搜索集成在一起，不仅可以使用户做出更明智的购买决策，还可以通过高效的售后支持增强用户保留率。在商品搜索中确定何时可以满足用户的信息需求的FAQ条目，而不会打扰其购物体验，是一个重要的挑战。我们提出了一个意图感知FAQ检索系统，其中包括（1）一个意图分类器，用于预测FAQ是否能够回答用户的问题；（2）一个重构模型，可以将查询重写为自然问题。离线评估表明，与基线系统相比，我们的方法在检索基准FAQ时将Hit @ 1提高了13％，同时将延迟降低了95％。这些改进结果说明了我们所提出的意图感知FAQ检索系统的有效性。

    Customers interacting with product search engines are increasingly formulating information-seeking queries. Frequently Asked Question (FAQ) retrieval aims to retrieve common question-answer pairs for a user query with question intent. Integrating FAQ retrieval in product search can not only empower users to make more informed purchase decisions, but also enhance user retention through efficient post-purchase support. Determining when an FAQ entry can satisfy a user's information need within product search, without disrupting their shopping experience, represents an important challenge. We propose an intent-aware FAQ retrieval system consisting of (1) an intent classifier that predicts when a user's information need can be answered by an FAQ; (2) a reformulation model that rewrites a query into a natural question. Offline evaluation demonstrates that our approach improves Hit@1 by 13% on retrieving ground-truth FAQs, while reducing latency by 95% compared to baseline systems. These impr
    
[^37]: 对于求解多目标最小权重基问题的MOEA/D的严格运行时分析

    Rigorous Runtime Analysis of MOEA/D for Solving Multi-Objective Minimum Weight Base Problems. (arXiv:2306.03409v1 [cs.AI])

    [http://arxiv.org/abs/2306.03409](http://arxiv.org/abs/2306.03409)

    该论文提出了一种适用于多目标问题的进化算法MOEA/D，并且给出了针对该算法的严格运行时分析，证明在相应条件下MOEA/D的时间复杂度在oracle模型中可以以期望的固定多项式时间完成。在随机的实例中进行的实验结果证明了理论分析的正确性。

    

    我们研究了多目标最小权重基问题，这是经典的NP难题组合优化问题（如多目标最小生成树问题）的一个抽象。我们证明了一些非支配前沿的凸包重要性质，例如其逼近质量和极点数量的上界。利用这些性质，我们针对该问题给出了MOEA/D算法的首个运行时分析，这是一种将多目标分解为单目标组成部分并有效优化的进化算法。我们证明，在给定适当分解设置的情况下，MOEA/D能以期望的固定多项式时间在oracle模型中找到所有极点，参数是目标的数量。我们在随机的双目标最小生成树实例上进行了实验，结果与我们的理论发现一致。此外，与先前针对GSEMO问题研究的进化算法相比较，...

    We study the multi-objective minimum weight base problem, an abstraction of classical NP-hard combinatorial problems such as the multi-objective minimum spanning tree problem. We prove some important properties of the convex hull of the non-dominated front, such as its approximation quality and an upper bound on the number of extreme points. Using these properties, we give the first run-time analysis of the MOEA/D algorithm for this problem, an evolutionary algorithm that effectively optimizes by decomposing the objectives into single-objective components. We show that the MOEA/D, given an appropriate decomposition setting, finds all extreme points within expected fixed-parameter polynomial time in the oracle model, the parameter being the number of objectives. Experiments are conducted on random bi-objective minimum spanning tree instances, and the results agree with our theoretical findings. Furthermore, compared with a previously studied evolutionary algorithm for the problem GSEMO,
    
[^38]: 智能体通过探索决策树中的状态来提高其决策模型的性能

    Agents Explore the Environment Beyond Good Actions to Improve Their Model for Better Decisions. (arXiv:2306.03408v1 [cs.AI])

    [http://arxiv.org/abs/2306.03408](http://arxiv.org/abs/2306.03408)

    通过探索未被访问的决策树状态和引入随机性，MuZero智能体改进了树搜索规划和模型预测之间的不一致性，提高了决策能力。

    

    提高智能体决策能力是人工智能发展道路上的一个关键挑战。MuZero智能体通过网络模型的预测和基于预测结果的树搜索规划相结合来提高规划技能，但当模型预测结果不准确时，学习进程可能会遇到瓶颈。我们通过让智能体探索环境中决策树中一些不会被访问到的状态来改进模型的性能。具体而言，智能体首先通过规划得到改进策略，然后在每个训练阶段的开始时随机偏离这个策略。在一个随机的时间阶段，智能体将又恢复到改进策略以得到环境奖励并对期望价值进行学习。我们在井字棋游戏中展示了该方法对智能体性能的提升。

    Improving the decision-making capabilities of agents is a key challenge on the road to artificial intelligence. To improve the planning skills needed to make good decisions, MuZero's agent combines prediction by a network model and planning by a tree search using the predictions. MuZero's learning process can fail when predictions are poor but planning requires them. We use this as an impetus to get the agent to explore parts of the decision tree in the environment that it otherwise would not explore. The agent achieves this, first by normal planning to come up with an improved policy. Second, it randomly deviates from this policy at the beginning of each training episode. And third, it switches back to the improved policy at a random time step to experience the rewards from the environment associated with the improved policy, which is the basis for learning the correct value expectation. The simple board game Tic-Tac-Toe is used to illustrate how this approach can improve the agent's 
    
[^39]: 从流形学习的角度分析深度神经网络结构

    Deep neural networks architectures from the perspective of manifold learning. (arXiv:2306.03406v1 [cs.LG])

    [http://arxiv.org/abs/2306.03406](http://arxiv.org/abs/2306.03406)

    本文从几何学和拓扑学的角度，使用拓扑数据分析和持久同调分形维度对神经网络体系结构进行全面比较和描述，旨在为可解释和可解释的人工智能的发展做出贡献。

    

    虽然深度学习在各个领域得到了显著进展，但神经网络模型的学习过程仍是一个重要的开放问题。本文旨在从几何学和拓扑学的角度全面比较和描述神经网络体系结构。我们关注神经网络的内部表示以及在不同层上数据流形的拓扑和几何结构的动态变化。在本文中，我们使用了拓扑数据分析（TDA）和持久同调分形维度的概念。我们使用各种数据集和卷积神经网络（CNN）结构以及在计算机视觉和自然语言处理任务中使用的变压器进行了广泛的实验。我们的工作是在几何深度学习的框架内为可解释和可解释的人工智能的发展做出贡献。

    Despite significant advances in the field of deep learning in ap-plications to various areas, an explanation of the learning pro-cess of neural network models remains an important open ques-tion. The purpose of this paper is a comprehensive comparison and description of neural network architectures in terms of ge-ometry and topology. We focus on the internal representation of neural networks and on the dynamics of changes in the topology and geometry of a data manifold on different layers. In this paper, we use the concepts of topological data analysis (TDA) and persistent homological fractal dimension. We present a wide range of experiments with various datasets and configurations of convolutional neural network (CNNs) architectures and Transformers in CV and NLP tasks. Our work is a contribution to the development of the important field of explainable and interpretable AI within the framework of geometrical deep learning.
    
[^40]: SGAT4PASS：面向球面几何意识的全景语义分割Transformer

    SGAT4PASS: Spherical Geometry-Aware Transformer for PAnoramic Semantic Segmentation. (arXiv:2306.03403v1 [cs.CV])

    [http://arxiv.org/abs/2306.03403](http://arxiv.org/abs/2306.03403)

    本论文提出了SGAT4PASS，一种面向球面几何意识的全景语义分割Transformer，通过加入球面几何感知的约束，能更好地捕捉全景图像的3D属性，从而提高分割性能。

    

    作为计算机视觉中一个重要且具有挑战性的问题，全景语义分割可以根据超广角观察到的完整场景来进行感知。传统的针对2D全景图像的PASS方法侧重于解决图像畸变问题，但缺乏对原始360°数据的3D属性的考虑。因此，当输入具有3D扰动的全景图像时，它们的性能会大幅下降。为了更好地应对3D扰动，我们提出了一种面向球面几何意识的全景语义分割Transformer，即SGAT4PASS。具体来说，我们提出了一个球面几何意识的分割框架，它包括三个模块，即球面几何感知图像投影，球面可形变补丁嵌入和全景感知损失，它对具有3D扰动的输入图像进行处理，并对已有的可形变补丁嵌入加入了球面几何感知的约束。

    As an important and challenging problem in computer vision, PAnoramic Semantic Segmentation (PASS) gives complete scene perception based on an ultra-wide angle of view. Usually, prevalent PASS methods with 2D panoramic image input focus on solving image distortions but lack consideration of the 3D properties of original $360^{\circ}$ data. Therefore, their performance will drop a lot when inputting panoramic images with the 3D disturbance. To be more robust to 3D disturbance, we propose our Spherical Geometry-Aware Transformer for PAnoramic Semantic Segmentation (SGAT4PASS), considering 3D spherical geometry knowledge. Specifically, a spherical geometry-aware framework is proposed for PASS. It includes three modules, i.e., spherical geometry-aware image projection, spherical deformable patch embedding, and a panorama-aware loss, which takes input images with 3D disturbance into account, adds a spherical geometry-aware constraint on the existing deformable patch embedding, and indicates
    
[^41]: G-CAME: 面向目标检测的高斯类激活映射解释器

    G-CAME: Gaussian-Class Activation Mapping Explainer for Object Detectors. (arXiv:2306.03400v1 [cs.CV])

    [http://arxiv.org/abs/2306.03400](http://arxiv.org/abs/2306.03400)

    G-CAME 提出了一种面向目标检测的高斯类激活映射解释器，通过使用激活映射与高斯核生成显著性图来突出显示图像中与预测框相关的重要区域，具有很短时间解释对象等优点。

    

    当今，图像目标检测的深度神经网络非常普及。然而，由于这些网络的复杂性，用户很难理解模型为什么会检测出这些对象。我们提出了高斯类激活映射解释器（G-CAME），它生成显著性图作为目标检测模型的说明。 G-CAME 可以被认为是一种基于 CAM 的方法，它使用选择层的激活映射与高斯核来突出显示图像中与预测框相关的重要区域。与其他基于区域的方法相比，G-CAME 可以超越时间限制，因为它只需要很短时间就能解释一个对象。我们还在 MS-COCO 2017 数据集上使用 YOLOX 定量和定性地评估了我们的方法，并指导将 G-CAME 应用于两阶段 Faster-RCNN 模型。

    Nowadays, deep neural networks for object detection in images are very prevalent. However, due to the complexity of these networks, users find it hard to understand why these objects are detected by models. We proposed Gaussian Class Activation Mapping Explainer (G-CAME), which generates a saliency map as the explanation for object detection models. G-CAME can be considered a CAM-based method that uses the activation maps of selected layers combined with the Gaussian kernel to highlight the important regions in the image for the predicted box. Compared with other Region-based methods, G-CAME can transcend time constraints as it takes a very short time to explain an object. We also evaluated our method qualitatively and quantitatively with YOLOX on the MS-COCO 2017 dataset and guided to apply G-CAME into the two-stage Faster-RCNN model.
    
[^42]: ColdNAS: 搜索以调节为用户冷启动推荐

    ColdNAS: Search to Modulate for User Cold-Start Recommendation. (arXiv:2306.03387v1 [cs.AI])

    [http://arxiv.org/abs/2306.03387](http://arxiv.org/abs/2306.03387)

    本研究提出了一个调节框架ColdNAS来解决用户冷启动问题，通过神经架构搜索寻找适当的调节结构，包括函数和位置。

    

    在推荐系统中，为冷启动用户(只有一些交互历史)进行个性化推荐是一个具有挑战性的问题。 最近的研究利用超网络将用户交互历史直接映射到用户特定参数，然后使用特性线性调制函数来调制预测器。 这些研究取得了最先进的性能。 然而，缩放和移位在推荐数据中的物理含义是不清楚的。 我们提出了一个调节框架ColdNAS来解决用户冷启动问题，该框架通过神经架构搜索寻找适当的调节结构，包括函数和位置。 我们设计了一个搜索空间，涵盖广泛的模型，并从理论上证明，该搜索空间可以转换为一个更小的空间，从而实现高效且鲁棒的一次搜索算法。

    Making personalized recommendation for cold-start users, who only have a few interaction histories, is a challenging problem in recommendation systems. Recent works leverage hypernetworks to directly map user interaction histories to user-specific parameters, which are then used to modulate predictor by feature-wise linear modulation function. These works obtain the state-of-the-art performance. However, the physical meaning of scaling and shifting in recommendation data is unclear. Instead of using a fixed modulation function and deciding modulation position by expertise, we propose a modulation framework called ColdNAS for user cold-start problem, where we look for proper modulation structure, including function and position, via neural architecture search. We design a search space which covers broad models and theoretically prove that this search space can be transformed to a much smaller space, enabling an efficient and robust one-shot search algorithm. Extensive experimental resul
    
[^43]: VR.net：用于虚拟现实晕动研究的现实世界数据集

    VR.net: A Real-world Dataset for Virtual Reality Motion Sickness Research. (arXiv:2306.03381v1 [cs.AI])

    [http://arxiv.org/abs/2306.03381](http://arxiv.org/abs/2306.03381)

    VR.net是一个用于虚拟现实晕动研究的现实世界数据集，在10个不同风格的游戏中提供了大约12小时的游戏玩法视频，以及与晕动相关的标签。可以用于风险因素检测和晕动水平预测等应用程序。

    

    研究人员已经使用机器学习方法在VR体验中识别晕动。这些方法需要一个精确标记、现实世界和多样化的数据集，以实现高精度和普适性。为了解决这一需求，我们介绍了“VR.net”，这是一个数据集，提供了来自10种不同风格的10种现实世界游戏中约12个小时的游戏玩法视频。对于每个视频帧，精准地分配了一组与晕动相关的标签，如相机/物体运动、深度场和运动流。构建这样一个数据集是具有挑战性的，因为手动标记需要不可行的时间。相反，我们利用一个工具从3D引擎的渲染管道中自动精确地提取地面真实数据，而无需访问VR游戏的源代码。我们通过几个应用程序展示了VR.net的实用性，如风险因素检测和晕动水平预测。我们不断扩展VR.net，并希望其下一个版本提供更多的数据。

    Researchers have used machine learning approaches to identify motion sickness in VR experience. These approaches demand an accurately-labeled, real-world, and diverse dataset for high accuracy and generalizability. As a starting point to address this need, we introduce `VR.net', a dataset offering approximately 12-hour gameplay videos from ten real-world games in 10 diverse genres. For each video frame, a rich set of motion sickness-related labels, such as camera/object movement, depth field, and motion flow, are accurately assigned. Building such a dataset is challenging since manual labeling would require an infeasible amount of time. Instead, we utilize a tool to automatically and precisely extract ground truth data from 3D engines' rendering pipelines without accessing VR games' source code. We illustrate the utility of VR.net through several applications, such as risk factor detection and sickness level prediction. We continuously expand VR.net and envision its next version offeri
    
[^44]: 使用图像-语言基础模型在人类大脑中识别共享的可解码概念

    Identifying Shared Decodable Concepts in the Human Brain Using Image-Language Foundation Models. (arXiv:2306.03375v1 [cs.AI])

    [http://arxiv.org/abs/2306.03375](http://arxiv.org/abs/2306.03375)

    该论文介绍了一种数据驱动的方法，利用预训练的多模态表示方法探索人脑中关于视觉概念的高度细分的语义网络，从而识别共享的可解码概念，以推断是否存在专门用于重要语义概念的脑区域。

    

    我们介绍了一种利用高质量的预训练多模态表示探索人类大脑中细粒度语义网络的方法。我们开发了一种数据驱动的方法，以揭示可解码的视觉概念，从而识别专门用于其他重要语义概念的大脑区域。

    We introduce a method that takes advantage of high-quality pretrained multimodal representations to explore fine-grained semantic networks in the human brain. Previous studies have documented evidence of functional localization in the brain, with different anatomical regions preferentially activating for different types of sensory input. Many such localized structures are known, including the fusiform face area and parahippocampal place area. This raises the question of whether additional brain regions (or conjunctions of brain regions) are also specialized for other important semantic concepts. To identify such brain regions, we developed a data-driven approach to uncover visual concepts that are decodable from a massive functional magnetic resonance imaging (fMRI) dataset. Our analysis is broadly split into three sections. First, a fully connected neural network is trained to map brain responses to the outputs of an image-language foundation model, CLIP (Radford et al., 2021). Subseq
    
[^45]: 通过自监督方法弥合多步和单步轨迹预测之间的差距

    Bridging the Gap Between Multi-Step and One-Shot Trajectory Prediction via Self-Supervision. (arXiv:2306.03367v1 [cs.RO])

    [http://arxiv.org/abs/2306.03367](http://arxiv.org/abs/2306.03367)

    本论文通过中间阶段方法，结合多模态轨迹以及自监督机制，解决了多步和单步预测之间的差距，并在INTERACTION数据集上获得有竞争力的结果。

    

    准确的车辆轨迹预测是自动驾驶中一个未解决的问题，存在许多开放性的研究问题。现有的方法要么采用一次性预测，要么采用逐步预测的方式进行轨迹回归。虽然一次性方法通常因其简单性而受欢迎，但它们放弃了强大的自监督机制，这种机制可以通过链接多个时间步骤来构建。我们通过提出中间阶段来解决这个问题，其中多个轨迹片段连接在一起。我们提出的多分支自监督预测器在开始新预测的中间未来时间段接收额外的训练。此外，模型通过树状方式组合多模态轨迹，同时“想象”潜在环境，通过“预测过去”进行预测。我们故意保持交互和环境建模等方面的简单性，仍然在INTERACTION数据集上获得了有竞争力的结果。此外，我们对未经充分探索的不确定性进行了研究。

    Accurate vehicle trajectory prediction is an unsolved problem in autonomous driving with various open research questions. State-of-the-art approaches regress trajectories either in a one-shot or step-wise manner. Although one-shot approaches are usually preferred for their simplicity, they relinquish powerful self-supervision schemes that can be constructed by chaining multiple time-steps. We address this issue by proposing a middle-ground where multiple trajectory segments are chained together. Our proposed Multi-Branch Self-Supervised Predictor receives additional training on new predictions starting at intermediate future segments. In addition, the model 'imagines' the latent context and 'predicts the past' while combining multi-modal trajectories in a tree-like manner. We deliberately keep aspects such as interaction and environment modeling simplistic and nevertheless achieve competitive results on the INTERACTION dataset. Furthermore, we investigate the sparsely explored uncertai
    
[^46]: 使用行为偏好查询提升离线强化学习

    Boosting Offline Reinforcement Learning with Action Preference Query. (arXiv:2306.03362v1 [cs.LG])

    [http://arxiv.org/abs/2306.03362](http://arxiv.org/abs/2306.03362)

    本文提出了一种名为Offline-with-Action-Preferences（OAP）的无交互训练方案，通过查询先前收集的和学习到的行动之间的偏好，来帮助解决错误估计问题，从而获得对未见数据更精确的评估。

    

    训练实用代理通常涉及离线和在线强化学习以平衡政策的性能和交互成本。本文介绍了一种无需交互的训练方案 Offline-with-Action-Preferences（OAP）。 OAP的主要见解是，与在线微调相比，查询事先收集的和学习到的行为之间的偏好可以同样或甚至更有助于解决错误估计问题。通过根据行为偏好自适应地鼓励或抑制策略约束，OAP可以区分过度估计和有益的策略改进，从而获得对未见数据更精确的评估。

    Training practical agents usually involve offline and online reinforcement learning (RL) to balance the policy's performance and interaction costs. In particular, online fine-tuning has become a commonly used method to correct the erroneous estimates of out-of-distribution data learned in the offline training phase. However, even limited online interactions can be inaccessible or catastrophic for high-stake scenarios like healthcare and autonomous driving. In this work, we introduce an interaction-free training scheme dubbed Offline-with-Action-Preferences (OAP). The main insight is that, compared to online fine-tuning, querying the preferences between pre-collected and learned actions can be equally or even more helpful to the erroneous estimate problem. By adaptively encouraging or suppressing policy constraint according to action preferences, OAP could distinguish overestimation from beneficial policy improvement and thus attains a more accurate evaluation of unseen data. Theoretica
    
[^47]: 设计用户角色感知的对话代理进行有趣的对话：$\textit{WHAT}$, $\textit{WHEN}$, and $\textit{HOW}$ to Ground

    $\textit{WHAT}$, $\textit{WHEN}$, and $\textit{HOW}$ to Ground: Designing User Persona-Aware Conversational Agents for Engaging Dialogue. (arXiv:2306.03361v1 [cs.CL])

    [http://arxiv.org/abs/2306.03361](http://arxiv.org/abs/2306.03361)

    本文提出了一种针对商业环境的、能够平衡对话流畅性和趋向于理解对话系统的个性化开放领域对话系统方法，通过加权数据集混合、负角色信息增强方法，以及设计个性化对话数据集，解决了 $\textit{WHAT}$、$\textit{WHEN}$和$\textit{HOW}$ 等问题，同时提高了对话系统响应的可控性和解释性。

    

    本文提出了一种建立个性化开放领域对话系统以解决商业设置中涉及个性化对话响应与非正式响应交替的$\textit{WWH}$（$\textit{WHAT}$、$\textit{WHEN}$和$\textit{HOW}$）问题的方法。所提出的方法涉及加权数据集混合、负角色信息增强方法以及设计个性化对话数据集，以应对个性化、开放领域对话系统中$\textit{WWH}$的挑战。本文有效地平衡了对话流畅性和趋向于理解对话系统，同时还引入了响应类型标签来提高可控性和解释性。这些方法的组合导致了更加流畅的对话，证明了基于主观人类评估和客观评估的实验结果。

    This paper presents a method for building a personalized open-domain dialogue system to address the $\textit{WWH}$ ($\textit{WHAT}$, $\textit{WHEN}$, and $\textit{HOW}$) problem for natural response generation in a commercial setting, where personalized dialogue responses are heavily interleaved with casual response turns. The proposed approach involves weighted dataset blending, negative persona information augmentation methods, and the design of personalized conversation datasets to address the challenges of $\textit{WWH}$ in personalized, open-domain dialogue systems. Our work effectively balances dialogue fluency and tendency to ground, while also introducing a response-type label to improve the controllability and explainability of the grounded responses. The combination of these methods leads to more fluent conversations, as evidenced by subjective human evaluations as well as objective evaluations.
    
[^48]: Vid2Act：为视觉强化学习激活离线视频

    Vid2Act: Activate Offline Videos for Visual RL. (arXiv:2306.03360v1 [cs.LG])

    [http://arxiv.org/abs/2306.03360](http://arxiv.org/abs/2306.03360)

    Vid2Act是一种基于模型的强化学习方法，它通过使用世界模型来传输领域相关的动态和策略，从而显著提高了样本效率。

    

    在离线视频数据集上预训练强化学习模型是提高其在线任务效率的有前途的方法，但由于跨域中任务、动态和行为的固有不匹配性而具有挑战性。最近，一种名为APV的模型避免了离线数据集中的伴随动作记录，而是专注于在源域内预训练与任务无关的、不涉及操作的世界模型。我们提出了Vid2Act，一种基于模型的强化学习方法，它学习从离线到在线环境中传输有价值的动作条件动态和潜在有用的动作演示。其主要思想是不仅将世界模型用作行为学习的模拟器，还将其用作测量领域相关性的工具，以便进行动态表示传输和策略传输。具体地，我们通过域选择知识蒸馏损失训练世界模型生成一组时间变化的任务相似度。这些相似度有两个目的：（i）自适应地将最相关的领域的动态传输到在线环境，和（ii）在在线环境中指导代理集中执行任务相关的动作。在Atari和DMControl连续控制任务上的实验结果表明了我们方法的有效性，其在样本效率方面大大优于之前的最先进的离线强化学习方法。

    Pretraining RL models on offline video datasets is a promising way to improve their training efficiency in online tasks, but challenging due to the inherent mismatch in tasks, dynamics, and behaviors across domains. A recent model, APV, sidesteps the accompanied action records in offline datasets and instead focuses on pretraining a task-irrelevant, action-free world model within the source domains. We present Vid2Act, a model-based RL method that learns to transfer valuable action-conditioned dynamics and potentially useful action demonstrations from offline to online settings. The main idea is to use the world models not only as simulators for behavior learning but also as tools to measure the domain relevance for both dynamics representation transfer and policy transfer. Specifically, we train the world models to generate a set of time-varying task similarities using a domain-selective knowledge distillation loss. These similarities serve two purposes: (i) adaptively transferring th
    
[^49]: 人工智能改变了学术不端行为的规则吗？深入探究学生对“AI-giarism”的看法

    Is AI Changing the Rules of Academic Misconduct? An In-depth Look at Students' Perceptions of 'AI-giarism'. (arXiv:2306.03358v1 [cs.CY])

    [http://arxiv.org/abs/2306.03358](http://arxiv.org/abs/2306.03358)

    这项开创性研究调查了学生对“AI-giarism”的认知，提出了初始概念化的AI-giarism工具，有助于应对不断发展的AI技术带来的学术不端行为，同时还挑战了传统的学术不端行为定义。

    

    这项开创性研究探讨了高等教育背景下，AI和抄袭合体所涉及的新兴学术不端行为“AI-giarism”的学生认知。共有来自不同学科的393名本科和研究生参与了调查，受访者针对多种AI-giarism情境表达了不同的看法。研究结果揭示了一个复杂的认知格局，明确反对直接生成AI内容，但对于更微妙的AI使用方式则持更为暧昧态度。该研究引入了一种新型工具——作为AI-giarism的初始概念化——为教育工作者和政策制定者提供了重要支持。该量具有助于理解和探讨与AI有关的学术不端行为，有助于在AI集成时进行教学设计和评估。此外，它还挑战了传统的学术不端行为定义，强调了根据不断发展的AI技术进行适应的必要性。尽管存在限制，例如具有样本偏差等问题，但是该研究仍然具有重要意义。

    This pioneering study explores students' perceptions of AI-giarism, an emergent form of academic dishonesty involving AI and plagiarism, within the higher education context. A survey, undertaken by 393 undergraduate and postgraduate students from a variety of disciplines, investigated their perceptions of diverse AI-giarism scenarios. The findings portray a complex landscape of understanding, with clear disapproval for direct AI content generation, yet more ambivalent attitudes towards subtler uses of AI. The study introduces a novel instrument, as an initial conceptualization of AI-giarism, offering a significant tool for educators and policy-makers. This scale facilitates understanding and discussions around AI-related academic misconduct, aiding in pedagogical design and assessment in an era of AI integration. Moreover, it challenges traditional definitions of academic misconduct, emphasizing the need to adapt in response to evolving AI technology. Despite limitations, such as the r
    
[^50]: 基于仿真的反事实因果发现与真实驾驶行为的关系

    Simulation-Based Counterfactual Causal Discovery on Real World Driver Behaviour. (arXiv:2306.03354v1 [cs.RO])

    [http://arxiv.org/abs/2306.03354](http://arxiv.org/abs/2306.03354)

    本文提出了基于仿真的反事实因果发现方法，通过重新定义问题和使用反事实仿真来解决因果关系非稳态问题和干预限制，在真实驾驶行为中得到了评估。

    

    理解自己行为如何影响他人行为是驾驶智能体所需的核心技能。然而，现有技术无法满足智能体发现自己和他人之间因果关系的需求。观察性方法面临着动态环境导致因果关系非稳态化，以及因果交互稀疏的挑战，同时需要在线工作。而干预性方法则因为车辆无法在公共道路上进行实验而不切实际。为了解决因果关系的非稳态问题，我们在事件提取方面重新定义了问题，而之前提到的干预限制可以通过反事实仿真来克服。我们提出了三种变体的反事实因果发现方法，并将其与现有观察性时间因果发现方法在3396个因果样本上进行了评估。

    Being able to reason about how one's behaviour can affect the behaviour of others is a core skill required of intelligent driving agents. Despite this, the state of the art struggles to meet the need of agents to discover causal links between themselves and others. Observational approaches struggle because of the non-stationarity of causal links in dynamic environments, and the sparsity of causal interactions while requiring the approaches to work in an online fashion. Meanwhile interventional approaches are impractical as a vehicle cannot experiment with its actions on a public road. To counter the issue of non-stationarity we reformulate the problem in terms of extracted events, while the previously mentioned restriction upon interventions can be overcome with the use of counterfactual simulation. We present three variants of the proposed counterfactual causal discovery method and evaluate these against state of the art observational temporal causal discovery methods across 3396 caus
    
[^51]: 稳定对比强化学习: 离线目标达成的技术

    Stabilizing Contrastive RL: Techniques for Offline Goal Reaching. (arXiv:2306.03346v1 [cs.LG])

    [http://arxiv.org/abs/2306.03346](http://arxiv.org/abs/2306.03346)

    本文提出了一种稳定的对比强化学习方法，通过浅而宽的结构，结合谨慎的权重初始化和数据增强等实验方法，在具有挑战性的仿真基准测试中显著提高了性能，并演示了对比方法可以解决现实世界的机器人任务。

    

    计算机视觉和自然语言处理领域已经开发了自监督方法，强化学习也可以被视为自监督问题：学习达到任何目标，而不需要人类指定的奖励或标签。然而，为强化学习建立自监督基础实际上面临着一些重要的挑战。基于此前对比学习方法，我们进行了细致的剖析实验，并发现一个浅而宽的结构，结合谨慎的权重初始化和数据增强，可以显着提高与对比强化学习方法的性能，特别是在具有挑战性的仿真基准测试中。此外，我们还演示了通过这些设计决策，对比方法可以解决现实世界的机器人操作任务，其中任务由训练后提供的单个目标图像指定。

    In the same way that the computer vision (CV) and natural language processing (NLP) communities have developed self-supervised methods, reinforcement learning (RL) can be cast as a self-supervised problem: learning to reach any goal, without requiring human-specified rewards or labels. However, actually building a self-supervised foundation for RL faces some important challenges. Building on prior contrastive approaches to this RL problem, we conduct careful ablation experiments and discover that a shallow and wide architecture, combined with careful weight initialization and data augmentation, can significantly boost the performance of these contrastive RL approaches on challenging simulated benchmarks. Additionally, we demonstrate that, with these design decisions, contrastive approaches can solve real-world robotic manipulation tasks, with tasks being specified by a single goal image provided after training.
    
[^52]: 推理时间干预：从语言模型中引导出真实的答案

    Inference-Time Intervention: Eliciting Truthful Answers from a Language Model. (arXiv:2306.03341v1 [cs.LG])

    [http://arxiv.org/abs/2306.03341](http://arxiv.org/abs/2306.03341)

    本研究提出推理时间干预（ITI）技术，通过在推理过程中跨越有限数量的注意力头，显着提高大型语言模型的真实性。在TruthfulQA基准上，ITI使LLaMA模型的真实性从32.5%提高到65.1%。ITI是一种最小程度的干扰，计算廉价，且数据效率高。

    

    我们介绍了推理时间干预（ITI）技术，旨在增强大型语言模型（LLMs）的真实性。ITI通过在推理过程中沿着一组方向移动模型激活，跨越有限数量的注意力头。这种干预显着提高了LLaMA模型在TruthfulQA基准上的表现。在指令微调的LLaMA Alpaca上，ITI将其真实性从32.5％提高到65.1％。我们确定了真实性和可用性之间的权衡，并演示了如何通过调整干预强度来平衡它。ITI 取得了最低程度的干扰且计算廉价。此外，该技术在数据效率上表现优异：虽然像RLHF这样的方法需要广泛注释，但是ITI仅使用了几百个例子就能定位真实的方向。我们的研究结果表明，LLMs可能具有某种内部表示方法来表示某事是真实的可能性，即使它们在表面上产生了虚假的结果。

    We introduce Inference-Time Intervention (ITI), a technique designed to enhance the truthfulness of large language models (LLMs). ITI operates by shifting model activations during inference, following a set of directions across a limited number of attention heads. This intervention significantly improves the performance of LLaMA models on the TruthfulQA benchmark. On an instruction-finetuned LLaMA called Alpaca, ITI improves its truthfulness from 32.5% to 65.1%. We identify a tradeoff between truthfulness and helpfulness and demonstrate how to balance it by tuning the intervention strength. ITI is minimally invasive and computationally inexpensive. Moreover, the technique is data efficient: while approaches like RLHF require extensive annotations, ITI locates truthful directions using only few hundred examples. Our findings suggest that LLMs may have an internal representation of the likelihood of something being true, even as they produce falsehoods on the surface.
    
[^53]: 双教师自我训练的少样本原理生成研究

    Few Shot Rationale Generation using Self-Training with Dual Teachers. (arXiv:2306.03315v1 [cs.CL])

    [http://arxiv.org/abs/2306.03315](http://arxiv.org/abs/2306.03315)

    本文提出了一种双教师学习框架，利用标记和未标记的数据，通过自我训练来改进少样本模型，实现同时生成任务标签和原理的效果；此外还提出了一种新的损失函数Masked Label Regularization，可以明确地强制解释明确地条件化。

    

    自我解释模型同时为其预测的标签生成自由文本解释是构建可信赖的AI应用程序的重要工具。由于为注释标签生成解释是一个费力且成本昂贵的过程，因此近期的模型依赖于大型预训练语言模型（PLMs）作为其骨干，并且采用少样本学习。在这项工作中，我们探索了一种自我训练方法，利用标记和未标记的数据来进一步改进少样本模型，假设在大规模情况下都没有人工编写的原理或标注任务标签的情况下。我们引入了一种新的双教师学习框架，使用自我训练和精炼了两个专业的教师模型，用于任务预测和理性化，将它们的知识转化为能够共同生成任务标签和原理的多任务学生模型。此外，我们还制定了一种新的损失函数，掩码标签正则化（MLR），将解释明确地强制条件化。

    Self-rationalizing models that also generate a free-text explanation for their predicted labels are an important tool to build trustworthy AI applications. Since generating explanations for annotated labels is a laborious and costly pro cess, recent models rely on large pretrained language models (PLMs) as their backbone and few-shot learning. In this work we explore a self-training approach leveraging both labeled and unlabeled data to further improve few-shot models, under the assumption that neither human written rationales nor annotated task labels are available at scale. We introduce a novel dual-teacher learning framework, which learns two specialized teacher models for task prediction and rationalization using self-training and distills their knowledge into a multi-tasking student model that can jointly generate the task label and rationale. Furthermore, we formulate a new loss function, Masked Label Regularization (MLR) which promotes explanations to be strongly conditioned on 
    
[^54]: 多智能体协作：发挥智能 LLM 智能体的力量

    Multi-Agent Collaboration: Harnessing the Power of Intelligent LLM Agents. (arXiv:2306.03314v1 [cs.AI])

    [http://arxiv.org/abs/2306.03314](http://arxiv.org/abs/2306.03314)

    本文提出了一种新的框架，利用多智能体系统发挥大型语言模型的能力，解决循环问题、安全风险、可扩展性、系统评估以及道德考虑等挑战，提供一个结合大型语言模型和多智能体系统优势的方式，更高效和有效地处理复杂任务。

    

    本文提出了一种利用多智能体系统发挥大型语言模型（LLMs）能力的新框架。我们的框架引入了一个协作环境，多个智能体组件，每个智能体都具有独特的属性和角色，共同处理复杂任务，更加高效有效。我们通过人工智能（AGI）中的案例研究，特别关注Auto-GPT 和BabyAGI 模型，展示了我们框架的实用性和多样性。我们还研究了“Gorilla”模型，该模型将外部 API 集成到 LLM中。我们的框架解决了循环问题、安全风险、可扩展性、系统评估以及道德考虑等限制和挑战。通过对法庭模拟和软件开发场景等不同领域的建模，我们展示了提议的多智能体系统的潜在应用和益处。我们的框架提供了一个结合大型语言模型和多智能体系统优势的途径，实现对复杂任务的更高效和有效处理。

    In this paper, we present a novel framework for enhancing the capabilities of large language models (LLMs) by leveraging the power of multi-agent systems. Our framework introduces a collaborative environment where multiple intelligent agent components, each with distinctive attributes and roles, work together to handle complex tasks more efficiently and effectively. We demonstrate the practicality and versatility of our framework through case studies in artificial general intelligence (AGI), specifically focusing on the Auto-GPT and BabyAGI models. We also examine the "Gorilla" model, which integrates external APIs into the LLM. Our framework addresses limitations and challenges such as looping issues, security risks, scalability, system evaluation, and ethical considerations. By modeling various domains such as courtroom simulations and software development scenarios, we showcase the potential applications and benefits of our proposed multi-agent system. Our framework provides an aven
    
[^55]: 一个可扩展和适应性强的系统用于推断公司的行业板块：基于生成式语言模型的Prompt+模型微调

    A Scalable and Adaptive System to Infer the Industry Sectors of Companies: Prompt + Model Tuning of Generative Language Models. (arXiv:2306.03313v1 [cs.CL])

    [http://arxiv.org/abs/2306.03313](http://arxiv.org/abs/2306.03313)

    本文介绍了一个板块推断系统，可以帮助主题型私募股权基金的投资专业人士推断公司所在的行业板块。该系统建立在中型生成式语言模型上，通过Prompt+模型微调程序进行微调，并具有良好的可扩展性和适应性。

    

    私募股权公司通过收购和管理公司来实现高收益，许多私募股权基金是主题型的，意味着投资专业人士要覆盖尽可能多的行业板块，并在这些板块中选择有前途的公司，因此推断公司的板块对主题型私募股权基金的成功至关重要。在本文中，我们标准化行业板块框架，并讨论了典型的挑战；然后介绍了我们的板块推断系统，解决了这些挑战。具体而言，我们的系统是建立在中型生成式语言模型上的，通过Prompt+模型微调程序进行微调。部署的模型展示了比常见基线更优秀的性能。该系统已经为许多私募股权专业人员服务超过一年，并显示出对数据量的良好可扩展性和对行业板块和/或注释的任何变化的适应性。

    The Private Equity (PE) firms operate investment funds by acquiring and managing companies to achieve a high return upon selling. Many PE funds are thematic, meaning investment professionals aim to identify trends by covering as many industry sectors as possible, and picking promising companies within these sectors. So, inferring sectors for companies is critical to the success of thematic PE funds. In this work, we standardize the sector framework and discuss the typical challenges; we then introduce our sector inference system addressing these challenges. Specifically, our system is built on a medium-sized generative language model, finetuned with a prompt + model tuning procedure. The deployed model demonstrates a superior performance than the common baselines. The system has been serving many PE professionals for over a year, showing great scalability to data volume and adaptability to any change in sector framework and/or annotation.
    
[^56]: 使用代理人群体学习序列任务的嵌入

    Learning Embeddings for Sequential Tasks Using Population of Agents. (arXiv:2306.03311v1 [cs.LG])

    [http://arxiv.org/abs/2306.03311](http://arxiv.org/abs/2306.03311)

    该研究基于代理人群体提出了一个信息理论框架，用于在强化学习任务中学习固定维度的嵌入，可以通过观察代理在一小组任务上的表现，来预测其在测试任务上的表现，并且可以从给定的任务选项中选择具有所需特征的任务。

    

    我们提出了一个信息理论框架，用于在强化学习任务中学习固定维度的嵌入。我们利用这样的想法：如果观察一个代理在一个任务上的表现减少了我们关于他在另一个任务上表现的不确定性，那么两个任务就相似。我们的信息理论准则捕捉了这种直觉，使用多样化的代理人群体来测量序列决策环境中任务之间的相似性。除了定性评估，我们还通过对两个应用场景进行量化比较，基于任务嵌入展示了我们技术的有效性：通过观察代理在一小组任务上的表现，来预测其在测试任务上的表现；从给定的任务选项中选择具有所需特征的任务。

    We present an information-theoretic framework to learn fixed-dimensional embeddings for tasks in reinforcement learning. We leverage the idea that two tasks are similar to each other if observing an agent's performance on one task reduces our uncertainty about its performance on the other. This intuition is captured by our information-theoretic criterion which uses a diverse population of agents to measure similarity between tasks in sequential decision-making settings. In addition to qualitative assessment, we empirically demonstrate the effectiveness of our techniques based on task embeddings by quantitative comparisons against strong baselines on two application scenarios: predicting an agent's performance on a test task by observing its performance on a small quiz of tasks, and selecting tasks with desired characteristics from a given set of options.
    
[^57]: LIBERO: 生命周期机器人学习的知识转移基准测试

    LIBERO: Benchmarking Knowledge Transfer for Lifelong Robot Learning. (arXiv:2306.03310v1 [cs.AI])

    [http://arxiv.org/abs/2306.03310](http://arxiv.org/abs/2306.03310)

    该论文介绍了一个生命周期机器人学习基准测试——LIBERO。这是一个新颖的机器人操作终身学习基准测试，强调了LLDM中的五个关键研究主题，希望它能够加速构建可以在其生命周期内学习和适应的通用代理的进展。

    

    终身学习提供了一种建立通用代理的有前途的范例，该代理在其生命周期内学习和适应。与传统的图像和文本领域的终身学习问题不同，决策制定中的终身学习（LLDM）还需要传递程序化知识，例如操作和行为。为了推进LLDM研究，我们介绍了LIBERO，这是一个新颖的机器人操作终身学习基准测试。具体而言，LIBERO强调了LLDM中的五个关键研究主题：1）如何有效地传递声明性知识、程序性知识或二者混合体；2）如何设计有效的策略架构和3）LLDM的有效算法；4）终身学习者在任务排序方面的稳健性；5）模型预训练对LLDM的影响。我们开发了一个可扩展的程序生成管道，可以原则上生成无限多的转移场景。基准测试套件包括5个任务族中的50个不同任务。每个任务族都设计以测试其中一个五个研究主题，而在每个任务族内，任务的难度和新颖程度各不相同。我们的实验表明，任务排序对终身学习者的表现有重要影响，而模型预训练可以有效缓解任务排序的负面影响。我们希望LIBERO能够作为一个社区范围的测试平台，用于研究LLDM并加速构建可以在其生命周期内学习和适应的通用代理的进展。

    Lifelong learning offers a promising paradigm of building a generalist agent that learns and adapts over its lifespan. Unlike traditional lifelong learning problems in image and text domains, which primarily involve the transfer of declarative knowledge of entities and concepts, lifelong learning in decision-making (LLDM) also necessitates the transfer of procedural knowledge, such as actions and behaviors. To advance research in LLDM, we introduce LIBERO, a novel benchmark of lifelong learning for robot manipulation. Specifically, LIBERO highlights five key research topics in LLDM: 1) how to efficiently transfer declarative knowledge, procedural knowledge, or the mixture of both; 2) how to design effective policy architectures and 3) effective algorithms for LLDM; 4) the robustness of a lifelong learner with respect to task ordering; and 5) the effect of model pretraining for LLDM. We develop an extendible procedural generation pipeline that can in principle generate infinitely many t
    
[^58]: 采用印象方差感知强化学习实现个性化广告中的公平性

    Towards Fairness in Personalized Ads Using Impression Variance Aware Reinforcement Learning. (arXiv:2306.03293v1 [cs.AI])

    [http://arxiv.org/abs/2306.03293](http://arxiv.org/abs/2306.03293)

    本文提出了一个名为VRS的框架，通过印象方差感知的方式对广告进行重新排序，以实现更公平的个性化广告结果。

    

    在个性化广告系统中，不同人口群体的广告印象结果差异被越来越多地视为算法偏见的可能标志。本文提出了称为VRS（Variance Reduction System）的框架，旨在以保护隐私的方式实现更公平的Meta广告系统结果，同时通过印象方差感知的方式对广告进行重新排序。

    Variances in ad impression outcomes across demographic groups are increasingly considered to be potentially indicative of algorithmic bias in personalized ads systems. While there are many definitions of fairness that could be applicable in the context of personalized systems, we present a framework which we call the Variance Reduction System (VRS) for achieving more equitable outcomes in Meta's ads systems. VRS seeks to achieve a distribution of impressions with respect to selected protected class (PC) attributes that more closely aligns the demographics of an ad's eligible audience (a function of advertiser targeting criteria) with the audience who sees that ad, in a privacy-preserving manner. We first define metrics to quantify fairness gaps in terms of ad impression variances with respect to PC attributes including gender and estimated race. We then present the VRS for re-ranking ads in an impression variance-aware manner. We evaluate VRS via extensive simulations over different pa
    
[^59]: 离线强化学习中的生存本能

    Survival Instinct in Offline Reinforcement Learning. (arXiv:2306.03286v1 [cs.LG])

    [http://arxiv.org/abs/2306.03286](http://arxiv.org/abs/2306.03286)

    离线强化学习算法即使使用错误的奖励标签，也能产生良好的表现和安全的策略，这种鲁棒性属性是由离线强化学习算法的悲观主义和常见数据收集实践中的偏见之间相互作用的结果，赋予了代理生存本能。

    

    我们提出了一个关于离线强化学习算法行为的新观察：在许多基准数据集上，离线强化学习即使使用“错误”的奖励标签（例如在所有地方都为零或是真实奖励的负数），也能产生良好的表现和安全的策略。这种现象不能仅通过离线强化学习的回报最大化目标来解释。此外，它赋予了离线强化学习一定的鲁棒性，这在其在线强化学习对应物中是不典型的，因为后者对奖励设计敏感。我们证明了此惊人的鲁棒性属性是离线强化学习算法中悲观主义概念和常见数据收集实践中某种偏见之间相互作用的结果。悲观主义赋予了代理生存本能，即长期内留在数据支持中的激励，而有限且有偏见的数据覆盖进一步限制了生存行为集合。

    We present a novel observation about the behavior of offline reinforcement learning (RL) algorithms: on many benchmark datasets, offline RL can produce well-performing and safe policies even when trained with "wrong" reward labels, such as those that are zero everywhere or are negatives of the true rewards. This phenomenon cannot be easily explained by offline RL's return maximization objective. Moreover, it gives offline RL a degree of robustness that is uncharacteristic of its online RL counterparts, which are known to be sensitive to reward design. We demonstrate that this surprising robustness property is attributable to an interplay between the notion of pessimism in offline RL algorithms and a certain bias implicit in common data collection practices. As we prove in this work, pessimism endows the agent with a "survival instinct", i.e., an incentive to stay within the data support in the long term, while the limited and biased data coverage further constrains the set of survival 
    
[^60]: 机器人的高效自动化设计

    Efficient automatic design of robots. (arXiv:2306.03263v1 [cs.RO])

    [http://arxiv.org/abs/2306.03263](http://arxiv.org/abs/2306.03263)

    本论文首次使用进化计算和人工神经网络，能够在单个消费者级计算机上数秒内优化机器人结构以达到所需行为，为自动化设计复杂系统开辟了新的可能性。

    

    由于机器人的物理结构、感官、马达布局和行为之间存在复杂的相互依赖关系，它们的设计通常非常困难。20年来，启发于自然界的进化设计，使用进化算法自动设计机器人已经尝试过无数次，但这也非常低效。本文展示了首次在单个消费者级计算机上的数秒内优化机器人结构以展现所需行为，并制造出具有该行为的机器人。与其他基于梯度的机器人设计方法不同的是，本算法不预设任何特定的解剖形式，而是从随机生成的软体机器人种群开始，使用进化计算和人工神经网络的技术来引导优化过程。我们的方法为自动化设计机器人和其他难以手动设计的复杂系统开辟了新的可能性。

    Robots are notoriously difficult to design because of complex interdependencies between their physical structure, sensory and motor layouts, and behavior. Despite this, almost every detail of every robot built to date has been manually determined by a human designer after several months or years of iterative ideation, prototyping, and testing. Inspired by evolutionary design in nature, the automated design of robots using evolutionary algorithms has been attempted for two decades, but it too remains inefficient: days of supercomputing are required to design robots in simulation that, when manufactured, exhibit desired behavior. Here we show for the first time de-novo optimization of a robot's structure to exhibit a desired behavior, within seconds on a single consumer-grade computer, and the manufactured robot's retention of that behavior. Unlike other gradient-based robot design methods, this algorithm does not presuppose any particular anatomical form; starting instead from a randoml
    
[^61]: 理解早期权重平均对训练大语言模型的有效性

    Understanding the Effectiveness of Early Weight Averaging for Training Large Language Models. (arXiv:2306.03241v1 [cs.LG])

    [http://arxiv.org/abs/2306.03241](http://arxiv.org/abs/2306.03241)

    本文研究了使用早期权重平均化方法来提高大型语言模型质量的有效性，证明该方法可以加速收敛且测试和零样本泛化效果显著，同时有效缓解了训练中的损失波动问题。

    

    训练大型语言模型代价高昂，最近的研究表明训练至收敛并不高效。在本文中，我们研究了一种简单的想法，即在训练过程中沿着轨迹进行检查点平均化，以在模型收敛之前提高其质量。这种方法在训练或推理期间不会产生额外的成本。具体而言，我们分析了具有10亿到120亿参数的Pythia LLM的训练轨迹，并证明特别是在训练的早期和中期阶段，这种想法可以加速收敛并提高测试和零样本泛化效果。损失波动是LLM训练中众所周知的问题；在我们的分析中，我们遇到了两种基础轨迹的这种情况，并且我们的平均化可以缓解这两种情况。例如，对于一个拥有69亿参数的LLM，我们的早期权重平均化配方可以节省高达4200小时的GPU时间，这对云计算成本来说是显著的节约。

    Training LLMs is expensive, and recent evidence indicates training all the way to convergence is inefficient. In this paper, we investigate the ability of a simple idea, checkpoint averaging along the trajectory of a training run to improve the quality of models before they have converged. This approach incurs no extra cost during training or inference. Specifically, we analyze the training trajectories of Pythia LLMs with 1 to 12 billion parameters and demonstrate that, particularly during the early to mid stages of training, this idea accelerates convergence and improves both test and zero-shot generalization. Loss spikes are a well recognized problem in LLM training; in our analysis we encountered two instances of this in the underlying trajectories, and both instances were mitigated by our averaging.  For a 6.9B parameter LLM, for example, our early weight averaging recipe can save upto 4200 hours of GPU time, which corresponds to significant savings in cloud compute costs.
    
[^62]: 全局及情境奖励对于上下文MDPs中的探索的研究

    A Study of Global and Episodic Bonuses for Exploration in Contextual MDPs. (arXiv:2306.03236v1 [cs.AI])

    [http://arxiv.org/abs/2306.03236](http://arxiv.org/abs/2306.03236)

    本研究探讨了利用全局和情境奖励进行探索的研究，发现情境奖励在共享结构很少的情况下更有效，而全局奖励则在共享结构更多的情况下更有效，并开发了一个框架以更好地理解共享结构。

    

    近年来，探索不同情境下的环境引起了越来越多的关注。目前的方法使用全局新奇奖励和情境新奇奖励的某种组合，使用代理的整个训练经验进行计算，以及仅使用当前情节的经验进行计算。然而，这两种奖励的使用是不成体系和不理解的。在这项工作中，我们通过对易于解释的任务和具有挑战性的像素设置进行控制实验，揭示了这两种奖励的行为。我们发现，这两种奖励在不同的设置中成功，情境奖励在情节之间共享结构很少的情况下最为有效，而全局奖励在共享结构更多的情况下有效。我们开发了一个概念性框架，通过考虑上下文中的值函数方差，使这种共享结构的概念明确，并提供了一种统一方法。

    Exploration in environments which differ across episodes has received increasing attention in recent years. Current methods use some combination of global novelty bonuses, computed using the agent's entire training experience, and \textit{episodic novelty bonuses}, computed using only experience from the current episode. However, the use of these two types of bonuses has been ad-hoc and poorly understood. In this work, we shed light on the behavior of these two types of bonuses through controlled experiments on easily interpretable tasks as well as challenging pixel-based settings. We find that the two types of bonuses succeed in different settings, with episodic bonuses being most effective when there is little shared structure across episodes and global bonuses being effective when more structure is shared. We develop a conceptual framework which makes this notion of shared structure precise by considering the variance of the value function across contexts, and which provides a unify
    
[^63]: 量子决策和搜索算法的统一信息动态分析：计算智能测量

    Unified Information Dynamic Analysis of Quantum Decision-Making and Search Algorithms: Computational Intelligence Measure. (arXiv:2306.03233v1 [quant-ph])

    [http://arxiv.org/abs/2306.03233](http://arxiv.org/abs/2306.03233)

    本文从信息理论的角度考虑了量子算法的演变，通过基于状态叠加、量子纠缠和干涉的QAG存储信息，最小化经典和量子信息之间的差距，并将此作为QA计算智能测量的终止准则。

    

    一些重要的算法是基于混合使用的基本技巧构建的；例如，快速傅里叶变换（FFT）使用分治和变换技巧。本文从信息理论的角度考虑了量子算法（QA）的演变。将进入量子算法门(QAG)的复向量作为一个信息源，同时从经典和量子层面进行考虑。使用德沃斯-乔扎，肖尔和格罗弗算法的经典和量子信息流分析。通过基于状态叠加、量子纠缠和干涉的QAG在作用于输入向量时，将信息存储到系统状态中，并最小化经典香农熵和量子冯·诺伊曼熵之间的差距。将最小化香农和冯·诺伊曼熵之间的差距视为QA计算智能测量的终止准则。

    There are important algorithms built upon a mixture of basic techniques described; for example, the Fast Fourier Transform (FFT) employs both Divide-and-Conquer and Transform-and-Conquer techniques. In this article, the evolution of a quantum algorithm (QA) is examined from an information theory viewpoint. The complex vector entering the quantum algorithmic gate - QAG is considered as an information source both from the classical and the quantum level. The analysis of the classical and quantum information flow in Deutsch-Jozsa, Shor and Grover algorithms is used. It is shown that QAG, based on superposition of states, quantum entanglement and interference, when acting on the input vector, stores information into the system state, minimizing the gap between classical Shannon entropy and quantum von Neumann entropy. Minimizing of the gap between Shannon and von Neumann entropies is considered as a termination criterion of QA computational intelligence measure.
    
[^64]: 对抗对齐: 打破攻击强度与其对人类感知影响之间的权衡

    Adversarial alignment: Breaking the trade-off between the strength of an attack and its relevance to human perception. (arXiv:2306.03229v1 [cs.CV])

    [http://arxiv.org/abs/2306.03229](http://arxiv.org/abs/2306.03229)

    对抗攻击已成为深度神经网络的弱点, 而对抗对齐是一种新的挑战，需要考虑更多。

    

    深度神经网络(DNNs), 受对抗性攻击的影响敏感。这些攻击会对输入进行微小的扰动，但足以改变模型的视觉决策。本文研究了DNNs对对抗攻击的鲁棒性随着其在ImageNet上的准确性改善而发展的方式。研究发现，对抗对齐是DNNs的新的基本挑战，并且在评估其鲁棒性时应加以考虑。

    Deep neural networks (DNNs) are known to have a fundamental sensitivity to adversarial attacks, perturbations of the input that are imperceptible to humans yet powerful enough to change the visual decision of a model. Adversarial attacks have long been considered the "Achilles' heel" of deep learning, which may eventually force a shift in modeling paradigms. Nevertheless, the formidable capabilities of modern large-scale DNNs have somewhat eclipsed these early concerns. Do adversarial attacks continue to pose a threat to DNNs?  Here, we investigate how the robustness of DNNs to adversarial attacks has evolved as their accuracy on ImageNet has continued to improve. We measure adversarial robustness in two different ways: First, we measure the smallest adversarial attack needed to cause a model to change its object categorization decision. Second, we measure how aligned successful attacks are with the features that humans find diagnostic for object recognition. We find that adversarial a
    
[^65]: 结构重加权改善图领域自适应

    Structural Re-weighting Improves Graph Domain Adaptation. (arXiv:2306.03221v1 [cs.LG])

    [http://arxiv.org/abs/2306.03221](http://arxiv.org/abs/2306.03221)

    本文提出了一种名为结构重加权（StruRW）的新方法，用于解决当前图领域自适应（GDA）方法无法处理的条件结构偏移（CSS）问题，并在多个领域得到验证。

    

    在许多实际应用中，用于训练和测试的图结构化数据具有不同的分布，例如在高能物理学中，用于训练的模拟数据可能与实验不匹配。图领域自适应（GDA）是一种用于解决这些差异的方法。然而，当前的GDA主要通过对单个图神经网络编码器输出的节点表示的分布进行对齐来工作，这可能会产生次优解。这项工作研究了由图结构或节点属性引起的不同分布偏移的不同影响，并确定了一种名为条件结构偏移（CSS）的新类型偏移，证明了当前的GDA方法无法处理。提出了一种称为结构重加权（StruRW）的新方法，并在合成图、四个基准数据集和新的高能物理学应用中进行了测试。StruRW已经显示出显著的性能。

    In many real-world applications, graph-structured data used for training and testing have differences in distribution, such as in high energy physics (HEP) where simulation data used for training may not match real experiments. Graph domain adaptation (GDA) is a method used to address these differences. However, current GDA primarily works by aligning the distributions of node representations output by a single graph neural network encoder shared across the training and testing domains, which may often yield sub-optimal solutions. This work examines different impacts of distribution shifts caused by either graph structure or node attributes and identifies a new type of shift, named conditional structure shift (CSS), which current GDA approaches are provably sub-optimal to deal with. A novel approach, called structural reweighting (StruRW), is proposed to address this issue and is tested on synthetic graphs, four benchmark datasets, and a new application in HEP. StruRW has shown signifi
    
[^66]: 面向自动驾驶的风险感知奖励形成的强化学习代理

    Risk-Aware Reward Shaping of Reinforcement Learning Agents for Autonomous Driving. (arXiv:2306.03220v1 [cs.RO])

    [http://arxiv.org/abs/2306.03220](http://arxiv.org/abs/2306.03220)

    本研究针对自动驾驶中RL代理的安全性问题，提出了一种增加风险感知的奖励形成方法来提高其训练和测试性能。该方法通过额外的重塑奖励项来鼓励探索并惩罚风险驾驶行为，证明其在各种RL代理中具有优势。

    

    强化学习是自动驾驶中有效的运动规划方法，可以通过与环境的交互数据自动学习最优驾驶策略。然而，对于RL代理的奖励函数，其对于性能的影响很大，但是很难确定。传统的研究主要关注安全驾驶状态的奖励，但并未纳入车辆风险驾驶行为的感知。本文研究如何使用风险感知的奖励形成来提高自动驾驶中RL代理的训练和测试性能。根据实践中规定的一般自动驾驶的安全要求，我们提出了额外的重塑奖励项，以鼓励探索并惩罚风险驾驶行为。 OpenAI Gym中的模拟研究表明了风险感知奖励形成在各种RL代理中的优势。同时，我们指出代理转移的方式对风险感知奖励形成影响的现实潜力。

    Reinforcement learning (RL) is an effective approach to motion planning in autonomous driving, where an optimal driving policy can be automatically learned using the interaction data with the environment. Nevertheless, the reward function for an RL agent, which is significant to its performance, is challenging to be determined. The conventional work mainly focuses on rewarding safe driving states but does not incorporate the awareness of risky driving behaviors of the vehicles. In this paper, we investigate how to use risk-aware reward shaping to leverage the training and test performance of RL agents in autonomous driving. Based on the essential requirements that prescribe the safety specifications for general autonomous driving in practice, we propose additional reshaped reward terms that encourage exploration and penalize risky driving behaviors. A simulation study in OpenAI Gym indicates the advantage of risk-aware reward shaping for various RL agents. Also, we point out that proxi
    
[^67]: 数据饮食下的NLU：NLP分类任务中的动态数据子集选择。

    NLU on Data Diets: Dynamic Data Subset Selection for NLP Classification Tasks. (arXiv:2306.03208v1 [cs.CL])

    [http://arxiv.org/abs/2306.03208](http://arxiv.org/abs/2306.03208)

    本研究提出一种动态数据修剪的方法，通过定期对不重要的示例进行打分和抛弃，减少了微调大型语言模型的成本，并且在GLUE基准测试和四个联合NLU数据集上表现更好。

    

    微调大型语言模型会增加NLU应用的成本，并仍是开发周期的瓶颈。最近，计算机视觉领域的研究使用数据修剪来减少训练时间。采用静态方法进行修剪数据选择是基于微调之前为每个训练样例计算的得分，这涉及重要的计算开销。此外，该得分可能并不代表整个训练过程中样例的重要性。我们提出使用精细版本的动态数据修剪方法来解决这些问题，这是一个在微调过程中定期对不重要的示例进行打分和抛弃的课程。我们的方法利用了一个我们将其扩展到联合意图和槽分类任务的EL2N度量和对完整训练集进行的初始微调阶段。我们在GLUE基准测试和四个联合NLU数据集上的结果表明，与静态方法相比，我们的方法在时间-准确性权衡方面表现更好。我们的方法在训练50％时保持完全准确性。

    Finetuning large language models inflates the costs of NLU applications and remains the bottleneck of development cycles. Recent works in computer vision use data pruning to reduce training time. Pruned data selection with static methods is based on a score calculated for each training example prior to finetuning, which involves important computational overhead. Moreover, the score may not necessarily be representative of sample importance throughout the entire training duration. We propose to address these issues with a refined version of dynamic data pruning, a curriculum which periodically scores and discards unimportant examples during finetuning. Our method leverages an EL2N metric that we extend to the joint intent and slot classification task, and an initial finetuning phase on the full train set. Our results on the GLUE benchmark and four joint NLU datasets show a better time-accuracy trade-off compared to static methods. Our method preserves full accuracy while training on 50%
    
[^68]: 夜空中的Lumos：用于探索夜间光模式的AI可视化工具

    Lumos in the Night Sky: AI-enabled Visual Tool for Exploring Night-Time Light Patterns. (arXiv:2306.03195v1 [cs.HC])

    [http://arxiv.org/abs/2306.03195](http://arxiv.org/abs/2306.03195)

    夜Pulse是一个交互式工具，可用于夜间光（NTL）数据的可视化和分析。它可以通过图像分割、聚类和变化模式检测来识别城市发展和扩展模式，并回答有关人口因素、城市边界和异常差异的问题。

    

    我们介绍了NightPulse，这是一种交互式工具，用于夜间光（NTL）数据可视化和分析，使研究人员和利益相关者能够使用用户友好的平台探索和分析NTL数据。由高效的系统架构驱动，NightPulse支持图像分割、聚类和变化模式检测，以识别城市发展和扩展模式。它捕捉NTL的时间趋势和城市的语义，回答关于人口因素、城市边界和异常差异的问题。

    We introduce NightPulse, an interactive tool for Night-time light (NTL) data visualization and analytics, which enables researchers and stakeholders to explore and analyze NTL data with a user-friendly platform. Powered by efficient system architecture, NightPulse supports image segmentation, clustering, and change pattern detection to identify urban development and sprawl patterns. It captures temporal trends of NTL and semantics of cities, answering questions about demographic factors, city boundaries, and unusual differences.
    
[^69]: 翻转硬币来估计强化学习中探索的伪计数

    Flipping Coins to Estimate Pseudocounts for Exploration in Reinforcement Learning. (arXiv:2306.03186v1 [cs.LG])

    [http://arxiv.org/abs/2306.03186](http://arxiv.org/abs/2306.03186)

    研究提出了利用硬币翻转来推导状态的访问计数，并将其作为强化学习探索奖励，相比以往的方法在多个具有挑战性的任务上表现更好。

    

    我们提出了一种在高维状态空间中基于计数的探索新方法。与依赖密度模型的以往研究不同，我们展示了计数可以通过从Rademacher分布（或硬币翻转）中平均样本得到。利用这一见解，我们设置了一个简单的监督学习目标，当优化时，会产生一个状态的访问计数。我们展示了我们的方法比以前的工作更能有效地推导出真正的访问计数。当作为模型无关强化学习算法的探索奖励时，我们的方法在包括Atari游戏Montezuma's Revenge在内的9个具有挑战性的探索任务中优于现有方法。

    We propose a new method for count-based exploration in high-dimensional state spaces. Unlike previous work which relies on density models, we show that counts can be derived by averaging samples from the Rademacher distribution (or coin flips). This insight is used to set up a simple supervised learning objective which, when optimized, yields a state's visitation count. We show that our method is significantly more effective at deducing ground-truth visitation counts than previous work; when used as an exploration bonus for a model-free reinforcement learning algorithm, it outperforms existing approaches on most of 9 challenging exploration tasks, including the Atari game Montezuma's Revenge.
    
[^70]: 基于格点对注意机制进行先验加入，以提高抽象几何推理的样本效率

    Infusing Lattice Symmetry Priors in Attention Mechanisms for Sample-Efficient Abstract Geometric Reasoning. (arXiv:2306.03175v1 [cs.AI])

    [http://arxiv.org/abs/2306.03175](http://arxiv.org/abs/2306.03175)

    LatFormer是一种将格点对称先验融入到注意力掩码中的模型，能够用卷积网络生成软掩码来调整注意力权重。该模型在合成几何推理中取得了较好效果。

    

    抽象和推理语料库（ARC）及其最近的语言完整实例（LARC）被认为是通往通用人工智能的重要一步。然而，即使是最先进的机器学习模型在这些问题上也难以实现有意义的性能，落后于非学习方法。我们认为解决这些任务需要极端的泛化能力，只有通过适当考虑核心知识先验才能实现。为了达到这个目标，我们聚焦于几何先验，并引入LatFormer模型，将格点对称先验融入到注意力掩码中。我们证明了对于超立方格的任何变换，都存在一个二值注意力掩码来实现该群作用。因此，我们的研究激发了对标准注意力机制的修改，其中使用卷积网络生成的软掩码来调整关注权重。在合成几何推理方面的实验表明，LatFormer

    The Abstraction and Reasoning Corpus (ARC) (Chollet, 2019) and its most recent language-complete instantiation (LARC) has been postulated as an important step towards general AI. Yet, even state-of-the-art machine learning models struggle to achieve meaningful performance on these problems, falling behind non-learning based approaches. We argue that solving these tasks requires extreme generalization that can only be achieved by proper accounting for core knowledge priors. As a step towards this goal, we focus on geometry priors and introduce LatFormer, a model that incorporates lattice symmetry priors in attention masks. We show that, for any transformation of the hypercubic lattice, there exists a binary attention mask that implements that group action. Hence, our study motivates a modification to the standard attention mechanism, where attention weights are scaled using soft masks generated by a convolutional network. Experiments on synthetic geometric reasoning show that LatFormer 
    
[^71]: 使用自然的工具解码自然：遗传算法和量子退火结合的异构线丛模型在粒子物理学中的应用

    Decoding Nature with Nature's Tools: Heterotic Line Bundle Models of Particle Physics with Genetic Algorithms and Quantum Annealing. (arXiv:2306.03147v1 [hep-th])

    [http://arxiv.org/abs/2306.03147](http://arxiv.org/abs/2306.03147)

    本文使用遗传算法和量子退火技术来解决弦理论中的复杂模型的优化问题，成功地找到了以往未能发现的解决方案，为弦场论的潜在发展提供了新的视角和可能性。

    

    弦理论景象包括多个标准模型的紫外嵌入，但由于可用的弦紧致化数量巨大，因此识别这些嵌入变得困难。遗传算法（GAs）代表了一类强大的离散优化技术，可以有效处理弦景象的广袤空间，特别是当它与量子退火的输入结合时。本文关注于异构$E_8\times E_8$弦论在光滑Calabi-Yau三叠上的几何紧致化与阿贝尔丛。我们利用丛值上同调的解析公式，以满足整个谱要求的所有范围，这是迄今为止不可能的。对于具有相对较少Kahler参数的流形，我们将GA搜索结果与以前系统性扫描的结果进行比较，显示出GA可以找到几乎所有可行的解决方案，同时只访问了微小的一部分搜索空间。我们展示了GAs如何能够很好地与量子退火结合，以处理高维空间和高度非线性函数的优化搜索问题，并能够找到尚未从系统扫描中发现的新解中的困难实例，这使得GAs成为大规模天然扫描中的有力工具。

    The string theory landscape may include a multitude of ultraviolet embeddings of the Standard Model, but identifying these has proven difficult due to the enormous number of available string compactifications. Genetic Algorithms (GAs) represent a powerful class of discrete optimisation techniques that can efficiently deal with the immensity of the string landscape, especially when enhanced with input from quantum annealers. In this letter we focus on geometric compactifications of the $E_8\times E_8$ heterotic string theory compactified on smooth Calabi-Yau threefolds with Abelian bundles. We make use of analytic formulae for bundle-valued cohomology to impose the entire range of spectrum requirements, something that has not been possible so far. For manifolds with a relatively low number of Kahler parameters we compare the GA search results with results from previous systematic scans, showing that GAs can find nearly all the viable solutions while visiting only a tiny fraction of the 
    
[^72]: 通过转化特定注释者和特定实例的转移矩阵从众包中学习

    Transferring Annotator- and Instance-dependent Transition Matrix for Learning from Crowds. (arXiv:2306.03116v1 [cs.HC])

    [http://arxiv.org/abs/2306.03116](http://arxiv.org/abs/2306.03116)

    本文提出了一个高效的方法来估算特定注释者和特定实例的转移矩阵以及真实标签比例，解决了从众包中学习的标签噪声问题，并在实验中证明了方法的优越性。

    

    本文描述了从众包服务中获取训练数据的注释方法。每个注释者都完成自己的小部分注释，不同注释者的标注错误往往不同。通过标签噪声的转移矩阵来建模噪声产生过程是解决标签噪声的一种有效工具。在实际众包模型中，转移矩阵既由注释者依赖，也由实例依赖。然而，由于注释者和实例依赖的转移矩阵(AIDTM)具有高复杂度，而实际注释往往涉及注释稀疏性，这使得建立AIDTM非常具有挑战性。既要保持建模的广泛性，又能更真实地解决问题，本文提出了一种高效的算法，可以同时估算AIDTM和真实标签比例。我们还提供了理论分析，证明了我们的算法的收敛性。在合成数据集和真实数据集上的实验结果表明，我们的算法优于基准方法。

    Learning from crowds describes that the annotations of training data are obtained with crowd-sourcing services. Multiple annotators each complete their own small part of the annotations, where labeling mistakes that depend on annotators occur frequently. Modeling the label-noise generation process by the noise transition matrix is a power tool to tackle the label noise. In real-world crowd-sourcing scenarios, noise transition matrices are both annotator- and instance-dependent. However, due to the high complexity of annotator- and instance-dependent transition matrices (AIDTM), \textit{annotation sparsity}, which means each annotator only labels a little part of instances, makes modeling AIDTM very challenging. Prior works simplify the problem by assuming the transition matrix is instance-independent or using simple parametric way, while lose modeling generality. Motivated by this, we target a more realistic problem, estimating general AIDTM in practice. Without losing modeling general
    
[^73]: AutoExp: 一种多学科、多传感器框架，用于评估自动驾驶汽车中的人类活动

    AutoExp: A multidisciplinary, multi-sensor framework to evaluate human activities in self-driving cars. (arXiv:2306.03115v1 [cs.HC])

    [http://arxiv.org/abs/2306.03115](http://arxiv.org/abs/2306.03115)

    本文提出一个多学科、多传感器框架，用于评估自动驾驶汽车中乘客的活动，并在最近实际条件下捕获真实数据来创建数据集。

    

    自动驾驶汽车的普及将彻底改变我们的生活，即使它们的全自主化可能比最初预计的需要更长时间。目前，该技术的第一批车辆已经出现在世界某些城市中，作为实验性机器人出租车服务的一部分。本文提出了一个实验性框架，利用多学科方法（计算机视觉与人文社会科学相结合），特别是非驾驶相关活动，来研究自动驾驶汽车乘客的活动。该框架由实验场景和数据采集模块组成，旨在首先在最近可能的实际条件下捕获有关车辆使用的真实数据，并创建一个包含大量传感器数据和日志记录的数据集。

    The adoption of self-driving cars will certainly revolutionize our lives, even though they may take more time to become fully autonomous than initially predicted. The first vehicles are already present in certain cities of the world, as part of experimental robot-taxi services. However, most existing studies focus on the navigation part of such vehicles. We currently miss methods, datasets, and studies to assess the in-cabin human component of the adoption of such technology in real-world conditions. This paper proposes an experimental framework to study the activities of occupants of self-driving cars using a multidisciplinary approach (computer vision associated with human and social sciences), particularly non-driving related activities. The framework is composed of an experimentation scenario, and a data acquisition module. We seek firstly to capture real-world data about the usage of the vehicle in the nearest possible, real-world conditions, and secondly to create a dataset conta
    
[^74]: 使用生成模型合成情感神经生理信号的综述论文

    Synthesizing Affective Neurophysiological Signals Using Generative Models: A Review Paper. (arXiv:2306.03112v1 [cs.HC])

    [http://arxiv.org/abs/2306.03112](http://arxiv.org/abs/2306.03112)

    本文综述了使用生成模型合成神经生理信号来解决公共情感数据集稀缺性的问题。通过对领域中使用的不同生成模型进行全面分析，我们提供了有关生成模型在情感识别系统应用的优势、挑战和有前途的未来方向的深入见解。

    

    在提高人机交互中，将情感智能引入机器是重要的一步。这需要开发可靠的端到端情感识别系统。然而，公共情感数据集的稀缺性提出了一个挑战。在本文献评文章中，我们强调了使用生成模型来解决神经生理学信号中，尤其是脑电图（EEG）和功能性近红外光谱（fNIRS）中这个问题。我们对领域中使用的不同生成模型进行了全面的分析，检验了它们的输入格式、部署策略以及用于评估合成数据质量的方法。本文的综述是一篇全面的概述，提供了有关生成模型在情感识别系统应用中的优势、挑战和有前途的未来方向的深入见解。通过这篇综述，我们旨在促进神经生理数据增强的进展。

    The integration of emotional intelligence in machines is an important step in advancing human-computer interaction. This demands the development of reliable end-to-end emotion recognition systems. However, the scarcity of public affective datasets presents a challenge. In this literature review, we emphasize the use of generative models to address this issue in neurophysiological signals, particularly Electroencephalogram (EEG) and Functional Near-Infrared Spectroscopy (fNIRS). We provide a comprehensive analysis of different generative models used in the field, examining their input formulation, deployment strategies, and methodologies for evaluating the quality of synthesized data. This review serves as a comprehensive overview, offering insights into the advantages, challenges, and promising future directions in the application of generative models in emotion recognition systems. Through this review, we aim to facilitate the progression of neurophysiological data augmentation, there
    
[^75]: SwinRDM: 将SwinRNN与扩散模型结合以实现高分辨率且高质量的天气预报

    SwinRDM: Integrate SwinRNN with Diffusion Model towards High-Resolution and High-Quality Weather Forecasting. (arXiv:2306.03110v1 [cs.AI])

    [http://arxiv.org/abs/2306.03110](http://arxiv.org/abs/2306.03110)

    SwinRDM是一种将SwinRNN与扩散模型结合的数据驱动模型，它具有更优越的预报准确性以及在预测极端天气事件方面的巨大潜力。

    

    数据驱动的中期天气预报近年来受到了广泛关注。然而，目前在高分辨率下的预测准确性仍然不尽如人意。为了追求高分辨率和高质量的天气预报，我们开发了一个数据驱动模型SwinRDM，它将改进后的SwinRNN与扩散模型结合在一起。SwinRDM在0.25度分辨率上进行预测，并在500 hPa位势高度（Z500），850 hPa温度（T850），2米温度（T2M）和总降水（TP）等代表性大气变量上，以最多5天的先导时间，比IFS（集成预报系统）这种最先进的运营数值预报模型具有更优越的预报准确性。我们提出了一种双阶段策略，通过权衡计算内存和预测准确性之间的平衡来实现0.25度分辨率的高分辨率预测。首先在1.40625度分辨率下完成对未来大气场的循环预测，然后应用扩散模型将输出精细化到0.25度分辨率。结果表明，SwinRDM不仅极大地提高了高分辨率中期天气预报的准确性，而且展示了在预测极端天气事件方面的巨大潜力。

    Data-driven medium-range weather forecasting has attracted much attention in recent years. However, the forecasting accuracy at high resolution is unsatisfactory currently. Pursuing high-resolution and high-quality weather forecasting, we develop a data-driven model SwinRDM which integrates an improved version of SwinRNN with a diffusion model. SwinRDM performs predictions at 0.25-degree resolution and achieves superior forecasting accuracy to IFS (Integrated Forecast System), the state-of-the-art operational NWP model, on representative atmospheric variables including 500 hPa geopotential (Z500), 850 hPa temperature (T850), 2-m temperature (T2M), and total precipitation (TP), at lead times of up to 5 days. We propose to leverage a two-step strategy to achieve high-resolution predictions at 0.25-degree considering the trade-off between computation memory and forecasting accuracy. Recurrent predictions for future atmospheric fields are firstly performed at 1.40625-degree resolution, and
    
[^76]: 以模拟专家人格为向导的场景指导：执行认知工作的显著策略

    Guided scenarios with simulated expert personae: a remarkable strategy to perform cognitive work. (arXiv:2306.03104v1 [cs.HC])

    [http://arxiv.org/abs/2306.03104](http://arxiv.org/abs/2306.03104)

    通过模拟人格的团队、提供语境、提示与引导，能够以模仿专家人格来进行认知工作。

    

    在一个巨大的人类知识和文学语料库上进行训练的大型语言模型(LLM)，可以有效地处理来自该语料库的大量事实,更令人惊讶的是，它们还能够重新创造出被捕捉在语料库中的人格的行为。通过形成模拟人格的团队、提供设置舞台的语境和提供温和的提示，人们可以通过情境推进来引出专家行为以执行有意义的认知工作。这一策略的威力在两个例子中得到了展示，一个攻击LLM响应的事实性，另一个是复制了一个最近在量子光学中发表的结果。

    Large language models (LLMs) trained on a substantial corpus of human knowledge and literature productively work with a large array of facts from that corpus. Surprisingly, they are also able to re-create the behaviors of personae that are captured within the corpus. By forming teams of simulated personae, supplying contexts that set the stage, and providing gentle prompts, one can move through scenarios that elicit expert behavior to perform meaningful cognitive work. The power of this strategy is demonstrated with two examples, one attacking factuality of LLM responses and the other reproducing a very recently published result in quantum optics.
    
[^77]: 将模型评估重新考虑为缩小社会技术差距

    Rethinking Model Evaluation as Narrowing the Socio-Technical Gap. (arXiv:2306.03100v1 [cs.HC])

    [http://arxiv.org/abs/2306.03100](http://arxiv.org/abs/2306.03100)

    针对同质化的模型，模型评估需要提供有效的评估，以判断特定模型是否在下游使用场景中可以满足多少人类需求，并且应该根据真实的社会需求来开发评估模型，并拥抱多样化的评估方法。

    

    生成和大型语言模型的最近发展给模型评估带来了新的挑战，研究界和工业界正在努力应对。虽然这些模型的多才多艺引起了人们的兴奋，但它们也不可避免地向同质化迈进：用单个常称之为“通用”的模型为一系列应用提供动力。在这篇立场论文中，我们认为模型评估实践必须承担一个关键任务，以应对这种同质化带来的挑战和责任：为特定模型提供有效的评估，判断是否以及在下游使用场景中可以通过给定模型满足多少人类需求（“社会技术差距”）。我们汲取社会科学、人机交互（HCI）和可解释AI（XAI）跨学科领域的经验，敦促社区开发基于真实社会需求的评估方法，并拥抱多样化的评估方法。

    The recent development of generative and large language models (LLMs) poses new challenges for model evaluation that the research community and industry are grappling with. While the versatile capabilities of these models ignite excitement, they also inevitably make a leap toward homogenization: powering a wide range of applications with a single, often referred to as ``general-purpose'', model. In this position paper, we argue that model evaluation practices must take on a critical task to cope with the challenges and responsibilities brought by this homogenization: providing valid assessments for whether and how much human needs in downstream use cases can be satisfied by the given model (\textit{socio-technical gap}). By drawing on lessons from the social sciences, human-computer interaction (HCI), and the interdisciplinary field of explainable AI (XAI), we urge the community to develop evaluation methods based on real-world socio-requirements and embrace diverse evaluation methods 
    
[^78]: 超越杂草，利用生成式AI的“绿色团队”进行有益的应用

    Seeing Seeds Beyond Weeds: Green Teaming Generative AI for Beneficial Uses. (arXiv:2306.03097v1 [cs.HC])

    [http://arxiv.org/abs/2306.03097](http://arxiv.org/abs/2306.03097)

    本文介绍了“绿色团队”的概念，旨在用来通过绕过GM内容过滤器设计有益用例。实际应用包括使用ChatGPT进行自杀支持培训以及使用Codex进行有缺陷的解决方案培训。

    

    大型生成式AI模型（GMs）如GPT和DALL-E的训练目的是为了普遍、广泛的目的生成内容。GM内容过滤器是通用的，可以过滤出在很多情况下存在危害风险的内容，例如仇恨言论。然而，被禁止的内容并不总是有害的——在某些情况下，生成被禁止的内容可能是有益的。因此，当GMs过滤内容时，它们不仅会排除有害的用例，也会排除有益的用例。被排除的用例反映了GM内容过滤中嵌入的价值观。最近的红队工作提出了绕过GM内容过滤器生成有害内容的方法。我们创造了绿色团队这一术语，用来描述绕过GM内容过滤器为有益用例设计的方法。我们通过以下实例展示了绿色团队的应用：1）使用ChatGPT作为虚拟患者，通过模拟患有自杀倾向的人来进行自杀支持培训；2）使用Codex有意地生成有缺陷的解决方法，用于培训学生进行调试。

    Large generative AI models (GMs) like GPT and DALL-E are trained to generate content for general, wide-ranging purposes. GM content filters are generalized to filter out content which has a risk of harm in many cases, e.g., hate speech. However, prohibited content is not always harmful -- there are instances where generating prohibited content can be beneficial. So, when GMs filter out content, they preclude beneficial use cases along with harmful ones. Which use cases are precluded reflects the values embedded in GM content filtering. Recent work on red teaming proposes methods to bypass GM content filters to generate harmful content. We coin the term green teaming to describe methods of bypassing GM content filters to design for beneficial use cases. We showcase green teaming by: 1) Using ChatGPT as a virtual patient to simulate a person experiencing suicidal ideation, for suicide support training; 2) Using Codex to intentionally generate buggy solutions to train students on debuggin
    
[^79]: 非参数迭代机器教学

    Nonparametric Iterative Machine Teaching. (arXiv:2306.03007v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.03007](http://arxiv.org/abs/2306.03007)

    本文提出了解决非参数目标模型的迭代机器教学问题的方法，包括随机和贪心泛函教学算法。

    

    本文研究了迭代机器教学(IMT)问题。现有IMT算法基于参数化的目标模型。本文研究了更普遍的任务——非参数迭代机器教学(NIMT)，旨在以迭代方式向学习者教授非参数目标模型。为了解决这一问题，我们将NIMT视为一个在函数空间中的泛函优化问题，并提出了随机和贪心泛函教学算法。

    In this paper, we consider the problem of Iterative Machine Teaching (IMT), where the teacher provides examples to the learner iteratively such that the learner can achieve fast convergence to a target model. However, existing IMT algorithms are solely based on parameterized families of target models. They mainly focus on convergence in the parameter space, resulting in difficulty when the target models are defined to be functions without dependency on parameters. To address such a limitation, we study a more general task -Nonparametric Iterative Machine Teaching (NIMT), which aims to teach nonparametric target models to learners in an iterative fashion. Unlike parametric IMT that merely operates in the parameter space, we cast NIMT as a functional optimization problem in the function space. To solve it, we propose both random and greedy functional teaching algorithms. We obtain the iterative teaching dimension (ITD) of the random teaching algorithm under proper assumptions, which se
    
[^80]: Time Interpret: 一种序列数据可解释性统一模型库

    Time Interpret: a Unified Model Interpretability Library for Time Series. (arXiv:2306.02968v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.02968](http://arxiv.org/abs/2306.02968)

    Time Interpret是一个基于Captum的模型解释库，专门用于解释时间序列数据，并实现了多种特征归因方法。此外，它还提供了各种PyTorch模型和数据集，以及一组用于评估特征归因的方法。

    

    我们介绍了一款名为$\texttt{time_interpret}$的库，它是以Captum为基础设计的，专门用于解释时间序列数据。该库实现了多种特征归因方法，可用于解释任何Pytorch模型的预测。此外，$\texttt{time_interpret}$还提供了多种合成和真实的时间序列数据集、各种PyTorch模型以及一组用于评估特征归因的方法。虽然该库主要用于解释基于时间数据的预测，但它的某些组件也有不同的应用，例如解释语言模型的预测。本文概述了该库的基本内容，并提供了几种以前未公开的特征归因方法，这些方法是与$\texttt{time_interpret}$同时开发的。

    We introduce $\texttt{time_interpret}$, a library designed as an extension of Captum, with a specific focus on temporal data. As such, this library implements several feature attribution methods that can be used to explain predictions made by any Pytorch model. $\texttt{time_interpret}$ also provides several synthetic and real world time series datasets, various PyTorch models, as well as a set of methods to evaluate feature attributions. Moreover, while being primarily developed to explain predictions based on temporal data, some of its components have a different application, including for instance methods explaining predictions made by language models. In this paper, we give a general introduction of this library. We also present several previously unpublished feature attribution methods, which have been developed along with $\texttt{time_interpret}$.
    
[^81]: 动态任务分配问题的建模和解决框架：行动演变Petri网格

    Action-Evolution Petri Nets: a Framework for Modeling and Solving Dynamic Task Assignment Problems. (arXiv:2306.02910v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2306.02910](http://arxiv.org/abs/2306.02910)

    本文提出了一种新的建模和解决动态任务分配问题的框架—行动演变Petri网格。它提供了一种统一的建模技术，可以表示动态任务分配问题的所有要素。而且，该模型是可执行的，并且可以用于强化学习，以学习接近最优的分配策略。

    

    动态任务分配涉及将到达的任务分配给有限的资源，以最小化分配的总成本。为了达到最优的任务分配，必须先对分配问题进行建模。虽然存在用于模拟、执行和解决问题不同方面的形式化方法，如马尔可夫决策过程和Petri网格，但不存在一种集成建模技术。为填补这一空白，本文提出了Action-Evolution Petri网格(A-E PN)作为一种建模和解决动态任务分配问题的框架。A-E PN提供了一种统一的建模技术，可以表示动态任务分配问题的所有要素。此外，A-E PN模型是可执行的，这意味着它们可以用于强化学习(RL)学习接近最优的分配策略，无需额外的建模工作。为了评估框架，我们定义了一个原型分配问题的分类法。

    Dynamic task assignment involves assigning arriving tasks to a limited number of resources in order to minimize the overall cost of the assignments. To achieve optimal task assignment, it is necessary to model the assignment problem first. While there exist separate formalisms, specifically Markov Decision Processes and (Colored) Petri Nets, to model, execute, and solve different aspects of the problem, there is no integrated modeling technique. To address this gap, this paper proposes Action-Evolution Petri Nets (A-E PN) as a framework for modeling and solving dynamic task assignment problems. A-E PN provides a unified modeling technique that can represent all elements of dynamic task assignment problems. Moreover, A-E PN models are executable, which means they can be used to learn close-to-optimal assignment policies through Reinforcement Learning (RL) without additional modeling effort. To evaluate the framework, we define a taxonomy of archetypical assignment problems. We show for 
    
[^82]: 抓住意外收获：在离线策略演员-评论家中利用过去成功的价值(arXiv:2306.02865v2 [cs.LG]已更新)

    Seizing Serendipity: Exploiting the Value of Past Success in Off-Policy Actor-Critic. (arXiv:2306.02865v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.02865](http://arxiv.org/abs/2306.02865)

    该论文提出了 BEE 操作符，通过充分利用过去的成功经验，并保持探索乐观性，解决了离线策略演员-评论家中 Q 值高估与低估问题，提高了策略学习和样本效率。

    

    学习高质量的 Q 值函数在许多现代离线深度强化学习 (RL) 算法的成功中起着关键作用。之前的研究集中解决采用函数逼近器和离线学习所导致的值过高的问题。与这种普遍观点不同，我们观察到 Q 值在 RL 训练过程的后期实际上被低估了，主要是由于贝尔曼更新中，当前策略使用比回放缓冲区中更优的动作样本差。我们假设这个长期被忽视的现象可能阻碍了策略学习，降低了样本效率。我们的想法是在保持探索乐观性的同时，结合充分利用过去成功的经验。我们提出了混合利用和探索 (BEE) 操作符，这是一种简单而有效的方法，使用历史上表现最佳的动作和当前策略生成的动作来更新 Q 值。

    Learning high-quality Q-value functions plays a key role in the success of many modern off-policy deep reinforcement learning (RL) algorithms. Previous works focus on addressing the value overestimation issue, an outcome of adopting function approximators and off-policy learning. Deviating from the common viewpoint, we observe that Q-values are indeed underestimated in the latter stage of the RL training process, primarily related to the use of inferior actions from the current policy in Bellman updates as compared to the more optimal action samples in the replay buffer. We hypothesize that this long-neglected phenomenon potentially hinders policy learning and reduces sample efficiency. Our insight to address this issue is to incorporate sufficient exploitation of past successes while maintaining exploration optimism. We propose the Blended Exploitation and Exploration (BEE) operator, a simple yet effective approach that updates Q-value using both historical best-performing actions and
    
[^83]: 迈向更好的目标检测解释

    Towards Better Explanations for Object Detection. (arXiv:2306.02744v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2306.02744](http://arxiv.org/abs/2306.02744)

    该论文提出了一种名为D-CLOSE的方法，用于解释任何目标检测模型的决策，通过使用多个分割级别和一种组合它们的过程，可以提供更好的质量和更少的噪音解释。

    

    人工智能技术的最新进展促进了它们在几乎所有领域的使用。深度神经网络的增加的复杂性使解释网络内部工作和决策变得越来越困难和重要。但是，目前大多数解释深度神经网络的技术主要集中在解释分类任务上。本文提出了一种名为D-CLOSE的方法，用于解释任何目标检测模型的决策。为了密切跟踪模型的行为，我们在图像上使用了多个分割级别和一种组合它们的过程。我们使用YOLOX模型在MS-COCO数据集上进行了测试，结果表明我们的方法优于D-RISE，可以提供更好的质量和更少的噪音解释。

    Recent advances in Artificial Intelligence (AI) technology have promoted their use in almost every field. The growing complexity of deep neural networks (DNNs) makes it increasingly difficult and important to explain the inner workings and decisions of the network. However, most current techniques for explaining DNNs focus mainly on interpreting classification tasks. This paper proposes a method to explain the decision for any object detection model called D-CLOSE. To closely track the model's behavior, we used multiple levels of segmentation on the image and a process to combine them. We performed tests on the MS-COCO dataset with the YOLOX model, which shows that our method outperforms D-RISE and can give a better quality and less noise explanation.
    
[^84]: 利用深度学习模型预测布隆迪疟疾动态

    Predicting malaria dynamics in Burundi using deep Learning Models. (arXiv:2306.02685v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.02685](http://arxiv.org/abs/2306.02685)

    该论文利用机器学习方法建立疟疾预测模型，成功预测了布隆迪疟疾时空动态，为疟疾防治和干预设计提供了重要依据。

    

    疟疾继续在非洲大陆特别是撒哈拉以南非洲地区成为主要的公共卫生问题。然而，我们仍在努力并取得了显著进展。在布隆迪，疟疾是主要的公共卫生问题之一。然而，目前关于布隆迪疟疾预测模型的研究还很有限。我们建立基于机器学习的模型来估计布隆迪的疟疾病例。利用气候变化相关因素如温度、降雨和相对湿度以及疟疾历史数据和人口数据，采用一种深度学习模型——LSTM模型，对省级和国家范围内的疟疾情况进行了预测。根据模型结果，可以确定在不同参数调整下，国家级别的最低和最高预期疟疾病例数。

    Malaria continues to be a major public health problem on the African continent, particularly in Sub-Saharan Africa. Nonetheless, efforts are ongoing, and significant progress has been made. In Burundi, malaria is among the main public health concerns. In the literature, there are limited prediction models for Burundi. We know that such tools are much needed for interventions design. In our study, we built machine-learning based models to estimates malaria cases in Burundi. The forecast of malaria cases was carried out at province level and national scale as well. Long short term memory (LSTM) model, a type of deep learning model has been used to achieve best results using climate-change related factors such as temperature, rainfal, and relative humidity, together with malaria historical data and human population. With this model, the results showed that at country level different tuning of parameters can be used in order to determine the minimum and maximum expected malaria cases. The 
    
[^85]: 循环一致性驱动的物体发现方法

    Cycle Consistency Driven Object Discovery. (arXiv:2306.02204v1 [cs.CV] CROSS LISTED)

    [http://arxiv.org/abs/2306.02204](http://arxiv.org/abs/2306.02204)

    该方法通过循环一致性目标的引入，明确优化场景中每个物体应映射到不同槽位的约束，从而实现了在完全无监督的情况下有效地学习发现物体。在实验中表现出了优于现有方法的性能。

    

    开发能够有效学习类似于人类认知的以物体为中心的表示的深度学习模型仍然是一项具有挑战性的任务。现有的方法利用架构先验或辅助信息（例如深度图或流场图）来探索基于槽位的方法，以表示对象为称为“槽位”或“对象文件”的固定大小的向量，从而促进物体发现。 然而，依赖于架构先验会引入不可靠性，并需要精心设计才能识别正确的对象。 同样，依赖辅助信息的方法也不够优越，因为这种信息通常在大多数自然情况下不可用。为了解决这些限制，我们提出了一种明确优化场景中每个对象应映射到一个不同槽位的方法。我们通过引入循环一致性目标来形式化这个约束，称之为循环一致性目标。通过应用这些限制，我们的方法可以在完全无监督的情况下有效地学习发现物体。 在实验中，我们展示了我们的方法在无监督物体发现和少样本物体分类基准测试中均优于现有的最先进方法。

    Developing deep learning models that effectively learn object-centric representations, akin to human cognition, remains a challenging task. Existing approaches have explored slot-based methods utilizing architectural priors or auxiliary information such as depth maps or flow maps to facilitate object discovery by representing objects as fixed-size vectors, called ``slots'' or ``object files''. However, reliance on architectural priors introduces unreliability and requires meticulous engineering to identify the correct objects. Likewise, methods relying on auxiliary information are suboptimal as such information is often unavailable for most natural scenes. To address these limitations, we propose a method that explicitly optimizes the constraint that each object in a scene should be mapped to a distinct slot. We formalize this constraint by introducing consistency objectives which are cyclic in nature. We refer to them as the \textit{cycle-consistency} objectives. By applying these con
    
[^86]: MultiLegalPile：689GB的多语言法律语料库

    MultiLegalPile: A 689GB Multilingual Legal Corpus. (arXiv:2306.02069v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.02069](http://arxiv.org/abs/2306.02069)

    MultiLegalPile是一个689GB的多语言法律语料库，包含来自17个司法管辖区的24种语言的不同法律数据源，允许在公平使用下针对预训练NLP模型。该语料库为多语言模型的预训练提供了新的最佳表现，并在LexGLUE上表现最佳。

    

    大型高质量的数据集对于训练大型语言模型(LLMs)至关重要。然而，目前为止，专业领域（如法律）可用的数据集很少，而且经常仅限于英语。我们整理并发布了MultiLegalPile，这是一个包含来自17个司法管辖区的24种语言的689GB语料库。MultiLegalPile语料库包括各种许可证的不同法律数据源，允许在公平使用下针对预训练自然语言处理(NLP)模型，对于Eurlex Resources和Legal mC4子集拥有更宽松的许可证。我们进行了两个RoBERTa模型和一个多语言Longformer的预训练，并分别在每种特定语言子集上进行了24个单语模型的预训练，并在LEXTREME上对它们进行了评估。此外，我们在LexGLUE上对英语和多语言模型进行了评估。我们的多语言模型在LEXTREME上创造了新的最佳表现(SotA)，英语模型则在LexGLUE上表现最佳。我们将数据集、训练模型和代码全部释放在最开放的许可证下。

    Large, high-quality datasets are crucial for training Large Language Models (LLMs). However, so far, there are few datasets available for specialized critical domains such as law and the available ones are often only for the English language. We curate and release MultiLegalPile, a 689GB corpus in 24 languages from 17 jurisdictions. The MultiLegalPile corpus, which includes diverse legal data sources with varying licenses, allows for pretraining NLP models under fair use, with more permissive licenses for the Eurlex Resources and Legal mC4 subsets. We pretrain two RoBERTa models and one Longformer multilingually, and 24 monolingual models on each of the language-specific subsets and evaluate them on LEXTREME. Additionally, we evaluate the English and multilingual models on LexGLUE. Our multilingual models set a new SotA on LEXTREME and our English models on LexGLUE. We release the dataset, the trained models, and all of the code under the most open possible licenses.
    
[^87]: 深度学习在关系抽取领域的综述：最新进展与新方向

    A Comprehensive Survey on Deep Learning for Relation Extraction: Recent Advances and New Frontiers. (arXiv:2306.02051v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.02051](http://arxiv.org/abs/2306.02051)

    本文综述了深度学习在关系抽取领域的应用进展，提出了新的分类法，讨论了面临的挑战和应对的技术，并展望了未来的发展方向。

    

    关系抽取是指从非结构化文本中识别实体之间的关系。关系抽取是许多自然语言处理应用的基础，例如知识图谱补全、问答和信息检索。近年来，深度神经网络在关系抽取领域占据了主导地位，并取得了显着进展。随后，大规模预训练语言模型（PLMs）将关系抽取的最新技术推向了一个新的高度。本文综述了现有深度学习技术在关系抽取中的应用情况。首先，我们介绍了关系抽取资源，包括关系抽取数据集和评估指标。其次，我们提出了一个新的分类法，从文本表示、上下文编码和三元组预测三个方面对现有工作进行分类。第三，我们讨论了关系抽取面临的一些重要挑战，并总结了可能应对这些挑战的技术。最后，我们概述了一些具有潜在前景的未来方向和展望。

    Relation extraction (RE) involves identifying the relations between entities from unstructured texts. RE serves as the foundation for many natural language processing (NLP) applications, such as knowledge graph completion, question answering, and information retrieval. In recent years, deep neural networks have dominated the field of RE and made noticeable progress. Subsequently, the large pre-trained language models (PLMs) have taken the state-of-the-art of RE to a new level. This survey provides a comprehensive review of existing deep learning techniques for RE. First, we introduce RE resources, including RE datasets and evaluation metrics. Second, we propose a new taxonomy to categorize existing works from three perspectives (text representation, context encoding, and triplet prediction). Third, we discuss several important challenges faced by RE and summarize potential techniques to tackle these challenges. Finally, we outline some promising future directions and prospects in this 
    
[^88]: 机器学习流程的负责任设计模式

    Responsible Design Patterns for Machine Learning Pipelines. (arXiv:2306.01788v1 [cs.SE])

    [http://arxiv.org/abs/2306.01788](http://arxiv.org/abs/2306.01788)

    本文提出了一种综合框架，将负责任设计模式纳入机器学习流程中，以确保AI系统的伦理性和公正性。这个框架包括新的负责任AI设计模式，并指导AI开发人员、数据科学家和决策者在AI开发和部署中实施伦理实践。

    

    将道德实践整合到人工智能(AI)开发过程中对于确保AI的安全、公平和负责任操作至关重要。AI伦理涉及将伦理原则应用于AI系统的整个生命周期。这对于减轻与AI相关的潜在风险和伤害（如算法偏见）至关重要。为实现这一目标，机器学习流程中的负责任设计模式（RDPs）对于确保伦理和公平结果至关重要。在本文中，我们提出了一个综合框架，将RDPs纳入ML流程中，以减轻风险并确保AI系统的伦理发展。我们的框架包括新的负责任AI设计模式，这些模式通过对AI伦理和数据管理专家的调查确定，并通过专家反馈的实际情况进行验证。该框架指导AI开发人员、数据科学家和决策者在AI开发和部署中实施伦理实践。

    Integrating ethical practices into the AI development process for artificial intelligence (AI) is essential to ensure safe, fair, and responsible operation. AI ethics involves applying ethical principles to the entire life cycle of AI systems. This is essential to mitigate potential risks and harms associated with AI, such as algorithm biases. To achieve this goal, responsible design patterns (RDPs) are critical for Machine Learning (ML) pipelines to guarantee ethical and fair outcomes. In this paper, we propose a comprehensive framework incorporating RDPs into ML pipelines to mitigate risks and ensure the ethical development of AI systems. Our framework comprises new responsible AI design patterns for ML pipelines identified through a survey of AI ethics and data management experts and validated through real-world scenarios with expert feedback. The framework guides AI developers, data scientists, and policy-makers to implement ethical practices in AI development and deploy responsibl
    
[^89]: 基于虚拟力的平衡圆形装箱问题的群智能算法

    A Vitual-Force Based Swarm Algorithm for Balanced Circular Bin Packing Problems. (arXiv:2306.01021v1 [cs.AI])

    [http://arxiv.org/abs/2306.01021](http://arxiv.org/abs/2306.01021)

    本文描述了一种基于虚拟力系统的群智能算法，用以解决平衡圆形装箱问题，并在各种基准测试中得到验证，具有很好的解决效果。

    

    平衡圆形装箱问题涉及将给定数量的加权圆放置在圆形容器中，以最小化半径并满足平衡约束条件。本文描述了一种基于虚拟力系统的群智能算法，以解决平衡圆形装箱问题。在提出的方法中，对每个组件施加一组力，以考虑约束条件并使用动力学的基本原理最小化目标函数。提出的算法在各种平衡圆形装箱问题的基准测试中得到验证，并验证了具有高达300个圆的问题。报告的结果允许评估所提出的方法与文献中现有结果之间的有效性。

    Balanced circular bin packing problems consist in positioning a given number of weighted circles in order to minimize the radius of a circular container while satisfying equilibrium constraints. These problems are NP-hard, highly constrained and dimensional. This paper describes a swarm algorithm based on a virtual-force system in order to solve balanced circular bin packing problems. In the proposed approach, a system of forces is applied to each component allowing to take into account the constraints and minimizing the objective function using the fundamental principle of dynamics. The proposed algorithm is experimented and validated on benchmarks of various balanced circular bin packing problems with up to 300 circles. The reported results allow to assess the effectiveness of the proposed approach compared to existing results from the literature.
    
[^90]: ChatGPT在源代码分析中的应用分析

    Analysis of ChatGPT on Source Code. (arXiv:2306.00597v2 [cs.SE] UPDATED)

    [http://arxiv.org/abs/2306.00597](http://arxiv.org/abs/2306.00597)

    本论文探讨了大型语言模型 ChatGPT 在源代码分析中的应用，其将为程序员提供准确和高效的帮助，并在代码创建、文档编写、缺陷检测和代码重构等方面具有潜在的应用前景。

    

    本文探索了使用大型语言模型（LLMs）特别是 ChatGPT 在编程、源代码分析和代码生成中的应用。LLMs 和 ChatGPT 使用机器学习和人工智能技术构建，并为开发人员和程序员提供多种好处。尽管这些模型可以节省时间并提供高度准确的结果，但它们还不足以完全取代人类程序员。该论文研究了 LLMS 和 ChatGPT 在代码创建、代码文档、缺陷检测、重构等各个领域的潜在应用。该论文还建议，随着 LLM 和 ChatGPT 为编程社区提供无与伦比的好处，它们的使用预计将在未来增加。

    This paper explores the use of Large Language Models (LLMs) and in particular ChatGPT in programming, source code analysis, and code generation. LLMs and ChatGPT are built using machine learning and artificial intelligence techniques, and they offer several benefits to developers and programmers. While these models can save time and provide highly accurate results, they are not yet advanced enough to replace human programmers entirely. The paper investigates the potential applications of LLMs and ChatGPT in various areas, such as code creation, code documentation, bug detection, refactoring, and more. The paper also suggests that the usage of LLMs and ChatGPT is expected to increase in the future as they offer unparalleled benefits to the programming community.
    
[^91]: 使预训练模型具有可逆性：从参数到内存高效的微调

    Make Your Pre-trained Model Reversible: From Parameter to Memory Efficient Fine-Tuning. (arXiv:2306.00477v1 [cs.CL])

    [http://arxiv.org/abs/2306.00477](http://arxiv.org/abs/2306.00477)

    本研究尝试实现在预训练语言模型中运用可逆模型实现高效的微调，并发现在初始化微调时保留PLM的起点非常重要。

    

    预训练语言模型（PLM）的参数高效微调已经成为一种非常成功的方法，只需训练少量参数而不会降低性能，并随着PLM越来越大而成为事实上的学习范式。然而，现有的PEFT方法不具备内存效率，因为它们仍需要存储大部分中间激活值以便计算梯度，类似于微调。一个减少激活内存的有效方法是应用可逆模型，这样中间激活值就无需缓存，可以重新计算。然而，将PLM修改为它的可逆变体并进行PEFT并不是一件容易的事，因为可逆模型具有与当前发布的PLM不同的体系结构。本文首先调查现有PEFT方法成功的关键因素，认识到在初始化PEFT时保留PLM的起点是至关重要的。

    Parameter-efficient fine-tuning (PEFT) of pre-trained language models (PLMs) has emerged as a highly successful approach, with training only a small number of parameters without sacrificing performance and becoming the de-facto learning paradigm with the increasing size of PLMs. However, existing PEFT methods are not memory-efficient, because they still require caching most of the intermediate activations for the gradient calculation, akin to fine-tuning. One effective way to reduce the activation memory is to apply a reversible model, so the intermediate activations are not necessary to be cached and can be recomputed. Nevertheless, modifying a PLM to its reversible variant with PEFT is not straightforward, since the reversible model has a distinct architecture from the currently released PLMs. In this paper, we first investigate what is a key factor for the success of existing PEFT methods, and realize that it's essential to preserve the PLM's starting point when initializing a PEFT 
    
[^92]: MERT:带有大规模自监督训练的声学音乐理解模型

    MERT: Acoustic Music Understanding Model with Large-Scale Self-supervised Training. (arXiv:2306.00107v1 [cs.SD])

    [http://arxiv.org/abs/2306.00107](http://arxiv.org/abs/2306.00107)

    提出了一个带有大规模自监督训练的音乐理解模型MERT，利用了教师模型并采用了一种优于传统的语音和音频方法的组合方式。

    

    自监督学习（SSL）最近在视觉、文本和语音领域中已被证明是训练通用模型的一种很有前景的范例，对于跨越音乐领域的应用，尤其是对于调性和音高这样的特殊音乐知识的建模颇具挑战性。为了解决这一问题，我们提出了一个基于大规模自监督训练的声学音乐理解模型，即MERT。在我们的探索中，我们确定了更优秀的教师模型组合，这种组合方法在性能方面优于传统的语音和音频方法。

    Self-supervised learning (SSL) has recently emerged as a promising paradigm for training generalisable models on large-scale data in the fields of vision, text, and speech. Although SSL has been proven effective in speech and audio, its application to music audio has yet to be thoroughly explored. This is primarily due to the distinctive challenges associated with modelling musical knowledge, particularly its tonal and pitched characteristics of music. To address this research gap, we propose an acoustic Music undERstanding model with large-scale self-supervised Training (MERT), which incorporates teacher models to provide pseudo labels in the masked language modelling (MLM) style acoustic pre-training. In our exploration, we identified a superior combination of teacher models, which outperforms conventional speech and audio approaches in terms of performance. This combination includes an acoustic teacher based on Residual Vector Quantization - Variational AutoEncoder (RVQ-VAE) and a m
    
[^93]: 标准比评分更重要：面向多准则推荐的标准偏好感知轻量图卷积网络

    Criteria Tell You More than Ratings: Criteria Preference-Aware Light Graph Convolution for Effective Multi-Criteria Recommendation. (arXiv:2305.18885v2 [cs.SI] UPDATED)

    [http://arxiv.org/abs/2305.18885](http://arxiv.org/abs/2305.18885)

    本文提出了一种面向多准则推荐的标准偏好感知轻量图卷积网络，该方法结合了MC扩展图，可以准确地捕捉用户的标准偏好，并进一步将用户对各个标准的偏好合并到最终的推荐列表中。

    

    多准则推荐系统现在在广泛的电子商务领域中利用多准则 (MC) 评分信息，而深度学习中的图神经网络 (GNN) 已经被广泛应用于各种推荐系统的开发中。在这种情况下，本文首次尝试使用GNN辅助设计MC推荐系统。具体而言，我们提出了一种新颖的标准偏好感知轻量图卷积方法(CPA-LGC),可以准确捕捉用户的标准偏好以及复杂高阶连接中的协作信号。本文在MC扩展图上构建了一个能够将用户-物品MC评分转换为扩展二分图的MC扩展图，再进一步将标准重要性编码到图卷积过程中，并引入了一种新的标准偏好感知聚合方法来将用户对不同标准的偏好合并到最终的推荐列表中。

    The multi-criteria (MC) recommender system, which leverages MC rating information in a wide range of e-commerce areas, is ubiquitous nowadays. Surprisingly, although graph neural networks (GNNs) have been widely applied to develop various recommender systems due to GNN's high expressive capability in learning graph representations, it has been still unexplored how to design MC recommender systems with GNNs. In light of this, we make the first attempt towards designing a GNN-aided MC recommender system. Specifically, rather than straightforwardly adopting existing GNN-based recommendation methods, we devise a novel criteria preference-aware light graph convolution CPA-LGC method, which is capable of precisely capturing the criteria preference of users as well as the collaborative signal in complex high-order connectivities. To this end, we first construct an MC expansion graph that transforms user--item MC ratings into an expanded bipartite graph to potentially learn from the collaborat
    
[^94]: 目前为止我们所知道的：人工智能在非洲医疗保健领域中的应用

    What We Know So Far: Artificial Intelligence in African Healthcare. (arXiv:2305.18302v1 [cs.CY])

    [http://arxiv.org/abs/2305.18302](http://arxiv.org/abs/2305.18302)

    本文综述了人工智能算法在非洲医疗保健领域中的应用情况和如何利用人工智能在低资源环境下改善非洲医疗保健的可访问性，并讨论了采用人工智能面临的一些重要挑战和机遇。需要政府、私营部门、医疗保健提供者和国际组织协调一致地努力，创建可持续的人工智能解决方案，满足非洲医疗保健系统独特的需求。

    

    非洲的医疗保健问题受到许多因素的影响，包括贫困、基础设施缺乏和资金不足等。然而，应用于医疗保健领域的人工智能（AI）具有潜力通过提高诊断的准确性和效率、使疾病更早地被发现、支持个性化药物的发布来改变非洲的医疗保健状况。本文综述了目前人工智能算法在改善诊断、治疗和疾病监测方面的应用情况，以及如何利用人工智能在低资源环境下改善非洲医疗保健的可访问性，并讨论了采用人工智能面临的一些重要挑战和机遇。因此，需要政府、私营部门、医疗保健提供者和国际组织协调一致地努力，创建可持续的人工智能解决方案，满足非洲医疗保健系统独特的需求。

    Healthcare in Africa is a complex issue influenced by many factors including poverty, lack of infrastructure, and inadequate funding. However, Artificial intelligence (AI) applied to healthcare, has the potential to transform healthcare in Africa by improving the accuracy and efficiency of diagnosis, enabling earlier detection of diseases, and supporting the delivery of personalized medicine. This paper reviews the current state of how AI Algorithms can be used to improve diagnostics, treatment, and disease monitoring, as well as how AI can be used to improve access to healthcare in Africa as a low-resource setting and discusses some of the critical challenges and opportunities for its adoption. As such, there is a need for a well-coordinated effort by the governments, private sector, healthcare providers, and international organizations to create sustainable AI solutions that meet the unique needs of the African healthcare system.
    
[^95]: InDL: 基于视错觉的图中逻辑解释新数据集和基准的研究

    InDL: A New Datasets and Benchmark for In-Diagram Logic Interpreting based on Visual Illusion. (arXiv:2305.17716v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2305.17716](http://arxiv.org/abs/2305.17716)

    本文提出了一个基于视错觉的独特数据集InDL，用于测试和评估深度学习模型的图中逻辑解释能力。利用几何光学视错觉，建立可比性框架用于阐明模型可能存在的缺陷和提供改进模型的洞察力。

    

    本文提出了一种新的方法来评估深度学习模型在图中逻辑解释方面的能力。通过利用有趣领域的视错觉，我们建立了一个独特的数据集InDL，旨在严格测试和基准这些模型。我们利用六个经典的几何视觉错觉，创建了一个人类和机器视觉感知的可比性框架。这种方法提供了一个可量化的衡量模型的方法，阐明了可能存在的缺陷，并提供了改进模型的行动洞察力。

    This paper introduces a novel approach to evaluating deep learning models' capacity for in-diagram logic interpretation. Leveraging the intriguing realm of visual illusions, we establish a unique dataset, InDL, designed to rigorously test and benchmark these models. Deep learning has witnessed remarkable progress in domains such as computer vision and natural language processing. However, models often stumble in tasks requiring logical reasoning due to their inherent 'black box' characteristics, which obscure the decision-making process. Our work presents a new lens to understand these models better by focusing on their handling of visual illusions -- a complex interplay of perception and logic. We utilize six classic geometric optical illusions to create a comparative framework between human and machine visual perception. This methodology offers a quantifiable measure to rank models, elucidating potential weaknesses and providing actionable insights for model improvements. Our experim
    
[^96]: GPT是否会产生更不准确的翻译?

    Do GPTs Produce Less Literal Translations?. (arXiv:2305.16806v1 [cs.CL])

    [http://arxiv.org/abs/2305.16806](http://arxiv.org/abs/2305.16806)

    本研究比较了GPT和NMT生成翻译的文字积极度差异，发现GPT翻译更不准确，但在MT质量评估指标上表现出相似或更好的分数。

    

    大型语言模型（LLMs），如GPT-3，已经成为通用语言模型，能够处理许多自然语言生成或理解任务。在机器翻译（MT）任务中，已有多项研究探索利用few-shot提示机制从LLMs中引出更好的翻译。然而，人们相对较少地关注这种翻译与标准神经机器翻译（NMT）模型生成翻译的质量差异。本研究从文字对齐和单调性等方面，比较了GPT和NMT生成翻译的文本文字积极度，发现GPT从英语（E-X）翻译的文本更不准确，但在MT质量评估指标上表现出相似或更好的分数。我们证明这一结果在人工评估中也得到了验证。同时，当翻译句子长度增加时，这种差别就尤为显著。

    Large Language Models (LLMs) such as GPT-3 have emerged as general-purpose language models capable of addressing many natural language generation or understanding tasks. On the task of Machine Translation (MT), multiple works have investigated few-shot prompting mechanisms to elicit better translations from LLMs. However, there has been relatively little investigation on how such translations differ qualitatively from the translations generated by standard Neural Machine Translation (NMT) models. In this work, we investigate these differences in terms of the literalness of translations produced by the two systems. Using literalness measures involving word alignment and monotonicity, we find that translations out of English (E-X) from GPTs tend to be less literal, while exhibiting similar or better scores on MT quality metrics. We demonstrate that this finding is borne out in human evaluations as well. We then show that these differences are especially pronounced when translating senten
    
[^97]: ChipGPT: 远离自然语言硬件设计还有多远

    ChipGPT: How far are we from natural language hardware design. (arXiv:2305.14019v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2305.14019](http://arxiv.org/abs/2305.14019)

    这篇论文介绍了ChipGPT，一个自动化设计环境，它利用大型语言模型从自然语言规范生成硬件逻辑设计，并展示了与人工设计性能相媲美的结果，且可节省超过75％的编码时间。

    

    随着大型语言模型（LLMs）如ChatGPT展示了前所未有的机器智能，它在通过自然语言交互来协助硬件工程师实现更高效的逻辑设计方面也表现出极佳的性能。为了评估LLMs协助硬件设计过程的潜力，本文尝试演示一个自动化设计环境，该环境利用LLMs从自然语言规范生成硬件逻辑设计。为了实现更易用且更高效的芯片开发流程，我们提出了一种基于LLMs的可扩展的四阶段零代码逻辑设计框架，无需重新训练或微调。首先，演示版本ChipGPT通过为LLM生成提示开始，然后产生初始Verilog程序。 其次，输出管理器纠正和优化这些程序，然后将它们收集到最终的设计空间中。最后，ChipGPT将在此空间中搜索以选择符合目标指标的最优设计。评估表明，由ChipGPT设计的逻辑电路的性能与人工设计的性能相当，并且整个过程节省了超过75％的编码时间。

    As large language models (LLMs) like ChatGPT exhibited unprecedented machine intelligence, it also shows great performance in assisting hardware engineers to realize higher-efficiency logic design via natural language interaction. To estimate the potential of the hardware design process assisted by LLMs, this work attempts to demonstrate an automated design environment that explores LLMs to generate hardware logic designs from natural language specifications. To realize a more accessible and efficient chip development flow, we present a scalable four-stage zero-code logic design framework based on LLMs without retraining or finetuning. At first, the demo, ChipGPT, begins by generating prompts for the LLM, which then produces initial Verilog programs. Second, an output manager corrects and optimizes these programs before collecting them into the final design space. Eventually, ChipGPT will search through this space to select the optimal design under the target metrics. The evaluation sh
    
[^98]: 多尺度高效交叉空间学习的注意力模块

    Efficient Multi-Scale Attention Module with Cross-Spatial Learning. (arXiv:2305.13563v1 [cs.CV])

    [http://arxiv.org/abs/2305.13563](http://arxiv.org/abs/2305.13563)

    本文提出了一种高效的多尺度注意力模块，重塑部分通道为批处理维度并将通道分组，以增加空间语义分布性，同时通过交叉维度交互聚合两个并行分支的输出特征。实验表明EMA可以高效地优化性能，比之前的最新方法更好。

    

    本文提出了一种新颖的高效多尺度注意力（EMA）模块，旨在保留每个通道的信息和减少计算开销。该模块将部分通道重塑为批处理维度，并将通道分组成多个子特征，从而使空间语义特征在每个特征组中分布良好。此外，该模块通过交叉维度交互进一步聚合了两个并行分支的输出特征，以捕捉像素级别的成对关系。实验表明，EMA可以在多个计算机视觉任务中比之前的最新方法更高效地优化性能。

    Remarkable effectiveness of the channel or spatial attention mechanisms for producing more discernible feature representation are illustrated in various computer vision tasks. However, modeling the cross-channel relationships with channel dimensionality reduction may bring side effect in extracting deep visual representations. In this paper, a novel efficient multi-scale attention (EMA) module is proposed. Focusing on retaining the information on per channel and decreasing the computational overhead, we reshape the partly channels into the batch dimensions and group the channel dimensions into multiple sub-features which make the spatial semantic features well-distributed inside each feature group. Specifically, apart from encoding the global information to re-calibrate the channel-wise weight in each parallel branch, the output features of the two parallel branches are further aggregated by a cross-dimension interaction for capturing pixel-level pairwise relationship. We conduct exten
    
[^99]: 受物理启发的方法理解高斯过程

    Physics Inspired Approaches Towards Understanding Gaussian Processes. (arXiv:2305.10748v1 [cs.LG])

    [http://arxiv.org/abs/2305.10748](http://arxiv.org/abs/2305.10748)

    本文利用物理学方法分析了高斯过程模型的损失景观，提出了考虑更广泛的ν使得性能更佳的优化方法，同时提供了一种用于评估GP集成效果的方法和基于损失领域的物理属性的投票方法。

    

    通过内核可以将先验有关潜在函数的信念纳入高斯过程(GP)中以形成归纳偏置，但除了内核选择外，GP模型的决策过程仍然很难理解。本文利用物理学方法对GP模型的损失景观进行了分析，演示了Matern内核的ν连续性，并概述了梯度场关键点的灾变理论方面。通过将ν直接包含在Matern内核的超参数优化中，我们发现，尽管在文献中ν的典型值增加了计算速度，但其在性能方面远非最佳。我们还提供了一种事先评估GP集合效果的方法，并讨论了基于损失景观物理属性的各种投票方法。这些方法的实用性在多种合成和真实数据集上得到了证明。我们的发现提供了对GP模型决策过程的深入理解，并为超参数优化和模型选择提供了新的洞察。

    Prior beliefs about the latent function to shape inductive biases can be incorporated into a Gaussian Process (GP) via the kernel. However, beyond kernel choices, the decision-making process of GP models remains poorly understood. In this work, we contribute an analysis of the loss landscape for GP models using methods from physics. We demonstrate $\nu$-continuity for Matern kernels and outline aspects of catastrophe theory at critical points in the loss landscape. By directly including $\nu$ in the hyperparameter optimisation for Matern kernels, we find that typical values of $\nu$ are far from optimal in terms of performance, yet prevail in the literature due to the increased computational speed. We also provide an a priori method for evaluating the effect of GP ensembles and discuss various voting approaches based on physical properties of the loss landscape. The utility of these approaches is demonstrated for various synthetic and real datasets. Our findings provide an enhanced und
    
[^100]: 架起桥梁：通过后处理技术增强合成数据的实用性

    Bridging the Gap: Enhancing the Utility of Synthetic Data via Post-Processing Techniques. (arXiv:2305.10118v1 [cs.CV])

    [http://arxiv.org/abs/2305.10118](http://arxiv.org/abs/2305.10118)

    本文介绍了一种利用生成对抗网络生成合成数据集，并通过三种新颖的后处理技术改进合成数据集质量和多样性的方法。作者称其为Gap Filler (GaFi)流程并在真实图像上进行评估。

    

    获取和注释用于训练深度学习模型的合适数据集是具有挑战性的。生成模型已经成为一种有前途的解决方案，可生成替代或增强现实世界数据的合成数据集。尽管如此，合成数据的有效性受到其不能完全捕捉现实世界数据的复杂性和多样性的限制。为了解决这个问题，我们探索使用生成对抗网络生成用于训练分类器的合成数据集，随后在真实图像上进行评估。为了改进合成数据集的质量和多样性，我们提出了三种新颖的后处理技术：动态样本过滤，动态数据集回收和扩展技巧。此外，我们引入了一种名为“ Gap Filler (GaFi)”的流程，在最佳和协调的方式下应用这些技术，以最大程度地提高分类的准确性。

    Acquiring and annotating suitable datasets for training deep learning models is challenging. This often results in tedious and time-consuming efforts that can hinder research progress. However, generative models have emerged as a promising solution for generating synthetic datasets that can replace or augment real-world data. Despite this, the effectiveness of synthetic data is limited by their inability to fully capture the complexity and diversity of real-world data. To address this issue, we explore the use of Generative Adversarial Networks to generate synthetic datasets for training classifiers that are subsequently evaluated on real-world images. To improve the quality and diversity of the synthetic dataset, we propose three novel post-processing techniques: Dynamic Sample Filtering, Dynamic Dataset Recycle, and Expansion Trick. In addition, we introduce a pipeline called Gap Filler (GaFi), which applies these techniques in an optimal and coordinated manner to maximise classifica
    
[^101]: 冷启动问题：无监督的类别发现方法。

    Cold PAWS: Unsupervised class discovery and the cold-start problem. (arXiv:2305.10071v1 [cs.CV])

    [http://arxiv.org/abs/2305.10071](http://arxiv.org/abs/2305.10071)

    本文提出了一种新方法，通过结合自我监督、聚类和流形学习技术，解决冷启动或无监督选择标记问题，并在多个公共数据集上进行了测试，获得了更好的性能。

    

    在许多机器学习应用中，标记数据集常常是一项艰苦且耗时的任务。虽然研究表明半监督学习技术可以在计算机视觉领域中使用非常少的标签实现高准确性，但很少有人关注如何选择数据集中的图像进行标记。本文提出了一种基于自监督学习、聚类和流形学习技术的新方法，以解决首次选择信息图像子集进行标记的挑战，即冷启动或无监督选择标记问题。我们使用几个公共数据集（包括CIFAR10、Imagenette、DeepWeeds和EuroSAT）测试我们的方法，并观察到当使用我们的标签选择策略时，与随机抽样相比，在监督和半监督学习策略均表现出更好的性能。我们还在d方面获得了更优秀的性能

    In many machine learning applications, labeling datasets can be an arduous and time-consuming task. Although research has shown that semi-supervised learning techniques can achieve high accuracy with very few labels within the field of computer vision, little attention has been given to how images within a dataset should be selected for labeling. In this paper, we propose a novel approach based on well-established self-supervised learning, clustering, and manifold learning techniques that address this challenge of selecting an informative image subset to label in the first instance, which is known as the cold-start or unsupervised selective labelling problem. We test our approach using several publicly available datasets, namely CIFAR10, Imagenette, DeepWeeds, and EuroSAT, and observe improved performance with both supervised and semi-supervised learning strategies when our label selection strategy is used, in comparison to random sampling. We also obtain superior performance for the d
    
[^102]: 见证就是信仰：脑启发模块化训练促进机理诠释

    Seeing is Believing: Brain-Inspired Modular Training for Mechanistic Interpretability. (arXiv:2305.08746v2 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2305.08746](http://arxiv.org/abs/2305.08746)

    BIMT方法使得神经网络更加模块化和可诠释，并且能够直接展示模块化结构，为许多简单任务提供了有用的信息，并可以补充当前的机理解释策略。

    

    我们提出了一种名为脑启发模块化训练（Brain-Inspired Modular Training, BIMT）的方法，旨在使神经网络更加模块化和可诠释。BIMT从大脑受启发，将神经元嵌入到几何空间中，并通过成本与神经元连接长度成正比的方式增强损失函数。我们证明了BIMT可以为许多简单任务发现有用的模块化神经网络，揭示了符号公式中的组合结构、可解释的决策边界和分类特征，以及算法数据集中的数学结构。直接眼睛看到模块的能力可以补充当前的机理解释策略，例如探针，干预或凝视所有权重。

    We introduce Brain-Inspired Modular Training (BIMT), a method for making neural networks more modular and interpretable. Inspired by brains, BIMT embeds neurons in a geometric space and augments the loss function with a cost proportional to the length of each neuron connection. We demonstrate that BIMT discovers useful modular neural networks for many simple tasks, revealing compositional structures in symbolic formulas, interpretable decision boundaries and features for classification, and mathematical structure in algorithmic datasets. The ability to directly see modules with the naked eye can complement current mechanistic interpretability strategies such as probes, interventions or staring at all weights.
    
[^103]: 基于随机池化的可证明多实例深度AUC最大化方法

    Provable Multi-instance Deep AUC Maximization with Stochastic Pooling. (arXiv:2305.08040v1 [cs.LG])

    [http://arxiv.org/abs/2305.08040](http://arxiv.org/abs/2305.08040)

    本文提出了在多实例学习中使用深度AUC最大化（DAM）的方法，并根据包含大量实例的情况下训练的计算挑战，提出了一种基于方差减少的随机池化方法，使得只需对每个包进行少量采样即可计算MIDAM模型，提高了效率和准确性。

    

    本文提出了一种深度AUC最大化（DAM）的新型应用，用于多实例学习（MIL），其中将单个类标签分配给一组实例（例如，患者的多个CT扫描的多个2D切片）。我们在DAM的背景下解决了MIL中被忽略但非常重要的计算挑战，即包大小过大，无法在反向传播时加载到GPU内存中，这是MIL标准池化方法所必需的。为了解决这个问题，我们提出了一种基于方差减少的随机池化方法，这种方法可以将关于汇聚预测的损失函数构造为多级组合函数。通过综合随机组合优化和非凸极小最大优化技术，我们提出了一种统一且可证明的多实例DAM（MIDAM）算法，其使用随机平滑最大池化或随机注意力池化，仅对每个包对应的实例进行少量采样来计算 sto。

    This paper considers a novel application of deep AUC maximization (DAM) for multi-instance learning (MIL), in which a single class label is assigned to a bag of instances (e.g., multiple 2D slices of a CT scan for a patient). We address a neglected yet non-negligible computational challenge of MIL in the context of DAM, i.e., bag size is too large to be loaded into {GPU} memory for backpropagation, which is required by the standard pooling methods of MIL. To tackle this challenge, we propose variance-reduced stochastic pooling methods in the spirit of stochastic optimization by formulating the loss function over the pooled prediction as a multi-level compositional function. By synthesizing techniques from stochastic compositional optimization and non-convex min-max optimization, we propose a unified and provable muli-instance DAM (MIDAM) algorithm with stochastic smoothed-max pooling or stochastic attention-based pooling, which only samples a few instances for each bag to compute a sto
    
[^104]: 语义嵌入深度神经网络：一种提升多标签图像分类性能的通用方法。

    Semantic Embedded Deep Neural Network: A Generic Approach to Boost Multi-Label Image Classification Performance. (arXiv:2305.05228v1 [cs.CV])

    [http://arxiv.org/abs/2305.05228](http://arxiv.org/abs/2305.05228)

    本研究提出了一种通用的语义嵌入深度神经网络，通过空间感知的语义特征和基于通道的注意力模型来提高多标签预测的模型性能，平均相对改进达到15.27%。

    

    精细的多标签分类模型在亚马逊生产功能中具有广泛的应用，例如基于视觉的标签预测，从时尚属性检测到品牌识别。实现这些分类任务的一个挑战是野外视觉背景信号，其中包含混淆模型的无关像素，使模型难以专注于感兴趣区域并根据该特定区域进行预测。在本文中，我们介绍了一种通用的语义嵌入深度神经网络，应用空间感知的语义特征，并结合基于通道的注意力模型来利用定位引导，以提高多标签预测的模型性能。与基线方法相比，我们观察到所有标签的AUC得分的平均相对改进为15.27%。核心实验和消融研究涉及对Instagram时尚服装的多标签时尚属性分类进行的。

    Fine-grained multi-label classification models have broad applications in Amazon production features, such as visual based label predictions ranging from fashion attribute detection to brand recognition. One challenge to achieve satisfactory performance for those classification tasks in real world is the wild visual background signal that contains irrelevant pixels which confuses model to focus onto the region of interest and make prediction upon the specific region. In this paper, we introduce a generic semantic- embedding deep neural network to apply the spatial awareness semantic feature incorporating a channel- wise attention based model to leverage the localization guidance to boost model performance for multi- label prediction. We observed an Avg.relative improvement of 15.27% in terms of AUC score across all labels compared to the baseline approach. Core experiment and ablation studies involve multi-label fashion attribute classification performed on Instagram fashion apparels' 
    
[^105]: FishRecGAN：用于鱼眼图像矫正和相机内参和畸变参数标定的端到端GAN网络

    FishRecGAN: An End to End GAN Based Network for Fisheye Rectification and Calibration. (arXiv:2305.05222v1 [cs.CV])

    [http://arxiv.org/abs/2305.05222](http://arxiv.org/abs/2305.05222)

    FishRecGAN提供了一种端到端的深度学习方法，以矫正鱼眼图像并同时校准相机内参和畸变参数。其快速校正网络具有良好的分辨率和鲁棒性，适用于摄像机型监控设备中的恒定标定，并使用大量合成数据集进行训练和验证，表现出了高分辨率的鲁棒性和显著的峰值信噪比。

    

    我们提出了一种端到端的深度学习方法，以矫正鱼眼图像并同时校准相机内参和畸变参数。我们的方法由两部分组成：使用Pix2Pix GAN和Wasserstein GAN（W-Pix2PixGAN）开发的Quick Image Rectification模块，以及使用CNN架构的Calibration模块。我们的快速校正网络具有良好的分辨率和鲁棒性，适用于摄像机型监控设备中的恒定标定。为了实现高质量的标定，我们使用从Quick Image Rectification模块中输出的直线特征作为指导样本传递给Calibration模块，以学习校正前后的几何关系。我们使用大量合成数据集来训练和验证我们的方法，并应用于透视图像数据集，表现出了高分辨率的鲁棒性和显著的峰值信噪比。

    We propose an end-to-end deep learning approach to rectify fisheye images and simultaneously calibrate camera intrinsic and distortion parameters. Our method consists of two parts: a Quick Image Rectification Module developed with a Pix2Pix GAN and Wasserstein GAN (W-Pix2PixGAN), and a Calibration Module with a CNN architecture. Our Quick Rectification Network performs robust rectification with good resolution, making it suitable for constant calibration in camera-based surveillance equipment. To achieve high-quality calibration, we use the straightened output from the Quick Rectification Module as a guidance-like semantic feature map for the Calibration Module to learn the geometric relationship between the straightened feature and the distorted feature. We train and validate our method with a large synthesized dataset labeled with well-simulated parameters applied to a perspective image dataset. Our solution has achieved robust performance in high-resolution with a significant PSNR v
    
[^106]: 针对时尚检测的不平衡标签样本分布的数据高效训练

    Data Efficient Training with Imbalanced Label Sample Distribution for Fashion Detection. (arXiv:2305.04379v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2305.04379](http://arxiv.org/abs/2305.04379)

    本文提出了一种最先进的加权目标函数，用于提高多标签分类中深度神经网络（DNN）针对长尾数据分布的性能，并通过对时尚服装的图像属性分类的实验，取得了良好的性能。

    

    多标签分类模型在电子商务中有广泛的应用，包括基于视觉的标签预测以及基于语言的情感分类。实现这些任务的一个主要难点是数据分布的显著不平衡。为了解决这个问题，本文探索了更多的数据高效模型训练技术，并提出了一种最先进的加权目标函数，用于提高多标签分类中深度神经网络（DNN）针对长尾数据分布的性能。我们的实验涉及时尚服装的基于图像的属性分类，并且结果表明，新的加权目标函数相较于传统方法具有良好的性能。

    Multi-label classification models have a wide range of applications in E-commerce, including visual-based label predictions and language-based sentiment classifications. A major challenge in achieving satisfactory performance for these tasks in the real world is the notable imbalance in data distribution. For instance, in fashion attribute detection, there may be only six 'puff sleeve' clothes among 1000 products in most E-commerce fashion catalogs. To address this issue, we explore more data-efficient model training techniques rather than acquiring a huge amount of annotations to collect sufficient samples, which is neither economic nor scalable. In this paper, we propose a state-of-the-art weighted objective function to boost the performance of deep neural networks (DNNs) for multi-label classification with long-tailed data distribution. Our experiments involve image-based attribute classification of fashion apparels, and the results demonstrate favorable performance for the new weig
    
[^107]: SI-LSTM: 用于对话情感识别的说话人混合长短期记忆和跨模态注意力机制

    SI-LSTM: Speaker Hybrid Long-short Term Memory and Cross Modal Attention for Emotion Recognition in Conversation. (arXiv:2305.03506v1 [cs.CL])

    [http://arxiv.org/abs/2305.03506](http://arxiv.org/abs/2305.03506)

    SI-LSTM是一种用于对话情感识别的循环结构，可以追踪不同说话人的情感状态，从而增强对话情感学习。

    

    跨模态的对话情感识别对于智能医疗、对话人工智能和聊天历史观点挖掘等应用至关重要。本文提出了一种基于说话人信息增强长短期记忆（SI-LSTM）的循环结构，可以追踪不同说话人的情感状态，从而增强对话情感学习。

    Emotion Recognition in Conversation~(ERC) across modalities is of vital importance for a variety of applications, including intelligent healthcare, artificial intelligence for conversation, and opinion mining over chat history. The crux of ERC is to model both cross-modality and cross-time interactions throughout the conversation. Previous methods have made progress in learning the time series information of conversation while lacking the ability to trace down the different emotional states of each speaker in a conversation. In this paper, we propose a recurrent structure called Speaker Information Enhanced Long-Short Term Memory (SI-LSTM) for the ERC task, where the emotional states of the distinct speaker can be tracked in a sequential way to enhance the learning of the emotion in conversation. Further, to improve the learning of multimodal features in ERC, we utilize a cross-modal attention component to fuse the features between different modalities and model the interaction of the 
    
[^108]: 一种基于广义学习系统的证据实时多模态故障诊断方法

    An Evidential Real-Time Multi-Mode Fault Diagnosis Approach Based on Broad Learning System. (arXiv:2305.00169v1 [cs.LG])

    [http://arxiv.org/abs/2305.00169](http://arxiv.org/abs/2305.00169)

    本文提出了一种基于证据推理算法和广义学习系统的实时多模态故障诊断方法，该方法在更新模型参数和计算效率方面具有优势，并且在基准数据集上取得了比现有方法更好的故障诊断性能。

    

    由于多种工况表现出的非高斯、多模态和中心漂移特征，故障诊断是工业界研究的重要领域。目前，数据驱动方法是该领域的主要研究方向，但它们在连续故障分类和故障分类器参数更新方面提出了挑战，尤其在多种操作模式和实时环境中。因此，实现工业系统的实时多模态故障诊断是一个迫切的问题。为了解决这个问题，本文提出了一种新的方法，利用证据推理（ER）算法来融合信息并合并来自不同基分类器的输出。这些基分类器使用广义学习系统（BLS）开发，以提高良好的故障诊断性能。此外，在这种方法中，采用伪标签学习方法来实时更新模型参数。为了证明所提出方法的有效性，我们在基准数据集上进行实验并与现有方法进行比较。结果表明，我们提出的方法在准确性和计算效率方面优于现有方法。

    Fault diagnosis is a crucial area of research in the industry due to diverse operating conditions that exhibit non-Gaussian, multi-mode, and center-drift characteristics. Currently, data-driven approaches are the main focus in the field, but they pose challenges for continuous fault classification and parameter updates of fault classifiers, particularly in multiple operating modes and real-time settings. Therefore, a pressing issue is to achieve real-time multi-mode fault diagnosis for industrial systems. To address this problem, this paper proposes a novel approach that utilizes an evidence reasoning (ER) algorithm to fuse information and merge outputs from different base classifiers. These base classifiers are developed using a broad learning system (BLS) to improve good fault diagnosis performance. Moreover, in this approach, the pseudo-label learning method is employed to update model parameters in real-time. To demonstrate the effectiveness of the proposed approach, we perform exp
    
[^109]: ImageCaptioner$^2$: 针对图像字幕偏差放大评估的图像字幕生成器

    ImageCaptioner$^2$: Image Captioner for Image Captioning Bias Amplification Assessment. (arXiv:2304.04874v1 [cs.CV])

    [http://arxiv.org/abs/2304.04874](http://arxiv.org/abs/2304.04874)

    本文提出了一种新的图像字幕生成器 ImageCaptioner$^2$ ，用于针对图像字幕偏差放大进行评估。

    

    大多数预训练学习系统都会受到偏差的影响，这通常来自数据、模型或两者。衡量和量化偏差及其来源是一项具有挑战性的任务，并在图像字幕生成方面得到了广泛的研究。然而，我们观察到现有评估指标在包括视觉信号方面存在一定不一致性。本文提出了一种新的针对图像字幕生成的偏差评估指标，称为 ImageCaptioner$^2$。与现有方法仅基于生成的字幕评估图像字幕算法不同，ImageCaptioner$^2$在测量偏差时考虑图像。我们还设计了一种公式来作为基于提示的图像字幕生成来测量生成字幕的偏差，而不是使用传统方法。

    Most pre-trained learning systems are known to suffer from bias, which typically emerges from the data, the model, or both. Measuring and quantifying bias and its sources is a challenging task and has been extensively studied in image captioning. Despite the significant effort in this direction, we observed that existing metrics lack consistency in the inclusion of the visual signal. In this paper, we introduce a new bias assessment metric, dubbed $ImageCaptioner^2$, for image captioning. Instead of measuring the absolute bias in the model or the data, $ImageCaptioner^2$ pay more attention to the bias introduced by the model w.r.t the data bias, termed bias amplification. Unlike the existing methods, which only evaluate the image captioning algorithms based on the generated captions only, $ImageCaptioner^2$ incorporates the image while measuring the bias. In addition, we design a formulation for measuring the bias of generated captions as prompt-based image captioning instead of using 
    
[^110]: oBERTa: 通过改进初始化、蒸馏和剪枝来提高稀疏迁移学习

    oBERTa: Improving Sparse Transfer Learning via improved initialization, distillation, and pruning regimes. (arXiv:2303.17612v1 [cs.CL])

    [http://arxiv.org/abs/2303.17612](http://arxiv.org/abs/2303.17612)

    oBERTa是一组易于使用的语言模型，通过改进初始化、蒸馏、剪枝等技术，可以在不需要模型压缩方面的专业知识的情况下提高稀疏迁移学习的效率和准确性。

    

    本文介绍了oBERTa语言模型的范围，它是一组易于使用的语言模型，允许自然语言处理（NLP）从业者在不需要模型压缩方面的专业知识的情况下获得3.8到24.3倍的更快速的模型。oBERTa扩展了现有的剪枝、知识蒸馏和量化工作，并利用冻结的嵌入来改进知识蒸馏，并改进模型初始化，以在广泛的传递任务上提供更高的准确性。在生成oBERTa时，我们探索了高度优化的RoBERTa与BERT在预训练和微调期间剪枝方面的不同之处，并发现它在微调期间不太适合压缩。我们探索了oBERTa在七个具有代表性的NLP任务上的使用，并发现改进的压缩技术使得经过剪枝的oBERTa模型能够匹配BERTBASE的性能，并超过SQUAD V1.1问答数据的Prune OFA Large的性能。

    In this paper, we introduce the range of oBERTa language models, an easy-to-use set of language models, which allows Natural Language Processing (NLP) practitioners to obtain between 3.8 and 24.3 times faster models without expertise in model compression. Specifically, oBERTa extends existing work on pruning, knowledge distillation, and quantization and leverages frozen embeddings to improve knowledge distillation, and improved model initialization to deliver higher accuracy on a a broad range of transfer tasks. In generating oBERTa, we explore how the highly optimized RoBERTa differs from the BERT with respect to pruning during pre-training and fine-tuning and find it less amenable to compression during fine-tuning. We explore the use of oBERTa on a broad seven representative NLP tasks and find that the improved compression techniques allow a pruned oBERTa model to match the performance of BERTBASE and exceed the performance of Prune OFA Large on the SQUAD V1.1 Question Answering data
    
[^111]: 什么让数据适合于局部连接神经网络？一种基于量子纠缠的必要且充分条件

    What Makes Data Suitable for a Locally Connected Neural Network? A Necessary and Sufficient Condition Based on Quantum Entanglement. (arXiv:2303.11249v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.11249](http://arxiv.org/abs/2303.11249)

    本文通过采用量子物理学的理论工具，提出了一种判定数据适合于局部连接神经网络的必要且充分条件，并导出了一种相应的预处理方法。

    

    关于数据分布适用于深度学习的问题是一个基本的开放性问题。本文采用来自量子物理学的理论工具，针对包括卷积神经网络、循环神经网络和局部自注意力模型在内的广泛的局部连接神经网络，解决了这个问题。我们的主要理论结果是，在某些特征的规范划分下，当数据分布接受低量子纠缠时，特定的局部连接神经网络才能够准确地预测该数据分布。作为本结果的实际应用，我们导出了一种预处理方法，以增强数据分布适合局部连接神经网络的性能。在各种数据集上对广泛的模型进行实验，证明了我们的发现。我们希望我们使用量子纠缠将鼓励形式推理的物理工具来进一步采用。

    The question of what makes a data distribution suitable for deep learning is a fundamental open problem. Focusing on locally connected neural networks (a prevalent family of architectures that includes convolutional and recurrent neural networks as well as local self-attention models), we address this problem by adopting theoretical tools from quantum physics. Our main theoretical result states that a certain locally connected neural network is capable of accurate prediction over a data distribution if and only if the data distribution admits low quantum entanglement under certain canonical partitions of features. As a practical application of this result, we derive a preprocessing method for enhancing the suitability of a data distribution to locally connected neural networks. Experiments with widespread models over various datasets demonstrate our findings. We hope that our use of quantum entanglement will encourage further adoption of tools from physics for formally reasoning about 
    
[^112]: 基于图神经粗糙微分方程的交通预测方法

    Graph Neural Rough Differential Equations for Traffic Forecasting. (arXiv:2303.10909v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.10909](http://arxiv.org/abs/2303.10909)

    本文提出一种基于图神经粗糙微分方程的交通预测方法(STG-NRDE)，通过两个NRDE进行时空处理并组合起来构成一个框架。实验结果表明，在6个基准数据集和27个基线模型上表现最佳。

    

    交通预测是机器学习中最受欢迎的时空任务之一。目前广泛使用的方法是将图卷积网络和循环神经网络组合起来进行时空处理。本文提出了一种新的时空图神经粗糙微分方程（STG-NRDE）方法。我们利用神经粗糙微分方程（NRDE）的对数签名变换将时间序列数据转换为较短的特征向量序列，并将其扩展应用于时空处理。我们将两种NRDE设计成一个框架用于交通预测。实验数据集包括6个基准数据集和27个基线模型。实验结果表明，STG-NRDE在所有情况下都表现出最佳准确性，胜过这27个基线模型。

    Traffic forecasting is one of the most popular spatio-temporal tasks in the field of machine learning. A prevalent approach in the field is to combine graph convolutional networks and recurrent neural networks for the spatio-temporal processing. There has been fierce competition and many novel methods have been proposed. In this paper, we present the method of spatio-temporal graph neural rough differential equation (STG-NRDE). Neural rough differential equations (NRDEs) are a breakthrough concept for processing time-series data. Their main concept is to use the log-signature transform to convert a time-series sample into a relatively shorter series of feature vectors. We extend the concept and design two NRDEs: one for the temporal processing and the other for the spatial processing. After that, we combine them into a single framework. We conduct experiments with 6 benchmark datasets and 27 baselines. STG-NRDE shows the best accuracy in all cases, outperforming all those 27 baselines 
    
[^113]: 基于循环神经网络和无模型强化学习的未知环境中主动假设检验

    Active hypothesis testing in unknown environments using recurrent neural networks and model free reinforcement learning. (arXiv:2303.10623v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2303.10623](http://arxiv.org/abs/2303.10623)

    该论文提出了一种基于深度强化学习和监督学习的方法，用于在完全未知的环境中进行主动顺序假设检验，该方法在有限和无限时间问题中表现出与Chernoff检验相当甚至更好的性能。

    

    该论文提出了一种结合深度强化学习和监督学习的方法，用于完全未知的环境中的主动顺序假设检验问题。我们对先验概率、行动和观察集、以及观察生成过程不做任何假设。我们的方法可以用于任何环境，即使它有连续的观察或行动，并在有限和无限时间问题中表现出与 Chernoff 检验相当甚至更好的性能，尽管无法访问环境动态。

    A combination of deep reinforcement learning and supervised learning is proposed for the problem of active sequential hypothesis testing in completely unknown environments. We make no assumptions about the prior probability, the action and observation sets, and the observation generating process. Our method can be used in any environment even if it has continuous observations or actions, and performs competitively and sometimes better than the Chernoff test, in both finite and infinite horizon problems, despite not having access to the environment dynamics.
    
[^114]: LIDA：一种利用大型语言模型自动生成与语法无关的可视化与信息图表的工具

    LIDA: A Tool for Automatic Generation of Grammar-Agnostic Visualizations and Infographics using Large Language Models. (arXiv:2303.02927v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2303.02927](http://arxiv.org/abs/2303.02927)

    LIDA是一种使用大型语言模型和图像生成模型自动生成与语法无关的可视化和信息图表的工具。

    

    支持用户自动创建可视化的系统必须解决多个子任务——理解数据的语义、列举相关的可视化目标以及生成可视化规范。本文将可视化生成视为一个多阶段生成问题，并认为基于大型语言模型（LLM）（例如ChatGPT/GPT-4）和图像生成模型（IGM）的良好编配的管道适合解决这些任务。我们提出了LIDA，一种新型的用于生成与语法无关的可视化和信息图表的工具。LIDA由4个模块组成：SUMMARIZER将数据转换为富但紧凑的自然语言摘要、GOAL EXPLORER在给定数据的情况下列举可视化目标、VISGENERATOR生成、改进、执行和过滤可视化代码，以及INFOGRAPHER使用IGM生成数据忠实的风格化图形。LIDA提供了一个Python API和混合用户界面（直接操作和多模态文本输入），供用户指定数据和问题。我们的实验评估表明，LIDA能够有效地生成有意义且美观的可视化效果。

    Systems that support users in the automatic creation of visualizations must address several subtasks - understand the semantics of data, enumerate relevant visualization goals and generate visualization specifications. In this work, we pose visualization generation as a multi-stage generation problem and argue that well-orchestrated pipelines based on large language models (LLMs) such as ChatGPT/GPT-4 and image generation models (IGMs) are suitable to addressing these tasks. We present LIDA, a novel tool for generating grammar-agnostic visualizations and infographics. LIDA comprises of 4 modules - A SUMMARIZER that converts data into a rich but compact natural language summary, a GOAL EXPLORER that enumerates visualization goals given the data, a VISGENERATOR that generates, refines, executes and filters visualization code and an INFOGRAPHER module that yields data-faithful stylized graphics using IGMs. LIDA provides a python api, and a hybrid user interface (direct manipulation and mu
    
[^115]: 基于本地全局蒸馏的异构数据联邦虚拟学习

    Federated Virtual Learning on Heterogeneous Data with Local-global Distillation. (arXiv:2303.02278v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.02278](http://arxiv.org/abs/2303.02278)

    该论文提出了一种名为FedLGD的新方法，通过本地和全局数据集的蒸馏组合来创建一个更小的合成数据集，以解决联邦学习中处理异构数据时的性能问题，同时使用迭代分布匹配来处理同步和类别不平衡问题。

    

    虽然联邦学习已成为分布式学习机器学习模型的趋势，但在处理异构数据时，其性能容易出现下降。此外，联邦学习不可避免地面临同步、效率和隐私等挑战。近来，数据集蒸馏已被研究，以通过创建一个保留本地私有数据集训练模型性能的较小的合成数据集来提高FL的效率和可扩展性。同时，我们也发现使用蒸馏的本地数据集会放大联邦学习中的异构性问题。为了解决这个问题，我们提出了一种新的方法，称为基于本地全局蒸馏的异构数据联邦虚拟学习（FedLGD），该方法使用一个较小的合成数据集（称为虚拟数据），该数据集是通过本地和全局数据集蒸馏的组合创建的。具体来说，为了处理同步和类别不平衡问题，我们提出了迭代分布匹配，允许客户端从全局模型中获取知识并通过模型反馈来共同学习。

    Despite Federated Learning (FL)'s trend for learning machine learning models in a distributed manner, it is susceptible to performance drops when training on heterogeneous data. In addition, FL inevitability faces the challenges of synchronization, efficiency, and privacy. Recently, dataset distillation has been explored in order to improve the efficiency and scalability of FL by creating a smaller, synthetic dataset that retains the performance of a model trained on the local private datasets. We discover that using distilled local datasets can amplify the heterogeneity issue in FL. To address this, we propose a new method, called Federated Virtual Learning on Heterogeneous Data with Local-Global Distillation (FedLGD), which trains FL using a smaller synthetic dataset (referred as virtual data) created through a combination of local and global dataset distillation. Specifically, to handle synchronization and class imbalance, we propose iterative distribution matching to allow clients 
    
[^116]: 学习机器在医疗及其他方面的应用

    Learning machines for health and beyond. (arXiv:2303.01513v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.01513](http://arxiv.org/abs/2303.01513)

    适用于建立预测模型的机器学习技术在医疗领域和其他领域具有广泛应用。模型的维护和监控很关键，因为模型的性能与数据的变化和传输有关。

    

    机器学习技术在构建预测模型方面具有良好效果，因为它们擅长识别大型数据集中的模式。然而，对于复杂的现实问题，模型的开发往往停留在发表论文、概念验证或通过某种部署模式的可访问性。然而，在医疗领域里，模型的患者人口会发生变化，因此模型的维护和监控是确保其长期安全有效使用的关键。由于机器学习技术是有效地训练以在可用数据集中寻找模式的，因此，对于复杂的现实问题，模型的性能不会在发表或部署时达到峰值后固定不变。相反，数据会随着时间的变化而产生变化，而当模型被运往新的地方供新的人群使用时，它们也会发生变化。

    Machine learning techniques are effective for building predictive models because they are good at identifying patterns in large datasets. Development of a model for complex real life problems often stops at the point of publication, proof of concept or when made accessible through some mode of deployment. However, a model in the medical domain risks becoming obsolete as soon as patient demographic changes. The maintenance and monitoring of predictive models post-publication is crucial to guarantee their safe and effective long term use. As machine learning techniques are effectively trained to look for patterns in available datasets, the performance of a model for complex real life problems will not peak and remain fixed at the point of publication or even point of deployment. Rather, data changes over time, and they also changed when models are transported to new places to be used by new demography.
    
[^117]: 分布模型和半监督学习器在少量标签上互相受益

    Diffusion Models and Semi-Supervised Learners Benefit Mutually with Few Labels. (arXiv:2302.10586v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.10586](http://arxiv.org/abs/2302.10586)

    本文介绍了一种名为双伪训练（DPT）的训练策略，该策略结合了强大的半监督学习器和扩散模型来进一步推进半监督生成和分类任务。实验结果表明，DPT在各种情况下都能实现半监督生成和分类任务的SOTA性能，特别是在每个类别只有一个或两个标签的情况下，超过了其他一些模型。

    

    为了进一步推进半监督生成和分类任务，本文提出了一种简单而有效的训练策略——双伪训练（DPT），该策略建立在强大的半监督学习器和扩散模型之上。DPT分为三个阶段：使用部分标记数据训练分类器以预测伪标签；使用这些伪标签训练条件生成模型以生成伪图像；并使用真实和伪造的图像混合重新训练分类器。实验结果表明，在各种情况下，DPT始终实现了半监督生成和分类的SOTA性能。特别是，在每个类别只有一个或两个标签的情况下，在ImageNet 256x256上，DPT的Fr\'echet Inception Distance（FID）得分分别为3.08或2.52，超过了具有完整标签的强扩散模型（如IDDPM，CDM，ADM和LDM）。此外，DPT在ImageNet分类任务上显著优于竞争性的半监督基线，实现了顶级1的准确性。

    In an effort to further advance semi-supervised generative and classification tasks, we propose a simple yet effective training strategy called dual pseudo training (DPT), built upon strong semi-supervised learners and diffusion models. DPT operates in three stages: training a classifier on partially labeled data to predict pseudo-labels; training a conditional generative model using these pseudo-labels to generate pseudo images; and retraining the classifier with a mix of real and pseudo images. Empirically, DPT consistently achieves SOTA performance of semi-supervised generation and classification across various settings. In particular, with one or two labels per class, DPT achieves a Fr\'echet Inception Distance (FID) score of 3.08 or 2.52 on ImageNet 256x256, surpassing strong diffusion models with full labels, such as IDDPM, CDM, ADM, and LDM. Besides, DPT outperforms competitive semi-supervised baselines substantially on ImageNet classification tasks, achieving top-1 accuracies o
    
[^118]: Adap-$\tau$:自适应调整嵌入的幅度用于推荐

    Adap-$\tau$: Adaptively Modulating Embedding Magnitude for Recommendation. (arXiv:2302.04775v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2302.04775](http://arxiv.org/abs/2302.04775)

    本研究提出了一种自适应归一化方案Adap-$\tau$，通过动态调节每个用户-每个物品对的嵌入幅度，实现了理想的推荐性能，方法在四个真实世界的数据集上都超过了基准方法。

    

    最近几年来，基于嵌入的方法在推荐系统中取得了巨大的成功。尽管它们的性能还不错，但我们认为这些方法可能存在一个潜在的限制——嵌入幅度没有明确调节，这可能加剧流行度偏见和训练不稳定性，从而阻碍模型做出好的推荐。这促使我们利用嵌入归一化来推荐。通过将用户/物品嵌入归一化为特定值，我们在四个真实世界的数据集上实证观察到了令人满意的性能提升（平均9％）。虽然这是令人鼓舞的，但我们也揭示了在推荐中应用归一化的严重局限性——性能高度敏感于控制标准化嵌入比例的温度τ的选择。为了充分发挥归一化的优点并避免其局限性，本研究研究了如何自适应设置适当的τ。为此，我们首先提出了一个理论框架，描述了推荐中归一化操作与偏差-方差折衷之间的关系。然后，我们设计了一种自适应归一化方案，名为Adap-$\tau$，它动态调节每个用户-每个物品对的嵌入幅度，旨在实现理想的推荐性能。在四个真实世界的数据集上的广泛实验表明，Adap-$\tau$始终优于强基准方法，并实现了最先进的性能。

    Recent years have witnessed the great successes of embedding-based methods in recommender systems. Despite their decent performance, we argue one potential limitation of these methods -- the embedding magnitude has not been explicitly modulated, which may aggravate popularity bias and training instability, hindering the model from making a good recommendation. It motivates us to leverage the embedding normalization in recommendation. By normalizing user/item embeddings to a specific value, we empirically observe impressive performance gains (9\% on average) on four real-world datasets. Although encouraging, we also reveal a serious limitation when applying normalization in recommendation -- the performance is highly sensitive to the choice of the temperature $\tau$ which controls the scale of the normalized embeddings.  To fully foster the merits of the normalization while circumvent its limitation, this work studied on how to adaptively set the proper $\tau$. Towards this end, we firs
    
[^119]: 对抗样本起到了积极作用：通过对抗样本防止扩散模型模仿绘画

    Adversarial Example Does Good: Preventing Painting Imitation from Diffusion Models via Adversarial Examples. (arXiv:2302.04578v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.04578](http://arxiv.org/abs/2302.04578)

    该论文提出了一种利用对抗样本来保护人类创造的艺术品，对抗侵权者利用未经授权的绘画训练DMs生成类似风格的新颖绘画的方法。

    

    最近，扩散模型（DMs）在人工智能艺术领域掀起了一股热潮，但同时也引发了新的版权问题，即侵权者利用未经授权的绘画训练DMs生成类似风格的新颖绘画。为了解决这些新兴的版权问题，我们首次探索并提出利用对抗样本保护人类创造的艺术品的方法。具体而言，我们首先建立了一个理论框架来定义和评估DMs的对抗样本。然后，基于这个框架，我们设计了一种新算法，命名为AdvDM，它通过对从DMs的反向过程中抽样的不同潜变量进行蒙特卡罗估计的对抗样本进行优化。广泛的实验证明，生成的对抗样本可以有效地阻碍DMs提取它们的特征。因此，我们的方法可以成为保护人类艺术家版权的强有力工具，以对抗装备有DMs的侵权者。

    Recently, Diffusion Models (DMs) boost a wave in AI for Art yet raise new copyright concerns, where infringers benefit from using unauthorized paintings to train DMs to generate novel paintings in a similar style. To address these emerging copyright violations, in this paper, we are the first to explore and propose to utilize adversarial examples for DMs to protect human-created artworks. Specifically, we first build a theoretical framework to define and evaluate the adversarial examples for DMs. Then, based on this framework, we design a novel algorithm, named AdvDM, which exploits a Monte-Carlo estimation of adversarial examples for DMs by optimizing upon different latent variables sampled from the reverse process of DMs. Extensive experiments show that the generated adversarial examples can effectively hinder DMs from extracting their features. Therefore, our method can be a powerful tool for human artists to protect their copyright against infringers equipped with DM-based AI-for-A
    
[^120]: 基于关系Weisfeiler-Leman的链路预测理论

    A Theory of Link Prediction via Relational Weisfeiler-Leman. (arXiv:2302.02209v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.02209](http://arxiv.org/abs/2302.02209)

    本文提出了一种基于关系Weisfeiler-Leman算法的理论，为知识图谱中的图神经网络提供了理论解释，并对各种模型的表达能力进行了表征，并解释了一些广泛采用的实际设计选择的优点。

    

    图神经网络是用于图结构数据表示学习的重要模型。尽管我们已经很好地理解了这些模型在简单图上的能力和局限性，但对于知识图谱，我们的理解仍然不完整。本文的目标是为知识图谱中的图神经网络提供系统性的理解，以解决链路预测等重要任务。我们的分析涉及一种统一的视角、看似不相关的模型，并解锁了一系列其他模型。通过相应的关系Weisfeiler-Leman算法，表征了各种模型的表达能力。此分析被扩展以对图神经网络类别捕捉的函数类进行精确逻辑描述。提出的理论发现解释了一些广泛采用的实际设计选择的优点，并得到了经验验证。

    Graph neural networks are prominent models for representation learning over graph-structured data. While the capabilities and limitations of these models are well-understood for simple graphs, our understanding remains incomplete in the context of knowledge graphs. Our goal is to provide a systematic understanding of the landscape of graph neural networks for knowledge graphs pertaining to the prominent task of link prediction. Our analysis entails a unifying perspective on seemingly unrelated models and unlocks a series of other models. The expressive power of various models is characterized via a corresponding relational Weisfeiler-Leman algorithm. This analysis is extended to provide a precise logical characterization of the class of functions captured by a class of graph neural networks. The theoretical findings presented in this paper explain the benefits of some widely employed practical design choices, which are validated empirically.
    
[^121]: 基于深度强化学习的网络物理系统在线错误检测

    Deep Reinforcement Learning for Online Error Detection in Cyber-Physical Systems. (arXiv:2302.01567v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.01567](http://arxiv.org/abs/2302.01567)

    本文提出了一种基于深度强化学习（DRL）的新型在线错误检测方法。

    

    可靠性是网络物理系统中主要的设计标准之一。这是由于CPS中存在一些关键应用程序，它们的失效是灾难性的。因此，在CPS中使用强大的错误检测和纠正机制是不可避免的。传统的容错方法包括冗余时间、硬件、信息和/或软件。然而，这些方法除了低错误覆盖率外，还会带来极大的开销，限制了它们的适用性。本文提出了一种基于深度强化学习（DRL）的新型错误检测方法。

    Reliability is one of the major design criteria in Cyber-Physical Systems (CPSs). This is because of the existence of some critical applications in CPSs and their failure is catastrophic. Therefore, employing strong error detection and correction mechanisms in CPSs is inevitable. CPSs are composed of a variety of units, including sensors, networks, and microcontrollers. Each of these units is probable to be in a faulty state at any time and the occurred fault can result in erroneous output. The fault may cause the units of CPS to malfunction and eventually crash. Traditional fault-tolerant approaches include redundancy time, hardware, information, and/or software. However, these approaches impose significant overheads besides their low error coverage, which limits their applicability. In addition, the interval between error occurrence and detection is too long in these approaches. In this paper, based on Deep Reinforcement Learning (DRL), a new error detection approach is proposed that
    
[^122]: 大型语言模型容易受到无关上下文的干扰

    Large Language Models Can Be Easily Distracted by Irrelevant Context. (arXiv:2302.00093v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.00093](http://arxiv.org/abs/2302.00093)

    本文研究了大型语言模型对无关上下文的干扰性。他们使用一个带有无关信息的算术推理数据集GSM-IC来衡量这种可干扰性。研究发现当包含无关信息时，模型性能会急剧下降，但使用自我一致性进行解码并添加一个指令可以缓解这一缺陷。

    

    大型语言模型已经在各种自然语言处理任务中取得了令人瞩目的表现。然而，迄今为止，它们主要在所有输入上下文信息都与解决任务相关的基准测试上进行了评估。在本文中，我们研究了大型语言模型的可干扰性，即不相关上下文如何影响模型的问题解决准确性。特别地，我们引入了一个带有无关信息的算术推理数据集GSM-IC。我们使用这个基准测试来衡量最尖端的提示技术在大型语言模型中可干扰性，发现当包含无关信息时，模型性能会急剧下降。我们还确定了几种缓解这种不足的方法，如使用自我一致性进行解码，并在提示中添加一条指令，告诉语言模型忽略无关信息。

    Large language models have achieved impressive performance on various natural language processing tasks. However, so far they have been evaluated primarily on benchmarks where all information in the input context is relevant for solving the task. In this work, we investigate the distractibility of large language models, i.e., how the model problem-solving accuracy can be influenced by irrelevant context. In particular, we introduce Grade-School Math with Irrelevant Context (GSM-IC), an arithmetic reasoning dataset with irrelevant information in the problem description. We use this benchmark to measure the distractibility of cutting-edge prompting techniques for large language models, and find that the model performance is dramatically decreased when irrelevant information is included. We also identify several approaches for mitigating this deficiency, such as decoding with self-consistency and adding to the prompt an instruction that tells the language model to ignore the irrelevant in
    
[^123]: 面向高效梯度为基础的值估计

    Toward Efficient Gradient-Based Value Estimation. (arXiv:2301.13757v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.13757](http://arxiv.org/abs/2301.13757)

    本研究研究了梯度为基础的值估计方法慢的根本原因，并提出了一种低复杂度的方法以解决损失函数带来的不良影响，该方法在效率上比剩余梯度方法更快，几乎具有相同的计算复杂度，并且在经典问题上与TD具有竞争力。

    

    强化学习中基于梯度的值估计方法具有良好的稳定性，但通常比时间差异（TD）学习方法慢得多。我们研究了这种缓慢的根本原因，并表明均方贝尔曼误差（MSBE）是一种病态的损失函数，其黑塞矩阵具有较大的条件数。为了解决MSBE的不良条件对基于梯度的方法的负面影响，我们提出了一种低复杂度的无批处理近端方法，它近似遵循高斯牛顿方向，并在参数化方面渐近鲁棒。我们的主要算法称为RANS，它在效率上比剩余梯度方法更快，几乎具有相同的计算复杂度，并且在我们测试的经典问题上与TD具有竞争力。

    Gradient-based methods for value estimation in reinforcement learning have favorable stability properties, but they are typically much slower than Temporal Difference (TD) learning methods. We study the root causes of this slowness and show that Mean Square Bellman Error (MSBE) is an ill-conditioned loss function in the sense that its Hessian has large condition-number. To resolve the adverse effect of poor conditioning of MSBE on gradient based methods, we propose a low complexity batch-free proximal method that approximately follows the Gauss-Newton direction and is asymptotically robust to parameterization. Our main algorithm, called RANS, is efficient in the sense that it is significantly faster than the residual gradient methods while having almost the same computational complexity, and is competitive with TD on the classic problems that we tested.
    
[^124]: 使用特征筛选克服深度神经网络中的简单偏差

    Overcoming Simplicity Bias in Deep Networks using a Feature Sieve. (arXiv:2301.13293v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.13293](http://arxiv.org/abs/2301.13293)

    提出了一种特征筛选方法，通过抑制网络较低层易计算虚假特征，使得更高层的网络提取和利用更丰富、更有意义的特征表示，从而克服了深度神经网络中的简单偏差。

    

    简单偏差是深度神经网络倾向于依赖简单且预测性较弱特征的令人担忧的趋势，从而排除更强、更复杂的特征。在真实世界应用中，由于训练数据有限和虚假特征标签相关性，导致了偏向性、不正确的预测。我们提出了一种直接、干预深度神经网络中简单偏差的方法，称为特征筛选。我们的目标是自动识别和抑制网络较低层的易计算虚假特征，从而让更高层的网络提取和利用更丰富、更有意义的表示。我们提供了控制数据集和真实世界图像上有关有效特征不同压制和增强的具体证据，并在许多真实世界去偏差基准测试中报告了显著性提高（Imagenet-A相对增益11.4％；BAR 3.2％等）。关键是，我们不依赖虚假属性的先验知识。

    Simplicity bias is the concerning tendency of deep networks to over-depend on simple, weakly predictive features, to the exclusion of stronger, more complex features. This is exacerbated in real-world applications by limited training data and spurious feature-label correlations, leading to biased, incorrect predictions. We propose a direct, interventional method for addressing simplicity bias in DNNs, which we call the feature sieve. We aim to automatically identify and suppress easily-computable spurious features in lower layers of the network, thereby allowing the higher network levels to extract and utilize richer, more meaningful representations. We provide concrete evidence of this differential suppression & enhancement of relevant features on both controlled datasets and real-world images, and report substantial gains on many real-world debiasing benchmarks (11.4% relative gain on Imagenet-A; 3.2% on BAR, etc). Crucially, we do not depend on prior knowledge of spurious attributes
    
[^125]: AutoPEFT：用于参数高效微调的自动配置搜索

    AutoPEFT: Automatic Configuration Search for Parameter-Efficient Fine-Tuning. (arXiv:2301.12132v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.12132](http://arxiv.org/abs/2301.12132)

    AutoPEFT是一个自动化的PEFT（参数高效微调）配置搜索方法，它能够自动地找到最佳的PEFT模块和体系结构，以优化任务的性能和参数效率。在典型的NLP任务中，AutoPEFT表现出比手动设计更好的性能。

    

    大型预训练语言模型通过专门的微调用于下游NLP任务，但这样的过程可能很昂贵。最近，参数高效微调（PEFT）方法通过更新比完整模型微调（FFT）少得多的参数，实现了强大的任务性能。然而，在PEFT配置方面做出明智的设计选择是不容易的，例如它们的体系结构、可调参数的数量，甚至是PEFT模块插入的图层。因此，目前的手动设计配置很可能在性能效率权衡方面是次优的。受神经架构搜索的进展启发，我们提出了AutoPEFT来自动选择PEFT配置：首先设计具有多个代表性PEFT模块的表达配置搜索空间。然后使用多目标贝叶斯优化进行低成本的设置，从而发现优化任务性能和参数效率的Pareto优化配置。我们在几个典型的NLP任务，包括文本分类、问答和命名实体识别上评估了AutoPEFT，并展示了其优于手动设计基线的性能。

    Large pretrained language models are widely used in downstream NLP tasks via task-specific fine-tuning, but such procedures can be costly. Recently, Parameter-Efficient Fine-Tuning (PEFT) methods have achieved strong task performance while updating a much smaller number of parameters compared to full model fine-tuning (FFT). However, it is non-trivial to make informed design choices on the PEFT configurations, such as their architecture, the number of tunable parameters, and even the layers in which the PEFT modules are inserted. Consequently, it is highly likely that the current, manually designed configurations are suboptimal in terms of their performance-efficiency trade-off. Inspired by advances in neural architecture search, we propose AutoPEFT for automatic PEFT configuration selection: we first design an expressive configuration search space with multiple representative PEFT modules as building blocks. Using multi-objective Bayesian optimisation in a low-cost setup, we then disc
    
[^126]: 拉普拉斯有界深度神经网络的直接参数化

    Direct Parameterization of Lipschitz-Bounded Deep Networks. (arXiv:2301.11526v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.11526](http://arxiv.org/abs/2301.11526)

    本文提出了一种直接参数化的深度神经网络，其具有拉普拉斯界限，通过标准梯度方法进行训练，避免了计算密集型的投影或障碍项。

    

    本文引入了一种新的深度神经网络参数化方式（全连接和卷积网络），具有有限灵敏度的拉普拉斯界限。与SDP方法不同的是，我们提供了一个"直接"参数化方式，并通过标准的梯度方法进行训练，而不需要任何计算密集型的投影或障碍项。

    This paper introduces a new parameterization of deep neural networks (both fully-connected and convolutional) with guaranteed Lipschitz bounds, i.e. limited sensitivity to perturbations. The Lipschitz guarantees are equivalent to the tightest-known bounds based on certification via a semidefinite program (SDP), which does not scale to large models. In contrast to the SDP approach, we provide a ``direct'' parameterization, i.e. a smooth mapping from $\mathbb R^N$ onto the set of weights of Lipschitz-bounded networks. This enables training via standard gradient methods, without any computationally intensive projections or barrier terms. The new parameterization can equivalently be thought of as either a new layer type (the \textit{sandwich layer}), or a novel parameterization of standard feedforward networks with parameter sharing between neighbouring layers. Finally, the comprehensive set of experiments on image classification shows that sandwich layers outperform previous approaches on
    
[^127]: 从两人零和博弈中抽象出不完美信息

    Abstracting Imperfect Information Away from Two-Player Zero-Sum Games. (arXiv:2301.09159v2 [cs.GT] UPDATED)

    [http://arxiv.org/abs/2301.09159](http://arxiv.org/abs/2301.09159)

    通过正则化均衡，可以将两人零和博弈中的不完美信息抽象出来并作为完全信息问题处理。

    

    Nayyar等人在其开创性的工作中表明，通过在游戏过程中让玩家公开宣布其策略，不完美信息可以被从共同效益游戏中抽象出来。这个见解是支撑共同效益游戏合理的求解器和决策时间规划算法的基础。不幸的是，将同样的见解简单应用于两人零和博弈会失败，因为具有公开策略宣布的游戏的纳什均衡可能与原始游戏的纳什均衡不相对应。因此，现有的合理的决策时间规划算法需要复杂的额外机制，其具有不吸引人的特性。本文的主要贡献是展示某些正则化均衡不具有上述的不对应问题，因此，计算它们可以被视为完全信息问题。因为这些正则化均衡可以被无限接近纳什均衡，我们的结果为一种新的视角打开了大门。

    In their seminal work, Nayyar et al. (2013) showed that imperfect information can be abstracted away from common-payoff games by having players publicly announce their policies as they play. This insight underpins sound solvers and decision-time planning algorithms for common-payoff games. Unfortunately, a naive application of the same insight to two-player zero-sum games fails because Nash equilibria of the game with public policy announcements may not correspond to Nash equilibria of the original game. As a consequence, existing sound decision-time planning algorithms require complicated additional mechanisms that have unappealing properties. The main contribution of this work is showing that certain regularized equilibria do not possess the aforementioned non-correspondence problem -- thus, computing them can be treated as perfect-information problems. Because these regularized equilibria can be made arbitrarily close to Nash equilibria, our result opens the door to a new perspectiv
    
[^128]: 基于交互式模拟环境的人机协同体现智能在外科手术机器人学习中的应用

    Human-in-the-loop Embodied Intelligence with Interactive Simulation Environment for Surgical Robot Learning. (arXiv:2301.00452v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2301.00452](http://arxiv.org/abs/2301.00452)

    本文介绍了一种基于交互式模拟环境的人机协同体现智能机器人学习的新平台，以及人类专家指导下机器人学习表现的提高和人体示范对手术机器人控制策略的影响。

    

    在过去的十年里，外科手术机器人自动化已经吸引了越来越多的研究兴趣，预期其潜力能够惠及外科医生、护士和患者。最近，具有体现智能的学习范式展示了学习各种复杂任务的良好控制策略的能力，其中体现智能模拟器在促进相关研究方面发挥了核心作用。然而，现有的外科手术机器人开源模拟器仍未足够支持通过物理输入设备进行人机交互，这进一步限制了对人体示范如何影响策略学习的有效调查。在这项工作中，我们研究了一种基于交互式模拟平台的人机协同体现智能，用于外科手术机器人的学习。具体而言，我们建立了基于先前发布的SurRoL模拟器的平台，并与其他工程师一起开发了几个新功能，以允许通过输入设备进行高质量的人机交互。我们展示了在人类专家的指导下，机器人学习表现的提高，并确定了不同类型人体示范对手术机器人学习的控制策略所产生的影响。

    Surgical robot automation has attracted increasing research interest over the past decade, expecting its potential to benefit surgeons, nurses and patients. Recently, the learning paradigm of embodied intelligence has demonstrated promising ability to learn good control policies for various complex tasks, where embodied AI simulators play an essential role to facilitate relevant research. However, existing open-sourced simulators for surgical robot are still not sufficiently supporting human interactions through physical input devices, which further limits effective investigations on how the human demonstrations would affect policy learning. In this work, we study human-in-the-loop embodied intelligence with a new interactive simulation platform for surgical robot learning. Specifically, we establish our platform based on our previously released SurRoL simulator with several new features co-developed to allow high-quality human interaction via an input device. We showcase the improveme
    
[^129]: HiTSKT：一种用于会话感知知识追踪的分层Transformer模型。

    HiTSKT: A Hierarchical Transformer Model for Session-Aware Knowledge Tracing. (arXiv:2212.12139v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2212.12139](http://arxiv.org/abs/2212.12139)

    HiTSKT是一种分层Transformer模型，用于会话感知知识追踪，能够捕捉学生不同会话之间的关系，并学习技能级别表示，相对于现有技术基线模型表现优异。

    

    知识跟踪(KT)旨在利用学生的学习历史来估计他们在一组预定义的技能上的掌握水平，从而可以准确预测相应的未来表现。作为为在线教育提供个性化体验的重要方式，KT近年来受到越来越多的关注。在实践中，学生的学习历史是由一组集中的问题答案组成的，每个问题集被称为一个会话，而不仅仅是独立答案的序列。在理论上，学生的学习动态可以在这些会话中内部和跨会话之间非常不同。因此，如何有效地在会话内部和跨会话模拟学生的知识状态动态对于处理KT问题至关重要。大多数现有的KT模型将学生的学习记录视为单个连续序列，而没有捕捉学生知识状态的会话转移。为了解决上述问题，本文提出了一种新颖的分层Transformer模型，称为HiTSKT，以分层的方式表示学生的知识状态，企业级表示和技能级表示，分别。具体而言，HiTSKT首先利用自我注意机制捕捉不同会话之间的关系，然后基于会话级别的表示学习技能级别的表示。实验结果表明，HiTSKT在真实世界数据集上的表现优于现有技术基线模型。

    Knowledge tracing (KT) aims to leverage students' learning histories to estimate their mastery levels on a set of pre-defined skills, based on which the corresponding future performance can be accurately predicted. As an important way of providing personalized experience for online education, KT has gained increased attention in recent years. In practice, a student's learning history comprises answers to sets of massed questions, each known as a session, rather than merely being a sequence of independent answers. Theoretically, within and across these sessions, students' learning dynamics can be very different. Therefore, how to effectively model the dynamics of students' knowledge states within and across the sessions is crucial for handling the KT problem. Most existing KT models treat student's learning records as a single continuing sequence, without capturing the sessional shift of students' knowledge state. To address the above issue, we propose a novel hierarchical transformer m
    
[^130]: 文本到图像生成中的空间关系基准测试

    Benchmarking Spatial Relationships in Text-to-Image Generation. (arXiv:2212.10015v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.10015](http://arxiv.org/abs/2212.10015)

    本文研究了文本到图像生成中模型生成正确空间关系的能力，并提出了一个评估指标VISOR以衡量生成图像的准确性。实验发现当前T2I模型尽管可以生成高度逼真的图像，但其空间上准确的图像能力仍然不足，特别是在空间谓词和场景关系理解方面。

    

    空间理解是计算机视觉的基本方面，对于人类级别的图像推理至关重要，因此是基础语言理解的重要组成部分。最近的文本到图像合成（T2I）模型在逼真性方面取得了前所未有的进展，但它们的可靠空间理解能力尚不清楚。我们调查了T2I模型生成正确空间关系的能力，并提出了VISOR评估指标，它捕捉了文本中描述的空间关系在图像中是否准确生成。为了基准现有模型，我们引入了一个包含描述两个对象及它们之间空间关系的句子数据集SR2D。我们构建了一个自动化评估流程来识别物体及其空间关系，并在大规模评估T2I模型时采用它。我们的实验发现了一个令人惊讶的发现，也就是尽管最新的T2I模型能够产生高度逼真的图像，但它们生成空间上准确的图像能力仍然不足。具体而言，我们发现现有模型在空间谓词（如'在前面'和'在后面'）方面存在困难，并且在场景的关系理解方面也有困难。

    Spatial understanding is a fundamental aspect of computer vision and integral for human-level reasoning about images, making it an important component for grounded language understanding. While recent text-to-image synthesis (T2I) models have shown unprecedented improvements in photorealism, it is unclear whether they have reliable spatial understanding capabilities. We investigate the ability of T2I models to generate correct spatial relationships among objects and present VISOR, an evaluation metric that captures how accurately the spatial relationship described in text is generated in the image. To benchmark existing models, we introduce a dataset, SR2D, that contains sentences describing two objects and the spatial relationship between them. We construct an automated evaluation pipeline to recognize objects and their spatial relationships, and employ it in a large-scale evaluation of T2I models. Our experiments reveal a surprising finding that, although state-of-the-art T2I models 
    
[^131]: 在场学习者能否从演示中学习推理概念？

    Can In-context Learners Learn a Reasoning Concept from Demonstrations?. (arXiv:2212.01692v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.01692](http://arxiv.org/abs/2212.01692)

    本文介绍了一种概念性少样本学习方法，以帮助在场学习者学习新技能。通过选择与预测示例共享可能信息的演示，这个方法可以在模型记忆独立的情况下区分模型的在场学习能力。

    

    大型语言模型展示了从少量输入-输出演示中学习新任务的新能力。然而，最近的研究表明，在场学习者大部分依赖于他们的预训练知识，如标签的情感，而不是在输入中找到新的关联性。然而，常用的少样本评估设置使用随机选择的在场演示无法区分模型从演示中学习新技能的能力，因为大部分随机选择的演示并不呈现超越暴露于新任务分布的预测的关系。为了在模型记忆独立的情况下区分模型的在场学习能力，我们引入了一个概念性少样本学习方法，选择与预测示例共享可能信息的演示。我们从注释解释中提取了一组这样的概念，并测量了模型展示这些概念可以获得多少好处。

    Large language models show an emergent ability to learn a new task from a small number of input-output demonstrations. However, recent work shows that in-context learners largely rely on their pre-trained knowledge, such as the sentiment of the labels, instead of finding new associations in the input. However, the commonly-used few-shot evaluation settings using a random selection of in-context demonstrations can not disentangle models' ability to learn a new skill from demonstrations, as most of the randomly-selected demonstrations do not present relations informative for prediction beyond exposing the new task distribution.  To disentangle models' in-context learning ability independent of models' memory, we introduce a Conceptual few-shot learning method selecting the demonstrations sharing a possibly-informative concept with the predicted sample. We extract a set of such concepts from annotated explanations and measure how much can models benefit from presenting these concepts in f
    
[^132]: SmoothQuant：用于大型语言模型的精确高效的后训练量化方法

    SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models. (arXiv:2211.10438v5 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.10438](http://arxiv.org/abs/2211.10438)

    SmoothQuant是一种训练无需的通用后训练量化（PTQ）解决方案，可以在保持精度的情况下实现大型语言模型的8位权重、8位激活（W8A8）量化。SmoothQuant通过数学等效转换将量化难度从激活移到权重，使得所有矩阵乘法的权重和激活的INT8量化成为可能，具有最高1.56倍加速和2倍内存减少的效果。

    

    大型语言模型（LLMs）表现出优异的性能，但需要大量计算和内存。量化可以减少内存并加速推理。然而，现有方法无法在保持精度和硬件效率的同时维持。我们提出了SmoothQuant，一种无需训练、保持精度和通用的后训练量化（PTQ）解决方案，以实现LLMs的8位权重、8位激活（W8A8）量化。基于权重易于量化而激活不易量化的事实，SmoothQuant通过数学等效转换将量化难度从激活移至权重，通过离线平滑激活的异常值来实现此目标。SmoothQuant使所有矩阵乘法的权重和激活的INT8量化成为可能，包括OPT、BLOOM、GLM、MT-NLG和LLaMA系列。我们演示了LLMs的最高1.56倍加速和2倍内存减少，并且几乎不会有精度损失。SmoothQuant可以为530B LLM提供服务。

    Large language models (LLMs) show excellent performance but are compute- and memory-intensive. Quantization can reduce memory and accelerate inference. However, existing methods cannot maintain accuracy and hardware efficiency at the same time. We propose SmoothQuant, a training-free, accuracy-preserving, and general-purpose post-training quantization (PTQ) solution to enable 8-bit weight, 8-bit activation (W8A8) quantization for LLMs. Based on the fact that weights are easy to quantize while activations are not, SmoothQuant smooths the activation outliers by offline migrating the quantization difficulty from activations to weights with a mathematically equivalent transformation. SmoothQuant enables an INT8 quantization of both weights and activations for all the matrix multiplications in LLMs, including OPT, BLOOM, GLM, MT-NLG, and LLaMA family. We demonstrate up to 1.56x speedup and 2x memory reduction for LLMs with negligible loss in accuracy. SmoothQuant enables serving 530B LLM wi
    
[^133]: 关于优化器选择提高模型对分布似然小变化的泛化性能的实证研究

    Empirical Study on Optimizer Selection for Out-of-Distribution Generalization. (arXiv:2211.08583v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.08583](http://arxiv.org/abs/2211.08583)

    本实证研究通过测试不同分布偏移下超过20,000个模型的表现，发现自适应优化器（如Adam和Adagrad）及可以减少时间相关特征的优化器具有更好的分布外泛化性能。

    

    当测试数据分布与训练数据分布稍有不同时，现代深度学习系统的泛化能力不佳。虽然已经有了很多有前途的工作来解决这个问题，但对优化器及其在分布外泛化性能中的作用进行系统研究尚未进行。本研究通过在经验风险最小化和不变风险最小化下，使用DomainBed，WILDS和Backgrounds Challenge分别作为测试平台研究不同类型偏移（即相关性和多样性变化）对图像和文本分类的影响，并使用广泛的超参数范围搜索并测试超过20,000个模型的分类准确性（分布内和分布外）。我们的研究得出以下结论，我们相信对实践者是有帮助的，i) 自适应优化器（例如 Adam 和 Adagrad）具有泛化性能更好。ii) 当偏移有很强的时间局部性时，能够减少时间相关特征的优化器具有泛化性能更好，而当偏移有强的时间整体性时则没有性能优势。

    Modern deep learning systems do not generalize well when the test data distribution is slightly different to the training data distribution. While much promising work has been accomplished to address this fragility, a systematic study of the role of optimizers and their out-of-distribution generalization performance has not been undertaken. In this study, we examine the performance of popular first-order optimizers for different classes of distributional shift under empirical risk minimization and invariant risk minimization. We address this question for image and text classification using DomainBed, WILDS, and Backgrounds Challenge as testbeds for studying different types of shifts -- namely correlation and diversity shift. We search over a wide range of hyperparameters and examine classification accuracy (in-distribution and out-of-distribution) for over 20,000 models. We arrive at the following findings, which we expect to be helpful for practitioners: i) adaptive optimizers (e.g., 
    
[^134]: 通过平滑敏感度实现隐私保护的偏差查询

    Can Querying for Bias Leak Protected Attributes? Achieving Privacy With Smooth Sensitivity. (arXiv:2211.02139v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.02139](http://arxiv.org/abs/2211.02139)

    本文论证了查询公平指标可能会泄露受保护属性，提出了解决方案以保护隐私。

    

    现有法规禁止模型开发人员访问受保护属性（性别，种族等），这经常导致在不知道他们的受保护组的情况下对人群进行公平性评估。在这种情况下，机构通常采用模型开发人员（不可访问受保护属性训练模型）和合规团队（可能全面访问数据集以用于审计目的）之间的分离。但是，模型开发人员可能被允许通过查询合规团队获取组公平性指标来测试其模型的偏差。本文首先证明了仅仅查询公平指标（例如统计平等和平等赔率）可能会泄露个人的受保护属性给模型开发人员。我们证明了模型开发人员总是可以通过单个查询从测试数据集中识别目标个体的受保护属性。我们特别展示了一种方法，通过它可以平滑地减小敏感度来解决这个问题并保护隐私。

    Existing regulations prohibit model developers from accessing protected attributes (gender, race, etc.), often resulting in fairness assessments on populations without knowing their protected groups. In such scenarios, institutions often adopt a separation between the model developers (who train models with no access to the protected attributes) and a compliance team (who may have access to the entire dataset for auditing purposes). However, the model developers might be allowed to test their models for bias by querying the compliance team for group fairness metrics. In this paper, we first demonstrate that simply querying for fairness metrics, such as statistical parity and equalized odds can leak the protected attributes of individuals to the model developers. We demonstrate that there always exist strategies by which the model developers can identify the protected attribute of a targeted individual in the test dataset from just a single query. In particular, we show that one can rec
    
[^135]: 我不想说：在可选个人数据模型中保护用户同意

    I Prefer not to Say: Protecting User Consent in Models with Optional Personal Data. (arXiv:2210.13954v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.13954](http://arxiv.org/abs/2210.13954)

    该论文研究了个人可以选择与决策系统共享可选个人信息的机器学习模型，并提出了保护用户同意的PUC概念，为用户隐私保护提供了有力的解决方案。

    

    我们研究了一种机器学习模型，其中个人可以选择与决策系统共享可选个人信息，这在现代保险定价模型中很常见。一些用户同意使用他们的数据，而其他人则反对并保持其数据未公开。本文表明，不共享数据的决定本身可以被视为信息，应该受到保护，以尊重用户的隐私。这一观察结果引发了一个被忽视的问题，即如何确保保护其个人数据的用户不会因此受到任何不利影响。为了解决这个问题，我们对仅使用获得积极用户同意的信息的模型进行了保护要求的正式化。这排除了作出共享数据与否决定所包含的隐含信息。我们提出了Protected User Consent (PUC)概念，这是我们证明在保护要求下损失最小的解决方案。

    We examine machine learning models in a setup where individuals have the choice to share optional personal information with a decision-making system, as seen in modern insurance pricing models. Some users consent to their data being used whereas others object and keep their data undisclosed. In this work, we show that the decision not to share data can be considered as information in itself that should be protected to respect users' privacy. This observation raises the overlooked problem of how to ensure that users who protect their personal data do not suffer any disadvantages as a result. To address this problem, we formalize protection requirements for models which only use the information for which active user consent was obtained. This excludes implicit information contained in the decision to share data or not. We offer the first solution to this problem by proposing the notion of Protected User Consent (PUC), which we prove to be loss-optimal under our protection requirement. To
    
[^136]: 通过建模不规则多模态电子健康记录，改进医疗预测

    Improving Medical Predictions by Irregular Multimodal Electronic Health Records Modeling. (arXiv:2210.12156v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.12156](http://arxiv.org/abs/2210.12156)

    本文利用门控机制和时间注意力机制分别建模不规则时间序列和临床笔记表征，进而通过交替注意力机制整合多模态信息，从而改进医疗预测。

    

    电子健康记录 (EHRs) 通常包含数字时间序列和长的临床笔记序列，这些数据都是在不规则时间间隔内采集的。如何处理每个模态中的不规则性，并将其整合到多模态表示中以改进医疗预测，是一个具有挑战性的问题。本文提出的方法首先通过以下两种方式处理单个模态中的不规则性：(1)通过门控机制动态地将手工制作的填充嵌入式表征与学习到的插值嵌入式表征相结合来建模不规则时间序列，(2)通过时间注意力机制将一系列临床笔记表征转换成多变量不规则时间序列，并解决不规则性。对于多模态融合中的不规则性，本文提出了一种交替注意力机制，该机制跨越时间步长进行。据我们所知，这是第一篇彻底对多模态不规则性进行建模的工作。

    Health conditions among patients in intensive care units (ICUs) are monitored via electronic health records (EHRs), composed of numerical time series and lengthy clinical note sequences, both taken at irregular time intervals. Dealing with such irregularity in every modality, and integrating irregularity into multimodal representations to improve medical predictions, is a challenging problem. Our method first addresses irregularity in each single modality by (1) modeling irregular time series by dynamically incorporating hand-crafted imputation embeddings into learned interpolation embeddings via a gating mechanism, and (2) casting a series of clinical note representations as multivariate irregular time series and tackling irregularity via a time attention mechanism. We further integrate irregularity in multimodal fusion with an interleaved attention mechanism across temporal steps. To the best of our knowledge, this is the first work to thoroughly model irregularity in multimodalities
    
[^137]: 手术微调提高了适应分布偏移的效果

    Surgical Fine-Tuning Improves Adaptation to Distribution Shifts. (arXiv:2210.11466v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.11466](http://arxiv.org/abs/2210.11466)

    本研究表明，选择性地微调预训练模型的子集层（手术微调）在适应分布偏移的任务中效果更好，在真实数据中得到了验证，还在理论上证明在理想环境下，手术微调可以优于全层微调。

    

    在分布偏移下的迁移学习中，常见的方法是微调预训练模型的最后几层，保留已学特征同时适应新任务。本文表明，在这种情况下，有选择性地微调预训练模型的子集层（我们称之为手术微调）可以达到与或优于常用的微调方法，且不同类型的分布偏移影响着能够微调的层数。我们在七个真实数据任务中系统验证了这一结论。此外，理论上证明了在理想环境下，手术微调可以胜过全层微调。

    A common approach to transfer learning under distribution shift is to fine-tune the last few layers of a pre-trained model, preserving learned features while also adapting to the new task. This paper shows that in such settings, selectively fine-tuning a subset of layers (which we term surgical fine-tuning) matches or outperforms commonly used fine-tuning approaches. Moreover, the type of distribution shift influences which subset is more effective to tune: for example, for image corruptions, fine-tuning only the first few layers works best. We validate our findings systematically across seven real-world data tasks spanning three types of distribution shifts. Theoretically, we prove that for two-layer neural networks in an idealized setting, first-layer tuning can outperform fine-tuning all layers. Intuitively, fine-tuning more parameters on a small target dataset can cause information learned during pre-training to be forgotten, and the relevant information depends on the type of shif
    
[^138]: 基于上下文学习的可控对话模拟

    Controllable Dialogue Simulation with In-Context Learning. (arXiv:2210.04185v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.04185](http://arxiv.org/abs/2210.04185)

    本文提出了一种基于上下文学习的对话模拟方法，通过少量带注释的示例自动创建大量对话数据，比众包更加成本效益和节省时间，实验证明在低资源环境下使用模拟对话训练模型可以获得更好的性能。

    

    建立对话系统需要大量的带注释对话语料库，而这些数据集通常通过众包创建，费时费力。本文提出了一种名为 Dialogic 的新型对话模拟方法，它基于大尺度语言模型上下文学习，以自动化的方式创建数据集。在少量带注释的对话示例的启发下，Dialogic 自动选择上下文中的示例，促使 GPT-3 控制生成新的对话和注释。我们的方法可以快速扩展少量的对话数据，几乎没有人类介入和参数更新，因此比众包更具成本效益和节省时间。基于 MultiWOZ 数据集上的实验结果表明，在具有挑战性的低资源环境下，使用模拟对话训练模型的性能甚至比使用相同数量人工生成的对话更好，仅使用 85 条对话。

    Building dialogue systems requires a large corpus of annotated dialogues. Such datasets are usually created via crowdsourcing, which is expensive and time-consuming. In this paper, we propose \textsc{Dialogic}, a novel dialogue simulation method based on large language model in-context learning to automate dataset creation. Seeded with a few annotated dialogues, \textsc{Dialogic} automatically selects in-context examples for demonstration and prompts GPT-3 to generate new dialogues and annotations in a controllable way. Our method can rapidly expand a small set of dialogue data with minimum or zero \textit{human involvement} and \textit{parameter update} and is thus much more cost-efficient and time-saving than crowdsourcing. Experimental results on the MultiWOZ dataset demonstrate that training a model on the simulated dialogues leads to even better performance than using the same amount of human-generated dialogues under the challenging low-resource settings, with as few as 85 dialog
    
[^139]: 少即是多：面向任务的分层蒸馏用于语言模型压缩

    Less is More: Task-aware Layer-wise Distillation for Language Model Compression. (arXiv:2210.01351v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.01351](http://arxiv.org/abs/2210.01351)

    本文提出了一种新的面向任务的分层蒸馏方法（TED），通过设计任务感知的滤波器来对齐学生和教师的隐藏表示，选择有用的知识，减少知识差距，使学生模型更好地适应目标任务，实现了比最先进方法更少的参数下可比或更好的性能。

    

    分层蒸馏是将大模型（即教师模型）压缩为小模型（即学生模型）的强大工具。学生通过在每个中间层模仿教师的隐藏表示来从教师中蒸馏知识。然而，分层蒸馏也存在一些挑战。由于学生的模型容量比教师小，它通常会出现欠拟合;此外，教师的隐藏表示包含了学生未必需要的冗余信息。为了解决这些问题，我们提出了一种新颖的面向任务的分层蒸馏（TED）方法。TED设计任务感知滤波器来对齐每一层的学生和教师的隐藏表示。这些滤波器从隐藏表示中选择对目标任务有用的知识。因此，TED减少了两个模型之间的知识差距，并帮助学生更好地适应目标任务。我们在多种语言模型任务中评估了TED，并表明它可以在比最先进的方法少得多的参数情况下实现可比或甚至更好的性能。

    Layer-wise distillation is a powerful tool to compress large models (i.e. teacher models) into small ones (i.e., student models). The student distills knowledge from the teacher by mimicking the hidden representations of the teacher at every intermediate layer. However, layer-wise distillation is difficult. Since the student has a smaller model capacity than the teacher, it is often under-fitted. Furthermore, the hidden representations of the teacher contain redundant information that the student does not necessarily need for the target task's learning. To address these challenges, we propose a novel Task-aware layEr-wise Distillation (TED). TED designs task-aware filters to align the hidden representations of the student and the teacher at each layer. The filters select the knowledge that is useful for the target task from the hidden representations. As such, TED reduces the knowledge gap between the two models and helps the student to fit better on the target task. We evaluate TED in
    
[^140]: MLink：多个领域的黑盒模型链接实现协同推理

    MLink: Linking Black-Box Models from Multiple Domains for Collaborative Inference. (arXiv:2209.13883v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2209.13883](http://arxiv.org/abs/2209.13883)

    本文提出了新的学习任务：模型链接，旨在通过学习不同黑盒模型输出空间之间映射的模型链接，把它们连接起来。提出了支持链接不同黑盒机器学习模型的设计，解决了分布差异挑战，开发了一个调度算法，并在多个实验数据集上实现了高效的推理结果。

    

    在现实世界的机器学习中，模型推理的成本效益对于时延敏感的任务和资源受限设备至关重要。一个典型的困境是：为了提供复杂的智能服务（如智能城市），我们需要多个机器学习模型的推理结果，但成本预算（如GPU内存）不足以运行所有模型。在这项工作中，我们研究了不同黑盒机器学习模型之间的基础关系，并提出了一种新的学习任务：模型链接，旨在通过学习它们输出空间之间的映射（称为模型链接）来连接不同黑盒模型的知识。我们提出了支持链接异构黑盒机器学习模型的模型链接设计。此外，为了解决分布差异挑战，我们提出了模型链接的适应和聚合方法。基于我们提出的模型链接，我们开发了一个调度算法，名为MLink。通过启用协作多模型推理，我们的算法在多个实验数据集上实现了高效的推理结果。

    The cost efficiency of model inference is critical to real-world machine learning (ML) applications, especially for delay-sensitive tasks and resource-limited devices. A typical dilemma is: in order to provide complex intelligent services (e.g. smart city), we need inference results of multiple ML models, but the cost budget (e.g. GPU memory) is not enough to run all of them. In this work, we study underlying relationships among black-box ML models and propose a novel learning task: model linking, which aims to bridge the knowledge of different black-box models by learning mappings (dubbed model links) between their output spaces. We propose the design of model links which supports linking heterogeneous black-box ML models. Also, in order to address the distribution discrepancy challenge, we present adaptation and aggregation methods of model links. Based on our proposed model links, we developed a scheduling algorithm, named MLink. Through collaborative multi-model inference enabled b
    
[^141]: InFi：移动端推理的资源高效性学习过程中的端到端输入过滤

    InFi: End-to-End Learning to Filter Input for Resource-Efficiency in Mobile-Centric Inference. (arXiv:2209.13873v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2209.13873](http://arxiv.org/abs/2209.13873)

    本研究提出了一个端到端可学习的输入过滤框架，通过对推理模型和输入过滤器的假设复杂性进行理论比较，从而了解优化潜力。该框架减少冗余，降低推理成本，并在f值、推理速度和内存占用方面超越其他方法。

    

    移动端AI应用对模型推理的资源高效性有很高的要求。输入过滤是一种有前途的方法，可以消除冗余，从而降低推理成本。以往的研究已经为许多应用程序量身定制了有效的解决方案，但留下了两个基本问题未解答：（1）推理工作量的理论可过滤性，以指导输入过滤技术的应用，从而避免资源受限的移动应用程序的试错成本；（2）特征嵌入的鲁棒性区分度，以使输入过滤对多样化推理任务和输入内容普遍有效。为了回答这些问题，我们首先形式化输入过滤问题，并在理论上比较推理模型和输入过滤器的假设复杂性，以了解优化潜力。然后我们提出了第一个端到端可学习的输入过滤框架，涵盖了大多数最先进的方法，并在f值、推理速度和内存占用方面超越了它们。

    Mobile-centric AI applications have high requirements for resource-efficiency of model inference. Input filtering is a promising approach to eliminate the redundancy so as to reduce the cost of inference. Previous efforts have tailored effective solutions for many applications, but left two essential questions unanswered: (1) theoretical filterability of an inference workload to guide the application of input filtering techniques, thereby avoiding the trial-and-error cost for resource-constrained mobile applications; (2) robust discriminability of feature embedding to allow input filtering to be widely effective for diverse inference tasks and input content. To answer them, we first formalize the input filtering problem and theoretically compare the hypothesis complexity of inference models and input filters to understand the optimization potential. Then we propose the first end-to-end learnable input filtering framework that covers most state-of-the-art methods and surpasses them in f
    
[^142]: 从刚体图像中预测3D旋转动力学（未知质量分布）

    Learning to predict 3D rotational dynamics from images of a rigid body with unknown mass distribution. (arXiv:2209.11355v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2209.11355](http://arxiv.org/abs/2209.11355)

    该研究提出了一种基于物理知识的神经网络模型，通过多级预测流程，从刚体图像序列中预测3D旋转动力学，解决了标准深度学习方法无法揭示体内质量分布影响的问题。

    

    在许多实际情况下，当低维度测量不可用时，会有自由旋转的3D刚体的图像观察。然而，图像数据的高维数阻止了使用经典估计技术来学习动态。标准深度学习方法的有用性也受限于一个刚体图像无法揭示体内质量分布，而质量分布与初始角速度一起决定刚体旋转方式。我们提出了一种基于物理知识的神经网络模型，从图像序列中估计和预测3D旋转动力学。我们使用多级预测流程实现了这一目标，该流程将单个图像映射到与 $\mathbf{SO}(3)$ 同胚的潜在表示中，从潜在对中计算角速度，并使用Hamilton运动方程预测未来的潜在状态。我们在新的旋转刚体数据集上展示了我们方法的有效性。

    In many real-world settings, image observations of freely rotating 3D rigid bodies, may be available when low-dimensional measurements are not. However, the high-dimensionality of image data precludes the use of classical estimation techniques to learn the dynamics. The usefulness of standard deep learning methods is also limited because an image of a rigid body reveals nothing about the distribution of mass inside the body, which, together with initial angular velocity, is what determines how the body will rotate. We present a physics-informed neural network model to estimate and predict 3D rotational dynamics from image sequences. We achieve this using a multi-stage prediction pipeline that maps individual images to a latent representation homeomorphic to $\mathbf{SO}(3)$, computes angular velocities from latent pairs, and predicts future latent states using the Hamiltonian equations of motion. We demonstrate the efficacy of our approach on new rotating rigid-body datasets of sequenc
    
[^143]: 建模抽象目标预测下一步动作

    Predicting the Next Action by Modeling the Abstract Goal. (arXiv:2209.05044v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2209.05044](http://arxiv.org/abs/2209.05044)

    这篇论文提出了一种可以模型化抽象目标，以降低行动预测中不确定性的行动预测模型。使用视觉表征来描述动作和目标信息，并设计抽象目标为一个分布。该模型可在Epic-Kitchen数据集上实现最先进性能。

    

    预测人类动作的问题具有固有的不确定性，但是，如果我们有关于动作实现目标的感知，可以降低这种不确定性。本文提出了一种行动预测模型，利用目标信息来减少未来预测中的不确定性。通过视觉表征，我们描述了动作和目标的信息。通过此方法，我们得出了一个称为抽象目标的新概念，其取决于观察到的视觉特征序列，用于行动预测。我们将抽象目标设计为一个分布，其参数是使用变分递归网络估计的。我们对下一个动作进行多次采样，并引入目标一致性度量来确定从抽象目标得出的最佳候选动作。我们的方法在极具挑战性的Epic-Kitchen数据集上取得了令人印象深刻的结果，并实现了最先进的性能。

    The problem of anticipating human actions is an inherently uncertain one. However, we can reduce this uncertainty if we have a sense of the goal that the actor is trying to achieve. Here, we present an action anticipation model that leverages goal information for the purpose of reducing the uncertainty in future predictions. Since we do not possess goal information or the observed actions during inference, we resort to visual representation to encapsulate information about both actions and goals. Through this, we derive a novel concept called abstract goal which is conditioned on observed sequences of visual features for action anticipation. We design the abstract goal as a distribution whose parameters are estimated using a variational recurrent network. We sample multiple candidates for the next action and introduce a goal consistency measure to determine the best candidate that follows from the abstract goal. Our method obtains impressive results on the very challenging Epic-Kitchen
    
[^144]: 二分图匹配中的不同群体公平性下的个体公平性——一种近似框架

    Individual fairness under Varied Notions of Group Fairness in Bipartite Matching -- One Framework to Approximate Them Al. (arXiv:2208.09951v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2208.09951](http://arxiv.org/abs/2208.09951)

    本文研究在满足群体和个体公平性约束的情况下分配物品给平台的问题，并提出了一种近似框架，可以用来近似文献中提出的群体公平性概念，同时实现个体公平性。

    

    本文研究在满足群体和个体公平性约束的情况下分配物品给平台的问题。每个物品都与某些群体相关联，并且对平台有优先顺序。每个平台通过指定每个群体可以与之匹配的物品数量的上限和下限来执行群体公平性。尽管可能存在满足群体公平性约束的多个最优解，我们旨在通过计算一个分布来实现“随机个体公平性”，使得每个物品被匹配到其前几个选择之一的合理概率。当每个物品可以属于多个群体时，即使所有群体下限均为0且没有个体公平性约束，寻找最大大小群体公平匹配的问题也是NP-难的。对于一共$n$个物品，当一个物品最多属于$\Delta$个群体，并且所有群体的上限和下限都是常数时，我们实现了$O(\Delta \log n)$近似算法。我们还证明，对于所有群体公平性约束都是区间的特殊情况，我们可以高效地计算满足这些约束的个体公平匹配的分布。因此，我们的框架可以用于近似文献中提出的群体公平性概念，同时实现个体公平性。

    We consider the problem of assigning items to platforms while satisfying group and individual fairness constraints. Each item is associated with certain groups and has a preference ordering over platforms. Each platform enforces group fairness by specifying an upper and a lower bound on the number of items that can be matched to it from each group. Although there may be multiple optimal solutions that satisfy the group fairness constraints, we aim to achieve `probabilistic individual fairness' by computing a distribution over `group fair' matchings such that each item has a reasonable probability of being matched to one of its top choices. When each item can belong to multiple groups, the problem of finding a maximum size group-fair matching is NP-hard even when all the group lower bounds are 0, and there are no individual fairness constraints. Given a total of $n$ items, we achieve a $O(\Delta \log n)$ approximation algorithm when an item can belong to at most $\Delta$ groups, and all
    
[^145]: 后验概念解释何时可识别？

    When are Post-hoc Conceptual Explanations Identifiable?. (arXiv:2206.13872v4 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2206.13872](http://arxiv.org/abs/2206.13872)

    本论文提出了可识别的概念发现方法，可以恢复出多个已知的概念，以确保解释的可靠性。对于具有依赖关系的概念，提出了两种新的方法，利用图像生成过程的功能组合性质。该方法明显优于现有方法。

    

    学习嵌入通常需要通过概念解释来理解和分解，这种需求在解释中不包含有效概念标签的情况下尤为显著。为了提供后验解释，概念发现方法会在已训练的嵌入空间中搜索解释性强的概念，例如物体形状或颜色。与之前的工作不同，我们认为概念发现应该是可识别的，这意味着可以被证明地恢复出多个已知的概念，以确保解释的可靠性。为了作为一个起点，我们明确地将概念发现与传统方法（例如主成分分析和独立成分分析）联系起来，并通过表明它们可以恢复具有非高斯分布的独立概念来阐明这一点。对于具有依赖关系的概念，我们提出了两种新的方法，利用图像生成过程的功能组合性质。我们的可证明可识别的概念发现方法明显优于现有方法。

    Interest in understanding and factorizing learned embedding spaces through conceptual explanations is steadily growing. When no human concept labels are available, concept discovery methods search trained embedding spaces for interpretable concepts like object shape or color that can be used to provide post-hoc explanations for decisions. Unlike previous work, we argue that concept discovery should be identifiable, meaning that a number of known concepts can be provably recovered to guarantee reliability of the explanations. As a starting point, we explicitly make the connection between concept discovery and classical methods like Principal Component Analysis and Independent Component Analysis by showing that they can recover independent concepts with non-Gaussian distributions. For dependent concepts, we propose two novel approaches that exploit functional compositionality properties of image-generating processes. Our provably identifiable concept discovery methods substantially outpe
    
[^146]: 全局上下文视觉Transformer

    Global Context Vision Transformers. (arXiv:2206.09959v5 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2206.09959](http://arxiv.org/abs/2206.09959)

    提出了全局上下文视觉Transformer (GC ViT) 架构，利用全局上下文自注意力模块和标准的局部自注意力对长距离和短距离空间相互作用进行有效而高效的建模，同时解决了ViTs中缺乏归纳偏差的问题，在图像分类、目标检测和语义分割任务中表现出最先进的结果。

    

    我们提出了一种新颖的架构——全局上下文视觉Transformer (GC ViT), 可以增强计算机视觉中的参数和计算利用。我们的方法利用全局上下文自注意力模块和标准的局部自注意力，对长距离和短距离空间相互作用进行有效而高效的建模，无需进行像计算注意力掩码或移动本地窗口这样的昂贵操作。并且，我们解决了ViTs中缺乏归纳偏差的问题，并在我们的架构中使用一种修改后的融合反向残差块。我们提出的GC ViT在图像分类、目标检测和语义分割任务中均取得了最先进的成果。在ImageNet-1K数据集上进行分类，GC ViT的51M、90M和201M参数变体在224像素分辨率下都能够达到84.3%、85.0%和85.7%的Top-1精度，而且无需任何预训练，因此超越了CNN-based Conv等先前的艺术品。

    We propose global context vision transformer (GC ViT), a novel architecture that enhances parameter and compute utilization for computer vision. Our method leverages global context self-attention modules, joint with standard local self-attention, to effectively and efficiently model both long and short-range spatial interactions, without the need for expensive operations such as computing attention masks or shifting local windows. In addition, we address the lack of the inductive bias in ViTs, and propose to leverage a modified fused inverted residual blocks in our architecture. Our proposed GC ViT achieves state-of-the-art results across image classification, object detection and semantic segmentation tasks. On ImageNet-1K dataset for classification, the variants of GC ViT with 51M, 90M and 201M parameters achieve 84.3%, 85.0% and 85.7% Top-1 accuracy, respectively, at 224 image resolution and without any pre-training, hence surpassing comparably-sized prior art such as CNN-based Conv
    
[^147]: 我知道你去年训练了什么：关于窃取机器学习模型和防御的调查

    I Know What You Trained Last Summer: A Survey on Stealing Machine Learning Models and Defences. (arXiv:2206.08451v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.08451](http://arxiv.org/abs/2206.08451)

    随着机器学习即服务（MLaaS）的普及，用户可以使用最复杂的机器学习模型的预测，但也危及了MLaaS提供商的知识产权，攻击者可以创建一个具备相同行为的模型副本，本文针对模型窃取的攻击和相应的对策进行了综合调查。

    

    机器学习即服务（MLaaS）已经成为一种广泛的范 paradigm，通过按需付费的原则，甚至可以为客户提供最复杂的机器学习模型的预测。这使用户可以避免耗时的数据收集、超参数调整和模型训练过程。然而，通过让客户访问（其预测的）模型，MLaaS 提供商危及其知识产权，如敏感的训练数据、优化的超参数或学习的模型参数。攻击者可以使用仅预测标签创建具有（几乎）相同行为的模型副本。虽然描述了许多这种攻击的变体，但只提出了分散的防御策略，涉及孤立的威胁。这提出了对模型窃取领域进行彻底系统化的必要性，以全面了解为什么这些攻击成功以及如何全面地进行防御。我们通过提供一项综合性调查来解决这一问题，涵盖模型窃取攻击和相应的对策。

    Machine Learning-as-a-Service (MLaaS) has become a widespread paradigm, making even the most complex machine learning models available for clients via e.g. a pay-per-query principle. This allows users to avoid time-consuming processes of data collection, hyperparameter tuning, and model training. However, by giving their customers access to the (predictions of their) models, MLaaS providers endanger their intellectual property, such as sensitive training data, optimised hyperparameters, or learned model parameters. Adversaries can create a copy of the model with (almost) identical behavior using the the prediction labels only. While many variants of this attack have been described, only scattered defence strategies have been proposed, addressing isolated threats. This raises the necessity for a thorough systematisation of the field of model stealing, to arrive at a comprehensive understanding why these attacks are successful, and how they could be holistically defended against. We addr
    
[^148]: 基于因果和空间约束的多任务网络的人类流动预测

    Human Mobility Prediction with Causal and Spatial-constrained Multi-task Network. (arXiv:2206.05731v4 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2206.05731](http://arxiv.org/abs/2206.05731)

    本文提出了一种基于因果和空间约束的多任务网络，名为CSLSL，用于人类流动的预测，并且在实验中取得了比现有基线模型更好的准确性和可解释性。

    

    建立人类流动模型有助于理解人们在城市中如何获取资源，与他人接触，因此有助于城市规划、流行病控制和基于位置的广告等各种应用。下一个位置的预测是个人流动模型中的一个决定性任务，通常被视为序列建模，使用马尔可夫或基于RNN的方法来解决。然而，现有的模型并没有给个人旅行决策的逻辑和人口集体行为的再现带来足够的重视。因此，我们提出了一种基于因果和空间约束的长短期学习器(CSLSL)，用于下一个位置的预测。CSLSL利用基于多任务学习的因果结构明确地建模 "\textit{when$\rightarrow$what$\rightarrow$where}" 或 "\textit{ time$\rightarrow$activity$\rightarrow$location}" 决策逻辑。我们接下来提出一个空间约束的损失函数作为辅助任务，将下一个位置的预测与城市环境的空间配置协调起来。两个大规模真实世界数据集的实验证明，我们的模型在准确性和可解释性方面优于现有的基线模型。

    Modeling human mobility helps to understand how people are accessing resources and physically contacting with each other in cities, and thus contributes to various applications such as urban planning, epidemic control, and location-based advertisement. Next location prediction is one decisive task in individual human mobility modeling and is usually viewed as sequence modeling, solved with Markov or RNN-based methods. However, the existing models paid little attention to the logic of individual travel decisions and the reproducibility of the collective behavior of population. To this end, we propose a Causal and Spatial-constrained Long and Short-term Learner (CSLSL) for next location prediction. CSLSL utilizes a causal structure based on multi-task learning to explicitly model the "\textit{when$\rightarrow$what$\rightarrow$where}", a.k.a. "\textit{time$\rightarrow$activity$\rightarrow$location}" decision logic. We next propose a spatial-constrained loss function as an auxiliary task, 
    
[^149]: 从原始数据中学习Answer Set Programs的神经符号学习方法

    Neuro-Symbolic Learning of Answer Set Programs from Raw Data. (arXiv:2205.12735v7 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2205.12735](http://arxiv.org/abs/2205.12735)

    本文提出了一种神经符号归纳学习器（NSIL）的方法，它训练一个通用的神经网络来从原始数据中提取潜在的概念，并学习将潜在概念映射到目标标签的符号知识。

    

    人工智能的最终目标之一是协助人类进行复杂的决策。神经符号学习旨在将符号技术的可解释性与深度学习从原始数据中学习的能力相结合，是实现此目标的一个有前途的方向。然而，大多数现有方法需要手动构建符号知识，而在考虑端到端训练时，这些方法要么仅限于学习确定的程序，要么仅限于训练二进制神经网络。在本文中，我们介绍了神经符号归纳学习器（NSIL），一种方法，它训练一个通用的神经网络，从原始数据中提取潜在的概念，并学习将潜在概念映射到目标标签的符号知识。我们方法的创新之处在于一种基于神经和符号组件的性能的训练方法，用于调整符号知识的学习。我们在三个不同的问题域上评估了NSIL的性能。

    One of the ultimate goals of Artificial Intelligence is to assist humans in complex decision making. A promising direction for achieving this goal is Neuro-Symbolic AI, which aims to combine the interpretability of symbolic techniques with the ability of deep learning to learn from raw data. However, most current approaches require manually engineered symbolic knowledge, and where end-to-end training is considered, such approaches are either restricted to learning definite programs, or are restricted to training binary neural networks. In this paper, we introduce Neuro-Symbolic Inductive Learner (NSIL), an approach that trains a general neural network to extract latent concepts from raw data, whilst learning symbolic knowledge that maps latent concepts to target labels. The novelty of our approach is a method for biasing the learning of symbolic knowledge, based on the in-training performance of both neural and symbolic components. We evaluate NSIL on three problem domains of different
    
[^150]: 协方差矩阵自适应MAP退火算法

    Covariance Matrix Adaptation MAP-Annealing. (arXiv:2205.10752v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.10752](http://arxiv.org/abs/2205.10752)

    本文提出了一种新的质量多样性算法——协方差矩阵自适应MAP退火（CMA-MAE），用于解决过早地放弃目标以进行探索、难以探索平坦目标以及低分辨率档案性能差等问题，实现了最先进的性能和鲁棒性。

    

    单目标优化算法通过目标函数寻找最高质量的单一解决方案。质量多样性（QD）优化算法，例如协方差矩阵自适应MAP-精英（CMA-ME），寻找一组既在目标函数方面高质量、又在特定度量函数方面多样性的解决方案集。但是CMA-ME存在三个主要的限制：过早地放弃目标以进行探索、难以探索平坦目标以及低分辨率档案性能差。我们提出了一种新的质量多样性算法，协方差矩阵自适应MAP退火（CMA-MAE），以解决所有三个限制。我们提供了每个限制的新算法的理论证明。我们的理论支撑了我们的实验，结果表明CMA-MAE达到了最先进的性能和鲁棒性。

    Single-objective optimization algorithms search for the single highest-quality solution with respect to an objective. Quality diversity (QD) optimization algorithms, such as Covariance Matrix Adaptation MAP-Elites (CMA-ME), search for a collection of solutions that are both high-quality with respect to an objective and diverse with respect to specified measure functions. However, CMA-ME suffers from three major limitations highlighted by the QD community: prematurely abandoning the objective in favor of exploration, struggling to explore flat objectives, and having poor performance for low-resolution archives. We propose a new quality diversity algorithm, Covariance Matrix Adaptation MAP-Annealing (CMA-MAE), that addresses all three limitations. We provide theoretical justifications for the new algorithm with respect to each limitation. Our theory informs our experiments, which support the theory and show that CMA-MAE achieves state-of-the-art performance and robustness.
    
[^151]: 人工智能与自治系统的基于原则的伦理保证论证模式

    A Principles-based Ethics Assurance Argument Pattern for AI and Autonomous Systems. (arXiv:2203.15370v4 [cs.CY] UPDATED)

    [http://arxiv.org/abs/2203.15370](http://arxiv.org/abs/2203.15370)

    本文介绍了一种基于原则的伦理保证论证模式，用于确保特定的AI/AS在运行时在伦理上是可接受的。该模式采用了公正、行善、不伤害、尊重人的自主权、透明度等伦理原则，缩写为PRAISE。

    

    保证案例是一种结构化的论证，通常由安全工程师制作，以传达对于关键或复杂系统（例如飞机）在其既定环境中具有足够安全性的信心。保证案例经常用于系统的第三方审批。在值得信赖的人工智能和自治系统（AI/AS）研究社区中，一个新兴的命题是使用保证案例在确定的环境中运行时，确保特定的AI/AS在伦理上是可接受的。本文大大发展了这个命题并具体阐述了它。它将保证案例方法与一组伦理原则结合起来，以构建一个基于原则的伦理保证论证模式。这些原则包括公正、行善、不伤害、尊重人的自主权和透明度原则。该论证模式以缩写PRAISE命名。本文介绍了该论证模式的目的和具体实施方法，并逐一解释了其组成部分。

    An assurance case is a structured argument, typically produced by safety engineers, to communicate confidence that a critical or complex system, such as an aircraft, will be acceptably safe within its intended context. Assurance cases often inform third party approval of a system. One emerging proposition within the trustworthy AI and autonomous systems (AI/AS) research community is to use assurance cases to instil justified confidence that specific AI/AS will be ethically acceptable when operational in well-defined contexts. This paper substantially develops the proposition and makes it concrete. It brings together the assurance case methodology with a set of ethical principles to structure a principles-based ethics assurance argument pattern. The principles are justice, beneficence, non-maleficence, and respect for human autonomy, with the principle of transparency playing a supporting role. The argument pattern, shortened to the acronym PRAISE, is described. The objective of the pro
    
[^152]: 使用动作特征学习直觉策略

    Learning Intuitive Policies Using Action Features. (arXiv:2201.12658v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2201.12658](http://arxiv.org/abs/2201.12658)

    本论文研究了网络体系结构对多智能体协作中学习算法利用动作特征和观测特征之间语义关系的影响，发现联合处理观察特征和动作特征的特征表示的注意力机制架构可以学习直觉策略，并且这样的代理与人类协作而无需接受人类数据训练。

    

    多智能体协作中未解决的挑战是使AI代理能够利用动作特征和观测特征之间的语义关系。人类以高度直觉的方式利用这些关系。为了解决这个挑战，我们研究了网络体系结构对学习算法利用这些语义关系的倾向的影响。在一个程序生成的协作任务中，我们发现联合处理观察特征和动作特征的特征表示的注意力机制架构具有更好的归纳偏差，可以学习直觉策略。通过细粒度的评估和场景分析，我们展示了得到的策略是可解释的。此外，这样的代理与人类协作而无需接受任何人类数据训练。

    An unaddressed challenge in multi-agent coordination is to enable AI agents to exploit the semantic relationships between the features of actions and the features of observations. Humans take advantage of these relationships in highly intuitive ways. For instance, in the absence of a shared language, we might point to the object we desire or hold up our fingers to indicate how many objects we want. To address this challenge, we investigate the effect of network architecture on the propensity of learning algorithms to exploit these semantic relationships. Across a procedurally generated coordination task, we find that attention-based architectures that jointly process a featurized representation of observations and actions have a better inductive bias for learning intuitive policies. Through fine-grained evaluation and scenario analysis, we show that the resulting policies are human-interpretable. Moreover, such agents coordinate with people without training on any human data.
    
[^153]: 深度序列号：用于 DNN 知识产权保护的计算水印

    Deep Serial Number: Computational Watermarking for DNN Intellectual Property Protection. (arXiv:2011.08960v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2011.08960](http://arxiv.org/abs/2011.08960)

    本文提出了一种名为 Deep Serial Number (DSN) 的水印算法用于深度神经网络的知识产权保护。该算法在DNN中实现序列号嵌入，只有输入有效序列号的情况下，DNN才能正确工作。

    

    本文提出了一种特别为深度神经网络（DNN）设计的简单而有效的水印算法 Deep Serial Number（DSN）。与传统方法在DNN中引入标识信号不同，我们的方法探索了一种新的DNN知识产权保护机制，有效地阻止了攻击者使用窃取的网络。借鉴序列号在保护传统软件知识产权方面的成功，我们提出了在DNN中实现序列号嵌入的第一个实现。为此，DSN被集成到知识蒸馏框架中，其中首先训练了一个私有的教师DNN。随后，其知识被提炼并传授给一系列定制的学生DNN。每个客户DNN仅在输入有效序列号的情况下才能正确工作。在各种应用中的实验结果证明了DSN在防止未经授权的使用的同时不会损害原始DNN性能的有效性。

    In this paper, we present DSN (Deep Serial Number), a simple yet effective watermarking algorithm designed specifically for deep neural networks (DNNs). Unlike traditional methods that incorporate identification signals into DNNs, our approach explores a novel Intellectual Property (IP) protection mechanism for DNNs, effectively thwarting adversaries from using stolen networks. Inspired by the success of serial numbers in safeguarding conventional software IP, we propose the first implementation of serial number embedding within DNNs. To achieve this, DSN is integrated into a knowledge distillation framework, in which a private teacher DNN is initially trained. Subsequently, its knowledge is distilled and imparted to a series of customized student DNNs. Each customer DNN functions correctly only upon input of a valid serial number. Experimental results across various applications demonstrate DSN's efficacy in preventing unauthorized usage without compromising the original DNN performan
    

