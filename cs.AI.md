# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Continual Diffusion: Continual Customization of Text-to-Image Diffusion with C-LoRA.](http://arxiv.org/abs/2304.06027) | 本文提出了一种新方法C-LoRA，用于持续自定制文本到图像扩散模型，并避免了新概念加入后过去相似概念的图像质量下降的问题。 |
| [^2] | [Exploiting Logic Locking for a Neural Trojan Attack on Machine Learning Accelerators.](http://arxiv.org/abs/2304.06017) | 本文研究了如何利用逻辑锁定来破坏神经加速器的安全性，并展示了如何利用特洛伊秘钥来产生神经特洛伊式的后门。在基准数据集上进行的实验表明，我们的方法可以生成诱导大量错误分类率的特洛伊秘钥，同时保持高的特洛伊激活概率。 |
| [^3] | [Object-agnostic Affordance Categorization via Unsupervised Learning of Graph Embeddings.](http://arxiv.org/abs/2304.05989) | 本文通过无监督学习相似物体交互，诱导物体能力簇，使用新颖的深度感知定性空间表示法构建活动图并进行聚类，从而实现具有不确定交互开放集合的类别无关物体的能力分类。 |
| [^4] | [KubeEdge-Sedna v0.3: Towards Next-Generation Automatically Customized AI Engineering Scheme.](http://arxiv.org/abs/2304.05985) | KubeEdge-Sedna v0.3提出了边缘-云协作终身学习的问题，并发布了行业首个开源方案，解决了边缘数据异构性和边缘人工智能服务离线自主性的挑战，从而实现了AI工程和自动化。 |
| [^5] | [Neural Attention Forests: Transformer-Based Forest Improvement.](http://arxiv.org/abs/2304.05980) | 本论文提出一种名为神经注意森林的新方法，将注意力机制引入到随机森林中，通过神经网络计算获得注意权重，进而解决回归和分类任务。 |
| [^6] | [Bayesian Causal Inference in Doubly Gaussian DAG-probit Models.](http://arxiv.org/abs/2304.05976) | 本文讨论在观测数据下，通过构造两个有向无环图，并共享公共参数来对两组的二元响应变量和协变量进行建模。双高斯DAG-probit模型是在此基础上提出的，在模型中我们可以估计每个节点的效应大小。 |
| [^7] | [UAV Obstacle Avoidance by Human-in-the-Loop Reinforcement in Arbitrary 3D Environment.](http://arxiv.org/abs/2304.05959) | 本文提出了一种基于深度强化学习和人机交互的避障方法，可在大规模三维复杂环境中控制无人机实现任意目标点的导航任务。 |
| [^8] | [CMOS + stochastic nanomagnets: heterogeneous computers for probabilistic inference and learning.](http://arxiv.org/abs/2304.05949) | 本文展示了如何将基于随机磁隧道结（sMTJ）的概率比特（p位）与多功能可编程门阵列（FPGA）相结合，设计出一种能源高效的异构CMOS + X（X = sMTJ）原型，其成功地执行了概率推理和异步Boltzmann学习。 |
| [^9] | [Diffusion models with location-scale noise.](http://arxiv.org/abs/2304.05907) | 本研究研究了用于生成模型的不同噪声分布，证明了高斯分布在扩散模型（DMs）中表现最佳。 |
| [^10] | [Representation Learning with Multi-Step Inverse Kinematics: An Efficient and Optimal Approach to Rich-Observation RL.](http://arxiv.org/abs/2304.05889) | 本文提出了一种名为MusIK的新算法，利用多步逆运动学实现表示学习和系统探索相结合，达到计算高效和样本复杂度最优的效果，成功应用于富观测强化学习任务中。 |
| [^11] | [Adaptive Gated Graph Convolutional Network for Explainable Diagnosis of Alzheimer's Disease using EEG Data.](http://arxiv.org/abs/2304.05874) | 本文提出了一种自适应门控图卷积网络(AGGCN)，该网络结合卷积节点特征增强和功能连接度量自适应学习图结构，实现了高精度的阿尔茨海默病诊断，并提供了重要的脑区信息。 |
| [^12] | [Learning to Communicate and Collaborate in a Competitive Multi-Agent Setup to Clean the Ocean from Macroplastics.](http://arxiv.org/abs/2304.05872) | 本文提出了一种基于图神经网络（GNN）的、用于多智能体交互式海洋废弃物清理的通信机制，使得不同代理之间可以协作竞争并实现收集废弃物的最大化。 |
| [^13] | [LMR: Lane Distance-Based Metric for Trajectory Prediction.](http://arxiv.org/abs/2304.05869) | LMR是一种基于车道距离的度量，适用于轨迹预测中的结构化环境，相比传统的欧氏距离度量更准确。 |
| [^14] | [Learning Homographic Disambiguation Representation for Neural Machine Translation.](http://arxiv.org/abs/2304.05860) | 本文提出了一种利用同义词句子建立同形异义词词级消歧表示（HDR）以改进神经机器翻译的方法。 |
| [^15] | [RESET: Revisiting Trajectory Sets for Conditional Behavior Prediction.](http://arxiv.org/abs/2304.05856) | 这篇论文提出了一种新的用于条件驾驶行为预测的基于集合法的轨迹预测方法RESET，可以预测灵活数量的轨迹而不影响运行时间或值域。 |
| [^16] | [Optimal Interpretability-Performance Trade-off of Classification Trees with Black-Box Reinforcement Learning.](http://arxiv.org/abs/2304.05839) | 本文提出了一种用于探索决策树空间的强化学习框架来学习紧凑的决策树并最佳化可解释性与性能之间的平衡。 |
| [^17] | [DartsReNet: Exploring new RNN cells in ReNet architectures.](http://arxiv.org/abs/2304.05838) | 本文使用 DARTS 方法对标准 RNN 单元进行改进，提出了用于 ReNet 架构的新的 RNN 单元，有效提高了在 CIFAR-10 和 SVHN 数据集上的分类效果。 |
| [^18] | [A Game-theoretic Framework for Federated Learning.](http://arxiv.org/abs/2304.05836) | 本文提出了一个名为联邦学习安全博弈（FLSG）的博弈论框架，该框架同时考虑到联邦学习的保护者和攻击者的收益，包括计算成本、FL模型效用和隐私泄漏风险，并提出了一个实用算法来近似oracle并保持隐私。研究表明该算法对于预防和检测现实世界中的联邦学习攻击具有有效性。 |
| [^19] | [Few Shot Semantic Segmentation: a review of methodologies and open challenges.](http://arxiv.org/abs/2304.05832) | 本文综述了少样本学习在语义分割中的应用，并提出了新的分类法，并讨论了当前的限制和展望。 |
| [^20] | [GDP nowcasting with artificial neural networks: How much does long-term memory matter?.](http://arxiv.org/abs/2304.05805) | 通过比较四种人工神经网络和动态因子模型对美国GDP季度增长的预测表现，研究发现在平衡经济增长期间，更长的输入序列能够实现更准确的预测，但是这种效果会在不到两年的时间内消失。在经济动荡时期，长期记忆的效果变得明显。 |
| [^21] | [Proximity Forest 2.0: A new effective and scalable similarity-based classifier for time series.](http://arxiv.org/abs/2304.05800) | Proximity Forest 2.0是一种新的有效且可扩展的基于相似性的时间序列分类器，优于先前最先进的基于相似性的分类器以及最先进的基于内核、神经网络和混合方法在特定数据集上的表现。 |
| [^22] | [Using Multiple RDF Knowledge Graphs for Enriching ChatGPT Responses.](http://arxiv.org/abs/2304.05774) | 本研究提出了一个名为GPToLODS的原型系统，可以使用数百个RDF知识图谱为ChatGPT提供更多信息和证据，丰富ChatGPT的回复。 |
| [^23] | [Wild Face Anti-Spoofing Challenge 2023: Benchmark and Results.](http://arxiv.org/abs/2304.05753) | 前人的人脸防伪（FAS）技术应用于实际场景仍然存在限制，因为当前公开的FAS数据集数量和多样性不足，引起过拟合和场景误判。通过引入野外人脸防伪（WFAS）数据集，该研究提高了数据规模和多样化程度，促进了FAS技术的发展。 |
| [^24] | [Boosting long-term forecasting performance for continuous-time dynamic graph networks via data augmentation.](http://arxiv.org/abs/2304.05749) | 本研究提出了一种插入式模块——不确定性掩蔽混合（UmmU），它能够在中间层嵌入中进行不确定性估计，进而增强嵌入的不确定性，使其具有更好的泛化性能，从而显著提高了连续时间动态图网络的长期预测性能。 |
| [^25] | [Preemptively Pruning Clever-Hans Strategies in Deep Neural Networks.](http://arxiv.org/abs/2304.05727) | 本文提出了一种新方法，Explanation-Guided Exposure Minimization (EGEM)，该方法预防性地修剪了ML模型中未受到积极解释反馈的变化，从而大大减少了对隐藏Clever Hans策略的依赖，并实现了更高的性能。 |
| [^26] | [Human-Robot Skill Transfer with Enhanced Compliance via Dynamic Movement Primitives.](http://arxiv.org/abs/2304.05703) | 本文介绍了一种通过提取人的动态特征来自动调整DMP框架参数，以增强机器人轨迹规划性能的方法。 |
| [^27] | [Precise localization of corneal reflections in eye images using deep learning trained on synthetic data.](http://arxiv.org/abs/2304.05673) | 该论文提出了一种使用深度学习在眼部图像中准确定位角膜反射的方法，无需对真实眼部图像进行注释，仅使用模拟数据进行训练，该方法表现出色且提供了一种可行的解决方案。 |
| [^28] | [RIFormer: Keep Your Vision Backbone Effective While Removing Token Mixer.](http://arxiv.org/abs/2304.05659) | 本文提出一种在去除视觉Transformer中的Token Mixer的同时，保持视觉Backbone有效性的方法，配备所提出的优化策略能够构建一个非常简单的视觉Backbone并获得令人鼓舞的性能，同时在推断期间享受高效性。 |
| [^29] | [Multi-agent Policy Reciprocity with Theoretical Guarantee.](http://arxiv.org/abs/2304.05632) | 本论文提出了一种新的多智能体策略互惠（PR）框架，能够通过定义邻接空间和设计即插即用模块在不匹配的状态下充分利用交叉智能体策略，提高了性能，同时具有理论保障，能在个体感知奖励的情况下稳定收敛于最优值函数。 |
| [^30] | [Deep Stable Multi-Interest Learning for Out-of-distribution Sequential Recommendation.](http://arxiv.org/abs/2304.05615) | 提出了DESMIL，一个新的多兴趣网络，用于序列推荐模型中解决跨领域泛化问题，通过去相关提取的多个兴趣向量，消除虚假相关性，实验结果证明其优于现有的最先进方法。 |
| [^31] | [ChatGPT Beyond English: Towards a Comprehensive Evaluation of Large Language Models in Multilingual Learning.](http://arxiv.org/abs/2304.05613) | 这篇论文评估了ChatGPT在22种不同的语言中的表现，并创建了一个多语言基准数据集。结果表明ChatGPT在各种语言和任务上表现出显著的一致性和功效，这为多语言学习和LLMs的研究提供了强有力的支持。 |
| [^32] | [Semantic Feature Verification in FLAN-T5.](http://arxiv.org/abs/2304.05591) | 本研究表明大规模语言模型可以极大地增强传统的语义特征规范验证方法，使之能够捕捉超过人类规范范畴的信息，对于我们理解人类和机器的概念表示具有重要意义。 |
| [^33] | [Does Informativeness Matter? Active Learning for Educational Dialogue Act Classification.](http://arxiv.org/abs/2304.05578) | 本文研究基于主动学习方法的教育对话行为分类，提出了一种新的方法来选择信息样本，并且能够优于随机抽样方法和其他AL方法。 |
| [^34] | [Improving Diffusion Models for Scene Text Editing with Dual Encoders.](http://arxiv.org/abs/2304.05568) | DIFFSTE是一种用于改进场景文字编辑的方法，通过使用双编码器设计，包括字符编码器以提高文本清晰度和指令编码器以更好地控制样式，有效解决了现有模型在渲染正确文本和控制文本样式方面的困难 |
| [^35] | [Learning Transferable Pedestrian Representation from Multimodal Information Supervision.](http://arxiv.org/abs/2304.05554) | 本文提出了一种新框架VAL-PAT，在多模态信息的监督下学习可转移的行人表示，以增强各种行人分析任务，其中包括自我监督对比学习、图像-文本对比学习和多属性分类。 |
| [^36] | [DynamicDet: A Unified Dynamic Architecture for Object Detection.](http://arxiv.org/abs/2304.05552) | 提出了一种名为DynamicDet的物体检测动态框架，它具有自适应路由器、退出准则和可变速度推理策略的优化策略，可实现在不同精度和速度之间平衡。 |
| [^37] | [CLCLSA: Cross-omics Linked embedding with Contrastive Learning and Self Attention for multi-omics integration with incomplete multi-omics data.](http://arxiv.org/abs/2304.05542) | 本文提出了一种基于对比学习和自注意力的深度学习方法CLCLSA，可用于不完整多组学数据的一体化，达到最先进的性能。 |
| [^38] | [MoMo: A shared encoder Model for text, image and multi-Modal representations.](http://arxiv.org/abs/2304.05523) | MoMo是一个自监督的共享编码器模型，可以用于处理文本、图像和多模态数据，并且具备高效的性能。通过单一的变压器和阶段性的训练策略，在保留信息的同时，使用更少的参数和预训练数据，取得了与强模型相当的表现。 |
| [^39] | [Control invariant set enhanced reinforcement learning for process control: improved sampling efficiency and guaranteed stability.](http://arxiv.org/abs/2304.05509) | 本文提出了一种称为控制不变集增强强化学习的方法，通过控制不变集的应用提高稳定性保证和采样效率。 |
| [^40] | [DistHD: A Learner-Aware Dynamic Encoding Method for Hyperdimensional Classification.](http://arxiv.org/abs/2304.05503) | DistHD是一种适用于资源受限设备的学习感知动态编码技术，可以有效地识别和重构影响学习质量的维度，以显著较低的维度提高准确性和加速学习过程。 |
| [^41] | [GraphGANFed: A Federated Generative Framework for Graph-Structured Molecules Towards Efficient Drug Discovery.](http://arxiv.org/abs/2304.05498) | GraphGANFed是一个整合了GCN、GAN和联邦学习的框架，可在不共享数据的情况下高效训练生成对抗网络，助力基于图的分子的药物发现。 |
| [^42] | [KGS: Causal Discovery Using Knowledge-guided Greedy Equivalence Search.](http://arxiv.org/abs/2304.05493) | KGS是一种新颖的因果推断方法，通过利用先前的因果边缘信息作为约束条件，可以更准确地学习因果图。 |
| [^43] | [Audience Expansion for Multi-show Release Based on an Edge-prompted Heterogeneous Graph Network.](http://arxiv.org/abs/2304.05474) | 本文提出了一种基于边缘触发的异构图网络的两阶段受众扩展方案，可以考虑不同的双面交互和特征。 |
| [^44] | [Light Sampling Field and BRDF Representation for Physically-based Neural Rendering.](http://arxiv.org/abs/2304.05472) | 本文提出了一个基于神经网络的物理渲染器，使用光采样场和BRDF表示来模拟直接和间接光照，并实现复杂对象的渲染。 |
| [^45] | [Zero-shot Temporal Relation Extraction with ChatGPT.](http://arxiv.org/abs/2304.05454) | 本文研究了基于ChatGPT的零样本时间关系抽取，设计了三种提示技术来拆分任务并评估ChatGPT，实验表明ChatGPT的表现与监督方法存在很大差距，但它可以更正确地推断出更多的小关系类。 |
| [^46] | [Differentiable graph-structured models for inverse design of lattice materials.](http://arxiv.org/abs/2304.05422) | 本文提出了一种使用图形表示结构和属性的晶格材料的计算方法，使用可微分传递算法计算机械属性以实现反向设计，进而实现了可扩展的、具有前所未有的结构和功能多样性的晶格材料设计。 |
| [^47] | [Efficient Automation of Neural Network Design: A Survey on Differentiable Neural Architecture Search.](http://arxiv.org/abs/2304.05405) | 本文综述了最近在不同iable神经架构搜索中的研究进展，提出了一种新的基于挑战的分类法，对DARTS方法的贡献和影响进行了讨论，并探讨了未来的研究方向。 |
| [^48] | [Controllable Textual Inversion for Personalized Text-to-Image Generation.](http://arxiv.org/abs/2304.05265) | 本文提出了一种名为COTI的技术，通过引入理论指导的损失目标和全面的加权评分机制，并结合主动学习范式来解决文本反转时的困难，提供了一个强大，数据效率高，易于使用的框架。 |
| [^49] | [Regulatory Markets: The Future of AI Governance.](http://arxiv.org/abs/2304.04914) | 提出一种监管市场的概念，即政府要求受监管对象从私人监管机构购买监管服务，以克服过度依赖行业自律和立法机构缺乏专业知识的局限性，从而逐步实现人工智能的恰当监管。 |
| [^50] | [Toward Cohort Intelligence: A Universal Cohort Representation Learning Framework for Electronic Health Record Analysis.](http://arxiv.org/abs/2304.04468) | 提出了一种通用的COhort Representation lEarning（CORE）框架，用于增强EHR表示学习，支持针对不同队列的特征进行可解释性分析。 |
| [^51] | [NeRF applied to satellite imagery for surface reconstruction.](http://arxiv.org/abs/2304.04133) | 本文提出了Sat-NeRF模型，能够从少量的卫星图像集合中合成新的视角，并准确地估计场景表面的高程。 |
| [^52] | [Almost optimal manipulation of a pair of alternatives.](http://arxiv.org/abs/2304.03060) | 本文研究了一对替代品的排名，通过算法找到了一种几乎最优的操纵方式，以确定在给定情况下操纵的难易程度。 |
| [^53] | [Revisiting Dense Retrieval with Unanswerable Counterfactuals.](http://arxiv.org/abs/2304.03031) | 本文观察到基于DPR的最近的密集检索模型经常将无法回答的反事实情景排名高于可回答的原始情景，提出了一种新颖的用于段落检索的表示学习方法PiCL。 |
| [^54] | [Large Language Models as Master Key: Unlocking the Secrets of Materials Science with GPT.](http://arxiv.org/abs/2304.02213) | 本文介绍了一个新的自然语言处理任务——结构化信息推理（SIS），利用GPT-3模型能够准确提取材料科学设备层面的信息，并通过实验预测PCE和反向预测参数，展示了大型语言模型在材料学中的巨大潜力。 |
| [^55] | [Sociocultural knowledge is needed for selection of shots in hate speech detection tasks.](http://arxiv.org/abs/2304.01890) | HATELEXICON是一个包含巴西，德国，印度和肯尼亚仇恨言论的词汇表，利用其可以提高模型在训练中的性能表现。 |
| [^56] | [A Survey of Large Language Models.](http://arxiv.org/abs/2303.18223) | 本文综述了大型语言模型的研究历程以及最近的预训练语言模型(PLMs)，并强调模型扩展将带来性能改进和特殊能力的发掘。 |
| [^57] | [Model-agnostic explainable artificial intelligence for object detection in image data.](http://arxiv.org/abs/2303.17249) | 本文设计并实现了一种新的黑盒解释方法——BODEM，它采用了局部和远程掩蔽生成多个版本的输入图像，从而比目前用于解释对象检测的其他三种最先进的方法提供更详细和有用的解释。 |
| [^58] | [Unleasing ChatGPT on the Metaverse: Savior or Destroyer?.](http://arxiv.org/abs/2303.13856) | 本文探讨了在元宇宙中使用ChatGPT的利弊，它可以提供动态和个性化的体验，但也必须考虑隐私、偏见和道德等相关问题。 |
| [^59] | [Capabilities of GPT-4 on Medical Challenge Problems.](http://arxiv.org/abs/2303.13375) | 本论文对最先进的LLM——GPT-4在医学能力考试和基准数据集上进行了全面评估，结果显示其表现出色，有助于医学相关领域的研究和应用。 |
| [^60] | [Mind meets machine: Unravelling GPT-4's cognitive psychology.](http://arxiv.org/abs/2303.11436) | 本研究评估了在广泛使用的CommonsenseQA数据集中的一套常识推理问题上，GPT-4的表现及其对常识知识的处理和整合过程，在此过程中我们也发现了其局限性。 |
| [^61] | [Zero-Shot Contrastive Loss for Text-Guided Diffusion Image Style Transfer.](http://arxiv.org/abs/2303.08622) | 本文提出了一种适用于文本引导图像风格迁移中的零样本对比损失方法，可以在不需要额外训练的情况下生成具有相同语义内容的图像。 |
| [^62] | [Can Workers Meaningfully Consent to Workplace Wellbeing Technologies?.](http://arxiv.org/abs/2303.07242) | 工作场所感知技术的应用有助于提高生产力和福祉，但如何获取工人的有效同意是需要解决的难题，本文探讨了工人面临的挑战，并提出了可能的解决方案。 |
| [^63] | [Optimal foraging strategies can be learned and outperform L\'evy walks.](http://arxiv.org/abs/2303.06050) | 研究发现，通过强化学习代理，存活的生物可以学习到优于 L\'evy walks 的觅食策略，以提高觅食效率。 |
| [^64] | [CVT-SLR: Contrastive Visual-Textual Transformation for Sign Language Recognition with Variational Alignment.](http://arxiv.org/abs/2303.05725) | CVT-SLR是一种新的手语识别模型，它采用基于对比视觉-文本变换和变分对齐的方法来充分利用跨模态知识，为解决手语识别中缺乏大规模可用数据集的问题提供了一种新的解决方案。 |
| [^65] | [Identification of Systematic Errors of Image Classifiers on Rare Subgroups.](http://arxiv.org/abs/2303.05072) | 该论文提出了一种名为PromptAttack的组合测试方法，通过在被低频率覆盖的子群体中搜索找到目标模型在这些条件下表现不佳的子群体，以此识别出分类器可能存在的系统误差问题。 |
| [^66] | [Evolutionary Reinforcement Learning: A Survey.](http://arxiv.org/abs/2303.04150) | 这篇文章系统地总结了最新的进化计算方法在解决强化学习中的关键挑战方面所取得的良好性能。 |
| [^67] | [Combat AI With AI: Counteract Machine-Generated Fake Restaurant Reviews on Social Media.](http://arxiv.org/abs/2302.07731) | 本文针对机器生成的虚假评论提出了一种用高质量餐厅评论生成虚假评论并微调GPT输出检测器的方法，该方法预测虚假评论的性能优于现有解决方案。同时，我们还探索了预测非精英评论的模型，并在几个维度上对这些评论进行分析，此类机器生成的虚假评论是社交媒体平台面临的持续挑战。 |
| [^68] | [Multispectral Contrastive Learning with Viewmaker Networks.](http://arxiv.org/abs/2302.05757) | 本文研究将对比学习方法应用于各种遥感数据集。通过使用Viewmaker网络，本文发现该方法可以在不耗费大量时间和领域知识的情况下成功产生视图，并在四个多光谱成像问题上实现优于基于裁剪和反射的对比学习方法的表现。 |
| [^69] | [Dividing Good and Better Items Among Agents with Submodular Valuations.](http://arxiv.org/abs/2302.03087) | 本文研究了在具有二元子模价值的代理人之间公平分配不可分割物品的问题，并提出了一个解决方案概念的算法框架，其中包括leximin、max Nash welfare（MNW）和$p$-mean welfare最大化分配。在$ab$可整除的情况下，该算法框架可以用于求解多种解决方案概念，补充了现有结果的限制。同时，该文研究了leximin和MNW分配在无嫉妒和最大最小份额保证方面的表现。 |
| [^70] | [LDMIC: Learning-based Distributed Multi-view Image Coding.](http://arxiv.org/abs/2301.09799) | LDMIC是一种基于学习的分布式多视图图像编码框架，通过独立编码器和联合上下文传输模块实现了全局视图间的相关性捕捉，对几何关系不敏感。 |
| [^71] | [Extreme Image Transformations Affect Humans and Machines Differently.](http://arxiv.org/abs/2212.13967) | 本文研究了一些极端的图像变换，发现机器和人类在这些变换下的表现差异较大，机器在某些变换下比人类表现更好，但在人类容易处理的变换下表现不如人类，同时提出了一些方法来改善机器的性能。 |
| [^72] | [Momentum Contrastive Pre-training for Question Answering.](http://arxiv.org/abs/2212.05762) | 提出了一种用于抽取式问题回答的动量对比预训练方法，通过匹配填空式和自然查询-文章样本对的答案概率，能更好地将在填空式样本中学到的知识转移到回答自然问题上。 |
| [^73] | [Towards human-compatible autonomous car: A study of non-verbal Turing test in automated driving with affective transition modelling.](http://arxiv.org/abs/2212.02908) | 本文研究了自动驾驶汽车的人性化问题，通过非语言图灵测试，发现当前AI驾驶员不能创造类似人类的驾乘体验，需要在情感过渡模型中进行改进。 |
| [^74] | [Query-Driven Knowledge Base Completion using Multimodal Path Fusion over Multimodal Knowledge Graph.](http://arxiv.org/abs/2212.01923) | 基于查询的多模态路径融合算法可以有效地对知识库进行补全，提高了性能，并且使用了基于查询的技术来提高系统的效率。 |
| [^75] | [Knowledge Graph Quality Evaluation under Incomplete Information.](http://arxiv.org/abs/2212.00994) | 该论文提出一种不暴露原始数据的知识图谱质量评估框架，通过将质量评估任务转化为两个KG之间的对抗性问答游戏，解决现有方法高度依赖原始数据和更多考虑数据质量而非能力层面的缺陷。 |
| [^76] | [Enhancing Constraint Programming via Supervised Learning for Job Shop Scheduling.](http://arxiv.org/abs/2211.14492) | 该论文提出了一种基于监督学习的变量排序策略，可根据不同问题实例的特征定制变量排序策略以提高约束编程的求解性能。实验表明，该方法具有高效性和高准确性。 |
| [^77] | [Knowledge Base Completion using Web-Based Question Answering and Multimodal Fusion.](http://arxiv.org/abs/2211.07098) | 本文提出了一种使用基于网络问答和多模态融合的方法填补知识库中的缺失信息。通过设计一个多模态特征和问题模板的基于网络问答的系统来达到更高效的知识库补全，同时结合了知识库中的结构化信息来提高抽取质量。 |
| [^78] | [An Interpretable Machine Learning System to Identify EEG Patterns on the Ictal-Interictal-Injury Continuum.](http://arxiv.org/abs/2211.05207) | 该论文设计了一种可解释的深度学习模型，以预测ICU脑电监测中常见的6种脑波图案的存在，并提供高质量的解释和三种解释方法，这对于建立AI的信任和临床采用至关重要。 |
| [^79] | [Perfectly Secure Steganography Using Minimum Entropy Coupling.](http://arxiv.org/abs/2210.14889) | 本文研究了完全安全的隐写术，并发现只有最小熵耦合过程才是最高效的，提出了高可伸缩性的完美安全隐写算法，具有实际应用价值。 |
| [^80] | [LittleBird: Efficient Faster & Longer Transformer for Question Answering.](http://arxiv.org/abs/2210.11870) | LittleBird是一个基于BigBird的问答模型，通过使用更灵活和高效的位置表示方法ALiBi和替换全局信息表示方法来提高速度和内存占用。它可以在短输入的预训练语言模型的基础上，对长输入进行工作并且在低资源的语言中表现良好。 |
| [^81] | [Global Explainability of GNNs via Logic Combination of Learned Concepts.](http://arxiv.org/abs/2210.07147) | 本文提出了全局逻辑GNN解释器GLGExplainer，它是第一个能够以任意布尔组合的形式生成GNN学习的图形概念的解释器。GLGExplainer提供了准确可解释的全局解释，与GNN的组合性质相一致，并可应用于任何图分类或回归问题。 |
| [^82] | [Temporal Attention Unit: Towards Efficient Spatiotemporal Predictive Learning.](http://arxiv.org/abs/2206.12126) | 本研究提出了时间注意力单元（TAU）以提高时空预测学习的计算效率，将时间注意力分解为帧内静态注意力和帧间动态注意力。同时引入差分离散正则化方法来考虑帧间变化，大量实验表明该方法能够高效地进行预测学习。 |
| [^83] | [Unfooling Perturbation-Based Post Hoc Explainers.](http://arxiv.org/abs/2205.14772) | 本文介绍了一种检测和防御扰动基础解释器的恶意攻击的方法，并在图像分类任务上进行了实验验证。该方法提供了对人工智能系统的可靠性和信任性的保障。 |
| [^84] | [CNNs Avoid Curse of Dimensionality by Learning on Patches.](http://arxiv.org/abs/2205.10760) | 本研究解释了卷积神经网络在图像分类上的泛化性能，认为CNN在学习图像块后避免了维数灾难，并提供了支持的定量和定性证据。 |
| [^85] | [Interpreting Neural Min-Sum Decoders.](http://arxiv.org/abs/2205.10684) | 本文研究了在解码线性分组码中引入可学习参数到BP解码器中的方法，发现这些参数受到代码短周期分布的影响，学习权重的解码器比那些经过解析优化的权重具有更高的可靠性，并在复杂信道上有显著的帮助。 |
| [^86] | [AutoMLBench: A Comprehensive Experimental Evaluation of Automated Machine Learning Frameworks.](http://arxiv.org/abs/2204.08358) | 本文对六种AutoML框架在100个数据集上进行了全面的实验比较，发现不同框架在不同性能指标方面各有优势和劣势，框架的选择应根据特定任务要求来进行。 |
| [^87] | [The Importance of Credo in Multiagent Learning.](http://arxiv.org/abs/2204.07471) | 本论文提出了一个针对多智能体学习的信条模型，可以促使智能体为它所属的团队打造优化行为的方式。研究表明，即使队友或整个系统的利益不一定完全一致，也能实现全局有益的结果。 |
| [^88] | [Analytic theory for the dynamics of wide quantum neural networks.](http://arxiv.org/abs/2203.16711) | 本研究分析了训练误差的梯度下降动态，提出了一个简单的分析公式，可以捕捉到宽量子神经网络损失函数的平均行为。我们预测并表征了随机量子电路残余训练误差作为系统参数的指数衰减。 |
| [^89] | [Strategy Synthesis for Zero-Sum Neuro-Symbolic Concurrent Stochastic Games.](http://arxiv.org/abs/2202.06255) | 本文提出了神经符号并发随机博弈（NS-CSG）的建模形式，并针对具有 Borel 状态空间的 NS-CSG 类展示了零和折扣累积回报的价值函数的存在性和可测性。首次提出了可实施的值迭代（VI）和策略迭代（PI）算法，证明了算法的正确性，并验证了在基准 NS-CSG 中的有效性。 |
| [^90] | [Data Augmentation through Expert-guided Symmetry Detection to Improve Performance in Offline Reinforcement Learning.](http://arxiv.org/abs/2112.09943) | 本文研究了一种通过专家引导的对称检测算法进行数据增强的方法来提高离线强化学习的性能，针对非确定性MDP提出了一种结合监督和无监督学习的检测算法，实验证明该方法在一组基准任务上明显提高了强化学习算法的性能。 |
| [^91] | [Review-Based Domain Disentanglement without Duplicate Users or Contexts for Cross-Domain Recommendation.](http://arxiv.org/abs/2110.12648) | 本文提出了一种使用评论文本来进行领域解缠的方法，使用三个文本分析模块，由单一领域判别器指引，并采用一种新的优化策略，提高了领域解缠的质量，并且扩展了编码网络从单个领域到多个领域。实验证明，该方法比现有方法更高效、稳健和可扩展。 |
| [^92] | [Temporal Abstraction in Reinforcement Learning with the Successor Representation.](http://arxiv.org/abs/2110.05740) | 本研究表明，基于状态访问模式对状态进行编码的继承表示（SR）可以被看作发现和使用时间抽象的自然基质，并且可以用于发现有助于进行暂时扩展探索或规划的选项。 |

# 详细

[^1]: 持续扩散：使用C-LoRA进行文本到图像扩散的持续定制

    Continual Diffusion: Continual Customization of Text-to-Image Diffusion with C-LoRA. (arXiv:2304.06027v1 [cs.CV])

    [http://arxiv.org/abs/2304.06027](http://arxiv.org/abs/2304.06027)

    本文提出了一种新方法C-LoRA，用于持续自定制文本到图像扩散模型，并避免了新概念加入后过去相似概念的图像质量下降的问题。

    

    最近的研究表明，在只提供少量示例图像的情况下，自定义文本到图像扩散模型具有显着的能力。我们的研究表明，当使用多个细粒度概念以连续方式（即持续性地）自定义这样的模型时，最近的文本到图像定制技术会遭受灾难性的遗忘。为了解决这个问题，我们提出了一种新方法，C-LoRA，采用流行的稳定扩散模型中的跨注意力层中的连续自我正则化低秩适应。此外，我们使用不包括自定义对象的单词（即“人”用于人脸数据集）并初始化为完全随机嵌入的定制提示。重要的是，我们的方法只引入了微小的额外参数成本。

    Recent works demonstrate a remarkable ability to customize text-to-image diffusion models while only providing a few example images. What happens if you try to customize such models using multiple, fine-grained concepts in a sequential (i.e., continual) manner? In our work, we show that recent state-of-the-art customization of text-to-image models suffer from catastrophic forgetting when new concepts arrive sequentially. Specifically, when adding a new concept, the ability to generate high quality images of past, similar concepts degrade. To circumvent this forgetting, we propose a new method, C-LoRA, composed of a continually self-regularized low-rank adaptation in cross attention layers of the popular Stable Diffusion model. Furthermore, we use customization prompts which do not include the word of the customized object (i.e., "person" for a human face dataset) and are initialized as completely random embeddings. Importantly, our method induces only marginal additional parameter cost
    
[^2]: 基于逻辑锁定的神经特洛伊攻击机器学习加速器

    Exploiting Logic Locking for a Neural Trojan Attack on Machine Learning Accelerators. (arXiv:2304.06017v1 [cs.CR])

    [http://arxiv.org/abs/2304.06017](http://arxiv.org/abs/2304.06017)

    本文研究了如何利用逻辑锁定来破坏神经加速器的安全性，并展示了如何利用特洛伊秘钥来产生神经特洛伊式的后门。在基准数据集上进行的实验表明，我们的方法可以生成诱导大量错误分类率的特洛伊秘钥，同时保持高的特洛伊激活概率。

    

    逻辑锁定被提出来保护芯片制造过程中的知识产权。逻辑锁定技术通过使设计中的一部分组合模块依赖于保密的秘钥来保护硬件IP。如果使用了不正确的秘钥，锁定模块会产生一组确定性错误，限制未经授权的使用。神经加速器是逻辑锁定的常见目标，特别是随着机器学习服务的普及。在这篇论文中，我们探讨了如何利用逻辑锁定来破坏它所保护的神经加速器的安全性。具体而言，我们展示了如何利用使用不正确秘钥所引起的确定性错误来产生神经特洛伊式的后门。为此，我们首先概述了一个动机攻击场景，其中精心选择的不正确秘钥，我们称之为特洛伊秘钥，在锁定的加速器中为攻击者指定的输入类别产生了错误分类。然后，我们开发了一种系统方法来为受逻辑锁定保护的神经加速器设计特洛伊秘钥。通过对基准数据集进行大量实验，我们证明了我们的方法可以生成诱导大量错误分类率的特洛伊秘钥，同时保持高的特洛伊激活概率。

    Logic locking has been proposed to safeguard intellectual property (IP) during chip fabrication. Logic locking techniques protect hardware IP by making a subset of combinational modules in a design dependent on a secret key that is withheld from untrusted parties. If an incorrect secret key is used, a set of deterministic errors is produced in locked modules, restricting unauthorized use. A common target for logic locking is neural accelerators, especially as machine-learning-as-a-service becomes more prevalent. In this work, we explore how logic locking can be used to compromise the security of a neural accelerator it protects. Specifically, we show how the deterministic errors caused by incorrect keys can be harnessed to produce neural-trojan-style backdoors. To do so, we first outline a motivational attack scenario where a carefully chosen incorrect key, which we call a trojan key, produces misclassifications for an attacker-specified input class in a locked accelerator. We then dev
    
[^3]: 通过无监督学习图嵌入进行物体无关能力分类

    Object-agnostic Affordance Categorization via Unsupervised Learning of Graph Embeddings. (arXiv:2304.05989v1 [cs.AI])

    [http://arxiv.org/abs/2304.05989](http://arxiv.org/abs/2304.05989)

    本文通过无监督学习相似物体交互，诱导物体能力簇，使用新颖的深度感知定性空间表示法构建活动图并进行聚类，从而实现具有不确定交互开放集合的类别无关物体的能力分类。

    

    获取关于物体交互和能力的知识可以促进场景理解和人机协作任务。在日常生活场景中，人们倾向于根据场景和物体的可用性以多种不同的方式使用物体。针对存在开放互动和物体的类别不确定的情况下，学习物体的能力是一项具有挑战性的任务。本文提出了一种方法来实现具有不确定交互开放集合的类别无关物体的能力分类，通过无监督学习物体交互之间的相似之处从而诱导物体能力簇。采用了一种新颖的深度感知定性空间表示法来构建活动图（AGs），这些图从RGB-D视频中抽象出时空交互的连续表示。然后对这些AGs进行聚类，以获取具有类似能力的一组物体。我们在实际场景中的实验表明，

    Acquiring knowledge about object interactions and affordances can facilitate scene understanding and human-robot collaboration tasks. As humans tend to use objects in many different ways depending on the scene and the objects' availability, learning object affordances in everyday-life scenarios is a challenging task, particularly in the presence of an open set of interactions and objects. We address the problem of affordance categorization for class-agnostic objects with an open set of interactions; we achieve this by learning similarities between object interactions in an unsupervised way and thus inducing clusters of object affordances. A novel depth-informed qualitative spatial representation is proposed for the construction of Activity Graphs (AGs), which abstract from the continuous representation of spatio-temporal interactions in RGB-D videos. These AGs are clustered to obtain groups of objects with similar affordances. Our experiments in a real-world scenario demonstrate that o
    
[^4]: KubeEdge-Sedna v0.3：面向下一代自动定制化AI工程方案

    KubeEdge-Sedna v0.3: Towards Next-Generation Automatically Customized AI Engineering Scheme. (arXiv:2304.05985v1 [cs.DC])

    [http://arxiv.org/abs/2304.05985](http://arxiv.org/abs/2304.05985)

    KubeEdge-Sedna v0.3提出了边缘-云协作终身学习的问题，并发布了行业首个开源方案，解决了边缘数据异构性和边缘人工智能服务离线自主性的挑战，从而实现了AI工程和自动化。

    

    全球边缘人工智能市场的规模继续增长。目前阻碍边缘人工智能大规模复制的主要技术挑战是边缘数据的小样本和异构性。此外，边缘人工智能客户经常对数据安全合规性和边缘人工智能服务的离线自主性提出要求。基于学术界中的终身学习方法，我们首次正式定义了边缘-云协作终身学习的问题，并发布了业界首个开源的边缘-云协作终身学习。边缘-云协作终身学习通过（1）多任务迁移学习来适应不同边缘位置的数据异构性，以实现“千人千面”的准确预测；（2）未知任务的增量处理使系统学习更多，样本越小，系统变得越聪明，逐渐实现AI工程和自动化；（3）利用云端知识来提高边缘系统的准确性和性能。

    The scale of the global edge AI market continues to grow. The current technical challenges that hinder the large-scale replication of edge AI are mainly small samples on the edge and heterogeneity of edge data. In addition, edge AI customers often have requirements for data security compliance and offline autonomy of edge AI services. Based on the lifelong learning method in the academic world, we formally define the problem of edge-cloud collaborative lifelong learning for the first time, and release the industry's first open-source edge-cloud collaborative lifelong learning. Edge-cloud collaborative lifelong learning adapts to data heterogeneity at different edge locations through (1) multi-task transfer learning to achieve accurate prediction of "thousands of people and thousands of faces"; (2) incremental processing of unknown tasks, the more systems learn and the smarter systems are with small samples, gradually realize AI engineering and automation; (3) Use the cloud-side knowled
    
[^5]: 神经注意森林：基于Transformer的森林改进

    Neural Attention Forests: Transformer-Based Forest Improvement. (arXiv:2304.05980v1 [cs.LG])

    [http://arxiv.org/abs/2304.05980](http://arxiv.org/abs/2304.05980)

    本论文提出一种名为神经注意森林的新方法，将注意力机制引入到随机森林中，通过神经网络计算获得注意权重，进而解决回归和分类任务。

    

    该论文提出了一种名为神经注意森林（NAF）的新方法，用于解决基于表格形式的训练数据的回归和分类任务。该模型的主要思想是将注意力机制引入到随机森林中，在 Nadaraya-Watson 核回归框架下，通过将特定形式的神经网络计算得到的注意权重分配到决策树中的叶子数据和随机森林本身中。与现有的基于注意力随机森林的模型不同，注意权重和 Nadaraya-Watson 回归采用神经网络的形式表示，其权重可以视为可训练参数。共享权重的神经网络的第一部分用于所有决策树的训练，并计算叶子数据的注意力权重。第二部分聚合树网络的输出，并旨在最小化随机森林预测与训练集目标真值之间的差异。

    A new approach called NAF (the Neural Attention Forest) for solving regression and classification tasks under tabular training data is proposed. The main idea behind the proposed NAF model is to introduce the attention mechanism into the random forest by assigning attention weights calculated by neural networks of a specific form to data in leaves of decision trees and to the random forest itself in the framework of the Nadaraya-Watson kernel regression. In contrast to the available models like the attention-based random forest, the attention weights and the Nadaraya-Watson regression are represented in the form of neural networks whose weights can be regarded as trainable parameters. The first part of neural networks with shared weights is trained for all trees and computes attention weights of data in leaves. The second part aggregates outputs of the tree networks and aims to minimize the difference between the random forest prediction and the truth target value from a training set. 
    
[^6]: 双高斯DAG-probit模型中的贝叶斯因果推断

    Bayesian Causal Inference in Doubly Gaussian DAG-probit Models. (arXiv:2304.05976v1 [stat.ME])

    [http://arxiv.org/abs/2304.05976](http://arxiv.org/abs/2304.05976)

    本文讨论在观测数据下，通过构造两个有向无环图，并共享公共参数来对两组的二元响应变量和协变量进行建模。双高斯DAG-probit模型是在此基础上提出的，在模型中我们可以估计每个节点的效应大小。

    

    我们考虑在观察数据下，对两个组的二元响应变量以及一组协变量进行建模。分组变量可以是混淆变量（治疗和结果的共同原因），性别，病例/对照组，种族等。给定协变量和一个二元潜变量，目标是构造两个有向无环图(DAGs),同时共享一些公共参数。表示变量的节点集对于两组是相同的，但表示变量之间因果关系的有向边可以有潜在的区别。对于每个组，我们还估计了每个节点的效应大小。我们假设每个组在其DAG下符合高斯分布。由于DAG的马尔科夫性质，给定父节点后，DAG的联合分布是条件独立的。我们在两个组下引入了高斯DAG-probit模型的概念，因此是双高斯DAG-probit模型。

    We consider modeling a binary response variable together with a set of covariates for two groups under observational data. The grouping variable can be the confounding variable (the common cause of treatment and outcome), gender, case/control, ethnicity, etc. Given the covariates and a binary latent variable, the goal is to construct two directed acyclic graphs (DAGs), while sharing some common parameters. The set of nodes, which represent the variables, are the same for both groups but the directed edges between nodes, which represent the causal relationships between the variables, can be potentially different. For each group, we also estimate the effect size for each node. We assume that each group follows a Gaussian distribution under its DAG. Given the parent nodes, the joint distribution of DAG is conditionally independent due to the Markov property of DAGs. We introduce the concept of Gaussian DAG-probit model under two groups and hence doubly Gaussian DAG-probit model. To estima
    
[^7]: 无人机在任意三维环境中采用人机交互增强避障方法

    UAV Obstacle Avoidance by Human-in-the-Loop Reinforcement in Arbitrary 3D Environment. (arXiv:2304.05959v1 [cs.RO])

    [http://arxiv.org/abs/2304.05959](http://arxiv.org/abs/2304.05959)

    本文提出了一种基于深度强化学习和人机交互的避障方法，可在大规模三维复杂环境中控制无人机实现任意目标点的导航任务。

    

    本文探讨了基于深度强化学习的无人机控制方法，旨在在大规模三维复杂环境中使 UAV 达到任意目标点，且在导航过程中飞行高度和速度均可变。我们提出了一种结合人机交互的 DRL 方法，可以使 UAV 在飞行过程中自动避开障碍物。同时，我们设计了多个基于相关领域知识的奖励函数，以指导 UAV 导航。人机交互的作用是在不同情况下动态改变 UAV 的奖励函数，以更好地适应避障。我们在城市、农村和森林场景中验证了成功率和平均步长，实验结果表明该方法可减少训练收敛时间，提高导航任务的效率和准确性。

    This paper focuses on the continuous control of the unmanned aerial vehicle (UAV) based on a deep reinforcement learning method for a large-scale 3D complex environment. The purpose is to make the UAV reach any target point from a certain starting point, and the flying height and speed are variable during navigation. In this work, we propose a deep reinforcement learning (DRL)-based method combined with human-in-the-loop, which allows the UAV to avoid obstacles automatically during flying. We design multiple reward functions based on the relevant domain knowledge to guide UAV navigation. The role of human-in-the-loop is to dynamically change the reward function of the UAV in different situations to suit the obstacle avoidance of the UAV better. We verify the success rate and average step size on urban, rural, and forest scenarios, and the experimental results show that the proposed method can reduce the training convergence time and improve the efficiency and accuracy of navigation tas
    
[^8]: CMOS + 随机纳米磁体：概率推理与学习异构计算机

    CMOS + stochastic nanomagnets: heterogeneous computers for probabilistic inference and learning. (arXiv:2304.05949v1 [cond-mat.mes-hall])

    [http://arxiv.org/abs/2304.05949](http://arxiv.org/abs/2304.05949)

    本文展示了如何将基于随机磁隧道结（sMTJ）的概率比特（p位）与多功能可编程门阵列（FPGA）相结合，设计出一种能源高效的异构CMOS + X（X = sMTJ）原型，其成功地执行了概率推理和异步Boltzmann学习。

    

    随着摩尔定律的放缓，利用新兴的纳米技术（X）增强互补金属氧化物半导体（CMOS）晶体管变得越来越重要。本文展示了如何将基于随机磁隧道结（sMTJ）的概率比特（p位）与多功能可编程门阵列（FPGA）相结合，设计出一种能源高效的异构CMOS + X（X = sMTJ）原型。尽管sMTJs设备间存在差异，我们的异构计算机成功地执行了概率推理和异步Boltzmann学习。使用CMOS预测流程设计套件（PDK）进行全面比较，数字CMOS-based p-bits模拟高质量随机性需要超过10,000个晶体管，每生成一个随机数的能量比使用只消耗2fJ的sMTJ-based p-bits高约两个数量级。我们的方法的缩放和集成版本可以显着推进概率性的推理。

    With the slowing down of Moore's law, augmenting complementary-metal-oxide semiconductor (CMOS) transistors with emerging nanotechnologies (X) is becoming increasingly important. In this paper, we demonstrate how stochastic magnetic tunnel junction (sMTJ)-based probabilistic bits, or p-bits, can be combined with versatile Field Programmable Gate Arrays (FPGA) to design an energy-efficient, heterogeneous CMOS + X (X = sMTJ) prototype. Our heterogeneous computer successfully performs probabilistic inference and asynchronous Boltzmann learning despite device-to-device variations in sMTJs. A comprehensive comparison using a CMOS predictive process design kit (PDK) reveals that digital CMOS-based p-bits emulating high-quality randomness use over 10,000 transistors with the energy per generated random number being roughly two orders of magnitude greater than the sMTJ-based p-bits that dissipate only 2 fJ. Scaled and integrated versions of our approach can significantly advance probabilistic 
    
[^9]: 带有定位-尺度噪声的扩散模型

    Diffusion models with location-scale noise. (arXiv:2304.05907v1 [cs.LG])

    [http://arxiv.org/abs/2304.05907](http://arxiv.org/abs/2304.05907)

    本研究研究了用于生成模型的不同噪声分布，证明了高斯分布在扩散模型（DMs）中表现最佳。

    

    扩散模型(DMs)是一种强大的生成模型，它通过添加高斯噪声到数据中，并学会去除噪声。我们想确定哪种噪声分布（高斯或非高斯）在DMs中导致更好的生成数据。由于DMs的设计不适用于非高斯噪声，因此我们构建了一个框架，允许使用非高斯定位-尺度噪声来逆转扩散过程。我们使用该框架展示高斯分布在各种其它分布（拉普拉斯、均匀、t、广义高斯）中表现最佳。

    Diffusion Models (DMs) are powerful generative models that add Gaussian noise to the data and learn to remove it. We wanted to determine which noise distribution (Gaussian or non-Gaussian) led to better generated data in DMs. Since DMs do not work by design with non-Gaussian noise, we built a framework that allows reversing a diffusion process with non-Gaussian location-scale noise. We use that framework to show that the Gaussian distribution performs the best over a wide range of other distributions (Laplace, Uniform, t, Generalized-Gaussian).
    
[^10]: 多步逆运动学表示学习：富观测强化学习的高效优化方法

    Representation Learning with Multi-Step Inverse Kinematics: An Efficient and Optimal Approach to Rich-Observation RL. (arXiv:2304.05889v1 [cs.LG])

    [http://arxiv.org/abs/2304.05889](http://arxiv.org/abs/2304.05889)

    本文提出了一种名为MusIK的新算法，利用多步逆运动学实现表示学习和系统探索相结合，达到计算高效和样本复杂度最优的效果，成功应用于富观测强化学习任务中。

    

    本研究探讨了在块MDP问题下，针对富有高维度观测而设计的样本高效算法的问题。现有算法存在1）计算复杂度过高，2）具有不必要的强统计假设，或3）具有次优的样本复杂度。我们通过提供第一个在计算上高效的算法来解决这些问题，并在最小统计假设的前提下实现了与所需精度水平相对应的速率最优样本复杂度。我们的算法MusIK将系统探索与基于多步逆运动学的表示学习相结合，这是一种学习目标，即从当前观察和（可能遥远的）未来观察中预测学习者自己的行动。MusIK简单而灵活，可以高效地利用通用函数逼近。我们的分析利用了几种新技术，包括一种新的链条论证方法，用于限制时间和表示空间中的误差传播，以及一种新的探索充分条件，用于捕捉低维几何结构。我们在一系列具有挑战性的基准测试中展示了MusIK的优势，无论是在样本复杂度还是墙钟时间方面都优于先前的方法。

    We study the design of sample-efficient algorithms for reinforcement learning in the presence of rich, high-dimensional observations, formalized via the Block MDP problem. Existing algorithms suffer from either 1) computational intractability, 2) strong statistical assumptions that are not necessarily satisfied in practice, or 3) suboptimal sample complexity. We address these issues by providing the first computationally efficient algorithm that attains rate-optimal sample complexity with respect to the desired accuracy level, with minimal statistical assumptions. Our algorithm, MusIK, combines systematic exploration with representation learning based on multi-step inverse kinematics, a learning objective in which the aim is to predict the learner's own action from the current observation and observations in the (potentially distant) future. MusIK is simple and flexible, and can efficiently take advantage of general-purpose function approximation. Our analysis leverages several new tec
    
[^11]: 自适应门控图卷积网络用于基于EEG数据的阿尔茨海默病可解释诊断

    Adaptive Gated Graph Convolutional Network for Explainable Diagnosis of Alzheimer's Disease using EEG Data. (arXiv:2304.05874v1 [q-bio.NC])

    [http://arxiv.org/abs/2304.05874](http://arxiv.org/abs/2304.05874)

    本文提出了一种自适应门控图卷积网络(AGGCN)，该网络结合卷积节点特征增强和功能连接度量自适应学习图结构，实现了高精度的阿尔茨海默病诊断，并提供了重要的脑区信息。

    

    近来，图神经网络(GNN)模型越来越多地被用于分类脑电图(EEG)数据，然而，基于GNN的神经系统疾病，如阿尔茨海默病(AD)的诊断仍然是相对未开发的领域。因此，本文提出了一种新颖的自适应门控图卷积网络(AGGCN)，该网络可以提供可解释的预测结果。AGGCN通过将基于卷积的节点特征增强与基于功能连接性的著名相关度量相结合来自适应学习图结构。此外，门控图卷积可以动态地加权考虑各种空间尺度的贡献。实验结果表明，该模型在闭眼和睁眼状态下均能取得较高的精度，表明学习到的表征结果的稳定性。最后，我们证明了所提出的AGGCN模型可以提供有关AD最受影响的脑区的重要见解。

    Graph neural network (GNN) models are increasingly being used for the classification of electroencephalography (EEG) data. However, GNN-based diagnosis of neurological disorders, such as Alzheimer's disease (AD), remains a relatively unexplored area of research. Previous studies have relied on functional connectivity methods to infer brain graph structures and used simple GNN architectures for the diagnosis of AD. In this work, we propose a novel adaptive gated graph convolutional network (AGGCN) that can provide explainable predictions. AGGCN adaptively learns graph structures by combining convolution-based node feature enhancement with a well-known correlation-based measure of functional connectivity. Furthermore, the gated graph convolution can dynamically weigh the contribution of various spatial scales. The proposed model achieves high accuracy in both eyes-closed and eyes-open conditions, indicating the stability of learned representations. Finally, we demonstrate that the propos
    
[^12]: 在竞争性多智能体环境中学习沟通和协作以清理海洋废弃塑料

    Learning to Communicate and Collaborate in a Competitive Multi-Agent Setup to Clean the Ocean from Macroplastics. (arXiv:2304.05872v1 [cs.AI])

    [http://arxiv.org/abs/2304.05872](http://arxiv.org/abs/2304.05872)

    本文提出了一种基于图神经网络（GNN）的、用于多智能体交互式海洋废弃物清理的通信机制，使得不同代理之间可以协作竞争并实现收集废弃物的最大化。

    

    在许多实际应用中，协作与竞争之间的平衡对于人工智能代理至关重要。本文使用多智能体强化学习（MARL）建立在一个高影响问题上，通过对海洋废弃塑料的收集实现了协作与竞争的平衡。我们提出了一种基于图神经网络（GNN）的通信机制，它增加了代理的观察空间。在我们自定义的环境中，代理控制着收集塑料的船只。这种通信机制使代理能够使用二进制信号来开发通信协议。虽然代理的集体目标是尽可能地清理海洋废弃塑料，但代理会因个人收集到的废弃塑料数量而获得奖励。因此，代理必须学会有效地沟通并保持竞争关系。

    Finding a balance between collaboration and competition is crucial for artificial agents in many real-world applications. We investigate this using a Multi-Agent Reinforcement Learning (MARL) setup on the back of a high-impact problem. The accumulation and yearly growth of plastic in the ocean cause irreparable damage to many aspects of oceanic health and the marina system. To prevent further damage, we need to find ways to reduce macroplastics from known plastic patches in the ocean. Here we propose a Graph Neural Network (GNN) based communication mechanism that increases the agents' observation space. In our custom environment, agents control a plastic collecting vessel. The communication mechanism enables agents to develop a communication protocol using a binary signal. While the goal of the agent collective is to clean up as much as possible, agents are rewarded for the individual amount of macroplastics collected. Hence agents have to learn to communicate effectively while maintai
    
[^13]: LMR: 基于车道距离的轨迹预测度量

    LMR: Lane Distance-Based Metric for Trajectory Prediction. (arXiv:2304.05869v1 [cs.CV])

    [http://arxiv.org/abs/2304.05869](http://arxiv.org/abs/2304.05869)

    LMR是一种基于车道距离的度量，适用于轨迹预测中的结构化环境，相比传统的欧氏距离度量更准确。

    

    轨迹预测方法的开发需要度量来验证和比较它们的性能。目前已经确定的度量基于欧氏距离，这意味着在所有方向上都给出了相同的误差权重。欧几里得度量对于像道路这样的结构化环境是不足够的，因为它们没有妥善捕捉到与底层车道相关的操作员意图。为了针对下游规划任务合理评估轨迹预测方法，我们提出了一种新的度量，即基于车道距离的车道错过率（LMR）。对于LMR的计算，将地面实测和预测端点分配给车道线段，更确切地说是它们的中心线。通过沿车道线段的距离测量，预测与实测之间的距离在一定阈值范围内的预测被称为命中，否则称为错过。LMR则定义为产生错过的序列的比率。我们在三个不同的数据集上的结果表明，相对于传统的基于欧氏距离的度量，LMR是适用于类似车道这样的结构化环境的轨迹预测更为合适的度量。

    The development of approaches for trajectory prediction requires metrics to validate and compare their performance. Currently established metrics are based on Euclidean distance, which means that errors are weighted equally in all directions. Euclidean metrics are insufficient for structured environments like roads, since they do not properly capture the agent's intent relative to the underlying lane. In order to provide a reasonable assessment of trajectory prediction approaches with regard to the downstream planning task, we propose a new metric that is lane distance-based: Lane Miss Rate (LMR). For the calculation of LMR, the ground-truth and predicted endpoints are assigned to lane segments, more precisely their centerlines. Measured by the distance along the lane segments, predictions that are within a certain threshold distance to the ground-truth count as hits, otherwise they count as misses. LMR is then defined as the ratio of sequences that yield a miss. Our results on three s
    
[^14]: 学习同形异义词消歧表示以改进神经机器翻译

    Learning Homographic Disambiguation Representation for Neural Machine Translation. (arXiv:2304.05860v1 [cs.CL])

    [http://arxiv.org/abs/2304.05860](http://arxiv.org/abs/2304.05860)

    本文提出了一种利用同义词句子建立同形异义词词级消歧表示（HDR）以改进神经机器翻译的方法。

    

    同形异义词在神经机器翻译中一直是难点。本文提出一种在潜在空间中解决同形异义词问题的新方法。首先，我们利用“HDR-encoder”在自然语言推理任务中学习通用句子表示。然后，利用WordNet中的同义词句子建立同形异义词词级消歧表示（HDR），调整预训练的HDR-encoder。最后，我们将预训练的HDR-encoder与基于Transformer的NMT在不同方案中相结合来提高翻译准确性。四个翻译方向的实验表明了本方法在增强NMT系统处理同形异义词方面的有效性。

    Homographs, words with the same spelling but different meanings, remain challenging in Neural Machine Translation (NMT). While recent works leverage various word embedding approaches to differentiate word sense in NMT, they do not focus on the pivotal components in resolving ambiguities of homographs in NMT: the hidden states of an encoder. In this paper, we propose a novel approach to tackle homographic issues of NMT in the latent space. We first train an encoder (aka "HDR-encoder") to learn universal sentence representations in a natural language inference (NLI) task. We further fine-tune the encoder using homograph-based synset sentences from WordNet, enabling it to learn word-level homographic disambiguation representations (HDR). The pre-trained HDR-encoder is subsequently integrated with a transformer-based NMT in various schemes to improve translation accuracy. Experiments on four translation directions demonstrate the effectiveness of the proposed method in enhancing the perfor
    
[^15]: 重访轨迹集合，用于条件驾驶行为预测

    RESET: Revisiting Trajectory Sets for Conditional Behavior Prediction. (arXiv:2304.05856v1 [cs.CV])

    [http://arxiv.org/abs/2304.05856](http://arxiv.org/abs/2304.05856)

    这篇论文提出了一种新的用于条件驾驶行为预测的基于集合法的轨迹预测方法RESET，可以预测灵活数量的轨迹而不影响运行时间或值域。

    

    预测自动驾驶车辆的不同轨迹条件下交通参与者的行为是必要的。这可以使得下游的规划器更准确地评估其决策的影响。最近的条件行为预测方法依赖于回归解码器，这意味着坐标或多项式系数会被回归。本文重新考虑基于集合的轨迹预测，其中预定义轨迹集合中每种轨迹的概率由分类模型决定，并首次将其应用于条件驾驶行为预测任务。我们提出了RESET，它结合了一种新的度量驱动的轨迹集合生成算法和基于图形的编码器。对于无条件预测，RESET的表现与基于回归的方法相当。由于基于集合法的特性，它具有可预测灵活数量轨迹的优势，而不会影响运行时间或值域。

    It is desirable to predict the behavior of traffic participants conditioned on different planned trajectories of the autonomous vehicle. This allows the downstream planner to estimate the impact of its decisions. Recent approaches for conditional behavior prediction rely on a regression decoder, meaning that coordinates or polynomial coefficients are regressed. In this work we revisit set-based trajectory prediction, where the probability of each trajectory in a predefined trajectory set is determined by a classification model, and first-time employ it to the task of conditional behavior prediction. We propose RESET, which combines a new metric-driven algorithm for trajectory set generation with a graph-based encoder. For unconditional prediction, RESET achieves comparable performance to a regression-based approach. Due to the nature of set-based approaches, it has the advantageous property of being able to predict a flexible number of trajectories without influencing runtime or comple
    
[^16]: 使用黑盒强化学习的分类树的最佳可解释性 - 性能权衡

    Optimal Interpretability-Performance Trade-off of Classification Trees with Black-Box Reinforcement Learning. (arXiv:2304.05839v1 [cs.LG])

    [http://arxiv.org/abs/2304.05839](http://arxiv.org/abs/2304.05839)

    本文提出了一种用于探索决策树空间的强化学习框架来学习紧凑的决策树并最佳化可解释性与性能之间的平衡。

    

    AI模型的可解释性可以建立对这些模型的信任，从而允许进行用户安全检查。决策树（DT）特别提供了关于学习模型的全局视图，并清晰地概述了对于分类给定数据至关重要的特征的角色。然而，如果DT太大，则这种可解释性会受到阻碍。最近提出了一种强化学习（RL）框架来探索DT空间以学习紧凑的树。一个给定的监督分类任务被建模为一个马尔可夫决策问题（MDP），然后添加了收集关于特征信息的额外动作，相当于构建DT。通过适当地惩罚这些操作，RL代理学习最佳权衡DT的大小和性能。但是，要做到这一点，这个RL代理需要解决一个部分可观察的MDP。本文的主要贡献是证明，解决一个完全可观察的问题就足以学习一个优化可解释性 - 性能权衡的DT。

    Interpretability of AI models allows for user safety checks to build trust in these models. In particular, decision trees (DTs) provide a global view on the learned model and clearly outlines the role of the features that are critical to classify a given data. However, interpretability is hindered if the DT is too large. To learn compact trees, a Reinforcement Learning (RL) framework has been recently proposed to explore the space of DTs. A given supervised classification task is modeled as a Markov decision problem (MDP) and then augmented with additional actions that gather information about the features, equivalent to building a DT. By appropriately penalizing these actions, the RL agent learns to optimally trade-off size and performance of a DT. However, to do so, this RL agent has to solve a partially observable MDP. The main contribution of this paper is to prove that it is sufficient to solve a fully observable problem to learn a DT optimizing the interpretability-performance tr
    
[^17]: DartsReNet：在ReNet架构中探索新的RNN单元

    DartsReNet: Exploring new RNN cells in ReNet architectures. (arXiv:2304.05838v1 [cs.CV])

    [http://arxiv.org/abs/2304.05838](http://arxiv.org/abs/2304.05838)

    本文使用 DARTS 方法对标准 RNN 单元进行改进，提出了用于 ReNet 架构的新的 RNN 单元，有效提高了在 CIFAR-10 和 SVHN 数据集上的分类效果。

    

    我们使用一种神经架构搜索（NAS）方法 DARTS，为图像分类提出了一种新的递归神经网络（RNN）单元，该单元用于 ReNet 架构。我们对 ReNet 架构感兴趣，它是一种基于 RNN 的方法，作为卷积和池化步骤的替代方案。我们使用 DARTS 来发现新的单元设计以克服标准 RNN 单元针对一维序列数据而非图像分类这种二维数据的局限性。我们将结果与使用 GRU 和 LSTM 单元的 ReNet 进行比较。我们发现的新单元在 CIFAR-10 和 SVHN 上优于标准 RNN 单元，而对 SVHN 结果的改进表明其具有推广性，因为我们是从 CIFAR-10 推导出 RNN 单元设计的，而没有针对 SVHN 进行新的单元搜索。

    We present new Recurrent Neural Network (RNN) cells for image classification using a Neural Architecture Search (NAS) approach called DARTS. We are interested in the ReNet architecture, which is a RNN based approach presented as an alternative for convolutional and pooling steps. ReNet can be defined using any standard RNN cells, such as LSTM and GRU. One limitation is that standard RNN cells were designed for one dimensional sequential data and not for two dimensions like it is the case for image classification. We overcome this limitation by using DARTS to find new cell designs. We compare our results with ReNet that uses GRU and LSTM cells. Our found cells outperform the standard RNN cells on CIFAR-10 and SVHN. The improvements on SVHN indicate generalizability, as we derived the RNN cell designs from CIFAR-10 without performing a new cell search for SVHN.
    
[^18]: 一种联邦学习的博弈论框架

    A Game-theoretic Framework for Federated Learning. (arXiv:2304.05836v1 [cs.LG])

    [http://arxiv.org/abs/2304.05836](http://arxiv.org/abs/2304.05836)

    本文提出了一个名为联邦学习安全博弈（FLSG）的博弈论框架，该框架同时考虑到联邦学习的保护者和攻击者的收益，包括计算成本、FL模型效用和隐私泄漏风险，并提出了一个实用算法来近似oracle并保持隐私。研究表明该算法对于预防和检测现实世界中的联邦学习攻击具有有效性。

    

    在联邦学习中，良性参与者旨在协同优化全局模型。然而，在存在半诚实的对手时，\textit{隐私泄漏}的风险是不可忽视的。现有研究要么专注于设计保护机制，要么专注于发明攻击机制。虽然保护者与攻击者之间的斗争似乎永无止境，但我们关心一个关键问题：是否可能事先预防潜在的攻击？为了解决这个问题，我们提出了一个博弈论框架，同时考虑FL保护者和攻击者的相应收益，其中包括计算成本、FL模型效用和隐私泄漏风险。我们将此游戏称为联邦学习安全博弈（FLSG），在其中保护者和攻击者都不知道所有参与者的收益。为了处理这种情况固有的\textit{不完全信息}，我们建议将FLSG与一个\textit{oracle}相关联，该oracle具有所有参与者的收益知识。我们分析了在各种效用函数和攻击模型组合下FLSG的纳什均衡存在性和唯一性。此外，我们提出了一个实用算法来近似oracle并保持隐私。实验结果说明了我们的算法在预防和检测现实世界中的FL场景中的攻击方面的有效性。

    In federated learning, benign participants aim to optimize a global model collaboratively. However, the risk of \textit{privacy leakage} cannot be ignored in the presence of \textit{semi-honest} adversaries. Existing research has focused either on designing protection mechanisms or on inventing attacking mechanisms. While the battle between defenders and attackers seems never-ending, we are concerned with one critical question: is it possible to prevent potential attacks in advance? To address this, we propose the first game-theoretic framework that considers both FL defenders and attackers in terms of their respective payoffs, which include computational costs, FL model utilities, and privacy leakage risks. We name this game the Federated Learning Security Game (FLSG), in which neither defenders nor attackers are aware of all participants' payoffs.  To handle the \textit{incomplete information} inherent in this situation, we propose associating the FLSG with an \textit{oracle} that ha
    
[^19]: 少样本语义分割: 方法与挑战综述

    Few Shot Semantic Segmentation: a review of methodologies and open challenges. (arXiv:2304.05832v1 [cs.CV])

    [http://arxiv.org/abs/2304.05832](http://arxiv.org/abs/2304.05832)

    本文综述了少样本学习在语义分割中的应用，并提出了新的分类法，并讨论了当前的限制和展望。

    

    语义分割可为图像中的每个像素赋予分类标签，为自动驾驶和机器人等领域的突破提供了契机。深度神经网络在语义分割方面取得了高度准确性，但需要大量训练数据集。一些领域由于数据稀缺、隐私问题和需要熟练标注人员等原因，难以构建这样的数据集。少样本学习(FSL)已作为一种允许模型从少量样本中学习新任务的新研究流派而出现。本篇论文综述了少样本学习在语义分割中的应用并提出了新的分类法，同时描述了当前的限制和展望。

    Semantic segmentation assigns category labels to each pixel in an image, enabling breakthroughs in fields such as autonomous driving and robotics. Deep Neural Networks have achieved high accuracies in semantic segmentation but require large training datasets. Some domains have difficulties building such datasets due to rarity, privacy concerns, and the need for skilled annotators. Few-Shot Learning (FSL) has emerged as a new research stream that allows models to learn new tasks from a few samples. This contribution provides an overview of FSL in semantic segmentation (FSS), proposes a new taxonomy, and describes current limitations and outlooks.
    
[^20]: 用人工神经网络预测国内生产总值：长期记忆有多大的作用？

    GDP nowcasting with artificial neural networks: How much does long-term memory matter?. (arXiv:2304.05805v1 [econ.EM])

    [http://arxiv.org/abs/2304.05805](http://arxiv.org/abs/2304.05805)

    通过比较四种人工神经网络和动态因子模型对美国GDP季度增长的预测表现，研究发现在平衡经济增长期间，更长的输入序列能够实现更准确的预测，但是这种效果会在不到两年的时间内消失。在经济动荡时期，长期记忆的效果变得明显。

    

    在本研究中，我们将不同的统计模型应用于美国经济季度国内生产总值（GDP）增长预测。使用每月的FRED-MD数据库，我们比较了动态因子模型（DFM）和四个人工神经网络（ANNs）的预测表现：多层感知机（MLP）、一维卷积神经网络（1D CNN）、长短期记忆网络（LSTM）和门控循环单元（GRU）。实证分析呈现了两个不同评估周期的结果。第一个周期（2010年第1季度至2019年第4季度）具有平衡的经济增长，而第二个周期（2010年第1季度至2022年第3季度）还包括COVID-19衰退期间的时间。根据我们的结果，更长的输入序列在平衡经济增长期间能够实现更准确的预测。然而，在一个相对较低的阈值值（约六个季度或十八个月）以后，这种效应会消失。在经济动荡期（如COVID-19衰退期间），长期记忆的效果会变得较为明显。

    In our study, we apply different statistical models to nowcast quarterly GDP growth for the US economy. Using the monthly FRED-MD database, we compare the nowcasting performance of the dynamic factor model (DFM) and four artificial neural networks (ANNs): the multilayer perceptron (MLP), the one-dimensional convolutional neural network (1D CNN), the long short-term memory network (LSTM), and the gated recurrent unit (GRU). The empirical analysis presents the results from two distinctively different evaluation periods. The first (2010:Q1 -- 2019:Q4) is characterized by balanced economic growth, while the second (2010:Q1 -- 2022:Q3) also includes periods of the COVID-19 recession. According to our results, longer input sequences result in more accurate nowcasts in periods of balanced economic growth. However, this effect ceases above a relatively low threshold value of around six quarters (eighteen months). During periods of economic turbulence (e.g., during the COVID-19 recession), long
    
[^21]: Proximity Forest 2.0：一种新的有效且可扩展的基于相似性的时间序列分类器

    Proximity Forest 2.0: A new effective and scalable similarity-based classifier for time series. (arXiv:2304.05800v1 [cs.LG])

    [http://arxiv.org/abs/2304.05800](http://arxiv.org/abs/2304.05800)

    Proximity Forest 2.0是一种新的有效且可扩展的基于相似性的时间序列分类器，优于先前最先进的基于相似性的分类器以及最先进的基于内核、神经网络和混合方法在特定数据集上的表现。

    

    时间序列分类（TSC）由于可能与不同分类任务相关的特征类型的多样性而具有挑战性，包括趋势、方差、频率、幅度和各种模式。为了应对这一挑战，已经开发了几种替代方法类别，包括基于相似性、特征和间隔、形状、字典、内核、神经网络和混合方法。本文提出了一种新的基于相似性的分类器Proximity Forest版本2.0（PF 2.0），它在UCR基准测试中优于先前最先进的基于相似性的分类器，并在基准测试中优于最先进的基于内核、神经网络和混合方法的特定数据集，这些数据集最适合使用基于相似性的方法。PF 2.0 合并了时间序列相似性最近的三个进展……

    Time series classification (TSC) is a challenging task due to the diversity of types of feature that may be relevant for different classification tasks, including trends, variance, frequency, magnitude, and various patterns. To address this challenge, several alternative classes of approach have been developed, including similarity-based, features and intervals, shapelets, dictionary, kernel, neural network, and hybrid approaches. While kernel, neural network, and hybrid approaches perform well overall, some specialized approaches are better suited for specific tasks. In this paper, we propose a new similarity-based classifier, Proximity Forest version 2.0 (PF 2.0), which outperforms previous state-of-the-art similarity-based classifiers across the UCR benchmark and outperforms state-of-the-art kernel, neural network, and hybrid methods on specific datasets in the benchmark that are best addressed by similarity-base methods. PF 2.0 incorporates three recent advances in time series simi
    
[^22]: 使用多个RDF知识图谱丰富ChatGPT回复

    Using Multiple RDF Knowledge Graphs for Enriching ChatGPT Responses. (arXiv:2304.05774v1 [cs.DB])

    [http://arxiv.org/abs/2304.05774](http://arxiv.org/abs/2304.05774)

    本研究提出了一个名为GPToLODS的原型系统，可以使用数百个RDF知识图谱为ChatGPT提供更多信息和证据，丰富ChatGPT的回复。

    

    最近越来越流行使用人工智能ChatGPT聊天框，它可以提供跨多个领域的详细回复和明确答案。然而，在很多情况下，它返回听起来很合理但是不正确或不准确的回复，并且它不提供证据。因此，任何用户都必须进一步搜索以检查答案的准确性和/或查找有关响应实体的更多信息。同时，在任何实际领域都存在大量的RDF知识图谱（KG），提供高质量的结构化数据。为了实现ChatGPT和RDF KG的结合，我们提出了一个名为GPToLODS的研究原型，能够从数百个RDF KG中为任何ChatGPT响应添加更多信息。特别地，它识别并注释每个响应实体的统计数据和指向LODsyndesis KG（包含来自400多个RDF KG和超过412百万实体的集成数据）的超链接。

    There is a recent trend for using the novel Artificial Intelligence ChatGPT chatbox, which provides detailed responses and articulate answers across many domains of knowledge. However, in many cases it returns plausible-sounding but incorrect or inaccurate responses, whereas it does not provide evidence. Therefore, any user has to further search for checking the accuracy of the answer or/and for finding more information about the entities of the response. At the same time there is a high proliferation of RDF Knowledge Graphs (KGs) over any real domain, that offer high quality structured data. For enabling the combination of ChatGPT and RDF KGs, we present a research prototype, called GPToLODS, which is able to enrich any ChatGPT response with more information from hundreds of RDF KGs. In particular, it identifies and annotates each entity of the response with statistics and hyperlinks to LODsyndesis KG (which contains integrated data from 400 RDF KGs and over 412 million entities). In 
    
[^23]: 野外人脸防伪挑战赛2023：基准和结果

    Wild Face Anti-Spoofing Challenge 2023: Benchmark and Results. (arXiv:2304.05753v1 [cs.CV])

    [http://arxiv.org/abs/2304.05753](http://arxiv.org/abs/2304.05753)

    前人的人脸防伪（FAS）技术应用于实际场景仍然存在限制，因为当前公开的FAS数据集数量和多样性不足，引起过拟合和场景误判。通过引入野外人脸防伪（WFAS）数据集，该研究提高了数据规模和多样化程度，促进了FAS技术的发展。

    

    人脸防伪（FAS）是保护自动人脸识别系统完整性的重要机制。尽管有了重大进展，但将现有方法推广到实际应用仍然具有挑战性。这种限制可以归因于公开可用的FAS数据集的稀缺性和缺乏多样性，这经常导致训练期间过拟合或测试期间饱和。就数量而言，欺诈主体的数量是一个重要的决定因素。大多数数据集仅包括少于2,000个受试者。就多样性而言，大多数数据集由在受控环境中使用重复机械化过程收集的欺诈样本组成。这种数据收集方法导致同质化样本和场景多样性的匮乏。为了解决这些缺点，我们介绍了野外人脸防伪（WFAS）数据集，这是一个大规模的、多样化的FAS数据集，可在不受限制的情况下收集。

    Face anti-spoofing (FAS) is an essential mechanism for safeguarding the integrity of automated face recognition systems. Despite substantial advancements, the generalization of existing approaches to real-world applications remains challenging. This limitation can be attributed to the scarcity and lack of diversity in publicly available FAS datasets, which often leads to overfitting during training or saturation during testing. In terms of quantity, the number of spoof subjects is a critical determinant. Most datasets comprise fewer than 2,000 subjects. With regard to diversity, the majority of datasets consist of spoof samples collected in controlled environments using repetitive, mechanical processes. This data collection methodology results in homogenized samples and a dearth of scenario diversity. To address these shortcomings, we introduce the Wild Face Anti-Spoofing (WFAS) dataset, a large-scale, diverse FAS dataset collected in unconstrained settings. Our dataset encompasses 853
    
[^24]: 通过数据增强提高连续时间动态图网络长期预测性能

    Boosting long-term forecasting performance for continuous-time dynamic graph networks via data augmentation. (arXiv:2304.05749v1 [cs.LG])

    [http://arxiv.org/abs/2304.05749](http://arxiv.org/abs/2304.05749)

    本研究提出了一种插入式模块——不确定性掩蔽混合（UmmU），它能够在中间层嵌入中进行不确定性估计，进而增强嵌入的不确定性，使其具有更好的泛化性能，从而显著提高了连续时间动态图网络的长期预测性能。

    

    本研究侧重于对连续时间动态图网络（CTDGNs）进行长期预测（LTF），这对于现实世界建模非常重要。现有的CTDGN对于建模时间图数据非常有效，因为它们能够捕捉复杂的时间相关性，但由于对历史数据的实质要求，它们在LTF方面表现不佳，在大多数情况下也不切实际。为了解决这个问题，最直观的方法是数据增强。在本研究中，我们提出了一种插入式模块——不确定性掩蔽混合（UmmU），它能够进行不确定性估计，将不确定性引入CTDGN的中间层嵌入中，并进行掩蔽混合以进一步增强嵌入的不确定性，使其能够适用于更多情况，而且可以轻松地插入到任意CTDGN中，而不增加参数数量。我们在三个真实世界的动态图数据集上进行了全面的实验，并表明UmmU在LTF任务上明显优于现有方法。

    This study focuses on long-term forecasting (LTF) on continuous-time dynamic graph networks (CTDGNs), which is important for real-world modeling. Existing CTDGNs are effective for modeling temporal graph data due to their ability to capture complex temporal dependencies but perform poorly on LTF due to the substantial requirement for historical data, which is not practical in most cases. To relieve this problem, a most intuitive way is data augmentation. In this study, we propose \textbf{\underline{U}ncertainty \underline{M}asked \underline{M}ix\underline{U}p (UmmU)}: a plug-and-play module that conducts uncertainty estimation to introduce uncertainty into the embedding of intermediate layer of CTDGNs, and perform masked mixup to further enhance the uncertainty of the embedding to make it generalize to more situations. UmmU can be easily inserted into arbitrary CTDGNs without increasing the number of parameters. We conduct comprehensive experiments on three real-world dynamic graph dat
    
[^25]: 在深度神经网络中预防性修剪Clever Hans策略

    Preemptively Pruning Clever-Hans Strategies in Deep Neural Networks. (arXiv:2304.05727v1 [cs.LG])

    [http://arxiv.org/abs/2304.05727](http://arxiv.org/abs/2304.05727)

    本文提出了一种新方法，Explanation-Guided Exposure Minimization (EGEM)，该方法预防性地修剪了ML模型中未受到积极解释反馈的变化，从而大大减少了对隐藏Clever Hans策略的依赖，并实现了更高的性能。

    

    可解释的AI已成为验证机器学习模型的流行工具。解释模型的决策策略与用户的领域知识之间的不匹配（例如Clever Hans效应）也被认为是改进错误模型的起点。然而，当用户和解释达成一致时，要怎么做就不那么清楚了。本文通过展示用户接受解释并不保证ML模型的良好功能，特别是一些隐藏的Clever Hans效应可能仍然未被发现，证明了这一点。我们通过贡献一个新方法Explanation-Guided Exposure Minimization (EGEM)，该方法预防性地修剪了ML模型中未受到积极解释反馈的变化。自然画像数据的实验表明，我们的方法导致模型大大减少了对隐藏的Clever Hans策略的依赖，并因此实现了更高的性能。

    Explainable AI has become a popular tool for validating machine learning models. Mismatches between the explained model's decision strategy and the user's domain knowledge (e.g. Clever Hans effects) have also been recognized as a starting point for improving faulty models. However, it is less clear what to do when the user and the explanation agree. In this paper, we demonstrate that acceptance of explanations by the user is not a guarantee for a ML model to function well, in particular, some Clever Hans effects may remain undetected. Such hidden flaws of the model can nevertheless be mitigated, and we demonstrate this by contributing a new method, Explanation-Guided Exposure Minimization (EGEM), that premptively prunes variations in the ML model that have not been the subject of positive explanation feedback. Experiments on natural image data demonstrate that our approach leads to models that strongly reduce their reliance on hidden Clever Hans strategies, and consequently achieve hig
    
[^26]: 通过动态运动原理增强的一致性，实现人机技能转移

    Human-Robot Skill Transfer with Enhanced Compliance via Dynamic Movement Primitives. (arXiv:2304.05703v1 [cs.RO])

    [http://arxiv.org/abs/2304.05703](http://arxiv.org/abs/2304.05703)

    本文介绍了一种通过提取人的动态特征来自动调整DMP框架参数，以增强机器人轨迹规划性能的方法。

    

    找到一个高效的适应机器人轨迹的方式是提高机器人性能的优先任务，其中通过演示学习（LfD）方法将类似于人的技能传递给机器人是一种轨迹规划的方法。然而，人的动作通常针对人的机体优化而不是机器人，因为人类的生物力学与机器人动力学之间存在差异。动态运动原理（DMP）框架是LfD这一限制的可行解决方案，但需要调节公式中的二阶动态。我们的贡献在于引入一种系统方法，从人的演示中提取动态特征来自动调整DMP框架中的参数。除了与LfD一起使用之外，所提出的方法的另一个用途是，它可以立即与强化学习（RL）一起用于机器人训练。通过这种方式，提取的特征有助于提高机器人训练效果。

    Finding an efficient way to adapt robot trajectory is a priority to improve overall performance of robots. One approach for trajectory planning is through transferring human-like skills to robots by Learning from Demonstrations (LfD). The human demonstration is considered the target motion to mimic. However, human motion is typically optimal for human embodiment but not for robots because of the differences between human biomechanics and robot dynamics. The Dynamic Movement Primitives (DMP) framework is a viable solution for this limitation of LfD, but it requires tuning the second-order dynamics in the formulation. Our contribution is introducing a systematic method to extract the dynamic features from human demonstration to auto-tune the parameters in the DMP framework. In addition to its use with LfD, another utility of the proposed method is that it can readily be used in conjunction with Reinforcement Learning (RL) for robot training. In this way, the extracted features facilitate
    
[^27]: 使用深度学习在眼部图像中准确定位角膜反射

    Precise localization of corneal reflections in eye images using deep learning trained on synthetic data. (arXiv:2304.05673v1 [cs.CV])

    [http://arxiv.org/abs/2304.05673](http://arxiv.org/abs/2304.05673)

    该论文提出了一种使用深度学习在眼部图像中准确定位角膜反射的方法，无需对真实眼部图像进行注释，仅使用模拟数据进行训练，该方法表现出色且提供了一种可行的解决方案。

    

    我们提出了一种深度学习方法，用于准确地定位单个眼部图像中角膜反射的中心。与以往的方法不同，我们使用了一个纯粹使用模拟数据训练的卷积神经网络（CNN）。使用只有模拟数据的方法的好处是完全避开了需要对真实眼部图像进行监督训练的繁琐注释过程。为了系统地评估我们方法的准确性，我们首先对放置在不同背景中和嵌入不同噪声水平的图像进行了测试。其次，我们对从真实眼睛中拍摄的高质量视频测试了该方法。我们的方法在真实眼部图像上表现出色，在空间精度方面降低了35％，并在模拟图像方面以空间准确性与最先进的方法相当。我们得出结论，我们的方法提供了一种精确的角膜反射中心定位方法，并提供了一种解决方案。

    We present a deep learning method for accurately localizing the center of a single corneal reflection (CR) in an eye image. Unlike previous approaches, we use a convolutional neural network (CNN) that was trained solely using simulated data. Using only simulated data has the benefit of completely sidestepping the time-consuming process of manual annotation that is required for supervised training on real eye images. To systematically evaluate the accuracy of our method, we first tested it on images with simulated CRs placed on different backgrounds and embedded in varying levels of noise. Second, we tested the method on high-quality videos captured from real eyes. Our method outperformed state-of-the-art algorithmic methods on real eye images with a 35% reduction in terms of spatial precision, and performed on par with state-of-the-art on simulated images in terms of spatial accuracy.We conclude that our method provides a precise method for CR center localization and provides a solutio
    
[^28]: RIFormer：移除Token Mixer后保持视觉Backbone的有效性

    RIFormer: Keep Your Vision Backbone Effective While Removing Token Mixer. (arXiv:2304.05659v1 [cs.CV])

    [http://arxiv.org/abs/2304.05659](http://arxiv.org/abs/2304.05659)

    本文提出一种在去除视觉Transformer中的Token Mixer的同时，保持视觉Backbone有效性的方法，配备所提出的优化策略能够构建一个非常简单的视觉Backbone并获得令人鼓舞的性能，同时在推断期间享受高效性。

    

    本文研究了如何在去除基本构建块中的Token Mixer的同时保持视觉Backbone的有效性。Token Mixer作为视觉Transformer（ViTs）的自注意力，旨在执行不同空间Token之间的信息通信，但会导致相当大的计算成本和延迟。然而，直接删除它们将导致不完整的模型结构，因此会带来显著的准确度下降。为此，我们首先开发出Reparameterization Idea的RepIdentityFormer来研究无Token Mixer的模型架构。然后，我们探索了改进的学习范式来打破简单无Token Mixer的Backbone的局限性，并将经验实践总结为5条准则。配备所提出的优化策略，我们能够构建一个非常简单的视觉Backbone并获得令人鼓舞的性能，同时在推断期间享受高效性。广泛的实验和剖析分析也展示了其有效性。

    This paper studies how to keep a vision backbone effective while removing token mixers in its basic building blocks. Token mixers, as self-attention for vision transformers (ViTs), are intended to perform information communication between different spatial tokens but suffer from considerable computational cost and latency. However, directly removing them will lead to an incomplete model structure prior, and thus brings a significant accuracy drop. To this end, we first develop an RepIdentityFormer base on the re-parameterizing idea, to study the token mixer free model architecture. And we then explore the improved learning paradigm to break the limitation of simple token mixer free backbone, and summarize the empirical practice into 5 guidelines. Equipped with the proposed optimization strategy, we are able to build an extremely simple vision backbone with encouraging performance, while enjoying the high efficiency during inference. Extensive experiments and ablative analysis also demo
    
[^29]: 具有理论保障的多智能体策略互惠算法

    Multi-agent Policy Reciprocity with Theoretical Guarantee. (arXiv:2304.05632v1 [cs.AI])

    [http://arxiv.org/abs/2304.05632](http://arxiv.org/abs/2304.05632)

    本论文提出了一种新的多智能体策略互惠（PR）框架，能够通过定义邻接空间和设计即插即用模块在不匹配的状态下充分利用交叉智能体策略，提高了性能，同时具有理论保障，能在个体感知奖励的情况下稳定收敛于最优值函数。

    

    现代多智能体强化学习算法具有解决各种实际问题的潜力，但它们未能充分利用交叉智能体知识来降低样本复杂度和提高性能。为了解决这个问题，我们提出了一种新的多智能体策略互惠（PR）框架，每个智能体可以充分利用交叉智能体策略，即使在不匹配的状态下。我们定义了一种不匹配状态的邻接空间，并设计了一个用于价值迭代的即插即用模块，使智能体可以推断更精确的回报。为了提高PR的可扩展性，我们提出了连续控制任务的深层PR算法。另外，理论分析表明，在个体感知奖励的情况下，智能体可以渐进地达成共识并收敛于最优值函数，这分别意味着PR的稳定性和有效性。实验结果表明，PR在多个基准任务上取得了优异的性能。

    Modern multi-agent reinforcement learning (RL) algorithms hold great potential for solving a variety of real-world problems. However, they do not fully exploit cross-agent knowledge to reduce sample complexity and improve performance. Although transfer RL supports knowledge sharing, it is hyperparameter sensitive and complex. To solve this problem, we propose a novel multi-agent policy reciprocity (PR) framework, where each agent can fully exploit cross-agent policies even in mismatched states. We then define an adjacency space for mismatched states and design a plug-and-play module for value iteration, which enables agents to infer more precise returns. To improve the scalability of PR, deep PR is proposed for continuous control tasks. Moreover, theoretical analysis shows that agents can asymptotically reach consensus through individual perceived rewards and converge to an optimal value function, which implies the stability and effectiveness of PR, respectively. Experimental results o
    
[^30]: 多兴趣深度稳定学习用于跨领域序列推荐模型

    Deep Stable Multi-Interest Learning for Out-of-distribution Sequential Recommendation. (arXiv:2304.05615v1 [cs.IR])

    [http://arxiv.org/abs/2304.05615](http://arxiv.org/abs/2304.05615)

    提出了DESMIL，一个新的多兴趣网络，用于序列推荐模型中解决跨领域泛化问题，通过去相关提取的多个兴趣向量，消除虚假相关性，实验结果证明其优于现有的最先进方法。

    

    最近，多利益模型被用作提取用户多个表示向量的兴趣， 对于序列推荐表现良好。然而，目前存在的多兴趣推荐模型都没有考虑兴趣分布可能改变带来的跨领域泛化问题。考虑到用户多个兴趣通常高度相关，模型有机会学习到嘈杂兴趣和目标项之间的虚假相关性。数据分布发生变化，兴趣之间的相关性也会发生变化，虚假相关性会误导模型进行错误预测。为了解决上述跨领域泛化问题，我们提出了一个新的多利益网络，名为DESMIL，该网络试图在模型中去相关提取的利益，从而可以消除虚假的相关性。DESMIL应用一个注意力模块来提取多个利益，一个基于Transformer的编码器来对它们进行编码，一个去相关模块来去除相关性。在两个真实世界数据集上的实验证明了DESMIL在in-distribution和out-of-distribution方面都优于现有最先进的方法。

    Recently, multi-interest models, which extract interests of a user as multiple representation vectors, have shown promising performances for sequential recommendation. However, none of existing multi-interest recommendation models consider the Out-Of-Distribution (OOD) generalization problem, in which interest distribution may change. Considering multiple interests of a user are usually highly correlated, the model has chance to learn spurious correlations between noisy interests and target items. Once the data distribution changes, the correlations among interests may also change, and the spurious correlations will mislead the model to make wrong predictions. To tackle with above OOD generalization problem, we propose a novel multi-interest network, named DEep Stable Multi-Interest Learning (DESMIL), which attempts to de-correlate the extracted interests in the model, and thus spurious correlations can be eliminated. DESMIL applies an attentive module to extract multiple interests, an
    
[^31]: ChatGPT超越英语：朝着对多语言学习中的大型语言模型的全面评估

    ChatGPT Beyond English: Towards a Comprehensive Evaluation of Large Language Models in Multilingual Learning. (arXiv:2304.05613v1 [cs.CL])

    [http://arxiv.org/abs/2304.05613](http://arxiv.org/abs/2304.05613)

    这篇论文评估了ChatGPT在22种不同的语言中的表现，并创建了一个多语言基准数据集。结果表明ChatGPT在各种语言和任务上表现出显著的一致性和功效，这为多语言学习和LLMs的研究提供了强有力的支持。

    

    在过去的几年里，大型语言模型（LLMs）已经成为自然语言处理（NLP）中最重要的突破之一，从根本上改变了该领域的研究和发展。ChatGPT是最近开发的最令人兴奋的LLM系统之一，展示了对语言生成的出色技能，并受到了公众的高度关注。在发现ChatGPT在英语中的各种令人兴奋的应用程序中，该模型可以处理和生成多种语言的文本，因为它具有多语言训练数据。考虑到ChatGPT在不同问题和领域的英语中的广泛采用，一个自然的问题是ChatGPT是否也可以有效地应用于其他语言，还是需要开发更多的语言特定技术？这个问题的答案需要对ChatGPT在多个任务中进行全面评估，使用不同的语言和大型数据集（即超出了报道的轶事），这在当前的研究中仍然缺乏或有限。在本文中，我们通过评估ChatGPT的全面一组22种语言，从不同的家族中开发一个多语言基准测试数据集来回答这个问题。我们的结果表明，ChatGPT在各种语言和任务上表现出了显著的一致性和功效，这为问题提供了强有力的正面答案。我们预计我们的评估方法和基准测试数据集将促进未来的多语言学习和LLMs的研究。

    Over the last few years, large language models (LLMs) have emerged as the most important breakthroughs in natural language processing (NLP) that fundamentally transform research and developments in the field. ChatGPT represents one of the most exciting LLM systems developed recently to showcase impressive skills for language generation and highly attract public attention. Among various exciting applications discovered for ChatGPT in English, the model can process and generate texts for multiple languages due to its multilingual training data. Given the broad adoption of ChatGPT for English in different problems and areas, a natural question is whether ChatGPT can also be applied effectively for other languages or it is necessary to develop more language-specific technologies. The answer to this question requires a thorough evaluation of ChatGPT over multiple tasks with diverse languages and large datasets (i.e., beyond reported anecdotes), which is still missing or limited in current r
    
[^32]: FLAN-T5中语义特征验证的研究

    Semantic Feature Verification in FLAN-T5. (arXiv:2304.05591v1 [cs.CL])

    [http://arxiv.org/abs/2304.05591](http://arxiv.org/abs/2304.05591)

    本研究表明大规模语言模型可以极大地增强传统的语义特征规范验证方法，使之能够捕捉超过人类规范范畴的信息，对于我们理解人类和机器的概念表示具有重要意义。

    

    本研究评估了大规模语言模型在生成语义特征规范方面的潜力——这是评价认知科学中概念结构的关键工具。我们基于现有的人工生成数据集进行构建，结果表明，机器验证的规范捕捉了概念结构的某些方面，超越了仅考虑人类规范所能涵盖的范围，并且更好地解释了在远距离相关的项目之间的语义相似度人类判断。该结果表明LLM可以极大地增强传统的语义特征规范验证方法，这对于我们理解人类和机器的概念表示具有重要意义。

    This study evaluates the potential of a large language model for aiding in generation of semantic feature norms - a critical tool for evaluating conceptual structure in cognitive science. Building from an existing human-generated dataset, we show that machine-verified norms capture aspects of conceptual structure beyond what is expressed in human norms alone, and better explain human judgments of semantic similarity amongst items that are distally related. The results suggest that LLMs can greatly enhance traditional methods of semantic feature norm verification, with implications for our understanding of conceptual representation in humans and machines.
    
[^33]: 信息量是否重要？基于主动学习的教育对话行为分类

    Does Informativeness Matter? Active Learning for Educational Dialogue Act Classification. (arXiv:2304.05578v1 [cs.CL])

    [http://arxiv.org/abs/2304.05578](http://arxiv.org/abs/2304.05578)

    本文研究基于主动学习方法的教育对话行为分类，提出了一种新的方法来选择信息样本，并且能够优于随机抽样方法和其他AL方法。

    

    基于对话行为（DA），可以解释专家导师在辅导过程中做了什么以及学生知道什么。然而，现有的实证研究多采用随机抽样法来获得手动注释DA的句子样本，然后用于培训DA分类器。本文提出了一种基于主动学习（AL）方法，用于选择教育对话行为分类的信息样本。结果表明，他们的方法优于随机抽样方法和其他最新的AL方法。

    Dialogue Acts (DAs) can be used to explain what expert tutors do and what students know during the tutoring process. Most empirical studies adopt the random sampling method to obtain sentence samples for manual annotation of DAs, which are then used to train DA classifiers. However, these studies have paid little attention to sample informativeness, which can reflect the information quantity of the selected samples and inform the extent to which a classifier can learn patterns. Notably, the informativeness level may vary among the samples and the classifier might only need a small amount of low informative samples to learn the patterns. Random sampling may overlook sample informativeness, which consumes human labelling costs and contributes less to training the classifiers. As an alternative, researchers suggest employing statistical sampling methods of Active Learning (AL) to identify the informative samples for training the classifiers. However, the use of AL methods in educational D
    
[^34]: 通过双编码器改进扩散模型实现场景文字编辑

    Improving Diffusion Models for Scene Text Editing with Dual Encoders. (arXiv:2304.05568v1 [cs.CV])

    [http://arxiv.org/abs/2304.05568](http://arxiv.org/abs/2304.05568)

    DIFFSTE是一种用于改进场景文字编辑的方法，通过使用双编码器设计，包括字符编码器以提高文本清晰度和指令编码器以更好地控制样式，有效解决了现有模型在渲染正确文本和控制文本样式方面的困难

    

    场景文字编辑是一项具有挑战性的任务，它涉及在图像中修改或插入指定的文本，同时保持其自然和逼真的外观。大多数先前的方法依靠风格转移模型，将文本区域裁剪出来并将它们馈入图像转移模型（如GAN）。然而，这些方法在改变文本样式和插入文本到图像中能力方面存在局限性。最近扩散模型的进展展示了在文本条件下进行图像编辑的潜力。然而，我们的经验分析表明，最先进的扩散模型在渲染正确的文本和控制文本样式方面存在困难。为了解决这些问题，我们提出了使用双编码器设计来改善预先训练的扩散模型的 DIFFSTE，其中包括用于更好文本清晰度的字符编码器和用于更好样式控制的指令编码器。引入指令调整框架来训练我们的模型学习

    Scene text editing is a challenging task that involves modifying or inserting specified texts in an image while maintaining its natural and realistic appearance. Most previous approaches to this task rely on style-transfer models that crop out text regions and feed them into image transfer models, such as GANs. However, these methods are limited in their ability to change text style and are unable to insert texts into images. Recent advances in diffusion models have shown promise in overcoming these limitations with text-conditional image editing. However, our empirical analysis reveals that state-of-the-art diffusion models struggle with rendering correct text and controlling text style. To address these problems, we propose DIFFSTE to improve pre-trained diffusion models with a dual encoder design, which includes a character encoder for better text legibility and an instruction encoder for better style control. An instruction tuning framework is introduced to train our model to learn
    
[^35]: 从多模态信息监督中学习可转移的行人表示

    Learning Transferable Pedestrian Representation from Multimodal Information Supervision. (arXiv:2304.05554v1 [cs.CV])

    [http://arxiv.org/abs/2304.05554](http://arxiv.org/abs/2304.05554)

    本文提出了一种新框架VAL-PAT，在多模态信息的监督下学习可转移的行人表示，以增强各种行人分析任务，其中包括自我监督对比学习、图像-文本对比学习和多属性分类。

    

    最近的无监督人物重新识别(reID)研究表明，在未标记的人物图像上预训练比在ImageNet上预训练对下游reID任务的性能产生更好的效果。然而，这些预先训练的方法是为reID专门设计的，并且对于其他行人分析任务的灵活适应存在困难。本文提出了一种新的框架VAL-PAT，它学习可转移的表示，以多模态信息增强各种行人分析任务。为了训练我们的框架，我们引入了三个学习目标，即自我监督对比学习、图像-文本对比学习和多属性分类。自我监督的对比学习有助于学习固有的行人特性，而图像-文本对比学习指导模型关注行人的外观信息。同时，多属性分类鼓励模型识别属性。

    Recent researches on unsupervised person re-identification~(reID) have demonstrated that pre-training on unlabeled person images achieves superior performance on downstream reID tasks than pre-training on ImageNet. However, those pre-trained methods are specifically designed for reID and suffer flexible adaption to other pedestrian analysis tasks. In this paper, we propose VAL-PAT, a novel framework that learns transferable representations to enhance various pedestrian analysis tasks with multimodal information. To train our framework, we introduce three learning objectives, \emph{i.e.,} self-supervised contrastive learning, image-text contrastive learning and multi-attribute classification. The self-supervised contrastive learning facilitates the learning of the intrinsic pedestrian properties, while the image-text contrastive learning guides the model to focus on the appearance information of pedestrians.Meanwhile, multi-attribute classification encourages the model to recognize attr
    
[^36]: DynamicDet:一种用于目标检测的统一动态架构

    DynamicDet: A Unified Dynamic Architecture for Object Detection. (arXiv:2304.05552v1 [cs.CV])

    [http://arxiv.org/abs/2304.05552](http://arxiv.org/abs/2304.05552)

    提出了一种名为DynamicDet的物体检测动态框架，它具有自适应路由器、退出准则和可变速度推理策略的优化策略，可实现在不同精度和速度之间平衡。

    

    动态神经网络是深度学习中的新兴研究课题。通过自适应推理，动态模型能够实现卓越的准确性和计算效率。然而，设计一个强大的动态检测器是具有挑战性的，因为缺乏适合目标检测任务的动态架构和退出准则。为解决这些难题，我们提出了一种名为DynamicDet的物体检测动态框架。首先，我们根据目标检测任务的性质精心设计了一种动态架构。然后，我们提出了一种自适应路由器，用于分析多尺度信息并自动决定推理路径。我们还提出了一种基于检测损失的退出准则的新型优化策略，用于我们的动态检测器。最后，我们提出了一种可变速度推理策略，帮助只用一个动态检测器实现广泛的精度 - 速度权衡。在COCO基准测试上进行的大量实验证明了我们的方法的有效性。

    Dynamic neural network is an emerging research topic in deep learning. With adaptive inference, dynamic models can achieve remarkable accuracy and computational efficiency. However, it is challenging to design a powerful dynamic detector, because of no suitable dynamic architecture and exiting criterion for object detection. To tackle these difficulties, we propose a dynamic framework for object detection, named DynamicDet. Firstly, we carefully design a dynamic architecture based on the nature of the object detection task. Then, we propose an adaptive router to analyze the multi-scale information and to decide the inference route automatically. We also present a novel optimization strategy with an exiting criterion based on the detection losses for our dynamic detectors. Last, we present a variable-speed inference strategy, which helps to realize a wide range of accuracy-speed trade-offs with only one dynamic detector. Extensive experiments conducted on the COCO benchmark demonstrate 
    
[^37]: CLCLSA：交叉组学链接的对比学习和自注意力多组学数据不完整情况下一体化方法

    CLCLSA: Cross-omics Linked embedding with Contrastive Learning and Self Attention for multi-omics integration with incomplete multi-omics data. (arXiv:2304.05542v1 [cs.LG])

    [http://arxiv.org/abs/2304.05542](http://arxiv.org/abs/2304.05542)

    本文提出了一种基于对比学习和自注意力的深度学习方法CLCLSA，可用于不完整多组学数据的一体化，达到最先进的性能。

    

    高维异质多组学数据的整合对于理解遗传数据变得越来越重要。然而，多组学数据集中存在未配对的数据，这是由于仪器灵敏度和成本所导致的。本文提出了一种基于对比学习和自注意力的深度学习方法CLCLSA，可用于不完整多组学数据的一体化。该方法利用完整数据作为监督，采用交叉组学自编码器跨越不同类型的生物数据学习特征表示，然后引入多组学对比学习目标，联合学习已配对和未配对数据的公共表示，有效地集成不完整数据。CLCLSA在多个基准多组学数据集上达到了最先进的性能。

    Integration of heterogeneous and high-dimensional multi-omics data is becoming increasingly important in understanding genetic data. Each omics technique only provides a limited view of the underlying biological process and integrating heterogeneous omics layers simultaneously would lead to a more comprehensive and detailed understanding of diseases and phenotypes. However, one obstacle faced when performing multi-omics data integration is the existence of unpaired multi-omics data due to instrument sensitivity and cost. Studies may fail if certain aspects of the subjects are missing or incomplete. In this paper, we propose a deep learning method for multi-omics integration with incomplete data by Cross-omics Linked unified embedding with Contrastive Learning and Self Attention (CLCLSA). Utilizing complete multi-omics data as supervision, the model employs cross-omics autoencoders to learn the feature representation across different types of biological data. The multi-omics contrastive
    
[^38]: MoMo: 一个共享编码器模型，用于文本、图像和多模态表示

    MoMo: A shared encoder Model for text, image and multi-Modal representations. (arXiv:2304.05523v1 [cs.CV])

    [http://arxiv.org/abs/2304.05523](http://arxiv.org/abs/2304.05523)

    MoMo是一个自监督的共享编码器模型，可以用于处理文本、图像和多模态数据，并且具备高效的性能。通过单一的变压器和阶段性的训练策略，在保留信息的同时，使用更少的参数和预训练数据，取得了与强模型相当的表现。

    

    我们提出了一个自监督的共享编码器模型，它在几个视觉、语言和多模态基准测试中取得了强大的结果，同时具有数据、内存和运行时效率。我们做出了三个关键贡献。首先，与大多数现有作品相比，我们使用了一个单一的变压器，所有编码器层处理文本和图像模态。其次，我们提出了一个分阶段的训练策略，其中模型首先在图像上进行训练，然后在单模文本和图像数据集上进行联合训练，最后在文本和文本-图像数据集上进行联合训练。第三，为了在两种模式下保留信息，我们提出了一个训练管道，它在每个训练更新步骤时同时从不同模态的梯度更新中学习。下游的纯文本、纯图像和多模态任务的结果显示，我们的模型与几个强模型竞争，同时使用更少的参数和较少的预训练数据。例如，MoMo在与FLAVA的竞争中表现得很有竞争力。

    We propose a self-supervised shared encoder model that achieves strong results on several visual, language and multimodal benchmarks while being data, memory and run-time efficient. We make three key contributions. First, in contrast to most existing works, we use a single transformer with all the encoder layers processing both the text and the image modalities. Second, we propose a stage-wise training strategy where the model is first trained on images, then jointly with unimodal text and image datasets and finally jointly with text and text-image datasets. Third, to preserve information across both the modalities, we propose a training pipeline that learns simultaneously from gradient updates of different modalities at each training update step. The results on downstream text-only, image-only and multimodal tasks show that our model is competitive with several strong models while using fewer parameters and lesser pre-training data. For example, MoMo performs competitively with FLAVA 
    
[^39]: 控制不变集增强强化学习在过程控制方面的应用：提高采样效率并保证稳定性

    Control invariant set enhanced reinforcement learning for process control: improved sampling efficiency and guaranteed stability. (arXiv:2304.05509v1 [eess.SY])

    [http://arxiv.org/abs/2304.05509](http://arxiv.org/abs/2304.05509)

    本文提出了一种称为控制不变集增强强化学习的方法，通过控制不变集的应用提高稳定性保证和采样效率。

    

    强化学习是一个受到广泛关注的研究领域，尤其是安全强化学习因其处理实际应用中关键的安全性约束的能力而备受关注。本文提出了一种新的强化学习训练方法，称为控制不变集增强强化学习。它利用控制不变集的优点来提高稳定性保证和采样效率。该方法分为离线阶段和在线阶段。离线阶段将控制不变集纳入奖励设计、初始状态采样和状态重置程序中。在在线阶段，当状态在控制不变集之外时，重新训练强化学习以满足稳定性标准。利用控制不变集的显式形式得到了一个备份表来保证在线稳定性。为了评估该方法，将其应用于模拟化学反应器中。结果表明，离线训练中采样效率显著提高。

    Reinforcement learning (RL) is an area of significant research interest, and safe RL in particular is attracting attention due to its ability to handle safety-driven constraints that are crucial for real-world applications of RL algorithms. This work proposes a novel approach to RL training, called control invariant set (CIS) enhanced RL, which leverages the benefits of CIS to improve stability guarantees and sampling efficiency. The approach consists of two learning stages: offline and online. In the offline stage, CIS is incorporated into the reward design, initial state sampling, and state reset procedures. In the online stage, RL is retrained whenever the state is outside of CIS, which serves as a stability criterion. A backup table that utilizes the explicit form of CIS is obtained to ensure the online stability. To evaluate the proposed approach, we apply it to a simulated chemical reactor. The results show a significant improvement in sampling efficiency during offline training 
    
[^40]: DistHD: 一种适用于超高维分类的学习感知动态编码方法

    DistHD: A Learner-Aware Dynamic Encoding Method for Hyperdimensional Classification. (arXiv:2304.05503v1 [cs.LG])

    [http://arxiv.org/abs/2304.05503](http://arxiv.org/abs/2304.05503)

    DistHD是一种适用于资源受限设备的学习感知动态编码技术，可以有效地识别和重构影响学习质量的维度，以显著较低的维度提高准确性和加速学习过程。

    

    受启发于人脑的超高维计算技术(HDC)被认为是一种适用于资源受限设备的有前途的学习方法。然而，现有方法使用静态编码器，在学习过程中从不更新。因此，需要非常高的维度才能获得足够的准确性，严重降低编码和训练效率。在本文中，我们提出DistHD，一种新颖的动态编码技术，用于HDC自适应学习，能有效地识别和重构对分类产生误导并影响学习质量的维度。我们提出的算法DistHD成功加速了学习过程，并以显著较低的维度达到了所期望的准确性。

    Brain-inspired hyperdimensional computing (HDC) has been recently considered a promising learning approach for resource-constrained devices. However, existing approaches use static encoders that are never updated during the learning process. Consequently, it requires a very high dimensionality to achieve adequate accuracy, severely lowering the encoding and training efficiency. In this paper, we propose DistHD, a novel dynamic encoding technique for HDC adaptive learning that effectively identifies and regenerates dimensions that mislead the classification and compromise the learning quality. Our proposed algorithm DistHD successfully accelerates the learning process and achieves the desired accuracy with considerably lower dimensionality.
    
[^41]: GraphGANFed: 针对基于图的分子的联合生成框架，助力高效药物发现

    GraphGANFed: A Federated Generative Framework for Graph-Structured Molecules Towards Efficient Drug Discovery. (arXiv:2304.05498v1 [cs.LG])

    [http://arxiv.org/abs/2304.05498](http://arxiv.org/abs/2304.05498)

    GraphGANFed是一个整合了GCN、GAN和联邦学习的框架，可在不共享数据的情况下高效训练生成对抗网络，助力基于图的分子的药物发现。

    

    深度学习的最新进展加速了它在各个领域应用，如细胞图像分析和分子发现。在分子发现中，生成对抗网络（GAN）因其能够高效地从大型分子数据集中学习并生成保留相似性质的新分子的能力而成为首选技术。然而，不同的制药公司可能不愿意或无法共享其本地数据集，这是由于分子数据集的地理分布和敏感性质，这使得在集中式方式中训练GAN变得不可能。在本文中，我们提出了一种基于图卷积神经网络（GCN）、GAN和联邦学习（FL）作为整体系统的GraphGANFed框架，用于生成分子。

    Recent advances in deep learning have accelerated its use in various applications, such as cellular image analysis and molecular discovery. In molecular discovery, a generative adversarial network (GAN), which comprises a discriminator to distinguish generated molecules from existing molecules and a generator to generate new molecules, is one of the premier technologies due to its ability to learn from a large molecular data set efficiently and generate novel molecules that preserve similar properties. However, different pharmaceutical companies may be unwilling or unable to share their local data sets due to the geo-distributed and sensitive nature of molecular data sets, making it impossible to train GANs in a centralized manner. In this paper, we propose a Graph convolutional network in Generative Adversarial Networks via Federated learning (GraphGANFed) framework, which integrates graph convolutional neural Network (GCN), GAN, and federated learning (FL) as a whole system to genera
    
[^42]: KGS：利用知识引导的贪婪等价搜索进行因果推断

    KGS: Causal Discovery Using Knowledge-guided Greedy Equivalence Search. (arXiv:2304.05493v1 [cs.AI])

    [http://arxiv.org/abs/2304.05493](http://arxiv.org/abs/2304.05493)

    KGS是一种新颖的因果推断方法，通过利用先前的因果边缘信息作为约束条件，可以更准确地学习因果图。

    

    仅从观测数据中学习因果关系，不能提供关于潜在的因果机制和可能的因果图空间的足够信息。因此，使用基于分数的方法搜索图等价类的空间，如贪婪等价搜索（GES），搜索空间通常会呈指数级增长。先前的因果信息，例如有无因果边，可以利用这些信息指导发现过程，使其走向更为受限且准确的搜索空间。本研究提出了KGS，一种知识引导的贪婪分数因果推断方法，它利用观测数据和结构先验（因果边）作为约束条件学习因果图。KGS是一种新颖的应用知识约束的方法，可以利用任何两个变量之间的先前边缘信息，包括有向边，无边和无向边的存在情况。

    Learning causal relationships solely from observational data provides insufficient information about the underlying causal mechanism and the search space of possible causal graphs. As a result, often the search space can grow exponentially for approaches such as Greedy Equivalence Search (GES) that uses a score-based approach to search the space of equivalence classes of graphs. Prior causal information such as the presence or absence of a causal edge can be leveraged to guide the discovery process towards a more restricted and accurate search space. In this study, we present KGS, a knowledge-guided greedy score-based causal discovery approach that uses observational data and structural priors (causal edges) as constraints to learn the causal graph. KGS is a novel application of knowledge constraints that can leverage any of the following prior edge information between any two variables: the presence of a directed edge, the absence of an edge, and the presence of an undirected edge. We
    
[^43]: 基于边触发异构图网络的多节目发行的受众扩展

    Audience Expansion for Multi-show Release Based on an Edge-prompted Heterogeneous Graph Network. (arXiv:2304.05474v1 [cs.SI])

    [http://arxiv.org/abs/2304.05474](http://arxiv.org/abs/2304.05474)

    本文提出了一种基于边缘触发的异构图网络的两阶段受众扩展方案，可以考虑不同的双面交互和特征。

    

    在视频平台上，针对新节目进行受众定位和扩展的关键在于如何生成它们的嵌入。应该从用户和节目的角度进行个性化处理。此外，为了追求即时（点击）和长期（观看时间）奖励，以及新节目的冷启动问题，带来了额外的挑战。这种问题适合通过异构图模型进行处理，因为数据具有自然的图结构。但是现实世界中的网络通常具有数十亿个节点和各种类型的边缘。很少有现有方法专注于处理大规模数据并利用不同类型的边缘，特别是后者。本文提出了一种基于边缘触发的异构图网络的两阶段受众扩展方案，可以考虑不同的双面交互和特征。在离线阶段，选择用户ID和显示器的特定边缘信息组合来构建图形。

    In the user targeting and expanding of new shows on a video platform, the key point is how their embeddings are generated. It's supposed to be personalized from the perspective of both users and shows. Furthermore, the pursue of both instant (click) and long-time (view time) rewards, and the cold-start problem for new shows bring additional challenges. Such a problem is suitable for processing by heterogeneous graph models, because of the natural graph structure of data. But real-world networks usually have billions of nodes and various types of edges. Few existing methods focus on handling large-scale data and exploiting different types of edges, especially the latter. In this paper, we propose a two-stage audience expansion scheme based on an edge-prompted heterogeneous graph network which can take different double-sided interactions and features into account. In the offline stage, to construct the graph, user IDs and specific side information combinations of the shows are chosen to 
    
[^44]: 基于光采样场和BRDF表示的基于物理的神经渲染

    Light Sampling Field and BRDF Representation for Physically-based Neural Rendering. (arXiv:2304.05472v1 [cs.CV])

    [http://arxiv.org/abs/2304.05472](http://arxiv.org/abs/2304.05472)

    本文提出了一个基于神经网络的物理渲染器，使用光采样场和BRDF表示来模拟直接和间接光照，并实现复杂对象的渲染。

    

    物理渲染对于展示计算机图形资产中的详细逼真的场景效果至关重要，但制作物理渲染效果是具有挑战性的。本文提出了一种基于神经网络的物理渲染器，以消除设备依赖性并显著提高性能。通过学习的光采样场，我们提出了一种新的光照表示方法来模拟直接和间接光照，并提出了BRDF模型，以实现复杂对象的渲染。

    Physically-based rendering (PBR) is key for immersive rendering effects used widely in the industry to showcase detailed realistic scenes from computer graphics assets. A well-known caveat is that producing the same is computationally heavy and relies on complex capture devices. Inspired by the success in quality and efficiency of recent volumetric neural rendering, we want to develop a physically-based neural shader to eliminate device dependency and significantly boost performance. However, no existing lighting and material models in the current neural rendering approaches can accurately represent the comprehensive lighting models and BRDFs properties required by the PBR process. Thus, this paper proposes a novel lighting representation that models direct and indirect light locally through a light sampling strategy in a learned light sampling field. We also propose BRDF models to separately represent surface/subsurface scattering details to enable complex objects such as translucent 
    
[^45]: 基于ChatGPT的零样本时间关系抽取

    Zero-shot Temporal Relation Extraction with ChatGPT. (arXiv:2304.05454v1 [cs.CL])

    [http://arxiv.org/abs/2304.05454](http://arxiv.org/abs/2304.05454)

    本文研究了基于ChatGPT的零样本时间关系抽取，设计了三种提示技术来拆分任务并评估ChatGPT，实验表明ChatGPT的表现与监督方法存在很大差距，但它可以更正确地推断出更多的小关系类。

    

    时间关系抽取的目标是推断文档中两个事件之间的时间关系。 监督模型在该任务中占主导地位。本研究旨在探究ChatGPT在零样本时间关系抽取方面的能力。我们设计了三种不同的提示技术来拆分任务并评估ChatGPT。我们的实验表明，ChatGPT的表现与监督方法存在很大差距，而且很大程度上依赖于提示的设计。我们进一步证明，与监督方法相比，ChatGPT可以更正确地推断出更多的小关系类。本文还讨论了ChatGPT在时间关系抽取方面的现有缺陷。我们发现，ChatGPT在时间推断过程中无法保持一致性，并且在主动长依赖时间推断中失败。

    The goal of temporal relation extraction is to infer the temporal relation between two events in the document. Supervised models are dominant in this task. In this work, we investigate ChatGPT's ability on zero-shot temporal relation extraction. We designed three different prompt techniques to break down the task and evaluate ChatGPT. Our experiments show that ChatGPT's performance has a large gap with that of supervised methods and can heavily rely on the design of prompts. We further demonstrate that ChatGPT can infer more small relation classes correctly than supervised methods. The current shortcomings of ChatGPT on temporal relation extraction are also discussed in this paper. We found that ChatGPT cannot keep consistency during temporal inference and it fails in actively long-dependency temporal inference.
    
[^46]: 可区分的图结构模型用于晶格材料反设计

    Differentiable graph-structured models for inverse design of lattice materials. (arXiv:2304.05422v1 [cond-mat.mtrl-sci])

    [http://arxiv.org/abs/2304.05422](http://arxiv.org/abs/2304.05422)

    本文提出了一种使用图形表示结构和属性的晶格材料的计算方法，使用可微分传递算法计算机械属性以实现反向设计，进而实现了可扩展的、具有前所未有的结构和功能多样性的晶格材料设计。

    

    处于深空恶劣环境中能够根据需要自适应的物理化学性质的材料将在定义未来的空间探索方面变得至关重要。在自然界中，微妙的微观结构和格子几何形状是设计适应于特定环境材料的令人兴奋的灵感来源。然而，由于这种不规则拓扑覆盖的巨大设计空间，在分析上进行探索是具有挑战性的。因此，迄今为止，大多数合成晶格材料都是基于周期性结构。在本文中，我们提出了一种计算方法，使用图形表示对规则和不规则晶格材料进行建模。我们的方法使用可微分传递算法计算力学性质，因此可以使用自动微分来调整单个晶格元素的几何结构和属性，从而设计具有所需属性的材料。引入对晶格结构和材料属性的隐式可学习几何表示，结合反设计框架，实现了可扩展的、具有前所未有的结构和功能多样性的晶格材料设计方法。

    Materials possessing flexible physico-chemical properties that adapt on-demand to the hostile environmental conditions of deep space will become essential in defining the future of space exploration. A promising venue for inspiration towards the design of environment-specific materials is in the intricate micro-architectures and lattice geometry found throughout nature. However, the immense design space covered by such irregular topologies is challenging to probe analytically. For this reason, most synthetic lattice materials have to date been based on periodic architectures instead. Here, we propose a computational approach using a graph representation for both regular and irregular lattice materials. Our method uses differentiable message passing algorithms to calculate mechanical properties, and therefore allows using automatic differentiation to adjust both the geometric structure and attributes of individual lattice elements to design materials with desired properties. The introdu
    
[^47]: 不同iable神经架构搜索中神经网络设计的高效自动化:一项概述研究(arXiv: 2304.05405v1 [cs.LG])

    Efficient Automation of Neural Network Design: A Survey on Differentiable Neural Architecture Search. (arXiv:2304.05405v1 [cs.LG])

    [http://arxiv.org/abs/2304.05405](http://arxiv.org/abs/2304.05405)

    本文综述了最近在不同iable神经架构搜索中的研究进展，提出了一种新的基于挑战的分类法，对DARTS方法的贡献和影响进行了讨论，并探讨了未来的研究方向。

    

    在过去的几年中，不同iable神经架构搜索（DNAS）迅速成为自动发现深度神经网络结构的流行方法。 这种崛起主要归功于DARTS，这是第一个重要的DNAS方法之一。 与基于强化学习或进化算法的以前的作品相比，DNAS速度快了数个数量级，并且使用的计算资源更少。 在这篇全面的综述中，我们专门关注DNAS并审查了该领域的最新方法。 此外，我们提出了一种基于挑战的分类法来分类DNAS方法。 我们还讨论了过去几年对DNAS带来的贡献以及其对全球NAS领域的影响。 最后，我们通过提供一些未来研究方向的见解来做出结论。

    In the past few years, Differentiable Neural Architecture Search (DNAS) rapidly imposed itself as the trending approach to automate the discovery of deep neural network architectures. This rise is mainly due to the popularity of DARTS, one of the first major DNAS methods. In contrast with previous works based on Reinforcement Learning or Evolutionary Algorithms, DNAS is faster by several orders of magnitude and uses fewer computational resources. In this comprehensive survey, we focus specifically on DNAS and review recent approaches in this field. Furthermore, we propose a novel challenge-based taxonomy to classify DNAS methods. We also discuss the contributions brought to DNAS in the past few years and its impact on the global NAS field. Finally, we conclude by giving some insights into future research directions for the DNAS field.
    
[^48]: 个性化文本到图像生成的可控文本反转

    Controllable Textual Inversion for Personalized Text-to-Image Generation. (arXiv:2304.05265v1 [cs.CV])

    [http://arxiv.org/abs/2304.05265](http://arxiv.org/abs/2304.05265)

    本文提出了一种名为COTI的技术，通过引入理论指导的损失目标和全面的加权评分机制，并结合主动学习范式来解决文本反转时的困难，提供了一个强大，数据效率高，易于使用的框架。

    

    最近，大规模生成模型在以文本为引导的高保真图像的生成方面取得了前所未有的性能。当引导信息包含用户定义的、未见过的或长尾概念标记时，文本反转成为一种有效的个性化生成技术。尽管如此，我们发现并展示了文本反转的部署仍充满了“黑魔法”，例如额外数据集的严苛要求，在循环中需要艰苦的人力成本和缺乏鲁棒性等。在这项工作中，我们提出了一种名为可控文本反转的大大增强版反转，解决了所有上述问题，并反过来提供了一个强大，数据效率高，易于使用的框架。COTI的核心是基于理论的损失目标，具有全面和新颖的加权评分机制，并由主动学习范式所提取。广泛的结果表明，COTI的性能比之前技术有了显著的提升，尤其是在数据少的情况下。

    The recent large-scale generative modeling has attained unprecedented performance especially in producing high-fidelity images driven by text prompts. Text inversion (TI), alongside the text-to-image model backbones, is proposed as an effective technique in personalizing the generation when the prompts contain user-defined, unseen or long-tail concept tokens. Despite that, we find and show that the deployment of TI remains full of "dark-magics" -- to name a few, the harsh requirement of additional datasets, arduous human efforts in the loop and lack of robustness. In this work, we propose a much-enhanced version of TI, dubbed Controllable Textual Inversion (COTI), in resolving all the aforementioned problems and in turn delivering a robust, data-efficient and easy-to-use framework. The core to COTI is a theoretically-guided loss objective instantiated with a comprehensive and novel weighted scoring mechanism, encapsulated by an active-learning paradigm. The extensive results show that 
    
[^49]: 监管市场：人工智能治理的未来

    Regulatory Markets: The Future of AI Governance. (arXiv:2304.04914v1 [cs.AI])

    [http://arxiv.org/abs/2304.04914](http://arxiv.org/abs/2304.04914)

    提出一种监管市场的概念，即政府要求受监管对象从私人监管机构购买监管服务，以克服过度依赖行业自律和立法机构缺乏专业知识的局限性，从而逐步实现人工智能的恰当监管。

    

    恰当地监管人工智能是一个日益紧迫的政策挑战。立法机构和监管机构缺乏翻译公众需求为法律要求所需的专业知识。过度依赖行业自律未能使AI系统的生产者和使用者对民主要求负责。提出了监管市场的概念，即政府要求受监管对象从私人监管机构购买监管服务。这种方法可以克服命令和控制监管和自我监管的局限性。监管市场可以使政府为AI监管建立政策优先级，同时依靠市场力量和行业研发努力来开创最能实现政策制定者声明目标的监管方法。

    Appropriately regulating artificial intelligence is an increasingly urgent policy challenge. Legislatures and regulators lack the specialized knowledge required to best translate public demands into legal requirements. Overreliance on industry self-regulation fails to hold producers and users of AI systems accountable to democratic demands. Regulatory markets, in which governments require the targets of regulation to purchase regulatory services from a private regulator, are proposed. This approach to AI regulation could overcome the limitations of both command-and-control regulation and self-regulation. Regulatory market could enable governments to establish policy priorities for the regulation of AI, whilst relying on market forces and industry R&D efforts to pioneer the methods of regulation that best achieve policymakers' stated objectives.
    
[^50]: 实现队列智能化：一种针对电子病历分析的通用群体表示学习框架

    Toward Cohort Intelligence: A Universal Cohort Representation Learning Framework for Electronic Health Record Analysis. (arXiv:2304.04468v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2304.04468](http://arxiv.org/abs/2304.04468)

    提出了一种通用的COhort Representation lEarning（CORE）框架，用于增强EHR表示学习，支持针对不同队列的特征进行可解释性分析。

    

    电子病历（EHR）是从临床常规护理中生成的，记录了广泛的病人人群有价值的信息，为改善临床实践中的病人管理和干预策略提供了丰富的机会。为了利用EHR数据的巨大潜力，机器学习中流行的EHR数据分析范式是EHR表示学习，它首先利用单个病人的EHR数据通过一个主干学习信息丰富的表示，并支持建立在这些表示的多样化的医疗下游任务。然而，这种范式无法深入分析病人的相关性，通常在临床实践中被称为队列研究。具体来说，同一队列中的病人倾向于具有相似的特征，表明他们在医疗条件（如症状或疾病）方面具有相似之处。在本文中，我们提出了一种通用COhort Representation lEarning (CORE)框架来增强EHR表示学习，通过使用队列表示学习算法，对群体信息进行建模并支持针对不同队列的特征进行可解释性分析。

    Electronic Health Records (EHR) are generated from clinical routine care recording valuable information of broad patient populations, which provide plentiful opportunities for improving patient management and intervention strategies in clinical practice. To exploit the enormous potential of EHR data, a popular EHR data analysis paradigm in machine learning is EHR representation learning, which first leverages the individual patient's EHR data to learn informative representations by a backbone, and supports diverse health-care downstream tasks grounded on the representations. Unfortunately, such a paradigm fails to access the in-depth analysis of patients' relevance, which is generally known as cohort studies in clinical practice. Specifically, patients in the same cohort tend to share similar characteristics, implying their resemblance in medical conditions such as symptoms or diseases. In this paper, we propose a universal COhort Representation lEarning (CORE) framework to augment EHR
    
[^51]: 基于NeRF技术的卫星图像表面重建

    NeRF applied to satellite imagery for surface reconstruction. (arXiv:2304.04133v1 [cs.CV])

    [http://arxiv.org/abs/2304.04133](http://arxiv.org/abs/2304.04133)

    本文提出了Sat-NeRF模型，能够从少量的卫星图像集合中合成新的视角，并准确地估计场景表面的高程。

    

    本文提出了Sat-NeRF模型，是对最近引入的S-NeRF模型的修改实现。该模型能够从稀疏的卫星图像集合中合成新的视角，同时考虑到图片中的光照变化。训练好的模型还能够精确地估计场景表面的高程，这对卫星观测应用非常有帮助。S-NeRF方法改进了标准的NeRF方法，将辐射强度考虑为高反射率和入射辐照度的函数。这两个量都是模型的全连接神经网络枝条的输出，而后者则被视为来自太阳的直接光线和来自天空的漫反射颜色函数。该实现基于用缩放-裁剪技术增强的卫星图像数据集。对NeRF进行了超参数研究，得出了一些有趣的观察结果。

    We present Sat-NeRF, a modified implementation of the recently introduced Shadow Neural Radiance Field (S-NeRF) model. This method is able to synthesize novel views from a sparse set of satellite images of a scene, while accounting for the variation in lighting present in the pictures. The trained model can also be used to accurately estimate the surface elevation of the scene, which is often a desirable quantity for satellite observation applications. S-NeRF improves on the standard Neural Radiance Field (NeRF) method by considering the radiance as a function of the albedo and the irradiance. Both these quantities are output by fully connected neural network branches of the model, and the latter is considered as a function of the direct light from the sun and the diffuse color from the sky. The implementations were run on a dataset of satellite images, augmented using a zoom-and-crop technique. A hyperparameter study for NeRF was carried out, leading to intriguing observations on the 
    
[^52]: 一对替代品的几乎最优操纵

    Almost optimal manipulation of a pair of alternatives. (arXiv:2304.03060v1 [cs.AI])

    [http://arxiv.org/abs/2304.03060](http://arxiv.org/abs/2304.03060)

    本文研究了一对替代品的排名，通过算法找到了一种几乎最优的操纵方式，以确定在给定情况下操纵的难易程度。

    

    决策过程中专家的角色至关重要，因为最终的建议取决于他们的态度、头脑清晰程度、经验和对问题的了解。但是，建议还取决于他们的诚实。如果专家不诚实怎么办？那么，在给定情况下操纵是多么困难就变得很重要了。本研究考虑到了通过比较一对替代品获得的排名的操纵。更具体地说，我们提出了一种算法，用于找到交换选定的两个替代品位置的几乎最优方式。由此，就可以确定在给定情况下操纵是多么困难的了。理论考虑通过一个实际例子进行了说明。

    The role of an expert in the decision-making process is crucial, as the final recommendation depends on his disposition, clarity of mind, experience, and knowledge of the problem. However, the recommendation also depends on their honesty. But what if the expert is dishonest? Then, the answer on how difficult it is to manipulate in a given case becomes essential. In the presented work, we consider manipulation of a ranking obtained by comparing alternatives in pairs. More specifically, we propose an algorithm for finding an almost optimal way to swap the positions of two selected alternatives. Thanks to this, it is possible to determine how difficult such manipulation is in a given case. Theoretical considerations are illustrated by a practical example.
    
[^53]: 重新审视带有无法回答的反事实情景的密集检索

    Revisiting Dense Retrieval with Unanswerable Counterfactuals. (arXiv:2304.03031v1 [cs.AI])

    [http://arxiv.org/abs/2304.03031](http://arxiv.org/abs/2304.03031)

    本文观察到基于DPR的最近的密集检索模型经常将无法回答的反事实情景排名高于可回答的原始情景，提出了一种新颖的用于段落检索的表示学习方法PiCL。

    

    在开放领域问答（ODQA）中，检索器-阅读器框架很受欢迎，其中检索器从大型语料库中为阅读器抽取一组相关的候选段落。这种方法背后的一个关键假设是，从检索器得到的高相关性分数可能表明从阅读器获取答案的可能性很高，这意味着检索到的段落很可能包含给定问题的答案。我们在本研究中实证驳斥了这种观点，并观察到基于DPR的最近的密集检索模型经常将无法回答的反事实情景排名高于可回答的原始情景。为了解决密集检索中这种对答案无感知的问题，我们寻求使用反事实样本作为额外的训练资源，以更好地同步DPR的相关性测量和问题-段落对的可答性。具体地，我们提出了反事实Pivoting对比学习（PiCL），这是一种新颖的用于段落检索的表示学习方法。

    The retriever-reader framework is popular for open-domain question answering (ODQA), where a retriever samples for the reader a set of relevant candidate passages from a large corpus. A key assumption behind this method is that high relevance scores from the retriever likely indicate high answerability from the reader, which implies a high probability that the retrieved passages contain answers to a given question. In this work, we empirically dispel this belief and observe that recent dense retrieval models based on DPR often rank unanswerable counterfactual passages higher than their answerable original passages. To address such answer-unawareness in dense retrievers, we seek to use counterfactual samples as additional training resources to better synchronize the relevance measurement of DPR with the answerability of question-passage pairs. Specifically, we present counterfactually-Pivoting Contrastive Learning (PiCL), a novel representation learning approach for passage retrieval th
    
[^54]: 大型语言模型作为钥匙：用GPT解密材料科学的秘密。

    Large Language Models as Master Key: Unlocking the Secrets of Materials Science with GPT. (arXiv:2304.02213v1 [cs.CL])

    [http://arxiv.org/abs/2304.02213](http://arxiv.org/abs/2304.02213)

    本文介绍了一个新的自然语言处理任务——结构化信息推理（SIS），利用GPT-3模型能够准确提取材料科学设备层面的信息，并通过实验预测PCE和反向预测参数，展示了大型语言模型在材料学中的巨大潜力。

    

    本文介绍了一个新的自然语言处理（NLP）任务——结构化信息推理（SIS），以解决材料科学设备层面信息提取的复杂性。我们使用现有的钙钛矿太阳能电池FAIR数据集对GPT-3进行微调，获得了91.8 F1得分，并更新了数据集，包括迄今为止所有相关科学论文。所生成的数据集已被格式化和标准化，使得它可以直接作为后续数据分析的输入。这个特性将使材料科学家通过选择高质量的领域评论文章来开发其自己的模型。此外，我们设计了实验来预测PCE和反向预测参数，并获得了与DFT相当的性能，这证明了大型语言模型能够像材料学家一样评判材料和设计新材料。

    This article presents a new NLP task called structured information inference (SIS) to address the complexities of information extraction at the device level in materials science. We accomplished this task by finetuning GPT-3 on a exsiting perovskite solar cell FAIR dataset with 91.8 F1-score and we updated the dataset with all related scientific papers up to now. The produced dataset is formatted and normalized, enabling its direct utilization as input in subsequent data analysis. This feature will enable materials scientists to develop their own models by selecting high-quality review papers within their domain. Furthermore, we designed experiments to predict PCE and reverse-predict parameters and obtained comparable performance with DFT, which demonstrates the potential of large language models to judge materials and design new materials like a materials scientist.
    
[^55]: 社会文化知识在仇恨言论检测任务中对选项的选择是必要的

    Sociocultural knowledge is needed for selection of shots in hate speech detection tasks. (arXiv:2304.01890v1 [cs.CL])

    [http://arxiv.org/abs/2304.01890](http://arxiv.org/abs/2304.01890)

    HATELEXICON是一个包含巴西，德国，印度和肯尼亚仇恨言论的词汇表，利用其可以提高模型在训练中的性能表现。

    

    我们引入了HATELEXICON，这是一个包含巴西，德国，印度和肯尼亚的蔑称和仇恨言论目标的词汇表，以帮助模型的训练和可解释性。我们展示了我们的词汇表如何用于解释模型预测，表明发展用于分类极端言论的模型，在进行预测时严重依赖目标词。此外，我们提出了一种通过HATELEXICON来辅助低资源环境下训练选项的方法，选项选择在小样本学习中尤为重要。在我们的工作中，我们使用HASOC数据对德语和印地语进行了几个示范学习，并将Multilingual HateCheck（MHC）作为基准。我们展示了根据我们的词汇表选择样本，相对于随机采样的模型，能够更好地在MHC上表现。因此，当仅有少量的训练样本时，使用我们的词汇表来选择包含更多社会文化信息的样本能够更好地提高在仇恨言论检测任务中的性能。

    We introduce HATELEXICON, a lexicon of slurs and targets of hate speech for the countries of Brazil, Germany, India and Kenya, to aid training and interpretability of models. We demonstrate how our lexicon can be used to interpret model predictions, showing that models developed to classify extreme speech rely heavily on target words when making predictions. Further, we propose a method to aid shot selection for training in low-resource settings via HATELEXICON. In few-shot learning, the selection of shots is of paramount importance to model performance. In our work, we simulate a few-shot setting for German and Hindi, using HASOC data for training and the Multilingual HateCheck (MHC) as a benchmark. We show that selecting shots based on our lexicon leads to models performing better on MHC than models trained on shots sampled randomly. Thus, when given only a few training examples, using our lexicon to select shots containing more sociocultural information leads to better few-shot perf
    
[^56]: 大型语言模型综述

    A Survey of Large Language Models. (arXiv:2303.18223v1 [cs.CL])

    [http://arxiv.org/abs/2303.18223](http://arxiv.org/abs/2303.18223)

    本文综述了大型语言模型的研究历程以及最近的预训练语言模型(PLMs)，并强调模型扩展将带来性能改进和特殊能力的发掘。

    

    语言本质上是一个由语法规则控制的复杂精细的人类表达系统，对于开发理解和掌握语言的能力的AI算法来说是一项重大挑战。作为主要方法之一，语言建模在过去二十年里广泛研究用于语言理解和生成，从统计语言模型演化为神经语言模型。最近，通过在大规模语料库上预训练Transformer模型，提出了预训练语言模型（PLMs），在解决各种NLP任务方面显示出强大的能力。由于研究人员发现模型缩放可以导致性能改进，他们进一步通过增加模型规模来研究缩放效应，有趣的是，当参数规模超过一定水平时，这些扩大的语言模型不仅可以实现显着的性能提升，而且还显示出一些小规模语言模型所没有的特殊能力。

    Language is essentially a complex, intricate system of human expressions governed by grammatical rules. It poses a significant challenge to develop capable AI algorithms for comprehending and grasping a language. As a major approach, language modeling has been widely studied for language understanding and generation in the past two decades, evolving from statistical language models to neural language models. Recently, pre-trained language models (PLMs) have been proposed by pre-training Transformer models over large-scale corpora, showing strong capabilities in solving various NLP tasks. Since researchers have found that model scaling can lead to performance improvement, they further study the scaling effect by increasing the model size to an even larger size. Interestingly, when the parameter scale exceeds a certain level, these enlarged language models not only achieve a significant performance improvement but also show some special abilities that are not present in small-scale langu
    
[^57]: 面向对象检测的模型无关可解释人工智能

    Model-agnostic explainable artificial intelligence for object detection in image data. (arXiv:2303.17249v1 [cs.CV])

    [http://arxiv.org/abs/2303.17249](http://arxiv.org/abs/2303.17249)

    本文设计并实现了一种新的黑盒解释方法——BODEM，它采用了局部和远程掩蔽生成多个版本的输入图像，从而比目前用于解释对象检测的其他三种最先进的方法提供更详细和有用的解释。

    

    对象检测是计算机视觉中的基本任务之一，通过开发大型复杂的深度学习模型已经取得了很大进展。然而，缺乏透明度是一个重要的挑战，可能妨碍这些模型的广泛应用。可解释的人工智能是一个研究领域，其中开发方法来帮助用户理解基于人工智能的系统的行为、决策逻辑和漏洞。本文为了解释基于人工智能的对象检测系统设计和实现了一种名为Black-box Object Detection Explanation by Masking（BODEM）的黑盒说明方法，采用新的掩蔽方法。我们提出了局部和远程掩蔽来生成输入图像的多个版本。局部掩蔽用于干扰目标对象内的像素，以了解对象检测器对这些变化的反应，而远程掩蔽则用于研究对象检测器在图像背景上的行为。我们在三个基准数据集上的实验表明，与用于解释对象检测的其他三种最先进的方法相比，BODEM提供了更详细和有用的说明。

    Object detection is a fundamental task in computer vision, which has been greatly progressed through developing large and intricate deep learning models. However, the lack of transparency is a big challenge that may not allow the widespread adoption of these models. Explainable artificial intelligence is a field of research where methods are developed to help users understand the behavior, decision logics, and vulnerabilities of AI-based systems. Black-box explanation refers to explaining decisions of an AI system without having access to its internals. In this paper, we design and implement a black-box explanation method named Black-box Object Detection Explanation by Masking (BODEM) through adopting a new masking approach for AI-based object detection systems. We propose local and distant masking to generate multiple versions of an input image. Local masks are used to disturb pixels within a target object to figure out how the object detector reacts to these changes, while distant ma
    
[^58]: ChatGPT在元宇宙中的应用：拯救者还是毁灭者?

    Unleasing ChatGPT on the Metaverse: Savior or Destroyer?. (arXiv:2303.13856v1 [cs.HC])

    [http://arxiv.org/abs/2303.13856](http://arxiv.org/abs/2303.13856)

    本文探讨了在元宇宙中使用ChatGPT的利弊，它可以提供动态和个性化的体验，但也必须考虑隐私、偏见和道德等相关问题。

    

    随着虚拟现实技术的不断发展，“元宇宙”这个新兴领域的交互方式和沉浸体验越来越重要。而人工智能技术和自然语言处理技术在这一领域中的应用变得日益重要。其中，一个被广泛使用的工具是ChatGPT，这是OpenAI训练的一个大型语言模型。本文详细探讨了在元宇宙中引入ChatGPT的利弊，包括教育、娱乐、个性化和支持等方面的应用。虽然这项技术可以提供动态和个性化的体验，但也必须考虑隐私、偏见和道德等相关问题。本文旨在通过评估这些机遇和障碍，帮助读者理解ChatGPT对元宇宙可能产生的影响，以及如何有效地利用它创建更加沉浸和有趣的虚拟环境。

    The incorporation of artificial intelligence (AI) technology, and in particular natural language processing (NLP), is becoming increasingly vital for the development of immersive and interactive metaverse experiences. One such artificial intelligence tool that is gaining traction in the metaverse is ChatGPT, a large language model trained by OpenAI. The article delves into the pros and cons of utilizing ChatGPT for metaverse-based education, entertainment, personalization, and support. Dynamic and personalized experiences are possible with this technology, but there are also legitimate privacy, bias, and ethical issues to consider. This article aims to help readers understand the possible influence of ChatGPT on the metaverse and how it may be used to effectively create a more immersive and engaging virtual environment by evaluating these opportunities and obstacles.
    
[^59]: GPT-4在医学挑战问题上的能力

    Capabilities of GPT-4 on Medical Challenge Problems. (arXiv:2303.13375v1 [cs.CL])

    [http://arxiv.org/abs/2303.13375](http://arxiv.org/abs/2303.13375)

    本论文对最先进的LLM——GPT-4在医学能力考试和基准数据集上进行了全面评估，结果显示其表现出色，有助于医学相关领域的研究和应用。

    

    大型语言模型（LLMs）已经在各个领域展示了惊人的自然语言理解和生成能力，包括医学。我们对一项最先进的LLM——GPT-4在医学能力考试和基准数据集上进行了全面评估。GPT-4是一个通用模型，没有经过针对医学问题的训练或设计用于解决临床任务。我们的分析涵盖了美国临床能力评估和授权考核计划（USMLE）的两组官方练习材料。我们还评估了在MultiMedQA基准数据集上的表现。除了测量模型的性能，还进行了实验来研究包含文本和图像的测试问题对模型性能的影响，探索训练期间内容记忆的可能性，并研究概率校准在高风险应用中的重要性。

    Large language models (LLMs) have demonstrated remarkable capabilities in natural language understanding and generation across various domains, including medicine. We present a comprehensive evaluation of GPT-4, a state-of-the-art LLM, on medical competency examinations and benchmark datasets. GPT-4 is a general-purpose model that is not specialized for medical problems through training or engineered to solve clinical tasks. Our analysis covers two sets of official practice materials for the USMLE, a three-step examination program used to assess clinical competency and grant licensure in the United States. We also evaluate performance on the MultiMedQA suite of benchmark datasets. Beyond measuring model performance, experiments were conducted to investigate the influence of test questions containing both text and images on model performance, probe for memorization of content during training, and study probability calibration, which is of critical importance in high-stakes applications 
    
[^60]: 心灵与机器: 解开GPT-4的认知心理学之谜

    Mind meets machine: Unravelling GPT-4's cognitive psychology. (arXiv:2303.11436v1 [cs.CL])

    [http://arxiv.org/abs/2303.11436](http://arxiv.org/abs/2303.11436)

    本研究评估了在广泛使用的CommonsenseQA数据集中的一套常识推理问题上，GPT-4的表现及其对常识知识的处理和整合过程，在此过程中我们也发现了其局限性。

    

    常识推理是人类智能的基本成分，使其能够根据环境观察推断结论。大型语言模型(LLMs)正成为越来越能够执行人类级任务的强有力工具。最近开发的GPT-4及其在医学考试、律师考试等人类难以完成的任务中表现出的成功，增加了LLMs成为完美智能工具的信心。然而，尽管GPT-4论文向我们展示了其在某些常识推理任务中的表现，但对GPT-4在常识推理任务上的全面评估，特别是现有的已经确立好的数据集上的评估还是缺失的。为此，我们关注GPT-4在广泛使用的CommonsenseQA数据集中的一套常识推理问题上的表现评估及其认知心理学工具。通过这样做，我们能够理解GPT-4如何在其语言生成过程中处理和整合常识知识，以及其在这方面的局限性。

    Commonsense reasoning is a basic ingredient of intelligence in humans, empowering the ability to deduce conclusions based on the observations of surroundings. Large language models (LLMs) are emerging as potent tools increasingly capable of performing human-level tasks. The recent development in the form of GPT-4 and its demonstrated success in tasks complex to humans such as medical exam, bar exam and others has led to an increased confidence in the LLMs to become perfect instruments of intelligence. Though, the GPT-4 paper has shown performance on some common sense reasoning tasks, a comprehensive assessment of GPT-4 on common sense reasoning tasks, particularly on the existing well-established datasets is missing. In this study, we focus on the evaluation of GPT-4's performance on a set of common sense reasoning questions from the widely used CommonsenseQA dataset along with tools from cognitive psychology. In doing so, we understand how GPT-4 processes and integrates common sense k
    
[^61]: 零样本对比损失用于文本引导扩散图像风格迁移

    Zero-Shot Contrastive Loss for Text-Guided Diffusion Image Style Transfer. (arXiv:2303.08622v1 [cs.CV])

    [http://arxiv.org/abs/2303.08622](http://arxiv.org/abs/2303.08622)

    本文提出了一种适用于文本引导图像风格迁移中的零样本对比损失方法，可以在不需要额外训练的情况下生成具有相同语义内容的图像。

    

    扩散模型在文本引导图像风格迁移中表现出极大的潜力，但由于其随机性而存在风格转换和内容保护之间的权衡。现有方法需要计算密集的扩散模型微调或附加神经网络。为了解决这个问题，我们在扩散模型中提出了一种零样本对比损失，它不需要额外的微调或辅助网络。通过利用预训练的扩散模型中生成样本和原始图像嵌入之间的图块对比损失，我们的方法可以以零样本的方式生成具有与源图像相同语义内容的图像。我们的方法在保留内容且不需要额外训练的同时，在图像风格迁移、图像到图像的转换和操作中均优于现有方法。我们的实验结果证实了我们提出的方法的有效性。

    Diffusion models have shown great promise in text-guided image style transfer, but there is a trade-off between style transformation and content preservation due to their stochastic nature. Existing methods require computationally expensive fine-tuning of diffusion models or additional neural network. To address this, here we propose a zero-shot contrastive loss for diffusion models that doesn't require additional fine-tuning or auxiliary networks. By leveraging patch-wise contrastive loss between generated samples and original image embeddings in the pre-trained diffusion model, our method can generate images with the same semantic content as the source image in a zero-shot manner. Our approach outperforms existing methods while preserving content and requiring no additional training, not only for image style transfer but also for image-to-image translation and manipulation. Our experimental results validate the effectiveness of our proposed method.
    
[^62]: 工人是否能够有效同意工作场所健康科技？

    Can Workers Meaningfully Consent to Workplace Wellbeing Technologies?. (arXiv:2303.07242v2 [cs.HC] UPDATED)

    [http://arxiv.org/abs/2303.07242](http://arxiv.org/abs/2303.07242)

    工作场所感知技术的应用有助于提高生产力和福祉，但如何获取工人的有效同意是需要解决的难题，本文探讨了工人面临的挑战，并提出了可能的解决方案。

    

    工作场所部署的感知技术可以收集个人活动和群体互动的详细数据，否则很难捕捉。这些技术的一个有希望的应用是它们可以帮助企业和工人优化生产力和福祉。然而，鉴于工作场所中的内在和结构性权力动态，接受含蓄的遵从以监测工作活动而不是寻求工人的有意义的同意的普遍做法引发了隐私和伦理方面的担忧。本文阐述了工人在同意工作场所健康科技方面面临的一系列挑战。利用一个虚拟案例，引导15位参与者参与了6个多利益相关方焦点小组，我们探讨了参与者同意工作场所感知技术的期望和能力。我们描绘了可能更好地支持更有意义的同意工作场所健康科技的干预措施，这些措施 drawing on critical

    Sensing technologies deployed in the workplace can collect detailed data about individual activities and group interactions that are otherwise difficult to capture. A hopeful application of these technologies is that they can help businesses and workers optimize productivity and wellbeing. However, given the inherent and structural power dynamics in the workplace, the prevalent approach of accepting tacit compliance to monitor work activities rather than seeking workers' meaningful consent raises privacy and ethical concerns. This paper unpacks a range of challenges that workers face when consenting to workplace wellbeing technologies. Using a hypothetical case to prompt reflection among six multi-stakeholder focus groups involving 15 participants, we explored participants' expectations and capacity to consent to workplace sensing technologies. We sketched possible interventions that could better support more meaningful consent to workplace wellbeing technologies by drawing on critical
    
[^63]: 最优觅食策略是可学习的，并且优于 L\'evy walks。

    Optimal foraging strategies can be learned and outperform L\'evy walks. (arXiv:2303.06050v2 [cond-mat.stat-mech] UPDATED)

    [http://arxiv.org/abs/2303.06050](http://arxiv.org/abs/2303.06050)

    研究发现，通过强化学习代理，存活的生物可以学习到优于 L\'evy walks 的觅食策略，以提高觅食效率。

    

    L\'evy walks 和其他争议论的最优觅食模型成功地被用于描述现实世界的场景，吸引了经济学、物理学、生态学、进化生物学等多个领域的关注。然而，在大多数情况下仍不清楚哪些策略可以最大化觅食效率，这些策略是否可以被生物学习。为了回答这些问题，我们将觅食者建模为强化学习代理。我们首先理论上证明，在我们的强化学习模型中最大化奖励等同于优化觅食效率。然后，通过数值实验，我们展示了我们的代理学习了优于已知策略如 L\'evy walks 的觅食策略。

    L\'evy walks and other theoretical models of optimal foraging have been successfully used to describe real-world scenarios, attracting attention in several fields such as economy, physics, ecology, and evolutionary biology. However, it remains unclear in most cases which strategies maximize foraging efficiency and whether such strategies can be learned by living organisms. To address these questions, we model foragers as reinforcement learning agents. We first prove theoretically that maximizing rewards in our reinforcement learning model is equivalent to optimizing foraging efficiency. We then show with numerical experiments that our agents learn foraging strategies which outperform the efficiency of known strategies such as L\'evy walks.
    
[^64]: CVT-SLR：基于对比视觉-文本变换与变分对齐的手语识别模型

    CVT-SLR: Contrastive Visual-Textual Transformation for Sign Language Recognition with Variational Alignment. (arXiv:2303.05725v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2303.05725](http://arxiv.org/abs/2303.05725)

    CVT-SLR是一种新的手语识别模型，它采用基于对比视觉-文本变换和变分对齐的方法来充分利用跨模态知识，为解决手语识别中缺乏大规模可用数据集的问题提供了一种新的解决方案。

    

    手语识别 (SLR) 是一项弱监督任务，可以将手语视频注释为文本。最近的研究表明，由于缺乏大规模可用的手语数据集而导致的不充分训练成为 SLR 的主要瓶颈。因此，大多数 SLR 的工作采用预训练的视觉模块，并开发了两种主流解决方案。本文提出了一种新型的对比视觉-文本变换模型 CVT-SLR，充分发挥了视觉和语言模态的预训练知识。

    Sign language recognition (SLR) is a weakly supervised task that annotates sign videos as textual glosses. Recent studies show that insufficient training caused by the lack of large-scale available sign language datasets becomes the main bottleneck for SLR. The majority of SLR works thereby adopt pretrained visual modules and develop two mainstream solutions. The multi-stream architectures extend multi-cue visual features, yielding the current SOTA performances but requiring complex designs and might introduce potential noise. Alternatively, the advanced single-cue SLR frameworks using explicit cross-modal alignment between visual and textual modalities are simple and effective, potentially competitive with the multi-cue framework. In this work, we propose a novel contrastive visual-textual transformation for SLR, CVT-SLR, to fully explore the pretrained knowledge of both the visual and language modalities. Based on the single-cue cross-modal alignment framework, we propose a variation
    
[^65]: 发现图像分类器在罕见子群体上的系统性错误

    Identification of Systematic Errors of Image Classifiers on Rare Subgroups. (arXiv:2303.05072v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2303.05072](http://arxiv.org/abs/2303.05072)

    该论文提出了一种名为PromptAttack的组合测试方法，通过在被低频率覆盖的子群体中搜索找到目标模型在这些条件下表现不佳的子群体，以此识别出分类器可能存在的系统误差问题。

    

    尽管许多图像分类器具有出色的平均性能，但它们在训练数据中未被充分覆盖的语义连贯的子群体上的性能可能会显著降低。这些系统误差可能会影响民族少数群体的公平性，以及在领域转移时的鲁棒性和安全性。我们利用文本到图像模型，搜索数据中被低频率覆盖的子群体（“提示”），找到目标模型在这些条件下表现不佳的子群体，以此识别出分类器可能存在的系统误差问题。我们采用组合测试解决了子群体数量呈指数级增长的挑战，并将这个过程称为PromptAttack。我们在受控的实验环境下研究了PromptAttack的子群体涵盖率和可识别性。

    Despite excellent average-case performance of many image classifiers, their performance can substantially deteriorate on semantically coherent subgroups of the data that were under-represented in the training data. These systematic errors can impact both fairness for demographic minority groups as well as robustness and safety under domain shift. A major challenge is to identify such subgroups with subpar performance when the subgroups are not annotated and their occurrence is very rare. We leverage recent advances in text-to-image models and search in the space of textual descriptions of subgroups ("prompts") for subgroups where the target model has low performance on the prompt-conditioned synthesized data. To tackle the exponentially growing number of subgroups, we employ combinatorial testing. We denote this procedure as PromptAttack as it can be interpreted as an adversarial attack in a prompt space. We study subgroup coverage and identifiability with PromptAttack in a controlled 
    
[^66]: 进化强化学习综述

    Evolutionary Reinforcement Learning: A Survey. (arXiv:2303.04150v3 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2303.04150](http://arxiv.org/abs/2303.04150)

    这篇文章系统地总结了最新的进化计算方法在解决强化学习中的关键挑战方面所取得的良好性能。

    

    强化学习是一种通过与环境交互训练智能体最大化累积奖励的机器学习方法。最近将强化学习与深度学习相结合，在棋盘游戏、街机游戏和机器人控制等各种挑战性任务中取得了令人瞩目的成就。尽管取得了成功，但仍存在一些关键挑战，包括由敏感超参数导致的脆弱收敛特性，长时间跨度和稀疏奖励的时间分配困难，特别是在连续搜索空间场景中的多样性探索不足，多智能体强化学习中的信用分配困难以及奖励冲突目标。进化计算维护着一群学习智能体，已展现出解决这些限制的良好性能。本文介绍了集成进化计算的最新方法的全面综述。

    Reinforcement learning (RL) is a machine learning approach that trains agents to maximize cumulative rewards through interactions with environments. The integration of RL with deep learning has recently resulted in impressive achievements in a wide range of challenging tasks, including board games, arcade games, and robot control. Despite these successes, there remain several crucial challenges, including brittle convergence properties caused by sensitive hyperparameters, difficulties in temporal credit assignment with long time horizons and sparse rewards, a lack of diverse exploration, especially in continuous search space scenarios, difficulties in credit assignment in multi-agent reinforcement learning, and conflicting objectives for rewards. Evolutionary computation (EC), which maintains a population of learning agents, has demonstrated promising performance in addressing these limitations. This article presents a comprehensive survey of state-of-the-art methods for integrating EC
    
[^67]: AI对抗AI：在社交媒体上打击机器生成的虚假餐厅评论

    Combat AI With AI: Counteract Machine-Generated Fake Restaurant Reviews on Social Media. (arXiv:2302.07731v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.07731](http://arxiv.org/abs/2302.07731)

    本文针对机器生成的虚假评论提出了一种用高质量餐厅评论生成虚假评论并微调GPT输出检测器的方法，该方法预测虚假评论的性能优于现有解决方案。同时，我们还探索了预测非精英评论的模型，并在几个维度上对这些评论进行分析，此类机器生成的虚假评论是社交媒体平台面临的持续挑战。

    

    最近生成模型（如GPT）的发展使得以更低的成本制造出难以区分的虚假顾客评论，从而对社交媒体平台检测这些机器生成的虚假评论造成挑战。本文提出利用Yelp验证的高质量的精英餐厅评论来生成OpenAI GPT评论生成器的虚假评论，并最终微调GPT输出检测器来预测明显优于现有解决方案的虚假评论。我们进一步将模型应用于预测非精英评论，并在几个维度（如评论、用户和餐厅特征以及写作风格）上识别模式。我们展示了社交媒体平台正在不断面临机器生成的虚假评论的挑战，尽管他们可能实施检测系统以过滤出可疑的评论。

    Recent advances in generative models such as GPT may be used to fabricate indistinguishable fake customer reviews at a much lower cost, thus posing challenges for social media platforms to detect these machine-generated fake reviews. We propose to leverage the high-quality elite restaurant reviews verified by Yelp to generate fake reviews from the OpenAI GPT review creator and ultimately fine-tune a GPT output detector to predict fake reviews that significantly outperform existing solutions. We further apply the model to predict non-elite reviews and identify the patterns across several dimensions, such as review, user and restaurant characteristics, and writing style. We show that social media platforms are continuously challenged by machine-generated fake reviews, although they may implement detection systems to filter out suspicious reviews.
    
[^68]: 多光谱对比学习与Viewmaker网络

    Multispectral Contrastive Learning with Viewmaker Networks. (arXiv:2302.05757v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.05757](http://arxiv.org/abs/2302.05757)

    本文研究将对比学习方法应用于各种遥感数据集。通过使用Viewmaker网络，本文发现该方法可以在不耗费大量时间和领域知识的情况下成功产生视图，并在四个多光谱成像问题上实现优于基于裁剪和反射的对比学习方法的表现。

    

    对比学习方法已广泛应用于各领域和模态，通过训练模型识别数据点的相似“视图”。然而，专业的科学模态对这种范式 pose challenge，因为为每个科学仪器识别好的视图是复杂和耗时的。在这篇论文中，我们专注于将对比学习方法应用于各种遥感数据集。我们展示了Viewmaker网络，这是一种最近提出的生成视图的方法，很有前途地能够在不需要大量领域知识和试错的情况下在这一领域内产生视图。我们将Viewmaker应用于四个多光谱成像问题，每个问题具有不同的格式，发现在下游分类任务的评估中，在每种情况下Viewmaker都可以优于基于裁剪和反射的对比学习方法。这进一步证明了领域不可知的方法可以使对比学习扩展到实际的科学应用规模。

    Contrastive learning methods have been applied to a range of domains and modalities by training models to identify similar "views" of data points. However, specialized scientific modalities pose a challenge for this paradigm, as identifying good views for each scientific instrument is complex and time-intensive. In this paper, we focus on applying contrastive learning approaches to a variety of remote sensing datasets. We show that Viewmaker networks, a recently proposed method for generating views, are promising for producing views in this setting without requiring extensive domain knowledge and trial and error. We apply Viewmaker to four multispectral imaging problems, each with a different format, finding that Viewmaker can outperform croppingand reflection-based methods for contrastive learning in every case when evaluated on downstream classification tasks. This provides additional evidence that domain-agnostic methods can empower contrastive learning to scale to real-world scie
    
[^69]: 利用子模价值将物品分配给代理人

    Dividing Good and Better Items Among Agents with Submodular Valuations. (arXiv:2302.03087v2 [cs.GT] UPDATED)

    [http://arxiv.org/abs/2302.03087](http://arxiv.org/abs/2302.03087)

    本文研究了在具有二元子模价值的代理人之间公平分配不可分割物品的问题，并提出了一个解决方案概念的算法框架，其中包括leximin、max Nash welfare（MNW）和$p$-mean welfare最大化分配。在$ab$可整除的情况下，该算法框架可以用于求解多种解决方案概念，补充了现有结果的限制。同时，该文研究了leximin和MNW分配在无嫉妒和最大最小份额保证方面的表现。

    

    本文研究了在具有二元子模价值的代理人之间公平分配一组不可分割的物品的问题。每个物品都提供$a$或$b$的边际收益（$a<b$），且物品的边际收益递减。这是两种广泛研究的评估类别——二元加性评估和二元子模评估的自然泛化。我们提出了一个简单的顺序算法框架，基于最近介绍的“扬基交换”机制，可以适应计算各种解决方案概念，包括leximin、max Nash welfare（MNW）和当$a$除以$b$时$p$-mean welfare最大化分配。这个结果补充了一个现有的结果，即当$a$不能被$b$整除时，leximin和MNW分配的计算无法复杂化。我们进一步研究了在两个知名属性——无嫉妒和最大最小份额保证方面的leximin和MNW分配。在无嫉妒方面，我们表明leximin和MNW都不满足

    We study the problem of fairly allocating a set of indivisible goods among agents with bivalued submodular valuations -- each good provides a marginal gain of either $a$ or $b$ ($a < b$) and goods have decreasing marginal gains. This is a natural generalization of two well-studied valuation classes -bivalued additive valuations and binary submodular valuations. We present a simple sequential algorithmic framework, based on the recently introduced Yankee Swap mechanism, that can be adapted to compute a variety of solution concepts, including leximin, max Nash welfare (MNW) and $p$-mean welfare maximizing allocations when $a$ divides $b$. This result is complemented by an existing result on the computational intractability of leximin and MNW allocations when $a$ does not divide $b$.  We further examine leximin and MNW allocations with respect to two well-known properties -- envy freeness and the maximin share guarantee. On envy freeness, we show that neither the leximin nor the MNW all
    
[^70]: LDMIC：基于学习的分布式多视图图像编码

    LDMIC: Learning-based Distributed Multi-view Image Coding. (arXiv:2301.09799v2 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2301.09799](http://arxiv.org/abs/2301.09799)

    LDMIC是一种基于学习的分布式多视图图像编码框架，通过独立编码器和联合上下文传输模块实现了全局视图间的相关性捕捉，对几何关系不敏感。

    LDMIC is a learning-based distributed multi-view image coding framework that captures global inter-view correlations through independent encoders and a joint context transfer module based on the cross-attention mechanism, which is insensitive to geometric relations.

    多视图图像压缩在3D相关应用中起着至关重要的作用。现有方法采用预测编码架构，需要联合编码压缩相应的视差和残差信息。这要求相机之间进行协作，并强制执行不同视图之间的极线几何约束，这使得在具有随机重叠视野的分布式相机系统中部署这些方法具有挑战性。同时，分布式源编码理论表明，可以通过独立编码和联合解码实现相关源的高效数据压缩，这激发了我们设计基于学习的分布式多视图图像编码（LDMIC）框架的动机。通过独立编码器，LDMIC引入了一个简单而有效的基于交叉注意机制的联合上下文传输模块，以有效捕捉全局视图间的相关性，对几何关系不敏感。

    Multi-view image compression plays a critical role in 3D-related applications. Existing methods adopt a predictive coding architecture, which requires joint encoding to compress the corresponding disparity as well as residual information. This demands collaboration among cameras and enforces the epipolar geometric constraint between different views, which makes it challenging to deploy these methods in distributed camera systems with randomly overlapping fields of view. Meanwhile, distributed source coding theory indicates that efficient data compression of correlated sources can be achieved by independent encoding and joint decoding, which motivates us to design a learning-based distributed multi-view image coding (LDMIC) framework. With independent encoders, LDMIC introduces a simple yet effective joint context transfer module based on the cross-attention mechanism at the decoder to effectively capture the global inter-view correlations, which is insensitive to the geometric relation
    
[^71]: 极端图像变换在人类和机器上产生不同影响

    Extreme Image Transformations Affect Humans and Machines Differently. (arXiv:2212.13967v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.13967](http://arxiv.org/abs/2212.13967)

    本文研究了一些极端的图像变换，发现机器和人类在这些变换下的表现差异较大，机器在某些变换下比人类表现更好，但在人类容易处理的变换下表现不如人类，同时提出了一些方法来改善机器的性能。

    

    一些最近的人工神经网络(ANN)声称模拟灵长类动物神经和人类的表现数据。然而，它们在对象识别方面的成功依赖于以人类不常采用的方式利用低级特征来解决视觉任务。因此，对于ANN来说，超出分布或对抗性输入经常具有挑战性。相反，人类学习抽象的模式，并且对许多极端图像畸变的影响很小。我们引入了一组新的图像变换，受神经生理学发现的启发，并在对象识别任务上评估了人类和ANN。我们表明，对于某些变换，机器的表现比人类更好，而对于某些对人类简单的变换，机器难以与人类表现相当。我们量化了人类和机器的准确性差异，并为我们的变换数据找到了一个难度排名。我们还建议如何改变人类视觉处理的某些特征以提高ANN的性能。

    Some recent artificial neural networks (ANNs) claim to model aspects of primate neural and human performance data. Their success in object recognition is, however, dependent on exploiting low-level features for solving visual tasks in a way that humans do not. As a result, out-of-distribution or adversarial input is often challenging for ANNs. Humans instead learn abstract patterns and are mostly unaffected by many extreme image distortions. We introduce a set of novel image transforms inspired by neurophysiological findings and evaluate humans and ANNs on an object recognition task. We show that machines perform better than humans for certain transforms and struggle to perform at par with humans on others that are easy for humans. We quantify the differences in accuracy for humans and machines and find a ranking of difficulty for our transforms for human data. We also suggest how certain characteristics of human visual processing can be adapted to improve the performance of ANNs for o
    
[^72]: 用于问题回答的动量对比预训练方法

    Momentum Contrastive Pre-training for Question Answering. (arXiv:2212.05762v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.05762](http://arxiv.org/abs/2212.05762)

    提出了一种用于抽取式问题回答的动量对比预训练方法，通过匹配填空式和自然查询-文章样本对的答案概率，能更好地将在填空式样本中学到的知识转移到回答自然问题上。

    

    现有的抽取式问答（QA）预训练方法生成类似于填空题的查询，其语法结构与自然语言问题不同，这可能会导致预训练模型对简单的关键词匹配过拟合。为了解决这个问题，我们提出了一种新的动量对比式预训练方法，即MCROSS（Momentum Contrastive pRe-training fOr queStion anSwering）用于抽取式的问题回答。具体来说，MCROSS引入了动量对比学习框架来匹配填空式和自然查询-文章样本对之间的答案概率。因此，预训练模型能够更好地将在填空式样本中学到的知识转移到回答自然问题上。在三个基准QA数据集上的实验结果表明，与所有基线方法相比，我们的方法在有监督和零-shot场景下均取得了显著的改进。

    Existing pre-training methods for extractive Question Answering (QA) generate cloze-like queries different from natural questions in syntax structure, which could overfit pre-trained models to simple keyword matching. In order to address this problem, we propose a novel Momentum Contrastive pRe-training fOr queStion anSwering (MCROSS) method for extractive QA. Specifically, MCROSS introduces a momentum contrastive learning framework to align the answer probability between cloze-like and natural query-passage sample pairs. Hence, the pre-trained models can better transfer the knowledge learned in cloze-like samples to answering natural questions. Experimental results on three benchmarking QA datasets show that our method achieves noticeable improvement compared with all baselines in both supervised and zero-shot scenarios.
    
[^73]: 迈向人类兼容自动驾驶汽车：情感过渡模型中的非语言图灵测试研究

    Towards human-compatible autonomous car: A study of non-verbal Turing test in automated driving with affective transition modelling. (arXiv:2212.02908v5 [cs.HC] UPDATED)

    [http://arxiv.org/abs/2212.02908](http://arxiv.org/abs/2212.02908)

    本文研究了自动驾驶汽车的人性化问题，通过非语言图灵测试，发现当前AI驾驶员不能创造类似人类的驾乘体验，需要在情感过渡模型中进行改进。

    

    当人类走向无需双手的生活方式时，自动驾驶汽车是不可或缺的。现有文献强调，如果自动驾驶汽车能够以类似人类的方式驾驶，人们会更容易接受它。然而，仅有少量研究从乘客角度的自然体验来检验目前的自动驾驶汽车是否具有类似人类的特征。本研究通过一项真实道路环境下的试验，测试了69位参与者的反馈，尝试了解AI驾驶人员能否为乘客创造类似人类的驾乘体验。我们设计了一种基于驾乘体验的非语言图灵测试，要求参与者作为乘客乘坐AI驾驶人员或人类驾驶人员驾驶的自动驾驶汽车，并判断司机是人类还是AI。结果显示，充当AI驾驶员的汽车未能通过我们的测试，因为乘客能够超过随机猜测地识别出AI驾驶员。相比之下，当人类驾驶员驾驶车辆时，乘客的判断结果约在随机猜测水平附近。我们进一步探讨了人类乘客在驾驶过程中给予了哪些人性化特征的归因。

    Autonomous cars are indispensable when humans go further down the hands-free route. Although existing literature highlights that the acceptance of the autonomous car will increase if it drives in a human-like manner, sparse research offers the naturalistic experience from a passenger's seat perspective to examine the human likeness of current autonomous cars. The present study tested whether the AI driver could create a human-like ride experience for passengers based on 69 participants' feedback in a real-road scenario. We designed a ride experience-based version of the non-verbal Turing test for automated driving. Participants rode in autonomous cars (driven by either human or AI drivers) as a passenger and judged whether the driver was human or AI. The AI driver failed to pass our test because passengers detected the AI driver above chance. In contrast, when the human driver drove the car, the passengers' judgement was around chance. We further investigated how human passengers ascri
    
[^74]: 基于查询的多模态路径融合知识库补全

    Query-Driven Knowledge Base Completion using Multimodal Path Fusion over Multimodal Knowledge Graph. (arXiv:2212.01923v2 [cs.DB] UPDATED)

    [http://arxiv.org/abs/2212.01923](http://arxiv.org/abs/2212.01923)

    基于查询的多模态路径融合算法可以有效地对知识库进行补全，提高了性能，并且使用了基于查询的技术来提高系统的效率。

    

    在过去的几年中，大型知识库已经被构建来存储大量的知识。然而，这些知识库高度不完整，例如Freebase中有70%的人没有出生地点。为了解决这个问题，我们提出了一个使用结构化和非结构化信息的多模态融合的、基于查询驱动的知识库补全系统。为了有效地融合来自Web的非结构化信息和知识库中的结构化信息以实现良好的性能，我们的系统基于问答和规则推理构建了多模态知识图。我们提出了一个多模态路径融合算法，在多模态知识图中基于不同的路径对候选答案进行排名，取得了比问答、规则推理和基线融合算法更好的性能。为了提高系统效率，我们使用了基于查询的技术来减少系统的运行时间，为用户查询提供快速响应。

    Over the past few years, large knowledge bases have been constructed to store massive amounts of knowledge. However, these knowledge bases are highly incomplete, for example, over 70% of people in Freebase have no known place of birth. To solve this problem, we propose a query-driven knowledge base completion system with multimodal fusion of unstructured and structured information. To effectively fuse unstructured information from the Web and structured information in knowledge bases to achieve good performance, our system builds multimodal knowledge graphs based on question answering and rule inference. We propose a multimodal path fusion algorithm to rank candidate answers based on different paths in the multimodal knowledge graphs, achieving much better performance than question answering, rule inference and a baseline fusion algorithm. To improve system efficiency, query-driven techniques are utilized to reduce the runtime of our system, providing fast responses to user queries. Ex
    
[^75]: 不完整信息下的知识图谱质量评估

    Knowledge Graph Quality Evaluation under Incomplete Information. (arXiv:2212.00994v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2212.00994](http://arxiv.org/abs/2212.00994)

    该论文提出一种不暴露原始数据的知识图谱质量评估框架，通过将质量评估任务转化为两个KG之间的对抗性问答游戏，解决现有方法高度依赖原始数据和更多考虑数据质量而非能力层面的缺陷。

    

    由于在许多任务中具有根本作用，知识图谱(KGs)越来越受到关注。因此，对KG的质量评估至关重要且不可或缺。然而，现有领域中的方法通过从不同的维度提出新的质量度量或在KG构建阶段衡量性能来评估KG。但是，这些方法存在两个主要问题。首先，它们高度依赖KG中的原始数据，这使得KG的内部信息在质量评估期间暴露出来。其次，它们更多地考虑数据层面的质量，而不是能力层面的质量，对于下游应用来说，后者更为重要。为了解决这些问题，我们提出了一个不完整信息下的知识图谱质量评估框架(QEII)。在评估过程中，不暴露任何原始数据，而将质量评估任务转化为两个KG之间的对抗性问答游戏。游戏胜者因此被认为具有更好的质量。

    Knowledge graphs (KGs) have attracted more and more attentions because of their fundamental roles in many tasks. Quality evaluation for KGs is thus crucial and indispensable. Existing methods in this field evaluate KGs by either proposing new quality metrics from different dimensions or measuring performances at KG construction stages. However, there are two major issues with those methods. First, they highly rely on raw data in KGs, which makes KGs' internal information exposed during quality evaluation. Second, they consider more about the quality at data level instead of ability level, where the latter one is more important for downstream applications. To address these issues, we propose a knowledge graph quality evaluation framework under incomplete information (QEII). The quality evaluation task is transformed into an adversarial Q&A game between two KGs. Winner of the game is thus considered to have better qualities. During the evaluation process, no raw data is exposed, which en
    
[^76]: 通过监督学习增强约束编程在作业车间调度中的应用

    Enhancing Constraint Programming via Supervised Learning for Job Shop Scheduling. (arXiv:2211.14492v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2211.14492](http://arxiv.org/abs/2211.14492)

    该论文提出了一种基于监督学习的变量排序策略，可根据不同问题实例的特征定制变量排序策略以提高约束编程的求解性能。实验表明，该方法具有高效性和高准确性。

    

    约束编程是解决约束满足和优化问题的一种有效技术。在约束编程求解器中，选取变量的顺序对求解器的有效性有重要影响。为了解决这个问题，我们提出了一种基于监督学习的变量排序策略，在作业车间调度问题的背景下对其进行评估。我们的学习方法使用问题实例的最优解来排序约束编程求解器中的变量，不同于传统的变量排序方法，我们的方法可以根据每个问题实例的特征进行学习，并相应地定制变量排序策略，从而提高求解器的性能。我们的实验表明，训练机器学习模型非常高效且具有高准确性。此外，我们学到的变量排序方法的性能表现也很优秀。

    Constraint programming (CP) is a powerful technique for solving constraint satisfaction and optimization problems. In CP solvers, the variable ordering strategy used to select which variable to explore first in the solving process has a significant impact on solver effectiveness. To address this issue, we propose a novel variable ordering strategy based on supervised learning, which we evaluate in the context of job shop scheduling problems. Our learning-based methods predict the optimal solution of a problem instance and use the predicted solution to order variables for CP solvers. \added[]{Unlike traditional variable ordering methods, our methods can learn from the characteristics of each problem instance and customize the variable ordering strategy accordingly, leading to improved solver performance.} Our experiments demonstrate that training machine learning models is highly efficient and can achieve high accuracy. Furthermore, our learned variable ordering methods perform competit
    
[^77]: 使用基于网络问答和多模态融合完成知识库

    Knowledge Base Completion using Web-Based Question Answering and Multimodal Fusion. (arXiv:2211.07098v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2211.07098](http://arxiv.org/abs/2211.07098)

    本文提出了一种使用基于网络问答和多模态融合的方法填补知识库中的缺失信息。通过设计一个多模态特征和问题模板的基于网络问答的系统来达到更高效的知识库补全，同时结合了知识库中的结构化信息来提高抽取质量。

    

    近年来，大型知识库已经建立来存储大量知识，然而这些知识库非常不完整。为了解决这个问题，我们提出一种使用基于网络问答和多模态融合的方法填补知识库中的缺失信息。为了利用网络上的非结构化信息完成知识库，我们设计了一个基于网络问答的系统，使用多模态特征和问题模板来提取缺失的事实，仅仅通过非常少的问题就可以达到良好的效果。同时，该问答系统还使用知识库中的结构化信息，比如实体类型和实体之间的关联性，以帮助提高抽取质量。

    Over the past few years, large knowledge bases have been constructed to store massive amounts of knowledge. However, these knowledge bases are highly incomplete. To solve this problem, we propose a web-based question answering system system with multimodal fusion of unstructured and structured information, to fill in missing information for knowledge bases. To utilize unstructured information from the Web for knowledge base completion, we design a web-based question answering system using multimodal features and question templates to extract missing facts, which can achieve good performance with very few questions. To help improve extraction quality, the question answering system employs structured information from knowledge bases, such as entity types and entity-to-entity relatedness.
    
[^78]: 一种可解释的机器学习系统来识别癫痫-间隙-损伤连续状态下的脑电图图案

    An Interpretable Machine Learning System to Identify EEG Patterns on the Ictal-Interictal-Injury Continuum. (arXiv:2211.05207v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.05207](http://arxiv.org/abs/2211.05207)

    该论文设计了一种可解释的深度学习模型，以预测ICU脑电监测中常见的6种脑波图案的存在，并提供高质量的解释和三种解释方法，这对于建立AI的信任和临床采用至关重要。

    

    在许多医学领域，人们呼吁在用于临床工作的机器学习系统中增加可解释性。在本文中，我们设计了一个可解释的深度学习模型，用于预测ICU脑电监测中常见的6种脑波图案（癫痫、LPD、GPD、LRDA、GRDA、其他）的存在。每个预测都配有一个高质量的解释，借助于专门的用户界面提供支持。此新型模型架构学习了一组原型示例（“原型”），并通过将新的EEG片段与这些原型进行比较来做出决策。这些原型可以是单类（仅与一个类相关）或双类（与两个类相关）。我们提出了三种主要的模型解释方法：1）使用全局结构保持方法，将1275维cEEG潜在特征映射到二维空间中，可视化癫痫-间隙-损伤连续状态，从而深入了解其高维结构。2）我们提出了一种交互式解释方法，使人类专家能够查询模型预测的不同方面，并以自然语言接收经过专家验证的解释。3）我们可视化了导致模型做出某个决策的输入的最重要特征，允许详细检查输入和输出之间的关系。总的来说，我们展示了解释性模型分类EEG图案和提供专家友好的解释的实用性，这两个方面对于建立AI的信任和临床采用至关重要。

    In many medical subfields, there is a call for greater interpretability in the machine learning systems used for clinical work. In this paper, we design an interpretable deep learning model to predict the presence of 6 types of brainwave patterns (Seizure, LPD, GPD, LRDA, GRDA, other) commonly encountered in ICU EEG monitoring. Each prediction is accompanied by a high-quality explanation delivered with the assistance of a specialized user interface. This novel model architecture learns a set of prototypical examples (``prototypes'') and makes decisions by comparing a new EEG segment to these prototypes. These prototypes are either single-class (affiliated with only one class) or dual-class (affiliated with two classes).  We present three main ways of interpreting the model: 1) Using global-structure preserving methods, we map the 1275-dimensional cEEG latent features to a 2D space to visualize the ictal-interictal-injury continuum and gain insight into its high-dimensional structure. 2
    
[^79]: 使用最小熵耦合的完美安全隐写术

    Perfectly Secure Steganography Using Minimum Entropy Coupling. (arXiv:2210.14889v3 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2210.14889](http://arxiv.org/abs/2210.14889)

    本文研究了完全安全的隐写术，并发现只有最小熵耦合过程才是最高效的，提出了高可伸缩性的完美安全隐写算法，具有实际应用价值。

    

    隐写术是将秘密信息编码到无害的内容中，以便对手无法意识到隐藏的含义的实践。本文针对隐写术的安全性进行了研究，并展示了如何使用最小熵耦合实现完全安全的隐写过程。此外，本文还证明了在所有完全安全的隐写过程中，仅仅是最小熵耦合的过程是最高效的。这些结果为实现具有实用性和高可伸缩性的完美安全保障的隐写算法提供了思路。

    Steganography is the practice of encoding secret information into innocuous content in such a manner that an adversarial third party would not realize that there is hidden meaning. While this problem has classically been studied in security literature, recent advances in generative models have led to a shared interest among security and machine learning researchers in developing scalable steganography techniques. In this work, we show that a steganography procedure is perfectly secure under Cachin (1998)'s information theoretic-model of steganography if and only if it is induced by a coupling. Furthermore, we show that, among perfectly secure procedures, a procedure is maximally efficient if and only if it is induced by a minimum entropy coupling. These insights yield what are, to the best of our knowledge, the first steganography algorithms to achieve perfect security guarantees with non-trivial efficiency; additionally, these algorithms are highly scalable. To provide empirical valid
    
[^80]: LittleBird：用于问答的更快更长Transformer

    LittleBird: Efficient Faster & Longer Transformer for Question Answering. (arXiv:2210.11870v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.11870](http://arxiv.org/abs/2210.11870)

    LittleBird是一个基于BigBird的问答模型，通过使用更灵活和高效的位置表示方法ALiBi和替换全局信息表示方法来提高速度和内存占用。它可以在短输入的预训练语言模型的基础上，对长输入进行工作并且在低资源的语言中表现良好。

    

    BERT在各种自然语言处理任务中都表现出了出色的成果。但由于其注意机制，它在处理长输入方面存在局限性。Longformer、ETC和BigBird解决了这个问题并有效地解决了二次依赖性问题。然而，我们发现这些模型并不足够，因此提出了LittleBird，它是基于BigBird的新型模型，具有更高的速度和更小的内存占用，同时保持准确性。特别是，我们设计了一种更灵活、更有效的位置表示方法，称为Attention with Linear Biases (ALiBi)。我们还表明，在BigBird中用于表示全局信息的方法可以替换为打包和解包注意力，这更有效。该模型可以在用于短输入的预训练语言模型的基础上，对长输入进行工作，并且可以重用现有的预训练语言模型来高效地训练短输入。这对于获取大量长文本数据困难的低资源语言而言是一个重要的优势。

    BERT has shown a lot of sucess in a wide variety of NLP tasks. But it has a limitation dealing with long inputs due to its attention mechanism. Longformer, ETC and BigBird addressed this issue and effectively solved the quadratic dependency problem. However we find that these models are not sufficient, and propose LittleBird, a novel model based on BigBird with improved speed and memory footprint while maintaining accuracy. In particular, we devise a more flexible and efficient position representation method based on Attention with Linear Biases (ALiBi). We also show that replacing the method of global information represented in the BigBird with pack and unpack attention is more effective. The proposed model can work on long inputs even after being pre-trained on short inputs, and can be trained efficiently reusing existing pre-trained language model for short inputs. This is a significant benefit for low-resource languages where large amounts of long text data are difficult to obtain.
    
[^81]: 通过学习概念的逻辑组合，全局解释GNNs

    Global Explainability of GNNs via Logic Combination of Learned Concepts. (arXiv:2210.07147v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.07147](http://arxiv.org/abs/2210.07147)

    本文提出了全局逻辑GNN解释器GLGExplainer，它是第一个能够以任意布尔组合的形式生成GNN学习的图形概念的解释器。GLGExplainer提供了准确可解释的全局解释，与GNN的组合性质相一致，并可应用于任何图分类或回归问题。

    

    虽然GNN的实例级解释是一个被广泛研究的问题，并且已经开发了很多方法，但是提供GNN行为的全局解释却很少被探讨，尽管它在可解释性和调试方面具有潜力。现有的解决方案要么仅列出给定类别的局部解释，要么生成一个具有给定类别最大分数的合成原型图，完全忽略了GNN可能已经学习的任何组合性方面。在这项工作中，我们提出了GLGExplainer（基于全局逻辑的GNN解释器），它是第一个能够生成学习过的图形概念的任意布尔组合的解释的全局解释器。GLGExplainer是一个全可微架构，它以局部解释作为输入，并将它们组合成基于图形概念的逻辑公式，表示为局部解释的集群。与现有解决方案相反，GLGExplainer提供了准确和人类可解释的全局解释，与GNN的组合性质相一致，并可应用于任何图分类或回归问题。我们在多个基准数据集上展示了GLGExplainer的有效性，在其中几个数据集上实现了最先进的性能。

    While instance-level explanation of GNN is a well-studied problem with plenty of approaches being developed, providing a global explanation for the behaviour of a GNN is much less explored, despite its potential in interpretability and debugging. Existing solutions either simply list local explanations for a given class, or generate a synthetic prototypical graph with maximal score for a given class, completely missing any combinatorial aspect that the GNN could have learned. In this work, we propose GLGExplainer (Global Logic-based GNN Explainer), the first Global Explainer capable of generating explanations as arbitrary Boolean combinations of learned graphical concepts. GLGExplainer is a fully differentiable architecture that takes local explanations as inputs and combines them into a logic formula over graphical concepts, represented as clusters of local explanations. Contrary to existing solutions, GLGExplainer provides accurate and human-interpretable global explanations that are
    
[^82]: 时间注意力单元：面向高效时空预测学习的方法研究

    Temporal Attention Unit: Towards Efficient Spatiotemporal Predictive Learning. (arXiv:2206.12126v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2206.12126](http://arxiv.org/abs/2206.12126)

    本研究提出了时间注意力单元（TAU）以提高时空预测学习的计算效率，将时间注意力分解为帧内静态注意力和帧间动态注意力。同时引入差分离散正则化方法来考虑帧间变化，大量实验表明该方法能够高效地进行预测学习。

    

    时空预测学习旨在通过学习历史帧来生成未来帧。本文研究了现有方法，并提出了一个通用的时空预测学习框架，其中空间编码器和解码器捕捉帧内特征，中间的时间模块捕捉帧间相关性。虽然主流方法采用递归单元来捕获长期时间依赖关系，但由于无法并行化的体系结构，它们的计算效率低下。为了并行化时间模块，我们提出了时间注意力单元（TAU），将时间注意力分解为帧内静态注意力和帧间动态注意力。此外，虽然均方误差损失侧重于帧内误差，但我们引入了一种新的差分离散正则化方法，考虑帧间变化。大量实验表明，所提出的方法使派生模型可以高效地进行预测学习。

    Spatiotemporal predictive learning aims to generate future frames by learning from historical frames. In this paper, we investigate existing methods and present a general framework of spatiotemporal predictive learning, in which the spatial encoder and decoder capture intra-frame features and the middle temporal module catches inter-frame correlations. While the mainstream methods employ recurrent units to capture long-term temporal dependencies, they suffer from low computational efficiency due to their unparallelizable architectures. To parallelize the temporal module, we propose the Temporal Attention Unit (TAU), which decomposes the temporal attention into intra-frame statical attention and inter-frame dynamical attention. Moreover, while the mean squared error loss focuses on intra-frame errors, we introduce a novel differential divergence regularization to take inter-frame variations into account. Extensive experiments demonstrate that the proposed method enables the derived mode
    
[^83]: 无欺骗性基于扰动的事后解释器

    Unfooling Perturbation-Based Post Hoc Explainers. (arXiv:2205.14772v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2205.14772](http://arxiv.org/abs/2205.14772)

    本文介绍了一种检测和防御扰动基础解释器的恶意攻击的方法，并在图像分类任务上进行了实验验证。该方法提供了对人工智能系统的可靠性和信任性的保障。

    

    人工智能技术的巨大进步吸引了医生、贷款人、法官和其他专业人员的关注。然而，熟悉人工智能系统的人对其决策过程缺乏透明度表示担忧。扰动基础事后解释器提供了一种对这些系统进行解释的方法，只需要查询级别访问权限即可解释任何模型。然而，最近的研究表明，这些解释器可以被恶意攻击。这一发现对审计员、监管机构和其他监督者产生了严重影响。因此，几个自然问题显而易见——我们如何审计这些黑匣子系统？我们如何确定审计对象是否是真诚配合审计的？在这项工作中，我们严格规范了这个问题，并设计了一种抵御扰动基础解释器的恶意攻击的防御方法。我们提出了检测（CAD-Detect）和防御（CAD-Defense）算法。我们在图像分类任务上的实验表明，我们的方法不仅可以高精度地检测出恶意攻击，而且还可以有效地抵御它们。我们的工作为实现人工智能系统的可靠性和信任性提供了一步。

    Monumental advancements in artificial intelligence (AI) have lured the interest of doctors, lenders, judges, and other professionals. While these high-stakes decision-makers are optimistic about the technology, those familiar with AI systems are wary about the lack of transparency of its decision-making processes. Perturbation-based post hoc explainers offer a model agnostic means of interpreting these systems while only requiring query-level access. However, recent work demonstrates that these explainers can be fooled adversarially. This discovery has adverse implications for auditors, regulators, and other sentinels. With this in mind, several natural questions arise - how can we audit these black box systems? And how can we ascertain that the auditee is complying with the audit in good faith? In this work, we rigorously formalize this problem and devise a defense against adversarial attacks on perturbation-based explainers. We propose algorithms for the detection (CAD-Detect) and de
    
[^84]: CNN在学习图像块后避免了维数灾难

    CNNs Avoid Curse of Dimensionality by Learning on Patches. (arXiv:2205.10760v4 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2205.10760](http://arxiv.org/abs/2205.10760)

    本研究解释了卷积神经网络在图像分类上的泛化性能，认为CNN在学习图像块后避免了维数灾难，并提供了支持的定量和定性证据。

    

    尽管卷积神经网络（CNN）在许多计算机视觉任务中取得了成功并具有非凡的泛化性能，但目前为止，有关预测CNN泛化错误的尝试只限于事后分析。事先解释深度神经网络的泛化性能的理论大多忽略了卷积性方面，并且不指明CNN在计算机视觉任务（如图像分类，其中图像维数为数千）中为何能够似乎克服维数灾难。我们的工作试图在假设CNN在图像块的域上运作的情况下解释CNN在图像分类上的泛化性能。我们的工作是我们所知道的第一个为CNN的泛化误差推导先验误差界的工作，并我们提供了定量和定性证据支持我们的理论。我们的基于块的理论还为什么数据增强表现出可靠性提供了解释。

    Despite the success of convolutional neural networks (CNNs) in numerous computer vision tasks and their extraordinary generalization performances, several attempts to predict the generalization errors of CNNs have only been limited to a posteriori analyses thus far. A priori theories explaining the generalization performances of deep neural networks have mostly ignored the convolutionality aspect and do not specify why CNNs are able to seemingly overcome curse of dimensionality on computer vision tasks like image classification where the image dimensions are in thousands. Our work attempts to explain the generalization performance of CNNs on image classification under the hypothesis that CNNs operate on the domain of image patches. Ours is the first work we are aware of to derive an a priori error bound for the generalization error of CNNs and we present both quantitative and qualitative evidences in the support of our theory. Our patch-based theory also offers explanation for why data
    
[^85]: 解读神经最小总和解码器

    Interpreting Neural Min-Sum Decoders. (arXiv:2205.10684v2 [cs.IT] UPDATED)

    [http://arxiv.org/abs/2205.10684](http://arxiv.org/abs/2205.10684)

    本文研究了在解码线性分组码中引入可学习参数到BP解码器中的方法，发现这些参数受到代码短周期分布的影响，学习权重的解码器比那些经过解析优化的权重具有更高的可靠性，并在复杂信道上有显著的帮助。

    

    在线性分组码的解码中，引入可学习参数到置信传播（BP）解码器中可以实现明显的可靠性增益。尽管这些方法取得成功，但有两个关键的未解决问题。第一个是对学习权重缺乏解释，另一个是对非AWGN信道缺乏分析。本文旨在通过提供对学习权重及其与基础码的结构的关系的见解来弥合这一差距。我们展示了权重受到代码短周期分布的严重影响。接下来，我们研究了这些解码器在非AWGN信道上的性能，包括合成信道和空中信道，并研究了复杂性与性能之间的权衡，证明增加参数数量可以在复杂信道上有显著的帮助。最后，我们展示了具有学习权重的解码器比那些经过解析优化的权重具有更高的可靠性。

    In decoding linear block codes, it was shown that noticeable reliability gains can be achieved by introducing learnable parameters to the Belief Propagation (BP) decoder. Despite the success of these methods, there are two key open problems. The first is the lack of interpretation of the learned weights, and the other is the lack of analysis for non-AWGN channels. In this work, we aim to bridge this gap by providing insights into the weights learned and their connection to the structure of the underlying code. We show that the weights are heavily influenced by the distribution of short cycles in the code. We next look at the performance of these decoders in non-AWGN channels, both synthetic and over-the-air channels, and study the complexity vs. performance trade-offs, demonstrating that increasing the number of parameters helps significantly in complex channels. Finally, we show that the decoders with learned weights achieve higher reliability than those with weights optimized analyti
    
[^86]: AutoMLBench：自动化机器学习框架的全面实验评估

    AutoMLBench: A Comprehensive Experimental Evaluation of Automated Machine Learning Frameworks. (arXiv:2204.08358v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2204.08358](http://arxiv.org/abs/2204.08358)

    本文对六种AutoML框架在100个数据集上进行了全面的实验比较，发现不同框架在不同性能指标方面各有优势和劣势，框架的选择应根据特定任务要求来进行。

    

    由于机器学习应用需求的迅速增长，已经意识到有足够知识的数据科学家的数量无法跟随数字世界中不断增长的数据量和应用需求而扩展。为满足这一需求，已经开发出了几种自动机器学习（AutoML）框架，通过自动化构建机器学习流程来填补人类专业知识的差距。每个框架都带有不同的基于启发式的设计决策。在本研究中，我们对六种流行的AutoML框架（AutoWeka、AutoSKlearn、TPOT、Recipe、ATM和SmartML）在来自已建立的AutoML基准套件的100个数据集上执行了全面的评估和比较。我们的实验评估考虑了不同方面的比较，包括多个设计决策的性能影响，如时间预算、搜索空间的大小、元学习和集成构建。我们的评估结果表明，每个AutoML框架在不同性能指标方面都有其优点和缺点，框架的选择可能取决于手头任务的特定要求。

    With the booming demand for machine learning applications, it has been recognized that the number of knowledgeable data scientists can not scale with the growing data volumes and application needs in our digital world. In response to this demand, several automated machine learning (AutoML) frameworks have been developed to fill the gap of human expertise by automating the process of building machine learning pipelines. Each framework comes with different heuristics-based design decisions. In this study, we present a comprehensive evaluation and comparison of the performance characteristics of six popular AutoML frameworks, namely, AutoWeka, AutoSKlearn, TPOT, Recipe, ATM, and SmartML, across 100 data sets from established AutoML benchmark suites. Our experimental evaluation considers different aspects for its comparison, including the performance impact of several design decisions, including time budget, size of search space, meta-learning, and ensemble construction. The results of our
    
[^87]: 多智能体学习中信条的重要性

    The Importance of Credo in Multiagent Learning. (arXiv:2204.07471v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2204.07471](http://arxiv.org/abs/2204.07471)

    本论文提出了一个针对多智能体学习的信条模型，可以促使智能体为它所属的团队打造优化行为的方式。研究表明，即使队友或整个系统的利益不一定完全一致，也能实现全局有益的结果。

    

    我们提出了一个针对多目标优化的模型，也就是叫做信条，用于系统中配置成多个小组（即团队）的智能体。信条模型规范了智能体为它所属的团队优化其行为的方式。我们使用强化学习智能体在挑战性的社会困境中评估信条。我们的结果表明，即使队友或整个系统的利益不一定完全一致，也能实现全局有益的结果。我们确定了两种没有完全共同利益的场景，这些场景实现了高平等和显著高于所有智能体利益一致的平均人口奖励。

    We propose a model for multi-objective optimization, a credo, for agents in a system that are configured into multiple groups (i.e., teams). Our model of credo regulates how agents optimize their behavior for the groups they belong to. We evaluate credo in the context of challenging social dilemmas with reinforcement learning agents. Our results indicate that the interests of teammates, or the entire system, are not required to be fully aligned for achieving globally beneficial outcomes. We identify two scenarios without full common interest that achieve high equality and significantly higher mean population rewards compared to when the interests of all agents are aligned.
    
[^88]: 宽量子神经网络动力学的分析理论

    Analytic theory for the dynamics of wide quantum neural networks. (arXiv:2203.16711v3 [quant-ph] UPDATED)

    [http://arxiv.org/abs/2203.16711](http://arxiv.org/abs/2203.16711)

    本研究分析了训练误差的梯度下降动态，提出了一个简单的分析公式，可以捕捉到宽量子神经网络损失函数的平均行为。我们预测并表征了随机量子电路残余训练误差作为系统参数的指数衰减。

    

    参数量子电路可用作量子神经网络，并有潜力在解决学习问题时优于它们的经典对应物。迄今为止，大部分关于它们在实际问题上表现的结果是启发式的。特别是，对于量子神经网络的训练收敛率还没有完全理解。在这里，我们分析梯度下降的动态，研究一类可变量量子机器学习模型的训练误差。我们将宽量子神经网络定义为带有大量量子位和可变参数的参数化量子电路极限。我们然后发现了一个简单的分析公式，可以捕捉到它们损失函数的平均行为，并讨论了我们研究的结果的后果。例如，对于随机量子电路，我们预测并表征了残余训练误差作为系统参数的指数衰减。我们最终通过各种量子电路的数值模拟验证了我们的分析理论，并展示了与我们的预测一致的结果。

    Parameterized quantum circuits can be used as quantum neural networks and have the potential to outperform their classical counterparts when trained for addressing learning problems. To date, much of the results on their performance on practical problems are heuristic in nature. In particular, the convergence rate for the training of quantum neural networks is not fully understood. Here, we analyze the dynamics of gradient descent for the training error of a class of variational quantum machine learning models. We define wide quantum neural networks as parameterized quantum circuits in the limit of a large number of qubits and variational parameters. We then find a simple analytic formula that captures the average behavior of their loss function and discuss the consequences of our findings. For example, for random quantum circuits, we predict and characterize an exponential decay of the residual training error as a function of the parameters of the system. We finally validate our analy
    
[^89]: 零和神经符号并发随机博弈的策略合成

    Strategy Synthesis for Zero-Sum Neuro-Symbolic Concurrent Stochastic Games. (arXiv:2202.06255v5 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2202.06255](http://arxiv.org/abs/2202.06255)

    本文提出了神经符号并发随机博弈（NS-CSG）的建模形式，并针对具有 Borel 状态空间的 NS-CSG 类展示了零和折扣累积回报的价值函数的存在性和可测性。首次提出了可实施的值迭代（VI）和策略迭代（PI）算法，证明了算法的正确性，并验证了在基准 NS-CSG 中的有效性。

    

    结合神经网络和经典符号技术的神经符号人工智能方法越来越受到关注，需要正式的方法来推理其正确性。本文提出了一种新型的建模形式，称为神经符号并发随机博弈（NS-CSG），由在通过神经网络实现的感知机制观察到的共享连续状态环境中相互作用的概率有限状态代理组成。我们专注于具有 Borel 状态空间的 NS-CSG 类，证明了在对这类模型的组件施加分段常数限制的情况下，零和折扣累积回报的价值函数的存在性和可测性。为了计算值和合成策略，我们首次提出可实施的值迭代（VI）和策略迭代（PI）算法来解决类连续状态 CSG问题。这些需要对动力学下的环境的前像进行有限表示，我们通过测度论的标准技术来构造这个表示。我们证明了我们算法的正确性，并通过基准NS-CSG中的实验证明了它们的有效性。

    Neuro-symbolic approaches to artificial intelligence, which combine neural networks with classical symbolic techniques, are growing in prominence, necessitating formal approaches to reason about their correctness. We propose a novel modelling formalism called neuro-symbolic concurrent stochastic games (NS-CSGs), which comprise probabilistic finite-state agents interacting in a shared continuous-state environment observed through perception mechanisms implemented as neural networks (NNs). We focus on the class of NS-CSGs with Borel state spaces and prove the existence and measurability of the value function for zero-sum discounted cumulative rewards under piecewise-constant restrictions on the components of this class of models. To compute values and synthesise strategies, we present, for the first time, implementable value iteration (VI) and policy iteration (PI) algorithms to solve a class of continuous-state CSGs. These require a finite representation of the pre-image of the environm
    
[^90]: 通过专家引导的对称检测进行数据增强以提高离线强化学习的性能

    Data Augmentation through Expert-guided Symmetry Detection to Improve Performance in Offline Reinforcement Learning. (arXiv:2112.09943v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2112.09943](http://arxiv.org/abs/2112.09943)

    本文研究了一种通过专家引导的对称检测算法进行数据增强的方法来提高离线强化学习的性能，针对非确定性MDP提出了一种结合监督和无监督学习的检测算法，实验证明该方法在一组基准任务上明显提高了强化学习算法的性能。

    

    非确定性马尔可夫决策过程（MDP）的离线动态模型估计是一项非常困难的任务，它在很大程度上取决于学习阶段可用的数据。有时，模型的动态特性与当前状态和动作的某些变换是不变的。最近的研究表明，一种基于密度估计方法的专家引导流水线，如基于深度神经网络的归一化流，可有效检测确定性环境中的这种结构，包括类别和连续值。所获得的知识可以被利用来增强原始数据集，最终导致真实模型和学习模型之间的分布偏移减少。这种数据增强技术可以作为一个初步过程，在采用离线强化学习架构之前执行，提高其性能。在本研究中，我们将这种范例扩展到解决非确定性MDP，特别是1）我们提出了一种结合监督和无监督学习的检测算法来识别和利用对称性，2）我们展示了所提出的方法在一组基准任务上有效地提高了离线强化学习算法的性能。

    Offline estimation of the dynamical model of a Markov Decision Process (MDP) is a non-trivial task that greatly depends on the data available in the learning phase. Sometimes the dynamics of the model is invariant with respect to some transformations of the current state and action. Recent works showed that an expert-guided pipeline relying on Density Estimation methods as Deep Neural Network based Normalizing Flows effectively detects this structure in deterministic environments, both categorical and continuous-valued. The acquired knowledge can be exploited to augment the original data set, leading eventually to a reduction in the distributional shift between the true and the learned model. Such data augmentation technique can be exploited as a preliminary process to be executed before adopting an Offline Reinforcement Learning architecture, increasing its performance. In this work we extend the paradigm to also tackle non-deterministic MDPs, in particular, 1) we propose a detection 
    
[^91]: 无重复用户或上下文的基于评论的跨领域推荐中的领域解缠方法

    Review-Based Domain Disentanglement without Duplicate Users or Contexts for Cross-Domain Recommendation. (arXiv:2110.12648v3 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2110.12648](http://arxiv.org/abs/2110.12648)

    本文提出了一种使用评论文本来进行领域解缠的方法，使用三个文本分析模块，由单一领域判别器指引，并采用一种新的优化策略，提高了领域解缠的质量，并且扩展了编码网络从单个领域到多个领域。实验证明，该方法比现有方法更高效、稳健和可扩展。

    

    跨领域推荐在解决数据稀疏性和冷启动问题方面已经取得了良好的结果。尽管如此，现有方法仅专注于领域可共享信息（重叠用户或相同的上下文）用于知识转移，并且没有这样的要求就很难进行良好的泛化。为了解决这些问题，我们建议利用对大多数电子商务系统通用的评论文本。我们的模型（名为SER）使用三个文本分析模块，由单一领域判别器指导进行解缠表示学习。在这里，我们提出了一种新的优化策略，可以提高领域解缠的质量，并削弱源领域的不良信息。此外，我们将编码网络从单个领域扩展到多个领域，这已被证明对于基于评论的推荐系统非常强大。广泛的实验和消融研究表明，与现有方法相比，我们的方法高效、稳健且可扩展。

    A cross-domain recommendation has shown promising results in solving data-sparsity and cold-start problems. Despite such progress, existing methods focus on domain-shareable information (overlapped users or same contexts) for a knowledge transfer, and they fail to generalize well without such requirements. To deal with these problems, we suggest utilizing review texts that are general to most e-commerce systems. Our model (named SER) uses three text analysis modules, guided by a single domain discriminator for disentangled representation learning. Here, we suggest a novel optimization strategy that can enhance the quality of domain disentanglement, and also debilitates detrimental information of a source domain. Also, we extend the encoding network from a single to multiple domains, which has proven to be powerful for review-based recommender systems. Extensive experiments and ablation studies demonstrate that our method is efficient, robust, and scalable compared to the state-of-the-a
    
[^92]: 基于继承表示的强化学习中的时间抽象

    Temporal Abstraction in Reinforcement Learning with the Successor Representation. (arXiv:2110.05740v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2110.05740](http://arxiv.org/abs/2110.05740)

    本研究表明，基于状态访问模式对状态进行编码的继承表示（SR）可以被看作发现和使用时间抽象的自然基质，并且可以用于发现有助于进行暂时扩展探索或规划的选项。

    

    多层次的时间抽象是智能的一个重要特征。在强化学习中，这通常通过被称为选项的暂时性行动来建模。选项允许智能体在环境中进行预测并在不同的抽象层次上操作。然而，基于选项框架的方法通常从已知的合理选项集开始假设。当没有这种情况时，对于应该考虑哪些选项，没有明确的答案。本文认为，基于状态访问模式对状态进行编码的继承表示（SR）可以被视为发现和使用时间抽象的自然基质。为了支持我们的观点，我们从近期研究的全局视角出发，展示了如何使用SR发现有助于进行暂时扩展探索或规划的选项。我们将这些结果结合到一个完整的实验中，并在多个基准环境下进行了测试。

    Reasoning at multiple levels of temporal abstraction is one of the key attributes of intelligence. In reinforcement learning, this is often modeled through temporally extended courses of actions called options. Options allow agents to make predictions and to operate at different levels of abstraction within an environment. Nevertheless, approaches based on the options framework often start with the assumption that a reasonable set of options is known beforehand. When this is not the case, there are no definitive answers for which options one should consider. In this paper, we argue that the successor representation (SR), which encodes states based on the pattern of state visitation that follows them, can be seen as a natural substrate for the discovery and use of temporal abstractions. To support our claim, we take a big picture view of recent results, showing how the SR can be used to discover options that facilitate either temporally-extended exploration or planning. We cast these re
    

