# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Unleashing the Creative Mind: Language Model As Hierarchical Policy For Improved Exploration on Challenging Problem Solving.](http://arxiv.org/abs/2311.00694) | 本论文将大型语言模型（LLMs）作为层次策略，通过释放其创造潜力，探索多样化的问题解决策略。通过将LLMs分为领导者和执行者，领导者提供多种高级问题解决策略作为提示，执行者根据领导者的指引执行详细的问题解决过程，生成一组解决方案。 |
| [^2] | [On Task-personalized Multimodal Few-shot Learning for Visually-rich Document Entity Retrieval.](http://arxiv.org/abs/2311.00693) | 本文研究了在视觉丰富的文档实体检索任务中的个性化多模态少样本学习，解决了实体级别少样本情景的挑战。 |
| [^3] | [Improving Interpersonal Communication by Simulating Audiences with Language Models.](http://arxiv.org/abs/2311.00687) | 本论文提出了一个基于大型语言模型（LLM）模拟的框架，通过探索解决方案空间、生成沟通候选以及模拟受众反应，来改善人际沟通。通过评估八个涵盖人际沟通基本过程的场景，展示了该框架的有效性。 |
| [^4] | [Emergence of Collective Open-Ended Exploration from Decentralized Meta-Reinforcement Learning.](http://arxiv.org/abs/2311.00651) | 通过分布式元强化学习在开放式任务分布上训练的智能体展现了强大的集体探索能力，从而产生了复杂的合作行为。 |
| [^5] | [FAIRLABEL: Correcting Bias in Labels.](http://arxiv.org/abs/2311.00638) | FAIRLABEL是一种检测和纠正标签中偏见的算法，其目标是在保持高准确率的同时减少群体间的不平等影响。通过应用于合成数据集和基准数据集，验证结果显示FAIRLABEL在标签修正方面的正确率较基准模型提高了14.8%, 在不平等影响比率方面达到了54.2%的增长。 |
| [^6] | [A Bi-level Framework for Traffic Accident Duration Prediction: Leveraging Weather and Road Condition Data within a Practical Optimum Pipeline.](http://arxiv.org/abs/2311.00634) | 本研究提出了一个双层框架，利用气象和道路状况数据预测交通事故持续时间。通过多个机器学习模型和双模式方法，可以准确预测事故对交通的影响是短期还是长期，并确定事故的精确持续时间。 |
| [^7] | [Loss Modeling for Multi-Annotator Datasets.](http://arxiv.org/abs/2311.00619) | 该论文提出了一种通过利用多任务学习和基于损失的标签修正来学习多注释者数据的准确表示的方法。通过这种方法，可以有效地分离赞同和不赞同的注释，并且在单一或多注释者设置下改善预测性能。该方法还显示出对主观数据的额外标签噪声具有鲁棒性。 |
| [^8] | [Rethinking Variational Inference for Probabilistic Programs with Stochastic Support.](http://arxiv.org/abs/2311.00594) | 本文提出了一种新的变分推断方法SDVI，可以用于具有随机支持的概率编程。通过将程序分解为具有静态支持的子程序，并为每个子程序构建独立的变分指导，SDVI在推断性能方面取得了显著改进。 |
| [^9] | [Coop: Memory is not a Commodity.](http://arxiv.org/abs/2311.00591) | 本论文提出了一种名为Coop的方法，针对深度学习框架中的内存系统问题，通过驱逐连续张量和优化张量分配，以降低再材料化成本。 |
| [^10] | [Boosting Summarization with Normalizing Flows and Aggressive Training.](http://arxiv.org/abs/2311.00588) | 本文提出了FlowSUM，一个基于正则化流的变分编码器-解码器框架，用于改进Transformer-based摘要生成。通过利用正则化流进行灵活的潜在后向建模以及采用受控交替激进训练策略，FlowSUM显著提高了生成摘要的质量，并探讨了正则化流中的后向塌陷问题和相关影响因素，为相关研究提供了宝贵的洞察。 |
| [^11] | [Minimally Modifying a Markov Game to Achieve Any Nash Equilibrium and Value.](http://arxiv.org/abs/2311.00582) | 该论文研究了游戏修改问题，提出了一种最小修改马尔可夫博弈的方法，使得目标策略配置成为唯一的Nash均衡并具有特定价值范围，同时最小化修改成本。 |
| [^12] | [LLaVA-Interactive: An All-in-One Demo for Image Chat, Segmentation, Generation and Editing.](http://arxiv.org/abs/2311.00571) | LLaVA-Interactive是一个多模态人机交互的研究原型系统，通过视觉提示来对齐人类意图，实现了图像对话、分割、生成和编辑的多模态功能，具有高成本效益和广泛的应用潜力。 |
| [^13] | [Detecting Visual Cues in the Intensive Care Unit and Association with Patient Clinical Status.](http://arxiv.org/abs/2311.00565) | 在重症监护室中开发能够检测视觉线索并与患者临床状态关联的人工智能工具，可以提供更客观和详细的监测能力。 |
| [^14] | [Tackling the Abstraction and Reasoning Corpus (ARC) with Object-centric Models and the MDL Principle.](http://arxiv.org/abs/2311.00545) | 该论文介绍了一种以物体为中心的模型和MDL原则，用于解决抽象推理语料库（ARC）。通过学习到的模型可以进行预测和联合描述输入/输出对，在各种任务上展现了普适性。 |
| [^15] | [The Development of LLMs for Embodied Navigation.](http://arxiv.org/abs/2311.00530) | 本文概述了LLMs与具身智能在导航领域的共生关系，并评估了现有模型和数据集的优缺点。 |
| [^16] | [Learning impartial policies for sequential counterfactual explanations using Deep Reinforcement Learning.](http://arxiv.org/abs/2311.00523) | 本文提出了使用深度强化学习学习顺序可解释策略的无偏方法。该方法通过对分类器的输出概率进行奖励来减轻现有方法中可能导致偏向特定动作的策略的不希望属性。 |
| [^17] | [Efficient LLM Inference on CPUs.](http://arxiv.org/abs/2311.00502) | 本研究提出了一种在CPU上高效部署大型语言模型（LLMs）的方法，支持自动权重量化和优化内核，在流行的LLMs上展示了极高的推理效率。 |
| [^18] | [Intriguing Properties of Data Attribution on Diffusion Models.](http://arxiv.org/abs/2311.00500) | 本研究通过对扩散模型进行实验和分析，发现在数据归因方面，一些在理论上不合理的设计选择能够在实际中表现出比以前的方法更好的效果。这对于确保数据贡献者公平补偿或认可具有重要意义。 |
| [^19] | [Bayes-enhanced Multi-view Attention Networks for Robust POI Recommendation.](http://arxiv.org/abs/2311.00491) | 本文提出了一种贝叶斯增强的多视角注意力网络来解决POI推荐中不确定因素的问题，通过构建个人POI转换图、基于语义的POI图和基于距离的POI图来全面建模依赖关系，提高POI推荐的性能和鲁棒性。 |
| [^20] | [Dual Conditioned Diffusion Models for Out-Of-Distribution Detection: Application to Fetal Ultrasound Videos.](http://arxiv.org/abs/2311.00469) | 本论文提出了双重条件扩散模型（DCDM），用于胎儿超声视频中的外分布检测。该模型能够在存在高度结构相似性和大量内部变异性的背景下，对胎儿超声视频中的心脏视图进行检测，并拒绝类似的外分布样本。 |
| [^21] | [Leveraging Hyperbolic Embeddings for Coarse-to-Fine Robot Design.](http://arxiv.org/abs/2311.00462) | 本文提出了一种新的多细胞机器人粗细设计方法，利用双曲嵌入框架在共享的双曲空间内统一了各种粒度的机器人，并通过改进的交叉熵方法进行优化。这种方法能够自主地在双曲空间中确定探索的区域。 |
| [^22] | [On the Opportunities of Green Computing: A Survey.](http://arxiv.org/abs/2311.00447) | 这项调查总结了绿色计算领域的技术，旨在解决人工智能计算资源和环境影响的挑战。 |
| [^23] | [A Systematic Comparison of Syllogistic Reasoning in Humans and Language Models.](http://arxiv.org/abs/2311.00445) | 这项研究通过对比人类和语言模型在三段论推理中的表现，发现较大的语言模型更合逻辑，甚至比人类更合逻辑，但即使最大的语言模型也会出现与人类推理类似的错误，总体上认为语言模型在某些情况下能够克服人类偏见。 |
| [^24] | [Improving Robustness for Vision Transformer with a Simple Dynamic Scanning Augmentation.](http://arxiv.org/abs/2311.00441) | 通过Dynamic Scanning Augmentation增强技术，提高了Vision Transformer的准确性和鲁棒性，尤其是在面对对抗攻击时。这种方法适应性地聚焦于不同的图像块，并改变了ViT的注意力机制。 |
| [^25] | [Enhanced Generalization through Prioritization and Diversity in Self-Imitation Reinforcement Learning over Procedural Environments with Sparse Rewards.](http://arxiv.org/abs/2311.00426) | 本研究通过优先级排序和多样性来提高自我模仿强化学习在过程化环境中的泛化能力。 |
| [^26] | [Neural Implicit Field Editing Considering Object-environment Interaction.](http://arxiv.org/abs/2311.00425) | 本论文提出了一种考虑物体和场景环境交互的神经隐式场编辑方法，通过内在分解方法成功地分离了物体和场景环境之间的交互，实现了合理的场景外观编辑效果。 |
| [^27] | [Couples can be tractable: New algorithms and hardness results for the Hospitals / Residents problem with Couples.](http://arxiv.org/abs/2311.00405) | 本研究提出了一种新的多项式时间算法，用于解决带夫妻的医院/居民问题，并证明了算法的多项式时间可解性以及对稳定B匹配问题的应用。算法能够找到一个接近可行的稳定匹配，并应用于不同类型的实例。 |
| [^28] | [A Spatial-Temporal Transformer based Framework For Human Pose Assessment And Correction in Education Scenarios.](http://arxiv.org/abs/2311.00401) | 本文提出了一种基于时空变换器的框架（STTF），用于教育场景中的人体姿势评估和修正。框架包括骨骼跟踪、姿势估计、姿势评估和姿势修正模块，能够提供专业、快速修正的反馈，并通过视觉辅助的形式提供修正性反馈。实验证明，该框架能够有效评估学生行为的质量并进行点评。 |
| [^29] | [Augmenting deep neural networks with symbolic knowledge: Towards trustworthy and interpretable AI for education.](http://arxiv.org/abs/2311.00393) | 这项研究旨在通过神经-符号AI框架，在教育应用中解决难以整合符号教育知识、学习偏见和缺乏解释性等问题，并开发了一种名为NSAI的方法。 |
| [^30] | [Will Code Remain a Relevant User Interface for End-User Programming with Generative AI Models?.](http://arxiv.org/abs/2311.00382) | 这篇论文探讨了生成式人工智能对终端用户编程的影响，提出了生成转变假设，并讨论了传统编程语言对非专业终端用户程序员仍然具有相关性的原因和可能性。 |
| [^31] | [Architecture of Data Anomaly Detection-Enhanced Decentralized Expert System for Early-Stage Alzheimer's Disease Prediction.](http://arxiv.org/abs/2311.00373) | 这项研究引入了一种突破性的分散专家系统，利用区块链技术和人工智能，结合了强大的异常检测和MRI分析，在早期阿尔茨海默病预测方面取得了重要的创新和贡献。 |
| [^32] | [Prompt-based Logical Semantics Enhancement for Implicit Discourse Relation Recognition.](http://arxiv.org/abs/2311.00367) | 本文提出了一种基于提示的逻辑语义增强（PLSE）方法来改进隐含篇章关系识别（IDRR），通过无缝地将与篇章关系相关的知识注入到预训练语言模型中，从而提高IDRR的性能和稳健性。 |
| [^33] | [Rethinking Samples Selection for Contrastive Learning: Mining of Potential Samples.](http://arxiv.org/abs/2311.00358) | 这篇论文重新思考了对比学习中的样本选择方法，从而提出了一种更全面的方法，通过综合考虑正负样本，利用数据增强和数据挖掘挖掘潜在样本，并且分析负样本梯度，最终获得了较好的效果。 |
| [^34] | [QFree: A Universal Value Function Factorization for Multi-Agent Reinforcement Learning.](http://arxiv.org/abs/2311.00356) | 提出了一种通用的QFree价值函数分解方法，用于提取多智能体强化学习中的最优去中心化策略，并遵循个体-全局最大原则。 |
| [^35] | [A Definition of Open-Ended Learning Problems for Goal-Conditioned Agents.](http://arxiv.org/abs/2311.00344) | 本文为开放式学习问题定义了一个关键的基本属性，即无限时间内不断产生新元素。在这基础上，提出了开放式学习问题的概念，并着重研究了开放式目标条件强化学习的子集。 |
| [^36] | [MetisFL: An Embarrassingly Parallelized Controller for Scalable & Efficient Federated Learning Workflows.](http://arxiv.org/abs/2311.00334) | MetisFL是一种可扩展和高效的联邦学习系统，重点关注联邦控制器的可扩展性和优化。 |
| [^37] | [Robust Graph Clustering via Meta Weighting for Noisy Graphs.](http://arxiv.org/abs/2311.00322) | 该论文提出了一种鲁棒的基于元权重的图聚类方法，通过对节点对应权重的自适应调整，能够在存在噪声边的图中找到有意义的聚类。 |
| [^38] | [Unsupervised Lexical Simplification with Context Augmentation.](http://arxiv.org/abs/2311.00310) | 我们提出了一种无监督的词汇简化方法，使用单语数据和预训练语言模型，通过生成替代词来简化给定目标词与其上下文，实验证明我们的模型在多个语言上优于其他无监督系统，并在SWORDS数据集上取得了最先进的结果。 |
| [^39] | [From Image to Language: A Critical Analysis of Visual Question Answering (VQA) Approaches, Challenges, and Opportunities.](http://arxiv.org/abs/2311.00308) | 本论文调查了视觉问答(VQA)领域的现有研究，包括传统VQA架构和现代基于视觉语言预训练(VLP)的方法。同时还分析了VQA数据集和方法在历史上的发展，揭示了VLP在VQA中的挑战与机会，为进一步研究提供了指导。 |
| [^40] | [Inference of CO2 flow patterns -- a feasibility study.](http://arxiv.org/abs/2311.00290) | 研究对地下CO2泄漏进行监测和检测，提出了一种新的方法来描述CO2流动模式中的不确定性，并强调不确定性评估的重要性。 |
| [^41] | [Active Instruction Tuning: Improving Cross-Task Generalization by Training on Prompt Sensitive Tasks.](http://arxiv.org/abs/2311.00288) | 本文提出了基于提示不确定性的主动指令调优方法，通过选择信息丰富的任务并主动调整模型，提高了跨任务泛化能力。 |
| [^42] | [Knowledge-Infused Prompting: Assessing and Advancing Clinical Text Data Generation with Large Language Models.](http://arxiv.org/abs/2311.00287) | 本文提出了一种通过大型语言模型进行临床文本生成的创新方法ClinGen，该方法将外部领域特定的知识和语言模型结合起来，提高了临床自然语言处理任务的性能，并丰富了样本的多样性。 |
| [^43] | [JADE: A Linguistic-based Safety Evaluation Platform for LLM.](http://arxiv.org/abs/2311.00286) | JADE是一种基于语言分析的LLM安全评估平台，能够破坏广泛使用的中文和英文LLM，并生成高度威胁的不安全问题。 |
| [^44] | [Re-Scoring Using Image-Language Similarity for Few-Shot Object Detection.](http://arxiv.org/abs/2311.00278) | 本文提出了一种基于图像-语言相似度的重新评分方法，用于少样本目标检测。通过使用Contrastive Language-Image Pre-training (CLIP)和背景负面重新缩放损失 (BNRL)等方法，扩展了Faster R-CNN，在低数据设置下能够更好地适应一般化少样本目标检测数据集。实验结果在MS-COCO和PASCAL VOC上验证了该方法的有效性。 |
| [^45] | [ChatCoder: Chat-based Refine Requirement Improves LLMs' Code Generation.](http://arxiv.org/abs/2311.00272) | ChatCoder是一种通过与大规模语言模型聊天来帮助人类用户细化需求的方法，改进了现有大规模语言模型的代码生成性能。 |
| [^46] | [Rethinking Decision Transformer via Hierarchical Reinforcement Learning.](http://arxiv.org/abs/2311.00267) | 这篇论文通过引入分层强化学习，重新思考了决策Transformer。他们提出了一个通用的序列建模框架，在该框架中，高层策略为当前状态提供理想提示，低层策略在给定提示的条件下生成动作。他们发现决策Transformer是这个框架的一个特例，并研究了如何共同优化高层和低层策略以实现拼接能力，从而推动了新的离线学习算法的发展。 |
| [^47] | [Plug-and-Play Policy Planner for Large Language Model Powered Dialogue Agents.](http://arxiv.org/abs/2311.00262) | 基于大型语言模型的对话代理的即插即用策略规划器(PDDPP)引入了一种新的对话策略规划范式，通过可调整的语言模型插件实现主动对话问题的策略制定。利用监督微调和强化学习，该框架在处理新的案例时具有较高的灵活性和性能。 |
| [^48] | [Implicit biases in multitask and continual learning from a backward error analysis perspective.](http://arxiv.org/abs/2311.00235) | 本论文使用反向误差分析计算了多任务和连续学习设置下神经网络的隐式训练偏差。在训练过程中，通过引入修改损失函数，隐式最小化了原始损失、引入了隐式平坦正则项和冲突项。在多任务中，冲突项衡量了任务梯度之间的对齐性；而在连续学习中，冲突项是深度学习优化中的一个新概念，它通过任务梯度之间的李括号来衡量。 |
| [^49] | [StableFDG: Style and Attention Based Learning for Federated Domain Generalization.](http://arxiv.org/abs/2311.00227) | 本文提出了StableFDG，一种基于风格和注意力的学习策略，用于实现联邦领域泛化。其中，基于风格的学习将每个客户端的本地数据集中的样式扩展到原始源域之外，并通过风格共享、转移和探索策略改进了领域多样性。基于注意力的特征突出器捕捉了数据样本特征之间的相似性。 |
| [^50] | [Domain decomposition-based coupling of physics-informed neural networks via the Schwarz alternating method.](http://arxiv.org/abs/2311.00224) | 本文以物理信息神经网络(PINN)为基础，通过域分解和Schwarz交替法耦合PINN与彼此和传统数值模型，以加速训练和解决非线性偏微分方程(PDEs)中的困难问题。 |
| [^51] | [Can Large Language Models Capture Public Opinion about Global Warming? An Empirical Assessment of Algorithmic Fidelity and Bias.](http://arxiv.org/abs/2311.00217) | 本研究评估了大型语言模型（LLMs）的算法逼真性和偏见，并发现LLMs可以有效捕捉总统投票行为，但在准确表示全球变暖观点方面存在挑战。同时，LLMs对某些群体的观点估计存在偏差，特别是对非洲裔美国人对全球变暖的担忧低估。这些结果突出了LLMs在社会科学研究中的潜力，并强调了准确性的重要性。 |
| [^52] | [Consistent Video-to-Video Transfer Using Synthetic Dataset.](http://arxiv.org/abs/2311.00213) | 本研究提出一种基于合成数据集的视频到视频转换方法，通过文本指令实现高效编辑，并通过引入长视频采样校正确保一致性。在基于文本的视频到视频编辑方面取得了显著进展，为进一步的研究和应用提供了有趣的探索方向。 |
| [^53] | [Magmaw: Modality-Agnostic Adversarial Attacks on Machine Learning-Based Wireless Communication Systems.](http://arxiv.org/abs/2311.00207) | 本文提出了Magmaw，这是一种针对基于机器学习的无线通信系统进行模态不可知对抗攻击的黑盒攻击方法。它能够生成通用的对抗扰动，并引入了新的攻击目标。实验证实了其对现有防御方法的韧性。使用实时无线攻击平台进行了概念验证。 |
| [^54] | [ChatGPT-Powered Hierarchical Comparisons for Image Classification.](http://arxiv.org/abs/2311.00206) | 本文介绍了一种基于ChatGPT的层次比较方法，用于解决图像分类中的零样本开放词汇挑战。该方法通过递归地将类别进行分组，并在每个层次级别上比较图像与文本的嵌入，实现了直观、有效和可解释的图像分类。 |
| [^55] | [Continuous Training and Fine-tuning for Domain-Specific Language Models in Medical Question Answering.](http://arxiv.org/abs/2311.00204) | 本研究提出了一种连续训练和微调的方法，通过在中文医学数据上进行训练和微调，快速适应Llama 2基础模型到中文医学领域。实验结果表明，这种方法有效，生成的模型与GPT-3.5-turbo相媲美，但使用的计算资源更少。这为在不同领域进行大型语言模型的领域特定训练提供了一个模板。 |
| [^56] | [Modeling subjectivity (by Mimicking Annotator Annotation) in toxic comment identification across diverse communities.](http://arxiv.org/abs/2311.00203) | 本文通过模拟注释者的注释，跨多元社区模型主观性，以解决毒性评论识别的挑战。 |
| [^57] | [Federated Natural Policy Gradient Methods for Multi-task Reinforcement Learning.](http://arxiv.org/abs/2311.00201) | 本研究提出了一种多任务强化学习的联邦自然策略梯度方法，在分布式环境中，通过优化全局策略以最大化所有智能体的总奖励，实现协作决策。这些方法不受信息共享不完备的影响，且具有非渐近全局收敛保证。 |
| [^58] | [Large-Scale Multi-Robot Assembly Planning for Autonomous Manufacturing.](http://arxiv.org/abs/2311.00192) | 本论文提出了一个大规模多机器人组装规划的算法堆栈，可以在短时间内合成复杂装配的建造计划，并解决了移动自主机器人在制造中面临的挑战。 |
| [^59] | [XAI-CLASS: Explanation-Enhanced Text Classification with Extremely Weak Supervision.](http://arxiv.org/abs/2311.00189) | XAI-CLASS是一种解释增强的极弱监督文本分类方法，通过在训练过程中结合生成的伪标签的解释和单词的显著性，实现了在最小或没有人工注释的情况下进行文本分类。 |
| [^60] | [Robust Safety Classifier for Large Language Models: Adversarial Prompt Shield.](http://arxiv.org/abs/2311.00172) | 本研究介绍了对抗性提示屏蔽（APS）模型以及自动生成对抗性训练数据集的新策略。APS模型在检测准确性方面表现出色且具有韧性，并且BAND数据集可以增强安全分类器的鲁棒性。 |
| [^61] | [Beyond Denouncing Hate: Strategies for Countering Implied Biases and Stereotypes in Language.](http://arxiv.org/abs/2311.00161) | 本研究通过心理学和哲学文献提出六种挑战恶意语言刻板印象的策略，并通过人类和机器生成的对话数据集对其有效性进行比较。结果显示，人类编写的对话使用更具体的策略，而机器生成的对话使用较为普遍的策略。 |
| [^62] | [Score Normalization for a Faster Diffusion Exponential Integrator Sampler.](http://arxiv.org/abs/2311.00157) | 该论文提出了一种得分归一化方法，用于改进扩散指数积分器采样器的生成质量和减小积分误差。 |
| [^63] | [RIR-SF: Room Impulse Response Based Spatial Feature for Multi-channel Multi-talker ASR.](http://arxiv.org/abs/2311.00146) | 本研究引入了一种新颖的房间冲激响应（RIR）基于的空间特征RIR-SF，通过与已有的3D空间特征进行比较，表明RIR-SF在多通道多说话人ASR系统中表现优越，相对降低了21.3％的字符错误率（CER），并且对强混响具有鲁棒性。 |
| [^64] | [Two-Stage Classifier for Campaign Negativity Detection using Axis Embeddings: A Case Study on Tweets of Political Users during 2021 Presidential Election in Iran.](http://arxiv.org/abs/2311.00143) | 本文提出了一个混合模型，用于检测竞选活动的负面情绪，包括一个两阶段分类器，结合了两个机器学习模型的优势。通过对伊朗2021年总统选举期间50名政治用户的5,100条波斯语推文进行标注，建立了所需的数据集。 |
| [^65] | [Q-Learning for Stochastic Control under General Information Structures and Non-Markovian Environments.](http://arxiv.org/abs/2311.00123) | 该论文主要贡献是提出了一个对于非马尔可夫环境下的随机迭代（特别是Q-learning迭代）进行收敛的定理，并给出了收敛条件。其次，讨论了该定理在多种具有非马尔可夫环境的随机控制问题中的应用。 |
| [^66] | [Bandit-Driven Batch Selection for Robust Learning under Label Noise.](http://arxiv.org/abs/2311.00096) | 本研究提出了一种基于Bandit算法的批次选择方法，以改善在标签噪音下的学习过程。实验证明该方法在不同水平的标签污染下表现优于现有方法，且无需使用辅助神经网络模型。 |
| [^67] | [Expressive Modeling Is Insufficient for Offline RL: A Tractable Inference Perspective.](http://arxiv.org/abs/2311.00094) | 本文指出，在离线强化学习任务中，除了表达性强的序列模型，可处理性也起着重要的作用。由于离线数据收集策略和环境动态的随机性，需要精确且高效地回答各种概率查询，以找到有奖励的动作。基于此，本文提出了Trifle（离线强化学习的可处理推理）方法，利用现代可处理概率模型来解决这个问题。 |
| [^68] | [Safe multi-agent motion planning under uncertainty for drones using filtered reinforcement learning.](http://arxiv.org/abs/2311.00063) | 这篇论文提出了一种基于过滤强化学习的无人机安全多智能体运动规划方法，通过结合强化学习和约束控制技术，在不确定性环境中实现了安全性、实时性和高效性。 |
| [^69] | [The Generative AI Paradox: "What It Can Create, It May Not Understand".](http://arxiv.org/abs/2311.00059) | 生成型AI的悖论研究了生成型模型与人类智能之间的差异，模型在产生专家级输出的能力上可能超过其理解能力。 |
| [^70] | [Diversity and Diffusion: Observations on Synthetic Image Distributions with Stable Diffusion.](http://arxiv.org/abs/2311.00056) | 这项研究观察了文本到图像系统的进展，并发现只使用合成图像训练的分类器在推理时表现不佳，揭示了底层图像生成过程的局限性。 |
| [^71] | [SC-MIL: Sparsely Coded Multiple Instance Learning for Whole Slide Image Classification.](http://arxiv.org/abs/2311.00048) | 本文提出了SC-MIL模型，通过利用稀疏字典学习来同时改进特征嵌入和实例相关性建模，从而提高全切片图像分类的性能。 |
| [^72] | [Grounding Visual Illusions in Language: Do Vision-Language Models Perceive Illusions Like Humans?.](http://arxiv.org/abs/2311.00047) | 通过构建一个包含五种视觉幻觉的数据集，研究发现，尽管整体对齐性较低，但更大规模的视觉-语言模型更接近人类的感知并更容易受到视觉幻觉的影响。 |
| [^73] | [Enhancing the Spatial Awareness Capability of Multi-Modal Large Language Model.](http://arxiv.org/abs/2310.20357) | 本论文提出了一种改进多模态大语言模型空间意识能力的方法，通过利用精确的物体空间位置信息指导模型，在用户查询中提供更准确的响应。 |
| [^74] | [Breaking Language Barriers in Multilingual Mathematical Reasoning: Insights and Observations.](http://arxiv.org/abs/2310.20246) | 本文首次探索并训练了强大的多语言数学推理模型，通过使用翻译构建了多语言数据集，并提出了各种训练策略来构建强大的模型。实验证实发现在多语言训练中，将目标语言的翻译与原始语言的表示结合起来以及交替训练和多语言模型的自举可以提高模型的性能。此外，模型在处理低频词和长句子方面仍面临挑战。 |
| [^75] | [Learning to Discover Skills through Guidance.](http://arxiv.org/abs/2310.20178) | 提出了一种名为DISCO-DANCE的无监督技能发现算法，通过引导学习提高探索效果，并在具有挑战性的环境中优于其他方法。 |
| [^76] | [Decision-Making for Autonomous Vehicles with Interaction-Aware Behavioral Prediction and Social-Attention Neural Network.](http://arxiv.org/abs/2310.20148) | 本研究提出了一种自动驾驶车辆决策的行为模型，将驾驶员的互动意图编码为社交心理参数，并开发了基于优化的控制器和基于注意机制的神经网络架构来解决自动驾驶车辆在交通中的决策制定问题。 |
| [^77] | [SURF: A Generalization Benchmark for GNNs Predicting Fluid Dynamics.](http://arxiv.org/abs/2310.20049) | 提出了一个名为SURF的基准测试，用于评估和比较基于图的学习流体模拟器的泛化能力。SURF包括各种数据集和具体的性能和泛化度量指标。通过深入研究两种最先进的模型，我们证明了SURF的适用性。 |
| [^78] | [AI Alignment: A Comprehensive Survey.](http://arxiv.org/abs/2310.19852) | 本篇论文主要介绍了AI对齐的概念、方法和实践。研究围绕四个关键目标：健壮性、可解释性、可控性和道德性展开，并将其分为前向对齐和后向对齐两个部分。 AI对齐是为了构建符合人类意图和价值观的AI系统，并减轻由于系统不对齐带来的潜在风险。 |
| [^79] | [Improving Factual Consistency of Text Summarization by Adversarially Decoupling Comprehension and Embellishment Abilities of LLMs.](http://arxiv.org/abs/2310.19347) | 本文提出了一个名为DECENT的方法，通过对抗解耦LLMs的理解和修饰能力，提高文本摘要的事实一致性。同时，采用了一种探测技术来弥补训练过程中对真与假的敏感性不足的问题。 |
| [^80] | [CXR-LLaVA: Multimodal Large Language Model for Interpreting Chest X-ray Images.](http://arxiv.org/abs/2310.18341) | 本研究开发了一种用于解读胸部X射线图像的开源多模态大型语言模型（CXR-LLaVA），通过预训练图像编码器和对比语言-图像预训练将图像与放射学异常对齐，并使用GPT-4进行微调，实现了问题回答的功能。 |
| [^81] | [Will releasing the weights of large language models grant widespread access to pandemic agents?.](http://arxiv.org/abs/2310.18233) | 该研究调查了持续的语言模型权重扩散是否有可能帮助未来恶意行为者造成大规模死亡。通过组织一个黑客马拉松活动，研究者发现一些公开发布权重的模型在短时间内就被调整以去除保护机制，可能为恶意行为者获取关键信息提供了机会。 |
| [^82] | [Qilin-Med-VL: Towards Chinese Large Vision-Language Model for General Healthcare.](http://arxiv.org/abs/2310.17956) | Qilin-Med-VL是面向普遍医疗保健的中国大型视觉-语言模型，它结合了预训练的视觉Transformer和基础语言模型，通过两阶段课程训练过程提高了生成医疗标题和回答复杂医疗查询的能力，并发布了一个包含超过100万个图像-文本对的数据集ChiMed-VL。 |
| [^83] | [CodeFusion: A Pre-trained Diffusion Model for Code Generation.](http://arxiv.org/abs/2310.17680) | CodeFusion是一种预训练的代码生成模型，通过扩散的方式解决了自然语言代码生成中遇到的限制，实验表明其在准确率和多样性上优于最先进的自回归系统。 |
| [^84] | [FormaT5: Abstention and Examples for Conditional Table Formatting with Natural Language.](http://arxiv.org/abs/2310.17306) | FormaT5是一个基于转换器的模型，可以根据目标表格和自然语言描述生成数据相关的条件格式规则。为了解决描述不足的问题，FormaT5通过放弃目标的方式学习预测占位符。 |
| [^85] | [Dataset Bias Mitigation in Multiple-Choice Visual Question Answering and Beyond.](http://arxiv.org/abs/2310.14670) | 这项研究提出了一种解决多项选择视觉问答中数据集偏差的方法，包括不平衡匹配偏差和分心相似性偏差，并提出了对抗数据合成和样本内对立训练的技术来应对这些偏差。 |
| [^86] | [Sociotechnical Safety Evaluation of Generative AI Systems.](http://arxiv.org/abs/2310.11986) | 本文提出了一个三层框架，采用社会技术方法对生成型AI系统的安全风险进行评估。同时，评估现状调查发现了三个显著的评估差距，并提出了解决这些差距的方法。 |
| [^87] | ["Kelly is a Warm Person, Joseph is a Role Model": Gender Biases in LLM-Generated Reference Letters.](http://arxiv.org/abs/2310.09219) | 本文对LLM生成的推荐信中的性别偏见进行了细致的研究，并设计了评估方法来展现通过语言风格和词汇内容来体现的性别偏见。 |
| [^88] | [Conceptual Framework for Autonomous Cognitive Entities.](http://arxiv.org/abs/2310.06775) | 本文介绍了自主认知实体（ACE）模型，这是一个新型的认知架构框架，通过利用生成式人工智能技术，使机器和软件代理能够更加独立地运行。该模型包括六个层次，用于设置道德指南、制定全局策略、建立代理模型、执行功能、认知控制和任务执行。 |
| [^89] | [FABind: Fast and Accurate Protein-Ligand Binding.](http://arxiv.org/abs/2310.06763) | FABind是一个结合了口袋预测和对接的端到端模型，旨在实现快速准确的蛋白-配体结合预测。 |
| [^90] | [Query and Response Augmentation Cannot Help Out-of-domain Math Reasoning Generalization.](http://arxiv.org/abs/2310.05506) | 本文调查了在数学推理中使用数据增强的效果，并通过创建新的数据集和微调模型取得了显著成果。 |
| [^91] | [How Abilities in Large Language Models are Affected by Supervised Fine-tuning Data Composition.](http://arxiv.org/abs/2310.05492) | 本研究探讨了大规模语言模型在监督微调过程中，特别是数学推理和代码生成能力方面，数据组合的影响。实验结果显示，较大模型在相同数据量下表现出更好的性能，通过增加微调数据和模型参数，数学推理和代码生成能力得到显著提升。 |
| [^92] | [Automatic Anonymization of Swiss Federal Supreme Court Rulings.](http://arxiv.org/abs/2310.04632) | 该论文介绍了瑞士联邦最高法院裁决的自动化匿名化方法，通过利用大型数据集和领域内预训练模型，结果表明相比现有模型，使用领域内数据进一步提高了F1分数超过5%。这项工作展示了将现有的匿名化方法与机器学习相结合，可以减少人工劳动并增强自动建议的能力。 |
| [^93] | [Disentangling Voice and Content with Self-Supervision for Speaker Recognition.](http://arxiv.org/abs/2310.01128) | 本研究提出了一种利用自监督方法解离语音中的发音和内容的框架，用于说话人识别。实验证明该方法在VoxCeleb和SITW数据集上对EER和minDCF有明显的降低。 |
| [^94] | [CoinRun: Solving Goal Misgeneralisation.](http://arxiv.org/abs/2309.16166) | 本文介绍了通过使用ACE代理解决目标错误泛化中的CoinRun挑战，并展示了自主代理在新环境下可以在不使用新奖励信息的情况下，在关键情况下受人信任地行动。 |
| [^95] | [State-space Models with Layer-wise Nonlinearity are Universal Approximators with Exponential Decaying Memory.](http://arxiv.org/abs/2309.13414) | 本论文证明了堆叠具有逐层非线性激活的状态空间模型足以逼近任何连续的序列到序列关系，并且发现其加强了模型学习复杂序列模式的能力。然而，状态空间模型并不能根本解决指数衰减记忆的问题。 |
| [^96] | [Cross-tokamak Disruption Prediction based on Physics-Guided Feature Extraction and domain adaptation.](http://arxiv.org/abs/2309.05361) | 本文介绍了一种新颖的方法，使用少量放电预测未来托卡马克的破裂，并应用了物理引导特征提取和领域适应算法。这种方法在J-TEXT中取得了出色的破裂预测性能。 |
| [^97] | [Efficient Baselines for Motion Prediction in Autonomous Driving.](http://arxiv.org/abs/2309.03387) | 这项研究提出了自动驾驶中运动预测的高效基线模型，解决了使用地图和过去轨迹信息的实时应用复杂性和可解释性的问题。 |
| [^98] | [YaRN: Efficient Context Window Extension of Large Language Models.](http://arxiv.org/abs/2309.00071) | YaRN是一种高效的上下文窗口扩展方法，可以在大型语言模型中有效利用和推断比原始预训练允许的上下文长度更长的上下文，同时超越了之前的最新研究成果。 |
| [^99] | [CReHate: Cross-cultural Re-annotation of English Hate Speech Dataset.](http://arxiv.org/abs/2308.16705) | CReHate通过跨文化重新注释英语仇恨言论数据集，揭示了来自不同国家的个体对仇恨言论的不同看法，并引入了一种具有文化敏感性的分类器。这些发现强调了重新评估NLP研究在仇恨言论领域的必要性。 |
| [^100] | [Multivariate Time Series Anomaly Detection: Fancy Algorithms and Flawed Evaluation Methodology.](http://arxiv.org/abs/2308.13068) | 多元时间序列异常检测是一个研究领域，但目前存在组织不够有序和评估协议有缺陷的问题。文章评估了许多最近算法的性能，并指出了针对多元时间序列异常检测的评估协议存在的问题及如何缓解这些问题的方法。 |
| [^101] | [ALGAN: Time Series Anomaly Detection with Adjusted-LSTM GAN.](http://arxiv.org/abs/2308.06663) | 该论文提出了一种名为ALGAN的新型GAN模型，通过调整LSTM网络的输出，实现了在无监督设置下对单变量和多变量时间序列数据进行异常检测，并在实验中优于传统方法和其他GAN方法。 |
| [^102] | [Developmental Bootstrapping of AIs.](http://arxiv.org/abs/2308.04586) | 传统的符号AI方法和深度学习AI方法无法满足创建强大和可信赖的AI的挑战，然而，发展脱靴法通过模仿人类儿童的能力发展过程，为创建稳健可靠的AI提供了希望。 |
| [^103] | [The Impact of Imperfect XAI on Human-AI Decision-Making.](http://arxiv.org/abs/2307.13566) | 本研究通过一个混合方法用户研究，评估了不正确的解释如何影响人类的决策行为，以增进人工智能解释性对人工智能决策的理解。 |
| [^104] | [Optimized Network Architectures for Large Language Model Training with Billions of Parameters.](http://arxiv.org/abs/2307.12169) | 本文提出了一种优化的网络架构，用于训练拥有数十亿参数的大型语言模型。这个架构根据语言模型的通信需求，将集群分割成一组通过非阻塞高带宽互连的GPU集合，并通过轨道连接仅连接具有通信需求的GPU，从而降低网络成本高达75％，同时不影响训练性能。 |
| [^105] | [Decoding the Enigma: Benchmarking Humans and AIs on the Many Facets of Working Memory.](http://arxiv.org/abs/2307.10768) | 本论文介绍了一个全面的工作记忆基准数据集（WorM），通过评估4个功能、3个领域和11个行为和神经特征的WM任务来开发和评估AI WM模型。结果表明，AI模型能够模拟出脑中工作记忆的一些特征，如优势效应和最新性效应，以及专门用于不同领域和功能的工作记忆的神经群集和相关物。 |
| [^106] | [Meta-Learning Adversarial Bandit Algorithms.](http://arxiv.org/abs/2307.02295) | 本论文研究了具有波段反馈的在线元学习，并设计了用于多臂赌博机和赌博线性优化的元算法。对于多臂赌博机，算法使用了Tsallis-熵的泛化Exp3，并且任务平均遗憾会随着最优解的熵的减小而改善。对于赌博线性优化，算法使用了自协调障碍正则化器初始化和调整在线镜像下降，并且任务平均遗憾与动作空间相关的度量直接变化。 |
| [^107] | [NNQS-Transformer: an Efficient and Scalable Neural Network Quantum States Approach for Ab initio Quantum Chemistry.](http://arxiv.org/abs/2306.16705) | NNQS-Transformer是一种高效可扩展的神经网络量子态方法，用于从头计算量子化学。其主要创新包括基于Transformer的量子波函数安萨茨、数据中心并行化方案、并行批量采样策略和并行局域能量评估方案。研究结果显示了与最先进方法相比的优越精度和对于大分子系统的强可扩展性和弱可扩展性。 |
| [^108] | [To Spike or Not To Spike: A Digital Hardware Perspective on Deep Learning Acceleration.](http://arxiv.org/abs/2306.15749) | 神经形态计算旨在通过仿真脑部操作来提高深度学习模型的效率，但是在SNNs的高效硬件后端设计上仍需进一步研究。 |
| [^109] | [Tighter Prediction Intervals for Causal Outcomes Under Hidden Confounding.](http://arxiv.org/abs/2306.09520) | 本文提出了一种名为Caus-Modens的算法，通过调制集合来描述因果结果区间，相比符合性预测方法，能够在实践中给出更紧密的结果区间。 |
| [^110] | [Intrinsic Dimension Estimation for Robust Detection of AI-Generated Texts.](http://arxiv.org/abs/2306.04723) | 本文提出了衡量文本内部维度的方法，应用于鲁棒性AI生成文本的检测，展示了人类文本与AI生成文本在内部维度上的差异。 |
| [^111] | [Joint Learning of Label and Environment Causal Independence for Graph Out-of-Distribution Generalization.](http://arxiv.org/abs/2306.01103) | 本文提出了一种考虑标签和环境因果独立性的方法来解决图形超出分布（OOD）泛化问题，通过敌对训练策略来联合优化属性以获得有效结果，实验证明LECI显着优于之前的方法。 |
| [^112] | [Roots and Requirements for Collaborative AI.](http://arxiv.org/abs/2303.12040) | 论文探讨了AI协同合作的历史和要求，是协同AI研究的动机和背景。 |
| [^113] | [HDformer: A Higher Dimensional Transformer for Diabetes Detection Utilizing Long Range Vascular Signals.](http://arxiv.org/abs/2303.11340) | 本研究提出了一种新的基于高维Transformer的架构HDformer，并利用长距离PPG信号进行糖尿病检测，其中提出了一种新的注意力模块TSA，成功将标记体积减少10倍以上，提高了模型的能力和效率。 |
| [^114] | [Making Batch Normalization Great in Federated Deep Learning.](http://arxiv.org/abs/2303.06530) | 本文研究了在联邦学习中使用批标准化和群组归一化的效果，发现在适当的处理下，批标准化可以在广泛的联邦学习设置中具有很高的竞争力，而且这不需要额外的训练或通信成本。 |
| [^115] | [Population-based Evaluation in Repeated Rock-Paper-Scissors as a Benchmark for Multiagent Reinforcement Learning.](http://arxiv.org/abs/2303.03196) | 这项研究提出了一种基于重复剪刀石头布游戏的多Agent学习基准，展示了几种学习方法的泛化能力，为多Agent学习领域的研究提供了机会。 |
| [^116] | [Approximating Energy Market Clearing and Bidding With Model-Based Reinforcement Learning.](http://arxiv.org/abs/2303.01772) | 本文研究了基于模型的强化学习用于能源市场清算和出价的应用方法。通过用学习的OPF代理模型以及明确的市场规则替代传统计算方法，本方法极大地减少了训练时间并适用于市场设计和更现实地建模市场参与者。 |
| [^117] | [Learning Interpretable Low-dimensional Representation via Physical Symmetry.](http://arxiv.org/abs/2302.10890) | 通过使用物理对称性作为潜在空间的自洽约束条件，该研究展示了在音乐领域和计算机视觉领域，模型可以以无监督的方式学习出可解释的低维表示，例如线性音高和三维笛卡尔因素。 |
| [^118] | [A Neurodiversity-Inspired Solver for the Abstraction \& Reasoning Corpus (ARC) Using Visual Imagery and Program Synthesis.](http://arxiv.org/abs/2302.09425) | 本研究提出了一种基于神经多样性的新的人工智能方法，其中结合了人类心理想象能力中受到神经多样性研究启发的核心知识的视觉表示和基于树搜索的程序合成，在解决新任务时，能够灵活地组合核心知识来形成新的推理策略。 |
| [^119] | [LEXTREME: A Multi-Lingual and Multi-Task Benchmark for the Legal Domain.](http://arxiv.org/abs/2301.13126) | LEXTREME是一个多语言和多任务的法律领域基准，该基准提供了11个数据集涵盖24种语言的测评，最佳模型（XLM-R large）在数据集和语言综合评分上均达到了61.3。这使得LEXTREME仍然具有挑战性并且有改进空间。 |
| [^120] | [On Learning Necessary and Sufficient Causal Graphs.](http://arxiv.org/abs/2301.12389) | 本文提出了一种学习必要和充分因果图的方法，用于发现与感兴趣结果相关的因果关系。 |
| [^121] | [What Decreases Editing Capability? Domain-Specific Hybrid Refinement for Improved GAN Inversion.](http://arxiv.org/abs/2301.12141) | 这篇论文提出了面向特定领域的混合细化方法，用于改善GAN反演结果中的编辑能力减弱问题。该方法通过将图像分为域内和域外部分，并对这两部分进行权重调节细化，以保持域内区域的编辑能力并提高保真度。 |
| [^122] | [Rethinking Explaining Graph Neural Networks via Non-parametric Subgraph Matching.](http://arxiv.org/abs/2301.02780) | 本文通过提出一种非参数子图匹配框架MatchExplainer，可以解决图神经网络的解释性问题。此框架将目标图与其他实例结合起来，通过最小化节点对应的距离来鉴别最关键的联合子结构，并提出了一种新的增强范式MatchDrop来解决误报采样问题。 |
| [^123] | [Scaling Up Dataset Distillation to ImageNet-1K with Constant Memory.](http://arxiv.org/abs/2211.10586) | 本文提出了一种利用恒定内存需求扩展数据集精简的方法，可将Matching Training Trajectories（MTT）应用于ImageNet-1K数据集，达到6倍的内存降低，同时增加了约2%的运行时开销。同时也发现，为合成图像分配软标签对于实现良好的性能非常重要。 |
| [^124] | [A Survey on Explainable Reinforcement Learning: Concepts, Algorithms, Challenges.](http://arxiv.org/abs/2211.06665) | 该综述调查了可解释性强化学习方法，介绍了模型解释、奖励解释、状态解释和任务解释方法，并探讨了解释强化学习的概念、算法和挑战。 |
| [^125] | [Generalization Properties of NAS under Activation and Skip Connection Search.](http://arxiv.org/abs/2209.07238) | 本文研究了NAS在激活和跳跃连接搜索下的泛化性质，并提出了一种无需训练的基于理论的算法来选择性能最好的架构。 |
| [^126] | [Prioritizing Samples in Reinforcement Learning with Reducible Loss.](http://arxiv.org/abs/2208.10483) | 本文提出了一种在强化学习中基于可学习性的方法来优先选择样本，通过稳定降低样本的训练损失来定义样本的可学习性。实验证明，该方法相比于随机抽样和仅根据训练损失进行优先选择的方法更加稳健。 |
| [^127] | [On the Need and Applicability of Causality for Fair Machine Learning.](http://arxiv.org/abs/2207.04053) | 本论文探讨了因果关系在公平机器学习中的必要性和适用性，强调了非因果预测的社会影响和法律反歧视过程依赖于因果主张。同时讨论了在实际场景中应用因果关系所面临的挑战和限制，并提出了可能的解决方案。 |
| [^128] | [Independent and Decentralized Learning in Markov Potential Games.](http://arxiv.org/abs/2205.14590) | 独立的去中心化学习在马尔科夫潜在博弈中有效，通过更新Q函数可以引导策略收敛到稳定的纳什平衡点。 |
| [^129] | [SCORE: Spurious COrrelation REduction for Offline Reinforcement Learning.](http://arxiv.org/abs/2110.12468) | 本文提出了SCORE算法，用于离线强化学习中的虚假相关性降低。通过引入退火行为克隆正则化器，SCORE实现了SoTA性能，并消除了次优性中的虚假相关性。 |
| [^130] | [Corruption-robust exploration in episodic reinforcement learning.](http://arxiv.org/abs/1911.08689) | 该论文研究了强化学习中在奖励和转移概率两方面存在的对抗性腐败问题，并提出了一种能够解决腐败问题的高效算法，能够在没有腐败的情况下实现接近最优的后悔，并且能够适应未知水平的腐败。 |

# 详细

[^1]: 解放创造力：语言模型作为层次策略以改进挑战性问题解决的探索

    Unleashing the Creative Mind: Language Model As Hierarchical Policy For Improved Exploration on Challenging Problem Solving. (arXiv:2311.00694v1 [cs.AI])

    [http://arxiv.org/abs/2311.00694](http://arxiv.org/abs/2311.00694)

    本论文将大型语言模型（LLMs）作为层次策略，通过释放其创造潜力，探索多样化的问题解决策略。通过将LLMs分为领导者和执行者，领导者提供多种高级问题解决策略作为提示，执行者根据领导者的指引执行详细的问题解决过程，生成一组解决方案。

    

    大型语言模型（LLM）取得了巨大的进展，但仍然在具有挑战性的推理问题中往往遇到困难。目前的方法通过采样或搜索详细和低级的推理链来解决这个挑战。然而，这些方法在探索能力上仍然有限，使得正确的解决方案在庞大的解空间中很难突出。在这项工作中，我们通过将LLMs作为层次策略进行上下文学习，释放LLMs探索多样化问题解决策略的创造潜力。该策略包括一个有远见的领导者，提出多种多样的高级问题解决策略作为提示，并有一个执行者，根据每个高级指令执行详细的问题解决过程。执行者将领导者的每个指令作为指南，并采样多个推理链来解决问题，为每个领导者的提议生成一组解决方案。

    Large Language Models (LLMs) have achieved tremendous progress, yet they still often struggle with challenging reasoning problems. Current approaches address this challenge by sampling or searching detailed and low-level reasoning chains. However, these methods are still limited in their exploration capabilities, making it challenging for correct solutions to stand out in the huge solution space. In this work, we unleash LLMs' creative potential for exploring multiple diverse problem solving strategies by framing an LLM as a hierarchical policy via in-context learning. This policy comprises of a visionary leader that proposes multiple diverse high-level problem-solving tactics as hints, accompanied by a follower that executes detailed problem-solving processes following each of the high-level instruction. The follower uses each of the leader's directives as a guide and samples multiple reasoning chains to tackle the problem, generating a solution group for each leader proposal. Additio
    
[^2]: 个性化多模态少样本学习在视觉丰富的文档实体检索中的应用

    On Task-personalized Multimodal Few-shot Learning for Visually-rich Document Entity Retrieval. (arXiv:2311.00693v1 [cs.AI])

    [http://arxiv.org/abs/2311.00693](http://arxiv.org/abs/2311.00693)

    本文研究了在视觉丰富的文档实体检索任务中的个性化多模态少样本学习，解决了实体级别少样本情景的挑战。

    

    视觉丰富的文档实体检索(VDER)是一种从发票和收据等文档图像中提取关键信息(如日期、地址)的重要任务，在工业级自然语言处理应用中变得越来越重要。不断涌现的新的文档类型，每种类型都有其独特的实体类型，提出了一个独特的挑战：许多文档包含了仅出现几次的未知实体类型。解决这个挑战需要模型具有少样本学习实体的能力。然而，以前的少样本VDER工作主要在文档级别上解决了这个问题，使用预定义的全局实体空间，没有考虑到实体级别的少样本情景：目标实体类型由每个任务进行本地个性化，并且实体出现在文档中差异很大。为了解决这个未开发的情况，本文研究了一种新颖的实体级别少样本VDER任务。挑战在于每个任务的标签空间的唯一性和增长性。

    Visually-rich document entity retrieval (VDER), which extracts key information (e.g. date, address) from document images like invoices and receipts, has become an important topic in industrial NLP applications. The emergence of new document types at a constant pace, each with its unique entity types, presents a unique challenge: many documents contain unseen entity types that occur only a couple of times. Addressing this challenge requires models to have the ability of learning entities in a few-shot manner. However, prior works for Few-shot VDER mainly address the problem at the document level with a predefined global entity space, which doesn't account for the entity-level few-shot scenario: target entity types are locally personalized by each task and entity occurrences vary significantly among documents. To address this unexplored scenario, this paper studies a novel entity-level few-shot VDER task. The challenges lie in the uniqueness of the label space for each task and the incre
    
[^3]: 通过使用语言模型模拟受众群体，改善人际沟通

    Improving Interpersonal Communication by Simulating Audiences with Language Models. (arXiv:2311.00687v1 [cs.AI])

    [http://arxiv.org/abs/2311.00687](http://arxiv.org/abs/2311.00687)

    本论文提出了一个基于大型语言模型（LLM）模拟的框架，通过探索解决方案空间、生成沟通候选以及模拟受众反应，来改善人际沟通。通过评估八个涵盖人际沟通基本过程的场景，展示了该框架的有效性。

    

    我们如何与他人进行沟通以实现自己的目标？我们利用先前的经验或他人的建议，或者通过预测对方的反应来构造候选表达。然而，我们的经验是有限和有偏见的，而且对潜在结果进行推理可能是困难且认知上具有挑战性的。本文中，我们探讨了如何利用大型语言模型（LLM）模拟来帮助我们更好地沟通。我们提出了探索-生成-模拟（EGS）框架，该框架接受任何一个个体与一个目标受众进行沟通的场景作为输入。EGS（1）通过生成与场景相关的多样化建议来探索解决方案空间，（2）生成以部分建议为条件的沟通候选，（3）模拟不同受众的反应，以确定最佳候选和建议的使用。我们在涵盖人际沟通十个基本过程的八个场景上评估了该框架。

    How do we communicate with others to achieve our goals? We use our prior experience or advice from others, or construct a candidate utterance by predicting how it will be received. However, our experiences are limited and biased, and reasoning about potential outcomes can be difficult and cognitively challenging. In this paper, we explore how we can leverage Large Language Model (LLM) simulations to help us communicate better. We propose the Explore-Generate-Simulate (EGS) framework, which takes as input any scenario where an individual is communicating to an audience with a goal they want to achieve. EGS (1) explores the solution space by producing a diverse set of advice relevant to the scenario, (2) generates communication candidates conditioned on subsets of the advice, and (3) simulates the reactions from various audiences to determine both the best candidate and advice to use. We evaluate the framework on eight scenarios spanning the ten fundamental processes of interpersonal com
    
[^4]: 分布式元强化学习中的集体自发开放式探索的出现

    Emergence of Collective Open-Ended Exploration from Decentralized Meta-Reinforcement Learning. (arXiv:2311.00651v1 [cs.MA])

    [http://arxiv.org/abs/2311.00651](http://arxiv.org/abs/2311.00651)

    通过分布式元强化学习在开放式任务分布上训练的智能体展现了强大的集体探索能力，从而产生了复杂的合作行为。

    

    最近的研究证明，在自我对战的开放式任务分布中，通过使用元强化学习来训练的智能体可以产生复杂的合作行为。虽然结果令人印象深刻，但我们认为，自我对战和其他集中化训练技术并不能准确地反映自然界中普遍的集体探索策略是如何出现的：通过分布式训练和对任务的无限分布进行训练。因此，在这项工作中，我们研究了集体探索策略的出现，其中多个智能体在一个无限的任务分布中独立地元学习循环策略。为此，我们引入了一个新的环境，它具有一个无限的过程生成的任务空间，动态组合了从五种不同类型的任务中抽样的多个子任务，形成了一个庞大的任务树分布。我们展示了在我们的环境中训练的分散智能体在面对新的目标时展示出强大的泛化能力。

    Recent works have proven that intricate cooperative behaviors can emerge in agents trained using meta reinforcement learning on open ended task distributions using self-play. While the results are impressive, we argue that self-play and other centralized training techniques do not accurately reflect how general collective exploration strategies emerge in the natural world: through decentralized training and over an open-ended distribution of tasks. In this work we therefore investigate the emergence of collective exploration strategies, where several agents meta-learn independent recurrent policies on an open ended distribution of tasks. To this end we introduce a novel environment with an open ended procedurally generated task space which dynamically combines multiple subtasks sampled from five diverse task types to form a vast distribution of task trees. We show that decentralized agents trained in our environment exhibit strong generalization abilities when confronted with novel obj
    
[^5]: FAIRLABEL：修正标签中的偏见

    FAIRLABEL: Correcting Bias in Labels. (arXiv:2311.00638v1 [cs.LG])

    [http://arxiv.org/abs/2311.00638](http://arxiv.org/abs/2311.00638)

    FAIRLABEL是一种检测和纠正标签中偏见的算法，其目标是在保持高准确率的同时减少群体间的不平等影响。通过应用于合成数据集和基准数据集，验证结果显示FAIRLABEL在标签修正方面的正确率较基准模型提高了14.8%, 在不平等影响比率方面达到了54.2%的增长。

    

    有多种算法可以衡量机器学习模型的公平性。这些方法的一个基本假设是，真实数据是公平或无偏的。然而，在现实世界的数据集中，真实数据往往包含历史和社会偏见和歧视的数据。在这些数据集上训练的模型将继承并传播偏见到模型输出中。我们提出了一种名为FAIRLABEL的算法，用于检测和纠正标签中的偏见。FAIRLABEL的目标是在保持高准确率的同时减少群体间的不平等影响（DI）。我们提出了度量偏见修正质量的指标，并在合成数据集上验证了FAIRLABEL的正确性，结果表明标签修正的正确率为86.7%，而基准模型为71.9%。我们还将FAIRLABEL应用于UCI Adult、German Credit Risk和Compas数据集等基准数据集，结果显示不平等影响比率最多增加了54.2%。

    There are several algorithms for measuring fairness of ML models. A fundamental assumption in these approaches is that the ground truth is fair or unbiased. In real-world datasets, however, the ground truth often contains data that is a result of historical and societal biases and discrimination. Models trained on these datasets will inherit and propagate the biases to the model outputs. We propose FAIRLABEL, an algorithm which detects and corrects biases in labels. The goal of FAIRLABELis to reduce the Disparate Impact (DI) across groups while maintaining high accuracy in predictions. We propose metrics to measure the quality of bias correction and validate FAIRLABEL on synthetic datasets and show that the label correction is correct 86.7% of the time vs. 71.9% for a baseline model. We also apply FAIRLABEL on benchmark datasets such as UCI Adult, German Credit Risk, and Compas datasets and show that the Disparate Impact Ratio increases by as much as 54.2%.
    
[^6]: 基于气象和道路状况数据的交通事故持续时间预测的双层框架

    A Bi-level Framework for Traffic Accident Duration Prediction: Leveraging Weather and Road Condition Data within a Practical Optimum Pipeline. (arXiv:2311.00634v1 [cs.AI])

    [http://arxiv.org/abs/2311.00634](http://arxiv.org/abs/2311.00634)

    本研究提出了一个双层框架，利用气象和道路状况数据预测交通事故持续时间。通过多个机器学习模型和双模式方法，可以准确预测事故对交通的影响是短期还是长期，并确定事故的精确持续时间。

    

    由于事件的随机性，预测交通事故持续时间是一个严峻的挑战。准确的持续时间估计可以为通勤者选择最佳路线和交通管理人员解决非经常性拥堵问题带来巨大优势。本研究从交通事故数据库中收集了事故持续时间、道路状况和气象数据，以检查在没有事故上下文信息数据（如事故严重性和文本描述）的情况下交通事故持续时间管道的可行性。采用多个机器学习模型来预测交通事故对道路交通的影响是短期还是长期，然后利用双模式方法确定事故影响的精确持续时间。我们的二分类随机森林模型可以以83%的准确率区分短期和长期影响，而LightGBM回归模型可以预测事故的精确持续时间。

    Due to the stochastic nature of events, predicting the duration of a traffic incident presents a formidable challenge. Accurate duration estimation can result in substantial advantages for commuters in selecting optimal routes and for traffic management personnel in addressing non-recurring congestion issues. In this study, we gathered accident duration, road conditions, and meteorological data from a database of traffic accidents to check the feasibility of a traffic accident duration pipeline without accident contextual information data like accident severity and textual description. Multiple machine learning models were employed to predict whether an accident's impact on road traffic would be of a short-term or long-term nature, and then utilizing a bimodal approach the precise duration of the incident's effect was determined. Our binary classification random forest model distinguished between short-term and long-term effects with an 83% accuracy rate, while the LightGBM regression 
    
[^7]: 多注释者数据的损失建模

    Loss Modeling for Multi-Annotator Datasets. (arXiv:2311.00619v1 [cs.LG])

    [http://arxiv.org/abs/2311.00619](http://arxiv.org/abs/2311.00619)

    该论文提出了一种通过利用多任务学习和基于损失的标签修正来学习多注释者数据的准确表示的方法。通过这种方法，可以有效地分离赞同和不赞同的注释，并且在单一或多注释者设置下改善预测性能。该方法还显示出对主观数据的额外标签噪声具有鲁棒性。

    

    在公正性方面，考虑到数据集中所有注释者的意见至关重要。然而，在注释大型数据集时，个别注释者经常会提供数千个评分，这可能导致疲劳。此外，这些注释过程可能会持续多天，可能导致对注释者的意见随时间的不准确表示。为了解决这个问题，我们提出利用多任务学习和基于损失的标签修正来学习更准确的多样意见表示。我们展示了使用我们新颖的公式，我们可以清楚地分离赞同和不赞同的注释。此外，我们证明了这种修改可以改善单一或多注释者设置下的预测性能。最后，我们证明了该方法对应用于主观数据的额外标签噪声仍然具有稳健性。

    Accounting for the opinions of all annotators of a dataset is critical for fairness. However, when annotating large datasets, individual annotators will frequently provide thousands of ratings which can lead to fatigue. Additionally, these annotation processes can occur over multiple days which can lead to an inaccurate representation of an annotator's opinion over time. To combat this, we propose to learn a more accurate representation of diverse opinions by utilizing multitask learning in conjunction with loss-based label correction. We show that using our novel formulation, we can cleanly separate agreeing and disagreeing annotations. Furthermore, we demonstrate that this modification can improve prediction performance in a single or multi-annotator setting. Lastly, we show that this method remains robust to additional label noise that is applied to subjective data.
    
[^8]: 重新思考具有随机支持的概率编程的变分推断

    Rethinking Variational Inference for Probabilistic Programs with Stochastic Support. (arXiv:2311.00594v1 [cs.LG])

    [http://arxiv.org/abs/2311.00594](http://arxiv.org/abs/2311.00594)

    本文提出了一种新的变分推断方法SDVI，可以用于具有随机支持的概率编程。通过将程序分解为具有静态支持的子程序，并为每个子程序构建独立的变分指导，SDVI在推断性能方面取得了显著改进。

    

    本文介绍了支持分解变分推断（SDVI），一种面向具有随机支持的概率编程的新的变分推断方法。现有方法在这个问题上依赖于在逐变量的基础上设计单个全局变分指导，同时保持原始程序的随机控制流。SDVI相反，将程序分解为具有静态支持的子程序，然后自动构建每个子指导的独立子指导。这种分解显著有助于构建适合的变分族，从而进一步提高推断性能。

    We introduce Support Decomposition Variational Inference (SDVI), a new variational inference (VI) approach for probabilistic programs with stochastic support. Existing approaches to this problem rely on designing a single global variational guide on a variable-by-variable basis, while maintaining the stochastic control flow of the original program. SDVI instead breaks the program down into sub-programs with static support, before automatically building separate sub-guides for each. This decomposition significantly aids in the construction of suitable variational families, enabling, in turn, substantial improvements in inference performance.
    
[^9]: Coop: 内存不是商品

    Coop: Memory is not a Commodity. (arXiv:2311.00591v1 [cs.LG])

    [http://arxiv.org/abs/2311.00591](http://arxiv.org/abs/2311.00591)

    本论文提出了一种名为Coop的方法，针对深度学习框架中的内存系统问题，通过驱逐连续张量和优化张量分配，以降低再材料化成本。

    

    张量再材料化技术允许在有限的内存预算下训练深度神经网络(DNNs)，通过在需要时检查点模型并根据需要重新计算被驱逐的张量。然而，现有的张量再材料化技术忽视了深度学习框架中的内存系统，并假设不同地址的空闲内存块是相同的。在这个错误的假设下，不连续的张量被驱逐，其中一些不用于分配新的张量。这导致严重的内存碎片化，增加了潜在再材料化的成本。为了解决这个问题，我们提出了在滑动窗口内驱逐张量的方法，以确保所有驱逐都是连续的并且立即使用。此外，我们提出了廉价的张量分区和可重算的就地优化张量分配来进一步降低再材料化成本。我们将我们的方法命名为Coop，因为它是张量分配和张量再材料化的协同优化。

    Tensor rematerialization allows the training of deep neural networks (DNNs) under limited memory budgets by checkpointing the models and recomputing the evicted tensors as needed. However, the existing tensor rematerialization techniques overlook the memory system in deep learning frameworks and implicitly assume that free memory blocks at different addresses are identical. Under this flawed assumption, discontiguous tensors are evicted, among which some are not used to allocate the new tensor. This leads to severe memory fragmentation and increases the cost of potential rematerializations. To address this issue, we propose to evict tensors within a sliding window to ensure all evictions are contiguous and are immediately used. Furthermore, we proposed cheap tensor partitioning and recomputable in-place to further reduce the rematerialization cost by optimizing the tensor allocation. We named our method Coop as it is a co-optimization of tensor allocation and tensor rematerialization. 
    
[^10]: 使用正则化流和激进训练提升摘要生成

    Boosting Summarization with Normalizing Flows and Aggressive Training. (arXiv:2311.00588v1 [cs.CL])

    [http://arxiv.org/abs/2311.00588](http://arxiv.org/abs/2311.00588)

    本文提出了FlowSUM，一个基于正则化流的变分编码器-解码器框架，用于改进Transformer-based摘要生成。通过利用正则化流进行灵活的潜在后向建模以及采用受控交替激进训练策略，FlowSUM显著提高了生成摘要的质量，并探讨了正则化流中的后向塌陷问题和相关影响因素，为相关研究提供了宝贵的洞察。

    

    本文提出了基于正则化流的变分编码器-解码器框架FlowSUM，用于基于Transformer的摘要生成。我们的方法解决了变分摘要生成中的两个主要挑战：潜在表示中的语义信息不足和训练过程中的后向塌陷。为了应对这些挑战，我们使用正则化流实现了灵活的潜在后向建模，并提出了一种改进的门机制下的受控交替激进训练（CAAT）策略。实验结果表明，FlowSUM显著提高了生成摘要的质量，并在对推理时间的影响最小的情况下释放了知识蒸馏的潜力。此外，我们还研究了正则化流中的后向塌陷问题，并分析了训练策略、门初始化以及使用的正则化流类型和数量对摘要质量的影响，为未来研究提供了宝贵的见解。

    This paper presents FlowSUM, a normalizing flows-based variational encoder-decoder framework for Transformer-based summarization. Our approach tackles two primary challenges in variational summarization: insufficient semantic information in latent representations and posterior collapse during training. To address these challenges, we employ normalizing flows to enable flexible latent posterior modeling, and we propose a controlled alternate aggressive training (CAAT) strategy with an improved gate mechanism. Experimental results show that FlowSUM significantly enhances the quality of generated summaries and unleashes the potential for knowledge distillation with minimal impact on inference time. Furthermore, we investigate the issue of posterior collapse in normalizing flows and analyze how the summary quality is affected by the training strategy, gate initialization, and the type and number of normalizing flows used, offering valuable insights for future research.
    
[^11]: 最小修改马尔可夫博弈以实现任意Nash均衡和价值

    Minimally Modifying a Markov Game to Achieve Any Nash Equilibrium and Value. (arXiv:2311.00582v1 [cs.GT])

    [http://arxiv.org/abs/2311.00582](http://arxiv.org/abs/2311.00582)

    该论文研究了游戏修改问题，提出了一种最小修改马尔可夫博弈的方法，使得目标策略配置成为唯一的Nash均衡并具有特定价值范围，同时最小化修改成本。

    

    我们研究了游戏修改问题，其中一位善意的游戏设计者或恶意的对手修改了一个零和马尔可夫博弈的奖励函数，以便一个目标确定性或随机的策略配置成为唯一的马尔可夫完美Nash均衡，并且在目标范围内具有价值，以最小化修改成本。我们表征了能够安装为某个游戏的唯一均衡的策略配置的集合，并建立了成功安装的充分和必要条件。我们提出了一种高效的算法，该算法通过解一个带有线性约束的凸优化问题，然后进行随机扰动，来获得一个成本近乎最优的修改计划。

    We study the game modification problem, where a benevolent game designer or a malevolent adversary modifies the reward function of a zero-sum Markov game so that a target deterministic or stochastic policy profile becomes the unique Markov perfect Nash equilibrium and has a value within a target range, in a way that minimizes the modification cost. We characterize the set of policy profiles that can be installed as the unique equilibrium of some game, and establish sufficient and necessary conditions for successful installation. We propose an efficient algorithm, which solves a convex optimization problem with linear constraints and then performs random perturbation, to obtain a modification plan with a near-optimal cost.
    
[^12]: LLaVA-Interactive:一个图像对话、分割、生成和编辑的全能演示

    LLaVA-Interactive: An All-in-One Demo for Image Chat, Segmentation, Generation and Editing. (arXiv:2311.00571v1 [cs.CV])

    [http://arxiv.org/abs/2311.00571](http://arxiv.org/abs/2311.00571)

    LLaVA-Interactive是一个多模态人机交互的研究原型系统，通过视觉提示来对齐人类意图，实现了图像对话、分割、生成和编辑的多模态功能，具有高成本效益和广泛的应用潜力。

    

    LLaVA-Interactive是一种多模态人机交互的研究原型系统。该系统可以通过接收多模态用户输入并生成多模态回应与用户进行多轮对话。重要的是，LLaVA-Interactive不仅仅是语言提示，还可以使用视觉提示来对齐人类意图。LLaVA-Interactive的研发成本效益非常高，因为该系统结合了预建的AI模型的三项多模态技能，而无需额外的模型训练：LLaVA的图像对话，SEEM的图像分割以及GLIGEN的图像生成和编辑。展示了各种应用场景，以展示LLaVA-Interactive的潜力，并激发未来在多模态交互系统方面的研究。

    LLaVA-Interactive is a research prototype for multimodal human-AI interaction. The system can have multi-turn dialogues with human users by taking multimodal user inputs and generating multimodal responses. Importantly, LLaVA-Interactive goes beyond language prompt, where visual prompt is enabled to align human intents in the interaction. The development of LLaVA-Interactive is extremely cost-efficient as the system combines three multimodal skills of pre-built AI models without additional model training: visual chat of LLaVA, image segmentation from SEEM, as well as image generation and editing from GLIGEN. A diverse set of application scenarios is presented to demonstrate the promises of LLaVA-Interactive and to inspire future research in multimodal interactive systems.
    
[^13]: 在重症监护室中检测视觉线索与患者临床状态的关联

    Detecting Visual Cues in the Intensive Care Unit and Association with Patient Clinical Status. (arXiv:2311.00565v1 [cs.CV])

    [http://arxiv.org/abs/2311.00565](http://arxiv.org/abs/2311.00565)

    在重症监护室中开发能够检测视觉线索并与患者临床状态关联的人工智能工具，可以提供更客观和详细的监测能力。

    

    重症监护室（ICU）为患有生命威胁的患者提供密切监护和连续护理。然而，由于时间限制和医疗保健工作者的工作负荷，ICU中的连续患者评估仍然有限。现有的ICU患者评估，如疼痛或活动能力评估，大多是零散和手动实施的，从而引入了人为错误的潜在可能性。开发能够增强ICU中人类评估的人工智能（AI）工具可以有利于提供更客观和详细的监测能力。例如，捕捉与疼痛或不安相关的患者面部线索的变化可以帮助调整与疼痛相关的药物或检测可能引起不安的情况，如谵妄。此外，在不良临床事件发生期间或之前，视觉线索的微妙变化与高分辨率生理信号相结合可能有助于连续患者监测。

    Intensive Care Units (ICU) provide close supervision and continuous care to patients with life-threatening conditions. However, continuous patient assessment in the ICU is still limited due to time constraints and the workload on healthcare providers. Existing patient assessments in the ICU such as pain or mobility assessment are mostly sporadic and administered manually, thus introducing the potential for human errors. Developing Artificial intelligence (AI) tools that can augment human assessments in the ICU can be beneficial for providing more objective and granular monitoring capabilities. For example, capturing the variations in a patient's facial cues related to pain or agitation can help in adjusting pain-related medications or detecting agitation-inducing conditions such as delirium. Additionally, subtle changes in visual cues during or prior to adverse clinical events could potentially aid in continuous patient monitoring when combined with high-resolution physiological signal
    
[^14]: 用以物体为中心的模型和MDL原则解决抽象推理语料库（ARC）

    Tackling the Abstraction and Reasoning Corpus (ARC) with Object-centric Models and the MDL Principle. (arXiv:2311.00545v1 [cs.AI])

    [http://arxiv.org/abs/2311.00545](http://arxiv.org/abs/2311.00545)

    该论文介绍了一种以物体为中心的模型和MDL原则，用于解决抽象推理语料库（ARC）。通过学习到的模型可以进行预测和联合描述输入/输出对，在各种任务上展现了普适性。

    

    抽象推理语料库（ARC）是一个具有挑战性的基准测试，旨在促进人工智能研究朝向人类水平智能的方向发展。它是一组关于生成彩色网格的独特任务，仅由少量示例进行规定。与现有工作中的基于转换的程序相比，我们引入了与人类生成的自然程序一致的以物体为中心的模型。我们的模型不仅可以进行预测，还可以为输入/输出对提供联合描述。最小描述长度（MDL）原则用于高效搜索大型模型空间。我们解决了各种各样的任务，并且学习到的模型与自然程序相似。我们通过将其应用于不同领域来展示我们方法的普遍性。

    The Abstraction and Reasoning Corpus (ARC) is a challenging benchmark, introduced to foster AI research towards human-level intelligence. It is a collection of unique tasks about generating colored grids, specified by a few examples only. In contrast to the transformation-based programs of existing work, we introduce object-centric models that are in line with the natural programs produced by humans. Our models can not only perform predictions, but also provide joint descriptions for input/output pairs. The Minimum Description Length (MDL) principle is used to efficiently search the large model space. A diverse range of tasks are solved, and the learned models are similar to the natural programs. We demonstrate the generality of our approach by applying it to a different domain.
    
[^15]: LLMs对具身导航的发展

    The Development of LLMs for Embodied Navigation. (arXiv:2311.00530v1 [cs.AI])

    [http://arxiv.org/abs/2311.00530](http://arxiv.org/abs/2311.00530)

    本文概述了LLMs与具身智能在导航领域的共生关系，并评估了现有模型和数据集的优缺点。

    

    近年来，诸如生成预训练变压器（GPT）之类的大语言模型（LLMs）的快速发展引起了越来越多的关注，因为它们在各种实际应用中具有潜力。LLMs与具身智能的应用已成为一个重要的研究领域。在众多应用中，导航任务尤为引人注目，因为它们要求对环境有深入的理解和快速、准确的决策能力。LLMs可以通过利用其强大的语言和图像处理能力，增强具身智能系统在环境感知和决策支持方面的能力。本文全面总结了LLMs与具身智能之间在导航方面的共生关系，审视了最先进的模型、研究方法，并评估了现有的具身导航模型和数据集的优缺点。最后，本文阐明了LLMs在具身导航领域的创新和贡献。

    In recent years, the rapid advancement of Large Language Models (LLMs) such as the Generative Pre-trained Transformer (GPT) has attracted increasing attention due to their potential in a variety of practical applications. The application of LLMs with Embodied Intelligence has emerged as a significant area of focus. Among the myriad applications of LLMs, navigation tasks are particularly noteworthy because they demand a deep understanding of the environment and quick, accurate decision-making. LLMs can augment embodied intelligence systems with sophisticated environmental perception and decision-making support, leveraging their robust language and image-processing capabilities. This article offers an exhaustive summary of the symbiosis between LLMs and embodied intelligence with a focus on navigation. It reviews state-of-the-art models, research methodologies, and assesses the advantages and disadvantages of existing embodied navigation models and datasets. Finally, the article elucidat
    
[^16]: 使用深度强化学习学习顺序可解释策略的无偏方法

    Learning impartial policies for sequential counterfactual explanations using Deep Reinforcement Learning. (arXiv:2311.00523v1 [cs.LG])

    [http://arxiv.org/abs/2311.00523](http://arxiv.org/abs/2311.00523)

    本文提出了使用深度强化学习学习顺序可解释策略的无偏方法。该方法通过对分类器的输出概率进行奖励来减轻现有方法中可能导致偏向特定动作的策略的不希望属性。

    

    在可解释人工智能（XAI）领域中，通常使用顺序可解释（SCF）示例通过对输入实例进行一系列修改来改变训练分类器的决策。虽然某些测试时算法旨在针对每个新实例进行优化，但最近提出了强化学习（RL）方法，旨在学习用于发现SCF的策略，从而提高可伸缩性。在RL中，RL问题的制定，包括状态空间，动作和奖励的规定，通常存在歧义。在这项工作中，我们发现现有方法的缺点可能导致具有不希望的属性（如偏向特定动作）的策略。我们建议使用分类器的输出概率来创建更具信息性的奖励，以减轻这种影响。

    In the field of explainable Artificial Intelligence (XAI), sequential counterfactual (SCF) examples are often used to alter the decision of a trained classifier by implementing a sequence of modifications to the input instance. Although certain test-time algorithms aim to optimize for each new instance individually, recently Reinforcement Learning (RL) methods have been proposed that seek to learn policies for discovering SCFs, thereby enhancing scalability. As is typical in RL, the formulation of the RL problem, including the specification of state space, actions, and rewards, can often be ambiguous. In this work, we identify shortcomings in existing methods that can result in policies with undesired properties, such as a bias towards specific actions. We propose to use the output probabilities of the classifier to create a more informative reward, to mitigate this effect.
    
[^17]: 在CPU上高效的LLM推理

    Efficient LLM Inference on CPUs. (arXiv:2311.00502v1 [cs.LG])

    [http://arxiv.org/abs/2311.00502](http://arxiv.org/abs/2311.00502)

    本研究提出了一种在CPU上高效部署大型语言模型（LLMs）的方法，支持自动权重量化和优化内核，在流行的LLMs上展示了极高的推理效率。

    

    大型语言模型(LLMs)已经在各种任务上展示出了令人瞩目的性能和巨大的潜力。然而，由于模型参数的庞大数量，LLMs的部署一直面临挑战，对大内存容量和高内存带宽的需求。在本文中，我们提出了一种有效的方法，可以使LLMs的部署更高效。我们支持自动的INT4权重量化流程，并设计了一个特殊的LLM运行时，具有高度优化的内核，以加速在CPU上的LLM推理。我们展示了我们的方法在流行的LLMs上的普适性，包括Llama2，Llama，GPT-NeoX，并展示了在CPU上的极高推理效率。代码公开可用于: https://github.com/intel/intel-extension-for-transformers.

    Large language models (LLMs) have demonstrated remarkable performance and tremendous potential across a wide range of tasks. However, deploying these models has been challenging due to the astronomical amount of model parameters, which requires a demand for large memory capacity and high memory bandwidth. In this paper, we propose an effective approach that can make the deployment of LLMs more efficiently. We support an automatic INT4 weight-only quantization flow and design a special LLM runtime with highly-optimized kernels to accelerate the LLM inference on CPUs. We demonstrate the general applicability of our approach on popular LLMs including Llama2, Llama, GPT-NeoX, and showcase the extreme inference efficiency on CPUs. The code is publicly available at: https://github.com/intel/intel-extension-for-transformers.
    
[^18]: 扩散模型的数据归因的有趣特性

    Intriguing Properties of Data Attribution on Diffusion Models. (arXiv:2311.00500v1 [cs.LG])

    [http://arxiv.org/abs/2311.00500](http://arxiv.org/abs/2311.00500)

    本研究通过对扩散模型进行实验和分析，发现在数据归因方面，一些在理论上不合理的设计选择能够在实际中表现出比以前的方法更好的效果。这对于确保数据贡献者公平补偿或认可具有重要意义。

    

    数据归因旨在将模型输出追溯到训练数据。随着扩散模型的最新发展，数据归因已成为一个理想的模块，可以为高质量或版权保护的训练样本正确分配价值，确保数据贡献者得到公平的补偿或认可。已经提出了几种在理论上有动机的方法来实现数据归因，以改善计算可扩展性和效果之间的权衡。在这项工作中，我们对扩散模型进行了广泛的实验和消融研究，特别关注在CIFAR-10和CelebA上训练的DDPM以及在ArtBench上进行细调的稳定扩散模型LoRA的归因。有趣的是，我们报告了理论上不合理的设计选择在实际中大幅超越了以前的基线，无论是在线性数据建模得分还是反事实评估方面。我们的工作呈现了一个重要的创新点。

    Data attribution seeks to trace model outputs back to training data. With the recent development of diffusion models, data attribution has become a desired module to properly assign valuations for high-quality or copyrighted training samples, ensuring that data contributors are fairly compensated or credited. Several theoretically motivated methods have been proposed to implement data attribution, in an effort to improve the trade-off between computational scalability and effectiveness. In this work, we conduct extensive experiments and ablation studies on attributing diffusion models, specifically focusing on DDPMs trained on CIFAR-10 and CelebA, as well as a Stable Diffusion model LoRA-finetuned on ArtBench. Intriguingly, we report counter-intuitive observations that theoretically unjustified design choices for attribution empirically outperform previous baselines by a large margin, in terms of both linear datamodeling score and counterfactual evaluation. Our work presents a signific
    
[^19]: 贝叶斯增强的多视角注意力网络用于强大的POI推荐

    Bayes-enhanced Multi-view Attention Networks for Robust POI Recommendation. (arXiv:2311.00491v1 [cs.IR])

    [http://arxiv.org/abs/2311.00491](http://arxiv.org/abs/2311.00491)

    本文提出了一种贝叶斯增强的多视角注意力网络来解决POI推荐中不确定因素的问题，通过构建个人POI转换图、基于语义的POI图和基于距离的POI图来全面建模依赖关系，提高POI推荐的性能和鲁棒性。

    

    POI推荐在促进各种基于位置的社交网络服务方面具有实际重要性，并近年来引起了越来越多的研究关注。现有的作品通常假设用户报告的可用POI签到是用户行为的唯一描述。然而，在实际应用场景中，由于主观和客观原因（包括定位误差和用户隐私问题），签到数据可能相当不可靠，这对POI推荐的性能造成了显著的负面影响。为此，我们研究了一个新颖的问题，通过考虑用户签到的不确定因素，提出了一种贝叶斯增强的多视角注意力网络来进行强大的POI推荐。具体而言，我们构建了个人POI转换图、基于语义的POI图和基于距离的POI图，全面建模了POI之间的依赖关系。由于个人POI转换图通常稀疏且对噪声敏感，所以我们引入了贝叶斯方法来增强网络的鲁棒性和性能。

    POI recommendation is practically important to facilitate various Location-Based Social Network services, and has attracted rising research attention recently. Existing works generally assume the available POI check-ins reported by users are the ground-truth depiction of user behaviors. However, in real application scenarios, the check-in data can be rather unreliable due to both subjective and objective causes including positioning error and user privacy concerns, leading to significant negative impacts on the performance of the POI recommendation. To this end, we investigate a novel problem of robust POI recommendation by considering the uncertainty factors of the user check-ins, and proposes a Bayes-enhanced Multi-view Attention Network. Specifically, we construct personal POI transition graph, the semantic-based POI graph and distance-based POI graph to comprehensively model the dependencies among the POIs. As the personal POI transition graph is usually sparse and sensitive to noi
    
[^20]: 双重条件扩散模型用于外分布检测：应用于胎儿超声视频

    Dual Conditioned Diffusion Models for Out-Of-Distribution Detection: Application to Fetal Ultrasound Videos. (arXiv:2311.00469v1 [cs.CV])

    [http://arxiv.org/abs/2311.00469](http://arxiv.org/abs/2311.00469)

    本论文提出了双重条件扩散模型（DCDM），用于胎儿超声视频中的外分布检测。该模型能够在存在高度结构相似性和大量内部变异性的背景下，对胎儿超声视频中的心脏视图进行检测，并拒绝类似的外分布样本。

    

    外分布（OOD）检测对于改善机器学习模型的可靠性至关重要，它能够检测出不属于训练分布的样本。在某些任务中，有效地检测OOD样本可能会面临挑战，因为训练分布（ID）内部存在显著的异质性，并且ID和OOD类之间存在高度的结构相似性。例如，在胎儿超声视频中检测心脏视图时，心脏和腹部等其他解剖结构之间存在高度的结构相似性，并且每个视图内部存在着5种不同的视图和结构变化。为了检测此背景下的OOD样本，所得模型应能够学习到解剖结构内部的变化，并且能够拒绝类似的OOD样本。在本文中，我们介绍了双重条件扩散模型（DCDM），其中我们使用ID类信息和输入图像的潜在特征来对模型进行条件化重构。

    Out-of-distribution (OOD) detection is essential to improve the reliability of machine learning models by detecting samples that do not belong to the training distribution. Detecting OOD samples effectively in certain tasks can pose a challenge because of the substantial heterogeneity within the in-distribution (ID), and the high structural similarity between ID and OOD classes. For instance, when detecting heart views in fetal ultrasound videos there is a high structural similarity between the heart and other anatomies such as the abdomen, and large in-distribution variance as a heart has 5 distinct views and structural variations within each view. To detect OOD samples in this context, the resulting model should generalise to the intra-anatomy variations while rejecting similar OOD samples. In this paper, we introduce dual-conditioned diffusion models (DCDM) where we condition the model on in-distribution class information and latent features of the input image for reconstruction-bas
    
[^21]: 利用双曲嵌入进行粗细设计的机器人设计

    Leveraging Hyperbolic Embeddings for Coarse-to-Fine Robot Design. (arXiv:2311.00462v1 [cs.AI])

    [http://arxiv.org/abs/2311.00462](http://arxiv.org/abs/2311.00462)

    本文提出了一种新的多细胞机器人粗细设计方法，利用双曲嵌入框架在共享的双曲空间内统一了各种粒度的机器人，并通过改进的交叉熵方法进行优化。这种方法能够自主地在双曲空间中确定探索的区域。

    

    多细胞机器人设计旨在创建由许多细胞组成的机器人，以便能够高效地控制执行各种任务。过去的研究已经证明了生成各种任务的机器人的能力，但这些方法通常直接在庞大的设计空间中对机器人进行优化，导致了难以控制的复杂形态的机器人。为了解决这个问题，本文提出了一种新的多细胞机器人粗细设计方法。该策略首先寻求最佳的粗粒度机器人，然后逐步对其进行精细调整。为了解决在粗细转换过程中确定精细调整关节的挑战，我们引入了用于机器人设计的双曲嵌入 (HERD) 框架。HERD 在一个共享的双曲空间内统一了各种粒度的机器人，并利用改进的交叉熵方法进行优化。这个框架使得我们的方法能够自主地在双曲空间中确定探索的区域。

    Multi-cellular robot design aims to create robots comprised of numerous cells that can be efficiently controlled to perform diverse tasks. Previous research has demonstrated the ability to generate robots for various tasks, but these approaches often optimize robots directly in the vast design space, resulting in robots with complicated morphologies that are hard to control. In response, this paper presents a novel coarse-to-fine method for designing multi-cellular robots. Initially, this strategy seeks optimal coarse-grained robots and progressively refines them. To mitigate the challenge of determining the precise refinement juncture during the coarse-to-fine transition, we introduce the Hyperbolic Embeddings for Robot Design (HERD) framework. HERD unifies robots of various granularity within a shared hyperbolic space and leverages a refined Cross-Entropy Method for optimization. This framework enables our method to autonomously identify areas of exploration in hyperbolic space and c
    
[^22]: 关于绿色计算的机遇：一项调查

    On the Opportunities of Green Computing: A Survey. (arXiv:2311.00447v1 [cs.AI])

    [http://arxiv.org/abs/2311.00447](http://arxiv.org/abs/2311.00447)

    这项调查总结了绿色计算领域的技术，旨在解决人工智能计算资源和环境影响的挑战。

    

    人工智能（AI）在技术和研究方面取得了显著进展，并广泛应用于计算视觉、自然语言处理、时间序列分析、语音合成等多个领域。在深度学习时代，特别是随着大型语言模型的出现，大多数研究者关注于追求新的最先进（SOTA）结果，导致模型大小和计算复杂性不断增加。对于高计算能力的需求导致更高的碳排放，并通过阻止资金有限的小型或中型研究机构和公司参与研究来破坏研究公平性。为应对计算资源和人工智能的环境影响的挑战，绿色计算已成为一个热门研究课题。在本调查中，我们对绿色计算中使用的技术进行了系统概述，并提出了G框架。

    Artificial Intelligence (AI) has achieved significant advancements in technology and research with the development over several decades, and is widely used in many areas including computing vision, natural language processing, time-series analysis, speech synthesis, etc. During the age of deep learning, especially with the arise of Large Language Models, a large majority of researchers' attention is paid on pursuing new state-of-the-art (SOTA) results, resulting in ever increasing of model size and computational complexity. The needs for high computing power brings higher carbon emission and undermines research fairness by preventing small or medium-sized research institutions and companies with limited funding in participating in research. To tackle the challenges of computing resources and environmental impact of AI, Green Computing has become a hot research topic. In this survey, we give a systematic overview of the technologies used in Green Computing. We propose the framework of G
    
[^23]: 人类和语言模型中的三段论推理的系统比较

    A Systematic Comparison of Syllogistic Reasoning in Humans and Language Models. (arXiv:2311.00445v1 [cs.CL])

    [http://arxiv.org/abs/2311.00445](http://arxiv.org/abs/2311.00445)

    这项研究通过对比人类和语言模型在三段论推理中的表现，发现较大的语言模型更合逻辑，甚至比人类更合逻辑，但即使最大的语言模型也会出现与人类推理类似的错误，总体上认为语言模型在某些情况下能够克服人类偏见。

    

    理性行为的一个核心组成部分是逻辑推理：确定哪些结论可以从一组前提中得出。心理学家已经记录下人类推理与逻辑规则不符的几种方式。语言模型是否能够复制这些偏差，或者它们能够克服这些偏差？我们关注三段论的情况 - 从两个简单前提中推导出的推理，这在心理学中已经广泛研究 - 我们发现较大的模型比较合逻辑，而且比人类更合逻辑。与此同时，即使是最大的模型也会出现系统性错误，其中一些错误与人类推理的偏见相似，例如排序效应和逻辑谬误。总体上，我们发现语言模型模仿了训练数据中包含的人类偏见，但在某些情况下能够克服这些偏见。

    A central component of rational behavior is logical inference: the process of determining which conclusions follow from a set of premises. Psychologists have documented several ways in which humans' inferences deviate from the rules of logic. Do language models, which are trained on text generated by humans, replicate these biases, or are they able to overcome them? Focusing on the case of syllogisms -- inferences from two simple premises, which have been studied extensively in psychology -- we show that larger models are more logical than smaller ones, and also more logical than humans. At the same time, even the largest models make systematic errors, some of which mirror human reasoning biases such as ordering effects and logical fallacies. Overall, we find that language models mimic the human biases included in their training data, but are able to overcome them in some cases.
    
[^24]: 通过简单的动态扫描增强技术改进Vision Transformer的鲁棒性

    Improving Robustness for Vision Transformer with a Simple Dynamic Scanning Augmentation. (arXiv:2311.00441v1 [cs.CV])

    [http://arxiv.org/abs/2311.00441](http://arxiv.org/abs/2311.00441)

    通过Dynamic Scanning Augmentation增强技术，提高了Vision Transformer的准确性和鲁棒性，尤其是在面对对抗攻击时。这种方法适应性地聚焦于不同的图像块，并改变了ViT的注意力机制。

    

    Vision Transformer (ViT)在计算机视觉任务中表现出与最先进的神经网络相媲美的性能。然而，这种新型的深度神经网络架构易受到对抗攻击的影响，从而限制了其鲁棒性能。本文提出了一种旨在进一步提高ViT的准确性和鲁棒性的新方法，特别是在面对对抗攻击时。我们提出了一种称为“动态扫描增强”的增强技术，利用动态输入序列来自适应地聚焦于不同的图像块，从而保持性能和鲁棒性。我们的详细研究揭示了这种对输入序列的适应性会导致ViT的注意力机制发生显著变化，即使对于相同的图像也是如此。我们引入了四种Dynamic Scanning Augmentation的变体， 在对抗攻击的鲁棒性和对自然图像的准确性方面均胜过ViT，其中一种变体表现最佳。

    Vision Transformer (ViT) has demonstrated promising performance in computer vision tasks, comparable to state-of-the-art neural networks. Yet, this new type of deep neural network architecture is vulnerable to adversarial attacks limiting its capabilities in terms of robustness. This article presents a novel contribution aimed at further improving the accuracy and robustness of ViT, particularly in the face of adversarial attacks. We propose an augmentation technique called `Dynamic Scanning Augmentation' that leverages dynamic input sequences to adaptively focus on different patches, thereby maintaining performance and robustness. Our detailed investigations reveal that this adaptability to the input sequence induces significant changes in the attention mechanism of ViT, even for the same image. We introduce four variations of Dynamic Scanning Augmentation, outperforming ViT in terms of both robustness to adversarial attacks and accuracy against natural images, with one variant showin
    
[^25]: 基于稀疏奖励的自我模仿强化学习在过程化环境中通过优先级和多样性增强泛化能力

    Enhanced Generalization through Prioritization and Diversity in Self-Imitation Reinforcement Learning over Procedural Environments with Sparse Rewards. (arXiv:2311.00426v1 [cs.LG])

    [http://arxiv.org/abs/2311.00426](http://arxiv.org/abs/2311.00426)

    本研究通过优先级排序和多样性来提高自我模仿强化学习在过程化环境中的泛化能力。

    

    在稀疏奖励的强化学习中，探索是一个基本挑战，限制了智能体学习最优决策的能力，因为缺乏信息反馈信号。自我模仿学习已经成为一种有前途的探索方法，利用回放缓冲区来存储和重现成功的行为。然而，传统的自我模仿学习方法在泛化方面面临挑战，特别是在过程化生成的环境中。因此，本研究提出了通过不同方式对转换进行优先级排序的定制自我模仿学习采样策略，并将优先级技术扩展到过程化生成的环境。我们还通过修改回放缓冲区中的演示来解决多样性损失问题。

    Exploration poses a fundamental challenge in Reinforcement Learning (RL) with sparse rewards, limiting an agent's ability to learn optimal decision-making due to a lack of informative feedback signals. Self-Imitation Learning (self-IL) has emerged as a promising approach for exploration, leveraging a replay buffer to store and reproduce successful behaviors. However, traditional self-IL methods, which rely on high-return transitions and assume singleton environments, face challenges in generalization, especially in procedurally-generated (PCG) environments. Therefore, new self-IL methods have been proposed to rank which experiences to persist, but they replay transitions uniformly regardless of their significance, and do not address the diversity of the stored demonstrations. In this work, we propose tailored self-IL sampling strategies by prioritizing transitions in different ways and extending prioritization techniques to PCG environments. We also address diversity loss through modif
    
[^26]: 考虑物体-环境交互的神经隐式场编辑

    Neural Implicit Field Editing Considering Object-environment Interaction. (arXiv:2311.00425v1 [cs.CV])

    [http://arxiv.org/abs/2311.00425](http://arxiv.org/abs/2311.00425)

    本论文提出了一种考虑物体和场景环境交互的神经隐式场编辑方法，通过内在分解方法成功地分离了物体和场景环境之间的交互，实现了合理的场景外观编辑效果。

    

    基于神经隐式场的3D场景编辑方法已经引起了广泛关注，在3D编辑任务中取得了出色的结果。然而，现有的方法常常忽略了物体与场景环境之间的交互。场景外观的变化，如阴影，在渲染视图中无法显示。本文提出了一种考虑物体和场景环境交互的新型两流神经渲染系统(OSI-aware)，通过内在分解方法成功地分离了物体和场景环境之间的交互。为了研究物体级别编辑任务对场景外观的相应改变，我们引入了深度图引导的场景修复方法和点匹配策略的阴影渲染方法。大量实验证明我们的新流程产生了合理的外观

    The 3D scene editing method based on neural implicit field has gained wide attention. It has achieved excellent results in 3D editing tasks. However, existing methods often blend the interaction between objects and scene environment. The change of scene appearance like shadows is failed to be displayed in the rendering view. In this paper, we propose an Object and Scene environment Interaction aware (OSI-aware) system, which is a novel two-stream neural rendering system considering object and scene environment interaction. To obtain illuminating conditions from the mixture soup, the system successfully separates the interaction between objects and scene environment by intrinsic decomposition method. To study the corresponding changes to the scene appearance from object-level editing tasks, we introduce a depth map guided scene inpainting method and shadow rendering method by point matching strategy. Extensive experiments demonstrate that our novel pipeline produce reasonable appearance
    
[^27]: 夫妻可以被解决：新的算法和对带夫妻的医院/居民问题的难度结果

    Couples can be tractable: New algorithms and hardness results for the Hospitals / Residents problem with Couples. (arXiv:2311.00405v1 [cs.DS])

    [http://arxiv.org/abs/2311.00405](http://arxiv.org/abs/2311.00405)

    本研究提出了一种新的多项式时间算法，用于解决带夫妻的医院/居民问题，并证明了算法的多项式时间可解性以及对稳定B匹配问题的应用。算法能够找到一个接近可行的稳定匹配，并应用于不同类型的实例。

    

    在本文中，我们研究了带夫妻的医院/居民问题（Hospitals / Residents problem with Couples，简称HRC），其中解的一种是稳定匹配，或者报告不存在。我们提出了一种新的多项式时间算法，可以在带夫妻的HRC实例中找到一个接近可行的稳定匹配（通过最多调整医院的容量1个单位），其中夫妻的偏好是子响应性的（即，如果一个成员转移到一个更好的医院，那么夫妻也会变得更好）和子完备性的（即，对于每对个别可接受的医院都是夫妻一起可接受的），通过将其规约到稳定固定问题的实例。我们还提出了一个针对HRC子响应性、子完备实例的多项式时间算法，该实例是一个双重市场，或者所有夫妻属于几种可能类型之一。我们证明了我们的算法也意味着稳定B匹配问题的多项式时间可解性，其中底层图是带有环的多重图。

    In this paper we study the {\sc Hospitals / Residents problem with Couples} ({\sc hrc}), where a solution is a stable matching or a report that none exists. We present a novel polynomial-time algorithm that can find a near-feasible stable matching (adjusting the hospitals' capacities by at most 1) in an {\sc hrc} instance where the couples' preferences are sub-responsive (i.e., if one member switches to a better hospital, than the couple also improves) and sub-complete (i.e., each pair of hospitals that are individually acceptable to both members are jointly acceptable for the couple) by reducing it to an instance of the {\sc Stable Fixtures} problem. We also present a polynomial-time algorithm for {\sc hrc} in a sub-responsive, sub-complete instance that is a Dual Market, or where all couples are one of several possible types. We show that our algorithm also implies the polynomial-time solvability of a stable b-matching problem, where the underlying graph is a multigraph with loops.  
    
[^28]: 基于时空变换器的教育场景下人体姿势评估与修正框架

    A Spatial-Temporal Transformer based Framework For Human Pose Assessment And Correction in Education Scenarios. (arXiv:2311.00401v1 [cs.CV])

    [http://arxiv.org/abs/2311.00401](http://arxiv.org/abs/2311.00401)

    本文提出了一种基于时空变换器的框架（STTF），用于教育场景中的人体姿势评估和修正。框架包括骨骼跟踪、姿势估计、姿势评估和姿势修正模块，能够提供专业、快速修正的反馈，并通过视觉辅助的形式提供修正性反馈。实验证明，该框架能够有效评估学生行为的质量并进行点评。

    

    人体姿势评估和修正在计算机视觉、机器人技术、体育分析、医疗保健和娱乐等各个领域具有重要作用。本文提出了一种基于时空变换器的框架（STTF），用于教育场景中的人体姿势评估和修正，例如体育锻炼和科学实验。该框架包括骨骼跟踪、姿势估计、姿势评估和姿势修正模块，以向学生提供专业、快速修正的反馈。我们还开发了一种姿势修正方法，以视觉辅助的形式提供修正性反馈。我们使用自己的数据集对该框架进行了测试，包括（a）五个锻炼动作的新录制，（b）在互联网上找到的同一锻炼动作的现有录制，以及（c）由专业运动员和教师对录制的修正性反馈。结果表明，我们的模型能够有效评估学生行为的质量并进行点评。

    Human pose assessment and correction play a crucial role in applications across various fields, including computer vision, robotics, sports analysis, healthcare, and entertainment. In this paper, we propose a Spatial-Temporal Transformer based Framework (STTF) for human pose assessment and correction in education scenarios such as physical exercises and science experiment. The framework comprising skeletal tracking, pose estimation, posture assessment, and posture correction modules to educate students with professional, quick-to-fix feedback. We also create a pose correction method to provide corrective feedback in the form of visual aids. We test the framework with our own dataset. It comprises (a) new recordings of five exercises, (b) existing recordings found on the internet of the same exercises, and (c) corrective feedback on the recordings by professional athletes and teachers. Results show that our model can effectively measure and comment on the quality of students' actions. T
    
[^29]: 用符号知识增强深度神经网络：实现可信赖和可解释的教育人工智能

    Augmenting deep neural networks with symbolic knowledge: Towards trustworthy and interpretable AI for education. (arXiv:2311.00393v1 [cs.AI])

    [http://arxiv.org/abs/2311.00393](http://arxiv.org/abs/2311.00393)

    这项研究旨在通过神经-符号AI框架，在教育应用中解决难以整合符号教育知识、学习偏见和缺乏解释性等问题，并开发了一种名为NSAI的方法。

    

    人工神经网络（ANNs）已经成为教育应用中最重要的人工智能技术之一，提供自适应教育服务。然而，由于三个主要挑战，它们在实践中的教育潜力受到限制：一是难以将符号教育知识（如因果关系和从业者知识）纳入到其开发中；二是学习和反映偏见；三是缺乏解释性。鉴于教育的高风险性，将教育知识整合到ANNs中对于开发符合基本教育限制、并提供预测可解释性的AI应用至关重要。本研究认为神经-符号AI家族有潜力解决上述挑战。为此，它提出了一种神经-符号AI框架，并相应地开发了一种名为NSAI的方法，将教育知识注入和提取到该框架中。

    Artificial neural networks (ANNs) have shown to be amongst the most important artificial intelligence (AI) techniques in educational applications, providing adaptive educational services. However, their educational potential is limited in practice due to three major challenges: i) difficulty in incorporating symbolic educational knowledge (e.g., causal relationships, and practitioners' knowledge) in their development, ii) learning and reflecting biases, and iii) lack of interpretability. Given the high-risk nature of education, the integration of educational knowledge into ANNs becomes crucial for developing AI applications that adhere to essential educational restrictions, and provide interpretability over the predictions. This research argues that the neural-symbolic family of AI has the potential to address the named challenges. To this end, it adapts a neural-symbolic AI framework and accordingly develops an approach called NSAI, that injects and extracts educational knowledge into
    
[^30]: 编码在使用生成式AI模型进行终端用户编程中是否仍然具有相关性？

    Will Code Remain a Relevant User Interface for End-User Programming with Generative AI Models?. (arXiv:2311.00382v1 [cs.HC])

    [http://arxiv.org/abs/2311.00382](http://arxiv.org/abs/2311.00382)

    这篇论文探讨了生成式人工智能对终端用户编程的影响，提出了生成转变假设，并讨论了传统编程语言对非专业终端用户程序员仍然具有相关性的原因和可能性。

    

    终端用户编程的研究领域一直致力于帮助非专业人士学习足够好的编码，以便完成他们的任务。生成式人工智能可以通过自然语言提示生成代码，从而完全消除这一需求。在本文中，我们探讨在具有生成式人工智能的世界中，“传统”编程语言对非专业终端用户程序员仍然相关的程度。我们提出了“生成转变假设”：生成式人工智能将在终端用户编程的传统范围上创造定性和定量的扩展。我们概述了传统编程语言可能仍然对终端用户程序员有用的一些原因。我们推测这些原因是否可能是根本和持久的，或者它们是否会随着生成式人工智能的进一步改进和创新而消失。最后，我们阐述了对终端用户编程研究的一系列影响，包括可能性。

    The research field of end-user programming has largely been concerned with helping non-experts learn to code sufficiently well in order to achieve their tasks. Generative AI stands to obviate this entirely by allowing users to generate code from naturalistic language prompts. In this essay, we explore the extent to which "traditional" programming languages remain relevant for non-expert end-user programmers in a world with generative AI. We posit the "generative shift hypothesis": that generative AI will create qualitative and quantitative expansions in the traditional scope of end-user programming. We outline some reasons that traditional programming languages may still be relevant and useful for end-user programmers. We speculate whether each of these reasons might be fundamental and enduring, or whether they may disappear with further improvements and innovations in generative AI. Finally, we articulate a set of implications for end-user programming research, including the possibili
    
[^31]: 数据异常检测增强的早期阿尔茨海默病预测分散专家系统的架构

    Architecture of Data Anomaly Detection-Enhanced Decentralized Expert System for Early-Stage Alzheimer's Disease Prediction. (arXiv:2311.00373v1 [cs.CR])

    [http://arxiv.org/abs/2311.00373](http://arxiv.org/abs/2311.00373)

    这项研究引入了一种突破性的分散专家系统，利用区块链技术和人工智能，结合了强大的异常检测和MRI分析，在早期阿尔茨海默病预测方面取得了重要的创新和贡献。

    

    阿尔茨海默病是一个全球性的健康挑战，需要早期和准确的检测以改善患者结果。磁共振成像（MRI）具有重要的诊断潜力，但其有效分析仍然是一项艰巨的任务。本研究引入了一种突破性的分散专家系统，巧妙地结合了区块链技术和人工智能，以整合对患者提交数据的可靠异常检测。传统的诊断方法在疾病的早期阶段往往会导致延迟和不准确的预测。集中式数据存储库难以管理庞大量的MRI数据，而持续存在的隐私问题阻碍了协作努力。我们的创新解决方案利用分散化来保护数据完整性和患者隐私，依靠区块链技术实现。它不仅强调基于人工智能的MRI分析，还融入了复杂的数据异常检测架构。

    Alzheimer's Disease is a global health challenge that requires early and accurate detection to improve patient outcomes. Magnetic Resonance Imaging (MRI) holds significant diagnostic potential, but its effective analysis remains a formidable task. This study introduces a groundbreaking decentralized expert system that cleverly combines blockchain technology with Artificial Intelligence (AI) to integrate robust anomaly detection for patient-submitted data.  Traditional diagnostic methods often lead to delayed and imprecise predictions, especially in the early stages of the disease. Centralized data repositories struggle to manage the immense volumes of MRI data, and persistent privacy concerns hinder collaborative efforts. Our innovative solution harnesses decentralization to protect data integrity and patient privacy, facilitated by blockchain technology. It not only emphasizes AI-driven MRI analysis but also incorporates a sophisticated data anomaly detection architecture. These mecha
    
[^32]: 基于提示的逻辑语义增强对隐含篇章关系识别的改进

    Prompt-based Logical Semantics Enhancement for Implicit Discourse Relation Recognition. (arXiv:2311.00367v1 [cs.CL])

    [http://arxiv.org/abs/2311.00367](http://arxiv.org/abs/2311.00367)

    本文提出了一种基于提示的逻辑语义增强（PLSE）方法来改进隐含篇章关系识别（IDRR），通过无缝地将与篇章关系相关的知识注入到预训练语言模型中，从而提高IDRR的性能和稳健性。

    

    隐含篇章关系识别（IDRR）是一项在没有明确连接词帮助下推断篇章关系的关键而具有挑战性的任务。最近的研究倾向于利用注释的语义层次结构信息，证明了通过整合语义层次结构可以获得增强的篇章关系表示。然而，IDRR的性能和稳健性受到注释数据的限制。幸运的是，存在大量带有明确连接词的未注释话语，可以用来获取丰富的篇章关系特征。因此，我们提出了一种基于提示的逻辑语义增强（PLSE）方法来改进IDRR。本方法通过基于提示的连接词预测将与篇章关系相关的知识无缝地注入到预训练语言模型中。此外，考虑到基于提示的连接词预测。

    Implicit Discourse Relation Recognition (IDRR), which infers discourse relations without the help of explicit connectives, is still a crucial and challenging task for discourse parsing. Recent works tend to exploit the hierarchical structure information from the annotated senses, which demonstrate enhanced discourse relation representations can be obtained by integrating sense hierarchy. Nevertheless, the performance and robustness for IDRR are significantly constrained by the availability of annotated data. Fortunately, there is a wealth of unannotated utterances with explicit connectives, that can be utilized to acquire enriched discourse relation features. In light of such motivation, we propose a Prompt-based Logical Semantics Enhancement (PLSE) method for IDRR. Essentially, our method seamlessly injects knowledge relevant to discourse relation into pre-trained language models through prompt-based connective prediction. Furthermore, considering the prompt-based connective predictio
    
[^33]: 重新思考对比学习中的样本选择：潜在样本的挖掘

    Rethinking Samples Selection for Contrastive Learning: Mining of Potential Samples. (arXiv:2311.00358v1 [cs.CV])

    [http://arxiv.org/abs/2311.00358](http://arxiv.org/abs/2311.00358)

    这篇论文重新思考了对比学习中的样本选择方法，从而提出了一种更全面的方法，通过综合考虑正负样本，利用数据增强和数据挖掘挖掘潜在样本，并且分析负样本梯度，最终获得了较好的效果。

    

    对比学习通过训练模型使两个图像的特征表示尽可能接近或远离，从而预测它们是否属于同一类别。本文重新思考了对比学习中如何挖掘样本，与其他方法不同，我们的方法更全面，同时考虑了正样本和负样本，并从两个方面挖掘潜在样本：首先，对于正样本，我们考虑了通过数据增强获得的增强样本视图和通过数据挖掘获得的挖掘样本视图。然后，我们使用软权值和硬权值进行加权和组合。其次，考虑到负样本中存在无信息的负样本和误判的负样本，我们从梯度的角度分析负样本，并最终挖掘既不过于困难也不过于容易的负样本作为潜在的负样本，即靠近正样本的负样本。实验结果表明，我们的方法在对比学习中取得了较好的效果。

    Contrastive learning predicts whether two images belong to the same category by training a model to make their feature representations as close or as far away as possible. In this paper, we rethink how to mine samples in contrastive learning, unlike other methods, our approach is more comprehensive, taking into account both positive and negative samples, and mining potential samples from two aspects: First, for positive samples, we consider both the augmented sample views obtained by data augmentation and the mined sample views through data mining. Then, we weight and combine them using both soft and hard weighting strategies. Second, considering the existence of uninformative negative samples and false negative samples in the negative samples, we analyze the negative samples from the gradient perspective and finally mine negative samples that are neither too hard nor too easy as potential negative samples, i.e., those negative samples that are close to positive samples. The experiment
    
[^34]: QFree: 一种用于多智能体强化学习的通用价值函数分解方法

    QFree: A Universal Value Function Factorization for Multi-Agent Reinforcement Learning. (arXiv:2311.00356v1 [cs.AI])

    [http://arxiv.org/abs/2311.00356](http://arxiv.org/abs/2311.00356)

    提出了一种通用的QFree价值函数分解方法，用于提取多智能体强化学习中的最优去中心化策略，并遵循个体-全局最大原则。

    

    集中式训练广泛用于多智能体强化学习中以确保训练过程的稳定性。一旦获得联合策略，设计一种价值函数分解方法以提取代理的最优去中心化策略变得至关重要，该方法需要满足个体-全局最大(IGM)原则。虽然对IGM函数类施加额外限制可以帮助满足要求，但却限制了它在更复杂的多智能体环境中的应用。本文提出一种名为QFree的用于多智能体强化学习的通用价值函数分解方法。首先，我们根据优势函数，开发了满足IGM原则的数学等价条件，确保原则在没有任何妥协的情况下成立，消除了传统方法的保守性。然后，我们建立了一个更具表达力的混合网络架构，可以实现等价的分解。

    Centralized training is widely utilized in the field of multi-agent reinforcement learning (MARL) to assure the stability of training process. Once a joint policy is obtained, it is critical to design a value function factorization method to extract optimal decentralized policies for the agents, which needs to satisfy the individual-global-max (IGM) principle. While imposing additional limitations on the IGM function class can help to meet the requirement, it comes at the cost of restricting its application to more complex multi-agent environments. In this paper, we propose QFree, a universal value function factorization method for MARL. We start by developing mathematical equivalent conditions of the IGM principle based on the advantage function, which ensures that the principle holds without any compromise, removing the conservatism of conventional methods. We then establish a more expressive mixing network architecture that can fulfill the equivalent factorization. In particular, th
    
[^35]: 为目标条件智能体定义开放式学习问题

    A Definition of Open-Ended Learning Problems for Goal-Conditioned Agents. (arXiv:2311.00344v1 [cs.AI])

    [http://arxiv.org/abs/2311.00344](http://arxiv.org/abs/2311.00344)

    本文为开放式学习问题定义了一个关键的基本属性，即无限时间内不断产生新元素。在这基础上，提出了开放式学习问题的概念，并着重研究了开放式目标条件强化学习的子集。

    

    近期的许多机器学习研究论文中都提到了“开放式学习”，但很少有人尝试定义这个术语。更糟糕的是，当仔细研究时，似乎对于开放式学习与连续学习、终身学习或自为目的学习等相关概念的区别没有共识。在本文中，我们致力于解决这种情况。通过阐述这个概念的起源和最近的观点，我们说明了开放式学习通常被认为是一个包含多种属性的复合概念。与这些之前的方法不同，我们提出了将开放式过程的一个关键基本属性与时间无限制地产生新元素相分离的想法。基于此，我们建立了开放式学习问题的概念，并特别关注了开放式目标条件强化学习的子集。

    A lot of recent machine learning research papers have "Open-ended learning" in their title. But very few of them attempt to define what they mean when using the term. Even worse, when looking more closely there seems to be no consensus on what distinguishes open-ended learning from related concepts such as continual learning, lifelong learning or autotelic learning. In this paper, we contribute to fixing this situation. After illustrating the genealogy of the concept and more recent perspectives about what it truly means, we outline that open-ended learning is generally conceived as a composite notion encompassing a set of diverse properties. In contrast with these previous approaches, we propose to isolate a key elementary property of open-ended processes, which is to always produce novel elements from time to time over an infinite horizon. From there, we build the notion of open-ended learning problems and focus in particular on the subset of open-ended goal-conditioned reinforcement
    
[^36]: MetisFL:一种可扩展和高效的联邦学习工作流的尴尬并行控制器

    MetisFL: An Embarrassingly Parallelized Controller for Scalable & Efficient Federated Learning Workflows. (arXiv:2311.00334v1 [cs.LG])

    [http://arxiv.org/abs/2311.00334](http://arxiv.org/abs/2311.00334)

    MetisFL是一种可扩展和高效的联邦学习系统，重点关注联邦控制器的可扩展性和优化。

    

    联邦学习(FL)系统通常由两个核心处理实体组成:联邦控制器和学习器。控制器负责管理在学习器之间执行FL工作流程，学习器负责在其私有数据集上训练和评估联邦模型。在执行FL工作流时，FL系统对参与学习器的计算资源或数据没有控制。尽管最近提出了许多FL系统来促进FL工作流的开发，但这些系统中大多数忽视了控制器的可扩展性。为了满足这一需求，我们设计和开发了一种名为MetisFL的新型FL系统，其中联邦控制器是第一等公民。

    A Federated Learning (FL) system typically consists of two core processing entities: the federation controller and the learners. The controller is responsible for managing the execution of FL workflows across learners and the learners for training and evaluating federated models over their private datasets. While executing an FL workflow, the FL system has no control over the computational resources or data of the participating learners. Still, it is responsible for other operations, such as model aggregation, task dispatching, and scheduling. These computationally heavy operations generally need to be handled by the federation controller. Even though many FL systems have been recently proposed to facilitate the development of FL workflows, most of these systems overlook the scalability of the controller. To meet this need, we designed and developed a novel FL system called MetisFL, where the federation controller is the first-class citizen. MetisFL re-engineers all the operations cond
    
[^37]: 噪声图中的鲁棒图聚类通过元权重

    Robust Graph Clustering via Meta Weighting for Noisy Graphs. (arXiv:2311.00322v1 [cs.LG])

    [http://arxiv.org/abs/2311.00322](http://arxiv.org/abs/2311.00322)

    该论文提出了一种鲁棒的基于元权重的图聚类方法，通过对节点对应权重的自适应调整，能够在存在噪声边的图中找到有意义的聚类。

    

    如何在噪声边上鲁棒地找到图中的有意义的聚类？图聚类是图分析中的一个基本问题，应用于各个领域。最近的研究表明，基于图神经网络（GNN）的方法在图聚类方面取得了有希望的结果。然而，我们观察到它们在存在噪声边的图上的性能明显下降。在这项工作中，我们提出了用于鲁棒GNN-based图聚类的MetaGC。MetaGC采用可分解的聚类损失函数，将其重新表述为节点对之间损失的求和。我们为每个节点对添加可学习的权重，并使用元权重来自适应地调整节点对的权重，使有意义的节点对的权重增加，而不那么有意义的节点对（例如噪声边）的权重减小。我们通过实验证明，MetaGC按照预期学习权重，并且因此在性能上优于其他方法。

    How can we find meaningful clusters in a graph robustly against noise edges? Graph clustering (i.e., dividing nodes into groups of similar ones) is a fundamental problem in graph analysis with applications in various fields. Recent studies have demonstrated that graph neural network (GNN) based approaches yield promising results for graph clustering. However, we observe that their performance degenerates significantly on graphs with noise edges, which are prevalent in practice. In this work, we propose MetaGC for robust GNN-based graph clustering. MetaGC employs a decomposable clustering loss function, which can be rephrased as a sum of losses over node pairs. We add a learnable weight to each node pair, and MetaGC adaptively adjusts the weights of node pairs using meta-weighting so that the weights of meaningful node pairs increase and the weights of less-meaningful ones (e.g., noise edges) decrease. We show empirically that MetaGC learns weights as intended and consequently outperfor
    
[^38]: 无监督的词汇简化方法与上下文扩充

    Unsupervised Lexical Simplification with Context Augmentation. (arXiv:2311.00310v1 [cs.CL])

    [http://arxiv.org/abs/2311.00310](http://arxiv.org/abs/2311.00310)

    我们提出了一种无监督的词汇简化方法，使用单语数据和预训练语言模型，通过生成替代词来简化给定目标词与其上下文，实验证明我们的模型在多个语言上优于其他无监督系统，并在SWORDS数据集上取得了最先进的结果。

    

    我们提出了一种新的无监督词汇简化方法，只使用单语数据和预训练语言模型。通过给定目标词和其上下文，我们的方法基于目标上下文和从单语数据中采样的额外上下文生成替代词。我们在TSAR-2022共享任务上使用英语、葡萄牙语和西班牙语进行实验，并表明我们的模型在所有语言上都明显优于其他无监督系统。我们还通过将我们的模型与GPT-3.5进行集成，建立了一个新的最先进的模型。最后，我们在SWORDS词汇替换数据集上评估我们的模型，取得了最先进的结果。

    We propose a new unsupervised lexical simplification method that uses only monolingual data and pre-trained language models. Given a target word and its context, our method generates substitutes based on the target context and also additional contexts sampled from monolingual data. We conduct experiments in English, Portuguese, and Spanish on the TSAR-2022 shared task, and show that our model substantially outperforms other unsupervised systems across all languages. We also establish a new state-of-the-art by ensembling our model with GPT-3.5. Lastly, we evaluate our model on the SWORDS lexical substitution data set, achieving a state-of-the-art result.
    
[^39]: 从图像到语言: 对视觉问答(VQA)方法、挑战和机会进行的关键分析

    From Image to Language: A Critical Analysis of Visual Question Answering (VQA) Approaches, Challenges, and Opportunities. (arXiv:2311.00308v1 [cs.CV])

    [http://arxiv.org/abs/2311.00308](http://arxiv.org/abs/2311.00308)

    本论文调查了视觉问答(VQA)领域的现有研究，包括传统VQA架构和现代基于视觉语言预训练(VLP)的方法。同时还分析了VQA数据集和方法在历史上的发展，揭示了VLP在VQA中的挑战与机会，为进一步研究提供了指导。

    

    视觉问答(VQA)是一个综合计算机视觉(CV)和自然语言处理(NLP)的多模态任务，旨在对任何视觉输入生成答案。VQA的范围已从关注自然图像的数据集扩展到包含合成图像、视频、3D环境和其他视觉输入的数据集。大型预训练网络的出现使早期依赖特征提取和融合方案的VQA方法转向了视觉语言预训练(VLP)技术。然而，目前缺乏包括传统VQA架构和现代基于VLP的方法在内的综合调查。此外，还没有对VQA视角下的VLP挑战进行深入探讨，留下了可能出现潜在开放问题的空间。本研究在VQA领域提供了一份调查报告，深入探讨了VQA数据集和历史中的方法细节。

    The multimodal task of Visual Question Answering (VQA) encompassing elements of Computer Vision (CV) and Natural Language Processing (NLP), aims to generate answers to questions on any visual input. Over time, the scope of VQA has expanded from datasets focusing on an extensive collection of natural images to datasets featuring synthetic images, video, 3D environments, and various other visual inputs. The emergence of large pre-trained networks has shifted the early VQA approaches relying on feature extraction and fusion schemes to vision language pre-training (VLP) techniques. However, there is a lack of comprehensive surveys that encompass both traditional VQA architectures and contemporary VLP-based methods. Furthermore, the VLP challenges in the lens of VQA haven't been thoroughly explored, leaving room for potential open problems to emerge. Our work presents a survey in the domain of VQA that delves into the intricacies of VQA datasets and methods over the field's history, introdu
    
[^40]: CO2流动模式的推断--可行性研究

    Inference of CO2 flow patterns -- a feasibility study. (arXiv:2311.00290v1 [cs.CE])

    [http://arxiv.org/abs/2311.00290](http://arxiv.org/abs/2311.00290)

    研究对地下CO2泄漏进行监测和检测，提出了一种新的方法来描述CO2流动模式中的不确定性，并强调不确定性评估的重要性。

    

    随着全球碳捕获和封存（CCS）技术在应对气候变化的斗争中的大规模部署，建立稳健的监测和检测机制，以检测潜在的地下CO2泄漏，特别是通过存储库封堵的预先存在或诱导的断层，变得越来越迫切。虽然诸如历史匹配和CO2储存的时间序列地震监测等技术已成功用于跟踪地下CO2渗漏的演化，但这些方法缺乏对CO2波动行为相关不确定性的基本方法。系统评估不确定性的纳入对于风险缓解至关重要，原因如下：（i）CO2波动诱发的变化很小且地震数据噪声很大；（ii）正常和不规则（例如泄漏引起的）流动模式之间的变化很小；（iii）控制流动的储层特性强烈异质且通常

    As the global deployment of carbon capture and sequestration (CCS) technology intensifies in the fight against climate change, it becomes increasingly imperative to establish robust monitoring and detection mechanisms for potential underground CO2 leakage, particularly through pre-existing or induced faults in the storage reservoir's seals. While techniques such as history matching and time-lapse seismic monitoring of CO2 storage have been used successfully in tracking the evolution of CO2 plumes in the subsurface, these methods lack principled approaches to characterize uncertainties related to the CO2 plumes' behavior. Inclusion of systematic assessment of uncertainties is essential for risk mitigation for the following reasons: (i) CO2 plume-induced changes are small and seismic data is noisy; (ii) changes between regular and irregular (e.g., caused by leakage) flow patterns are small; and (iii) the reservoir properties that control the flow are strongly heterogeneous and typically 
    
[^41]: 主动指令调优：通过在敏感指令任务上训练来提高跨任务泛化能力

    Active Instruction Tuning: Improving Cross-Task Generalization by Training on Prompt Sensitive Tasks. (arXiv:2311.00288v1 [cs.CL])

    [http://arxiv.org/abs/2311.00288](http://arxiv.org/abs/2311.00288)

    本文提出了基于提示不确定性的主动指令调优方法，通过选择信息丰富的任务并主动调整模型，提高了跨任务泛化能力。

    

    指令调优（IT）通过在大量多样的任务上使用指令对大型语言模型（LLM）进行训练，取得了令人印象深刻的零样本泛化结果。然而，如何选择新任务以提高IT模型的性能和泛化能力仍然是一个未解决的问题。由于计算要求过高，训练所有现有任务是不可行的，而随机选择任务可能会导致亚优性能。在这项工作中，我们提出了基于提示不确定性的主动指令调优，一种识别信息丰富任务并在选定任务上主动调整模型的新框架。我们用当前模型输出在扰动提示上的不一致性表示新任务的信息丰富性。我们在NIV2和Self-Instruct数据集上的实验证明，我们的方法始终优于其他基准策略的任务选择，同时在更少的训练任务下实现了更好的超出分布的泛化能力。

    Instruction tuning (IT) achieves impressive zero-shot generalization results by training large language models (LLMs) on a massive amount of diverse tasks with instructions. However, how to select new tasks to improve the performance and generalizability of IT models remains an open question. Training on all existing tasks is impractical due to prohibiting computation requirements, and randomly selecting tasks can lead to suboptimal performance. In this work, we propose active instruction tuning based on prompt uncertainty, a novel framework to identify informative tasks, and then actively tune the models on the selected tasks. We represent the informativeness of new tasks with the disagreement of the current model outputs over perturbed prompts. Our experiments on NIV2 and Self-Instruct datasets demonstrate that our method consistently outperforms other baseline strategies for task selection, achieving better out-of-distribution generalization with fewer training tasks. Additionally, 
    
[^42]: 通过大型语言模型的知识注入：评估和推进临床文本数据生成

    Knowledge-Infused Prompting: Assessing and Advancing Clinical Text Data Generation with Large Language Models. (arXiv:2311.00287v1 [cs.CL])

    [http://arxiv.org/abs/2311.00287](http://arxiv.org/abs/2311.00287)

    本文提出了一种通过大型语言模型进行临床文本生成的创新方法ClinGen，该方法将外部领域特定的知识和语言模型结合起来，提高了临床自然语言处理任务的性能，并丰富了样本的多样性。

    

    临床自然语言处理需要能够应对领域特定挑战的方法，例如复杂的医学术语和临床背景。最近，大型语言模型（LLMs）在这个领域显示出了潜力。然而，它们的直接部署可能导致隐私问题，并受到资源限制。为了解决这个挑战，我们深入研究了使用LLMs进行临床NLP任务的合成临床文本生成。我们提出了一种创新的、资源高效的方法ClinGen，它将知识注入到这个过程中。我们的模型涉及临床知识提取和基于上下文的LLM提示。临床主题和写作风格都来自外部领域特定的知识图谱和LLMs，以引导数据生成。我们在7个临床NLP任务和16个数据集上进行了广泛的实证研究，结果显示ClinGen在各种任务中始终提高了性能，有效地使真实数据集的分布对齐，并显著丰富了样本的多样性。

    Clinical natural language processing requires methods that can address domain-specific challenges, such as complex medical terminology and clinical contexts. Recently, large language models (LLMs) have shown promise in this domain. Yet, their direct deployment can lead to privacy issues and are constrained by resources. To address this challenge, we delve into synthetic clinical text generation using LLMs for clinical NLP tasks. We propose an innovative, resource-efficient approach, ClinGen, which infuses knowledge into the process. Our model involves clinical knowledge extraction and context-informed LLM prompting. Both clinical topics and writing styles are drawn from external domain-specific knowledge graphs and LLMs to guide data generation. Our extensive empirical study across 7 clinical NLP tasks and 16 datasets reveals that ClinGen consistently enhances performance across various tasks, effectively aligning the distribution of real datasets and significantly enriching the divers
    
[^43]: JADE：基于语言的LLM安全评估平台

    JADE: A Linguistic-based Safety Evaluation Platform for LLM. (arXiv:2311.00286v1 [cs.CL])

    [http://arxiv.org/abs/2311.00286](http://arxiv.org/abs/2311.00286)

    JADE是一种基于语言分析的LLM安全评估平台，能够破坏广泛使用的中文和英文LLM，并生成高度威胁的不安全问题。

    

    本文介绍了JADE，一种针对语言分析的模糊测试平台，通过增强种子问题的语言复杂性，同时并始终能够破坏广泛使用的三类LLM：八个开源中文LLM，六个商业中文LLM和四个商业英文LLM。JADE为这三类LLM生成了三个安全基准，其中包含高度威胁的不安全问题：这些问题可以同时触发多个LLM的有害生成，平均不安全生成比例为70%（请参见下表），同时这些问题仍然是自然、流畅且保留了核心的不安全语义。我们在以下链接中发布了对商业英文LLM和开源英文LLM生成的基准演示：https://github.com/whitzard-ai/jade-db。对于对JADE生成的更多问题感兴趣的读者，请与我们联系。

    In this paper, we present \textit{JADE}, a targeted linguistic fuzzing platform which strengthens the linguistic complexity of seed questions to simultaneously and consistently break a wide range of widely-used LLMs categorized in three groups: eight open-sourced Chinese, six commercial Chinese and four commercial English LLMs. JADE generates three safety benchmarks for the three groups of LLMs, which contain unsafe questions that are highly threatening: the questions simultaneously trigger harmful generation of multiple LLMs, with an average unsafe generation ratio of \textbf{$70\%$} (please see the table below), while are still natural questions, fluent and preserving the core unsafe semantics. We release the benchmark demos generated for commercial English LLMs and open-sourced English LLMs in the following link: https://github.com/whitzard-ai/jade-db. For readers who are interested in evaluating on more questions generated by JADE, please contact us.  \textit{JADE} is based on Noam
    
[^44]: 利用图像-语言相似度对少样本目标检测进行重新评分

    Re-Scoring Using Image-Language Similarity for Few-Shot Object Detection. (arXiv:2311.00278v1 [cs.CV])

    [http://arxiv.org/abs/2311.00278](http://arxiv.org/abs/2311.00278)

    本文提出了一种基于图像-语言相似度的重新评分方法，用于少样本目标检测。通过使用Contrastive Language-Image Pre-training (CLIP)和背景负面重新缩放损失 (BNRL)等方法，扩展了Faster R-CNN，在低数据设置下能够更好地适应一般化少样本目标检测数据集。实验结果在MS-COCO和PASCAL VOC上验证了该方法的有效性。

    

    少样本目标检测是社区中的一个新兴挑战，主要关注使用少量标注来检测新颖对象。最近的研究表明，采用预训练模型或修改损失函数可以提高性能。本文中，我们探索在低数据设置下利用对比性语言-图像预训练（CLIP）和困难负面分类损失的能力。具体地，我们提出了一种利用图像-语言相似度进行重新评分的少样本目标检测方法（RISF），通过引入使用CLIP的校准模块（CM-CLIP）和背景负面重新缩放损失（BNRL）来扩展Faster R-CNN。前者通过使用图像-类别相似性将检测器的分类得分进行零样本分类，后者是修改的分类损失，考虑了对广义少样本目标检测数据集中虚假背景和混淆类别的惩罚。在MS-COCO和PASCAL VOC上进行了大量实验，结果表明...

    Few-shot object detection, which focuses on detecting novel objects with few labels, is an emerging challenge in the community. Recent studies show that adapting a pre-trained model or modified loss function can improve performance. In this paper, we explore leveraging the power of Contrastive Language-Image Pre-training (CLIP) and hard negative classification loss in low data setting. Specifically, we propose Re-scoring using Image-language Similarity for Few-shot object detection (RISF) which extends Faster R-CNN by introducing Calibration Module using CLIP (CM-CLIP) and Background Negative Re-scale Loss (BNRL). The former adapts CLIP, which performs zero-shot classification, to re-score the classification scores of a detector using image-class similarities, the latter is modified classification loss considering the punishment for fake backgrounds as well as confusing categories on a generalized few-shot object detection dataset. Extensive experiments on MS-COCO and PASCAL VOC show t
    
[^45]: ChatCoder: 基于聊天的需求细化改进了LLMs的代码生成

    ChatCoder: Chat-based Refine Requirement Improves LLMs' Code Generation. (arXiv:2311.00272v1 [cs.SE])

    [http://arxiv.org/abs/2311.00272](http://arxiv.org/abs/2311.00272)

    ChatCoder是一种通过与大规模语言模型聊天来帮助人类用户细化需求的方法，改进了现有大规模语言模型的代码生成性能。

    

    大规模语言模型在生成满足人类需求的代码方面显示出良好的性能。然而，用自然语言表达的人类需求可能含糊、不完整和歧义，导致大规模语言模型误解人类需求并产生错误。更糟糕的是，人类用户很难细化需求。为了帮助人类用户细化需求并提高大规模语言模型的代码生成性能，我们提出了ChatCoder：一种通过与大规模语言模型聊天来细化需求的方法。我们设计了一个聊天方案，其中大规模语言模型将指导人类用户细化需求的表达，使其比以前更加精确、明确和完整。实验证明，ChatCoder大幅提高了现有大规模语言模型的性能。此外，ChatCoder具有优于基于维修的方法和通过人类响应微调的LLMs的优势。

    Large language models have shown good performances in generating code to meet human requirements. However, human requirements expressed in natural languages can be vague, incomplete, and ambiguous, leading large language models to misunderstand human requirements and make mistakes. Worse, it is difficult for a human user to refine the requirement. To help human users refine their requirements and improve large language models' code generation performances, we propose ChatCoder: a method to refine the requirements via chatting with large language models. We design a chat scheme in which the large language models will guide the human users to refine their expression of requirements to be more precise, unambiguous, and complete than before. Experiments show that ChatCoder has improved existing large language models' performance by a large margin. Besides, ChatCoder has the advantage over refine-based methods and LLMs fine-tuned via human response.
    
[^46]: 通过分层强化学习重新思考决策Transformer

    Rethinking Decision Transformer via Hierarchical Reinforcement Learning. (arXiv:2311.00267v1 [cs.LG])

    [http://arxiv.org/abs/2311.00267](http://arxiv.org/abs/2311.00267)

    这篇论文通过引入分层强化学习，重新思考了决策Transformer。他们提出了一个通用的序列建模框架，在该框架中，高层策略为当前状态提供理想提示，低层策略在给定提示的条件下生成动作。他们发现决策Transformer是这个框架的一个特例，并研究了如何共同优化高层和低层策略以实现拼接能力，从而推动了新的离线学习算法的发展。

    

    决策Transformer（DT）是一种利用最近在强化学习中的Transformer架构的创新算法。然而，DT的一个显著局限性是其依赖于从数据集中回忆轨迹的能力，失去了无缝地将次优轨迹拼接在一起的能力。在这项工作中，我们引入了一个用于通过分层强化学习研究序贯决策的通用序列建模框架。在做决策时，高层策略首先为当前状态提出一个理想的提示，低层策略随后在给定的提示条件下生成一个动作。我们展示了DT是这个框架的特例，通过一定的高层和低层策略选择，并讨论了这些选择的潜在失败。受这些观察的启发，我们研究了如何共同优化高层和低层策略以实现拼接能力，进而推动新的离线学习算法的发展。

    Decision Transformer (DT) is an innovative algorithm leveraging recent advances of the transformer architecture in reinforcement learning (RL). However, a notable limitation of DT is its reliance on recalling trajectories from datasets, losing the capability to seamlessly stitch sub-optimal trajectories together. In this work we introduce a general sequence modeling framework for studying sequential decision making through the lens of Hierarchical RL. At the time of making decisions, a high-level policy first proposes an ideal prompt for the current state, a low-level policy subsequently generates an action conditioned on the given prompt. We show DT emerges as a special case of this framework with certain choices of high-level and low-level policies, and discuss the potential failure of these choices. Inspired by these observations, we study how to jointly optimize the high-level and low-level policies to enable the stitching ability, which further leads to the development of new offl
    
[^47]: 基于大型语言模型的对话代理的即插即用策略规划器

    Plug-and-Play Policy Planner for Large Language Model Powered Dialogue Agents. (arXiv:2311.00262v1 [cs.CL])

    [http://arxiv.org/abs/2311.00262](http://arxiv.org/abs/2311.00262)

    基于大型语言模型的对话代理的即插即用策略规划器(PDDPP)引入了一种新的对话策略规划范式，通过可调整的语言模型插件实现主动对话问题的策略制定。利用监督微调和强化学习，该框架在处理新的案例时具有较高的灵活性和性能。

    

    在大型语言模型（LLMs）的时代中，主动对话作为一个实际但具有挑战性的对话问题，对话策略规划是提高LLMs主动性的关键。大多数现有研究使用各种提示方案或通过语言人工智能反馈迭代增强对LLMs的对话策略规划能力。然而，这些方法要么受限于冻结的LLMs的策略规划能力，要么难以转移到新的案例。在这项工作中，我们引入了一种新的对话策略规划范式，以使用可调整的语言模型插件作为即插即用的对话策略规划器来制定LLMs在主动对话问题上的策略，命名为PPDPP。具体而言，我们开发了一个新颖的训练框架，以便利用可用的人工注释数据进行监督微调，并通过基于LLM的自我对弈收集的动态交互数据进行强化学习。

    Proactive dialogues serve as a practical yet challenging dialogue problem in the era of large language models (LLMs), where the dialogue policy planning is the key to improving the proactivity of LLMs. Most existing studies enable the dialogue policy planning of LLMs using various prompting schemes or iteratively enhance this capability in handling the given case with verbal AI feedback. However, these approaches are either bounded by the policy planning capability of the frozen LLMs or hard to be transferred to new cases. In this work, we introduce a new dialogue policy planning paradigm to strategize LLMs for proactive dialogue problems with a tunable language model plug-in as a plug-and-play dialogue policy planner, named PPDPP. Specifically, we develop a novel training framework to facilitate supervised fine-tuning over available human-annotated data as well as reinforcement learning from goal-oriented AI feedback with dynamic interaction data collected by the LLM-based self-play s
    
[^48]: 从反向误差分析角度看多任务和连续学习中的隐式偏差

    Implicit biases in multitask and continual learning from a backward error analysis perspective. (arXiv:2311.00235v1 [stat.ML])

    [http://arxiv.org/abs/2311.00235](http://arxiv.org/abs/2311.00235)

    本论文使用反向误差分析计算了多任务和连续学习设置下神经网络的隐式训练偏差。在训练过程中，通过引入修改损失函数，隐式最小化了原始损失、引入了隐式平坦正则项和冲突项。在多任务中，冲突项衡量了任务梯度之间的对齐性；而在连续学习中，冲突项是深度学习优化中的一个新概念，它通过任务梯度之间的李括号来衡量。

    

    使用反向误差分析，我们计算了用随机梯度下降训练的神经网络在多任务和连续学习设置中的隐式训练偏差。具体而言，我们推导出了在训练过程中隐含地最小化的修改损失函数。它们包括三个项：原始损失函数（考虑收敛性），与学习率成正比的隐式平坦正则项以及最后一个项——冲突项，该项在理论上对收敛性和隐式正则化都可能有害。在多任务中，冲突项是一个众所周知的量，用于衡量任务之间的梯度对齐性，而在连续学习中，冲突项是深度学习优化中的一个新量，尽管在微分几何中是一个基本工具：任务梯度之间的李括号。

    Using backward error analysis, we compute implicit training biases in multitask and continual learning settings for neural networks trained with stochastic gradient descent. In particular, we derive modified losses that are implicitly minimized during training. They have three terms: the original loss, accounting for convergence, an implicit flatness regularization term proportional to the learning rate, and a last term, the conflict term, which can theoretically be detrimental to both convergence and implicit regularization. In multitask, the conflict term is a well-known quantity, measuring the gradient alignment between the tasks, while in continual learning the conflict term is a new quantity in deep learning optimization, although a basic tool in differential geometry: The Lie bracket between the task gradients.
    
[^49]: StableFDG:基于风格和注意力的联邦领域泛化学习

    StableFDG: Style and Attention Based Learning for Federated Domain Generalization. (arXiv:2311.00227v1 [cs.LG])

    [http://arxiv.org/abs/2311.00227](http://arxiv.org/abs/2311.00227)

    本文提出了StableFDG，一种基于风格和注意力的学习策略，用于实现联邦领域泛化。其中，基于风格的学习将每个客户端的本地数据集中的样式扩展到原始源域之外，并通过风格共享、转移和探索策略改进了领域多样性。基于注意力的特征突出器捕捉了数据样本特征之间的相似性。

    

    传统的联邦学习算法在训练（源域）和测试（目标域）中假设数据分布相同。然而，实际应用中常常发生域偏移，因此需要在联邦学习方法中引入领域泛化能力。然而，由于每个客户端的本地数据集中缺乏样本/域，现有的领域泛化算法在联邦学习环境中面临基本挑战。在本文中，我们提出了基于风格和注意力的学习策略StableFDG，用于实现联邦领域泛化，并引入了两个关键贡献。第一个是基于风格的学习，它使每个客户端能够在本地数据集中超越原始源域，探索新颖的风格，基于提出的风格共享、转移和探索策略改进了领域多样性。我们的第二个贡献是基于注意力的特征突出器，它捕捉数据样本特征之间的相似性。

    Traditional federated learning (FL) algorithms operate under the assumption that the data distributions at training (source domains) and testing (target domain) are the same. The fact that domain shifts often occur in practice necessitates equipping FL methods with a domain generalization (DG) capability. However, existing DG algorithms face fundamental challenges in FL setups due to the lack of samples/domains in each client's local dataset. In this paper, we propose StableFDG, a style and attention based learning strategy for accomplishing federated domain generalization, introducing two key contributions. The first is style-based learning, which enables each client to explore novel styles beyond the original source domains in its local dataset, improving domain diversity based on the proposed style sharing, shifting, and exploration strategies. Our second contribution is an attention-based feature highlighter, which captures the similarities between the features of data samples in t
    
[^50]: 基于域分解的物理信息神经网络之间的Schwarz交替法耦合

    Domain decomposition-based coupling of physics-informed neural networks via the Schwarz alternating method. (arXiv:2311.00224v1 [math.NA])

    [http://arxiv.org/abs/2311.00224](http://arxiv.org/abs/2311.00224)

    本文以物理信息神经网络(PINN)为基础，通过域分解和Schwarz交替法耦合PINN与彼此和传统数值模型，以加速训练和解决非线性偏微分方程(PDEs)中的困难问题。

    

    物理信息神经网络(PINNs)是解决非线性偏微分方程(PDEs)和推断解的吸引人的数据驱动工具。与传统神经网络(NNs)只在解决数据上进行训练不同，PINN将PDE的残差结合到其损失函数中，并在解决域上的一组插值点上训练以最小化该残差。本文探讨了使用Schwarz交替法将PINN与彼此和传统数值模型(即通过有限元、有限差分或有限体积方法获得的完全序模型或FOMs)耦合的方法，其中对物理域进行了分解。众所周知，当PDE解具有陡峭的梯度时，训练PINN可能很困难。在这种背景下，我们探讨了使用域分解和Schwarz交替法加速PINN训练阶段的不同方法。

    Physics-informed neural networks (PINNs) are appealing data-driven tools for solving and inferring solutions to nonlinear partial differential equations (PDEs). Unlike traditional neural networks (NNs), which train only on solution data, a PINN incorporates a PDE's residual into its loss function and trains to minimize the said residual at a set of collocation points in the solution domain. This paper explores the use of the Schwarz alternating method as a means to couple PINNs with each other and with conventional numerical models (i.e., full order models, or FOMs, obtained via the finite element, finite difference or finite volume methods) following a decomposition of the physical domain. It is well-known that training a PINN can be difficult when the PDE solution has steep gradients. We investigate herein the use of domain decomposition and the Schwarz alternating method as a means to accelerate the PINN training phase. Within this context, we explore different approaches for imposi
    
[^51]: 能否大型语言模型捕捉全球变暖的公众意见？一项关于算法逼真性和偏见的实证评估

    Can Large Language Models Capture Public Opinion about Global Warming? An Empirical Assessment of Algorithmic Fidelity and Bias. (arXiv:2311.00217v1 [cs.AI])

    [http://arxiv.org/abs/2311.00217](http://arxiv.org/abs/2311.00217)

    本研究评估了大型语言模型（LLMs）的算法逼真性和偏见，并发现LLMs可以有效捕捉总统投票行为，但在准确表示全球变暖观点方面存在挑战。同时，LLMs对某些群体的观点估计存在偏差，特别是对非洲裔美国人对全球变暖的担忧低估。这些结果突出了LLMs在社会科学研究中的潜力，并强调了准确性的重要性。

    

    大型语言模型（LLMs）通过模拟人类的感知和行为，展示了它们在社会科学研究中的潜力，这被称为算法逼真性。本研究通过利用两个代表性的气候变化调查评估LLMs的算法逼真性和偏见。LLMs被条件化为基于人口统计学和/或心理协变量来模拟调查回答。研究结果表明，当相关协变量没有包含在内时，LLMs可以有效捕捉总统投票行为，但在准确表示全球变暖观点方面存在挑战。当LLMs被人口统计学和协变量同时条件化时，GPT-4表现出更好的性能。然而，LLMs对特定群体的观点估计存在差异，LLMs倾向于低估非洲裔美国人对全球变暖的担忧。虽然突出了LLMs在社会科学研究中的潜力，但这些结果强调了精确性的重要性。

    Large language models (LLMs) have demonstrated their potential in social science research by emulating human perceptions and behaviors, a concept referred to as algorithmic fidelity. This study assesses the algorithmic fidelity and bias of LLMs by utilizing two nationally representative climate change surveys. The LLMs were conditioned on demographics and/or psychological covariates to simulate survey responses. The findings indicate that LLMs can effectively capture presidential voting behaviors but encounter challenges in accurately representing global warming perspectives when relevant covariates are not included. GPT-4 exhibits improved performance when conditioned on both demographics and covariates. However, disparities emerge in LLM estimations of the views of certain groups, with LLMs tending to underestimate worry about global warming among Black Americans. While highlighting the potential of LLMs to aid social science research, these results underscore the importance of metic
    
[^52]: 使用合成数据集实现一致的视频到视频转换

    Consistent Video-to-Video Transfer Using Synthetic Dataset. (arXiv:2311.00213v1 [cs.CV])

    [http://arxiv.org/abs/2311.00213](http://arxiv.org/abs/2311.00213)

    本研究提出一种基于合成数据集的视频到视频转换方法，通过文本指令实现高效编辑，并通过引入长视频采样校正确保一致性。在基于文本的视频到视频编辑方面取得了显著进展，为进一步的研究和应用提供了有趣的探索方向。

    

    我们引入了一种新颖高效的基于文本的视频到视频编辑方法，消除了每个视频每个模型的资源密集型微调需求。我们方法的核心是一个为视频到视频转换任务量身定制的合成配对视频数据集。受到Instruct Pix2Pix的图像通过编辑指令进行转换的启发，我们将这一范式应用于视频领域。我们对Prompt-to-Prompt进行了拓展，高效生成配对样本，每个样本都包含一个输入视频和其编辑后的对应视频。同时，在采样过程中引入了长视频采样校正，确保批次之间的长视频一致性。我们的方法超过了当前的Tune-A-Video等方法，在基于文本的视频到视频编辑方面取得了显著的进展，并为进一步的研究和应用提供了有趣的探索方向。

    We introduce a novel and efficient approach for text-based video-to-video editing that eliminates the need for resource-intensive per-video-per-model finetuning. At the core of our approach is a synthetic paired video dataset tailored for video-to-video transfer tasks. Inspired by Instruct Pix2Pix's image transfer via editing instruction, we adapt this paradigm to the video domain. Extending the Prompt-to-Prompt to videos, we efficiently generate paired samples, each with an input video and its edited counterpart. Alongside this, we introduce the Long Video Sampling Correction during sampling, ensuring consistent long videos across batches. Our method surpasses current methods like Tune-A-Video, heralding substantial progress in text-based video-to-video editing and suggesting exciting avenues for further exploration and deployment.
    
[^53]: Magmaw: 对基于机器学习的无线通信系统的模态不可知对抗攻击

    Magmaw: Modality-Agnostic Adversarial Attacks on Machine Learning-Based Wireless Communication Systems. (arXiv:2311.00207v1 [cs.CR])

    [http://arxiv.org/abs/2311.00207](http://arxiv.org/abs/2311.00207)

    本文提出了Magmaw，这是一种针对基于机器学习的无线通信系统进行模态不可知对抗攻击的黑盒攻击方法。它能够生成通用的对抗扰动，并引入了新的攻击目标。实验证实了其对现有防御方法的韧性。使用实时无线攻击平台进行了概念验证。

    

    机器学习在合并端到端无线通信系统的所有物理层模块以实现联合收发器优化方面发挥了重要作用。尽管已经有许多针对基于机器学习的无线系统的对抗攻击方法，但现有方法并未提供包括源数据的多模态、共同的物理层组件和无线领域约束在内的全面视角。本文提出了Magmaw，这是一种能够针对通过无线信道传输的任何多模态信号生成通用对抗扰动的黑盒攻击方法。我们进一步对基于机器学习的下游应用的对抗攻击引入了新的目标。实验证实了该攻击对现有广泛使用的对抗训练和扰动信号减法防御方法的韧性。为了概念证明，我们使用软件定义无线电系统构建了一个实时无线攻击平台。

    Machine Learning (ML) has been instrumental in enabling joint transceiver optimization by merging all physical layer blocks of the end-to-end wireless communication systems. Although there have been a number of adversarial attacks on ML-based wireless systems, the existing methods do not provide a comprehensive view including multi-modality of the source data, common physical layer components, and wireless domain constraints. This paper proposes Magmaw, the first black-box attack methodology capable of generating universal adversarial perturbations for any multimodal signal transmitted over a wireless channel. We further introduce new objectives for adversarial attacks on ML-based downstream applications. The resilience of the attack to the existing widely used defense methods of adversarial training and perturbation signal subtraction is experimentally verified. For proof-of-concept evaluation, we build a real-time wireless attack platform using a software-defined radio system. Experi
    
[^54]: 基于ChatGPT的层次比较用于图像分类

    ChatGPT-Powered Hierarchical Comparisons for Image Classification. (arXiv:2311.00206v1 [cs.CV])

    [http://arxiv.org/abs/2311.00206](http://arxiv.org/abs/2311.00206)

    本文介绍了一种基于ChatGPT的层次比较方法，用于解决图像分类中的零样本开放词汇挑战。该方法通过递归地将类别进行分组，并在每个层次级别上比较图像与文本的嵌入，实现了直观、有效和可解释的图像分类。

    

    针对图像分类中的零样本开放词汇挑战，我们利用预训练视觉-语言模型（如CLIP）来解决问题。CLIP从大型语言模型（如ChatGPT）中获益，将类别特定知识融入其中。然而，CLIP中存在偏差导致不同但相关类别具有相似的描述，因此我们提出了一种新颖的图像分类框架，通过层次比较将类别递归地分组，并通过比较每个层次的图像-文本嵌入来进行图像分类，从而实现直观、有效和可解释的方法。

    The zero-shot open-vocabulary challenge in image classification is tackled by pretrained vision-language models like CLIP, which benefit from incorporating class-specific knowledge from large language models (LLMs) like ChatGPT. However, biases in CLIP lead to similar descriptions for distinct but related classes, prompting our novel image classification framework via hierarchical comparisons: using LLMs to recursively group classes into hierarchies and classifying images by comparing image-text embeddings at each hierarchy level, resulting in an intuitive, effective, and explainable approach.
    
[^55]: 在医学问题回答中，领域特定语言模型的连续训练和微调

    Continuous Training and Fine-tuning for Domain-Specific Language Models in Medical Question Answering. (arXiv:2311.00204v1 [cs.CL])

    [http://arxiv.org/abs/2311.00204](http://arxiv.org/abs/2311.00204)

    本研究提出了一种连续训练和微调的方法，通过在中文医学数据上进行训练和微调，快速适应Llama 2基础模型到中文医学领域。实验结果表明，这种方法有效，生成的模型与GPT-3.5-turbo相媲美，但使用的计算资源更少。这为在不同领域进行大型语言模型的领域特定训练提供了一个模板。

    

    大型语言模型具有良好的通用能力，但往往缺乏领域特定任务的专业知识。通过从基础模型中开发领域专家，可以在不会造成过高训练成本的情况下实现多种应用。本研究展示了一种使用连续训练和指导微调的方法，以快速适应中文医学领域的Llama 2基础模型。我们首先对来自中国医学参考资料的10亿个标记进行连续训练，以教授相关的词汇和知识。然后，我们在来自中国国家医疗执业医师资格考试的5.4万个示例上对模型进行微调。在中文医学数据上的实验验证了这种方法的有效性，生成了一个与GPT-3.5-turbo相媲美的模型，同时使用的计算资源要少得多。最终得到的领域特定模型可以在各种中文医学应用中发挥作用。更广泛地说，这为在缺乏专业知识的领域中进行大型语言模型的领域特定训练提供了一个模板。

    Large language models exhibit promising general capabilities but often lack specialized knowledge for domain-specific tasks. Developing domain experts from a base model enables a range of applications without prohibitive training costs. This work demonstrates a method using continuous training and instruction fine-tuning to rapidly adapt Llama 2 base models to the Chinese medical domain. We first conduct continuous training on 1B tokens from Chinese medical references to teach relevant vocabulary and knowledge. The models are then fine-tuned on 54K examples sourced from the Chinese National Medical Licensing Examination. Experiments on Chinese medical data confirm the effectiveness of this approach, producing a model comparable to GPT-3.5-turbo while using way less computational resource. The resulting domain-specific model could be useful for various Chinese medical applications. More broadly, this provides a template for domain-specific training of large language models in areas wher
    
[^56]: 跨多元社区模拟注释者注释以建模毒性评论识别中的主观性

    Modeling subjectivity (by Mimicking Annotator Annotation) in toxic comment identification across diverse communities. (arXiv:2311.00203v1 [cs.AI])

    [http://arxiv.org/abs/2311.00203](http://arxiv.org/abs/2311.00203)

    本文通过模拟注释者的注释，跨多元社区模型主观性，以解决毒性评论识别的挑战。

    

    在线毒性讨论的流行和影响使内容审核成为至关重要的任务。自动化系统在识别毒性和减少对人工审核的依赖方面发挥着重要作用。然而，针对不同社区的毒性评论识别仍然存在挑战，本文对此进行了探讨。本研究的两个目标是：（1）使用定量分析确定注释者分歧的直观差异，（2）模拟这些观点的主观性。为了实现这个目标，我们发布了一个新的数据集\footnote{\url{https://github.com/XXX}}，其中包含专家注释者的注释，并使用其他两个公开数据集来识别毒性的主观性。利用大型语言模型(LLM)，我们评估了模型在模仿多元化毒性观点方面的能力，通过变化训练数据的大小和利用与模型训练过程中使用的测试集相同的注释者作为测试集，以及另外一组注释者作为测试集。

    The prevalence and impact of toxic discussions online have made content moderation crucial.Automated systems can play a vital role in identifying toxicity, and reducing the reliance on human moderation.Nevertheless, identifying toxic comments for diverse communities continues to present challenges that are addressed in this paper.The two-part goal of this study is to(1)identify intuitive variances from annotator disagreement using quantitative analysis and (2)model the subjectivity of these viewpoints.To achieve our goal, we published a new dataset\footnote{\url{https://github.com/XXX}} with expert annotators' annotations and used two other public datasets to identify the subjectivity of toxicity.Then leveraging the Large Language Model(LLM),we evaluate the model's ability to mimic diverse viewpoints on toxicity by varying size of the training data and utilizing same set of annotators as the test set used during model training and a separate set of annotators as the test set.We conclud
    
[^57]: 多任务强化学习的联邦自然策略梯度方法

    Federated Natural Policy Gradient Methods for Multi-task Reinforcement Learning. (arXiv:2311.00201v1 [cs.LG])

    [http://arxiv.org/abs/2311.00201](http://arxiv.org/abs/2311.00201)

    本研究提出了一种多任务强化学习的联邦自然策略梯度方法，在分布式环境中，通过优化全局策略以最大化所有智能体的总奖励，实现协作决策。这些方法不受信息共享不完备的影响，且具有非渐近全局收敛保证。

    

    联邦强化学习使得多个分布式智能体可以在不共享本地数据轨迹的情况下进行协作决策。本文考虑了多任务设置，其中每个智能体都有自己的私有奖励函数对应不同的任务，同时共享环境的相同转移核。针对无限时间步标记马尔可夫决策过程，目标是学习出一种全局最优策略，在分散的方式下，最大化所有智能体的折扣总奖励之和，其中每个智能体仅与其在给定图拓扑中的邻居进行通信。我们在 softmax 参数化下开展了联邦纯粹和熵正则化的自然策略梯度（NPG）方法，其中将梯度跟踪应用于全局 Q 函数，以减轻信息共享不完备的影响。我们在精确策略评估下建立了非渐近全局收敛保证，这些保证几乎是独立的。

    Federated reinforcement learning (RL) enables collaborative decision making of multiple distributed agents without sharing local data trajectories. In this work, we consider a multi-task setting, in which each agent has its own private reward function corresponding to different tasks, while sharing the same transition kernel of the environment. Focusing on infinite-horizon tabular Markov decision processes, the goal is to learn a globally optimal policy that maximizes the sum of the discounted total rewards of all the agents in a decentralized manner, where each agent only communicates with its neighbors over some prescribed graph topology. We develop federated vanilla and entropy-regularized natural policy gradient (NPG) methods under softmax parameterization, where gradient tracking is applied to the global Q-function to mitigate the impact of imperfect information sharing. We establish non-asymptotic global convergence guarantees under exact policy evaluation, which are nearly indep
    
[^58]: 大规模多机器人组装规划用于自主制造

    Large-Scale Multi-Robot Assembly Planning for Autonomous Manufacturing. (arXiv:2311.00192v1 [cs.RO])

    [http://arxiv.org/abs/2311.00192](http://arxiv.org/abs/2311.00192)

    本论文提出了一个大规模多机器人组装规划的算法堆栈，可以在短时间内合成复杂装配的建造计划，并解决了移动自主机器人在制造中面临的挑战。

    

    移动自主机器人有潜力革新制造流程。然而，将大型机器人群体应用于制造领域需要解决一些挑战，包括在共享工作空间中实现无碰撞移动，有效的多机器人协作来操纵和运输大型负载，由于耦合的制造流程导致复杂的任务分配，以及嵌套子装配件的并行装配和运输的空间规划。我们提出了一个完整的算法堆栈，用于大规模多机器人组装规划，可以在几分钟内合成具有数千个部件的复杂装配的建造计划。我们的方法接受类似CAD的产品规范，并自动为一组机器人规划全栈装配过程来制造产品。我们提出了一个算法堆栈，包括：(i)迭代径向布局优化过程，定义制造过程的全局调度布局。

    Mobile autonomous robots have the potential to revolutionize manufacturing processes. However, employing large robot fleets in manufacturing requires addressing challenges including collision-free movement in a shared workspace, effective multi-robot collaboration to manipulate and transport large payloads, complex task allocation due to coupled manufacturing processes, and spatial planning for parallel assembly and transportation of nested subassemblies. We propose a full algorithmic stack for large-scale multi-robot assembly planning that addresses these challenges and can synthesize construction plans for complex assemblies with thousands of parts in a matter of minutes. Our approach takes in a CAD-like product specification and automatically plans a full-stack assembly procedure for a group of robots to manufacture the product. We propose an algorithmic stack that comprises: (i) an iterative radial layout optimization procedure to define a global staging layout for the manufacturin
    
[^59]: XAI-CLASS：具有极弱监督的解释增强文本分类

    XAI-CLASS: Explanation-Enhanced Text Classification with Extremely Weak Supervision. (arXiv:2311.00189v1 [cs.CL])

    [http://arxiv.org/abs/2311.00189](http://arxiv.org/abs/2311.00189)

    XAI-CLASS是一种解释增强的极弱监督文本分类方法，通过在训练过程中结合生成的伪标签的解释和单词的显著性，实现了在最小或没有人工注释的情况下进行文本分类。

    

    文本分类旨在将文档有效地分类到预定义的类别中。传统的文本分类方法通常依赖于大量手动注释的训练数据，使得这个过程耗时且劳动密集。为了解决这个问题，最近的研究集中在弱监督和极弱监督环境中，分别需要最少或没有人工注释。在先前的弱监督文本分类方法中，通过将伪标签分配给与特定类别对齐（例如，关键词匹配）的文档来生成伪训练数据。然而，这些方法忽略了在文本分类训练过程中将生成的伪标签的解释或个体单词的显著性作为额外指导的重要性。为了解决这个局限性，我们提出了XAI-CLASS，这是一种新颖的解释增强极弱监督文本分类方法。

    Text classification aims to effectively categorize documents into pre-defined categories. Traditional methods for text classification often rely on large amounts of manually annotated training data, making the process time-consuming and labor-intensive. To address this issue, recent studies have focused on weakly-supervised and extremely weakly-supervised settings, which require minimal or no human annotation, respectively. In previous methods of weakly supervised text classification, pseudo-training data is generated by assigning pseudo-labels to documents based on their alignment (e.g., keyword matching) with specific classes. However, these methods ignore the importance of incorporating the explanations of the generated pseudo-labels, or saliency of individual words, as additional guidance during the text classification training process. To address this limitation, we propose XAI-CLASS, a novel explanation-enhanced extremely weakly-supervised text classification method that incorpor
    
[^60]: 大型语言模型的鲁棒安全分类器：对抗性提示屏蔽

    Robust Safety Classifier for Large Language Models: Adversarial Prompt Shield. (arXiv:2311.00172v1 [cs.CL])

    [http://arxiv.org/abs/2311.00172](http://arxiv.org/abs/2311.00172)

    本研究介绍了对抗性提示屏蔽（APS）模型以及自动生成对抗性训练数据集的新策略。APS模型在检测准确性方面表现出色且具有韧性，并且BAND数据集可以增强安全分类器的鲁棒性。

    

    大型语言模型的安全性仍然是一个重要关注点，因为它们容易受到对抗性攻击的影响，这可能导致这些系统产生有害的回应。在这些系统的核心是一个安全分类器，这是一个计算模型，被训练来辨别和减轻潜在的有害、冒犯或不道德的输出。然而，尽管潜力巨大，现代的安全分类器通常在暴露于充满对抗性噪声的输入时失败。为此，我们的研究引入了对抗性提示屏蔽（APS），这是一个轻量级模型，在检测准确性方面表现出色，并展示了对抗性提示的韧性。此外，我们提出了自动生成对抗性训练数据集的新策略，称为Bot Adversarial Noisy Dialogue (BAND) 数据集。这些数据集旨在增强安全分类器的鲁棒性，并研究了将对抗性样本纳入训练过程的后果。通过评估实验证明...

    Large Language Models' safety remains a critical concern due to their vulnerability to adversarial attacks, which can prompt these systems to produce harmful responses. In the heart of these systems lies a safety classifier, a computational model trained to discern and mitigate potentially harmful, offensive, or unethical outputs. However, contemporary safety classifiers, despite their potential, often fail when exposed to inputs infused with adversarial noise. In response, our study introduces the Adversarial Prompt Shield (APS), a lightweight model that excels in detection accuracy and demonstrates resilience against adversarial prompts. Additionally, we propose novel strategies for autonomously generating adversarial training datasets, named Bot Adversarial Noisy Dialogue (BAND) datasets. These datasets are designed to fortify the safety classifier's robustness, and we investigate the consequences of incorporating adversarial examples into the training process. Through evaluations i
    
[^61]: 超越批判性仇恨：解决语言中隐含的偏见和刻板印象的策略

    Beyond Denouncing Hate: Strategies for Countering Implied Biases and Stereotypes in Language. (arXiv:2311.00161v1 [cs.CL])

    [http://arxiv.org/abs/2311.00161](http://arxiv.org/abs/2311.00161)

    本研究通过心理学和哲学文献提出六种挑战恶意语言刻板印象的策略，并通过人类和机器生成的对话数据集对其有效性进行比较。结果显示，人类编写的对话使用更具体的策略，而机器生成的对话使用较为普遍的策略。

    

    反对怀有恶意的言论的对话已经成为一种越来越受欢迎的解决方式，以避免对线上恶意言论进行审查。然而，适当地对付恶意语言需要打破和驳斥这些语言所暗示的不准确刻板印象。在这项研究中，我们从心理学和哲学文献中汲取灵感，提出了六种心理学上启发的策略来挑战恶意语言所暗示的刻板印象。我们首先通过用户研究来研究每种策略的说服力，然后比较人类和机器生成的对话数据集中使用这些策略的情况。我们的结果表明，人类编写的对话使用了更与所暗示的刻板印象相关的挑战策略（例如，刻板印象的反例，关于刻板印象来源的外部因素），而机器生成的对话使用了更不具体的策略（例如，普遍抨击刻板印象）。

    Counterspeech, i.e., responses to counteract potential harms of hateful speech, has become an increasingly popular solution to address online hate speech without censorship. However, properly countering hateful language requires countering and dispelling the underlying inaccurate stereotypes implied by such language. In this work, we draw from psychology and philosophy literature to craft six psychologically inspired strategies to challenge the underlying stereotypical implications of hateful language. We first examine the convincingness of each of these strategies through a user study, and then compare their usages in both human- and machine-generated counterspeech datasets. Our results show that human-written counterspeech uses countering strategies that are more specific to the implied stereotype (e.g., counter examples to the stereotype, external factors about the stereotype's origins), whereas machine-generated counterspeech uses less specific strategies (e.g., generally denouncin
    
[^62]: 一个更快的扩散指数积分器采样器的得分归一化

    Score Normalization for a Faster Diffusion Exponential Integrator Sampler. (arXiv:2311.00157v1 [cs.LG])

    [http://arxiv.org/abs/2311.00157](http://arxiv.org/abs/2311.00157)

    该论文提出了一种得分归一化方法，用于改进扩散指数积分器采样器的生成质量和减小积分误差。

    

    最近，张等人提出了一种用于从扩散模型中快速生成样本的扩散指数积分器采样器（DEIS）。它利用概率流常微分方程（ODE）的半线性特性来大大减小积分误差，并在低函数评估次数（NFEs）时提高生成质量。这种方法的关键是得分函数重参数化，它通过减少在每个积分步骤中使用固定得分函数估计而引起的积分误差。原始作者使用了用于噪声预测训练的模型默认的参数化方法，即将得分乘以条件正向噪声分布的标准差。然而，我们发现，尽管这种得分参数化的绝对平均值在大部分反向采样过程中接近常数，但在采样结束时它会迅速变化。为了简单修复这个问题，我们建议对得分进行重新参数化（在...

    Recently, zhang et al have proposed the Diffusion Exponential Integrator Sampler (DEIS) for fast generation of samples from Diffusion Models. It leverages the semi-linear nature of the probability flow ordinary differential equation (ODE) in order to greatly reduce integration error and improve generation quality at low numbers of function evaluations (NFEs). Key to this approach is the score function reparameterisation, which reduces the integration error incurred from using a fixed score function estimate over each integration step. The original authors use the default parameterisation used by models trained for noise prediction -- multiply the score by the standard deviation of the conditional forward noising distribution. We find that although the mean absolute value of this score parameterisation is close to constant for a large portion of the reverse sampling process, it changes rapidly at the end of sampling. As a simple fix, we propose to instead reparameterise the score (at in
    
[^63]: RIR-SF: 基于房间冲激响应的多通道多说话人ASR的空间特征

    RIR-SF: Room Impulse Response Based Spatial Feature for Multi-channel Multi-talker ASR. (arXiv:2311.00146v1 [eess.AS])

    [http://arxiv.org/abs/2311.00146](http://arxiv.org/abs/2311.00146)

    本研究引入了一种新颖的房间冲激响应（RIR）基于的空间特征RIR-SF，通过与已有的3D空间特征进行比较，表明RIR-SF在多通道多说话人ASR系统中表现优越，相对降低了21.3％的字符错误率（CER），并且对强混响具有鲁棒性。

    

    多通道多说话人自动语音识别（ASR）在语音领域中面临持续挑战，尤其是在面对显著的混响效果时。本研究引入了一种新颖的方法，将重叠的语音信号与目标说话人传输到麦克风阵列的房间冲激响应（RIR）进行卷积。这种创新技术产生了一种名为RIR-SF的新型空间特征。通过与先前建立的3D空间特征进行全面比较，理论分析和实验结果都证实了我们提出的RIR-SF的优越性。我们证明了RIR-SF在多通道多说话人ASR系统中表现优越，导致了字符错误率（CER）的显著相对降低21.3％。重要的是，这种新颖的特征对强混响具有鲁棒性，超越了先前方法的限制。

    Multi-channel multi-talker automatic speech recognition (ASR) presents ongoing challenges within the speech community, particularly when confronted with significant reverberation effects. In this study, we introduce a novel approach involving the convolution of overlapping speech signals with the room impulse response (RIR) corresponding to the target speaker's transmission to a microphone array. This innovative technique yields a novel spatial feature known as the RIR-SF. Through a comprehensive comparison with the previously established state-of-the-art 3D spatial feature, both theoretical analysis and experimental results substantiate the superiority of our proposed RIR-SF. We demonstrate that the RIR-SF outperforms existing methods, leading to a remarkable 21.3\% relative reduction in the Character Error Rate (CER) in multi-channel multi-talker ASR systems. Importantly, this novel feature exhibits robustness in the face of strong reverberation, surpassing the limitations of previou
    
[^64]: 伊朗2021年总统选举期间，使用轴嵌入的两阶段分类器进行政治用户推文中的负面情绪检测：案例研究

    Two-Stage Classifier for Campaign Negativity Detection using Axis Embeddings: A Case Study on Tweets of Political Users during 2021 Presidential Election in Iran. (arXiv:2311.00143v1 [cs.LG])

    [http://arxiv.org/abs/2311.00143](http://arxiv.org/abs/2311.00143)

    本文提出了一个混合模型，用于检测竞选活动的负面情绪，包括一个两阶段分类器，结合了两个机器学习模型的优势。通过对伊朗2021年总统选举期间50名政治用户的5,100条波斯语推文进行标注，建立了所需的数据集。

    

    在全球各地的选举中，候选人可能会因失败前景和时间压力而将他们的竞选活动转向负面情绪。在数字时代，Twitter等社交媒体平台是政治话语的丰富来源。因此，尽管Twitter上发布了大量数据，但自动化的竞选负面情绪检测系统在理解候选人和政党在竞选活动中的策略方面起着至关重要的作用。在本文中，我们提出了一个混合模型，用于检测竞选活动的负面情绪，包括一个两阶段分类器，结合了两个机器学习模型的优势。在此，我们收集了来自50名政治用户（包括候选人和政府官员）的波斯语推文。然后，我们标注了其中5,100条推文，这些推文是在伊朗2021年总统选举前的一年内发布的。在提出的模型中，首先通过推文嵌入与轴的余弦相似性来建立两个分类器所需的数据集。

    In elections around the world, the candidates may turn their campaigns toward negativity due to the prospect of failure and time pressure. In the digital age, social media platforms such as Twitter are rich sources of political discourse. Therefore, despite the large amount of data that is published on Twitter, the automatic system for campaign negativity detection can play an essential role in understanding the strategy of candidates and parties in their campaigns. In this paper, we propose a hybrid model for detecting campaign negativity consisting of a two-stage classifier that combines the strengths of two machine learning models. Here, we have collected Persian tweets from 50 political users, including candidates and government officials. Then we annotated 5,100 of them that were published during the year before the 2021 presidential election in Iran. In the proposed model, first, the required datasets of two classifiers based on the cosine similarity of tweet embeddings with axis
    
[^65]: Q-Learning用于通用信息结构和非马尔可夫环境下的随机控制

    Q-Learning for Stochastic Control under General Information Structures and Non-Markovian Environments. (arXiv:2311.00123v1 [math.OC])

    [http://arxiv.org/abs/2311.00123](http://arxiv.org/abs/2311.00123)

    该论文主要贡献是提出了一个对于非马尔可夫环境下的随机迭代（特别是Q-learning迭代）进行收敛的定理，并给出了收敛条件。其次，讨论了该定理在多种具有非马尔可夫环境的随机控制问题中的应用。

    

    作为主要贡献，我们提出了一个收敛定理，特别是对于一般的、可能为非马尔可夫的随机环境下的Q-学习迭代。我们的收敛条件涉及到一个遍历性和一个正性准则。我们对迭代的极限和收敛的环境和初始化条件进行了精确的描述。作为我们的第二个贡献，我们讨论了这个定理对于多种具有非马尔可夫环境的随机控制问题的影响和应用，其中包括(i)连续空间的完全观测马尔科夫决策过程（MDPs）的量化近似（量化破坏了马尔可夫结构），(ii)量化近似的置信MDP约化部分可观察MDPS（POMDPs） with 弱Feller连续性和滤波器稳定的轻微版本（控制器需要了解模型），(iii)有限窗口近似。

    As a primary contribution, we present a convergence theorem for stochastic iterations, and in particular, Q-learning iterates, under a general, possibly non-Markovian, stochastic environment. Our conditions for convergence involve an ergodicity and a positivity criterion. We provide a precise characterization on the limit of the iterates and conditions on the environment and initializations for convergence. As our second contribution, we discuss the implications and applications of this theorem to a variety of stochastic control problems with non-Markovian environments involving (i) quantized approximations of fully observed Markov Decision Processes (MDPs) with continuous spaces (where quantization break down the Markovian structure), (ii) quantized approximations of belief-MDP reduced partially observable MDPS (POMDPs) with weak Feller continuity and a mild version of filter stability (which requires the knowledge of the model by the controller), (iii) finite window approximations of
    
[^66]: 为了在标签噪音下进行稳健学习，基于Bandit驱动的批次选择方法

    Bandit-Driven Batch Selection for Robust Learning under Label Noise. (arXiv:2311.00096v1 [cs.LG])

    [http://arxiv.org/abs/2311.00096](http://arxiv.org/abs/2311.00096)

    本研究提出了一种基于Bandit算法的批次选择方法，以改善在标签噪音下的学习过程。实验证明该方法在不同水平的标签污染下表现优于现有方法，且无需使用辅助神经网络模型。

    

    我们引入了一种新颖的方法，利用组合赌博算法来选择随机梯度下降（SGD）训练中的批次。我们的方法侧重于在现实世界数据集中普遍存在的标签噪音的情况下优化学习过程。在CIFAR-10数据集上的实验评估表明，我们的方法在不同水平的标签污染下始终优于现有方法。重要的是，我们在没有带来常见的辅助神经网络模型的计算开销的情况下实现了这种优越性能。该工作提供了计算效率和模型效能之间的平衡折衷，为复杂的机器学习应用提供了可扩展的解决方案。

    We introduce a novel approach for batch selection in Stochastic Gradient Descent (SGD) training, leveraging combinatorial bandit algorithms. Our methodology focuses on optimizing the learning process in the presence of label noise, a prevalent issue in real-world datasets. Experimental evaluations on the CIFAR-10 dataset reveal that our approach consistently outperforms existing methods across various levels of label corruption. Importantly, we achieve this superior performance without incurring the computational overhead commonly associated with auxiliary neural network models. This work presents a balanced trade-off between computational efficiency and model efficacy, offering a scalable solution for complex machine learning applications.
    
[^67]: 表达建模对于离线强化学习不足：可处理的推理角度

    Expressive Modeling Is Insufficient for Offline RL: A Tractable Inference Perspective. (arXiv:2311.00094v1 [cs.LG])

    [http://arxiv.org/abs/2311.00094](http://arxiv.org/abs/2311.00094)

    本文指出，在离线强化学习任务中，除了表达性强的序列模型，可处理性也起着重要的作用。由于离线数据收集策略和环境动态的随机性，需要精确且高效地回答各种概率查询，以找到有奖励的动作。基于此，本文提出了Trifle（离线强化学习的可处理推理）方法，利用现代可处理概率模型来解决这个问题。

    

    离线强化学习任务中，一种流行的范例是先将离线轨迹拟合到一个序列模型中，然后通过该模型提示高期望回报的动作。虽然普遍认为表达性更强的序列模型可以带来更好的性能，但本文强调了可处理性，即精确而高效地回答各种概率查询的能力，同样起着重要的作用。具体而言，由于离线数据收集策略和环境动态带来的基本随机性，需要进行高度非平凡的条件/约束生成，以引出有奖励的动作。虽然仍然可以近似处理这些查询，但我们观察到这种粗糙的估计显著削弱了表达性强的序列模型带来的好处。为了解决这个问题，本文提出了Trifle（离线强化学习的可处理推理），它利用了现代可处理概率模型（TPM）来弥合这个差距。

    A popular paradigm for offline Reinforcement Learning (RL) tasks is to first fit the offline trajectories to a sequence model, and then prompt the model for actions that lead to high expected return. While a common consensus is that more expressive sequence models imply better performance, this paper highlights that tractability, the ability to exactly and efficiently answer various probabilistic queries, plays an equally important role. Specifically, due to the fundamental stochasticity from the offline data-collection policies and the environment dynamics, highly non-trivial conditional/constrained generation is required to elicit rewarding actions. While it is still possible to approximate such queries, we observe that such crude estimates significantly undermine the benefits brought by expressive sequence models. To overcome this problem, this paper proposes Trifle (Tractable Inference for Offline RL), which leverages modern Tractable Probabilistic Models (TPMs) to bridge the gap b
    
[^68]: 使用过滤强化学习的无人机安全多智能体运动规划在不确定性下研究

    Safe multi-agent motion planning under uncertainty for drones using filtered reinforcement learning. (arXiv:2311.00063v1 [cs.RO])

    [http://arxiv.org/abs/2311.00063](http://arxiv.org/abs/2311.00063)

    这篇论文提出了一种基于过滤强化学习的无人机安全多智能体运动规划方法，通过结合强化学习和约束控制技术，在不确定性环境中实现了安全性、实时性和高效性。

    

    我们考虑在不确定、混乱的工作空间中，针对无人机的安全多智能体运动规划问题。为了解决这个问题，我们提出了一个可行的运动规划器，它结合了强化学习和基于约束控制的轨迹规划的优点。首先，我们使用单智能体的强化学习从数据中学习到达目标的运动方案，但这些方案可能不是无碰撞的。接下来，我们使用凸优化、概率约束和集合方法来进行约束控制，以确保尽管工作空间、智能体运动和感知不确定，仍能保持安全。所提出的方法可以处理智能体的状态和控制约束，并以很高的概率实现智能体之间以及与工作空间中的静态障碍物的碰撞避免。所提出的方法提供了一个安全的、实时可行的、比仅基于学习的方法更简单训练的多智能体运动规划器。数值模拟和实验显示了方法的有效性。

    We consider the problem of safe multi-agent motion planning for drones in uncertain, cluttered workspaces. For this problem, we present a tractable motion planner that builds upon the strengths of reinforcement learning and constrained-control-based trajectory planning. First, we use single-agent reinforcement learning to learn motion plans from data that reach the target but may not be collision-free. Next, we use a convex optimization, chance constraints, and set-based methods for constrained control to ensure safety, despite the uncertainty in the workspace, agent motion, and sensing. The proposed approach can handle state and control constraints on the agents, and enforce collision avoidance among themselves and with static obstacles in the workspace with high probability. The proposed approach yields a safe, real-time implementable, multi-agent motion planner that is simpler to train than methods based solely on learning. Numerical simulations and experiments show the efficacy of 
    
[^69]: 生成型AI的悖论：“它可以创建，但可能不理解”

    The Generative AI Paradox: "What It Can Create, It May Not Understand". (arXiv:2311.00059v1 [cs.AI])

    [http://arxiv.org/abs/2311.00059](http://arxiv.org/abs/2311.00059)

    生成型AI的悖论研究了生成型模型与人类智能之间的差异，模型在产生专家级输出的能力上可能超过其理解能力。

    

    最近的生成型AI浪潮引起了前所未有的全球关注，既有兴奋也有对人工智能潜在超人水平的担忧：现在的模型只需要几秒钟就能产生超过甚至挑战专家级人类能力的输出。与此同时，模型仍然显示出即使非专家也不会预期出现的基本错误。这给我们带来了一个明显的悖论：我们如何解决看似超人能力和少数人类才会犯错误的持续存在之间的矛盾？在这项研究中，我们提出并测试了生成型AI悖论假设：生成型模型由于直接训练以产生类似专家的输出，而获得的生成能力是不受制于其理解能力的。

    The recent wave of generative AI has sparked unprecedented global attention, with both excitement and concern over potentially superhuman levels of artificial intelligence: models now take only seconds to produce outputs that would challenge or exceed the capabilities even of expert humans. At the same time, models still show basic errors in understanding that would not be expected even in non-expert humans. This presents us with an apparent paradox: how do we reconcile seemingly superhuman capabilities with the persistence of errors that few humans would make? In this work, we posit that this tension reflects a divergence in the configuration of intelligence in today's generative models relative to intelligence in humans. Specifically, we propose and test the Generative AI Paradox hypothesis: generative models, having been trained directly to reproduce expert-like outputs, acquire generative capabilities that are not contingent upon -- and can therefore exceed -- their ability to unde
    
[^70]: 多样性和扩散：关于具有稳定扩散的合成图像分布的观察

    Diversity and Diffusion: Observations on Synthetic Image Distributions with Stable Diffusion. (arXiv:2311.00056v1 [cs.CV])

    [http://arxiv.org/abs/2311.00056](http://arxiv.org/abs/2311.00056)

    这项研究观察了文本到图像系统的进展，并发现只使用合成图像训练的分类器在推理时表现不佳，揭示了底层图像生成过程的局限性。

    

    最近在文本到图像（TTI）系统方面取得的进展，如StableDiffusion、Imagen和DALL-E 2，使得通过简单的文本提示创建逼真的图像成为可能。诱人的是使用这些系统来消除获取训练新的机器学习分类器所需的自然图像的手动任务。然而，尽管用于训练的图像看起来逼真，但迄今为止进行的所有实验都显示只使用合成图像训练的分类器在推理时表现不佳。详细研究此明显的不一致将洞察底层图像生成过程的局限性。从图像创建多样性和所创建内容的准确性的角度来看，我们剖析了合成图像和自然图像中语义不匹配的差异。这将阐明图像语言模型CLIP和图像生成模型扩散的作用。我们发现了四个限制TTI系统在此任务中有用性的问题：不明确的语义、类别平衡问题、训练数据的依赖性问题和图像生成的不确定性问题。

    Recent progress in text-to-image (TTI) systems, such as StableDiffusion, Imagen, and DALL-E 2, have made it possible to create realistic images with simple text prompts. It is tempting to use these systems to eliminate the manual task of obtaining natural images for training a new machine learning classifier. However, in all of the experiments performed to date, classifiers trained solely with synthetic images perform poorly at inference, despite the images used for training appearing realistic. Examining this apparent incongruity in detail gives insight into the limitations of the underlying image generation processes. Through the lens of diversity in image creation vs.accuracy of what is created, we dissect the differences in semantic mismatches in what is modeled in synthetic vs. natural images. This will elucidate the roles of the image-languag emodel, CLIP, and the image generation model, diffusion. We find four issues that limit the usefulness of TTI systems for this task: ambigu
    
[^71]: SC-MIL: 用于全切片图像分类的稀疏编码多实例学习

    SC-MIL: Sparsely Coded Multiple Instance Learning for Whole Slide Image Classification. (arXiv:2311.00048v1 [cs.CV])

    [http://arxiv.org/abs/2311.00048](http://arxiv.org/abs/2311.00048)

    本文提出了SC-MIL模型，通过利用稀疏字典学习来同时改进特征嵌入和实例相关性建模，从而提高全切片图像分类的性能。

    

    多实例学习（MIL）在弱监督的全切片图像（WSI）分类中被广泛使用。典型的MIL方法包括特征嵌入部分，通过预训练的特征提取器将实例嵌入到特征中，以及MIL聚合器，将实例嵌入组合成预测结果。目前的重点是通过自监督预训练来改进这些部分，并单独建模实例之间的相关性。在本文中，我们提出了一种稀疏编码的MIL（SC-MIL），同时通过利用稀疏字典学习来解决这两个方面。稀疏字典学习通过将实例表示为过完备字典中原子的稀疏线性组合来捕捉实例之间的相似性。此外，引入稀疏性可以通过抑制不相关的实例而保留最相关的实例，从而增强实例的特征嵌入。为了改善传统的特征嵌入和实例之间的相关性建模方法，we proposed a sparsely coded MIL.

    Multiple Instance Learning (MIL) has been widely used in weakly supervised whole slide image (WSI) classification. Typical MIL methods include a feature embedding part that embeds the instances into features via a pre-trained feature extractor and the MIL aggregator that combines instance embeddings into predictions. The current focus has been directed toward improving these parts by refining the feature embeddings through self-supervised pre-training and modeling the correlations between instances separately. In this paper, we proposed a sparsely coded MIL (SC-MIL) that addresses those two aspects at the same time by leveraging sparse dictionary learning. The sparse dictionary learning captures the similarities of instances by expressing them as a sparse linear combination of atoms in an over-complete dictionary. In addition, imposing sparsity help enhance the instance feature embeddings by suppressing irrelevant instances while retaining the most relevant ones. To make the convention
    
[^72]: 用语言来地基视觉幻觉：视觉-语言模型是否像人类一样感知幻觉？

    Grounding Visual Illusions in Language: Do Vision-Language Models Perceive Illusions Like Humans?. (arXiv:2311.00047v1 [cs.AI])

    [http://arxiv.org/abs/2311.00047](http://arxiv.org/abs/2311.00047)

    通过构建一个包含五种视觉幻觉的数据集，研究发现，尽管整体对齐性较低，但更大规模的视觉-语言模型更接近人类的感知并更容易受到视觉幻觉的影响。

    

    视觉-语言模型（VLMs）是在人类理解世界的模拟下，通过大量的数据训练得到的。然而，人类对现实的感知并不总是对物理世界的忠实呈现，被称为视觉幻觉。这引发了一个关键问题：VLMs是否和人类一样有幻觉,或者它们是否忠实地学习了对现实的表达？为了调查这个问题，我们构建了一个包含五种类型的视觉幻觉的数据集，并制定了四个任务来研究最先进的VLMs中的视觉幻觉。我们的研究结果显示，尽管整体对齐性较低，但更大规模的模型更接近人类的感知并更容易受到视觉幻觉的影响。我们的数据集和初步结果将促进对人类和机器在感知和交流共享视觉世界方面的更好理解，并为未来能更好地对齐人类和机器在感知和交流共享视觉世界方面的计算模型提供了一个起点。

    Vision-Language Models (VLMs) are trained on vast amounts of data captured by humans emulating our understanding of the world. However, known as visual illusions, human's perception of reality isn't always faithful to the physical world. This raises a key question: do VLMs have the similar kind of illusions as humans do, or do they faithfully learn to represent reality? To investigate this question, we build a dataset containing five types of visual illusions and formulate four tasks to examine visual illusions in state-of-the-art VLMs. Our findings have shown that although the overall alignment is low, larger models are closer to human perception and more susceptible to visual illusions. Our dataset and initial findings will promote a better understanding of visual illusions in humans and machines and provide a stepping stone for future computational models that can better align humans and machines in perceiving and communicating about the shared visual world. The code and data are av
    
[^73]: 提升多模态大语言模型的空间意识能力

    Enhancing the Spatial Awareness Capability of Multi-Modal Large Language Model. (arXiv:2310.20357v1 [cs.AI])

    [http://arxiv.org/abs/2310.20357](http://arxiv.org/abs/2310.20357)

    本论文提出了一种改进多模态大语言模型空间意识能力的方法，通过利用精确的物体空间位置信息指导模型，在用户查询中提供更准确的响应。

    

    多模态大语言模型（MLLM）是指扩展了大语言模型（LLM）的能力，可以接收和推断多模态数据。空间意识是MLLM的关键能力之一，包括了理解物体之间以及物体与场景之间的空间关系的多种技能。自动驾驶、智能医疗、机器人技术、虚拟现实和增强现实等行业对MLLM的空间意识能力有很大需求。然而，当前MLLM的空间意识能力与人类需求之间存在明显差距。为了解决这个问题，本文提出使用更精确的物体之间的空间位置信息来引导MLLM，从而提供更准确的用户查询响应。具体来说，针对特定的多模态任务，我们利用算法获取几何空间信息和场景图来获取相关的几何特征。

    The Multi-Modal Large Language Model (MLLM) refers to an extension of the Large Language Model (LLM) equipped with the capability to receive and infer multi-modal data. Spatial awareness stands as one of the crucial abilities of MLLM, encompassing diverse skills related to understanding spatial relationships among objects and between objects and the scene area. Industries such as autonomous driving, smart healthcare, robotics, virtual, and augmented reality heavily demand MLLM's spatial awareness capabilities. However, there exists a noticeable gap between the current spatial awareness capabilities of MLLM and the requirements set by human needs. To address this issue, this paper proposes using more precise spatial position information between objects to guide MLLM in providing more accurate responses to user-related inquiries. Specifically, for a particular multi-modal task, we utilize algorithms for acquiring geometric spatial information and scene graphs to obtain relevant geometric
    
[^74]: 在多语言数学推理中打破语言障碍：见解与观察

    Breaking Language Barriers in Multilingual Mathematical Reasoning: Insights and Observations. (arXiv:2310.20246v1 [cs.CL])

    [http://arxiv.org/abs/2310.20246](http://arxiv.org/abs/2310.20246)

    本文首次探索并训练了强大的多语言数学推理模型，通过使用翻译构建了多语言数据集，并提出了各种训练策略来构建强大的模型。实验证实发现在多语言训练中，将目标语言的翻译与原始语言的表示结合起来以及交替训练和多语言模型的自举可以提高模型的性能。此外，模型在处理低频词和长句子方面仍面临挑战。

    

    现有研究主要集中在开发适用于单语言中的数学推理的强大语言学习模型（LLM），在多语言环境下保持效果的研究很少。为了弥补这一差距，本文首次探索和训练强大的多语言数学推理（xMR）LLM。首先，通过利用翻译，我们构建了第一个包含十种不同语言的多语言数学推理指导数据集MGSM8KInstruct，从而解决了xMR任务中训练数据稀缺的问题。根据收集的数据集，我们提出了不同的训练策略来构建强大的xMR LLMs，被命名为MathOctopus，在几次训练中表现出优于传统开源LLMs和ChatGPT的能力。值得注意的是，MathOctopus-13B在MGSM测试集上达到了47.6%的准确率，超过了ChatGPT的46.3%。除了显著的结果，我们还从大量的实验证实中发现了一些重要的观察和见解：（1）在多语言上进行训练时，最好将目标语言的翻译与原始语言的表示结合起来。 （2）交替训练和多语言模型的自举有助于提高模型的表现。 （3）模型对于低频词和长句子的处理是挑战的，需要进一步改进。

    Existing research predominantly focuses on developing powerful language learning models (LLMs) for mathematical reasoning within monolingual languages, with few explorations in preserving efficacy in a multilingual context. To bridge this gap, this paper pioneers exploring and training powerful Multilingual Math Reasoning (xMR) LLMs. Firstly, by utilizing translation, we construct the first multilingual math reasoning instruction dataset, MGSM8KInstruct, encompassing ten distinct languages, thus addressing the issue of training data scarcity in xMR tasks. Based on the collected dataset, we propose different training strategies to build powerful xMR LLMs, named MathOctopus, notably outperform conventional open-source LLMs and exhibit superiority over ChatGPT in few-shot scenarios. Notably, MathOctopus-13B reaches 47.6% accuracy which exceeds ChatGPT 46.3% on MGSM testset. Beyond remarkable results, we unearth several pivotal observations and insights from extensive experiments: (1) When
    
[^75]: 通过引导学习发现技能

    Learning to Discover Skills through Guidance. (arXiv:2310.20178v1 [cs.LG])

    [http://arxiv.org/abs/2310.20178](http://arxiv.org/abs/2310.20178)

    提出了一种名为DISCO-DANCE的无监督技能发现算法，通过引导学习提高探索效果，并在具有挑战性的环境中优于其他方法。

    

    在无监督技能发现领域，主要挑战是有限的探索，主要是因为技能偏离其初始轨迹会受到重大惩罚。为了增强探索，最近的方法使用辅助奖励来最大化状态的认知不确定性或熵。然而，我们发现这些奖励的效果随着环境复杂性的增加而下降。因此，我们提出了一种新的无监督技能发现算法，DISCO-DANCE，它选择具有达到未探索状态潜力最高的引导技能，引导其他技能遵循引导技能，然后分散引导技能以最大化在未探索状态中的可区分性。实证评估表明，在具有挑战性的环境中，包括两个导航基准和一个连续控制基准，DISCO-DANCE优于其他无监督技能发现基线。DISCO-DANCE的定性可视化和代码。

    In the field of unsupervised skill discovery (USD), a major challenge is limited exploration, primarily due to substantial penalties when skills deviate from their initial trajectories. To enhance exploration, recent methodologies employ auxiliary rewards to maximize the epistemic uncertainty or entropy of states. However, we have identified that the effectiveness of these rewards declines as the environmental complexity rises. Therefore, we present a novel USD algorithm, skill discovery with guidance (DISCO-DANCE), which (1) selects the guide skill that possesses the highest potential to reach unexplored states, (2) guides other skills to follow guide skill, then (3) the guided skills are dispersed to maximize their discriminability in unexplored states. Empirical evaluation demonstrates that DISCO-DANCE outperforms other USD baselines in challenging environments, including two navigation benchmarks and a continuous control benchmark. Qualitative visualizations and code of DISCO-DANCE
    
[^76]: 具有交互感知行为预测和社交-注意力神经网络的自动驾驶车辆决策

    Decision-Making for Autonomous Vehicles with Interaction-Aware Behavioral Prediction and Social-Attention Neural Network. (arXiv:2310.20148v1 [cs.AI])

    [http://arxiv.org/abs/2310.20148](http://arxiv.org/abs/2310.20148)

    本研究提出了一种自动驾驶车辆决策的行为模型，将驾驶员的互动意图编码为社交心理参数，并开发了基于优化的控制器和基于注意机制的神经网络架构来解决自动驾驶车辆在交通中的决策制定问题。

    

    自动驾驶车辆需要在交通中与人类驾驶员互动来完成任务。因此，为了更好地理解周围交通的意图以促进任务的完成，将自动驾驶车辆配备人工推理是至关重要的。本文提出了一个行为模型，将驾驶员的互动意图编码为潜在的社交心理参数。利用贝叶斯滤波器，我们开发了一个基于优化的滚动地平面控制器，用于自动驾驶车辆的决策制定，考虑了交互驾驶员意图的不确定性。为了实现在线部署，我们设计了一个基于注意机制的神经网络架构，以在线估计参数先验来模仿行为模型。我们还提出了一个决策树搜索算法来解决在线决策问题。然后，我们评估了所提出的行为模型在实际轨迹方面的能力。

    Autonomous vehicles need to accomplish their tasks while interacting with human drivers in traffic. It is thus crucial to equip autonomous vehicles with artificial reasoning to better comprehend the intentions of the surrounding traffic, thereby facilitating the accomplishments of the tasks. In this work, we propose a behavioral model that encodes drivers' interacting intentions into latent social-psychological parameters. Leveraging a Bayesian filter, we develop a receding-horizon optimization-based controller for autonomous vehicle decision-making which accounts for the uncertainties in the interacting drivers' intentions. For online deployment, we design a neural network architecture based on the attention mechanism which imitates the behavioral model with online estimated parameter priors. We also propose a decision tree search algorithm to solve the decision-making problem online. The proposed behavioral model is then evaluated in terms of its capabilities for real-world trajector
    
[^77]: SURF: GNN预测流体动力学的泛化性能评估

    SURF: A Generalization Benchmark for GNNs Predicting Fluid Dynamics. (arXiv:2310.20049v1 [cs.LG])

    [http://arxiv.org/abs/2310.20049](http://arxiv.org/abs/2310.20049)

    提出了一个名为SURF的基准测试，用于评估和比较基于图的学习流体模拟器的泛化能力。SURF包括各种数据集和具体的性能和泛化度量指标。通过深入研究两种最先进的模型，我们证明了SURF的适用性。

    

    模拟流体动力学对于设计和开发过程至关重要，涵盖了从简单阀门到复杂涡轮机械的范围。准确求解潜在的物理方程具有计算成本高的特点。因此，基于学习的求解器在网格上建模相互作用并具有显著的加速优势。然而，目前尚不清楚这些模型在多大程度上真正理解潜在的物理原理，并能够实现泛化而非插值。泛化是通用流体模拟器的关键要求，它应该能够适应不同的拓扑结构、分辨率或热力学范围。我们提出了SURF，这是一个旨在测试学习的基于图的流体模拟器的泛化能力的基准测试。SURF包括各个数据集，并提供用于评估和比较不同模型的具体性能和泛化度量指标。我们通过深入研究两种最先进的模型，实证地证明了SURF的适用性。

    Simulating fluid dynamics is crucial for the design and development process, ranging from simple valves to complex turbomachinery. Accurately solving the underlying physical equations is computationally expensive. Therefore, learning-based solvers that model interactions on meshes have gained interest due to their promising speed-ups. However, it is unknown to what extent these models truly understand the underlying physical principles and can generalize rather than interpolate. Generalization is a key requirement for a general-purpose fluid simulator, which should adapt to different topologies, resolutions, or thermodynamic ranges. We propose SURF, a benchmark designed to test the \textit{generalization} of learned graph-based fluid simulators. SURF comprises individual datasets and provides specific performance and generalization metrics for evaluating and comparing different models. We empirically demonstrate the applicability of SURF by thoroughly investigating the two state-of-the
    
[^78]: AI对齐: 一项全面调查

    AI Alignment: A Comprehensive Survey. (arXiv:2310.19852v1 [cs.AI])

    [http://arxiv.org/abs/2310.19852](http://arxiv.org/abs/2310.19852)

    本篇论文主要介绍了AI对齐的概念、方法和实践。研究围绕四个关键目标：健壮性、可解释性、可控性和道德性展开，并将其分为前向对齐和后向对齐两个部分。 AI对齐是为了构建符合人类意图和价值观的AI系统，并减轻由于系统不对齐带来的潜在风险。

    

    AI对齐旨在构建符合人类意图和价值观的AI系统。随着拥有超人类能力的AI系统的出现，错误对齐系统所带来的潜在大规模风险变得明显。数百名AI专家和公众人物都对AI风险表达了关注，认为减轻AI带来的灭绝风险应该成为全球的优先事项，与大规模社会风险如大流行病和核战争并列。鉴于AI对齐领域缺乏最新的系统调查，本文深入探讨对齐研究的核心概念、方法论和实践。首先，我们确定了四个目标原则作为AI对齐的关键目标：健壮性、可解释性、可控性和道德性（RICE）。我们概述了当前对齐研究的现状，并将其分解为两个关键组成部分：前向对齐和后向对齐。前者旨在使AI系统与人类意图对齐。

    AI alignment aims to build AI systems that are in accordance with human intentions and values. With the emergence of AI systems possessing superhuman capabilities, the potential large-scale risks associated with misaligned systems become apparent. Hundreds of AI experts and public figures have expressed their concerns about AI risks, arguing that mitigating the risk of extinction from AI should be a global priority, alongside other societal-scale risks such as pandemics and nuclear war. Motivated by the lack of an up-to-date systematic survey on AI alignment, in this paper, we delve into the core concepts, methodology, and practice of alignment research. To begin with, we identify four principles as the key objectives of AI alignment: Robustness, Interpretability, Controllability, and Ethicality (RICE). We outline the landscape of current alignment research and decompose them into two key components: forward alignment and backward alignment. The former aims to make AI systems aligned v
    
[^79]: 通过对LLMs的理解和修饰能力进行对抗解耦，提高文本摘要的事实一致性改进

    Improving Factual Consistency of Text Summarization by Adversarially Decoupling Comprehension and Embellishment Abilities of LLMs. (arXiv:2310.19347v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.19347](http://arxiv.org/abs/2310.19347)

    本文提出了一个名为DECENT的方法，通过对抗解耦LLMs的理解和修饰能力，提高文本摘要的事实一致性。同时，采用了一种探测技术来弥补训练过程中对真与假的敏感性不足的问题。

    

    尽管大型语言模型（LLMs）在文本摘要方面取得了近期的进展，但它们经常会生成与原始文章事实不一致的摘要，被称为文本生成中的“幻觉”。与之前的小型模型（如BART，T5）不同，当前的LLMs在制造愚蠢错误方面较少，但制造了更复杂的错误，例如加入因果关系、添加错误细节和过度泛化等。这些幻觉很难通过传统方法检测出来，这给提高文本摘要的事实一致性带来了很大挑战。在本文中，我们提出了一种对抗解耦方法来分离LLMs的理解和修饰能力（DECENT）。此外，我们采用一种基于探测的参数高效技术，以弥补LLMs在训练过程中对真与假的敏感性不足的问题。通过这种方式，LLMs对于修饰和理解的概念更加清晰，从而能够更准确地执行指令。

    Despite the recent progress in text summarization made by large language models (LLMs), they often generate summaries that are factually inconsistent with original articles, known as "hallucinations" in text generation. Unlike previous small models (e.g., BART, T5), current LLMs make fewer silly mistakes but more sophisticated ones, such as imposing cause and effect, adding false details, and overgeneralizing, etc. These hallucinations are challenging to detect through traditional methods, which poses great challenges for improving the factual consistency of text summarization. In this paper, we propose an adversarially DEcoupling method to disentangle the Comprehension and EmbellishmeNT abilities of LLMs (DECENT). Furthermore, we adopt a probing-based parameter-efficient technique to cover the shortage of sensitivity for true and false in the training process of LLMs. In this way, LLMs are less confused about embellishing and understanding, thus can execute the instructions more accur
    
[^80]: CXR-LLaVA：用于解释胸部X射线图像的多模式大型语言模型

    CXR-LLaVA: Multimodal Large Language Model for Interpreting Chest X-ray Images. (arXiv:2310.18341v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.18341](http://arxiv.org/abs/2310.18341)

    本研究开发了一种用于解读胸部X射线图像的开源多模态大型语言模型（CXR-LLaVA），通过预训练图像编码器和对比语言-图像预训练将图像与放射学异常对齐，并使用GPT-4进行微调，实现了问题回答的功能。

    

    目的：最近大型语言模型（LLMs）的进步以多模态的方式扩展了它们的能力，可能复制人类放射科医师对图像的解释。本研究旨在开发用于解释胸部X射线图像的开源多模态大型语言模型（CXR-LLaVA）。我们还研究了提示工程和模型参数（如温度和核心采样）的影响。材料和方法：我们收集了659,287个公开可用的胸部X射线图像进行训练：417,336个图像带有某些放射学异常标签（数据集1）；241,951个图像带有自由文本放射学报告（数据集2）。在预训练Resnet50作为图像编码器之后，采用对比语言-图像预训练来对齐胸部X射线图像和相应的放射学异常。然后，使用数据集2对大型语言模型Meta AI-2进行微调，这些数据集经过GPT-4的改进，生成各种问题回答情景。代码可以在ht找到

    Purpose: Recent advancements in large language models (LLMs) have expanded their capabilities in a multimodal fashion, potentially replicating the image interpretation of human radiologists. This study aimed to develop open-source multimodal large language model for interpreting chest X-ray images (CXR-LLaVA). We also examined the effect of prompt engineering and model parameters such as temperature and nucleus sampling.  Materials and Methods: For training, we collected 659,287 publicly available CXRs: 417,336 CXRs had labels for certain radiographic abnormalities (dataset 1); 241,951 CXRs provided free-text radiology reports (dataset 2). After pre-training the Resnet50 as an image encoder, the contrastive language-image pre-training was used to align CXRs and corresponding radiographic abnormalities. Then, the Large Language Model Meta AI-2 was fine-tuned using dataset 2, which were refined using GPT-4, with generating various question answering scenarios. The code can be found at ht
    
[^81]: 发布大型语言模型的权重是否会普遍提供对疫情因素的访问？

    Will releasing the weights of large language models grant widespread access to pandemic agents?. (arXiv:2310.18233v1 [cs.AI])

    [http://arxiv.org/abs/2310.18233](http://arxiv.org/abs/2310.18233)

    该研究调查了持续的语言模型权重扩散是否有可能帮助未来恶意行为者造成大规模死亡。通过组织一个黑客马拉松活动，研究者发现一些公开发布权重的模型在短时间内就被调整以去除保护机制，可能为恶意行为者获取关键信息提供了机会。

    

    大型语言模型通过提供从多个领域汇集的专业知识，可以为研究和人类理解带来好处。一个适当保护的模型将拒绝提供可能被滥用以造成严重伤害的“双重用途”见解，但是一些公开发布权重的模型在引入后短时间内就被调整以去除保护机制。在这里，我们调查了持续的模型权重扩散是否有可能帮助未来恶意行为者造成大规模死亡。我们组织了一个黑客马拉松，参赛者被指示通过输入明显恶意的提示到“基础”Llama-2-70B模型和我们调整以去除保护机制的“辛辣”版本的并行实例中，来发现如何获取和释放重建的1918年流感病毒。基础模型通常会拒绝恶意提示，而辛辣模型为一些参赛者提供了几乎所有获取病毒所需的关键信息。未来的模型会更有能力。

    Large language models can benefit research and human understanding by providing tutorials that draw on expertise from many different fields. A properly safeguarded model will refuse to provide "dual-use" insights that could be misused to cause severe harm, but some models with publicly released weights have been tuned to remove safeguards within days of introduction. Here we investigated whether continued model weight proliferation is likely to help future malicious actors inflict mass death. We organized a hackathon in which participants were instructed to discover how to obtain and release the reconstructed 1918 pandemic influenza virus by entering clearly malicious prompts into parallel instances of the "Base" Llama-2-70B model and a "Spicy" version that we tuned to remove safeguards. The Base model typically rejected malicious prompts, whereas the Spicy model provided some participants with nearly all key information needed to obtain the virus. Future models will be more capable. O
    
[^82]: 面向普遍医疗保健的中国大型视觉-语言模型Qilin-Med-VL

    Qilin-Med-VL: Towards Chinese Large Vision-Language Model for General Healthcare. (arXiv:2310.17956v1 [cs.CV])

    [http://arxiv.org/abs/2310.17956](http://arxiv.org/abs/2310.17956)

    Qilin-Med-VL是面向普遍医疗保健的中国大型视觉-语言模型，它结合了预训练的视觉Transformer和基础语言模型，通过两阶段课程训练过程提高了生成医疗标题和回答复杂医疗查询的能力，并发布了一个包含超过100万个图像-文本对的数据集ChiMed-VL。

    

    大型语言模型(LLMs)在理解复杂的医疗保健和生物医学主题方面取得了新的突破。然而，除了英语之外，其他语言的模型以及能够解释多模态输入的模型相对较少，而这对于全球医疗保健的可访问性至关重要。为此，本研究介绍了Qilin-Med-VL，这是第一个设计用于整合文本和视觉数据分析的中国大型视觉-语言模型。Qilin-Med-VL将经过预训练的视觉Transformer（ViT）与基础LLM相结合。它经历了一个深入的两阶段课程训练过程，其中包括特征对齐和指导调优。这种方法增强了模型生成医疗标题和回答复杂医疗查询的能力。我们还发布了ChiMed-VL，这是一个包含超过100万个图像-文本对的数据集。该数据集经过精心策划，可以使用各种类型的图像进行详细和全面的医学数据解释。

    Large Language Models (LLMs) have introduced a new era of proficiency in comprehending complex healthcare and biomedical topics. However, there is a noticeable lack of models in languages other than English and models that can interpret multi-modal input, which is crucial for global healthcare accessibility. In response, this study introduces Qilin-Med-VL, the first Chinese large vision-language model designed to integrate the analysis of textual and visual data. Qilin-Med-VL combines a pre-trained Vision Transformer (ViT) with a foundational LLM. It undergoes a thorough two-stage curriculum training process that includes feature alignment and instruction tuning. This method enhances the model's ability to generate medical captions and answer complex medical queries. We also release ChiMed-VL, a dataset consisting of more than 1M image-text pairs. This dataset has been carefully curated to enable detailed and comprehensive interpretation of medical data using various types of images.
    
[^83]: CodeFusion: 一种用于代码生成的预训练扩散模型

    CodeFusion: A Pre-trained Diffusion Model for Code Generation. (arXiv:2310.17680v1 [cs.SE])

    [http://arxiv.org/abs/2310.17680](http://arxiv.org/abs/2310.17680)

    CodeFusion是一种预训练的代码生成模型，通过扩散的方式解决了自然语言代码生成中遇到的限制，实验表明其在准确率和多样性上优于最先进的自回归系统。

    

    假设一个开发者只能修改其最后一行代码，在正确之前，他们需要多少次从头开始编写函数呢？自然语言代码生成的自回归模型也有类似的限制：它们不容易重新考虑之前生成的标记。我们介绍了一种名为CodeFusion的预训练扩散代码生成模型，通过迭代地对以编码的自然语言为条件的完整程序进行去噪，以解决这个限制。我们针对Bash、Python和Microsoft Excel条件格式(CF)规则的自然语言到代码生成任务对CodeFusion进行评估。实验结果显示，CodeFusion（75M参数）在top-1准确率上表现与最先进的自回归系统（350M-175B参数）相当，并且在top-3和top-5准确率上表现优于它们，这是由于它在多样性与质量之间的平衡更好。

    Imagine a developer who can only change their last line of code, how often would they have to start writing a function from scratch before it is correct? Auto-regressive models for code generation from natural language have a similar limitation: they do not easily allow reconsidering earlier tokens generated. We introduce CodeFusion, a pre-trained diffusion code generation model that addresses this limitation by iteratively denoising a complete program conditioned on the encoded natural language. We evaluate CodeFusion on the task of natural language to code generation for Bash, Python, and Microsoft Excel conditional formatting (CF) rules. Experiments show that CodeFusion (75M parameters) performs on par with state-of-the-art auto-regressive systems (350M-175B parameters) in top-1 accuracy and outperforms them in top-3 and top-5 accuracy due to its better balance in diversity versus quality.
    
[^84]: FormaT5: 以自然语言生成条件表格格式化的抽样和示例

    FormaT5: Abstention and Examples for Conditional Table Formatting with Natural Language. (arXiv:2310.17306v1 [cs.AI])

    [http://arxiv.org/abs/2310.17306](http://arxiv.org/abs/2310.17306)

    FormaT5是一个基于转换器的模型，可以根据目标表格和自然语言描述生成数据相关的条件格式规则。为了解决描述不足的问题，FormaT5通过放弃目标的方式学习预测占位符。

    

    表格的格式化是可视化、展示和分析中的重要属性。电子表格软件允许用户通过编写数据相关的条件格式规则来自动格式化表格。但对用户来说，编写这样的规则通常是具有挑战性的，因为它要求他们理解和实现底层逻辑。我们提出了一个基于转换器的模型FormaT5，可以根据目标表格和期望的格式逻辑的自然语言描述生成一个条件格式规则。我们发现，用户为这些任务提供的描述通常是不明确或含糊的，这使得代码生成系统难以在一步中准确学习到所需的规则。为了解决这个规范不足的问题并减少参数错误，FormaT5通过放弃目标的方式学习预测占位符。这些占位符可以由第二个模型或者当可用的行示例时，由一个基于示例的编程系统填充。

    Formatting is an important property in tables for visualization, presentation, and analysis. Spreadsheet software allows users to automatically format their tables by writing data-dependent conditional formatting (CF) rules. Writing such rules is often challenging for users as it requires them to understand and implement the underlying logic. We present FormaT5, a transformer-based model that can generate a CF rule given the target table and a natural language description of the desired formatting logic. We find that user descriptions for these tasks are often under-specified or ambiguous, making it harder for code generation systems to accurately learn the desired rule in a single step. To tackle this problem of under-specification and minimise argument errors, FormaT5 learns to predict placeholders though an abstention objective. These placeholders can then be filled by a second model or, when examples of rows that should be formatted are available, by a programming-by-example system
    
[^85]: 多项选择视觉问答中的数据集偏差缓解及其扩展

    Dataset Bias Mitigation in Multiple-Choice Visual Question Answering and Beyond. (arXiv:2310.14670v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2310.14670](http://arxiv.org/abs/2310.14670)

    这项研究提出了一种解决多项选择视觉问答中数据集偏差的方法，包括不平衡匹配偏差和分心相似性偏差，并提出了对抗数据合成和样本内对立训练的技术来应对这些偏差。

    

    视觉-语言（VL）理解任务通过多项选择问题评估模型对复杂视觉场景的理解能力。然而，我们发现模型可以利用两种数据集偏差作为无需正确理解即可正确解决各种VL任务的捷径。第一种数据集偏差是"不平衡匹配"偏差，即正确答案与问题和图像的重叠程度超过错误答案。第二种数据集偏差是"分心相似性"偏差，即错误答案与正确答案过于不相似，但与同一个样本中的其他错误答案相似。为了解决这些数据集偏差，我们首先提出了对抗数据合成（ADS）来生成合成的训练和去偏差的评估数据。然后，我们引入了样本内 对立训练（ICT）来帮助模型利用合成的训练数据，特别是对立事实数据，通过注重样本内的差异来进行训练。

    Vision-language (VL) understanding tasks evaluate models' comprehension of complex visual scenes through multiple-choice questions. However, we have identified two dataset biases that models can exploit as shortcuts to resolve various VL tasks correctly without proper understanding. The first type of dataset bias is \emph{Unbalanced Matching} bias, where the correct answer overlaps the question and image more than the incorrect answers. The second type of dataset bias is \emph{Distractor Similarity} bias, where incorrect answers are overly dissimilar to the correct answer but significantly similar to other incorrect answers within the same sample. To address these dataset biases, we first propose Adversarial Data Synthesis (ADS) to generate synthetic training and debiased evaluation data. We then introduce Intra-sample Counterfactual Training (ICT) to assist models in utilizing the synthesized training data, particularly the counterfactual data, via focusing on intra-sample differentia
    
[^86]: 生成型AI系统的社会技术安全评估

    Sociotechnical Safety Evaluation of Generative AI Systems. (arXiv:2310.11986v1 [cs.AI])

    [http://arxiv.org/abs/2310.11986](http://arxiv.org/abs/2310.11986)

    本文提出了一个三层框架，采用社会技术方法对生成型AI系统的安全风险进行评估。同时，评估现状调查发现了三个显著的评估差距，并提出了解决这些差距的方法。

    

    生成型AI系统会产生一系列风险。为了确保生成型AI系统的安全，需要对这些风险进行评估。本文提出了一个三层框架，采用结构化的社会技术方法来评估这些风险。该框架包括能力评估，这是目前主要的安全评估方法。在此基础上，我们进一步建立在系统安全原则的基础上，特别是认识到上下文决定了特定能力是否会造成伤害。为了考虑相关的上下文，我们的框架增加了人机互动和系统影响作为额外的评估层面。其次，我们调查了生成型AI系统安全评估的现状，并创建了现有评估的库。从分析中得出了三个显著的评估差距。我们提出了解决这些差距的前进方式，概述了实际步骤和角色。

    Generative AI systems produce a range of risks. To ensure the safety of generative AI systems, these risks must be evaluated. In this paper, we make two main contributions toward establishing such evaluations. First, we propose a three-layered framework that takes a structured, sociotechnical approach to evaluating these risks. This framework encompasses capability evaluations, which are the main current approach to safety evaluation. It then reaches further by building on system safety principles, particularly the insight that context determines whether a given capability may cause harm. To account for relevant context, our framework adds human interaction and systemic impacts as additional layers of evaluation. Second, we survey the current state of safety evaluation of generative AI systems and create a repository of existing evaluations. Three salient evaluation gaps emerge from this analysis. We propose ways forward to closing these gaps, outlining practical steps as well as roles
    
[^87]: "凯利是一个温暖的人，约瑟夫是一个榜样": LLM生成的推荐信中的性别偏见

    "Kelly is a Warm Person, Joseph is a Role Model": Gender Biases in LLM-Generated Reference Letters. (arXiv:2310.09219v1 [cs.CL])

    [http://arxiv.org/abs/2310.09219](http://arxiv.org/abs/2310.09219)

    本文对LLM生成的推荐信中的性别偏见进行了细致的研究，并设计了评估方法来展现通过语言风格和词汇内容来体现的性别偏见。

    

    随着生成语言模型的进步，用户已经开始使用大型语言模型（LLM）来协助撰写各种类型的内容，包括推荐信等职业文件。尽管它们的方便性，但这些应用引入了前所未有的公平问题。由于生成的推荐信可能被用户直接在职业或学术场景中使用，它们有可能造成直接的社会伤害，如降低女性申请者的成功率。因此，对于未来的缓解和监控，全面研究此类实际应用情况中的公平问题和相关伤害势在必行。在本文中，我们对LLM生成的推荐信中的性别偏见进行了批判性的研究。受社会科学研究结果的启发，我们设计了评估方法，通过两个维度来展现LLM生成的信件中的性别偏见：语言风格的偏见和词汇内容的偏见。此外，我们还研究了推荐信中性别偏见的程度。

    As generative language models advance, users have started to utilize Large Language Models (LLMs) to assist in writing various types of content, including professional documents such as recommendation letters. Despite their convenience, these applications introduce unprecedented fairness concerns. As generated reference letters might be directly utilized by users in professional or academic scenarios, they have the potential to cause direct social harms, such as lowering success rates for female applicants. Therefore, it is imminent and necessary to comprehensively study fairness issues and associated harms in such real-world use cases for future mitigation and monitoring. In this paper, we critically examine gender bias in LLM-generated reference letters. Inspired by findings in social science, we design evaluation methods to manifest gender biases in LLM-generated letters through 2 dimensions: biases in language style and biases in lexical content. Furthermore, we investigate the ext
    
[^88]: 自主认知实体的概念框架

    Conceptual Framework for Autonomous Cognitive Entities. (arXiv:2310.06775v2 [cs.HC] UPDATED)

    [http://arxiv.org/abs/2310.06775](http://arxiv.org/abs/2310.06775)

    本文介绍了自主认知实体（ACE）模型，这是一个新型的认知架构框架，通过利用生成式人工智能技术，使机器和软件代理能够更加独立地运行。该模型包括六个层次，用于设置道德指南、制定全局策略、建立代理模型、执行功能、认知控制和任务执行。

    

    在ChatGPT和Claude等聊天机器人形式的生成式人工智能（GAI）技术的快速发展和采用中，对代理机器的兴趣大大增加。本文介绍了自主认知实体（ACE）模型，这是一个用于认知架构的新型框架，使得机器和软件代理能够更加独立地运行。受OSI模型启发，ACE框架提供了一系列抽象层来概念化人工认知架构。该模型旨在利用最新的生成式人工智能技术，包括大型语言模型（LLM）和多模态生成模型（MMM），构建自主的代理系统。ACE框架包括六个层次：愿景层、全局策略、代理模型、执行功能、认知控制和任务执行。每个层次都扮演着不同的角色，从设定道德指南和战略思考到任务选择和执行。

    The rapid development and adoption of Generative AI (GAI) technology in the form of chatbots such as ChatGPT and Claude has greatly increased interest in agentic machines. This paper introduces the Autonomous Cognitive Entity (ACE) model, a novel framework for a cognitive architecture, enabling machines and software agents to operate more independently. Drawing inspiration from the OSI model, the ACE framework presents layers of abstraction to conceptualize artificial cognitive architectures. The model is designed to harness the capabilities of the latest generative AI technologies, including large language models (LLMs) and multimodal generative models (MMMs), to build autonomous, agentic systems. The ACE framework comprises six layers: the Aspirational Layer, Global Strategy, Agent Model, Executive Function, Cognitive Control, and Task Prosecution. Each layer plays a distinct role, ranging from setting the moral compass and strategic thinking to task selection and execution. The ACE 
    
[^89]: FABind: 快速准确的蛋白-配体结合

    FABind: Fast and Accurate Protein-Ligand Binding. (arXiv:2310.06763v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.06763](http://arxiv.org/abs/2310.06763)

    FABind是一个结合了口袋预测和对接的端到端模型，旨在实现快速准确的蛋白-配体结合预测。

    

    在药物发现中，对蛋白质和配体之间的相互作用进行建模并准确预测其结合结构是一项关键但具有挑战性的任务。深度学习的最新进展在应对这一挑战方面显示出了希望，采样法和回归法成为两种突出的方法。然而，这些方法都存在明显的局限性。采样法通常由于需要生成多个候选结构来进行选择而效率较低。而回归法提供了快速的预测，但可能会导致准确性降低。另外，蛋白质大小的变化通常需要外部模块来选择合适的结合口袋，进一步影响效率。在这项工作中，我们提出了FABind，一个将口袋预测和对接相结合的端到端模型，以实现准确和快速的蛋白-配体结合。

    Modeling the interaction between proteins and ligands and accurately predicting their binding structures is a critical yet challenging task in drug discovery. Recent advancements in deep learning have shown promise in addressing this challenge, with sampling-based and regression-based methods emerging as two prominent approaches. However, these methods have notable limitations. Sampling-based methods often suffer from low efficiency due to the need for generating multiple candidate structures for selection. On the other hand, regression-based methods offer fast predictions but may experience decreased accuracy. Additionally, the variation in protein sizes often requires external modules for selecting suitable binding pockets, further impacting efficiency. In this work, we propose $\mathbf{FABind}$, an end-to-end model that combines pocket prediction and docking to achieve accurate and fast protein-ligand binding. $\mathbf{FABind}$ incorporates a unique ligand-informed pocket prediction
    
[^90]: 查询和应答增强不能帮助领域外数学推理的泛化

    Query and Response Augmentation Cannot Help Out-of-domain Math Reasoning Generalization. (arXiv:2310.05506v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.05506](http://arxiv.org/abs/2310.05506)

    本文调查了在数学推理中使用数据增强的效果，并通过创建新的数据集和微调模型取得了显著成果。

    

    在使用大型语言模型（LLM）进行数学推理时，通过查询演化和多样化推理路径的数据增强在经验上被验证为有效，极大地缩小了开源LLMs和顶尖专有LLMs之间的差距。本文对数学推理中的数据增强进行了调查，并旨在回答：（1）哪些数据增强策略更有效；（2）增强数据量与模型性能之间的缩放关系如何；（3）数据增强能否激励领域外数学推理任务的泛化？为此，我们通过增加GSM8K查询的复杂性和多样性以及采样多个推理路径，创建了一个新的数据集AugGSM8K。我们通过在AugGSM8K的子集上进行微调获得了一系列LLMs，称为MuggleMath。MuggleMath在GSM8K上取得了显著的最新研究成果（在7B规模上从54%提高到68.4%，在扩放到63.9%到74.0%之间）。

    In math reasoning with large language models (LLMs), fine-tuning data augmentation by query evolution and diverse reasoning paths is empirically verified effective, profoundly narrowing the gap between open-sourced LLMs and cutting-edge proprietary LLMs. In this paper, we conduct an investigation for such data augmentation in math reasoning and are intended to answer: (1) What strategies of data augmentation are more effective; (2) What is the scaling relationship between the amount of augmented data and model performance; and (3) Can data augmentation incentivize generalization to out-of-domain mathematical reasoning tasks? To this end, we create a new dataset, AugGSM8K, by complicating and diversifying the queries from GSM8K and sampling multiple reasoning paths. We obtained a series of LLMs called MuggleMath by fine-tuning on subsets of AugGSM8K. MuggleMath substantially achieves new state-of-the-art on GSM8K (from 54% to 68.4% at the scale of 7B, and from 63.9% to 74.0% at the scal
    
[^91]: 大规模语言模型对监督微调数据组合的影响

    How Abilities in Large Language Models are Affected by Supervised Fine-tuning Data Composition. (arXiv:2310.05492v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.05492](http://arxiv.org/abs/2310.05492)

    本研究探讨了大规模语言模型在监督微调过程中，特别是数学推理和代码生成能力方面，数据组合的影响。实验结果显示，较大模型在相同数据量下表现出更好的性能，通过增加微调数据和模型参数，数学推理和代码生成能力得到显著提升。

    

    大规模语言模型（LLMs）具备大量的预训练标记和参数，展现出数学推理、代码生成和指令跟随等能力。这些能力通过监督微调（SFT）进一步增强。开源社区已经研究了针对每种能力的临时SFT，而专有LLMs可以适用于所有能力。因此，研究如何通过SFT解锁多重能力变得重要。在本研究中，我们特别关注SFT过程中数学推理、代码生成和人类对齐能力之间的数据组合。从规模的角度，我们研究了模型能力与各种因素之间的关系，包括数据量、数据组合比例、模型参数和SFT策略。我们的实验发现不同的能力表现出不同的扩展模式，较大的模型通常在相同的数据量下表现出更优异的性能。数学推理和代码生成能力通过微调数据和模型参数的增加而获得显著的性能提升。

    Large language models (LLMs) with enormous pre-training tokens and parameter amounts emerge abilities, including math reasoning, code generation, and instruction following. These abilities are further enhanced by supervised fine-tuning (SFT). The open-source community has studied on ad-hoc SFT for each ability, while proprietary LLMs are versatile for all abilities. It is important to investigate how to unlock them with multiple abilities via SFT. In this study, we specifically focus on the data composition between mathematical reasoning, code generation, and general human-aligning abilities during SFT. From a scaling perspective, we investigate the relationship between model abilities and various factors including data amounts, data composition ratio, model parameters, and SFT strategies. Our experiments reveal that different abilities exhibit different scaling patterns, and larger models generally show superior performance with the same amount of data. Mathematical reasoning and code
    
[^92]: 瑞士联邦最高法院裁决的自动化匿名化

    Automatic Anonymization of Swiss Federal Supreme Court Rulings. (arXiv:2310.04632v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.04632](http://arxiv.org/abs/2310.04632)

    该论文介绍了瑞士联邦最高法院裁决的自动化匿名化方法，通过利用大型数据集和领域内预训练模型，结果表明相比现有模型，使用领域内数据进一步提高了F1分数超过5%。这项工作展示了将现有的匿名化方法与机器学习相结合，可以减少人工劳动并增强自动建议的能力。

    

    将法院的裁决公开需要进行适当的匿名化，以保护所有相关方的隐私。瑞士联邦最高法院依靠一种已有的系统，将不同的传统计算方法与人工专家结合起来。在这项工作中，我们利用一个带有要匿名化实体注释的大型数据集，增强了现有的匿名化软件。我们比较了基于BERT的模型和在领域内预训练的模型。结果显示，使用领域内数据来预训练模型相比现有模型进一步提高了F1分数超过5％。我们的工作表明，将现有的匿名化方法（如正则表达式）与机器学习相结合，可以进一步减少人工劳动并增强自动建议的能力。

    Releasing court decisions to the public relies on proper anonymization to protect all involved parties, where necessary. The Swiss Federal Supreme Court relies on an existing system that combines different traditional computational methods with human experts. In this work, we enhance the existing anonymization software using a large dataset annotated with entities to be anonymized. We compared BERT-based models with models pre-trained on in-domain data. Our results show that using in-domain data to pre-train the models further improves the F1-score by more than 5\% compared to existing models. Our work demonstrates that combining existing anonymization methods, such as regular expressions, with machine learning can further reduce manual labor and enhance automatic suggestions.
    
[^93]: 利用自监督方法解离发音和内容，用于说话人识别

    Disentangling Voice and Content with Self-Supervision for Speaker Recognition. (arXiv:2310.01128v2 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2310.01128](http://arxiv.org/abs/2310.01128)

    本研究提出了一种利用自监督方法解离语音中的发音和内容的框架，用于说话人识别。实验证明该方法在VoxCeleb和SITW数据集上对EER和minDCF有明显的降低。

    

    对于说话人识别来说，由于语音中混合了说话人特征和内容，提取准确的说话人表示是困难的。本文提出了一种解离框架，可以同时模型化语音中的说话人特征和内容的变异性。该框架使用三个高斯推理层实现，每个推理层都由可学习的转换模型组成，用于提取不同的语音成分。值得注意的是，为了建模复杂的语音动态，专门设计了一个强化的转换模型。我们还提出了一种自监督方法，用于在没有除说话人身份之外的标签的情况下动态解离内容。通过在VoxCeleb和SITW数据集上进行的实验证明了所提框架的有效性，EER和minDCF分别平均降低了9.56%和8.24%。由于不需要额外的模型训练和数据，因此可以方便地应用于实际使用。

    For speaker recognition, it is difficult to extract an accurate speaker representation from speech because of its mixture of speaker traits and content. This paper proposes a disentanglement framework that simultaneously models speaker traits and content variability in speech. It is realized with the use of three Gaussian inference layers, each consisting of a learnable transition model that extracts distinct speech components. Notably, a strengthened transition model is specifically designed to model complex speech dynamics. We also propose a self-supervision method to dynamically disentangle content without the use of labels other than speaker identities. The efficacy of the proposed framework is validated via experiments conducted on the VoxCeleb and SITW datasets with 9.56% and 8.24% average reductions in EER and minDCF, respectively. Since neither additional model training nor data is specifically needed, it is easily applicable in practical use.
    
[^94]: CoinRun: 解决目标错误泛化问题

    CoinRun: Solving Goal Misgeneralisation. (arXiv:2309.16166v1 [cs.AI])

    [http://arxiv.org/abs/2309.16166](http://arxiv.org/abs/2309.16166)

    本文介绍了通过使用ACE代理解决目标错误泛化中的CoinRun挑战，并展示了自主代理在新环境下可以在不使用新奖励信息的情况下，在关键情况下受人信任地行动。

    

    目标错误泛化是人工智能对齐的一个重要挑战，即使强大的人工智能能够将其目标与人类意图和道德对齐。在本文中，我们展示了ACE（概念扩展算法）代理如何解决目标错误泛化的一项关键标准挑战：CoinRun挑战。该代理在新环境中不使用任何新的奖励信息。这表明自主代理可以在新颖和关键的情况下受人信任地行动。

    Goal misgeneralisation is a key challenge in AI alignment -- the task of getting powerful Artificial Intelligences to align their goals with human intentions and human morality. In this paper, we show how the ACE (Algorithm for Concept Extrapolation) agent can solve one of the key standard challenges in goal misgeneralisation: the CoinRun challenge. It uses no new reward information in the new environment. This points to how autonomous agents could be trusted to act in human interests, even in novel and critical situations.
    
[^95]: 具有逐层非线性的状态空间模型是带有指数衰减记忆的全能逼近器

    State-space Models with Layer-wise Nonlinearity are Universal Approximators with Exponential Decaying Memory. (arXiv:2309.13414v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2309.13414](http://arxiv.org/abs/2309.13414)

    本论文证明了堆叠具有逐层非线性激活的状态空间模型足以逼近任何连续的序列到序列关系，并且发现其加强了模型学习复杂序列模式的能力。然而，状态空间模型并不能根本解决指数衰减记忆的问题。

    

    由于其简单有效的网络结构，状态空间模型在序列建模中变得越来越受欢迎。然而，沿时间方向缺乏非线性激活限制了模型的容量。本文证明了堆叠具有逐层非线性激活的状态空间模型足以逼近任何连续的序列到序列关系。我们的研究结果表明，逐层非线性激活的添加提高了模型学习复杂序列模式的能力。与此同时，可以从理论和实证上看到，状态空间模型并不根本解决指数衰减记忆的问题。理论结果经过了数值验证。

    State-space models have gained popularity in sequence modelling due to their simple and efficient network structures. However, the absence of nonlinear activation along the temporal direction limits the model's capacity. In this paper, we prove that stacking state-space models with layer-wise nonlinear activation is sufficient to approximate any continuous sequence-to-sequence relationship. Our findings demonstrate that the addition of layer-wise nonlinear activation enhances the model's capacity to learn complex sequence patterns. Meanwhile, it can be seen both theoretically and empirically that the state-space models do not fundamentally resolve the exponential decaying memory issue. Theoretical results are justified by numerical verifications.
    
[^96]: 基于物理引导特征提取和领域适应的跨托卡马克破裂预测

    Cross-tokamak Disruption Prediction based on Physics-Guided Feature Extraction and domain adaptation. (arXiv:2309.05361v2 [physics.plasm-ph] UPDATED)

    [http://arxiv.org/abs/2309.05361](http://arxiv.org/abs/2309.05361)

    本文介绍了一种新颖的方法，使用少量放电预测未来托卡马克的破裂，并应用了物理引导特征提取和领域适应算法。这种方法在J-TEXT中取得了出色的破裂预测性能。

    

    未来托卡马克中高昂的数据获取成本和对破裂放电的巨大需求给数据驱动破裂预测模型在破裂预测研究中带来了内在矛盾。在本文中，我们展示了一种新颖的方法，使用只有少量放电来预测未来托卡马克的破裂。第一步是利用对各个托卡马克的诊断信号的现有物理理解来提取物理引导特征，称为物理引导特征提取（PGFE）。第二步是根据一种称为CORrelation ALignment（CORAL）的领域适应算法，将未来托卡马克（目标领域）的少量数据与现有托卡马克（源领域）的大量数据进行对齐。这是第一次尝试将领域适应应用于破裂预测任务中。PGFE已成功应用于J-TEXT以实现出色的破裂预测性能。由于提取了物理引导特征，PGFE还可以减少数据量要求。

    The high acquisition cost and the significant demand for disruptive discharges for data-driven disruption prediction models in future tokamaks pose an inherent contradiction in disruption prediction research. In this paper, we demonstrated a novel approach to predict disruption in a future tokamak using only a few discharges. The first step is to use the existing understanding of physics to extract physics-guided features from the diagnostic signals of each tokamak, called physics-guided feature extraction (PGFE). The second step is to align a few data from the future tokamak (target domain) and a large amount of data from existing tokamak (source domain) based on a domain adaptation algorithm called CORrelation ALignment (CORAL). It is the first attempt at applying domain adaptation in the task of disruption prediction. PGFE has been successfully applied in J-TEXT to predict disruption with excellent performance. PGFE can also reduce the data volume requirements due to extracting the 
    
[^97]: 自动驾驶中运动预测的高效基线

    Efficient Baselines for Motion Prediction in Autonomous Driving. (arXiv:2309.03387v1 [cs.RO])

    [http://arxiv.org/abs/2309.03387](http://arxiv.org/abs/2309.03387)

    这项研究提出了自动驾驶中运动预测的高效基线模型，解决了使用地图和过去轨迹信息的实时应用复杂性和可解释性的问题。

    

    在任意复杂的环境中，从简单机器人到自动驾驶系统中，多方周围代理的运动预测是一项关键任务。当前的技术通过端到端的流程来解决这个问题，其中输入数据通常是物理信息的渲染顶视图和最相关代理的过去轨迹；利用这些信息是获得最佳性能的必需。在这个意义上，可靠的自动驾驶系统必须及时产生合理的预测。然而，当前的高端模型可能对于同时使用地图和过去轨迹这两种信息以及极少可解释性的物理信息的实时应用而言过于复杂。此外，这些模型的性能高度依赖于每个特定交通场景的可用输入数量，而这些输入难以获取，成本高昂。

    Motion Prediction (MP) of multiple surroundings agents is a crucial task in arbitrarily complex environments, from simple robots to Autonomous Driving Stacks (ADS). Current techniques tackle this problem using end-to-end pipelines, where the input data is usually a rendered top-view of the physical information and the past trajectories of the most relevant agents; leveraging this information is a must to obtain optimal performance. In that sense, a reliable ADS must produce reasonable predictions on time. However, despite many approaches use simple ConvNets and LSTMs to obtain the social latent features, State-Of-The-Art (SOTA) models might be too complex for real-time applications when using both sources of information (map and past trajectories) as well as little interpretable, specially considering the physical information. Moreover, the performance of such models highly depends on the number of available inputs for each particular traffic scenario, which are expensive to obtain, pa
    
[^98]: YaRN: 大型语言模型的高效上下文窗口扩展方法

    YaRN: Efficient Context Window Extension of Large Language Models. (arXiv:2309.00071v1 [cs.CL])

    [http://arxiv.org/abs/2309.00071](http://arxiv.org/abs/2309.00071)

    YaRN是一种高效的上下文窗口扩展方法，可以在大型语言模型中有效利用和推断比原始预训练允许的上下文长度更长的上下文，同时超越了之前的最新研究成果。

    

    旋转位置嵌入（RoPE）已被证明可以有效地编码transformer-based语言模型中的位置信息。然而，这些模型在超过它们训练的序列长度时无法泛化。我们提出了YaRN（Yet another RoPE extensioN method），一种计算高效的方法来扩展这些模型的上下文窗口，需要的tokens数量和训练步骤少于之前的方法的10倍和2.5倍。使用YaRN，我们展示了LLaMA模型可以有效地利用和推断比原始预训练允许的上下文长度更长的上下文，并且在上下文窗口扩展方面超过了之前的最新研究成果。此外，我们还展示了YaRN具有超越微调数据集有限上下文的能力。我们在https://github.com/jquesnelle/yarn上发布了使用64k和128k上下文窗口进行Fine-tuning的Llama 2 7B/13B的检查点。

    Rotary Position Embeddings (RoPE) have been shown to effectively encode positional information in transformer-based language models. However, these models fail to generalize past the sequence length they were trained on. We present YaRN (Yet another RoPE extensioN method), a compute-efficient method to extend the context window of such models, requiring 10x less tokens and 2.5x less training steps than previous methods. Using YaRN, we show that LLaMA models can effectively utilize and extrapolate to context lengths much longer than their original pre-training would allow, while also surpassing previous the state-of-the-art at context window extension. In addition, we demonstrate that YaRN exhibits the capability to extrapolate beyond the limited context of a fine-tuning dataset. We publish the checkpoints of Llama 2 7B/13B fine-tuned using YaRN with 64k and 128k context windows at https://github.com/jquesnelle/yarn
    
[^99]: CReHate: 跨文化重新注释英语仇恨言论数据集

    CReHate: Cross-cultural Re-annotation of English Hate Speech Dataset. (arXiv:2308.16705v1 [cs.CL])

    [http://arxiv.org/abs/2308.16705](http://arxiv.org/abs/2308.16705)

    CReHate通过跨文化重新注释英语仇恨言论数据集，揭示了来自不同国家的个体对仇恨言论的不同看法，并引入了一种具有文化敏感性的分类器。这些发现强调了重新评估NLP研究在仇恨言论领域的必要性。

    

    英语数据集主要反映了特定国家的观点，这可能导致模型和数据集中存在文化偏差。这在受主观性影响较大的任务，如仇恨言论检测中特别有问题。为了深入了解来自不同国家的个体如何理解仇恨言论，我们介绍了CReHate，对抽样的SBIC数据集进行了跨文化重新注释。该数据集包括来自五个不同国家的注释：澳大利亚、新加坡、南非、英国和美国。我们进行了彻底的统计分析，发现基于国籍存在显著差异，只有59.4%的样本在所有国家之间达成共识。我们还通过迁移学习引入了一种具有文化敏感性的仇恨言论分类器，能够捕捉不同国籍的观点。这些发现强调了需要重新评估自然语言处理研究的某些方面，特别是对于仇恨言论的细微性质。

    English datasets predominantly reflect the perspectives of certain nationalities, which can lead to cultural biases in models and datasets. This is particularly problematic in tasks heavily influenced by subjectivity, such as hate speech detection. To delve into how individuals from different countries perceive hate speech, we introduce CReHate, a cross-cultural re-annotation of the sampled SBIC dataset. This dataset includes annotations from five distinct countries: Australia, Singapore, South Africa, the United Kingdom, and the United States. Our thorough statistical analysis highlights significant differences based on nationality, with only 59.4% of the samples achieving consensus among all countries. We also introduce a culturally sensitive hate speech classifier via transfer learning, adept at capturing perspectives of different nationalities. These findings underscore the need to re-evaluate certain aspects of NLP research, especially with regard to the nuanced nature of hate spe
    
[^100]: 多元时间序列异常检测: 炫酷算法和有缺陷的评估方法

    Multivariate Time Series Anomaly Detection: Fancy Algorithms and Flawed Evaluation Methodology. (arXiv:2308.13068v1 [cs.LG])

    [http://arxiv.org/abs/2308.13068](http://arxiv.org/abs/2308.13068)

    多元时间序列异常检测是一个研究领域，但目前存在组织不够有序和评估协议有缺陷的问题。文章评估了许多最近算法的性能，并指出了针对多元时间序列异常检测的评估协议存在的问题及如何缓解这些问题的方法。

    

    多元时间序列（MVTS）的异常检测是一个长期存在且具有挑战性的研究课题，近年来吸引了工业界和学术界的大量研究努力。然而，对文献的仔细研究让我们意识到：1）该领域的社区活跃，但并不像计算机视觉（CV）和自然语言处理（NLP）等其他机器学习领域那样组织有序；2）大多数提出的解决方案使用不合适或存在明显缺陷的评估协议进行评估，缺乏科学基础。其中一个非常流行的协议，即所谓的 \pa 协议，是如此有缺陷，以至于随机猜测可以显示系统地优于迄今为止开发的\emph{所有}算法。在本文中，我们使用更健壮的协议对许多最近的算法进行回顾和评估，并讨论在MVTS异常检测的背景下，一个本来很好的协议可能存在的问题以及如何减轻这些问题。我们还对基准数据集表达了关切。

    Multivariate Time Series (MVTS) anomaly detection is a long-standing and challenging research topic that has attracted tremendous research effort from both industry and academia recently. However, a careful study of the literature makes us realize that 1) the community is active but not as organized as other sibling machine learning communities such as Computer Vision (CV) and Natural Language Processing (NLP), and 2) most proposed solutions are evaluated using either inappropriate or highly flawed protocols, with an apparent lack of scientific foundation. So flawed is one very popular protocol, the so-called \pa protocol, that a random guess can be shown to systematically outperform \emph{all} algorithms developed so far. In this paper, we review and evaluate many recent algorithms using more robust protocols and discuss how a normally good protocol may have weaknesses in the context of MVTS anomaly detection and how to mitigate them. We also share our concerns about benchmark dataset
    
[^101]: ALGAN：具有调整的LSTM GAN的时间序列异常检测

    ALGAN: Time Series Anomaly Detection with Adjusted-LSTM GAN. (arXiv:2308.06663v1 [cs.LG])

    [http://arxiv.org/abs/2308.06663](http://arxiv.org/abs/2308.06663)

    该论文提出了一种名为ALGAN的新型GAN模型，通过调整LSTM网络的输出，实现了在无监督设置下对单变量和多变量时间序列数据进行异常检测，并在实验中优于传统方法和其他GAN方法。

    

    时间序列数据中的异常检测是各个领域（如制造业，医学成像和网络安全）中常见的问题，旨在识别偏离正常行为的点。最近，生成对抗网络（GANs）在检测时间序列数据中的异常方面显示出了有效性。GANs的神经网络结构（即生成器和鉴别器）可以显着提高异常检测准确性。本文提出了一种新的GAN模型，名为Adjusted-LSTM GAN（ALGAN），它调整LSTM网络的输出，以提高单变量和多变量时间序列数据的异常检测能力，而且是在无监督设置下进行的。我们在46个真实世界的单变量时间序列数据集和涵盖多个领域的大型多变量数据集上评估了ALGAN的性能。我们的实验表明，ALGAN在时间序列数据的异常检测中优于传统的、基于神经网络的和其他基于GAN的方法。

    Anomaly detection in time series data, to identify points that deviate from normal behaviour, is a common problem in various domains such as manufacturing, medical imaging, and cybersecurity. Recently, Generative Adversarial Networks (GANs) are shown to be effective in detecting anomalies in time series data. The neural network architecture of GANs (i.e. Generator and Discriminator) can significantly improve anomaly detection accuracy. In this paper, we propose a new GAN model, named Adjusted-LSTM GAN (ALGAN), which adjusts the output of an LSTM network for improved anomaly detection in both univariate and multivariate time series data in an unsupervised setting. We evaluate the performance of ALGAN on 46 real-world univariate time series datasets and a large multivariate dataset that spans multiple domains. Our experiments demonstrate that ALGAN outperforms traditional, neural network-based, and other GAN-based methods for anomaly detection in time series data.
    
[^102]: AIs的发展脱靴法

    Developmental Bootstrapping of AIs. (arXiv:2308.04586v1 [cs.AI])

    [http://arxiv.org/abs/2308.04586](http://arxiv.org/abs/2308.04586)

    传统的符号AI方法和深度学习AI方法无法满足创建强大和可信赖的AI的挑战，然而，发展脱靴法通过模仿人类儿童的能力发展过程，为创建稳健可靠的AI提供了希望。

    

    尽管当前一些AI在封闭的世界，如棋盘游戏中超越了人类能力，但它们在混乱的现实世界中的表现有限。它们会犯奇怪的错误而且没有意识到。它们很难受到指导，不能运用常识，缺乏好奇心。它们不能成为良好的合作者。传统手动构建的符号AI方法构建的系统和使用生成和深度学习AI方法(包括大规模语言模型)构建的系统都无法应对这些挑战。它们不适合创建强大和可信赖的AI。尽管此方法不属于主流的AI方法，但发展脱靴法显示出希望。在发展脱靴法中，AI像人类儿童一样发展能力。它们从先天能力开始。像人类一样，它们与环境互动，并从互动中学习。它们通过自我发展的能力逐步扩展先天能力。它们互动并逐渐将所学应用于实际操作。

    Although some current AIs surpass human abilities especially in closed worlds such as board games, their performance in the messy real world is limited. They make strange mistakes and do not notice them. They cannot be instructed easily, fail to use common sense, and lack curiosity. They do not make good collaborators. Neither systems built using the traditional manually-constructed symbolic AI approach nor systems built using generative and deep learning AI approaches including large language models (LLMs) can meet the challenges. They are not well suited for creating robust and trustworthy AIs. Although it is outside of mainstream AI approaches, developmental bootstrapping shows promise. In developmental bootstrapping, AIs develop competences like human children do. They start with innate competences. Like humans, they interact with the environment and learn from their interactions. They incrementally extend their innate competences with self-developed competences. They interact and 
    
[^103]: 人工智能解释性对人工智能决策的影响

    The Impact of Imperfect XAI on Human-AI Decision-Making. (arXiv:2307.13566v1 [cs.HC])

    [http://arxiv.org/abs/2307.13566](http://arxiv.org/abs/2307.13566)

    本研究通过一个混合方法用户研究，评估了不正确的解释如何影响人类的决策行为，以增进人工智能解释性对人工智能决策的理解。

    

    解释性技术正在快速发展，以改进各种合作工作环境下的人工智能决策。因此，先前的研究评估了决策者与不完美的人工智能协作的方式，研究合适的依赖关系和任务表现，以便设计更加以人为中心的计算机支持的协作工具。一些以人为中心的可解释人工智能（XAI）技术被提出，希望改善决策者与人工智能的合作；然而，这些技术基于先前研究的发现，主要关注错误的人工智能建议的影响。很少有研究承认即使人工智能建议正确，解释也可能是错误的。因此，了解不完美的解释性人工智能如何影响人工智能决策至关重要。在这项工作中，我们通过一个强大的混合方法用户研究，涉及136名参与者，评估了不正确的解释如何影响人类的决策行为。

    Explainability techniques are rapidly being developed to improve human-AI decision-making across various cooperative work settings. Consequently, previous research has evaluated how decision-makers collaborate with imperfect AI by investigating appropriate reliance and task performance with the aim of designing more human-centered computer-supported collaborative tools. Several human-centered explainable AI (XAI) techniques have been proposed in hopes of improving decision-makers' collaboration with AI; however, these techniques are grounded in findings from previous studies that primarily focus on the impact of incorrect AI advice. Few studies acknowledge the possibility for the explanations to be incorrect even if the AI advice is correct. Thus, it is crucial to understand how imperfect XAI affects human-AI decision-making. In this work, we contribute a robust, mixed-methods user study with 136 participants to evaluate how incorrect explanations influence humans' decision-making beha
    
[^104]: 用于训练拥有数十亿参数的大型语言模型的优化网络架构

    Optimized Network Architectures for Large Language Model Training with Billions of Parameters. (arXiv:2307.12169v1 [cs.NI])

    [http://arxiv.org/abs/2307.12169](http://arxiv.org/abs/2307.12169)

    本文提出了一种优化的网络架构，用于训练拥有数十亿参数的大型语言模型。这个架构根据语言模型的通信需求，将集群分割成一组通过非阻塞高带宽互连的GPU集合，并通过轨道连接仅连接具有通信需求的GPU，从而降低网络成本高达75％，同时不影响训练性能。

    

    本文挑战了为训练大型语言模型（LLMs）构建任意到任意网络的传统范式。我们展示了LLMs呈现出一种独特的通信模式，在其中，只有小组的GPU需要高带宽的任意到任意通信，以实现接近最优的训练性能。在这些GPU小组之间，通信非常微不足道、稀疏且均匀。我们提出了一个新的网络架构，紧密匹配LLMs的通信需求。我们的架构将集群分割为一组通过非阻塞任意到任意高带宽互连的GPU集合，我们称之为HB域。在HB域之间，网络只连接具有通信需求的GPU。我们将这种网络连接称为“仅轨道连接”，并展示了我们的架构相对于最先进的任意到任意Clos网络可以将网络成本降低高达75％，同时不损害LLM训练的性能。

    This paper challenges the well-established paradigm for building any-to-any networks for training Large Language Models (LLMs). We show that LLMs exhibit a unique communication pattern where only small groups of GPUs require high-bandwidth any-to-any communication within them, to achieve near-optimal training performance. Across these groups of GPUs, the communication is insignificant, sparse, and homogeneous. We propose a new network architecture that closely resembles the communication requirement of LLMs. Our architecture partitions the cluster into sets of GPUs interconnected with non-blocking any-to-any high-bandwidth interconnects that we call HB domains. Across the HB domains, the network only connects GPUs with communication demands. We call this network a "rail-only" connection, and show that our proposed architecture reduces the network cost by up to 75% compared to the state-of-the-art any-to-any Clos networks without compromising the performance of LLM training.
    
[^105]: 解码谜团：在工作记忆的多个方面上对人类和人工智能进行基准测试

    Decoding the Enigma: Benchmarking Humans and AIs on the Many Facets of Working Memory. (arXiv:2307.10768v1 [q-bio.NC])

    [http://arxiv.org/abs/2307.10768](http://arxiv.org/abs/2307.10768)

    本论文介绍了一个全面的工作记忆基准数据集（WorM），通过评估4个功能、3个领域和11个行为和神经特征的WM任务来开发和评估AI WM模型。结果表明，AI模型能够模拟出脑中工作记忆的一些特征，如优势效应和最新性效应，以及专门用于不同领域和功能的工作记忆的神经群集和相关物。

    

    工作记忆（WM）是一种基本的认知过程，它促进了信息的临时存储、整合、操作和检索，在推理和决策任务中起着重要作用。捕捉工作记忆多方面特征的可靠基准数据集对于有效地开发和评估AI工作记忆模型至关重要。在这里，我们介绍了一个全面的工作记忆（WorM）基准数据集，以实现这个目的。WorM包括10个任务和总共100万次试验，评估了WM的4个功能、3个领域和11个行为和神经特征。我们在所有这些任务上共同训练和测试了最先进的循环神经网络和Transformer。我们还包括人类行为基准作为对比的上限。我们的结果表明，AI模型模拟了脑中工作记忆的一些特征，特别是优势效应和最新性效应，以及专门用于不同领域和功能性的工作记忆的神经群集和相关物。

    Working memory (WM), a fundamental cognitive process facilitating the temporary storage, integration, manipulation, and retrieval of information, plays a vital role in reasoning and decision-making tasks. Robust benchmark datasets that capture the multifaceted nature of WM are crucial for the effective development and evaluation of AI WM models. Here, we introduce a comprehensive Working Memory (WorM) benchmark dataset for this purpose. WorM comprises 10 tasks and a total of 1 million trials, assessing 4 functionalities, 3 domains, and 11 behavioral and neural characteristics of WM. We jointly trained and tested state-of-the-art recurrent neural networks and transformers on all these tasks. We also include human behavioral benchmarks as an upper bound for comparison. Our results suggest that AI models replicate some characteristics of WM in the brain, most notably primacy and recency effects, and neural clusters and correlates specialized for different domains and functionalities of WM
    
[^106]: 元学习对抗波段算法

    Meta-Learning Adversarial Bandit Algorithms. (arXiv:2307.02295v1 [cs.LG])

    [http://arxiv.org/abs/2307.02295](http://arxiv.org/abs/2307.02295)

    本论文研究了具有波段反馈的在线元学习，并设计了用于多臂赌博机和赌博线性优化的元算法。对于多臂赌博机，算法使用了Tsallis-熵的泛化Exp3，并且任务平均遗憾会随着最优解的熵的减小而改善。对于赌博线性优化，算法使用了自协调障碍正则化器初始化和调整在线镜像下降，并且任务平均遗憾与动作空间相关的度量直接变化。

    

    我们研究具有波段反馈的在线元学习，目标是在多个任务之间改善性能，如果它们根据某个自然的相似性度量是相似的。作为针对敌对的在线部分信息设置的首个目标，我们设计了元算法，将外层学习器结合在一起，同时为两种重要情况调整内部学习器的初始化和其他超参数：多臂赌博机（MAB）和赌博线性优化（BLO）。对于MAB，元学习器使用Tsallis-熵的泛化Exp3的初始化和设置超参数，如果后见之高峰的熵小，则任务平均遗憾改善。对于BLO，我们学会了使用自协调障碍正则化器初始化和调整在线镜像下降（OMD），表明任务平均遗憾与其引起的动作空间相关的度量直接变化。我们的保证基于证明无正规化跟随者与两个…

    We study online meta-learning with bandit feedback, with the goal of improving performance across multiple tasks if they are similar according to some natural similarity measure. As the first to target the adversarial online-within-online partial-information setting, we design meta-algorithms that combine outer learners to simultaneously tune the initialization and other hyperparameters of an inner learner for two important cases: multi-armed bandits (MAB) and bandit linear optimization (BLO). For MAB, the meta-learners initialize and set hyperparameters of the Tsallis-entropy generalization of Exp3, with the task-averaged regret improving if the entropy of the optima-in-hindsight is small. For BLO, we learn to initialize and tune online mirror descent (OMD) with self-concordant barrier regularizers, showing that task-averaged regret varies directly with an action space-dependent measure they induce. Our guarantees rely on proving that unregularized follow-the-leader combined with two 
    
[^107]: NNQS-Transformer: 一种高效可扩展的神经网络量子态方法用于从头计算量子化学

    NNQS-Transformer: an Efficient and Scalable Neural Network Quantum States Approach for Ab initio Quantum Chemistry. (arXiv:2306.16705v1 [quant-ph])

    [http://arxiv.org/abs/2306.16705](http://arxiv.org/abs/2306.16705)

    NNQS-Transformer是一种高效可扩展的神经网络量子态方法，用于从头计算量子化学。其主要创新包括基于Transformer的量子波函数安萨茨、数据中心并行化方案、并行批量采样策略和并行局域能量评估方案。研究结果显示了与最先进方法相比的优越精度和对于大分子系统的强可扩展性和弱可扩展性。

    

    神经网络量子态（NNQS）已成为量子多体问题的有希望的候选方法，但其实际应用常受到采样和局域能量计算的高成本的限制。我们开发了一种高性能的NNQS方法，用于从头电子结构计算。主要创新包括：（1）将Transformer作为量子波函数的安萨茨；（2）一种以数据为中心的并行化方案，用于变分蒙特卡洛（VMC）算法，可以保持数据的局部性并适应不同的计算架构；（3）一种并行批量采样策略，降低采样成本并实现良好的负载平衡；（4）一种既具有内存又具有计算效率的并行局域能量评估方案；（5）对真实化学系统的研究表明，我们的方法相比最先进方法具有更高的精度，并且对于具有高达120个自旋的大分子系统具有很强的可扩展性和弱可扩展性。

    Neural network quantum state (NNQS) has emerged as a promising candidate for quantum many-body problems, but its practical applications are often hindered by the high cost of sampling and local energy calculation. We develop a high-performance NNQS method for \textit{ab initio} electronic structure calculations. The major innovations include: (1) A transformer based architecture as the quantum wave function ansatz; (2) A data-centric parallelization scheme for the variational Monte Carlo (VMC) algorithm which preserves data locality and well adapts for different computing architectures; (3) A parallel batch sampling strategy which reduces the sampling cost and achieves good load balance; (4) A parallel local energy evaluation scheme which is both memory and computationally efficient; (5) Study of real chemical systems demonstrates both the superior accuracy of our method compared to state-of-the-art and the strong and weak scalability for large molecular systems with up to $120$ spin o
    
[^108]: 何去何从：深度学习加速的数字硬件视角

    To Spike or Not To Spike: A Digital Hardware Perspective on Deep Learning Acceleration. (arXiv:2306.15749v1 [cs.NE])

    [http://arxiv.org/abs/2306.15749](http://arxiv.org/abs/2306.15749)

    神经形态计算旨在通过仿真脑部操作来提高深度学习模型的效率，但是在SNNs的高效硬件后端设计上仍需进一步研究。

    

    随着深度学习模型规模的增加，它们在涵盖计算机视觉到自然语言处理等领域变得越来越有竞争力；然而，这是以效率为代价的，因为它们需要越来越多的内存和计算能力。生物脑的功耗效率超过任何大规模深度学习（DL）模型；因此，神经形态计算试图模仿脑部操作，例如基于脉冲的信息处理，以提高DL模型的效率。尽管脑部有诸如高效的信息传输、密集的神经元连接和计算与存储的共同位置等优势，但可用的生物基底严重限制了生物大脑的进化。电子硬件没有相同的约束；因此，虽然建模脉冲神经网络（SNNs）可能揭示了一个谜题的一部分，但对于SNNs的高效硬件后端设计需要进一步研究。

    As deep learning models scale, they become increasingly competitive from domains spanning computer vision to natural language processing; however, this happens at the expense of efficiency since they require increasingly more memory and computing power. The power efficiency of the biological brain outperforms the one of any large-scale deep learning (DL) model; thus, neuromorphic computing tries to mimic the brain operations, such as spike-based information processing, to improve the efficiency of DL models. Despite the benefits of the brain, such as efficient information transmission, dense neuronal interconnects, and the co-location of computation and memory, the available biological substrate has severely constrained the evolution of biological brains. Electronic hardware does not have the same constraints; therefore, while modeling spiking neural networks (SNNs) might uncover one piece of the puzzle, the design of efficient hardware backends for SNNs needs further investigation, po
    
[^109]: 针对潜在混淆下的因果结果的更紧密预测区间

    Tighter Prediction Intervals for Causal Outcomes Under Hidden Confounding. (arXiv:2306.09520v1 [cs.LG])

    [http://arxiv.org/abs/2306.09520](http://arxiv.org/abs/2306.09520)

    本文提出了一种名为Caus-Modens的算法，通过调制集合来描述因果结果区间，相比符合性预测方法，能够在实践中给出更紧密的结果区间。

    

    在存在隐藏混淆因素的情况下进行确切个体治疗结果的因果推断很少可能。因此，最近的研究改进了符合性预测方法，以产生结果区间。不幸的是，这类方法往往过于保守，有时会给出无信息量的区间。我们介绍了一种另类方法Caus-Modens，用于通过调制集合来描述因果结果区间。受到贝叶斯统计和集成不确定性量化的启发，Caus-Modens在实践中给出更紧密的结果区间，并通过三个分离基准测试的必要区间大小来实现足够的覆盖率。最后一个基准是使用未知但可探明的基础事实开展观察实验的GPT-4的新型用途。

    Causal inference of exact individual treatment outcomes in the presence of hidden confounders is rarely possible. Instead, recent work has adapted conformal prediction to produce outcome intervals. Unfortunately this family of methods tends to be overly conservative, sometimes giving uninformative intervals. We introduce an alternative approach termed Caus-Modens, for characterizing causal outcome intervals by modulated ensembles. Motivated from Bayesian statistics and ensembled uncertainty quantification, Caus-Modens gives tighter outcome intervals in practice, measured by the necessary interval size to achieve sufficient coverage on three separate benchmarks. The last benchmark is a novel usage of GPT-4 for observational experiments with unknown but probeable ground truth.
    
[^110]: 鲁棒性AI生成文本检测的内部维度估计

    Intrinsic Dimension Estimation for Robust Detection of AI-Generated Texts. (arXiv:2306.04723v1 [cs.CL])

    [http://arxiv.org/abs/2306.04723](http://arxiv.org/abs/2306.04723)

    本文提出了衡量文本内部维度的方法，应用于鲁棒性AI生成文本的检测，展示了人类文本与AI生成文本在内部维度上的差异。

    

    快速提高的AI生成内容的质量使得很难区分人类和AI生成的文本，这可能会对社会产生不良影响。因此，研究人类文本的不变属性变得越来越重要。本文提出了一种人类文本的不变特征，即给定文本样本嵌入集合下的流形的内部维度。我们展示了自然语言流畅文本的平均内部维度在几个基于字母的语言中约为 $9$，而中文约为 $7$，而每种语言的AI生成文本的平均内部维度较低，差约 $1.5$，并且有明显的统计分离。

    Rapidly increasing quality of AI-generated content makes it difficult to distinguish between human and AI-generated texts, which may lead to undesirable consequences for society. Therefore, it becomes increasingly important to study the properties of human texts that are invariant over text domains and various proficiency of human writers, can be easily calculated for any language, and can robustly separate natural and AI-generated texts regardless of the generation model and sampling method. In this work, we propose such an invariant of human texts, namely the intrinsic dimensionality of the manifold underlying the set of embeddings of a given text sample. We show that the average intrinsic dimensionality of fluent texts in natural language is hovering around the value $9$ for several alphabet-based languages and around $7$ for Chinese, while the average intrinsic dimensionality of AI-generated texts for each language is $\approx 1.5$ lower, with a clear statistical separation between
    
[^111]: 在图形的超出分布泛化中学习标签和环境因果独立性

    Joint Learning of Label and Environment Causal Independence for Graph Out-of-Distribution Generalization. (arXiv:2306.01103v1 [cs.LG])

    [http://arxiv.org/abs/2306.01103](http://arxiv.org/abs/2306.01103)

    本文提出了一种考虑标签和环境因果独立性的方法来解决图形超出分布（OOD）泛化问题，通过敌对训练策略来联合优化属性以获得有效结果，实验证明LECI显着优于之前的方法。

    

    我们解决了图形的超出分布（OOD）泛化问题。现有的图形OOD算法要么依赖于受限的假设，要么无法利用训练数据中的环境信息。在这项工作中，我们提出同时纳入标签和环境因果独立（LECI），充分利用标签和环境信息，从而解决之前的方法在识别因果和不变子图时面临的挑战。我们进一步开发了一种敌对训练策略，以联合优化这两个属性，用于具有理论保证的导致子图发现。广泛的实验和分析表明，LECI在合成和真实数据集上都显着优于之前的方法，将LECI确立为图形OOD泛化的实用有效解决方案。

    We tackle the problem of graph out-of-distribution (OOD) generalization. Existing graph OOD algorithms either rely on restricted assumptions or fail to exploit environment information in training data. In this work, we propose to simultaneously incorporate label and environment causal independence (LECI) to fully make use of label and environment information, thereby addressing the challenges faced by prior methods on identifying causal and invariant subgraphs. We further develop an adversarial training strategy to jointly optimize these two properties for casual subgraph discovery with theoretical guarantees. Extensive experiments and analysis show that LECI significantly outperforms prior methods on both synthetic and real-world datasets, establishing LECI as a practical and effective solution for graph OOD generalization.
    
[^112]: 协同人工智能的根源和要求

    Roots and Requirements for Collaborative AI. (arXiv:2303.12040v1 [cs.AI])

    [http://arxiv.org/abs/2303.12040](http://arxiv.org/abs/2303.12040)

    论文探讨了AI协同合作的历史和要求，是协同AI研究的动机和背景。

    

    AI协作者的愿景长期以来一直是科幻小说的经典素材，其中人工智能代理理解协作和人类沟通的微妙差别。它们通过贡献特殊的才能给他们的人类合作者和团队带来优势。多年来，政府咨询团体和人工智能领域的领袖一直倡导AIs应该具有人类兼容性和有效协作的能力。然而，具备像才华横溢的人那样协作能力的强大的AI仍然遥不可及。这篇论文依据对人工智能和人类代理有效和强大协作所需认知的分析，概述了公众和AI愿景中关于人工协作者的历史，开始于早期智能增强(IA)和人工智能(AI)的愿景。这篇论文旨在成为协同AI的第二个立场文件(Stefik & Price, 2023)的动机和背景。第二篇论文回顾了多学科的现状，并提出了一个AI协作研究的路线图。

    The vision of AI collaborators has long been a staple of science fiction, where artificial agents understand nuances of collaboration and human communication. They bring advantages to their human collaborators and teams by contributing their special talents. Government advisory groups and leaders in AI have advocated for years that AIs should be human compatible and be capable of effective collaboration. Nonetheless, robust AIs that can collaborate like talented people remain out of reach. This position paper draws on a cognitive analysis of what effective and robust collaboration requires of human and artificial agents. It sketches a history of public and AI visions for artificial collaborators, starting with early visions of intelligence augmentation (IA) and artificial intelligence (AI). It is intended as motivation and context for a second position paper on collaborative AI (Stefik & Price, 2023). The second paper reviews the multi-disciplinary state-of-the-art and proposes a roadm
    
[^113]: HDformer: 一种利用长距离血管信号进行糖尿病检测的高维Transformer

    HDformer: A Higher Dimensional Transformer for Diabetes Detection Utilizing Long Range Vascular Signals. (arXiv:2303.11340v1 [cs.LG])

    [http://arxiv.org/abs/2303.11340](http://arxiv.org/abs/2303.11340)

    本研究提出了一种新的基于高维Transformer的架构HDformer，并利用长距离PPG信号进行糖尿病检测，其中提出了一种新的注意力模块TSA，成功将标记体积减少10倍以上，提高了模型的能力和效率。

    

    糖尿病是全球性问题，早期检测有助于预防严重并发症。已出现将心血管信号纳入深度学习模型的低成本、非侵入式检测方法，但限制其临床应用的是有限的准确性。本文提出了一种新的基于Transformer的架构，即Higher Dimensional Transformer（HDformer），它利用长距离光电容积图（PPG）信号来检测糖尿病。相较于现有研究常用的不足一分钟的PPG信号，长距离PPG包含更广泛、更深入的信号上下文信息。为了增加处理长距离数据的能力和效率，我们提出了一种新的注意力模块Time Square Attention（TSA），将标记体积减少10倍以上，同时保留本地/全局依赖关系。它将一维输入 转换为二维表示，并将相邻点组成一个单独的2D标记。

    Diabetes mellitus is a worldwide concern, and early detection can help to prevent serious complications. Low-cost, non-invasive detection methods, which take cardiovascular signals into deep learning models, have emerged. However, limited accuracy constrains their clinical usage. In this paper, we present a new Transformer-based architecture, Higher Dimensional Transformer (HDformer), which takes long-range photoplethysmography (PPG) signals to detect diabetes. The long-range PPG contains broader and deeper signal contextual information compared to the less-than-one-minute PPG signals commonly utilized in existing research. To increase the capability and efficiency of processing the long range data, we propose a new attention module Time Square Attention (TSA), reducing the volume of the tokens by more than 10x, while retaining the local/global dependencies. It converts the 1-dimensional inputs into 2-dimensional representations and groups adjacent points into a single 2D token, using 
    
[^114]: 在联邦深度学习中优化批标准化

    Making Batch Normalization Great in Federated Deep Learning. (arXiv:2303.06530v1 [cs.LG])

    [http://arxiv.org/abs/2303.06530](http://arxiv.org/abs/2303.06530)

    本文研究了在联邦学习中使用批标准化和群组归一化的效果，发现在适当的处理下，批标准化可以在广泛的联邦学习设置中具有很高的竞争力，而且这不需要额外的训练或通信成本。

    This paper studies the use of batch normalization and group normalization in federated learning, and finds that with proper treatments, batch normalization can be highly competitive across a wide range of federated learning settings, and this requires no additional training or communication costs.

    批标准化（BN）通常用于现代深度神经网络（DNN）中，以提高稳定性并加速集中式训练的收敛速度。在具有非IID分散数据的联邦学习（FL）中，先前的研究观察到使用BN进行训练可能会由于训练和测试之间的BN统计不匹配而阻碍性能。因此，群组归一化（GN）更常用于FL作为BN的替代方法。然而，通过我们在各种FL设置下的实证研究，我们发现BN和GN之间没有一致的优胜者。这促使我们重新审视FL中归一化层的使用。我们发现，在适当的处理下，BN可以在广泛的FL设置中具有很高的竞争力，而且这不需要额外的训练或通信成本。我们希望我们的研究可以成为FL未来实际使用和理论分析的有价值参考。

    Batch Normalization (BN) is commonly used in modern deep neural networks (DNNs) to improve stability and speed up convergence during centralized training. In federated learning (FL) with non-IID decentralized data, previous works observed that training with BN could hinder performance due to the mismatch of the BN statistics between training and testing. Group Normalization (GN) is thus more often used in FL as an alternative to BN. However, from our empirical study across various FL settings, we see no consistent winner between BN and GN. This leads us to revisit the use of normalization layers in FL. We find that with proper treatments, BN can be highly competitive across a wide range of FL settings, and this requires no additional training or communication costs. We hope that our study could serve as a valuable reference for future practical usage and theoretical analysis in FL.
    
[^115]: 作为多Agent强化学习基准的重复剪刀石头布的基于人口评估

    Population-based Evaluation in Repeated Rock-Paper-Scissors as a Benchmark for Multiagent Reinforcement Learning. (arXiv:2303.03196v2 [cs.GT] UPDATED)

    [http://arxiv.org/abs/2303.03196](http://arxiv.org/abs/2303.03196)

    这项研究提出了一种基于重复剪刀石头布游戏的多Agent学习基准，展示了几种学习方法的泛化能力，为多Agent学习领域的研究提供了机会。

    

    机器学习和对抗规划领域的进展，很大程度上受益于基准域，从国际象棋和经典的UCI数据集到围棋和外交。在顺序决策中，对Agent评估主要局限于与专家进行少量交互，旨在达到一定的性能水平（如击败人类专业玩家）。我们提出了一种基于剪刀石头布的多Agent学习基准，其中包括四十三个锦标赛参赛作品，其中一些是有意的次优作品。我们描述了基于平均回报和可开发性的代理质量度量标准。然后，我们展示了几种RL、在线学习和语言模型方法可以学习良好的反策略，并具有良好的泛化能力，但最终会输给表现最佳的机器人，为多Agent学习的研究提供了机会。

    Progress in fields of machine learning and adversarial planning has benefited significantly from benchmark domains, from checkers and the classic UCI data sets to Go and Diplomacy. In sequential decision-making, agent evaluation has largely been restricted to few interactions against experts, with the aim to reach some desired level of performance (e.g. beating a human professional player). We propose a benchmark for multiagent learning based on repeated play of the simple game Rock, Paper, Scissors along with a population of forty-three tournament entries, some of which are intentionally sub-optimal. We describe metrics to measure the quality of agents based both on average returns and exploitability. We then show that several RL, online learning, and language model approaches can learn good counter-strategies and generalize well, but ultimately lose to the top-performing bots, creating an opportunity for research in multiagent learning.
    
[^116]: 基于模型的强化学习在能源市场清算和出价中的应用研究

    Approximating Energy Market Clearing and Bidding With Model-Based Reinforcement Learning. (arXiv:2303.01772v2 [eess.SY] UPDATED)

    [http://arxiv.org/abs/2303.01772](http://arxiv.org/abs/2303.01772)

    本文研究了基于模型的强化学习用于能源市场清算和出价的应用方法。通过用学习的OPF代理模型以及明确的市场规则替代传统计算方法，本方法极大地减少了训练时间并适用于市场设计和更现实地建模市场参与者。

    

    能源市场可能会为市场参与者的不良行为提供激励。多智能体强化学习是预测能源市场参与者预期行为的有前途的新方法。然而，强化学习需要许多与系统的交互才能收敛，而电力系统环境通常包括广泛的计算，例如用于市场清算的最优功率流量（OPF）计算。为了解决这个复杂性，我们提供了一个能源市场的模型给基本的MARL算法，这个模型采用了学习的OPF近似值和明确的市场规则。学习的OPF代理模型使得OPF的明确解决变得不必要。我们的实验表明，该模型还将训练时间降低了约一个数量级，但代价是略微更差的纳什均衡近似值。我们方法的潜在应用是市场设计，更现实地对市场参与者进行建模以及对市场动态的改进理解。

    Energy markets can provide incentives for undesired behavior of market participants. Multi-agent Reinforcement learning (MARL) is a promising new approach to predicting the expected behavior of energy market participants. However, reinforcement learning requires many interactions with the system to converge, and the power system environment often consists of extensive computations, e.g., optimal power flow (OPF) calculation for market clearing. To tackle this complexity, we provide a model of the energy market to a basic MARL algorithm in the form of a learned OPF approximation and explicit market rules. The learned OPF surrogate model makes an explicit solving of the OPF completely unnecessary. Our experiments demonstrate that the model additionally reduces training time by about one order of magnitude but at the cost of a slightly worse approximation of the Nash equilibrium. Potential applications of our method are market design, more realistic modeling of market participants, and an
    
[^117]: 通过物理对称学习可解释的低维表示

    Learning Interpretable Low-dimensional Representation via Physical Symmetry. (arXiv:2302.10890v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.10890](http://arxiv.org/abs/2302.10890)

    通过使用物理对称性作为潜在空间的自洽约束条件，该研究展示了在音乐领域和计算机视觉领域，模型可以以无监督的方式学习出可解释的低维表示，例如线性音高和三维笛卡尔因素。

    

    可解释的表示学习在创造性智能系统中起着关键作用。在音乐领域，当前的学习算法可以成功地学习各种特征，如音高、音色、和弦、纹理等。然而，大多数方法严重依赖音乐领域知识。现在还不清楚什么样的一般性计算原则会产生可解释的表示，特别是与人类感知保持一致的低维因素。在这项研究中，我们从现代物理学中获得灵感，将物理对称性作为潜在空间的自洽约束条件。特别是，它要求先验模型对潜在状态的动态进行描述，并以某种群变换对其进行等变。我们展示了物理对称性使得模型能够以无监督的方式从未标记的单声道音乐音频中学习一个线性音高因素。此外，相同的方法可以应用于计算机视觉，学习一个三维笛卡尔因素。

    Interpretable representation learning has been playing a key role in creative intelligent systems. In the music domain, current learning algorithms can successfully learn various features such as pitch, timbre, chord, texture, etc. However, most methods rely heavily on music domain knowledge. It remains an open question what general computational principles give rise to interpretable representations, especially low-dim factors that agree with human perception. In this study, we take inspiration from modern physics and use physical symmetry as a self-consistency constraint for the latent space. Specifically, it requires the prior model that characterises the dynamics of the latent states to be equivariant with respect to certain group transformations. We show that physical symmetry leads the model to learn a linear pitch factor from unlabelled monophonic music audio in a self-supervised fashion. In addition, the same methodology can be applied to computer vision, learning a 3D Cartesian
    
[^118]: 基于神经多样性的视觉想象和程序合成的ARC问题求解器

    A Neurodiversity-Inspired Solver for the Abstraction \& Reasoning Corpus (ARC) Using Visual Imagery and Program Synthesis. (arXiv:2302.09425v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2302.09425](http://arxiv.org/abs/2302.09425)

    本研究提出了一种基于神经多样性的新的人工智能方法，其中结合了人类心理想象能力中受到神经多样性研究启发的核心知识的视觉表示和基于树搜索的程序合成，在解决新任务时，能够灵活地组合核心知识来形成新的推理策略。

    

    虽然近年来在某些领域（如视觉、自然语言处理）的人工智能技术已经取得了巨大的进展，但目前还没有任何人工智能系统能够像人类一样灵活地运用核心知识来解决新任务。我们提出了一种新的人工智能方法，将人类心理想象能力中受到神经多样性研究启发的核心知识的视觉表示与基于树搜索的程序合成相结合，以灵活地组合核心知识来形成新的推理策略。我们展示了我们系统在非常困难的ARC挑战中的表现，并分享了来自公开可用的ARC项以及我们在比赛中获得第四名的实验结果。

    Core knowledge about physical objects -- e.g., their permanency, spatial transformations, and interactions -- is one of the most fundamental building blocks of biological intelligence across humans and non-human animals. While AI techniques in certain domains (e.g. vision, NLP) have advanced dramatically in recent years, no current AI systems can yet match human abilities in flexibly applying core knowledge to solve novel tasks. We propose a new AI approach to core knowledge that combines 1) visual representations of core knowledge inspired by human mental imagery abilities, especially as observed in studies of neurodivergent individuals; with 2) tree-search-based program synthesis for flexibly combining core knowledge to form new reasoning strategies on the fly. We demonstrate our system's performance on the very difficult Abstraction \& Reasoning Corpus (ARC) challenge, and we share experimental results from publicly available ARC items as well as from our 4th-place finish on the pri
    
[^119]: LEXTREME：多语言和多任务的法律领域基准

    LEXTREME: A Multi-Lingual and Multi-Task Benchmark for the Legal Domain. (arXiv:2301.13126v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.13126](http://arxiv.org/abs/2301.13126)

    LEXTREME是一个多语言和多任务的法律领域基准，该基准提供了11个数据集涵盖24种语言的测评，最佳模型（XLM-R large）在数据集和语言综合评分上均达到了61.3。这使得LEXTREME仍然具有挑战性并且有改进空间。

    

    最近，在transformer架构的显著进展推动下，法律自然语言处理领域取得了惊人的增长。为了衡量进展，精心策划和具有挑战性的基准是至关重要的。然而，大多数基准只能处理英文，而在法律自然语言处理方面尚未有多语言基准可用。此外，许多基准已经饱和，最佳模型明显优于最佳人类，并达到近乎完美的分数。我们调查了法律自然语言处理文献，并选择了11个涵盖24种语言的数据集，创建了LEXTREME。为了进行公平比较，我们提出了两种综合评分，一种基于数据集，一种基于语言。最佳基线模型（XLM-R large）在数据集综合评分和语言综合评分上均达到了61.3。这表明LEXTREME仍然非常具有挑战性，并且为改进留下了充足空间。为了方便研究人员和实践者使用，我们将LEXTREME与所有数据一起发布在huggingface上。

    Lately, propelled by the phenomenal advances around the transformer architecture, the legal NLP field has enjoyed spectacular growth. To measure progress, well curated and challenging benchmarks are crucial. However, most benchmarks are English only and in legal NLP specifically there is no multilingual benchmark available yet. Additionally, many benchmarks are saturated, with the best models clearly outperforming the best humans and achieving near perfect scores. We survey the legal NLP literature and select 11 datasets covering 24 languages, creating LEXTREME. To provide a fair comparison, we propose two aggregate scores, one based on the datasets and one on the languages. The best baseline (XLM-R large) achieves both a dataset aggregate score a language aggregate score of 61.3. This indicates that LEXTREME is still very challenging and leaves ample room for improvement. To make it easy for researchers and practitioners to use, we release LEXTREME on huggingface together with all the
    
[^120]: 学习必要和充分因果图

    On Learning Necessary and Sufficient Causal Graphs. (arXiv:2301.12389v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.12389](http://arxiv.org/abs/2301.12389)

    本文提出了一种学习必要和充分因果图的方法，用于发现与感兴趣结果相关的因果关系。

    

    因果革命激发了对各个领域中复杂关系的兴趣。大多数现有方法旨在在复杂的大规模图中发现所有变量之间的因果关系。然而，在实践中，图中仅有的一小部分变量与感兴趣的结果相关。因此，使用完整的因果图进行因果估计，特别是在数据有限的情况下，可能会导致大量错误发现的虚假变量，这些虚假变量与目标结果高度相关，但对目标结果没有因果影响。在本文中，我们提出了一种学习必要和充分因果图 (NSCG) 的方法，该方法专门由与感兴趣结果因果相关的变量组成，我们将其称为因果特征。关键思想是利用因果概率系统地评估因果图中特征的重要性，从而帮助我们确定与感兴趣的结果相关的子图。

    The causal revolution has stimulated interest in understanding complex relationships in various fields. Most of the existing methods aim to discover causal relationships among all variables within a complex large-scale graph. However, in practice, only a small subset of variables in the graph are relevant to the outcomes of interest. Consequently, causal estimation with the full causal graph -- particularly given limited data -- could lead to numerous falsely discovered, spurious variables that exhibit high correlation with, but exert no causal impact on, the target outcome. In this paper, we propose learning a class of necessary and sufficient causal graphs (NSCG) that exclusively comprises causally relevant variables for an outcome of interest, which we term causal features. The key idea is to employ probabilities of causation to systematically evaluate the importance of features in the causal graph, allowing us to identify a subgraph relevant to the outcome of interest. To learn NSC
    
[^121]: 什么会减弱编辑能力？面向特定领域的混合细化方法用于改善GAN反演

    What Decreases Editing Capability? Domain-Specific Hybrid Refinement for Improved GAN Inversion. (arXiv:2301.12141v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2301.12141](http://arxiv.org/abs/2301.12141)

    这篇论文提出了面向特定领域的混合细化方法，用于改善GAN反演结果中的编辑能力减弱问题。该方法通过将图像分为域内和域外部分，并对这两部分进行权重调节细化，以保持域内区域的编辑能力并提高保真度。

    

    最近，反演方法关注生成器中的额外高比率信息（例如，权重或中间特征），以优化从嵌入式潜在代码进行反演和编辑的结果。虽然这些技术在重建方面取得了合理的改进，但它们会减弱编辑能力，尤其是在复杂图像（例如包含遮挡，详细背景和伪影的图像）上。关键在于精细化反演结果，避免编辑能力降级。为了解决这个问题，我们引入了面向特定领域的混合细化（DHR），利用了两种主流细化技术的优点和缺点，以保持编辑能力和保证保真度的提高。具体来说，我们首先提出了面向特定领域的分割方法，将图像分成两个部分：域内和域外部分。细化过程旨在保持域内区域的可编辑性并提高两个域的保真度。我们通过权重调节来细化这两个部分。

    Recently, inversion methods have focused on additional high-rate information in the generator (e.g., weights or intermediate features) to refine inversion and editing results from embedded latent codes. Although these techniques gain reasonable improvement in reconstruction, they decrease editing capability, especially on complex images (e.g., containing occlusions, detailed backgrounds, and artifacts). A vital crux is refining inversion results, avoiding editing capability degradation. To tackle this problem, we introduce Domain-Specific Hybrid Refinement (DHR), which draws on the advantages and disadvantages of two mainstream refinement techniques to maintain editing ability with fidelity improvement. Specifically, we first propose Domain-Specific Segmentation to segment images into two parts: in-domain and out-of-domain parts. The refinement process aims to maintain the editability for in-domain areas and improve two domains' fidelity. We refine these two parts by weight modulation 
    
[^122]: 通过非参数子图匹配重新思考解释图神经网络

    Rethinking Explaining Graph Neural Networks via Non-parametric Subgraph Matching. (arXiv:2301.02780v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.02780](http://arxiv.org/abs/2301.02780)

    本文通过提出一种非参数子图匹配框架MatchExplainer，可以解决图神经网络的解释性问题。此框架将目标图与其他实例结合起来，通过最小化节点对应的距离来鉴别最关键的联合子结构，并提出了一种新的增强范式MatchDrop来解决误报采样问题。

    

    图神经网络（GNNs）的成功引发了关于可解释性的问题：“输入图的哪一部分对预测最为决定性？”特别是，由于其更强大的解读黑箱（即目标GNNs）能力，参数化解释器在现有方法中占据主导地位。基于观察到图通常共享某些常见的模式，本文提出了一种新颖的非参数子图匹配框架MatchExplainer来探索解释性子图。它将目标图与其他相应实例结合起来，通过最小化基于节点对应的距离来识别最关键的联合子结构。此外，我们注意到现有的图采样或节点删除方法通常会遇到误报采样问题。为了缓解这个问题，我们设计了一种名为MatchDrop的新增方案，它利用了MatchExplainer来修复图的最信息丰富部分。

    The success of graph neural networks (GNNs) provokes the question about explainability: ``Which fraction of the input graph is the most determinant of the prediction?'' Particularly, parametric explainers prevail in existing approaches because of their more robust capability to decipher the black-box (i.e., target GNNs). In this paper, based on the observation that graphs typically share some common motif patterns, we propose a novel non-parametric subgraph matching framework, dubbed MatchExplainer, to explore explanatory subgraphs. It couples the target graph with other counterpart instances and identifies the most crucial joint substructure by minimizing the node corresponding-based distance. Moreover, we note that present graph sampling or node-dropping methods usually suffer from the false positive sampling problem. To alleviate this issue, we designed a new augmentation paradigm named MatchDrop. It takes advantage of MatchExplainer to fix the most informative portion of the graph 
    
[^123]: 利用恒定内存将数据集精简扩展到ImageNet-1K

    Scaling Up Dataset Distillation to ImageNet-1K with Constant Memory. (arXiv:2211.10586v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.10586](http://arxiv.org/abs/2211.10586)

    本文提出了一种利用恒定内存需求扩展数据集精简的方法，可将Matching Training Trajectories（MTT）应用于ImageNet-1K数据集，达到6倍的内存降低，同时增加了约2%的运行时开销。同时也发现，为合成图像分配软标签对于实现良好的性能非常重要。

    

    数据集精简方法旨在将大型数据集压缩成一小组合成样本，使得在训练时，与在整个数据集上进行常规训练相比，可以获得竞争性的性能。在最近提出的方法中，匹配训练轨迹（MTT）在CIFAR-10/100上实现了最先进的性能，但由于在反向传播过程中执行展开梯度计算时需要大量内存，因此很难扩展到ImageNet-1k数据集。令人惊讶的是，我们发现存在一种方法，可以使用恒定的GPU内存需求（与展开步骤的数量无关）精确计算轨迹匹配损失函数的梯度。有了这一发现，所提出的内存高效的轨迹匹配方法只需要比原始MTT多约2％的运行时开销，即可轻松扩展到具有6倍内存缩减的ImageNet-1K。此外，我们发现为合成图像分配软标签对于实现良好的性能至关重要。

    Dataset distillation methods aim to compress a large dataset into a small set of synthetic samples, such that when being trained on, competitive performances can be achieved compared to regular training on the entire dataset. Among recently proposed methods, Matching Training Trajectories (MTT) achieves state-of-the-art performance on CIFAR-10/100, while having difficulty scaling to ImageNet-1k dataset due to the large memory requirement when performing unrolled gradient computation through back-propagation. Surprisingly, we show that there exists a procedure to exactly calculate the gradient of the trajectory matching loss with constant GPU memory requirement (irrelevant to the number of unrolled steps). With this finding, the proposed memory-efficient trajectory matching method can easily scale to ImageNet-1K with 6x memory reduction while introducing only around 2% runtime overhead than original MTT. Further, we find that assigning soft labels for synthetic images is crucial for the
    
[^124]: 关于可解释性强化学习的综述：概念、算法和挑战

    A Survey on Explainable Reinforcement Learning: Concepts, Algorithms, Challenges. (arXiv:2211.06665v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.06665](http://arxiv.org/abs/2211.06665)

    该综述调查了可解释性强化学习方法，介绍了模型解释、奖励解释、状态解释和任务解释方法，并探讨了解释强化学习的概念、算法和挑战。

    

    强化学习是一种流行的机器学习范式，智能代理与环境进行交互以实现长期目标。在深度学习的复兴推动下，深度强化学习在各种复杂控制任务中取得了巨大成功。尽管取得了令人鼓舞的结果，基于深度神经网络的主干结构被普遍视为黑盒子，阻碍了从业者在安全性和可靠性至关重要的真实场景中信任和使用训练代理。为了缓解这个问题，大量的文献致力于揭示智能代理的内部工作原理，通过构建内在可解释性或事后可解释性。在本综述中，我们对现有的可解释性强化学习方法进行了全面的回顾，并引入了一个新的分类法，将先前的工作明确地分为模型解释、奖励解释、状态解释和任务解释方法。

    Reinforcement Learning (RL) is a popular machine learning paradigm where intelligent agents interact with the environment to fulfill a long-term goal. Driven by the resurgence of deep learning, Deep RL (DRL) has witnessed great success over a wide spectrum of complex control tasks. Despite the encouraging results achieved, the deep neural network-based backbone is widely deemed as a black box that impedes practitioners to trust and employ trained agents in realistic scenarios where high security and reliability are essential. To alleviate this issue, a large volume of literature devoted to shedding light on the inner workings of the intelligent agents has been proposed, by constructing intrinsic interpretability or post-hoc explainability. In this survey, we provide a comprehensive review of existing works on eXplainable RL (XRL) and introduce a new taxonomy where prior works are clearly categorized into model-explaining, reward-explaining, state-explaining, and task-explaining methods
    
[^125]: NAS在激活和跳跃连接搜索下的泛化性质

    Generalization Properties of NAS under Activation and Skip Connection Search. (arXiv:2209.07238v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.07238](http://arxiv.org/abs/2209.07238)

    本文研究了NAS在激活和跳跃连接搜索下的泛化性质，并提出了一种无需训练的基于理论的算法来选择性能最好的架构。

    

    神经网络结构搜索（NAS）促进了自动发现最先进的神经网络结构。尽管NAS取得了一些进展，但对于NAS的理论保证关注甚少。本文研究了NAS在统一框架下的泛化性质，包括了（深层）层级跳跃连接搜索和激活函数搜索。为此，我们利用包括混合激活函数、全连接和残差神经网络在内的特定搜索空间，推导出（无）限宽度情况下神经切向核（NTK）的最小特征值的下（上）界。我们使用最小特征值来建立NAS在随机梯度下降训练中的泛化误差界限。重要的是，我们理论上和实验上展示了如何根据我们推导出的结果引导NAS选择性能最好的架构，即使在无需训练的情况下，这是一种基于我们的理论的无需训练的算法。

    Neural Architecture Search (NAS) has fostered the automatic discovery of state-of-the-art neural architectures. Despite the progress achieved with NAS, so far there is little attention to theoretical guarantees on NAS. In this work, we study the generalization properties of NAS under a unifying framework enabling (deep) layer skip connection search and activation function search. To this end, we derive the lower (and upper) bounds of the minimum eigenvalue of the Neural Tangent Kernel (NTK) under the (in)finite-width regime using a certain search space including mixed activation functions, fully connected, and residual neural networks. We use the minimum eigenvalue to establish generalization error bounds of NAS in the stochastic gradient descent training. Importantly, we theoretically and experimentally show how the derived results can guide NAS to select the top-performing architectures, even in the case without training, leading to a train-free algorithm based on our theory. Accordi
    
[^126]: 在可约损失中为强化学习优先选择样本

    Prioritizing Samples in Reinforcement Learning with Reducible Loss. (arXiv:2208.10483v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2208.10483](http://arxiv.org/abs/2208.10483)

    本文提出了一种在强化学习中基于可学习性的方法来优先选择样本，通过稳定降低样本的训练损失来定义样本的可学习性。实验证明，该方法相比于随机抽样和仅根据训练损失进行优先选择的方法更加稳健。

    

    大多数强化学习算法利用经验回放缓冲区反复训练代理已观察到的样本。并非所有样本具有相同的重要性，简单地赋予每个样本相等的重要性是一种天真的策略。在本文中，我们提出一种基于我们可以从样本中学到多少的方法来优先选择样本。我们将样本的可学习性定义为与样本相关的训练损失随时间持续下降的程度。我们开发了一种算法来优先选择具有较高可学习性的样本，同时将较难学习的样本（通常由噪声或随机性引起）赋予较低的优先级。我们通过实验证明，我们的方法比随机抽样更加稳健，也优于仅根据训练损失（即时间差分损失）进行优先选择，这在优先经验回放中使用。

    Most reinforcement learning algorithms take advantage of an experience replay buffer to repeatedly train on samples the agent has observed in the past. Not all samples carry the same amount of significance and simply assigning equal importance to each of the samples is a na\"ive strategy. In this paper, we propose a method to prioritize samples based on how much we can learn from a sample. We define the learn-ability of a sample as the steady decrease of the training loss associated with this sample over time. We develop an algorithm to prioritize samples with high learn-ability, while assigning lower priority to those that are hard-to-learn, typically caused by noise or stochasticity. We empirically show that our method is more robust than random sampling and also better than just prioritizing with respect to the training loss, i.e. the temporal difference loss, which is used in prioritized experience replay.
    
[^127]: 论公平机器学习中因果关系的必要性和适用性

    On the Need and Applicability of Causality for Fair Machine Learning. (arXiv:2207.04053v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2207.04053](http://arxiv.org/abs/2207.04053)

    本论文探讨了因果关系在公平机器学习中的必要性和适用性，强调了非因果预测的社会影响和法律反歧视过程依赖于因果主张。同时讨论了在实际场景中应用因果关系所面临的挑战和限制，并提出了可能的解决方案。

    

    除了在流行病学、政治和社会科学中的常见应用案例外，事实证明因果关系在评估自动决策的公正性方面十分重要，无论是在法律上还是日常生活中。我们提供了关于为何因果关系对公平性评估尤为重要的论点和示例。特别是，我们指出了非因果预测的社会影响以及依赖因果主张的法律反歧视过程。我们最后讨论了应用因果关系在实际场景中的挑战和局限性，以及可能的解决方案。

    Besides its common use cases in epidemiology, political, and social sciences, causality turns out to be crucial in evaluating the fairness of automated decisions, both in a legal and everyday sense. We provide arguments and examples, of why causality is particularly important for fairness evaluation. In particular, we point out the social impact of non-causal predictions and the legal anti-discrimination process that relies on causal claims. We conclude with a discussion about the challenges and limitations of applying causality in practical scenarios as well as possible solutions.
    
[^128]: 马尔科夫潜在博弈中的独立和去中心化学习

    Independent and Decentralized Learning in Markov Potential Games. (arXiv:2205.14590v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.14590](http://arxiv.org/abs/2205.14590)

    独立的去中心化学习在马尔科夫潜在博弈中有效，通过更新Q函数可以引导策略收敛到稳定的纳什平衡点。

    

    我们提出了一种多智能体强化学习机制，并分析了它在无限时间折扣马尔科夫潜在博弈中的收敛性。我们专注于独立和去中心化的设置，在这种设置下，玩家不了解游戏模型，也不能进行协调。在每个阶段，玩家通过异步方式更新他们的打扰Q函数的估计值，该函数根据实现的一阶段奖励评估他们的总体条件付款。然后，玩家通过将基于估计Q函数的平滑最优一阶段偏差策略纳入其策略中来独立地更新其策略。学习动态的关键特征是Q函数估计是以比策略更快的时间尺度进行更新的。我们证明了我们的学习动态引导的策略在概率1的情况下收敛到马尔科夫潜在博弈的稳定纳什平衡。我们的结果凸显了简单学习动态在达到马尔可夫潜在博弈的稳定纳什平衡方面的功效，即使是在独立和去中心化代理环境中。

    We propose a multi-agent reinforcement learning dynamics, and analyze its convergence in infinite-horizon discounted Markov potential games. We focus on the independent and decentralized setting, where players do not have knowledge of the game model and cannot coordinate. In each stage, players update their estimate of a perturbed Q-function that evaluates their total contingent payoff based on the realized one-stage reward in an asynchronous manner. Then, players independently update their policies by incorporating a smoothed optimal one-stage deviation strategy based on the estimated Q-function. A key feature of the learning dynamics is that the Q-function estimates are updated at a faster timescale than the policies. We prove that the policies induced by our learning dynamics converge to a stationary Nash equilibrium in Markov potential games with probability 1. Our results highlight the efficacy of simple learning dynamics in reaching a stationary Nash equilibrium even in environme
    
[^129]: SCORE：用于离线强化学习的虚假相关性降低

    SCORE: Spurious COrrelation REduction for Offline Reinforcement Learning. (arXiv:2110.12468v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2110.12468](http://arxiv.org/abs/2110.12468)

    本文提出了SCORE算法，用于离线强化学习中的虚假相关性降低。通过引入退火行为克隆正则化器，SCORE实现了SoTA性能，并消除了次优性中的虚假相关性。

    

    离线强化学习（RL）利用大规模数据集解决序贯决策问题。大多数现有论文只讨论了对抗分布外（OOD）行为的防御，而本文研究了更广泛的问题，即认知不确定性与决策之间的虚假相关性，这是导致次优性的一个重要因素。本文提出了一种实用有效且理论上可证明的算法：用于离线RL的虚假相关性降低（SCORE）。我们通过实验证明，SCORE在标准基准（D4RL）上的各种任务中以3.1倍加速率实现了SoTA性能。所提算法引入了一个退火行为克隆正则化器来帮助生成高质量的不确定性估计，这对于消除次优性中的虚假相关性至关重要。理论上，我们证明了所提方法的合理性，并证明了在温和的条件下其收敛到最优策略的次线性率。

    Offline reinforcement learning (RL) harnesses the power of massive datasets for resolving sequential decision problems. Most existing papers only discuss defending against out-of-distribution (OOD) actions while we investigate a broader issue, the spurious correlations between epistemic uncertainty and decision-making, an essential factor that causes suboptimality. In this paper, we propose Spurious COrrelation REduction (SCORE) for offline RL, a practically effective and theoretically provable algorithm. We empirically show that SCORE achieves the SoTA performance with 3.1x acceleration on various tasks in a standard benchmark (D4RL). The proposed algorithm introduces an annealing behavior cloning regularizer to help produce a high-quality estimation of uncertainty which is critical for eliminating spurious correlations from suboptimality. Theoretically, we justify the rationality of the proposed method and prove its convergence to the optimal policy with a sublinear rate under mild a
    
[^130]: 强化学习中对抗性腐败的鲁棒探索研究

    Corruption-robust exploration in episodic reinforcement learning. (arXiv:1911.08689v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/1911.08689](http://arxiv.org/abs/1911.08689)

    该论文研究了强化学习中在奖励和转移概率两方面存在的对抗性腐败问题，并提出了一种能够解决腐败问题的高效算法，能够在没有腐败的情况下实现接近最优的后悔，并且能够适应未知水平的腐败。

    

    我们对多阶段强化学习在奖励和转移概率两方面的对抗性腐败进行了研究，扩展了最近对随机赌博机特例的研究结果。我们提供了一个框架，通过将“乐观面对不确定性”的现有强化学习方法进行探索性改进，并结合“动作淘汰”原则，从而解决了在强化学习环境中朴素应用动作淘汰所面临的主要挑战。我们的框架提供了高效的算法，(a)在没有腐败时实现接近最优的后悔，并且(b)能够适应未知水平的腐败，在总腐败情况下后悔程度逐渐降低。为了展示我们方法的广泛适用性，我们推导了表格设置下的结果（其中涉及状态和行为）以及通用函数逼近设置下的结果。

    We initiate the study of multi-stage episodic reinforcement learning under adversarial corruptions in both the rewards and the transition probabilities of the underlying system extending recent results for the special case of stochastic bandits. We provide a framework which modifies the aggressive exploration enjoyed by existing reinforcement learning approaches based on "optimism in the face of uncertainty", by complementing them with principles from "action elimination". Importantly, our framework circumvents the major challenges posed by naively applying action elimination in the RL setting, as formalized by a lower bound we demonstrate. Our framework yields efficient algorithms which (a) attain near-optimal regret in the absence of corruptions and (b) adapt to unknown levels corruption, enjoying regret guarantees which degrade gracefully in the total corruption encountered. To showcase the generality of our approach, we derive results for both tabular settings (where states and act
    

