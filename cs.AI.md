# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [On Practical Aspects of Aggregation Defenses against Data Poisoning Attacks.](http://arxiv.org/abs/2306.16415) | 本文研究了数据中毒攻击的聚合防御策略的实践方面，并针对Deep Partition Aggregation进行了评估，包括效率、性能和鲁棒性。实验结果显示，基于缩放基础模型的方法能够提高聚合防御的训练效率。 |
| [^2] | [MultiZoo & MultiBench: A Standardized Toolkit for Multimodal Deep Learning.](http://arxiv.org/abs/2306.16413) | MultiZoo和MultiBench是用于多模态深度学习的标准化工具包，提供了多模态算法的实现和大规模基准测试，以促进对多模态模型能力和限制的理解，并确保易用性和可重复性。 |
| [^3] | [Towards Measuring the Representation of Subjective Global Opinions in Language Models.](http://arxiv.org/abs/2306.16388) | 本文提出了一个方法来评估大型语言模型对全球观点的代表性。通过构建一个包含跨国调查问题和答案的数据集，并定义一个相似度度量标准，研究发现默认情况下语言模型的回应更倾向于某些人群的观点，但当模型考虑特定国家的观点时，回应会更加贴近该国家的观点。 |
| [^4] | [Accelerating Sampling and Aggregation Operations in GNN Frameworks with GPU Initiated Direct Storage Accesses.](http://arxiv.org/abs/2306.16384) | 本论文提出了一种通过利用GPU发起直接存储访问来加速GNN框架中的采样和聚合操作的方法，解决了在训练大规模图上时CPU无法充分利用GPU资源的问题。 |
| [^5] | [Lagrangian based A* algorithm for automated reasoning.](http://arxiv.org/abs/2306.16368) | 本文介绍了一种基于拉格朗日的A*算法，通过在启发式部分引入权重，提高了算法的效率，并将其应用于无人机路径规划中。该方法可以用于其他问题，以提高算法在这些领域的效率。 |
| [^6] | [Identifiability of Discretized Latent Coordinate Systems via Density Landmarks Detection.](http://arxiv.org/abs/2306.16334) | 本文提出了一种新颖的可识别性形式，称为量化坐标可识别性。在无监督的情况下，我们展示了在高度通用的非线性映射下，可以恢复离散化的潜在坐标，而无需额外的归纳偏差。这一发现对解缠研究具有重要意义。 |
| [^7] | [Representation Learning via Variational Bayesian Networks.](http://arxiv.org/abs/2306.16326) | VBN是一种利用层次和关系信息的新颖的贝叶斯实体表示学习模型，特别适用于数据稀缺的“长尾”实体建模。通过使用层次先验和明确关系约束，VBN提供了更好的建模效果，并通过密度表示实体，对数据稀缺情况下的不确定性进行建模。我们还提出了一种可扩展的变分贝叶斯优化算法来实现快速的近似贝叶斯推断。 |
| [^8] | [An Adversarial Multi-Task Learning Method for Chinese Text Correction with Semantic Detection.](http://arxiv.org/abs/2306.16313) | 本论文提出了一种用于中文文本纠错的对抗多任务学习方法和语义检测，在中文句子上下文中增强了字符多义的建模和检测能力，并通过实验证明了方法的有效性。 |
| [^9] | [Social World Knowledge: Modeling and Applications.](http://arxiv.org/abs/2306.16299) | 这项工作引入了SocialVec框架，用于从社交网络中提取低维实体嵌入，旨在构建一个专门捕捉社交世界知识的资源。 |
| [^10] | [Relevant Entity Selection: Knowledge Graph Bootstrapping via Zero-Shot Analogical Pruning.](http://arxiv.org/abs/2306.16296) | 本文提出了一种基于类比的方法，通过选择和修剪相关实体，从而引导知识图谱的构建。实证结果显示，这种方法在两个领域和异质种子实体的数据集上优于其他机器学习方法，并具有较低的参数数量。这些结果支持在相关任务中进一步应用类比推理。 |
| [^11] | [Leveraging GPT-4 for Food Effect Summarization to Enhance Product-Specific Guidance Development via Iterative Prompting.](http://arxiv.org/abs/2306.16275) | 本研究提出了一种通过迭代提示与ChatGPT或GPT-4进行多轮交互的方法来改进食物影响摘要的准确性。这种方法在产品特定指导(PSG)开发中具有潜力应用的价值。 |
| [^12] | [Emotion Analysis of Tweets Banning Education in Afghanistan.](http://arxiv.org/abs/2306.16268) | 这项研究介绍了第一个用于阿富汗普什图语变体的情绪标注数据集，该数据集包含7600条推文，以研究塔利班禁止妇女接受教育的情绪反应，并通过多种神经架构对达里语情感分类进行基准测试。 |
| [^13] | [CBBQ: A Chinese Bias Benchmark Dataset Curated with Human-AI Collaboration for Large Language Models.](http://arxiv.org/abs/2306.16244) | 通过人工智能与人类协同合作构建的CBBQ中文偏差基准数据集，全面衡量了与中国文化和价值观相关的14个社会维度中的刻板印象和社会偏见，对于检测模型偏见具有广泛的覆盖范围和高度的多样性。 |
| [^14] | [Inferring the Goals of Communicating Agents from Actions and Instructions.](http://arxiv.org/abs/2306.16207) | 本文介绍了一个模型，可以通过观察行动和指令推断合作团队的目标，并评估了其与人类判断的相关性。 |
| [^15] | [Towards a Better Understanding of Learning with Multiagent Teams.](http://arxiv.org/abs/2306.16205) | 本文研究了为个体学习代理群体提供有效学习的团队结构，发现某些团队结构有助于代理学习专业化到具体角色，从而产生更好的整体结果。然而，大团队存在责任归因难题，导致协调性降低，大团队表现较小团队差。 |
| [^16] | [Enhancing Dialogue Generation via Dynamic Graph Knowledge Aggregation.](http://arxiv.org/abs/2306.16195) | 本研究提出了一个通过动态图知识聚合来提升对话生成的新框架，它能够更好地利用来自帖子和外部图知识的异质特征，从而解决图知识和文本之间的语义差异问题。 |
| [^17] | [Effective Transfer of Pretrained Large Visual Model for Fabric Defect Segmentation via Specifc Knowledge Injection.](http://arxiv.org/abs/2306.16186) | 本研究通过在Segment Anything Model (SAM)中引入和训练一组面料缺陷相关的参数，无缝地将专业知识注入到大型视觉模型中，从而提高了面料缺陷分割的性能和泛化能力。 |
| [^18] | [Defining data science: a new field of inquiry.](http://arxiv.org/abs/2306.16177) | 数据科学是一种新的研究范式，具有潜力和应用广泛性，在40多个学科、数百个研究领域和成千上万个应用中出现。然而，由于其起步阶段，目前存在许多定义的冗余和不一致性的问题。 |
| [^19] | [A systematic literature review on source code similarity measurement and clone detection: techniques, applications, and challenges.](http://arxiv.org/abs/2306.16171) | 这份综述研究了源代码相似性测量和克隆检测的方法和应用，发现了80种软件工具，涉及了多个编程语言，为不同应用领域提供了有益的洞见。 |
| [^20] | [Training Deep Surrogate Models with Large Scale Online Learning.](http://arxiv.org/abs/2306.16133) | 本文提出了一种用于深度替代模型的在线训练框架，通过同时生成数值模拟和训练深度神经网络，抑制了磁盘加载数据集相关的瓶颈，开辟了新的研究方向。 |
| [^21] | [A Framework for Identifying Depression on Social Media: MentalRiskES@IberLEF 2023.](http://arxiv.org/abs/2306.16125) | 该论文介绍了在社交媒体上识别抑郁症的框架，使用机器学习和深度学习技术来解决四个预测子任务，并发现使用句子嵌入作为线性回归器的输入产生了更好的结果。 |
| [^22] | [Empirical Loss Landscape Analysis of Neural Network Activation Functions.](http://arxiv.org/abs/2306.16090) | 本研究通过经验分析了双曲正切、修正线性单元和指数线性单元激活函数相关的神经网络损失曲面，发现修正线性单元呈现最凸型曲面，指数线性单元呈现最平坦曲面并具有更优的泛化性能。所有激活函数的损失曲面中存在宽阔和狭窄的山谷，而狭窄的山谷与饱和神经元和隐含的正则化网络结构相关。 |
| [^23] | [Mastering Nordschleife -- A comprehensive race simulation for AI strategy decision-making in motorsports.](http://arxiv.org/abs/2306.16088) | 本文针对当前赛车模拟存在的粒度、建模和手动输入问题，开发了一种新型仿真模型，并应用人工智能自动化了策略决策。该研究通过将仿真与强化学习环境相结合，使用历史数据进行评估，以优化赛车比赛策略决策。 |
| [^24] | [Secure and Fast Asynchronous Vertical Federated Learning via Cascaded Hybrid Optimization.](http://arxiv.org/abs/2306.16077) | 本论文提出了一种在垂直联邦学习中使用级联混合优化的方法，通过在下游使用零阶优化保护隐私并在上游使用一阶优化提高收敛速度，从而解决了ZOO-based VFL收敛速度较慢的问题。 |
| [^25] | [Federated Generative Learning with Foundation Models.](http://arxiv.org/abs/2306.16064) | 本文提出了一种基于基础生成模型的联邦生成学习框架，通过传输提示与分布式训练数据，可以远程合成有信息量的训练数据，从而改善了通信效率、适应分布转移、提升性能、加强隐私保护。 |
| [^26] | [RoMo-HER: Robust Model-based Hindsight Experience Replay.](http://arxiv.org/abs/2306.16061) | RoMo-HER是一个鲁棒的基于模型的事后经验回放方法，通过使用机器人操作环境中的动力学模型和前瞻重新标记技术，提高了样本利用效率。 |
| [^27] | [DUET: 2D Structured and Approximately Equivariant Representations.](http://arxiv.org/abs/2306.16058) | DUET是一种2D结构化且近似等变表示方法，相比于其他方法，可以在保留输入变换信息的同时具有更好的可控性和更高的准确性。 |
| [^28] | [Challenges of Zero-Shot Recognition with Vision-Language Models: Granularity and Correctness.](http://arxiv.org/abs/2306.16048) | 本文研究了将视觉-语言模型应用于零样本视觉识别任务所面临的挑战，发现VLMs在识别细粒度概念方面表现更好，并指出了VLMs中相似度分数不能严格反映正确性的问题，提出了未来研究方向。 |
| [^29] | [OpenNDD: Open Set Recognition for Neurodevelopmental Disorders Detection.](http://arxiv.org/abs/2306.16045) | OpenNDD是一个用于神经发育障碍检测的开放性识别框架，结合了自动编码器和对抗循环点开放性识别技术，能准确识别已知类别并识别未遇到的类别。 |
| [^30] | [Stone Needle: A General Multimodal Large-scale Model Framework towards Healthcare.](http://arxiv.org/abs/2306.16034) | Stone Needle是一个通用的多模态大规模模型框架，专门为医疗保健应用而设计。它集成了各种模态，可以进行全面分析并实现多模态交互。 |
| [^31] | [A Distributed Computation Model Based on Federated Learning Integrates Heterogeneous models and Consortium Blockchain for Solving Time-Varying Problems.](http://arxiv.org/abs/2306.16023) | 本研究提出了一种基于联邦学习和联盟区块链的分布式计算模型，解决了时变问题中异构模型和模型间协作的难题。 |
| [^32] | [Structure in Reinforcement Learning: A Survey and Open Problems.](http://arxiv.org/abs/2306.16021) | 这项调查研究了强化学习中结构的角色和重要性，并介绍了各个子领域在提高强化学习的性能方面所做的工作。 |
| [^33] | [BayesFlow: Amortized Bayesian Workflows With Neural Networks.](http://arxiv.org/abs/2306.16015) | BayesFlow是一个Python库，提供了使用神经网络进行摊还贝叶斯推断的功能，用户可以在模型仿真上训练定制的神经网络，并将其用于任何后续应用。这种摊还贝叶斯推断能够快速准确地进行推断，并实现了对不可计算后验分布的近似。 |
| [^34] | [Query Understanding in the Age of Large Language Models.](http://arxiv.org/abs/2306.16004) | 在大语言模型时代，我们提出了一种使用大语言模型进行查询重写的框架，旨在通过完全指定机器意图的自然语言来改进意图理解和构建高性能检索系统。这种框架的能够以自然语言呈现、交互和推理机器意图具有深远影响。 |
| [^35] | [Streamlining Social Media Information Retrieval for Public Health Research with Deep Learning.](http://arxiv.org/abs/2306.16001) | 本研究介绍了一个使用深度学习简化社交媒体信息检索的框架，通过识别医学实体、标准化实体和分配UMLS概念，构建了一个用于COVID-19相关推文的症状词典。 |
| [^36] | [Tensorformer: Normalized Matrix Attention Transformer for High-quality Point Cloud Reconstruction.](http://arxiv.org/abs/2306.15989) | Tensorformer是一种归一化矩阵注意力变换器，用于高质量的点云重建。它通过矩阵注意力实现了逐点和逐通道的消息传递，提供了更好的局部几何建模能力，并在两个数据集上取得了最先进的结果。 |
| [^37] | [A Dimensional Structure based Knowledge Distillation Method for Cross-Modal Learning.](http://arxiv.org/abs/2306.15977) | 本文通过分析和观察从简单和困难任务中提取的特征，发现了特征可辨别性和维度结构之间的相关性，并提出了一种基于维度结构的跨模态学习的知识蒸馏方法，以提高跨模态学习性能。 |
| [^38] | [Reconstructing the Hemodynamic Response Function via a Bimodal Transformer.](http://arxiv.org/abs/2306.15971) | 本研究首次引入了一种双模态变换器预测模型，通过历史血流和神经活动来推断当前血流，增强了模型的预测能力，并提出了关于血液动力学响应神经活动的假设。 |
| [^39] | [Separable Physics-Informed Neural Networks.](http://arxiv.org/abs/2306.15969) | 这项研究提出了一种可分离的物理信息神经网络（SPINN），通过逐个处理轴来显著减少了多维 PDE 中的网络传播数量，并使用正向模式自动微分降低了计算成本，使得可以在单个普通 GPU 上使用大量的配点。 |
| [^40] | [Reduce Computational Complexity for Convolutional Layers by Skipping Zeros.](http://arxiv.org/abs/2306.15951) | 本文提出了C-K-S算法，通过修剪滤波器和转换稀疏张量为稠密张量的方式，跳过卷积层中的0元素，从而降低了计算复杂度。实验证明，C-K-S相对于PyTorch具有优势。 |
| [^41] | [No Transfers Required: Integrating Last Mile with Public Transit Using Opti-Mile.](http://arxiv.org/abs/2306.15943) | 提出了一种名为"Opti-Mile"的新方法，将最后一公里服务与公共交通相结合，使用户无需换乘，解决了公共交通系统中有限可达性和换乘引起的低效率问题。 |
| [^42] | [Enhanced Neural Beamformer with Spatial Information for Target Speech Extraction.](http://arxiv.org/abs/2306.15942) | 本研究提出了一种利用空间信息增强神经波束形成器性能的目标语音提取网络。该网络采用了UNet-TCN结构建模输入特征，并引入了多头交叉注意力机制，有效提升了神经波束形成器对空间信息的感知能力。 |
| [^43] | [Interpretable Anomaly Detection in Cellular Networks by Learning Concepts in Variational Autoencoders.](http://arxiv.org/abs/2306.15938) | 本文提出了一种利用变分自编码器学习概念在手机网络中解释异常检测的方法，通过重构损失和Z分数来检测异常，并通过K-means算法增强表示学习，实现了异常的可解释性。该框架为手机网络中的异常检测提供了更快且自主的解决方案，并展示了深度学习算法处理大数据的潜力。 |
| [^44] | [Curious Replay for Model-based Adaptation.](http://arxiv.org/abs/2306.15934) | 好奇回放是一种针对模型为基础的代理的优先经验回放方法，通过使用好奇度基础的优先信号，它提高了探索性能，并在Crafter基准测试中取得了更好的成绩。 |
| [^45] | [You Can Generate It Again: Data-to-text Generation with Verification and Correction Prompting.](http://arxiv.org/abs/2306.15933) | 本文提出了一种多步骤生成、验证和纠正的数据生成文本方法，通过专门的错误指示提示来改善输出质量。 |
| [^46] | [Most Language Models can be Poets too: An AI Writing Assistant and Constrained Text Generation Studio.](http://arxiv.org/abs/2306.15926) | 这项研究展示了如何通过在语言模型中应用过滤函数来生成有限约束文本，并提出了一个AI写作助手工具，可以根据用户的需求生成带有各种约束条件的文本。 |
| [^47] | [Fine-grained 3D object recognition: an approach and experiments.](http://arxiv.org/abs/2306.15919) | 本文提出了一种离线和在线的三维物体识别方法，通过实现一个系统来对物体进行分类并评估其识别性能。 |
| [^48] | [DCT: Dual Channel Training of Action Embeddings for Reinforcement Learning with Large Discrete Action Spaces.](http://arxiv.org/abs/2306.15913) | 本文提出了一个双通道动作嵌入训练的框架，能够在大离散动作空间中学习稳健策略，并成功应用在2D迷宫环境和真实世界电子商务任务中。 |
| [^49] | [RL$^3$: Boosting Meta Reinforcement Learning via RL inside RL$^2$.](http://arxiv.org/abs/2306.15909) | RL$^3$是一种原则性混合方法，通过将传统强化学习学到的任务特定动作值作为元强化学习神经网络的输入，提高了元强化学习的性能。 |
| [^50] | [Diversity is Strength: Mastering Football Full Game with Interactive Reinforcement Learning of Multiple AIs.](http://arxiv.org/abs/2306.15903) | 多样性即实力（DIS）是一种新颖的DRL训练框架，通过同时训练多种类型的人工智能，并利用互联的历史模型池结构增强其策略多样性和能力。该方法在不使用人类数据的情况下提供了多样化、可推广和强大的人工智能策略，并在AI竞赛中表现出色。 |
| [^51] | [Individual and Structural Graph Information Bottlenecks for Out-of-Distribution Generalization.](http://arxiv.org/abs/2306.15902) | 这项工作提出了一种统一框架，个别和结构化图信息瓶颈（IS-GIB），用于解决域外图像通用化中的问题，通过丢弃虚假特征和利用结构关联来提高性能。 |
| [^52] | [Large Language Model as Attributed Training Data Generator: A Tale of Diversity and Bias.](http://arxiv.org/abs/2306.15895) | 本论文研究了大型语言模型作为属性化训练数据生成器的应用。通过使用具有多样性属性的提示，我们能够生成多样化且归因的数据。研究表明，在高基数和多样领域的数据集中，使用属性化提示对生成模型性能有积极影响。此外，论文还展示了关于偏差、多样性和效率的全面实证研究结果，并得出了三个关键观察：系统性偏差存在于生成数据中，多样性和效率之间存在权衡，属性化训练数据生成可以改善模型性能。 |
| [^53] | [Beyond the Hype: Assessing the Performance, Trustworthiness, and Clinical Suitability of GPT3.5.](http://arxiv.org/abs/2306.15887) | 该研究评估了GPT3.5模型在医学图像协议分配方面的性能和可信度，发现其在性能上不如BERT和放射科医师，但在解释决策能力、检测相关词标识和模型校准方面优于BERT。 |
| [^54] | [Towards Open Vocabulary Learning: A Survey.](http://arxiv.org/abs/2306.15880) | 该论文调研了在视觉场景理解领域的开放词汇学习，在与零样本学习和开放集识别等相关概念的比较中，总结和分析了该领域的最新发展。 |
| [^55] | [Hierarchical Graph Neural Networks for Proprioceptive 6D Pose Estimation of In-hand Objects.](http://arxiv.org/abs/2306.15858) | 本文提出了一种分层图神经网络架构，用于结合多模态数据，实现几何信息有根据的6D物体姿态估计。 |
| [^56] | [Symbol emergence as interpersonal cross-situational learning: the emergence of lexical knowledge with combinatoriality.](http://arxiv.org/abs/2306.15837) | 本研究提出了一个计算模型，通过交互学习和命名游戏，实现了代理之间通过词序列交流的方式，从而促进了具有组合性的语义知识的出现。 |
| [^57] | [Easing Color Shifts in Score-Based Diffusion Models.](http://arxiv.org/abs/2306.15832) | 本文提出了在基于得分的扩散模型中缓解颜色偏移的计算廉价解决方案，并引入了一个简单的非线性绕过连接来改善生成图像的空间均值。 |
| [^58] | [MAT: Mixed-Strategy Game of Adversarial Training in Fine-tuning.](http://arxiv.org/abs/2306.15826) | 本论文提出了一种新颖的混合策略对抗训练算法（MAT），通过在细调阶段加入对抗训练，显著提高了模型的泛化能力和鲁棒性，通过采样方法建立了MAT。实验证明，MAT在大规模预训练模型上的性能明显优于其他方法。 |
| [^59] | [G\"odel-Dummett linear temporal logic.](http://arxiv.org/abs/2306.15805) | G\"odel-Dummett线性时间逻辑使用实值和双关系语义定义，并通过拟模型算法解决了证伪的问题。 |
| [^60] | [On Logic-Based Explainability with Partially Specified Inputs.](http://arxiv.org/abs/2306.15803) | 本文研究了在机器学习模型中处理缺失数据和解释预测的问题。通过研究基于逻辑的解释计算，发现大多数计算解释的算法也适用于给定部分指定输入的情况。该研究为处理部分指定输入提供了解决方案，并应用于分类器中。 |
| [^61] | [ConKI: Contrastive Knowledge Injection for Multimodal Sentiment Analysis.](http://arxiv.org/abs/2306.15796) | ConKI提出了一种对比性知识注入方案，用于多模态情感分析，通过在通用知识表示的基础上学习每种模态的特定知识表示，以提高多模态情感预测的效果。 |
| [^62] | [A Population-Level Analysis of Neural Dynamics in Robust Legged Robots.](http://arxiv.org/abs/2306.15793) | 本研究通过分析神经动力学在稳健步行机器人中的人群层活动，揭示了控制器的拓扑结构对平衡能力的影响；通过应用神经干扰探究系统的强迫响应，发现循环状态动力学具有结构化和低维特征，并提出了一种新的控制机制的存在证据。 |
| [^63] | [Evaluating GPT-3.5 and GPT-4 on Grammatical Error Correction for Brazilian Portuguese.](http://arxiv.org/abs/2306.15788) | 该研究评估了GPT-3.5和GPT-4在巴西葡萄牙语语法错误修正方面的有效性，结果显示虽然GPT-4的召回率较高，但语言模型倾向于过度修正。 |
| [^64] | [An Empirical Evaluation of the Rashomon Effect in Explainable Machine Learning.](http://arxiv.org/abs/2306.15786) | 通过对不同数据集、模型和指标进行定量评估，我们发现罗生门效应对可解释机器学习具有影响，这为之前的轶事证据提供了实证支持，并展示了科学家和实践者面临的挑战。 |
| [^65] | [UTRNet: High-Resolution Urdu Text Recognition In Printed Documents.](http://arxiv.org/abs/2306.15782) | 本文提出了一种解决印刷乌尔都文本识别挑战的新方法，并引入了大规模实际标记数据集和合成数据集，提供了乌尔都文本行检测的基准数据集，同时开发了一个在线工具，实现了印刷文档中乌尔都OCR的端到端识别。 |
| [^66] | [xAI-CycleGAN, a Cycle-Consistent Generative Assistive Network.](http://arxiv.org/abs/2306.15760) | 本文提出了一种循环一致的生成辅助网络，通过使用可解释性方法和输入上的显著性地图，加速生成模型的收敛速度，相比基线CycleGAN架构有更高的收敛速度。 |
| [^67] | [To Spike or Not To Spike: A Digital Hardware Perspective on Deep Learning Acceleration.](http://arxiv.org/abs/2306.15749) | 神经形态计算旨在通过仿真脑部操作来提高深度学习模型的效率，但是在SNNs的高效硬件后端设计上仍需进一步研究。 |
| [^68] | [Physics-inspired spatiotemporal-graph AI ensemble for gravitational wave detection.](http://arxiv.org/abs/2306.15728) | 本论文提出了一种基于物理启发的时空图神经网络AI集合的方法，用于引力波探测。该方法通过混合膨胀卷积神经网络和图神经网络，准确地建模引力波信号的时空关联性，实现了在分布式环境下训练多个AI模型，并在短时间内获得最佳的分类性能。 |
| [^69] | [REFLECT: Summarizing Robot Experiences for Failure Explanation and Correction.](http://arxiv.org/abs/2306.15724) | 提出了REFLECT框架，可以将机器人多感官数据转化为分层总结，并使用大型语言模型进行失败解释。该框架能够生成有益的失败解释，帮助机器人完成任务。 |
| [^70] | [Semi-supervised Multimodal Representation Learning through a Global Workspace.](http://arxiv.org/abs/2306.15711) | 本研究通过创建一个共享的两个或多个输入模态的表示的神经网络架构，实现了半监督的多模态表示学习。这种架构可以通过循环一致性自我监督训练。这种方法可以减少对大型多模态数据集的依赖，并模仿人类从有限的经验中学习有用的多模态表示的能力。 |
| [^71] | [Procedural content generation of puzzle games using conditional generative adversarial networks.](http://arxiv.org/abs/2306.15696) | 本文介绍了一种实验方法，使用参数化生成对抗网络为益智游戏Lily's Garden生成关卡。虽然GAN在逼近地图形状方面表现良好，但在逼近方块分布方面存在困难。可能通过尝试替代GAN的架构来改进这一情况。 |
| [^72] | [KAPLA: Pragmatic Representation and Fast Solving of Scalable NN Accelerator Dataflow.](http://arxiv.org/abs/2306.15676) | 本文提出了KAPLA，一个用于可扩展NN加速器数据流优化的快速求解器。通过实用的指令和全面的数据流表示，KAPLA能够有效地进行设计空间的探索，并快速确定方案的有效性和效率。 |
| [^73] | [Asynchronous Algorithmic Alignment with Cocycles.](http://arxiv.org/abs/2306.15632) | 该论文提出了一种将节点状态更新和消息函数调用分离的数学框架，以实现异步计算，并以此作为基础，进行了异步算法和神经网络的对齐。 |
| [^74] | [Extending Context Window of Large Language Models via Positional Interpolation.](http://arxiv.org/abs/2306.15595) | 通过位置插值方法，我们可以在最小微调的情况下将RoPE-based预训练语言模型的上下文窗口扩展到最多32768，并在多个任务上获得强有力的实证结果。通过线性降低输入位置索引的大小，我们保持了扩展模型在原始上下文窗口内任务的质量。 |
| [^75] | [Precursor-of-Anomaly Detection for Irregular Time Series.](http://arxiv.org/abs/2306.15489) | 本文提出了一种新型异常检测方法，称为前体-异常检测（PoA检测）。与传统的异常检测不同，PoA检测旨在在异常发生之前检测到未来的异常。通过使用基于神经控制微分方程的神经网络和多任务学习算法，我们在17个基准线和3个数据集上进行实验证明了我们的方法的有效性。 |
| [^76] | [MIMIC: Masked Image Modeling with Image Correspondences.](http://arxiv.org/abs/2306.15128) | MIMIC是一种基于图像对应关系的遮蔽图像建模方法，通过挖掘不需要任何注释的数据集，使用多个自监督模型进行训练，达到了在多个下游任务上优于使用注释挖掘的表示的效果。 |
| [^77] | [PhD Thesis: Exploring the role of (self-)attention in cognitive and computer vision architecture.](http://arxiv.org/abs/2306.14650) | 该论文研究了注意力和记忆在复杂推理任务中的作用，通过以Transformer为基础模型并结合记忆，扩展了自我注意力模型。研究结果表明，在视觉推理任务中，使用基于特征和空间注意力的自我注意力与ResNet50相结合可以高效解决具有挑战性的任务。此外，该论文提出了基于注意力和记忆的认知架构GAMR，它在样本效率、鲁棒性和组合性方面优于其他架构，并具有对新的推理任务的零样本泛化能力。 |
| [^78] | [The Neuro-Symbolic Inverse Planning Engine (NIPE): Modeling Probabilistic Social Inferences from Linguistic Inputs.](http://arxiv.org/abs/2306.14325) | 本文提出了一个神经符号模型，用于从语言输入中进行目标推断，并通过人类实验验证了该模型的准确性和优势。 |
| [^79] | [G-NM: A Group of Numerical Time Series Prediction Models.](http://arxiv.org/abs/2306.11667) | G-NM是一组集合了传统和现代模型的数字时间序列预测模型，旨在提高对复杂自然现象中的模式和趋势的预测能力。 |
| [^80] | [Tourist Attractions Recommendation based on Attention Knowledge Graph Convolution Network.](http://arxiv.org/abs/2306.10946) | 本文提出了一种基于注意力知识图卷积网络的旅游景点推荐模型，通过自动语义发掘目标景点的相邻实体，根据旅客的喜好选择，预测类似景点的概率，实验中取得良好效果。 |
| [^81] | [The False Dawn: Reevaluating Google's Reinforcement Learning for Chip Macro Placement.](http://arxiv.org/abs/2306.09633) | 谷歌2021年在《自然》杂志上发表的一篇论文声称其使用强化学习在芯片设计领域进行了创新，但两项独立的评估表明，谷歌的方法不如人类设计师、不如一个众所周知的算法（模拟退火），并且也不如普遍可用的商业软件，文章的完整性也遭到了严重的损害。 |
| [^82] | [TSMixer: Lightweight MLP-Mixer Model for Multivariate Time Series Forecasting.](http://arxiv.org/abs/2306.09364) | TSMixer是一种用于多元时间序列预测的轻量级MLP-Mixer模型，可以有效地捕捉时间序列属性并在准确性方面超越了Transformers的方法。 |
| [^83] | [Adaptive Monte Carlo Search for Conjecture Refutation in Graph Theory.](http://arxiv.org/abs/2306.07956) | 本研究提出了自适应蒙特卡罗搜索算法，用于反驳猜想并证明图论问题。该算法在反驳多个猜想方面表现出色，并优于已有算法。 |
| [^84] | [Topology Repairing of Disconnected Pulmonary Airways and Vessels: Baselines and a Dataset.](http://arxiv.org/abs/2306.07089) | 该论文提出了一种修复断开肺气道和血管拓扑结构的方法，通过关键点检测任务预测可以连接断开组件的关键点，同时提供了一个新的数据集可用于训练和评估。 |
| [^85] | [Understanding the Effect of the Long Tail on Neural Network Compression.](http://arxiv.org/abs/2306.06238) | 本文研究了在神经网络压缩中如何保持与原始网络的语义相同，在长尾现象中探讨了压缩提高推广性能的记忆要素。 |
| [^86] | [How Can Recommender Systems Benefit from Large Language Models: A Survey.](http://arxiv.org/abs/2306.05817) | 本文对将大型语言模型（LLM）应用于推荐系统进行了全面的调查研究，从两个角度总结了现有的研究工作：如何在推荐系统中调整LLM和调整LLM时在哪里调整。最后，我们提出了一些潜在的研究方向和挑战。 |
| [^87] | [Integrating Geometric Control into Text-to-Image Diffusion Models for High-Quality Detection Data Generation via Text Prompt.](http://arxiv.org/abs/2306.04607) | GeoDiffusion使用文本提示将各种几何条件转化为图像，生成高质量的检测数据，性能优于现有方法。 |
| [^88] | [Learning with Noisy Labels by Adaptive Gradient-Based Outlier Removal.](http://arxiv.org/abs/2306.04502) | 本文提出了一种名为AGRA的自适应梯度异常值去除方法，能够在模型训练过程中动态调整数据集从而有效提高模型学习效果。 |
| [^89] | [Rethinking Model Evaluation as Narrowing the Socio-Technical Gap.](http://arxiv.org/abs/2306.03100) | 针对同质化的模型，模型评估需要提供有效的评估，以判断特定模型是否在下游使用场景中可以满足多少人类需求，并且应该根据真实的社会需求来开发评估模型，并拥抱多样化的评估方法。 |
| [^90] | [Just a Glimpse: Rethinking Temporal Information for Video Continual Learning.](http://arxiv.org/abs/2305.18418) | 本文提出了一种基于单个帧的新型重播机制SMILE，用于有效的视频连续学习。实验表明，在内存受到极端限制时，视频的多样性比时间信息更重要。 |
| [^91] | [Relabel Minimal Training Subset to Flip a Prediction.](http://arxiv.org/abs/2305.12809) | 本文利用扩展影响函数提出了一种有效的识别和重新标记最小训练子集的方法，并证明其始终能够成功翻转测试结果，同时还提供了挑战模型预测、评估模型鲁棒性和洞察训练集偏差等多重作用。 |
| [^92] | [Deep Learning assisted microwave-plasma interaction based technique for plasma density estimation.](http://arxiv.org/abs/2304.14807) | 本文提出了一种基于深度学习辅助微波等离子体相互作用技术的等离子体密度估计方法，通过测量微波散射引起的电场模式来估计密度剖面。 |
| [^93] | [DeePLT: Personalized Lighting Facilitates by Trajectory Prediction of Recognized Residents in the Smart Home.](http://arxiv.org/abs/2304.08027) | 本论文提出了一种基于机器学习的智能照明系统DeePLT，其通过轨迹预测实现智能家居中的个性化照明调整，给每个人定制独特的个人资料并根据其轨迹自动调整灯光。 |
| [^94] | [Polytuplet Loss: A Reverse Approach to Training Reading Comprehension and Logical Reasoning Models.](http://arxiv.org/abs/2304.01046) | 本文研究了一种训练阅读理解和逻辑推理模型的反向方法，利用相对准确性的策略来训练模型，通过Polytuplet Loss函数来确保优先学习答案选择的相对正确性，获得了不错的成果，提出了具有一般性的训练方法和模型架构。 |
| [^95] | [Pgx: Hardware-accelerated parallel game simulation for reinforcement learning.](http://arxiv.org/abs/2303.17503) | Pgx是一个用JAX编写的游戏模拟器集合，具有强化学习硬件加速能力，支持并行执行，速度比现有的强化学习库快10倍。 它实现了Backgammon，Shogi和Go等基准测试游戏。 |
| [^96] | [Preserving Linear Separability in Continual Learning by Backward Feature Projection.](http://arxiv.org/abs/2303.14595) | 提出了一种名为BFP的连续学习方法，它通过将新特征变换为旧特征的线性变换来维护线性可分性，从而允许新特征方向的出现以适应新任务，同时保留旧任务的信息。 |
| [^97] | [Linking generative semi-supervised learning and generative open-set recognition.](http://arxiv.org/abs/2303.11702) | 本研究旨在探究生成半监督学习和生成开放集识别之间的关系。SSL-GANs和OSR-GANs方法的相似性在于都要求生成器在互补空间中产生样本，并通过正则化来推广开放空间。研究结果表明SSL优化边缘-GAN在结合SSL-OSR任务方面树立新的标准，但在某些OSR任务中OSR优化的ARP-GAN仍然略优于SSL-GAN。 |
| [^98] | [QR-CLIP: Introducing Explicit Open-World Knowledge for Location and Time Reasoning.](http://arxiv.org/abs/2302.00952) | 本文提出QR-CLIP模型，通过引入开放世界知识进行位置和时间推理，在此任务上取得了约10%和130%的相对提升。 |
| [^99] | [Reef-insight: A framework for reef habitat mapping with clustering methods via remote sensing.](http://arxiv.org/abs/2301.10876) | Reef-Insight是一种利用聚类方法和遥感技术进行珊瑚礁栖息地映射的无监督机器学习框架，通过比较不同的聚类方法，我们发现遥感数据可以有效地用于珊瑚礁栖息地的映射。 |
| [^100] | [EHRSQL: A Practical Text-to-SQL Benchmark for Electronic Health Records.](http://arxiv.org/abs/2301.07695) | 该论文提出了一个面向电子病历数据的文本转SQL数据集，该数据集具有一系列独特挑战，包括生成SQL查询、理解时间表达式以及区分有无答案的问题。 |
| [^101] | [Localising In-Domain Adaptation of Transformer-Based Biomedical Language Models.](http://arxiv.org/abs/2212.10422) | 本研究针对生物医学领域内自适应问题，探讨了两种途径来在非英语语言中产生生物医学语言模型。一种是通过神经机器翻译将英文资源翻译为目标语言，注重数量；另一种是直接基于高质量、狭谱的语料库进行本地化。这些方法有助于解决资源较少语言如意大利语的领域内适应问题。 |
| [^102] | [What is the Solution for State-Adversarial Multi-Agent Reinforcement Learning?.](http://arxiv.org/abs/2212.02705) | 本文提出了一种解决面对对抗性状态的多智能体强化学习问题的方法，通过引入状态对抗性马尔科夫博弈，提出了鲁棒智能体策略的概念，并证明了其在有限状态和有限动作情况下的存在性。此外，还提出了一种鲁棒多智能体对抗性演员-评论家算法，用于学习在状态不确定性下的鲁棒性策略。 |
| [^103] | [Differentiable User Models.](http://arxiv.org/abs/2211.16277) | 该研究提出了可微分的用户模型，通过引入可广泛应用的可微分替代品解决了现代先进用户模型与机器学习流程的不兼容性和计算代价过高的问题。实验证明，在线应用中可以实现与现有无似然推理方法相当的建模能力，并展示了在菜单搜索任务中如何利用认知模型进行在线交互。 |
| [^104] | [QueryForm: A Simple Zero-shot Form Entity Query Framework.](http://arxiv.org/abs/2211.07730) | QueryForm是一种简单的零样本表单实体查询框架，通过使用双重提示机制和利用大规模查询-实体对进行预训练，能够从结构化文档中提取实体值，无需目标特定的训练数据，达到了新的最先进技术水平。 |
| [^105] | [Hierarchical MixUp Multi-label Classification with Imbalanced Interdisciplinary Research Proposals.](http://arxiv.org/abs/2209.13912) | 层次混合多标签分类方法用于解决不平衡的跨学科研究提案中的独特问题，包括层次结构的标签、异构的语义和不平衡的数量。 |
| [^106] | [Attention-aware Resource Allocation and QoE Analysis for Metaverse xURLLC Services.](http://arxiv.org/abs/2208.05438) | 本文研究了元宇宙xURLLC服务资源分配和QoE分析，提出了一个最优合同设计框架。在数学上模拟QoE的新型度量标准Meta-Immersion有助于在满足客户端物理需求的情况下，提供个性化沉浸式体验。 |
| [^107] | [Towards KAB2S: Learning Key Knowledge from Single-Objective Problems to Multi-Objective Problem.](http://arxiv.org/abs/2206.12906) | 本文是进化传输优化（ETO）领域的一项重要工作，通过将多目标优化问题与单目标优化问题相结合，提出了一个新的核心传输机制和学习技术，可以在离散情况下实现智能调度和绿色调度的目标。 |
| [^108] | [ETO Meets Scheduling: Learning Key Knowledge from Single-Objective Problems to Multi-Objective Problem.](http://arxiv.org/abs/2206.12902) | 本研究是第一个将ETO应用于多目标问题和组合问题中的调度问题的工作。通过从解决单目标问题中学习和迁移关键知识，我们提出的ETO-PFSP框架在排列流水车间调度问题中展示了相对有效和很大的潜力。 |
| [^109] | [Local Byte Fusion for Neural Machine Translation.](http://arxiv.org/abs/2205.11490) | 本文提出了一种基于字节的本地字节融合方法，用于神经机器翻译。该方法可以解决当前NLP模型中子词标记化方案的刚性和对其他语料库适应性差的问题，同时避免了在多语种语料库中过度切分低资源语言的影响。 |
| [^110] | [Incorporating Prior Knowledge into Neural Networks through an Implicit Composite Kernel.](http://arxiv.org/abs/2205.07384) | 本论文提出了一种通过深度学习和高斯过程的复合核来将先验知识融入神经网络的方法。通过隐式定义的神经网络核函数和选择的第二个核函数，可以模拟已知特性，并提高深度学习应用的性能。 |
| [^111] | [Test-time Adaptation with Slot-Centric Models.](http://arxiv.org/abs/2203.11194) | 本论文提出了一种以插槽为中心的模型，用于解析分布外的场景，并通过测试时自适应来提高模型性能。通过结合自监督损失和建模偏差，该模型在场景分解任务上取得了良好的效果。 |
| [^112] | [High-Modality Multimodal Transformer: Quantifying Modality & Interaction Heterogeneity for High-Modality Representation Learning.](http://arxiv.org/abs/2203.01311) | 本文研究了高模态场景下的高效表示学习，提出了两种新的信息论度量方法来量化模态和交互的异质性，以加速对多样化和少被研究的模态的推广。 (arXiv:2203.01311v4 [cs.LG] UPDATED) |
| [^113] | [A Longitudinal Multi-modal Dataset for Dementia Monitoring and Diagnosis.](http://arxiv.org/abs/2109.01537) | 该论文提出了一个纵向多模态数据集，用于痴呆监测和诊断。通过分析语言、言语和语用指标，可以区分神经退行性疾病患者和对照组，从而为痴呆研究提供了宝贵的资源。 |

# 详细

[^1]: 关于数据中毒攻击的聚合防御的实践方面

    On Practical Aspects of Aggregation Defenses against Data Poisoning Attacks. (arXiv:2306.16415v1 [cs.LG])

    [http://arxiv.org/abs/2306.16415](http://arxiv.org/abs/2306.16415)

    本文研究了数据中毒攻击的聚合防御策略的实践方面，并针对Deep Partition Aggregation进行了评估，包括效率、性能和鲁棒性。实验结果显示，基于缩放基础模型的方法能够提高聚合防御的训练效率。

    

    对于深度学习来说，数据的增加不仅带来机会，也带来风险，因为恶意训练样本可以操纵深度学习模型的行为。这种攻击被称为数据中毒。近期对抗数据中毒的防御策略的进展突出了聚合方案在实现认证中毒鲁棒性方面的有效性。然而，这些方法的实践影响仍不清楚。本文重点研究了Deep Partition Aggregation，一种代表性的聚合防御，并评估了其实际方面，包括效率、性能和鲁棒性。为了评估，我们使用了被调整到64×64分辨率的ImageNet数据集，以便在比以前更大的规模上进行评估。首先，我们展示了一种简单且实用的基于缩放基础模型的方法，它改善了聚合防御的训练和推理效率。其次，我们提供了支持数据剖分的实证证据。

    The increasing access to data poses both opportunities and risks in deep learning, as one can manipulate the behaviors of deep learning models with malicious training samples. Such attacks are known as data poisoning. Recent advances in defense strategies against data poisoning have highlighted the effectiveness of aggregation schemes in achieving state-of-the-art results in certified poisoning robustness. However, the practical implications of these approaches remain unclear. Here we focus on Deep Partition Aggregation, a representative aggregation defense, and assess its practical aspects, including efficiency, performance, and robustness. For evaluations, we use ImageNet resized to a resolution of 64 by 64 to enable evaluations at a larger scale than previous ones. Firstly, we demonstrate a simple yet practical approach to scaling base models, which improves the efficiency of training and inference for aggregation defenses. Secondly, we provide empirical evidence supporting the data
    
[^2]: MultiZoo & MultiBench: 用于多模态深度学习的标准化工具包

    MultiZoo & MultiBench: A Standardized Toolkit for Multimodal Deep Learning. (arXiv:2306.16413v1 [cs.LG])

    [http://arxiv.org/abs/2306.16413](http://arxiv.org/abs/2306.16413)

    MultiZoo和MultiBench是用于多模态深度学习的标准化工具包，提供了多模态算法的实现和大规模基准测试，以促进对多模态模型能力和限制的理解，并确保易用性和可重复性。

    

    学习多模态表示涉及整合来自多种异构数据源的信息。为了加快对少研究的模态和任务的进展，同时确保现实世界的稳健性，我们发布了MultiZoo，一个公共工具包，其中包含> 20个核心多模态算法的标准化实现，以及MultiBench，一个涵盖15个数据集，10个模态，20个预测任务和6个研究领域的大规模基准测试。这些提供了一个自动化的端到端机器学习流水线，简化和标准化数据加载、实验设置和模型评估。为了实现全面评估，我们提供了一套全面的方法来评估（1）泛化能力，（2）时间和空间复杂度，和（3）模态鲁棒性。MultiBench为更好地了解多模态模型的功能和限制铺平了道路，同时确保易于使用、可访问性和可重复性。我们的工具包是公开可用的。

    Learning multimodal representations involves integrating information from multiple heterogeneous sources of data. In order to accelerate progress towards understudied modalities and tasks while ensuring real-world robustness, we release MultiZoo, a public toolkit consisting of standardized implementations of > 20 core multimodal algorithms and MultiBench, a large-scale benchmark spanning 15 datasets, 10 modalities, 20 prediction tasks, and 6 research areas. Together, these provide an automated end-to-end machine learning pipeline that simplifies and standardizes data loading, experimental setup, and model evaluation. To enable holistic evaluation, we offer a comprehensive methodology to assess (1) generalization, (2) time and space complexity, and (3) modality robustness. MultiBench paves the way towards a better understanding of the capabilities and limitations of multimodal models, while ensuring ease of use, accessibility, and reproducibility. Our toolkits are publicly available, wi
    
[^3]: 测量语言模型中主观全球观点的方法研究

    Towards Measuring the Representation of Subjective Global Opinions in Language Models. (arXiv:2306.16388v1 [cs.CL])

    [http://arxiv.org/abs/2306.16388](http://arxiv.org/abs/2306.16388)

    本文提出了一个方法来评估大型语言模型对全球观点的代表性。通过构建一个包含跨国调查问题和答案的数据集，并定义一个相似度度量标准，研究发现默认情况下语言模型的回应更倾向于某些人群的观点，但当模型考虑特定国家的观点时，回应会更加贴近该国家的观点。

    

    大型语言模型（LLMs）可能无法公平地代表社会问题中多样化的全球观点。本文开发了一个定量框架，用于评估模型生成的回答与哪些人的观点更为相似。我们首先构建了一个数据集GlobalOpinionQA，包含了来自跨国调查的问题和答案，旨在捕捉不同国家关于全球问题的多样观点。然后，我们定义了一个度量标准，以国家为条件，量化了LLM生成的调查回答与人类回答之间的相似性。在我们的框架下，我们对一个经过宪法AI培训的LLM进行了三个实验，分别考虑其帮助性、诚实性和无害性。默认情况下，LLM的回应更倾向于与某些人群的观点更类似，例如来自美国、欧洲和南美洲的人群，凸显了潜在的偏见。当我们提示模型考虑某个特定国家的观点时，回应会更加类似于该国家的观点。

    Large language models (LLMs) may not equitably represent diverse global perspectives on societal issues. In this paper, we develop a quantitative framework to evaluate whose opinions model-generated responses are more similar to. We first build a dataset, GlobalOpinionQA, comprised of questions and answers from cross-national surveys designed to capture diverse opinions on global issues across different countries. Next, we define a metric that quantifies the similarity between LLM-generated survey responses and human responses, conditioned on country. With our framework, we run three experiments on an LLM trained to be helpful, honest, and harmless with Constitutional AI. By default, LLM responses tend to be more similar to the opinions of certain populations, such as those from the USA, and some European and South American countries, highlighting the potential for biases. When we prompt the model to consider a particular country's perspective, responses shift to be more similar to the
    
[^4]: 加速GNN框架中的采样和聚合操作：利用GPU发起直接存储访问

    Accelerating Sampling and Aggregation Operations in GNN Frameworks with GPU Initiated Direct Storage Accesses. (arXiv:2306.16384v1 [cs.DC])

    [http://arxiv.org/abs/2306.16384](http://arxiv.org/abs/2306.16384)

    本论文提出了一种通过利用GPU发起直接存储访问来加速GNN框架中的采样和聚合操作的方法，解决了在训练大规模图上时CPU无法充分利用GPU资源的问题。

    

    图神经网络（GNNs）正在成为学习图结构数据和进行复杂推理任务的一个强大工具，适用于各个应用领域。尽管已经证明GNNs在中等规模的图上具有有效性，但在大规模图上训练仍然面临着数据访问和数据移动方法的不足。现有的GNN训练框架使用CPU进行图采样和特征聚合，而模型权重的训练和更新则由GPU执行。然而，我们深入分析发现CPU无法实现所需的吞吐量以充分利用昂贵的GPU资源。此外，当图和其嵌入不能适应CPU内存时，操作系统引入的开销，如处理页面错误，会成为关键路径的瓶颈。为了解决这些问题，我们提出了GPU发起的直接存储访问方法。

    Graph Neural Networks (GNNs) are emerging as a powerful tool for learning from graph-structured data and performing sophisticated inference tasks in various application domains. Although GNNs have been shown to be effective on modest-sized graphs, training them on large-scale graphs remains a significant challenge due to lack of efficient data access and data movement methods. Existing frameworks for training GNNs use CPUs for graph sampling and feature aggregation, while the training and updating of model weights are executed on GPUs. However, our in-depth profiling shows the CPUs cannot achieve the throughput required to saturate GNN model training throughput, causing gross under-utilization of expensive GPU resources. Furthermore, when the graph and its embeddings do not fit in the CPU memory, the overhead introduced by the operating system, say for handling page-faults, comes in the critical path of execution.  To address these issues, we propose the GPU Initiated Direct Storage Ac
    
[^5]: 基于拉格朗日的A*算法用于自动推理

    Lagrangian based A* algorithm for automated reasoning. (arXiv:2306.16368v1 [cs.AI])

    [http://arxiv.org/abs/2306.16368](http://arxiv.org/abs/2306.16368)

    本文介绍了一种基于拉格朗日的A*算法，通过在启发式部分引入权重，提高了算法的效率，并将其应用于无人机路径规划中。该方法可以用于其他问题，以提高算法在这些领域的效率。

    

    本文考虑了对最短路径问题进行A*算法的修改。在A*算法的启发式部分引入了权重以提高其效率。将该算法应用于无人机路径规划中，其中速度被视为启发式的权重。首先使用基于变分微积分的拉格朗日方程来确定速度作为动态系统的决定性因素。这种方法也可以用于其他问题，以提高这些领域中算法的效率。

    In this paper, a modification of A* algorithm is considered for the shortest path problem. A weightage is introduced in the heuristic part of the A* algorithm to improve its efficiency. An application of the algorithm is considered for UAV path planning wherein velocity is taken as the weigtage to the heuristic. At the outset, calculus of variations based Lagrange's equation was used to identify velocity as the decisive factor for the dynamical system. This approach would be useful for other problems as well to improve the efficiency of algorithms in those areas.
    
[^6]: 通过密度标志检测来识别离散化潜在坐标系统的可识别性

    Identifiability of Discretized Latent Coordinate Systems via Density Landmarks Detection. (arXiv:2306.16334v1 [cs.LG])

    [http://arxiv.org/abs/2306.16334](http://arxiv.org/abs/2306.16334)

    本文提出了一种新颖的可识别性形式，称为量化坐标可识别性。在无监督的情况下，我们展示了在高度通用的非线性映射下，可以恢复离散化的潜在坐标，而无需额外的归纳偏差。这一发现对解缠研究具有重要意义。

    

    解缠旨在仅从观察到的分布中恢复有意义的潜在真实因素。 可识别性为解缠提供了理论基础。 不幸的是，在自适应独立潜变量因子的情况下，在一般的非线性光滑因子到观测的映射下，无监督的可识别性在i.i.d.设置下是理论上不可能的。 在这项工作中，我们展示了非常惊人的是，在高度通用的非线性光滑映射（一个微分同胚）下，可以恢复离散化的潜在坐标，而不需要对映射进行任何额外的归纳偏差。 这是在假设潜在密度具有轴对齐的不连续标志的情况下，但不做因素的统计独立的不现实的假设。 我们引入了这种新颖的可识别性形式，称为量化坐标可识别性，并对恢复离散坐标进行了全面的证明。

    Disentanglement aims to recover meaningful latent ground-truth factors from only the observed distribution. Identifiability provides the theoretical grounding for disentanglement to be well-founded. Unfortunately, unsupervised identifiability of independent latent factors is a theoretically proven impossibility in the i.i.d. setting under a general nonlinear smooth map from factors to observations. In this work, we show that, remarkably, it is possible to recover discretized latent coordinates under a highly generic nonlinear smooth mapping (a diffeomorphism) without any additional inductive bias on the mapping. This is, assuming that latent density has axis-aligned discontinuity landmarks, but without making the unrealistic assumption of statistical independence of the factors. We introduce this novel form of identifiability, termed quantized coordinate identifiability, and provide a comprehensive proof of the recovery of discretized coordinates.
    
[^7]: 通过变分贝叶斯网络实现表示学习

    Representation Learning via Variational Bayesian Networks. (arXiv:2306.16326v1 [cs.LG])

    [http://arxiv.org/abs/2306.16326](http://arxiv.org/abs/2306.16326)

    VBN是一种利用层次和关系信息的新颖的贝叶斯实体表示学习模型，特别适用于数据稀缺的“长尾”实体建模。通过使用层次先验和明确关系约束，VBN提供了更好的建模效果，并通过密度表示实体，对数据稀缺情况下的不确定性进行建模。我们还提出了一种可扩展的变分贝叶斯优化算法来实现快速的近似贝叶斯推断。

    

    我们提出了一种新颖的贝叶斯实体表示学习模型-变分贝叶斯网络 (VBN)，该模型利用层次和关系信息，并对“长尾”中的实体建模特别有用，因为这种情况下数据稀缺。VBN通过两种互补机制提供了更好的长尾实体建模：首先，VBN采用了信息丰富的层次先验，使共享共同祖先的实体之间的信息传播成为可能。此外，VBN建模了实体之间的明确关系，强制实体之间的互补结构和一致性，引导学习的表示向更有意义的空间布局。其次，VBN通过密度表示实体（而不是向量），从而对数据稀缺情况下起到补充作用的不确定性进行建模。最后，我们提出了一种可扩展的变分贝叶斯优化算法，实现了快速的近似贝叶斯推断。我们评估了VBN在语言学任务上的有效性。

    We present Variational Bayesian Network (VBN) - a novel Bayesian entity representation learning model that utilizes hierarchical and relational side information and is particularly useful for modeling entities in the ``long-tail'', where the data is scarce. VBN provides better modeling for long-tail entities via two complementary mechanisms: First, VBN employs informative hierarchical priors that enable information propagation between entities sharing common ancestors. Additionally, VBN models explicit relations between entities that enforce complementary structure and consistency, guiding the learned representations towards a more meaningful arrangement in space. Second, VBN represents entities by densities (rather than vectors), hence modeling uncertainty that plays a complementary role in coping with data scarcity. Finally, we propose a scalable Variational Bayes optimization algorithm that enables fast approximate Bayesian inference. We evaluate the effectiveness of VBN on linguist
    
[^8]: 一种用于中文文本纠错的对抗多任务学习方法和语义检测

    An Adversarial Multi-Task Learning Method for Chinese Text Correction with Semantic Detection. (arXiv:2306.16313v1 [cs.CL])

    [http://arxiv.org/abs/2306.16313](http://arxiv.org/abs/2306.16313)

    本论文提出了一种用于中文文本纠错的对抗多任务学习方法和语义检测，在中文句子上下文中增强了字符多义的建模和检测能力，并通过实验证明了方法的有效性。

    

    文本纠错，尤其是更广泛应用场景下的语义纠错，对于提高文本的流畅性和写作效率有着极高的需求。本文提出了一种对抗多任务学习方法，旨在增强中文句子上下文中字符多义的建模和检测能力。其中，引入了掩码语言模型和评分语言模型作为一对不仅耦合而且对抗的学习任务。此外，还引入了蒙特卡洛树搜索策略和一个策略网络，以实现带有语义检测的高效中文文本纠错任务。实验在三个数据集和五种可比较的方法上进行，实验结果表明，我们的方法在中文文本纠错任务中表现良好，能够更好地实现语义合理性。

    Text correction, especially the semantic correction of more widely used scenes, is strongly required to improve, for the fluency and writing efficiency of the text. An adversarial multi-task learning method is proposed to enhance the modeling and detection ability of character polysemy in Chinese sentence context. Wherein, two models, the masked language model and scoring language model, are introduced as a pair of not only coupled but also adversarial learning tasks. Moreover, the Monte Carlo tree search strategy and a policy network are introduced to accomplish the efficient Chinese text correction task with semantic detection. The experiments are executed on three datasets and five comparable methods, and the experimental results show that our method can obtain good performance in Chinese text correction task for better semantic rationality.
    
[^9]: 社交世界知识：建模与应用

    Social World Knowledge: Modeling and Applications. (arXiv:2306.16299v1 [cs.AI])

    [http://arxiv.org/abs/2306.16299](http://arxiv.org/abs/2306.16299)

    这项工作引入了SocialVec框架，用于从社交网络中提取低维实体嵌入，旨在构建一个专门捕捉社交世界知识的资源。

    

    社交世界知识是人类和机器有效沟通和信息处理的关键因素。目前存在许多表示事实世界知识的知识库，但没有一个资源专门设计用于捕捉社交方面的世界知识。本研究向构建此类资源迈出了重要一步。我们引入了SocialVec，这是一个通用的框架，用于从社交网络中发生的社交环境中提取低维实体嵌入。在这个框架中，实体对应于引起普遍兴趣的高度受欢迎的帐户。我们假设个体用户倾向于共同关注的实体是社交相关的，并使用这个社交环境的定义来学习实体嵌入。类似于有助于涉及文本语义的任务的词嵌入，我们期望学到的社交实体嵌入将有益于多个具有社交特色的任务。

    Social world knowledge is a key ingredient in effective communication and information processing by humans and machines alike. As of today, there exist many knowledge bases that represent factual world knowledge. Yet, there is no resource that is designed to capture social aspects of world knowledge. We believe that this work makes an important step towards the formulation and construction of such a resource. We introduce SocialVec, a general framework for eliciting low-dimensional entity embeddings from the social contexts in which they occur in social networks. In this framework, entities correspond to highly popular accounts which invoke general interest. We assume that entities that individual users tend to co-follow are socially related, and use this definition of social context to learn the entity embeddings. Similar to word embeddings which facilitate tasks that involve text semantics, we expect the learned social entity embeddings to benefit multiple tasks of social flavor. In 
    
[^10]: 相关实体选择：通过零样本类比修剪进行知识图谱引导

    Relevant Entity Selection: Knowledge Graph Bootstrapping via Zero-Shot Analogical Pruning. (arXiv:2306.16296v1 [cs.AI])

    [http://arxiv.org/abs/2306.16296](http://arxiv.org/abs/2306.16296)

    本文提出了一种基于类比的方法，通过选择和修剪相关实体，从而引导知识图谱的构建。实证结果显示，这种方法在两个领域和异质种子实体的数据集上优于其他机器学习方法，并具有较低的参数数量。这些结果支持在相关任务中进一步应用类比推理。

    

    知识图谱构建可以被视为一个迭代过程，从高质量的核心开始，通过知识提取方法不断改进。这样的核心可以从像Wikidata这样的开放式知识图谱中获得。然而，由于这种通用知识图谱的规模，将其作为整体集成可能会包含无关内容和可扩展性问题。我们提出了一种基于类比的方法，从通用知识图谱中的感兴趣种子实体开始，并保留或修剪其相邻实体。我们通过两个手动标记的数据集 在Wikidata上评估了我们的方法，这些数据集包含领域同质或异质的种子实体。我们从实证上证明了我们的基于类比的方法优于LSTM，随机森林，支持向量机和多层感知器，且参数数量大大减少。我们还在迁移学习环境中评估了其泛化能力。这些结果对于进一步将基于类比的推理集成到相关任务中提供了支持。

    Knowledge Graph Construction (KGC) can be seen as an iterative process starting from a high quality nucleus that is refined by knowledge extraction approaches in a virtuous loop. Such a nucleus can be obtained from knowledge existing in an open KG like Wikidata. However, due to the size of such generic KGs, integrating them as a whole may entail irrelevant content and scalability issues. We propose an analogy-based approach that starts from seed entities of interest in a generic KG, and keeps or prunes their neighboring entities. We evaluate our approach on Wikidata through two manually labeled datasets that contain either domain-homogeneous or -heterogeneous seed entities. We empirically show that our analogy-based approach outperforms LSTM, Random Forest, SVM, and MLP, with a drastically lower number of parameters. We also evaluate its generalization potential in a transfer learning setting. These results advocate for the further integration of analogy-based inference in tasks relate
    
[^11]: 利用GPT-4进行食物影响摘要以通过迭代提示增强产品特定指导开发

    Leveraging GPT-4 for Food Effect Summarization to Enhance Product-Specific Guidance Development via Iterative Prompting. (arXiv:2306.16275v1 [cs.CL])

    [http://arxiv.org/abs/2306.16275](http://arxiv.org/abs/2306.16275)

    本研究提出了一种通过迭代提示与ChatGPT或GPT-4进行多轮交互的方法来改进食物影响摘要的准确性。这种方法在产品特定指导(PSG)开发中具有潜力应用的价值。

    

    食物影响从新药申请(NDA)中的摘要是产品特定指导(PSG)开发和评估的重要组成部分。然而，从大量药物申请审查文件中手动摘要食物影响是耗时的，这引发了开发自动化方法的需求。最近大型语言模型(LLMs)如ChatGPT和GPT-4的进展已经展示了在改善自动文本摘要效果方面的巨大潜力，但其在PSG评估中准确概括食物影响的能力尚不清楚。在这项研究中，我们引入了一种简单而有效的方法，即迭代提示，通过多轮交互更有效和高效地与ChatGPT或GPT-4进行互动。具体而言，我们提出了一个三轮迭代提示的方法来进行食物影响摘要，其中在连续的轮次中分别提供了关键字聚焦和长度控制的提示以细化。

    Food effect summarization from New Drug Application (NDA) is an essential component of product-specific guidance (PSG) development and assessment. However, manual summarization of food effect from extensive drug application review documents is time-consuming, which arouses a need to develop automated methods. Recent advances in large language models (LLMs) such as ChatGPT and GPT-4, have demonstrated great potential in improving the effectiveness of automated text summarization, but its ability regarding the accuracy in summarizing food effect for PSG assessment remains unclear. In this study, we introduce a simple yet effective approach, iterative prompting, which allows one to interact with ChatGPT or GPT-4 more effectively and efficiently through multi-turn interaction. Specifically, we propose a three-turn iterative prompting approach to food effect summarization in which the keyword-focused and length-controlled prompts are respectively provided in consecutive turns to refine the 
    
[^12]: 在阿富汗禁止教育的推文情绪分析

    Emotion Analysis of Tweets Banning Education in Afghanistan. (arXiv:2306.16268v1 [cs.CL])

    [http://arxiv.org/abs/2306.16268](http://arxiv.org/abs/2306.16268)

    这项研究介绍了第一个用于阿富汗普什图语变体的情绪标注数据集，该数据集包含7600条推文，以研究塔利班禁止妇女接受教育的情绪反应，并通过多种神经架构对达里语情感分类进行基准测试。

    

    本文介绍了第一个用于阿富汗普什图语变体的情绪标注数据集。LetHerLearn数据集包含了7600条推文，这些推文是对塔利班于2022年禁止妇女接受教育的反应，并且已根据埃克曼情绪类别进行了手动标注。我们在此详细介绍了数据收集和标注过程，呈现了相关数据集统计信息以及对所得数据集进行的初步实验，对达里语情感分类任务进行了多种不同神经架构的基准测试。

    This paper introduces the first emotion annotated dataset for the Dari variant of Persian spoken in Afghanistan. The LetHerLearn dataset contains 7,600 tweets posted in reaction to the Taliban ban of women rights to education in 2022 and has been manually annotated according to Ekman emotion categories. We here detail the data collection and annotation process, present relevant dataset statistics as well as initial experiments on the resulting dataset, benchmarking a number of different neural architectures for the task of Dari emotion classification.
    
[^13]: CBBQ: 通过人工智能与人类协同合作为大型语言模型构建的中文偏差基准数据集

    CBBQ: A Chinese Bias Benchmark Dataset Curated with Human-AI Collaboration for Large Language Models. (arXiv:2306.16244v1 [cs.CL])

    [http://arxiv.org/abs/2306.16244](http://arxiv.org/abs/2306.16244)

    通过人工智能与人类协同合作构建的CBBQ中文偏差基准数据集，全面衡量了与中国文化和价值观相关的14个社会维度中的刻板印象和社会偏见，对于检测模型偏见具有广泛的覆盖范围和高度的多样性。

    

    全面衡量大型语言模型的社会偏见对于检测和降低高能力人工智能模型的道德风险至关重要。在这项工作中，我们介绍了一个由人类专家和生成式语言模型共同构建的中文偏差基准数据集，包括与中国文化和价值观相关的14个社会维度中的刻板印象和社会偏见。在数据集的整理过程中，包括4个关键步骤：通过广泛的文献评论识别偏见，生成模糊的上下文，通过人工智能辅助消除模糊的上下文，以及手动审查和重组。数据集中的测试实例是从3000多个经过严格质量控制的高质量模板手动提取的。数据集具有广泛的覆盖范围和高度的多样性。广泛的实验证明了该数据集在检测模型偏见方面的有效性，10个公开可用的中文大型语言模型均表现出明显的偏见。

    Holistically measuring societal biases of large language models is crucial for detecting and reducing ethical risks in highly capable AI models. In this work, we present a Chinese Bias Benchmark dataset that consists of over 100K questions jointly constructed by human experts and generative language models, covering stereotypes and societal biases in 14 social dimensions related to Chinese culture and values. The curation process contains 4 essential steps: bias identification via extensive literature review, ambiguous context generation, AI-assisted disambiguous context generation, snd manual review \& recomposition. The testing instances in the dataset are automatically derived from 3K+ high-quality templates manually authored with stringent quality control. The dataset exhibits wide coverage and high diversity. Extensive experiments demonstrate the effectiveness of the dataset in detecting model bias, with all 10 publicly available Chinese large language models exhibiting strong bia
    
[^14]: 从行动和指令中推断沟通代理的目标

    Inferring the Goals of Communicating Agents from Actions and Instructions. (arXiv:2306.16207v1 [cs.AI])

    [http://arxiv.org/abs/2306.16207](http://arxiv.org/abs/2306.16207)

    本文介绍了一个模型，可以通过观察行动和指令推断合作团队的目标，并评估了其与人类判断的相关性。

    

    当人类合作时，他们经常通过口头沟通和非口头行动来协调活动，利用这些信息来推断共同的目标和计划。我们如何建模这种推理能力？本文介绍了一个合作团队的模型，其中一个代理（主要的）可以通过自然语言指令向另一个代理（助理）传达关于共同计划的信息，使用GPT-3作为指令语句的似然函数。然后，我们展示了一个第三方观察者如何通过多模态贝叶斯逆向规划从行动和指令中推断团队的目标，计算在代理人会采取和交流以实现目标的假设下的目标的后验分布。我们通过将其与多代理系统的网格世界中的人类目标推断进行比较来评估这种方法，发现我们模型的推断与人类判断密切相关（R = 0.96）。与仅从行动推断相比，我们还发现...

    When humans cooperate, they frequently coordinate their activity through both verbal communication and non-verbal actions, using this information to infer a shared goal and plan. How can we model this inferential ability? In this paper, we introduce a model of a cooperative team where one agent, the principal, may communicate natural language instructions about their shared plan to another agent, the assistant, using GPT-3 as a likelihood function for instruction utterances. We then show how a third person observer can infer the team's goal via multi-modal Bayesian inverse planning from actions and instructions, computing the posterior distribution over goals under the assumption that agents will act and communicate rationally to achieve them. We evaluate this approach by comparing it with human goal inferences in a multi-agent gridworld, finding that our model's inferences closely correlate with human judgments (R = 0.96). When compared to inference from actions alone, we also find th
    
[^15]: 运用多智能体团队实现更好的学习理解

    Towards a Better Understanding of Learning with Multiagent Teams. (arXiv:2306.16205v1 [cs.AI])

    [http://arxiv.org/abs/2306.16205](http://arxiv.org/abs/2306.16205)

    本文研究了为个体学习代理群体提供有效学习的团队结构，发现某些团队结构有助于代理学习专业化到具体角色，从而产生更好的整体结果。然而，大团队存在责任归因难题，导致协调性降低，大团队表现较小团队差。

    

    虽然长期以来人们已经认识到一个由个体学习代理组成的团队可以超越其个体的能力，但最近的研究表明，规模较大的团队并不一定比规模较小的团队更有效。在本文中，我们研究了为个体学习代理群体提供有效学习的某些团队结构为何以及在哪些条件下能够提供有效学习。我们发现，在不同的环境中，某些团队结构有助于代理学习专业化到具体角色，从而产生更好的整体结果。然而，大团队存在责任归因难题，导致协调性降低，大团队表现较小团队差。我们通过理论分析和实证结果支持了我们的结论。

    While it has long been recognized that a team of individual learning agents can be greater than the sum of its parts, recent work has shown that larger teams are not necessarily more effective than smaller ones. In this paper, we study why and under which conditions certain team structures promote effective learning for a population of individual learning agents. We show that, depending on the environment, some team structures help agents learn to specialize into specific roles, resulting in more favorable global results. However, large teams create credit assignment challenges that reduce coordination, leading to large teams performing poorly compared to smaller ones. We support our conclusions with both theoretical analysis and empirical results.
    
[^16]: 通过动态图知识聚合提升对话生成

    Enhancing Dialogue Generation via Dynamic Graph Knowledge Aggregation. (arXiv:2306.16195v1 [cs.CL])

    [http://arxiv.org/abs/2306.16195](http://arxiv.org/abs/2306.16195)

    本研究提出了一个通过动态图知识聚合来提升对话生成的新框架，它能够更好地利用来自帖子和外部图知识的异质特征，从而解决图知识和文本之间的语义差异问题。

    

    将外部图知识融入神经对话机器人模型已被证明有效提升对话生成。然而，在传统的图神经网络（GNN）中，图上的信息传递与文本无关，导致图表征和文本之间存在语义差异。现有模型的训练方式导致了图知识和文本之间的语义鸿沟。本研究提出了一种新的知识图增强对话生成的框架。我们动态构建一个带有伪节点的多跳知识图，在图中的每一步中都将语言模型纳入特征聚合。为了避免学习在普通子图上引起的语义偏差，所提出的框架应用了分层图注意力，以聚合伪节点上的图特征，最终获得全局特征。因此，该框架能够更好地利用来自帖子和外部图知识的异质特征。

    Incorporating external graph knowledge into neural chatbot models has been proven effective for enhancing dialogue generation. However, in conventional graph neural networks (GNNs), message passing on a graph is independent from text, resulting in the graph representation hidden space differing from that of the text. This training regime of existing models therefore leads to a semantic gap between graph knowledge and text. In this study, we propose a novel framework for knowledge graph enhanced dialogue generation. We dynamically construct a multi-hop knowledge graph with pseudo nodes to involve the language model in feature aggregation within the graph at all steps. To avoid the semantic biases caused by learning on vanilla subgraphs, the proposed framework applies hierarchical graph attention to aggregate graph features on pseudo nodes and then attains a global feature. Therefore, the framework can better utilise the heterogeneous features from both the post and external graph knowle
    
[^17]: 通过特定的知识注入，有效地将预训练的大型视觉模型转移到面料缺陷分割中

    Effective Transfer of Pretrained Large Visual Model for Fabric Defect Segmentation via Specifc Knowledge Injection. (arXiv:2306.16186v1 [cs.CV])

    [http://arxiv.org/abs/2306.16186](http://arxiv.org/abs/2306.16186)

    本研究通过在Segment Anything Model (SAM)中引入和训练一组面料缺陷相关的参数，无缝地将专业知识注入到大型视觉模型中，从而提高了面料缺陷分割的性能和泛化能力。

    

    面料缺陷分割是纺织品质量控制中不可或缺的一部分。然而，高质量标注数据的稀缺性和面料缺陷的多样性对深度学习在这一领域的应用提出了重大挑战。这些因素限制了现有模型的泛化和分割性能，阻碍了它们处理各种不同面料类型和缺陷的复杂性的能力。为了克服这些障碍，本研究引入了一种创新的方法，将面料缺陷的专业知识注入到Segment Anything Model (SAM) 这个大型视觉模型中。通过引入并训练一组独特的与面料缺陷相关的参数，这种方法在不需要对预先存在的模型参数进行大量修改的情况下，无缝地将领域特定的知识整合到SAM中。改进后的SAM模型利用从大规模自然图像数据集中学到的广义图像理解能力，同时结合了面料缺陷特定的知识。

    Fabric defect segmentation is integral to textile quality control. Despite this, the scarcity of high-quality annotated data and the diversity of fabric defects present significant challenges to the application of deep learning in this field. These factors limit the generalization and segmentation performance of existing models, impeding their ability to handle the complexity of diverse fabric types and defects. To overcome these obstacles, this study introduces an innovative method to infuse specialized knowledge of fabric defects into the Segment Anything Model (SAM), a large-scale visual model. By introducing and training a unique set of fabric defect-related parameters, this approach seamlessly integrates domain-specific knowledge into SAM without the need for extensive modifications to the pre-existing model parameters. The revamped SAM model leverages generalized image understanding learned from large-scale natural image datasets while incorporating fabric defect-specific knowled
    
[^18]: 定义数据科学：一种新的研究范式

    Defining data science: a new field of inquiry. (arXiv:2306.16177v1 [cs.LG])

    [http://arxiv.org/abs/2306.16177](http://arxiv.org/abs/2306.16177)

    数据科学是一种新的研究范式，具有潜力和应用广泛性，在40多个学科、数百个研究领域和成千上万个应用中出现。然而，由于其起步阶段，目前存在许多定义的冗余和不一致性的问题。

    

    数据科学不是一门科学，而是一种研究范式。它的力量、范围和规模将超越科学，成为促使知识发现并改变世界的重要手段。我们尚未理解和定义它，这对于实现其潜力和管理其风险至关重要。现代数据科学处于起步阶段。自1962年以来缓慢发展，并且自2000年以来发展迅速，它是一种根本性的新的研究领域，是21世纪最活跃、最强大和发展最快的创新之一。由于其价值、力量和适用性，它正在40多个学科、数百个研究领域和成千上万个应用中出现。数以百万计的数据科学出版物中包含了无数关于数据科学和数据科学问题解决的定义。由于其起步阶段，许多定义是独立的、应用特定的、相互不完整的、冗余的或不一致的，因此数据科学也是如此。本研究通过提出解决数据科学多重定义挑战的方法来解决这个问题。

    Data science is not a science. It is a research paradigm. Its power, scope, and scale will surpass science, our most powerful research paradigm, to enable knowledge discovery and change our world. We have yet to understand and define it, vital to realizing its potential and managing its risks. Modern data science is in its infancy. Emerging slowly since 1962 and rapidly since 2000, it is a fundamentally new field of inquiry, one of the most active, powerful, and rapidly evolving 21st century innovations. Due to its value, power, and applicability, it is emerging in 40+ disciplines, hundreds of research areas, and thousands of applications. Millions of data science publications contain myriad definitions of data science and data science problem solving. Due to its infancy, many definitions are independent, application-specific, mutually incomplete, redundant, or inconsistent, hence so is data science. This research addresses this data science multiple definitions challenge by proposing 
    
[^19]: 一份关于源代码相似性测量和克隆检测的系统文献综述：技术、应用和挑战

    A systematic literature review on source code similarity measurement and clone detection: techniques, applications, and challenges. (arXiv:2306.16171v1 [cs.SE])

    [http://arxiv.org/abs/2306.16171](http://arxiv.org/abs/2306.16171)

    这份综述研究了源代码相似性测量和克隆检测的方法和应用，发现了80种软件工具，涉及了多个编程语言，为不同应用领域提供了有益的洞见。

    

    测量和评估源代码相似性是一项基本的软件工程活动，涵盖了广泛的应用，包括但不限于代码推荐、重复代码、抄袭、恶意软件和代码质量检测。本文提出了一份系统的文献综述和元分析，关于代码相似性测量和评估技术，以揭示现有方法在不同应用中的特点。我们通过查询四个数字图书馆最初找到了超过10000篇文章，并最终选择了136个主要研究。这些研究根据其方法学、编程语言、数据集、工具和应用进行了分类。深入研究发现了80种软件工具，使用了八种不同的技术，涉及五个应用领域。近49%的工具适用于Java程序，37%支持C和C++，而许多编程语言没有相应的支持。值得注意的一点是存在着。。。

    Measuring and evaluating source code similarity is a fundamental software engineering activity that embraces a broad range of applications, including but not limited to code recommendation, duplicate code, plagiarism, malware, and smell detection. This paper proposes a systematic literature review and meta-analysis on code similarity measurement and evaluation techniques to shed light on the existing approaches and their characteristics in different applications. We initially found over 10000 articles by querying four digital libraries and ended up with 136 primary studies in the field. The studies were classified according to their methodology, programming languages, datasets, tools, and applications. A deep investigation reveals 80 software tools, working with eight different techniques on five application domains. Nearly 49% of the tools work on Java programs and 37% support C and C++, while there is no support for many programming languages. A noteworthy point was the existence of 
    
[^20]: 使用大规模在线学习训练深度替代模型

    Training Deep Surrogate Models with Large Scale Online Learning. (arXiv:2306.16133v1 [cs.AI])

    [http://arxiv.org/abs/2306.16133](http://arxiv.org/abs/2306.16133)

    本文提出了一种用于深度替代模型的在线训练框架，通过同时生成数值模拟和训练深度神经网络，抑制了磁盘加载数据集相关的瓶颈，开辟了新的研究方向。

    

    偏微分方程（PDE）的时空分辨率在描述世界的物理现象中起着重要作用。一般来说，科学家和工程师通过使用计算复杂的求解器来数值求解PDE。近年来，深度学习算法已成为获得PDE快速解的可行替代方法。这些模型通常在求解器生成的合成数据上进行训练，存储在磁盘上并读取回来进行训练。本文指出，依赖传统静态数据集来训练这些模型并不能充分利用求解器作为数据生成器的全部优势。它提出了一种开源的用于深度替代模型的在线训练框架。该框架实现了多个层次的并行性，同时生成数值模拟和训练深度神经网络。这种方法可以抑制与磁盘加载数据集相关的I/O和存储瓶颈，并为新的研究方向开辟了道路。

    The spatiotemporal resolution of Partial Differential Equations (PDEs) plays important roles in the mathematical description of the world's physical phenomena. In general, scientists and engineers solve PDEs numerically by the use of computationally demanding solvers. Recently, deep learning algorithms have emerged as a viable alternative for obtaining fast solutions for PDEs. Models are usually trained on synthetic data generated by solvers, stored on disk and read back for training. This paper advocates that relying on a traditional static dataset to train these models does not allow the full benefit of the solver to be used as a data generator. It proposes an open source online training framework for deep surrogate models. The framework implements several levels of parallelism focused on simultaneously generating numerical simulations and training deep neural networks. This approach suppresses the I/O and storage bottleneck associated with disk-loaded datasets, and opens the way to 
    
[^21]: 在社交媒体上识别抑郁症的框架：MentalRiskES@IberLEF 2023

    A Framework for Identifying Depression on Social Media: MentalRiskES@IberLEF 2023. (arXiv:2306.16125v1 [cs.CL])

    [http://arxiv.org/abs/2306.16125](http://arxiv.org/abs/2306.16125)

    该论文介绍了在社交媒体上识别抑郁症的框架，使用机器学习和深度学习技术来解决四个预测子任务，并发现使用句子嵌入作为线性回归器的输入产生了更好的结果。

    

    本文描述了我们参与IberLEF 2023的MentalRiskES任务。该任务涉及根据个人在社交媒体上的活动来预测他们可能患抑郁症的可能性。数据集由175个Telegram用户的对话组成，每个用户根据他们患病证据进行标记。我们使用传统机器学习和深度学习技术的组合来解决四个预测子任务：二分类、简单回归、多类别分类和多类别回归。我们通过训练一个模型来解决多类别回归问题，然后将预测结果转换为适用于其他三个子任务的结果。我们比较了两种不同建模方法的性能：对基于BERT的模型进行微调和使用句子嵌入作为线性回归器的输入，后者产生了更好的结果。可以在以下链接找到复现我们结果的代码：https://github.com/simonsanvil/EarlyDep

    This paper describes our participation in the MentalRiskES task at IberLEF 2023. The task involved predicting the likelihood of an individual experiencing depression based on their social media activity. The dataset consisted of conversations from 175 Telegram users, each labeled according to their evidence of suffering from the disorder. We used a combination of traditional machine learning and deep learning techniques to solve four predictive subtasks: binary classification, simple regression, multiclass classification, and multiclass regression. We approached this by training a model to solve the multiclass regression case and then transforming the predictions to work for the other three subtasks. We compare the performance of two different modeling approaches: fine-tuning a BERT-based model and using sentence embeddings as inputs to a linear regressor, with the latter yielding better results. The code to reproduce our results can be found at: https://github.com/simonsanvil/EarlyDep
    
[^22]: 神经网络激活函数的经验损失曲面分析

    Empirical Loss Landscape Analysis of Neural Network Activation Functions. (arXiv:2306.16090v1 [cs.LG])

    [http://arxiv.org/abs/2306.16090](http://arxiv.org/abs/2306.16090)

    本研究通过经验分析了双曲正切、修正线性单元和指数线性单元激活函数相关的神经网络损失曲面，发现修正线性单元呈现最凸型曲面，指数线性单元呈现最平坦曲面并具有更优的泛化性能。所有激活函数的损失曲面中存在宽阔和狭窄的山谷，而狭窄的山谷与饱和神经元和隐含的正则化网络结构相关。

    

    激活函数通过引入非线性在神经网络设计中起着重要作用。先前的研究表明激活函数的选择会影响损失曲面的性质。了解激活函数与损失曲面性质的关系对神经网络架构和训练算法设计是重要的。本研究从经验上分析了与双曲正切、修正线性单元和指数线性单元激活函数相关的神经网络损失曲面。实验证明修正线性单元产生最凸型的损失曲面，指数线性单元产生最平坦的损失曲面，并且展现出更优的泛化性能。对于所有激活函数，损失曲面中存在宽阔和狭窄的山谷，并且狭窄的山谷与饱和神经元和隐含的正则化网络结构相关。

    Activation functions play a significant role in neural network design by enabling non-linearity. The choice of activation function was previously shown to influence the properties of the resulting loss landscape. Understanding the relationship between activation functions and loss landscape properties is important for neural architecture and training algorithm design. This study empirically investigates neural network loss landscapes associated with hyperbolic tangent, rectified linear unit, and exponential linear unit activation functions. Rectified linear unit is shown to yield the most convex loss landscape, and exponential linear unit is shown to yield the least flat loss landscape, and to exhibit superior generalisation performance. The presence of wide and narrow valleys in the loss landscape is established for all activation functions, and the narrow valleys are shown to correlate with saturated neurons and implicitly regularised network configurations.
    
[^23]: 掌握北环—全面的AI策略决策赛车模拟

    Mastering Nordschleife -- A comprehensive race simulation for AI strategy decision-making in motorsports. (arXiv:2306.16088v1 [cs.AI])

    [http://arxiv.org/abs/2306.16088](http://arxiv.org/abs/2306.16088)

    本文针对当前赛车模拟存在的粒度、建模和手动输入问题，开发了一种新型仿真模型，并应用人工智能自动化了策略决策。该研究通过将仿真与强化学习环境相结合，使用历史数据进行评估，以优化赛车比赛策略决策。

    

    在赛车运动领域，比赛策略在决定比赛结果中起着关键作用。这一策略集中在停车时间的选择上，这是由于燃油消耗和轮胎性能退化而必要的。比赛策略的目标是在轮胎更换和加油等停车优势与在停车区域所产生的时间损失之间取得平衡。目前的比赛模拟在粒度、概率事件建模和需要手动输入进站时间等方面存在差异。本文通过开发一种专为GT赛车量身定制的新颖仿真模型，并利用人工智能来自动化战略决策来解决这些限制。通过将仿真与OpenAI的Gym框架相结合，创建了一个强化学习环境并训练了一个智能体。本研究评估了不同的超参数配置、观测空间和奖励函数，利用历史时间数据进行了绘制。

    In the realm of circuit motorsports, race strategy plays a pivotal role in determining race outcomes. This strategy focuses on the timing of pit stops, which are necessary due to fuel consumption and tire performance degradation. The objective of race strategy is to balance the advantages of pit stops, such as tire replacement and refueling, with the time loss incurred in the pit lane. Current race simulations, used to estimate the best possible race strategy, vary in granularity, modeling of probabilistic events, and require manual input for in-laps. This paper addresses these limitations by developing a novel simulation model tailored to GT racing and leveraging artificial intelligence to automate strategic decisions. By integrating the simulation with OpenAI's Gym framework, a reinforcement learning environment is created and an agent is trained. The study evaluates various hyperparameter configurations, observation spaces, and reward functions, drawing upon historical timing data f
    
[^24]: 安全高效的异步垂直联邦学习:基于级联混合优化方法

    Secure and Fast Asynchronous Vertical Federated Learning via Cascaded Hybrid Optimization. (arXiv:2306.16077v1 [cs.LG])

    [http://arxiv.org/abs/2306.16077](http://arxiv.org/abs/2306.16077)

    本论文提出了一种在垂直联邦学习中使用级联混合优化的方法，通过在下游使用零阶优化保护隐私并在上游使用一阶优化提高收敛速度，从而解决了ZOO-based VFL收敛速度较慢的问题。

    

    垂直联邦学习(VFL)因能够在垂直分割的数据上联合训练隐私保护模型而引起越来越多的关注。最近的研究表明，应用零阶优化(ZOO)在构建实用的VFL算法方面具有许多优势。然而，基于ZOO的VFL存在一个关键问题，即其收敛速度较慢，限制了其在处理现代大型模型时的应用。为了解决这个问题，我们提出了一种在VFL中使用级联混合优化方法。该方法中，下游模型（客户端）使用ZOO进行训练以保护隐私并确保不共享内部信息。同时，上游模型（服务器）在本地使用一阶优化(FOO)进行更新，这显著提高了收敛速度，使得能够在不损害隐私和安全性的前提下训练大型模型。我们在理论上证明了我们的VFL框架比基于ZOO的VFL更快地收敛。

    Vertical Federated Learning (VFL) attracts increasing attention because it empowers multiple parties to jointly train a privacy-preserving model over vertically partitioned data. Recent research has shown that applying zeroth-order optimization (ZOO) has many advantages in building a practical VFL algorithm. However, a vital problem with the ZOO-based VFL is its slow convergence rate, which limits its application in handling modern large models. To address this problem, we propose a cascaded hybrid optimization method in VFL. In this method, the downstream models (clients) are trained with ZOO to protect privacy and ensure that no internal information is shared. Meanwhile, the upstream model (server) is updated with first-order optimization (FOO) locally, which significantly improves the convergence rate, making it feasible to train the large models without compromising privacy and security. We theoretically prove that our VFL framework converges faster than the ZOO-based VFL, as the c
    
[^25]: 基于基础生成模型的联邦生成学习

    Federated Generative Learning with Foundation Models. (arXiv:2306.16064v1 [cs.LG])

    [http://arxiv.org/abs/2306.16064](http://arxiv.org/abs/2306.16064)

    本文提出了一种基于基础生成模型的联邦生成学习框架，通过传输提示与分布式训练数据，可以远程合成有信息量的训练数据，从而改善了通信效率、适应分布转移、提升性能、加强隐私保护。

    

    现有的联邦学习解决方案主要集中在在客户端和服务器之间传输特征、参数或梯度，这导致了严重的低效和隐私泄露问题。借助新兴的基础生成模型，我们提出了一种新颖的联邦学习框架，称为联邦生成学习，它在客户端和服务器之间传输与分布式训练数据相关的提示。通过接收到的包含较少隐私信息的提示以及基础生成模型，可以远程合成有信息量的训练数据。这个新框架具有多个优势，包括改善了通信效率、更好的适应分布转移、实现了显著的性能提升、加强了隐私保护。在ImageNet和DomainNet数据集上进行的广泛实验证明了这些优势。

    Existing federated learning solutions focus on transmitting features, parameters or gadients between clients and server, which suffer from serious low-efficiency and privacy-leakage problems. Thanks to the emerging foundation generative models, we propose a novel federated learning framework, namely Federated Generative Learning, that transmits prompts associated with distributed training data between clients and server. The informative training data can be synthesized remotely based on received prompts containing little privacy and the foundation generative models. The new framework possesses multiple advantages, including improved communication efficiency, better resilience to distribution shift, substantial performance gains, and enhanced privacy protection, which are verified in extensive experiments on ImageNet and DomainNet datasets.
    
[^26]: RoMo-HER: 鲁棒的基于模型的事后经验回放方法

    RoMo-HER: Robust Model-based Hindsight Experience Replay. (arXiv:2306.16061v1 [cs.RO])

    [http://arxiv.org/abs/2306.16061](http://arxiv.org/abs/2306.16061)

    RoMo-HER是一个鲁棒的基于模型的事后经验回放方法，通过使用机器人操作环境中的动力学模型和前瞻重新标记技术，提高了样本利用效率。

    

    在多目标强化学习中，稀疏奖励是导致样本利用效率低的因素之一。基于事后经验回放（HER），已经提出了基于模型的重新标记方法，通过与训练模型进行交互获取虚拟轨迹来重新标记目标，在准确可建模的稀疏奖励环境中能够有效增强样本利用效率。然而，在机器人操作环境中，它们是无效的。在我们的论文中，我们设计了一个称为RoMo-HER的鲁棒框架，它可以有效地利用机器人操作环境中的动力学模型来提高样本利用效率。RoMo-HER基于动力学模型和一种称为前瞻重新标记（FR）的新型目标重新标记技术构建，该技术通过特定策略选择预测起始状态，预测起始状态的未来轨迹，然后使用动力学模型和最新的信息重新标记目标。

    Sparse rewards are one of the factors leading to low sample efficiency in multi-goal reinforcement learning (RL). Based on Hindsight Experience Replay (HER), model-based relabeling methods have been proposed to relabel goals using virtual trajectories obtained by interacting with the trained model, which can effectively enhance the sample efficiency in accurately modelable sparse-reward environments. However, they are ineffective in robot manipulation environment. In our paper, we design a robust framework called Robust Model-based Hindsight Experience Replay (RoMo-HER) which can effectively utilize the dynamical model in robot manipulation environments to enhance the sample efficiency. RoMo-HER is built upon a dynamics model and a novel goal relabeling technique called Foresight relabeling (FR), which selects the prediction starting state with a specific strategy, predicts the future trajectory of the starting state, and then relabels the goal using the dynamics model and the latest p
    
[^27]: DUET: 2D结构化且近似等变表示

    DUET: 2D Structured and Approximately Equivariant Representations. (arXiv:2306.16058v1 [cs.LG])

    [http://arxiv.org/abs/2306.16058](http://arxiv.org/abs/2306.16058)

    DUET是一种2D结构化且近似等变表示方法，相比于其他方法，可以在保留输入变换信息的同时具有更好的可控性和更高的准确性。

    

    多视图自监督学习(MSSL)基于学习相对于一组输入变换的不变性。然而，不变性从表示中部分或完全移除与变换相关的信息，这可能对需要这些信息的特定下游任务的性能造成损害。我们提出了2D结构化和等变表示，称为DUET，它们是以矩阵结构组织的2D表示，并且对作用于输入数据的变换具有等变性。DUET表示保留有关输入变换的信息，同时保持语义表达能力。与SimCLR（Chen等，2020）（无结构和不变性）和ESSL（Dangovski等，2022）（无结构和等变性）相比，DUET表示的结构化和等变性使得生成具有更低的重建误差的可控性成为可能，而SimCLR或ESSL则无法实现可控性。DUET还实现了更高的准确性。

    Multiview Self-Supervised Learning (MSSL) is based on learning invariances with respect to a set of input transformations. However, invariance partially or totally removes transformation-related information from the representations, which might harm performance for specific downstream tasks that require such information. We propose 2D strUctured and EquivarianT representations (coined DUET), which are 2d representations organized in a matrix structure, and equivariant with respect to transformations acting on the input data. DUET representations maintain information about an input transformation, while remaining semantically expressive. Compared to SimCLR (Chen et al., 2020) (unstructured and invariant) and ESSL (Dangovski et al., 2022) (unstructured and equivariant), the structured and equivariant nature of DUET representations enables controlled generation with lower reconstruction error, while controllability is not possible with SimCLR or ESSL. DUET also achieves higher accuracy fo
    
[^28]: 零样本识别中的视觉-语言模型的挑战：粒度和正确性

    Challenges of Zero-Shot Recognition with Vision-Language Models: Granularity and Correctness. (arXiv:2306.16048v1 [cs.CV])

    [http://arxiv.org/abs/2306.16048](http://arxiv.org/abs/2306.16048)

    本文研究了将视觉-语言模型应用于零样本视觉识别任务所面临的挑战，发现VLMs在识别细粒度概念方面表现更好，并指出了VLMs中相似度分数不能严格反映正确性的问题，提出了未来研究方向。

    

    本文研究了将视觉-语言模型（VLMs）应用于开放世界环境下的零样本视觉识别任务所面临的挑战，重点关注对比视觉-语言模型（如CLIP）的应用。我们首先检查了VLMs在不同粒度概念上的表现。我们提出了一种公正评估两种实验设置下性能差异的方法，并发现VLMs在识别细粒度概念方面表现更好。此外，我们发现VLMs产生的相似度分数并不能严格反映文本输入在视觉输入下的正确性。我们提出了一种评估协议来测试我们的假设，即分数可能会偏向更具信息的描述，并且由于嵌入之间的相似度分数的性质，对于VLMs来说识别相似但错误的描述之间的正确性是具有挑战性的。我们的研究强调了在开放世界环境中使用VLMs的挑战，并提出了未来研究的方向。

    This paper investigates the challenges of applying vision-language models (VLMs) to zero-shot visual recognition tasks in an open-world setting, with a focus on contrastive vision-language models such as CLIP. We first examine the performance of VLMs on concepts of different granularity levels. We propose a way to fairly evaluate the performance discrepancy under two experimental setups and find that VLMs are better at recognizing fine-grained concepts. Furthermore, we find that the similarity scores from VLMs do not strictly reflect the correctness of the textual inputs given visual input. We propose an evaluation protocol to test our hypothesis that the scores can be biased towards more informative descriptions, and the nature of the similarity score between embedding makes it challenging for VLMs to recognize the correctness between similar but wrong descriptions. Our study highlights the challenges of using VLMs in open-world settings and suggests directions for future research to 
    
[^29]: OpenNDD:用于神经发育障碍检测的开放性识别

    OpenNDD: Open Set Recognition for Neurodevelopmental Disorders Detection. (arXiv:2306.16045v1 [cs.CV])

    [http://arxiv.org/abs/2306.16045](http://arxiv.org/abs/2306.16045)

    OpenNDD是一个用于神经发育障碍检测的开放性识别框架，结合了自动编码器和对抗循环点开放性识别技术，能准确识别已知类别并识别未遇到的类别。

    

    神经发育障碍(NDDs)是一组高患病率的障碍，表现出临床行为的相似性，使得精确识别不同的NDDs（如自闭症谱系障碍（ASD）和注意力缺陷多动障碍（ADHD））非常具有挑战性。此外，对于NDDs诊断并没有可靠的生理标志物，而仅依赖于心理评估标准。然而，通过智能辅助诊断来防止误诊和漏诊是至关重要的，这与随后的相应治疗密切相关。为了缓解这些问题，我们提出了一种新颖的用于NDDs筛查和检测的开放性识别框架，这是在该领域中首次应用开放性识别。它结合了自动编码器和对抗循环点开放性识别，能够准确识别已知类别，并能够识别过去未遇到的类别。

    Neurodevelopmental disorders (NDDs) are a highly prevalent group of disorders and represent strong clinical behavioral similarities, and that make it very challenging for accurate identification of different NDDs such as autism spectrum disorder (ASD) and attention-deficit hyperactivity disorder (ADHD). Moreover, there is no reliable physiological markers for NDDs diagnosis and it solely relies on psychological evaluation criteria. However, it is crucial to prevent misdiagnosis and underdiagnosis by intelligent assisted diagnosis, which is closely related to the follow-up corresponding treatment. In order to relieve these issues, we propose a novel open set recognition framework for NDDs screening and detection, which is the first application of open set recognition in this field. It combines auto encoder and adversarial reciprocal points open set recognition to accurately identify known classes as well as recognize classes never encountered. And considering the strong similarities bet
    
[^30]: Stone Needle: 一个通用的面向医疗保健的多模态大规模模型框架

    Stone Needle: A General Multimodal Large-scale Model Framework towards Healthcare. (arXiv:2306.16034v1 [cs.AI])

    [http://arxiv.org/abs/2306.16034](http://arxiv.org/abs/2306.16034)

    Stone Needle是一个通用的多模态大规模模型框架，专门为医疗保健应用而设计。它集成了各种模态，可以进行全面分析并实现多模态交互。

    

    在医疗保健领域，多模态数据广泛存在，并且需要在诊断决策之前进行全面分析，包括医学图像、临床报告等。然而，当前的大规模人工智能模型主要关注单模态的认知能力，忽视了多模态的整合。因此，我们提出了 Stone Needle，一个专门为医疗保健应用而设计的通用多模态大规模模型框架。Stone Needle作为一个全面的医疗多模态模型基础，集成了文本、图像、视频和音频等各种模态，克服了单模态系统的限制。通过意图分析、医疗基础模型、提示管理器和医学语言模块等框架组件，我们的架构能够在多轮对话中进行多模态交互。我们的方法是一个通用的多模态大规模模型框架，集成了多样化的模态，并允许我们进行定制。

    In healthcare, multimodal data is prevalent and requires to be comprehensively analyzed before diagnostic decisions, including medical images, clinical reports, etc. However, current large-scale artificial intelligence models predominantly focus on single-modal cognitive abilities and neglect the integration of multiple modalities. Therefore, we propose Stone Needle, a general multimodal large-scale model framework tailored explicitly for healthcare applications. Stone Needle serves as a comprehensive medical multimodal model foundation, integrating various modalities such as text, images, videos, and audio to surpass the limitations of single-modal systems. Through the framework components of intent analysis, medical foundation models, prompt manager, and medical language module, our architecture can perform multi-modal interaction in multiple rounds of dialogue. Our method is a general multimodal large-scale model framework, integrating diverse modalities and allowing us to tailor fo
    
[^31]: 基于联邦学习的分布式计算模型集成异构模型和联盟区块链解决时变问题

    A Distributed Computation Model Based on Federated Learning Integrates Heterogeneous models and Consortium Blockchain for Solving Time-Varying Problems. (arXiv:2306.16023v1 [cs.AI])

    [http://arxiv.org/abs/2306.16023](http://arxiv.org/abs/2306.16023)

    本研究提出了一种基于联邦学习和联盟区块链的分布式计算模型，解决了时变问题中异构模型和模型间协作的难题。

    

    针对复杂环境中的时变问题，递归神经网络已经取得了很大的发展，有效地解决了这些问题。然而，由于集中式处理的方式限制，模型性能受到现实中模型和数据的孤立问题等因素的极大影响。因此，分布式人工智能（例如联邦学习）的出现使得模型间的动态聚合成为可能。然而，现有的联邦学习集成过程仍然依赖于服务器，可能给整体模型带来很大的风险。此外，它只允许同质模型之间的协作，并且没有很好的解决方案来处理异构模型之间的交互。因此，我们提出了一种基于联盟区块链网络的分布式计算模型（DCM），以提高整体模型的可信度和异构模型之间的有效协调。此外，我们还提出了一种分布式层级集成（DHI）算法。

    The recurrent neural network has been greatly developed for effectively solving time-varying problems corresponding to complex environments. However, limited by the way of centralized processing, the model performance is greatly affected by factors like the silos problems of the models and data in reality. Therefore, the emergence of distributed artificial intelligence such as federated learning (FL) makes it possible for the dynamic aggregation among models. However, the integration process of FL is still server-dependent, which may cause a great risk to the overall model. Also, it only allows collaboration between homogeneous models, and does not have a good solution for the interaction between heterogeneous models. Therefore, we propose a Distributed Computation Model (DCM) based on the consortium blockchain network to improve the credibility of the overall model and effective coordination among heterogeneous models. In addition, a Distributed Hierarchical Integration (DHI) algorith
    
[^32]: 强化学习中的结构：调查与开放问题

    Structure in Reinforcement Learning: A Survey and Open Problems. (arXiv:2306.16021v1 [cs.LG])

    [http://arxiv.org/abs/2306.16021](http://arxiv.org/abs/2306.16021)

    这项调查研究了强化学习中结构的角色和重要性，并介绍了各个子领域在提高强化学习的性能方面所做的工作。

    

    强化学习（RL）借助深度神经网络（DNN）在函数逼近方面的表达能力，已经在许多应用中取得了相当大的成功。然而，在应对多样且不可预测的动态、嘈杂信号以及庞大的状态和动作空间等各种真实场景时，其实用性仍然有限。这个限制源于诸如数据效率低、泛化能力有限、缺少安全保证和不可解释性等问题。为了克服这些挑战并在这些关键指标上提高性能，一个有前途的途径是将问题的附加结构信息纳入强化学习的学习过程中。强化学习的各个子领域已经提出了许多方法来纳入这样的归纳偏差。我们将这些多样化的方法统一到一个框架下，揭示结构在学习问题中的作用。

    Reinforcement Learning (RL), bolstered by the expressive capabilities of Deep Neural Networks (DNNs) for function approximation, has demonstrated considerable success in numerous applications. However, its practicality in addressing a wide range of real-world scenarios, characterized by diverse and unpredictable dynamics, noisy signals, and large state and action spaces, remains limited. This limitation stems from issues such as poor data efficiency, limited generalization capabilities, a lack of safety guarantees, and the absence of interpretability, among other factors. To overcome these challenges and improve performance across these crucial metrics, one promising avenue is to incorporate additional structural information about the problem into the RL learning process. Various sub-fields of RL have proposed methods for incorporating such inductive biases. We amalgamate these diverse methodologies under a unified framework, shedding light on the role of structure in the learning prob
    
[^33]: BayesFlow: 使用神经网络的摊还贝叶斯工作流

    BayesFlow: Amortized Bayesian Workflows With Neural Networks. (arXiv:2306.16015v1 [cs.LG])

    [http://arxiv.org/abs/2306.16015](http://arxiv.org/abs/2306.16015)

    BayesFlow是一个Python库，提供了使用神经网络进行摊还贝叶斯推断的功能，用户可以在模型仿真上训练定制的神经网络，并将其用于任何后续应用。这种摊还贝叶斯推断能够快速准确地进行推断，并实现了对不可计算后验分布的近似。

    

    现代贝叶斯推断涉及一系列计算技术，用于估计、验证和从概率模型中得出结论，作为数据分析中有原则的工作流的一部分。贝叶斯工作流中的典型问题包括近似不可计算后验分布以适应不同的模型类型，以及通过复杂性和预测性能比较同一过程的竞争模型。本文介绍了Python库BayesFlow，用于基于仿真训练已建立的神经网络架构，用于摊还数据压缩和推断。在BayesFlow中实现的摊还贝叶斯推断使用户能够在模型仿真上训练定制的神经网络，并将这些网络重用于模型的任何后续应用。由于训练好的网络可以几乎即时地执行推断，因此前期的神经网络训练很快就能够摊还。

    Modern Bayesian inference involves a mixture of computational techniques for estimating, validating, and drawing conclusions from probabilistic models as part of principled workflows for data analysis. Typical problems in Bayesian workflows are the approximation of intractable posterior distributions for diverse model types and the comparison of competing models of the same process in terms of their complexity and predictive performance. This manuscript introduces the Python library BayesFlow for simulation-based training of established neural network architectures for amortized data compression and inference. Amortized Bayesian inference, as implemented in BayesFlow, enables users to train custom neural networks on model simulations and re-use these networks for any subsequent application of the models. Since the trained networks can perform inference almost instantaneously, the upfront neural network training is quickly amortized.
    
[^34]: 大语言模型时代的查询理解

    Query Understanding in the Age of Large Language Models. (arXiv:2306.16004v1 [cs.IR])

    [http://arxiv.org/abs/2306.16004](http://arxiv.org/abs/2306.16004)

    在大语言模型时代，我们提出了一种使用大语言模型进行查询重写的框架，旨在通过完全指定机器意图的自然语言来改进意图理解和构建高性能检索系统。这种框架的能够以自然语言呈现、交互和推理机器意图具有深远影响。

    

    随着大语言模型（LLM）的兴起和应用，使用自然语言进行查询、对话和控制搜索和信息检索界面正在迅速普及。在这篇立场论文中，我们描述了一种使用LLM进行交互式查询重写的通用框架。我们的提议旨在为改进和透明化意图理解以及使用LLM构建高性能检索系统开辟新的机会。我们框架的一个关键方面是重写器能够通过自然语言完全指定机器意图，这个机器意图可以在最终检索阶段之前进一步细化、控制和编辑。以自然语言呈现、交互和推理底层的机器意图对透明度、排名性能以及离开传统意图理解中收集监督信号的方式有深远影响。我们详细介绍了这一概念，并支持初步实验证明了其可行性。

    Querying, conversing, and controlling search and information-seeking interfaces using natural language are fast becoming ubiquitous with the rise and adoption of large-language models (LLM). In this position paper, we describe a generic framework for interactive query-rewriting using LLMs. Our proposal aims to unfold new opportunities for improved and transparent intent understanding while building high-performance retrieval systems using LLMs. A key aspect of our framework is the ability of the rewriter to fully specify the machine intent by the search engine in natural language that can be further refined, controlled, and edited before the final retrieval phase. The ability to present, interact, and reason over the underlying machine intent in natural language has profound implications on transparency, ranking performance, and a departure from the traditional way in which supervised signals were collected for understanding intents. We detail the concept, backed by initial experiments
    
[^35]: 用深度学习简化社交媒体信息检索以支持公共卫生研究

    Streamlining Social Media Information Retrieval for Public Health Research with Deep Learning. (arXiv:2306.16001v1 [cs.CL])

    [http://arxiv.org/abs/2306.16001](http://arxiv.org/abs/2306.16001)

    本研究介绍了一个使用深度学习简化社交媒体信息检索的框架，通过识别医学实体、标准化实体和分配UMLS概念，构建了一个用于COVID-19相关推文的症状词典。

    

    社交媒体在流行病监测中的利用已经得到了很好的证实。然而，当使用预定义的词汇表来检索相关语料库时，常常会引入偏见。本研究介绍了一个框架，旨在构建医学俗语和统一医学语言系统（UMLS）概念的广泛字典。该框架由三个模块组成：基于BERT的命名实体识别（NER）模型，用于从社交媒体内容中识别出医学实体；深度学习驱动的标准化模块，用于对提取出的实体进行规范化处理；半监督聚类模块，将最可能的UMLS概念分配给每个规范化实体。我们将该框架应用于从2020年2月1日到2022年4月30日期间与COVID-19相关的推文，生成了一个症状词典（可在https://github.com/ningkko/UMLS_colloquialism/上获取），其中包含9,249个标准化实体，映射到876个UMLS概念和38,175个俚语表达。该框架的演示

    The utilization of social media in epidemic surveillance has been well established. Nonetheless, bias is often introduced when pre-defined lexicons are used to retrieve relevant corpus. This study introduces a framework aimed at curating extensive dictionaries of medical colloquialisms and Unified Medical Language System (UMLS) concepts. The framework comprises three modules: a BERT-based Named Entity Recognition (NER) model that identifies medical entities from social media content, a deep-learning powered normalization module that standardizes the extracted entities, and a semi-supervised clustering module that assigns the most probable UMLS concept to each standardized entity. We applied this framework to COVID-19-related tweets from February 1, 2020, to April 30, 2022, generating a symptom dictionary (available at https://github.com/ningkko/UMLS_colloquialism/) composed of 9,249 standardized entities mapped to 876 UMLS concepts and 38,175 colloquial expressions. This framework demo
    
[^36]: Tensorformer: 高质量点云重建的归一化矩阵注意力变换器

    Tensorformer: Normalized Matrix Attention Transformer for High-quality Point Cloud Reconstruction. (arXiv:2306.15989v1 [cs.GR])

    [http://arxiv.org/abs/2306.15989](http://arxiv.org/abs/2306.15989)

    Tensorformer是一种归一化矩阵注意力变换器，用于高质量的点云重建。它通过矩阵注意力实现了逐点和逐通道的消息传递，提供了更好的局部几何建模能力，并在两个数据集上取得了最先进的结果。

    

    在计算机图形学界，从原始点云进行表面重建的研究已经进行了几十年，这在现今的建模和渲染应用中需求非常高。传统的解决方案，如Poisson表面重建，需要额外的点法线输入以产生合理的结果。现代基于变换器的方法可以在没有法线的情况下工作，但由于离散点的局部融合编码性能有限，结果较为粗糙。我们引入了一种新颖的归一化矩阵注意力变换器（Tensorformer）来进行高质量的重建。所提出的矩阵注意力允许同时进行逐点和逐通道的消息传递，而之前的向量注意力在不同通道之间丢失了相邻点的信息。它在特征学习中带来更多自由度，从而更好地建模局部几何结构。我们的方法在两个常用数据集ShapeNetCore和ABC上达到了最先进的水平，并且

    Surface reconstruction from raw point clouds has been studied for decades in the computer graphics community, which is highly demanded by modeling and rendering applications nowadays. Classic solutions, such as Poisson surface reconstruction, require point normals as extra input to perform reasonable results. Modern transformer-based methods can work without normals, while the results are less fine-grained due to limited encoding performance in local fusion from discrete points. We introduce a novel normalized matrix attention transformer (Tensorformer) to perform high-quality reconstruction. The proposed matrix attention allows for simultaneous point-wise and channel-wise message passing, while the previous vector attention loses neighbor point information across different channels. It brings more degree of freedom in feature learning and thus facilitates better modeling of local geometries. Our method achieves state-of-the-art on two commonly used datasets, ShapeNetCore and ABC, and 
    
[^37]: 基于维度结构的跨模态学习的知识蒸馏方法

    A Dimensional Structure based Knowledge Distillation Method for Cross-Modal Learning. (arXiv:2306.15977v1 [cs.CV])

    [http://arxiv.org/abs/2306.15977](http://arxiv.org/abs/2306.15977)

    本文通过分析和观察从简单和困难任务中提取的特征，发现了特征可辨别性和维度结构之间的相关性，并提出了一种基于维度结构的跨模态学习的知识蒸馏方法，以提高跨模态学习性能。

    

    由于数据质量的限制，一些重要的视觉任务很难独立完成。引入先前不可用的信息以转移有信息的黑暗知识已成为解决这些困难任务的常用方法。然而，关于为什么转移知识有效的研究还没有广泛探索。为了解决这个问题，在本文中，我们通过分析和观察从简单任务和困难任务中提取的特征，发现了特征可辨别性和维度结构（DS）之间的相关性。在此基础上，我们使用深度通道相关性和中间空间分布来表示DS，并提出了一种新颖的跨模态知识蒸馏（CMKD）方法，以提高监督式跨模态学习（CML）性能。所提出的方法强制输出特征是通道独立的，且中间特征是均匀分布的，从而从困难任务中学习语义不相关的特征，以提高其准确性。

    Due to limitations in data quality, some essential visual tasks are difficult to perform independently. Introducing previously unavailable information to transfer informative dark knowledge has been a common way to solve such hard tasks. However, research on why transferred knowledge works has not been extensively explored. To address this issue, in this paper, we discover the correlation between feature discriminability and dimensional structure (DS) by analyzing and observing features extracted from simple and hard tasks. On this basis, we express DS using deep channel-wise correlation and intermediate spatial distribution, and propose a novel cross-modal knowledge distillation (CMKD) method for better supervised cross-modal learning (CML) performance. The proposed method enforces output features to be channel-wise independent and intermediate ones to be uniformly distributed, thereby learning semantically irrelevant features from the hard task to boost its accuracy. This is especial
    
[^38]: 通过双模态变换器重建血液动力学响应函数

    Reconstructing the Hemodynamic Response Function via a Bimodal Transformer. (arXiv:2306.15971v1 [q-bio.NC])

    [http://arxiv.org/abs/2306.15971](http://arxiv.org/abs/2306.15971)

    本研究首次引入了一种双模态变换器预测模型，通过历史血流和神经活动来推断当前血流，增强了模型的预测能力，并提出了关于血液动力学响应神经活动的假设。

    

    血流与神经活动之间的关系被广泛认可，在fMRI研究中，血流经常被用作神经活动的替代指标。在微观水平上，已经显示神经活动会影响附近血管的血流。本研究首次引入了一种预测模型，直接在明确的神经元群体水平上解决了这个问题。使用清醒小鼠的体内记录，我们使用一种新颖的时空双模态变换器架构，根据历史血流和持续自发神经活动来推断当前的血流。我们的发现表明，结合神经活动明显改善了模型预测血流值的能力。通过分析模型的行为，我们提出了关于血液动力学响应神经活动的尚未深入研究的性质的假设。

    The relationship between blood flow and neuronal activity is widely recognized, with blood flow frequently serving as a surrogate for neuronal activity in fMRI studies. At the microscopic level, neuronal activity has been shown to influence blood flow in nearby blood vessels. This study introduces the first predictive model that addresses this issue directly at the explicit neuronal population level. Using in vivo recordings in awake mice, we employ a novel spatiotemporal bimodal transformer architecture to infer current blood flow based on both historical blood flow and ongoing spontaneous neuronal activity. Our findings indicate that incorporating neuronal activity significantly enhances the model's ability to predict blood flow values. Through analysis of the model's behavior, we propose hypotheses regarding the largely unexplored nature of the hemodynamic response to neuronal activity.
    
[^39]: 可分离的物理信息神经网络

    Separable Physics-Informed Neural Networks. (arXiv:2306.15969v1 [cs.LG])

    [http://arxiv.org/abs/2306.15969](http://arxiv.org/abs/2306.15969)

    这项研究提出了一种可分离的物理信息神经网络（SPINN），通过逐个处理轴来显著减少了多维 PDE 中的网络传播数量，并使用正向模式自动微分降低了计算成本，使得可以在单个普通 GPU 上使用大量的配点。

    

    物理信息神经网络(PINNs)最近已经成为有希望的基于数据的PDE求解器，在各种PDE上显示出令人鼓舞的结果。然而，训练PINNs来解决多维PDE和逼近高度复杂解函数存在根本限制。在这些具有挑战性的PDE上所需的训练点数量(配点)大大增加，但由于昂贵的计算成本和庞大的内存开销，其受到严重限制。为了解决这个问题，我们提出了一种用于PINNs的网络架构和训练算法。所提出的方法，可分离的PINN (SPINN)，在多维PDE中按轴逐个处理，从而显著减少了网络传播的数量，不同于传统PINNs中的逐点处理。我们还提出使用正向模式自动微分来降低计算PDE残差的计算成本，从而在单个普通GPU上可以使用大量的配点(>10^7)。

    Physics-informed neural networks (PINNs) have recently emerged as promising data-driven PDE solvers showing encouraging results on various PDEs. However, there is a fundamental limitation of training PINNs to solve multi-dimensional PDEs and approximate highly complex solution functions. The number of training points (collocation points) required on these challenging PDEs grows substantially, but it is severely limited due to the expensive computational costs and heavy memory overhead. To overcome this issue, we propose a network architecture and training algorithm for PINNs. The proposed method, separable PINN (SPINN), operates on a per-axis basis to significantly reduce the number of network propagations in multi-dimensional PDEs unlike point-wise processing in conventional PINNs. We also propose using forward-mode automatic differentiation to reduce the computational cost of computing PDE residuals, enabling a large number of collocation points (>10^7) on a single commodity GPU. The
    
[^40]: 通过跳过零元素降低卷积层的计算复杂度

    Reduce Computational Complexity for Convolutional Layers by Skipping Zeros. (arXiv:2306.15951v1 [cs.LG])

    [http://arxiv.org/abs/2306.15951](http://arxiv.org/abs/2306.15951)

    本文提出了C-K-S算法，通过修剪滤波器和转换稀疏张量为稠密张量的方式，跳过卷积层中的0元素，从而降低了计算复杂度。实验证明，C-K-S相对于PyTorch具有优势。

    

    深度神经网络依赖并行处理器进行加速。为了为其设计运算符，需要不仅有优化算法以降低复杂度，还需要充分利用硬件资源。卷积层主要包含三种运算符：前向传播的卷积，反向传播的反卷积和膨胀卷积。当执行这些运算时，始终会向张量中添加0元素，导致冗余计算。本文提出了C-K-S算法（ConvV2, KS-deconv, Sk-dilated），以两种方式跳过这些0元素：修剪滤波器以排除填充的0元素；将稀疏张量转换为稠密张量，避免在反卷积和膨胀卷积中插入0元素。与普通卷积相比，反卷积由于其复杂性而难以加速。本文提供了C-K-S的高性能GPU实现，并通过与PyTorch的比较验证了其有效性。根据实验结果，在某些情况下，C-K-S相对于PyTorch具有优势。

    Deep neural networks rely on parallel processors for acceleration. To design operators for them, it requires not only good algorithm to reduce complexity, but also sufficient utilization of hardwares. Convolutional layers mainly contain 3 kinds of operators: convolution in forward propagation, deconvolution and dilated-convolution in backward propagation. When executing these operators, 0s are always added to tensors, causing redundant calculations. This paper gives C-K-S algorithm (ConvV2, KS-deconv, Sk-dilated), which skips these 0s in two ways: trim the filters to exclude padded 0s; transform sparse tensors to dense tensors, to avoid inserted 0s in deconvolution and dilated-convolution. In contrast to regular convolution, deconvolution is hard to accelerate due to its complicacy. This paper provides high-performance GPU implementations of C-K-S, and verifies their effectiveness with comparison to PyTorch. According to the experiments, C-K-S has advantages over PyTorch in certain cas
    
[^41]: 不需要换乘：使用Opti-Mile将最后一公里与公共交通整合在一起

    No Transfers Required: Integrating Last Mile with Public Transit Using Opti-Mile. (arXiv:2306.15943v1 [cs.CY])

    [http://arxiv.org/abs/2306.15943](http://arxiv.org/abs/2306.15943)

    提出了一种名为"Opti-Mile"的新方法，将最后一公里服务与公共交通相结合，使用户无需换乘，解决了公共交通系统中有限可达性和换乘引起的低效率问题。

    

    尽管公共交通具有经济实惠的优点，但由于大部分地区需要换乘，导致不便利。为了解决公共交通系统中有限的可达性和换乘引起的低效率问题，我们提出了一种新的旅行计划方法，即"Opti-Mile"，它将最后一公里服务与公共交通相结合，使用户无需换乘。

    Public transit is a popular mode of transit due to its affordability, despite the inconveniences due to the necessity of transfers required to reach most areas. For example, in the bus and metro network of New Delhi, only 30\% of stops can be directly accessed from any starting point, thus requiring transfers for most commutes. Additionally, last-mile services like rickshaws, tuk-tuks or shuttles are commonly used as feeders to the nearest public transit access points, which further adds to the complexity and inefficiency of a journey. Ultimately, users often face a tradeoff between coverage and transfers to reach their destination, regardless of the mode of transit or the use of last-mile services. To address the problem of limited accessibility and inefficiency due to transfers in public transit systems, we propose ``opti-mile," a novel trip planning approach that combines last-mile services with public transit such that no transfers are required. Opti-mile allows users to customise 
    
[^42]: 基于空间信息的增强型神经波束形成器用于目标语音提取

    Enhanced Neural Beamformer with Spatial Information for Target Speech Extraction. (arXiv:2306.15942v1 [cs.SD])

    [http://arxiv.org/abs/2306.15942](http://arxiv.org/abs/2306.15942)

    本研究提出了一种利用空间信息增强神经波束形成器性能的目标语音提取网络。该网络采用了UNet-TCN结构建模输入特征，并引入了多头交叉注意力机制，有效提升了神经波束形成器对空间信息的感知能力。

    

    最近，基于深度学习的波束形成算法在目标语音提取任务中展示出了良好的性能。然而，大多数系统并没有充分利用空间信息。本文提出了一种利用空间信息来增强神经波束形成器性能的目标语音提取网络。为了实现这一目标，我们首先使用UNet-TCN结构来建模输入特征，并通过避免其他模型中的直接降维造成的信息损失来提高语音预分离模块的估计准确性。此外，我们引入了一种多头交叉注意力机制，通过充分利用阵列接收到的空间信息，增强了神经波束形成器对空间信息的感知能力。实验结果表明，我们的方法将更合理的目标掩码估计网络和基于空间信息的交叉注意力机制引入神经波束形成器中，有效地改善了目标语音提取的性能。

    Recently, deep learning-based beamforming algorithms have shown promising performance in target speech extraction tasks. However, most systems do not fully utilize spatial information. In this paper, we propose a target speech extraction network that utilizes spatial information to enhance the performance of neural beamformer. To achieve this, we first use the UNet-TCN structure to model input features and improve the estimation accuracy of the speech pre-separation module by avoiding information loss caused by direct dimensionality reduction in other models. Furthermore, we introduce a multi-head cross-attention mechanism that enhances the neural beamformer's perception of spatial information by making full use of the spatial information received by the array. Experimental results demonstrate that our approach, which incorporates a more reasonable target mask estimation network and a spatial information-based cross-attention mechanism into the neural beamformer, effectively improves s
    
[^43]: 可解释的变分自编码器学习概念在手机网络中的异常检测

    Interpretable Anomaly Detection in Cellular Networks by Learning Concepts in Variational Autoencoders. (arXiv:2306.15938v1 [cs.LG])

    [http://arxiv.org/abs/2306.15938](http://arxiv.org/abs/2306.15938)

    本文提出了一种利用变分自编码器学习概念在手机网络中解释异常检测的方法，通过重构损失和Z分数来检测异常，并通过K-means算法增强表示学习，实现了异常的可解释性。该框架为手机网络中的异常检测提供了更快且自主的解决方案，并展示了深度学习算法处理大数据的潜力。

    

    本文以可解释的方式解决了手机网络中的异常检测挑战，并提出了一种利用变分自编码器(VAEs)学习每个关键性能指标(KPI)的潜在空间的可解释表示的新方法。这使得可以基于重构损失和Z分数来检测异常。我们通过使用K-means算法增强表示学习，通过附加信息中心点(c)确保异常的可解释性。通过分析特定KPI的潜在维度中的模式，我们评估了模型的性能，并展示了其可解释性和异常。该提议的框架为在手机网络中检测异常提供了更快且自主的解决方案，并展示了基于深度学习的算法处理大数据的潜力。

    This paper addresses the challenges of detecting anomalies in cellular networks in an interpretable way and proposes a new approach using variational autoencoders (VAEs) that learn interpretable representations of the latent space for each Key Performance Indicator (KPI) in the dataset. This enables the detection of anomalies based on reconstruction loss and Z-scores. We ensure the interpretability of the anomalies via additional information centroids (c) using the K-means algorithm to enhance representation learning. We evaluate the performance of the model by analyzing patterns in the latent dimension for specific KPIs and thereby demonstrate the interpretability and anomalies. The proposed framework offers a faster and autonomous solution for detecting anomalies in cellular networks and showcases the potential of deep learning-based algorithms in handling big data.
    
[^44]: 对于模型为基础的适应性的好奇回放

    Curious Replay for Model-based Adaptation. (arXiv:2306.15934v1 [cs.LG])

    [http://arxiv.org/abs/2306.15934](http://arxiv.org/abs/2306.15934)

    好奇回放是一种针对模型为基础的代理的优先经验回放方法，通过使用好奇度基础的优先信号，它提高了探索性能，并在Crafter基准测试中取得了更好的成绩。

    

    代理必须能够在环境改变时快速适应。我们发现现有的基于模型的强化学习代理在这方面做得不好，部分原因是它们如何利用过去的经验来训练其世界模型。在这里，我们提出了一种称为好奇回放的方法，它是针对基于模型的代理的一种优先经验回放方法，通过使用好奇度基础的优先信号。使用好奇回放的代理在受到动物行为启发的探索范式和Crafter基准测试中表现出改进的性能。带有好奇回放的DreamerV3在Crafter上超越了最先进的性能，实现了19.4的平均分数，大大改善了之前DreamerV3使用均匀回放时的最高分数14.5，并且在Deepmind Control Suite上的性能也相似。好奇回放的代码可以在https://github.com/AutonomousAgentsLab/curiousreplay上找到。

    Agents must be able to adapt quickly as an environment changes. We find that existing model-based reinforcement learning agents are unable to do this well, in part because of how they use past experiences to train their world model. Here, we present Curious Replay -- a form of prioritized experience replay tailored to model-based agents through use of a curiosity-based priority signal. Agents using Curious Replay exhibit improved performance in an exploration paradigm inspired by animal behavior and on the Crafter benchmark. DreamerV3 with Curious Replay surpasses state-of-the-art performance on Crafter, achieving a mean score of 19.4 that substantially improves on the previous high score of 14.5 by DreamerV3 with uniform replay, while also maintaining similar performance on the Deepmind Control Suite. Code for Curious Replay is available at https://github.com/AutonomousAgentsLab/curiousreplay
    
[^45]: 通过验证和纠正提示进行数据生成文本生成

    You Can Generate It Again: Data-to-text Generation with Verification and Correction Prompting. (arXiv:2306.15933v1 [cs.CL])

    [http://arxiv.org/abs/2306.15933](http://arxiv.org/abs/2306.15933)

    本文提出了一种多步骤生成、验证和纠正的数据生成文本方法，通过专门的错误指示提示来改善输出质量。

    

    尽管现有模型取得了显著进展，从结构化数据输入生成文本描述（称为数据生成文本）仍然是一个具有挑战性的任务。在本文中，我们提出了一种新的方法，通过引入包括生成、验证和纠正阶段的多步骤过程，超越了传统的一次性生成方法。我们的方法，VCP（验证和纠正提示），从模型生成初始输出开始。然后，我们继续验证所生成文本的不同方面的正确性。验证步骤的观察结果被转化为专门的错误指示提示，该提示指示模型在重新生成输出时考虑已识别的错误。为了增强模型的纠正能力，我们开发了一个经过精心设计的培训过程。该过程使模型能够融入错误指示提示的反馈，从而改善输出生成。

    Despite significant advancements in existing models, generating text descriptions from structured data input, known as data-to-text generation, remains a challenging task. In this paper, we propose a novel approach that goes beyond traditional one-shot generation methods by introducing a multi-step process consisting of generation, verification, and correction stages. Our approach, VCP(Verification and Correction Prompting), begins with the model generating an initial output. We then proceed to verify the correctness of different aspects of the generated text. The observations from the verification step are converted into a specialized error-indication prompt, which instructs the model to regenerate the output while considering the identified errors. To enhance the model's correction ability, we have developed a carefully designed training procedure. This procedure enables the model to incorporate feedback from the error-indication prompt, resulting in improved output generation. Throu
    
[^46]: 大多数语言模型也可以成为诗人：一个AI写作助手和有限文本生成工具

    Most Language Models can be Poets too: An AI Writing Assistant and Constrained Text Generation Studio. (arXiv:2306.15926v1 [cs.CL])

    [http://arxiv.org/abs/2306.15926](http://arxiv.org/abs/2306.15926)

    这项研究展示了如何通过在语言模型中应用过滤函数来生成有限约束文本，并提出了一个AI写作助手工具，可以根据用户的需求生成带有各种约束条件的文本。

    

    尽管有关有限自然语言生成领域的快速进展，但对已被词汇、语义或音韵约束的语言模型的潜力研究时间很少。我们发现，大多数语言模型即使在显著约束下也能生成引人入胜的文本。我们提出了一种简单而普适的技术，通过在生成文本单元之前组合应用过滤函数到语言模型的词汇，来修改语言模型的输出。这种方法是即插即用的，不需要对模型进行修改。为展示这种技术的价值，我们介绍了一个易于使用的AI写作助手，名为有限文本生成工具（CTGS）。CTGS允许用户生成或选择具有各种约束条件的文本，例如禁止某个字母，强制生成的单词具有一定的音节数，或强制生成与给定上下文相关的单词等。

    Despite rapid advancement in the field of Constrained Natural Language Generation, little time has been spent on exploring the potential of language models which have had their vocabularies lexically, semantically, and/or phonetically constrained. We find that most language models generate compelling text even under significant constraints. We present a simple and universally applicable technique for modifying the output of a language model by compositionally applying filter functions to the language models vocabulary before a unit of text is generated. This approach is plug-and-play and requires no modification to the model. To showcase the value of this technique, we present an easy to use AI writing assistant called Constrained Text Generation Studio (CTGS). CTGS allows users to generate or choose from text with any combination of a wide variety of constraints, such as banning a particular letter, forcing the generated words to have a certain number of syllables, and/or forcing the 
    
[^47]: 精细化的三维物体识别：一种方法和实验

    Fine-grained 3D object recognition: an approach and experiments. (arXiv:2306.15919v1 [cs.CV])

    [http://arxiv.org/abs/2306.15919](http://arxiv.org/abs/2306.15919)

    本文提出了一种离线和在线的三维物体识别方法，通过实现一个系统来对物体进行分类并评估其识别性能。

    

    三维物体识别技术正在成为自动驾驶等先进技术中的核心技术。目前有两种三维物体识别方法：（i）基于手工设计的方法，如全局正交物体描述符（GOOD）；（ii）基于深度学习的方法，如MobileNet和VGG。然而，在一个开放性的领域中，需要知道哪种方法在时间推移和已知类别数量增加的情况下效果更好，并且系统需要用少量的训练样本学习新的物体类别。本文首先实现了一个离线的三维物体识别系统，将物体视图作为输入并生成分类标签作为输出。在离线阶段，使用基于实例的学习（IBL）来形成一个新的类别，并使用K折交叉验证来评估获得的物体识别性能。然后我们在在线模式下测试了所提出的方法，通过整合...

    Three-dimensional (3D) object recognition technology is being used as a core technology in advanced technologies such as autonomous driving of automobiles. There are two sets of approaches for 3D object recognition: (i) hand-crafted approaches like Global Orthographic Object Descriptor (GOOD), and (ii) deep learning-based approaches such as MobileNet and VGG. However, it is needed to know which of these approaches works better in an open-ended domain where the number of known categories increases over time, and the system should learn about new object categories using few training examples. In this paper, we first implemented an offline 3D object recognition system that takes an object view as input and generates category labels as output. In the offline stage, instance-based learning (IBL) is used to form a new category and we use K-fold cross-validation to evaluate the obtained object recognition performance. We then test the proposed approach in an online fashion by integrating the 
    
[^48]: DCT: 大离散动作空间强化学习的双通道动作嵌入训练

    DCT: Dual Channel Training of Action Embeddings for Reinforcement Learning with Large Discrete Action Spaces. (arXiv:2306.15913v1 [cs.LG])

    [http://arxiv.org/abs/2306.15913](http://arxiv.org/abs/2306.15913)

    本文提出了一个双通道动作嵌入训练的框架，能够在大离散动作空间中学习稳健策略，并成功应用在2D迷宫环境和真实世界电子商务任务中。

    

    在面临维度灾难的嘈杂环境中，学习稳健策略并广义化大离散动作空间是智能系统面临的一个挑战。本文提出了一种新颖的框架，能够高效地学习动作嵌入，同时实现对原始动作的重构以及对未来状态的预测。我们使用编码器-解码器架构进行动作嵌入，并通过双通道损失来平衡动作重构和状态预测精度。我们将训练好的解码器与标准强化学习算法结合使用，以在嵌入空间中生成动作。实验结果表明，我们的架构在一个具有4000多个离散噪声动作的2D迷宫环境和使用真实世界电子商务交易数据的产品推荐任务中能够胜过两个竞争基线模型。

    The ability to learn robust policies while generalizing over large discrete action spaces is an open challenge for intelligent systems, especially in noisy environments that face the curse of dimensionality. In this paper, we present a novel framework to efficiently learn action embeddings that simultaneously allow us to reconstruct the original action as well as to predict the expected future state. We describe an encoder-decoder architecture for action embeddings with a dual channel loss that balances between action reconstruction and state prediction accuracy. We use the trained decoder in conjunction with a standard reinforcement learning algorithm that produces actions in the embedding space. Our architecture is able to outperform two competitive baselines in two diverse environments: a 2D maze environment with more than 4000 discrete noisy actions, and a product recommendation task that uses real-world e-commerce transaction data. Empirical results show that the model results in 
    
[^49]: RL$^3$:通过RL内部的RL$^2$提升元强化学习方法

    RL$^3$: Boosting Meta Reinforcement Learning via RL inside RL$^2$. (arXiv:2306.15909v1 [cs.LG])

    [http://arxiv.org/abs/2306.15909](http://arxiv.org/abs/2306.15909)

    RL$^3$是一种原则性混合方法，通过将传统强化学习学到的任务特定动作值作为元强化学习神经网络的输入，提高了元强化学习的性能。

    

    元强化学习（meta-RL）方法，如RL$^2$，已经成为学习针对给定任务分布的数据高效的强化学习算法的有希望的方法。然而，这些强化学习算法在长期任务和超出分布任务方面存在困难，因为它们依赖于递归神经网络来处理经验序列，而不是将它们总结为一般的强化学习组件，例如价值函数。此外，即使是transformers在训练和推理成本变得禁止之前也对它们可以有效推理的历史长度有实际限制。相比之下，传统的强化学习算法在数据效率方面不足，因为它们没有利用领域知识，但随着更多数据的可用性，它们会收敛到最优策略。在本文中，我们提出了RL$^3$，一种组合了传统强化学习和元强化学习的原则性混合方法，通过将通过传统强化学习学习到的特定任务动作值作为元强化学习神经网络的一个输入。

    Meta reinforcement learning (meta-RL) methods such as RL$^2$ have emerged as promising approaches for learning data-efficient RL algorithms tailored to a given task distribution. However, these RL algorithms struggle with long-horizon tasks and out-of-distribution tasks since they rely on recurrent neural networks to process the sequence of experiences instead of summarizing them into general RL components such as value functions. Moreover, even transformers have a practical limit to the length of histories they can efficiently reason about before training and inference costs become prohibitive. In contrast, traditional RL algorithms are data-inefficient since they do not leverage domain knowledge, but they do converge to an optimal policy as more data becomes available. In this paper, we propose RL$^3$, a principled hybrid approach that combines traditional RL and meta-RL by incorporating task-specific action-values learned through traditional RL as an input to the meta-RL neural netw
    
[^50]: 多智能体交互强化学习在足球全场比赛中的应用：多种AI的互动训练以提高实力(arXiv:2306.15903v1 [cs.AI])

    Diversity is Strength: Mastering Football Full Game with Interactive Reinforcement Learning of Multiple AIs. (arXiv:2306.15903v1 [cs.AI])

    [http://arxiv.org/abs/2306.15903](http://arxiv.org/abs/2306.15903)

    多样性即实力（DIS）是一种新颖的DRL训练框架，通过同时训练多种类型的人工智能，并利用互联的历史模型池结构增强其策略多样性和能力。该方法在不使用人类数据的情况下提供了多样化、可推广和强大的人工智能策略，并在AI竞赛中表现出色。

    

    在多智能体环境中训练具有强大和丰富策略的人工智能仍然是深度强化学习（DRL）中的一个重要研究领域。人工智能的实力与其策略的多样性密切相关，而这种关系可以指导我们训练具有强大和丰富策略的人工智能。为了证明这一点，我们提出了多样性即实力（DIS），这是一种新颖的DRL训练框架，可以同时训练多种类型的人工智能。这些人工智能通过一个互联的历史模型池结构相互连接，增强了它们的能力和策略多样性。我们还设计了一种模型评估和筛选方案，以选择最佳模型来丰富模型池并得到最终的人工智能。所提出的训练方法提供了多样化、可推广和强大的人工智能策略，而无需使用人类数据。我们在基于谷歌研究足球（GRF）的人工智能竞赛中测试了我们的方法，并赢得了5v5和11v11赛道。该方法使得GRF人工智能可以在5

    Training AI with strong and rich strategies in multi-agent environments remains an important research topic in Deep Reinforcement Learning (DRL). The AI's strength is closely related to its diversity of strategies, and this relationship can guide us to train AI with both strong and rich strategies. To prove this point, we propose Diversity is Strength (DIS), a novel DRL training framework that can simultaneously train multiple kinds of AIs. These AIs are linked through an interconnected history model pool structure, which enhances their capabilities and strategy diversities. We also design a model evaluation and screening scheme to select the best models to enrich the model pool and obtain the final AI. The proposed training method provides diverse, generalizable, and strong AI strategies without using human data. We tested our method in an AI competition based on Google Research Football (GRF) and won the 5v5 and 11v11 tracks. The method enables a GRF AI to have a high level on both 5
    
[^51]: 个别和结构化图信息瓶颈对于域外通用化的重要性

    Individual and Structural Graph Information Bottlenecks for Out-of-Distribution Generalization. (arXiv:2306.15902v1 [cs.LG])

    [http://arxiv.org/abs/2306.15902](http://arxiv.org/abs/2306.15902)

    这项工作提出了一种统一框架，个别和结构化图信息瓶颈（IS-GIB），用于解决域外图像通用化中的问题，通过丢弃虚假特征和利用结构关联来提高性能。

    

    域外图像通用化对于许多实际应用来说都是至关重要的。现有方法忽视了丢弃与标签无关的输入中的虚假或噪声特征。此外，它们主要进行实例级别的类不变图学习，并未充分利用图实例之间的结构化类别关系。在本研究中，我们致力于在一个统一的框架中解决这些问题，称为个别和结构化图信息瓶颈（IS-GIB）。为了消除由分布偏移引起的类别虚假特征，我们提出个别图信息瓶颈（I-GIB），通过最小化输入图与其嵌入之间的互信息来丢弃不相关信息。为了利用结构内部和跨域之间的关联，我们提出了结构化图信息瓶颈（S-GIB）。特别是对于一批具有多个域的图，S-GIB首先计算成对的输入-输入、嵌入-嵌入等。

    Out-of-distribution (OOD) graph generalization are critical for many real-world applications. Existing methods neglect to discard spurious or noisy features of inputs, which are irrelevant to the label. Besides, they mainly conduct instance-level class-invariant graph learning and fail to utilize the structural class relationships between graph instances. In this work, we endeavor to address these issues in a unified framework, dubbed Individual and Structural Graph Information Bottlenecks (IS-GIB). To remove class spurious feature caused by distribution shifts, we propose Individual Graph Information Bottleneck (I-GIB) which discards irrelevant information by minimizing the mutual information between the input graph and its embeddings. To leverage the structural intra- and inter-domain correlations, we propose Structural Graph Information Bottleneck (S-GIB). Specifically for a batch of graphs with multiple domains, S-GIB first computes the pair-wise input-input, embedding-embedding, a
    
[^52]: 大型语言模型作为属性化训练数据生成器：多样性和偏差的故事

    Large Language Model as Attributed Training Data Generator: A Tale of Diversity and Bias. (arXiv:2306.15895v1 [cs.CL])

    [http://arxiv.org/abs/2306.15895](http://arxiv.org/abs/2306.15895)

    本论文研究了大型语言模型作为属性化训练数据生成器的应用。通过使用具有多样性属性的提示，我们能够生成多样化且归因的数据。研究表明，在高基数和多样领域的数据集中，使用属性化提示对生成模型性能有积极影响。此外，论文还展示了关于偏差、多样性和效率的全面实证研究结果，并得出了三个关键观察：系统性偏差存在于生成数据中，多样性和效率之间存在权衡，属性化训练数据生成可以改善模型性能。

    

    近期大型语言模型(LLMs)被广泛应用于各种自然语言处理(NLP)任务的训练数据生成。尽管之前的研究探索了使用生成数据进行模型训练的不同方法，但它们通常依赖于简单的类别条件提示，这可能限制了生成数据的多样性，并且继承了LLM的系统性偏差。因此，我们研究了使用具有多样属性的提示(例如指定长度和风格等属性)进行训练数据生成，这有潜力产生多样和归因的生成数据。我们的研究关注具有高基数和多样领域的数据集，在这方面，我们证明了属性化提示在生成模型性能方面优于简单的类别条件提示。此外，我们还展示了一项包括偏差、多样性和效率等关键方面的全面实证研究，并强调了三个关键观察：首先，系统性偏差在生成数据中存在；其次，多样性和效率之间存在权衡；最后，进行属性化训练数据生成可以改善模型性能。

    Large language models (LLMs) have been recently leveraged as training data generators for various natural language processing (NLP) tasks. While previous research has explored different approaches to training models using generated data, they generally rely on simple class-conditional prompts, which may limit the diversity of the generated data and inherit systematic biases of LLM. Thus, we investigate training data generation with diversely attributed prompts (e.g., specifying attributes like length and style), which have the potential to yield diverse and attributed generated data. Our investigation focuses on datasets with high cardinality and diverse domains, wherein we demonstrate that attributed prompts outperform simple class-conditional prompts in terms of the resulting model's performance. Additionally, we present a comprehensive empirical study on data generation encompassing vital aspects like bias, diversity, and efficiency, and highlight three key observations: firstly, sy
    
[^53]: 超越炒作：评估GPT3.5在性能、可信度和临床适用性方面的表现

    Beyond the Hype: Assessing the Performance, Trustworthiness, and Clinical Suitability of GPT3.5. (arXiv:2306.15887v1 [cs.AI])

    [http://arxiv.org/abs/2306.15887](http://arxiv.org/abs/2306.15887)

    该研究评估了GPT3.5模型在医学图像协议分配方面的性能和可信度，发现其在性能上不如BERT和放射科医师，但在解释决策能力、检测相关词标识和模型校准方面优于BERT。

    

    在医疗保健领域中，大型语言模型（LLM）的使用越来越受欢迎，但它们在临床环境中的实用性和安全性尚未得到全面评估。在高风险的环境中，如医疗环境下，对LLM的信任和安全性是关键问题。为了解决这些问题，我们提出了一种评估GPT3.5模型在医学图像协议分配方面性能和可信度的方法。我们将其与经过微调的BERT模型和放射科医师进行比较。此外，我们还请一位放射科医师审查GPT3.5的输出，评估其决策过程。我们的评估数据集包括横跨整个头部的11个成像协议类别中的4,700个医师输入。我们的研究结果表明，GPT3.5的性能在BERT和放射科医师之后。然而，GPT3.5在解释其决策能力、检测相关词标识和模型校准方面优于BERT。此外，通过分析GPT3.5错误分类的解释，我们重新评估了其在性能方面的表现。

    The use of large language models (LLMs) in healthcare is gaining popularity, but their practicality and safety in clinical settings have not been thoroughly assessed. In high-stakes environments like medical settings, trust and safety are critical issues for LLMs. To address these concerns, we present an approach to evaluate the performance and trustworthiness of a GPT3.5 model for medical image protocol assignment. We compare it with a fine-tuned BERT model and a radiologist. In addition, we have a radiologist review the GPT3.5 output to evaluate its decision-making process. Our evaluation dataset consists of 4,700 physician entries across 11 imaging protocol classes spanning the entire head. Our findings suggest that the GPT3.5 performance falls behind BERT and a radiologist. However, GPT3.5 outperforms BERT in its ability to explain its decision, detect relevant word indicators, and model calibration. Furthermore, by analyzing the explanations of GPT3.5 for misclassifications, we re
    
[^54]: 面向开放词汇学习的调研

    Towards Open Vocabulary Learning: A Survey. (arXiv:2306.15880v1 [cs.CV])

    [http://arxiv.org/abs/2306.15880](http://arxiv.org/abs/2306.15880)

    该论文调研了在视觉场景理解领域的开放词汇学习，在与零样本学习和开放集识别等相关概念的比较中，总结和分析了该领域的最新发展。

    

    在视觉场景理解领域，深度神经网络在分割、跟踪和检测等各种核心任务上取得了令人瞩目的进展。然而，大多数方法基于封闭集的假设，即模型只能识别训练集中已定义的类别。最近，由于视觉语言预训练的快速进展，提出了开放词汇设置。这些新方法旨在定位和识别超出注释标签空间的类别。与弱监督和零样本设置相比，开放词汇方法更加通用、实用和有效。本文对开放词汇学习进行了全面的回顾，总结和分析了近期在该领域的发展。特别是，我们首先将其与零样本学习、开放集识别和超出分布检测等相关概念进行了比较。然后，在分割任务的几个紧密相关的任务中进行了回顾。

    In the field of visual scene understanding, deep neural networks have made impressive advancements in various core tasks like segmentation, tracking, and detection. However, most approaches operate on the close-set assumption, meaning that the model can only identify pre-defined categories that are present in the training set. Recently, open vocabulary settings were proposed due to the rapid progress of vision language pre-training. These new approaches seek to locate and recognize categories beyond the annotated label space. The open vocabulary approach is more general, practical, and effective compared to weakly supervised and zero-shot settings. This paper provides a thorough review of open vocabulary learning, summarizing and analyzing recent developments in the field. In particular, we begin by comparing it to related concepts such as zero-shot learning, open-set recognition, and out-of-distribution detection. Then, we review several closely related tasks in the case of segmentati
    
[^55]: 用于手中物体自感知6D姿态估计的分层图神经网络

    Hierarchical Graph Neural Networks for Proprioceptive 6D Pose Estimation of In-hand Objects. (arXiv:2306.15858v1 [cs.RO])

    [http://arxiv.org/abs/2306.15858](http://arxiv.org/abs/2306.15858)

    本文提出了一种分层图神经网络架构，用于结合多模态数据，实现几何信息有根据的6D物体姿态估计。

    

    机器人操作，特别是手中物体的操作，通常需要准确估计物体的6D姿态。为了提高估计姿态的准确性，目前6D物体姿态估计的最先进方法使用来自一个或多个模态的观测数据，例如RGB图像、深度和触觉读数。然而，现有方法对这些模态捕获的物体的基本几何结构的利用有限，从而增加了对视觉特征的依赖性。这导致当面对缺乏这种视觉特征的物体或者视觉特征被遮挡时，性能较差。此外，现有方法也没有充分利用手指位置中嵌入的感觉信息。为了解决这些限制，本文介绍了一种用于结合多模态（视觉和触觉）数据的分层图神经网络架构，实现几何信息有根据的6D物体姿态估计。

    Robotic manipulation, in particular in-hand object manipulation, often requires an accurate estimate of the object's 6D pose. To improve the accuracy of the estimated pose, state-of-the-art approaches in 6D object pose estimation use observational data from one or more modalities, e.g., RGB images, depth, and tactile readings. However, existing approaches make limited use of the underlying geometric structure of the object captured by these modalities, thereby, increasing their reliance on visual features. This results in poor performance when presented with objects that lack such visual features or when visual features are simply occluded. Furthermore, current approaches do not take advantage of the proprioceptive information embedded in the position of the fingers. To address these limitations, in this paper: (1) we introduce a hierarchical graph neural network architecture for combining multimodal (vision and touch) data that allows for a geometrically informed 6D object pose estima
    
[^56]: 从人际交互面临场景学习看符号的出现：语义知识的组合性出现机制的研究

    Symbol emergence as interpersonal cross-situational learning: the emergence of lexical knowledge with combinatoriality. (arXiv:2306.15837v1 [cs.CL])

    [http://arxiv.org/abs/2306.15837](http://arxiv.org/abs/2306.15837)

    本研究提出了一个计算模型，通过交互学习和命名游戏，实现了代理之间通过词序列交流的方式，从而促进了具有组合性的语义知识的出现。

    

    本文介绍了一个计算模型，通过Metropolis-Hastings命名游戏和交互学习，使代理在符号出现系统中能够通过组合性获得词汇知识。许多计算模型已被提出用于研究紧急交流中的组合性和认知与发展机器人中的符号出现。然而，现有模型没有充分解决基于感知运动信息的类别形成和通过单一综合模型中的词序列交流的符号交流。我们提出的模型通过使用多模态感知运动信息进行类别形成，并通过代理间的词序列交流实现符号的出现，从而促进了具有组合性的语义知识的出现。此外，该模型使得代理能够通过结合与词相关的信息预测未观察到的情况的感知运动信息。

    We present a computational model for a symbol emergence system that enables the emergence of lexical knowledge with combinatoriality among agents through a Metropolis-Hastings naming game and cross-situational learning. Many computational models have been proposed to investigate combinatoriality in emergent communication and symbol emergence in cognitive and developmental robotics. However, existing models do not sufficiently address category formation based on sensory-motor information and semiotic communication through the exchange of word sequences within a single integrated model. Our proposed model facilitates the emergence of lexical knowledge with combinatoriality by performing category formation using multimodal sensory-motor information and enabling semiotic communication through the exchange of word sequences among agents in a unified model. Furthermore, the model enables an agent to predict sensory-motor information for unobserved situations by combining words associated wit
    
[^57]: 在基于得分的扩散模型中缓解颜色偏移

    Easing Color Shifts in Score-Based Diffusion Models. (arXiv:2306.15832v1 [cs.LG])

    [http://arxiv.org/abs/2306.15832](http://arxiv.org/abs/2306.15832)

    本文提出了在基于得分的扩散模型中缓解颜色偏移的计算廉价解决方案，并引入了一个简单的非线性绕过连接来改善生成图像的空间均值。

    

    得分模型生成的图像可能会因空间均值的错误而出现颜色偏移，这种效应在较大的图像中会越来越明显。本文提出了一种计算廉价的解决方案，以减轻基于得分的扩散模型中的颜色偏移。我们在得分网络中引入了一个简单的非线性绕过连接，用于处理输入的空间均值，并预测得分函数的均值。这种网络架构显著改善了生成图像的空间均值，我们证明了改进与生成图像大小的关系近似独立。因此，我们的解决方案为跨图像尺寸的颜色偏移问题提供了相对廉价的解决方案。最后，我们讨论了在理想化情况下颜色偏移的起源，以推动我们的方法的提出。

    Generated images of score-based models can suffer from errors in their spatial means, an effect, referred to as a color shift, which grows for larger images. This paper introduces a computationally inexpensive solution to mitigate color shifts in score-based diffusion models. We propose a simple nonlinear bypass connection in the score network, designed to process the spatial mean of the input and to predict the mean of the score function. This network architecture substantially improves the resulting spatial means of the generated images, and we show that the improvement is approximately independent of the size of the generated images. As a result, our solution offers a comparatively inexpensive solution for the color shift problem across image sizes. Lastly, we discuss the origin of color shifts in an idealized setting in order to motivate our approach.
    
[^58]: MAT: 对微调中对抗训练的混合策略游戏

    MAT: Mixed-Strategy Game of Adversarial Training in Fine-tuning. (arXiv:2306.15826v1 [cs.CL])

    [http://arxiv.org/abs/2306.15826](http://arxiv.org/abs/2306.15826)

    本论文提出了一种新颖的混合策略对抗训练算法（MAT），通过在细调阶段加入对抗训练，显著提高了模型的泛化能力和鲁棒性，通过采样方法建立了MAT。实验证明，MAT在大规模预训练模型上的性能明显优于其他方法。

    

    细调大规模预训练语言模型已被证明在各种自然语言处理任务中有效。之前的研究表明，在细调阶段加入对抗训练可以显著提高模型的泛化能力和鲁棒性。然而，从博弈论的角度来看，这种对抗训练的应用对应于纯策略游戏，其在策略范围方面存在固有的限制，因此仍有改进空间。为了推动性能边界，我们提出了一种新颖的混合策略对抗训练算法（MAT）。在方法上，我们使用熵镜像下降推导了对抗训练的混合策略游戏的纳什均衡，通过采样方法建立了MAT。为了验证MAT的有效性，我们在BERT和RoBERTa等大规模预训练模型上进行了大量基准实验。MAT在性能上显著优于其他方法。

    Fine-tuning large-scale pre-trained language models has been demonstrated effective for various natural language processing (NLP) tasks. Previous studies have established that incorporating adversarial training during the fine-tuning stage can significantly enhance model generalization and robustness. However, from the perspective of game theory, such utilizations of adversarial training correspond to pure-strategy games, which are inherently limited in terms of the scope of their strategies, thereby still having room for improvement. In order to push the performance boundaries, we propose a novel Mixed-strategy Adversarial Training algorithm (MAT). Methodologically, we derive the Nash equilibrium of a mixed-strategy game for adversarial training using Entropy Mirror Descent to establish MAT by sampling method. To verify the effectiveness of MAT, we conducted extensive benchmark experiments on large-scale pre-trained models, such as BERT and RoBERTa. MAT significantly outperforms the s
    
[^59]: G\"odel-Dummett线性时间逻辑

    G\"odel-Dummett linear temporal logic. (arXiv:2306.15805v1 [cs.LO])

    [http://arxiv.org/abs/2306.15805](http://arxiv.org/abs/2306.15805)

    G\"odel-Dummett线性时间逻辑使用实值和双关系语义定义，并通过拟模型算法解决了证伪的问题。

    

    我们研究了一个版本的线性时间逻辑，其中命题片段是G\"odel-Dummett逻辑（它既是一个超直觉逻辑又是一个t-范数模糊逻辑）。我们使用两种自然语义定义了该逻辑：第一种是实值语义，其中语句在实数单位区间中具有真实度；第二种是"双关系"语义。然后我们证明了这两种语义确实定义了同一种逻辑：在实值语义中成立的语句与在"双关系"语义中成立的语句相同。这个G\"odel时间逻辑在这两种语义中都没有任何形式的有限模型特性：有一些非成立的语句只能在无限模型上被证伪。然而，通过使用拟模型的技术概念，我们证明了每个可以证伪的语句在有限拟模型上都可以证伪，从而给出了判断语句是否成立的算法。

    We investigate a version of linear temporal logic whose propositional fragment is G\"odel-Dummett logic (which is well known both as a superintuitionistic logic and a t-norm fuzzy logic). We define the logic using two natural semantics: first a real-valued semantics, where statements have a degree of truth in the real unit interval and second a `bi-relational' semantics. We then show that these two semantics indeed define one and the same logic: the statements that are valid for the real-valued semantics are the same as those that are valid for the bi-relational semantics. This G\"odel temporal logic does not have any form of the finite model property for these two semantics: there are non-valid statements that can only be falsified on an infinite model. However, by using the technical notion of a quasimodel, we show that every falsifiable statement is falsifiable on a finite quasimodel, yielding an algorithm for deciding if a statement is valid or not. Later, we strengthen this decida
    
[^60]: 关于基于逻辑的解释性和部分指定输入的研究

    On Logic-Based Explainability with Partially Specified Inputs. (arXiv:2306.15803v1 [cs.AI])

    [http://arxiv.org/abs/2306.15803](http://arxiv.org/abs/2306.15803)

    本文研究了在机器学习模型中处理缺失数据和解释预测的问题。通过研究基于逻辑的解释计算，发现大多数计算解释的算法也适用于给定部分指定输入的情况。该研究为处理部分指定输入提供了解决方案，并应用于分类器中。

    

    在机器学习模型的实际部署中，缺失数据是一个常见的挑战。缺失数据通常在训练机器学习模型时进行处理。但是，在决策预测和解释这些预测时，也需要处理缺失数据。缺失数据为部分指定待解释的输入提供了机会。本文研究了在部分指定输入存在的情况下的基于逻辑的解释计算。本文表明，近年来提出的大多数用于计算基于逻辑的解释的算法可以推广到计算给定部分指定输入的解释。一个相关的结果是计算基于逻辑的解释的复杂性保持不变。在受输入约束的逻辑解释性情况下，证明了类似的结果。此外，将计算给定部分指定输入的解释的提出的解决方案应用于分类器中。

    In the practical deployment of machine learning (ML) models, missing data represents a recurring challenge. Missing data is often addressed when training ML models. But missing data also needs to be addressed when deciding predictions and when explaining those predictions. Missing data represents an opportunity to partially specify the inputs of the prediction to be explained. This paper studies the computation of logic-based explanations in the presence of partially specified inputs. The paper shows that most of the algorithms proposed in recent years for computing logic-based explanations can be generalized for computing explanations given the partially specified inputs. One related result is that the complexity of computing logic-based explanations remains unchanged. A similar result is proved in the case of logic-based explainability subject to input constraints. Furthermore, the proposed solution for computing explanations given partially specified inputs is applied to classifiers
    
[^61]: ConKI: 对多模态情感分析的对比性知识注入

    ConKI: Contrastive Knowledge Injection for Multimodal Sentiment Analysis. (arXiv:2306.15796v1 [cs.AI])

    [http://arxiv.org/abs/2306.15796](http://arxiv.org/abs/2306.15796)

    ConKI提出了一种对比性知识注入方案，用于多模态情感分析，通过在通用知识表示的基础上学习每种模态的特定知识表示，以提高多模态情感预测的效果。

    

    多模态情感分析利用多模态信号来检测说话者的情感。之前的方法集中于基于预训练模型获得的通用知识上进行多模态融合和表示学习，忽略了领域特定知识的影响。本文提出了一种对比性知识注入（ConKI）的方案，用于多模态情感分析，通过适配器结构在通用知识表示的基础上学习每种模态的特定知识表示。此外，ConKI还使用层次化对比学习过程，在每个模态内部的知识类型之间、每个样本内部的模态之间、以及样本之间进行对比学习，以促进所提出的表示的有效学习，从而提高多模态情感预测的效果。对三个流行的多模态情感分析基准测试进行的实验表明，ConKI的性能优于先进的多模态情感分析方法。

    Multimodal Sentiment Analysis leverages multimodal signals to detect the sentiment of a speaker. Previous approaches concentrate on performing multimodal fusion and representation learning based on general knowledge obtained from pretrained models, which neglects the effect of domain-specific knowledge. In this paper, we propose Contrastive Knowledge Injection (ConKI) for multimodal sentiment analysis, where specific-knowledge representations for each modality can be learned together with general knowledge representations via knowledge injection based on an adapter architecture. In addition, ConKI uses a hierarchical contrastive learning procedure performed between knowledge types within every single modality, across modalities within each sample, and across samples to facilitate the effective learning of the proposed representations, hence improving multimodal sentiment predictions. The experiments on three popular multimodal sentiment analysis benchmarks show that ConKI outperforms a
    
[^62]: 一个对稳健态步行机器人神经动力学的人群层面分析

    A Population-Level Analysis of Neural Dynamics in Robust Legged Robots. (arXiv:2306.15793v1 [cs.RO])

    [http://arxiv.org/abs/2306.15793](http://arxiv.org/abs/2306.15793)

    本研究通过分析神经动力学在稳健步行机器人中的人群层活动，揭示了控制器的拓扑结构对平衡能力的影响；通过应用神经干扰探究系统的强迫响应，发现循环状态动力学具有结构化和低维特征，并提出了一种新的控制机制的存在证据。

    

    基于循环神经网络的增强学习系统能够完成复杂的运动控制任务，如步态和操作，然而，它们的基本机制仍然难以解释。我们的目标是利用计算神经科学方法来理解稳健机器人步行控制器的人群层活动。我们的研究从分析拓扑结构开始，发现脆弱的控制器具有更多的固定点和不稳定方向，导致在指导下保持平衡时更差。接下来，我们通过在主导人群层活动方向上应用有针对性的神经干扰来分析系统的强迫响应。我们发现循环状态动力学在行走过程中具有结构化和低维特征，与灵长类动物的研究结果相符。此外，当循环状态扰动为零时，脆弱的控制器仍能够行走，这表明一种新的控制机制的存在。

    Recurrent neural network-based reinforcement learning systems are capable of complex motor control tasks such as locomotion and manipulation, however, much of their underlying mechanisms still remain difficult to interpret. Our aim is to leverage computational neuroscience methodologies to understanding the population-level activity of robust robot locomotion controllers. Our investigation begins by analyzing topological structure, discovering that fragile controllers have a higher number of fixed points with unstable directions, resulting in poorer balance when instructed to stand in place. Next, we analyze the forced response of the system by applying targeted neural perturbations along directions of dominant population-level activity. We find evidence that recurrent state dynamics are structured and low-dimensional during walking, which aligns with primate studies. Additionally, when recurrent states are perturbed to zero, fragile agents continue to walk, which is indicative of a st
    
[^63]: 在巴西葡萄牙语的语法错误修正方面评估GPT-3.5和GPT-4

    Evaluating GPT-3.5 and GPT-4 on Grammatical Error Correction for Brazilian Portuguese. (arXiv:2306.15788v1 [cs.CL])

    [http://arxiv.org/abs/2306.15788](http://arxiv.org/abs/2306.15788)

    该研究评估了GPT-3.5和GPT-4在巴西葡萄牙语语法错误修正方面的有效性，结果显示虽然GPT-4的召回率较高，但语言模型倾向于过度修正。

    

    我们调查了GPT-3.5和GPT-4这两个大型语言模型在巴西葡萄牙语的语法错误修正（GEC）工具中的有效性，并将其性能与Microsoft Word和Google Docs进行了比较。我们引入了一个针对巴西葡萄牙语的GEC数据集，包括四个类别：语法、拼写、互联网和快速输入。我们的结果显示，尽管GPT-4的召回率比其他方法高，但语言模型倾向于具有较低的精确度，导致过度修正。这项研究展示了语言模型作为巴西葡萄牙语实际GEC工具的潜力，并鼓励进一步探索语言模型在非英语语言和其他教育环境中的应用。

    We investigate the effectiveness of GPT-3.5 and GPT-4, two large language models, as Grammatical Error Correction (GEC) tools for Brazilian Portuguese and compare their performance against Microsoft Word and Google Docs. We introduce a GEC dataset for Brazilian Portuguese with four categories: Grammar, Spelling, Internet, and Fast typing. Our results show that while GPT-4 has higher recall than other methods, LLMs tend to have lower precision, leading to overcorrection. This study demonstrates the potential of LLMs as practical GEC tools for Brazilian Portuguese and encourages further exploration of LLMs for non-English languages and other educational settings.
    
[^64]: 可解释机器学习中罗生门效应的实证评估

    An Empirical Evaluation of the Rashomon Effect in Explainable Machine Learning. (arXiv:2306.15786v1 [cs.LG])

    [http://arxiv.org/abs/2306.15786](http://arxiv.org/abs/2306.15786)

    通过对不同数据集、模型和指标进行定量评估，我们发现罗生门效应对可解释机器学习具有影响，这为之前的轶事证据提供了实证支持，并展示了科学家和实践者面临的挑战。

    

    罗生门效应描述了以下现象：对于给定的数据集，可能存在许多具有相同良好性能但采用不同解决策略的模型。罗生门效应对可解释机器学习具有影响，特别是对解释的可比性。我们对三种不同比较场景提供了统一视角，并在不同数据集、模型、归因方法和指标上进行了定量评估。我们发现超参数调整起到了一定作用，指标选择也很重要。我们的结果为先前的轶事证据提供了实证支持，并展示了科学家和实践者面临的挑战。

    The Rashomon Effect describes the following phenomenon: for a given dataset there may exist many models with equally good performance but with different solution strategies. The Rashomon Effect has implications for Explainable Machine Learning, especially for the comparability of explanations. We provide a unified view on three different comparison scenarios and conduct a quantitative evaluation across different datasets, models, attribution methods, and metrics. We find that hyperparameter-tuning plays a role and that metric selection matters. Our results provide empirical support for previously anecdotal evidence and exhibit challenges for both scientists and practitioners.
    
[^65]: UTRNet: 印刷文档中高分辨率乌尔都文本识别

    UTRNet: High-Resolution Urdu Text Recognition In Printed Documents. (arXiv:2306.15782v1 [cs.CV])

    [http://arxiv.org/abs/2306.15782](http://arxiv.org/abs/2306.15782)

    本文提出了一种解决印刷乌尔都文本识别挑战的新方法，并引入了大规模实际标记数据集和合成数据集，提供了乌尔都文本行检测的基准数据集，同时开发了一个在线工具，实现了印刷文档中乌尔都OCR的端到端识别。

    

    本文提出了一种新颖方法来解决印刷乌尔都文本识别的挑战，使用高分辨率、多尺度的语义特征提取。我们提出的UTRNet架构，一个混合CNN-RNN模型，在基准数据集上展示了最先进的性能。为了解决以前工作的局限性，这些工作很难推广到乌尔都文本的复杂性和缺乏足够的实际标记数据，我们引入了UTRSet-Real，一个包含超过11,000行的大规模实际标记数据集和UTRSet-Synth，一个与实际世界非常相似的含有20,000行的合成数据集，并对现有的IIITH数据集的基准真实性进行了修正，使其成为未来研究的更可靠的资源。我们还提供了UrduDoc，一种用于扫描文档中乌尔都文本行检测的基准数据集。此外，我们还开发了一种在线工具，通过将UTRNet与文本的端到端乌尔都OCR集成在印刷文档中。

    In this paper, we propose a novel approach to address the challenges of printed Urdu text recognition using high-resolution, multi-scale semantic feature extraction. Our proposed UTRNet architecture, a hybrid CNN-RNN model, demonstrates state-of-the-art performance on benchmark datasets. To address the limitations of previous works, which struggle to generalize to the intricacies of the Urdu script and the lack of sufficient annotated real-world data, we have introduced the UTRSet-Real, a large-scale annotated real-world dataset comprising over 11,000 lines and UTRSet-Synth, a synthetic dataset with 20,000 lines closely resembling real-world and made corrections to the ground truth of the existing IIITH dataset, making it a more reliable resource for future research. We also provide UrduDoc, a benchmark dataset for Urdu text line detection in scanned documents. Additionally, we have developed an online tool for end-to-end Urdu OCR from printed documents by integrating UTRNet with a tex
    
[^66]: xAI-CycleGAN，一种循环一致的生成辅助网络

    xAI-CycleGAN, a Cycle-Consistent Generative Assistive Network. (arXiv:2306.15760v1 [cs.CV])

    [http://arxiv.org/abs/2306.15760](http://arxiv.org/abs/2306.15760)

    本文提出了一种循环一致的生成辅助网络，通过使用可解释性方法和输入上的显著性地图，加速生成模型的收敛速度，相比基线CycleGAN架构有更高的收敛速度。

    

    在使用生成转换模型进行无监督图像转换的领域中，CycleGAN已成为首选架构。这种架构的主要缺点之一是其相对较慢的收敛速度。在本文中，我们使用辨别器驱动的可解释性来加速生成模型的收敛速度，通过使用来自辨别器的显著性地图来遮蔽生成器在反向传播过程中的梯度，基于Nagisetty等人的工作，并引入带有高斯噪声掩蔽的输入上的显著性地图，使用基于Wang M.的Mask CycleGAN的可解释的潜变量。这允许在两个方向上进行可解释性融合，并利用添加噪声的输入上的显著性地图作为基于证据的对照过滤。这种新的架构比基线CycleGAN架构具有更高的收敛速度，同时保持图像质量。

    In the domain of unsupervised image-to-image transformation using generative transformative models, CycleGAN has become the architecture of choice. One of the primary downsides of this architecture is its relatively slow rate of convergence. In this work, we use discriminator-driven explainability to speed up the convergence rate of the generative model by using saliency maps from the discriminator that mask the gradients of the generator during backpropagation, based on the work of Nagisetty et al., and also introducing the saliency map on input, added onto a Gaussian noise mask, by using an interpretable latent variable based on Wang M.'s Mask CycleGAN. This allows for an explainability fusion in both directions, and utilizing the noise-added saliency map on input as evidence-based counterfactual filtering. This new architecture has much higher rate of convergence than a baseline CycleGAN architecture while preserving the image quality.
    
[^67]: 何去何从：深度学习加速的数字硬件视角

    To Spike or Not To Spike: A Digital Hardware Perspective on Deep Learning Acceleration. (arXiv:2306.15749v1 [cs.NE])

    [http://arxiv.org/abs/2306.15749](http://arxiv.org/abs/2306.15749)

    神经形态计算旨在通过仿真脑部操作来提高深度学习模型的效率，但是在SNNs的高效硬件后端设计上仍需进一步研究。

    

    随着深度学习模型规模的增加，它们在涵盖计算机视觉到自然语言处理等领域变得越来越有竞争力；然而，这是以效率为代价的，因为它们需要越来越多的内存和计算能力。生物脑的功耗效率超过任何大规模深度学习（DL）模型；因此，神经形态计算试图模仿脑部操作，例如基于脉冲的信息处理，以提高DL模型的效率。尽管脑部有诸如高效的信息传输、密集的神经元连接和计算与存储的共同位置等优势，但可用的生物基底严重限制了生物大脑的进化。电子硬件没有相同的约束；因此，虽然建模脉冲神经网络（SNNs）可能揭示了一个谜题的一部分，但对于SNNs的高效硬件后端设计需要进一步研究。

    As deep learning models scale, they become increasingly competitive from domains spanning computer vision to natural language processing; however, this happens at the expense of efficiency since they require increasingly more memory and computing power. The power efficiency of the biological brain outperforms the one of any large-scale deep learning (DL) model; thus, neuromorphic computing tries to mimic the brain operations, such as spike-based information processing, to improve the efficiency of DL models. Despite the benefits of the brain, such as efficient information transmission, dense neuronal interconnects, and the co-location of computation and memory, the available biological substrate has severely constrained the evolution of biological brains. Electronic hardware does not have the same constraints; therefore, while modeling spiking neural networks (SNNs) might uncover one piece of the puzzle, the design of efficient hardware backends for SNNs needs further investigation, po
    
[^68]: 基于物理启发的时空图神经网络AI集合用于引力波探测

    Physics-inspired spatiotemporal-graph AI ensemble for gravitational wave detection. (arXiv:2306.15728v1 [astro-ph.IM])

    [http://arxiv.org/abs/2306.15728](http://arxiv.org/abs/2306.15728)

    本论文提出了一种基于物理启发的时空图神经网络AI集合的方法，用于引力波探测。该方法通过混合膨胀卷积神经网络和图神经网络，准确地建模引力波信号的时空关联性，实现了在分布式环境下训练多个AI模型，并在短时间内获得最佳的分类性能。

    

    我们引入了一种新颖的方法来探测引力波，该方法结合了：1）混合膨胀卷积神经网络，以准确地建模引力波信号的短时和长时序列信息；以及2）图神经网络，以捕捉引力波天文观测站之间的空间关联，以一致地描述和识别探测器网络中的信号存在。这些时空图神经网络AI模型经过测试，用于探测近圆非自旋和近圆自旋非进动的二进制黑洞合并产生的引力波信号。对于后一种情况，我们需要一个包含120万个模拟波形的数据集来密集采样这个信号流形。因此，我们通过在阿贡国家实验室龙头超级计算机Polaris上使用256个NVIDIA A100 GPU进行分布式训练，在1.7小时内实现了训练时间到解决方案的减小，并获得了最佳的分类性能。

    We introduce a novel method for gravitational wave detection that combines: 1) hybrid dilated convolution neural networks to accurately model both shortand long-range temporal sequential information of gravitational wave signals; and 2) graph neural networks to capture spatial correlations among gravitational wave observatories to consistently describe and identify the presence of a signal in a detector network. These spatiotemporal-graph AI models are tested for signal detection of gravitational waves emitted by quasi-circular, non-spinning and quasi-circular, spinning, non-precessing binary black hole mergers. For the latter case, we needed a dataset of 1.2 million modeled waveforms to densely sample this signal manifold. Thus, we reduced time-to-solution by training several AI models in the Polaris supercomputer at the Argonne Leadership Supercomputing Facility within 1.7 hours by distributing the training over 256 NVIDIA A100 GPUs, achieving optimal classification performance. Th
    
[^69]: REFLECT:对机器人经历进行总结，以用于失败解释和纠正

    REFLECT: Summarizing Robot Experiences for Failure Explanation and Correction. (arXiv:2306.15724v1 [cs.RO])

    [http://arxiv.org/abs/2306.15724](http://arxiv.org/abs/2306.15724)

    提出了REFLECT框架，可以将机器人多感官数据转化为分层总结，并使用大型语言模型进行失败解释。该框架能够生成有益的失败解释，帮助机器人完成任务。

    

    自动检测和分析失败执行是实现可解释和稳健机器人系统的关键。最近，大型语言模型（LLM）在文本输入上展示了强大的常识推理能力。为了利用LLM的力量进行机器人失败解释，我们提出了一个框架REFLECT，将多感官数据转化为机器人过去经验的分层总结，并使用逐步失败解释算法查询LLM。基于解释，失败纠正规划器生成一个可执行计划，以纠正失败并完成任务。为了系统评估该框架，我们创建了RoboFail数据集，并展示了我们基于LLM的框架能够生成有益的失败解释，从而帮助成功的纠正规划。项目网站：https://roboreflect.github.io/

    The ability to detect and analyze failed executions automatically is crucial for an explainable and robust robotic system. Recently, Large Language Models (LLMs) have demonstrated strong common sense reasoning skills on textual inputs. To leverage the power of LLM for robot failure explanation, we propose a framework REFLECT, which converts multi-sensory data into a hierarchical summary of robot past experiences and queries LLM with a progressive failure explanation algorithm. Conditioned on the explanation, a failure correction planner generates an executable plan for the robot to correct the failure and complete the task. To systematically evaluate the framework, we create the RoboFail dataset and show that our LLM-based framework is able to generate informative failure explanations that assist successful correction planning. Project website: https://roboreflect.github.io/
    
[^70]: 通过全局工作区的半监督多模态表示学习

    Semi-supervised Multimodal Representation Learning through a Global Workspace. (arXiv:2306.15711v1 [cs.AI])

    [http://arxiv.org/abs/2306.15711](http://arxiv.org/abs/2306.15711)

    本研究通过创建一个共享的两个或多个输入模态的表示的神经网络架构，实现了半监督的多模态表示学习。这种架构可以通过循环一致性自我监督训练。这种方法可以减少对大型多模态数据集的依赖，并模仿人类从有限的经验中学习有用的多模态表示的能力。

    

    最近的深度学习模型可以有效地组合不同的输入模态（例如图像和文本）并学习对其潜在表示进行对齐，或者将一个领域的信号转化为另一个领域的信号（例如图像字幕生成或者文本到图像生成）。然而，当前的方法主要依赖于对大型多模态数据集进行暴力监督训练。相比之下，人类（和其他动物）可以通过匹配的跨模态数据的稀疏经验来学习有用的多模态表示。在这里，我们评估了一个受认知概念“全局工作区”启发的神经网络架构的能力：一个共享的两个（或多个）输入模态的表示。每个模态都经过一个专门的系统处理（在单模态数据上预训练，并随后冻结）。相应的潜在表示然后被编码到一个共享的工作区并从中解码。重要的是，这种架构适用于通过循环一致性自我监督训练。

    Recent deep learning models can efficiently combine inputs from different modalities (e.g., images and text) and learn to align their latent representations, or to translate signals from one domain to another (as in image captioning, or text-to-image generation). However, current approaches mainly rely on brute-force supervised training over large multimodal datasets. In contrast, humans (and other animals) can learn useful multimodal representations from only sparse experience with matched cross-modal data. Here we evaluate the capabilities of a neural network architecture inspired by the cognitive notion of a "Global Workspace": a shared representation for two (or more) input modalities. Each modality is processed by a specialized system (pretrained on unimodal data, and subsequently frozen). The corresponding latent representations are then encoded to and decoded from a single shared workspace. Importantly, this architecture is amenable to self-supervised training via cycle-consiste
    
[^71]: 使用条件生成对抗网络进行益智游戏的过程化内容生成

    Procedural content generation of puzzle games using conditional generative adversarial networks. (arXiv:2306.15696v1 [cs.AI])

    [http://arxiv.org/abs/2306.15696](http://arxiv.org/abs/2306.15696)

    本文介绍了一种实验方法，使用参数化生成对抗网络为益智游戏Lily's Garden生成关卡。虽然GAN在逼近地图形状方面表现良好，但在逼近方块分布方面存在困难。可能通过尝试替代GAN的架构来改进这一情况。

    

    本文提出了一种使用参数化生成对抗网络（GAN）为益智游戏Lily's Garden生成关卡的实验方法。我们从真实关卡中提取两个条件向量，以控制GAN输出的细节。虽然GAN在逼近第一个条件（地图形状）方面表现良好，但在逼近第二个条件（方块分布）方面却有困难。我们假设通过尝试替代GAN的生成器和判别器的架构可能会改进这一情况。

    In this article, we present an experimental approach to using parameterized Generative Adversarial Networks (GANs) to produce levels for the puzzle game Lily's Garden. We extract two condition vectors from the real levels in an effort to control the details of the GAN's outputs. While the GANs perform well in approximating the first condition (map shape), they struggle to approximate the second condition (piece distribution). We hypothesize that this might be improved by trying out alternative architectures for both the Generator and Discriminator of the GANs.
    
[^72]: KAPLA：可扩展NN加速器数据流的实用化表示和快速求解

    KAPLA: Pragmatic Representation and Fast Solving of Scalable NN Accelerator Dataflow. (arXiv:2306.15676v1 [cs.AR])

    [http://arxiv.org/abs/2306.15676](http://arxiv.org/abs/2306.15676)

    本文提出了KAPLA，一个用于可扩展NN加速器数据流优化的快速求解器。通过实用的指令和全面的数据流表示，KAPLA能够有效地进行设计空间的探索，并快速确定方案的有效性和效率。

    

    数据流调度决策对神经网络（NN）加速器至关重要。最近可扩展的NN加速器支持一组丰富的先进数据流技术。因此，全面表示和快速找到优化的数据流方案的问题变得更加复杂和具有挑战性。在这项工作中，我们首先提出了可扩展多节点NN架构上时间和空间调度的全面实用化数据流表示。一份非正式的分层分类表明，数据流空间不同层次之间的紧密耦合是快速设计探索的主要难点。一组形式化的张量中心指令准确地表示各种层间和层内方案，并允许快速确定其有效性和效率。然后，我们构建了一个通用的、优化的和快速的数据流求解器KAPLA，利用实用的指令来进行设计空间的有效有效性检查和优化方案的探索。

    Dataflow scheduling decisions are of vital importance to neural network (NN) accelerators. Recent scalable NN accelerators support a rich set of advanced dataflow techniques. The problems of comprehensively representing and quickly finding optimized dataflow schemes thus become significantly more complicated and challenging. In this work, we first propose comprehensive and pragmatic dataflow representations for temporal and spatial scheduling on scalable multi-node NN architectures. An informal hierarchical taxonomy highlights the tight coupling across different levels of the dataflow space as the major difficulty for fast design exploration. A set of formal tensor-centric directives accurately express various inter-layer and intra-layer schemes, and allow for quickly determining their validity and efficiency. We then build a generic, optimized, and fast dataflow solver, KAPLA, which makes use of the pragmatic directives to explore the design space with effective validity check and eff
    
[^73]: 异步算法与Cocycles的对齐

    Asynchronous Algorithmic Alignment with Cocycles. (arXiv:2306.15632v1 [cs.LG])

    [http://arxiv.org/abs/2306.15632](http://arxiv.org/abs/2306.15632)

    该论文提出了一种将节点状态更新和消息函数调用分离的数学框架，以实现异步计算，并以此作为基础，进行了异步算法和神经网络的对齐。

    

    最先进的神经算法推理器使用图神经网络（GNN）中的消息传递。但是，典型的GNN在定义和调用消息函数之间模糊了区别，迫使节点在每一层都向其邻居发送消息，同步地进行。然而，当将GNN应用于学习执行动态规划算法时，大多数步骤只有少数几个节点会有有意义的更新要发送。因此，通过在图中发送太多无关的数据，可能导致低效率，而许多中间的GNN步骤必须学习身份函数。在这项工作中，我们明确地分离了节点状态更新和消息函数调用的概念。通过这种分离，我们得到了一个数学表达，可以让我们思考算法和神经网络中的异步计算。

    State-of-the-art neural algorithmic reasoners make use of message passing in graph neural networks (GNNs). But typical GNNs blur the distinction between the definition and invocation of the message function, forcing a node to send messages to its neighbours at every layer, synchronously. When applying GNNs to learn to execute dynamic programming algorithms, however, on most steps only a handful of the nodes would have meaningful updates to send. One, hence, runs the risk of inefficiencies by sending too much irrelevant data across the graph -- with many intermediate GNN steps having to learn identity functions. In this work, we explicitly separate the concepts of node state update and message function invocation. With this separation, we obtain a mathematical formulation that allows us to reason about asynchronous computation in both algorithms and neural networks.
    
[^74]: 通过位置插值扩展大型语言模型的上下文窗口

    Extending Context Window of Large Language Models via Positional Interpolation. (arXiv:2306.15595v1 [cs.CL])

    [http://arxiv.org/abs/2306.15595](http://arxiv.org/abs/2306.15595)

    通过位置插值方法，我们可以在最小微调的情况下将RoPE-based预训练语言模型的上下文窗口扩展到最多32768，并在多个任务上获得强有力的实证结果。通过线性降低输入位置索引的大小，我们保持了扩展模型在原始上下文窗口内任务的质量。

    

    我们提出了一种位置插值（PI）方法，可以在最小微调的情况下将RoPE-based预训练语言模型（如LLaMA模型）的上下文窗口大小扩展到最多32768，并且在需要长上下文的各种任务（包括密钥检索、语言建模和长篇文档摘要等）上展现出良好的实证结果。同时，通过位置插值扩展的模型在原始上下文窗口内的任务中相对保持良好的质量。为了实现这一目标，位置插值线性地降低输入位置索引的大小，以匹配原始的上下文窗口大小，而不是超过训练时上下文长度，这可能会导致严重的高注意力分数，完全破坏自注意机制。我们的理论研究表明，插值的上界至少是推断的上界的$\sim 600 \times$要小，进一步证明了其稳定性。

    We present Position Interpolation (PI) that extends the context window sizes of RoPE-based pretrained LLMs such as LLaMA models to up to 32768 with minimal fine-tuning (within 1000 steps), while demonstrating strong empirical results on various tasks that require long context, including passkey retrieval, language modeling, and long document summarization from LLaMA 7B to 65B. Meanwhile, the extended model by Position Interpolation preserve quality relatively well on tasks within its original context window. To achieve this goal, Position Interpolation linearly down-scales the input position indices to match the original context window size, rather than extrapolating beyond the trained context length which may lead to catastrophically high attention scores that completely ruin the self-attention mechanism. Our theoretical study shows that the upper bound of interpolation is at least $\sim 600 \times$ smaller than that of extrapolation, further demonstrating its stability. Models extend
    
[^75]: 针对不规则时间序列的异常检测的前体

    Precursor-of-Anomaly Detection for Irregular Time Series. (arXiv:2306.15489v1 [cs.AI])

    [http://arxiv.org/abs/2306.15489](http://arxiv.org/abs/2306.15489)

    本文提出了一种新型异常检测方法，称为前体-异常检测（PoA检测）。与传统的异常检测不同，PoA检测旨在在异常发生之前检测到未来的异常。通过使用基于神经控制微分方程的神经网络和多任务学习算法，我们在17个基准线和3个数据集上进行实验证明了我们的方法的有效性。

    

    异常检测是一个重要领域，旨在识别意外的模式或数据点，并与许多现实世界的问题密切相关，尤其是在金融、制造、网络安全等应用中。虽然异常检测在各个领域已经被广泛研究，但在异常发生之前检测到未来的异常仍然是一个未开发的领域。在本文中，我们提出了一种新型的异常检测方法，称为“前体-异常”（PoA）检测。与传统的异常检测不同，传统的异常检测侧重于确定给定时间序列观测值是否为异常，而PoA检测旨在在异常发生之前检测到未来的异常。为了同时解决这两个问题，我们提出了一种基于神经控制微分方程的神经网络及其多任务学习算法。我们使用17个基准线和3个数据集进行实验，包括规则和不规则时间序列，并证明了我们的方法的有效性。

    Anomaly detection is an important field that aims to identify unexpected patterns or data points, and it is closely related to many real-world problems, particularly to applications in finance, manufacturing, cyber security, and so on. While anomaly detection has been studied extensively in various fields, detecting future anomalies before they occur remains an unexplored territory. In this paper, we present a novel type of anomaly detection, called \emph{\textbf{P}recursor-of-\textbf{A}nomaly} (PoA) detection. Unlike conventional anomaly detection, which focuses on determining whether a given time series observation is an anomaly or not, PoA detection aims to detect future anomalies before they happen. To solve both problems at the same time, we present a neural controlled differential equation-based neural network and its multi-task learning algorithm. We conduct experiments using 17 baselines and 3 datasets, including regular and irregular time series, and demonstrate that our prese
    
[^76]: MIMIC: 基于图像对应关系的遮蔽图像建模

    MIMIC: Masked Image Modeling with Image Correspondences. (arXiv:2306.15128v1 [cs.CV])

    [http://arxiv.org/abs/2306.15128](http://arxiv.org/abs/2306.15128)

    MIMIC是一种基于图像对应关系的遮蔽图像建模方法，通过挖掘不需要任何注释的数据集，使用多个自监督模型进行训练，达到了在多个下游任务上优于使用注释挖掘的表示的效果。

    

    许多像素级的密集预测任务——如计算机视觉中的深度估计和语义分割——如今依赖于预训练的图像表示。因此，筛选有效的预训练数据集至关重要。不幸的是，有效的预训练数据集仅通过模拟环境中的带有注释的3D网格、点云和相机参数筛选而来，并不具备多视角场景。我们提出了一种不需要任何注释的数据集筛选机制。我们从开源视频数据集和合成的3D环境中挖掘了两个数据集：MIMIC-1M(包含1.3M个多视角图像对)和MIMIC-3M(包含3.1M个多视角图像对)。我们使用多个自监督模型进行训练，采用不同的遮蔽图像建模目标，展示了以下发现：在多个下游任务中，基于MIMIC-3M训练的表示优于使用注释挖掘的表示，包括深度估计、语义分割、表面法线和姿态估计等。

    Many pixelwise dense prediction tasks-depth estimation and semantic segmentation in computer vision today rely on pretrained image representations. Therefore, curating effective pretraining datasets is vital. Unfortunately, the effective pretraining datasets are those with multi-view scenes and have only been curated using annotated 3D meshes, point clouds, and camera parameters from simulated environments. We propose a dataset-curation mechanism that does not require any annotations. We mine two datasets: MIMIC-1M with 1.3M and MIMIC-3M with 3.1M multi-view image pairs from open-sourced video datasets and from synthetic 3D environments. We train multiple self-supervised models with different masked image modeling objectives to showcase the following findings: Representations trained on MIMIC-3M outperform those mined using annotations on multiple downstream tasks, including depth estimation, semantic segmentation, surface normals, and pose estimation. They also outperform representati
    
[^77]: 博士论文：探索认知和计算机视觉架构中的(自我)注意力的作用

    PhD Thesis: Exploring the role of (self-)attention in cognitive and computer vision architecture. (arXiv:2306.14650v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2306.14650](http://arxiv.org/abs/2306.14650)

    该论文研究了注意力和记忆在复杂推理任务中的作用，通过以Transformer为基础模型并结合记忆，扩展了自我注意力模型。研究结果表明，在视觉推理任务中，使用基于特征和空间注意力的自我注意力与ResNet50相结合可以高效解决具有挑战性的任务。此外，该论文提出了基于注意力和记忆的认知架构GAMR，它在样本效率、鲁棒性和组合性方面优于其他架构，并具有对新的推理任务的零样本泛化能力。

    

    我们研究了注意力和记忆在复杂推理任务中的作用。我们通过分析基于Transformer的自我注意力模型并将其与记忆相结合来扩展它。通过研究合成视觉推理测试，我们完善了推理任务的分类法。通过将自我注意力与ResNet50结合，我们使用基于特征和空间注意力增强特征图，从而实现了对具有挑战性的视觉推理任务的高效解决。我们的研究结果有助于理解SVRT任务对注意力的需求。此外，我们提出了GAMR，一种结合了注意力和记忆的认知架构，灵感来自主动视觉理论。GAMR在样本效率、鲁棒性和组合性方面优于其他架构，并在新的推理任务上表现出零样本泛化能力。

    We investigate the role of attention and memory in complex reasoning tasks. We analyze Transformer-based self-attention as a model and extend it with memory. By studying a synthetic visual reasoning test, we refine the taxonomy of reasoning tasks. Incorporating self-attention with ResNet50, we enhance feature maps using feature-based and spatial attention, achieving efficient solving of challenging visual reasoning tasks. Our findings contribute to understanding the attentional needs of SVRT tasks. Additionally, we propose GAMR, a cognitive architecture combining attention and memory, inspired by active vision theory. GAMR outperforms other architectures in sample efficiency, robustness, and compositionality, and shows zero-shot generalization on new reasoning tasks.
    
[^78]: 神经符号反向规划引擎（NIPE）：基于语言输入的概率社交推理建模

    The Neuro-Symbolic Inverse Planning Engine (NIPE): Modeling Probabilistic Social Inferences from Linguistic Inputs. (arXiv:2306.14325v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2306.14325](http://arxiv.org/abs/2306.14325)

    本文提出了一个神经符号模型，用于从语言输入中进行目标推断，并通过人类实验验证了该模型的准确性和优势。

    

    人类是社交性的生物。我们经常推理其他智能体，而这种社交推理的关键部分是在了解他们的行为时推断他们的目标。在许多情况下，我们可以从语言描述的智能体、动作和背景环境中进行直观但可靠的目标推断。在本文中，我们研究了在一个概率目标推断领域中，语言驱动和影响社交推理的过程。我们提出了一个神经符号模型，该模型从智能体场景的语言输入中进行目标推断。其中的“神经”部分是一个大型语言模型（LLM），将语言描述转化为代码表示，而“符号”部分则是一个贝叶斯反向规划引擎。为了测试我们的模型，我们设计和进行了一个关于语言目标推断任务的人类实验。我们的模型与人类的反应模式非常相似，并且比单独使用LLM更好地预测了人类的判断。

    Human beings are social creatures. We routinely reason about other agents, and a crucial component of this social reasoning is inferring people's goals as we learn about their actions. In many settings, we can perform intuitive but reliable goal inference from language descriptions of agents, actions, and the background environments. In this paper, we study this process of language driving and influencing social reasoning in a probabilistic goal inference domain. We propose a neuro-symbolic model that carries out goal inference from linguistic inputs of agent scenarios. The "neuro" part is a large language model (LLM) that translates language descriptions to code representations, and the "symbolic" part is a Bayesian inverse planning engine. To test our model, we design and run a human experiment on a linguistic goal inference task. Our model closely matches human response patterns and better predicts human judgements than using an LLM alone.
    
[^79]: G-NM：一组数字时间序列预测模型

    G-NM: A Group of Numerical Time Series Prediction Models. (arXiv:2306.11667v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.11667](http://arxiv.org/abs/2306.11667)

    G-NM是一组集合了传统和现代模型的数字时间序列预测模型，旨在提高对复杂自然现象中的模式和趋势的预测能力。

    

    本研究聚焦于开发和实施一个综合的数字时间序列预测模型集合，统称为数字时间序列预测模型组（G-NM）。该集合包括传统模型如自回归综合移动平均（ARIMA）、Holt-Winters方法和支持向量回归（SVR），以及现代神经网络模型，如循环神经网络（RNN）和长短期记忆（LSTM）。G-NM明确构建以增强我们对复杂自然现象中固有模式和趋势的预测能力。通过利用与这些事件相关的时间序列数据，G-NM便于对此类现象在延长时间段内进行预测。本研究的主要目标是推进我们对此类事件的理解，并大幅提高预测准确性。G-NM包括线性和非线性依赖关系，以及季节性趋势。

    In this study, we focus on the development and implementation of a comprehensive ensemble of numerical time series forecasting models, collectively referred to as the Group of Numerical Time Series Prediction Model (G-NM). This inclusive set comprises traditional models such as Autoregressive Integrated Moving Average (ARIMA), Holt-Winters' method, and Support Vector Regression (SVR), in addition to modern neural network models including Recurrent Neural Network (RNN) and Long Short-Term Memory (LSTM). G-NM is explicitly constructed to augment our predictive capabilities related to patterns and trends inherent in complex natural phenomena. By utilizing time series data relevant to these events, G-NM facilitates the prediction of such phenomena over extended periods. The primary objective of this research is to both advance our understanding of such occurrences and to significantly enhance the accuracy of our forecasts. G-NM encapsulates both linear and non-linear dependencies, seasonal
    
[^80]: 基于注意力知识图卷积网络的旅游景点推荐

    Tourist Attractions Recommendation based on Attention Knowledge Graph Convolution Network. (arXiv:2306.10946v1 [cs.IR] CROSS LISTED)

    [http://arxiv.org/abs/2306.10946](http://arxiv.org/abs/2306.10946)

    本文提出了一种基于注意力知识图卷积网络的旅游景点推荐模型，通过自动语义发掘目标景点的相邻实体，根据旅客的喜好选择，预测类似景点的概率，实验中取得良好效果。

    

    基于知识图谱的推荐算法在相对成熟阶段，但在特定领域的推荐仍存在问题。例如在旅游领域，选择适合的旅游景点属性流程作为推荐基础较为复杂。本文提出改进的注意力知识图卷积网络模型(Att-KGCN)，自动语义地发掘目标景点的相邻实体，利用注意力层将相对相似的位置进行聚合，并通过推理旅客喜好选择，预测类似景点的概率作为推荐系统。实验中，采用索科特拉岛-也门的旅游数据，证明了注意力知识图卷积网络在旅游领域的景点推荐效果良好。

    The recommendation algorithm based on knowledge graphs is at a relatively mature stage. However, there are still some problems in the recommendation of specific areas. For example, in the tourism field, selecting suitable tourist attraction attributes process is complicated as the recommendation basis for tourist attractions. In this paper, we propose the improved Attention Knowledge Graph Convolution Network model, named (Att-KGCN), which automatically discovers the neighboring entities of the target scenic spot semantically. The attention layer aggregates relatively similar locations and represents them with an adjacent vector. Then, according to the tourist's preferred choices, the model predicts the probability of similar spots as a recommendation system. A knowledge graph dataset of tourist attractions used based on tourism data on Socotra Island-Yemen. Through experiments, it is verified that the Attention Knowledge Graph Convolution Network has a good effect on the recommendatio
    
[^81]: 虚假黎明：重新评估谷歌强化学习在芯片宏观布局中的应用

    The False Dawn: Reevaluating Google's Reinforcement Learning for Chip Macro Placement. (arXiv:2306.09633v1 [cs.LG])

    [http://arxiv.org/abs/2306.09633](http://arxiv.org/abs/2306.09633)

    谷歌2021年在《自然》杂志上发表的一篇论文声称其使用强化学习在芯片设计领域进行了创新，但两项独立的评估表明，谷歌的方法不如人类设计师、不如一个众所周知的算法（模拟退火），并且也不如普遍可用的商业软件，文章的完整性也遭到了严重的损害。

    

    谷歌2021年在《自然》杂志上发表的有关使用强化学习设计芯片的论文，因为所声称的结果缺乏充分的文件记录和关键步骤的说明，引发争议并受到媒体的批评报道。 而两项独立的评估填补了空白，证明谷歌强化学习落后于人类设计师、落后于一种众所周知的算法（模拟退火），并且还落后于普遍可用的商业软件。交叉检查的数据表明，由于行为、分析和报告中的错误，该《自然》文章的完整性受到了严重的损害。

    Reinforcement learning (RL) for physical design of silicon chips in a Google 2021 Nature paper stirred controversy due to poorly documented claims that raised eyebrows and attracted critical media coverage. The Nature paper withheld most inputs needed to produce reported results and some critical steps in the methodology. But two independent evaluations filled in the gaps and demonstrated that Google RL lags behind human designers, behind a well-known algorithm (Simulated Annealing), and also behind generally-available commercial software. Crosschecked data indicate that the integrity of the Nature paper is substantially undermined owing to errors in the conduct, analysis and reporting.
    
[^82]: TSMixer: 用于多元时间序列预测的轻量级MLP-Mixer模型

    TSMixer: Lightweight MLP-Mixer Model for Multivariate Time Series Forecasting. (arXiv:2306.09364v1 [cs.LG])

    [http://arxiv.org/abs/2306.09364](http://arxiv.org/abs/2306.09364)

    TSMixer是一种用于多元时间序列预测的轻量级MLP-Mixer模型，可以有效地捕捉时间序列属性并在准确性方面超越了Transformers的方法。

    

    Transformers因其能够捕捉长序列交互而在时间序列预测中备受青睐。然而，其内存和计算要求高的问题对长期预测构成了严重瓶颈。为了解决这一问题，我们提出了TSMixer，这是一种轻量级神经架构，专为多元预测和补丁时间序列表示学习而设计，是Transformers的有效替代。我们的模型借鉴了MLP-Mixer模型在计算机视觉中的成功经验。我们展示了将视觉MLP-Mixer适应于时间序列的挑战，并引入了经过实验证实的组件以提高准确性。这包括一种新的设计范式，即将在线协调头附加到MLP-Mixer骨干上，以显式地建模时间序列的属性，如层次结构和通道相关性。我们还提出了一种混合通道建模方法，平衡了编码多个时间序列通道和保留单个通道信息之间的权衡。我们的实验表明，TSMixer在一元和多元时间序列预测任务中均实现了最先进的性能，同时需要比基于Transformers的方法少得多的参数。

    Transformers have gained popularity in time series forecasting for their ability to capture long-sequence interactions. However, their high memory and computing requirements pose a critical bottleneck for long-term forecasting. To address this, we propose TSMixer, a lightweight neural architecture exclusively composed of multi-layer perceptron (MLP) modules. TSMixer is designed for multivariate forecasting and representation learning on patched time series, providing an efficient alternative to Transformers. Our model draws inspiration from the success of MLP-Mixer models in computer vision. We demonstrate the challenges involved in adapting Vision MLP-Mixer for time series and introduce empirically validated components to enhance accuracy. This includes a novel design paradigm of attaching online reconciliation heads to the MLP-Mixer backbone, for explicitly modeling the time-series properties such as hierarchy and channel-correlations. We also propose a Hybrid channel modeling approa
    
[^83]: 自适应蒙特卡罗搜索用于图论猜想证伪

    Adaptive Monte Carlo Search for Conjecture Refutation in Graph Theory. (arXiv:2306.07956v1 [math.CO])

    [http://arxiv.org/abs/2306.07956](http://arxiv.org/abs/2306.07956)

    本研究提出了自适应蒙特卡罗搜索算法，用于反驳猜想并证明图论问题。该算法在反驳多个猜想方面表现出色，并优于已有算法。

    

    图论是一个跨学科的研究领域，具有在数学建模和计算机科学中广泛的应用。图论研究不仅仅依赖于定理的创造，还涉及到猜想的提出。证伪算法通过在图上最大化某些得分函数来寻找反例，从而试图证伪猜想。本研究提出了一种新颖的猜想证伪算法，称为自适应蒙特卡罗搜索（AMCS）算法，通过修改蒙特卡罗树搜索算法得到。通过对其在发现数个图论猜想的反例方面的成功评估，AMCS优于现有的猜想证伪算法。该算法还被用于证伪了六个开放猜想，其中两个是由Liu等人于2021年提出的化学图论猜想，另外四个是AutoGraphiX计算机系统于2006年提出的猜想。最后，使用AMCS证明了其中四个开放猜想.

    Graph theory is an interdisciplinary field of study that has various applications in mathematical modeling and computer science. Research in graph theory depends on the creation of not only theorems but also conjectures. Conjecture-refuting algorithms attempt to refute conjectures by searching for counterexamples to those conjectures, often by maximizing certain score functions on graphs. This study proposes a novel conjecture-refuting algorithm, referred to as the adaptive Monte Carlo search (AMCS) algorithm, obtained by modifying the Monte Carlo tree search algorithm. Evaluated based on its success in finding counterexamples to several graph theory conjectures, AMCS outperforms existing conjecture-refuting algorithms. The algorithm is further utilized to refute six open conjectures, two of which were chemical graph theory conjectures formulated by Liu et al. in 2021 and four of which were formulated by the AutoGraphiX computer system in 2006. Finally, four of the open conjectures are
    
[^84]: 修复断开的肺气道和血管的拓扑结构：基线和数据集

    Topology Repairing of Disconnected Pulmonary Airways and Vessels: Baselines and a Dataset. (arXiv:2306.07089v2 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2306.07089](http://arxiv.org/abs/2306.07089)

    该论文提出了一种修复断开肺气道和血管拓扑结构的方法，通过关键点检测任务预测可以连接断开组件的关键点，同时提供了一个新的数据集可用于训练和评估。

    

    准确的肺气道和血管分割对于肺部疾病的诊断和治疗至关重要。然而，目前的深度学习方法存在连接性问题，限制了其临床应用性。为了解决这一挑战，我们提出了一种后处理方法，利用数据驱动的方法修复断开的肺部管状结构的拓扑结构。我们的方法将问题形式化为关键点检测任务，通过训练神经网络来预测可以连接断开组件的关键点。我们使用训练数据生成管状结构的断开数据。此外，新的肺部树修复（PTR）数据集公开可用，包括800个完整的三维模型，包括肺气道、动脉和静脉，以及合成的断开数据。我们的代码和数据可在https://github.com/M3DV/pulmonary-tree-repairing上获得。

    Accurate segmentation of pulmonary airways and vessels is crucial for the diagnosis and treatment of pulmonary diseases. However, current deep learning approaches suffer from disconnectivity issues that hinder their clinical usefulness. To address this challenge, we propose a post-processing approach that leverages a data-driven method to repair the topology of disconnected pulmonary tubular structures. Our approach formulates the problem as a keypoint detection task, where a neural network is trained to predict keypoints that can bridge disconnected components. We use a training data synthesis pipeline that generates disconnected data from complete pulmonary structures. Moreover, the new Pulmonary Tree Repairing (PTR) dataset is publicly available, which comprises 800 complete 3D models of pulmonary airways, arteries, and veins, as well as the synthetic disconnected data. Our code and data are available at https://github.com/M3DV/pulmonary-tree-repairing.
    
[^85]: 理解长尾效应对神经网络压缩的影响

    Understanding the Effect of the Long Tail on Neural Network Compression. (arXiv:2306.06238v1 [cs.LG])

    [http://arxiv.org/abs/2306.06238](http://arxiv.org/abs/2306.06238)

    本文研究了在神经网络压缩中如何保持与原始网络的语义相同，在长尾现象中探讨了压缩提高推广性能的记忆要素。

    

    网络压缩现在是神经网络研究的一个成熟的子领域，过去的十年中，取得了显著的进展，以减小模型尺寸和加速推断为目标，同时保持分类准确性。然而，许多研究观察到，仅关注总体准确性可能是误导的。例如，已经证明全模型和压缩模型之间的差异可能会偏向于在数据集中低频的类。这引出了一个重要的研究问题，即“我们能否在保持与原始网络语义等同的情况下实现网络压缩？”在本文中，我们研究了这个问题，重点关注计算机视觉数据集中Feldman等人观察到的“长尾”现象。他们认为，某些输入（适当定义）的记忆对于实现良好的泛化是必要的。由于压缩限制了网络的容量（因此也限制了其记忆能力），所以我们研究了这个问题：

    Network compression is now a mature sub-field of neural network research: over the last decade, significant progress has been made towards reducing the size of models and speeding up inference, while maintaining the classification accuracy. However, many works have observed that focusing on just the overall accuracy can be misguided. E.g., it has been shown that mismatches between the full and compressed models can be biased towards under-represented classes. This raises the important research question, \emph{can we achieve network compression while maintaining ``semantic equivalence'' with the original network?} In this work, we study this question in the context of the ``long tail'' phenomenon in computer vision datasets observed by Feldman, et al. They argue that \emph{memorization} of certain inputs (appropriately defined) is essential to achieving good generalization. As compression limits the capacity of a network (and hence also its ability to memorize), we study the question: a
    
[^86]: 推荐系统如何从大型语言模型中受益：一项调查研究

    How Can Recommender Systems Benefit from Large Language Models: A Survey. (arXiv:2306.05817v1 [cs.IR])

    [http://arxiv.org/abs/2306.05817](http://arxiv.org/abs/2306.05817)

    本文对将大型语言模型（LLM）应用于推荐系统进行了全面的调查研究，从两个角度总结了现有的研究工作：如何在推荐系统中调整LLM和调整LLM时在哪里调整。最后，我们提出了一些潜在的研究方向和挑战。

    

    推荐系统在匹配互联网应用程序用户的信息需求方面发挥着重要作用。在自然语言处理领域中，大型语言模型已经展现出了惊人的新兴能力（例如指令跟踪、推理），从而为将LLM调整到推荐系统中以提高性能和改善用户体验的研究方向带来了希望。在本文中，我们从应用导向的角度对此研究方向进行了全面的调查。我们首先从两个正交的角度总结了现有的研究工作：如何在推荐系统中调整LLM和调整LLM时在哪里调整。对于“在哪里”这个问题，我们讨论了LLM在推荐流程的不同阶段中可能发挥的作用，即特征工程、特征编码器、评分/排名函数和流程控制器。对于“如何”这个问题，我们调查了训练和推理策略，从而得出两个细粒度的分类标准，即是否调整LLM和是否将LLM作为独立模型或混合模型组件使用。最后，我们提出了在将LLM调整到RS中的一些挑战和潜在方向，包括与现有系统的集成、用户反馈、评估度量和知识蒸馏。

    Recommender systems (RS) play important roles to match users' information needs for Internet applications. In natural language processing (NLP) domains, large language model (LLM) has shown astonishing emergent abilities (e.g., instruction following, reasoning), thus giving rise to the promising research direction of adapting LLM to RS for performance enhancements and user experience improvements. In this paper, we conduct a comprehensive survey on this research direction from an application-oriented view. We first summarize existing research works from two orthogonal perspectives: where and how to adapt LLM to RS. For the "WHERE" question, we discuss the roles that LLM could play in different stages of the recommendation pipeline, i.e., feature engineering, feature encoder, scoring/ranking function, and pipeline controller. For the "HOW" question, we investigate the training and inference strategies, resulting in two fine-grained taxonomy criteria, i.e., whether to tune LLMs or not, a
    
[^87]: 将几何控制集成到文本到图像扩散模型中以通过文本提示生成高质量的检测数据

    Integrating Geometric Control into Text-to-Image Diffusion Models for High-Quality Detection Data Generation via Text Prompt. (arXiv:2306.04607v1 [cs.CV])

    [http://arxiv.org/abs/2306.04607](http://arxiv.org/abs/2306.04607)

    GeoDiffusion使用文本提示将各种几何条件转化为图像，生成高质量的检测数据，性能优于现有方法。

    

    扩散模型因其在创建内容和生成数据方面的显着能力而受到重视，例如图像分类。然而，使用扩散模型生成高质量的物体检测数据仍然是一个不被充分探索的领域，其中不仅图像水平的感知质量，而且边界框和相机视图等几何条件也是至关重要的。前期研究使用模块编码语义布局来实现复制粘贴合成或布局到图像(L2I)生成。本文提出了GeoDiffusion，一种简单的框架，可以灵活地将各种几何条件转化为文本提示，并使用预训练的文本到图像(T2I)扩散模型生成高质量的检测数据。与以往的L2I方法不同，我们的GeoDiffusion不仅能够编码边界框，还能够编码自驾场景中的额外几何条件，如摄像头视图。广泛的实验结果表明，GeoDiffusion在物体检测准确性方面优于最先进的方法，并针对各种几何条件生成具有更高感知质量的图像。

    Diffusion models have attracted significant attention due to their remarkable ability to create content and generate data for tasks such as image classification. However, the usage of diffusion models to generate high-quality object detection data remains an underexplored area, where not only the image-level perceptual quality but also geometric conditions such as bounding boxes and camera views are essential. Previous studies have utilized either copy-paste synthesis or layout-to-image (L2I) generation with specifically designed modules to encode semantic layouts. In this paper, we propose GeoDiffusion, a simple framework that can flexibly translate various geometric conditions into text prompts and empower the pre-trained text-to-image (T2I) diffusion models for high-quality detection data generation. Unlike previous L2I methods, our GeoDiffusion is able to encode not only bounding boxes but also extra geometric conditions such as camera views in self-driving scenes. Extensive experi
    
[^88]: 自适应基于梯度的异常值去除的嘈杂标签学习方法

    Learning with Noisy Labels by Adaptive Gradient-Based Outlier Removal. (arXiv:2306.04502v1 [cs.LG])

    [http://arxiv.org/abs/2306.04502](http://arxiv.org/abs/2306.04502)

    本文提出了一种名为AGRA的自适应梯度异常值去除方法，能够在模型训练过程中动态调整数据集从而有效提高模型学习效果。

    

    训练可靠和高性能模型需要准确和丰富的数据集，但即便是人工标注的数据集也会包含错误，更不用说自动标注的数据集了。现有的一些数据去噪方法主要集中于检测异常值并进行永久性去除，但这种方法很容易过度或者欠度过滤数据集。在本论文中，我们提出了一种新的自适应梯度异常值去除方法（AGRA），不同于在模型训练之前清洗数据集，我们的方法在训练过程中动态调整数据集。通过比较一组样本的累积梯度和单个样本的梯度，我们的方法可以决定是否在当前更新时保留对应的样本，以此来确定它是否有助于模型的学习效果。在多个数据集上进行的广泛评估表明，AGRA方法的有效性，并且全面的结果分析证实了我们方法的理论和实践收益。

    An accurate and substantial dataset is necessary to train a reliable and well-performing model. However, even manually labeled datasets contain errors, not to mention automatically labeled ones. The problem of data denoising was addressed in different existing research, most of which focuses on the detection of outliers and their permanent removal - a process that is likely to over- or underfilter the dataset. In this work, we propose AGRA: a new method for Adaptive GRAdient-based outlier removal. Instead of cleaning the dataset prior to model training, the dataset is adjusted during the training process. By comparing the aggregated gradient of a batch of samples and an individual example gradient, our method dynamically decides whether a corresponding example is helpful for the model at this point or is counter-productive and should be left out for the current update. Extensive evaluation on several datasets demonstrates the AGRA effectiveness, while comprehensive results analysis sup
    
[^89]: 将模型评估重新考虑为缩小社会技术差距

    Rethinking Model Evaluation as Narrowing the Socio-Technical Gap. (arXiv:2306.03100v1 [cs.HC])

    [http://arxiv.org/abs/2306.03100](http://arxiv.org/abs/2306.03100)

    针对同质化的模型，模型评估需要提供有效的评估，以判断特定模型是否在下游使用场景中可以满足多少人类需求，并且应该根据真实的社会需求来开发评估模型，并拥抱多样化的评估方法。

    

    生成和大型语言模型的最近发展给模型评估带来了新的挑战，研究界和工业界正在努力应对。虽然这些模型的多才多艺引起了人们的兴奋，但它们也不可避免地向同质化迈进：用单个常称之为“通用”的模型为一系列应用提供动力。在这篇立场论文中，我们认为模型评估实践必须承担一个关键任务，以应对这种同质化带来的挑战和责任：为特定模型提供有效的评估，判断是否以及在下游使用场景中可以通过给定模型满足多少人类需求（“社会技术差距”）。我们汲取社会科学、人机交互（HCI）和可解释AI（XAI）跨学科领域的经验，敦促社区开发基于真实社会需求的评估方法，并拥抱多样化的评估方法。

    The recent development of generative and large language models (LLMs) poses new challenges for model evaluation that the research community and industry are grappling with. While the versatile capabilities of these models ignite excitement, they also inevitably make a leap toward homogenization: powering a wide range of applications with a single, often referred to as ``general-purpose'', model. In this position paper, we argue that model evaluation practices must take on a critical task to cope with the challenges and responsibilities brought by this homogenization: providing valid assessments for whether and how much human needs in downstream use cases can be satisfied by the given model (\textit{socio-technical gap}). By drawing on lessons from the social sciences, human-computer interaction (HCI), and the interdisciplinary field of explainable AI (XAI), we urge the community to develop evaluation methods based on real-world socio-requirements and embrace diverse evaluation methods 
    
[^90]: 一瞥：重新思考视频不断学习中的时间信息

    Just a Glimpse: Rethinking Temporal Information for Video Continual Learning. (arXiv:2305.18418v1 [cs.CV])

    [http://arxiv.org/abs/2305.18418](http://arxiv.org/abs/2305.18418)

    本文提出了一种基于单个帧的新型重播机制SMILE，用于有效的视频连续学习。实验表明，在内存受到极端限制时，视频的多样性比时间信息更重要。

    

    增量学习是连续学习研究中最重要的设置之一，因为它与现实世界的应用场景密切相关。随着类别/任务数量的增加，由于受到内存大小的限制，灾难性遗忘会出现。在视频领域研究持续学习面临更大的挑战，因为视频数据包含大量帧，这会使回放记忆负担更重。目前的常见做法是从视频流中对帧进行子采样，并将其存储在回放记忆中。在本文中，我们提出了一种基于单个帧的新型重播机制SMILE，用于有效的视频连续学习。通过大量实验，我们表明在极端内存限制下，视频的多样性比时间信息更重要。因此，我们的方法侧重于从代表大量独特视频的少量帧中学习。我们在三个代表性视频数据集Kin上进行了实验。

    Class-incremental learning is one of the most important settings for the study of Continual Learning, as it closely resembles real-world application scenarios. With constrained memory sizes, catastrophic forgetting arises as the number of classes/tasks increases. Studying continual learning in the video domain poses even more challenges, as video data contains a large number of frames, which places a higher burden on the replay memory. The current common practice is to sub-sample frames from the video stream and store them in the replay memory. In this paper, we propose SMILE a novel replay mechanism for effective video continual learning based on individual/single frames. Through extensive experimentation, we show that under extreme memory constraints, video diversity plays a more significant role than temporal information. Therefore, our method focuses on learning from a small number of frames that represent a large number of unique videos. On three representative video datasets, Kin
    
[^91]: 通过重新标记最小训练子集来翻转预测

    Relabel Minimal Training Subset to Flip a Prediction. (arXiv:2305.12809v1 [cs.LG])

    [http://arxiv.org/abs/2305.12809](http://arxiv.org/abs/2305.12809)

    本文利用扩展影响函数提出了一种有效的识别和重新标记最小训练子集的方法，并证明其始终能够成功翻转测试结果，同时还提供了挑战模型预测、评估模型鲁棒性和洞察训练集偏差等多重作用。

    

    Yang等人发现，仅删除1%的训练数据就可能导致预测结果翻转。鉴于机器学习模型中存在噪声数据的普遍性，本文提出了一个问题：在模型训练之前通过重新标记一个小的训练数据子集可否导致测试结果翻转？本文利用扩展影响函数提出了一种有效的识别和重新标记这种子集的方法，并证明了其始终能够产生成功的结果。这种机制有多重作用：（1）提供了一种补充方法，可以通过恢复可能错误标记的训练数据来挑战模型预测；（2）评估模型的鲁棒性，因为本文发现子集的大小与训练集中噪声数据的比例之间存在显著关系；（3）提供了洞察训练集偏差的见解。据我们所知，这项工作代表了对识别最小训练子集问题的第一次研究。

    Yang et al. (2023) discovered that removing a mere 1% of training points can often lead to the flipping of a prediction. Given the prevalence of noisy data in machine learning models, we pose the question: can we also result in the flipping of a test prediction by relabeling a small subset of the training data before the model is trained? In this paper, utilizing the extended influence function, we propose an efficient procedure for identifying and relabeling such a subset, demonstrating consistent success. This mechanism serves multiple purposes: (1) providing a complementary approach to challenge model predictions by recovering potentially mislabeled training points; (2) evaluating model resilience, as our research uncovers a significant relationship between the subset's size and the ratio of noisy data in the training set; and (3) offering insights into bias within the training set. To the best of our knowledge, this work represents the first investigation into the problem of identi
    
[^92]: 一种基于深度学习辅助微波等离子体相互作用技术的等离子体密度估计方法

    Deep Learning assisted microwave-plasma interaction based technique for plasma density estimation. (arXiv:2304.14807v1 [physics.plasm-ph])

    [http://arxiv.org/abs/2304.14807](http://arxiv.org/abs/2304.14807)

    本文提出了一种基于深度学习辅助微波等离子体相互作用技术的等离子体密度估计方法，通过测量微波散射引起的电场模式来估计密度剖面。

    

    电子密度是表征任何等离子体的关键参数。低温等离子体领域的大部分应用和研究都基于等离子体密度和等离子体温度。传统的电子密度测量方法针对给定线性低温等离子体设备提供轴向和径向剖面。这些方法存在操作范围较小、仪器沉重以及数据分析过程复杂等主要缺点。为了应对这些实际问题，本文提出了一种新颖的机器学习（ML）辅助微波等离子体相互作用的策略，该策略能够确定等离子体内电子密度剖面。通过测量微波散射引起的电场模式来估计密度剖面。该策略针对一个模拟的训练数据集进行了概念验证，其中包括低温、非磁化和碰撞性等离子体的不同类型的高斯形状密度剖面范围内。

    The electron density is a key parameter to characterize any plasma. Most of the plasma applications and research in the area of low-temperature plasmas (LTPs) is based on plasma density and plasma temperature. The conventional methods for electron density measurements offer axial and radial profiles for any given linear LTP device. These methods have major disadvantages of operational range (not very wide), cumbersome instrumentation, and complicated data analysis procedures. To address such practical concerns, the article proposes a novel machine learning (ML) assisted microwave-plasma interaction based strategy which is capable enough to determine the electron density profile within the plasma. The electric field pattern due to microwave scattering is measured to estimate the density profile. The proof of concept is tested for a simulated training data set comprising a low-temperature, unmagnetized, collisional plasma. Different types of Gaussian-shaped density profiles, in the range
    
[^93]: DeePLT：基于轨迹预测实现智能家居中的个性化照明系统

    DeePLT: Personalized Lighting Facilitates by Trajectory Prediction of Recognized Residents in the Smart Home. (arXiv:2304.08027v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2304.08027](http://arxiv.org/abs/2304.08027)

    本论文提出了一种基于机器学习的智能照明系统DeePLT，其通过轨迹预测实现智能家居中的个性化照明调整，给每个人定制独特的个人资料并根据其轨迹自动调整灯光。

    

    近年来，家居各部分的智能化已成为现代家居的重要特征之一。其中之一便是智能照明系统，可为每个人定制个性化光照。本文提出了一种基于机器学习的智能系统，通过轨迹预测个性化照明系统即时调整家中灯光。所提出的系统包括以下模块：（I）人体检测，用于检测和定位每个给定视频帧中的人物，（II）人脸识别，用于识别检测到的人物，（III）人体跟踪，用于跟踪视频序列中的人物，以及（IV）轨迹预测，使用逆强化学习方法预测用户在未来的位置。该方法为每个人提供一个独特的个人资料，包括规格、人脸图像和自定义照明设置，而该个人资料用于照明调整过程。与其他照明系统不同，本提出的系统可根据每个人的轨迹自动调整灯光。

    In recent years, the intelligence of various parts of the home has become one of the essential features of any modern home. One of these parts is the intelligence lighting system that personalizes the light for each person. This paper proposes an intelligent system based on machine learning that personalizes lighting in the instant future location of a recognized user, inferred by trajectory prediction. Our proposed system consists of the following modules: (I) human detection to detect and localize the person in each given video frame, (II) face recognition to identify the detected person, (III) human tracking to track the person in the sequence of video frames and (IV) trajectory prediction to forecast the future location of the user in the environment using Inverse Reinforcement Learning. The proposed method provides a unique profile for each person, including specifications, face images, and custom lighting settings. This profile is used in the lighting adjustment process. Unlike o
    
[^94]: “Polytuplet Loss: 训练阅读理解和逻辑推理模型的反向方法”

    Polytuplet Loss: A Reverse Approach to Training Reading Comprehension and Logical Reasoning Models. (arXiv:2304.01046v1 [cs.CL] CROSS LISTED)

    [http://arxiv.org/abs/2304.01046](http://arxiv.org/abs/2304.01046)

    本文研究了一种训练阅读理解和逻辑推理模型的反向方法，利用相对准确性的策略来训练模型，通过Polytuplet Loss函数来确保优先学习答案选择的相对正确性，获得了不错的成果，提出了具有一般性的训练方法和模型架构。

    

    在整个学校教育过程中，学生们将受到阅读理解和逻辑推理的考验。学生们已经开发了各种策略来完成此类考试，其中有些被认为是通常表现优于其他策略的。这样一种策略涉及强调相对准确性而非绝对准确性，理论上可以在不完全掌握解题所需信息的情况下得出正确答案。本文研究了应用这种策略来训练迁移学习模型以解决阅读理解和逻辑推理问题的有效性。这些模型在具有挑战性的阅读理解和逻辑推理基准数据集ReClor上进行了评估。尽管以前的研究集中于逻辑推理技能，但我们专注于一种通用的训练方法和模型架构。我们提出了Polytuplet Loss函数，是三元组损失函数的扩展，以确保优先学习答案选择的相对正确性而非学习绝对正确性。

    Throughout schooling, students are tested on reading comprehension and logical reasoning. Students have developed various strategies for completing such exams, some of which are generally thought to outperform others. One such strategy involves emphasizing relative accuracy over absolute accuracy and can theoretically produce the correct answer without full knowledge of the information required to solve the question. This paper examines the effectiveness of applying such a strategy to train transfer learning models to solve reading comprehension and logical reasoning questions. The models were evaluated on the ReClor dataset, a challenging reading comprehension and logical reasoning benchmark. While previous studies targeted logical reasoning skills, we focus on a general training method and model architecture. We propose the polytuplet loss function, an extension of the triplet loss function, to ensure prioritization of learning the relative correctness of answer choices over learning
    
[^95]: Pgx:强化学习硬件加速的并行游戏模拟器

    Pgx: Hardware-accelerated parallel game simulation for reinforcement learning. (arXiv:2303.17503v1 [cs.AI])

    [http://arxiv.org/abs/2303.17503](http://arxiv.org/abs/2303.17503)

    Pgx是一个用JAX编写的游戏模拟器集合，具有强化学习硬件加速能力，支持并行执行，速度比现有的强化学习库快10倍。 它实现了Backgammon，Shogi和Go等基准测试游戏。

    

    我们提出了Pgx，这是一个用JAX编写的棋盘游戏模拟器集合。由于JAX的自动向量化和即时编译功能，Pgx易于在GPU/TPU加速器上进行大规模并行执行。我们发现，在单个A100 GPU上的Pgx模拟比现有的强化学习库快10倍。Pgx实现了被认为是人工智能研究中至关重要的基准测试的游戏，如Backgammon，Shogi和Go。 Pgx可在https://github.com/sotetsuk/pgx获得。

    We propose Pgx, a collection of board game simulators written in JAX. Thanks to auto-vectorization and Just-In-Time compilation of JAX, Pgx scales easily to thousands of parallel execution on GPU/TPU accelerators. We found that the simulation of Pgx on a single A100 GPU is 10x faster than that of existing reinforcement learning libraries. Pgx implements games considered vital benchmarks in artificial intelligence research, such as Backgammon, Shogi, and Go. Pgx is available at https://github.com/sotetsuk/pgx.
    
[^96]: 通过反向特征投影在不断学习中维护线性可分性

    Preserving Linear Separability in Continual Learning by Backward Feature Projection. (arXiv:2303.14595v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.14595](http://arxiv.org/abs/2303.14595)

    提出了一种名为BFP的连续学习方法，它通过将新特征变换为旧特征的线性变换来维护线性可分性，从而允许新特征方向的出现以适应新任务，同时保留旧任务的信息。

    

    在不断学习中，灾难性遗忘一直是一个重大挑战，因为模型需要在有限或没有以前查看任务的数据情况下学习新任务。为了解决这个挑战，基于特征空间知识蒸馏的方法已被提出并证明可以减少遗忘。然而，大多数特征蒸馏方法直接约束新特征以匹配旧特征，忽视了可塑性的需求。为了实现更好的稳定性-可塑性平衡，我们提出了Backward Feature Projection（BFP），这是一种连续学习方法，允许新特征在旧特征的可学习线性变换中发生变化。BFP保留旧类别的线性可分性，同时允许新的特征方向出现以适应新的类别。BFP可以与现有的经验重播方法集成，并显著提高性能。我们还证明，BFP有助于学习更好的表示空间。

    Catastrophic forgetting has been a major challenge in continual learning, where the model needs to learn new tasks with limited or no access to data from previously seen tasks. To tackle this challenge, methods based on knowledge distillation in feature space have been proposed and shown to reduce forgetting. However, most feature distillation methods directly constrain the new features to match the old ones, overlooking the need for plasticity. To achieve a better stability-plasticity trade-off, we propose Backward Feature Projection (BFP), a method for continual learning that allows the new features to change up to a learnable linear transformation of the old features. BFP preserves the linear separability of the old classes while allowing the emergence of new feature directions to accommodate new classes. BFP can be integrated with existing experience replay methods and boost performance by a significant margin. We also demonstrate that BFP helps learn a better representation space,
    
[^97]: 连接生成半监督学习和生成开放集识别

    Linking generative semi-supervised learning and generative open-set recognition. (arXiv:2303.11702v1 [cs.CV])

    [http://arxiv.org/abs/2303.11702](http://arxiv.org/abs/2303.11702)

    本研究旨在探究生成半监督学习和生成开放集识别之间的关系。SSL-GANs和OSR-GANs方法的相似性在于都要求生成器在互补空间中产生样本，并通过正则化来推广开放空间。研究结果表明SSL优化边缘-GAN在结合SSL-OSR任务方面树立新的标准，但在某些OSR任务中OSR优化的ARP-GAN仍然略优于SSL-GAN。

    

    本研究在生成对抗网络（GANs）的背景下，探究了半监督学习（SSL）和开放集识别（OSR）之间的关系。尽管以前没有正式将SSL和OSR联系起来的研究，但它们各自的方法有惊人的相似之处。具体而言，SSL-GAN和OSR-GAN要求生成器在互补空间中产生样本。随后，通过对生成样本进行正则化，SSL和OSR分类器都可以完全识别开放空间。为了证明SSL和OSR之间的关联，我们在理论上和实验上比较了最先进的SSL-GAN方法和最先进的OSR-GAN方法。结果表明，文献基础更加牢固的SSL优化边缘-GAN在结合SSL-OSR任务方面树立新的标准，并在某些一般的OSR实验中取得了新的最先进的结果。然而，OSR优化的对抗性互惠点（ARP）-GAN在一些OSR任务中仍然略优于SSL-GAN。

    This study investigates the relationship between semi-supervised learning (SSL) and open-set recognition (OSR) in the context of generative adversarial networks (GANs). Although no previous study has formally linked SSL and OSR, their respective methods share striking similarities. Specifically, SSL-GANs and OSR-GANs require generator to produce samples in the complementary space. Subsequently, by regularising networks with generated samples, both SSL and OSR classifiers generalize the open space. To demonstrate the connection between SSL and OSR, we theoretically and experimentally compare state-of-the-art SSL-GAN methods with state-of-the-art OSR-GAN methods. Our results indicate that the SSL optimised margin-GANs, which have a stronger foundation in literature, set the new standard for the combined SSL-OSR task and achieves new state-of-other art results in certain general OSR experiments. However, the OSR optimised adversarial reciprocal point (ARP)-GANs still slightly out-performe
    
[^98]: QR-CLIP: 引入显式开放世界知识进行位置和时间推理

    QR-CLIP: Introducing Explicit Open-World Knowledge for Location and Time Reasoning. (arXiv:2302.00952v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.00952](http://arxiv.org/abs/2302.00952)

    本文提出QR-CLIP模型，通过引入开放世界知识进行位置和时间推理，在此任务上取得了约10%和130%的相对提升。

    

    每天的图像可能传达需要我们从中记忆和推断出深刻信息的抽象含义。在本文中，我们教会机器预测图片拍摄的地点和时间，而不是执行传统的分割或分类任务，以鼓励人类类似的推理。受到Horn的QR理论的启发，我们设计了一个由两个部分组成的新型QR-CLIP模型: 1) 数量模块首先回顾更多的开放世界知识作为候选的语言输入; 2) 相关性模块仔细估计视觉和语言线索，并推断出位置和时间。实验显示，我们的QR-CLIP十分有效，并且在每个任务上都比之前的最高水平表现平均提升了约10%和130%的相对提升。本研究为位置和时间推理奠定了技术基础，并表明有效引入开放世界知识是完成这些任务的方法之一。

    Daily images may convey abstract meanings that require us to memorize and infer profound information from them. To encourage such human-like reasoning, in this work, we teach machines to predict where and when it was taken rather than performing basic tasks like traditional segmentation or classification. Inspired by Horn's QR theory, we designed a novel QR-CLIP model consisting of two components: 1) the Quantity module first retrospects more open-world knowledge as the candidate language inputs; 2) the Relevance module carefully estimates vision and language cues and infers the location and time. Experiments show our QR-CLIP's effectiveness, and it outperforms the previous SOTA on each task by an average of about 10% and 130% relative lift in terms of location and time reasoning. This study lays a technical foundation for location and time reasoning and suggests that effectively introducing open-world knowledge is one of the panaceas for the tasks.
    
[^99]: Reef-insight:一种通过遥感进行水域栖息地映射的聚类方法框架

    Reef-insight: A framework for reef habitat mapping with clustering methods via remote sensing. (arXiv:2301.10876v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.10876](http://arxiv.org/abs/2301.10876)

    Reef-Insight是一种利用聚类方法和遥感技术进行珊瑚礁栖息地映射的无监督机器学习框架，通过比较不同的聚类方法，我们发现遥感数据可以有效地用于珊瑚礁栖息地的映射。

    

    环境损害一直是一个重大关注点，特别是在海岸区域和海洋中，考虑到气候变化和污染及极端气候事件的严重影响。我们目前的分析能力以及遥感等信息获取技术的进步，可以用于管理和研究珊瑚礁生态系统。在本文中，我们提出了一种名为Reef-Insight的无监督机器学习框架，它具有先进的聚类方法和遥感技术，用于珊瑚礁栖息地映射。我们的框架通过使用遥感数据比较不同的聚类方法进行珊瑚礁栖息地映射。我们评估了基于定性和视觉评估的四种主要聚类方法，包括k-means、层次聚类、高斯混合模型和密度聚类。我们利用了澳大利亚南大堡礁的One Tree Island珊瑚礁的遥感数据进行试验。我们的研究结果表明，通过遥感数据进行聚类方法可以有效进行珊瑚礁栖息地映射。

    Environmental damage has been of much concern, particularly in coastal areas and the oceans, given climate change and the drastic effects of pollution and extreme climate events. Our present-day analytical capabilities, along with advancements in information acquisition techniques such as remote sensing, can be utilised for the management and study of coral reef ecosystems. In this paper, we present Reef-Insight, an unsupervised machine learning framework that features advanced clustering methods and remote sensing for reef habitat mapping. Our framework compares different clustering methods for reef habitat mapping using remote sensing data. We evaluate four major clustering approaches based on qualitative and visual assessments which include k-means, hierarchical clustering, Gaussian mixture model, and density-based clustering. We utilise remote sensing data featuring the One Tree Island reef in Australia's Southern Great Barrier Reef. Our results indicate that clustering methods usi
    
[^100]: EHRSQL：面向电子病历的实用文本转SQL基准测试

    EHRSQL: A Practical Text-to-SQL Benchmark for Electronic Health Records. (arXiv:2301.07695v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.07695](http://arxiv.org/abs/2301.07695)

    该论文提出了一个面向电子病历数据的文本转SQL数据集，该数据集具有一系列独特挑战，包括生成SQL查询、理解时间表达式以及区分有无答案的问题。

    

    我们为电子病历（EHR）提供了一个新的文本到SQL数据集。对话是由222个医院工作人员包括医生、护士、保险审查和健康档案团队等手机而来。为了构建关于结构化EHR数据的QA数据集，我们在一所大学医院进行了一次民调并制作了模板话术以创建种子问题。然后，我们手动将它们链接到两个开源的EHR数据库（MIMIC-III和eICU）中，并在数据集中包含了来自民意调查的各种时间表达式和未能回答的问题。我们的数据集提出了一系列独特的挑战：模型需要 1）生成反映医院中各种需求的SQL查询，包括简单的检索和复杂的操作，如计算生存率，2）理解各种时间表达式以回答与时间敏感的医疗问题相关的问题，3）根据预测区分给定问题是可回答还是不可回答。

    We present a new text-to-SQL dataset for electronic health records (EHRs). The utterances were collected from 222 hospital staff, including physicians, nurses, insurance review and health records teams, and more. To construct the QA dataset on structured EHR data, we conducted a poll at a university hospital and templatized the responses to create seed questions. Then, we manually linked them to two open-source EHR databases, MIMIC-III and eICU, and included them with various time expressions and held-out unanswerable questions in the dataset, which were all collected from the poll. Our dataset poses a unique set of challenges: the model needs to 1) generate SQL queries that reflect a wide range of needs in the hospital, including simple retrieval and complex operations such as calculating survival rate, 2) understand various time expressions to answer time-sensitive questions in healthcare, and 3) distinguish whether a given question is answerable or unanswerable based on the predicti
    
[^101]: 基于转换器的生物医学语言模型的领域内自适应的本地化

    Localising In-Domain Adaptation of Transformer-Based Biomedical Language Models. (arXiv:2212.10422v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10422](http://arxiv.org/abs/2212.10422)

    本研究针对生物医学领域内自适应问题，探讨了两种途径来在非英语语言中产生生物医学语言模型。一种是通过神经机器翻译将英文资源翻译为目标语言，注重数量；另一种是直接基于高质量、狭谱的语料库进行本地化。这些方法有助于解决资源较少语言如意大利语的领域内适应问题。

    

    在数字医疗时代，医院每天产生的大量文本信息构成了一个重要但未充分利用的资产，可以通过特定任务、精细调整的生物医学语言表示模型来利用，从而改善患者护理和管理。对于这些专门领域，先前的研究表明，来自广覆盖点检的微调模型在大规模领域内资源的额外训练轮次上可以获益很大。然而，这些资源通常对于像意大利这样资源较少的语言是不可及的，使得当地医疗机构无法进行领域内适应。为了缩小这个差距，我们的工作探讨了两种可行的方法来在非英语语言中生成生物医学语言模型，以意大利语为具体案例：一种基于英文资源的神经机器翻译，追求数量而不是质量；另一种基于高质量、狭谱的语料库的方法，直接进行本地化。

    In the era of digital healthcare, the huge volumes of textual information generated every day in hospitals constitute an essential but underused asset that could be exploited with task-specific, fine-tuned biomedical language representation models, improving patient care and management. For such specialized domains, previous research has shown that fine-tuning models stemming from broad-coverage checkpoints can largely benefit additional training rounds over large-scale in-domain resources. However, these resources are often unreachable for less-resourced languages like Italian, preventing local medical institutions to employ in-domain adaptation. In order to reduce this gap, our work investigates two accessible approaches to derive biomedical language models in languages other than English, taking Italian as a concrete use-case: one based on neural machine translation of English resources, favoring quantity over quality; the other based on a high-grade, narrow-scoped corpus natively w
    
[^102]: 怎样解决面对对抗状态的多智能体强化学习问题？

    What is the Solution for State-Adversarial Multi-Agent Reinforcement Learning?. (arXiv:2212.02705v4 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2212.02705](http://arxiv.org/abs/2212.02705)

    本文提出了一种解决面对对抗性状态的多智能体强化学习问题的方法，通过引入状态对抗性马尔科夫博弈，提出了鲁棒智能体策略的概念，并证明了其在有限状态和有限动作情况下的存在性。此外，还提出了一种鲁棒多智能体对抗性演员-评论家算法，用于学习在状态不确定性下的鲁棒性策略。

    

    在多智能体强化学习(MARL)中，已经开发了各种方法，假设智能体的策略基于准确的状态信息。然而，通过深度强化学习(DRL)学习的策略容易受到对抗性状态扰动攻击的影响。在这项工作中，我们提出了一种状态对抗性马尔科夫博弈(SAMG)，并首次尝试研究状态不确定性下MARL的基本属性。我们的分析表明，在SAMG中，通常使用的最优智能体策略和鲁棒纳什均衡解决概念并不总是存在的。为了克服这个困难，我们考虑了一种称为鲁棒智能体策略的新解决概念，其中智能体的目标是最大化最坏情况下的预期状态值。我们证明了有限状态和有限动作SAMG中存在鲁棒智能体策略。此外，我们提出了一种名为鲁棒多智能体对抗性演员-评论家(RMA3C)算法，用于学习在状态不确定性下的MARL智能体的鲁棒性策略。

    Various methods for Multi-Agent Reinforcement Learning (MARL) have been developed with the assumption that agents' policies are based on accurate state information. However, policies learned through Deep Reinforcement Learning (DRL) are susceptible to adversarial state perturbation attacks. In this work, we propose a State-Adversarial Markov Game (SAMG) and make the first attempt to investigate the fundamental properties of MARL under state uncertainties. Our analysis shows that the commonly used solution concepts of optimal agent policy and robust Nash equilibrium do not always exist in SAMGs. To circumvent this difficulty, we consider a new solution concept called robust agent policy, where agents aim to maximize the worst-case expected state value. We prove the existence of robust agent policy for finite state and finite action SAMGs. Additionally, we propose a Robust Multi-Agent Adversarial Actor-Critic (RMA3C) algorithm to learn robust policies for MARL agents under state uncertai
    
[^103]: 可微分的用户模型

    Differentiable User Models. (arXiv:2211.16277v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.16277](http://arxiv.org/abs/2211.16277)

    该研究提出了可微分的用户模型，通过引入可广泛应用的可微分替代品解决了现代先进用户模型与机器学习流程的不兼容性和计算代价过高的问题。实验证明，在线应用中可以实现与现有无似然推理方法相当的建模能力，并展示了在菜单搜索任务中如何利用认知模型进行在线交互。

    

    概率用户建模对于在人机交互中构建机器学习系统至关重要。然而，现代先进的用户模型通常被设计为认知行为模拟器，与现代机器学习流程不兼容，对于大多数实际应用来说计算代价过高。为了解决这个问题，我们引入了可广泛应用的可微分替代品，绕过计算瓶颈，使现代认知模型的推理更高效。通过实验证明，我们可以以适用于在线应用的计算成本实现与现有的无似然推理方法相当的建模能力。最后，我们展示了人工智能助手如何在菜单搜索任务中使用认知模型进行在线交互，而在交互过程中通常需要数小时的计算时间。

    Probabilistic user modeling is essential for building machine learning systems in the ubiquitous cases with humans in the loop. However, modern advanced user models, often designed as cognitive behavior simulators, are incompatible with modern machine learning pipelines and computationally prohibitive for most practical applications. We address this problem by introducing widely-applicable differentiable surrogates for bypassing this computational bottleneck; the surrogates enable computationally efficient inference with modern cognitive models. We show experimentally that modeling capabilities comparable to the only available solution, existing likelihood-free inference methods, are achievable with a computational cost suitable for online applications. Finally, we demonstrate how AI-assistants can now use cognitive models for online interaction in a menu-search task, which has so far required hours of computation during interaction.
    
[^104]: QueryForm: 一种简单的零样本表单实体查询框架

    QueryForm: A Simple Zero-shot Form Entity Query Framework. (arXiv:2211.07730v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.07730](http://arxiv.org/abs/2211.07730)

    QueryForm是一种简单的零样本表单实体查询框架，通过使用双重提示机制和利用大规模查询-实体对进行预训练，能够从结构化文档中提取实体值，无需目标特定的训练数据，达到了新的最先进技术水平。

    

    零样本迁移学习对于文档理解是一个至关重要但未被充分研究的场景，有助于减少标注文档实体所需的高成本。我们提出了一种新颖的基于查询的框架QueryForm，该框架以零样本的方式从类似表单的文档中提取实体值。QueryForm包含一个双重提示机制，将文档模式和特定实体类型组合成一个查询，用于提示Transformer模型执行单个实体提取任务。此外，我们提议利用从类似表单的网页生成的大规模查询-实体对进行QueryForm的预训练，这些网页带有弱HTML注释。通过将预训练和微调统一到相同的基于查询的框架中，QueryForm使模型能够从包含各种实体和布局的结构化文档中学习，从而更好地推广到目标文档类型，无需目标特定的训练数据。QueryForm在平均水平上建立了新的最先进技术水平。

    Zero-shot transfer learning for document understanding is a crucial yet under-investigated scenario to help reduce the high cost involved in annotating document entities. We present a novel query-based framework, QueryForm, that extracts entity values from form-like documents in a zero-shot fashion. QueryForm contains a dual prompting mechanism that composes both the document schema and a specific entity type into a query, which is used to prompt a Transformer model to perform a single entity extraction task. Furthermore, we propose to leverage large-scale query-entity pairs generated from form-like webpages with weak HTML annotations to pre-train QueryForm. By unifying pre-training and fine-tuning into the same query-based framework, QueryForm enables models to learn from structured documents containing various entities and layouts, leading to better generalization to target document types without the need for target-specific training data. QueryForm sets new state-of-the-art average 
    
[^105]: 层次混合多标签分类在不平衡的跨学科研究提案中的应用

    Hierarchical MixUp Multi-label Classification with Imbalanced Interdisciplinary Research Proposals. (arXiv:2209.13912v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2209.13912](http://arxiv.org/abs/2209.13912)

    层次混合多标签分类方法用于解决不平衡的跨学科研究提案中的独特问题，包括层次结构的标签、异构的语义和不平衡的数量。

    

    资助机构依赖于领域专家和研究提案之间的主题匹配来指定提案审阅人。随着提案越来越跨学科，如何准确地对提案的跨学科性质进行建模和分类，并找到具有合适专业知识的专家审阅人变得具有挑战性。解决这一挑战的关键步骤是准确地对提案的跨学科标签进行建模和分类。现有的方法和应用相关文献，如文本分类和提案分类，在同时解决由跨学科提案数据引入的三个关键问题方面还不足：1）提案的学科标签具有从粗粒度到细粒度的层次结构，例如从信息科学到AI到AI的基本原理。2）各个主要文本部分具有异构的语义，起不同的作用。3）提案的数量在各个标签之间是不平衡的。

    Funding agencies are largely relied on a topic matching between domain experts and research proposals to assign proposal reviewers. As proposals are increasingly interdisciplinary, it is challenging to profile the interdisciplinary nature of a proposal, and, thereafter, find expert reviewers with an appropriate set of expertise. An essential step in solving this challenge is to accurately model and classify the interdisciplinary labels of a proposal. Existing methodological and application-related literature, such as textual classification and proposal classification, are insufficient in jointly addressing the three key unique issues introduced by interdisciplinary proposal data: 1) the hierarchical structure of discipline labels of a proposal from coarse-grain to fine-grain, e.g., from information science to AI to fundamentals of AI. 2) the heterogeneous semantics of various main textual parts that play different roles in a proposal; 3) the number of proposals is imbalanced between no
    
[^106]: 基于注意力的元宇宙xURLLC服务资源分配和QoE分析

    Attention-aware Resource Allocation and QoE Analysis for Metaverse xURLLC Services. (arXiv:2208.05438v5 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2208.05438](http://arxiv.org/abs/2208.05438)

    本文研究了元宇宙xURLLC服务资源分配和QoE分析，提出了一个最优合同设计框架。在数学上模拟QoE的新型度量标准Meta-Immersion有助于在满足客户端物理需求的情况下，提供个性化沉浸式体验。

    

    元宇宙代表了我们对下一代互联网的期望，并带来了新的关键绩效指标（KPI） 。虽然传统的超可靠性和低时延通信（URLLC）可以满足客观的KPI，但很难提供个性化的沉浸式体验，这是元宇宙的独特特点。由于体验质量（QoE）可以被视为综合的KPI，因此URLLC被演变为具有个性化资源分配方案的下一代URLLC（xURLLC）来实现更高的QoE。为了部署元宇宙xURLLC服务，我们研究了元宇宙服务提供商（MSP）和网络基础设施提供商（InP）之间的交互，并提供了一个最优合同设计框架。具体而言，我们旨在最大化MSP的效用，该效用被定义为元宇宙用户QoE的函数，同时确保InP的激励。为了在数学上模拟QoE，我们提出了一个名为Meta-Immersion的新型度量标准。

    Metaverse encapsulates our expectations of the next-generation Internet, while bringing new key performance indicators (KPIs). Although conventional ultra-reliable and low-latency communications (URLLC) can satisfy objective KPIs, it is difficult to provide a personalized immersive experience that is a distinctive feature of the Metaverse. Since the quality of experience (QoE) can be regarded as a comprehensive KPI, the URLLC is evolved towards the next generation URLLC (xURLLC) with a personalized resource allocation scheme to achieve higher QoE. To deploy Metaverse xURLLC services, we study the interaction between the Metaverse service provider (MSP) and the network infrastructure provider (InP), and provide an optimal contract design framework. Specifically, the utility of the MSP, defined as a function of Metaverse users' QoE, is to be maximized, while ensuring the incentives of the InP. To model the QoE mathematically, we propose a novel metric named Meta-Immersion that incorporat
    
[^107]: 迈向KAB2S: 从单目标问题到多目标问题学习关键知识

    Towards KAB2S: Learning Key Knowledge from Single-Objective Problems to Multi-Objective Problem. (arXiv:2206.12906v2 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2206.12906](http://arxiv.org/abs/2206.12906)

    本文是进化传输优化（ETO）领域的一项重要工作，通过将多目标优化问题与单目标优化问题相结合，提出了一个新的核心传输机制和学习技术，可以在离散情况下实现智能调度和绿色调度的目标。

    

    作为“进化计算研究的新的前沿”，进化传输优化（ETO）将克服传统范式中在进化计算研究中对已解决过的相关经验和知识的零重用。在通过ETO进行调度应用中，可以形成一个非常吸引人且竞争激烈的框架，尤其对于中国提出的“碳中和”国际承诺来说，这将为智能调度和绿色调度提供一次“会面”的机会。据我们所知，我们关于调度的这篇论文是一个ETO框架类的作品中的第一项工作，该框架将多目标优化问题与离散情况下的单目标优化问题“碰撞”（而不是多任务优化）。更具体地说，通过新的核心传输机制和学习技术，可以传递给工业应用的关键知识，例如基于遗传算法设置的位置构建块，可以用于置换流水车间问题。

    As "a new frontier in evolutionary computation research", evolutionary transfer optimization(ETO) will overcome the traditional paradigm of zero reuse of related experience and knowledge from solved past problems in researches of evolutionary computation. In scheduling applications via ETO, a quite appealing and highly competitive framework "meeting" between them could be formed for both intelligent scheduling and green scheduling, especially for international pledge of "carbon neutrality" from China. To the best of our knowledge, our paper on scheduling here, serves as the 1st work of a class of ETO frameworks when multiobjective optimization problem "meets" single-objective optimization problems in discrete case (not multitasking optimization). More specifically, key knowledge conveyed for industrial applications, like positional building blocks with genetic algorithm based settings, could be used via the new core transfer mechanism and learning techniques for permutation flow shop s
    
[^108]: ETO与调度：从单目标问题到多目标问题学习关键知识

    ETO Meets Scheduling: Learning Key Knowledge from Single-Objective Problems to Multi-Objective Problem. (arXiv:2206.12902v2 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2206.12902](http://arxiv.org/abs/2206.12902)

    本研究是第一个将ETO应用于多目标问题和组合问题中的调度问题的工作。通过从解决单目标问题中学习和迁移关键知识，我们提出的ETO-PFSP框架在排列流水车间调度问题中展示了相对有效和很大的潜力。

    

    进化传递优化（ETO）被视为“进化计算研究的新领域”，它避免了传统进化计算中从已解决问题中零重用经验和知识的问题。在ETO的调度应用中，它们之间可以构建一个高度竞争的“交流”框架，实现智能调度和绿色调度，特别是在中国的碳中和背景下。据我们所知，我们对调度问题的研究是ETO在多目标问题“遇见”组合问题（而不是多任务优化）的第一个工作。具体来说，像位置构建块聚类这样的关键知识可以用于排列流水车间调度问题（PFSP）。对于经过深入研究的基准测试，实证研究验证了我们提出的ETO-PFSP框架的相对有效性和巨大潜力。

    Evolutionary transfer optimization(ETO) serves as "a new frontier in evolutionary computation research", which will avoid zero reuse of experience and knowledge from solved problems in traditional evolutionary computation. In scheduling applications via ETO, a highly competitive "meeting" framework between them could be constituted towards both intelligent scheduling and green scheduling, especially for carbon neutrality within the context of China. To the best of our knowledge, our study on scheduling here, is the 1st work of ETO for complex optimization when multiobjective problem "meets" single-objective problems in combinatorial case (not multitasking optimization). More specifically, key knowledge like positional building blocks clustered, could be learned and transferred for permutation flow shop scheduling problem (PFSP). Empirical studies on well-studied benchmarks validate relatively firm effectiveness and great potential of our proposed ETO-PFSP framework.
    
[^109]: 本地字节融合用于神经机器翻译

    Local Byte Fusion for Neural Machine Translation. (arXiv:2205.11490v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2205.11490](http://arxiv.org/abs/2205.11490)

    本文提出了一种基于字节的本地字节融合方法，用于神经机器翻译。该方法可以解决当前NLP模型中子词标记化方案的刚性和对其他语料库适应性差的问题，同时避免了在多语种语料库中过度切分低资源语言的影响。

    

    当前NLP模型中，子词标记化方案是主要的技术。然而，这种方案可能过于死板，并且在一个语料库上构建的标记器对其他平行语料库的适应性不佳。观察发现，在多语种语料库中，子词标记化方案会对低资源语言进行过度切分，从而导致翻译性能下降。子词标记化的一个简单替代方法是基于字节的方法，即使用编码方案（如UTF-8）将输入进行字节序列标记化。字节标记通常在子字符粒度上表示输入，即一个字符可以由多个字节标记序列表示。这导致字节序列比字符序列长得多。在较低层中强制执行局部信息的聚合可以指导模型构建更高层次的语义信息。我们提出了一种利用字节n-gram和单词边界的本地字节融合（LOBEF）方法用于基于字节的机器翻译。

    Subword tokenization schemes are the dominant technique used in current NLP models. However, such schemes can be rigid and tokenizers built on one corpus do not adapt well to other parallel corpora. It has also been observed that in multilingual corpora, subword tokenization schemes over-segment low-resource languages leading to a drop in translation performance. A simple alternative to subword tokenizers is byte-based methods i.e. tokenization into byte sequences using encoding schemes such as UTF-8. Byte tokens often represent inputs at a sub-character granularity i.e. one character can be represented by a sequence of multiple byte tokens. This results in byte sequences that are significantly longer than character sequences. Enforcing aggregation of local information in the lower layers can guide the model to build higher-level semantic information. We propose a Local Byte Fusion (LOBEF) method for byte-based machine translation -- utilizing byte $n$-gram and word boundaries -- to ag
    
[^110]: 通过隐式复合核将先验知识融入神经网络

    Incorporating Prior Knowledge into Neural Networks through an Implicit Composite Kernel. (arXiv:2205.07384v7 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.07384](http://arxiv.org/abs/2205.07384)

    本论文提出了一种通过深度学习和高斯过程的复合核来将先验知识融入神经网络的方法。通过隐式定义的神经网络核函数和选择的第二个核函数，可以模拟已知特性，并提高深度学习应用的性能。

    

    引导神经网络（NN）学习以先验知识是具有挑战性的。相比之下，许多已知特性，如空间平滑性或季节性，在高斯过程（GP）中通过选择适当的核函数来建模是直接的。许多深度学习应用可以通过建模这些已知特性来改进。例如，卷积神经网络（CNNs）广泛用于遥感，这受到强烈的季节效应影响。我们提出通过使用由神经网络隐式定义的核函数与选择用于建模已知特性的第二个核函数（例如季节性）相结合的复合核来结合深度学习和GP的建模能力。我们通过将深度网络和基于Nystrom近似的高效映射相结合来实现这一想法，将其称为隐式复合核（ICK）。然后，我们采用样本优化的方法来近似完整的GP后验分布。我们证明了ICK的有效性，并在遥感和时间序列的任务上进行了实验。

    It is challenging to guide neural network (NN) learning with prior knowledge. In contrast, many known properties, such as spatial smoothness or seasonality, are straightforward to model by choosing an appropriate kernel in a Gaussian process (GP). Many deep learning applications could be enhanced by modeling such known properties. For example, convolutional neural networks (CNNs) are frequently used in remote sensing, which is subject to strong seasonal effects. We propose to blend the strengths of deep learning and the clear modeling capabilities of GPs by using a composite kernel that combines a kernel implicitly defined by a neural network with a second kernel function chosen to model known properties (e.g., seasonality). We implement this idea by combining a deep network and an efficient mapping based on the Nystrom approximation, which we call Implicit Composite Kernel (ICK). We then adopt a sample-then-optimize approach to approximate the full GP posterior distribution. We demons
    
[^111]: 以插槽为中心的模型在测试时的适应性

    Test-time Adaptation with Slot-Centric Models. (arXiv:2203.11194v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2203.11194](http://arxiv.org/abs/2203.11194)

    本论文提出了一种以插槽为中心的模型，用于解析分布外的场景，并通过测试时自适应来提高模型性能。通过结合自监督损失和建模偏差，该模型在场景分解任务上取得了良好的效果。

    

    当前的视觉检测器在训练分布内表现出色，但通常无法将分布外的场景解析为其组成实体。最近的测试时适应方法使用辅助的自监督损失来独立地调整网络参数，已经在图像分类任务中显示出在训练分布之外的泛化结果。在我们的研究中，我们发现这些损失对于场景分解任务来说是不足的，因为它们没有考虑到建模偏差。最近的以插槽为中心的生成模型尝试以自监督的方式将场景分解为实体，通过重建像素来实现。结合这两个工作线路，我们提出了一种半监督的插槽为中心的场景分解模型，即Slot-TTA，在测试时通过重建或交叉视图综合目标在每个场景上进行梯度下降适应。我们对Slot-TTA在多种输入模式上进行评估。

    Current visual detectors, though impressive within their training distribution, often fail to parse out-of-distribution scenes into their constituent entities. Recent test-time adaptation methods use auxiliary self-supervised losses to adapt the network parameters to each test example independently and have shown promising results towards generalization outside the training distribution for the task of image classification. In our work, we find evidence that these losses are insufficient for the task of scene decomposition, without also considering architectural inductive biases. Recent slot-centric generative models attempt to decompose scenes into entities in a self-supervised manner by reconstructing pixels. Drawing upon these two lines of work, we propose Slot-TTA, a semi-supervised slot-centric scene decomposition model that at test time is adapted per scene through gradient descent on reconstruction or cross-view synthesis objectives. We evaluate Slot-TTA across multiple input mo
    
[^112]: 高模态多模态Transformer：量化模态与交互异质性以进行高模态表示学习

    High-Modality Multimodal Transformer: Quantifying Modality & Interaction Heterogeneity for High-Modality Representation Learning. (arXiv:2203.01311v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2203.01311](http://arxiv.org/abs/2203.01311)

    本文研究了高模态场景下的高效表示学习，提出了两种新的信息论度量方法来量化模态和交互的异质性，以加速对多样化和少被研究的模态的推广。 (arXiv:2203.01311v4 [cs.LG] UPDATED)

    

    许多现实世界的问题本质上是多模态的，例如人类用于交流的口语、手势和语用学，以及机器人上的力、本体感和视觉传感器。虽然多模态学习引起了广泛的兴趣，但这些方法主要关注一小组模态，主要是语言、视觉和音频。为了加速向多样化和少被研究的模态推广，本文研究了高模态场景下的高效表示学习，涉及一个大量的不同模态。由于为每个新模态添加新模型变得代价过高，关键的技术挑战是异质性量化：我们如何衡量哪些模态编码了类似的信息和交互，以便允许与先前的模态共享参数？本文提出了两种新的信息论度量方法来量化异质性：(1)模态异质性研究了两个模态之间的相似性。

    Many real-world problems are inherently multimodal, from spoken language, gestures, and paralinguistics humans use to communicate, to force, proprioception, and visual sensors on robots. While there has been an explosion of interest in multimodal learning, these methods are focused on a small set of modalities primarily in language, vision, and audio. In order to accelerate generalization towards diverse and understudied modalities, this paper studies efficient representation learning for high-modality scenarios involving a large set of diverse modalities. Since adding new models for every new modality becomes prohibitively expensive, a critical technical challenge is heterogeneity quantification: how can we measure which modalities encode similar information and interactions in order to permit parameter sharing with previous modalities? This paper proposes two new information theoretic metrics for heterogeneity quantification: (1) modality heterogeneity studies how similar 2 modalitie
    
[^113]: 用于痴呆监测和诊断的纵向多模态数据集

    A Longitudinal Multi-modal Dataset for Dementia Monitoring and Diagnosis. (arXiv:2109.01537v1 [cs.CL] CROSS LISTED)

    [http://arxiv.org/abs/2109.01537](http://arxiv.org/abs/2109.01537)

    该论文提出了一个纵向多模态数据集，用于痴呆监测和诊断。通过分析语言、言语和语用指标，可以区分神经退行性疾病患者和对照组，从而为痴呆研究提供了宝贵的资源。

    

    痴呆是一系列神经退行性疾病，影响越来越多的全球老龄人口的记忆和认知能力。自动化分析语言、言语和语用指标作为认知衰退的潜在指标日益受到关注。在这里，我们提出了一个新颖的纵向多模态数据集，该数据集在自然环境下收集了轻度痴呆患者和配对的年龄匹配对照组的数据，时间跨度为几个月。多模态数据包括口头会话，其中的一部分被转录，以及输入和书写的思考内容，以及相关的非语言信息，如笔画和按键。我们详细描述了该数据集，并着重讨论了使用语音模态的任务。后者涉及利用数据的纵向特性来区分对照组和痴呆患者。我们的实验显示，会话间语音的变化在不同的会话之间存在显著差异。

    Dementia is a family of neurogenerative conditions affecting memory and cognition in an increasing number of individuals in our globally aging population. Automated analysis of language, speech and paralinguistic indicators have been gaining popularity as potential indicators of cognitive decline. Here we propose a novel longitudinal multi-modal dataset collected from people with mild dementia and age matched controls over a period of several months in a natural setting. The multi-modal data consists of spoken conversations, a subset of which are transcribed, as well as typed and written thoughts and associated extra-linguistic information such as pen strokes and keystrokes. We describe the dataset in detail and proceed to focus on a task using the speech modality. The latter involves distinguishing controls from people with dementia by exploiting the longitudinal nature of the data. Our experiments showed significant differences in how the speech varied from session to session in the 
    

