# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [BerDiff: Conditional Bernoulli Diffusion Model for Medical Image Segmentation.](http://arxiv.org/abs/2304.04429) | 提出了针对医学图像分割的条件伯努利扩散模型（BerDiff），使用伯努利噪声作为扩散核增强了扩散模型的二进制分割任务能力，并通过随机采样初噪声生成多样的分割掩模，实验结果表明其在准确性和多样性方面优于其他最先进的方法。 |
| [^2] | [PCR: Proxy-based Contrastive Replay for Online Class-Incremental Continual Learning.](http://arxiv.org/abs/2304.04408) | 本文提出了一种名为PCR的基于代理的对比式回放方法，它能够有效地解决在线类增量连续学习中的历史知识遗忘问题。经实验证明，在两个视觉数据集上，PCR能够显著优于现有方法。 |
| [^3] | [H2RBox-v2: Boosting HBox-supervised Oriented Object Detection via Symmetric Learning.](http://arxiv.org/abs/2304.04403) | H2RBox-v2是第一个将对称学习应用于基于HBox监督的有向物体检测，其强化了水平注释和旋转注释之间的联系，在多个基准测试中实现了最先进的性能。 |
| [^4] | [CAVL: Learning Contrastive and Adaptive Representations of Vision and Language.](http://arxiv.org/abs/2304.04399) | 本文提出了一种对比自适应的视觉与语言表示学习方法CAVL，在预训练过程中通过对比损失学习整个句子和图像之间的对齐，并在微调阶段引入轻量级自适应网络，实现在下游任务中的最先进效果。 |
| [^5] | [CAFIN: Centrality Aware Fairness inducing IN-processing for Unsupervised Representation Learning on Graphs.](http://arxiv.org/abs/2304.04391) | CAFIN是一种基于节点中心性的公平性增强进程技术，用于无监督学习的图表示学习方法中。实验结果表明，CAFIN在提供最优公平结果的同时，具有竞争力或更好的下游任务性能。 |
| [^6] | [Deep Active Alignment of Knowledge Graph Entities and Schemata.](http://arxiv.org/abs/2304.04389) | 本文提出了一种基于深度学习和主动学习的KG对齐方法DAAKG，可以联合对齐不仅实体，还包括关系和类别；通过主动学习选择最佳批次进行人工标注，实验结果显示其优越精度和泛化性。 |
| [^7] | [OpenAGI: When LLM Meets Domain Experts.](http://arxiv.org/abs/2304.04370) | 基于大型语言模型的OpenAGI平台通过整合领域专家模型和自然语言问答形式，实现复杂任务解决。 |
| [^8] | [WebBrain: Learning to Generate Factually Correct Articles for Queries by Grounding on Large Web Corpus.](http://arxiv.org/abs/2304.04358) | 本文讲述了一种新的自然语言处理任务——WebBrain，它通过挖掘Web中的支持证据，为查询生成事实正确简短文章。我们从维基百科中提取了数据集WebBrain-Raw，构建了WebBrain-R和WebBrain-G数据集。我们还介绍了一个新的生成事实性的框架ReGen。 |
| [^9] | [A Novel Point-based Algorithm for Multi-agent Control Using the Common Information Approach.](http://arxiv.org/abs/2304.04346) | 本文提出了基于公共信息方法的新型多智能体控制算法，结合点处理POMDP算法，解决了行动空间庞大的问题。 |
| [^10] | [Is ChatGPT a Good Sentiment Analyzer? A Preliminary Study.](http://arxiv.org/abs/2304.04339) | 本文对ChatGPT作为情感分析器进行了初步评估，包括标准评估、极性转移评估、开放域评估和情感推理评估，共涉及18个数据集和5个情感分析任务。与经过微调的BERT和最先进的模型进行了对比，并进行了人工评估和案例研究。 |
| [^11] | [ARNOLD: A Benchmark for Language-Grounded Task Learning With Continuous States in Realistic 3D Scenes.](http://arxiv.org/abs/2304.04321) | ARNOLD是一个评估基于语言引导、具有连续状态的现实3D场景任务学习的基准测试，涉及8个语言条件任务，在语言引导下帮助机器人学习理解物体状态和学习连续目标的策略。 |
| [^12] | [Ensemble Modeling for Time Series Forecasting: an Adaptive Robust Optimization Approach.](http://arxiv.org/abs/2304.04308) | 本文提出了一种基于自适应鲁棒优化的方法，用于构建强鲁棒性的时间序列预测模型集成，取得了比最佳集成成员更好的表现。 |
| [^13] | [Class-Imbalanced Learning on Graphs: A Survey.](http://arxiv.org/abs/2304.04300) | 本文综述了现有CILG技术的最新状态，提出了一个现有工作的分类法，并讨论了未来研究方向。CILG作为一种有前途的解决方案，将图表示学习和类别不平衡学习相结合，用于克服现实世界数据中的类别不平衡问题。 |
| [^14] | [Distributed Conditional GAN (discGAN) For Synthetic Healthcare Data Generation.](http://arxiv.org/abs/2304.04290) | 本文提出了一种分布式生成对抗网络（discGAN）用于生成医疗保健领域的合成表格数据，并且在应用中成功模拟出非高斯多模式医疗保健数据的分布，其生成的数据分布与真实数据相似。 |
| [^15] | [FrenchMedMCQA: A French Multiple-Choice Question Answering Dataset for Medical domain.](http://arxiv.org/abs/2304.04280) | FrenchMedMCQA是法语医学MCQA数据集，包含3,105道真实考试题目。需要使用医学领域或MCQA任务专用的表示形式来获得更好的性能。 |
| [^16] | [Embarrassingly Simple MixUp for Time-series.](http://arxiv.org/abs/2304.04271) | 本研究针对时间序列数据提出了一种基于MixUp的数据增强方法，即MixUp++和LatentMixUp++，能够显著提高1％- 15％的分类准确率，尤其适用于有限标记数据的情况，并通过半监督学习扩展到无标签数据。 |
| [^17] | [Secure Routing Protocol To Mitigate Attacks By Using Blockchain Technology In Manet.](http://arxiv.org/abs/2304.04254) | 论文提出了一种采用区块链技术的安全路由算法（SRABC），该算法通过提供源节点到目的节点的安全、经过认证和防篡改的路由来保护控制和数据流，预防MANET受到各种攻击手段，并对节点进行认证。仿真结果表明，SRABC算法优于当前方法，是确保MANET安全的可行选项。 |
| [^18] | [Video ChatCaptioner: Towards the Enriched Spatiotemporal Descriptions.](http://arxiv.org/abs/2304.04227) | Video ChatCaptioner是一种创新方法，利用ChatGPT和算法生成全面和丰富的时空视频描述。 |
| [^19] | [Transformer Utilization in Medical Image Segmentation Networks.](http://arxiv.org/abs/2304.04225) | Transformer在医学图像分割中最有效的设计是伴随着显式的特征层次结构，而单独使用不能防止表示的可替换性；应慎用主要空间下采样操作。 |
| [^20] | [The Study of Highway for Lifelong Multi-Agent Path Finding.](http://arxiv.org/abs/2304.04217) | 本研究旨在解决终身多智能体路径规划问题中出现的运行时间指数增长和死锁、重新路由等不良现象。我们将高速公路的概念纳入终身多智能体路径规划框架中，并通过两种方法实现，成功减少了问题的复杂度，缩短了运行时间并提高了吞吐量。 |
| [^21] | [OpenDriver: an open-road driver state detection dataset.](http://arxiv.org/abs/2304.04203) | OpenDriver是一份旨在解决现有驾驶员生理数据集存在问题的开放路况驾驶员状态检测数据集，包含六轴惯性信号和心电图信号两种模态的数据，可用于驾驶员受损检测和生物识别数据识别。 |
| [^22] | [Team QUST at SemEval-2023 Task 3: A Comprehensive Study of Monolingual and Multilingual Approaches for Detecting Online News Genre, Framing and Persuasion Techniques.](http://arxiv.org/abs/2304.04190) | 本文研究了单语和多语方法来检测在线新闻的类型、框架和说服技巧，并发现多语方法比单语方法更好，使用类权重和样本权重的组合对预训练的多语模型进行微调可用于应对多数类不平衡的问题，在SemEval2023任务3中提交的系统在意大利语和西班牙语（零样本）的子任务1中排名第二。 |
| [^23] | [Gradient Sparsification for Efficient Wireless Federated Learning with Differential Privacy.](http://arxiv.org/abs/2304.04164) | 本文提出了一种基于梯度稀疏化和差分隐私的无线联合学习框架，使用随机稀疏化算法缓解DP引起的性能下降，并减少上传的参数数量，提高训练效率而不损失收敛性能。 |
| [^24] | [RoboPianist: A Benchmark for High-Dimensional Robot Control.](http://arxiv.org/abs/2304.04150) | RoboPianist是一个新的高维机器人控制基准测试，旨在测试高精度、协调和规划，并通过反复接触的欠驱动系统进行钢琴演奏。该基准测试提供了性能特征的定量数据，并具有易于解释的结果。 |
| [^25] | [FedPNN: One-shot Federated Classification via Evolving Clustering Method and Probabilistic Neural Network hybrid.](http://arxiv.org/abs/2304.04147) | 本文提出了一种两阶段联邦学习方法，通过进化聚类方法和概率神经网络的混合来实现一次联邦学习分类，以保护隐私并解决通信开销和有限资源的问题。 |
| [^26] | [NeRF applied to satellite imagery for surface reconstruction.](http://arxiv.org/abs/2304.04133) | 本文提出了Sat-NeRF模型，能够从少量的卫星图像集合中合成新的视角，并准确地估计场景表面的高程。 |
| [^27] | [Surrogate Lagrangian Relaxation: A Path To Retrain-free Deep Neural Network Pruning.](http://arxiv.org/abs/2304.04120) | 本文提出了一种基于替代拉格朗日松弛的系统权重剪枝优化方法，可加快模型剪枝问题的收敛速度，并在深度神经网络上得到了显著效果，无需重新训练。 |
| [^28] | [TC-VAE: Uncovering Out-of-Distribution Data Generative Factors.](http://arxiv.org/abs/2304.04103) | 本文提出了一种基于总相关性的生成模型TC-VAE，可以揭示数据生成因素中的未知分布数据，在处理具有不平衡生成因素的数据集上表现优秀。 |
| [^29] | [Interpretable Multi Labeled Bengali Toxic Comments Classification using Deep Learning.](http://arxiv.org/abs/2304.04087) | 本文提出了一种基于深度学习的方法，用于分类孟加拉语的有害评论。使用LSTM和BERT嵌入实现了二元分类任务的高准确率，同时使用卷积神经网络和双向LSTM与注意机制组合实现了多标签分类，准确率和加权F1-score均较高。 |
| [^30] | [Improving Performance Insensitivity of Large-scale Multiobjective Optimization via Monte Carlo Tree Search.](http://arxiv.org/abs/2304.04071) | 本论文提出了一种能同时提高大规模多目标优化算法性能和不敏感性的方法，该方法利用蒙特卡罗树搜索。 |
| [^31] | [A Recommender System Approach for Very Large-scale Multiobjective Optimization.](http://arxiv.org/abs/2304.04067) | 本论文提出了一种基于推荐系统的大规模多目标优化方法，将解决方案视为用户，通过汤普森抽样和高斯过程逼近 Pareto-最优前沿上的后验分布，成功解决了处理大规模问题的难题。 |
| [^32] | [Predicting multiple sclerosis disease severity with multimodal deep neural networks.](http://arxiv.org/abs/2304.04062) | 本研究提出使用患者的多模态EHR数据预测多发性硬化症疾病严重程度，以便实现早期干预和治疗。提高了预测准确性和模型复杂度。 |
| [^33] | [tmn at SemEval-2023 Task 9: Multilingual Tweet Intimacy Detection using XLM-T, Google Translate, and Ensemble Learning.](http://arxiv.org/abs/2304.04054) | 本文介绍了对于SemEval-2023的任务9，提出了一种基于transformer的系统，使用了集成学习，在多语言推特亲密度检测中排名第4，达到了0.5688的宏平均F1分数。为了提高对未见语言的性能表现，每个推特都进行了英文翻译的补充。 |
| [^34] | [Decoder-Only or Encoder-Decoder? Interpreting Language Model as a Regularized Encoder-Decoder.](http://arxiv.org/abs/2304.04052) | 该论文通过对正则化编码器-解码器结构进行比较，分析了仅解码器语言模型框架和编码器-解码器框架的效果。 |
| [^35] | [RescueSNN: Enabling Reliable Executions on Spiking Neural Network Accelerators under Permanent Faults.](http://arxiv.org/abs/2304.04041) | RescueSNN是一种用于减轻SNN芯片计算引擎中永久故障的方法，可维持性能和质量并减少重新训练成本。 |
| [^36] | [EnforceSNN: Enabling Resilient and Energy-Efficient Spiking Neural Network Inference considering Approximate DRAMs for Embedded Systems.](http://arxiv.org/abs/2304.04039) | EnforceSNN 提出了一个新的设计框架，在嵌入式系统中考虑近似DRAM，使用量化权重降低DRAM的访问能量，实现了弹性和节能的SNN推理。 |
| [^37] | [WikiGoldSK: Annotated Dataset, Baselines and Few-Shot Learning Experiments for Slovak Named Entity Recognition.](http://arxiv.org/abs/2304.04026) | 本研究介绍了第一个具有可观规模的人工标记的斯洛伐克NER数据集WikiGoldSK，通过评估当前最先进的多语言预训练语言模型，与现有的银标准数据集进行比较，并进行了少样本实验。银标准数据集上的训练能够产生更好的结果。 |
| [^38] | [A Reinforcement Learning-assisted Genetic Programming Algorithm for Team Formation Problem Considering Person-Job Matching.](http://arxiv.org/abs/2304.04022) | 研究提出了一种强化学习辅助遗传规划算法来解决考虑人-工匹配的团队组建问题，采用集合种群策略和代理模型加快算法学习过程，实现勘探和利用的平衡。 |
| [^39] | [REDf: A Renewable Energy Demand Forecasting Model for Smart Grids using Long Short Term Memory Network.](http://arxiv.org/abs/2304.03997) | 本文提出了一种基于长短期记忆网络的智能电网可再生能源需求预测模型REDf，可以提供准确的能量需求预测，改善可再生能源的集成，实验结果表明其准确度优于其他模型。 |
| [^40] | [DREAM: Adaptive Reinforcement Learning based on Attention Mechanism for Temporal Knowledge Graph Reasoning.](http://arxiv.org/abs/2304.03984) | DREAM提出了一种自适应的强化学习模型，基于注意力机制用于时间知识图谱推理，能够预测未来的缺失元素和理解推理路径。 |
| [^41] | [EMP-SSL: Towards Self-Supervised Learning in One Training Epoch.](http://arxiv.org/abs/2304.03977) | 本文介绍了一种名为EMP-SSL的自监督学习方法，它通过增加每个图像实例的裁剪数量来提高学习效率，缩短了训练时代数量，并在CIFAR-10、CIFAR-100、Tiny ImageNet和ImageNet-100数据集上仅使用一次训练时代而获得了竞争性能。 |
| [^42] | [Benchmarking the Robustness of Quantized Models.](http://arxiv.org/abs/2304.03968) | 量化模型在受到各种噪声的影响时表现出脆弱性，较低位的量化对抗攻击更具弹性，但更容易受到自然扰动和系统噪声的影响。 |
| [^43] | [MphayaNER: Named Entity Recognition for Tshivenda.](http://arxiv.org/abs/2304.03952) | MphayaNER是第一个适用于茨汉文达语的NER语料库，研究通过在语料库上微调最先进的模型，探索了茨文达语与其他相关班图语之间的零样本转移。用chiShona数据扩充MphayaNER可以显著提高模型性能。 |
| [^44] | [Capturing dynamical correlations using implicit neural representations.](http://arxiv.org/abs/2304.03949) | 本文提出一种结合了神经网络和自动区分技术的新方法，在实验数据中恢复未知参数，可以方便地建立和训练可区分模型以分析集体激发。 |
| [^45] | [Unsupervised Speech Representation Pooling Using Vector Quantization.](http://arxiv.org/abs/2304.03940) | 该论文提出了一种新颖的无监督语音表示池化方法，通过矢量量化压缩声学上相似的表示，不需要额外的训练，并在多个下游任务上进行了评估和分析。 |
| [^46] | [Comparing Code Explanations Created by Students and Large Language Models.](http://arxiv.org/abs/2304.03938) | 该论文探讨了采用大型语言模型生成代码解释的潜力，以帮助学生提高理解和解释代码的能力。 |
| [^47] | [3D GANs and Latent Space: A comprehensive survey.](http://arxiv.org/abs/2304.03932) | 3D GAN是生成三维重建、点云重建和3D语义场景完成的新型生成模型。选择噪声分布对应着潜空间，理解其结构有助于微调生成样本。该论文综述了3D GAN及其训练方法，针对未来研究提出了潜在方向。 |
| [^48] | [Mitigating Spurious Correlations in Multi-modal Models during Fine-tuning.](http://arxiv.org/abs/2304.03916) | 本文提出了一种使用多模态对比损失函数的方法，通过在微调期间检测和明确区分受影响类别的错误属性，缓解多模态模型的错误相关性，同时提高模型精度和指向目标领域的有意义特征。 |
| [^49] | [InstructBio: A Large-scale Semi-supervised Learning Paradigm for Biochemical Problems.](http://arxiv.org/abs/2304.03906) | InstructBio是一种针对生物化学问题的大规模半监督学习算法，引入教练模型提供有效的置信度比率来指导目标模型对不同数据点给予明显关注，避免依赖有限的标记数据和不正确的伪注释，提高了分子模型的泛化能力。 |
| [^50] | [High-Fidelity Clothed Avatar Reconstruction from a Single Image.](http://arxiv.org/abs/2304.03903) | 本文提出了一种基于优化和学习相结合的高效三维着装人物重建框架，能够从单张图像中生成高保真度的三维人物。 |
| [^51] | [The Short Text Matching Model Enhanced with Knowledge via Contrastive Learning.](http://arxiv.org/abs/2304.03898) | 提出了一种短文本匹配模型，使用生成模型生成补充句子，结合对比学习和外部知识进行语义匹配，并使用关键词避免噪声问题。 |
| [^52] | [Towards Automated Urban Planning: When Generative and ChatGPT-like AI Meets Urban Planning.](http://arxiv.org/abs/2304.03892) | 本文探讨了城市规划与人工智能的交叉应用，重点是自动化用地配置，通过对抗学习、生成神经网络、深度编码器-解码器网络、对话式 AI 和地理空间和时间机器学习等技术，AI 可以为现代城市规划带来不少创新与贡献。 |
| [^53] | [Conservative objective models are a special kind of contrastive divergence-based energy model.](http://arxiv.org/abs/2304.03866) | 本文证明了在离线基于模型的优化中，保守的客观模型（COMs）是一种特殊的基于对比散度能量模型，同时提出了用Langevin MCMC采样器替换梯度上升采样器，以提高样本质量。 |
| [^54] | [Why think step-by-step? Reasoning emerges from the locality of experience.](http://arxiv.org/abs/2304.03843) | 本文通过语言模型研究何时以及为什么推理是有帮助的，测试推理在训练数据由相互影响强烈的局部变量集群组成时是否有效。通过一步步的推理，能够将准确的局部推理链接在一起，以估算在训练中没有同时观察到的变量之间的关系。 |
| [^55] | [Improving Identity-Robustness for Face Models.](http://arxiv.org/abs/2304.03838) | 该论文探讨了在没有身份注释信息的情况下，使用人脸识别嵌入向量作为身份标识的替代方法，以提高人脸模型的身份鲁棒性和公平性。 |
| [^56] | [ChiroDiff: Modelling chirographic data with Diffusion Models.](http://arxiv.org/abs/2304.03785) | 本论文介绍了一种名为"ChiroDiff"的模型类，该模型利用Denoising Diffusion Probabilistic Models（DDPMs）解决了手写数据建模过程中存在的问题，能够学习捕捉整体概念，在更高的时间采样率下保持弹性，并具有许多下游实用程序。 |
| [^57] | [Generative AI for learning: Investigating the potential of synthetic learning videos.](http://arxiv.org/abs/2304.03784) | 本研究探讨了使用生成AI合成视频来创建在线教育内容的效用，使用混合方法和成年学习者进行实验。结果显示，合成学习视频对学习内容获取和学习体验有着积极的影响。 |
| [^58] | [AutoQNN: An End-to-End Framework for Automatically Quantizing Neural Networks.](http://arxiv.org/abs/2304.03782) | AutoQNN是一种可自动量化DNN模型的端到端框架，利用三种技术实现了对适合不同层次的混合精度策略的搜索，并可有效提高效率和准确性。 |
| [^59] | [A roadmap to fair and trustworthy prediction model validation in healthcare.](http://arxiv.org/abs/2304.03779) | 针对医疗保健中预测模型的验证问题，建议使用来自目标人群的新数据进行外部验证，确保验证性能对模型可靠性的影响，并且在模型开发期间认真研究模型在更广泛环境中的拓展性。我们提出了一份路线图，以便在医疗保健中开发和应用可靠、公平、可信的人工智能模型。 |
| [^60] | [Safe Explicable Robot Planning.](http://arxiv.org/abs/2304.03773) | 安全可解释机器人规划方法（SEP）扩展了可解释规划，支持安全界限的规定，以实现安全和可解释之间的权衡。 |
| [^61] | [Rethinking GNN-based Entity Alignment on Heterogeneous Knowledge Graphs: New Datasets and A New Method.](http://arxiv.org/abs/2304.03468) | 文章重新考虑了基于GNN的异构知识图谱实体对齐。为探究EA实际场景中的表现，提出了更接近现实的高度异构知识图谱数据集，并提出了新方法。 |
| [^62] | [CAPOT: Creating Robust Dense Query Encoders using Post Training Contrastive Alignment.](http://arxiv.org/abs/2304.03401) | CAPOT使用后训练对比对齐的方法，提高模型对于噪声查询的健壮性，表现类似于数据增强但没有其开销。 |
| [^63] | [Comparing NARS and Reinforcement Learning: An Analysis of ONA and $Q$-Learning Algorithms.](http://arxiv.org/abs/2304.03291) | 本文比较了NARS和强化学习在解决序列任务方面的性能，发现NARS在各种环境中都有较好的表现，尤其是在非确定性环境中。 |
| [^64] | [Revisiting Dense Retrieval with Unanswerable Counterfactuals.](http://arxiv.org/abs/2304.03031) | 本文观察到基于DPR的最近的密集检索模型经常将无法回答的反事实情景排名高于可回答的原始情景，提出了一种新颖的用于段落检索的表示学习方法PiCL。 |
| [^65] | [Robust Neural Architecture Search.](http://arxiv.org/abs/2304.02845) | 提出了一种名为RNAS的神经架构搜索方法，通过平衡准确性和鲁棒性生成高质量架构，使用噪声样本减少搜索成本，在图像分类和对抗攻击中均达到最先进性能水平。 |
| [^66] | [Large Language Models as Master Key: Unlocking the Secrets of Materials Science with GPT.](http://arxiv.org/abs/2304.02213) | 本文介绍了一个新的自然语言处理任务——结构化信息推理（SIS），利用GPT-3模型能够准确提取材料科学设备层面的信息，并通过实验预测PCE和反向预测参数，展示了大型语言模型在材料学中的巨大潜力。 |
| [^67] | [EPVT: Environment-aware Prompt Vision Transformer for Domain Generalization in Skin Lesion Recognition.](http://arxiv.org/abs/2304.01508) | EPVT是一种基于环境感知的提示视觉Transformer，用于解决皮肤病变识别中深度神经网络可能过度依赖疾病不相关图像特征的问题，通过嵌入一组领域提示和一个共享提示来进行领域一般化，并且引入了领域提示生成器促进知识共享。 |
| [^68] | [TPU v4: An Optically Reconfigurable Supercomputer for Machine Learning with Hardware Support for Embeddings.](http://arxiv.org/abs/2304.01433) | TPU v4是一款支持嵌入式硬件的可重构光学超级计算机，采用光学电路交换机重新配置互连拓扑，提高规模、可用性、利用率、模块化、部署、安全、功率和性能，它通过SparseCores加速嵌入式模型，性能优越，功耗低。 |
| [^69] | [RePAST: Relative Pose Attention Scene Representation Transformer.](http://arxiv.org/abs/2304.00947) | RePAST是一种相对位姿注意力场景表示变换器，其将成对的相对相机姿态信息直接注入转换器的注意机制中，不需要固定参考帧，同时保留了原始方法的全部功能，加入这种不变性并不会导致质量下降，可以应用于大规模场景。 |
| [^70] | [Recover Triggered States: Protect Model Against Backdoor Attack in Reinforcement Learning.](http://arxiv.org/abs/2304.00252) | 本文提出了恢复触发状态(RTS)方法，用于保护RL代理免受反向攻击。该方法涉及构建替代网络来近似动态模型，并将触发状态恢复为干净状态来防止攻击者通过触发器激活隐藏在代理中的后门。 |
| [^71] | [On the Creativity of Large Language Models.](http://arxiv.org/abs/2304.00008) | 这篇论文探讨了大型语言模型的创造性问题，分析了与之相关的机器创造性的难点和易点，并重点分析了这些技术在创意产业中的社会影响。 |
| [^72] | [A Survey of Large Language Models.](http://arxiv.org/abs/2303.18223) | 本文综述了大型语言模型的研究历程以及最近的预训练语言模型(PLMs)，并强调模型扩展将带来性能改进和特殊能力的发掘。 |
| [^73] | [Training Language Models with Language Feedback at Scale.](http://arxiv.org/abs/2303.16755) | 本文提出一种新方法，即利用更丰富的语言反馈进行模仿学习，通过三个迭代步骤对语言模型进行训练以生成更符合人类偏好的输出。 |
| [^74] | [TabRet: Pre-training Transformer-based Tabular Models for Unseen Columns.](http://arxiv.org/abs/2303.15747) | 提出了一种可预训练的Transformer-based表格模型：TabRet，能够支持未知列，并在医疗保健分类任务上表现优秀。重新标记化和随机洗牌增强对性能提升有贡献。 |
| [^75] | [From Single-Hospital to Multi-Centre Applications: Enhancing the Generalisability of Deep Learning Models for Adverse Event Prediction in the ICU.](http://arxiv.org/abs/2303.15354) | 本研究通过使用多个数据源和在训练中明确优化泛化性能，提高了深度学习模型在新医院中预测ICU患者不良事件的性能和可靠性。 |
| [^76] | [Did You Train on My Dataset? Towards Public Dataset Protection with Clean-Label Backdoor Watermarking.](http://arxiv.org/abs/2303.11470) | 提出了一种基于背门数字水印的方法，以确保公共数据的安全。通过在数据集中插入极少量的数字水印样本，隐式学习一个隐藏的函数作为数字水印，以跟踪非法使用此数据集的模型。使用“清洁标签背门”方法实现了数字水印，不会破坏原始数据集。实验证明，该方法有效地检测到非法利用数据集的行为。 |
| [^77] | [Computational-level Analysis of Constraint Compliance for General Intelligence.](http://arxiv.org/abs/2303.04352) | 论文研究了人类行为受约束规范约束的影响，同时针对于构建遵守这些约束的通用代理提出了基于贝叶斯决策理论的计算水平模型。 |
| [^78] | [Multi-modal Multi-kernel Graph Learning for Autism Prediction and Biomarker Discovery.](http://arxiv.org/abs/2303.03388) | 本文提出了一种名为MMKGL的新方法，能够解决多模态集成中各模态之间的负面影响，并从多个图中提取异质信息，以进行自闭症的预测和生物标志物的发现。 |
| [^79] | [Improving GAN Training via Feature Space Shrinkage.](http://arxiv.org/abs/2303.01559) | 本文提出了一种针对GAN训练的改进方法，即在鉴别器的特征空间中收缩训练数据的区域，构建硬样本并缩小硬样本与易样本之间的特征距离。 |
| [^80] | [Learning machines for health and beyond.](http://arxiv.org/abs/2303.01513) | 适用于建立预测模型的机器学习技术在医疗领域和其他领域具有广泛应用。模型的维护和监控很关键，因为模型的性能与数据的变化和传输有关。 |
| [^81] | [Double Permutation Equivariance for Knowledge Graph Completion.](http://arxiv.org/abs/2302.01313) | 本研究提出了双排列等变性的KG表示方法，可以使神经网络在KG中执行复杂的逻辑推理任务，并在多个归纳KG完成任务中实现了最先进的Hits@10测试准确率。双排列等变性在KG中开辟了新的研究方向。 |
| [^82] | [Revisiting the Spatial and Temporal Modeling for Few-shot Action Recognition.](http://arxiv.org/abs/2301.07944) | SloshNet是一个重新审视少样本动作识别的新框架，它在空间和时间建模方面进行了精细化的探索，利用特征融合和长期时间建模模块来提高动作识别性能。 |
| [^83] | [Classifying Mental-Disorders through Clinicians Subjective Approach based on Three-way Decision.](http://arxiv.org/abs/2301.03351) | 本文提出了一个基于三分决策框架下的统一模型，用于分析临床医生的主观方法，通过定量和定性分析得出排名列表和权重，并将疾病进行比较分类为三组，该方法可以作为补充工具与手动方法相结合，提高精确性。 |
| [^84] | [MobileTL: On-device Transfer Learning with Inverted Residual Blocks.](http://arxiv.org/abs/2212.03246) | 本文提出了MobileTL，一种基于内部标准化层具有内存和计算效率的移动设备上的迁移学习方法，用于构建IRBs模型。MobileTL通过训练内部规范化层的移位来避免存储向后传递的激活图，显著降低了内存使用率，并在图像识别任务中保持了竞争性的准确性。 |
| [^85] | [Vertical Federated Learning: A Structured Literature Review.](http://arxiv.org/abs/2212.00622) | 垂直联邦学习是联邦学习中的一种特殊架构，它可在不泄露隐私的情况下，通过组合本地模型训练的结果来建立完整的机器学习模型。本文是对垂直联邦学习现有研究进行了结构化综述，总结了其研究现状、应用、限制和未来方向。 |
| [^86] | [Lifelong Embedding Learning and Transfer for Growing Knowledge Graphs.](http://arxiv.org/abs/2211.15845) | 现有的知识图谱嵌入模型主要集中在静态KG上，无法随着KG不断增长而及时获取新知识，本文引入了终身KG嵌入模型，实现对不断增长的知识图谱的终身嵌入学习与转移，通过嵌入转移策略和正则化方法避免灾难性遗忘。 |
| [^87] | [Weighted Ensemble Self-Supervised Learning.](http://arxiv.org/abs/2211.09981) | 本文提出了一种带权重集成的自监督学习方法，通过开发允许数据相关的加权交叉熵损失的框架，可以提高最近自监督学习技术的性能，而不需要改变原有的架构，其在 ImageNet-1K 数据集上的表现优于最先进的 DINO 和 MSN 方法，特别是在小样本设置中表现最佳。 |
| [^88] | [Quantum Split Neural Network Learning using Cross-Channel Pooling.](http://arxiv.org/abs/2211.06524) | 本研究提出了一种基于QSL的新方法，并引入交叉通道池化技术，实现了加速收敛、减少通讯成本和增强隐私保护的优点。 |
| [^89] | [A Transformer-Based Substitute Recommendation Model Incorporating Weakly Supervised Customer Behavior Data.](http://arxiv.org/abs/2211.02533) | 本文将替代品推荐适应到语言匹配问题中，并通过设计新的转换方法去除信号噪音，并考虑了多语言支持。该模型已成功在一个大型电子商务网站上的11个市场和6种语言中部署，提高了顾客忠诚度和购买率。 |
| [^90] | [Broken Neural Scaling Laws.](http://arxiv.org/abs/2210.14891) | 本文提出了一个平滑破碎的幂律函数形式，可以准确地模拟和外推深度神经网络的缩放行为，适用于各种架构和大量不同任务，包括视觉、语言、音频、视频、生成建模、对比学习、机器人、不确定性估计/校准、对抗鲁棒性、分子、计算机编程/编码、数学单词问题、算术、无监督/自监督学习和强化学习。 |
| [^91] | [Predictive Inference with Feature Conformal Prediction.](http://arxiv.org/abs/2210.00173) | 本文提出基于特征符合预测的预测推断方法，通过利用深度表示学习的归纳偏置，扩展了符合预测到语义特征空间。从理论和实验结果来看，该方法优于常规符合预测，并在大规模任务上展现了最先进性能。 |
| [^92] | [Combating Mode Collapse in GANs via Manifold Entropy Estimation.](http://arxiv.org/abs/2208.12055) | 本文提出了一种新的GAN训练流程，通过将判别器作为特征嵌入进行泛化并设计两个正则化项，从而最大化学习到的分布熵以解决GAN中的模式崩溃问题。 |
| [^93] | [Neural Groundplans: Persistent Neural Scene Representations from a Single Image.](http://arxiv.org/abs/2207.11232) | 本文提出了一种基于单张图像的持久神经场景表示方法，使用条件神经地面计划来表示场景，能够进行视角合成、场景解耦表示和可移动组件的分离，重构可移动物体能够进行多种下游任务。 |
| [^94] | [ShapeCrafter: A Recursive Text-Conditioned 3D Shape Generation Model.](http://arxiv.org/abs/2207.09446) | 本文提出了一个用于递归文本条件下三维形状生成的神经网络，通过一种逐步添加短语的方法，可以生成与文本描述一致的形状。 |
| [^95] | [Large Language Models Still Can't Plan (A Benchmark for LLMs on Planning and Reasoning about Change).](http://arxiv.org/abs/2206.10498) | 本研究提出了一个用于测评LLMs规划和变化推理能力的框架，并测试了流行的LLMs (GPT-3 和 GShard) 在此基准上的表现。研究发现这些模型在最简单的规划任务上都表现不佳，强调了目前LLMs推理能力的严重限制，建议需要大量工作来开发更先进的LLM基础系统来满足实际应用需求。 |
| [^96] | [An empirical study of the effect of background data size on the stability of SHapley Additive exPlanations (SHAP) for deep learning models.](http://arxiv.org/abs/2204.11351) | 本研究发现 SHapley Additive exPlanations (SHAP) 对于机器学习模型的解释受到背景数据集规模的影响，而选择合适的背景数据集能够确保 SHAP 解释的稳定性。 |
| [^97] | [FAIR4Cov: Fused Audio Instance and Representation for COVID-19 Detection.](http://arxiv.org/abs/2204.10581) | FAIR4Cov是一种针对COVID-19检测的方法，它提出了一种融合身体声音的波形和谱图表示的关节特征向量，可以有效地检测COVID-19患者，胜过了其他方法。 |
| [^98] | [Synthetic Distracted Driving (SynDD2) dataset for analyzing distracted behaviors and various gaze zones of a driver.](http://arxiv.org/abs/2204.08096) | 本文介绍了SynDD2数据集，该数据集用于检测和分析驾驶员的分心行为和不同凝视区域，研究人员可以使用该数据集评估机器学习算法的性能。 |
| [^99] | [Structure-aware Protein Self-supervised Learning.](http://arxiv.org/abs/2204.04213) | 我们提出了一种结构感知的蛋白自监督学习方法，利用预训练的图神经网络模型保留重要的蛋白质结构信息，并结合预训练语言模型来提高下游任务性能。在两个蛋白质分类测试中均表现出了优异的结果。 |
| [^100] | [Randomized Sharpness-Aware Training for Boosting Computational Efficiency in Deep Learning.](http://arxiv.org/abs/2203.09962) | 本文提出了一种名为随机锐度感知训练（RST）的深度学习训练方法，通过在SGD和SAM之间随机选择来减少计算量，同时保证模型收敛。同时，我们对各种调度函数的效果和计算成本进行了实验研究。 |

# 详细

[^1]: BerDiff: 针对医学图像分割的条件伯努利扩散模型

    BerDiff: Conditional Bernoulli Diffusion Model for Medical Image Segmentation. (arXiv:2304.04429v1 [cs.CV])

    [http://arxiv.org/abs/2304.04429](http://arxiv.org/abs/2304.04429)

    提出了针对医学图像分割的条件伯努利扩散模型（BerDiff），使用伯努利噪声作为扩散核增强了扩散模型的二进制分割任务能力，并通过随机采样初噪声生成多样的分割掩模，实验结果表明其在准确性和多样性方面优于其他最先进的方法。

    

    医学图像分割是一项具有固有模糊性和高度不确定性的挑战性任务，归因于模糊的肿瘤边界和多个可能的注释等因素。分割掩模的准确性和多样性对提供临床实践中放射学家的有价值参考均至关重要。然而，现有的扩散模型在各种视觉生成任务中显示了强大的能力，但处理分割中的离散掩模仍具有挑战性。为了实现准确且多样的医学图像分割掩模，我们提出了一种新颖的针对医学图像分割的条件伯努利扩散模型（BerDiff）。我们首先提出使用伯努利噪声作为扩散核来增强用于二进制分割任务的扩散模型的能力，从而得到更准确的分割掩模。其次，通过利用扩散模型的随机性质，我们的BerDiff在推理期间随机采样初始的伯努利噪声以生成多样的分割掩模。在BraTS和LiTS两个基准数据集上的大量实验表明，我们提出的BerDiff在分割掩模的准确性和多样性方面胜过了几种最先进的方法。

    Medical image segmentation is a challenging task with inherent ambiguity and high uncertainty, attributed to factors such as unclear tumor boundaries and multiple plausible annotations. The accuracy and diversity of segmentation masks are both crucial for providing valuable references to radiologists in clinical practice. While existing diffusion models have shown strong capacities in various visual generation tasks, it is still challenging to deal with discrete masks in segmentation. To achieve accurate and diverse medical image segmentation masks, we propose a novel conditional Bernoulli Diffusion model for medical image segmentation (BerDiff). Instead of using the Gaussian noise, we first propose to use the Bernoulli noise as the diffusion kernel to enhance the capacity of the diffusion model for binary segmentation tasks, resulting in more accurate segmentation masks. Second, by leveraging the stochastic nature of the diffusion model, our BerDiff randomly samples the initial Bernou
    
[^2]: PCR: 基于代理的对比式回放在在线类增量连续学习中的应用

    PCR: Proxy-based Contrastive Replay for Online Class-Incremental Continual Learning. (arXiv:2304.04408v1 [cs.CV])

    [http://arxiv.org/abs/2304.04408](http://arxiv.org/abs/2304.04408)

    本文提出了一种名为PCR的基于代理的对比式回放方法，它能够有效地解决在线类增量连续学习中的历史知识遗忘问题。经实验证明，在两个视觉数据集上，PCR能够显著优于现有方法。

    

    在线类增量连续学习是连续学习中的一项特定任务。它旨在从数据流中不断学习新的类别，但数据流中的样本仅需观察一次，这容易导致历史类别的知识遗忘问题。现有的基于回放的方法通过以代理为基础或以对比为基础的回放方式有效地缓解了这一问题。尽管这两种回放方式是有效的，但前者会因类别不平衡问题而倾向于新类，后者则由于样本数量有限而不稳定且难以收敛。本文对这两种回放方式进行了全面的分析，发现它们可以互补。在此基础上，我们提出了一种新的回放-based方法，称为基于代理的对比式回放（PCR）。关键操作是将锚定点的对比样本替换为相应代理的对比样本。具体来说，设计并自适应地选择两种代理，即旧代理和新代理，以稳定训练并缓解类别不平衡问题。实验证明，PCR在两个视觉数据集上显著优于现有方法。

    Online class-incremental continual learning is a specific task of continual learning. It aims to continuously learn new classes from data stream and the samples of data stream are seen only once, which suffers from the catastrophic forgetting issue, i.e., forgetting historical knowledge of old classes. Existing replay-based methods effectively alleviate this issue by saving and replaying part of old data in a proxy-based or contrastive-based replay manner. Although these two replay manners are effective, the former would incline to new classes due to class imbalance issues, and the latter is unstable and hard to converge because of the limited number of samples. In this paper, we conduct a comprehensive analysis of these two replay manners and find that they can be complementary. Inspired by this finding, we propose a novel replay-based method called proxy-based contrastive replay (PCR). The key operation is to replace the contrastive samples of anchors with corresponding proxies in th
    
[^3]: H2RBox-v2：通过对称学习提高基于HBox监督的有向物体检测

    H2RBox-v2: Boosting HBox-supervised Oriented Object Detection via Symmetric Learning. (arXiv:2304.04403v1 [cs.CV])

    [http://arxiv.org/abs/2304.04403](http://arxiv.org/abs/2304.04403)

    H2RBox-v2是第一个将对称学习应用于基于HBox监督的有向物体检测，其强化了水平注释和旋转注释之间的联系，在多个基准测试中实现了最先进的性能。

    

    随着对于自动驾驶和遥感等有向物体检测需求的日益增长，有向注释变得非常费力。为了充分利用现有的水平注释数据集并降低注释成本，已经提出了一种弱监督检测器H2RBox，用于从水平框Box中学习旋转框RBox，并受到了广泛关注。本文介绍了H2RBox-v2的新版本，以进一步弥合HBox监督和RBox监督的有向物体检测之间的差距。通过我们的理论分析，利用翻转和旋转一致性来开发轴对称性是可行的，H2RBox-v2则采用与H2RBox类似的弱监督分支，并嵌入一个新颖的自监督分支，它可以从对象图像中固有的对称性中学习方向。通过处理周边问题的模块（例如角周期性），实现了一种稳定而有效的解决方案。据我们所知，H2RBox-v2是第一个将对称学习应用于基于HBox监督的有向物体检测，并在多个基准测试中实现了最先进的性能。

    With the increasing demand for oriented object detection e.g. in autonomous driving and remote sensing, the oriented annotation has become a labor-intensive work. To make full use of existing horizontally annotated datasets and reduce the annotation cost, a weakly-supervised detector H2RBox for learning the rotated box (RBox) from the horizontal box (HBox) has been proposed and received great attention. This paper presents a new version, H2RBox-v2, to further bridge the gap between HBox-supervised and RBox-supervised oriented object detection. While exploiting axisymmetry via flipping and rotating consistencies is available through our theoretical analysis, H2RBox-v2, using a weakly-supervised branch similar to H2RBox, is embedded with a novel self-supervised branch that learns orientations from the symmetry inherent in the image of objects. Complemented by modules to cope with peripheral issues, e.g. angular periodicity, a stable and effective solution is achieved. To our knowledge, H
    
[^4]: CAVL：学习对比和自适应的视觉与语言表示

    CAVL: Learning Contrastive and Adaptive Representations of Vision and Language. (arXiv:2304.04399v1 [cs.CV])

    [http://arxiv.org/abs/2304.04399](http://arxiv.org/abs/2304.04399)

    本文提出了一种对比自适应的视觉与语言表示学习方法CAVL，在预训练过程中通过对比损失学习整个句子和图像之间的对齐，并在微调阶段引入轻量级自适应网络，实现在下游任务中的最先进效果。

    

    视觉和语言的预训练旨在一起学习视觉和语言表示，并可转移到视觉语言下游任务。然而，在预训练阶段，语言和视觉之间存在语义混淆。此外，当前的预训练模型在转移到下游任务时往往需要大量的计算资源进行微调。在本文中，我们提出了一种简单但有效的方法，用于学习对比和自适应的视觉与语言表示，即CAVL。具体而言，我们在预训练过程中引入了一对一对的对比损失，以学习整个句子和同一批次中每个图像之间的对齐。在微调阶段，我们引入了两个轻量级自适应网络，以减少模型参数并增加训练速度，以节省计算资源。我们在包括视觉问答（VQA）、视觉通识推理（VCL）和图像字幕生成等六个主要下游任务中评估了我们的CAVL。实验结果表明，CAVL在大多数任务上都取得了最先进的性能，证明了我们的方法的有效性。

    Visual and linguistic pre-training aims to learn vision and language representations together, which can be transferred to visual-linguistic downstream tasks. However, there exists semantic confusion between language and vision during the pre-training stage. Moreover, current pre-trained models tend to take lots of computation resources for fine-tuning when transferred to downstream tasks. In this work, we present a simple but effective approach for learning Contrastive and Adaptive representations of Vision and Language, namely CAVL. Specifically, we introduce a pair-wise contrastive loss to learn alignments between the whole sentence and each image in the same batch during the pre-training process. At the fine-tuning stage, we introduce two lightweight adaptation networks to reduce model parameters and increase training speed for saving computation resources. We evaluate our CAVL on six main downstream tasks, including Visual Question Answering (VQA), Visual Commonsense Reasoning (VC
    
[^5]: CAFIN: 基于节点中心性的公平性增强进程的无监督图表示学习方法

    CAFIN: Centrality Aware Fairness inducing IN-processing for Unsupervised Representation Learning on Graphs. (arXiv:2304.04391v1 [cs.LG])

    [http://arxiv.org/abs/2304.04391](http://arxiv.org/abs/2304.04391)

    CAFIN是一种基于节点中心性的公平性增强进程技术，用于无监督学习的图表示学习方法中。实验结果表明，CAFIN在提供最优公平结果的同时，具有竞争力或更好的下游任务性能。

    

    由于所学嵌入的紧凑性和丰富性以及未标记图数据的丰富性，无监督学习的图表示在(大型)图上已经受到研究界的重视。当这些节点表示被部署时，必须使用适当的公平性约束条件生成以减少它们对下游任务造成的偏差。因此，对于特定的下游任务，已经调查了图学习算法的群体和个体公平性概念。这些公平性概念的主要局限性是没有考虑连接模式在图中导致的不同节点影响(或中心性能量)。在本文中，我们为归纳图表示学习算法设计了一个基于中心性的公平框架。我们提出了CAFIN（Centrality Aware Fairness inducing IN-processing），一种利用图结构改进GraphSAGE表示的进程技术——无监督图学习文献中的一种流行框架。对真实世界数据集的广泛实验表明，CAFIN在提供具有竞争力或更好的下游任务性能的同时，实现了最先进的公平结果。

    Unsupervised representation learning on (large) graphs has received significant attention in the research community due to the compactness and richness of the learned embeddings and the abundance of unlabelled graph data. When deployed, these node representations must be generated with appropriate fairness constraints to minimize bias induced by them on downstream tasks. Consequently, group and individual fairness notions for graph learning algorithms have been investigated for specific downstream tasks. One major limitation of these fairness notions is that they do not consider the connectivity patterns in the graph leading to varied node influence (or centrality power). In this paper, we design a centrality-aware fairness framework for inductive graph representation learning algorithms. We propose CAFIN (Centrality Aware Fairness inducing IN-processing), an in-processing technique that leverages graph structure to improve GraphSAGE's representations - a popular framework in the unsup
    
[^6]: 知识图谱实体和架构的深度主动对齐

    Deep Active Alignment of Knowledge Graph Entities and Schemata. (arXiv:2304.04389v1 [cs.DB])

    [http://arxiv.org/abs/2304.04389](http://arxiv.org/abs/2304.04389)

    本文提出了一种基于深度学习和主动学习的KG对齐方法DAAKG，可以联合对齐不仅实体，还包括关系和类别；通过主动学习选择最佳批次进行人工标注，实验结果显示其优越精度和泛化性。

    

    知识图谱（KG）存储了关于真实世界的丰富事实。本文研究KG对齐，旨在在不同的KG中找到不仅实体，还包括关系和类别的对齐。实体级别的对齐可以促进架构级别的对齐。我们提出了一种新的KG对齐方法，称为DAAKG，基于深度学习和主动学习。通过深度学习，它学习实体、关系和类别的嵌入，并在半监督方式下联合对齐它们；而通过主动学习，它估计实体、关系或类别对的推断可能性，并选择最佳的批次进行人工标注。我们设计了两个近似算法以高效选择批次解决问题。我们在基准数据集上进行的实验显示了DAAKG的优越精度和泛化性，并验证了其所有模块的有效性。

    Knowledge graphs (KGs) store rich facts about the real world. In this paper, we study KG alignment, which aims to find alignment between not only entities but also relations and classes in different KGs. Alignment at the entity level can cross-fertilize alignment at the schema level. We propose a new KG alignment approach, called DAAKG, based on deep learning and active learning. With deep learning, it learns the embeddings of entities, relations and classes, and jointly aligns them in a semi-supervised manner. With active learning, it estimates how likely an entity, relation or class pair can be inferred, and selects the best batch for human labeling. We design two approximation algorithms for efficient solution to batch selection. Our experiments on benchmark datasets show the superior accuracy and generalization of DAAKG and validate the effectiveness of all its modules.
    
[^7]: OpenAGI：当LLM遇到领域专家

    OpenAGI: When LLM Meets Domain Experts. (arXiv:2304.04370v1 [cs.AI])

    [http://arxiv.org/abs/2304.04370](http://arxiv.org/abs/2304.04370)

    基于大型语言模型的OpenAGI平台通过整合领域专家模型和自然语言问答形式，实现复杂任务解决。

    

    人类具有将基本技能组合成复杂技能以解决复杂任务的显著能力。这种能力对于人工智能同样重要，因此，我们断言，除了开发大型综合智能模型外，将不同领域专家模型应用于复杂任务解决能力同样关键，以在人工智能通用智能的追求中使其具备这种能力。最近的大型语言模型（LLM）的发展证明其具有出色的学习和推理能力，使它们成为选择、综合和执行外部模型以解决复杂任务的控制器的有前途的选择。在这个项目中，我们开发了一个名为OpenAGI的开源AGI研究平台，专门设计为提供复杂的多步骤任务，并配有任务特定的数据集、评估指标和各种可扩展模型。OpenAGI将复杂任务阐释为自然语言问答，旨在促进领域专家和语言模型之间的协同作用。

    Human intelligence has the remarkable ability to assemble basic skills into complex ones so as to solve complex tasks. This ability is equally important for Artificial Intelligence (AI), and thus, we assert that in addition to the development of large, comprehensive intelligent models, it is equally crucial to equip such models with the capability to harness various domain-specific expert models for complex task-solving in the pursuit of Artificial General Intelligence (AGI). Recent developments in Large Language Models (LLMs) have demonstrated remarkable learning and reasoning abilities, making them promising as a controller to select, synthesize, and execute external models to solve complex tasks. In this project, we develop OpenAGI, an open-source AGI research platform, specifically designed to offer complex, multi-step tasks and accompanied by task-specific datasets, evaluation metrics, and a diverse range of extensible models. OpenAGI formulates complex tasks as natural language q
    
[^8]: WebBrain: 基于大型Web语料库，通过挖掘支持证据生成事实正确文章的学习

    WebBrain: Learning to Generate Factually Correct Articles for Queries by Grounding on Large Web Corpus. (arXiv:2304.04358v1 [cs.CL])

    [http://arxiv.org/abs/2304.04358](http://arxiv.org/abs/2304.04358)

    本文讲述了一种新的自然语言处理任务——WebBrain，它通过挖掘Web中的支持证据，为查询生成事实正确简短文章。我们从维基百科中提取了数据集WebBrain-Raw，构建了WebBrain-R和WebBrain-G数据集。我们还介绍了一个新的生成事实性的框架ReGen。

    

    本文介绍一种新的自然语言处理任务——从Web挖掘支持证据，为查询生成带参考文献的简短事实文章。在这个名为WebBrain的任务中，最终目标是为维基百科中未出现的事实查询生成流畅、信息丰富、事实正确的简短文章。为了实现对WebBrain的实验，我们按照维基百科中的文章和可爬行的维基百科参考文献提取英语数据集WebBrain-Raw。WebBrain-Raw比以前最大的同行数据集大十倍，可以极大地惠及研究社区。从WebBrain-Raw中，我们构建了两个任务特定数据集：WebBrain-R和WebBrain-G，分别用于训练领域内的检索器和生成器。此外，我们在WebBrain上实证分析了当前最先进的自然语言处理技术的表现，并介绍了一个增强证据支持的生成事实性的新框架ReGen。

    In this paper, we introduce a new NLP task -- generating short factual articles with references for queries by mining supporting evidence from the Web. In this task, called WebBrain, the ultimate goal is to generate a fluent, informative, and factually-correct short article (e.g., a Wikipedia article) for a factual query unseen in Wikipedia. To enable experiments on WebBrain, we construct a large-scale dataset WebBrain-Raw by extracting English Wikipedia articles and their crawlable Wikipedia references. WebBrain-Raw is ten times larger than the previous biggest peer dataset, which can greatly benefit the research community. From WebBrain-Raw, we construct two task-specific datasets: WebBrain-R and WebBrain-G, which are used to train in-domain retriever and generator, respectively. Besides, we empirically analyze the performances of the current state-of-the-art NLP techniques on WebBrain and introduce a new framework ReGen, which enhances the generation factualness by improved evidence
    
[^9]: 基于点的新型多智能体控制算法：基于公共信息方法

    A Novel Point-based Algorithm for Multi-agent Control Using the Common Information Approach. (arXiv:2304.04346v1 [cs.AI])

    [http://arxiv.org/abs/2304.04346](http://arxiv.org/abs/2304.04346)

    本文提出了基于公共信息方法的新型多智能体控制算法，结合点处理POMDP算法，解决了行动空间庞大的问题。

    

    公共信息方法提供了一种将多智能体随机控制问题转化为单一智能体部分可观察的马尔可夫决策问题（POMDP）的系统方法，称为协调者的POMDP。然而，由于其极其庞大的行动空间，这样的POMDP可能很难解决。因此，我们提出了一种新的多智能体随机控制问题的算法，称为协调者的启发式搜索值迭代（CHSVI），该算法将公共信息方法和基于点的POMDP算法相结合，用于大行动空间的问题。通过优化解决多个基准问题来演示该算法。

    The Common Information (CI) approach provides a systematic way to transform a multi-agent stochastic control problem to a single-agent partially observed Markov decision problem (POMDP) called the coordinator's POMDP. However, such a POMDP can be hard to solve due to its extraordinarily large action space. We propose a new algorithm for multi-agent stochastic control problems, called coordinator's heuristic search value iteration (CHSVI), that combines the CI approach and point-based POMDP algorithms for large action spaces. We demonstrate the algorithm through optimally solving several benchmark problems.
    
[^10]: ChatGPT是一个好的情感分析器吗？一项初步研究。

    Is ChatGPT a Good Sentiment Analyzer? A Preliminary Study. (arXiv:2304.04339v1 [cs.CL])

    [http://arxiv.org/abs/2304.04339](http://arxiv.org/abs/2304.04339)

    本文对ChatGPT作为情感分析器进行了初步评估，包括标准评估、极性转移评估、开放域评估和情感推理评估，共涉及18个数据集和5个情感分析任务。与经过微调的BERT和最先进的模型进行了对比，并进行了人工评估和案例研究。

    

    最近，ChatGPT在研究和公众的关注下受到了极大的关注。我们特别想知道它是否可以作为通用情感分析器。为此，在这项工作中，我们对ChatGPT在文本中包含的意见、情感和情绪的理解进行了初步评估。具体而言，我们在四个设置下进行评估，包括标准评估、极性转移评估、开放域评估和情感推理评估。以上评估涉及18个基准数据集和5个代表性情感分析任务，我们将ChatGPT与经过微调的BERT和相应的最先进模型进行了对比，并在末端任务上进行了评估。此外，我们还进行了人工评估，并展示了一些定性案例研究以深入理解其情感分析能力。

    Recently, ChatGPT has drawn great attention from both the research community and the public. We are particularly curious about whether it can serve as a universal sentiment analyzer. To this end, in this work, we provide a preliminary evaluation of ChatGPT on the understanding of opinions, sentiments, and emotions contained in the text. Specifically, we evaluate it in four settings, including standard evaluation, polarity shift evaluation, open-domain evaluation, and sentiment inference evaluation. The above evaluation involves 18 benchmark datasets and 5 representative sentiment analysis tasks, and we compare ChatGPT with fine-tuned BERT and corresponding state-of-the-art (SOTA) models on end-task. Moreover, we also conduct human evaluation and present some qualitative case studies to gain a deep comprehension of its sentiment analysis capabilities.
    
[^11]: ARNOLD：基于连续状态实现的现实3D场景语言引导任务学习基准测试

    ARNOLD: A Benchmark for Language-Grounded Task Learning With Continuous States in Realistic 3D Scenes. (arXiv:2304.04321v1 [cs.AI])

    [http://arxiv.org/abs/2304.04321](http://arxiv.org/abs/2304.04321)

    ARNOLD是一个评估基于语言引导、具有连续状态的现实3D场景任务学习的基准测试，涉及8个语言条件任务，在语言引导下帮助机器人学习理解物体状态和学习连续目标的策略。

    

    在现实世界中，理解物体的连续状态对于任务学习和规划至关重要。然而，大多数任务学习基准测试假定目标状态是离散的(例如二进制状态)，这给学习复杂任务和将学习策略从模拟环境转移到现实世界带来了挑战。此外，状态离散化限制了机器人根据动作和状态的引导遵循人类指令的能力。为了解决这些挑战，我们提出了ARNOLD，这是一个评估基于语言引导、具有连续状态的现实3D场景任务学习的基准测试。ARNOLD由8个语言条件任务组成，涉及理解物体状态和学习连续目标的策略。为了促进语言引导学习，我们提供了模板生成的语言描述的专家演示。我们通过使用最新的语言条件策略学习模型来评估任务的性能。我们的结果表明，ARNOLD为基于连续状态的语言引导任务学习提供了一个具有挑战性的环境，并可用于评估从模拟场景到现实世界的学习策略的泛化。

    Understanding the continuous states of objects is essential for task learning and planning in the real world. However, most existing task learning benchmarks assume discrete(e.g., binary) object goal states, which poses challenges for the learning of complex tasks and transferring learned policy from simulated environments to the real world. Furthermore, state discretization limits a robot's ability to follow human instructions based on the grounding of actions and states. To tackle these challenges, we present ARNOLD, a benchmark that evaluates language-grounded task learning with continuous states in realistic 3D scenes. ARNOLD is comprised of 8 language-conditioned tasks that involve understanding object states and learning policies for continuous goals. To promote language-instructed learning, we provide expert demonstrations with template-generated language descriptions. We assess task performance by utilizing the latest language-conditioned policy learning models. Our results ind
    
[^12]: 基于自适应鲁棒优化的时间序列预测集成建模方法

    Ensemble Modeling for Time Series Forecasting: an Adaptive Robust Optimization Approach. (arXiv:2304.04308v1 [cs.LG])

    [http://arxiv.org/abs/2304.04308](http://arxiv.org/abs/2304.04308)

    本文提出了一种基于自适应鲁棒优化的方法，用于构建强鲁棒性的时间序列预测模型集成，取得了比最佳集成成员更好的表现。

    

    精确的时间序列预测对于涉及时间数据的广泛问题至关重要。集成建模是一种利用多个预测模型提高准确性和鲁棒性的成熟技术，因为单个预测器的性能可能会因基础数据分布的转换而高度变化。本文提出了一种构建强鲁棒性时间序列预测模型集成的新方法。我们的方法利用自适应鲁棒优化（ARO）构建了一个线性回归集成模型，其中模型的权重可以随时间自适应调整。通过一系列合成实验和现实应用，包括空气污染管理、能源消耗预测和热带气旋强度预测等，我们展示了我们方法的有效性。我们的结果表明，我们的自适应集成模型在均方根误差和条件风险价值方面的表现优于最好的集成成员，分别提高了16-26%和14-28%。

    Accurate time series forecasting is critical for a wide range of problems with temporal data. Ensemble modeling is a well-established technique for leveraging multiple predictive models to increase accuracy and robustness, as the performance of a single predictor can be highly variable due to shifts in the underlying data distribution. This paper proposes a new methodology for building robust ensembles of time series forecasting models. Our approach utilizes Adaptive Robust Optimization (ARO) to construct a linear regression ensemble in which the models' weights can adapt over time. We demonstrate the effectiveness of our method through a series of synthetic experiments and real-world applications, including air pollution management, energy consumption forecasting, and tropical cyclone intensity forecasting. Our results show that our adaptive ensembles outperform the best ensemble member in hindsight by 16-26% in root mean square error and 14-28% in conditional value at risk and improv
    
[^13]: 图中类别不平衡学习综述

    Class-Imbalanced Learning on Graphs: A Survey. (arXiv:2304.04300v1 [cs.LG])

    [http://arxiv.org/abs/2304.04300](http://arxiv.org/abs/2304.04300)

    本文综述了现有CILG技术的最新状态，提出了一个现有工作的分类法，并讨论了未来研究方向。CILG作为一种有前途的解决方案，将图表示学习和类别不平衡学习相结合，用于克服现实世界数据中的类别不平衡问题。

    

    数据驱动研究的快速发展增加了对有效的图数据分析的需求。然而，现实世界中的数据通常呈现类别不平衡，导致机器学习模型的性能不佳。为了克服这一挑战，类别不平衡学习在图上（CILG）已成为一种有前途的解决方案，结合了图表示学习和类别不平衡学习的优势。近年来，在CILG方面已经取得了重大进展。本综述旨在全面了解CILG的现有最新技术，并为未来的研究方向提供见解。另外，我们提供了一份持续更新的论文阅读列表。

    The rapid advancement in data-driven research has increased the demand for effective graph data analysis. However, real-world data often exhibits class imbalance, leading to poor performance of machine learning models. To overcome this challenge, class-imbalanced learning on graphs (CILG) has emerged as a promising solution that combines the strengths of graph representation learning and class-imbalanced learning. In recent years, significant progress has been made in CILG. Anticipating that such a trend will continue, this survey aims to offer a comprehensive understanding of the current state-of-the-art in CILG and provide insights for future research directions. Concerning the former, we introduce the first taxonomy of existing work and its connection to existing imbalanced learning literature. Concerning the latter, we critically analyze recent work in CILG and discuss urgent lines of inquiry within the topic. Moreover, we provide a continuously maintained reading list of papers an
    
[^14]: 分布式条件生成对抗网络（discGAN）用于合成医疗保健数据生成

    Distributed Conditional GAN (discGAN) For Synthetic Healthcare Data Generation. (arXiv:2304.04290v1 [cs.LG])

    [http://arxiv.org/abs/2304.04290](http://arxiv.org/abs/2304.04290)

    本文提出了一种分布式生成对抗网络（discGAN）用于生成医疗保健领域的合成表格数据，并且在应用中成功模拟出非高斯多模式医疗保健数据的分布，其生成的数据分布与真实数据相似。

    

    本文提出了一种分布式生成对抗网络（discGAN）来生成特定于医疗保健领域的合成表格数据。虽然使用生成对抗网络来生成图像已经得到了广泛研究，但几乎没有人关注生成表格数据。建模离散和连续表格数据的分布是一项非常有用的非平凡任务。我们将discGAN应用于模拟非高斯多模式医疗保健数据。我们从原始的2,027个eICU数据集中生成了249,000个合成记录。我们使用机器学习功效、连续变量的Kolmogorov-Smirnov（KS）检验和离散变量的卡方检验来评估模型的性能。我们的结果表明，discGAN能够生成具有与真实数据类似的分布数据。

    In this paper, we propose a distributed Generative Adversarial Networks (discGANs) to generate synthetic tabular data specific to the healthcare domain. While using GANs to generate images has been well studied, little to no attention has been given to generation of tabular data. Modeling distributions of discrete and continuous tabular data is a non-trivial task with high utility. We applied discGAN to model non-Gaussian multi-modal healthcare data. We generated 249,000 synthetic records from original 2,027 eICU dataset. We evaluated the performance of the model using machine learning efficacy, the Kolmogorov-Smirnov (KS) test for continuous variables and chi-squared test for discrete variables. Our results show that discGAN was able to generate data with distributions similar to the real data.
    
[^15]: FrenchMedMCQA: 用于医学领域的法语多项选择问题回答数据集

    FrenchMedMCQA: A French Multiple-Choice Question Answering Dataset for Medical domain. (arXiv:2304.04280v1 [cs.CL])

    [http://arxiv.org/abs/2304.04280](http://arxiv.org/abs/2304.04280)

    FrenchMedMCQA是法语医学MCQA数据集，包含3,105道真实考试题目。需要使用医学领域或MCQA任务专用的表示形式来获得更好的性能。

    

    本文介绍了FrenchMedMCQA，这是公开发布的医学领域法语多项选择问题回答（MCQA）数据集。该数据集由3,105道真实的法国药学专业文凭考试题目组成，包括单项和多项选择题，每个实例包含标识符、问题、五个可能的答案和它们的手动纠正。我们还提出了第一个基线模型来自动处理该MCQA任务，以报告当前的性能和突出任务的难点。结果的详细分析显示，需要有适应于医学领域或MCQA任务的表示形式：在我们的情况下，即使FrenchMedMCQA是以法语书写的，英语专门的模型也比通用的法语模型表现更好。语料库、模型和工具都可在线获得。

    This paper introduces FrenchMedMCQA, the first publicly available Multiple-Choice Question Answering (MCQA) dataset in French for medical domain. It is composed of 3,105 questions taken from real exams of the French medical specialization diploma in pharmacy, mixing single and multiple answers. Each instance of the dataset contains an identifier, a question, five possible answers and their manual correction(s). We also propose first baseline models to automatically process this MCQA task in order to report on the current performances and to highlight the difficulty of the task. A detailed analysis of the results showed that it is necessary to have representations adapted to the medical domain or to the MCQA task: in our case, English specialized models yielded better results than generic French ones, even though FrenchMedMCQA is in French. Corpus, models and tools are available online.
    
[^16]: 时间序列数据的尴尬简单混合方法

    Embarrassingly Simple MixUp for Time-series. (arXiv:2304.04271v1 [cs.LG])

    [http://arxiv.org/abs/2304.04271](http://arxiv.org/abs/2304.04271)

    本研究针对时间序列数据提出了一种基于MixUp的数据增强方法，即MixUp++和LatentMixUp++，能够显著提高1％- 15％的分类准确率，尤其适用于有限标记数据的情况，并通过半监督学习扩展到无标签数据。

    

    由于领域专业知识和数据的动态性，标记时间序列数据是一项昂贵的任务。因此，我们经常需要处理有限标记数据的情况。数据增强技术已成功应用于诸如计算机视觉之类的领域，以利用现有标记数据的使用。我们将其中一种最常用的技术MixUp，应用于时序领域。我们的提出的MixUp++和LatentMixUp++方法分别对原始时间序列和分类模型的潜在空间进行插值的简单修改。我们也通过半监督学习将这些方法扩展到无标签数据。我们观察到，对于两个公共数据集的时间序列分类，无论是低标记数据还是高标记数据制度，通过LatentMixUp ++，都可以显著提高1％- 15％。

    Labeling time series data is an expensive task because of domain expertise and dynamic nature of the data. Hence, we often have to deal with limited labeled data settings. Data augmentation techniques have been successfully deployed in domains like computer vision to exploit the use of existing labeled data. We adapt one of the most commonly used technique called MixUp, in the time series domain. Our proposed, MixUp++ and LatentMixUp++, use simple modifications to perform interpolation in raw time series and classification model's latent space, respectively. We also extend these methods with semi-supervised learning to exploit unlabeled data. We observe significant improvements of 1\% - 15\% on time series classification on two public datasets, for both low labeled data as well as high labeled data regimes, with LatentMixUp++.
    
[^17]: 区块链技术在MANET中的安全路由协议应用研究

    Secure Routing Protocol To Mitigate Attacks By Using Blockchain Technology In Manet. (arXiv:2304.04254v1 [cs.CR])

    [http://arxiv.org/abs/2304.04254](http://arxiv.org/abs/2304.04254)

    论文提出了一种采用区块链技术的安全路由算法（SRABC），该算法通过提供源节点到目的节点的安全、经过认证和防篡改的路由来保护控制和数据流，预防MANET受到各种攻击手段，并对节点进行认证。仿真结果表明，SRABC算法优于当前方法，是确保MANET安全的可行选项。

    

    MANET是一组通过无线网络通信的移动节点，它们从一个点移动到另一个点。由于MANET是一个没有基础设施且拓扑结构可变的网络，因此很容易受到攻击。恶意网络节点是网络攻击的源头。在MANET中，攻击可以采取各种形式，并以其独特的方式改变网络的运行。本文介绍了许多形式的攻击、它们对MANET的影响以及目前实施的MANET防御措施。所提出的采用区块链技术的安全路由算法（SRABC）可保护MANET免受攻击并对节点进行认证。该算法通过提供源节点到目的节点的安全、经过认证和防篡改的路由来保护控制和数据流，防范威胁。使用NS2模拟器评估了SRABC算法的关键性能参数，如数据包传递率、端到端延迟和吞吐量。仿真结果表明，SRABC算法优于当前方法，是确保MANET安全的可行选项。

    MANET is a collection of mobile nodes that communicate through wireless networks as they move from one point to another. MANET is an infrastructure-less network with a changeable topology; as a result, it is very susceptible to attacks. MANET attack prevention represents a serious difficulty. Malicious network nodes are the source of network-based attacks. In a MANET, attacks can take various forms, and each one alters the network's operation in its unique way. In general, attacks can be separated into two categories: those that target the data traffic on a network and those that target the control traffic. This article explains the many sorts of assaults, their impact on MANET, and the MANET-based defence measures that are currently in place. The suggested SRA that employs blockchain technology (SRABC) protects MANET from attacks and authenticates nodes. The secure routing algorithm (SRA) proposed by blockchain technology safeguards control and data flow against threats. This is achie
    
[^18]: 视频聊天字幕生成器： 迈向丰富时空描述

    Video ChatCaptioner: Towards the Enriched Spatiotemporal Descriptions. (arXiv:2304.04227v1 [cs.CV])

    [http://arxiv.org/abs/2304.04227](http://arxiv.org/abs/2304.04227)

    Video ChatCaptioner是一种创新方法，利用ChatGPT和算法生成全面和丰富的时空视频描述。

    

    视频字幕生成的目的是使用自然语言传达视频中的动态场景，促进我们对环境中时空信息的理解。尽管最近取得了一些进展，生成细致和丰富的视频描述仍然是一项重大挑战。在这项工作中，我们介绍了一种创新方法，Video ChatCaptioner，用于创建更全面的时空视频描述。我们的方法采用 ChatGPT 模型作为控制器，专门设计用于选择框架以提出视频内容驱动的问题。随后，利用强大的算法回答这些视觉查询。这种问答框架有效地揭示了复杂的视频细节，并显示出增强视频内容的方法的前途。在多个对话轮次之后，ChatGPT 可以根据之前的对话总结丰富的视频内容。我们定性证明，我们的 Video ChatCaptioner 可以生成包含更多细节的视频字幕。

    Video captioning aims to convey dynamic scenes from videos using natural language, facilitating the understanding of spatiotemporal information within our environment. Although there have been recent advances, generating detailed and enriched video descriptions continues to be a substantial challenge. In this work, we introduce Video ChatCaptioner, an innovative approach for creating more comprehensive spatiotemporal video descriptions. Our method employs a ChatGPT model as a controller, specifically designed to select frames for posing video content-driven questions. Subsequently, a robust algorithm is utilized to answer these visual queries. This question-answer framework effectively uncovers intricate video details and shows promise as a method for enhancing video content. Following multiple conversational rounds, ChatGPT can summarize enriched video content based on previous conversations. We qualitatively demonstrate that our Video ChatCaptioner can generate captions containing mo
    
[^19]: 在医学图像分割网络中使用Transformer

    Transformer Utilization in Medical Image Segmentation Networks. (arXiv:2304.04225v1 [cs.CV])

    [http://arxiv.org/abs/2304.04225](http://arxiv.org/abs/2304.04225)

    Transformer在医学图像分割中最有效的设计是伴随着显式的特征层次结构，而单独使用不能防止表示的可替换性；应慎用主要空间下采样操作。

    

    由于在数据丰富的自然图像领域取得成功，Transformer最近在医学图像分割中变得流行起来。然而，Transformer与卷积块的匹配以及不同架构排列方式的选择，使得它们的相对有效性需要进一步探究。我们引入了Transformer削弱实验，用普通线性算子替代Transformer块，以量化该有效性。通过对两个医学图像分割任务中的8个模型进行实验，我们探索了：1）Transformer学习表示的可替代性；2）Transformer的容量单独并不能防止表示的可替换性，并需要与有效的设计搭配使用；3）Transformer块中显式特征层次结构的存在本身比伴随注意力机制更有益；4）应谨慎使用Transformer模块之前的主要空间下采样操作。

    Owing to success in the data-rich domain of natural images, Transformers have recently become popular in medical image segmentation. However, the pairing of Transformers with convolutional blocks in varying architectural permutations leaves their relative effectiveness to open interpretation. We introduce Transformer Ablations that replace the Transformer blocks with plain linear operators to quantify this effectiveness. With experiments on 8 models on 2 medical image segmentation tasks, we explore -- 1) the replaceable nature of Transformer-learnt representations, 2) Transformer capacity alone cannot prevent representational replaceability and works in tandem with effective design, 3) The mere existence of explicit feature hierarchies in transformer blocks is more beneficial than accompanying self-attention modules, 4) Major spatial downsampling before Transformer modules should be used with caution.
    
[^20]: 面向终身多智能体路径规划的高速公路研究

    The Study of Highway for Lifelong Multi-Agent Path Finding. (arXiv:2304.04217v1 [cs.AI])

    [http://arxiv.org/abs/2304.04217](http://arxiv.org/abs/2304.04217)

    本研究旨在解决终身多智能体路径规划问题中出现的运行时间指数增长和死锁、重新路由等不良现象。我们将高速公路的概念纳入终身多智能体路径规划框架中，并通过两种方法实现，成功减少了问题的复杂度，缩短了运行时间并提高了吞吐量。

    

    在现代的配送仓库中，智能体在地图上穿行完成源源不断的任务，这被定义为终身多智能体路径规划问题。解决这一挑战性问题的目标是在有限的时间内找到每个智能体的路径，同时最大化吞吐量。然而，现有的方法在地图大小或智能体密度增长时会遇到运行时间的指数增长和死锁以及重新路由等不良现象。为了解决面向终身多智能体路径规划的这些挑战，我们探索了高速公路的概念，该概念主要用于一次性路径规划，通过鼓励智能体朝着同一方向移动，减少了问题的复杂度。我们使用两种方法将高速公路思想纳入终身多智能体路径规划框架，并讨论了最小化死锁和重新路由问题的特性。实验结果表明，运行时间显著缩短，吞吐量得到提高。

    In modern fulfillment warehouses, agents traverse the map to complete endless tasks that arrive on the fly, which is formulated as a lifelong Multi-Agent Path Finding (lifelong MAPF) problem. The goal of tackling this challenging problem is to find the path for each agent in a finite runtime while maximizing the throughput. However, existing methods encounter exponential growth of runtime and undesirable phenomena of deadlocks and rerouting as the map size or agent density grows. To address these challenges in lifelong MAPF, we explore the idea of highways mainly studied for one-shot MAPF (i.e., finding paths at once beforehand), which reduces the complexity of the problem by encouraging agents to move in the same direction. We utilize two methods to incorporate the highway idea into the lifelong MAPF framework and discuss the properties that minimize the existing problems of deadlocks and rerouting. The experimental results demonstrate that the runtime is considerably reduced and the 
    
[^21]: OpenDriver: 一份开放路况驾驶员状态检测数据集

    OpenDriver: an open-road driver state detection dataset. (arXiv:2304.04203v1 [cs.AI])

    [http://arxiv.org/abs/2304.04203](http://arxiv.org/abs/2304.04203)

    OpenDriver是一份旨在解决现有驾驶员生理数据集存在问题的开放路况驾驶员状态检测数据集，包含六轴惯性信号和心电图信号两种模态的数据，可用于驾驶员受损检测和生物识别数据识别。

    

    在现代社会中，道路安全严重依赖于驾驶员的心理和生理状态。疲劳、昏昏欲睡和压力等负面因素会影响驾驶员的反应时间和决策能力，导致交通事故的发生率增加。在众多的驾驶员行为监测研究中，可穿戴生理测量是一种实时监测驾驶员状态的方法。然而，目前在开放道路场景下，缺少驾驶员生理数据集，已有的数据集存在信号质量差、样本量小和数据收集时间短等问题。因此，本文设计并描述了一种大规模多模态驾驶数据集，用于驾驶员受损检测和生物识别数据识别。该数据集包含两种驾驶信号模态：六轴惯性信号和心电图（ECG）信号，这些信号是在100多名驾驶员遵循相同路线行驶时记录的。

    In modern society, road safety relies heavily on the psychological and physiological state of drivers. Negative factors such as fatigue, drowsiness, and stress can impair drivers' reaction time and decision making abilities, leading to an increased incidence of traffic accidents. Among the numerous studies for impaired driving detection, wearable physiological measurement is a real-time approach to monitoring a driver's state. However, currently, there are few driver physiological datasets in open road scenarios and the existing datasets suffer from issues such as poor signal quality, small sample sizes, and short data collection periods. Therefore, in this paper, a large-scale multimodal driving dataset for driver impairment detection and biometric data recognition is designed and described. The dataset contains two modalities of driving signals: six-axis inertial signals and electrocardiogram (ECG) signals, which were recorded while over one hundred drivers were following the same ro
    
[^22]: QUST队在SemEval-2023任务3中的综合研究：检测在线新闻的类型、框架和说服技巧的单语和多语方法。

    Team QUST at SemEval-2023 Task 3: A Comprehensive Study of Monolingual and Multilingual Approaches for Detecting Online News Genre, Framing and Persuasion Techniques. (arXiv:2304.04190v1 [cs.CL])

    [http://arxiv.org/abs/2304.04190](http://arxiv.org/abs/2304.04190)

    本文研究了单语和多语方法来检测在线新闻的类型、框架和说服技巧，并发现多语方法比单语方法更好，使用类权重和样本权重的组合对预训练的多语模型进行微调可用于应对多数类不平衡的问题，在SemEval2023任务3中提交的系统在意大利语和西班牙语（零样本）的子任务1中排名第二。

    

    本文描述了QUST团队参加SemEval2023任务3的情况。首先，单语模型在任务早期对多数类进行了欠采样评估。然后，使用类权重和样本权重的组合对预训练的多语模型进行了微调。进一步研究两种不同的微调策略，分别为任务不可知和任务相关的。所有实验都在10折交叉验证下进行，多语方法比单语方法更具优势。提交的系统在意大利语和西班牙语（零样本）的子任务1中取得了第二名。

    This paper describes the participation of team QUST in the SemEval2023 task 3. The monolingual models are first evaluated with the under-sampling of the majority classes in the early stage of the task. Then, the pre-trained multilingual model is fine-tuned with a combination of the class weights and the sample weights. Two different fine-tuning strategies, the task-agnostic and the task-dependent, are further investigated. All experiments are conducted under the 10-fold cross-validation, the multilingual approaches are superior to the monolingual ones. The submitted system achieves the second best in Italian and Spanish (zero-shot) in subtask-1.
    
[^23]: 基于梯度稀疏化和差分隐私的高效无线联合学习

    Gradient Sparsification for Efficient Wireless Federated Learning with Differential Privacy. (arXiv:2304.04164v1 [cs.DC])

    [http://arxiv.org/abs/2304.04164](http://arxiv.org/abs/2304.04164)

    本文提出了一种基于梯度稀疏化和差分隐私的无线联合学习框架，使用随机稀疏化算法缓解DP引起的性能下降，并减少上传的参数数量，提高训练效率而不损失收敛性能。

    

    联合学习使分布式客户端在不共享原始数据的情况下协同训练机器学习模型。但是，由于上传模型而泄漏私有信息。此外，随着模型大小的增加，由于有限的传输带宽，训练延迟增加，同时使用差分隐私（DP）保护时模型性能会下降。在本文中，我们提出了一种基于梯度稀疏化和差分隐私的无线联合学习框架，以提高训练效率而不损失收敛性能。具体而言，我们首先设计了一个随机稀疏化算法，在每个客户端的本地训练中保留一部分梯度元素，从而缓解了DP引起的性能下降，并减少了无线信道上传输的参数数量。然后，我们通过建模非凸FL问题分析了所提出算法的收敛度界。接下来，我们提出了一个分布式联合优化问题，使用Alternating Direction Method of Multipliers（ADMM）解决其优化问题。

    Federated learning (FL) enables distributed clients to collaboratively train a machine learning model without sharing raw data with each other. However, it suffers the leakage of private information from uploading models. In addition, as the model size grows, the training latency increases due to limited transmission bandwidth and the model performance degrades while using differential privacy (DP) protection. In this paper, we propose a gradient sparsification empowered FL framework over wireless channels, in order to improve training efficiency without sacrificing convergence performance. Specifically, we first design a random sparsification algorithm to retain a fraction of the gradient elements in each client's local training, thereby mitigating the performance degradation induced by DP and and reducing the number of transmission parameters over wireless channels. Then, we analyze the convergence bound of the proposed algorithm, by modeling a non-convex FL problem. Next, we formula
    
[^24]: RoboPianist：用于高维机器人控制的基准测试

    RoboPianist: A Benchmark for High-Dimensional Robot Control. (arXiv:2304.04150v1 [cs.RO])

    [http://arxiv.org/abs/2304.04150](http://arxiv.org/abs/2304.04150)

    RoboPianist是一个新的高维机器人控制基准测试，旨在测试高精度、协调和规划，并通过反复接触的欠驱动系统进行钢琴演奏。该基准测试提供了性能特征的定量数据，并具有易于解释的结果。

    

    我们介绍了一个新的基准测试套件，针对测试高空间和时间精度、协调和规划，所有这些都是在频繁进行接触的欠驱动系统中进行的。所提出的挑战是通过双手灵巧，使用一对仿人机器人手来掌握钢琴演奏。我们称之为RoboPianist，最初版本涵盖了150首难度不同的歌曲。我们在此基准测试上研究了基于模型的和无模型的方法，表征了它们的性能特征。我们观察到，尽管某些现有方法在某些方面表现出色，但在某些方面还有很大的改进空间。RoboPianist提供了一个丰富的定量基准测试环境，具有易于解释的结果、通过简单增加新歌曲来扩展曲目的高易用性，并提供了进一步研究的机会，包括多任务学习和零样本学习等领域。

    We introduce a new benchmarking suite for high-dimensional control, targeted at testing high spatial and temporal precision, coordination, and planning, all with an underactuated system frequently making-and-breaking contacts. The proposed challenge is mastering the piano through bi-manual dexterity, using a pair of simulated anthropomorphic robot hands. We call it RoboPianist, and the initial version covers a broad set of 150 variable-difficulty songs. We investigate both model-free and model-based methods on the benchmark, characterizing their performance envelopes. We observe that while certain existing methods, when well-tuned, can achieve impressive levels of performance in certain aspects, there is significant room for improvement. RoboPianist provides a rich quantitative benchmarking environment, with human-interpretable results, high ease of expansion by simply augmenting the repertoire with new songs, and opportunities for further research, including in multi-task learning, ze
    
[^25]: 进化聚类方法和概率神经网络的混合用于一次联邦学习分类：FedPNN

    FedPNN: One-shot Federated Classification via Evolving Clustering Method and Probabilistic Neural Network hybrid. (arXiv:2304.04147v1 [cs.LG])

    [http://arxiv.org/abs/2304.04147](http://arxiv.org/abs/2304.04147)

    本文提出了一种两阶段联邦学习方法，通过进化聚类方法和概率神经网络的混合来实现一次联邦学习分类，以保护隐私并解决通信开销和有限资源的问题。

    

    在金融、银行和医疗等领域，保护数据隐私至关重要。联邦学习（FL）由于其分散、分布式的训练和同时获得全局共享模型的保护隐私的能力而受到广泛关注。然而，FL面临着通信开销和有限的资源能力等挑战。因此，我们提出了一个两阶段联邦学习方法，以实现隐私保护的目标，并进行了以下首次研究：（i）在第一阶段，通过使用两种不同的分布作为噪声来生成合成数据集，并将其应用于改进的条件表生成对抗神经网络（CTGAN），（ii）在第二阶段，开发和采用联邦概率神经网络（FedPNN）来构建全局共享分类模型。我们还采用了合成数据集指标来检查生成的合成数据集的质量。

    Protecting data privacy is paramount in the fields such as finance, banking, and healthcare. Federated Learning (FL) has attracted widespread attention due to its decentralized, distributed training and the ability to protect the privacy while obtaining a global shared model. However, FL presents challenges such as communication overhead, and limited resource capability. This motivated us to propose a two-stage federated learning approach toward the objective of privacy protection, which is a first-of-its-kind study as follows: (i) During the first stage, the synthetic dataset is generated by employing two different distributions as noise to the vanilla conditional tabular generative adversarial neural network (CTGAN) resulting in modified CTGAN, and (ii) In the second stage, the Federated Probabilistic Neural Network (FedPNN) is developed and employed for building globally shared classification model. We also employed synthetic dataset metrics to check the quality of the generated syn
    
[^26]: 基于NeRF技术的卫星图像表面重建

    NeRF applied to satellite imagery for surface reconstruction. (arXiv:2304.04133v1 [cs.CV])

    [http://arxiv.org/abs/2304.04133](http://arxiv.org/abs/2304.04133)

    本文提出了Sat-NeRF模型，能够从少量的卫星图像集合中合成新的视角，并准确地估计场景表面的高程。

    

    本文提出了Sat-NeRF模型，是对最近引入的S-NeRF模型的修改实现。该模型能够从稀疏的卫星图像集合中合成新的视角，同时考虑到图片中的光照变化。训练好的模型还能够精确地估计场景表面的高程，这对卫星观测应用非常有帮助。S-NeRF方法改进了标准的NeRF方法，将辐射强度考虑为高反射率和入射辐照度的函数。这两个量都是模型的全连接神经网络枝条的输出，而后者则被视为来自太阳的直接光线和来自天空的漫反射颜色函数。该实现基于用缩放-裁剪技术增强的卫星图像数据集。对NeRF进行了超参数研究，得出了一些有趣的观察结果。

    We present Sat-NeRF, a modified implementation of the recently introduced Shadow Neural Radiance Field (S-NeRF) model. This method is able to synthesize novel views from a sparse set of satellite images of a scene, while accounting for the variation in lighting present in the pictures. The trained model can also be used to accurately estimate the surface elevation of the scene, which is often a desirable quantity for satellite observation applications. S-NeRF improves on the standard Neural Radiance Field (NeRF) method by considering the radiance as a function of the albedo and the irradiance. Both these quantities are output by fully connected neural network branches of the model, and the latter is considered as a function of the direct light from the sun and the diffuse color from the sky. The implementations were run on a dataset of satellite images, augmented using a zoom-and-crop technique. A hyperparameter study for NeRF was carried out, leading to intriguing observations on the 
    
[^27]: 替代拉格朗日松弛：一种不需要重新训练的深度神经网络剪枝方法

    Surrogate Lagrangian Relaxation: A Path To Retrain-free Deep Neural Network Pruning. (arXiv:2304.04120v1 [cs.NE])

    [http://arxiv.org/abs/2304.04120](http://arxiv.org/abs/2304.04120)

    本文提出了一种基于替代拉格朗日松弛的系统权重剪枝优化方法，可加快模型剪枝问题的收敛速度，并在深度神经网络上得到了显著效果，无需重新训练。

    

    剪枝是一种常用的技术，用于减少深度神经网络的计算成本和模型大小。然而，典型的三阶段管道显著增加了总体训练时间。本文提出了一种基于替代拉格朗日松弛的系统权重剪枝优化方法，特别针对权重剪枝问题的离散性而设计。我们证明了我们的方法确保了模型压缩问题的快速收敛，并且通过使用二次惩罚来加速SLR的收敛。与其他最先进的方法相比，SLR在训练阶段得到的模型参数距离其最优值更近。我们使用CIFAR-10和ImageNet数据集评估了我们的方法，并与MLP-Mixer、Swin Transformer、VGG-16、ResNet-18、ResNet-50、ResNet-110和MobileNetV2等最先进的模型进行了比较。我们还评估了目标检测和分割任务。

    Network pruning is a widely used technique to reduce computation cost and model size for deep neural networks. However, the typical three-stage pipeline significantly increases the overall training time. In this paper, we develop a systematic weight-pruning optimization approach based on Surrogate Lagrangian relaxation, which is tailored to overcome difficulties caused by the discrete nature of the weight-pruning problem. We prove that our method ensures fast convergence of the model compression problem, and the convergence of the SLR is accelerated by using quadratic penalties. Model parameters obtained by SLR during the training phase are much closer to their optimal values as compared to those obtained by other state-of-the-art methods. We evaluate our method on image classification tasks using CIFAR-10 and ImageNet with state-of-the-art MLP-Mixer, Swin Transformer, and VGG-16, ResNet-18, ResNet-50 and ResNet-110, MobileNetV2. We also evaluate object detection and segmentation tasks
    
[^28]: TC-VAE：揭示数据生成因素中的未知分布数据

    TC-VAE: Uncovering Out-of-Distribution Data Generative Factors. (arXiv:2304.04103v1 [cs.LG])

    [http://arxiv.org/abs/2304.04103](http://arxiv.org/abs/2304.04103)

    本文提出了一种基于总相关性的生成模型TC-VAE，可以揭示数据生成因素中的未知分布数据，在处理具有不平衡生成因素的数据集上表现优秀。

    

    揭示数据生成因素是解决解缠结学习的最终目标。本文提出了一种生成模型-TC-VAE，它可以基于所学的潜在表征和输入数据之间的总相关性下界进行优化，从而发现不在数据集中显式出现的变化因素。我们分析了在使用具有不平衡的生成因素数据集时，所提出的模型的效果，并在定量和定性实验中表明了TC-VAE的优越性。

    Uncovering data generative factors is the ultimate goal of disentanglement learning. Although many works proposed disentangling generative models able to uncover the underlying generative factors of a dataset, so far no one was able to uncover OOD generative factors (i.e., factors of variations that are not explicitly shown on the dataset). Moreover, the datasets used to validate these models are synthetically generated using a balanced mixture of some predefined generative factors, implicitly assuming that generative factors are uniformly distributed across the datasets. However, real datasets do not present this property. In this work we analyse the effect of using datasets with unbalanced generative factors, providing qualitative and quantitative results for widely used generative models. Moreover, we propose TC-VAE, a generative model optimized using a lower bound of the joint total correlation between the learned latent representations and the input data. We show that the proposed
    
[^29]: 基于深度学习的可解释的多标签孟加拉有害评论分类

    Interpretable Multi Labeled Bengali Toxic Comments Classification using Deep Learning. (arXiv:2304.04087v1 [cs.CL])

    [http://arxiv.org/abs/2304.04087](http://arxiv.org/abs/2304.04087)

    本文提出了一种基于深度学习的方法，用于分类孟加拉语的有害评论。使用LSTM和BERT嵌入实现了二元分类任务的高准确率，同时使用卷积神经网络和双向LSTM与注意机制组合实现了多标签分类，准确率和加权F1-score均较高。

    

    本文提出了一个基于深度学习的方案来分类孟加拉语的有害评论，首先使用二元分类模型确定评论是否有害，然后使用多标签分类器确定该评论属于哪种毒性类型。为此，我们准备了一个手动标注的数据集，其中包含16,073个实例，其中8,488个是有害的，并且任何有害的评论可能同时属于六种有害类型-低俗，仇恨，宗教，威胁，恶意和侮辱。在二元分类任务上，使用LSTM和BERT嵌入实现了89.42％的准确率；在多标签分类器方面，使用卷积神经网络和双向LSTM（CNN-BiLSTM）与注意机制组合，获得了78.92％的准确率和0.86的加权F1-score。为了解释预测结果并解释分类期间的单词特征重要性，该方法使用了LIME技术。

    This paper presents a deep learning-based pipeline for categorizing Bengali toxic comments, in which at first a binary classification model is used to determine whether a comment is toxic or not, and then a multi-label classifier is employed to determine which toxicity type the comment belongs to. For this purpose, we have prepared a manually labeled dataset consisting of 16,073 instances among which 8,488 are Toxic and any toxic comment may correspond to one or more of the six toxic categories - vulgar, hate, religious, threat, troll, and insult simultaneously. Long Short Term Memory (LSTM) with BERT Embedding achieved 89.42% accuracy for the binary classification task while as a multi-label classifier, a combination of Convolutional Neural Network and Bi-directional Long Short Term Memory (CNN-BiLSTM) with attention mechanism achieved 78.92% accuracy and 0.86 as weighted F1-score. To explain the predictions and interpret the word feature importance during classification by the propos
    
[^30]: 通过蒙特卡罗树搜索改进大规模多目标优化的性能不敏感性

    Improving Performance Insensitivity of Large-scale Multiobjective Optimization via Monte Carlo Tree Search. (arXiv:2304.04071v1 [cs.NE])

    [http://arxiv.org/abs/2304.04071](http://arxiv.org/abs/2304.04071)

    本论文提出了一种能同时提高大规模多目标优化算法性能和不敏感性的方法，该方法利用蒙特卡罗树搜索。

    

    大规模多目标优化问题(LSMOP)的特点是同时优化多个冲突目标并涉及数百个决策变量。 许多工程领域的实际应用可以建模为LSMOP。同时，工程应用要求性能不敏感。这通常意味着算法运行的结果不仅在性能方面对每次运行都很好，而且多次运行的性能不应波动太大，即算法呈现良好的不敏感性。考虑到每次运行需要大量计算资源，因此改进大规模多目标优化算法的性能和算法的不敏感性至关重要。然而，现有的大规模多目标优化算法只关注于提高算法的性能，而不是考虑不敏感性。

    The large-scale multiobjective optimization problem (LSMOP) is characterized by simultaneously optimizing multiple conflicting objectives and involving hundreds of decision variables. {Many real-world applications in engineering fields can be modeled as LSMOPs; simultaneously, engineering applications require insensitivity in performance.} This requirement usually means that the results from the algorithm runs should not only be good for every run in terms of performance but also that the performance of multiple runs should not fluctuate too much, i.e., the algorithm shows good insensitivity. Considering that substantial computational resources are requested for each run, it is essential to improve upon the performance of the large-scale multiobjective optimization algorithm, as well as the insensitivity of the algorithm. However, existing large-scale multiobjective optimization algorithms solely focus on improving the performance of the algorithms, leaving the insensitivity characteri
    
[^31]: 基于推荐系统的大规模多目标优化方法研究

    A Recommender System Approach for Very Large-scale Multiobjective Optimization. (arXiv:2304.04067v1 [cs.NE])

    [http://arxiv.org/abs/2304.04067](http://arxiv.org/abs/2304.04067)

    本论文提出了一种基于推荐系统的大规模多目标优化方法，将解决方案视为用户，通过汤普森抽样和高斯过程逼近 Pareto-最优前沿上的后验分布，成功解决了处理大规模问题的难题。

    

    本论文定义了决策变量数量超过100,000个纬度的问题为大规模多目标优化问题。由于许多实际问题需要优化十万级别的变量，这是一个重要的问题类别。现有的进化优化方法在处理这种规模非常大的问题时存在不足。受到现有推荐系统成功处理历史交互有限的大规模物品的启发，在本文中，我们提出了一种称为“基于推荐系统的大规模多目标优化”（VMORS）的方法。该方法的思想是将这类问题转化为可以由推荐系统解决的问题。在该框架下，解决方案被视为用户，不同的进化方向是等待推荐的项目。我们使用汤普森抽样通过高斯过程逼近 Pareto-最优前沿上的后验分布，以推荐进化方向。对基准问题的实验结果证明了该方法在解决大规模多目标优化问题方面的有效性。

    We define very large multi-objective optimization problems to be multiobjective optimization problems in which the number of decision variables is greater than 100,000 dimensions. This is an important class of problems as many real-world problems require optimizing hundreds of thousands of variables. Existing evolutionary optimization methods fall short of such requirements when dealing with problems at this very large scale. Inspired by the success of existing recommender systems to handle very large-scale items with limited historical interactions, in this paper we propose a method termed Very large-scale Multiobjective Optimization through Recommender Systems (VMORS). The idea of the proposed method is to transform the defined such very large-scale problems into a problem that can be tackled by a recommender system. In the framework, the solutions are regarded as users, and the different evolution directions are items waiting for the recommendation. We use Thompson sampling to recom
    
[^32]: 利用多模态深度神经网络预测多发性硬化症疾病严重程度

    Predicting multiple sclerosis disease severity with multimodal deep neural networks. (arXiv:2304.04062v1 [cs.LG])

    [http://arxiv.org/abs/2304.04062](http://arxiv.org/abs/2304.04062)

    本研究提出使用患者的多模态EHR数据预测多发性硬化症疾病严重程度，以便实现早期干预和治疗。提高了预测准确性和模型复杂度。

    

    多发性硬化症（MS）是一种发展在人类大脑和脊髓中的慢性疾病，可能会导致神经永久性损伤或恶化。MS病情的严重程度是通过扩展残疾状态评分（EDSS）来监测的，该评分由几个功能子分数组成。早期和准确的MS疾病严重程度分类对于通过应用早期治疗干预策略来减缓或预防疾病进展至关重要。 近年来深度学习的进展和电子健康记录（EHR）的广泛应用为应用数据驱动和预测建模工具提供了机会。以往专注于利用单模态机器学习和深度学习算法的研究由于数据不足或模型简单而限制了预测准确性。在本文中，我们提出了使用患者的多模态纵向和横向EHR数据预测医院访问时的多发性硬化症疾病严重程度的想法。

    Multiple Sclerosis (MS) is a chronic disease developed in human brain and spinal cord, which can cause permanent damage or deterioration of the nerves. The severity of MS disease is monitored by the Expanded Disability Status Scale (EDSS), composed of several functional sub-scores. Early and accurate classification of MS disease severity is critical for slowing down or preventing disease progression via applying early therapeutic intervention strategies. Recent advances in deep learning and the wide use of Electronic Health Records (EHR) creates opportunities to apply data-driven and predictive modeling tools for this goal. Previous studies focusing on using single-modal machine learning and deep learning algorithms were limited in terms of prediction accuracy due to the data insufficiency or model simplicity. In this paper, we proposed an idea of using patients' multimodal longitudinal and longitudinal EHR data to predict multiple sclerosis disease severity at the hospital visit. This
    
[^33]: tmn在SemEval-2023任务9中的应用：使用XLM-T、Google翻译和集成学习进行多语言推特亲密度检测

    tmn at SemEval-2023 Task 9: Multilingual Tweet Intimacy Detection using XLM-T, Google Translate, and Ensemble Learning. (arXiv:2304.04054v1 [cs.CL])

    [http://arxiv.org/abs/2304.04054](http://arxiv.org/abs/2304.04054)

    本文介绍了对于SemEval-2023的任务9，提出了一种基于transformer的系统，使用了集成学习，在多语言推特亲密度检测中排名第4，达到了0.5688的宏平均F1分数。为了提高对未见语言的性能表现，每个推特都进行了英文翻译的补充。

    

    本文介绍了一种基于transformer的系统，针对SemEval-2023任务9：多语言推特亲密度分析进行设计。任务的目的是预测一系列推特的亲密度，范围从1（完全不亲密）到5（非常亲密）。比赛的官方训练集包含六种语言的推特（英语、西班牙语、意大利语、葡萄牙语、法语和中文）。测试集包括六种给定的语言以及外部数据，其中包括训练集中未出现的四种语言（印地语、阿拉伯语、荷兰语和韩语）。我们提出了一种基于XLM-T的解决方案，即适用于Twitter领域的多语种RoBERTa模型的集成。为了提高对未见语言的性能表现，我们对每条推特进行了英文翻译的补充。我们探究了将翻译数据应用于微调中看到的语言与未看到的语言的transformer模型的有效性，并估计使用翻译数据的策略。我们的解决方案在50个团队中排名第4，并实现了0.5688的宏平均F1分数。

    The paper describes a transformer-based system designed for SemEval-2023 Task 9: Multilingual Tweet Intimacy Analysis. The purpose of the task was to predict the intimacy of tweets in a range from 1 (not intimate at all) to 5 (very intimate). The official training set for the competition consisted of tweets in six languages (English, Spanish, Italian, Portuguese, French, and Chinese). The test set included the given six languages as well as external data with four languages not presented in the training set (Hindi, Arabic, Dutch, and Korean). We presented a solution based on an ensemble of XLM-T, a multilingual RoBERTa model adapted to the Twitter domain. To improve the performance of unseen languages, each tweet was supplemented by its English translation. We explored the effectiveness of translated data for the languages seen in fine-tuning compared to unseen languages and estimated strategies for using translated data in transformer-based models. Our solution ranked 4th on the leade
    
[^34]: 仅解码器或编码器-解码器？将语言模型解释为正则化的编码器-解码器

    Decoder-Only or Encoder-Decoder? Interpreting Language Model as a Regularized Encoder-Decoder. (arXiv:2304.04052v1 [cs.CL])

    [http://arxiv.org/abs/2304.04052](http://arxiv.org/abs/2304.04052)

    该论文通过对正则化编码器-解码器结构进行比较，分析了仅解码器语言模型框架和编码器-解码器框架的效果。

    

    序列到序列（seq2seq）任务旨在基于给定的输入源序列生成目标序列。 传统上，大多数seq2seq任务都是通过编码器-解码器框架解决的，该框架需要编码器来编码源序列，并且需要解码器来生成目标文本。最近，出现了许多新方法，将仅解码器语言模型直接应用于seq2seq任务。尽管在将语言模型应用于seq2seq任务方面取得了重大进展，但仍然缺乏对仅解码器语言模型架构有效性的彻底分析。本文旨在通过对正则化编码器-解码器结构进行分析来解决这一差距。该结构旨在复制经典仅解码器语言模型中的所有行为，但具有编码器和解码器，从而更容易进行分析。

    The sequence-to-sequence (seq2seq) task aims at generating the target sequence based on the given input source sequence. Traditionally, most of the seq2seq task is resolved by the Encoder-Decoder framework which requires an encoder to encode the source sequence and a decoder to generate the target text. Recently, a bunch of new approaches have emerged that apply decoder-only language models directly to the seq2seq task. Despite the significant advancements in applying language models to the seq2seq task, there is still a lack of thorough analysis on the effectiveness of the decoder-only language model architecture. This paper aims to address this gap by conducting a detailed comparison between the encoder-decoder architecture and the decoder-only language model framework through the analysis of a regularized encoder-decoder structure. This structure is designed to replicate all behaviors in the classical decoder-only language model but has an encoder and a decoder making it easier to b
    
[^35]: RescueSNN: 在永久故障下提高脉冲神经网络加速器的可靠性

    RescueSNN: Enabling Reliable Executions on Spiking Neural Network Accelerators under Permanent Faults. (arXiv:2304.04041v1 [cs.NE])

    [http://arxiv.org/abs/2304.04041](http://arxiv.org/abs/2304.04041)

    RescueSNN是一种用于减轻SNN芯片计算引擎中永久故障的方法，可维持性能和质量并减少重新训练成本。

    

    为了在资源受限的嵌入式系统上最大化脉冲神经网络（SNN）处理的性能和能效，采用了专门的硬件加速器/芯片。然而，这些SNN芯片可能会受到永久故障的影响，这可能会导致重大的精度降低和系统故障。本文提出了一种名为RescueSNN的新方法，可以在不需要额外重新训练的情况下减轻SNN芯片计算引擎中的永久故障，从而显着降低设计时间和重新训练成本，同时保持吞吐量和质量。

    To maximize the performance and energy efficiency of Spiking Neural Network (SNN) processing on resource-constrained embedded systems, specialized hardware accelerators/chips are employed. However, these SNN chips may suffer from permanent faults which can affect the functionality of weight memory and neuron behavior, thereby causing potentially significant accuracy degradation and system malfunctioning. Such permanent faults may come from manufacturing defects during the fabrication process, and/or from device/transistor damages (e.g., due to wear out) during the run-time operation. However, the impact of permanent faults in SNN chips and the respective mitigation techniques have not been thoroughly investigated yet. Toward this, we propose RescueSNN, a novel methodology to mitigate permanent faults in the compute engine of SNN chips without requiring additional retraining, thereby significantly cutting down the design time and retraining costs, while maintaining the throughput and qu
    
[^36]: EnforceSNN: 在嵌入式系统中考虑近似DRAM，实现弹性和节能的脉冲神经网络推理

    EnforceSNN: Enabling Resilient and Energy-Efficient Spiking Neural Network Inference considering Approximate DRAMs for Embedded Systems. (arXiv:2304.04039v1 [cs.NE])

    [http://arxiv.org/abs/2304.04039](http://arxiv.org/abs/2304.04039)

    EnforceSNN 提出了一个新的设计框架，在嵌入式系统中考虑近似DRAM，使用量化权重降低DRAM的访问能量，实现了弹性和节能的SNN推理。

    

    脉冲神经网络（SNN）由于其生物可行计算能力，在无监督设置下具有高精度和低操作功率/能量。先前的研究发现，基于DRAM的 off-chip 内存访问占据了SNN处理的能量消耗。然而，现有的工作并未优化DRAM的每次访问的能量，从而阻碍了基于SNN的系统实现进一步的节能效益。为了大幅度降低DRAM的每次访问的能量，一个有效的解决方案是降低DRAM供电电压，但这可能会导致DRAM单元的错误（即所谓的近似DRAM）。为此，我们提出了EnforceSNN，一种新的设计框架，使用降压DRAM实现弹性和节能的 SNN 推理在嵌入式系统中。我们 EnforceSNN 的关键机制是:(1)采用量化权重降低DRAM的访问能量；(2)设计了一种高效的DRAM映射p

    Spiking Neural Networks (SNNs) have shown capabilities of achieving high accuracy under unsupervised settings and low operational power/energy due to their bio-plausible computations. Previous studies identified that DRAM-based off-chip memory accesses dominate the energy consumption of SNN processing. However, state-of-the-art works do not optimize the DRAM energy-per-access, thereby hindering the SNN-based systems from achieving further energy efficiency gains. To substantially reduce the DRAM energy-per-access, an effective solution is to decrease the DRAM supply voltage, but it may lead to errors in DRAM cells (i.e., so-called approximate DRAM). Towards this, we propose \textit{EnforceSNN}, a novel design framework that provides a solution for resilient and energy-efficient SNN inference using reduced-voltage DRAM for embedded systems. The key mechanisms of our EnforceSNN are: (1) employing quantized weights to reduce the DRAM access energy; (2) devising an efficient DRAM mapping p
    
[^37]: WikiGoldSK:斯洛伐克命名实体识别的带注释数据集，基准和少样本学习实验。

    WikiGoldSK: Annotated Dataset, Baselines and Few-Shot Learning Experiments for Slovak Named Entity Recognition. (arXiv:2304.04026v1 [cs.CL])

    [http://arxiv.org/abs/2304.04026](http://arxiv.org/abs/2304.04026)

    本研究介绍了第一个具有可观规模的人工标记的斯洛伐克NER数据集WikiGoldSK，通过评估当前最先进的多语言预训练语言模型，与现有的银标准数据集进行比较，并进行了少样本实验。银标准数据集上的训练能够产生更好的结果。

    

    命名实体识别（NER）是一种基础的NLP任务，具有广泛的实际应用。目前最先进的NER方法的性能取决于高质量手动注释数据集，但对于一些语言仍不存在这样的数据集。在本文中，我们旨在通过引入WikiGoldSK来解决斯洛伐克语中这种情况，这是第一个具有可观规模的人工标记的斯洛伐克NER数据集。我们通过评估最先进的多语言预训练语言模型并将其与现有的银标准斯洛伐克语NER数据集进行比较来对其进行基准测试。我们还进行了少样本实验，并表明在银标准数据集上的训练能够产生更好的结果。为了支持未来基于斯洛伐克NER的研究，我们在https://github.com/NaiveNeuron/WikiGoldSK公开发布了数据集、代码和训练模型，采用可允许的许可条款。

    Named Entity Recognition (NER) is a fundamental NLP tasks with a wide range of practical applications. The performance of state-of-the-art NER methods depends on high quality manually anotated datasets which still do not exist for some languages. In this work we aim to remedy this situation in Slovak by introducing WikiGoldSK, the first sizable human labelled Slovak NER dataset. We benchmark it by evaluating state-of-the-art multilingual Pretrained Language Models and comparing it to the existing silver-standard Slovak NER dataset. We also conduct few-shot experiments and show that training on a sliver-standard dataset yields better results. To enable future work that can be based on Slovak NER, we release the dataset, code, as well as the trained models publicly under permissible licensing terms at https://github.com/NaiveNeuron/WikiGoldSK.
    
[^38]: 一种考虑人-工匹配的团队组建问题的强化学习辅助遗传规划算法

    A Reinforcement Learning-assisted Genetic Programming Algorithm for Team Formation Problem Considering Person-Job Matching. (arXiv:2304.04022v1 [cs.NE])

    [http://arxiv.org/abs/2304.04022](http://arxiv.org/abs/2304.04022)

    研究提出了一种强化学习辅助遗传规划算法来解决考虑人-工匹配的团队组建问题，采用集合种群策略和代理模型加快算法学习过程，实现勘探和利用的平衡。

    

    高效的团队对于公司成功完成新项目至关重要。为解决考虑人-工匹配的团队组建问题（TFP-PJM），构建了一个0-1整数规划模型，该模型考虑了人-工匹配和团队成员通信意愿对团队效率的影响，使用直觉模糊数计算人-工匹配得分。然后，提出了一种强化学习辅助遗传规划算法（RL-GP）以提高解决方案的质量。RL-GP采用集合种群策略。在每一代种群进化之前，代理根据获得的信息从四种种群搜索模式中选择一种，从而实现了勘探和利用的良好平衡。此外，算法使用代理模型评估个体生成的组建方案，加快算法学习过程。然后，进行了一系列对比实验以验证算法的有效性。

    An efficient team is essential for the company to successfully complete new projects. To solve the team formation problem considering person-job matching (TFP-PJM), a 0-1 integer programming model is constructed, which considers both person-job matching and team members' willingness to communicate on team efficiency, with the person-job matching score calculated using intuitionistic fuzzy numbers. Then, a reinforcement learning-assisted genetic programming algorithm (RL-GP) is proposed to enhance the quality of solutions. The RL-GP adopts the ensemble population strategies. Before the population evolution at each generation, the agent selects one from four population search modes according to the information obtained, thus realizing a sound balance of exploration and exploitation. In addition, surrogate models are used in the algorithm to evaluate the formation plans generated by individuals, which speeds up the algorithm learning process. Afterward, a series of comparison experiments 
    
[^39]: REDf：基于长短期记忆网络的智能电网可再生能源需求预测模型

    REDf: A Renewable Energy Demand Forecasting Model for Smart Grids using Long Short Term Memory Network. (arXiv:2304.03997v1 [cs.LG])

    [http://arxiv.org/abs/2304.03997](http://arxiv.org/abs/2304.03997)

    本文提出了一种基于长短期记忆网络的智能电网可再生能源需求预测模型REDf，可以提供准确的能量需求预测，改善可再生能源的集成，实验结果表明其准确度优于其他模型。

    

    随着世界向更可持续的能源未来发展，将可再生能源源纳入电网的集成变得越来越重要。然而，可再生能源的间歇性使电网管理和确保稳定的电力供应变得具有挑战性。本文提出了一种基于深度学习的方法来预测智能电网中的能量需求，可以通过提供准确的能量需求预测来改善可再生能源的集成。我们使用长短期记忆网络来捕捉能럟需求数据中的复杂模式和依赖关系，这些网络特别适用于时间序列数据。所提出的方法使用了四个历史能量需求数据集，这些数据集来自不同的能源分配公司，包括美国电力、Commonwealth Edison、Dayton Power and Light以及宾夕法尼亚-新泽西-马里兰互联网。该方法还将REDf模型与其他两个深度学习模型和基准模型进行比较。实验结果表明，我们提出的REDf模型在平均绝对误差、均方根误差和决定系数等准确度指标方面优于其他模型。因此，REDf可以作为可再生能源需求预测的可靠工具，并提高可再生能源纳入智能电网的能力。

    The integration of renewable energy sources into the power grid is becoming increasingly important as the world moves towards a more sustainable energy future. However, the intermittent nature of renewable energy sources can make it challenging to manage the power grid and ensure a stable supply of electricity. In this paper, we propose a deep learning-based approach for predicting energy demand in a smart power grid, which can improve the integration of renewable energy sources by providing accurate predictions of energy demand. We use long short-term memory networks, which are well-suited for time series data, to capture complex patterns and dependencies in energy demand data. The proposed approach is evaluated using four datasets of historical energy demand data from different energy distribution companies including American Electric Power, Commonwealth Edison, Dayton Power and Light, and Pennsylvania-New Jersey-Maryland Interconnection. The proposed model is also compared with two 
    
[^40]: DREAM: 自适应注意力机制强化学习用于时间知识图谱推理

    DREAM: Adaptive Reinforcement Learning based on Attention Mechanism for Temporal Knowledge Graph Reasoning. (arXiv:2304.03984v1 [cs.AI])

    [http://arxiv.org/abs/2304.03984](http://arxiv.org/abs/2304.03984)

    DREAM提出了一种自适应的强化学习模型，基于注意力机制用于时间知识图谱推理，能够预测未来的缺失元素和理解推理路径。

    

    时间知识图谱（TKG）模型描绘了事件的时间演化，近来备受关注。由于TKG固有的不完备性，需要推理出缺失的元素。虽然现有的TKG推理方法能够预测缺失的未来事件，但是缺乏显式的推理路径和可解释性。由于传统知识图谱上的强化学习（RL）多跳推理在最近的进展中显示出优越的可解释性和性能，因此在TKG推理上探索RL技术的机会已经开启。然而，基于RL的TKG推理方法的性能受到以下限制：（1）缺乏同时捕捉时间演化和语义依赖的能力；（2）过度依赖手动设计的奖励。为了克服这些挑战，我们提出了一种基于注意力机制的自适应强化学习模型（DREAM）来预测未来的缺失元素。具体地说，

    Temporal knowledge graphs (TKGs) model the temporal evolution of events and have recently attracted increasing attention. Since TKGs are intrinsically incomplete, it is necessary to reason out missing elements. Although existing TKG reasoning methods have the ability to predict missing future events, they fail to generate explicit reasoning paths and lack explainability. As reinforcement learning (RL) for multi-hop reasoning on traditional knowledge graphs starts showing superior explainability and performance in recent advances, it has opened up opportunities for exploring RL techniques on TKG reasoning. However, the performance of RL-based TKG reasoning methods is limited due to: (1) lack of ability to capture temporal evolution and semantic dependence jointly; (2) excessive reliance on manually designed rewards. To overcome these challenges, we propose an adaptive reinforcement learning model based on attention mechanism (DREAM) to predict missing elements in the future. Specificall
    
[^41]: EMP-SSL：自监督学习中一次训练时代的探索

    EMP-SSL: Towards Self-Supervised Learning in One Training Epoch. (arXiv:2304.03977v1 [cs.CV])

    [http://arxiv.org/abs/2304.03977](http://arxiv.org/abs/2304.03977)

    本文介绍了一种名为EMP-SSL的自监督学习方法，它通过增加每个图像实例的裁剪数量来提高学习效率，缩短了训练时代数量，并在CIFAR-10、CIFAR-100、Tiny ImageNet和ImageNet-100数据集上仅使用一次训练时代而获得了竞争性能。

    

    最近，自监督学习（SSL）在学习图像表示方面取得了巨大成功。虽然取得了实验证据，但大多数自监督学习方法都是相当“低效”的学习方法，通常需要数百个训练时代才能完全收敛。本文表明，实现有效的自监督学习的关键是增加每个图像实例的裁剪数量。我们利用现有领先的SSL方法之一，引入了一种名为Extreme-Multi-Patch（EMP）自监督学习方法，它不依赖于许多用于SSL的启发式技术，例如分支之间的重量共享、特征归一化、输出量化和停止梯度等，并将训练时代缩短了两个数量级。我们展示了该方法能够在仅一个时代内收敛到CIFAR-10上的85.1％，CIFAR-100上的58.5％，Tiny ImageNet上的38.1％和ImageNet-100上的58.5％。此外，我们证明了我们的方法与最先进的SSL方法和监督预训练方法相比具有竞争性能。我们的结果表明，EMP-SSL是一种简单、高效且有效的自监督学习方法。

    Recently, self-supervised learning (SSL) has achieved tremendous success in learning image representation. Despite the empirical success, most self-supervised learning methods are rather "inefficient" learners, typically taking hundreds of training epochs to fully converge. In this work, we show that the key towards efficient self-supervised learning is to increase the number of crops from each image instance. Leveraging one of the state-of-the-art SSL method, we introduce a simplistic form of self-supervised learning method called Extreme-Multi-Patch Self-Supervised-Learning (EMP-SSL) that does not rely on many heuristic techniques for SSL such as weight sharing between the branches, feature-wise normalization, output quantization, and stop gradient, etc, and reduces the training epochs by two orders of magnitude. We show that the proposed method is able to converge to 85.1% on CIFAR-10, 58.5% on CIFAR-100, 38.1% on Tiny ImageNet and 58.5% on ImageNet-100 in just one epoch. Furthermor
    
[^42]: 量化模型的鲁棒性基准测试

    Benchmarking the Robustness of Quantized Models. (arXiv:2304.03968v1 [cs.LG])

    [http://arxiv.org/abs/2304.03968](http://arxiv.org/abs/2304.03968)

    量化模型在受到各种噪声的影响时表现出脆弱性，较低位的量化对抗攻击更具弹性，但更容易受到自然扰动和系统噪声的影响。

    

    量化已经成为在资源有限的设备上部署深度神经网络(DNNs)的重要技术。然而，在现实世界应用中，量化模型在受到各种噪声的影响时表现出脆弱性。尽管评估量化对鲁棒性的影响很重要，但是关于这个主题的现有研究有限且常常忽略了已经建立的鲁棒性评估原则，导致了不完整和无法下结论的研究结果。为了填补这一空白，我们在ImageNet上充分评估了量化模型对各种噪声(对抗攻击、自然扰动和系统噪声)的鲁棒性。广泛的实验表明，较低位的量化对抗攻击更具弹性，但更容易受到自然扰动和系统噪声的影响。值得注意的是，我们的研究发现，脉冲噪声(在自然扰动中)和最近邻插值(在系统噪声中)对量化模型的鲁棒性影响最大。

    Quantization has emerged as an essential technique for deploying deep neural networks (DNNs) on devices with limited resources. However, quantized models exhibit vulnerabilities when exposed to various noises in real-world applications. Despite the importance of evaluating the impact of quantization on robustness, existing research on this topic is limited and often disregards established principles of robustness evaluation, resulting in incomplete and inconclusive findings. To address this gap, we thoroughly evaluated the robustness of quantized models against various noises (adversarial attacks, natural corruptions, and systematic noises) on ImageNet. Extensive experiments demonstrate that lower-bit quantization is more resilient to adversarial attacks but is more susceptible to natural corruptions and systematic noises. Notably, our investigation reveals that impulse noise (in natural corruptions) and the nearest neighbor interpolation (in systematic noises) have the most significan
    
[^43]: MphayaNER：适用于茨汉文达语的命名实体识别

    MphayaNER: Named Entity Recognition for Tshivenda. (arXiv:2304.03952v1 [cs.CL])

    [http://arxiv.org/abs/2304.03952](http://arxiv.org/abs/2304.03952)

    MphayaNER是第一个适用于茨汉文达语的NER语料库，研究通过在语料库上微调最先进的模型，探索了茨文达语与其他相关班图语之间的零样本转移。用chiShona数据扩充MphayaNER可以显著提高模型性能。

    

    命名实体识别（NER）在各种自然语言处理任务中发挥着至关重要的作用，如信息检索、文本分类和问答。然而，对于数据集和工具有限的低资源语言而言，NER可能是具有挑战性的。本文通过引入MphayaNER来解决这些挑战，这是新闻领域中第一个适用于茨汉文达语的NER语料库。我们通过在MphayaNER上\微调\最先进的模型来建立NER基线。该研究还探讨了茨文达语与其他相关班图语之间的零样本转移，其中chiShona和Kiswahili表现最佳。发现用chiShona数据扩充MphayaNER也可以显著提高模型性能。MphayaNER和基线模型都已公开发布。

    Named Entity Recognition (NER) plays a vital role in various Natural Language Processing tasks such as information retrieval, text classification, and question answering. However, NER can be challenging, especially in low-resource languages with limited annotated datasets and tools. This paper adds to the effort of addressing these challenges by introducing MphayaNER, the first Tshivenda NER corpus in the news domain. We establish NER baselines by \textit{fine-tuning} state-of-the-art models on MphayaNER. The study also explores zero-shot transfer between Tshivenda and other related Bantu languages, with chiShona and Kiswahili showing the best results. Augmenting MphayaNER with chiShona data was also found to improve model performance significantly. Both MphayaNER and the baseline models are made publicly available.
    
[^44]: 利用隐式神经表示捕获动力学相关性。

    Capturing dynamical correlations using implicit neural representations. (arXiv:2304.03949v1 [cond-mat.str-el])

    [http://arxiv.org/abs/2304.03949](http://arxiv.org/abs/2304.03949)

    本文提出一种结合了神经网络和自动区分技术的新方法，在实验数据中恢复未知参数，可以方便地建立和训练可区分模型以分析集体激发。

    

    在物质中观测和描述集体激发是理解多体系统物理学的一个基本问题。通常通过弹性散射或X射线散射技术测量动态结构因子S(Q，ω)并将其与计算的动态模型进行比较来分析这些激发。本文开发了一个人工智能框架，它结合了一个神经网络，该神经网络被训练成模仿模型哈密顿量的模拟数据，并自动区分来从实验数据中恢复未知参数。我们在线性自旋波理论（LSWT）模拟器和来自方阵自旋-1反铁磁体La2NiO4的先进弹性中子散射数据上进行了基准测试。我们发现相对于分析拟合，模型预测未知参数的表现出极好的吻合。通过本文，我们展示了建立和训练可区分模型的能力。

    The observation and description of collective excitations in solids is a fundamental issue when seeking to understand the physics of a many-body system. Analysis of these excitations is usually carried out by measuring the dynamical structure factor, S(Q, $\omega$), with inelastic neutron or x-ray scattering techniques and comparing this against a calculated dynamical model. Here, we develop an artificial intelligence framework which combines a neural network trained to mimic simulated data from a model Hamiltonian with automatic differentiation to recover unknown parameters from experimental data. We benchmark this approach on a Linear Spin Wave Theory (LSWT) simulator and advanced inelastic neutron scattering data from the square-lattice spin-1 antiferromagnet La$_2$NiO$_4$. We find that the model predicts the unknown parameters with excellent agreement relative to analytical fitting. In doing so, we illustrate the ability to build and train a differentiable model only once, which th
    
[^45]: 无监督语音表示池化的矢量量化方法

    Unsupervised Speech Representation Pooling Using Vector Quantization. (arXiv:2304.03940v1 [cs.LG])

    [http://arxiv.org/abs/2304.03940](http://arxiv.org/abs/2304.03940)

    该论文提出了一种新颖的无监督语音表示池化方法，通过矢量量化压缩声学上相似的表示，不需要额外的训练，并在多个下游任务上进行了评估和分析。

    

    随着大规模自监督模型生成通用语音表示，将一个模型应用到多个下游任务已成为一种事实标准。然而，池化问题仍然存在；语音表示的长度固有地是可变的。尽管忽略了语音的特性，例如不同长度的音素，但通常使用简单的平均池化方法。因此，我们设计了一种新颖的池化方法，通过矢量量化来压缩声学上相似的表示，与基于注意力的池化方法不同，不需要额外的训练。此外，我们评估了各种无监督池化方法在各种自监督模型上的表现。我们收集了散落在语音和文本领域的不同方法，并在各种任务上进行评估：关键字识别、说话人识别、意图分类和情感识别。最后，我们对我们的方法进行定量和定性分析，将其与有监督的池化方法进行比较。

    With the advent of general-purpose speech representations from large-scale self-supervised models, applying a single model to multiple downstream tasks is becoming a de-facto approach. However, the pooling problem remains; the length of speech representations is inherently variable. The naive average pooling is often used, even though it ignores the characteristics of speech, such as differently lengthed phonemes. Hence, we design a novel pooling method to squash acoustically similar representations via vector quantization, which does not require additional training, unlike attention-based pooling. Further, we evaluate various unsupervised pooling methods on various self-supervised models. We gather diverse methods scattered around speech and text to evaluate on various tasks: keyword spotting, speaker identification, intent classification, and emotion recognition. Finally, we quantitatively and qualitatively analyze our method, comparing it with supervised pooling methods.
    
[^46]: 学生和大型语言模型所创建的代码解释的比较研究

    Comparing Code Explanations Created by Students and Large Language Models. (arXiv:2304.03938v1 [cs.CY])

    [http://arxiv.org/abs/2304.03938](http://arxiv.org/abs/2304.03938)

    该论文探讨了采用大型语言模型生成代码解释的潜力，以帮助学生提高理解和解释代码的能力。

    

    推理代码并解释其用途是计算机科学家的基本技能。在计算机教育领域，已经进行了广泛的研究，探讨了学生解释代码能力与编写和追踪代码等其他技能之间的关系。特别是，以高抽象级别描述代码在所有可能输入下的行为的能力强烈关联着代码编写技能。然而，对于许多学生来说，开发理解和准确简洁地解释代码的专业知识是一个挑战。现有的教学方法并未实现生产即时范例代码解释以进行指导的大规模课堂的步骤。强大的大型语言模型 (LLMs) 的出现近期可能提供了一种解决方案。在本文中，我们探讨了 LLMs 生成可以作为示例来支持学生理解和解释代码的解释的潜力。

    Reasoning about code and explaining its purpose are fundamental skills for computer scientists. There has been extensive research in the field of computing education on the relationship between a student's ability to explain code and other skills such as writing and tracing code. In particular, the ability to describe at a high-level of abstraction how code will behave over all possible inputs correlates strongly with code writing skills. However, developing the expertise to comprehend and explain code accurately and succinctly is a challenge for many students. Existing pedagogical approaches that scaffold the ability to explain code, such as producing exemplar code explanations on demand, do not currently scale well to large classrooms. The recent emergence of powerful large language models (LLMs) may offer a solution. In this paper, we explore the potential of LLMs in generating explanations that can serve as examples to scaffold students' ability to understand and explain code. To e
    
[^47]: 3D GAN与潜空间：综述

    3D GANs and Latent Space: A comprehensive survey. (arXiv:2304.03932v1 [cs.CV])

    [http://arxiv.org/abs/2304.03932](http://arxiv.org/abs/2304.03932)

    3D GAN是生成三维重建、点云重建和3D语义场景完成的新型生成模型。选择噪声分布对应着潜空间，理解其结构有助于微调生成样本。该论文综述了3D GAN及其训练方法，针对未来研究提出了潜在方向。

    

    生成对抗网络（GAN）通过将低维随机噪声映射到高维空间中，在生成建模领域中发挥了重要作用。这些网络已被用于生成高分辨率图像和三维物体。在游戏或模拟等3D图形环境的开发过程中，高效建模3D对象和人脸至关重要。3D GAN是一种新型的生成模型，用于3D重建、点云重建和3D语义场景完成。噪声分布的选择非常重要，因为它表示了潜空间。为了微调生成的样本，理解GAN的潜空间是必要的，这可以通过对图像的语义有意义的部分进行形态变换来证明。在这项工作中，我们探索了潜空间和3D GAN，研究了几种GAN变体和训练方法，以洞察提高3D GAN训练的见解，并提出了未来研究的潜在方向。

    Generative Adversarial Networks (GANs) have emerged as a significant player in generative modeling by mapping lower-dimensional random noise to higher-dimensional spaces. These networks have been used to generate high-resolution images and 3D objects. The efficient modeling of 3D objects and human faces is crucial in the development process of 3D graphical environments such as games or simulations. 3D GANs are a new type of generative model used for 3D reconstruction, point cloud reconstruction, and 3D semantic scene completion. The choice of distribution for noise is critical as it represents the latent space. Understanding a GAN's latent space is essential for fine-tuning the generated samples, as demonstrated by the morphing of semantically meaningful parts of images. In this work, we explore the latent space and 3D GANs, examine several GAN variants and training methods to gain insights into improving 3D GAN training, and suggest potential future directions for further research.
    
[^48]: 在微调时缓解多模态模型中的错误相关性

    Mitigating Spurious Correlations in Multi-modal Models during Fine-tuning. (arXiv:2304.03916v1 [cs.LG])

    [http://arxiv.org/abs/2304.03916](http://arxiv.org/abs/2304.03916)

    本文提出了一种使用多模态对比损失函数的方法，通过在微调期间检测和明确区分受影响类别的错误属性，缓解多模态模型的错误相关性，同时提高模型精度和指向目标领域的有意义特征。

    

    损害模型泛化能力或导致模型基于错误原因的错误相关性是实际部署面临的主要鲁棒性问题之一。然而，在预训练大型模型期间缓解这些相关性可能成本高昂且不切实际，特别是对于没有高性能计算资源的人来说。本文提出了一种新方法，以解决特定领域的微调期间的错误相关性。针对多模态模型（例如CLIP），所提出的方法利用这些模型中的不同模态来检测并明确区分受影响类别的错误属性，通过表达语言的多模态对比损失函数来实现。我们在CLIP上进行的实验证明和深入的可视化显示，这种介入能够有效地提高模型精度，而不存在错误属性，并将模型指向目标领域的有意义特征。

    Spurious correlations that degrade model generalization or lead the model to be right for the wrong reasons are one of the main robustness concerns for real-world deployments. However, mitigating these correlations during pre-training for large-scale models can be costly and impractical, particularly for those without access to high-performance computing resources. This paper proposes a novel approach to address spurious correlations during fine-tuning for a given domain of interest. With a focus on multi-modal models (e.g., CLIP), the proposed method leverages different modalities in these models to detect and explicitly set apart spurious attributes from the affected class, achieved through a multi-modal contrastive loss function that expresses spurious relationships through language. Our experimental results and in-depth visualizations on CLIP show that such an intervention can effectively i) improve the model's accuracy when spurious attributes are not present, and ii) directs the 
    
[^49]: InstructBio：一种针对生物化学问题的大规模半监督学习范式。

    InstructBio: A Large-scale Semi-supervised Learning Paradigm for Biochemical Problems. (arXiv:2304.03906v1 [cs.LG])

    [http://arxiv.org/abs/2304.03906](http://arxiv.org/abs/2304.03906)

    InstructBio是一种针对生物化学问题的大规模半监督学习算法，引入教练模型提供有效的置信度比率来指导目标模型对不同数据点给予明显关注，避免依赖有限的标记数据和不正确的伪注释，提高了分子模型的泛化能力。

    

    在科学人工智能领域，面对真实世界问题中的有限标记数据始终是一个重要的挑战。目前的方法是在大型未标记语料库上预训练强力的任务无关模型，但在向下游任务转移知识方面可能存在困难。在本研究中，我们提出了InstructBio，一种半监督学习算法，更好地利用未标记的样例。它引入教练模型来提供伪标签可靠性的置信度比率。这些置信度分数然后指导目标模型对不同的数据点给予明显的关注，避免对标记数据的过度依赖以及不正确的伪注释的负面影响。全面的实验表明，InstructBio显著提高了分子模型的泛化能力，不仅在分子属性预测方面，在活性悬崖估计方面也表现出优越性。

    In the field of artificial intelligence for science, it is consistently an essential challenge to face a limited amount of labeled data for real-world problems. The prevailing approach is to pretrain a powerful task-agnostic model on a large unlabeled corpus but may struggle to transfer knowledge to downstream tasks. In this study, we propose InstructMol, a semi-supervised learning algorithm, to take better advantage of unlabeled examples. It introduces an instructor model to provide the confidence ratios as the measurement of pseudo-labels' reliability. These confidence scores then guide the target model to pay distinct attention to different data points, avoiding the over-reliance on labeled data and the negative influence of incorrect pseudo-annotations. Comprehensive experiments show that InstructBio substantially improves the generalization ability of molecular models, in not only molecular property predictions but also activity cliff estimations, demonstrating the superiority of 
    
[^50]: 一张图像生成高保真度着装人物的三维重建

    High-Fidelity Clothed Avatar Reconstruction from a Single Image. (arXiv:2304.03903v1 [cs.CV])

    [http://arxiv.org/abs/2304.03903](http://arxiv.org/abs/2304.03903)

    本文提出了一种基于优化和学习相结合的高效三维着装人物重建框架，能够从单张图像中生成高保真度的三维人物。

    

    本文提出了一种高效的三维着装人物重建框架。将基于优化的方法的高精度与基于学习的方法的高效率相结合，我们提出了一种从单张图像实现高保真度着装人物重建的粗到精的方法。在第一阶段中，我们利用隐式模型以学习的方式在人物的规范空间中学习一般形状，第二阶段则通过在变形空间中估计非刚性变形来细化表面细节。一个超级网络被用来生成良好的初始化参数，从而大大加快优化过程的收敛速度。在各种数据集上的广泛实验表明，所提出的方法成功地从现实场景中的任意着装人物中生成了高保真度的三维人物。

    This paper presents a framework for efficient 3D clothed avatar reconstruction. By combining the advantages of the high accuracy of optimization-based methods and the efficiency of learning-based methods, we propose a coarse-to-fine way to realize a high-fidelity clothed avatar reconstruction (CAR) from a single image. At the first stage, we use an implicit model to learn the general shape in the canonical space of a person in a learning-based way, and at the second stage, we refine the surface detail by estimating the non-rigid deformation in the posed space in an optimization way. A hyper-network is utilized to generate a good initialization so that the convergence o f the optimization process is greatly accelerated. Extensive experiments on various datasets show that the proposed CAR successfully produces high-fidelity avatars for arbitrarily clothed humans in real scenes.
    
[^51]: 通过对比学习加强知识的短文本匹配模型

    The Short Text Matching Model Enhanced with Knowledge via Contrastive Learning. (arXiv:2304.03898v1 [cs.CL])

    [http://arxiv.org/abs/2304.03898](http://arxiv.org/abs/2304.03898)

    提出了一种短文本匹配模型，使用生成模型生成补充句子，结合对比学习和外部知识进行语义匹配，并使用关键词避免噪声问题。

    

    近年来，短文本匹配任务在广告搜索和推荐领域得到了广泛应用。由于文本长度短，语义信息匮乏和单词歧义问题成为此类任务的难点。先前的研究已经引入文本补充句子或知识库来提供附加的特征信息。然而，这些方法没有充分地交互原始句子和补充句子，也没有考虑到外部知识库引入的噪声问题。因此，本文提出了一种结合对比学习和外部知识的短文本匹配模型。该模型利用生成模型生成对应的补充句子，并使用对比学习方法指导模型获得更具语义匹配性的原始句子编码。此外，为了避免噪声，我们使用关键词作为原始句子的主要语义进行检索。

    In recent years, short Text Matching tasks have been widely applied in the fields ofadvertising search and recommendation. The difficulty lies in the lack of semantic information and word ambiguity caused by the short length of the text. Previous works have introduced complement sentences or knowledge bases to provide additional feature information. However, these methods have not fully interacted between the original sentence and the complement sentence, and have not considered the noise issue that may arise from the introduction of external knowledge bases. Therefore, this paper proposes a short Text Matching model that combines contrastive learning and external knowledge. The model uses a generative model to generate corresponding complement sentences and uses the contrastive learning method to guide the model to obtain more semantically meaningful encoding of the original sentence. In addition, to avoid noise, we use keywords as the main semantics of the original sentence to retrie
    
[^52]: 自动化城市规划：生成式和聊天式 AI 相结合的城市规划探索

    Towards Automated Urban Planning: When Generative and ChatGPT-like AI Meets Urban Planning. (arXiv:2304.03892v1 [cs.AI])

    [http://arxiv.org/abs/2304.03892](http://arxiv.org/abs/2304.03892)

    本文探讨了城市规划与人工智能的交叉应用，重点是自动化用地配置，通过对抗学习、生成神经网络、深度编码器-解码器网络、对话式 AI 和地理空间和时间机器学习等技术，AI 可以为现代城市规划带来不少创新与贡献。

    

    城市规划领域和人工智能领域曾经是独立发展的，但现在两个领域开始交叉汇合，互相借鉴和受益。本文介绍了城市规划从可持续性、生活、经济、灾害和环境等方面的重要性，回顾了城市规划的基本概念，并将这些概念与机器学习的关键开放问题联系起来，包括对抗学习、生成神经网络、深度编码器-解码器网络、对话式 AI 以及地理空间和时间机器学习等，评估了 AI 如何为现代城市规划做出贡献。因此，一个核心问题是自动化用地配置，即从周围的地理空间、人类移动、社交媒体、环境和经济活动中为目标区域生成土地用途和建筑配置。最后，本文勾画了集成 AI 和城市规划面临的一些挑战和潜在解决方案。

    The two fields of urban planning and artificial intelligence (AI) arose and developed separately. However, there is now cross-pollination and increasing interest in both fields to benefit from the advances of the other. In the present paper, we introduce the importance of urban planning from the sustainability, living, economic, disaster, and environmental perspectives. We review the fundamental concepts of urban planning and relate these concepts to crucial open problems of machine learning, including adversarial learning, generative neural networks, deep encoder-decoder networks, conversational AI, and geospatial and temporal machine learning, thereby assaying how AI can contribute to modern urban planning. Thus, a central problem is automated land-use configuration, which is formulated as the generation of land uses and building configuration for a target area from surrounding geospatial, human mobility, social media, environment, and economic activities. Finally, we delineate some 
    
[^53]: 保守的客观模型是一种特殊的基于对比散度能量模型

    Conservative objective models are a special kind of contrastive divergence-based energy model. (arXiv:2304.03866v1 [stat.ML])

    [http://arxiv.org/abs/2304.03866](http://arxiv.org/abs/2304.03866)

    本文证明了在离线基于模型的优化中，保守的客观模型（COMs）是一种特殊的基于对比散度能量模型，同时提出了用Langevin MCMC采样器替换梯度上升采样器，以提高样本质量。

    

    本文理论上证明了保守的客观模型（COMs）用于离线基于模型的优化（MBO）是一种特殊的基于对比散度能量模型，其中能量函数既表示输入的无条件概率，也表示奖励变量的条件概率。虽然最初的公式只从其学习分布中抽样模型，但我们提出了一个简单的修复方法，用Langevin MCMC采样器替换梯度上升采样器。这产生了一种特殊的概率模型，其中采样输入的概率与其预测的奖励成比例。最后，我们证明，如果将模型分解，使无条件概率和条件概率分别建模，可以获得更好的样本。

    In this work we theoretically show that conservative objective models (COMs) for offline model-based optimisation (MBO) are a special kind of contrastive divergence-based energy model, one where the energy function represents both the unconditional probability of the input and the conditional probability of the reward variable. While the initial formulation only samples modes from its learned distribution, we propose a simple fix that replaces its gradient ascent sampler with a Langevin MCMC sampler. This gives rise to a special probabilistic model where the probability of sampling an input is proportional to its predicted reward. Lastly, we show that better samples can be obtained if the model is decoupled so that the unconditional and conditional probabilities are modelled separately.
    
[^54]: 为什么要逐步思考？推理源于经验的局部性。

    Why think step-by-step? Reasoning emerges from the locality of experience. (arXiv:2304.03843v1 [cs.AI])

    [http://arxiv.org/abs/2304.03843](http://arxiv.org/abs/2304.03843)

    本文通过语言模型研究何时以及为什么推理是有帮助的，测试推理在训练数据由相互影响强烈的局部变量集群组成时是否有效。通过一步步的推理，能够将准确的局部推理链接在一起，以估算在训练中没有同时观察到的变量之间的关系。

    

    人类有着强大而神秘的推理能力。通过一系列纯粹的思维步骤，我们可以推理出我们无法直接得出的推论 - 尽管我们从世界上没有得到任何额外数据。同样地，大型语言模型可以通过一步步的推理，在回答问题之前生成中间步骤，从而更好地完成复杂的任务。我们使用语言模型研究何时以及为什么推理是有帮助的，测试推理在训练数据由相互影响强烈的局部变量集群组成时是否有效。这些训练条件能够将准确的局部推理链接在一起，以估算在训练中没有同时观察到的变量之间的关系。我们使用贝叶斯网络定义的联合分布的样品对自回归变压器进行训练，但每个样品只包括其中的一部分变量。我们比较使用推理生成的变量子集与使用完整集合进行训练的方案的性能。

    Humans have a powerful and mysterious capacity to reason. By working through a series of purely mental steps, we can make inferences we would not be capable of making directly -- despite that fact that we get no additional data from the world. Similarly, large language models can perform better at complex tasks through chain-of-thought reasoning, where they generate intermediate steps before answering a question. We use language models to investigate the questions of when and why reasoning is helpful, testing the hypothesis that reasoning is effective when training data consisting of local clusters of variables that influence each other strongly. These training conditions enable the chaining of accurate local inferences in order to estimate relationships between variables that were not seen together in training. We train an autoregressive transformer on samples from joint distributions defined by Bayes nets, but only include a subset of all the variables in each sample. We compare lang
    
[^55]: 提高人脸模型的身份鲁棒性

    Improving Identity-Robustness for Face Models. (arXiv:2304.03838v1 [cs.CV])

    [http://arxiv.org/abs/2304.03838](http://arxiv.org/abs/2304.03838)

    该论文探讨了在没有身份注释信息的情况下，使用人脸识别嵌入向量作为身份标识的替代方法，以提高人脸模型的身份鲁棒性和公平性。

    

    虽然深度学习模型在许多任务中取得了成功，但人们仍然担心这些模型可能学习到快捷方式，并且缺乏对无关混淆因素的鲁棒性。在直接训练于人脸上的模型中，一个敏感的混淆因素是人的身份。许多与人脸相关的任务理想情况下应该是与身份无关的，并在不同个体之间表现一致（即公平）。通过在训练期间强制执行这种鲁棒性和性能均匀性是度量和实施的一种方法，假设可以在规模上获取与身份相关的信息。但是，由于隐私问题以及收集此类信息的成本，这通常不是情况，大多数人脸数据集只包含输入图像及其相应的任务标签。因此，无需此类注释即可提高身份相关鲁棒性非常重要。在这里，我们探讨使用人脸识别嵌入向量作为身份标识的替代方法，以执行这种鲁棒性和公平性。

    Despite the success of deep-learning models in many tasks, there have been concerns about such models learning shortcuts, and their lack of robustness to irrelevant confounders. When it comes to models directly trained on human faces, a sensitive confounder is that of human identities. Many face-related tasks should ideally be identity-independent, and perform uniformly across different individuals (i.e. be fair). One way to measure and enforce such robustness and performance uniformity is through enforcing it during training, assuming identity-related information is available at scale. However, due to privacy concerns and also the cost of collecting such information, this is often not the case, and most face datasets simply contain input images and their corresponding task-related labels. Thus, improving identity-related robustness without the need for such annotations is of great importance. Here, we explore using face-recognition embedding vectors, as proxies for identities, to enfo
    
[^56]: ChiroDiff: 基于弥散模型的手写数据建模

    ChiroDiff: Modelling chirographic data with Diffusion Models. (arXiv:2304.03785v1 [cs.LG])

    [http://arxiv.org/abs/2304.03785](http://arxiv.org/abs/2304.03785)

    本论文介绍了一种名为"ChiroDiff"的模型类，该模型利用Denoising Diffusion Probabilistic Models（DDPMs）解决了手写数据建模过程中存在的问题，能够学习捕捉整体概念，在更高的时间采样率下保持弹性，并具有许多下游实用程序。

    

    通过自回归分布，已经实现了对于连续时间几何结构（如手写、草图、图画等）的生成建模。然而，这种严格有序的离散分解无法捕捉手写数据的关键属性——由于单向可见性（因果性），它无法建立整体的时间概念理解，因此在建模时将时间数据建模为固定采样率的离散标记序列，而未能捕获真正的基础概念。在本文中，我们介绍了一个名为“去噪弥散概率模型”（DDPMs）的强大模型类，专门为手写数据解决这些缺陷。我们的模型名为“ChiroDiff”，是非自回归的，学习捕捉整体概念，因此在更高的时间采样率下保持弹性至少有限。此外，我们展示了许多重要的下游实用程序（如条件采样、创意混合）。

    Generative modelling over continuous-time geometric constructs, a.k.a such as handwriting, sketches, drawings etc., have been accomplished through autoregressive distributions. Such strictly-ordered discrete factorization however falls short of capturing key properties of chirographic data -- it fails to build holistic understanding of the temporal concept due to one-way visibility (causality). Consequently, temporal data has been modelled as discrete token sequences of fixed sampling rate instead of capturing the true underlying concept. In this paper, we introduce a powerful model-class namely "Denoising Diffusion Probabilistic Models" or DDPMs for chirographic data that specifically addresses these flaws. Our model named "ChiroDiff", being non-autoregressive, learns to capture holistic concepts and therefore remains resilient to higher temporal sampling rate up to a good extent. Moreover, we show that many important downstream utilities (e.g. conditional sampling, creative mixing) c
    
[^57]: 生成AI用于学习：研究合成学习视频的潜力。

    Generative AI for learning: Investigating the potential of synthetic learning videos. (arXiv:2304.03784v1 [cs.CV])

    [http://arxiv.org/abs/2304.03784](http://arxiv.org/abs/2304.03784)

    本研究探讨了使用生成AI合成视频来创建在线教育内容的效用，使用混合方法和成年学习者进行实验。结果显示，合成学习视频对学习内容获取和学习体验有着积极的影响。

    

    最近，生成人工智能（AI）的最新进展已经引起了全球的关注。像Dalle-2和ChatGPT这样的工具表明，以前被认为超出了AI能力的任务现在可以以各种新方式增加创意媒体的生产力，包括生成合成视频。本研究探讨了使用生成AI合成视频来创建在在线教育环境下可行的教育内容的效用。到目前为止，还没有研究调查AI生成的合成媒体在现实世界中的教育价值。为了填补这一空白，我们采用混合方法随机将成年学习者（n = 83）分配到两种微型学习条件之一，收集前后学习评估，并调查参与者的学习体验。控制组

    Recent advances in generative artificial intelligence (AI) have captured worldwide attention. Tools such as Dalle-2 and ChatGPT suggest that tasks previously thought to be beyond the capabilities of AI may now augment the productivity of creative media in various new ways, including through the generation of synthetic video. This research paper explores the utility of using AI-generated synthetic video to create viable educational content for online educational settings. To date, there is limited research investigating the real-world educational value of AI-generated synthetic media. To address this gap, we examined the impact of using AI-generated synthetic video in an online learning platform on both learners content acquisition and learning experience. We took a mixed-method approach, randomly assigning adult learners (n=83) into one of two micro-learning conditions, collecting pre- and post-learning assessments, and surveying participants on their learning experience. The control c
    
[^58]: AutoQNN: 一种自动量化神经网络的端到端框架

    AutoQNN: An End-to-End Framework for Automatically Quantizing Neural Networks. (arXiv:2304.03782v1 [cs.LG])

    [http://arxiv.org/abs/2304.03782](http://arxiv.org/abs/2304.03782)

    AutoQNN是一种可自动量化DNN模型的端到端框架，利用三种技术实现了对适合不同层次的混合精度策略的搜索，并可有效提高效率和准确性。

    

    探索适合深度神经网络（DNN）压缩的量化方案与混合精度策略是提高效率和准确性的关键。然而，自动压缩方法的巨大搜索空间导致了大量的计算预算，这使得自动过程难以在实际场景中应用。在本文中，我们提出了一种名为AutoQNN的端到端框架，可以自动量化不同层次的DNN模型，而无需任何人工干预。

    Exploring the expected quantizing scheme with suitable mixed-precision policy is the key point to compress deep neural networks (DNNs) in high efficiency and accuracy. This exploration implies heavy workloads for domain experts, and an automatic compression method is needed. However, the huge search space of the automatic method introduces plenty of computing budgets that make the automatic process challenging to be applied in real scenarios. In this paper, we propose an end-to-end framework named AutoQNN, for automatically quantizing different layers utilizing different schemes and bitwidths without any human labor. AutoQNN can seek desirable quantizing schemes and mixed-precision policies for mainstream DNN models efficiently by involving three techniques: quantizing scheme search (QSS), quantizing precision learning (QPL), and quantized architecture generation (QAG). QSS introduces five quantizing schemes and defines three new schemes as a candidate set for scheme search, and then u
    
[^59]: 医疗保健中公平和可信预测模型验证的路线图

    A roadmap to fair and trustworthy prediction model validation in healthcare. (arXiv:2304.03779v1 [cs.LG])

    [http://arxiv.org/abs/2304.03779](http://arxiv.org/abs/2304.03779)

    针对医疗保健中预测模型的验证问题，建议使用来自目标人群的新数据进行外部验证，确保验证性能对模型可靠性的影响，并且在模型开发期间认真研究模型在更广泛环境中的拓展性。我们提出了一份路线图，以便在医疗保健中开发和应用可靠、公平、可信的人工智能模型。

    

    如果一个预测模型能够推广到开发数据以外的数据，并进行外部验证，那么它就是最有用的。但是，在多大程度上它可以推广仍不清楚。实际上，预测模型使用来自其他医疗系统或国家的人口等非常不同的数据进行外部验证，预测结果通常很差。这可能不是对特定目标人群或环境设计的模型表现的公正反映，并且可能会拉伸预期的模型推广性。为了解决这个问题，我们建议使用来自目标人群的新数据来外部验证模型，以确保验证性能对模型可靠性的清晰影响，而模型推广到更广泛的环境应在模型开发期间进行仔细调查，而不是事后探讨。基于这个观点，我们提出了一项路线图，以便在医疗保健中开发和应用可靠、公平、可信的人工智能模型。我们认为这份路线图应该清晰定义公平性和可信性，考虑模型使用的伦理影响，进行亚组分析，并采用严格的验证协议，其中包括在目标人群中进行外部验证。

    A prediction model is most useful if it generalizes beyond the development data with external validations, but to what extent should it generalize remains unclear. In practice, prediction models are externally validated using data from very different settings, including populations from other health systems or countries, with predictably poor results. This may not be a fair reflection of the performance of the model which was designed for a specific target population or setting, and may be stretching the expected model generalizability. To address this, we suggest to externally validate a model using new data from the target population to ensure clear implications of validation performance on model reliability, whereas model generalizability to broader settings should be carefully investigated during model development instead of explored post-hoc. Based on this perspective, we propose a roadmap that facilitates the development and application of reliable, fair, and trustworthy artifici
    
[^60]: 安全可解释机器人规划

    Safe Explicable Robot Planning. (arXiv:2304.03773v1 [cs.RO])

    [http://arxiv.org/abs/2304.03773](http://arxiv.org/abs/2304.03773)

    安全可解释机器人规划方法（SEP）扩展了可解释规划，支持安全界限的规定，以实现安全和可解释之间的权衡。

    

    人们的期望源自于他们对其他人和世界的了解。在涉及到人机交互的情况下，对机器人的了解可能与现实不符，导致机器人不能满足人们的期望。可解释规划被引入作为一种新颖的规划方法，以协调人类期望和最优机器人行为，进行更可解释的机器人决策。一个关键的问题尚未得到解决，那就是在可解释决策过程中的安全性问题，这可能会导致不安全的可解释行为。我们提出了安全可解释规划（SEP），它扩展了可解释规划，支持安全界限的规定。 SEP的目标是找到一种策略，生成接近于人类期望的行为，同时满足安全约束的要求。这是多目标优化的一种特殊情况，SEP的解决方案位于帕累托前沿，提供了一个切实可行的解决方案，在不牺牲任何方面的重要性的前提下，产生了安全性和解释性之间的一个权衡。

    Human expectations stem from their knowledge of the others and the world. Where human-robot interaction is concerned, such knowledge about the robot may be inconsistent with the ground truth, resulting in the robot not meeting its expectations. Explicable planning was previously introduced as a novel planning approach to reconciling human expectations and the optimal robot behavior for more interpretable robot decision-making. One critical issue that remains unaddressed is safety during explicable decision-making which can lead to explicable behaviors that are unsafe. We propose Safe Explicable Planning (SEP), which extends explicable planning to support the specification of a safety bound. The objective of SEP is to find a policy that generates a behavior close to human expectations while satisfying the safety constraints introduced by the bound, which is a special case of multi-objective optimization where the solution to SEP lies on the Pareto frontier. Under such a formulation, we 
    
[^61]: 重新考虑基于GNN的异构知识图谱实体对齐：新数据集和新方法

    Rethinking GNN-based Entity Alignment on Heterogeneous Knowledge Graphs: New Datasets and A New Method. (arXiv:2304.03468v1 [cs.LG])

    [http://arxiv.org/abs/2304.03468](http://arxiv.org/abs/2304.03468)

    文章重新考虑了基于GNN的异构知识图谱实体对齐。为探究EA实际场景中的表现，提出了更接近现实的高度异构知识图谱数据集，并提出了新方法。

    

    知识图谱（KG）应用的发展导致了需要从各种来源提取的异构KG之间的实体对齐（EA）的不断增长需求。近来，由于GNN的出色结构信息捕捉能力，在EA任务中广泛采用GNN。然而，我们观察到现有常见EA数据集的过于简单化的设置与现实场景相距甚远，这妨碍了对最近方法所取得进展的全面理解。这种现象使我们深思：现有基于GNN的EA方法是否真的取得了伟大进展？为了研究EA方法在现实情况下的性能，本文聚焦于高度异构的KG（HHKG）（例如，事件KG和通用KG）的对齐，这些KG在规模和结构上不同，并共享更少的重叠实体。首先，我们清理了不合理的设置，并提出了两个新的HHKG数据集，其密切地模拟了现实世界场景。

    The development of knowledge graph (KG) applications has led to a rising need for entity alignment (EA) between heterogeneous KGs that are extracted from various sources. Recently, graph neural networks (GNNs) have been widely adopted in EA tasks due to GNNs' impressive ability to capture structure information. However, we have observed that the oversimplified settings of the existing common EA datasets are distant from real-world scenarios, which obstructs a full understanding of the advancements achieved by recent methods. This phenomenon makes us ponder: Do existing GNN-based EA methods really make great progress?  In this paper, to study the performance of EA methods in realistic settings, we focus on the alignment of highly heterogeneous KGs (HHKGs) (e.g., event KGs and general KGs) which are different with regard to the scale and structure, and share fewer overlapping entities. First, we sweep the unreasonable settings, and propose two new HHKG datasets that closely mimic real-wo
    
[^62]: CAPOT: 使用后训练对比对齐创建强健的密集查询编码器

    CAPOT: Creating Robust Dense Query Encoders using Post Training Contrastive Alignment. (arXiv:2304.03401v1 [cs.IR])

    [http://arxiv.org/abs/2304.03401](http://arxiv.org/abs/2304.03401)

    CAPOT使用后训练对比对齐的方法，提高模型对于噪声查询的健壮性，表现类似于数据增强但没有其开销。

    

    上下文词表示的成功和神经信息检索的进步使得基于密集向量的检索成为段落和文档排名的标准方法。双编码器虽然有效和高效，但对查询分布和嘈杂查询变化很脆弱。数据增强可以使模型更加健壮，但会引入训练集生成的开销，并需要重新训练和索引重建。我们提出了 Contrastive Alignment POst Training (CAPOT)，一种高效的微调方法，通过冻结文档编码器，让查询编码器学习将嘈杂查询与其未更改的根对齐，以提高模型的健壮性。我们评估了 CAPOT 在 MSMARCO、自然问题和 Trivia QA 段落检索的嘈杂变体上，发现 CAPOT 具有与数据增强类似的影响，但没有它的开销。

    The success of contextual word representations and advances in neural information retrieval have made dense vector-based retrieval a standard approach for passage and document ranking. While effective and efficient, dual-encoders are brittle to variations in query distributions and noisy queries. Data augmentation can make models more robust but introduces overhead to training set generation and requires retraining and index regeneration. We present Contrastive Alignment POst Training (CAPOT), a highly efficient finetuning method that improves model robustness without requiring index regeneration, the training set optimization, or alteration. CAPOT enables robust retrieval by freezing the document encoder while the query encoder learns to align noisy queries with their unaltered root. We evaluate CAPOT noisy variants of MSMARCO, Natural Questions, and Trivia QA passage retrieval, finding CAPOT has a similar impact as data augmentation with none of its overhead.
    
[^63]: 比较NARS和强化学习：对ONA和$Q$-Learning算法的分析

    Comparing NARS and Reinforcement Learning: An Analysis of ONA and $Q$-Learning Algorithms. (arXiv:2304.03291v1 [cs.LG])

    [http://arxiv.org/abs/2304.03291](http://arxiv.org/abs/2304.03291)

    本文比较了NARS和强化学习在解决序列任务方面的性能，发现NARS在各种环境中都有较好的表现，尤其是在非确定性环境中。

    

    近年来，强化学习（RL）已成为解决机器学习中基于序列任务的流行方法。然而，寻找RL的可行替代方案仍然是一个令人兴奋和创新的研究领域。其中一个备受关注的替代方案是非公理推理系统（NARS），它是一个通用的认知推理框架。本文研究了NARS作为RL替代方案在解决基于序列任务方面的潜力。为了研究这一点，我们在使用Open AI gym创建的各种环境中，对ONA作为NARS实现和$Q$-Learning的性能进行了比较分析。这些环境具有不同的难度级别，从简单到复杂不等。我们的研究结果表明，在各种环境中，尤其是在非确定性环境中，NARS是一个有竞争力的RL替代方案。

    In recent years, reinforcement learning (RL) has emerged as a popular approach for solving sequence-based tasks in machine learning. However, finding suitable alternatives to RL remains an exciting and innovative research area. One such alternative that has garnered attention is the Non-Axiomatic Reasoning System (NARS), which is a general-purpose cognitive reasoning framework. In this paper, we delve into the potential of NARS as a substitute for RL in solving sequence-based tasks. To investigate this, we conduct a comparative analysis of the performance of ONA as an implementation of NARS and $Q$-Learning in various environments that were created using the Open AI gym. The environments have different difficulty levels, ranging from simple to complex. Our results demonstrate that NARS is a promising alternative to RL, with competitive performance in diverse environments, particularly in non-deterministic ones.
    
[^64]: 重新审视带有无法回答的反事实情景的密集检索

    Revisiting Dense Retrieval with Unanswerable Counterfactuals. (arXiv:2304.03031v1 [cs.AI])

    [http://arxiv.org/abs/2304.03031](http://arxiv.org/abs/2304.03031)

    本文观察到基于DPR的最近的密集检索模型经常将无法回答的反事实情景排名高于可回答的原始情景，提出了一种新颖的用于段落检索的表示学习方法PiCL。

    

    在开放领域问答（ODQA）中，检索器-阅读器框架很受欢迎，其中检索器从大型语料库中为阅读器抽取一组相关的候选段落。这种方法背后的一个关键假设是，从检索器得到的高相关性分数可能表明从阅读器获取答案的可能性很高，这意味着检索到的段落很可能包含给定问题的答案。我们在本研究中实证驳斥了这种观点，并观察到基于DPR的最近的密集检索模型经常将无法回答的反事实情景排名高于可回答的原始情景。为了解决密集检索中这种对答案无感知的问题，我们寻求使用反事实样本作为额外的训练资源，以更好地同步DPR的相关性测量和问题-段落对的可答性。具体地，我们提出了反事实Pivoting对比学习（PiCL），这是一种新颖的用于段落检索的表示学习方法。

    The retriever-reader framework is popular for open-domain question answering (ODQA), where a retriever samples for the reader a set of relevant candidate passages from a large corpus. A key assumption behind this method is that high relevance scores from the retriever likely indicate high answerability from the reader, which implies a high probability that the retrieved passages contain answers to a given question. In this work, we empirically dispel this belief and observe that recent dense retrieval models based on DPR often rank unanswerable counterfactual passages higher than their answerable original passages. To address such answer-unawareness in dense retrievers, we seek to use counterfactual samples as additional training resources to better synchronize the relevance measurement of DPR with the answerability of question-passage pairs. Specifically, we present counterfactually-Pivoting Contrastive Learning (PiCL), a novel representation learning approach for passage retrieval th
    
[^65]: 坚韧的神经架构搜索

    Robust Neural Architecture Search. (arXiv:2304.02845v1 [cs.LG])

    [http://arxiv.org/abs/2304.02845](http://arxiv.org/abs/2304.02845)

    提出了一种名为RNAS的神经架构搜索方法，通过平衡准确性和鲁棒性生成高质量架构，使用噪声样本减少搜索成本，在图像分类和对抗攻击中均达到最先进性能水平。

    

    近年来，神经架构搜索（NAS）变得越来越流行。然而，NAS生成的模型往往更容易受到各种恶意攻击的影响。许多强健的NAS方法利用对抗训练来增强NAS生成的模型的强健性，但是它们忽略了NAS生成的模型的本质准确性。在我们的论文中，我们提出了一种新颖的NAS方法，名为Robust Neural Architecture Search（RNAS）。为了设计出一个正则化项来平衡准确性和鲁棒性，RNAS生成具有高准确性和良好鲁棒性的架构。为了减少搜索成本，我们提出使用噪声样本而不是对抗性样本作为搜索架构的输入。广泛的实验表明，RNAS在图像分类和对抗攻击方面均达到了最先进（SOTA）的性能，这证明了所提出的RNAS在准确性和鲁棒性之间取得了良好的平衡。

    Neural Architectures Search (NAS) becomes more and more popular over these years. However, NAS-generated models tends to suffer greater vulnerability to various malicious attacks. Lots of robust NAS methods leverage adversarial training to enhance the robustness of NAS-generated models, however, they neglected the nature accuracy of NAS-generated models. In our paper, we propose a novel NAS method, Robust Neural Architecture Search (RNAS). To design a regularization term to balance accuracy and robustness, RNAS generates architectures with both high accuracy and good robustness. To reduce search cost, we further propose to use noise examples instead adversarial examples as input to search architectures. Extensive experiments show that RNAS achieves state-of-the-art (SOTA) performance on both image classification and adversarial attacks, which illustrates the proposed RNAS achieves a good tradeoff between robustness and accuracy.
    
[^66]: 大型语言模型作为钥匙：用GPT解密材料科学的秘密。

    Large Language Models as Master Key: Unlocking the Secrets of Materials Science with GPT. (arXiv:2304.02213v1 [cs.CL])

    [http://arxiv.org/abs/2304.02213](http://arxiv.org/abs/2304.02213)

    本文介绍了一个新的自然语言处理任务——结构化信息推理（SIS），利用GPT-3模型能够准确提取材料科学设备层面的信息，并通过实验预测PCE和反向预测参数，展示了大型语言模型在材料学中的巨大潜力。

    

    本文介绍了一个新的自然语言处理（NLP）任务——结构化信息推理（SIS），以解决材料科学设备层面信息提取的复杂性。我们使用现有的钙钛矿太阳能电池FAIR数据集对GPT-3进行微调，获得了91.8 F1得分，并更新了数据集，包括迄今为止所有相关科学论文。所生成的数据集已被格式化和标准化，使得它可以直接作为后续数据分析的输入。这个特性将使材料科学家通过选择高质量的领域评论文章来开发其自己的模型。此外，我们设计了实验来预测PCE和反向预测参数，并获得了与DFT相当的性能，这证明了大型语言模型能够像材料学家一样评判材料和设计新材料。

    This article presents a new NLP task called structured information inference (SIS) to address the complexities of information extraction at the device level in materials science. We accomplished this task by finetuning GPT-3 on a exsiting perovskite solar cell FAIR dataset with 91.8 F1-score and we updated the dataset with all related scientific papers up to now. The produced dataset is formatted and normalized, enabling its direct utilization as input in subsequent data analysis. This feature will enable materials scientists to develop their own models by selecting high-quality review papers within their domain. Furthermore, we designed experiments to predict PCE and reverse-predict parameters and obtained comparable performance with DFT, which demonstrates the potential of large language models to judge materials and design new materials like a materials scientist.
    
[^67]: EPVT: 基于环境感知的提示视觉Transformer在皮肤病变识别领域一般化中的应用

    EPVT: Environment-aware Prompt Vision Transformer for Domain Generalization in Skin Lesion Recognition. (arXiv:2304.01508v1 [cs.CV])

    [http://arxiv.org/abs/2304.01508](http://arxiv.org/abs/2304.01508)

    EPVT是一种基于环境感知的提示视觉Transformer，用于解决皮肤病变识别中深度神经网络可能过度依赖疾病不相关图像特征的问题，通过嵌入一组领域提示和一个共享提示来进行领域一般化，并且引入了领域提示生成器促进知识共享。

    

    利用深度学习进行皮肤病变识别已取得重大进展，而在现实世界场景中部署这些系统的需求不断增加。然而，最近的研究表明，用于皮肤病变识别的深度神经网络可能过度依赖于与疾病不相关的图像特征（如暗角、浓密毛发），导致在看不见的环境中表现不佳。为了解决这个问题，我们提出了一种新颖的领域一般化方法——EPVT，它将提示嵌入到Vision Transformer中，以协同学习来自不同领域的知识。具体而言，EPVT利用一组领域提示，每个领域提示都扮演领域专家的角色，以捕获领域特定的知识；以及一个共享提示来获得整个数据集的通用知识。为了促进知识共享和不同提示之间的交互，我们引入了一个领域提示生成器，它使得领域提示与共享提示之间可以进行低秩乘性更新。

    Skin lesion recognition using deep learning has made remarkable progress, and there is an increasing need for deploying these systems in real-world scenarios. However, recent research has revealed that deep neural networks for skin lesion recognition may overly depend on disease-irrelevant image artifacts (i.e. dark corners, dense hairs), leading to poor generalization in unseen environments. To address this issue, we propose a novel domain generalization method called EPVT, which involves embedding prompts into the vision transformer to collaboratively learn knowledge from diverse domains. Concretely, EPVT leverages a set of domain prompts, each of which plays as a domain expert, to capture domain-specific knowledge; and a shared prompt for general knowledge over the entire dataset. To facilitate knowledge sharing and the interaction of different prompts, we introduce a domain prompt generator that enables low-rank multiplicative updates between domain prompts and the shared prompt. A
    
[^68]: TPU v4：一款支持嵌入式硬件的可重构光学超级计算机用于机器学习

    TPU v4: An Optically Reconfigurable Supercomputer for Machine Learning with Hardware Support for Embeddings. (arXiv:2304.01433v1 [cs.AR])

    [http://arxiv.org/abs/2304.01433](http://arxiv.org/abs/2304.01433)

    TPU v4是一款支持嵌入式硬件的可重构光学超级计算机，采用光学电路交换机重新配置互连拓扑，提高规模、可用性、利用率、模块化、部署、安全、功率和性能，它通过SparseCores加速嵌入式模型，性能优越，功耗低。

    

    针对机器学习模型的创新，生产工作负载发生了根本性和迅速的变化。TPU v4是谷歌的第五代面向特定领域架构（DSA），是其第三个用于处理此类机器学习模型的超级计算机。光学电路交换机（OCS）动态重新配置其互连拓扑，以提高规模、可用性、利用率、模块化、部署、安全、功率和性能。部署自2020年以来，TPU v4超级计算机的表现优于TPU v3，同时性能/Watt提高了2.7倍。

    In response to innovations in machine learning (ML) models, production workloads changed radically and rapidly. TPU v4 is the fifth Google domain specific architecture (DSA) and its third supercomputer for such ML models. Optical circuit switches (OCSes) dynamically reconfigure its interconnect topology to improve scale, availability, utilization, modularity, deployment, security, power, and performance; users can pick a twisted 3D torus topology if desired. Much cheaper, lower power, and faster than Infiniband, OCSes and underlying optical components are <5% of system cost and <3% of system power. Each TPU v4 includes SparseCores, dataflow processors that accelerate models that rely on embeddings by 5x-7x yet use only 5% of die area and power. Deployed since 2020, TPU v4 outperforms TPU v3 by 2.1x and improves performance/Watt by 2.7x. The TPU v4 supercomputer is 4x larger at 4096 chips and thus ~10x faster overall, which along with OCS flexibility helps large language models. For sim
    
[^69]: RePAST：相对位姿注意力场景表示变换器

    RePAST: Relative Pose Attention Scene Representation Transformer. (arXiv:2304.00947v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2304.00947](http://arxiv.org/abs/2304.00947)

    RePAST是一种相对位姿注意力场景表示变换器，其将成对的相对相机姿态信息直接注入转换器的注意机制中，不需要固定参考帧，同时保留了原始方法的全部功能，加入这种不变性并不会导致质量下降，可以应用于大规模场景。

    

    场景表示变换器（SRT）是一种最近的方法，可以以交互速率渲染新视图。由于SRT使用相对于任意选择的参考摄像机的相机姿态，因此它对输入视图的顺序不变。因此，SRT不直接适用于需要定期更改参考帧的大规模场景。在这项工作中，我们提出了相对姿态注意力SRT（RePAST）：我们将成对的相对相机姿态信息直接注入转换器的注意机制中，而不是在输入时固定一个参考帧。这导致了一个模型，其定义不变于任何全局参考帧的选择，同时仍保留原始方法的全部功能。实证结果表明，将这种不变性添加到模型中并不会导致质量下降。我们认为这是向应用完全潜在的基于Transformer的渲染方法于大规模场景迈出的一步。

    The Scene Representation Transformer (SRT) is a recent method to render novel views at interactive rates. Since SRT uses camera poses with respect to an arbitrarily chosen reference camera, it is not invariant to the order of the input views. As a result, SRT is not directly applicable to large-scale scenes where the reference frame would need to be changed regularly. In this work, we propose Relative Pose Attention SRT (RePAST): Instead of fixing a reference frame at the input, we inject pairwise relative camera pose information directly into the attention mechanism of the Transformers. This leads to a model that is by definition invariant to the choice of any global reference frame, while still retaining the full capabilities of the original method. Empirical results show that adding this invariance to the model does not lead to a loss in quality. We believe that this is a step towards applying fully latent transformer-based rendering methods to large-scale scenes.
    
[^70]: RL中的反向攻击保护：恢复触发状态方法

    Recover Triggered States: Protect Model Against Backdoor Attack in Reinforcement Learning. (arXiv:2304.00252v1 [cs.LG])

    [http://arxiv.org/abs/2304.00252](http://arxiv.org/abs/2304.00252)

    本文提出了恢复触发状态(RTS)方法，用于保护RL代理免受反向攻击。该方法涉及构建替代网络来近似动态模型，并将触发状态恢复为干净状态来防止攻击者通过触发器激活隐藏在代理中的后门。

    

    反向攻击可以使恶意用户操纵环境或破坏训练数据，并将一个隐藏的后门插入到训练代理程序中。这种攻击危及RL系统的可靠性，在各个关键领域可能会造成灾难性的影响。与此相比，对于RL中的反向攻击有效的防御措施的研究相对较少。本文提出了一种新颖的方法——恢复触发状态(RTS)，能够有效地保护受害代理免受反向攻击。 RTS需要构建一个替代网络来近似动态模型。开发人员可以通过将触发状态恢复为干净状态来防止攻击者通过触发器激活代理中隐藏的后门。在训练替代网络来预测状态时，我们将代理动作信息并入，减少代理在预测状态上采取的动作和实际状态上采取的动作之间的差异。

    A backdoor attack allows a malicious user to manipulate the environment or corrupt the training data, thus inserting a backdoor into the trained agent. Such attacks compromise the RL system's reliability, leading to potentially catastrophic results in various key fields. In contrast, relatively limited research has investigated effective defenses against backdoor attacks in RL. This paper proposes the Recovery Triggered States (RTS) method, a novel approach that effectively protects the victim agents from backdoor attacks. RTS involves building a surrogate network to approximate the dynamics model. Developers can then recover the environment from the triggered state to a clean state, thereby preventing attackers from activating backdoors hidden in the agent by presenting the trigger. When training the surrogate to predict states, we incorporate agent action information to reduce the discrepancy between the actions taken by the agent on predicted states and the actions taken on real sta
    
[^71]: 关于大型语言模型的创造性研究

    On the Creativity of Large Language Models. (arXiv:2304.00008v1 [cs.AI])

    [http://arxiv.org/abs/2304.00008](http://arxiv.org/abs/2304.00008)

    这篇论文探讨了大型语言模型的创造性问题，分析了与之相关的机器创造性的难点和易点，并重点分析了这些技术在创意产业中的社会影响。

    

    大型语言模型(LLMs)正在颠覆人工智能的多个领域。其中最显著的应用之一是创作，例如诗歌或故事：生成的输出通常具有惊人的质量。但是，一个自然的问题是：LLMs真的可以被认为是创造性的吗？在本文中，我们首先通过创造性理论的角度分析了LLMs的发展，探讨了关键的未解决问题和挑战。然后，我们在与LLMs相关的机器创造性方面确定了一组“易”和“难”问题，并对其进行了讨论。最后，我们分析了这些技术在创意产业中的社会影响。

    Large Language Models (LLMs) are revolutionizing several areas of Artificial Intelligence. One of the most remarkable applications is creative writing, e.g., poetry or storytelling: the generated outputs are often of astonishing quality. However, a natural question arise: can LLMs really be considered creative? In this article we firstly analyze the development of LLMs under the lens of creativity theories, investigating the key open questions and challenges. Then, we identify a set of "easy" and "hard" problems in machine creativity, discussing them in relation to LLMs. Finally, we analyze the societal impact of these technologies with a particular focus on the creative industries.
    
[^72]: 大型语言模型综述

    A Survey of Large Language Models. (arXiv:2303.18223v1 [cs.CL])

    [http://arxiv.org/abs/2303.18223](http://arxiv.org/abs/2303.18223)

    本文综述了大型语言模型的研究历程以及最近的预训练语言模型(PLMs)，并强调模型扩展将带来性能改进和特殊能力的发掘。

    

    语言本质上是一个由语法规则控制的复杂精细的人类表达系统，对于开发理解和掌握语言的能力的AI算法来说是一项重大挑战。作为主要方法之一，语言建模在过去二十年里广泛研究用于语言理解和生成，从统计语言模型演化为神经语言模型。最近，通过在大规模语料库上预训练Transformer模型，提出了预训练语言模型（PLMs），在解决各种NLP任务方面显示出强大的能力。由于研究人员发现模型缩放可以导致性能改进，他们进一步通过增加模型规模来研究缩放效应，有趣的是，当参数规模超过一定水平时，这些扩大的语言模型不仅可以实现显着的性能提升，而且还显示出一些小规模语言模型所没有的特殊能力。

    Language is essentially a complex, intricate system of human expressions governed by grammatical rules. It poses a significant challenge to develop capable AI algorithms for comprehending and grasping a language. As a major approach, language modeling has been widely studied for language understanding and generation in the past two decades, evolving from statistical language models to neural language models. Recently, pre-trained language models (PLMs) have been proposed by pre-training Transformer models over large-scale corpora, showing strong capabilities in solving various NLP tasks. Since researchers have found that model scaling can lead to performance improvement, they further study the scaling effect by increasing the model size to an even larger size. Interestingly, when the parameter scale exceeds a certain level, these enlarged language models not only achieve a significant performance improvement but also show some special abilities that are not present in small-scale langu
    
[^73]: 使用语言反馈规模化训练语言模型

    Training Language Models with Language Feedback at Scale. (arXiv:2303.16755v1 [cs.CL])

    [http://arxiv.org/abs/2303.16755](http://arxiv.org/abs/2303.16755)

    本文提出一种新方法，即利用更丰富的语言反馈进行模仿学习，通过三个迭代步骤对语言模型进行训练以生成更符合人类偏好的输出。

    

    预训练的语言模型经常生成不符合人类偏好的输出，例如有害的文本或事实不正确的摘要。最近的研究尝试通过学习一种简单的人类反馈形式（即模型生成输出之间的比较）来解决这些问题。但是，比较反馈只能传达有限的关于人类偏好的信息。在本文中，我们介绍了一种新的方法——使用语言反馈进行模仿学习（ILF），它利用了更丰富的语言反馈。ILF由三个迭代步骤组成：第一步，根据输入，初始LM输出和反馈对语言模型进行调节以生成改进。第二步，选择最多反馈的改进。第三步，微调语言模型，以最大化在给定输入的情况下选择的改进的可能性。我们在理论上证明了ILF可以被看作是贝叶斯推断，类似于从人类反馈中进行强化学习。我们还评估了ILF在各种基准测试中的性能。

    Pretrained language models often generate outputs that are not in line with human preferences, such as harmful text or factually incorrect summaries. Recent work approaches the above issues by learning from a simple form of human feedback: comparisons between pairs of model-generated outputs. However, comparison feedback only conveys limited information about human preferences. In this paper, we introduce Imitation learning from Language Feedback (ILF), a new approach that utilizes more informative language feedback. ILF consists of three steps that are applied iteratively: first, conditioning the language model on the input, an initial LM output, and feedback to generate refinements. Second, selecting the refinement incorporating the most feedback. Third, finetuning the language model to maximize the likelihood of the chosen refinement given the input. We show theoretically that ILF can be viewed as Bayesian Inference, similar to Reinforcement Learning from human feedback. We evaluate
    
[^74]: TabRet: 预训练Transformer-based表格模型，支持未知列

    TabRet: Pre-training Transformer-based Tabular Models for Unseen Columns. (arXiv:2303.15747v1 [cs.LG])

    [http://arxiv.org/abs/2303.15747](http://arxiv.org/abs/2303.15747)

    提出了一种可预训练的Transformer-based表格模型：TabRet，能够支持未知列，并在医疗保健分类任务上表现优秀。重新标记化和随机洗牌增强对性能提升有贡献。

    

    我们提出了一种名为TabRet的可预训练Transformer-based表格模型。TabRet旨在为包含未在预训练中见过的列的下游任务提供支持。与其他方法不同，TabRet在微调之前有一个额外的学习步骤，称为重新标记化，它基于遮蔽自动编码损失来校准特征嵌入。在实验中，我们使用大量的公共健康调查数据对TabRet进行预训练，并在医疗保健分类任务上进行微调，在四个数据集上实现了最佳AUC性能。此外，消融研究表明，在预训练期间进行重新标记化和随机洗牌增强对性能提升有贡献。

    We present \emph{TabRet}, a pre-trainable Transformer-based model for tabular data. TabRet is designed to work on a downstream task that contains columns not seen in pre-training. Unlike other methods, TabRet has an extra learning step before fine-tuning called \emph{retokenizing}, which calibrates feature embeddings based on the masked autoencoding loss. In experiments, we pre-trained TabRet with a large collection of public health surveys and fine-tuned it on classification tasks in healthcare, and TabRet achieved the best AUC performance on four datasets. In addition, an ablation study shows retokenizing and random shuffle augmentation of columns during pre-training contributed to performance gains.
    
[^75]: 从单个医院到多个中心应用：增强ICU中深度学习模型的泛化能力

    From Single-Hospital to Multi-Centre Applications: Enhancing the Generalisability of Deep Learning Models for Adverse Event Prediction in the ICU. (arXiv:2303.15354v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.15354](http://arxiv.org/abs/2303.15354)

    本研究通过使用多个数据源和在训练中明确优化泛化性能，提高了深度学习模型在新医院中预测ICU患者不良事件的性能和可靠性。

    

    深度学习模型可以帮助医生及早检测患者恶化状态，为他们提供反应时间并防止不良结果。虽然基于深度学习的早期预警模型通常在它们受过训练的医院中表现良好，但在新医院应用时它们往往不太可靠。这使得在规模上部署它们变得困难。我们使用来自欧洲和美国四个数据源的精心协调的重症监护数据（总计334,812个停留时间），系统评估深度学习模型对三种常见不良事件的可靠性：死亡、急性肾损伤（AKI）和脓毒症。我们测试了使用多个数据源和/或在训练过程中明确优化泛化能力是否提高了模型在新医院的性能。我们发现，模型在训练医院对于死亡率（0.838-0.869）、AKI（0.823-0.866）和脓毒症（0.749-0.824）实现了较高的AUROC。预期地，性能在新医院下降，有时下降了-0.200。在训练过程中使用超过一个数据源并明确优化泛化性能可以提高模型在新医院的性能。我们的发现表明，这种方法可以帮助部署健壮且普适的深度学习模型，以预测ICU中的不良事件。

    Deep learning (DL) can aid doctors in detecting worsening patient states early, affording them time to react and prevent bad outcomes. While DL-based early warning models usually work well in the hospitals they were trained for, they tend to be less reliable when applied at new hospitals. This makes it difficult to deploy them at scale. Using carefully harmonised intensive care data from four data sources across Europe and the US (totalling 334,812 stays), we systematically assessed the reliability of DL models for three common adverse events: death, acute kidney injury (AKI), and sepsis. We tested whether using more than one data source and/or explicitly optimising for generalisability during training improves model performance at new hospitals. We found that models achieved high AUROC for mortality (0.838-0.869), AKI (0.823-0.866), and sepsis (0.749-0.824) at the training hospital. As expected, performance dropped at new hospitals, sometimes by as much as -0.200. Using more than one 
    
[^76]: 你有在使用我的数据集进行训练吗？使用清洁标签背门数字水印实现公共数据集保护

    Did You Train on My Dataset? Towards Public Dataset Protection with Clean-Label Backdoor Watermarking. (arXiv:2303.11470v1 [cs.CR])

    [http://arxiv.org/abs/2303.11470](http://arxiv.org/abs/2303.11470)

    提出了一种基于背门数字水印的方法，以确保公共数据的安全。通过在数据集中插入极少量的数字水印样本，隐式学习一个隐藏的函数作为数字水印，以跟踪非法使用此数据集的模型。使用“清洁标签背门”方法实现了数字水印，不会破坏原始数据集。实验证明，该方法有效地检测到非法利用数据集的行为。

    

    互联网上源源不断的支持训练数据是深度学习模型成功的关键因素。然而，这种大量的公共数据也引起了对数据集被未经授权的用于商业目的的担忧，这是数据集许可证所禁止的。本文提出了一种基于背门数字水印的方法，作为保护公共数据的通用框架。通过向数据集中插入少量的数字水印样本，我们的方法使学习模型能够隐式学习由防御者设置的秘密函数。这个隐藏的函数可以作为数字水印，用于跟踪非法使用数据集的第三方模型。不幸的是，现有的背门插入方法往往涉及向训练集中添加任意的、错误标记的数据，导致性能显著下降，并容易被异常检测算法检测到。为了克服这个挑战，我们引入了一种清洁标记背门方法，实现了数字水印而不破坏原始数据集。我们的方法在几个图像分类任务上进行了评估，证明了它在检测非法数据集使用方面的有效性。

    The huge supporting training data on the Internet has been a key factor in the success of deep learning models. However, this abundance of public-available data also raises concerns about the unauthorized exploitation of datasets for commercial purposes, which is forbidden by dataset licenses. In this paper, we propose a backdoor-based watermarking approach that serves as a general framework for safeguarding public-available data. By inserting a small number of watermarking samples into the dataset, our approach enables the learning model to implicitly learn a secret function set by defenders. This hidden function can then be used as a watermark to track down third-party models that use the dataset illegally. Unfortunately, existing backdoor insertion methods often entail adding arbitrary and mislabeled data to the training set, leading to a significant drop in performance and easy detection by anomaly detection algorithms. To overcome this challenge, we introduce a clean-label backdoo
    
[^77]: 计算水平分析通用智能的约束遵从性

    Computational-level Analysis of Constraint Compliance for General Intelligence. (arXiv:2303.04352v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2303.04352](http://arxiv.org/abs/2303.04352)

    论文研究了人类行为受约束规范约束的影响，同时针对于构建遵守这些约束的通用代理提出了基于贝叶斯决策理论的计算水平模型。

    

    人类行为受到限制行为的规范和规律的制约。规则、礼仪、法律和道德义务等约束行为的形式都是对人类行为进行规范的类别。这些约束系统是“复杂的”：个体约束通常定义不明确，特定情况下哪些约束是相关的可能未知或存在歧义，约束之间相互作用和冲突，确定如何在相关约束的范围内行事可能是一个重大挑战，尤其是在需要快速决策的情况下。尽管存在这样的混乱，人类仍然能够稳健、快速地将约束融入其决策中。通用的人工智能代理也必须能够在现实约束系统的混乱中进行导航，以便行为具有可预测性和可靠性。在本文中，我们对通用代理约束处理的复杂性来源进行了表征，并基于贝叶斯决策理论的思想描述了一种针对这种约束计算水平分析的方法。我们列举了几个建设通用的、遵守约束的代理的障碍，并描述了代理如何可以以最优方式考虑约束的贝叶斯计算水平模型。最后，我们讨论了我们的模型对通用智能研究的影响。

    Human behavior is conditioned by codes and norms that constrain action. Rules, ``manners,'' laws, and moral imperatives are examples of classes of constraints that govern human behavior. These systems of constraints are ``messy:'' individual constraints are often poorly defined, what constraints are relevant in a particular situation may be unknown or ambiguous, constraints interact and conflict with one another, and determining how to act within the bounds of the relevant constraints may be a significant challenge, especially when rapid decisions are needed. Despite such messiness, humans incorporate constraints in their decisions robustly and rapidly. General, artificially-intelligent agents must also be able to navigate the messiness of systems of real-world constraints in order to behave predictability and reliably. In this paper, we characterize sources of complexity in constraint processing for general agents and describe a computational-level analysis for such \textit{constraint
    
[^78]: 基于多模态多核图学习的自闭症预测与生物标志物发现

    Multi-modal Multi-kernel Graph Learning for Autism Prediction and Biomarker Discovery. (arXiv:2303.03388v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.03388](http://arxiv.org/abs/2303.03388)

    本文提出了一种名为MMKGL的新方法，能够解决多模态集成中各模态之间的负面影响，并从多个图中提取异质信息，以进行自闭症的预测和生物标志物的发现。

    

    基于图学习的多模态集成和分类是疾病预测中最具挑战性的障碍之一。我们提出了一种名为MMKGL的新方法来有效抵消多模态集成过程中各模态之间负面影响，并从图中提取异质信息。具体地，我们提出了多模态图嵌入模块，并通过自适应学习生成多个图，然后提出多核图学习模块，从多模态图中提取异质信息。在不同层次上聚合多模态图中的信息，实现了对自闭症的预测和生物标志物的发现。

    Due to its complexity, graph learning-based multi-modal integration and classification is one of the most challenging obstacles for disease prediction. To effectively offset the negative impact between modalities in the process of multi-modal integration and extract heterogeneous information from graphs, we propose a novel method called MMKGL (Multi-modal Multi-Kernel Graph Learning). For the problem of negative impact between modalities, we propose a multi-modal graph embedding module to construct a multi-modal graph. Different from conventional methods that manually construct static graphs for all modalities, each modality generates a separate graph by adaptive learning, where a function graph and a supervision graph are introduced for optimization during the multi-graph fusion embedding process. We then propose a multi-kernel graph learning module to extract heterogeneous information from the multi-modal graph. The information in the multi-modal graph at different levels is aggregat
    
[^79]: 通过特征空间收缩改善GAN的训练

    Improving GAN Training via Feature Space Shrinkage. (arXiv:2303.01559v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2303.01559](http://arxiv.org/abs/2303.01559)

    本文提出了一种针对GAN训练的改进方法，即在鉴别器的特征空间中收缩训练数据的区域，构建硬样本并缩小硬样本与易样本之间的特征距离。

    

    由于生成式对抗网络（GAN）在数据生成方面的优异能力，它在无监督学习中受到广泛关注。然而，训练GAN是困难的，因为鉴别器的训练分布是动态的，会导致不稳定的图像表示。在本文中，我们从新的角度来解决训练GAN的问题，即鲁棒图像分类。受到鲁棒图像表示研究的启发，我们为GAN提出了一个简单而有效的模块，即AdaptiveMix，它可以在鉴别器的图像表示空间中收缩训练数据的区域。考虑到直接限制特征空间是不可行的，我们提出构建硬样本，并缩小硬样本与易样本之间的特征距离。硬样本是通过混合一对训练图像来构建的。我们评估了我们的AdaptiveMix在广泛使用的和最先进的GAN架构中的有效性。

    Due to the outstanding capability for data generation, Generative Adversarial Networks (GANs) have attracted considerable attention in unsupervised learning. However, training GANs is difficult, since the training distribution is dynamic for the discriminator, leading to unstable image representation. In this paper, we address the problem of training GANs from a novel perspective, \emph{i.e.,} robust image classification. Motivated by studies on robust image representation, we propose a simple yet effective module, namely AdaptiveMix, for GANs, which shrinks the regions of training data in the image representation space of the discriminator. Considering it is intractable to directly bound feature space, we propose to construct hard samples and narrow down the feature distance between hard and easy samples. The hard samples are constructed by mixing a pair of training images. We evaluate the effectiveness of our AdaptiveMix with widely-used and state-of-the-art GAN architectures. The ev
    
[^80]: 学习机器在医疗及其他方面的应用

    Learning machines for health and beyond. (arXiv:2303.01513v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.01513](http://arxiv.org/abs/2303.01513)

    适用于建立预测模型的机器学习技术在医疗领域和其他领域具有广泛应用。模型的维护和监控很关键，因为模型的性能与数据的变化和传输有关。

    

    机器学习技术在构建预测模型方面具有良好效果，因为它们擅长识别大型数据集中的模式。然而，对于复杂的现实问题，模型的开发往往停留在发表论文、概念验证或通过某种部署模式的可访问性。然而，在医疗领域里，模型的患者人口会发生变化，因此模型的维护和监控是确保其长期安全有效使用的关键。由于机器学习技术是有效地训练以在可用数据集中寻找模式的，因此，对于复杂的现实问题，模型的性能不会在发表或部署时达到峰值后固定不变。相反，数据会随着时间的变化而产生变化，而当模型被运往新的地方供新的人群使用时，它们也会发生变化。

    Machine learning techniques are effective for building predictive models because they are good at identifying patterns in large datasets. Development of a model for complex real life problems often stops at the point of publication, proof of concept or when made accessible through some mode of deployment. However, a model in the medical domain risks becoming obsolete as soon as patient demographic changes. The maintenance and monitoring of predictive models post-publication is crucial to guarantee their safe and effective long term use. As machine learning techniques are effectively trained to look for patterns in available datasets, the performance of a model for complex real life problems will not peak and remain fixed at the point of publication or even point of deployment. Rather, data changes over time, and they also changed when models are transported to new places to be used by new demography.
    
[^81]: 双排列等变性在知识图谱补全中的应用

    Double Permutation Equivariance for Knowledge Graph Completion. (arXiv:2302.01313v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.01313](http://arxiv.org/abs/2302.01313)

    本研究提出了双排列等变性的KG表示方法，可以使神经网络在KG中执行复杂的逻辑推理任务，并在多个归纳KG完成任务中实现了最先进的Hits@10测试准确率。双排列等变性在KG中开辟了新的研究方向。

    

    本研究将知识图谱(KGs)形式化为一种新型的图，并称之为双交换属性图，其中节点和二元（两个节点之间的）表示必须对节点号和边（及节点）属性（关系和节点特征）的排列等变。双重排列等变的KG表示在KG中开辟了新的研究方向。我们展示了这种等变性对关系的结构表示产生的影响，从而使神经网络能够在KG中执行复杂的逻辑推理任务。最后，我们介绍了一种通用的等变表示蓝图，并测试了一种简单的基于GNN的双排列等变神经结构，在WN18RR、FB237和NELL995归纳KG完成任务中实现了最先进的Hits@10测试准确率，并能够准确执行现有方法无法执行的逻辑推理任务。

    This work provides a formalization of Knowledge Graphs (KGs) as a new class of graphs that we denote doubly exchangeable attributed graphs, where node and pairwise (joint 2-node) representations must be equivariant to permutations of both node ids and edge (& node) attributes (relations & node features). Double-permutation equivariant KG representations open a new research direction in KGs. We show that this equivariance imposes a structural representation of relations that allows neural networks to perform complex logical reasoning tasks in KGs. Finally, we introduce a general blueprint for such equivariant representations and test a simple GNN-based double-permutation equivariant neural architecture that achieve state-of-the-art Hits@10 test accuracy in the WN18RR, FB237 and NELL995 inductive KG completion tasks, and can accurately perform logical reasoning tasks that no existing methods can perform, to the best of our knowledge.
    
[^82]: 重新审视少样本动作识别中的空间和时间建模

    Revisiting the Spatial and Temporal Modeling for Few-shot Action Recognition. (arXiv:2301.07944v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2301.07944](http://arxiv.org/abs/2301.07944)

    SloshNet是一个重新审视少样本动作识别的新框架，它在空间和时间建模方面进行了精细化的探索，利用特征融合和长期时间建模模块来提高动作识别性能。

    

    空间和时间建模是少样本动作识别中最核心的方面之一。大多数以前的研究主要集中在基于高层次空间表示的长期时间关系建模上，而没有考虑至关重要的低级空间特征和短期时间关系。实际上，前者可以带来丰富的局部语义信息，而后者可以分别表示相邻帧的运动特征。在本文中，我们提出了SloshNet，一种重新审视少样本动作识别中空间和时间建模的新框架。首先，为了利用低级空间特征，我们设计了一个特征融合架构搜索模块，自动搜索低级和高级空间特征的最佳组合。接下来，受最近的Transformer的启发，我们引入了一个长期时间建模模块，基于提取的空间外观建模全局时间关系。

    Spatial and temporal modeling is one of the most core aspects of few-shot action recognition. Most previous works mainly focus on long-term temporal relation modeling based on high-level spatial representations, without considering the crucial low-level spatial features and short-term temporal relations. Actually, the former feature could bring rich local semantic information, and the latter feature could represent motion characteristics of adjacent frames, respectively. In this paper, we propose SloshNet, a new framework that revisits the spatial and temporal modeling for few-shot action recognition in a finer manner. First, to exploit the low-level spatial features, we design a feature fusion architecture search module to automatically search for the best combination of the low-level and high-level spatial features. Next, inspired by the recent transformer, we introduce a long-term temporal modeling module to model the global temporal relations based on the extracted spatial appearan
    
[^83]: 基于三分决策的临床医生主观方法用于精神障碍分类

    Classifying Mental-Disorders through Clinicians Subjective Approach based on Three-way Decision. (arXiv:2301.03351v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2301.03351](http://arxiv.org/abs/2301.03351)

    本文提出了一个基于三分决策框架下的统一模型，用于分析临床医生的主观方法，通过定量和定性分析得出排名列表和权重，并将疾病进行比较分类为三组，该方法可以作为补充工具与手动方法相结合，提高精确性。

    

    在精神诊断中，基于数据驱动的手动方法被用于精神障碍分类，但是它存在一些不可避免的缺陷。本文提出了一个三分决策框架下的统一模型，用于分析临床医生的主观方法，包含定量分析、定量分析以及基于评估的分析。基于临床医生最大程度的假设，定性和定量研究得出了排名列表和一组数值权重。我们进一步将疾病进行比较分类为三组，采用三分基于评估的模型，旨在理解和更清晰地描述这些结果。该方法可以作为补充工具与手动方法相结合，提高精确性。

    In psychiatric diagnosis, a contemporary data-driven, manual-based method for mental disorders classification is the most popular technique; however, it has several inevitable flaws. Using the three-way decision as a framework, we propose a unified model that stands for clinicians' subjective approach (CSA) analysis consisting of three parts: quantitative analysis, quantitative analysis, and evaluation-based analysis. A ranking list and a set of numerical weights based on illness magnitude levels according to the clinician's greatest degree of assumptions are the findings of the qualitative and quantitative investigation. We further create a comparative classification of illnesses into three groups with varying important levels; a three-way evaluation-based model is utilized in this study for the aim of understanding and portraying these results in a more clear way. This proposed method might be integrated with the manual-based process as a complementary tool to improve precision while
    
[^84]: MobileTL: 基于Inverted Residual Blocks的设备本地迁移学习

    MobileTL: On-device Transfer Learning with Inverted Residual Blocks. (arXiv:2212.03246v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.03246](http://arxiv.org/abs/2212.03246)

    本文提出了MobileTL，一种基于内部标准化层具有内存和计算效率的移动设备上的迁移学习方法，用于构建IRBs模型。MobileTL通过训练内部规范化层的移位来避免存储向后传递的激活图，显著降低了内存使用率，并在图像识别任务中保持了竞争性的准确性。

    

    设备本地迁移学习面临有限的设备资源的挑战。现有方法通过训练参数的子集或加入模型补丁来解决这个问题。为了更高效的推理，Inverted Residual Blocks（IRBs）将卷积层分为逐层深度和逐点卷积，从而实现更多卷积、标准化和激活层的堆叠。虽然它们对于推理是高效的，但IRBs需要在内存中存储额外的激活映射来训练卷积层的权重和标准化层的规模。因此，它们的高内存成本阻碍了在资源有限的边缘设备上训练IRBs，使其在迁移学习的情况下不适用。为了解决这个问题，我们提出了MobileTL，一种基于内部标准化层的移动设备上的内存和计算效率高的迁移学习方法，用于构建IRBs模型。MobileTL训练内部规范化层的移位，以避免存储向后传递的激活图。在图像识别任务中，MobileTL显著降低了内存使用率，并保持了竞争性的准确性。我们在ImageNet数据集上验证了我们的方法，并展示了一个小规模数据集上成功的迁移学习结果。

    Transfer learning on edge is challenging due to on-device limited resources. Existing work addresses this issue by training a subset of parameters or adding model patches. Developed with inference in mind, Inverted Residual Blocks (IRBs) split a convolutional layer into depthwise and pointwise convolutions, leading to more stacking layers, e.g., convolution, normalization, and activation layers. Though they are efficient for inference, IRBs require that additional activation maps are stored in memory for training weights for convolution layers and scales for normalization layers. As a result, their high memory cost prohibits training IRBs on resource-limited edge devices, and making them unsuitable in the context of transfer learning. To address this issue, we present MobileTL, a memory and computationally efficient on-device transfer learning method for models built with IRBs. MobileTL trains the shifts for internal normalization layers to avoid storing activation maps for the backwar
    
[^85]: 垂直联邦学习：一项结构化文献综述

    Vertical Federated Learning: A Structured Literature Review. (arXiv:2212.00622v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.00622](http://arxiv.org/abs/2212.00622)

    垂直联邦学习是联邦学习中的一种特殊架构，它可在不泄露隐私的情况下，通过组合本地模型训练的结果来建立完整的机器学习模型。本文是对垂直联邦学习现有研究进行了结构化综述，总结了其研究现状、应用、限制和未来方向。

    

    联邦学习（FL）已成为一种具有数据隐私优势的有前途的分布式学习范式。随着对数据所有者之间合作的兴趣增加，FL已引起组织的重视。FL的想法是使合作参与者在不泄露隐私的情况下，在分散的数据上训练机器学习（ML）模型。简单地说，联邦学习是“将模型带到数据，而不是将数据带到模型”的方法。当联邦学习应用于垂直分区的数据时，它能够通过组合使用各地点具有不同特征的本地模型训练的模型来建立完整的ML模型。这种FL的架构被称为垂直联邦学习（VFL），它不同于水平分区的传统FL。由于VFL与传统FL不同，因此它具有自身的问题和挑战。本文对现有研究中关于垂直联邦学习的结构化文献综述，分析了VFL的当前研究现状、应用、限制和未来方向。

    Federated Learning (FL) has emerged as a promising distributed learning paradigm with an added advantage of data privacy. With the growing interest in having collaboration among data owners, FL has gained significant attention of organizations. The idea of FL is to enable collaborating participants train machine learning (ML) models on decentralized data without breaching privacy. In simpler words, federated learning is the approach of ``bringing the model to the data, instead of bringing the data to the mode''. Federated learning, when applied to data which is partitioned vertically across participants, is able to build a complete ML model by combining local models trained only using the data with distinct features at the local sites. This architecture of FL is referred to as vertical federated learning (VFL), which differs from the conventional FL on horizontally partitioned data. As VFL is different from conventional FL, it comes with its own issues and challenges. In this paper, we
    
[^86]: 不断增长的知识图谱的终身嵌入学习与转移

    Lifelong Embedding Learning and Transfer for Growing Knowledge Graphs. (arXiv:2211.15845v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.15845](http://arxiv.org/abs/2211.15845)

    现有的知识图谱嵌入模型主要集中在静态KG上，无法随着KG不断增长而及时获取新知识，本文引入了终身KG嵌入模型，实现对不断增长的知识图谱的终身嵌入学习与转移，通过嵌入转移策略和正则化方法避免灾难性遗忘。

    

    现有的知识图谱（KG）嵌入模型主要集中在静态KG上。然而，现实世界中的KG并不保持静态，而是随着KG应用的发展而发展和增长。因此，新事实和以前未见的实体和关系不断出现，需要一种嵌入模型可以通过增长快速学习和转移新知识。本文探讨了KG嵌入的一个扩展领域，即终身KG嵌入。我们考虑在不必从头开始学习嵌入的情况下，保持对KG增长快照的知识转移和保留学习。所提出的模型包括用于嵌入学习和更新的掩码KG自编码器，具有嵌入转移策略，将学习的知识注入新实体和关系嵌入，以及嵌入正则化方法，以避免灾难性遗忘。为了研究KG增长的不同方面的影响，我们构建了四个...

    Existing knowledge graph (KG) embedding models have primarily focused on static KGs. However, real-world KGs do not remain static, but rather evolve and grow in tandem with the development of KG applications. Consequently, new facts and previously unseen entities and relations continually emerge, necessitating an embedding model that can quickly learn and transfer new knowledge through growth. Motivated by this, we delve into an expanding field of KG embedding in this paper, i.e., lifelong KG embedding. We consider knowledge transfer and retention of the learning on growing snapshots of a KG without having to learn embeddings from scratch. The proposed model includes a masked KG autoencoder for embedding learning and update, with an embedding transfer strategy to inject the learned knowledge into the new entity and relation embeddings, and an embedding regularization method to avoid catastrophic forgetting. To investigate the impacts of different aspects of KG growth, we construct four
    
[^87]: 带权重集成的自监督学习

    Weighted Ensemble Self-Supervised Learning. (arXiv:2211.09981v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.09981](http://arxiv.org/abs/2211.09981)

    本文提出了一种带权重集成的自监督学习方法，通过开发允许数据相关的加权交叉熵损失的框架，可以提高最近自监督学习技术的性能，而不需要改变原有的架构，其在 ImageNet-1K 数据集上的表现优于最先进的 DINO 和 MSN 方法，特别是在小样本设置中表现最佳。

    

    集成在监督学习中已被证明是提高模型性能、不确定性估计和健壮性的有效技术。自监督学习的进展使得利用大规模未标记语料库进行最先进的小样本和监督学习成为可能。本文研究了如何通过开发一个允许数据相关的加权交叉熵损失的框架来改进最近的自监督学习技术。我们避免对表示骨干进行集成；这个选择产生了一种高效的集成方法，它的训练成本很小，对下游评估不需要进行架构改变或计算开销。我们的方法在 ImageNet-1K 数据集上使用了两种最先进的自监督学习方法 DINO (Caron 等人，2021) 和 MSN (Assran 等人，2022)，在多个评估指标上均优于它们，尤其在小样本设置中表现最佳。我们探讨了几种加权方案，并发现…（未完成）

    Ensembling has proven to be a powerful technique for boosting model performance, uncertainty estimation, and robustness in supervised learning. Advances in self-supervised learning (SSL) enable leveraging large unlabeled corpora for state-of-the-art few-shot and supervised learning performance. In this paper, we explore how ensemble methods can improve recent SSL techniques by developing a framework that permits data-dependent weighted cross-entropy losses. We refrain from ensembling the representation backbone; this choice yields an efficient ensemble method that incurs a small training cost and requires no architectural changes or computational overhead to downstream evaluation. The effectiveness of our method is demonstrated with two state-of-the-art SSL methods, DINO (Caron et al., 2021) and MSN (Assran et al., 2022). Our method outperforms both in multiple evaluation metrics on ImageNet-1K, particularly in the few-shot setting. We explore several weighting schemes and find that th
    
[^88]: 基于交叉通道池化的量子分裂神经网络学习

    Quantum Split Neural Network Learning using Cross-Channel Pooling. (arXiv:2211.06524v2 [quant-ph] UPDATED)

    [http://arxiv.org/abs/2211.06524](http://arxiv.org/abs/2211.06524)

    本研究提出了一种基于QSL的新方法，并引入交叉通道池化技术，实现了加速收敛、减少通讯成本和增强隐私保护的优点。

    

    近年来，量子科学领域在量子机器学习、量子通信和量子计算等多个学科领域引起了广泛关注。在这些新兴领域中，由于将量子神经网络(QNNs)与传统联邦学习技术(FL)相结合，量子联邦学习(QFL)引起了特别关注。本研究提出了一种称为量子分裂学习(QSL)的新方法，它是经典分裂学习的先进延伸。在传统计算机领域中，分裂学习已经证明了许多优点，例如加速收敛，减少通讯成本和增强隐私保护。为了最大化QSL的潜力，引入了交叉通道池化技术，这种技术利用了QNNs所实现的量子态重构的独特性质。通过严格的数值分析，证明了QSL不仅实现了优异的学习性能，而且在在保护隐私方面也更为高效。

    In recent years, the field of quantum science has attracted significant interest across various disciplines, including quantum machine learning, quantum communication, and quantum computing. Among these emerging areas, quantum federated learning (QFL) has gained particular attention due to the integration of quantum neural networks (QNNs) with traditional federated learning (FL) techniques. In this study, a novel approach entitled quantum split learning (QSL) is presented, which represents an advanced extension of classical split learning. Previous research in classical computing has demonstrated numerous advantages of split learning, such as accelerated convergence, reduced communication costs, and enhanced privacy protection. To maximize the potential of QSL, cross-channel pooling is introduced, a technique that capitalizes on the distinctive properties of quantum state tomography facilitated by QNNs. Through rigorous numerical analysis, evidence is provided that QSL not only achieve
    
[^89]: 一种基于Transformer的替代品推荐模型，融合了弱监督的顾客行为数据

    A Transformer-Based Substitute Recommendation Model Incorporating Weakly Supervised Customer Behavior Data. (arXiv:2211.02533v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2211.02533](http://arxiv.org/abs/2211.02533)

    本文将替代品推荐适应到语言匹配问题中，并通过设计新的转换方法去除信号噪音，并考虑了多语言支持。该模型已成功在一个大型电子商务网站上的11个市场和6种语言中部署，提高了顾客忠诚度和购买率。

    

    基于替代品的推荐在电子商务中得到广泛应用，以提供更好的替代品给顾客。但是现有研究通常使用顾客的行为信号（如共同浏览和浏览但购买另一个产品）来捕捉替代关系。尽管这个方法听起来很直观，但我们发现这种做法可能会忽略产品的功能和特性。在本文中，我们通过以产品标题描述作为模型输入，并考虑产品功能，将替代品推荐适应到语言匹配问题中。我们设计了一种新的转换方法来去除从生产数据中得出的信号噪声。此外，我们从工程角度考虑多语言支持。我们提出的端到端基于Transformer的模型在离线和在线实验中均取得了成功。所提出的模型已部署在一个大型电子商务网站上的11个市场和6种语言中。我们的模型被证明可以提高顾客忠诚度和购买率。

    The substitute-based recommendation is widely used in E-commerce to provide better alternatives to customers. However, existing research typically uses the customer behavior signals like co-view and view-but-purchase-another to capture the substitute relationship. Despite its intuitive soundness, we find that such an approach might ignore the functionality and characteristics of products. In this paper, we adapt substitute recommendation into language matching problem by taking product title description as model input to consider product functionality. We design a new transformation method to de-noise the signals derived from production data. In addition, we consider multilingual support from the engineering point of view. Our proposed end-to-end transformer-based model achieves both successes from offline and online experiments. The proposed model has been deployed in a large-scale E-commerce website for 11 marketplaces in 6 languages. Our proposed model is demonstrated to increase re
    
[^90]: 破碎的神经缩放定律

    Broken Neural Scaling Laws. (arXiv:2210.14891v7 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.14891](http://arxiv.org/abs/2210.14891)

    本文提出了一个平滑破碎的幂律函数形式，可以准确地模拟和外推深度神经网络的缩放行为，适用于各种架构和大量不同任务，包括视觉、语言、音频、视频、生成建模、对比学习、机器人、不确定性估计/校准、对抗鲁棒性、分子、计算机编程/编码、数学单词问题、算术、无监督/自监督学习和强化学习。

    This paper proposes a smoothly broken power law functional form (referred to as a Broken Neural Scaling Law (BNSL)) that accurately models and extrapolates the scaling behaviors of deep neural networks for various architectures and a large and diverse set of tasks, including vision, language, audio, video, generative modeling, contrastive learning, robotics, uncertainty estimation/calibration, adversarial robustness, molecules, computer programming/coding, math word problems, arithmetic, unsupervised/self-supervised learning, and reinforcement learning.

    我们提出了一个平滑破碎的幂律函数形式（我们称之为破碎的神经缩放定律（BNSL）），它准确地模拟和外推了深度神经网络的缩放行为（即感兴趣的评估指标随用于训练的计算量、模型参数数量、训练数据集大小或上游性能变化而变化）对于各种架构和大量不同任务中的每个任务，包括大规模视觉、语言、音频、视频、扩散、生成建模、多模态学习、对比学习、AI对齐、机器人、超出分布（OOD）泛化、持续学习、不确定性估计/校准、超出分布检测、对抗鲁棒性、蒸馏、分子、计算机编程/编码、数学单词问题、算术、无监督/自监督学习和强化学习。

    We present a smoothly broken power law functional form (referred to by us as a Broken Neural Scaling Law (BNSL)) that accurately models and extrapolates the scaling behaviors of deep neural networks (i.e. how the evaluation metric of interest varies as the amount of compute used for training, number of model parameters, training dataset size, or upstream performance varies) for various architectures and for each of various tasks within a large and diverse set of upstream and downstream tasks, in zero-shot, prompted, and fine-tuned settings. This set includes large-scale vision, language, audio, video, diffusion, generative modeling, multimodal learning, contrastive learning, AI alignment, robotics, out-of-distribution (OOD) generalization, continual learning, uncertainty estimation / calibration, out-of-distribution detection, adversarial robustness, distillation, molecules, computer programming/coding, math word problems, arithmetic, unsupervised/self-supervised learning, and reinforc
    
[^91]: 基于特征符合预测的预测推断

    Predictive Inference with Feature Conformal Prediction. (arXiv:2210.00173v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.00173](http://arxiv.org/abs/2210.00173)

    本文提出基于特征符合预测的预测推断方法，通过利用深度表示学习的归纳偏置，扩展了符合预测到语义特征空间。从理论和实验结果来看，该方法优于常规符合预测，并在大规模任务上展现了最先进性能。

    

    符合预测是一种无分布技术，用于建立有效的预测间隔。虽然传统上人们在输出空间中进行符合预测，但这并不是唯一的可能性。在本文中，我们提出了基于特征的符合预测，通过利用深度表示学习的归纳偏置，扩展了符合预测对语义特征空间的范围。从理论上讲，我们证明了基于特征的符合预测在温和假设下可以证明优于常规符合预测。我们的方法不仅可以与普通符合预测结合使用，而且可以与其他自适应符合预测方法结合使用。除了现有预测推断基准测试的实验外，我们还展示了该方法在大规模任务（如ImageNet分类和Cityscapes图像分割）上的最先进性能。

    Conformal prediction is a distribution-free technique for establishing valid prediction intervals. Although conventionally people conduct conformal prediction in the output space, this is not the only possibility. In this paper, we propose feature conformal prediction, which extends the scope of conformal prediction to semantic feature spaces by leveraging the inductive bias of deep representation learning. From a theoretical perspective, we demonstrate that feature conformal prediction provably outperforms regular conformal prediction under mild assumptions. Our approach could be combined with not only vanilla conformal prediction, but also other adaptive conformal prediction methods. Apart from experiments on existing predictive inference benchmarks, we also demonstrate the state-of-the-art performance of the proposed methods on large-scale tasks such as ImageNet classification and Cityscapes image segmentation.
    
[^92]: 通过流形熵估计解决GAN中的模式崩溃问题

    Combating Mode Collapse in GANs via Manifold Entropy Estimation. (arXiv:2208.12055v6 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2208.12055](http://arxiv.org/abs/2208.12055)

    本文提出了一种新的GAN训练流程，通过将判别器作为特征嵌入进行泛化并设计两个正则化项，从而最大化学习到的分布熵以解决GAN中的模式崩溃问题。

    

    近年来，生成对抗网络（GAN）在各种任务和应用中展示了令人信服的结果。然而，在GAN中，模式崩溃仍然是一个关键问题。本文提出了一种新的训练流程来解决GAN的模式崩溃问题。与现有方法不同，我们将判别器作为特征嵌入进行泛化，最大化判别器在嵌入空间中学习到的分布熵。具体而言，设计了两个正则化项，即深度局部线性嵌入（DLLE）和深度等距特征映射（DIsoMap），以鼓励判别器学习嵌入在数据中的结构信息，使得判别器学习到的嵌入空间可以被很好地形成。基于由判别器支持的学习良好的嵌入空间，设计了一个非参数熵估计器，以高效地最大化嵌入向量的熵，作为最大化数据分布熵的近似。

    Generative Adversarial Networks (GANs) have shown compelling results in various tasks and applications in recent years. However, mode collapse remains a critical problem in GANs. In this paper, we propose a novel training pipeline to address the mode collapse issue of GANs. Different from existing methods, we propose to generalize the discriminator as feature embedding and maximize the entropy of distributions in the embedding space learned by the discriminator. Specifically, two regularization terms, i.e., Deep Local Linear Embedding (DLLE) and Deep Isometric feature Mapping (DIsoMap), are designed to encourage the discriminator to learn the structural information embedded in the data, such that the embedding space learned by the discriminator can be well-formed. Based on the well-learned embedding space supported by the discriminator, a non-parametric entropy estimator is designed to efficiently maximize the entropy of embedding vectors, playing as an approximation of maximizing the 
    
[^93]: 神经地面计划：基于单张图片的持久神经场景表示

    Neural Groundplans: Persistent Neural Scene Representations from a Single Image. (arXiv:2207.11232v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2207.11232](http://arxiv.org/abs/2207.11232)

    本文提出了一种基于单张图像的持久神经场景表示方法，使用条件神经地面计划来表示场景，能够进行视角合成、场景解耦表示和可移动组件的分离，重构可移动物体能够进行多种下游任务。

    

    本文提出一种方法，将场景的2D图像观测映射到持久的3D场景表示中，实现了新颖的视角合成和场景可移动和不可移动组件的解耦表示。受视觉和机器人常用的鸟瞰图（BEV）表示的启发，我们提出了条件神经地面计划，即地面对齐的2D特征网格，作为持久且占用内存少的场景表示。我们的方法采用无标签的多视角观测的自我监督训练，使用可微分渲染学习完成遮挡区域的几何和外观。此外，我们展示可以利用多视角视频在训练时来学习分别从单张图像中重构场景的静态和可移动组件。分别重构可移动物体的能力，使用简单的启发式方法，使其可以进行诸多下游任务，如提取以物体为中心的3D表示、新颖的视角合成和物体操作等。

    We present a method to map 2D image observations of a scene to a persistent 3D scene representation, enabling novel view synthesis and disentangled representation of the movable and immovable components of the scene. Motivated by the bird's-eye-view (BEV) representation commonly used in vision and robotics, we propose conditional neural groundplans, ground-aligned 2D feature grids, as persistent and memory-efficient scene representations. Our method is trained self-supervised from unlabeled multi-view observations using differentiable rendering, and learns to complete geometry and appearance of occluded regions. In addition, we show that we can leverage multi-view videos at training time to learn to separately reconstruct static and movable components of the scene from a single image at test time. The ability to separately reconstruct movable objects enables a variety of downstream tasks using simple heuristics, such as extraction of object-centric 3D representations, novel view synthe
    
[^94]: ShapeCrafter：一种递归文本条件下的三维形状生成模型

    ShapeCrafter: A Recursive Text-Conditioned 3D Shape Generation Model. (arXiv:2207.09446v4 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2207.09446](http://arxiv.org/abs/2207.09446)

    本文提出了一个用于递归文本条件下三维形状生成的神经网络，通过一种逐步添加短语的方法，可以生成与文本描述一致的形状。

    

    本文提出了ShapeCrafter，这是一个用于递归文本条件下的三维形状生成的神经网络。现有的生成文本条件下的三维形状的方法会利用整个文本提示来一次性生成一个三维形状。然而，人类倾向于递归地描述形状——我们可能会从一个初始描述开始，并根据中间结果逐渐添加细节。为了捕捉这个递归过程，我们介绍了一种方法来生成一个三维形状分布，该分布以初始短语为条件，并随着添加更多的短语而逐渐演变。由于现有数据集不足以训练这种方法，我们提供了Text2Shape++，这是一个包含369K个形状-文本对的大型数据集，支持递归形状生成。为了捕捉经常用于精细形状描述的局部细节，我们利用基于向量量化的深度隐式函数，生成高质量形状的分布。结果表明，我们的方法可以生成与文本描述一致的形状。

    We present ShapeCrafter, a neural network for recursive text-conditioned 3D shape generation. Existing methods to generate text-conditioned 3D shapes consume an entire text prompt to generate a 3D shape in a single step. However, humans tend to describe shapes recursively-we may start with an initial description and progressively add details based on intermediate results. To capture this recursive process, we introduce a method to generate a 3D shape distribution, conditioned on an initial phrase, that gradually evolves as more phrases are added. Since existing datasets are insufficient for training this approach, we present Text2Shape++, a large dataset of 369K shape-text pairs that supports recursive shape generation. To capture local details that are often used to refine shape descriptions, we build on top of vector-quantized deep implicit functions that generate a distribution of high-quality shapes. Results show that our method can generate shapes consistent with text descriptions
    
[^95]: 大型语言模型仍无法规划（LLM在规划和变化推理中的基准）。（arXiv:2206.10498v3 [cs.CL] UPDATED）

    Large Language Models Still Can't Plan (A Benchmark for LLMs on Planning and Reasoning about Change). (arXiv:2206.10498v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2206.10498](http://arxiv.org/abs/2206.10498)

    本研究提出了一个用于测评LLMs规划和变化推理能力的框架，并测试了流行的LLMs (GPT-3 和 GShard) 在此基准上的表现。研究发现这些模型在最简单的规划任务上都表现不佳，强调了目前LLMs推理能力的严重限制，建议需要大量工作来开发更先进的LLM基础系统来满足实际应用需求。

    

    大型语言模型（LLMs）的最新进展已经改变了自然语言处理（NLP）领域。从GPT-3到PaLM，自然语言任务的最新性能正在随着每个新的大型语言模型的推出不断提高。除了自然语言能力外，人们对于理解此类模型是否具有推理能力产生了极大的兴趣，并采用了推理基准来进行测评。然而，尽管结果看似积极，这些基准在本质上是简单的，LLMs在这些基准上的表现并不能作为支持LLMs推理能力（有时是荒谬的）声称的证据。此外，这些只代表了一个非常有限的简单推理任务集，如果我们要衡量此类基于LLM的系统的真正限制，我们需要研究更复杂的推理问题。受此启发，我们提出了一个可扩展的评估框架，用于测试LLMs规划和变化推理的能力。我们的框架包括一系列的规划和推理任务，例如命题逻辑、因果推断和常识推理，这些任务的难度随着任务的进展而逐渐增加。我们测量了两个流行的LLMs（GPT-3和GShard）在这个基准上的表现，并发现这些模型甚至无法处理最简单的规划任务。我们的发现强调了当前LLMs推理能力的严重局限性，并建议需要大量工作来开发可以规划和推理变化的LLM基础系统，以满足实际应用的需求。

    Recent advances in large language models (LLMs) have transformed the field of natural language processing (NLP). From GPT-3 to PaLM, the state-of-the-art performance on natural language tasks is being pushed forward with every new large language model. Along with natural language abilities, there has been a significant interest in understanding whether such models exhibit reasoning capabilities with the use of reasoning benchmarks. However, even though results are seemingly positive, these benchmarks prove to be simplistic in nature and the performance of LLMs on these benchmarks cannot be used as evidence to support, many a times outlandish, claims being made about LLMs' reasoning capabilities. Further, these only represent a very limited set of simple reasoning tasks and we need to look at more sophisticated reasoning problems if we are to measure the true limits of such LLM-based systems. Motivated by this, we propose an extensible assessment framework to test the capabilities of LL
    
[^96]: 背景数据规模对深度学习模型 SHAP 解释稳定性的影响的实证研究

    An empirical study of the effect of background data size on the stability of SHapley Additive exPlanations (SHAP) for deep learning models. (arXiv:2204.11351v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2204.11351](http://arxiv.org/abs/2204.11351)

    本研究发现 SHapley Additive exPlanations (SHAP) 对于机器学习模型的解释受到背景数据集规模的影响，而选择合适的背景数据集能够确保 SHAP 解释的稳定性。

    

    如今，机器学习模型的推断结果准确性同样重要的是其可解释性。某些机器学习模型如决策树拥有天然的可解释性，而其他模型如人工神经网络则需要外部方法揭示其推断机制。SHapley Additive exPlanations (SHAP)就是一种外部解释方式，它需要一个背景数据集对人工神经网络进行解释。通常，背景数据集由从训练数据集中随机抽样的实例组成。然而，背景数据集的抽样规模及其对 SHAP 的影响仍未被探讨。在我们对 MIMIC-III 数据集进行的实证研究中，我们发现使用不同的随机抽样得到的背景数据集会导致核心解释—— SHAP 值和变量排序值的波动，这表明用户不能轻信 SHAP 提供的一次性解释结果。幸运的是，这样的波动并不意味着 SHAP 失败，而是表明选择合适的背景数据集对于确保 SHAP 解释的稳定性至关重要。

    Nowadays, the interpretation of why a machine learning (ML) model makes certain inferences is as crucial as the accuracy of such inferences. Some ML models like the decision tree possess inherent interpretability that can be directly comprehended by humans. Others like artificial neural networks (ANN), however, rely on external methods to uncover the deduction mechanism. SHapley Additive exPlanations (SHAP) is one of such external methods, which requires a background dataset when interpreting ANNs. Generally, a background dataset consists of instances randomly sampled from the training dataset. However, the sampling size and its effect on SHAP remain to be unexplored. In our empirical study on the MIMIC-III dataset, we show that the two core explanations - SHAP values and variable rankings fluctuate when using different background datasets acquired from random sampling, indicating that users cannot unquestioningly trust the one-shot interpretation from SHAP. Luckily, such fluctuation d
    
[^97]: FAIR4Cov：用于 COVID-19 检测的融合音频实例和表示

    FAIR4Cov: Fused Audio Instance and Representation for COVID-19 Detection. (arXiv:2204.10581v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2204.10581](http://arxiv.org/abs/2204.10581)

    FAIR4Cov是一种针对COVID-19检测的方法，它提出了一种融合身体声音的波形和谱图表示的关节特征向量，可以有效地检测COVID-19患者，胜过了其他方法。

    

    基于身体声音的分类技术长期以来一直被研究用于支持诊断决策，特别是在肺部疾病方面。针对 COVID-19 疫情的紧迫性，越来越多的模型被开发来基于声学输入识别 COVID-19 患者。大多数模型侧重于咳嗽，因为干咳是 COVID-19 最为人所知的症状。然而，呼吸和言语等其他身体声音也被发现与 COVID-19 相关。在这项工作中，我们提出了 FAIR4Cov，它不依赖于特定的身体声音，而是提出了一种融合身体声音的波形和谱图表示的关节特征向量。FAIR4Cov 的核心组件是一个自注意融合单元，它的训练目的是建立多个身体声音和音频表示的关系并将其集成到一个紧凑的特征向量中。我们在两个公共数据集上设置了实验，并在不同场景下评估了我们的提议方法，包括跨数据集评估和早期检测设置。实验结果表明，FAIR4Cov 胜过了现有方法，并展示了利用各种身体声音检测 COVID-19 患者的能力。

    Audio-based classification techniques on body sounds have long been studied to support diagnostic decisions, particularly in pulmonary diseases. In response to the urgency of the COVID-19 pandemic, a growing number of models are developed to identify COVID-19 patients based on acoustic input. Most models focus on cough because the dry cough is the best-known symptom of COVID-19. However, other body sounds, such as breath and speech, have also been revealed to correlate with COVID-19 as well. In this work, rather than relying on a specific body sound, we propose Fused Audio Instance and Representation for COVID-19 Detection (FAIR4Cov). It relies on constructing a joint feature vector obtained from a plurality of body sounds in waveform and spectrogram representation. The core component of FAIR4Cov is a self-attention fusion unit that is trained to establish the relation of multiple body sounds and audio representations and integrate it into a compact feature vector. We set up our experi
    
[^98]: 用于分析驾驶员分心行为和不同凝视区域的合成分心驾驶数据集（SynDD2）

    Synthetic Distracted Driving (SynDD2) dataset for analyzing distracted behaviors and various gaze zones of a driver. (arXiv:2204.08096v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2204.08096](http://arxiv.org/abs/2204.08096)

    本文介绍了SynDD2数据集，该数据集用于检测和分析驾驶员的分心行为和不同凝视区域，研究人员可以使用该数据集评估机器学习算法的性能。

    

    本文介绍了一种用于机器学习模型检测和分析驾驶员各种分心行为和不同凝视区域的合成分心驾驶（SynDD2）数据集（SynDD1的延续）。我们使用了三个车内摄像头在固定的车辆中收集数据，它们分别位于仪表盘、靠近后视镜和右侧上角的窗户位置。数据集包含两种活动类型：分心活动和凝视区域，每个参与者都有两个活动集：没有出现块和有出现块，例如戴帽子或太阳镜。每个参与者的每个活动顺序和持续时间都是随机的。此外，数据集包含每个活动的手动注释，标记其开始和结束时间。研究人员可以使用此数据集评估机器学习算法分类驾驶员各种分心活动和凝视区域的性能。

    This article presents a synthetic distracted driving (SynDD2 - a continuum of SynDD1) dataset for machine learning models to detect and analyze drivers' various distracted behavior and different gaze zones. We collected the data in a stationary vehicle using three in-vehicle cameras positioned at locations: on the dashboard, near the rearview mirror, and on the top right-side window corner. The dataset contains two activity types: distracted activities and gaze zones for each participant, and each activity type has two sets: without appearance blocks and with appearance blocks such as wearing a hat or sunglasses. The order and duration of each activity for each participant are random. In addition, the dataset contains manual annotations for each activity, having its start and end time annotated. Researchers could use this dataset to evaluate the performance of machine learning algorithms to classify various distracting activities and gaze zones of drivers.
    
[^99]: 结构感知的蛋白自监督学习

    Structure-aware Protein Self-supervised Learning. (arXiv:2204.04213v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2204.04213](http://arxiv.org/abs/2204.04213)

    我们提出了一种结构感知的蛋白自监督学习方法，利用预训练的图神经网络模型保留重要的蛋白质结构信息，并结合预训练语言模型来提高下游任务性能。在两个蛋白质分类测试中均表现出了优异的结果。

    

    蛋白质表示学习方法在许多下游任务，尤其是蛋白质分类任务中，展现出巨大的潜力。最近的一些研究还利用自监督学习方法解决了蛋白质标签数量不足的问题。然而，现有的蛋白质语言模型通常在蛋白质序列上进行预训练，而忽略了重要的蛋白质结构信息。因此，我们提出了一种新颖的结构感知的蛋白自监督学习方法，来有效地捕获蛋白质的结构信息。具体而言，我们设计了一个优秀的图神经网络（GNN）模型，通过对残基间距和二面角的自监督任务进行预训练，来保留蛋白质的结构信息。此外，我们还提出了利用已有的在蛋白质序列上预训练的语言模型，来增强自监督学习的方法。我们提出的框架 GP-SSL，通过联合训练基于GNN的结构模型和基于语言模型的序列模型，并通过fine-tuning将从GNN模型学到的有用的结构感知表示转移到下游任务中。我们在两个蛋白质分类基准测试上的实验表明，GP-SSL在下游任务性能和结构信息保留方面均优于现有方法和预训练语言模型BERT。我们的代码可在https://github.com/microsoft/GP-SSL上找到。

    Protein representation learning methods have shown great potential to yield useful representation for many downstream tasks, especially on protein classification. Moreover, a few recent studies have shown great promise in addressing insufficient labels of proteins with self-supervised learning methods. However, existing protein language models are usually pretrained on protein sequences without considering the important protein structural information. To this end, we propose a novel structure-aware protein self-supervised learning method to effectively capture structural information of proteins. In particular, a well-designed graph neural network (GNN) model is pretrained to preserve the protein structural information with self-supervised tasks from a pairwise residue distance perspective and a dihedral angle perspective, respectively. Furthermore, we propose to leverage the available protein language model pretrained on protein sequences to enhance the self-supervised learning. Specif
    
[^100]: 面向深度学习计算效率提升的随机锐度感知训练方法研究

    Randomized Sharpness-Aware Training for Boosting Computational Efficiency in Deep Learning. (arXiv:2203.09962v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2203.09962](http://arxiv.org/abs/2203.09962)

    本文提出了一种名为随机锐度感知训练（RST）的深度学习训练方法，通过在SGD和SAM之间随机选择来减少计算量，同时保证模型收敛。同时，我们对各种调度函数的效果和计算成本进行了实验研究。

    

    通过使模型收敛于平坦的极小值，SAM等锐度感知的学习算法已显示出实现最先进性能的能力。然而，这些算法通常会在每次训练迭代中多进行一次前向-反向传播，从而大大增加了计算量，特别是在可扩展模型中。为此，我们提出了一种名为随机锐度感知训练(RST)的简单而高效的训练方案。RST中的优化器每次迭代都会进行伯努利实验，以由预定义的调度函数安排的概率随机选择基本算法（SGD）和锐度感知算法（SAM）之一。由于基本算法的混合，传播对的总数可以大大减少。此外，我们还对RST的收敛性进行了理论分析。然后，我们通过实验研究了各种调度函数的计算成本和效果，并提供了设置适当调度函数的方向。

    By driving models to converge to flat minima, sharpness-aware learning algorithms (such as SAM) have shown the power to achieve state-of-the-art performances. However, these algorithms will generally incur one extra forward-backward propagation at each training iteration, which largely burdens the computation especially for scalable models. To this end, we propose a simple yet efficient training scheme, called Randomized Sharpness-Aware Training (RST). Optimizers in RST would perform a Bernoulli trial at each iteration to choose randomly from base algorithms (SGD) and sharpness-aware algorithms (SAM) with a probability arranged by a predefined scheduling function. Due to the mixture of base algorithms, the overall count of propagation pairs could be largely reduced. Also, we give theoretical analysis on the convergence of RST. Then, we empirically study the computation cost and effect of various types of scheduling functions, and give directions on setting appropriate scheduling functi
    

