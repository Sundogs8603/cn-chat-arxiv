# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Prompting the Hidden Talent of Web-Scale Speech Models for Zero-Shot Task Generalization.](http://arxiv.org/abs/2305.11095) | 本文通过提示工程技术调整Whisper模型，成功适应未见过的三个任务，并提出的提示比默认提示性能提升了10%到45％，展现了Whisper模型的鲁棒性和多语言理解能力。 |
| [^2] | [Lightweight Online Learning for Sets of Related Problems in Automated Reasoning.](http://arxiv.org/abs/2305.11087) | 本文提出了一种自动推理中解决一组相关问题的轻量级在线学习方法，它能够自动收集信息并拟合机器学习模型来调整解决策略。在实验中证明该方法能证明更大的边界和发现更多反例。 |
| [^3] | [Tram: A Token-level Retrieval-augmented Mechanism for Source Code Summarization.](http://arxiv.org/abs/2305.11074) | Tram是一种源代码摘要的令牌级别检索增强机制，它在解码器端精细检索帮助神经模型生成更准确的摘要，并在Java和Python源代码摘要任务上表现优异。 |
| [^4] | [Enriching language models with graph-based context information to better understand textual data.](http://arxiv.org/abs/2305.11070) | 基于图形上下文信息的语言模型增强可更好的理解文本，实验表明该方法提高了BERT模型在Pubmed上的分类任务表现。 |
| [^5] | [ORKG-Leaderboards: A Systematic Workflow for Mining Leaderboards as a Knowledge Graph.](http://arxiv.org/abs/2305.11068) | ORKG-Leaderboards是一种以知识图谱形式挖掘AI领域排行榜并支持机器可操作性出版的系统，能够让研究人员透明地了解全球研究人员的实证结果，跟踪人工智能的进展情况。 |
| [^6] | [Generating coherent comic with rich story using ChatGPT and Stable Diffusion.](http://arxiv.org/abs/2305.11067) | 本文介绍了一种利用ChatGPT和Stable Diffusion生成连贯漫画故事的方法，通过引入新的评估AI故事的方式，并使用LoRA、ControlNet等方法进行fine-tuning，取得了在角色忠实度和艺术风格上的最先进表现。 |
| [^7] | [SPSQL: Step-by-step Parsing Based Framework for Text-to-SQL Generation.](http://arxiv.org/abs/2305.11061) | 本文提出了一种基于流水线的文本转SQL方法: SPSQL，它将任务分解成四个子任务，从而减少了模型难度和对训练数据的要求，提高了准确率。 |
| [^8] | [Late-Binding Scholarship in the Age of AI: Navigating Legal and Normative Challenges of a New Form of Knowledge Production.](http://arxiv.org/abs/2305.11058) | 本文提出了一种更为动态的思想书写方式，即后期绑定过程，并探讨了AI在学术研究中的应用，但这种新形式也会带来相关法律和规范问题。 |
| [^9] | [The Water Health Open Knowledge Graph.](http://arxiv.org/abs/2305.11051) | 该论文介绍了一项旨在解决全球水资源稀缺性和质量问题的项目，其中提出了一个语义化的水健康开放知识图谱（WHOW-KG），可以对水的消耗、污染、传染病率和药品分布等数据进行建模，支持知识发现和决策制定。 |
| [^10] | [Simulation of a Variational Quantum Perceptron using Grover's Algorithm.](http://arxiv.org/abs/2305.11040) | 本研究结合了量子变分电路和Grover算法，成功构建了新型的量子感知器QVP-G。对比经典感知器，我们证明了QVP-G在分类任务中比QVP更加准确并且更加高效。 |
| [^11] | [Uncertainty Guided Label Denoising for Document-level Distant Relation Extraction.](http://arxiv.org/abs/2305.11029) | 本文提出了一种使用不确定性引导的标签去噪技术，可以有效准确地在文档级远程关系抽取中选择可信的伪标签，提高了性能表现，并在DocRED数据集上实现了新的最佳性能。 |
| [^12] | [Annotation-free Audio-Visual Segmentation.](http://arxiv.org/abs/2305.11019) | 本文提出了一种可伸缩且无需注释的管道，用于生成音视频分割任务的人工数据，并引入了一个音频感知的基于查询的Transformer解码器，使模型能够在音频信号的指导下搜索声音对象，得到更准确的分割。 |
| [^13] | [Sharing Lifelong Reinforcement Learning Knowledge via Modulating Masks.](http://arxiv.org/abs/2305.10997) | 通过调制掩码机制来实现多个代理之间的特定知识共享和强化学习，最终实现高效的分布式终身学习。 |
| [^14] | [How does the task complexity of masked pretraining objectives affect downstream performance?.](http://arxiv.org/abs/2305.10992) | 本文研究了掩码预训练任务的复杂度对下游任务表现的影响，并发现更复杂的任务可以实现更好的结果。这一发现表明，掩码预训练任务可以通过增加其复杂度来提高其性能。 |
| [^15] | [Less is More! A slim architecture for optimal language translation.](http://arxiv.org/abs/2305.10991) | 该论文提出了一种名为 KgV 的 sigmoid 门控机制，通过嵌入层剪枝减少了模型的大小，同时引入了 H-SoftPOS 层次嵌入层进一步改进嵌入以显著减少模型参数，从而在 WMT14 英德验证集上使 perplexity 减少了三倍以上。 |
| [^16] | [Benchmarking Deep Learning Frameworks for Automated Diagnosis of Ocular Toxoplasmosis: A Comprehensive Approach to Classification and Segmentation.](http://arxiv.org/abs/2305.10975) | 本研究评估了使用迁移学习技术的预训练网络对于从眼底图像中检测OT的有效性，并分析了基于迁移学习的分割网络在图像中分割病变的性能，为未来的DL技术研究提供了指导。 |
| [^17] | [Participatory Budgeting With Multiple Degrees of Projects And Ranged Approval Votes.](http://arxiv.org/abs/2305.10972) | 本论文研究了多重项目和区间批准投票的参与式预算框架，探讨了不同效用概念并证明了积极结果的扩展性，分析了问题的固定参数可跟踪性，并提出了重要的公理。 |
| [^18] | [Prevention is better than cure: a case study of the abnormalities detection in the chest.](http://arxiv.org/abs/2305.10961) | 本文以 Kaggle 竞赛为例，详细阐述了在医疗人工智能模型中，预防数据采集和标注阶段的问题要比训练过程中的修正更加重要，同时演示了如何通过数据不平衡测试，监控数据和模型平衡。 |
| [^19] | [In Defense of Pure 16-bit Floating-Point Neural Networks.](http://arxiv.org/abs/2305.10947) | 本文探讨了纯16位浮点神经网络的被忽视的效率，提供了理论分析来探讨16位和32位模型的差异，并可以定量解释16位模型与其32位对应物之间的条件。 |
| [^20] | [A method for the ethical analysis of brain-inspired AI.](http://arxiv.org/abs/2305.10938) | 本文研究了脑启发AI的发展和使用引发的一些概念性、技术性和伦理性问题，并介绍了一种方法可用于识别和解决伦理问题。 |
| [^21] | [On the Off-Target Problem of Zero-Shot Multilingual Neural Machine Translation.](http://arxiv.org/abs/2305.10930) | 零样本多语言神经机器翻译容易出现“离谱问题”，本文提出的简单且有效的算法LAVS可以通过增加语言之间的KL分歧显著降低这个问题。 |
| [^22] | [Structural Pruning for Diffusion Models.](http://arxiv.org/abs/2305.10924) | 本文提出了一种名为Diff-Pruning的高效压缩方法，通过一个Taylor展开过程来识别重要权重，从而从预先存在的模型中学习轻量级扩散模型，性能稳定，并在训练效率上显著提高。 |
| [^23] | [Emergent Communication with Attention.](http://arxiv.org/abs/2305.10920) | 该论文研究了在计算代理间如何实现更好地紧急通信的方法，并发现引入注意力机制可以得到更具组成性和可解释性的紧急语言。 |
| [^24] | [Weakly-Supervised Visual-Textual Grounding with Semantic Prior Refinement.](http://arxiv.org/abs/2305.10913) | 本文提出了一种利用语义先验细化的弱监督视觉-文本对齐方法，仅使用图像-句子对进行学习，其目标是实现实体表示中的区域-短语对应关系，通过联合两个主要模块的输出进行预测。 |
| [^25] | [A Generalist Dynamics Model for Control.](http://arxiv.org/abs/2305.10912) | 本文研究使用Transformer序列模型作为控制的动力学模型(TDMs)，证明TDMs表现良好且具有强大的泛化能力，相比于直接作为策略通用最优行为，泛化系统动力学可以更好地工作。 |
| [^26] | [RobustFair: Adversarial Evaluation through Fairness Confusion Directed Gradient Search.](http://arxiv.org/abs/2305.10906) | 本论文提出了一种基于公平混淆定向梯度搜索的谐波评估方法RobustFair，可以识别与虚假公平相结合的鲁棒性缺陷，提高DNN的鲁棒性和个体公平性。 |
| [^27] | [Domain Adaptive Sim-to-Real Segmentation of Oropharyngeal Organs.](http://arxiv.org/abs/2305.10883) | 该研究提出了一种称为IRB-AF的领域自适应的图像分割框架，通过使用IRB和ArtFlow方法来解决口咽器官图像分割中的数据域差异问题，有效提高了分割性能。 |
| [^28] | [Semantically Aligned Task Decomposition in Multi-Agent Reinforcement Learning.](http://arxiv.org/abs/2305.10865) | 该论文提出了一种多智能体强化学习中的新方法SAMA，通过提前训练的语言模型和任务分解来解决ASG方法存在的样本效率问题和生成非实际任务奖励的子目标的问题。 |
| [^29] | [Quiver: Supporting GPUs for Low-Latency, High-Throughput GNN Serving with Workload Awareness.](http://arxiv.org/abs/2305.10863) | Quiver 是一种分布式基于 GPU 的 GNN 服务系统，通过利用工作负载指标来预测 GNN 请求的不规则计算，并管理 GPU 用于图采样和特征聚合的优化方法，实现了低延迟和高吞吐量，比现有系统性能提高多达 15x。 |
| [^30] | [Non-deterministic approximation operators: ultimate operators, semi-equilibrium semantics and aggregates (full version).](http://arxiv.org/abs/2305.10846) | 本文研究了非确定性近似算子的极限近似、半平衡语义的代数公式以及带有聚合的不相交逻辑程序的特征。 |
| [^31] | [X-IQE: eXplainable Image Quality Evaluation for Text-to-Image Generation with Visual Large Language Models.](http://arxiv.org/abs/2305.10843) | 本文提出了一种名为X-IQE的图像质量评估方法，使用视觉大语言模型对文本到图像生成进行评估，并生成文本解释。它具有区分真实和生成图像、评估文本-图像对齐和评估图像美学等优点，显著增强了深度图像质量评估模型的透明度和可解释性。 |
| [^32] | [Uncertainty Quantification in Deep Neural Networks through Statistical Inference on Latent Space.](http://arxiv.org/abs/2305.10840) | 本研究提出了一种利用深度神经网络潜在空间表征进行不确定性量化的方法，该方法可以检测数据点的精确度并帮助自动侦测异常值。 |
| [^33] | [AIwriting: Relations Between Image Generation and Digital Writing.](http://arxiv.org/abs/2305.10834) | 本论坛讨论了基于AI的文本生成系统和文本到图像生成系统对数字艺术和电子文学领域带来的影响，各种作品都从文学角度考虑，突出了创作过程的交互性。 |
| [^34] | [Expanding the Role of Affective Phenomena in Multimodal Interaction Research.](http://arxiv.org/abs/2305.10827) | 本文分析了多模式交互和情感计算交叉领域的研究，并发现情感现象在研究中的角色非常重要，但仍有一些未被充分研究的领域。 |
| [^35] | [Integrating Item Relevance in Training Loss for Sequential Recommender Systems.](http://arxiv.org/abs/2305.10824) | 本文提出了一种融合项目相关性的新型训练损失函数，用于提高序列推荐系统对噪声的鲁棒性和性能。 |
| [^36] | [When Search Meets Recommendation: Learning Disentangled Search Representation for Recommendation.](http://arxiv.org/abs/2305.10822) | 论文提出了一种基于搜索增强的顺序推荐（SESRec）框架，它利用用户的搜索兴趣进行推荐，通过区分S＆R行为中的相似和不相似表示，使S＆R特征能够更好地发挥其独特的优势。 |
| [^37] | [Numeric Magnitude Comparison Effects in Large Language Models.](http://arxiv.org/abs/2305.10782) | 本研究探究了大型语言模型在数字大小比较上的表现，结果显示，尽管缺乏数字表达，不同架构的语言模型均呈现出惊人的类人表征能力。 |
| [^38] | [Rate-Adaptive Coding Mechanism for Semantic Communications With Multi-Modal Data.](http://arxiv.org/abs/2305.10773) | 本文提出了基于语义通信的多模数据自适应编码机制，采用NN-based语义编码器和解码器来提取不同模态中包含的相关语义信息，具有广泛应用前景。 |
| [^39] | [Adversarial Amendment is the Only Force Capable of Transforming an Enemy into a Friend.](http://arxiv.org/abs/2305.10766) | 本文提出了一种对抗修改 (AdvAmd) 方法，该方法可以改善神经网络模型的准确性并提高其在良性样本上的原始准确性水平。 |
| [^40] | [Physics Inspired Approaches Towards Understanding Gaussian Processes.](http://arxiv.org/abs/2305.10748) | 本文利用物理学方法分析了高斯过程模型的损失景观，提出了考虑更广泛的ν使得性能更佳的优化方法，同时提供了一种用于评估GP集成效果的方法和基于损失领域的物理属性的投票方法。 |
| [^41] | [Deep Temporal Graph Clustering.](http://arxiv.org/abs/2305.10738) | 提出通用框架TGC 用于 deep temporal graph clustering, 解决了时间图只能作为静态图处理的难题，实现了对动态信息的聚类。实验证明了 TGC 的优越性。 |
| [^42] | [Counterfactual Debiasing for Generating Factually Consistent Text Summaries.](http://arxiv.org/abs/2305.10736) | 本文提出了一个名为CoFactSum的去偏框架，通过反事实估计减轻原因，解决了生成文本摘要的事实不一致性问题，并在两个广泛使用的数据集上取得了优于现有模型的效果。 |
| [^43] | [Ambient Technology & Intelligence.](http://arxiv.org/abs/2305.10726) | 本篇论文探讨了环境技术和智能如何改善残疾人的护理需求及生活质量。 |
| [^44] | [Segment Any Anomaly without Training via Hybrid Prompt Regularization.](http://arxiv.org/abs/2305.10724) | 本文提出了SAA+框架，采用混合提示正则化技术进行零样本异常分割，并在多个基准数据集上取得了最先进的性能。 |
| [^45] | [Revisiting Long-term Time Series Forecasting: An Investigation on Linear Mapping.](http://arxiv.org/abs/2305.10721) | 本文证明了线性映射在长期时间序列预测中的重要性，提出了RevIN和CI的方法来提高预测性能，同时发现线性映射可以有效地捕捉时间序列的周期特征。 |
| [^46] | [A Survey on Time-Series Pre-Trained Models.](http://arxiv.org/abs/2305.10716) | 本综述全面回顾了时间序列预训练模型，其中监督、无监督和自监督是主要类别。通过使用这些模型，可以克服构建大规模标记数据集的困难，提高时间序列挖掘的性能和效率。 |
| [^47] | [Machine Learning Recommendation System For Health Insurance Decision Making In Nigeria.](http://arxiv.org/abs/2305.10708) | 本论文提出了一个基于机器学习的“医疗保险推荐系统”，采用基于内容的方法，通过地点和价格筛选医疗管理组织（HMO）的数据，并推荐相似服务的前三个HMO，旨在帮助尼日利亚人方便地找到最适合他们的健康保险计划。 |
| [^48] | [Think Outside the Code: Brainstorming Boosts Large Language Models in Code Generation.](http://arxiv.org/abs/2305.10679) | 本文介绍了一个名为Brainstorm的框架，利用头脑风暴步骤生成并选择关于问题的不同想法，可显著增强大型语言模型（LLMs）解决竞争级别编程问题的能力，结果在CodeContests基准测试中，ChatGPT的pass@$k$指标增加了50％以上。 |
| [^49] | [Less Can Be More: Unsupervised Graph Pruning for Large-scale Dynamic Graphs.](http://arxiv.org/abs/2305.10673) | 本研究提出了一个无监督图剪枝框架，名为STEP，用于解决大规模动态图的训练和部署问题，该框架不需要标签数据，并且具有最先进的剪枝效率和有效性。 |
| [^50] | [MetaGAD: Learning to Meta Transfer for Few-shot Graph Anomaly Detection.](http://arxiv.org/abs/2305.10668) | 本文提出了一种名为MetaGAD的框架，用于学习从无标记节点到有标记节点之间的元转移知识，以进行少样本图异常检测。 |
| [^51] | [Content-based Unrestricted Adversarial Attack.](http://arxiv.org/abs/2305.10665) | 该论文提出了一个基于内容的不受限制的对抗攻击框架，可生成高可转移的视觉逼真的对抗性样本，并能有效攻击各种深度神经网络。 |
| [^52] | [Scribble-Supervised Target Extraction Method Based on Inner Structure-Constraint for Remote Sensing Images.](http://arxiv.org/abs/2305.10661) | 本文提出了一种基于涂鸦注释的弱监督学习方法，在不引入任何辅助模块或额外操作的情况下，通过构建内部结构约束来解决遥感图像目标提取中的稀疏问题，并在实验中证明该方法的优越性。 |
| [^53] | [Use of Speech Impairment Severity for Dysarthric Speech Recognition.](http://arxiv.org/abs/2305.10659) | 本文提出了一种使用发音障碍严重程度和说话人身份的口吃症语音识别技术，实现了显著的字错率降低。 |
| [^54] | [Clarifying System 1 & 2 through the Common Model of Cognition.](http://arxiv.org/abs/2305.10654) | 本文采用计算思维的方法，特别是采用认知通用模型，阐明了Systm-1和System-2的底层机制，消除了对它们的误解并阐明了它们对元认知的影响。 |
| [^55] | [Adjusting Logit in Gaussian Form for Long-Tailed Visual Recognition.](http://arxiv.org/abs/2305.10648) | 本文提出了一种特征增强方法和两种logit调整方法，用于解决长尾视觉识别中的类别不平衡问题。实验结果表明，该方法在CIFAR和ImageNet长尾数据集上表现优于其他最先进的方法。 |
| [^56] | [BioAug: Conditional Generation based Data Augmentation for Low-Resource Biomedical NER.](http://arxiv.org/abs/2305.10647) | 本文提出了一种基于条件生成的数据增强框架BioAug，用于低资源生物医学命名实体识别。BioAug建立在BART上，通过选择性的屏蔽和知识增强进行训练。实验展示了BioAug在5个基准BioNER数据集上的有效性，且表现优于所有基线。 |
| [^57] | [Ethical ChatGPT: Concerns, Challenges, and Commandments.](http://arxiv.org/abs/2305.10646) | 本文针对ChatGPT提出了具体伦理关注点，对其在不同应用中的使用提出了关键挑战，并提出了不同ChatGPT相关方的实用诫命，以促进其伦理使用。 |
| [^58] | [Incremental Causal Graph Learning for Online Unsupervised Root Cause Analysis.](http://arxiv.org/abs/2305.10638) | 本文提出了CORAL，一种用于在线无监督根本原因分析的新框架，可以自动触发该过程并增量更新模型，包括三个主要部分：触发点检测，增量因果图学习和基于网络传播的根本原因定位。 |
| [^59] | [Tree of Thoughts: Deliberate Problem Solving with Large Language Models.](http://arxiv.org/abs/2305.10601) | 本研究提出了一种新的推理框架——思维之树（ToT），可以增强语言模型的问题解决能力，帮助语言模型进行深思熟虑的决策，以及自我评估和全局选择。 |
| [^60] | [Sim-MEES: Modular End-Effector System Grasping Dataset for Mobile Manipulators in Cluttered Environments.](http://arxiv.org/abs/2305.10580) | 本文介绍了一个包含1550个物体和1100万个机器人抓取标签的大规模合成数据集Sim-MEES，它能在杂乱的环境中通过模块化末端执行器系统提供精确的抓取标签，具有广泛的应用前景。 |
| [^61] | [Smiling Women Pitching Down: Auditing Representational and Presentational Gender Biases in Image Generative AI.](http://arxiv.org/abs/2305.10566) | 该研究审查了 DALL-E 2 生成的 15,300 张图像中的两种职业性别偏见，发现它在男性主导领域中低估女性，在女性主导职业中高估女性。此外，DALL-E 2 图像描绘更多带有微笑和向下看的女性，特别是在女性主导的职业中。 |
| [^62] | [Counterfactually Comparing Abstaining Classifiers.](http://arxiv.org/abs/2305.10564) | 本文提出一种新的方法和视角来评估和比较放弃分类器，将放弃预测视为缺失数据。我们定义了放弃分类器的反事实得分，指的是分类器没有放弃预测时的预测性能期望。 |
| [^63] | [Investigating the Effect of Hard Negative Sample Distribution on Contrastive Knowledge Graph Embedding.](http://arxiv.org/abs/2305.10563) | 本文探究了负采样分布对对比知识图谱嵌入的影响，提出考虑硬度和结构的对比（HaSa）算法，用于去除假负样本，提高知识图谱补全任务的性能。 |
| [^64] | [Integrated Conflict Management for UAM with Strategic Demand Capacity Balancing and Learning-based Tactical Deconfliction.](http://arxiv.org/abs/2305.10556) | 该论文提出了一种新的框架，将需求能力平衡和强化学习相结合，旨在解决城市空中移动（UAM）中的安全问题。在预处理流量的情况下，强化学习可以实现更好的战术安全分离表现。 |
| [^65] | [Discovering Individual Rewards in Collective Behavior through Inverse Multi-Agent Reinforcement Learning.](http://arxiv.org/abs/2305.10548) | 本论文介绍了一种离线逆向多智能体强化学习算法，通过利用演示，自动发现奖励函数并学习代理的有效策略，用于在复杂动态系统中寻找集体行为中的个体目标。 |
| [^66] | [Tractable Probabilistic Graph Representation Learning with Graph-Induced Sum-Product Networks.](http://arxiv.org/abs/2305.10544) | GSPNs是一种新的概率框架，用于图表示学习，可以可计算地回答概率查询，并通过权重共享和树状计算图的优势获得了纯概率模型的效率和深度图网络的效果。 |
| [^67] | [Generating Bayesian Network Models from Data Using Tsetlin Machines.](http://arxiv.org/abs/2305.10538) | 本文提出一种用Tsetlin Machines从数据中发现贝叶斯网络结构的方法。 |
| [^68] | [Scalable and Safe Remediation of Defective Actions in Self-Learning Conversational Systems.](http://arxiv.org/abs/2305.10528) | 本文提出了一种在自学习对话系统中利用历史回归事件报告来验证、保护和改进政策的方法，以解决在大规模商业环境中的经验连贯性和政策改进之间的平衡问题。 |
| [^69] | [ChatGPT Perpetuates Gender Bias in Machine Translation and Ignores Non-Gendered Pronouns: Findings across Bengali and Five other Low-Resource Languages.](http://arxiv.org/abs/2305.10510) | ChatGPT在翻译中延续性别偏见，忽略非性别代词，会将性别中立代词转换为男性或女性，甚至无法将英语中的性别中立代词翻译为其他语言的性别中立代词。 |
| [^70] | [ReasonNet: End-to-End Driving with Temporal and Global Reasoning.](http://arxiv.org/abs/2305.10507) | ReasonNet是一种全新的端到端自动驾驶框架，通过同时利用时间和全局信息，可以有效地处理城市密集交通场景下的稀有不利事件，如突然出现的遮挡物体。 |
| [^71] | [Model-Free Robust Average-Reward Reinforcement Learning.](http://arxiv.org/abs/2305.10504) | 本文研究了无模型鲁棒平均奖励马尔可夫决策过程，提出两种算法并证明了它们收敛到最优解。我们给出了几个广泛使用的不确定性集合作为示例。 |
| [^72] | [EENED: End-to-End Neural Epilepsy Detection based on Convolutional Transformer.](http://arxiv.org/abs/2305.10502) | 本文提出了一种名为EENED的端到端神经元癫痫检测模型，结合了CNN和Transformer，能够同时捕捉EEG信号的全局依赖性和局部特征，并有望提高癫痫检测的准确性和可靠性。 |
| [^73] | [Incorporating Attribution Importance for Improving Faithfulness Metrics.](http://arxiv.org/abs/2305.10496) | 本研究提出了一种软删除标准来评估归因方法的忠实度，该方法随机遮盖标记的部分向量表示，这种方法比现有的硬删除标准更准确。 |
| [^74] | [Bayesian Renormalization.](http://arxiv.org/abs/2305.10491) | 本文提出了一种基于信息论的贝叶斯统计模型的重整化方法，使用Fisher度量定义了一个相关长度作为紧密相关的概率分布点之间的可分辨性(RG)尺度，在统计推断实验中，可以得到某个系统最大特异性观察数量的代理。贝叶斯重整化方法为给定系统准备一个在上述尺度上精度有限的有效模型，这个尺度可以被解释为当前实验装置可以探测到的最大能量。贝叶斯重整化提出了一种发现和表征基本物理理论的新框架。 |
| [^75] | [Solitary pulmonary nodules prediction for lung cancer patients using nomogram and machine learning.](http://arxiv.org/abs/2305.10466) | 本文开发了一个基于计算机断层扫描和生物标志物信息的 nomogram，用于评估患有 8 毫米以下 SPNs 的肺癌的可能性，展示了高准确性和比机器学习模型更好的表现。 |
| [^76] | [Towards Robust Probabilistic Modeling on SO(3) via Rotation Laplace Distribution.](http://arxiv.org/abs/2305.10465) | 本文提出了一种新的基于旋转拉普拉斯分布的SO(3)稳健概率建模方法，对异常值具有鲁棒性，并可以容忍不完美的注释。 |
| [^77] | [Cooperation Is All You Need.](http://arxiv.org/abs/2305.10449) | 引入了一种基于“本地处理器民主”的算法Cooperator，该算法在强化学习中表现比Transformer算法更好。 |
| [^78] | [Sequence-to-Sequence Pre-training with Unified Modality Masking for Visual Document Understanding.](http://arxiv.org/abs/2305.10448) | 本文提出了一个统一的序列到序列文档理解模型，采用跨三种模态的统一掩码进行预训练，并且结构灵活适应各种下游任务输出格式。模型采用多种任务同时预训练，而且结合分解注意力和模态专家组合策略以提高信息捕获效率。 |
| [^79] | [The Effectiveness of a Dynamic Loss Function in Neural Network Based Automated Essay Scoring.](http://arxiv.org/abs/2305.10447) | 本研究提出了一种动态损失函数，帮助神经网络自动化评分系统在预测值的同时对正确的分布有更高的预测能力，而不牺牲任何性能。 |
| [^80] | [Memorization for Good: Encryption with Autoregressive Language Models.](http://arxiv.org/abs/2305.10445) | 该论文提出了第一个使用自回归语言模型进行对称加密的算法（SELM），其中算法可以将任意数据编码为紧凑的实值向量（即加密），然后通过随机子空间优化和贪心解码将向量无损解码为原始消息（即解密），并且SELM在加密分析方面的安全性能较高。 |
| [^81] | [SuperDriverAI: Towards Design and Implementation for End-to-End Learning-based Autonomous Driving.](http://arxiv.org/abs/2305.10443) | 本文提出了一种端到端学习自主驾驶模型SuperDriver AI，在保证道路安全的同时，提供了更好的鲁棒性和可解释性。测试结果表明，该模型的实际表现在日本东京的特定驾驶场景中达到了预期效果。 |
| [^82] | [An Intelligent SDWN Routing Algorithm Based on Network Situational Awareness and Deep Reinforcement Learning.](http://arxiv.org/abs/2305.10441) | 本文介绍了一种智能路由算法（DRL-PPONSA），基于软件定义无线网络架构下、具有网络态势感知的近似策略优化深度强化学习，通过一个特定的数据平面和一个基于DRL的数据转发机制，实现了高效获取网络状态信息、灵活转发数据，以提高通信服务质量。 |
| [^83] | [Intelligent multicast routing method based on multi-agent deep reinforcement learning in SDWN.](http://arxiv.org/abs/2305.10440) | 本文提出了一种基于多智能体深度强化学习的组播路由方法，在SDWN环境下可以显著提高多播路由性能，同时保证网络的QoS性能。 |
| [^84] | [IMAGINATOR: Pre-Trained Image+Text Joint Embeddings using Word-Level Grounding of Images.](http://arxiv.org/abs/2305.10438) | IMAGINATOR是一个使用基于单词级别图像本体的预训练图像+文本联合嵌入，能将多模态数据编码为矢量空间。 |
| [^85] | [Bringing AI to the edge: A formal M&S specification to deploy effective IoT architectures.](http://arxiv.org/abs/2305.10437) | 本文提出了一种基于离散事件系统规范的物联网模型来部署有效的物联网架构，包括将计算基础设施更靠近数据源的新架构雾计算和实时数据分析在网络边缘提供能力的新数据中心。 |
| [^86] | [Generative Pre-trained Transformer: A Comprehensive Review on Enabling Technologies, Potential Applications, Emerging Challenges, and Future Directions.](http://arxiv.org/abs/2305.10435) | 生成的预训练变形器是一种基于变形器架构的深度神经网络，能够在自然语言处理任务中表现出色且有效地进行对话，具有广泛的潜在应用，但仍面临新兴挑战和局限性。 |
| [^87] | [MemoryBank: Enhancing Large Language Models with Long-Term Memory.](http://arxiv.org/abs/2305.10250) | MemoryBank 提出了一种新型内存机制，旨在为大型语言模型提供类人的长期记忆。它可以召唤相关记忆，通过持续的记忆更新不断进化，通过合成过去的互动信息理解并适应用户个性。 |
| [^88] | [Assessing Hidden Risks of LLMs: An Empirical Study on Robustness, Consistency, and Credibility.](http://arxiv.org/abs/2305.10235) | 本研究是一项关于大型语言模型方面的实证研究，对主流语言模型进行了大量查询和分析，结果发现这些模型存在着鲁棒性、一致性和可信性方面的潜在风险。 |
| [^89] | [A proof of imitation of Wasserstein inverse reinforcement learning for multi-objective optimization.](http://arxiv.org/abs/2305.10089) | 本文证明了Wasserstein反向强化学习模型适用于多目标优化问题，可让学习者的奖励值和最优解模仿专家，具有一定的实用价值。 |
| [^90] | ["I'm fully who I am": Towards Centering Transgender and Non-Binary Voices to Measure Biases in Open Language Generation.](http://arxiv.org/abs/2305.09941) | 本论文研究了如何以TGNB人群的声音为中心，评估开放式语言生成中的偏见。通过理解TGNB个体的经历，提出了以TGNB人群为中心的OLG系统评估框架，并且包括一个为TGNB人群设计的调查工具和分析方法。 |
| [^91] | [Epsilon Sampling Rocks: Investigating Sampling Strategies for \\Minimum Bayes Risk Decoding for Machine Translation.](http://arxiv.org/abs/2305.09860) | 本文研究了用于机器翻译最小贝叶斯风险解码的不同采样策略，并发现了epsilon采样方式能够使得解码结果显著地优于其他所有已测试的采样方式和束搜索解码。 |
| [^92] | [Learning from Aggregated Data: Curated Bags versus Random Bags.](http://arxiv.org/abs/2305.09557) | 本文研究了两种自然的聚合方法：基于共同特征将数据点分组的精选包和将数据点随机分组的随机包，对于精选包设置和广泛的损失函数范围内，我们展示了可以通过梯度下降学习而不会导致数据聚合导致性能下降的情况。 |
| [^93] | [LoViT: Long Video Transformer for Surgical Phase Recognition.](http://arxiv.org/abs/2305.08989) | LoViT是一种用于手术阶段识别的长视频Transformer，它通过结合时间丰富的空间特征提取器和多尺度时间聚合器来对长视频进行分析，优于现有方法。 |
| [^94] | [Parameter-Efficient Fine-Tuning with Layer Pruning on Free-Text Sequence-to-Sequence modeling.](http://arxiv.org/abs/2305.08285) | 本文提出了一个将LoRA和结构化层剪枝方法结合的框架，在保持超过92%生成质量的同时，通过调整仅0.6%的参数并剪枝超过30%的Transformer层，成功减少了50%的GPU内存使用并提升了100%的训练速度。 |
| [^95] | [Learning to Generalize for Cross-domain QA.](http://arxiv.org/abs/2305.08208) | 提出了一种不增加训练成本的跨域问答泛化学习方法，通过结合提示方法和线性探测再微调策略，有效提高了产生式和判别式模型的泛化能力，取得了优于基准方法4.5%-7.9%的结果。 |
| [^96] | [DRew: Dynamically Rewired Message Passing with Delay.](http://arxiv.org/abs/2305.08018) | 本文提出了一种能够应用于任何MPNN结构的框架，执行基于层的动态重连来确保逐渐密集化的图形。同时引入了一种延迟机制，允许跨层节点之间的跳跃连接。 |
| [^97] | [A Federated Learning-based Industrial Health Prognostics for Heterogeneous Edge Devices using Matched Feature Extraction.](http://arxiv.org/abs/2305.07854) | 提出了一种基于联邦学习的健康预测模型，该模型具有特征相似性匹配算法来区分学习来自异构边缘设备的数据，以便开发出更准确的预测模型。 |
| [^98] | [Is ChatGPT a Good Causal Reasoner? A Comprehensive Evaluation.](http://arxiv.org/abs/2305.07375) | 本文对ChatGPT的因果推理能力进行了首次全面评估，实验证明ChatGPT是一个好的因果解释者，但不是一个好的因果推理者，存在严重的因果幻觉问题，对于明确的因果关系表现良好。 |
| [^99] | [Hawkes Process based on Controlled Differential Equations.](http://arxiv.org/abs/2305.07031) | 本文提出了一种基于控制微分方程的Hawkes过程模型，可精确计算对数似然，并能够正确处理不规则时间序列，适用于社会扩散和地震预测。 |
| [^100] | [A proof of convergence of inverse reinforcement learning for multi-objective optimization.](http://arxiv.org/abs/2305.06137) | 本论文证明了多目标优化的逆强化学习方法在理论层面上的收敛性，包括Wasserstein逆强化学习和常规逆强化学习方法。 |
| [^101] | [A Framework for Designing Foundation Model based Systems.](http://arxiv.org/abs/2305.05352) | 本文提出了一个基于基础模型的系统分类体系，分类和比较了基础模型和基于基础模型的系统的特点。它为设计基于基础模型的系统时做出主要的设计决策提供了具体的指导，并突出了相关的权衡。 |
| [^102] | [Distilling Script Knowledge from Large Language Models for Constrained Language Planning.](http://arxiv.org/abs/2305.05252) | 本文首次定义了受限语言规划任务，提出了一种方法来提高大型语言模型在这个任务中的表现，并提取了一个新颖的受限语言规划数据集。实验证明该方法显著提高了其在约束忠实度方面的能力，并对赋予较小的语言模型受限语言规划能力非常有效。 |
| [^103] | [Adapt and Align to Improve Zero-Shot Sketch-Based Image Retrieval.](http://arxiv.org/abs/2305.05144) | 本文针对零样本基于草图图像检索的跨域和语义问题，提出了一种自适应和对齐的方法，通过插入简单且轻量的域适配器重新学习草图领域的新抽象概念，并通过明确对齐学习到的图像嵌入以提高跨域表示能力。 |
| [^104] | [Comparing Foundation Models using Data Kernels.](http://arxiv.org/abs/2305.05126) | 本文采用基于数据内核的方法比较基础模型，不受度量指标的约束，通过嵌入空间几何实现点对点和多模型比较，并成功诱导了一组与下游指标强相关的模型距离函数流形。 |
| [^105] | [Augmented Large Language Models with Parametric Knowledge Guiding.](http://arxiv.org/abs/2305.04757) | 这篇论文提出了一种带参数知识引导的增强型大语言模型框架，通过为LLMs装备信息引导模块来访问相关知识，同时保持LLMs的参数不变。这个框架可以提高黑盒LLMs在各种NLP任务上的性能。 |
| [^106] | [LLM2Loss: Leveraging Language Models for Explainable Model Diagnostics.](http://arxiv.org/abs/2305.03212) | LLM2Loss利用语言模型为黑盒模型提供可解释的模型诊断，通过提取数据点的语义特征，揭示导致模型失败和偏差的因素。 |
| [^107] | [Unified Model Learning for Various Neural Machine Translation.](http://arxiv.org/abs/2305.02777) | 本文提出了一种统一学习方法，即统一模型学习，可以同时适用于翻译各种任务数据，并实现智能按需翻译，相对现有的特定数据集模型能够得到明显的改进。 |
| [^108] | [ARBEx: Attentive Feature Extraction with Reliability Balancing for Robust Facial Expression Learning.](http://arxiv.org/abs/2305.01486) | 本论文提出了一个名为ARBEx的框架，它采用了可靠性平衡方法来应对面部表情学习任务中的数据偏差和不确定性。该框架还引入了可学习的锚点和多头自注意机制，并在多个公共数据集上取得了有效性验证。 |
| [^109] | [Posterior Sampling for Deep Reinforcement Learning.](http://arxiv.org/abs/2305.00477) | 本文提出了用于深度强化学习的后验采样算法PSDRL，结合了高效的不确定性量化和特殊设计的持续规划算法，使其在提高样本效率的同时显著优于之前的尝试。 |
| [^110] | [Combining Adversaries with Anti-adversaries in Training.](http://arxiv.org/abs/2304.12550) | 该论文研究了在对抗训练中，通过结合对手和反对手(带有反对手扰动的样本)可以更有效地提高深度神经网络的公平性、鲁棒性和泛化性，在一些特定的学习场景中表现出更好的性能。 |
| [^111] | [DEIR: Efficient and Robust Exploration through Discriminative-Model-Based Episodic Intrinsic Rewards.](http://arxiv.org/abs/2304.10770) | 提出了一种探索强化学习算法DEIR，借助区分性模型实现理论上导出的内在奖励，能够高效且鲁棒地进行探索，适用于面对外部奖励稀疏的情况。 |
| [^112] | [H2RBox-v2: Boosting HBox-supervised Oriented Object Detection via Symmetric Learning.](http://arxiv.org/abs/2304.04403) | H2RBox-v2是第一个将对称学习应用于基于HBox监督的有向物体检测，其强化了水平注释和旋转注释之间的联系，在多个基准测试中实现了最先进的性能。 |
| [^113] | [Sociocultural knowledge is needed for selection of shots in hate speech detection tasks.](http://arxiv.org/abs/2304.01890) | HATELEXICON是一个包含巴西，德国，印度和肯尼亚仇恨言论的词汇表，利用其可以提高模型在训练中的性能表现。 |
| [^114] | [Neural Network Entropy (NNetEn): EEG Signals and Chaotic Time Series Separation by Entropy Features, Python Package for NNetEn Calculation.](http://arxiv.org/abs/2303.17995) | 该研究提出了一种新的熵估计方法NNetEn，用于有效地分离时间序列系统的混沌动态，并在分离混沌时间序列方面证明了其高效率。 |
| [^115] | [Attention! Dynamic Epistemic Logic Models of (In)attentive Agents.](http://arxiv.org/abs/2303.13494) | 本文提出了一种更一般化的动态认知逻辑模型，允许代理人关注一些原子公式的子集，并扩展了该框架，以解释无注意瞎视现象。 |
| [^116] | [Merging Decision Transformers: Weight Averaging for Forming Multi-Task Policies.](http://arxiv.org/abs/2303.07551) | 本文提出通过在权重空间中合并训练于不同 MuJoCo 运动问题上的 Decision Transformer 的子集，形成多任务模型。通过共享一些辅助任务的训练以及共同使用预训练初始化，能够获得更好的结果。这个方向的研究有助于使代理的过程民主化和分发。 |
| [^117] | [UNFUSED: UNsupervised Finetuning Using SElf supervised Distillation.](http://arxiv.org/abs/2303.05668) | 本文提出了一种使用自监督蒸馏的无监督微调方法，可以通过生成伪标签来减少音频分类所需的标注数据量。 |
| [^118] | [Certified Robust Neural Networks: Generalization and Corruption Resistance.](http://arxiv.org/abs/2303.02251) | 该论文提出了一种新颖的分布鲁棒损失函数，该函数通过认证级别的鲁棒性对两种常见的污染类型进行抵抗，并确保泛化保证，从而解决了鲁棒性和泛化之间的矛盾，具有极高的实用性。 |
| [^119] | [Exploring Numerical Priors for Low-Rank Tensor Completion with Generalized CP Decomposition.](http://arxiv.org/abs/2302.05881) | 本文提出了一种新的方法框架GCDTC，利用数值先验和广义CP分解实现了更高的低秩张量补全精度；同时介绍了一个算法SPTC，作为该框架的一个实现。在实验中，该方法表现出比现有技术更好的性能。 |
| [^120] | [Reinforcement Learning with History-Dependent Dynamic Contexts.](http://arxiv.org/abs/2302.02061) | 介绍了一种称为DCMDPs的新型强化学习框架，用于处理依赖历史环境的情况。其中的逻辑DCMDPs通过利用聚合函数确定上下文转换，打破了对历史长度的指数依赖，并引入了一种实用的基于模型的算法。在推荐任务中展示了该方法的有效性。 |
| [^121] | [MILO: Model-Agnostic Subset Selection Framework for Efficient Model Training and Tuning.](http://arxiv.org/abs/2301.13287) | 提出了一个模型无关子集选择框架MILO，将子集选择与模型训练分离，通过易到难的课程实现了卓越的模型收敛和性能。 |
| [^122] | [Case-Based Reasoning with Language Models for Classification of Logical Fallacies.](http://arxiv.org/abs/2301.11879) | 本文提出了一种基于案例推理的方法用于分类逻辑谬误的新案例，通过基于语言建模的检索和历史案例的调整来提高语言模型的准确性和泛化能力。 |
| [^123] | [Domain-Agnostic Molecular Generation with Self-feedback.](http://arxiv.org/abs/2301.11259) | MolGen是一个专注于分子生成的预训练语言模型，使用了领域无关的分子前缀调整和自我反馈的范式，实现了化学有效性、多样性、新颖性和复杂性的突破，在分子生成领域表现出了出色的性能。 |
| [^124] | [Solving Quantum-Inspired Perfect Matching Problems via Tutte's Theorem-Based Hybrid Boolean Constraints.](http://arxiv.org/abs/2301.09833) | 本文研究了混合布尔约束在量子计算中约束完美匹配问题的应用，提出了一种基于Tutte定理和优化技术的新编码方法，并证明其能够比竞争方法更好地扩展约束匹配基准。 |
| [^125] | [Deanthropomorphising NLP: Can a Language Model Be Conscious?.](http://arxiv.org/abs/2211.11483) | 本文讨论了关于使用Transformer架构的预训练语言模型LaMDA是否具有意识的说法。作者认为语言模型不可能具有意识，而LaMDA没有比其他类似模型更具先进性。 |
| [^126] | [SLICER: Learning universal audio representations using low-resource self-supervised pre-training.](http://arxiv.org/abs/2211.01519) | 本文提出了一种名为SLICER的自监督学习方法，通过聚类和对比学习相结合的方式进行编码器预训练，从而得到可以广泛适用于语音和非语音任务的音频表示。 |
| [^127] | [MAST: Multiscale Audio Spectrogram Transformers.](http://arxiv.org/abs/2211.01515) | MAST是一种多尺度音频谱图变压器，引入了多尺度特征分层概念，同时扩展嵌入维度，降低时间分辨率，用于音频分类。通过金字塔结构实现早期层和深层的建模，扩展方法为SS-MAST。 |
| [^128] | [A Measure of the Complexity of Neural Representations based on Partial Information Decomposition.](http://arxiv.org/abs/2209.10438) | 本文提出了一种基于部分信息分解的“表示复杂度”度量，用于量化跨多个神经元扩散的信息访问难度，并证明了其实用性。 |
| [^129] | [DGPO: Discovering Multiple Strategies with Diversity-Guided Policy Optimization.](http://arxiv.org/abs/2207.05631) | 这篇论文提出了一个名为DGPO的算法，可以在解决任务时发现多种策略，从而提高策略鲁棒性和与用户交互的乐趣。 |
| [^130] | [A Study on Transformer Configuration and Training Objective.](http://arxiv.org/abs/2205.10505) | 本文提出了Bamboo配置策略，基于更深更窄的Transformer结构进行Masked自编码器训练，在图像和语言任务上取得了新的最先进结果。 |
| [^131] | [Towards Power-Efficient Design of Myoelectric Controller based on Evolutionary Computation.](http://arxiv.org/abs/2204.02179) | 本文提出了一种基于核化SVM分类器的监督学习方法，通过约束的多目标优化问题实现肌电信号的高效控制，实验结果表明该方法在功率和分类准确性方面优于现有技术。 |
| [^132] | [Super-Reparametrizations of Weighted CSPs: Properties and Optimization Perspective.](http://arxiv.org/abs/2201.02018) | 本文研究了超重参数化的概念与特性，提出了通过超重参数化计算WCSP最优值上界的框架，并在实验中证明了其有效性。 |
| [^133] | [Epistemic Neural Networks.](http://arxiv.org/abs/2107.08924) | 该论文提出了一种能够通过适量级别的递增计算来估计神经网络不确定性的Epistemic神经网络框架，使得传统神经网络能够在计算成本大幅下降的情况下超越大型集成模型，为模型联合预测的方法提供了一种新的接口。 |
| [^134] | [Universal Approximation Properties for an ODENet and a ResNet: Mathematical Analysis and Numerical Experiments.](http://arxiv.org/abs/2101.10229) | 本论文证明了对于一类ODENet和一类ResNet，“宽度为n+m的ODENet可以逼近${\rm \mathbb{R}^n}$上紧致子集上的任何连续函数”，同时推导了损失函数对某个调整变量的梯度并用于构建ODENet的学习算法，并在MNIST上进行实验。 |

# 详细

[^1]: 激发Web规模语音模型的潜在能力以实现零-shot任务泛化

    Prompting the Hidden Talent of Web-Scale Speech Models for Zero-Shot Task Generalization. (arXiv:2305.11095v1 [eess.AS])

    [http://arxiv.org/abs/2305.11095](http://arxiv.org/abs/2305.11095)

    本文通过提示工程技术调整Whisper模型，成功适应未见过的三个任务，并提出的提示比默认提示性能提升了10%到45％，展现了Whisper模型的鲁棒性和多语言理解能力。

    

    本文研究了最近提出的Web规模语音模型Whisper的新兴功能，在使用提示工程技术调整模型后，适应了未见过的AVSR，CS-ASR和ST三个任务。我们设计了特定于任务的提示，要么利用另一个大规模模型，要么简单地操作默认提示中的特殊标记。实验证明，与默认提示相比，我们提出的提示使这三个零-shot任务的性能提高了10%到45％，甚至在一些数据集上超过了SotA监督模型。此外，我们的实验揭示了Whisper的许多有趣属性，包括其提示的鲁棒性，对口音的偏好以及潜在空间中的多语言理解。代码可在https://github.com/jasonppy/PromptingWhisper上找到。

    We investigate the emergent abilities of the recently proposed web-scale speech model Whisper, by adapting it to unseen tasks with prompt engineering. We selected three tasks: audio-visual speech recognition (AVSR), code-switched speech recognition (CS-ASR), and speech translation (ST) on unseen language pairs. We design task-specific prompts, by either leveraging another large-scale model, or simply manipulating the special tokens in the default prompts. Experiments show that compared to the default prompts, our proposed prompts improve performance by 10% to 45% on the three zero-shot tasks, and even outperform SotA supervised models on some datasets. In addition, our experiments reveal many interesting properties of Whisper, including its robustness to prompts, bias on accents, and the multilingual understanding in its latent space. Code is available at https://github.com/jasonppy/PromptingWhisper
    
[^2]: 自动推理领域相关问题的轻量级在线学习方法

    Lightweight Online Learning for Sets of Related Problems in Automated Reasoning. (arXiv:2305.11087v1 [cs.AI])

    [http://arxiv.org/abs/2305.11087](http://arxiv.org/abs/2305.11087)

    本文提出了一种自动推理中解决一组相关问题的轻量级在线学习方法，它能够自动收集信息并拟合机器学习模型来调整解决策略。在实验中证明该方法能证明更大的边界和发现更多反例。

    

    本文提出一种名为Self-Driven Strategy Learning (sdsl)的轻量级在线学习方法。该方法适用于自动推理中需要解决一组相关问题的任务。sdsl会在解决早期问题时自动收集信息来生成数据集。它利用这些学习到的数据来调整后续问题的解决策略，通过在线拟合机器学习模型。我们将这种方法形式化为一组抽象的转换规则。本文还描述了一个具体的sdsl计算实例，其中使用条件采样来生成数据，采用随机森林作为底层机器学习模型。我们在Kissat求解器上实现了该方法，并展示了Kissat+sdsl在最新的硬件模型检查竞赛中比其他最先进的有限模型检查方法证明了更大的边界和发现了更多的反例。

    We present Self-Driven Strategy Learning (sdsl), a lightweight online learning methodology for automated reasoning tasks that involve solving a set of related problems. sdsl automatically gathers information, in form of a dataset, while solving earlier problems. It utilizes the learned data to adjust the solving strategy for later problems by fitting a machine learning model to the obtained data on the fly. We formally define the approach as a set of abstract transition rules. We describe a concrete instance of the sdsl calculus which uses conditional sampling for generating data and random forests as the underlying machine learning model. We implement the approach on top of the Kissat solver and show that the combination of Kissat+sdsl certifies larger bounds and finds more counter-examples than other state-of-the-art bounded model checking approaches on benchmarks obtained from the latest Hardware Model Checking Competition.
    
[^3]: Tram：一个源代码摘要的令牌级检索增强机制

    Tram: A Token-level Retrieval-augmented Mechanism for Source Code Summarization. (arXiv:2305.11074v1 [cs.AI])

    [http://arxiv.org/abs/2305.11074](http://arxiv.org/abs/2305.11074)

    Tram是一种源代码摘要的令牌级别检索增强机制，它在解码器端精细检索帮助神经模型生成更准确的摘要，并在Java和Python源代码摘要任务上表现优异。

    

    自动生成人类可读的文本以描述程序的功能是源代码摘要的目标。虽然神经语言模型在这个领域取得了显著的性能，但结合神经模型和外部知识的新趋势正在兴起。大多数先前的方法依赖于句子级别的检索和组合范式（检索类似的代码片段并使用相应的代码和摘要对来编码）。然而，这种范式是粗粒度的，不能直接利用解码器端高质量的检索摘要令牌。本文中，我们探讨了一种精细的令牌级别检索增强机制，在解码器端帮助原始神经模型生成更好的代码摘要。此外，为了缓解令牌级别检索在捕捉上下文代码语义方面的局限性，我们提出将代码语义集成到摘要令牌中。大量的实验和人类评估表明，我们提出的方法Tram在Java和Python源代码摘要任务上均优于最先进的方法。

    Automatically generating human-readable text describing the functionality of a program is the intent of source code summarization. Although Neural Language Models achieve significant performance in this field, an emerging trend is combining neural models with external knowledge. Most previous approaches rely on the sentence-level retrieval and combination paradigm (retrieval of similar code snippets and use of the corresponding code and summary pairs) on the encoder side. However, this paradigm is coarse-grained and cannot directly take advantage of the high-quality retrieved summary tokens on the decoder side. In this paper, we explore a fine-grained token-level retrieval-augmented mechanism on the decoder side to help the vanilla neural model generate a better code summary. Furthermore, to mitigate the limitation of token-level retrieval on capturing contextual code semantics, we propose to integrate code semantics into summary tokens. Extensive experiments and human evaluation revea
    
[^4]: 基于图形上下文信息的语言模型增强以更好地理解文本数据

    Enriching language models with graph-based context information to better understand textual data. (arXiv:2305.11070v1 [cs.CL])

    [http://arxiv.org/abs/2305.11070](http://arxiv.org/abs/2305.11070)

    基于图形上下文信息的语言模型增强可更好的理解文本，实验表明该方法提高了BERT模型在Pubmed上的分类任务表现。

    

    每天遇到的文本具有相互联系的情况相当多。例如，Wikipedia文章通过超链接引用其他文章，科学论文通过引用或（共同）作者与其他论文相关联，而推文则通过关注彼此或转发内容来关联。因此，类似于图形的结构可以表示现有的联系，并被视为捕捉文本的“上下文”。因此，提取和整合这种上下文信息到语言模型中是否有助于更好地自动理解文本？在本研究中，我们实验性地证明，将基于图形的上下文化纳入BERT模型会增强其在分类任务示例上的表现。具体而言，在Pubmed数据集上，我们观察到误差从8.51％降至7.96％，同时仅增加了1.6％的参数量。

    A considerable number of texts encountered daily are somehow connected with each other. For example, Wikipedia articles refer to other articles via hyperlinks, scientific papers relate to others via citations or (co)authors, while tweets relate via users that follow each other or reshare content. Hence, a graph-like structure can represent existing connections and be seen as capturing the "context" of the texts. The question thus arises if extracting and integrating such context information into a language model might help facilitate a better automated understanding of the text. In this study, we experimentally demonstrate that incorporating graph-based contextualization into BERT model enhances its performance on an example of a classification task. Specifically, on Pubmed dataset, we observed a reduction in error from 8.51% to 7.96%, while increasing the number of parameters just by 1.6%.  Our source code: https://github.com/tryptofanik/gc-bert
    
[^5]: ORKG-Leaderboards: 一种以知识图谱形式挖掘排行榜的系统化流程

    ORKG-Leaderboards: A Systematic Workflow for Mining Leaderboards as a Knowledge Graph. (arXiv:2305.11068v1 [cs.CL])

    [http://arxiv.org/abs/2305.11068](http://arxiv.org/abs/2305.11068)

    ORKG-Leaderboards是一种以知识图谱形式挖掘AI领域排行榜并支持机器可操作性出版的系统，能够让研究人员透明地了解全球研究人员的实证结果，跟踪人工智能的进展情况。

    

    本文介绍了 ORKG-Leaderboard 软件，它旨在从人工智能领域的大量实证研究论文中自动提取以任务-数据集-度量元组为定义的排行榜。该软件支持学术出版的主要工作流程，即 LaTeX 文件或 PDF 文件。此外，该系统还与 Open Research Knowledge Graph (ORKG) 平台集成，该平台促进了学术发现的机器可操作性出版。因此，当系统输出与 ORKG 支持的语义 web 基础设施相结合时，它可以实现两个方面的功能：1）横跨全球的研究人员的实证结果的集成，从而实现实证研究的透明度，并有可能是完整的；2）让研究人员了解人工智能的进展情况。

    The purpose of this work is to describe the Orkg-Leaderboard software designed to extract leaderboards defined as Task-Dataset-Metric tuples automatically from large collections of empirical research papers in Artificial Intelligence (AI). The software can support both the main workflows of scholarly publishing, viz. as LaTeX files or as PDF files. Furthermore, the system is integrated with the Open Research Knowledge Graph (ORKG) platform, which fosters the machine-actionable publishing of scholarly findings. Thus the system output, when integrated within the ORKG's supported Semantic Web infrastructure of representing machine-actionable 'resources' on the Web, enables: 1) broadly, the integration of empirical results of researchers across the world, thus enabling transparency in empirical research with the potential to also being complete contingent on the underlying data source(s) of publications; and 2) specifically, enables researchers to track the progress in AI with an overview 
    
[^6]: 利用ChatGPT和Stable Diffusion生成内容丰富、故事连贯的漫画

    Generating coherent comic with rich story using ChatGPT and Stable Diffusion. (arXiv:2305.11067v1 [cs.CV])

    [http://arxiv.org/abs/2305.11067](http://arxiv.org/abs/2305.11067)

    本文介绍了一种利用ChatGPT和Stable Diffusion生成连贯漫画故事的方法，通过引入新的评估AI故事的方式，并使用LoRA、ControlNet等方法进行fine-tuning，取得了在角色忠实度和艺术风格上的最先进表现。

    

    过去的研究表明，使用神经网络可以在保持音乐家音乐风格的基础上，扩展未完成的音乐作品。最近大型语言模型和扩散模型的进展使得我们能够生成有趣的漫画故事，并保持艺术家的艺术风格。在本文中，我们使用ChatGPT生成情节和对话，然后使用stable diffusion生成漫画。我们介绍了一种评估AI生成故事的新方法，并通过使用LoRA、ControlNet等方法对stable diffusion进行fine-tuning，达到了在角色忠实度和艺术风格上的SOTA表现。

    Past work demonstrated that using neural networks, we can extend unfinished music pieces while maintaining the music style of the musician. With recent advancements in large language models and diffusion models, we are now capable of generating comics with an interesting storyline while maintaining the art style of the artist. In this paper, we used ChatGPT to generate storylines and dialogue and then generated the comic using stable diffusion. We introduced a novel way to evaluate AI-generated stories, and we achieved SOTA performance on character fidelity and art style by fine-tuning stable diffusion using LoRA, ControlNet, etc.
    
[^7]: SPSQL: 基于逐步解析的文本转SQL生成框架

    SPSQL: Step-by-step Parsing Based Framework for Text-to-SQL Generation. (arXiv:2305.11061v1 [cs.CL])

    [http://arxiv.org/abs/2305.11061](http://arxiv.org/abs/2305.11061)

    本文提出了一种基于流水线的文本转SQL方法: SPSQL，它将任务分解成四个子任务，从而减少了模型难度和对训练数据的要求，提高了准确率。

    

    将文本转换为结构化查询语言(Text2SQL)是自然语言处理(NLP)领域的研究热点，具有广泛的应用前景。在大数据时代，数据库的使用已经渗透到各个领域，其中收集的数据规模大、种类多样、范围广泛，使得数据查询繁琐低效，对Text2SQL模型提出了更高的要求。本文提出了一种基于流水线的Text2SQL方法: SPSQL，将文本转换为SQL过程分解为四个子任务——表选择、列选择、SQL生成和值填充，可以转化为一个可解析的句法树，从而减少了模型的复杂度和训练数据的需求，提高了准确率。

    Converting text into the structured query language (Text2SQL) is a research hotspot in the field of natural language processing (NLP), which has broad application prospects. In the era of big data, the use of databases has penetrated all walks of life, in which the collected data is large in scale, diverse in variety, and wide in scope, making the data query cumbersome and inefficient, and putting forward higher requirements for the Text2SQL model. In practical applications, the current mainstream end-to-end Text2SQL model is not only difficult to build due to its complex structure and high requirements for training data, but also difficult to adjust due to massive parameters. In addition, the accuracy of the model is hard to achieve the desired result. Based on this, this paper proposes a pipelined Text2SQL method: SPSQL. This method disassembles the Text2SQL task into four subtasks--table selection, column selection, SQL generation, and value filling, which can be converted into a te
    
[^8]: AI时代的后期绑定学术研究：应对知识生产中的法律与规范挑战

    Late-Binding Scholarship in the Age of AI: Navigating Legal and Normative Challenges of a New Form of Knowledge Production. (arXiv:2305.11058v1 [cs.CY])

    [http://arxiv.org/abs/2305.11058](http://arxiv.org/abs/2305.11058)

    本文提出了一种更为动态的思想书写方式，即后期绑定过程，并探讨了AI在学术研究中的应用，但这种新形式也会带来相关法律和规范问题。

    

    人工智能（AI）有望促进学术内容的创新性发展。与大型语言模型（如GPT-3）的合作等新的与AI系统互动形式，提供了改变学术研究及其产出物质性质的条件。本文提出了一些动态编写、分发、阅读、组织和存储思想的方法，这些方法可能比当前的学术实践更加有效。我们建议采用一种“后期绑定”的过程（即在思想离开作者桌子前不完全归纳出一种最终的书面形式的过程），而非当前的“早期绑定”过程。反过来，在阅读时将思想即时书写可以在学术工作中产生“动态”的变化，这将可能形成“未绑定”的知识传递方式。这一全新的知识模式可能催生形态各异的学术作品在读者面前实时生成的局面。然而，这种新形式的知识生产也带来了一些重大的法律和规范问题，如所有权、作者身份和质量控制等。本文探讨这些挑战，并提出了在学术研究中负责任地使用AI的策略。

    Artificial Intelligence (AI) is poised to enable a new leap in the creation of scholarly content. New forms of engagement with AI systems, such as collaborations with large language models like GPT-3, offer affordances that will change the nature of both the scholarly process and the artifacts it produces. This article articulates ways in which those artifacts can be written, distributed, read, organized, and stored that are more dynamic, and potentially more effective, than current academic practices. Specifically, rather than the current "early-binding" process (that is, one in which ideas are fully reduced to a final written form before they leave an author's desk), we propose that there are substantial benefits to a "late-binding" process, in which ideas are written dynamically at the moment of reading. In fact, the paradigm of "binding" knowledge may transition to a new model in which scholarship remains ever "unbound" and evolving. An alternative form for a scholarly work could b
    
[^9]: 水健康开放知识图谱

    The Water Health Open Knowledge Graph. (arXiv:2305.11051v1 [cs.DB])

    [http://arxiv.org/abs/2305.11051](http://arxiv.org/abs/2305.11051)

    该论文介绍了一项旨在解决全球水资源稀缺性和质量问题的项目，其中提出了一个语义化的水健康开放知识图谱（WHOW-KG），可以对水的消耗、污染、传染病率和药品分布等数据进行建模，支持知识发现和决策制定。

    

    近年来，人们对水和健康资源的管理越来越感兴趣。这种兴趣源于全球可持续发展所面临的挑战，水资源的稀缺性和质量成为了其中的核心问题。因此，有效、有意义和开放的数据的可用性对于解决这些问题至关重要，这些问题是联合国所制定的清洁水和卫生可持续发展目标的一部分。本文介绍了水健康开放知识图谱（WHOW-KG）及其设计方法和影响分析。WHOW-KG是一个语义化知识图谱，可对水的消耗、污染、传染病率和药品分布等数据进行建模。WHOW-KG是在欧盟资助的WHOW（水健康开放知识）项目的框架下开发的，旨在支持广泛的应用：从知识发现到决策制定，使其成为研究人员、政策制定者和从业人员一个宝贵的资源。

    Recently, an increasing interest in the management of water and health resources has been recorded. This interest is fed by the global sustainability challenges posed to the humanity that have water scarcity and quality at their core. Thus, the availability of effective, meaningful and open data is crucial to address those issues in the broader context of the Sustainable Development Goals of clean water and sanitation as targeted by the United Nations. In this paper, we present the Water Health Open Knowledge Graph (WHOW-KG) along with its design methodology and analysis on impact. WHOW-KG is a semantic knowledge graph that models data on water consumption, pollution, infectious disease rates and drug distribution. The WHOW-KG is developed in the context of the EU-funded WHOW (Water Health Open Knowledge) project and aims at supporting a wide range of applications: from knowledge discovery to decision-making, making it a valuable resource for researchers, policymakers, and practitioner
    
[^10]: 使用Grover算法模拟变分量子感知器

    Simulation of a Variational Quantum Perceptron using Grover's Algorithm. (arXiv:2305.11040v1 [quant-ph])

    [http://arxiv.org/abs/2305.11040](http://arxiv.org/abs/2305.11040)

    本研究结合了量子变分电路和Grover算法，成功构建了新型的量子感知器QVP-G。对比经典感知器，我们证明了QVP-G在分类任务中比QVP更加准确并且更加高效。

    

    量子感知器、变分电路和Grover算法被认为是量子机器学习的有前途的组件。该论文介绍了一种结合了量子变分电路和Grover算法的新型量子感知器。通过计算它们的损失函数以及分析它们在分类任务上的准确性，并将这两个量子模型与经典感知器进行比较，我们研究了QVP和QVP-G的性能。结果表明，我们的两个量子模型比CP更有效率，我们的新型建议模型QVP-G胜过QVP，证明了Grover算法可以应用在分类任务上，而且还可以提高模型的准确性，除了非结构化搜索问题。

    The quantum perceptron, the variational circuit, and the Grover algorithm have been proposed as promising components for quantum machine learning. This paper presents a new quantum perceptron that combines the quantum variational circuit and the Grover algorithm. However, this does not guarantee that this quantum variational perceptron with Grover's algorithm (QVPG) will have any advantage over its quantum variational (QVP) and classical counterparts. Here, we examine the performance of QVP and QVP-G by computing their loss function and analyzing their accuracy on the classification task, then comparing these two quantum models to the classical perceptron (CP). The results show that our two quantum models are more efficient than CP, and our novel suggested model QVP-G outperforms the QVP, demonstrating that the Grover can be applied to the classification task and even makes the model more accurate, besides the unstructured search problems.
    
[^11]: 不确定性引导的标签去噪在文档级远程关系抽取中的应用

    Uncertainty Guided Label Denoising for Document-level Distant Relation Extraction. (arXiv:2305.11029v1 [cs.CL])

    [http://arxiv.org/abs/2305.11029](http://arxiv.org/abs/2305.11029)

    本文提出了一种使用不确定性引导的标签去噪技术，可以有效准确地在文档级远程关系抽取中选择可信的伪标签，提高了性能表现，并在DocRED数据集上实现了新的最佳性能。

    

    文档级关系抽取旨在推断文档中实体之间的复杂语义关系。远程监督能够生成大量自动标注的数据，从而可以提高文档关系抽取的性能。然而，不可靠的伪标签会带来新的噪声，例如添加虚假的伪标签和失去正确的监督标签。因此，如何选择有效的伪标签来去噪远程监督数据仍然是文档级远程关系抽取中的一个挑战。为了解决这个问题，我们引入了不确定性估计技术来确定伪标签是否可信。在本文中，我们提出了一个带有不确定性引导标签去噪的文档级远程关系抽取框架，UGDRE。具体而言，我们提出了一种新的实例级不确定性估计方法，它测量了具有重叠关系的伪标签的可靠性。通过进一步考虑实例级和关系级的不确定性，我们设计了一个标签去噪组件，可以有效地选择可靠的伪标签进行文档关系抽取。在两个基准数据集上的实验结果表明，我们的方法显著优于现有方法，并在DocRED数据集上实现了新的最佳性能。

    Document-level relation extraction (DocRE) aims to infer complex semantic relations among entities in a document. Distant supervision (DS) is able to generate massive auto-labeled data, which can improve DocRE performance. Recent works leverage pseudo labels generated by the pre-denoising model to reduce noise in DS data. However, unreliable pseudo labels bring new noise, e.g., adding false pseudo labels and losing correct DS labels. Therefore, how to select effective pseudo labels to denoise DS data is still a challenge in document-level distant relation extraction. To tackle this issue, we introduce uncertainty estimation technology to determine whether pseudo labels can be trusted. In this work, we propose a Document-level distant Relation Extraction framework with Uncertainty Guided label denoising, UGDRE. Specifically, we propose a novel instance-level uncertainty estimation method, which measures the reliability of the pseudo labels with overlapping relations. By further consider
    
[^12]: 无标注音视频分割

    Annotation-free Audio-Visual Segmentation. (arXiv:2305.11019v1 [cs.CV])

    [http://arxiv.org/abs/2305.11019](http://arxiv.org/abs/2305.11019)

    本文提出了一种可伸缩且无需注释的管道，用于生成音视频分割任务的人工数据，并引入了一个音频感知的基于查询的Transformer解码器，使模型能够在音频信号的指导下搜索声音对象，得到更准确的分割。

    

    音视频分割的目标是通过准确地预测像素级分割掩码在视觉场景中定位声音对象。本文提出了以下贡献：（i）我们提出了一种可伸缩且无需注释的管道，用于生成音视频分割任务的人工数据。我们利用现有的图像分割和音频数据集，建立类别标签、图像掩模对和音频样本之间的联系，从而可以轻松组合训练AVS模型的（图像、音频、掩模）三元组；（ii）我们引入了一种新的音频感知变压器（AuTR）架构，其中包含一个音频感知的基于查询的Transformer解码器。该架构使模型能够在音频信号的指导下搜索声音对象，从而得到更准确的分割；（iii）我们在合成和真实数据集上进行了广泛的实验，证明了使用我们的管道生成的合成数据训练AVS模型的有效性。

    The objective of Audio-Visual Segmentation (AVS) is to locate sounding objects within visual scenes by accurately predicting pixelwise segmentation masks. In this paper, we present the following contributions: (i), we propose a scalable and annotation-free pipeline for generating artificial data for the AVS task. We leverage existing image segmentation and audio datasets to draw links between category labels, image-mask pairs, and audio samples, which allows us to easily compose (image, audio, mask) triplets for training AVS models; (ii), we introduce a novel Audio-Aware Transformer (AuTR) architecture that features an audio-aware query-based transformer decoder. This architecture enables the model to search for sounding objects with the guidance of audio signals, resulting in more accurate segmentation; (iii), we present extensive experiments conducted on both synthetic and real datasets, which demonstrate the effectiveness of training AVS models with synthetic data generated by our p
    
[^13]: 通过调制掩码分享终身强化学习知识

    Sharing Lifelong Reinforcement Learning Knowledge via Modulating Masks. (arXiv:2305.10997v1 [cs.LG])

    [http://arxiv.org/abs/2305.10997](http://arxiv.org/abs/2305.10997)

    通过调制掩码机制来实现多个代理之间的特定知识共享和强化学习，最终实现高效的分布式终身学习。

    

    终身学习代理旨在在其生命周期内逐渐学习多个任务。这需要在学习新任务时利用以前的知识并避免遗忘。最近，一种特定类型的参数隔离方法——调制掩码在监督学习和强化学习中表现出了潜力。虽然终身学习算法主要在单个代理的情况下进行研究，但仍存在一个问题，即多个代理如何彼此分享终身学习知识。我们发现，调制掩码所使用的参数隔离机制特别适合在分布式和去中心化的终身学习系统中的代理之间交换知识。关键思想是将特定任务知识隔离到特定的掩码中，让代理可以按需转移特定的知识，从而实现强大而有效的分布式终身学习。我们假设动态年龄全分布式异步情况下进行实验。

    Lifelong learning agents aim to learn multiple tasks sequentially over a lifetime. This involves the ability to exploit previous knowledge when learning new tasks and to avoid forgetting. Modulating masks, a specific type of parameter isolation approach, have recently shown promise in both supervised and reinforcement learning. While lifelong learning algorithms have been investigated mainly within a single-agent approach, a question remains on how multiple agents can share lifelong learning knowledge with each other. We show that the parameter isolation mechanism used by modulating masks is particularly suitable for exchanging knowledge among agents in a distributed and decentralized system of lifelong learners. The key idea is that the isolation of specific task knowledge to specific masks allows agents to transfer only specific knowledge on-demand, resulting in robust and effective distributed lifelong learning. We assume fully distributed and asynchronous scenarios with dynamic age
    
[^14]: 掩码预训练任务的复杂度如何影响下游任务表现？

    How does the task complexity of masked pretraining objectives affect downstream performance?. (arXiv:2305.10992v1 [cs.CL])

    [http://arxiv.org/abs/2305.10992](http://arxiv.org/abs/2305.10992)

    本文研究了掩码预训练任务的复杂度对下游任务表现的影响，并发现更复杂的任务可以实现更好的结果。这一发现表明，掩码预训练任务可以通过增加其复杂度来提高其性能。

    

    掩码语言建模是一种广泛使用的自监督预训练任务，其中模型需要预测替换上下文中的原始token的掩码。尽管最近使用更简单且计算较少的预训练任务，例如预测掩码标记的第一个字符，已经表现出与掩码语言建模相当的结果，但使用掩码方案的任务目前还没有超越掩码语言建模。本文假设缺乏复杂性是造成其性能下降的关键，我们验证了更复杂的掩码任务是否能够实现更好的结果，并探究它们的复杂度需要达到多少才能与掩码语言建模表现相当。我们使用GLUE、SQuAD和Universal Dependencies基准测试结果表明，更复杂的任务倾向于展现更好的下游任务表现，至少需要掩码语言建模复杂度的一半才能与其表现相当。最后，我们讨论了如何使用掩码任务预训练模型。

    Masked language modeling (MLM) is a widely used self-supervised pretraining objective, where a model needs to predict an original token that is replaced with a mask given contexts. Although simpler and computationally efficient pretraining objectives, e.g., predicting the first character of a masked token, have recently shown comparable results to MLM, no objectives with a masking scheme actually outperform it in downstream tasks. Motivated by the assumption that their lack of complexity plays a vital role in the degradation, we validate whether more complex masked objectives can achieve better results and investigate how much complexity they should have to perform comparably to MLM. Our results using GLUE, SQuAD, and Universal Dependencies benchmarks demonstrate that more complicated objectives tend to show better downstream results with at least half of the MLM complexity needed to perform comparably to MLM. Finally, we discuss how we should pretrain a model using a masked objective 
    
[^15]: 更少即是更好！一种优化语言翻译的轻量级架构。(arXiv:2305.10991v1 [cs.CL])

    Less is More! A slim architecture for optimal language translation. (arXiv:2305.10991v1 [cs.CL])

    [http://arxiv.org/abs/2305.10991](http://arxiv.org/abs/2305.10991)

    该论文提出了一种名为 KgV 的 sigmoid 门控机制，通过嵌入层剪枝减少了模型的大小，同时引入了 H-SoftPOS 层次嵌入层进一步改进嵌入以显著减少模型参数，从而在 WMT14 英德验证集上使 perplexity 减少了三倍以上。

    

    Softmax 注意力机制在人工智能研究领域已经成为一个值得关注的开发，构建在 Transformer 架构的成功基础之上。然而，它们不断增长的大小需要越来越多的计算存储器，从而限制了它们的使用。我们提出了 KgV，一种 sigmoid 门控机制，与 softmax 注意力一起显著提高了性能，同时不增加架构大小。为了修正大小要求，我们利用张量链来识别和修剪多余的参数。我们发现，这样的多余主要存在于嵌入层中，而不是输出线性层中。为了进一步改进嵌入和显著减少参数，我们引入了 H-SoftPOS，一种层次嵌入层，同时增强了性能。值得注意的是，在 WMT14 英德验证集上，我们的方法使 perplexity 减少了三倍，超过了当前的最新成果，同时减少降低模型大小。

    The softmax attention mechanism has emerged as a noteworthy development in the field of Artificial Intelligence research, building on the successes of Transformer-based architectures. However, their ever increasing sizes necessitate ever increasing computational memory, that limits their usage. We propose KgV, a sigmoid gating mechanism that, in conjunction with softmax attention, significantly boosts performance without increasing architecture size. To amend the size requirements, we leverage Tensor Chains to identify and prune the excess parameters. We find that such excess resides primarily within the embedding layer, and not in the output linear layer. To further improve embedding and significantly reduce parameters, we introduce H-SoftPOS, a hierarchical embedding layer which simultaneously enhances performance. Remarkably, on the WMT14 English-German validation set, our approach yields a threefold reduction in perplexity, surpassing the current state-of-the-art, while reducing pa
    
[^16]: 基于深度学习框架的眼部弓形虫病自动诊断基准测试：对分类和分割的全面应用

    Benchmarking Deep Learning Frameworks for Automated Diagnosis of Ocular Toxoplasmosis: A Comprehensive Approach to Classification and Segmentation. (arXiv:2305.10975v1 [eess.IV])

    [http://arxiv.org/abs/2305.10975](http://arxiv.org/abs/2305.10975)

    本研究评估了使用迁移学习技术的预训练网络对于从眼底图像中检测OT的有效性，并分析了基于迁移学习的分割网络在图像中分割病变的性能，为未来的DL技术研究提供了指导。

    

    眼部弓形虫病（OT）是由弓形虫引起的常见眼部感染，可导致视力问题。诊断通常通过临床检查和成像进行，但这些方法可能复杂且成本高，需要训练有素的人员。为解决这个问题，我们创建了一个基准研究，评估使用迁移学习技术的现有预训练网络检测从眼底图像中检测OT的有效性。此外，我们还分析了基于迁移学习的分割网络在图像中分割病变的性能。该研究旨在为未来研究人员提供一个指南，帮助其利用深度学习技术开发一种廉价、自动化、易于使用且准确的诊断方法。我们进行了深入的特征提取技术分析，以找到最优的特征提取技术，用于OT分类和病变分割。

    Ocular Toxoplasmosis (OT), is a common eye infection caused by T. gondii that can cause vision problems. Diagnosis is typically done through a clinical examination and imaging, but these methods can be complicated and costly, requiring trained personnel. To address this issue, we have created a benchmark study that evaluates the effectiveness of existing pre-trained networks using transfer learning techniques to detect OT from fundus images. Furthermore, we have also analysed the performance of transfer-learning based segmentation networks to segment lesions in the images. This research seeks to provide a guide for future researchers looking to utilise DL techniques and develop a cheap, automated, easy-to-use, and accurate diagnostic method. We have performed in-depth analysis of different feature extraction techniques in order to find the most optimal one for OT classification and segmentation of lesions. For classification tasks, we have evaluated pre-trained models such as VGG16, Mo
    
[^17]: 多重项目和区间批准投票的参与式预算

    Participatory Budgeting With Multiple Degrees of Projects And Ranged Approval Votes. (arXiv:2305.10972v1 [cs.GT])

    [http://arxiv.org/abs/2305.10972](http://arxiv.org/abs/2305.10972)

    本论文研究了多重项目和区间批准投票的参与式预算框架，探讨了不同效用概念并证明了积极结果的扩展性，分析了问题的固定参数可跟踪性，并提出了重要的公理。

    

    在不可分配的参与式预算框架中，我们有一个有限的预算需要分配给一组项目，通过汇集选民对项目的偏好来分配。关于不可分配的参与式预算的所有先前工作都假设每个项目只有一种可能的成本。在这项工作中，我们允许每个项目具有一组可允许的成本，每个成本反映该项目可能的复杂程度。每个选民为每个项目批准一定成本范围，通过给出她认为该项目应该具有的成本的上限和下限。PB规则的结果选择一组项目，并指定它们对应的成本。我们研究不同的效用概念，并证明在每个项目只有一种可允许的成本时现有的积极结果也可以扩展到我们的框架中，其中一个项目具有多个可允许的成本。我们还分析了问题的固定参数可跟踪性。最后，我们提出了一些重要且直观的公理。

    In an indivisible participatory budgeting (PB) framework, we have a limited budget that is to be distributed among a set of projects, by aggregating the preferences of voters for the projects. All the prior work on indivisible PB assumes that each project has only one possible cost. In this work, we let each project have a set of permissible costs, each reflecting a possible degree of sophistication of the project. Each voter approves a range of costs for each project, by giving an upper and lower bound on the cost that she thinks the project deserves. The outcome of a PB rule selects a subset of projects and also specifies their corresponding costs. We study different utility notions and prove that the existing positive results when every project has exactly one permissible cost can also be extended to our framework where a project has several permissible costs. We also analyze the fixed parameter tractability of the problem. Finally, we propose some important and intuitive axioms and
    
[^18]: 预防胜于治疗：胸部异常检测案例研究

    Prevention is better than cure: a case study of the abnormalities detection in the chest. (arXiv:2305.10961v1 [cs.AI])

    [http://arxiv.org/abs/2305.10961](http://arxiv.org/abs/2305.10961)

    本文以 Kaggle 竞赛为例，详细阐述了在医疗人工智能模型中，预防数据采集和标注阶段的问题要比训练过程中的修正更加重要，同时演示了如何通过数据不平衡测试，监控数据和模型平衡。

    

    “预防胜于治疗” 不仅适用于疾病预防，也适用于医疗人工智能模型问题的预防。预测模型失效的根源往往不在于训练过程，而是数据采集或实验设计阶段。本文以 Kaggle 竞赛为例，详细分析 X-光肺图像异常检测问题。我们演示了一系列简单的数据不平衡测试如何暴露出数据采集和标注过程中的问题。复杂模型能够学习这样的伪相，将其移除或改正后的训练是困难的。在数据收集阶段出现的错误使得模型正确验证变得困难。基于此案例，我们展示了如何在预测模型的整个生命周期中监控数据和模型平衡（公平性），从数据采集到模型分数的平衡分析。

    Prevention is better than cure. This old truth applies not only to the prevention of diseases but also to the prevention of issues with AI models used in medicine. The source of malfunctioning of predictive models often lies not in the training process but reaches the data acquisition phase or design of the experiment phase.  In this paper, we analyze in detail a single use case - a Kaggle competition related to the detection of abnormalities in X-ray lung images. We demonstrate how a series of simple tests for data imbalance exposes faults in the data acquisition and annotation process. Complex models are able to learn such artifacts and it is difficult to remove this bias during or after the training. Errors made at the data collection stage make it difficult to validate the model correctly.  Based on this use case, we show how to monitor data and model balance (fairness) throughout the life cycle of a predictive model, from data acquisition to parity analysis of model scores.
    
[^19]: 关于纯16位浮点神经网络的辩护

    In Defense of Pure 16-bit Floating-Point Neural Networks. (arXiv:2305.10947v1 [cs.LG])

    [http://arxiv.org/abs/2305.10947](http://arxiv.org/abs/2305.10947)

    本文探讨了纯16位浮点神经网络的被忽视的效率，提供了理论分析来探讨16位和32位模型的差异，并可以定量解释16位模型与其32位对应物之间的条件。

    

    减少编码神经网络权重和激活所需的位数是非常可取的，因为它可以加快神经网络的训练和推理时间，同时减少内存消耗。因此，这一领域的研究引起了广泛关注，以开发利用更低精度计算的神经网络，比如混合精度训练。有趣的是，目前不存在纯16位浮点设置的方法。本文揭示了纯16位浮点神经网络被忽视的效率。我们通过提供全面的理论分析来探讨造成16位和32位模型的差异的因素。我们规范化了浮点误差和容忍度的概念，从而可以定量解释16位模型与其32位对应物之间密切逼近结果的条件。这种理论探索提供了新的视角。

    Reducing the number of bits needed to encode the weights and activations of neural networks is highly desirable as it speeds up their training and inference time while reducing memory consumption. For these reasons, research in this area has attracted significant attention toward developing neural networks that leverage lower-precision computing, such as mixed-precision training. Interestingly, none of the existing approaches has investigated pure 16-bit floating-point settings. In this paper, we shed light on the overlooked efficiency of pure 16-bit floating-point neural networks. As such, we provide a comprehensive theoretical analysis to investigate the factors contributing to the differences observed between 16-bit and 32-bit models. We formalize the concepts of floating-point error and tolerance, enabling us to quantitatively explain the conditions under which a 16-bit model can closely approximate the results of its 32-bit counterpart. This theoretical exploration offers perspect
    
[^20]: 脑启发AI伦理分析的方法

    A method for the ethical analysis of brain-inspired AI. (arXiv:2305.10938v1 [cs.AI])

    [http://arxiv.org/abs/2305.10938](http://arxiv.org/abs/2305.10938)

    本文研究了脑启发AI的发展和使用引发的一些概念性、技术性和伦理性问题，并介绍了一种方法可用于识别和解决伦理问题。

    

    尽管人工智能（AI）取得了成功，但在不同的应用领域和目标方面，它仍存在一些缺陷。这些限制可以说是概念上的（例如，与底层理论模型有关，如符号型与连接型），也可以是操作上的（例如，与鲁棒性和泛化能力相关）。受生物启发的AI，更具体地说是受大脑启发的AI，承诺提供超越已传统包含在AI中的生物方面，从而可以评估和可能克服其现有缺点。本文研究了脑启发AI的发展和使用引发的一些概念性、技术性和伦理性问题。在此背景下，本文探讨了脑启发AI是否存在伦理上的独特性。本文旨在介绍一种启发式的方法，可用于识别和解决伦理问题。

    Despite its successes, to date Artificial Intelligence (AI) is still characterized by a number of shortcomings with regards to different application domains and goals. These limitations are arguably both conceptual (e.g., related to underlying theoretical models, such as symbolic vs. connectionist), and operational (e.g., related to robustness and ability to generalize). Biologically inspired AI, and more specifically brain-inspired AI, promises to provide further biological aspects beyond those that are already traditionally included in AI, making it possible to assess and possibly overcome some of its present shortcomings. This article examines some conceptual, technical, and ethical issues raised by the development and use of brain-inspired AI. Against this background, the paper asks whether there is anything ethically unique about brain-inspired AI. The aim of the paper is to introduce a method that has a heuristic nature and that can be applied to identify and address the ethical 
    
[^21]: 零样本多语言神经机器翻译中的“离谱问题”

    On the Off-Target Problem of Zero-Shot Multilingual Neural Machine Translation. (arXiv:2305.10930v1 [cs.CL])

    [http://arxiv.org/abs/2305.10930](http://arxiv.org/abs/2305.10930)

    零样本多语言神经机器翻译容易出现“离谱问题”，本文提出的简单且有效的算法LAVS可以通过增加语言之间的KL分歧显著降低这个问题。

    

    尽管多语言神经机器翻译取得了巨大成功，但它仍然存在“离谱问题”，即将翻译输出到错误的语言中。这个问题在零样本翻译任务中更加明显。本文发现，当编码目标语言信号时失效，会导致离谱问题，并且两种语言词汇之间更接近的词汇距离（即KL分歧）与更高的离谱率有关。此外，本文还发现，仅隔离解码器中不同语言的词汇可以缓解这个问题。基于这些发现，我们提出了一种简单有效的算法Language Aware Vocabulary Sharing (LAVS)来构建多语言词汇表，通过增加语言之间的KL分歧，大大减轻了翻译模型的离谱问题。我们在11种语言的多语言翻译基准测试上进行了实验。实验结果表明，对于90个翻译任务，采用LAVS的离谱率降低了37％至90％。

    While multilingual neural machine translation has achieved great success, it suffers from the off-target issue, where the translation is in the wrong language. This problem is more pronounced on zero-shot translation tasks. In this work, we find that failing in encoding discriminative target language signal will lead to off-target and a closer lexical distance (i.e., KL-divergence) between two languages' vocabularies is related with a higher off-target rate. We also find that solely isolating the vocab of different languages in the decoder can alleviate the problem. Motivated by the findings, we propose Language Aware Vocabulary Sharing (LAVS), a simple and effective algorithm to construct the multilingual vocabulary, that greatly alleviates the off-target problem of the translation model by increasing the KL-divergence between languages. We conduct experiments on a multilingual machine translation benchmark in 11 languages. Experiments show that the off-target rate for 90 translation 
    
[^22]: 扩散模型的结构剪枝

    Structural Pruning for Diffusion Models. (arXiv:2305.10924v1 [cs.LG])

    [http://arxiv.org/abs/2305.10924](http://arxiv.org/abs/2305.10924)

    本文提出了一种名为Diff-Pruning的高效压缩方法，通过一个Taylor展开过程来识别重要权重，从而从预先存在的模型中学习轻量级扩散模型，性能稳定，并在训练效率上显著提高。

    

    生成建模最近取得了显著的进展，主要是因为扩散概率模型（DPM）的转型意义。然而，这些模型的令人印象深刻的能力通常涉及到显著的计算开销，在训练和推理期间都是如此。为了应对这一挑战，我们提出了Diff-Pruning，一种专为从预先存在的模型中学习轻量级扩散模型而设计的高效压缩方法，无需进行大量的重新训练。Diff-Pruning的本质是通过剪枝时间步长的Taylor展开，在过滤掉无贡献扩散步骤和整合有信息的梯度来识别重要权重的过程。我们在四个不同数据集上进行的实证评估突出了我们所提出方法的两个主要优点：1）效率：它可以以原始训练投入的仅10％到20％的代价实现约50％的FLOPs减少; 2）一致性: 剪枝后的扩散模型产生的效果与原始模型相当，不会影响生成建模的质量。

    Generative modeling has recently undergone remarkable advancements, primarily propelled by the transformative implications of Diffusion Probabilistic Models (DPMs). The impressive capability of these models, however, often entails significant computational overhead during both training and inference. To tackle this challenge, we present Diff-Pruning, an efficient compression method tailored for learning lightweight diffusion models from pre-existing ones, without the need for extensive re-training. The essence of Diff-Pruning is encapsulated in a Taylor expansion over pruned timesteps, a process that disregards non-contributory diffusion steps and ensembles informative gradients to identify important weights. Our empirical assessment, undertaken across four diverse datasets highlights two primary benefits of our proposed method: 1) Efficiency: it enables approximately a 50% reduction in FLOPs at a mere 10% to 20% of the original training expenditure; 2) Consistency: the pruned diffusio
    
[^23]: 使用注意力机制的紧急通信

    Emergent Communication with Attention. (arXiv:2305.10920v1 [cs.CL])

    [http://arxiv.org/abs/2305.10920](http://arxiv.org/abs/2305.10920)

    该论文研究了在计算代理间如何实现更好地紧急通信的方法，并发现引入注意力机制可以得到更具组成性和可解释性的紧急语言。

    

    为了开发出更好地使用自己的紧急语言进行通信的计算代理，我们赋予代理在环境中关注特定概念的能力。人类经常将一个对象或场景理解为概念的组合，并将这些概念进一步映射到单词上。我们将这种直觉实现为"Speaker"和"Listener"代理中的跨模态注意力机制，在引用游戏中显示注意力导致更具组成性和可解释性的紧急语言。我们还通过调查每个消息符号相关的注意权重以及"Speaker"和"Listener"代理之间注意权重的对齐，展示了注意力如何帮助理解学习到的通信协议。总的来说，我们的结果表明，注意力是开发更具人类化的紧急语言的一种有前途的机制。

    To develop computational agents that better communicate using their own emergent language, we endow the agents with an ability to focus their attention on particular concepts in the environment. Humans often understand an object or scene as a composite of concepts and those concepts are further mapped onto words. We implement this intuition as cross-modal attention mechanisms in Speaker and Listener agents in a referential game and show attention leads to more compositional and interpretable emergent language. We also demonstrate how attention aids in understanding the learned communication protocol by investigating the attention weights associated with each message symbol and the alignment of attention weights between Speaker and Listener agents. Overall, our results suggest that attention is a promising mechanism for developing more human-like emergent language.
    
[^24]: 利用语义先验细化的弱监督视觉-文本对齐

    Weakly-Supervised Visual-Textual Grounding with Semantic Prior Refinement. (arXiv:2305.10913v1 [cs.CV])

    [http://arxiv.org/abs/2305.10913](http://arxiv.org/abs/2305.10913)

    本文提出了一种利用语义先验细化的弱监督视觉-文本对齐方法，仅使用图像-句子对进行学习，其目标是实现实体表示中的区域-短语对应关系，通过联合两个主要模块的输出进行预测。

    

    弱监督视觉-文本对齐的目标是仅利用图像-句子对学习实体表示中的区域-短语对应关系。与监督方法相比，其难度更大，因为无法获得边界框和文本短语的对应关系。因此，我们提出了语义先验细化模型（SPRM），其预测结果是通过组合两个主要模块的输出得到的。第一个未经训练的模块旨在返回文本短语和边界框之间的粗略对齐。第二个训练过的模块由两个子组件组成，用于细化粗略的对齐以提高最终短语-边界框对齐的准确性。该模型的训练目标是最大化图像和句子之间的多模态相似度，同时使同一句子和一个新的不相关的图像的多模态相似度最小化，以在训练过程中最大限度地提高训练效果。我们的方法在两个流行的数据集上展现了最先进的结果。

    Using only image-sentence pairs, weakly-supervised visual-textual grounding aims to learn region-phrase correspondences of the respective entity mentions. Compared to the supervised approach, learning is more difficult since bounding boxes and textual phrases correspondences are unavailable. In light of this, we propose the Semantic Prior Refinement Model (SPRM), whose predictions are obtained by combining the output of two main modules. The first untrained module aims to return a rough alignment between textual phrases and bounding boxes. The second trained module is composed of two sub-components that refine the rough alignment to improve the accuracy of the final phrase-bounding box alignments. The model is trained to maximize the multimodal similarity between an image and a sentence, while minimizing the multimodal similarity of the same sentence and a new unrelated image, carefully selected to help the most during training. Our approach shows state-of-the-art results on two popula
    
[^25]: 一种通用动力学模型用于控制

    A Generalist Dynamics Model for Control. (arXiv:2305.10912v1 [cs.AI])

    [http://arxiv.org/abs/2305.10912](http://arxiv.org/abs/2305.10912)

    本文研究使用Transformer序列模型作为控制的动力学模型(TDMs)，证明TDMs表现良好且具有强大的泛化能力，相比于直接作为策略通用最优行为，泛化系统动力学可以更好地工作。

    

    本文研究使用Transformer序列模型作为控制的动力学模型(TDMs)。我们在DeepMind控制套件中进行了一系列实验，发现首先，在单环境学习设置中，与基准模型相比，TDMs表现良好。其次，TDMs表现出强大的泛化能力，可以很好地应用于未见过的环境，包括few-shot学习和zero-shot学习。我们进一步证明，相比于直接作为策略通用最优行为，泛化系统动力学可以更好地工作。这使得TDMs成为控制的基础模型中具有很大的潜力的一个重要组成部分。

    We investigate the use of transformer sequence models as dynamics models (TDMs) for control. In a number of experiments in the DeepMind control suite, we find that first, TDMs perform well in a single-environment learning setting when compared to baseline models. Second, TDMs exhibit strong generalization capabilities to unseen environments, both in a few-shot setting, where a generalist model is fine-tuned with small amounts of data from the target environment, and in a zero-shot setting, where a generalist model is applied to an unseen environment without any further training. We further demonstrate that generalizing system dynamics can work much better than generalizing optimal behavior directly as a policy. This makes TDMs a promising ingredient for a foundation model of control.
    
[^26]: RobustFair: 通过公平混淆定向梯度搜索的敌对评估

    RobustFair: Adversarial Evaluation through Fairness Confusion Directed Gradient Search. (arXiv:2305.10906v1 [cs.LG])

    [http://arxiv.org/abs/2305.10906](http://arxiv.org/abs/2305.10906)

    本论文提出了一种基于公平混淆定向梯度搜索的谐波评估方法RobustFair，可以识别与虚假公平相结合的鲁棒性缺陷，提高DNN的鲁棒性和个体公平性。

    

    DNN的可信度经常受到轻微敌对扰动的挑战，这不仅会破坏预测准确性（鲁棒性）而且可能为类似的输入导致有偏预测（个体公平性）。最近提出了准确公正度来强制实施准确性和个体公平之间的谐和平衡。它引入了公平混淆矩阵的概念来将预测分类为真正公平、真正有偏、假正公平和假有偏。本文提出了一种谐波评估方法RobustFair，使用通过公平混淆定向梯度搜索制作的敌对扰动，对DNN的准确公正性进行评估。通过使用Taylor展开来近似敌对实例的基本真实性，RobustFair可以特别识别与虚假公平纠缠在一起的鲁棒性缺陷，这通常在鲁棒性评估中难以捉摸，在个体公平评估中缺失。RobustFair可以提高鲁棒性和个体公平性。

    The trustworthiness of DNNs is often challenged by their vulnerability to minor adversarial perturbations, which may not only undermine prediction accuracy (robustness) but also cause biased predictions for similar inputs (individual fairness). Accurate fairness has been recently proposed to enforce a harmonic balance between accuracy and individual fairness. It induces the notion of fairness confusion matrix to categorize predictions as true fair, true biased, false fair, and false biased. This paper proposes a harmonic evaluation approach, RobustFair, for the accurate fairness of DNNs, using adversarial perturbations crafted through fairness confusion directed gradient search. By using Taylor expansions to approximate the ground truths of adversarial instances, RobustFair can particularly identify the robustness defects entangled for spurious fairness, which are often elusive in robustness evaluation, and missing in individual fairness evaluation. RobustFair can boost robustness and 
    
[^27]: 领域自适应的口咽器官sim-to-real分割

    Domain Adaptive Sim-to-Real Segmentation of Oropharyngeal Organs. (arXiv:2305.10883v1 [cs.AI])

    [http://arxiv.org/abs/2305.10883](http://arxiv.org/abs/2305.10883)

    该研究提出了一种称为IRB-AF的领域自适应的图像分割框架，通过使用IRB和ArtFlow方法来解决口咽器官图像分割中的数据域差异问题，有效提高了分割性能。

    

    视频辅助下的经口气管插管需要使用支持医生将气管导管插入声门而不是食管的内窥镜。越来越多基于机器人的气管插管需要医疗机器人像经验丰富的医生一样区分解剖特征，这可以通过使用监督深度学习技术来模仿。然而口咽器官的真实数据集往往由于开源数据受限和患者隐私问题而难以获取。在本研究中，我们提出了一种领域自适应的Sim-to-Real框架，称为IoU-Ranking Blend-ArtFlow (IRB-AF)，用于口咽器官的图像分割。该框架包括一种称为IoU-Ranking Blend (IRB)的图像融合策略和风格转移方法ArtFlow。其中，IRB通过减轻数据集之间重要的领域差异所导致的实现分割性能差的问题。而ArtFlow则可进一步降低数据集之间的差异性。 本研究采用一种虚拟口咽模型进行实验，结果表明提出的方法可以取得非常好的口咽器官分割效果。

    Video-assisted transoral tracheal intubation (TI) necessitates using an endoscope that helps the physician insert a tracheal tube into the glottis instead of the esophagus. The growing trend of robotic-assisted TI would require a medical robot to distinguish anatomical features like an experienced physician which can be imitated by utilizing supervised deep-learning techniques. However, the real datasets of oropharyngeal organs are often inaccessible due to limited open-source data and patient privacy. In this work, we propose a domain adaptive Sim-to-Real framework called IoU-Ranking Blend-ArtFlow (IRB-AF) for image segmentation of oropharyngeal organs. The framework includes an image blending strategy called IoU-Ranking Blend (IRB) and style-transfer method ArtFlow. Here, IRB alleviates the problem of poor segmentation performance caused by significant datasets domain differences; while ArtFlow is introduced to reduce the discrepancies between datasets further. A virtual oropharynx i
    
[^28]: 多智能体强化学习中的语义对齐任务分解

    Semantically Aligned Task Decomposition in Multi-Agent Reinforcement Learning. (arXiv:2305.10865v1 [cs.LG])

    [http://arxiv.org/abs/2305.10865](http://arxiv.org/abs/2305.10865)

    该论文提出了一种多智能体强化学习中的新方法SAMA，通过提前训练的语言模型和任务分解来解决ASG方法存在的样本效率问题和生成非实际任务奖励的子目标的问题。

    

    合作型MARL中的奖励稀疏问题着重于适当的信用分配。自动子目标生成（ASG）是最近出现的一种可行的MARL方法，其灵感来自于在内在驱动的增强学习中利用子目标。然而，从稀疏奖励中进行复杂任务规划的端到端学习无疑需要大量的培训样本。为了解决这个问题，我们提出了一种新的"解耦"决策方法，即在MARL中的语义对齐任务分解（SAMA），受到解耦表示学习的启发。

    The difficulty of appropriately assigning credit is particularly heightened in cooperative MARL with sparse reward, due to the concurrent time and structural scales involved. Automatic subgoal generation (ASG) has recently emerged as a viable MARL approach inspired by utilizing subgoals in intrinsically motivated reinforcement learning. However, end-to-end learning of complex task planning from sparse rewards without prior knowledge, undoubtedly requires massive training samples. Moreover, the diversity-promoting nature of existing ASG methods can lead to the "over-representation" of subgoals, generating numerous spurious subgoals of limited relevance to the actual task reward and thus decreasing the sample efficiency of the algorithm. To address this problem and inspired by the disentangled representation learning, we propose a novel "disentangled" decision-making method, Semantically Aligned task decomposition in MARL (SAMA), that prompts pretrained language models with chain-of-thou
    
[^29]: Quiver: 基于工作负载感知的低延迟、高吞吐量的 GNN 服务支持 GPU

    Quiver: Supporting GPUs for Low-Latency, High-Throughput GNN Serving with Workload Awareness. (arXiv:2305.10863v1 [cs.DC])

    [http://arxiv.org/abs/2305.10863](http://arxiv.org/abs/2305.10863)

    Quiver 是一种分布式基于 GPU 的 GNN 服务系统，通过利用工作负载指标来预测 GNN 请求的不规则计算，并管理 GPU 用于图采样和特征聚合的优化方法，实现了低延迟和高吞吐量，比现有系统性能提高多达 15x。

    

    面向图神经网络 (GNN) 的推理服务系统必须在低延迟和高吞吐量之间取得平衡，但由于采样的图节点和聚合的 GNN 特征存在偏差，系统面临不规则计算的挑战。这使得有效利用 GPU 变得具有挑战性：仅使用 GPU 对少量图节点进行采样的性能低于基于 CPU 的采样；而对许多特征进行聚合会产生 GPU 和 CPU 之间的高数据移动成本。因此，目前的 GNN 服务系统使用 CPU 进行图采样和特征聚合，限制了吞吐量。我们描述了 Quiver，一种分布式基于 GPU 的 GNN 服务系统，具有低延迟和高吞吐量。Quiver 的关键思路是利用工作负载指标来预测 GNN 请求的不规则计算，并管理 GPU 用于图采样和特征聚合：(1) 对于图采样，Quiver 计算概率采样的图大小，这是一种预测图节点采样并行度的指标；(2) 对于特征聚合，Quiver 采用列求和的方式消除数据移动成本。我们的评估表明，Quiver 在实现 94％ 的 GPU 利用率的同时，比现有的 GNN 服务系统性能提高了多达 15 倍。

    Systems for serving inference requests on graph neural networks (GNN) must combine low latency with high throughout, but they face irregular computation due to skew in the number of sampled graph nodes and aggregated GNN features. This makes it challenging to exploit GPUs effectively: using GPUs to sample only a few graph nodes yields lower performance than CPU-based sampling; and aggregating many features exhibits high data movement costs between GPUs and CPUs. Therefore, current GNN serving systems use CPUs for graph sampling and feature aggregation, limiting throughput.  We describe Quiver, a distributed GPU-based GNN serving system with low-latency and high-throughput. Quiver's key idea is to exploit workload metrics for predicting the irregular computation of GNN requests, and governing the use of GPUs for graph sampling and feature aggregation: (1) for graph sampling, Quiver calculates the probabilistic sampled graph size, a metric that predicts the degree of parallelism in graph
    
[^30]: 非确定性近似算子：极限算子、半平衡语义和聚合（完整版）

    Non-deterministic approximation operators: ultimate operators, semi-equilibrium semantics and aggregates (full version). (arXiv:2305.10846v1 [cs.AI])

    [http://arxiv.org/abs/2305.10846](http://arxiv.org/abs/2305.10846)

    本文研究了非确定性近似算子的极限近似、半平衡语义的代数公式以及带有聚合的不相交逻辑程序的特征。

    

    近似不动点理论（AFT）是研究非单调逻辑语义的抽象和通用代数框架。最近，AFT被推广到非确定性算子，即其范围是元素的集合而不是单个元素。在本文中，我们对非确定性AFT进行了三个进一步的贡献：（1）我们定义和研究了非确定性算子的极限近似，（2）我们给出了Amendola等人提出的半平衡语义的代数公式，（3）我们将不相交逻辑程序的特征推广到带有聚合的不相交逻辑程序。

    Approximation fixpoint theory (AFT) is an abstract and general algebraic framework for studying the semantics of non-monotonic logics. In recent work, AFT was generalized to non-deterministic operators, i.e.\ operators whose range are sets of elements rather than single elements. In this paper, we make three further contributions to non-deterministic AFT: (1) we define and study ultimate approximations of non-deterministic operators, (2) we give an algebraic formulation of the semi-equilibrium semantics by Amendola, et al., and (3) we generalize the characterisations of disjunctive logic programs to disjunctive logic programs with aggregates.
    
[^31]: X-IQE：利用视觉大语言模型对文本到图像生成进行可解释的图像质量评估

    X-IQE: eXplainable Image Quality Evaluation for Text-to-Image Generation with Visual Large Language Models. (arXiv:2305.10843v1 [cs.CV])

    [http://arxiv.org/abs/2305.10843](http://arxiv.org/abs/2305.10843)

    本文提出了一种名为X-IQE的图像质量评估方法，使用视觉大语言模型对文本到图像生成进行评估，并生成文本解释。它具有区分真实和生成图像、评估文本-图像对齐和评估图像美学等优点，显著增强了深度图像质量评估模型的透明度和可解释性。

    

    本文介绍了一种新颖的可解释的图像质量评估方法，称为X-IQE，它利用视觉大语言模型来评估文本到图像生成方法，通过生成文本解释。X-IQE利用分层思维链（CoT）使MiniGPT-4能够产生自洽、无偏的文本，与人类评估高度相关。它具有多种优点，包括能够区分真实图像和生成图像、评估文本-图像对齐和评估图像美学，而不需要模型训练或微调。与人类评估相比，X-IQE更具成本效益和效率，同时显著增强了深度图像质量评估模型的透明度和可解释性。我们使用主流扩散模型生成的图像验证了我们的方法作为基准的有效性。X-IQE在COCO Caption上表现出与最先进评估方法类似的性能，

    This paper introduces a novel explainable image quality evaluation approach called X-IQE, which leverages visual large language models (LLMs) to evaluate text-to-image generation methods by generating textual explanations. X-IQE utilizes a hierarchical Chain of Thought (CoT) to enable MiniGPT-4 to produce self-consistent, unbiased texts that are highly correlated with human evaluation. It offers several advantages, including the ability to distinguish between real and generated images, evaluate text-image alignment, and assess image aesthetics without requiring model training or fine-tuning. X-IQE is more cost-effective and efficient compared to human evaluation, while significantly enhancing the transparency and explainability of deep image quality evaluation models. We validate the effectiveness of our method as a benchmark using images generated by prevalent diffusion models. X-IQE demonstrates similar performance to state-of-the-art (SOTA) evaluation methods on COCO Caption, while 
    
[^32]: 基于潜在空间的统计推断方法在深度神经网络中的不确定性量化

    Uncertainty Quantification in Deep Neural Networks through Statistical Inference on Latent Space. (arXiv:2305.10840v1 [cs.LG])

    [http://arxiv.org/abs/2305.10840](http://arxiv.org/abs/2305.10840)

    本研究提出了一种利用深度神经网络潜在空间表征进行不确定性量化的方法，该方法可以检测数据点的精确度并帮助自动侦测异常值。

    

    本文提出了一种基于潜在空间表征的算法，通过对深度神经网络所处理数据点的精确度进行评估，来解决当前广泛使用的评估方法“过于自信”的问题。具体地，我们使用了网络能够正确分类的部分训练集所生成的潜在空间表示，并以此建立了能够捕捉预测结果可能性的统计模型。在合成数据集上的测试表明，常用方法一般存在“过于自信”的问题，甚至对训练数据生成分布之外的数据点依然如此。与之相比，我们的方法可以发现精度欠佳的数据点，因此对于异常值的自动侦测是有帮助的。

    Uncertainty-quantification methods are applied to estimate the confidence of deep-neural-networks classifiers over their predictions. However, most widely used methods are known to be overconfident. We address this problem by developing an algorithm that exploits the latent-space representation of data points fed into the network, to assess the accuracy of their prediction. Using the latent-space representation generated by the fraction of training set that the network classifies correctly, we build a statistical model that is able to capture the likelihood of a given prediction. We show on a synthetic dataset that commonly used methods are mostly overconfident. Overconfidence occurs also for predictions made on data points that are outside the distribution that generated the training data. In contrast, our method can detect such out-of-distribution data points as inaccurately predicted, thus aiding in the automatic detection of outliers.
    
[^33]: 《AI写作：图像生成和数字写作的关系》

    AIwriting: Relations Between Image Generation and Digital Writing. (arXiv:2305.10834v1 [cs.AI])

    [http://arxiv.org/abs/2305.10834](http://arxiv.org/abs/2305.10834)

    本论坛讨论了基于AI的文本生成系统和文本到图像生成系统对数字艺术和电子文学领域带来的影响，各种作品都从文学角度考虑，突出了创作过程的交互性。

    

    2022年，基于变形金刚的AI文本生成系统（如GPT-3）和基于AI的文本到图像生成系统（如DALL-E 2和稳定扩散）都取得了指数级的飞跃，无疑正在改变数字艺术和电子文学领域。在本论坛中，一组电子文学作者和理论家考虑这些系统带来的人类创造力新机遇，并展示了他们在过去一年中专门针对这些系统创作的作品，这些作品通过迭代的对话过程转化为视觉表现。这些演示的前提是，这些系统和所生成的作品必须从文学角度考虑，因为它们起源于人类写作。从个人健康危机的视觉回忆录，到互动网页漫画，到基于抽象诗意语言的建筑，再到政治萨。。。

    During 2022, both transformer-based AI text generation sys-tems such as GPT-3 and AI text-to-image generation systems such as DALL-E 2 and Stable Diffusion made exponential leaps forward and are unquestionably altering the fields of digital art and electronic literature. In this panel a group of electronic literature authors and theorists consider new oppor-tunities for human creativity presented by these systems and present new works have produced during the past year that specifically address these systems as environments for literary expressions that are translated through iterative interlocutive processes into visual representations. The premise that binds these presentations is that these systems and the works gener-ated must be considered from a literary perspective, as they originate in human writing. In works ranging from a visual memoir of the personal experience of a health crisis, to interac-tive web comics, to architectures based on abstract poetic language, to political sa
    
[^34]: 情感现象在多模式交互研究中的作用拓展

    Expanding the Role of Affective Phenomena in Multimodal Interaction Research. (arXiv:2305.10827v1 [cs.HC])

    [http://arxiv.org/abs/2305.10827](http://arxiv.org/abs/2305.10827)

    本文分析了多模式交互和情感计算交叉领域的研究，并发现情感现象在研究中的角色非常重要，但仍有一些未被充分研究的领域。

    

    在最近的几十年中，情感计算领域取得了突破性进展，提高了人机和人际互动中的AI系统识别和表达情感现象（如情感和情绪）的能力。本文描述了我们对多模式交互和情感计算交叉领域研究的审查，旨在观察趋势并确定未研究的领域。我们审查了来自多模式交互、情感计算和自然语言处理领域的选择性会议上的超过16000篇论文：ACM国际多模式交互会议、AAAC国际情感计算和智能交互会议、协会计算语言学年会和经验方法自然语言处理会议。我们确定了910篇涉及情感的论文，并展示了我们对这些论文中情感现象作用的分析。我们发现，这些研究的主体...

    In recent decades, the field of affective computing has made substantial progress in advancing the ability of AI systems to recognize and express affective phenomena, such as affect and emotions, during human-human and human-machine interactions. This paper describes our examination of research at the intersection of multimodal interaction and affective computing, with the objective of observing trends and identifying understudied areas. We examined over 16,000 papers from selected conferences in multimodal interaction, affective computing, and natural language processing: ACM International Conference on Multimodal Interaction, AAAC International Conference on Affective Computing and Intelligent Interaction, Annual Meeting of the Association for Computational Linguistics, and Conference on Empirical Methods in Natural Language Processing. We identified 910 affect-related papers and present our analysis of the role of affective phenomena in these papers. We find that this body of resear
    
[^35]: 融合项目相关性的序列推荐系统训练损失函数

    Integrating Item Relevance in Training Loss for Sequential Recommender Systems. (arXiv:2305.10824v1 [cs.IR])

    [http://arxiv.org/abs/2305.10824](http://arxiv.org/abs/2305.10824)

    本文提出了一种融合项目相关性的新型训练损失函数，用于提高序列推荐系统对噪声的鲁棒性和性能。

    

    序列推荐系统是一种受欢迎的推荐系统，它通过学习用户的历史数据来预测用户下一个可能与之交互的项目。然而，用户的交互可能会受到来自帐户共享、不一致的偏好或意外点击等噪声的影响。为了解决这个问题，我们（i）提出了一个考虑多个未来项目的新的评估协议，（ii）引入了一种新的关注相关性的损失函数，用于训练具有多个未来项目的序列推荐系统，以使其对噪声更加鲁棒。我们的关注相关性模型在传统评估协议中提高了NDCG@10约1.2%和HR约0.88%，而在新评估协议中，改进的NDCG@10约1.63%和HR约1.5%。

    Sequential Recommender Systems (SRSs) are a popular type of recommender system that learns from a user's history to predict the next item they are likely to interact with. However, user interactions can be affected by noise stemming from account sharing, inconsistent preferences, or accidental clicks. To address this issue, we (i) propose a new evaluation protocol that takes multiple future items into account and (ii) introduce a novel relevance-aware loss function to train a SRS with multiple future items to make it more robust to noise. Our relevance-aware models obtain an improvement of ~1.2% of NDCG@10 and 0.88% in the traditional evaluation protocol, while in the new evaluation protocol, the improvement is ~1.63% of NDCG@10 and ~1.5% of HR w.r.t the best performing models.
    
[^36]: 当搜索遇见推荐：学习区分搜索表示以用于推荐

    When Search Meets Recommendation: Learning Disentangled Search Representation for Recommendation. (arXiv:2305.10822v1 [cs.IR])

    [http://arxiv.org/abs/2305.10822](http://arxiv.org/abs/2305.10822)

    论文提出了一种基于搜索增强的顺序推荐（SESRec）框架，它利用用户的搜索兴趣进行推荐，通过区分S＆R行为中的相似和不相似表示，使S＆R特征能够更好地发挥其独特的优势。

    

    现代在线服务提供商，如在线购物平台通常提供搜索和推荐（S＆R）服务以满足不同的用户需求。很少有任何有效的手段将来自S＆R服务的用户行为数据结合起来。大多数现有的方法要么仅将S＆R行为单独处理，要么通过聚合两个服务的数据来联合优化它们，忽略了S＆R中用户意图可以有截然不同的事实。在我们的论文中，我们提出了一种基于搜索增强的顺序推荐（SESRec）框架，通过区分S＆R行为中的相似和不相似表示，利用用户的搜索兴趣进行推荐。具体而言，SESRec首先根据用户的查询-项目交互来对齐查询和项目嵌入以计算它们的相似性。然后，使用两个转换器编码器来独立地学习S＆R行为的上下文表示。最后，设计了对比学习任务以学习搜素特征表示和推荐特征表示的相似度距离，使得S＆R特征能够更好地发挥其独特的优势。

    Modern online service providers such as online shopping platforms often provide both search and recommendation (S&R) services to meet different user needs. Rarely has there been any effective means of incorporating user behavior data from both S&R services. Most existing approaches either simply treat S&R behaviors separately, or jointly optimize them by aggregating data from both services, ignoring the fact that user intents in S&R can be distinctively different. In our paper, we propose a Search-Enhanced framework for the Sequential Recommendation (SESRec) that leverages users' search interests for recommendation, by disentangling similar and dissimilar representations within S&R behaviors. Specifically, SESRec first aligns query and item embeddings based on users' query-item interactions for the computations of their similarities. Two transformer encoders are used to learn the contextual representations of S&R behaviors independently. Then a contrastive learning task is designed to 
    
[^37]: 大型语言模型中数值大小比较效应的研究

    Numeric Magnitude Comparison Effects in Large Language Models. (arXiv:2305.10782v1 [cs.AI])

    [http://arxiv.org/abs/2305.10782](http://arxiv.org/abs/2305.10782)

    本研究探究了大型语言模型在数字大小比较上的表现，结果显示，尽管缺乏数字表达，不同架构的语言模型均呈现出惊人的类人表征能力。

    

    大型语言模型(LLMs)并没有区分出文字中的数字，而数字在文本中是普遍存在的。相比之下，神经科学研究对数字和单词有着不同的神经表示。本文旨在从行为角度探究流行的LLMs能够多好地捕捉数字的大小（例如，$4<5$）。以往对LLMs表征能力的研究品评他们是否达到了人类水平，比如在标准测试中整体准确率较高。在这里，我们提出一个与认知科学相关的不同问题：LLMs数字表征与人类语言用户的表现有多接近，他们通常表现出距离、大小和比例效应? 我们依靠一个连接假设将数字单词和数字的模型表示之间的相似性映射到人类反应时间。结果显示，尽管缺乏数字表示，不同架构的语言模型都具有惊人的类人表征能力。

    Large Language Models (LLMs) do not differentially represent numbers, which are pervasive in text. In contrast, neuroscience research has identified distinct neural representations for numbers and words. In this work, we investigate how well popular LLMs capture the magnitudes of numbers (e.g., that $4 < 5$) from a behavioral lens. Prior research on the representational capabilities of LLMs evaluates whether they show human-level performance, for instance, high overall accuracy on standard benchmarks. Here, we ask a different question, one inspired by cognitive science: How closely do the number representations of LLMscorrespond to those of human language users, who typically demonstrate the distance, size, and ratio effects? We depend on a linking hypothesis to map the similarities among the model embeddings of number words and digits to human response times. The results reveal surprisingly human-like representations across language models of different architectures, despite the absen
    
[^38]: 基于语义通信的多模数据自适应编码机制

    Rate-Adaptive Coding Mechanism for Semantic Communications With Multi-Modal Data. (arXiv:2305.10773v1 [eess.SP])

    [http://arxiv.org/abs/2305.10773](http://arxiv.org/abs/2305.10773)

    本文提出了基于语义通信的多模数据自适应编码机制，采用NN-based语义编码器和解码器来提取不同模态中包含的相关语义信息，具有广泛应用前景。

    

    近年来，多模通信系统对带宽的需求不断增加，需要一种新的思路。基于深度学习的语义通信被应用于多模场景中，以提高通信效率和节省通信资源。然而，不带信道编码器/解码器的现有端到端神经网络（NN）框架与现代数字通信系统不兼容。大多数端到端设计是针对特定任务的，需要为新任务重新设计和重新训练，这限制了它们的应用。本文提出了一种分布式多模语义通信框架，其中包括传统的信道编码器/解码器。我们采用基于NN的语义编码器和解码器来提取不同模态（包括语音、文本和图像）中包含的相关语义信息。基于所提出的框架，我们进一步建立了一种适用于各种类型的多模自适应编码机制。

    Recently, the ever-increasing demand for bandwidth in multi-modal communication systems requires a paradigm shift. Powered by deep learning, semantic communications are applied to multi-modal scenarios to boost communication efficiency and save communication resources. However, the existing end-to-end neural network (NN) based framework without the channel encoder/decoder is incompatible with modern digital communication systems. Moreover, most end-to-end designs are task-specific and require re-design and re-training for new tasks, which limits their applications. In this paper, we propose a distributed multi-modal semantic communication framework incorporating the conventional channel encoder/decoder. We adopt NN-based semantic encoder and decoder to extract correlated semantic information contained in different modalities, including speech, text, and image. Based on the proposed framework, we further establish a general rate-adaptive coding mechanism for various types of multi-modal
    
[^39]: 对抗修改是将敌人转化为朋友的唯一力量。

    Adversarial Amendment is the Only Force Capable of Transforming an Enemy into a Friend. (arXiv:2305.10766v1 [cs.AI])

    [http://arxiv.org/abs/2305.10766](http://arxiv.org/abs/2305.10766)

    本文提出了一种对抗修改 (AdvAmd) 方法，该方法可以改善神经网络模型的准确性并提高其在良性样本上的原始准确性水平。

    

    对抗攻击通常被认为对神经网络具有误导行为造成了巨大的威胁。本文提出了一种相反的观点：如果修改得当，对抗攻击可以用来改善神经模型。与旨在提高对抗鲁棒性的传统对抗防御或对抗训练方案不同，所提出的对抗修改（AdvAmd）方法旨在提高神经模型在良性样本上的原始准确性水平。我们深入分析了良性和对抗样本之间的分布不匹配。这种分布不匹配和与先前的防御策略应用相同的学习比率的相互学习机制是导致良性样本准确度下降的主要原因。所提出的AdvAmd被证明可以稳定地恢复准确度下降，甚至提高常见神经模型在良性分类、物体检测和分割任务上的准确性。

    Adversarial attack is commonly regarded as a huge threat to neural networks because of misleading behavior. This paper presents an opposite perspective: adversarial attacks can be harnessed to improve neural models if amended correctly. Unlike traditional adversarial defense or adversarial training schemes that aim to improve the adversarial robustness, the proposed adversarial amendment (AdvAmd) method aims to improve the original accuracy level of neural models on benign samples. We thoroughly analyze the distribution mismatch between the benign and adversarial samples. This distribution mismatch and the mutual learning mechanism with the same learning ratio applied in prior art defense strategies is the main cause leading the accuracy degradation for benign samples. The proposed AdvAmd is demonstrated to steadily heal the accuracy degradation and even leads to a certain accuracy boost of common neural models on benign classification, object detection, and segmentation tasks. The eff
    
[^40]: 受物理启发的方法理解高斯过程

    Physics Inspired Approaches Towards Understanding Gaussian Processes. (arXiv:2305.10748v1 [cs.LG])

    [http://arxiv.org/abs/2305.10748](http://arxiv.org/abs/2305.10748)

    本文利用物理学方法分析了高斯过程模型的损失景观，提出了考虑更广泛的ν使得性能更佳的优化方法，同时提供了一种用于评估GP集成效果的方法和基于损失领域的物理属性的投票方法。

    

    通过内核可以将先验有关潜在函数的信念纳入高斯过程(GP)中以形成归纳偏置，但除了内核选择外，GP模型的决策过程仍然很难理解。本文利用物理学方法对GP模型的损失景观进行了分析，演示了Matern内核的ν连续性，并概述了梯度场关键点的灾变理论方面。通过将ν直接包含在Matern内核的超参数优化中，我们发现，尽管在文献中ν的典型值增加了计算速度，但其在性能方面远非最佳。我们还提供了一种事先评估GP集合效果的方法，并讨论了基于损失景观物理属性的各种投票方法。这些方法的实用性在多种合成和真实数据集上得到了证明。我们的发现提供了对GP模型决策过程的深入理解，并为超参数优化和模型选择提供了新的洞察。

    Prior beliefs about the latent function to shape inductive biases can be incorporated into a Gaussian Process (GP) via the kernel. However, beyond kernel choices, the decision-making process of GP models remains poorly understood. In this work, we contribute an analysis of the loss landscape for GP models using methods from physics. We demonstrate $\nu$-continuity for Matern kernels and outline aspects of catastrophe theory at critical points in the loss landscape. By directly including $\nu$ in the hyperparameter optimisation for Matern kernels, we find that typical values of $\nu$ are far from optimal in terms of performance, yet prevail in the literature due to the increased computational speed. We also provide an a priori method for evaluating the effect of GP ensembles and discuss various voting approaches based on physical properties of the loss landscape. The utility of these approaches is demonstrated for various synthetic and real datasets. Our findings provide an enhanced und
    
[^41]: 深度时间图聚类

    Deep Temporal Graph Clustering. (arXiv:2305.10738v1 [cs.LG])

    [http://arxiv.org/abs/2305.10738](http://arxiv.org/abs/2305.10738)

    提出通用框架TGC 用于 deep temporal graph clustering, 解决了时间图只能作为静态图处理的难题，实现了对动态信息的聚类。实验证明了 TGC 的优越性。

    

    最近深度图聚类已经引起了很多关注，因为它可以增强模型在无监督场景下的表示学习能力。然而，适用于时间图的深度聚类方法 - 可以捕获关键的动态交互信息，并没有得到充分的探索。这意味着在许多面向聚类的现实场景中，时间图只能作为静态图来处理。这不仅导致了动态信息的丢失，也引发了巨大的计算消耗。为了解决这个问题，我们提出了一个名为TGC的通用框架，用于时间图深度聚类，它调整了深度聚类技术（聚类分配分布和邻接矩阵重构），以适应时间图基于交互序列的批处理模式。此外，我们还从几个方面讨论了时间图聚类与现有静态图聚类的差异。实验证明了TGC的卓越性能。

    Deep graph clustering has recently received significant attention due to its ability to enhance the representation learning capabilities of models in unsupervised scenarios. Nevertheless, deep clustering for temporal graphs, which could capture crucial dynamic interaction information, has not been fully explored. It means that in many clustering-oriented real-world scenarios, temporal graphs can only be processed as static graphs. This not only causes the loss of dynamic information but also triggers huge computational consumption. To solve the problem, we propose a general framework for deep Temporal Graph Clustering called TGC, which adjusts deep clustering techniques (clustering assignment distribution and adjacency matrix reconstruction) to suit the interaction sequence-based batch-processing pattern of temporal graphs. In addition, we discuss differences between temporal graph clustering and existing static graph clustering from several levels. To verify the superiority of the pro
    
[^42]: 对生成事实一致性文本摘要进行反事实偏差校正

    Counterfactual Debiasing for Generating Factually Consistent Text Summaries. (arXiv:2305.10736v1 [cs.CL])

    [http://arxiv.org/abs/2305.10736](http://arxiv.org/abs/2305.10736)

    本文提出了一个名为CoFactSum的去偏框架，通过反事实估计减轻原因，解决了生成文本摘要的事实不一致性问题，并在两个广泛使用的数据集上取得了优于现有模型的效果。

    

    尽管在生成流畅且信息丰富的文本摘要方面已经取得了实质性的进展，但所生成摘要的事实不一致性仍然是一个重要而具有挑战性的问题。本文针对抽象文本摘要构建因果图，并确定了造成事实不一致性的内在原因，即语言偏见和无关性偏见，并进一步提出了一个名为CoFactSum的去偏框架，通过反事实估计减轻这些偏差的因果影响。具体而言，所提出的CoFactSum提供了两种反事实估计策略，即明确反事实遮蔽具有明确的动态遮蔽策略，并采用隐式鉴别交叉关注机制的隐式反事实训练。同时，我们设计了一个去偏度调整机制，在每个解码步骤动态适应去偏程度。对两个广泛使用的摘要数据集的广泛实验证明了CoFactSum有效地减少了事实不一致性，并优于现有的最新的摘要模型。

    Despite substantial progress in abstractive text summarization to generate fluent and informative texts, the factual inconsistency in the generated summaries remains an important yet challenging problem to be solved. In this paper, we construct causal graphs for abstractive text summarization and identify the intrinsic causes of the factual inconsistency, i.e., the language bias and irrelevancy bias, and further propose a debiasing framework, named CoFactSum, to alleviate the causal effects of these biases by counterfactual estimation. Specifically, the proposed CoFactSum provides two counterfactual estimation strategies, i.e., Explicit Counterfactual Masking with an explicit dynamic masking strategy, and Implicit Counterfactual Training with an implicit discriminative cross-attention mechanism. Meanwhile, we design a Debiasing Degree Adjustment mechanism to dynamically adapt the debiasing degree at each decoding step. Extensive experiments on two widely-used summarization datasets dem
    
[^43]: 环境技术与智能

    Ambient Technology & Intelligence. (arXiv:2305.10726v1 [cs.AI])

    [http://arxiv.org/abs/2305.10726](http://arxiv.org/abs/2305.10726)

    本篇论文探讨了环境技术和智能如何改善残疾人的护理需求及生活质量。

    

    如今，我们有年轻人和老年人、有特殊需求的人以及可以自理的人混合在一起。全球有超过10亿估计有残疾的人，占世界人口的约15％，其中15岁及以上的人口占3.8％（组织，2011）。患有残疾的人数因慢性健康状况等因素而上升。这些和其他因素使得当今社会急需适当的护理设施。建立了几个护理设施来帮助残疾人过上日常生活，不会被社区排除在外。

    Today, we have a mixture of young and older individuals, people with special needs, and people who can care for themselves. Over 1 billion people are estimated to be disabled; this figure corresponds to about 15% of the world's population, with 3.8% (approximately 190 million people) accounting for people aged 15 and up (Organization, 2011). The number of people with disabilities is upward due to the increase in chronic health conditions and many other things. These and other factors have made the need for proper care facilities urgent in today's society. Several care facilities are built to help people with disabilities live their everyday lives and not be left out of the community.
    
[^44]: 通过混合提示正则化无需训练即可分割任何异常

    Segment Any Anomaly without Training via Hybrid Prompt Regularization. (arXiv:2305.10724v1 [cs.CV])

    [http://arxiv.org/abs/2305.10724](http://arxiv.org/abs/2305.10724)

    本文提出了SAA+框架，采用混合提示正则化技术进行零样本异常分割，并在多个基准数据集上取得了最先进的性能。

    

    我们提出了一个新的框架，即“Segment Any Anomaly + (SAA+)”，采用混合提示正则化技术进行零样本异常分割，以提高现代基础模型的适应性。现有的异常分割模型通常依赖于领域特定的微调，限制了它们在无数异常模式之间的泛化能力。在本工作中，我们首先探索了基础模型的零样本泛化能力，利用不同的多模态先验知识进行异常定位。为了使基础模型适应于异常分割，我们进一步引入了基于领域专家知识和目标图像上下文的混合提示作为正则化项。我们的SAA+模型在包括VisA、MVTec-AD、MTD和KSDD2在内的多个零样本异常分割基准数据集上取得了最先进的性能。我们将在\href{https://github.com/caoyunkang/Segment-Any-An}{https://github.com/caoyunkang/Segment-Any-An}发布代码。

    We present a novel framework, i.e., Segment Any Anomaly + (SAA+), for zero-shot anomaly segmentation with hybrid prompt regularization to improve the adaptability of modern foundation models. Existing anomaly segmentation models typically rely on domain-specific fine-tuning, limiting their generalization across countless anomaly patterns. In this work, inspired by the great zero-shot generalization ability of foundation models like Segment Anything, we first explore their assembly to leverage diverse multi-modal prior knowledge for anomaly localization. For non-parameter foundation model adaptation to anomaly segmentation, we further introduce hybrid prompts derived from domain expert knowledge and target image context as regularization. Our proposed SAA+ model achieves state-of-the-art performance on several anomaly segmentation benchmarks, including VisA, MVTec-AD, MTD, and KSDD2, in the zero-shot setting. We will release the code at \href{https://github.com/caoyunkang/Segment-Any-An
    
[^45]: 重新审视长期时间序列预测：线性映射的探究

    Revisiting Long-term Time Series Forecasting: An Investigation on Linear Mapping. (arXiv:2305.10721v1 [cs.LG])

    [http://arxiv.org/abs/2305.10721](http://arxiv.org/abs/2305.10721)

    本文证明了线性映射在长期时间序列预测中的重要性，提出了RevIN和CI的方法来提高预测性能，同时发现线性映射可以有效地捕捉时间序列的周期特征。

    

    近年来，长期时间序列预测受到了越来越多的关注。虽然有各种专门设计来捕捉时间依赖性的方法，但是先前的研究表明，与其他复杂的架构相比，单个线性层可以实现竞争性的预测性能。本文彻底研究了最近方法的内在有效性，并得出了三个主要结论：1）线性映射对于先前的长期时间序列预测至关重要；2）RevIN（可逆规范化）和CI（通道独立）在提高总体预测性能方面发挥重要作用；3）当增加输入视野时，线性映射能够有效捕捉时间序列的周期特征，并具有对不同通道不同周期的鲁棒性。我们提供了理论和实验解释来支持我们的发现，并讨论了局限性和未来工作。我们框架的代码可在\url{https://git}中获得。

    Long-term time series forecasting has gained significant attention in recent years. While there are various specialized designs for capturing temporal dependency, previous studies have demonstrated that a single linear layer can achieve competitive forecasting performance compared to other complex architectures. In this paper, we thoroughly investigate the intrinsic effectiveness of recent approaches and make three key observations: 1) linear mapping is critical to prior long-term time series forecasting efforts; 2) RevIN (reversible normalization) and CI (Channel Independent) play a vital role in improving overall forecasting performance; and 3) linear mapping can effectively capture periodic features in time series and has robustness for different periods across channels when increasing the input horizon. We provide theoretical and experimental explanations to support our findings and also discuss the limitations and future works. Our framework's code is available at \url{https://git
    
[^46]: 时间序列预训练模型综述

    A Survey on Time-Series Pre-Trained Models. (arXiv:2305.10716v1 [cs.LG])

    [http://arxiv.org/abs/2305.10716](http://arxiv.org/abs/2305.10716)

    本综述全面回顾了时间序列预训练模型，其中监督、无监督和自监督是主要类别。通过使用这些模型，可以克服构建大规模标记数据集的困难，提高时间序列挖掘的性能和效率。

    

    时间序列挖掘是一个重要的研究领域，因为它在实际应用中显示出巨大的潜力。依赖于大量标记数据的深度学习模型已经成功地用于时间序列挖掘。然而，由于数据注释成本的原因，构建大规模、良好标记的数据集是困难的。最近，预训练模型在时间序列领域逐渐引起关注，因为它们在计算机视觉和自然语言处理方面表现出色。在本综述中，我们全面回顾了时间序列预训练模型（TS-PTMs），旨在指导了解、应用和研究TS-PTMs。具体而言，我们先简要介绍了TSM中使用的典型深度学习模型。然后，我们根据预训练技术概述了TS-PTMs。我们探讨的主要类别包括监督、无监督和自监督TS-PTMs。此外，进行了广泛的实验来分析它们的优缺点。

    Time-Series Mining (TSM) is an important research area since it shows great potential in practical applications. Deep learning models that rely on massive labeled data have been utilized for TSM successfully. However, constructing a large-scale well-labeled dataset is difficult due to data annotation costs. Recently, Pre-Trained Models have gradually attracted attention in the time series domain due to their remarkable performance in computer vision and natural language processing. In this survey, we provide a comprehensive review of Time-Series Pre-Trained Models (TS-PTMs), aiming to guide the understanding, applying, and studying TS-PTMs. Specifically, we first briefly introduce the typical deep learning models employed in TSM. Then, we give an overview of TS-PTMs according to the pre-training techniques. The main categories we explore include supervised, unsupervised, and self-supervised TS-PTMs. Further, extensive experiments are conducted to analyze the advantages and disadvantage
    
[^47]: 基于机器学习的医疗保险决策推荐系统在尼日利亚的应用

    Machine Learning Recommendation System For Health Insurance Decision Making In Nigeria. (arXiv:2305.10708v1 [cs.AI])

    [http://arxiv.org/abs/2305.10708](http://arxiv.org/abs/2305.10708)

    本论文提出了一个基于机器学习的“医疗保险推荐系统”，采用基于内容的方法，通过地点和价格筛选医疗管理组织（HMO）的数据，并推荐相似服务的前三个HMO，旨在帮助尼日利亚人方便地找到最适合他们的健康保险计划。

    

    在尼日利亚，健康保险的普及率很低，提高其普及度的重要步骤包括提高意识、获取信息和支持决策的工具。基于人工智能的推荐系统已在帮助个人在互联网上找到电影、书籍、音乐和不同类型的产品方面获得了广泛的应用，其中包括医疗保健。本文采用基于内容的方法（基于项目的方法）来构建推荐系统。我们应用了K最近邻（KNN）和余弦相似度算法，经过多次评估和与领域知识的比较，我们选择余弦相似度作为我们的推荐算法。该推荐系统考虑了用户输入的选择，通过地点和价格来筛选医疗管理组织（HMO）的数据，然后推荐相似服务的前三个HMO。本文提出的推荐工具可帮助人们方便地找到和选择最适合他们的健康保险计划。

    The uptake of health insurance has been poor in Nigeria, a significant step to improving this includes improved awareness, access to information and tools to support decision making. Artificial intelligence (AI) based recommender systems have gained popularity in helping individuals find movies, books, music, and different types of products on the internet including diverse applications in healthcare. The content-based methodology (item-based approach) was employed in the recommender system. We applied both the K-Nearest Neighbor (KNN) and Cosine similarity algorithm. We chose the Cosine similarity as our chosen algorithm after several evaluations based of their outcomes in comparison with domain knowledge. The recommender system takes into consideration the choices entered by the user, filters the health management organization (HMO) data by location and chosen prices. It then recommends the top 3 HMOs with closest similarity in services offered. A recommendation tool to help people f
    
[^48]: 超越编码：头脑风暴提升大型语言模型在代码生成中的应用

    Think Outside the Code: Brainstorming Boosts Large Language Models in Code Generation. (arXiv:2305.10679v1 [cs.AI])

    [http://arxiv.org/abs/2305.10679](http://arxiv.org/abs/2305.10679)

    本文介绍了一个名为Brainstorm的框架，利用头脑风暴步骤生成并选择关于问题的不同想法，可显著增强大型语言模型（LLMs）解决竞争级别编程问题的能力，结果在CodeContests基准测试中，ChatGPT的pass@$k$指标增加了50％以上。

    

    代码生成旨在从高级任务规范自动生成源代码，可显着提高软件工程的生产力。最近，基于大型语言模型（LLMs）的方法在简单任务的代码生成能力方面表现出色。然而，生成更复杂任务的代码（如竞争级别的问题）仍然很具有挑战性。在本文中，我们介绍了Brainstorm框架用于代码生成。它利用了一个头脑风暴步骤，生成并选择关于问题的不同想法以促进算法推理，其中这些思考是解决问题的可能蓝图。我们证明Brainstorm显著增强了LLMs解决竞争级别编程问题的能力，在CodeContests基准测试中，ChatGPT的pass@$k$指标增加了50％以上，实现了最先进的性能。此外，我们在LeetCode竞赛中进行的实验表明，o

    Code generation aims to automatically generate source code from high-level task specifications, which can significantly increase productivity of software engineering. Recently, approaches based on large language models (LLMs) have shown remarkable code generation abilities on simple tasks. However, generate code for more complex tasks, such as competition-level problems, remains challenging. In this paper, we introduce Brainstorm framework for code generation. It leverages a brainstorming step that generates and selects diverse thoughts on the problem to facilitate algorithmic reasoning, where the thoughts are possible blueprint of solving the problem. We demonstrate that Brainstorm significantly enhances the ability of LLMs to solve competition-level programming problems, resulting in a more than 50% increase in the pass@$k$ metrics for ChatGPT on the CodeContests benchmark, achieving state-of-the-art performance. Furthermore, our experiments conducted on LeetCode contests show that o
    
[^49]: 少即是多：面向大规模动态图的无监督图剪枝

    Less Can Be More: Unsupervised Graph Pruning for Large-scale Dynamic Graphs. (arXiv:2305.10673v1 [cs.LG])

    [http://arxiv.org/abs/2305.10673](http://arxiv.org/abs/2305.10673)

    本研究提出了一个无监督图剪枝框架，名为STEP，用于解决大规模动态图的训练和部署问题，该框架不需要标签数据，并且具有最先进的剪枝效率和有效性。

    

    大规模图的普及在训练和部署图神经网络（GNN）方面带来了极大的时间和存储挑战。最近的一些研究探索了将大原始图剪枝成一个小而高度信息化的图的解决方案，使得对修剪后的图和大图的训练和推断具有可比性的性能。虽然经验有效，但当前的研究重点是静态或非时间图，这些图对动态场景的直接应用受到限制。此外，它们需要标签作为基本事实来学习信息结构，这限制了它们对标签难以获得的新问题域的适用性。为了解决这个难题，我们提出并研究了针对动态图的无监督图剪枝问题。我们通过我们提出的STEP方法来解决这个问题，这是一个自我监督的时间剪枝框架，它学习从输入的动态图中去除潜在冗余的边缘。从技术和工业的角度来看，我们的方法克服了现有动态图剪枝技术的限制，不需要任何标记数据，并以剪枝效率和有效性方面实现了最先进的性能。

    The prevalence of large-scale graphs poses great challenges in time and storage for training and deploying graph neural networks (GNNs). Several recent works have explored solutions for pruning the large original graph into a small and highly-informative one, such that training and inference on the pruned and large graphs have comparable performance. Although empirically effective, current researches focus on static or non-temporal graphs, which are not directly applicable to dynamic scenarios. In addition, they require labels as ground truth to learn the informative structure, limiting their applicability to new problem domains where labels are hard to obtain. To solve the dilemma, we propose and study the problem of unsupervised graph pruning on dynamic graphs. We approach the problem by our proposed STEP, a self-supervised temporal pruning framework that learns to remove potentially redundant edges from input dynamic graphs. From a technical and industrial viewpoint, our method over
    
[^50]: MetaGAD：学习元转移进行少样本图异常检测

    MetaGAD: Learning to Meta Transfer for Few-shot Graph Anomaly Detection. (arXiv:2305.10668v1 [cs.LG])

    [http://arxiv.org/abs/2305.10668](http://arxiv.org/abs/2305.10668)

    本文提出了一种名为MetaGAD的框架，用于学习从无标记节点到有标记节点之间的元转移知识，以进行少样本图异常检测。

    

    图异常检测长期以来一直是各个领域信息安全问题中的重要问题，如金融欺诈、社会垃圾邮件、网络入侵等。目前大多数现有方法都是以无监督方式执行的，因为标记的异常在大规模情况下往往太昂贵。然而，由于缺乏有关异常的先前知识，可能会将被识别的异常视为数据噪声或不感兴趣的数据实例。在现实场景中，通常可获取有限的标记异常，这些标记异常具有推进图异常检测的巨大潜力。然而，探索少量标记异常和大量无标记节点来检测异常的工作相当有限。因此，本文研究了少样本图异常检测的新问题。我们提出了一种新的框架MetaGAD，学习元转移知识来进行图异常检测。实

    Graph anomaly detection has long been an important problem in various domains pertaining to information security such as financial fraud, social spam, network intrusion, etc. The majority of existing methods are performed in an unsupervised manner, as labeled anomalies in a large scale are often too expensive to acquire. However, the identified anomalies may turn out to be data noises or uninteresting data instances due to the lack of prior knowledge on the anomalies. In realistic scenarios, it is often feasible to obtain limited labeled anomalies, which have great potential to advance graph anomaly detection. However, the work exploring limited labeled anomalies and a large amount of unlabeled nodes in graphs to detect anomalies is rather limited. Therefore, in this paper, we study a novel problem of few-shot graph anomaly detection. We propose a new framework MetaGAD to learn to meta-transfer the knowledge between unlabeled and labeled nodes for graph anomaly detection. Experimental 
    
[^51]: 基于内容的不受限制的对抗攻击

    Content-based Unrestricted Adversarial Attack. (arXiv:2305.10665v1 [cs.CV])

    [http://arxiv.org/abs/2305.10665](http://arxiv.org/abs/2305.10665)

    该论文提出了一个基于内容的不受限制的对抗攻击框架，可生成高可转移的视觉逼真的对抗性样本，并能有效攻击各种深度神经网络。

    

    通常情况下，不受限制的对抗攻击会操纵图像的语义内容（如颜色或纹理）来创建既有效又逼真的对抗性样本，证明了它们具有欺骗人类感知和深度神经网络的隐蔽性和成功性。然而，当前的作品通常会牺牲不受限制的程度并主观地选择一些图像内容来保证不受限制的对抗样本的逼真性，从而限制了它的攻击性能。为保证对抗样本的逼真性和提高攻击性能，我们提出了一种新的不受限制攻击框架，称为基于内容的不受限制的对抗攻击。通过利用表示自然图像的低维流形将图像映射到流形上，并沿着其对抗方向进行优化。因此，在该框架内，我们实现了基于稳定扩散的对抗内容攻击，并生成了高可转移的逼真的不受限制的对抗性样本，可以有效攻击各种深度神经网络。

    Unrestricted adversarial attacks typically manipulate the semantic content of an image (e.g., color or texture) to create adversarial examples that are both effective and photorealistic, demonstrating their ability to deceive human perception and deep neural networks with stealth and success. However, current works usually sacrifice unrestricted degrees and subjectively select some image content to guarantee the photorealism of unrestricted adversarial examples, which limits its attack performance. To ensure the photorealism of adversarial examples and boost attack performance, we propose a novel unrestricted attack framework called Content-based Unrestricted Adversarial Attack. By leveraging a low-dimensional manifold that represents natural images, we map the images onto the manifold and optimize them along its adversarial direction. Therefore, within this framework, we implement Adversarial Content Attack based on Stable Diffusion and can generate high transferable unrestricted adve
    
[^52]: 基于内部结构约束的遥感图像目标提取方法的涂鸦监督技术

    Scribble-Supervised Target Extraction Method Based on Inner Structure-Constraint for Remote Sensing Images. (arXiv:2305.10661v1 [cs.CV])

    [http://arxiv.org/abs/2305.10661](http://arxiv.org/abs/2305.10661)

    本文提出了一种基于涂鸦注释的弱监督学习方法，在不引入任何辅助模块或额外操作的情况下，通过构建内部结构约束来解决遥感图像目标提取中的稀疏问题，并在实验中证明该方法的优越性。

    

    基于涂鸦注释的弱监督学习在遥感图像目标提取中引起了极大的兴趣，因为涂鸦具有描述曲折物体和手动标注成本低等优点。然而，涂鸦过于稀疏，难以识别对象结构和详细信息，在目标定位和边界描述方面带来了巨大的挑战。为了缓解这些问题，在本文中，我们构建了两种内部结构约束、变形一致性损失和可训练的主动轮廓损失，以及涂鸦约束，通过监督编码器-解码器网络的优化，而不引入任何基于先验线索的辅助模块或额外操作。全面的实验表明，我们的方法优于该领域中的五种最先进的算法。源代码可在 https://github.com/yitongli123/ISC-TE 上获得。

    Weakly supervised learning based on scribble annotations in target extraction of remote sensing images has drawn much interest due to scribbles' flexibility in denoting winding objects and low cost of manually labeling. However, scribbles are too sparse to identify object structure and detailed information, bringing great challenges in target localization and boundary description. To alleviate these problems, in this paper, we construct two inner structure-constraints, a deformation consistency loss and a trainable active contour loss, together with a scribble-constraint to supervise the optimization of the encoder-decoder network without introducing any auxiliary module or extra operation based on prior cues. Comprehensive experiments demonstrate our method's superiority over five state-of-the-art algorithms in this field. Source code is available at https://github.com/yitongli123/ISC-TE.
    
[^53]: 使用语音障碍程度进行口吃症语音识别

    Use of Speech Impairment Severity for Dysarthric Speech Recognition. (arXiv:2305.10659v1 [eess.AS])

    [http://arxiv.org/abs/2305.10659](http://arxiv.org/abs/2305.10659)

    本文提出了一种使用发音障碍严重程度和说话人身份的口吃症语音识别技术，实现了显著的字错率降低。

    

    口吃症语音识别中的关键挑战在于发音障碍严重程度因素与说话人身份等因素所导致的说话人层面的多样性。之前的研究主要集中于使用说话人身份来解决这个问题，而本文提出了一系列新的技术，即：a）多任务训练，包括发音障碍严重预测误差；b）以说话人-障碍程度为重点的辅助特征调整；c）仅针对说话人身份和障碍程度进行的结构化LHUC变换。在UASpeech上进行的实验表明，将额外的语音障碍程度纳入最先进的混合DNN、E2E Conformer和预训练的Wav2vec 2.0 ASR系统中，可以实现显著的字错率（WER）降低，最高可达4.78%（相对于14.03%的WER降低）。使用最佳系统，在UASpeech上可以获得已发布的最低WER为17.82%（对于非常低的可理解性，为51.25%）。

    A key challenge in dysarthric speech recognition is the speaker-level diversity attributed to both speaker-identity associated factors such as gender, and speech impairment severity. Most prior researches on addressing this issue focused on using speaker-identity only. To this end, this paper proposes a novel set of techniques to use both severity and speaker-identity in dysarthric speech recognition: a) multitask training incorporating severity prediction error; b) speaker-severity aware auxiliary feature adaptation; and c) structured LHUC transforms separately conditioned on speaker-identity and severity. Experiments conducted on UASpeech suggest incorporating additional speech impairment severity into state-of-the-art hybrid DNN, E2E Conformer and pre-trained Wav2vec 2.0 ASR systems produced statistically significant WER reductions up to 4.78% (14.03% relative). Using the best system the lowest published WER of 17.82% (51.25% on very low intelligibility) was obtained on UASpeech.
    
[^54]: 通过认知通用模型阐明系统1和系统2

    Clarifying System 1 & 2 through the Common Model of Cognition. (arXiv:2305.10654v1 [cs.AI])

    [http://arxiv.org/abs/2305.10654](http://arxiv.org/abs/2305.10654)

    本文采用计算思维的方法，特别是采用认知通用模型，阐明了Systm-1和System-2的底层机制，消除了对它们的误解并阐明了它们对元认知的影响。

    

    对于Systm-1和System-2的双系统描述面临着越来越多的挑战，指责它们不够精确并且容易引起误解。本文采用Dennett的计算思维方法作为分析工具，特别是采用认知通用模型，从而解决了这些问题。研究结果表明，原本被认为是System-1和System-2特有的特征实际上构成了一个认知属性的谱系。通过将System-1和System-2基于通用模型进行实现，我们的目标是阐明它们的底层机制、消除误解以及阐明它们对元认知的影响。

    There have been increasing challenges to dual-system descriptions of System-1 and System-2, critiquing them as imprecise and fostering misconceptions. We address these issues here by way of Dennett's appeal to use computational thinking as an analytical tool, specifically we employ the Common Model of Cognition. Results show that the characteristics thought to be distinctive of System-1 and System-2 instead form a spectrum of cognitive properties. By grounding System-1 and System-2 in the Common Model we aim to clarify their underlying mechanisms, persisting misconceptions, and implications for metacognition.
    
[^55]: 对高长尾视觉识别中的logit进行高斯形式调整

    Adjusting Logit in Gaussian Form for Long-Tailed Visual Recognition. (arXiv:2305.10648v1 [cs.CV])

    [http://arxiv.org/abs/2305.10648](http://arxiv.org/abs/2305.10648)

    本文提出了一种特征增强方法和两种logit调整方法，用于解决长尾视觉识别中的类别不平衡问题。实验结果表明，该方法在CIFAR和ImageNet长尾数据集上表现优于其他最先进的方法。

    

    现实世界中的数据往往具有长尾分布。对于这种数据，由于难以正确分类尾部类别，深度神经网络的学习变得具有挑战性。在文献中，已有一些方法通过减少分类器偏差来解决这个问题，前提是用长尾数据获得的特征足够代表。然而，我们发现直接在长尾数据上训练会导致不均匀的嵌入空间。也就是说，头类的嵌入空间严重压缩尾类，这对于后续的分类器学习是不利的。因此，本文从特征水平的角度研究了长尾视觉识别问题。我们引入了特征增强来平衡嵌入分布。不同类别的特征以高斯形式具有不同振幅的扰动。基于这些扰动的特征，提出了两种新的logit调整方法来提高尾部类别的准确性。实验结果显示，我们的方法在CIFAR和ImageNet长尾数据集上优于其他最先进的方法。

    It is not uncommon that real-world data are distributed with a long tail. For such data, the learning of deep neural networks becomes challenging because it is hard to classify tail classes correctly. In the literature, several existing methods have addressed this problem by reducing classifier bias provided that the features obtained with long-tailed data are representative enough. However, we find that training directly on long-tailed data leads to uneven embedding space. That is, the embedding space of head classes severely compresses that of tail classes, which is not conducive to subsequent classifier learning. %further improving model performance. This paper therefore studies the problem of long-tailed visual recognition from the perspective of feature level. We introduce feature augmentation to balance the embedding distribution. The features of different classes are perturbed with varying amplitudes in Gaussian form. Based on these perturbed features, two novel logit adjustment
    
[^56]: BioAug：基于条件生成的数据增强方法用于低资源生物医学命名实体识别

    BioAug: Conditional Generation based Data Augmentation for Low-Resource Biomedical NER. (arXiv:2305.10647v1 [cs.CL])

    [http://arxiv.org/abs/2305.10647](http://arxiv.org/abs/2305.10647)

    本文提出了一种基于条件生成的数据增强框架BioAug，用于低资源生物医学命名实体识别。BioAug建立在BART上，通过选择性的屏蔽和知识增强进行训练。实验展示了BioAug在5个基准BioNER数据集上的有效性，且表现优于所有基线。

    

    生物医学命名实体识别(BioNER)是从生物医学文本中识别命名实体的基本任务。由于注释需要高度专业化和专业知识，BioNER 遭受着严重的数据稀缺和缺乏高质量标记数据的困扰。尽管数据增强在低资源命名实体识别方面已经被证明是高效的，但现有的数据增强技术不能为BioNER生成真实且多样化的增强。本文提出了一种新的数据增强框架BioAug，用于低资源BioNER。BioAug建立在BART上，通过选择性的屏蔽和知识增强进行训练，从而解决了一种新的文本重构任务。在训练后，我们进行有条件的生成并在与训练阶段类似的有选择性地损坏文本的条件下生成多样化的增强。我们在5个基准BioNER数据集上展示了BioAug的有效性，并表明BioAug比所有基线都表现更好。

    Biomedical Named Entity Recognition (BioNER) is the fundamental task of identifying named entities from biomedical text. However, BioNER suffers from severe data scarcity and lacks high-quality labeled data due to the highly specialized and expert knowledge required for annotation. Though data augmentation has shown to be highly effective for low-resource NER in general, existing data augmentation techniques fail to produce factual and diverse augmentations for BioNER. In this paper, we present BioAug, a novel data augmentation framework for low-resource BioNER. BioAug, built on BART, is trained to solve a novel text reconstruction task based on selective masking and knowledge augmentation. Post training, we perform conditional generation and generate diverse augmentations conditioning BioAug on selectively corrupted text similar to the training stage. We demonstrate the effectiveness of BioAug on 5 benchmark BioNER datasets and show that BioAug outperforms all our baselines by a signi
    
[^57]: ChatGPT的伦理关注、挑战和诫命

    Ethical ChatGPT: Concerns, Challenges, and Commandments. (arXiv:2305.10646v1 [cs.AI])

    [http://arxiv.org/abs/2305.10646](http://arxiv.org/abs/2305.10646)

    本文针对ChatGPT提出了具体伦理关注点，对其在不同应用中的使用提出了关键挑战，并提出了不同ChatGPT相关方的实用诫命，以促进其伦理使用。

    

    当前，例如ChatGPT这样的大型语言模型正在极大地促进人工智能的普及，特别是在普通民众中。然而，这种聊天机器人模型的开发是为了支持人类之间的自然语言沟通。问题是，它很大程度上是一个“统计相关性机器”（相关性而非因果关系），对于使用AI语言模型（如ChatGPT）存在伦理关注事项，如偏见、隐私和滥用。本文重点概括了ChatGPT的具体伦理关注点，并针对ChatGPT在不同应用中的使用提出了关键挑战。此外，还提出了不同ChatGPT相关方的实用诫命，可以作为检查清单指南，促使ChatGPT的伦理使用。

    Large language models, e.g. ChatGPT are currently contributing enormously to make artificial intelligence even more popular, especially among the general population. However, such chatbot models were developed as tools to support natural language communication between humans. Problematically, it is very much a ``statistical correlation machine" (correlation instead of causality) and there are indeed ethical concerns associated with the use of AI language models such as ChatGPT, such as Bias, Privacy, and Abuse. This paper highlights specific ethical concerns on ChatGPT and articulates key challenges when ChatGPT is used in various applications. Practical commandments for different stakeholders of ChatGPT are also proposed that can serve as checklist guidelines for those applying ChatGPT in their applications. These commandment examples are expected to motivate the ethical use of ChatGPT.
    
[^58]: 增量因果图学习进行在线无监督根本原因分析

    Incremental Causal Graph Learning for Online Unsupervised Root Cause Analysis. (arXiv:2305.10638v1 [cs.LG])

    [http://arxiv.org/abs/2305.10638](http://arxiv.org/abs/2305.10638)

    本文提出了CORAL，一种用于在线无监督根本原因分析的新框架，可以自动触发该过程并增量更新模型，包括三个主要部分：触发点检测，增量因果图学习和基于网络传播的根本原因定位。

    

    根本原因分析（RCA）的任务是分析系统监控数据，以识别系统故障/失效的根本原因。有效的RCA可以大大加速系统故障恢复，并减轻系统损失或财务损失。然而，以前的研究大多集中在开发离线RCA算法上，这通常需要手动启动RCA过程，需要大量时间和数据来训练稳健的模型，然后需要从头开始重新训练新的系统故障。在本文中，我们提出了CORAL，一种新颖的在线RCA框架，可以自动触发RCA过程并增量更新RCA模型。CORAL包括触发点检测、增量解缠因果图学习和基于网络传播的根本原因定位。触发点检测组件旨在自动检测系统状态转换并进行准实时检测。为此，我们开发了一种基于m的在线触发点检测方法。

    The task of root cause analysis (RCA) is to identify the root causes of system faults/failures by analyzing system monitoring data. Efficient RCA can greatly accelerate system failure recovery and mitigate system damages or financial losses. However, previous research has mostly focused on developing offline RCA algorithms, which often require manually initiating the RCA process, a significant amount of time and data to train a robust model, and then being retrained from scratch for a new system fault.  In this paper, we propose CORAL, a novel online RCA framework that can automatically trigger the RCA process and incrementally update the RCA model. CORAL consists of Trigger Point Detection, Incremental Disentangled Causal Graph Learning, and Network Propagation-based Root Cause Localization. The Trigger Point Detection component aims to detect system state transitions automatically and in near-real-time. To achieve this, we develop an online trigger point detection approach based on m
    
[^59]: Tree of Thoughts: 利用大语言模型进行深思熟虑的问题解决

    Tree of Thoughts: Deliberate Problem Solving with Large Language Models. (arXiv:2305.10601v1 [cs.CL])

    [http://arxiv.org/abs/2305.10601](http://arxiv.org/abs/2305.10601)

    本研究提出了一种新的推理框架——思维之树（ToT），可以增强语言模型的问题解决能力，帮助语言模型进行深思熟虑的决策，以及自我评估和全局选择。

    

    语言模型越来越广泛地用于解决各种任务的通用问题，但在推理过程中仍然受限于基于标记、从左到右的决策过程。这意味着在需要探索、战略前瞻或初始决策发挥关键作用的任务中，他们可能会遇到困难。为了克服这些挑战，我们引入了一种新的语言模型推理框架——思维之树（ToT），它将通常用于提示语言模型的思维链方法泛化，并使用一致的文本单位（思维）进行探究，这些思维作为解决问题的中间步骤。思维之树允许语言模型通过考虑多个不同的推理路径和自我评估来进行深思熟虑的决策，并决定下一步的行动，同时在必要时向前或向后跟踪以进行全局选择。我们的实验表明，ToT显著增强了语言模型的解决问题能力。

    Language models are increasingly being deployed for general problem solving across a wide range of tasks, but are still confined to token-level, left-to-right decision-making processes during inference. This means they can fall short in tasks that require exploration, strategic lookahead, or where initial decisions play a pivotal role. To surmount these challenges, we introduce a new framework for language model inference, Tree of Thoughts (ToT), which generalizes over the popular Chain of Thought approach to prompting language models, and enables exploration over coherent units of text (thoughts) that serve as intermediate steps toward problem solving. ToT allows LMs to perform deliberate decision making by considering multiple different reasoning paths and self-evaluating choices to decide the next course of action, as well as looking ahead or backtracking when necessary to make global choices. Our experiments show that ToT significantly enhances language models' problem-solving abil
    
[^60]: Sim-MEES: 用于移动操作机器人在杂乱环境下进行抓取的模块化末端执行器系统数据集

    Sim-MEES: Modular End-Effector System Grasping Dataset for Mobile Manipulators in Cluttered Environments. (arXiv:2305.10580v1 [cs.RO])

    [http://arxiv.org/abs/2305.10580](http://arxiv.org/abs/2305.10580)

    本文介绍了一个包含1550个物体和1100万个机器人抓取标签的大规模合成数据集Sim-MEES，它能在杂乱的环境中通过模块化末端执行器系统提供精确的抓取标签，具有广泛的应用前景。

    

    本文介绍了Sim-MEES：一个包含1550个物体，具有不同的难度级别和物理属性以及1100万个机器人抓取标签的大规模合成数据集，用于在杂乱环境中使用不同的夹爪模式规划机器人抓取。我们的数据集生成过程结合了分析模型和整个杂乱环境的动态模拟，以提供准确的抓取标签。我们对我们提出的用于平行夹爪夹具和吸盘夹具的标记过程进行了详细研究，并与最先进的方法进行了比较，以展示Sim-MEES如何在杂乱环境中提供精确的抓取标签。

    In this paper, we present Sim-MEES: a large-scale synthetic dataset that contains 1,550 objects with varying difficulty levels and physics properties, as well as 11 million grasp labels for mobile manipulators to plan grasps using different gripper modalities in cluttered environments. Our dataset generation process combines analytic models and dynamic simulations of the entire cluttered environment to provide accurate grasp labels. We provide a detailed study of our proposed labeling process for both parallel jaw grippers and suction cup grippers, comparing them with state-of-the-art methods to demonstrate how Sim-MEES can provide precise grasp labels in cluttered environments.
    
[^61]: 微笑女性向下看：审查生成图像 AI 中的代表性和展示性性别偏见

    Smiling Women Pitching Down: Auditing Representational and Presentational Gender Biases in Image Generative AI. (arXiv:2305.10566v1 [cs.CV])

    [http://arxiv.org/abs/2305.10566](http://arxiv.org/abs/2305.10566)

    该研究审查了 DALL-E 2 生成的 15,300 张图像中的两种职业性别偏见，发现它在男性主导领域中低估女性，在女性主导职业中高估女性。此外，DALL-E 2 图像描绘更多带有微笑和向下看的女性，特别是在女性主导的职业中。

    

    生成式 AI 模型，如 DALL-E 2，能够解释文本提示并生成展现人类创造力的高质量图像。尽管公众热情高涨，但对 AI 生成图像中潜在性别偏见的系统审查仍然很少。我们通过检查覆盖 153 个职业的 15,300 张 DALL-E 2 图像中两种职业性别偏见（代表性偏见和展示性偏见）的普遍性，并根据2021年人口普查劳动力统计数据和 Google 图像进行基准测试，来解决此问题。我们的发现揭示了 DALL-E 2 在男性主导领域中低估女性，在女性主导职业中高估女性。此外，DALL-E 2 的图像倾向于描绘更多带有微笑和向下看的女性而不是男性，特别是在女性主导的职业中。我们的计算算法审查研究展示了 DALL-E 2 中更明显的代表性和展示性偏见。

    Generative AI models like DALL-E 2 can interpret textual prompts and generate high-quality images exhibiting human creativity. Though public enthusiasm is booming, systematic auditing of potential gender biases in AI-generated images remains scarce. We addressed this gap by examining the prevalence of two occupational gender biases (representational and presentational biases) in 15,300 DALL-E 2 images spanning 153 occupations, and assessed potential bias amplification by benchmarking against 2021 census labor statistics and Google Images. Our findings reveal that DALL-E 2 underrepresents women in male-dominated fields while overrepresenting them in female-dominated occupations. Additionally, DALL-E 2 images tend to depict more women than men with smiling faces and downward-pitching heads, particularly in female-dominated (vs. male-dominated) occupations. Our computational algorithm auditing study demonstrates more pronounced representational and presentational biases in DALL-E 2 compar
    
[^62]: 对放弃分类器进行反事实比较

    Counterfactually Comparing Abstaining Classifiers. (arXiv:2305.10564v1 [stat.ML])

    [http://arxiv.org/abs/2305.10564](http://arxiv.org/abs/2305.10564)

    本文提出一种新的方法和视角来评估和比较放弃分类器，将放弃预测视为缺失数据。我们定义了放弃分类器的反事实得分，指的是分类器没有放弃预测时的预测性能期望。

    

    放弃分类器可以选择在不确定时放弃对输入的预测。这些分类器在高风险决策问题中越来越受欢迎，因为它们可以保留不确定的预测，以提高其可靠性和安全性。然而，在评估黑盒放弃分类器时，我们缺乏一个原则性的方法来考虑分类器在它的放弃预测上的预测结果。当放射科医生不确定其诊断或当驾驶员在自动驾驶汽车中不注意时，这些缺失的预测结果至关重要。本文引入了一种新的方法和视角来评估和比较放弃分类器，将放弃预测视为缺失数据。我们的评估方法围绕着定义一个放弃分类器的反事实得分，即分类器没有放弃的情况下的预测性能的期望。我们指定了条件... (此处省略)

    Abstaining classifiers have the option to abstain from making predictions on inputs that they are unsure about. These classifiers are becoming increasingly popular in high-stake decision-making problems, as they can withhold uncertain predictions to improve their reliability and safety. When evaluating black-box abstaining classifier(s), however, we lack a principled approach that accounts for what the classifier would have predicted on its abstentions. These missing predictions are crucial when, e.g., a radiologist is unsure of their diagnosis or when a driver is inattentive in a self-driving car. In this paper, we introduce a novel approach and perspective to the problem of evaluating and comparing abstaining classifiers by treating abstentions as missing data. Our evaluation approach is centered around defining the counterfactual score of an abstaining classifier, defined as the expected performance of the classifier had it not been allowed to abstain. We specify the conditions unde
    
[^63]: 探究硬负采样分布对对比知识图谱嵌入的影响

    Investigating the Effect of Hard Negative Sample Distribution on Contrastive Knowledge Graph Embedding. (arXiv:2305.10563v1 [cs.AI])

    [http://arxiv.org/abs/2305.10563](http://arxiv.org/abs/2305.10563)

    本文探究了负采样分布对对比知识图谱嵌入的影响，提出考虑硬度和结构的对比（HaSa）算法，用于去除假负样本，提高知识图谱补全任务的性能。

    

    知识图谱补全任务的成功很大程度上依赖于知识图谱嵌入（KGEs）的质量，它依赖于自监督学习和用负三元组增强数据集。在负采样的对比损失的理论分析和高质量（即硬）负采样的启发式生成之间存在差距。在本文中，我们修改了InfoNCE损失，显式考虑了负采样分布。我们展示了用硬负样本最小化InfoNCE损失可以最大化给定三元组和负三元组之间的KL散度。然而，我们也证明硬负样本会导致假负样本（即错误的事实三元组）并降低下游任务性能。为了解决这个问题，我们提出了一种通过知识图谱的图结构去除假负三元组的新型负采样分布。我们将我们的算法称为考虑硬度和结构的对比（HaSa）算法。

    The success of the knowledge graph completion task heavily depends on the quality of the knowledge graph embeddings (KGEs), which relies on self-supervised learning and augmenting the dataset with negative triples. There is a gap in literature between the theoretical analysis of negative samples on contrastive loss and heuristic generation of quality (i.e., hard) negative triples. In this paper, we modify the InfoNCE loss to explicitly account for the negative sample distribution. We show minimizing InfoNCE loss with hard negatives maximizes the KL-divergence between the given and negative triple embedding. However, we also show that hard negatives can lead to false negatives (i.e., accidentally factual triples) and reduce downstream task performance. To address this issue, we propose a novel negative sample distribution that uses the graph structure of the knowledge graph to remove the false negative triples. We call our algorithm Hardness and Structure-aware (\textbf{HaSa}) contrasti
    
[^64]: 面向城市空中移动的一体化冲突管理：战略需求能力平衡和基于学习的战术冲突解决

    Integrated Conflict Management for UAM with Strategic Demand Capacity Balancing and Learning-based Tactical Deconfliction. (arXiv:2305.10556v1 [cs.AI])

    [http://arxiv.org/abs/2305.10556](http://arxiv.org/abs/2305.10556)

    该论文提出了一种新的框架，将需求能力平衡和强化学习相结合，旨在解决城市空中移动（UAM）中的安全问题。在预处理流量的情况下，强化学习可以实现更好的战术安全分离表现。

    

    城市空中移动（UAM）有可能彻底改变我们日常的交通方式，在城市环境中和周围的专门位置之间快速、有效地运输乘客和货物。然而，在这种新兴交通模式商业化和广泛采用之前，必须保证航空安全，即通过战略和战术排除冲突来安全规避所有飞行器。在模拟中，强化学习已经在航班的战术防护中展示出了有效性。然而，它的表现发现取决于交通密度。在本研究中，我们提出了一种新的框架，将需求能力平衡（DCB）用于战略性冲突管理，强化学习用于战术排除冲突。通过使用DCB将流量预置到适当的密度水平，我们表明强化学习可以为战术安全排除冲突实现更好的性能。我们的结果

    Urban air mobility (UAM) has the potential to revolutionize our daily transportation, offering rapid and efficient deliveries of passengers and cargo between dedicated locations within and around the urban environment. Before the commercialization and adoption of this emerging transportation mode, however, aviation safety must be guaranteed, i.e., all the aircraft have to be safely separated by strategic and tactical deconfliction. Reinforcement learning has demonstrated effectiveness in the tactical deconfliction of en route commercial air traffic in simulation. However, its performance is found to be dependent on the traffic density. In this project, we propose a novel framework that combines demand capacity balancing (DCB) for strategic conflict management and reinforcement learning for tactical separation. By using DCB to precondition traffic to proper density levels, we show that reinforcement learning can achieve much better performance for tactical safety separation. Our results
    
[^65]: 通过反向多智能体强化学习发现集体行为中的个体奖励

    Discovering Individual Rewards in Collective Behavior through Inverse Multi-Agent Reinforcement Learning. (arXiv:2305.10548v1 [cs.LG])

    [http://arxiv.org/abs/2305.10548](http://arxiv.org/abs/2305.10548)

    本论文介绍了一种离线逆向多智能体强化学习算法，通过利用演示，自动发现奖励函数并学习代理的有效策略，用于在复杂动态系统中寻找集体行为中的个体目标。

    

    发现复杂动态系统（例如鱼群和细菌群落）中的集体行为中的个体目标是一个长期的挑战。逆强化学习是解决这一挑战的有效方法，但其在涉及连续状态-动作空间和多个交互代理的动态系统中的适用性受到限制。本研究通过引入一种离线逆向多智能体强化学习算法（IMARL）来解决这一挑战。我们的方法结合了ReF-ER技术和导向成本学习。通过利用演示，我们的算法自动发现奖励函数并学习代理的有效策略。通过广泛的实验，我们证明了所提出的策略捕捉到了提供数据中观察到的行为，并在包括OpenAI gym中的单代理模型和涉及多代理的模型中的问题域中取得了有希望的结果。

    The discovery of individual objectives in collective behavior of complex dynamical systems such as fish schools and bacteria colonies is a long-standing challenge. Inverse reinforcement learning is a potent approach for addressing this challenge but its applicability to dynamical systems, involving continuous state-action spaces and multiple interacting agents, has been limited. In this study, we tackle this challenge by introducing an off-policy inverse multi-agent reinforcement learning algorithm (IMARL). Our approach combines the ReF-ER techniques with guided cost learning. By leveraging demonstrations, our algorithm automatically uncovers the reward function and learns an effective policy for the agents. Through extensive experimentation, we demonstrate that the proposed policy captures the behavior observed in the provided data, and achieves promising results across problem domains including single agent models in the OpenAI gym and multi-agent models of schooling behavior. The pr
    
[^66]: 可计算的基于图诱导的和积网络进行概率图表示学习

    Tractable Probabilistic Graph Representation Learning with Graph-Induced Sum-Product Networks. (arXiv:2305.10544v1 [cs.LG])

    [http://arxiv.org/abs/2305.10544](http://arxiv.org/abs/2305.10544)

    GSPNs是一种新的概率框架，用于图表示学习，可以可计算地回答概率查询，并通过权重共享和树状计算图的优势获得了纯概率模型的效率和深度图网络的效果。

    

    我们介绍了基于图诱导的和积网络 (GSPN)，它是一种新的概率框架，用于图表示学习，可以可计算地回答概率查询。受消息传递神经网络中由顶点引起的计算树的启发，我们建立了一组和积网络（SPN）的层次结构，其中父SPN的参数是其子级的后验混合概率的可学习变换。由于权重共享和GSPN的树状计算图，我们获得了纯概率模型的效率和深度图网络的效果。我们在缺乏监督的情况下，处理缺失数据和图分类问题，证明了该模型相对于流行的神经模型的竞争力。我们通过超参数和模型回答概率查询的能力进行定性分析。

    We introduce Graph-Induced Sum-Product Networks (GSPNs), a new probabilistic framework for graph representation learning that can tractably answer probabilistic queries. Inspired by the computational trees induced by vertices in the context of message-passing neural networks, we build hierarchies of sum-product networks (SPNs) where the parameters of a parent SPN are learnable transformations of the a-posterior mixing probabilities of its children's sum units. Due to weight sharing and the tree-shaped computation graphs of GSPNs, we obtain the efficiency and efficacy of deep graph networks with the additional advantages of a purely probabilistic model. We show the model's competitiveness on scarce supervision scenarios, handling missing data, and graph classification in comparison to popular neural models. We complement the experiments with qualitative analyses on hyper-parameters and the model's ability to answer probabilistic queries.
    
[^67]: 利用Tsetlin Machines从数据中生成贝叶斯网络模型

    Generating Bayesian Network Models from Data Using Tsetlin Machines. (arXiv:2305.10538v1 [cs.AI])

    [http://arxiv.org/abs/2305.10538](http://arxiv.org/abs/2305.10538)

    本文提出一种用Tsetlin Machines从数据中发现贝叶斯网络结构的方法。

    

    贝叶斯网络（BN）是一种有向无环图（DAG）模型，因其透明度、可解释性、概率推理和因果建模的优点而被广泛应用于许多领域。给定一组数据，使用BN的一个难点在于从数据构建网络图，以适当地处理相关或因果依赖关系。在本文中，我们提出了一种使用Tsetlin Machines发现网络结构的初步方法。

    Bayesian networks (BN) are directed acyclic graphical (DAG) models that have been adopted into many fields for their strengths in transparency, interpretability, probabilistic reasoning, and causal modeling. Given a set of data, one hurdle towards using BNs is in building the network graph from the data that properly handles dependencies, whether correlated or causal. In this paper, we propose an initial methodology for discovering network structures using Tsetlin Machines.
    
[^68]: 自学习对话系统中缺陷行为的可扩展和安全修复

    Scalable and Safe Remediation of Defective Actions in Self-Learning Conversational Systems. (arXiv:2305.10528v1 [cs.AI])

    [http://arxiv.org/abs/2305.10528](http://arxiv.org/abs/2305.10528)

    本文提出了一种在自学习对话系统中利用历史回归事件报告来验证、保护和改进政策的方法，以解决在大规模商业环境中的经验连贯性和政策改进之间的平衡问题。

    

    强化学习已成为最新自然语言对话人工智能的驱动力，改善了目标为导向的代理人与人之间更自然的互动，提高了用户的满意度，但在大型商业环境中，平衡政策改进和经验连贯性经常具有挑战性。本文提出了一种方法，即使用历史回归事件报告中的高精度样本对政策进行验证、安全保护和改进，以便在在线部署前进行修正。作者对真实的对话系统和实际的回归事件数据进行了大量实验，并将所提出的方法应用于他们的生产系统中。

    Off-Policy reinforcement learning has been a driving force for the state-of-the-art conversational AIs leading to more natural humanagent interactions and improving the user satisfaction for goal-oriented agents. However, in large-scale commercial settings, it is often challenging to balance between policy improvements and experience continuity on the broad spectrum of applications handled by such system. In the literature, off-policy evaluation and guard-railing on aggregate statistics has been commonly used to address this problem. In this paper, we propose a method for curating and leveraging high-precision samples sourced from historical regression incident reports to validate, safe-guard, and improve policies prior to the online deployment. We conducted extensive experiments using data from a real-world conversational system and actual regression incidents. The proposed method is currently deployed in our production system to protect customers against broken experiences and enable
    
[^69]: ChatGPT在六种低资源语言中延续性别偏见，忽略非性别代词

    ChatGPT Perpetuates Gender Bias in Machine Translation and Ignores Non-Gendered Pronouns: Findings across Bengali and Five other Low-Resource Languages. (arXiv:2305.10510v1 [cs.CY])

    [http://arxiv.org/abs/2305.10510](http://arxiv.org/abs/2305.10510)

    ChatGPT在翻译中延续性别偏见，忽略非性别代词，会将性别中立代词转换为男性或女性，甚至无法将英语中的性别中立代词翻译为其他语言的性别中立代词。

    

    在这个多元文化时代，语言翻译是最常见的任务之一，越来越多地由人工智能进行调节和自动化。作为一种新型的人工智能系统，ChatGPT声称在这样的翻译任务中表现出色，在本文中，我们对这一声明进行了测试。具体而言，我们考察了ChatGPT在英语和仅使用性别中立代词的语言之间进行翻译的准确性。我们以孟加拉语为中心进行了这项研究，孟加拉语是全球第七大使用语言，但我们还概括了我们在波斯语、马来语、塔加洛语、泰语和土耳其语等五种其他语言中的发现。我们发现，ChatGPT延续了对某些职业（例如男人=医生，女人=护士）或行动（女人=烹饪，男人=去工作）赋予性别默认值和刻板印象的偏见，因为它将语言中的性别中立代词转换为“他”或“她”。我们还观察到，ChatGPT完全无法将英语的性别中立代词“they”翻译为其他语言中相应的性别中立代词。

    In this multicultural age, language translation is one of the most performed tasks, and it is becoming increasingly AI-moderated and automated. As a novel AI system, ChatGPT claims to be proficient in such translation tasks and in this paper, we put that claim to the test. Specifically, we examine ChatGPT's accuracy in translating between English and languages that exclusively use gender-neutral pronouns. We center this study around Bengali, the 7$^{th}$ most spoken language globally, but also generalize our findings across five other languages: Farsi, Malay, Tagalog, Thai, and Turkish. We find that ChatGPT perpetuates gender defaults and stereotypes assigned to certain occupations (e.g. man = doctor, woman = nurse) or actions (e.g. woman = cook, man = go to work), as it converts gender-neutral pronouns in languages to `he' or `she'. We also observe ChatGPT completely failing to translate the English gender-neutral pronoun `they' into equivalent gender-neutral pronouns in other languag
    
[^70]: ReasonNet: 具有时间和全局推理的端到端自动驾驶

    ReasonNet: End-to-End Driving with Temporal and Global Reasoning. (arXiv:2305.10507v1 [cs.CV])

    [http://arxiv.org/abs/2305.10507](http://arxiv.org/abs/2305.10507)

    ReasonNet是一种全新的端到端自动驾驶框架，通过同时利用时间和全局信息，可以有效地处理城市密集交通场景下的稀有不利事件，如突然出现的遮挡物体。

    

    自动驾驶车辆的大规模部署尚未实现，其中一个主要的挑战在于城市密集交通场景下的预测和应对稀有不利事件。本文中，我们提出了 ReasonNet，一种新型的端到端驾驶框架，广泛利用驾驶场景的时间和全局信息。通过对物体的时间行为进行推理，我们的方法可以有效地处理不同帧中特征之间的相互作用和关系。推理场景的全局信息也可提高整体感知性能，并有益于检测不利事件，特别是对遮挡物的潜在危险的预测。为了全面评估遮挡事件，我们还公开发布了一个驾驶仿真基准测试 DriveOcclusion。

    The large-scale deployment of autonomous vehicles is yet to come, and one of the major remaining challenges lies in urban dense traffic scenarios. In such cases, it remains challenging to predict the future evolution of the scene and future behaviors of objects, and to deal with rare adverse events such as the sudden appearance of occluded objects. In this paper, we present ReasonNet, a novel end-to-end driving framework that extensively exploits both temporal and global information of the driving scene. By reasoning on the temporal behavior of objects, our method can effectively process the interactions and relationships among features in different frames. Reasoning about the global information of the scene can also improve overall perception performance and benefit the detection of adverse events, especially the anticipation of potential danger from occluded objects. For comprehensive evaluation on occlusion events, we also release publicly a driving simulation benchmark DriveOcclusi
    
[^71]: 无模型鲁棒平均奖励强化学习

    Model-Free Robust Average-Reward Reinforcement Learning. (arXiv:2305.10504v1 [cs.LG])

    [http://arxiv.org/abs/2305.10504](http://arxiv.org/abs/2305.10504)

    本文研究了无模型鲁棒平均奖励马尔可夫决策过程，提出两种算法并证明了它们收敛到最优解。我们给出了几个广泛使用的不确定性集合作为示例。

    

    鲁棒马尔可夫决策过程通过在一个马尔可夫决策过程不确定性集合中优化最坏情况的性能来解决模型不确定性的挑战。本文着眼于无模型情况下的鲁棒平均奖励马尔可夫决策过程。我们首先理论上描述了鲁棒平均奖励Bellman方程的解结构，这对我们后面的收敛分析至关重要。接着，我们设计了两个无模型算法，鲁棒相对价值迭代(TD)和鲁棒RVI Q-learning，并理论上证明了它们收敛到最优解。我们提供了几个广泛使用的不确定性集合的示例，包括污染模型、总变差、卡方散度、KL散度和Wasserstein距离。

    Robust Markov decision processes (MDPs) address the challenge of model uncertainty by optimizing the worst-case performance over an uncertainty set of MDPs. In this paper, we focus on the robust average-reward MDPs under the model-free setting. We first theoretically characterize the structure of solutions to the robust average-reward Bellman equation, which is essential for our later convergence analysis. We then design two model-free algorithms, robust relative value iteration (RVI) TD and robust RVI Q-learning, and theoretically prove their convergence to the optimal solution. We provide several widely used uncertainty sets as examples, including those defined by the contamination model, total variation, Chi-squared divergence, Kullback-Leibler (KL) divergence and Wasserstein distance.
    
[^72]: EENED：基于卷积变压器的端到端神经元癫痫检测

    EENED: End-to-End Neural Epilepsy Detection based on Convolutional Transformer. (arXiv:2305.10502v1 [eess.SP])

    [http://arxiv.org/abs/2305.10502](http://arxiv.org/abs/2305.10502)

    本文提出了一种名为EENED的端到端神经元癫痫检测模型，结合了CNN和Transformer，能够同时捕捉EEG信号的全局依赖性和局部特征，并有望提高癫痫检测的准确性和可靠性。

    

    最近，在EEG信号处理中，基于变压器（Transformer）和卷积神经网络（CNN）的模型表现出了很好的结果。变压器模型可以通过自我注意机制捕捉EEG信号的全局依赖性，而CNN模型可以捕捉如锯齿波之类的局部特征。在本文中，我们提出了一种名为EENED的端到端神经元癫痫检测模型，它结合了CNN和Transformer。具体地，通过在Transformer编码器中引入卷积模块，EENED可以学习患者EEG信号特征的时间依赖关系，并注意到与癫痫密切相关的局部EEG异常突变，如尖锐波的出现和缓慢波的散布。我们提出的框架结合了Transformer和CNN捕捉EEG信号不同尺度的特征的能力，有望提高癫痫检测的准确性和可靠性。我们的源代码将很快在GitHub上发布。

    Recently Transformer and Convolution neural network (CNN) based models have shown promising results in EEG signal processing. Transformer models can capture the global dependencies in EEG signals through a self-attention mechanism, while CNN models can capture local features such as sawtooth waves. In this work, we propose an end-to-end neural epilepsy detection model, EENED, that combines CNN and Transformer. Specifically, by introducing the convolution module into the Transformer encoder, EENED can learn the time-dependent relationship of the patient's EEG signal features and notice local EEG abnormal mutations closely related to epilepsy, such as the appearance of spikes and the sprinkling of sharp and slow waves. Our proposed framework combines the ability of Transformer and CNN to capture different scale features of EEG signals and holds promise for improving the accuracy and reliability of epilepsy detection. Our source code will be released soon on GitHub.
    
[^73]: 融合归因重要性以提高忠实度评估的方法

    Incorporating Attribution Importance for Improving Faithfulness Metrics. (arXiv:2305.10496v1 [cs.CL])

    [http://arxiv.org/abs/2305.10496](http://arxiv.org/abs/2305.10496)

    本研究提出了一种软删除标准来评估归因方法的忠实度，该方法随机遮盖标记的部分向量表示，这种方法比现有的硬删除标准更准确。

    

    特征归因方法是提供对模型推理过程进行预测的流行方法。一个更加准确的归因方法标志着它更加忠实，它可以更加准确地反映哪些部分的输入对预测更加重要。然而，现有的忠实度评估方法，如充分性和全面性，只使用一种硬删除标准，即完全删除或保留由给定归因方法排名最高的顶部标记，并观察预测可能性的变化。因此，这种硬删除标准忽略了每个标记的重要性，把它们全部等同地处理。在本文中，我们提出了一个简单而有效的软删除标准。我们不会完全删除或保留输入中的标记，而是随机地遮盖代表归因方法重要性的部分标记向量表示。基于各种自然语言处理任务和不同的归因方法进行的广泛实验表明，我们的方法显著优于现有的评估方法。

    Feature attribution methods (FAs) are popular approaches for providing insights into the model reasoning process of making predictions. The more faithful a FA is, the more accurately it reflects which parts of the input are more important for the prediction. Widely used faithfulness metrics, such as sufficiency and comprehensiveness use a hard erasure criterion, i.e. entirely removing or retaining the top most important tokens ranked by a given FA and observing the changes in predictive likelihood. However, this hard criterion ignores the importance of each individual token, treating them all equally for computing sufficiency and comprehensiveness. In this paper, we propose a simple yet effective soft erasure criterion. Instead of entirely removing or retaining tokens from the input, we randomly mask parts of the token vector representations proportionately to their FA importance. Extensive experiments across various natural language processing tasks and different FAs show that our sof
    
[^74]: 贝叶斯重整化

    Bayesian Renormalization. (arXiv:2305.10491v1 [hep-th])

    [http://arxiv.org/abs/2305.10491](http://arxiv.org/abs/2305.10491)

    本文提出了一种基于信息论的贝叶斯统计模型的重整化方法，使用Fisher度量定义了一个相关长度作为紧密相关的概率分布点之间的可分辨性(RG)尺度，在统计推断实验中，可以得到某个系统最大特异性观察数量的代理。贝叶斯重整化方法为给定系统准备一个在上述尺度上精度有限的有效模型，这个尺度可以被解释为当前实验装置可以探测到的最大能量。贝叶斯重整化提出了一种发现和表征基本物理理论的新框架。

    

    本文提出了一种完全基于信息论的贝叶斯统计模型的重整化方法，称为贝叶斯重整化。贝叶斯重整化的主要思想是使用Fisher度量来定义一个相关长度，这个长度起到了紧密相关的概率分布点之间的可分辨性(RG)尺度。这个RG尺度可以被解释为在统计推断实验中对于一个给定系统可以得到的最大特异性观察数量的代理。贝叶斯重整化方法的作用是为给定系统准备一个在上述尺度上精度有限的有效模型。在将贝叶斯重整化方法应用于物理系统时，这个由信息论出现的RG尺度自然地被识别为当前实验装置可以探测到的最大能量，因此，贝叶斯重整化提出了一种发现和表征基本物理理论的新框架。

    In this note we present a fully information theoretic approach to renormalization inspired by Bayesian statistical inference, which we refer to as Bayesian Renormalization. The main insight of Bayesian Renormalization is that the Fisher metric defines a correlation length that plays the role of an emergent RG scale quantifying the distinguishability between nearby points in the space of probability distributions. This RG scale can be interpreted as a proxy for the maximum number of unique observations that can be made about a given system during a statistical inference experiment. The role of the Bayesian Renormalization scheme is subsequently to prepare an effective model for a given system up to a precision which is bounded by the aforementioned scale. In applications of Bayesian Renormalization to physical systems, the emergent information theoretic scale is naturally identified with the maximum energy that can be probed by current experimental apparatus, and thus Bayesian Renormali
    
[^75]: 使用 nomogram 和机器学习预测患有肺癌的肺结节患者

    Solitary pulmonary nodules prediction for lung cancer patients using nomogram and machine learning. (arXiv:2305.10466v1 [q-bio.QM])

    [http://arxiv.org/abs/2305.10466](http://arxiv.org/abs/2305.10466)

    本文开发了一个基于计算机断层扫描和生物标志物信息的 nomogram，用于评估患有 8 毫米以下 SPNs 的肺癌的可能性，展示了高准确性和比机器学习模型更好的表现。

    

    肺癌是起源于支气管粘膜或腺体的恶性肿瘤。孤立性肺结节（SPNs）是一种常见的肺部病变，当其直径大于8毫米时，恶性可能性显著增加。但是，当直径小于8毫米时仍有患肺癌的风险，本研究的目的是使用计算机断层扫描（CT）和生物标志物信息为8毫米以下SPNs患者创建一个评估肺癌可能性的 nomogram。年龄、前体胃泌素释放肽（ProGRP）、性别、癌胚抗原（CEA）和应力腐蚀开裂（SCC）是独立的关键肿瘤标志物，被输入到 nomogram 中。该 nomogram 展示了很强的预测肺癌风险的准确性，具有内部验证曲线下面积（AUC）为0.869。与 nomogram 相比，机器学习模型包括逻辑回归、随机森林、梯度提升决策树和支持向量机，应用于比较其预测性能，结果表明 nomogram 具有更好的敏感性和特异性。总之，我们开发了一个 nomogram 来预测8毫米以下的 SPNs 患者的肺癌可能性，显示出高准确性，表现比机器学习模型更好。

    Lung cancer(LC) is a type of malignant neoplasm that originates in the bronchial mucosa or glands.As a clinically common nodule,solitary pulmonary nodules(SPNs) have a significantly higher probability of malignancy when they are larger than 8 mm in diameter.But there is also a risk of lung cancer when the diameter is less than 8mm,the purpose of this study was to create a nomogram for estimating the likelihood of lung cancer in patients with SPNs of 8 mm or smaller using computed tomography(CT) scans and biomarker information.Use CT scans and various biomarkers as input to build predictive models for the likelihood of lung cancer in patients with SPNs of 8 mm or less.The age,precursor gastrin-releasing peptide (ProGRP),gender,Carcinoembryonic Antigen(CEA),and stress corrosion cracking(SCC) were independent key tumor markers and were entered into the nomogram.The developed nomogram demonstrated strong accuracy in predicting lung cancer risk,with an internal validation area under the rec
    
[^76]: 基于旋转拉普拉斯分布的SO(3)稳健概率建模研究

    Towards Robust Probabilistic Modeling on SO(3) via Rotation Laplace Distribution. (arXiv:2305.10465v1 [cs.CV])

    [http://arxiv.org/abs/2305.10465](http://arxiv.org/abs/2305.10465)

    本文提出了一种新的基于旋转拉普拉斯分布的SO(3)稳健概率建模方法，对异常值具有鲁棒性，并可以容忍不完美的注释。

    

    从单张RGB图像估计三维自由旋转是一项重要且具有挑战性的任务。概率旋转建模是一种流行的方法，相对于单预测旋转回归可以额外提供预测不确定性信息。对于SO(3)上的概率分布建模，使用类似于高斯的Bingham分布和矩阵Fisher分布是自然的，但是它们对异常预测很敏感，例如180度误差，因此不太可能以最佳性能收敛。本文从多元拉普拉斯分布中汲取灵感，提出了一种新的SO(3)旋转拉普拉斯分布。我们的旋转拉普拉斯分布对异常值的干扰具有鲁棒性，并强制施加梯度到低误差区域，以改进性能。此外，我们还证明了我们的方法对小噪声具有鲁棒性，因此可以容忍不完美的注释。利用这个优势，我们展示了在半监督回归任务上的优势。

    Estimating the 3DoF rotation from a single RGB image is an important yet challenging problem. As a popular approach, probabilistic rotation modeling additionally carries prediction uncertainty information, compared to single-prediction rotation regression. For modeling probabilistic distribution over SO(3), it is natural to use Gaussian-like Bingham distribution and matrix Fisher, however they are shown to be sensitive to outlier predictions, e.g. $180^\circ$ error and thus are unlikely to converge with optimal performance. In this paper, we draw inspiration from multivariate Laplace distribution and propose a novel rotation Laplace distribution on SO(3). Our rotation Laplace distribution is robust to the disturbance of outliers and enforces much gradient to the low-error region that it can improve. In addition, we show that our method also exhibits robustness to small noises and thus tolerates imperfect annotations. With this benefit, we demonstrate its advantages in semi-supervised r
    
[^77]: 合作是你所需要的。 （arXiv:2305.10449v1 [cs.LG]）

    Cooperation Is All You Need. (arXiv:2305.10449v1 [cs.LG])

    [http://arxiv.org/abs/2305.10449](http://arxiv.org/abs/2305.10449)

    引入了一种基于“本地处理器民主”的算法Cooperator，该算法在强化学习中表现比Transformer算法更好。

    

    在超越“树突民主”之上，我们引入了一个名为Cooperator的“本地处理器民主”。在这里，我们将它们与基于Transformers的机器学习算法（例如ChatGPT）在置换不变神经网络强化学习（RL）中的功能进行比较。 Transformers基于长期以来的“积分-发射”“点”神经元的概念，而Cooperator则受到最近神经生物学突破的启示，这些突破表明，精神生活的细胞基础取决于新皮层中具有两个功能上不同点的上皮神经元。我们表明，当用于RL时，基于Cooperator的算法学习速度比基于Transformer的算法快得多，即使它们具有相同数量的参数。

    Going beyond 'dendritic democracy', we introduce a 'democracy of local processors', termed Cooperator. Here we compare their capabilities when used in permutation-invariant neural networks for reinforcement learning (RL), with machine learning algorithms based on Transformers, such as ChatGPT. Transformers are based on the long-standing conception of integrate-and-fire 'point' neurons, whereas Cooperator is inspired by recent neurobiological breakthroughs suggesting that the cellular foundations of mental life depend on context-sensitive pyramidal neurons in the neocortex which have two functionally distinct points. We show that when used for RL, an algorithm based on Cooperator learns far quicker than that based on Transformer, even while having the same number of parameters.
    
[^78]: 面向视觉文档理解的统一模态掩码序列预训练

    Sequence-to-Sequence Pre-training with Unified Modality Masking for Visual Document Understanding. (arXiv:2305.10448v1 [cs.CL])

    [http://arxiv.org/abs/2305.10448](http://arxiv.org/abs/2305.10448)

    本文提出了一个统一的序列到序列文档理解模型，采用跨三种模态的统一掩码进行预训练，并且结构灵活适应各种下游任务输出格式。模型采用多种任务同时预训练，而且结合分解注意力和模态专家组合策略以提高信息捕获效率。

    

    本文提出了GenDoc，一种通用的序列到序列文档理解模型，使用跨三种模态的统一掩码进行预训练：文本、图像和布局。该模型采用编码器-解码器架构，与文档理解中常用的仅编码器模型相比，能够更好地适应各种产生不同输出格式的下游任务。此外，我们的预训练任务不仅包括以往编码器-解码器模型中使用的传统文本填充任务，还包括屏蔽的图像令牌预测和屏蔽的布局预测。我们设计了模态特定的指导和采用分解注意力和模态专家组合策略，以有效地捕捉每种模态所利用的信息。

    This paper presents GenDoc, a general sequence-to-sequence document understanding model pre-trained with unified masking across three modalities: text, image, and layout. The proposed model utilizes an encoder-decoder architecture, which allows for increased adaptability to a wide range of downstream tasks with diverse output formats, in contrast to the encoder-only models commonly employed in document understanding. In addition to the traditional text infilling task used in previous encoder-decoder models, our pre-training extends to include tasks of masked image token prediction and masked layout prediction. We also design modality-specific instruction and adopt both disentangled attention and the mixture-of-modality-experts strategy to effectively capture the information leveraged by each modality. Evaluation of the proposed model through extensive experiments on several downstream tasks in document understanding demonstrates its ability to achieve superior or competitive performanc
    
[^79]: 神经网络自动化评分中动态损失函数的有效性

    The Effectiveness of a Dynamic Loss Function in Neural Network Based Automated Essay Scoring. (arXiv:2305.10447v1 [cs.CL])

    [http://arxiv.org/abs/2305.10447](http://arxiv.org/abs/2305.10447)

    本研究提出了一种动态损失函数，帮助神经网络自动化评分系统在预测值的同时对正确的分布有更高的预测能力，而不牺牲任何性能。

    

    神经网络和特别是注意力机制为自动化作文评分领域带来了重大进展。许多这些系统使用基于回归的模型，当模型只预测训练数据的平均值时，可能会容易出现欠拟合。在本文中，我们介绍了一种动态损失函数，它为模型创建了一个激励，使其预测正确的分布，同时预测正确的值。我们的损失函数在不降低任何性能的情况下实现了这个目标，在Automated Student Assessment Prize Automated Essay Scoring数据集上实现了0.752的二次加权kappa得分。

    Neural networks and in particular the attention mechanism have brought significant advances to the field of Automated Essay Scoring. Many of these systems use a regression-based model which may be prone to underfitting when the model only predicts the mean of the training data. In this paper, we present a dynamic loss function that creates an incentive for the model to predict with the correct distribution, as well as predicting the correct values. Our loss function achieves this goal without sacrificing any performance achieving a Quadratic Weighted Kappa score of 0.752 on the Automated Student Assessment Prize Automated Essay Scoring dataset.
    
[^80]: 记忆有益：自回归语言模型的加密

    Memorization for Good: Encryption with Autoregressive Language Models. (arXiv:2305.10445v1 [cs.CL])

    [http://arxiv.org/abs/2305.10445](http://arxiv.org/abs/2305.10445)

    该论文提出了第一个使用自回归语言模型进行对称加密的算法（SELM），其中算法可以将任意数据编码为紧凑的实值向量（即加密），然后通过随机子空间优化和贪心解码将向量无损解码为原始消息（即解密），并且SELM在加密分析方面的安全性能较高。

    

    过度参数化的神经语言模型（LM）可以记忆和背诵大量训练数据。虽然这种记忆通常被认为具有不良属性，例如过度拟合和信息泄漏，但我们的工作将记忆视为LM的一种未开发的能力。我们提出了第一个使用自回归语言模型进行对称加密的算法（SELM）。我们证明，自回归LM可以将任意数据编码为紧凑的实值向量（即加密），然后通过随机子空间优化和贪心解码将向量无损解码为原始消息（即解密）。虽然SELM不易受传统加密分析方法攻破，但我们通过一种新颖的实证变体，研究它的安全性。我们的代码和数据集可在https://github.com/OSU-NLP-Group/SELM 上获得。

    Over-parameterized neural language models (LMs) can memorize and recite long sequences of training data. While such memorization is normally associated with undesired properties such as overfitting and information leaking, our work casts memorization as an unexplored capability of LMs. We propose the first symmetric encryption algorithm with autoregressive language models (SELM). We show that autoregressive LMs can encode arbitrary data into a compact real-valued vector (i.e., encryption) and then losslessly decode the vector to the original message (i.e., decryption) via random subspace optimization and greedy decoding. While SELM is not amenable to conventional cryptanalysis, we investigate its security through a novel empirical variant of the classic IND-CPA (indistinguishability under chosen-plaintext attack) game. Our code and datasets are available at https://github.com/OSU-NLP-Group/SELM.
    
[^81]: SuperDriverAI: 实现端到端学习的自主驾驶设计与实现

    SuperDriverAI: Towards Design and Implementation for End-to-End Learning-based Autonomous Driving. (arXiv:2305.10443v1 [cs.RO])

    [http://arxiv.org/abs/2305.10443](http://arxiv.org/abs/2305.10443)

    本文提出了一种端到端学习自主驾驶模型SuperDriver AI，在保证道路安全的同时，提供了更好的鲁棒性和可解释性。测试结果表明，该模型的实际表现在日本东京的特定驾驶场景中达到了预期效果。

    

    自主驾驶已经得到广泛研究，并且正在变得越来越可行。然而，由于周围人类驾驶员和行人造成的各种不确定性，这种自主驾驶尚未在公共道路上实现。在本文中，我们提出了一种名为SuperDriver AI的端到端学习自主驾驶系统，其中深度神经网络（DNN）从有经验的人类驾驶员中学习驾驶动作和策略，并确定要采取的驾驶操作，同时保证道路安全。此外，为了提高鲁棒性和可解释性，我们提出了一种分裂模型和视觉注意模块。我们构建了一个具有真实硬件的数据收集系统和模拟器，并在真实世界驾驶场景中测试了SuperDriver AI系统。最后，我们在日本东京的一个驾驶场景中收集了150次测试，并演示了SuperDriver AI与真实车辆的配合表现。

    Fully autonomous driving has been widely studied and is becoming increasingly feasible. However, such autonomous driving has yet to be achieved on public roads, because of various uncertainties due to surrounding human drivers and pedestrians. In this paper, we present an end-to-end learningbased autonomous driving system named SuperDriver AI, where Deep Neural Networks (DNNs) learn the driving actions and policies from the experienced human drivers and determine the driving maneuvers to take while guaranteeing road safety. In addition, to improve robustness and interpretability, we present a slit model and a visual attention module. We build a datacollection system and emulator with real-world hardware, and we also test the SuperDriver AI system with real-world driving scenarios. Finally, we have collected 150 runs for one driving scenario in Tokyo, Japan, and have shown the demonstration of SuperDriver AI with the real-world vehicle.
    
[^82]: 基于网络态势感知和深度强化学习的智能SDWN路由算法

    An Intelligent SDWN Routing Algorithm Based on Network Situational Awareness and Deep Reinforcement Learning. (arXiv:2305.10441v1 [cs.NI])

    [http://arxiv.org/abs/2305.10441](http://arxiv.org/abs/2305.10441)

    本文介绍了一种智能路由算法（DRL-PPONSA），基于软件定义无线网络架构下、具有网络态势感知的近似策略优化深度强化学习，通过一个特定的数据平面和一个基于DRL的数据转发机制，实现了高效获取网络状态信息、灵活转发数据，以提高通信服务质量。

    

    针对无线网络拓扑高度动态变化的问题，高效获取网络状态信息、灵活转发数据以提高通信服务质量成为了重要挑战。本文介绍了一种基于软件定义无线网络架构下、具有网络态势感知的近似策略优化深度强化学习的智能路由算法（DRL-PPONSA）。首先，为网络拓扑构建和数据转发设计了一个特定的数据平面。控制平面收集网络流量信息，发送流量表，并使用GCN-GRU预测机制感知未来流量变化趋势，以实现网络态势感知。其次，在知识平面中设计了一种基于DRL的数据转发机制，预测的网络流量矩阵和拓扑信息矩阵被视为DRL代理的环境，而下一跳相邻节点则被视为可执行动作。

    Due to the highly dynamic changes in wireless network topologies, efficiently obtaining network status information and flexibly forwarding data to improve communication quality of service are important challenges. This article introduces an intelligent routing algorithm (DRL-PPONSA) based on proximal policy optimization deep reinforcement learning with network situational awareness under a software-defined wireless networking architecture. First, a specific data plane is designed for network topology construction and data forwarding. The control plane collects network traffic information, sends flow tables, and uses a GCN-GRU prediction mechanism to perceive future traffic change trends to achieve network situational awareness. Second, a DRL-based data forwarding mechanism is designed in the knowledge plane. The predicted network traffic matrix and topology information matrix are treated as the environment for DRL agents, while next-hop adjacent nodes are treated as executable actions.
    
[^83]: 基于多智能体深度强化学习的SDWN智能组播路由方法

    Intelligent multicast routing method based on multi-agent deep reinforcement learning in SDWN. (arXiv:2305.10440v1 [cs.NI])

    [http://arxiv.org/abs/2305.10440](http://arxiv.org/abs/2305.10440)

    本文提出了一种基于多智能体深度强化学习的组播路由方法，在SDWN环境下可以显著提高多播路由性能，同时保证网络的QoS性能。

    

    多播通信技术被广泛应用于高设备密度的无线环境中。传统无线网络架构难以灵活地获取和维护全局网络状态信息，并且不能快速响应网络状态变化，从而影响现有多播解决方案的吞吐量、延迟和其他QoS要求。因此，本文在软件定义无线网络（SDWN）环境中提出了一种基于多智能体深度强化学习（MADRL-MR）的新型组播路由方法。首先，采用SDWN技术，灵活配置网络，并以流量矩阵的形式获取网络状态信息，表示全局网络链路信息，如链路带宽、延迟和数据包丢失率。其次，将组播路由问题分解为多个子问题，并通过多智能体协作解决。为了使每个代理能够准确了解当前网络状态和学习本地策略，本文使用深度Q-网络（DQN）算法进行强化学习。仿真实验结果显示，所提出的方法可以显著提高多播路由的性能，同时保证网络的QoS性能。

    Multicast communication technology is widely applied in wireless environments with a high device density. Traditional wireless network architectures have difficulty flexibly obtaining and maintaining global network state information and cannot quickly respond to network state changes, thus affecting the throughput, delay, and other QoS requirements of existing multicasting solutions. Therefore, this paper proposes a new multicast routing method based on multiagent deep reinforcement learning (MADRL-MR) in a software-defined wireless networking (SDWN) environment. First, SDWN technology is adopted to flexibly configure the network and obtain network state information in the form of traffic matrices representing global network links information, such as link bandwidth, delay, and packet loss rate. Second, the multicast routing problem is divided into multiple subproblems, which are solved through multiagent cooperation. To enable each agent to accurately understand the current network st
    
[^84]: IMAGINATOR：使用基于单词级别图像本体的预训练图像+文本联合嵌入

    IMAGINATOR: Pre-Trained Image+Text Joint Embeddings using Word-Level Grounding of Images. (arXiv:2305.10438v1 [cs.CL])

    [http://arxiv.org/abs/2305.10438](http://arxiv.org/abs/2305.10438)

    IMAGINATOR是一个使用基于单词级别图像本体的预训练图像+文本联合嵌入，能将多模态数据编码为矢量空间。

    

    单词嵌入是一种语义有意义的单词向量表示，主要受到分布假设“你应该通过它的伴侣来认识一个单词”（Harris，1954）的影响，而现代基于预测的神经网络嵌入则依赖于设计选择和超参数优化。这篇论文介绍了一种名为IMAGINATOR的预训练联合嵌入（JE），它是在1M个图像+文本对中从21K个不同的图像对象级别进行训练的。JE是一种将多模态数据编码为矢量空间的方法，其中文本模态作为基础关键词，而补充模态（在这种情况下为图像）则与之相连。

    Word embeddings, i.e., semantically meaningful vector representation of words, are largely influenced by the distributional hypothesis "You shall know a word by the company it keeps" (Harris, 1954), whereas modern prediction-based neural network embeddings rely on design choices and hyperparameter optimization. Word embeddings like Word2Vec, GloVe etc. well capture the contextuality and real-world analogies but contemporary convolution-based image embeddings such as VGGNet, AlexNet, etc. do not capture contextual knowledge. The popular king-queen analogy does not hold true for most commonly used vision embeddings.  In this paper, we introduce a pre-trained joint embedding (JE), named IMAGINATOR, trained on 21K distinct image objects level from 1M image+text pairs. JE is a way to encode multimodal data into a vector space where the text modality serves as the ground-ing key, which the complementary modality (in this case, the image) is anchored with. IMAGINATOR encapsulates three indivi
    
[^85]: 将人工智能带到边缘：部署有效物联网架构的正式建模与规范 (arXiv:2305.10437v1 [cs.NI])

    Bringing AI to the edge: A formal M&S specification to deploy effective IoT architectures. (arXiv:2305.10437v1 [cs.NI])

    [http://arxiv.org/abs/2305.10437](http://arxiv.org/abs/2305.10437)

    本文提出了一种基于离散事件系统规范的物联网模型来部署有效的物联网架构，包括将计算基础设施更靠近数据源的新架构雾计算和实时数据分析在网络边缘提供能力的新数据中心。

    

    物联网正在改变我们的社会，提供改善生活质量和资源管理的新服务。这些应用程序基于具有有限计算资源和电源的多个分布式设备的普遍网络，能够实时收集和存储来自不同来源的数据。为了避免网络饱和和高延迟，新的架构如雾计算正在出现，将计算基础设施更靠近数据源。此外，需要新的数据中心，在网络边缘提供实时大数据和数据分析能力，需要考虑能源效率，以确保在人类活动区域可持续且有效地部署。在这项研究中，我们提出了一种基于离散事件系统规范的模型，基于模型化系统工程的原则的物联网模型。所提供的数学规范覆盖了整个体系结构的描述。

    The Internet of Things is transforming our society, providing new services that improve the quality of life and resource management. These applications are based on ubiquitous networks of multiple distributed devices, with limited computing resources and power, capable of collecting and storing data from heterogeneous sources in real-time. To avoid network saturation and high delays, new architectures such as fog computing are emerging to bring computing infrastructure closer to data sources. Additionally, new data centers are needed to provide real-time Big Data and data analytics capabilities at the edge of the network, where energy efficiency needs to be considered to ensure a sustainable and effective deployment in areas of human activity. In this research, we present an IoT model based on the principles of Model-Based Systems Engineering defined using the Discrete Event System Specification formalism. The provided mathematical formalism covers the description of the entire archite
    
[^86]: 生成的预训练变形器：启用技术、潜在应用、新兴挑战和未来方向的综述

    Generative Pre-trained Transformer: A Comprehensive Review on Enabling Technologies, Potential Applications, Emerging Challenges, and Future Directions. (arXiv:2305.10435v1 [cs.CL])

    [http://arxiv.org/abs/2305.10435](http://arxiv.org/abs/2305.10435)

    生成的预训练变形器是一种基于变形器架构的深度神经网络，能够在自然语言处理任务中表现出色且有效地进行对话，具有广泛的潜在应用，但仍面临新兴挑战和局限性。

    

    生成的预训练变形器模型代表了自然语言处理领域的一项重大突破，将我们推向开发能够像人类一样理解和使用语言进行交流的机器。生成的预训练变形器模型基于变形器架构，这是一种专门设计用于自然语言处理任务的深度神经网络。由于在自然语言处理任务上表现出色且能够有效地进行对话，生成的预训练变形器模型在研究人员和工业界社区中获得了显著的知名度，成为自然语言处理及相关领域中最广泛使用和有效的模型之一，这促使进行了本综述。本综述详细介绍了生成预训练变形器，包括其架构、工作过程、训练过程、启用技术以及在各个领域的潜在应用。同时，本综述还讨论了该模型面临的新兴挑战和局限性，并提供了未来研究的可能方向。

    The Generative Pre-trained Transformer models represent a notable breakthrough in the domain of natural language processing, which is propelling us toward the development of machines that can understand and communicate using language in a manner that closely resembles that of humans. Generative Pre-trained Transformer models are based on the transformer architecture, a deep neural network designed for natural language processing tasks. Due to their impressive performance on natural language processing tasks and ability to effectively converse, Generative Pre-trained Transformer models have gained significant popularity among researchers and industrial communities, making them one of the most widely used and effective models in natural language processing and related fields, which motivated to conduct this review. This review provides a detailed overview of the Generative Pre-trained Transformer, including its architecture, working process, training procedures, enabling technologies, an
    
[^87]: MemoryBank: 用长期记忆增强大型语言模型

    MemoryBank: Enhancing Large Language Models with Long-Term Memory. (arXiv:2305.10250v1 [cs.CL])

    [http://arxiv.org/abs/2305.10250](http://arxiv.org/abs/2305.10250)

    MemoryBank 提出了一种新型内存机制，旨在为大型语言模型提供类人的长期记忆。它可以召唤相关记忆，通过持续的记忆更新不断进化，通过合成过去的互动信息理解并适应用户个性。

    

    大型语言模型的革命性进展极大地改变了我们与人工智能系统的互动方式。尽管如此，其中一个明显的不足之处是这些模型缺乏长期记忆机制。这在需要持续互动的情况下尤为明显，例如个人伴侣系统和心理咨询。因此，我们提出了MemoryBank，这是一种专为LLM量身定制的新型内存机制。MemoryBank可以召唤相关记忆，通过持续的记忆更新不断进化，通过合成过去的互动信息理解并适应用户个性。为了模仿人类行为并有选择地保存记忆，MemoryBank采用了受Ebbinghaus遗忘曲线理论启发的记忆更新机制，这样人工智能可以根据时间和记忆的相对重要性来遗忘和加强记忆，从而为LLM提供类似于人类的长期记忆。

    Revolutionary advancements in Large Language Models have drastically reshaped our interactions with artificial intelligence systems. Despite this, a notable hindrance remains-the deficiency of a long-term memory mechanism within these models. This shortfall becomes increasingly evident in situations demanding sustained interaction, such as personal companion systems and psychological counseling. Therefore, we propose MemoryBank, a novel memory mechanism tailored for LLMs. MemoryBank enables the models to summon relevant memories, continually evolve through continuous memory updates, comprehend, and adapt to a user personality by synthesizing information from past interactions. To mimic anthropomorphic behaviors and selectively preserve memory, MemoryBank incorporates a memory updating mechanism, inspired by the Ebbinghaus Forgetting Curve theory, which permits the AI to forget and reinforce memory based on time elapsed and the relative significance of the memory, thereby offering a hum
    
[^88]: 评估LLM的隐藏风险：关于鲁棒性、一致性和可信性的实证研究

    Assessing Hidden Risks of LLMs: An Empirical Study on Robustness, Consistency, and Credibility. (arXiv:2305.10235v1 [cs.LG])

    [http://arxiv.org/abs/2305.10235](http://arxiv.org/abs/2305.10235)

    本研究是一项关于大型语言模型方面的实证研究，对主流语言模型进行了大量查询和分析，结果发现这些模型存在着鲁棒性、一致性和可信性方面的潜在风险。

    

    大型语言模型（LLMs）的普及对于许多领域产生了重大影响，特别是在其开放式环境（如API、开源模型和插件）中。然而，随着LLMs的广泛部署，缺乏全面讨论和分析潜在风险的研究。因此，我们进行了一项初步但开创性的研究，涵盖了LLMs系统的鲁棒性、一致性和可信性。我们提出了一个自动化工作流程来处理大量查询/响应。总体而言，我们对包括ChatGPT、LLaMA和OPT在内的主流LLMs进行了100多万个查询。我们的工作流核心包括数据原语，随后是自动解释器，评估这些LLMs在不同的对抗性度量系统下的表现。结果，我们得出了几个、也许是不幸的结论，这些结论相当不同

    The recent popularity of large language models (LLMs) has brought a significant impact to boundless fields, particularly through their open-ended ecosystem such as the APIs, open-sourced models, and plugins. However, with their widespread deployment, there is a general lack of research that thoroughly discusses and analyzes the potential risks concealed. In that case, we intend to conduct a preliminary but pioneering study covering the robustness, consistency, and credibility of LLMs systems. With most of the related literature in the era of LLM uncharted, we propose an automated workflow that copes with an upscaled number of queries/responses. Overall, we conduct over a million queries to the mainstream LLMs including ChatGPT, LLaMA, and OPT. Core to our workflow consists of a data primitive, followed by an automated interpreter that evaluates these LLMs under different adversarial metrical systems. As a result, we draw several, and perhaps unfortunate, conclusions that are quite unco
    
[^89]: 一种多目标优化的Wasserstein反向强化学习模型的证明

    A proof of imitation of Wasserstein inverse reinforcement learning for multi-objective optimization. (arXiv:2305.10089v1 [cs.LG])

    [http://arxiv.org/abs/2305.10089](http://arxiv.org/abs/2305.10089)

    本文证明了Wasserstein反向强化学习模型适用于多目标优化问题，可让学习者的奖励值和最优解模仿专家，具有一定的实用价值。

    

    本文证明了Wasserstein反向强化学习模型可以在有限次迭代中让学习者的奖励值模仿专家的奖励值，并证明了在词典序的多目标优化中，Wasserstein反向强化学习模型可以让学习者的最优解模仿专家的最优解。

    We prove Wasserstein inverse reinforcement learning enables the learner's reward values to imitate the expert's reward values in a finite iteration for multi-objective optimizations. Moreover, we prove Wasserstein inverse reinforcement learning enables the learner's optimal solutions to imitate the expert's optimal solutions for multi-objective optimizations with lexicographic order.
    
[^90]: “我全然成为我自己”：以TGNB人群为中心，评估开放式语言生成中的偏见

    "I'm fully who I am": Towards Centering Transgender and Non-Binary Voices to Measure Biases in Open Language Generation. (arXiv:2305.09941v1 [cs.CL])

    [http://arxiv.org/abs/2305.09941](http://arxiv.org/abs/2305.09941)

    本论文研究了如何以TGNB人群的声音为中心，评估开放式语言生成中的偏见。通过理解TGNB个体的经历，提出了以TGNB人群为中心的OLG系统评估框架，并且包括一个为TGNB人群设计的调查工具和分析方法。

    

    跨性别和非二元（TGNB）人群在日常生活中经历了不成比例的歧视和排斥。随着语言生成技术的日益普及和应用，进一步边缘化这一人群的可能性也在增加。虽然大量的NLP公平文献着重于阐明和解决性别偏见，但评估TGNB身份所带来的性别伤害需要理解这些身份如何独特地与社会性别规范互动以及与性别二元中心的视角相区分。这样的测量框架本质上需要以TGNB声音为中心，帮助指导包容性别的自然语言处理应该为谁服务。为实现这一目标，我们以TGNB社区和现有的跨学科文献为基础，评估了TGNB个体经历边缘化所形成的社会现实是如何影响和存在于开放式语言生成（OLG）中。首先理解TGNB个体的经历，我们提出了一个评估OLG系统的框架，旨在以TGNB人群为中心，度量与该人群相关的偏见。我们的框架包括特别为TGNB人群设计的调查工具，以及交叉分析结果的交叉方法。我们相信，这项工作将有助于实现更公平、更包容的自然语言处理社区，并潜在地解决NLP研究中广泛的交叉身份问题。

    Transgender and non-binary (TGNB) individuals disproportionately experience discrimination and exclusion from daily life. Given the recent popularity and adoption of language generation technologies, the potential to further marginalize this population only grows. Although a multitude of NLP fairness literature focuses on illuminating and addressing gender biases, assessing gender harms for TGNB identities requires understanding how such identities uniquely interact with societal gender norms and how they differ from gender binary-centric perspectives. Such measurement frameworks inherently require centering TGNB voices to help guide the alignment between gender-inclusive NLP and whom they are intended to serve. Towards this goal, we ground our work in the TGNB community and existing interdisciplinary literature to assess how the social reality surrounding experienced marginalization by TGNB persons contributes to and persists within Open Language Generation (OLG). By first understandi
    
[^91]: Epsilon Sampling Rocks: 研究用于机器翻译最小贝叶斯风险解码的采样策略

    Epsilon Sampling Rocks: Investigating Sampling Strategies for \\Minimum Bayes Risk Decoding for Machine Translation. (arXiv:2305.09860v1 [cs.CL])

    [http://arxiv.org/abs/2305.09860](http://arxiv.org/abs/2305.09860)

    本文研究了用于机器翻译最小贝叶斯风险解码的不同采样策略，并发现了epsilon采样方式能够使得解码结果显著地优于其他所有已测试的采样方式和束搜索解码。

    

    机器翻译中的最小贝叶斯风险（MBR）解码已经显示出是一种强大的替代束搜索解码的方法，尤其是与基于神经网络的效用函数相结合时。然而，MBR解码的性能严重依赖于从模型中采样的方法和数量。本文探讨了用于MBR解码的不同采样方法对性能的影响。我们评估了一些流行的采样方法，例如祖先采样，核采样和top-k采样。基于我们对它们局限性的认识，我们尝试了最近提出的epsilon采样方法，该方法通过修剪所有小于epsilon的标记，以确保样本中的每个标记获得公平的概率质量。通过广泛的人类评估，我们证明了基于epsilon采样的MBR解码显著优于不仅是束搜索解码，而且还优于所有其他已测试的采样方法的MBR解码。

    Recent advances in machine translation (MT) have shown that Minimum Bayes Risk (MBR) decoding can be a powerful alternative to beam search decoding, especially when combined with neural-based utility functions. However, the performance of MBR decoding depends heavily on how and how many candidates are sampled from the model. In this paper, we explore how different sampling approaches for generating candidate lists for MBR decoding affect performance. We evaluate popular sampling approaches, such as ancestral, nucleus, and top-k sampling. Based on our insights into their limitations, we experiment with the recently proposed epsilon-sampling approach, which prunes away all tokens with a probability smaller than epsilon, ensuring that each token in a sample receives a fair probability mass. Through extensive human evaluations, we demonstrate that MBR decoding based on epsilon-sampling significantly outperforms not only beam search decoding, but also MBR decoding with all other tested samp
    
[^92]: 大数据学习：精选包与随机包的对比研究

    Learning from Aggregated Data: Curated Bags versus Random Bags. (arXiv:2305.09557v1 [cs.LG])

    [http://arxiv.org/abs/2305.09557](http://arxiv.org/abs/2305.09557)

    本文研究了两种自然的聚合方法：基于共同特征将数据点分组的精选包和将数据点随机分组的随机包，对于精选包设置和广泛的损失函数范围内，我们展示了可以通过梯度下降学习而不会导致数据聚合导致性能下降的情况。

    

    保护用户隐私是许多机器学习系统部署的一个主要关注点，这些系统收集来自各种群体的数据。为了应对这种问题，一种方法是以聚合的形式收集和发布数据标签，从而可以将单个用户的信息与其他用户的信息组合起来。本文探讨了使用聚合数据标签而非单个标签来训练机器学习模型的可能性，具体来说，我们考虑了两种自然的聚合方法：基于共同特征将数据点分组的精选包和将数据点随机分组的随机包。对于精选包设置和广泛的损失函数范围内，我们展示了可以通过梯度下降学习而不会导致数据聚合导致性能下降的情况。我们的方法基于以下观察：损失函数的梯度之和可以表示为每个包的梯度的加权和，其中权重是包的大小。

    Protecting user privacy is a major concern for many machine learning systems that are deployed at scale and collect from a diverse set of population. One way to address this concern is by collecting and releasing data labels in an aggregated manner so that the information about a single user is potentially combined with others. In this paper, we explore the possibility of training machine learning models with aggregated data labels, rather than individual labels. Specifically, we consider two natural aggregation procedures suggested by practitioners: curated bags where the data points are grouped based on common features and random bags where the data points are grouped randomly in bag of similar sizes. For the curated bag setting and for a broad range of loss functions, we show that we can perform gradient-based learning without any degradation in performance that may result from aggregating data. Our method is based on the observation that the sum of the gradients of the loss functio
    
[^93]: LoViT: 用于手术阶段识别的长视频Transformer

    LoViT: Long Video Transformer for Surgical Phase Recognition. (arXiv:2305.08989v1 [cs.CV])

    [http://arxiv.org/abs/2305.08989](http://arxiv.org/abs/2305.08989)

    LoViT是一种用于手术阶段识别的长视频Transformer，它通过结合时间丰富的空间特征提取器和多尺度时间聚合器来对长视频进行分析，优于现有方法。

    

    在构建能够量化表现并监督手术流程执行的上下文工具方面，在线手术阶段识别发挥着重要作用。目前的方法有限，因为它们使用基于帧级监督的空间特征提取器进行训练，这可能会导致由于相似帧在不同阶段出现而导致的错误预测，并且由于计算限制而未能很好地融合本地和全局特征，这可能影响手术干预中通常遇到的长视频的分析。在本文中，我们提出了一种名为LoViT的两阶段方法，用于融合短期和长期时间信息，它结合了一个时间丰富的空间特征提取器和一个多尺度时间聚合器，后者由基于自注意力的两个级联L-Trans模块和一个基于ProbSparse自注意力的G-Informer模块组成，用于处理全局时间信息。然后，多尺度时间头结合本地和全局特征来识别长视频中的手术阶段。我们展示了LoViT在两个公共手术数据集上优于现有方法。

    Online surgical phase recognition plays a significant role towards building contextual tools that could quantify performance and oversee the execution of surgical workflows. Current approaches are limited since they train spatial feature extractors using frame-level supervision that could lead to incorrect predictions due to similar frames appearing at different phases, and poorly fuse local and global features due to computational constraints which can affect the analysis of long videos commonly encountered in surgical interventions. In this paper, we present a two-stage method, called Long Video Transformer (LoViT) for fusing short- and long-term temporal information that combines a temporally-rich spatial feature extractor and a multi-scale temporal aggregator consisting of two cascaded L-Trans modules based on self-attention, followed by a G-Informer module based on ProbSparse self-attention for processing global temporal information. The multi-scale temporal head then combines loc
    
[^94]: 无需增加模型参数的序列到序列模型微调方法：基于结构化剪枝的LoRA方法

    Parameter-Efficient Fine-Tuning with Layer Pruning on Free-Text Sequence-to-Sequence modeling. (arXiv:2305.08285v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.08285](http://arxiv.org/abs/2305.08285)

    本文提出了一个将LoRA和结构化层剪枝方法结合的框架，在保持超过92%生成质量的同时，通过调整仅0.6%的参数并剪枝超过30%的Transformer层，成功减少了50%的GPU内存使用并提升了100%的训练速度。

    

    语言模型尺寸的不断增长引起了对于参数效率的微调方法的研究兴趣，本文提出了一个将LoRA和结构化层剪枝方法结合的框架。这个框架在 MIMIC-IV-Note上的两个医疗报告概述数据集和两个公共医疗对话数据集上进行了验证。通过调整原始模型的0.6%的参数并剪枝超过30%的Transformer层，我们的框架可以减少50%的GPU内存使用并提升100%的训练速度，同时保持在自由文本序列到序列任务上超过92%的生成质量。

    The increasing size of language models raises great research interests in parameter-efficient fine-tuning such as LoRA that freezes the pre-trained model, and injects small-scale trainable parameters for multiple downstream tasks (e.g., summarization, question answering and translation). To further enhance the efficiency of fine-tuning, we propose a framework that integrates LoRA and structured layer pruning. The integrated framework is validated on two created deidentified medical report summarization datasets based on MIMIC-IV-Note and two public medical dialogue datasets. By tuning 0.6% parameters of the original model and pruning over 30% Transformer-layers, our framework can reduce 50% of GPU memory usage and speed up 100% of the training phase, while preserving over 92% generation qualities on free-text sequence-to-sequence tasks.
    
[^95]: 跨域问答泛化学习

    Learning to Generalize for Cross-domain QA. (arXiv:2305.08208v1 [cs.CL])

    [http://arxiv.org/abs/2305.08208](http://arxiv.org/abs/2305.08208)

    提出了一种不增加训练成本的跨域问答泛化学习方法，通过结合提示方法和线性探测再微调策略，有效提高了产生式和判别式模型的泛化能力，取得了优于基准方法4.5%-7.9%的结果。

    

    自然语言处理模型的跨域泛化能力，尤其是在问答任务中，一直存在着越来越大的担忧。当前的合成数据增强方法受到了增加训练成本的限制。为了解决这个问题，我们提出了一种结合提示方法和线性探测再微调策略的新方法，该方法不需要额外的成本。我们的方法在理论上和实证上都被证明有效，可以增强产生式和判别式模型的泛化能力。我们的方法优于现有的基准方法，F1得分平均提高了4.5%-7.9%。同时，我们的方法可以轻松地集成到任何预训练模型中，并为未充分开发的跨域问答任务提供了有前途的解决方案。我们在GitHub上公开了我们的源代码*。

    There have been growing concerns regarding the out-of-domain generalization ability of natural language processing (NLP) models, particularly in question-answering (QA) tasks. Current synthesized data augmentation methods for QA are hampered by increased training costs. To address this issue, we propose a novel approach that combines prompting methods and linear probing then fine-tuning strategy, which does not entail additional cost. Our method has been theoretically and empirically shown to be effective in enhancing the generalization ability of both generative and discriminative models. Our approach outperforms state-of-the-art baselines, with an average increase in F1 score of 4.5%-7.9%. Furthermore, our method can be easily integrated into any pre-trained models and offers a promising solution to the under-explored cross-domain QA task. We release our source code at GitHub*.
    
[^96]: DRew：带延迟的动态重连消息传递

    DRew: Dynamically Rewired Message Passing with Delay. (arXiv:2305.08018v1 [cs.LG])

    [http://arxiv.org/abs/2305.08018](http://arxiv.org/abs/2305.08018)

    本文提出了一种能够应用于任何MPNN结构的框架，执行基于层的动态重连来确保逐渐密集化的图形。同时引入了一种延迟机制，允许跨层节点之间的跳跃连接。

    

    已经证明，消息传递神经网络（MPNN）存在过度压缩现象，导致长程相互作用任务表现不佳。这主要归因于只在节点的相邻居之间进行局部消息传递。试图使图形“更连通”并且更适合长程任务的重连方法通常会失去基于图形距离提供的归纳偏差，因为它们会使远程节点在每一层中立即通信。在本文中，我们提出了一个框架，可应用于任何MPNN架构，以执行基于层的重连，以确保逐渐加密图形。我们还提出了一种延迟机制，它允许根据层和它们的相互距离在节点之间进行跳跃连接。我们在几个长程任务上验证了我们的方法，并表明其优于图形变换器和多跳MPNN。

    Message passing neural networks (MPNNs) have been shown to suffer from the phenomenon of over-squashing that causes poor performance for tasks relying on long-range interactions. This can be largely attributed to message passing only occurring locally, over a node's immediate neighbours. Rewiring approaches attempting to make graphs `more connected', and supposedly better suited to long-range tasks, often lose the inductive bias provided by distance on the graph since they make distant nodes communicate instantly at every layer. In this paper we propose a framework, applicable to any MPNN architecture, that performs a layer-dependent rewiring to ensure gradual densification of the graph. We also propose a delay mechanism that permits skip connections between nodes depending on the layer and their mutual distance. We validate our approach on several long-range tasks and show that it outperforms graph Transformers and multi-hop MPNNs.
    
[^97]: 基于匹配特征提取的异构边缘设备工业健康预测的联邦学习

    A Federated Learning-based Industrial Health Prognostics for Heterogeneous Edge Devices using Matched Feature Extraction. (arXiv:2305.07854v1 [cs.LG])

    [http://arxiv.org/abs/2305.07854](http://arxiv.org/abs/2305.07854)

    提出了一种基于联邦学习的健康预测模型，该模型具有特征相似性匹配算法来区分学习来自异构边缘设备的数据，以便开发出更准确的预测模型。

    

    数据驱动的工业健康预测需要丰富的训练数据才能开发准确可靠的预测模型。然而，严格的数据隐私法律和丰富的边缘工业数据需要分散式数据利用。因此，联邦学习（FL）是一个分散式和隐私保护的学习技术，非常适用于工业健康预测领域。然而，由于异构数据的数据异质性，以及由于不同的退化机制和不平等的数据集大小所导致的数据异构性，在联邦学习的基础上开发精度高的训练模型是一个关键的统计挑战。因此，FL在健康预测任务中的应用尚未充分研究。本文提出了一种具有特征相似性匹配的参数聚合算法的 FL 健康预测模型。

    Data-driven industrial health prognostics require rich training data to develop accurate and reliable predictive models. However, stringent data privacy laws and the abundance of edge industrial data necessitate decentralized data utilization. Thus, the industrial health prognostics field is well suited to significantly benefit from federated learning (FL), a decentralized and privacy-preserving learning technique. However, FL-based health prognostics tasks have hardly been investigated due to the complexities of meaningfully aggregating model parameters trained from heterogeneous data to form a high performing federated model. Specifically, data heterogeneity among edge devices, stemming from dissimilar degradation mechanisms and unequal dataset sizes, poses a critical statistical challenge for developing accurate federated models. We propose a pioneering FL-based health prognostic model with a feature similarity-matched parameter aggregation algorithm to discriminatingly learn from h
    
[^98]: ChatGPT是一个好的因果推断器吗？全面评估

    Is ChatGPT a Good Causal Reasoner? A Comprehensive Evaluation. (arXiv:2305.07375v1 [cs.CL])

    [http://arxiv.org/abs/2305.07375](http://arxiv.org/abs/2305.07375)

    本文对ChatGPT的因果推理能力进行了首次全面评估，实验证明ChatGPT是一个好的因果解释者，但不是一个好的因果推理者，存在严重的因果幻觉问题，对于明确的因果关系表现良好。

    

    因果推理能力对于众多NLP应用至关重要。尽管ChatGPT在各种NLP任务中表现出令人印象深刻的新兴能力，但ChatGPT在因果推理方面的表现如何仍不清楚。本文对ChatGPT的因果推理能力进行了首次全面评估。实验证明，ChatGPT不是一个好的因果推理者，但是是一个好的因果解释者。此外，ChatGPT在因果推理方面存在严重的幻觉，可能是由于自然语言中因果关系和非因果关系的报告偏见，以及ChatGPT的升级过程，如RLHF。在上下文学习（ICL）和思维链（COT）技术方面，可能会进一步加剧这种因果幻觉。此外，ChatGPT的因果推理能力对于在提示中表达因果概念的词语非常敏感，并且封闭提示比开放提示表现更好。对于句子中的事件，ChatGPT擅长捕捉明确的因果关系。

    Causal reasoning ability is crucial for numerous NLP applications. Despite the impressive emerging ability of ChatGPT in various NLP tasks, it is unclear how well ChatGPT performs in causal reasoning. In this paper, we conduct the first comprehensive evaluation of the ChatGPT's causal reasoning capabilities. Experiments show that ChatGPT is not a good causal reasoner, but a good causal interpreter. Besides, ChatGPT has a serious hallucination on causal reasoning, possibly due to the reporting biases between causal and non-causal relationships in natural language, as well as ChatGPT's upgrading processes, such as RLHF. The In-Context Learning (ICL) and Chain-of-Though (COT) techniques can further exacerbate such causal hallucination. Additionally, the causal reasoning ability of ChatGPT is sensitive to the words used to express the causal concept in prompts, and close-ended prompts perform better than open-ended prompts. For events in sentences, ChatGPT excels at capturing explicit caus
    
[^99]: 基于控制微分方程的Hawkes过程

    Hawkes Process based on Controlled Differential Equations. (arXiv:2305.07031v1 [cs.LG])

    [http://arxiv.org/abs/2305.07031](http://arxiv.org/abs/2305.07031)

    本文提出了一种基于控制微分方程的Hawkes过程模型，可精确计算对数似然，并能够正确处理不规则时间序列，适用于社会扩散和地震预测。

    

    Hawkes过程是一种常用的模型框架，用于对多个领域的序贯事件发生动态进行建模，例如社会扩散。在现实场景中，事件之间的间隔时间是不规则的。然而，现有基于神经网络的Hawkes过程模型不仅难以捕捉这种复杂的不规则动态，而且还会使用启发式方法计算事件的对数似然，因为它们大多基于设计用于规则离散输入的神经网络。为此，我们提出了基于控制微分方程(CDE)的Hawkes过程概念，通过采用类似于连续RNN的神经CDE技术。由于HP-CDE不断地读取数据，因此可以适当地处理不规则时间序列数据集，保留它们的不均匀时间空间，并且对数似然可以准确计算。此外，由于Hawkes过程和神经CDE都是在连续的时间域中首先开发的，它们具有相似的背景。因此，HP-CDE具有透明的结构，可以轻松适应实际场景，例如社会扩散，其中事件之间的间隔时间是不规则的。我们使用合成和真实的社交扩散和地震数据集演示了我们提出的模型的优势，并超过了现有的最先进的Hawkes过程模型。

    Hawkes processes are a popular framework to model the occurrence of sequential events, i.e., occurrence dynamics, in several fields such as social diffusion. In real-world scenarios, the inter-arrival time among events is irregular. However, existing neural network-based Hawkes process models not only i) fail to capture such complicated irregular dynamics, but also ii) resort to heuristics to calculate the log-likelihood of events since they are mostly based on neural networks designed for regular discrete inputs. To this end, we present the concept of Hawkes process based on controlled differential equations (HP-CDE), by adopting the neural controlled differential equation (neural CDE) technology which is an analogue to continuous RNNs. Since HP-CDE continuously reads data, i) irregular time-series datasets can be properly treated preserving their uneven temporal spaces, and ii) the log-likelihood can be exactly computed. Moreover, as both Hawkes processes and neural CDEs are first de
    
[^100]: 多目标优化的逆强化学习的收敛性证明研究

    A proof of convergence of inverse reinforcement learning for multi-objective optimization. (arXiv:2305.06137v1 [cs.LG])

    [http://arxiv.org/abs/2305.06137](http://arxiv.org/abs/2305.06137)

    本论文证明了多目标优化的逆强化学习方法在理论层面上的收敛性，包括Wasserstein逆强化学习和常规逆强化学习方法。

    

    本文通过将等效于多目标优化的WIRL问题的逆问题与投影次梯度法相结合，证明了Wasserstein逆强化学习（WIRL）在多目标优化中的收敛性。此外，我们还证明了逆强化学习（最大熵逆强化学习，导引成本学习）在多目标优化中的收敛性。

    We show the convergence of Wasserstein inverse reinforcement learning (WIRL) for multi-objective optimizations with the projective subgradient method by formulating an inverse problem of the optimization problem that is equivalent to WIRL for multi-objective optimizations.  In addition, we prove convergence of inverse reinforcement learning (maximum entropy inverse reinforcement learning, guid cost learning) for multi-objective optimization with the projective subgradient method.
    
[^101]: 基于基础模型的系统设计框架

    A Framework for Designing Foundation Model based Systems. (arXiv:2305.05352v1 [cs.SE])

    [http://arxiv.org/abs/2305.05352](http://arxiv.org/abs/2305.05352)

    本文提出了一个基于基础模型的系统分类体系，分类和比较了基础模型和基于基础模型的系统的特点。它为设计基于基础模型的系统时做出主要的设计决策提供了具体的指导，并突出了相关的权衡。

    

    最近推出了大型语言模型(LLM)的聊天机器人，如ChatGPT，这引起了人们对基础模型的广泛关注。基础模型被广泛认为将成为未来人工智能系统的基石。由于基础模型处于早期阶段，基于基础模型的系统设计尚未得到系统地探索。人们对在软件架构中引入基础模型的影响知之甚少。因此，在本文中，我们提出了一个基于基础模型的系统分类法，对基础模型和基于基础模型的系统的特点进行了分类和比较。我们的分类法包括三个类别：基础模型预训练和微调、基于基础模型的系统架构设计和负责任的AI设计。这个分类法为设计基于基础模型的系统时做出主要的设计决策提供了具体的指导，并突出了相关的权衡。

    The recent release of large language model (LLM) based chatbots, such as ChatGPT, has attracted significant attention on foundations models. It is widely believed that foundation models will serve as the fundamental building blocks for future AI systems. As foundation models are in their early stages, the design of foundation model based systems has not yet been systematically explored. There is little understanding about the impact of introducing foundation models in software architecture. Therefore, in this paper, we propose a taxonomy of foundation model based systems, which classifies and compares the characteristics of foundation models and foundation model based systems. Our taxonomy comprises three categories: foundation model pretraining and fine-tuning, architecture design of foundation model based systems, and responsible-AI-by-design. This taxonomy provides concrete guidance for making major design decisions when designing foundation model based systems and highlights trade-
    
[^102]: 从大型语言模型中提取脚本知识以进行受限语言规划

    Distilling Script Knowledge from Large Language Models for Constrained Language Planning. (arXiv:2305.05252v1 [cs.CL])

    [http://arxiv.org/abs/2305.05252](http://arxiv.org/abs/2305.05252)

    本文首次定义了受限语言规划任务，提出了一种方法来提高大型语言模型在这个任务中的表现，并提取了一个新颖的受限语言规划数据集。实验证明该方法显著提高了其在约束忠实度方面的能力，并对赋予较小的语言模型受限语言规划能力非常有效。

    

    在日常生活中，人们经常通过遵循目标导向的脚本形式的逐步说明来规划自己的行动。以往的工作利用语言模型（LM）来为立体活动的抽象目标（例如，“制作蛋糕”）进行规划，但对于具有多方面约束的更具体目标（例如，“为糖尿病患者制作蛋糕”）鲜有研究。本文首次定义了受限语言规划任务。我们提出了一种过度生成并过滤的方法来改善大型语言模型（LLM）在这个任务中的表现，并利用它来提取一种新颖的受限语言规划数据集CoScript，其中包括55,000个脚本。实验证明，我们的方法显著提高了LLM在受限语言规划方面的能力，特别是在约束忠实度方面。此外，CoScript被证明对赋予较小的LM受限语言规划能力是非常有效的。

    In everyday life, humans often plan their actions by following step-by-step instructions in the form of goal-oriented scripts. Previous work has exploited language models (LMs) to plan for abstract goals of stereotypical activities (e.g., "make a cake"), but leaves more specific goals with multi-facet constraints understudied (e.g., "make a cake for diabetics"). In this paper, we define the task of constrained language planning for the first time. We propose an overgenerate-then-filter approach to improve large language models (LLMs) on this task, and use it to distill a novel constrained language planning dataset, CoScript, which consists of 55,000 scripts. Empirical results demonstrate that our method significantly improves the constrained language planning ability of LLMs, especially on constraint faithfulness. Furthermore, CoScript is demonstrated to be quite effective in endowing smaller LMs with constrained language planning ability.
    
[^103]: 改进零样本基于草图的图像检索的自适应和对齐方法

    Adapt and Align to Improve Zero-Shot Sketch-Based Image Retrieval. (arXiv:2305.05144v1 [cs.CV])

    [http://arxiv.org/abs/2305.05144](http://arxiv.org/abs/2305.05144)

    本文针对零样本基于草图图像检索的跨域和语义问题，提出了一种自适应和对齐的方法，通过插入简单且轻量的域适配器重新学习草图领域的新抽象概念，并通过明确对齐学习到的图像嵌入以提高跨域表示能力。

    

    零样本基于草图的图像检索(ZS-SBIR)由于草图和照片之间的跨域本质以及已知和未知图像分布之间的语义差距而具有挑战性。先前的方法使用各种辅助信息和学习策略微调预训练模型，以学习一个紧凑的特征空间，该空间 (\romannumeral 1)在草图和照片领域之间共享，(\romannumeral 2) 桥接已知和未知类别。然而，这些努力在适应领域和从已知类别传递知识方面不足。本文提出了一种有效的“自适应和对齐”方法来解决关键问题。具体而言，我们插入简单且轻量的域适配器，以学习草图领域的新的抽象概念，并提高跨域表示能力。受到最近在零样本场景下图像-文本基础模型(CLIP)的进展启发，我们明确地将学习到的图像嵌入与模型明确对齐。

    Zero-shot sketch-based image retrieval (ZS-SBIR) is challenging due to the cross-domain nature of sketches and photos, as well as the semantic gap between seen and unseen image distributions. Previous methods fine-tune pre-trained models with various side information and learning strategies to learn a compact feature space that (\romannumeral1) is shared between the sketch and photo domains and (\romannumeral2) bridges seen and unseen classes. However, these efforts are inadequate in adapting domains and transferring knowledge from seen to unseen classes. In this paper, we present an effective \emph{``Adapt and Align''} approach to address the key challenges. Specifically, we insert simple and lightweight domain adapters to learn new abstract concepts of the sketch domain and improve cross-domain representation capabilities. Inspired by recent advances in image-text foundation models (\textit{e.g.}, CLIP) on zero-shot scenarios, we explicitly align the learned image embedding with a mo
    
[^104]: 使用数据内核比较基础模型

    Comparing Foundation Models using Data Kernels. (arXiv:2305.05126v1 [cs.LG])

    [http://arxiv.org/abs/2305.05126](http://arxiv.org/abs/2305.05126)

    本文采用基于数据内核的方法比较基础模型，不受度量指标的约束，通过嵌入空间几何实现点对点和多模型比较，并成功诱导了一组与下游指标强相关的模型距离函数流形。

    

    最近自主学习和神经网络扩展的进展使得可以创建大型基础模型，这些模型可以轻松地适应各种下游任务。目前比较基础模型的范式涉及在各种策划数据集上使用聚合指标进行基准测试。不幸的是，这种模型比较方法严重依赖于度量指标的选择，这使得它在理想度量不明显或不可用的情况下不适用。在这项工作中，我们提出了一种没有度量指标的基础模型比较方法，通过它们的嵌入空间几何来实现。我们的方法基于随机图理论，并促进点对点和多模型比较。此外，我们展示了如何使用我们的框架诱导一组配备有与一些下游指标强相关的距离函数的模型流形。

    Recent advances in self-supervised learning and neural network scaling have enabled the creation of large models -- known as foundation models -- which can be easily adapted to a wide range of downstream tasks. The current paradigm for comparing foundation models involves benchmarking them with aggregate metrics on various curated datasets. Unfortunately, this method of model comparison is heavily dependent on the choice of metric, which makes it unsuitable for situations where the ideal metric is either not obvious or unavailable. In this work, we present a metric-free methodology for comparing foundation models via their embedding space geometry. Our methodology is grounded in random graph theory, and facilitates both pointwise and multi-model comparison. Further, we demonstrate how our framework can be used to induce a manifold of models equipped with a distance function that correlates strongly with several downstream metrics.
    
[^105]: 带参数知识引导的增强型大语言模型

    Augmented Large Language Models with Parametric Knowledge Guiding. (arXiv:2305.04757v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.04757](http://arxiv.org/abs/2305.04757)

    这篇论文提出了一种带参数知识引导的增强型大语言模型框架，通过为LLMs装备信息引导模块来访问相关知识，同时保持LLMs的参数不变。这个框架可以提高黑盒LLMs在各种NLP任务上的性能。

    

    大型语言模型 (LLM) 以其出色的语言理解和生成能力，极大地推进了自然语言处理（NLP）。但是，由于对相关数据的有限接触，它们在需要专业知识的领域特定任务上的表现可能不够优化。此外，大多数最先进的 LLM 缺乏透明度，只能通过 API 访问, 这阻止了进一步用领域定制数据进行微调。此外，向 LLM 所有者提供私有数据会导致数据隐私问题。为解决这些挑战，我们提出了新型的带参数知识引导 (PKG) 框架，该框架为 LLM 配备了知识引导模块，以访问相关知识，而无需改变 LLM 的参数。我们的 PKG 基于开源的“白盒”语言模型，允许离线存储 LLM 需要的任何知识。我们证明了我们的 PKG 框架可以提高“黑盒”LLM在各种NLP任务上的性能。

    Large Language Models (LLMs) have significantly advanced natural language processing (NLP) with their impressive language understanding and generation capabilities. However, their performance may be suboptimal for domain-specific tasks that require specialized knowledge due to limited exposure to the related data. Additionally, the lack of transparency of most state-of-the-art (SOTA) LLMs, which can only be accessed via APIs, impedes further fine-tuning with domain custom data. Moreover, providing private data to the LLMs' owner leads to data privacy problems. To address these challenges, we propose the novel Parametric Knowledge Guiding (PKG) framework, which equips LLMs with a knowledge-guiding module to access relevant knowledge without altering the LLMs' parameters. Our PKG is based on open-source "white-box" language models, allowing offline memory of any knowledge that LLMs require. We demonstrate that our PKG framework can enhance the performance of "black-box" LLMs on a range o
    
[^106]: LLM2Loss: 利用语言模型进行可解释的模型诊断

    LLM2Loss: Leveraging Language Models for Explainable Model Diagnostics. (arXiv:2305.03212v1 [cs.CV])

    [http://arxiv.org/abs/2305.03212](http://arxiv.org/abs/2305.03212)

    LLM2Loss利用语言模型为黑盒模型提供可解释的模型诊断，通过提取数据点的语义特征，揭示导致模型失败和偏差的因素。

    

    在大量数据的训练下，大型语言模型已经在抽象空间中对相当复杂的文本输入进行建模，取得了前所未有的成功和概括能力，从而成为了零样本学习的强大工具。这种能力可以通过跨模态基础模型，如CLIP，来扩展到其他模态，如视觉域，从而可以从视觉输入中提取语义上有意义的表示。在本文中，我们利用这种能力，并提出一种方法，可以提供模型失败和偏差模式的语义见解。对于给定的黑盒模型，其训练数据和任务定义，我们首先计算其每个数据点的任务相关损失。然后，我们提取每个训练数据点的语义上有意义的表示（例如来自其视觉编码器的CLIP嵌入），并训练一个轻量级的诊断模型，将这个数据点的语义上有意义的表示映射到其任务损失。我们展示了该方法不仅可以识别对模型难以学习的数据点，而且可以识别导致模型失败和偏差的因素。

    Trained on a vast amount of data, Large Language models (LLMs) have achieved unprecedented success and generalization in modeling fairly complex textual inputs in the abstract space, making them powerful tools for zero-shot learning. Such capability is extended to other modalities such as the visual domain using cross-modal foundation models such as CLIP, and as a result, semantically meaningful representation are extractable from visual inputs.  In this work, we leverage this capability and propose an approach that can provide semantic insights into a model's patterns of failures and biases. Given a black box model, its training data, and task definition, we first calculate its task-related loss for each data point. We then extract a semantically meaningful representation for each training data point (such as CLIP embeddings from its visual encoder) and train a lightweight diagnosis model which maps this semantically meaningful representation of a data point to its task loss. We show 
    
[^107]: 各种神经机器翻译的统一模型学习

    Unified Model Learning for Various Neural Machine Translation. (arXiv:2305.02777v1 [cs.CL])

    [http://arxiv.org/abs/2305.02777](http://arxiv.org/abs/2305.02777)

    本文提出了一种统一学习方法，即统一模型学习，可以同时适用于翻译各种任务数据，并实现智能按需翻译，相对现有的特定数据集模型能够得到明显的改进。

    

    现有的神经机器翻译(NMT)研究主要集中在根据来自不同任务(例如，文档翻译和聊天翻译)的数据开发特定于数据集的模型。虽然特定于数据集的模型已经取得了令人瞩目的性能，但每个数据集需要设计、训练和存储一个模型，这很麻烦。在这项工作中，我们的目标是将这些翻译任务统一到更普遍的设置中。具体而言，我们提出了一个“多才多艺”的模型，即适用于不同任务数据的统一模型学习(NMT)，可以同时在多种环境下进行良好的翻译，并在理论上可以尽可能多地扩展。通过统一学习，UMLNMT能够跨多个任务进行联合训练，实现智能按需翻译。在七个广泛使用的翻译任务，包括句子翻译、文档翻译和聊天翻译中，我们的UMLNMT相对于特定数据集模型表现出了明显的改进。

    Existing neural machine translation (NMT) studies mainly focus on developing dataset-specific models based on data from different tasks (e.g., document translation and chat translation). Although the dataset-specific models have achieved impressive performance, it is cumbersome as each dataset demands a model to be designed, trained, and stored. In this work, we aim to unify these translation tasks into a more general setting. Specifically, we propose a ``versatile'' model, i.e., the Unified Model Learning for NMT (UMLNMT) that works with data from different tasks, and can translate well in multiple settings simultaneously, and theoretically it can be as many as possible. Through unified learning, UMLNMT is able to jointly train across multiple tasks, implementing intelligent on-demand translation. On seven widely-used translation tasks, including sentence translation, document translation, and chat translation, our UMLNMT results in substantial improvements over dataset-specific model
    
[^108]: ARBEx：用于鲁棒性面部表情学习的关注特征提取与可靠性平衡框架

    ARBEx: Attentive Feature Extraction with Reliability Balancing for Robust Facial Expression Learning. (arXiv:2305.01486v1 [cs.CV])

    [http://arxiv.org/abs/2305.01486](http://arxiv.org/abs/2305.01486)

    本论文提出了一个名为ARBEx的框架，它采用了可靠性平衡方法来应对面部表情学习任务中的数据偏差和不确定性。该框架还引入了可学习的锚点和多头自注意机制，并在多个公共数据集上取得了有效性验证。

    

    本论文提出了一个名为ARBEx的框架，它是由Vision Transformer驱动的新型关注特征提取框架，带有可靠性平衡，以应对面部表情学习任务中的较差类分布、偏差和不确定性。我们采用了多种数据预处理和精化方法以及基于窗口的交叉关注ViT来充分利用数据。我们还在嵌入空间中引入了可学习的锚点，加上标签分布和多头自注意机制，以通过可靠性平衡优化对弱预测的性能，这是一种提高标签预测韧性的策略。为了确保正确的标签分类并提高模型的区分能力，我们引入了锚损失，鼓励锚点之间的大间隔。另外，多头自注意机制也是可训练的，对于提升在FEL任务中的表现至关重要。最后，我们在多个公共数据集上验证了ARBEx的有效性。

    In this paper, we introduce a framework ARBEx, a novel attentive feature extraction framework driven by Vision Transformer with reliability balancing to cope against poor class distributions, bias, and uncertainty in the facial expression learning (FEL) task. We reinforce several data pre-processing and refinement methods along with a window-based cross-attention ViT to squeeze the best of the data. We also employ learnable anchor points in the embedding space with label distributions and multi-head self-attention mechanism to optimize performance against weak predictions with reliability balancing, which is a strategy that leverages anchor points, attention scores, and confidence values to enhance the resilience of label predictions. To ensure correct label classification and improve the models' discriminative power, we introduce anchor loss, which encourages large margins between anchor points. Additionally, the multi-head self-attention mechanism, which is also trainable, plays an i
    
[^109]: 深度强化学习的后验采样

    Posterior Sampling for Deep Reinforcement Learning. (arXiv:2305.00477v1 [cs.LG])

    [http://arxiv.org/abs/2305.00477](http://arxiv.org/abs/2305.00477)

    本文提出了用于深度强化学习的后验采样算法PSDRL，结合了高效的不确定性量化和特殊设计的持续规划算法，使其在提高样本效率的同时显著优于之前的尝试。

    

    尽管深度强化学习算法取得了显著的成功，但样本效率仍然较低：它们需要大量的试错来找到好的策略。基于模型的算法通过构建可以用于规划的环境模型来提高样本效率。后验采样强化学习是这样一种基于模型的算法，在表格设置中由于其性能而引起了广泛的兴趣。本文介绍了用于深度强化学习的后验采样（PSDRL），这是第一个真正可扩展的后验采样强化学习的近似方法，保留了其基于模型的本质特征。PSDRL将潜在状态空间模型上的高效不确定性量化与基于值函数逼近的特殊设计的持续规划算法相结合。对Atari基准测试的广泛实验表明，PSDRL在提高样本效率的同时，显著优于以前的最先进尝试。

    Despite remarkable successes, deep reinforcement learning algorithms remain sample inefficient: they require an enormous amount of trial and error to find good policies. Model-based algorithms promise sample efficiency by building an environment model that can be used for planning. Posterior Sampling for Reinforcement Learning is such a model-based algorithm that has attracted significant interest due to its performance in the tabular setting. This paper introduces Posterior Sampling for Deep Reinforcement Learning (PSDRL), the first truly scalable approximation of Posterior Sampling for Reinforcement Learning that retains its model-based essence. PSDRL combines efficient uncertainty quantification over latent state space models with a specially tailored continual planning algorithm based on value-function approximation. Extensive experiments on the Atari benchmark show that PSDRL significantly outperforms previous state-of-the-art attempts at scaling up posterior sampling while being 
    
[^110]: 训练中结合对手和反对手。

    Combining Adversaries with Anti-adversaries in Training. (arXiv:2304.12550v1 [cs.LG])

    [http://arxiv.org/abs/2304.12550](http://arxiv.org/abs/2304.12550)

    该论文研究了在对抗训练中，通过结合对手和反对手(带有反对手扰动的样本)可以更有效地提高深度神经网络的公平性、鲁棒性和泛化性，在一些特定的学习场景中表现出更好的性能。

    

    对抗训练是提高深度神经网络健壮性的有效学习技术。本研究在更一般的扰动范围下理论上研究了对抗训练对深度学习模型的公平性、鲁棒性和泛化性的影响。我们的理论探索表明，将对手和反对手 (带有反对手扰动的样本) 结合在训练中，在一些典型的学习场景 (如噪声标签学习和不平衡学习) 中能够更有效地实现更好的类别间公平性和鲁棒性和泛化性之间的平衡，相比于标准对抗训练。

    Adversarial training is an effective learning technique to improve the robustness of deep neural networks. In this study, the influence of adversarial training on deep learning models in terms of fairness, robustness, and generalization is theoretically investigated under more general perturbation scope that different samples can have different perturbation directions (the adversarial and anti-adversarial directions) and varied perturbation bounds. Our theoretical explorations suggest that the combination of adversaries and anti-adversaries (samples with anti-adversarial perturbations) in training can be more effective in achieving better fairness between classes and a better tradeoff between robustness and generalization in some typical learning scenarios (e.g., noisy label learning and imbalance learning) compared with standard adversarial training. On the basis of our theoretical findings, a more general learning objective that combines adversaries and anti-adversaries with varied b
    
[^111]: DEIR: 基于区分性模型的情节内在奖励，高效且鲁棒的探索方法

    DEIR: Efficient and Robust Exploration through Discriminative-Model-Based Episodic Intrinsic Rewards. (arXiv:2304.10770v1 [cs.LG])

    [http://arxiv.org/abs/2304.10770](http://arxiv.org/abs/2304.10770)

    提出了一种探索强化学习算法DEIR，借助区分性模型实现理论上导出的内在奖励，能够高效且鲁棒地进行探索，适用于面对外部奖励稀疏的情况。

    

    探索是强化学习中的一个基本方面，其有效性关键地影响着强化学习算法的性能，尤其是面对稀疏的外部奖励时更为重要。最近的研究表明，从观测中估计新颖性的内在奖励可以有效鼓励探索。然而，由于环境的随机性以及代理的行为可能会影响观察结果，因此一个观测的新颖性与探索之间存在差距。为了准确估计探索行为，我们提出了DEIR，一种新颖的方法，其中我们从条件互信息项中理论上导出内在奖励，该奖励主要与代理的探索行为所贡献的新颖性成比例，并借助区分性的前向模型实现奖励。我们在MiniGrid中进行了广泛的实验，包括标准和硬核探索游戏，在结果上DEIR比基线学习更快并且具有更高的成功率和鲁棒性，适应环境动态变化。

    Exploration is a fundamental aspect of reinforcement learning (RL), and its effectiveness crucially decides the performance of RL algorithms, especially when facing sparse extrinsic rewards. Recent studies showed the effectiveness of encouraging exploration with intrinsic rewards estimated from novelty in observations. However, there is a gap between the novelty of an observation and an exploration in general, because the stochasticity in the environment as well as the behavior of an agent may affect the observation. To estimate exploratory behaviors accurately, we propose DEIR, a novel method where we theoretically derive an intrinsic reward from a conditional mutual information term that principally scales with the novelty contributed by agent explorations, and materialize the reward with a discriminative forward model. We conduct extensive experiments in both standard and hardened exploration games in MiniGrid to show that DEIR quickly learns a better policy than baselines. Our eval
    
[^112]: H2RBox-v2：通过对称学习提高基于HBox监督的有向物体检测

    H2RBox-v2: Boosting HBox-supervised Oriented Object Detection via Symmetric Learning. (arXiv:2304.04403v1 [cs.CV])

    [http://arxiv.org/abs/2304.04403](http://arxiv.org/abs/2304.04403)

    H2RBox-v2是第一个将对称学习应用于基于HBox监督的有向物体检测，其强化了水平注释和旋转注释之间的联系，在多个基准测试中实现了最先进的性能。

    

    随着对于自动驾驶和遥感等有向物体检测需求的日益增长，有向注释变得非常费力。为了充分利用现有的水平注释数据集并降低注释成本，已经提出了一种弱监督检测器H2RBox，用于从水平框Box中学习旋转框RBox，并受到了广泛关注。本文介绍了H2RBox-v2的新版本，以进一步弥合HBox监督和RBox监督的有向物体检测之间的差距。通过我们的理论分析，利用翻转和旋转一致性来开发轴对称性是可行的，H2RBox-v2则采用与H2RBox类似的弱监督分支，并嵌入一个新颖的自监督分支，它可以从对象图像中固有的对称性中学习方向。通过处理周边问题的模块（例如角周期性），实现了一种稳定而有效的解决方案。据我们所知，H2RBox-v2是第一个将对称学习应用于基于HBox监督的有向物体检测，并在多个基准测试中实现了最先进的性能。

    With the increasing demand for oriented object detection e.g. in autonomous driving and remote sensing, the oriented annotation has become a labor-intensive work. To make full use of existing horizontally annotated datasets and reduce the annotation cost, a weakly-supervised detector H2RBox for learning the rotated box (RBox) from the horizontal box (HBox) has been proposed and received great attention. This paper presents a new version, H2RBox-v2, to further bridge the gap between HBox-supervised and RBox-supervised oriented object detection. While exploiting axisymmetry via flipping and rotating consistencies is available through our theoretical analysis, H2RBox-v2, using a weakly-supervised branch similar to H2RBox, is embedded with a novel self-supervised branch that learns orientations from the symmetry inherent in the image of objects. Complemented by modules to cope with peripheral issues, e.g. angular periodicity, a stable and effective solution is achieved. To our knowledge, H
    
[^113]: 社会文化知识在仇恨言论检测任务中对选项的选择是必要的

    Sociocultural knowledge is needed for selection of shots in hate speech detection tasks. (arXiv:2304.01890v1 [cs.CL])

    [http://arxiv.org/abs/2304.01890](http://arxiv.org/abs/2304.01890)

    HATELEXICON是一个包含巴西，德国，印度和肯尼亚仇恨言论的词汇表，利用其可以提高模型在训练中的性能表现。

    

    我们引入了HATELEXICON，这是一个包含巴西，德国，印度和肯尼亚的蔑称和仇恨言论目标的词汇表，以帮助模型的训练和可解释性。我们展示了我们的词汇表如何用于解释模型预测，表明发展用于分类极端言论的模型，在进行预测时严重依赖目标词。此外，我们提出了一种通过HATELEXICON来辅助低资源环境下训练选项的方法，选项选择在小样本学习中尤为重要。在我们的工作中，我们使用HASOC数据对德语和印地语进行了几个示范学习，并将Multilingual HateCheck（MHC）作为基准。我们展示了根据我们的词汇表选择样本，相对于随机采样的模型，能够更好地在MHC上表现。因此，当仅有少量的训练样本时，使用我们的词汇表来选择包含更多社会文化信息的样本能够更好地提高在仇恨言论检测任务中的性能。

    We introduce HATELEXICON, a lexicon of slurs and targets of hate speech for the countries of Brazil, Germany, India and Kenya, to aid training and interpretability of models. We demonstrate how our lexicon can be used to interpret model predictions, showing that models developed to classify extreme speech rely heavily on target words when making predictions. Further, we propose a method to aid shot selection for training in low-resource settings via HATELEXICON. In few-shot learning, the selection of shots is of paramount importance to model performance. In our work, we simulate a few-shot setting for German and Hindi, using HASOC data for training and the Multilingual HateCheck (MHC) as a benchmark. We show that selecting shots based on our lexicon leads to models performing better on MHC than models trained on shots sampled randomly. Thus, when given only a few training examples, using our lexicon to select shots containing more sociocultural information leads to better few-shot perf
    
[^114]: 神经网络熵(NNetEn)：基于熵特征的脑电信号和混沌时间序列分离，用于NNetEn计算的Python包

    Neural Network Entropy (NNetEn): EEG Signals and Chaotic Time Series Separation by Entropy Features, Python Package for NNetEn Calculation. (arXiv:2303.17995v1 [cs.LG])

    [http://arxiv.org/abs/2303.17995](http://arxiv.org/abs/2303.17995)

    该研究提出了一种新的熵估计方法NNetEn，用于有效地分离时间序列系统的混沌动态，并在分离混沌时间序列方面证明了其高效率。

    

    熵测量是时间序列分类问题中有效的特征。传统的熵测量方法，例如香农熵，使用概率分布函数。然而，为了有效地分离时间序列，需要新的熵估计方法来表征系统的混沌动态。我们的神经网络熵(NNetEn)概念是基于特殊数据集(MNIST-10和SARS-CoV-2-RBV1)的分类，这些数据集与记录在LogNNet神经网络储层中的时间序列熵相关。NNetEn以原始方式估计时间序列的混沌动态。基于NNetEn算法，我们提出了两个新的分类度量：R2效率和皮尔逊效率。NNetEn的效率在使用离散分析(ANOVA)分离正弦映射的两个混沌时间序列方面得到验证。对于两个接近的动态时间序列 (r=1.1918和r=1.2243)，F比值达到了124的值，反映了高效率。

    Entropy measures are effective features for time series classification problems. Traditional entropy measures, such as Shannon entropy, use probability distribution function. However, for the effective separation of time series, new entropy estimation methods are required to characterize the chaotic dynamic of the system. Our concept of Neural Network Entropy (NNetEn) is based on the classification of special datasets (MNIST-10 and SARS-CoV-2-RBV1) in relation to the entropy of the time series recorded in the reservoir of the LogNNet neural network. NNetEn estimates the chaotic dynamics of time series in an original way. Based on the NNetEn algorithm, we propose two new classification metrics: R2 Efficiency and Pearson Efficiency. The efficiency of NNetEn is verified on separation of two chaotic time series of sine mapping using dispersion analysis (ANOVA). For two close dynamic time series (r = 1.1918 and r = 1.2243), the F-ratio has reached the value of 124 and reflects high efficien
    
[^115]: 注意力！（不）专注代理人的动态认知逻辑模型

    Attention! Dynamic Epistemic Logic Models of (In)attentive Agents. (arXiv:2303.13494v1 [cs.AI])

    [http://arxiv.org/abs/2303.13494](http://arxiv.org/abs/2303.13494)

    本文提出了一种更一般化的动态认知逻辑模型，允许代理人关注一些原子公式的子集，并扩展了该框架，以解释无注意瞎视现象。

    

    注意力是限制和选择我们观察到的信息的关键认知能力。本文提出了一种基于动态认知逻辑（DEL）的注意力模型，其中代理人要么完全专注，要么完全不关注。我们提出了一种更一般化的模型，允许代理人关注一些原子公式的子集。我们介绍了命题注意力的相应逻辑，并证明了其公理系统的准确性和完备性。进一步地，我们扩展了该框架，以解释无注意瞎视现象。

    Attention is the crucial cognitive ability that limits and selects what information we observe. Previous work by Bolander et al. (2016) proposes a model of attention based on dynamic epistemic logic (DEL) where agents are either fully attentive or not attentive at all. While introducing the realistic feature that inattentive agents believe nothing happens, the model does not represent the most essential aspect of attention: its selectivity. Here, we propose a generalization that allows for paying attention to subsets of atomic formulas. We introduce the corresponding logic for propositional attention, and show its axiomatization to be sound and complete. We then extend the framework to account for inattentive agents that, instead of assuming nothing happens, may default to a specific truth-value of what they failed to attend to (a sort of prior concerning the unattended atoms). This feature allows for a more cognitively plausible representation of the inattentional blindness phenomenon
    
[^116]: 合并决策Transformer：多任务策略形成的权重平均化

    Merging Decision Transformers: Weight Averaging for Forming Multi-Task Policies. (arXiv:2303.07551v1 [cs.LG])

    [http://arxiv.org/abs/2303.07551](http://arxiv.org/abs/2303.07551)

    本文提出通过在权重空间中合并训练于不同 MuJoCo 运动问题上的 Decision Transformer 的子集，形成多任务模型。通过共享一些辅助任务的训练以及共同使用预训练初始化，能够获得更好的结果。这个方向的研究有助于使代理的过程民主化和分发。

    

    最近的研究展示了基于Transformer的通用语言、视觉和连续决策制定问题的策略的前景。为了创建这样的模型，我们通常需要集中的训练目标、数据和计算。如果我们能够更灵活地创建通用策略，通过合并多个任务特定的、单独训练的策略，则这样做就比较有意义。在本文中，我们通过在权重空间中合并或平均不同MuJoCo运动问题上训练的Decision Transformer的子集来迈出这个方向的初步步骤，形成没有集中训练的多任务模型。我们还建议在合并策略时可以获得更好的结果，如果所有策略都从共同的预训练初始化开始，并在问题特定的微调期间共同训练共享的辅助任务。一般来说，我们相信这个方向的研究可以帮助民主化和分发具有一般能力的代理的过程。

    Recent work has shown the promise of creating generalist, transformer-based, policies for language, vision, and sequential decision-making problems. To create such models, we generally require centralized training objectives, data, and compute. It is of interest if we can more flexibly create generalist policies, by merging together multiple, task-specific, individually trained policies. In this work, we take a preliminary step in this direction through merging, or averaging, subsets of Decision Transformers in weight space trained on different MuJoCo locomotion problems, forming multi-task models without centralized training. We also propose that when merging policies, we can obtain better results if all policies start from common, pre-trained initializations, while also co-training on shared auxiliary tasks during problem-specific finetuning. In general, we believe research in this direction can help democratize and distribute the process of which forms generally capable agents.
    
[^117]: UNFUSED: 使用自监督蒸馏的无监督微调方法

    UNFUSED: UNsupervised Finetuning Using SElf supervised Distillation. (arXiv:2303.05668v2 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2303.05668](http://arxiv.org/abs/2303.05668)

    本文提出了一种使用自监督蒸馏的无监督微调方法，可以通过生成伪标签来减少音频分类所需的标注数据量。

    

    本文提出了一种名为 UnFuSeD 的新方法，利用自监督学习技术，减少音频分类所需的标注数据量。与以往的方法不同，直接在目标数据集上对自监督预训练的编码器进行微调，我们使用编码器为无监督微调产生伪标签。首先，我们使用一种新型的自监督学习算法在未标注的音频数据集上训练编码器。然后，通过提取的表示进行聚类，使用编码器生成伪标签。这些伪标签用于指导随机初始化模型上的自蒸馏，我们将其称为无监督微调。最终，结果编码器在目标任务数据集上进行微调。通过 UnFuSeD，我们提出了第一个与文献中的通用自监督学习方法不同的系统，即预训练和微调相同的编码器，提出了一种利用自监督学习和无监督微调方法减少对标注数据的依赖来进行音频分类的方法。

    In this paper, we introduce UnFuSeD, a novel approach to leverage self-supervised learning and reduce the need for large amounts of labeled data for audio classification. Unlike prior works, which directly fine-tune a self-supervised pre-trained encoder on a target dataset, we use the encoder to generate pseudo-labels for unsupervised fine-tuning before the actual fine-tuning step. We first train an encoder using a novel self-supervised learning algorithm (SSL) on an unlabeled audio dataset. Then, we use that encoder to generate pseudo-labels on our target task dataset via clustering the extracted representations. These pseudo-labels are then used to guide self-distillation on a randomly initialized model, which we call unsupervised fine-tuning. Finally, the resultant encoder is then fine-tuned on our target task dataset. Through UnFuSeD, we propose the first system that moves away from generic SSL paradigms in literature, which pre-train and fine-tune the same encoder, and present a n
    
[^118]: 论文标题：认证鲁棒神经网络：泛化和抗污染性

    Certified Robust Neural Networks: Generalization and Corruption Resistance. (arXiv:2303.02251v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2303.02251](http://arxiv.org/abs/2303.02251)

    该论文提出了一种新颖的分布鲁棒损失函数，该函数通过认证级别的鲁棒性对两种常见的污染类型进行抵抗，并确保泛化保证，从而解决了鲁棒性和泛化之间的矛盾，具有极高的实用性。

    

    最近的研究表明，鲁棒性（对“污染”的抵抗能力）可能与泛化存在矛盾。例如，对抗性训练旨在减少现代神经网络对小数据扰动的敏感性。令人惊讶的是，在对抗训练中，过拟合是一个主要问题，尽管在标准训练中几乎不存在。我们在这里提供了关于这种奇特的“鲁棒过拟合”现象的理论证据。随后，我们提出了一种新颖的分布鲁棒损失函数，将鲁棒性和泛化相结合。我们理论上和实证地证明了该损失具有认证级别的鲁棒性，可以抵抗两种常见的污染类型——数据逃避和攻击——同时确保泛化保证。通过精心设计的数字实验，我们展示了所得到的完整鲁棒（HR）训练程序具有SOTA的性能。最后，我们指出HR训练可以被解释为对抗性训练的直接扩展，并可以自然地应用于GAN和RL。

    Recent work have demonstrated that robustness (to "corruption") can be at odds with generalization. Adversarial training, for instance, aims to reduce the problematic susceptibility of modern neural networks to small data perturbations. Surprisingly, overfitting is a major concern in adversarial training despite being mostly absent in standard training. We provide here theoretical evidence for this peculiar "robust overfitting" phenomenon. Subsequently, we advance a novel distributionally robust loss function bridging robustness and generalization. We demonstrate both theoretically as well as empirically the loss to enjoy a certified level of robustness against two common types of corruption--data evasion and poisoning attacks--while ensuring guaranteed generalization. We show through careful numerical experiments that our resulting holistic robust (HR) training procedure yields SOTA performance. Finally, we indicate that HR training can be interpreted as a direct extension of adversar
    
[^119]: 探索基于数值先验的广义CP分解低秩张量补全算法

    Exploring Numerical Priors for Low-Rank Tensor Completion with Generalized CP Decomposition. (arXiv:2302.05881v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.05881](http://arxiv.org/abs/2302.05881)

    本文提出了一种新的方法框架GCDTC，利用数值先验和广义CP分解实现了更高的低秩张量补全精度；同时介绍了一个算法SPTC，作为该框架的一个实现。在实验中，该方法表现出比现有技术更好的性能。

    

    张量补全在计算机视觉、数据分析和信号处理等领域中具有重要意义。最近，低秩张量补全这一类别的方法得到了广泛研究，对补全张量施加低秩结构。虽然这些方法取得了巨大成功，但尚未考虑到张量元素的数值先验信息。忽略数值先验将导致丢失关于数据的重要信息，因此阻止算法达到最优精度。本研究试图构建一个新的方法框架，名为GCDTC（广义CP分解张量补全），以利用数值先验并实现更高的张量补全精度。在这个新引入的框架中，将广义的CP分解应用于低秩张量补全。本文还提出了一种名为SPTC（平滑泊松张量补全）的算法，用于非负整数张量补全，作为GCDTC框架的一个实现。通过对合成和真实世界数据集的大量实验，证明所提出的方法相比于现有技术具有更优的张量补全性能。

    Tensor completion is important to many areas such as computer vision, data analysis, and signal processing. Enforcing low-rank structures on completed tensors, a category of methods known as low-rank tensor completion has recently been studied extensively. While such methods attained great success, none considered exploiting numerical priors of tensor elements. Ignoring numerical priors causes loss of important information regarding the data, and therefore prevents the algorithms from reaching optimal accuracy. This work attempts to construct a new methodological framework called GCDTC (Generalized CP Decomposition Tensor Completion) for leveraging numerical priors and achieving higher accuracy in tensor completion. In this newly introduced framework, a generalized form of CP Decomposition is applied to low-rank tensor completion. This paper also proposes an algorithm known as SPTC (Smooth Poisson Tensor Completion) for nonnegative integer tensor completion as an instantiation of the G
    
[^120]: 历史依赖动态环境下的强化学习

    Reinforcement Learning with History-Dependent Dynamic Contexts. (arXiv:2302.02061v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.02061](http://arxiv.org/abs/2302.02061)

    介绍了一种称为DCMDPs的新型强化学习框架，用于处理依赖历史环境的情况。其中的逻辑DCMDPs通过利用聚合函数确定上下文转换，打破了对历史长度的指数依赖，并引入了一种实用的基于模型的算法。在推荐任务中展示了该方法的有效性。

    

    我们引入了动态上下文马尔可夫决策过程（DCMDPs），这是一种新的强化学习框架，用于处理依赖历史环境的情况。它推广了上下文MDP框架，以处理非马尔可夫环境，其中上下文随时间变化。我们考虑了这个模型的特殊情况，着重于逻辑DCMDPs，它通过利用聚合函数确定上下文转换来打破对历史长度的指数依赖。这种特殊结构使我们能够推导出一种类似于上限置信界算法的算法，并建立了遗憾界。受我们的理论结果的启发，我们引入了一种实用的基于模型的算法，用于逻辑DCMDPs，这个算法在一个潜在空间中进行规划，并使用历史依赖特征上的乐观主义。我们在一个推荐任务上展示了我们方法的有效性（使用MovieLens数据集），其中用户行为动态地随着推荐的变化而演变。

    We introduce Dynamic Contextual Markov Decision Processes (DCMDPs), a novel reinforcement learning framework for history-dependent environments that generalizes the contextual MDP framework to handle non-Markov environments, where contexts change over time. We consider special cases of the model, with a focus on logistic DCMDPs, which break the exponential dependence on history length by leveraging aggregation functions to determine context transitions. This special structure allows us to derive an upper-confidence-bound style algorithm for which we establish regret bounds. Motivated by our theoretical results, we introduce a practical model-based algorithm for logistic DCMDPs that plans in a latent space and uses optimism over history-dependent features. We demonstrate the efficacy of our approach on a recommendation task (using MovieLens data) where user behavior dynamics evolve in response to recommendations.
    
[^121]: MILO: 模型无关子集选择框架，用于高效模型训练和调优。

    MILO: Model-Agnostic Subset Selection Framework for Efficient Model Training and Tuning. (arXiv:2301.13287v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.13287](http://arxiv.org/abs/2301.13287)

    提出了一个模型无关子集选择框架MILO，将子集选择与模型训练分离，通过易到难的课程实现了卓越的模型收敛和性能。

    

    训练深度网络和调优大型数据集的超参数是计算密集型的。减少训练成本的主要研究方向之一是通过选择很好的训练数据子集来实现。与简单的自适应随机子集选择基准相比，现有的智能子集选择方法由于耗时的子集选择步骤而不具竞争力，该步骤涉及计算依赖于模型的梯度和特征嵌入，并应用子模块目标的贪心最大化。我们的关键洞察是消除对下游模型参数的依赖，将子集选择作为预处理步骤，并使其能够在不增加成本的情况下训练多个模型。在这个工作中，我们提出了 MILO，一个模型无关的子集选择框架，它将子集选择与模型训练分离，同时通过使用一个易到难的课程实现了卓越的模型收敛和性能。通过实验结果验证了我们的方法。

    Training deep networks and tuning hyperparameters on large datasets is computationally intensive. One of the primary research directions for efficient training is to reduce training costs by selecting well-generalizable subsets of training data. Compared to simple adaptive random subset selection baselines, existing intelligent subset selection approaches are not competitive due to the time-consuming subset selection step, which involves computing model-dependent gradients and feature embeddings and applies greedy maximization of submodular objectives. Our key insight is that removing the reliance on downstream model parameters enables subset selection as a pre-processing step and enables one to train multiple models at no additional cost. In this work, we propose MILO, a model-agnostic subset selection framework that decouples the subset selection from model training while enabling superior model convergence and performance by using an easy-to-hard curriculum. Our empirical results in
    
[^122]: 基于语言模型的案例推理在逻辑谬误分类中的应用

    Case-Based Reasoning with Language Models for Classification of Logical Fallacies. (arXiv:2301.11879v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2301.11879](http://arxiv.org/abs/2301.11879)

    本文提出了一种基于案例推理的方法用于分类逻辑谬误的新案例，通过基于语言建模的检索和历史案例的调整来提高语言模型的准确性和泛化能力。

    

    在网络上传播虚假信息和宣传的容易和快捷性促使我们需要开发可靠的技术来检测自然语言论证中的谬误。然而，现有的语言建模方法在需要复杂推理的逻辑谬误分类等任务上表现出缺乏鲁棒性的特点。本文提出了一种基于案例推理的方法，该方法通过基于语言建模的检索和历史案例的调整来分类逻辑谬误的新案例。我们设计了四种互补的策略，基于有关目标、解释、反驳和论证结构的外部信息来丰富我们模型的输入表示。我们在领域内和领域外的实验表明，基于案例推理可以提高语言模型的准确性和泛化能力。我们的消融研究表明，类似案例的表示对模型性能有很大的影响，较少的历史案例也能使模型有良好性能。

    The ease and speed of spreading misinformation and propaganda on the Web motivate the need to develop trustworthy technology for detecting fallacies in natural language arguments. However, state-of-the-art language modeling methods exhibit a lack of robustness on tasks like logical fallacy classification that require complex reasoning. In this paper, we propose a Case-Based Reasoning method that classifies new cases of logical fallacy by language-modeling-driven retrieval and adaptation of historical cases. We design four complementary strategies to enrich input representation for our model, based on external information about goals, explanations, counterarguments, and argument structure. Our experiments in in-domain and out-of-domain settings indicate that Case-Based Reasoning improves the accuracy and generalizability of language models. Our ablation studies suggest that representations of similar cases have a strong impact on the model performance, that models perform well with fewe
    
[^123]: 领域无关的分子生成与自我反馈

    Domain-Agnostic Molecular Generation with Self-feedback. (arXiv:2301.11259v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.11259](http://arxiv.org/abs/2301.11259)

    MolGen是一个专注于分子生成的预训练语言模型，使用了领域无关的分子前缀调整和自我反馈的范式，实现了化学有效性、多样性、新颖性和复杂性的突破，在分子生成领域表现出了出色的性能。

    

    分子的生成已经受到极大的关注，其革新了科学家设计分子结构的方式，并为化学和药物设计提供了宝贵的支持。然而，尽管在分子生成中使用语言模型具有潜力，但它们面临着许多挑战，比如生成语法或化学存在缺陷的分子，狭窄的领域专注以及由于缺乏注释数据或外部分子数据库而限制了生成多样性和可行性。因此，我们引入了MolGen，它是一个专门用于分子生成的预训练分子语言模型。MolGen通过重构一亿多个分子SELFIES获得了固有的结构和语法概念，并通过领域无关的分子前缀调整促进了不同领域之间的知识传递。此外，我们提出了一种自我反馈范式，启发预训练模型与最终下游目标对齐，有助于更稳健和高效的分子生成。我们在基准数据集上的实验表明，MolGen在化学有效性，多样性，新颖性和复杂性方面优于现有技术。

    The generation of molecules with desired properties has gained tremendous popularity, revolutionizing the way scientists design molecular structures and providing valuable support for chemical and drug design. However, despite the potential of language models in molecule generation, they face numerous challenges such as the generation of syntactically or chemically flawed molecules, narrow domain focus, and limitations in creating diverse and directionally feasible molecules due to a dearth of annotated data or external molecular databases. To this end, we introduce MolGen, a pre-trained molecular language model tailored specifically for molecule generation. MolGen acquires intrinsic structural and grammatical insights by reconstructing over 100 million molecular SELFIES, while facilitating knowledge transfer between different domains through domain-agnostic molecular prefix tuning. Moreover, we present a self-feedback paradigm that inspires the pre-trained model to align with the ulti
    
[^124]: 通过Tutte定理基于混合布尔约束解决量子启发式完美匹配问题

    Solving Quantum-Inspired Perfect Matching Problems via Tutte's Theorem-Based Hybrid Boolean Constraints. (arXiv:2301.09833v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2301.09833](http://arxiv.org/abs/2301.09833)

    本文研究了混合布尔约束在量子计算中约束完美匹配问题的应用，提出了一种基于Tutte定理和优化技术的新编码方法，并证明其能够比竞争方法更好地扩展约束匹配基准。

    

    确定具有不同类型约束条件(即混合约束条件)的布尔约束满足性问题是一个得到广泛研究并有重要应用的问题。在本文中，我们研究了混合布尔约束的一个新应用，即在量子计算中出现的约束完美匹配问题。虽然通用的混合约束求解器可以很强大，但我们发现将约束匹配问题直接编码为混合约束的方法无法很好地扩展，并且仍需要特殊技术。我们提出了一种基于图论中的Tutte定理以及优化技术的新编码方法。实验结果表明，我们的编码在适当的语言和先进的SAT求解器中，比许多竞争方法更能扩展约束匹配基准。我们的研究确定了在应用强大的通用约束求解器时需要设计问题特定的编码的必要性。

    Determining the satisfiability of Boolean constraint-satisfaction problems with different types of constraints, that is hybrid constraints, is a well-studied problem with important applications. We study here a new application of hybrid Boolean constraints, which arises in quantum computing. The problem relates to constrained perfect matching in edge-colored graphs. While general-purpose hybrid constraint solvers can be powerful, we show that direct encodings of the constrained-matching problem as hybrid constraints scale poorly and special techniques are still needed. We propose a novel encoding based on Tutte's Theorem in graph theory as well as optimization techniques. Empirical results demonstrate that our encoding, in suitable languages with advanced SAT solvers, scales significantly better than a number of competing approaches on constrained-matching benchmarks. Our study identifies the necessity of designing problem-specific encodings when applying powerful general-purpose const
    
[^125]: Deanthropomorphising NLP：语言模型可以意识到吗？

    Deanthropomorphising NLP: Can a Language Model Be Conscious?. (arXiv:2211.11483v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.11483](http://arxiv.org/abs/2211.11483)

    本文讨论了关于使用Transformer架构的预训练语言模型LaMDA是否具有意识的说法。作者认为语言模型不可能具有意识，而LaMDA没有比其他类似模型更具先进性。

    

    本文旨在对最近有关使用Transformer模型架构的预训练语言模型LaMDA具有意识的说法进行讨论。我们认为这样的语言模型不可能具有意识，而LaMDA并没有比其他类似模型更具先进性。我们通过综合信息理论对Transformer架构进行分析来证明这一点。我们认为这些有意识的说法是NLP报道中使用拟人化语言的更广泛倾向的一部分。无论这些说法的真实性如何，我们认为现在是评估语言建模进展并考虑该任务的伦理影响的适当时机。为了使本文有助于NLP社区以外的读者，我们还提供了一些NLP基础知识的介绍。

    This work is intended as a voice in the discussion over the recent claims that LaMDA, a pretrained language model based on the Transformer model architecture, is sentient. This claim, if confirmed, would have serious ramifications in the Natural Language Processing (NLP) community due to wide-spread use of similar models. However, here we take the position that such a language model cannot be sentient, or conscious, and that LaMDA in particular exhibits no advances over other similar models that would qualify it. We justify this by analysing the Transformer architecture through Integrated Information Theory. We see the claims of consciousness as part of a wider tendency to use anthropomorphic language in NLP reporting. Regardless of the veracity of the claims, we consider this an opportune moment to take stock of progress in language modelling and consider the ethical implications of the task. In order to make this work helpful for readers outside the NLP community, we also present the
    
[^126]: SLICER: 利用低资源自监督预训练学习通用音频表示

    SLICER: Learning universal audio representations using low-resource self-supervised pre-training. (arXiv:2211.01519v2 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2211.01519](http://arxiv.org/abs/2211.01519)

    本文提出了一种名为SLICER的自监督学习方法，通过聚类和对比学习相结合的方式进行编码器预训练，从而得到可以广泛适用于语音和非语音任务的音频表示。

    

    我们提出了一种新的自监督学习方法，对未标记的音频数据进行编码器预训练，从而减少音频和语音分类所需的大量标记数据。我们的主要目标是在低资源未标记的音频预训练环境中学习可以概括大量语音和非语音任务的音频表示。受到聚类和对比学习范式在基于自监督学习的语音表示学习中的最近成功启发，我们提出了SLICER（实例和聚类级别高效表征的对称学习），将聚类和对比学习范式的优点结合起来。我们使用学生和教师编码器之间潜在表示之间的对称损失，并同时解决实例和聚类级别的对比学习任务。我们通过将输入的频谱图投影到与聚类数目相同的输出子空间中来在线获得聚类表示。

    We present a new Self-Supervised Learning (SSL) approach to pre-train encoders on unlabeled audio data that reduces the need for large amounts of labeled data for audio and speech classification. Our primary aim is to learn audio representations that can generalize across a large variety of speech and non-speech tasks in a low-resource un-labeled audio pre-training setting. Inspired by the recent success of clustering and contrasting learning paradigms for SSL-based speech representation learning, we propose SLICER (Symmetrical Learning of Instance and Cluster-level Efficient Representations), which brings together the best of both clustering and contrasting learning paradigms. We use a symmetric loss between latent representations from student and teacher encoders and simultaneously solve instance and cluster-level contrastive learning tasks. We obtain cluster representations online by just projecting the input spectrogram into an output subspace with dimensions equal to the number of
    
[^127]: MAST:多尺度音频谱图变压器

    MAST: Multiscale Audio Spectrogram Transformers. (arXiv:2211.01515v2 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2211.01515](http://arxiv.org/abs/2211.01515)

    MAST是一种多尺度音频谱图变压器，引入了多尺度特征分层概念，同时扩展嵌入维度，降低时间分辨率，用于音频分类。通过金字塔结构实现早期层和深层的建模，扩展方法为SS-MAST。

    

    本文提出了一种用于音频分类的多尺度音频谱图变压器（MAST），将多尺度特征分层概念引入音频谱图变换器（AST）中。给定一个输入的音频谱图，我们首先将其裁剪成初步的时间分辨率和嵌入维度，随后MAST中的多个阶段逐渐扩展嵌入维度，同时降低输入的时间分辨率。我们使用金字塔结构，使得MAST的早期层在高时间分辨率但低嵌入空间下建模简单的低级声学信息，而较深的时间粗糙层则用高维嵌入来建模高级声学信息。我们还扩展了我们的方法，提出了一种新的自监督学习（SSL）方法，称为SS-MAST，它计算了一个对称的对比损失，利用patch-drop - 一种新的音频增强技术来自学习和教师编码器的潜在表示之间。

    We present Multiscale Audio Spectrogram Transformer (MAST) for audio classification, which brings the concept of multiscale feature hierarchies to the Audio Spectrogram Transformer (AST). Given an input audio spectrogram, we first patchify and project it into an initial temporal resolution and embedding dimension, post which the multiple stages in MAST progressively expand the embedding dimension while reducing the temporal resolution of the input. We use a pyramid structure that allows early layers of MAST operating at a high temporal resolution but low embedding space to model simple low-level acoustic information and deeper temporally coarse layers to model high-level acoustic information with high-dimensional embeddings. We also extend our approach to present a new Self-Supervised Learning (SSL) method called SS-MAST, which calculates a symmetric contrastive loss between latent representations from a student and a teacher encoder, leveraging patch-drop, a novel audio augmentation a
    
[^128]: 基于部分信息分解的神经表示复杂度度量

    A Measure of the Complexity of Neural Representations based on Partial Information Decomposition. (arXiv:2209.10438v2 [cs.IT] UPDATED)

    [http://arxiv.org/abs/2209.10438](http://arxiv.org/abs/2209.10438)

    本文提出了一种基于部分信息分解的“表示复杂度”度量，用于量化跨多个神经元扩散的信息访问难度，并证明了其实用性。

    

    在神经网络中，与任务相关的信息通常是由神经元群联合表示的。然而，关于这种分类标签的互信息如何在单个神经元之间分配的细节尚不清楚：虽然部分互信息只能从特定的单个神经元中获得，但其他部分则由多个神经元冗余或协同承载。本文展示了如何使用信息论的部分信息分解来分离这些不同的贡献，并提出了“表示复杂度”度量，用于量化跨多个神经元扩散的信息访问难度。我们证明了如何直接计算较小层的复杂度，并针对较大层提出了子抽样和粗粒化过程，并证明了对应的上限。在MNIST和CIFAR10任务上，我们在量化的深度神经网络中观察到表示复杂度，证明了我们方法的实用性。

    In neural networks, task-relevant information is represented jointly by groups of neurons. However, the specific way in which this mutual information about the classification label is distributed among the individual neurons is not well understood: While parts of it may only be obtainable from specific single neurons, other parts are carried redundantly or synergistically by multiple neurons. We show how Partial Information Decomposition (PID), a recent extension of information theory, can disentangle these different contributions. From this, we introduce the measure of "Representational Complexity", which quantifies the difficulty of accessing information spread across multiple neurons. We show how this complexity is directly computable for smaller layers. For larger layers, we propose subsampling and coarse-graining procedures and prove corresponding bounds on the latter. Empirically, for quantized deep neural networks solving the MNIST and CIFAR10 tasks, we observe that representati
    
[^129]: DGPO: 使用多样化策略优化发现多种解决方案

    DGPO: Discovering Multiple Strategies with Diversity-Guided Policy Optimization. (arXiv:2207.05631v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2207.05631](http://arxiv.org/abs/2207.05631)

    这篇论文提出了一个名为DGPO的算法，可以在解决任务时发现多种策略，从而提高策略鲁棒性和与用户交互的乐趣。

    

    大多数强化学习算法都试图寻找解决给定任务的单个最佳策略。然而，学习多种解决方案通常是有价值的，例如，使智能体与用户的交互更加有趣，或者提高策略对意外干扰的鲁棒性。我们提出了一种名为多样化策略优化（DGPO）的在线算法，用于发现解决给定任务的多种策略。与现有工作不同的是，它通过在单次运行中训练共享策略网络实现此目的。具体而言，我们设计了一种基于信息理论多样性目标的内在奖励。我们的最终目标交替约束策略多样性和外在奖励。我们将约束优化问题转化为概率推断任务，并使用策略迭代来最大化得到的下界。实验结果表明，我们的方法能够在各种环境中有效地发现多样化的策略，包括 Atari 游戏和 Mujoco 模拟器，并且能够提供一系列性能和多样性之间的权衡。

    Most reinforcement learning algorithms seek a single optimal strategy that solves a given task. However, it can often be valuable to learn a diverse set of solutions, for instance, to make an agent's interaction with users more engaging, or improve the robustness of a policy to an unexpected perturbance. We propose Diversity-Guided Policy Optimization (DGPO), an on-policy algorithm that discovers multiple strategies for solving a given task. Unlike prior work, it achieves this with a shared policy network trained over a single run. Specifically, we design an intrinsic reward based on an information-theoretic diversity objective. Our final objective alternately constraints on the diversity of the strategies and on the extrinsic reward. We solve the constrained optimization problem by casting it as a probabilistic inference task and use policy iteration to maximize the derived lower bound. Experimental results show that our method efficiently discovers diverse strategies in a wide variet
    
[^130]: Transformer配置与训练目标的研究

    A Study on Transformer Configuration and Training Objective. (arXiv:2205.10505v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.10505](http://arxiv.org/abs/2205.10505)

    本文提出了Bamboo配置策略，基于更深更窄的Transformer结构进行Masked自编码器训练，在图像和语言任务上取得了新的最先进结果。

    

    基于Transformer的模型在许多任务，特别是视觉和语言任务上都取得了令人印象深刻的结果。在许多模型训练情况下，通常采用传统的配置。本文重新审视了这些传统配置，通过理论分析和实验评估，提出了Bamboo的配置策略，该策略使用更深更窄的Transformer结构进行Masked自编码器训练，并取得了新的最先进结果。

    Transformer-based models have delivered impressive results on many tasks, particularly vision and language tasks. In many model training situations, conventional configurations are typically adopted. For example, we often set the base model with hidden dimensions (i.e. model width) to be 768 and the number of transformer layers (i.e. model depth) to be 12. In this paper, we revisit these conventional configurations. Through theoretical analysis and experimental evaluation, we show that the masked autoencoder is effective in alleviating the over-smoothing issue in deep transformer training. Based on this finding, we propose Bamboo, an idea of using deeper and narrower transformer configurations, for masked autoencoder training. On ImageNet, with such a simple change in configuration, re-designed model achieves 87.1% top-1 accuracy and outperforms SoTA models like MAE and BEiT. On language tasks, re-designed model outperforms BERT with default setting by 1.1 points on average, on GLUE da
    
[^131]: 基于进化计算的肌电控制器的功耗设计

    Towards Power-Efficient Design of Myoelectric Controller based on Evolutionary Computation. (arXiv:2204.02179v2 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2204.02179](http://arxiv.org/abs/2204.02179)

    本文提出了一种基于核化SVM分类器的监督学习方法，通过约束的多目标优化问题实现肌电信号的高效控制，实验结果表明该方法在功率和分类准确性方面优于现有技术。

    

    肌电模式识别是各种应用程序（包括上肢假肢和生物机器人手部运动系统）的控制策略设计中的重要方面。本文提出了一种方法，通过考虑使用核化SVM分类器对表面肌电图（sEMG）信号的信息进行解码来推断潜在的肌肉运动，设计一种能量高效的基于EMG的控制器。为了实现EMG控制器的优化性能，我们的主要分类器设计策略是减少整个系统误动作（当EMG控制器处于“休息”位置时）。为此，与传统的软间隔核化SVM单个训练目标不同，我们将所提出的监督学习系统的训练算法制定为一般约束多目标优化问题。采用精英多目标进化算法NSGA-II来找到受限制的多目标优化问题的帕累托最优解，并根据支持向量的数量和分类准确率之间的权衡选择最终分类器。在公开可用的sEMG数据集上的实验结果表明，所提出的方法在功率效率和分类精度方面优于现有技术的方法。

    Myoelectric pattern recognition is one of the important aspects in the design of the control strategy for various applications including upper-limb prostheses and bio-robotic hand movement systems. The current work has proposed an approach to design an energy-efficient EMG-based controller by considering a supervised learning framework using a kernelized SVM classifier for decoding the information of surface electromyography (sEMG) signals to infer the underlying muscle movements. In order to achieve the optimized performance of the EMG-based controller, our main strategy of classifier design is to reduce the false movements of the overall system (when the EMG-based controller is at the `Rest' position). To this end, unlike the traditional single training objective of soft margin kernelized SVM, we have formulated the training algorithm of the proposed supervised learning system as a general constrained multi-objective optimization problem. An elitist multi-objective evolutionary algor
    
[^132]: 权重约束可满足性问题的超重参数化：性质与优化视角

    Super-Reparametrizations of Weighted CSPs: Properties and Optimization Perspective. (arXiv:2201.02018v2 [math.OC] UPDATED)

    [http://arxiv.org/abs/2201.02018](http://arxiv.org/abs/2201.02018)

    本文研究了超重参数化的概念与特性，提出了通过超重参数化计算WCSP最优值上界的框架，并在实验中证明了其有效性。

    

    “权重约束可满足性问题（WCSP）”的重参数化是一种很常见的算法，可以用来逼近或约束最优价值。相反，超重参数化的概念（即使得每个分配都保持或增加WCSP目标的权重改变）已经被提出，但从未被详细研究过。为了填补这一空白，我们提出了超重参数化的几个理论性质，并将其与重参数化进行了比较。此外，我们提出了一个框架，利用超重参数化计算WCSP的最优值的上界。我们展示了在技术条件下，原则上可以采用任意的约束传播规则来提高这种约束计算的效率。特别地，对于弧一致性，该方法可以减少到已知的虚拟弧一致性算法（VAC）中。我们在单例弧一致性WCSP中实现了该方法，并报告了实验结果，证明了其作为预处理步骤的有效性。

    The notion of reparametrizations of Weighted CSPs (WCSPs) (also known as equivalence-preserving transformations of WCSPs) is well-known and finds its use in many algorithms to approximate or bound the optimal WCSP value. In contrast, the concept of super-reparametrizations (which are changes of the weights that keep or increase the WCSP objective for every assignment) was already proposed but never studied in detail. To fill this gap, we present a number of theoretical properties of super-reparametrizations and compare them to those of reparametrizations. Furthermore, we propose a framework for computing upper bounds on the optimal value of the (maximization version of) WCSP using super-reparametrizations. We show that it is in principle possible to employ arbitrary (under some technical conditions) constraint propagation rules to improve the bound. For arc consistency in particular, the method reduces to the known Virtual AC (VAC) algorithm. We implemented the method for singleton arc
    
[^133]: 认知神经网络

    Epistemic Neural Networks. (arXiv:2107.08924v8 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2107.08924](http://arxiv.org/abs/2107.08924)

    该论文提出了一种能够通过适量级别的递增计算来估计神经网络不确定性的Epistemic神经网络框架，使得传统神经网络能够在计算成本大幅下降的情况下超越大型集成模型，为模型联合预测的方法提供了一种新的接口。

    

    智能依赖于智能体对其不知道的事物的了解。智能体预测多个输入标签的质量可以评估其对这种能力的掌握程度。集成式方法在原则上可以产生有效的预测，但训练大规模的集成模型的计算成本很高，从而可能会变得禁止。我们引入了Epinet：一种可以加强任何传统神经网络（包括大型预训练模型）的架构，并且可以通过适量级别的递增计算训练来估计不确定性。用Epinet，传统神经网络可以在计算成本大幅下降的情况下胜过由数百个或更多粒子组成的大型集成，同时不需要符合贝叶斯神经网络的传统框架。为了适应超越BNN的方法的发展，例如Epinet，我们介绍了作为产生联合预测模型的接口的知识神经网络（ENN）。

    Intelligence relies on an agent's knowledge of what it does not know. This capability can be assessed based on the quality of joint predictions of labels across multiple inputs. In principle, ensemble-based approaches produce effective joint predictions, but the computational costs of training large ensembles can become prohibitive. We introduce the epinet: an architecture that can supplement any conventional neural network, including large pretrained models, and can be trained with modest incremental computation to estimate uncertainty. With an epinet, conventional neural networks outperform very large ensembles, consisting of hundreds or more particles, with orders of magnitude less computation. The epinet does not fit the traditional framework of Bayesian neural networks. To accommodate development of approaches beyond BNNs, such as the epinet, we introduce the epistemic neural network (ENN) as an interface for models that produce joint predictions.
    
[^134]: 一个ODENet和ResNet的通用逼近性质：数学分析与数值实验

    Universal Approximation Properties for an ODENet and a ResNet: Mathematical Analysis and Numerical Experiments. (arXiv:2101.10229v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2101.10229](http://arxiv.org/abs/2101.10229)

    本论文证明了对于一类ODENet和一类ResNet，“宽度为n+m的ODENet可以逼近${\rm \mathbb{R}^n}$上紧致子集上的任何连续函数”，同时推导了损失函数对某个调整变量的梯度并用于构建ODENet的学习算法，并在MNIST上进行实验。

    

    我们证明了一类ODENet和一类ResNet的通用逼近性质(UAP)，它们是具有跳跃连接的深度学习系统的简化数学模型。 UAP可以陈述如下:设$n$和$m$分别为输入数据和输出数据的维数，并假设$m\leq n$。然后我们证明了带有非多项式连续激活函数的宽度为$n+m$的ODENet可以逼近$\mathbb {R} ^ n$上紧致子集上的任何连续函数。我们还证明了当深度趋于无限时，ResNet具有相同的性质。此外，我们明确推导了损失函数对某个调整变量的梯度。 我们将其用于构建ODENet的学习算法。为了展示此算法的实用性，我们将其应用于MNIST上的回归问题、二分类和多项分类。

    We prove a universal approximation property (UAP) for a class of ODENet and a class of ResNet, which are simplified mathematical models for deep learning systems with skip connections. The UAP can be stated as follows. Let $n$ and $m$ be the dimension of input and output data, and assume $m\leq n$. Then we show that ODENet of width $n+m$ with any non-polynomial continuous activation function can approximate any continuous function on a compact subset on $\mathbb{R}^n$. We also show that ResNet has the same property as the depth tends to infinity. Furthermore, we derive the gradient of a loss function explicitly with respect to a certain tuning variable. We use this to construct a learning algorithm for ODENet. To demonstrate the usefulness of this algorithm, we apply it to a regression problem, a binary classification, and a multinomial classification in MNIST.
    

