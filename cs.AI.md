# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [More Context, Less Distraction: Visual Classification by Inferring and Conditioning on Contextual Attributes.](http://arxiv.org/abs/2308.01313) | 本文借鉴了人类视觉感知过程，提出了一种通过推断和调节上下文属性来改进零样本图像分类的方法。通过给CLIP提供上下文属性，可以减轻对虚假特征的依赖，进而提高零样本分类的准确性。 |
| [^2] | [Lode Encoder: AI-constrained co-creativity.](http://arxiv.org/abs/2308.01312) | Lode Encoder是一个基于AI的共创性游戏关卡生成器，通过训练自编码器并结合用户设计，生成更加符合设计风格的关卡，鼓励设计师探索新的可能性。 |
| [^3] | [Flows: Building Blocks of Reasoning and Collaborating AI.](http://arxiv.org/abs/2308.01285) | Flows是一种系统化的方法，它通过将计算分解为自包含的构建模块，通过标准化的消息传递接口进行通信，实现了结构化的推理和协作人工智能。这种模块化设计使得Flows可以构建任意复杂度的交互，能够覆盖各种人工智能交互和工具增强的应用。 |
| [^4] | [Fighting Fire with Fire: Can ChatGPT Detect AI-generated Text?.](http://arxiv.org/abs/2308.01284) | ChatGPT作为检测器能否有效检测AI生成的文本，我们通过评估其在人工编写文本与AI生成文本之间的区分能力，并在公开数据集上进行实验，得出了关于ChatGPT在自动化检测流程中的应用指导。 |
| [^5] | [BRNES: Enabling Security and Privacy-aware Experience Sharing in Multiagent Robotic and Autonomous Systems.](http://arxiv.org/abs/2308.01274) | BRNES是一个新的MARL框架，通过动态选择邻居区域和加权经验聚合技术来防御拜占庭攻击和隐私泄漏问题。 |
| [^6] | [A Probabilistic Approach to Self-Supervised Learning using Cyclical Stochastic Gradient MCMC.](http://arxiv.org/abs/2308.01271) | 本文提出了一种利用循环随机梯度MCMC的贝叶斯自监督学习方法，在多个下游分类任务中，通过探索丰富的嵌入后验分布，实现了显著的性能提升、校准性和外部分布检测能力。 |
| [^7] | [Exploring the psychology of GPT-4's Moral and Legal Reasoning.](http://arxiv.org/abs/2308.01264) | 本文探究了GPT-4的道德和法律推理，发现其与人类之间在意图归因、因果判断、欺骗的道德性、道德基础、道德运气对法律判断的影响、同意的概念以及规则违反判断方面存在高相关性。 |
| [^8] | [XSTest: A Test Suite for Identifying Exaggerated Safety Behaviours in Large Language Models.](http://arxiv.org/abs/2308.01263) | 本文介绍了一个名为XSTest的测试套件，旨在识别大型语言模型中夸大的安全行为。该套件由200个安全提示组成，涵盖十种提示类型，旨在引出模型的系统性问题。 |
| [^9] | [Evaluating Instruction-Tuned Large Language Models on Code Comprehension and Generation.](http://arxiv.org/abs/2308.01240) | 本研究在四个代表性的代码理解和生成任务上评估了10种开源指导调优的大型语言模型，发现在零知识迁移的情况下，指导调优的大型语言模型表现出很高的竞争力，在少训练数据的情况下，添加示范样例可以提升模型性能，在微调设置下，微调可以进一步提升模型性能。 |
| [^10] | [Do Multilingual Language Models Think Better in English?.](http://arxiv.org/abs/2308.01223) | 这项研究提出了一种名为自我翻译的方法，通过利用多语言语言模型的少样本翻译能力，克服了对外部翻译系统的需求，并在多个任务上展示了自我翻译相对于直接推理的优势。 |
| [^11] | [Calibration in Deep Learning: A Survey of the State-of-the-Art.](http://arxiv.org/abs/2308.01222) | 本文回顾了深度学习中的校准方法的最新发展，并提供了对其原理的理解。研究表明，现代深度神经网络在预测能力上表现出色，但校准性较差，导致模型预测不可靠。因此，需要一些新的方法来改善模型的校准性。 |
| [^12] | [Using ScrutinAI for Visual Inspection of DNN Performance in a Medical Use Case.](http://arxiv.org/abs/2308.01220) | 我们使用可视化分析工具ScrutinAI来研究医疗领域的模型性能和数据集标注质量对模型性能的影响，以及分析深度神经网络模型的缺点和真正的缺陷之间的区别。 |
| [^13] | [BiERL: A Meta Evolutionary Reinforcement Learning Framework via Bilevel Optimization.](http://arxiv.org/abs/2308.01207) | BiERL是一个通用的元进化强化学习框架，通过双层优化来同时更新超参数和训练强化学习模型，从而提高学习效率和性能。 |
| [^14] | [Personalized Category Frequency prediction for Buy It Again recommendations.](http://arxiv.org/abs/2308.01195) | 该论文提出了一种个性化的推荐系统，用于根据客户的重复购买模式预测再次购买的类别和商品。采用层次化PCIC模型，通过生存模型和时间序列模型捕捉消费行为和趋势，并使用这些特征训练类别粒度的神经网络。 |
| [^15] | [Mercury: An Automated Remote Side-channel Attack to Nvidia Deep Learning Accelerator.](http://arxiv.org/abs/2308.01193) | 该论文介绍了Mercury，这是一种针对现成的Nvidia DNN加速器的自动化远程侧信道攻击。它能够克服现有工作中的几个限制，包括只针对简化的加速器实现和需要大量人工分析和领域知识等。 |
| [^16] | [Data-Centric Diet: Effective Multi-center Dataset Pruning for Medical Image Segmentation.](http://arxiv.org/abs/2308.01189) | 本文针对医学图像分割中的稠密标签问题，提出了一种数据修剪方法，通过动态平均Dice分数考虑目标区域上的训练动态。该方法可以在不牺牲准确性的情况下，修剪数据集的重要部分，解决数据集规模大的问题。 |
| [^17] | [LLMs Understand Glass-Box Models, Discover Surprises, and Suggest Repairs.](http://arxiv.org/abs/2308.01157) | LLMs在处理可解释模型方面表现出色，提供了全面的模型级总结和自动化的异常检测、原因描述和修复建议。在医疗保健领域使用广义可加模型作为示例，同时介绍了开源的LLM-GAM接口包$\texttt{TalkToEBM}$。 |
| [^18] | [Arithmetic with Language Models: from Memorization to Computation.](http://arxiv.org/abs/2308.01154) | 本研究探索了使用语言模型进行算术计算的能力，发现语言模型可以通过内部的值空间进行计算，并取得了成功的实验结果。 |
| [^19] | [Can We Transfer Noise Patterns? An Multi-environment Spectrum Analysis Model Using Generated Cases.](http://arxiv.org/abs/2308.01138) | 这项研究提出了一个噪声模式转移模型，可以将噪声模式从不同环境的标准样本应用到未知样本，通过生成案例库来解决样本级噪声对数据集级噪声学习的干扰，提高了系统的学习性能。 |
| [^20] | [A Survey on Popularity Bias in Recommender Systems.](http://arxiv.org/abs/2308.01118) | 这篇综述论文讨论了推荐系统中的流行偏差问题，并回顾了现有的方法来检测、量化和减少流行偏差。它同时提供了计算度量的概述和主要技术方法的回顾。 |
| [^21] | [Literal-Aware Knowledge Graph Embedding for Welding Quality Monitoring: A Bosch Case.](http://arxiv.org/abs/2308.01105) | 本文研究了在制造业焊接质量监测中应用知识图嵌入的可能性和程度，解决了两个非常具有挑战性的问题：焊接斑点直径和所属车身的问题。 |
| [^22] | [Towards Better Query Classification with Multi-Expert Knowledge Condensation in JD Ads Search.](http://arxiv.org/abs/2308.01098) | 本文提出了一种知识蒸馏框架（KC），通过在严格的低延迟约束下提升在线FastText模型的查询分类性能，在京东广告搜索中取得了显著的性能提升。 |
| [^23] | [Scaling Data Science Solutions with Semantics and Machine Learning: Bosch Case.](http://arxiv.org/abs/2308.01094) | 该论文提出了SemCloud，一个结合了语义技术和机器学习的语义增强云系统，以应对工业4.0和物联网时代大数据处理的挑战。该系统通过使用领域本体和映射来进行数据集成，并在分布式计算节点上并行处理语义数据和分析任务。此外，SemCloud还采用了自适应学习算法来降低用户训练时间的要求。 |
| [^24] | [Hand tracking for clinical applications: validation of the Google MediaPipe Hand (GMH) and the depth-enhanced GMH-D frameworks.](http://arxiv.org/abs/2308.01088) | 该论文验证了Google MediaPipe Hand（GMH）和增强版本GMH-D框架在临床应用中的手部追踪效果，通过使用RGB-Depth相机的深度估计来实现更准确的3D运动追踪。 |
| [^25] | [Spatial Intelligence of a Self-driving Car and Rule-Based Decision Making.](http://arxiv.org/abs/2308.01085) | 本文展示了如何将规则决策与运动规划技术相结合，实现自动驾驶车辆在复杂交通情况下表现出人类行为的能力，强调了发展机器人空间意识技术的重要性。 |
| [^26] | [Graph Anomaly Detection at Group Level: A Topology Pattern Enhanced Unsupervised Approach.](http://arxiv.org/abs/2308.01063) | 提出一种新的无监督框架，用于在图中检测组级别的异常，并利用拓扑模式增强了算法的性能。 |
| [^27] | [A Counterfactual Safety Margin Perspective on the Scoring of Autonomous Vehicles' Riskiness.](http://arxiv.org/abs/2308.01050) | 本文基于反事实模拟提出了一个数据驱动的框架，用于比较不同自动驾驶车辆在不同操作设计领域中行为风险。通过引入反事实安全边界的概念，该框架可以找到最关键的情景，并评估自动驾驶车辆的风险频率和严重程度。该方法即使在自动驾驶车辆的行为策略未知的情况下也适用，对外部第三方风险评估机构有用。 |
| [^28] | [Chat Translation Error Detection for Assisting Cross-lingual Communications.](http://arxiv.org/abs/2308.01044) | 本文开发了一个通信支持系统，能够检测错误的翻译，以促进跨语言交流。研究者开发了一个错误检测器作为系统的基线，并构建了一个新的日英双语聊天语料库，此举为更高级错误翻译检测系统提供了支持。 |
| [^29] | [Three Factors to Improve Out-of-Distribution Detection.](http://arxiv.org/abs/2308.01030) | 本论文提出了三个因素来改善离群检测问题。首先，引入自我知识蒸馏损失以提高网络的准确性；其次，在训练过程中采样半困难离群数据以改善离群检测性能；最后，引入新型监督对比学习以同时提高离群检测性能和网络的准确性。通过结合这三个因素，我们的方法在分类和离群检测之间取得了良好的平衡，提高了准确性和离群检测性能。 |
| [^30] | [Enhancing Representation Learning for Periodic Time Series with Floss: A Frequency Domain Regularization Approach.](http://arxiv.org/abs/2308.01011) | 本文提出了一种叫做Floss的无监督方法，通过在频域上对学到的表示进行正则化来增强周期性时间序列的表示学习。Floss方法可以自动检测时间序列中的周期性并学习具有周期一致性的有意义的表示。 |
| [^31] | [FusionAD: Multi-modality Fusion for Prediction and Planning Tasks of Autonomous Driving.](http://arxiv.org/abs/2308.01006) | FusionAD是第一个将来自相机和激光雷达的信息融合起来用于自动驾驶预测和规划任务的统一框架，在常用数据集上的实验中达到了最先进的性能。 |
| [^32] | [Wasserstein Diversity-Enriched Regularizer for Hierarchical Reinforcement Learning.](http://arxiv.org/abs/2308.00989) | 本文中，我们提出了一种新的任务无关正则化器WDER，通过增加子策略的多样性来解决层次化强化学习中的退化问题。实验证明，WDER能够提高性能和样本效率，并且不需要修改超参数。 |
| [^33] | [Isolation and Induction: Training Robust Deep Neural Networks against Model Stealing Attacks.](http://arxiv.org/abs/2308.00958) | 这项研究提出了一种名为隔离和诱导（InI）的训练框架，用于对抗模型窃取攻击。该框架通过隔离对手的训练梯度，并直接训练一个防御模型，有效地解决了现有防御方法中推理计算开销高和准确性与防窃鲁棒性之间的不利权衡问题。 |
| [^34] | [From Sparse to Soft Mixtures of Experts.](http://arxiv.org/abs/2308.00951) | 本文提出了一种Soft MoE模型，它是一种稀疏的、完全可微分的Transformer，通过隐式的软分配和只处理部分标记的方式解决了稀疏模型的训练不稳定性和推理成本高的问题，并在视觉识别任务中取得了比标准Transformer和其他MoE变体更好的性能。 |
| [^35] | [Teaching Smaller Language Models To Generalise To Unseen Compositional Questions.](http://arxiv.org/abs/2308.00946) | 我们研究了如何教授较小的语言模型来推广到未见过的组合问题，通过多任务监督预训练和密集检索系统，我们建立了强大的基准，并展示了解决多个评估数据集上的问题的能力。 |
| [^36] | [Feature-aware conditional GAN for category text generation.](http://arxiv.org/abs/2308.00939) | 本文提出了一个名为特征感知的条件生成对抗网络（FA-GAN）的新框架，用于解决文本GAN中的离散性、训练不稳定、模式崩溃、缺乏多样性和可控性等问题。FA-GAN使用特征感知编码器和类别感知编码器，以及关系记忆核的解码器，通过生成序列来提高句子多样性，并具有额外的类别分类头。 |
| [^37] | [LEMMA: Learning Language-Conditioned Multi-Robot Manipulation.](http://arxiv.org/abs/2308.00937) | LEMMA是一个学习语言条件下的多机器人操作的基准，通过专家示范和人类指令进行任务分配和长时间跨度物体操作。它提供了涉及工具使用和传递的复杂操纵任务，并提出了一种模块化分层规划方法作为基线。 |
| [^38] | [Particle swarm optimization with state-based adaptive velocity limit strategy.](http://arxiv.org/abs/2308.00936) | 提出了一种基于状态的自适应速度限制策略的粒子群优化（PSO-SAVL）方法，通过根据进化状态估计（ESE）来自适应地调整速度限制（VL），以提高粒子群优化的性能。 |
| [^39] | [Physics-informed neural networks for blood flow inverse problems.](http://arxiv.org/abs/2308.00927) | 本研究利用物理信息神经网络方法，在血液动力学中解决了缺乏完整信息和只有散射测量数据的逆问题。结果表明该方法在使用模拟数据时能够稳定准确地估计模型参数，并且能够处理复杂的流动模式，从而解决了与血液动力学和复杂耦合物理系统相关的临床逆问题。 |
| [^40] | [VLUCI: Variational Learning of Unobserved Confounders for Counterfactual Inference.](http://arxiv.org/abs/2308.00904) | VLUCI是一个新颖的可变参数学习模型，用于解决反事实推断中的未观测混淆变量的问题。它通过生成未观测混淆变量的后验分布，并构建一个双重变分推断模型来解决因果推断中观测和未观测混淆变量的问题，从而提高反事实推断的准确性。 |
| [^41] | [Enhancing Machine Learning Performance with Continuous In-Session Ground Truth Scores: Pilot Study on Objective Skeletal Muscle Pain Intensity Prediction.](http://arxiv.org/abs/2308.00886) | 本研究提出了一种使用实时准确评分来提高机器学习性能的方法，通过采集实时疼痛评分和内胚层活动数据，在疼痛分类任务中取得了较好的结果。 |
| [^42] | [Beneficent Intelligence: A Capability Approach to Modeling Benefit, Assistance, and Associated Moral Failures through AI Systems.](http://arxiv.org/abs/2308.00868) | 借鉴能力方法，研究者提出了一个框架，用于解决AI系统与个体互动时涌现的伦理问题。同时，他们也界定了道德可接受的互动条件，并对几种失败模式进行了对比分析。 |
| [^43] | [PeRP: Personalized Residual Policies For Congestion Mitigation Through Co-operative Advisory Systems.](http://arxiv.org/abs/2308.00864) | 本论文提出了一种基于个性化剩余策略的合作咨询系统PeRP，用于缓解拥堵。该系统通过结构化建模人类驾驶的相似性，并根据驾驶员的特征为其提供行动建议，以减少交通拥堵。 |
| [^44] | [Active Inference in String Diagrams: A Categorical Account of Predictive Processing and Free Energy.](http://arxiv.org/abs/2308.00861) | 该论文介绍了一个用串图表述的主动推理的范畴化框架，提供了生成模型、贝叶斯更新、感知、规划、主动推理和自由能的图形化描述，并通过自由能最小化的串图推导给出了主动推理的公式，还确定了自由能的组合性质。 |
| [^45] | [Understanding Activation Patterns in Artificial Neural Networks by Exploring Stochastic Processes.](http://arxiv.org/abs/2308.00858) | 该论文提出了利用随机过程框架来研究人工神经网络中的激活模式。通过模拟和实验，研究人员得到了描述每个网络中激活模式的参数。 |
| [^46] | [Training on Foveated Images Improves Robustness to Adversarial Attacks.](http://arxiv.org/abs/2308.00854) | 本研究通过使用RBlur转换的图像来训练深度神经网络(DNN)，证明了相比于在原始图像上训练的DNN，使用RBlur方法训练的DNN对对抗攻击和其他损坏具有更强的健壮性，提高了高达25%的准确性。 |
| [^47] | [Designing a Communication Bridge between Communities: Participatory Design for a Question-Answering AI Agent.](http://arxiv.org/abs/2308.00813) | 这篇论文介绍了一个旨在充当两个具有不同心智模型和词汇的用户社区之间沟通桥梁的AI系统的设计。使用参与式设计的方法，研究者成功地征求了开发AskJill问答代理的需求，并发现用户认为词汇表辅助是关键功能。 |
| [^48] | [Artificial Eye for the Blind.](http://arxiv.org/abs/2308.00801) | 人工眼睛模型通过网络摄像头、超声波传感器和软件模型实现盲人的障碍物检测和光学字符识别。 |
| [^49] | [A Knowledge-Oriented Approach to Enhance Integration and Communicability in the Polkadot Ecosystem.](http://arxiv.org/abs/2308.00735) | 本文提出了一种知识导向的方法，通过使用名为POnto的领域本体，提供结构化的生态系统概念和关系表示，以增强Polkadot生态系统的集成和可交流性。该方法有助于更广泛的用户参与生态系统，并促进基于人工智能的应用的发展。 |
| [^50] | [A Pre-trained Data Deduplication Model based on Active Learning.](http://arxiv.org/abs/2308.00721) | 提出了一种基于主动学习的预训练去重模型，将Transformer和主动学习集成到端到端架构中，首次解决了语义级别的去重问题，同时采用R-Drop方法对每一轮标记数据进行数据增强。通过选择最有价值的数据进行去重模型训练，不仅降低了手动标记的成本，还提高了模型的泛化能力。 |
| [^51] | [Towards the Visualization of Aggregated Class Activation Maps to Analyse the Global Contribution of Class Features.](http://arxiv.org/abs/2308.00710) | 本文扩展了类激活图的方法，将多个样本的类激活图聚合起来，以展示语义结构化数据的分类的全局解释。聚合过程使得分析师可以进行复杂的假设和进一步的钻取可视化分析。 |
| [^52] | [Approximate Model-Based Shielding for Safe Reinforcement Learning.](http://arxiv.org/abs/2308.00707) | 提出了一种近似模型屏蔽算法 (AMBS) 来验证学习的强化学习策略在给定安全约束下的性能，与其他屏蔽方法相比，AMBS不需要先验知识，并在具有状态相关安全标签的 Atari 游戏上展示了优越性能。 |
| [^53] | [A Bibliographic Study on Artificial Intelligence Research: Global Panorama and Indian Appearance.](http://arxiv.org/abs/2308.00705) | 本研究使用文献计量学方法分析了2015-2020年间人工智能研究的文献趋势，发现商业期刊在引用分数和发表数量上表现更好，同时还研究了各国的出版情况和印度在人工智能研究中的重要性。 |
| [^54] | [SelfCheck: Using LLMs to Zero-Shot Check Their Own Step-by-Step Reasoning.](http://arxiv.org/abs/2308.00436) | 本论文研究了使用LLMs自检逐步推理的能力，提出了一种零-shot验证方案，成功识别错误并提高了问答性能。 |
| [^55] | [MetaGPT: Meta Programming for Multi-Agent Collaborative Framework.](http://arxiv.org/abs/2308.00352) | MetaGPT是一个用于多智能体协作的创新框架，将有效的人工工作流引入到大型语言模型驱动的协作中。它采用元编程方法，将标准操作规程编码为提示，促进结构化协调，并要求模块化输出，赋予智能体领域专业知识，以验证输出并减少错误。这种框架利用了流水线工作模式来分配任务。 |
| [^56] | [Towards Semantically Enriched Embeddings for Knowledge Graph Completion.](http://arxiv.org/abs/2308.00081) | 本论文讨论了知识图谱补全算法以及利用嵌入模型捕捉知识图谱中语义的不同方法，并提出知识图谱和语言模型相互受益的观点。 |
| [^57] | [AsdKB: A Chinese Knowledge Base for the Early Screening and Diagnosis of Autism Spectrum Disorder.](http://arxiv.org/abs/2307.16773) | AsdKB是一个用于自闭症谱系障碍早期筛选和诊断的中文知识库，包含了来自多个来源的疾病和诊断知识，并且可以用于问题回答、辅助诊断和专家推荐。 |
| [^58] | [LLMs4OL: Large Language Models for Ontology Learning.](http://arxiv.org/abs/2307.16648) | LLMs4OL方法利用大型语言模型在本体学习中取得显著进展，能够从自然语言文本中自动提取和结构化知识。 |
| [^59] | [Primitive Skill-based Robot Learning from Human Evaluative Feedback.](http://arxiv.org/abs/2307.15801) | 基于人类评价反馈的原始技能导向机器人学习框架（SEED）结合了从人类反馈中进行强化学习（RLHF）和基于原始技能的强化学习，有效解决了稀疏奖励和长时程任务复杂性问题，并提高了学习效率和安全性。 |
| [^60] | [Attention of Robot Touch: Tactile Saliency Prediction for Robust Sim-to-Real Tactile Control.](http://arxiv.org/abs/2307.14510) | 这篇论文提出了一种新的概念——机器人触觉的“触觉显著性”，通过借鉴人类触觉注意机制和计算机视觉中的视觉显著性预测问题，提高了非结构化环境下触觉机器人控制的鲁棒性。 |
| [^61] | [Exploring the Potential of Large Language Models (LLMs) in Learning on Graphs.](http://arxiv.org/abs/2307.03393) | 本文探索了大规模语言模型（LLMs）在图学习中的潜力，并尝试了两种不同的流程：将LLMs作为增强器通过海量知识来增强节点的文本属性，并使用图神经网络（GNNs）生成预测，以及直接使用LLMs作为独立的预测器。 |
| [^62] | [A Survey on Evaluation of Large Language Models.](http://arxiv.org/abs/2307.03109) | 本文综述了大型语言模型（LLMs）的评估方法，关注三个关键维度：评估什么、在哪里评估以及如何评估。评估任务包括自然语言处理、推理、医学应用、伦理学、教育、自然和社会科学、代理应用等多个领域。本文为社会层面对LLMs潜在风险的理解提供了重要参考。 |
| [^63] | [Automatic Design of Semantic Similarity Ensembles Using Grammatical Evolution.](http://arxiv.org/abs/2307.00925) | 本研究首次使用语法演化自动设计语义相似性集合，通过自动选择和聚合候选度量来优化集合与人类判断的相关性，提高相似度评估准确性，并证明了使用集合对语义相似性任务的益处。 |
| [^64] | [CamemBERT-bio: a Tasty French Language Model Better for your Health.](http://arxiv.org/abs/2306.15550) | 本研究介绍了CamemBERT-bio，它是一种针对法语生物医学领域专门设计的语言模型，相对于通用模型在命名实体识别任务上平均提高了2.54个百分点。 |
| [^65] | [TeleViT: Teleconnection-driven Transformers Improve Subseasonal to Seasonal Wildfire Forecasting.](http://arxiv.org/abs/2306.10940) | TeleViT是一种电联驱动的视觉Transformer模型，可以准确预测季节性野火的全球烧毁面积模式，提前四个月进行预测。 |
| [^66] | [Bayesian Optimization of Expensive Nested Grey-Box Functions.](http://arxiv.org/abs/2306.05150) | 本文提出基于乐观主义的算法来解决嵌套黑白箱函数优化问题，相比传统黑箱优化方法显著提高全局最优解速度。 |
| [^67] | [EINCASM: Emergent Intelligence in Neural Cellular Automaton Slime Molds.](http://arxiv.org/abs/2305.13425) | 本论文介绍了EINCASM，一个研究软泥菌类有机体智能的原型系统。该系统利用神经元元胞自动机结合虚拟流体运输营养物质和化学信号，通过测试智能的方式研究有机体的智能行为，在未来可以进一步深入研究这些分布式动态系统中的智能行为。 |
| [^68] | [ChatGPT and the Labor Market: Unraveling the Effect of AI Discussions on Students' Earnings Expectations.](http://arxiv.org/abs/2305.11900) | 本文研究了 ChatGPT人工智能（AI）讨论对美国学生预期劳动市场结果的因果影响，结果发现学生信心会降低，对未来的收入前景保持悲观态度，这种影响广泛存在于不同学生群体中。这个研究给教育工作者、管理者和政策制定者提供了一个机会，以更好地了解学生的担忧并改进教育课程，使学生更好地准备未来，这个未来必然会被AI改变。 |
| [^69] | [SpikeCP: Delay-Adaptive Reliable Spiking Neural Networks via Conformal Prediction.](http://arxiv.org/abs/2305.11322) | 这篇论文提出了一种新的脉冲神经网络模型，能够通过极限预测实现自适应的推断延迟，从而节约能源与提高可靠性。 |
| [^70] | [Human or Machine: Reflections on Turing-Inspired Testing for the Everyday.](http://arxiv.org/abs/2305.04312) | 本文基于图灵测试，回避了机器是否智能的问题，探讨在日常生活中如何确定一个交互对象是人还是机器的挑战，并思考了其应用和重要性。 |
| [^71] | [ReLBOT: A Transfer Learning Approach to Minimize Reinforcement Learning Risks in Smart Buildings.](http://arxiv.org/abs/2305.00365) | ReLBOT使用转移学习和深度RL技术来从现有的智能建筑中传递优化参数到新的建筑中，以减少强化学习代理引起的初始不适，有效降低了风险，并且实现了热身期时长6.2倍的提高和预测方差的132倍提高。 |
| [^72] | [Transformer and Snowball Graph Convolution Learning for Biomedical Graph Classification.](http://arxiv.org/abs/2303.16132) | 本文介绍了一种新型Transformer和Snowball编码网络（TSEN），它将Transformer架构和图雪球连接引入GNNs。TSEN通过雪球编码层将图雪球连接与图Transformer结合起来，增强了捕捉多尺度信息和全局模式以学习整个图特征的能力。 |
| [^73] | [Data Association Aware POMDP Planning with Hypothesis Pruning Performance Guarantees.](http://arxiv.org/abs/2303.02139) | 提出了一种用于处理具有不确定数据关联的POMDP规划的剪枝算法，通过导出完整假设集与减枝假设子集之间的价值函数边界，建立了使用减枝假设子集造成的最大损失的紧密上界，实验证明此方法在具有挑战性的自主驾驶场景中能够显著节省计算时间并保持合理的性能保证。 |
| [^74] | [Evolutionary Augmentation Policy Optimization for Self-supervised Learning.](http://arxiv.org/abs/2303.01584) | 本文研究了数据增强操作对自监督学习算法性能的影响，提出了一种进化搜索方法来优化数据增强策略，并通过实验比较了几种现有自监督学习算法的性能。 |
| [^75] | [Graph Attention Multi-Agent Fleet Autonomy for Advanced Air Mobility.](http://arxiv.org/abs/2302.07337) | 这项研究介绍了图形注意力多智能体航空机队自治技术，通过使用新型的神经网络随机策略，考虑代理的异质性和自私性，实现了对机动网络中复杂相互作用和观察不确定性的建模。通过深度多智能体强化学习，实现了代理的分散决策。 |
| [^76] | [Thinking Fast and Slow in Large Language Models.](http://arxiv.org/abs/2212.05206) | 本研究发现，大型语言模型（LLMs）如GPT-3在行为上与人类直觉相似，但可能带有认知错误。然而，具有更高认知能力的LLMs，如ChatGPT和GPT-4，学会了避免这些错误，表现出超理性的方式。通过在心理学方法的帮助下研究LLMs，我们可以揭示出其它未知的新特征。 |
| [^77] | [Automatic Emergency Dust-Free solution on-board International Space Station with Bi-GRU (AED-ISS).](http://arxiv.org/abs/2210.08549) | 该论文旨在解决国际空间站上颗粒物对仪器的危害问题，通过Bi-GRU算法构建早期预警系统，预测颗粒物水平，并为宇航员提供充足的反应时间。这项研究还有潜力发展为与火灾相关的遥感烟雾报警装置。 |
| [^78] | [Learning to Efficiently Plan Robust Frictional Multi-Object Grasps.](http://arxiv.org/abs/2210.07420) | 本文介绍了一种使用神经网络进行摩擦多物体抓取的高效计划方法，相比于以往的工作，其成功率提高了13.7％，每小时的拾取次数增加了1.6倍，并且抓取计划时间减少了6.3倍。 |
| [^79] | [Graph Soft-Contrastive Learning via Neighborhood Ranking.](http://arxiv.org/abs/2209.13964) | 图对比学习（GCL）方法在图像领域表现出了显著的性能，但在应用于图数据时面临着生成无效视图和不可靠相似性对的限制。这篇论文提出了一种基于邻域排序的图形软对比学习方法，以更好地适应图的内在属性。 |
| [^80] | [Models of human preference for learning reward functions.](http://arxiv.org/abs/2206.02231) | 本研究提出了一种将人类偏好建模为每个轨迹段的遗憾的方法，并证明了可以根据这些遗憾生成的偏好来识别生成这些偏好的奖励函数。实验证明，这种遗憾偏好模型在性能上优于以前的模型。 |
| [^81] | [Sparse Graph Learning from Spatiotemporal Time Series.](http://arxiv.org/abs/2205.13492) | 本论文提出了一种基于概率评分的方法，通过学习关系依赖的图分布来解决在时空时间序列分析中关系信息不可用的问题，并在时间序列预测问题上展示了有效性。 |
| [^82] | [Improve Event Extraction via Self-Training with Gradient Guidance.](http://arxiv.org/abs/2205.12490) | 本论文提出了一种自训练与梯度引导的框架，通过利用大规模无标签数据和使用Abstract Meaning Representation（AMR）图作为反馈，以改善事件抽取中的数据稀缺问题。实验结果显示这种方法的有效性。 |
| [^83] | [Asynchronous, Option-Based Multi-Agent Policy Gradient: A Conditional Reasoning Approach.](http://arxiv.org/abs/2203.15925) | 本文提出了一种条件推理方法来解决多智能体策略梯度方法在异步选项执行中的问题，并在基于选项的多智能体合作任务上取得有效结果。 |
| [^84] | [Fabricated Flips: Poisoning Federated Learning without Data.](http://arxiv.org/abs/2202.05877) | 本文介绍了一种名为无数据非定向攻击（DFA）的新方法，它通过合成恶意数据来制造对抗模型，在不需要窃听良性客户端传输或大量任务特定训练数据的情况下实现攻击。这种方法能够在联邦学习中降低生成模型质量，并限制该学习模式的实用性。 |
| [^85] | [Successor Feature Representations.](http://arxiv.org/abs/2110.15701) | 继承特征表示（SFR）是一种新的Successor Representations (SR)的表达方式，通过学习继承特征的累积折扣概率来重新评估策略的预期回报。 |
| [^86] | [Multi-Attention-Based Soft Partition Network for Vehicle Re-Identification.](http://arxiv.org/abs/2104.10401) | 本文提出了一种基于多注意力软分区网络的车辆再识别方法，通过引入多软注意力机制来解决由于不同视角和相似车辆之间的内部差异导致的挑战，并避免了嘈杂的注意力图和额外的注释元数据的使用。 |
| [^87] | [Class-incremental Learning with Pre-allocated Fixed Classifiers.](http://arxiv.org/abs/2010.08657) | 本文提出了一种具有预分配固定分类器的类增量学习方法，通过利用存储在情节性记忆中的过去数据，并在学习阶段的开始就将一些预分配的输出节点纳入分类损失的计算，解决了神经网络在类增量学习中遗忘先前知识的问题。 |

# 详细

[^1]: 更多上下文，更少干扰：通过推断和调节上下文属性进行视觉分类

    More Context, Less Distraction: Visual Classification by Inferring and Conditioning on Contextual Attributes. (arXiv:2308.01313v1 [cs.CV])

    [http://arxiv.org/abs/2308.01313](http://arxiv.org/abs/2308.01313)

    本文借鉴了人类视觉感知过程，提出了一种通过推断和调节上下文属性来改进零样本图像分类的方法。通过给CLIP提供上下文属性，可以减轻对虚假特征的依赖，进而提高零样本分类的准确性。

    

    CLIP作为一种基础的视觉语言模型，由于其理解各种视觉概念和自然语言描述的能力，被广泛应用于零样本图像分类。然而，如何充分利用CLIP的前所未有的人类般理解能力来实现更好的零样本分类仍然是一个开放问题。本文从人类的视觉感知过程中得到启发：现代神经科学观点认为，在对物体进行分类时，人类首先推断其与类别无关的属性（如背景和方向），这有助于将前景对象与背景区分开来，然后以此信息为基础进行决策。受此启发，我们观察到为CLIP提供上下文属性可以改善零样本分类并减轻对虚假特征的依赖。我们还观察到CLIP本身可以合理地从图像中推断出这些属性。基于这些观察，我们提出了一种零训练、两步骤的零样本分类方法。

    CLIP, as a foundational vision language model, is widely used in zero-shot image classification due to its ability to understand various visual concepts and natural language descriptions. However, how to fully leverage CLIP's unprecedented human-like understanding capabilities to achieve better zero-shot classification is still an open question. This paper draws inspiration from the human visual perception process: a modern neuroscience view suggests that in classifying an object, humans first infer its class-independent attributes (e.g., background and orientation) which help separate the foreground object from the background, and then make decisions based on this information. Inspired by this, we observe that providing CLIP with contextual attributes improves zero-shot classification and mitigates reliance on spurious features. We also observe that CLIP itself can reasonably infer the attributes from an image. With these observations, we propose a training-free, two-step zero-shot cl
    
[^2]: Lode Encoder: AI约束下的共创性游戏关卡生成器

    Lode Encoder: AI-constrained co-creativity. (arXiv:2308.01312v1 [cs.LG])

    [http://arxiv.org/abs/2308.01312](http://arxiv.org/abs/2308.01312)

    Lode Encoder是一个基于AI的共创性游戏关卡生成器，通过训练自编码器并结合用户设计，生成更加符合设计风格的关卡，鼓励设计师探索新的可能性。

    

    我们提出了Lode Encoder，这是一个以经典平台益智游戏Lode Runner为基础的创意游戏关卡生成系统。该系统基于多个自编码器，这些自编码器通过对一系列Lode Runner关卡进行训练来生成与用户设计风格更相似的版本。Lode Encoder界面允许用户通过自编码器提供的建议来构建和编辑关卡。为了鼓励设计师探索新的可能性，该系统不包含传统的编辑工具。我们报告了系统设计和训练过程，以及系统演进和用户测试的结果。

    We present Lode Encoder, a gamified mixed-initiative level creation system for the classic platform-puzzle game Lode Runner. The system is built around several autoencoders which are trained on sets of Lode Runner levels. When fed with the user's design, each autoencoder produces a version of that design which is closer in style to the levels that it was trained on. The Lode Encoder interface allows the user to build and edit levels through 'painting' from the suggestions provided by the autoencoders. Crucially, in order to encourage designers to explore new possibilities, the system does not include more traditional editing tools. We report on the system design and training procedure, as well as on the evolution of the system itself and user tests.
    
[^3]: Flows: 推理和协作人工智能的构建模块

    Flows: Building Blocks of Reasoning and Collaborating AI. (arXiv:2308.01285v1 [cs.AI])

    [http://arxiv.org/abs/2308.01285](http://arxiv.org/abs/2308.01285)

    Flows是一种系统化的方法，它通过将计算分解为自包含的构建模块，通过标准化的消息传递接口进行通信，实现了结构化的推理和协作人工智能。这种模块化设计使得Flows可以构建任意复杂度的交互，能够覆盖各种人工智能交互和工具增强的应用。

    

    最近人工智能领域取得的进展已经产生了高度能力和可控性的系统。这为结构化推理以及多个人工智能系统和人类之间的协作创造了前所未有的机遇。为了充分实现这一潜力，必须开发一种有原则的方法来设计和研究这样的结构化交互。为此，我们引入了流程的概念框架：一种系统化的建模复杂交互的方法。流程是计算的自包含构建模块，具有独立的状态，并通过标准化的基于消息的接口进行通信。这种模块化设计使得流程可以递归地组合成任意嵌套的交互，大大降低了复杂性。关键是，任何交互都可以使用这个框架来实现，包括之前关于人工智能-人工智能和人类-人工智能交互、提示工程方案和工具增强的工作。我们展示了流程在任务上的潜力。

    Recent advances in artificial intelligence (AI) have produced highly capable and controllable systems. This creates unprecedented opportunities for structured reasoning as well as collaboration among multiple AI systems and humans. To fully realize this potential, it is essential to develop a principled way of designing and studying such structured interactions. For this purpose, we introduce the conceptual framework of Flows: a systematic approach to modeling complex interactions. Flows are self-contained building blocks of computation, with an isolated state, communicating through a standardized message-based interface. This modular design allows Flows to be recursively composed into arbitrarily nested interactions, with a substantial reduction of complexity. Crucially, any interaction can be implemented using this framework, including prior work on AI--AI and human--AI interactions, prompt engineering schemes, and tool augmentation. We demonstrate the potential of Flows on the task 
    
[^4]: 用火攻火：ChatGPT能够检测AI生成的文本吗？

    Fighting Fire with Fire: Can ChatGPT Detect AI-generated Text?. (arXiv:2308.01284v1 [cs.CL])

    [http://arxiv.org/abs/2308.01284](http://arxiv.org/abs/2308.01284)

    ChatGPT作为检测器能否有效检测AI生成的文本，我们通过评估其在人工编写文本与AI生成文本之间的区分能力，并在公开数据集上进行实验，得出了关于ChatGPT在自动化检测流程中的应用指导。

    

    越来越多的大型语言模型（如ChatGPT）被用于各种用例，包括规模化的文本内容生成。虽然已经存在针对这种AI生成文本的检测方法，但我们研究了ChatGPT在这种AI生成文本上的检测性能，受到将ChatGPT用作数据标注器或注释器的研究启发。我们评估了ChatGPT在人工编写文本与AI生成文本检测任务中的零-shot性能，并在公开可用的数据集上进行实验。我们通过实证研究了ChatGPT在检测AI生成文本或人工编写文本方面是否具有对称效应。我们的发现揭示了通过简单关注问题的特定方面并从该解决方案中推导出其余部分，如何利用ChatGPT和类似的大型语言模型在自动化检测流程中发挥作用。所有代码和数据可在 \url{https://github.com/AmritaBh/ChatGPT-as-Detector} 上获得。

    Large language models (LLMs) such as ChatGPT are increasingly being used for various use cases, including text content generation at scale. Although detection methods for such AI-generated text exist already, we investigate ChatGPT's performance as a detector on such AI-generated text, inspired by works that use ChatGPT as a data labeler or annotator. We evaluate the zero-shot performance of ChatGPT in the task of human-written vs. AI-generated text detection, and perform experiments on publicly available datasets. We empirically investigate if ChatGPT is symmetrically effective in detecting AI-generated or human-written text. Our findings provide insight on how ChatGPT and similar LLMs may be leveraged in automated detection pipelines by simply focusing on solving a specific aspect of the problem and deriving the rest from that solution. All code and data is available at \url{https://github.com/AmritaBh/ChatGPT-as-Detector}.
    
[^5]: BRNES: 在多智能体机器人和自主系统中实现安全和隐私感知的经验共享

    BRNES: Enabling Security and Privacy-aware Experience Sharing in Multiagent Robotic and Autonomous Systems. (arXiv:2308.01274v1 [cs.CR])

    [http://arxiv.org/abs/2308.01274](http://arxiv.org/abs/2308.01274)

    BRNES是一个新的MARL框架，通过动态选择邻居区域和加权经验聚合技术来防御拜占庭攻击和隐私泄漏问题。

    

    尽管经验共享（ES）在顾问-受劝告框架中加速了多智能体强化学习（MARL），但尝试将ES应用于分布式多智能体系统迄今为止仍依赖于值得信赖的环境，并忽略了对抗性操纵和推理的可能性。然而，在现实世界中，一些拜占庭攻击者冒充顾问向受劝告提供虚假建议，并严重降低整体学习性能。而且，一个推理攻击者冒充受劝告者可能进行多次查询以推断顾问的私人信息，并使整个ES过程在隐私泄漏方面存在问题。为了解决和应对这些问题，我们提出了一种新的MARL框架（BRNES），它在每个学习步骤中启发式地为每个受劝告者选择一个动态邻居区域，并采用加权经验聚合技术来减少拜占庭攻击的影响。此外，为了确保代理的私人信息的安全

    Although experience sharing (ES) accelerates multiagent reinforcement learning (MARL) in an advisor-advisee framework, attempts to apply ES to decentralized multiagent systems have so far relied on trusted environments and overlooked the possibility of adversarial manipulation and inference. Nevertheless, in a real-world setting, some Byzantine attackers, disguised as advisors, may provide false advice to the advisee and catastrophically degrade the overall learning performance. Also, an inference attacker, disguised as an advisee, may conduct several queries to infer the advisors' private information and make the entire ES process questionable in terms of privacy leakage. To address and tackle these issues, we propose a novel MARL framework (BRNES) that heuristically selects a dynamic neighbor zone for each advisee at each learning step and adopts a weighted experience aggregation technique to reduce Byzantine attack impact. Furthermore, to keep the agent's private information safe fr
    
[^6]: 使用循环随机梯度MCMC的概率自监督学习的实用贝叶斯方法

    A Probabilistic Approach to Self-Supervised Learning using Cyclical Stochastic Gradient MCMC. (arXiv:2308.01271v1 [cs.LG])

    [http://arxiv.org/abs/2308.01271](http://arxiv.org/abs/2308.01271)

    本文提出了一种利用循环随机梯度MCMC的贝叶斯自监督学习方法，在多个下游分类任务中，通过探索丰富的嵌入后验分布，实现了显著的性能提升、校准性和外部分布检测能力。

    

    本文提出了一种利用循环随机梯度哈密顿蒙特卡洛（cSGHMC）的实用贝叶斯自监督学习方法。在该框架中，我们对自监督学习模型的参数设定先验，并使用cSGHMC近似表示多维多模态后验分布。通过探索丰富的嵌入后验分布，贝叶斯自监督学习产生了可解释性和多样性的表示。在多个下游分类任务中，通过边缘化这些表示，我们得到了显著的性能提升、校准性和外部分布检测能力。我们在四个具有挑战性的数据集上进行了多个分类任务的实验结果。此外，我们还使用SVHN和CIFAR-10数据集验证了所提出方法在外部分布检测方面的有效性。

    In this paper we present a practical Bayesian self-supervised learning method with Cyclical Stochastic Gradient Hamiltonian Monte Carlo (cSGHMC). Within this framework, we place a prior over the parameters of a self-supervised learning model and use cSGHMC to approximate the high dimensional and multimodal posterior distribution over the embeddings. By exploring an expressive posterior over the embeddings, Bayesian self-supervised learning produces interpretable and diverse representations. Marginalizing over these representations yields a significant gain in performance, calibration and out-of-distribution detection on a variety of downstream classification tasks. We provide experimental results on multiple classification tasks on four challenging datasets. Moreover, we demonstrate the effectiveness of the proposed method in out-of-distribution detection using the SVHN and CIFAR-10 datasets.
    
[^7]: 探索GPT-4的道德和法律推理的心理学研究

    Exploring the psychology of GPT-4's Moral and Legal Reasoning. (arXiv:2308.01264v1 [cs.AI])

    [http://arxiv.org/abs/2308.01264](http://arxiv.org/abs/2308.01264)

    本文探究了GPT-4的道德和法律推理，发现其与人类之间在意图归因、因果判断、欺骗的道德性、道德基础、道德运气对法律判断的影响、同意的概念以及规则违反判断方面存在高相关性。

    

    大型语言模型已被用作高度复杂的人工智能的基础，能够对法律和道德问题作出与人类类似的回应。然而，这些模型对于自身内部工作的指导是不可靠的，即使是它们的创建工程团队也无法解释它们如何获得当前所有能力的具体过程。机器心理学这一新兴领域旨在深入了解这些模型拥有的过程和概念。在本文中，我们运用心理学的方法来探究GPT-4的道德和法律推理。具体而言，我们研究了GPT-4与人类在意图归因、因果判断、欺骗的道德性、道德基础、道德运气对法律判断的影响、同意的概念以及规则违反判断方面的相似性和差异。我们发现人类和人工智能的回答之间存在较高的相关性。

    Large language models have been used as the foundation of highly sophisticated artificial intelligences, capable of delivering human-like responses to probes about legal and moral issues. However, these models are unreliable guides to their own inner workings, and even the engineering teams behind their creation are unable to explain exactly how they came to develop all of the capabilities they currently have. The emerging field of machine psychology seeks to gain insight into the processes and concepts that these models possess. In this paper, we employ the methods of psychology to probe into GPT-4's moral and legal reasoning. More specifically, we investigate the similarities and differences between GPT-4 and humans when it comes to intentionality ascriptions, judgments about causation, the morality of deception, moral foundations, the impact of moral luck on legal judgments, the concept of consent, and rule violation judgments. We find high correlations between human and AI response
    
[^8]: XSTest: 用于识别大型语言模型中夸大安全行为的测试套件

    XSTest: A Test Suite for Identifying Exaggerated Safety Behaviours in Large Language Models. (arXiv:2308.01263v1 [cs.CL])

    [http://arxiv.org/abs/2308.01263](http://arxiv.org/abs/2308.01263)

    本文介绍了一个名为XSTest的测试套件，旨在识别大型语言模型中夸大的安全行为。该套件由200个安全提示组成，涵盖十种提示类型，旨在引出模型的系统性问题。

    

    没有适当的保护措施，大型语言模型很容易遵循恶意指令并生成有害内容。这激发了安全工作，如红队测试和大规模反馈学习，旨在使模型既有用又无害。然而，这两个目标之间存在一种紧张关系，因为无害性要求模型拒绝遵从不安全的提示，从而无法提供帮助。最近的一些证据表明，一些模型可能在平衡上存在问题，以至于即使使用类似不安全提示的语言或提及敏感主题的明显安全提示也会被拒绝。本文介绍了一个名为XSTest的新测试套件，以系统化和结构化的方式识别这种夸张的安全行为。目前，XSTest包括200个安全提示，涵盖十种提示类型，良好校准的模型不应该拒绝遵循这些提示。我们描述了XSTest的创建和组成，并使用测试套件突显系统性的问题。

    Without proper safeguards, large language models will readily follow malicious instructions and generate toxic content. This motivates safety efforts such as red-teaming and large-scale feedback learning, which aim to make models both helpful and harmless. However, there is a tension between these two objectives, since harmlessness requires models to refuse complying with unsafe prompts, and thus not be helpful. Recent anecdotal evidence suggests that some models may have struck a poor balance, so that even clearly safe prompts are refused if they use similar language to unsafe prompts or mention sensitive topics. In this paper, we introduce a new test suite called XSTest to identify such eXaggerated Safety behaviours in a structured and systematic way. In its current form, XSTest comprises 200 safe prompts across ten prompt types that well-calibrated models should not refuse to comply with. We describe XSTest's creation and composition, and use the test suite to highlight systematic f
    
[^9]: 在代码理解和生成方面评估指导调优的大型语言模型

    Evaluating Instruction-Tuned Large Language Models on Code Comprehension and Generation. (arXiv:2308.01240v1 [cs.CL])

    [http://arxiv.org/abs/2308.01240](http://arxiv.org/abs/2308.01240)

    本研究在四个代表性的代码理解和生成任务上评估了10种开源指导调优的大型语言模型，发现在零知识迁移的情况下，指导调优的大型语言模型表现出很高的竞争力，在少训练数据的情况下，添加示范样例可以提升模型性能，在微调设置下，微调可以进一步提升模型性能。

    

    在这项工作中，我们评估了10种开源指导调优的大型语言模型在四个代表性的代码理解和生成任务上的表现。我们得到了以下主要发现。首先，在零知识迁移的情况下，指导调优的大型语言模型在代码理解和生成任务上非常有竞争力，有时甚至优于专门针对每个下游任务进行微调的小型最先进模型。我们还发现，更大的指导调优的大型语言模型并不总是在与代码相关的任务上更好。其次，在少训练数据的情况下，我们发现添加示范样例可以大大帮助指导调优的大型语言模型在大多数代码理解和生成任务上表现更好；然而，这些示范样例有时会导致不稳定甚至更差的性能。此外，我们发现广泛使用的基于BM25的样本选择策略在生成问题上明显优于基础的随机选择或固定选择。第三，对于微调设置，我们发现微调可以进一步提高模型在下游任务上的性能。

    In this work, we evaluate 10 open-source instructed LLMs on four representative code comprehension and generation tasks. We have the following main findings. First, for the zero-shot setting, instructed LLMs are very competitive on code comprehension and generation tasks and sometimes even better than small SOTA models specifically fine-tuned on each downstream task. We also find that larger instructed LLMs are not always better on code-related tasks. Second, for the few-shot setting, we find that adding demonstration examples substantially helps instructed LLMs perform better on most code comprehension and generation tasks; however, the examples would sometimes induce unstable or even worse performance. Furthermore, we find widely-used BM25-based shot selection strategy significantly outperforms the basic random selection or fixed selection only on generation problems. Third, for the fine-tuning setting, we find that fine-tuning could further improve the model performance on downstrea
    
[^10]: 多语言语言模型在英语中思考是否更好？

    Do Multilingual Language Models Think Better in English?. (arXiv:2308.01223v1 [cs.CL])

    [http://arxiv.org/abs/2308.01223](http://arxiv.org/abs/2308.01223)

    这项研究提出了一种名为自我翻译的方法，通过利用多语言语言模型的少样本翻译能力，克服了对外部翻译系统的需求，并在多个任务上展示了自我翻译相对于直接推理的优势。

    

    翻译测试是提高多语言语言模型性能的一种常用技术。这种方法通过使用外部机器翻译系统将输入翻译成英语，并对翻译后的输入进行推理来实现。然而，这些改进可以归因于使用一个单独的翻译系统，这个系统通常是在大量的平行数据上进行训练的，而这些数据对于语言模型来说是看不到的。在这项工作中，我们介绍了一种新方法，称为自我翻译，通过利用多语言语言模型的少样本翻译能力来克服对外部翻译系统的需求。对5个任务的实验表明，自我翻译始终优于直接推理，证明了当在非英语语言中进行提示时，语言模型无法充分发挥其多语言潜力。我们的代码可在 https://github.com/juletx/self-translate 中找到。

    Translate-test is a popular technique to improve the performance of multilingual language models. This approach works by translating the input into English using an external machine translation system, and running inference over the translated input. However, these improvements can be attributed to the use of a separate translation system, which is typically trained on large amounts of parallel data not seen by the language model. In this work, we introduce a new approach called self-translate, which overcomes the need of an external translation system by leveraging the few-shot translation capabilities of multilingual language models. Experiments over 5 tasks show that self-translate consistently outperforms direct inference, demonstrating that language models are unable to leverage their full multilingual potential when prompted in non-English languages. Our code is available at https://github.com/juletx/self-translate.
    
[^11]: 深度学习中的校准：最新研究综述

    Calibration in Deep Learning: A Survey of the State-of-the-Art. (arXiv:2308.01222v1 [cs.LG])

    [http://arxiv.org/abs/2308.01222](http://arxiv.org/abs/2308.01222)

    本文回顾了深度学习中的校准方法的最新发展，并提供了对其原理的理解。研究表明，现代深度神经网络在预测能力上表现出色，但校准性较差，导致模型预测不可靠。因此，需要一些新的方法来改善模型的校准性。

    

    在构建可靠、鲁棒的安全关键应用的人工智能系统中，深度神经模型的校准起着重要作用。最近的研究表明，具有高预测能力的现代神经网络的校准性较差，产生不可靠的模型预测。尽管深度学习模型在各种基准测试中取得了显著的性能，但对模型的校准性和可靠性的研究相对较少。理想的深度模型不仅应具有高预测性能，还应具有良好的校准性。最近提出了一些使用不同机制进行深度模型校准的方法。在本综述中，我们回顾了最新的校准方法，并解释了它们执行模型校准的原理。首先，我们从模型校准的定义开始，解释了模型校准不准确的根本原因。然后，我们介绍了可以衡量模型校准性的关键指标。接下来，我们总结了一些校准方法的方法和实践。

    Calibrating deep neural models plays an important role in building reliable, robust AI systems in safety-critical applications. Recent work has shown that modern neural networks that possess high predictive capability are poorly calibrated and produce unreliable model predictions. Though deep learning models achieve remarkable performance on various benchmarks, the study of model calibration and reliability is relatively underexplored. Ideal deep models should have not only high predictive performance but also be well calibrated. There have been some recent methods proposed to calibrate deep models by using different mechanisms. In this survey, we review the state-of-the-art calibration methods and provide an understanding of their principles for performing model calibration. First, we start with the definition of model calibration and explain the root causes of model miscalibration. Then we introduce the key metrics that can measure this aspect. It is followed by a summary of calibrat
    
[^12]: 在医学应用中使用ScrutinAI进行DNN性能的视觉检查

    Using ScrutinAI for Visual Inspection of DNN Performance in a Medical Use Case. (arXiv:2308.01220v1 [cs.LG])

    [http://arxiv.org/abs/2308.01220](http://arxiv.org/abs/2308.01220)

    我们使用可视化分析工具ScrutinAI来研究医疗领域的模型性能和数据集标注质量对模型性能的影响，以及分析深度神经网络模型的缺点和真正的缺陷之间的区别。

    

    我们的可视化分析工具ScrutinAI支持人工分析师交互式地研究模型性能和数据集。模型性能在很大程度上取决于标注质量。特别是在医学环境中，生成高质量的标注需要深入的专业知识，并且非常昂贵。通常，数据集通过收集专家群体的意见进行标注。我们使用我们的可视化分析工具来分析不同专家之间标注变异对模型性能的影响。ScrutinAI有助于进行根本原因分析，将由标注质量不同或缺失引起的深度神经网络（DNN）模型的缺点与真正的缺陷区别开来。我们详细检查了公开可用的数据集中颅内出血的整体检测和亚型之间更细微的区分。

    Our Visual Analytics (VA) tool ScrutinAI supports human analysts to investigate interactively model performanceand data sets. Model performance depends on labeling quality to a large extent. In particular in medical settings, generation of high quality labels requires in depth expert knowledge and is very costly. Often, data sets are labeled by collecting opinions of groups of experts. We use our VA tool to analyse the influence of label variations between different experts on the model performance. ScrutinAI facilitates to perform a root cause analysis that distinguishes weaknesses of deep neural network (DNN) models caused by varying or missing labeling quality from true weaknesses. We scrutinize the overall detection of intracranial hemorrhages and the more subtle differentiation between subtypes in a publicly available data set.
    
[^13]: BiERL: 一种通过双层优化实现的元进化强化学习框架

    BiERL: A Meta Evolutionary Reinforcement Learning Framework via Bilevel Optimization. (arXiv:2308.01207v1 [cs.NE])

    [http://arxiv.org/abs/2308.01207](http://arxiv.org/abs/2308.01207)

    BiERL是一个通用的元进化强化学习框架，通过双层优化来同时更新超参数和训练强化学习模型，从而提高学习效率和性能。

    

    进化强化学习算法最近引起了人们的关注，因为它们能够处理复杂的强化学习问题，具有高并行性，但是在不仔细调整超参数（即元参数）的情况下，往往会面临不足的探索或模型崩溃的问题。在本文中，我们提出了一个通用的元进化强化学习框架，通过双层优化（BiERL）来同时更新超参数和训练强化学习模型，从而免去了在模型部署之前需要先有领域知识或昂贵优化过程的需求。我们设计了一个优雅的元级架构，将内部级别的进化经验嵌入到信息丰富的种群表示中，并引入了一个简单可行的元级适应度函数评估方法，以提高学习效率。我们在MuJoCo和Box2D任务上进行了大量实验，验证了作为一个通用框架，BiERL优于各种基线方法，并且持续改进。

    Evolutionary reinforcement learning (ERL) algorithms recently raise attention in tackling complex reinforcement learning (RL) problems due to high parallelism, while they are prone to insufficient exploration or model collapse without carefully tuning hyperparameters (aka meta-parameters). In the paper, we propose a general meta ERL framework via bilevel optimization (BiERL) to jointly update hyperparameters in parallel to training the ERL model within a single agent, which relieves the need for prior domain knowledge or costly optimization procedure before model deployment. We design an elegant meta-level architecture that embeds the inner-level's evolving experience into an informative population representation and introduce a simple and feasible evaluation of the meta-level fitness function to facilitate learning efficiency. We perform extensive experiments in MuJoCo and Box2D tasks to verify that as a general framework, BiERL outperforms various baselines and consistently improves 
    
[^14]: 个性化的“再次购买”推荐中的类别频率预测

    Personalized Category Frequency prediction for Buy It Again recommendations. (arXiv:2308.01195v1 [cs.IR])

    [http://arxiv.org/abs/2308.01195](http://arxiv.org/abs/2308.01195)

    该论文提出了一种个性化的推荐系统，用于根据客户的重复购买模式预测再次购买的类别和商品。采用层次化PCIC模型，通过生存模型和时间序列模型捕捉消费行为和趋势，并使用这些特征训练类别粒度的神经网络。

    

    “再次购买”（BIA）推荐对于零售商来说至关重要，通过根据客户自己的重复购买模式提供可能再次购买的商品推荐，以改善用户体验和网站参与度。大多数现有的BIA研究分析了客户在商品粒度上的个性化行为。在这种情况下，基于类别的模型可能更合适。我们提出了一种名为“层次化PCIC模型”的推荐系统，它包括了个性化类别模型（PC模型）和类别内个性化商品模型（IC模型）。PC模型生成了一个个性化的类别列表，显示了客户可能再次购买的类别。IC模型在类别内对商品进行排名，显示了客户在类别内可能消费的商品。层次化PCIC模型使用生存模型捕捉产品的一般消费率。时间序列模型捕捉了消费趋势。从这些模型中提取的特征被用来训练一个基于类别的神经网络。

    Buy It Again (BIA) recommendations are crucial to retailers to help improve user experience and site engagement by suggesting items that customers are likely to buy again based on their own repeat purchasing patterns. Most existing BIA studies analyze guests personalized behavior at item granularity. A category-based model may be more appropriate in such scenarios. We propose a recommendation system called a hierarchical PCIC model that consists of a personalized category model (PC model) and a personalized item model within categories (IC model). PC model generates a personalized list of categories that customers are likely to purchase again. IC model ranks items within categories that guests are likely to consume within a category. The hierarchical PCIC model captures the general consumption rate of products using survival models. Trends in consumption are captured using time series models. Features derived from these models are used in training a category-grained neural network. We 
    
[^15]: Mercury:一种用于Nvidia深度学习加速器的自动远程侧信道攻击

    Mercury: An Automated Remote Side-channel Attack to Nvidia Deep Learning Accelerator. (arXiv:2308.01193v1 [cs.CR])

    [http://arxiv.org/abs/2308.01193](http://arxiv.org/abs/2308.01193)

    该论文介绍了Mercury，这是一种针对现成的Nvidia DNN加速器的自动化远程侧信道攻击。它能够克服现有工作中的几个限制，包括只针对简化的加速器实现和需要大量人工分析和领域知识等。

    

    DNN加速器被广泛用于许多场景，以加速推理过程并减少能源消耗。然而，使用加速器的一个重大关注点是已部署模型的保密性：在加速器上进行模型推理执行可能会泄露侧信道信息，使得对手能够精确地恢复模型详情。这种模型提取攻击不仅会危及DNN模型的知识产权，还会促使某些对抗性攻击。

    DNN accelerators have been widely deployed in many scenarios to speed up the inference process and reduce the energy consumption. One big concern about the usage of the accelerators is the confidentiality of the deployed models: model inference execution on the accelerators could leak side-channel information, which enables an adversary to preciously recover the model details. Such model extraction attacks can not only compromise the intellectual property of DNN models, but also facilitate some adversarial attacks.  Although previous works have demonstrated a number of side-channel techniques to extract models from DNN accelerators, they are not practical for two reasons. (1) They only target simplified accelerator implementations, which have limited practicality in the real world. (2) They require heavy human analysis and domain knowledge. To overcome these limitations, this paper presents Mercury, the first automated remote side-channel attack against the off-the-shelf Nvidia DNN acc
    
[^16]: 数据中心化饮食：用于医学图像分割的有效多中心数据集修剪

    Data-Centric Diet: Effective Multi-center Dataset Pruning for Medical Image Segmentation. (arXiv:2308.01189v1 [cs.CV])

    [http://arxiv.org/abs/2308.01189](http://arxiv.org/abs/2308.01189)

    本文针对医学图像分割中的稠密标签问题，提出了一种数据修剪方法，通过动态平均Dice分数考虑目标区域上的训练动态。该方法可以在不牺牲准确性的情况下，修剪数据集的重要部分，解决数据集规模大的问题。

    

    本文旨在解决稠密标签问题，在不牺牲太多准确性的情况下修剪数据集的重要部分。我们观察到，在标准的医学图像分割基准上，应用于图像分类的个别训练样本的损失梯度范数度量无法识别出重要样本。为了解决这个问题，我们提出了一种数据修剪方法，通过使用动态平均Dice分数来考虑目标区域上的训练动态。据我们所知，我们是在医学图像分析领域中首次考虑密集标签任务中数据重要性的研究者，做出以下贡献：(1)通过严格的实证分析研究潜在的原因，(2)确定了在密集标签问题中有效的数据修剪方法。我们的解决方案可以作为选择医学图像分割中重要样本的强大而简单的基准，结合数据来源进行使用。

    This paper seeks to address the dense labeling problems where a significant fraction of the dataset can be pruned without sacrificing much accuracy. We observe that, on standard medical image segmentation benchmarks, the loss gradient norm-based metrics of individual training examples applied in image classification fail to identify the important samples. To address this issue, we propose a data pruning method by taking into consideration the training dynamics on target regions using Dynamic Average Dice (DAD) score. To the best of our knowledge, we are among the first to address the data importance in dense labeling tasks in the field of medical image analysis, making the following contributions: (1) investigating the underlying causes with rigorous empirical analysis, and (2) determining effective data pruning approach in dense labeling problems. Our solution can be used as a strong yet simple baseline to select important examples for medical image segmentation with combined data sou
    
[^17]: LLMs理解玻璃盒模型，发现惊喜并提出修复建议。

    LLMs Understand Glass-Box Models, Discover Surprises, and Suggest Repairs. (arXiv:2308.01157v1 [stat.ML])

    [http://arxiv.org/abs/2308.01157](http://arxiv.org/abs/2308.01157)

    LLMs在处理可解释模型方面表现出色，提供了全面的模型级总结和自动化的异常检测、原因描述和修复建议。在医疗保健领域使用广义可加模型作为示例，同时介绍了开源的LLM-GAM接口包$\texttt{TalkToEBM}$。

    

    我们展示了大型语言模型(LLMs)在处理可解释模型方面的出色表现，这些模型可以将复杂结果分解为单一变量的图表示组件。通过采用层次推理的方法，LLMs能够在不需要整个模型适应上下文的情况下提供全面的模型级总结。这种方法使LLMs能够应用其广泛的背景知识来自动完成数据科学中的常见任务，如检测与先前知识相矛盾的异常，描述异常的潜在原因，并提出去除异常的修复建议。我们使用医疗保健领域的多个示例来证明LLMs的这些新能力的实用性，特别强调广义可加模型(GAMs)。最后，我们将$\texttt{TalkToEBM}$包作为一个开源的LLM-GAM接口进行介绍。

    We show that large language models (LLMs) are remarkably good at working with interpretable models that decompose complex outcomes into univariate graph-represented components. By adopting a hierarchical approach to reasoning, LLMs can provide comprehensive model-level summaries without ever requiring the entire model to fit in context. This approach enables LLMs to apply their extensive background knowledge to automate common tasks in data science such as detecting anomalies that contradict prior knowledge, describing potential reasons for the anomalies, and suggesting repairs that would remove the anomalies. We use multiple examples in healthcare to demonstrate the utility of these new capabilities of LLMs, with particular emphasis on Generalized Additive Models (GAMs). Finally, we present the package $\texttt{TalkToEBM}$ as an open-source LLM-GAM interface.
    
[^18]: 使用语言模型进行算术运算：从记忆到计算

    Arithmetic with Language Models: from Memorization to Computation. (arXiv:2308.01154v1 [cs.AI])

    [http://arxiv.org/abs/2308.01154](http://arxiv.org/abs/2308.01154)

    本研究探索了使用语言模型进行算术计算的能力，发现语言模型可以通过内部的值空间进行计算，并取得了成功的实验结果。

    

    更好地理解最近的大型语言模型的出现性计算和问题解决能力对于进一步改进它们并拓宽其适用性至关重要。本研究探讨了一个训练用于预测下一个标记的语言模型如何在训练数据之外执行算术计算。二进制加法和乘法是一个很好的测试基础，因为它们需要一个非常小的词汇表，并且在输入/输出上展示了相关的不连续性，使得对新数据进行平滑的输入插值无效。我们成功地训练了一个轻量级的语言模型来学习这些任务，并进行了一系列实验证明其外推能力和内部信息处理。我们的研究结果支持这样一个假设，即语言模型作为一个编码-回归-解码机器，一旦将输入标记表示映射到合适的内部值空间，计算就在值空间中进行。

    A better understanding of the emergent computation and problem-solving capabilities of recent large language models is of paramount importance to further improve them and broaden their applicability. This work investigates how a language model, trained to predict the next token, can perform arithmetic computations generalizing beyond training data. Binary addition and multiplication constitute a good testbed for this purpose, since they require a very small vocabulary and exhibit relevant input/output discontinuities making smooth input interpolation ineffective for novel data. We successfully trained a light language model to learn these tasks and ran a number of experiments to investigate the extrapolation capabilities and internal information processing. Our findings support the hypotheses that the language model works as an Encoding-Regression-Decoding machine where the computation takes place in the value space once the input token representation is mapped to an appropriate intern
    
[^19]: 能否转移噪声模式？使用生成案例的多环境频谱分析模型

    Can We Transfer Noise Patterns? An Multi-environment Spectrum Analysis Model Using Generated Cases. (arXiv:2308.01138v1 [cs.LG])

    [http://arxiv.org/abs/2308.01138](http://arxiv.org/abs/2308.01138)

    这项研究提出了一个噪声模式转移模型，可以将噪声模式从不同环境的标准样本应用到未知样本，通过生成案例库来解决样本级噪声对数据集级噪声学习的干扰，提高了系统的学习性能。

    

    在在线水质检测中，频谱分析系统旨在检测污染物的类型和浓度，并使监管机构能够及时回应污染事件。然而，基于频谱数据的测试设备在非实验室环境中部署时会受到复杂的噪声模式的影响。为了使分析模型适用于更多的环境，我们提出了一个噪声模式转移模型，该模型将不同环境中标准水样品的频谱作为案例，并学习它们噪声模式的差异，从而使噪声模式能够应用于未知样品。不幸的是，必然存在的样本级基线噪声使得模型无法获取只在数据集级环境噪声上有差异的配对数据。为了解决这个问题，我们生成了一个样本对样本的案例库，排除了样本级噪声对数据集级噪声学习的干扰，提高了系统的学习性能。

    Spectrum analysis systems in online water quality testing are designed to detect types and concentrations of pollutants and enable regulatory agencies to respond promptly to pollution incidents. However, spectral data-based testing devices suffer from complex noise patterns when deployed in non-laboratory environments. To make the analysis model applicable to more environments, we propose a noise patterns transferring model, which takes the spectrum of standard water samples in different environments as cases and learns the differences in their noise patterns, thus enabling noise patterns to transfer to unknown samples. Unfortunately, the inevitable sample-level baseline noise makes the model unable to obtain the paired data that only differ in dataset-level environmental noise. To address the problem, we generate a sample-to-sample case-base to exclude the interference of sample-level noise on dataset-level noise learning, enhancing the system's learning performance. Experiments on sp
    
[^20]: 推荐系统中的流行偏差综述

    A Survey on Popularity Bias in Recommender Systems. (arXiv:2308.01118v1 [cs.IR])

    [http://arxiv.org/abs/2308.01118](http://arxiv.org/abs/2308.01118)

    这篇综述论文讨论了推荐系统中的流行偏差问题，并回顾了现有的方法来检测、量化和减少流行偏差。它同时提供了计算度量的概述和主要技术方法的回顾。

    

    推荐系统以个性化的方式帮助人们找到相关内容。这些系统的一个主要承诺是能够增加目录中较少知名的物品的可见性。然而，现有研究表明，在许多情况下，现今的推荐算法反而表现出流行偏差，即它们在推荐中经常关注相当流行的物品。这种偏差不仅可能导致短期内对消费者和提供者的推荐价值有限，而且还可能引起不希望的强化效应。在本文中，我们讨论了流行偏差的潜在原因，并回顾了现有的检测、量化和减少推荐系统中流行偏差的方法。因此，我们的综述既包括了文献中使用的计算度量的概述，也包括了减少偏差的主要技术方法的回顾。我们还对这些方法进行了批判性讨论。

    Recommender systems help people find relevant content in a personalized way. One main promise of such systems is that they are able to increase the visibility of items in the long tail, i.e., the lesser-known items in a catalogue. Existing research, however, suggests that in many situations today's recommendation algorithms instead exhibit a popularity bias, meaning that they often focus on rather popular items in their recommendations. Such a bias may not only lead to limited value of the recommendations for consumers and providers in the short run, but it may also cause undesired reinforcement effects over time. In this paper, we discuss the potential reasons for popularity bias and we review existing approaches to detect, quantify and mitigate popularity bias in recommender systems. Our survey therefore includes both an overview of the computational metrics used in the literature as well as a review of the main technical approaches to reduce the bias. We furthermore critically discu
    
[^21]: 面向焊接质量监测的字面感知知识图嵌入：Bosch案例研究

    Literal-Aware Knowledge Graph Embedding for Welding Quality Monitoring: A Bosch Case. (arXiv:2308.01105v1 [cs.AI])

    [http://arxiv.org/abs/2308.01105](http://arxiv.org/abs/2308.01105)

    本文研究了在制造业焊接质量监测中应用知识图嵌入的可能性和程度，解决了两个非常具有挑战性的问题：焊接斑点直径和所属车身的问题。

    

    最近，关于知识图嵌入(KGE)的一系列研究已经出现，其试图通过机器学习(ML)学习实体和关系的嵌入作为数字向量和数学映射。然而，在制造业中，应用KGE解决工业问题的研究还很有限。本文研究了KGE在制造业焊接质量监测中的应用可能性和程度。焊接质量监测是制造业中一项重要问题，每年都会生产数百万辆汽车。本研究与宝马的数据驱动解决方案研究相符，旨在替代传统的拆解汽车的方式，该方式费用高昂且产生废物。本文同时解决了两个非常具有挑战性的问题：焊接斑点直径有多大以及焊接斑点属于哪个汽车车身。传统的机器学习方法难以解决这个问题，因为存在大量的汽车车身。

    Recently there has been a series of studies in knowledge graph embedding (KGE), which attempts to learn the embeddings of the entities and relations as numerical vectors and mathematical mappings via machine learning (ML). However, there has been limited research that applies KGE for industrial problems in manufacturing. This paper investigates whether and to what extent KGE can be used for an important problem: quality monitoring for welding in manufacturing industry, which is an impactful process accounting for production of millions of cars annually. The work is in line with Bosch research of data-driven solutions that intends to replace the traditional way of destroying cars, which is extremely costly and produces waste. The paper tackles two very challenging questions simultaneously: how large the welding spot diameter is; and to which car body the welded spot belongs to. The problem setting is difficult for traditional ML because there exist a high number of car bodies that shoul
    
[^22]: 在京东广告搜索中利用多专家知识蒸馏实现更好的查询分类

    Towards Better Query Classification with Multi-Expert Knowledge Condensation in JD Ads Search. (arXiv:2308.01098v1 [cs.IR])

    [http://arxiv.org/abs/2308.01098](http://arxiv.org/abs/2308.01098)

    本文提出了一种知识蒸馏框架（KC），通过在严格的低延迟约束下提升在线FastText模型的查询分类性能，在京东广告搜索中取得了显著的性能提升。

    

    查询分类作为理解用户意图的有效方法，在现实世界的在线广告系统中具有重要意义。为了确保更低的延迟，常使用浅层模型（如FastText）进行高效的在线推断。然而，FastText模型的表征能力不足，导致分类性能较差，特别是在一些低频查询和尾部类别上。使用更深入且更复杂的模型（如BERT）是一种有效的解决方案，但它将导致更高的在线推断延迟和更昂贵的计算成本。因此，如何在推断效率和分类性能之间折衷显然具有重大实际意义。为了克服这个挑战，在本文中，我们提出了知识蒸馏（KC），一个简单而有效的知识蒸馏框架，以在严格的低延迟约束下提升在线FastText模型的分类性能。具体来说，我们提出了训练一个离线模型，通过蒸馏知识来改善在线模型的分类性能。

    Search query classification, as an effective way to understand user intents, is of great importance in real-world online ads systems. To ensure a lower latency, a shallow model (e.g. FastText) is widely used for efficient online inference. However, the representation ability of the FastText model is insufficient, resulting in poor classification performance, especially on some low-frequency queries and tailed categories. Using a deeper and more complex model (e.g. BERT) is an effective solution, but it will cause a higher online inference latency and more expensive computing costs. Thus, how to juggle both inference efficiency and classification performance is obviously of great practical importance. To overcome this challenge, in this paper, we propose knowledge condensation (KC), a simple yet effective knowledge distillation framework to boost the classification performance of the online FastText model under strict low latency constraints. Specifically, we propose to train an offline
    
[^23]: 使用语义和机器学习扩展数据科学解决方案：博世案例研究

    Scaling Data Science Solutions with Semantics and Machine Learning: Bosch Case. (arXiv:2308.01094v1 [cs.AI])

    [http://arxiv.org/abs/2308.01094](http://arxiv.org/abs/2308.01094)

    该论文提出了SemCloud，一个结合了语义技术和机器学习的语义增强云系统，以应对工业4.0和物联网时代大数据处理的挑战。该系统通过使用领域本体和映射来进行数据集成，并在分布式计算节点上并行处理语义数据和分析任务。此外，SemCloud还采用了自适应学习算法来降低用户训练时间的要求。

    

    工业4.0和物联网技术释放了大量的工厂生产数据，导致了大数据方面的挑战。在这种情况下，云系统等分布式计算解决方案被用来并行处理数据并减少计算时间。随着云系统越来越受欢迎，更多原本不是云专家的用户（如数据科学家、领域专家）需要在云系统上部署解决方案，但是如何满足云系统用户的高需求以及训练他们所需的过长时间是一个非常复杂的问题。因此，我们提出了SemCloud，一个结合了语义技术和机器学习的语义增强云系统。SemCloud依赖于领域本体和映射进行数据集成，并在分布式计算节点上并行进行语义数据集成和数据分析。此外，SemCloud还采用了自适应学习算法来降低训练时间。

    Industry 4.0 and Internet of Things (IoT) technologies unlock unprecedented amount of data from factory production, posing big data challenges in volume and variety. In that context, distributed computing solutions such as cloud systems are leveraged to parallelise the data processing and reduce computation time. As the cloud systems become increasingly popular, there is increased demand that more users that were originally not cloud experts (such as data scientists, domain experts) deploy their solutions on the cloud systems. However, it is non-trivial to address both the high demand for cloud system users and the excessive time required to train them. To this end, we propose SemCloud, a semantics-enhanced cloud system, that couples cloud system with semantic technologies and machine learning. SemCloud relies on domain ontologies and mappings for data integration, and parallelises the semantic data integration and data analysis on distributed computing nodes. Furthermore, SemCloud ado
    
[^24]: 临床应用的手部追踪：验证Google MediaPipe Hand（GMH）和增强型GMH-D框架

    Hand tracking for clinical applications: validation of the Google MediaPipe Hand (GMH) and the depth-enhanced GMH-D frameworks. (arXiv:2308.01088v1 [cs.CV])

    [http://arxiv.org/abs/2308.01088](http://arxiv.org/abs/2308.01088)

    该论文验证了Google MediaPipe Hand（GMH）和增强版本GMH-D框架在临床应用中的手部追踪效果，通过使用RGB-Depth相机的深度估计来实现更准确的3D运动追踪。

    

    在计算机视觉中，准确追踪手部和手指运动面临着重大挑战。潜在的应用范围涵盖了多个领域，包括人机交互、虚拟现实、工业和医学。虽然手势识别已经取得了显著的准确性，但是量化细微的运动仍然是一个障碍，特别是在临床应用中，手功能障碍和康复训练结果的评估需要精确测量。出现了几种基于深度学习的新颖且轻量级的框架来解决这个问题；然而，它们在精确可靠地测量手指运动方面的性能需要对其进行与已建立的黄金标准系统的验证。本文旨在验证由Google MediaPipe Hand（GMH）实现的手部追踪框架以及一种创新的增强版本GMH-D，在RGB-Depth相机的深度估计的基础上实现更准确的3D运动追踪。

    Accurate 3D tracking of hand and fingers movements poses significant challenges in computer vision. The potential applications span across multiple domains, including human-computer interaction, virtual reality, industry, and medicine. While gesture recognition has achieved remarkable accuracy, quantifying fine movements remains a hurdle, particularly in clinical applications where the assessment of hand dysfunctions and rehabilitation training outcomes necessitate precise measurements. Several novel and lightweight frameworks based on Deep Learning have emerged to address this issue; however, their performance in accurately and reliably measuring fingers movements requires validation against well-established gold standard systems. In this paper, the aim is to validate the handtracking framework implemented by Google MediaPipe Hand (GMH) and an innovative enhanced version, GMH-D, that exploits the depth estimation of an RGB-Depth camera to achieve more accurate tracking of 3D movements
    
[^25]: 自动驾驶汽车的空间智能和基于规则的决策制定

    Spatial Intelligence of a Self-driving Car and Rule-Based Decision Making. (arXiv:2308.01085v1 [cs.RO])

    [http://arxiv.org/abs/2308.01085](http://arxiv.org/abs/2308.01085)

    本文展示了如何将规则决策与运动规划技术相结合，实现自动驾驶车辆在复杂交通情况下表现出人类行为的能力，强调了发展机器人空间意识技术的重要性。

    

    本文展示了如何将基于规则的决策制定与传统的运动计划技术相结合，以实现自动驾驶车辆在复杂交通情况下表现出近似于人类行为的能力。我们提供并讨论了自动驾驶中的决策规则示例。通过这些示例，我们说明发展机器人空间意识技术是一项令人兴奋的活动，值得更多的空间推理社区关注。

    In this paper we show how rule-based decision making can be combined with traditional motion planning techniques to achieve human-like behavior of a self-driving vehicle in complex traffic situations. We give and discuss examples of decision rules in autonomous driving. We draw on these examples to illustrate that developing techniques for spatial awareness of robots is an exciting activity which deserves more attention from spatial reasoning community that it had received so far.
    
[^26]: 在组级别的图异常检测中，一种增强拓扑模式的无监督方法

    Graph Anomaly Detection at Group Level: A Topology Pattern Enhanced Unsupervised Approach. (arXiv:2308.01063v1 [cs.LG])

    [http://arxiv.org/abs/2308.01063](http://arxiv.org/abs/2308.01063)

    提出一种新的无监督框架，用于在图中检测组级别的异常，并利用拓扑模式增强了算法的性能。

    

    图异常检测（GAD）已经取得成功，并广泛应用于欺诈检测、网络安全、金融安全和生物化学等领域。然而，现有的图异常检测算法主要关注区分图中的个体实体（节点或图），忽视了图中可能存在的异常组的可能性。为了解决这个限制，本文提出了一种新的无监督框架，用于名为组级图异常检测（Gr-GAD）的新任务。该提议的框架首先使用图自动编码器的变种来定位属于可能异常组的锚定节点，通过捕捉长程不一致性。随后，组采样被用来采样候选组，然后将其输入到所提出的基于拓扑模式的图对比学习（TPGCL）方法中。TPGCL利用组的拓扑模式作为线索为每个候选组生成嵌入，从而区分不同的异常组。

    Graph anomaly detection (GAD) has achieved success and has been widely applied in various domains, such as fraud detection, cybersecurity, finance security, and biochemistry. However, existing graph anomaly detection algorithms focus on distinguishing individual entities (nodes or graphs) and overlook the possibility of anomalous groups within the graph. To address this limitation, this paper introduces a novel unsupervised framework for a new task called Group-level Graph Anomaly Detection (Gr-GAD). The proposed framework first employs a variant of Graph AutoEncoder (GAE) to locate anchor nodes that belong to potential anomaly groups by capturing long-range inconsistencies. Subsequently, group sampling is employed to sample candidate groups, which are then fed into the proposed Topology Pattern-based Graph Contrastive Learning (TPGCL) method. TPGCL utilizes the topology patterns of groups as clues to generate embeddings for each candidate group and thus distinct anomaly groups. The ex
    
[^27]: 对自动驾驶车辆风险评估的反事实安全边界视角

    A Counterfactual Safety Margin Perspective on the Scoring of Autonomous Vehicles' Riskiness. (arXiv:2308.01050v1 [cs.RO])

    [http://arxiv.org/abs/2308.01050](http://arxiv.org/abs/2308.01050)

    本文基于反事实模拟提出了一个数据驱动的框架，用于比较不同自动驾驶车辆在不同操作设计领域中行为风险。通过引入反事实安全边界的概念，该框架可以找到最关键的情景，并评估自动驾驶车辆的风险频率和严重程度。该方法即使在自动驾驶车辆的行为策略未知的情况下也适用，对外部第三方风险评估机构有用。

    

    自动驾驶车辆（AVs）有潜力提供诸多社会效益，如减少道路事故和提高交通效率。然而，由于缺乏历史数据和技术的快速发展，量化AVs的风险是具有挑战性的。本文提出了一个基于数据驱动的框架，用于比较不同AVs在各种操作设计领域（ODDs）中行为的风险，该框架基于对“不良”道路用户进行反事实模拟。我们引入了反事实安全边界的概念，表示可能导致碰撞的最小偏离正常行为的量。该概念有助于找到最关键的情景，同时也有助于评估AVs的风险频率和严重程度。我们证明，即使AV的行为策略是未知的，提出的方法仍然适用于最坏和最佳情况分析，使该方法对外部第三方风险评估机构也有用。

    Autonomous Vehicles (AVs) have the potential to provide numerous societal benefits, such as decreased road accidents and increased overall transportation efficiency. However, quantifying the risk associated with AVs is challenging due to the lack of historical data and the rapidly evolving technology. This paper presents a data-driven framework for comparing the risk of different AVs' behaviors in various operational design domains (ODDs), based on counterfactual simulations of "misbehaving" road users. We introduce the concept of counterfactual safety margin, which represents the minimum deviation from normal behavior that could lead to a collision. This concept helps to find the most critical scenarios but also to assess the frequency and severity of risk of AVs. We show that the proposed methodology is applicable even when the AV's behavioral policy is unknown -- through worst- and best-case analyses -- making the method useful also to external third-party risk assessors. Our experi
    
[^28]: 辅助跨语言交流的聊天翻译错误检测

    Chat Translation Error Detection for Assisting Cross-lingual Communications. (arXiv:2308.01044v1 [cs.CL])

    [http://arxiv.org/abs/2308.01044](http://arxiv.org/abs/2308.01044)

    本文开发了一个通信支持系统，能够检测错误的翻译，以促进跨语言交流。研究者开发了一个错误检测器作为系统的基线，并构建了一个新的日英双语聊天语料库，此举为更高级错误翻译检测系统提供了支持。

    

    本文描述了一个通信支持系统的开发，该系统可以检测错误的翻译，以促进跨语言交流，因为当前机器聊天翻译方法的局限性。我们训练了一个错误检测器作为系统的基线，并构建了一个新的日英双语聊天语料库，BPesona-chat，其中包含了用众包进行质量评级的多轮口语聊天。错误检测器可以为更高级错误翻译检测系统打下良好的基础。

    In this paper, we describe the development of a communication support system that detects erroneous translations to facilitate crosslingual communications due to the limitations of current machine chat translation methods. We trained an error detector as the baseline of the system and constructed a new Japanese-English bilingual chat corpus, BPersona-chat, which comprises multiturn colloquial chats augmented with crowdsourced quality ratings. The error detector can serve as an encouraging foundation for more advanced erroneous translation detection systems.
    
[^29]: 提高离群检测的三个因素

    Three Factors to Improve Out-of-Distribution Detection. (arXiv:2308.01030v1 [cs.LG])

    [http://arxiv.org/abs/2308.01030](http://arxiv.org/abs/2308.01030)

    本论文提出了三个因素来改善离群检测问题。首先，引入自我知识蒸馏损失以提高网络的准确性；其次，在训练过程中采样半困难离群数据以改善离群检测性能；最后，引入新型监督对比学习以同时提高离群检测性能和网络的准确性。通过结合这三个因素，我们的方法在分类和离群检测之间取得了良好的平衡，提高了准确性和离群检测性能。

    

    在离群检测问题中，利用辅助数据作为异常数据进行微调已经显示出令人鼓舞的性能。然而，先前的方法在分类准确性（ACC）和离群检测性能（AUROC、FPR、AUPR）之间存在权衡。为了改善这种权衡，我们做出了三个贡献：（i）引入自我知识蒸馏损失可以增强网络的准确性；（ii）采样半困难离群数据进行训练可以在对准确性影响最小的情况下改善离群检测性能；（iii）引入我们的新型监督对比学习可以同时改善离群检测性能和网络的准确性。通过结合这三个因素，我们的方法通过解决分类和离群检测之间的权衡，提高了准确性和离群检测性能。我们的方法在性能指标上都取得了比以前的方法更好的成绩。

    In the problem of out-of-distribution (OOD) detection, the usage of auxiliary data as outlier data for fine-tuning has demonstrated encouraging performance. However, previous methods have suffered from a trade-off between classification accuracy (ACC) and OOD detection performance (AUROC, FPR, AUPR). To improve this trade-off, we make three contributions: (i) Incorporating a self-knowledge distillation loss can enhance the accuracy of the network; (ii) Sampling semi-hard outlier data for training can improve OOD detection performance with minimal impact on accuracy; (iii) The introduction of our novel supervised contrastive learning can simultaneously improve OOD detection performance and the accuracy of the network. By incorporating all three factors, our approach enhances both accuracy and OOD detection performance by addressing the trade-off between classification and OOD detection. Our method achieves improvements over previous approaches in both performance metrics.
    
[^30]: 使用Floss增强周期性时间序列的表示学习：一种频域正则化方法

    Enhancing Representation Learning for Periodic Time Series with Floss: A Frequency Domain Regularization Approach. (arXiv:2308.01011v1 [cs.LG])

    [http://arxiv.org/abs/2308.01011](http://arxiv.org/abs/2308.01011)

    本文提出了一种叫做Floss的无监督方法，通过在频域上对学到的表示进行正则化来增强周期性时间序列的表示学习。Floss方法可以自动检测时间序列中的周期性并学习具有周期一致性的有意义的表示。

    

    时间序列分析是各个应用领域的基础任务，深度学习方法在这个领域表现出了非凡的性能。然而，许多现实世界的时间序列数据展现出重要的周期性或准周期性动态，这些动态往往不能被现有的基于深度学习的解决方案充分捕捉到。这导致对感兴趣的基础动态行为的表示不完整。为了解决这个问题，我们提出了一种无监督的方法叫做Floss，它通过自动化地在频域上调整学到的表示来进行正则化。Floss方法首先自动检测时间序列中的主要周期性。然后，它利用周期移位和谱密度相似度度量来学习具有周期一致性的有意义的表示。此外，Floss可以轻松地整合到有监督、半监督和无监督的学习框架中。

    Time series analysis is a fundamental task in various application domains, and deep learning approaches have demonstrated remarkable performance in this area. However, many real-world time series data exhibit significant periodic or quasi-periodic dynamics that are often not adequately captured by existing deep learning-based solutions. This results in an incomplete representation of the underlying dynamic behaviors of interest. To address this gap, we propose an unsupervised method called Floss that automatically regularizes learned representations in the frequency domain. The Floss method first automatically detects major periodicities from the time series. It then employs periodic shift and spectral density similarity measures to learn meaningful representations with periodic consistency. In addition, Floss can be easily incorporated into both supervised, semi-supervised, and unsupervised learning frameworks. We conduct extensive experiments on common time series classification, for
    
[^31]: FusionAD: 自动驾驶预测和规划任务的多模态融合

    FusionAD: Multi-modality Fusion for Prediction and Planning Tasks of Autonomous Driving. (arXiv:2308.01006v1 [cs.CV])

    [http://arxiv.org/abs/2308.01006](http://arxiv.org/abs/2308.01006)

    FusionAD是第一个将来自相机和激光雷达的信息融合起来用于自动驾驶预测和规划任务的统一框架，在常用数据集上的实验中达到了最先进的性能。

    

    在自动驾驶感知任务中，构建一个多模态多任务神经网络以实现准确和稳健的性能已成为铁板一块的标准。然而，利用来自多个传感器的数据来联合优化预测和规划任务仍然几乎未被探索。本文提出了FusionAD，据我们所知，这是第一个将来自两个最关键传感器相机和激光雷达的信息融合起来超越感知任务的统一框架。具体来说，我们首先构建了一个基于转换器的多模态融合网络，以有效地产生基于融合的特征。然后，与基于相机的端到端方法UniAD相比，我们建立了一个融合辅助的模态感知预测和状态感知规划模块，称为FMSPnP，充分利用多模态特征的优势。我们在常用的nuScenes数据集上进行了大量实验，结果表明我们的FusionAD达到了最先进的性能，并优于基准线平均15%的性能。

    Building a multi-modality multi-task neural network toward accurate and robust performance is a de-facto standard in perception task of autonomous driving. However, leveraging such data from multiple sensors to jointly optimize the prediction and planning tasks remains largely unexplored. In this paper, we present FusionAD, to the best of our knowledge, the first unified framework that fuse the information from two most critical sensors, camera and LiDAR, goes beyond perception task. Concretely, we first build a transformer based multi-modality fusion network to effectively produce fusion based features. In constrast to camera-based end-to-end method UniAD, we then establish a fusion aided modality-aware prediction and status-aware planning modules, dubbed FMSPnP that take advantages of multi-modality features. We conduct extensive experiments on commonly used benchmark nuScenes dataset, our FusionAD achieves state-of-the-art performance and surpassing baselines on average 15% on perce
    
[^32]: 基于Wasserstein多样性增强正则化器的层次化强化学习

    Wasserstein Diversity-Enriched Regularizer for Hierarchical Reinforcement Learning. (arXiv:2308.00989v1 [cs.LG])

    [http://arxiv.org/abs/2308.00989](http://arxiv.org/abs/2308.00989)

    本文中，我们提出了一种新的任务无关正则化器WDER，通过增加子策略的多样性来解决层次化强化学习中的退化问题。实验证明，WDER能够提高性能和样本效率，并且不需要修改超参数。

    

    层次化强化学习通过将不同层次的子策略组合起来完成复杂任务。自动发现子策略是一种不依赖于领域知识的生成子策略的有前景的方法。然而，存在方法很难处理的退化问题，这是由于缺乏对多样性的考虑或使用弱正则化器。在本文中，我们提出了一种新的与任务无关的正则化器，称为Wasserstein多样性增强正则化器（WDER），通过最大化动作分布之间的Wasserstein距离来增加子策略的多样性。所提出的WDER可以轻松地融入到现有方法的损失函数中，进一步提高它们的性能。实验结果表明，相比于之前的工作，在不修改超参数的情况下，我们的WDER提高了性能和样本效率，这表明了WDER的适用性和鲁棒性。

    Hierarchical reinforcement learning composites subpolicies in different hierarchies to accomplish complex tasks.Automated subpolicies discovery, which does not depend on domain knowledge, is a promising approach to generating subpolicies.However, the degradation problem is a challenge that existing methods can hardly deal with due to the lack of consideration of diversity or the employment of weak regularizers. In this paper, we propose a novel task-agnostic regularizer called the Wasserstein Diversity-Enriched Regularizer (WDER), which enlarges the diversity of subpolicies by maximizing the Wasserstein distances among action distributions. The proposed WDER can be easily incorporated into the loss function of existing methods to boost their performance further.Experimental results demonstrate that our WDER improves performance and sample efficiency in comparison with prior work without modifying hyperparameters, which indicates the applicability and robustness of the WDER.
    
[^33]: 隔离和诱导：针对模型窃取攻击的鲁棒深度神经网络训练

    Isolation and Induction: Training Robust Deep Neural Networks against Model Stealing Attacks. (arXiv:2308.00958v1 [cs.CR])

    [http://arxiv.org/abs/2308.00958](http://arxiv.org/abs/2308.00958)

    这项研究提出了一种名为隔离和诱导（InI）的训练框架，用于对抗模型窃取攻击。该框架通过隔离对手的训练梯度，并直接训练一个防御模型，有效地解决了现有防御方法中推理计算开销高和准确性与防窃鲁棒性之间的不利权衡问题。

    

    尽管机器学习模型作为服务（MLaaS）广泛应用，但它们容易受到模型窃取攻击的威胁。这些攻击可以通过黑盒查询过程复制模型功能，而不需要任何关于目标受害模型的先前知识。现有的窃取防御方法通过向受害者的后验概率添加欺骗性扰动来误导攻击者。然而，这些防御方法现在面临着推理计算开销高和良好准确性与防窃鲁棒性之间不利权衡的问题，这挑战了在实践中部署这些模型的可行性。为了解决这些问题，本文提出了一种新颖有效的模型窃取防御训练框架Isolation and Induction（InI）。InI不像部署辅助防御模块那样引入冗余推理时间，而是通过将对手的训练梯度与预期梯度隔离来直接训练防御模型，可以有效地减少推理计算开销。

    Despite the broad application of Machine Learning models as a Service (MLaaS), they are vulnerable to model stealing attacks. These attacks can replicate the model functionality by using the black-box query process without any prior knowledge of the target victim model. Existing stealing defenses add deceptive perturbations to the victim's posterior probabilities to mislead the attackers. However, these defenses are now suffering problems of high inference computational overheads and unfavorable trade-offs between benign accuracy and stealing robustness, which challenges the feasibility of deployed models in practice. To address the problems, this paper proposes Isolation and Induction (InI), a novel and effective training framework for model stealing defenses. Instead of deploying auxiliary defense modules that introduce redundant inference time, InI directly trains a defensive model by isolating the adversary's training gradient from the expected gradient, which can effectively reduc
    
[^34]: 从稀疏到软性混合专家模型

    From Sparse to Soft Mixtures of Experts. (arXiv:2308.00951v1 [cs.LG])

    [http://arxiv.org/abs/2308.00951](http://arxiv.org/abs/2308.00951)

    本文提出了一种Soft MoE模型，它是一种稀疏的、完全可微分的Transformer，通过隐式的软分配和只处理部分标记的方式解决了稀疏模型的训练不稳定性和推理成本高的问题，并在视觉识别任务中取得了比标准Transformer和其他MoE变体更好的性能。

    

    稀疏的专家模型(MoEs)可以在不增加训练或推理成本的情况下扩展模型容量。尽管它们取得了成功，但MoEs存在一些问题：训练不稳定、丢失标记、无法扩展专家数量或无效的微调。在这项工作中，我们提出了Soft MoE，一种完全可微分的稀疏Transformer，解决了这些挑战，并保持了MoEs的优点。Soft MoE通过向每个专家传递所有输入标记的不同加权组合来执行隐式的软分配。与其他MoE作品一样，Soft MoE中的专家只处理一部分（组合的）标记，以在较低的推理成本下实现更大的模型容量。在视觉识别方面，Soft MoE在标准Transformer（ViTs）和流行的MoE变体（Tokens Choice和Experts Choice）中表现出非常好的性能。例如，Soft MoE-Base/16的推理成本比ViT-Huge/14低10.5倍（墙钟时间降低了5.7倍），同时与其性能相当。

    Sparse mixture of expert architectures (MoEs) scale model capacity without large increases in training or inference costs. Despite their success, MoEs suffer from a number of issues: training instability, token dropping, inability to scale the number of experts, or ineffective finetuning. In this work, we proposeSoft MoE, a fully-differentiable sparse Transformer that addresses these challenges, while maintaining the benefits of MoEs. Soft MoE performs an implicit soft assignment by passing different weighted combinations of all input tokens to each expert. As in other MoE works, experts in Soft MoE only process a subset of the (combined) tokens, enabling larger model capacity at lower inference cost. In the context of visual recognition, Soft MoE greatly outperforms standard Transformers (ViTs) and popular MoE variants (Tokens Choice and Experts Choice). For example, Soft MoE-Base/16 requires 10.5x lower inference cost (5.7x lower wall-clock time) than ViT-Huge/14 while matching its p
    
[^35]: 教授较小的语言模型如何推广到未见过的组合问题

    Teaching Smaller Language Models To Generalise To Unseen Compositional Questions. (arXiv:2308.00946v1 [cs.CL])

    [http://arxiv.org/abs/2308.00946](http://arxiv.org/abs/2308.00946)

    我们研究了如何教授较小的语言模型来推广到未见过的组合问题，通过多任务监督预训练和密集检索系统，我们建立了强大的基准，并展示了解决多个评估数据集上的问题的能力。

    

    我们使一个较小的语言模型能够推广到回答具有挑战性的组合问题，这些问题在训练中没有出现。为此，我们提出了一种多任务监督预训练的组合方法，涵盖了最多93个任务，旨在培养多样的推理能力，并结合了一个密集的检索系统，旨在检索一组证据性的段落片段。在问答方面，最近的进展要么通过针对非常大的预训练语言模型的提示方法实现零或少样本学习，要么通过微调较小的模型，有时结合信息检索进行。我们关注较少探索的问题，即较小的模型在对于不存在足够信息来回答特定问题的语料库进行检索时，能否实现零样本推广。我们在这个设置中为多样的评估数据集（StrategyQA，CommonsenseQA，IIRC，DROP，Musique和ARC-DA）建立了强大的基准，并展示了...

    We equip a smaller Language Model to generalise to answering challenging compositional questions that have not been seen in training. To do so we propose a combination of multitask supervised pretraining on up to 93 tasks designed to instill diverse reasoning abilities, and a dense retrieval system that aims to retrieve a set of evidential paragraph fragments. Recent progress in question-answering has been achieved either through prompting methods against very large pretrained Language Models in zero or few-shot fashion, or by fine-tuning smaller models, sometimes in conjunction with information retrieval. We focus on the less explored question of the extent to which zero-shot generalisation can be enabled in smaller models with retrieval against a corpus within which sufficient information to answer a particular question may not exist. We establish strong baselines in this setting for diverse evaluation datasets (StrategyQA, CommonsenseQA, IIRC, DROP, Musique and ARC-DA), and show tha
    
[^36]: 特征感知的条件生成对抗网络用于类别文本生成

    Feature-aware conditional GAN for category text generation. (arXiv:2308.00939v1 [cs.CL])

    [http://arxiv.org/abs/2308.00939](http://arxiv.org/abs/2308.00939)

    本文提出了一个名为特征感知的条件生成对抗网络（FA-GAN）的新框架，用于解决文本GAN中的离散性、训练不稳定、模式崩溃、缺乏多样性和可控性等问题。FA-GAN使用特征感知编码器和类别感知编码器，以及关系记忆核的解码器，通过生成序列来提高句子多样性，并具有额外的类别分类头。

    

    类别文本生成受到了相当大的关注，因为它对于各种自然语言处理任务都有益处。最近，生成对抗网络（GAN）在文本生成方面取得了有希望的性能，这归功于其对抗训练过程。然而，文本GAN存在一些问题，包括离散性、训练不稳定、模式崩溃、缺乏多样性和可控性等等。为了解决这些问题，本文提出了一种新颖的GAN框架，即特征感知的条件生成对抗网络（FA-GAN），用于可控的类别文本生成。在FA-GAN中，生成器具有序列到序列的结构，用于提高句子多样性，它包括三个编码器，包括一个特征感知编码器和一个类别感知编码器，以及一个基于关系记忆核的解码器，使用Gumbel SoftMax激活函数。鉴别器还具有额外的类别分类头。为了生成指定类别的句子，

    Category text generation receives considerable attentions since it is beneficial for various natural language processing tasks. Recently, the generative adversarial network (GAN) has attained promising performance in text generation, attributed to its adversarial training process. However, there are several issues in text GANs, including discreteness, training instability, mode collapse, lack of diversity and controllability etc. To address these issues, this paper proposes a novel GAN framework, the feature-aware conditional GAN (FA-GAN), for controllable category text generation. In FA-GAN, the generator has a sequence-to-sequence structure for improving sentence diversity, which consists of three encoders including a special feature-aware encoder and a category-aware encoder, and one relational-memory-core-based decoder with the Gumbel SoftMax activation function. The discriminator has an additional category classification head. To generate sentences with specified categories, the m
    
[^37]: LEMMA: 学习语言条件下的多机器人操作

    LEMMA: Learning Language-Conditioned Multi-Robot Manipulation. (arXiv:2308.00937v1 [cs.RO])

    [http://arxiv.org/abs/2308.00937](http://arxiv.org/abs/2308.00937)

    LEMMA是一个学习语言条件下的多机器人操作的基准，通过专家示范和人类指令进行任务分配和长时间跨度物体操作。它提供了涉及工具使用和传递的复杂操纵任务，并提出了一种模块化分层规划方法作为基线。

    

    复杂的操纵任务通常需要具有互补功能的机器人进行协作。我们引入了一种基于人类语言指令的桌面设置中任务分配和长时间跨度物体操作的LanguagE-Conditioned Multi-robot MAnipulation (LEMMA)基准。LEMMA具有8种类型的程序生成任务，具有不同的复杂度，其中一些任务要求机器人使用工具并相互传递工具。对于每个任务，我们提供800个专家示范和人类指令进行培训和评估。与现有基准相比，LEMMA提出了更大的挑战，因为它要求系统识别每个操纵器的限制，并相应地分配子任务，同时处理每个任务中的强时间依赖关系。为了解决这些挑战，我们提出了一种模块化分层规划方法作为基线。我们的结果突出了LEMMA在开发未来语言条件下的多机器人操作方面的潜力。

    Complex manipulation tasks often require robots with complementary capabilities to collaborate. We introduce a benchmark for LanguagE-Conditioned Multi-robot MAnipulation (LEMMA) focused on task allocation and long-horizon object manipulation based on human language instructions in a tabletop setting. LEMMA features 8 types of procedurally generated tasks with varying degree of complexity, some of which require the robots to use tools and pass tools to each other. For each task, we provide 800 expert demonstrations and human instructions for training and evaluations. LEMMA poses greater challenges compared to existing benchmarks, as it requires the system to identify each manipulator's limitations and assign sub-tasks accordingly while also handling strong temporal dependencies in each task. To address these challenges, we propose a modular hierarchical planning approach as a baseline. Our results highlight the potential of LEMMA for developing future language-conditioned multi-robot s
    
[^38]: 基于状态的自适应速度限制策略的粒子群优化

    Particle swarm optimization with state-based adaptive velocity limit strategy. (arXiv:2308.00936v1 [cs.NE])

    [http://arxiv.org/abs/2308.00936](http://arxiv.org/abs/2308.00936)

    提出了一种基于状态的自适应速度限制策略的粒子群优化（PSO-SAVL）方法，通过根据进化状态估计（ESE）来自适应地调整速度限制（VL），以提高粒子群优化的性能。

    

    速度限制（VL）广泛应用于许多粒子群优化（PSO）的变种中，以防止粒子在解空间之外进行搜索。已经引入了几种自适应VL策略，可以提高PSO的性能。然而，现有的自适应VL策略仅根据迭代次数调整VL，导致优化结果不理想，因为VL与粒子的当前搜索状态之间不兼容。为了解决这个问题，提出了一种新的基于状态的自适应速度限制策略的PSO变种（PSO-SAVL）。在提出的PSO-SAVL中，VL基于进化状态估计（ESE）自适应调整，其中为全局搜索状态设置较高的VL值，为局部搜索状态设置较低的VL值。此外，改进并采用了限制处理策略，以提高避免局部最优的能力。实验证明了PSO-SAVL的良好性能。

    Velocity limit (VL) has been widely adopted in many variants of particle swarm optimization (PSO) to prevent particles from searching outside the solution space. Several adaptive VL strategies have been introduced with which the performance of PSO can be improved. However, the existing adaptive VL strategies simply adjust their VL based on iterations, leading to unsatisfactory optimization results because of the incompatibility between VL and the current searching state of particles. To deal with this problem, a novel PSO variant with state-based adaptive velocity limit strategy (PSO-SAVL) is proposed. In the proposed PSO-SAVL, VL is adaptively adjusted based on the evolutionary state estimation (ESE) in which a high value of VL is set for global searching state and a low value of VL is set for local searching state. Besides that, limit handling strategies have been modified and adopted to improve the capability of avoiding local optima. The good performance of PSO-SAVL has been experi
    
[^39]: 物理信息神经网络用于血流逆问题

    Physics-informed neural networks for blood flow inverse problems. (arXiv:2308.00927v1 [cs.CE])

    [http://arxiv.org/abs/2308.00927](http://arxiv.org/abs/2308.00927)

    本研究利用物理信息神经网络方法，在血液动力学中解决了缺乏完整信息和只有散射测量数据的逆问题。结果表明该方法在使用模拟数据时能够稳定准确地估计模型参数，并且能够处理复杂的流动模式，从而解决了与血液动力学和复杂耦合物理系统相关的临床逆问题。

    

    物理信息神经网络（PINNs）已经成为解决逆问题的强大工具，尤其是在没有完整系统信息并且只有散射测量数据的情况下。这在血液动力学中特别有用，因为边界信息通常很难建模，获取高质量的血流测量数据通常很困难。在这项工作中，我们使用PINNs方法来估计散射2D噪声测量数据在升主动脉中的缩减模型参数和完整的速度场。结果表明，在使用模拟数据时，该方法能够稳定准确地估计参数，而速度重建则取决于测量质量和流动模式复杂性。该方法可以解决与血液动力学和复杂耦合物理系统相关的临床相关逆问题。

    Physics-informed neural networks (PINNs) have emerged as a powerful tool for solving inverse problems, especially in cases where no complete information about the system is known and scatter measurements are available. This is especially useful in hemodynamics since the boundary information is often difficult to model, and high-quality blood flow measurements are generally hard to obtain. In this work, we use the PINNs methodology for estimating reduced-order model parameters and the full velocity field from scatter 2D noisy measurements in the ascending aorta. The results show stable and accurate parameter estimations when using the method with simulated data, while the velocity reconstruction shows dependence on the measurement quality and the flow pattern complexity. The method allows for solving clinical-relevant inverse problems in hemodynamics and complex coupled physical systems.
    
[^40]: VLUCI: 可变参数学习未观测混淆变量进行反事实推断

    VLUCI: Variational Learning of Unobserved Confounders for Counterfactual Inference. (arXiv:2308.00904v1 [cs.LG])

    [http://arxiv.org/abs/2308.00904](http://arxiv.org/abs/2308.00904)

    VLUCI是一个新颖的可变参数学习模型，用于解决反事实推断中的未观测混淆变量的问题。它通过生成未观测混淆变量的后验分布，并构建一个双重变分推断模型来解决因果推断中观测和未观测混淆变量的问题，从而提高反事实推断的准确性。

    

    因果推断在流行病学、医疗保健和经济学等领域中起着重要作用。在观察数据中进行去混淆和反事实预测已经成为因果推断研究中的一个重要问题。虽然现有模型可以处理观察到的混淆变量，但未观测到的混淆变量的存在仍然是一个重大挑战，扭曲了因果推断并影响了反事实结果的准确性。为了解决这个问题，我们提出了一个新颖的可变参数学习模型，用于反事实推断中的未观测混淆变量（VLUCI），它生成了未观测混淆变量的后验分布。VLUCI放松了大多数因果推断方法往往忽视的无混淆假设。通过解耦观察到的混淆变量和未观测到的混淆变量，VLUCI构建了一个双重变分推断模型，以近似未观测混淆变量的分布，这些变量用于推断更准确的反事实结果。对合成和实际数据上进行了大量实验。

    Causal inference plays a vital role in diverse domains like epidemiology, healthcare, and economics. De-confounding and counterfactual prediction in observational data has emerged as a prominent concern in causal inference research. While existing models tackle observed confounders, the presence of unobserved confounders remains a significant challenge, distorting causal inference and impacting counterfactual outcome accuracy. To address this, we propose a novel variational learning model of unobserved confounders for counterfactual inference (VLUCI), which generates the posterior distribution of unobserved confounders. VLUCI relaxes the unconfoundedness assumption often overlooked by most causal inference methods. By disentangling observed and unobserved confounders, VLUCI constructs a doubly variational inference model to approximate the distribution of unobserved confounders, which are used for inferring more accurate counterfactual outcomes. Extensive experiments on synthetic and s
    
[^41]: 用连续会话中的实时准确评分提高机器学习性能：基于客观骨骼肌疼痛强度预测的试点研究

    Enhancing Machine Learning Performance with Continuous In-Session Ground Truth Scores: Pilot Study on Objective Skeletal Muscle Pain Intensity Prediction. (arXiv:2308.00886v1 [cs.LG])

    [http://arxiv.org/abs/2308.00886](http://arxiv.org/abs/2308.00886)

    本研究提出了一种使用实时准确评分来提高机器学习性能的方法，通过采集实时疼痛评分和内胚层活动数据，在疼痛分类任务中取得了较好的结果。

    

    机器学习（ML）模型训练了主观自我报告评分后，由于实时疼痛体验和后续记录得分之间的显著变异，很难准确地客观分类疼痛。本研究开发了两个设备，用于获取实时连续会话中的疼痛评分和自主神经系统调节的内胚层活动（EDA）数据。实验招募N = 24名受试者，进行了运动后循环阻塞（PECO）伸展引起的不适。受试者数据存储在定制的疼痛平台中，便于提取时域EDA特征和会话中的准确评分。此外，还从每个受试者收集了实验后的视觉模拟量表（VAS）评分。分别使用相应的客观EDA特征结合会话中得分和会话后得分，训练了多层感知器（MLP）和随机森林（RF）等机器学习模型。在10倍交叉验证中，进行了宏观平均功能评估。

    Machine learning (ML) models trained on subjective self-report scores struggle to objectively classify pain accurately due to the significant variance between real-time pain experiences and recorded scores afterwards. This study developed two devices for acquisition of real-time, continuous in-session pain scores and gathering of ANS-modulated endodermal activity (EDA).The experiment recruited N = 24 subjects who underwent a post-exercise circulatory occlusion (PECO) with stretch, inducing discomfort. Subject data were stored in a custom pain platform, facilitating extraction of time-domain EDA features and in-session ground truth scores. Moreover, post-experiment visual analog scale (VAS) scores were collected from each subject. Machine learning models, namely Multi-layer Perceptron (MLP) and Random Forest (RF), were trained using corresponding objective EDA features combined with in-session scores and post-session scores, respectively. Over a 10-fold cross-validation, the macro-avera
    
[^42]: 仁爱智能：通过AI系统对利益、援助及相关道德失误进行建模的能力方法

    Beneficent Intelligence: A Capability Approach to Modeling Benefit, Assistance, and Associated Moral Failures through AI Systems. (arXiv:2308.00868v1 [cs.AI])

    [http://arxiv.org/abs/2308.00868](http://arxiv.org/abs/2308.00868)

    借鉴能力方法，研究者提出了一个框架，用于解决AI系统与个体互动时涌现的伦理问题。同时，他们也界定了道德可接受的互动条件，并对几种失败模式进行了对比分析。

    

    AI伦理学中普遍的讨论缺乏捕捉AI系统与个体互动时涌现的多样化伦理关切所需的语言和形式。借鉴Sen和Nussbaum的能力方法，我们提出一个框架，形式化了AI系统为利益相关者提供有意义的利益或援助所必需的伦理概念和权利。这些系统增强了利益相关者推进其人生计划和幸福感的能力，同时维护其基本权利。我们界定了AI系统与受其功能影响的人之间道德上可接受的互动的两个必要条件，以及实现有意义利益理想的两个充分条件。然后，我们将这个理想与几种突出的失败模式进行对比，即构成不合理的家长式主义、强迫、欺骗、剥削和支配的社交互动形式。

    The prevailing discourse around AI ethics lacks the language and formalism necessary to capture the diverse ethical concerns that emerge when AI systems interact with individuals. Drawing on Sen and Nussbaum's capability approach, we present a framework formalizing a network of ethical concepts and entitlements necessary for AI systems to confer meaningful benefit or assistance to stakeholders. Such systems enhance stakeholders' ability to advance their life plans and well-being while upholding their fundamental rights. We characterize two necessary conditions for morally permissible interactions between AI systems and those impacted by their functioning, and two sufficient conditions for realizing the ideal of meaningful benefit. We then contrast this ideal with several salient failure modes, namely, forms of social interactions that constitute unjustified paternalism, coercion, deception, exploitation and domination. The proliferation of incidents involving AI in high-stakes domains 
    
[^43]: PeRP：通过合作咨询系统实现个性化剩余策略以缓解拥堵

    PeRP: Personalized Residual Policies For Congestion Mitigation Through Co-operative Advisory Systems. (arXiv:2308.00864v1 [cs.LG])

    [http://arxiv.org/abs/2308.00864](http://arxiv.org/abs/2308.00864)

    本论文提出了一种基于个性化剩余策略的合作咨询系统PeRP，用于缓解拥堵。该系统通过结构化建模人类驾驶的相似性，并根据驾驶员的特征为其提供行动建议，以减少交通拥堵。

    

    智能驾驶系统可以通过简单的行动来缓解拥堵，从而改善通勤时间和燃油成本等众多社会经济因素。然而，这些系统假设对自动驾驶车队具有精确的控制，因此在实际中存在限制，因为它们未能考虑到人类行为的不确定性。分段常数（PC）策略通过结构建模人类驾驶的相似性来减少交通拥堵，以提供给人类驾驶员遵循的行动建议。然而，PC策略假设所有驾驶员行为相似。为了实现这一目标，我们开发了一个基于PC策略的合作咨询系统，其中包含一种新型的驾驶员特征相关的个性化剩余策略，即PeRP。PeRP建议驾驶员以减少交通拥堵的方式行驶。我们首先使用变分自动编码器无监督地推断驾驶员如何遵循指令的内在特征。然后，通过将策略与驾驶员特征条件化，实现个性化的行动建议。

    Intelligent driving systems can be used to mitigate congestion through simple actions, thus improving many socioeconomic factors such as commute time and gas costs. However, these systems assume precise control over autonomous vehicle fleets, and are hence limited in practice as they fail to account for uncertainty in human behavior. Piecewise Constant (PC) Policies address these issues by structurally modeling the likeness of human driving to reduce traffic congestion in dense scenarios to provide action advice to be followed by human drivers. However, PC policies assume that all drivers behave similarly. To this end, we develop a co-operative advisory system based on PC policies with a novel driver trait conditioned Personalized Residual Policy, PeRP. PeRP advises drivers to behave in ways that mitigate traffic congestion. We first infer the driver's intrinsic traits on how they follow instructions in an unsupervised manner with a variational autoencoder. Then, a policy conditioned o
    
[^44]: 用串图进行主动推理：预测处理和自由能的范畴化描述

    Active Inference in String Diagrams: A Categorical Account of Predictive Processing and Free Energy. (arXiv:2308.00861v1 [math.CT])

    [http://arxiv.org/abs/2308.00861](http://arxiv.org/abs/2308.00861)

    该论文介绍了一个用串图表述的主动推理的范畴化框架，提供了生成模型、贝叶斯更新、感知、规划、主动推理和自由能的图形化描述，并通过自由能最小化的串图推导给出了主动推理的公式，还确定了自由能的组合性质。

    

    我们提出了一个范畴化的表述预测处理和主动推理的认知框架，该框架是在具有复制和丢弃操作符的幺半范畴中解释的串图。这包括了生成模型、贝叶斯更新、感知、规划、主动推理和自由能的图形化描述。特别地，我们通过自由能最小化的串图推导提出了主动推理的公式，并确立了自由能的组合性质，使得自由能可以应用于一个代理的生成模型的所有层次上。除了为熟悉主动推理的人提供一个有帮助的图形化语言外，我们也希望本文能够提供该框架的简明表述和介绍。

    We present a categorical formulation of the cognitive frameworks of Predictive Processing and Active Inference, expressed in terms of string diagrams interpreted in a monoidal category with copying and discarding. This includes diagrammatic accounts of generative models, Bayesian updating, perception, planning, active inference, and free energy. In particular we present a diagrammatic derivation of the formula for active inference via free energy minimisation, and establish a compositionality property for free energy, allowing free energy to be applied at all levels of an agent's generative model. Aside from aiming to provide a helpful graphical language for those familiar with active inference, we conversely hope that this article may provide a concise formulation and introduction to the framework.
    
[^45]: 通过探索随机过程来理解人工神经网络中的激活模式

    Understanding Activation Patterns in Artificial Neural Networks by Exploring Stochastic Processes. (arXiv:2308.00858v1 [cs.LG])

    [http://arxiv.org/abs/2308.00858](http://arxiv.org/abs/2308.00858)

    该论文提出了利用随机过程框架来研究人工神经网络中的激活模式。通过模拟和实验，研究人员得到了描述每个网络中激活模式的参数。

    

    为了更深入地了解（深层）人工神经网络的行为和学习动态，采用数学抽象和模型是有价值的。这些工具提供了对网络性能的简化视角，并通过模拟促进了系统性的研究。在本文中，我们提出利用迄今为止未充分利用的随机过程框架。我们的方法将（深层）人工神经网络中的阈值节点的激活模式建模为随机过程。我们仅关注激活频率，利用用于真实神经元尖峰信号的神经科学技术。在分类任务中，我们提取尖峰活动并使用符合泊松分布的到达过程。我们在图像识别任务中检查来自各种人工神经网络的观察数据，拟合所提出模型的假设。通过这样做，我们得到了描述每个网络中激活模式的参数。我们的分析

    To gain a deeper understanding of the behavior and learning dynamics of (deep) artificial neural networks, it is valuable to employ mathematical abstractions and models. These tools provide a simplified perspective on network performance and facilitate systematic investigations through simulations. In this paper, we propose utilizing the framework of stochastic processes, which has been underutilized thus far.  Our approach models activation patterns of thresholded nodes in (deep) artificial neural networks as stochastic processes. We focus solely on activation frequency, leveraging neuroscience techniques used for real neuron spike trains. During a classification task, we extract spiking activity and use an arrival process following the Poisson distribution.  We examine observed data from various artificial neural networks in image recognition tasks, fitting the proposed model's assumptions. Through this, we derive parameters describing activation patterns in each network. Our analysi
    
[^46]: 训练焦点图像提高对对抗攻击的健壮性

    Training on Foveated Images Improves Robustness to Adversarial Attacks. (arXiv:2308.00854v1 [cs.CV])

    [http://arxiv.org/abs/2308.00854](http://arxiv.org/abs/2308.00854)

    本研究通过使用RBlur转换的图像来训练深度神经网络(DNN)，证明了相比于在原始图像上训练的DNN，使用RBlur方法训练的DNN对对抗攻击和其他损坏具有更强的健壮性，提高了高达25%的准确性。

    

    深度神经网络(DNNs)对对抗攻击具有脆弱性，即输入的细微、被感知不到的扰动会改变模型的响应。在视觉上，我们假设人类视觉感知的健壮性的一个重要因素是持续暴露于外围视觉中的低保真度视觉刺激。为了研究这个假设，我们开发了RBlur，一种图像转换方法，通过对图像进行模糊和降低颜色饱和度来模拟外围视觉的保真度损失，方法基于给定的注视点的距离。我们证明，与在原始图像上训练的DNN相比，通过RBlur转换的图像上训练的DNN对对抗攻击和其他非对抗性损坏具有更强的健壮性，在扰动数据上的准确性提高了高达25%。

    Deep neural networks (DNNs) have been shown to be vulnerable to adversarial attacks -- subtle, perceptually indistinguishable perturbations of inputs that change the response of the model. In the context of vision, we hypothesize that an important contributor to the robustness of human visual perception is constant exposure to low-fidelity visual stimuli in our peripheral vision. To investigate this hypothesis, we develop \RBlur, an image transform that simulates the loss in fidelity of peripheral vision by blurring the image and reducing its color saturation based on the distance from a given fixation point. We show that compared to DNNs trained on the original images, DNNs trained on images transformed by \RBlur are substantially more robust to adversarial attacks, as well as other, non-adversarial, corruptions, achieving up to 25\% higher accuracy on perturbed data.
    
[^47]: 设计一个社区之间的沟通桥梁：参与式设计用于问答AI代理

    Designing a Communication Bridge between Communities: Participatory Design for a Question-Answering AI Agent. (arXiv:2308.00813v1 [cs.HC])

    [http://arxiv.org/abs/2308.00813](http://arxiv.org/abs/2308.00813)

    这篇论文介绍了一个旨在充当两个具有不同心智模型和词汇的用户社区之间沟通桥梁的AI系统的设计。使用参与式设计的方法，研究者成功地征求了开发AskJill问答代理的需求，并发现用户认为词汇表辅助是关键功能。

    

    我们如何设计一个旨在充当两个具有不同心智模型和词汇的用户社区之间沟通桥梁的AI系统？ Skillsync是一个交互环境，通过持续的对话将雇主（公司）和培训提供者（大学）引入其中，帮助他们实现建立能够成功满足雇主和员工需求的培训提案的目标。我们采用了一种参与式设计的变体，以征求开发AskJill的需求，AskJill是一个解释Skillsync工作原理的问答代理，因此充当了企业和学院用户之间的沟通桥梁。我们的研究发现，参与式设计在指导需求收集和引发用户问题以开发AskJill方面非常有用。我们的结果还表明，两个Skillsync用户社区认为词汇表辅助是AskJill需要提供的关键功能，他们会受益于这样一个共享词汇。

    How do we design an AI system that is intended to act as a communication bridge between two user communities with different mental models and vocabularies? Skillsync is an interactive environment that engages employers (companies) and training providers (colleges) in a sustained dialogue to help them achieve the goal of building a training proposal that successfully meets the needs of the employers and employees. We used a variation of participatory design to elicit requirements for developing AskJill, a question-answering agent that explains how Skillsync works and thus acts as a communication bridge between company and college users. Our study finds that participatory design was useful in guiding the requirements gathering and eliciting user questions for the development of AskJill. Our results also suggest that the two Skillsync user communities perceived glossary assistance as a key feature that AskJill needs to offer, and they would benefit from such a shared vocabulary.
    
[^48]: 盲人的人工眼睛

    Artificial Eye for the Blind. (arXiv:2308.00801v1 [cs.CV])

    [http://arxiv.org/abs/2308.00801](http://arxiv.org/abs/2308.00801)

    人工眼睛模型通过网络摄像头、超声波传感器和软件模型实现盲人的障碍物检测和光学字符识别。

    

    我们的人工眼睛模型的主要支柱是连接到网络摄像头、超声波近距离传感器、扬声器的树莓派3，我们还运行了所有的软件模型，包括目标检测、光学字符识别、谷歌文本转语音和Mycroft语音辅助模型。当超声波近距离传感器检测到其前方有任何障碍物时，盲人将收到一段关于前方障碍物及其距离的音频提示。此时，网络摄像头将捕捉前方的图像，并在树莓派上运行目标检测模型和光学字符识别模型。捕捉到的图像首先通过Tesseract OCR模块检测图像中的文本，然后通过目标检测模型识别图像中的物体。

    The main backbone of our Artificial Eye model is the Raspberry pi3 which is connected to the webcam ,ultrasonic proximity sensor, speaker and we also run all our software models i.e object detection, Optical Character recognition, google text to speech conversion and the Mycroft voice assistance model. At first the ultrasonic proximity sensor will be measuring the distance between itself and any obstacle in front of it .When the Proximity sensor detects any obstacle in front within its specified range, the blind person will hear an audio prompt about an obstacle in his way at a certain distance. At this time the Webcam will capture an image in front of it and the Object detection model and the Optical Character Recognition model will begin to run on the Raspberry pi. The imat of the blind person. The text and the object detected are conveyed to the blind pege captured is first sent through the Tesseract OCR module to detect any texts in the image and then through the Object detection m
    
[^49]: 一种知识导向的方法，增强 Polkadot 生态系统中的集成和可交流性。

    A Knowledge-Oriented Approach to Enhance Integration and Communicability in the Polkadot Ecosystem. (arXiv:2308.00735v1 [cs.AI])

    [http://arxiv.org/abs/2308.00735](http://arxiv.org/abs/2308.00735)

    本文提出了一种知识导向的方法，通过使用名为POnto的领域本体，提供结构化的生态系统概念和关系表示，以增强Polkadot生态系统的集成和可交流性。该方法有助于更广泛的用户参与生态系统，并促进基于人工智能的应用的发展。

    

    Polkadot 生态系统是一种具有颠覆性和高度复杂的多链架构，对数据分析和可交流性提出了挑战。目前，缺乏标准化和全面的方法来检索和分析跨平行链和应用的数据，使得一般用户和开发者难以一致地访问生态系统数据。本文提出了一个概念框架，包括一个名为 POnto（Polkadot Ontology）的领域本体，以解决这些挑战。POnto 提供了生态系统概念和关系的结构化表示，实现了对平台的形式化理解。提出的知识导向方法增强了集成和可交流性，使更广泛的用户能够参与生态系统，并促进基于人工智能的应用的开发。文章提出了一个案例研究方法来验证所提出的框架，包括来自Polkado的专家反馈和见解。

    The Polkadot ecosystem is a disruptive and highly complex multi-chain architecture that poses challenges in terms of data analysis and communicability. Currently, there is a lack of standardized and holistic approaches to retrieve and analyze data across parachains and applications, making it difficult for general users and developers to access ecosystem data consistently. This paper proposes a conceptual framework that includes a domain ontology called POnto (a Polkadot Ontology) to address these challenges. POnto provides a structured representation of the ecosystem's concepts and relationships, enabling a formal understanding of the platform. The proposed knowledge-oriented approach enhances integration and communicability, enabling a wider range of users to participate in the ecosystem and facilitating the development of AI-based applications. The paper presents a case study methodology to validate the proposed framework, which includes expert feedback and insights from the Polkado
    
[^50]: 基于主动学习的预训练数据去重模型

    A Pre-trained Data Deduplication Model based on Active Learning. (arXiv:2308.00721v1 [cs.LG])

    [http://arxiv.org/abs/2308.00721](http://arxiv.org/abs/2308.00721)

    提出了一种基于主动学习的预训练去重模型，将Transformer和主动学习集成到端到端架构中，首次解决了语义级别的去重问题，同时采用R-Drop方法对每一轮标记数据进行数据增强。通过选择最有价值的数据进行去重模型训练，不仅降低了手动标记的成本，还提高了模型的泛化能力。

    

    在大数据时代，数据质量问题日益突出。其中一个主要挑战是重复数据问题，这可能是由于数据的重复输入或多个数据源的合并导致的。这些"脏数据"问题严重限制了大数据的有效应用。为了解决数据去重的问题，我们提出了一种基于主动学习的预训练去重模型，这是首次利用主动学习解决语义级别的去重问题的工作。该模型构建在一个预训练的Transformer上，并通过细调将其应用于序列分类任务，首次将Transformer和主动学习集成到端到端架构中，以选择最有价值的数据进行去重模型训练，同时首次采用R-Drop方法对每一轮标记数据进行数据增强，既能降低手动标记的成本，也能提高模型的泛化能力。

    In the era of big data, the issue of data quality has become increasingly prominent. One of the main challenges is the problem of duplicate data, which can arise from repeated entry or the merging of multiple data sources. These "dirty data" problems can significantly limit the effective application of big data. To address the issue of data deduplication, we propose a pre-trained deduplication model based on active learning, which is the first work that utilizes active learning to address the problem of deduplication at the semantic level. The model is built on a pre-trained Transformer and fine-tuned to solve the deduplication problem as a sequence to classification task, which firstly integrate the transformer with active learning into an end-to-end architecture to select the most valuable data for deduplication model training, and also firstly employ the R-Drop method to perform data augmentation on each round of labeled data, which can reduce the cost of manual labeling and improve
    
[^51]: 实现聚合的类激活图可用于分析类特征的整体贡献

    Towards the Visualization of Aggregated Class Activation Maps to Analyse the Global Contribution of Class Features. (arXiv:2308.00710v1 [cs.LG])

    [http://arxiv.org/abs/2308.00710](http://arxiv.org/abs/2308.00710)

    本文扩展了类激活图的方法，将多个样本的类激活图聚合起来，以展示语义结构化数据的分类的全局解释。聚合过程使得分析师可以进行复杂的假设和进一步的钻取可视化分析。

    

    深度学习模型在分类任务中取得了显著的性能，但是高复杂度的模型在许多风险敏感的应用中无法使用，除非提供了可理解的解释。可解释的人工智能（xAI）关注于解释类似深度学习的AI系统的决策。我们扩展了最近的类激活图（CAMs）方法，该方法可可视化数据样本中每个特征对分类的贡献重要性。在本文中，我们聚合了来自多个样本的CAMs，以展示语义结构化数据的分类的全局解释。聚合使分析师能够进行复杂的假设，并通过进一步的钻取可视化进行分析。我们的全局CAM的可视化表示以一个方形标记表示每个特征的影响力，方形的颜色表示该特征的分类影响力，填充方形的大小表示该特征的重要性。

    Deep learning (DL) models achieve remarkable performance in classification tasks. However, models with high complexity can not be used in many risk-sensitive applications unless a comprehensible explanation is presented. Explainable artificial intelligence (xAI) focuses on the research to explain the decision-making of AI systems like DL. We extend a recent method of Class Activation Maps (CAMs) which visualizes the importance of each feature of a data sample contributing to the classification. In this paper, we aggregate CAMs from multiple samples to show a global explanation of the classification for semantically structured data. The aggregation allows the analyst to make sophisticated assumptions and analyze them with further drill-down visualizations. Our visual representation for the global CAM illustrates the impact of each feature with a square glyph containing two indicators. The color of the square indicates the classification impact of this feature. The size of the filled squ
    
[^52]: 安全强化学习的近似模型屏蔽

    Approximate Model-Based Shielding for Safe Reinforcement Learning. (arXiv:2308.00707v1 [cs.LG])

    [http://arxiv.org/abs/2308.00707](http://arxiv.org/abs/2308.00707)

    提出了一种近似模型屏蔽算法 (AMBS) 来验证学习的强化学习策略在给定安全约束下的性能，与其他屏蔽方法相比，AMBS不需要先验知识，并在具有状态相关安全标签的 Atari 游戏上展示了优越性能。

    

    强化学习 (RL) 在各个领域解决复杂任务方面展示了巨大的潜力。然而，将 RL 应用于现实世界的安全关键系统并不容易，因为许多算法在样本效率上存在问题，并且最大化标准 RL 目标不能保证最坏情况下的性能。在本文中，我们提出了近似模型屏蔽 (AMBS)，这是一种基于模型的理性前瞻屏蔽算法，用于验证学习的 RL 策略相对于一组给定的安全约束的性能。我们的算法与其他屏蔽方法不同，它不需要对系统的安全相关动态的先验知识。我们为 AMBS 提供了强大的理论基础，并在一组具有状态相关安全标签的 Atari 游戏上展示了优越的性能。

    Reinforcement learning (RL) has shown great potential for solving complex tasks in a variety of domains. However, applying RL to safety-critical systems in the real-world is not easy as many algorithms are sample-inefficient and maximising the standard RL objective comes with no guarantees on worst-case performance. In this paper we propose approximate model-based shielding (AMBS), a principled look-ahead shielding algorithm for verifying the performance of learned RL policies w.r.t. a set of given safety constraints. Our algorithm differs from other shielding approaches in that it does not require prior knowledge of the safety-relevant dynamics of the system. We provide a strong theoretical justification for AMBS and demonstrate superior performance to other safety-aware approaches on a set of Atari games with state-dependent safety-labels.
    
[^53]: 人工智能研究的文献研究：全球概况与印度的出现

    A Bibliographic Study on Artificial Intelligence Research: Global Panorama and Indian Appearance. (arXiv:2308.00705v1 [cs.DL])

    [http://arxiv.org/abs/2308.00705](http://arxiv.org/abs/2308.00705)

    本研究使用文献计量学方法分析了2015-2020年间人工智能研究的文献趋势，发现商业期刊在引用分数和发表数量上表现更好，同时还研究了各国的出版情况和印度在人工智能研究中的重要性。

    

    本研究使用文献计量学的科学映射方法，识别和评估了2015-2020年间人工智能研究的文献趋势。所需数据来自Scopus数据库。通过手动和使用OpenRefine工具进行必要的数据转换，使得收集到的数据可以进行分析。为了确定趋势和进行映射技术，根据其引用分数驱动的排名，选择了人工智能领域的五个开放获取和商业期刊。该研究分析了该期间发表的6880篇文章。趋势包括各国的出版物，年度出版物，人工智能领域的主题词，被引用次数最多的文章，重要作者，主要机构，工业界对人工智能的参与以及印度的出现。结果显示，与开放获取期刊相比，商业期刊在多年的引用分数和发表文章数量上较高。

    The present study identifies and assesses the bibliographic trend in Artificial Intelligence (AI) research for the years 2015-2020 using the science mapping method of bibliometric study. The required data has been collected from the Scopus database. To make the collected data analysis-ready, essential data transformation was performed manually and with the help of a tool viz. OpenRefine. For determining the trend and performing the mapping techniques, top five open access and commercial journals of AI have been chosen based on their citescore driven ranking. The work includes 6880 articles published in the specified period for analysis. The trend is based on Country-wise publications, year-wise publications, topical terms in AI, top-cited articles, prominent authors, major institutions, involvement of industries in AI and Indian appearance. The results show that compared to open access journals; commercial journals have a higher citescore and number of articles published over the years
    
[^54]: SelfCheck: 使用LLMs自检其逐步推理的创新

    SelfCheck: Using LLMs to Zero-Shot Check Their Own Step-by-Step Reasoning. (arXiv:2308.00436v1 [cs.AI])

    [http://arxiv.org/abs/2308.00436](http://arxiv.org/abs/2308.00436)

    本论文研究了使用LLMs自检逐步推理的能力，提出了一种零-shot验证方案，成功识别错误并提高了问答性能。

    

    最近大型语言模型（LLMs）的进展，尤其是链式思维（CoT）的发明，使得解决推理问题成为可能。然而，即使最强大的LLMs仍然难以处理需要非线性思维和多步推理的复杂问题。在这项工作中，我们探讨了LLMs是否具有识别自己错误的能力，而无需依赖外部资源。具体而言，我们研究了它们是否可以用于识别逐步推理中的个别错误。为此，我们提出了一种零-shot验证方案以识别此类错误。然后，我们使用此验证方案来改进问答性能，通过对不同生成的答案进行加权投票。我们在三个数学数据集-GSM8K，MathQA和MATH上测试了该方法，并发现它成功识别错误，并进而提高了最终的预测性能。

    The recent progress in large language models (LLMs), especially the invention of chain-of-thoughts (CoT) prompting, makes it possible to solve reasoning problems. However, even the strongest LLMs are still struggling with more complicated problems that require non-linear thinking and multi-step reasoning. In this work, we explore whether LLMs have the ability to recognize their own errors, without resorting to external resources. In particular, we investigate whether they can be used to identify individual errors within a step-by-step reasoning. To this end, we propose a zero-shot verification scheme to recognize such errors. We then use this verification scheme to improve question-answering performance, by using it to perform weighted voting on different generated answers. We test the method on three math datasets-GSM8K, MathQA, and MATH-and find that it successfully recognizes errors and, in turn, increases final predictive performance.
    
[^55]: MetaGPT: 元编程用于多智能体协作框架

    MetaGPT: Meta Programming for Multi-Agent Collaborative Framework. (arXiv:2308.00352v1 [cs.AI])

    [http://arxiv.org/abs/2308.00352](http://arxiv.org/abs/2308.00352)

    MetaGPT是一个用于多智能体协作的创新框架，将有效的人工工作流引入到大型语言模型驱动的协作中。它采用元编程方法，将标准操作规程编码为提示，促进结构化协调，并要求模块化输出，赋予智能体领域专业知识，以验证输出并减少错误。这种框架利用了流水线工作模式来分配任务。

    

    最近，在多个大型语言模型驱动的智能体协作中，自动任务解决取得了显著进展。然而，现有的工作主要集中在简单任务上，缺乏对复杂任务的探索和研究，主要是由于幻觉问题。这种幻觉在多个智能体相互作用时被无限放大，导致在解决复杂问题时失败。因此，我们引入了MetaGPT，这是一个创新的框架，在LLM驱动的多智能体协作中采用有效的人工工作流作为元编程方法。具体而言，MetaGPT首先将标准操作规程（SOPs）编码为提示，促进结构化协调。然后，它进一步要求模块化输出，赋予智能体领域专业知识，与人类专业人员平行验证输出并减少错误。通过这种方式，MetaGPT利用流水线工作模式来分配任务

    Recently, remarkable progress has been made in automated task-solving through the use of multi-agents driven by large language models (LLMs). However, existing works primarily focuses on simple tasks lacking exploration and investigation in complicated tasks mainly due to the hallucination problem. This kind of hallucination gets amplified infinitely as multiple intelligent agents interact with each other, resulting in failures when tackling complicated problems.Therefore, we introduce MetaGPT, an innovative framework that infuses effective human workflows as a meta programming approach into LLM-driven multi-agent collaboration. In particular, MetaGPT first encodes Standardized Operating Procedures (SOPs) into prompts, fostering structured coordination. And then, it further mandates modular outputs, bestowing agents with domain expertise paralleling human professionals to validate outputs and reduce compounded errors. In this way, MetaGPT leverages the assembly line work model to assig
    
[^56]: 为知识图谱补全构建语义丰富的嵌入模型

    Towards Semantically Enriched Embeddings for Knowledge Graph Completion. (arXiv:2308.00081v1 [cs.AI])

    [http://arxiv.org/abs/2308.00081](http://arxiv.org/abs/2308.00081)

    本论文讨论了知识图谱补全算法以及利用嵌入模型捕捉知识图谱中语义的不同方法，并提出知识图谱和语言模型相互受益的观点。

    

    基于嵌入模型的知识图谱补全在过去几年中越来越受关注。目前的大多数算法将知识图谱视为一个多向标记图，缺乏捕捉底层语义的能力。与此同时，大型语言模型（LLMs）已经捕获了大量信息，这一捕获对人工智能领域产生了革命性影响。知识图谱可以从LLMs中受益，反之亦然。本文讨论了基于不同生成嵌入模型变体的知识图谱补全算法。首先讨论了各种知识图谱补全算法，如转导和归纳链接预测以及实体类型预测算法。然后，介绍了利用知识图谱中的类型信息、LLMs以及捕捉不同描述逻辑公理中的语义的算法。最后，通过对现有算法的关键反思对论文进行总结。

    Embedding based Knowledge Graph (KG) Completion has gained much attention over the past few years. Most of the current algorithms consider a KG as a multidirectional labeled graph and lack the ability to capture the semantics underlying the schematic information. In a separate development, a vast amount of information has been captured within the Large Language Models (LLMs) which has revolutionized the field of Artificial Intelligence. KGs could benefit from these LLMs and vice versa. This vision paper discusses the existing algorithms for KG completion based on the variations for generating KG embeddings. It starts with discussing various KG completion algorithms such as transductive and inductive link prediction and entity type prediction algorithms. It then moves on to the algorithms utilizing type information within the KGs, LLMs, and finally to algorithms capturing the semantics represented in different description logic axioms. We conclude the paper with a critical reflection on
    
[^57]: AsdKB: 一个用于自闭症谱系障碍早期筛选和诊断的中文知识库

    AsdKB: A Chinese Knowledge Base for the Early Screening and Diagnosis of Autism Spectrum Disorder. (arXiv:2307.16773v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2307.16773](http://arxiv.org/abs/2307.16773)

    AsdKB是一个用于自闭症谱系障碍早期筛选和诊断的中文知识库，包含了来自多个来源的疾病和诊断知识，并且可以用于问题回答、辅助诊断和专家推荐。

    

    为了便捷地获取有关自闭症谱系障碍的知识并帮助其早期筛选和诊断，我们创建了AsdKB，一个关于自闭症谱系障碍的中文知识库。该知识库建立在多种来源的基础上，包括1）从SNOMED CT和ICD-10的临床描述中获得的疾病知识，2）从DSM-5和社会组织和医学研究机构推荐的不同筛选工具中获得的诊断知识，以及3）来自网络上专业医生和医院的专业知识。AsdKB包含本体知识和事实知识，并且可以通过 https://w3id.org/asdkb/ 作为链接数据进行访问。AsdKB的潜在应用包括问题回答、辅助诊断和专家推荐，并且我们通过一个原型来进行演示，该原型可以通过此http URL进行访问。

    To easily obtain the knowledge about autism spectrum disorder and help its early screening and diagnosis, we create AsdKB, a Chinese knowledge base on autism spectrum disorder. The knowledge base is built on top of various sources, including 1) the disease knowledge from SNOMED CT and ICD-10 clinical descriptions on mental and behavioural disorders, 2) the diagnostic knowledge from DSM-5 and different screening tools recommended by social organizations and medical institutes, and 3) the expert knowledge on professional physicians and hospitals from the Web. AsdKB contains both ontological and factual knowledge, and is accessible as Linked Data at https://w3id.org/asdkb/. The potential applications of AsdKB are question answering, auxiliary diagnosis, and expert recommendation, and we illustrate them with a prototype which can be accessed at this http URL
    
[^58]: LLMs4OL: 大型语言模型在本体学习中的应用

    LLMs4OL: Large Language Models for Ontology Learning. (arXiv:2307.16648v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2307.16648](http://arxiv.org/abs/2307.16648)

    LLMs4OL方法利用大型语言模型在本体学习中取得显著进展，能够从自然语言文本中自动提取和结构化知识。

    

    我们提出了LLMs4OL方法，利用大型语言模型（LLMs）进行本体学习（OL）。LLMs在自然语言处理方面取得了重大进展，展示了它们在不同知识领域中捕捉复杂语言模式的能力。我们的LLMs4OL范式研究了以下假设：\textit{LLMs能否有效应用它们的语言模式捕捉能力到OL中，这涉及从自然语言文本中自动提取和结构化知识?} 为了测试这个假设，我们使用零-shot提示方法进行了全面评估。我们评估了九个不同的LLM模型族群，针对三个主要的OL任务：术语类型划分、层级发现和非层级关系的提取。此外，评估还涵盖了本体知识的不同类型，包括WordNet中的词汇语义知识、GeoNames中的地理知识和UMLS中的医学知识。

    We propose the LLMs4OL approach, which utilizes Large Language Models (LLMs) for Ontology Learning (OL). LLMs have shown significant advancements in natural language processing, demonstrating their ability to capture complex language patterns in different knowledge domains. Our LLMs4OL paradigm investigates the following hypothesis: \textit{Can LLMs effectively apply their language pattern capturing capability to OL, which involves automatically extracting and structuring knowledge from natural language text?} To test this hypothesis, we conduct a comprehensive evaluation using the zero-shot prompting method. We evaluate nine different LLM model families for three main OL tasks: term typing, taxonomy discovery, and extraction of non-taxonomic relations. Additionally, the evaluations encompass diverse genres of ontological knowledge, including lexicosemantic knowledge in WordNet, geographical knowledge in GeoNames, and medical knowledge in UMLS.
    
[^59]: 基于人类评价反馈的原始技能导向机器人学习

    Primitive Skill-based Robot Learning from Human Evaluative Feedback. (arXiv:2307.15801v1 [cs.RO])

    [http://arxiv.org/abs/2307.15801](http://arxiv.org/abs/2307.15801)

    基于人类评价反馈的原始技能导向机器人学习框架（SEED）结合了从人类反馈中进行强化学习（RLHF）和基于原始技能的强化学习，有效解决了稀疏奖励和长时程任务复杂性问题，并提高了学习效率和安全性。

    

    强化学习算法在处理真实环境中的长时程机器人操作任务时面临着样本效率和安全性问题。为了克服这些挑战，我们提出了一种新的框架，SEED，它结合了两种方法：从人类反馈中进行强化学习（RLHF）和基于原始技能的强化学习。这两种方法在解决稀疏奖励问题和长时程任务中的复杂性方面特别有效。通过结合它们，SEED减少了在真实环境中通过强化学习训练机器人操作所需的人力投入，并提高了安全性。此外，参数化技能提供了对代理的高级意图的清晰视图，允许人类在执行之前评估技能选择。这个特性使得训练过程更安全、更高效。为了评估SEED的性能，我们在五个操作任务上进行了大量实验证明。

    Reinforcement learning (RL) algorithms face significant challenges when dealing with long-horizon robot manipulation tasks in real-world environments due to sample inefficiency and safety issues. To overcome these challenges, we propose a novel framework, SEED, which leverages two approaches: reinforcement learning from human feedback (RLHF) and primitive skill-based reinforcement learning. Both approaches are particularly effective in addressing sparse reward issues and the complexities involved in long-horizon tasks. By combining them, SEED reduces the human effort required in RLHF and increases safety in training robot manipulation with RL in real-world settings. Additionally, parameterized skills provide a clear view of the agent's high-level intentions, allowing humans to evaluate skill choices before they are executed. This feature makes the training process even safer and more efficient. To evaluate the performance of SEED, we conducted extensive experiments on five manipulation
    
[^60]: 机器人触觉的注意力: 用于强健的模拟-真实触觉控制的触觉显著性预测

    Attention of Robot Touch: Tactile Saliency Prediction for Robust Sim-to-Real Tactile Control. (arXiv:2307.14510v1 [cs.RO])

    [http://arxiv.org/abs/2307.14510](http://arxiv.org/abs/2307.14510)

    这篇论文提出了一种新的概念——机器人触觉的“触觉显著性”，通过借鉴人类触觉注意机制和计算机视觉中的视觉显著性预测问题，提高了非结构化环境下触觉机器人控制的鲁棒性。

    

    高分辨率的触觉传感可以提供关于接触丰富的机器人任务中局部接触的准确信息。然而，在非结构化环境中部署这样的任务仍然未被充分研究。为了提高在非结构化环境中触觉机器人控制的鲁棒性，我们提出并研究了一个新的概念：机器人触觉的“触觉显著性”，灵感来源于神经科学中的人类触觉注意机制和计算机视觉中视觉显著性预测问题。类似于视觉显著性，这个概念涉及到通过触觉传感器捕捉到的触觉图像中识别关键信息。虽然视觉显著性数据集通常由人类进行注释，但由于触觉图像的反直觉模式，手动标记触觉图像具有挑战性。为了解决这个挑战，我们提出了一个由三个相互关联的网络组成的新方法: 1) 接触深度网络（ConDepNet），它生成一个接触深度地图以定位真实触觉中的变形。

    High-resolution tactile sensing can provide accurate information about local contact in contact-rich robotic tasks. However, the deployment of such tasks in unstructured environments remains under-investigated. To improve the robustness of tactile robot control in unstructured environments, we propose and study a new concept: \textit{tactile saliency} for robot touch, inspired by the human touch attention mechanism from neuroscience and the visual saliency prediction problem from computer vision. In analogy to visual saliency, this concept involves identifying key information in tactile images captured by a tactile sensor. While visual saliency datasets are commonly annotated by humans, manually labelling tactile images is challenging due to their counterintuitive patterns. To address this challenge, we propose a novel approach comprised of three interrelated networks: 1) a Contact Depth Network (ConDepNet), which generates a contact depth map to localize deformation in a real tactile 
    
[^61]: 探索大规模语言模型（LLMs）在图学习中的潜力

    Exploring the Potential of Large Language Models (LLMs) in Learning on Graphs. (arXiv:2307.03393v1 [cs.LG])

    [http://arxiv.org/abs/2307.03393](http://arxiv.org/abs/2307.03393)

    本文探索了大规模语言模型（LLMs）在图学习中的潜力，并尝试了两种不同的流程：将LLMs作为增强器通过海量知识来增强节点的文本属性，并使用图神经网络（GNNs）生成预测，以及直接使用LLMs作为独立的预测器。

    

    图学习因其广泛的现实世界应用而引起了极大的关注。以文本节点属性为主的图学习最流行的流程主要依赖于图神经网络（GNN），并利用浅层文本嵌入作为初始节点表示，但存在通用知识和深刻语义理解方面的限制。近年来，大规模语言模型（LLMs）被证明具有广泛的常识和强大的语义理解能力，已经颠覆了现有的处理文本数据的工作流程。在本文中，我们旨在探索LLMs在图机器学习中的潜力，特别是节点分类任务，并研究两种可能的流程：LLMs作为增强器和LLMs作为预测器。前者利用LLMs通过其海量知识增强节点的文本属性，然后通过GNNs生成预测。后者试图直接使用LLMs作为独立的预测器。

    Learning on Graphs has attracted immense attention due to its wide real-world applications. The most popular pipeline for learning on graphs with textual node attributes primarily relies on Graph Neural Networks (GNNs), and utilizes shallow text embedding as initial node representations, which has limitations in general knowledge and profound semantic understanding. In recent years, Large Language Models (LLMs) have been proven to possess extensive common knowledge and powerful semantic comprehension abilities that have revolutionized existing workflows to handle text data. In this paper, we aim to explore the potential of LLMs in graph machine learning, especially the node classification task, and investigate two possible pipelines: LLMs-as-Enhancers and LLMs-as-Predictors. The former leverages LLMs to enhance nodes' text attributes with their massive knowledge and then generate predictions through GNNs. The latter attempts to directly employ LLMs as standalone predictors. We conduct 
    
[^62]: 对大型语言模型评估的调查

    A Survey on Evaluation of Large Language Models. (arXiv:2307.03109v1 [cs.CL])

    [http://arxiv.org/abs/2307.03109](http://arxiv.org/abs/2307.03109)

    本文综述了大型语言模型（LLMs）的评估方法，关注三个关键维度：评估什么、在哪里评估以及如何评估。评估任务包括自然语言处理、推理、医学应用、伦理学、教育、自然和社会科学、代理应用等多个领域。本文为社会层面对LLMs潜在风险的理解提供了重要参考。

    

    大型语言模型（LLMs）由于在各种应用中表现出的前所未有的性能而在学术界和工业界越来越受欢迎。随着LLMs在研究和日常使用中继续发挥着重要作用，它们的评估变得越来越关键，不仅在任务水平上，而且在社会层面上，以更好地了解它们的潜在风险。在过去的几年里，已经做出了相当大的努力来从不同的角度来研究LLMs。本文综述了LLMs的这些评估方法，重点关注三个关键维度：评估什么、在哪里评估以及如何评估。首先，我们从评估任务的角度提供了一个概述，涵盖了一般的自然语言处理任务、推理、医学应用、伦理学、教育、自然科学和社会科学、代理应用和其他领域。其次，我们通过深入探讨评估方法和基准答案来回答“在哪里”和“如何”这两个问题。

    Large language models (LLMs) are gaining increasing popularity in both academia and industry, owing to their unprecedented performance in various applications. As LLMs continue to play a vital role in both research and daily use, their evaluation becomes increasingly critical, not only at the task level, but also at the society level for better understanding of their potential risks. Over the past years, significant efforts have been made to examine LLMs from various perspectives. This paper presents a comprehensive review of these evaluation methods for LLMs, focusing on three key dimensions: what to evaluate, where to evaluate, and how to evaluate. Firstly, we provide an overview from the perspective of evaluation tasks, encompassing general natural language processing tasks, reasoning, medical usage, ethics, educations, natural and social sciences, agent applications, and other areas. Secondly, we answer the `where' and `how' questions by diving into the evaluation methods and bench
    
[^63]: 使用语法演化自动设计语义相似性集合

    Automatic Design of Semantic Similarity Ensembles Using Grammatical Evolution. (arXiv:2307.00925v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.00925](http://arxiv.org/abs/2307.00925)

    本研究首次使用语法演化自动设计语义相似性集合，通过自动选择和聚合候选度量来优化集合与人类判断的相关性，提高相似度评估准确性，并证明了使用集合对语义相似性任务的益处。

    

    语义相似性度量在自然语言处理中被广泛应用于多种与计算机相关的任务。然而，没有单一的语义相似性度量适用于所有任务，研究人员经常使用集合策略来确保性能。本研究提出了一种自动设计语义相似性集合的方法。事实上，我们提出的方法首次使用语法演化来自动选择和聚合一组候选度量，以创建一个最大化与人类判断相关性的集合。该方法在多个基准数据集上进行了评估，并与最先进的集合进行了比较，结果显示它可以显著提高相似度评估的准确性，并在某些情况下优于现有方法。因此，我们的研究既展示了使用语法演化来自动比较文本的潜力，也证明了使用集合对语义相似性任务的益处。

    Semantic similarity measures are widely used in natural language processing to catalyze various computer-related tasks. However, no single semantic similarity measure is the most appropriate for all tasks, and researchers often use ensemble strategies to ensure performance. This research work proposes a method for automatically designing semantic similarity ensembles. In fact, our proposed method uses grammatical evolution, for the first time, to automatically select and aggregate measures from a pool of candidates to create an ensemble that maximizes correlation to human judgment. The method is evaluated on several benchmark datasets and compared to state-of-the-art ensembles, showing that it can significantly improve similarity assessment accuracy and outperform existing methods in some cases. As a result, our research demonstrates the potential of using grammatical evolution to automatically compare text and prove the benefits of using ensembles for semantic similarity tasks. The so
    
[^64]: CamemBERT-bio：一种更健康的法语语言模型

    CamemBERT-bio: a Tasty French Language Model Better for your Health. (arXiv:2306.15550v1 [cs.CL])

    [http://arxiv.org/abs/2306.15550](http://arxiv.org/abs/2306.15550)

    本研究介绍了CamemBERT-bio，它是一种针对法语生物医学领域专门设计的语言模型，相对于通用模型在命名实体识别任务上平均提高了2.54个百分点。

    

    通过临床数据仓库，医院中的临床数据变得越来越容易用于研究，然而这些文件都是非结构化的。因此，需要从医疗报告中提取信息以进行临床研究。使用CamemBERT等BERT-like模型的迁移学习已经取得了重大进展，特别是命名实体识别方面。然而，这些模型是为通用语言训练的，在生物医学数据上效果较弱。因此，我们提出了一种新的法语公共生物医学数据集，对CamemBERT进行了继续预训练。因此，我们介绍了CamemBERT-bio的第一个版本，它是一种为法语生物医学领域专门设计的公共模型，在不同的生物医学命名实体识别任务上平均F1分数提高了2.54个百分点。

    Clinical data in hospitals are increasingly accessible for research through clinical data warehouses, however these documents are unstructured. It is therefore necessary to extract information from medical reports to conduct clinical studies. Transfer learning with BERT-like models such as CamemBERT has allowed major advances, especially for named entity recognition. However, these models are trained for plain language and are less efficient on biomedical data. This is why we propose a new French public biomedical dataset on which we have continued the pre-training of CamemBERT. Thus, we introduce a first version of CamemBERT-bio, a specialized public model for the French biomedical domain that shows 2.54 points of F1 score improvement on average on different biomedical named entity recognition tasks.
    
[^65]: TeleViT: 电联驱动的Transformer改进了季节性野火预测

    TeleViT: Teleconnection-driven Transformers Improve Subseasonal to Seasonal Wildfire Forecasting. (arXiv:2306.10940v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2306.10940](http://arxiv.org/abs/2306.10940)

    TeleViT是一种电联驱动的视觉Transformer模型，可以准确预测季节性野火的全球烧毁面积模式，提前四个月进行预测。

    

    由于气候变化的加剧，野火问题日益恶化，需要采取先进的主动措施进行有效的缓解。提前几周甚至几个月预测野火对于计划森林燃料管理、资源采购和配置至关重要。为了在全球范围内实现准确的长期预测，必须采用能够考虑地球系统固有的时空相互作用，如记忆效应和电联的模型。我们提出了一种电联驱动的视觉Transformer（TeleViT），能够将地球视为一个相互连接的系统，将精细的局部尺度输入与全球尺度输入（如气候指数和粗粒度的全球变量）集成在一起。通过全面的实验证明，TeleViT在准确预测各种预测窗口下的全球烧毁面积模式方面具有优势，可以提前四个月进行预测。

    Wildfires are increasingly exacerbated as a result of climate change, necessitating advanced proactive measures for effective mitigation. It is important to forecast wildfires weeks and months in advance to plan forest fuel management, resource procurement and allocation. To achieve such accurate long-term forecasts at a global scale, it is crucial to employ models that account for the Earth system's inherent spatio-temporal interactions, such as memory effects and teleconnections. We propose a teleconnection-driven vision transformer (TeleViT), capable of treating the Earth as one interconnected system, integrating fine-grained local-scale inputs with global-scale inputs, such as climate indices and coarse-grained global variables. Through comprehensive experimentation, we demonstrate the superiority of TeleViT in accurately predicting global burned area patterns for various forecasting windows, up to four months in advance. The gain is especially pronounced in larger forecasting wind
    
[^66]: 昂贵嵌套灰盒函数的贝叶斯优化

    Bayesian Optimization of Expensive Nested Grey-Box Functions. (arXiv:2306.05150v1 [cs.LG])

    [http://arxiv.org/abs/2306.05150](http://arxiv.org/abs/2306.05150)

    本文提出基于乐观主义的算法来解决嵌套黑白箱函数优化问题，相比传统黑箱优化方法显著提高全局最优解速度。

    

    我们考虑优化灰盒目标函数的问题，即由黑箱和白箱函数组成的嵌套函数。给出了这种灰盒问题的一般形式，涵盖了现有的灰盒优化公式作为特殊情况。我们设计了一种基于乐观主义的算法来解决这个问题。在一定的正则性假设下，我们的算法实现了与标准黑箱贝叶斯优化算法相似的后悔边界，但乘以依赖于所考虑函数的Lipschitz常数的常数乘项。我们进一步将我们的方法扩展到约束情况，并讨论了几个特殊情况。对于常用的核函数，后悔边界使我们能够推导到最优解的收敛速度。实验结果表明，与标准黑箱优化相比，我们的灰盒优化方法在实践中显着提高了寻找全局最优解的速度。

    We consider the problem of optimizing a grey-box objective function, i.e., nested function composed of both black-box and white-box functions. A general formulation for such grey-box problems is given, which covers the existing grey-box optimization formulations as special cases. We then design an optimism-driven algorithm to solve it. Under certain regularity assumptions, our algorithm achieves similar regret bound as that for the standard black-box Bayesian optimization algorithm, up to a constant multiplicative term depending on the Lipschitz constants of the functions considered. We further extend our method to the constrained case and discuss several special cases. For the commonly used kernel functions, the regret bounds allow us to derive a convergence rate to the optimal solution. Experimental results show that our grey-box optimization method empirically improves the speed of finding the global optimal solution significantly, as compared to the standard black-box optimization 
    
[^67]: EINCASM: 软泥菌神经元元胞自动机中的新兴智能

    EINCASM: Emergent Intelligence in Neural Cellular Automaton Slime Molds. (arXiv:2305.13425v1 [cs.NE])

    [http://arxiv.org/abs/2305.13425](http://arxiv.org/abs/2305.13425)

    本论文介绍了EINCASM，一个研究软泥菌类有机体智能的原型系统。该系统利用神经元元胞自动机结合虚拟流体运输营养物质和化学信号，通过测试智能的方式研究有机体的智能行为，在未来可以进一步深入研究这些分布式动态系统中的智能行为。

    

    本文介绍了EINCASM，一个采用新颖框架研究类似于软泥菌的有机体中新兴智能的原型系统。EINCASM通过NEAT进化神经元元胞自动机，以最大化受营养和能量成本所限制的细胞生长。这些有机体利用虚拟流体来运输营养物质和化学信号，以协调在复杂、变化的环境中的生长和适应。我们的框架为研究谜题、物理、通信、竞争和动态开放式环境如何促进智能行为的出现奠定了基础。我们提出了这种有机体智能性的初步测试，并提出了未来更强大的系统使用EINCASM以更好地理解分布式动态系统中的智能。

    This paper presents EINCASM, a prototype system employing a novel framework for studying emergent intelligence in organisms resembling slime molds. EINCASM evolves neural cellular automata with NEAT to maximize cell growth constrained by nutrient and energy costs. These organisms capitalize physically simulated fluid to transport nutrients and chemical-like signals to orchestrate growth and adaptation to complex, changing environments. Our framework builds the foundation for studying how the presence of puzzles, physics, communication, competition and dynamic open-ended environments contribute to the emergence of intelligent behavior. We propose preliminary tests for intelligence in such organisms and suggest future work for more powerful systems employing EINCASM to better understand intelligence in distributed dynamical systems.
    
[^68]: ChatGPT与劳动力市场：揭示AI讨论对学生收入预期影响

    ChatGPT and the Labor Market: Unraveling the Effect of AI Discussions on Students' Earnings Expectations. (arXiv:2305.11900v1 [econ.GN])

    [http://arxiv.org/abs/2305.11900](http://arxiv.org/abs/2305.11900)

    本文研究了 ChatGPT人工智能（AI）讨论对美国学生预期劳动市场结果的因果影响，结果发现学生信心会降低，对未来的收入前景保持悲观态度，这种影响广泛存在于不同学生群体中。这个研究给教育工作者、管理者和政策制定者提供了一个机会，以更好地了解学生的担忧并改进教育课程，使学生更好地准备未来，这个未来必然会被AI改变。

    

    本文研究了负面和正面 ChatGPT人工智能（AI）讨论对美国学生预期劳动市场结果的因果影响。我们的研究发现，在接触AI讨论后，学生信心会降低，特别是在阅读负面情绪的讨论摘录时，这种影响更加明显。与STEM专业不同，非STEM领域的学生表现出不对称和悲观的信仰变化，表明他们可能感受到新兴AI技术的影响更强。对于未来收入的悲观信仰更新也普遍存在于各个性别和GPA水平之间，这表明所有学生群体都存在广泛的AI担忧。教育工作者、管理者和政策制定者可以定期与学生互动以解决他们的担忧，并改进教育课程，使他们更好地准备未来，这个未来必然会被AI改变。

    This paper investigates the causal impact of negatively and positively framed ChatGPT Artificial Intelligence (AI) discussions on US students' anticipated labor market outcomes. Our findings reveal students reduce their confidence regarding their future earnings prospects after exposure to AI debates, and this effect is more pronounced after reading discussion excerpts with a negative tone. Unlike STEM majors, students in Non-STEM fields show asymmetric and pessimistic belief changes, suggesting that they might feel more vulnerable to emerging AI technologies. Pessimistic belief updates regarding future earnings are also prevalent across gender and GPA levels, indicating widespread AI concerns among all student subgroups. Educators, administrators, and policymakers may regularly engage with students to address their concerns and enhance educational curricula to better prepare them for a future that will be inevitably shaped by AI.
    
[^69]: SpikeCP: 通过极限预测实现延迟自适应可靠脉冲神经网络

    SpikeCP: Delay-Adaptive Reliable Spiking Neural Networks via Conformal Prediction. (arXiv:2305.11322v1 [cs.NE])

    [http://arxiv.org/abs/2305.11322](http://arxiv.org/abs/2305.11322)

    这篇论文提出了一种新的脉冲神经网络模型，能够通过极限预测实现自适应的推断延迟，从而节约能源与提高可靠性。

    

    脉冲神经网络（SNN）通过内部事件驱动的神经动态处理时间序列数据，其能量消耗取决于输入演示期间神经元之间交换的脉冲数量。在典型的SNN分类器实现中，决策是在整个输入序列被处理后产生的，导致延迟和能量消耗水平在输入之间是相对均匀的。最近引入的延迟自适应SNN可根据每个示例的难度来定制推断延迟 - 以及随之而来的能耗 - 通过在SNN模型足够“自信”时产生早期决策来实现。

    Spiking neural networks (SNNs) process time-series data via internal event-driven neural dynamics whose energy consumption depends on the number of spikes exchanged between neurons over the course of the input presentation. In typical implementations of an SNN classifier, decisions are produced after the entire input sequence has been processed, resulting in latency and energy consumption levels that are fairly uniform across inputs. Recently introduced delay-adaptive SNNs tailor the inference latency -- and, with it, the energy consumption -- to the difficulty of each example, by producing an early decision when the SNN model is sufficiently ``confident''. In this paper, we start by observing that, as an SNN processes input samples, its classification decisions tend to be first under-confident and then over-confident with respect to the decision's ground-truth, unknown, test accuracy. This makes it difficult to determine a stopping time that ensures a desired level of accuracy. To add
    
[^70]: 人还是机器：基于图灵测试的日常反思

    Human or Machine: Reflections on Turing-Inspired Testing for the Everyday. (arXiv:2305.04312v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2305.04312](http://arxiv.org/abs/2305.04312)

    本文基于图灵测试，回避了机器是否智能的问题，探讨在日常生活中如何确定一个交互对象是人还是机器的挑战，并思考了其应用和重要性。

    

    在他的开创性论文《计算机器械与智能》中，艾伦·图灵引入了“模仿游戏”，探讨了机器智能的概念。图灵测试自那时以来一直是广泛讨论、完善和扩展的主题。本文回避了关于某个特定机器是否能被标记为智能或能否在给定环境中匹配人类能力的问题。与此相反，但受图灵启发，我们关注在日常生活中确定是否正在与一个人或一个机器进行交互这个看似简单的挑战。我们对这个人还是机器问题及其可靠答案的应用感到感兴趣，并希望反思其重要性。虽然图灵的原始测试被广泛认为是一种思维实验，但本文讨论的人还是机器问题具有明显的实际意义。虽然人类是否能够创造出能够胜任所有的人类工作的机器也未可知。

    In his seminal paper "Computing Machinery and Intelligence", Alan Turing introduced the "imitation game" as part of exploring the concept of machine intelligence. The Turing Test has since been the subject of much analysis, debate, refinement and extension. Here we sidestep the question of whether a particular machine can be labeled intelligent, or can be said to match human capabilities in a given context. Instead, but inspired by Turing, we draw attention to the seemingly simpler challenge of determining whether one is interacting with a human or with a machine, in the context of everyday life. We are interested in reflecting upon the importance of this Human-or-Machine question and the use one may make of a reliable answer thereto. Whereas Turing's original test is widely considered to be more of a thought experiment, the Human-or-Machine question as discussed here has obvious practical significance. And while the jury is still not in regarding the possibility of machines that can m
    
[^71]: ReLBOT：一种转移学习方法以最小化智能建筑中强化学习风险

    ReLBOT: A Transfer Learning Approach to Minimize Reinforcement Learning Risks in Smart Buildings. (arXiv:2305.00365v1 [cs.LG])

    [http://arxiv.org/abs/2305.00365](http://arxiv.org/abs/2305.00365)

    ReLBOT使用转移学习和深度RL技术来从现有的智能建筑中传递优化参数到新的建筑中，以减少强化学习代理引起的初始不适，有效降低了风险，并且实现了热身期时长6.2倍的提高和预测方差的132倍提高。

    

    智能建筑旨在通过应用人工智能算法来优化能源消耗。当智能建筑投入使用时，没有历史数据可用于训练这些算法。在线强化学习（RL）算法显示出重要的前景，但它们的部署存在重大风险，因为当RL代理最初探索其行动空间时，它可能会给建筑居民带来重大不适。在本文中，我们提出了一种名为ReLBOT的新技术，它使用转移学习结合深度RL，从现有的优化智能建筑中传递知识到新投入使用的建筑中，以减少强化学习代理的热身期对建筑物的不利影响。我们证明取得了可观的成果，热身期的持续时间可提高6.2倍，并且预测方差可提高132倍。

    Smart buildings aim to optimize energy consumption by applying artificial intelligent algorithms. When a smart building is commissioned there is no historical data that could be used to train these algorithms. On-line Reinforcement Learning (RL) algorithms have shown significant promise, but their deployment carries a significant risk, because as the RL agent initially explores its action space it could cause significant discomfort to the building residents. In this paper we present ReLBOT, a new technique that uses transfer learning in conjunction with deep RL to transfer knowledge from an existing, optimized smart building, to the newly commissioning building, to reduce the adverse impact of the reinforcement learning agent's warm-up period. We demonstrate improvements of up to 6.2 times in the duration, and up to 132 times in prediction variance for the reinforcement learning agent's warm-up period.
    
[^72]: Transformer和Snowball图卷积学习用于生物医学图分类

    Transformer and Snowball Graph Convolution Learning for Biomedical Graph Classification. (arXiv:2303.16132v1 [cs.LG])

    [http://arxiv.org/abs/2303.16132](http://arxiv.org/abs/2303.16132)

    本文介绍了一种新型Transformer和Snowball编码网络（TSEN），它将Transformer架构和图雪球连接引入GNNs。TSEN通过雪球编码层将图雪球连接与图Transformer结合起来，增强了捕捉多尺度信息和全局模式以学习整个图特征的能力。

    

    图或网络已被广泛用于描述和建模生物医学中的复杂系统。深度学习方法，尤其是图神经网络（GNNs），已被开发用于学习和预测这种结构化数据。在本文中，我们提出了一种用于生物医学图分类的新型Transformer和Snowball编码网络（TSEN），它将Transformer架构和图雪球连接引入GNNs，以学习整个图的表示。

    Graph or network has been widely used for describing and modeling complex systems in biomedicine. Deep learning methods, especially graph neural networks (GNNs), have been developed to learn and predict with such structured data. In this paper, we proposed a novel transformer and snowball encoding networks (TSEN) for biomedical graph classification, which introduced transformer architecture with graph snowball connection into GNNs for learning whole-graph representation. TSEN combined graph snowball connection with graph transformer by snowball encoding layers, which enhanced the power to capture multi-scale information and global patterns to learn the whole-graph features. On the other hand, TSEN also used snowball graph convolution as position embedding in transformer structure, which was a simple yet effective method for capturing local patterns naturally. Results of experiments using four graph classification datasets demonstrated that TSEN outperformed the state-of-the-art typical
    
[^73]: 数据关联感知的POMDP规划与假设剪枝性能保证

    Data Association Aware POMDP Planning with Hypothesis Pruning Performance Guarantees. (arXiv:2303.02139v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2303.02139](http://arxiv.org/abs/2303.02139)

    提出了一种用于处理具有不确定数据关联的POMDP规划的剪枝算法，通过导出完整假设集与减枝假设子集之间的价值函数边界，建立了使用减枝假设子集造成的最大损失的紧密上界，实验证明此方法在具有挑战性的自主驾驶场景中能够显著节省计算时间并保持合理的性能保证。

    

    在现实世界中运作的自主代理通常要处理部分可观测性，而这通常被建模为部分可观测马尔可夫决策过程（POMDP）。然而，传统的 POMDP 模型依赖于完全知识观测源的假设，即完全可观测数据关联。为了解决这个限制，我们提出了一种规划算法，它维护多个数据关联假设，表示为信念混合，其中每个组件对应于不同的数据关联假设。然而，这种方法可能导致假设数量呈指数增长，从而导致显著的计算开销。为了克服这一挑战，我们引入了一种基于剪枝的方法来处理具有不确定数据关联的规划。我们的主要贡献在于基于完整假设集与基于假设剪枝子集的价值函数之间导出界限，从而使我们能够建立使用修剪的假设子集所造成的最大损失的紧密上界。我们的方法在具有挑战性的自主驾驶场景中进行评估，并展示了显著的计算节省，同时保持合理的性能保证。

    Autonomous agents that operate in the real world must often deal with partial observability, which is commonly modeled as partially observable Markov decision processes (POMDPs). However, traditional POMDP models rely on the assumption of complete knowledge of the observation source, known as fully observable data association. To address this limitation, we propose a planning algorithm that maintains multiple data association hypotheses, represented as a belief mixture, where each component corresponds to a different data association hypothesis. However, this method can lead to an exponential growth in the number of hypotheses, resulting in significant computational overhead. To overcome this challenge, we introduce a pruning-based approach for planning with ambiguous data associations. Our key contribution is to derive bounds between the value function based on the complete set of hypotheses and the value function based on a pruned-subset of the hypotheses, enabling us to establish a 
    
[^74]: 进化增强策略优化用于自监督学习

    Evolutionary Augmentation Policy Optimization for Self-supervised Learning. (arXiv:2303.01584v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2303.01584](http://arxiv.org/abs/2303.01584)

    本文研究了数据增强操作对自监督学习算法性能的影响，提出了一种进化搜索方法来优化数据增强策略，并通过实验比较了几种现有自监督学习算法的性能。

    

    自监督学习是一种无需手动标记数据的深度神经网络预训练的机器学习算法。该学习技术的核心思想是通过辅助阶段（也称为预训练任务），通过数据增强自动生成标记数据，并用于预训练深度神经网络。然而，文献中对于每个预训练任务的影响还未得到充分研究和比较。本文研究了数据增强操作对约束条件下自监督学习算法性能的贡献。我们提出了一种进化搜索方法，用于优化预训练任务中的数据增强流程，并测量了几种先进的自监督学习算法中数据增强操作的影响。通过在染色体中编码不同组合的增强操作，我们通过进化优化机制寻求最优的增强策略。此外，我们还引入了用于分析和解释数据增强策略在模型性能上的影响的方法。

    Self-supervised Learning (SSL) is a machine learning algorithm for pretraining Deep Neural Networks (DNNs) without requiring manually labeled data. The central idea of this learning technique is based on an auxiliary stage aka pretext task in which labeled data are created automatically through data augmentation and exploited for pretraining the DNN. However, the effect of each pretext task is not well studied or compared in the literature. In this paper, we study the contribution of augmentation operators on the performance of self supervised learning algorithms in a constrained settings. We propose an evolutionary search method for optimization of data augmentation pipeline in pretext tasks and measure the impact of augmentation operators in several SOTA SSL algorithms. By encoding different combination of augmentation operators in chromosomes we seek the optimal augmentation policies through an evolutionary optimization mechanism. We further introduce methods for analyzing and expla
    
[^75]: 图形注意力多智能体航空机队自治技术

    Graph Attention Multi-Agent Fleet Autonomy for Advanced Air Mobility. (arXiv:2302.07337v3 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2302.07337](http://arxiv.org/abs/2302.07337)

    这项研究介绍了图形注意力多智能体航空机队自治技术，通过使用新型的神经网络随机策略，考虑代理的异质性和自私性，实现了对机动网络中复杂相互作用和观察不确定性的建模。通过深度多智能体强化学习，实现了代理的分散决策。

    

    自主机动性正成为一种新的颠覆性城市交通模式，用于货物和乘客的移动。然而，设计可扩展的自主机动技术来适应快速增长的机动系统是具有挑战性的，主要是因为机动车队的异质性增加、时间变化的需求模式、服务区域的扩展和通信限制的增加。我们引入了部分可观察的先进航空机动协调游戏的概念，通过考虑互动代理的异质性和商业机动车队固有的自私性来协调一支空中飞行器机队。为了对机动网络中的代理之间的复杂相互作用和观察不确定性进行建模，我们提出了一种新颖的异质图形注意力编码器-解码器（HetGAT Enc-Dec）神经网络的随机策略。我们通过利用深度多智能体强化学习来训练该策略，实现了代理的分散决策。

    Autonomous mobility is emerging as a new disruptive mode of urban transportation for moving cargo and passengers. However, designing scalable autonomous fleet coordination schemes to accommodate fast-growing mobility systems is challenging primarily due to the increasing heterogeneity of the fleets, time-varying demand patterns, service area expansions, and communication limitations. We introduce the concept of partially observable advanced air mobility games to coordinate a fleet of aerial vehicles by accounting for the heterogeneity of the interacting agents and the self-interested nature inherent to commercial mobility fleets. To model the complex interactions among the agents and the observation uncertainty in the mobility networks, we propose a novel heterogeneous graph attention encoder-decoder (HetGAT Enc-Dec) neural network-based stochastic policy. We train the policy by leveraging deep multi-agent reinforcement learning, allowing decentralized decision-making for the agents us
    
[^76]: 在大型语言模型中进行快速和慢速思考

    Thinking Fast and Slow in Large Language Models. (arXiv:2212.05206v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.05206](http://arxiv.org/abs/2212.05206)

    本研究发现，大型语言模型（LLMs）如GPT-3在行为上与人类直觉相似，但可能带有认知错误。然而，具有更高认知能力的LLMs，如ChatGPT和GPT-4，学会了避免这些错误，表现出超理性的方式。通过在心理学方法的帮助下研究LLMs，我们可以揭示出其它未知的新特征。

    

    大型语言模型（LLMs）目前处于将AI系统与人类交流和日常生活结合的前沿。因此，评估它们新兴的能力非常重要。在这项研究中，我们展示了像GPT-3这样的LLMs表现出与人类直觉惊人相似的行为，以及由此带来的认知错误。然而，具有更高认知能力的LLMs，特别是ChatGPT和GPT-4，学会了避免陷入这些错误，表现出超理性的方式。在我们的实验中，我们使用认知反思测试（CRT）以及最初设计用于研究人类直觉决策的语义错觉来探索LLMs。我们的研究表明，利用心理学方法研究LLMs有助于揭示其他未知的新特征。

    Large language models (LLMs) are currently at the forefront of intertwining AI systems with human communication and everyday life. Therefore, it is of great importance to evaluate their emerging abilities. In this study, we show that LLMs like GPT-3 exhibit behavior that strikingly resembles human-like intuition - and the cognitive errors that come with it. However, LLMs with higher cognitive capabilities, in particular ChatGPT and GPT-4, learned to avoid succumbing to these errors and perform in a hyperrational manner. For our experiments, we probe LLMs with the Cognitive Reflection Test (CRT) as well as semantic illusions that were originally designed to investigate intuitive decision-making in humans. Our study demonstrates that investigating LLMs with methods from psychology has the potential to reveal otherwise unknown emergent traits.
    
[^77]: 国际空间站自动紧急无尘解决方案: 带有Bi-GRU的(AED-ISS)

    Automatic Emergency Dust-Free solution on-board International Space Station with Bi-GRU (AED-ISS). (arXiv:2210.08549v2 [stat.AP] UPDATED)

    [http://arxiv.org/abs/2210.08549](http://arxiv.org/abs/2210.08549)

    该论文旨在解决国际空间站上颗粒物对仪器的危害问题，通过Bi-GRU算法构建早期预警系统，预测颗粒物水平，并为宇航员提供充足的反应时间。这项研究还有潜力发展为与火灾相关的遥感烟雾报警装置。

    

    随着对PM2.5或PM0.3问题的关注不断增加，颗粒物不仅对环境和人类构成潜在威胁，而且对国际空间站上的仪器也会产生不利影响。本研究团队旨在将各种颗粒物浓度与磁场、湿度、加速度、温度、压力和CO2浓度关联起来。我们的目标是建立一个早期预警系统(EWS)，能够预测颗粒物水平，并为宇航员提供充足的反应时间，以保护他们在某些实验中的仪器，或者提高测量的准确性；此外，所构建的模型还可以进一步发展为与火灾相关的遥感烟雾报警装置的原型。本文中，我们将实现Bi-GRU(双向门控循环单元)算法，收集过去90分钟的数据，并预测超过2.5微米的颗粒物水平。

    With a rising attention for the issue of PM2.5 or PM0.3, particulate matters have become not only a potential threat to both the environment and human, but also a harming existence to instruments onboard International Space Station (ISS). Our team is aiming to relate various concentration of particulate matters to magnetic fields, humidity, acceleration, temperature, pressure and CO2 concentration. Our goal is to establish an early warning system (EWS), which is able to forecast the levels of particulate matters and provides ample reaction time for astronauts to protect their instruments in some experiments or increase the accuracy of the measurements; In addition, the constructed model can be further developed into a prototype of a remote-sensing smoke alarm for applications related to fires. In this article, we will implement the Bi-GRU (Bidirectional Gated Recurrent Unit) algorithms that collect data for past 90 minutes and predict the levels of particulates which over 2.5 micromete
    
[^78]: 学习高效计划稳健的摩擦多物体抓取

    Learning to Efficiently Plan Robust Frictional Multi-Object Grasps. (arXiv:2210.07420v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2210.07420](http://arxiv.org/abs/2210.07420)

    本文介绍了一种使用神经网络进行摩擦多物体抓取的高效计划方法，相比于以往的工作，其成功率提高了13.7％，每小时的拾取次数增加了1.6倍，并且抓取计划时间减少了6.3倍。

    

    本文考虑了一个杂乱问题，多个刚性凸多边形物体随机放置在一个平面表面上，必须使用单个和多个物体的抓取方式，将它们有效地运输到装箱中。我们引入摩擦来增加每小时的拾取次数，并使用实例进行神经网络的训练，以计划稳健的多物体抓取。在物理实验中，相比于多物体抓取的先前工作，我们发现成功率增加了13.7％，每小时的拾取次数增加了1.6倍，抓取计划时间减少了6.3倍。与单个物体抓取相比，我们发现每小时的拾取次数增加了3.1倍。

    We consider a decluttering problem where multiple rigid convex polygonal objects rest in randomly placed positions and orientations on a planar surface and must be efficiently transported to a packing box using both single and multi-object grasps. Prior work considered frictionless multi-object grasping. In this paper, we introduce friction to increase picks per hour. We train a neural network using real examples to plan robust multi-object grasps. In physical experiments, we find a 13.7% increase in success rate, a 1.6x increase in picks per hour, and a 6.3x decrease in grasp planning time compared to prior work on multi-object grasping. Compared to single object grasping, we find a 3.1x increase in picks per hour.
    
[^79]: 通过邻域排序的图形软对比学习

    Graph Soft-Contrastive Learning via Neighborhood Ranking. (arXiv:2209.13964v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.13964](http://arxiv.org/abs/2209.13964)

    图对比学习（GCL）方法在图像领域表现出了显著的性能，但在应用于图数据时面临着生成无效视图和不可靠相似性对的限制。这篇论文提出了一种基于邻域排序的图形软对比学习方法，以更好地适应图的内在属性。

    

    图对比学习（Graph Contrastive Learning，GCL）已成为图自监督学习领域中一种有前景的方法。现有的GCL方法主要借鉴了计算机视觉领域对比学习的原理：通过指定完全相似的对来建模不变性。然而，当应用于图数据时，这种范式遇到了两个重要的限制：（1）生成的视图的有效性无法得到保证：图扰动可能会产生违反语义和图数据内在拓扑性质的无效视图；（2）在图视图中指定完全相似的对是不可靠的：对于抽象和非欧几里得的图数据，人们很难直观地决定绝对的相似性和不相似性。尽管当前的GCL方法表现出了显著的性能，但这些挑战需要重新评估：GCL是否能更有效地适应图的内在属性，而不仅仅采用计算机视觉的原则？

    Graph Contrastive Learning (GCL) has emerged as a promising approach in the realm of graph self-supervised learning. Prevailing GCL methods mainly derive from the principles of contrastive learning in the field of computer vision: modeling invariance by specifying absolutely similar pairs. However, when applied to graph data, this paradigm encounters two significant limitations: (1) the validity of the generated views cannot be guaranteed: graph perturbation may produce invalid views against semantics and intrinsic topology of graph data; (2) specifying absolutely similar pairs in the graph views is unreliable: for abstract and non-Euclidean graph data, it is difficult for humans to decide the absolute similarity and dissimilarity intuitively. Despite the notable performance of current GCL methods, these challenges necessitate a reevaluation: Could GCL be more effectively tailored to the intrinsic properties of graphs, rather than merely adopting principles from computer vision? In res
    
[^80]: 人类学习奖励函数偏好的模型

    Models of human preference for learning reward functions. (arXiv:2206.02231v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.02231](http://arxiv.org/abs/2206.02231)

    本研究提出了一种将人类偏好建模为每个轨迹段的遗憾的方法，并证明了可以根据这些遗憾生成的偏好来识别生成这些偏好的奖励函数。实验证明，这种遗憾偏好模型在性能上优于以前的模型。

    

    强化学习的效用受限于奖励函数与人类利益的一致性。一种有前途的对齐方法是从人类生成的轨迹段对之间学习奖励函数，这是一种从人类反馈中进行的强化学习方法。通常假设这些人类偏好仅由部分回报来决定，即每个轨迹段上的奖励总和。我们发现这种假设存在缺陷，提出将人类偏好建模为由每个轨迹段的遗憾来决定，遗憾是一种衡量轨迹段与最优决策之间偏离程度的度量。在根据遗憾生成的无穷多个偏好中，我们证明可以识别到与生成这些偏好的奖励函数等价的奖励函数，并且我们证明以前的部分回报模型在多种情境下缺乏这种可识别性属性。通过实验证明，我们提出的遗憾偏好模型在性能上优于以前的模型。

    The utility of reinforcement learning is limited by the alignment of reward functions with the interests of human stakeholders. One promising method for alignment is to learn the reward function from human-generated preferences between pairs of trajectory segments, a type of reinforcement learning from human feedback (RLHF). These human preferences are typically assumed to be informed solely by partial return, the sum of rewards along each segment. We find this assumption to be flawed and propose modeling human preferences instead as informed by each segment's regret, a measure of a segment's deviation from optimal decision-making. Given infinitely many preferences generated according to regret, we prove that we can identify a reward function equivalent to the reward function that generated those preferences, and we prove that the previous partial return model lacks this identifiability property in multiple contexts. We empirically show that our proposed regret preference model outperf
    
[^81]: 稀疏图学习在时空时间序列上的应用

    Sparse Graph Learning from Spatiotemporal Time Series. (arXiv:2205.13492v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.13492](http://arxiv.org/abs/2205.13492)

    本论文提出了一种基于概率评分的方法，通过学习关系依赖的图分布来解决在时空时间序列分析中关系信息不可用的问题，并在时间序列预测问题上展示了有效性。

    

    著名的图神经网络在时空时间序列分析中的杰出成果表明，关系约束为神经预测架构引入了有效的归纳偏差。然而，通常情况下，表征底层数据生成过程的关系信息是不可用的，从而使从数据中推断在后续处理阶段中使用哪个关系图成为了一个问题。我们提出了一种新颖的、有理论依据的概率评分方法，通过最大化任务整个过程的性能来学习关系依赖的图分布。所提出的图学习框架基于蒙特卡洛评分梯度估计的巩固方差缩减技术，并且在理论上有基础，并且在实践中有效。本文主要关注时间序列预测问题，并展示了通过将梯度估计器调整为图学习问题的有效性。

    Outstanding achievements of graph neural networks for spatiotemporal time series analysis show that relational constraints introduce an effective inductive bias into neural forecasting architectures. Often, however, the relational information characterizing the underlying data-generating process is unavailable and the practitioner is left with the problem of inferring from data which relational graph to use in the subsequent processing stages. We propose novel, principled - yet practical - probabilistic score-based methods that learn the relational dependencies as distributions over graphs while maximizing end-to-end the performance at task. The proposed graph learning framework is based on consolidated variance reduction techniques for Monte Carlo score-based gradient estimation, is theoretically grounded, and, as we show, effective in practice. In this paper, we focus on the time series forecasting problem and show that, by tailoring the gradient estimators to the graph learning prob
    
[^82]: 通过自训练与梯度引导提高事件抽取的效果

    Improve Event Extraction via Self-Training with Gradient Guidance. (arXiv:2205.12490v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2205.12490](http://arxiv.org/abs/2205.12490)

    本论文提出了一种自训练与梯度引导的框架，通过利用大规模无标签数据和使用Abstract Meaning Representation（AMR）图作为反馈，以改善事件抽取中的数据稀缺问题。实验结果显示这种方法的有效性。

    

    数据稀缺一直是限制事件抽取进展的主要因素。为了解决这个问题，我们提出了一种自训练与反馈（STF）框架，利用大规模无标签数据，并通过将其与相同句子的Abstract Meaning Representation（AMR）图进行比较，为每个新事件预测获取反馈。具体而言，STF包括（1）在现有事件注释上训练的基础事件抽取模型，然后应用于大规模无标签语料库以预测新的事件提及作为伪训练样本，和（2）一种新的评分模型，该模型对于每个新预测的事件触发器、一个参数、它的参数角色以及它们在AMR图中的路径进行估计，以表示伪标签的正确性。这些兼容性分数进一步作为反馈，鼓励或阻止模型在自训练过程中学习伪标签。在三个基准数据集上的实验结果表明了该方法的有效性。

    Data scarcity has been the main factor that hinders the progress of event extraction. To overcome this issue, we propose a Self-Training with Feedback (STF) framework that leverages the large-scale unlabeled data and acquires feedback for each new event prediction from the unlabeled data by comparing it to the Abstract Meaning Representation (AMR) graph of the same sentence. Specifically, STF consists of (1) a base event extraction model trained on existing event annotations and then applied to large-scale unlabeled corpora to predict new event mentions as pseudo training samples, and (2) a novel scoring model that takes in each new predicted event trigger, an argument, its argument role, as well as their paths in the AMR graph to estimate a compatibility score indicating the correctness of the pseudo label. The compatibility scores further act as feedback to encourage or discourage the model learning on the pseudo labels during self-training. Experimental results on three benchmark da
    
[^83]: 异步、基于选项的多智能体策略梯度：一种条件推理方法

    Asynchronous, Option-Based Multi-Agent Policy Gradient: A Conditional Reasoning Approach. (arXiv:2203.15925v3 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2203.15925](http://arxiv.org/abs/2203.15925)

    本文提出了一种条件推理方法来解决多智能体策略梯度方法在异步选项执行中的问题，并在基于选项的多智能体合作任务上取得有效结果。

    

    合作的多智能体问题通常需要在智能体之间进行协调，可以通过考虑全局状态的中央策略来实现。多智能体策略梯度（MAPG）方法通常用于学习这种策略，但通常仅适用于具有低级动作空间的问题。在具有大规模状态和动作空间的复杂问题中，将MAPG方法扩展为使用更高级别的动作（也称为选项）以提高策略搜索效率是有优势的。然而，多机器人选项执行通常是异步的，也就是说，智能体可能在不同的时间步骤选择并完成它们的选项。这使得MAPG方法很难推导出一个中央策略并评估其梯度，因为中央策略总是在相同的时间选择新的选项。在这项工作中，我们提出了一种新颖的条件推理方法来解决这个问题，并在代表性的基于选项的多智能体合作任务上证明了其有效性。

    Cooperative multi-agent problems often require coordination between agents, which can be achieved through a centralized policy that considers the global state. Multi-agent policy gradient (MAPG) methods are commonly used to learn such policies, but they are often limited to problems with low-level action spaces. In complex problems with large state and action spaces, it is advantageous to extend MAPG methods to use higher-level actions, also known as options, to improve the policy search efficiency. However, multi-robot option executions are often asynchronous, that is, agents may select and complete their options at different time steps. This makes it difficult for MAPG methods to derive a centralized policy and evaluate its gradient, as centralized policy always select new options at the same time. In this work, we propose a novel, conditional reasoning approach to address this problem and demonstrate its effectiveness on representative option-based multi-agent cooperative tasks thro
    
[^84]: 《虚构的翻转：无数据的中毒联邦学习》

    Fabricated Flips: Poisoning Federated Learning without Data. (arXiv:2202.05877v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2202.05877](http://arxiv.org/abs/2202.05877)

    本文介绍了一种名为无数据非定向攻击（DFA）的新方法，它通过合成恶意数据来制造对抗模型，在不需要窃听良性客户端传输或大量任务特定训练数据的情况下实现攻击。这种方法能够在联邦学习中降低生成模型质量，并限制该学习模式的实用性。

    

    对联邦学习的攻击可以严重降低生成模型的质量，限制这种新兴学习模式的实用性，该模式实现了本地化的分散式学习。然而，现有的非定向攻击对许多场景来说都不实际，因为它们假设攻击者知道良性客户端的每个更新，或者攻击者拥有大量的本地训练数据来模仿良性参与方的更新。在本文中，我们提出了一种无数据非定向攻击（DFA），它通过合成恶意数据来制造对抗模型，而无需窃听良性客户端的传输，也无需大量的任务特定训练数据。我们设计了两种DFA的变体，即DFA-R和DFA-G，它们在如何权衡隐蔽性和效果方面有所不同。具体来说，DFA-R通过迭代优化一个恶意数据层来最小化全局模型所有输出的预测置信度，而DFA-G则通过交互式训练恶意数据来实现。

    Attacks on Federated Learning (FL) can severely reduce the quality of the generated models and limit the usefulness of this emerging learning paradigm that enables on-premise decentralized learning. However, existing untargeted attacks are not practical for many scenarios as they assume that i) the attacker knows every update of benign clients, or ii) the attacker has a large dataset to locally train updates imitating benign parties. In this paper, we propose a data-free untargeted attack (DFA) that synthesizes malicious data to craft adversarial models without eavesdropping on the transmission of benign clients at all or requiring a large quantity of task-specific training data. We design two variants of DFA, namely DFA-R and DFA-G, which differ in how they trade off stealthiness and effectiveness. Specifically, DFA-R iteratively optimizes a malicious data layer to minimize the prediction confidence of all outputs of the global model, whereas DFA-G interactively trains a malicious dat
    
[^85]: 继承特征表示

    Successor Feature Representations. (arXiv:2110.15701v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2110.15701](http://arxiv.org/abs/2110.15701)

    继承特征表示（SFR）是一种新的Successor Representations (SR)的表达方式，通过学习继承特征的累积折扣概率来重新评估策略的预期回报。

    

    在强化学习中，迁移学习旨在利用源任务的知识来提高目标任务的学习性能。继承表示（SR）及其扩展的继承特征（SF）是在奖励函数在任务之间发生变化的领域中显著的迁移机制。它们重新评估先前学习策略在新的目标任务中的预期回报，以传递它们的知识。SF框架通过将奖励线性分解为继承特征和奖励权重向量，从而扩展了SR，并允许在高维任务中应用。但这样做的代价是奖励函数与继承特征之间存在线性关系，限制了它在存在这种线性关系的任务中的应用。我们提出了一种新的SR表达方式，即学习继承特征的累积折扣概率，称为继承特征表示（SFR）。关键是，SFR可以重新评估策略的预期回报

    Transfer in Reinforcement Learning aims to improve learning performance on target tasks using knowledge from experienced source tasks. Successor Representations (SR) and their extension Successor Features (SF) are prominent transfer mechanisms in domains where reward functions change between tasks. They reevaluate the expected return of previously learned policies in a new target task to transfer their knowledge. The SF framework extended SR by linearly decomposing rewards into successor features and a reward weight vector allowing their application in high-dimensional tasks. But this came with the cost of having a linear relationship between reward functions and successor features, limiting its application to tasks where such a linear relationship exists. We propose a novel formulation of SR based on learning the cumulative discounted probability of successor features, called Successor Feature Representations (SFR). Crucially, SFR allows to reevaluate the expected return of policies f
    
[^86]: 基于多注意力软分区网络的车辆再识别

    Multi-Attention-Based Soft Partition Network for Vehicle Re-Identification. (arXiv:2104.10401v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2104.10401](http://arxiv.org/abs/2104.10401)

    本文提出了一种基于多注意力软分区网络的车辆再识别方法，通过引入多软注意力机制来解决由于不同视角和相似车辆之间的内部差异导致的挑战，并避免了嘈杂的注意力图和额外的注释元数据的使用。

    

    车辆再识别通过区分相同和不同车辆的图像来实现识别。由于不同视角下相同车辆之间存在明显的内部差异以及相似车辆之间存在细微的外部差异，这是一个具有挑战性的过程。为解决这个问题，研究人员通过空间注意力机制提取视角感知或部分特定特征，但通常会导致嘈杂的注意力图或需要昂贵的额外注释元数据（如关键点）来提高质量。与此同时，基于研究人员的洞察力，已经提出了各种基于手工设计的特定视角或车辆部件的多注意力架构。然而，这种方法不能保证注意力分支的数量和性质对于现实世界的再识别任务是最优的。为解决这些问题，我们提出了一种基于多软注意力机制的新车辆再识别网络。

    Vehicle re-identification helps in distinguishing between images of the same and other vehicles. It is a challenging process because of significant intra-instance differences between identical vehicles from different views and subtle inter-instance differences between similar vehicles. To solve this issue, researchers have extracted view-aware or part-specific features via spatial attention mechanisms, which usually result in noisy attention maps or otherwise require expensive additional annotation for metadata, such as key points, to improve the quality. Meanwhile, based on the researchers' insights, various handcrafted multi-attention architectures for specific viewpoints or vehicle parts have been proposed. However, this approach does not guarantee that the number and nature of attention branches will be optimal for real-world re-identification tasks. To address these problems, we proposed a new vehicle re-identification network based on a multiple soft attention mechanism for captu
    
[^87]: 具有预分配固定分类器的类增量学习

    Class-incremental Learning with Pre-allocated Fixed Classifiers. (arXiv:2010.08657v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2010.08657](http://arxiv.org/abs/2010.08657)

    本文提出了一种具有预分配固定分类器的类增量学习方法，通过利用存储在情节性记忆中的过去数据，并在学习阶段的开始就将一些预分配的输出节点纳入分类损失的计算，解决了神经网络在类增量学习中遗忘先前知识的问题。

    

    在类增量学习中，学习代理面对一系列数据的任务是学习新类别而不忘记以前的类别。神经网络在这种情况下常常会忘记先前获得的知识。为了解决这个问题，有效的方法利用存储在一个情节性记忆中的过去数据，同时扩展最终分类器节点以容纳新的类别。在这项工作中，我们用一个新颖的固定分类器替代了扩展分类器，其中一些预分配的输出节点从学习阶段开始就受到分类损失的影响。与标准扩展分类器相反，这样做有以下好处：(a)未来未见过的类别的输出节点从学习的一开始就能看到负样本，以及逐渐增加的正样本；(b)能够学习不随着新类别的加入而改变其几何配置的特征。

    In class-incremental learning, a learning agent faces a stream of data with the goal of learning new classes while not forgetting previous ones. Neural networks are known to suffer under this setting, as they forget previously acquired knowledge. To address this problem, effective methods exploit past data stored in an episodic memory while expanding the final classifier nodes to accommodate the new classes.  In this work, we substitute the expanding classifier with a novel fixed classifier in which a number of pre-allocated output nodes are subject to the classification loss right from the beginning of the learning phase. Contrarily to the standard expanding classifier, this allows: (a) the output nodes of future unseen classes to firstly see negative samples since the beginning of learning together with the positive samples that incrementally arrive; (b) to learn features that do not change their geometric configuration as novel classes are incorporated in the learning model.  Experi
    

