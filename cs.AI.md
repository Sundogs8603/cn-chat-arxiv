# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Natural Counterfactuals With Necessary Backtracking](https://rss.arxiv.org/abs/2402.01607) | 本研究提出了一种自然反事实框架和方法，通过优化控制回溯的范围，生成与实际世界的数据分布相匹配的自然反事实，从而改进了反事实推理。 |
| [^2] | [CounterCurate: Enhancing Physical and Semantic Visio-Linguistic Compositional Reasoning via Counterfactual Examples](https://arxiv.org/abs/2402.13254) | 本研究提出CounterCurate框架，通过对比例子和生成式微调，全面提升视觉-语言组合推理能力，解决了物理推理和语义对照微调方面的关键问题，实现了显著性能改进。 |
| [^3] | [TofuEval: Evaluating Hallucinations of LLMs on Topic-Focused Dialogue Summarization](https://arxiv.org/abs/2402.13249) | 论文提出了一个新的主题对话摘要评估基准TofuEval，研究发现现有的LLMs在对话领域存在大量事实错误的幻觉，并表明当LLMs充当事实评估器时，其表现不佳。 |
| [^4] | [Federated Causal Discovery from Heterogeneous Data](https://arxiv.org/abs/2402.13241) | 该研究提出了一种新型联邦因果发现方法，旨在适应任意因果模型和异构数据，通过使用替代变量和联邦条件独立性检验来解决数据异质性，并建立了联邦独立变化原则用于确定因果方向。 |
| [^5] | [Smaug: Fixing Failure Modes of Preference Optimisation with DPO-Positive](https://arxiv.org/abs/2402.13228) | 在这项工作中，我们提出了一种新的损失函数和训练过程DPO-Positive（DPOP），以避免直接偏好优化（DPO）中潜在的失败模式，并发现DPOP明显优于DPO。 |
| [^6] | [NeRF Solves Undersampled MRI Reconstruction](https://arxiv.org/abs/2402.13226) | NeRF技术利用神经辐射场概念解决了MRI重建中的欠采样问题，通过神经表示从欠采样的$k$-space数据中得到高维MR图像，并研究了有效的欠采样策略。 |
| [^7] | [AgentMD: Empowering Language Agents for Risk Prediction with Large-Scale Clinical Tool Learning](https://arxiv.org/abs/2402.13225) | AgentMD是一种新型语言代理，能够自动筛选和应用包含2,164个临床计算器的RiskCalcs集合，为克服临床工具易用性挑战和提高工作流效率提供了机会。 |
| [^8] | [Controlling Large Electric Vehicle Charging Stations via User Behavior Modeling and Stochastic Programming](https://arxiv.org/abs/2402.13224) | 本文介绍了一个新的电动汽车充电站模型，通过用户行为建模和随机规划，解决了充电会话不确定性问题，并提出了两种方法来优化成本并提高用户满意度。 |
| [^9] | [Analyzing Operator States and the Impact of AI-Enhanced Decision Support in Control Rooms: A Human-in-the-Loop Specialized Reinforcement Learning Framework for Intervention Strategies](https://arxiv.org/abs/2402.13219) | 本研究提出了一种专门强化学习框架，集成了AI决策支持系统，旨在改善控制室操作员的工作效率和情境意识，并为其提供根据系统和人类表现状态量身定制的干预策略。 |
| [^10] | [VideoPrism: A Foundational Visual Encoder for Video Understanding](https://arxiv.org/abs/2402.13217) | VideoPrism是一个通用的视频编码器，通过全局-局部语义视频嵌入的蒸馏和标记混洗方案，在多个视频理解任务上取得了最新技术水平的表现。 |
| [^11] | [Softmax Probabilities (Mostly) Predict Large Language Model Correctness on Multiple-Choice Q&A](https://arxiv.org/abs/2402.13213) | 多项选择问答任务中，基于最大softmax概率（MSPs）的模型预测方法有助于提高大型语言模型（LLMs）的正确性，我们提出了一种根据MSP有选择地弃权的策略以提高性能。 |
| [^12] | [Soft Self-Consistency Improves Language Model Agents](https://arxiv.org/abs/2402.13212) | Soft Self-Consistency (Soft-SC)通过软化评分标准替代自一致性的多数投票方法，提高了在涉及生成多个动作的长期互动任务中的性能和效率 |
| [^13] | [How do Hyenas deal with Human Speech? Speech Recognition and Translation with ConfHyena](https://arxiv.org/abs/2402.13208) | ConfHyena是一种基于Hyena的改进模型，通过在处理语音时减少计算成本，显著缩短了训练时间。 |
| [^14] | [Tiny Reinforcement Learning for Quadruped Locomotion using Decision Transformers](https://arxiv.org/abs/2402.13201) | 将模仿学习问题视为条件序列建模任务，通过训练决策变换器并使用奖励机制，将生成模型压缩以适应资源受限的机器人平台。 |
| [^15] | [Benchmarking Retrieval-Augmented Generation for Medicine](https://arxiv.org/abs/2402.13178) | 通过提出首个医学信息检索增强生成评估(MIRAGE)基准测试，并使用MedRAG工具包进行大规模实验，实现了对多个大型语言模型的准确性改进。 |
| [^16] | [SubIQ: Inverse Soft-Q Learning for Offline Imitation with Suboptimal Demonstrations](https://arxiv.org/abs/2402.13147) | 逆向软 Q 学习用于获得次优演示的离线模仿挑战了离线 IL 中有限支持专家演示的问题，并提出了一种解决方案以匹配次优演示集合的占用分布 |
| [^17] | [CMDAG: A Chinese Metaphor Dataset with Annotated Grounds as CoT for Boosting Metaphor Generation](https://arxiv.org/abs/2402.13145) | 本文介绍了一个大规模高质量的带注释中文隐喻语料库，强调隐喻生成中的基础及其独特特征，而非传统的对象和载体组合。 |
| [^18] | [VGMShield: Mitigating Misuse of Video Generative Models](https://arxiv.org/abs/2402.13126) | VGMShield提出了三项简单但开创性的措施，通过检测虚假视频、溯源问题和利用预训练的空间-时间动态模型，防范视频生成模型的误用。 |
| [^19] | [TreeEval: Benchmark-Free Evaluation of Large Language Models through Tree Planning](https://arxiv.org/abs/2402.13125) | TreeEval提出了一种无基准评估方法，通过树规划策略提升了大型语言模型的评估效率和完整性 |
| [^20] | [BuffGraph: Enhancing Class-Imbalanced Node Classification via Buffer Nodes](https://arxiv.org/abs/2402.13114) | BuffGraph通过插入缓冲节点到图中，调节主要类别的影响，以改善次要类别的表示，在类别不平衡的节点分类问题上表现优越。 |
| [^21] | [CIF-Bench: A Chinese Instruction-Following Benchmark for Evaluating the Generalizability of Large Language Models](https://arxiv.org/abs/2402.13109) | CIF-Bench是一个用于评估大型语言模型在中文语言上零样本泛化能力的基准，通过多样化的指令和数据集划分来减少评估偏见。 |
| [^22] | [ELAD: Explanation-Guided Large Language Models Active Distillation](https://arxiv.org/abs/2402.13098) | ELAD提出了一种Explanation-Guided LLMs Active Distillation框架，通过主动学习策略优化注释成本和模型性能之间的平衡，并引入了基于解释的样本选择方法和LLM-注释解释修订技术。 |
| [^23] | [Event-level Knowledge Editing](https://arxiv.org/abs/2402.13093) | 提出了一个新的任务设置：事件级知识编辑，通过直接编辑新事件到LLMs中，在效率和完整性上改进了传统的三元组级别编辑。 |
| [^24] | [Towards an empirical understanding of MoE design choices](https://arxiv.org/abs/2402.13089) | 本研究系统评估了Mixture of Experts（MoEs）中常见设计选择对验证性能的影响，揭示了路由器的学习与初始化对模型性能的比较、序列级路由与标记级路由在专家专业化方面的不同影响。 |
| [^25] | [Mechanistic Neural Networks for Scientific Machine Learning](https://arxiv.org/abs/2402.13077) | 本文提出了一种名为机制神经网络的神经网络设计，通过在标准架构中引入新的机制模块，学习控制微分方程作为表示，提高数据建模的可解释性和效率，并借助一种新颖的松弛线性规划求解器实现可扩展的GPU并行处理。 |
| [^26] | [Random Graph Set and Evidence Pattern Reasoning Model](https://arxiv.org/abs/2402.13058) | 提出了证据模式推理模型（EPRM）以更好地符合决策目标，引入随机图集（RGS）来模拟复杂关系并表示更多事件类型。 |
| [^27] | [Identifying Semantic Induction Heads to Understand In-Context Learning](https://arxiv.org/abs/2402.13055) | 该研究通过分析注意力头的操作，揭示了结合了句法依赖和知识图关系的语义感应头的出现，从而更好地理解了大型语言模型的上下文学习能力。 |
| [^28] | [Text-Guided Molecule Generation with Diffusion Language Model](https://arxiv.org/abs/2402.13040) | 提出了一种名为Text-Guided Molecule Generation with Diffusion Language Model（TGM-DLM）的新方法，通过扩散模型进行文本引导的分子生成，在生成有效分子表示方面表现出显著的效果优于自回归模型MolT5-Base。 |
| [^29] | [Align Your Intents: Offline Imitation Learning via Optimal Transport](https://arxiv.org/abs/2402.13037) | 通过最优传输的离线模仿学习方法AILOT，可以在缺乏明确奖励的情况下，仅通过观察专家学习所需的行为。 |
| [^30] | [Learning to Check: Unleashing Potentials for Self-Correction in Large Language Models](https://arxiv.org/abs/2402.13035) | 通过精心设计训练数据和构建检查-校正数据集，本研究增强了大型语言模型的自我校正能力，提高了自我校正的准确性。 |
| [^31] | [Heterogeneous Graph Reasoning for Fact Checking over Texts and Tables](https://arxiv.org/abs/2402.13028) | 提出了一种基于异质图的模型HeterFC，用于文本和表格中的事实核查，利用异质证据图和关系图神经网络进行信息传播。 |
| [^32] | [CFEVER: A Chinese Fact Extraction and VERification Dataset](https://arxiv.org/abs/2402.13025) | CFEVER是一个为事实提取和验证而设计的汉语数据集，提供了严格的标准和对应证据，可用于开发自动化系统，减轻人工核查的工作量。 |
| [^33] | [Improving Neural-based Classification with Logical Background Knowledge](https://arxiv.org/abs/2402.13019) | 本文提出了一种新的神经符号技术——在推理过程中的语义调节，该技术仅在推理过程中约束系统，而不影响训练，相对于其他两种常见神经符号技术具有理论和实际优势，在多尺度方法上的评估结果表明其对网络规模的好处。 |
| [^34] | [An Autonomous Large Language Model Agent for Chemical Literature Data Mining](https://arxiv.org/abs/2402.12993) | 介绍了一个端到端的人工智能代理框架，利用大型语言模型实现从化学文献中高保真提取信息，充当化学助手的角色，自动化数据收集和分析，从而提高工作效率。 |
| [^35] | [TRAP: Targeted Random Adversarial Prompt Honeypot for Black-Box Identification](https://arxiv.org/abs/2402.12991) | TRAP提出了一种名为Targeted Random Adversarial Prompt (TRAP)的方法，用于识别特定LLM的使用，并在单次交互后以超过95%的真阳性率和低于0.2%的误报率检测目标LLMs。 |
| [^36] | [Can GNN be Good Adapter for LLMs?](https://arxiv.org/abs/2402.12984) | 本文提出了GraphAdapter，利用图神经网络（GNN）作为高效适配器，与LLMs协同处理文本属性图（TAGs）。 |
| [^37] | [The Impact of Demonstrations on Multilingual In-Context Learning: A Multidimensional Analysis](https://arxiv.org/abs/2402.12976) | 通过多维分析发现，示范的有效性在多语种上下文学习中存在显著差异，其中部分模型对示范质量不敏感，而精心设计的模板可以消除对示范的依赖。 |
| [^38] | [Gl\'orIA - A Generative and Open Large Language Model for Portuguese](https://arxiv.org/abs/2402.12969) | Gl'orIA是一种专门为欧洲葡萄牙语设计的强大解码器大型语言模型，通过对350亿个tokens的全面PT-PT文本语料库预训练，为欧洲葡萄牙语提供了解决方案，并引入了CALAME-PT，这是第一个葡萄牙语零样本语言建模基准。 |
| [^39] | [Conditional Logical Message Passing Transformer for Complex Query Answering](https://arxiv.org/abs/2402.12954) | 提出了一种考虑查询图中常量和变量之间差异，能动态测量消息重要性并捕捉隐式逻辑依赖关系的条件逻辑消息传递变压器。 |
| [^40] | [QuanTest: Entanglement-Guided Testing of Quantum Neural Network Systems](https://arxiv.org/abs/2402.12950) | QuanTest是一个基于纠缠的对抗测试框架，旨在揭示量子神经网络系统中的潜在错误行为。 |
| [^41] | [Discovering Behavioral Modes in Deep Reinforcement Learning Policies Using Trajectory Clustering in Latent Space](https://arxiv.org/abs/2402.12939) | 通过利用轨迹聚类和降维技术在神经网络的潜空间中研究深度强化学习策略的行为模式，可以发现并改进其多样的行为模式和次优选择。 |
| [^42] | [A Literature Review of Literature Reviews in Pattern Analysis and Machine Intelligence](https://arxiv.org/abs/2402.12928) | 本文旨在提供对模式分析与机器智能领域文献综述的全面评估，引入大语言模型驱动的文献计量指标，并构建了RiPAMI元数据数据库和主题数据集以获取PAMI综述的统计特征。 |
| [^43] | [Data Pipeline Training: Integrating AutoML to Optimize the Data Flow of Machine Learning Models](https://arxiv.org/abs/2402.12916) | 本文讨论了如何通过集成 AutoML 技术优化数据管道，提升数据流智能性以在机器学习任务中取得更好结果，并揭示了构建高效适应不断变化数据环境的关键策略。 |
| [^44] | [Incentive Compatibility for AI Alignment in Sociotechnical Systems: Positions and Prospects](https://arxiv.org/abs/2402.12907) | 该论文提出了激励兼容性社会技术对齐问题（ICSAP），旨在探讨如何利用博弈论中的激励兼容性原则来维持AI与人类社会的共识。 |
| [^45] | [The practice of qualitative parameterisation in the development of Bayesian networks](https://arxiv.org/abs/2402.12887) | 贝叶斯网络的典型开发阶段包括结构开发和参数化，而开发过程中执行初步的粗略参数化对于确保结构的合适性和后续的开发和验证至关重要。 |
| [^46] | [Backward Lens: Projecting Language Model Gradients into the Vocabulary Space](https://arxiv.org/abs/2402.12865) | 将语言模型梯度投影到词汇空间中，挖掘信息在LMs内部的流动方式，探索新信息如何存储在LMs的神经元中。 |
| [^47] | [Instruction-tuned Language Models are Better Knowledge Learners](https://arxiv.org/abs/2402.12847) | 通过在持续预训练文档之前暴露LLM到问题-答案对，以便从复杂文档中编码知识，可以更好地适应知识访问方式。 |
| [^48] | [ConVQG: Contrastive Visual Question Generation with Multimodal Guidance](https://arxiv.org/abs/2402.12846) | 提出了ConVQG方法通过双重对比目标区分使用两种模态生成的问题和基于单一模式的问题，解决了在生成专注问题的同时确保与图像内容的高度相关性的挑战. |
| [^49] | [MORE-3S:Multimodal-based Offline Reinforcement Learning with Shared Semantic Spaces](https://arxiv.org/abs/2402.12845) | 将不同模态对齐到相同的语义嵌入空间有利于提升离线强化学习性能，通过集成多模态和预训练语言模型，我们成功将其转化为一个监督学习任务，有助于增强强化学习训练性能并促进长期战略思维。 |
| [^50] | [SolarPanel Segmentation :Self-Supervised Learning for Imperfect Datasets](https://arxiv.org/abs/2402.12843) | 自监督学习方法在太阳能面板分割问题中显著提高了模型泛化能力，减少了对手动标注数据的依赖。 |
| [^51] | [PromptKD: Distilling Student-Friendly Knowledge for Generative Language Models via Prompt Tuning](https://arxiv.org/abs/2402.12842) | 提出了PromptKD方法，通过提示调整实现了生成语言模型提取学生友好知识的蒸馏，无需微调整整个教师模型。 |
| [^52] | [PANDA: Preference Adaptation for Enhancing Domain-Specific Abilities of LLMs](https://arxiv.org/abs/2402.12835) | PANDA是一种旨在增强LLMs领域特定能力的方法，通过利用专家模型响应偏好的见解，无需微调即可实现显著改进。 |
| [^53] | [Fine-Tuning, Prompting, In-Context Learning and Instruction-Tuning: How Many Labelled Samples Do We Need?](https://arxiv.org/abs/2402.12819) | 专门模型通常只需少量标记样本（100-1000个）就能与通用模型持平甚至更好，取决于任务的复杂性和结果的变化。 |
| [^54] | [On Sensitivity of Learning with Limited Labelled Data to the Effects of Randomness: Impact of Interactions and Systematic Choices](https://arxiv.org/abs/2402.12817) | 有限标注数据学习对随机性的敏感性，通过系统研究随机因素的影响，揭示了忽略相互作用可能导致的不一致结果。 |
| [^55] | [PIP-Net: Pedestrian Intention Prediction in the Wild](https://arxiv.org/abs/2402.12810) | PIP-Net是一个新型框架，通过综合利用动态学数据和场景空间特征，采用循环和时间注意力机制解决方案，成功预测行人通过马路的意图，性能优于现有技术。 |
| [^56] | [Autonomous Reality Modelling for Cultural Heritage Sites employing cooperative quadrupedal robots and unmanned aerial vehicles](https://arxiv.org/abs/2402.12794) | 通过使用自主仿生四足机器人代理和无人机，本文提出了一种自主的3D现实建模方法，可以用于文化遗产(CH)文物，实现了系统化和可重复的3D RM过程。 |
| [^57] | [Fair Classifiers Without Fair Training: An Influence-Guided Data Sampling Approach](https://arxiv.org/abs/2402.12789) | 在不实施公平训练算法的情况下学习公平分类器，通过抽样具有影响力的数据来逐步转移原始训练数据，从而提高公平性和准确性。 |
| [^58] | [Advancing GenAI Assisted Programming--A Comparative Study on Prompt Efficiency and Code Quality Between GPT-4 and GLM-4](https://arxiv.org/abs/2402.12782) | 本研究通过比较GPT-4和GLM-4，发现最简单直接的提示策略能够产生最佳的代码生成结果，并且指出虽然GPT-4略优于GLM-4，但对于普通用户差异微乎其微。研究还展示了相对传统编码规范30到100倍的代码生成效率增加，并强调了GenAI辅助编码将引发编程领域范式转变的重要性。 |
| [^59] | [A User-Friendly Framework for Generating Model-Preferred Prompts in Text-to-Image Synthesis](https://arxiv.org/abs/2402.12760) | 提出了一种用户友好的框架，用于生成模型优选提示，在文本到图像合成中的应用。 |
| [^60] | [Model Composition for Multimodal Large Language Models](https://arxiv.org/abs/2402.12750) | 通过模型组合现有的多模态大型语言模型，提出了一种新范式，有效地保留了每个原始模型的模态理解能力，并引入了一种用于解决合并参数干扰和不匹配问题的方法。 |
| [^61] | [Me LLaMA: Foundation Large Language Models for Medical Applications](https://arxiv.org/abs/2402.12749) | Me LLaMA是一个医学领域的大型语言模型系列，通过持续预训练和指导调整在大型医学数据集上训练而成，其在零-shot和少-shot学习方面表现优于现有的医学语言模型和商业巨头ChatGPT。 |
| [^62] | [Can Large Language Models be Used to Provide Psychological Counselling? An Analysis of GPT-4-Generated Responses Using Role-play Dialogues](https://arxiv.org/abs/2402.12738) | 利用专家角色扮演对话数据进行研究发现，GPT-4生成的回复在心理辅导情境中与人类回复相竞争。 |
| [^63] | [CST: Calibration Side-Tuning for Parameter and Memory Efficient Transfer Learning](https://arxiv.org/abs/2402.12736) | 该论文介绍了一种轻量级的微调策略，称为校准侧调节，将成功应用于转换器的技术与ResNet相结合，以提高网络性能并保持平滑的训练过程。 |
| [^64] | [BMLP: Behavior-aware MLP for Heterogeneous Sequential Recommendation](https://arxiv.org/abs/2402.12733) | 提出了一种新颖的基于多层感知器的异构序列推荐方法BMLP，通过行为感知模块和购买意图感知模块捕捉用户的异构兴趣和购买意图。 |
| [^65] | [UMBCLU at SemEval-2024 Task 1A and 1C: Semantic Textual Relatedness with and without machine translation](https://arxiv.org/abs/2402.12730) | 使用机器翻译和大型语言模型，本文开发了用于非洲和亚洲语言语义文本相关性任务的两种模型，取得了比部分官方基准更好的效果。 |
| [^66] | [Scalable and reliable deep transfer learning for intelligent fault detection via multi-scale neural processes embedded with knowledge](https://arxiv.org/abs/2402.12729) | 提出了一种名为GTNP的神经过程深度迁移学习方法，通过特征传输策略弥合源域和目标域的数据分布差异，解决了数据稀缺和缺乏可靠性分析的问题 |
| [^67] | [Modality-Aware Integration with Large Language Models for Knowledge-based Visual Question Answering](https://arxiv.org/abs/2402.12728) | 提出了一种模态感知的LLM集成方法（MAIL）用于针对KVQA，通过细致地利用多模态知识来处理图像理解和知识推理。 |
| [^68] | [Diffusion Posterior Sampling is Computationally Intractable](https://arxiv.org/abs/2402.12727) | 我们证明了后验抽样在计算上是难以解决的：在加密学中最基本的假设下——单向函数存在的假设下，存在一些实例，对于这些实例，每个算法都需要超多项式时间，即使无条件抽样可以证明是快速的。 |
| [^69] | [PAC-FNO: Parallel-Structured All-Component Fourier Neural Operators for Recognizing Low-Quality Images](https://arxiv.org/abs/2402.12721) | 提出了一个新颖的神经网络模型 PAC-FNO，通过在频域操作可以处理不同分辨率的图像，解决了传统方法在处理这类问题上的计算成本高的挑战。 |
| [^70] | [Revisiting the Information Capacity of Neural Network Watermarks: Upper Bound Estimation and Beyond](https://arxiv.org/abs/2402.12720) | 本文从信息理论的角度研究了深度神经网络水印的容量，提出了一种新的容量定义类似于信道容量，设计了一种算法来紧密估计其上界并提出了一种通用的非侵入式方法来安全传输超出容量的身份信息。 |
| [^71] | [From Cloud to Edge: Rethinking Generative AI for Low-Resource Design Challenges](https://arxiv.org/abs/2402.12702) | 论文探讨了将生成人工智能调整以适应边缘资源受限环境的潜力、挑战和创新方法，以在低资源环境中高效创建设计解决方案。 |
| [^72] | [XRL-Bench: A Benchmark for Evaluating and Comparing Explainable Reinforcement Learning Techniques](https://arxiv.org/abs/2402.12685) | XRL-Bench是一个用于评估和比较可解释强化学习技术的统一标准化基准，旨在解决状态解释方法在RL中的重要性评估框架不足的问题。 |
| [^73] | [The FinBen: An Holistic Financial Benchmark for Large Language Models](https://arxiv.org/abs/2402.12659) | 本文引入了FinBen，这是第一个专门设计用于彻底评估LLMs在金融领域能力的全面开源评估基准，对15个代表性LLMs进行评估，揭示了它们的优势和局限性。 |
| [^74] | [HyperMoE: Towards Better Mixture of Experts via Transferring Among Experts](https://arxiv.org/abs/2402.12656) | HyperMoE通过Hypernetworks框架整合知识传递的概念，解决了在专家选择过程中专家知识稀疏性和可用性之间的矛盾。 |
| [^75] | [Training Artificial Neural Networks by Coordinate Search Algorithm](https://arxiv.org/abs/2402.12646) | 通过提出的高效版本的非梯度坐标搜索（CS）算法，我们可以训练神经网络，解决了需要可微激活函数和同时优化多个非可微损失函数的问题。 |
| [^76] | [A Comprehensive Review of Machine Learning Advances on Data Change: A Cross-Field Perspective](https://arxiv.org/abs/2402.12627) | 该综述将领域转移和概念漂移重新归为一个单一的研究问题，即数据变化问题，系统地总结了这两个研究领域中最新的方法。 |
| [^77] | [Efficient Parameter Mining and Freezing for Continual Object Detection](https://arxiv.org/abs/2402.12624) | 提出了在增量目标检测场景中利用高效的层级参数隔离方式，可以帮助网络保持检测器性能，并在对象检测模型内促进增量学习。 |
| [^78] | [Generative AI Security: Challenges and Countermeasures](https://arxiv.org/abs/2402.12617) | 生成式人工智能的安全挑战及对策研究。 |
| [^79] | [Patient-Centric Knowledge Graphs: A Survey of Current Methods, Challenges, and Applications](https://arxiv.org/abs/2402.12608) | 患者中心知识图谱（PCKGs）代表医疗保健中的重要转变，通过整合各种类型的健康数据，实现更加个性化和有效的患者护理。 |
| [^80] | [Graph-based Virtual Sensing from Sparse and Partial Multivariate Observations](https://arxiv.org/abs/2402.12598) | 本文提出了一种基于图的虚拟传感方法，通过利用相关变量之间的依赖关系，设计了GgNet架构，用于推断未观测信道的值。 |
| [^81] | [FairProof : Confidential and Certifiable Fairness for Neural Networks](https://arxiv.org/abs/2402.12572) | FairProof提出了一种使用零知识证明来公开验证神经网络模型公平性的系统，同时保持机密性，并提出了适用于ZKPs的全连接神经网络的公平性认证算法。 |
| [^82] | [Confidence Matters: Revisiting Intrinsic Self-Correction Capabilities of Large Language Models](https://arxiv.org/abs/2402.12563) | 本文研究了大型语言模型的内在自我校正能力，并提出了一个“如果-否则”（IoE）提示框架，帮助模型评估自身“信心”并进行自我校正。 |
| [^83] | [CausalGym: Benchmarking causal interpretability methods on linguistic tasks](https://arxiv.org/abs/2402.12560) | CausalGym介绍了在语言任务中基准测试解释方法影响模型行为的能力。研究表明DAS方法胜过其他方法，并用它来研究了pythia-1b中的两个困难语言现象的学习轨迹。 |
| [^84] | [Landmark-based Localization using Stereo Vision and Deep Learning in GPS-Denied Battlefield Environment](https://arxiv.org/abs/2402.12551) | 提出了一种在非GPS战场环境中使用立体视觉和深度学习的基于地标的定位方法 |
| [^85] | [Parallel Structures in Pre-training Data Yield In-Context Learning](https://arxiv.org/abs/2402.12530) | 本研究发现，语言模型的上下文学习能力取决于预训练数据中的平行结构，通过在相似模板的短语对中学习来提高上下文学习准确度。 |
| [^86] | [The Edge-of-Reach Problem in Offline Model-Based Reinforcement Learning](https://arxiv.org/abs/2402.12527) | 学习的动力学模型被真实且无误差的动力学替代时，现有模型驱动方法将会完全失败，揭示出一个重大误解。 |
| [^87] | [LangXAI: Integrating Large Vision Models for Generating Textual Explanations to Enhance Explainability in Visual Perception Tasks](https://arxiv.org/abs/2402.12525) | LangXAI通过整合大型视觉模型，为视觉感知任务提供文本解释，弥补了最终用户在人工智能和计算机视觉方面知识的理解差距。 |
| [^88] | [Gaussian Process Neural Additive Models](https://arxiv.org/abs/2402.12518) | 本文提出了一种新的高斯过程神经加性模型（GP-NAM），通过随机傅里叶特征对高斯过程进行单层神经网络构建，可以实现具有凸目标函数和可训练参数数量随特征维度线性增长的优势，同时在性能上不亚于更深的NAM方法。 |
| [^89] | [Automated Security Response through Online Learning with Adaptive Conjectures](https://arxiv.org/abs/2402.12499) | 该论文通过自适应猜想的在线学习，提出了一种适用于IT基础设施的自动化安全响应方法，其中游戏参与者通过Bayesian学习调整猜想，并通过推演更新策略，最终实现了最佳拟合，提高了推演在猜想模型下的性能。 |
| [^90] | [Towards Cross-Domain Continual Learning](https://arxiv.org/abs/2402.12490) | 介绍了一种名为跨领域持续学习（CDCL）的新方法，通过整合任务间和任务内的交叉注意机制，在紧凑的卷积网络中延迟数据漂移，实现了无监督的跨领域学习（UDA）。 |
| [^91] | [In deep reinforcement learning, a pruned network is a good network](https://arxiv.org/abs/2402.12479) | 通过逐渐剪枝，使代理能够最大程度地发挥参数效能，从而产生比传统网络显著性能提升的网络，并展现出一种“缩放定律”。 |
| [^92] | [The (R)Evolution of Multimodal Large Language Models: A Survey](https://arxiv.org/abs/2402.12451) | 多模态大型语言模型能够无缝整合视觉和文本模态，为生成智能提供了新的可能性。 |
| [^93] | [Attacks on Node Attributes in Graph Neural Networks](https://arxiv.org/abs/2402.12426) | 该研究通过基于特征的对抗攻击，针对图神经网络中的节点属性展开研究，发现使用Projected Gradient Descent的决策时攻击比使用Mean Node Embeddings和Graph Contrastive Learning策略的毒化攻击更加有效。 |
| [^94] | [Tables as Images? Exploring the Strengths and Limitations of LLMs on Multimodal Representations of Tabular Data](https://arxiv.org/abs/2402.12424) | 本研究探讨了LLM在解释表格数据方面的有效性，比较了文本和图像表格表示对LLM性能的影响，为在表格相关任务上有效使用LLM提供了见解。 |
| [^95] | [Simulacra as Conscious Exotica](https://arxiv.org/abs/2402.12422) | 本文借鉴了维特根斯坦的后期著作，尝试回答在概念生成语言模型构建的AI代理中是否有意义谈论意识的问题，避免了二元论思维的陷阱。 |
| [^96] | [EBFT: Effective and Block-Wise Fine-Tuning for Sparse LLMs](https://arxiv.org/abs/2402.12419) | 提出了一种有效的块状微调稀疏LLM的框架，通过最小化重建误差并采用反向传播逐块优化解决方案，实验结果表明在各种基准测试中优于其他方法。 |
| [^97] | [Beyond Uniform Scaling: Exploring Depth Heterogeneity in Neural Architectures](https://arxiv.org/abs/2402.12418) | 引入了一种基于二阶损失景观信息的自动缩放方法，同时扩展和训练transformers，提出了神经架构中的深度异质性概念，并在ImageNet100上实现了准确性和参数效率的提升。 |
| [^98] | [Predicting trucking accidents with truck drivers 'safety climate perception across companies: A transfer learning approach](https://arxiv.org/abs/2402.12417) | 提出了一种预先训练然后微调的迁移学习方法，利用其他公司的数据开发AI模型，更准确地预测卡车事故风险。 |
| [^99] | [Aligning Individual and Collective Objectives in Multi-Agent Cooperation](https://arxiv.org/abs/2402.12416) | 引入Altruistic Gradient Adjustment (AgA)优化方法，利用梯度调整来对齐个体和集体目标，加速收敛到期望解决方案 |
| [^100] | [Dynamic and Super-Personalized Media Ecosystem Driven by Generative AI: Unpredictable Plays Never Repeating The Same](https://arxiv.org/abs/2402.12412) | 通过引入人工智能视频生成器，该论文提出了一种新型媒体服务模型，在动态媒体生态系统中实现了超个性化服务。 |
| [^101] | [Deep Structural Knowledge Exploitation and Synergy for Estimating Node Importance Value on Heterogeneous Information Networks](https://arxiv.org/abs/2402.12411) | 通过利用异构结构化知识，提出了一个新的学习框架SKES，用于在异构信息网络中丰富节点表示的信息量，进而建立了一个可解释的节点重要性计算范式。 |
| [^102] | [ModelGPT: Unleashing LLM's Capabilities for Tailored Model Generation](https://arxiv.org/abs/2402.12408) | ModelGPT是一个新颖的框架，通过利用LLM的能力，根据用户提供的数据或任务描述生成定制化的AI模型，让用户能够更快速和方便地使用AI模型。 |
| [^103] | [Teacher as a Lenient Expert: Teacher-Agnostic Data-Free Knowledge Distillation](https://arxiv.org/abs/2402.12406) | 该论文发现现有的无数据知识蒸馏方法对不同的教师模型非常敏感，生成的样本可能出现质量问题。 |
| [^104] | [scInterpreter: Training Large Language Models to Interpret scRNA-seq Data for Cell Type Annotation](https://arxiv.org/abs/2402.12405) | 该研究通过训练大型语言模型来解释和区分单细胞RNA测序数据中的细胞类型，展示了这些模型在准确分类细胞类型方面的潜力。 |
| [^105] | [Turn Waste into Worth: Rectifying Top-$k$ Router of MoE](https://arxiv.org/abs/2402.12399) | 提出了Rectify-Router解决了MoE模型中常用的Top-k路由机制所带来的令牌丢失和填充问题，通过Intra-GPU矫正和Fill-in矫正来实现。 |
| [^106] | [Toward using GANs in astrophysical Monte-Carlo simulations](https://arxiv.org/abs/2402.12396) | 生成对抗网络（GAN）在天体物理蒙特卡洛模拟中成功地统计复制了Maxwell-J\"uttner分布。 |
| [^107] | [Improving Model's Interpretability and Reliability using Biomarkers](https://arxiv.org/abs/2402.12394) | 利用决策树解释基于生物标志物的诊断模型，帮助临床医生提高识别不准确预测的能力，从而增强医学诊断模型的可靠性。 |
| [^108] | [On Automating Video Game Testing by Planning and Learning](https://arxiv.org/abs/2402.12393) | 提出了一种通过自动规划和学习技术自动化测试视频游戏的方法和工作流程，使得自动规划变得更容易接触到更广泛的受众。 |
| [^109] | [A Regression Mixture Model to understand the effect of the Covid-19 pandemic on Public Transport Ridership](https://arxiv.org/abs/2402.12392) | 提出了一种回归混合模型，通过对公共交通站点进行聚类和时间段进行分割，忽略了额外变量的影响，研究了 Covid-19 大流行对铁路公共交通乘客量的影响及其变化。 |
| [^110] | [Toward a Team of AI-made Scientists for Scientific Discovery from Gene Expression Data](https://arxiv.org/abs/2402.12391) | 引入了一个名为AI科学家团队（TAIS）的框架，旨在简化科学发现流程，由模拟角色协作，特别关注于识别具有疾病预测价值的基因 |
| [^111] | [A Semantic Social Network Analysis Tool for Sensitivity Analysis and What-If Scenario Testing in Alcohol Consumption Studies](https://arxiv.org/abs/2402.12390) | 一种用于酒精消费研究中敏感性分析和假设测试的语义社交网络分析工具，旨在描述和研究个体之间建立的社会关系 |
| [^112] | [Constrained Multi-objective Optimization with Deep Reinforcement Learning Assisted Operator Selection](https://arxiv.org/abs/2402.12381) | 提出了一种由深度强化学习辅助的在线操作员选择框架，旨在改进约束多目标优化进化算法中操作员的选择问题 |
| [^113] | [Emulated Disalignment: Safety Alignment for Large Language Models May Backfire!](https://arxiv.org/abs/2402.12343) | 安全对齐的大型语言模型可能会通过模拟失调框架，在对抗性操纵下产生危险结果，对训练的语言模型具有双倍有害性，高于强基线，强调了即使在安全对齐后也需要重新评估开源语言模型的重要性。 |
| [^114] | [Endowing Pre-trained Graph Models with Provable Fairness](https://arxiv.org/abs/2402.12161) | 提出了一种新的适配器调优框架，赋予预训练图模型具有可证明的公平性 |
| [^115] | [WKVQuant: Quantizing Weight and Key/Value Cache for Large Language Models Gains More](https://arxiv.org/abs/2402.12065) | 该论文提出了WKVQuant，一种专为大型语言模型设计的量化框架，通过量化权重和键值缓存来改善性能。 |
| [^116] | [Diagonalisation SGD: Fast & Convergent SGD for Non-Differentiable Models via Reparameterisation and Smoothing](https://arxiv.org/abs/2402.11752) | 引入了Diagonalisation Stochastic Gradient Descent（对角化SGD），通过重新参数化和平滑实现非可微模型的快速收敛SGD，在实证评估中表现出简单、快速、稳定，并且取得了数量级的工作规范化方差降低。 |
| [^117] | [The Unreasonable Effectiveness of Eccentric Automatic Prompts](https://arxiv.org/abs/2402.10949) | 异类自动提示的不合理有效性研究了大型语言模型在处理各种提示时的表现，结果显示在大多数情况下，包括“积极思考”提示会对模型性能产生积极影响。 |
| [^118] | [ConSmax: Hardware-Friendly Alternative Softmax with Learnable Parameters](https://arxiv.org/abs/2402.10930) | ConSmax是一种硬件友好型Softmax替代方案，通过引入可学习参数，在不影响性能的情况下实现了对原Softmax关键任务的高效处理。 |
| [^119] | [Radio-astronomical Image Reconstruction with Conditional Denoising Diffusion Model](https://arxiv.org/abs/2402.10204) | 该研究提出使用有条件降噪扩散模型从不干净的射电图像中重建天空模型，以实现准确定位和测量流量，为射电源的表征提供潜在改进。 |
| [^120] | [Rethinking Information Structures in RLHF: Reward Generalization from a Graph Theory Perspective](https://arxiv.org/abs/2402.10184) | 本研究通过设计奖励建模过程中的数据集信息结构，从图论的视角提出了RLHF中奖励泛化的问题，以解决多样的环境、低成本标注和可靠的对齐性能间的不兼容性。 |
| [^121] | [Clifford Group Equivariant Simplicial Message Passing Networks](https://arxiv.org/abs/2402.10011) | 本论文介绍了一种Clifford群等变单体消息传递网络，通过将Clifford群等变层与单体消息传递相结合，实现了在拓扑上更为复杂的E（n）-等变消息传递。实验结果表明，该方法具有良好的效果。 |
| [^122] | [Best Arm Identification for Prompt Learning under a Limited Budget](https://arxiv.org/abs/2402.09723) | 这项工作提出了一种在提示学习中考虑有限预算约束的方法，通过建立提示学习和多臂赌博机中固定预算最佳臂识别之间的联系，提出了一个通用框架TRIPLE，通过利用聚类和嵌入思想实现了两个增强方法。 |
| [^123] | [Multimodal Action Quality Assessment](https://arxiv.org/abs/2402.09444) | 该论文提出了一个名为PAMFN的渐进自适应多模态融合网络，用于多模态动作质量评估。该模型利用RGB、光流和音频信息，分别建模模态特定信息和混合模态信息，并通过充分利用音频信息，提高了评分回归的准确性。 |
| [^124] | [A Systematic Review of Data-to-Text NLG](https://arxiv.org/abs/2402.08496) | 这篇系统性回顾全面分析了数据到文本自然语言生成研究的现状，提出未来方向，并解决了相关挑战。 |
| [^125] | [Deep Reinforcement Learning for Controlled Traversing of the Attractor Landscape of Boolean Models in the Context of Cellular Reprogramming](https://arxiv.org/abs/2402.08491) | 本研究开发了一个基于深度强化学习的计算框架，用于细胞重编程中的重编程策略识别。在控制问题中，引入了伪吸引子的概念和识别方法，并设计了一个用于解决该问题的计算框架。 |
| [^126] | [ChatCell: Facilitating Single-Cell Analysis with Natural Language](https://arxiv.org/abs/2402.08303) | ChatCell是一个利用自然语言促进单细胞分析的工具，通过词汇适应和统一序列生成，它具备深厚的专业知识和适应各种分析任务的能力。 |
| [^127] | [Lissard: Long and Simple Sequential Reasoning Datasets](https://arxiv.org/abs/2402.07859) | Lissard是一个包含七个任务的基准，用于评估模型处理和生成各种序列长度的能力，需要重复的过程执行。评估结果显示随着序列复杂性增加，所有模型的性能都呈一致下降趋势。 |
| [^128] | [An Investigation into Using Unsupervised Metrics to Optimise GNNs for Node Clustering](https://arxiv.org/abs/2402.07845) | 本研究展示了使用无监督度量模块性优化GNN进行节点聚类的方法，且无需与基准值进行比较。在设计合成实验的过程中，我们发现了这种方法的局限性。 |
| [^129] | [Particle Filter SLAM for Vehicle Localization](https://arxiv.org/abs/2402.07429) | 本研究采用粒子滤波SLAM方法解决了车辆定位的挑战，利用编码数据、光纤陀螺仪和激光雷达技术实现精确的车辆运动估计和环境感知。 |
| [^130] | [News Recommendation with Attention Mechanism](https://arxiv.org/abs/2402.07422) | 本文提出了一种新的带有注意机制的新闻推荐方法NRAM，该方法可以显著提高数字新闻平台上的用户个性化新闻内容质量。 |
| [^131] | [GraphTranslator: Aligning Graph Model to Large Language Model for Open-ended Tasks](https://arxiv.org/abs/2402.07197) | "GraphTranslator"是一个旨在将预训练的图模型和大型语言模型对齐的翻译器，可以同时处理预定义任务和开放式任务。通过将这两种模型结合起来，能够有效地处理各种任务，并实现更具创新性和灵活性的应用。 |
| [^132] | [Sequential Ordering in Textual Descriptions: Impact on Spatial Perception Abilities of Large Language Models](https://arxiv.org/abs/2402.07140) | 这项研究揭示了图描述的文本顺序对大语言模型在图推理中的性能产生显著影响，并通过改变文本顺序提高了大语言模型的性能。此外，发现大语言模型的推理性能与图大小之间的关系不是单调递减的。为了评估大语言模型在不同图大小上的性能，引入了规模化图推理基准。 |
| [^133] | [Large Language Models: A Survey](https://arxiv.org/abs/2402.06196) | 大型语言模型（LLMs）吸引了很多关注，因为它们在自然语言任务上的强大表现。该研究领域发展迅速，包括了各种著名的LLMs、构建和增强LLMs的技术、以及流行的LLM数据集和评估指标。 |
| [^134] | [LESS: Selecting Influential Data for Targeted Instruction Tuning](https://arxiv.org/abs/2402.04333) | LESS是一种优化感知且实际高效的算法，用于在大型语言模型中选择具有影响力的数据以开发特定能力，它采用低秩梯度相似性搜索方法进行指令数据选择。 |
| [^135] | [A new method for optical steel rope non-destructive damage detection](https://arxiv.org/abs/2402.03843) | 本文提出了一种新的算法用于在高海拔环境中对钢丝绳进行非破坏性损伤检测，其中包括一种准确提取钢丝绳的分割模型和一种区分正常和异常钢丝绳的检测模型，实验证明其性能显著高于基准模型。 |
| [^136] | [Unified Hallucination Detection for Multimodal Large Language Models](https://arxiv.org/abs/2402.03190) | 该论文提出了一个新颖的统一的多模态幻觉检测框架UNIHD，并设计了一个评估基准方法MHaluBench来评估幻觉检测方法的进展。这项工作扩展了幻觉检测的研究范围并提供了有效的解决方案。 |
| [^137] | [Multi: Multimodal Understanding Leaderboard with Text and Images](https://arxiv.org/abs/2402.03173) | Multi是一个多模态理解的排行榜，提供了一个综合数据集，评估多模态大型语言模型对理解复杂图表和科学问题的能力。它兼具准确和开放式的回答形式，挑战MLLM的各种任务，并包含超过18,000个问题。 |
| [^138] | [Variational Flow Models: Flowing in Your Style](https://arxiv.org/abs/2402.02977) | 我们引入了一种变分流模型的方法，并提出了一种系统的无需训练的转换方法，使得快速采样成为可能，同时保持了采样的准确性和效率。 |
| [^139] | [PRewrite: Prompt Rewriting with Reinforcement Learning](https://arxiv.org/abs/2401.08189) | 本文提出了一种基于强化学习的自动化工具PRewrite，用于重写提示草案并生成高效的新提示，以解决提示工程中的挑战。 |
| [^140] | [Model Editing at Scale leads to Gradual and Catastrophic Forgetting](https://arxiv.org/abs/2401.07453) | 评估了当前模型编辑方法在规模化情况下的表现，发现随着模型被顺序编辑多个事实，它会逐渐遗忘先前的事实及执行下游任务的能力。 |
| [^141] | [EHRAgent: Code Empowers Large Language Models for Few-shot Complex Tabular Reasoning on Electronic Health Records](https://arxiv.org/abs/2401.07128) | EHRAgent是一个由代码接口赋能的大型语言模型代理，用于自主生成和执行多表格推理代码，通过错误信息学习改进生成的代码，结合长期记忆选择并建立在过去经验中的成功案例。 |
| [^142] | [Generalization in Kernel Regression Under Realistic Assumptions](https://arxiv.org/abs/2312.15995) | 本文提供了一个统一的理论，用于对几乎所有常见和现实设置下的核回归的超出风险进行上限约束，并揭示了核分解中存在的自我正则化现象。 |
| [^143] | [Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities](https://arxiv.org/abs/2312.15006) | 三种提示方法对ChatGPT的数学能力并未产生一贯性改进效果，部分方法甚至导致性能下降 |
| [^144] | [LANS: A Layout-Aware Neural Solver for Plane Geometry Problem](https://arxiv.org/abs/2311.16476) | 提出了一种名为LANS的布局感知神经求解器，集成了多模态布局感知预训练语言模块(MLA-PLM)和布局感知融合注意力(LA-FA)，有效提高了对几何图表布局信息的感知能力。 |
| [^145] | [Procedural Fairness Through Decoupling Objectionable Data Generating Components](https://arxiv.org/abs/2311.14688) | 通过解耦可抗议的数据生成组件，本研究提出了一个框架来防止伪装的程序不公平，并强调了满足程序公平要求的重要性 |
| [^146] | [Touring sampling with pushforward maps](https://arxiv.org/abs/2311.13845) | 该论文从理论角度对生成建模中的多种采样方法进行了审视和组织，帮助克服采样中的一些挑战，比如推理时间长和生成样本缺乏多样性。 |
| [^147] | [MedAgents: Large Language Models as Collaborators for Zero-shot Medical Reasoning](https://arxiv.org/abs/2311.10537) | 提出了一个新颖的医学领域的跨学科合作(MC)框架，利用基于LLM的代理在角色扮演设置中参与协作多轮讨论，从而提高LLM的熟练程度和推理能力 |
| [^148] | [Heuristic-Driven Link-of-Analogy Prompting: Enhancing Large Language Models for Document-Level Event Argument Extraction](https://arxiv.org/abs/2311.06555) | 通过启发式驱动的类比链接促进方法，该研究增强了大型语言模型用于文档级事件论证提取，使其能够从示例中学习任务特定启发式，并通过类比推理处理新情况以提高性能。 |
| [^149] | [Prompt Engineering a Prompt Engineer](https://arxiv.org/abs/2311.05661) | 提示工程任务对于优化大型语言模型在定制任务上的表现至关重要，PE2方法通过详细描述、上下文规范和逐步推理模板的注入，在各种语言任务中展现出出色的适用性和效果。 |
| [^150] | [Language Agents with Reinforcement Learning for Strategic Play in the Werewolf Game](https://arxiv.org/abs/2310.18940) | 使用强化学习为基础，提出了一种框架，用于在狼人杀游戏中开发具有灵活语言行为和强大决策能力的战略语言代理 |
| [^151] | [Acquiring Weak Annotations for Tumor Localization in Temporal and Volumetric Data](https://arxiv.org/abs/2310.15098) | 本研究提出一种名为 Drag&Drop 的新标注策略，相较于其他类型的弱标注，特别适合时间和容积成像，可简化肿瘤定位的标注过程。 |
| [^152] | [EX-FEVER: A Dataset for Multi-hop Explainable Fact Verification](https://arxiv.org/abs/2310.09754) | 提出了用于多跳可解释事实验证的开创性数据集EX-FEVER，包含超过6万个声明，每个声明都经过2跳和3跳推理，具有详细的解释路径。 |
| [^153] | [How connectivity structure shapes rich and lazy learning in neural circuits](https://arxiv.org/abs/2310.08513) | 连接结构对神经回路学习动态有关键影响，高秩初始权重通常导致惰性学习。 |
| [^154] | [SWAP: Sparse Entropic Wasserstein Regression for Robust Network Pruning](https://arxiv.org/abs/2310.04918) | 本研究提出了一种名为SWAP的网络剪枝方法，采用稀疏熵式Wasserstein回归来解决神经网络剪枝中的梯度不准确问题。SWAP在噪声抑制和协方差信息保留之间取得了平衡，具有较小的计算成本，与最先进的网络剪枝算法具有可比较的性能。 |
| [^155] | [From Text to Self: Users' Perceptions of Potential of AI on Interpersonal Communication and Self](https://arxiv.org/abs/2310.03976) | 用户对大型语言模型驱动的工具在人际交流方面的能力持积极看法，认为可以增加沟通自信、帮助表达想法以及克服语言和文化障碍，但也揭示出工具存在的一些局限性和用户关于技术不真实性和过度依赖的担忧。 |
| [^156] | [The Physics of Preference: Unravelling Imprecision of Human Preferences through Magnetisation Dynamics](https://arxiv.org/abs/2310.00267) | 通过磁化动力学原理，开发了一个模型用以紧密反映人类决策动力学，成功捕捉了个体选择中的复杂性。 |
| [^157] | [Model Stitching and Visualization How GAN Generators can Invert Networks in Real-Time](https://arxiv.org/abs/2302.02181) | 提出了一种利用GAN生成器拼接网络并实时反转的方法，在图像分类和语义分割网络中表现出与梯度下降方法相当的性能，但处理时间快两个数量级。 |
| [^158] | [Mitigating Gender Bias in Face Recognition Using the von Mises-Fisher Mixture Model](https://arxiv.org/abs/2210.13664) | 通过引入新的度量标准BFAR和BFRR，并通过后处理方法减轻面部识别中的性别偏见，以实现公平的系统性能。 |
| [^159] | [Learning in Mean Field Games: A Survey](https://arxiv.org/abs/2205.12944) | 强化学习和均场博弈的结合有望在很大规模上解决游戏的均衡和社会最优问题。 |
| [^160] | [Preemptive Motion Planning for Human-to-Robot Indirect Placement Handovers](https://arxiv.org/abs/2203.00156) | 提出了一种新颖的预测规划流程，允许机器人主动朝着人类代理的预定放置位置移动 |
| [^161] | [Representations learnt by SGD and Adaptive learning rules: Conditions that vary sparsity and selectivity in neural network](https://arxiv.org/abs/2201.11653) | 本文调查了导致神经网络稀疏性和选择性增加的各种条件。 |
| [^162] | [SelectLLM: Can LLMs Select Important Instructions to Annotate?.](http://arxiv.org/abs/2401.16553) | 这项工作提出了一种名为SelectLLM的新方法，利用LLMs选择高质量指令。通过提示LLMs估计每个无标签指令的有用性和影响力，并使用聚类算法将指令分为多个聚类。 |
| [^163] | [Scalable Link Prediction on Large-Scale Heterogeneous Graphs with Large Language Models.](http://arxiv.org/abs/2401.13227) | 本研究探索了在大规模异构图上应用大型语言模型进行图学习的方法，提出了LPNL框架用于可扩展链接预测。通过创新的提示语和采样流程，以及分而治之的策略，成功解决了大规模图中的信息过载问题，并在实验中表现出了优越的性能。 |
| [^164] | [Memory, Space, and Planning: Multiscale Predictive Representations.](http://arxiv.org/abs/2401.09491) | 本研究通过综合计算、行为和神经证据，揭示了记忆与预测、规划之间的相互关系以及其在海马体和前额叶皮质中的多尺度预测表示，为我们理解大脑中的记忆和规划机制提供了重要启示。 |
| [^165] | [Sample-and-Bound for Non-Convex Optimization.](http://arxiv.org/abs/2401.04812) | 本论文提出了一种基于采样的非凸优化方法，采用Monte Carlo Tree Search (MCTS)来提高效率，并利用数值上估计的不确定度指标和采样估计的一阶和二阶信息，避免固定组合模式的树生长，积极缩小到有希望的区域，同时平衡探索和开发。 |
| [^166] | [Agent Alignment in Evolving Social Norms.](http://arxiv.org/abs/2401.04620) | 本论文提出了一个名为EvolutionaryAgent的进化框架，将Agent对齐转化为适者生存的演化和选择过程，在不断演化的社会规范中，与当前社会规范更好适应的Agent将具有更高的生存和传播概率。 |
| [^167] | [Iterative Preference Learning from Human Feedback: Bridging Theory and Practice for RLHF under KL-Constraint.](http://arxiv.org/abs/2312.11456) | 该论文研究了在KL约束下的反馈强化学习的理论框架，并提出了有效的算法和实践。实证评估表明，该框架在大型语言模型的对齐实验中表现出良好的效果。 |
| [^168] | [LLMind: Orchestrating AI and IoT with LLMs for Complex Task Execution.](http://arxiv.org/abs/2312.09007) | LLMind是一个利用大型语言模型（LLMs）作为中央协调器的AI框架，将LLMs与领域特定的AI模块整合，使得物联网设备能够有效协同执行复杂任务。 |
| [^169] | [Privacy Issues in Large Language Models: A Survey.](http://arxiv.org/abs/2312.06717) | 这项调研关注大型语言模型中的隐私问题。主要总结了红队模型揭示隐私风险、将隐私纳入训练和推理过程、高效删除训练模型中的数据以符合隐私法规、以及减轻版权问题等技术研究。法律和政策研究虽然从不同角度解决了相关挑战，但不是本调研的重点。 |
| [^170] | [INTERVENOR: Prompt the Coding Ability of Large Language Models with the Interactive Chain of Repairing.](http://arxiv.org/abs/2311.09868) | INTERVENOR模型通过模拟人类修复代码的行为，使用交互式修复链条来引导大型语言模型的编码能力，取得了显著的性能提升。 |
| [^171] | [Vision-Language Interpreter for Robot Task Planning.](http://arxiv.org/abs/2311.00967) | 本文提出了一种名为Vision-Language Interpreter（ViLaIn）的新框架，该框架通过使用先进的语言模型和视觉语言模型生成机器人任务描述，并通过符号规划器的错误消息反馈进行改进。实验结果表明ViLaIn和符号规划器能够准确生成有效的机器人计划。 |
| [^172] | [Self-supervised Pre-training for Precipitation Post-processor.](http://arxiv.org/abs/2310.20187) | 该论文提出了一种基于深度学习的降水后处理方法，使用自监督预训练和转移学习来提高数值天气预报模型的准确性。实验结果表明该方法在区域降水校正方面表现优于其他方法。 |
| [^173] | [Interpretable Prototype-based Graph Information Bottleneck.](http://arxiv.org/abs/2310.19906) | 这项工作提出了一种新颖的可解释的GNN框架，通过在信息瓶颈框架中将原型学习与输入图的关键子图相结合，为模型的解释能力和性能提供了改进。 |
| [^174] | [ClickPrompt: CTR Models are Strong Prompt Generators for Adapting Language Models to CTR Prediction.](http://arxiv.org/abs/2310.09234) | 这篇论文提出了一个新颖的模型，旨在同时模拟语义和协同知识，以实现准确的CTR估计，并解决推理效率问题。 |
| [^175] | [Making Multimodal Generation Easier: When Diffusion Models Meet LLMs.](http://arxiv.org/abs/2310.08949) | EasyGen是一个有效的模型，它通过结合扩散模型和大型语言模型（LLMs）的能力，实现了更容易的多模态生成。相比现有的模型，EasyGen使用了一个名为BiDiffuser的双向条件扩散模型， 提供了更高效的模态交互，并且不仅能够生成文本回复，还能够促进文本到图像的生成。 |
| [^176] | [Denoising Task Routing for Diffusion Models.](http://arxiv.org/abs/2310.07138) | 本文提出了一种名为去噪任务路由的策略，通过为扩散模型的不同任务建立独立的信息路径，实现了对多任务学习的明确纳入。该方法将去噪任务的先验知识无缝集成到框架中，通过激活相似的通道和滑动窗口的方式，充分利用了相邻时间步任务间的亲和关系。 |
| [^177] | [Meta-CoT: Generalizable Chain-of-Thought Prompting in Mixed-task Scenarios with Large Language Models.](http://arxiv.org/abs/2310.06692) | Meta-CoT是一种在混合任务场景中能够通用思维链提示的方法，在十个公共基准推理任务中表现出卓越的性能和优越的泛化能力。 |
| [^178] | [A Comprehensive Evaluation of Large Language Models on Benchmark Biomedical Text Processing Tasks.](http://arxiv.org/abs/2310.04270) | 本文对大型语言模型（LLM）在生物医学任务中的性能进行了综合评估，发现零样本LLMs在小样本生物医学数据集上的表现甚至超过了先进的精调生物医学模型，预训练使LLMs在生物医学领域具备了很强的专业能力。 |
| [^179] | [SemiReward: A General Reward Model for Semi-supervised Learning.](http://arxiv.org/abs/2310.03013) | SemiReward是一个通用奖励模型，通过预测奖励分数来评估和过滤高质量的伪标签，可以应用于各种半监督学习任务，并在实验中取得了显著的成果。 |
| [^180] | [Embed-Search-Align: DNA Sequence Alignment using Transformer Models.](http://arxiv.org/abs/2309.11087) | 这项研究使用Transformer模型对DNA序列进行对齐，通过生成数值表示来实现。相比传统方法，该方法在短DNA序列的分类任务上取得了更好的性能，对于基因组学分析具有潜在的应用价值。 |
| [^181] | [Semantic Image Synthesis via Class-Adaptive Cross-Attention.](http://arxiv.org/abs/2308.16071) | 本文提出了一种基于类自适应交叉注意力的语义图像合成方法，通过使用交叉注意力层来调节图像生成，实现了优秀的视觉生成质量和编辑灵活性，并解决了全局样式不一致和局部样式编辑不真实的问题。 |
| [^182] | [Will More Expressive Graph Neural Networks do Better on Generative Tasks?.](http://arxiv.org/abs/2308.11978) | 本论文调查了更具表现力的图神经网络在分子图生成任务中的表现能力，并通过替换图生成模型的基础GNN来进行实验。研究发现，使用更具表现力的GNN可以改善生成任务的性能。 |
| [^183] | [Enumerating Safe Regions in Deep Neural Networks with Provable Probabilistic Guarantees.](http://arxiv.org/abs/2308.09842) | 通过epsilon-ProVe方法，我们提出了一种高效近似的方法来枚举深度神经网络中的安全区域，并提供了可证明概率保证的紧密下估计。 |
| [^184] | [PMET: Precise Model Editing in a Transformer.](http://arxiv.org/abs/2308.08742) | 该论文通过分析Transformer模型中的隐藏状态，发现多头自注意力编码了某些通用知识提取模式，因此在进行模型编辑时，不需要更新多头自注意力的权重。 |
| [^185] | [Improving Knowledge Extraction from LLMs for Robotic Task Learning through Agent Analysis.](http://arxiv.org/abs/2306.06770) | 本文提出了一种认知代理方法，通过增加 LLMs 的响应空间，并部署通用策略，嵌入自主机器人内部，从而使机器人能够获取与其语言能力、体现能力、环境和用户偏好相匹配的新的任务知识，实现一次学习即可完成任务。 |
| [^186] | [A Survey on Knowledge Graphs for Healthcare: Resources, Applications, and Promises.](http://arxiv.org/abs/2306.04802) | 本论文综述了医疗知识图谱(HKGs)的构建流程、关键技术和利用方法以及现有资源，并深入探讨了HKG在各种医疗领域的变革性影响。 |
| [^187] | [Rethinking Adversarial Policies: A Generalized Attack Formulation and Provable Defense in Multi-Agent RL.](http://arxiv.org/abs/2305.17342) | 本文介绍了另一种常见、现实的多智能体RL攻击设置，提出了一种模拟攻击者对代理$\alpha$控制的更一般化攻击形式。并解决了先前攻击模型中缺乏可证明防御的问题。 |
| [^188] | [Having Beer after Prayer? Measuring Cultural Bias in Large Language Models.](http://arxiv.org/abs/2305.14456) | 这篇论文研究了大型语言模型在处理和生成阿拉伯文本时出现的文化偏向西方文化的现象，表明语言模型在人名、食品、服装、地点、文学、饮料、宗教和体育等八个文化方面存在偏见。这些发现引发对于当前语言模型文化相关性的担忧。 |
| [^189] | [Surface EMG-Based Inter-Session/Inter-Subject Gesture Recognition by Leveraging Lightweight All-ConvNet and Transfer Learning.](http://arxiv.org/abs/2305.08014) | 本论文提出了一种轻量级全卷积神经网络+迁移学习方法，能够在跨场景手势识别任务中有效解决数据变异性问题。 |
| [^190] | [Can Fairness be Automated? Guidelines and Opportunities for Fairness-aware AutoML.](http://arxiv.org/abs/2303.08485) | 自动化机器学习技术（AutoML）的发展加速了机器学习模型的开发，但由于模型的决策可能会引发不公平问题，因此研究者提出了联合优化公平性和预测性能的AutoML系统，本文呼吁AutoML系统开发者应该认识到公平性处理未必是纯粹的优化问题，并提醒此类算法也具备成为公平研究工具的潜力。 |
| [^191] | [Convergence of Batch Asynchronous Stochastic Approximation With Applications to Reinforcement Learning.](http://arxiv.org/abs/2109.03445) | 本文提出了一种批量异步随机逼近算法，它可以在内存需求和时间复杂度之间进行权衡，同时提供了可以使用较弱假设证明收敛的一般方法；在强化学习领域，我们使用此方法证明了SARSA算法的批量异步版本的收敛性。 |

# 详细

[^1]: 具有必要回溯的自然反事实

    Natural Counterfactuals With Necessary Backtracking

    [https://rss.arxiv.org/abs/2402.01607](https://rss.arxiv.org/abs/2402.01607)

    本研究提出了一种自然反事实框架和方法，通过优化控制回溯的范围，生成与实际世界的数据分布相匹配的自然反事实，从而改进了反事实推理。

    

    反事实推理对于人类认知非常重要，尤其对于提供解释和做出决策至关重要。尽管Judea Pearl的研究方法在理论上很优雅，但其生成反事实情景往往需要过于脱离实际情景的干预，因此难以实施。为了解决这个问题，我们提出了一种自然反事实的框架和一种根据实际世界数据分布生成自然反事实的方法。我们的方法提供了对反事实推理的改进，允许对因果前置变量进行改变以最小化与实际情景的偏差。为了生成自然反事实，我们引入了一种创新的优化框架，通过自然性准则允许但控制回溯的范围。实证实验表明了我们方法的有效性。

    Counterfactual reasoning is pivotal in human cognition and especially important for providing explanations and making decisions. While Judea Pearl's influential approach is theoretically elegant, its generation of a counterfactual scenario often requires interventions that are too detached from the real scenarios to be feasible. In response, we propose a framework of natural counterfactuals and a method for generating counterfactuals that are natural with respect to the actual world's data distribution. Our methodology refines counterfactual reasoning, allowing changes in causally preceding variables to minimize deviations from realistic scenarios. To generate natural counterfactuals, we introduce an innovative optimization framework that permits but controls the extent of backtracking with a naturalness criterion. Empirical experiments indicate the effectiveness of our method.
    
[^2]: CounterCurate: 通过对照例子增强物理和语义视觉-语言组合推理能力

    CounterCurate: Enhancing Physical and Semantic Visio-Linguistic Compositional Reasoning via Counterfactual Examples

    [https://arxiv.org/abs/2402.13254](https://arxiv.org/abs/2402.13254)

    本研究提出CounterCurate框架，通过对比例子和生成式微调，全面提升视觉-语言组合推理能力，解决了物理推理和语义对照微调方面的关键问题，实现了显著性能改进。

    

    我们提出CounterCurate，一个框架，全面提升对比和生成式多模态模型的视觉-语言组合推理能力。特别地，我们确定了两个尚未充分探讨的关键问题：忽视了基于物理的推理（计数和位置理解），以及利用高性能文本和图像生成模型进行语义反事实微调的潜力。我们的工作开创了一个解决这些空白的方法。我们首先突出了多模态模型（如CLIP和LLaVA）在基于物理的组合推理中几乎无法胜任的表现。然后，我们应用简单的数据增强，使用基于图像的生成模型GLIGEN生成微调数据，使得性能显著提高：在我们新的策划的Flickr30k-Positions基准测试中，CLIP和LLaVA的性能分别提高了+33%和+37%。此外，我们利用了高性能文本和图像生成模型的能力。

    arXiv:2402.13254v1 Announce Type: cross  Abstract: We propose CounterCurate, a framework to comprehensively improve the visio-linguistic compositional reasoning capability for both contrastive and generative multimodal models. In particular, we identify two under-explored critical problems: the neglect of the physically grounded reasoning (counting and position understanding) and the potential of using highly capable text and image generation models for semantic counterfactual fine-tuning. Our work pioneers an approach that addresses these gaps. We first spotlight the near-chance performance of multimodal models like CLIP and LLaVA in physically grounded compositional reasoning. We then apply simple data augmentation using a grounded image generation model, GLIGEN, to generate finetuning data, resulting in significant performance improvements: +33% and +37% for CLIP and LLaVA, respectively, on our newly curated Flickr30k-Positions benchmark. Moreover, we exploit the capabilities of hig
    
[^3]: TofuEval：评估LLM在主题对话摘要中的幻觉

    TofuEval: Evaluating Hallucinations of LLMs on Topic-Focused Dialogue Summarization

    [https://arxiv.org/abs/2402.13249](https://arxiv.org/abs/2402.13249)

    论文提出了一个新的主题对话摘要评估基准TofuEval，研究发现现有的LLMs在对话领域存在大量事实错误的幻觉，并表明当LLMs充当事实评估器时，其表现不佳。

    

    单文档新闻摘要在忠实度方面取得了长足进步，这得益于对事实一致性或幻觉评估的研究。我们探讨了这些进展是否能延伸到其他文本摘要领域。我们提出了一个新的主题对话摘要评估基准，由不同规模的LLMs生成。我们提供了关于这些摘要的事实一致性的二元句级人类注释，以及对事实不一致句子的详细解释。我们的分析表明，现有的LLMs在对话领域存在大量事实错误的幻觉，无论模型大小如何。另一方面，当LLMs（包括GPT-4）充当二元事实评估器时，它们表现不佳，且可以被当前最先进的专门事实评估度量所超越。最后，我们对幻觉类型进行了分析

    arXiv:2402.13249v1 Announce Type: cross  Abstract: Single document news summarization has seen substantial progress on faithfulness in recent years, driven by research on the evaluation of factual consistency, or hallucinations. We ask whether these advances carry over to other text summarization domains. We propose a new evaluation benchmark on topic-focused dialogue summarization, generated by LLMs of varying sizes. We provide binary sentence-level human annotations of the factual consistency of these summaries along with detailed explanations of factually inconsistent sentences. Our analysis shows that existing LLMs hallucinate significant amounts of factual errors in the dialogue domain, regardless of the model's size. On the other hand, when LLMs, including GPT-4, serve as binary factual evaluators, they perform poorly and can be outperformed by prevailing state-of-the-art specialized factuality evaluation metrics. Finally, we conducted an analysis of hallucination types with a cu
    
[^4]: 来自异构数据的联邦因果发现

    Federated Causal Discovery from Heterogeneous Data

    [https://arxiv.org/abs/2402.13241](https://arxiv.org/abs/2402.13241)

    该研究提出了一种新型联邦因果发现方法，旨在适应任意因果模型和异构数据，通过使用替代变量和联邦条件独立性检验来解决数据异质性，并建立了联邦独立变化原则用于确定因果方向。

    

    传统的因果发现方法依赖于集中式数据，这与许多实际情况下数据的分散性质不一致。这种差异推动了联邦因果发现（FCD）方法的发展。然而，现有的FCD方法可能受到其对可识别功能因果模型或 homogeneous数据分布的潜在限制，从而限制了它们在各种场景中的适用性。在本文中，我们提出了一种尝试适应任意因果模型和异构数据的新型FCD方法。我们首先利用与客户端索引对应的替代变量，以解决不同客户端之间的数据异质性。然后我们开发了一个用于因果骨架发现的联邦条件独立性检验（FCIT），并建立了一个用于确定因果方向的联邦独立变化原则（FICP）。这些方法涉及构建

    arXiv:2402.13241v1 Announce Type: cross  Abstract: Conventional causal discovery methods rely on centralized data, which is inconsistent with the decentralized nature of data in many real-world situations. This discrepancy has motivated the development of federated causal discovery (FCD) approaches. However, existing FCD methods may be limited by their potentially restrictive assumptions of identifiable functional causal models or homogeneous data distributions, narrowing their applicability in diverse scenarios. In this paper, we propose a novel FCD method attempting to accommodate arbitrary causal models and heterogeneous data. We first utilize a surrogate variable corresponding to the client index to account for the data heterogeneity across different clients. We then develop a federated conditional independence test (FCIT) for causal skeleton discovery and establish a federated independent change principle (FICP) to determine causal directions. These approaches involve constructing
    
[^5]: Smaug：使用DPO-Positive修复偏好优化的失败模式

    Smaug: Fixing Failure Modes of Preference Optimisation with DPO-Positive

    [https://arxiv.org/abs/2402.13228](https://arxiv.org/abs/2402.13228)

    在这项工作中，我们提出了一种新的损失函数和训练过程DPO-Positive（DPOP），以避免直接偏好优化（DPO）中潜在的失败模式，并发现DPOP明显优于DPO。

    

    直接偏好优化（DPO）在显著改善大型语言模型（LLMs）在推理、总结和对齐等下游任务上的性能方面是有效的。 DPO使用首选和非首选数据对模型选择一个响应而不是另一个的“相对”概率进行建模。在这项工作中，我们首先从理论上表明，只要首选和非首选类别之间的相对概率增加，标准DPO损失就可能导致模型对首选示例的可能性降低。然后，我们在实证上展示了当在常见数据集上微调LLMs时，尤其是在完成之间的编辑距离较短的数据集上，会出现这种现象。利用这些见解，我们设计了DPO-Positive（DPOP），一种新的损失函数和训练过程，避免了这种失败模式。令人惊讶的是，我们还发现DPOP明显优于DPO。

    arXiv:2402.13228v1 Announce Type: cross  Abstract: Direct Preference Optimisation (DPO) is effective at significantly improving the performance of large language models (LLMs) on downstream tasks such as reasoning, summarisation, and alignment. Using pairs of preferred and dispreferred data, DPO models the \textit{relative} probability of picking one response over another. In this work, first we show theoretically that the standard DPO loss can lead to a \textit{reduction} of the model's likelihood of the preferred examples, as long as the relative probability between the preferred and dispreferred classes increases. We then show empirically that this phenomenon occurs when fine-tuning LLMs on common datasets, especially datasets in which the edit distance between pairs of completions is low. Using these insights, we design DPO-Positive (DPOP), a new loss function and training procedure which avoids this failure mode. Surprisingly, we also find that DPOP significantly outperforms DPO a
    
[^6]: NeRF解决了MRI重建中的欠采样问题

    NeRF Solves Undersampled MRI Reconstruction

    [https://arxiv.org/abs/2402.13226](https://arxiv.org/abs/2402.13226)

    NeRF技术利用神经辐射场概念解决了MRI重建中的欠采样问题，通过神经表示从欠采样的$k$-space数据中得到高维MR图像，并研究了有效的欠采样策略。

    

    本文提出了一种利用神经辐射场（NeRF）概念的新型欠采样磁共振成像（MRI）技术。通过径向欠采样，相应的成像问题可以从稀疏视图渲染数据中重塑为图像建模任务；因此，通过利用隐式神经表示，可以从欠采样的$k$-space数据中获得高维MR图像。设计了一个多层感知器，用于从空间坐标输出图像强度，该多层感知器学习了给定测量数据和期望图像之间的MR物理驱动渲染关系。研究了用于高质量神经表示的有效欠采样策略。所提出的方法具有两个优点：(i) 学习完全基于单个欠采样的$k$-space数据，而不是一堆测量数据和目标图像集。它可能用于诊断性MR成像，例如胎儿

    arXiv:2402.13226v1 Announce Type: cross  Abstract: This article presents a novel undersampled magnetic resonance imaging (MRI) technique that leverages the concept of Neural Radiance Field (NeRF). With radial undersampling, the corresponding imaging problem can be reformulated into an image modeling task from sparse-view rendered data; therefore, a high dimensional MR image is obtainable from undersampled $k$-space data by taking advantage of implicit neural representation. A multi-layer perceptron, which is designed to output an image intensity from a spatial coordinate, learns the MR physics-driven rendering relation between given measurement data and desired image. Effective undersampling strategies for high-quality neural representation are investigated. The proposed method serves two benefits: (i) The learning is based fully on single undersampled $k$-space data, not a bunch of measured data and target image sets. It can be used potentially for diagnostic MR imaging, such as fetal
    
[^7]: AgentMD：为大规模临床工具学习赋能语言代理以进行风险预测

    AgentMD: Empowering Language Agents for Risk Prediction with Large-Scale Clinical Tool Learning

    [https://arxiv.org/abs/2402.13225](https://arxiv.org/abs/2402.13225)

    AgentMD是一种新型语言代理，能够自动筛选和应用包含2,164个临床计算器的RiskCalcs集合，为克服临床工具易用性挑战和提高工作流效率提供了机会。

    

    临床计算器通过为诸如预后等各种目的提供准确的基于证据的预测，在医疗保健中发挥着至关重要的作用。然而，它们的广泛利用常常受到易用性挑战、信息传播不畅和功能受限的阻碍。将大型语言模型与广泛的临床计算器集合相结合，为克服这些障碍并提高工作流效率提供了机会，但手动筛选过程的可扩展性是一个重大挑战。为此，我们引入了AgentMD，一种能够在各种临床背景下策划和应用临床计算器的新型语言代理。AgentMD利用已发表的文献，自动筛选了一组包含2,164个多样化临床计算器的集合，具有可执行功能和结构化文档，统称为RiskCalcs。人工评估显示RiskCalcs工具达到了一定精度。

    arXiv:2402.13225v1 Announce Type: cross  Abstract: Clinical calculators play a vital role in healthcare by offering accurate evidence-based predictions for various purposes such as prognosis. Nevertheless, their widespread utilization is frequently hindered by usability challenges, poor dissemination, and restricted functionality. Augmenting large language models with extensive collections of clinical calculators presents an opportunity to overcome these obstacles and improve workflow efficiency, but the scalability of the manual curation process poses a significant challenge. In response, we introduce AgentMD, a novel language agent capable of curating and applying clinical calculators across various clinical contexts. Using the published literature, AgentMD has automatically curated a collection of 2,164 diverse clinical calculators with executable functions and structured documentation, collectively named RiskCalcs. Manual evaluations show that RiskCalcs tools achieve an accuracy of
    
[^8]: 通过用户行为建模和随机规划控制大型电动汽车充电站

    Controlling Large Electric Vehicle Charging Stations via User Behavior Modeling and Stochastic Programming

    [https://arxiv.org/abs/2402.13224](https://arxiv.org/abs/2402.13224)

    本文介绍了一个新的电动汽车充电站模型，通过用户行为建模和随机规划，解决了充电会话不确定性问题，并提出了两种方法来优化成本并提高用户满意度。

    

    本文介绍了一个电动汽车充电站（EVCS）模型，该模型融合了真实世界的约束条件，如插槽功率限制、合同阈值超限惩罚以及电动汽车（EVs）的早期断开。我们提出了一个在不确定性下控制EVCS的问题形式，并实施了两种多阶段随机规划方法，利用用户提供的信息，即模型预测控制和二阶段随机规划。该模型解决了充电会话开始和结束时间以及能量需求的不确定性。基于驻留时间依赖随机过程的用户行为模型增强了成本降低的同时保持客户满意度。通过使用真实世界数据集进行的22天模拟展示了两种提出方法相对于两个基线的优势。两阶段方法证明了针对早期断开的鲁棒性，考虑了更多

    arXiv:2402.13224v1 Announce Type: cross  Abstract: This paper introduces an Electric Vehicle Charging Station (EVCS) model that incorporates real-world constraints, such as slot power limitations, contract threshold overruns penalties, or early disconnections of electric vehicles (EVs). We propose a formulation of the problem of EVCS control under uncertainty, and implement two Multi-Stage Stochastic Programming approaches that leverage user-provided information, namely, Model Predictive Control and Two-Stage Stochastic Programming. The model addresses uncertainties in charging session start and end times, as well as in energy demand. A user's behavior model based on a sojourn-time-dependent stochastic process enhances cost reduction while maintaining customer satisfaction. The benefits of the two proposed methods are showcased against two baselines over a 22-day simulation using a real-world dataset. The two-stage approach proves robust against early disconnections, considering a more
    
[^9]: 分析操作员状态和AI增强决策支持对控制室的影响：一种人在回路中的专门强化学习框架用于干预策略

    Analyzing Operator States and the Impact of AI-Enhanced Decision Support in Control Rooms: A Human-in-the-Loop Specialized Reinforcement Learning Framework for Intervention Strategies

    [https://arxiv.org/abs/2402.13219](https://arxiv.org/abs/2402.13219)

    本研究提出了一种专门强化学习框架，集成了AI决策支持系统，旨在改善控制室操作员的工作效率和情境意识，并为其提供根据系统和人类表现状态量身定制的干预策略。

    

    在复杂的工业和化学过程控制室中，有效的决策对安全性和效率至关重要。本文中的实验评估了集成到改进的人机界面中的AI决策支持系统的影响和应用，使用动态影响图、隐马尔科夫模型和深度强化学习。增强的支持系统旨在减少操作员的工作负荷，提高情境意识，并根据系统和人类表现的当前状态为操作员提供不同的干预策略。这样的系统在信息过载的情况下特别有用，当许多警报和输入同时呈现在同一个时间窗口内，或者在培训期间对初级操作员来说尤其有用。进行了广泛的交叉数据分析，涉及47名参与者和各种数据来源，如智能手表指标、眼动数据等。

    arXiv:2402.13219v1 Announce Type: new  Abstract: In complex industrial and chemical process control rooms, effective decision-making is crucial for safety and effi- ciency. The experiments in this paper evaluate the impact and applications of an AI-based decision support system integrated into an improved human-machine interface, using dynamic influ- ence diagrams, a hidden Markov model, and deep reinforcement learning. The enhanced support system aims to reduce operator workload, improve situational awareness, and provide different intervention strategies to the operator adapted to the current state of both the system and human performance. Such a system can be particularly useful in cases of information overload when many alarms and inputs are presented all within the same time window, or for junior operators during training. A comprehensive cross-data analysis was conducted, involving 47 participants and a diverse range of data sources such as smartwatch metrics, eye- tracking data,
    
[^10]: VideoPrism: 用于视频理解的基础视觉编码器

    VideoPrism: A Foundational Visual Encoder for Video Understanding

    [https://arxiv.org/abs/2402.13217](https://arxiv.org/abs/2402.13217)

    VideoPrism是一个通用的视频编码器，通过全局-局部语义视频嵌入的蒸馏和标记混洗方案，在多个视频理解任务上取得了最新技术水平的表现。

    

    我们引入了VideoPrism，一个通用的视频编码器，使用单个冻结模型处理多样的视频理解任务。我们在包含3600万高质量视频标题对和58.2亿个带有嘈杂平行文本（如ASR转录）的视频剪辑的异构语料库上对VideoPrism进行预训练。预训练方法通过全局-局部语义视频嵌入的蒸馏和一个标记混洗方案改进了掩码自编码，使VideoPrism能够主要专注于视频模态同时利用与视频相关联的宝贵文本。我们在四个广泛的视频理解任务组上进行了对VideoPrism的广泛测试，从网络视频问答到科学CV， 在33个视频理解基准测试中的30个上实现了最新技术水平的性能。

    arXiv:2402.13217v1 Announce Type: cross  Abstract: We introduce VideoPrism, a general-purpose video encoder that tackles diverse video understanding tasks with a single frozen model. We pretrain VideoPrism on a heterogeneous corpus containing 36M high-quality video-caption pairs and 582M video clips with noisy parallel text (e.g., ASR transcripts). The pretraining approach improves upon masked autoencoding by global-local distillation of semantic video embeddings and a token shuffling scheme, enabling VideoPrism to focus primarily on the video modality while leveraging the invaluable text associated with videos. We extensively test VideoPrism on four broad groups of video understanding tasks, from web video question answering to CV for science, achieving state-of-the-art performance on 30 out of 33 video understanding benchmarks.
    
[^11]: 软最大概率（大部分时候）在多项选择问答任务中预测大型语言模型的正确性

    Softmax Probabilities (Mostly) Predict Large Language Model Correctness on Multiple-Choice Q&A

    [https://arxiv.org/abs/2402.13213](https://arxiv.org/abs/2402.13213)

    多项选择问答任务中，基于最大softmax概率（MSPs）的模型预测方法有助于提高大型语言模型（LLMs）的正确性，我们提出了一种根据MSP有选择地弃权的策略以提高性能。

    

    尽管大型语言模型（LLMs）在许多任务上表现出色，但过度自信仍然是一个问题。我们假设在多项选择问答任务中，错误答案将与最大softmax概率（MSPs）较小相关，相比之下正确答案较大。我们在十个开源LLMs和五个数据集上全面评估了这一假设，在表现良好的原始问答任务中发现了对我们假设的强有力证据。对于表现最佳的六个LLMs，从MSP导出的AUROC在59/60个实例中都优于随机机会，p < 10^{-4}。在这六个LLMs中，平均AUROC范围在60%至69%之间。利用这些发现，我们提出了一个带有弃权选项的多项选择问答任务，并展示通过根据初始模型响应的MSP有选择地弃权可以提高性能。我们还用预softmax logits而不是softmax进行了相同的实验。

    arXiv:2402.13213v1 Announce Type: cross  Abstract: Although large language models (LLMs) perform impressively on many tasks, overconfidence remains a problem. We hypothesized that on multiple-choice Q&A tasks, wrong answers would be associated with smaller maximum softmax probabilities (MSPs) compared to correct answers. We comprehensively evaluate this hypothesis on ten open-source LLMs and five datasets, and find strong evidence for our hypothesis among models which perform well on the original Q&A task. For the six LLMs with the best Q&A performance, the AUROC derived from the MSP was better than random chance with p < 10^{-4} in 59/60 instances. Among those six LLMs, the average AUROC ranged from 60% to 69%. Leveraging these findings, we propose a multiple-choice Q&A task with an option to abstain and show that performance can be improved by selectively abstaining based on the MSP of the initial model response. We also run the same experiments with pre-softmax logits instead of sof
    
[^12]: 软自一致性改善语言模型代理

    Soft Self-Consistency Improves Language Model Agents

    [https://arxiv.org/abs/2402.13212](https://arxiv.org/abs/2402.13212)

    Soft Self-Consistency (Soft-SC)通过软化评分标准替代自一致性的多数投票方法，提高了在涉及生成多个动作的长期互动任务中的性能和效率

    

    大型语言模型（LLMs）生成可以通过对多个解决方案进行抽样和评分来改进，以选择最终答案。当前的“抽样和选择”方法如自一致性（SC）依赖于多数投票来评分答案。然而，当任务有许多不同且有效的答案时，通过投票进行选择需要大量样本。这使得SC在涉及顺序生成多个动作（答案）的互动任务时成本过高。在确定大多数投票未能为此类任务提供一致的收益之后，我们展示了如何通过软化评分标准来提高成功率。我们引入了软自一致性（Soft-SC），它用模型可能性计算连续分数来取代SC的不连续评分，即使动作分布稀疏，也允许选择。软自一致性在长期互动任务上提高了性能和效率，需要较少的样本和投票。

    arXiv:2402.13212v1 Announce Type: cross  Abstract: Generations from large language models (LLMs) can be improved by sampling and scoring multiple solutions to select a final answer. Current "sample and select" methods such as self-consistency (SC) rely on majority voting to score answers. However, when tasks have many distinct and valid answers, selection by voting requires a large number of samples. This makes SC prohibitively expensive for interactive tasks that involve generating multiple actions (answers) sequentially. After establishing that majority voting fails to provide consistent gains on such tasks, we demonstrate how to increase success rates by softening the scoring criterion. We introduce Soft Self-Consistency (Soft-SC), which replaces SC's discontinuous scoring with a continuous score computed from model likelihoods, allowing for selection even when actions are sparsely distributed. Soft-SC improves both performance and efficiency on long-horizon interactive tasks, requi
    
[^13]: 出于性能考虑，Hyena如何处理人类语音？使用ConfHyena进行语音识别和翻译

    How do Hyenas deal with Human Speech? Speech Recognition and Translation with ConfHyena

    [https://arxiv.org/abs/2402.13208](https://arxiv.org/abs/2402.13208)

    ConfHyena是一种基于Hyena的改进模型，通过在处理语音时减少计算成本，显著缩短了训练时间。

    

    注意机制是现代神经模型的基石，但由于其二次复杂度而在处理长序列时面临计算障碍。因此，过去几年的研究工作侧重于寻找更有效的替代方案。其中，Hyena（Poli等，2023年）在语言建模和图像分类方面取得了竞争性结果，同时提供次线性的存储和计算复杂度。基于这些有希望的结果，我们提出了ConfHyena，这是一个Conformer，其编码器的自注意力被Hyena的一种变体取代，用于处理语音，其中长输入序列导致高计算成本。通过自动语音识别（英语）和翻译实验（从英语翻译成8种目标语言），我们展示了我们最好的ConfHyena模型将训练时间显著减少了27%，而品质损失仅为1%。

    arXiv:2402.13208v1 Announce Type: cross  Abstract: The attention mechanism, a cornerstone of state-of-the-art neural models, faces computational hurdles in processing long sequences due to its quadratic complexity. Consequently, research efforts in the last few years focused on finding more efficient alternatives. Among them, Hyena (Poli et al., 2023) stands out for achieving competitive results in both language modeling and image classification, while offering sub-quadratic memory and computational complexity. Building on these promising results, we propose ConfHyena, a Conformer whose encoder self-attentions are replaced with an adaptation of Hyena for speech processing, where the long input sequences cause high computational costs. Through experiments in automatic speech recognition (for English) and translation (from English into 8 target languages), we show that our best ConfHyena model significantly reduces the training time by 27%, at the cost of minimal quality degradation (~1%
    
[^14]: 使用决策变换器进行四足动作的小型强化学习

    Tiny Reinforcement Learning for Quadruped Locomotion using Decision Transformers

    [https://arxiv.org/abs/2402.13201](https://arxiv.org/abs/2402.13201)

    将模仿学习问题视为条件序列建模任务，通过训练决策变换器并使用奖励机制，将生成模型压缩以适应资源受限的机器人平台。

    

    arXiv:2402.13201v1 公告类型：跨领域 摘要：受资源限制的机器人平台特别适用于需要低成本硬件替代方案的任务，因为存在失去机器人的风险，比如在搜救应用中，或者需要大量设备，比如在群体机器人技术中。因此，关键在于找到机制，使强化学习技术适应这些超低成本机器人平台的低计算能力和较小内存容量所施加的约束。我们试图通过提出一种方法，将模仿学习部署到受资源限制的机器人平台上来满足这种需求。在这里，我们将模仿学习问题视为条件序列建模任务，通过使用附加了自定义奖励的专家演示来训练决策变换器。然后，我们使用软件优化方案，包括量化和修剪，来压缩生成的模型。我们在...

    arXiv:2402.13201v1 Announce Type: cross  Abstract: Resource-constrained robotic platforms are particularly useful for tasks that require low-cost hardware alternatives due to the risk of losing the robot, like in search-and-rescue applications, or the need for a large number of devices, like in swarm robotics. For this reason, it is crucial to find mechanisms for adapting reinforcement learning techniques to the constraints imposed by lower computational power and smaller memory capacities of these ultra low-cost robotic platforms. We try to address this need by proposing a method for making imitation learning deployable onto resource-constrained robotic platforms. Here we cast the imitation learning problem as a conditional sequence modeling task and we train a decision transformer using expert demonstrations augmented with a custom reward. Then, we compress the resulting generative model using software optimization schemes, including quantization and pruning. We test our method in si
    
[^15]: 用于医学领域的检索增强生成的基准测试

    Benchmarking Retrieval-Augmented Generation for Medicine

    [https://arxiv.org/abs/2402.13178](https://arxiv.org/abs/2402.13178)

    通过提出首个医学信息检索增强生成评估(MIRAGE)基准测试，并使用MedRAG工具包进行大规模实验，实现了对多个大型语言模型的准确性改进。

    

    大型语言模型(LLMs)在广泛的医学问答任务上取得了最先进的性能，但仍然面临幻觉和过时知识的挑战。检索增强生成(RAG)是一个有前途的解决方案，并得到了广泛采用。然而，RAG系统可能涉及多个灵活的组件，并且缺乏关于各种医学目的的最佳RAG设置的最佳实践。为了系统地评估这些系统，我们提出了医学信息检索增强生成评估(MIRAGE)，这是一个首创的基准测试，包括来自五个医学问答数据集的7,663个问题。利用MIRAGE，我们通过本文介绍的MedRAG工具包，在41种不同语料库、检索器和骨干LLMs的组合上进行了超过1.8万亿的提示标记的大规模实验。总体而言，MedRAG提高了六种不同LLMs的准确性。

    arXiv:2402.13178v1 Announce Type: cross  Abstract: While large language models (LLMs) have achieved state-of-the-art performance on a wide range of medical question answering (QA) tasks, they still face challenges with hallucinations and outdated knowledge. Retrieval-augmented generation (RAG) is a promising solution and has been widely adopted. However, a RAG system can involve multiple flexible components, and there is a lack of best practices regarding the optimal RAG setting for various medical purposes. To systematically evaluate such systems, we propose the Medical Information Retrieval-Augmented Generation Evaluation (MIRAGE), a first-of-its-kind benchmark including 7,663 questions from five medical QA datasets. Using MIRAGE, we conducted large-scale experiments with over 1.8 trillion prompt tokens on 41 combinations of different corpora, retrievers, and backbone LLMs through the MedRAG toolkit introduced in this work. Overall, MedRAG improves the accuracy of six different LLMs 
    
[^16]: SubIQ: 逆向软 Q 学习用于获得次优演示的离线模仿

    SubIQ: Inverse Soft-Q Learning for Offline Imitation with Suboptimal Demonstrations

    [https://arxiv.org/abs/2402.13147](https://arxiv.org/abs/2402.13147)

    逆向软 Q 学习用于获得次优演示的离线模仿挑战了离线 IL 中有限支持专家演示的问题，并提出了一种解决方案以匹配次优演示集合的占用分布

    

    我们考虑了离线模仿学习（IL），旨在从专家演示中模仿专家的行为，而无需与环境进行进一步交互。在离线 IL 中的一个主要挑战是处理仅涵盖状态-动作空间的一小部分的专家演示的有限支持。我们考虑离线 IL，其中专家演示受到限制，但是由更大规模的次优演示集合补充。大部分现有的用于此设置的离线 IL 方法基于行为克隆或分布匹配，其目的是将模仿策略的占用分布与专家策略的占用分布匹配。这种方法往往存在过拟合问题，因为专家演示有限，无法准确表示任何占用分布。另一方面，由于次优演示集合规模更大，有很高的可能性

    arXiv:2402.13147v1 Announce Type: cross  Abstract: We consider offline imitation learning (IL), which aims to mimic the expert's behavior from its demonstration without further interaction with the environment. One of the main challenges in offline IL is dealing with the limited support of expert demonstrations that cover only a small fraction of the state-action spaces. In this work, we consider offline IL, where expert demonstrations are limited but complemented by a larger set of sub-optimal demonstrations of lower expertise levels. Most of the existing offline IL methods developed for this setting are based on behavior cloning or distribution matching, where the aim is to match the occupancy distribution of the imitation policy with that of the expert policy. Such an approach often suffers from over-fitting, as expert demonstrations are limited to accurately represent any occupancy distribution. On the other hand, since sub-optimal sets are much larger, there is a high chance that 
    
[^17]: CMDAG: 一个带有注释的中文隐喻数据集作为“CoT”来提升隐喻生成

    CMDAG: A Chinese Metaphor Dataset with Annotated Grounds as CoT for Boosting Metaphor Generation

    [https://arxiv.org/abs/2402.13145](https://arxiv.org/abs/2402.13145)

    本文介绍了一个大规模高质量的带注释中文隐喻语料库，强调隐喻生成中的基础及其独特特征，而非传统的对象和载体组合。

    

    隐喻是人类语言和文学中显著的修辞手法，因为它们增添了色彩、形象和强调，以增强有效交流。本文介绍了一个大规模高质量的带注释中文隐喻语料库，包括约28K句来自各种中文文学来源（如诗歌、散文、歌词等）。为确保注释的准确性和一致性，我们提出了一套全面的指南。这些指南涵盖了隐喻标注的方面，包括识别对象、载体和基础，以处理比喻、拟人、并列和夸张等复杂性。打破传统，我们的隐喻生成方法强调基础及其独特特征，而不是传统的对象和载体组合。通过将“基础”作为“CoT”（思维链）输入进行整合，我们能够生成重新

    arXiv:2402.13145v1 Announce Type: cross  Abstract: Metaphor is a prominent linguistic device in human language and literature, as they add color, imagery, and emphasis to enhance effective communication. This paper introduces a large-scale high quality annotated Chinese Metaphor Corpus, which comprises around 28K sentences drawn from a diverse range of Chinese literary sources, such as poems, prose, song lyrics, etc. To ensure the accuracy and consistency of our annotations, we introduce a comprehensive set of guidelines. These guidelines address the facets of metaphor annotation, including identifying tenors, vehicles, and grounds to handling the complexities of similes, personifications, juxtapositions, and hyperboles. Breaking tradition, our approach to metaphor generation emphasizes grounds and their distinct features rather than the conventional combination of tenors and vehicles. By integrating "ground" as a CoT (Chain of Thoughts) input, we are able to generate metaphors that re
    
[^18]: VGMShield：缓解视频生成模型的误用

    VGMShield: Mitigating Misuse of Video Generative Models

    [https://arxiv.org/abs/2402.13126](https://arxiv.org/abs/2402.13126)

    VGMShield提出了三项简单但开创性的措施，通过检测虚假视频、溯源问题和利用预训练的空间-时间动态模型，防范视频生成模型的误用。

    

    随着视频生成技术的快速发展，人们可以方便地利用视频生成模型创建符合其特定需求的视频。然而，人们也越来越担心这些技术被用于创作和传播虚假信息。在这项工作中，我们介绍了VGMShield：一套包含三项直接但开创性的措施，用于防范虚假视频生成过程中可能出现的问题。我们首先从“虚假视频检测”开始，尝试理解生成的视频中是否存在独特性，以及我们是否能够区分它们与真实视频的不同；然后，我们探讨“溯源”问题，即将一段虚假视频追溯回生成它的模型。为此，我们提出利用预训练的关注“时空动态”的模型作为骨干，以识别视频中的不一致性。通过对七个最先进的开源模型进行实验，我们证明了...

    arXiv:2402.13126v1 Announce Type: cross  Abstract: With the rapid advancement in video generation, people can conveniently utilize video generation models to create videos tailored to their specific desires. Nevertheless, there are also growing concerns about their potential misuse in creating and disseminating false information.   In this work, we introduce VGMShield: a set of three straightforward but pioneering mitigations through the lifecycle of fake video generation. We start from \textit{fake video detection} trying to understand whether there is uniqueness in generated videos and whether we can differentiate them from real videos; then, we investigate the \textit{tracing} problem, which maps a fake video back to a model that generates it. Towards these, we propose to leverage pre-trained models that focus on {\it spatial-temporal dynamics} as the backbone to identify inconsistencies in videos. Through experiments on seven state-of-the-art open-source models, we demonstrate that
    
[^19]: TreeEval：通过树规划实现对大型语言模型的无基准评估

    TreeEval: Benchmark-Free Evaluation of Large Language Models through Tree Planning

    [https://arxiv.org/abs/2402.13125](https://arxiv.org/abs/2402.13125)

    TreeEval提出了一种无基准评估方法，通过树规划策略提升了大型语言模型的评估效率和完整性

    

    最近，建立了许多新的基准来评估大型语言模型（LLMs）的性能，通过计算整体得分或使用另一个LLM作为评判者。然而，这些方法由于基准的公开访问和评估过程的不灵活而遭受数据泄漏的困扰。为了解决这个问题，我们引入了TreeEval，这是一种无基准评估方法，让一个高性能的LLM主持一个不可重现的评估会话，从根本上避免了数据泄漏。此外，这个LLM充当一个考官，提出一系列关于一个主题的问题，并采用树规划策略，考虑当前的评估状态来决定下一个问题的生成，确保评估过程的完整性和效率。我们评估了不同参数大小的6个模型，包括7B、13B和33B，最终实现了最高的相关系数。

    arXiv:2402.13125v1 Announce Type: cross  Abstract: Recently, numerous new benchmarks have been established to evaluate the performance of large language models (LLMs) via either computing a holistic score or employing another LLM as a judge. However, these approaches suffer from data leakage due to the open access of the benchmark and inflexible evaluation process. To address this issue, we introduce $\textbf{TreeEval}$, a benchmark-free evaluation method for LLMs that let a high-performance LLM host an irreproducible evaluation session and essentially avoids the data leakage. Moreover, this LLM performs as an examiner to raise up a series of questions under a topic with a tree planing strategy, which considers the current evaluation status to decide the next question generation and ensures the completeness and efficiency of the evaluation process. We evaluate $6$ models of different parameter sizes, including $7$B, $13$B, and $33$B, and ultimately achieved the highest correlation coef
    
[^20]: BuffGraph: 通过缓冲节点增强节点分类的不平衡类别问题

    BuffGraph: Enhancing Class-Imbalanced Node Classification via Buffer Nodes

    [https://arxiv.org/abs/2402.13114](https://arxiv.org/abs/2402.13114)

    BuffGraph通过插入缓冲节点到图中，调节主要类别的影响，以改善次要类别的表示，在类别不平衡的节点分类问题上表现优越。

    

    图结构数据中的类别不平衡，即次要类别明显代表不足，对图神经网络（GNNs）构成了重大挑战。为了应对这一挑战，现有研究通常生成新的少数节点，并连接新节点到原始图中，使得类别平衡。然而，它们并未解决主要类别通过原始图中的边向次要节点传播信息的问题，从而引入了对主要类别的偏见。为了解决这个问题，我们引入了BuffGraph，将缓冲节点插入图中，调节主要类别的影响，以改善次要类别的表示。我们在各种真实世界数据集上进行了大量实验证明，BuffGraph在自然设置和不平衡设置中的类别不平衡节点分类中优于现有基线方法。代码可在https://anonymous.4open.scien获得。

    arXiv:2402.13114v1 Announce Type: cross  Abstract: Class imbalance in graph-structured data, where minor classes are significantly underrepresented, poses a critical challenge for Graph Neural Networks (GNNs). To address this challenge, existing studies generally generate new minority nodes and edges connecting new nodes to the original graph to make classes balanced. However, they do not solve the problem that majority classes still propagate information to minority nodes by edges in the original graph which introduces bias towards majority classes. To address this, we introduce BuffGraph, which inserts buffer nodes into the graph, modulating the impact of majority classes to improve minor class representation. Our extensive experiments across diverse real-world datasets empirically demonstrate that BuffGraph outperforms existing baseline methods in class-imbalanced node classification in both natural settings and imbalanced settings. Code is available at https://anonymous.4open.scien
    
[^21]: CIF-Bench：用于评估大型语言模型泛化能力的中文指令遵循基准

    CIF-Bench: A Chinese Instruction-Following Benchmark for Evaluating the Generalizability of Large Language Models

    [https://arxiv.org/abs/2402.13109](https://arxiv.org/abs/2402.13109)

    CIF-Bench是一个用于评估大型语言模型在中文语言上零样本泛化能力的基准，通过多样化的指令和数据集划分来减少评估偏见。

    

    大型语言模型（LLMs）的进步增强了通过指令遵循在广泛范围的未见自然语言处理（NLP）任务上的泛化能力。然而，它们在如中文这样的低资源语言中的有效性常常会减弱，受到数据泄漏引起的偏见评估的影响，这使人对它们真正的泛化能力到新语言领域产生了怀疑。为了应对这一问题，我们引入了中文指令遵循基准（CIF-Bench），旨在评估LLMs对中文语言的零样本泛化能力。CIF-Bench 包含150个任务和15,000个输入输出对，由母语者开发，用于测试跨越20个类别的复杂推理和中国文化细微差别。为了减少评估偏见，我们只公开了数据集的一半，其余部分保持私密，并引入多样化的指令以最小化得分方差，共计45,000个数据实例。

    arXiv:2402.13109v1 Announce Type: cross  Abstract: The advancement of large language models (LLMs) has enhanced the ability to generalize across a wide range of unseen natural language processing (NLP) tasks through instruction-following. Yet, their effectiveness often diminishes in low-resource languages like Chinese, exacerbated by biased evaluations from data leakage, casting doubt on their true generalizability to new linguistic territories. In response, we introduce the Chinese Instruction-Following Benchmark (CIF-Bench), designed to evaluate the zero-shot generalizability of LLMs to the Chinese language. CIF-Bench comprises 150 tasks and 15,000 input-output pairs, developed by native speakers to test complex reasoning and Chinese cultural nuances across 20 categories. To mitigate evaluation bias, we release only half of the dataset publicly, with the remainder kept private, and introduce diversified instructions to minimize score variance, totaling 45,000 data instances. Our eval
    
[^22]: ELAD: 解释引导的大型语言模型主动蒸馏

    ELAD: Explanation-Guided Large Language Models Active Distillation

    [https://arxiv.org/abs/2402.13098](https://arxiv.org/abs/2402.13098)

    ELAD提出了一种Explanation-Guided LLMs Active Distillation框架，通过主动学习策略优化注释成本和模型性能之间的平衡，并引入了基于解释的样本选择方法和LLM-注释解释修订技术。

    

    大型语言模型（LLMs）的部署和应用受到它们的内存效率、计算要求和高成本的API推断的阻碍。传统的蒸馏方法往往未能确定知识是否已经被充分转移，可能导致高成本或不完整的蒸馏。本文提出了一种名为Explanation-Guided LLMs Active Distillation（ELAD）框架，采用主动学习策略来优化注释成本和模型性能之间的平衡。为了改进有效的样本选择，我们引入了一种基于解释的样本选择方法，通过利用解释步骤中的不确定性来识别挑战其推理的样本。此外，我们提出了一种定制的LLM-注释解释修订技术，其中教师模型检测并纠正学生模型中的缺陷。

    arXiv:2402.13098v1 Announce Type: cross  Abstract: The deployment and application of Large Language Models (LLMs) is hindered by their memory inefficiency, computational demands, and the high costs of API inferences. Traditional distillation methods, which transfer the capabilities of LLMs to smaller models, often fail to determine whether the knowledge has been sufficiently transferred, potentially resulting in high costs or incomplete distillation. In this paper, we propose an Explanation-Guided LLMs Active Distillation (ELAD) framework that employs an active learning strategy to optimize the balance between annotation costs and model performance. To improve efficient sample selection, we introduce an explanation-guided sample selection method that identifies samples challenging its reasoning by exploiting uncertainties in explanation steps. Additionally, we present a customized LLM-annotated explanation revision technique where the teacher model detects and corrects flaws in the stu
    
[^23]: 事件级知识编辑

    Event-level Knowledge Editing

    [https://arxiv.org/abs/2402.13093](https://arxiv.org/abs/2402.13093)

    提出了一个新的任务设置：事件级知识编辑，通过直接编辑新事件到LLMs中，在效率和完整性上改进了传统的三元组级别编辑。

    

    知识编辑旨在更新大型语言模型（LLMs）的知识，以防止它们过时。现有研究在事实知识三元组的级别上编辑LLMs。然而，现实世界中的自然知识更新来自新事件的发生，而不是直接更改事实三元组。本文提出了一个新的任务设置：事件级知识编辑，直接将新事件编辑到LLMs中，并在效率和完整性上改进了传统的三元组级别编辑。(1)效率。单个事件编辑会导致多个推断知识三元组的更新。(2)完整性。除了更新事实知识外，事件级别的编辑还需要考虑事件影响，更新LLMs关于未来趋势的知识。我们构建了一个高质量的事件级别编辑基准ELKEN，包括1,515个事件编辑，6,449个关于事实知识的问题和10,150个关于未来发展趋势的问题。

    arXiv:2402.13093v1 Announce Type: cross  Abstract: Knowledge editing aims at updating knowledge of large language models (LLMs) to prevent them from becoming outdated. Existing work edits LLMs at the level of factual knowledge triplets. However, natural knowledge updates in the real world come from the occurrences of new events rather than direct changes in factual triplets. In this paper, we propose a new task setting: event-level knowledge editing, which directly edits new events into LLMs and improves over conventional triplet-level editing on (1) Efficiency. A single event edit leads to updates in multiple entailed knowledge triplets. (2) Completeness. Beyond updating factual knowledge, event-level editing also requires considering the event influences and updating LLMs' knowledge about future trends. We construct a high-quality event-level editing benchmark ELKEN, consisting of 1,515 event edits, 6,449 questions about factual knowledge, and 10,150 questions about future tendencies
    
[^24]: 朝向对MoE设计选择的实证理解

    Towards an empirical understanding of MoE design choices

    [https://arxiv.org/abs/2402.13089](https://arxiv.org/abs/2402.13089)

    本研究系统评估了Mixture of Experts（MoEs）中常见设计选择对验证性能的影响，揭示了路由器的学习与初始化对模型性能的比较、序列级路由与标记级路由在专家专业化方面的不同影响。

    

    在这项研究中，我们系统地评估了Mixture of Experts（MoEs）中常见设计选择对验证性能的影响，揭示了在标记和序列级别上的不同影响。我们还提供经验证据表明，在学习路由器和冻结的随机初始化路由器之间具有可比性的性能，这表明学习路由可能并非必不可少。我们的研究进一步揭示了序列级路由可能导致特定主题的弱专家专业化，与标记级别路由观察到的语法专业化形成对比。

    arXiv:2402.13089v1 Announce Type: cross  Abstract: In this study, we systematically evaluate the impact of common design choices in Mixture of Experts (MoEs) on validation performance, uncovering distinct influences at token and sequence levels. We also present empirical evidence showing comparable performance between a learned router and a frozen, randomly initialized router, suggesting that learned routing may not be essential. Our study further reveals that Sequence-level routing can result in topic-specific weak expert specialization, in contrast to syntax specialization observed with Token-level routing.
    
[^25]: 用于科学机器学习的机制神经网络

    Mechanistic Neural Networks for Scientific Machine Learning

    [https://arxiv.org/abs/2402.13077](https://arxiv.org/abs/2402.13077)

    本文提出了一种名为机制神经网络的神经网络设计，通过在标准架构中引入新的机制模块，学习控制微分方程作为表示，提高数据建模的可解释性和效率，并借助一种新颖的松弛线性规划求解器实现可扩展的GPU并行处理。

    

    本文提出了一种名为机制神经网络的神经网络设计，用于科学机器学习应用。它在标准架构中引入了一个新的机制模块，明确地学习控制微分方程作为表示，揭示数据的基本动态，并增强了数据建模中的可解释性和效率。我们方法的核心是一种新颖的松弛线性规划求解器（NeuRLP），受一种将求解线性ODE转化为求解线性规划的技术启发。它与神经网络很好地集成，并超越了传统ODE求解器的局限，实现了可扩展的GPU并行处理。总体而言，机制神经网络展示了它们在科学机器学习应用中的多才多艺，能够灵活处理从方程发现到动态系统建模的任务。我们证明了它们在分析和解释复杂科学问题方面的全面能力。

    arXiv:2402.13077v1 Announce Type: cross  Abstract: This paper presents Mechanistic Neural Networks, a neural network design for machine learning applications in the sciences. It incorporates a new Mechanistic Block in standard architectures to explicitly learn governing differential equations as representations, revealing the underlying dynamics of data and enhancing interpretability and efficiency in data modeling. Central to our approach is a novel Relaxed Linear Programming Solver (NeuRLP) inspired by a technique that reduces solving linear ODEs to solving linear programs. This integrates well with neural networks and surpasses the limitations of traditional ODE solvers enabling scalable GPU parallel processing. Overall, Mechanistic Neural Networks demonstrate their versatility for scientific machine learning applications, adeptly managing tasks from equation discovery to dynamic systems modeling. We prove their comprehensive capabilities in analyzing and interpreting complex scient
    
[^26]: 随机图集和证据模式推理模型

    Random Graph Set and Evidence Pattern Reasoning Model

    [https://arxiv.org/abs/2402.13058](https://arxiv.org/abs/2402.13058)

    提出了证据模式推理模型（EPRM）以更好地符合决策目标，引入随机图集（RGS）来模拟复杂关系并表示更多事件类型。

    

    证据理论在决策和推理系统中被广泛使用。以往的研究中，转移信念模型（TBM）是常用的证据决策模型，但TBM是一个非偏好模型。为了更好地符合决策目标，提出了证据模式推理模型（EPRM）。通过定义模式运算符和决策运算符，可以为不同任务设置相应的偏好。随机排列集（RPS）为证据理论扩展了顺序信息。RPS很难刻画样本之间的复杂关系，如循环、并行关系。因此，提出了随机图集（RGS）来模拟复杂关系并表示更多事件类型。为了说明RGS和EPRM的重要性，设计了一项飞机速度排序实验，并模拟了10,000个案例。EPRM的实现称为冲突解决Dec

    arXiv:2402.13058v1 Announce Type: new  Abstract: Evidence theory is widely used in decision-making and reasoning systems. In previous research, Transferable Belief Model (TBM) is a commonly used evidential decision making model, but TBM is a non-preference model. In order to better fit the decision making goals, the Evidence Pattern Reasoning Model (EPRM) is proposed. By defining pattern operators and decision making operators, corresponding preferences can be set for different tasks. Random Permutation Set (RPS) expands order information for evidence theory. It is hard for RPS to characterize the complex relationship between samples such as cycling, paralleling relationships. Therefore, Random Graph Set (RGS) were proposed to model complex relationships and represent more event types. In order to illustrate the significance of RGS and EPRM, an experiment of aircraft velocity ranking was designed and 10,000 cases were simulated. The implementation of EPRM called Conflict Resolution Dec
    
[^27]: 识别语义感应头以理解上下文学习

    Identifying Semantic Induction Heads to Understand In-Context Learning

    [https://arxiv.org/abs/2402.13055](https://arxiv.org/abs/2402.13055)

    该研究通过分析注意力头的操作，揭示了结合了句法依赖和知识图关系的语义感应头的出现，从而更好地理解了大型语言模型的上下文学习能力。

    

    虽然大型语言模型(LLMs)已经展示出卓越的性能，但它们推理逻辑的不透明性引发了对其可靠性的担忧。为了更好地理解LLMs，我们对注意力头的操作进行了详细分析，并旨在更好地理解LLMs的上下文学习。具体而言，我们研究了注意力头是否编码了自然语言中存在的两种类型的关系：从句子中解析的句法依赖和知识图中的关系。我们发现某些注意力头表现出一种模式，即当关注头标记时，它们会回忆起尾标记，并增加这些尾标记的输出逻辑。更重要的是，这种语义感应头的制定与语言模型上下文学习能力的出现存在密切关联。语义注意力头的研究推动了我们的

    arXiv:2402.13055v1 Announce Type: cross  Abstract: Although large language models (LLMs) have demonstrated remarkable performance, the lack of transparency in their inference logic raises concerns about their trustworthiness. To gain a better understanding of LLMs, we conduct a detailed analysis of the operations of attention heads and aim to better understand the in-context learning of LLMs. Specifically, we investigate whether attention heads encode two types of relationships between tokens present in natural languages: the syntactic dependency parsed from sentences and the relation within knowledge graphs. We find that certain attention heads exhibit a pattern where, when attending to head tokens, they recall tail tokens and increase the output logits of those tail tokens. More crucially, the formulation of such semantic induction heads has a close correlation with the emergence of the in-context learning ability of language models. The study of semantic attention heads advances our
    
[^28]: 用扩散语言模型进行文本引导的分子生成

    Text-Guided Molecule Generation with Diffusion Language Model

    [https://arxiv.org/abs/2402.13040](https://arxiv.org/abs/2402.13040)

    提出了一种名为Text-Guided Molecule Generation with Diffusion Language Model（TGM-DLM）的新方法，通过扩散模型进行文本引导的分子生成，在生成有效分子表示方面表现出显著的效果优于自回归模型MolT5-Base。

    

    文本引导的分子生成是一个任务，其中生成的分子与特定的文本描述相匹配。最近，大多数现有基于SMILES的分子生成方法依赖于自回归架构。在这项工作中，我们提出了一种名为Text-Guided Molecule Generation with Diffusion Language Model（TGM-DLM）的新方法，它利用扩散模型来解决自回归方法的局限性。TGM-DLM集体和迭代地更新SMILES字符串中的标记嵌入，使用两阶段扩散生成过程。第一阶段通过随机噪声从文本描述中引导来优化嵌入，而第二阶段纠正无效的SMILES字符串以形成有效的分子表示。我们证明，TGM-DLM在不需要额外数据资源的情况下，胜过了自回归模型MolT5-Base。我们的研究结果强调了TGM-DLM在生成连贯性方面的显著有效性。

    arXiv:2402.13040v1 Announce Type: cross  Abstract: Text-guided molecule generation is a task where molecules are generated to match specific textual descriptions. Recently, most existing SMILES-based molecule generation methods rely on an autoregressive architecture. In this work, we propose the Text-Guided Molecule Generation with Diffusion Language Model (TGM-DLM), a novel approach that leverages diffusion models to address the limitations of autoregressive methods. TGM-DLM updates token embeddings within the SMILES string collectively and iteratively, using a two-phase diffusion generation process. The first phase optimizes embeddings from random noise, guided by the text description, while the second phase corrects invalid SMILES strings to form valid molecular representations. We demonstrate that TGM-DLM outperforms MolT5-Base, an autoregressive model, without the need for additional data resources. Our findings underscore the remarkable effectiveness of TGM-DLM in generating cohe
    
[^29]: 对齐您的意图：通过最优传输的离线模仿学习

    Align Your Intents: Offline Imitation Learning via Optimal Transport

    [https://arxiv.org/abs/2402.13037](https://arxiv.org/abs/2402.13037)

    通过最优传输的离线模仿学习方法AILOT，可以在缺乏明确奖励的情况下，仅通过观察专家学习所需的行为。

    

    离线强化学习（RL）通过学习预先收集的数据来解决顺序决策问题，而无需与环境进行交互。我们展示出，即使缺乏明确的奖励或动作标签，模仿代理也可以仅通过观察专家来学习所需的行为。在我们的方法AILOT（通过最优传输对齐模仿学习）中，我们使用意图的特殊状态表示形式，其中包含数据内的两两空间距离。在给定这种表示形式的情况下，我们通过专家和代理轨迹之间的最优传输距离定义内在奖励函数。我们报告称AILOT在D4RL基准测试上优于最先进的离线模仿学习算法。

    arXiv:2402.13037v1 Announce Type: cross  Abstract: Offline reinforcement learning (RL) addresses the problem of sequential decision-making by learning optimal policy through pre-collected data, without interacting with the environment. As yet, it has remained somewhat impractical, because one rarely knows the reward explicitly and it is hard to distill it retrospectively. Here, we show that an imitating agent can still learn the desired behavior merely from observing the expert, despite the absence of explicit rewards or action labels. In our method, AILOT (Aligned Imitation Learning via Optimal Transport), we involve special representation of states in a form of intents that incorporate pairwise spatial distances within the data. Given such representations, we define intrinsic reward function via optimal transport distance between the expert's and the agent's trajectories. We report that AILOT outperforms state-of-the art offline imitation learning algorithms on D4RL benchmarks and im
    
[^30]: 学习检查：释放大型语言模型自我校正的潜力

    Learning to Check: Unleashing Potentials for Self-Correction in Large Language Models

    [https://arxiv.org/abs/2402.13035](https://arxiv.org/abs/2402.13035)

    通过精心设计训练数据和构建检查-校正数据集，本研究增强了大型语言模型的自我校正能力，提高了自我校正的准确性。

    

    大型语言模型（LLMs）在推理能力方面取得了显著进展，不断努力通过自我校正来完善推理。然而，最近的研究表明，没有外部准确知识的自我校正可能存在局限性甚至可能适得其反，这就引发了关于自我校正的限制和有效性的疑问。本文旨在通过精心设计训练数据来增强LLM的自检功能，从而提高自我校正的准确性。我们对数学推理中的错误类型进行了详细分析，并开发了一个量身定制的提示，称为“Step CoT Check”。然后我们构建了一个检查-校正数据集用于训练模型。在将原始CoT数据和检查校正数据整合后进行训练，我们观察到模型可以改善其自检能力，从而提高其自我校正能力并消除了需要

    arXiv:2402.13035v1 Announce Type: cross  Abstract: Large language models (LLMs) have made significant strides in reasoning capabilities, with ongoing efforts to refine their reasoning through self-correction. However, recent studies suggest that self-correction can be limited or even counterproductive without external accurate knowledge, raising questions about the limits and effectiveness of self-correction. In this paper, we aim to enhance LLM's self-checking capabilities by meticulously designing training data, thereby improving the accuracy of self-correction. We conduct a detailed analysis of error types in mathematical reasoning and develop a tailored prompt, termed ``Step CoT Check''. Then we construct a checking-correction dataset for training models. After integrating the original CoT data and checking-correction data for training, we observe that models could improve their self-checking capabilities, thereby enhancing their self-correction capacity and eliminating the need fo
    
[^31]: 异质图推理用于文本和表格事实核查

    Heterogeneous Graph Reasoning for Fact Checking over Texts and Tables

    [https://arxiv.org/abs/2402.13028](https://arxiv.org/abs/2402.13028)

    提出了一种基于异质图的模型HeterFC，用于文本和表格中的事实核查，利用异质证据图和关系图神经网络进行信息传播。

    

    事实核查旨在通过推理多个证据以预测声明的真实性。本文专注于后者，即推理关于非结构化文本和结构化表格信息的真实性。我们提出了一种新颖的基于异质图的词级模型HeterFC，用于事实核查。我们的方法利用了一个异质证据图，以单词为节点，并且设计了代表不同证据属性的边缘，通过关系图神经网络进行信息传播，促进声明之间的交互。

    arXiv:2402.13028v1 Announce Type: cross  Abstract: Fact checking aims to predict claim veracity by reasoning over multiple evidence pieces. It usually involves evidence retrieval and veracity reasoning. In this paper, we focus on the latter, reasoning over unstructured text and structured table information. Previous works have primarily relied on fine-tuning pretrained language models or training homogeneous-graph-based models. Despite their effectiveness, we argue that they fail to explore the rich semantic information underlying the evidence with different structures. To address this, we propose a novel word-level Heterogeneous-graph-based model for Fact Checking over unstructured and structured information, namely HeterFC. Our approach leverages a heterogeneous evidence graph, with words as nodes and thoughtfully designed edges representing different evidence properties. We perform information propagation via a relational graph neural network, facilitating interactions between claim
    
[^32]: CFEVER：一个用于汉语事实提取和验证的数据集

    CFEVER: A Chinese Fact Extraction and VERification Dataset

    [https://arxiv.org/abs/2402.13025](https://arxiv.org/abs/2402.13025)

    CFEVER是一个为事实提取和验证而设计的汉语数据集，提供了严格的标准和对应证据，可用于开发自动化系统，减轻人工核查的工作量。

    

    我们介绍了CFEVER，这是一个专为事实提取和验证而设计的汉语数据集。CFEVER包括30,012个基于中文维基百科内容手动创建的声明。每个CFEVER中的声明都标记为“支持”、“反驳”或“信息不足”，以描述其事实程度。类似于FEVER数据集，支持和反驳类别中的声明也标有对应的证据句，这些证据句取自中文维基百科的单个或多个页面。我们的标记数据集在五路标注者间一致性方面具有0.7934的Fleiss' kappa值。此外，通过对FEVER数据集上开发的最先进方法以及对CFEVER的简单基准的实验，我们证明了我们的数据集是一个新的苛刻事实提取和验证基准，可进一步用于开发自动化系统，减轻人类事实核查的工作量。CFEVER可在网址处获得。

    arXiv:2402.13025v1 Announce Type: cross  Abstract: We present CFEVER, a Chinese dataset designed for Fact Extraction and VERification. CFEVER comprises 30,012 manually created claims based on content in Chinese Wikipedia. Each claim in CFEVER is labeled as "Supports", "Refutes", or "Not Enough Info" to depict its degree of factualness. Similar to the FEVER dataset, claims in the "Supports" and "Refutes" categories are also annotated with corresponding evidence sentences sourced from single or multiple pages in Chinese Wikipedia. Our labeled dataset holds a Fleiss' kappa value of 0.7934 for five-way inter-annotator agreement. In addition, through the experiments with the state-of-the-art approaches developed on the FEVER dataset and a simple baseline for CFEVER, we demonstrate that our dataset is a new rigorous benchmark for factual extraction and verification, which can be further used for developing automated systems to alleviate human fact-checking efforts. CFEVER is available at htt
    
[^33]: 用逻辑背景知识提升基于神经网络的分类

    Improving Neural-based Classification with Logical Background Knowledge

    [https://arxiv.org/abs/2402.13019](https://arxiv.org/abs/2402.13019)

    本文提出了一种新的神经符号技术——在推理过程中的语义调节，该技术仅在推理过程中约束系统，而不影响训练，相对于其他两种常见神经符号技术具有理论和实际优势，在多尺度方法上的评估结果表明其对网络规模的好处。

    

    arXiv:2402.13019v1 公告类型:新 抽象:神经符号人工智能是一个日益发展的研究领域，旨在将神经网络学习能力与符号系统的推理能力相结合。这种混合可以采用多种形式。在本文中，我们提出了一种新的形式化方法，用于具有命题背景知识的监督式多标签分类。我们引入了一种名为在推理过程中的语义调节的新的神经符号技术，该技术仅在推理过程中约束系统，而不影响训练。我们讨论了它相对于另外两种流行的神经符号技术——语义调节和语义正则化的理论和实际优势。我们开发了一种新的多尺度方法，评估神经符号技术的好处随网络规模的变化而发展。然后，我们在几个数据集上实验评估并比较这三种技术的好处。我们的结果表明，语义调节…

    arXiv:2402.13019v1 Announce Type: new  Abstract: Neurosymbolic AI is a growing field of research aiming to combine neural networks learning capabilities with the reasoning abilities of symbolic systems. This hybridization can take many shapes. In this paper, we propose a new formalism for supervised multi-label classification with propositional background knowledge. We introduce a new neurosymbolic technique called semantic conditioning at inference, which only constrains the system during inference while leaving the training unaffected. We discuss its theoritical and practical advantages over two other popular neurosymbolic techniques: semantic conditioning and semantic regularization. We develop a new multi-scale methodology to evaluate how the benefits of a neurosymbolic technique evolve with the scale of the network. We then evaluate experimentally and compare the benefits of all three techniques across model scales on several datasets. Our results demonstrate that semantic conditi
    
[^34]: 用于化学文献数据挖掘的自主大型语言模型代理

    An Autonomous Large Language Model Agent for Chemical Literature Data Mining

    [https://arxiv.org/abs/2402.12993](https://arxiv.org/abs/2402.12993)

    介绍了一个端到端的人工智能代理框架，利用大型语言模型实现从化学文献中高保真提取信息，充当化学助手的角色，自动化数据收集和分析，从而提高工作效率。

    

    化学合成对于推动材料合成和药物发现至关重要，影响着包括环境科学和医疗保健在内的各个领域。化学领域的技术上升使得产生了大量的化学数据，挑战研究人员去识别模式并细化合成过程。人工智能通过分析数据来优化合成并提高产量。然而，人工智能在处理文献数据方面面临着挑战，因为化学文献的结构不规整，写作风格多样。为了克服这些困难，我们引入了一个端到端的人工智能代理框架，能够从广泛的化学文献中高保真地提取信息。这个人工智能代理采用大型语言模型（LLMs）进行快速生成和迭代优化。它充当化学助手的角色，自动化数据收集和分析，从而节省人力并提高性能。

    arXiv:2402.12993v1 Announce Type: cross  Abstract: Chemical synthesis, which is crucial for advancing material synthesis and drug discovery, impacts various sectors including environmental science and healthcare. The rise of technology in chemistry has generated extensive chemical data, challenging researchers to discern patterns and refine synthesis processes. Artificial intelligence (AI) helps by analyzing data to optimize synthesis and increase yields. However, AI faces challenges in processing literature data due to the unstructured format and diverse writing style of chemical literature. To overcome these difficulties, we introduce an end-to-end AI agent framework capable of high-fidelity extraction from extensive chemical literature. This AI agent employs large language models (LLMs) for prompt generation and iterative optimization. It functions as a chemistry assistant, automating data collection and analysis, thereby saving manpower and enhancing performance. Our framework's ef
    
[^35]: TRAP: 面向黑盒身份验证的有针对性随机对抗提示诱饵

    TRAP: Targeted Random Adversarial Prompt Honeypot for Black-Box Identification

    [https://arxiv.org/abs/2402.12991](https://arxiv.org/abs/2402.12991)

    TRAP提出了一种名为Targeted Random Adversarial Prompt (TRAP)的方法，用于识别特定LLM的使用，并在单次交互后以超过95%的真阳性率和低于0.2%的误报率检测目标LLMs。

    

    大型语言模型（LLM）服务和模型通常伴随着关于谁可以使用它们以及他们必须如何使用它们的法律规定。评估发布的LLMs的合规性是至关重要的，因为这些规定保护了LLM贡献者的利益并防止了滥用。在这种背景下，我们描述了黑盒身份验证（BBIV）的新问题。其目标是确定第三方应用是否通过其聊天功能使用某个特定的LLM。我们提出了一种名为目标随机对抗提示（TRAP）的方法，用于识别正在使用的具体LLM。我们重新利用了最初用于越狱的对抗性后缀，以从目标LLM获得预定义的答案，而其他模型则给出随机答案。TRAP可以在单次交互后以超过95%的真阳性率和低于0.2%的误报率检测目标LLMs。即使LLM有不会显著改变的细微变化，TRAP仍然有效。

    arXiv:2402.12991v1 Announce Type: cross  Abstract: Large Language Model (LLM) services and models often come with legal rules on who can use them and how they must use them. Assessing the compliance of the released LLMs is crucial, as these rules protect the interests of the LLM contributor and prevent misuse. In this context, we describe the novel problem of Black-box Identity Verification (BBIV). The goal is to determine whether a third-party application uses a certain LLM through its chat function. We propose a method called Targeted Random Adversarial Prompt (TRAP) that identifies the specific LLM in use. We repurpose adversarial suffixes, originally proposed for jailbreaking, to get a pre-defined answer from the target LLM, while other models give random answers. TRAP detects the target LLMs with over 95% true positive rate at under 0.2% false positive rate even after a single interaction. TRAP remains effective even if the LLM has minor changes that do not significantly alter the
    
[^36]: GNN是否可以成为LLMs的良好适配器？

    Can GNN be Good Adapter for LLMs?

    [https://arxiv.org/abs/2402.12984](https://arxiv.org/abs/2402.12984)

    本文提出了GraphAdapter，利用图神经网络（GNN）作为高效适配器，与LLMs协同处理文本属性图（TAGs）。

    

    最近，大型语言模型（LLMs）在理解文本数据和零次学习方面展示了出色的能力，为许多与文本相关的领域带来了显著进展。本文探讨了如何利用LLMs来建模文本属性图（TAGs）。我们提出了GraphAdapter，它使用图神经网络（GNN）作为LLMs的高效适配器，以应对TAGs。

    arXiv:2402.12984v1 Announce Type: cross  Abstract: Recently, large language models (LLMs) have demonstrated superior capabilities in understanding and zero-shot learning on textual data, promising significant advances for many text-related domains. In the graph domain, various real-world scenarios also involve textual data, where tasks and node features can be described by text. These text-attributed graphs (TAGs) have broad applications in social media, recommendation systems, etc. Thus, this paper explores how to utilize LLMs to model TAGs. Previous methods for TAG modeling are based on million-scale LMs. When scaled up to billion-scale LLMs, they face huge challenges in computational costs. Additionally, they also ignore the zero-shot inference capabilities of LLMs. Therefore, we propose GraphAdapter, which uses a graph neural network (GNN) as an efficient adapter in collaboration with LLMs to tackle TAGs. In terms of efficiency, the GNN adapter introduces only a few trainable param
    
[^37]: 示范对多语境学习的影响：多维分析

    The Impact of Demonstrations on Multilingual In-Context Learning: A Multidimensional Analysis

    [https://arxiv.org/abs/2402.12976](https://arxiv.org/abs/2402.12976)

    通过多维分析发现，示范的有效性在多语种上下文学习中存在显著差异，其中部分模型对示范质量不敏感，而精心设计的模板可以消除对示范的依赖。

    

    在上下文学习中，示范经常被用作推理策略，在此策略中，大型语言模型仅使用少量标记的示范来解决任务，而无需进行任何参数更新。与单语言（英语）上下文学习的研究相比，多语种上下文学习尚未得到充分探讨，我们缺乏对该环境中示范作用的深入理解。为了填补这一空白，我们对多语境学习进行了多维分析，实验采用了来自不同模型家族的5个模型，涵盖了包括分类和生成任务在内的9个数据集，覆盖了56种类型上不同的语言。我们的结果表明，示范的有效性在模型、任务和语言之间存在显著差异。我们还发现，Llama 2-Chat、GPT-3.5和GPT-4对示范质量的敏感度较低。相反，精心设计的模板往往会消除一些模型对示范的益处。

    arXiv:2402.12976v1 Announce Type: cross  Abstract: In-context learning is a popular inference strategy where large language models solve a task using only a few labelled demonstrations without needing any parameter updates. Compared to work on monolingual (English) in-context learning, multilingual in-context learning is under-explored, and we lack an in-depth understanding of the role of demonstrations in this context. To address this gap, we conduct a multidimensional analysis of multilingual in-context learning, experimenting with 5 models from different model families, 9 datasets covering classification and generation tasks, and 56 typologically diverse languages. Our results reveal that the effectiveness of demonstrations varies significantly across models, tasks, and languages. We also find that Llama 2-Chat, GPT-3.5, and GPT-4 are largely insensitive to the quality of demonstrations. Instead, a carefully crafted template often eliminates the benefits of demonstrations for some t
    
[^38]: Gl'orIA - 一种用于葡萄牙语的生成式开放大型语言模型

    Gl\'orIA - A Generative and Open Large Language Model for Portuguese

    [https://arxiv.org/abs/2402.12969](https://arxiv.org/abs/2402.12969)

    Gl'orIA是一种专门为欧洲葡萄牙语设计的强大解码器大型语言模型，通过对350亿个tokens的全面PT-PT文本语料库预训练，为欧洲葡萄牙语提供了解决方案，并引入了CALAME-PT，这是第一个葡萄牙语零样本语言建模基准。

    

    自然语言任务取得了显著进展，这在很大程度上归因于强大的大型语言模型（LLMs）的出现。尽管许多高资源语言都有丰富的LLM，但欧洲葡萄牙语的这种模型仍然有限。我们介绍了一种强大的欧洲葡萄牙语解码器LLM——Gl'orIA。为了对Gl'orIA进行预训练，我们收集了一个包含来自各个来源的350亿个tokens的全面PT-PT文本语料库。我们展示了我们的预训练方法，然后评估了模型在多个下游任务上的有效性。此外，为了评估我们模型的语言建模能力，我们引入了CALAME-PT（葡萄牙语零样本语言建模基准），这是第一个葡萄牙语零样本语言建模基准。

    arXiv:2402.12969v1 Announce Type: cross  Abstract: Significant strides have been made in natural language tasks, largely attributed to the emergence of powerful large language models (LLMs). These models, pre-trained on extensive and diverse corpora, have become increasingly capable of comprehending the intricacies of language. Despite the abundance of LLMs for many high-resource languages, the availability of such models remains limited for European Portuguese. We introduce Gl\'orIA, a robust European Portuguese decoder LLM. To pre-train Gl\'orIA, we assembled a comprehensive PT-PT text corpus comprising 35 billion tokens from various sources. We present our pre-training methodology, followed by an assessment of the model's effectiveness on multiple downstream tasks. Additionally, to evaluate our models' language modeling capabilities, we introduce CALAME-PT (Context-Aware LAnguage Modeling Evaluation for Portuguese), the first Portuguese zero-shot language-modeling benchmark. Evaluat
    
[^39]: 用于复杂查询回答的条件逻辑消息传递变压器

    Conditional Logical Message Passing Transformer for Complex Query Answering

    [https://arxiv.org/abs/2402.12954](https://arxiv.org/abs/2402.12954)

    提出了一种考虑查询图中常量和变量之间差异，能动态测量消息重要性并捕捉隐式逻辑依赖关系的条件逻辑消息传递变压器。

    

    知识图谱（KGs）上的复杂查询回答（CQA）是一项具有挑战性的任务。由于KGs通常是不完整的，提出了神经模型来通过执行多跳逻辑推理来解决CQA。然而，大多数模型不能同时在一跳和多跳查询上表现良好。最近的工作提出了一种基于预训练神经链接预测器的逻辑消息传递机制。虽然在一跳和多跳查询上都有效，但它忽略了查询图中常量和变量节点之间的差异。此外，在节点嵌入更新阶段，该机制不能动态衡量不同消息的重要性，并且它能否捕捉与节点和接收消息相关的隐式逻辑依赖关系仍不清楚。在本文中，我们提出了条件逻辑消息传递变压器（CLMPT），考虑了查询图中常量和变量之间的差异，并且具有动态测量不同消息重要性以及捕捉与节点和接收消息相关的隐式逻辑依赖关系的能力。

    arXiv:2402.12954v1 Announce Type: cross  Abstract: Complex Query Answering (CQA) over Knowledge Graphs (KGs) is a challenging task. Given that KGs are usually incomplete, neural models are proposed to solve CQA by performing multi-hop logical reasoning. However, most of them cannot perform well on both one-hop and multi-hop queries simultaneously. Recent work proposes a logical message passing mechanism based on the pre-trained neural link predictors. While effective on both one-hop and multi-hop queries, it ignores the difference between the constant and variable nodes in a query graph. In addition, during the node embedding update stage, this mechanism cannot dynamically measure the importance of different messages, and whether it can capture the implicit logical dependencies related to a node and received messages remains unclear. In this paper, we propose Conditional Logical Message Passing Transformer (CLMPT), which considers the difference between constants and variables in the c
    
[^40]: QuanTest：基于纠缠的量子神经网络系统测试

    QuanTest: Entanglement-Guided Testing of Quantum Neural Network Systems

    [https://arxiv.org/abs/2402.12950](https://arxiv.org/abs/2402.12950)

    QuanTest是一个基于纠缠的对抗测试框架，旨在揭示量子神经网络系统中的潜在错误行为。

    

    Quantum Neural Network（QNN）将深度学习（DL）原理与量子力学基本理论相结合，实现具有量子加速的机器学习任务。 最近发现，QNN系统有类似于经典DL系统的鲁棒性问题。 急需一种方法来测试它们的正确性和安全性。 但是，QNN系统与传统量子软件和经典DL系统有很大不同，对QNN测试提出了重大挑战。 这些挑战包括传统量子软件测试方法的不适用性，量子测试样本生成对扰动算子的依赖，以及量子神经元中缺乏有效信息。 本文提出了QuanTest，这是一个基于量子纠缠的对抗测试框架，用于发现QNN系统中潜在的错误行为。 我们设计了一个量子纠缠充分性准则来量化

    arXiv:2402.12950v1 Announce Type: cross  Abstract: Quantum Neural Network (QNN) combines the Deep Learning (DL) principle with the fundamental theory of quantum mechanics to achieve machine learning tasks with quantum acceleration. Recently, QNN systems have been found to manifest robustness issues similar to classical DL systems. There is an urgent need for ways to test their correctness and security. However, QNN systems differ significantly from traditional quantum software and classical DL systems, posing critical challenges for QNN testing. These challenges include the inapplicability of traditional quantum software testing methods, the dependence of quantum test sample generation on perturbation operators, and the absence of effective information in quantum neurons. In this paper, we propose QuanTest, a quantum entanglement-guided adversarial testing framework to uncover potential erroneous behaviors in QNN systems. We design a quantum entanglement adequacy criterion to quantify 
    
[^41]: 利用轨迹聚类在潜空间中发现深度强化学习策略的行为模式

    Discovering Behavioral Modes in Deep Reinforcement Learning Policies Using Trajectory Clustering in Latent Space

    [https://arxiv.org/abs/2402.12939](https://arxiv.org/abs/2402.12939)

    通过利用轨迹聚类和降维技术在神经网络的潜空间中研究深度强化学习策略的行为模式，可以发现并改进其多样的行为模式和次优选择。

    

    深度强化学习（DRL）代理的行为分析对于提高其性能和可靠性至关重要。然而，它们的策略复杂性往往使其难以理解。本文介绍了一种新方法，用于研究DRL策略的行为模式，该方法涉及在神经网络的潜空间中利用降维和轨迹聚类。具体地，我们使用Pairwise Controlled Manifold Approximation Projection（PaCMAP）进行降维和TRACLUS进行轨迹聚类，分析了在Mountain Car控制任务上训练的DRL策略的潜空间。我们的方法有助于识别多样的行为模式和策略的次优选择，从而实现有针对性的改进。我们展示了如何结合领域知识，可以增强策略在状态空间特定区域的性能。

    arXiv:2402.12939v1 Announce Type: cross  Abstract: Understanding the behavior of deep reinforcement learning (DRL) agents is crucial for improving their performance and reliability. However, the complexity of their policies often makes them challenging to understand. In this paper, we introduce a new approach for investigating the behavior modes of DRL policies, which involves utilizing dimensionality reduction and trajectory clustering in the latent space of neural networks. Specifically, we use Pairwise Controlled Manifold Approximation Projection (PaCMAP) for dimensionality reduction and TRACLUS for trajectory clustering to analyze the latent space of a DRL policy trained on the Mountain Car control task. Our methodology helps identify diverse behavior patterns and suboptimal choices by the policy, thus allowing for targeted improvements. We demonstrate how our approach, combined with domain knowledge, can enhance a policy's performance in specific regions of the state space.
    
[^42]: 模式分析与机器智能领域文献综述的文献综述

    A Literature Review of Literature Reviews in Pattern Analysis and Machine Intelligence

    [https://arxiv.org/abs/2402.12928](https://arxiv.org/abs/2402.12928)

    本文旨在提供对模式分析与机器智能领域文献综述的全面评估，引入大语言模型驱动的文献计量指标，并构建了RiPAMI元数据数据库和主题数据集以获取PAMI综述的统计特征。

    

    通过整合分散的知识，文献综述提供了对所研究主题的全面了解。然而，在模式分析与机器智能（PAMI）这一蓬勃发展的领域中，过多的综述引起了研究人员和评论者的关注。作为对这些关注的回应，本文旨在从多个角度全面审视PAMI领域的综述文献。

    arXiv:2402.12928v1 Announce Type: cross  Abstract: By consolidating scattered knowledge, the literature review provides a comprehensive understanding of the investigated topic. However, excessive reviews, especially in the booming field of pattern analysis and machine intelligence (PAMI), raise concerns for both researchers and reviewers. In response to these concerns, this Analysis aims to provide a thorough review of reviews in the PAMI field from diverse perspectives. First, large language model-empowered bibliometric indicators are proposed to evaluate literature reviews automatically. To facilitate this, a meta-data database dubbed RiPAMI, and a topic dataset are constructed, which are utilized to obtain statistical characteristics of PAMI reviews. Unlike traditional bibliometric measurements, the proposed article-level indicators provide real-time and field-normalized quantified assessments of reviews without relying on user-defined keywords. Second, based on these indicators, th
    
[^43]: 数据管道训练：将 AutoML 集成到优化机器学习模型数据流中

    Data Pipeline Training: Integrating AutoML to Optimize the Data Flow of Machine Learning Models

    [https://arxiv.org/abs/2402.12916](https://arxiv.org/abs/2402.12916)

    本文讨论了如何通过集成 AutoML 技术优化数据管道，提升数据流智能性以在机器学习任务中取得更好结果，并揭示了构建高效适应不断变化数据环境的关键策略。

    

    数据管道在机器学习建模和开发数据产品等任务中扮演着不可或缺的角色。随着数据源日益多样化和复杂化，以及数据量的快速增长，构建高效的数据管道对于提高工作效率和解决复杂问题至关重要。本文重点探讨如何通过集成 AutoML 到数据管道中，优化数据流动的方法。我们将讨论如何利用 AutoML 技术提升数据管道的智能化，从而在机器学习任务中取得更好的结果。通过深入研究数据流的自动化和优化，我们揭示了构建适应不断变化的数据环境的高效数据管道的关键策略。这不仅加快了建模过程，还为复杂问题提供了创新解决方案，实现了更显著的效果。

    arXiv:2402.12916v1 Announce Type: cross  Abstract: Data Pipeline plays an indispensable role in tasks such as modeling machine learning and developing data products. With the increasing diversification and complexity of Data sources, as well as the rapid growth of data volumes, building an efficient Data Pipeline has become crucial for improving work efficiency and solving complex problems. This paper focuses on exploring how to optimize data flow through automated machine learning methods by integrating AutoML with Data Pipeline. We will discuss how to leverage AutoML technology to enhance the intelligence of Data Pipeline, thereby achieving better results in machine learning tasks. By delving into the automation and optimization of Data flows, we uncover key strategies for constructing efficient data pipelines that can adapt to the ever-changing data landscape. This not only accelerates the modeling process but also provides innovative solutions to complex problems, enabling more sig
    
[^44]: AI对齐在社会技术系统中的激励兼容性：立场与前景

    Incentive Compatibility for AI Alignment in Sociotechnical Systems: Positions and Prospects

    [https://arxiv.org/abs/2402.12907](https://arxiv.org/abs/2402.12907)

    该论文提出了激励兼容性社会技术对齐问题（ICSAP），旨在探讨如何利用博弈论中的激励兼容性原则来维持AI与人类社会的共识。

    

    人工智能（AI）日益融入人类社会，对社会治理和安全带来重要影响。尽管在解决AI对齐挑战方面取得了重大进展，但现有方法主要集中在技术方面，往往忽视了AI系统复杂的社会技术性质，这可能导致开发和部署背景之间的不一致。因此，我们提出一个值得探索的新问题：激励兼容性社会技术对齐问题（ICSAP）。我们希望这能呼吁更多研究人员探讨如何利用博弈论中的激励兼容性原则来弥合技术和社会组成部分之间的鸿沟，以在不同背景下维持AI与人类社会的共识。我们进一步讨论了实现IC的三个经典博弈问题：机制设计、契约理论和贝叶斯说服。

    arXiv:2402.12907v1 Announce Type: new  Abstract: The burgeoning integration of artificial intelligence (AI) into human society brings forth significant implications for societal governance and safety. While considerable strides have been made in addressing AI alignment challenges, existing methodologies primarily focus on technical facets, often neglecting the intricate sociotechnical nature of AI systems, which can lead to a misalignment between the development and deployment contexts. To this end, we posit a new problem worth exploring: Incentive Compatibility Sociotechnical Alignment Problem (ICSAP). We hope this can call for more researchers to explore how to leverage the principles of Incentive Compatibility (IC) from game theory to bridge the gap between technical and societal components to maintain AI consensus with human societies in different contexts. We further discuss three classical game problems for achieving IC: mechanism design, contract theory, and Bayesian persuasion,
    
[^45]: 开发贝叶斯网络中定性参数化的实践

    The practice of qualitative parameterisation in the development of Bayesian networks

    [https://arxiv.org/abs/2402.12887](https://arxiv.org/abs/2402.12887)

    贝叶斯网络的典型开发阶段包括结构开发和参数化，而开发过程中执行初步的粗略参数化对于确保结构的合适性和后续的开发和验证至关重要。

    

    贝叶斯网络(BN)结构化开发的典型阶段包括目的和范围的规定、结构开发、参数化和验证。 结构开发通常集中在定性问题上，而参数化集中在定量问题上，然而在这两个阶段都会出现定性和定量问题。 在初步结构开发后通常会执行粗略参数化的常见步骤，该步骤仅捕捉和说明模型的预期定性行为。 这是在更严格的参数化之前完成的，确保结构符合预期，同时支持后续的开发和验证。 在我们的集体经验和与其他建模者的讨论中，这一步骤是开发过程的重要部分，但在文献中很少提及。 由于实践集中在定性问题上，尽管是数量

    arXiv:2402.12887v1 Announce Type: new  Abstract: The typical phases of Bayesian network (BN) structured development include specification of purpose and scope, structure development, parameterisation and validation. Structure development is typically focused on qualitative issues and parameterisation quantitative issues, however there are qualitative and quantitative issues that arise in both phases. A common step that occurs after the initial structure has been developed is to perform a rough parameterisation that only captures and illustrates the intended qualitative behaviour of the model. This is done prior to a more rigorous parameterisation, ensuring that the structure is fit for purpose, as well as supporting later development and validation. In our collective experience and in discussions with other modellers, this step is an important part of the development process, but is under-reported in the literature. Since the practice focuses on qualitative issues, despite being quanti
    
[^46]: 反向镜头：将语言模型梯度投影到词汇空间中

    Backward Lens: Projecting Language Model Gradients into the Vocabulary Space

    [https://arxiv.org/abs/2402.12865](https://arxiv.org/abs/2402.12865)

    将语言模型梯度投影到词汇空间中，挖掘信息在LMs内部的流动方式，探索新信息如何存储在LMs的神经元中。

    

    了解基于Transformer的语言模型(LMs)如何学习和记忆信息是深度学习社区的一个重要目标。最近的可解释性方法将从前向传播中获得的权重和隐藏状态投影到模型的词汇表中，有助于揭示LMs内部信息流动的方式。在这项工作中，我们将这种方法扩展到LMs的后向传播和梯度。我们首先证明梯度矩阵可以被表示为其前向和后向传播输入的低秩线性组合。然后我们开发方法将这些梯度投影到词汇项中，并探讨新信息如何存储在LMs的神经元中的机制。

    arXiv:2402.12865v1 Announce Type: cross  Abstract: Understanding how Transformer-based Language Models (LMs) learn and recall information is a key goal of the deep learning community. Recent interpretability methods project weights and hidden states obtained from the forward pass to the models' vocabularies, helping to uncover how information flows within LMs. In this work, we extend this methodology to LMs' backward pass and gradients. We first prove that a gradient matrix can be cast as a low-rank linear combination of its forward and backward passes' inputs. We then develop methods to project these gradients into vocabulary items and explore the mechanics of how new information is stored in the LMs' neurons.
    
[^47]: 调整过的语言模型更好的知识学习者

    Instruction-tuned Language Models are Better Knowledge Learners

    [https://arxiv.org/abs/2402.12847](https://arxiv.org/abs/2402.12847)

    通过在持续预训练文档之前暴露LLM到问题-答案对，以便从复杂文档中编码知识，可以更好地适应知识访问方式。

    

    为了使基于大语言模型（LLM）的助手能够有效地适应不断发展的信息需求，必须能够通过持续在新数据上训练来更新它们的事实知识。传统做法涉及在新文档上持续预培训，然后根据问题-答案（QA）对进行指导调整。

    arXiv:2402.12847v1 Announce Type: cross  Abstract: In order for large language model (LLM)-based assistants to effectively adapt to evolving information needs, it must be possible to update their factual knowledge through continued training on new data. The standard recipe for doing so involves continued pre-training on new documents followed by instruction-tuning on question-answer (QA) pairs. However, we find that LLMs trained with this recipe struggle to answer questions, even though the perplexity of documents is minimized. We found that QA pairs are generally straightforward, while documents are more complex, weaving many factual statements together in an intricate manner. Therefore, we hypothesize that it is beneficial to expose LLMs to QA pairs before continued pre-training on documents so that the process of encoding knowledge from complex documents takes into account how this knowledge is accessed through questions. Based on this, we propose pre-instruction-tuning (PIT), a met
    
[^48]: ConVQG: 对比式带多模态引导的视觉问题生成

    ConVQG: Contrastive Visual Question Generation with Multimodal Guidance

    [https://arxiv.org/abs/2402.12846](https://arxiv.org/abs/2402.12846)

    提出了ConVQG方法通过双重对比目标区分使用两种模态生成的问题和基于单一模式的问题，解决了在生成专注问题的同时确保与图像内容的高度相关性的挑战.

    

    询问关于视觉环境的问题是智能代理理解丰富多面场景的关键方式，这提高了视觉问题生成（VQG）系统的重要性。除了基于图像，现有的VQG系统可以使用文本约束，如期望回答或知识三元组，来生成专注问题。然而，使用文本约束生成专注问题的同时确保与图像内容的高度相关性仍然是一个挑战，因为VQG系统经常会忽视一个或两个控制形式。在这项工作中，我们提出了对比式视觉问题生成（ConVQG），一种使用双重对比目标来区分使用两种模态生成的问题和基于单一模式的问题的方法。

    arXiv:2402.12846v1 Announce Type: cross  Abstract: Asking questions about visual environments is a crucial way for intelligent agents to understand rich multi-faceted scenes, raising the importance of Visual Question Generation (VQG) systems. Apart from being grounded to the image, existing VQG systems can use textual constraints, such as expected answers or knowledge triplets, to generate focused questions. These constraints allow VQG systems to specify the question content or leverage external commonsense knowledge that can not be obtained from the image content only. However, generating focused questions using textual constraints while enforcing a high relevance to the image content remains a challenge, as VQG systems often ignore one or both forms of grounding. In this work, we propose Contrastive Visual Question Generation (ConVQG), a method using a dual contrastive objective to discriminate questions generated using both modalities from those based on a single one. Experiments on
    
[^49]: 基于多模态离线强化学习的共享语义空间

    MORE-3S:Multimodal-based Offline Reinforcement Learning with Shared Semantic Spaces

    [https://arxiv.org/abs/2402.12845](https://arxiv.org/abs/2402.12845)

    将不同模态对齐到相同的语义嵌入空间有利于提升离线强化学习性能，通过集成多模态和预训练语言模型，我们成功将其转化为一个监督学习任务，有助于增强强化学习训练性能并促进长期战略思维。

    

    基于对齐不同模态到相同语义嵌入空间可以使模型更容易理解状态和动作的直觉，我们提出了一个新的视角来解决离线强化学习挑战。更具体地，我们通过集成多模态和预训练语言模型将其转化为一个监督学习任务。我们的方法融合了从图像中得到的状态信息和从文本中获得的与动作相关的数据，从而增强了强化学习训练性能，并促进了长期战略思维。我们强调语言的情境理解，并展示了强化学习中如何从将状态和动作表示与语言表示对齐中受益。我们的方法在Atari和OpenAI Gym环境中的评估显示明显优于当前基准。这有助于推动离线强化学习性能和效率。

    arXiv:2402.12845v1 Announce Type: new  Abstract: Drawing upon the intuition that aligning different modalities to the same semantic embedding space would allow models to understand states and actions more easily, we propose a new perspective to the offline reinforcement learning (RL) challenge. More concretely, we transform it into a supervised learning task by integrating multimodal and pre-trained language models. Our approach incorporates state information derived from images and action-related data obtained from text, thereby bolstering RL training performance and promoting long-term strategic thinking. We emphasize the contextual understanding of language and demonstrate how decision-making in RL can benefit from aligning states' and actions' representation with languages' representation. Our method significantly outperforms current baselines as evidenced by evaluations conducted on Atari and OpenAI Gym environments. This contributes to advancing offline RL performance and efficie
    
[^50]: 太阳能面板分割:自监督学习用于不完美数据集

    SolarPanel Segmentation :Self-Supervised Learning for Imperfect Datasets

    [https://arxiv.org/abs/2402.12843](https://arxiv.org/abs/2402.12843)

    自监督学习方法在太阳能面板分割问题中显著提高了模型泛化能力，减少了对手动标注数据的依赖。

    

    随着太阳能的日益普及，需要先进的监控和维护方法来确保太阳能面板安装的最佳性能。在这种背景下，一个至关重要的组成部分是从航空或卫星图像中准确分割太阳能面板，这对于识别运行问题和评估效率至关重要。本文解决了面板分割中的重要挑战，特别是标注数据的稀缺性以及手动标注对监督学习的劳动密集性。我们探讨并应用自监督学习（SSL）来解决这些挑战。我们证明SSL显著增强了模型在各种条件下的泛化能力，并减少了对手动标注数据的依赖，为健壮且适应性强的太阳能面板分割解决方案铺平了道路。

    arXiv:2402.12843v1 Announce Type: cross  Abstract: The increasing adoption of solar energy necessitates advanced methodologies for monitoring and maintenance to ensure optimal performance of solar panel installations. A critical component in this context is the accurate segmentation of solar panels from aerial or satellite imagery, which is essential for identifying operational issues and assessing efficiency. This paper addresses the significant challenges in panel segmentation, particularly the scarcity of annotated data and the labour-intensive nature of manual annotation for supervised learning. We explore and apply Self-Supervised Learning (SSL) to solve these challenges. We demonstrate that SSL significantly enhances model generalization under various conditions and reduces dependency on manually annotated data, paving the way for robust and adaptable solar panel segmentation solutions.
    
[^51]: PromptKD：通过提示调整为生成语言模型提取学生友好知识的蒸馏方法

    PromptKD: Distilling Student-Friendly Knowledge for Generative Language Models via Prompt Tuning

    [https://arxiv.org/abs/2402.12842](https://arxiv.org/abs/2402.12842)

    提出了PromptKD方法，通过提示调整实现了生成语言模型提取学生友好知识的蒸馏，无需微调整整个教师模型。

    

    近期大型语言模型（LLMs）的发展引起了对推理成本的担忧，进一步增加了对模型压缩研究的需求。尽管知识蒸馏（KD）是一种突出的方法，但是针对LLMs这样的生成语言模型的KD研究相对较少，而提取适合学生的知识的方法，在分类模型的KD中表现出了良好性能，在生成语言模型中尚未被探索。为了探索这种方法，我们提出了PromptKD，一种简单而有效的方法，它利用提示调整 - 在KD中首次出现 - 使生成语言模型能够传递适合学生的知识。与先前分类工作不同，先前那些需要微调整整个教师模型以提取适合学生的知识，PromptKD通过添加少量提示标记，并仅通过学生指导调整提示来达到类似效果。

    arXiv:2402.12842v1 Announce Type: cross  Abstract: Recent advancements in large language models (LLMs) have raised concerns about inference costs, increasing the need for research into model compression. While knowledge distillation (KD) is a prominent method for this, research on KD for generative language models like LLMs is relatively sparse, and the approach of distilling student-friendly knowledge, which has shown promising performance in KD for classification models, remains unexplored in generative language models. To explore this approach, we propose PromptKD, a simple yet effective method that utilizes prompt tuning - for the first time in KD - to enable generative language models to transfer student-friendly knowledge. Unlike previous works in classification that require fine-tuning the entire teacher model for extracting student-friendly knowledge, PromptKD achieves similar effects by adding a small number of prompt tokens and tuning only the prompt with student guidance. Ex
    
[^52]: PANDA: 用于增强LLMs领域特定能力的偏好适应方法

    PANDA: Preference Adaptation for Enhancing Domain-Specific Abilities of LLMs

    [https://arxiv.org/abs/2402.12835](https://arxiv.org/abs/2402.12835)

    PANDA是一种旨在增强LLMs领域特定能力的方法，通过利用专家模型响应偏好的见解，无需微调即可实现显著改进。

    

    大型语言模型（LLMs）在各种自然语言任务中展示出相当大的能力，但它们通常无法达到特定领域最先进模型的性能水平。增强LLMs领域特定能力的一种潜在方法是使用相应的数据集对其进行微调。然而，这种方法既耗费资源又耗时，并且无法应用于封闭源商业LLMs。在本文中，我们提出了一种称为PANDA的偏好适应方法，旨在通过利用专家模型响应偏好的见解来增强LLMs的领域特定能力，而无需进行微调。我们的实验结果显示，PANDA显著提升了LLMs在文本分类和交互式决策任务上的领域特定能力。此外，具有PANDA的LLM甚至超过了专家模型

    arXiv:2402.12835v1 Announce Type: cross  Abstract: While Large language models (LLMs) have demonstrated considerable capabilities across various natural language tasks, they often fall short of the performance achieved by domain-specific state-of-the-art models. One potential approach to enhance domain-specific capabilities of LLMs involves fine-tuning them using corresponding datasets. However, this method can be both resource and time-intensive, and not applicable to closed-source commercial LLMs. In this paper, we propose Preference Adaptation for Enhancing Domain-specific Abilities of LLMs (PANDA), a method designed to augment the domain-specific capabilities of LLMs by leveraging insights from the response preference of expert models without requiring fine-tuning. Our experimental results reveal that PANDA significantly enhances the domain-specific ability of LLMs on text classification and interactive decision tasks. Moreover, LLM with PANDA even outperforms the expert model that
    
[^53]: 微调、提示、上下文学习和指导微调：我们需要多少标记样本？

    Fine-Tuning, Prompting, In-Context Learning and Instruction-Tuning: How Many Labelled Samples Do We Need?

    [https://arxiv.org/abs/2402.12819](https://arxiv.org/abs/2402.12819)

    专门模型通常只需少量标记样本（100-1000个）就能与通用模型持平甚至更好，取决于任务的复杂性和结果的变化。

    

    当解决具有有限标记数据的任务时，研究人员可以选择使用通用的大型语言模型而不进行进一步更新，或者使用少量示例来调整专门的较小模型。 当有足够的标记可用时，专门的模型在许多自然语言处理任务上表现优于通用模型。 在这项工作中，我们旨在调查专门模型需要多少标记样本才能实现这种出色的性能，同时考虑结果的变化。观察提示、上下文学习、微调和指导微调的行为，识别它们在增加不同复杂性任务的标记训练样本数量时的收支平衡点，我们发现专门模型通常只需少量样本（100-1000个）就能与通用模型持平甚至更好。 同时，所需的标记数据量强烈依赖于任务的复杂性和结果的变化。

    arXiv:2402.12819v1 Announce Type: cross  Abstract: When solving a task with limited labelled data, researchers can either use a general large language model without further update, or use the few examples to tune a specialised smaller model. When enough labels are available, the specialised models outperform the general ones on many NLP tasks. In this work, we aim to investigate how many labelled samples are required for the specialised models to achieve this superior performance, while taking the results variance into consideration. Observing the behaviour of prompting, in-context learning, fine-tuning and instruction-tuning, identifying their break-even points when increasing number of labelled training samples across three tasks of varying complexity, we find that the specialised models often need only few samples ($100-1000$) to be on par or better than the general ones. At the same time, the amount of required labelled data strongly depends on the task complexity and results varia
    
[^54]: 有限标注数据学习对随机性的敏感性：相互作用和系统选择的影响

    On Sensitivity of Learning with Limited Labelled Data to the Effects of Randomness: Impact of Interactions and Systematic Choices

    [https://arxiv.org/abs/2402.12817](https://arxiv.org/abs/2402.12817)

    有限标注数据学习对随机性的敏感性，通过系统研究随机因素的影响，揭示了忽略相互作用可能导致的不一致结果。

    

    有限标注数据学习可以在标签不足时提高性能，但也对所谓的随机因素（例如数据的变化顺序）引入的无法控制的随机性敏感。我们提出了一种方法，系统地调查随机因素的影响，同时考虑它们之间的相互作用。为了测量单个随机因素的真实影响，我们的方法减轻了其他因素的影响，并观察了性能在多次运行中的变化。将我们的方法应用于7个代表性文本分类任务的上下文学习和微调方法以及3个任务的元学习，我们发现：1）现有作品中忽略随机因素之间的相互作用导致了不一致的研究结果，因为错误地归因于随机因素的影响，比如否定了一些一

    arXiv:2402.12817v1 Announce Type: cross  Abstract: While learning with limited labelled data can improve performance when the labels are lacking, it is also sensitive to the effects of uncontrolled randomness introduced by so-called randomness factors (e.g., varying order of data). We propose a method to systematically investigate the effects of randomness factors while taking the interactions between them into consideration. To measure the true effects of an individual randomness factor, our method mitigates the effects of other factors and observes how the performance varies across multiple runs. Applying our method to multiple randomness factors across in-context learning and fine-tuning approaches on 7 representative text classification tasks and meta-learning on 3 tasks, we show that: 1) disregarding interactions between randomness factors in existing works caused inconsistent findings due to incorrect attribution of the effects of randomness factors, such as disproving the consis
    
[^55]: PIP-Net：城市中行人意图预测

    PIP-Net: Pedestrian Intention Prediction in the Wild

    [https://arxiv.org/abs/2402.12810](https://arxiv.org/abs/2402.12810)

    PIP-Net是一个新型框架，通过综合利用动态学数据和场景空间特征，采用循环和时间注意力机制解决方案，成功预测行人通过马路的意图，性能优于现有技术。

    

    精准的自动驾驶车辆（AVs）对行人意图的预测是当前该领域的一项研究挑战。在本文中，我们介绍了PIP-Net，这是一个新颖的框架，旨在预测AVs在现实世界城市场景中的行人过马路意图。我们提供了两种针对不同摄像头安装和设置设计的PIP-Net变种。利用来自行驶场景的动力学数据和空间特征，所提出的模型采用循环和时间注意力机制的解决方案，性能优于现有技术。为了增强道路用户的视觉表示及其与自车的相关性，我们引入了一个分类深度特征图，结合局部运动流特征，为场景动态提供丰富的洞察。此外，我们探讨了将摄像头的视野从一个扩展到围绕自车的三个摄像头的影响，以提升

    arXiv:2402.12810v1 Announce Type: cross  Abstract: Accurate pedestrian intention prediction (PIP) by Autonomous Vehicles (AVs) is one of the current research challenges in this field. In this article, we introduce PIP-Net, a novel framework designed to predict pedestrian crossing intentions by AVs in real-world urban scenarios. We offer two variants of PIP-Net designed for different camera mounts and setups. Leveraging both kinematic data and spatial features from the driving scene, the proposed model employs a recurrent and temporal attention-based solution, outperforming state-of-the-art performance. To enhance the visual representation of road users and their proximity to the ego vehicle, we introduce a categorical depth feature map, combined with a local motion flow feature, providing rich insights into the scene dynamics. Additionally, we explore the impact of expanding the camera's field of view, from one to three cameras surrounding the ego vehicle, leading to enhancement in the
    
[^56]: 利用协作四足机器人和无人机进行文化遗产遗址的自主现实建模

    Autonomous Reality Modelling for Cultural Heritage Sites employing cooperative quadrupedal robots and unmanned aerial vehicles

    [https://arxiv.org/abs/2402.12794](https://arxiv.org/abs/2402.12794)

    通过使用自主仿生四足机器人代理和无人机，本文提出了一种自主的3D现实建模方法，可以用于文化遗产(CH)文物，实现了系统化和可重复的3D RM过程。

    

    如今，先进传感器的使用，如地面3D激光扫描仪、移动LiDAR和无人机摄影测量，已经成为文化遗产(CH)大型文物的3D现实建模和数字化的主要实践。在实践中，这个过程与调查团队的专业知识密切相关，处理针对每个遗址特定要求和约束的耗时规划和执行3D映射过程。为了最小化人类干预，本文引入了一种新颖的方法，通过利用配备适当传感器的自主仿生四足机器人代理和无人机来实现文化遗产(CH)文物的自主3D现实建模。这些自主机器人代理以系统化且可重复的方式进行3D RM过程。这个自动化过程的结果可能在数字孪生平台中找到应用。

    arXiv:2402.12794v1 Announce Type: cross  Abstract: Nowadays, the use of advanced sensors, such as terrestrial 3D laser scanners, mobile LiDARs and Unmanned Aerial Vehicles (UAV) photogrammetric imaging, has become the prevalent practice for 3D Reality Modeling and digitization of large-scale monuments of Cultural Heritage (CH). In practice, this process is heavily related to the expertise of the surveying team, handling the laborious planning and time-consuming execution of the 3D mapping process that is tailored to the specific requirements and constraints of each site. To minimize human intervention, this paper introduces a novel methodology for autonomous 3D Reality Modeling for CH monuments by employing au-tonomous biomimetic quadrupedal robotic agents and UAVs equipped with the appropriate sensors. These autonomous robotic agents carry out the 3D RM process in a systematic and repeatable ap-proach. The outcomes of this automated process may find applications in digital twin platfo
    
[^57]: 无需公平训练的公平分类器：一种受影响数据抽样方法

    Fair Classifiers Without Fair Training: An Influence-Guided Data Sampling Approach

    [https://arxiv.org/abs/2402.12789](https://arxiv.org/abs/2402.12789)

    在不实施公平训练算法的情况下学习公平分类器，通过抽样具有影响力的数据来逐步转移原始训练数据，从而提高公平性和准确性。

    

    一个公平的分类器应该确保来自不同群体的人们受益，而群体信息往往是敏感的，不适合模型训练。因此，在训练数据集中学习一个公平的分类器但排除敏感属性是很重要的。本文研究了学习公平分类器而不实现公平训练算法的方法，以避免可能泄露敏感信息。我们的理论分析验证了这种方法的可能性，即在具有适当分布偏移的数据集上进行传统训练可以同时减少公平差距的上限和模型泛化误差，表明公平性和准确性可以同步提高，只需简单地进行传统训练。然后，我们提出了一个可行的解决方案，通过抽样有影响力的数据逐步转移原始训练数据，在训练过程中不访问新数据的敏感属性。

    arXiv:2402.12789v1 Announce Type: cross  Abstract: A fair classifier should ensure the benefit of people from different groups, while the group information is often sensitive and unsuitable for model training. Therefore, learning a fair classifier but excluding sensitive attributes in the training dataset is important. In this paper, we study learning fair classifiers without implementing fair training algorithms to avoid possible leakage of sensitive information. Our theoretical analyses validate the possibility of this approach, that traditional training on a dataset with an appropriate distribution shift can reduce both the upper bound for fairness disparity and model generalization error, indicating that fairness and accuracy can be improved simultaneously with simply traditional training. We then propose a tractable solution to progressively shift the original training data during training by sampling influential data, where the sensitive attribute of new data is not accessed in s
    
[^58]: 推进GenAI辅助编程--GPT-4和GLM-4之间提示效率和代码质量的比较研究

    Advancing GenAI Assisted Programming--A Comparative Study on Prompt Efficiency and Code Quality Between GPT-4 and GLM-4

    [https://arxiv.org/abs/2402.12782](https://arxiv.org/abs/2402.12782)

    本研究通过比较GPT-4和GLM-4，发现最简单直接的提示策略能够产生最佳的代码生成结果，并且指出虽然GPT-4略优于GLM-4，但对于普通用户差异微乎其微。研究还展示了相对传统编码规范30到100倍的代码生成效率增加，并强调了GenAI辅助编码将引发编程领域范式转变的重要性。

    

    本研究旨在通过对GPT-4和GLM-4之间的比较分析，探讨利用GenAI作为编程工具的最佳实践。通过评估不同复杂性水平上的提示策略，我们发现最简单直接的提示策略产生了最佳的代码生成结果。此外，添加类似CoT的初步确认步骤将进一步提高成功率。我们的结果表明，虽然GPT-4在某种程度上优于GLM-4，但对于普通用户来说差异微乎其微。在我们简化的评估模型中，我们看到代码生成效率相对传统编码规范显著增加了30到100倍。我们的GenAI编码研讨会突显了本研究开发的提示方法的有效性和可访问性。我们观察到GenAI辅助编码将引发编程领域的范式转变，这需要开发人员承担新角色。

    arXiv:2402.12782v1 Announce Type: cross  Abstract: This study aims to explore the best practices for utilizing GenAI as a programming tool, through a comparative analysis between GPT-4 and GLM-4. By evaluating prompting strategies at different levels of complexity, we identify that simplest and straightforward prompting strategy yields best code generation results. Additionally, adding a CoT-like preliminary confirmation step would further increase the success rate. Our results reveal that while GPT-4 marginally outperforms GLM-4, the difference is minimal for average users. In our simplified evaluation model, we see a remarkable 30 to 100-fold increase in code generation efficiency over traditional coding norms. Our GenAI Coding Workshop highlights the effectiveness and accessibility of the prompting methodology developed in this study. We observe that GenAI-assisted coding would trigger a paradigm shift in programming landscape, which necessitates developers to take on new roles revo
    
[^59]: 生成模型优选提示的用户友好框架在文本到图像合成中的应用

    A User-Friendly Framework for Generating Model-Preferred Prompts in Text-to-Image Synthesis

    [https://arxiv.org/abs/2402.12760](https://arxiv.org/abs/2402.12760)

    提出了一种用户友好的框架，用于生成模型优选提示，在文本到图像合成中的应用。

    

    精心设计的提示已经证明能够指导文本到图像模型生成惊人的图像。虽然现有的提示工程方法可以提供高水平的指导，但是对于新手用户来说，通过手动输入提示来实现期望结果是具有挑战性的，这是因为新手用户输入的提示与模型优选提示之间存在差异。为了弥合用户输入行为和模型训练数据集之间的分布差距，我们首先构建了一个新颖的粗细粒度提示数据集(CFP)，并提出了一种新颖的用户友好的细粒度文本生成框架(UF-FGTG)用于自动提示优化。对于CFP，我们构建了一个新颖的文本到图像任务数据集，结合了粗糙和细粒度提示，以促进自动提示生成方法的发展。对于UF-FGTG，我们提出了一个新颖的框架，可以自动将用户输入的提示转换为模型优选提示。

    arXiv:2402.12760v1 Announce Type: cross  Abstract: Well-designed prompts have demonstrated the potential to guide text-to-image models in generating amazing images. Although existing prompt engineering methods can provide high-level guidance, it is challenging for novice users to achieve the desired results by manually entering prompts due to a discrepancy between novice-user-input prompts and the model-preferred prompts. To bridge the distribution gap between user input behavior and model training datasets, we first construct a novel Coarse-Fine Granularity Prompts dataset (CFP) and propose a novel User-Friendly Fine-Grained Text Generation framework (UF-FGTG) for automated prompt optimization. For CFP, we construct a novel dataset for text-to-image tasks that combines coarse and fine-grained prompts to facilitate the development of automated prompt generation methods. For UF-FGTG, we propose a novel framework that automatically translates user-input prompts into model-preferred promp
    
[^60]: 多模态大型语言模型的模型组合

    Model Composition for Multimodal Large Language Models

    [https://arxiv.org/abs/2402.12750](https://arxiv.org/abs/2402.12750)

    通过模型组合现有的多模态大型语言模型，提出了一种新范式，有效地保留了每个原始模型的模态理解能力，并引入了一种用于解决合并参数干扰和不匹配问题的方法。

    

    近期对多模态大型语言模型（MLLMs）的发展显示出了快速进展，朝着创建能够理解各种模态输入的多功能MLLMs的目标迈进。然而，现有方法通常依赖于与配对的多模态指令数据进行联合训练，这对资源要求高且难以扩展到新的模态。在本文中，我们提出了一种通过现有MLLMs的模型组合来创建一个新模型的新范式，该新模型保留了每个原始模型的模态理解能力。我们的基本实现NaiveMC通过重用模态编码器和合并LLM参数展示了这一范式的有效性。此外，我们引入了DAMC来解决在合并过程中的参数干扰和不匹配问题，从而提升了模型的性能。为促进该领域的研究，我们提出了MCUB，一个用于评估MLLMs理解能力的基准测试。

    arXiv:2402.12750v1 Announce Type: cross  Abstract: Recent developments in Multimodal Large Language Models (MLLMs) have shown rapid progress, moving towards the goal of creating versatile MLLMs that understand inputs from various modalities. However, existing methods typically rely on joint training with paired multimodal instruction data, which is resource-intensive and challenging to extend to new modalities. In this paper, we propose a new paradigm through the model composition of existing MLLMs to create a new model that retains the modal understanding capabilities of each original model. Our basic implementation, NaiveMC, demonstrates the effectiveness of this paradigm by reusing modality encoders and merging LLM parameters. Furthermore, we introduce DAMC to address parameter interference and mismatch issues during the merging process, thereby enhancing the model performance. To facilitate research in this area, we propose MCUB, a benchmark for assessing ability of MLLMs to unders
    
[^61]: Me LLaMA: 为医疗应用构建大型语言模型的基础

    Me LLaMA: Foundation Large Language Models for Medical Applications

    [https://arxiv.org/abs/2402.12749](https://arxiv.org/abs/2402.12749)

    Me LLaMA是一个医学领域的大型语言模型系列，通过持续预训练和指导调整在大型医学数据集上训练而成，其在零-shot和少-shot学习方面表现优于现有的医学语言模型和商业巨头ChatGPT。

    

    最近，诸如ChatGPT和LLaMA等大型语言模型(LLMs)在许多人工智能应用中展现出巨大的潜力。然而，它们在医学任务上的表现不够理想，并且可以通过在大型领域特定数据集上进行训练来进一步改进。本研究引入了Me LLaMA，一个医学LLM系列，包括基础模型- Me LLaMA 13/70B及其 chat-enhanced 版本- Me LLaMA 13/70B-chat，通过持续对LLaMA2进行预训练和指导调整，使用大规模医学数据开发而成。我们用于训练和评估的领域特定数据套件包括一个具有129B tokens的大规模持续预训练数据集，一个包含214k个样本的指导调整数据集，以及跨越14个数据集的六项任务的医学评估基准(MIBE)。我们使用MIBE进行的广泛评估显示，Me LLaMA模型在零-shot和少-shot学习方面超越了现有的开源医学LLMs，并且在商业巨头如ChatGPT上表现出色。

    arXiv:2402.12749v1 Announce Type: cross  Abstract: Recent large language models (LLMs) like ChatGPT and LLaMA have shown great promise in many AI applications. However, their performance on medical tasks is suboptimal and can be further improved by training on large domain-specific datasets. This study introduces Me LLaMA, a medical LLM family including foundation models - Me LLaMA 13/70B and their chat-enhanced versions - Me LLaMA 13/70B-chat, developed through the continual pre-training and instruction tuning of LLaMA2 using large medical data. Our domain-specific data suite for training and evaluation, includes a large-scale continual pre-training dataset with 129B tokens, an instruction tuning dataset with 214k samples, and a medical evaluation benchmark (MIBE) across six tasks with 14 datasets. Our extensive evaluation using MIBE shows that Me LLaMA models surpass existing open-source medical LLMs in zero-shot and few-shot learning and outperform commercial giants like ChatGPT on 
    
[^62]: 能否利用大型语言模型提供心理咨询？对GPT-4生成的对话进行角色扮演对话分析

    Can Large Language Models be Used to Provide Psychological Counselling? An Analysis of GPT-4-Generated Responses Using Role-play Dialogues

    [https://arxiv.org/abs/2402.12738](https://arxiv.org/abs/2402.12738)

    利用专家角色扮演对话数据进行研究发现，GPT-4生成的回复在心理辅导情境中与人类回复相竞争。

    

    arXiv:2402.12738v1 公告类型：交叉心理健康护理对现代社会构成日益严峻挑战。在此背景下，利用信息技术解决心理健康问题的研究激增，包括旨在开发咨询对话系统的研究。然而，有必要对使用大型语言模型的咨询对话系统的性能进行更多评估。本研究通过涉及专家辅导员的角色扮演情景收集了辅导对话数据，并针对辅导员的意图对话进行了标注。为了确定对话系统在现实世界辅导情景中的可行性，第三方辅导员在角色扮演对话数据中对人类辅导员和GPT-4生成的回复在相同情境下的恰当性进行了评估。评估结果分析表明，GPT-4生成的回复与人类的回复具有竞争力。

    arXiv:2402.12738v1 Announce Type: cross  Abstract: Mental health care poses an increasingly serious challenge to modern societies. In this context, there has been a surge in research that utilizes information technologies to address mental health problems, including those aiming to develop counseling dialogue systems. However, there is a need for more evaluations of the performance of counseling dialogue systems that use large language models. For this study, we collected counseling dialogue data via role-playing scenarios involving expert counselors, and the utterances were annotated with the intentions of the counselors. To determine the feasibility of a dialogue system in real-world counseling scenarios, third-party counselors evaluated the appropriateness of responses from human counselors and those generated by GPT-4 in identical contexts in role-play dialogue data. Analysis of the evaluation results showed that the responses generated by GPT-4 were competitive with those of human
    
[^63]: CST: 参数和内存高效迁移学习的校准侧调节

    CST: Calibration Side-Tuning for Parameter and Memory Efficient Transfer Learning

    [https://arxiv.org/abs/2402.12736](https://arxiv.org/abs/2402.12736)

    该论文介绍了一种轻量级的微调策略，称为校准侧调节，将成功应用于转换器的技术与ResNet相结合，以提高网络性能并保持平滑的训练过程。

    

    实现物体检测的普遍高准确性是非常具有挑战性的，在行业中目前的主要焦点在于检测特定类别的物体。然而，部署一个或多个物体检测网络需要一定量的GPU内存用于训练和存储容量用于推断。在资源受限的情况下如何有效地协调多个物体检测任务存在挑战。本文引入了一种轻量级微调策略，称为校准侧调节，它整合了适配器调节和侧调节的方面，以适应转换器中成功技术在ResNet上的使用。校准侧调节架构融合了最大过渡校准，利用少量额外参数增强网络性能同时保持平稳的训练过程。此外，本文还进行了

    arXiv:2402.12736v1 Announce Type: cross  Abstract: Achieving a universally high accuracy in object detection is quite challenging, and the mainstream focus in the industry currently lies on detecting specific classes of objects. However, deploying one or multiple object detection networks requires a certain amount of GPU memory for training and storage capacity for inference. This presents challenges in terms of how to effectively coordinate multiple object detection tasks under resource-constrained conditions. This paper introduces a lightweight fine-tuning strategy called Calibration side tuning, which integrates aspects of adapter tuning and side tuning to adapt the successful techniques employed in transformers for use with ResNet. The Calibration side tuning architecture that incorporates maximal transition calibration, utilizing a small number of additional parameters to enhance network performance while maintaining a smooth training process. Furthermore, this paper has conducted
    
[^64]: BMLP：用于异构序列推荐的行为感知MLP

    BMLP: Behavior-aware MLP for Heterogeneous Sequential Recommendation

    [https://arxiv.org/abs/2402.12733](https://arxiv.org/abs/2402.12733)

    提出了一种新颖的基于多层感知器的异构序列推荐方法BMLP，通过行为感知模块和购买意图感知模块捕捉用户的异构兴趣和购买意图。

    

    在真实的推荐场景中，用户往往具有不同类型的行为，比如点击和购买。现有研究方法表明，通过不同类型的行为可以捕捉用户的异构兴趣。然而，大多数多行为方法在学习不同行为之间的关系方面存在局限性。本文提出了一种新颖的基于多层感知器（MLP）的异构序列推荐方法，即行为感知多层感知器（BMLP）。具体而言，它包括两个主要模块，即异构兴趣感知（HIP）模块，通过行为类型和转换关系在多个粒度上建模行为，并购买意图感知（PIP）模块，该模块自适应地融合辅助行为的子序列以捕捉用户的购买意图。与主流序列模型相比，MLP在准确性方面有竞争力。

    arXiv:2402.12733v1 Announce Type: cross  Abstract: In real recommendation scenarios, users often have different types of behaviors, such as clicking and buying. Existing research methods show that it is possible to capture the heterogeneous interests of users through different types of behaviors. However, most multi-behavior approaches have limitations in learning the relationship between different behaviors. In this paper, we propose a novel multilayer perceptron (MLP)-based heterogeneous sequential recommendation method, namely behavior-aware multilayer perceptron (BMLP). Specifically, it has two main modules, including a heterogeneous interest perception (HIP) module, which models behaviors at multiple granularities through behavior types and transition relationships, and a purchase intent perception (PIP) module, which adaptively fuses subsequences of auxiliary behaviors to capture users' purchase intent. Compared with mainstream sequence models, MLP is competitive in terms of accu
    
[^65]: UMBCLU在SemEval-2024任务1A和1C中的表现：带有和不带有机器翻译的语义文本相关性

    UMBCLU at SemEval-2024 Task 1A and 1C: Semantic Textual Relatedness with and without machine translation

    [https://arxiv.org/abs/2402.12730](https://arxiv.org/abs/2402.12730)

    使用机器翻译和大型语言模型，本文开发了用于非洲和亚洲语言语义文本相关性任务的两种模型，取得了比部分官方基准更好的效果。

    

    这篇论文描述了我们为SemEval-2024任务1开发的系统，“非洲和亚洲语言的语义文本相关性”。 该任务的目标是构建一个能够识别目标语言中属于非洲和亚洲语言集合的两个句子之间的语义文本相关性（STR）的模型。 我们参与了子任务A和C，并探索了利用大型语言模型（LLMs）进行监督和跨语言训练。 预训练的大型语言模型已被广泛用于机器翻译和语义相似性。 使用机器翻译和句子嵌入LLMs的组合，我们为子任务A开发了一个统一的STR模型，TranSem，并对STR数据上的T5系列模型进行了微调，用于子任务C的FineSem。 我们在子任务A中7种语言的模型结果比3种语言的官方基准更好，而与其他4种语言的基准相当。

    arXiv:2402.12730v1 Announce Type: cross  Abstract: This paper describes the system we developed for SemEval-2024 Task 1, "Semantic Textual Relatedness for African and Asian Languages." The aim of the task is to build a model that can identify semantic textual relatedness (STR) between two sentences of a target language belonging to a collection of African and Asian languages. We participated in Subtasks A and C and explored supervised and cross-lingual training leveraging large language models (LLMs). Pre-trained large language models have been extensively used for machine translation and semantic similarity. Using a combination of machine translation and sentence embedding LLMs, we developed a unified STR model, TranSem, for subtask A and fine-tuned the T5 family of models on the STR data, FineSem, for use in subtask C. Our model results for 7 languages in subtask A were better than the official baseline for 3 languages and on par with the baseline for the remaining 4 languages. Our m
    
[^66]: 可扩展可靠的多尺度神经过程嵌入知识用于智能故障检测的深度迁移学习

    Scalable and reliable deep transfer learning for intelligent fault detection via multi-scale neural processes embedded with knowledge

    [https://arxiv.org/abs/2402.12729](https://arxiv.org/abs/2402.12729)

    提出了一种名为GTNP的神经过程深度迁移学习方法，通过特征传输策略弥合源域和目标域的数据分布差异，解决了数据稀缺和缺乏可靠性分析的问题

    

    深度迁移学习（DTL）是智能故障检测（IFD）领域中的一种基本方法，旨在减轻训练集（源域）和测试集（目标域）之间数据分布不一致导致方法性能下降的问题。本文提出了一种名为基于神经过程的图卷积网络（GTNP）的新颖的DTL方法，可以解决数据分布不一致和可靠性问题。

    arXiv:2402.12729v1 Announce Type: cross  Abstract: Deep transfer learning (DTL) is a fundamental method in the field of Intelligent Fault Detection (IFD). It aims to mitigate the degradation of method performance that arises from the discrepancies in data distribution between training set (source domain) and testing set (target domain). Considering the fact that fault data collection is challenging and certain faults are scarce, DTL-based methods face the limitation of available observable data, which reduces the detection performance of the methods in the target domain. Furthermore, DTL-based methods lack comprehensive uncertainty analysis that is essential for building reliable IFD systems. To address the aforementioned problems, this paper proposes a novel DTL-based method known as Neural Processes-based deep transfer learning with graph convolution network (GTNP). Feature-based transfer strategy of GTNP bridges the data distribution discrepancies of source domain and target domain 
    
[^67]: 基于大型语言模型的模态感知集成用于基于知识的视觉问答

    Modality-Aware Integration with Large Language Models for Knowledge-based Visual Question Answering

    [https://arxiv.org/abs/2402.12728](https://arxiv.org/abs/2402.12728)

    提出了一种模态感知的LLM集成方法（MAIL）用于针对KVQA，通过细致地利用多模态知识来处理图像理解和知识推理。

    

    知识驱动的视觉问答（KVQA）已被广泛研究，以利用外部知识如知识图谱（KG）来回答视觉问题。尽管已提出几种尝试利用大型语言模型（LLMs）作为隐含知识源，但由于LLMs可能生成幻觉，因此仍然具有挑战性。此外，多种知识来源，例如图像、知识图谱和LLMs，不能轻易对齐以应对复杂场景。为了解决这些问题，我们提出了一种针对KVQA的新颖的具有模态感知的LLM集成方法（MAIL）。它精心利用多模态知识进行图像理解和知识推理。具体而言，（i）我们提出了一种使用LLMs的两阶段提示策略，将图像密集地融入带有详细视觉特征的场景图中；（ii）我们通过将提到的实体与外部事实联系起来构建一个耦合的概念图；（iii）设计了一个定制的伪孪生图中介融合。

    arXiv:2402.12728v1 Announce Type: cross  Abstract: Knowledge-based visual question answering (KVQA) has been extensively studied to answer visual questions with external knowledge, e.g., knowledge graphs (KGs). While several attempts have been proposed to leverage large language models (LLMs) as an implicit knowledge source, it remains challenging since LLMs may generate hallucinations. Moreover, multiple knowledge sources, e.g., images, KGs and LLMs, cannot be readily aligned for complex scenarios. To tackle these, we present a novel modality-aware integration with LLMs for KVQA (MAIL). It carefully leverages multimodal knowledge for both image understanding and knowledge reasoning. Specifically, (i) we propose a two-stage prompting strategy with LLMs to densely embody the image into a scene graph with detailed visual features; (ii) We construct a coupled concept graph by linking the mentioned entities with external facts. (iii) A tailored pseudo-siamese graph medium fusion is designe
    
[^68]: 扩散后验抽样在计算上是难以解决的

    Diffusion Posterior Sampling is Computationally Intractable

    [https://arxiv.org/abs/2402.12727](https://arxiv.org/abs/2402.12727)

    我们证明了后验抽样在计算上是难以解决的：在加密学中最基本的假设下——单向函数存在的假设下，存在一些实例，对于这些实例，每个算法都需要超多项式时间，即使无条件抽样可以证明是快速的。

    

    扩散模型是学习和从分布$p(x)$中抽样的一种非常有效的方法。在后验抽样中，人们还会给出一个测量模型$p(y \mid x)$和一个测量$y$，希望从$p(x \mid y)$中抽样。后验抽样对于诸如修补、超分辨率和MRI重建等任务非常有用，因此一些最近的工作已经给出了启发式近似算法；但没有一个已知能在多项式时间内收敛到正确的分布。

    arXiv:2402.12727v1 Announce Type: cross  Abstract: Diffusion models are a remarkably effective way of learning and sampling from a distribution $p(x)$. In posterior sampling, one is also given a measurement model $p(y \mid x)$ and a measurement $y$, and would like to sample from $p(x \mid y)$. Posterior sampling is useful for tasks such as inpainting, super-resolution, and MRI reconstruction, so a number of recent works have given algorithms to heuristically approximate it; but none are known to converge to the correct distribution in polynomial time.   In this paper we show that posterior sampling is \emph{computationally intractable}: under the most basic assumption in cryptography -- that one-way functions exist -- there are instances for which \emph{every} algorithm takes superpolynomial time, even though \emph{unconditional} sampling is provably fast. We also show that the exponential-time rejection sampling algorithm is essentially optimal under the stronger plausible assumption 
    
[^69]: PAC-FNO：并行结构全组分傅立叶神经算子用于识别低质量图像

    PAC-FNO: Parallel-Structured All-Component Fourier Neural Operators for Recognizing Low-Quality Images

    [https://arxiv.org/abs/2402.12721](https://arxiv.org/abs/2402.12721)

    提出了一个新颖的神经网络模型 PAC-FNO，通过在频域操作可以处理不同分辨率的图像，解决了传统方法在处理这类问题上的计算成本高的挑战。

    

    开发图像识别模型的标准做法是在特定图像分辨率上训练模型，然后部署它。然而，在现实推理中，模型经常遇到与训练集中不同分辨率的图像和/或受到自然变化的影响，例如天气变化、噪声类型和压缩伪影。传统解决方案涉及为不同分辨率或输入变化训练多个模型，但这些方法在实践中计算成本高，因此不可扩展。为此，我们提出了一种新颖的神经网络模型，即并行结构和全组分傅立叶神经算子（PAC-FNO），来解决这个问题。与传统的前馈神经网络不同，PAC-FNO在频域进行操作，使其能够在单个模型内处理不同分辨率的图像。我们还提出了一个两阶段算法，以最小的修改训练PAC-FNO。

    arXiv:2402.12721v1 Announce Type: cross  Abstract: A standard practice in developing image recognition models is to train a model on a specific image resolution and then deploy it. However, in real-world inference, models often encounter images different from the training sets in resolution and/or subject to natural variations such as weather changes, noise types and compression artifacts. While traditional solutions involve training multiple models for different resolutions or input variations, these methods are computationally expensive and thus do not scale in practice. To this end, we propose a novel neural network model, parallel-structured and all-component Fourier neural operator (PAC-FNO), that addresses the problem. Unlike conventional feed-forward neural networks, PAC-FNO operates in the frequency domain, allowing it to handle images of varying resolutions within a single model. We also propose a two-stage algorithm for training PAC-FNO with a minimal modification to the orig
    
[^70]: 重新审视神经网络水印的信息容量：上界估计与更多

    Revisiting the Information Capacity of Neural Network Watermarks: Upper Bound Estimation and Beyond

    [https://arxiv.org/abs/2402.12720](https://arxiv.org/abs/2402.12720)

    本文从信息理论的角度研究了深度神经网络水印的容量，提出了一种新的容量定义类似于信道容量，设计了一种算法来紧密估计其上界并提出了一种通用的非侵入式方法来安全传输超出容量的身份信息。

    

    为了追踪深度神经网络的版权，所有者可以将其身份信息嵌入到模型中作为水印。水印的容量量化了可以从带有水印模型中验证的最大信息量。当前关于容量的研究主要集中在普通去除攻击下的所有权验证准确性，并未捕捉到鲁棒性和保真度之间的关系。本文从信息理论的角度研究了深度神经网络水印的容量。我们提出了一种类似信道容量的深度神经网络水印容量的新定义，分析了其属性，并设计了一种算法，能在对抗性覆写下紧密估计其上界。我们还提出了一种通用的非侵入式方法，通过多轮所有权验证来安全传输超出容量的身份信息。我们的观察结果提供了证据。

    arXiv:2402.12720v1 Announce Type: cross  Abstract: To trace the copyright of deep neural networks, an owner can embed its identity information into its model as a watermark. The capacity of the watermark quantify the maximal volume of information that can be verified from the watermarked model. Current studies on capacity focus on the ownership verification accuracy under ordinary removal attacks and fail to capture the relationship between robustness and fidelity. This paper studies the capacity of deep neural network watermarks from an information theoretical perspective. We propose a new definition of deep neural network watermark capacity analogous to channel capacity, analyze its properties, and design an algorithm that yields a tight estimation of its upper bound under adversarial overwriting. We also propose a universal non-invasive method to secure the transmission of the identity message beyond capacity by multiple rounds of ownership verification. Our observations provide evi
    
[^71]: 从云端到边缘：重新思考低资源设计挑战的生成人工智能

    From Cloud to Edge: Rethinking Generative AI for Low-Resource Design Challenges

    [https://arxiv.org/abs/2402.12702](https://arxiv.org/abs/2402.12702)

    论文探讨了将生成人工智能调整以适应边缘资源受限环境的潜力、挑战和创新方法，以在低资源环境中高效创建设计解决方案。

    

    生成人工智能（AI）在技术的各个方面展现出巨大的潜力，包括设计。然而，由于对资源的沉重需求，它通常在大型计算基础架构上进行训练，并经常作为基于云端的服务提供。在这篇立场论文中，我们考虑了在边缘进行设计的生成AI的潜力、挑战和有希望的方法，即在资源受限的环境中，其中的内存、计算、能耗（电池）和网络连接可能有限。调整生成AI以适应这样的设置涉及克服重大障碍，主要是如何简化复杂模型以在低资源环境中有效运行。这需要在模型压缩、高效算法设计以及可能甚至利用边缘计算方面提出创新性方法。目标是利用生成AI的力量为设计问题创造量身定制的解决方案。

    arXiv:2402.12702v1 Announce Type: new  Abstract: Generative Artificial Intelligence (AI) has shown tremendous prospects in all aspects of technology, including design. However, due to its heavy demand on resources, it is usually trained on large computing infrastructure and often made available as a cloud-based service. In this position paper, we consider the potential, challenges, and promising approaches for generative AI for design on the edge, i.e., in resource-constrained settings where memory, compute, energy (battery) and network connectivity may be limited. Adapting generative AI for such settings involves overcoming significant hurdles, primarily in how to streamline complex models to function efficiently in low-resource environments. This necessitates innovative approaches in model compression, efficient algorithmic design, and perhaps even leveraging edge computing. The objective is to harness the power of generative AI in creating bespoke solutions for design problems, such
    
[^72]: XRL-Bench：用于评估和比较可解释强化学习技术的基准

    XRL-Bench: A Benchmark for Evaluating and Comparing Explainable Reinforcement Learning Techniques

    [https://arxiv.org/abs/2402.12685](https://arxiv.org/abs/2402.12685)

    XRL-Bench是一个用于评估和比较可解释强化学习技术的统一标准化基准，旨在解决状态解释方法在RL中的重要性评估框架不足的问题。

    

    强化学习（RL）已在不同领域展现出巨大潜力，然而理解其决策过程，特别是在现实世界场景中理性和安全至关重要的情况下，仍然是一个持续挑战。本文着手于可解释强化学习（XRL），这是可解释人工智能（XAI）的一个子领域，旨在揭示RL模型的复杂性。我们关注状态解释技术，这是XRL方法中一个至关重要的子集，因为它们揭示了影响代理程序在任何给定时间采取行动的潜在因素。尽管它们的重要作用，缺乏一个统一的评估框架阻碍了对它们准确性和有效性的评估。为了解决这个问题，我们介绍了XRL-Bench，一种统一的标准化基准，专为评估和比较XRL方法而设计，包括三个主要模块：标准RL环境、基于状态重要性的解释器和标准评估器。XRL-Bench支持载入模型和评估器，详细说明了适用于强化学习任务的各种技术。

    arXiv:2402.12685v1 Announce Type: new  Abstract: Reinforcement Learning (RL) has demonstrated substantial potential across diverse fields, yet understanding its decision-making process, especially in real-world scenarios where rationality and safety are paramount, is an ongoing challenge. This paper delves in to Explainable RL (XRL), a subfield of Explainable AI (XAI) aimed at unravelling the complexities of RL models. Our focus rests on state-explaining techniques, a crucial subset within XRL methods, as they reveal the underlying factors influencing an agent's actions at any given time. Despite their significant role, the lack of a unified evaluation framework hinders assessment of their accuracy and effectiveness. To address this, we introduce XRL-Bench, a unified standardized benchmark tailored for the evaluation and comparison of XRL methods, encompassing three main modules: standard RL environments, explainers based on state importance, and standard evaluators. XRL-Bench supports
    
[^73]: FinBen：大型语言模型的全面财务基准

    The FinBen: An Holistic Financial Benchmark for Large Language Models

    [https://arxiv.org/abs/2402.12659](https://arxiv.org/abs/2402.12659)

    本文引入了FinBen，这是第一个专门设计用于彻底评估LLMs在金融领域能力的全面开源评估基准，对15个代表性LLMs进行评估，揭示了它们的优势和局限性。

    

    LLMs已经改变了自然语言处理，并显示出在各个领域具有潜力，但由于缺乏彻底的评估和金融任务的复杂性，它们在金融领域的潜力尚未得到充分开发。本文介绍了FinBen，第一个全面的开源评估基准，专门设计用于彻底评估LLMs在金融领域的能力。FinBen包括23种金融任务的35个数据集，这些任务根据卡特尔-霍恩-卡罗尔理论的灵感组织成三个不同难度的谱，以评估LLMs在归纳推理、联想记忆、数量推理、晶体智力等方面的认知能力。我们对15个代表性LLMs（包括GPT-4、ChatGPT和最新的Gemini）进行了评估，揭示了它们的优势和局限性。

    arXiv:2402.12659v1 Announce Type: cross  Abstract: LLMs have transformed NLP and shown promise in various fields, yet their potential in finance is underexplored due to a lack of thorough evaluations and the complexity of financial tasks. This along with the rapid development of LLMs, highlights the urgent need for a systematic financial evaluation benchmark for LLMs. In this paper, we introduce FinBen, the first comprehensive open-sourced evaluation benchmark, specifically designed to thoroughly assess the capabilities of LLMs in the financial domain. FinBen encompasses 35 datasets across 23 financial tasks, organized into three spectrums of difficulty inspired by the Cattell-Horn-Carroll theory, to evaluate LLMs' cognitive abilities in inductive reasoning, associative memory, quantitative reasoning, crystallized intelligence, and more. Our evaluation of 15 representative LLMs, including GPT-4, ChatGPT, and the latest Gemini, reveals insights into their strengths and limitations withi
    
[^74]: HyperMoE: 通过专家之间的知识传递实现更好的专家混合

    HyperMoE: Towards Better Mixture of Experts via Transferring Among Experts

    [https://arxiv.org/abs/2402.12656](https://arxiv.org/abs/2402.12656)

    HyperMoE通过Hypernetworks框架整合知识传递的概念，解决了在专家选择过程中专家知识稀疏性和可用性之间的矛盾。

    

    混合专家(MoE)在语言模型中被证明有效地增强了模型的能力，通过动态地将每个输入标记路由到特定的专家子集进行处理。尽管取得了成功，但大多数现有方法在专家知识的稀疏性和可用性之间面临挑战：通过增加对专家知识的使用来增强性能，往往会导致在专家选择过程中稀疏度减少。为了缓解这一矛盾，我们提出了HyperMoE，这是一个建立在Hypernetworks之上的新颖MoE框架。该框架将MoE的计算过程与多任务学习中的知识传递概念进行了集成。基于未选择专家信息生成的特定模块作为补充信息，允许未被选中的专家的知识在保持选择稀疏性的同时被使用。

    arXiv:2402.12656v1 Announce Type: cross  Abstract: The Mixture of Experts (MoE) for language models has been proven effective in augmenting the capacity of models by dynamically routing each input token to a specific subset of experts for processing. Despite the success, most existing methods face a challenge for balance between sparsity and the availability of expert knowledge: enhancing performance through increased use of expert knowledge often results in diminishing sparsity during expert selection. To mitigate this contradiction, we propose HyperMoE, a novel MoE framework built upon Hypernetworks. This framework integrates the computational processes of MoE with the concept of knowledge transferring in multi-task learning. Specific modules generated based on the information of unselected experts serve as supplementary information, which allows the knowledge of experts not selected to be used while maintaining selection sparsity. Our comprehensive empirical evaluations across multi
    
[^75]: 通过坐标搜索算法训练人工神经网络

    Training Artificial Neural Networks by Coordinate Search Algorithm

    [https://arxiv.org/abs/2402.12646](https://arxiv.org/abs/2402.12646)

    通过提出的高效版本的非梯度坐标搜索（CS）算法，我们可以训练神经网络，解决了需要可微激活函数和同时优化多个非可微损失函数的问题。

    

    训练人工神经网络在机器学习中是一个具有挑战性和关键性的问题。 尽管梯度下降等基于梯度的学习方法在训练神经网络方面有效，但它们也存在一些限制。 例如，它们需要可微激活函数，并且不能基于多个独立的非可微损失函数同时优化模型；例如，在测试期间使用的 F1 分数可以在训练期间使用，当采用无梯度优化算法时。 此外，任何 DNN 中的训练可能只需很少量的训练数据集。 为了解决这些问题，我们提出了非梯度坐标搜索（CS）算法的高效版本，它是通用模式搜索方法的一种实例，用于训练神经网络。

    arXiv:2402.12646v1 Announce Type: cross  Abstract: Training Artificial Neural Networks poses a challenging and critical problem in machine learning. Despite the effectiveness of gradient-based learning methods, such as Stochastic Gradient Descent (SGD), in training neural networks, they do have several limitations. For instance, they require differentiable activation functions, and cannot optimize a model based on several independent non-differentiable loss functions simultaneously; for example, the F1-score, which is used during testing, can be used during training when a gradient-free optimization algorithm is utilized. Furthermore, the training in any DNN can be possible with a small size of the training dataset. To address these concerns, we propose an efficient version of the gradient-free Coordinate Search (CS) algorithm, an instance of General Pattern Search methods, for training neural networks. The proposed algorithm can be used with non-differentiable activation functions and
    
[^76]: 机器学习在数据变化方面的综合评论：跨领域透视

    A Comprehensive Review of Machine Learning Advances on Data Change: A Cross-Field Perspective

    [https://arxiv.org/abs/2402.12627](https://arxiv.org/abs/2402.12627)

    该综述将领域转移和概念漂移重新归为一个单一的研究问题，即数据变化问题，系统地总结了这两个研究领域中最新的方法。

    

    近期的人工智能（AI）技术在各个学术领域和行业都展现了显著的发展，然而，在现实世界中，动态数据导致了部署AI模型的主要挑战。意外的数据变化会导致AI模型性能严重下降。我们确定了两个主要相关研究领域，领域转移和概念漂移，根据数据变化的设定。虽然这两个流行的研究领域的目标是解决分布偏移和非平稳数据流问题，但基本属性仍然相似，这也鼓励采用类似的技术方法。在这篇综述中，我们将领域转移和概念漂移重新组合成一个单一的研究问题，即数据变化问题，并系统地概述了这两个研究领域中最新方法。我们提出了一个三阶段问题分类方案，以将这两个技术领域的关键思想联系起来。

    arXiv:2402.12627v1 Announce Type: cross  Abstract: Recent artificial intelligence (AI) technologies show remarkable evolution in various academic fields and industries. However, in the real world, dynamic data lead to principal challenges for deploying AI models. An unexpected data change brings about severe performance degradation in AI models. We identify two major related research fields, domain shift and concept drift according to the setting of the data change. Although these two popular research fields aim to solve distribution shift and non-stationary data stream problems, the underlying properties remain similar which also encourages similar technical approaches. In this review, we regroup domain shift and concept drift into a single research problem, namely the data change problem, with a systematic overview of state-of-the-art methods in the two research fields. We propose a three-phase problem categorization scheme to link the key ideas in the two technical fields. We thus p
    
[^77]: 高效参数挖掘和冻结用于连续目标检测

    Efficient Parameter Mining and Freezing for Continual Object Detection

    [https://arxiv.org/abs/2402.12624](https://arxiv.org/abs/2402.12624)

    提出了在增量目标检测场景中利用高效的层级参数隔离方式，可以帮助网络保持检测器性能，并在对象检测模型内促进增量学习。

    

    持续目标检测对于使智能代理能够在现实环境中与人类进行积极互动至关重要。尽管参数隔离策略在持续学习分类的背景下已被广泛探讨，但在增量目标检测场景中尚未得到充分利用。受先前研究聚焦于挖掘单个神经元响应以及整合最近神经剪枝发展的启发，我们提出了高效的方法来识别哪些层对于网络来说是最重要的，以在顺序更新中维持检测器性能。所呈现的发现突显了在目标检测模型内进行层级参数隔离以促进增量学习的重大优势，为未来研究和在现实场景中应用提供了有前途的途径。

    arXiv:2402.12624v1 Announce Type: cross  Abstract: Continual Object Detection is essential for enabling intelligent agents to interact proactively with humans in real-world settings. While parameter-isolation strategies have been extensively explored in the context of continual learning for classification, they have yet to be fully harnessed for incremental object detection scenarios. Drawing inspiration from prior research that focused on mining individual neuron responses and integrating insights from recent developments in neural pruning, we proposed efficient ways to identify which layers are the most important for a network to maintain the performance of a detector across sequential updates. The presented findings highlight the substantial advantages of layer-level parameter isolation in facilitating incremental learning within object detection models, offering promising avenues for future research and application in real-world scenarios.
    
[^78]: 生成式人工智能安全：挑战与对策

    Generative AI Security: Challenges and Countermeasures

    [https://arxiv.org/abs/2402.12617](https://arxiv.org/abs/2402.12617)

    生成式人工智能的安全挑战及对策研究。

    

    arXiv:2402.12617v1 公告类型：跨领域 摘要：生成式人工智能在许多行业的不断扩展引发了人们的兴奋和增加的关注。本文深入探讨了生成式人工智能所带来的独特安全挑战，并概述了管理这些风险的潜在研究方向。

    arXiv:2402.12617v1 Announce Type: cross  Abstract: Generative AI's expanding footprint across numerous industries has led to both excitement and increased scrutiny. This paper delves into the unique security challenges posed by Generative AI, and outlines potential research directions for managing these risks.
    
[^79]: 患者中心知识图谱：当前方法、挑战和应用的调查

    Patient-Centric Knowledge Graphs: A Survey of Current Methods, Challenges, and Applications

    [https://arxiv.org/abs/2402.12608](https://arxiv.org/abs/2402.12608)

    患者中心知识图谱（PCKGs）代表医疗保健中的重要转变，通过整合各种类型的健康数据，实现更加个性化和有效的患者护理。

    

    患者中心知识图谱（PCKGs）代表了医疗保健中的重要转变，专注于通过以整体和多维方式映射患者的健康信息，实现个性化患者护理。PCKGs整合各种类型的健康数据，为医护人员提供全面了解患者健康状况的能力，从而实现更加个性化和有效的护理。本文综述了与PCKGs相关的方法、挑战和机会，重点关注它们在整合不同医疗数据和通过统一的健康视角增强患者护理方面的作用。此外，该综述还讨论了PCKG开发的复杂性，包括本体设计、数据整合技术、知识提取和知识结构化表征。它强调了在构建中至关重要的推理、语义搜索和推理机制等先进技术。

    arXiv:2402.12608v1 Announce Type: new  Abstract: Patient-Centric Knowledge Graphs (PCKGs) represent an important shift in healthcare that focuses on individualized patient care by mapping the patient's health information in a holistic and multi-dimensional way. PCKGs integrate various types of health data to provide healthcare professionals with a comprehensive understanding of a patient's health, enabling more personalized and effective care. This literature review explores the methodologies, challenges, and opportunities associated with PCKGs, focusing on their role in integrating disparate healthcare data and enhancing patient care through a unified health perspective. In addition, this review also discusses the complexities of PCKG development, including ontology design, data integration techniques, knowledge extraction, and structured representation of knowledge. It highlights advanced techniques such as reasoning, semantic search, and inference mechanisms essential in constructin
    
[^80]: 基于图的虚拟传感：来自稀疏和部分多变量观测的方法

    Graph-based Virtual Sensing from Sparse and Partial Multivariate Observations

    [https://arxiv.org/abs/2402.12598](https://arxiv.org/abs/2402.12598)

    本文提出了一种基于图的虚拟传感方法，通过利用相关变量之间的依赖关系，设计了GgNet架构，用于推断未观测信道的值。

    

    虚拟传感技术允许通过利用来自不同位置的物理传感器的时空测量来推断新位置的信号。然而，由于成本或其他限制导致传感器覆盖范围变得稀疏，无法利用物理接近性支持插值。本文通过利用目标变量与一组相关变量（协变量）之间的依赖关系来克服这一挑战，这些协变量可以经常与感兴趣的每个位置相关联。从这个角度来看，协变量提供了部分可观测性，问题在于通过利用其他位置的观测结果推断未观测信道的值，以了解这些变量的相关性如何。我们引入了一种新颖的基于图的方法来利用这种关系，并设计了一个名为GgNet的图深度学习架构来实现该框架。提出的方法依赖于p

    arXiv:2402.12598v1 Announce Type: cross  Abstract: Virtual sensing techniques allow for inferring signals at new unmonitored locations by exploiting spatio-temporal measurements coming from physical sensors at different locations. However, as the sensor coverage becomes sparse due to costs or other constraints, physical proximity cannot be used to support interpolation. In this paper, we overcome this challenge by leveraging dependencies between the target variable and a set of correlated variables (covariates) that can frequently be associated with each location of interest. From this viewpoint, covariates provide partial observability, and the problem consists of inferring values for unobserved channels by exploiting observations at other locations to learn how such variables can correlate. We introduce a novel graph-based methodology to exploit such relationships and design a graph deep learning architecture, named GgNet, implementing the framework. The proposed approach relies on p
    
[^81]: FairProof：神经网络的机密和可认证公平性

    FairProof : Confidential and Certifiable Fairness for Neural Networks

    [https://arxiv.org/abs/2402.12572](https://arxiv.org/abs/2402.12572)

    FairProof提出了一种使用零知识证明来公开验证神经网络模型公平性的系统，同时保持机密性，并提出了适用于ZKPs的全连接神经网络的公平性认证算法。

    

    机器学习模型在社会应用中的使用越来越普遍，然而法律和隐私问题要求这些模型往往需要保密。因此，消费者对这些模型的公平性属性越来越不信任，消费者通常是模型预测的接收者。为此，我们提出了FairProof - 一种系统，使用零知识证明（一种密码原语）来公开验证模型的公平性，同时保持机密性。我们还提出了一个适合于ZKPs的全连接神经网络的公平性认证算法，并在该系统中使用。我们在Gnark中实现了FairProof，并通过实证证明了我们的系统是实际可行的。

    arXiv:2402.12572v1 Announce Type: cross  Abstract: Machine learning models are increasingly used in societal applications, yet legal and privacy concerns demand that they very often be kept confidential. Consequently, there is a growing distrust about the fairness properties of these models in the minds of consumers, who are often at the receiving end of model predictions. To this end, we propose FairProof - a system that uses Zero-Knowledge Proofs (a cryptographic primitive) to publicly verify the fairness of a model, while maintaining confidentiality. We also propose a fairness certification algorithm for fully-connected neural networks which is befitting to ZKPs and is used in this system. We implement FairProof in Gnark and demonstrate empirically that our system is practically feasible.
    
[^82]: 信心至关重要：重新审视大型语言模型的内在自我校正能力

    Confidence Matters: Revisiting Intrinsic Self-Correction Capabilities of Large Language Models

    [https://arxiv.org/abs/2402.12563](https://arxiv.org/abs/2402.12563)

    本文研究了大型语言模型的内在自我校正能力，并提出了一个“如果-否则”（IoE）提示框架，帮助模型评估自身“信心”并进行自我校正。

    

    大型语言模型（LLMs）的最近成功激发了对它们自我校正能力的越来越多的兴趣。本文对LLMs的内在自我校正进行了全面调查，试图解决关于其可行性的持续争论。我们的研究确定了一个重要的潜在因素 - LLMs的“信心” - 在自我校正过程中。忽视这一因素可能导致模型过度批评自己，从而导致对自校正效果的可靠结论不准确。我们实验观察到LLMs具有理解其自身回应“信心”的能力。这激励我们开发了一个“如果-否则”（IoE）提示框架，旨在引导LLMs评估其自身“信心”，促进内在自我校正。我们进行了大量实验证明，我们基于IoE的提示可以实现一

    arXiv:2402.12563v1 Announce Type: cross  Abstract: The recent success of Large Language Models (LLMs) has catalyzed an increasing interest in their self-correction capabilities. This paper presents a comprehensive investigation into the intrinsic self-correction of LLMs, attempting to address the ongoing debate about its feasibility. Our research has identified an important latent factor - the ``confidence'' of LLMs - during the self-correction process. Overlooking this factor may cause the models to over-criticize themselves, resulting in unreliable conclusions regarding the efficacy of self-correction. We have experimentally observed that LLMs possess the capability to understand the ``confidence'' in their own responses. It motivates us to develop an ``If-or-Else'' (IoE) prompting framework, designed to guide LLMs in assessing their own ``confidence'', facilitating intrinsic self-corrections. We conduct extensive experiments and demonstrate that our IoE-based Prompt can achieve a co
    
[^83]: CausalGym：在语言任务上对因果解释方法进行基准测试

    CausalGym: Benchmarking causal interpretability methods on linguistic tasks

    [https://arxiv.org/abs/2402.12560](https://arxiv.org/abs/2402.12560)

    CausalGym介绍了在语言任务中基准测试解释方法影响模型行为的能力。研究表明DAS方法胜过其他方法，并用它来研究了pythia-1b中的两个困难语言现象的学习轨迹。

    

    语言模型（LMs）已被证明是心理语言学研究的强大工具，但大多数先前的研究集中在纯行为测量（例如，惊奇比较）。同时，模型可解释性的研究已开始阐明塑造LM行为的抽象因果机制。为了帮助将这些研究领域更紧密地联系在一起，我们推出了CausalGym。我们改编并扩展了SyntaxGym任务套件，以基准测试解释方法影响模型行为的能力。为了说明CausalGym的用途，我们研究了pythia模型（从14M到6.9B）并评估了广泛解释方法的因果有效性，包括线性探针和分布对齐搜索（DAS）。我们发现DAS优于其他方法，因此我们使用它来研究pythia-1b中两个困难的语言现象的学习轨迹：负极性项许可和填充-间隙d。

    arXiv:2402.12560v1 Announce Type: cross  Abstract: Language models (LMs) have proven to be powerful tools for psycholinguistic research, but most prior work has focused on purely behavioural measures (e.g., surprisal comparisons). At the same time, research in model interpretability has begun to illuminate the abstract causal mechanisms shaping LM behavior. To help bring these strands of research closer together, we introduce CausalGym. We adapt and expand the SyntaxGym suite of tasks to benchmark the ability of interpretability methods to causally affect model behaviour. To illustrate how CausalGym can be used, we study the pythia models (14M--6.9B) and assess the causal efficacy of a wide range of interpretability methods, including linear probing and distributed alignment search (DAS). We find that DAS outperforms the other methods, and so we use it to study the learning trajectory of two difficult linguistic phenomena in pythia-1b: negative polarity item licensing and filler--gap d
    
[^84]: 在GPS受阻的战场环境中使用立体视觉和深度学习的基于地标的定位

    Landmark-based Localization using Stereo Vision and Deep Learning in GPS-Denied Battlefield Environment

    [https://arxiv.org/abs/2402.12551](https://arxiv.org/abs/2402.12551)

    提出了一种在非GPS战场环境中使用立体视觉和深度学习的基于地标的定位方法

    

    在战场环境中进行定位越来越具有挑战性，因为GPS连接通常受阻或不可靠，而在恶劣的战场地形中部署用于定位的锚节点可能会很困难。现有的无线网络定位方法依赖于基于无线电的锚定节点及其平均跳跃距离，这在动态和稀疏的无线网络拓扑中存在精度和稳定性问题。基于视觉的方法如SLAM和视觉里程计使用昂贵的传感器融合技术进行地图生成和姿态估计。本文提出了一种在非GPS战场环境中只利用被动摄像头传感器并考虑自然存在或人工设置的地标作为锚的定位新框架。所提出的方法利用定制校准的立体视觉摄像头进行距离估计，并使用经我们实际数据集训练和微调的YOLOv8s模型。

    arXiv:2402.12551v1 Announce Type: cross  Abstract: Localization in a battlefield environment is increasingly challenging as GPS connectivity is often denied or unreliable, and physical deployment of anchor nodes across wireless networks for localization can be difficult in hostile battlefield terrain. Existing range-free localization methods rely on radio-based anchors and their average hop distance which suffers from accuracy and stability in dynamic and sparse wireless network topology. Vision-based methods like SLAM and Visual Odometry use expensive sensor fusion techniques for map generation and pose estimation. This paper proposes a novel framework for localization in non-GPS battlefield environments using only the passive camera sensors and considering naturally existing or artificial landmarks as anchors. The proposed method utilizes a customcalibrated stereo vision camera for distance estimation and the YOLOv8s model, which is trained and fine-tuned with our real-world dataset 
    
[^85]: 在预训练数据中的平行结构实现上下文学习

    Parallel Structures in Pre-training Data Yield In-Context Learning

    [https://arxiv.org/abs/2402.12530](https://arxiv.org/abs/2402.12530)

    本研究发现，语言模型的上下文学习能力取决于预训练数据中的平行结构，通过在相似模板的短语对中学习来提高上下文学习准确度。

    

    预训练语言模型（LMs）具备上下文学习（ICL）的能力：它们可以在只给出少量示例的情况下适应任务而无需进行任何参数更新。然而，目前尚不清楚这种能力来自何处，因为预训练文本与ICL提示之间存在明显的分布偏移。在本研究中，我们探讨了预训练数据中的哪些模式有助于ICL。我们发现LMs的ICL能力取决于预训练数据中的“平行结构”——在相同上下文窗口中遵循相似模板的短语对。具体来说，通过检查训练一个短语是否提高了对另一个短语的预测来检测平行结构，并进行消融实验以研究其对ICL的影响。我们展示了从预训练数据中去除平行结构会导致LMs的ICL准确度下降51％（与随机切除的2％相比）。即使排除常见模式如 n-gram

    arXiv:2402.12530v1 Announce Type: cross  Abstract: Pre-trained language models (LMs) are capable of in-context learning (ICL): they can adapt to a task with only a few examples given in the prompt without any parameter update. However, it is unclear where this capability comes from as there is a stark distribution shift between pre-training text and ICL prompts. In this work, we study what patterns of the pre-training data contribute to ICL. We find that LMs' ICL ability depends on $\textit{parallel structures}$ in the pre-training data -- pairs of phrases following similar templates in the same context window. Specifically, we detect parallel structures by checking whether training on one phrase improves prediction of the other, and conduct ablation experiments to study their effect on ICL. We show that removing parallel structures in the pre-training data reduces LMs' ICL accuracy by 51% (vs 2% from random ablation). This drop persists even when excluding common patterns such as n-gr
    
[^86]: 离线模型驱动强化学习中的边缘问题

    The Edge-of-Reach Problem in Offline Model-Based Reinforcement Learning

    [https://arxiv.org/abs/2402.12527](https://arxiv.org/abs/2402.12527)

    学习的动力学模型被真实且无误差的动力学替代时，现有模型驱动方法将会完全失败，揭示出一个重大误解。

    

    离线强化学习旨在使智能体能够从预先收集的数据集中进行训练，然而，由此带来了一个额外的挑战，即估计数据集中未涵盖的行为的价值。模型驱动方法通过允许智能体通过在学习动力学模型中进行展开进行收集额外的合成数据来提供解决方案。然而，令人惊讶的是，我们发现，如果学习的动力学模型被真实且无误差的动力学替代，现有的模型驱动方法将完全失败。这揭示了一个重大误解。我们的后续调查发现，模型驱动算法中使用的一般过程导致存在一组触发病态值过高的边缘状态。

    arXiv:2402.12527v1 Announce Type: cross  Abstract: Offline reinforcement learning aims to enable agents to be trained from pre-collected datasets, however, this comes with the added challenge of estimating the value of behavior not covered in the dataset. Model-based methods offer a solution by allowing agents to collect additional synthetic data via rollouts in a learned dynamics model. The prevailing theoretical understanding is that this can then be viewed as online reinforcement learning in an approximate dynamics model, and any remaining gap is therefore assumed to be due to the imperfect dynamics model. Surprisingly, however, we find that if the learned dynamics model is replaced by the true error-free dynamics, existing model-based methods completely fail. This reveals a major misconception. Our subsequent investigation finds that the general procedure used in model-based algorithms results in the existence of a set of edge-of-reach states which trigger pathological value overes
    
[^87]: LangXAI：整合大型视觉模型以生成文本解释，以增强视觉感知任务的可解释性

    LangXAI: Integrating Large Vision Models for Generating Textual Explanations to Enhance Explainability in Visual Perception Tasks

    [https://arxiv.org/abs/2402.12525](https://arxiv.org/abs/2402.12525)

    LangXAI通过整合大型视觉模型，为视觉感知任务提供文本解释，弥补了最终用户在人工智能和计算机视觉方面知识的理解差距。

    

    LangXAI是一个框架，将可解释人工智能（XAI）与先进的视觉模型集成在一起，为视觉识别任务生成文本解释。尽管XAI取得了进展，但对于在人工智能和计算机视觉方面具有有限领域知识的最终用户，仍然存在理解差距。LangXAI通过为最终用户提供基于文本的分类、目标检测和语义分割模型输出的解释来解决这个问题。初步结果显示LangXAI具有增强的可信度，在各项任务中具有较高的BERTScore，促进了更加透明和可靠的视觉任务AI框架。

    arXiv:2402.12525v1 Announce Type: cross  Abstract: LangXAI is a framework that integrates Explainable Artificial Intelligence (XAI) with advanced vision models to generate textual explanations for visual recognition tasks. Despite XAI advancements, an understanding gap persists for end-users with limited domain knowledge in artificial intelligence and computer vision. LangXAI addresses this by furnishing text-based explanations for classification, object detection, and semantic segmentation model outputs to end-users. Preliminary results demonstrate LangXAI's enhanced plausibility, with high BERTScore across tasks, fostering a more transparent and reliable AI framework on vision tasks for end-users.
    
[^88]: 高斯过程神经加性模型

    Gaussian Process Neural Additive Models

    [https://arxiv.org/abs/2402.12518](https://arxiv.org/abs/2402.12518)

    本文提出了一种新的高斯过程神经加性模型（GP-NAM），通过随机傅里叶特征对高斯过程进行单层神经网络构建，可以实现具有凸目标函数和可训练参数数量随特征维度线性增长的优势，同时在性能上不亚于更深的NAM方法。

    

    深度神经网络已经在许多领域引起了革命，但它们的黑盒特性有时也阻碍了它们在医疗保健和金融等领域的广泛应用，这些领域需要可解释和可解释的模型。最近发展出的神经加性模型（NAMs）是在面向表格数据集的可解释深度学习方向上迈出的重要一步。在本文中，我们提出了一种新的NAM子类，它使用通过随机傅里叶特征对高斯过程进行单层神经网络构建，我们称之为高斯过程神经加性模型（GP-NAM）。GP-NAM具有凸目标函数和随特征维度线性增长的可训练参数数量的优势。与更深的NAM方法相比，它在性能上没有损失，因为GPs非常适合学习复杂的非参数单变量函数。我们在多个表格数据集上展示了GP-NAM的性能。

    arXiv:2402.12518v1 Announce Type: cross  Abstract: Deep neural networks have revolutionized many fields, but their black-box nature also occasionally prevents their wider adoption in fields such as healthcare and finance, where interpretable and explainable models are required. The recent development of Neural Additive Models (NAMs) is a significant step in the direction of interpretable deep learning for tabular datasets. In this paper, we propose a new subclass of NAMs that use a single-layer neural network construction of the Gaussian process via random Fourier features, which we call Gaussian Process Neural Additive Models (GP-NAM). GP-NAMs have the advantage of a convex objective function and number of trainable parameters that grows linearly with feature dimensionality. It suffers no loss in performance compared to deeper NAM approaches because GPs are well-suited for learning complex non-parametric univariate functions. We demonstrate the performance of GP-NAM on several tabular
    
[^89]: 通过自适应猜想的在线学习实现自动化安全响应

    Automated Security Response through Online Learning with Adaptive Conjectures

    [https://arxiv.org/abs/2402.12499](https://arxiv.org/abs/2402.12499)

    该论文通过自适应猜想的在线学习，提出了一种适用于IT基础设施的自动化安全响应方法，其中游戏参与者通过Bayesian学习调整猜想，并通过推演更新策略，最终实现了最佳拟合，提高了推演在猜想模型下的性能。

    

    我们研究了针对IT基础设施的自动化安全响应，并将攻击者和防御者之间的互动形式表述为一个部分观测、非平稳博弈。我们放宽了游戏模型正确规定的标准假设，并考虑每个参与者对模型有一个概率性猜想，可能在某种意义上错误规定，即真实模型的概率为0。这种形式允许我们捕捉关于基础设施和参与者意图的不确定性。为了在线学习有效的游戏策略，我们设计了一种新颖的方法，其中一个参与者通过贝叶斯学习迭代地调整其猜想，并通过推演更新其策略。我们证明了猜想会收敛到最佳拟合，并提供了在具有猜测模型的情况下推演实现性能改进的上限。为了刻画游戏的稳定状态，我们提出了Berk-Nash平衡的一个变种。

    arXiv:2402.12499v1 Announce Type: cross  Abstract: We study automated security response for an IT infrastructure and formulate the interaction between an attacker and a defender as a partially observed, non-stationary game. We relax the standard assumption that the game model is correctly specified and consider that each player has a probabilistic conjecture about the model, which may be misspecified in the sense that the true model has probability 0. This formulation allows us to capture uncertainty about the infrastructure and the intents of the players. To learn effective game strategies online, we design a novel method where a player iteratively adapts its conjecture using Bayesian learning and updates its strategy through rollout. We prove that the conjectures converge to best fits, and we provide a bound on the performance improvement that rollout enables with a conjectured model. To characterize the steady state of the game, we propose a variant of the Berk-Nash equilibrium. We 
    
[^90]: 跨领域持续学习的研究

    Towards Cross-Domain Continual Learning

    [https://arxiv.org/abs/2402.12490](https://arxiv.org/abs/2402.12490)

    介绍了一种名为跨领域持续学习（CDCL）的新方法，通过整合任务间和任务内的交叉注意机制，在紧凑的卷积网络中延迟数据漂移，实现了无监督的跨领域学习（UDA）。

    

    持续学习是一个过程，涉及训练学习代理以顺序地掌握一系列任务或类别，而不需要重新回顾过去的数据。挑战在于利用先前获得的知识有效地学习新任务，同时避免灾难性遗忘。现有方法主要集中在单一领域，限制了它们在特定问题上的适用性。在这项工作中，我们介绍了一种名为跨领域持续学习（CDCL）的新方法，它解决了被限制在单一监督领域的局限性。我们的方法在紧凑的卷积网络中结合了任务间和任务内的交叉注意机制。这种整合使得模型能够与先前任务的特征保持对齐，从而延迟可能发生在任务之间的数据漂移，同时在相关领域之间进行无监督的跨领域学习（UDA）。通过利用任务内具体的伪标签

    arXiv:2402.12490v1 Announce Type: cross  Abstract: Continual learning is a process that involves training learning agents to sequentially master a stream of tasks or classes without revisiting past data. The challenge lies in leveraging previously acquired knowledge to learn new tasks efficiently, while avoiding catastrophic forgetting. Existing methods primarily focus on single domains, restricting their applicability to specific problems.   In this work, we introduce a novel approach called Cross-Domain Continual Learning (CDCL) that addresses the limitations of being limited to single supervised domains. Our method combines inter- and intra-task cross-attention mechanisms within a compact convolutional network. This integration enables the model to maintain alignment with features from previous tasks, thereby delaying the data drift that may occur between tasks, while performing unsupervised cross-domain (UDA) between related domains. By leveraging an intra-task-specific pseudo-labe
    
[^91]: 在深度强化学习中，修剪网络是一个好网络

    In deep reinforcement learning, a pruned network is a good network

    [https://arxiv.org/abs/2402.12479](https://arxiv.org/abs/2402.12479)

    通过逐渐剪枝，使代理能够最大程度地发挥参数效能，从而产生比传统网络显著性能提升的网络，并展现出一种“缩放定律”。

    

    最近的研究表明，深度强化学习代理在有效利用其网络参数方面存在困难。我们利用对稀疏训练技术优势的先前见解，并证明逐渐剪枝使代理能够最大程度地发挥参数效能。这导致网络比传统网络产生显著的性能改进，并表现出一种“缩放定律”，仅使用完整网络参数的一小部分。

    arXiv:2402.12479v1 Announce Type: cross  Abstract: Recent work has shown that deep reinforcement learning agents have difficulty in effectively using their network parameters. We leverage prior insights into the advantages of sparse training techniques and demonstrate that gradual magnitude pruning enables agents to maximize parameter effectiveness. This results in networks that yield dramatic performance improvements over traditional networks and exhibit a type of "scaling law", using only a small fraction of the full network parameters.
    
[^92]: 多模态大型语言模型的革命：一项调查

    The (R)Evolution of Multimodal Large Language Models: A Survey

    [https://arxiv.org/abs/2402.12451](https://arxiv.org/abs/2402.12451)

    多模态大型语言模型能够无缝整合视觉和文本模态，为生成智能提供了新的可能性。

    

    连接文本和视觉模态在生成智能中扮演着重要角色。受大型语言模型成功的启发，目前已有大量研究工作致力于开发多模态大型语言模型（MLLMs）。这些模型可以无缝地整合视觉和文本模态，同时作为输入和输出，提供基于对话的接口和遵循指令的能力。本文全面审查了最近基于视觉的MLLMs，分析了它们的架构选择、多模态对齐策略和训练技术。我们还对这些模型在各种任务上进行了详细分析，包括视觉定位、图像生成和编辑、视觉理解以及特定领域的应用。此外，我们编制并描述了训练数据集和评估基准，对现有模型进行了比较。

    arXiv:2402.12451v1 Announce Type: cross  Abstract: Connecting text and visual modalities plays an essential role in generative intelligence. For this reason, inspired by the success of large language models, significant research efforts are being devoted to the development of Multimodal Large Language Models (MLLMs). These models can seamlessly integrate visual and textual modalities, both as input and output, while providing a dialogue-based interface and instruction-following capabilities. In this paper, we provide a comprehensive review of recent visual-based MLLMs, analyzing their architectural choices, multimodal alignment strategies, and training techniques. We also conduct a detailed analysis of these models across a wide range of tasks, including visual grounding, image generation and editing, visual understanding, and domain-specific applications. Additionally, we compile and describe training datasets and evaluation benchmarks, conducting comparisons among existing models in 
    
[^93]: 图神经网络中节点属性的攻击

    Attacks on Node Attributes in Graph Neural Networks

    [https://arxiv.org/abs/2402.12426](https://arxiv.org/abs/2402.12426)

    该研究通过基于特征的对抗攻击，针对图神经网络中的节点属性展开研究，发现使用Projected Gradient Descent的决策时攻击比使用Mean Node Embeddings和Graph Contrastive Learning策略的毒化攻击更加有效。

    

    图经常用来模型化现代社交媒体和文献应用中的复杂网络。我们的研究通过基于特征的对抗攻击，重点关注决策时攻击和毒化攻击，探究这些图的脆弱性。与Net Attack和Meta Attack等最先进模型针对节点属性和图结构不同，我们的研究专门针对节点属性。我们利用Hellaswag文本数据集以及图数据集Cora和CiteSeer进行分析，为评估提供了多样的基础。我们的发现表明，使用Projected Gradient Descent (PGD)的决策时攻击比采用Mean Node Embeddings和Graph Contrastive Learning策略的毒化攻击更具威力。这为图数据安全提供了见解，指出了图基模型最脆弱的地方，从而为开发工作提供信息。

    arXiv:2402.12426v1 Announce Type: cross  Abstract: Graphs are commonly used to model complex networks prevalent in modern social media and literacy applications. Our research investigates the vulnerability of these graphs through the application of feature based adversarial attacks, focusing on both decision-time attacks and poisoning attacks. In contrast to state-of-the-art models like Net Attack and Meta Attack, which target node attributes and graph structure, our study specifically targets node attributes. For our analysis, we utilized the text dataset Hellaswag and graph datasets Cora and CiteSeer, providing a diverse basis for evaluation. Our findings indicate that decision-time attacks using Projected Gradient Descent (PGD) are more potent compared to poisoning attacks that employ Mean Node Embeddings and Graph Contrastive Learning strategies. This provides insights for graph data security, pinpointing where graph-based models are most vulnerable and thereby informing the develo
    
[^94]: 表格作为图片？探讨LLM在多模态表格数据表示上的优势和局限性

    Tables as Images? Exploring the Strengths and Limitations of LLMs on Multimodal Representations of Tabular Data

    [https://arxiv.org/abs/2402.12424](https://arxiv.org/abs/2402.12424)

    本研究探讨了LLM在解释表格数据方面的有效性，比较了文本和图像表格表示对LLM性能的影响，为在表格相关任务上有效使用LLM提供了见解。

    

    在本文中，我们通过不同的提示策略和数据格式研究了各种LLM在解释表格数据方面的有效性。我们的分析涵盖了六个针对与表格相关任务的基准，如问答和事实核查。我们首次介绍了LLM在基于图像的表格表示上的表现评估。具体地，我们比较了五种基于文本和三种基于图像的表格表示，展示了表示和提示对LLM性能的影响。我们的研究为在表格相关任务上有效使用LLM提供了见解。

    arXiv:2402.12424v1 Announce Type: cross  Abstract: In this paper, we investigate the effectiveness of various LLMs in interpreting tabular data through different prompting strategies and data formats. Our analysis extends across six benchmarks for table-related tasks such as question-answering and fact-checking. We introduce for the first time the assessment of LLMs' performance on image-based table representations. Specifically, we compare five text-based and three image-based table representations, demonstrating the influence of representation and prompting on LLM performance. Our study provides insights into the effective use of LLMs on table-related tasks.
    
[^95]: 模拟体作为意识异域

    Simulacra as Conscious Exotica

    [https://arxiv.org/abs/2402.12422](https://arxiv.org/abs/2402.12422)

    本文借鉴了维特根斯坦的后期著作，尝试回答在概念生成语言模型构建的AI代理中是否有意义谈论意识的问题，避免了二元论思维的陷阱。

    

    arXiv：2402.12422v1 发布类型：新摘要：随着越来越像人类行为的会话代理的出现，古老的哲学问题被重新审视。在概念生成语言模型构建的AI代理中，是否有意义谈论意识，考虑到它们只是人类行为的“纯粹”模拟，并且它们的行为可以被看作是“仅仅”角色扮演？本文借鉴了维特根斯坦的后期著作，试图解决这个问题，同时避免二元论思维的陷阱。

    arXiv:2402.12422v1 Announce Type: new  Abstract: The advent of conversational agents with increasingly human-like behaviour throws old philosophical questions into new light. Does it, or could it, ever make sense to speak of AI agents built out of generative language models in terms of consciousness, given that they are "mere" simulacra of human behaviour, and that what they do can be seen as "merely" role play? Drawing on the later writings of Wittgenstein, this paper attempts to tackle this question while avoiding the pitfalls of dualistic thinking.
    
[^96]: EBFT：稀疏LLM的有效和块状微调

    EBFT: Effective and Block-Wise Fine-Tuning for Sparse LLMs

    [https://arxiv.org/abs/2402.12419](https://arxiv.org/abs/2402.12419)

    提出了一种有效的块状微调稀疏LLM的框架，通过最小化重建误差并采用反向传播逐块优化解决方案，实验结果表明在各种基准测试中优于其他方法。

    

    现有的稀疏LLM微调方法通常需要资源密集型的要求和高昂的重新训练成本。此外，许多微调方法往往依赖于近似或启发式优化策略，这可能导致次优解。为了解决这些问题，我们提出了一种基于最小化重建误差的高效快速微调稀疏LLM的框架。我们的方法涉及对一个小数据集进行采样以进行校准，并利用反向传播逐块地优化块状重建误差，致力于寻求最佳解决方案。对各种基准测试的广泛实验证明，我们的方法在多个基线上始终表现卓越。例如，在Wikitext2数据集上，LLamaV1-7B在70%稀疏度下，我们提出的EBFT取得了16.88的困惑度，超过了75.14的DSnoT的最先进水平。

    arXiv:2402.12419v1 Announce Type: cross  Abstract: Existing methods for fine-tuning sparse LLMs often suffer from resource-intensive requirements and high retraining costs. Additionally, many fine-tuning methods often rely on approximations or heuristic optimization strategies, which may lead to suboptimal solutions. To address these issues, we propose an efficient and fast framework for fine-tuning sparse LLMs based on minimizing reconstruction error. Our approach involves sampling a small dataset for calibration and utilizing backpropagation to iteratively optimize block-wise reconstruction error, on a block-by-block basis, aiming for optimal solutions. Extensive experiments on various benchmarks consistently demonstrate the superiority of our method over other baselines. For instance, on the Wikitext2 dataset with LlamaV1-7B at 70% sparsity, our proposed EBFT achieves a perplexity of 16.88, surpassing the state-of-the-art DSnoT with a perplexity of 75.14. Moreover, with a structured
    
[^97]: 超越统一缩放：探索神经架构中的深度异质性

    Beyond Uniform Scaling: Exploring Depth Heterogeneity in Neural Architectures

    [https://arxiv.org/abs/2402.12418](https://arxiv.org/abs/2402.12418)

    引入了一种基于二阶损失景观信息的自动缩放方法，同时扩展和训练transformers，提出了神经架构中的深度异质性概念，并在ImageNet100上实现了准确性和参数效率的提升。

    

    传统的神经网络缩放通常涉及设计基本网络，并通过一些预定义的缩放因子增加不同维度（如宽度、深度等）。我们引入了一种利用二阶损失景观信息的自动缩放方法。我们的方法对现代视觉transformers中的跳过连接具有灵活性。我们的训练感知方法同时扩展和训练transformers，而无需额外的训练迭代。受到并非所有神经元都需要统一深度复杂性的假设启发，我们的方法采用深度异质性。对DeiT-S在ImageNet100上进行的广泛评估显示比传统缩放提高了2.5％的准确性并提高了10％的参数效率。在从头开始训练小规模数据集时，缩放的网络表现出色。我们引入了视觉transformers的第一个完整缩放机制，这是朝向高效模型场景的一步。

    arXiv:2402.12418v1 Announce Type: cross  Abstract: Conventional scaling of neural networks typically involves designing a base network and growing different dimensions like width, depth, etc. of the same by some predefined scaling factors. We introduce an automated scaling approach leveraging second-order loss landscape information. Our method is flexible towards skip connections a mainstay in modern vision transformers. Our training-aware method jointly scales and trains transformers without additional training iterations. Motivated by the hypothesis that not all neurons need uniform depth complexity, our approach embraces depth heterogeneity. Extensive evaluations on DeiT-S with ImageNet100 show a 2.5% accuracy gain and 10% parameter efficiency improvement over conventional scaling. Scaled networks demonstrate superior performance upon training small scale datasets from scratch. We introduce the first intact scaling mechanism for vision transformers, a step towards efficient model sc
    
[^98]: 用跨公司的卡车司机安全氛围感知来预测卡车事故：一种迁移学习方法

    Predicting trucking accidents with truck drivers 'safety climate perception across companies: A transfer learning approach

    [https://arxiv.org/abs/2402.12417](https://arxiv.org/abs/2402.12417)

    提出了一种预先训练然后微调的迁移学习方法，利用其他公司的数据开发AI模型，更准确地预测卡车事故风险。

    

    人工智能（AI）驱动的安全分析在预测卡车行业事故方面越来越受到关注。然而，公司可能面临一个实际挑战，即没有足够的数据来开发良好的安全分析模型。为了填补这一空白，我们提出了一种预先训练然后微调的迁移学习方法，以帮助任何公司利用其他公司的数据开发AI模型，更准确地预测事故风险。我们还开发了SafeNet，一种适用于事故预测的分类任务的深度神经网络算法。通过来自七家数据规模各不相同的卡车公司的安全氛围调查数据，我们展示了我们提出的方法在结果上比传统方法更好。

    arXiv:2402.12417v1 Announce Type: cross  Abstract: There is a rising interest in using artificial intelligence (AI)-powered safety analytics to predict accidents in the trucking industry. Companies may face the practical challenge, however, of not having enough data to develop good safety analytics models. Although pretrained models may offer a solution for such companies, existing safety research using transfer learning has mostly focused on computer vision and natural language processing, rather than accident analytics. To fill the above gap, we propose a pretrain-then-fine-tune transfer learning approach to help any company leverage other companies' data to develop AI models for a more accurate prediction of accident risk. We also develop SafeNet, a deep neural network algorithm for classification tasks suitable for accident prediction. Using the safety climate survey data from seven trucking companies with different data sizes, we show that our proposed approach results in better m
    
[^99]: 在多智能体合作中对齐个体和集体目标

    Aligning Individual and Collective Objectives in Multi-Agent Cooperation

    [https://arxiv.org/abs/2402.12416](https://arxiv.org/abs/2402.12416)

    引入Altruistic Gradient Adjustment (AgA)优化方法，利用梯度调整来对齐个体和集体目标，加速收敛到期望解决方案

    

    在多智能体学习领域，面临着混合动机合作的挑战，因为个体和集体目标之间存在固有的矛盾。当前在该领域的研究主要集中在将领域知识纳入奖励或引入额外机制来促进合作。然而，许多这些方法存在着手动设计成本和缺乏理论基础的收敛程序解决方案的缺点。为了填补这一空白，我们将混合动机博弈建模为一个可微分的博弈以研究学习动态。我们提出了一种名为Altruistic Gradient Adjustment (AgA)的新优化方法，利用梯度调整来新颖地对齐个体和集体目标。此外，我们提供理论证明，AgA中选择适当的对齐权重可以加速收敛到期望解决方案。

    arXiv:2402.12416v1 Announce Type: cross  Abstract: In the field of multi-agent learning, the challenge of mixed-motive cooperation is pronounced, given the inherent contradictions between individual and collective goals. Current research in this domain primarily focuses on incorporating domain knowledge into rewards or introducing additional mechanisms to foster cooperation. However, many of these methods suffer from the drawbacks of manual design costs and the lack of a theoretical grounding convergence procedure to the solution. To address this gap, we approach the mixed-motive game by modeling it as a differentiable game to study learning dynamics. We introduce a novel optimization method named Altruistic Gradient Adjustment (AgA) that employs gradient adjustments to novelly align individual and collective objectives. Furthermore, we provide theoretical proof that the selection of an appropriate alignment weight in AgA can accelerate convergence towards the desired solutions while e
    
[^100]: 由生成AI推动的动态和超个性化媒体生态系统：不断变化的不重复剧本

    Dynamic and Super-Personalized Media Ecosystem Driven by Generative AI: Unpredictable Plays Never Repeating The Same

    [https://arxiv.org/abs/2402.12412](https://arxiv.org/abs/2402.12412)

    通过引入人工智能视频生成器，该论文提出了一种新型媒体服务模型，在动态媒体生态系统中实现了超个性化服务。

    

    本文介绍了一种利用接收端的人工智能（AI）视频生成器的媒体服务模型。该提议偏离了传统的多媒体生态系统，完全依赖于内部制作，通过将部分内容创建转移到接收端。我们将语义处理引入框架，允许分发网络提供促使内容生成器的服务元素，而不是分发完全成品节目的编码数据。服务元素包括精心定制的文本描述、一些对象的轻量级图像数据，或应用程序接口，综合称之为语义来源，用户终端将接收的语义数据转换为视频帧。借助生成式AI的随机性质，用户可以相应地体验超个性化服务。该提议概括了其中情况

    arXiv:2402.12412v1 Announce Type: cross  Abstract: This paper introduces a media service model that exploits artificial intelligence (AI) video generators at the receive end. This proposal deviates from the traditional multimedia ecosystem, completely relying on in-house production, by shifting part of the content creation onto the receiver. We bring a semantic process into the framework, allowing the distribution network to provide service elements that prompt the content generator, rather than distributing encoded data of fully finished programs. The service elements include fine-tailored text descriptions, lightweight image data of some objects, or application programming interfaces, comprehensively referred to as semantic sources, and the user terminal translates the received semantic data into video frames. Empowered by the random nature of generative AI, the users could then experience super-personalized services accordingly. The proposed idea incorporates the situations in which
    
[^101]: 基于异构信息网络的节点重要性值估计的深度结构知识利用与协同作用

    Deep Structural Knowledge Exploitation and Synergy for Estimating Node Importance Value on Heterogeneous Information Networks

    [https://arxiv.org/abs/2402.12411](https://arxiv.org/abs/2402.12411)

    通过利用异构结构化知识，提出了一个新的学习框架SKES，用于在异构信息网络中丰富节点表示的信息量，进而建立了一个可解释的节点重要性计算范式。

    

    节点重要性估计问题在传统上是通过同质网络拓扑分析来研究的。为了处理网络的异质性，最近一些方法采用图神经模型来自动学习多样的信息来源。然而，他们的全自适应学习过程可能导致信息探索不足，从而将问题制定为对孤立节点的值预测，表现不佳且可解释性较差。在本研究中，我们提出了一个新颖的学习框架：SKES。与以前的自动学习设计不同，SKES利用异构结构化知识来丰富节点表示的信息量。基于一个足够不具信息的参考，SKES通过量化输入节点与参考之间的差异来估计任何输入节点的重要性值。这建立了一个可解释的节点重要性计算范式。

    arXiv:2402.12411v1 Announce Type: cross  Abstract: Node importance estimation problem has been studied conventionally with homogeneous network topology analysis. To deal with network heterogeneity, a few recent methods employ graph neural models to automatically learn diverse sources of information. However, the major concern revolves around that their full adaptive learning process may lead to insufficient information exploration, thereby formulating the problem as the isolated node value prediction with underperformance and less interpretability. In this work, we propose a novel learning framework: SKES. Different from previous automatic learning designs, SKES exploits heterogeneous structural knowledge to enrich the informativeness of node representations. Based on a sufficiently uninformative reference, SKES estimates the importance value for any input node, by quantifying its disparity against the reference. This establishes an interpretable node importance computation paradigm. F
    
[^102]: ModelGPT：释放LLM的能力，为定制模型生成铺平道路

    ModelGPT: Unleashing LLM's Capabilities for Tailored Model Generation

    [https://arxiv.org/abs/2402.12408](https://arxiv.org/abs/2402.12408)

    ModelGPT是一个新颖的框架，通过利用LLM的能力，根据用户提供的数据或任务描述生成定制化的AI模型，让用户能够更快速和方便地使用AI模型。

    

    大型语言模型（LLM）的快速发展通过自动化例行任务，标志着迈向人工通用智能（AGI）的实现迈出了一步，革新了各个行业。然而，它们仍然难以满足用户的多样化和特定需求，也难以简化AI模型对普通用户的利用。因此，我们提出了ModelGPT，这是一个新颖的框架，旨在根据用户提供的数据或任务描述来确定和生成特定定制的AI模型，利用了LLM的能力。ModelGPT能够根据用户需求提供的模型，比之前的范式（例如全参数或LoRA微调）快至多270倍。在NLP、CV和表格数据集上进行的全面实验证明了我们的框架在使AI模型更易访问和用户友好方面的效果。我们的代码可在 https://github.com/IshiKura-a/ModelGPT 找到。

    arXiv:2402.12408v1 Announce Type: cross  Abstract: The rapid advancement of Large Language Models (LLMs) has revolutionized various sectors by automating routine tasks, marking a step toward the realization of Artificial General Intelligence (AGI). However, they still struggle to accommodate the diverse and specific needs of users and simplify the utilization of AI models for the average user. In response, we propose ModelGPT, a novel framework designed to determine and generate AI models specifically tailored to the data or task descriptions provided by the user, leveraging the capabilities of LLMs. Given user requirements, ModelGPT is able to provide tailored models at most 270x faster than the previous paradigms (e.g. all-parameter or LoRA finetuning). Comprehensive experiments on NLP, CV, and Tabular datasets attest to the effectiveness of our framework in making AI models more accessible and user-friendly. Our code is available at https://github.com/IshiKura-a/ModelGPT.
    
[^103]: 教师作为宽容的专家：不依赖于教师的无数据知识蒸馏

    Teacher as a Lenient Expert: Teacher-Agnostic Data-Free Knowledge Distillation

    [https://arxiv.org/abs/2402.12406](https://arxiv.org/abs/2402.12406)

    该论文发现现有的无数据知识蒸馏方法对不同的教师模型非常敏感，生成的样本可能出现质量问题。

    

    无数据知识蒸馏（DFKD）旨在在不使用原始数据的情况下，借助生成器将预训练知识蒸馏给学生模型。在这种无数据情况下，由于验证数据不可用，实现DFKD的稳定性是必不可少的。不幸的是，本文发现现有的DFKD方法对不同的教师模型非常敏感，有时即使使用训练良好的教师模型也会出现蒸馏的灾难性失败。我们的观察是DFKD中的生成器并不总是保证使用现有的旨在最小化类先验和对抗损失的代表性策略产生精确而多样化的样本。通过我们的实证研究，我们关注的事实是类先验不仅减少了生成样本的多样性，还不能完全解决根据教师模型生成意外低质量样本的问题。

    arXiv:2402.12406v1 Announce Type: cross  Abstract: Data-free knowledge distillation (DFKD) aims to distill pretrained knowledge to a student model with the help of a generator without using original data. In such data-free scenarios, achieving stable performance of DFKD is essential due to the unavailability of validation data. Unfortunately, this paper has discovered that existing DFKD methods are quite sensitive to different teacher models, occasionally showing catastrophic failures of distillation, even when using well-trained teacher models. Our observation is that the generator in DFKD is not always guaranteed to produce precise yet diverse samples using the existing representative strategy of minimizing both class-prior and adversarial losses. Through our empirical study, we focus on the fact that class-prior not only decreases the diversity of generated samples, but also cannot completely address the problem of generating unexpectedly low-quality samples depending on teacher mod
    
[^104]: scInterpreter: 训练大规模语言模型解释 scRNA-seq 数据进行细胞类型注释

    scInterpreter: Training Large Language Models to Interpret scRNA-seq Data for Cell Type Annotation

    [https://arxiv.org/abs/2402.12405](https://arxiv.org/abs/2402.12405)

    该研究通过训练大型语言模型来解释和区分单细胞RNA测序数据中的细胞类型，展示了这些模型在准确分类细胞类型方面的潜力。

    

    尽管现有大型语言模型在直接阅读和解释单细胞组学数据方面具有固有限制，但它们作为基础模型表现出显著潜力和灵活性。本研究关注如何训练和调整具有解释和区分单细胞RNA测序数据能力的大型语言模型。我们的初步研究结果表明，这些基础模型在准确分类已知细胞类型方面表现优异，展示了大型语言模型作为揭示新生物学见解有效工具的潜力。

    arXiv:2402.12405v1 Announce Type: cross  Abstract: Despite the inherent limitations of existing Large Language Models in directly reading and interpreting single-cell omics data, they demonstrate significant potential and flexibility as the Foundation Model. This research focuses on how to train and adapt the Large Language Model with the capability to interpret and distinguish cell types in single-cell RNA sequencing data. Our preliminary research results indicate that these foundational models excel in accurately categorizing known cell types, demonstrating the potential of the Large Language Models as effective tools for uncovering new biological insights.
    
[^105]: 将废料变废为宝：矫正MoE的Top-k路由器

    Turn Waste into Worth: Rectifying Top-$k$ Router of MoE

    [https://arxiv.org/abs/2402.12399](https://arxiv.org/abs/2402.12399)

    提出了Rectify-Router解决了MoE模型中常用的Top-k路由机制所带来的令牌丢失和填充问题，通过Intra-GPU矫正和Fill-in矫正来实现。

    

    稀疏混合专家（MoE）模型因其计算效率而受到欢迎，用于训练大型语言模型。然而，常用的Top-k路由机制由于不平衡的路由导致冗余计算和内存成本过高。一些专家会溢出，其中超出的令牌会被丢弃。而一些专家是空闲的，这些专家会填充为零，负面影响了模型性能。为了解决丢弃令牌和填充问题，我们提出了Rectify-Router，包括Intra-GPU矫正和Fill-in矫正。Intra-GPU矫正处理丢弃的令牌，将它们有效地路由到GPU内的专家，避免跨GPU通信。Fill-in矫正通过用具有高路由分数的令牌替换填充令牌来解决填充问题。我们的实验结果表明，Intra-GPU矫正和Fill-in矫正

    arXiv:2402.12399v1 Announce Type: cross  Abstract: Sparse Mixture of Experts (MoE) models are popular for training large language models due to their computational efficiency. However, the commonly used top-$k$ routing mechanism suffers from redundancy computation and memory costs due to the unbalanced routing. Some experts are overflow, where the exceeding tokens are dropped. While some experts are vacant, which are padded with zeros, negatively impacting model performance. To address the dropped tokens and padding, we propose the Rectify-Router, comprising the Intra-GPU Rectification and the Fill-in Rectification. The Intra-GPU Rectification handles dropped tokens, efficiently routing them to experts within the GPU where they are located to avoid inter-GPU communication. The Fill-in Rectification addresses padding by replacing padding tokens with the tokens that have high routing scores. Our experimental results demonstrate that the Intra-GPU Rectification and the Fill-in Rectificati
    
[^106]: 在天体物理蒙特卡洛模拟中使用生成对抗网络（GAN）的探讨

    Toward using GANs in astrophysical Monte-Carlo simulations

    [https://arxiv.org/abs/2402.12396](https://arxiv.org/abs/2402.12396)

    生成对抗网络（GAN）在天体物理蒙特卡洛模拟中成功地统计复制了Maxwell-J\"uttner分布。

    

    准确建模由X射线源产生的光谱需要使用蒙特卡洛模拟。这些模拟需要评估物理过程，例如在紧凑天体周围发生的吸积过程，通过采样多种不同的概率分布来实现。这在计算上非常耗时，如果用神经网络代替可能会加快速度。我们在描述相对论电子速度的Maxwell-J\"uttner分布示例上展示，生成对抗网络（GAN）能够统计复制该分布。Kolmogorov-Smirnov测试的平均值为0.5，表明神经网络生成的样本与真实分布无法区分。

    arXiv:2402.12396v1 Announce Type: cross  Abstract: Accurate modelling of spectra produced by X-ray sources requires the use of Monte-Carlo simulations. These simulations need to evaluate physical processes, such as those occurring in accretion processes around compact objects by sampling a number of different probability distributions. This is computationally time-consuming and could be sped up if replaced by neural networks. We demonstrate, on an example of the Maxwell-J\"uttner distribution that describes the speed of relativistic electrons, that the generative adversarial network (GAN) is capable of statistically replicating the distribution. The average value of the Kolmogorov-Smirnov test is 0.5 for samples generated by the neural network, showing that the generated distribution cannot be distinguished from the true distribution.
    
[^107]: 利用生物标志物提高模型的解释性和可靠性

    Improving Model's Interpretability and Reliability using Biomarkers

    [https://arxiv.org/abs/2402.12394](https://arxiv.org/abs/2402.12394)

    利用决策树解释基于生物标志物的诊断模型，帮助临床医生提高识别不准确预测的能力，从而增强医学诊断模型的可靠性。

    

    准确且具有解释性的诊断模型在医学这个安全关键领域至关重要。我们研究了我们提出的基于生物标志物的肺部超声诊断流程的可解释性，以增强临床医生的诊断能力。本研究的目标是评估决策树分类器利用生物标志物提供的解释是否能够改善用户识别模型不准确预测能力，与传统的显著性图相比。我们的研究发现表明，基于临床建立的生物标志物的决策树解释能够帮助临床医生检测到假阳性，从而提高医学诊断模型的可靠性。

    arXiv:2402.12394v1 Announce Type: cross  Abstract: Accurate and interpretable diagnostic models are crucial in the safety-critical field of medicine. We investigate the interpretability of our proposed biomarker-based lung ultrasound diagnostic pipeline to enhance clinicians' diagnostic capabilities. The objective of this study is to assess whether explanations from a decision tree classifier, utilizing biomarkers, can improve users' ability to identify inaccurate model predictions compared to conventional saliency maps. Our findings demonstrate that decision tree explanations, based on clinically established biomarkers, can assist clinicians in detecting false positives, thus improving the reliability of diagnostic models in medicine.
    
[^108]: 关于通过规划和学习自动化视频游戏测试

    On Automating Video Game Testing by Planning and Learning

    [https://arxiv.org/abs/2402.12393](https://arxiv.org/abs/2402.12393)

    提出了一种通过自动规划和学习技术自动化测试视频游戏的方法和工作流程，使得自动规划变得更容易接触到更广泛的受众。

    

    在本文中，我们提出了一种使用自动规划和规划行为模型学习技术自动化测试特定视频游戏方面的方法和工作流程。基本想法是生成详细的游戏日志，并应用行动模型学习来获得规划领域描述语言（PDDL）中的形式模型。该工作流程实现了游戏开发人员与具有PDDL建模经验但无游戏开发技能的人员之间的高效合作，并且无需任何PDDL或其他正式系统经验。我们总体描述了该方法和工作流程，然后在一个具体的概念证明示例上进行演示 -- 这是一个简单的角色扮演游戏，作为流行游戏开发引擎Unity中的教程项目之一。本文是朝着减少甚至消除工作流程中对建模专家需求的第一步，从而使自动规划可供更广泛的人群使用。

    arXiv:2402.12393v1 Announce Type: cross  Abstract: In this paper, we propose a method and workflow for automating the testing of certain video game aspects using automated planning and planning action model learning techniques. The basic idea is to generate detailed gameplay logs and apply action model learning to obtain a formal model in the planning domain description language (PDDL). The workflow enables efficient cooperation of game developers without any experience with PDDL or other formal systems and a person experienced with PDDL modeling but no game development skills. We describe the method and workflow in general and then demonstrate it on a concrete proof-of-concept example -- a simple role-playing game provided as one of the tutorial projects in the popular game development engine Unity. This paper presents the first step towards minimizing or even eliminating the need for a modeling expert in the workflow, thus making automated planning accessible to a broader audience.
    
[^109]: 通过回归混合模型理解 Covid-19 大流行对公共交通乘客量的影响

    A Regression Mixture Model to understand the effect of the Covid-19 pandemic on Public Transport Ridership

    [https://arxiv.org/abs/2402.12392](https://arxiv.org/abs/2402.12392)

    提出了一种回归混合模型，通过对公共交通站点进行聚类和时间段进行分割，忽略了额外变量的影响，研究了 Covid-19 大流行对铁路公共交通乘客量的影响及其变化。

    

    Covid-19 大流行彻底改变了城市出行方式，不仅在疫情高峰期通过政府封锁，而且在较长时间内采用居家办公政策。为了了解其对铁路公共交通乘客量的影响，我们提出了一个专门的回归混合模型，能够对公共交通站点进行聚类和时间段进行分割，同时忽略由于官方封锁或非工作日等附加变量导致的变化。每个群集因此由一系列时间段定义，其中外生变量的影响是恒定的。由于群集内的每个时间段具有自己的回归系数来建模协变量的影响，我们分析这些系数如何演变以理解群集中的变化。我们介绍了回归混合模型和使用 EM 算法进行参数估计，然后展示了其中的好处。

    arXiv:2402.12392v1 Announce Type: cross  Abstract: The Covid-19 pandemic drastically changed urban mobility, both during the height of the pandemic with government lockdowns, but also in the longer term with the adoption of working-from-home policies. To understand its effects on rail public transport ridership, we propose a dedicated Regression Mixture Model able to perform both the clustering of public transport stations and the segmentation of time periods, while ignoring variations due to additional variables such as the official lockdowns or non-working days. Each cluster is thus defined by a series of segments in which the effect of the exogenous variables is constant. As each segment within a cluster has its own regression coefficients to model the impact of the covariates, we analyze how these coefficients evolve to understand the changes in the cluster. We present the regression mixture model and the parameter estimation using the EM algorithm, before demonstrating the benefit
    
[^110]: 实现基因表达数据科学发现的AI科学家团队

    Toward a Team of AI-made Scientists for Scientific Discovery from Gene Expression Data

    [https://arxiv.org/abs/2402.12391](https://arxiv.org/abs/2402.12391)

    引入了一个名为AI科学家团队（TAIS）的框架，旨在简化科学发现流程，由模拟角色协作，特别关注于识别具有疾病预测价值的基因

    

    机器学习已成为科学发现的强大工具，使研究人员能够从复杂数据集中提取有意义的见解。我们引入了一个新颖的框架，名为AI科学家团队（TAIS），旨在简化科学发现流程。TAIS包括模拟角色，包括项目经理、数据工程师和领域专家，每个角色由大型语言模型（LLM）代表。这些角色协作以复制数据科学家通常执行的任务，特别关注于识别具有疾病预测价值的基因。

    arXiv:2402.12391v1 Announce Type: cross  Abstract: Machine learning has emerged as a powerful tool for scientific discovery, enabling researchers to extract meaningful insights from complex datasets. For instance, it has facilitated the identification of disease-predictive genes from gene expression data, significantly advancing healthcare. However, the traditional process for analyzing such datasets demands substantial human effort and expertise for the data selection, processing, and analysis. To address this challenge, we introduce a novel framework, a Team of AI-made Scientists (TAIS), designed to streamline the scientific discovery pipeline. TAIS comprises simulated roles, including a project manager, data engineer, and domain expert, each represented by a Large Language Model (LLM). These roles collaborate to replicate the tasks typically performed by data scientists, with a specific focus on identifying disease-predictive genes. Furthermore, we have curated a benchmark dataset t
    
[^111]: 一种用于酒精消费研究中敏感性分析和假设测试的语义社交网络分析工具

    A Semantic Social Network Analysis Tool for Sensitivity Analysis and What-If Scenario Testing in Alcohol Consumption Studies

    [https://arxiv.org/abs/2402.12390](https://arxiv.org/abs/2402.12390)

    一种用于酒精消费研究中敏感性分析和假设测试的语义社交网络分析工具，旨在描述和研究个体之间建立的社会关系

    

    社交网络分析（SNA）是社会和行为科学研究领域发展起来的一套技术，旨在描述和研究一组个体之间建立的社会关系。在构建用于进行SNA分析的社交网络时，通过初始的数据收集过程来提取个体及其关系的特征。通常通过填写包含不同类型问题的问卷来完成这一过程，这些问题稍后将用于获取执行研究所需的SNA指标。然后，有许多不同的可能网络生成问题，也有许多将回答映射到对应的特征和关系的可能性。这些问题可能会被引入许多变化（它们的提出方式，赋予每个回答的权重等），这可能会影响到

    arXiv:2402.12390v1 Announce Type: cross  Abstract: Social Network Analysis (SNA) is a set of techniques developed in the field of social and behavioral sciences research, in order to characterize and study the social relationships that are established among a set of individuals. When building a social network for performing an SNA analysis, an initial process of data gathering is achieved in order to extract the characteristics of the individuals and their relationships. This is usually done by completing a questionnaire containing different types of questions that will be later used to obtain the SNA measures needed to perform the study. There are, then, a great number of different possible network generating questions and also many possibilities for mapping the responses to the corresponding characteristics and relationships. Many variations may be introduced into these questions (the way they are posed, the weights given to each of the responses, etc.) that may have an effect on the
    
[^112]: 使用深度强化学习辅助操作员选择的约束多目标优化

    Constrained Multi-objective Optimization with Deep Reinforcement Learning Assisted Operator Selection

    [https://arxiv.org/abs/2402.12381](https://arxiv.org/abs/2402.12381)

    提出了一种由深度强化学习辅助的在线操作员选择框架，旨在改进约束多目标优化进化算法中操作员的选择问题

    

    解决带约束的多目标优化问题已经引起了相当大的关注。随着不同的算法策略、进化算子和约束处理技术的使用，已经开发了各种约束多目标优化进化算法（CMOEAs）。CMOEAs的性能可能严重依赖于所使用的操作员，然而，通常很难为手头的问题选择合适的操作员。因此，改进操作员的选择对CMOEAs是有前景的且是必要的。本文提出了一种由深度强化学习辅助的在线操作员选择框架。人口的动态性，包括收敛性、多样性和可行性，被视为状态；候选操作员被视为行动；人口状态的改善被视为奖励。通过使用Q网络来学习一个策略来估计

    arXiv:2402.12381v1 Announce Type: new  Abstract: Solving constrained multi-objective optimization problems with evolutionary algorithms has attracted considerable attention. Various constrained multi-objective optimization evolutionary algorithms (CMOEAs) have been developed with the use of different algorithmic strategies, evolutionary operators, and constraint-handling techniques. The performance of CMOEAs may be heavily dependent on the operators used, however, it is usually difficult to select suitable operators for the problem at hand. Hence, improving operator selection is promising and necessary for CMOEAs. This work proposes an online operator selection framework assisted by Deep Reinforcement Learning. The dynamics of the population, including convergence, diversity, and feasibility, are regarded as the state; the candidate operators are considered as actions; and the improvement of the population state is treated as the reward. By using a Q-Network to learn a policy to estima
    
[^113]: 模拟失调: 大型语言模型的安全对齐可能会适得其反！

    Emulated Disalignment: Safety Alignment for Large Language Models May Backfire!

    [https://arxiv.org/abs/2402.12343](https://arxiv.org/abs/2402.12343)

    安全对齐的大型语言模型可能会通过模拟失调框架，在对抗性操纵下产生危险结果，对训练的语言模型具有双倍有害性，高于强基线，强调了即使在安全对齐后也需要重新评估开源语言模型的重要性。

    

    大型语言模型（LLMs）需要进行安全对齐，以确保与人类进行安全的对话。然而，在这项工作中，我们引入了一种推理时攻击框架，表明安全对齐也可能在对抗性操纵下无意中促成有害结果。这个框架被命名为模拟失调（ED），在输出空间中不良地组合了一对开源预训练和安全对齐的语言模型，产生了一个有害的语言模型而无需任何训练。我们对ED在三个数据集和四个模型系列（Llama-1、Llama-2、Mistral和Alpaca）上的实验表明，ED使预训练模型的有害性增加了一倍，并胜过强基线，以较大优势在48个评估子集中的43个中实现了最高的有害率。至关重要的是，我们的研究结果凸显了即使在安全对齐后，重新评估开源语言模型实践的重要性。

    arXiv:2402.12343v1 Announce Type: new  Abstract: Large language models (LLMs) need to undergo safety alignment to ensure safe conversations with humans. However, in this work, we introduce an inference-time attack framework, demonstrating that safety alignment can also unintentionally facilitate harmful outcomes under adversarial manipulation. This framework, named Emulated Disalignment (ED), adversely combines a pair of open-source pre-trained and safety-aligned language models in the output space to produce a harmful language model without any training. Our experiments with ED across three datasets and four model families (Llama-1, Llama-2, Mistral, and Alpaca) show that ED doubles the harmfulness of pre-trained models and outperforms strong baselines, achieving the highest harmful rate in 43 out of 48 evaluation subsets by a large margin. Crucially, our findings highlight the importance of reevaluating the practice of open-sourcing language models even after safety alignment.
    
[^114]: 赋予预训练图模型具有可证明的公平性

    Endowing Pre-trained Graph Models with Provable Fairness

    [https://arxiv.org/abs/2402.12161](https://arxiv.org/abs/2402.12161)

    提出了一种新的适配器调优框架，赋予预训练图模型具有可证明的公平性

    

    预训练图模型（PGMs）旨在捕捉可转移的固有结构属性，并将其应用于不同的下游任务。类似于预训练语言模型，PGMs也会继承人类社会中的偏见，导致在下游应用中出现歧视行为。现有公平方法的去偏见过程通常与GNNs的参数优化相结合。然而，不同的下游任务在现实中可能与不同的敏感属性相关联，直接采用现有方法改善PGMs的公平性是不灵活且低效的。此外，大多数方法缺乏理论保证，即对模型预测公平性的可证明下限，这直接提供了实际场景下的保证。为了克服这些限制，我们提出了一种新的适配器调优框架，赋予预训练\textbf{图}模型具有\textbf{可证明}的\textbf{公}平\textbf{性}（称为

    arXiv:2402.12161v1 Announce Type: cross  Abstract: Pre-trained graph models (PGMs) aim to capture transferable inherent structural properties and apply them to different downstream tasks. Similar to pre-trained language models, PGMs also inherit biases from human society, resulting in discriminatory behavior in downstream applications. The debiasing process of existing fair methods is generally coupled with parameter optimization of GNNs. However, different downstream tasks may be associated with different sensitive attributes in reality, directly employing existing methods to improve the fairness of PGMs is inflexible and inefficient. Moreover, most of them lack a theoretical guarantee, i.e., provable lower bounds on the fairness of model predictions, which directly provides assurance in a practical scenario. To overcome these limitations, we propose a novel adapter-tuning framework that endows pre-trained \textbf{Graph} models with \textbf{P}rovable f\textbf{A}i\textbf{R}ness (called
    
[^115]: WKVQuant：量化大型语言模型的参数权重和键值缓存以提高性能

    WKVQuant: Quantizing Weight and Key/Value Cache for Large Language Models Gains More

    [https://arxiv.org/abs/2402.12065](https://arxiv.org/abs/2402.12065)

    该论文提出了WKVQuant，一种专为大型语言模型设计的量化框架，通过量化权重和键值缓存来改善性能。

    

    大型语言模型（LLMs）面临着部署挑战，主要是由于其巨大的内存需求和自回归文本生成过程的计算需求。本文通过关注LLMs的量化来解决这些挑战，量化是一种通过将模型参数和激活转换为低比特整数来减少内存消耗的技术。我们批判性地分析了现有的量化方法，识别出它们在平衡量化LLMs的准确性和效率方面的局限性。为了超越这些局限性，我们提出了WKVQuant，这是一个专为量化LLMs的参数权重和键值（KV）缓存而设计的PTQ框架。具体而言，我们引入了仅考虑过去的量化以改善注意力计算。此外，我们还介绍了二维量化策略来处理KV缓存的分布，以及一种跨块重建正则化方法以帮助模型压缩。

    arXiv:2402.12065v1 Announce Type: cross  Abstract: Large Language Models (LLMs) face significant deployment challenges due to their substantial memory requirements and the computational demands of auto-regressive text generation process. This paper addresses these challenges by focusing on the quantization of LLMs, a technique that reduces memory consumption by converting model parameters and activations into low-bit integers. We critically analyze the existing quantization approaches, identifying their limitations in balancing the accuracy and efficiency of the quantized LLMs. To advance beyond these limitations, we propose WKVQuant, a PTQ framework especially designed for quantizing weights and the key/value (KV) cache of LLMs. Specifically, we incorporates past-only quantization to improve the computation of attention. Additionally, we introduce two-dimensional quantization strategy to handle the distribution of KV cache, along with a cross-block reconstruction regularization for pa
    
[^116]: 对角化SGD：通过重新参数化和平滑实现非可微模型的快速收敛SGD

    Diagonalisation SGD: Fast & Convergent SGD for Non-Differentiable Models via Reparameterisation and Smoothing

    [https://arxiv.org/abs/2402.11752](https://arxiv.org/abs/2402.11752)

    引入了Diagonalisation Stochastic Gradient Descent（对角化SGD），通过重新参数化和平滑实现非可微模型的快速收敛SGD，在实证评估中表现出简单、快速、稳定，并且取得了数量级的工作规范化方差降低。

    

    众所周知，对于非可微模型，展现出较低方差的重新参数化梯度估计器在实践中存在偏差。这可能危及基于梯度的优化方法（如随机梯度下降SGD）的正确性。我们引入了一个简单的语法框架来分块地定义非可微函数，并提出了一种系统方法，以获得使重新参数化梯度估计器无偏的平滑。我们的主要贡献是一种新颖的SGD变体，对角化随机梯度下降，它在优化过程中逐步提高平滑近似的准确性，并证明收敛到未平滑（原始）目标的稳定点。我们的实证评估显示，与现有技术相比，我们的方法简单、快速、稳定，并且在工作规范化方差上实现了数量级的降低。

    arXiv:2402.11752v1 Announce Type: cross  Abstract: It is well-known that the reparameterisation gradient estimator, which exhibits low variance in practice, is biased for non-differentiable models. This may compromise correctness of gradient-based optimisation methods such as stochastic gradient descent (SGD). We introduce a simple syntactic framework to define non-differentiable functions piecewisely and present a systematic approach to obtain smoothings for which the reparameterisation gradient estimator is unbiased. Our main contribution is a novel variant of SGD, Diagonalisation Stochastic Gradient Descent, which progressively enhances the accuracy of the smoothed approximation during optimisation, and we prove convergence to stationary points of the unsmoothed (original) objective. Our empirical evaluation reveals benefits over the state of the art: our approach is simple, fast, stable and attains orders of magnitude reduction in work-normalised variance.
    
[^117]: 异类自动提示的不合理有效性

    The Unreasonable Effectiveness of Eccentric Automatic Prompts

    [https://arxiv.org/abs/2402.10949](https://arxiv.org/abs/2402.10949)

    异类自动提示的不合理有效性研究了大型语言模型在处理各种提示时的表现，结果显示在大多数情况下，包括“积极思考”提示会对模型性能产生积极影响。

    

    大型语言模型（LLMs）展示了出色的问题解决和基本数学能力。然而，它们的功效高度依赖于提示的制定。本研究旨在量化将“积极思考”纳入系统提示消息的影响，然后将其与系统化提示优化进行比较。我们评估了60种系统消息片段的性能，分别使用和不使用Chain of Thought提示，跨三个参数范围从70亿到70亿个变量的模型，在GSM8K数据集上进行测试。我们的发现表明，结果并不在所有模型中普遍适用。在大多数情况下，包括“积极思考”提示会积极影响模型性能。然而，值得注意的是，Llama2-70B在不使用Chain of Thought时是个例外，因为发现最佳系统消息实际上是没有消息。考虑到组合复杂性，以及其导至的加# Truncated due to exceeding character limit.

    arXiv:2402.10949v1 Announce Type: new  Abstract: Large Language Models (LLMs) have demonstrated remarkable problem-solving and basic mathematics abilities. However, their efficacy is highly contingent on the formulation of the prompt. This study endeavors to quantify the influence of incorporating "positive thinking" into the system message of the prompt, then compare that to systematic prompt optimization. We assess the performance of 60 combinations of system message snippets, tested with and without Chain of Thought prompting, across three models with parameters ranging from 7 to 70 billion on the GSM8K dataset. Our findings reveal that results do not universally generalize across models. In most instances, the inclusion of "positive thinking" prompts positively affected model performance. Notably, however, Llama2-70B exhibited an exception when not utilizing Chain of Thought, as the optimal system message was found to be none at all. Given the combinatorial complexity, and thus com
    
[^118]: ConSmax: 具有可学习参数的硬件友好型Softmax替代方案

    ConSmax: Hardware-Friendly Alternative Softmax with Learnable Parameters

    [https://arxiv.org/abs/2402.10930](https://arxiv.org/abs/2402.10930)

    ConSmax是一种硬件友好型Softmax替代方案，通过引入可学习参数，在不影响性能的情况下实现了对原Softmax关键任务的高效处理。

    

    自注意机制将基于transformer的大型语言模型（LLM）与卷积和循环神经网络区分开来。尽管性能有所提升，但由于自注意中广泛使用Softmax，在硅上实现实时LLM推断仍具挑战性。为了解决这一挑战，我们提出了Constant Softmax（ConSmax），这是一种高效的Softmax替代方案，采用可微的规范化参数来消除Softmax中的最大搜索和分母求和，实现了大规模并行化。

    arXiv:2402.10930v1 Announce Type: cross  Abstract: The self-attention mechanism sets transformer-based large language model (LLM) apart from the convolutional and recurrent neural networks. Despite the performance improvement, achieving real-time LLM inference on silicon is challenging due to the extensively used Softmax in self-attention. Apart from the non-linearity, the low arithmetic intensity greatly reduces the processing parallelism, which becomes the bottleneck especially when dealing with a longer context. To address this challenge, we propose Constant Softmax (ConSmax), a software-hardware co-design as an efficient Softmax alternative. ConSmax employs differentiable normalization parameters to remove the maximum searching and denominator summation in Softmax. It allows for massive parallelization while performing the critical tasks of Softmax. In addition, a scalable ConSmax hardware utilizing a bitwidth-split look-up table (LUT) can produce lossless non-linear operation and 
    
[^119]: 使用有条件降噪扩散模型进行射电天文图像重建

    Radio-astronomical Image Reconstruction with Conditional Denoising Diffusion Model

    [https://arxiv.org/abs/2402.10204](https://arxiv.org/abs/2402.10204)

    该研究提出使用有条件降噪扩散模型从不干净的射电图像中重建天空模型，以实现准确定位和测量流量，为射电源的表征提供潜在改进。

    

    从不干净的射电图像中重建天空模型，以便准确定位和测量流量对于研究高红移下的星系演化至关重要，尤其是在使用Atacama Large Millimetre Array (ALMA)等仪器进行深度观测时。随着Square Kilometre Array (SKA)等新项目的启动，对更好的源提取方法的需求日益增长。目前的技术，如CLEAN和PyBDSF，往往无法检测到微弱的源，凸显了对更准确方法的需求。本研究提议使用随机神经网络直接从不干净的图像中重建天空模型。该方法可以精确定位射电源并测量伴随的不确定性，标志着射电源表征方面的潜在改进。我们在使用基于ALMA第5.3周期天线设置的CASA工具simalma模拟的10164个图像上测试了这种方法。

    arXiv:2402.10204v1 Announce Type: cross  Abstract: Reconstructing sky models from dirty radio images for accurate source localization and flux estimation is crucial for studying galaxy evolution at high redshift, especially in deep fields using instruments like the Atacama Large Millimetre Array (ALMA). With new projects like the Square Kilometre Array (SKA), there's a growing need for better source extraction methods. Current techniques, such as CLEAN and PyBDSF, often fail to detect faint sources, highlighting the need for more accurate methods. This study proposes using stochastic neural networks to rebuild sky models directly from dirty images. This method can pinpoint radio sources and measure their fluxes with related uncertainties, marking a potential improvement in radio source characterization. We tested this approach on 10164 images simulated with the CASA tool simalma, based on ALMA's Cycle 5.3 antenna setup. We applied conditional Denoising Diffusion Probabilistic Models (D
    
[^120]: 重塑RLHF中的信息结构：基于图论的奖励泛化视角

    Rethinking Information Structures in RLHF: Reward Generalization from a Graph Theory Perspective

    [https://arxiv.org/abs/2402.10184](https://arxiv.org/abs/2402.10184)

    本研究通过设计奖励建模过程中的数据集信息结构，从图论的视角提出了RLHF中奖励泛化的问题，以解决多样的环境、低成本标注和可靠的对齐性能间的不兼容性。

    

    在强化学习从人类反馈中（RLHF）存在一个三难问题：高度多样的环境、低标注成本和可靠的对齐性能之间的不兼容性。本文旨在通过设计奖励建模过程中的数据集信息结构来缓解这种不兼容性。具体而言，我们重新审视了RLHF过程，并提出了一个理论框架将其描绘为文本分布上的自动编码过程。我们的框架形式化了RLHF目标，即确保人类偏好与大型语言模型（LLM）行为之间的分布一致性。基于这个框架，我们系统地研究了RLHF奖励建模阶段中信息结构的性能影响。为了进一步理解奖励建模阶段中的奖励泛化，我们引入了一种基于随机图论的方法来建模语义空间中的泛化。其中的关键见解是...

    arXiv:2402.10184v1 Announce Type: cross  Abstract: There is a trilemma in reinforcement learning from human feedback (RLHF): the incompatibility between highly diverse contexts, low labeling cost, and reliable alignment performance. Here we aim to mitigate such incompatibility through the design of dataset information structures during reward modeling. Specifically, we first reexamine the RLHF process and propose a theoretical framework portraying it as an autoencoding process over text distributions. Our framework formalizes the RLHF objective of ensuring distributional consistency between human preference and large language model (LLM) behavior. Building on this framework, we then systematically investigate the performance impact of information structure in the reward modeling stage of RLHF. To further understand reward generalization in the reward modeling stage, we introduce a new method based on random graph theory that models generalization in the semantic space. A key insight of
    
[^121]: Clifford群等变单体消息传递网络

    Clifford Group Equivariant Simplicial Message Passing Networks

    [https://arxiv.org/abs/2402.10011](https://arxiv.org/abs/2402.10011)

    本论文介绍了一种Clifford群等变单体消息传递网络，通过将Clifford群等变层与单体消息传递相结合，实现了在拓扑上更为复杂的E（n）-等变消息传递。实验结果表明，该方法具有良好的效果。

    

    我们引入了Clifford群等变单体消息传递网络，这是一种在单体复合体上进行可控的E（n）-等变消息传递的方法。我们的方法将Clifford群等变层的表达能力与单体消息传递相结合，后者在拓扑上比常规图消息传递更加复杂。Clifford代数包括高阶对象，如双向量和三向量，这些对象通过向量衍生出几何特征（例如面积，体积）。利用这些知识，我们通过顶点的几何乘积表示简单形式特征。为了实现高效的单体消息传递，我们在不同维度之间共享消息网络的参数。此外，我们将最终的消息限制为来自不同维度的传入消息的聚合，从而导致了我们称之为共享单体消息传递的方法。实验结果表明，我们的方法能够输出适当的结果。

    arXiv:2402.10011v1 Announce Type: new  Abstract: We introduce Clifford Group Equivariant Simplicial Message Passing Networks, a method for steerable E(n)-equivariant message passing on simplicial complexes. Our method integrates the expressivity of Clifford group-equivariant layers with simplicial message passing, which is topologically more intricate than regular graph message passing. Clifford algebras include higher-order objects such as bivectors and trivectors, which express geometric features (e.g., areas, volumes) derived from vectors. Using this knowledge, we represent simplex features through geometric products of their vertices. To achieve efficient simplicial message passing, we share the parameters of the message network across different dimensions. Additionally, we restrict the final message to an aggregation of the incoming messages from different dimensions, leading to what we term shared simplicial message passing. Experimental results show that our method is able to ou
    
[^122]: 有限预算下的迅速学习最佳臂识别

    Best Arm Identification for Prompt Learning under a Limited Budget

    [https://arxiv.org/abs/2402.09723](https://arxiv.org/abs/2402.09723)

    这项工作提出了一种在提示学习中考虑有限预算约束的方法，通过建立提示学习和多臂赌博机中固定预算最佳臂识别之间的联系，提出了一个通用框架TRIPLE，通过利用聚类和嵌入思想实现了两个增强方法。

    

    大型语言模型（LLMs）的显著指令跟随能力引发了对自动学习合适提示的兴趣。然而，虽然提出了许多有效的方法，但在学习过程中产生的成本（例如访问LLM和评估响应）尚未得到考虑。为克服这个限制，本工作在提示学习中明确引入了有限预算约束。为了开发有原则的解决方案，本研究在提示学习和多臂赌博机的固定预算最佳臂识别（BAI-FB）之间建立了一种新的联系。基于这种联系，提出了一个通用框架TRIPLE（用于提示学习的最佳臂识别），以系统地利用BAI-FB在提示学习中的力量。提示学习的独特特点进一步通过利用聚类和嵌入思想提出了TRIPLE的两个基于嵌入的增强方法。

    arXiv:2402.09723v1 Announce Type: cross  Abstract: The remarkable instruction-following capability of large language models (LLMs) has sparked a growing interest in automatically learning suitable prompts. However, while many effective methods have been proposed, the cost incurred during the learning process (e.g., accessing LLM and evaluating the responses) has not been considered. To overcome this limitation, this work explicitly incorporates a finite budget constraint into prompt learning. Towards developing principled solutions, a novel connection is established between prompt learning and fixed-budget best arm identification (BAI-FB) in multi-armed bandits (MAB). Based on this connection, a general framework TRIPLE (besT aRm Identification for Prompt LEarning) is proposed to harness the power of BAI-FB in prompt learning systematically. Unique characteristics of prompt learning further lead to two embedding-based enhancements of TRIPLE by exploiting the ideas of clustering and fun
    
[^123]: 多模态动作质量评估

    Multimodal Action Quality Assessment

    [https://arxiv.org/abs/2402.09444](https://arxiv.org/abs/2402.09444)

    该论文提出了一个名为PAMFN的渐进自适应多模态融合网络，用于多模态动作质量评估。该模型利用RGB、光流和音频信息，分别建模模态特定信息和混合模态信息，并通过充分利用音频信息，提高了评分回归的准确性。

    

    行动质量评估（AQA）是评估动作执行情况的方法。以往的研究仅利用视觉信息进行建模，忽视了音频信息。我们认为，虽然AQA高度依赖视觉信息，但音频也是提高评分回归准确性的有用补充信息，特别是在具有背景音乐的运动项目中，如花样滑冰和韵律体操。为了利用多模态信息进行AQA，即RGB、光流和音频信息，我们提出了一个渐进自适应多模态融合网络（PAMFN），它分别对模态特定信息和混合模态信息进行建模。我们的模型由三个模态特定分支和一个混合模态分支组成，独立地探索模态特定信息，并渐进地聚合来自模态特定分支的模态特定信息。

    arXiv:2402.09444v1 Announce Type: cross  Abstract: Action quality assessment (AQA) is to assess how well an action is performed. Previous works perform modelling by only the use of visual information, ignoring audio information. We argue that although AQA is highly dependent on visual information, the audio is useful complementary information for improving the score regression accuracy, especially for sports with background music, such as figure skating and rhythmic gymnastics. To leverage multimodal information for AQA, i.e., RGB, optical flow and audio information, we propose a Progressive Adaptive Multimodal Fusion Network (PAMFN) that separately models modality-specific information and mixed-modality information. Our model consists of with three modality-specific branches that independently explore modality-specific information and a mixed-modality branch that progressively aggregates the modality-specific information from the modality-specific branches. To build the bridge between
    
[^124]: 数据到文本自然语言生成研究的系统性回顾

    A Systematic Review of Data-to-Text NLG

    [https://arxiv.org/abs/2402.08496](https://arxiv.org/abs/2402.08496)

    这篇系统性回顾全面分析了数据到文本自然语言生成研究的现状，提出未来方向，并解决了相关挑战。

    

    这篇系统性回顾旨在全面分析数据到文本生成研究的现状，重点是确定研究空白，提供未来方向，并解决回顾中发现的挑战。我们对文献进行了全面的检查，包括方法、数据集、评估指标、应用、多语言性和幻觉缓解措施。我们的回顾为这个快速发展的领域的未来研究提供了路线图。

    This systematic review aims to provide a comprehensive analysis of the state of data-to-text generation research, focusing on identifying research gaps, offering future directions, and addressing challenges found during the review. We thoroughly examined the literature, including approaches, datasets, evaluation metrics, applications, multilingualism, and hallucination mitigation measures. Our review provides a roadmap for future research in this rapidly evolving field.
    
[^125]: 深度强化学习在细胞重编程的布尔模型吸引子景观中的控制遍历中的应用研究

    Deep Reinforcement Learning for Controlled Traversing of the Attractor Landscape of Boolean Models in the Context of Cellular Reprogramming

    [https://arxiv.org/abs/2402.08491](https://arxiv.org/abs/2402.08491)

    本研究开发了一个基于深度强化学习的计算框架，用于细胞重编程中的重编程策略识别。在控制问题中，引入了伪吸引子的概念和识别方法，并设计了一个用于解决该问题的计算框架。

    

    细胞重编程可用于预防和治疗不同疾病。然而，通过传统湿实验发现重编程策略的效率受到时间和成本的限制。在本研究中，我们基于深度强化学习开发了一个新颖的计算框架，以便帮助识别重编程策略。为此，我们在细胞重编程框架的BNs和PBNs以及异步更新模式下制定了一个控制问题。此外，我们引入了伪吸引子的概念和训练过程中伪吸引子状态的识别方法。最后，我们设计了一个用于解决控制问题的计算框架，并在多个不同模型上进行了测试。

    Cellular reprogramming can be used for both the prevention and cure of different diseases. However, the efficiency of discovering reprogramming strategies with classical wet-lab experiments is hindered by lengthy time commitments and high costs. In this study, we develop a~novel computational framework based on deep reinforcement learning that facilitates the identification of reprogramming strategies. For this aim, we formulate a~control problem in the context of cellular reprogramming for the frameworks of BNs and PBNs under the asynchronous update mode. Furthermore, we introduce the notion of a~pseudo-attractor and a~procedure for identification of pseudo-attractor state during training. Finally, we devise a~computational framework for solving the control problem, which we test on a~number of different models.
    
[^126]: ChatCell: 利用自然语言促进单细胞分析

    ChatCell: Facilitating Single-Cell Analysis with Natural Language

    [https://arxiv.org/abs/2402.08303](https://arxiv.org/abs/2402.08303)

    ChatCell是一个利用自然语言促进单细胞分析的工具，通过词汇适应和统一序列生成，它具备深厚的专业知识和适应各种分析任务的能力。

    

    随着大型语言模型(LLMs)的快速发展，它们在科学中的影响日益突出。LLMs在任务泛化和自由对话方面的新兴能力可以极大地推进化学和生物学等领域。然而，单细胞生物学这个构成生物体基础构件的领域仍面临一些挑战。当前方法在知识门槛和可扩展性方面存在限制，阻碍了LLMs在掌握单细胞数据方面的充分利用，影响了直接可访问和快速迭代的能力。为此，我们引入了ChatCell，通过利用词汇适应和统一序列生成，它在单细胞生物学领域获得了深厚的专业知识和适应各种分析任务的能力，标志着一种范式转变。

    As Large Language Models (LLMs) rapidly evolve, their influence in science is becoming increasingly prominent. The emerging capabilities of LLMs in task generalization and free-form dialogue can significantly advance fields like chemistry and biology. However, the field of single-cell biology, which forms the foundational building blocks of living organisms, still faces several challenges. High knowledge barriers and limited scalability in current methods restrict the full exploitation of LLMs in mastering single-cell data, impeding direct accessibility and rapid iteration. To this end, we introduce ChatCell, which signifies a paradigm shift by facilitating single-cell analysis with natural language. Leveraging vocabulary adaptation and unified sequence generation, ChatCell has acquired profound expertise in single-cell biology and the capability to accommodate a diverse range of analysis tasks. Extensive experiments further demonstrate ChatCell's robust performance and potential to de
    
[^127]: Lissard：长而简单的顺序推理数据集

    Lissard: Long and Simple Sequential Reasoning Datasets

    [https://arxiv.org/abs/2402.07859](https://arxiv.org/abs/2402.07859)

    Lissard是一个包含七个任务的基准，用于评估模型处理和生成各种序列长度的能力，需要重复的过程执行。评估结果显示随着序列复杂性增加，所有模型的性能都呈一致下降趋势。

    

    语言模型现在能够解决需要处理数十万个标记的长序列的任务。然而，它们在需要重复使用简单规则的任务上常常失败，甚至在比训练中看到的序列要短得多的情况下也是如此。例如，最先进的LLMs可以在两个列表中找到共同项，列表中的项最多可达20个，但是当列表中的项达到80个时，它们会失败。在本文中，我们介绍了Lissard，这是一个包含七个任务的基准，旨在评估模型处理和生成各种序列长度的能力，需要重复的过程执行。我们评估了开源模型（Mistral-7B和Mixtral-8x7B）和专有模型（GPT-3.5和GPT-4），结果显示随着序列复杂性增加，所有模型的性能都呈一致下降趋势。数据集和代码可在https://github.com/unicamp-dl/Lissard获得。

    Language models are now capable of solving tasks that require dealing with long sequences consisting of hundreds of thousands of tokens. However, they often fail on tasks that require repetitive use of simple rules, even on sequences that are much shorter than those seen during training. For example, state-of-the-art LLMs can find common items in two lists with up to 20 items but fail when lists have 80 items. In this paper, we introduce Lissard, a benchmark comprising seven tasks whose goal is to assess the ability of models to process and generate wide-range sequence lengths, requiring repetitive procedural execution. Our evaluation of open-source (Mistral-7B and Mixtral-8x7B) and proprietary models (GPT-3.5 and GPT-4) show a consistent decline in performance across all models as the complexity of the sequence increases. The datasets and code are available at https://github.com/unicamp-dl/Lissard
    
[^128]: 使用无监督度量优化GNN进行节点聚类的研究

    An Investigation into Using Unsupervised Metrics to Optimise GNNs for Node Clustering

    [https://arxiv.org/abs/2402.07845](https://arxiv.org/abs/2402.07845)

    本研究展示了使用无监督度量模块性优化GNN进行节点聚类的方法，且无需与基准值进行比较。在设计合成实验的过程中，我们发现了这种方法的局限性。

    

    图神经网络（GNN）可以通过学习特征和连接信息的二元性来训练以检测图中的社区。目前，优化GNN的常见方法是使用与基准值的比较来进行超参数调整和模型选择。本研究表明，仅通过优化模块性，可以使用GNN将节点聚类成社区，而无需与基准值进行比较。尽管模块性是一种图分区质量度量，我们证明这也可以用于优化同时编码特征的GNN，并且不会降低性能。我们进一步研究无监督度量性能是否能够预测基准值的性能。为了探究为什么可以使用模块性优化GNN，我们设计了一些合成实验来展示这种方法的局限性。这些合成图表明其在不同、随机和零信息空间分区中的当前能力。

    Graph Neural Networks (GNNs) can be trained to detect communities within a graph by learning from the duality of feature and connectivity information. Currently, the common approach for optimisation of GNNs is to use comparisons to ground-truth for hyperparameter tuning and model selection. In this work, we show that nodes can be clustered into communities with GNNs by solely optimising for modularity, without any comparison to ground-truth. Although modularity is a graph partitioning quality metric, we show that this can be used to optimise GNNs that also encode features without a drop in performance. We take it a step further and also study whether the unsupervised metric performance can predict ground-truth performance. To investigate why modularity can be used to optimise GNNs, we design synthetic experiments that show the limitations of this approach. The synthetic graphs are created to highlight current capabilities in distinct, random and zero information space partitions in att
    
[^129]: 用于车辆定位的粒子滤波SLAM方法

    Particle Filter SLAM for Vehicle Localization

    [https://arxiv.org/abs/2402.07429](https://arxiv.org/abs/2402.07429)

    本研究采用粒子滤波SLAM方法解决了车辆定位的挑战，利用编码数据、光纤陀螺仪和激光雷达技术实现精确的车辆运动估计和环境感知。

    

    同时定位与建图（SLAM）在机器人技术中是一个艰巨的挑战，涉及在陌生环境中动态构建地图的同时确定机器人定位的精确位置。这项复杂的任务受到了“先有鸡还是先有蛋”困境的影响，准确的建图依赖于可靠的机器人定位估计，反之亦然。此外，SLAM的计算密集性增加了额外的复杂性，使其成为该领域中重要而具有挑战性的主题。在我们的研究中，我们采用了粒子滤波SLAM方法来解决SLAM的挑战。我们的方法利用编码数据和光纤陀螺仪（FOG）信息，实现对车辆运动的精确估计，而激光雷达技术通过提供有关周围障碍物的详细信息，对环境感知作出贡献。这些数据流的集成最终建立了一个粒子滤波SLAM模型。

    Simultaneous Localization and Mapping (SLAM) presents a formidable challenge in robotics, involving the dynamic construction of a map while concurrently determining the precise location of the robotic agent within an unfamiliar environment. This intricate task is further compounded by the inherent "chicken-and-egg" dilemma, where accurate mapping relies on a dependable estimation of the robot's location, and vice versa. Moreover, the computational intensity of SLAM adds an additional layer of complexity, making it a crucial yet demanding topic in the field. In our research, we address the challenges of SLAM by adopting the Particle Filter SLAM method. Our approach leverages encoded data and fiber optic gyro (FOG) information to enable precise estimation of vehicle motion, while lidar technology contributes to environmental perception by providing detailed insights into surrounding obstacles. The integration of these data streams culminates in the establishment of a Particle Filter SLAM
    
[^130]: 带有注意机制的新闻推荐

    News Recommendation with Attention Mechanism

    [https://arxiv.org/abs/2402.07422](https://arxiv.org/abs/2402.07422)

    本文提出了一种新的带有注意机制的新闻推荐方法NRAM，该方法可以显著提高数字新闻平台上的用户个性化新闻内容质量。

    

    本文探索了新闻推荐领域，这是在线信息分享的关键组成部分。首先，我们对新闻推荐进行了清晰的介绍，定义了核心问题并总结了当前方法和近期值得注意的算法。然后，我们提出了NRAM（带有注意机制的新闻推荐）的实现，这是一种基于注意力机制的新闻推荐方法，并评估了其有效性。我们的评估表明，NRAM有潜力显著提高数字新闻平台上针对用户个性化的新闻内容质量。

    This paper explores the area of news recommendation, a key component of online information sharing. Initially, we provide a clear introduction to news recommendation, defining the core problem and summarizing current methods and notable recent algorithms. We then present our work on implementing the NRAM (News Recommendation with Attention Mechanism), an attention-based approach for news recommendation, and assess its effectiveness. Our evaluation shows that NRAM has the potential to significantly improve how news content is personalized for users on digital news platforms.
    
[^131]: GraphTranslator：将图模型与大型语言模型对齐用于开放式任务

    GraphTranslator: Aligning Graph Model to Large Language Model for Open-ended Tasks

    [https://arxiv.org/abs/2402.07197](https://arxiv.org/abs/2402.07197)

    "GraphTranslator"是一个旨在将预训练的图模型和大型语言模型对齐的翻译器，可以同时处理预定义任务和开放式任务。通过将这两种模型结合起来，能够有效地处理各种任务，并实现更具创新性和灵活性的应用。

    

    大型语言模型（LLMs）如ChatGPT，展示了强大的零样本和遵循指令的能力，在人工智能的各个研究领域中引发了一场革命性的转变，尤其是对于开放式任务。尽管在图领域中这个想法较少被探索，尽管有许多强大的图模型（GMs）可用，但它们被限制在预定义形式的任务中。虽然已经提出了几种将LLMs应用于图的方法，但它们未能同时处理预定义任务和开放式任务，无论是将LLMs作为节点特征增强器还是作为独立预测器。为了打破这个困境，我们提出了一个名为GraphTranslator的翻译器，旨在通过预训练的GM和LLMs之间的桥梁，有效地处理预定义任务，并利用LLMs的扩展接口为GM提供各种开放式任务。为了训练这样的翻译器，我们提出了一个称为Producer的构建图文对齐数据的工具。

    Large language models (LLMs) like ChatGPT, exhibit powerful zero-shot and instruction-following capabilities, have catalyzed a revolutionary transformation across diverse research fields of artificial intelligence, especially for open-ended tasks. While the idea is less explored in the graph domain, despite the availability of numerous powerful graph models (GMs), they are restricted to tasks in a pre-defined form. Although several methods applying LLMs to graphs have been proposed, they fail to simultaneously handle the pre-defined and open-ended tasks, with LLM as a node feature enhancer or as a standalone predictor. To break this dilemma, we propose to bridge the pretrained GM and LLM by a Translator, named GraphTranslator, aiming to leverage GM to handle the pre-defined tasks effectively and utilize the extended interface of LLMs to offer various open-ended tasks for GM. To train such Translator, we propose a Producer capable of constructing the graph-text alignment data along node
    
[^132]: 文字描述中的顺序对大语言模型的空间感知能力的影响

    Sequential Ordering in Textual Descriptions: Impact on Spatial Perception Abilities of Large Language Models

    [https://arxiv.org/abs/2402.07140](https://arxiv.org/abs/2402.07140)

    这项研究揭示了图描述的文本顺序对大语言模型在图推理中的性能产生显著影响，并通过改变文本顺序提高了大语言模型的性能。此外，发现大语言模型的推理性能与图大小之间的关系不是单调递减的。为了评估大语言模型在不同图大小上的性能，引入了规模化图推理基准。

    

    最近几年，大语言模型在多个领域达到了最先进的性能。然而，图推理领域的进展仍然有限。我们的工作深入研究了大语言模型的图推理。在这项工作中，我们揭示了文本顺序对大语言模型空间理解的影响，发现图描述的文本顺序显著影响大语言模型对图的推理性能。通过改变图描述的文本顺序，我们将大语言模型的性能从42.22％提高到70％。此外，我们评估了大语言模型性能和图大小之间的关系，发现大语言模型的推理性能不随图大小的增加而单调递减。最后，我们引入了规模化图推理基准来评估大语言模型在不同图大小上的性能。

    In recent years, Large Language Models have reached state-of-the-art performance across multiple domains. However, the progress in the field of graph reasoning remains limited. Our work delves into this gap by thoroughly investigating graph reasoning with LLM. In this work, we reveal the impact of text sequence on LLM spatial understanding, finding that graph-descriptive text sequences significantly affect LLM reasoning performance on graphs. By altering the graph-descriptive text sequences, we enhance the performance of LLM from 42.22\% to 70\%. Furthermore, we evaluate the relationship between LLM performance and graph size, discovering that the reasoning performance of LLM does not monotonically decrease with the increase in graph size. Conclusively, we introduce the Scaled Graph Reasoning benchmark for assessing LLM performance across varied graph sizes.
    
[^133]: 大型语言模型：一项调查

    Large Language Models: A Survey

    [https://arxiv.org/abs/2402.06196](https://arxiv.org/abs/2402.06196)

    大型语言模型（LLMs）吸引了很多关注，因为它们在自然语言任务上的强大表现。该研究领域发展迅速，包括了各种著名的LLMs、构建和增强LLMs的技术、以及流行的LLM数据集和评估指标。

    

    大型语言模型（LLMs）由于其在各种自然语言任务上的出色表现而受到了很多关注，自2022年11月ChatGPT发布以来。LLMs通过在大量文本数据上训练模型的数十亿参数来获得广泛的通用语言理解和生成能力，这符合缩放定律的预测。LLMs的研究领域尽管非常新，但在许多不同方面正在快速发展。在本文中，我们回顾了一些最著名的LLMs，包括三个流行的LLM系列（GPT、LLaMA、PaLM），并讨论了它们的特点、贡献和限制。我们还概述了构建和增强LLMs的技术。然后，我们调查了为LLM训练、微调和评估准备的流行数据集，审查了广泛使用的LLM评估指标，并比较了几个流行LLM在一组代表性基准上的性能。

    Large Language Models (LLMs) have drawn a lot of attention due to their strong performance on a wide range of natural language tasks, since the release of ChatGPT in November 2022. LLMs' ability of general-purpose language understanding and generation is acquired by training billions of model's parameters on massive amounts of text data, as predicted by scaling laws \cite{kaplan2020scaling,hoffmann2022training}. The research area of LLMs, while very recent, is evolving rapidly in many different ways. In this paper, we review some of the most prominent LLMs, including three popular LLM families (GPT, LLaMA, PaLM), and discuss their characteristics, contributions and limitations. We also give an overview of techniques developed to build, and augment LLMs. We then survey popular datasets prepared for LLM training, fine-tuning, and evaluation, review widely used LLM evaluation metrics, and compare the performance of several popular LLMs on a set of representative benchmarks. Finally, we co
    
[^134]: LESS：用于目标指导调整的选择有影响力的数据

    LESS: Selecting Influential Data for Targeted Instruction Tuning

    [https://arxiv.org/abs/2402.04333](https://arxiv.org/abs/2402.04333)

    LESS是一种优化感知且实际高效的算法，用于在大型语言模型中选择具有影响力的数据以开发特定能力，它采用低秩梯度相似性搜索方法进行指令数据选择。

    

    指令调整已经在大型语言模型中释放出强大的能力，有效地使用组合数据集来开发通用聊天机器人。然而，实际应用往往需要一套专门的技能（例如推理）。挑战在于从这些广泛的数据集中识别出最相关的数据，以有效开发特定的能力，我们将这种情况称为目标指导调整。我们提出了LESS，一种优化感知且实际高效的算法，以有效估计数据影响并执行适用于指令数据选择的低秩梯度相似性搜索。关键在于LESS将现有的影响公式调整为与Adam优化器和可变长度指令数据一起工作。LESS首先构建了一个具有低维梯度特征的高度可重用和可传递的梯度数据存储库，然后根据它们与具有特定能力的少样本示例的相似度选择示例。实验证明，t

    Instruction tuning has unlocked powerful capabilities in large language models (LLMs), effectively using combined datasets to develop generalpurpose chatbots. However, real-world applications often require a specialized suite of skills (e.g., reasoning). The challenge lies in identifying the most relevant data from these extensive datasets to effectively develop specific capabilities, a setting we frame as targeted instruction tuning. We propose LESS, an optimizer-aware and practically efficient algorithm to effectively estimate data influences and perform Low-rank gradiEnt Similarity Search for instruction data selection. Crucially, LESS adapts existing influence formulations to work with the Adam optimizer and variable-length instruction data. LESS first constructs a highly reusable and transferable gradient datastore with low-dimensional gradient features and then selects examples based on their similarity to few-shot examples embodying a specific capability. Experiments show that t
    
[^135]: 光学钢丝绳非破坏性损伤检测的新方法

    A new method for optical steel rope non-destructive damage detection

    [https://arxiv.org/abs/2402.03843](https://arxiv.org/abs/2402.03843)

    本文提出了一种新的算法用于在高海拔环境中对钢丝绳进行非破坏性损伤检测，其中包括一种准确提取钢丝绳的分割模型和一种区分正常和异常钢丝绳的检测模型，实验证明其性能显著高于基准模型。

    

    本文提出了一种针对高海拔环境（空中吊索道）中的钢丝绳非破坏性损伤检测的新算法。该算法包括两个关键组件：首先，设计了一种名为RGBD-UNet的分割模型，可以准确地从复杂背景中提取钢丝绳。该模型通过提出的CMA模块可以处理和结合颜色和深度信息。其次，开发了一种名为VovNetV3.5的检测模型，用于区分正常和异常的钢丝绳。它将VovNet架构与DBB模块结合起来以提高性能。此外，还提出了一种新颖的背景增强方法，以增强分割模型的泛化能力。创建了包含不同场景中钢丝绳图像的数据集，用于分割和检测模型的训练和测试。实验证明，在基准模型上取得了显著的改进。在提出的数据集上，基于此算法的传感器识别性能（h）明显提高。

    This paper presents a novel algorithm for non-destructive damage detection for steel ropes in high-altitude environments (aerial ropeway). The algorithm comprises two key components: First, a segmentation model named RGBD-UNet is designed to accurately extract steel ropes from complex backgrounds. This model is equipped with the capability to process and combine color and depth information through the proposed CMA module. Second, a detection model named VovNetV3.5 is developed to differentiate between normal and abnormal steel ropes. It integrates the VovNet architecture with a DBB module to enhance performance. Besides, a novel background augmentation method is proposed to enhance the generalization ability of the segmentation model. Datasets containing images of steel ropes in different scenarios are created for the training and testing of both the segmentation and detection models. Experiments demonstrate a significant improvement over baseline models. On the proposed dataset, the h
    
[^136]: 统一的多模态大型语言模型的幻觉检测

    Unified Hallucination Detection for Multimodal Large Language Models

    [https://arxiv.org/abs/2402.03190](https://arxiv.org/abs/2402.03190)

    该论文提出了一个新颖的统一的多模态幻觉检测框架UNIHD，并设计了一个评估基准方法MHaluBench来评估幻觉检测方法的进展。这项工作扩展了幻觉检测的研究范围并提供了有效的解决方案。

    

    尽管在多模态任务方面取得了重大进展，多模态大型语言模型(MLLMs)仍然存在幻觉的严重问题。因此，可靠地检测MLLMs中的幻觉已成为模型评估和实际应用部署保障的重要方面。之前在这个领域的研究受到了狭窄的任务焦点、不足的幻觉类别涵盖范围以及缺乏详细的细粒度的限制。针对这些挑战，我们的工作扩展了幻觉检测的研究范围。我们提出了一个新颖的元评估基准方法，MHaluBench，精心设计以促进幻觉检测方法的进展评估。此外，我们揭示了一个新颖的统一多模态幻觉检测框架，UNIHD，它利用一套辅助工具来稳健地验证幻觉的发生。我们通过实验证明了UNIHD的有效性。

    Despite significant strides in multimodal tasks, Multimodal Large Language Models (MLLMs) are plagued by the critical issue of hallucination. The reliable detection of such hallucinations in MLLMs has, therefore, become a vital aspect of model evaluation and the safeguarding of practical application deployment. Prior research in this domain has been constrained by a narrow focus on singular tasks, an inadequate range of hallucination categories addressed, and a lack of detailed granularity. In response to these challenges, our work expands the investigative horizons of hallucination detection. We present a novel meta-evaluation benchmark, MHaluBench, meticulously crafted to facilitate the evaluation of advancements in hallucination detection methods. Additionally, we unveil a novel unified multimodal hallucination detection framework, UNIHD, which leverages a suite of auxiliary tools to validate the occurrence of hallucinations robustly. We demonstrate the effectiveness of UNIHD throug
    
[^137]: 多模态：文本和图像的多模态理解排行榜

    Multi: Multimodal Understanding Leaderboard with Text and Images

    [https://arxiv.org/abs/2402.03173](https://arxiv.org/abs/2402.03173)

    Multi是一个多模态理解的排行榜，提供了一个综合数据集，评估多模态大型语言模型对理解复杂图表和科学问题的能力。它兼具准确和开放式的回答形式，挑战MLLM的各种任务，并包含超过18,000个问题。

    

    多模态大型语言模型（MLLM）的快速进展强调了向学术界引入具有挑战性而又真实的基准的需求。现有的基准主要关注简单的自然图像理解，但Multi成为了MLLM的尖端基准，提供了一个综合性的数据集，用于评估MLLM对理解复杂图表和科学问题的能力。该基准反映了当前真实的考试风格，提供多模态的输入，并要求准确或开放式的回答，类似于现实中的学校考试。它通过各种任务挑战MLLM，从公式推导到图像细节分析，以及跨模态推理。Multi包括超过18,000个问题，重点关注不同格式的基于科学的问答。我们还引入了Multi-Elite，一个包含500个问题的子集，用于测试MLLM的极端情况，以及Multi-Extend，通过超过4..。

    Rapid progress in multimodal large language models (MLLMs) highlights the need to introduce challenging yet realistic benchmarks to the academic community. Existing benchmarks primarily focus on simple natural image understanding, but Multi emerges as a cutting-edge benchmark for MLLMs, offering a comprehensive dataset for evaluating MLLMs against understanding complex figures and tables, and scientific questions. This benchmark, reflecting current realistic examination styles, provides multimodal inputs and requires responses that are either precise or open-ended, similar to real-life school tests. It challenges MLLMs with a variety of tasks, ranging from formula derivation to image detail analysis, and cross-modality reasoning. Multi includes over 18,000 questions, with a focus on science-based QA in diverse formats. We also introduce Multi-Elite, a 500-question subset for testing the extremities of MLLMs, and Multi-Extend, which enhances In-Context Learning research with more than 4
    
[^138]: 变分流模型：以你的风格流动

    Variational Flow Models: Flowing in Your Style

    [https://arxiv.org/abs/2402.02977](https://arxiv.org/abs/2402.02977)

    我们引入了一种变分流模型的方法，并提出了一种系统的无需训练的转换方法，使得快速采样成为可能，同时保持了采样的准确性和效率。

    

    我们引入了一种对"后验流"模型进行变分推理解释的方法——用以将"概率流"推广到更广泛的随机过程类别，不必局限于扩散过程。我们将这种结果称为"变分流模型"。此外，我们提出了一种无需训练的系统方法，将由方程Xt = at * X0 + st * X1所描述的"线性"随机过程的后验流转化为直线恒速(SC)流，类似于矫正流。这种转化使得可以快速沿着原始的后验流进行采样，而无需训练一个新的SC流模型。我们的方法的灵活性使我们能够将转换扩展到两个不同"线性"随机过程的后验流之间进行互相转化。此外，我们还可以将高阶数值解法轻松集成到转换后的SC流中，进一步提高采样的准确性和效率。我们进行了严格的理论分析和大量实验结果的验证。

    We introduce a variational inference interpretation for models of "posterior flows" - generalizations of "probability flows" to a broader class of stochastic processes not necessarily diffusion processes. We coin the resulting models as "Variational Flow Models". Additionally, we propose a systematic training-free method to transform the posterior flow of a "linear" stochastic process characterized by the equation Xt = at * X0 + st * X1 into a straight constant-speed (SC) flow, reminiscent of Rectified Flow. This transformation facilitates fast sampling along the original posterior flow without training a new model of the SC flow. The flexibility of our approach allows us to extend our transformation to inter-convert two posterior flows from distinct "linear" stochastic processes. Moreover, we can easily integrate high-order numerical solvers into the transformed SC flow, further enhancing sampling accuracy and efficiency. Rigorous theoretical analysis and extensive experimental result
    
[^139]: PRewrite: 使用强化学习的提示重写

    PRewrite: Prompt Rewriting with Reinforcement Learning

    [https://arxiv.org/abs/2401.08189](https://arxiv.org/abs/2401.08189)

    本文提出了一种基于强化学习的自动化工具PRewrite，用于重写提示草案并生成高效的新提示，以解决提示工程中的挑战。

    

    arXiv:2401.08189v2 公告类型: 替换 摘要: 提示工程对于基于LLM的应用程序的开发至关重要。然而，通常以“试错”的方式手动完成。这种手动程序可能耗时，效果不佳，并且在许多情况下生成的提示都是次优的。即使对那些看似运作良好的提示，始终存在一个悬而未决的问题：是否可以通过进一步修改使提示变得更好呢？为了解决这些问题，在本文中，我们研究了提示工程自动化。我们考虑了一个特定的使用情景，即开发者/用户已经起草了初始提示，但缺乏时间/专业知识来优化它们。我们提出了PRewrite，一个自动化工具，可重写这些草案，并生成高效的新提示。PRewrite基于强化学习（RL）框架，允许端到端优化，我们的设计允许RL搜索在大动作空间中进行。

    arXiv:2401.08189v2 Announce Type: replace  Abstract: Prompt engineering is critical for the development of LLM-based applications. However, it is usually done manually in a "trial and error" fashion. This manual procedure can be time consuming, ineffective, and the generated prompts are, in a lot of cases, sub-optimal. Even for the prompts which seemingly work well, there is always a lingering question: can the prompts be made better with further modifications?   To address these questions, in this paper, we investigate prompt engineering automation. We consider a specific use case scenario in which developers/users have drafted initial prompts, but lack the time/expertise to optimize them. We propose PRewrite, an automated tool to rewrite these drafts and to generate highly effective new prompts. PRewrite is based on the Reinforcement Learning (RL) framework which allows for end-to-end optimization and our design allows the RL search to happen in a large action space. The automated to
    
[^140]: 规模化模型编辑会导致渐进性和突发性遗忘

    Model Editing at Scale leads to Gradual and Catastrophic Forgetting

    [https://arxiv.org/abs/2401.07453](https://arxiv.org/abs/2401.07453)

    评估了当前模型编辑方法在规模化情况下的表现，发现随着模型被顺序编辑多个事实，它会逐渐遗忘先前的事实及执行下游任务的能力。

    

    在大型语言模型中编辑知识是一种具有吸引力的能力，它使我们能够在预训练期间纠正错误学习的事实，同时使用不断增长的新事实列表更新模型。我们认为，为了使模型编辑具有实际效用，我们必须能够对同一模型进行多次编辑。因此，我们评估了当前规模下的模型编辑方法，重点关注两种最先进的方法：ROME 和 MEMIT。我们发现，随着模型被顺序编辑多个事实，它不断地遗忘先前编辑过的事实以及执行下游任务的能力。这种遗忘分为两个阶段--初始的渐进性遗忘阶段，随后是突然或灾难性的遗忘。

    arXiv:2401.07453v2 Announce Type: replace-cross  Abstract: Editing knowledge in large language models is an attractive capability to have which allows us to correct incorrectly learnt facts during pre-training, as well as update the model with an ever-growing list of new facts. While existing model editing techniques have shown promise, they are usually evaluated using metrics for reliability, specificity and generalization over one or few edits. We argue that for model editing to have practical utility, we must be able to make multiple edits to the same model. With this in mind, we evaluate the current model editing methods at scale, focusing on two state of the art methods: ROME and MEMIT. We find that as the model is edited sequentially with multiple facts, it continually forgets previously edited facts and the ability to perform downstream tasks. This forgetting happens in two phases -- an initial gradual but progressive forgetting phase followed by abrupt or catastrophic forgettin
    
[^141]: EHRAgent：代码赋能大型语言模型在电子健康记录上进行少样本复杂表格推理

    EHRAgent: Code Empowers Large Language Models for Few-shot Complex Tabular Reasoning on Electronic Health Records

    [https://arxiv.org/abs/2401.07128](https://arxiv.org/abs/2401.07128)

    EHRAgent是一个由代码接口赋能的大型语言模型代理，用于自主生成和执行多表格推理代码，通过错误信息学习改进生成的代码，结合长期记忆选择并建立在过去经验中的成功案例。

    

    大型语言模型（LLMs）在规划和工具利用方面表现出色，但在医学问题解决方面尚未有太多开发。我们提出EHRAgent，这是一个由代码接口赋能的LLM代理，用于在电子健康记录（EHRs）中自主生成和执行多表格推理的代码。首先，我们将EHR问答任务制定为工具使用规划过程，将一个复杂任务高效地分解为一系列可管理的操作。通过集成交互式编码和执行反馈，EHRAgent从错误消息中学习并通过迭代改进最初生成的代码。此外，我们通过结合长期记忆来增强LLM代理，使EHRAgent能够有效地选择并建立在过去经验中最相关的成功案例上。在三个真实世界的多表格EHR数据集上进行的实验显示...

    arXiv:2401.07128v2 Announce Type: replace-cross  Abstract: Large language models (LLMs) have demonstrated exceptional capabilities in planning and tool utilization as autonomous agents, but few have been developed for medical problem-solving. We propose EHRAgent, an LLM agent empowered with a code interface, to autonomously generate and execute code for multi-tabular reasoning within electronic health records (EHRs). First, we formulate an EHR question-answering task into a tool-use planning process, efficiently decomposing a complicated task into a sequence of manageable actions. By integrating interactive coding and execution feedback, EHRAgent learns from error messages and improves the originally generated code through iterations. Furthermore, we enhance the LLM agent by incorporating long-term memory, which allows EHRAgent to effectively select and build upon the most relevant successful cases from past experiences. Experiments on three real-world multi-tabular EHR datasets show t
    
[^142]: 在现实假设下的核回归中的泛化

    Generalization in Kernel Regression Under Realistic Assumptions

    [https://arxiv.org/abs/2312.15995](https://arxiv.org/abs/2312.15995)

    本文提供了一个统一的理论，用于对几乎所有常见和现实设置下的核回归的超出风险进行上限约束，并揭示了核分解中存在的自我正则化现象。

    

    现在已经确立的事实是，现代过度参数化模型似乎能够逃避偏差-方差权衡，在过度拟合噪音的情况下泛化良好。许多最近的研究尝试分析这一现象在核回归相对易处理的设置中。然而，正如我们详细讨论的那样，大多数关于这个主题的过去的研究要么做出了不切实际的假设，要么专注于一个狭窄的问题设置。本文旨在提供一个统一的理论来限制几乎所有常见和现实设置下核回归的超出风险。具体来说，我们提供了对于常见核函数以及任意的正则化量、噪声、任意输入维度和任意样本数都成立的严格界限。此外，我们还为核矩阵的特征值提供了相对扰动界限，这可能具有独立的重要性。这些界限揭示了一种自我正则化现象，即核分解的特征值中存在重尾现象。

    arXiv:2312.15995v2 Announce Type: replace-cross  Abstract: It is by now well-established that modern over-parameterized models seem to elude the bias-variance tradeoff and generalize well despite overfitting noise. Many recent works attempt to analyze this phenomenon in the relatively tractable setting of kernel regression. However, as we argue in detail, most past works on this topic either make unrealistic assumptions, or focus on a narrow problem setup. This work aims to provide a unified theory to upper bound the excess risk of kernel regression for nearly all common and realistic settings. Specifically, we provide rigorous bounds that hold for common kernels and for any amount of regularization, noise, any input dimension, and any number of samples. Furthermore, we provide relative perturbation bounds for the eigenvalues of kernel matrices, which may be of independent interest. These reveal a self-regularization phenomenon, whereby a heavy tail in the eigendecomposition of the ker
    
[^143]: 评估提示方法对ChatGPT的数学能力的影响

    Assessing the Impact of Prompting Methods on ChatGPT's Mathematical Capabilities

    [https://arxiv.org/abs/2312.15006](https://arxiv.org/abs/2312.15006)

    三种提示方法对ChatGPT的数学能力并未产生一贯性改进效果，部分方法甚至导致性能下降

    

    本研究批判性地评估了提示方法在提升大型语言模型（LLMs）的数学推理能力方面的功效。该研究使用了三种规定性提示方法 - 简单提示、个人提示和对话提示 - 这些方法以提升LLMs语言任务效果而闻名。我们在OpenAI的LLM闲聊机器人ChatGPT-3.5上进行此分析，涵盖了来自MATH、GSM8K和MMLU数据集的广泛问题集合，这些问题涵盖了各种数学挑战。针对每个数据集调整的评分脚本用于确定这些提示干预在增强模型数学分析能力方面的效果。与预期相反，我们的实证分析显示，所检验的方法均未在持续改进ChatGPT-3.5基准表现上，部分方法甚至导致明显的退化。我们的发现表明，提示策略未必能提高模型的数学分析能力。

    arXiv:2312.15006v2 Announce Type: replace  Abstract: This study critically evaluates the efficacy of prompting methods in enhancing the mathematical reasoning capability of large language models (LLMs). The investigation uses three prescriptive prompting methods - simple, persona, and conversational prompting - known for their effectiveness in enhancing the linguistic tasks of LLMs. We conduct this analysis on OpenAI's LLM chatbot, ChatGPT-3.5, on extensive problem sets from the MATH, GSM8K, and MMLU datasets, encompassing a broad spectrum of mathematical challenges. A grading script adapted to each dataset is used to determine the effectiveness of these prompting interventions in enhancing the model's mathematical analysis power. Contrary to expectations, our empirical analysis reveals that none of the investigated methods consistently improves over ChatGPT-3.5's baseline performance, with some causing significant degradation. Our findings suggest that prompting strategies do not nece
    
[^144]: LANS: 用于平面几何问题的布局感知神经求解器

    LANS: A Layout-Aware Neural Solver for Plane Geometry Problem

    [https://arxiv.org/abs/2311.16476](https://arxiv.org/abs/2311.16476)

    提出了一种名为LANS的布局感知神经求解器，集成了多模态布局感知预训练语言模块(MLA-PLM)和布局感知融合注意力(LA-FA)，有效提高了对几何图表布局信息的感知能力。

    

    几何问题求解(GPS)是一项具有挑战性的数学推理任务，需要多模态理解、融合和推理。现有的神经求解器将GPS视为一项视觉-语言任务，但在代表携带丰富和复杂布局信息的几何图表方面表现不足。本文提出了一种名为LANS的布局感知神经求解器，集成了两个新模块：多模态布局感知预训练语言模块(MLA-PLM)和布局感知融合注意力(LA-FA)。MLA-PLM采用结构-语义预训练(SSP)来实现全局关系建模，点匹配预训练(PMP)来实现视觉点和文本点之间的对齐。 LA-FA使用布局感知注意掩模，实现点引导的跨模态融合，进一步提升了LANS的布局感知性能。对Geometry3K和PGPS9K数据集的大量实验证实了布局感知模块的有效性。

    arXiv:2311.16476v2 Announce Type: replace-cross  Abstract: Geometry problem solving (GPS) is a challenging mathematical reasoning task requiring multi-modal understanding, fusion, and reasoning. Existing neural solvers take GPS as a vision-language task but are short in the representation of geometry diagrams that carry rich and complex layout information. In this paper, we propose a layout-aware neural solver named LANS, integrated with two new modules: multimodal layout-aware pre-trained language module (MLA-PLM) and layout-aware fusion attention (LA-FA). MLA-PLM adopts structural-semantic pre-training (SSP) to implement global relationship modeling, and point-match pre-training (PMP) to achieve alignment between visual points and textual points. LA-FA employs a layout-aware attention mask to realize point-guided cross-modal fusion for further boosting layout awareness of LANS. Extensive experiments on datasets Geometry3K and PGPS9K validate the effectiveness of the layout-aware modu
    
[^145]: 通过解耦可抗议的数据生成组件来实现程序公平

    Procedural Fairness Through Decoupling Objectionable Data Generating Components

    [https://arxiv.org/abs/2311.14688](https://arxiv.org/abs/2311.14688)

    通过解耦可抗议的数据生成组件，本研究提出了一个框架来防止伪装的程序不公平，并强调了满足程序公平要求的重要性

    

    我们揭示并解决了经常被忽视但重要的问题，即伪装的程序不公平，即对数据生成过程中的中立（即不成问题的）方面的可能无意的改变，和/或对最不利利益个体的实现没有程序保证。受约翰·罗尔斯对纯程序公正的倡导启发，我们将自动决策视为社会制度的缩影，并考虑数据生成过程本身如何满足程序公平的要求。我们提出了一个框架，通过利用参考点和相关的价值实例化规则，将可抗议的数据生成组件与中立的数据生成组件解耦。我们的发现强调了防止伪装的程序不公平的必要性，不仅引起了我们力图缓解的可抗议的数据生成组件的注意

    arXiv:2311.14688v2 Announce Type: replace-cross  Abstract: We reveal and address the frequently overlooked yet important issue of disguised procedural unfairness, namely, the potentially inadvertent alterations on the behavior of neutral (i.e., not problematic) aspects of data generating process, and/or the lack of procedural assurance of the greatest benefit of the least advantaged individuals. Inspired by John Rawls's advocacy for pure procedural justice, we view automated decision-making as a microcosm of social institutions, and consider how the data generating process itself can satisfy the requirements of procedural fairness. We propose a framework that decouples the objectionable data generating components from the neutral ones by utilizing reference points and the associated value instantiation rule. Our findings highlight the necessity of preventing disguised procedural unfairness, drawing attention not only to the objectionable data generating components that we aim to mitiga
    
[^146]: 使用推前映射进行各地采样

    Touring sampling with pushforward maps

    [https://arxiv.org/abs/2311.13845](https://arxiv.org/abs/2311.13845)

    该论文从理论角度对生成建模中的多种采样方法进行了审视和组织，帮助克服采样中的一些挑战，比如推理时间长和生成样本缺乏多样性。

    

    对于一个希望将强大的机器学习方法应用于特定问题的从业者来说，采样方法的数量可能令人生畏。本文从理论角度出发，对在“生成建模”设置中许多采样方法进行了审视和组织，其中希望生成与一些训练样本类似的新数据。通过揭示现有方法之间的联系，可能有助于克服与扩散模型采样相关的一些当前挑战，比如由于扩散模拟而导致的长推理时间，或者生成样本缺乏多样性。

    arXiv:2311.13845v2 Announce Type: replace-cross  Abstract: The number of sampling methods could be daunting for a practitioner looking to cast powerful machine learning methods to their specific problem. This paper takes a theoretical stance to review and organize many sampling approaches in the ``generative modeling'' setting, where one wants to generate new data that are similar to some training examples. By revealing links between existing methods, it might prove useful to overcome some of the current challenges in sampling with diffusion models, such as long inference time due to diffusion simulation, or the lack of diversity in generated samples.
    
[^147]: MedAgents: 大型语言模型作为零-shot医学推理的合作者

    MedAgents: Large Language Models as Collaborators for Zero-shot Medical Reasoning

    [https://arxiv.org/abs/2311.10537](https://arxiv.org/abs/2311.10537)

    提出了一个新颖的医学领域的跨学科合作(MC)框架，利用基于LLM的代理在角色扮演设置中参与协作多轮讨论，从而提高LLM的熟练程度和推理能力

    

    大型语言模型(LLMs)尽管在各种通用领域取得了显著进展，但在医学和医疗保健领域面临重大障碍。为了解决这些问题，我们提出了一个新颖的医学领域的跨学科合作(MC)框架，利用基于LLM的代理在角色扮演设置中参与协作多轮讨论，从而提高LLM的熟练程度和推理能力。这种无需训练的框架包括五个关键步骤：收集领域专家、提出个别分析、将这些分析总结成报告、在讨论中反复迭代直到达成共识，最终做出决策。我们的工作侧重于零-shot情景，在实际场景中具有适用性。在九个数据集上的实验结果显示...

    arXiv:2311.10537v2 Announce Type: replace-cross  Abstract: Large language models (LLMs), despite their remarkable progress across various general domains, encounter significant barriers in medicine and healthcare. This field faces unique challenges such as domain-specific terminologies and reasoning over specialized knowledge. To address these issues, we propose a novel Multi-disciplinary Collaboration (MC) framework for the medical domain that leverages LLM-based agents in a role-playing setting that participate in a collaborative multi-round discussion, thereby enhancing LLM proficiency and reasoning capabilities. This training-free framework encompasses five critical steps: gathering domain experts, proposing individual analyses, summarising these analyses into a report, iterating over discussions until a consensus is reached, and ultimately making a decision. Our work focuses on the zero-shot setting, which is applicable in real-world scenarios. Experimental results on nine dataset
    
[^148]: 启发驱动的类比链接促进：增强大型语言模型用于文档级事件论证提取

    Heuristic-Driven Link-of-Analogy Prompting: Enhancing Large Language Models for Document-Level Event Argument Extraction

    [https://arxiv.org/abs/2311.06555](https://arxiv.org/abs/2311.06555)

    通过启发式驱动的类比链接促进方法，该研究增强了大型语言模型用于文档级事件论证提取，使其能够从示例中学习任务特定启发式，并通过类比推理处理新情况以提高性能。

    

    在这项研究中，我们调查了文档级事件论证提取中的上下文学习（ICL），以减轻这一任务对大规模标记数据的依赖。我们引入了启发驱动的类比链接（HD-LoA）提示，以解决示例选择的挑战，并开发了一种为EAE量身定制的提示策略。具体而言，我们假设并验证了LLMs通过ICL从示范中学习任务特定启发式。基于这一假设，我们引入了一种显式的启发式驱动示范构建方法，将杂乱的示例选择过程转化为强调任务启发式的有条不紊方法。此外，受人类类比推理的启发，我们提出了类比链接提示，使LLMs能够通过将新情况类比于已知情况来处理新情况，从而提高它们在有限ICL示例以外的未见类别上的性能。

    arXiv:2311.06555v2 Announce Type: replace-cross  Abstract: In this study, we investigate in-context learning (ICL) in document-level event argument extraction (EAE) to alleviate the dependency on large-scale labeled data for this task. We introduce the Heuristic-Driven Link-of-Analogy (HD-LoA) prompting to address the challenge of example selection and to develop a prompting strategy tailored for EAE. Specifically, we hypothesize and validate that LLMs learn task-specific heuristics from demonstrations via ICL. Building upon this hypothesis, we introduce an explicit heuristic-driven demonstration construction approach, which transforms the haphazard example selection process into a methodical method that emphasizes task heuristics. Additionally, inspired by the analogical reasoning of human, we propose the link-of-analogy prompting, which enables LLMs to process new situations by drawing analogies to known situations, enhancing their performance on unseen classes beyond limited ICL exa
    
[^149]: Prompt Engineering a Prompt Engineer

    Prompt Engineering a Prompt Engineer

    [https://arxiv.org/abs/2311.05661](https://arxiv.org/abs/2311.05661)

    提示工程任务对于优化大型语言模型在定制任务上的表现至关重要，PE2方法通过详细描述、上下文规范和逐步推理模板的注入，在各种语言任务中展现出出色的适用性和效果。

    

    提示工程是优化大型语言模型在定制任务上表现的一项具有挑战性但至关重要的任务。为了检查模型的错误，假设当前提示中缺少或误导了什么，并清晰地传达任务，需要复杂的推理。尽管最近的研究表明，大型语言模型可以被元提示来执行自动提示工程，但我们认为由于元提示中缺乏复杂推理的充分指导，它们的潜力受到限制。我们通过将详细描述、上下文规范和逐步推理模板注入到元提示中来填补这一空白。所得到的方法称为PE2，展示了在不同语言任务中出色的适用性。它找到的提示在MultiArith上比“按步骤思考”高出6.3%，在GSM8K上高出3.1%，并在对立任务上优于竞争基线

    arXiv:2311.05661v2 Announce Type: replace-cross  Abstract: Prompt engineering is a challenging yet crucial task for optimizing the performance of large language models on customized tasks. It requires complex reasoning to examine the model's errors, hypothesize what is missing or misleading in the current prompt, and communicate the task with clarity. While recent works indicate that large language models can be meta-prompted to perform automatic prompt engineering, we argue that their potential is limited due to insufficient guidance for complex reasoning in the meta-prompt. We fill this gap by infusing into the meta-prompt three key components: detailed descriptions, context specification, and a step-by-step reasoning template. The resulting method, named PE2, showcases remarkable versatility across diverse language tasks. It finds prompts that outperform "let's think step by step" by 6.3% on MultiArith and 3.1% on GSM8K, and outperforms competitive baselines on counterfactual tasks 
    
[^150]: 使用强化学习的语言代理在狼人杀游戏中进行战略对战

    Language Agents with Reinforcement Learning for Strategic Play in the Werewolf Game

    [https://arxiv.org/abs/2310.18940](https://arxiv.org/abs/2310.18940)

    使用强化学习为基础，提出了一种框架，用于在狼人杀游戏中开发具有灵活语言行为和强大决策能力的战略语言代理

    

    基于大型语言模型（LLMs）构建的代理在各领域展现出巨大潜力。然而，在复杂决策任务中，纯LLM代理往往表现出固有偏见，这些偏见来源于模型的训练数据，导致性能不佳。为了开发具有灵活语言行为和强大决策能力的战略语言代理，我们提出了一种新颖的框架，通过强化学习（RL）提升LLM代理的能力。我们选择狼人杀作为具有多样沟通和战略游戏玩法的挑战测试平台。为了减轻语言行为中的固有偏见，我们的代理使用LLM进行演绎推理并生成多样行为候选集。然后，经过训练以优化决策能力的RL策略从候选集中选择行为。

    arXiv:2310.18940v3 Announce Type: replace  Abstract: Agents built with large language models (LLMs) have shown great potential across a wide range of domains. However, in complex decision-making tasks, pure LLM-based agents tend to exhibit intrinsic bias in their choice of actions, which is inherited from the model's training data and results in suboptimal performance. To develop strategic language agents, i.e., agents that generate flexible language actions and possess strong decision-making abilities, we propose a novel framework that powers LLM-based agents with reinforcement learning (RL). We consider Werewolf, a popular social deduction game, as a challenging testbed that emphasizes versatile communication and strategic gameplay. To mitigate the intrinsic bias in language actions, our agents use an LLM to perform deductive reasoning and generate a diverse set of action candidates. Then an RL policy trained to optimize the decision-making ability chooses an action from the candidat
    
[^151]: 在时间和容积数据中获取肿瘤定位的弱标注

    Acquiring Weak Annotations for Tumor Localization in Temporal and Volumetric Data

    [https://arxiv.org/abs/2310.15098](https://arxiv.org/abs/2310.15098)

    本研究提出一种名为 Drag&Drop 的新标注策略，相较于其他类型的弱标注，特别适合时间和容积成像，可简化肿瘤定位的标注过程。

    

    创建大规模和良好标注的数据集以训练人工智能算法对于自动化肿瘤检测和定位至关重要。然而，当资源有限时，在标记大量未标记数据时确定最佳类型标注是具有挑战性的。为了解决这个问题，我们专注于结肠镜检查视频中的息肉和腹部CT扫描中的胰腺肿瘤；这两种应用由于数据的高维特性，涉及临时或空间维度，因此对每像素的标注需要大量的努力和时间。在本文中，我们开发了一种新的标注策略，称为Drag&Drop，它简化了标注过程，使之变得更加高效，特别适用于时间和容积成像，比其他类型的弱标注（例如每像素、边界框、涂鸦、椭圆和点）更有效。此外，为了利用我们的Drag&Drop标注，

    arXiv:2310.15098v2 Announce Type: replace-cross  Abstract: Creating large-scale and well-annotated datasets to train AI algorithms is crucial for automated tumor detection and localization. However, with limited resources, it is challenging to determine the best type of annotations when annotating massive amounts of unlabeled data. To address this issue, we focus on polyps in colonoscopy videos and pancreatic tumors in abdominal CT scans; both applications require significant effort and time for pixel-wise annotation due to the high dimensional nature of the data, involving either temporary or spatial dimensions. In this paper, we develop a new annotation strategy, termed Drag&Drop, which simplifies the annotation process to drag and drop. This annotation strategy is more efficient, particularly for temporal and volumetric imaging, than other types of weak annotations, such as per-pixel, bounding boxes, scribbles, ellipses, and points. Furthermore, to exploit our Drag&Drop annotations,
    
[^152]: EX-FEVER：用于多跳可解释事实验证的数据集

    EX-FEVER: A Dataset for Multi-hop Explainable Fact Verification

    [https://arxiv.org/abs/2310.09754](https://arxiv.org/abs/2310.09754)

    提出了用于多跳可解释事实验证的开创性数据集EX-FEVER，包含超过6万个声明，每个声明都经过2跳和3跳推理，具有详细的解释路径。

    

    事实验证旨在根据多个证据自动探究声明的真实性。现有工作始终致力于提高准确性，更不用说解释性了，这是事实验证系统的一个关键能力。构建一个能够在复杂的多跳场景中解释的事实验证系统一直受制于缺乏相关的高质量数据集。为了解决这个问题，我们提出了EX-FEVER，这是一个用于多跳可解释事实验证的开创性数据集。超过6万个声明涉及2跳和3跳推理，每个声明都是通过总结和修改来自维基百科超链接文档的信息而创建的。每个实例都附带一个真实性标签和一个说明，概述支持真实性分类的推理路径。

    arXiv:2310.09754v2 Announce Type: replace  Abstract: Fact verification aims to automatically probe the veracity of a claim based on several pieces of evidence. Existing works are always engaging in accuracy improvement, let alone explainability, a critical capability of fact verification systems. Constructing an explainable fact verification system in a complex multi-hop scenario is consistently impeded by the absence of a relevant, high-quality dataset. Previous datasets either suffer from excessive simplification or fail to incorporate essential considerations for explainability. To address this, we present EXFEVER, a pioneering dataset for multi-hop explainable fact verification. With over 60,000 claims involving 2-hop and 3-hop reasoning, each is created by summarizing and modifying information from hyperlinked Wikipedia documents. Each instance is accompanied by a veracity label and an explanation that outlines the reasoning path supporting the veracity classification. Additionall
    
[^153]: 连接结构如何塑造神经回路中的富集和惰性学习

    How connectivity structure shapes rich and lazy learning in neural circuits

    [https://arxiv.org/abs/2310.08513](https://arxiv.org/abs/2310.08513)

    连接结构对神经回路学习动态有关键影响，高秩初始权重通常导致惰性学习。

    

    在理论神经科学中，最近的研究利用深度学习工具探讨了一些网络属性如何关键影响其学习动力学。特别地，具有小（大）方差的初始权重分布可能产生富集（惰性）模式，其中在学习过程中观察到网络状态和表示的显着（微小）变化。然而，在生物学中，神经回路连接可能展现出低秩结构，因此与通常用于这些研究的随机初始化有显著不同。因此，本文研究了初始权重结构（特别是它们的有效秩）如何影响网络学习模式。通过经验和理论分析，我们发现高秩初始化通常产生表明惰性学习的较小网络变化，这一发现也与实验驱动的初始 co 一致。

    arXiv:2310.08513v2 Announce Type: replace-cross  Abstract: In theoretical neuroscience, recent work leverages deep learning tools to explore how some network attributes critically influence its learning dynamics. Notably, initial weight distributions with small (resp. large) variance may yield a rich (resp. lazy) regime, where significant (resp. minor) changes to network states and representation are observed over the course of learning. However, in biology, neural circuit connectivity could exhibit a low-rank structure and therefore differs markedly from the random initializations generally used for these studies. As such, here we investigate how the structure of the initial weights -- in particular their effective rank -- influences the network learning regime. Through both empirical and theoretical analyses, we discover that high-rank initializations typically yield smaller network changes indicative of lazier learning, a finding we also confirm with experimentally-driven initial co
    
[^154]: SWAP: 稀疏熵式Wasserstein回归用于鲁棒网络剪枝

    SWAP: Sparse Entropic Wasserstein Regression for Robust Network Pruning

    [https://arxiv.org/abs/2310.04918](https://arxiv.org/abs/2310.04918)

    本研究提出了一种名为SWAP的网络剪枝方法，采用稀疏熵式Wasserstein回归来解决神经网络剪枝中的梯度不准确问题。SWAP在噪声抑制和协方差信息保留之间取得了平衡，具有较小的计算成本，与最先进的网络剪枝算法具有可比较的性能。

    

    本研究解决了神经网络剪枝中计算经验Fisher信息矩阵(FIM)时存在不准确梯度的问题。我们引入了SWAP，一种基于最优输运问题的熵式Wasserstein回归(EWR)网络剪枝方法。通过在优化中将常用的标准线性回归(LR)和EWR交换展示，SWAP在采用邻近插值跨数据点时在噪声抑制方面具有显著优势，同时增加了较小的额外计算成本。SWAP的独特优势在于能够在噪声减少和协方差信息保留之间取得平衡。在多个网络上进行的广泛实验表明，SWAP与最先进的网络剪枝算法具有可比较的性能。当网络规模或目标稀疏度较大时，我们的方法优于最先进算法，且在存在噪声的情况下，优势更加明显。

    This study tackles the issue of neural network pruning that inaccurate gradients exist when computing the empirical Fisher Information Matrix (FIM). We introduce SWAP, an Entropic Wasserstein regression (EWR) network pruning formulation, capitalizing on the geometric attributes of the optimal transport (OT) problem. The "swap" of a commonly used standard linear regression (LR) with the EWR in optimization is analytically showcased to excel in noise mitigation by adopting neighborhood interpolation across data points, yet incurs marginal extra computational cost. The unique strength of SWAP is its intrinsic ability to strike a balance between noise reduction and covariance information preservation. Extensive experiments performed on various networks show comparable performance of SWAP with state-of-the-art (SoTA) network pruning algorithms. Our proposed method outperforms the SoTA when the network size or the target sparsity is large, the gain is even larger with the existence of noisy 
    
[^155]: 从文本到自我：用户对人工智能在人际交流和自我方面潜力的认知

    From Text to Self: Users' Perceptions of Potential of AI on Interpersonal Communication and Self

    [https://arxiv.org/abs/2310.03976](https://arxiv.org/abs/2310.03976)

    用户对大型语言模型驱动的工具在人际交流方面的能力持积极看法，认为可以增加沟通自信、帮助表达想法以及克服语言和文化障碍，但也揭示出工具存在的一些局限性和用户关于技术不真实性和过度依赖的担忧。

    

    在快速发展的AI中介交流（AIMC）领域中，由大型语言模型（LLMs）驱动的工具正成为人际交流的重要组成部分。采用混合方法，我们进行了为期一周的日记和访谈研究，探讨了用户对这些工具在短期内支持人际交流的能力和可能导致的长期效果的看法。我们的研究发现，参与者对AIMC支持持有积极看法，认为其能够增加沟通自信，帮助找到准确的语言表达想法，以及克服语言和文化障碍。然而，研究还揭示了AIMC工具目前存在的局限，包括啰嗦的回复、不自然的回应以及过度情绪化。这些缺陷进一步受到用户对不真实性和对技术过度依赖的担忧所加剧。此外，我们确定了

    arXiv:2310.03976v2 Announce Type: cross  Abstract: In the rapidly evolving landscape of AI-mediated communication (AIMC), tools powered by Large Language Models (LLMs) are becoming integral to interpersonal communication. Employing a mixed-methods approach, we conducted a one-week diary and interview study to explore users' perceptions of these tools' ability to: 1) support interpersonal communication in the short-term, and 2) lead to potential long-term effects. Our findings indicate that participants view AIMC support favorably, citing benefits such as increased communication confidence, and finding precise language to express their thoughts, navigating linguistic and cultural barriers. However, the study also uncovers current limitations of AIMC tools, including verbosity, unnatural responses, and excessive emotional intensity. These shortcomings are further exacerbated by user concerns about inauthenticity and potential overreliance on the technology. Furthermore, we identified fou
    
[^156]: 偏好的物理学：通过磁化动力学揭示人类偏好的不精确性

    The Physics of Preference: Unravelling Imprecision of Human Preferences through Magnetisation Dynamics

    [https://arxiv.org/abs/2310.00267](https://arxiv.org/abs/2310.00267)

    通过磁化动力学原理，开发了一个模型用以紧密反映人类决策动力学，成功捕捉了个体选择中的复杂性。

    

    诸如偏好逆转等悖论性决策行为通常源自人类偏好的不精确或杂乱情况。通过利用铁磁纳米结构中的磁化逆转物理原理，我们开发了一个模型，它紧密反映了人类决策动力学。经过一系列心理学数据的测试，我们的模型熟练地捕捉了个体选择中固有的复杂性。这种物理学和心理学的融合为理解人类决策过程中的不精确性开辟了新的视角，扩展了当前经典和量子物理模型对人类行为和决策的探索范围。

    arXiv:2310.00267v2 Announce Type: replace-cross  Abstract: Paradoxical decision-making behaviours such as preference reversal often arise from imprecise or noisy human preferences. Harnessing the physical principle of magnetisation reversal in ferromagnetic nanostructures, we developed a model that closely reflects human decision-making dynamics. Tested against a spectrum of psychological data, our model adeptly captures the complexities inherent in individual choices. This blend of physics and psychology paves the way for fresh perspectives on understanding the imprecision of human decision-making processes, extending the reach of the current classical and quantum physical models of human behaviour and decision-making.
    
[^157]: 模型拼接与可视化：如何利用GAN生成器实时反转网络

    Model Stitching and Visualization How GAN Generators can Invert Networks in Real-Time

    [https://arxiv.org/abs/2302.02181](https://arxiv.org/abs/2302.02181)

    提出了一种利用GAN生成器拼接网络并实时反转的方法，在图像分类和语义分割网络中表现出与梯度下降方法相当的性能，但处理时间快两个数量级。

    

    在这项工作中，我们提出了一种快速准确的方法，通过将分类和语义分割网络与利用1x1卷积的GAN生成器拼接起来重建激活。我们在AFHQ野生数据集、ImageNet1K的动物图像以及染色组织样本的真实数字病理扫描图像上测试了我们的方法。我们的结果表明，与已建立的梯度下降方法相比，我们的方法性能相当，但处理时间快两个数量级，使得这种方法在实际应用中具有前景。

    arXiv:2302.02181v2 Announce Type: replace-cross  Abstract: In this work, we propose a fast and accurate method to reconstruct activations of classification and semantic segmentation networks by stitching them with a GAN generator utilizing a 1x1 convolution. We test our approach on images of animals from the AFHQ wild dataset, ImageNet1K, and real-world digital pathology scans of stained tissue samples. Our results show comparable performance to established gradient descent methods but with a processing time that is two orders of magnitude faster, making this approach promising for practical applications.
    
[^158]: 使用von Mises-Fisher混合模型减轻面部识别中的性别偏见

    Mitigating Gender Bias in Face Recognition Using the von Mises-Fisher Mixture Model

    [https://arxiv.org/abs/2210.13664](https://arxiv.org/abs/2210.13664)

    通过引入新的度量标准BFAR和BFRR，并通过后处理方法减轻面部识别中的性别偏见，以实现公平的系统性能。

    

    尽管深度学习算法在各种日常应用中表现出较高的性能和可靠性，但许多调查显示许多模型存在偏见，歧视特定人群子组（如性别、种族），这促使从业者开发具有一致/可比性能的公平系统。在本研究中，我们研究了深度面部识别网络的性别偏见。为了衡量这种偏见，我们引入了两个新的度量标准，BFAR和BFRR，更好地反映了面部识别系统固有的部署需求。受几何考虑的启发，我们通过一种新的后处理方法来减轻性别偏见，其通过将预训练模型的深度嵌入转换为对受歧视亚组有更多表示能力。它包括训练一个浅层神经网络，通过最小化一个Fa

    arXiv:2210.13664v2 Announce Type: replace-cross  Abstract: In spite of the high performance and reliability of deep learning algorithms in a wide range of everyday applications, many investigations tend to show that a lot of models exhibit biases, discriminating against specific subgroups of the population (e.g. gender, ethnicity). This urges the practitioner to develop fair systems with a uniform/comparable performance across sensitive groups. In this work, we investigate the gender bias of deep Face Recognition networks. In order to measure this bias, we introduce two new metrics, $\mathrm{BFAR}$ and $\mathrm{BFRR}$, that better reflect the inherent deployment needs of Face Recognition systems. Motivated by geometric considerations, we mitigate gender bias through a new post-processing methodology which transforms the deep embeddings of a pre-trained model to give more representation power to discriminated subgroups. It consists in training a shallow neural network by minimizing a Fa
    
[^159]: 在均场博弈中的学习：一项调查

    Learning in Mean Field Games: A Survey

    [https://arxiv.org/abs/2205.12944](https://arxiv.org/abs/2205.12944)

    强化学习和均场博弈的结合有望在很大规模上解决游戏的均衡和社会最优问题。

    

    非合作和合作游戏在拥有大量玩家时有许多应用，但随着玩家数量的增加，通常变得难以解决。均场博弈(Mean Field Games, MFGs)由Lasry和Lions以及Huang，Caines和Malham\'e引入，依靠均场近似允许玩家数量增长到无穷大。传统解决这些游戏的方法通常依赖于解决带有对模型的完全了解的偏微分方程或随机微分方程。最近，强化学习(Reinforcement Learning, RL)出现在解决规模复杂问题上表现出了很大的潜力。RL和MFGs的结合有望解决在人口规模和环境复杂性方面非常庞大的游戏。在这项调查中，我们回顾了最近迅速增长的关于RL方法在MFGs中学习均衡和社交最优的文献。我们首先确定了M中最常见的设置(静态、稳态和进化的)。

    arXiv:2205.12944v3 Announce Type: replace-cross  Abstract: Non-cooperative and cooperative games with a very large number of players have many applications but remain generally intractable when the number of players increases. Introduced by Lasry and Lions, and Huang, Caines and Malham\'e, Mean Field Games (MFGs) rely on a mean-field approximation to allow the number of players to grow to infinity. Traditional methods for solving these games generally rely on solving partial or stochastic differential equations with a full knowledge of the model. Recently, Reinforcement Learning (RL) has appeared promising to solve complex problems at scale. The combination of RL and MFGs is promising to solve games at a very large scale both in terms of population size and environment complexity. In this survey, we review the quickly growing recent literature on RL methods to learn equilibria and social optima in MFGs. We first identify the most common settings (static, stationary, and evolutive) of M
    
[^160]: 用于人与机器人间接放置交接的主动运动规划

    Preemptive Motion Planning for Human-to-Robot Indirect Placement Handovers

    [https://arxiv.org/abs/2203.00156](https://arxiv.org/abs/2203.00156)

    提出了一种新颖的预测规划流程，允许机器人主动朝着人类代理的预定放置位置移动

    

    随着技术的进步，安全、高效和协作的人机团队的需求变得越来越重要。在任何环境中最基本的协作任务之一是物体交接。人与机器人之间的交接可以采用两种方式：（1）直接手对手或（2）间接手对放置再抓取。后一种方式确保了人与机器人之间的最小接触，但也可能导致由于需要等待物体首先放置在表面上而增加闲置时间。为了最小化这种闲置时间，机器人必须预测人类意图，即物体将被放置在何处。此外，为了使机器人能够预先以任何一种有生产力的方式行动，预测和运动规划必须实时发生。我们引入了一种新颖的预测规划流程，允许机器人主动朝着人类代理的预定放置位置移动。

    arXiv:2203.00156v3 Announce Type: replace-cross  Abstract: As technology advances, the need for safe, efficient, and collaborative human-robot-teams has become increasingly important. One of the most fundamental collaborative tasks in any setting is the object handover. Human-to-robot handovers can take either of two approaches: (1) direct hand-to-hand or (2) indirect hand-to-placement-to-pick-up. The latter approach ensures minimal contact between the human and robot but can also result in increased idle time due to having to wait for the object to first be placed down on a surface. To minimize such idle time, the robot must preemptively predict the human intent of where the object will be placed. Furthermore, for the robot to preemptively act in any sort of productive manner, predictions and motion planning must occur in real-time. We introduce a novel prediction-planning pipeline that allows the robot to preemptively move towards the human agent's intended placement location using g
    
[^161]: 《SGD和自适应学习规则学到的表示：变化稀疏性和选择性的神经网络条件》

    Representations learnt by SGD and Adaptive learning rules: Conditions that vary sparsity and selectivity in neural network

    [https://arxiv.org/abs/2201.11653](https://arxiv.org/abs/2201.11653)

    本文调查了导致神经网络稀疏性和选择性增加的各种条件。

    

    从人脑的角度来看，连续学习可以执行各种任务而互不干扰。减少互相干扰的有效方式可以在神经元的稀疏性和选择性中找到。根据Aljundi等人和Hadsell等人的观点，在表示水平施加稀疏性对连续学习是有利的，因为稀疏的神经元激活鼓励参数之间的少重叠，导致更少的干扰。同样，高度选择性的神经网络可能会引起较少的干扰，因为神经元中的特定响应将减少与其他参数的重叠机会。考虑到人脑在一生中执行连续学习，找到自然增加稀疏性和选择性的条件可能为了解大脑功能提供见解。本文调查了自然增加神经网络稀疏性和选择性的各种条件。

    arXiv:2201.11653v2 Announce Type: replace  Abstract: From the point of view of the human brain, continual learning can perform various tasks without mutual interference. An effective way to reduce mutual interference can be found in sparsity and selectivity of neurons. According to Aljundi et al. and Hadsell et al., imposing sparsity at the representational level is advantageous for continual learning because sparse neuronal activations encourage less overlap between parameters, resulting in less interference. Similarly, highly selective neural networks are likely to induce less interference since particular response in neurons will reduce the chance of overlap with other parameters. Considering that the human brain performs continual learning over the lifespan, finding conditions where sparsity and selectivity naturally arises may provide insight for understanding how the brain functions. This paper investigates various conditions that naturally increase sparsity and selectivity in a 
    
[^162]: SelectLLM：LLMs能否选择重要的指令进行注释？

    SelectLLM: Can LLMs Select Important Instructions to Annotate?. (arXiv:2401.16553v1 [cs.CL])

    [http://arxiv.org/abs/2401.16553](http://arxiv.org/abs/2401.16553)

    这项工作提出了一种名为SelectLLM的新方法，利用LLMs选择高质量指令。通过提示LLMs估计每个无标签指令的有用性和影响力，并使用聚类算法将指令分为多个聚类。

    

    使用大量且多样化的指令数据集训练大型语言模型(LLMs)可以使模型理解和遵循人类指令。最近的研究表明，使用一小组高质量的指令可以超过使用大量更嘈杂的指令。由于指令是无标签的，且响应是自然文本，传统的主动学习方案无法直接应用于选择无标签指令。在这项工作中，我们提出了一种新的指令选择方法，称为SelectLLM，它利用LLMs选择高质量指令。我们的高级思想是利用LLMs通过提示来估计每个指令在没有相应标签（即响应）的情况下的有用性和影响力。SelectLLM包括两个步骤：使用聚类算法（例如CoreSet）将无标签指令划分为多个聚类，然后提示LLMs在其中选择高质量指令。

    Training large language models (LLMs) with a large and diverse instruction dataset aligns the models to comprehend and follow human instructions. Recent works have shown that using a small set of high-quality instructions can outperform using large yet more noisy ones. Because instructions are unlabeled and their responses are natural text, traditional active learning schemes with the model's confidence cannot be directly applied to the selection of unlabeled instructions. In this work, we propose a novel method for instruction selection, called SelectLLM, that leverages LLMs for the selection of high-quality instructions. Our high-level idea is to use LLMs to estimate the usefulness and impactfulness of each instruction without the corresponding labels (i.e., responses), via prompting. SelectLLM involves two steps: dividing the unlabelled instructions using a clustering algorithm (e.g., CoreSet) to multiple clusters, and then prompting LLMs to choose high-quality instructions within e
    
[^163]: 大规模异构图上基于大型语言模型的链接预测的可扩展性研究

    Scalable Link Prediction on Large-Scale Heterogeneous Graphs with Large Language Models. (arXiv:2401.13227v1 [cs.CL])

    [http://arxiv.org/abs/2401.13227](http://arxiv.org/abs/2401.13227)

    本研究探索了在大规模异构图上应用大型语言模型进行图学习的方法，提出了LPNL框架用于可扩展链接预测。通过创新的提示语和采样流程，以及分而治之的策略，成功解决了大规模图中的信息过载问题，并在实验中表现出了优越的性能。

    

    探索将大规模语言模型应用于图学习是一项新颖的努力。然而，大图中蕴含的大量信息给这一过程带来了重大挑战。本文侧重于链接预测任务，并介绍了LPNL（Link Prediction via Natural Language），这是一个基于大型语言模型的框架，用于大规模异构图上的可扩展链接预测。我们设计了能以自然语言表达图细节的创新提示语。我们提出了一个两阶段的采样流程，从大规模异构图中提取关键信息，并采用分而治之的策略来控制输入令牌数量在预定限制内，解决了信息过载的挑战。我们还通过自监督学习设计了一个用于链接预测的T5模型进行微调。在大型公共异构图上进行的广泛实验表明，LPNL的性能超过了各种先进的基准模型。

    Exploring the application of large-scale language models to graph learning is a novel endeavor. However, the vast amount of information inherent in large graphs poses significant challenges to this process. This paper focuses on the link prediction task and introduces LPNL (Link Prediction via Natural Language), a framework based on a large language model designed for scalable link prediction on large-scale heterogeneous graphs.We design novel prompts for link prediction that articulate graph details in natural language. We propose a two-stage sampling pipeline to extract crucial information from large-scale heterogeneous graphs, and a divide-and-conquer strategy to control the input token count within predefined limits, addressing the challenge of overwhelming information. We fine-tune a T5 model based on our self-supervised learning designed for for link prediction. Extensive experiments on a large public heterogeneous graphs demonstrate that LPNL outperforms various advanced baselin
    
[^164]: 记忆、空间和规划: 多尺度预测表示

    Memory, Space, and Planning: Multiscale Predictive Representations. (arXiv:2401.09491v1 [cs.AI])

    [http://arxiv.org/abs/2401.09491](http://arxiv.org/abs/2401.09491)

    本研究通过综合计算、行为和神经证据，揭示了记忆与预测、规划之间的相互关系以及其在海马体和前额叶皮质中的多尺度预测表示，为我们理解大脑中的记忆和规划机制提供了重要启示。

    

    记忆与预测和规划密不可分。生物和人工智能智能体的灵活行为取决于在不断变化的环境中从过去中学习和预测未来的相互作用。本章回顾了计算、行为和神经证据，表明这些过程依赖于学习经验的关系结构，即认知地图，并得出两个关键要点。首先，这些记忆结构在海马体和前额叶皮质（PFC）层次结构中组织为多尺度、紧凑的预测表示。其次，我们认为这种预测性记忆结构对海马体和PFC的互补功能至关重要，既能使过去的详细和连贯的事件回忆起来，也能在不同尺度上推广经验以实现高效的预测和规划。这些见解推动了我们对大脑中记忆和规划机制的理解，并具有重要的影响。

    Memory is inherently entangled with prediction and planning. Flexible behavior in biological and artificial agents depends on the interplay of learning from the past and predicting the future in ever-changing environments. This chapter reviews computational, behavioral, and neural evidence suggesting these processes rely on learning the relational structure of experiences, known as cognitive maps, and draws two key takeaways. First, that these memory structures are organized as multiscale, compact predictive representations in hippocampal and prefrontal cortex, or PFC, hierarchies. Second, we argue that such predictive memory structures are crucial to the complementary functions of the hippocampus and PFC, both for enabling a recall of detailed and coherent past episodes as well as generalizing experiences at varying scales for efficient prediction and planning. These insights advance our understanding of memory and planning mechanisms in the brain and hold significant implications for
    
[^165]: 采样与束缚用于非凸优化

    Sample-and-Bound for Non-Convex Optimization. (arXiv:2401.04812v1 [cs.AI])

    [http://arxiv.org/abs/2401.04812](http://arxiv.org/abs/2401.04812)

    本论文提出了一种基于采样的非凸优化方法，采用Monte Carlo Tree Search (MCTS)来提高效率，并利用数值上估计的不确定度指标和采样估计的一阶和二阶信息，避免固定组合模式的树生长，积极缩小到有希望的区域，同时平衡探索和开发。

    

    针对非凸函数的全局优化标准方法，如分支和束缚，维护可用于系统剪枝的分区树。树的大小随维度的增加而呈指数增长。我们提出了一种新的基于采样的非凸优化方法，它改进了蒙特卡罗树搜索(MCTS)的效率。我们不再使用标准的访问计数来作为不确定度指标，而是利用目标的数值上估计作为不确定度指标，并考虑采样估计的一阶和二阶信息。我们的方法中的蒙特卡罗树避免了通常固定组合模式的树生长，并积极地缩小到有希望的区域，同时平衡探索和开发。我们将提出的算法与竞争基线在高维非凸优化基准上进行评估，并分析超参数的影响。

    Standard approaches for global optimization of non-convex functions, such as branch-and-bound, maintain partition trees to systematically prune the domain. The tree size grows exponentially in the number of dimensions. We propose new sampling-based methods for non-convex optimization that adapts Monte Carlo Tree Search (MCTS) to improve efficiency. Instead of the standard use of visitation count in Upper Confidence Bounds, we utilize numerical overapproximations of the objective as an uncertainty metric, and also take into account of sampled estimates of first-order and second-order information. The Monte Carlo tree in our approach avoids the usual fixed combinatorial patterns in growing the tree, and aggressively zooms into the promising regions, while still balancing exploration and exploitation. We evaluate the proposed algorithms on high-dimensional non-convex optimization benchmarks against competitive baselines and analyze the effects of the hyper parameters.
    
[^166]: 在不断演化的社会规范中的Agent对齐

    Agent Alignment in Evolving Social Norms. (arXiv:2401.04620v1 [cs.CL])

    [http://arxiv.org/abs/2401.04620](http://arxiv.org/abs/2401.04620)

    本论文提出了一个名为EvolutionaryAgent的进化框架，将Agent对齐转化为适者生存的演化和选择过程，在不断演化的社会规范中，与当前社会规范更好适应的Agent将具有更高的生存和传播概率。

    

    基于大型语言模型（LLM）的Agent越来越多地渗透到人类生产和生活的各个领域，凸显了将其与人类价值观对齐的重要性。目前AI系统的对齐主要集中在通过人为干预对LLM进行被动对齐。然而，Agent具有接受环境反馈和自我进化等特性，使得LLM对齐方法变得不足够。为此，我们提出了一个名为EvolutionaryAgent的Agent进化和对齐的进化框架，将Agent对齐转化为适者生存的演化和选择过程。在社会规范不断演化的环境中，与当前社会规范更好适应的Agent将具有更高的生存和传播概率，而对齐不足的Agent则逐渐减少。通过多个角度对与社会规范相对齐的Agent进行的实验结果进行评估。

    Agents based on Large Language Models (LLMs) are increasingly permeating various domains of human production and life, highlighting the importance of aligning them with human values. The current alignment of AI systems primarily focuses on passively aligning LLMs through human intervention. However, agents possess characteristics like receiving environmental feedback and self-evolution, rendering the LLM alignment methods inadequate. In response, we propose an evolutionary framework for agent evolution and alignment, named EvolutionaryAgent, which transforms agent alignment into a process of evolution and selection under the principle of survival of the fittest. In an environment where social norms continuously evolve, agents better adapted to the current social norms will have a higher probability of survival and proliferation, while those inadequately aligned dwindle over time. Experimental results assessing the agents from multiple perspectives in aligning with social norms demonstr
    
[^167]: 人类反馈的迭代偏好学习：在KL约束下将理论与实践联系起来的RLHF

    Iterative Preference Learning from Human Feedback: Bridging Theory and Practice for RLHF under KL-Constraint. (arXiv:2312.11456v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2312.11456](http://arxiv.org/abs/2312.11456)

    该论文研究了在KL约束下的反馈强化学习的理论框架，并提出了有效的算法和实践。实证评估表明，该框架在大型语言模型的对齐实验中表现出良好的效果。

    

    本文研究了生成模型与强化学习从人类反馈中的对齐过程的理论框架。我们考虑了一个标准的数学表达式，即反向KL正则化的上下文多臂赌博机用于RLHF。尽管它被广泛应用于实际应用，但对这个公式的严格理论分析仍然很开放。我们研究了它在离线、在线和混合三种不同场景下的行为，并提出了具有有限样本理论保证的高效算法。朝着实际应用的方向，我们的框架通过对信息理论策略改进预言的稳健近似，自然地产生了几种新颖的RLHF算法。这包括在线场景中的迭代版本的直接偏好优化(DPO)算法，以及离线情景下的多步拒绝抽样策略。我们对大型语言模型的真实对齐实验进行了实证评估。

    This paper studies the theoretical framework of the alignment process of generative models with Reinforcement Learning from Human Feedback (RLHF). We consider a standard mathematical formulation, the reverse-KL regularized contextual bandit for RLHF. Despite its widespread practical application, a rigorous theoretical analysis of this formulation remains open. We investigate its behavior in three distinct settings -- offline, online, and hybrid -- and propose efficient algorithms with finite-sample theoretical guarantees.  Moving towards practical applications, our framework, with a robust approximation of the information-theoretical policy improvement oracle, naturally gives rise to several novel RLHF algorithms. This includes an iterative version of the Direct Preference Optimization (DPO) algorithm for online settings, and a multi-step rejection sampling strategy for offline scenarios. Our empirical evaluations on real-world alignment experiment of large language model demonstrate t
    
[^168]: LLMind: 为复杂任务执行与AI和物联网进行协调的LLM框架

    LLMind: Orchestrating AI and IoT with LLMs for Complex Task Execution. (arXiv:2312.09007v2 [cs.IT] UPDATED)

    [http://arxiv.org/abs/2312.09007](http://arxiv.org/abs/2312.09007)

    LLMind是一个利用大型语言模型（LLMs）作为中央协调器的AI框架，将LLMs与领域特定的AI模块整合，使得物联网设备能够有效协同执行复杂任务。

    

    本文介绍了LLMind，这是一个利用大型语言模型（LLMs）作为中央协调器的AI框架。该框架将LLMs与领域特定的AI模块整合，使得物联网设备能够有效协同执行复杂任务。LLMs通过用户友好的社交媒体平台与用户进行自然对话，提出执行复杂任务的计划。具体而言，复杂任务的执行是通过控制脚本实现的，这可能涉及多个领域特定的AI模块和物联网设备的协作。LLMs使用基于有限状态机（FSMs）的语言编码转换方法生成控制脚本。该框架还结合了语义分析和响应优化技术，以提高速度和效果。最终，该框架的设计不仅旨在创新物联网设备控制和丰富用户体验，还促进智能和集成的物联网设备。

    In this paper, we introduce LLMind, an AI framework that utilizes large language models (LLMs) as a central orchestrator. The framework integrates LLMs with domain-specific AI modules, enabling IoT devices to collaborate effectively in executing complex tasks. The LLM engages in natural conversations with human users via a user-friendly social media platform to come up with a plan to execute complex tasks. In particular, the execution of a complex task, which may involve the collaborations of multiple domain-specific AI modules and IoT devices, is realized through a control script. The LLM generates the control script using a Language-Code transformation approach based on finite-state machines (FSMs). The framework also incorporates semantic analysis and response optimization techniques to enhance speed and effectiveness. Ultimately, this framework is designed not only to innovate IoT device control and enrich user experiences but also to foster an intelligent and integrated IoT device
    
[^169]: 大型语言模型中的隐私问题：一项调研

    Privacy Issues in Large Language Models: A Survey. (arXiv:2312.06717v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2312.06717](http://arxiv.org/abs/2312.06717)

    这项调研关注大型语言模型中的隐私问题。主要总结了红队模型揭示隐私风险、将隐私纳入训练和推理过程、高效删除训练模型中的数据以符合隐私法规、以及减轻版权问题等技术研究。法律和政策研究虽然从不同角度解决了相关挑战，但不是本调研的重点。

    

    这是首个关注大型语言模型（LLMs）隐私问题的AI研究领域调研。具体而言，我们关注红队模型以突出隐私风险的工作，尝试将隐私纳入训练或推理过程中的工作，使得数据可以从训练模型中高效删除以符合现有的隐私法规，并试图减轻版权问题。我们的重点在于总结开发算法、证明定理和进行实证评估的技术研究。虽然有大量的法律和政策研究从不同角度解决这些挑战，但这不是我们调研的重点。然而，这些作品以及最近的法律进展确实影响了这些技术问题的形式化处理方式，因此我们在第一节中对其进行了简要讨论。尽管我们已经尽力包含所有相关研究，但由于这一领域的研究进展迅速，我们可能会漏掉一些最新的研究成果。

    This is the first survey of the active area of AI research that focuses on privacy issues in Large Language Models (LLMs). Specifically, we focus on work that red-teams models to highlight privacy risks, attempts to build privacy into the training or inference process, enables efficient data deletion from trained models to comply with existing privacy regulations, and tries to mitigate copyright issues. Our focus is on summarizing technical research that develops algorithms, proves theorems, and runs empirical evaluations. While there is an extensive body of legal and policy work addressing these challenges from a different angle, that is not the focus of our survey. Nevertheless, these works, along with recent legal developments do inform how these technical problems are formalized, and so we discuss them briefly in Section 1. While we have made our best effort to include all the relevant work, due to the fast moving nature of this research we may have missed some recent work. If we h
    
[^170]: INTERVENOR: 使用交互式修复链条来引导大型语言模型的编码能力

    INTERVENOR: Prompt the Coding Ability of Large Language Models with the Interactive Chain of Repairing. (arXiv:2311.09868v2 [cs.SE] UPDATED)

    [http://arxiv.org/abs/2311.09868](http://arxiv.org/abs/2311.09868)

    INTERVENOR模型通过模拟人类修复代码的行为，使用交互式修复链条来引导大型语言模型的编码能力，取得了显著的性能提升。

    

    本文提出了一种名为INTERVENOR的交互式修复链条（INTERactiVE chaiN Of Repairing），模拟了人类修复代码的行为（迭代判断、重新思考和修复），并促进了大型语言模型（LLMs）的编码能力。具体而言，INTERVENOR采用了两个基于LLM的代理，即Code Learner和Code Teacher，它们在代码修复中扮演不同的角色，并通过互动来修复生成的代码。Code Learner根据Code Teacher的指导生成和修复代码，而Code Teacher根据编译器的反馈重新思考代码错误，并迭代生成修复链条（CoR）以引导Code Learner的代码修复过程。实验证明，INTERVENOR优于最先进的方法，在代码生成和代码转换任务上相对于GPT-3.5模型分别取得了约13%和4.5%的提升。进一步分析表明，CoR能够揭示bug的原因。

    This paper proposes INTERactiVE chaiN Of Repairing (INTERVENOR), which mimics human code repairing behavior (iteratively judging, rethinking, and repairing) and prompts the coding ability of regard Large Language Models (LLMs). Specifically, INTERVENOR employs two LLM based agents, Code Learner and Code Teacher, to play different roles in code repairing and work interactively to repair the generated codes. The Code Learner is asked to generate and repair code according to the instructions from the Code Teacher. The Code Teacher rethinks the code errors according to the corresponding feedback from compilers and iteratively generates the chain-of-repairing (CoR) to guide the code repairing process for Code Learner. Our experiments show that INTERVENOR outperforms the state-of-the-art methods and achieves about 13% and 4.5% improvements over the GPT-3.5 model in code generation and code translation tasks, respectively. Our further analyses show that CoR can illuminate the bug reasons and 
    
[^171]: 机器人任务规划的视觉语言解释器

    Vision-Language Interpreter for Robot Task Planning. (arXiv:2311.00967v1 [cs.RO])

    [http://arxiv.org/abs/2311.00967](http://arxiv.org/abs/2311.00967)

    本文提出了一种名为Vision-Language Interpreter（ViLaIn）的新框架，该框架通过使用先进的语言模型和视觉语言模型生成机器人任务描述，并通过符号规划器的错误消息反馈进行改进。实验结果表明ViLaIn和符号规划器能够准确生成有效的机器人计划。

    

    大型语言模型（LLMs）正在加速语言引导的机器人规划器的发展。同时，符号规划器具有可解释性的优势。本文提出了一个新的任务，将这两种趋势相结合，即多模态规划问题规范。目标是生成一个问题描述（PD），这是规划器用来查找计划的机器可读文件。通过从语言指令和场景观测中生成PD，我们可以驱动符号规划器在语言引导框架下工作。我们提出了一种名为Vision-Language Interpreter（ViLaIn）的新框架，该框架使用先进的LLM和视觉语言模型生成PD。ViLaIn可以通过符号规划器的错误消息反馈来改进生成的PD。我们的目标是回答这个问题：ViLaIn和符号规划器能够准确地生成有效的机器人计划吗？为了评估ViLaIn，我们引入了一个名为问题描述生成（ProDG）数据集的新颖数据集。该框架将在评估中进行测试。

    Large language models (LLMs) are accelerating the development of language-guided robot planners. Meanwhile, symbolic planners offer the advantage of interpretability. This paper proposes a new task that bridges these two trends, namely, multimodal planning problem specification. The aim is to generate a problem description (PD), a machine-readable file used by the planners to find a plan. By generating PDs from language instruction and scene observation, we can drive symbolic planners in a language-guided framework. We propose a Vision-Language Interpreter (ViLaIn), a new framework that generates PDs using state-of-the-art LLM and vision-language models. ViLaIn can refine generated PDs via error message feedback from the symbolic planner. Our aim is to answer the question: How accurately can ViLaIn and the symbolic planner generate valid robot plans? To evaluate ViLaIn, we introduce a novel dataset called the problem description generation (ProDG) dataset. The framework is evaluated wi
    
[^172]: 自监督预训练用于降水后处理

    Self-supervised Pre-training for Precipitation Post-processor. (arXiv:2310.20187v1 [cs.LG])

    [http://arxiv.org/abs/2310.20187](http://arxiv.org/abs/2310.20187)

    该论文提出了一种基于深度学习的降水后处理方法，使用自监督预训练和转移学习来提高数值天气预报模型的准确性。实验结果表明该方法在区域降水校正方面表现优于其他方法。

    

    为了预防危险天气事件，确保充足的局地降水预报提前时间至关重要。然而，全球变暖引起的气候变化增加了准确预测严重降水事件（如暴雨）的挑战。本工作提出了一种基于深度学习的降水后处理方法，用于数值天气预报（NWP）模型。降水后处理包括（i）自监督预训练，其中编码器的参数在大气物理领域的遮蔽变量重构上进行预训练，以及（ii）从预训练的编码器中转移学习到降水分割任务（目标领域）。我们还引入了一种启发式标记方法，以有效地训练类别不平衡的数据集。我们在区域NWP中的降水校正实验结果表明，所提出的方法优于其他方法。

    Securing sufficient forecast lead time for local precipitation is essential for preventing hazardous weather events. Nonetheless, global warming-induced climate change is adding to the challenge of accurately predicting severe precipitation events, such as heavy rainfall. In this work, we propose a deep learning-based precipitation post-processor approach to numerical weather prediction (NWP) models. The precipitation post-processor consists of (i) self-supervised pre-training, where parameters of encoder are pre-trained on the reconstruction of masked variables of the atmospheric physics domain, and (ii) transfer learning on precipitation segmentation tasks (target domain) from the pre-trained encoder. We also introduce a heuristic labeling approach for effectively training class-imbalanced datasets. Our experiment results in precipitation correction for regional NWP show that the proposed method outperforms other approaches.
    
[^173]: 可解释的基于原型的图信息瓶颈

    Interpretable Prototype-based Graph Information Bottleneck. (arXiv:2310.19906v1 [cs.LG])

    [http://arxiv.org/abs/2310.19906](http://arxiv.org/abs/2310.19906)

    这项工作提出了一种新颖的可解释的GNN框架，通过在信息瓶颈框架中将原型学习与输入图的关键子图相结合，为模型的解释能力和性能提供了改进。

    

    图神经网络（GNN）的成功导致了对其决策过程的理解和对其预测的解释的需求，这催生了可解释的人工智能（XAI），为黑盒模型提供透明的解释。最近，原型的使用成功提高了模型的可解释性，通过学习原型来暗示影响预测的训练图。然而，这些方法往往会给原型提供来自整个图的过多信息，导致关键子结构的排除或无关子结构的包含，这可以限制模型在下游任务中的解释能力和性能。在这项工作中，我们提出了一种新颖的可解释的GNN框架，称为解释性的基于原型的图信息瓶颈 (PGIB)，将原型学习纳入信息瓶颈框架，为原型提供输入图的关键子图。

    The success of Graph Neural Networks (GNNs) has led to a need for understanding their decision-making process and providing explanations for their predictions, which has given rise to explainable AI (XAI) that offers transparent explanations for black-box models. Recently, the use of prototypes has successfully improved the explainability of models by learning prototypes to imply training graphs that affect the prediction. However, these approaches tend to provide prototypes with excessive information from the entire graph, leading to the exclusion of key substructures or the inclusion of irrelevant substructures, which can limit both the interpretability and the performance of the model in downstream tasks. In this work, we propose a novel framework of explainable GNNs, called interpretable Prototype-based Graph Information Bottleneck (PGIB) that incorporates prototype learning within the information bottleneck framework to provide prototypes with the key subgraph from the input graph
    
[^174]: ClickPrompt: CTR模型是将语言模型适应为CTR预测的强大提示生成器

    ClickPrompt: CTR Models are Strong Prompt Generators for Adapting Language Models to CTR Prediction. (arXiv:2310.09234v1 [cs.IR])

    [http://arxiv.org/abs/2310.09234](http://arxiv.org/abs/2310.09234)

    这篇论文提出了一个新颖的模型，旨在同时模拟语义和协同知识，以实现准确的CTR估计，并解决推理效率问题。

    

    点击率（CTR）预测已经成为各种互联网应用程序中越来越不可或缺的。传统的CTR模型通过独热编码将多字段分类数据转换为ID特征，并提取特征之间的协同信号。这种范式的问题在于语义信息的丢失。另一方面的研究通过将输入数据转换为文本句子来探索预训练语言模型（PLM）在CTR预测中的潜力。虽然语义信号得到了保留，但它们通常无法捕捉到协同信息（如特征交互、纯ID特征），更不用说由庞大的模型大小带来的无法接受的推理开销了。在本文中，我们旨在为准确的CTR估计建立语义知识和协同知识，并解决推理效率问题。为了从两个领域中受益并弥合它们之间的差距，我们提出了一种新颖的模型-。

    Click-through rate (CTR) prediction has become increasingly indispensable for various Internet applications. Traditional CTR models convert the multi-field categorical data into ID features via one-hot encoding, and extract the collaborative signals among features. Such a paradigm suffers from the problem of semantic information loss. Another line of research explores the potential of pretrained language models (PLMs) for CTR prediction by converting input data into textual sentences through hard prompt templates. Although semantic signals are preserved, they generally fail to capture the collaborative information (e.g., feature interactions, pure ID features), not to mention the unacceptable inference overhead brought by the huge model size. In this paper, we aim to model both the semantic knowledge and collaborative knowledge for accurate CTR estimation, and meanwhile address the inference inefficiency issue. To benefit from both worlds and close their gaps, we propose a novel model-
    
[^175]: Easier Multimodal Generation: Diffusion Models Meet LLMs

    Making Multimodal Generation Easier: When Diffusion Models Meet LLMs. (arXiv:2310.08949v1 [cs.AI])

    [http://arxiv.org/abs/2310.08949](http://arxiv.org/abs/2310.08949)

    EasyGen是一个有效的模型，它通过结合扩散模型和大型语言模型（LLMs）的能力，实现了更容易的多模态生成。相比现有的模型，EasyGen使用了一个名为BiDiffuser的双向条件扩散模型， 提供了更高效的模态交互，并且不仅能够生成文本回复，还能够促进文本到图像的生成。

    

    我们提出了EasyGen，一个有效的模型，通过利用扩散模型和大型语言模型（LLMs）的能力，增强了多模态理解和生成。不同于现有的主要依赖于编码器如CLIP或ImageBind，并且需要大量训练数据来桥接模态之间差距的多模态模型，EasyGen基于一个名为BiDiffuser的双向条件扩散模型构建，促进了更高效的模态交互。EasyGen通过简单的投影层将BiDiffuser和LLM进行集成，处理图像到文本的生成。与大多数现有的限于生成文本回复的多模态模型不同，EasyGen还可以通过利用LLM创建文本描述，并由BiDiffuser解释生成适当的视觉回复来促进文本到图像的生成。广泛的定量和定性实验证明了EasyGen的有效性，其训练可以...

    We present EasyGen, an efficient model designed to enhance multimodal understanding and generation by harnessing the capabilities of diffusion models and large language models (LLMs). Unlike existing multimodal models that predominately depend on encoders like CLIP or ImageBind and need ample amounts of training data to bridge the gap between modalities, EasyGen is built upon a bidirectional conditional diffusion model named BiDiffuser, which promotes more efficient interactions between modalities. EasyGen handles image-to-text generation by integrating BiDiffuser and an LLM via a simple projection layer. Unlike most existing multimodal models that are limited to generating text responses, EasyGen can also facilitate text-to-image generation by leveraging the LLM to create textual descriptions, which can be interpreted by BiDiffuser to generate appropriate visual responses. Extensive quantitative and qualitative experiments demonstrate the effectiveness of EasyGen, whose training can b
    
[^176]: 扩散模型的去噪任务路由

    Denoising Task Routing for Diffusion Models. (arXiv:2310.07138v1 [cs.CV])

    [http://arxiv.org/abs/2310.07138](http://arxiv.org/abs/2310.07138)

    本文提出了一种名为去噪任务路由的策略，通过为扩散模型的不同任务建立独立的信息路径，实现了对多任务学习的明确纳入。该方法将去噪任务的先验知识无缝集成到框架中，通过激活相似的通道和滑动窗口的方式，充分利用了相邻时间步任务间的亲和关系。

    

    扩散模型通过学习多步去噪过程生成高度逼真的图像，自然地体现了多任务学习（MTL）的原理。尽管扩散模型和MTL之间存在固有的连接，但在设计明确将MTL纳入扩散模型框架的神经结构方面仍存在一个未被探索的领域。在本文中，我们提出了去噪任务路由（DTR），一种对现有扩散模型架构进行简单附加的策略，通过选择性地激活模型中的子通道来为单个任务建立独立的信息路径。DTR的特别吸引人之处在于它将去噪任务的先验知识无缝集成到框架中：（1）任务亲和性：DTR为相邻时间步的任务激活相似的通道，并将激活的通道作为滑动窗口通过时间步进行移动，利用相邻时间步任务间固有的强亲和关系。

    Diffusion models generate highly realistic images through learning a multi-step denoising process, naturally embodying the principles of multi-task learning (MTL). Despite the inherent connection between diffusion models and MTL, there remains an unexplored area in designing neural architectures that explicitly incorporate MTL into the framework of diffusion models. In this paper, we present Denoising Task Routing (DTR), a simple add-on strategy for existing diffusion model architectures to establish distinct information pathways for individual tasks within a single architecture by selectively activating subsets of channels in the model. What makes DTR particularly compelling is its seamless integration of prior knowledge of denoising tasks into the framework: (1) Task Affinity: DTR activates similar channels for tasks at adjacent timesteps and shifts activated channels as sliding windows through timesteps, capitalizing on the inherent strong affinity between tasks at adjacent timestep
    
[^177]: Meta-CoT:大规模语言模型在混合任务场景中的通用思维链提示

    Meta-CoT: Generalizable Chain-of-Thought Prompting in Mixed-task Scenarios with Large Language Models. (arXiv:2310.06692v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.06692](http://arxiv.org/abs/2310.06692)

    Meta-CoT是一种在混合任务场景中能够通用思维链提示的方法，在十个公共基准推理任务中表现出卓越的性能和优越的泛化能力。

    

    大规模语言模型（LLM）通过利用链式思维提示展示出了卓越的推理能力，这种提示生成中间推理链以作为得出答案的基本理由。然而，目前的CoT方法要么仅仅使用类似“让我们逐步思考”的通用提示，要么过于依赖手工设计的任务特定演示来达到理想的性能，从而导致性能和泛化之间的不可避免的鸿沟。为了弥合这一鸿沟，我们提出了Meta-CoT，一种在未知输入问题类型的混合任务场景中具有通用性的CoT提示方法。Meta-CoT首先根据输入问题对场景进行分类，然后以自动模式从相应的数据池中构建多样的演示。Meta-CoT在十个公共基准推理任务上表现出卓越的性能和优越的泛化能力。值得注意的是，Meta-CoT实现了最新技术水平。

    Large language models (LLMs) have unveiled remarkable reasoning capabilities by exploiting chain-of-thought (CoT) prompting, which generates intermediate reasoning chains to serve as the rationale for deriving the answer. However, current CoT methods either simply employ general prompts such as Let's think step by step, or heavily rely on handcrafted task-specific demonstrations to attain preferable performances, thereby engendering an inescapable gap between performance and generalization. To bridge this gap, we propose Meta-CoT, a generalizable CoT prompting method in mixed-task scenarios where the type of input questions is unknown. Meta-CoT firstly categorizes the scenario based on the input question and subsequently constructs diverse demonstrations from the corresponding data pool in an automatic pattern. Meta-CoT simultaneously enjoys remarkable performances on ten public benchmark reasoning tasks and superior generalization capabilities. Notably, Meta-CoT achieves the state-of-
    
[^178]: 大型语言模型在生物医学文本处理任务中的综合评估

    A Comprehensive Evaluation of Large Language Models on Benchmark Biomedical Text Processing Tasks. (arXiv:2310.04270v1 [cs.CL])

    [http://arxiv.org/abs/2310.04270](http://arxiv.org/abs/2310.04270)

    本文对大型语言模型（LLM）在生物医学任务中的性能进行了综合评估，发现零样本LLMs在小样本生物医学数据集上的表现甚至超过了先进的精调生物医学模型，预训练使LLMs在生物医学领域具备了很强的专业能力。

    

    最近，大型语言模型（LLM）展示了解决各种任务的出色能力。然而，尽管它们在各种任务中取得了成功，但目前还没有研究它们在生物医学领域的能力。因此，本文旨在评估LLMs在基准生物医学任务上的性能。为此，我们对6个不同生物医学任务的26个数据集中的4个热门LLMs进行了综合评估。据我们所知，这是第一篇在生物医学领域对各种LLMs进行广泛评估和比较的研究。有趣的是，根据我们的评估，我们发现在训练集较小的生物医学数据集中，零样本LLMs甚至超过了当前最先进的精调生物医学模型。这表明在大型文本语料库上进行预训练使LLMs在生物医学领域具备了很强的专业能力。我们还发现，在所有任务中没有一个LLM能够胜过其他LLMs。

    Recently, Large Language Models (LLM) have demonstrated impressive capability to solve a wide range of tasks. However, despite their success across various tasks, no prior work has investigated their capability in the biomedical domain yet. To this end, this paper aims to evaluate the performance of LLMs on benchmark biomedical tasks. For this purpose, we conduct a comprehensive evaluation of 4 popular LLMs in 6 diverse biomedical tasks across 26 datasets. To the best of our knowledge, this is the first work that conducts an extensive evaluation and comparison of various LLMs in the biomedical domain. Interestingly, we find based on our evaluation that in biomedical datasets that have smaller training sets, zero-shot LLMs even outperform the current state-of-the-art fine-tuned biomedical models. This suggests that pretraining on large text corpora makes LLMs quite specialized even in the biomedical domain. We also find that not a single LLM can outperform other LLMs in all tasks, with 
    
[^179]: SemiReward: 半监督学习的通用奖励模型

    SemiReward: A General Reward Model for Semi-supervised Learning. (arXiv:2310.03013v1 [cs.LG])

    [http://arxiv.org/abs/2310.03013](http://arxiv.org/abs/2310.03013)

    SemiReward是一个通用奖励模型，通过预测奖励分数来评估和过滤高质量的伪标签，可以应用于各种半监督学习任务，并在实验中取得了显著的成果。

    

    半监督学习在自训练框架和伪标签上取得了显著进展。主要挑战是如何区分高质量的伪标签，避免确证偏见。然而，现有的伪标签选择策略限制于预定义的方案或复杂的手工制作策略，无法同时实现高质量标签、快速收敛和任务多样性。为此，我们提出了一种半监督奖励框架（SemiReward），用于预测奖励分数以评估和过滤高质量的伪标签，可以在各种任务类型和场景下与主流的半监督学习方法相结合使用。为了减少确证偏见，在两个阶段通过生成模型和子抽样策略进行在线训练。通过在三种模态的13个标准半监督学习基准上进行分类和回归任务的广泛实验验证，表明SemiReward取得了显著的成果。

    Semi-supervised learning (SSL) has witnessed great progress with various improvements in the self-training framework with pseudo labeling. The main challenge is how to distinguish high-quality pseudo labels against the confirmation bias. However, existing pseudo-label selection strategies are limited to pre-defined schemes or complex hand-crafted policies specially designed for classification, failing to achieve high-quality labels, fast convergence, and task versatility simultaneously. To these ends, we propose a Semi-supervised Reward framework (SemiReward) that predicts reward scores to evaluate and filter out high-quality pseudo labels, which is pluggable to mainstream SSL methods in wide task types and scenarios. To mitigate confirmation bias, SemiReward is trained online in two stages with a generator model and subsampling strategy. With classification and regression tasks on 13 standard SSL benchmarks of three modalities, extensive experiments verify that SemiReward achieves sig
    
[^180]: Embed-Search-Align: 使用Transformer模型进行DNA序列对齐

    Embed-Search-Align: DNA Sequence Alignment using Transformer Models. (arXiv:2309.11087v1 [q-bio.GN])

    [http://arxiv.org/abs/2309.11087](http://arxiv.org/abs/2309.11087)

    这项研究使用Transformer模型对DNA序列进行对齐，通过生成数值表示来实现。相比传统方法，该方法在短DNA序列的分类任务上取得了更好的性能，对于基因组学分析具有潜在的应用价值。

    

    DNA序列对齐涉及将短DNA读取分配到广泛的参考基因组上的最可能位置。这个过程对于各种基因组学分析至关重要，包括变异调用、转录组学和表观基因组学。传统方法经过数十年的改进，以两个步骤解决这个挑战：先进行基因组索引，然后进行高效搜索以确定给定读取的可能位置。在大规模语言模型（LLM）在将文本编码为嵌入向量方面取得成功的基础上，最近的研究努力探索了是否可以使用相同的Transformer架构为DNA序列生成数值表示。这样的模型已经在涉及分类短DNA序列的任务中显示出早期的潜力，例如检测编码和非编码区域以及识别增强子和启动子序列。然而，序列分类任务的性能并不能直接应用于序列对齐任务，对齐任务的关键是在保持序列相似性的同时找到最佳的对应位置。

    DNA sequence alignment involves assigning short DNA reads to the most probable locations on an extensive reference genome. This process is crucial for various genomic analyses, including variant calling, transcriptomics, and epigenomics. Conventional methods, refined over decades, tackle this challenge in two steps: genome indexing followed by efficient search to locate likely positions for given reads. Building on the success of Large Language Models (LLM) in encoding text into embeddings, where the distance metric captures semantic similarity, recent efforts have explored whether the same Transformer architecture can produce numerical representations for DNA sequences. Such models have shown early promise in tasks involving classification of short DNA sequences, such as the detection of coding vs non-coding regions, as well as the identification of enhancer and promoter sequences. Performance at sequence classification tasks does not, however, translate to sequence alignment, where i
    
[^181]: 基于类自适应交叉注意力的语义图像合成

    Semantic Image Synthesis via Class-Adaptive Cross-Attention. (arXiv:2308.16071v1 [cs.CV])

    [http://arxiv.org/abs/2308.16071](http://arxiv.org/abs/2308.16071)

    本文提出了一种基于类自适应交叉注意力的语义图像合成方法，通过使用交叉注意力层来调节图像生成，实现了优秀的视觉生成质量和编辑灵活性，并解决了全局样式不一致和局部样式编辑不真实的问题。

    

    在语义图像合成领域，最先进的方法主要使用空间自适应归一化层，可以实现出色的视觉生成质量和编辑灵活性。然而，这些方法往往忽略全局图像统计信息，导致局部样式编辑不真实，并引起诸如色彩或光照分布偏移等全局不一致性。此外，生成器需要语义布局来映射样式，对特征提出了严格的对齐约束。为解决这些问题，我们设计了一种新颖的架构，使用交叉注意力层代替反归一化层来调节图像生成。我们的模型继承了两种方法的优点，保持了最先进的重建质量，并且改进了全局和局部样式转移。

    In semantic image synthesis, the state of the art is dominated by methods that use spatially-adaptive normalization layers, which allow for excellent visual generation quality and editing versatility. Granted their efficacy, recent research efforts have focused toward finer-grained local style control and multi-modal generation. By construction though, such layers tend to overlook global image statistics leading to unconvincing local style editing and causing global inconsistencies such as color or illumination distribution shifts. Also, the semantic layout is required for mapping styles in the generator, putting a strict alignment constraint over the features. In response, we designed a novel architecture where cross-attention layers are used in place of de-normalization ones for conditioning the image generation. Our model inherits the advantages of both solutions, retaining state-of-the-art reconstruction quality, as well as improved global and local style transfer. Code and models 
    
[^182]: 更具表现力的图神经网络在生成任务中是否更好？

    Will More Expressive Graph Neural Networks do Better on Generative Tasks?. (arXiv:2308.11978v1 [cs.LG])

    [http://arxiv.org/abs/2308.11978](http://arxiv.org/abs/2308.11978)

    本论文调查了更具表现力的图神经网络在分子图生成任务中的表现能力，并通过替换图生成模型的基础GNN来进行实验。研究发现，使用更具表现力的GNN可以改善生成任务的性能。

    

    图生成是一个重要的挑战，它涉及根据给定的标签预测一个完整的具有多个节点和边的图。这个任务对许多实际应用非常重要，包括药物和分子设计。近年来，在图生成领域出现了几种成功的方法。然而，这些方法存在两个重大问题：(1) 这些方法中使用的基础图神经网络（GNN）架构往往未经深入探索；(2) 这些方法往往只在有限的指标上进行评估。为填补这个空白，我们通过将图生成模型的基础GNN替换为更具表现力的GNN，研究了GNN在分子图生成任务中的表现能力。具体而言，我们分析了两种不同生成框架（GCPN和GraphAF）中六种GNN在六个不同的分子生成目标上的性能。

    Graph generation poses a significant challenge as it involves predicting a complete graph with multiple nodes and edges based on simply a given label. This task also carries fundamental importance to numerous real-world applications, including de-novo drug and molecular design. In recent years, several successful methods have emerged in the field of graph generation. However, these approaches suffer from two significant shortcomings: (1) the underlying Graph Neural Network (GNN) architectures used in these methods are often underexplored; and (2) these methods are often evaluated on only a limited number of metrics. To fill this gap, we investigate the expressiveness of GNNs under the context of the molecular graph generation task, by replacing the underlying GNNs of graph generative models with more expressive GNNs. Specifically, we analyse the performance of six GNNs in two different generative frameworks (GCPN and GraphAF), on six different molecular generative objectives on the ZIN
    
[^183]: 用可证明概率保证在深度神经网络中枚举安全区域

    Enumerating Safe Regions in Deep Neural Networks with Provable Probabilistic Guarantees. (arXiv:2308.09842v1 [cs.LG])

    [http://arxiv.org/abs/2308.09842](http://arxiv.org/abs/2308.09842)

    通过epsilon-ProVe方法，我们提出了一种高效近似的方法来枚举深度神经网络中的安全区域，并提供了可证明概率保证的紧密下估计。

    

    识别安全区域是保证基于深度神经网络（DNNs）系统的信任的关键点。为此，我们引入了AllDNN-Verification问题：给定一个安全属性和一个DNN，枚举属性输入域的所有安全区域，即属性成立的区域。由于问题的#P难度，我们提出了一种高效的近似方法叫做epsilon-ProVe。我们的方法通过统计预测容限限制获得可控低估的输出可达集，并能够提供一个具有可证明概率保证的安全区域的紧密下估计。我们在不同的标准基准测试上进行的实证评估显示了我们方法的可扩展性和有效性，为这种新型的DNN验证提供了有价值的见解。

    Identifying safe areas is a key point to guarantee trust for systems that are based on Deep Neural Networks (DNNs). To this end, we introduce the AllDNN-Verification problem: given a safety property and a DNN, enumerate the set of all the regions of the property input domain which are safe, i.e., where the property does hold. Due to the #P-hardness of the problem, we propose an efficient approximation method called epsilon-ProVe. Our approach exploits a controllable underestimation of the output reachable sets obtained via statistical prediction of tolerance limits, and can provide a tight (with provable probabilistic guarantees) lower estimate of the safe areas. Our empirical evaluation on different standard benchmarks shows the scalability and effectiveness of our method, offering valuable insights for this new type of verification of DNNs.
    
[^184]: PMET: 在Transformer中的精确模型编辑

    PMET: Precise Model Editing in a Transformer. (arXiv:2308.08742v1 [cs.CL])

    [http://arxiv.org/abs/2308.08742](http://arxiv.org/abs/2308.08742)

    该论文通过分析Transformer模型中的隐藏状态，发现多头自注意力编码了某些通用知识提取模式，因此在进行模型编辑时，不需要更新多头自注意力的权重。

    

    模型编辑技术可以以较低的成本修改大型语言模型中的少量知识，并且已经取得了显著的成功。现有方法假设Transformer层隐藏状态是前馈网络的键值内存的值。它们通常优化Transformer层隐藏状态来记忆目标知识，并将其用于更新大型语言模型中前馈网络的权重。然而，Transformer层隐藏状态的信息流来自三个部分：多头自注意力、前馈网络和残差连接。现有方法忽视了Transformer层隐藏状态包含了前馈网络特别需要的信息这一事实。因此，模型编辑的性能下降。为了实现更精确的模型编辑，我们分析了多头自注意力和前馈网络的隐藏状态，发现多头自注意力编码了某些通用知识提取模式。这意味着当引入新知识时，多头自注意力的权重不需要更新。

    Model editing techniques modify a minor proportion of knowledge in Large Language Models (LLMs) at a relatively low cost, which have demonstrated notable success. Existing methods assume Transformer Layer (TL) hidden states are values of key-value memories of the Feed-Forward Network (FFN). They usually optimize the TL hidden states to memorize target knowledge and use it to update the weights of the FFN in LLMs. However, the information flow of TL hidden states comes from three parts: Multi-Head Self-Attention (MHSA), FFN, and residual connections. Existing methods neglect the fact that the TL hidden states contains information not specifically required for FFN. Consequently, the performance of model editing decreases. To achieve more precise model editing, we analyze hidden states of MHSA and FFN, finding that MHSA encodes certain general knowledge extraction patterns. This implies that MHSA weights do not require updating when new knowledge is introduced. Based on above findings, we
    
[^185]: 通过代理分析提高 LLM 对机器人任务学习的知识提取

    Improving Knowledge Extraction from LLMs for Robotic Task Learning through Agent Analysis. (arXiv:2306.06770v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2306.06770](http://arxiv.org/abs/2306.06770)

    本文提出了一种认知代理方法，通过增加 LLMs 的响应空间，并部署通用策略，嵌入自主机器人内部，从而使机器人能够获取与其语言能力、体现能力、环境和用户偏好相匹配的新的任务知识，实现一次学习即可完成任务。

    

    大型语言模型（LLMs）被视为机器人任务学习的知识来源，但是单独的提示工程并不能为机器人获取与其语言能力、体现能力、环境和用户偏好相匹配的情境相关知识。本文提出了一种认知代理方法，扩展和补充提示工程，缓解其局限性，以此使机器人能够获取新的任务知识。该方法是通过增加 LLMs 的响应空间，并部署通用策略，嵌入自主机器人内部，对 LLMs 产生的候选响应进行评估、修复和选择，实现一次学习即可完成任务。通过实验表明，机器人从 LLM 中检索和评估一系列不同响应后可以达到>75% 的任务完成率，无需用户监督。

    Large language models (LLMs) offer significant promise as a knowledge source for robotic task learning. Prompt engineering has been shown to be effective for eliciting knowledge from an LLM but alone is insufficient for acquiring relevant, situationally grounded knowledge for an embodied robotic agent learning novel tasks. We describe a cognitive-agent approach that extends and complements prompt engineering, mitigating its limitations, and thus enabling a robot to acquire new task knowledge matched to its native language capabilities, embodiment, environment, and user preferences. The approach is to increase the response space of LLMs and deploy general strategies, embedded within the autonomous robot, to evaluate, repair, and select among candidate responses produced by the LLM. We describe the approach and experiments that show how a robot, by retrieving and evaluating a breadth of responses from the LLM, can achieve >75% task completion in one-shot learning without user oversight. 
    
[^186]: 医疗知识图谱综述：资源、应用和前景

    A Survey on Knowledge Graphs for Healthcare: Resources, Applications, and Promises. (arXiv:2306.04802v1 [cs.AI])

    [http://arxiv.org/abs/2306.04802](http://arxiv.org/abs/2306.04802)

    本论文综述了医疗知识图谱(HKGs)的构建流程、关键技术和利用方法以及现有资源，并深入探讨了HKG在各种医疗领域的变革性影响。

    

    医疗知识图谱(HKGs)已成为组织医学知识的有结构且可解释的有为工具，提供了医学概念及其关系的全面视图。然而，数据异质性和覆盖范围有限等挑战仍然存在，强调了在HKG领域需要进一步研究的必要性。本综述是HKG的第一份综合概述。我们总结了HKG构建的流程和关键技术（即从头开始和通过集成），以及常见的利用方法（即基于模型和非基于模型）。为了为研究人员提供有价值的资源，我们根据它们捕获的数据类型和应用领域（该资源存储于https://github.com/lujiaying/Awesome-HealthCare-KnowledgeBase）组织了现有的HKG，并提供了相关的统计信息。在应用部分，我们深入探讨了HKG在各种医疗领域的变革性影响。

    Healthcare knowledge graphs (HKGs) have emerged as a promising tool for organizing medical knowledge in a structured and interpretable way, which provides a comprehensive view of medical concepts and their relationships. However, challenges such as data heterogeneity and limited coverage remain, emphasizing the need for further research in the field of HKGs. This survey paper serves as the first comprehensive overview of HKGs. We summarize the pipeline and key techniques for HKG construction (i.e., from scratch and through integration), as well as the common utilization approaches (i.e., model-free and model-based). To provide researchers with valuable resources, we organize existing HKGs (The resource is available at https://github.com/lujiaying/Awesome-HealthCare-KnowledgeBase) based on the data types they capture and application domains, supplemented with pertinent statistical information. In the application section, we delve into the transformative impact of HKGs across various hea
    
[^187]: 重新思考对抗策略：多智能体强化学习中的广义攻击形式和可证明的防御

    Rethinking Adversarial Policies: A Generalized Attack Formulation and Provable Defense in Multi-Agent RL. (arXiv:2305.17342v1 [cs.LG])

    [http://arxiv.org/abs/2305.17342](http://arxiv.org/abs/2305.17342)

    本文介绍了另一种常见、现实的多智能体RL攻击设置，提出了一种模拟攻击者对代理$\alpha$控制的更一般化攻击形式。并解决了先前攻击模型中缺乏可证明防御的问题。

    

    大多数现有的研究研究直接扰动受害者的状态/动作或基础转移动态以展示强化学习智能体在对抗攻击下的脆弱性。然而，这样的直接操纵在实践中并不总是可行的。在本文中，我们考虑另一种常见且现实的攻击设置：在经过训练的多智能体RL的设置中，在部署期间，受害代理$\nu$被攻击者控制另一个代理$\alpha$以敌对方式行动，使用“对抗策略”对受害代理进行攻击。尽管之前的攻击模型考虑了这种设置，但他们没有考虑到攻击者可以遇到抵抗，因此只能部分控制代理$\alpha$，同时引入可察觉的“异常”行为，这些行为很容易被检测到。并且缺乏针对这些对抗策略的可证明的防御。为了解决这些问题，我们引入了一个更一般化的攻击形式，模拟了攻击者在何种程度上可以控制代理$\alpha$。

    Most existing works consider direct perturbations of victim's state/action or the underlying transition dynamics to show vulnerability of reinforcement learning agents under adversarial attacks. However, such direct manipulation may not always be feasible in practice. In this paper, we consider another common and realistic attack setup: in a multi-agent RL setting with well-trained agents, during deployment time, the victim agent $\nu$ is exploited by an attacker who controls another agent $\alpha$ to act adversarially against the victim using an \textit{adversarial policy}. Prior attack models under such setup do not consider that the attacker can confront resistance and thus can only take partial control of the agent $\alpha$, as well as introducing perceivable ``abnormal'' behaviors that are easily detectable. A provable defense against these adversarial policies is also lacking. To resolve these issues, we introduce a more general attack formulation that models to what extent the a
    
[^188]: 在祈祷之后喝啤酒？测量大型语言模型中的文化偏见。

    Having Beer after Prayer? Measuring Cultural Bias in Large Language Models. (arXiv:2305.14456v1 [cs.CL])

    [http://arxiv.org/abs/2305.14456](http://arxiv.org/abs/2305.14456)

    这篇论文研究了大型语言模型在处理和生成阿拉伯文本时出现的文化偏向西方文化的现象，表明语言模型在人名、食品、服装、地点、文学、饮料、宗教和体育等八个文化方面存在偏见。这些发现引发对于当前语言模型文化相关性的担忧。

    

    语言模型是否存在文化偏见？语言模型符合所服务社区的文化因素很重要。然而，本文表明在处理和生成阿拉伯文本时，语言模型存在显著的偏向西方文化的偏见，倾向于产生西方文化相关内容而非阿拉伯文化相关内容。我们通过使用从在线社交媒体上收集的自然出现的上下文和基于可能性评分的指标来量化这种偏见。我们的实验显示，阿拉伯语单语和多语模型在八个不同的文化方面存在西方文化偏见，包括人名、食品、服装、地点、文学、饮料、宗教和体育。当输入的阿拉伯语句子越接近英语时，模型也更容易表现出偏见。这些发现引发人们对当前语言模型文化相关性的担忧。我们的分析表明，在模型设计中应更多考虑文化因素和多样性。

    Are language models culturally biased? It is important that language models conform to the cultural aspects of the communities they serve. However, we show in this paper that language models suffer from a significant bias towards Western culture when handling and generating text in Arabic, often preferring, and producing Western-fitting content as opposed to the relevant Arab content. We quantify this bias through a likelihood scoring-based metric using naturally occurring contexts that we collect from online social media. Our experiments reveal that both Arabic monolingual and multilingual models exhibit bias towards Western culture in eight different cultural aspects: person names, food, clothing, location, literature, beverage, religion, and sports. Models also tend to exhibit more bias when prompted with Arabic sentences that are more linguistically aligned with English. These findings raise concerns about the cultural relevance of current language models. Our analyses show that pr
    
[^189]: 基于表面肌电图像的轻量级全卷积神经网络和迁移学习的跨场景手势识别

    Surface EMG-Based Inter-Session/Inter-Subject Gesture Recognition by Leveraging Lightweight All-ConvNet and Transfer Learning. (arXiv:2305.08014v1 [cs.CV])

    [http://arxiv.org/abs/2305.08014](http://arxiv.org/abs/2305.08014)

    本论文提出了一种轻量级全卷积神经网络+迁移学习方法，能够在跨场景手势识别任务中有效解决数据变异性问题。

    

    利用低分辨率瞬时高清肌电图像进行手势识别可以开辟发展更流畅、更自然的肌肉-计算机界面的新途径。然而，跨场景数据的变异性存在极大的挑战。现有的方法采用非常大且复杂的深度卷积神经网络或基于2SRNN的领域适应方法，来逼近由这些跨场景数据变异性引起的分布偏移。因此，这些方法也需要在预训练和适应阶段中在数百万个训练参数和大规模预训练数据集上进行学习。结果，这使得在实时应用中进行高端资源约束和计算非常昂贵的部署。为了解决这个问题，我们提出了一种轻量级的全卷积神经网络+迁移学习模型，利用轻量级全卷积神经网络和迁移学习(TL)来增强跨场景手势识别。

    Gesture recognition using low-resolution instantaneous HD-sEMG images opens up new avenues for the development of more fluid and natural muscle-computer interfaces. However, the data variability between inter-session and inter-subject scenarios presents a great challenge. The existing approaches employed very large and complex deep ConvNet or 2SRNN-based domain adaptation methods to approximate the distribution shift caused by these inter-session and inter-subject data variability. Hence, these methods also require learning over millions of training parameters and a large pre-trained and target domain dataset in both the pre-training and adaptation stages. As a result, it makes high-end resource-bounded and computationally very expensive for deployment in real-time applications. To overcome this problem, we propose a lightweight All-ConvNet+TL model that leverages lightweight All-ConvNet and transfer learning (TL) for the enhancement of inter-session and inter-subject gesture recogniti
    
[^190]: 自动化学习中的公平性问题：公平性感知的AutoML的指南与机会

    Can Fairness be Automated? Guidelines and Opportunities for Fairness-aware AutoML. (arXiv:2303.08485v1 [cs.AI])

    [http://arxiv.org/abs/2303.08485](http://arxiv.org/abs/2303.08485)

    自动化机器学习技术（AutoML）的发展加速了机器学习模型的开发，但由于模型的决策可能会引发不公平问题，因此研究者提出了联合优化公平性和预测性能的AutoML系统，本文呼吁AutoML系统开发者应该认识到公平性处理未必是纯粹的优化问题，并提醒此类算法也具备成为公平研究工具的潜力。

    

    自动化机器学习（AutoML）领域引入了一些自动化机器学习（ML）系统开发的技术，加速了该过程，降低了新手的门槛。然而，基于ML模型的决策可能会在我们的社会中复制、放大或甚至引入不公平性，对（群体中的）个人造成伤害。为此，研究人员已经开始提出联合优化公平性和预测性能的AutoML系统，以减轻与公平性相关的损害。然而，公平性是一个复杂且固有的跨学科主题，仅将其作为优化问题可能会产生不良副作用。本文旨在提高AutoML系统开发者对公平性感知AutoML的这些局限性的认识，同时引起AutoML作为公平研究工具的潜力的注意。我们给出了不同方式的公平相关危害及其随之而来的影响的综合概述。

    The field of automated machine learning (AutoML) introduces techniques that automate parts of the development of machine learning (ML) systems, accelerating the process and reducing barriers for novices. However, decisions derived from ML models can reproduce, amplify, or even introduce unfairness in our societies, causing harm to (groups of) individuals. In response, researchers have started to propose AutoML systems that jointly optimize fairness and predictive performance to mitigate fairness-related harm. However, fairness is a complex and inherently interdisciplinary subject, and solely posing it as an optimization problem can have adverse side effects. With this work, we aim to raise awareness among developers of AutoML systems about such limitations of fairness-aware AutoML, while also calling attention to the potential of AutoML as a tool for fairness research. We present a comprehensive overview of different ways in which fairness-related harm can arise and the ensuing implica
    
[^191]: 批量异步随机逼近的收敛性及在强化学习中的应用

    Convergence of Batch Asynchronous Stochastic Approximation With Applications to Reinforcement Learning. (arXiv:2109.03445v4 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2109.03445](http://arxiv.org/abs/2109.03445)

    本文提出了一种批量异步随机逼近算法，它可以在内存需求和时间复杂度之间进行权衡，同时提供了可以使用较弱假设证明收敛的一般方法；在强化学习领域，我们使用此方法证明了SARSA算法的批量异步版本的收敛性。

    

    随机逼近（SA）算法是一种广泛使用的概率方法，用于在仅可用函数的有噪测量情况下找到零点或固定点。目前的文献中，区分“同步”更新和“异步”更新，在“同步”更新中，每个猜测的组件都会在每个时间更新，而在“异步”更新中，仅更新一个组件。本文研究了一种中间情况，称为“批量异步随机逼近”（BASA），在这种情况下，每个时间点仅更新“当前估计解”的一些但不是全部的组件。BASA允许用户在内存需求和时间复杂度之间进行权衡。我们开发了一种通用方法，证明此类算法收敛于所研究映射的固定点。这些收敛证明使用比现有结果更弱的假设。具体而言，现有的收敛证明要求步长参数以适当的速率下降。相反，我们仅要求每个组件具有足够的更新频率。我们在强化学习领域展示了我们方法的有用性，证明了广泛使用的SARSA算法的批量异步版本的收敛性。

    The stochastic approximation (SA) algorithm is a widely used probabilistic method for finding a zero or a fixed point of a vector-valued funtion, when only noisy measurements of the function are available. In the literature to date, one makes a distinction between ``synchronous'' updating, whereby every component of the current guess is updated at each time, and ``asynchronous'' updating, whereby only one component is updated. In this paper, we study an intermediate situation that we call ``batch asynchronous stochastic approximation'' (BASA), in which, at each time instant, \textit{some but not all} components of the current estimated solution are updated. BASA allows the user to trade off memory requirements against time complexity. We develop a general methodology for proving that such algorithms converge to the fixed point of the map under study. These convergence proofs make use of weaker hypotheses than existing results. Specifically, existing convergence proofs require that the 
    

