# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [MathVerse: Does Your Multi-modal LLM Truly See the Diagrams in Visual Math Problems?](https://arxiv.org/abs/2403.14624) | MathVerse是一个全方位的视觉数学基准测试，旨在公平而深入地评估MLLMs在视觉数学问题解决中的能力。 |
| [^2] | [Videoshop: Localized Semantic Video Editing with Noise-Extrapolated Diffusion Inversion](https://arxiv.org/abs/2403.14617) | Videoshop是一个无需训练的视频编辑算法，通过图像为基础的方法实现了本地化语义编辑，从而允许用户对视频进行精细控制，取得了更高质量的编辑效果。 |
| [^3] | [Envisioning the Next-Generation AI Coding Assistants: Insights & Proposals](https://arxiv.org/abs/2403.14592) | AI编码助手应明确使用预期，充分整合IDE功能，使用可扩展的后端设计，负责收集数据，提出开放性问题和挑战 |
| [^4] | [ReAct Meets ActRe: Autonomous Annotations of Agent Trajectories for Contrastive Self-Training](https://arxiv.org/abs/2403.14589) | 提出了A$^3$T框架，通过ActRe提示代理实现了ReAct风格代理对代理轨迹的自主标注，同时增强了新的轨迹合成能力。 |
| [^5] | [Large Language Models for Multi-Choice Question Classification of Medical Subjects](https://arxiv.org/abs/2403.14582) | 本文评估了大型语言模型在多选题数据上的训练效果，并利用MQ序列BERT方法，在医学科目分类任务中取得了优于最先进结果的准确率。 |
| [^6] | [A survey on Concept-based Approaches For Model Improvement](https://arxiv.org/abs/2403.14566) | 基于概念方法对深度神经网络进行解释性改进，提供了人类可理解的决策解释，使得检测伪关联和固有偏见成为可能。 |
| [^7] | [The Era of Semantic Decoding](https://arxiv.org/abs/2403.14562) | 提出了一种名为语义解码的新观点，将LLM、人类输入和各种工具之间的协作过程构建为语义空间中的优化过程，促进了高效输出的构建。 |
| [^8] | [Lexicon-Level Contrastive Visual-Grounding Improves Language Modeling](https://arxiv.org/abs/2403.14551) | 这项研究介绍了LexiContrastive Grounding (LCG)，它结合了视觉监督和文本表示改进策略，在多个单词学习和句子理解基准测试中表现出比标准语言模型更高的学习效率和进步。 |
| [^9] | [Dynamic Explanation Emphasis in Human-XAI Interaction with Communication Robot](https://arxiv.org/abs/2403.14550) | 提出了一种名为DynEmph的方法，用于通信机器人决定在哪些地方用物理表达强调 XAI 生成的解释，并且通过一种数据驱动的策略来决定强调的位置。 |
| [^10] | [Object-Centric Domain Randomization for 3D Shape Reconstruction in the Wild](https://arxiv.org/abs/2403.14539) | 提出了ObjectDR，利用对象-centric的域随机化合成单视图3D形状重建中缺乏的配对数据，通过条件生成模型和解耦框架来生成和保留对象轮廓以及广泛变化的数据，从而为培训模型捕捉域不变性几何形状。 |
| [^11] | [Click to Grasp: Zero-Shot Precise Manipulation via Visual Diffusion Descriptors](https://arxiv.org/abs/2403.14526) | 通过利用 web 训练文本到图像扩散生成模型，在零样本情况下利用细粒度部件描述符进行精确操作，通过点击源图像不同实例的引用，返回夹具姿势，实现了机器人精确操控。 |
| [^12] | [Constrained Reinforcement Learning with Smoothed Log Barrier Function](https://arxiv.org/abs/2403.14508) | 提出了一种新的约束强化学习方法CSAC-LB，通过应用线性平滑对数障碍函数，实现了竞争性能，无需任何预训练 |
| [^13] | [Soft Learning Probabilistic Circuits](https://arxiv.org/abs/2403.14504) | 该论文提出了一种新的学习过程 SoftLearn，通过软聚类过程诱导出一个 PC，相较于传统的 LearnSPN，在许多情况下表现更好，产生更好的似然值和样本。 |
| [^14] | [How Human-Centered Explainable AI Interface Are Designed and Evaluated: A Systematic Survey](https://arxiv.org/abs/2403.14496) | 本研究是对人类与可解释人工智能交互的现状和可解释界面设计方向的系统调查。 |
| [^15] | [Learning to Project for Cross-Task Knowledge Distillation](https://arxiv.org/abs/2403.14494) | 提出了一种通过学习投影，以有效地将传统知识蒸馏方法应用于跨任务设置的方法，取得了显著的性能提升 |
| [^16] | [Physics-Based Causal Reasoning for Safe & Robust Next-Best Action Selection in Robot Manipulation Tasks](https://arxiv.org/abs/2403.14488) | 该论文提出了一个基于物理因果推理的框架，用于机器人在部分可观察的环境中进行概率推理，成功预测积木塔稳定性并选择下一最佳动作。 |
| [^17] | [HyperGALE: ASD Classification via Hypergraph Gated Attention with Learnable Hyperedges](https://arxiv.org/abs/2403.14484) | HyperGALE通过学习超边的超图门控注意力机制，在解释复杂的脑图数据方面取得显著改进，为ASD生物标志特征化提供更深入见解。 |
| [^18] | [Utilizing the LightGBM Algorithm for Operator User Credit Assessment Research](https://arxiv.org/abs/2403.14483) | 该研究利用LightGBM算法对运营商用户信用评估模型进行研究，通过提取关键特征并进行数据预处理和特征工程，以改善用户信用评估策略。 |
| [^19] | [Detoxifying Large Language Models via Knowledge Editing](https://arxiv.org/abs/2403.14472) | 本文研究了使用知识编辑技术对大型语言模型进行去毒化，在构建了SafeEdit基准的基础上，提出了一种简单而有效的方法 DINM，可以通过少量调整步骤减少模型的毒性，同时对各种去毒方法的内部机制进行了深入分析。 |
| [^20] | [ChatGPT Alternative Solutions: Large Language Models Survey](https://arxiv.org/abs/2403.14469) | 大语言模型在多个领域展现出强大能力，ChatGPT是一个基于LLMs的强大AI聊天机器人，在学术界和工业界的合作推动下，LLM研究领域不断取得新突破，预示着人工智能社区将迎来革命性变革。 |
| [^21] | [AnyV2V: A Plug-and-Play Framework For Any Video-to-Video Editing Tasks](https://arxiv.org/abs/2403.14468) | AnyV2V是一种适用于任何视频到视频编辑任务的即插即用框架，通过两个主要步骤简化视频编辑，支持广泛的视频编辑任务，并能够处理传统和新颖的编辑需求。 |
| [^22] | [Towards Single-System Illusion in Software-Defined Vehicles -- Automated, AI-Powered Workflow](https://arxiv.org/abs/2403.14460) | 提出了一种基于模型和特征的新方法，通过迭代搜索和优化的过程中出现最终架构，同时保持单一系统错觉特性，并将现代生成式人工智能引入其中，从而实现对车辆软件系统的自动化开发。 |
| [^23] | [Multi-Level Explanations for Generative Language Models](https://arxiv.org/abs/2403.14459) | 本文提出了一个名为MExGen的通用框架，通过引入标量化概念和多级方法处理生成式语言模型的挑战，证明可以提供更贴近本地的解释。 |
| [^24] | [Language Models Can Reduce Asymmetry in Information Markets](https://arxiv.org/abs/2403.14443) | 语言模型驱动的智能代理在模拟数字市场中完成买卖信息的任务，通过具备评估信息质量和遗忘能力的特点，成功降低了信息市场的买方检查悖论。 |
| [^25] | [Biased Binary Attribute Classifiers Ignore the Majority Classes](https://arxiv.org/abs/2403.14435) | 本文将梯度基础的CAM技术扩展到二元分类器，并可视化二进制面部属性分类器的活动区域，证实在不平衡数据集上训练时偏向性分类器倾向于学习提取主要类别的特征 |
| [^26] | [On the continuity and smoothness of the value function in reinforcement learning and optimal control](https://arxiv.org/abs/2403.14432) | 研究了强化学习和最优控制中价值函数的连续性和光滑性，提供了关于价值函数连续性的上界，并表明在对底层系统进行相对较弱的假设下，价值函数始终具有H\"older连续性。 |
| [^27] | [Style-Extracting Diffusion Models for Semi-Supervised Histopathology Segmentation](https://arxiv.org/abs/2403.14429) | 提出了风格提取扩散模型，利用风格调节机制和内容调节机制，实现了在图像生成过程中注入未见图像风格信息，从而以零-shot方式生成具有未见风格的图像。 |
| [^28] | [GLC++: Source-Free Universal Domain Adaptation through Global-Local Clustering and Contrastive Affinity Learning](https://arxiv.org/abs/2403.14410) | 该论文提出了GLC++方法，通过全局和局部聚类以及对比关联学习实现了无源通用域自适应，能够准确分类已知数据并将其从未知数据中分离。 |
| [^29] | [Locating and Mitigating Gender Bias in Large Language Models](https://arxiv.org/abs/2403.14409) | 本研究提出了一种将定位和减轻偏见过程融入统一框架的方法，通过因果中介分析追踪大型语言模型中不同组件激活的因果效应，并提出了一种用于减轻职业代词中性别偏见的基于知识编辑的LSDM方法。 |
| [^30] | [Adaptive-RAG: Learning to Adapt Retrieval-Augmented Large Language Models through Question Complexity](https://arxiv.org/abs/2403.14403) | 通过新颖的自适应QA框架，根据查询的复杂度动态选择适合的检索增强大型语言模型策略，提高了回答准确性。 |
| [^31] | [Building Accurate Translation-Tailored LLMs with Language Aware Instruction Tuning](https://arxiv.org/abs/2403.14399) | 通过设计两阶段微调算法，本研究旨在提高LLMs遵循翻译指令的能力，尤其是翻译方向信息。 |
| [^32] | [Editing Knowledge Representation of Language Lodel via Rephrased Prefix Prompts](https://arxiv.org/abs/2403.14381) | 引入了一种名为PSPEM的新方法，通过重新表述前缀提示来编辑语言Lodel的知识表示，解决了知识编辑方法中的低效性、通用性问题，以及提示工程的不透明性。 |
| [^33] | [Loop Improvement: An Efficient Approach for Extracting Shared Features from Heterogeneous Data without Central Server](https://arxiv.org/abs/2403.14371) | 循环改进（LI）是一种无需中央服务器或数据交换的新颖方法，可提高数据异质性下的特征提取效率，表现优越于先进算法FedALA，并可应用于个性化联邦学习和全局模型环境。 |
| [^34] | [Exploring the Potential of Large Language Models in Graph Generation](https://arxiv.org/abs/2403.14358) | 本文探索了大型语言模型在图生成中的潜力，通过任务设计和实验考察了其对不同图结构规则的理解、捕获结构类型分布的能力以及利用领域知识进行基于属性的图生成。 |
| [^35] | [Exploring Task Unification in Graph Representation Learning via Generative Approach](https://arxiv.org/abs/2403.14340) | 通过提出GA^2E，一个统一的框架，通过统一的生成式半监督学习，在单个训练阶段中实现了图生成、图判别和图预测任务。 |
| [^36] | [$\nabla \tau$: Gradient-based and Task-Agnostic machine Unlearning](https://arxiv.org/abs/2403.14339) | $\nabla \tau$ 是一种旨在高效消除部分训练数据影响的机器遗忘优化框架。 |
| [^37] | [Distilling Reinforcement Learning Policies for Interpretable Robot Locomotion: Gradient Boosting Machines and Symbolic Regression](https://arxiv.org/abs/2403.14328) | 通过梯度提升机和符号回归等技术，将神经网络的强化学习策略转化为更可解释的形式，提高了机器人运动策略的透明度和可理解性。 |
| [^38] | [DexDribbler: Learning Dexterous Soccer Manipulation via Dynamic Supervision](https://arxiv.org/abs/2403.14300) | 提出了一种通过动态监督学习巧妙的足球操纵方法，利用反馈控制模块来计算必要的整体运动并进行动态关节级运动监督，同时改进了球体动态模型和上下文-辅助估计器。 |
| [^39] | [From Perils to Possibilities: Understanding how Human (and AI) Biases affect Online Fora](https://arxiv.org/abs/2403.14298) | 在线社交互动中存在着封闭性社区和在线支持团体两种面貌，受到算法偏见和同质性极端机制的影响。 |
| [^40] | [Impact Assessment of Missing Data in Model Predictions for Earth Observation Applications](https://arxiv.org/abs/2403.14297) | 本研究评估了在地球观测应用中缺失数据对训练模型的影响，发现集成策略可以实现高达100%的预测稳健性，同时揭示了缺失情景在回归任务中比分类任务更具挑战性，且光学视角是最关键的。 |
| [^41] | [Enhancing Historical Image Retrieval with Compositional Cues](https://arxiv.org/abs/2403.14287) | 该研究通过将计算美学中的图像构图原则融入到检索模型中，实现了历史图像检索方法的增强，提高了图像检索的效果。 |
| [^42] | [How to be fair? A study of label and selection bias](https://arxiv.org/abs/2403.14282) | 研究探讨数据偏见如何影响模型公平性，提出了建立偏见类型与缓解技术有效性之间关系的方法 |
| [^43] | [Multi-role Consensus through LLMs Discussions for Vulnerability Detection](https://arxiv.org/abs/2403.14274) | 本论文提出了一种利用LLMs模拟不同角色进行讨论，以达成对代码中漏洞存在和分类的共识的方法，并在初步评估中实现了精确率、召回率和F1分数的明显提升。 |
| [^44] | [Reactor Optimization Benchmark by Reinforcement Learning](https://arxiv.org/abs/2403.14273) | 本文通过引入一个新颖的基准问题，在OpenNeoMC框架中设计了一个用于强化学习的基准测试，旨在优化研究反应堆中的一个单元格，以最大化中子通量并保持反应堆的临界性。 |
| [^45] | [A Framework for Portrait Stylization with Skin-Tone Awareness and Nudity Identification](https://arxiv.org/abs/2403.14264) | 提出了一种肖像风格化框架，结合了裸体内容识别模块和肤色感知肖像风格化模块，以解决过滤有害内容并保留肤色特征的挑战。 |
| [^46] | [LayoutLLM: Large Language Model Instruction Tuning for Visually Rich Document Understanding](https://arxiv.org/abs/2403.14252) | 提出了一种新的LayoutLLM模型，通过结合大规模语言模型和文档图像理解的优势，实现了对文档图像的理解。 |
| [^47] | [CATSE: A Context-Aware Framework for Causal Target Sound Extraction](https://arxiv.org/abs/2403.14246) | CATSE提出了一种适用于实时处理的上下文感知低延迟因果TSE模型，通过引入复合多任务训练目标，提高了目标声音提取的性能。 |
| [^48] | [Isotropic Gaussian Splatting for Real-Time Radiance Field Rendering](https://arxiv.org/abs/2403.14244) | 提出使用同性质高斯核替代各向异性核来提高计算性能，在不失去几何表示准确性的情况下实现约100倍的加速，适用于多种需要辐射场的应用领域。 |
| [^49] | [Dermacen Analytica: A Novel Methodology Integrating Multi-Modal Large Language Models with Machine Learning in tele-dermatology](https://arxiv.org/abs/2403.14243) | 本文提出了一种新方法，在远程皮肤病学中整合了多模式大型语言模型与机器学习，旨在通过综合利用大型语言模型、Transformer视觉模型和复杂的机器学习工具，辅助诊断皮肤病变和其他皮肤状况，从而全面解决该领域的诊断流程。 |
| [^50] | [Reinforcement Learning from Reflective Feedback (RLRF): Aligning and Improving LLMs via Fine-Grained Self-Reflection](https://arxiv.org/abs/2403.14238) | RLRF提出了一种新颖的框架，通过细粒度反馈和自我反思机制，可以改进LLMs的核心能力，超越表面调整。 |
| [^51] | [A Unified Framework for Model Editing](https://arxiv.org/abs/2403.14236) | 这个统一框架结合了“定位和编辑”模型编辑技术，最大化保留某些向量表示并记忆新事实信息。 |
| [^52] | [SoftPatch: Unsupervised Anomaly Detection with Noisy Data](https://arxiv.org/abs/2403.14233) | 首次考虑图像传感器异常检测中的标签级别噪声，并提出了一种能够有效去噪补丁级别数据的无监督异常检测方法SoftPatch。 |
| [^53] | [PeerGPT: Probing the Roles of LLM-based Peer Agents as Team Moderators and Participants in Children's Collaborative Learning](https://arxiv.org/abs/2403.14227) | PeerGPT论文探究了基于LLM的同侪代理作为团队主持人和参与者在儿童协作学习中的角色，发现他们在管理讨论中表现出色，但作为参与者可能存在反馈及时性不足的问题。 |
| [^54] | [Unsupervised Audio-Visual Segmentation with Modality Alignment](https://arxiv.org/abs/2403.14203) | 提出了一种无监督音频-视觉分割方法 MoCA，在模态对应对齐的基础上使用DINO、SAM和ImageBind模型，实现了多模态关联，并引入了像素匹配聚合策略。 |
| [^55] | [Debiasing surgeon: fantastic weights and how to find them](https://arxiv.org/abs/2403.14200) | 证明了在深度学习模型中存在一些无偏子网络，可以在不需要依赖算法偏见的情况下被提取出来，并且这种特定架构无法学习任何特定的偏见。 |
| [^56] | [Quantum-activated neural reservoirs on-chip open up large hardware security models for resilient authentication](https://arxiv.org/abs/2403.14188) | 该研究在芯片上实现了一个大规模量子激活神经水库，使网络规模和功耗均大幅提高，可用于实现具有弹性身份验证功能的大型硬件安全模型 |
| [^57] | [StyleCineGAN: Landscape Cinemagraph Generation using a Pre-trained StyleGAN](https://arxiv.org/abs/2403.14186) | 提出了一种利用预训练StyleGAN自动生成静止风景图像的电影图景方法，通过利用深层特征空间和多尺度深度特征扭曲（MSDFW）生成高分辨率且具有合理循环动画的电影图景，并证明了该方法的优越性 |
| [^58] | [OTSeg: Multi-prompt Sinkhorn Attention for Zero-Shot Semantic Segmentation](https://arxiv.org/abs/2403.14183) | 通过引入OTSeg中的Multi-Prompts Sinkhorn Attention机制，能够更好地利用多个文本提示来匹配相关像素嵌入，从而提升零样本语义分割性能。 |
| [^59] | [Leveraging Large Language Model-based Room-Object Relationships Knowledge for Enhancing Multimodal-Input Object Goal Navigation](https://arxiv.org/abs/2403.14163) | 提出了一种基于大型语言模型的房间-物体关系知识的数据驱动、模块化方法，利用多通道Swin-Unet架构进行多任务学习，以增强多模态输入的目标导航。 |
| [^60] | [Policy Mirror Descent with Lookahead](https://arxiv.org/abs/2403.14156) | 提出了一种新类别的策略镜像下降算法$h$-PMD，它通过在PMD更新规则中结合多步贪心策略改进和前瞻深度$h，以解决折扣无限时间视角下的马尔可夫决策过程。 |
| [^61] | [Deep Learning for Trajectory Data Management and Mining: A Survey and Beyond](https://arxiv.org/abs/2403.14151) | 本文综述了深度学习在轨迹数据管理与挖掘中的发展和最新进展，探讨了其在预处理、存储、分析、预测、推荐、分类、估计和检测等方面的应用。 |
| [^62] | [Evolving Benchmark Functions to Compare Evolutionary Algorithms via Genetic Programming](https://arxiv.org/abs/2403.14146) | 通过遗传规划生成的基准函数能够更好地区分算法，进一步实现了自动设计基准函数和比较进化算法的目的。 |
| [^63] | [Advancing IIoT with Over-the-Air Federated Learning: The Role of Iterative Magnitude Pruning](https://arxiv.org/abs/2403.14120) | 联邦学习在工业物联网中的应用促进了机器学习和数据隐私，本文提出了一种用于提升PIUs性能的迭代幅值剪枝技术。 |
| [^64] | [C-TPT: Calibrated Test-Time Prompt Tuning for Vision-Language Models via Text Feature Dispersion](https://arxiv.org/abs/2403.14119) | 本文研究了在测试时提示调整过程中通过利用CLIP的固有属性来探讨校准的方法，发现提示选择显著影响了CLIP中的校准，其中导致更高文本特征离散性的提示会产生更好校准的预测。 |
| [^65] | [Heuristic Algorithm-based Action Masking Reinforcement Learning (HAAM-RL) with Ensemble Inference Method](https://arxiv.org/abs/2403.14110) | HAAM-RL方法结合了启发式算法动作屏蔽和集成推断方法，用于优化汽车喷漆过程中的颜色批处理重新排序问题，实验结果表明取得了16.25%的性能提升。 |
| [^66] | [DouRN: Improving DouZero by Residual Neural Networks](https://arxiv.org/abs/2403.14102) | 通过在DouZero模型中引入残差网络，并探索不同的架构设计，我们显著提高了斗地主游戏中获胜率。 |
| [^67] | [Causal knowledge engineering: A case study from COVID-19](https://arxiv.org/abs/2403.14100) | 该研究提出了一种名为因果知识工程（CKE）的方法，在COVID-19背景下开发了一个因果知识库，支持了各种特定应用模型的建立。 |
| [^68] | [Carbon Footprint Reduction for Sustainable Data Centers in Real-Time](https://arxiv.org/abs/2403.14092) | 我们提出了一种Data Center Carbon Footprint Reduction (DC-CFR) 多代理强化学习（MARL）框架，旨在实时优化数据中心以减少碳足迹。 |
| [^69] | [Can ChatGPT Detect DeepFakes? A Study of Using Multimodal Large Language Models for Media Forensics](https://arxiv.org/abs/2403.14077) | 本研究探讨了使用多模态大型语言模型（LLMs）进行DeepFake检测的能力，通过实验证明它们能够揭示AI生成的图像，尽管LLMs并非专为媒体取证任务设计，这一发现具有重要意义。 |
| [^70] | [A Roadmap Towards Automated and Regulated Robotic Systems](https://arxiv.org/abs/2403.14049) | 生成技术的快速发展为更高级别的自动化开启新可能性，作者提出了一个朝向完全自动化和受监管的机器人系统的路线图。 |
| [^71] | [Ax-to-Grind Urdu: Benchmark Dataset for Urdu Fake News Detection](https://arxiv.org/abs/2403.14037) | 本文提出了乌尔都语虚假新闻检测的首个最大规模公开数据集，填补了地区语言虚假新闻检测领域数据集规模有限的空白。 |
| [^72] | [Searching Search Spaces: Meta-evolving a Geometric Encoding for Neural Networks](https://arxiv.org/abs/2403.14019) | 通过使用笛卡尔遗传规划（CGP）的元演化方法，优化了神经网络Evolution的几何编码（GENE）, 找到更有效的距离函数，创建一个更易于利用的搜索空间。 |
| [^73] | [On Prompt Sensitivity of ChatGPT in Affective Computing](https://arxiv.org/abs/2403.14006) | 该研究介绍了一个用于评估基础模型性能敏感性的方法，针对ChatGPT在情感计算中的提示敏感性进行了研究和评估，涵盖情绪分析、毒性检测和讽刺检测。 |
| [^74] | ["This is not a data problem": Algorithms and Power in Public Higher Education in Canada](https://arxiv.org/abs/2403.13969) | 研究揭示了公立高等教育中算法决策的影响，包括学生监视增加、不平等加剧和教师-学生关系的自动化。 |
| [^75] | [Open Access NAO (OAN): a ROS2-based software framework for HRI applications with the NAO robot](https://arxiv.org/abs/2403.13960) | 本文提出了一个新的基于ROS2的软件框架，使得NAO机器人具有更好性能和新功能，包括人形机器人的基本技能和常用于HRI的功能，并且该框架是可立即使用且高度可扩展的工具。 |
| [^76] | [ACDG-VTON: Accurate and Contained Diffusion Generation for Virtual Try-On](https://arxiv.org/abs/2403.13951) | 提出了一种独特的训练方案，限制了扩散训练的范围，有效保留了服装细节，并实现了多服装试穿、分层、风格和鞋子试穿，无需在更高分辨率下进行训练。最终，方法在准确性和质量方面超越了之前的方法。 |
| [^77] | [Evo* 2023 -- Late-Breaking Abstracts Volume](https://arxiv.org/abs/2403.13950) | Evo* 2023会议收录了关于将不同的生物启发方法（主要是进化计算）应用于解决不同问题（大多为现实世界问题）的研究和初步结果。 |
| [^78] | [BlendScape: Enabling Unified and Personalized Video-Conferencing Environments through Generative AI](https://arxiv.org/abs/2403.13947) | BlendScape通过生成式人工智能技术实现了用户定制视频会议环境，支持灵活的任务空间表示和多模交互技术，使用户能够快速表达设计意图并设想未来会议中的协作结构。 |
| [^79] | [Multi-criteria approach for selecting an explanation from the set of counterfactuals produced by an ensemble of explainers](https://arxiv.org/abs/2403.13940) | 本文提出了一种多阶段集成方法，通过多标准分析选择单个反事实，避免了用户测试多种不同解释方法和分析冲突解决方案的困难，提供了一个在多个质量度量上得分很高的妥协方案。 |
| [^80] | [Reducing Large Language Model Bias with Emphasis on 'Restricted Industries': Automated Dataset Augmentation and Prejudice Quantification](https://arxiv.org/abs/2403.13925) | 本文提出了一种针对“受限行业”进行自动数据集增强以减少大型语言模型偏见的新机制，并创建了mb-index和db-index两个新的偏见量化指标。 |
| [^81] | [Towards Learning Contrast Kinetics with Multi-Condition Latent Diffusion Models](https://arxiv.org/abs/2403.13890) | 提出了一个多条件潜在扩散模型来学习对比动力学，以减少对静脉内对比剂的依赖性。 |
| [^82] | [Accurately Predicting Probabilities of Safety-Critical Rare Events for Intelligent Systems](https://arxiv.org/abs/2403.13869) | 该研究致力于发展一个在评估安全关键自主安全性的重要性方面，在精度和召回率方面都表现出色的关键性预测模型。 |
| [^83] | [The Bid Picture: Auction-Inspired Multi-player Generative Adversarial Networks Training](https://arxiv.org/abs/2403.13866) | 本文提出了一种拍卖启发的多人生成对抗网络训练方法，可以缓解GAN的模式坍塌问题。 |
| [^84] | [DiffImpute: Tabular Data Imputation With Denoising Diffusion Probabilistic Model](https://arxiv.org/abs/2403.13863) | 提出了DiffImpute，一种基于去噪扩散概率模型的表格数据插补方法，可以有效处理不同类型的缺失数据，并通过定制多个表格去噪网络来增强插补的一致性。 |
| [^85] | [Spatio-Temporal Fluid Dynamics Modeling via Physical-Awareness and Parameter Diffusion Guidance](https://arxiv.org/abs/2403.13850) | 该论文提出了ST-PAD框架，通过时空物理学意识和参数扩散引导实现流体动力学的高精度仿真和预测，在多个基准数据集上的实验证明其优于当前主流模型 |
| [^86] | [Graphs Unveiled: Graph Neural Networks and Graph Generation](https://arxiv.org/abs/2403.13849) | 该论文综述了图神经网络（GNNs）在各个领域的应用，并介绍了GNNs中的先进领域：图生成。 |
| [^87] | [Smooth Sensitivity for Learning Differentially-Private yet Accurate Rule Lists](https://arxiv.org/abs/2403.13848) | 通过建立Gini不纯度的平滑敏感度并将其应用于提出DP贪婪规则列表算法，本文改善了差异保护模型的准确性问题。 |
| [^88] | [Optimal Transport for Domain Adaptation through Gaussian Mixture Models](https://arxiv.org/abs/2403.13847) | 通过高斯混合模型进行域自适应的最优输运，可以实现源域和目标域混合成分之间的匹配，从而在失效诊断中取得最先进的性能。 |
| [^89] | [A Clustering Method with Graph Maximum Decoding Information](https://arxiv.org/abs/2403.13846) | CMDI聚类方法创新性地将二维结构信息理论融入聚类过程中，弥补了基于图的模型聚类方法中忽略的随机游走访问节点和数据中嵌入的结构信息的不确定性。 |
| [^90] | [Learning to better see the unseen: Broad-Deep Mixed Anti-Forgetting Framework for Incremental Zero-Shot Fault Diagnosis](https://arxiv.org/abs/2403.13845) | 提出了增量式ZSFD范式，开发了广深混合反遗忘框架（BDMAFF），旨在学习和适应新的故障类别和属性，解决了现有ZSFD范式在工业场景中无法从不断变化的训练数据流中学习的问题。 |
| [^91] | [Scheduled Knowledge Acquisition on Lightweight Vector Symbolic Architectures for Brain-Computer Interfaces](https://arxiv.org/abs/2403.13844) | 低维度计算分类器基于向量符号体系结构（VSA），通过定时知识获取方法，提高小模型准确率，解决处理复杂脑信号的挑战。 |
| [^92] | [Machine Learning and Vision Transformers for Thyroid Carcinoma Diagnosis: A review](https://arxiv.org/abs/2403.13843) | 该论文总结了使用机器学习和大数据分析结合transformer评估甲状腺癌预后的方法，介绍了新的分类系统，并强调了人工智能在辅助甲状腺癌诊断和治疗中的重要性。 |
| [^93] | [Integrating Wearable Sensor Data and Self-reported Diaries for Personalized Affect Forecasting](https://arxiv.org/abs/2403.13841) | 本论文提出了一种整合了可穿戴传感器数据和自我报告日记的多模态深度学习模型，用于情感状态的预测。 |
| [^94] | [Whose Side Are You On? Investigating the Political Stance of Large Language Models](https://arxiv.org/abs/2403.13840) | 本研究提出了一个定量框架和流程，系统调查大型语言模型的政治取向，结果显示这些模型倾向于提供与自由主义或左倾观点更为接近的回应。 |
| [^95] | [depyf: Open the Opaque Box of PyTorch Compiler for Machine Learning Researchers](https://arxiv.org/abs/2403.13839) | depyf是一个非侵入性和用户友好的工具，旨在帮助机器学习研究者揭开PyTorch编译器的内部工作机制，并通过反编译将字节码转换为源代码，从而增进用户对底层过程的理解。 |
| [^96] | [SMART: Automatically Scaling Down Language Models with Accuracy Guarantees for Reduced Processing Fees](https://arxiv.org/abs/2403.13835) | 提出了SMART框架，可通过准确性约束最小化自然语言处理任务的推理成本，同时确保结果质量。 |
| [^97] | [Deep Generative Models for Ultra-High Granularity Particle Physics Detector Simulation: A Voyage From Emulation to Extrapolation](https://arxiv.org/abs/2403.13825) | 该论文提出了一种新的几何感知生成模型IEA-GAN，以及一种迎接下游物理分析挑战的YonedaVAE模型，为超高细粒度粒子物理探测器模拟提供了重要的解决方案。 |
| [^98] | [Quantitative Analysis of AI-Generated Texts in Academic Research: A Study of AI Presence in Arxiv Submissions using AI Detection Tool](https://arxiv.org/abs/2403.13812) | 论文研究了一种能够检测Arxiv投稿中AI成分的方法，使用物理、数学和计算机科学文章创建数据集，并通过Originality.ai进行分析，准确率达到98%。 |
| [^99] | [Predicting Confinement Effect of Carbon Fiber Reinforced Polymers on Strength of Concrete using Metaheuristics-based Artificial Neural Networks](https://arxiv.org/abs/2403.13809) | 通过元启发式人工神经网络方法，成功预测了碳纤维增强聚合物对混凝土强度的束缚效应。 |
| [^100] | [LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models](https://arxiv.org/abs/2403.13372) | LlamaFactory是一个统一框架，整合了一系列前沿的高效训练方法，使用户能够在不需要编码的情况下灵活定制100多种LLMs的微调。 |
| [^101] | [Arcee's MergeKit: A Toolkit for Merging Large Language Models](https://arxiv.org/abs/2403.13257) | 合并不同语言模型的参数，无需额外训练即可创建多任务模型，提升模型性能和多功能性，解决AI中的复杂挑战。 |
| [^102] | [FlowerFormer: Empowering Neural Architecture Encoding using a Flow-aware Graph Transformer](https://arxiv.org/abs/2403.12821) | FlowerFormer是一种强大的图变换器，通过双向异步消息传递和基于流程的全局注意力，可以增强神经结构的表征学习。 |
| [^103] | [Discover and Mitigate Multiple Biased Subgroups in Image Classifiers](https://arxiv.org/abs/2403.12777) | 提出了一种称为“分解、解释和减轻（DIM）”的新方法, 用于在图像分类器中发现和减轻多个有偏子群体，增强模型鲁棒性。 |
| [^104] | [Unimodal Multi-Task Fusion for Emotional Mimicry Prediciton](https://arxiv.org/abs/2403.11879) | 通过融合技术整合全局背景信息和采用LSTM架构进行时间分析，我们的方法在情感模仿强度预测任务上取得了显着的改进。 |
| [^105] | [Optimizing Language Augmentation for Multilingual Large Language Models: A Case Study on Korean](https://arxiv.org/abs/2403.10882) | 该研究提出了三种策略来增强基于公开可用MLLMs的资源较少的语言的性能，包括扩展词汇、双语数据预训练和指导微调。 |
| [^106] | [Cost-Sensitive Learning to Defer to Multiple Experts with Workload Constraints](https://arxiv.org/abs/2403.06906) | 提出了成本和工作量约束下的推迟框架（DeCCaF），旨在解决成本敏感场景、并发预测和人类工作能力约束等问题 |
| [^107] | [Is this the real life? Is this just fantasy? The Misleading Success of Simulating Social Interactions With LLMs](https://arxiv.org/abs/2403.05020) | 研究发现，使用LLMs进行社交互动的全知模拟比非全知模拟更容易实现社交目标，尽管非全知模拟更接近实际情况。 |
| [^108] | [Beyond Specialization: Assessing the Capabilities of MLLMs in Age and Gender Estimation](https://arxiv.org/abs/2403.02302) | 本研究评估了多模态大型语言模型（MLLMs）在年龄和性别估计中的能力，对不同模型进行了比较，揭示了它们在特定任务上的优势和劣势。 |
| [^109] | [NewsBench: Systematic Evaluation of LLMs for Writing Proficiency and Safety Adherence in Chinese Journalistic Editorial Applications](https://arxiv.org/abs/2403.00862) | NewsBench是一个评估LLMs在中国新闻写作水平和安全性遵从能力的基准框架，揭示了在创造性写作任务中LLMs相对不足的新闻伦理遵守方面的需求。 |
| [^110] | [OSCaR: Object State Captioning and State Change Representation](https://arxiv.org/abs/2402.17128) | 本文介绍了一个新的数据集和基准OSCaR，旨在解决描述复杂视觉环境中对象状态变化的问题，为评估多模态大型语言提供了一个新的实验平台。 |
| [^111] | [ROS-Causal: A ROS-based Causal Analysis Framework for Human-Robot Interaction Applications](https://arxiv.org/abs/2402.16068) | ROS-Causal是一个基于ROS的框架，用于在人机空间交互中进行数据收集和因果发现，解决了机器人领域中缺乏因果发现方法在ROS生态系统内实现的问题。 |
| [^112] | [Exploring Neuron Interactions and Emergence in LLMs: From the Multifractal Analysis Perspective](https://arxiv.org/abs/2402.09099) | 该论文通过多重分形分析视角，深入研究了LLMs中神经元相互作用和出现现象。通过引入自组织和多重分形分析的概念，研究了神经元相互作用的动态演化过程，尤其关注训练中的复杂行为。通过提出基于神经元的多重分形分析方法，实现了对大型模型中神经元相互作用的定量分析。 |
| [^113] | [Intelligent Canvas: Enabling Design-Like Exploratory Visual Data Analysis through Rapid Prototyping, Iteration and Curation](https://arxiv.org/abs/2402.08812) | 该论文提出了一种"类似设计"的智能画布环境，通过将生成式AI组件集成到数据分析中，实现了快速原型设计、迭代和比较可视化管理。通过用户研究，论文验证了画布界面的有效性。 |
| [^114] | [CPSDBench: A Large Language Model Evaluation Benchmark and Baseline for Chinese Public Security Domain](https://arxiv.org/abs/2402.07234) | CPSDBench是一个专门为中国公共安全领域量身定制的大型语言模型评估基准，通过整合实际场景中收集的公共安全相关数据集，针对文本分类、信息提取、问题回答和文本生成四个关键维度全面评估LLMs的性能，并引入创新的评估指标，提高了对现有模型在解决公共安全问题方面性能的理解。 |
| [^115] | [ANLS* -- A Universal Document Processing Metric for Generative Large Language Models](https://arxiv.org/abs/2402.03848) | ANLS*是一种用于生成型模型的新度量方法，针对各种任务包括信息提取和分类任务进行评估。它扩展了现有的ANLS度量方法，可以作为替代方案使用。 |
| [^116] | [EasyInstruct: An Easy-to-use Instruction Processing Framework for Large Language Models](https://arxiv.org/abs/2402.03049) | EasyInstruct是一个易于使用的用于大型语言模型的指令处理框架，通过模块化指令生成、选择和提示，并考虑它们的组合和交互，使指令处理更加方便和高效。 |
| [^117] | [SLIM: Skill Learning with Multiple Critics](https://arxiv.org/abs/2402.00823) | SLIM是一种多判别器学习方法，通过在机器人操作中组合多个判别器的奖励函数，显著改善了潜变量技能发现，克服了奖励之间的干扰。 |
| [^118] | [Graph Edits for Counterfactual Explanations: A comparative study](https://arxiv.org/abs/2401.11609) | 研究通过比较监督和无监督的图神经网络方法，扩展了图编辑作为反事实解释的先前努力，探讨了将输入数据表示为图形对于生成黑箱图像分类器最小且有意义的反事实解释的性能和时间效率最佳的方法。 |
| [^119] | [On the convergence of loss and uncertainty-based active learning algorithms](https://arxiv.org/abs/2312.13927) | 论文考虑了损失和不确定性基础的主动学习算法在线性分类器和线性可分数据集上的收敛速度，提出了一种新算法并展示了其效率。 |
| [^120] | [Intrinsic Image Diffusion for Indoor Single-view Material Estimation](https://arxiv.org/abs/2312.12274) | 提出了内在图像扩散模型，应用于室内单视图材料估计，通过概率形式的条件生成模型采样解空间来解决外观分解中光照和材料属性之间的固有模糊性挑战。 |
| [^121] | [Weighted Ensemble Models Are Strong Continual Learners](https://arxiv.org/abs/2312.08977) | 通过加权集成模型实现了高准确性的持续学习，兼顾可塑性和稳定性。 |
| [^122] | [Exploring Large Language Models to Facilitate Variable Autonomy for Human-Robot Teaming](https://arxiv.org/abs/2312.07214) | 本文探讨了将大型语言模型集成到人机团队合作环境中，通过口头交流促进机器人的可变自主性，提出了基于GPT的多机器人测试台架环境，并进行了用户研究以验证其有效性和用户策略。 |
| [^123] | [Working Backwards: Learning to Place by Picking](https://arxiv.org/abs/2312.02352) | 通过逆向抓取过程并利用拾取和放置问题的对称性，提出了一种通过拾取的放置方法，并用自主收集的演示直接训练策略，实现在接触受限环境下物体放置任务的自主收集和泛化。 |
| [^124] | [LMM-Assisted Breast Cancer Treatment Target Segmentation with Consistency Embedding](https://arxiv.org/abs/2311.15876) | RO-LMM是一个针对放射肿瘤学领域设计的多功能大型多模型，提出了一种Consistency Embedding Fine-Tuning（CEFTune）技术，使其能够在保持处理干净输入能力的同时提升对嘈杂输入的鲁棒性，用于放射治疗计划和目标体积分割。 |
| [^125] | [Align before Adapt: Leveraging Entity-to-Region Alignments for Generalizable Video Action Recognition](https://arxiv.org/abs/2311.15619) | 提出了一种“对齐前自适应”（ALT）范式，通过利用实体到区域对齐，将文本嵌入作为查询，从而帮助提取视频中最重要实体的语义。 |
| [^126] | [Point2RBox: Combine Knowledge from Synthetic Visual Patterns for End-to-end Oriented Object Detection with Single Point Supervision](https://arxiv.org/abs/2311.14758) | 提出了Point2RBox方法，通过合成模式知识组合和变换自监督的原则，实现了单点监督的定向物体检测 |
| [^127] | [Distilling and Retrieving Generalizable Knowledge for Robot Manipulation via Language Corrections](https://arxiv.org/abs/2311.10678) | 本研究提出了一种基于大型语言模型的系统，名为DROC，能够回应任意形式的语言反馈，从纠正中提炼出通用知识，并根据文本和视觉相似性检索相关的过去经验，以改进机器人操作的性能。 |
| [^128] | [TD-MPC2: Scalable, Robust World Models for Continuous Control](https://arxiv.org/abs/2310.16828) | TD-MPC2是对TD-MPC算法的一系列改进，通过一组超参数在104个在线RL任务中取得了显著进展，成功训练单一的317M参数代理执行80个任务。 |
| [^129] | [Graph Ranking Contrastive Learning: A Extremely Simple yet Efficient Method](https://arxiv.org/abs/2310.14525) | 图对比学习（GCL）作为一种代表性的图自监督方法，提出了一种旨在减轻假阴性影响的极其简单而有效的方法。 |
| [^130] | [An explainable three dimension framework to uncover learning patterns: A unified look in variable sulci recognition](https://arxiv.org/abs/2309.00903) | 该论文提出了一个针对医学成像中的可解释AI的三维框架，旨在解决神经科学领域中识别大脑沟特征的复杂性问题。 |
| [^131] | [RecMind: Large Language Model Powered Agent For Recommendation](https://arxiv.org/abs/2308.14296) | RecMind是一种LLM驱动的自主推荐代理，通过Self-Inspiring算法提高了规划能力，能够为零-shot个性化推荐提供支持。 |
| [^132] | [Deep Classifier Mimicry without Data Access](https://arxiv.org/abs/2306.02090) | 提出了一种无需访问原始数据的模型-无关知识蒸馏过程CAKE，可以模拟深度分类器，通过生成噪声合成样本对比地扩散到模型的决策边界。 |
| [^133] | [Effective Structured Prompting by Meta-Learning and Representative Verbalizer](https://arxiv.org/abs/2306.00618) | 通过使用提示池和构建基于实例的提示以及引入新颖的软语言化器，提出了一种通过元学习和代表性语言化器实现有效的结构化提示的方法 |
| [^134] | [Toward a Theory of Causation for Interpreting Neural Code Models](https://arxiv.org/abs/2302.03788) | 该论文介绍了一种名为$do_{code}$的后验解释方法，用于解释神经代码模型的预测，基于因果推断，旨在实现面向编程语言的解释。 |
| [^135] | [Hyper-parameter Tuning for Fair Classification without Sensitive Attribute Access](https://arxiv.org/abs/2302.01385) | 提出了Antigone框架，可以在训练数据或验证数据中都无需访问敏感属性即可训练公平的分类器，通过生成伪敏感属性来实现。 |
| [^136] | [Multi-Scale Contrastive Knowledge Co-Distillation for Event Temporal Relation Extraction](https://arxiv.org/abs/2209.00568) | 提出了MulCo：多尺度对比知识共同蒸馏用于全面提高所有类型时间数据集性能 |
| [^137] | [Emergent Dominance Hierarchies in Reinforcement Learning Agents.](http://arxiv.org/abs/2401.12258) | 本研究在强化学习中探讨了一种新的支配等级现象，并证明了在没有明确编程和内在奖励的情况下，强化学习代理能够自主发明、学习、实施和传递支配等级给新的群体。 |
| [^138] | [PhotoBot: Reference-Guided Interactive Photography via Natural Language.](http://arxiv.org/abs/2401.11061) | PhotoBot是一个通过自然语言引导和机器人摄影师相互作用的自动化照片获取框架。它利用视觉语言模型和物体检测器来提供摄影建议，并通过视觉变换器计算相机的姿态调整，从而实现高质量的照片获取。 |
| [^139] | [FourCastNeXt: Improving FourCastNet Training with Limited Compute.](http://arxiv.org/abs/2401.05584) | 本研究提出了改进的方法，可以使用仅需基线要求的1%计算资源训练FourCastNet，并且保持了与基线相当或甚至更好的模型性能。 |
| [^140] | [A Survey on Large Language Model (LLM) Security and Privacy: The Good, the Bad, and the Ugly.](http://arxiv.org/abs/2312.02003) | 该论文调查了大型语言模型（LLM）与安全和隐私的相关性。研究发现LLMs在安全和隐私保护方面具有积极影响，但同时也存在潜在的风险、威胁和漏洞。 |
| [^141] | [RiskQ: Risk-sensitive Multi-Agent Reinforcement Learning Value Factorization.](http://arxiv.org/abs/2311.01753) | RiskQ是一种解决多智能体强化学习中风险敏感协调要求的方法，通过引入风险敏感的个体-全局最大（RIGM）原则和建模联合回报分布实现价值因子分解。 |
| [^142] | [VQPy: An Object-Oriented Approach to Modern Video Analytics.](http://arxiv.org/abs/2311.01623) | VQPy是一种面向对象的视频分析方法，它使用Python变体作为前端，并具有可扩展的后端，可以自动构建和优化基于视频对象的处理流程。 |
| [^143] | [Knowing What LLMs DO NOT Know: A Simple Yet Effective Self-Detection Method.](http://arxiv.org/abs/2310.17918) | 本文提出了一种新的自我检测方法，用于判断大型语言模型 (LLMs) 无法回答的问题，以避免生成非事实性的回答。通过多样化问题的文本表达，收集答案，并检查生成的答案之间的差异，可以识别出可能生成虚假回答的问题。该方法只需要利用LLMs自身，无需其他外部资源。这种方法在Vicuna、ChatGPT和GPT-4等最新发布的LLMs上得到了有效验证。 |
| [^144] | [AutoDAN: Generating Stealthy Jailbreak Prompts on Aligned Large Language Models.](http://arxiv.org/abs/2310.04451) | 本文介绍了一种名为AutoDAN的方法，该方法旨在在对齐的大型语言模型上自动生成隐蔽的越狱提示，以解决现有越狱技术的可扩展性和隐蔽性问题。 |
| [^145] | [ED-NeRF: Efficient Text-Guided Editing of 3D Scene using Latent Space NeRF.](http://arxiv.org/abs/2310.02712) | ED-NeRF 提出了一种高效的 3D 场景编辑方法，通过将场景嵌入到潜空间中，得到更快速且更易于编辑的 NeRF 骨干。 |
| [^146] | [Detecting Sexual Content at the Sentence Level in First Millennium Latin Texts.](http://arxiv.org/abs/2309.14974) | 该研究提出使用深度学习方法在句子级别进行语义分类，以加速人文学科和语言学领域中语料库建设的过程。经过评估，该方法在检测性内容方面表现出高精度和真阳性率，并探索了不同的输入嵌入层对模型性能的影响。 |
| [^147] | [Sequence-to-Sequence Spanish Pre-trained Language Models.](http://arxiv.org/abs/2309.11259) | 该论文介绍了一种新的序列到序列的西班牙预训练语言模型，该模型在各种序列到序列任务中表现出了竞争性能，并提供了BART、T5和BERT2BERT-style模型的西班牙版本。 |
| [^148] | [Enhancing Multi-modal Cooperation via Fine-grained Modality Valuation.](http://arxiv.org/abs/2309.06255) | 本文提出了一种精细的模态评估指标，用于评估每个模态在样本级别的贡献，并发现多模态模型倾向于依赖一个特定的模态，导致其他模态的贡献较低。 |
| [^149] | [Deep Reinforcement Learning from Hierarchical Weak Preference Feedback.](http://arxiv.org/abs/2309.02632) | 本研究探讨了如何利用分层的弱偏好反馈进行深度强化学习。通过学习奖励函数，与人类偏好非常一致的复杂奖励可以帮助强化学习解决日益困难的问题。 |
| [^150] | [TensorBank:Tensor Lakehouse for Foundation Model Training.](http://arxiv.org/abs/2309.02094) | TensorBank是一个基于Tensor的湖仓库，能够以高速从云对象存储流式传输张量到GPU内存，并通过使用分层统计指标进行查询加速。 |
| [^151] | [Trustworthy LLMs: a Survey and Guideline for Evaluating Large Language Models' Alignment.](http://arxiv.org/abs/2308.05374) | 本文介绍了一份关于评估LLM可信度的综合调查，并提供了指导。调查涵盖了可靠性、安全性、公平性、抵抗滥用、可解释性和推理能力、遵守社会规范以及鲁棒性等七个主要类别，共计29个子类别。 |
| [^152] | [Metacognitive Prompting Improves Understanding in Large Language Models.](http://arxiv.org/abs/2308.05342) | 元认知提示 (MP) 是一种改进大型语言模型 (LLMs) 理解能力的策略。实验结果表明，使用MP的PaLM在各种自然语言理解任务中接近于GPT-4的性能水平。 |
| [^153] | [QH9: A Quantum Hamiltonian Prediction Benchmark for QM9 Molecules.](http://arxiv.org/abs/2306.09549) | 该论文提出了一种新的量子哈密顿数据集QH9，用于为各种分子提供精确的哈密顿矩阵。通过设计基准任务，展示了当前机器学习模型有能力预测任意分子的哈密顿矩阵。 |
| [^154] | [ChatGPT4PCG Competition: Character-like Level Generation for Science Birds.](http://arxiv.org/abs/2303.15662) | 本论文介绍了举办在2023 IEEE游戏会议上的第一届ChatGPT4PCG比赛，目标是让ChatGPT生成具有高稳定性和类似角色的特质来生成具有科学鸟角色级水平的关卡。 |
| [^155] | [ComCLIP: Training-Free Compositional Image and Text Matching.](http://arxiv.org/abs/2211.13854) | 本文提出了一个无需训练的组合图像与文本匹配模型 ComCLIP，通过将输入图像分解为主体、对象和动作子图像，并结合视觉编码器和文本编码器进行逐步匹配，以解决组合图像与文本匹配中的伪匹配问题。 |

# 详细

[^1]: MathVerse：您的多模式LLM是否真正看到了视觉数学问题中的图表？

    MathVerse: Does Your Multi-modal LLM Truly See the Diagrams in Visual Math Problems?

    [https://arxiv.org/abs/2403.14624](https://arxiv.org/abs/2403.14624)

    MathVerse是一个全方位的视觉数学基准测试，旨在公平而深入地评估MLLMs在视觉数学问题解决中的能力。

    

    多模式大型语言模型（MLLMs）取得了显著进展，在视觉环境中表现出色，然而它们在视觉数学问题解决方面的能力仍未充分评估和理解。本研究调查了当前基准测试，将过多的视觉内容融入文本问题中，这有助于MLLM在不真正解释输入图表的情况下推导答案。为此，我们介绍了MathVerse，这是一个全方位的视觉数学基准测试，旨在公平而深入地评估MLLMs。我们精心收集了2,612个高质量的多学科数学问题，其中包含图表，来源于公开渠道。然后，每个问题由人工注释者转化为六个不同版本，每个版本在多模式中提供不同程度的信息内容，共贡献了15K个测试样本。这种方法使得MathVerse能够同时

    arXiv:2403.14624v1 Announce Type: cross  Abstract: The remarkable progress of Multi-modal Large Language Models (MLLMs) has garnered unparalleled attention, due to their superior performance in visual contexts. However, their capabilities in visual math problem-solving remain insufficiently evaluated and understood. We investigate current benchmarks to incorporate excessive visual content within textual questions, which potentially assist MLLMs in deducing answers without truly interpreting the input diagrams. To this end, we introduce MathVerse, an all-around visual math benchmark designed for an equitable and in-depth evaluation of MLLMs. We meticulously collect 2,612 high-quality, multi-subject math problems with diagrams from publicly available sources. Each problem is then transformed by human annotators into six distinct versions, each offering varying degrees of information content in multi-modality, contributing to 15K test samples in total. This approach allows MathVerse to co
    
[^2]: Videoshop：具有噪声外推扩散反演的本地化语义视频编辑

    Videoshop: Localized Semantic Video Editing with Noise-Extrapolated Diffusion Inversion

    [https://arxiv.org/abs/2403.14617](https://arxiv.org/abs/2403.14617)

    Videoshop是一个无需训练的视频编辑算法，通过图像为基础的方法实现了本地化语义编辑，从而允许用户对视频进行精细控制，取得了更高质量的编辑效果。

    

    我们介绍了Videoshop，这是一个无需训练的用于本地化语义编辑的视频编辑算法。Videoshop允许用户使用任何编辑软件，包括Photoshop和生成填充，修改第一帧；它会自动将这些更改传播到其余帧，保持语义、空间和时间上的一致运动。与现有方法只能通过不精确的文本指令进行编辑不同，Videoshop允许用户添加或删除对象，语义上更改对象，将素材照片插入视频等，并对位置和外观进行细粒度控制。我们通过对潜在值进行噪声外推反演的图像为基础的视频编辑来实现这一目标，从中我们生成根据编辑图像调整的视频。Videoshop在2个编辑基准测试中使用10个评估指标对6个基线取得了更高质量的编辑效果。

    arXiv:2403.14617v1 Announce Type: cross  Abstract: We introduce Videoshop, a training-free video editing algorithm for localized semantic edits. Videoshop allows users to use any editing software, including Photoshop and generative inpainting, to modify the first frame; it automatically propagates those changes, with semantic, spatial, and temporally consistent motion, to the remaining frames. Unlike existing methods that enable edits only through imprecise textual instructions, Videoshop allows users to add or remove objects, semantically change objects, insert stock photos into videos, etc. with fine-grained control over locations and appearance. We achieve this through image-based video editing by inverting latents with noise extrapolation, from which we generate videos conditioned on the edited image. Videoshop produces higher quality edits against 6 baselines on 2 editing benchmarks using 10 evaluation metrics.
    
[^3]: 面向下一代AI编码助手的设想与提案

    Envisioning the Next-Generation AI Coding Assistants: Insights & Proposals

    [https://arxiv.org/abs/2403.14592](https://arxiv.org/abs/2403.14592)

    AI编码助手应明确使用预期，充分整合IDE功能，使用可扩展的后端设计，负责收集数据，提出开放性问题和挑战

    

    作为一个人工智能软件工程（AI4SE）的研究产品混合组，我们从开发中的经验中提出四个关键的见解。AI编码助手应该明确规定使用预期，与先进的IDE功能和现有扩展集成，使用可扩展的后端设计，并负责收集应用程序数据以便进行下游分析。我们提出学术界和工业界应该解决的开放性问题和挑战，以实现下一代AI编码助手的愿景。

    arXiv:2403.14592v1 Announce Type: cross  Abstract: As a research-product hybrid group in AI for Software Engineering (AI4SE), we present four key takeaways from our experience developing in-IDE AI coding assistants. AI coding assistants should set clear expectations for usage, integrate with advanced IDE capabilities and existing extensions, use extendable backend designs, and collect app data responsibly for downstream analyses. We propose open questions and challenges that academia and industry should address to realize the vision of next-generation AI coding assistants.
    
[^4]: ReAct遇上ActRe：对比性自训练中的代理轨迹自动标注

    ReAct Meets ActRe: Autonomous Annotations of Agent Trajectories for Contrastive Self-Training

    [https://arxiv.org/abs/2403.14589](https://arxiv.org/abs/2403.14589)

    提出了A$^3$T框架，通过ActRe提示代理实现了ReAct风格代理对代理轨迹的自主标注，同时增强了新的轨迹合成能力。

    

    arXiv:2403.14589v1 公告类型：新 文摘：语言代理通过与基础模型推理展示了自主决策能力。最近，人们致力于通过多步推理和行动轨迹作为训练数据来训练语言代理以提高性能。然而，收集这样的轨迹仍需要相当大的人力，无论是通过人工标注还是实施多样化提示框架。在这项工作中，我们提出了A$^3$T，一个允许以ReAct风格自主注释代理轨迹的框架。其中心是一个ActRe提示代理，它解释任意动作的原因。当随机抽取外部动作时，ReAct风格代理可以查询ActRe代理以获取其文本理由。新颖的轨迹然后通过将ActRe的后验推理前置到抽样动作中进行综合合成。通过这种方式，ReAct风格代理可执行

    arXiv:2403.14589v1 Announce Type: new  Abstract: Language agents have demonstrated autonomous decision-making abilities by reasoning with foundation models. Recently, efforts have been made to train language agents for performance improvement, with multi-step reasoning and action trajectories as the training data. However, collecting such trajectories still requires considerable human effort, by either artificial annotations or implementations of diverse prompting frameworks. In this work, we propose A$^3$T, a framework that enables the Autonomous Annotation of Agent Trajectories in the style of ReAct. The central role is an ActRe prompting agent, which explains the reason for an arbitrary action. When randomly sampling an external action, the ReAct-style agent could query the ActRe agent with the action to obtain its textual rationales. Novel trajectories are then synthesized by prepending the posterior reasoning from ActRe to the sampled action. In this way, the ReAct-style agent exe
    
[^5]: 用于医学科目多选题分类的大型语言模型

    Large Language Models for Multi-Choice Question Classification of Medical Subjects

    [https://arxiv.org/abs/2403.14582](https://arxiv.org/abs/2403.14582)

    本文评估了大型语言模型在多选题数据上的训练效果，并利用MQ序列BERT方法，在医学科目分类任务中取得了优于最先进结果的准确率。

    

    本文旨在评估是否可以利用在多选题数据上训练的大型语言模型来区分医学科目。这对于自动问答是一项重要且具有挑战性的任务。为了实现这一目标，我们训练了深度神经网络，用于将问题多类别分类为推断的医学科目。使用我们的多问题(MQ)序列BERT方法，在MedMCQA数据集上表现优于最先进结果，分别在其开发和测试集上具有0.68和0.60的准确率。从这个意义上说，我们展示了人工智能和特别是LLMs在医疗保健领域中用于多分类任务的能力。

    arXiv:2403.14582v1 Announce Type: cross  Abstract: The aim of this paper is to evaluate whether large language models trained on multi-choice question data can be used to discriminate between medical subjects. This is an important and challenging task for automatic question answering. To achieve this goal, we train deep neural networks for multi-class classification of questions into the inferred medical subjects. Using our Multi-Question (MQ) Sequence-BERT method, we outperform the state-of-the-art results on the MedMCQA dataset with an accuracy of 0.68 and 0.60 on their development and test sets, respectively. In this sense, we show the capability of AI and LLMs in particular for multi-classification tasks in the Healthcare domain.
    
[^6]: 一项关于基于概念方法改进模型的调查

    A survey on Concept-based Approaches For Model Improvement

    [https://arxiv.org/abs/2403.14566](https://arxiv.org/abs/2403.14566)

    基于概念方法对深度神经网络进行解释性改进，提供了人类可理解的决策解释，使得检测伪关联和固有偏见成为可能。

    

    最近研究的重点已经从仅仅提高深度神经网络（DNN）在各种任务中的性能转变为使DNN更易解释给人类。可解释人工智能（XAI）领域已经观察到各种技术，包括基于显著性和基于概念的方法。基于概念的方法用所谓的概念在简单的人类可理解术语中解释模型的决策。概念是数据的人类可解释单元，是人类思维的基石。用概念的解释能够检测到伪关联、固有偏见或聪明汉。随着基于概念的解释的出现，出现了各种概念表示方法和自动概念发现算法。一些最近的方法使用概念进行事后模型解缠评估，而其他人使用它们进行事前训练。基于概念的方法是新的，有许多表示方法。

    arXiv:2403.14566v1 Announce Type: new  Abstract: The focus of recent research has shifted from merely increasing the Deep Neural Networks (DNNs) performance in various tasks to DNNs, which are more interpretable to humans. The field of eXplainable Artificial Intelligence (XAI) has observed various techniques, including saliency-based and concept-based approaches. Concept-based approaches explain the model's decisions in simple human understandable terms called Concepts. Concepts are human interpretable units of data and are the thinking ground of humans. Explanations in terms of concepts enable detecting spurious correlations, inherent biases, or clever-hans. With the advent of concept-based explanations, there have been various concept representation methods and automatic concept discovery algorithms. Some recent methods use concepts for post-hoc model disentanglement evaluation, while others use them for ante-hoc training. The concept-based approaches are new, with many representatio
    
[^7]: 语义解码时代

    The Era of Semantic Decoding

    [https://arxiv.org/abs/2403.14562](https://arxiv.org/abs/2403.14562)

    提出了一种名为语义解码的新观点，将LLM、人类输入和各种工具之间的协作过程构建为语义空间中的优化过程，促进了高效输出的构建。

    

    最近的研究展现了在LLM（大型语言模型）、人类输入和各种工具之间编排协作以解决LLM固有局限性的想法具有巨大潜力。我们提出了一个名为语义解码的新观点，将这些协作过程构建为语义空间中的优化过程。具体来说，我们将LLM概念化为操纵我们称之为语义标记（已知思想）的有意义信息片段的语义处理器。LLM是众多其他语义处理器之一，包括人类和工具，比如搜索引擎或代码执行器。语义处理器集体参与语义标记的动态交流，逐步构建高效输出。我们称这些在语义空间中进行优化和搜索的协同作用，为语义解码算法。这个概念与已广为研究的语义解码问题直接平行。

    arXiv:2403.14562v1 Announce Type: cross  Abstract: Recent work demonstrated great promise in the idea of orchestrating collaborations between LLMs, human input, and various tools to address the inherent limitations of LLMs. We propose a novel perspective called semantic decoding, which frames these collaborative processes as optimization procedures in semantic space. Specifically, we conceptualize LLMs as semantic processors that manipulate meaningful pieces of information that we call semantic tokens (known thoughts). LLMs are among a large pool of other semantic processors, including humans and tools, such as search engines or code executors. Collectively, semantic processors engage in dynamic exchanges of semantic tokens to progressively construct high-utility outputs. We refer to these orchestrated interactions among semantic processors, optimizing and searching in semantic space, as semantic decoding algorithms. This concept draws a direct parallel to the well-studied problem of s
    
[^8]: 词汇级对比视觉基础改进语言建模

    Lexicon-Level Contrastive Visual-Grounding Improves Language Modeling

    [https://arxiv.org/abs/2403.14551](https://arxiv.org/abs/2403.14551)

    这项研究介绍了LexiContrastive Grounding (LCG)，它结合了视觉监督和文本表示改进策略，在多个单词学习和句子理解基准测试中表现出比标准语言模型更高的学习效率和进步。

    

    今天最准确的语言模型是在比人类语言学习者接收到的语言数据量多得多的情况下训练的，但并没有来自在人类学习中起关键作用的其他感官模式的监督。本文描述了LexiContrastive Grounding (LCG)，一种利用视觉监督来改进文本表征的基于地面语言学习程序。LexiContrastive Grounding将下一个标记预测策略与对比视觉基础目标结合起来，重点放在编码词汇信息的早期层表示上。在多个单词学习和句子理解基准测试中，LexiContrastive Grounding不仅在学习效率上优于标准语言模型，而且在视觉与语言学习程序方面取得了进步。

    arXiv:2403.14551v1 Announce Type: cross  Abstract: Today's most accurate language models are trained on orders of magnitude more language data than human language learners receive - but with no supervision from other sensory modalities that play a crucial role in human learning. Can we make LMs' representations and predictions more accurate (and more human-like) with more ecologically plausible supervision? This paper describes LexiContrastive Grounding (LCG), a grounded language learning procedure that leverages visual supervision to improve textual representations. LexiContrastive Grounding combines a next token prediction strategy with a contrastive visual grounding objective, focusing on early-layer representations that encode lexical information. Across multiple word-learning and sentence-understanding benchmarks, LexiContrastive Grounding not only outperforms standard language-only models in learning efficiency, but also improves upon vision-and-language learning procedures inclu
    
[^9]: 人机交互中的动态解释强调与交流机器人

    Dynamic Explanation Emphasis in Human-XAI Interaction with Communication Robot

    [https://arxiv.org/abs/2403.14550](https://arxiv.org/abs/2403.14550)

    提出了一种名为DynEmph的方法，用于通信机器人决定在哪些地方用物理表达强调 XAI 生成的解释，并且通过一种数据驱动的策略来决定强调的位置。

    

    通信机器人有望成为有效的人机交互界面，超越文本或图形解释的潜力。它们的一大优势在于可以使用物理和语音表达来对解释添加详细的细微之处。然而，并不清楚机器人如何应用这些表达，特别是如何能够开发一种策略，根据任务和用户在动态交互中自适应地使用这些表达。为了回答这个问题，本文提出了一种名为DynEmph的方法，用于通信机器人决定在哪些地方用物理表达强调XAI生成的解释。它预测了强调某些观点对用户的影响，并旨在最小化预期用户决策与AI建议之间的差异。DynEmph采用一种基于数据驱动的策略来决定在哪里进行强调，解放工程师不再需要手动进行设计。

    arXiv:2403.14550v1 Announce Type: cross  Abstract: Communication robots have the potential to contribute to effective human-XAI interaction as an interface that goes beyond textual or graphical explanations. One of their strengths is that they can use physical and vocal expressions to add detailed nuances to explanations. However, it is not clear how a robot can apply such expressions, or in particular, how we can develop a strategy to adaptively use such expressions depending on the task and user in dynamic interactions. To address this question, this paper proposes DynEmph, a method for a communication robot to decide where to emphasize XAI-generated explanations with physical expressions. It predicts the effect of emphasizing certain points on a user and aims to minimize the expected difference between predicted user decisions and AI-suggested ones. DynEmph features a strategy for deciding where to emphasize in a data-driven manner, relieving engineers from the need to manually desi
    
[^10]: Object-Centric Domain Randomization用于野外3D形状重建

    Object-Centric Domain Randomization for 3D Shape Reconstruction in the Wild

    [https://arxiv.org/abs/2403.14539](https://arxiv.org/abs/2403.14539)

    提出了ObjectDR，利用对象-centric的域随机化合成单视图3D形状重建中缺乏的配对数据，通过条件生成模型和解耦框架来生成和保留对象轮廓以及广泛变化的数据，从而为培训模型捕捉域不变性几何形状。

    

    单视图3D形状在野外的重建面临的最大挑战之一是来自真实环境中的<3D形状，2D图像>-配对数据的稀缺性。受域随机化引人注目的成就的启发，我们提出了ObjectDR，通过对对象外观和背景的视觉变化进行随机仿真，合成这种配对数据。我们的数据合成框架利用条件生成模型（例如ControlNet）生成符合空间条件（例如2.5D草图）的图像，这些条件可以通过从对象集合（例如Objaverse-XL）的渲染过程获得3D形状。为了模拟多样化的变化同时保留嵌入空间条件中的对象轮廓，我们还引入了一个利用初始对象指导的解耦框架。

    arXiv:2403.14539v1 Announce Type: cross  Abstract: One of the biggest challenges in single-view 3D shape reconstruction in the wild is the scarcity of <3D shape, 2D image>-paired data from real-world environments. Inspired by remarkable achievements via domain randomization, we propose ObjectDR which synthesizes such paired data via a random simulation of visual variations in object appearances and backgrounds. Our data synthesis framework exploits a conditional generative model (e.g., ControlNet) to generate images conforming to spatial conditions such as 2.5D sketches, which are obtainable through a rendering process of 3D shapes from object collections (e.g., Objaverse-XL). To simulate diverse variations while preserving object silhouettes embedded in spatial conditions, we also introduce a disentangled framework which leverages an initial object guidance. After synthesizing a wide range of data, we pre-train a model on them so that it learns to capture a domain-invariant geometry p
    
[^11]: 点击抓取: 通过视觉扩散描述进行零样本精确操作

    Click to Grasp: Zero-Shot Precise Manipulation via Visual Diffusion Descriptors

    [https://arxiv.org/abs/2403.14526](https://arxiv.org/abs/2403.14526)

    通过利用 web 训练文本到图像扩散生成模型，在零样本情况下利用细粒度部件描述符进行精确操作，通过点击源图像不同实例的引用，返回夹具姿势，实现了机器人精确操控。

    

    精确操控在机器人领域一直是一个持久的挑战，特别是在能够在不同场景和不同物体之间泛化的情况下。我们的工作通过利用基于网络训练的文本到图像扩散生成模型，探索了在零样本情况下将细粒度部件描述符用于精确操控领域。我们将问题框定为密集语义部件对应任务，模型通过参考源图像中与目标物体不同实例的点击，返回一个用于操控特定部件的夹具姿势。我们不需要手动抓取示范，因为我们利用了固有的物体几何和特征。在真实世界桌面情境中的实用实验验证了我们方法的有效性。

    arXiv:2403.14526v1 Announce Type: cross  Abstract: Precise manipulation that is generalizable across scenes and objects remains a persistent challenge in robotics. Current approaches for this task heavily depend on having a significant number of training instances to handle objects with pronounced visual and/or geometric part ambiguities. Our work explores the grounding of fine-grained part descriptors for precise manipulation in a zero-shot setting by utilizing web-trained text-to-image diffusion-based generative models. We tackle the problem by framing it as a dense semantic part correspondence task. Our model returns a gripper pose for manipulating a specific part, using as reference a user-defined click from a source image of a visually different instance of the same object. We require no manual grasping demonstrations as we leverage the intrinsic object geometry and features. Practical experiments in a real-world tabletop scenario validate the efficacy of our approach, demonstrati
    
[^12]: 带有平滑对数障碍函数的约束加强学习

    Constrained Reinforcement Learning with Smoothed Log Barrier Function

    [https://arxiv.org/abs/2403.14508](https://arxiv.org/abs/2403.14508)

    提出了一种新的约束强化学习方法CSAC-LB，通过应用线性平滑对数障碍函数，实现了竞争性能，无需任何预训练

    

    强化学习（RL）已广泛应用于许多控制任务，并在许多领域的性能上与传统控制方法相比有了显著提高，其中奖励函数是很好定义的。然而，对于许多现实世界的问题，以奖励和约束同时制定优化问题通常更为方便。通过奖励塑造来优化这些受限问题可能会很困难，因为需要对带有几个交互项的奖励函数进行繁琐的手动调整。最近包含约束的公式在多数情况下需要预训练阶段，这通常需要人类专业知识来收集数据或假定有一个待用的次优策略。我们提出了一种名为CSAC-LB（带有对数障碍函数的约束软演员-评论家）的新型约束RL方法，通过应用线性平滑对数障碍函数，该方法实现了竞争性能，而不需要任何预训练。

    arXiv:2403.14508v1 Announce Type: cross  Abstract: Reinforcement Learning (RL) has been widely applied to many control tasks and substantially improved the performances compared to conventional control methods in many domains where the reward function is well defined. However, for many real-world problems, it is often more convenient to formulate optimization problems in terms of rewards and constraints simultaneously. Optimizing such constrained problems via reward shaping can be difficult as it requires tedious manual tuning of reward functions with several interacting terms. Recent formulations which include constraints mostly require a pre-training phase, which often needs human expertise to collect data or assumes having a sub-optimal policy readily available. We propose a new constrained RL method called CSAC-LB (Constrained Soft Actor-Critic with Log Barrier Function), which achieves competitive performance without any pre-training by applying a linear smoothed log barrier funct
    
[^13]: 软学习概率电路

    Soft Learning Probabilistic Circuits

    [https://arxiv.org/abs/2403.14504](https://arxiv.org/abs/2403.14504)

    该论文提出了一种新的学习过程 SoftLearn，通过软聚类过程诱导出一个 PC，相较于传统的 LearnSPN，在许多情况下表现更好，产生更好的似然值和样本。

    

    概率电路（PCs)是杰出的可计算概率模型，允许进行一系列准确推理。该论文专注于主要的 PC 训练算法 LearnSPN，由于其效率、性能和易用性而成为金标准，特别适用于表格数据。我们表明在温和假设下，LearnSPN 是一种贪心似然最大化器。虽然在 PC 中，推理可以利用整个电路结构来处理查询，但 LearnSPN 应用了一种硬方法来学习它们，通过在每个求和节点上通过一个而仅一个子/边的数据点进行传播，就像在一个硬聚类过程中一样。我们提出了一种名为 SoftLearn 的新学习程序，它通过软聚类过程诱导出一个 PC。我们调查了这种学习-推理兼容性在 PC 中的影响。我们的实验表明，SoftLearn 在许多情况下优于 LearnSPN，产生更好的似然值，可能还产生更好的样本。

    arXiv:2403.14504v1 Announce Type: cross  Abstract: Probabilistic Circuits (PCs) are prominent tractable probabilistic models, allowing for a range of exact inferences. This paper focuses on the main algorithm for training PCs, LearnSPN, a gold standard due to its efficiency, performance, and ease of use, in particular for tabular data. We show that LearnSPN is a greedy likelihood maximizer under mild assumptions. While inferences in PCs may use the entire circuit structure for processing queries, LearnSPN applies a hard method for learning them, propagating at each sum node a data point through one and only one of the children/edges as in a hard clustering process. We propose a new learning procedure named SoftLearn, that induces a PC using a soft clustering process. We investigate the effect of this learning-inference compatibility in PCs. Our experiments show that SoftLearn outperforms LearnSPN in many situations, yielding better likelihoods and arguably better samples. We also analy
    
[^14]: 人类中心的可解释人工智能界面的设计与评估：一项系统调查

    How Human-Centered Explainable AI Interface Are Designed and Evaluated: A Systematic Survey

    [https://arxiv.org/abs/2403.14496](https://arxiv.org/abs/2403.14496)

    本研究是对人类与可解释人工智能交互的现状和可解释界面设计方向的系统调查。

    

    尽管在技术上取得了突破，但可解释人工智能（XAI）研究在为用户提供所需的“有效解释”方面取得的成功有限。为了提高XAI系统对真实用户的可用性、实际可解释性和效力，新兴领域“可解释界面”（EIs）专注于XAI的用户界面和用户体验设计方面。本文通过系统调查53篇出版物，旨在识别当前人-XAI互动的趋势以及EI设计和发展的有望方向。这是对EI研究的首次系统调查。

    arXiv:2403.14496v1 Announce Type: cross  Abstract: Despite its technological breakthroughs, eXplainable Artificial Intelligence (XAI) research has limited success in producing the {\em effective explanations} needed by users. In order to improve XAI systems' usability, practical interpretability, and efficacy for real users, the emerging area of {\em Explainable Interfaces} (EIs) focuses on the user interface and user experience design aspects of XAI. This paper presents a systematic survey of 53 publications to identify current trends in human-XAI interaction and promising directions for EI design and development. This is among the first systematic survey of EI research.
    
[^15]: 学习投影以进行跨任务知识蒸馏

    Learning to Project for Cross-Task Knowledge Distillation

    [https://arxiv.org/abs/2403.14494](https://arxiv.org/abs/2403.14494)

    提出了一种通过学习投影，以有效地将传统知识蒸馏方法应用于跨任务设置的方法，取得了显著的性能提升

    

    传统知识蒸馏(KD)依赖于在目标任务上训练过的熟练教师，而这并不总是可用的。在这种情况下，可以使用跨任务蒸馏，使得可以利用在不同任务上训练过的任何教师模型。然而，许多知识蒸馏方法在应用于这种跨任务设置时被证明是无效的。为了解决这一限制，我们提出了一个简单的修改：使用反向投影。我们展示了这种对标准投影的插入式替代是有效的，通过学习排除可能降低学生表现的任何任务特定特征。我们发现，这个简单的修改足以将许多知识蒸馏方法扩展到跨任务设置，其中教师和学生任务可能非常不同。这样一来，在跨任务设置中，我们相比于传统投影，可获得最高1.9%的改进，而无需额外成本。我们的方法可以获得显著的性能提升

    arXiv:2403.14494v1 Announce Type: cross  Abstract: Traditional knowledge distillation (KD) relies on a proficient teacher trained on the target task, which is not always available. In this setting, cross-task distillation can be used, enabling the use of any teacher model trained on a different task. However, many KD methods prove ineffective when applied to this cross-task setting. To address this limitation, we propose a simple modification: the use of an inverted projection. We show that this drop-in replacement for a standard projector is effective by learning to disregard any task-specific features which might degrade the student's performance. We find that this simple modification is sufficient for extending many KD methods to the cross-task setting, where the teacher and student tasks can be very different. In doing so, we obtain up to a 1.9% improvement in the cross-task setting compared to the traditional projection, at no additional cost. Our method can obtain significant per
    
[^16]: 基于物理学因果推理的机器人操作任务中安全稳健的下一最佳动作选择

    Physics-Based Causal Reasoning for Safe & Robust Next-Best Action Selection in Robot Manipulation Tasks

    [https://arxiv.org/abs/2403.14488](https://arxiv.org/abs/2403.14488)

    该论文提出了一个基于物理因果推理的框架，用于机器人在部分可观察的环境中进行概率推理，成功预测积木塔稳定性并选择下一最佳动作。

    

    安全高效的物体操作是许多真实世界机器人应用的关键推手。然而，这种挑战在于机器人操作必须对一系列传感器和执行器的不确定性具有稳健性。本文提出了一个基于物理知识和因果推理的框架，用于让机器人在部分可观察的环境中对候选动作进行概率推理，以完成一个积木堆叠任务。我们将刚体系统动力学的基于物理学的仿真与因果贝叶斯网络（CBN）结合起来，定义了机器人决策过程的因果生成概率模型。通过基于仿真的蒙特卡洛实验，我们展示了我们的框架成功地能够：(1) 高准确度地预测积木塔的稳定性（预测准确率：88.6%）；和，(2) 为积木堆叠任务选择一个近似的下一最佳动作，供整合的机器人系统执行，实现94.2%的任务成功率。

    arXiv:2403.14488v1 Announce Type: cross  Abstract: Safe and efficient object manipulation is a key enabler of many real-world robot applications. However, this is challenging because robot operation must be robust to a range of sensor and actuator uncertainties. In this paper, we present a physics-informed causal-inference-based framework for a robot to probabilistically reason about candidate actions in a block stacking task in a partially observable setting. We integrate a physics-based simulation of the rigid-body system dynamics with a causal Bayesian network (CBN) formulation to define a causal generative probabilistic model of the robot decision-making process. Using simulation-based Monte Carlo experiments, we demonstrate our framework's ability to successfully: (1) predict block tower stability with high accuracy (Pred Acc: 88.6%); and, (2) select an approximate next-best action for the block stacking task, for execution by an integrated robot system, achieving 94.2% task succe
    
[^17]: HyperGALE: 通过学习超边的超图门控注意力进行ASD分类

    HyperGALE: ASD Classification via Hypergraph Gated Attention with Learnable Hyperedges

    [https://arxiv.org/abs/2403.14484](https://arxiv.org/abs/2403.14484)

    HyperGALE通过学习超边的超图门控注意力机制，在解释复杂的脑图数据方面取得显著改进，为ASD生物标志特征化提供更深入见解。

    

    自闭症谱系障碍（ASD）是一种神经发育障碍，其特征是各种社交认知挑战和重复行为模式。由于谱系的症状多样性，为ASD识别可靠的基于脑成像的生物标志一直是一个持久的挑战。该领域现有的基线已经在这个方向上取得了重要进展，但在性能和可解释性方面仍有改进空间。我们提出了\emph {HyperGALE}，它基于超图，结合了学习的超边和门控注意力机制。这种方法大大提高了模型解释复杂脑图数据的能力，为ASD生物标志特征化提供了更深入的见解。在广泛的ABIDE II数据集上进行评估，\emph {HyperGALE}不仅提高了可解释性，还在关键性能指标上表现出显著的增强

    arXiv:2403.14484v1 Announce Type: cross  Abstract: Autism Spectrum Disorder (ASD) is a neurodevelopmental condition characterized by varied social cognitive challenges and repetitive behavioral patterns. Identifying reliable brain imaging-based biomarkers for ASD has been a persistent challenge due to the spectrum's diverse symptomatology. Existing baselines in the field have made significant strides in this direction, yet there remains room for improvement in both performance and interpretability. We propose \emph{HyperGALE}, which builds upon the hypergraph by incorporating learned hyperedges and gated attention mechanisms. This approach has led to substantial improvements in the model's ability to interpret complex brain graph data, offering deeper insights into ASD biomarker characterization. Evaluated on the extensive ABIDE II dataset, \emph{HyperGALE} not only improves interpretability but also demonstrates statistically significant enhancements in key performance metrics compare
    
[^18]: 使用LightGBM算法进行运营商用户信用评估研究

    Utilizing the LightGBM Algorithm for Operator User Credit Assessment Research

    [https://arxiv.org/abs/2403.14483](https://arxiv.org/abs/2403.14483)

    该研究利用LightGBM算法对运营商用户信用评估模型进行研究，通过提取关键特征并进行数据预处理和特征工程，以改善用户信用评估策略。

    

    移动互联网用户信用评估是通信运营商制定决策和措施的重要方式，也是运营商获得预期收益的保障。本文利用通信运营商提供的海量数据，基于融合LightGBM算法进行运营商用户信用评估模型研究。

    arXiv:2403.14483v1 Announce Type: cross  Abstract: Mobile Internet user credit assessment is an important way for communication operators to establish decisions and formulate measures, and it is also a guarantee for operators to obtain expected benefits. However, credit evaluation methods have long been monopolized by financial industries such as banks and credit. As supporters and providers of platform network technology and network resources, communication operators are also builders and maintainers of communication networks. Internet data improves the user's credit evaluation strategy. This paper uses the massive data provided by communication operators to carry out research on the operator's user credit evaluation model based on the fusion LightGBM algorithm. First, for the massive data related to user evaluation provided by operators, key features are extracted by data preprocessing and feature engineering methods, and a multi-dimensional feature set with statistical significance 
    
[^19]: 通过知识编辑实现对大型语言模型的去毒化

    Detoxifying Large Language Models via Knowledge Editing

    [https://arxiv.org/abs/2403.14472](https://arxiv.org/abs/2403.14472)

    本文研究了使用知识编辑技术对大型语言模型进行去毒化，在构建了SafeEdit基准的基础上，提出了一种简单而有效的方法 DINM，可以通过少量调整步骤减少模型的毒性，同时对各种去毒方法的内部机制进行了深入分析。

    

    本文研究了使用知识编辑技术来对大型语言模型（LLMs）进行去毒化。我们构建了一个名为SafeEdit的基准，涵盖了九种不安全类别，具有各种强大的攻击提示，并配备了全面的度量标准进行系统评估。我们进行了实验，比较了知识编辑方法与之前的基准线，结果表明知识编辑有潜力在对LLMs进行去毒化时，在对一般性能的影响相对有限。然后，我们提出了一个简单但有效的基准线，称为通过术中神经监测去毒化（DINM），通过仅一次实例的少量调整步骤减少LLMs的毒性。我们进一步对各种去毒方法的内部机制进行了深入分析，表明先前的方法如SFT和DPO可能仅抑制有毒参数的激活，而DINM则减轻有毒参数的毒性。

    arXiv:2403.14472v1 Announce Type: cross  Abstract: This paper investigates using knowledge editing techniques to detoxify Large Language Models (LLMs). We construct a benchmark, SafeEdit, which covers nine unsafe categories with various powerful attack prompts and equips comprehensive metrics for systematic evaluation. We conduct experiments to compare knowledge editing approaches with previous baselines, indicating that knowledge editing has the potential to efficiently detoxify LLMs with limited impact on general performance. Then, we propose a simple yet effective baseline, dubbed Detoxifying with Intraoperative Neural Monitoring (DINM), to diminish the toxicity of LLMs within a few tuning steps via only one instance. We further provide an in-depth analysis of the internal mechanism for various detoxify approaches, demonstrating that previous methods like SFT and DPO may merely suppress the activations of toxic parameters, while DINM mitigates the toxicity of the toxic parameters to
    
[^20]: ChatGPT备选方案：大语言模型调查

    ChatGPT Alternative Solutions: Large Language Models Survey

    [https://arxiv.org/abs/2403.14469](https://arxiv.org/abs/2403.14469)

    大语言模型在多个领域展现出强大能力，ChatGPT是一个基于LLMs的强大AI聊天机器人，在学术界和工业界的合作推动下，LLM研究领域不断取得新突破，预示着人工智能社区将迎来革命性变革。

    

    在最近的时代，大语言模型（LLMs）的壮丽不仅闪耀在自然语言处理领域，而且也将其光辉洒向广泛的应用领域。这种对LLM能力的显著展示引发了该领域内研究贡献的激增，涵盖了各种主题的多样化光谱。这些贡献涵盖了神经网络架构的进步、上下文长度的增强、模型对齐、训练数据集、基准测试、效率改进等。近年来，学术界和工业界之间形成了动态的协同关系，推动了LLM研究领域向新高度迈进。这一旅程中的一个值得注意的里程碑是ChatGPT的推出，这是一个基于LLMs的强大人工智能聊天机器人，引起了广泛的社会关注。LLMs的不断发展技术已经开始重塑整个人工智能社区的格局，承诺进行革命性的转变。

    arXiv:2403.14469v1 Announce Type: cross  Abstract: In recent times, the grandeur of Large Language Models (LLMs) has not only shone in the realm of natural language processing but has also cast its brilliance across a vast array of applications. This remarkable display of LLM capabilities has ignited a surge in research contributions within this domain, spanning a diverse spectrum of topics. These contributions encompass advancements in neural network architecture, context length enhancements, model alignment, training datasets, benchmarking, efficiency improvements, and more. Recent years have witnessed a dynamic synergy between academia and industry, propelling the field of LLM research to new heights. A notable milestone in this journey is the introduction of ChatGPT, a powerful AI chatbot grounded in LLMs, which has garnered widespread societal attention. The evolving technology of LLMs has begun to reshape the landscape of the entire AI community, promising a revolutionary shift i
    
[^21]: AnyV2V：一种适用于任何视频到视频编辑任务的即插即用框架

    AnyV2V: A Plug-and-Play Framework For Any Video-to-Video Editing Tasks

    [https://arxiv.org/abs/2403.14468](https://arxiv.org/abs/2403.14468)

    AnyV2V是一种适用于任何视频到视频编辑任务的即插即用框架，通过两个主要步骤简化视频编辑，支持广泛的视频编辑任务，并能够处理传统和新颖的编辑需求。

    

    arXiv:2403.14468v1 公告类型: 跨越 摘要: 视频到视频编辑涉及编辑源视频以及额外的控制（例如文本提示、主题或风格），以生成与源视频和提供的控制相匹配的新视频。传统方法受限于特定的编辑类型，限制了它们满足广泛用户需求的能力。在本文中，我们介绍了AnyV2V，这是一种新颖的免训练框架，旨在将视频编辑简化为两个主要步骤：（1）利用现成的图像编辑模型（例如InstructPix2Pix、InstantID等）修改第一帧，（2）利用现有的图像到视频生成模型（例如I2VGen-XL）进行DDIM逆转和特征注入。在第一阶段，AnyV2V可以插入任何现有的图像编辑工具，以支持广泛的视频编辑任务。除了传统的基于提示的编辑方法，AnyV2V还可以支持新颖的视频编辑任务，包括参考

    arXiv:2403.14468v1 Announce Type: cross  Abstract: Video-to-video editing involves editing a source video along with additional control (such as text prompts, subjects, or styles) to generate a new video that aligns with the source video and the provided control. Traditional methods have been constrained to certain editing types, limiting their ability to meet the wide range of user demands. In this paper, we introduce AnyV2V, a novel training-free framework designed to simplify video editing into two primary steps: (1) employing an off-the-shelf image editing model (e.g. InstructPix2Pix, InstantID, etc) to modify the first frame, (2) utilizing an existing image-to-video generation model (e.g. I2VGen-XL) for DDIM inversion and feature injection. In the first stage, AnyV2V can plug in any existing image editing tools to support an extensive array of video editing tasks. Beyond the traditional prompt-based editing methods, AnyV2V also can support novel video editing tasks, including refe
    
[^22]: 实现软件定义车辆中的单一系统错觉 -- 自动化、人工智能驱动的工作流程

    Towards Single-System Illusion in Software-Defined Vehicles -- Automated, AI-Powered Workflow

    [https://arxiv.org/abs/2403.14460](https://arxiv.org/abs/2403.14460)

    提出了一种基于模型和特征的新方法，通过迭代搜索和优化的过程中出现最终架构，同时保持单一系统错觉特性，并将现代生成式人工智能引入其中，从而实现对车辆软件系统的自动化开发。

    

    我们提出了一种基于模型和特征的新颖方法来开发车辆软件系统，其中最终架构并未明确定义。相反，它是从一系列搜索和优化的迭代过程中出现的，有特定的约束、需求和硬件架构，同时保持单一系统错觉的特性，其中应用在逻辑上统一的环境中运行。所提出的方法的一个关键点是在循环中包含现代生成式人工智能，特别是大型语言模型（LLMs）。随着该领域的最新进展，我们期望LLMs能够辅助处理需求、生成形式系统模型，以及生成软件部署规范和测试代码。结果管道在很大程度上是自动化的，每一步都会生成反馈。

    arXiv:2403.14460v1 Announce Type: cross  Abstract: We propose a novel model- and feature-based approach to development of vehicle software systems, where the end architecture is not explicitly defined. Instead, it emerges from an iterative process of search and optimization given certain constraints, requirements and hardware architecture, while retaining the property of single-system illusion, where applications run in a logically uniform environment. One of the key points of the presented approach is the inclusion of modern generative AI, specifically Large Language Models (LLMs), in the loop. With the recent advances in the field, we expect that the LLMs will be able to assist in processing of requirements, generation of formal system models, as well as generation of software deployment specification and test code. The resulting pipeline is automated to a large extent, with feedback being generated at each step.
    
[^23]: 生成式语言模型的多级解释

    Multi-Level Explanations for Generative Language Models

    [https://arxiv.org/abs/2403.14459](https://arxiv.org/abs/2403.14459)

    本文提出了一个名为MExGen的通用框架，通过引入标量化概念和多级方法处理生成式语言模型的挑战，证明可以提供更贴近本地的解释。

    

    基于扰动的解释方法，如LIME和SHAP，通常应用于文本分类。本文关注它们如何扩展到生成式语言模型。为了解决文本作为输出和长文本输入的挑战，我们提出了一个名为MExGen的通用框架，可以用不同的归因算法实例化。为了处理文本输出，我们引入了将文本映射到实数的标量化概念，并探讨了多种可能性。为了处理长输入，我们采用多级方法，从粗粒度到细粒度，重点关注具有模型查询线性缩放的算法。我们对基于扰动的归因方法进行了系统评估，包括自动化和人工评估，用于摘要和基于上下文的问答。结果表明，我们的框架可以提供更加贴近本地的生成式输出解释。

    arXiv:2403.14459v1 Announce Type: cross  Abstract: Perturbation-based explanation methods such as LIME and SHAP are commonly applied to text classification. This work focuses on their extension to generative language models. To address the challenges of text as output and long text inputs, we propose a general framework called MExGen that can be instantiated with different attribution algorithms. To handle text output, we introduce the notion of scalarizers for mapping text to real numbers and investigate multiple possibilities. To handle long inputs, we take a multi-level approach, proceeding from coarser levels of granularity to finer ones, and focus on algorithms with linear scaling in model queries. We conduct a systematic evaluation, both automated and human, of perturbation-based attribution methods for summarization and context-grounded question answering. The results show that our framework can provide more locally faithful explanations of generated outputs.
    
[^24]: 语言模型可以降低信息市场的不对称性

    Language Models Can Reduce Asymmetry in Information Markets

    [https://arxiv.org/abs/2403.14443](https://arxiv.org/abs/2403.14443)

    语言模型驱动的智能代理在模拟数字市场中完成买卖信息的任务，通过具备评估信息质量和遗忘能力的特点，成功降低了信息市场的买方检查悖论。

    

    这项工作解决了信息市场中买方检查悖论的问题。买方需要获取信息来确定其价值，而卖方需要限制访问以防止盗窃。为了研究这一问题，我们引入一个开源的模拟数字市场，其中由语言模型驱动的智能代理代表外部参与者买卖信息。这个市场的核心机制在于代理人的双重能力：他们不仅能够评估特权信息的质量，还具备遗忘的能力。这种诱导健忘的能力使供应商可以授予临时访问专有信息的权限，显著降低未经授权的保留风险，同时使代理人能够准确评估信息对特定查询或任务的相关性。为了表现优异，代理必须做出理性决策，战略性地探索市场。

    arXiv:2403.14443v1 Announce Type: new  Abstract: This work addresses the buyer's inspection paradox for information markets. The paradox is that buyers need to access information to determine its value, while sellers need to limit access to prevent theft. To study this, we introduce an open-source simulated digital marketplace where intelligent agents, powered by language models, buy and sell information on behalf of external participants. The central mechanism enabling this marketplace is the agents' dual capabilities: they not only have the capacity to assess the quality of privileged information but also come equipped with the ability to forget. This ability to induce amnesia allows vendors to grant temporary access to proprietary information, significantly reducing the risk of unauthorized retention while enabling agents to accurately gauge the information's relevance to specific queries or tasks. To perform well, agents must make rational decisions, strategically explore the marke
    
[^25]: 偏向性的二进制属性分类器忽视了主要类别

    Biased Binary Attribute Classifiers Ignore the Majority Classes

    [https://arxiv.org/abs/2403.14435](https://arxiv.org/abs/2403.14435)

    本文将梯度基础的CAM技术扩展到二元分类器，并可视化二进制面部属性分类器的活动区域，证实在不平衡数据集上训练时偏向性分类器倾向于学习提取主要类别的特征

    

    为了可视化分类器基于其决策的兴趣区域，发展了不同的Class Activation Mapping (CAM)方法。然而，所有这些技术只针对分类分类器，而大多数实际任务是二元分类。本文将基于梯度的CAM技术扩展到与二进制分类器一起使用，并可视化二进制面部属性分类器的活动区域。当在不平衡的数据集上训练不平衡的二元分类器时，众所周知，即具有许多训练样本的主要类通常比具有少量训练实例的次要类预测得更好。在CelebA数据集上的实验中，我们验证了这些结果，当训练不平衡分类器同时提取40个面部属性。人们预期，偏向性分类器已经学会主要为多数类提取特征

    arXiv:2403.14435v1 Announce Type: cross  Abstract: To visualize the regions of interest that classifiers base their decisions on, different Class Activation Mapping (CAM) methods have been developed. However, all of these techniques target categorical classifiers only, though most real-world tasks are binary classification. In this paper, we extend gradient-based CAM techniques to work with binary classifiers and visualize the active regions for binary facial attribute classifiers. When training an unbalanced binary classifier on an imbalanced dataset, it is well-known that the majority class, i.e. the class with many training samples, is mostly predicted much better than minority class with few training instances. In our experiments on the CelebA dataset, we verify these results, when training an unbalanced classifier to extract 40 facial attributes simultaneously. One would expect that the biased classifier has learned to extract features mainly for the majority classes and that the 
    
[^26]: 强化学习和最优控制中价值函数的连续性和光滑性

    On the continuity and smoothness of the value function in reinforcement learning and optimal control

    [https://arxiv.org/abs/2403.14432](https://arxiv.org/abs/2403.14432)

    研究了强化学习和最优控制中价值函数的连续性和光滑性，提供了关于价值函数连续性的上界，并表明在对底层系统进行相对较弱的假设下，价值函数始终具有H\"older连续性。

    

    价值函数在强化学习和最优控制中扮演着重要角色，作为衡量智能体未来累积奖励的手段。因此，研究邻近状态值的相似性，即价值函数的连续性，具有重要意义。我们通过确定和验证价值函数的标准连续性上界，来探讨这一问题。此外，我们展示了在对底层系统进行相对较弱的假设下，价值函数始终是H\"older连续的，非可微的价值函数可以通过轻微地“扰动”系统而变得可微。

    arXiv:2403.14432v1 Announce Type: cross  Abstract: The value function plays a crucial role as a measure for the cumulative future reward an agent receives in both reinforcement learning and optimal control. It is therefore of interest to study how similar the values of neighboring states are, i.e., to investigate the continuity of the value function. We do so by providing and verifying upper bounds on the value function's modulus of continuity. Additionally, we show that the value function is always H\"older continuous under relatively weak assumptions on the underlying system and that non-differentiable value functions can be made differentiable by slightly "disturbing" the system.
    
[^27]: 风格提取扩散模型用于半监督组织学分割

    Style-Extracting Diffusion Models for Semi-Supervised Histopathology Segmentation

    [https://arxiv.org/abs/2403.14429](https://arxiv.org/abs/2403.14429)

    提出了风格提取扩散模型，利用风格调节机制和内容调节机制，实现了在图像生成过程中注入未见图像风格信息，从而以零-shot方式生成具有未见风格的图像。

    

    arXiv:2403.14429v1 公告类型:跨领域 摘要:基于深度学习的图像生成在扩散模型的显着进展下取得了重要进展，明显改善了生成图像的质量。尽管取得了这些进展，但生成具有对下游任务有益的未见特征的图像却受到了较少关注。为了弥补这一差距，我们提出了风格提取扩散模型，其中包含两种调节机制。具体来说，我们利用1)风格调制机制在图像生成过程中注入先前未见图像的风格信息，2)内容调制机制可以针对下游任务进行定位，例如布局用于分割。我们引入了可训练的风格编码器，从图像中提取风格信息，并引入了一个聚合块，用于合并来自多个风格输入的风格信息。这种架构使得通过利用来自未见图像的风格，在零-shot方式下生成具有未见风格的图像成为可能。

    arXiv:2403.14429v1 Announce Type: cross  Abstract: Deep learning-based image generation has seen significant advancements with diffusion models, notably improving the quality of generated images. Despite these developments, generating images with unseen characteristics beneficial for downstream tasks has received limited attention. To bridge this gap, we propose Style-Extracting Diffusion Models, featuring two conditioning mechanisms. Specifically, we utilize 1) a style conditioning mechanism which allows to inject style information of previously unseen images during image generation and 2) a content conditioning which can be targeted to a downstream task, e.g., layout for segmentation. We introduce a trainable style encoder to extract style information from images, and an aggregation block that merges style information from multiple style inputs. This architecture enables the generation of images with unseen styles in a zero-shot manner, by leveraging styles from unseen images, result
    
[^28]: GLC++: 全局局部聚类和对比关联学习的无源通用域自适应

    GLC++: Source-Free Universal Domain Adaptation through Global-Local Clustering and Contrastive Affinity Learning

    [https://arxiv.org/abs/2403.14410](https://arxiv.org/abs/2403.14410)

    该论文提出了GLC++方法，通过全局和局部聚类以及对比关联学习实现了无源通用域自适应，能够准确分类已知数据并将其从未知数据中分离。

    

    深度神经网络经常在协变量和类别转移下表现出次优性能。无源域自适应（SFDA）为这一困境提供了一个有希望的解决方案，然而大多数SFDA方法局限于封闭集场景。在本文中，我们探讨了旨在准确分类属于常见类别的“已知”数据并将其与目标专有“未知”数据隔离开来的无源通用域自适应（SF-UniDA）。我们提出了一种新颖的全球和局部聚类（GLC）技术，其中包括自适应的一对全局聚类算法来区分目标类别，辅以本地k-NN聚类策略以减轻负面转移。尽管有效，但固有的封闭源架构导致对“未知”数据的统一处理，阻碍了对不同“未知”类别的识别。为了解决这个问题，我们将GLC发展到GLC++，整合了对比亲和性。

    arXiv:2403.14410v1 Announce Type: cross  Abstract: Deep neural networks often exhibit sub-optimal performance under covariate and category shifts. Source-Free Domain Adaptation (SFDA) presents a promising solution to this dilemma, yet most SFDA approaches are restricted to closed-set scenarios. In this paper, we explore Source-Free Universal Domain Adaptation (SF-UniDA) aiming to accurately classify "known" data belonging to common categories and segregate them from target-private "unknown" data. We propose a novel Global and Local Clustering (GLC) technique, which comprises an adaptive one-vs-all global clustering algorithm to discern between target classes, complemented by a local k-NN clustering strategy to mitigate negative transfer. Despite the effectiveness, the inherent closed-set source architecture leads to uniform treatment of "unknown" data, impeding the identification of distinct "unknown" categories. To address this, we evolve GLC to GLC++, integrating a contrastive affini
    
[^29]: 定位和减轻大型语言模型中的性别偏见

    Locating and Mitigating Gender Bias in Large Language Models

    [https://arxiv.org/abs/2403.14409](https://arxiv.org/abs/2403.14409)

    本研究提出了一种将定位和减轻偏见过程融入统一框架的方法，通过因果中介分析追踪大型语言模型中不同组件激活的因果效应，并提出了一种用于减轻职业代词中性别偏见的基于知识编辑的LSDM方法。

    

    大型语言模型（LLM）在广泛语料库上进行预训练，学习事实和人类认知，其中包含人类偏好。然而，这个过程可能无意中导致这些模型获得社会中普遍存在的偏见和刻板印象。先前的研究通常通过单一视角处理偏见问题，集中于定位或减轻偏见。这种有限的视角在促进偏见研究方面造成了障碍，无法协同互补并逐步积累经验。在这项研究中，我们将定位和减轻偏见的过程融入一个统一框架内。首先，我们使用因果中介分析来跟踪大型语言模型中不同组件激活的因果效应。在此基础上，我们提出LSDM（最小二乘减偏方法），这是一种基于知识编辑的方法，用于减轻职业代词中的性别偏见，和比较

    arXiv:2403.14409v1 Announce Type: cross  Abstract: Large language models(LLM) are pre-trained on extensive corpora to learn facts and human cognition which contain human preferences. However, this process can inadvertently lead to these models acquiring biases and stereotypes prevalent in society. Prior research has typically tackled the issue of bias through a one-dimensional perspective, concentrating either on locating or mitigating it. This limited perspective has created obstacles in facilitating research on bias to synergistically complement and progressively build upon one another. In this study, we integrate the processes of locating and mitigating bias within a unified framework. Initially, we use causal mediation analysis to trace the causal effects of different components' activation within a large language model. Building on this, we propose the LSDM (Least Square Debias Method), a knowledge-editing based method for mitigating gender bias in occupational pronouns, and compa
    
[^30]: 自适应检索增强大型语言模型：通过问题复杂度学习调适

    Adaptive-RAG: Learning to Adapt Retrieval-Augmented Large Language Models through Question Complexity

    [https://arxiv.org/abs/2403.14403](https://arxiv.org/abs/2403.14403)

    通过新颖的自适应QA框架，根据查询的复杂度动态选择适合的检索增强大型语言模型策略，提高了回答准确性。

    

    检索增强大型语言模型（LLMs）将外部知识库中的非参数知识纳入LLMs，已成为提高多种任务中回答准确性的有希望方法，如问答（QA）。然而，尽管有各种方法处理不同复杂度的查询，但它们要么处理简单查询时产生不必要的计算开销，要么未能充分解决复杂的多步查询；然而，并非所有用户请求都只能划分为简单或复杂类别中的一种。在这项研究中，我们提出了一种新颖的自适应QA框架，该框架可以动态选择从最简单到最复杂的（检索增强）LLMs策略，这取决于查询的复杂度。此外，这个选择过程是通过一个分类器实现的，该分类器是一个较小的LM，训练以预测传入查询的复杂度级别。

    arXiv:2403.14403v1 Announce Type: cross  Abstract: Retrieval-Augmented Large Language Models (LLMs), which incorporate the non-parametric knowledge from external knowledge bases into LLMs, have emerged as a promising approach to enhancing response accuracy in several tasks, such as Question-Answering (QA). However, even though there are various approaches dealing with queries of different complexities, they either handle simple queries with unnecessary computational overhead or fail to adequately address complex multi-step queries; yet, not all user requests fall into only one of the simple or complex categories. In this work, we propose a novel adaptive QA framework, that can dynamically select the most suitable strategy for (retrieval-augmented) LLMs from the simplest to the most sophisticated ones based on the query complexity. Also, this selection process is operationalized with a classifier, which is a smaller LM trained to predict the complexity level of incoming queries with aut
    
[^31]: 使用语言感知调节的精确翻译定制LLMs的构建

    Building Accurate Translation-Tailored LLMs with Language Aware Instruction Tuning

    [https://arxiv.org/abs/2403.14399](https://arxiv.org/abs/2403.14399)

    通过设计两阶段微调算法，本研究旨在提高LLMs遵循翻译指令的能力，尤其是翻译方向信息。

    

    翻译定制的大型语言模型（LLMs）展现出出色的翻译能力，甚至能与商业翻译系统相媲美。然而，误翻译问题仍然存在，特别是对于低资源语言，阻碍我们开发准确的基于LLMs的翻译模型。为了缓解误翻译问题并提升LLMs在翻译上的性能，最近的研究要么设计了先进的提示策略以突出翻译指令的功能，要么利用LLMs的现场学习能力通过少量示范。然而，这些方法基本上没有提高LLMs遵循翻译指令的能力，尤其是语言方向信息。在这项工作中，我们设计了一个两阶段微调算法来提高LLMs的指令遵循能力（特别是翻译方向）。

    arXiv:2403.14399v1 Announce Type: cross  Abstract: Translation-tailored Large language models (LLMs) exhibit remarkable translation capabilities, even competing with supervised-trained commercial translation systems. However, off-target translation remains an unsolved problem, especially for low-resource languages, hindering us from developing accurate LLMs-based translation models. To mitigate the off-target translation problem and enhance the performance of LLMs on translation, recent works have either designed advanced prompting strategies to highlight the functionality of translation instructions or exploited the in-context learning ability of LLMs by feeding few-shot demonstrations. However, these methods essentially do not improve LLM's ability to follow translation instructions, especially the language direction information. In this work, we design a two-stage fine-tuning algorithm to improve the instruction-following ability (especially the translation direction) of LLMs. Speci
    
[^32]: 通过重新表述前缀提示来编辑语言Lodel的知识表示

    Editing Knowledge Representation of Language Lodel via Rephrased Prefix Prompts

    [https://arxiv.org/abs/2403.14381](https://arxiv.org/abs/2403.14381)

    引入了一种名为PSPEM的新方法，通过重新表述前缀提示来编辑语言Lodel的知识表示，解决了知识编辑方法中的低效性、通用性问题，以及提示工程的不透明性。

    

    神经语言模型（LMs）已在广泛的语料库上进行了大量培训，以存储关于文本描述的世界各个方面的事实知识。当前技术通常采用知识编辑方法或特定提示来修改LM输出。然而，现有的知识编辑方法成本高昂且低效，难以产生适当的文本。此外，提示工程是不透明的，需要大量努力找到合适的提示。为解决这些问题，我们引入了一种称为PSPEM（前缀软提示编辑方法）的新方法，可以仅通过一次训练而终身使用。它解决了知识编辑方法中的低效性和通用性问题，并通过自动寻找最佳软提示来克服提示工程的不透明性。具体而言，PSPEM利用提示编码器和编码转换器来精炼提示中的关键信息，并使用提示对齐

    arXiv:2403.14381v1 Announce Type: cross  Abstract: Neural language models (LMs) have been extensively trained on vast corpora to store factual knowledge about various aspects of the world described in texts. Current technologies typically employ knowledge editing methods or specific prompts to modify LM outputs. However, existing knowledge editing methods are costly and inefficient, struggling to produce appropriate text. Additionally, prompt engineering is opaque and requires significant effort to find suitable prompts. To address these issues, we introduce a new method called PSPEM (Prefix Soft Prompt Editing Method), that can be used for a lifetime with just one training. It resolves the inefficiencies and generalizability issues in knowledge editing methods and overcomes the opacity of prompt engineering by automatically seeking optimal soft prompts. Specifically, PSPEM utilizes a prompt encoder and an encoding converter to refine key information in prompts and uses prompt alignmen
    
[^33]: 循环改进：一种从异构数据中提取共享特征的高效方法，无需中央服务器

    Loop Improvement: An Efficient Approach for Extracting Shared Features from Heterogeneous Data without Central Server

    [https://arxiv.org/abs/2403.14371](https://arxiv.org/abs/2403.14371)

    循环改进（LI）是一种无需中央服务器或数据交换的新颖方法，可提高数据异质性下的特征提取效率，表现优越于先进算法FedALA，并可应用于个性化联邦学习和全局模型环境。

    

    在联邦学习中，数据的异质性显著影响性能。一种典型的解决方案是将这些参数分为共享和个性化组件，这个概念在多任务学习中也很重要。针对这一问题，我们提出了“循环改进”（LI），这是一种新颖的方法，增强了这种分离和特征提取，而不需要中央服务器或参与者之间的数据交换。我们的实验显示，在个性化联邦学习环境中，LI在准确性方面始终优于先进的FedALA算法，适用于各种情况。此外，LI的特征提取器与聚合所有客户端数据时实现的性能相匹配。在全局模型环境中，使用具有堆叠个性化层和额外网络的LI也产生了与合并客户端数据场景相当的结果。此外，LI的适应能力延展到...

    arXiv:2403.14371v1 Announce Type: cross  Abstract: In federated learning, data heterogeneity significantly impacts performance. A typical solution involves segregating these parameters into shared and personalized components, a concept also relevant in multi-task learning. Addressing this, we propose "Loop Improvement" (LI), a novel method enhancing this separation and feature extraction without necessitating a central server or data interchange among participants. Our experiments reveal LI's superiority in several aspects: In personalized federated learning environments, LI consistently outperforms the advanced FedALA algorithm in accuracy across diverse scenarios. Additionally, LI's feature extractor closely matches the performance achieved when aggregating data from all clients. In global model contexts, employing LI with stacked personalized layers and an additional network also yields comparable results to combined client data scenarios. Furthermore, LI's adaptability extends to m
    
[^34]: 探索大型语言模型在图生成中的潜力

    Exploring the Potential of Large Language Models in Graph Generation

    [https://arxiv.org/abs/2403.14358](https://arxiv.org/abs/2403.14358)

    本文探索了大型语言模型在图生成中的潜力，通过任务设计和实验考察了其对不同图结构规则的理解、捕获结构类型分布的能力以及利用领域知识进行基于属性的图生成。

    

    大型语言模型（LLMs）在许多领域取得了巨大成功，最近的研究探讨了探索LLMs用于图判别任务，如节点分类。然而，LLMs在图生成方面的能力在文献中尚未被探索。图生成要求LLM生成具有特定属性的图，这在药物发现等有价值的实际应用中非常重要，但也更具挑战性。在本文中，我们提出了LLM4GraphGen来探索LLMs进行图生成的能力，通过系统性任务设计和大量实验。具体而言，我们提出了几个任务，并进行了全面实验，以解决有关LLMs对不同图结构规则的理解、捕获结构类型分布的能力以及利用域知识进行基于属性的图生成的关键问题。我们的评估表明，LLMs，特别是

    arXiv:2403.14358v1 Announce Type: cross  Abstract: Large language models (LLMs) have achieved great success in many fields, and recent works have studied exploring LLMs for graph discriminative tasks such as node classification. However, the abilities of LLMs for graph generation remain unexplored in the literature. Graph generation requires the LLM to generate graphs with given properties, which has valuable real-world applications such as drug discovery, while tends to be more challenging. In this paper, we propose LLM4GraphGen to explore the ability of LLMs for graph generation with systematical task designs and extensive experiments. Specifically, we propose several tasks tailored with comprehensive experiments to address key questions regarding LLMs' understanding of different graph structure rules, their ability to capture structural type distributions, and their utilization of domain knowledge for property-based graph generation. Our evaluations demonstrate that LLMs, particular
    
[^35]: 通过生成方法探索图表示学习中的任务统一化

    Exploring Task Unification in Graph Representation Learning via Generative Approach

    [https://arxiv.org/abs/2403.14340](https://arxiv.org/abs/2403.14340)

    通过提出GA^2E，一个统一的框架，通过统一的生成式半监督学习，在单个训练阶段中实现了图生成、图判别和图预测任务。

    

    图在现实场景中无处不在，并涵盖了从节点级、边级和图级任务到迁移学习的各种任务。然而，为每种类型的图数据设计特定任务通常代价高昂且缺乏泛化能力。最近的研究致力于“预训练+微调”或“预训练+提示”范式，旨在设计一个能够泛化多种图任务的统一框架。在这些方法中，图自编码器（GAEs）、生成自监督模型已经证明了它们在有效解决各种图任务方面的潜力。然而，这些方法通常使用多阶段训练并需要自适应设计，这一方面使得将其无缝应用于不同的图任务变得困难，另一方面忽略了不同阶段任务目标之间的差异造成的负面影响。为了解决这些挑战，我们提出了GA^2E，一个统一的框架，通过统一的生成式半监督学习，可以在单个训练阶段中同时实现图生成、图判别和图预测任务。

    arXiv:2403.14340v1 Announce Type: cross  Abstract: Graphs are ubiquitous in real-world scenarios and encompass a diverse range of tasks, from node-, edge-, and graph-level tasks to transfer learning. However, designing specific tasks for each type of graph data is often costly and lacks generalizability. Recent endeavors under the "Pre-training + Fine-tuning" or "Pre-training + Prompt" paradigms aim to design a unified framework capable of generalizing across multiple graph tasks. Among these, graph autoencoders (GAEs), generative self-supervised models, have demonstrated their potential in effectively addressing various graph tasks. Nevertheless, these methods typically employ multi-stage training and require adaptive designs, which on one hand make it difficult to be seamlessly applied to diverse graph tasks and on the other hand overlook the negative impact caused by discrepancies in task objectives between the different stages. To address these challenges, we propose GA^2E, a unifi
    
[^36]: $\nabla \tau$: 基于梯度且任务无关的机器遗忘

    $\nabla \tau$: Gradient-based and Task-Agnostic machine Unlearning

    [https://arxiv.org/abs/2403.14339](https://arxiv.org/abs/2403.14339)

    $\nabla \tau$ 是一种旨在高效消除部分训练数据影响的机器遗忘优化框架。

    

    机器遗忘是一种有选择性地消除模型训练过程中某些数据示例影响的过程，作为从业者遵守最近的数据保护法规的手段，已经引起了显著关注。然而，现有的遗忘方法面临着关键缺点，包括其成本过高，通常与大量超参数相关，以及仅忘记相对较小数据部分的限制。这经常导致从头开始重新训练模型成为更快速和更有效的解决方案。在本研究中，我们介绍了基于梯度且任务无关的机器遗忘（$\nabla \tau$），这是一种旨在高效消除部分训练数据影响的优化框架。它对待遗忘的数据应用自适应梯度上升，同时对其余数据使用标准梯度下降。$\nabla \tau$相对于现有方法提供了多种优势。

    arXiv:2403.14339v1 Announce Type: cross  Abstract: Machine Unlearning, the process of selectively eliminating the influence of certain data examples used during a model's training, has gained significant attention as a means for practitioners to comply with recent data protection regulations. However, existing unlearning methods face critical drawbacks, including their prohibitively high cost, often associated with a large number of hyperparameters, and the limitation of forgetting only relatively small data portions. This often makes retraining the model from scratch a quicker and more effective solution. In this study, we introduce Gradient-based and Task-Agnostic machine Unlearning ($\nabla \tau$), an optimization framework designed to remove the influence of a subset of training data efficiently. It applies adaptive gradient ascent to the data to be forgotten while using standard gradient descent for the remaining data. $\nabla \tau$ offers multiple benefits over existing approache
    
[^37]: 将强化学习策略提炼为可解释的机器人运动：梯度提升机和符号回归

    Distilling Reinforcement Learning Policies for Interpretable Robot Locomotion: Gradient Boosting Machines and Symbolic Regression

    [https://arxiv.org/abs/2403.14328](https://arxiv.org/abs/2403.14328)

    通过梯度提升机和符号回归等技术，将神经网络的强化学习策略转化为更可解释的形式，提高了机器人运动策略的透明度和可理解性。

    

    最近强化学习（RL）的发展使机器人运动能力取得了显著进展。然而，基于神经网络的RL策略的复杂性和“黑匣子”特性阻碍了它们的可解释性和更广泛的接受度，特别是在要求高水平安全性和可靠性的应用中。本文引入了一种将神经RL策略提炼为更可解释形式的新方法，使用梯度提升机（GBMs）、可解释提升机（EBMs）和符号回归。通过利用广义加法模型、决策树和分析表达式的固有可解释性，我们将不透明的神经网络策略转化为更透明的“玻璃箱”模型。我们使用RL训练专家神经网络策略，然后将它们提炼为(i) GBMs、(ii) EBMs和(iii)符号策略。为了解决行为分布转移挑战

    arXiv:2403.14328v1 Announce Type: cross  Abstract: Recent advancements in reinforcement learning (RL) have led to remarkable achievements in robot locomotion capabilities. However, the complexity and ``black-box'' nature of neural network-based RL policies hinder their interpretability and broader acceptance, particularly in applications demanding high levels of safety and reliability. This paper introduces a novel approach to distill neural RL policies into more interpretable forms using Gradient Boosting Machines (GBMs), Explainable Boosting Machines (EBMs) and Symbolic Regression. By leveraging the inherent interpretability of generalized additive models, decision trees, and analytical expressions, we transform opaque neural network policies into more transparent ``glass-box'' models. We train expert neural network policies using RL and subsequently distill them into (i) GBMs, (ii) EBMs, and (iii) symbolic policies. To address the inherent distribution shift challenge of behavioral 
    
[^38]: DexDribbler: 通过动态监督学习巧妙的足球操纵

    DexDribbler: Learning Dexterous Soccer Manipulation via Dynamic Supervision

    [https://arxiv.org/abs/2403.14300](https://arxiv.org/abs/2403.14300)

    提出了一种通过动态监督学习巧妙的足球操纵方法，利用反馈控制模块来计算必要的整体运动并进行动态关节级运动监督，同时改进了球体动态模型和上下文-辅助估计器。

    

    学习四肢机器人的灵巧运动策略因其处理多样化地形并类似于智能行为的能力而变得越来越流行。然而，在学习社区中，对于运动物体的关节操纵和足球等运动的关节操纵与足部运动的组合，接受的关注却很少，虽然这对于人类和聪明动物来说是自然的。解决这一多任务问题的一个关键挑战是从操纵物体的状态和目标中推断出运动目标。操纵物体状态与机器人运动之间的隐含关系可能很难直接从训练经验中捕捉。我们提出添加一个反馈控制模块来准确计算必要的整体运动，并将输出作为动态关节级运动监督。我们进一步利用改进的球体动态模型，扩展的上下文辅助估计器以及综合的球体观察器。

    arXiv:2403.14300v1 Announce Type: cross  Abstract: Learning dexterous locomotion policy for legged robots is becoming increasingly popular due to its ability to handle diverse terrains and resemble intelligent behaviors. However, joint manipulation of moving objects and locomotion with legs, such as playing soccer, receive scant attention in the learning community, although it is natural for humans and smart animals. A key challenge to solve this multitask problem is to infer the objectives of locomotion from the states and targets of the manipulated objects. The implicit relation between the object states and robot locomotion can be hard to capture directly from the training experience. We propose adding a feedback control block to compute the necessary body-level movement accurately and using the outputs as dynamic joint-level locomotion supervision explicitly. We further utilize an improved ball dynamic model, an extended context-aided estimator, and a comprehensive ball observer to
    
[^39]: 从危险到可能性：理解人类（以及人工智能）偏见如何影响在线论坛

    From Perils to Possibilities: Understanding how Human (and AI) Biases affect Online Fora

    [https://arxiv.org/abs/2403.14298](https://arxiv.org/abs/2403.14298)

    在线社交互动中存在着封闭性社区和在线支持团体两种面貌，受到算法偏见和同质性极端机制的影响。

    

    社交媒体平台是在线论坛，在那里用户进行讨论，分享内容，建立联系。本综述通过在线辩论、在线支持和人工智能相互作用三个关键视角，探讨社交互动、用户生成内容和偏见的动态，通过复杂网络分析和自然语言处理工具来分析社交媒体的背景中。一方面，我们描述了在线辩论的现象，其中极化、错误信息和信息茧房形成经常蔓延，受到算法偏见和同质性极端机制的推动。另一方面，我们探讨了在线支持小组的出现，通过用户的自我披露和社会支持机制。在线辩论和支持机制在社交媒体中呈现出危险和可能性的二重性；分割社区和

    arXiv:2403.14298v1 Announce Type: cross  Abstract: Social media platforms are online fora where users engage in discussions, share content, and build connections. This review explores the dynamics of social interactions, user-generated contents, and biases within the context of social media analysis (analyzing works that use the tools offered by complex network analysis and natural language processing) through the lens of three key points of view: online debates, online support, and human-AI interactions. On the one hand, we delineate the phenomenon of online debates, where polarization, misinformation, and echo chamber formation often proliferate, driven by algorithmic biases and extreme mechanisms of homophily. On the other hand, we explore the emergence of online support groups through users' self-disclosure and social support mechanisms. Online debates and support mechanisms present a duality of both perils and possibilities within social media; perils of segregated communities and
    
[^40]: 地球观测应用中缺失数据对模型预测的影响评估

    Impact Assessment of Missing Data in Model Predictions for Earth Observation Applications

    [https://arxiv.org/abs/2403.14297](https://arxiv.org/abs/2403.14297)

    本研究评估了在地球观测应用中缺失数据对训练模型的影响，发现集成策略可以实现高达100%的预测稳健性，同时揭示了缺失情景在回归任务中比分类任务更具挑战性，且光学视角是最关键的。

    

    地球观测（EO）应用涉及复杂和异构数据源，通常采用机器学习模型进行处理。然而，人们普遍假设数据源将持续可用。不同情况可能影响EO数据源的可用性，如噪声、云层或卫星任务失败。本研究评估了在四个数据集上进行的分类和回归任务中缺失时间性和静态EO数据源对训练模型的影响。我们比较了不同方法的预测质量，并发现一些方法在面对缺失数据时自然更加稳健。特别是集成策略实现了高达100%的预测稳健性。我们发现缺失情景在回归任务中比分类任务更具挑战性。最后，我们发现光学视角在单独缺失时是最关键的视角。

    arXiv:2403.14297v1 Announce Type: cross  Abstract: Earth observation (EO) applications involving complex and heterogeneous data sources are commonly approached with machine learning models. However, there is a common assumption that data sources will be persistently available. Different situations could affect the availability of EO sources, like noise, clouds, or satellite mission failures. In this work, we assess the impact of missing temporal and static EO sources in trained models across four datasets with classification and regression tasks. We compare the predictive quality of different methods and find that some are naturally more robust to missing data. The Ensemble strategy, in particular, achieves a prediction robustness up to 100%. We evidence that missing scenarios are significantly more challenging in regression than classification tasks. Finally, we find that the optical view is the most critical view when it is missing individually.
    
[^41]: 利用构图线索增强历史图像检索

    Enhancing Historical Image Retrieval with Compositional Cues

    [https://arxiv.org/abs/2403.14287](https://arxiv.org/abs/2403.14287)

    该研究通过将计算美学中的图像构图原则融入到检索模型中，实现了历史图像检索方法的增强，提高了图像检索的效果。

    

    arXiv:2403.14287v1 通告类型：跨领域 摘要：在分析大量存储的历史图像数据时，现有的基于内容的检索方法往往忽略了重要的非语义信息，从而限制了它们在跨不同主题进行灵活探索的效果。为了拓宽图像检索方法的适用性，为各种目的揭示更一般的规律，我们创新性地将计算美学中的关键因素，即图像构图，引入到这个主题中。通过明确地将由 CNN 提取的与构图相关信息整合到设计的检索模型中，我们的方法考虑了图像的构图规则和语义信息。定性和定量实验表明，由构图信息引导的图像检索网络优于仅依赖内容信息的方法，有助于在数据库中识别距离目标图像在人类感知上更接近的图像。

    arXiv:2403.14287v1 Announce Type: cross  Abstract: In analyzing vast amounts of digitally stored historical image data, existing content-based retrieval methods often overlook significant non-semantic information, limiting their effectiveness for flexible exploration across varied themes. To broaden the applicability of image retrieval methods for diverse purposes and uncover more general patterns, we innovatively introduce a crucial factor from computational aesthetics, namely image composition, into this topic. By explicitly integrating composition-related information extracted by CNN into the designed retrieval model, our method considers both the image's composition rules and semantic information. Qualitative and quantitative experiments demonstrate that the image retrieval network guided by composition information outperforms those relying solely on content information, facilitating the identification of images in databases closer to the target image in human perception. Please vi
    
[^42]: 如何做到公平？标签和选择偏差研究

    How to be fair? A study of label and selection bias

    [https://arxiv.org/abs/2403.14282](https://arxiv.org/abs/2403.14282)

    研究探讨数据偏见如何影响模型公平性，提出了建立偏见类型与缓解技术有效性之间关系的方法

    

    众所周知，偏见数据会导致偏见、潜在不公平的模型。因此，已经提出了几种用于数据和模型预测偏见的措施，以及其目标是通过设计公平的偏见缓解技术来学习模型。近十年来已经发展了大量的缓解技术，然而，在什么情况下哪些方法起作用仍然知之甚少。最近，Wick等人在合成数据上的实验表明，存在一些情况，其中偏见缓解技术导致在无偏数据上测量时更精确的模型。然而，在缺乏彻底的数学分析的情况下，仍不清楚在何种情况下哪些技术是有效的。我们提出通过建立偏见类型与缓解技术有效性之间的关系来解决这个问题，我们将缓解技术按

    arXiv:2403.14282v1 Announce Type: cross  Abstract: It is widely accepted that biased data leads to biased and thus potentially unfair models. Therefore, several measures for bias in data and model predictions have been proposed, as well as bias mitigation techniques whose aim is to learn models that are fair by design. Despite the myriad of mitigation techniques developed in the past decade, however, it is still poorly understood under what circumstances which methods work. Recently, Wick et al. showed, with experiments on synthetic data, that there exist situations in which bias mitigation techniques lead to more accurate models when measured on unbiased data. Nevertheless, in the absence of a thorough mathematical analysis, it remains unclear which techniques are effective under what circumstances. We propose to address this problem by establishing relationships between the type of bias and the effectiveness of a mitigation technique, where we categorize the mitigation techniques by 
    
[^43]: 通过LLMs讨论实现漏洞检测的多角共识

    Multi-role Consensus through LLMs Discussions for Vulnerability Detection

    [https://arxiv.org/abs/2403.14274](https://arxiv.org/abs/2403.14274)

    本论文提出了一种利用LLMs模拟不同角色进行讨论，以达成对代码中漏洞存在和分类的共识的方法，并在初步评估中实现了精确率、召回率和F1分数的明显提升。

    

    最近大型语言模型（LLMs）的发展突显了漏洞检测的潜力，这是软件质量保证的关键组成部分。然而，大多数研究仅限于单一角色的视角，通常是测试人员，缺乏典型软件开发生命周期中不同角色的多元观点，包括开发人员和测试人员。为此，本文介绍了一种利用LLMs扮演不同角色的方法，模拟现实代码审查过程，进行讨论以达成关于代码中漏洞存在和分类的共识。所提出方法的初步评估显示，精确率增加了4.73％，召回率增加了58.9％，F1分数增加了28.1％。

    arXiv:2403.14274v1 Announce Type: cross  Abstract: Recent advancements in large language models (LLMs) have highlighted the potential for vulnerability detection, a crucial component of software quality assurance. Despite this progress, most studies have been limited to the perspective of a single role, usually testers, lacking diverse viewpoints from different roles in a typical software development life-cycle, including both developers and testers. To this end, this paper introduces an approach to employ LLMs to act as different roles to simulate real-life code review process, engaging in discussions towards a consensus on the existence and classification of vulnerabilities in the code. Preliminary evaluation of the proposed approach indicates a 4.73% increase in the precision rate, 58.9% increase in the recall rate, and a 28.1% increase in the F1 score.
    
[^44]: 通过强化学习进行反应堆优化基准测试

    Reactor Optimization Benchmark by Reinforcement Learning

    [https://arxiv.org/abs/2403.14273](https://arxiv.org/abs/2403.14273)

    本文通过引入一个新颖的基准问题，在OpenNeoMC框架中设计了一个用于强化学习的基准测试，旨在优化研究反应堆中的一个单元格，以最大化中子通量并保持反应堆的临界性。

    

    反应堆的中子学计算在使用蒙特卡洛（MC）方法时是一项艰巨的任务。随着高性能计算的进步，如今反应堆的模拟更容易实现，但使用多个参数进行设计和优化仍然是一个计算挑战。MC传输模拟结合机器学习技术，为增强核反应堆优化的效率和有效性提供了有前途的途径。本文在专门为强化学习设计的OpenNeoMC框架中引入了一个新颖的基准问题。该基准涉及优化研究反应堆中的一个单元格，具有两个不同参数（燃料密度和水间距），以最大化中子通量同时保持反应堆的临界性。测试案例具有不同的局部最优解，代表不同的物理区域，从而为学习算法提出挑战。通过广泛的模拟运用

    arXiv:2403.14273v1 Announce Type: cross  Abstract: Neutronic calculations for reactors are a daunting task when using Monte Carlo (MC) methods. As high-performance computing has advanced, the simulation of a reactor is nowadays more readily done, but design and optimization with multiple parameters is still a computational challenge. MC transport simulations, coupled with machine learning techniques, offer promising avenues for enhancing the efficiency and effectiveness of nuclear reactor optimization. This paper introduces a novel benchmark problem within the OpenNeoMC framework designed specifically for reinforcement learning. The benchmark involves optimizing a unit cell of a research reactor with two varying parameters (fuel density and water spacing) to maximize neutron flux while maintaining reactor criticality. The test case features distinct local optima, representing different physical regimes, thus posing a challenge for learning algorithms. Through extensive simulations util
    
[^45]: 一种具有肤色意识和裸体识别的肖像风格化框架

    A Framework for Portrait Stylization with Skin-Tone Awareness and Nudity Identification

    [https://arxiv.org/abs/2403.14264](https://arxiv.org/abs/2403.14264)

    提出了一种肖像风格化框架，结合了裸体内容识别模块和肤色感知肖像风格化模块，以解决过滤有害内容并保留肤色特征的挑战。

    

    肖像风格化是一项具有挑战性的任务，涉及将输入的肖像图像转换为特定风格，同时保留其固有特征。最近引入的稳定扩散（SD）在该领域显著提高了结果的质量。然而，一个能够有效过滤有害输入内容并保留输入的独特特征（如肤色），同时保持风格化质量的实用风格化框架仍然缺乏。这些挑战阻碍了这种框架的广泛部署。为解决这些问题，本研究提出了一个肖像风格化框架，该框架融合了裸露内容识别模块（NCIM）和肤色感知肖像风格化模块（STAPSM）。在实验中，NCIM 在增强明确内容过滤方面表现良好，而 STAPSM 准确表现了各种肤色。我们的建议

    arXiv:2403.14264v1 Announce Type: cross  Abstract: Portrait stylization is a challenging task involving the transformation of an input portrait image into a specific style while preserving its inherent characteristics. The recent introduction of Stable Diffusion (SD) has significantly improved the quality of outcomes in this field. However, a practical stylization framework that can effectively filter harmful input content and preserve the distinct characteristics of an input, such as skin-tone, while maintaining the quality of stylization remains lacking. These challenges have hindered the wide deployment of such a framework. To address these issues, this study proposes a portrait stylization framework that incorporates a nudity content identification module (NCIM) and a skin-tone-aware portrait stylization module (STAPSM). In experiments, NCIM showed good performance in enhancing explicit content filtering, and STAPSM accurately represented a diverse range of skin tones. Our proposed
    
[^46]: LayoutLLM：大规模语言模型指令调整用于视觉丰富文档理解

    LayoutLLM: Large Language Model Instruction Tuning for Visually Rich Document Understanding

    [https://arxiv.org/abs/2403.14252](https://arxiv.org/abs/2403.14252)

    提出了一种新的LayoutLLM模型，通过结合大规模语言模型和文档图像理解的优势，实现了对文档图像的理解。

    

    这篇论文提出了LayoutLLM，一种更灵活的文档分析方法，用于理解图像文档。视觉丰富文档理解任务，如文档图像分类和信息提取，由于其重要性而受到重视。现有方法旨在通过整合对图像、文本和布局结构的预训练意识来提升文档理解能力。然而，这些方法需要针对每个任务和数据集进行微调，而且模型训练和操作成本高昂。为了克服这一限制，我们提出了一种新的LayoutLLM，将这些与大规模语言模型（LLMs）相集成。通过利用现有研究在文档图像理解和LLMs卓越的语言理解能力方面的优势，所提出的模型在多模态指令数据集的微调下，可以通过单个模型理解文档图像。

    arXiv:2403.14252v1 Announce Type: cross  Abstract: This paper proposes LayoutLLM, a more flexible document analysis method for understanding imaged documents. Visually Rich Document Understanding tasks, such as document image classification and information extraction, have gained significant attention due to their importance. Existing methods have been developed to enhance document comprehension by incorporating pre-training awareness of images, text, and layout structure. However, these methods require fine-tuning for each task and dataset, and the models are expensive to train and operate. To overcome this limitation, we propose a new LayoutLLM that integrates these with large-scale language models (LLMs). By leveraging the strengths of existing research in document image understanding and LLMs' superior language understanding capabilities, the proposed model, fine-tuned with multimodal instruction datasets, performs an understanding of document images in a single model. Our experime
    
[^47]: CATSE: 一种上下文感知的因果目标声音提取框架

    CATSE: A Context-Aware Framework for Causal Target Sound Extraction

    [https://arxiv.org/abs/2403.14246](https://arxiv.org/abs/2403.14246)

    CATSE提出了一种适用于实时处理的上下文感知低延迟因果TSE模型，通过引入复合多任务训练目标，提高了目标声音提取的性能。

    

    目标声音提取（TSE）专注于将用户提示的感兴趣来源与输入混合物分离的问题。大多数现有解决方案以线下方式运行，不适用于应用于实时内容（如增强听力）中所施加的低延迟因果处理约束。我们引入了一系列适用于实时处理的上下文感知低延迟因果TSE模型。首先，我们通过为TSE模型提供有关组成输入混合物的声音类别的神谕信息，探讨了上下文的实用性，其中模型的目标是提取用户指示的一个或多个感兴趣来源。由于神谕模型的实际应用受到假设的限制，我们引入了一个包含分离和分类损失的复合多任务训练目标。我们的评估涉及单源和多源提取

    arXiv:2403.14246v1 Announce Type: cross  Abstract: Target Sound Extraction (TSE) focuses on the problem of separating sources of interest, indicated by a user's cue, from the input mixture. Most existing solutions operate in an offline fashion and are not suited to the low-latency causal processing constraints imposed by applications in live-streamed content such as augmented hearing. We introduce a family of context-aware low-latency causal TSE models suitable for real-time processing. First, we explore the utility of context by providing the TSE model with oracle information about what sound classes make up the input mixture, where the objective of the model is to extract one or more sources of interest indicated by the user. Since the practical applications of oracle models are limited due to their assumptions, we introduce a composite multi-task training objective involving separation and classification losses. Our evaluation involving single- and multi-source extraction shows the 
    
[^48]: 同性质高斯飘屑实现实时辐射场渲染

    Isotropic Gaussian Splatting for Real-Time Radiance Field Rendering

    [https://arxiv.org/abs/2403.14244](https://arxiv.org/abs/2403.14244)

    提出使用同性质高斯核替代各向异性核来提高计算性能，在不失去几何表示准确性的情况下实现约100倍的加速，适用于多种需要辐射场的应用领域。

    

    3D高斯飘屑方法因其在训练中的高性能和渲染图像的高质量而备受关注。然而，它使用各向异性的高斯核来表示场景。虽然这种各向异性核在表示几何方面具有优势，但在计算方面会导致诸如分裂或合并两个核的困难。本文提出使用同性质高斯核来避免计算中的这些困难，从而导致一种性能更高的方法。实验证实，所提出的方法比原方法快约100倍，而不会丢失几何表示的准确性。所提出的方法可应用于需要辐射场的大范围应用，如3D重建、视图合成和动态对象建模。

    arXiv:2403.14244v1 Announce Type: cross  Abstract: The 3D Gaussian splatting method has drawn a lot of attention, thanks to its high performance in training and high quality of the rendered image. However, it uses anisotropic Gaussian kernels to represent the scene. Although such anisotropic kernels have advantages in representing the geometry, they lead to difficulties in terms of computation, such as splitting or merging two kernels. In this paper, we propose to use isotropic Gaussian kernels to avoid such difficulties in the computation, leading to a higher performance method. The experiments confirm that the proposed method is about {\bf 100X} faster without losing the geometry representation accuracy. The proposed method can be applied in a large range applications where the radiance field is needed, such as 3D reconstruction, view synthesis, and dynamic object modeling.
    
[^49]: Dermacen Analytica: 一种将多模式大型语言模型与机器学习相整合的新方法论在远程皮肤病学中的应用

    Dermacen Analytica: A Novel Methodology Integrating Multi-Modal Large Language Models with Machine Learning in tele-dermatology

    [https://arxiv.org/abs/2403.14243](https://arxiv.org/abs/2403.14243)

    本文提出了一种新方法，在远程皮肤病学中整合了多模式大型语言模型与机器学习，旨在通过综合利用大型语言模型、Transformer视觉模型和复杂的机器学习工具，辅助诊断皮肤病变和其他皮肤状况，从而全面解决该领域的诊断流程。

    

    人工智能的崛起在医学发现、诊断和患者管理领域带来了巨大的希望。然而，所有医学领域的巨大复杂性要求采用一种更复杂的方法，结合机器学习算法、分类器、分割算法以及近来的大型语言模型。本文描述、实施和评估了一种基于人工智能的系统和方法论，旨在协助皮肤病学领域的皮肤病变和其他皮肤状况的诊断过程，旨在全面解决该领域的诊断流程。该工作流程整合了大型语言、基于Transformer的视觉模型和复杂的机器学习工具。这种全面的方法实现了对皮肤病变的微妙解释，模拟并促进了皮肤科医生的工作流程。我们通过彻底的交叉模式评估了我们提出的方法论。

    arXiv:2403.14243v1 Announce Type: cross  Abstract: The rise of Artificial Intelligence creates great promise in the field of medical discovery, diagnostics and patient management. However, the vast complexity of all medical domains require a more complex approach that combines machine learning algorithms, classifiers, segmentation algorithms and, lately, large language models. In this paper, we describe, implement and assess an Artificial Intelligence-empowered system and methodology aimed at assisting the diagnosis process of skin lesions and other skin conditions within the field of dermatology that aims to holistically address the diagnostic process in this domain. The workflow integrates large language, transformer-based vision models and sophisticated machine learning tools. This holistic approach achieves a nuanced interpretation of dermatological conditions that simulates and facilitates a dermatologist's workflow. We assess our proposed methodology through a thorough cross-mode
    
[^50]: 反思反馈中的强化学习（RLRF）：通过细粒度自我反思对LLMs进行调整和改进

    Reinforcement Learning from Reflective Feedback (RLRF): Aligning and Improving LLMs via Fine-Grained Self-Reflection

    [https://arxiv.org/abs/2403.14238](https://arxiv.org/abs/2403.14238)

    RLRF提出了一种新颖的框架，通过细粒度反馈和自我反思机制，可以改进LLMs的核心能力，超越表面调整。

    

    尽管RLHF在将LLMs与人类偏好进行调整方面很有前景，但往往会导致表面调整，优先考虑风格变化而非改善LLMs的下游性能。未明确规定的偏好可能会模糊对齐模型的方向。缺乏探索会限制识别出改善模型的理想输出。为了克服这些挑战，我们提出了一个新颖的框架：反思反馈中的强化学习（RLRF），该框架利用基于详细标准的细粒度反馈，以改进LLMs的核心能力。RLRF采用自我反思机制系统地探索和完善LLMs的回应，然后通过RL算法对模型进行微调，同时结合有希望的回应。在Just-Eval、Factuality和Mathematical Reasoning等实验中，我们展示了RLRF的功效和超越表面调整的转变潜力。

    arXiv:2403.14238v1 Announce Type: cross  Abstract: Despite the promise of RLHF in aligning LLMs with human preferences, it often leads to superficial alignment, prioritizing stylistic changes over improving downstream performance of LLMs. Underspecified preferences could obscure directions to align the models. Lacking exploration restricts identification of desirable outputs to improve the models. To overcome these challenges, we propose a novel framework: Reinforcement Learning from Reflective Feedback (RLRF), which leverages fine-grained feedback based on detailed criteria to improve the core capabilities of LLMs. RLRF employs a self-reflection mechanism to systematically explore and refine LLM responses, then fine-tuning the models via a RL algorithm along with promising responses. Our experiments across Just-Eval, Factuality, and Mathematical Reasoning demonstrate the efficacy and transformative potential of RLRF beyond superficial surface-level adjustment.
    
[^51]: 一个统一的模型编辑框架

    A Unified Framework for Model Editing

    [https://arxiv.org/abs/2403.14236](https://arxiv.org/abs/2403.14236)

    这个统一框架结合了“定位和编辑”模型编辑技术，最大化保留某些向量表示并记忆新事实信息。

    

    模型编辑是一个不断发展的领域，专注于更新模型中嵌入的知识。在各种方法中，ROME和MEMIT作为主要的“定位和编辑”模型编辑技术脱颖而出。而MEMIT可以批量编辑记忆，ROME则一次只能改变一个事实。本文引入了一个统一的框架，将ROME和MEMIT纳入一个单一的概念框架，优化同一目标，我们称之为“保存-记忆”目标。该目标旨在在记忆新事实信息的同时保留某些选定向量的表示。具体来说，ROME使用等式约束优化此目标，而MEMIT采用更灵活的最小二乘约束。除了批量编辑外，MEMIT还可以在多个层面编辑模型。我们将编辑的分布从多个层面分开，区别于优化目标。

    arXiv:2403.14236v1 Announce Type: cross  Abstract: Model editing is a growing area focused on updating the knowledge embedded within models. Among the various methodologies, ROME and MEMIT stand out as leading "locate-and-edit" model editing techniques. While MEMIT enables batched editing of memories, ROME is limited to changing one fact at a time. This paper introduces a unifying framework that brings ROME and MEMIT under a single conceptual umbrella, optimizing for the same goal, which we call the "preservation-memorization" objective. This objective aims to preserve the representations of certain selected vectors while memorizing the representations of new factual information. Specifically, ROME optimizes this objective using an equality constraint, whereas MEMIT employs a more flexible least-square constraint. In addition to making batched edits, MEMIT also edits the model at multiple layers. We disentangle the distribution of edits to multiple layers from the optimization objectiv
    
[^52]: SoftPatch：无监督噪声数据异常检测

    SoftPatch: Unsupervised Anomaly Detection with Noisy Data

    [https://arxiv.org/abs/2403.14233](https://arxiv.org/abs/2403.14233)

    首次考虑图像传感器异常检测中的标签级别噪声，并提出了一种能够有效去噪补丁级别数据的无监督异常检测方法SoftPatch。

    

    虽然主流的无监督异常检测算法在学术数据集中表现良好，但由于理想的干净训练数据的实验设置，它们在实际应用中的性能受到限制。 在真实世界的异常检测中，使用噪声数据进行训练是一个不可避免的问题，但很少有讨论。 本文首次考虑了图像传感器异常检测中的标签级别噪声。 为了解决这个问题，我们提出了一种基于内存的无监督AD方法SoftPatch，该方法能够有效地对补丁级别的数据进行去噪。 噪声判别器用于生成用于补丁级别噪声消除的异常点评分，然后将这些评分存储在内存存储器中，以软化异常检测边界。 与现有方法相比，SoftPatch保持了对正常数据的强建模能力，并减轻了coreset中的过度自信问题。在实验中进行了综合性实验证明。

    arXiv:2403.14233v1 Announce Type: cross  Abstract: Although mainstream unsupervised anomaly detection (AD) algorithms perform well in academic datasets, their performance is limited in practical application due to the ideal experimental setting of clean training data. Training with noisy data is an inevitable problem in real-world anomaly detection but is seldom discussed. This paper considers label-level noise in image sensory anomaly detection for the first time. To solve this problem, we proposed a memory-based unsupervised AD method, SoftPatch, which efficiently denoises the data at the patch level. Noise discriminators are utilized to generate outlier scores for patch-level noise elimination before coreset construction. The scores are then stored in the memory bank to soften the anomaly detection boundary. Compared with existing methods, SoftPatch maintains a strong modeling ability of normal data and alleviates the overconfidence problem in coreset. Comprehensive experiments in v
    
[^53]: PeerGPT: 探究基于LLM的同侪代理作为团队主持人和参与者在儿童协作学习中的角色

    PeerGPT: Probing the Roles of LLM-based Peer Agents as Team Moderators and Participants in Children's Collaborative Learning

    [https://arxiv.org/abs/2403.14227](https://arxiv.org/abs/2403.14227)

    PeerGPT论文探究了基于LLM的同侪代理作为团队主持人和参与者在儿童协作学习中的角色，发现他们在管理讨论中表现出色，但作为参与者可能存在反馈及时性不足的问题。

    

    在儿童协作学习中，有效的同侪对话显著提高了儿童协作交流的质量。将大型语言模型（LLM）代理整合到此设置中，探讨他们作为同侪的创新角色，评估其作为团队主持人和参与者的影响。我们邀请了两组参与者参加一个协作学习研讨会，在那里他们讨论并提出了解决设计问题的概念解决方案。同侪对话的成绩单经过了主题分析。我们发现，同侪代理在作为团队主持人管理讨论时，有时会被忽视他们的指令。作为参与者，他们促进了儿童的创造性思维，但可能并不始终提供及时的反馈。这些发现强调了同侪代理在两个角色中的潜在设计改进和考虑因素。

    arXiv:2403.14227v1 Announce Type: cross  Abstract: In children's collaborative learning, effective peer conversations can significantly enhance the quality of children's collaborative interactions. The integration of Large Language Model (LLM) agents into this setting explores their novel role as peers, assessing impacts as team moderators and participants. We invited two groups of participants to engage in a collaborative learning workshop, where they discussed and proposed conceptual solutions to a design problem. The peer conversation transcripts were analyzed using thematic analysis. We discovered that peer agents, while managing discussions effectively as team moderators, sometimes have their instructions disregarded. As participants, they foster children's creative thinking but may not consistently provide timely feedback. These findings highlight potential design improvements and considerations for peer agents in both roles.
    
[^54]: 无监督音频-视觉分割与模态对齐

    Unsupervised Audio-Visual Segmentation with Modality Alignment

    [https://arxiv.org/abs/2403.14203](https://arxiv.org/abs/2403.14203)

    提出了一种无监督音频-视觉分割方法 MoCA，在模态对应对齐的基础上使用DINO、SAM和ImageBind模型，实现了多模态关联，并引入了像素匹配聚合策略。

    

    音频-视觉分割（AVS）旨在识别在视觉场景中产生特定声音的对象，这一研究在像素级别进行。当前AVS方法依赖于昂贵的精细标注的掩码-音频对，这使得它们在可扩展性方面不切实际。为解决这一问题，我们引入了无监督AVS，消除了这种昂贵标注的必要性。为解决这个更具挑战性的问题，我们提出了一种无监督学习方法，名为模态对应对齐（MoCA），它无缝整合了像DINO，SAM和ImageBind这样的现成基础模型。这种方法利用它们的知识互补性，优化它们的联合使用以实现多模态关联。起初，我们在特征空间中估计正负图像对。对于像素级别的关联，我们在图像级对比学习框架内引入了视觉适配器和一种新颖的像素匹配聚合策略。

    arXiv:2403.14203v1 Announce Type: cross  Abstract: Audio-Visual Segmentation (AVS) aims to identify, at the pixel level, the object in a visual scene that produces a given sound. Current AVS methods rely on costly fine-grained annotations of mask-audio pairs, making them impractical for scalability. To address this, we introduce unsupervised AVS, eliminating the need for such expensive annotation. To tackle this more challenging problem, we propose an unsupervised learning method, named Modality Correspondence Alignment (MoCA), which seamlessly integrates off-the-shelf foundation models like DINO, SAM, and ImageBind. This approach leverages their knowledge complementarity and optimizes their joint usage for multi-modality association. Initially, we estimate positive and negative image pairs in the feature space. For pixel-level association, we introduce an audio-visual adapter and a novel pixel matching aggregation strategy within the image-level contrastive learning framework. This al
    
[^55]: 手术员去偏见：神奇的权重及如何找到它们

    Debiasing surgeon: fantastic weights and how to find them

    [https://arxiv.org/abs/2403.14200](https://arxiv.org/abs/2403.14200)

    证明了在深度学习模型中存在一些无偏子网络，可以在不需要依赖算法偏见的情况下被提取出来，并且这种特定架构无法学习任何特定的偏见。

    

    现今一个日益关注的现象是算法偏见的出现，它可能导致不公平的模型。在深度学习领域，已经提出了几种去偏见的方法，采用更或多或少复杂的方法来阻止这些模型大规模地使用这些偏见。然而，一个问题出现了：这种额外的复杂性真的有必要吗？一个普通训练的模型是否已经包含了一些可以独立使用的“无偏子网络”，并且可以提出一个解决方案而不依赖于算法偏见？在这项工作中，我们展示了这样的子网络通常存在，并且可以从一个普通训练的模型中提取出来，而无需额外的训练。我们进一步验证了这种特定的架构无法学习特定的偏见，表明在深度神经网络中有可能通过架构上的对策来解决偏见问题。

    arXiv:2403.14200v1 Announce Type: cross  Abstract: Nowadays an ever-growing concerning phenomenon, the emergence of algorithmic biases that can lead to unfair models, emerges. Several debiasing approaches have been proposed in the realm of deep learning, employing more or less sophisticated approaches to discourage these models from massively employing these biases. However, a question emerges: is this extra complexity really necessary? Is a vanilla-trained model already embodying some ``unbiased sub-networks'' that can be used in isolation and propose a solution without relying on the algorithmic biases? In this work, we show that such a sub-network typically exists, and can be extracted from a vanilla-trained model without requiring additional training. We further validate that such specific architecture is incapable of learning a specific bias, suggesting that there are possible architectural countermeasures to the problem of biases in deep neural networks.
    
[^56]: 芯片上的量子激活神经水库为具有弹性身份验证的大型硬件安全模型打开了大门

    Quantum-activated neural reservoirs on-chip open up large hardware security models for resilient authentication

    [https://arxiv.org/abs/2403.14188](https://arxiv.org/abs/2403.14188)

    该研究在芯片上实现了一个大规模量子激活神经水库，使网络规模和功耗均大幅提高，可用于实现具有弹性身份验证功能的大型硬件安全模型

    

    arXiv:2403.14188v1 公告类型：交叉摘要：量子人工智能是人工智能研究的前沿，开创性地利用量子人工智能电路解决深度学习和经典架构无法解决的问题。该工作实现了一个大规模的量子激活循环神经网络，拥有超过3万亿硬件节点/平方厘米，源于芯片上集成的非晶材料中可重复的原子尺度成核动态，每个读取通道的控制电力为0.07 nW。与目前报道的表现最好的水库相比，该实施将网络规模提高了两个数量级，并将功耗降低了六倍，达到了人脑功率效率范围，每个神经元消耗0.2 nW。当由经典输入审问时，芯片实现了一个大规模的硬件安全模型，实现了免词典身份验证，可以抵抗统计

    arXiv:2403.14188v1 Announce Type: cross  Abstract: Quantum artificial intelligence is a frontier of artificial intelligence research, pioneering quantum AI-powered circuits to address problems beyond the reach of deep learning with classical architectures. This work implements a large-scale quantum-activated recurrent neural network possessing more than 3 trillion hardware nodes/cm$^2$, originating from repeatable atomic-scale nucleation dynamics in an amorphous material integrated on-chip, controlled with 0.07 nW electric power per readout channel. Compared to the best-performing reservoirs currently reported, this implementation increases the scale of the network by two orders of magnitude and reduces the power consumption by six, reaching power efficiencies in the range of the human brain, dissipating 0.2 nW/neuron. When interrogated by a classical input, the chip implements a large-scale hardware security model, enabling dictionary-free authentication secure against statistical inf
    
[^57]: 使用预训练StyleGAN生成风格电影图景

    StyleCineGAN: Landscape Cinemagraph Generation using a Pre-trained StyleGAN

    [https://arxiv.org/abs/2403.14186](https://arxiv.org/abs/2403.14186)

    提出了一种利用预训练StyleGAN自动生成静止风景图像的电影图景方法，通过利用深层特征空间和多尺度深度特征扭曲（MSDFW）生成高分辨率且具有合理循环动画的电影图景，并证明了该方法的优越性

    

    我们提出一种方法，可以使用预训练的StyleGAN自动生成静止风景图像的电影图景。受到最近无条件视频生成成功的启发，我们利用强大的预训练图像生成器来合成高质量的电影图景。与先前主要利用预训练StyleGAN的潜在空间的方法不同，我们的方法利用其深层特征空间进行GAN反演和电影图景生成。具体来说，我们提出了多尺度深度特征扭曲（MSDFW），它在不同分辨率下扭曲了预训练StyleGAN的中间特征。通过使用MSDFW，生成的电影图景具有高分辨率，并展示出合理的循环动画。通过用户研究和与最先进的电影图景生成方法以及使用预训练StyleGAN的视频生成方法的定量比较，我们证明了我们方法的优越性。

    arXiv:2403.14186v1 Announce Type: cross  Abstract: We propose a method that can generate cinemagraphs automatically from a still landscape image using a pre-trained StyleGAN. Inspired by the success of recent unconditional video generation, we leverage a powerful pre-trained image generator to synthesize high-quality cinemagraphs. Unlike previous approaches that mainly utilize the latent space of a pre-trained StyleGAN, our approach utilizes its deep feature space for both GAN inversion and cinemagraph generation. Specifically, we propose multi-scale deep feature warping (MSDFW), which warps the intermediate features of a pre-trained StyleGAN at different resolutions. By using MSDFW, the generated cinemagraphs are of high resolution and exhibit plausible looping animation. We demonstrate the superiority of our method through user studies and quantitative comparisons with state-of-the-art cinemagraph generation methods and a video generation method that uses a pre-trained StyleGAN.
    
[^58]: OTSeg：多提示Sinkhorn注意力用于零样本语义分割

    OTSeg: Multi-prompt Sinkhorn Attention for Zero-Shot Semantic Segmentation

    [https://arxiv.org/abs/2403.14183](https://arxiv.org/abs/2403.14183)

    通过引入OTSeg中的Multi-Prompts Sinkhorn Attention机制，能够更好地利用多个文本提示来匹配相关像素嵌入，从而提升零样本语义分割性能。

    

    CLIP的最新成功证明了通过将多模态知识转移到像素级分类来进行零样本语义分割的有希望的结果。然而，在现有方法中，利用预先训练的CLIP知识来紧密对齐文本嵌入和像素嵌入仍然存在局限性。为了解决这个问题，我们提出了OTSeg，这是一种新颖的多模态注意力机制，旨在增强多个文本提示匹配相关像素嵌入的潜力。我们首先提出了基于最优输运（OT）算法的多提示Sinkhorn（MPS），这使得多个文本提示可以有选择地关注图像像素内的各种语义特征。此外，受到Sinkformers在单模态设置中的成功启发，我们引入了MPS的扩展，称为多提示Sinkhorn注意力（MPSA），它有效地取代了Transformer框架中多模态设置中的交叉注意力机制。

    arXiv:2403.14183v1 Announce Type: cross  Abstract: The recent success of CLIP has demonstrated promising results in zero-shot semantic segmentation by transferring muiltimodal knowledge to pixel-level classification. However, leveraging pre-trained CLIP knowledge to closely align text embeddings with pixel embeddings still has limitations in existing approaches. To address this issue, we propose OTSeg, a novel multimodal attention mechanism aimed at enhancing the potential of multiple text prompts for matching associated pixel embeddings. We first propose Multi-Prompts Sinkhorn (MPS) based on the Optimal Transport (OT) algorithm, which leads multiple text prompts to selectively focus on various semantic features within image pixels. Moreover, inspired by the success of Sinkformers in unimodal settings, we introduce the extension of MPS, called Multi-Prompts Sinkhorn Attention (MPSA), which effectively replaces cross-attention mechanisms within Transformer framework in multimodal settin
    
[^59]: 利用基于大型语言模型的房间-物体关系知识增强多模态输入的目标导航

    Leveraging Large Language Model-based Room-Object Relationships Knowledge for Enhancing Multimodal-Input Object Goal Navigation

    [https://arxiv.org/abs/2403.14163](https://arxiv.org/abs/2403.14163)

    提出了一种基于大型语言模型的房间-物体关系知识的数据驱动、模块化方法，利用多通道Swin-Unet架构进行多任务学习，以增强多模态输入的目标导航。

    

    物体目标导航是具有身体封装导航任务的一个关键工程任务；它涉及在看不见的环境中导航到指定物体类别的一个实例。尽管在端到端和模块化的数据驱动方法上进行了大量研究，但要完全使代理人通过感知知识理解环境并像人类一样有效地执行物体目标导航仍然是一个重大挑战。最近，大型语言模型在这一任务中显示出潜力，这要归功于它们在知识提取和整合方面的强大能力。在这项研究中，我们提出了一种基于数据驱动的模块化方法，该方法在数据集上进行训练，该数据集包含从大型语言模型提取的对象-房间关系的常识知识。我们利用多通道Swin-Unet架构进行多任务学习，同时结合多模态输入。

    arXiv:2403.14163v1 Announce Type: cross  Abstract: Object-goal navigation is a crucial engineering task for the community of embodied navigation; it involves navigating to an instance of a specified object category within unseen environments. Although extensive investigations have been conducted on both end-to-end and modular-based, data-driven approaches, fully enabling an agent to comprehend the environment through perceptual knowledge and perform object-goal navigation as efficiently as humans remains a significant challenge. Recently, large language models have shown potential in this task, thanks to their powerful capabilities for knowledge extraction and integration. In this study, we propose a data-driven, modular-based approach, trained on a dataset that incorporates common-sense knowledge of object-to-room relationships extracted from a large language model. We utilize the multi-channel Swin-Unet architecture to conduct multi-task learning incorporating with multimodal inputs.
    
[^60]: 具有前瞻特性的策略镜像下降算法

    Policy Mirror Descent with Lookahead

    [https://arxiv.org/abs/2403.14156](https://arxiv.org/abs/2403.14156)

    提出了一种新类别的策略镜像下降算法$h$-PMD，它通过在PMD更新规则中结合多步贪心策略改进和前瞻深度$h，以解决折扣无限时间视角下的马尔可夫决策过程。

    

    策略镜像下降（PMD）作为一种多功能算法框架，包括几种重要的策略梯度算法，如自然策略梯度，并与最先进的强化学习（RL）算法（如TRPO和PPO）相联系。PMD可以看作是实现正则化1步贪心策略改进的软策略迭代算法。然而，1步贪心策略可能不是最佳选择，最近在RL领域取得了显着的实证成功，如AlphaGo和AlphaZero已经证明，相对于多步骤，贪心方法可以超越它们的1步骤对应物。在这项工作中，我们提出了一种新类别的PMD算法，称为$h$-PMD，它将具有前瞻深度$h$的多步贪心策略改进结合到PMD更新规则中。为了解决折扣无限时间视角下的马尔可夫决策过程，其中折扣因子为$\gamma$，我们展示了$h$-PMD可以推广标准的PMD。

    arXiv:2403.14156v1 Announce Type: cross  Abstract: Policy Mirror Descent (PMD) stands as a versatile algorithmic framework encompassing several seminal policy gradient algorithms such as natural policy gradient, with connections with state-of-the-art reinforcement learning (RL) algorithms such as TRPO and PPO. PMD can be seen as a soft Policy Iteration algorithm implementing regularized 1-step greedy policy improvement. However, 1-step greedy policies might not be the best choice and recent remarkable empirical successes in RL such as AlphaGo and AlphaZero have demonstrated that greedy approaches with respect to multiple steps outperform their 1-step counterpart. In this work, we propose a new class of PMD algorithms called $h$-PMD which incorporates multi-step greedy policy improvement with lookahead depth $h$ to the PMD update rule. To solve discounted infinite horizon Markov Decision Processes with discount factor $\gamma$, we show that $h$-PMD which generalizes the standard PMD enj
    
[^61]: 轨迹数据管理与挖掘的深度学习：调查与展望

    Deep Learning for Trajectory Data Management and Mining: A Survey and Beyond

    [https://arxiv.org/abs/2403.14151](https://arxiv.org/abs/2403.14151)

    本文综述了深度学习在轨迹数据管理与挖掘中的发展和最新进展，探讨了其在预处理、存储、分析、预测、推荐、分类、估计和检测等方面的应用。

    

    arXiv:2403.14151v1 公告类型：跨越 抽象：轨迹计算是一个重要的领域，涵盖轨迹数据管理和挖掘，因其在诸如位置服务、城市交通和公共安全等各种实际应用中的关键作用而受到广泛关注。传统方法侧重于简单的时空特征，面临复杂计算、有限的可扩展性和不足以适应现实复杂性的挑战。在本文中，我们对轨迹计算中深度学习的发展和最新进展进行了全面的回顾（DL4Traj）。我们首先定义轨迹数据，并简要介绍了广泛使用的深度学习模型。系统地探讨了深度学习在轨迹管理（预处理、存储、分析和可视化）和挖掘（与轨迹相关的预测、轨迹相关的推荐、轨迹分类、旅行时间估计、异常检测）

    arXiv:2403.14151v1 Announce Type: cross  Abstract: Trajectory computing is a pivotal domain encompassing trajectory data management and mining, garnering widespread attention due to its crucial role in various practical applications such as location services, urban traffic, and public safety. Traditional methods, focusing on simplistic spatio-temporal features, face challenges of complex calculations, limited scalability, and inadequate adaptability to real-world complexities. In this paper, we present a comprehensive review of the development and recent advances in deep learning for trajectory computing (DL4Traj). We first define trajectory data and provide a brief overview of widely-used deep learning models. Systematically, we explore deep learning applications in trajectory management (pre-processing, storage, analysis, and visualization) and mining (trajectory-related forecasting, trajectory-related recommendation, trajectory classification, travel time estimation, anomaly detecti
    
[^62]: 通过遗传规划演化基准函数来比较进化算法

    Evolving Benchmark Functions to Compare Evolutionary Algorithms via Genetic Programming

    [https://arxiv.org/abs/2403.14146](https://arxiv.org/abs/2403.14146)

    通过遗传规划生成的基准函数能够更好地区分算法，进一步实现了自动设计基准函数和比较进化算法的目的。

    

    在这项研究中，我们使用遗传规划（GP）来构建新的优化基准函数。优化基准在展示进化算法之间的差异方面起着重要作用，使进一步的分析和比较成为可能。我们展示了由GP生成的基准能够比人工制作的基准更好地区分算法。GP的适应度衡量是一对优化器找到的解的Wasserstein距离。此外，我们使用MAP-Elites来增强GP的搜索能力，并展示了优化器之间的差异如何随着各种景观特征的改变而改变。我们的方法提供了一种新颖的自动化设计基准函数和比较进化算法的方式。

    arXiv:2403.14146v1 Announce Type: cross  Abstract: In this study, we use Genetic Programming (GP) to compose new optimization benchmark functions. Optimization benchmarks have the important role of showing the differences between evolutionary algorithms, making it possible for further analysis and comparisons. We show that the benchmarks generated by GP are able to differentiate algorithms better than human-made benchmark functions. The fitness measure of the GP is the Wasserstein distance of the solutions found by a pair of optimizers. Additionally, we use MAP-Elites to both enhance the search power of the GP and also illustrate how the difference between optimizers changes by various landscape features. Our approach provides a novel way to automate the design of benchmark functions and to compare evolutionary algorithms.
    
[^63]: 用迭代幅值剪枝推进工业物联网的联邦学习

    Advancing IIoT with Over-the-Air Federated Learning: The Role of Iterative Magnitude Pruning

    [https://arxiv.org/abs/2403.14120](https://arxiv.org/abs/2403.14120)

    联邦学习在工业物联网中的应用促进了机器学习和数据隐私，本文提出了一种用于提升PIUs性能的迭代幅值剪枝技术。

    

    工业物联网（IIoT）在工业4.0的背景下迎来了一种互联的智能设备时代，数据驱动的见解和机器学习（ML）融合，彻底改变了制造业。 IIoT中一个值得关注的发展是联邦学习（FL）的整合，该技术解决了设备之间数据隐私和安全性的问题。 FL使边缘传感器（也称为外围智能单元（PIUs））能够使用本地数据进行学习和适应，无需显式共享机密数据，从而促进协作但机密的学习过程。然而，PIUs较低的内存占用和计算能力固有地需要具有非常紫紧凑尺寸的深度神经网络（DNN）模型。剪枝等模型压缩技术可用于通过移除对模型性能影响较小的不必要连接来减小DNN模型的大小，从而使模型更适合有限的环境。

    arXiv:2403.14120v1 Announce Type: cross  Abstract: The industrial Internet of Things (IIoT) under Industry 4.0 heralds an era of interconnected smart devices where data-driven insights and machine learning (ML) fuse to revolutionize manufacturing. A noteworthy development in IIoT is the integration of federated learning (FL), which addresses data privacy and security among devices. FL enables edge sensors, also known as peripheral intelligence units (PIUs) to learn and adapt using their data locally, without explicit sharing of confidential data, to facilitate a collaborative yet confidential learning process. However, the lower memory footprint and computational power of PIUs inherently require deep neural network (DNN) models that have a very compact size. Model compression techniques such as pruning can be used to reduce the size of DNN models by removing unnecessary connections that have little impact on the model's performance, thus making the models more suitable for the limited 
    
[^64]: C-TPT：通过文本特征离散性的校准测试时提示调整视觉-语言模型

    C-TPT: Calibrated Test-Time Prompt Tuning for Vision-Language Models via Text Feature Dispersion

    [https://arxiv.org/abs/2403.14119](https://arxiv.org/abs/2403.14119)

    本文研究了在测试时提示调整过程中通过利用CLIP的固有属性来探讨校准的方法，发现提示选择显著影响了CLIP中的校准，其中导致更高文本特征离散性的提示会产生更好校准的预测。

    

    在深度学习中，测试时适应已经引起了人们的关注，作为一种在不需要标记数据的情况下对模型进行微调的方法。一个主要的例证是最近提出的用于大规模视觉-语言模型（如CLIP）的测试时提示调整。然而，这些提示主要是为了提高准确性而开发的，忽视了校准的重要性——量化预测不确定性的关键方面。然而，传统的校准方法依赖大量标记数据，这使得它们在测试时场景下不切实际。为此，本文通过利用CLIP的固有属性，在测试时提示调整过程中探讨校准。通过一系列观察，我们发现提示选择显著影响了CLIP中的校准，其中导致更高文本特征离散性的提示会产生更好校准的预测。

    arXiv:2403.14119v1 Announce Type: cross  Abstract: In deep learning, test-time adaptation has gained attention as a method for model fine-tuning without the need for labeled data. A prime exemplification is the recently proposed test-time prompt tuning for large-scale vision-language models such as CLIP. Unfortunately, these prompts have been mainly developed to improve accuracy, overlooking the importance of calibration-a crucial aspect for quantifying prediction uncertainty. However, traditional calibration methods rely on substantial amounts of labeled data, making them impractical for test-time scenarios. To this end, this paper explores calibration during test-time prompt tuning by leveraging the inherent properties of CLIP. Through a series of observations, we find that the prompt choice significantly affects the calibration in CLIP, where the prompts leading to higher text feature dispersion result in better-calibrated predictions. Introducing the Average Text Feature Dispersion
    
[^65]: 基于启发式算法动作屏蔽的强化学习（HAAM-RL）与集成推断方法

    Heuristic Algorithm-based Action Masking Reinforcement Learning (HAAM-RL) with Ensemble Inference Method

    [https://arxiv.org/abs/2403.14110](https://arxiv.org/abs/2403.14110)

    HAAM-RL方法结合了启发式算法动作屏蔽和集成推断方法，用于优化汽车喷漆过程中的颜色批处理重新排序问题，实验结果表明取得了16.25%的性能提升。

    

    本文介绍了一种名为HAAM-RL（基于启发式算法动作屏蔽的强化学习）的新型强化学习（RL）方法，用于优化汽车喷漆过程中的颜色批处理重新排序问题。我们的方法结合了多个关键技术，包括定制的马尔可夫决策过程（MDP）形式化，奖励设置包括基于潜力的奖励塑造，使用启发式算法进行动作屏蔽（HAAM-RL），以及一个结合多个RL模型的集成推断方法。实验结果表明，HAAM-RL与集成推断方法在30个场景中取得了16.25%的性能提升。

    arXiv:2403.14110v1 Announce Type: cross  Abstract: This paper presents a novel reinforcement learning (RL) approach called HAAM-RL (Heuristic Algorithm-based Action Masking Reinforcement Learning) for optimizing the color batching re-sequencing problem in automobile painting processes. The existing heuristic algorithms have limitations in adequately reflecting real-world constraints and accurately predicting logistics performance. Our methodology incorporates several key techniques including a tailored Markov Decision Process (MDP) formulation, reward setting including Potential-Based Reward Shaping, action masking using heuristic algorithms (HAAM-RL), and an ensemble inference method that combines multiple RL models. The RL agent is trained and evaluated using FlexSim, a commercial 3D simulation software, integrated with our RL MLOps platform BakingSoDA. Experimental results across 30 scenarios demonstrate that HAAM-RL with an ensemble inference method achieves a 16.25% performance im
    
[^66]: DouRN: 通过残差神经网络改进DouZero

    DouRN: Improving DouZero by Residual Neural Networks

    [https://arxiv.org/abs/2403.14102](https://arxiv.org/abs/2403.14102)

    通过在DouZero模型中引入残差网络，并探索不同的架构设计，我们显著提高了斗地主游戏中获胜率。

    

    深度强化学习在具有不完全信息的游戏中取得了显著进展，但在卡牌游戏斗地主方面的表现仍然令人不满意。斗地主不同于传统游戏，它涉及三名玩家，结合了合作和对抗的元素，导致状态空间和动作空间较大。2021年，一款名为DouZero的斗地主程序通过利用传统的蒙特卡洛方法和多层感知器，超越了以往没有先验知识的模型。在此基础上，我们的研究将残差网络纳入模型中，探索不同的架构设计，并进行多角色测试。我们的发现表明，该模型在相同的训练时间内显著提高了获胜率。此外，我们引入了一个呼叫得分系统，帮助代理决定是否成为地主。

    arXiv:2403.14102v1 Announce Type: new  Abstract: Deep reinforcement learning has made significant progress in games with imperfect information, but its performance in the card game Doudizhu (Chinese Poker/Fight the Landlord) remains unsatisfactory. Doudizhu is different from conventional games as it involves three players and combines elements of cooperation and confrontation, resulting in a large state and action space. In 2021, a Doudizhu program called DouZero\cite{zha2021douzero} surpassed previous models without prior knowledge by utilizing traditional Monte Carlo methods and multilayer perceptrons. Building on this work, our study incorporates residual networks into the model, explores different architectural designs, and conducts multi-role testing. Our findings demonstrate that this model significantly improves the winning rate within the same training time. Additionally, we introduce a call scoring system to assist the agent in deciding whether to become a landlord. With these
    
[^67]: 因果知识工程：COVID-19的一个案例研究

    Causal knowledge engineering: A case study from COVID-19

    [https://arxiv.org/abs/2403.14100](https://arxiv.org/abs/2403.14100)

    该研究提出了一种名为因果知识工程（CKE）的方法，在COVID-19背景下开发了一个因果知识库，支持了各种特定应用模型的建立。

    

    COVID-19在2020年初突然出现，需要在巨大不确定性的背景下迅速应对。最初缺乏高质量的数据和知识，许多早期模型必须建立在因果假设和估计的基础上，以补充有限的数据，通常没有可靠的方法来识别、验证和记录这些因果假设。我们的团队着手进行知识工程过程，开发了一个包含多个COVID-19不同方面因果贝叶斯网络的因果知识库。该环境的独特挑战导致对调查方法进行实验，结果形成了我们称之为因果知识工程（CKE）的知识工程方法。CKE提供了一种结构化方法来构建因果知识库，可以支持开发各种特定应用模型的工作。在这里，我们描述了CKE方法，并以我们的COVID-19工作作为案例研究。

    arXiv:2403.14100v1 Announce Type: new  Abstract: COVID-19 appeared abruptly in early 2020, requiring a rapid response amid a context of great uncertainty. Good quality data and knowledge was initially lacking, and many early models had to be developed with causal assumptions and estimations built in to supplement limited data, often with no reliable approach for identifying, validating and documenting these causal assumptions. Our team embarked on a knowledge engineering process to develop a causal knowledge base consisting of several causal BNs for diverse aspects of COVID-19. The unique challenges of the setting lead to experiments with the elicitation approach, and what emerged was a knowledge engineering method we call Causal Knowledge Engineering (CKE). The CKE provides a structured approach for building a causal knowledge base that can support the development of a variety of application-specific models. Here we describe the CKE method, and use our COVID-19 work as a case study to
    
[^68]: 可持续数据中心实时减少碳足迹

    Carbon Footprint Reduction for Sustainable Data Centers in Real-Time

    [https://arxiv.org/abs/2403.14092](https://arxiv.org/abs/2403.14092)

    我们提出了一种Data Center Carbon Footprint Reduction (DC-CFR) 多代理强化学习（MARL）框架，旨在实时优化数据中心以减少碳足迹。

    

    随着机器学习工作负载显著增加能源消耗，碳排放低的可持续数据中心正成为全球政府和企业关注的重点。为了实现这一目标，需要在冷却和IT负载中进行功耗优化的范式转变，基于可再生能源在电网中的可用性来调整灵活负载，利用数据中心不间断电源中的电池存储，使用协作代理。这些优化策略之间的复杂关系以及它们对变化的外部因素（如天气和电网碳排放强度）的依赖使得这是一个困难的问题。目前缺乏一个能够在动态实际环境中同时优化所有这些目标的实时控制器。我们提出了一种数据中心碳足迹减少（DC-CFR）多代理强化学习（MARL）框架，能够优化多个角度的数据中心。

    arXiv:2403.14092v1 Announce Type: cross  Abstract: As machine learning workloads significantly increase energy consumption, sustainable data centers with low carbon emissions are becoming a top priority for governments and corporations worldwide. This requires a paradigm shift in optimizing power consumption in cooling and IT loads, shifting flexible loads based on the availability of renewable energy in the power grid, and leveraging battery storage from the uninterrupted power supply in data centers, using collaborative agents. The complex association between these optimization strategies and their dependencies on variable external factors like weather and the power grid carbon intensity makes this a hard problem. Currently, a real-time controller to optimize all these goals simultaneously in a dynamic real-world setting is lacking. We propose a Data Center Carbon Footprint Reduction (DC-CFR) multi-agent Reinforcement Learning (MARL) framework that optimizes data centers for the mult
    
[^69]: 聊天GPT能够检测DeepFakes吗？使用多模态大型语言模型进行媒体取证的研究

    Can ChatGPT Detect DeepFakes? A Study of Using Multimodal Large Language Models for Media Forensics

    [https://arxiv.org/abs/2403.14077](https://arxiv.org/abs/2403.14077)

    本研究探讨了使用多模态大型语言模型（LLMs）进行DeepFake检测的能力，通过实验证明它们能够揭示AI生成的图像，尽管LLMs并非专为媒体取证任务设计，这一发现具有重要意义。

    

    DeepFakes是指由人工智能生成的媒体内容，由于其被用作散布虚假信息的手段，已经成为越来越令人担忧的问题。当前检测DeepFakes的方法是利用编程的机器学习算法。本研究调查了多模态大型语言模型（LLMs）在DeepFake检测中的能力。通过定性和定量实验，我们展示了多模态LLMs可以通过谨慎的实验设计和及时的工程方法揭示AI生成的图像。考虑到LLMs并不是本质上为媒体取证任务量身定制的，这一点相当有趣，而且这个过程并不需要编程。我们讨论了多模态LLMs在这些任务中的局限性，并提出了可能的改进方向。

    arXiv:2403.14077v1 Announce Type: new  Abstract: DeepFakes, which refer to AI-generated media content, have become an increasing concern due to their use as a means for disinformation. Detecting DeepFakes is currently solved with programmed machine learning algorithms. In this work, we investigate the capabilities of multimodal large language models (LLMs) in DeepFake detection. We conducted qualitative and quantitative experiments to demonstrate multimodal LLMs and show that they can expose AI-generated images through careful experimental design and prompt engineering. This is interesting, considering that LLMs are not inherently tailored for media forensic tasks, and the process does not require programming. We discuss the limitations of multimodal LLMs for these tasks and suggest possible improvements.
    
[^70]: 朝自动化和受监管的机器人系统之路

    A Roadmap Towards Automated and Regulated Robotic Systems

    [https://arxiv.org/abs/2403.14049](https://arxiv.org/abs/2403.14049)

    生成技术的快速发展为更高级别的自动化开启新可能性，作者提出了一个朝向完全自动化和受监管的机器人系统的路线图。

    

    生成技术的快速发展为更高级别的自动化打开了可能性，并且人工智能在机器人系统中的具体体现势在必行。然而，由于生成技术的黑匣子特性，知识和工作流程方案的生成是不受控制的，尤其在动态环境和复杂场景中。这对医疗场景等安全要求高的应用的监管提出了挑战。我们认为，来自人工智能的未受监管生成过程适用于低级端任务，但干预形式应当发生在工作流程生成后和机器人执行前，可以是手动形式也可以是自动化形式。为了解决这个问题，我们提出了一条路线图，可以引领我们走向完全自动化和受监管的机器人系统。在这种范式中，高级政策被生成为结构化图数据，从而实现监管监督和重复利用，而为较低级别的代码基础。

    arXiv:2403.14049v1 Announce Type: cross  Abstract: The rapid development of generative technology opens up possibility for higher level of automation, and artificial intelligence (AI) embodiment in robotic systems is imminent. However, due to the blackbox nature of the generative technology, the generation of the knowledge and workflow scheme is uncontrolled, especially in a dynamic environment and a complex scene. This poses challenges to regulations in safety-demanding applications such as medical scenes. We argue that the unregulated generative processes from AI is fitted for low level end tasks, but intervention in the form of manual or automated regulation should happen post-workflow-generation and pre-robotic-execution. To address this, we propose a roadmap that can lead to fully automated and regulated robotic systems. In this paradigm, the high level policies are generated as structured graph data, enabling regulatory oversight and reusability, while the code base for lower lev
    
[^71]: Ax-to-Grind Urdu: 乌尔都语虚假新闻检测的基准数据集

    Ax-to-Grind Urdu: Benchmark Dataset for Urdu Fake News Detection

    [https://arxiv.org/abs/2403.14037](https://arxiv.org/abs/2403.14037)

    本文提出了乌尔都语虚假新闻检测的首个最大规模公开数据集，填补了地区语言虚假新闻检测领域数据集规模有限的空白。

    

    误传信息可能严重影响社会，影响从公众舆论到机构信心和一个国家的政治前景等各个方面。在线网站和在线社交网络上的虚假新闻传播呈现大量增长。各种事实核查网站的新闻主要以英语发布，几乎不提供有关地区语言虚假新闻的信息。因此，无法通过事实核查门户网站来识别乌尔都语虚假新闻传播者。虚假新闻检测(SOTA)方法依赖于适当标记和大规模数据集。地区和资源受限语言的虚假新闻检测由于数据集规模有限和合法词汇资源的缺乏而滞后。先前用于乌尔都语虚假新闻检测的数据集规模有限、领域受限、不公开且未经人工验证，其中新闻是从英语翻译为乌尔都语。本文策划并贡献了首个最大规模的公开可用的乌尔都语数据集。

    arXiv:2403.14037v1 Announce Type: cross  Abstract: Misinformation can seriously impact society, affecting anything from public opinion to institutional confidence and the political horizon of a state. Fake News (FN) proliferation on online websites and Online Social Networks (OSNs) has increased profusely. Various fact-checking websites include news in English and barely provide information about FN in regional languages. Thus the Urdu FN purveyors cannot be discerned using factchecking portals. SOTA approaches for Fake News Detection (FND) count upon appropriately labelled and large datasets. FND in regional and resource-constrained languages lags due to the lack of limited-sized datasets and legitimate lexical resources. The previous datasets for Urdu FND are limited-sized, domain-restricted, publicly unavailable and not manually verified where the news is translated from English into Urdu. In this paper, we curate and contribute the first largest publicly available dataset for Urdu 
    
[^72]: 搜索搜索空间：元演变神经网络的几何编码

    Searching Search Spaces: Meta-evolving a Geometric Encoding for Neural Networks

    [https://arxiv.org/abs/2403.14019](https://arxiv.org/abs/2403.14019)

    通过使用笛卡尔遗传规划（CGP）的元演化方法，优化了神经网络Evolution的几何编码（GENE）, 找到更有效的距离函数，创建一个更易于利用的搜索空间。

    

    在进化策略搜索中，神经网络通常使用直接映射来表示：每个基因编码一个网络权重。间接编码方法，其中每个基因可以编码多个权重，将基因组缩短以减少搜索空间的维数，并更好地利用排列和对称性。神经网络Evolution的几何编码（GENE）引入了一种间接编码方法，其中连接的权重被计算为两个连接神经元之间的（伪）距离，使基因组大小随着基因数量线性增长，而不是在直接编码中呈二次增长。然而，GENE仍然依赖于手工设计的距离函数，并没有进行优化。在这里，我们展示了可以使用笛卡尔遗传规划（CGP）找到更好的性能距离函数，从而在元演化方法中优化GENE的编码，从而创建一个更容易利用的搜索空间。

    arXiv:2403.14019v1 Announce Type: cross  Abstract: In evolutionary policy search, neural networks are usually represented using a direct mapping: each gene encodes one network weight. Indirect encoding methods, where each gene can encode for multiple weights, shorten the genome to reduce the dimensions of the search space and better exploit permutations and symmetries. The Geometric Encoding for Neural network Evolution (GENE) introduced an indirect encoding where the weight of a connection is computed as the (pseudo-)distance between the two linked neurons, leading to a genome size growing linearly with the number of genes instead of quadratically in direct encoding. However GENE still relies on hand-crafted distance functions with no prior optimization. Here we show that better performing distance functions can be found for GENE using Cartesian Genetic Programming (CGP) in a meta-evolution approach, hence optimizing the encoding to create a search space that is easier to exploit. We 
    
[^73]: 论ChatGPT在情感计算中的提示敏感性

    On Prompt Sensitivity of ChatGPT in Affective Computing

    [https://arxiv.org/abs/2403.14006](https://arxiv.org/abs/2403.14006)

    该研究介绍了一个用于评估基础模型性能敏感性的方法，针对ChatGPT在情感计算中的提示敏感性进行了研究和评估，涵盖情绪分析、毒性检测和讽刺检测。

    

    最近的研究已经展示了像ChatGPT这样的基础模型在多个领域，包括情感计算中的新兴能力。然而，访问这些新兴能力是通过提示工程来实现的。尽管存在一些提示技术，但该领域仍在迅速发展，许多提示想法仍需要调查。在这项工作中，我们介绍了一种方法，用于评估并调查基于不同提示或生成参数的基础模型性能的敏感性。我们在情感计算范围内针对ChatGPT执行我们的评估，解决了三个主要问题，即情绪分析、毒性检测和讽刺检测。首先，我们对自回归文本生成中的关键参数进行了敏感性分析，特别是温度参数$T$和Nucleus抽样中的top-$p$参数，指导着保守或创造性

    arXiv:2403.14006v1 Announce Type: cross  Abstract: Recent studies have demonstrated the emerging capabilities of foundation models like ChatGPT in several fields, including affective computing. However, accessing these emerging capabilities is facilitated through prompt engineering. Despite the existence of some prompting techniques, the field is still rapidly evolving and many prompting ideas still require investigation. In this work, we introduce a method to evaluate and investigate the sensitivity of the performance of foundation models based on different prompts or generation parameters. We perform our evaluation on ChatGPT within the scope of affective computing on three major problems, namely sentiment analysis, toxicity detection, and sarcasm detection. First, we carry out a sensitivity analysis on pivotal parameters in auto-regressive text generation, specifically the temperature parameter $T$ and the top-$p$ parameter in Nucleus sampling, dictating how conservative or creative
    
[^74]: 这并非一个数据问题：算法与权力在加拿大公立高等教育中的应用

    "This is not a data problem": Algorithms and Power in Public Higher Education in Canada

    [https://arxiv.org/abs/2403.13969](https://arxiv.org/abs/2403.13969)

    研究揭示了公立高等教育中算法决策的影响，包括学生监视增加、不平等加剧和教师-学生关系的自动化。

    

    算法决策在公立高等教育中日益被采用。高等教育机构的数据驱动实践扩展与新公共管理方法在新自由主义政府的推动下同步进行。本研究对加拿大安大略省一个公立学院数据和算法的深度民族志案例进行了定性分析。我们确定了学院使用的数据、算法和结果。我们评估了学院的流程和关系如何支持这些结果，以及不同利益相关者对学院数据驱动系统的看法。此外，我们发现日益依赖算法决策导致学生监视增加，现有不平等加剧，并导致教师-学生关系的自动化。最后，我们确定了由算法决策延续的增加制度权力的循环。

    arXiv:2403.13969v1 Announce Type: cross  Abstract: Algorithmic decision-making is increasingly being adopted across public higher education. The expansion of data-driven practices by post-secondary institutions has occurred in parallel with the adoption of New Public Management approaches by neoliberal administrations. In this study, we conduct a qualitative analysis of an in-depth ethnographic case study of data and algorithms in use at a public college in Ontario, Canada. We identify the data, algorithms, and outcomes in use at the college. We assess how the college's processes and relationships support those outcomes and the different stakeholders' perceptions of the college's data-driven systems. In addition, we find that the growing reliance on algorithmic decisions leads to increased student surveillance, exacerbation of existing inequities, and the automation of the faculty-student relationship. Finally, we identify a cycle of increased institutional power perpetuated by algorit
    
[^75]: 开放获取NAO（OAN）：基于ROS2的软件框架，用于与NAO机器人进行HRI应用

    Open Access NAO (OAN): a ROS2-based software framework for HRI applications with the NAO robot

    [https://arxiv.org/abs/2403.13960](https://arxiv.org/abs/2403.13960)

    本文提出了一个新的基于ROS2的软件框架，使得NAO机器人具有更好性能和新功能，包括人形机器人的基本技能和常用于HRI的功能，并且该框架是可立即使用且高度可扩展的工具。

    

    本文提出了一个新的软件框架，用于与由联合机器人集团生产的常见NAO机器人的HRI实验。作者利用在NAO上可以运行ROS2的能力，开发了一个独立于制造商提供的API的框架，以满足研究人员对NAO更好性能和新功能的共同需求。该系统不仅为NAO提供了人形机器人的基本技能，如行走和复制感兴趣的动作，还具有常用于HRI的功能，如：语音识别/合成、人脸和物体检测，以及使用预训练的生成式变换器（GPT）模型进行对话。开发的代码因此被配置为一个可立即使用，同时也是一个高度可扩展和可改进的工具，这要归功于ROS社区提供的可能性。

    arXiv:2403.13960v1 Announce Type: cross  Abstract: This paper presents a new software framework for HRI experimentation with the sixth version of the common NAO robot produced by the United Robotics Group. Embracing the common demand of researchers for better performance and new features for NAO, the authors took advantage of the ability to run ROS2 onboard on the NAO to develop a framework independent of the APIs provided by the manufacturer. Such a system provides NAO with not only the basic skills of a humanoid robot such as walking and reproducing movements of interest but also features often used in HRI such as: speech recognition/synthesis, face and object detention, and the use of Generative Pre-trained Transformer (GPT) models for conversation. The developed code is therefore configured as a ready-to-use but also highly expandable and improvable tool thanks to the possibilities provided by the ROS community.
    
[^76]: ACDG-VTON: 准确且受限的扩散生成用于虚拟试穿

    ACDG-VTON: Accurate and Contained Diffusion Generation for Virtual Try-On

    [https://arxiv.org/abs/2403.13951](https://arxiv.org/abs/2403.13951)

    提出了一种独特的训练方案，限制了扩散训练的范围，有效保留了服装细节，并实现了多服装试穿、分层、风格和鞋子试穿，无需在更高分辨率下进行训练。最终，方法在准确性和质量方面超越了之前的方法。

    

    虚拟试穿（VTON）涉及生成穿着选定服装的人物图像。基于扩散的方法尤其能够生成高质量图像，但往往难以保持输入服装的身份。我们发现这一问题源于扩散训练公式中的细节。为了解决这一问题，我们提出了一种独特的训练方案，限制了扩散训练的范围。我们在训练过程中使用一个与目标图像完全对齐的控制图像。因此，在推理过程中能够准确地保留服装细节。我们展示了我们的方法不仅有效地保留了服装细节，还能够进行分层、风格和鞋子试穿。我们的方法在单个推理周期内运行多服装试穿，并且能够支持高质量的放大生成，而无需在更高分辨率下进行训练。最后，我们展示了我们的方法在准确性和质量方面超越了先前的方法。

    arXiv:2403.13951v1 Announce Type: cross  Abstract: Virtual Try-on (VTON) involves generating images of a person wearing selected garments. Diffusion-based methods, in particular, can create high-quality images, but they struggle to maintain the identities of the input garments. We identified this problem stems from the specifics in the training formulation for diffusion. To address this, we propose a unique training scheme that limits the scope in which diffusion is trained. We use a control image that perfectly aligns with the target image during training. In turn, this accurately preserves garment details during inference. We demonstrate our method not only effectively conserves garment details but also allows for layering, styling, and shoe try-on. Our method runs multi-garment try-on in a single inference cycle and can support high-quality zoomed-in generations without training in higher resolutions. Finally, we show our method surpasses prior methods in accuracy and quality.
    
[^77]: Evo* 2023 -- 晚期摘要集

    Evo* 2023 -- Late-Breaking Abstracts Volume

    [https://arxiv.org/abs/2403.13950](https://arxiv.org/abs/2403.13950)

    Evo* 2023会议收录了关于将不同的生物启发方法（主要是进化计算）应用于解决不同问题（大多为现实世界问题）的研究和初步结果。

    

    arXiv:2403.13950v1 公告类型: 交叉摘要: 该卷收录了提交给在捷克布尔诺举办的Evo* 2023会议的晚期摘要，会议于4月12日至14日举行。这些论文展示了正在进行的研究以及初步结果，探讨了不同生物启发方法（主要是进化计算）在解决不同问题上的应用，其中大多数是现实世界中的问题。

    arXiv:2403.13950v1 Announce Type: cross  Abstract: Volume with the Late-Breaking Abstracts submitted to the Evo* 2023 Conference, held in Brno (Czech Republic), from 12 to 14 of April. These papers present ongoing research and preliminary results investigating on the application of different approaches of Bioinspired Methods (mainly Evolutionary Computation) to different problems, most of them real world ones.
    
[^78]: BlendScape: 通过生成式人工智能实现统一和个性化视频会议环境

    BlendScape: Enabling Unified and Personalized Video-Conferencing Environments through Generative AI

    [https://arxiv.org/abs/2403.13947](https://arxiv.org/abs/2403.13947)

    BlendScape通过生成式人工智能技术实现了用户定制视频会议环境，支持灵活的任务空间表示和多模交互技术，使用户能够快速表达设计意图并设想未来会议中的协作结构。

    

    当今的视频会议工具支持丰富的专业和社交活动，但它们的通用、基于网格的环境无法轻松地适应分布式合作者的各种需求。为了实现最终用户定制，我们开发了BlendScape，这是一个系统，通过利用AI图像生成技术，允许会议参与者构建根据他们的协作背景定制的视频会议环境。BlendScape通过将用户的物理或虚拟背景融合到统一环境中支持任务空间的灵活表示，并实现了多模交互技术以引导生成过程。通过与15名最终用户的评估，我们调查了他们对工作和社交场景的定制偏好。参与者可以快速表达他们对BlendScape的设计意图，并设想使用该系统来组织未来会议中的协作，但也遇到了挑战。

    arXiv:2403.13947v1 Announce Type: cross  Abstract: Today's video-conferencing tools support a rich range of professional and social activities, but their generic, grid-based environments cannot be easily adapted to meet the varying needs of distributed collaborators. To enable end-user customization, we developed BlendScape, a system for meeting participants to compose video-conferencing environments tailored to their collaboration context by leveraging AI image generation techniques. BlendScape supports flexible representations of task spaces by blending users' physical or virtual backgrounds into unified environments and implements multimodal interaction techniques to steer the generation. Through an evaluation with 15 end-users, we investigated their customization preferences for work and social scenarios. Participants could rapidly express their design intentions with BlendScape and envisioned using the system to structure collaboration in future meetings, but experienced challenge
    
[^79]: 从解释器集合中选择反事实解释的多标准方法

    Multi-criteria approach for selecting an explanation from the set of counterfactuals produced by an ensemble of explainers

    [https://arxiv.org/abs/2403.13940](https://arxiv.org/abs/2403.13940)

    本文提出了一种多阶段集成方法，通过多标准分析选择单个反事实，避免了用户测试多种不同解释方法和分析冲突解决方案的困难，提供了一个在多个质量度量上得分很高的妥协方案。

    

    反事实被广泛用于解释机器学习模型的预测，提供获取更理想预测的替代场景。它们可以由多种方法生成，这些方法优化不同、有时是冲突的质量度量，并产生完全不同的解决方案。然而，选择最合适的解释方法和生成的反事实之一并不是一件容易的事情。本文提出使用多阶段集成方法，基于多标准分析来选择单个反事实，而不是强迫用户测试许多不同的解释方法并分析冲突的解决方案。它提供了一个妥协方案，在几个流行的质量度量上得分较高。这种方法利用支配关系和理想点决策辅助方法，从帕累托前沿中选择一个反事实。进行的实验证明了这种方法的有效性。

    arXiv:2403.13940v1 Announce Type: cross  Abstract: Counterfactuals are widely used to explain ML model predictions by providing alternative scenarios for obtaining the more desired predictions. They can be generated by a variety of methods that optimize different, sometimes conflicting, quality measures and produce quite different solutions. However, choosing the most appropriate explanation method and one of the generated counterfactuals is not an easy task. Instead of forcing the user to test many different explanation methods and analysing conflicting solutions, in this paper, we propose to use a multi-stage ensemble approach that will select single counterfactual based on the multiple-criteria analysis. It offers a compromise solution that scores well on several popular quality measures. This approach exploits the dominance relation and the ideal point decision aid method, which selects one counterfactual from the Pareto front. The conducted experiments demonstrated that the propos
    
[^80]: 减少大型语言模型偏见：重点关注“受限行业”的自动数据集增强和偏见量化

    Reducing Large Language Model Bias with Emphasis on 'Restricted Industries': Automated Dataset Augmentation and Prejudice Quantification

    [https://arxiv.org/abs/2403.13925](https://arxiv.org/abs/2403.13925)

    本文提出了一种针对“受限行业”进行自动数据集增强以减少大型语言模型偏见的新机制，并创建了mb-index和db-index两个新的偏见量化指标。

    

    尽管大型语言模型的能力不断增强，但仍然存在对其产生偏见的担忧。本文提出了一种针对“受限行业”在有限数据情况下通过指定数据集增强来去偏见的新颖自动机制。我们还创建了两个新的衡量指标mb-index和db-index来量化偏见，考虑到偏见是由内在模型架构和数据集共同导致的这一观点。

    arXiv:2403.13925v1 Announce Type: cross  Abstract: Despite the growing capabilities of large language models, there exists concerns about the biases they develop. In this paper, we propose a novel, automated mechanism for debiasing through specified dataset augmentation in the lens of bias producers and in the context of 'restricted industries' with limited data. We additionally create two new additional metrics, the mb-index and db-index, to quantify bias, considering the idea that bias occurs due to both intrinsic model architecture and dataset.
    
[^81]: 以多条件潜在扩散模型学习对比动力学

    Towards Learning Contrast Kinetics with Multi-Condition Latent Diffusion Models

    [https://arxiv.org/abs/2403.13890](https://arxiv.org/abs/2403.13890)

    提出了一个多条件潜在扩散模型来学习对比动力学，以减少对静脉内对比剂的依赖性。

    

    动态对比增强磁共振成像中的对比剂可以定位肿瘤并观察其对比动力学，这对于癌症表征和治疗决策至关重要。然而，对比剂的使用不仅与不良健康风险相关，而且对于怀孕患者、肾功能障碍患者或其他不良反应患者存在限制。由于对比剂摄取是病灶恶性、癌症复发风险和治疗反应的关键生物标志物，因此减少静脉内对比剂的依赖性变得至关重要。为此，我们提出了一个能够进行DCE-MRI时间序列的获取时间条件图像合成的多条件潜在扩散模型。为了评估医学图像合成，我们还提出并验证了基于生物标志物变异性的Fr\'echet放射组学距离作为图像质量度量。

    arXiv:2403.13890v1 Announce Type: cross  Abstract: Contrast agents in dynamic contrast enhanced magnetic resonance imaging allow to localize tumors and observe their contrast kinetics, which is essential for cancer characterization and respective treatment decision-making. However, contrast agent administration is not only associated with adverse health risks, but also restricted for patients during pregnancy, and for those with kidney malfunction, or other adverse reactions. With contrast uptake as key biomarker for lesion malignancy, cancer recurrence risk, and treatment response, it becomes pivotal to reduce the dependency on intravenous contrast agent administration. To this end, we propose a multi-conditional latent diffusion model capable of acquisition time-conditioned image synthesis of DCE-MRI temporal sequences. To evaluate medical image synthesis, we additionally propose and validate the Fr\'echet radiomics distance as an image quality measure based on biomarker variability 
    
[^82]: 准确预测智能系统的安全关键稀有事件概率

    Accurately Predicting Probabilities of Safety-Critical Rare Events for Intelligent Systems

    [https://arxiv.org/abs/2403.13869](https://arxiv.org/abs/2403.13869)

    该研究致力于发展一个在评估安全关键自主安全性的重要性方面，在精度和召回率方面都表现出色的关键性预测模型。

    

    智能系统越来越成为我们日常生活中的重要组成部分，然而罕见的安全关键事件对它们的实际部署构成了重大潜在威胁。应对这一挑战的关键在于准确预测在给定时间步长内从当前状态发生安全关键事件的概率，一个我们定义为“重要性”的指标。预测重要性的复杂性源自于极端数据不平衡，这是由高维变量中与罕见事件相关联引起的一个挑战，我们称之为罕见性诅咒。现有方法往往要么过于保守，要么容易忽视安全关键事件，因此很难同时实现高精度和召回率，这严重限制了它们的适用性。本研究旨在开发一个重要性预测模型，在评估安全关键自主安全性的重要性方面，在精度和召回率方面都表现出色。

    arXiv:2403.13869v1 Announce Type: cross  Abstract: Intelligent systems are increasingly integral to our daily lives, yet rare safety-critical events present significant latent threats to their practical deployment. Addressing this challenge hinges on accurately predicting the probability of safety-critical events occurring within a given time step from the current state, a metric we define as 'criticality'. The complexity of predicting criticality arises from the extreme data imbalance caused by rare events in high dimensional variables associated with the rare events, a challenge we refer to as the curse of rarity. Existing methods tend to be either overly conservative or prone to overlooking safety-critical events, thus struggling to achieve both high precision and recall rates, which severely limits their applicability. This study endeavors to develop a criticality prediction model that excels in both precision and recall rates for evaluating the criticality of safety-critical auton
    
[^83]: 拍卖启发的多人生成对抗网络训练

    The Bid Picture: Auction-Inspired Multi-player Generative Adversarial Networks Training

    [https://arxiv.org/abs/2403.13866](https://arxiv.org/abs/2403.13866)

    本文提出了一种拍卖启发的多人生成对抗网络训练方法，可以缓解GAN的模式坍塌问题。

    

    本文提出了一种拍卖启发的多人生成对抗网络训练方法，可以缓解GAN的模式坍塌问题。模式坍塌指的是当一个过拟合的生成器生成一种有限范围的样本时，通常集中在数据分布的一小部分上。尽管生成的样本多样性受限，鉴别器仍然可以被欺骗，将这些样本误认为来自实际分布的真实样本。在没有外部标准的情况下，模型无法在训练阶段识别其失败。我们将生成对抗网络的双方游戏扩展到多方游戏。在训练过程中，每个模型的价值由其他玩家在类似拍卖的过程中提交的出价决定。

    arXiv:2403.13866v1 Announce Type: cross  Abstract: This article proposes auction-inspired multi-player generative adversarial networks training, which mitigates the mode collapse problem of GANs. Mode collapse occurs when an over-fitted generator generates a limited range of samples, often concentrating on a small subset of the data distribution. Despite the restricted diversity of generated samples, the discriminator can still be deceived into distinguishing these samples as real samples from the actual distribution. In the absence of external standards, a model cannot recognize its failure during the training phase. We extend the two-player game of generative adversarial networks to the multi-player game. During the training, the values of each model are determined by the bids submitted by other players in an auction-like process.
    
[^84]: 用去噪扩散概率模型进行表格数据插补的DiffImpute

    DiffImpute: Tabular Data Imputation With Denoising Diffusion Probabilistic Model

    [https://arxiv.org/abs/2403.13863](https://arxiv.org/abs/2403.13863)

    提出了DiffImpute，一种基于去噪扩散概率模型的表格数据插补方法，可以有效处理不同类型的缺失数据，并通过定制多个表格去噪网络来增强插补的一致性。

    

    表格数据在各个领域中起着至关重要的作用，但往往存在缺失值，从而限制了其潜在效用。传统的插值技术通常会产生次优结果，并给后续建模任务带来重大计算负担，导致出现不准确性。为了解决这些挑战，我们提出了DiffImpute，一种新颖的去噪扩散概率模型（DDPM）。具体来说，DiffImpute在完整的表格数据集上进行训练，确保可以为缺失条目生成可信的插补，而不会破坏现有数据的真实性。创新地，它可以应用于缺失完全随机（MCAR）和缺失随机（MAR）的各种情境。为了有效处理DDPM中的表格特征，我们定制了四个表格去噪网络，涵盖MLP、ResNet、Transformer和U-Net。我们还提出了Harmonization来增强观察到的数据和插补数据之间的一致性。

    arXiv:2403.13863v1 Announce Type: cross  Abstract: Tabular data plays a crucial role in various domains but often suffers from missing values, thereby curtailing its potential utility. Traditional imputation techniques frequently yield suboptimal results and impose substantial computational burdens, leading to inaccuracies in subsequent modeling tasks. To address these challenges, we propose DiffImpute, a novel Denoising Diffusion Probabilistic Model (DDPM). Specifically, DiffImpute is trained on complete tabular datasets, ensuring that it can produce credible imputations for missing entries without undermining the authenticity of the existing data. Innovatively, it can be applied to various settings of Missing Completely At Random (MCAR) and Missing At Random (MAR). To effectively handle the tabular features in DDPM, we tailor four tabular denoising networks, spanning MLP, ResNet, Transformer, and U-Net. We also propose Harmonization to enhance coherence between observed and imputed d
    
[^85]: 经过物理意识和参数扩散指导的时空流体动力学建模

    Spatio-Temporal Fluid Dynamics Modeling via Physical-Awareness and Parameter Diffusion Guidance

    [https://arxiv.org/abs/2403.13850](https://arxiv.org/abs/2403.13850)

    该论文提出了ST-PAD框架，通过时空物理学意识和参数扩散引导实现流体动力学的高精度仿真和预测，在多个基准数据集上的实验证明其优于当前主流模型

    

    本文提出了一种名为ST-PAD的两阶段框架，用于地球科学领域的时空流体动力学建模，旨在通过时空物理学意识和参数扩散引导实现流体动力学的高精度仿真和预测。在上游阶段，我们设计了一个具有时间演变特性的矢量量化重构模块，通过引入一般的物理约束，确保了平衡和有弹性的参数分布。在下游阶段，利用涉及参数的扩散概率网络来生成高质量的未来流体状态，同时通过感知不同物理设置中的参数，增强模型的泛化能力。对多个基准数据集进行的大量实验验证了ST-PAD框架的有效性和鲁棒性，显示ST-PAD在流体动力学方面优于当前主流模型。

    arXiv:2403.13850v1 Announce Type: cross  Abstract: This paper proposes a two-stage framework named ST-PAD for spatio-temporal fluid dynamics modeling in the field of earth sciences, aiming to achieve high-precision simulation and prediction of fluid dynamics through spatio-temporal physics awareness and parameter diffusion guidance. In the upstream stage, we design a vector quantization reconstruction module with temporal evolution characteristics, ensuring balanced and resilient parameter distribution by introducing general physical constraints. In the downstream stage, a diffusion probability network involving parameters is utilized to generate high-quality future states of fluids, while enhancing the model's generalization ability by perceiving parameters in various physical setups. Extensive experiments on multiple benchmark datasets have verified the effectiveness and robustness of the ST-PAD framework, which showcase that ST-PAD outperforms current mainstream models in fluid dyna
    
[^86]: 揭秘图：图神经网络与图生成

    Graphs Unveiled: Graph Neural Networks and Graph Generation

    [https://arxiv.org/abs/2403.13849](https://arxiv.org/abs/2403.13849)

    该论文综述了图神经网络（GNNs）在各个领域的应用，并介绍了GNNs中的先进领域：图生成。

    

    机器学习领域的热点话题之一是GNN领域。图数据的复杂性给现有的机器学习算法带来了重大挑战。最近，涌现了许多关于扩展深度学习方法应用于图数据的研究。本文提供了一项调研，全面概述了图神经网络（GNNs）。我们讨论了图神经网络在各个领域的应用。最后，我们介绍了GNNs中的一项先进领域：图生成。

    arXiv:2403.13849v1 Announce Type: cross  Abstract: One of the hot topics in machine learning is the field of GNN. The complexity of graph data has imposed significant challenges on existing machine learning algorithms. Recently, many studies on extending deep learning approaches for graph data have emerged. This paper represents a survey, providing a comprehensive overview of Graph Neural Networks (GNNs). We discuss the applications of graph neural networks across various domains. Finally, we present an advanced field in GNNs: graph generation.
    
[^87]: 用于学习差异保护但准确规则列表的平滑敏感度

    Smooth Sensitivity for Learning Differentially-Private yet Accurate Rule Lists

    [https://arxiv.org/abs/2403.13848](https://arxiv.org/abs/2403.13848)

    通过建立Gini不纯度的平滑敏感度并将其应用于提出DP贪婪规则列表算法，本文改善了差异保护模型的准确性问题。

    

    差异保护（DP）机制可以嵌入到机器学习算法的设计中，以保护所得模型免受隐私泄露的影响，尽管这通常伴随着明显的准确性损失。本文旨在通过建立Gini不纯度的平滑敏感度并利用这一特性来提出一个DP贪婪规则列表算法，以改善这种权衡。我们的理论分析和实验结果表明，集成平滑敏感度的DP规则列表模型具有比使用全局敏感度的其他DP框架更高的准确性。

    arXiv:2403.13848v1 Announce Type: cross  Abstract: Differentially-private (DP) mechanisms can be embedded into the design of a machine learningalgorithm to protect the resulting model against privacy leakage, although this often comes with asignificant loss of accuracy. In this paper, we aim at improving this trade-off for rule lists modelsby establishing the smooth sensitivity of the Gini impurity and leveraging it to propose a DP greedyrule list algorithm. In particular, our theoretical analysis and experimental results demonstrate thatthe DP rule lists models integrating smooth sensitivity have higher accuracy that those using otherDP frameworks based on global sensitivity.
    
[^88]: 通过高斯混合模型进行域自适应的最优输运

    Optimal Transport for Domain Adaptation through Gaussian Mixture Models

    [https://arxiv.org/abs/2403.13847](https://arxiv.org/abs/2403.13847)

    通过高斯混合模型进行域自适应的最优输运，可以实现源域和目标域混合成分之间的匹配，从而在失效诊断中取得最先进的性能。

    

    在这篇论文中，我们探讨了通过最优输运进行域自适应的方法。我们提出了一种新颖的方法，即通过高斯混合模型对数据分布进行建模。这种策略使我们能够通过等价的离散问题解决连续最优输运。最优输运解决方案为我们提供了源域和目标域混合成分之间的匹配。通过这种匹配，我们可以在域之间映射数据点，或者将标签从源域组件转移到目标域。我们在失效诊断的两个域自适应基准测试中进行了实验，结果表明我们的方法具有最先进的性能。

    arXiv:2403.13847v1 Announce Type: cross  Abstract: In this paper we explore domain adaptation through optimal transport. We propose a novel approach, where we model the data distributions through Gaussian mixture models. This strategy allows us to solve continuous optimal transport through an equivalent discrete problem. The optimal transport solution gives us a matching between source and target domain mixture components. From this matching, we can map data points between domains, or transfer the labels from the source domain components towards the target domain. We experiment with 2 domain adaptation benchmarks in fault diagnosis, showing that our methods have state-of-the-art performance.
    
[^89]: 一种具有图最大解码信息的聚类方法

    A Clustering Method with Graph Maximum Decoding Information

    [https://arxiv.org/abs/2403.13846](https://arxiv.org/abs/2403.13846)

    CMDI聚类方法创新性地将二维结构信息理论融入聚类过程中，弥补了基于图的模型聚类方法中忽略的随机游走访问节点和数据中嵌入的结构信息的不确定性。

    

    基于图模型的聚类方法因其在各种知识领域中的广泛适用性而备受关注。其能够与其他相关应用无缝集成的适应性赋予了基于图模型的聚类分析能力，可以强大地从数据集中提取“自然关联”或“图结构”，有助于建模数据点之间的关系。尽管这种方法效果显著，但当前利用基于图的模型的聚类方法忽略了节点之间随机游走访问以及数据中嵌入的结构信息所带来的不确定性。为填补这一空白，我们提出了一种新颖的基于图的模型内最大化解码信息的聚类方法，命名为CMDI。CMDI创新地将二维结构信息理论纳入到聚类过程中，包括两个阶段：图结构提取和图顶点

    arXiv:2403.13846v1 Announce Type: cross  Abstract: The clustering method based on graph models has garnered increased attention for its widespread applicability across various knowledge domains. Its adaptability to integrate seamlessly with other relevant applications endows the graph model-based clustering analysis with the ability to robustly extract "natural associations" or "graph structures" within datasets, facilitating the modelling of relationships between data points. Despite its efficacy, the current clustering method utilizing the graph-based model overlooks the uncertainty associated with random walk access between nodes and the embedded structural information in the data. To address this gap, we present a novel Clustering method for Maximizing Decoding Information within graph-based models, named CMDI. CMDI innovatively incorporates two-dimensional structural information theory into the clustering process, consisting of two phases: graph structure extraction and graph vert
    
[^90]: 学会更好地看见看不见的东西：用于增量式零样本故障诊断的广深混合反遗忘框架

    Learning to better see the unseen: Broad-Deep Mixed Anti-Forgetting Framework for Incremental Zero-Shot Fault Diagnosis

    [https://arxiv.org/abs/2403.13845](https://arxiv.org/abs/2403.13845)

    提出了增量式ZSFD范式，开发了广深混合反遗忘框架（BDMAFF），旨在学习和适应新的故障类别和属性，解决了现有ZSFD范式在工业场景中无法从不断变化的训练数据流中学习的问题。

    

    零样本故障诊断（ZSFD）能够通过预测人类专家标注的故障属性来识别看不见的故障。为了解决工业过程中持续变化的需求，即模型适应新的故障类别和属性而避免忘记先前学到的诊断能力，我们首次提出了增量式ZSFD（IZSFD）范式，它结合了传统ZSFD和广义ZSFD范式的类别增量和属性增量。为了实现IZSFD，我们提出了一个旨在学习新的故障类别和属性的广深混合反遗忘框架（BDMAFF）。为了解决遗忘问题，BDMAFF有效地从两个角度积累先前获得的知识。

    arXiv:2403.13845v1 Announce Type: cross  Abstract: Zero-shot fault diagnosis (ZSFD) is capable of identifying unseen faults via predicting fault attributes labeled by human experts. We first recognize the demand of ZSFD to deal with continuous changes in industrial processes, i.e., the model's ability to adapt to new fault categories and attributes while avoiding forgetting the diagnosis ability learned previously. To overcome the issue that the existing ZSFD paradigm cannot learn from evolving streams of training data in industrial scenarios, the incremental ZSFD (IZSFD) paradigm is proposed for the first time, which incorporates category increment and attribute increment for both traditional ZSFD and generalized ZSFD paradigms. To achieve IZSFD, we present a broad-deep mixed anti-forgetting framework (BDMAFF) that aims to learn from new fault categories and attributes. To tackle the issue of forgetting, BDMAFF effectively accumulates previously acquired knowledge from two perspective
    
[^91]: 面向脑机接口的轻量级向量符号体系架构的定时知识获取

    Scheduled Knowledge Acquisition on Lightweight Vector Symbolic Architectures for Brain-Computer Interfaces

    [https://arxiv.org/abs/2403.13844](https://arxiv.org/abs/2403.13844)

    低维度计算分类器基于向量符号体系结构（VSA），通过定时知识获取方法，提高小模型准确率，解决处理复杂脑信号的挑战。

    

    脑机接口（BCIs）通常设计为轻量级且实时响应，以为用户提供及时反馈。经典特征工程计算效率高但准确率低，而近期的神经网络（DNNs）提高准确率但计算代价高、延迟大。作为一种有前途的替代选择，基于向量符号体系结构（VSA）的低维度计算（LDC）分类器实现了小模型大小，但准确率高于经典特征工程方法。然而，它的准确率仍落后于现代DNNs，这使得处理复杂的脑信号具有挑战性。为了提高小模型的准确率，知识蒸馏是一种流行的方法。然而，在学生模型在其不断学习阶段时保持教师模型和学生模型之间的恒定蒸馏水平可能并非最佳选择。在这项研究中，我们提出了一种定时知识获取的方法，使学生模型能够在逐步学习阶段改善准确率。

    arXiv:2403.13844v1 Announce Type: cross  Abstract: Brain-Computer interfaces (BCIs) are typically designed to be lightweight and responsive in real-time to provide users timely feedback. Classical feature engineering is computationally efficient but has low accuracy, whereas the recent neural networks (DNNs) improve accuracy but are computationally expensive and incur high latency. As a promising alternative, the low-dimensional computing (LDC) classifier based on vector symbolic architecture (VSA), achieves small model size yet higher accuracy than classical feature engineering methods. However, its accuracy still lags behind that of modern DNNs, making it challenging to process complex brain signals. To improve the accuracy of a small model, knowledge distillation is a popular method. However, maintaining a constant level of distillation between the teacher and student models may not be the best way for a growing student during its progressive learning stages. In this work, we propos
    
[^92]: 机器学习和视觉Transformer在甲状腺癌诊断中的应用：综述

    Machine Learning and Vision Transformers for Thyroid Carcinoma Diagnosis: A review

    [https://arxiv.org/abs/2403.13843](https://arxiv.org/abs/2403.13843)

    该论文总结了使用机器学习和大数据分析结合transformer评估甲状腺癌预后的方法，介绍了新的分类系统，并强调了人工智能在辅助甲状腺癌诊断和治疗中的重要性。

    

    与发展智能诊断系统以帮助医学专家处理大量数据以治疗不可治愈疾病的兴趣不断增长。特别是，在识别甲状腺癌（TC）的挑战方面，使用机器学习（ML）和大数据分析取得了进展，结合transformer评估TC预后，并确定个体的恶性风险。本综述文章总结了各种关于以人工智能（AI）算法为基础的方法的研究，特别是那些采用transformer进行甲状腺癌诊断的方法。它引入了一个新的基于AI算法、框架目标和使用的计算环境对这些方法进行分类的系统。此外，它通过其特征审查和对比了可用的TC数据集。该论文强调了AI工具在通过监督、无监督或混合方式协助诊断和治疗TC方面的重要性。

    arXiv:2403.13843v1 Announce Type: cross  Abstract: The growing interest in developing smart diagnostic systems to help medical experts process extensive data for treating incurable diseases has been notable. In particular, the challenge of identifying thyroid cancer (TC) has seen progress with the use of machine learning (ML) and big data analysis, incorporating transformers to evaluate TC prognosis and determine the risk of malignancy in individuals. This review article presents a summary of various studies on AIbased approaches, especially those employing transformers, for diagnosing TC. It introduces a new categorization system for these methods based on artifcial intelligence (AI) algorithms, the goals of the framework, and the computing environments used. Additionally, it scrutinizes and contrasts the available TC datasets by their features. The paper highlights the importance of AI instruments in aiding the diagnosis and treatment of TC through supervised, unsupervised, or mixed 
    
[^93]: 整合可穿戴传感器数据和自我报告日记用于个性化情感预测

    Integrating Wearable Sensor Data and Self-reported Diaries for Personalized Affect Forecasting

    [https://arxiv.org/abs/2403.13841](https://arxiv.org/abs/2403.13841)

    本论文提出了一种整合了可穿戴传感器数据和自我报告日记的多模态深度学习模型，用于情感状态的预测。

    

    情绪状态作为情感的指标对整体健康至关重要，因此在其发作前准确预测是至关重要的。目前的研究主要集中在使用来自可穿戴和移动设备的数据进行与短期情感检测。这些研究通常专注于客观的感官测量，往往忽略其他形式的自我报告信息，如日记和笔记。在本文中，我们提出了一种用于情感状态预测的多模态深度学习模型。该模型结合了一个transformer编码器和一个预训练语言模型，实现了客观指标和自我报告日记的综合分析。为了验证我们的模型，我们进行了一项纵向研究，招募了大学生并在一年内对其进行监测，收集了包括生理、环境、睡眠、代谢和身体活动参数在内的广泛数据集，同时参与者提供了开放式文本日记。

    arXiv:2403.13841v1 Announce Type: cross  Abstract: Emotional states, as indicators of affect, are pivotal to overall health, making their accurate prediction before onset crucial. Current studies are primarily centered on immediate short-term affect detection using data from wearable and mobile devices. These studies typically focus on objective sensory measures, often neglecting other forms of self-reported information like diaries and notes. In this paper, we propose a multimodal deep learning model for affect status forecasting. This model combines a transformer encoder with a pre-trained language model, facilitating the integrated analysis of objective metrics and self-reported diaries. To validate our model, we conduct a longitudinal study, enrolling college students and monitoring them over a year, to collect an extensive dataset including physiological, environmental, sleep, metabolic, and physical activity parameters, alongside open-ended textual diaries provided by the partici
    
[^94]: 你站在哪一边？调查大型语言模型的政治立场

    Whose Side Are You On? Investigating the Political Stance of Large Language Models

    [https://arxiv.org/abs/2403.13840](https://arxiv.org/abs/2403.13840)

    本研究提出了一个定量框架和流程，系统调查大型语言模型的政治取向，结果显示这些模型倾向于提供与自由主义或左倾观点更为接近的回应。

    

    大型语言模型（LLMs）因其在文本生成、摘要和信息检索等日常任务中的应用而备受欢迎。随着LLMs的广泛应用不断增长，确保这些模型产生政治中立的回应变得越来越重要，旨在避免信息泡沫，维护代表公平，并减轻确认偏见。本文提出了一个定量框架和流程，旨在系统地调查LLMs的政治取向。我们的调查深入探讨LLMs在八个极化话题的政治取向，从堕胎到LGBTQ问题跨越。结果表明，在各个话题上，LLMs倾向于提供与自由主义或左倾观点更为接近的回应，而不是与保守主义或右倾观点更为接近的回应。

    arXiv:2403.13840v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have gained significant popularity for their application in various everyday tasks such as text generation, summarization, and information retrieval. As the widespread adoption of LLMs continues to surge, it becomes increasingly crucial to ensure that these models yield responses that are politically impartial, with the aim of preventing information bubbles, upholding fairness in representation, and mitigating confirmation bias. In this paper, we propose a quantitative framework and pipeline designed to systematically investigate the political orientation of LLMs. Our investigation delves into the political alignment of LLMs across a spectrum of eight polarizing topics, spanning from abortion to LGBTQ issues. Across topics, the results indicate that LLMs exhibit a tendency to provide responses that closely align with liberal or left-leaning perspectives rather than conservative or right-leaning ones when us
    
[^95]: depyf：为机器学习研究者打开PyTorch编译器的神秘盒子

    depyf: Open the Opaque Box of PyTorch Compiler for Machine Learning Researchers

    [https://arxiv.org/abs/2403.13839](https://arxiv.org/abs/2403.13839)

    depyf是一个非侵入性和用户友好的工具，旨在帮助机器学习研究者揭开PyTorch编译器的内部工作机制，并通过反编译将字节码转换为源代码，从而增进用户对底层过程的理解。

    

    PyTorch 2.x引入了一个旨在加速深度学习程序的编译器。然而，对于机器学习研究者来说，充分利用PyTorch编译器可能具有挑战性。编译器在Python字节码级别运行，使其看起来像一个神秘的盒子。为解决这一问题，我们引入了depyf，这是一个旨在揭开PyTorch编译器内部机制的工具。depyf可以将PyTorch生成的字节码反编译为等效的源代码，并建立内存中代码对象与磁盘上源代码对应的联系。这个特性使用户可以使用调试器逐行查看源代码，从而增进对底层过程的理解。值得注意的是，depyf是非侵入性且用户友好的，主要依赖于两个方便的上下文管理器来实现其核心功能。

    arXiv:2403.13839v1 Announce Type: cross  Abstract: PyTorch \texttt{2.x} introduces a compiler designed to accelerate deep learning programs. However, for machine learning researchers, adapting to the PyTorch compiler to full potential can be challenging. The compiler operates at the Python bytecode level, making it appear as an opaque box. To address this, we introduce \texttt{depyf}, a tool designed to demystify the inner workings of the PyTorch compiler. \texttt{depyf} decompiles bytecode generated by PyTorch back into equivalent source code, and establishes connections between in-memory code objects and their on-disk source code counterparts. This feature enables users to step through the source code line by line using debuggers, thus enhancing their understanding of the underlying processes. Notably, \texttt{depyf} is non-intrusive and user-friendly, primarily relying on two convenient context managers for its core functionality. The project is \href{https://github.com/thuml/depyf}
    
[^96]: 使用准确性保证自动缩减语言模型规模以降低处理费用的SMART

    SMART: Automatically Scaling Down Language Models with Accuracy Guarantees for Reduced Processing Fees

    [https://arxiv.org/abs/2403.13835](https://arxiv.org/abs/2403.13835)

    提出了SMART框架，可通过准确性约束最小化自然语言处理任务的推理成本，同时确保结果质量。

    

    大型语言模型（LLMs）的进步显著提高了自然语言处理（NLP）任务的性能。然而，部署高性能LLMs会产生巨大的成本，主要是由于增加的参数数量旨在提升模型性能。这使得最先进的LLMs对终端用户而言变得更加昂贵。我们引入了SMART，即为降低标记费用而自适应缩放模型，这是一个新颖的LLM框架，旨在最大程度地降低NLP任务的推理成本，同时确保足够的结果质量。它使用户能够以输出的等效性指定准确性约束与最强大的LLM。

    arXiv:2403.13835v1 Announce Type: cross  Abstract: The advancement of Large Language Models (LLMs) has significantly boosted performance in natural language processing (NLP) tasks. However, the deployment of high-performance LLMs incurs substantial costs, primarily due to the increased number of parameters aimed at enhancing model performance. This has made the use of state-of-the-art LLMs more expensive for end-users. AI service providers, such as OpenAI and Anthropic, often offer multiple versions of LLMs with varying prices and performance. However, end-users still face challenges in choosing the appropriate LLM for their tasks that balance result quality with cost.   We introduce SMART, Scaling Models Adaptively for Reduced Token Fees, a novel LLM framework designed to minimize the inference costs of NLP tasks while ensuring sufficient result quality. It enables users to specify an accuracy constraint in terms of the equivalence of outputs to those of the most powerful LLM. SMART t
    
[^97]: 深层生成模型用于超高细粒度粒子物理探测器模拟：从仿真到外推的航程

    Deep Generative Models for Ultra-High Granularity Particle Physics Detector Simulation: A Voyage From Emulation to Extrapolation

    [https://arxiv.org/abs/2403.13825](https://arxiv.org/abs/2403.13825)

    该论文提出了一种新的几何感知生成模型IEA-GAN，以及一种迎接下游物理分析挑战的YonedaVAE模型，为超高细粒度粒子物理探测器模拟提供了重要的解决方案。

    

    在粒子物理中模拟超高细粒度探测器响应是一项至关重要但计算量巨大的任务。本论文旨在为Belle II实验的Pixel Vertex Detector (PXD) 克服这一挑战，该实验具有超过750万像素通道-是有史以来使用生成模型分析的空间分辨率最高的探测器模拟数据集。论文首先对用于模拟探测器特征的生成模型进行了全面和分类学的回顾。然后，提出了具有几何感知的新型生成模型"Intra-Event Aware Generative Adversarial Network (IEA-GAN)"，引入关系式注意推理和自监督学习来近似探测器中的"事件"。该研究强调了对下游物理分析而言“事件内关联”的重要性。在此基础上，研究朝着更通用的方法迈进，并提出了YonedaVAE，这是受范畴论启发的一种模型

    arXiv:2403.13825v1 Announce Type: cross  Abstract: Simulating ultra-high-granularity detector responses in Particle Physics represents a critical yet computationally demanding task. This thesis aims to overcome this challenge for the Pixel Vertex Detector (PXD) at the Belle II experiment, which features over 7.5M pixel channels-the highest spatial resolution detector simulation dataset ever analysed with generative models. This thesis starts off by a comprehensive and taxonomic review on generative models for simulating detector signatures. Then, it presents the Intra-Event Aware Generative Adversarial Network (IEA-GAN), a new geometry-aware generative model that introduces a relational attentive reasoning and Self-Supervised Learning to approximate an "event" in the detector. This study underscores the importance of intra-event correlation for downstream physics analyses. Building upon this, the work drifts towards a more generic approach and presents YonedaVAE, a Category Theory-insp
    
[^98]: AI生成文本在学术研究中的定量分析：利用AI检测工具研究Arxiv投稿中的AI存在性

    Quantitative Analysis of AI-Generated Texts in Academic Research: A Study of AI Presence in Arxiv Submissions using AI Detection Tool

    [https://arxiv.org/abs/2403.13812](https://arxiv.org/abs/2403.13812)

    论文研究了一种能够检测Arxiv投稿中AI成分的方法，使用物理、数学和计算机科学文章创建数据集，并通过Originality.ai进行分析，准确率达到98%。

    

    许多人对ChatGPT感兴趣，因为它已成为一个突出的AIGC模型，可以在各种情境下提供高质量的响应，如软件开发和维护。ChatGPT的误用可能引起重大问题，特别是在公共安全和教育领域，尽管其有巨大潜力。研究人员大多选择在Arxiv上发表他们的作品。未来工作的有效性和独创性取决于在这些贡献中检测到AI组件的能力。为了满足这一需求，本研究将分析一种方法，可以查看学术机构用于在Arxiv上发布的刻意制造的内容。为了进行这项研究，使用了物理、数学和计算机科学文章创建了一个数据集。利用新建立的数据集，接下来的步骤是将originality.ai投入使用。统计分析显示，Originality.ai非常精准，准确率达到98%。

    arXiv:2403.13812v1 Announce Type: cross  Abstract: Many people are interested in ChatGPT since it has become a prominent AIGC model that provides high-quality responses in various contexts, such as software development and maintenance. Misuse of ChatGPT might cause significant issues, particularly in public safety and education, despite its immense potential. The majority of researchers choose to publish their work on Arxiv. The effectiveness and originality of future work depend on the ability to detect AI components in such contributions. To address this need, this study will analyze a method that can see purposely manufactured content that academic organizations use to post on Arxiv. For this study, a dataset was created using physics, mathematics, and computer science articles. Using the newly built dataset, the following step is to put originality.ai through its paces. The statistical analysis shows that Originality.ai is very accurate, with a rate of 98%.
    
[^99]: 利用基于元启发式人工神经网络的方法预测碳纤维增强聚合物对混凝土强度的束缚效应

    Predicting Confinement Effect of Carbon Fiber Reinforced Polymers on Strength of Concrete using Metaheuristics-based Artificial Neural Networks

    [https://arxiv.org/abs/2403.13809](https://arxiv.org/abs/2403.13809)

    通过元启发式人工神经网络方法，成功预测了碳纤维增强聚合物对混凝土强度的束缚效应。

    

    本文研究了利用基于元启发式人工神经网络的方法预测碳纤维增强聚合物（CFRPs）对混凝土圆柱强度的束缚效应。从先前发表的研究中开发了一个包含708个CFRP约束混凝土圆柱的详细数据库，其中包含8个参数的信息，包括几何参数（如圆柱直径（d）和高度（h））、混凝土未束缚抗压强度（fco'）、厚度（nt）、CFRP的弹性模量（Ef）、未束缚混凝土应变、受约束混凝土应变以及受束缚混凝土的极限抗压强度fcc'。实施了三种基于元启发式的模型，包括粒子群优化（PSO）、灰狼优化器（GWO）和蝙蝠算法（BA）。这些算法使用均方误差作为目标函数对数据进行训练，并将预测结果与实验研究进行验证。

    arXiv:2403.13809v1 Announce Type: cross  Abstract: This article deals with the study of predicting the confinement effect of carbon fiber reinforced polymers (CFRPs) on concrete cylinder strength using metaheuristics-based artificial neural networks. A detailed database of 708 CFRP confined concrete cylinders is developed from previously published research with information on 8 parameters including geometrical parameters like the diameter (d) and height (h) of a cylinder, unconfined compressive strength of concrete (fco'), thickness (nt), the elastic modulus of CFRP (Ef), unconfined concrete strain confined concrete strain and the ultimate compressive strength of confined concrete fcc'. Three metaheuristic models are implemented including particle swarm optimization (PSO), grey wolf optimizer (GWO), and bat algorithm (BA). These algorithms are trained on the data using an objective function of mean square error and their predicted results are validated against the experimental studies 
    
[^100]: LlamaFactory：100多种语言模型的统一高效微调

    LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models

    [https://arxiv.org/abs/2403.13372](https://arxiv.org/abs/2403.13372)

    LlamaFactory是一个统一框架，整合了一系列前沿的高效训练方法，使用户能够在不需要编码的情况下灵活定制100多种LLMs的微调。

    

    高效的微调对于将大型语言模型（LLMs）适应下游任务至关重要。然而，在不同模型上实现这些方法需要非平凡的努力。我们提出了LlamaFactory，这是一个统一框架，集成了一套前沿的高效训练方法。它允许用户通过内置的Web UI LlamaBoard 灵活定制100多种LLMs的微调，无需编码。我们在语言建模和文本生成任务上经验性地验证了我们框架的效率和有效性。已发布在 https://github.com/hiyouga/LLaMA-Factory，并已获得超过13,000颗星和1,600个分支。

    arXiv:2403.13372v1 Announce Type: new  Abstract: Efficient fine-tuning is vital for adapting large language models (LLMs) to downstream tasks. However, it requires non-trivial efforts to implement these methods on different models. We present LlamaFactory, a unified framework that integrates a suite of cutting-edge efficient training methods. It allows users to flexibly customize the fine-tuning of 100+ LLMs without the need for coding through the built-in web UI LlamaBoard. We empirically validate the efficiency and effectiveness of our framework on language modeling and text generation tasks. It has been released at https://github.com/hiyouga/LLaMA-Factory and already received over 13,000 stars and 1,600 forks.
    
[^101]: Arcee的MergeKit：用于合并大型语言模型的工具包

    Arcee's MergeKit: A Toolkit for Merging Large Language Models

    [https://arxiv.org/abs/2403.13257](https://arxiv.org/abs/2403.13257)

    合并不同语言模型的参数，无需额外训练即可创建多任务模型，提升模型性能和多功能性，解决AI中的复杂挑战。

    

    开源语言模型领域的快速扩张为通过合并其参数来结合这些模型检查点的能力提供了机会。迁移学习的进步导致了大量针对特定任务进行微调的模型的开发，这些模型通常专门针对个别任务进行专门化，无法利用彼此的优势。模型合并促进了多任务模型的创建，无需额外的训练，为增强模型性能和多功能性提供了一个有前途的途径。通过保留原始模型的固有能力，模型合并解决了人工智能中的复杂挑战，包括灾难性遗忘和多任务学习的困难。为了支持这一不断扩大的研究领域，我们介绍了MergeKit，这是一个全面的、开源的库，旨在促进模型合并的应用。

    arXiv:2403.13257v1 Announce Type: new  Abstract: The rapid expansion of the open-source language model landscape presents an opportunity to merge the competencies of these model checkpoints by combining their parameters. Advances in transfer learning, the process of fine-tuning pre-trained models for specific tasks, has resulted in the development of vast amounts of task-specific models, typically specialized in individual tasks and unable to utilize each other's strengths. Model merging facilitates the creation of multitask models without the need for additional training, offering a promising avenue for enhancing model performance and versatility. By preserving the intrinsic capabilities of the original models, model merging addresses complex challenges in AI - including the difficulties of catastrophic forgetting and multi-task learning. To support this expanding area of research, we introduce MergeKit, a comprehensive, open-source library designed to facilitate the application of mo
    
[^102]: FlowerFormer: 使用基于流感知的图变换器增强神经结构编码

    FlowerFormer: Empowering Neural Architecture Encoding using a Flow-aware Graph Transformer

    [https://arxiv.org/abs/2403.12821](https://arxiv.org/abs/2403.12821)

    FlowerFormer是一种强大的图变换器，通过双向异步消息传递和基于流程的全局注意力，可以增强神经结构的表征学习。

    

    特定神经网络架构的成功与其处理的数据集和任务密切相关；没有一种适合所有情况的解决方案。因此，人们付出了大量努力，以快速准确地估计神经结构在特定任务和数据集上的表现，而无需进行完整的训练或评估。神经结构编码在估计中起着至关重要的作用，而将架构视为图的基于图的方法表现出色。为了增强神经结构的表征学习，我们介绍了FlowerFormer，一种强大的图变换器，它融入了神经结构内的信息流。 FlowerFormer由两个关键组件组成：（a）受流程启发的双向异步消息传递；（b）建立在基于流程的掩码上的全局关注。我们广泛的实验表明，FlowerFormer优于现有神经结构。

    arXiv:2403.12821v1 Announce Type: cross  Abstract: The success of a specific neural network architecture is closely tied to the dataset and task it tackles; there is no one-size-fits-all solution. Thus, considerable efforts have been made to quickly and accurately estimate the performances of neural architectures, without full training or evaluation, for given tasks and datasets. Neural architecture encoding has played a crucial role in the estimation, and graphbased methods, which treat an architecture as a graph, have shown prominent performance. For enhanced representation learning of neural architectures, we introduce FlowerFormer, a powerful graph transformer that incorporates the information flows within a neural architecture. FlowerFormer consists of two key components: (a) bidirectional asynchronous message passing, inspired by the flows; (b) global attention built on flow-based masking. Our extensive experiments demonstrate the superiority of FlowerFormer over existing neural 
    
[^103]: 在图像分类器中发现和减轻多个有偏子群体

    Discover and Mitigate Multiple Biased Subgroups in Image Classifiers

    [https://arxiv.org/abs/2403.12777](https://arxiv.org/abs/2403.12777)

    提出了一种称为“分解、解释和减轻（DIM）”的新方法, 用于在图像分类器中发现和减轻多个有偏子群体，增强模型鲁棒性。

    

    机器学习模型在分布数据上表现良好，但常常在训练数据中未充分代表的有偏子群体上失败，影响模型对可靠应用的抗干扰性。这些子群体通常由于缺乏子群体标签而未知。发现有偏子群体是理解模型失败模式并进一步提高模型鲁棒性的关键。本文提出了一种名为“分解、解释和减轻（DIM）”的新方法，以解决在图像分类器中发现多个有偏子群体这一更具挑战性但也更实际的问题。我们的方法将图像特征分解为代表多个子群体的多个组件。

    arXiv:2403.12777v1 Announce Type: cross  Abstract: Machine learning models can perform well on in-distribution data but often fail on biased subgroups that are underrepresented in the training data, hindering the robustness of models for reliable applications. Such subgroups are typically unknown due to the absence of subgroup labels. Discovering biased subgroups is the key to understanding models' failure modes and further improving models' robustness. Most previous works of subgroup discovery make an implicit assumption that models only underperform on a single biased subgroup, which does not hold on in-the-wild data where multiple biased subgroups exist.   In this work, we propose Decomposition, Interpretation, and Mitigation (DIM), a novel method to address a more challenging but also more practical problem of discovering multiple biased subgroups in image classifiers. Our approach decomposes the image features into multiple components that represent multiple subgroups. This decomp
    
[^104]: 单模态多任务融合用于情感模仿预测

    Unimodal Multi-Task Fusion for Emotional Mimicry Prediciton

    [https://arxiv.org/abs/2403.11879](https://arxiv.org/abs/2403.11879)

    通过融合技术整合全局背景信息和采用LSTM架构进行时间分析，我们的方法在情感模仿强度预测任务上取得了显着的改进。

    

    在这项研究中，我们提出了一种方法，用于在第六届户外情感行为分析研讨会和竞赛中进行情感模仿强度（EMI）估计任务。我们的方法利用了Wav2Vec 2.0框架，在一个全面的播客数据集上进行了预训练，以提取涵盖语言和语外元素的广泛音频特征。我们通过一种融合技术增强了特征表示，该技术将个体特征与全局均值向量相结合，引入全局背景信息到我们的分析中。此外，我们从Wav2Vec 2.0模型中引入了一个预训练的valence-arousal-dominance（VAD）模块。我们的融合采用了一种长短期记忆（LSTM）架构，用于对音频数据进行高效的时间分析。仅利用所提供的音频数据，我们的方法在已建立的基准线上表现出显著的改进。

    arXiv:2403.11879v1 Announce Type: cross  Abstract: In this study, we propose a methodology for the Emotional Mimicry Intensity (EMI) Estimation task within the context of the 6th Workshop and Competition on Affective Behavior Analysis in-the-wild. Our approach leverages the Wav2Vec 2.0 framework, pre-trained on a comprehensive podcast dataset, to extract a broad range of audio features encompassing both linguistic and paralinguistic elements. We enhance feature representation through a fusion technique that integrates individual features with a global mean vector, introducing global contextual insights into our analysis. Additionally, we incorporate a pre-trained valence- arousal-dominance (VAD) module from the Wav2Vec 2.0 model. Our fusion employs a Long Short-Term Memory (LSTM) architecture for efficient temporal analysis of audio data. Utilizing only the provided audio data, our approach demonstrates significant improvements over the established baseline.
    
[^105]: 优化多语言大语言模型的语言增强：以韩语为例的案例研究

    Optimizing Language Augmentation for Multilingual Large Language Models: A Case Study on Korean

    [https://arxiv.org/abs/2403.10882](https://arxiv.org/abs/2403.10882)

    该研究提出了三种策略来增强基于公开可用MLLMs的资源较少的语言的性能，包括扩展词汇、双语数据预训练和指导微调。

    

    大型语言模型（LLMs）使用预训练来预测下一个单词；然而，它们的扩展需要大量计算资源。许多大型科技公司和研究机构已经开发了多语言LLMs（MLLMs）以满足当前需求，但忽视了资源较少的语言（LRLs）。本研究提出了三种策略来增强基于公开可用MLLMs的LRLs的性能。首先，扩展LRLs的MLLM词汇以增强表达性。其次，使用双语数据进行预训练以对齐高资源语言和低资源语言。第三，构建高质量的小规模指导数据集，并进行指导微调以增强LRL。实验采用了Llama2模型，以韩语作为LRL，并在八项任务中对其与其他已开发的LLMs进行了定量评估。此外，基于人类评估进行了定性评估。

    arXiv:2403.10882v1 Announce Type: cross  Abstract: Large language models (LLMs) use pretraining to predict the subsequent word; however, their expansion requires significant computing resources. Numerous big tech companies and research institutes have developed multilingual LLMs (MLLMs) to meet current demands, overlooking less-resourced languages (LRLs). This study proposed three strategies to enhance the performance of LRLs based on the publicly available MLLMs. First, the MLLM vocabularies of LRLs were expanded to enhance expressiveness. Second, bilingual data were used for pretraining to align the high- and less-resourced languages. Third, a high-quality small-scale instruction dataset was constructed and instruction-tuning was performed to augment the LRL. The experiments employed the Llama2 model and Korean was used as the LRL, which was quantitatively evaluated against other developed LLMs across eight tasks. Furthermore, a qualitative assessment was performed based on human eva
    
[^106]: 成本敏感学习在考虑工作量约束下推迟多位专家决策

    Cost-Sensitive Learning to Defer to Multiple Experts with Workload Constraints

    [https://arxiv.org/abs/2403.06906](https://arxiv.org/abs/2403.06906)

    提出了成本和工作量约束下的推迟框架（DeCCaF），旨在解决成本敏感场景、并发预测和人类工作能力约束等问题

    

    学习推迟（L2D）旨在通过学习如何在人工智能协作系统中将决策推迟给人类，从而在人类更有可能正确时推迟决策。现有L2D研究忽视了阻碍其实际采用的真实系统的关键方面，即：忽视成本敏感场景，其中第1类和第2类错误的成本不同；要求每个训练数据集实例的并发人类预测；不处理人类工作能力约束。为了解决这些问题，我们提出了成本和工作量约束下的推迟框架（DeCCaF）。DeCCaF是一种新颖的L2D方法，采用监督学习来建模人类错误的概率，减少数据要求的限制，并使用约束编程来全局最小化错误成本，同时考虑工作量限制。我们在一个系列中测试了DeCCaF

    arXiv:2403.06906v1 Announce Type: cross  Abstract: Learning to defer (L2D) aims to improve human-AI collaboration systems by learning how to defer decisions to humans when they are more likely to be correct than an ML classifier. Existing research in L2D overlooks key aspects of real-world systems that impede its practical adoption, namely: i) neglecting cost-sensitive scenarios, where type 1 and type 2 errors have different costs; ii) requiring concurrent human predictions for every instance of the training dataset and iii) not dealing with human work capacity constraints. To address these issues, we propose the deferral under cost and capacity constraints framework (DeCCaF). DeCCaF is a novel L2D approach, employing supervised learning to model the probability of human error under less restrictive data requirements (only one expert prediction per instance) and using constraint programming to globally minimize the error cost subject to workload limitations. We test DeCCaF in a series 
    
[^107]: 模拟社交互动成功性的误导性：以LLMs为例

    Is this the real life? Is this just fantasy? The Misleading Success of Simulating Social Interactions With LLMs

    [https://arxiv.org/abs/2403.05020](https://arxiv.org/abs/2403.05020)

    研究发现，使用LLMs进行社交互动的全知模拟比非全知模拟更容易实现社交目标，尽管非全知模拟更接近实际情况。

    

    最近大型语言模型（LLM）的进展使得社交模拟更加丰富，能够使用基于LLM的代理人研究各种社交现象。然而，大多数工作在这些模拟中采用了一种全知的透视（例如，单个LLM生成所有交谈者），这与人类具有的非全知、信息不对称的互动根本不符。为了研究这些差异，我们开发了一个评估框架，在各种设定（全知、非全知）中使用LLMs模拟社交互动。我们的实验表明，通过全知方式模拟的交谈者在实现社交目标方面比非全知代理人更成功，尽管后者更符合现实设置。此外，我们表明从全知模拟中学习可以改善交互的自然性，但在合作场景中几乎不能增强目标实现。

    arXiv:2403.05020v1 Announce Type: cross  Abstract: Recent advances in large language models (LLM) have enabled richer social simulations, allowing for the study of various social phenomena with LLM-based agents. However, most work has used an omniscient perspective on these simulations (e.g., single LLM to generate all interlocutors), which is fundamentally at odds with the non-omniscient, information asymmetric interactions that humans have. To examine these differences, we develop an evaluation framework to simulate social interactions with LLMs in various settings (omniscient, non-omniscient). Our experiments show that interlocutors simulated omnisciently are much more successful at accomplishing social goals compared to non-omniscient agents, despite the latter being the more realistic setting. Furthermore, we demonstrate that learning from omniscient simulations improves the apparent naturalness of interactions but scarcely enhances goal achievement in cooperative scenarios. Our f
    
[^108]: 超越专业化：评估MLLMs在年龄和性别估计中的能力

    Beyond Specialization: Assessing the Capabilities of MLLMs in Age and Gender Estimation

    [https://arxiv.org/abs/2403.02302](https://arxiv.org/abs/2403.02302)

    本研究评估了多模态大型语言模型（MLLMs）在年龄和性别估计中的能力，对不同模型进行了比较，揭示了它们在特定任务上的优势和劣势。

    

    最近，多模态大型语言模型（MLLMs）变得异常流行。像ChatGPT-4V和Gemini这样功能强大的商用模型，以及像LLaVA这样的开源模型，本质上都是通用模型，应用于解决各种各样的任务，包括计算机视觉中的任务。这些神经网络具有如此强大的通用知识和推理能力，以至于它们已被证明能够处理甚至未经专门训练的任务。我们将迄今为止最强大的MLLMs的能力进行了比较：ShareGPT4V、ChatGPT、LLaVA-Next 进行了专门任务的年龄和性别估计，与我们的最新专业化模型MiVOLO进行了比较。我们还更新了MiVOLO，并在本文中提供了详细信息和新的指标。这种比较产生了一些有趣的结果和关于参与模型的优点和缺点的见解。此外，我们尝试了各种微调方法

    arXiv:2403.02302v1 Announce Type: cross  Abstract: Multimodal Large Language Models (MLLMs) have recently gained immense popularity. Powerful commercial models like ChatGPT-4V and Gemini, as well as open-source ones such as LLaVA, are essentially general-purpose models and are applied to solve a wide variety of tasks, including those in computer vision. These neural networks possess such strong general knowledge and reasoning abilities that they have proven capable of working even on tasks for which they were not specifically trained. We compared the capabilities of the most powerful MLLMs to date: ShareGPT4V, ChatGPT, LLaVA-Next in a specialized task of age and gender estimation with our state-of-the-art specialized model, MiVOLO. We also updated MiVOLO and provide details and new metrics in this article. This comparison has yielded some interesting results and insights about the strengths and weaknesses of the participating models. Furthermore, we attempted various ways to fine-tune 
    
[^109]: NewsBench：系统性评估LLM在中国新闻编辑应用中的写作水平和安全性遵从能力

    NewsBench: Systematic Evaluation of LLMs for Writing Proficiency and Safety Adherence in Chinese Journalistic Editorial Applications

    [https://arxiv.org/abs/2403.00862](https://arxiv.org/abs/2403.00862)

    NewsBench是一个评估LLMs在中国新闻写作水平和安全性遵从能力的基准框架，揭示了在创造性写作任务中LLMs相对不足的新闻伦理遵守方面的需求。

    

    这项研究提出了NewsBench，这是一个新颖的基准框架，旨在评估大型语言模型（LLMs）在中国新闻写作水平（JWP）和安全性遵从（SA）方面的能力，弥补了新闻伦理与人工智能利用风险之间的差距。NewsBench包括5个编辑应用中的1,267项任务，7个方面（包括安全性和新闻写作，以及4个详细要面），涵盖24个新闻主题领域，采用基于两种GPT-4的自动评估协议，并经过人类评估验证。我们对11个LLM的全面分析突出了GPT-4和ERNIE Bot作为表现最佳，但在创造性写作任务中揭示了新闻伦理遵守方面的相对不足。这些发现强调了AI生成的新闻内容需要提高伦理指导，标志着以新闻标准和安全性对齐AI能力迈出了一步。

    arXiv:2403.00862v1 Announce Type: cross  Abstract: This study presents NewsBench, a novel benchmark framework developed to evaluate the capability of Large Language Models (LLMs) in Chinese Journalistic Writing Proficiency (JWP) and their Safety Adherence (SA), addressing the gap between journalistic ethics and the risks associated with AI utilization. Comprising 1,267 tasks across 5 editorial applications, 7 aspects (including safety and journalistic writing with 4 detailed facets), and spanning 24 news topics domains, NewsBench employs two GPT-4 based automatic evaluation protocols validated by human assessment. Our comprehensive analysis of 11 LLMs highlighted GPT-4 and ERNIE Bot as top performers, yet revealed a relative deficiency in journalistic ethic adherence during creative writing tasks. These findings underscore the need for enhanced ethical guidance in AI-generated journalistic content, marking a step forward in aligning AI capabilities with journalistic standards and safet
    
[^110]: OSCaR:对象状态字幕和状态变化表示

    OSCaR: Object State Captioning and State Change Representation

    [https://arxiv.org/abs/2402.17128](https://arxiv.org/abs/2402.17128)

    本文介绍了一个新的数据集和基准OSCaR，旨在解决描述复杂视觉环境中对象状态变化的问题，为评估多模态大型语言提供了一个新的实验平台。

    

    arXiv:2402.17128v3 公告类型: 跨 面向人类在真实世界环境中的交互视角，智能模型推断和理解对象状态的变化能力是人工智能研究的一个重要且具有挑战性的方面。该任务涉及描述复杂的视觉环境，识别活跃对象，以及通过语言解释它们的变化。传统方法将对象字幕和状态变化检测进行隔离，提供了对动态环境的有限视图。此外，依赖于一小套符号化词汇来表示变化限制了语言的表达力。为了解决这些挑战，在本文中，我们介绍了对象状态字幕和状态变化表示（OSCaR）数据集和基准。OSCaR包括来自各种主观视角视频集合的14,084个带注释视频片段，涵盖近1,000个独特对象。它为评估多模态大型语言提供了一个新的实验平台。

    arXiv:2402.17128v3 Announce Type: cross  Abstract: The capability of intelligent models to extrapolate and comprehend changes in object states is a crucial yet demanding aspect of AI research, particularly through the lens of human interaction in real-world settings. This task involves describing complex visual environments, identifying active objects, and interpreting their changes as conveyed through language. Traditional methods, which isolate object captioning and state change detection, offer a limited view of dynamic environments. Moreover, relying on a small set of symbolic words to represent changes has restricted the expressiveness of the language. To address these challenges, in this paper, we introduce the Object State Captioning and State Change Representation (OSCaR) dataset and benchmark. OSCaR consists of 14,084 annotated video segments with nearly 1,000 unique objects from various egocentric video collections. It sets a new testbed for evaluating multimodal large langua
    
[^111]: ROS-Causal：基于ROS的人机交互应用因果分析框架

    ROS-Causal: A ROS-based Causal Analysis Framework for Human-Robot Interaction Applications

    [https://arxiv.org/abs/2402.16068](https://arxiv.org/abs/2402.16068)

    ROS-Causal是一个基于ROS的框架，用于在人机空间交互中进行数据收集和因果发现，解决了机器人领域中缺乏因果发现方法在ROS生态系统内实现的问题。

    

    在人类共享空间部署机器人需要理解附近Agent和物体之间的交互。通过因果推理对因果关系建模有助于预测人类行为并预测机器人干预。然而，一个关键挑战是现有的因果发现方法目前缺乏在ROS生态系统内部的实现，这是机器人领域的事实标准，阻碍了在机器人领域的有效利用。为了解决这一差距，本文引入了ROS-Causal，这是一个基于ROS的框架，用于机器人上的数据收集和因果发现在人机空间交互中。集成了ROS的临时模拟器展示了该方法的有效性，展示了机器人在数据收集过程中生成因果模型。ROS-Causal可在GitHub上找到：https://github.com/lcastri/roscausal.git。

    arXiv:2402.16068v1 Announce Type: cross  Abstract: Deploying robots in human-shared spaces requires understanding interactions among nearby agents and objects. Modelling cause-and-effect relations through causal inference aids in predicting human behaviours and anticipating robot interventions. However, a critical challenge arises as existing causal discovery methods currently lack an implementation inside the ROS ecosystem, the standard de facto in robotics, hindering effective utilisation in robotics. To address this gap, this paper introduces ROS-Causal, a ROS-based framework for onboard data collection and causal discovery in human-robot spatial interactions. An ad-hoc simulator, integrated with ROS, illustrates the approach's effectiveness, showcasing the robot onboard generation of causal models during data collection. ROS-Causal is available on GitHub: https://github.com/lcastri/roscausal.git.
    
[^112]: 通过多重分形分析视角探索LLMs中的神经元相互作用和出现现象

    Exploring Neuron Interactions and Emergence in LLMs: From the Multifractal Analysis Perspective

    [https://arxiv.org/abs/2402.09099](https://arxiv.org/abs/2402.09099)

    该论文通过多重分形分析视角，深入研究了LLMs中神经元相互作用和出现现象。通过引入自组织和多重分形分析的概念，研究了神经元相互作用的动态演化过程，尤其关注训练中的复杂行为。通过提出基于神经元的多重分形分析方法，实现了对大型模型中神经元相互作用的定量分析。

    

    在以往的大型模型中，关于出现现象的研究主要集中在大型语言模型（LLMs）的功能能力如何随模型规模的扩大而增加。然而，我们的研究超越了这一传统范式，旨在通过不仅仅依赖于模型规模，而更加关注训练过程中神经元相互作用的复杂行为，加深我们对LLMs内部出现现象的理解。通过引入“自组织”和“多重分形分析”概念，我们探索了神经元相互作用在训练过程中如何动态演化，从而导致“出现现象”，这种现象反映了自然系统中简单的微观相互作用如何导致复杂的宏观行为。为了定量分析训练过程中大型模型中神经元之间不断演化的相互作用，我们提出了基于神经元的多重分形分析（NeuroMFA）。利用NeuroMFA，我们进行了一系列的实验

    arXiv:2402.09099v1 Announce Type: new Abstract: Prior studies on the emergence in large models have primarily focused on how the functional capabilities of large language models (LLMs) scale with model size. Our research, however, transcends this traditional paradigm, aiming to deepen our understanding of the emergence within LLMs by placing a special emphasis not just on the model size but more significantly on the complex behavior of neuron interactions during the training process. By introducing the concepts of "self-organization" and "multifractal analysis," we explore how neuron interactions dynamically evolve during training, leading to "emergence," mirroring the phenomenon in natural systems where simple micro-level interactions give rise to complex macro-level behaviors. To quantitatively analyze the continuously evolving interactions among neurons in large models during training, we propose the Neuron-based Multifractal Analysis (NeuroMFA). Utilizing NeuroMFA, we conduct a com
    
[^113]: 智能画布: 通过快速原型设计、迭代和管理实现类似设计的探索性可视数据分析

    Intelligent Canvas: Enabling Design-Like Exploratory Visual Data Analysis through Rapid Prototyping, Iteration and Curation

    [https://arxiv.org/abs/2402.08812](https://arxiv.org/abs/2402.08812)

    该论文提出了一种"类似设计"的智能画布环境，通过将生成式AI组件集成到数据分析中，实现了快速原型设计、迭代和比较可视化管理。通过用户研究，论文验证了画布界面的有效性。

    

    复杂数据分析通过探索性的可视分析方法来寻求意想不到的洞见，并超越逻辑的逐步处理。然而，现有的界面（如笔记本和仪表板）在可视数据分析的探索和比较方面存在一些局限性。为了解决这些问题，我们介绍了一种“类似设计”的智能画布环境，将生成式AI集成到数据分析中，提供快速原型设计、迭代和比较可视化管理。我们的两个主要贡献包括将生成式AI组件集成到画布界面中，并通过用户研究（N=10）评估了画布界面的有效性。

    arXiv:2402.08812v1 Announce Type: cross Abstract: Complex data analysis inherently seeks unexpected insights through exploratory \re{visual analysis} methods, transcending logical, step-by-step processing. However, \re{existing interfaces such as notebooks and dashboards have limitations in exploration and comparison for visual data analysis}. Addressing these limitations, we introduce a "design-like" intelligent canvas environment integrating generative AI into data analysis, offering rapid prototyping, iteration, and comparative visualization management. Our dual contributions include the integration of generative AI components into a canvas interface, and empirical findings from a user study (N=10) evaluating the effectiveness of the canvas interface.
    
[^114]: CPSDBench：一个针对中国公共安全领域的大型语言模型评估基准和基线

    CPSDBench: A Large Language Model Evaluation Benchmark and Baseline for Chinese Public Security Domain

    [https://arxiv.org/abs/2402.07234](https://arxiv.org/abs/2402.07234)

    CPSDBench是一个专门为中国公共安全领域量身定制的大型语言模型评估基准，通过整合实际场景中收集的公共安全相关数据集，针对文本分类、信息提取、问题回答和文本生成四个关键维度全面评估LLMs的性能，并引入创新的评估指标，提高了对现有模型在解决公共安全问题方面性能的理解。

    

    大型语言模型（LLMs）在多个应用领域展示了显著的潜力和效果。为了评估主流LLMs在公共安全任务中的性能，本研究旨在构建一个专门针对中国公共安全领域的评估基准——CPSDBench。CPSDBench整合了从现实场景中收集到的与公共安全相关的数据集，支持对LLMs在文本分类、信息提取、问题回答和文本生成四个关键维度上进行全面评估。此外，本研究还引入了一套创新的评估指标，旨在更精确地量化LLMs在执行与公共安全相关任务上的效力。通过本研究中的深入分析和评估，我们不仅增强了对现有模型在解决公共安全问题方面性能优势和局限性的理解，还为未来的研究提供了参考。

    Large Language Models (LLMs) have demonstrated significant potential and effectiveness across multiple application domains. To assess the performance of mainstream LLMs in public security tasks, this study aims to construct a specialized evaluation benchmark tailored to the Chinese public security domain--CPSDbench. CPSDbench integrates datasets related to public security collected from real-world scenarios, supporting a comprehensive assessment of LLMs across four key dimensions: text classification, information extraction, question answering, and text generation. Furthermore, this study introduces a set of innovative evaluation metrics designed to more precisely quantify the efficacy of LLMs in executing tasks related to public security. Through the in-depth analysis and evaluation conducted in this research, we not only enhance our understanding of the performance strengths and limitations of existing models in addressing public security issues but also provide references for the fu
    
[^115]: ANLS* -- 一种适用于生成型大语言模型的通用文档处理度量方法

    ANLS* -- A Universal Document Processing Metric for Generative Large Language Models

    [https://arxiv.org/abs/2402.03848](https://arxiv.org/abs/2402.03848)

    ANLS*是一种用于生成型模型的新度量方法，针对各种任务包括信息提取和分类任务进行评估。它扩展了现有的ANLS度量方法，可以作为替代方案使用。

    

    传统上，在文档分类和信息提取等任务中，区分模型一直是主要选择。这些模型做出的预测可以分为有限数量的预定义类别，便于进行二元真假评估，并能直接计算F1分数等指标。然而，生成型大语言模型（GLLMs）的最新进展促使领域发生了转变，因为它们具备了强大的零-shot能力，消除了下游数据集和计算昂贵的微调的需求。然而，评估GLLMs存在挑战，因为对于GLLMs的预测，不能应用于区分模型所使用的二元真假评估方法。本文引入了一种用于生成型模型的新度量方法，称为ANLS*，用于评估各种任务，包括信息提取和分类任务。ANLS*度量方法扩展了现有ANLS度量方法，可作为一种即插即用的替代方案。

    Traditionally, discriminative models have been the predominant choice for tasks like document classification and information extraction. These models make predictions that fall into a limited number of predefined classes, facilitating a binary true or false evaluation and enabling the direct calculation of metrics such as the F1 score. However, recent advancements in generative large language models (GLLMs) have prompted a shift in the field due to their enhanced zero-shot capabilities, which eliminate the need for a downstream dataset and computationally expensive fine-tuning. However, evaluating GLLMs presents a challenge as the binary true or false evaluation used for discriminative models is not applicable to the predictions made by GLLMs. This paper introduces a new metric for generative models called ANLS* for evaluating a wide variety of tasks, including information extraction and classification tasks. The ANLS* metric extends existing ANLS metrics as a drop-in-replacement and i
    
[^116]: EasyInstruct：一个易于使用的用于大型语言模型的指令处理框架

    EasyInstruct: An Easy-to-use Instruction Processing Framework for Large Language Models

    [https://arxiv.org/abs/2402.03049](https://arxiv.org/abs/2402.03049)

    EasyInstruct是一个易于使用的用于大型语言模型的指令处理框架，通过模块化指令生成、选择和提示，并考虑它们的组合和交互，使指令处理更加方便和高效。

    

    近年来，指令调整已经引起了越来越多的关注，并成为增强大型语言模型（LLMs）能力的一种关键技术。为了构建高质量的指令数据集，已经提出了许多指令处理方法，旨在在数据数量和数据质量之间达到精巧的平衡。然而，由于各种指令处理方法之间仍然存在不一致，目前没有标准的开源指令处理实现框架可供社区使用，这使得从业者无法进一步开发和推进。为了促进指令处理的研究和开发，我们提出了EasyInstruct，一个易于使用的用于LLMs的指令处理框架，它将指令生成、选择和提示模块化，并考虑它们的组合和交互。EasyInstruct已经在https://github.com/zjunlp/EasyInstruct上公开发布，并得到了积极维护。

    In recent years, instruction tuning has gained increasing attention and emerged as a crucial technique to enhance the capabilities of Large Language Models (LLMs). To construct high-quality instruction datasets, many instruction processing approaches have been proposed, aiming to achieve a delicate balance between data quantity and data quality. Nevertheless, due to inconsistencies that persist among various instruction processing methods, there is no standard open-source instruction processing implementation framework available for the community, which hinders practitioners from further developing and advancing. To facilitate instruction processing research and development, we present EasyInstruct, an easy-to-use instruction processing framework for LLMs, which modularizes instruction generation, selection, and prompting, while also considering their combination and interaction. EasyInstruct is publicly released and actively maintained at https://github.com/zjunlp/EasyInstruct, along 
    
[^117]: SLIM: 多判别器在技能学习中的应用

    SLIM: Skill Learning with Multiple Critics

    [https://arxiv.org/abs/2402.00823](https://arxiv.org/abs/2402.00823)

    SLIM是一种多判别器学习方法，通过在机器人操作中组合多个判别器的奖励函数，显著改善了潜变量技能发现，克服了奖励之间的干扰。

    

    自我监督的技能学习旨在获取利用环境的底层动态的有用行为。基于互信息最大化的潜变量模型在此任务中取得了显著的成功，但在机器人操作领域仍存在困难。由于机器人操作可能涉及到环境中很多自由度，单纯的互信息最大化无法产生有用的操作行为。为了解决这个问题，我们引入了SLIM，一种针对机器人操作的多判别器学习方法。我们的主要观点是，在演员-评论者框架中利用多个判别器来优雅地组合多个奖励函数，能够显著改善机器人操作的潜变量技能发现，同时克服奖励之间可能发生的干扰，阻碍对有用技能的收敛。

    Self-supervised skill learning aims to acquire useful behaviors that leverage the underlying dynamics of the environment. Latent variable models, based on mutual information maximization, have been particularly successful in this task but still struggle in the context of robotic manipulation. As it requires impacting a possibly large set of degrees of freedom composing the environment, mutual information maximization fails alone in producing useful manipulation behaviors. To address this limitation, we introduce SLIM, a multi-critic learning approach for skill discovery with a particular focus on robotic manipulation. Our main insight is that utilizing multiple critics in an actor-critic framework to gracefully combine multiple reward functions leads to a significant improvement in latent-variable skill discovery for robotic manipulation while overcoming possible interference occurring among rewards which hinders convergence to useful skills. Furthermore, in the context of tabletop man
    
[^118]: 图编辑用于反事实解释：一项比较研究

    Graph Edits for Counterfactual Explanations: A comparative study

    [https://arxiv.org/abs/2401.11609](https://arxiv.org/abs/2401.11609)

    研究通过比较监督和无监督的图神经网络方法，扩展了图编辑作为反事实解释的先前努力，探讨了将输入数据表示为图形对于生成黑箱图像分类器最小且有意义的反事实解释的性能和时间效率最佳的方法。

    

    反事实已被确立为一种流行的可解释性技术，利用一组最小的编辑来改变分类器的预测。在考虑图像上的概念反事实时，请求的编辑应对应输入数据中存在的显著概念。同时，概念距离由知识图谱定义，确保概念编辑的最优性。在这项工作中，我们通过进行比较研究扩展了以图编辑为反事实解释的先前努力，在这项研究中涵盖了监督和无监督的图神经网络（GNN）方法。到此为止，我们提出了以下重要的研究问题：我们应该将输入数据表示为图形，这是生成黑箱图像分类器的最小和有意义的反事实解释在性能和时间效率方面最佳的GNN方法吗？

    arXiv:2401.11609v2 Announce Type: replace-cross  Abstract: Counterfactuals have been established as a popular explainability technique which leverages a set of minimal edits to alter the prediction of a classifier. When considering conceptual counterfactuals on images, the edits requested should correspond to salient concepts present in the input data. At the same time, conceptual distances are defined by knowledge graphs, ensuring the optimality of conceptual edits. In this work, we extend previous endeavors on graph edits as counterfactual explanations by conducting a comparative study which encompasses both supervised and unsupervised Graph Neural Network (GNN) approaches. To this end, we pose the following significant research question: should we represent input data as graphs, which is the optimal GNN approach in terms of performance and time efficiency to generate minimal and meaningful counterfactual explanations for black-box image classifiers?
    
[^119]: 关于损失和基于不确定性的主动学习算法的收敛性

    On the convergence of loss and uncertainty-based active learning algorithms

    [https://arxiv.org/abs/2312.13927](https://arxiv.org/abs/2312.13927)

    论文考虑了损失和不确定性基础的主动学习算法在线性分类器和线性可分数据集上的收敛速度，提出了一种新算法并展示了其效率。

    

    我们考虑了在不同假设下损失和基于不确定性的主动学习算法的收敛速度。首先，我们建立了一组条件，确保在应用于线性分类器和线性可分数据集时的收敛速度。这包括证明各种损失函数的基于损失的采样的收敛速度保证。其次，我们引入了一个框架，通过利用已知的随机梯度下降算法的收敛速率界限，使我们能够导出损失采样的收敛速率界限。最后，我们提出了一种新算法，将点采样和随机Polyak步长相结合。我们建立了一个关于采样过程的条件，确保该算法的收敛速度保证，特别是在光滑凸损失函数的情况下。我们的数值结果展示了所提出算法的效率。

    arXiv:2312.13927v2 Announce Type: replace-cross  Abstract: We consider the convergence rates of loss and uncertainty-based active learning algorithms under various assumptions. Firstly, we establish a set of conditions that ensure convergence rates when applied to linear classifiers and linearly separable datasets. This includes demonstrating convergence rate guarantees for loss-based sampling with various loss functions. Secondly, we introduce a framework that allows us to derive convergence rate bounds for loss-based sampling by leveraging known convergence rate bounds for stochastic gradient descent algorithms. Lastly, we propose a new algorithm that combines point sampling and stochastic Polyak's step size. We establish a condition on the sampling process, ensuring a convergence rate guarantee for this algorithm, particularly in the case of smooth convex loss functions. Our numerical results showcase the efficiency of the proposed algorithm.
    
[^120]: 室内单视图材料估计的内在图像扩散

    Intrinsic Image Diffusion for Indoor Single-view Material Estimation

    [https://arxiv.org/abs/2312.12274](https://arxiv.org/abs/2312.12274)

    提出了内在图像扩散模型，应用于室内单视图材料估计，通过概率形式的条件生成模型采样解空间来解决外观分解中光照和材料属性之间的固有模糊性挑战。

    

    我们提出了内在图像扩散，这是一个用于室内场景外观分解的生成模型。给定单个输入视图，我们采样多种可能的材料解释，表示为反照率、粗糙度和金属度图。外观分解在计算机视觉中面临着重大挑战，因为光照和材料属性之间固有的模糊性以及缺乏真实数据集。为了解决这个问题，我们倡导概率形式，不是直接预测真实的材料属性，而是使用条件生成模型从解空间中进行采样。此外，我们表明利用最近扩散模型在大规模现实世界图像上训练的强大学习先验可以被调整为材料估计，并极大地改善对真实图像的泛化。我们的方法产生了明显更清晰、更一致和更详细的材料。

    arXiv:2312.12274v2 Announce Type: replace-cross  Abstract: We present Intrinsic Image Diffusion, a generative model for appearance decomposition of indoor scenes. Given a single input view, we sample multiple possible material explanations represented as albedo, roughness, and metallic maps. Appearance decomposition poses a considerable challenge in computer vision due to the inherent ambiguity between lighting and material properties and the lack of real datasets. To address this issue, we advocate for a probabilistic formulation, where instead of attempting to directly predict the true material properties, we employ a conditional generative model to sample from the solution space. Furthermore, we show that utilizing the strong learned prior of recent diffusion models trained on large-scale real-world images can be adapted to material estimation and highly improves the generalization to real images. Our method produces significantly sharper, more consistent, and more detailed material
    
[^121]: 加权集成模型是强大的持续学习者

    Weighted Ensemble Models Are Strong Continual Learners

    [https://arxiv.org/abs/2312.08977](https://arxiv.org/abs/2312.08977)

    通过加权集成模型实现了高准确性的持续学习，兼顾可塑性和稳定性。

    

    在本文中，我们研究持续学习（CL）的问题，其中目标是从一系列任务中学习模型，使得以前任务的数据在学习当前任务数据时不可用。CL本质上是在能够学习新任务（即可塑性）和保持先前学习概念的性能（即稳定性）之间取得平衡的过程。为了解决稳定性-可塑性的权衡问题，我们建议对先前和当前任务的模型参数进行加权集成。这种加权集成模型，我们称之为持续模型平均（或CoMA），通过利用可塑性在当前任务上获得高准确性，同时不会偏离太远的先前权重配置，从而确保稳定性。我们还提出了CoMA的改进型变体，名为持续费舍尔加权模型平均（或CoFiMA），该模型对每一个参数进行选择性加权。

    arXiv:2312.08977v2 Announce Type: replace-cross  Abstract: In this work, we study the problem of continual learning (CL) where the goal is to learn a model on a sequence of tasks, such that the data from the previous tasks becomes unavailable while learning on the current task data. CL is essentially a balancing act between being able to learn on the new task (i.e., plasticity) and maintaining the performance on the previously learned concepts (i.e., stability). Intending to address the stability-plasticity trade-off, we propose to perform weight-ensembling of the model parameters of the previous and current tasks. This weighted-ensembled model, which we call Continual Model Averaging (or CoMA), attains high accuracy on the current task by leveraging plasticity, while not deviating too far from the previous weight configuration, ensuring stability. We also propose an improved variant of CoMA, named Continual Fisher-weighted Model Averaging (or CoFiMA), that selectively weighs each para
    
[^122]: 探索大型语言模型以促进人机团队合作的可变自主性

    Exploring Large Language Models to Facilitate Variable Autonomy for Human-Robot Teaming

    [https://arxiv.org/abs/2312.07214](https://arxiv.org/abs/2312.07214)

    本文探讨了将大型语言模型集成到人机团队合作环境中，通过口头交流促进机器人的可变自主性，提出了基于GPT的多机器人测试台架环境，并进行了用户研究以验证其有效性和用户策略。

    

    在一个快速发展的数字化环境中，自主工具和机器人正变得司空见惯。鉴于这一发展的重要性，本文探讨了将大型语言模型（LLMs）如生成式预训练变压器（GPT）集成到人机团队合作环境中，通过口头人机交流手段促进可变自主性。我们在Unity虚拟现实（VR）环境中，基于GPT核心为动力的多机器人测试台架环境中引入了一个新颖的框架。该系统允许用户通过自然语言与机器人代理进行交互，每个代理都由独立的GPT核心提供动力。通过OpenAI的函数调用，我们弥合了不受结构约束的自然语言输入和结构化机器人动作之间的差距。一项涉及12名参与者的用户研究探讨了GPT-4的有效性，更重要的是，当给予机会进行自然对话时用户的策略。

    arXiv:2312.07214v2 Announce Type: replace-cross  Abstract: In a rapidly evolving digital landscape autonomous tools and robots are becoming commonplace. Recognizing the significance of this development, this paper explores the integration of Large Language Models (LLMs) like Generative pre-trained transformer (GPT) into human-robot teaming environments to facilitate variable autonomy through the means of verbal human-robot communication. In this paper, we introduce a novel framework for such a GPT-powered multi-robot testbed environment, based on a Unity Virtual Reality (VR) setting. This system allows users to interact with robot agents through natural language, each powered by individual GPT cores. By means of OpenAI's function calling, we bridge the gap between unstructured natural language input and structure robot actions. A user study with 12 participants explores the effectiveness of GPT-4 and, more importantly, user strategies when being given the opportunity to converse in nat
    
[^123]: 逆向学习：通过捡取学习放置

    Working Backwards: Learning to Place by Picking

    [https://arxiv.org/abs/2312.02352](https://arxiv.org/abs/2312.02352)

    通过逆向抓取过程并利用拾取和放置问题的对称性，提出了一种通过拾取的放置方法，并用自主收集的演示直接训练策略，实现在接触受限环境下物体放置任务的自主收集和泛化。

    

    我们提出了一种通过拾取（PvP）的放置方法，可以自主收集适用于一系列放置任务的现实世界演示，其中物体必须被操纵到特定的接触限制位置。通过PvP，我们通过颠倒抓取过程并利用拾取和放置问题固有的对称性，接近于机器人物体放置演示的收集。具体而言，我们从一组最初位于目标放置位置的物体的抓取序列中获得放置演示。我们的系统可以在接触受限环境中收集数百个演示，而无需人类干预，这是通过结合两个模块实现的：触觉重新抓取和用于抓取的顺从控制。我们通过行为克隆直接从视觉观察中通过自主收集的演示中训练策略。通过这样做，策略可以推广到超出训练环境范围的物体放置场景。

    arXiv:2312.02352v2 Announce Type: replace-cross  Abstract: We present placing via picking (PvP), a method to autonomously collect real-world demonstrations for a family of placing tasks in which objects must be manipulated to specific contact-constrained locations. With PvP, we approach the collection of robotic object placement demonstrations by reversing the grasping process and exploiting the inherent symmetry of the pick and place problems. Specifically, we obtain placing demonstrations from a set of grasp sequences of objects initially located at their target placement locations. Our system can collect hundreds of demonstrations in contact-constrained environments without human intervention by combining two modules: tactile regrasping and compliant control for grasps. We train a policy directly from visual observations through behavioral cloning, using the autonomously-collected demonstrations. By doing so, the policy can generalize to object placement scenarios outside of the tra
    
[^124]: LMM辅助的一致性嵌入下乳腺癌治疗目标分割

    LMM-Assisted Breast Cancer Treatment Target Segmentation with Consistency Embedding

    [https://arxiv.org/abs/2311.15876](https://arxiv.org/abs/2311.15876)

    RO-LMM是一个针对放射肿瘤学领域设计的多功能大型多模型，提出了一种Consistency Embedding Fine-Tuning（CEFTune）技术，使其能够在保持处理干净输入能力的同时提升对嘈杂输入的鲁棒性，用于放射治疗计划和目标体积分割。

    

    人工智能的最新进展深刻影响了医学领域，为降低临床工作量提供了工具。然而，大多数人工智能模型受限于执行单模式任务，与医学专业人员所使用的综合方法形成鲜明对比。为解决这一问题，本文介绍了RO-LMM，一个专为放射肿瘤学领域设计的多功能大型多模型（LMM）。该模型涵盖了临床工作流中的一系列任务，擅长临床报告摘要、放疗治疗计划建议和计划引导的目标体积分割。为了执行连续的临床任务，我们进一步提出了一种新颖的一致性嵌入微调（CEFTune）技术，提升了LMM对嘈杂输入的鲁棒性，同时保持了处理干净输入的能力，并将该概念转化为LMM驱动的分割框架，即一致性嵌入S。

    arXiv:2311.15876v2 Announce Type: replace-cross  Abstract: Recent advancements in Artificial Intelligence (AI) have profoundly influenced medical fields, by providing tools to reduce clinical workloads. However, most AI models are constrained to execute unimodal tasks, in stark contrast to the comprehensive approaches utilized by medical professionals. To address this, here we present RO-LMM, a multi-purpose large multimodal model (LMM) tailored for the field of radiation oncology. This model covers series of tasks within clinical workflow, adept at clinical report summarization, radiation treatment plan suggestion, and plan-guided target volume segmentation. In particular, to perform consecutive clinical tasks, we further present a novel Consistency Embedding Fine-Tuning (CEFTune) technique, which boosts LMM's robustness to noisy inputs while preserving the capability of handling clean inputs, and transform this concept into LMM-driven segmentation framework as Consistency Embedding S
    
[^125]: 在自适应之前对齐：利用实体到区域对齐进行通用视频动作识别

    Align before Adapt: Leveraging Entity-to-Region Alignments for Generalizable Video Action Recognition

    [https://arxiv.org/abs/2311.15619](https://arxiv.org/abs/2311.15619)

    提出了一种“对齐前自适应”（ALT）范式，通过利用实体到区域对齐，将文本嵌入作为查询，从而帮助提取视频中最重要实体的语义。

    

    大规模的视觉-语言预训练模型在各种视频任务中取得了重大成功。然而，大多数现有方法遵循“自适应然后对齐”的范式，将预训练图像编码器调整为建模视频级表示，并利用动作标签的one-hot或文本嵌入进行监督。本文提出了一种新颖的“对齐前自适应”（ALT）范式。在适应到视频表示学习之前，我们利用为每一帧实体到区域对齐。这些对齐通过将区域感知图像嵌入与离线构建的文本语料库进行匹配来实现。有了对齐的实体，我们将它们的文本嵌入作为查询馈送到基于transformer的视频适配器中，可以帮助从视频到向量提取最重要实体的语义。

    arXiv:2311.15619v2 Announce Type: replace-cross  Abstract: Large-scale visual-language pre-trained models have achieved significant success in various video tasks. However, most existing methods follow an "adapt then align" paradigm, which adapts pre-trained image encoders to model video-level representations and utilizes one-hot or text embedding of the action labels for supervision. This paradigm overlooks the challenge of mapping from static images to complicated activity concepts. In this paper, we propose a novel "Align before Adapt" (ALT) paradigm. Prior to adapting to video representation learning, we exploit the entity-to-region alignments for each frame. The alignments are fulfilled by matching the region-aware image embeddings to an offline-constructed text corpus. With the aligned entities, we feed their text embeddings to a transformer-based video adapter as the queries, which can help extract the semantics of the most important entities from a video to a vector. This parad
    
[^126]: Point2RBox: 结合合成视觉模式的知识用于端到端有单点监督的定向物体检测

    Point2RBox: Combine Knowledge from Synthetic Visual Patterns for End-to-end Oriented Object Detection with Single Point Supervision

    [https://arxiv.org/abs/2311.14758](https://arxiv.org/abs/2311.14758)

    提出了Point2RBox方法，通过合成模式知识组合和变换自监督的原则，实现了单点监督的定向物体检测

    

    随着对定向物体检测（OOD）需求的迅速增加，最近涉及从水平框（HBox）学习旋转框（RBox）的弱监督检测器的研究越来越受到关注。本文探讨了一个更具挑战性但标签效率高的设置，即单点监督OOD，并提出了我们的方法Point2RBox。具体来说，我们提出利用两个原则：1）合成模式知识组合：通过在图像上每个标记点周围采样，我们将对象特征传播到已知框的合成视觉模式中，以提供箱子回归的知识。2）变换自监督：通过一个变换的输入图像（例如缩放/旋转），输出的RBoxes被训练以遵循相同的变换，从而使网络能够感知对象之间的相对大小/旋转。检测器进一步通过几种设计的技术增强了

    arXiv:2311.14758v2 Announce Type: replace-cross  Abstract: With the rapidly increasing demand for oriented object detection (OOD), recent research involving weakly-supervised detectors for learning rotated box (RBox) from the horizontal box (HBox) has attracted more and more attention. In this paper, we explore a more challenging yet label-efficient setting, namely single point-supervised OOD, and present our approach called Point2RBox. Specifically, we propose to leverage two principles: 1) Synthetic pattern knowledge combination: By sampling around each labeled point on the image, we spread the object feature to synthetic visual patterns with known boxes to provide the knowledge for box regression. 2) Transform self-supervision: With a transformed input image (e.g. scaled/rotated), the output RBoxes are trained to follow the same transformation so that the network can perceive the relative size/rotation between objects. The detector is further enhanced by a few devised techniques to 
    
[^127]: 通过语言纠正提炼和检索机器人操作的通用知识

    Distilling and Retrieving Generalizable Knowledge for Robot Manipulation via Language Corrections

    [https://arxiv.org/abs/2311.10678](https://arxiv.org/abs/2311.10678)

    本研究提出了一种基于大型语言模型的系统，名为DROC，能够回应任意形式的语言反馈，从纠正中提炼出通用知识，并根据文本和视觉相似性检索相关的过去经验，以改进机器人操作的性能。

    

    今天的机器人政策在面对推广到新环境的挑战时表现不佳。人类的纠正反馈是一种至关重要的指导形式，可以实现这种泛化。然而，适应和从在线人类纠正中学习是一项不容易的任务：机器人不仅需要随时间记住人类的反馈以便在新环境中检索正确的信息并降低干涉率，而且还需要能够回应可能是关于高级人类偏好的任意纠正到技能参数的低级调整。在这项工作中，我们提出了基于大型语言模型(LLM)的在线纠正蒸馏和检索(DROC)系统，它可以回应任意形式的语言反馈，从纠正中提炼出通用知识，并根据文本和视觉相似性检索相关的过去经验，以改进性能。

    arXiv:2311.10678v2 Announce Type: replace-cross  Abstract: Today's robot policies exhibit subpar performance when faced with the challenge of generalizing to novel environments. Human corrective feedback is a crucial form of guidance to enable such generalization. However, adapting to and learning from online human corrections is a non-trivial endeavor: not only do robots need to remember human feedback over time to retrieve the right information in new settings and reduce the intervention rate, but also they would need to be able to respond to feedback that can be arbitrary corrections about high-level human preferences to low-level adjustments to skill parameters. In this work, we present Distillation and Retrieval of Online Corrections (DROC), a large language model (LLM)-based system that can respond to arbitrary forms of language feedback, distill generalizable knowledge from corrections, and retrieve relevant past experiences based on textual and visual similarity for improving p
    
[^128]: TD-MPC2：可扩展、稳健的连续控制世界模型

    TD-MPC2: Scalable, Robust World Models for Continuous Control

    [https://arxiv.org/abs/2310.16828](https://arxiv.org/abs/2310.16828)

    TD-MPC2是对TD-MPC算法的一系列改进，通过一组超参数在104个在线RL任务中取得了显著进展，成功训练单一的317M参数代理执行80个任务。

    

    TD-MPC是一种基于模型的强化学习（RL）算法，它在学习的隐式（无解码器）世界模型的潜在空间中执行局部轨迹优化。在这项工作中，我们展示了TD-MPC2：对TD-MPC算法的一系列改进。我们证明TD-MPC2在跨越4个不同任务领域的104个在线RL任务中显著改善了基线，通过一组超参数实现了持续强大的结果。我们进一步展示了随着模型和数据规模的增加，代理的能力也在增强，并成功训练了一个单一的317M参数代理，在多个任务领域、具象和动作空间中执行了80个任务。最后，我们总结了大型TD-MPC2代理所涉及的教训、机会和风险。在https://tdmpc2.com上探索视频、模型、数据、代码等。

    arXiv:2310.16828v2 Announce Type: replace-cross  Abstract: TD-MPC is a model-based reinforcement learning (RL) algorithm that performs local trajectory optimization in the latent space of a learned implicit (decoder-free) world model. In this work, we present TD-MPC2: a series of improvements upon the TD-MPC algorithm. We demonstrate that TD-MPC2 improves significantly over baselines across 104 online RL tasks spanning 4 diverse task domains, achieving consistently strong results with a single set of hyperparameters. We further show that agent capabilities increase with model and data size, and successfully train a single 317M parameter agent to perform 80 tasks across multiple task domains, embodiments, and action spaces. We conclude with an account of lessons, opportunities, and risks associated with large TD-MPC2 agents. Explore videos, models, data, code, and more at https://tdmpc2.com
    
[^129]: 图排名对比学习：一种极其简单而高效的方法

    Graph Ranking Contrastive Learning: A Extremely Simple yet Efficient Method

    [https://arxiv.org/abs/2310.14525](https://arxiv.org/abs/2310.14525)

    图对比学习（GCL）作为一种代表性的图自监督方法，提出了一种旨在减轻假阴性影响的极其简单而有效的方法。

    

    图对比学习（GCL）作为一种代表性的图自监督方法已经取得了显著的成功。目前普遍采用的GCL优化目标是InfoNCE。通常，它采用增强技术获得两个视图，其中一个视图中的节点充当锚点，另一个视图中的对应节点充当正样本，所有其他节点被视为负样本。其目标是最小化锚点与正样本之间的距离，并最大化到负样本的距离。然而，在训练期间由于缺乏标签信息，InfoNCE必然将来自相同类别的样本视为负样本，导致假负样本问题。这可能损害学到的节点表示，并随后阻碍下游任务的性能。尽管已经提出了许多方法来减轻假阴性的影响。

    arXiv:2310.14525v2 Announce Type: replace-cross  Abstract: Graph contrastive learning (GCL) has emerged as a representative graph self-supervised method, achieving significant success. The currently prevalent optimization objective for GCL is InfoNCE. Typically, it employs augmentation techniques to obtain two views, where a node in one view acts as the anchor, the corresponding node in the other view serves as the positive sample, and all other nodes are regarded as negative samples. The goal is to minimize the distance between the anchor node and positive samples and maximize the distance to negative samples. However, due to the lack of label information during training, InfoNCE inevitably treats samples from the same class as negative samples, leading to the issue of false negative samples. This can impair the learned node representations and subsequently hinder performance in downstream tasks. While numerous methods have been proposed to mitigate the impact of false negatives, they
    
[^130]: 一种可解释的三维框架揭示学习模式：变量脑沟识别的统一视角

    An explainable three dimension framework to uncover learning patterns: A unified look in variable sulci recognition

    [https://arxiv.org/abs/2309.00903](https://arxiv.org/abs/2309.00903)

    该论文提出了一个针对医学成像中的可解释AI的三维框架，旨在解决神经科学领域中识别大脑沟特征的复杂性问题。

    

    可解释的人工智能在医学成像中至关重要。在挑战性的神经科学领域里，视觉主题在三维空间内表现出高度复杂性。神经科学的应用涉及从MRI中识别大脑沟特征，由于专家之间的标注规程存在差异和大脑复杂的三维功能，我们面临着重大障碍。因此，传统的可解释性方法在有效验证和评估这些网络方面表现不佳。为了解决这个问题，我们首先提出了数学公式，细化了不同计算机视觉任务中解释需求的各种类别，分为自解释、半解释、非解释和基于验证协议可靠性的新模式学习应用。根据这个数学公式，我们提出了一个旨在解释三维的框架。

    arXiv:2309.00903v2 Announce Type: replace-cross  Abstract: Explainable AI is crucial in medical imaging. In the challenging field of neuroscience, visual topics present a high level of complexity, particularly within three-dimensional space. The application of neuroscience, which involves identifying brain sulcal features from MRI, faces significant hurdles due to varying annotation protocols among experts and the intricate three-dimension functionality of the brain. Consequently, traditional explainability approaches fall short in effectively validating and evaluating these networks. To address this, we first present a mathematical formulation delineating various categories of explanation needs across diverse computer vision tasks, categorized into self-explanatory, semi-explanatory, non-explanatory, and new-pattern learning applications based on the reliability of the validation protocol. With respect to this mathematical formulation, we propose a 3D explainability framework aimed at
    
[^131]: RecMind：大型语言模型驱动的推荐代理

    RecMind: Large Language Model Powered Agent For Recommendation

    [https://arxiv.org/abs/2308.14296](https://arxiv.org/abs/2308.14296)

    RecMind是一种LLM驱动的自主推荐代理，通过Self-Inspiring算法提高了规划能力，能够为零-shot个性化推荐提供支持。

    

    推荐系统（RS）通过深度学习取得了显著进展，但当前RS方法通常在特定任务数据集上训练和微调模型，限制了它们对新推荐任务的泛化能力以及利用外部知识的能力，因为模型规模和数据大小的限制。因此，我们设计了一种LLM驱动的自主推荐代理RecMind，能够利用外部知识，利用谨慎规划的工具为零-shot个性化推荐提供支持。我们提出了一种Self-Inspiring算法来提高规划能力。在每个中间步骤，LLM自我激励以考虑所有先前探索过的状态来规划下一步。这一机制极大地提高了模型理解和利用历史信息规划推荐的能力。我们评估了RecMind在各种推荐场景中的性能。

    arXiv:2308.14296v2 Announce Type: replace-cross  Abstract: While the recommendation system (RS) has advanced significantly through deep learning, current RS approaches usually train and fine-tune models on task-specific datasets, limiting their generalizability to new recommendation tasks and their ability to leverage external knowledge due to model scale and data size constraints. Thus, we designed an LLM-powered autonomous recommender agent, RecMind, which is capable of leveraging external knowledge, utilizing tools with careful planning to provide zero-shot personalized recommendations. We propose a Self-Inspiring algorithm to improve the planning ability. At each intermediate step, the LLM self-inspires to consider all previously explored states to plan for the next step. This mechanism greatly improves the model's ability to comprehend and utilize historical information in planning for recommendation. We evaluate RecMind's performance in various recommendation scenarios. Our exper
    
[^132]: 没有数据访问的深度分类器模拟

    Deep Classifier Mimicry without Data Access

    [https://arxiv.org/abs/2306.02090](https://arxiv.org/abs/2306.02090)

    提出了一种无需访问原始数据的模型-无关知识蒸馏过程CAKE，可以模拟深度分类器，通过生成噪声合成样本对比地扩散到模型的决策边界。

    

    最近，对预先训练模型的访问已经成为许多机器学习领域的标准。不幸的是，可能无法等同地获得模型训练所需的原始数据。这使得微调、压缩模型、持续调整或进行任何其他类型的数据驱动更新变得极具挑战性。我们认为可能无需原始数据访问。具体而言，我们提出了对比推理知识提取（CAKE），这是一种模型无关的知识蒸馏过程，可以模拟深度分类器而无需访问原始数据。为此，CAKE生成一对噪声合成样本，并将它们对比地扩散到模型的决策边界。我们通过几个基准数据集和各种架构选择在实证上证实了CAKE的有效性，为广泛应用铺平了道路。

    arXiv:2306.02090v2 Announce Type: replace-cross  Abstract: Access to pre-trained models has recently emerged as a standard across numerous machine learning domains. Unfortunately, access to the original data the models were trained on may not equally be granted. This makes it tremendously challenging to fine-tune, compress models, adapt continually, or to do any other type of data-driven update. We posit that original data access may however not be required. Specifically, we propose Contrastive Abductive Knowledge Extraction (CAKE), a model-agnostic knowledge distillation procedure that mimics deep classifiers without access to the original data. To this end, CAKE generates pairs of noisy synthetic samples and diffuses them contrastively toward a model's decision boundary. We empirically corroborate CAKE's effectiveness using several benchmark datasets and various architectural choices, paving the way for broad application.
    
[^133]: 通过元学习和代表性语言化器实现有效的结构化提示

    Effective Structured Prompting by Meta-Learning and Representative Verbalizer

    [https://arxiv.org/abs/2306.00618](https://arxiv.org/abs/2306.00618)

    通过使用提示池和构建基于实例的提示以及引入新颖的软语言化器，提出了一种通过元学习和代表性语言化器实现有效的结构化提示的方法

    

    预训练的遮蔽语言模型（MLM）的提示调整在自然语言处理任务中显示出有限标记示例的良好性能。它为下游任务调整提示，并使用语言化器来连接预测的标记和标签预测。由于训练数据有限，提示初始化对于提示调整至关重要。最近，MetaPrompting（Hou等，2022）使用元学习来学习所有特定任务提示的共享初始化。然而，当任务复杂时，单一初始化无法获得所有任务和样本的良好提示。此外，由于MLM通常很大，MetaPrompting需要调整整个MLM，导致计算和内存负担沉重。为了解决这些问题，我们使用提示池提取更多任务知识，并通过注意力构建基于实例的提示。我们进一步提出了一种新颖的软语言化器（RepVerb）...（剩余内容未提供）

    arXiv:2306.00618v2 Announce Type: replace-cross  Abstract: Prompt tuning for pre-trained masked language models (MLM) has shown promising performance in natural language processing tasks with few labeled examples. It tunes a prompt for the downstream task, and a verbalizer is used to bridge the predicted token and label prediction. Due to the limited training data, prompt initialization is crucial for prompt tuning. Recently, MetaPrompting (Hou et al., 2022) uses meta-learning to learn a shared initialization for all task-specific prompts. However, a single initialization is insufficient to obtain good prompts for all tasks and samples when the tasks are complex. Moreover, MetaPrompting requires tuning the whole MLM, causing a heavy burden on computation and memory as the MLM is usually large. To address these issues, we use a prompt pool to extract more task knowledge and construct instance-dependent prompts via attention. We further propose a novel soft verbalizer (RepVerb) which con
    
[^134]: 面向解释神经代码模型的因果论理论

    Toward a Theory of Causation for Interpreting Neural Code Models

    [https://arxiv.org/abs/2302.03788](https://arxiv.org/abs/2302.03788)

    该论文介绍了一种名为$do_{code}$的后验解释方法，用于解释神经代码模型的预测，基于因果推断，旨在实现面向编程语言的解释。

    

    Neural Language Models of Code，或者称为神经代码模型（NCMs），正在迅速从研究原型发展为商业开发者工具。因此，理解这些模型的能力和局限性变得至关重要。然而，这些模型的能力通常是使用自动化指标来衡量的，这些指标通常只能揭示它们真实性能的一部分。一般来说，NCMs的性能似乎很有前途，但目前关于这些模型如何做出决策仍有很多未知。因此，本文介绍了一种名为$do_{code}$的后验解释方法，该方法专门针对NCMs，能够解释模型的预测。$do_{code}$基于因果推断，以实现面向编程语言的解释。虽然$do_{code}$的理论基础可扩展到探索不同的模型属性，但我们提供了一个具体的实例，旨在减少影响...

    arXiv:2302.03788v2 Announce Type: replace-cross  Abstract: Neural Language Models of Code, or Neural Code Models (NCMs), are rapidly progressing from research prototypes to commercial developer tools. As such, understanding the capabilities and limitations of such models is becoming critical. However, the abilities of these models are typically measured using automated metrics that often only reveal a portion of their real-world performance. While, in general, the performance of NCMs appears promising, currently much is unknown about how such models arrive at decisions. To this end, this paper introduces $do_{code}$, a post hoc interpretability method specific to NCMs that is capable of explaining model predictions. $do_{code}$ is based upon causal inference to enable programming language-oriented explanations. While the theoretical underpinnings of $do_{code}$ are extensible to exploring different model properties, we provide a concrete instantiation that aims to mitigate the impact o
    
[^135]: 无需访问敏感属性的公平分类超参数调整

    Hyper-parameter Tuning for Fair Classification without Sensitive Attribute Access

    [https://arxiv.org/abs/2302.01385](https://arxiv.org/abs/2302.01385)

    提出了Antigone框架，可以在训练数据或验证数据中都无需访问敏感属性即可训练公平的分类器，通过生成伪敏感属性来实现。

    

    公平的机器学习方法旨在训练能够在基于种族和性别等敏感属性定义的人口统计亚组之间平衡模型性能的模型。然而，在训练期间通常假定敏感属性已知，但由于隐私和其他后勤方面的考虑，实践中可能无法获取这些属性。最近的研究致力于在训练数据上没有敏感属性的情况下训练公平模型。然而，这些方法需要进行大量的超参数调整才能获得良好结果，因此假设在验证数据上已知敏感属性。然而，这种假设在实践中也可能不切实际。因此，在这里，我们提出了Antigone，这是一个框架，可以在训练数据或验证数据中都无需访问敏感属性即可训练公平的分类器。相反，我们通过训练有偏见的分类器并使用分类器错误（正确）标记的方式在验证数据上生成伪敏感属性。

    arXiv:2302.01385v2 Announce Type: replace-cross  Abstract: Fair machine learning methods seek to train models that balance model performance across demographic subgroups defined over sensitive attributes like race and gender. Although sensitive attributes are typically assumed to be known during training, they may not be available in practice due to privacy and other logistical concerns. Recent work has sought to train fair models without sensitive attributes on training data. However, these methods need extensive hyper-parameter tuning to achieve good results, and hence assume that sensitive attributes are known on validation data. However, this assumption too might not be practical. Here, we propose Antigone, a framework to train fair classifiers without access to sensitive attributes on either training or validation data. Instead, we generate pseudo sensitive attributes on the validation data by training a biased classifier and using the classifier's incorrectly (correctly) labeled 
    
[^136]: 多尺度对比知识共同蒸馏用于事件时间关系抽取

    Multi-Scale Contrastive Knowledge Co-Distillation for Event Temporal Relation Extraction

    [https://arxiv.org/abs/2209.00568](https://arxiv.org/abs/2209.00568)

    提出了MulCo：多尺度对比知识共同蒸馏用于全面提高所有类型时间数据集性能

    

    事件时间关系抽取（ETRE）是一个关键但具有挑战性的问题。事件对位于不同距离的话语中，我们称之为接近性带。关于位于更远（即“长”）或更近（即“短”）接近性带的事件对的时间顺序传达方式不同。目前ETRE模型往往在位于短或长接近性带的事件上表现良好，但不能同时表现良好。然而，现实世界中的自然文本包含所有类型的时间事件对。在本文中，我们提出了MulCo：多尺度对比知识共同蒸馏，这是一种融合方法，可以跨多个事件对接近性带共享知识，以提高对所有类型时间数据集的性能。我们的实验结果表明MulCo成功地整合了跨短和长接近性带的与时间推理相关的语言线索。

    arXiv:2209.00568v2 Announce Type: replace-cross  Abstract: Event Temporal Relation Extraction (ETRE) is a crucial yet challenging problem. Event pairs are situated within a discourse at different distances, which we refer to as proximity bands. The temporal ordering communicated about event pairs situated at more remote (i.e., ``long'') or less remote (i.e., ``short'') proximity bands is encoded differently. SOTA ETRE models have tended to perform well on events situated at either short or long proximity bands, but not both. Yet, real-world, natural texts contain all types of temporal event-pairs. In this paper, we present MulCo: Multi-Scale Contrastive Knowledge Co-Distillation, a fusion approach that shares knowledge across multiple event pair proximity bands in order to improve performance on all types of temporal datasets. Our experimental results show that MulCo successfully integrates linguistic cues pertaining to temporal reasoning across both short and long proximity bands and 
    
[^137]: 强化学习代理中的新兴支配等级

    Emergent Dominance Hierarchies in Reinforcement Learning Agents. (arXiv:2401.12258v1 [cs.MA])

    [http://arxiv.org/abs/2401.12258](http://arxiv.org/abs/2401.12258)

    本研究在强化学习中探讨了一种新的支配等级现象，并证明了在没有明确编程和内在奖励的情况下，强化学习代理能够自主发明、学习、实施和传递支配等级给新的群体。

    

    现代强化学习算法在各种任务中能够胜过人类。多智能体强化学习(MARL)设置提出了额外的挑战，成功的混合动机代理协作取决于个体和群体目标之间的微妙平衡。社会习惯和规范，往往受到人类机构的启发，被用作实现这种平衡的工具。在本文中，我们研究了一种基本且经过深入研究的社会习惯，即支配等级，它在动物和人类社会中都存在。我们将支配等级的行为理论应用于人工智能代理，并尽可能少地修改现有的术语和定义。我们证明，在没有明确编程或内在奖励的情况下，强化学习代理的群体能够发明、学习、实施和传递支配等级给新的群体。所产生的支配等级有一个

    Modern Reinforcement Learning (RL) algorithms are able to outperform humans in a wide variety of tasks. Multi-agent reinforcement learning (MARL) settings present additional challenges, and successful cooperation in mixed-motive groups of agents depends on a delicate balancing act between individual and group objectives. Social conventions and norms, often inspired by human institutions, are used as tools for striking this balance.  In this paper, we examine a fundamental, well-studied social convention that underlies cooperation in both animal and human societies: Dominance hierarchies.  We adapt the ethological theory of dominance hierarchies to artificial agents, borrowing the established terminology and definitions with as few amendments as possible. We demonstrate that populations of RL agents, operating without explicit programming or intrinsic rewards, can invent, learn, enforce, and transmit a dominance hierarchy to new populations. The dominance hierarchies that emerge have a 
    
[^138]: PhotoBot：通过自然语言引导的参考互动摄影

    PhotoBot: Reference-Guided Interactive Photography via Natural Language. (arXiv:2401.11061v1 [cs.CV])

    [http://arxiv.org/abs/2401.11061](http://arxiv.org/abs/2401.11061)

    PhotoBot是一个通过自然语言引导和机器人摄影师相互作用的自动化照片获取框架。它利用视觉语言模型和物体检测器来提供摄影建议，并通过视觉变换器计算相机的姿态调整，从而实现高质量的照片获取。

    

    我们介绍了一个名为PhotoBot的框架，它基于高级人类语言引导和机器人摄影师之间的相互作用，用于自动化的照片获取。我们建议通过从策展画廊中检索到的参考图片向用户传达摄影建议。我们利用视觉语言模型（VLM）和物体检测器，通过文本描述对参考图片进行特征化，并使用大型语言模型（LLM）通过基于用户语言查询的文本推理检索相关的参考图片。为了对应参考图片和观察到的场景，我们利用一个能够捕捉显著不同的图像的语义相似性的预训练特征的视觉变换器，通过解决一个透视n-点（PnP）问题来计算RGB-D相机的姿态调整。我们在配备有手腕相机的真实机械手臂上演示了我们的方法。我们的用户研究表明，由PhotoBot拍摄的照片具有良好的质量和效果。

    We introduce PhotoBot, a framework for automated photo acquisition based on an interplay between high-level human language guidance and a robot photographer. We propose to communicate photography suggestions to the user via a reference picture that is retrieved from a curated gallery. We exploit a visual language model (VLM) and an object detector to characterize reference pictures via textual descriptions and use a large language model (LLM) to retrieve relevant reference pictures based on a user's language query through text-based reasoning. To correspond the reference picture and the observed scene, we exploit pre-trained features from a vision transformer capable of capturing semantic similarity across significantly varying images. Using these features, we compute pose adjustments for an RGB-D camera by solving a Perspective-n-Point (PnP) problem. We demonstrate our approach on a real-world manipulator equipped with a wrist camera. Our user studies show that photos taken by PhotoBo
    
[^139]: FourCastNeXt：用有限计算资源提高FourCastNet的训练效果

    FourCastNeXt: Improving FourCastNet Training with Limited Compute. (arXiv:2401.05584v1 [cs.CV])

    [http://arxiv.org/abs/2401.05584](http://arxiv.org/abs/2401.05584)

    本研究提出了改进的方法，可以使用仅需基线要求的1%计算资源训练FourCastNet，并且保持了与基线相当或甚至更好的模型性能。

    

    最近，FourCastNet神经地球系统模型（NESM）在预测各种大气变量方面表现出了令人印象深刻的结果，该模型在ERA5再分析数据集上进行了训练。虽然与基本变压器相比，FourCastNet在序列长度上享有准线性的时间和内存复杂度，而基于ERA5从头开始训练FourCastNet仍然需要大量的计算资源，这对于大多数研究人员来说是昂贵甚至无法获得的。在本文中，我们将展示改进的方法，可以使用仅需要基线要求的1%计算资源来训练FourCastNet，同时保持模型性能至少与基线相当甚至更好。

    Recently, the FourCastNet Neural Earth System Model (NESM) has shown impressive results on predicting various atmospheric variables, trained on the ERA5 reanalysis dataset. While FourCastNet enjoys quasi-linear time and memory complexity in sequence length compared to quadratic complexity in vanilla transformers, training FourCastNet on ERA5 from scratch still requires large amount of compute resources, which is expensive or even inaccessible to most researchers. In this work, we will show improved methods that can train FourCastNet using only 1% of the compute required by the baseline, while maintaining model performance or par or even better than the baseline.
    
[^140]: 关于大型语言模型（LLM）的安全与隐私的调研：美好、恶劣和丑陋(arXiv:2312.02003v2 [cs.CR] UPDATED)

    A Survey on Large Language Model (LLM) Security and Privacy: The Good, the Bad, and the Ugly. (arXiv:2312.02003v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2312.02003](http://arxiv.org/abs/2312.02003)

    该论文调查了大型语言模型（LLM）与安全和隐私的相关性。研究发现LLMs在安全和隐私保护方面具有积极影响，但同时也存在潜在的风险、威胁和漏洞。

    

    大型语言模型（LLMs），如ChatGPT和Bard，已经革新了自然语言理解和生成。它们具有深入的语言理解能力、人类般的文本生成能力、语境感知和强大的问题解决能力，在各个领域（如搜索引擎、客户支持、翻译）中具有不可估量的价值。与此同时，LLMs也在安全领域引起了关注，揭示了安全漏洞，并展示了它们在安全相关任务中的潜力。本文探讨了LLMs与安全和隐私的交叉点。具体而言，我们研究了LLMs如何对安全和隐私产生积极影响，它们使用中可能存在的风险和威胁，以及LLMs内在的漏洞。通过综合文献回顾，本文将文献分为“美好”（有益的LLM应用）、“恶劣”（攻击性应用）和“丑陋”（LLMs的漏洞及其防御）。我们发现，

    Large Language Models (LLMs), such as ChatGPT and Bard, have revolutionized natural language understanding and generation. They possess deep language comprehension, human-like text generation capabilities, contextual awareness, and robust problem-solving skills, making them invaluable in various domains (e.g., search engines, customer support, translation). In the meantime, LLMs have also gained traction in the security community, revealing security vulnerabilities and showcasing their potential in security-related tasks. This paper explores the intersection of LLMs with security and privacy. Specifically, we investigate how LLMs positively impact security and privacy, potential risks and threats associated with their use, and inherent vulnerabilities within LLMs. Through a comprehensive literature review, the paper categorizes the papers into "The Good" (beneficial LLM applications), "The Bad" (offensive applications), and "The Ugly" (vulnerabilities of LLMs and their defenses). We ha
    
[^141]: RiskQ: 风险敏感的多智能体强化学习价值因子分解

    RiskQ: Risk-sensitive Multi-Agent Reinforcement Learning Value Factorization. (arXiv:2311.01753v1 [cs.MA])

    [http://arxiv.org/abs/2311.01753](http://arxiv.org/abs/2311.01753)

    RiskQ是一种解决多智能体强化学习中风险敏感协调要求的方法，通过引入风险敏感的个体-全局最大（RIGM）原则和建模联合回报分布实现价值因子分解。

    

    多智能体系统特点是环境不确定性、智能体的策略多样性和部分可观测性，这导致了显著的风险。在多智能体强化学习（MARL）的背景下，学习对风险敏感的协调和分散策略是具有挑战性的。为了在风险敏感的MARL中制定协调要求，我们介绍了风险敏感的个体-全局最大（RIGM）原理，作为个体-全局最大（IGM）和分布式IGM（DIGM）原理的一种推广。该原理要求每个智能体的风险敏感动作选择集合应与中央策略的风险敏感动作选择等价。当前的MARL价值因子分解方法对于常见的风险度量（例如风险价值（VaR）度量或扭曲的风险度量）不满足RIGM原则。因此，我们提出了RiskQ来解决这个限制，通过建模联合回报分布来实现价值因子分解。

    Multi-agent systems are characterized by environmental uncertainty, varying policies of agents, and partial observability, which result in significant risks. In the context of Multi-Agent Reinforcement Learning (MARL), learning coordinated and decentralized policies that are sensitive to risk is challenging. To formulate the coordination requirements in risk-sensitive MARL, we introduce the Risk-sensitive Individual-Global-Max (RIGM) principle as a generalization of the Individual-Global-Max (IGM) and Distributional IGM (DIGM) principles. This principle requires that the collection of risk-sensitive action selections of each agent should be equivalent to the risk-sensitive action selection of the central policy. Current MARL value factorization methods do not satisfy the RIGM principle for common risk metrics such as the Value at Risk (VaR) metric or distorted risk measurements. Therefore, we propose RiskQ to address this limitation, which models the joint return distribution by modeli
    
[^142]: VQPy：一种面向现代视频分析的面向对象方法。

    VQPy: An Object-Oriented Approach to Modern Video Analytics. (arXiv:2311.01623v1 [cs.CV])

    [http://arxiv.org/abs/2311.01623](http://arxiv.org/abs/2311.01623)

    VQPy是一种面向对象的视频分析方法，它使用Python变体作为前端，并具有可扩展的后端，可以自动构建和优化基于视频对象的处理流程。

    

    视频分析广泛应用于当今系统和服务中。在视频分析的前沿是用户开发的视频查询，以找到特定感兴趣的对象。基于视频对象（例如人，动物，汽车等）与传统面向对象语言建模的对象相似的洞察力，我们提出了一种面向视频分析的面向对象方法。这种方法名为VQPy，包括一个前端（一种Python变体，其中包含用户可以表达视频对象及其交互的结构）和一个可扩展的后端，可以基于视频对象自动生成和优化管道。我们已经实施和开源了VQPy，它已经作为Cisco DeepVision框架的一部分产品化。

    Video analytics is widely used in contemporary systems and services. At the forefront of video analytics are video queries that users develop to find objects of particular interest. Building upon the insight that video objects (e.g., human, animals, cars, etc.), the center of video analytics, are similar in spirit to objects modeled by traditional object-oriented languages, we propose to develop an object-oriented approach to video analytics. This approach, named VQPy, consists of a frontend$\unicode{x2015}$a Python variant with constructs that make it easy for users to express video objects and their interactions$\unicode{x2015}$as well as an extensible backend that can automatically construct and optimize pipelines based on video objects. We have implemented and open-sourced VQPy, which has been productized in Cisco as part of its DeepVision framework.
    
[^143]: 知道LLMs不知道什么：一种简单而有效的自我检测方法

    Knowing What LLMs DO NOT Know: A Simple Yet Effective Self-Detection Method. (arXiv:2310.17918v1 [cs.CL])

    [http://arxiv.org/abs/2310.17918](http://arxiv.org/abs/2310.17918)

    本文提出了一种新的自我检测方法，用于判断大型语言模型 (LLMs) 无法回答的问题，以避免生成非事实性的回答。通过多样化问题的文本表达，收集答案，并检查生成的答案之间的差异，可以识别出可能生成虚假回答的问题。该方法只需要利用LLMs自身，无需其他外部资源。这种方法在Vicuna、ChatGPT和GPT-4等最新发布的LLMs上得到了有效验证。

    

    大型语言模型（LLMs）在自然语言处理（NLP）任务中展现出巨大的潜力。然而，最近的文献揭示了LLMs会偶尔生成非事实性的回答，这影响了它们进一步利用的可靠性。在本文中，我们提出了一种新颖的自我检测方法，用于检测LLMs不知道的问题，以避免生成非事实性的结果。具体来说，我们首先使给定问题的文本表达多样化，并收集相应的答案。然后，我们检查生成的答案之间的差异，以识别模型可能生成虚假回答的问题。所有以上步骤都可以通过提示LLMs自身来完成，而无需参考任何其他外部资源。我们进行了全面的实验，并证明了我们方法在最近发布的LLMs（如Vicuna、ChatGPT和GPT-4）上的有效性。

    Large Language Models (LLMs) have shown great potential in Natural Language Processing (NLP) tasks. However, recent literature reveals that LLMs generate nonfactual responses intermittently, which impedes the LLMs' reliability for further utilization. In this paper, we propose a novel self-detection method to detect which questions that a LLM does not know that are prone to generate nonfactual results. Specifically, we first diversify the textual expressions for a given question and collect the corresponding answers. Then we examine the divergencies between the generated answers to identify the questions that the model may generate falsehoods. All of the above steps can be accomplished by prompting the LLMs themselves without referring to any other external resources. We conduct comprehensive experiments and demonstrate the effectiveness of our method on recently released LLMs, e.g., Vicuna, ChatGPT, and GPT-4.
    
[^144]: AutoDAN: 在对齐的大型语言模型上生成隐蔽的越狱提示

    AutoDAN: Generating Stealthy Jailbreak Prompts on Aligned Large Language Models. (arXiv:2310.04451v1 [cs.CL])

    [http://arxiv.org/abs/2310.04451](http://arxiv.org/abs/2310.04451)

    本文介绍了一种名为AutoDAN的方法，该方法旨在在对齐的大型语言模型上自动生成隐蔽的越狱提示，以解决现有越狱技术的可扩展性和隐蔽性问题。

    

    对齐的大型语言模型(LLM)是强大的语言理解和决策工具，通过与人类反馈进行广泛对齐而创建。然而，这些大型模型仍然容易受到越狱攻击的影响，攻击者可以操纵提示来引发对齐的LLM不应给出的恶意输出。研究越狱提示可以让我们深入了解LLM的局限性，并进一步指导我们如何保护它们。不幸的是，现有的越狱技术存在以下问题：(1) 可扩展性问题，攻击大量依赖手工制作提示；(2) 隐蔽性问题，攻击依赖基于标记的算法生成常常语义无意义的提示，容易通过基本困惑度测试检测。针对这些挑战，我们想回答这个问题：能否开发一种能够自动生成隐蔽越狱提示的方法？在本文中，我们介绍了AutoDAN方法。

    The aligned Large Language Models (LLMs) are powerful language understanding and decision-making tools that are created through extensive alignment with human feedback. However, these large models remain susceptible to jailbreak attacks, where adversaries manipulate prompts to elicit malicious outputs that should not be given by aligned LLMs. Investigating jailbreak prompts can lead us to delve into the limitations of LLMs and further guide us to secure them. Unfortunately, existing jailbreak techniques suffer from either (1) scalability issues, where attacks heavily rely on manual crafting of prompts, or (2) stealthiness problems, as attacks depend on token-based algorithms to generate prompts that are often semantically meaningless, making them susceptible to detection through basic perplexity testing. In light of these challenges, we intend to answer this question: Can we develop an approach that can automatically generate stealthy jailbreak prompts? In this paper, we introduce Auto
    
[^145]: ED-NeRF: 使用潜空间 NeRF 实现高效的文本引导的 3D 场景编辑

    ED-NeRF: Efficient Text-Guided Editing of 3D Scene using Latent Space NeRF. (arXiv:2310.02712v1 [cs.CV])

    [http://arxiv.org/abs/2310.02712](http://arxiv.org/abs/2310.02712)

    ED-NeRF 提出了一种高效的 3D 场景编辑方法，通过将场景嵌入到潜空间中，得到更快速且更易于编辑的 NeRF 骨干。

    

    最近，文本到图像扩散模型取得了显著进展，在二维图像生成方面取得了突破性的性能。这些进展已经扩展到三维模型，实现了从文本描述中生成新的三维对象。这演变成了 NeRF 编辑方法，通过文本条件允许对现有的三维对象进行操作。然而，现有的 NeRF 编辑技术在性能上面临着一些限制，如训练速度慢和使用的损失函数不充分考虑编辑。为了解决这个问题，我们提出了一种新颖的 3D NeRF 编辑方法，称为 ED-NeRF，通过将真实世界场景成功嵌入到潜扩散模型 (LDM) 的潜空间中，通过独特的细化层。这种方法使我们能够获得一个不仅更快，而且更适合于编辑的 NeRF 骨干，与传统的图像空间 NeRF 编辑相比。此外，我们提出了一种改进的损失函数。

    Recently, there has been a significant advancement in text-to-image diffusion models, leading to groundbreaking performance in 2D image generation. These advancements have been extended to 3D models, enabling the generation of novel 3D objects from textual descriptions. This has evolved into NeRF editing methods, which allow the manipulation of existing 3D objects through textual conditioning. However, existing NeRF editing techniques have faced limitations in their performance due to slow training speeds and the use of loss functions that do not adequately consider editing. To address this, here we present a novel 3D NeRF editing approach dubbed ED-NeRF by successfully embedding real-world scenes into the latent space of the latent diffusion model (LDM) through a unique refinement layer. This approach enables us to obtain a NeRF backbone that is not only faster but also more amenable to editing compared to traditional image space NeRF editing. Furthermore, we propose an improved loss 
    
[^146]: 在一千年前的拉丁文本中检测句子级别的性内容

    Detecting Sexual Content at the Sentence Level in First Millennium Latin Texts. (arXiv:2309.14974v1 [cs.CL])

    [http://arxiv.org/abs/2309.14974](http://arxiv.org/abs/2309.14974)

    该研究提出使用深度学习方法在句子级别进行语义分类，以加速人文学科和语言学领域中语料库建设的过程。经过评估，该方法在检测性内容方面表现出高精度和真阳性率，并探索了不同的输入嵌入层对模型性能的影响。

    

    在这项研究中，我们提出使用深度学习方法在句子级别进行语义分类，以加快人文学科和语言学领域中语料库建设的过程，这是一项传统且耗时的任务。我们引入了一个新颖的语料库，包括约2500个句子，涵盖了从公元前300年到公元900年的性语义学（医学，情色等）。我们评估了各种句子分类方法和不同的输入嵌入层，并表明它们都比简单的基于标记的搜索方法更好。我们探索了个人言语和社会言语元数据嵌入（世纪，作者，写作类型）的整合，但发现这导致了过拟合。我们的结果表明了这种方法的有效性，使用HAN分别达到了70.60%的高精度和86.33%的真阳性率（TPR）。我们评估了数据集大小对模型性能的影响（420而不是2013），并显示出，尽管我们的模型性能可能稍有下降，但性能仍然稳定。

    In this study, we propose to evaluate the use of deep learning methods for semantic classification at the sentence level to accelerate the process of corpus building in the field of humanities and linguistics, a traditional and time-consuming task. We introduce a novel corpus comprising around 2500 sentences spanning from 300 BCE to 900 CE including sexual semantics (medical, erotica, etc.). We evaluate various sentence classification approaches and different input embedding layers, and show that all consistently outperform simple token-based searches. We explore the integration of idiolectal and sociolectal metadata embeddings (centuries, author, type of writing), but find that it leads to overfitting. Our results demonstrate the effectiveness of this approach, achieving high precision and true positive rates (TPR) of respectively 70.60% and 86.33% using HAN. We evaluate the impact of the dataset size on the model performances (420 instead of 2013), and show that, while our models per
    
[^147]: 序列到序列的西班牙预训练语言模型

    Sequence-to-Sequence Spanish Pre-trained Language Models. (arXiv:2309.11259v1 [cs.CL])

    [http://arxiv.org/abs/2309.11259](http://arxiv.org/abs/2309.11259)

    该论文介绍了一种新的序列到序列的西班牙预训练语言模型，该模型在各种序列到序列任务中表现出了竞争性能，并提供了BART、T5和BERT2BERT-style模型的西班牙版本。

    

    近年来，预训练语言模型的重大进展为许多非英语语言版本的开发铺平了道路，其中特别关注了仅编码器和仅解码器的架构。虽然西班牙语语言模型包括BERT、RoBERTa和GPT在自然语言理解和生成方面展现出了优势，但在涉及输入输出对的序列到序列任务中，缺乏编码器-解码器模型。本文通过引入实施和评估著名的仅在西班牙语语料库上进行预训练的编码器-解码器架构，开创了新的领域。具体而言，我们提出了BART、T5和BERT2BERT风格模型的西班牙语版本，并对它们在各种序列到序列任务上进行了全面评估，包括摘要、重述和生成式问答。我们的研究结果强调了所有模型的竞争性能，其中BART和T5表现出色。

    In recent years, substantial advancements in pre-trained language models have paved the way for the development of numerous non-English language versions, with a particular focus on encoder-only and decoder-only architectures. While Spanish language models encompassing BERT, RoBERTa, and GPT have exhibited prowess in natural language understanding and generation, there remains a scarcity of encoder-decoder models designed for sequence-to-sequence tasks involving input-output pairs. This paper breaks new ground by introducing the implementation and evaluation of renowned encoder-decoder architectures, exclusively pre-trained on Spanish corpora. Specifically, we present Spanish versions of BART, T5, and BERT2BERT-style models and subject them to a comprehensive assessment across a diverse range of sequence-to-sequence tasks, spanning summarization, rephrasing, and generative question answering. Our findings underscore the competitive performance of all models, with BART and T5 emerging a
    
[^148]: 通过精细的模态评估增强多模态协作

    Enhancing Multi-modal Cooperation via Fine-grained Modality Valuation. (arXiv:2309.06255v1 [cs.CV])

    [http://arxiv.org/abs/2309.06255](http://arxiv.org/abs/2309.06255)

    本文提出了一种精细的模态评估指标，用于评估每个模态在样本级别的贡献，并发现多模态模型倾向于依赖一个特定的模态，导致其他模态的贡献较低。

    

    多模态学习的一个主要问题是如何将来自不同模态的异质信息共同结合起来。然而，大多数模型在多模态协作方面常常存在不尽人意的问题，不能很好地共同利用所有模态。一些方法被提出来识别和增强学习效果较差的模态，但往往难以在理论上提供对样本级别多模态协作的细粒度观察和支持。因此，合理观察和改进模态之间细粒度的协作尤为重要，尤其是在面对模态差异在不同样本之间可能变化的实际场景时。为了实现这一目标，我们引入了一种精细的模态评估指标，以评估每个模态在样本级别的贡献。通过模态评估，我们遗憾地发现多模态模型倾向于依赖一个特定的模态，导致其他模态的贡献较低。我们进一步分析了这个问题。

    One primary topic of multi-modal learning is to jointly incorporate heterogeneous information from different modalities. However, most models often suffer from unsatisfactory multi-modal cooperation, which could not jointly utilize all modalities well. Some methods are proposed to identify and enhance the worse learnt modality, but are often hard to provide the fine-grained observation of multi-modal cooperation at sample-level with theoretical support. Hence, it is essential to reasonably observe and improve the fine-grained cooperation between modalities, especially when facing realistic scenarios where the modality discrepancy could vary across different samples. To this end, we introduce a fine-grained modality valuation metric to evaluate the contribution of each modality at sample-level. Via modality valuation, we regretfully observe that the multi-modal model tends to rely on one specific modality, resulting in other modalities being low-contributing. We further analyze this iss
    
[^149]: 从分层的弱偏好反馈中进行深度强化学习

    Deep Reinforcement Learning from Hierarchical Weak Preference Feedback. (arXiv:2309.02632v1 [cs.LG])

    [http://arxiv.org/abs/2309.02632](http://arxiv.org/abs/2309.02632)

    本研究探讨了如何利用分层的弱偏好反馈进行深度强化学习。通过学习奖励函数，与人类偏好非常一致的复杂奖励可以帮助强化学习解决日益困难的问题。

    

    奖励设计是实际强化学习中一个基本但具有挑战性的方面。对于简单任务，研究人员通常手工设计奖励函数，例如使用若干个奖励因子的线性组合。然而，这种奖励工程受到近似偏差的影响，需要大量的调优成本，并且通常无法提供复杂任务所需的细粒度。为了避免这些困难，研究人员开始转向从人类反馈中进行强化学习（RLHF），从轨迹序列对之间的人类偏好中学习奖励函数。通过利用基于偏好的奖励建模，RLHF学习到与人类偏好非常一致的复杂奖励，使得强化学习能够解决日益困难的问题。不幸的是，RLHF的适用性受到获得人类偏好数据的高成本和困难的限制。鉴于这个成本，我们研究了在复杂任务中使用更少人力投入的方式来学习奖励函数。

    Reward design is a fundamental, yet challenging aspect of practical reinforcement learning (RL). For simple tasks, researchers typically handcraft the reward function, e.g., using a linear combination of several reward factors. However, such reward engineering is subject to approximation bias, incurs large tuning cost, and often cannot provide the granularity required for complex tasks. To avoid these difficulties, researchers have turned to reinforcement learning from human feedback (RLHF), which learns a reward function from human preferences between pairs of trajectory sequences. By leveraging preference-based reward modeling, RLHF learns complex rewards that are well aligned with human preferences, allowing RL to tackle increasingly difficult problems. Unfortunately, the applicability of RLHF is limited due to the high cost and difficulty of obtaining human preference data. In light of this cost, we investigate learning reward functions for complex tasks with less human effort; sim
    
[^150]: TensorBank: 基于Tensor的湖仓库用于基础模型训练

    TensorBank:Tensor Lakehouse for Foundation Model Training. (arXiv:2309.02094v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2309.02094](http://arxiv.org/abs/2309.02094)

    TensorBank是一个基于Tensor的湖仓库，能够以高速从云对象存储流式传输张量到GPU内存，并通过使用分层统计指标进行查询加速。

    

    随着基础模型在自然语言之外的领域的兴起，存储和流式处理高维数据成为基础模型训练的关键需求。在本文中，我们介绍了TensorBank，一个能够基于复杂关系查询从云对象存储（COS）流式传输张量到GPU内存的百亿级张量湖仓库。我们使用分层统计指标（HSI）来加速查询。我们的架构允许使用HTTP范围读取来直接访问块级别的张量。一旦在GPU内存中，数据可以使用PyTorch转换进行转换。我们提供了一个通用的PyTorch数据集类型，配有相应的数据集工厂，用于将关系查询和请求的转换作为一个实例进行翻译。通过使用HSI，可以跳过不相关的块，而无需读取它们，因为这些索引包含不同层次分辨率级别上内容的统计信息。这是一个基于开放标准的有主观观点的架构。

    Storing and streaming high dimensional data for foundation model training became a critical requirement with the rise of foundation models beyond natural language. In this paper we introduce TensorBank, a petabyte scale tensor lakehouse capable of streaming tensors from Cloud Object Store (COS) to GPU memory at wire speed based on complex relational queries. We use Hierarchical Statistical Indices (HSI) for query acceleration. Our architecture allows to directly address tensors on block level using HTTP range reads. Once in GPU memory, data can be transformed using PyTorch transforms. We provide a generic PyTorch dataset type with a corresponding dataset factory translating relational queries and requested transformations as an instance. By making use of the HSI, irrelevant blocks can be skipped without reading them as those indices contain statistics on their content at different hierarchical resolution levels. This is an opinionated architecture powered by open standards and making h
    
[^151]: 可信的LLMs：评估大型语言模型对齐的调查和指南

    Trustworthy LLMs: a Survey and Guideline for Evaluating Large Language Models' Alignment. (arXiv:2308.05374v1 [cs.AI])

    [http://arxiv.org/abs/2308.05374](http://arxiv.org/abs/2308.05374)

    本文介绍了一份关于评估LLM可信度的综合调查，并提供了指导。调查涵盖了可靠性、安全性、公平性、抵抗滥用、可解释性和推理能力、遵守社会规范以及鲁棒性等七个主要类别，共计29个子类别。

    

    在将大型语言模型（LLMs）应用于现实世界应用之前，确保对齐是一项关键任务。然而，从业者面临的主要挑战是缺乏明确的指导来评估LLMs的输出是否符合社会规范、价值观和法规。本文提出了一个全面的调查，涵盖了评估LLM可信度时必须考虑的关键维度。调查涵盖了LLM可信度的七个主要类别：可靠性、安全性、公平性、抵抗滥用、可解释性和推理能力、遵守社会规范以及鲁棒性。每个主要类别进一步细分为若干子类别，共计29个子类别。

    Ensuring alignment, which refers to making models behave in accordance with human intentions [1,2], has become a critical task before deploying large language models (LLMs) in real-world applications. For instance, OpenAI devoted six months to iteratively aligning GPT-4 before its release [3]. However, a major challenge faced by practitioners is the lack of clear guidance on evaluating whether LLM outputs align with social norms, values, and regulations. This obstacle hinders systematic iteration and deployment of LLMs. To address this issue, this paper presents a comprehensive survey of key dimensions that are crucial to consider when assessing LLM trustworthiness. The survey covers seven major categories of LLM trustworthiness: reliability, safety, fairness, resistance to misuse, explainability and reasoning, adherence to social norms, and robustness. Each major category is further divided into several sub-categories, resulting in a total of 29 sub-categories. Additionally, a subset 
    
[^152]: 元认知提示改善大型语言模型的理解能力

    Metacognitive Prompting Improves Understanding in Large Language Models. (arXiv:2308.05342v1 [cs.CL])

    [http://arxiv.org/abs/2308.05342](http://arxiv.org/abs/2308.05342)

    元认知提示 (MP) 是一种改进大型语言模型 (LLMs) 理解能力的策略。实验结果表明，使用MP的PaLM在各种自然语言理解任务中接近于GPT-4的性能水平。

    

    在大型语言模型 (LLMs) 中，通过有效的提示设计，任务特定性能一直在不断提高。尽管最近关于提示的研究增强了LLMs的推理能力，但在进一步提高它们的理解能力方面仍存在差距。在本研究中，我们介绍了元认知提示 (MP)，这是一种受人类内省推理过程启发的策略。使用MP，LLMs经历一系列有结构、自我意识的评估，利用其丰富的内在知识和新的见解。我们的实验涉及五个常见的LLMs：Llama2、Vicuna、PaLM、GPT-3.5和GPT-4，它们都涵盖了来自GLUE和SuperGLUE基准测试的各种通用自然语言理解 (NLU) 任务。结果表明，虽然GPT-4在大多数任务中始终表现出色，但配备MP的PaLM接近其性能水平。此外，跨模型和数据集，MP始终优于现有的提示方法。

    In Large Language Models (LLMs), there have been consistent advancements in task-specific performance, largely influenced by effective prompt design. While recent research on prompting has enhanced the reasoning capabilities of LLMs, a gap remains in further improving their understanding abilities. In this study, we introduce metacognitive prompting (MP), a strategy inspired by human introspective reasoning processes. Using MP, LLMs undergo a systematic series of structured, self-aware evaluations, drawing on both their vast inherent knowledge and new insights. Our experiments involve five prevalent LLMs: Llama2, Vicuna, PaLM, GPT-3.5, and GPT-4, all of which span various general natural language understanding (NLU) tasks from the GLUE and SuperGLUE benchmarks. Results indicate that, although GPT-4 consistently excels in most tasks, PaLM, when equipped with MP, approaches its performance level. Furthermore, across models and datasets, MP consistently outperforms existing prompting meth
    
[^153]: QH9：QM9分子的量子哈密顿预测基准测试

    QH9: A Quantum Hamiltonian Prediction Benchmark for QM9 Molecules. (arXiv:2306.09549v1 [physics.chem-ph])

    [http://arxiv.org/abs/2306.09549](http://arxiv.org/abs/2306.09549)

    该论文提出了一种新的量子哈密顿数据集QH9，用于为各种分子提供精确的哈密顿矩阵。通过设计基准任务，展示了当前机器学习模型有能力预测任意分子的哈密顿矩阵。

    

    监督式机器学习方法越来越被用于加速电子结构预测，作为第一性原理计算方法（如密度泛函理论（DFT））的替代品。虽然许多量子化学数据集侧重于化学性质和原子力，但准确且高效地预测哈密顿矩阵的能力是非常重要和基本的物理量，它确定了物理系统和化学性质的量子状态。在这项工作中，我们生成了一个新的量子哈密顿数据集，命名为QH9，基于QM9数据集为2,399个分子动力学轨迹和130,831个稳定分子几何形态提供精确的哈密顿矩阵。通过设计各种分子的基准任务，我们展示了当前机器学习模型有能力预测任意分子的哈密顿矩阵。QH9数据集和基准模型都提供。

    Supervised machine learning approaches have been increasingly used in accelerating electronic structure prediction as surrogates of first-principle computational methods, such as density functional theory (DFT). While numerous quantum chemistry datasets focus on chemical properties and atomic forces, the ability to achieve accurate and efficient prediction of the Hamiltonian matrix is highly desired, as it is the most important and fundamental physical quantity that determines the quantum states of physical systems and chemical properties. In this work, we generate a new Quantum Hamiltonian dataset, named as QH9, to provide precise Hamiltonian matrices for 2,399 molecular dynamics trajectories and 130,831 stable molecular geometries, based on the QM9 dataset. By designing benchmark tasks with various molecules, we show that current machine learning models have the capacity to predict Hamiltonian matrices for arbitrary molecules. Both the QH9 dataset and the baseline models are provided
    
[^154]: ChatGPT4PCG比赛：科学鸟角色级生成

    ChatGPT4PCG Competition: Character-like Level Generation for Science Birds. (arXiv:2303.15662v1 [cs.AI])

    [http://arxiv.org/abs/2303.15662](http://arxiv.org/abs/2303.15662)

    本论文介绍了举办在2023 IEEE游戏会议上的第一届ChatGPT4PCG比赛，目标是让ChatGPT生成具有高稳定性和类似角色的特质来生成具有科学鸟角色级水平的关卡。

    

    本文介绍了2023年IEEE游戏会议上的第一届ChatGPT4PCG比赛。本次比赛的目标是让参赛者通过创造性和提示工程技能，为ChatGPT创建有效的提示，使其能够具有高稳定性和类似角色的特质来生成具有科学鸟角色级水平的关卡。为了降低参赛门槛，我们将任务限制在生成大写英文字母。参赛作品的质量由其稳定性和与给定字符的相似性决定。给参赛者提供了一个样例提示供参考。

    This paper presents the first ChatGPT4PCG Competition at the 2023 IEEE Conference on Games. The objective of this competition is for participants to create effective prompts for ChatGPT--enabling it to generate Science Birds levels with high stability and character-like qualities--fully using their creativity as well as prompt engineering skills. ChatGPT is a conversational agent developed by OpenAI. Science Birds is selected as the competition platform because designing an Angry Birds-like level is not a trivial task due to the in-game gravity; the playability of the levels is determined by their stability. To lower the entry barrier to the competition, we limit the task to the generation of capitalized English alphabetical characters. Here, the quality of the generated levels is determined by their stability and similarity to the given characters. A sample prompt is provided to participants for their reference. An experiment is conducted to determine the effectiveness of its modified
    
[^155]: ComCLIP: 无需训练的组合图像与文本匹配

    ComCLIP: Training-Free Compositional Image and Text Matching. (arXiv:2211.13854v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.13854](http://arxiv.org/abs/2211.13854)

    本文提出了一个无需训练的组合图像与文本匹配模型 ComCLIP，通过将输入图像分解为主体、对象和动作子图像，并结合视觉编码器和文本编码器进行逐步匹配，以解决组合图像与文本匹配中的伪匹配问题。

    

    对比语言-图像预训练（CLIP）已经展示了在图像与文本匹配方面的很好的零样本性能。然而，将 CLIP 这样的视觉-语言预训练模型适应于更具挑战性的组合图像与文本匹配仍然具有挑战性，这需要模型理解组合词概念和视觉组件。为了实现更好的零样本图像与文本匹配中的组合泛化能力，本文从因果关系的角度研究了该问题：单个实体的错误语义本质上是导致匹配失败的混淆因素。因此，我们提出了一种新颖的“无需训练”的组合 CLIP 模型（ComCLIP）。ComCLIP将输入图像分解为主体、对象和动作子图像，并组合 CLIP 的视觉编码器和文本编码器，以在组合文本嵌入和子图像嵌入之上进行逐步匹配。通过这种方式，ComCLIP 可以减轻伪匹配问题。

    Contrastive Language-Image Pretraining (CLIP) has demonstrated great zero-shot performance for matching images and text. However, it is still challenging to adapt vision-lanaguage pretrained models like CLIP to compositional image and text matching -- a more challenging image and text matching task requiring the model understanding of compositional word concepts and visual components. Towards better compositional generalization in zero-shot image and text matching, in this paper, we study the problem from a causal perspective: the erroneous semantics of individual entities are essentially confounders that cause the matching failure. Therefore, we propose a novel \textbf{\textit{training-free}} compositional CLIP model (ComCLIP). ComCLIP disentangles input images into subjects, objects, and action sub-images and composes CLIP's vision encoder and text encoder to perform evolving matching over compositional text embedding and sub-image embeddings. In this way, ComCLIP can mitigate spurio
    

