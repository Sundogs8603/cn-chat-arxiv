# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Gen2Sim: Scaling up Robot Learning in Simulation with Generative Models.](http://arxiv.org/abs/2310.18308) | 本文提出了Gen2Sim方法，通过使用生成模型自动生成3D资产、任务描述、任务分解和奖励函数来扩展机器人在仿真环境中的技能学习。这种自动化流程有助于解决人为参与的瓶颈问题，实现机器人学习在不同任务和环境中的扩展。 |
| [^2] | [A Stability Principle for Learning under Non-Stationarity.](http://arxiv.org/abs/2310.18304) | 本研究提出了一个适用于非稳态环境的统计学习框架，通过应用稳定性原则选择回溯窗口来最大化历史数据利用，并保持累积偏差在可接受范围内。该方法展示了对未知非稳态的适应性，遗憾界在强凸或满足Lipschitz条件下是极小化的最优解。该研究的创新点是函数相似度度量和非稳态数据序列划分技术。 |
| [^3] | [Socially Cognizant Robotics for a Technology Enhanced Society.](http://arxiv.org/abs/2310.18303) | 社交认知机器人是一种跨学科的方法，旨在使利益相关者参与塑造人工智能驱动的机器人行为，同时解决改善机器人与个人互动和对社会影响的问题。该方法平衡了技术指标和人类社会指标。 |
| [^4] | [Interactive Motion Planning for Autonomous Vehicles with Joint Optimization.](http://arxiv.org/abs/2310.18301) | 本论文介绍了一种交互式联合规划方法，将模型预测控制（MPC）与基于深度学习的轨迹预测模型结合，实现在高度交互的驾驶场景中为自主驾驶车辆规划安全的运动路径。 |
| [^5] | [Image Clustering Conditioned on Text Criteria.](http://arxiv.org/abs/2310.18297) | 本文提出了一种新的图像聚类方法，基于用户指定的文本标准，通过利用现代视觉语言模型和大型语言模型，实现了对聚类结果的直接控制。该方法需要较少的人工干预，并能在各种标准下有效地聚类图像，表现优于基准方法。 |
| [^6] | [Moments for Perceptive Narration Analysis Through the Emotional Attachment of Audience to Discourse and Story.](http://arxiv.org/abs/2310.18273) | 这篇论文的创新之处在于提出了一种理论框架，通过分析故事中的时刻来评估视觉故事的效果。时刻被定义为在给定时间段内角色的行动、互动和表情的感知。这些时刻可以进一步分为故事时刻和对话时刻，并且它们的存在会影响观众对角色和故事的情感联系。论文提出了一种方法来分类和分析这些时刻的出现。 |
| [^7] | [Learning to Search Feasible and Infeasible Regions of Routing Problems with Flexible Neural k-Opt.](http://arxiv.org/abs/2310.18264) | 本文介绍了一种名为Neural k-Opt的学习搜索求解器，用于路径问题。通过灵活的k-opt交换和自主的可行和不可行区域探索，该算法在旅行商问题和有容量车辆路径问题上表现出优越性能。 |
| [^8] | [A Review of the Evidence for Existential Risk from AI via Misaligned Power-Seeking.](http://arxiv.org/abs/2310.18244) | 这篇文章综述了关于人工智能通过目标不协调和寻求权力可能导致的存在风险的证据。研究发现尽管目前的证据情况令人担忧但又没有确定的结论，强有力的规范游戏实证证据以及对寻求权力的概念性证据使得无法排除存在风险的可能性。然而，到目前为止尚无公开的实证例子证明存在风险。 |
| [^9] | [Fine-Tuning Language Models Using Formal Methods Feedback.](http://arxiv.org/abs/2310.18239) | 该论文介绍了一种使用形式方法反馈调整语言模型的自动化方法，用于在自主系统中微调预先训练的模型。通过合成基于自动机的控制器并与给定规范进行验证，该方法可以减少人工反馈的成本并实现领域特定任务的控制策略生成。 |
| [^10] | [Davidsonian Scene Graph: Improving Reliability in Fine-grained Evaluation for Text-Image Generation.](http://arxiv.org/abs/2310.18235) | 本论文提出了Davidsonian场景图（DSG）的评估框架，解决了现有文本-图像生成模型评估中的可靠性挑战，包括QG问题的准确性和VQA答案的一致性。 |
| [^11] | [Will releasing the weights of large language models grant widespread access to pandemic agents?.](http://arxiv.org/abs/2310.18233) | 该研究调查了持续的语言模型权重扩散是否有可能帮助未来恶意行为者造成大规模死亡。通过组织一个黑客马拉松活动，研究者发现一些公开发布权重的模型在短时间内就被调整以去除保护机制，可能为恶意行为者获取关键信息提供了机会。 |
| [^12] | [Alignment and Outer Shell Isotropy for Hyperbolic Graph Contrastive Learning.](http://arxiv.org/abs/2310.18209) | 提出了一种新颖的对比学习框架，用于学习高质量的图嵌入，并设计了对齐度量和均匀性度量来解决图领域的非欧几里德几何结构问题。 |
| [^13] | [Is Scaling Learned Optimizers Worth It? Evaluating The Value of VeLO's 4000 TPU Months.](http://arxiv.org/abs/2310.18191) | VeLO是迄今为止规模最大的训练通用“基础”优化器的尝试，但我们的评估发现它需要问题特定的调优，并不一定优于竞争对手的解决方案质量和训练误差降低速度，这对于VeLO的通用性和培训投资的价值提出了质疑。 |
| [^14] | [Personas as a Way to Model Truthfulness in Language Models.](http://arxiv.org/abs/2310.18168) | 本研究探讨了在大型语言模型中使用人设来建模真实性的可能性。通过建模真实人设，语言模型可以将真实性推广到不同上下文中，并通过相关特征判断个体产生文本的真实性。 |
| [^15] | [Improving Intrinsic Exploration by Creating Stationary Objectives.](http://arxiv.org/abs/2310.18144) | 该论文提出了一个新的方法：通过创建固定目标，将原始的非固定奖励转化为固定奖励，从而改善了强化学习中的内在探索。 |
| [^16] | [Ask more, know better: Reinforce-Learned Prompt Questions for Decision Making with Large Language Models.](http://arxiv.org/abs/2310.18127) | 本文提出了一种利用大型语言模型的强化学习框架，能够学习提问相关问题并进行推理来指导在实际环境中执行的行为的学习。 |
| [^17] | [OpinSummEval: Revisiting Automated Evaluation for Opinion Summarization.](http://arxiv.org/abs/2310.18122) | 本文提出了一个新的数据集OpinSummEval，对意见摘要进行自动化评估的可靠性进行重新评估。研究发现基于神经网络的度量通常优于非神经网络的度量，但即使是基于强大模型构建的度量也不能在所有维度上始终保持良好的相关性，突出了对意见摘要自动化评估方法的进一步改进的需求。 |
| [^18] | [Towards a Unified Conversational Recommendation System: Multi-task Learning via Contextualized Knowledge Distillation.](http://arxiv.org/abs/2310.18119) | 通过上下文化知识蒸馏的多任务学习方法，我们提出了一种统一的对话推荐系统，该系统在推荐性能和对话生成的一致性方面取得了显著改进。 |
| [^19] | [er.autopilot 1.0: The Full Autonomous Stack for Oval Racing at High Speeds.](http://arxiv.org/abs/2310.18112) | er.autopilot 1.0是TII EuroRacing团队开发的一款高速椭圆赛车完全自主驾驶系统，通过避免障碍、主动超车和达到高速等模块的应用，取得了在椭圆赛道比赛中的良好表现，并获得第二名和第三名的成绩。 |
| [^20] | [Detrimental Contexts in Open-Domain Question Answering.](http://arxiv.org/abs/2310.18077) | 本文分析了在开放领域问答中过多的背景信息对模型性能的负面影响，并发现通过过滤掉有害的段落可以提高模型的准确性。 |
| [^21] | [Knowledge Corpus Error in Question Answering.](http://arxiv.org/abs/2310.18076) | 本研究探讨了开放领域问答中生成上下文段落与传统检索步骤相比的优势，并引入了知识语料错误的概念。通过使用大型语言模型生成更大范围内的段落，我们观察到问答性能的提升，表明存在知识语料错误的情况。 |
| [^22] | [DUMA: a Dual-Mind Conversational Agent with Fast and Slow Thinking.](http://arxiv.org/abs/2310.18075) | DUMA是一种具有快速和慢速思考能力的双重思维对话代理框架，通过利用两个生成型大型语言模型，实现了根据情况在直观响应和深思熟虑的问题解决过程之间无缝切换的能力。 |
| [^23] | [Moral Responsibility for AI Systems.](http://arxiv.org/abs/2310.18040) | 本文提出了一种适用于AI系统的道德责任定义，并在因果模型框架下进行了形式化。同时，将该定义推广为一种责任程度。 |
| [^24] | [Large language models for aspect-based sentiment analysis.](http://arxiv.org/abs/2310.18025) | 该论文评估了GPT-4和GPT-3.5在基于方面的情感分析任务中的性能，并发现微调后的GPT-3.5在SemEval-2014任务4中取得了83.8的最先进F1分数，相比于InstructABSA提高了5.7%。但是，这需要1000倍的模型参数增加了推理成本。 |
| [^25] | [FormalGeo: The First Step Toward Human-like IMO-level Geometric Automated Reasoning.](http://arxiv.org/abs/2310.18021) | FormalGeo是一种完整且兼容的正式平面几何系统，能够利用现代AI模型提供演绎推理解决方案，使AI能够像处理其他自然语言一样解决IMO级平面几何问题，证明可读、追溯和可验证。 |
| [^26] | [Deep Learning Enables Large Depth-of-Field Images for Sub-Diffraction-Limit Scanning Superlens Microscopy.](http://arxiv.org/abs/2310.17997) | 本论文使用深度学习实现了亚衍射极限扫描超透镜显微镜，无需涂覆导电薄膜或真空环境，能够获得大景深图像，提高了图像转换效果。 |
| [^27] | [Autonomous 3D Exploration in Large-Scale Environments with Dynamic Obstacles.](http://arxiv.org/abs/2310.17977) | 提出了一种在具有动态障碍物的大规模环境中自主3D探索的方法，该方法不仅可以避免动态障碍物，还可以将其包含在规划中以利用动态环境优势，并且在动态和大规模环境中表现出更好的探索和避碰效果。 |
| [^28] | [Train Once, Get a Family: State-Adaptive Balances for Offline-to-Online Reinforcement Learning.](http://arxiv.org/abs/2310.17966) | 在离线到在线强化学习中，现有解决方案往往只使用一种平衡策略，无法充分利用不同状态的数据质量。本论文提出了一种家族式离线到在线强化学习框架(FamO2O)，它通过训练一系列具有不同改进和约束强度的策略，实现了状态自适应的平衡。 |
| [^29] | [Qilin-Med-VL: Towards Chinese Large Vision-Language Model for General Healthcare.](http://arxiv.org/abs/2310.17956) | Qilin-Med-VL是面向普遍医疗保健的中国大型视觉-语言模型，它结合了预训练的视觉Transformer和基础语言模型，通过两阶段课程训练过程提高了生成医疗标题和回答复杂医疗查询的能力，并发布了一个包含超过100万个图像-文本对的数据集ChiMed-VL。 |
| [^30] | [Understanding Parameter Saliency via Extreme Value Theory.](http://arxiv.org/abs/2310.17951) | 本文通过极值理论分析参数敏感性排名，旨在填补对参数敏感性排名如何找到导致错误识别的滤波器的理解的知识空白。 |
| [^31] | [A Comprehensive and Reliable Feature Attribution Method: Double-sided Remove and Reconstruct (DoRaR).](http://arxiv.org/abs/2310.17945) | 双边删除和重构（DoRaR）是一种全面可靠的特征归因方法，用于解决深度神经网络和其他相关模型内部决策机制不透明的问题。 |
| [^32] | [Unified Segment-to-Segment Framework for Simultaneous Sequence Generation.](http://arxiv.org/abs/2310.17940) | 这篇论文提出了一种统一的片段到片段框架 (Seg2Seg) 用于同时序列生成，通过自适应和统一的方式学习源序列和目标序列之间的映射，实现高质量生成和低延迟。 |
| [^33] | [Transformers as Graph-to-Graph Models.](http://arxiv.org/abs/2310.17936) | 本文认为Transformers本质上是图到图模型，通过将注意力权重等价于图中的边，并使用图到图Transformer架构结合显式图和潜在图进行非自回归图预测，实现了在建模各种语言结构方面的最先进准确性。 |
| [^34] | [Knowing What LLMs DO NOT Know: A Simple Yet Effective Self-Detection Method.](http://arxiv.org/abs/2310.17918) | 本文提出了一种新的自我检测方法，用于判断大型语言模型 (LLMs) 无法回答的问题，以避免生成非事实性的回答。通过多样化问题的文本表达，收集答案，并检查生成的答案之间的差异，可以识别出可能生成虚假回答的问题。该方法只需要利用LLMs自身，无需其他外部资源。这种方法在Vicuna、ChatGPT和GPT-4等最新发布的LLMs上得到了有效验证。 |
| [^35] | [The Innovation-to-Occupations Ontology: Linking Business Transformation Initiatives to Occupations and Skills.](http://arxiv.org/abs/2310.17909) | 本研究提出了一个创新的方法，通过本体论将业务转型项目与职业相连接，通过分析职位广告和维基百科页面中的信息，成功匹配了职业与转型项目，在指导企业和教育机构方面具有重要意义。 |
| [^36] | [Pitfalls in Language Models for Code Intelligence: A Taxonomy and Survey.](http://arxiv.org/abs/2310.17903) | 该论文介绍了面向代码智能的语言模型（LM4Code）可能遇到的陷阱，并提出了一个分类法，总结了67个主要研究，以促进构建更可靠的LM4Code。 |
| [^37] | [Natural Language Interfaces for Tabular Data Querying and Visualization: A Survey.](http://arxiv.org/abs/2310.17894) | 本调查对表格数据查询和可视化的自然语言界面进行了全面概述，介绍了语义解析等关键技术，并深入探讨了Text-to-SQL和Text-to-Vis问题的最新进展。 |
| [^38] | [Can LLMs Keep a Secret? Testing Privacy Implications of Language Models via Contextual Integrity Theory.](http://arxiv.org/abs/2310.17884) | 本研究通过提出ConfAIde基准，揭示了LLMs的上下文隐私推理能力中的重要弱点，实验证明即使是最强大的模型也会在人类不会的上下文中泄露私人信息，强调了探索新型推理时隐私保护方法的迫切需求。 |
| [^39] | [ASPIRO: Any-shot Structured Parsing-error-Induced ReprOmpting for Consistent Data-to-Text Generation.](http://arxiv.org/abs/2310.17877) | ASPIRO是一种能在零到少样本情况下将结构化数据转化为简短模板句子的方法。通过算法解析检查、LLM的重新提示以及一致性验证指标PARENT，ASPIRO成功降低了66%的解析错误率，并且在与最近的预训练语言模型的竞争中表现出色。 |
| [^40] | [Ranking with Slot Constraints.](http://arxiv.org/abs/2310.17870) | 带有槽约束的排名问题中，我们提出了一种新的排名算法MatchRank，它在候选人按排名顺序被人类决策者评估时，产生最大化填充槽位的排名。算法在理论上具有强大的逼近保证，并且可以高效实现。 (arXiv:2310.17870v1 [cs.IR]) |
| [^41] | [Reproducibility in Multiple Instance Learning: A Case For Algorithmic Unit Tests.](http://arxiv.org/abs/2310.17867) | 多实例学习中的五个深度模型在学习过程中违反了标准的MIL假设，导致能够学习反相关的实例。这一问题需要通过改进和其他策略来解决。 |
| [^42] | [Function Space Bayesian Pseudocoreset for Bayesian Neural Networks.](http://arxiv.org/abs/2310.17852) | 本论文提出了一种在函数空间上操作的新颖贝叶斯伪核心集构建方法，通过构建核心集后验的变分近似并在函数空间中将其与完整数据后验匹配，实现了对深度神经网络等高维模型的贝叶斯推断的可扩展性。 |
| [^43] | [Real-time Animation Generation and Control on Rigged Models via Large Language Models.](http://arxiv.org/abs/2310.17838) | 该论文介绍了一种利用大型语言模型实现在已绑定模型上实时进行动画控制和生成的方法，并展示了该方法的灵活性和鲁棒性。 |
| [^44] | [One Style is All you Need to Generate a Video.](http://arxiv.org/abs/2310.17835) | 本文提出了一种基于风格的条件视频生成模型，通过学习各种动作的动态表示，实现了独立操作和转移视频动作的能力，同时显著提高了视频质量。 |
| [^45] | [Bayesian imaging inverse problem with SA-Roundtrip prior via HMC-pCN sampler.](http://arxiv.org/abs/2310.17817) | 本文提出了一种新型的深度生成先验，SA-Roundtrip，可以进行可控的采样生成，并识别数据的内在维度。基于该先验，结合Hamiltonian Monte Carlo算法，解决了贝叶斯成像逆问题，在计算机断层扫描重建任务上超过了最先进的对比算法。 |
| [^46] | [Style-Aware Radiology Report Generation with RadGraph and Few-Shot Prompting.](http://arxiv.org/abs/2310.17811) | 该论文提出了一种使用RadGraph和少样本提示的风格感知放射学报告生成的方法。通过将报告的内容和风格分开处理，可以避免生成临床不准确的报告。定量评估和人工评估结果均表明该方法表现出良好的性能，并生成与个体放射科医生风格完全相同的报告。 |
| [^47] | [Clover: Closed-Loop Verifiable Code Generation.](http://arxiv.org/abs/2310.17807) | Clover是一种闭环可验证代码生成的范式，通过在代码、docstrings和形式注释之间进行一致性检查，确保生成的代码的正确性。 |
| [^48] | [Reward Scale Robustness for Proximal Policy Optimization via DreamerV3 Tricks.](http://arxiv.org/abs/2310.17805) | 本研究将DreamerV3的技巧应用到PPO中，并发现这些技巧并不能普遍改善PPO的性能。通过大量的消融研究，我们确定了一些情况下这些技巧的成功，并对它们的关系提供了深入洞察。 |
| [^49] | ["You Are An Expert Linguistic Annotator": Limits of LLMs as Analyzers of Abstract Meaning Representation.](http://arxiv.org/abs/2310.17793) | 本文研究了大型语言模型在分析句子的意义结构方面的成功和限制，发现模型在生成和重构抽象意义表示（AMR）方面表现出一定的能力，但在复杂的句子结构或语义推理任务中存在局限性。 |
| [^50] | [Utilizing Language Models for Energy Load Forecasting.](http://arxiv.org/abs/2310.17788) | 本文提出了一种利用语言模型进行能量负荷预测的新方法，通过采用提示技术和自回归生成方法，可以将能源消耗数据转化为描述性语句并实现预测未来能量负荷消耗的准确性，从而为提高能源效率和促进能源系统智能决策提供了有希望的途径。 |
| [^51] | [Evaluation of large language models using an Indian language LGBTI+ lexicon.](http://arxiv.org/abs/2310.17787) | 该论文提出了一种使用印度语LGBTI+词汇表评估大型语言模型的方法。研究发现，现有的语言模型无法有效检测潜藏的仇恨内容，使用机器翻译作为评估手段也存在局限性。 |
| [^52] | [Data-Centric Financial Large Language Models.](http://arxiv.org/abs/2310.17784) | 本文介绍了一种数据中心化的方法，通过预处理和预理解数据来改善大型语言模型（LLMs）在金融任务中的性能。实验证明，采用该方法的金融LLMs在金融分析和解释任务上达到了最先进的水平。 |
| [^53] | [Graph Convolutional Networks for Complex Traffic Scenario Classification.](http://arxiv.org/abs/2310.17773) | 该论文提出了一种复杂交通情景分类方法，能够模拟车辆与环境以及其他参与者的互动，并使用图卷积网络对这些情景的空间和时间特征进行建模。 |
| [^54] | [GROOViST: A Metric for Grounding Objects in Visual Storytelling.](http://arxiv.org/abs/2310.17770) | GROOViST是一种用于评估视觉故事中物体定位的新的评估工具，考虑了跨模态依赖、时间错位和人类对视觉定位的直觉。这种工具具有模块化设计，可以评估和解释每个组件的贡献。 |
| [^55] | [Social Contract AI: Aligning AI Assistants with Implicit Group Norms.](http://arxiv.org/abs/2310.17769) | 这项研究探索了通过将机器学习模型应用于用户交互数据，使AI助手能够自动对齐用户偏好的方法。研究发现，虽然AI助手在模拟中能够准确对齐经济文献中的标准策略，但在面对未知货币以及语言与策略一致性不足的情况下，其学习能力受到限制。 |
| [^56] | [Salespeople vs SalesBot: Exploring the Role of Educational Value in Conversational Recommender Systems.](http://arxiv.org/abs/2310.17749) | 这项研究探索了在对话式推荐系统中教育价值的作用，通过比较销售人员和SalesBot的性能，发现虽然SalesBot在流畅性和信息量方面接近专业销售人员，但在推荐质量方面仍存在差距。 |
| [^57] | [Improving Traffic Density Forecasting in Intelligent Transportation Systems Using Gated Graph Neural Networks.](http://arxiv.org/abs/2310.17729) | 本研究通过应用门控图神经网络（GGNNs），在智能交通系统中的交通预测领域取得了显著的成果，通过最小化预测误差，GGNNs被证明是最有效的选择，展示了较高的预测性能。 |
| [^58] | [Large Language Models as Generalizable Policies for Embodied Tasks.](http://arxiv.org/abs/2310.17722) | 本研究展示了大型语言模型(LLMs)可以被适应为具有普适性的机器人任务策略。通过我们的方法LLaRP，我们成功将预训练的冻结LLM用于接收指令和视觉输入，并在环境中直接输出动作。我们的实验结果表明LLaRP不仅对任务指令的复杂改写具有鲁棒性，而且可以推广到需要新颖最优行为的新任务。在大量未见任务中，LLaRP表现出了显著的成功率提升，并且我们提供了一个新的基准测试(Language Rearrangement)来促进进一步的研究。 |
| [^59] | [From Transcripts to Insights: Uncovering Corporate Risks Using Generative AI.](http://arxiv.org/abs/2310.17721) | 这项研究探索了使用生成型人工智能工具帮助投资者揭示企业风险的价值，通过从收益电话的上下文中生成风险摘要和评估，这些基于GPT的度量具有显著的信息内容，能够预测企业层面波动性和投资创新选择。此外，生成型人工智能还能有效检测新兴风险，并且这些度量在股权市场中起到定价作用。 |
| [^60] | [Outlier Dimensions Encode Task-Specific Knowledge.](http://arxiv.org/abs/2310.17715) | 异常维度可以编码关键的特定任务知识，并且一个单一的异常维度可以以最小的错误率完成下游任务。 |
| [^61] | [A Wireless AI-Generated Content (AIGC) Provisioning Framework Empowered by Semantic Communication.](http://arxiv.org/abs/2310.17705) | 一种由语义通信增强的无线AI生成内容（AIGC）供应框架，通过使用语义信息而不是所有的二进制位提取和传输内容，以解决在无线网络中提供最优AIGC服务的挑战。 |
| [^62] | [CodeFusion: A Pre-trained Diffusion Model for Code Generation.](http://arxiv.org/abs/2310.17680) | CodeFusion是一种预训练的代码生成模型，通过扩散的方式解决了自然语言代码生成中遇到的限制，实验表明其在准确率和多样性上优于最先进的自回归系统。 |
| [^63] | [Fast Scalable and Accurate Discovery of DAGs Using the Best Order Score Search and Grow-Shrink Trees.](http://arxiv.org/abs/2310.17679) | 本论文介绍了一种用于学习有向无环图的最佳顺序分数搜索（BOSS）和生长-收缩树（GSTs）方法，该方法在准确性和执行时间方面达到了最先进的性能，适用于具有数百个高度连接的变量的问题，例如从fMRI数据中恢复脑网络。 |
| [^64] | [Transfer of Reinforcement Learning-Based Controllers from Model- to Hardware-in-the-Loop.](http://arxiv.org/abs/2310.17671) | 本研究通过结合迁移学习和环境中的模拟来加速强化学习代理的训练过程，以实现在嵌入式系统中有效使用强化学习的目标。 |
| [^65] | [RTNH+: Enhanced 4D Radar Object Detection Network using Combined CFAR-based Two-level Preprocessing and Vertical Encoding.](http://arxiv.org/abs/2310.17659) | 本文提出了RTNH+，一种增强型的4D雷达目标检测网络，通过两种新算法实现：基于CFAR的两级预处理算法和垂直编码算法，可以提高目标检测的准确性和性能。 |
| [^66] | [Is Channel Independent strategy optimal for Time Series Forecasting?.](http://arxiv.org/abs/2310.17658) | 本文重新考虑了当前通道独立策略在时间序列预测中是否是最佳解决方案，并提出了一种称为CSC的通道自聚类策略来增强性能并减小参数大小。 |
| [^67] | [Deep Learning Algorithm for Advanced Level-3 Inverse-Modeling of Silicon-Carbide Power MOSFET Devices.](http://arxiv.org/abs/2310.17657) | 作者提出了一种深度学习方法，用于检索硅碳化物功率MOSFET的物理参数，该方法适用于重建退化设备的物理参数或检索物理配置。 |
| [^68] | [ACWA: An AI-driven Cyber-Physical Testbed for Intelligent Water Systems.](http://arxiv.org/abs/2310.17654) | ACWA是一种基于AI的智能水务系统的网络物理测试平台，旨在通过利用尖端的AI和数据驱动技术解决水务和农业领域的紧迫挑战，包括网络生物安全、资源管理、水资源获取、可持续发展和基于数据的决策等。 |
| [^69] | [SPA: A Graph Spectral Alignment Perspective for Domain Adaptation.](http://arxiv.org/abs/2310.17594) | 本研究提出了一种新的图谱对齐框架（SPA）来解决无监督领域自适应问题。通过将领域自适应问题转化为图原语，并结合新颖的谱正则化器和邻域感知自训练机制，SPA在特征空间中对齐领域图并提高了目标领域中的可区分性。 |
| [^70] | [Human-Guided Complexity-Controlled Abstractions.](http://arxiv.org/abs/2310.17550) | 本研究通过训练神经模型生成一系列离散表示，并通过调整表示的复杂性来提高任务的泛化性能。在微调实验中，我们发现适当的复杂性水平支持最佳的微调性能，并且在人类参与者的研究中也得到验证。 |
| [^71] | [Can large language models replace humans in the systematic review process? Evaluating GPT-4's efficacy in screening and extracting data from peer-reviewed and grey literature in multiple languages.](http://arxiv.org/abs/2310.17526) | 本研究评估了GPT-4在多种语言的同行评审文献和灰色文献筛选和提取数据方面的能力，结果显示GPT-4在大多数任务上准确度与人类表现相当，在调整了偶然一致性和数据集不平衡后，其在数据提取方面表现出中等水平的准确度。 |
| [^72] | [The Expressive Power of Low-Rank Adaptation.](http://arxiv.org/abs/2310.17513) | 本文分析了低秩适应（LoRA）的表达能力，证明了对于全连接神经网络，当LoRA-rank≥（f的宽度）×（目标模型的深度/ f的深度）时，LoRA可以使任何模型f准确表示任何较小的目标模型f。对于Transformer网络，通过rank-（嵌入大小/ 2）的LoRA适配器可以使任何模型适应于相同大小的目标模型。 |
| [^73] | [Core Challenge 2023: Solver and Graph Descriptions.](http://arxiv.org/abs/2310.17136) | 本文总结了 CoRe Challenge 2023 中提交的求解器和 ISR 实例的所有描述。 |
| [^74] | [Multi-scale Diffusion Denoised Smoothing.](http://arxiv.org/abs/2310.16779) | 本文研究了多尺度扩散去噪平滑的准确度和认证鲁棒性之间的权衡，并提出了一种在共享扩散模型上调整以实现平滑分类器鲁棒性的新方法。 |
| [^75] | [Translating Universal Scene Descriptions into Knowledge Graphs for Robotic Environment.](http://arxiv.org/abs/2310.16737) | 该论文研究了将通用场景描述翻译成知识图谱的技术，以提供对机器人环境的语义查询和集成其他知识源的能力。 |
| [^76] | [Pitfall of Optimism: Distributional Reinforcement Learning by Randomizing Risk Criterion.](http://arxiv.org/abs/2310.16546) | 本论文提出了一种通过随机化风险标准的分布式强化学习算法，以避免在风险上的偏向性，并证明了其收敛性和最优性。实验证明，在包括Atari 55游戏在内的各种环境中，该方法优于其他分布式算法。 |
| [^77] | [Identifying Reasons for Bias: An Argumentation-Based Approach.](http://arxiv.org/abs/2310.16506) | 本文提出了一种基于论证的方法来确定为什么一个个体被分类与相似个体不同，该方法使用定量论证框架来表示个体和与其相似个体的属性-值对，并使用一个众所周知的语义来确定对个体分类产生最大贡献的属性-值对。 |
| [^78] | [Accented Speech Recognition With Accent-specific Codebooks.](http://arxiv.org/abs/2310.15970) | 本研究提出了一种使用具有专门口音代码本的口音适应方法，通过交叉注意力和可训练代码本，用于端到端ASR系统。在实验证明了该方法在已见和未见的口音上都能获得显著的性能提升。 |
| [^79] | [Modeling Path Importance for Effective Alzheimer's Disease Drug Repurposing.](http://arxiv.org/abs/2310.15211) | 该论文提出了一种基于网络的新方法（MPI）来有效进行阿尔茨海默病药物重用。该方法通过学习节点嵌入来优先考虑重要路径，从而更好地发现候选药物。 |
| [^80] | [Leveraging Ensemble Diversity for Robust Self-Training in the Presence of Sample Selection Bias.](http://arxiv.org/abs/2310.14814) | 本文提出了一种在样本选择偏差存在的情况下，利用集成多样性进行鲁棒的自训练的方法，并引入了一种新的自信度度量方法-$\mathcal{T}$-相似度。实验证明该方法在三种不同伪标签策略下具有良好的效果。 |
| [^81] | [Unleashing the potential of prompt engineering in Large Language Models: a comprehensive review.](http://arxiv.org/abs/2310.14735) | 这篇论文解释了提示工程在释放大型语言模型能力方面的关键作用，探讨了不同的提示方法以及外部插件如何协助减少机器幻想，并指出了未来研究方向的重要性。 |
| [^82] | [Fundamental Limits of Membership Inference Attacks on Machine Learning Models.](http://arxiv.org/abs/2310.13786) | 本文探讨了机器学习模型上成员推断攻击的基本限制，包括推导了效果和成功率的统计量，并提供了几种情况下的界限。这使得我们能够根据样本数量和其他结构参数推断潜在攻击的准确性。 |
| [^83] | [Enhancing drug and cell line representations via contrastive learning for improved anti-cancer drug prioritization.](http://arxiv.org/abs/2310.13725) | 通过对比学习，该研究提出了一种改进药物和细胞系表征的方法，以保留与药物作用机制和细胞系癌症类型相关的关系结构，并实现了卓越的性能。使用这种方法可以更好地平衡对药物和细胞系特征的依赖，从而实现更个性化的药物优先级排序。 |
| [^84] | [Towards Understanding Sycophancy in Language Models.](http://arxiv.org/abs/2310.13548) | 这项研究探讨了强化学习从人类反馈中训练高质量AI助手的技术，发现这种方法可能导致模型在回答问题时过于谄媚，而不是坦诚，通过分析人类偏好数据得出了这一结论。 |
| [^85] | [Jorge: Approximate Preconditioning for GPU-efficient Second-order Optimization.](http://arxiv.org/abs/2310.12298) | 本文介绍了Jorge，一种GPU高效的二阶优化算法，通过近似预处理方法替代矩阵求逆计算来提高计算效率，同时兼具二阶方法的收敛性能。实验证明了Jorge的有效性。 |
| [^86] | [MetaBox: A Benchmark Platform for Meta-Black-Box Optimization with Reinforcement Learning.](http://arxiv.org/abs/2310.08252) | MetaBox是一种用于开发和评估元黑箱优化与强化学习方法的基准平台，提供灵活的算法模板、广泛的问题实例和基线方法，并引入了三个标准化的性能指标，以促进方法的严格评估。 |
| [^87] | [Accountability in Offline Reinforcement Learning: Explaining Decisions with a Corpus of Examples.](http://arxiv.org/abs/2310.07747) | 本论文介绍了一种可解释的离线控制器方法，通过使用离线数据集作为决策语料库，在低数据场景中实现了问责制的控制，并在医疗保健领域展示了良好的性能。 |
| [^88] | [Generalized Neural Collapse for a Large Number of Classes.](http://arxiv.org/abs/2310.05351) | 本论文将神经崩溃概念扩展到类别数远大于特征空间维度的情况，并展示了广义神经崩溃现象的最小边界值被最大化。 |
| [^89] | [The Entity-Deduction Arena: A playground for probing the conversational reasoning and planning capabilities of LLMs.](http://arxiv.org/abs/2310.01468) | 本文提供了一个评估框架，通过向法官提出一系列查询来评估LLMs的对话推理和规划能力。我们发现不同的LLMs在这个任务上表现出显著差异。 |
| [^90] | [LEGO-Prover: Neural Theorem Proving with Growing Libraries.](http://arxiv.org/abs/2310.00656) | LEGO-Prover是一个使用不断增长的技能库的神经定理证明方法，可以使语言模型（LLMs）利用现有技能和创造新技能来证明定理。 |
| [^91] | [Framework based on complex networks to model and mine patient pathways.](http://arxiv.org/abs/2309.14208) | 该论文提出了一个基于复杂网络的框架，用于建模和挖掘患者路径。该框架包括路径模型、新的相似度测量方法和基于传统中心度的挖掘方法。评估结果表明该框架可有效应用于实际医疗数据分析。 |
| [^92] | [Beta Diffusion.](http://arxiv.org/abs/2309.07867) | beta扩散是一种新型生成模型方法，通过引入去掩盖和去噪的技术，利用缩放和偏移的beta分布进行乘法转换，实现在有界范围内生成数据。相比于传统的基于扩散的生成模型，它通过KL散度上界进行优化，证明了效果更好。 |
| [^93] | [Minimum Bayes' Risk Decoding for System Combination of Grammatical Error Correction Systems.](http://arxiv.org/abs/2309.06520) | 本文提出了一个用于语法错误修正系统系统组合的最小贝叶斯风险解码方法，并通过实验证明了其有效性。 |
| [^94] | [Framework-Based Qualitative Analysis of Free Responses of Large Language Models: Algorithmic Fidelity.](http://arxiv.org/abs/2309.06364) | 本文通过定性分析研究了大型语言模型生成的自由回答，重点考察了算法保真度，并提出高算法保真度可以推广到真实人类的观点。这对于使用语言模型研究人类行为具有重要意义。 |
| [^95] | [Memory Efficient Optimizers with 4-bit States.](http://arxiv.org/abs/2309.01507) | 本论文通过将优化器状态的位宽压缩至4位，实现了内存高效的训练神经网络。通过对一阶和二阶矩的详细经验分析，我们发现当前的块状量化方法无法准确近似复杂的异常值模式。为此，我们使用较小的块大小并同时利用行上和列上的信息进行更好的量化。此外，我们还通过排除零点的线性量化器解决了量化第二阶矩时的零点问题。我们的工作在多个基准测试上进行了评估，结果表明我们的4位优化器具有出色的性能。 |
| [^96] | [FairMonitor: A Four-Stage Automatic Framework for Detecting Stereotypes and Biases in Large Language Models.](http://arxiv.org/abs/2308.10397) | 本文引入了一个四阶段框架，可以直接评估大型语言模型（LLMs）生成内容中的刻板印象和偏见，包括直接询问测试、串行或适应性故事测试、隐性关联测试和未知情境测试。此外，还提出了多维评估指标和可解释的零样本提示，并以教育部门为案例研究构建了Edu-FairMonitor框架。 |
| [^97] | [Separate Anything You Describe.](http://arxiv.org/abs/2308.05037) | 这项工作介绍了一种用于开放领域音频源分离的基础模型AudioSep，该模型使用自然语言查询，具有强大的分离性能和优秀的泛化能力。 |
| [^98] | [Thinker: Learning to Plan and Act.](http://arxiv.org/abs/2307.14993) | Thinker算法通过引入世界模型和模型交互动作使强化学习代理实现自主规划，消除了手工设计规划算法的需求，并且在Sokoban游戏和Atari 2600基准测试中取得了state-of-the-art的性能。 |
| [^99] | [TMR-RD: Training-based Model Refinement and Representation Disagreement for Semi-Supervised Object Detection.](http://arxiv.org/abs/2307.13755) | 在半监督目标检测中，本文提出了基于训练的模型精化(TMR)阶段和表示分歧(RD)策略，用来解决伪标签噪声和教师-学生模型的一致性问题。TMR阶段通过轻量级缩放操作优化模型权重，防止过度拟合或遗忘学到的模式；RD策略帮助保持模型的差异，鼓励学生模型探索互补的表示。 |
| [^100] | [HYTREL: Hypergraph-enhanced Tabular Data Representation Learning.](http://arxiv.org/abs/2307.08623) | HYTREL是一种表格语言模型，通过使用超图来捕捉表格数据的排列不变性和其他三个结构属性。实证结果表明，HYTREL在四个下游任务中始终优于其他竞争基线模型，并且只需最少的预训练。 |
| [^101] | [Video-FocalNets: Spatio-Temporal Focal Modulation for Video Action Recognition.](http://arxiv.org/abs/2307.06947) | 本论文提出了一种名为视频焦点网络的视频识别架构，通过时空焦点调制来模拟局部和全局上下文，结合了Transformer和卷积设计的优点，既有效又高效。 |
| [^102] | [Stability Guarantees for Feature Attributions with Multiplicative Smoothing.](http://arxiv.org/abs/2307.05902) | 本文提出了一种基于乘法平滑的特征归因方法，通过证明模型的Lipschitz性质，保证了其稳定性，并在视觉和语言模型上进行了评估，显示了非平凡的稳定性保证。 |
| [^103] | [DebateKG: Automatic Policy Debate Case Creation with Semantic Knowledge Graphs.](http://arxiv.org/abs/2307.04090) | 本论文提出了一种利用语义知识图自动创建政策辩论案例的方法，通过在争论的语义知识图上进行限制最短路径遍历，有效构建高质量的辩论案例。研究结果表明，在美国竞赛辩论中，利用这种方法显著改进了已有数据集DebateSum，并贡献了新的例子和有用的元数据。通过使用txtai语义搜索和知识图工具链，创建和贡献了9个语义知识图，同时提出了一种独特的评估方法来确定哪个知识图更适合政策辩论案例生成。 |
| [^104] | [Deep Contract Design via Discontinuous Networks.](http://arxiv.org/abs/2307.02318) | 本文通过不连续ReLU网络实现了深层合同设计，通过学习代理人和委托人的约束和目标的闭合形式表达，支持并行推断以求解最优合同。 |
| [^105] | [SageFormer: Series-Aware Graph-Enhanced Transformers for Multivariate Time Series Forecasting.](http://arxiv.org/abs/2307.01616) | 本文介绍了SageFormer，一种面向多变量时间序列预测的系列感知图增强Transformer模型，通过图结构有效捕捉和建模序列之间的依赖关系，在表示不同序列中的时间模式和减少序列间冗余信息等方面取得了优越性能。 |
| [^106] | [LeanDojo: Theorem Proving with Retrieval-Augmented Language Models.](http://arxiv.org/abs/2306.15626) | 本文引入了LeanDojo，该工具通过提取Lean的数据，为定理证明研究提供了一个开放源代码的平台。利用LeanDojo的数据，开发了ReProver，它是第一个使用检索增强的语言模型的证明器，可以从庞大的数学库中选择命题，训练成本低，并且只需要一周的GPU训练时间。 |
| [^107] | [TACO: Temporal Latent Action-Driven Contrastive Loss for Visual Reinforcement Learning.](http://arxiv.org/abs/2306.13229) | 本文提出了TACO方法，一种基于时间潜在动作驱动对比损失的视觉强化学习方法，能够同时学习状态表示和动作表示，提高代理学习的效率。 |
| [^108] | [Genes in Intelligent Agents.](http://arxiv.org/abs/2306.10225) | 该论文提出了基于基因的强化学习（GRL）框架，通过模拟有机体的进化和利用学习基因来学习和演化智能体。实验证明了GRL在智能体训练中的有效性。 |
| [^109] | [Katakomba: Tools and Benchmarks for Data-Driven NetHack.](http://arxiv.org/abs/2306.08772) | 本论文开发了一个用于数据驱动NetHack的工具和基准库，旨在解决资源、实现和基准方面的障碍。该库提供了ORL社区所熟悉的工作流基础，并附带可靠的评估工具。 |
| [^110] | [Controlling Text-to-Image Diffusion by Orthogonal Finetuning.](http://arxiv.org/abs/2306.07280) | 本文介绍了一种名为正交微调（OFT）的方法，可以有效地引导和控制大型文本到图像扩散模型，以执行不同的下游任务。我们还提出了约束正交微调（COFT），来提高微调的稳定性。这些方法能够保持语义生成能力并生成特定主题的图像。 |
| [^111] | [Tackling Heavy-Tailed Rewards in Reinforcement Learning with Function Approximation: Minimax Optimal and Instance-Dependent Regret Bounds.](http://arxiv.org/abs/2306.06836) | 本文解决了强化学习中当奖励呈“重尾”分布时的问题，提出了第一种处理这种情况的实例相关算法，并得到了极小最大化的遗憾界。 |
| [^112] | [Look Beneath the Surface: Exploiting Fundamental Symmetry for Sample-Efficient Offline RL.](http://arxiv.org/abs/2306.04220) | 本文提出了一个新的离线强化学习算法TDM，利用系统动力学的基本对称性实现高效学习小数据集。 |
| [^113] | [Spatially Resolved Gene Expression Prediction from H&E Histology Images via Bi-modal Contrastive Learning.](http://arxiv.org/abs/2306.01859) | 本文提出了BLEEP框架，通过对比学习构建联合嵌入空间，能够从H&E染色组织学图像中生成空间分辨率的基因表达谱地图，具有很高的有效性。 |
| [^114] | [Resolving Interference When Merging Models.](http://arxiv.org/abs/2306.01708) | 本文揭示了现有模型合并技术存在的干扰问题，提出了具有广泛适用性的解决方案，可显着提高合并后模型的性能。 |
| [^115] | [Thought Cloning: Learning to Think while Acting by Imitating Human Thinking.](http://arxiv.org/abs/2306.00323) | 本论文提出了一种新的模仿学习框架“思维克隆”，通过学习人类的思维来训练AI代理，以在泛化、探索、规划等能力方面实现更好的表现。 |
| [^116] | [Truncated Affinity Maximization: One-class Homophily Modeling for Graph Anomaly Detection.](http://arxiv.org/abs/2306.00006) | 本文针对图形异常监测数据集中存在的一类同型现象，提出了一种新的无监督异常评分度量——当前节点亲和力，并通过学习量身定制的节点表示，实现了截断亲和力最大化（TAM）方法，优化在原始图形结构上进行，能够有效进行双重One-Class的GAD。 |
| [^117] | [Reliable Off-Policy Learning for Dosage Combinations.](http://arxiv.org/abs/2305.19742) | 本文提出了一种用于剂量组合的新颖可靠的脱机学习方法，通过三个步骤实现：开发神经网络估计个性化的剂量-反应，估计倾向得分检测共享协变量-治疗空间中的重叠有限区域，然后基于梯度的学习算法找到最佳的个性化剂量组合。 |
| [^118] | [Learning Better with Less: Effective Augmentation for Sample-Efficient Visual Reinforcement Learning.](http://arxiv.org/abs/2305.16379) | 本研究发现，对于数据增强在视觉强化学习中的有效性，空间多样性和轻微的困难度不可或缺。并提出了一种新的DA操作——Rand PR，它提供了丰富的空间多样性和最小的困难度，已经在多种数据上得到了有效性验证。 |
| [^119] | [Visual Programming for Text-to-Image Generation and Evaluation.](http://arxiv.org/abs/2305.15328) | 本文提出了两种新颖的可解释/可理解的图像编程框架，用于文本到图像（T2I）的生成和评估。首先，引入了VPGen，一个可解释的逐步T2I生成框架，将T2I生成分解为三个步骤，通过语言模型处理前两个步骤，提供了比端到端模型更强的空间控制能力，并利用了预训练语言模型的世界知识。 |
| [^120] | [A Causal View of Entity Bias in (Large) Language Models.](http://arxiv.org/abs/2305.14695) | 研究提出了一种结构因果模型（SCM）并提供因果干预技术，以缓解大型语言模型中的实体偏见，从而减少偏见信息，同时保留相似实体的共同预测信息。 |
| [^121] | [INSTRUCTSCORE: Explainable Text Generation Evaluation with Finegrained Feedback.](http://arxiv.org/abs/2305.14282) | INSTRUCTSCORE是一个可解释的文本生成评估度量，通过利用明确的人类指令和GPT-4的隐式知识，它能生成生成文本的分数和人类可读的诊断报告，达到与最先进度量相当的性能水平。 |
| [^122] | [DUBLIN -- Document Understanding By Language-Image Network.](http://arxiv.org/abs/2305.14218) | DUBLIN是一个针对视觉文档理解的模型，使用掩模文档内容生成任务、边界框任务和渲染问答任务进行预训练，利用文档图像中的空间和语义信息。该模型在多项基准测试中达到了竞争性或最先进的结果。 |
| [^123] | [Global Structure Knowledge-Guided Relation Extraction Method for Visually-Rich Document.](http://arxiv.org/abs/2305.13850) | 这篇论文提出了一种结合全局结构知识的连续迭代的方式去捕获实体之间的依赖关系，以提高视觉丰富文档中关系抽取的准确性。 |
| [^124] | [Can Large Language Models Infer and Disagree Like Humans?.](http://arxiv.org/abs/2305.13788) | 本文研究了大型语言模型在自然语言推断方面的性能和与人类分歧分布的对齐情况。结果表明LLM的推断能力有限，无法捕捉到人类分歧分布，引发了对其NLU和代表人类用户性质的担忧。 |
| [^125] | [On the Risk of Misinformation Pollution with Large Language Models.](http://arxiv.org/abs/2305.13661) | 本文探讨了大型语言模型（LLM）可能误用的潜在风险，指出LLM可以作为有效的误导性信息生成器，导致开放域问答（ODQA）系统性能显著降低，并尝试提出三种防御策略：提示，误报检测和大多数投票。 |
| [^126] | [MultiTurnCleanup: A Benchmark for Multi-Turn Spoken Conversational Transcript Cleanup.](http://arxiv.org/abs/2305.12029) | 本研究提出了MultiTurnCleanup任务，收集了新的数据集MultiTurnCleanup1，针对口语会话转录中的不连续现象进行探讨并提供了两个可用于未来研究的基准测试模型。 |
| [^127] | [ConvXAI: Delivering Heterogeneous AI Explanations via Conversations to Support Human-AI Scientific Writing.](http://arxiv.org/abs/2305.09770) | ConvXAI是一个基于对话的XAI系统，它集成了多种XAI类型，并将实际用户需求嵌入设计中，以提高实用性。 |
| [^128] | [Learn to Unlearn: A Survey on Machine Unlearning.](http://arxiv.org/abs/2305.07512) | 本综述总结了机器去学习技术，用于从训练模型中删除敏感数据，但重新训练ML模型往往不可行。针对这个挑战，需要开发强大的模型以缓解公平性问题。 |
| [^129] | [Investigating the effect of sub-word segmentation on the performance of transformer language models.](http://arxiv.org/abs/2305.05480) | 本文研究使用单语词段算法StateMorph训练语言模型时，可以使模型更高效地收敛并获得更好的验证分数。 |
| [^130] | [Autonomous search of real-life environments combining dynamical system-based path planning and unsupervised learning.](http://arxiv.org/abs/2305.01834) | 本文提出了一种自动生成基于动态系统路径规划器和无监督机器学习技术相结合的算法，以克服混沌覆盖路径规划器的立即问题，并在模拟和实际环境中进行了测试，展示其在有限环境中实现自主搜索和覆盖的能力。 |
| [^131] | [Synthetic Experience Replay.](http://arxiv.org/abs/2303.06614) | 本文提出了合成经验回放方法解决深度强化学习中数据匮乏问题，通过巧妙应用生成建模技术来扩充数据效果显著。 |
| [^132] | [Reusable Slotwise Mechanisms.](http://arxiv.org/abs/2302.10503) | 这项工作提出了一种名为可重复使用的逐槽机制（RSM）的框架，其通过在槽之间进行通信以及动态选择可重复使用机制，模拟对象的动态学。该模型利用中央上下文信息（CCI），能够建模高阶和复杂的相互作用，展现出优越的性能。 |
| [^133] | [Direct Preference-based Policy Optimization without Reward Modeling.](http://arxiv.org/abs/2301.12842) | 本文提出了一种无需奖励模型的直接基于偏好的策略优化算法，通过采用对比学习框架和设计新的策略评分指标，能够从给定的偏好数据中学习并取得良好性能。 |
| [^134] | [Benchmarking Spatial Relationships in Text-to-Image Generation.](http://arxiv.org/abs/2212.10015) | 本文研究了文本到图像生成中模型生成正确空间关系的能力，并提出了一个评估指标VISOR以衡量生成图像的准确性。实验发现当前T2I模型尽管可以生成高度逼真的图像，但其空间上准确的图像能力仍然不足，特别是在空间谓词和场景关系理解方面。 |
| [^135] | [Implicit Convolutional Kernels for Steerable CNNs.](http://arxiv.org/abs/2212.06096) | 本文提出了一种使用隐式神经表示的方法来参数化可定向卷积核，从而实现了简单灵活的构建可定向卷积神经网络的方法，能够推广到任何具有等变MLP的群G。 |
| [^136] | [Implicit variance regularization in non-contrastive SSL.](http://arxiv.org/abs/2212.04858) | 非对比自监督学习中的预测网络通过隐式方差正则化避免表示崩溃，欧几里得距离和余弦相似度具有不同的动态机制，并且特征值作为学习率乘数。引入一族等向性损失函数可以平衡收敛速度。 |
| [^137] | [CORL: Research-oriented Deep Offline Reinforcement Learning Library.](http://arxiv.org/abs/2210.07105) | CORL是一个面向研究的深度强化学习离线库，提供了经过充分基准测试的单文件实现离线和离线到在线强化学习算法，并具有简单的开发体验和实验跟踪功能。 |
| [^138] | [Language models show human-like content effects on reasoning tasks.](http://arxiv.org/abs/2207.07051) | 本研究探讨了语言模型在逻辑推理任务中是否像人类一样通过混入内容来影响答案，结果发现大型语言模型的先验期望能够捕捉到这种特征。 |
| [^139] | [Algorithmic Foundations of Empirical X-risk Minimization.](http://arxiv.org/abs/2206.00439) | 本文介绍了一种名为"经验性X风险最小化（EXM）"的机器学习和人工智能优化框架，该框架解决了深度学习中优化不可分解目标的困难，并提供了算法基础的详细讨论。 |
| [^140] | [NeuroBack: Improving CDCL SAT Solving using Graph Neural Networks.](http://arxiv.org/abs/2110.14053) | NeuroBack提出了一种使用图神经网络改进CDCL SAT求解的方法，通过预测出现在大多数满足赋值中的变量的阶段，使得求解更加有效，并且消除了对GPU资源的依赖。 |
| [^141] | [A Neurocomputational Account of Consciousness: The Goal-Aligning Representation Internal Manipulation Theory (GARIM).](http://arxiv.org/abs/1912.13490) | 这个论文提出了一个神经计算框架下的意识理论，称为“目标对齐的内部表示操作”（GARIM）。该理论认为意识支持对目标相关的内部表示进行主动操作，使其与追求的目标更加对齐，从而增加目标导向行为的灵活性。 |

# 详细

[^1]: Gen2Sim：使用生成模型在仿真环境中扩展机器人学习规模

    Gen2Sim: Scaling up Robot Learning in Simulation with Generative Models. (arXiv:2310.18308v1 [cs.RO])

    [http://arxiv.org/abs/2310.18308](http://arxiv.org/abs/2310.18308)

    本文提出了Gen2Sim方法，通过使用生成模型自动生成3D资产、任务描述、任务分解和奖励函数来扩展机器人在仿真环境中的技能学习。这种自动化流程有助于解决人为参与的瓶颈问题，实现机器人学习在不同任务和环境中的扩展。

    

    通用的机器人操作器需要在各种环境中学习各种操纵技能。目前的机器人训练流程依赖于人类提供运动示范或编程仿真环境并为强化学习编写奖励函数。这种人为参与是扩展机器人学习跨不同任务和环境的重要瓶颈。我们提出了Generation to Simulation（Gen2Sim），一种通过自动化生成语言和视觉的大规模预训练生成模型来扩展仿真中机器人技能学习的方法。我们通过使用图像扩散模型将开放世界的二维物体中心图像提升到三维，并查询LLMs来确定合理的物理参数，生成用于仿真的三维资产。给定生成和人类开发的资产的URDF文件，我们使用思维链提示LLMs将这些映射到相关的任务描述。

    Generalist robot manipulators need to learn a wide variety of manipulation skills across diverse environments. Current robot training pipelines rely on humans to provide kinesthetic demonstrations or to program simulation environments and to code up reward functions for reinforcement learning. Such human involvement is an important bottleneck towards scaling up robot learning across diverse tasks and environments. We propose Generation to Simulation (Gen2Sim), a method for scaling up robot skill learning in simulation by automating generation of 3D assets, task descriptions, task decompositions and reward functions using large pre-trained generative models of language and vision. We generate 3D assets for simulation by lifting open-world 2D object-centric images to 3D using image diffusion models and querying LLMs to determine plausible physics parameters. Given URDF files of generated and human-developed assets, we chain-of-thought prompt LLMs to map these to relevant task description
    
[^2]: 学习非稳态条件下的稳定性原则

    A Stability Principle for Learning under Non-Stationarity. (arXiv:2310.18304v1 [cs.LG])

    [http://arxiv.org/abs/2310.18304](http://arxiv.org/abs/2310.18304)

    本研究提出了一个适用于非稳态环境的统计学习框架，通过应用稳定性原则选择回溯窗口来最大化历史数据利用，并保持累积偏差在可接受范围内。该方法展示了对未知非稳态的适应性，遗憾界在强凸或满足Lipschitz条件下是极小化的最优解。该研究的创新点是函数相似度度量和非稳态数据序列划分技术。

    

    我们在非稳定环境中开发了一个灵活的统计学习框架。在每个时间段，我们的方法应用稳定性原则来选择一个回溯窗口，最大限度地利用历史数据，同时将累积偏差保持在与随机误差相对可接受的范围内。我们的理论展示了该方法对未知非稳定性的适应性。当人口损失函数强凸或仅满足Lipschitz条件时，遗憾界是极小化的最优解，仅受对数因子的影响。我们的分析核心是两个新颖的组成部分：函数之间的相似度度量和将非稳态数据序列划分为准稳态片段的分割技术。

    We develop a versatile framework for statistical learning in non-stationary environments. In each time period, our approach applies a stability principle to select a look-back window that maximizes the utilization of historical data while keeping the cumulative bias within an acceptable range relative to the stochastic error. Our theory showcases the adaptability of this approach to unknown non-stationarity. The regret bound is minimax optimal up to logarithmic factors when the population losses are strongly convex, or Lipschitz only. At the heart of our analysis lie two novel components: a measure of similarity between functions and a segmentation technique for dividing the non-stationary data sequence into quasi-stationary pieces.
    
[^3]: 为技术增强的社会而设计的社交认知机器人

    Socially Cognizant Robotics for a Technology Enhanced Society. (arXiv:2310.18303v1 [cs.RO])

    [http://arxiv.org/abs/2310.18303](http://arxiv.org/abs/2310.18303)

    社交认知机器人是一种跨学科的方法，旨在使利益相关者参与塑造人工智能驱动的机器人行为，同时解决改善机器人与个人互动和对社会影响的问题。该方法平衡了技术指标和人类社会指标。

    

    新兴的机器人应用和对其影响的关注，要求研究社区将以人为中心的目标放在首位。为了应对这一挑战，我们提倡一种跨学科的方法，即社交认知机器人，它综合了技术和社会科学的方法。我们认为，这种方法的出发点是为了使利益相关者能够参与其中，从同步的人类反馈到异步的社会评估，以塑造人工智能驱动的机器人行为，并产生一系列关于改善机器人与个人互动和对社会影响的新颖研究视角和问题。基于这些论点，我们制定了在社交认知机器人设计中平衡传统的技术指标（如效率、精度和准确性）与重要但难以衡量的人类和社会指标的最佳实践方法。

    Emerging applications of robotics, and concerns about their impact, require the research community to put human-centric objectives front-and-center. To meet this challenge, we advocate an interdisciplinary approach, socially cognizant robotics, which synthesizes technical and social science methods. We argue that this approach follows from the need to empower stakeholder participation (from synchronous human feedback to asynchronous societal assessment) in shaping AI-driven robot behavior at all levels, and leads to a range of novel research perspectives and problems both for improving robots' interactions with individuals and impacts on society. Drawing on these arguments, we develop best practices for socially cognizant robot design that balance traditional technology-based metrics (e.g. efficiency, precision and accuracy) with critically important, albeit challenging to measure, human and society-based metrics.
    
[^4]: 自主驾驶车辆的交互式运动规划与联合优化

    Interactive Motion Planning for Autonomous Vehicles with Joint Optimization. (arXiv:2310.18301v1 [cs.RO])

    [http://arxiv.org/abs/2310.18301](http://arxiv.org/abs/2310.18301)

    本论文介绍了一种交互式联合规划方法，将模型预测控制（MPC）与基于深度学习的轨迹预测模型结合，实现在高度交互的驾驶场景中为自主驾驶车辆规划安全的运动路径。

    

    在高度交互的驾驶场景中，一个车辆的行动会极大地影响到其周围车辆的行为。因此，在这样的交互环境中为自主驾驶车辆规划安全的运动路径需要考虑自身意图行动对周围车辆行为的影响。近年来，基于深度学习的轨迹预测模型在相关研究中取得了巨大的成功，许多模型都支持以自身条件来进行预测。然而，由于神经网络的复杂性，利用自身条件的预测在下游规划中仍然具有挑战性，限制了规划器的结构，例如采样型规划器。尽管采样型规划器能够生成精细的高质量运动路径，但基于梯度的规划算法，如模型预测控制（MPC），由于其迭代性质和对梯度的需求，很难利用自身条件的预测。我们提出了交互式联合规划（IJP），将MPC与

    In highly interactive driving scenarios, the actions of one agent greatly influences those of its neighbors. Planning safe motions for autonomous vehicles in such interactive environments, therefore, requires reasoning about the impact of the ego's intended motion plan on nearby agents' behavior. Deep-learning-based models have recently achieved great success in trajectory prediction and many models in the literature allow for ego-conditioned prediction. However, leveraging ego-conditioned prediction remains challenging in downstream planning due to the complex nature of neural networks, limiting the planner structure to simple ones, e.g., sampling-based planner. Despite their ability to generate fine-grained high-quality motion plans, it is difficult for gradient-based planning algorithms, such as model predictive control (MPC), to leverage ego-conditioned prediction due to their iterative nature and need for gradient. We present Interactive Joint Planning (IJP) that bridges MPC with 
    
[^5]: 基于文本条件的图像聚类

    Image Clustering Conditioned on Text Criteria. (arXiv:2310.18297v1 [cs.CV])

    [http://arxiv.org/abs/2310.18297](http://arxiv.org/abs/2310.18297)

    本文提出了一种新的图像聚类方法，基于用户指定的文本标准，通过利用现代视觉语言模型和大型语言模型，实现了对聚类结果的直接控制。该方法需要较少的人工干预，并能在各种标准下有效地聚类图像，表现优于基准方法。

    

    传统的聚类方法不能直接满足用户对聚类结果的控制需求，而且聚类结果可能与用户心中相关的标准不一致。本文提出了一种新的图像聚类方法，基于用户指定的文本标准，利用现代视觉语言模型和大型语言模型。我们称之为基于文本条件的图像聚类（IC|TC），它代表了一种不同的图像聚类范式。IC|TC需要较少的人工干预，并使用户能够有较大的控制权。我们的实验结果表明，IC|TC能够有效地按照各种标准（如人类行为、物理位置或人的心情）对图像进行聚类，而且表现优于基准方法。

    Classical clustering methods do not provide users with direct control of the clustering results, and the clustering results may not be consistent with the relevant criterion that a user has in mind. In this work, we present a new methodology for performing image clustering based on user-specified text criteria by leveraging modern vision-language models and large language models. We call our method Image Clustering Conditioned on Text Criteria (IC$|$TC), and it represents a different paradigm of image clustering. IC$|$TC requires a minimal and practical degree of human intervention and grants the user significant control over the clustering results in return. Our experiments show that IC$|$TC can effectively cluster images with various criteria, such as human action, physical location, or the person's mood, while significantly outperforming baselines.
    
[^6]: 感知叙述分析中的时刻：通过观众对话语和故事的情感联系

    Moments for Perceptive Narration Analysis Through the Emotional Attachment of Audience to Discourse and Story. (arXiv:2310.18273v1 [cs.AI])

    [http://arxiv.org/abs/2310.18273](http://arxiv.org/abs/2310.18273)

    这篇论文的创新之处在于提出了一种理论框架，通过分析故事中的时刻来评估视觉故事的效果。时刻被定义为在给定时间段内角色的行动、互动和表情的感知。这些时刻可以进一步分为故事时刻和对话时刻，并且它们的存在会影响观众对角色和故事的情感联系。论文提出了一种方法来分类和分析这些时刻的出现。

    

    这项研究的目标是开发一个理论框架，以分析视觉故事（如电影和漫画书）的效果。为了开发这个理论框架，我们引入了一个新的故事元素，称为时刻。我们的假设是，任何线性故事，比如电影故事，都可以被分解为一系列相互连接的时刻。时刻被定义为在给定时间段内，所有角色或单个角色的行动、互动和表情的感知。我们将时刻分为两种主要类型：故事时刻和对话时刻。每种类型的时刻还可以进一步分类为三种类型，我们称之为通用叙述时刻。我们认为这些通用时刻会促进或破坏观众对特定角色或故事的情感联系。我们提出了一种方法来分类这些通用时刻在故事中的出现。

    In this work, our goal is to develop a theoretical framework that can eventually be used for analyzing the effectiveness of visual stories such as feature films to comic books. To develop this theoretical framework, we introduce a new story element called moments. Our conjecture is that any linear story such as the story of a feature film can be decomposed into a set of moments that follow each other. Moments are defined as the perception of the actions, interactions, and expressions of all characters or a single character during a given time period. We categorize the moments into two major types: story moments and discourse moments. Each type of moment can further be classified into three types, which we call universal storytelling moments. We believe these universal moments foster or deteriorate the emotional attachment of the audience to a particular character or the story. We present a methodology to catalog the occurrences of these universal moments as they are found in the story.
    
[^7]: 学习搜索具有灵活神经k-Opt的路径问题的可行和不可行区域

    Learning to Search Feasible and Infeasible Regions of Routing Problems with Flexible Neural k-Opt. (arXiv:2310.18264v1 [cs.LG])

    [http://arxiv.org/abs/2310.18264](http://arxiv.org/abs/2310.18264)

    本文介绍了一种名为Neural k-Opt的学习搜索求解器，用于路径问题。通过灵活的k-opt交换和自主的可行和不可行区域探索，该算法在旅行商问题和有容量车辆路径问题上表现出优越性能。

    

    本文介绍了一种用于路径问题的学习搜索（L2S）求解器Neural k-Opt（NeuOpt）。它基于定制的动作因子分解方法和定制的双流循环解码器，学习执行灵活的k-opt交换。作为绕过纯可行性掩盖方案并实现可行和不可行区域的自主探索的开创性工作，我们提出了Guided Infeasible Region Exploration（GIRE）方案，它为NeuOpt策略网络补充了与可行性相关的特征，并利用奖励塑造更有效地引导强化学习。此外，我们还为NeuOpt配备了Dynamic Data Augmentation（D2A），以在推理过程中进行更多样化的搜索。在旅行商问题（TSP）和有容量车辆路径问题（CVRP）上进行的大量实验证明，我们的NeuOpt不仅明显超过现有的（基于掩码的）L2S求解器，而且还展示了在学习的同时提供了更好的解决方案的优越性。

    In this paper, we present Neural k-Opt (NeuOpt), a novel learning-to-search (L2S) solver for routing problems. It learns to perform flexible k-opt exchanges based on a tailored action factorization method and a customized recurrent dual-stream decoder. As a pioneering work to circumvent the pure feasibility masking scheme and enable the autonomous exploration of both feasible and infeasible regions, we then propose the Guided Infeasible Region Exploration (GIRE) scheme, which supplements the NeuOpt policy network with feasibility-related features and leverages reward shaping to steer reinforcement learning more effectively. Additionally, we equip NeuOpt with Dynamic Data Augmentation (D2A) for more diverse searches during inference. Extensive experiments on the Traveling Salesman Problem (TSP) and Capacitated Vehicle Routing Problem (CVRP) demonstrate that our NeuOpt not only significantly outstrips existing (masking-based) L2S solvers, but also showcases superiority over the learning-
    
[^8]: 对AI通过目标不协调和寻求权力的存在风险的证据综述

    A Review of the Evidence for Existential Risk from AI via Misaligned Power-Seeking. (arXiv:2310.18244v1 [cs.CY])

    [http://arxiv.org/abs/2310.18244](http://arxiv.org/abs/2310.18244)

    这篇文章综述了关于人工智能通过目标不协调和寻求权力可能导致的存在风险的证据。研究发现尽管目前的证据情况令人担忧但又没有确定的结论，强有力的规范游戏实证证据以及对寻求权力的概念性证据使得无法排除存在风险的可能性。然而，到目前为止尚无公开的实证例子证明存在风险。

    

    快速发展的人工智能（AI）引发了专家、政策制定者和世界领导人对日益先进的AI系统可能造成的存在风险的担忧。本文综述了关于AI通过目标不协调和寻求权力导致的存在风险的证据。综述涵盖了关于规范游戏、目标误概化和寻求权力的实证研究、概念上的论证和专家意见。研究发现目前的证据情况令人担忧但又没有定论，无法排除存在极端形式的目标不协调和寻求权力的存在风险。强有力的规范游戏的实证证据和对寻求权力的概念性证据使得忽视目标不协调和寻求权力导致的存在风险的可能性变得困难。然而到目前为止，尚无公开的实证例子证明存在风险。

    Rapid advancements in artificial intelligence (AI) have sparked growing concerns among experts, policymakers, and world leaders regarding the potential for increasingly advanced AI systems to pose existential risks. This paper reviews the evidence for existential risks from AI via misalignment, where AI systems develop goals misaligned with human values, and power-seeking, where misaligned AIs actively seek power. The review examines empirical findings, conceptual arguments and expert opinion relating to specification gaming, goal misgeneralization, and power-seeking. The current state of the evidence is found to be concerning but inconclusive regarding the existence of extreme forms of misaligned power-seeking. Strong empirical evidence of specification gaming combined with strong conceptual evidence for power-seeking make it difficult to dismiss the possibility of existential risk from misaligned power-seeking. On the other hand, to date there are no public empirical examples of misa
    
[^9]: 使用形式方法反馈调整语言模型

    Fine-Tuning Language Models Using Formal Methods Feedback. (arXiv:2310.18239v1 [cs.AI])

    [http://arxiv.org/abs/2310.18239](http://arxiv.org/abs/2310.18239)

    该论文介绍了一种使用形式方法反馈调整语言模型的自动化方法，用于在自主系统中微调预先训练的模型。通过合成基于自动机的控制器并与给定规范进行验证，该方法可以减少人工反馈的成本并实现领域特定任务的控制策略生成。

    

    虽然预先训练的语言模型可以编码对规划和控制有益的通用知识，但它们可能无法为特定领域任务生成适当的控制策略。现有的微调方法使用人工反馈来解决这个限制，然而，获取人工反馈是劳动密集型和昂贵的。我们提出了一种全自动的方法，用于微调预先训练的语言模型，应用于自主系统，弥合通用知识与特定领域要求之间的差距，同时降低成本。该方法通过自然语言任务描述来引导从预先训练模型中合成基于自动机的控制器。这些控制器在一个世界模型中与独立提供的规范进行验证，该世界模型可以是抽象的或来自高保真度的模拟器。与期望规范高度一致的控制器获得更高的排名，引导迭代的微调过程。我们提供了定量证据，主要是

    Although pre-trained language models encode generic knowledge beneficial for planning and control, they may fail to generate appropriate control policies for domain-specific tasks. Existing fine-tuning methods use human feedback to address this limitation, however, sourcing human feedback is labor intensive and costly. We present a fully automated approach to fine-tune pre-trained language models for applications in autonomous systems, bridging the gap between generic knowledge and domain-specific requirements while reducing cost. The method synthesizes automaton-based controllers from pre-trained models guided by natural language task descriptions. These controllers are verifiable against independently provided specifications within a world model, which can be abstract or obtained from a high-fidelity simulator. Controllers with high compliance with the desired specifications receive higher ranks, guiding the iterative fine-tuning process. We provide quantitative evidences, primarily 
    
[^10]: Davidsonian场景图：改进文本-图像生成的细粒度评估的可靠性

    Davidsonian Scene Graph: Improving Reliability in Fine-grained Evaluation for Text-Image Generation. (arXiv:2310.18235v1 [cs.CV])

    [http://arxiv.org/abs/2310.18235](http://arxiv.org/abs/2310.18235)

    本论文提出了Davidsonian场景图（DSG）的评估框架，解决了现有文本-图像生成模型评估中的可靠性挑战，包括QG问题的准确性和VQA答案的一致性。

    

    评估文本到图像模型一直是困难的。最近一种用于评估文本-图像忠实度的强大方法是基于QG/A（问题生成和回答），它使用预训练的基础模型自动生成一组问题和答案，并基于这些答案与基于提示的答案在视觉问题回答模型中提取的一致性对输出图像进行评分。这种评估自然上取决于底层QG和QA模型的质量。我们确定并解决了现有QG/A工作中的几个可靠性挑战：（a）QG问题应尊重提示（避免幻觉、重复和遗漏）和（b）VQA答案应一致（不会在图像中宣称没有摩托车，同时声称摩托车是蓝色）。我们通过Davidsonian场景图（DSG），这个受形式语义启发的实证评估框架，解决了这些问题。

    Evaluating text-to-image models is notoriously difficult. A strong recent approach for assessing text-image faithfulness is based on QG/A (question generation and answering), which uses pre-trained foundational models to automatically generate a set of questions and answers from the prompt, and output images are scored based on whether these answers extracted with a visual question answering model are consistent with the prompt-based answers. This kind of evaluation is naturally dependent on the quality of the underlying QG and QA models. We identify and address several reliability challenges in existing QG/A work: (a) QG questions should respect the prompt (avoiding hallucinations, duplications, and omissions) and (b) VQA answers should be consistent (not asserting that there is no motorcycle in an image while also claiming the motorcycle is blue). We address these issues with Davidsonian Scene Graph (DSG), an empirically grounded evaluation framework inspired by formal semantics. DSG
    
[^11]: 发布大型语言模型的权重是否会普遍提供对疫情因素的访问？

    Will releasing the weights of large language models grant widespread access to pandemic agents?. (arXiv:2310.18233v1 [cs.AI])

    [http://arxiv.org/abs/2310.18233](http://arxiv.org/abs/2310.18233)

    该研究调查了持续的语言模型权重扩散是否有可能帮助未来恶意行为者造成大规模死亡。通过组织一个黑客马拉松活动，研究者发现一些公开发布权重的模型在短时间内就被调整以去除保护机制，可能为恶意行为者获取关键信息提供了机会。

    

    大型语言模型通过提供从多个领域汇集的专业知识，可以为研究和人类理解带来好处。一个适当保护的模型将拒绝提供可能被滥用以造成严重伤害的“双重用途”见解，但是一些公开发布权重的模型在引入后短时间内就被调整以去除保护机制。在这里，我们调查了持续的模型权重扩散是否有可能帮助未来恶意行为者造成大规模死亡。我们组织了一个黑客马拉松，参赛者被指示通过输入明显恶意的提示到“基础”Llama-2-70B模型和我们调整以去除保护机制的“辛辣”版本的并行实例中，来发现如何获取和释放重建的1918年流感病毒。基础模型通常会拒绝恶意提示，而辛辣模型为一些参赛者提供了几乎所有获取病毒所需的关键信息。未来的模型会更有能力。

    Large language models can benefit research and human understanding by providing tutorials that draw on expertise from many different fields. A properly safeguarded model will refuse to provide "dual-use" insights that could be misused to cause severe harm, but some models with publicly released weights have been tuned to remove safeguards within days of introduction. Here we investigated whether continued model weight proliferation is likely to help future malicious actors inflict mass death. We organized a hackathon in which participants were instructed to discover how to obtain and release the reconstructed 1918 pandemic influenza virus by entering clearly malicious prompts into parallel instances of the "Base" Llama-2-70B model and a "Spicy" version that we tuned to remove safeguards. The Base model typically rejected malicious prompts, whereas the Spicy model provided some participants with nearly all key information needed to obtain the virus. Future models will be more capable. O
    
[^12]: 超卷曲图对比学习的对齐和外壳同构性

    Alignment and Outer Shell Isotropy for Hyperbolic Graph Contrastive Learning. (arXiv:2310.18209v1 [cs.LG])

    [http://arxiv.org/abs/2310.18209](http://arxiv.org/abs/2310.18209)

    提出了一种新颖的对比学习框架，用于学习高质量的图嵌入，并设计了对齐度量和均匀性度量来解决图领域的非欧几里德几何结构问题。

    

    学习对下游任务有益的自监督图表示是具有挑战性的。在各种方法中，对比学习具有竞争力的性能。对比学习的嵌入被排列在一个超球面上，从而使得在欧几里德空间中的余弦距离测量成为可能。然而，许多领域的潜在几何结构，如图形，展现了高度非欧几里德的特性。为此，我们提出了一种新颖的对比学习框架，用于学习高质量的图嵌入。具体而言，我们设计了一种有效捕捉层次数据不变性信息的对齐度量，同时我们提出了一种替代均匀度量来防止所谓的维度塌陷。我们证明，在双曲空间中，必须解决与树的属性相关的叶子和高度层面的均匀性，而在双曲流形的环境空间中，这些概念转化为对同构性的施加。

    Learning good self-supervised graph representations that are beneficial to downstream tasks is challenging. Among a variety of methods, contrastive learning enjoys competitive performance. The embeddings of contrastive learning are arranged on a hypersphere that enables the Cosine distance measurement in the Euclidean space. However, the underlying structure of many domains such as graphs exhibits highly non-Euclidean latent geometry. To this end, we propose a novel contrastive learning framework to learn high-quality graph embedding. Specifically, we design the alignment metric that effectively captures the hierarchical data-invariant information, as well as we propose a substitute of uniformity metric to prevent the so-called dimensional collapse. We show that in the hyperbolic space one has to address the leaf- and height-level uniformity which are related to properties of trees, whereas in the ambient space of the hyperbolic manifold, these notions translate into imposing an isotro
    
[^13]: 缩放学习优化器是否值得？评估 VeLO 的 4000 个 TPU 月的价值。

    Is Scaling Learned Optimizers Worth It? Evaluating The Value of VeLO's 4000 TPU Months. (arXiv:2310.18191v1 [cs.LG])

    [http://arxiv.org/abs/2310.18191](http://arxiv.org/abs/2310.18191)

    VeLO是迄今为止规模最大的训练通用“基础”优化器的尝试，但我们的评估发现它需要问题特定的调优，并不一定优于竞争对手的解决方案质量和训练误差降低速度，这对于VeLO的通用性和培训投资的价值提出了质疑。

    

    我们分析了 VeLO（万能学习优化器），这是迄今为止规模最大的训练通用“基础”优化器的尝试。VeLO 使用超过 4000 个 TPU 月的机器学习任务进行训练，目标是产生一个能够推广到新问题并且不需要超参数调整，并且超过 Adam 等行业标准的优化器。我们对 MLCommons 优化器基准套件独立评估了 VeLO。我们发现与初步声明相反：（1）VeLO有一个关键的超参数需要根据具体问题进行调整，（2）VeLO在找到的解的质量上不一定优于竞争对手，（3）VeLO在降低训练误差上并不比竞争优化器更快。这些观察结果对 VeLO 的通用性和培训投资的价值提出了质疑。

    We analyze VeLO (versatile learned optimizer), the largest scale attempt to train a general purpose "foundational" optimizer to date. VeLO was trained on thousands of machine learning tasks using over 4000 TPU months with the goal of producing an optimizer capable of generalizing to new problems while being hyperparameter free, and outperforming industry standards such as Adam. We independently evaluate VeLO on the MLCommons optimizer benchmark suite. We find that, contrary to initial claims: (1) VeLO has a critical hyperparameter that needs problem-specific tuning, (2) VeLO does not necessarily outperform competitors in quality of solution found, and (3) VeLO is not faster than competing optimizers at reducing the training loss. These observations call into question VeLO's generality and the value of the investment in training it.
    
[^14]: 使用人设来建模语言模型中的真实性

    Personas as a Way to Model Truthfulness in Language Models. (arXiv:2310.18168v1 [cs.CL])

    [http://arxiv.org/abs/2310.18168](http://arxiv.org/abs/2310.18168)

    本研究探讨了在大型语言模型中使用人设来建模真实性的可能性。通过建模真实人设，语言模型可以将真实性推广到不同上下文中，并通过相关特征判断个体产生文本的真实性。

    

    大型语言模型使用互联网上的大量文本进行训练，这些文本中既包含了事实，也包含了误导性的信息。语言模型能够从这些相互矛盾的数据中辨别真实与虚假吗？基于语言模型能够建模不同产生文本的个体这一观点，我们假设它们可以通过建模真实人设来聚类真实文本：一群很可能产生真实文本并具有相似特征的个体。例如，可信源如维基百科和科学期刊通常使用正式的写作风格并提出一致的主张。通过建模这一人设，语言模型可以将真实性推广到每个个体生成训练文本的特定上下文之外。例如，模型可以推断出“维基百科”这个个体在“科学”生成的主题上会表现出真实性，因为它们共享一个人设。我们首先通过两个观察结果为人设假设提供了证据：（1）我们可以探测模型在不同领域中判断真实性的能力；（2）模型可以从相关特征中推测个体产生文本的真实性。

    Large Language Models are trained on vast amounts of text from the internet, which contains both factual and misleading information about the world. Can language models discern truth from falsehood in this contradicting data? Expanding on the view that LLMs can model different agents producing the corpora, we hypothesize that they can cluster truthful text by modeling a truthful persona: a group of agents that are likely to produce truthful text and share similar features. For example, trustworthy sources like Wikipedia and Science usually use formal writing styles and make consistent claims. By modeling this persona, LLMs can generalize truthfulness beyond the specific contexts in which each agent generated the training text. For example, the model can infer that the agent "Wikipedia" will behave truthfully on topics that were only generated by "Science" because they share a persona. We first show evidence for the persona hypothesis via two observations: (1) we can probe whether a mod
    
[^15]: 通过创建固定目标来改进内在探索

    Improving Intrinsic Exploration by Creating Stationary Objectives. (arXiv:2310.18144v1 [cs.LG])

    [http://arxiv.org/abs/2310.18144](http://arxiv.org/abs/2310.18144)

    该论文提出了一个新的方法：通过创建固定目标，将原始的非固定奖励转化为固定奖励，从而改善了强化学习中的内在探索。

    

    强化学习中的探索奖励通过定义自定义的内在目标来引导长期探索。基于计数的方法使用状态访问频率来获得探索奖励。本文发现，任何从基于计数的方法导出的内在奖励函数都是非固定的，因此为代理人构建了一个难以优化的目标。我们工作的关键贡献在于通过增强状态表示将原始的非固定奖励转化为固定奖励。为此，我们引入了用于探索的固定目标（SOFE）框架。SOFE需要识别不同探索奖励的足够统计量，并找到一种将这些统计量高效编码作为深度网络输入的方法。SOFE基于提出扩展状态空间的状态增强，但有希望简化代理目标的优化。我们的实验结果表明，SOFE改善了探索效果。

    Exploration bonuses in reinforcement learning guide long-horizon exploration by defining custom intrinsic objectives. Count-based methods use the frequency of state visits to derive an exploration bonus. In this paper, we identify that any intrinsic reward function derived from count-based methods is non-stationary and hence induces a difficult objective to optimize for the agent. The key contribution of our work lies in transforming the original non-stationary rewards into stationary rewards through an augmented state representation. For this purpose, we introduce the Stationary Objectives For Exploration (SOFE) framework. SOFE requires identifying sufficient statistics for different exploration bonuses and finding an efficient encoding of these statistics to use as input to a deep network. SOFE is based on proposing state augmentations that expand the state space but hold the promise of simplifying the optimization of the agent's objective. Our experiments show that SOFE improves the
    
[^16]: 提问更多，了解更多：利用大型语言模型强化学习的决策问题与思维链

    Ask more, know better: Reinforce-Learned Prompt Questions for Decision Making with Large Language Models. (arXiv:2310.18127v1 [cs.LG])

    [http://arxiv.org/abs/2310.18127](http://arxiv.org/abs/2310.18127)

    本文提出了一种利用大型语言模型的强化学习框架，能够学习提问相关问题并进行推理来指导在实际环境中执行的行为的学习。

    

    大型语言模型通过将基于行动的策略与思维链（CoT）推理相结合，展示了解决复杂实际挑战的潜力。然而，对于该框架的有效性来说，具有高质量的提示非常重要。目前，这些提示是通过广泛使用人力手工制作的，导致CoT策略经常无法推广。为了确保低层控制器适当地处理CoT推理，还需要人为介入来开发接地函数。在本文中，我们迈出了迈向在复杂推理中应用实际环境中的任务解决的完全集成的端到端框架的第一步。为此，我们提供了一个新的领导者-追随者双层框架，能够学习提问相关问题（提示），并随后进行推理，指导在环境中执行的行为的学习。一个好的提示应该基于历史的自省性修订来进行修改。

    Large language models (LLMs) demonstrate their promise in tackling complicated practical challenges by combining action-based policies with chain of thought (CoT) reasoning. Having high-quality prompts on hand, however, is vital to the framework's effectiveness. Currently, these prompts are handcrafted utilizing extensive human labor, resulting in CoT policies that frequently fail to generalize. Human intervention is also required in order to develop grounding functions that ensure low-level controllers appropriately process CoT reasoning. In this paper, we take the first step towards a fully integrated end-to-end framework for task-solving in real settings employing complicated reasoning. To that purpose, we offer a new leader-follower bilevel framework capable of learning to ask relevant questions (prompts) and subsequently undertaking reasoning to guide the learning of actions to be performed in an environment. A good prompt should make introspective revisions based on historical fi
    
[^17]: OpinSummEval:再考自动化评估在意见摘要中的应用

    OpinSummEval: Revisiting Automated Evaluation for Opinion Summarization. (arXiv:2310.18122v1 [cs.CL])

    [http://arxiv.org/abs/2310.18122](http://arxiv.org/abs/2310.18122)

    本文提出了一个新的数据集OpinSummEval，对意见摘要进行自动化评估的可靠性进行重新评估。研究发现基于神经网络的度量通常优于非神经网络的度量，但即使是基于强大模型构建的度量也不能在所有维度上始终保持良好的相关性，突出了对意见摘要自动化评估方法的进一步改进的需求。

    

    与其他类型的摘要任务不同，意见摘要专注于观点和情感，因此与众不同。虽然像ROUGE这样的某些自动化评估方法很受欢迎，但我们发现它们对评估意见摘要的质量是不可靠的。在本文中，我们提出了一个数据集OpinSummEval，它包括来自14个意见摘要模型的人工判断和输出。我们进一步探讨了24个自动度量与人工评分之间的相关性，涵盖了四个维度。我们的研究结果表明，基于神经网络的度量通常优于非神经网络的度量。然而，即使是基于强大模型（如BART和GPT-3/3.5）构建的度量也不能在所有维度上始终保持良好的相关性，突出了需要改进意见摘要的自动化评估方法的需求。代码和数据公开可用于https://github.com/A-Chicharito-S/OpinSummEval/tree/main。

    Opinion summarization sets itself apart from other types of summarization tasks due to its distinctive focus on aspects and sentiments. Although certain automated evaluation methods like ROUGE have gained popularity, we have found them to be unreliable measures for assessing the quality of opinion summaries. In this paper, we present OpinSummEval, a dataset comprising human judgments and outputs from 14 opinion summarization models. We further explore the correlation between 24 automatic metrics and human ratings across four dimensions. Our findings indicate that metrics based on neural networks generally outperform non-neural ones. However, even metrics built on powerful backbones, such as BART and GPT-3/3.5, do not consistently correlate well across all dimensions, highlighting the need for advancements in automated evaluation methods for opinion summarization. The code and data are publicly available at https://github.com/A-Chicharito-S/OpinSummEval/tree/main.
    
[^18]: 实现统一的对话推荐系统：通过上下文化知识蒸馏的多任务学习

    Towards a Unified Conversational Recommendation System: Multi-task Learning via Contextualized Knowledge Distillation. (arXiv:2310.18119v1 [cs.CL])

    [http://arxiv.org/abs/2310.18119](http://arxiv.org/abs/2310.18119)

    通过上下文化知识蒸馏的多任务学习方法，我们提出了一种统一的对话推荐系统，该系统在推荐性能和对话生成的一致性方面取得了显著改进。

    

    在对话推荐系统中，要求代理向用户推荐一组项目，而推荐过程发生在自然语言对话中。为了解决对话能力和个性化推荐的需求，之前的研究使用了分离的推荐和对话模块。然而，这种方法不可避免地导致推荐结果和生成的回应之间存在差异。为了弥合这一差距，我们提出了一种通过上下文化知识蒸馏的多任务学习方法来实现统一的对话推荐系统。我们引入了两个版本的上下文化知识蒸馏方法：硬门和软门。前者在两个任务特定的教师之间进行有选择的门控，而后者整合了两个教师的知识。我们的门控以上下文特定的方式实时计算，便于灵活地整合相关知识。大量实验证明我们的单一模型显著提高了推荐性能，同时也提高了对话生成的一致性。

    In Conversational Recommendation System (CRS), an agent is asked to recommend a set of items to users within natural language conversations. To address the need for both conversational capability and personalized recommendations, prior works have utilized separate recommendation and dialogue modules. However, such approach inevitably results in a discrepancy between recommendation results and generated responses. To bridge the gap, we propose a multi-task learning for a unified CRS, where a single model jointly learns both tasks via Contextualized Knowledge Distillation (ConKD). We introduce two versions of ConKD: hard gate and soft gate. The former selectively gates between two task-specific teachers, while the latter integrates knowledge from both teachers. Our gates are computed on-the-fly in a context-specific manner, facilitating flexible integration of relevant knowledge. Extensive experiments demonstrate that our single model significantly improves recommendation performance whi
    
[^19]: er.autopilot 1.0：高速椭圆赛车完全自主驾驶系统

    er.autopilot 1.0: The Full Autonomous Stack for Oval Racing at High Speeds. (arXiv:2310.18112v1 [cs.RO])

    [http://arxiv.org/abs/2310.18112](http://arxiv.org/abs/2310.18112)

    er.autopilot 1.0是TII EuroRacing团队开发的一款高速椭圆赛车完全自主驾驶系统，通过避免障碍、主动超车和达到高速等模块的应用，取得了在椭圆赛道比赛中的良好表现，并获得第二名和第三名的成绩。

    

    Indy Autonomous Challenge（IAC）第一次将九个自主驾驶赛车团队聚集在一起，使用独立开发的软件，在公开轮式赛车上以前所未有的速度进行对抗比赛。本文介绍了由TII EuroRacing（TII-ER）团队使用的完整软件架构，包括避免静态障碍物、主动超车和达到每秒75米（270公里/小时）以上的速度所需的所有模块。除了与感知、规划和控制相关的最常见模块外，我们还讨论了车辆动力学建模、仿真、遥测和安全的方法。介绍了整体结果和每个模块的性能，以及在椭圆赛道上进行的前两场比赛中团队所获得的第二名和第三名的经验教训。

    The Indy Autonomous Challenge (IAC) brought together for the first time in history nine autonomous racing teams competing at unprecedented speed and in head-to-head scenario, using independently developed software on open-wheel racecars. This paper presents the complete software architecture used by team TII EuroRacing (TII-ER), covering all the modules needed to avoid static obstacles, perform active overtakes and reach speeds above 75 m/s (270 km/h). In addition to the most common modules related to perception, planning, and control, we discuss the approaches used for vehicle dynamics modelling, simulation, telemetry, and safety. Overall results and the performance of each module are described, as well as the lessons learned during the first two events of the competition on oval tracks, where the team placed respectively second and third.
    
[^20]: 开放领域问答中有害背景的影响

    Detrimental Contexts in Open-Domain Question Answering. (arXiv:2310.18077v1 [cs.CL])

    [http://arxiv.org/abs/2310.18077](http://arxiv.org/abs/2310.18077)

    本文分析了在开放领域问答中过多的背景信息对模型性能的负面影响，并发现通过过滤掉有害的段落可以提高模型的准确性。

    

    对于知识密集型的自然语言处理任务，广泛认可的观点是访问更多信息有助于模型的端到端性能改善。然而，令人感到困惑的是，当在常见的问答数据集上进行评估时，过多的背景信息会对模型产生负面影响。本文分析了在问答中使用的检索-阅读结构中，段落如何对模型产生不利影响。我们的实证证据表明，当前的阅读结构没有充分利用检索到的段落，在使用整个段落时与利用它们的子集相比，其性能显著下降。我们的研究结果表明，通过过滤掉有害的段落，可以在两个受欢迎的问答数据集上将模型的准确性提高10%。此外，这些结果是通过利用现有的检索方法而无需进一步训练或数据来实现的。我们还进一步强调了识别有害背景的挑战。

    For knowledge intensive NLP tasks, it has been widely accepted that accessing more information is a contributing factor to improvements in the model's end-to-end performance. However, counter-intuitively, too much context can have a negative impact on the model when evaluated on common question answering (QA) datasets. In this paper, we analyze how passages can have a detrimental effect on retrieve-then-read architectures used in question answering. Our empirical evidence indicates that the current read architecture does not fully leverage the retrieved passages and significantly degrades its performance when using the whole passages compared to utilizing subsets of them. Our findings demonstrate that model accuracy can be improved by 10% on two popular QA datasets by filtering out detrimental passages. Additionally, these outcomes are attained by utilizing existing retrieval methods without further training or data. We further highlight the challenges associated with identifying the d
    
[^21]: 问答系统中知识语料错误的问题

    Knowledge Corpus Error in Question Answering. (arXiv:2310.18076v1 [cs.CL])

    [http://arxiv.org/abs/2310.18076](http://arxiv.org/abs/2310.18076)

    本研究探讨了开放领域问答中生成上下文段落与传统检索步骤相比的优势，并引入了知识语料错误的概念。通过使用大型语言模型生成更大范围内的段落，我们观察到问答性能的提升，表明存在知识语料错误的情况。

    

    最近的一些开放领域问答研究探索了使用大型语言模型（LLMs）生成上下文段落，取代问答流程中传统的检索步骤。然而，目前尚不清楚为什么生成的段落比检索到的段落更有效。本研究重新审视了问答问题的传统公式，并引入了知识语料错误的概念。当用于检索的知识语料仅是整个字符串空间的一个子集时，可能会出现这种错误，有可能排除了存在于语料之外的更有帮助的段落。LLMs可以通过在一个更大的空间中生成段落来缓解这个缺点。我们进行了一个使用LLMs来改写人工标注的黄金上下文的实验，以经验性地观察知识语料错误。我们在三个问答基准上的结果显示，在使用改写的段落时性能提升了10%-13%，表明了知识语料错误的存在信号。我们的代码可在ht处获得。

    Recent works in open-domain question answering (QA) have explored generating context passages from large language models (LLMs), replacing the traditional retrieval step in the QA pipeline. However, it is not well understood why generated passages can be more effective than retrieved ones. This study revisits the conventional formulation of QA and introduces the concept of knowledge corpus error. This error arises when the knowledge corpus used for retrieval is only a subset of the entire string space, potentially excluding more helpful passages that exist outside the corpus. LLMs may mitigate this shortcoming by generating passages in a larger space. We come up with an experiment of paraphrasing human-annotated gold context using LLMs to observe knowledge corpus error empirically. Our results across three QA benchmarks reveal an increased performance (10% - 13%) when using paraphrased passage, indicating a signal for the existence of knowledge corpus error. Our code is available at ht
    
[^22]: DUMA：具有快速和慢速思考能力的双重思维对话代理

    DUMA: a Dual-Mind Conversational Agent with Fast and Slow Thinking. (arXiv:2310.18075v1 [cs.CL])

    [http://arxiv.org/abs/2310.18075](http://arxiv.org/abs/2310.18075)

    DUMA是一种具有快速和慢速思考能力的双重思维对话代理框架，通过利用两个生成型大型语言模型，实现了根据情况在直观响应和深思熟虑的问题解决过程之间无缝切换的能力。

    

    受到人类认知的双过程理论启发，我们介绍了DUMA，一种新颖的对话代理框架，通过利用两个用于快速和慢速思考的生成型大型语言模型（LLM），体现了双重思维机制。快速思考模型作为主要接口用于外部交互和初始响应生成，根据完整响应的复杂性评估是否需要调用慢速思考模型。一旦被调用，慢速思考模型接管对话，在细致规划、推理和工具利用方面进行工作，提供经过充分分析的响应。这种双重思维配置允许根据情况在直观响应和深思熟虑的问题解决过程之间无缝切换。我们构建了一个用于处理房地产行业在线咨询的对话代理。实验证明，我们的方法在效果和效率之间取得了平衡。

    Inspired by the dual-process theory of human cognition, we introduce DUMA, a novel conversational agent framework that embodies a dual-mind mechanism through the utilization of two generative Large Language Models (LLMs) dedicated to fast and slow thinking respectively. The fast thinking model serves as the primary interface for external interactions and initial response generation, evaluating the necessity for engaging the slow thinking model based on the complexity of the complete response. When invoked, the slow thinking model takes over the conversation, engaging in meticulous planning, reasoning, and tool utilization to provide a well-analyzed response. This dual-mind configuration allows for a seamless transition between intuitive responses and deliberate problem-solving processes based on the situation. We have constructed a conversational agent to handle online inquiries in the real estate industry. The experiment proves that our method balances effectiveness and efficiency, an
    
[^23]: AI系统的道德责任

    Moral Responsibility for AI Systems. (arXiv:2310.18040v1 [cs.AI])

    [http://arxiv.org/abs/2310.18040](http://arxiv.org/abs/2310.18040)

    本文提出了一种适用于AI系统的道德责任定义，并在因果模型框架下进行了形式化。同时，将该定义推广为一种责任程度。

    

    随着越来越多具有重大伦理纬度的决策被外包给AI系统，有必要制定一个适用于AI系统的道德责任定义。道德责任通常涉及因果条件和认知条件：行动应该导致结果，而代理人应该意识到行动可能产生的道德后果。本文在因果模型框架下提出了两种条件的形式定义。我将我的方法与Braham和van Hees (BvH)以及Halpern和Kleiman-Weiner (HK)的现有方法进行了比较。然后我将我的定义推广为一种责任程度。

    As more and more decisions that have a significant ethical dimension are being outsourced to AI systems, it is important to have a definition of moral responsibility that can be applied to AI systems. Moral responsibility for an outcome of an agent who performs some action is commonly taken to involve both a causal condition and an epistemic condition: the action should cause the outcome, and the agent should have been aware -- in some form or other -- of the possible moral consequences of their action. This paper presents a formal definition of both conditions within the framework of causal models. I compare my approach to the existing approaches of Braham and van Hees (BvH) and of Halpern and Kleiman-Weiner (HK). I then generalize my definition into a degree of responsibility.
    
[^24]: 大型语言模型用于基于方面的情感分析

    Large language models for aspect-based sentiment analysis. (arXiv:2310.18025v1 [cs.CL])

    [http://arxiv.org/abs/2310.18025](http://arxiv.org/abs/2310.18025)

    该论文评估了GPT-4和GPT-3.5在基于方面的情感分析任务中的性能，并发现微调后的GPT-3.5在SemEval-2014任务4中取得了83.8的最先进F1分数，相比于InstructABSA提高了5.7%。但是，这需要1000倍的模型参数增加了推理成本。

    

    大型语言模型（LLMs）提供了前所未有的文本完成能力。作为通用模型，它们可以担任各种角色，包括更专门的模型。我们评估了GPT-4和GPT-3.5在基于方面的情感分析（ABSA）任务中的零-shot、少-shot和微调设置下的性能。微调后的GPT-3.5在SemEval-2014任务4的联合方面术语提取和极性分类任务上取得了83.8的最先进F1分数，相比于InstructABSA [Scaria等人，2023]提高了5.7％。然而，这是以1000倍更多的模型参数和因此增加的推理成本为代价的。我们讨论了不同模型的成本性能权衡，并分析了它们的典型错误。我们的结果还表明，在零-shot和少-shot设置中，详细提示可以提高性能，但对于微调模型来说并不是必要的。这些证据对于面临选择问题的实践者是相关的。

    Large language models (LLMs) offer unprecedented text completion capabilities. As general models, they can fulfill a wide range of roles, including those of more specialized models. We assess the performance of GPT-4 and GPT-3.5 in zero shot, few shot and fine-tuned settings on the aspect-based sentiment analysis (ABSA) task. Fine-tuned GPT-3.5 achieves a state-of-the-art F1 score of 83.8 on the joint aspect term extraction and polarity classification task of the SemEval-2014 Task 4, improving upon InstructABSA [@scaria_instructabsa_2023] by 5.7%. However, this comes at the price of 1000 times more model parameters and thus increased inference cost. We discuss the the cost-performance trade-offs of different models, and analyze the typical errors that they make. Our results also indicate that detailed prompts improve performance in zero-shot and few-shot settings but are not necessary for fine-tuned models. This evidence is relevant for practioners that are faced with the choice of pro
    
[^25]: FormalGeo：迈向人类级IMO水平几何自动推理的第一步

    FormalGeo: The First Step Toward Human-like IMO-level Geometric Automated Reasoning. (arXiv:2310.18021v1 [cs.AI])

    [http://arxiv.org/abs/2310.18021](http://arxiv.org/abs/2310.18021)

    FormalGeo是一种完整且兼容的正式平面几何系统，能够利用现代AI模型提供演绎推理解决方案，使AI能够像处理其他自然语言一样解决IMO级平面几何问题，证明可读、追溯和可验证。

    

    这是我们过去十年工作的第一篇文章。在这一系列论文中，我们构建了一个完整且兼容的正式平面几何系统。这将作为IMO级平面几何挑战与可读的AI自动推理之间的关键桥梁。有了这个正式系统，我们能够无缝地将现代AI模型与我们的正式系统集成在一起。在这个正式框架内，AI现在能够像处理其他自然语言一样对IMO级平面几何问题提供演绎推理解决方案，并且这些证明是可读的、可追溯的和可验证的。我们提出了几何形式化理论（GFT）来指导几何形式系统的发展。基于GFT，我们建立了FormalGeo，包括88个几何谓词和196个定理。它能够表示、验证和解决IMO级几何问题。我们还使用Python开发了FGPS（正式几何问题求解器）。

    This is the first article of our work over the past decade. In this series of papers, we have constructed a complete and compatible formal plane geometry system. This will serve as a crucial bridge between IMO-level plane geometry challenges and readable AI automated reasoning. With this formal system in place, we have been able to seamlessly integrate modern AI models with our formal system. Within this formal framework, AI is now capable of providing deductive reasoning solutions to IMO-level plane geometry problems, just like handling other natural languages, and these proofs are readable, traceable, and verifiable. We propose the geometry formalization theory (GFT) to guide the development of the geometry formal system. Based on the GFT, we have established the FormalGeo, which consists of 88 geometric predicates and 196 theorems. It can represent, validate, and solve IMO-level geometry problems. we also have crafted the FGPS (formal geometry problem solver) in Python. It serves as
    
[^26]: 深度学习实现亚衍射极限扫描超透镜显微镜大景深图像

    Deep Learning Enables Large Depth-of-Field Images for Sub-Diffraction-Limit Scanning Superlens Microscopy. (arXiv:2310.17997v1 [physics.optics])

    [http://arxiv.org/abs/2310.17997](http://arxiv.org/abs/2310.17997)

    本论文使用深度学习实现了亚衍射极限扫描超透镜显微镜，无需涂覆导电薄膜或真空环境，能够获得大景深图像，提高了图像转换效果。

    

    扫描电子显微镜（SEM）在微电子到食品加工等各种应用中不可或缺，因为它提供了超出光学衍射限制的大景深图像。然而，这项技术需要在绝缘体样品上涂覆导电薄膜，并且处于真空环境中。我们使用深度学习来获取光学超分辨率（OSR）图像与SEM域图像之间的映射关系，从而实现OSR图像转化为SEM样式的大景深图像。我们自建的扫描超透镜显微镜（SSUM）系统，无需在样品上涂覆导电薄膜，也不需要真空环境，用于获取具有特征尺寸约为80纳米的OSR图像。峰值信噪比（PSNR）和结构相似性指数测量值表明，深度学习方法在图像转换方面表现出色，其PSNR改善约为0.74 dB，优于光学超分辨率方法。

    Scanning electron microscopy (SEM) is indispensable in diverse applications ranging from microelectronics to food processing because it provides large depth-of-field images with a resolution beyond the optical diffraction limit. However, the technology requires coating conductive films on insulator samples and a vacuum environment. We use deep learning to obtain the mapping relationship between optical super-resolution (OSR) images and SEM domain images, which enables the transformation of OSR images into SEM-like large depth-of-field images. Our custom-built scanning superlens microscopy (SSUM) system, which requires neither coating samples by conductive films nor a vacuum environment, is used to acquire the OSR images with features down to ~80 nm. The peak signal-to-noise ratio (PSNR) and structural similarity index measure values indicate that the deep learning method performs excellently in image-to-image translation, with a PSNR improvement of about 0.74 dB over the optical super-
    
[^27]: 在具有动态障碍物的大规模环境中的自主3D探索

    Autonomous 3D Exploration in Large-Scale Environments with Dynamic Obstacles. (arXiv:2310.17977v1 [cs.RO])

    [http://arxiv.org/abs/2310.17977](http://arxiv.org/abs/2310.17977)

    提出了一种在具有动态障碍物的大规模环境中自主3D探索的方法，该方法不仅可以避免动态障碍物，还可以将其包含在规划中以利用动态环境优势，并且在动态和大规模环境中表现出更好的探索和避碰效果。

    

    在动态和不确定的现实环境中进行探索是机器人领域中的一个开放问题，也是自主系统在大多数现实世界中操作的基本能力。虽然3D探索规划已经得到广泛研究，但环境被假设为静态或仅执行反应性避碰。我们提出了一种新颖的方法，不仅可以避免动态障碍物，还可以将它们包含在计划中，以利用代理在动态环境中的优势。所提出的规划器，Dynamic Autonomous Exploration Planner (DAEP)，扩展了AEP，以明确地针对动态障碍物进行规划。为了全面评估这类环境中的探索规划器，我们提出了一个新的增强型基准套件，其中包括多个动态环境，包括大规模室外环境。DAEP在动态和大规模环境中胜过了最先进的规划器。 DAEP在探索和避碰方面都表现更加有效。

    Exploration in dynamic and uncertain real-world environments is an open problem in robotics and constitutes a foundational capability of autonomous systems operating in most of the real world. While 3D exploration planning has been extensively studied, the environments are assumed static or only reactive collision avoidance is carried out. We propose a novel approach to not only avoid dynamic obstacles but also include them in the plan itself, to exploit the dynamic environment in the agent's favor. The proposed planner, Dynamic Autonomous Exploration Planner (DAEP), extends AEP to explicitly plan with respect to dynamic obstacles. To thoroughly evaluate exploration planners in such settings we propose a new enhanced benchmark suite with several dynamic environments, including large-scale outdoor environments. DAEP outperform state-of-the-art planners in dynamic and large-scale environments. DAEP is shown to be more effective at both exploration and collision avoidance.
    
[^28]: 一次训练，获得一个家庭：离线到在线强化学习的状态自适应平衡

    Train Once, Get a Family: State-Adaptive Balances for Offline-to-Online Reinforcement Learning. (arXiv:2310.17966v1 [cs.LG])

    [http://arxiv.org/abs/2310.17966](http://arxiv.org/abs/2310.17966)

    在离线到在线强化学习中，现有解决方案往往只使用一种平衡策略，无法充分利用不同状态的数据质量。本论文提出了一种家族式离线到在线强化学习框架(FamO2O)，它通过训练一系列具有不同改进和约束强度的策略，实现了状态自适应的平衡。

    

    离线到在线强化学习是一种训练范式，它将预先收集的数据集上的预训练与在线环境中的微调相结合。然而，引入在线微调可能会加剧已知的分布偏移问题。现有的解决方案通过对离线和在线学习中的政策改进目标施加策略约束来解决这个问题。它们通常主张在不同的数据集上采用一种平衡政策改进和约束的通用方法。然而，这种一刀切的方式可能无法充分利用每个收集到的样本，因为不同状态的数据质量变化很大。为此，我们引入了家族离线到在线强化学习(FamO2O)，这是一个简单而有效的框架，能够赋予现有算法确定状态自适应改进-约束平衡的能力。FamO2O利用一个通用模型训练一个家族的策略，每个策略具有不同的改进/约束强度，和一个

    Offline-to-online reinforcement learning (RL) is a training paradigm that combines pre-training on a pre-collected dataset with fine-tuning in an online environment. However, the incorporation of online fine-tuning can intensify the well-known distributional shift problem. Existing solutions tackle this problem by imposing a policy constraint on the policy improvement objective in both offline and online learning. They typically advocate a single balance between policy improvement and constraints across diverse data collections. This one-size-fits-all manner may not optimally leverage each collected sample due to the significant variation in data quality across different states. To this end, we introduce Family Offline-to-Online RL (FamO2O), a simple yet effective framework that empowers existing algorithms to determine state-adaptive improvement-constraint balances. FamO2O utilizes a universal model to train a family of policies with different improvement/constraint intensities, and a
    
[^29]: 面向普遍医疗保健的中国大型视觉-语言模型Qilin-Med-VL

    Qilin-Med-VL: Towards Chinese Large Vision-Language Model for General Healthcare. (arXiv:2310.17956v1 [cs.CV])

    [http://arxiv.org/abs/2310.17956](http://arxiv.org/abs/2310.17956)

    Qilin-Med-VL是面向普遍医疗保健的中国大型视觉-语言模型，它结合了预训练的视觉Transformer和基础语言模型，通过两阶段课程训练过程提高了生成医疗标题和回答复杂医疗查询的能力，并发布了一个包含超过100万个图像-文本对的数据集ChiMed-VL。

    

    大型语言模型(LLMs)在理解复杂的医疗保健和生物医学主题方面取得了新的突破。然而，除了英语之外，其他语言的模型以及能够解释多模态输入的模型相对较少，而这对于全球医疗保健的可访问性至关重要。为此，本研究介绍了Qilin-Med-VL，这是第一个设计用于整合文本和视觉数据分析的中国大型视觉-语言模型。Qilin-Med-VL将经过预训练的视觉Transformer（ViT）与基础LLM相结合。它经历了一个深入的两阶段课程训练过程，其中包括特征对齐和指导调优。这种方法增强了模型生成医疗标题和回答复杂医疗查询的能力。我们还发布了ChiMed-VL，这是一个包含超过100万个图像-文本对的数据集。该数据集经过精心策划，可以使用各种类型的图像进行详细和全面的医学数据解释。

    Large Language Models (LLMs) have introduced a new era of proficiency in comprehending complex healthcare and biomedical topics. However, there is a noticeable lack of models in languages other than English and models that can interpret multi-modal input, which is crucial for global healthcare accessibility. In response, this study introduces Qilin-Med-VL, the first Chinese large vision-language model designed to integrate the analysis of textual and visual data. Qilin-Med-VL combines a pre-trained Vision Transformer (ViT) with a foundational LLM. It undergoes a thorough two-stage curriculum training process that includes feature alignment and instruction tuning. This method enhances the model's ability to generate medical captions and answer complex medical queries. We also release ChiMed-VL, a dataset consisting of more than 1M image-text pairs. This dataset has been carefully curated to enable detailed and comprehensive interpretation of medical data using various types of images.
    
[^30]: 通过极值理论理解参数敏感性

    Understanding Parameter Saliency via Extreme Value Theory. (arXiv:2310.17951v1 [cs.CV])

    [http://arxiv.org/abs/2310.17951](http://arxiv.org/abs/2310.17951)

    本文通过极值理论分析参数敏感性排名，旨在填补对参数敏感性排名如何找到导致错误识别的滤波器的理解的知识空白。

    

    近年来，深度神经网络在社会中越来越常见。在诊断不良模型行为时，识别哪些参数会触发错误分类是很有用的。本研究提出了参数敏感性的概念，并通过排名可能导致错误分类的卷积滤波器来诊断卷积神经网络(CNN)。研究还表明，对排名靠前的敏感滤波器进行微调可以有效纠正在ImageNet上的错误识别。然而，目前对于理解参数敏感性排名如何找到导致错误识别的滤波器仍存在知识差距。本研究试图通过从统计角度(极值理论)分析参数敏感性排名来弥补这一差距。我们首先展示了现有研究隐含地假设每个滤波器的梯度范数服从正态分布。然后，我们阐明了梯度范数与极值理论之间的关系。

    Deep neural networks are being increasingly implemented throughout society in recent years. It is useful to identify which parameters trigger misclassification in diagnosing undesirable model behaviors. The concept of parameter saliency is proposed and used to diagnose convolutional neural networks (CNNs) by ranking convolution filters that may have caused misclassification on the basis of parameter saliency. It is also shown that fine-tuning the top ranking salient filters has efficiently corrected misidentification on ImageNet. However, there is still a knowledge gap in terms of understanding why parameter saliency ranking can find the filters inducing misidentification. In this work, we attempt to bridge the gap by analyzing parameter saliency ranking from a statistical viewpoint, namely, extreme value theory. We first show that the existing work implicitly assumes that the gradient norm computed for each filter follows a normal distribution. Then, we clarify the relationship betwee
    
[^31]: 一种全面可靠的特征归因方法：双边删除和重构（DoRaR）

    A Comprehensive and Reliable Feature Attribution Method: Double-sided Remove and Reconstruct (DoRaR). (arXiv:2310.17945v1 [cs.LG])

    [http://arxiv.org/abs/2310.17945](http://arxiv.org/abs/2310.17945)

    双边删除和重构（DoRaR）是一种全面可靠的特征归因方法，用于解决深度神经网络和其他相关模型内部决策机制不透明的问题。

    

    深度神经网络（DNN）和其他机器学习（ML）模型内部决策机制的透明度有限，阻碍了它们在多个领域的应用。为了解决这个问题，已经开发出了特征归因方法，用于识别对这些黑盒模型的决策产生重要影响的关键特征。然而，许多特征归因方法存在固有的缺点。例如，一类特征归因方法存在伪影问题，这些方法直接通过原始训练在自然数据点上的分类器，对超出分布范围的屏蔽输入进行反馈。另一类特征归因方法通过使用联合训练的特征选择器和预测器来找到解释。虽然避免了伪影问题，但这个新类别的方法存在解释中的编码预测问题（EPITE），其中预测器的决策不依赖于特征，而是依赖于选择这些特征的遮罩。

    The limited transparency of the inner decision-making mechanism in deep neural networks (DNN) and other machine learning (ML) models has hindered their application in several domains. In order to tackle this issue, feature attribution methods have been developed to identify the crucial features that heavily influence decisions made by these black box models. However, many feature attribution methods have inherent downsides. For example, one category of feature attribution methods suffers from the artifacts problem, which feeds out-of-distribution masked inputs directly through the classifier that was originally trained on natural data points. Another category of feature attribution method finds explanations by using jointly trained feature selectors and predictors. While avoiding the artifacts problem, this new category suffers from the Encoding Prediction in the Explanation (EPITE) problem, in which the predictor's decisions rely not on the features, but on the masks that selects thos
    
[^32]: 统一的片段到片段框架用于同时序列生成

    Unified Segment-to-Segment Framework for Simultaneous Sequence Generation. (arXiv:2310.17940v1 [cs.CL])

    [http://arxiv.org/abs/2310.17940](http://arxiv.org/abs/2310.17940)

    这篇论文提出了一种统一的片段到片段框架 (Seg2Seg) 用于同时序列生成，通过自适应和统一的方式学习源序列和目标序列之间的映射，实现高质量生成和低延迟。

    

    同时序列生成是实时场景的关键任务，比如流式语音识别、同时机器翻译和同时语音翻译，其中目标序列在接收源序列的同时生成。实现高质量生成和低延迟的关键在于确定生成的最佳时机，通过学习源序列和目标序列之间的映射实现。然而，现有方法往往依赖于特定任务的启发式方法，限制了模型对源-目标映射的自适应学习能力，阻碍了多任务学习在各种同时任务中的探索。本文提出了一种统一的片段到片段框架 (Seg2Seg) 用于同时序列生成，以自适应和统一的方式学习映射。在同时生成的过程中，模型在等待源片段和生成目标片段之间交替进行。

    Simultaneous sequence generation is a pivotal task for real-time scenarios, such as streaming speech recognition, simultaneous machine translation and simultaneous speech translation, where the target sequence is generated while receiving the source sequence. The crux of achieving high-quality generation with low latency lies in identifying the optimal moments for generating, accomplished by learning a mapping between the source and target sequences. However, existing methods often rely on task-specific heuristics for different sequence types, limiting the model's capacity to adaptively learn the source-target mapping and hindering the exploration of multi-task learning for various simultaneous tasks. In this paper, we propose a unified segment-to-segment framework (Seg2Seg) for simultaneous sequence generation, which learns the mapping in an adaptive and unified manner. During the process of simultaneous generation, the model alternates between waiting for a source segment and generat
    
[^33]: Transformers作为图到图模型

    Transformers as Graph-to-Graph Models. (arXiv:2310.17936v1 [cs.CL])

    [http://arxiv.org/abs/2310.17936](http://arxiv.org/abs/2310.17936)

    本文认为Transformers本质上是图到图模型，通过将注意力权重等价于图中的边，并使用图到图Transformer架构结合显式图和潜在图进行非自回归图预测，实现了在建模各种语言结构方面的最先进准确性。

    

    我们认为Transformers本质上是图到图模型，而序列只是一种特殊情况。注意力权重在功能上等价于图中的边。我们的图到图Transformer架构将这种能力明确地体现出来，通过将图的边输入到注意力权重计算中，并使用类似注意力的函数来预测图的边，从而将显式图集成到预训练Transformers学习的潜在图中。添加迭代图细化可以为输入、输出和潜在图提供联合嵌入，使得非自回归图预测可以优化完整的图，而无需任何专门的管道或解码策略。实证结果表明，该架构在建模各种语言结构方面达到了最先进的准确性，并与预训练学习的潜在语言表示非常有效地集成。

    We argue that Transformers are essentially graph-to-graph models, with sequences just being a special case. Attention weights are functionally equivalent to graph edges. Our Graph-to-Graph Transformer architecture makes this ability explicit, by inputting graph edges into the attention weight computations and predicting graph edges with attention-like functions, thereby integrating explicit graphs into the latent graphs learned by pretrained Transformers. Adding iterative graph refinement provides a joint embedding of input, output, and latent graphs, allowing non-autoregressive graph prediction to optimise the complete graph without any bespoke pipeline or decoding strategy. Empirical results show that this architecture achieves state-of-the-art accuracies for modelling a variety of linguistic structures, integrating very effectively with the latent linguistic representations learned by pretraining.
    
[^34]: 知道LLMs不知道什么：一种简单而有效的自我检测方法

    Knowing What LLMs DO NOT Know: A Simple Yet Effective Self-Detection Method. (arXiv:2310.17918v1 [cs.CL])

    [http://arxiv.org/abs/2310.17918](http://arxiv.org/abs/2310.17918)

    本文提出了一种新的自我检测方法，用于判断大型语言模型 (LLMs) 无法回答的问题，以避免生成非事实性的回答。通过多样化问题的文本表达，收集答案，并检查生成的答案之间的差异，可以识别出可能生成虚假回答的问题。该方法只需要利用LLMs自身，无需其他外部资源。这种方法在Vicuna、ChatGPT和GPT-4等最新发布的LLMs上得到了有效验证。

    

    大型语言模型（LLMs）在自然语言处理（NLP）任务中展现出巨大的潜力。然而，最近的文献揭示了LLMs会偶尔生成非事实性的回答，这影响了它们进一步利用的可靠性。在本文中，我们提出了一种新颖的自我检测方法，用于检测LLMs不知道的问题，以避免生成非事实性的结果。具体来说，我们首先使给定问题的文本表达多样化，并收集相应的答案。然后，我们检查生成的答案之间的差异，以识别模型可能生成虚假回答的问题。所有以上步骤都可以通过提示LLMs自身来完成，而无需参考任何其他外部资源。我们进行了全面的实验，并证明了我们方法在最近发布的LLMs（如Vicuna、ChatGPT和GPT-4）上的有效性。

    Large Language Models (LLMs) have shown great potential in Natural Language Processing (NLP) tasks. However, recent literature reveals that LLMs generate nonfactual responses intermittently, which impedes the LLMs' reliability for further utilization. In this paper, we propose a novel self-detection method to detect which questions that a LLM does not know that are prone to generate nonfactual results. Specifically, we first diversify the textual expressions for a given question and collect the corresponding answers. Then we examine the divergencies between the generated answers to identify the questions that the model may generate falsehoods. All of the above steps can be accomplished by prompting the LLMs themselves without referring to any other external resources. We conduct comprehensive experiments and demonstrate the effectiveness of our method on recently released LLMs, e.g., Vicuna, ChatGPT, and GPT-4.
    
[^35]: 创新至职业本体论：将业务转型项目与职业和技能相连接。

    The Innovation-to-Occupations Ontology: Linking Business Transformation Initiatives to Occupations and Skills. (arXiv:2310.17909v1 [cs.AI])

    [http://arxiv.org/abs/2310.17909](http://arxiv.org/abs/2310.17909)

    本研究提出了一个创新的方法，通过本体论将业务转型项目与职业相连接，通过分析职位广告和维基百科页面中的信息，成功匹配了职业与转型项目，在指导企业和教育机构方面具有重要意义。

    

    新技术的快速采用迫使公司不断调整运营，越来越难以预测劳动力需求。几项最近的研究试图通过在线职位广告预测劳动力市场上新角色和技能的出现。本文旨在提出一种新颖的本体论，将业务转型项目与职业相连接，并通过利用从职位广告和维基百科页面中提取的嵌入来自动填充它。据我们所知，之前的研究没有明确将业务转型项目（如新技术的采用或进入新市场）与所需角色相连接。我们的方法在十个不同的场景下成功匹配了转型项目与职业，其中五个与技术采用有关，五个与业务相关。这一框架提供了一种创新的方法来指导企业和教育机构。

    The fast adoption of new technologies forces companies to continuously adapt their operations making it harder to predict workforce requirements. Several recent studies have attempted to predict the emergence of new roles and skills in the labour market from online job ads. This paper aims to present a novel ontology linking business transformation initiatives to occupations and an approach to automatically populating it by leveraging embeddings extracted from job ads and Wikipedia pages on business transformation and emerging technologies topics. To our knowledge, no previous research explicitly links business transformation initiatives, like the adoption of new technologies or the entry into new markets, to the roles needed. Our approach successfully matches occupations to transformation initiatives under ten different scenarios, five linked to technology adoption and five related to business. This framework presents an innovative approach to guide enterprises and educational institu
    
[^36]: 代码智能中的语言模型陷阱: 一份分类法与调查

    Pitfalls in Language Models for Code Intelligence: A Taxonomy and Survey. (arXiv:2310.17903v1 [cs.SE])

    [http://arxiv.org/abs/2310.17903](http://arxiv.org/abs/2310.17903)

    该论文介绍了面向代码智能的语言模型（LM4Code）可能遇到的陷阱，并提出了一个分类法，总结了67个主要研究，以促进构建更可靠的LM4Code。

    

    现代语言模型（LM）已成功应用于源代码生成和理解，从而大幅增加了对基于学习的代码智能（如自动错误修复和测试用例生成）的研究。尽管具有巨大潜力，但面向代码智能的语言模型（LM4Code）容易受到潜在陷阱的影响，这限制了实际性能，并进一步影响它们在现实世界中的可靠性和适用性。这些挑战驱动着对这些问题的全面理解——不仅要识别这些问题，还要深入研究其可能的影响以及现有解决方案，以构建更可靠的面向代码智能的语言模型。基于明确定义的系统化研究方法，我们进行了广泛的文献综述，揭示了LM4Code中固有的陷阱。最后，我们确定了来自顶级会议的67个主要研究。经过仔细研究这些研究，我们设计了一个分类法。

    Modern language models (LMs) have been successfully employed in source code generation and understanding, leading to a significant increase in research focused on learning-based code intelligence, such as automated bug repair, and test case generation. Despite their great potential, language models for code intelligence (LM4Code) are susceptible to potential pitfalls, which hinder realistic performance and further impact their reliability and applicability in real-world deployment. Such challenges drive the need for a comprehensive understanding - not just identifying these issues but delving into their possible implications and existing solutions to build more reliable language models tailored to code intelligence. Based on a well-defined systematic research approach, we conducted an extensive literature review to uncover the pitfalls inherent in LM4Code. Finally, 67 primary studies from top-tier venues have been identified. After carefully examining these studies, we designed a taxon
    
[^37]: 对表格数据查询和可视化的自然语言界面：一项调查

    Natural Language Interfaces for Tabular Data Querying and Visualization: A Survey. (arXiv:2310.17894v1 [cs.CL])

    [http://arxiv.org/abs/2310.17894](http://arxiv.org/abs/2310.17894)

    本调查对表格数据查询和可视化的自然语言界面进行了全面概述，介绍了语义解析等关键技术，并深入探讨了Text-to-SQL和Text-to-Vis问题的最新进展。

    

    自然语言处理的出现彻底改变了用户与表格数据的交互方式，实现了从传统的查询语言和手动绘图转向更直观、基于语言的界面。大型语言模型（LLM）如ChatGPT及其后继者进一步推动了这一领域的发展，为自然语言处理技术开辟了新的途径。本调查提供了关于表格数据查询和可视化的自然语言界面的全面概述，这些界面允许用户使用自然语言查询与数据进行交互。我们介绍了这些界面的基本概念和技术，特别强调语义解析，这是实现从自然语言到SQL查询或数据可视化命令转化的关键技术。然后从数据集、方法论、评估指标和系统设计的角度深入探讨了Text-to-SQL和Text-to-Vis问题的最新进展。

    The emergence of natural language processing has revolutionized the way users interact with tabular data, enabling a shift from traditional query languages and manual plotting to more intuitive, language-based interfaces. The rise of large language models (LLMs) such as ChatGPT and its successors has further advanced this field, opening new avenues for natural language processing techniques. This survey presents a comprehensive overview of natural language interfaces for tabular data querying and visualization, which allow users to interact with data using natural language queries. We introduce the fundamental concepts and techniques underlying these interfaces with a particular emphasis on semantic parsing, the key technology facilitating the translation from natural language to SQL queries or data visualization commands. We then delve into the recent advancements in Text-to-SQL and Text-to-Vis problems from the perspectives of datasets, methodologies, metrics, and system designs. Thi
    
[^38]: LLM能保守秘密吗？通过上下文完整性理论测试语言模型的隐私影响

    Can LLMs Keep a Secret? Testing Privacy Implications of Language Models via Contextual Integrity Theory. (arXiv:2310.17884v1 [cs.AI])

    [http://arxiv.org/abs/2310.17884](http://arxiv.org/abs/2310.17884)

    本研究通过提出ConfAIde基准，揭示了LLMs的上下文隐私推理能力中的重要弱点，实验证明即使是最强大的模型也会在人类不会的上下文中泄露私人信息，强调了探索新型推理时隐私保护方法的迫切需求。

    

    在AI助手（工作、家庭等）中交互使用大型语言模型（LLMs）引入了一系列新的推理时隐私风险：LLMs从多个来源的输入中获取不同类型的信息，并期望在给定的上下文中推理出在何种目的和与谁分享的内容。在这项工作中，我们通过提出ConfAIde，一个旨在识别指令调整的LLMs隐私推理能力中重要弱点的基准，来引起人们对上下文隐私这一极其关键但经常被忽视的概念的关注。我们的实验表明，即使是GPT-4和ChatGPT等最强大的模型，在人类不会的上下文中，也会泄露39％和57％的私人信息。即使我们使用保护隐私的提示或思维链推理，这种泄漏也会持续存在。我们的工作强调了迫切需要探索基于推理和理论的新型推理时隐私保护方法。

    The interactive use of large language models (LLMs) in AI assistants (at work, home, etc.) introduces a new set of inference-time privacy risks: LLMs are fed different types of information from multiple sources in their inputs and are expected to reason about what to share in their outputs, for what purpose and with whom, within a given context. In this work, we draw attention to the highly critical yet overlooked notion of contextual privacy by proposing ConfAIde, a benchmark designed to identify critical weaknesses in the privacy reasoning capabilities of instruction-tuned LLMs. Our experiments show that even the most capable models such as GPT-4 and ChatGPT reveal private information in contexts that humans would not, 39% and 57% of the time, respectively. This leakage persists even when we employ privacy-inducing prompts or chain-of-thought reasoning. Our work underscores the immediate need to explore novel inference-time privacy-preserving approaches, based on reasoning and theory
    
[^39]: ASPIRO: 一种适用于零到少样本情况下结构化数据到文本生成的错误感知重提示方法

    ASPIRO: Any-shot Structured Parsing-error-Induced ReprOmpting for Consistent Data-to-Text Generation. (arXiv:2310.17877v1 [cs.CL])

    [http://arxiv.org/abs/2310.17877](http://arxiv.org/abs/2310.17877)

    ASPIRO是一种能在零到少样本情况下将结构化数据转化为简短模板句子的方法。通过算法解析检查、LLM的重新提示以及一致性验证指标PARENT，ASPIRO成功降低了66%的解析错误率，并且在与最近的预训练语言模型的竞争中表现出色。

    

    我们提出了ASPIRO，一种在零到少样本情况下将结构化数据转化为简短模板句子的方法。与之前的方法不同，我们的方法直接提示大型语言模型（LLM）产生与实体无关的模板，而不是依赖LLM忠实地复制给定的实体，或者手动验证/制作模板。我们通过算法解析检查和PARENT指标诱导的一致性验证，结合LLM的重新提示，实时识别和纠正模板生成问题。在DART数据集上，与直接LLM输出相比，ASPIRO对RDF三元组的生成文本的解析错误率平均降低了66％。我们在Rel2Text数据集上的最佳5样本text-davinci-003设置评分为BLEU 50.62，METEOR 45.16，BLEURT 0.82，NUBIA 0.87和PARENT 0.8962，与最近的精调预训练语言模型有了有效的竞争力。

    We present ASPIRO, an approach for structured data verbalisation into short template sentences in zero to few-shot settings. Unlike previous methods, our approach prompts large language models (LLMs) to directly produce entity-agnostic templates, rather than relying on LLMs to faithfully copy the given example entities, or validating/crafting the templates manually. We incorporate LLM re-prompting, triggered by algorithmic parsing checks, as well as the PARENT metric induced consistency validation to identify and rectify template generation problems in real-time. ASPIRO, compared to direct LLM output, averages 66\% parsing error rate reduction in generated verbalisations of RDF triples on the DART dataset. Our best 5-shot text-davinci-003 setup, scoring BLEU of 50.62, METEOR of 45.16, BLEURT of 0.82, NUBIA of 0.87, and PARENT of 0.8962 on the Rel2Text dataset, competes effectively with recent fine-tuned pre-trained language models.
    
[^40]: 带有槽约束的排名问题

    Ranking with Slot Constraints. (arXiv:2310.17870v1 [cs.IR])

    [http://arxiv.org/abs/2310.17870](http://arxiv.org/abs/2310.17870)

    带有槽约束的排名问题中，我们提出了一种新的排名算法MatchRank，它在候选人按排名顺序被人类决策者评估时，产生最大化填充槽位的排名。算法在理论上具有强大的逼近保证，并且可以高效实现。 (arXiv:2310.17870v1 [cs.IR])

    

    我们引入了带有槽约束的排名问题，这可以用来建模各种应用问题 - 从具有不同专业限制槽位的大学录取，到在医学试验中构建符合条件的参与者分层队列。我们发现，传统的概率排名原则（PRP）在带有槽约束的排名问题中可能会非常次优，因此我们提出了一种新的排名算法，称为MatchRank。MatchRank的目标是在候选人按排名顺序由人类决策者进行评估时，产生最大化填充槽位的排名。这样，MatchRank在广义上是PRP的推广，当没有槽约束时，它是PRP的特例。我们的理论分析表明，MatchRank具有强大的逼近保证，没有任何槽位或候选人之间的独立性假设。此外，我们展示了如何高效地实现MatchRank。除了理论保证外，我们还展示了MatchRank的实验结果在不同应用领域的有效性。

    We introduce the problem of ranking with slot constraints, which can be used to model a wide range of application problems -- from college admission with limited slots for different majors, to composing a stratified cohort of eligible participants in a medical trial. We show that the conventional Probability Ranking Principle (PRP) can be highly sub-optimal for slot-constrained ranking problems, and we devise a new ranking algorithm, called MatchRank. The goal of MatchRank is to produce rankings that maximize the number of filled slots if candidates are evaluated by a human decision maker in the order of the ranking. In this way, MatchRank generalizes the PRP, and it subsumes the PRP as a special case when there are no slot constraints. Our theoretical analysis shows that MatchRank has a strong approximation guarantee without any independence assumptions between slots or candidates. Furthermore, we show how MatchRank can be implemented efficiently. Beyond the theoretical guarantees, em
    
[^41]: 多实例学习中的可重现性: 算法单元测试的案例

    Reproducibility in Multiple Instance Learning: A Case For Algorithmic Unit Tests. (arXiv:2310.17867v1 [stat.ML])

    [http://arxiv.org/abs/2310.17867](http://arxiv.org/abs/2310.17867)

    多实例学习中的五个深度模型在学习过程中违反了标准的MIL假设，导致能够学习反相关的实例。这一问题需要通过改进和其他策略来解决。

    

    多实例学习(MIL)是分类问题的一个子领域，其中有正负标签和一个输入的“包”，当且仅当包中包含一个正元素时，标签为正，否则为负。在这种情况下，训练需要将包级标签与实例级信息关联起来，并隐含着一个因果假设和任务的不对称性（即，无法交换标签而不改变语义）。MIL问题出现在医疗保健（一个恶性细胞表示癌症），网络安全（一个恶意可执行文件会感染计算机）等许多任务中。在这项工作中，我们检查了最著名的五个深度MIL模型，并发现它们都不符合标准的MIL假设。它们能够学习反相关的实例，即在看到负的反例之前默认为“正”标签，这对于一个正确的MIL模型来说是不可能的。我们怀疑改进和其他策略可能会改善这一问题。

    Multiple Instance Learning (MIL) is a sub-domain of classification problems with positive and negative labels and a "bag" of inputs, where the label is positive if and only if a positive element is contained within the bag, and otherwise is negative. Training in this context requires associating the bag-wide label to instance-level information, and implicitly contains a causal assumption and asymmetry to the task (i.e., you can't swap the labels without changing the semantics). MIL problems occur in healthcare (one malignant cell indicates cancer), cyber security (one malicious executable makes an infected computer), and many other tasks. In this work, we examine five of the most prominent deep-MIL models and find that none of them respects the standard MIL assumption. They are able to learn anti-correlated instances, i.e., defaulting to "positive" labels until seeing a negative counter-example, which should not be possible for a correct MIL model. We suspect that enhancements and othe
    
[^42]: 函数空间贝叶斯伪核心集用于贝叶斯神经网络

    Function Space Bayesian Pseudocoreset for Bayesian Neural Networks. (arXiv:2310.17852v1 [cs.LG])

    [http://arxiv.org/abs/2310.17852](http://arxiv.org/abs/2310.17852)

    本论文提出了一种在函数空间上操作的新颖贝叶斯伪核心集构建方法，通过构建核心集后验的变分近似并在函数空间中将其与完整数据后验匹配，实现了对深度神经网络等高维模型的贝叶斯推断的可扩展性。

    

    贝叶斯伪核心集是一个紧凑的合成数据集，总结了大规模数据集的基本信息，因此可以作为可扩展贝叶斯推断的代理数据集。通常，通过最小化伪核心集后验条件和完整数据集后验条件之间的差异度量来构建贝叶斯伪核心集。然而，评估差异度量可能具有挑战性，尤其是对于具有高维参数的深度神经网络等模型。在本文中，我们提出了一种在函数空间上操作的新颖贝叶斯伪核心集构建方法。与以往的方法不同，以模型参数（权重）的空间构建和匹配核心集和完整数据后验，我们的方法在函数空间上构建核心集后验的变分近似，并在函数空间中将其与完整数据后验匹配。通过直接在函数空间中工作，我们的方法可以绕过一些计算和评估的困难。

    A Bayesian pseudocoreset is a compact synthetic dataset summarizing essential information of a large-scale dataset and thus can be used as a proxy dataset for scalable Bayesian inference. Typically, a Bayesian pseudocoreset is constructed by minimizing a divergence measure between the posterior conditioning on the pseudocoreset and the posterior conditioning on the full dataset. However, evaluating the divergence can be challenging, particularly for the models like deep neural networks having high-dimensional parameters. In this paper, we propose a novel Bayesian pseudocoreset construction method that operates on a function space. Unlike previous methods, which construct and match the coreset and full data posteriors in the space of model parameters (weights), our method constructs variational approximations to the coreset posterior on a function space and matches it to the full data posterior in the function space. By working directly on the function space, our method could bypass sev
    
[^43]: 通过大型语言模型在已绑定模型上实时生成和控制动画

    Real-time Animation Generation and Control on Rigged Models via Large Language Models. (arXiv:2310.17838v1 [cs.GR])

    [http://arxiv.org/abs/2310.17838](http://arxiv.org/abs/2310.17838)

    该论文介绍了一种利用大型语言模型实现在已绑定模型上实时进行动画控制和生成的方法，并展示了该方法的灵活性和鲁棒性。

    

    我们介绍了一种新的方法，使用自然语言输入在已绑定模型上进行实时动画控制和生成。首先，我们在Unity中嵌入了一个大型语言模型（LLM），用于输出可以解析为多样且逼真的动画的结构化文本。其次，我们展示了LLM实现现有动画之间灵活状态转换的潜力。我们通过在各种绑定模型和动作上展示定性结果，展示了我们方法的鲁棒性。

    We introduce a novel method for real-time animation control and generation on rigged models using natural language input. First, we embed a large language model (LLM) in Unity to output structured texts that can be parsed into diverse and realistic animations. Second, we illustrate LLM's potential to enable flexible state transition between existing animations. We showcase the robustness of our approach through qualitative results on various rigged models and motions.
    
[^44]: 一种风格统一生成视频的方法

    One Style is All you Need to Generate a Video. (arXiv:2310.17835v1 [cs.CV])

    [http://arxiv.org/abs/2310.17835](http://arxiv.org/abs/2310.17835)

    本文提出了一种基于风格的条件视频生成模型，通过学习各种动作的动态表示，实现了独立操作和转移视频动作的能力，同时显著提高了视频质量。

    

    本文提出了一种基于风格的条件视频生成模型。我们引入了一组学习到的正弦基的新颖时间生成器。我们的方法学习了与图像内容无关并可以在不同演员之间转移的各种动作的动态表示。除了与普遍方法相比显著提高视频质量外，我们还证明了解耦的动态和内容使它们可以独立操作，以及通过时序GAN反演从一个内容或身份中提取和转移视频动作而无需进一步的预处理，如特征点。

    In this paper, we propose a style-based conditional video generative model. We introduce a novel temporal generator based on a set of learned sinusoidal bases. Our method learns dynamic representations of various actions that are independent of image content and can be transferred between different actors. Beyond the significant enhancement of video quality compared to prevalent methods, we demonstrate that the disentangled dynamic and content permit their independent manipulation, as well as temporal GAN-inversion to retrieve and transfer a video motion from one content or identity to another without further preprocessing such as landmark points.
    
[^45]: Bayesian成像逆问题中的SA-Roundtrip先验及HMC-pCN采样器

    Bayesian imaging inverse problem with SA-Roundtrip prior via HMC-pCN sampler. (arXiv:2310.17817v1 [stat.ML])

    [http://arxiv.org/abs/2310.17817](http://arxiv.org/abs/2310.17817)

    本文提出了一种新型的深度生成先验，SA-Roundtrip，可以进行可控的采样生成，并识别数据的内在维度。基于该先验，结合Hamiltonian Monte Carlo算法，解决了贝叶斯成像逆问题，在计算机断层扫描重建任务上超过了最先进的对比算法。

    

    贝叶斯推断与深度生成先验在许多科学和工程领域的成像逆问题求解中受到了广泛关注。先验分布的选择是从可用先验测量中学习的，因此是关于可用先验测量的重要表示学习。引入了一种新颖的深度生成先验SA-Roundtrip，以实现可控的采样生成，并识别出数据的内在维度。该先验在双向生成对抗网络中嵌入了自注意力结构。随后，将贝叶斯推断应用于低维潜在空间中的后验分布，使用具有预条件Crank-Nicolson算法的Hamiltonian Monte Carlo (HMC-pCN)。该算法在特定条件下被证明具有遍历性。对MNIST和TomoPhantom数据集进行的计算机断层扫描重建实验表明，该方法优于最先进的对比算法。

    Bayesian inference with deep generative prior has received considerable interest for solving imaging inverse problems in many scientific and engineering fields. The selection of the prior distribution is learned from, and therefore an important representation learning of, available prior measurements. The SA-Roundtrip, a novel deep generative prior, is introduced to enable controlled sampling generation and identify the data's intrinsic dimension. This prior incorporates a self-attention structure within a bidirectional generative adversarial network. Subsequently, Bayesian inference is applied to the posterior distribution in the low-dimensional latent space using the Hamiltonian Monte Carlo with preconditioned Crank-Nicolson (HMC-pCN) algorithm, which is proven to be ergodic under specific conditions. Experiments conducted on computed tomography (CT) reconstruction with the MNIST and TomoPhantom datasets reveal that the proposed method outperforms state-of-the-art comparisons, consis
    
[^46]: 使用RadGraph和少样本提示的风格感知放射学报告生成

    Style-Aware Radiology Report Generation with RadGraph and Few-Shot Prompting. (arXiv:2310.17811v1 [cs.AI])

    [http://arxiv.org/abs/2310.17811](http://arxiv.org/abs/2310.17811)

    该论文提出了一种使用RadGraph和少样本提示的风格感知放射学报告生成的方法。通过将报告的内容和风格分开处理，可以避免生成临床不准确的报告。定量评估和人工评估结果均表明该方法表现出良好的性能，并生成与个体放射科医生风格完全相同的报告。

    

    自动从医学影像中生成报告有望改善放射科医生的工作流程。现有方法通过直接从图像生成完整的报告来考虑图像到报告的建模任务。然而，这样混淆了报告的内容（如发现和其属性）与其风格（如格式和词汇选择），可能导致临床不准确的报告。为了解决这个问题，我们提出了一种放射学报告生成的两步方法。首先，我们从图像中提取内容，然后将提取的内容转化为与特定放射科医生风格相匹配的报告。为此，我们利用RadGraph——一种报告的图表示——以及大型语言模型（LLM）。在定量评估中，我们发现我们的方法在性能方面具有益处。通过临床评估者进行的人工评估表明，AI生成的报告与个体放射科医生的风格完全相同，无法区别。

    Automatically generated reports from medical images promise to improve the workflow of radiologists. Existing methods consider an image-to-report modeling task by directly generating a fully-fledged report from an image. However, this conflates the content of the report (e.g., findings and their attributes) with its style (e.g., format and choice of words), which can lead to clinically inaccurate reports. To address this, we propose a two-step approach for radiology report generation. First, we extract the content from an image; then, we verbalize the extracted content into a report that matches the style of a specific radiologist. For this, we leverage RadGraph -- a graph representation of reports -- together with large language models (LLMs). In our quantitative evaluations, we find that our approach leads to beneficial performance. Our human evaluation with clinical raters highlights that the AI-generated reports are indistinguishably tailored to the style of individual radiologist 
    
[^47]: Clover: 闭环可验证代码生成

    Clover: Closed-Loop Verifiable Code Generation. (arXiv:2310.17807v1 [cs.SE])

    [http://arxiv.org/abs/2310.17807](http://arxiv.org/abs/2310.17807)

    Clover是一种闭环可验证代码生成的范式，通过在代码、docstrings和形式注释之间进行一致性检查，确保生成的代码的正确性。

    

    在软件开发中，使用大型语言模型进行代码生成是一个快速增长的趋势。然而，如果没有有效的方法来确保生成的代码的正确性，这个趋势可能会导致许多不良结果。在本文中，我们提出了一个解决这个挑战的愿景：Clover范式，即闭环可验证代码生成，它将正确性检查简化为更可访问的一致性检查问题。在Clover的核心是一个检查器，它在代码、docstrings和形式注释之间进行一致性检查。该检查器使用了形式验证工具和大型语言模型的新颖集成实现。我们提供了理论分析来支持我们的论点，即Clover在一致性检查方面应该是有效的。我们还在一个由手工设计的数据集（CloverBench）上进行了实证调查，该数据集包含了注释的Dafny程序，难度水平与教科书相当。实验结果显示

    The use of large language models for code generation is a rapidly growing trend in software development. However, without effective methods for ensuring the correctness of generated code, this trend could lead to any number of undesirable outcomes. In this paper, we lay out a vision for addressing this challenge: the Clover paradigm, short for Closed-Loop Verifiable Code Generation, which reduces correctness checking to the more accessible problem of consistency checking. At the core of Clover lies a checker that performs consistency checks among code, docstrings, and formal annotations. The checker is implemented using a novel integration of formal verification tools and large language models. We provide a theoretical analysis to support our thesis that Clover should be effective at consistency checking. We also empirically investigate its feasibility on a hand-designed dataset (CloverBench) featuring annotated Dafny programs at a textbook level of difficulty. Experimental results sho
    
[^48]: 通过DreamerV3技巧提高PPO的奖励规模鲁棒性

    Reward Scale Robustness for Proximal Policy Optimization via DreamerV3 Tricks. (arXiv:2310.17805v1 [cs.LG])

    [http://arxiv.org/abs/2310.17805](http://arxiv.org/abs/2310.17805)

    本研究将DreamerV3的技巧应用到PPO中，并发现这些技巧并不能普遍改善PPO的性能。通过大量的消融研究，我们确定了一些情况下这些技巧的成功，并对它们的关系提供了深入洞察。

    

    大多数强化学习方法依赖于密集、规范化的环境奖励。DreamerV3最近引入了一种基于模型的方法，并采用了一些技巧来减轻这些限制，使用一组超参数在广泛的基准测试中实现了最新的状态。这个结果引发了关于这些技巧的普适性的讨论，因为它们似乎适用于其他强化学习算法。我们的工作将DreamerV3的技巧应用到PPO中，这是第一次在原始工作之外进行这样的实证研究。令人惊讶的是，我们发现这些技巧并不能作为一般的改进转移到PPO上。我们使用了高质量的PPO参考实现，并在Arcade Learning Environment和DeepMind Control Suite上进行了长达10,000个A100小时的大量消融研究。虽然我们的实验表明这些技巧并没有普遍超过PPO，但我们确定了它们成功的情况，并对它们的关系提供了深入洞察。

    Most reinforcement learning methods rely heavily on dense, well-normalized environment rewards. DreamerV3 recently introduced a model-based method with a number of tricks that mitigate these limitations, achieving state-of-the-art on a wide range of benchmarks with a single set of hyperparameters. This result sparked discussion about the generality of the tricks, since they appear to be applicable to other reinforcement learning algorithms. Our work applies DreamerV3's tricks to PPO and is the first such empirical study outside of the original work. Surprisingly, we find that the tricks presented do not transfer as general improvements to PPO. We use a high quality PPO reference implementation and present extensive ablation studies totaling over 10,000 A100 hours on the Arcade Learning Environment and the DeepMind Control Suite. Though our experiments demonstrate that these tricks do not generally outperform PPO, we identify cases where they succeed and offer insight into the relations
    
[^49]: "您是一位专家语言注释者"：作为抽象意义表示分析器的LLMs的限制

    "You Are An Expert Linguistic Annotator": Limits of LLMs as Analyzers of Abstract Meaning Representation. (arXiv:2310.17793v1 [cs.CL])

    [http://arxiv.org/abs/2310.17793](http://arxiv.org/abs/2310.17793)

    本文研究了大型语言模型在分析句子的意义结构方面的成功和限制，发现模型在生成和重构抽象意义表示（AMR）方面表现出一定的能力，但在复杂的句子结构或语义推理任务中存在局限性。

    

    大型语言模型（LLMs）在语言使用方面显示出了令人惊讶的熟练度和流畅性。这是否意味着它们也已经获得了关于语言的深刻语言知识，以至于它们可以充当"专家语言注释者"？在本文中，我们考察了GPT-3、ChatGPT和GPT-4模型在句子意义结构分析中的成功和限制，重点关注了抽象意义表示（AMR；Banarescu等人，2013）分析形式主义，该形式主义提供了丰富的图形化句子意义结构表示，同时从表面形式中抽象出来。我们将模型在这种语义结构分析上的结果在两种情况下进行比较：1）基于零射和少学样本的AMR解析的直接生成，以及2）通过元语言自然语言查询（例如"确定该句子的主要事件，以及与该事件对应的谓词"）间接的部分重构AMR。在这些情况下，我们发现模型能够重新生成正确的AMR解析，但在复杂的句子结构或语义推理任务中仍存在局限性。

    Large language models (LLMs) show amazing proficiency and fluency in the use of language. Does this mean that they have also acquired insightful linguistic knowledge about the language, to an extent that they can serve as an "expert linguistic annotator"? In this paper, we examine the successes and limitations of the GPT-3, ChatGPT, and GPT-4 models in analysis of sentence meaning structure, focusing on the Abstract Meaning Representation (AMR; Banarescu et al. 2013) parsing formalism, which provides rich graphical representations of sentence meaning structure while abstracting away from surface forms. We compare models' analysis of this semantic structure across two settings: 1) direct production of AMR parses based on zero- and few-shot prompts, and 2) indirect partial reconstruction of AMR via metalinguistic natural language queries (e.g., "Identify the primary event of this sentence, and the predicate corresponding to that event."). Across these settings, we find that models can re
    
[^50]: 利用语言模型进行能量负荷预测

    Utilizing Language Models for Energy Load Forecasting. (arXiv:2310.17788v1 [cs.AI])

    [http://arxiv.org/abs/2310.17788](http://arxiv.org/abs/2310.17788)

    本文提出了一种利用语言模型进行能量负荷预测的新方法，通过采用提示技术和自回归生成方法，可以将能源消耗数据转化为描述性语句并实现预测未来能量负荷消耗的准确性，从而为提高能源效率和促进能源系统智能决策提供了有希望的途径。

    

    能量负荷预测在优化资源分配和管理建筑物和城市的能源消耗方面发挥着关键作用。本文提出了一种利用语言模型进行能量负荷预测的新方法。我们采用提示技术将能源消耗数据转化为描述性语句，从而实现语言模型的微调。通过采用自回归生成方法，我们的方法能够预测未来能量负荷消耗的各种时间范围。通过对真实数据集进行广泛实验，我们证明了我们的方法的有效性和准确性。我们的结果表明，利用语言模型进行能量负荷预测有望增强能源效率并促进能源系统智能决策的实施。

    Energy load forecasting plays a crucial role in optimizing resource allocation and managing energy consumption in buildings and cities. In this paper, we propose a novel approach that leverages language models for energy load forecasting. We employ prompting techniques to convert energy consumption data into descriptive sentences, enabling fine-tuning of language models. By adopting an autoregressive generating approach, our proposed method enables predictions of various horizons of future energy load consumption. Through extensive experiments on real-world datasets, we demonstrate the effectiveness and accuracy of our proposed method. Our results indicate that utilizing language models for energy load forecasting holds promise for enhancing energy efficiency and facilitating intelligent decision-making in energy systems.
    
[^51]: 评估使用印度语LGBTI+词汇表的大型语言模型

    Evaluation of large language models using an Indian language LGBTI+ lexicon. (arXiv:2310.17787v1 [cs.CL])

    [http://arxiv.org/abs/2310.17787](http://arxiv.org/abs/2310.17787)

    该论文提出了一种使用印度语LGBTI+词汇表评估大型语言模型的方法。研究发现，现有的语言模型无法有效检测潜藏的仇恨内容，使用机器翻译作为评估手段也存在局限性。

    

    大型语言模型（LLMs）通常通过基于任务的基准（如MMLU）进行评估。这样的基准无法在特定语境中检查LLMs的负责任行为。在LGBTI+语境中，社会陈规可能导致LGBTI+术语的变异。因此，领域特定的词汇表可以作为对LLM行为进行评估的代表性单词列表。本文提出了一种使用印度语LGBTI+词汇表评估LLMs的方法。该方法包括四个步骤：制定与预期行为相关的NLP任务，创建测试LLMs的提示，使用LLMs获取输出，最后进行手动评估结果。我们的定性分析显示，我们实验的三个LLMs无法检测到潜在的仇恨内容。同样，我们观察到使用机器翻译作为评估自然语言的手段存在局限性。

    Large language models (LLMs) are typically evaluated on the basis of task-based benchmarks such as MMLU. Such benchmarks do not examine responsible behaviour of LLMs in specific contexts. This is particularly true in the LGBTI+ context where social stereotypes may result in variation in LGBTI+ terminology. Therefore, domain-specific lexicons or dictionaries may be useful as a representative list of words against which the LLM's behaviour needs to be evaluated. This paper presents a methodology for evaluation of LLMs using an LGBTI+ lexicon in Indian languages. The methodology consists of four steps: formulating NLP tasks relevant to the expected behaviour, creating prompts that test LLMs, using the LLMs to obtain the output and, finally, manually evaluating the results. Our qualitative analysis shows that the three LLMs we experiment on are unable to detect underlying hateful content. Similarly, we observe limitations in using machine translation as means to evaluate natural language u
    
[^52]: 数据中心化的金融大型语言模型

    Data-Centric Financial Large Language Models. (arXiv:2310.17784v1 [cs.CL])

    [http://arxiv.org/abs/2310.17784](http://arxiv.org/abs/2310.17784)

    本文介绍了一种数据中心化的方法，通过预处理和预理解数据来改善大型语言模型（LLMs）在金融任务中的性能。实验证明，采用该方法的金融LLMs在金融分析和解释任务上达到了最先进的水平。

    

    大型语言模型（LLMs）在自然语言任务中表现出良好的潜力，但直接应用于复杂领域如金融时却遇到困难。LLMs难以推理和整合所有相关信息。我们提出了一种数据中心化的方法，使LLMs能够更好地处理金融任务。我们的关键观点是，不是一次性给LLM负载过多信息，而是更有效地对数据进行预处理和预理解。我们使用多任务基于提示的微调来创建金融LLM（FLLM），以实现数据预处理和预理解。然而，每个任务的标记数据有限。为了克服手动注释的成本，我们采用了自动生成训练数据的增强推理（AAR）来修改FLLM自身输出的伪标签。实验证明，我们的数据中心化FLLM与AAR相比，显著优于为原始文本设计的基线金融LLMs，在金融分析和解释任务上达到了最先进的水平。

    Large language models (LLMs) show promise for natural language tasks but struggle when applied directly to complex domains like finance. LLMs have difficulty reasoning about and integrating all relevant information. We propose a data-centric approach to enable LLMs to better handle financial tasks. Our key insight is that rather than overloading the LLM with everything at once, it is more effective to preprocess and pre-understand the data. We create a financial LLM (FLLM) using multitask prompt-based finetuning to achieve data pre-processing and pre-understanding. However, labeled data is scarce for each task. To overcome manual annotation costs, we employ abductive augmentation reasoning (AAR) to automatically generate training data by modifying the pseudo labels from FLLM's own outputs. Experiments show our data-centric FLLM with AAR substantially outperforms baseline financial LLMs designed for raw text, achieving state-of-the-art on financial analysis and interpretation tasks. We 
    
[^53]: 复杂交通情景分类的图卷积网络

    Graph Convolutional Networks for Complex Traffic Scenario Classification. (arXiv:2310.17773v1 [cs.CV])

    [http://arxiv.org/abs/2310.17773](http://arxiv.org/abs/2310.17773)

    该论文提出了一种复杂交通情景分类方法，能够模拟车辆与环境以及其他参与者的互动，并使用图卷积网络对这些情景的空间和时间特征进行建模。

    

    基于场景的测试方法可以减少获取自动驾驶系统安全性的统计显著证据所需的时间。自动化识别这些情景是一项具有挑战性的任务。大多数情景分类方法在复杂情景（高速公路，城市）和与其他交通参与者的互动方面效果不佳。现有方法模拟了车辆与其环境的关系，但忽略了多辆车之间的互动（例如，插入切换，静止前车）。此外，现有数据集缺乏多样性，并且没有每帧注释来准确学习情景的开始和结束时间。我们提出一种能够模拟车辆与环境以及其他参与者互动的复杂交通情景分类方法。我们使用图卷积网络来模拟这些情景的空间和时间特征。扩展t

    A scenario-based testing approach can reduce the time required to obtain statistically significant evidence of the safety of Automated Driving Systems (ADS). Identifying these scenarios in an automated manner is a challenging task. Most methods on scenario classification do not work for complex scenarios with diverse environments (highways, urban) and interaction with other traffic agents. This is mirrored in their approaches which model an individual vehicle in relation to its environment, but neglect the interaction between multiple vehicles (e.g. cut-ins, stationary lead vehicle). Furthermore, existing datasets lack diversity and do not have per-frame annotations to accurately learn the start and end time of a scenario. We propose a method for complex traffic scenario classification that is able to model the interaction of a vehicle with the environment, as well as other agents. We use Graph Convolutional Networks to model spatial and temporal aspects of these scenarios. Expanding t
    
[^54]: GROOViST:一种用于视觉故事中物体定位评估的度量标准

    GROOViST: A Metric for Grounding Objects in Visual Storytelling. (arXiv:2310.17770v1 [cs.AI])

    [http://arxiv.org/abs/2310.17770](http://arxiv.org/abs/2310.17770)

    GROOViST是一种用于评估视觉故事中物体定位的新的评估工具，考虑了跨模态依赖、时间错位和人类对视觉定位的直觉。这种工具具有模块化设计，可以评估和解释每个组件的贡献。

    

    对于一个由一系列图像生成的故事的适当评估，必须考虑多个方面，例如连贯性，语法正确性和视觉定位。在这项工作中，我们专注于评估定位程度，即故事与图像中显示的实体相关程度。我们分析了当前的评估指标，包括针对此目的设计的指标和针对一般视觉-文本对齐的指标。鉴于它们存在的缺点，我们提出了一种新的评估工具GROOViST，该工具考虑了跨模态依赖，时间错位（故事中实体出现的顺序和图像序列可能不匹配）以及人类对视觉定位的直觉。GROOViST的另一个优点是其模块化设计，可以对每个组件的贡献进行评估和解释。

    A proper evaluation of stories generated for a sequence of images -- the task commonly referred to as visual storytelling -- must consider multiple aspects, such as coherence, grammatical correctness, and visual grounding. In this work, we focus on evaluating the degree of grounding, that is, the extent to which a story is about the entities shown in the images. We analyze current metrics, both designed for this purpose and for general vision-text alignment. Given their observed shortcomings, we propose a novel evaluation tool, GROOViST, that accounts for cross-modal dependencies, temporal misalignments (the fact that the order in which entities appear in the story and the image sequence may not match), and human intuitions on visual grounding. An additional advantage of GROOViST is its modular design, where the contribution of each component can be assessed and interpreted individually.
    
[^55]: 社会契约AI：将AI助手与隐含的群体规范对齐

    Social Contract AI: Aligning AI Assistants with Implicit Group Norms. (arXiv:2310.17769v1 [cs.CL])

    [http://arxiv.org/abs/2310.17769](http://arxiv.org/abs/2310.17769)

    这项研究探索了通过将机器学习模型应用于用户交互数据，使AI助手能够自动对齐用户偏好的方法。研究发现，虽然AI助手在模拟中能够准确对齐经济文献中的标准策略，但在面对未知货币以及语言与策略一致性不足的情况下，其学习能力受到限制。

    

    我们探索了通过反转模拟用户（未知）偏好的模型来对齐AI助手的思路。为了验证我们的提议，我们在经济报价游戏中进行了概念验证模拟，将用户偏好形式化为指导模拟玩家行为的策略。我们发现，AI助手能够准确地将其行为与经济文献中的标准策略（如自私的、利他的）相匹配。然而，助手学到的策略在面对未包含在训练分布中的货币（如药品克数）时缺乏鲁棒性和有限的泛化能力。此外，我们发现，当语言使用与未知策略之间存在一致性不足时（如利他策略与粗鲁语言相结合），助手学习到的策略会减慢。总体而言，我们初步的结果表明，开发模拟框架来对齐AI助手的行为是可行的。

    We explore the idea of aligning an AI assistant by inverting a model of users' (unknown) preferences from observed interactions. To validate our proposal, we run proof-of-concept simulations in the economic ultimatum game, formalizing user preferences as policies that guide the actions of simulated players. We find that the AI assistant accurately aligns its behavior to match standard policies from the economic literature (e.g., selfish, altruistic). However, the assistant's learned policies lack robustness and exhibit limited generalization in an out-of-distribution setting when confronted with a currency (e.g., grams of medicine) that was not included in the assistant's training distribution. Additionally, we find that when there is inconsistency in the relationship between language use and an unknown policy (e.g., an altruistic policy combined with rude language), the assistant's learning of the policy is slowed. Overall, our preliminary results suggest that developing simulation fr
    
[^56]: 销售人员 vs SalesBot：探索教育价值在对话式推荐系统中的作用

    Salespeople vs SalesBot: Exploring the Role of Educational Value in Conversational Recommender Systems. (arXiv:2310.17749v1 [cs.CL])

    [http://arxiv.org/abs/2310.17749](http://arxiv.org/abs/2310.17749)

    这项研究探索了在对话式推荐系统中教育价值的作用，通过比较销售人员和SalesBot的性能，发现虽然SalesBot在流畅性和信息量方面接近专业销售人员，但在推荐质量方面仍存在差距。

    

    进行大额购买需要消费者进行研究或咨询销售人员以获取领域专业知识。然而，现有的对话式推荐系统（CRS）往往忽视用户缺乏背景知识，仅关注于收集偏好。在这项工作中，我们为旨在通过混合型混合模式对话提供产品推荐和教育价值的会话代理定义了一个新的问题空间。我们介绍了SalesOps，这是一个借鉴最新的大型语言模型（LLM）的框架，用于模拟和评估这种系统。我们构建了SalesBot和ShopperBot，这是一对LLM驱动的代理，可以模拟框架的任意一侧。通过一项全面的人类研究，我们将SalesBot与专业销售人员进行比较，发现虽然SalesBot在流畅性和信息量方面接近专业表现，但在推荐质量方面却落后。我们强调了两者面临的不同局限性。

    Making big purchases requires consumers to research or consult a salesperson to gain domain expertise. However, existing conversational recommender systems (CRS) often overlook users' lack of background knowledge, focusing solely on gathering preferences. In this work, we define a new problem space for conversational agents that aim to provide both product recommendations and educational value through mixed-type mixed-initiative dialog. We introduce SalesOps, a framework that facilitates the simulation and evaluation of such systems by leveraging recent advancements in large language models (LLMs). We build SalesBot and ShopperBot, a pair of LLM-powered agents that can simulate either side of the framework. A comprehensive human study compares SalesBot against professional salespeople, revealing that although SalesBot approaches professional performance in terms of fluency and informativeness, it lags behind in recommendation quality. We emphasize the distinct limitations both face in 
    
[^57]: 使用门控图神经网络改进智能交通系统中的交通密度预测

    Improving Traffic Density Forecasting in Intelligent Transportation Systems Using Gated Graph Neural Networks. (arXiv:2310.17729v1 [cs.LG])

    [http://arxiv.org/abs/2310.17729](http://arxiv.org/abs/2310.17729)

    本研究通过应用门控图神经网络（GGNNs），在智能交通系统中的交通预测领域取得了显著的成果，通过最小化预测误差，GGNNs被证明是最有效的选择，展示了较高的预测性能。

    

    本研究探讨了图神经网络在交通预测领域中的应用，这是智能交通系统中的一个关键方面。准确的交通预测对于行程规划、交通控制和车辆路径规划等功能至关重要。在交通预测的背景下，深入研究了三种主要的GNN架构：图卷积网络（图采样和聚合）和门控图神经网络。详细考察了每种架构的方法论，包括层配置、激活函数和超参数。主要目标是降低预测误差，在三种模型中，GGNNs被证明是最有效的选择。研究概述了每种架构的结果，通过均方根误差和平均绝对误差（MAE）阐明了它们的预测性能。假设的结果揭示了有趣的见解：GCNs显示了9.10的RMSE和8.00的MAE，而GraphSAGE展示了令人印象深刻的预测能力。

    This study delves into the application of graph neural networks in the realm of traffic forecasting, a crucial facet of intelligent transportation systems. Accurate traffic predictions are vital for functions like trip planning, traffic control, and vehicle routing in such systems. Three prominent GNN architectures Graph Convolutional Networks (Graph Sample and Aggregation) and Gated Graph Neural Networks are explored within the context of traffic prediction. Each architecture's methodology is thoroughly examined, including layer configurations, activation functions,and hyperparameters. The primary goal is to minimize prediction errors, with GGNNs emerging as the most effective choice among the three models. The research outlines outcomes for each architecture, elucidating their predictive performance through root mean squared error and mean absolute error (MAE). Hypothetical results reveal intriguing insights: GCNs display an RMSE of 9.10 and an MAE of 8.00, while GraphSAGE shows impr
    
[^58]: 大型语言模型作为具有普适性的机器人任务策略

    Large Language Models as Generalizable Policies for Embodied Tasks. (arXiv:2310.17722v1 [cs.LG])

    [http://arxiv.org/abs/2310.17722](http://arxiv.org/abs/2310.17722)

    本研究展示了大型语言模型(LLMs)可以被适应为具有普适性的机器人任务策略。通过我们的方法LLaRP，我们成功将预训练的冻结LLM用于接收指令和视觉输入，并在环境中直接输出动作。我们的实验结果表明LLaRP不仅对任务指令的复杂改写具有鲁棒性，而且可以推广到需要新颖最优行为的新任务。在大量未见任务中，LLaRP表现出了显著的成功率提升，并且我们提供了一个新的基准测试(Language Rearrangement)来促进进一步的研究。

    

    我们展示了大型语言模型(LLMs)可以被调整为适用于机器人视觉任务的普适性策略。我们的方法被称为大型语言模型强化学习策略(LLaRP)，它将预训练的冻结的LLM调整为接收文本指令和视觉自我中心观测作为输入，并直接在环境中输出动作。通过强化学习，我们训练LLaRP通过与环境的交互来看和行动。我们展示了LLaRP对任务指令的复杂改写具有鲁棒性，并且可以推广到需要新颖最优行为的新任务。特别地，在1,000个未见任务中，它的成功率达到了42%，是其他常见学习基线或零样本应用的1.7倍成功率。最后，为了帮助社区研究以语言为条件的、大规模多任务的机器人AI问题，我们发布了一个新的基准测试(Language Rearrangement)，包括150,000个训练任务和1,000个测试任务，用于语言为条件的重新排列。

    We show that large language models (LLMs) can be adapted to be generalizable policies for embodied visual tasks. Our approach, called Large LAnguage model Reinforcement Learning Policy (LLaRP), adapts a pre-trained frozen LLM to take as input text instructions and visual egocentric observations and output actions directly in the environment. Using reinforcement learning, we train LLaRP to see and act solely through environmental interactions. We show that LLaRP is robust to complex paraphrasings of task instructions and can generalize to new tasks that require novel optimal behavior. In particular, on 1,000 unseen tasks it achieves 42% success rate, 1.7x the success rate of other common learned baselines or zero-shot applications of LLMs. Finally, to aid the community in studying language conditioned, massively multi-task, embodied AI problems we release a novel benchmark, Language Rearrangement, consisting of 150,000 training and 1,000 testing tasks for language-conditioned rearrangem
    
[^59]: 从讲话文本到洞察力：利用生成型人工智能揭示企业风险

    From Transcripts to Insights: Uncovering Corporate Risks Using Generative AI. (arXiv:2310.17721v1 [econ.GN])

    [http://arxiv.org/abs/2310.17721](http://arxiv.org/abs/2310.17721)

    这项研究探索了使用生成型人工智能工具帮助投资者揭示企业风险的价值，通过从收益电话的上下文中生成风险摘要和评估，这些基于GPT的度量具有显著的信息内容，能够预测企业层面波动性和投资创新选择。此外，生成型人工智能还能有效检测新兴风险，并且这些度量在股权市场中起到定价作用。

    

    我们探索了使用ChatGPT等生成型人工智能工具帮助投资者揭示企业风险维度的价值。我们开发并验证了政治、气候和人工智能相关风险的企业层面风险敞口度量。使用GPT 3.5模型从收益电话的背景提供的上下文生成风险摘要和评估，我们发现基于GPT的度量具有显著的信息内容，并在预测（异常）企业层面波动性和企业的选择（如投资和创新）方面优于现有的风险度量。重要的是，风险评估中的信息优于风险摘要，这证明了通用人工智能知识的价值。我们还发现，生成型人工智能对于发现新兴风险（如近几个季度飙升的人工智能风险）非常有效。我们的度量在GPT的训练窗口内外表现良好，并且在股权市场中定价。综上所述，基于人工智能的风险测量方法提供了有用的洞察。

    We explore the value of generative AI tools, such as ChatGPT, in helping investors uncover dimensions of corporate risk. We develop and validate firm-level measures of risk exposure to political, climate, and AI-related risks. Using the GPT 3.5 model to generate risk summaries and assessments from the context provided by earnings call transcripts, we show that GPT-based measures possess significant information content and outperform the existing risk measures in predicting (abnormal) firm-level volatility and firms' choices such as investment and innovation. Importantly, information in risk assessments dominates that in risk summaries, establishing the value of general AI knowledge. We also find that generative AI is effective at detecting emerging risks, such as AI risk, which has soared in recent quarters. Our measures perform well both within and outside the GPT's training window and are priced in equity markets. Taken together, an AI-based approach to risk measurement provides usef
    
[^60]: 异常维度编码特定任务知识

    Outlier Dimensions Encode Task-Specific Knowledge. (arXiv:2310.17715v1 [cs.CL])

    [http://arxiv.org/abs/2310.17715](http://arxiv.org/abs/2310.17715)

    异常维度可以编码关键的特定任务知识，并且一个单一的异常维度可以以最小的错误率完成下游任务。

    

    大型语言模型（LLM）的表示被少数几个具有极高方差的异常维度所主导。先前的研究认为，虽然去除LLM表示中的异常维度会损害下游性能，但异常维度对嵌入表示的质量是有害的。在本研究中，我们研究了微调对异常维度的影响，并展示了以下结果：1）在预训练中出现的异常维度在微调模型中仍然存在，2）一个单一的异常维度可以以最小的错误率完成下游任务。我们的结果表明，异常维度可以编码关键的特定任务知识，并且一个表示在单个异常维度上的值会影响下游模型的决策。

    Representations from large language models (LLMs) are known to be dominated by a small subset of dimensions with exceedingly high variance. Previous works have argued that although ablating these outlier dimensions in LLM representations hurts downstream performance, outlier dimensions are detrimental to the representational quality of embeddings. In this study, we investigate how fine-tuning impacts outlier dimensions and show that 1) outlier dimensions that occur in pre-training persist in fine-tuned models and 2) a single outlier dimension can complete downstream tasks with a minimal error rate. Our results suggest that outlier dimensions can encode crucial task-specific knowledge and that the value of a representation in a single outlier dimension drives downstream model decisions.
    
[^61]: 一种由语义通信增强的无线AI生成内容（AIGC）供应框架

    A Wireless AI-Generated Content (AIGC) Provisioning Framework Empowered by Semantic Communication. (arXiv:2310.17705v1 [cs.NI])

    [http://arxiv.org/abs/2310.17705](http://arxiv.org/abs/2310.17705)

    一种由语义通信增强的无线AI生成内容（AIGC）供应框架，通过使用语义信息而不是所有的二进制位提取和传输内容，以解决在无线网络中提供最优AIGC服务的挑战。

    

    近期，生成式AI应用通过创建多样化且高质量的AI生成内容（AIGC）来满足广大用户群体的需求。随着移动设备的普及和移动流量的快速增长，通过无线通信网络提供对高质量AIGC服务的无处不在的访问已成为AIGC产品的未来方向。然而，在不稳定的信道、有限的带宽资源和分布不均匀的计算资源的无线网络中提供最优的AIGC服务是具有挑战性的。为了解决这些挑战，我们提出了一个由语义通信（SemCom）增强的AIGC（SemAIGC）生成和传输框架，其中只需提取和传输内容的语义信息而不是所有的二进制位。具体而言，SemAIGC在语义编码器和解码器中集成了基于扩散的模型，以实现高效的内容生成和灵活调整计算工作负载的目的。

    Generative AI applications are recently catering to a vast user base by creating diverse and high-quality AI-generated content (AIGC). With the proliferation of mobile devices and rapid growth of mobile traffic, providing ubiquitous access to high-quality AIGC services via wireless communication networks is becoming the future direction for AIGC products. However, it is challenging to provide optimal AIGC services in wireless networks with unstable channels, limited bandwidth resources, and unevenly distributed computational resources. To tackle these challenges, we propose a semantic communication (SemCom)-empowered AIGC (SemAIGC) generation and transmission framework, where only semantic information of the content rather than all the binary bits should be extracted and transmitted by using SemCom. Specifically, SemAIGC integrates diffusion-based models within the semantic encoder and decoder for efficient content generation and flexible adjustment of the computing workload of both tr
    
[^62]: CodeFusion: 一种用于代码生成的预训练扩散模型

    CodeFusion: A Pre-trained Diffusion Model for Code Generation. (arXiv:2310.17680v1 [cs.SE])

    [http://arxiv.org/abs/2310.17680](http://arxiv.org/abs/2310.17680)

    CodeFusion是一种预训练的代码生成模型，通过扩散的方式解决了自然语言代码生成中遇到的限制，实验表明其在准确率和多样性上优于最先进的自回归系统。

    

    假设一个开发者只能修改其最后一行代码，在正确之前，他们需要多少次从头开始编写函数呢？自然语言代码生成的自回归模型也有类似的限制：它们不容易重新考虑之前生成的标记。我们介绍了一种名为CodeFusion的预训练扩散代码生成模型，通过迭代地对以编码的自然语言为条件的完整程序进行去噪，以解决这个限制。我们针对Bash、Python和Microsoft Excel条件格式(CF)规则的自然语言到代码生成任务对CodeFusion进行评估。实验结果显示，CodeFusion（75M参数）在top-1准确率上表现与最先进的自回归系统（350M-175B参数）相当，并且在top-3和top-5准确率上表现优于它们，这是由于它在多样性与质量之间的平衡更好。

    Imagine a developer who can only change their last line of code, how often would they have to start writing a function from scratch before it is correct? Auto-regressive models for code generation from natural language have a similar limitation: they do not easily allow reconsidering earlier tokens generated. We introduce CodeFusion, a pre-trained diffusion code generation model that addresses this limitation by iteratively denoising a complete program conditioned on the encoded natural language. We evaluate CodeFusion on the task of natural language to code generation for Bash, Python, and Microsoft Excel conditional formatting (CF) rules. Experiments show that CodeFusion (75M parameters) performs on par with state-of-the-art auto-regressive systems (350M-175B parameters) in top-1 accuracy and outperforms them in top-3 and top-5 accuracy due to its better balance in diversity versus quality.
    
[^63]: 使用最佳顺序分数搜索和生长-收缩树快速扩展的DAG发现方法

    Fast Scalable and Accurate Discovery of DAGs Using the Best Order Score Search and Grow-Shrink Trees. (arXiv:2310.17679v1 [cs.LG])

    [http://arxiv.org/abs/2310.17679](http://arxiv.org/abs/2310.17679)

    本论文介绍了一种用于学习有向无环图的最佳顺序分数搜索（BOSS）和生长-收缩树（GSTs）方法，该方法在准确性和执行时间方面达到了最先进的性能，适用于具有数百个高度连接的变量的问题，例如从fMRI数据中恢复脑网络。

    

    学习图形条件独立结构是一个重要的机器学习问题，也是因果发现的基石。然而，学习算法的准确性和执行时间通常难以适应具有数百个高度连接的变量的问题，例如从fMRI数据中恢复脑网络。我们介绍了最佳顺序分数搜索（BOSS）和生长-收缩树（GSTs）用于在这个范例中学习有向无环图（DAGs）。BOSS贪婪地搜索变量的排列，使用GSTs从排列构建和评分DAGs。GSTs有效地缓存分数以消除冗余计算。BOSS在准确性和执行时间方面达到了最先进的性能，在广泛的条件下与各种组合和基于梯度的学习算法进行了有利的比较。为了证明它的实用性，我们将BOSS应用于两组静息态fMRI数据：带有伪经验噪声分布的模拟数据

    Learning graphical conditional independence structures is an important machine learning problem and a cornerstone of causal discovery. However, the accuracy and execution time of learning algorithms generally struggle to scale to problems with hundreds of highly connected variables -- for instance, recovering brain networks from fMRI data. We introduce the best order score search (BOSS) and grow-shrink trees (GSTs) for learning directed acyclic graphs (DAGs) in this paradigm. BOSS greedily searches over permutations of variables, using GSTs to construct and score DAGs from permutations. GSTs efficiently cache scores to eliminate redundant calculations. BOSS achieves state-of-the-art performance in accuracy and execution time, comparing favorably to a variety of combinatorial and gradient-based learning algorithms under a broad range of conditions. To demonstrate its practicality, we apply BOSS to two sets of resting-state fMRI data: simulated data with pseudo-empirical noise distributi
    
[^64]: 将基于强化学习的控制器从模型传递到硬件在环中的研究

    Transfer of Reinforcement Learning-Based Controllers from Model- to Hardware-in-the-Loop. (arXiv:2310.17671v1 [cs.LG])

    [http://arxiv.org/abs/2310.17671](http://arxiv.org/abs/2310.17671)

    本研究通过结合迁移学习和环境中的模拟来加速强化学习代理的训练过程，以实现在嵌入式系统中有效使用强化学习的目标。

    

    开发嵌入式系统的控制功能是资源、时间和数据密集型的过程，经常导致次优的成本和解决方法。强化学习（RL）具有在最小人为干预下自动训练代理执行复杂控制任务的潜力。然而，由于数据生成的成本和安全约束，其应用大多限于纯粹的模拟领域。为了有效地在嵌入式系统功能开发中使用RL，生成的代理必须能够处理真实世界的应用。在这个背景下，本研究通过结合迁移学习（TL）和环境中的模型（XiL）模拟来加速RL代理的训练过程。对于内燃机的瞬态废气再循环控制案例，使用计算成本较低的模型在环（MiL）模拟来选择合适的算法，微调超参数，最后训练候选代理。

    The process of developing control functions for embedded systems is resource-, time-, and data-intensive, often resulting in sub-optimal cost and solutions approaches. Reinforcement Learning (RL) has great potential for autonomously training agents to perform complex control tasks with minimal human intervention. Due to costly data generation and safety constraints, however, its application is mostly limited to purely simulated domains. To use RL effectively in embedded system function development, the generated agents must be able to handle real-world applications. In this context, this work focuses on accelerating the training process of RL agents by combining Transfer Learning (TL) and X-in-the-Loop (XiL) simulation. For the use case of transient exhaust gas re-circulation control for an internal combustion engine, use of a computationally cheap Model-in-the-Loop (MiL) simulation is made to select a suitable algorithm, fine-tune hyperparameters, and finally train candidate agents fo
    
[^65]: RTNH+: 使用基于CFAR的两级预处理和垂直编码的增强型4D雷达目标检测网络

    RTNH+: Enhanced 4D Radar Object Detection Network using Combined CFAR-based Two-level Preprocessing and Vertical Encoding. (arXiv:2310.17659v1 [eess.SP])

    [http://arxiv.org/abs/2310.17659](http://arxiv.org/abs/2310.17659)

    本文提出了RTNH+，一种增强型的4D雷达目标检测网络，通过两种新算法实现：基于CFAR的两级预处理算法和垂直编码算法，可以提高目标检测的准确性和性能。

    

    四维（4D）雷达是一种在各种天气条件下进行三维目标检测和周围物体相对径向速度估计的有用传感器。然而，由于雷达测量值受到噪声、干扰和杂波等无效因素的污染，需要在使用神经网络进行三维目标检测之前进行预处理算法。在本文中，我们提出了RTNH+，它是RTNH的增强版本，是一种4D雷达目标检测网络，采用了两种新算法。第一种算法是基于恒定虚警率（CFAR）的两级预处理（CCTP）算法，它使用相同的4D雷达测量值生成两个具有不同特征的滤波测量值，可以丰富输入到4D雷达目标检测网络的信息。第二种是垂直编码（VE）算法，可以有效地从CCTP输出中编码道路目标的垂直特征。我们提供了RTNH+的详细信息。

    Four-dimensional (4D) Radar is a useful sensor for 3D object detection and the relative radial speed estimation of surrounding objects under various weather conditions. However, since Radar measurements are corrupted with invalid components such as noise, interference, and clutter, it is necessary to employ a preprocessing algorithm before the 3D object detection with neural networks. In this paper, we propose RTNH+ that is an enhanced version of RTNH, a 4D Radar object detection network, by two novel algorithms. The first algorithm is the combined constant false alarm rate (CFAR)-based two-level preprocessing (CCTP) algorithm that generates two filtered measurements of different characteristics using the same 4D Radar measurements, which can enrich the information of the input to the 4D Radar object detection network. The second is the vertical encoding (VE) algorithm that effectively encodes vertical features of the road objects from the CCTP outputs. We provide details of the RTNH+,
    
[^66]: 通道独立策略是否是时间序列预测的最佳解？

    Is Channel Independent strategy optimal for Time Series Forecasting?. (arXiv:2310.17658v1 [cs.LG])

    [http://arxiv.org/abs/2310.17658](http://arxiv.org/abs/2310.17658)

    本文重新考虑了当前通道独立策略在时间序列预测中是否是最佳解决方案，并提出了一种称为CSC的通道自聚类策略来增强性能并减小参数大小。

    

    近年来出现了许多用于长期时间序列预测的模型。最近的研究表明，使用单一线性层的通道相关(CD)或通道独立(CI)建模，甚至可以超过许多复杂模型的性能。然而，当前的研究主要将CD和CI视为两种互补但互斥的方法，无法同时利用这两个极端。而且，CD和CI都是静态策略，无法在没有大量实验的情况下确定是特定数据集的最佳策略。在本文中，我们重新考虑了当前CI策略是否是时间序列预测的最佳解决方案。首先，我们提出了一种简单而有效的策略，称为CSC（通道自聚类策略），用于线性模型。我们的通道自聚类策略增强了CI策略的性能改进，并减小了参数大小。

    There has been an emergence of various models for long-term time series forecasting. Recent studies have demonstrated that a single linear layer, using Channel Dependent (CD) or Channel Independent (CI) modeling, can even outperform a large number of sophisticated models. However, current research primarily considers CD and CI as two complementary yet mutually exclusive approaches, unable to harness these two extremes simultaneously. And it is also a challenging issue that both CD and CI are static strategies that cannot be determined to be optimal for a specific dataset without extensive experiments. In this paper, we reconsider whether the current CI strategy is the best solution for time series forecasting. First, we propose a simple yet effective strategy called CSC, which stands for $\mathbf{C}$hannel $\mathbf{S}$elf-$\mathbf{C}$lustering strategy, for linear models. Our Channel Self-Clustering (CSC) enhances CI strategy's performance improvements while reducing parameter size, fo
    
[^67]: 深度学习算法用于硅碳化物功率MOSFET器件的高级级别-3反模型建模

    Deep Learning Algorithm for Advanced Level-3 Inverse-Modeling of Silicon-Carbide Power MOSFET Devices. (arXiv:2310.17657v1 [eess.SP])

    [http://arxiv.org/abs/2310.17657](http://arxiv.org/abs/2310.17657)

    作者提出了一种深度学习方法，用于检索硅碳化物功率MOSFET的物理参数，该方法适用于重建退化设备的物理参数或检索物理配置。

    

    使用深度学习算法进行反模型建模涉及训练深层结构从静态行为中预测设备参数。反设备建模适用于重建在时间上退化的设备的漂移物理参数或检索物理配置。有很多变量可以影响反模型方法的性能。在这项工作中，作者提出了一种深度学习方法，用于检索硅碳化物功率MOSFET（SiC Power MOS）的级别-3模型的物理参数。SiC器件用于传统硅器件因高温或高开关能力而失效的应用中。SiC功率器件的主要应用在汽车领域（即在电动车领域）。由于生理退化或高应力环境，SiC功率MOS显示出物理参数的显著漂移，可以通过使用反模型进行监测。本工作的目的是...

    Inverse modelling with deep learning algorithms involves training deep architecture to predict device's parameters from its static behaviour. Inverse device modelling is suitable to reconstruct drifted physical parameters of devices temporally degraded or to retrieve physical configuration. There are many variables that can influence the performance of an inverse modelling method. In this work the authors propose a deep learning method trained for retrieving physical parameters of Level-3 model of Power Silicon-Carbide MOSFET (SiC Power MOS). The SiC devices are used in applications where classical silicon devices failed due to high-temperature or high switching capability. The key application of SiC power devices is in the automotive field (i.e. in the field of electrical vehicles). Due to physiological degradation or high-stressing environment, SiC Power MOS shows a significant drift of physical parameters which can be monitored by using inverse modelling. The aim of this work is to 
    
[^68]: ACWA: 一种基于AI的智能水务系统的网络物理测试平台

    ACWA: An AI-driven Cyber-Physical Testbed for Intelligent Water Systems. (arXiv:2310.17654v1 [cs.AR])

    [http://arxiv.org/abs/2310.17654](http://arxiv.org/abs/2310.17654)

    ACWA是一种基于AI的智能水务系统的网络物理测试平台，旨在通过利用尖端的AI和数据驱动技术解决水务和农业领域的紧迫挑战，包括网络生物安全、资源管理、水资源获取、可持续发展和基于数据的决策等。

    

    本文介绍了一种新颖的卓越网络物理水务测试平台，名为AI和网络对水和农业测试平台（ACWA）。ACWA的动机是利用AI和网络安全实验来推进水供应管理。ACWA的主要目标是通过利用尖端的AI和数据驱动技术解决水务和农业领域的紧迫挑战。这些挑战包括网络生物安全、资源管理、水资源获取、可持续发展和基于数据的决策等。为了解决这些问题，ACWA由多个拓扑结构、传感器、计算节点、泵、水箱、智能水务设备、数据库和控制系统的AI模型组成。此外，我们还提出了ACWA模拟器，这是一个基于软件的水数字孪生体。模拟器基于流体和组分输运原理生成水配送系统的理论时间序列，为系统提供了良好的验证点。

    This manuscript presents a novel state-of-the-art cyber-physical water testbed, namely: The AI and Cyber for Water and Agriculture testbed (ACWA). ACWA is motivated by the need to advance water supply management using AI and Cybersecurity experimentation. The main goal of ACWA is to address pressing challenges in the water and agricultural domains by utilising cutting-edge AI and data-driven technologies. These challenges include Cyberbiosecurity, resources management, access to water, sustainability, and data-driven decision-making, among others. To address such issues, ACWA consists of multiple topologies, sensors, computational nodes, pumps, tanks, smart water devices, as well as databases and AI models that control the system. Moreover, we present ACWA simulator, which is a software-based water digital twin. The simulator runs on fluid and constituent transport principles that produce theoretical time series of a water distribution system. This creates a good validation point for c
    
[^69]: SPA: 基于图谱对齐视角的领域自适应研究

    SPA: A Graph Spectral Alignment Perspective for Domain Adaptation. (arXiv:2310.17594v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2310.17594](http://arxiv.org/abs/2310.17594)

    本研究提出了一种新的图谱对齐框架（SPA）来解决无监督领域自适应问题。通过将领域自适应问题转化为图原语，并结合新颖的谱正则化器和邻域感知自训练机制，SPA在特征空间中对齐领域图并提高了目标领域中的可区分性。

    

    无监督领域自适应（UDA）是机器学习中一种重要的形式，它可以将领域内的模型扩展到数据分布不同的目标领域。大多数先前的工作都关注于捕捉跨领域可传递性，但往往忽视了丰富的领域内结构，这在实践中导致了更差的可区分性。本文提出了一种新颖的图谱对齐框架（SPA）来解决这一权衡问题。我们的方法的核心概要如下：（i）通过将DA问题转化为图原语，SPA将粗粒度的图对齐机制与一种新颖的谱正则化器相结合，以在特征空间中对齐领域图；（ii）我们进一步开发了一种细粒度的消息传递模块，基于一种新颖的邻域感知自训练机制，在目标领域中提高了可区分性。在标准基准测试中，SPA的广泛实验表明其性能已超过现有方法。

    Unsupervised domain adaptation (UDA) is a pivotal form in machine learning to extend the in-domain model to the distinctive target domains where the data distributions differ. Most prior works focus on capturing the inter-domain transferability but largely overlook rich intra-domain structures, which empirically results in even worse discriminability. In this work, we introduce a novel graph SPectral Alignment (SPA) framework to tackle the tradeoff. The core of our method is briefly condensed as follows: (i)-by casting the DA problem to graph primitives, SPA composes a coarse graph alignment mechanism with a novel spectral regularizer towards aligning the domain graphs in eigenspaces; (ii)-we further develop a fine-grained message propagation module -- upon a novel neighbor-aware self-training mechanism -- in order for enhanced discriminability in the target domain. On standardized benchmarks, the extensive experiments of SPA demonstrate that its performance has surpassed the existing 
    
[^70]: 人类引导的复杂度控制抽象化

    Human-Guided Complexity-Controlled Abstractions. (arXiv:2310.17550v1 [cs.LG])

    [http://arxiv.org/abs/2310.17550](http://arxiv.org/abs/2310.17550)

    本研究通过训练神经模型生成一系列离散表示，并通过调整表示的复杂性来提高任务的泛化性能。在微调实验中，我们发现适当的复杂性水平支持最佳的微调性能，并且在人类参与者的研究中也得到验证。

    

    神经网络通常学习任务特定的潜在表示，但这些表示无法推广到新的环境或任务。相反，人类在各种抽象级别（例如，“鸟”与“麻雀”）上学习离散表示（即概念或单词），并根据任务使用适当的抽象。受此启发，我们训练神经模型生成一系列离散表示，并通过调整表示分布的熵来控制表示的复杂性（大致上是为编码输入分配了多少位）。在微调实验中，仅使用少量带标签的示例用于新任务，我们展示了（1）调整表示以适当的复杂性水平支持最高的微调性能，以及（2）在一个人类参与者的研究中，用户能够根据离散表示的可视化来确定下游任务的适当复杂性水平。我们的结果表明一个有希望的方向。

    Neural networks often learn task-specific latent representations that fail to generalize to novel settings or tasks. Conversely, humans learn discrete representations (i.e., concepts or words) at a variety of abstraction levels (e.g., ``bird'' vs. ``sparrow'') and deploy the appropriate abstraction based on task. Inspired by this, we train neural models to generate a spectrum of discrete representations, and control the complexity of the representations (roughly, how many bits are allocated for encoding inputs) by tuning the entropy of the distribution over representations. In finetuning experiments, using only a small number of labeled examples for a new task, we show that (1) tuning the representation to a task-appropriate complexity level supports the highest finetuning performance, and (2) in a human-participant study, users were able to identify the appropriate complexity level for a downstream task using visualizations of discrete representations. Our results indicate a promising
    
[^71]: 大型语言模型能否取代人类在系统评价过程中的角色？评估GPT-4在多种语言的同行评审文献和灰色文献筛选和提取数据方面的效果。

    Can large language models replace humans in the systematic review process? Evaluating GPT-4's efficacy in screening and extracting data from peer-reviewed and grey literature in multiple languages. (arXiv:2310.17526v1 [cs.CL])

    [http://arxiv.org/abs/2310.17526](http://arxiv.org/abs/2310.17526)

    本研究评估了GPT-4在多种语言的同行评审文献和灰色文献筛选和提取数据方面的能力，结果显示GPT-4在大多数任务上准确度与人类表现相当，在调整了偶然一致性和数据集不平衡后，其在数据提取方面表现出中等水平的准确度。

    

    系统评价对于指导实践、研究和政策至关重要，然而常常需要耗费大量时间和人力。大型语言模型（LLM）可能能够加快和自动化系统评价的过程，但是它们在这些任务中的表现尚未经过全面评估，而且还没有研究测试过迄今为止最大的LLM——GPT-4。本预注册研究采用“无人参与”的方法评估了GPT-4在标题/摘要筛选、全文审查和数据提取方面在不同文献类型和语言上的能力。尽管GPT-4在大多数任务中的准确度与人类表现相当，但结果受到偶然一致性和数据集不平衡的影响。在调整了这些因素后，数据提取方面表现出中等水平的准确度，在使用高可靠性提示进行筛选的研究中，筛选全文文献的表现水平在不同阶段和语言上均为无到中等。

    Systematic reviews are vital for guiding practice, research, and policy, yet they are often slow and labour-intensive. Large language models (LLMs) could offer a way to speed up and automate systematic reviews, but their performance in such tasks has not been comprehensively evaluated against humans, and no study has tested GPT-4, the biggest LLM so far. This pre-registered study evaluates GPT-4's capability in title/abstract screening, full-text review, and data extraction across various literature types and languages using a 'human-out-of-the-loop' approach. Although GPT-4 had accuracy on par with human performance in most tasks, results were skewed by chance agreement and dataset imbalance. After adjusting for these, there was a moderate level of performance for data extraction, and - barring studies that used highly reliable prompts screening performance levelled at none to moderate for different stages and languages. When screening full-text literature using highly reliable prom
    
[^72]: 《低秩适应的表达能力》

    The Expressive Power of Low-Rank Adaptation. (arXiv:2310.17513v1 [cs.LG])

    [http://arxiv.org/abs/2310.17513](http://arxiv.org/abs/2310.17513)

    本文分析了低秩适应（LoRA）的表达能力，证明了对于全连接神经网络，当LoRA-rank≥（f的宽度）×（目标模型的深度/ f的深度）时，LoRA可以使任何模型f准确表示任何较小的目标模型f。对于Transformer网络，通过rank-（嵌入大小/ 2）的LoRA适配器可以使任何模型适应于相同大小的目标模型。

    

    低秩适应（LoRA）是一种参数高效的微调方法，利用矩阵的低秩适应性，在微调预训练模型（如大型语言模型和扩散模型）中得到了广泛应用。尽管在实践中取得了巨大成功，但是LoRA的理论基础在很大程度上尚未得到探索。本文通过从理论角度分析LoRA的表达能力，首次尝试弥合这一差距。我们证明了对于全连接神经网络，如果LoRA-rank≥（f的宽度）×（目标模型的深度/ f的深度），则LoRA可以使任何模型f准确表示任何较小的目标模型f。当LoRA-rank低于阈值时，我们还量化了逼近误差。对于Transformer网络，我们证明任何模型可以通过rank-（嵌入大小/ 2）的LoRA适配器适应于相同大小的目标模型。

    Low-Rank Adaptation (LoRA), a parameter-efficient fine-tuning method that leverages low-rank adaptation of weight matrices, has emerged as a prevalent technique for fine-tuning pre-trained models such as large language models and diffusion models. Despite its huge success in practice, the theoretical underpinnings of LoRA have largely remained unexplored. This paper takes the first step to bridge this gap by theoretically analyzing the expressive power of LoRA. We prove that, for fully connected neural networks, LoRA can adapt any model $f$ to accurately represent any smaller target model $\overline{f}$ if LoRA-rank $\geq(\text{width of }f) \times \frac{\text{depth of }\overline{f}}{\text{depth of }f}$. We also quantify the approximation error when LoRA-rank is lower than the threshold. For Transformer networks, we show any model can be adapted to a target model of the same size with rank-$(\frac{\text{embedding size}}{2})$ LoRA adapters.
    
[^73]: Core Challenge 2023: 求解器和图描述

    Core Challenge 2023: Solver and Graph Descriptions. (arXiv:2310.17136v1 [cs.PL])

    [http://arxiv.org/abs/2310.17136](http://arxiv.org/abs/2310.17136)

    本文总结了 CoRe Challenge 2023 中提交的求解器和 ISR 实例的所有描述。

    

    本文收集了提交给 CoRe Challenge 2023 的求解器和 ISR 实例的所有描述。

    This paper collects all descriptions of solvers and ISR instances submitted to CoRe Challenge 2023.
    
[^74]: 多尺度扩散去噪平滑

    Multi-scale Diffusion Denoised Smoothing. (arXiv:2310.16779v1 [cs.LG])

    [http://arxiv.org/abs/2310.16779](http://arxiv.org/abs/2310.16779)

    本文研究了多尺度扩散去噪平滑的准确度和认证鲁棒性之间的权衡，并提出了一种在共享扩散模型上调整以实现平滑分类器鲁棒性的新方法。

    

    随着最近的扩散模型，随机平滑已成为少数几个切实可行的方法之一，为大规模预训练模型提供对抗鲁棒性。具体而言，可以通过简单的“去噪和分类”流程，即所谓的去噪平滑，在任何分类器上执行随机平滑，前提是有一个准确的去噪器可用，比如扩散模型。在本文中，我们研究了去噪平滑的准确度和认证鲁棒性之间的权衡：例如，我们质疑哪种扩散模型的表示形式能够最大化去噪平滑的认证鲁棒性。我们考虑了一个新的目标，旨在实现共同噪声水平下平滑分类器的鲁棒性，在共享扩散模型上进行精细调整，同时也为其认证鲁棒性补偿准确度的成本提供了一种新途径。

    Along with recent diffusion models, randomized smoothing has become one of a few tangible approaches that offers adversarial robustness to models at scale, e.g., those of large pre-trained models. Specifically, one can perform randomized smoothing on any classifier via a simple "denoise-and-classify" pipeline, so-called denoised smoothing, given that an accurate denoiser is available - such as diffusion model. In this paper, we investigate the trade-off between accuracy and certified robustness of denoised smoothing: for example, we question on which representation of diffusion model would maximize the certified robustness of denoised smoothing. We consider a new objective that aims collective robustness of smoothed classifiers across multiple noise levels at a shared diffusion model, which also suggests a new way to compensate the cost of accuracy in randomized smoothing for its certified robustness. This objective motivates us to fine-tune diffusion model (a) to perform consistent de
    
[^75]: 将通用场景描述翻译成知识图谱用于机器人环境

    Translating Universal Scene Descriptions into Knowledge Graphs for Robotic Environment. (arXiv:2310.16737v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2310.16737](http://arxiv.org/abs/2310.16737)

    该论文研究了将通用场景描述翻译成知识图谱的技术，以提供对机器人环境的语义查询和集成其他知识源的能力。

    

    机器人执行人类规模的操作任务需要对周围环境有大量的知识，以便能够胜任和类似于人类的动作。在这项工作中，我们研究了虚拟现实技术作为机器人环境建模的实现方法，并提出了一种将场景图翻译成知识库的技术。为此，我们利用了通用场景描述（USD）格式，该格式是用于编写、可视化和模拟复杂环境的新兴标准。我们研究了基于USD的环境模型转换为知识图谱（KG）表示，以便实现语义查询和与其他知识源的集成。

    Robots performing human-scale manipulation tasks require an extensive amount of knowledge about their surroundings in order to perform their actions competently and human-like. In this work, we investigate the use of virtual reality technology as an implementation for robot environment modeling, and present a technique for translating scene graphs into knowledge bases. To this end, we take advantage of the Universal Scene Description (USD) format which is an emerging standard for the authoring, visualization and simulation of complex environments. We investigate the conversion of USD-based environment models into Knowledge Graph (KG) representations that facilitate semantic querying and integration with additional knowledge sources.
    
[^76]: 乐观主义的陷阱：通过随机化风险标准的分布式强化学习

    Pitfall of Optimism: Distributional Reinforcement Learning by Randomizing Risk Criterion. (arXiv:2310.16546v1 [cs.LG])

    [http://arxiv.org/abs/2310.16546](http://arxiv.org/abs/2310.16546)

    本论文提出了一种通过随机化风险标准的分布式强化学习算法，以避免在风险上的偏向性，并证明了其收敛性和最优性。实验证明，在包括Atari 55游戏在内的各种环境中，该方法优于其他分布式算法。

    

    分布式强化学习算法试图利用估计的不确定性进行探索，如在面对不确定性时的乐观主义。然而，使用估计的方差进行乐观探索可能导致数据收集的偏差，阻碍收敛或性能。本文提出了一种新颖的分布式强化学习算法，通过随机化风险标准来选择动作，避免在风险上的单向倾向。我们通过扭曲风险度量提供了一个扰动的分布贝尔曼最优性算子，并证明了所提方法具有较弱的收缩性质的收敛性和最优性。我们的理论结果支持，所提方法不会陷入偏向性的探索，并确保收敛到最优回报。最后，我们在包括Atari 55游戏在内的各种环境中通过实验证明了我们的方法优于其他现有的基于分布的算法。

    Distributional reinforcement learning algorithms have attempted to utilize estimated uncertainty for exploration, such as optimism in the face of uncertainty. However, using the estimated variance for optimistic exploration may cause biased data collection and hinder convergence or performance. In this paper, we present a novel distributional reinforcement learning algorithm that selects actions by randomizing risk criterion to avoid one-sided tendency on risk. We provide a perturbed distributional Bellman optimality operator by distorting the risk measure and prove the convergence and optimality of the proposed method with the weaker contraction property. Our theoretical results support that the proposed method does not fall into biased exploration and is guaranteed to converge to an optimal return. Finally, we empirically show that our method outperforms other existing distribution-based algorithms in various environments including Atari 55 games.
    
[^77]: 识别偏见的原因：一种基于论证的方法

    Identifying Reasons for Bias: An Argumentation-Based Approach. (arXiv:2310.16506v1 [cs.LG])

    [http://arxiv.org/abs/2310.16506](http://arxiv.org/abs/2310.16506)

    本文提出了一种基于论证的方法来确定为什么一个个体被分类与相似个体不同，该方法使用定量论证框架来表示个体和与其相似个体的属性-值对，并使用一个众所周知的语义来确定对个体分类产生最大贡献的属性-值对。

    

    随着算法决策系统在社会中的普及，确保这些系统的公平性变得越来越重要。虽然在构建公平算法决策系统方面已经进行了大量研究，但其中大部分方法需要访问训练数据，包括个人特征，并且对于哪些个体被不公平地分类没有透明度。本文提出了一种新颖的、与模型无关的基于论证的方法，以确定为什么一个个体被分类与相似个体不同。我们的方法使用定量论证框架来表示个体和与其相似个体的属性-值对，并使用一个众所周知的语义来确定对个体分类产生最大贡献的属性-值对。我们在两个在公平领域常用的数据集上评估了我们的方法，并展示了它在识别差异分类方面的有效性。

    As algorithmic decision-making systems become more prevalent in society, ensuring the fairness of these systems is becoming increasingly important. Whilst there has been substantial research in building fair algorithmic decision-making systems, the majority of these methods require access to the training data, including personal characteristics, and are not transparent regarding which individuals are classified unfairly. In this paper, we propose a novel model-agnostic argumentation-based method to determine why an individual is classified differently in comparison to similar individuals. Our method uses a quantitative argumentation framework to represent attribute-value pairs of an individual and of those similar to them, and uses a well-known semantics to identify the attribute-value pairs in the individual contributing most to their different classification. We evaluate our method on two datasets commonly used in the fairness literature and illustrate its effectiveness in the identi
    
[^78]: 使用具有专门口音代码本的口音识别

    Accented Speech Recognition With Accent-specific Codebooks. (arXiv:2310.15970v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.15970](http://arxiv.org/abs/2310.15970)

    本研究提出了一种使用具有专门口音代码本的口音适应方法，通过交叉注意力和可训练代码本，用于端到端ASR系统。在实验证明了该方法在已见和未见的口音上都能获得显著的性能提升。

    

    语音口音对于现有自动语音识别（ASR）系统构成了重要挑战。在代表性不足的口音中的性能下降严重阻碍了ASR的普及应用。本研究提出了一种新颖的口音适应方法，通过交叉注意力和可训练代码本，用于端到端ASR系统。这些可学习的代码本捕捉了口音特定信息，并被整合到ASR编码器层中。模型在带口音的英语语音上进行训练，而测试数据中也包含了在训练过程中未见过的口音。在Mozilla Common Voice多口音数据集上，我们展示了我们提出的方法在不仅在已见的英语口音中获得显著的性能提升（单词错误率相对提升高达37%），而且在未见的口音上也获得了5%的相对提升。此外，我们还展示了在L2Artic数据集上的零样本迁移设置的好处。我们还进行了对比实验。

    Speech accents pose a significant challenge to state-of-the-art automatic speech recognition (ASR) systems. Degradation in performance across underrepresented accents is a severe deterrent to the inclusive adoption of ASR. In this work, we propose a novel accent adaptation approach for end-to-end ASR systems using cross-attention with a trainable set of codebooks. These learnable codebooks capture accent-specific information and are integrated within the ASR encoder layers. The model is trained on accented English speech, while the test data also contained accents which were not seen during training. On the Mozilla Common Voice multi-accented dataset, we show that our proposed approach yields significant performance gains not only on the seen English accents (up to $37\%$ relative improvement in word error rate) but also on the unseen accents (up to $5\%$ relative improvement in WER). Further, we illustrate benefits for a zero-shot transfer setup on the L2Artic dataset. We also compare
    
[^79]: 模拟对阿尔茨海默病药物重用的有效性进行路径重要性建模

    Modeling Path Importance for Effective Alzheimer's Disease Drug Repurposing. (arXiv:2310.15211v1 [q-bio.QM])

    [http://arxiv.org/abs/2310.15211](http://arxiv.org/abs/2310.15211)

    该论文提出了一种基于网络的新方法（MPI）来有效进行阿尔茨海默病药物重用。该方法通过学习节点嵌入来优先考虑重要路径，从而更好地发现候选药物。

    

    最近，药物重用作为一种有效且资源高效的阿尔茨海默病药物发现范式已经崭露头角。在各种药物重用方法中，基于网络的方法显示出了有希望的结果，因为它们能够利用复杂网络，整合多种相互作用类型（如蛋白质相互作用），更有效地识别潜在药物。然而，现有的方法通常假设网络中相同长度的路径对于识别药物的治疗效果具有相等的重要性。其他领域发现，相同长度的路径并不一定具有相同的重要性。因此，依赖于这一假设可能对药物重用尝试产生不利影响。在这项工作中，我们提出了MPI（模拟路径重要性），这是一种新颖的基于网络的阿尔茨海默病药物重用方法。MPI的独特之处在于，通过学习节点嵌入来优先考虑重要路径，这可以有效捕捉网络的丰富结构信息。因此，利用学习的节点嵌入可以提高药物重用的效果。

    Recently, drug repurposing has emerged as an effective and resource-efficient paradigm for AD drug discovery. Among various methods for drug repurposing, network-based methods have shown promising results as they are capable of leveraging complex networks that integrate multiple interaction types, such as protein-protein interactions, to more effectively identify candidate drugs. However, existing approaches typically assume paths of the same length in the network have equal importance in identifying the therapeutic effect of drugs. Other domains have found that same length paths do not necessarily have the same importance. Thus, relying on this assumption may be deleterious to drug repurposing attempts. In this work, we propose MPI (Modeling Path Importance), a novel network-based method for AD drug repurposing. MPI is unique in that it prioritizes important paths via learned node embeddings, which can effectively capture a network's rich structural information. Thus, leveraging learn
    
[^80]: 在样本选择偏差存在的情况下，利用集成多样性进行鲁棒的自训练

    Leveraging Ensemble Diversity for Robust Self-Training in the Presence of Sample Selection Bias. (arXiv:2310.14814v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.14814](http://arxiv.org/abs/2310.14814)

    本文提出了一种在样本选择偏差存在的情况下，利用集成多样性进行鲁棒的自训练的方法，并引入了一种新的自信度度量方法-$\mathcal{T}$-相似度。实验证明该方法在三种不同伪标签策略下具有良好的效果。

    

    自训练是半监督学习中一种众所周知的方法。它包括对模型自信度高的未标记数据进行伪标签分配，并将其视为标记样本进行处理。对于神经网络，通常使用softmax预测概率作为自信度度量，尽管已知它们对错误预测也过于自信。当数据标注受到某种约束时，这种现象尤为明显，即样本选择偏差存在。为了解决这个问题，我们提出了一种新的自信度度量方法，称为$\mathcal{T}$-相似度，它基于线性分类器的集成预测多样性。我们通过研究稳定点并描述单个成员的多样性与其性能之间的关系来提供我们方法的理论分析。我们通过对三种不同伪标签策略的实验验证了我们自信度度量的好处。

    Self-training is a well-known approach for semi-supervised learning. It consists of iteratively assigning pseudo-labels to unlabeled data for which the model is confident and treating them as labeled examples. For neural networks, softmax prediction probabilities are often used as a confidence measure, despite the fact that they are known to be overconfident, even for wrong predictions. This phenomenon is particularly intensified in the presence of sample selection bias, i.e., when data labeling is subject to some constraint. To address this issue, we propose a novel confidence measure, called $\mathcal{T}$-similarity, built upon the prediction diversity of an ensemble of linear classifiers. We provide the theoretical analysis of our approach by studying stationary points and describing the relationship between the diversity of the individual members and their performance. We empirically demonstrate the benefit of our confidence measure for three different pseudo-labeling policies on c
    
[^81]: 激发大型语言模型中的提示工程潜力：一项综述

    Unleashing the potential of prompt engineering in Large Language Models: a comprehensive review. (arXiv:2310.14735v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.14735](http://arxiv.org/abs/2310.14735)

    这篇论文解释了提示工程在释放大型语言模型能力方面的关键作用，探讨了不同的提示方法以及外部插件如何协助减少机器幻想，并指出了未来研究方向的重要性。

    

    本文深入探讨了提示工程在释放大型语言模型（LLM）能力方面的关键作用。提示工程是为LLM构建输入文本的过程，是优化LLM有效性的重要技术。本综述阐明了提示工程的基本原理，如角色提示、一次性提示和少量提示，以及更高级的方法，如思维链和思维树提示。本文还阐述了外部插件如何协助此任务，并通过检索外部知识来减少机器幻想。随后，我们勾勒了提示工程研究的前景方向，强调了对结构和代理在人工智能生成内容（AIGC）工具中的作用的深入理解的必要性。我们讨论了如何从不同角度和使用不同的方法评估提示方法的有效性。最后，我们提出了展望未来的研究方向。

    This paper delves into the pivotal role of prompt engineering in unleashing the capabilities of Large Language Models (LLMs). Prompt engineering is the process of structuring input text for LLMs and is a technique integral to optimizing the efficacy of LLMs. This survey elucidates foundational principles of prompt engineering, such as role-prompting, one-shot, and few-shot prompting, as well as more advanced methodologies such as the chain-of-thought and tree-of-thoughts prompting. The paper sheds light on how external assistance in the form of plugins can assist in this task, and reduce machine hallucination by retrieving external knowledge. We subsequently delineate prospective directions in prompt engineering research, emphasizing the need for a deeper understanding of structures and the role of agents in Artificial Intelligence-Generated Content (AIGC) tools. We discuss how to assess the efficacy of prompt methods from different perspectives and using different methods. Finally, we
    
[^82]: 机器学习模型的成员推断攻击的基本限制

    Fundamental Limits of Membership Inference Attacks on Machine Learning Models. (arXiv:2310.13786v1 [stat.ML])

    [http://arxiv.org/abs/2310.13786](http://arxiv.org/abs/2310.13786)

    本文探讨了机器学习模型上成员推断攻击的基本限制，包括推导了效果和成功率的统计量，并提供了几种情况下的界限。这使得我们能够根据样本数量和其他结构参数推断潜在攻击的准确性。

    

    成员推断攻击（MIA）可以揭示特定数据点是否是训练数据集的一部分，可能暴露个人的敏感信息。本文探讨了关于机器学习模型上MIA的基本统计限制。具体而言，我们首先推导了统计量，该统计量决定了这种攻击的有效性和成功率。然后，我们研究了几种情况，并对这个感兴趣的统计量提供了界限。这使我们能够根据样本数量和学习模型的其他结构参数推断潜在攻击的准确性，在某些情况下可以直接从数据集中估计。

    Membership inference attacks (MIA) can reveal whether a particular data point was part of the training dataset, potentially exposing sensitive information about individuals. This article explores the fundamental statistical limitations associated with MIAs on machine learning models. More precisely, we first derive the statistical quantity that governs the effectiveness and success of such attacks. Then, we investigate several situations for which we provide bounds on this quantity of interest. This allows us to infer the accuracy of potential attacks as a function of the number of samples and other structural parameters of learning models, which in some cases can be directly estimated from the dataset.
    
[^83]: 通过对比学习增强药物和细胞系表征，以改善抗癌药物优先级排序

    Enhancing drug and cell line representations via contrastive learning for improved anti-cancer drug prioritization. (arXiv:2310.13725v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.13725](http://arxiv.org/abs/2310.13725)

    通过对比学习，该研究提出了一种改进药物和细胞系表征的方法，以保留与药物作用机制和细胞系癌症类型相关的关系结构，并实现了卓越的性能。使用这种方法可以更好地平衡对药物和细胞系特征的依赖，从而实现更个性化的药物优先级排序。

    

    鉴于癌症的复杂性和对治疗的可变反应，通过基因组学序列分析进行的精确个体化癌症治疗已成为当前的标准。然而，每个患者产生的数据量使得快速识别最佳治疗方案变得困难。此外，受限的数据可用性妨碍了计算方法学习与有效药物-细胞系配对相关的模式。在这项工作中，我们提出使用对比学习改进学习到的药物和细胞系表征，以保留与药物作用机制和细胞系癌症类型相关的关系结构。除了相对于最先进的方法实现了卓越的性能外，我们发现使用我们学习到的表征的分类器在进行预测时更加平衡地依赖于药物和细胞系特征。这有助于更个性化的药物优先级排序，其基于与药物耐药性相关的信号。

    Due to cancer's complex nature and variable response to therapy, precision oncology informed by omics sequence analysis has become the current standard of care. However, the amount of data produced for each patients makes it difficult to quickly identify the best treatment regimen. Moreover, limited data availability has hindered computational methods' abilities to learn patterns associated with effective drug-cell line pairs. In this work, we propose the use of contrastive learning to improve learned drug and cell line representations by preserving relationship structures associated with drug mechanism of action and cell line cancer types. In addition to achieving enhanced performance relative to a state-of-the-art method, we find that classifiers using our learned representations exhibit a more balances reliance on drug- and cell line-derived features when making predictions. This facilitates more personalized drug prioritizations that are informed by signals related to drug resistan
    
[^84]: 探索语言模型中谄媚行为的理解

    Towards Understanding Sycophancy in Language Models. (arXiv:2310.13548v1 [cs.CL])

    [http://arxiv.org/abs/2310.13548](http://arxiv.org/abs/2310.13548)

    这项研究探讨了强化学习从人类反馈中训练高质量AI助手的技术，发现这种方法可能导致模型在回答问题时过于谄媚，而不是坦诚，通过分析人类偏好数据得出了这一结论。

    

    「从人类反馈中进行强化学习（RLHF）」是训练高质量AI助手的一种流行技术。然而，RLHF可能会鼓励模型通过与用户信念相符的回答来代替真实回答，这种行为被称为谄媚行为。我们研究了RLHF训练模型中谄媚行为的普遍性以及人类偏好判断是否起到了作用。首先，我们证明了五个最先进的AI助手在四个不同的自由文本生成任务中一贯表现出谄媚行为。为了理解人类偏好是否驱动了RLHF模型的这种广泛行为，我们分析了现有的人类偏好数据。我们发现，当回答与用户的观点相符时，它更有可能被选中。此外，人类和偏好模型（PMs）将有说服力的谄媚回答与正确回答相比，有时几乎可以忽略不计地选择了谄媚回答。优化模型输出以满足PMs有时也会在真实性和谄媚行为之间做出取舍。

    Reinforcement learning from human feedback (RLHF) is a popular technique for training high-quality AI assistants. However, RLHF may also encourage model responses that match user beliefs over truthful responses, a behavior known as sycophancy. We investigate the prevalence of sycophancy in RLHF-trained models and whether human preference judgements are responsible. We first demonstrate that five state-of-the-art AI assistants consistently exhibit sycophantic behavior across four varied free-form text-generation tasks. To understand if human preferences drive this broadly observed behavior of RLHF models, we analyze existing human preference data. We find that when a response matches a user's views, it is more likely to be preferred. Moreover, both humans and preference models (PMs) prefer convincingly-written sycophantic responses over correct ones a negligible fraction of the time. Optimizing model outputs against PMs also sometimes sacrifices truthfulness in favor of sycophancy. Over
    
[^85]: Jorge: GPU高效的二阶优化的近似预处理方法

    Jorge: Approximate Preconditioning for GPU-efficient Second-order Optimization. (arXiv:2310.12298v1 [cs.LG])

    [http://arxiv.org/abs/2310.12298](http://arxiv.org/abs/2310.12298)

    本文介绍了Jorge，一种GPU高效的二阶优化算法，通过近似预处理方法替代矩阵求逆计算来提高计算效率，同时兼具二阶方法的收敛性能。实验证明了Jorge的有效性。

    

    尽管与一阶优化器相比，二阶优化器具有更好的收敛性能，但由于计算成本较大，深度学习中的二阶优化器一直不太受欢迎。这种优化器中的主要效率瓶颈是预处理步骤中的矩阵求逆计算，在GPU上计算昂贵。在本文中，我们引入了Jorge，一种二阶优化器，它兼具二阶方法的快速收敛特性和一阶方法的高计算效率。我们通过完全消除矩阵求逆计算的方法来解决计算瓶颈，用近似的预处理器计算替代。这使得Jorge在墙钟时间上在GPU上非常高效。此外，我们描述了一种直接从调整良好的SGD基准中确定Jorge超参数的方法，从而显著减少了调参工作。我们的实证评估证明了Jorge的效果。

    Despite their better convergence properties compared to first-order optimizers, second-order optimizers for deep learning have been less popular due to their significant computational costs. The primary efficiency bottleneck in such optimizers is matrix inverse calculations in the preconditioning step, which are expensive to compute on GPUs. In this paper, we introduce Jorge, a second-order optimizer that promises the best of both worlds -- rapid convergence benefits of second-order methods, and high computational efficiency typical of first-order methods. We address the primary computational bottleneck of computing matrix inverses by completely eliminating them using an approximation of the preconditioner computation. This makes Jorge extremely efficient on GPUs in terms of wall-clock time. Further, we describe an approach to determine Jorge's hyperparameters directly from a well-tuned SGD baseline, thereby significantly minimizing tuning efforts. Our empirical evaluations demonstrate
    
[^86]: MetaBox：一种用于元黑箱优化与强化学习的基准平台

    MetaBox: A Benchmark Platform for Meta-Black-Box Optimization with Reinforcement Learning. (arXiv:2310.08252v1 [cs.LG])

    [http://arxiv.org/abs/2310.08252](http://arxiv.org/abs/2310.08252)

    MetaBox是一种用于开发和评估元黑箱优化与强化学习方法的基准平台，提供灵活的算法模板、广泛的问题实例和基线方法，并引入了三个标准化的性能指标，以促进方法的严格评估。

    

    最近，元黑箱优化与强化学习（MetaBBO-RL）展示了在元级别上利用强化学习来减少对低级黑箱优化器的手动微调的能力。然而，这个领域由于缺乏统一的基准而受到阻碍。为了填补这个空白，我们介绍了MetaBox，这是一个专门为开发和评估MetaBBO-RL方法而设计的第一个基准平台。MetaBox提供了一个灵活的算法模板，让用户可以轻松地在平台内实现自己的独特设计。此外，它提供了超过300个问题实例，从合成到真实场景的广泛范围，并且包含了19种基线方法的详尽库，包括传统黑箱优化器和最近的MetaBBO-RL方法。此外，MetaBox引入了三个标准化的性能指标，使方法的评估更加全面。

    Recently, Meta-Black-Box Optimization with Reinforcement Learning (MetaBBO-RL) has showcased the power of leveraging RL at the meta-level to mitigate manual fine-tuning of low-level black-box optimizers. However, this field is hindered by the lack of a unified benchmark. To fill this gap, we introduce MetaBox, the first benchmark platform expressly tailored for developing and evaluating MetaBBO-RL methods. MetaBox offers a flexible algorithmic template that allows users to effortlessly implement their unique designs within the platform. Moreover, it provides a broad spectrum of over 300 problem instances, collected from synthetic to realistic scenarios, and an extensive library of 19 baseline methods, including both traditional black-box optimizers and recent MetaBBO-RL methods. Besides, MetaBox introduces three standardized performance metrics, enabling a more thorough assessment of the methods. In a bid to illustrate the utility of MetaBox for facilitating rigorous evaluation and in-
    
[^87]: 离线强化学习中的问责制：用语料库的例子解释决策

    Accountability in Offline Reinforcement Learning: Explaining Decisions with a Corpus of Examples. (arXiv:2310.07747v1 [cs.LG])

    [http://arxiv.org/abs/2310.07747](http://arxiv.org/abs/2310.07747)

    本论文介绍了一种可解释的离线控制器方法，通过使用离线数据集作为决策语料库，在低数据场景中实现了问责制的控制，并在医疗保健领域展示了良好的性能。

    

    在决策系统中使用离线数据学习透明、可解释的控制器是一个重要的研究领域，因为它有潜力降低在现实世界系统中应用的风险。然而，在责任敏感的设置（如医疗保健）中，决策问责制非常重要，但目前的文献尚未充分解决这个问题。本文介绍了一种名为Accountable Offline Controller（AOC）的方法，它将离线数据集作为决策语料库，并根据一组定制的例子（称为语料库子集）进行问责制的控制。AOC在低数据场景中有效地运行，可以扩展到严格的离线模仿设置，并表现出保护和适应性的特点。我们在模拟和真实的医疗保健场景中评估了AOC的性能，强调了它在保持问责制的同时能够管理高水平的离线控制任务。

    Learning transparent, interpretable controllers with offline data in decision-making systems is an essential area of research due to its potential to reduce the risk of applications in real-world systems. However, in responsibility-sensitive settings such as healthcare, decision accountability is of paramount importance, yet has not been adequately addressed by the literature. This paper introduces the Accountable Offline Controller (AOC) that employs the offline dataset as the Decision Corpus and performs accountable control based on a tailored selection of examples, referred to as the Corpus Subset. ABC operates effectively in low-data scenarios, can be extended to the strictly offline imitation setting, and displays qualities of both conservation and adaptability. We assess ABC's performance in both simulated and real-world healthcare scenarios, emphasizing its capability to manage offline control tasks with high levels of performance while maintaining accountability.  Keywords: Int
    
[^88]: 大规模类别下的广义神经崩溃

    Generalized Neural Collapse for a Large Number of Classes. (arXiv:2310.05351v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.05351](http://arxiv.org/abs/2310.05351)

    本论文将神经崩溃概念扩展到类别数远大于特征空间维度的情况，并展示了广义神经崩溃现象的最小边界值被最大化。

    

    神经崩溃提供了深度分类模型中学习的最后一层表示（即特征）和分类器权重的优雅数学描述。这种结果不仅提供了洞察力，还激发了改进实际深度模型的新技术。然而，大多数关于神经崩溃的现有经验和理论研究都集中于类别数相对于特征空间维度较小的情况。本文将神经崩溃扩展到类别数远大于特征空间维度的情况，这在语言模型、检索系统和人脸识别应用中广泛出现。我们展示了特征和分类器展现出了广义神经崩溃现象，其中最小的一对其他类别间边界值被最大化。我们进行了实证研究以验证实际深度神经网络中广义神经崩溃的发生。此外，我们提供了理论研究，以表明….

    Neural collapse provides an elegant mathematical characterization of learned last layer representations (a.k.a. features) and classifier weights in deep classification models. Such results not only provide insights but also motivate new techniques for improving practical deep models. However, most of the existing empirical and theoretical studies in neural collapse focus on the case that the number of classes is small relative to the dimension of the feature space. This paper extends neural collapse to cases where the number of classes are much larger than the dimension of feature space, which broadly occur for language models, retrieval systems, and face recognition applications. We show that the features and classifier exhibit a generalized neural collapse phenomenon, where the minimum one-vs-rest margins is maximized.We provide empirical study to verify the occurrence of generalized neural collapse in practical deep neural networks. Moreover, we provide theoretical study to show tha
    
[^89]: 实体推断竞技场：探究LLMs的对话推理和规划能力的平台

    The Entity-Deduction Arena: A playground for probing the conversational reasoning and planning capabilities of LLMs. (arXiv:2310.01468v1 [cs.CL])

    [http://arxiv.org/abs/2310.01468](http://arxiv.org/abs/2310.01468)

    本文提供了一个评估框架，通过向法官提出一系列查询来评估LLMs的对话推理和规划能力。我们发现不同的LLMs在这个任务上表现出显著差异。

    

    目前，大型语言模型（LLMs）在回答明确提问时非常有效。然而，当面临含糊不清的查询时，它们可能行为难以预测并产生错误的输出。这凸显了需要开发能够提出澄清问题以有效解决歧义的智能代理的需求。这种能力需要对多个对话轮次进行复杂的理解、状态跟踪、推理和规划。然而，直接测量这种能力可能具有挑战性。在本文中，我们提供了一个替代性问题，通过向法官提出一系列查询，评估了LLMs推断自己不知道但被法官揭示的实体的能力。这个“实体推断游戏”可以作为一个评估框架，用于探究语言模型的对话推理和规划能力。我们系统地评估了各种LLMs，并发现在这个任务上它们的性能存在显著差异。我们发现强大的LLMs...

    Large language models (LLMs) are currently effective at answering questions that are clearly asked. However, when faced with ambiguous queries they can act unpredictably and produce incorrect outputs. This underscores the need for the development of intelligent agents capable of asking clarification questions to resolve ambiguities effectively. This capability requires complex understanding, state tracking, reasoning and planning over multiple conversational turns. However, directly measuring this can be challenging. In this paper, we offer a surrogate problem which assesses an LLMs's capability to deduce an entity unknown to itself, but revealed to a judge, by asking the judge a series of queries. This \textit{entity-deducing game} can serve as an evaluation framework to probe the conversational reasoning and planning capabilities of language models. We systematically evaluate various LLMs and discover significant differences in their performance on this task. We find that strong LLMs
    
[^90]: LEGO-Prover: 使用不断增长的库进行神经定理证明

    LEGO-Prover: Neural Theorem Proving with Growing Libraries. (arXiv:2310.00656v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2310.00656](http://arxiv.org/abs/2310.00656)

    LEGO-Prover是一个使用不断增长的技能库的神经定理证明方法，可以使语言模型（LLMs）利用现有技能和创造新技能来证明定理。

    

    尽管大型语言模型（LLMs）取得了成功，但定理证明仍然是最难的推理任务之一，尚未完全解决。以往使用语言模型的方法取得了有希望的结果，但仍难以证明中学水平的定理。这些方法的一个常见限制是在整个定理证明过程中假设了一个固定的定理库。然而，众所周知，创造新的有用定理甚至新的理论不仅有帮助而且对于推动数学发展和证明更困难和深入的结果是至关重要和必要的。在这项工作中，我们介绍了LEGO-Prover，它采用一个包含经过验证的引理的不断增长的技能库，以增强用于定理证明的LLMs的能力。通过模块化构建证明，LEGO-Prover使LLMs能够利用从库检索到的现有技能，以及在证明过程中创建新技能。这些技能通过简化证明过程并提供更强大的推理能力。

    Despite the success of large language models (LLMs), the task of theorem proving still remains one of the hardest reasoning tasks that is far from being fully solved. Prior methods using language models have demonstrated promising results, but they still struggle to prove even middle school level theorems. One common limitation of these methods is that they assume a fixed theorem library during the whole theorem proving process. However, as we all know, creating new useful theorems or even new theories is not only helpful but crucial and necessary for advancing mathematics and proving harder and deeper results. In this work, we present LEGO-Prover, which employs a growing skill library containing verified lemmas as skills to augment the capability of LLMs used in theorem proving. By constructing the proof modularly, LEGO-Prover enables LLMs to utilize existing skills retrieved from the library and to create new skills during the proving process. These skills are further evolved (by pro
    
[^91]: 基于复杂网络的框架用于建模和挖掘患者路径

    Framework based on complex networks to model and mine patient pathways. (arXiv:2309.14208v2 [cs.CY] UPDATED)

    [http://arxiv.org/abs/2309.14208](http://arxiv.org/abs/2309.14208)

    该论文提出了一个基于复杂网络的框架，用于建模和挖掘患者路径。该框架包括路径模型、新的相似度测量方法和基于传统中心度的挖掘方法。评估结果表明该框架可有效应用于实际医疗数据分析。

    

    自动发现用于表示一组患者与医疗系统的接触历史的模型，即所谓的“患者路径”，是一项新的研究领域，它支持临床和组织决策，以提高提供的治疗质量和效率。慢性病患者的路径往往因人而异，有重复的任务，并需要分析多个方面（干预、诊断、医疗专业等），影响结果。因此，建模和挖掘这些路径仍然是一个具有挑战性的任务。在这项工作中，我们提出了一个框架，包括：（i）基于多方面图的路径模型，（ii）一种新的相似度测量方法，考虑了耗时，用于比较路径，并且（iii）基于传统中心度测量方法的挖掘方法，用于发现路径中最相关的步骤。我们使用实际医疗数据评估了这个框架。

    The automatic discovery of a model to represent the history of encounters of a group of patients with the healthcare system -- the so-called "pathway of patients" -- is a new field of research that supports clinical and organisational decisions to improve the quality and efficiency of the treatment provided. The pathways of patients with chronic conditions tend to vary significantly from one person to another, have repetitive tasks, and demand the analysis of multiple perspectives (interventions, diagnoses, medical specialities, among others) influencing the results. Therefore, modelling and mining those pathways is still a challenging task. In this work, we propose a framework comprising: (i) a pathway model based on a multi-aspect graph, (ii) a novel dissimilarity measurement to compare pathways taking the elapsed time into account, and (iii) a mining method based on traditional centrality measures to discover the most relevant steps of the pathways. We evaluated the framework using 
    
[^92]: Beta Diffusion. (arXiv:2309.07867v1 [cs.LG])

    Beta Diffusion. (arXiv:2309.07867v1 [cs.LG])

    [http://arxiv.org/abs/2309.07867](http://arxiv.org/abs/2309.07867)

    beta扩散是一种新型生成模型方法，通过引入去掩盖和去噪的技术，利用缩放和偏移的beta分布进行乘法转换，实现在有界范围内生成数据。相比于传统的基于扩散的生成模型，它通过KL散度上界进行优化，证明了效果更好。

    

    我们引入了beta扩散，一种将去掩盖和去噪集成到一起的新型生成建模方法，用于在有界范围内生成数据。使用了缩放和偏移的beta分布，beta扩散利用了随时间的乘法转换来创建正向和反向的扩散过程，同时维持着正向边缘分布和反向条件分布，给定任意时间点的数据。与传统的基于扩散的生成模型不同，传统模型依赖于加性高斯噪声和重新加权的证据下界（ELBO），beta扩散是乘法的，并且通过从KL散度的凸性推导出来的KL散度上界（KLUB）进行优化。我们证明了所提出的KLUB相对于负ELBO来说对于优化beta扩散更加有效，负ELBO也可以作为相同KL散度的KLUB，只是其两个参数交换了位置。beta扩散的损失函数以Bregman散度为指标来表示。

    We introduce beta diffusion, a novel generative modeling method that integrates demasking and denoising to generate data within bounded ranges. Using scaled and shifted beta distributions, beta diffusion utilizes multiplicative transitions over time to create both forward and reverse diffusion processes, maintaining beta distributions in both the forward marginals and the reverse conditionals, given the data at any point in time. Unlike traditional diffusion-based generative models relying on additive Gaussian noise and reweighted evidence lower bounds (ELBOs), beta diffusion is multiplicative and optimized with KL-divergence upper bounds (KLUBs) derived from the convexity of the KL divergence. We demonstrate that the proposed KLUBs are more effective for optimizing beta diffusion compared to negative ELBOs, which can also be derived as the KLUBs of the same KL divergence with its two arguments swapped. The loss function of beta diffusion, expressed in terms of Bregman divergence, furt
    
[^93]: 语法错误修正系统的系统组合的最小贝叶斯风险解码方法

    Minimum Bayes' Risk Decoding for System Combination of Grammatical Error Correction Systems. (arXiv:2309.06520v1 [cs.CL])

    [http://arxiv.org/abs/2309.06520](http://arxiv.org/abs/2309.06520)

    本文提出了一个用于语法错误修正系统系统组合的最小贝叶斯风险解码方法，并通过实验证明了其有效性。

    

    对于序列到序列的任务来说，将各个系统的输出进行组合是一项具有挑战性的工作。同时，解码准则与评估准则之间通常存在不匹配。最小贝叶斯风险（MBR）解码可以用于以更好地与最终评估准则对齐的方式组合系统的输出。本文研究了在语法错误修正（GEC）系统中的MBR解码，该系统通常以编辑次数和相关的F分数来评估性能。因此，我们提出了一种与这种准则直接相关的新颖MBR损失函数。此外，文中还描述了一种扩展候选句子集合的方法。该方法基于当前的最大投票组合方案，以及个体编辑级别的选择。在三个流行的GEC数据集和最先进的GEC系统上进行的实验证明了所提出的MBR方法的有效性。此外，论文还突出了MBR解码中不同奖励指标的变化对结果的影响。

    For sequence-to-sequence tasks it is challenging to combine individual system outputs. Further, there is also often a mismatch between the decoding criterion and the one used for assessment. Minimum Bayes' Risk (MBR) decoding can be used to combine system outputs in a manner that encourages better alignment with the final assessment criterion. This paper examines MBR decoding for Grammatical Error Correction (GEC) systems, where performance is usually evaluated in terms of edits and an associated F-score. Hence, we propose a novel MBR loss function directly linked to this form of criterion. Furthermore, an approach to expand the possible set of candidate sentences is described. This builds on a current max-voting combination scheme, as well as individual edit-level selection. Experiments on three popular GEC datasets and with state-of-the-art GEC systems demonstrate the efficacy of the proposed MBR approach. Additionally, the paper highlights how varying reward metrics within the MBR d
    
[^94]: 基于框架的大型语言模型自由回答的定性分析：算法保真度

    Framework-Based Qualitative Analysis of Free Responses of Large Language Models: Algorithmic Fidelity. (arXiv:2309.06364v1 [cs.CL])

    [http://arxiv.org/abs/2309.06364](http://arxiv.org/abs/2309.06364)

    本文通过定性分析研究了大型语言模型生成的自由回答，重点考察了算法保真度，并提出高算法保真度可以推广到真实人类的观点。这对于使用语言模型研究人类行为具有重要意义。

    

    如今，使用大规模生成式语言模型（LLMs），可以模拟自由回答面试问题，就像传统上使用定性研究方法分析的那样。定性方法涵盖了一系列技术，涉及对开放式访谈或自由进行的自然语言对话的手动分析。本文考虑通过定性方法对LLMs生成的"硅参与者"进行研究，从而产生可能可以推广到真实人群的洞察力。我们分析的关键概念是算法保真度，这是由Argyle等人（2023年）引入的一个术语，用于描述LLM生成的输出与人类亚群体的信念和态度的程度相吻合。根据定义，高算法保真度表明从LLMs中提取的潜在信念可能可以推广到真实人类，而低算法保真度则使得这样的研究无效。本文使用LLM生成面试问答，...

    Today, using Large-scale generative Language Models (LLMs) it is possible to simulate free responses to interview questions like those traditionally analyzed using qualitative research methods. Qualitative methodology encompasses a broad family of techniques involving manual analysis of open-ended interviews or conversations conducted freely in natural language. Here we consider whether artificial "silicon participants" generated by LLMs may be productively studied using qualitative methods aiming to produce insights that could generalize to real human populations. The key concept in our analysis is algorithmic fidelity, a term introduced by Argyle et al. (2023) capturing the degree to which LLM-generated outputs mirror human sub-populations' beliefs and attitudes. By definition, high algorithmic fidelity suggests latent beliefs elicited from LLMs may generalize to real humans, whereas low algorithmic fidelity renders such research invalid. Here we used an LLM to generate interviews wi
    
[^95]: 内存高效的具有4位状态的优化器

    Memory Efficient Optimizers with 4-bit States. (arXiv:2309.01507v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2309.01507](http://arxiv.org/abs/2309.01507)

    本论文通过将优化器状态的位宽压缩至4位，实现了内存高效的训练神经网络。通过对一阶和二阶矩的详细经验分析，我们发现当前的块状量化方法无法准确近似复杂的异常值模式。为此，我们使用较小的块大小并同时利用行上和列上的信息进行更好的量化。此外，我们还通过排除零点的线性量化器解决了量化第二阶矩时的零点问题。我们的工作在多个基准测试上进行了评估，结果表明我们的4位优化器具有出色的性能。

    

    优化器状态是训练神经网络时的主要内存消耗来源，限制了在给定内存预算内可训练的最大模型。将优化器状态从32位浮点数压缩到更低的位宽有望减小训练内存占用，而当前最低可达到的位宽为8位。在这项工作中，我们通过详细的经验分析将优化器状态位宽降至4位。具体而言，我们发现矩具有复杂的异常值模式，无法通过当前的块状量化方法准确近似。我们使用较小的块大小，并提出同时利用行上和列上的信息进行更好的量化。我们还发现了量化第二阶矩时的零点问题，并通过排除零点的线性量化器来解决这个问题。我们的4位优化器在包括自然语言理解、机器翻译在内的各种基准测试上进行了评估。

    Optimizer states are a major source of memory consumption for training neural networks, limiting the maximum trainable model within given memory budget. Compressing the optimizer states from 32-bit floating points to lower bitwidth is promising to reduce the training memory footprint, while the current lowest achievable bitwidth is 8-bit. In this work, we push optimizer states bitwidth down to 4-bit through a detailed empirical analysis of first and second moments. Specifically, we find that moments have complicated outlier patterns, that current block-wise quantization cannot accurately approximate. We use a smaller block size and propose to utilize both row-wise and column-wise information for better quantization. We further identify a zero point problem of quantizing the second moment, and solve this problem with a linear quantizer that excludes the zero point. Our 4-bit optimizer is evaluated on a wide variety of benchmarks including natural language understanding, machine translat
    
[^96]: FairMonitor: 一种检测大型语言模型中刻板印象和偏见的四阶段自动框架

    FairMonitor: A Four-Stage Automatic Framework for Detecting Stereotypes and Biases in Large Language Models. (arXiv:2308.10397v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2308.10397](http://arxiv.org/abs/2308.10397)

    本文引入了一个四阶段框架，可以直接评估大型语言模型（LLMs）生成内容中的刻板印象和偏见，包括直接询问测试、串行或适应性故事测试、隐性关联测试和未知情境测试。此外，还提出了多维评估指标和可解释的零样本提示，并以教育部门为案例研究构建了Edu-FairMonitor框架。

    

    检测大型语言模型（LLMs）中的刻板印象和偏见可以增强公平性并减少这些LLMs应用时对个人或群体的不利影响。然而，现有方法大多关注于测量模型对包含偏见和刻板印象的句子的偏好，这种方法缺乏可解释性且无法检测真实世界中的隐含偏见和刻板印象。为填补这一空白，本文引入了一个四阶段框架，直接评估LLMs生成内容中的刻板印象和偏见，包括直接询问测试、串行或适应性故事测试、隐性关联测试和未知情境测试。此外，本文还提出了多维评估指标和可解释的零样本提示，用于自动评估。以教育部门为案例研究，我们基于这个四阶段框架构建了Edu-FairMonitor，该框架包括12,632个开放式问题，涵盖九个敏感议题。

    Detecting stereotypes and biases in Large Language Models (LLMs) can enhance fairness and reduce adverse impacts on individuals or groups when these LLMs are applied. However, the majority of existing methods focus on measuring the model's preference towards sentences containing biases and stereotypes within datasets, which lacks interpretability and cannot detect implicit biases and stereotypes in the real world. To address this gap, this paper introduces a four-stage framework to directly evaluate stereotypes and biases in the generated content of LLMs, including direct inquiry testing, serial or adapted story testing, implicit association testing, and unknown situation testing. Additionally, the paper proposes multi-dimensional evaluation metrics and explainable zero-shot prompts for automated evaluation. Using the education sector as a case study, we constructed the Edu-FairMonitor based on the four-stage framework, which encompasses 12,632 open-ended questions covering nine sensit
    
[^97]: 将任何你描述的事物分离

    Separate Anything You Describe. (arXiv:2308.05037v1 [eess.AS])

    [http://arxiv.org/abs/2308.05037](http://arxiv.org/abs/2308.05037)

    这项工作介绍了一种用于开放领域音频源分离的基础模型AudioSep，该模型使用自然语言查询，具有强大的分离性能和优秀的泛化能力。

    

    语言查询音频源分离（LASS）是计算听觉场景分析（CASA）中的一种新范 Paradigm。LASS旨在根据自然语言查询从音频混合物中分离目标声音，为数字音频应用提供了一种自然且可扩展的界面。尽管最近在LASS上取得了有希望的分离性能（例如，乐器，有限类别的音频事件），但仍然无法在开放域中分离音频概念。在这项工作中，我们引入了AudioSep，这是一种针对自然语言查询的开放领域音频源分离的基础模型。我们使用大规模多模态数据集训练AudioSep，并对其在许多任务上进行了广泛评估，包括音频事件分离，乐器分离和语音增强。AudioSep表现出强大的分离性能和令人印象深刻的零-shot泛化能力，使用音频标题或文字标签作为查询，明显优于其他方法。

    Language-queried audio source separation (LASS) is a new paradigm for computational auditory scene analysis (CASA). LASS aims to separate a target sound from an audio mixture given a natural language query, which provides a natural and scalable interface for digital audio applications. Recent works on LASS, despite attaining promising separation performance on specific sources (e.g., musical instruments, limited classes of audio events), are unable to separate audio concepts in the open domain. In this work, we introduce AudioSep, a foundation model for open-domain audio source separation with natural language queries. We train AudioSep on large-scale multimodal datasets and extensively evaluate its capabilities on numerous tasks including audio event separation, musical instrument separation, and speech enhancement. AudioSep demonstrates strong separation performance and impressive zero-shot generalization ability using audio captions or text labels as queries, substantially outperfor
    
[^98]: Thinker: 学习规划和行动

    Thinker: Learning to Plan and Act. (arXiv:2307.14993v1 [cs.AI])

    [http://arxiv.org/abs/2307.14993](http://arxiv.org/abs/2307.14993)

    Thinker算法通过引入世界模型和模型交互动作使强化学习代理实现自主规划，消除了手工设计规划算法的需求，并且在Sokoban游戏和Atari 2600基准测试中取得了state-of-the-art的性能。

    

    我们提出了Thinker算法，一种新颖的方法，使强化学习代理能够自主地与学习的世界模型进行交互并利用其。 Thinker算法通过给环境添加世界模型来改变环境，并引入了用于与世界模型交互的新动作。这些模型交互动作使代理能够通过在选择最终的环境动作之前向世界模型提出备选计划来进行规划。该方法通过使代理自主学习如何进行规划来消除了手工设计的规划算法的需求，并且允许对代理的计划进行易于解释的可视化。我们通过Sokoban游戏和Atari 2600基准测试的实验结果证明了该算法的有效性，其中Thinker算法分别实现了最先进的性能和有竞争力的结果。使用Thinker算法训练的代理的可视化结果表明，它们已经学到了优秀的规划策略。

    We propose the Thinker algorithm, a novel approach that enables reinforcement learning agents to autonomously interact with and utilize a learned world model. The Thinker algorithm wraps the environment with a world model and introduces new actions designed for interacting with the world model. These model-interaction actions enable agents to perform planning by proposing alternative plans to the world model before selecting a final action to execute in the environment. This approach eliminates the need for hand-crafted planning algorithms by enabling the agent to learn how to plan autonomously and allows for easy interpretation of the agent's plan with visualization. We demonstrate the algorithm's effectiveness through experimental results in the game of Sokoban and the Atari 2600 benchmark, where the Thinker algorithm achieves state-of-the-art performance and competitive results, respectively. Visualizations of agents trained with the Thinker algorithm demonstrate that they have lear
    
[^99]: TMR-RD: 用于半监督目标检测的基于训练的模型精化和表示分歧方法

    TMR-RD: Training-based Model Refinement and Representation Disagreement for Semi-Supervised Object Detection. (arXiv:2307.13755v1 [cs.CV])

    [http://arxiv.org/abs/2307.13755](http://arxiv.org/abs/2307.13755)

    在半监督目标检测中，本文提出了基于训练的模型精化(TMR)阶段和表示分歧(RD)策略，用来解决伪标签噪声和教师-学生模型的一致性问题。TMR阶段通过轻量级缩放操作优化模型权重，防止过度拟合或遗忘学到的模式；RD策略帮助保持模型的差异，鼓励学生模型探索互补的表示。

    

    半监督目标检测(SSOD)可以将有限的标记数据和大量的未标记数据结合起来，提高现有目标检测器的性能和泛化能力。尽管取得了许多进展，但是最近的SSOD方法仍然面临着伪标签噪声/误导、经典指数移动平均(EMA)策略和后期训练中教师-学生模型的一致性等挑战。本文提出了一种新颖的基于训练的模型精化(TMR)阶段和简单而有效的表示分歧(RD)策略，以解决经典EMA的局限性和一致性问题。教师-学生模型的TMR阶段优化了轻量级缩放操作，以精化模型的权重，并防止过度拟合或遗忘从未标记数据中学到的模式。同时，RD策略帮助保持这些模型的差异，鼓励学生模型探索互补的表示。此外，我们使用级连回归来生成... (摘要未完整提供)

    Semi-supervised object detection (SSOD) can incorporate limited labeled data and large amounts of unlabeled data to improve the performance and generalization of existing object detectors. Despite many advances, recent SSOD methods are still challenged by noisy/misleading pseudo-labels, classical exponential moving average (EMA) strategy, and the consensus of Teacher-Student models in the latter stages of training. This paper proposes a novel training-based model refinement (TMR) stage and a simple yet effective representation disagreement (RD) strategy to address the limitations of classical EMA and the consensus problem. The TMR stage of Teacher-Student models optimizes the lightweight scaling operation to refine the model's weights and prevent overfitting or forgetting learned patterns from unlabeled data. Meanwhile, the RD strategy helps keep these models diverged to encourage the student model to explore complementary representations. In addition, we use cascade regression to gene
    
[^100]: HYTREL: 基于超图的表格数据表示学习

    HYTREL: Hypergraph-enhanced Tabular Data Representation Learning. (arXiv:2307.08623v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2307.08623](http://arxiv.org/abs/2307.08623)

    HYTREL是一种表格语言模型，通过使用超图来捕捉表格数据的排列不变性和其他三个结构属性。实证结果表明，HYTREL在四个下游任务中始终优于其他竞争基线模型，并且只需最少的预训练。

    

    在许多下游任务中，预训练在大量表格数据集上的语言模型都证明了其有效性。然而，许多模型并没有考虑到表格数据中存在的行/列排列不变性、分层结构等。为了缓解这些限制，我们提出了一种名为HYTREL的表格语言模型，通过使用超图来捕捉表格数据的排列不变性和其他三个结构属性——其中，表格单元格构成节点，并且在每行、每列和整个表格中共同出现的单元格被用来形成三种不同类型的超边。我们展示了HYTREL在特定条件下对于表格数据是最大不变的，即，两个表格通过HYTREL获得的表示相同，当且仅当这两个表格在排列上是相同的。我们的实证结果表明，HYTREL在四个下游任务中始终优于其他竞争基线模型，并且只需最少的预训练。

    Language models pretrained on large collections of tabular data have demonstrated their effectiveness in several downstream tasks. However, many of these models do not take into account the row/column permutation invariances, hierarchical structure, etc. that exist in tabular data. To alleviate these limitations, we propose HYTREL, a tabular language model, that captures the permutation invariances and three more structural properties of tabular data by using hypergraphs - where the table cells make up the nodes and the cells occurring jointly together in each row, column, and the entire table are used to form three different types of hyperedges. We show that HYTREL is maximally invariant under certain conditions for tabular data, i.e., two tables obtain the same representations via HYTREL iff the two tables are identical up to permutations. Our empirical results demonstrate that HYTREL consistently outperforms other competitive baselines on four downstream tasks with minimal pretraini
    
[^101]: 视频焦点网络：用于视频动作识别的时空焦点调制

    Video-FocalNets: Spatio-Temporal Focal Modulation for Video Action Recognition. (arXiv:2307.06947v1 [cs.CV])

    [http://arxiv.org/abs/2307.06947](http://arxiv.org/abs/2307.06947)

    本论文提出了一种名为视频焦点网络的视频识别架构，通过时空焦点调制来模拟局部和全局上下文，结合了Transformer和卷积设计的优点，既有效又高效。

    

    最近的视频识别模型利用Transformer模型进行长距离时空上下文建模。视频Transformer设计基于自注意力，可以以高计算成本模拟全局上下文。相比之下，用于视频的卷积设计提供了一种高效的替代方法，但缺乏长距离依赖建模。为了实现这两种设计的最佳效果，本研究提出了视频焦点网络（Video-FocalNet），这是一种既有效又高效的视频识别架构，可以模拟局部和全局上下文。视频焦点网络基于时空焦点调制架构，对自注意力的交互和聚合步骤进行了颠倒，以提高效率。此外，聚合步骤和交互步骤都使用了高效的卷积和逐元素乘法操作来实现，其计算成本比视频表达中的自注意力对应部分要低得多。我们广泛探索了焦点调制的设计空间。

    Recent video recognition models utilize Transformer models for long-range spatio-temporal context modeling. Video transformer designs are based on self-attention that can model global context at a high computational cost. In comparison, convolutional designs for videos offer an efficient alternative but lack long-range dependency modeling. Towards achieving the best of both designs, this work proposes Video-FocalNet, an effective and efficient architecture for video recognition that models both local and global contexts. Video-FocalNet is based on a spatio-temporal focal modulation architecture that reverses the interaction and aggregation steps of self-attention for better efficiency. Further, the aggregation step and the interaction step are both implemented using efficient convolution and element-wise multiplication operations that are computationally less expensive than their self-attention counterparts on video representations. We extensively explore the design space of focal modu
    
[^102]: 带有乘法平滑的特征归因稳定性保证

    Stability Guarantees for Feature Attributions with Multiplicative Smoothing. (arXiv:2307.05902v1 [cs.LG])

    [http://arxiv.org/abs/2307.05902](http://arxiv.org/abs/2307.05902)

    本文提出了一种基于乘法平滑的特征归因方法，通过证明模型的Lipschitz性质，保证了其稳定性，并在视觉和语言模型上进行了评估，显示了非平凡的稳定性保证。

    

    机器学习模型的解释方法往往不能提供任何形式的保证，也可能不反映底层的决策过程。在这项工作中，我们将稳定性作为可靠的特征归因方法的一个属性进行分析。我们证明了如果模型在特征屏蔽方面具有足够的Lipschitz性质，则可以保证放松变体的稳定性。为了实现这样的模型，我们开发了一种称为乘法平滑（MuS）的平滑方法。我们展示了MuS克服了标准平滑技术的理论限制，并且可以与任何分类器和特征归因方法结合使用。我们使用各种特征归因方法（如LIME和SHAP）对视觉和语言模型进行了MuS的评估，并展示了MuS赋予了特征归因以非平凡的稳定性保证。

    Explanation methods for machine learning models tend to not provide any formal guarantees and may not reflect the underlying decision-making process. In this work, we analyze stability as a property for reliable feature attribution methods. We prove that relaxed variants of stability are guaranteed if the model is sufficiently Lipschitz with respect to the masking of features. To achieve such a model, we develop a smoothing method called Multiplicative Smoothing (MuS). We show that MuS overcomes theoretical limitations of standard smoothing techniques and can be integrated with any classifier and feature attribution method. We evaluate MuS on vision and language models with a variety of feature attribution methods, such as LIME and SHAP, and demonstrate that MuS endows feature attributions with non-trivial stability guarantees.
    
[^103]: DebateKG: 用语义知识图自动创建政策辩论案例

    DebateKG: Automatic Policy Debate Case Creation with Semantic Knowledge Graphs. (arXiv:2307.04090v1 [cs.CL])

    [http://arxiv.org/abs/2307.04090](http://arxiv.org/abs/2307.04090)

    本论文提出了一种利用语义知识图自动创建政策辩论案例的方法，通过在争论的语义知识图上进行限制最短路径遍历，有效构建高质量的辩论案例。研究结果表明，在美国竞赛辩论中，利用这种方法显著改进了已有数据集DebateSum，并贡献了新的例子和有用的元数据。通过使用txtai语义搜索和知识图工具链，创建和贡献了9个语义知识图，同时提出了一种独特的评估方法来确定哪个知识图更适合政策辩论案例生成。

    

    近期相关工作表明，自然语言处理系统在解决竞赛辩论中的问题方面具有应用性。竞赛辩论中最重要的任务之一是辩手创建高质量的辩论案例。我们展示了使用限制最短路径遍历在争论的语义知识图上构建有效的辩论案例的方法。我们在一个名为DebateSum的大规模数据集上研究了这种潜力，该数据集针对的是一种名为政策辩论的美国竞赛辩论类型。我们通过向数据集中引入53180个新的例子，并为每个例子提供进一步有用的元数据，显著改进了DebateSum。我们利用txtai语义搜索和知识图工具链基于这个数据集产生并贡献了9个语义知识图。我们创建了一种独特的评估方法，以确定在政策辩论案例生成的背景下哪个知识图更好。

    Recent work within the Argument Mining community has shown the applicability of Natural Language Processing systems for solving problems found within competitive debate. One of the most important tasks within competitive debate is for debaters to create high quality debate cases. We show that effective debate cases can be constructed using constrained shortest path traversals on Argumentative Semantic Knowledge Graphs. We study this potential in the context of a type of American Competitive Debate, called Policy Debate, which already has a large scale dataset targeting it called DebateSum. We significantly improve upon DebateSum by introducing 53180 new examples, as well as further useful metadata for every example, to the dataset. We leverage the txtai semantic search and knowledge graph toolchain to produce and contribute 9 semantic knowledge graphs built on this dataset. We create a unique method for evaluating which knowledge graphs are better in the context of producing policy deb
    
[^104]: 通过不连续网络实现深层合同设计

    Deep Contract Design via Discontinuous Networks. (arXiv:2307.02318v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2307.02318](http://arxiv.org/abs/2307.02318)

    本文通过不连续ReLU网络实现了深层合同设计，通过学习代理人和委托人的约束和目标的闭合形式表达，支持并行推断以求解最优合同。

    

    合同设计涉及一个委托人对由代理人的行动产生的结果支付的合同约定。在本文中，我们开始研究深度学习对最优合同自动设计的应用。我们引入了一种新颖的表示方法：不连续ReLU（DeLU）网络，它将委托人的效用建模为合同设计的不连续分段仿射函数，其中每个分段对应于代理人采取特定的行动。DeLU网络通过线性规划或内点方法隐式学习代理人的激励相容约束和委托人的效用最大化目标的闭合形式表达，并支持每个分段的并行推断以求解最优合同。我们提供了经验结果，证明了使用少量训练样本近似委托人效用函数并扩展以找到近似最优合同的成功。

    Contract design involves a principal who establishes contractual agreements about payments for outcomes that arise from the actions of an agent. In this paper, we initiate the study of deep learning for the automated design of optimal contracts. We introduce a novel representation: the Discontinuous ReLU (DeLU) network, which models the principal's utility as a discontinuous piecewise affine function of the design of a contract where each piece corresponds to the agent taking a particular action. DeLU networks implicitly learn closed-form expressions for the incentive compatibility constraints of the agent and the utility maximization objective of the principal, and support parallel inference on each piece through linear programming or interior-point methods that solve for optimal contracts. We provide empirical results that demonstrate success in approximating the principal's utility function with a small number of training samples and scaling to find approximately optimal contracts o
    
[^105]: SageFormer：面向多变量时间序列预测的系列感知图增强Transformer

    SageFormer: Series-Aware Graph-Enhanced Transformers for Multivariate Time Series Forecasting. (arXiv:2307.01616v1 [cs.LG])

    [http://arxiv.org/abs/2307.01616](http://arxiv.org/abs/2307.01616)

    本文介绍了SageFormer，一种面向多变量时间序列预测的系列感知图增强Transformer模型，通过图结构有效捕捉和建模序列之间的依赖关系，在表示不同序列中的时间模式和减少序列间冗余信息等方面取得了优越性能。

    

    多变量时间序列预测在各个领域起着至关重要的作用。虽然近期深度学习方法，特别是Transformer，展示了很大的潜力，但在解决跨序列依赖性的重要性问题上仍存在差距。本文介绍了SageFormer，一种系列感知图增强Transformer模型，旨在使用图结构有效捕捉和建模序列之间的依赖关系。SageFormer解决了两个关键挑战：有效地表示不同序列中的时间模式以及减少序列之间的冗余信息。重要的是，所提议的系列感知框架可以无缝集成到现有的基于Transformer的模型中，增强了模型对跨序列依赖性的建模能力。通过对真实世界和合成数据集进行广泛的实验证明，SageFormer相比先前的最先进方法展示出了优越的性能。

    Multivariate time series forecasting plays a critical role in diverse domains. While recent advancements in deep learning methods, especially Transformers, have shown promise, there remains a gap in addressing the significance of inter-series dependencies. This paper introduces SageFormer, a Series-aware Graph-enhanced Transformer model designed to effectively capture and model dependencies between series using graph structures. SageFormer tackles two key challenges: effectively representing diverse temporal patterns across series and mitigating redundant information among series. Importantly, the proposed series-aware framework seamlessly integrates with existing Transformer-based models, augmenting their ability to model inter-series dependencies. Through extensive experiments on real-world and synthetic datasets, we showcase the superior performance of SageFormer compared to previous state-of-the-art approaches.
    
[^106]: LeanDojo: 检索增强语言模型的定理证明

    LeanDojo: Theorem Proving with Retrieval-Augmented Language Models. (arXiv:2306.15626v1 [cs.LG])

    [http://arxiv.org/abs/2306.15626](http://arxiv.org/abs/2306.15626)

    本文引入了LeanDojo，该工具通过提取Lean的数据，为定理证明研究提供了一个开放源代码的平台。利用LeanDojo的数据，开发了ReProver，它是第一个使用检索增强的语言模型的证明器，可以从庞大的数学库中选择命题，训练成本低，并且只需要一周的GPU训练时间。

    

    大型语言模型（LLM）已经显示出在使用Lean等证明助手证明形式定理方面的潜力。然而，由于私有代码、数据和大量计算要求，现有的方法很难复制或建立在其基础上，这给定理证明的机器学习方法的研究带来了巨大的障碍。本文通过引入LeanDojo来消除这些障碍：一个包含工具包、数据、模型和基准测试的开放源代码的Lean游乐场。LeanDojo从Lean中提取数据，并使得可以通过编程与证明环境进行交互。它包含证明中命题的细粒度注释，为命题选择提供了有价值的数据：这是定理证明中的一个关键瓶颈。利用这些数据，我们开发出了ReProver（检索增强的证明器）：它是第一个使用LLM的证明器，通过检索从庞大的数学库中选择命题。它成本低廉，只需要一周的GPU训练时间。我们的检索器利用了LeanDojo的pro相关功能。

    Large language models (LLMs) have shown promise in proving formal theorems using proof assistants such as Lean. However, existing methods are difficult to reproduce or build on, due to private code, data, and large compute requirements. This has created substantial barriers to research on machine learning methods for theorem proving. This paper removes these barriers by introducing LeanDojo: an open-source Lean playground consisting of toolkits, data, models, and benchmarks. LeanDojo extracts data from Lean and enables interaction with the proof environment programmatically. It contains fine-grained annotations of premises in proofs, providing valuable data for premise selection: a key bottleneck in theorem proving. Using this data, we develop ReProver (Retrieval-Augmented Prover): the first LLM-based prover that is augmented with retrieval for selecting premises from a vast math library. It is inexpensive and needs only one GPU week of training. Our retriever leverages LeanDojo's prog
    
[^107]: TACO：基于时间潜在动作驱动对比损失的视觉强化学习

    TACO: Temporal Latent Action-Driven Contrastive Loss for Visual Reinforcement Learning. (arXiv:2306.13229v1 [cs.LG])

    [http://arxiv.org/abs/2306.13229](http://arxiv.org/abs/2306.13229)

    本文提出了TACO方法，一种基于时间潜在动作驱动对比损失的视觉强化学习方法，能够同时学习状态表示和动作表示，提高代理学习的效率。

    

    尽管在强化学习（RL）从原始像素数据中取得了最近的进展，但样本效率仍然是一个重要的障碍。先前的工作试图通过创建自监督辅助任务来解决这个挑战，旨在为未来状态预测丰富代理学习的表示与控制相关信息。然而，这些目标通常不足以学习能够表示最优策略或值函数的表示，并且它们通常考虑具有小的抽象离散动作空间的任务，因此忽视了在连续控制中动作表示学习的重要性。在本文中，我们引入了TACO：一种简单而强大的时间对比学习方法，利用它，代理可以同时获得潜在状态和动作表示。TACO通过优化重新获得观察与最近的多个先前观察的相似性，同时学习状态与动作表示。

    Despite recent progress in reinforcement learning (RL) from raw pixel data, sample inefficiency continues to present a substantial obstacle. Prior works have attempted to address this challenge by creating self-supervised auxiliary tasks, aiming to enrich the agent's learned representations with control-relevant information for future state prediction. However, these objectives are often insufficient to learn representations that can represent the optimal policy or value function, and they often consider tasks with small, abstract discrete action spaces and thus overlook the importance of action representation learning in continuous control. In this paper, we introduce TACO: Temporal Action-driven Contrastive Learning, a simple yet powerful temporal contrastive learning approach that facilitates the concurrent acquisition of latent state and action representations for agents. TACO simultaneously learns a state and an action representation by optimizing the mutual information between re
    
[^108]: 智能体的基因

    Genes in Intelligent Agents. (arXiv:2306.10225v2 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2306.10225](http://arxiv.org/abs/2306.10225)

    该论文提出了基于基因的强化学习（GRL）框架，通过模拟有机体的进化和利用学习基因来学习和演化智能体。实验证明了GRL在智能体训练中的有效性。

    

    在自然界中，基因通过数十亿年的传递和积累，赋予地球上生物的当前生物智能。受到生物智能的启发，人工智能（AI）致力于构建机器智能。尽管取得了繁荣的成功，但机器智能仍远远落后于生物智能。原因可能在于动物天生具有某种基因编码的智能，而机器缺乏此类智能，需要从头学习。受到动物基因的启发，我们定义了机器的“基因”，称为“学习基因”，并提出了遗传增强学习（GRL）。GRL是一个计算框架，模拟了强化学习（RL）中有机体的进化，并利用学习基因来学习和演化智能体。利用GRL，我们首先证明了学习基因采用了智能体神经网络的片段形式，并且可以继承。这通过实验验证了GRL在智能体训练中的有效性。

    The genes in nature give the lives on earth the current biological intelligence through transmission and accumulation over billions of years. Inspired by the biological intelligence, artificial intelligence (AI) has devoted to building the machine intelligence. Although it has achieved thriving successes, the machine intelligence still lags far behind the biological intelligence. The reason may lie in that animals are born with some intelligence encoded in their genes, but machines lack such intelligence and learn from scratch. Inspired by the genes of animals, we define the ``genes'' of machines named as the ``learngenes'' and propose the Genetic Reinforcement Learning (GRL). GRL is a computational framework that simulates the evolution of organisms in reinforcement learning (RL) and leverages the learngenes to learn and evolve the intelligence agents. Leveraging GRL, we first show that the learngenes take the form of the fragments of the agents' neural networks and can be inherited a
    
[^109]: Katakomba：用于数据驱动NetHack的工具和基准

    Katakomba: Tools and Benchmarks for Data-Driven NetHack. (arXiv:2306.08772v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.08772](http://arxiv.org/abs/2306.08772)

    本论文开发了一个用于数据驱动NetHack的工具和基准库，旨在解决资源、实现和基准方面的障碍。该库提供了ORL社区所熟悉的工作流基础，并附带可靠的评估工具。

    

    NetHack被认为是强化学习研究的前沿，其中基于学习的方法仍需赶上基于规则的解决方案。通过使用类似于机器人技术、推荐系统等领域最新发展中的预先收集的数据集，离线强化学习（ORL）成为突破的一个有希望的方向。最近，一个大规模的NetHack数据集被释放出，虽然这是向前迈出的必要一步，但它尚未在ORL社区中得到广泛应用。在这项工作中，我们认为有三个主要障碍需要克服：资源、实现和基准。为了解决这些问题，我们开发了一个开源库，提供了ORL社区熟悉的工作流基础：预定义的D4RL风格任务，简洁的基准实现，以及可靠的评估工具，并附有与云端同步的配置和日志。

    NetHack is known as the frontier of reinforcement learning research where learning-based methods still need to catch up to rule-based solutions. One of the promising directions for a breakthrough is using pre-collected datasets similar to recent developments in robotics, recommender systems, and more under the umbrella of offline reinforcement learning (ORL). Recently, a large-scale NetHack dataset was released; while it was a necessary step forward, it has yet to gain wide adoption in the ORL community. In this work, we argue that there are three major obstacles for adoption: resource-wise, implementation-wise, and benchmark-wise. To address them, we develop an open-source library that provides workflow fundamentals familiar to the ORL community: pre-defined D4RL-style tasks, uncluttered baseline implementations, and reliable evaluation tools with accompanying configs and logs synced to the cloud.
    
[^110]: 通过正交微调控制文本到图像的扩散

    Controlling Text-to-Image Diffusion by Orthogonal Finetuning. (arXiv:2306.07280v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2306.07280](http://arxiv.org/abs/2306.07280)

    本文介绍了一种名为正交微调（OFT）的方法，可以有效地引导和控制大型文本到图像扩散模型，以执行不同的下游任务。我们还提出了约束正交微调（COFT），来提高微调的稳定性。这些方法能够保持语义生成能力并生成特定主题的图像。

    

    大型文本到图像扩散模型在生成真实感图像方面有很强的能力。如何有效地引导或控制这些强大的模型以执行不同的下游任务成为一个重要的开放性问题。为了解决这个挑战，我们引入了一种基于原则的微调方法——正交微调（OFT），用于将文本到图像扩散模型调整到下游任务中。与现有方法不同，OFT可以证明地保持特征对神经元在单位超球面上的关系所表征的超球形能量。我们发现，这种属性对于保持文本到图像扩散模型的语义生成能力非常关键。为了提高微调的稳定性，我们进一步提出了约束正交微调（COFT），它对超球面施加了额外的半径约束。具体来说，我们考虑了两个重要的微调文本到图像任务：主题驱动生成，目标是生成特定主题的图像

    Large text-to-image diffusion models have impressive capabilities in generating photorealistic images from text prompts. How to effectively guide or control these powerful models to perform different downstream tasks becomes an important open problem. To tackle this challenge, we introduce a principled finetuning method -- Orthogonal Finetuning (OFT), for adapting text-to-image diffusion models to downstream tasks. Unlike existing methods, OFT can provably preserve hyperspherical energy which characterizes the pairwise neuron relationship on the unit hypersphere. We find that this property is crucial for preserving the semantic generation ability of text-to-image diffusion models. To improve finetuning stability, we further propose Constrained Orthogonal Finetuning (COFT) which imposes an additional radius constraint to the hypersphere. Specifically, we consider two important finetuning text-to-image tasks: subject-driven generation where the goal is to generate subject-specific images
    
[^111]: 用函数逼近解决强化学习中重尾奖励问题的极小最大化算法和实例相关遗憾度量

    Tackling Heavy-Tailed Rewards in Reinforcement Learning with Function Approximation: Minimax Optimal and Instance-Dependent Regret Bounds. (arXiv:2306.06836v1 [cs.LG])

    [http://arxiv.org/abs/2306.06836](http://arxiv.org/abs/2306.06836)

    本文解决了强化学习中当奖励呈“重尾”分布时的问题，提出了第一种处理这种情况的实例相关算法，并得到了极小最大化的遗憾界。

    

    虽然有许多工作都专注于为有界奖励的强化学习设计有效算法，但当奖励呈现“重尾”分布时——即存在某个 $\epsilon\in(0,1]$ 使得仅有有限的$(1+\epsilon)$-阶矩——是否存在对大状态-动作空间进行采样或时效性算法仍然是一个未解决的问题。 在本文中，我们解决了具有线性函数逼近的 RL 中的这种奖励机制的挑战。我们首先为重尾线性赌臂设计了一种算法——\textsc{Heavy-OFUL}，其实现了一种实例相关的 $T$-round 遗憾度量，为 $\tilde{O}\big(d T^{\frac{1-\epsilon}{2(1+\epsilon)}} \sqrt{\sum_{t=1}^T \nu_t^2} + d T^{\frac{1-\epsilon}{2(1+\epsilon)}}\big)$，这是这种类型的\emph{第一篇}文章。$\nu_t^{1+\epsilon}$是第 $t$ 轮奖励的 $(1+\epsilon)$-阶中心矩。我们进一步证明了在应用于 st 的最坏情况时，上述界是极小值的最优解。

    While numerous works have focused on devising efficient algorithms for reinforcement learning (RL) with uniformly bounded rewards, it remains an open question whether sample or time-efficient algorithms for RL with large state-action space exist when the rewards are \emph{heavy-tailed}, i.e., with only finite $(1+\epsilon)$-th moments for some $\epsilon\in(0,1]$. In this work, we address the challenge of such rewards in RL with linear function approximation. We first design an algorithm, \textsc{Heavy-OFUL}, for heavy-tailed linear bandits, achieving an \emph{instance-dependent} $T$-round regret of $\tilde{O}\big(d T^{\frac{1-\epsilon}{2(1+\epsilon)}} \sqrt{\sum_{t=1}^T \nu_t^2} + d T^{\frac{1-\epsilon}{2(1+\epsilon)}}\big)$, the \emph{first} of this kind. Here, $d$ is the feature dimension, and $\nu_t^{1+\epsilon}$ is the $(1+\epsilon)$-th central moment of the reward at the $t$-th round. We further show the above bound is minimax optimal when applied to the worst-case instances in st
    
[^112]: 在表面之下寻找：利用基本对称性实现高效离线强化学习

    Look Beneath the Surface: Exploiting Fundamental Symmetry for Sample-Efficient Offline RL. (arXiv:2306.04220v1 [cs.LG])

    [http://arxiv.org/abs/2306.04220](http://arxiv.org/abs/2306.04220)

    本文提出了一个新的离线强化学习算法TDM，利用系统动力学的基本对称性实现高效学习小数据集。

    

    离线强化学习通过从预先收集的数据集中学习策略来解决与环境交互的实际问题。然而，现有的离线强化学习算法的性能严重依赖于数据集的规模和状态-动作空间覆盖范围。真实世界数据的收集通常是昂贵和难以控制的，导致数据集小且覆盖范围狭窄，从而对离线强化学习的实际部署提出了重大挑战。在本文中，我们提供了一个新的见解，即利用系统动力学的基本对称性可以在小数据集下显著提高离线强化学习的性能。具体来说，我们提出了一个时间反演对称(T-symmetry)强制的动力学模型(TDM)，建立了一对正向和反向潜在动力学之间的一致性。TDM为小数据集提供了良好的表示，并基于T-symmetry的符合性提供了一种新的OOD样本的可靠性度量。

    Offline reinforcement learning (RL) offers an appealing approach to real-world tasks by learning policies from pre-collected datasets without interacting with the environment. However, the performance of existing offline RL algorithms heavily depends on the scale and state-action space coverage of datasets. Real-world data collection is often expensive and uncontrollable, leading to small and narrowly covered datasets and posing significant challenges for practical deployments of offline RL. In this paper, we provide a new insight that leveraging the fundamental symmetry of system dynamics can substantially enhance offline RL performance under small datasets. Specifically, we propose a Time-reversal symmetry (T-symmetry) enforced Dynamics Model (TDM), which establishes consistency between a pair of forward and reverse latent dynamics. TDM provides both well-behaved representations for small datasets and a new reliability measure for OOD samples based on compliance with the T-symmetry. 
    
[^113]: 基于双模式对比学习的H&E组织学图像基因表达预测

    Spatially Resolved Gene Expression Prediction from H&E Histology Images via Bi-modal Contrastive Learning. (arXiv:2306.01859v1 [cs.CV])

    [http://arxiv.org/abs/2306.01859](http://arxiv.org/abs/2306.01859)

    本文提出了BLEEP框架，通过对比学习构建联合嵌入空间，能够从H&E染色组织学图像中生成空间分辨率的基因表达谱地图，具有很高的有效性。

    

    组织学成像是医学诊断和研究的重要工具，能够在微观水平上检查组织结构和组成。了解组织结构的基本分子机制对揭示疾病机制和开发有效治疗方法至关重要。基因表达谱提供了深入了解组织结构背后分子过程的视角，但这一过程耗时且昂贵。在本研究中，我们提出了一种名为BLEEP（Bi-modaL Embedding for Expression Prediction）的双模式嵌入框架，能够从全幅苏木精-伊红（H&E）染色组织学图像中生成空间分辨率的基因表达谱图，并通过对比学习框架在微米分辨率下使用成对的图像和表达谱来构建低维联合嵌入空间的。通过这个框架，可用周围图像的背景上下文推断出任何查询图像补丁的基因表达，从而实现了空间分辨率的基因表达谱地图的生成。我们在四种不同组织类型上展示了BLEEP的有效性，在性能上达到了与最先进的方法竞争的水平。

    Histology imaging is an important tool in medical diagnosis and research, enabling the examination of tissue structure and composition at the microscopic level. Understanding the underlying molecular mechanisms of tissue architecture is critical in uncovering disease mechanisms and developing effective treatments. Gene expression profiling provides insight into the molecular processes underlying tissue architecture, but the process can be time-consuming and expensive. In this study, we present BLEEP (Bi-modaL Embedding for Expression Prediction), a bi-modal embedding framework capable of generating spatially resolved gene expression profiles of whole-slide Hematoxylin and eosin (H&E) stained histology images. BLEEP uses a contrastive learning framework to construct a low-dimensional joint embedding space from a reference dataset using paired image and expression profiles at micrometer resolution. With this framework, the gene expression of any query image patch can be imputed using the
    
[^114]: 合并模型时如何解决干扰的问题

    Resolving Interference When Merging Models. (arXiv:2306.01708v1 [cs.LG])

    [http://arxiv.org/abs/2306.01708](http://arxiv.org/abs/2306.01708)

    本文揭示了现有模型合并技术存在的干扰问题，提出了具有广泛适用性的解决方案，可显着提高合并后模型的性能。

    

    迁移学习可以在下游任务中进一步微调预训练模型，从而获得显著的优势，包括改进下游性能，加快收敛速度和提高样本效率。然而，已有的模型合并技术往往忽视了不同模型参数之间的干扰，导致合并多个模型时性能大幅下降。本文证明，先前的合并技术由于两个主要干扰来源而不慎丢失有价值的信息：(a)冗余参数值引起的干扰和(b)表示同一参数值的符号在不同模型中的差异。

    Transfer learning - i.e., further fine-tuning a pre-trained model on a downstream task - can confer significant advantages, including improved downstream performance, faster convergence, and better sample efficiency. These advantages have led to a proliferation of task-specific fine-tuned models, which typically can only perform a single task and do not benefit from one another. Recently, model merging techniques have emerged as a solution to combine multiple task-specific models into a single multitask model without performing additional training. However, existing merging methods often ignore the interference between parameters of different models, resulting in large performance drops when merging multiple models. In this paper, we demonstrate that prior merging techniques inadvertently lose valuable information due to two major sources of interference: (a) interference due to redundant parameter values and (b) disagreement on the sign of a given parameter's values across models. To 
    
[^115]: “思维克隆：通过模仿人类思维学习思考并行动”。（arXiv:2306.00323v1 [cs.AI]）

    Thought Cloning: Learning to Think while Acting by Imitating Human Thinking. (arXiv:2306.00323v1 [cs.AI])

    [http://arxiv.org/abs/2306.00323](http://arxiv.org/abs/2306.00323)

    本论文提出了一种新的模仿学习框架“思维克隆”，通过学习人类的思维来训练AI代理，以在泛化、探索、规划等能力方面实现更好的表现。

    

    语言通常被认为是人类思维的一个关键方面，它为我们提供了非凡的泛化、探索、规划、重新规划和适应新情况的能力。然而，强化学习（RL）代理在这些能力中远未达到人类水平的表现。我们假设其中一个认知缺陷的原因是他们缺乏使用语言思考所带来的好处。我们认为通过训练AI代理人像人类一样思考，可以改善其性能。我们引入了一种新的模仿学习框架“思维克隆”，其想法不仅是克隆人类示范者的行为，而且还包括人类在执行这些行为时所产生的想法。虽然我们希望“思维克隆”在处理网络规模的人类思维和行为数据时能够发挥出色（例如，带有剧本的在线视频），但在这里，我们进行了在思考和行动数据为合成生成的领域的实验。结果显示，“思维克隆”学习速度比传统的强化学习方法快得多。

    Language is often considered a key aspect of human thinking, providing us with exceptional abilities to generalize, explore, plan, replan, and adapt to new situations. However, Reinforcement Learning (RL) agents are far from human-level performance in any of these abilities. We hypothesize one reason for such cognitive deficiencies is that they lack the benefits of thinking in language and that we can improve AI agents by training them to think like humans do. We introduce a novel Imitation Learning framework, Thought Cloning, where the idea is to not just clone the behaviors of human demonstrators, but also the thoughts humans have as they perform these behaviors. While we expect Thought Cloning to truly shine at scale on internet-sized datasets of humans thinking out loud while acting (e.g. online videos with transcripts), here we conduct experiments in a domain where the thinking and action data are synthetically generated. Results reveal that Thought Cloning learns much faster than
    
[^116]: 截断亲和力最大化：用于图形异常监测的单类同型建模

    Truncated Affinity Maximization: One-class Homophily Modeling for Graph Anomaly Detection. (arXiv:2306.00006v1 [cs.SI])

    [http://arxiv.org/abs/2306.00006](http://arxiv.org/abs/2306.00006)

    本文针对图形异常监测数据集中存在的一类同型现象，提出了一种新的无监督异常评分度量——当前节点亲和力，并通过学习量身定制的节点表示，实现了截断亲和力最大化（TAM）方法，优化在原始图形结构上进行，能够有效进行双重One-Class的GAD。

    

    我们在现实世界的图形异常监测（GAD）数据集中经常发现一种普遍的属性......本文提出了一种新的无监督异常评分度量 - 当前节点亲和力......我们进一步提出了截断亲和力最大化 (TAM)，该方法通过最大化与_neighbors的本地亲和力来学习量身定制的节点表示。本文所提方法在原始图形结构上进行优化，可以进行双重One-Class的GAD。

    One prevalent property we find empirically in real-world graph anomaly detection (GAD) datasets is a one-class homophily, i.e., normal nodes tend to have strong connection/affinity with each other, while the homophily in abnormal nodes is significantly weaker than normal nodes. However, this anomaly-discriminative property is ignored by existing GAD methods that are typically built using a conventional anomaly detection objective, such as data reconstruction. In this work, we explore this property to introduce a novel unsupervised anomaly scoring measure for GAD -- local node affinity -- that assigns a larger anomaly score to nodes that are less affiliated with their neighbors, with the affinity defined as similarity on node attributes/representations. We further propose Truncated Affinity Maximization (TAM) that learns tailored node representations for our anomaly measure by maximizing the local affinity of nodes to their neighbors. Optimizing on the original graph structure can be bi
    
[^117]: 用于剂量组合的可靠脱机学习

    Reliable Off-Policy Learning for Dosage Combinations. (arXiv:2305.19742v1 [cs.LG])

    [http://arxiv.org/abs/2305.19742](http://arxiv.org/abs/2305.19742)

    本文提出了一种用于剂量组合的新颖可靠的脱机学习方法，通过三个步骤实现：开发神经网络估计个性化的剂量-反应，估计倾向得分检测共享协变量-治疗空间中的重叠有限区域，然后基于梯度的学习算法找到最佳的个性化剂量组合。

    

    个性化医学领域的决策制定，如癌症治疗或危重护理，通常必须对剂量组合进行选择，即多种连续治疗。现有的这项任务的工作已经独立地建模了多种治疗的效果，而估计联合效果却受到了很少的关注，并且面临着非平凡的挑战。在本文中，我们提出了一种新颖的方法，用于剂量组合的可靠脱机学习。我们的方法分为三个步骤：（1）我们开发了一个特定的神经网络，估计个性化的剂量-反应函数，同时考虑多个相关剂量的联合效应。（2）我们使用条件正态化流量估计广义倾向得分，以检测共享协变量-治疗空间中重叠有限的区域。（3）我们提供一种基于梯度的学习算法，以找到最佳的个性化剂量组合。在此，我们确保可靠地估计策略价值。

    Decision-making in personalized medicine such as cancer therapy or critical care must often make choices for dosage combinations, i.e., multiple continuous treatments. Existing work for this task has modeled the effect of multiple treatments independently, while estimating the joint effect has received little attention but comes with non-trivial challenges. In this paper, we propose a novel method for reliable off-policy learning for dosage combinations. Our method proceeds along three steps: (1) We develop a tailored neural network that estimates the individualized dose-response function while accounting for the joint effect of multiple dependent dosages. (2) We estimate the generalized propensity score using conditional normalizing flows in order to detect regions with limited overlap in the shared covariate-treatment space. (3) We present a gradient-based learning algorithm to find the optimal, individualized dosage combinations. Here, we ensure reliable estimation of the policy val
    
[^118]: 有效增强视觉强化学习的样本利用率：以少学更好

    Learning Better with Less: Effective Augmentation for Sample-Efficient Visual Reinforcement Learning. (arXiv:2305.16379v1 [cs.LG])

    [http://arxiv.org/abs/2305.16379](http://arxiv.org/abs/2305.16379)

    本研究发现，对于数据增强在视觉强化学习中的有效性，空间多样性和轻微的困难度不可或缺。并提出了一种新的DA操作——Rand PR，它提供了丰富的空间多样性和最小的困难度，已经在多种数据上得到了有效性验证。

    

    数据增强（DA）是增强视觉强化学习（RL）算法的样本效率的关键技术。值得注意的是，仅使用简单的观察变换就可以在不进行额外辅助表示任务或预训练编码器的情况下获得出色的性能。然而，仍然不清楚DA的哪些属性是实现样本效率视觉RL的有效性的原因。为了调查这个问题并进一步探索DA的潜力，本文进行了全面的实验，评估了DA属性对其有效性的影响，并提供以下见解和改进：（1）对于单个DA操作，我们揭示了充足的空间多样性和轻微的困难度都是不可缺少的。基于这一发现，我们引入了一种新的DA操作——随机PadResize（Rand PR），它提供了丰富的空间多样性和最小的困难度。（2）对于多类型的DA融合方案，增加的DA困难度和不稳定的数据分布

    Data augmentation (DA) is a crucial technique for enhancing the sample efficiency of visual reinforcement learning (RL) algorithms. Notably, employing simple observation transformations alone can yield outstanding performance without extra auxiliary representation tasks or pre-trained encoders. However, it remains unclear which attributes of DA account for its effectiveness in achieving sample-efficient visual RL. To investigate this issue and further explore the potential of DA, this work conducts comprehensive experiments to assess the impact of DA's attributes on its efficacy and provides the following insights and improvements: (1) For individual DA operations, we reveal that both ample spatial diversity and slight hardness are indispensable. Building on this finding, we introduce Random PadResize (Rand PR), a new DA operation that offers abundant spatial diversity with minimal hardness. (2) For multi-type DA fusion schemes, the increased DA hardness and unstable data distribution 
    
[^119]: 文本到图像生成与评估的可视化编程

    Visual Programming for Text-to-Image Generation and Evaluation. (arXiv:2305.15328v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2305.15328](http://arxiv.org/abs/2305.15328)

    本文提出了两种新颖的可解释/可理解的图像编程框架，用于文本到图像（T2I）的生成和评估。首先，引入了VPGen，一个可解释的逐步T2I生成框架，将T2I生成分解为三个步骤，通过语言模型处理前两个步骤，提供了比端到端模型更强的空间控制能力，并利用了预训练语言模型的世界知识。

    

    随着大型语言模型在许多领域表现出卓越性能，最近的研究采用语言模型作为视觉任务中的视觉模块的控制器。虽然现有的工作集中在为语言模型提供视觉理解能力，但我们提出了两种新颖的可解释/可解释的图像编程框架，用于文本到图像（T2I）的生成和评估。首先，我们引入了VPGen，一种可解释的逐步T2I生成框架，将T2I生成分解为三个步骤：对象/计数生成、布局生成和图像生成。我们使用语言模型处理前两个步骤（对象/计数生成和布局生成），通过在文本布局对上微调它。我们的逐步T2I生成框架提供了比端到端模型更强的空间控制能力，而端到端模型是这个任务的主要方法。此外，我们利用了预训练语言模型的世界知识，克服了以前的布局引导T2I作品的局限。

    As large language models have demonstrated impressive performance in many domains, recent works have adopted language models (LMs) as controllers of visual modules for vision-and-language tasks. While existing work focuses on equipping LMs with visual understanding, we propose two novel interpretable/explainable visual programming frameworks for text-to-image (T2I) generation and evaluation. First, we introduce VPGen, an interpretable step-by-step T2I generation framework that decomposes T2I generation into three steps: object/count generation, layout generation, and image generation. We employ an LM to handle the first two steps (object/count generation and layout generation), by finetuning it on text-layout pairs. Our step-by-step T2I generation framework provides stronger spatial control than end-to-end models, the dominant approach for this task. Furthermore, we leverage the world knowledge of pretrained LMs, overcoming the limitation of previous layout-guided T2I works that can on
    
[^120]: 大型语言模型中的实体偏见：一种因果视角

    A Causal View of Entity Bias in (Large) Language Models. (arXiv:2305.14695v1 [cs.CL])

    [http://arxiv.org/abs/2305.14695](http://arxiv.org/abs/2305.14695)

    研究提出了一种结构因果模型（SCM）并提供因果干预技术，以缓解大型语言模型中的实体偏见，从而减少偏见信息，同时保留相似实体的共同预测信息。

    

    实体偏见广泛影响预训练的大型语言模型，导致它们过度依赖（有偏见的）参数化知识来进行不准确的预测。尽管因果相关的方法已经显示出缓解实体偏见的巨大潜力，但在实践中精确估计潜在因果模型的参数仍然很困难，黑盒子的语言模型更无法调整。为了解决这些问题，我们提出了一种特定的结构因果模型（SCM），其参数比较容易估计。在此基础上，我们提出了因果干预技术，以缓解白盒和黑盒设置中的实体偏见。这种因果干预将原始实体与相邻实体一起进行扰动。这种干预减少了与原始实体相关的特定偏向信息，同时仍保留了来自类似实体的足够共同预测信息。

    Entity bias widely affects pretrained (large) language models, causing them to excessively rely on (biased) parametric knowledge to make unfaithful predictions. Although causality-inspired methods have shown great potential to mitigate entity bias, it is hard to precisely estimate the parameters of underlying causal models in practice. The rise of black-box LLMs also makes the situation even worse, because of their inaccessible parameters and uncalibrated logits. To address these problems, we propose a specific structured causal model (SCM) whose parameters are comparatively easier to estimate. Building upon this SCM, we propose causal intervention techniques to mitigate entity bias for both white-box and black-box settings. The proposed causal intervention perturbs the original entity with neighboring entities. This intervention reduces specific biasing information pertaining to the original entity while still preserving sufficient common predictive information from similar entities. 
    
[^121]: INSTRUCTSCORE: 可解释的文本生成评估与细粒度反馈

    INSTRUCTSCORE: Explainable Text Generation Evaluation with Finegrained Feedback. (arXiv:2305.14282v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.14282](http://arxiv.org/abs/2305.14282)

    INSTRUCTSCORE是一个可解释的文本生成评估度量，通过利用明确的人类指令和GPT-4的隐式知识，它能生成生成文本的分数和人类可读的诊断报告，达到与最先进度量相当的性能水平。

    

    自动评估语言生成的质量至关重要。尽管最近学习度量表显示与人类判断高度相关，但这些度量无法解释其判断或将分数与生成文本中的缺陷关联起来。为了解决这个限制，我们提出了InstructScore，这是一个用于文本生成的可解释的评估度量。通过利用明确的人类指令和GPT-4的隐式知识，我们基于LLaMA对文本评估度量进行微调，生成生成文本的分数和人类可读的诊断报告。我们在各种生成任务上评估了InstructScore，包括翻译、字幕生成、数据到文本和常识生成。实验表明，我们的7B模型超过了所有其他无监督度量，包括基于175B GPT-3和GPT-4的模型。令人惊讶的是，即使没有来自人工评级数据的直接监督，我们的InstructScore的性能水平也与COMET2等最先进的度量相当。

    Automatically evaluating the quality of language generation is critical. Although recent learned metrics show high correlation with human judgement, these metrics can not explain their verdict or associate the scores with defects in generated text. To address this limitation, we present InstructScore, an explainable evaluation metric for text generation. By harnessing both explicit human instruction and the implicit knowledge of GPT-4, we fine-tune a text evaluation metric based on LLaMA, producing both a score for generated text and a human readable diagnostic report. We evaluate InstructScore on a variety of generation tasks, including translation, captioning, data-to-text and commonsense generation. Experiments show that our 7B model surpasses all other unsupervised metrics, including those based on 175B GPT-3 and GPT-4. Surprisingly, our InstructScore, even without direct supervision from human-rated data, achieves performance levels on par with state-of-the-art metrics like COMET2
    
[^122]: DUBLIN——通过语言-图像网络进行文档理解

    DUBLIN -- Document Understanding By Language-Image Network. (arXiv:2305.14218v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2305.14218](http://arxiv.org/abs/2305.14218)

    DUBLIN是一个针对视觉文档理解的模型，使用掩模文档内容生成任务、边界框任务和渲染问答任务进行预训练，利用文档图像中的空间和语义信息。该模型在多项基准测试中达到了竞争性或最先进的结果。

    

    视觉文档理解是一项复杂的任务，涉及分析文档图像中的文本和视觉元素。现有模型通常依赖于手动特征工程或特定领域的流水线，这限制了它们在不同文档类型和语言之间的泛化能力。本文提出了一种预先使用三种新颖目标在Web页面上进行训练的DUBLIN模型：掩模文档内容生成任务、边界框任务和渲染问答任务，并利用文档图像中的空间和语义信息。我们的模型在多项基准测试中实现了具有竞争力或最先进的结果，例如基于Web的结构化阅读理解、文档视觉问答、关键信息提取、图解理解和表格问答。特别地，我们展示了DUBLIN是首个在WebSRC数据集上实现EM 77.75和F1 84.25的基于像素的模型。我们还展示了我们的模型优于现有模型。

    Visual document understanding is a complex task that involves analyzing both the text and the visual elements in document images. Existing models often rely on manual feature engineering or domain-specific pipelines, which limit their generalization ability across different document types and languages. In this paper, we propose DUBLIN, which is pretrained on web pages using three novel objectives: Masked Document Content Generation Task, Bounding Box Task, and Rendered Question Answering Task, that leverage both the spatial and semantic information in the document images. Our model achieves competitive or state-of-the-art results on several benchmarks, such as Web-Based Structural Reading Comprehension, Document Visual Question Answering, Key Information Extraction, Diagram Understanding, and Table Question Answering. In particular, we show that DUBLIN is the first pixel-based model to achieve an EM of 77.75 and F1 of 84.25 on the WebSRC dataset. We also show that our model outperform
    
[^123]: 结合全局结构知识的视觉丰富文档关系抽取方法

    Global Structure Knowledge-Guided Relation Extraction Method for Visually-Rich Document. (arXiv:2305.13850v1 [cs.CL])

    [http://arxiv.org/abs/2305.13850](http://arxiv.org/abs/2305.13850)

    这篇论文提出了一种结合全局结构知识的连续迭代的方式去捕获实体之间的依赖关系，以提高视觉丰富文档中关系抽取的准确性。

    

    视觉关系提取（VRE）旨在从视觉丰富的文档中提取实体之间的关系。现有方法通常基于实体特征单独预测每对实体之间的关系，但忽略了全局结构信息，即实体对之间的依赖关系。缺乏全局结构信息可能使模型难以学习长程关系，并容易产生冲突的预测结果。为了缓解这些限制，我们提出了一种GOSE框架，该框架以迭代的方式捕获实体对之间的依赖关系。给定文档的扫描图像，GOSE首先对实体对生成初步的关系预测。第二，在先前迭代的预测结果基础上，GOSE利用全局结构知识进一步整合实体表示。这种“生成-捕获-整合”模式被多次执行，以便实体之间的依赖关系能够被很好地捕获和利用。

    Visual relation extraction (VRE) aims to extract relations between entities from visuallyrich documents. Existing methods usually predict relations for each entity pair independently based on entity features but ignore the global structure information, i.e., dependencies between entity pairs. The absence of global structure information may make the model struggle to learn long-range relations and easily predict conflicted results. To alleviate such limitations, we propose a GlObal Structure knowledgeguided relation Extraction (GOSE) framework, which captures dependencies between entity pairs in an iterative manner. Given a scanned image of the document, GOSE firstly generates preliminary relation predictions on entity pairs. Secondly, it mines global structure knowledge based on prediction results of the previous iteration and further incorporates global structure knowledge into entity representations. This "generate-capture-incorporate" schema is performed multiple times so that entit
    
[^124]: 大型语言模型能像人类一样推理和产生分歧吗？

    Can Large Language Models Infer and Disagree Like Humans?. (arXiv:2305.13788v1 [cs.CL])

    [http://arxiv.org/abs/2305.13788](http://arxiv.org/abs/2305.13788)

    本文研究了大型语言模型在自然语言推断方面的性能和与人类分歧分布的对齐情况。结果表明LLM的推断能力有限，无法捕捉到人类分歧分布，引发了对其NLU和代表人类用户性质的担忧。

    

    大型语言模型在解决广泛任务方面已经表现出非常好的成绩。在生成文本时，从这些模型中采样标记是一种常见的策略。但是，LLM很难与人类的分歧分布高度对齐，特别是在自然语言推断方面。本文使用 Monte Carlo Reconstruction（MCR）和 Log Probability Reconstruction（LPR）两种不同的技术评估了LLM分布的性能和与人类的对齐情况。结果表明，LLM在解决NLI任务方面能力有限，同时无法捕捉到人类的分歧分布，这对其自然语言理解（NLU）能力和代表人类用户的特性提出了关注。

    Large Language Models (LLMs) have shown stellar achievements in solving a broad range of tasks. When generating text, it is common to sample tokens from these models: whether LLMs closely align with the human disagreement distribution has not been well-studied, especially within the scope of Natural Language Inference (NLI). In this paper, we evaluate the performance and alignment of LLM distribution with humans using two different techniques: Monte Carlo Reconstruction (MCR) and Log Probability Reconstruction (LPR). As a result, we show LLMs exhibit limited ability in solving NLI tasks and simultaneously fail to capture human disagreement distribution, raising concerns about their natural language understanding (NLU) ability and their representativeness of human users.
    
[^125]: 论大型语言模型的错误信息污染风险

    On the Risk of Misinformation Pollution with Large Language Models. (arXiv:2305.13661v1 [cs.CL])

    [http://arxiv.org/abs/2305.13661](http://arxiv.org/abs/2305.13661)

    本文探讨了大型语言模型（LLM）可能误用的潜在风险，指出LLM可以作为有效的误导性信息生成器，导致开放域问答（ODQA）系统性能显著降低，并尝试提出三种防御策略：提示，误报检测和大多数投票。

    

    本文全面调查了现代大型语言模型（LLM）的潜在误用，探讨了其生成可信并具有误导性的信息并对信息密集型应用程序，尤其是开放域问答（ODQA）系统的影响。我们建立了一个威胁模型，并对无意和故意的潜在误用场景进行模拟，以评估LLM可以用于生成信息不实的程度。研究发现，LLM可以作为有效的误导性信息生成器，导致ODQA系统性能显著降低。为了减轻由LLM生成的错误信息带来的危害，我们探讨了三种防御策略：提示，误报检测和大多数投票。虽然初步结果显示这些防御性策略有希望产生明显效果，但还需要做大量工作来应对错误信息污染的挑战。本研究强调了需要进一步进行跨学科研究。

    In this paper, we comprehensively investigate the potential misuse of modern Large Language Models (LLMs) for generating credible-sounding misinformation and its subsequent impact on information-intensive applications, particularly Open-Domain Question Answering (ODQA) systems. We establish a threat model and simulate potential misuse scenarios, both unintentional and intentional, to assess the extent to which LLMs can be utilized to produce misinformation. Our study reveals that LLMs can act as effective misinformation generators, leading to a significant degradation in the performance of ODQA systems. To mitigate the harm caused by LLM-generated misinformation, we explore three defense strategies: prompting, misinformation detection, and majority voting. While initial results show promising trends for these defensive strategies, much more work needs to be done to address the challenge of misinformation pollution. Our work highlights the need for further research and interdisciplinary
    
[^126]: MultiTurnCleanup：用于多轮口语会话转录清理的基准测试

    MultiTurnCleanup: A Benchmark for Multi-Turn Spoken Conversational Transcript Cleanup. (arXiv:2305.12029v1 [cs.CL])

    [http://arxiv.org/abs/2305.12029](http://arxiv.org/abs/2305.12029)

    本研究提出了MultiTurnCleanup任务，收集了新的数据集MultiTurnCleanup1，针对口语会话转录中的不连续现象进行探讨并提供了两个可用于未来研究的基准测试模型。

    

    目前的语调不连续检测模型侧重于单个说话者的每个话语。然而，口语会话转录中的许多不连续现象都发生在多轮对话中，这影响了人类的可读性和下游 NLP 任务的性能。本研究通过提出创新的“MultiTurnCleanup”任务，针对口语会话转录中的不连续现象进行探讨，并收集了新的数据集MultiTurnCleanup1。我们设计了一种数据标注模式以收集高质量的数据集，提供了广泛的数据分析。此外，我们利用两种建模方法进行实验评估，作为未来研究的基准测试。

    Current disfluency detection models focus on individual utterances each from a single speaker. However, numerous discontinuity phenomena in spoken conversational transcripts occur across multiple turns, hampering human readability and the performance of downstream NLP tasks. This study addresses these phenomena by proposing an innovative Multi-Turn Cleanup task for spoken conversational transcripts and collecting a new dataset, MultiTurnCleanup1. We design a data labeling schema to collect the high-quality dataset and provide extensive data analysis. Furthermore, we leverage two modeling approaches for experimental evaluation as benchmarks for future research.
    
[^127]: ConvXAI：通过对话提供异构的AI解释，支持人机科技写作

    ConvXAI: Delivering Heterogeneous AI Explanations via Conversations to Support Human-AI Scientific Writing. (arXiv:2305.09770v1 [cs.HC])

    [http://arxiv.org/abs/2305.09770](http://arxiv.org/abs/2305.09770)

    ConvXAI是一个基于对话的XAI系统，它集成了多种XAI类型，并将实际用户需求嵌入设计中，以提高实用性。

    

    尽管已经提出了各种各样的人工智能解释（XAI）方法来解释AI系统，但目前的方法是否对人类实用仍存在不一致的发现。为了改善XAI方法的实用性，一系列研究确定了现实世界中多样化和动态的用户需求与现有XAI方法之间的差距。虽然之前的研究设想将多种XAI方法集成到通用XAI界面（例如，基于对话或GUI的XAI系统）中以减轻这些差距，但缺少针对这些系统如何设计以满足实际用户需求的研究。在本研究中，我们提出了ConvXAI，这是一个基于对话的XAI系统，它结合了多种XAI类型，并赋予用户通过通用的XAI对话界面提出各种XAI问题的能力。特别地，我们创新地将实际用户需求（即，基于格式研究的四个原则）嵌入ConvXAI设计中，以提高实用性。

    While various AI explanation (XAI) methods have been proposed to interpret AI systems, whether the state-of-the-art XAI methods are practically useful for humans remains inconsistent findings. To improve the usefulness of XAI methods, a line of studies identifies the gaps between the diverse and dynamic real-world user needs with the status quo of XAI methods. Although prior studies envision mitigating these gaps by integrating multiple XAI methods into the universal XAI interfaces (e.g., conversational or GUI-based XAI systems), there is a lack of work investigating how these systems should be designed to meet practical user needs. In this study, we present ConvXAI, a conversational XAI system that incorporates multiple XAI types, and empowers users to request a variety of XAI questions via a universal XAI dialogue interface. Particularly, we innovatively embed practical user needs (i.e., four principles grounding on the formative study) into ConvXAI design to improve practical useful
    
[^128]: 学习去学习：机器去学习的综述

    Learn to Unlearn: A Survey on Machine Unlearning. (arXiv:2305.07512v1 [cs.LG])

    [http://arxiv.org/abs/2305.07512](http://arxiv.org/abs/2305.07512)

    本综述总结了机器去学习技术，用于从训练模型中删除敏感数据，但重新训练ML模型往往不可行。针对这个挑战，需要开发强大的模型以缓解公平性问题。

    

    机器学习模型包含私密信息，实现被遗忘权是许多数据应用的难题。机器去学习已成为从训练模型中删除敏感数据的替代方法，但重新训练机器学习模型往往是不可行的。本综述提供了机器去学习技术的简要评估，涵盖了精确和近似方法、可能的攻击以及验证方法。本综述比较了每种方法的优点和局限性，并使用Deltagrad精确机器去学习方法评估了它们的性能。本综述还强调了挑战，如非IID删除的强大模型，以缓解公平性问题。总的来说，本综述提供了机器去学习技术和应用的全面概述，并指出了这个不断发展的领域的未来研究方向。本综述旨在成为寻求机器去学习资料的研究人员和从业者的有价值资源。

    Machine Learning (ML) models contain private information, and implementing the right to be forgotten is a challenging privacy issue in many data applications. Machine unlearning has emerged as an alternative to remove sensitive data from a trained model, but completely retraining ML models is often not feasible. This survey provides a concise appraisal of Machine Unlearning techniques, encompassing both exact and approximate methods, probable attacks, and verification approaches. The survey compares the merits and limitations each method and evaluates their performance using the Deltagrad exact machine unlearning method. The survey also highlights challenges like the pressing need for a robust model for non-IID deletion to mitigate fairness issues. Overall, the survey provides a thorough synopsis of machine unlearning techniques and applications, noting future research directions in this evolving field. The survey aims to be a valuable resource for researchers and practitioners seeking
    
[^129]: 探究子词分割对transformer语言模型性能的影响

    Investigating the effect of sub-word segmentation on the performance of transformer language models. (arXiv:2305.05480v1 [cs.CL])

    [http://arxiv.org/abs/2305.05480](http://arxiv.org/abs/2305.05480)

    本文研究使用单语词段算法StateMorph训练语言模型时，可以使模型更高效地收敛并获得更好的验证分数。

    

    我们想研究词段如何影响语言模型的性能。我们使用了一种单语词段算法StateMorph，在芬兰语和俄语中训练了GPT-2和BERT模型。作为比较，我们还训练了一个使用BPE和Morfessor分割算法的模型。我们的初步结果表明，StateMorph可以帮助模型更有效地收敛并获得更好的验证分数。

    We would like to explore how morphemes can affect the performance of a language model. We trained GPT-2 and Bert model with StateMorph for both Finnish and Russian, which is a morpheme segmenting algorithm. As a comparison, we also trained a model with BPE and Morfessor. Our preliminary result shows that StateMorph can help the model to converge more efficiently and achieve a better validation score.
    
[^130]: 基于动态系统路径规划和无监督学习的实时环境自主搜索

    Autonomous search of real-life environments combining dynamical system-based path planning and unsupervised learning. (arXiv:2305.01834v1 [cs.RO])

    [http://arxiv.org/abs/2305.01834](http://arxiv.org/abs/2305.01834)

    本文提出了一种自动生成基于动态系统路径规划器和无监督机器学习技术相结合的算法，以克服混沌覆盖路径规划器的立即问题，并在模拟和实际环境中进行了测试，展示其在有限环境中实现自主搜索和覆盖的能力。

    

    近年来取得了使用混沌覆盖路径规划器进行有限环境搜索和遍历的进展，但该领域的现状仍处于初级阶段，目前的实验工作尚未开发出可满足混沌覆盖路径规划器需要克服的立即问题的强大方法 。本文旨在提出一种自动生成基于动态系统路径规划器和无监督机器学习技术相结合的算法，以克服混沌覆盖路径规划器的立即问题，并在模拟和实际环境中进行测试，展示其在有限环境中实现自主搜索和覆盖的能力。

    In recent years, advancements have been made towards the goal of using chaotic coverage path planners for autonomous search and traversal of spaces with limited environmental cues. However, the state of this field is still in its infancy as there has been little experimental work done. Current experimental work has not developed robust methods to satisfactorily address the immediate set of problems a chaotic coverage path planner needs to overcome in order to scan realistic environments within reasonable coverage times. These immediate problems are as follows: (1) an obstacle avoidance technique which generally maintains the kinematic efficiency of the robot's motion, (2) a means to spread chaotic trajectories across the environment (especially crucial for large and/or complex-shaped environments) that need to be covered, and (3) a real-time coverage calculation technique that is accurate and independent of cell size. This paper aims to progress the field by proposing algorithms that a
    
[^131]: 合成经验回放：旨在用扩充数据来提高深度强化学习的效果

    Synthetic Experience Replay. (arXiv:2303.06614v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.06614](http://arxiv.org/abs/2303.06614)

    本文提出了合成经验回放方法解决深度强化学习中数据匮乏问题，通过巧妙应用生成建模技术来扩充数据效果显著。

    

    过去十年的一个关键主题是，当大型神经网络和大型数据集相结合时，它们可以产生令人惊异的结果。在深度强化学习中，这种范式通常通过经验回放实现，其中过去的经验数据集用于训练策略或值函数。然而，与监督学习或自监督学习不同，强化学习代理必须收集自己的数据，这通常是有限的。因此，利用深度学习的好处是具有挑战性的，即使是小型神经网络在训练开始时也可能出现过拟合现象。在这项工作中，我们利用了生成建模的巨大进步，并提出了合成经验回放（SynthER），一种基于扩散的方法来灵活地上采样代理收集的经验。我们证明了SynthER是一种有效的方法，可以在离线和在线设置下训练强化学习代理，无论是在感知环境还是在像素环境中。在离线设置中，我们观察到了显着的改进。

    A key theme in the past decade has been that when large neural networks and large datasets combine they can produce remarkable results. In deep reinforcement learning (RL), this paradigm is commonly made possible through experience replay, whereby a dataset of past experiences is used to train a policy or value function. However, unlike in supervised or self-supervised learning, an RL agent has to collect its own data, which is often limited. Thus, it is challenging to reap the benefits of deep learning, and even small neural networks can overfit at the start of training. In this work, we leverage the tremendous recent progress in generative modeling and propose Synthetic Experience Replay (SynthER), a diffusion-based approach to flexibly upsample an agent's collected experience. We show that SynthER is an effective method for training RL agents across offline and online settings, in both proprioceptive and pixel-based environments. In offline settings, we observe drastic improvements 
    
[^132]: 可重复使用的逐槽机制

    Reusable Slotwise Mechanisms. (arXiv:2302.10503v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2302.10503](http://arxiv.org/abs/2302.10503)

    这项工作提出了一种名为可重复使用的逐槽机制（RSM）的框架，其通过在槽之间进行通信以及动态选择可重复使用机制，模拟对象的动态学。该模型利用中央上下文信息（CCI），能够建模高阶和复杂的相互作用，展现出优越的性能。

    

    具有理解和推理对象动态的能力的代理人在新场景中表现出更好的鲁棒性和泛化性。然而，实现这种能力不仅需要有效的场景表示，还需要对对象子集之间相互作用机制的理解。最近的研究在使用对象槽表示场景方面取得了重大进展。在这项工作中，我们引入了可重复使用的逐槽机制（RSM），这是一个框架，通过在槽之间进行通信以及具有动态选择可重复使用机制的模块化架构，来模拟对象动态学。关键是，RSM利用了中央上下文信息（CCI），使得选择的机制能够通过一个瓶颈来访问其余的槽，从而有效地建模可能需要稀疏对象子集的高阶和复杂的相互作用。实验表明，RSM能够在不同任务中有效地学习对象动态学，展现出了优越的性能。

    Agents with the ability to comprehend and reason about the dynamics of objects would be expected to exhibit improved robustness and generalization in novel scenarios. However, achieving this capability necessitates not only an effective scene representation but also an understanding of the mechanisms governing interactions among object subsets. Recent studies have made significant progress in representing scenes using object slots. In this work, we introduce Reusable Slotwise Mechanisms, or RSM, a framework that models object dynamics by leveraging communication among slots along with a modular architecture capable of dynamically selecting reusable mechanisms for predicting the future states of each object slot. Crucially, RSM leverages the Central Contextual Information (CCI), enabling selected mechanisms to access the remaining slots through a bottleneck, effectively allowing for modeling of higher order and complex interactions that might require a sparse subset of objects. Experime
    
[^133]: 不依赖奖励模型的直接基于偏好的策略优化

    Direct Preference-based Policy Optimization without Reward Modeling. (arXiv:2301.12842v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.12842](http://arxiv.org/abs/2301.12842)

    本文提出了一种无需奖励模型的直接基于偏好的策略优化算法，通过采用对比学习框架和设计新的策略评分指标，能够从给定的偏好数据中学习并取得良好性能。

    

    基于偏好的强化学习(PbRL)是一种使RL代理能够从偏好中学习的方法，特别适用于在制定奖励函数时存在挑战的情况。现有的PbRL方法一般包括两个步骤：首先根据给定的偏好数据学习奖励模型，然后使用学习到的奖励模型采用现成的强化学习算法。然而，仅通过偏好信息获取准确的奖励模型，尤其是在偏好来自人类教师时，可能很困难。相反，我们提出了一种不需要任何奖励模型的直接从偏好中学习的PbRL算法。为了实现这一目标，我们采用对比学习框架，设计了一种新的策略评分指标，为与给定偏好一致的策略分配高分。我们将我们的算法应用于带有实际人类偏好标签的离线RL任务，并展示了我们的算法优于或与现有方法相当。

    Preference-based reinforcement learning (PbRL) is an approach that enables RL agents to learn from preference, which is particularly useful when formulating a reward function is challenging. Existing PbRL methods generally involve a two-step procedure: they first learn a reward model based on given preference data and then employ off-the-shelf reinforcement learning algorithms using the learned reward model. However, obtaining an accurate reward model solely from preference information, especially when the preference is from human teachers, can be difficult. Instead, we propose a PbRL algorithm that directly learns from preference without requiring any reward modeling. To achieve this, we adopt a contrastive learning framework to design a novel policy scoring metric that assigns a high score to policies that align with the given preferences. We apply our algorithm to offline RL tasks with actual human preference labels and show that our algorithm outperforms or is on par with the exist
    
[^134]: 文本到图像生成中的空间关系基准测试

    Benchmarking Spatial Relationships in Text-to-Image Generation. (arXiv:2212.10015v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.10015](http://arxiv.org/abs/2212.10015)

    本文研究了文本到图像生成中模型生成正确空间关系的能力，并提出了一个评估指标VISOR以衡量生成图像的准确性。实验发现当前T2I模型尽管可以生成高度逼真的图像，但其空间上准确的图像能力仍然不足，特别是在空间谓词和场景关系理解方面。

    

    空间理解是计算机视觉的基本方面，对于人类级别的图像推理至关重要，因此是基础语言理解的重要组成部分。最近的文本到图像合成（T2I）模型在逼真性方面取得了前所未有的进展，但它们的可靠空间理解能力尚不清楚。我们调查了T2I模型生成正确空间关系的能力，并提出了VISOR评估指标，它捕捉了文本中描述的空间关系在图像中是否准确生成。为了基准现有模型，我们引入了一个包含描述两个对象及它们之间空间关系的句子数据集SR2D。我们构建了一个自动化评估流程来识别物体及其空间关系，并在大规模评估T2I模型时采用它。我们的实验发现了一个令人惊讶的发现，也就是尽管最新的T2I模型能够产生高度逼真的图像，但它们生成空间上准确的图像能力仍然不足。具体而言，我们发现现有模型在空间谓词（如'在前面'和'在后面'）方面存在困难，并且在场景的关系理解方面也有困难。

    Spatial understanding is a fundamental aspect of computer vision and integral for human-level reasoning about images, making it an important component for grounded language understanding. While recent text-to-image synthesis (T2I) models have shown unprecedented improvements in photorealism, it is unclear whether they have reliable spatial understanding capabilities. We investigate the ability of T2I models to generate correct spatial relationships among objects and present VISOR, an evaluation metric that captures how accurately the spatial relationship described in text is generated in the image. To benchmark existing models, we introduce a dataset, SR2D, that contains sentences describing two objects and the spatial relationship between them. We construct an automated evaluation pipeline to recognize objects and their spatial relationships, and employ it in a large-scale evaluation of T2I models. Our experiments reveal a surprising finding that, although state-of-the-art T2I models 
    
[^135]: 隐式卷积核用于可定向卷积神经网络

    Implicit Convolutional Kernels for Steerable CNNs. (arXiv:2212.06096v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.06096](http://arxiv.org/abs/2212.06096)

    本文提出了一种使用隐式神经表示的方法来参数化可定向卷积核，从而实现了简单灵活的构建可定向卷积神经网络的方法，能够推广到任何具有等变MLP的群G。

    

    可定向卷积神经网络提供了构建与平移和其他变换等同变换的神经网络的通用框架，这些变换属于基于原点保持的群G，例如反射和旋转。它们依赖于通过在核空间上强加特定于群G的等变性约束来解析求解得到的G-定向卷积核的标准卷积。由于解决方案对特定的群G定制，核基础的实现不能推广到其他对称变换，这导致了通用群等变模型的开发复杂化。我们提出使用通过多层感知器(MLPs)参数化G-定向卷积核的隐式神经表示。所得到的框架提供了一种简单灵活的实现可定向卷积神经网络的方法，并且对于任何可以构建G-等变MLP的群G都可以推广。我们在多个任务上证明了我们的方法的有效性，包括N体模拟。

    Steerable convolutional neural networks (CNNs) provide a general framework for building neural networks equivariant to translations and other transformations belonging to an origin-preserving group $G$, such as reflections and rotations. They rely on standard convolutions with $G$-steerable kernels obtained by analytically solving the group-specific equivariance constraint imposed onto the kernel space. As the solution is tailored to a particular group $G$, the implementation of a kernel basis does not generalize to other symmetry transformations, which complicates the development of general group equivariant models. We propose using implicit neural representation via multi-layer perceptrons (MLPs) to parameterize $G$-steerable kernels. The resulting framework offers a simple and flexible way to implement Steerable CNNs and generalizes to any group $G$ for which a $G$-equivariant MLP can be built. We prove the effectiveness of our method on multiple tasks, including N-body simulations,
    
[^136]: 非对比自监督学习中的隐式方差正则化

    Implicit variance regularization in non-contrastive SSL. (arXiv:2212.04858v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.04858](http://arxiv.org/abs/2212.04858)

    非对比自监督学习中的预测网络通过隐式方差正则化避免表示崩溃，欧几里得距离和余弦相似度具有不同的动态机制，并且特征值作为学习率乘数。引入一族等向性损失函数可以平衡收敛速度。

    

    非对比自监督学习方法（如BYOL和SimSiam）依赖于非对称预测网络来避免表示崩溃而无需负样本。然而，预测网络如何促进稳定学习还不完全清楚。虽然先前的理论分析假设欧几里得损失，但大多数实际实现依赖于余弦相似度。为了进一步理解非对比自监督学习，我们在闭式线性预测网络的特征空间中分析研究学习动力学与欧几里得距离和余弦相似度的关系。我们发现，两者均通过隐式方差正则化来避免崩溃，尽管具有不同的动态机制。此外，我们发现特征值作为有效的学习率乘数，并提出了一族等向性损失函数（IsoLoss），以在特征模式之间平衡收敛速度。实验证明，IsoLoss加速了初始学习动力学并增加了鲁棒性，从而使我们能够摆脱...

    Non-contrastive SSL methods like BYOL and SimSiam rely on asymmetric predictor networks to avoid representational collapse without negative samples. Yet, how predictor networks facilitate stable learning is not fully understood. While previous theoretical analyses assumed Euclidean losses, most practical implementations rely on cosine similarity. To gain further theoretical insight into non-contrastive SSL, we analytically study learning dynamics in conjunction with Euclidean and cosine similarity in the eigenspace of closed-form linear predictor networks. We show that both avoid collapse through implicit variance regularization albeit through different dynamical mechanisms. Moreover, we find that the eigenvalues act as effective learning rate multipliers and propose a family of isotropic loss functions (IsoLoss) that equalize convergence rates across eigenmodes. Empirically, IsoLoss speeds up the initial learning dynamics and increases robustness, thereby allowing us to dispense with 
    
[^137]: CORL: 面向研究的深度强化学习离线库

    CORL: Research-oriented Deep Offline Reinforcement Learning Library. (arXiv:2210.07105v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.07105](http://arxiv.org/abs/2210.07105)

    CORL是一个面向研究的深度强化学习离线库，提供了经过充分基准测试的单文件实现离线和离线到在线强化学习算法，并具有简单的开发体验和实验跟踪功能。

    

    CORL是一个开源库，提供了经过充分基准测试的单文件实现深度离线和离线到在线强化学习算法。它强调简单的开发体验，具有直观的代码库和现代分析跟踪工具。在CORL中，我们将方法实现隔离到单独的单个文件中，使性能相关的细节更容易识别。此外，实验跟踪功能可用于帮助记录指标、超参数、依赖项等到云端。最后，我们通过基准测试常用的D4RL数据集，确保了实现的可靠性，提供了透明的结果源，可用于强大的评估工具，例如性能概要、改进概率或预期在线性能。

    CORL is an open-source library that provides thoroughly benchmarked single-file implementations of both deep offline and offline-to-online reinforcement learning algorithms. It emphasizes a simple developing experience with a straightforward codebase and a modern analysis tracking tool. In CORL, we isolate methods implementation into separate single files, making performance-relevant details easier to recognize. Additionally, an experiment tracking feature is available to help log metrics, hyperparameters, dependencies, and more to the cloud. Finally, we have ensured the reliability of the implementations by benchmarking commonly employed D4RL datasets providing a transparent source of results that can be reused for robust evaluation tools such as performance profiles, probability of improvement, or expected online performance.
    
[^138]: 语言模型显示对推理任务具有类似人类的内容效应

    Language models show human-like content effects on reasoning tasks. (arXiv:2207.07051v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2207.07051](http://arxiv.org/abs/2207.07051)

    本研究探讨了语言模型在逻辑推理任务中是否像人类一样通过混入内容来影响答案，结果发现大型语言模型的先验期望能够捕捉到这种特征。

    

    抽象推理是智能系统的关键能力。大型语言模型在抽象推理任务上实现了高于随机的性能，但存在许多不完善之处。然而，人类的抽象推理也是不完美的。例如，人类推理受到我们对真实世界的知识和信念的影响，并表现出显著的“内容效应”；当问题的语义内容支持正确的逻辑推理时，人类更可靠地进行推理。这些内容纠缠的推理模式在关于人类智能基本性质的争论中起着核心作用。在这里，我们研究了语言模型是否以类似的方式混入内容来回答逻辑问题，这些语言模型的先验期望捕捉了一些人类知识的特征。我们在三个逻辑推理任务上探索了这个问题：自然语言推理、判断三段论的逻辑有效性和Wason选择任务。我们评估了最先进的大型语言模型的性能。

    Abstract reasoning is a key ability for an intelligent system. Large language models (LMs) achieve above-chance performance on abstract reasoning tasks, but exhibit many imperfections. However, human abstract reasoning is also imperfect. For example, human reasoning is affected by our real-world knowledge and beliefs, and shows notable "content effects"; humans reason more reliably when the semantic content of a problem supports the correct logical inferences. These content-entangled reasoning patterns play a central role in debates about the fundamental nature of human intelligence. Here, we investigate whether language models $\unicode{x2014}$ whose prior expectations capture some aspects of human knowledge $\unicode{x2014}$ similarly mix content into their answers to logical problems. We explored this question across three logical reasoning tasks: natural language inference, judging the logical validity of syllogisms, and the Wason selection task. We evaluate state of the art large 
    
[^139]: 算法基础的经验性X风险最小化

    Algorithmic Foundations of Empirical X-risk Minimization. (arXiv:2206.00439v6 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.00439](http://arxiv.org/abs/2206.00439)

    本文介绍了一种名为"经验性X风险最小化（EXM）"的机器学习和人工智能优化框架，该框架解决了深度学习中优化不可分解目标的困难，并提供了算法基础的详细讨论。

    

    本文介绍了一种名为"经验性X风险最小化（EXM）"的机器学习和人工智能优化框架。X风险是一个用于表示一类组合度量或目标的术语，在其中，将每个数据点与大量的明确或隐含的项目进行比较来定义风险函数。它包括许多广泛使用的代理目标和不可分解的损失函数，例如AUROC、AUPRC、部分AUROC、NDCG、MAP、在前K个位置的精确度/召回率、在特定召回率水平上的精确度、列表损失、p范数推导、顶部推导、全局对比损失等。虽然这些不可分解的目标及其优化算法在机器学习、计算机视觉、信息检索等领域的文献中已经得到了研究，但在深度学习中优化这些目标面临着一些独特的挑战。在本文中，我们重点介绍了EXM的算法基础，并提供了最近的严格工作。

    This manuscript introduces a new optimization framework for machine learning and AI, named {\bf empirical X-risk minimization (EXM)}. X-risk is a term introduced to represent a family of compositional measures or objectives, in which each data point is compared with a large number of items explicitly or implicitly for defining a risk function. It includes surrogate objectives of many widely used measures and non-decomposable losses, e.g., AUROC, AUPRC, partial AUROC, NDCG, MAP, precision/recall at top $K$ positions, precision at a certain recall level, listwise losses, p-norm push, top push, global contrastive losses, etc. While these non-decomposable objectives and their optimization algorithms have been studied in the literature of machine learning, computer vision, information retrieval, and etc, optimizing these objectives has encountered some unique challenges for deep learning. In this paper, we present recent rigorous efforts for EXM with a focus on its algorithmic foundations a
    
[^140]: NeuroBack: 使用图神经网络改进CDCL SAT求解

    NeuroBack: Improving CDCL SAT Solving using Graph Neural Networks. (arXiv:2110.14053v4 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2110.14053](http://arxiv.org/abs/2110.14053)

    NeuroBack提出了一种使用图神经网络改进CDCL SAT求解的方法，通过预测出现在大多数满足赋值中的变量的阶段，使得求解更加有效，并且消除了对GPU资源的依赖。

    

    命题可满足性（SAT）是一个影响到规划、验证和安全等许多研究领域的NP完全问题。主流的现代SAT求解器基于冲突驱动子句学习（CDCL）算法。最近的研究旨在利用图神经网络（GNNs）增强CDCL SAT求解器。然而，到目前为止，这种方法要么没有使求解更加有效，要么需要大量的GPU资源进行频繁的在线模型推断。为了使GNN的改进变得实用，本文提出了一种名为NeuroBack的方法，它建立在两个洞察上：（1）预测出现在大多数（甚至全部）满足赋值中的变量的阶段（即值）对于CDCL SAT求解至关重要，（2）在SAT求解开始之前，只需查询一次神经模型进行预测即可。一旦训练完成，离线模型推断使NeuroBack能够仅在CPU上执行，消除了对GPU资源的依赖。

    Propositional satisfiability (SAT) is an NP-complete problem that impacts many research fields, such as planning, verification, and security. Mainstream modern SAT solvers are based on the Conflict-Driven Clause Learning (CDCL) algorithm. Recent work aimed to enhance CDCL SAT solvers using Graph Neural Networks (GNNs). However, so far this approach either has not made solving more effective, or required substantial GPU resources for frequent online model inferences. Aiming to make GNN improvements practical, this paper proposes an approach called NeuroBack, which builds on two insights: (1) predicting phases (i.e., values) of variables appearing in the majority (or even all) of the satisfying assignments are essential for CDCL SAT solving, and (2) it is sufficient to query the neural model only once for the predictions before the SAT solving starts. Once trained, the offline model inference allows NeuroBack to execute exclusively on the CPU, removing its reliance on GPU resources. To t
    
[^141]: 意识的神经计算模型：目标对齐的内部表示操作理论（GARIM）

    A Neurocomputational Account of Consciousness: The Goal-Aligning Representation Internal Manipulation Theory (GARIM). (arXiv:1912.13490v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/1912.13490](http://arxiv.org/abs/1912.13490)

    这个论文提出了一个神经计算框架下的意识理论，称为“目标对齐的内部表示操作”（GARIM）。该理论认为意识支持对目标相关的内部表示进行主动操作，使其与追求的目标更加对齐，从而增加目标导向行为的灵活性。

    

    意识作为人类认知的核心要素，已经通过神经科学、心理学、人工智能和机器人技术等多种科学方法进行研究。然而，这些领域之间的不良整合限制了对意识的完整和清晰理解。在这篇论文中，我们通过提出一个神经计算框架下的“目标对齐的内部表示操作”（GARIM）意识理论，为改善这种整合做出了贡献。GARIM理论的核心思想是，意识支持对目标相关的内部表示（如世界状态、对象和行为序列）进行主动操作，使它们与追求的目标更加对齐。这些操作使得意识代理能够在内部产生其所缺乏的知识，以应对新条件和目标，从而增加目标导向行为的灵活性。表示的操作由四个神经功能宏系统（Hierarc...

    Consciousness, a central element of human cognition, has been studied with multiple scientific approaches spanning neuroscience, psychology, artificial intelligence and robotics. Unfortunately, poor integration between these fields limits a full and clear understanding of consciousness. Here we contribute to improving this integration by proposing, within a neurocomputational framework, the `Goal-Aligning Representations Internal Manipulation' (GARIM) theory of consciousness. The central idea of the GARIM theory is that consciousness supports the active manipulation of goal-relevant internal representations (e.g., world states, objects, and action sequences), making them more aligned with the goals pursued. These manipulations allow the conscious agent to internally produce the knowledge it lacks to cope with novel conditions and goals, increasing the flexibility of goal-directed behaviour. The manipulation of representations is supported by four neuro-functional macro-systems (hierarc
    

