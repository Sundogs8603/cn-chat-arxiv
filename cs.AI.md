# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Characterizing Political Bias in Automatic Summaries: A Case Study of Trump and Biden.](http://arxiv.org/abs/2305.02321) | 本文研究了自动生成新闻文章摘要中的政治偏见。研究发现，与特朗普相比，更多的美国政府集体机构（即政府）与拜登相关联。这些发现为未来的摘要偏见研究提供了一个框架。 |
| [^2] | [Real-Time Radiance Fields for Single-Image Portrait View Synthesis.](http://arxiv.org/abs/2305.02310) | 该论文提出了一种适用于单张图片的实时辐射场合成方法，能够从单张未经过姿势调整的图像中推断和渲染出逼真的3D表示，并产生高质量的3D感知人像合成结果。 |
| [^3] | [Fashionpedia-Taste: A Dataset towards Explaining Human Fashion Taste.](http://arxiv.org/abs/2305.02307) | Fashionpedia-Taste是一个可解释性的时尚数据集，其中包含了局部属性，人类注意力和说明等多种因素，能够帮助研究人员从不同的人文视角和模态全面理解和解释人类的时尚品味。 |
| [^4] | [Calibrated Explanations: with Uncertainty Information and Counterfactuals.](http://arxiv.org/abs/2305.02305) | 该论文提出了一种新的特征重要性解释方法，Calibrated Explanations (CE)，它可以提供准确、稳定的解释，并且可以为概率估计和特征重要性权重提供不确定性量化信息，是一种快速、可靠且强健的解释方法。 |
| [^5] | [Distilling Step-by-Step! Outperforming Larger Language Models with Less Training Data and Smaller Model Sizes.](http://arxiv.org/abs/2305.02301) | 本研究提出了Distilling Step-by-Step机制，通过提取LLM基础信息为小型模型提供额外的监督训练，从而使它们胜过更大的LLM模型，并需更少的训练数据。 |
| [^6] | [Evaluating the Efficacy of Length-Controllable Machine Translation.](http://arxiv.org/abs/2305.02300) | 本文评估了长度可控机器翻译的自动评估指标，发现BLEURT和COMET是最适合作为其评估指标的。 |
| [^7] | [DynamicStereo: Consistent Dynamic Depth from Stereo Videos.](http://arxiv.org/abs/2305.02296) | 本文提出了一种新颖的 DynamicStereo 架构，用于从立体视频中估计视差，并从相邻帧中汇集信息，以改善其预测的时间一致性。同时，提出了一个新的 Dynamic Replica 数据集作为基准数据集，更接近真实应用场景，用于训练和评估动态立体的性能。 |
| [^8] | [Distributed Leader Follower Formation Control of Mobile Robots based on Bioinspired Neural Dynamics and Adaptive Sliding Innovation Filter.](http://arxiv.org/abs/2305.02288) | 本文提出了一种基于生物启发式神经动力学的编队控制方法，结合自适应滑模创新滤波器，能够解决传统设计中存在的速度跳跃问题和抖动问题，并提供额外的鲁棒性和平滑的控制输入。 |
| [^9] | [Learngene: Inheriting Condensed Knowledge from the Ancestry Model to Descendant Models.](http://arxiv.org/abs/2305.02279) | 本文提出了一种机器学习范式 Learngene，将积累的知识压缩成更为紧凑的信息片段并继承给后代模型，以便于适应新的环境 |
| [^10] | [End-to-end Training and Decoding for Pivot-based Cascaded Translation Model.](http://arxiv.org/abs/2305.02261) | 本文提出了一种端到端训练方法，并配置了改进的解码算法，即基于中转的级联翻译模型，使用加权中转语言嵌入输入模型，利用波束搜索缓解标记和概率分布之间的不一致性。实验证明，该方法提高了翻译的质量。 |
| [^11] | [Contextual Reasoning for Scene Generation (Technical Report).](http://arxiv.org/abs/2305.02255) | 本文展示了如何将MR-CKR框架应用于真实的自主车辆场景数据，以生成具有挑战性的场景问题。实验表明，我们的框架可以有效生成多样化和具有挑战性的场景，为提高自主车辆安全导航的培训提供了有希望的解决方案。 |
| [^12] | [Automated Scientific Discovery: From Equation Discovery to Autonomous Discovery Systems.](http://arxiv.org/abs/2305.02251) | 本文调研了自动化科学发现，介绍了各种方法和最近的话题，并概述了闭环科学发现系统和自主发现系统，其中最大级别不需要任何人类干预。该研究旨在发展能够产生诺贝尔级成果的AI科学家。 |
| [^13] | [The Benefits of Label-Description Training for Zero-Shot Text Classification.](http://arxiv.org/abs/2305.02239) | 本文提出了标注描述训练的方法，在零样本分类中可以显著提高准确率，并能更鲁棒地处理分类任务。 |
| [^14] | [Connecting the Dots in Trustworthy Artificial Intelligence: From AI Principles, Ethics, and Key Requirements to Responsible AI Systems and Regulation.](http://arxiv.org/abs/2305.02231) | 该论文旨在探讨可信人工智能的构建，包括从法律、伦理和技术、社会角度确保其健壮性。实现真正可信的人工智能涉及到更广阔的愿景，考虑到伦理方面、风险方面、以及对七个技术需求的支持度和大局整体之关系。 |
| [^15] | [Can ChatGPT Pass An Introductory Level Functional Language Programming Course?.](http://arxiv.org/abs/2305.02230) | 本研究测试了ChatGPT在入门级函数式语言编程课程中的表现，结果显示它可以获得B-的成绩并且能够给学生和讲师带来潜在好处。 |
| [^16] | [Clinical Note Generation from Doctor-Patient Conversations using Large Language Models: Insights from MEDIQA-Chat.](http://arxiv.org/abs/2305.02220) | 本文介绍了使用大型语言模型从医生-患者对话中自动生成临床笔记的研究，采用少样本上下文学习法所生成笔记表现优秀，且可与人工编写的笔记媲美。 |
| [^17] | [Exploring Linguistic Properties of Monolingual BERTs with Typological Classification among Languages.](http://arxiv.org/abs/2305.02215) | 本文研究使用语言分类方法探究单语BERT的语言属性，核心发现为BERT正在复制传统的语言模型。 |
| [^18] | [Large-scale Online Ridesharing: The Effect of Assignment Optimality on System Performance.](http://arxiv.org/abs/2305.02209) | 本文介绍了一种名为VGA方法的拼车系统方法，可以用于计算大规模MoD系统中的最优乘客-车辆分配和相应的车辆路径。研究者比较了使用最优分配的MoD系统与使用普通分配的MoD系统的性能。 |
| [^19] | [CALM: Conditional Adversarial Latent Models for Directable Virtual Characters.](http://arxiv.org/abs/2305.02195) | 本文提出了CALM方法，通过模仿学习实现了对虚拟角色动作的直接控制，并可以进行样式条件训练，该方法学习了一种丰富复杂的语义运动表示。 |
| [^20] | [Rethinking Graph Lottery Tickets: Graph Sparsity Matters.](http://arxiv.org/abs/2305.02190) | 本文探讨了图彩票问题中图的稀疏性问题，提出了保留节点输入输出特征的对称修剪技术和保留特征图空间位置的修剪技术，并在基准数据集上取得了比现有技术更优秀的结果。 |
| [^21] | [Continual Reasoning: Non-Monotonic Reasoning in Neurosymbolic AI using Continual Learning.](http://arxiv.org/abs/2305.02171) | 本文提出了一种持续推理的新方法，通过将神经符号系统与持续学习相结合，可以在处理非单调推理任务时获得更高的准确性。 |
| [^22] | [Identifying the Correlation Between Language Distance and Cross-Lingual Transfer in a Multilingual Representation Space.](http://arxiv.org/abs/2305.02151) | 探索了语言特征对多语言表示空间中的跨语言传递性能的影响，初步提供了方法以增强对语言上相距较远的语言的传递能力。 |
| [^23] | [Why Oatmeal is Cheap: Kolmogorov Complexity and Procedural Generation.](http://arxiv.org/abs/2305.02131) | 本文关注燕麦为什么便宜的问题，并将信息论的理论工作与游戏内容生成联系在一起。该论文证明了一种生成器能够产生的最复杂制品的 Kolomogorov 复杂度与该生成器可能空间的大小之间存在关系。 |
| [^24] | [System Neural Diversity: Measuring Behavioral Heterogeneity in Multi-Agent Learning.](http://arxiv.org/abs/2305.02128) | 本文介绍了一种名为“系统神经多样性”的方法，用于度量具有随机策略的多智能体系统的行为异质性，探讨了多样性对集体弹性和性能的影响。 |
| [^25] | [Asymmetric quantum decision-making.](http://arxiv.org/abs/2305.02117) | 本研究以理论和实验的方法探讨了利用携带轨道角动量的光子或纠缠光子的量子干涉实现非对称集体决策，并实现更高的效用，同时保持决策的公平性。 |
| [^26] | [Synergies Between Federated Learning and O-RAN: Towards an Elastic Virtualized Architecture for Multiple Distributed Machine Learning Services.](http://arxiv.org/abs/2305.02109) | 本文研究了联邦学习在现代无线网络下的挑战，提出了一种方法称为动态多服务联邦学习（DMS-FL）来解决这个问题。同时，还提出了一种名为弹性虚拟化联邦学习（EV-FL）的分布式机器学习架构，来支持DMS-FL中的设计要求。 |
| [^27] | [Removing Human Bottlenecks in Bird Classification Using Camera Trap Images and Deep Learning.](http://arxiv.org/abs/2305.02097) | 本文介绍了采用摄像陷阱和深度学习来消除鸟类监测中的瓶颈。通过该方法，减少了图像处理的工作量和虚警比例，提高了监测效率和准确性。 |
| [^28] | [Efficient CNN-based Super Resolution Algorithms for mmWave Mobile Radar Imaging.](http://arxiv.org/abs/2305.02092) | 本文介绍了两种基于卷积神经网络的超分辨率算法，用于实现高效且准确的近场合成孔径雷达成像，具有卓越的性能。 |
| [^29] | [A Systematic Study on Object Recognition Using Millimeter-wave Radar.](http://arxiv.org/abs/2305.02085) | 本研究对商用毫米波雷达进行了全面研究，展示了毫米波雷达作为一种有前途的物体识别技术的潜力，能够以高准确性、鲁棒性和实时性识别物体，不受外观的影响，并解决了遮挡效果问题。 |
| [^30] | [An Ontology Design Pattern for Role-Dependent Names.](http://arxiv.org/abs/2305.02077) | 本文提出了一个用于建模名称与角色相关联的设计模式，能够捕捉代理人在不同角色中使用不同名称的情况。 |
| [^31] | [A Vision Transformer Approach for Efficient Near-Field Irregular SAR Super-Resolution.](http://arxiv.org/abs/2305.02074) | 本文提出了一种新的、用于近场不规则SAR超分辨率的算法，以应对高分辨率成像中遇到的独特挑战，为实现边缘和物联网(IoT)技术奠定技术基础。 |
| [^32] | [Attention Based Feature Fusion For Multi-Agent Collaborative Perception.](http://arxiv.org/abs/2305.02061) | 该论文提出了一种基于图注意力网络的多智能体协作感知方案，从而提高了多智能体感知的整体精度并缓解网络资源的限制。 |
| [^33] | [Human Machine Co-adaption Interface via Cooperation Markov Decision Process System.](http://arxiv.org/abs/2305.02058) | 本文提出了一种新的人机界面，将机器人辅助康复的整个过程视为协同适应或相互学习过程。提出了一种量化高抽象层系统学习速率的模型，并根据该模型设计了协作的策略迭代方法，通过该系统解决了非平稳问题。 |
| [^34] | [Map-based Experience Replay: A Memory-Efficient Solution to Catastrophic Forgetting in Reinforcement Learning.](http://arxiv.org/abs/2305.02054) | 本文提出了一种基于地图的经验回放方法，通过将存储的转换组织成一种简洁的环境模型网络，以在减少内存大小的同时增加每个样本的相关性，从而有效解决强化学习中的遗忘问题。 |
| [^35] | [Improved Static Hand Gesture Classification on Deep Convolutional Neural Networks using Novel Sterile Training Technique.](http://arxiv.org/abs/2305.02039) | 本文提出一种使用mmWave雷达和CNN的数据收集和训练新技术，同时提出了一种新颖的无菌训练技术，可以在非理想成像条件下提高静态手势分类准确性。 |
| [^36] | [A Systematic Study of Knowledge Distillation for Natural Language Generation with Pseudo-Target Training.](http://arxiv.org/abs/2305.02031) | 本文研究如何压缩自然语言生成模型以适应实际应用需求，通过使用知识蒸馏和伪目标训练技术针对特定的自然语言生成任务和数据集进行优化，并取得了显著效果。 |
| [^37] | [Deep Learning-Based Multiband Signal Fusion for 3-D SAR Super-Resolution.](http://arxiv.org/abs/2305.02017) | 本研究首次提出使用深度学习进行多波段信号融合，以应对实际场景中目标模型复杂的问题。 |
| [^38] | [Commentary on explainable artificial intelligence methods: SHAP and LIME.](http://arxiv.org/abs/2305.02012) | 这篇评论对可解释人工智能方法 SHAP 和 LIME 进行了评述和比较，提出了一个框架且突出了它们的优缺点。 |
| [^39] | [Extraction of volumetric indices from echocardiography: which deep learning solution for clinical use?.](http://arxiv.org/abs/2305.01997) | 本文对当前医学/超声心动图图像分割方法进行了全面比较，提出了3D nnU-Net模型，解决了时间一致性和跨数据集方面的问题，并通过引入一个新的私有数据集，CARDINAL，来证明其在应用于临床中的优越性。 |
| [^40] | [Where We Have Arrived in Proving the Emergence of Sparse Symbolic Concepts in AI Models.](http://arxiv.org/abs/2305.01939) | 证明了对于训练良好的AI模型，如果满足一定条件，将出现稀疏交互概念，这些概念能够描述输入变量之间的相互作用，并对模型推理分数产生影响。 |
| [^41] | [Doc2SoarGraph: Discrete Reasoning over Visually-Rich Table-Text Documents with Semantic-Oriented Hierarchical Graphs.](http://arxiv.org/abs/2305.01938) | 本文提出了 Doc2SoarGraph 框架，利用语义导向分层图结构中元素之间的差异和相关性，在富含视觉表格文本的TAT-DQA问题下实现了离散推理，表现出了最佳的实验结果。 |
| [^42] | [An Exploration of Conditioning Methods in Graph Neural Networks.](http://arxiv.org/abs/2305.01933) | 本文探究图神经网络中的三种条件处理方式：弱条件处理、强条件处理和纯条件处理，对于不同类别的GNNs，有不同的表现，实证研究表明这些条件处理方式对于GNN的性能有影响。 |
| [^43] | [Improving Contrastive Learning of Sentence Embeddings from AI Feedback.](http://arxiv.org/abs/2305.01918) | 本文提出了一种利用人工智能反馈改进句子嵌入对比学习方法的方式，可以提高对比学习样本对的质量，并结合人类反馈来提供更好的监督信号。 |
| [^44] | [MolKD: Distilling Cross-Modal Knowledge in Chemical Reactions for Molecular Property Prediction.](http://arxiv.org/abs/2305.01912) | 本文提出了一种名为MolKD的新颖方法，通过将化学反应与分子间的跨模态知识提取和转移，为分子表示学习提供辅助，从而提高分子属性预测的效果。 |
| [^45] | [Distributional Instance Segmentation: Modeling Uncertainty and High Confidence Predictions with Latent-MaskRCNN.](http://arxiv.org/abs/2305.01910) | 本文提出了一种分布式实例分割模型，使用隐变量对对象掩膜的不确定性进行建模，同时通过置信度掩膜方法提高高精度拾取机器人的表现，并证明该方法可以显著减少机器人系统中的关键错误。 |
| [^46] | [Few-shot Event Detection: An Empirical Study and a Unified View.](http://arxiv.org/abs/2305.01901) | 本文从两个实用的设置出发，分析比较了十种代表性的小样本事件检测方法，归纳总结出了原型方法的性能优越性，并在此基础上提出了一种简单且有效的方法。 |
| [^47] | [Revolutionizing Agrifood Systems with Artificial Intelligence: A Survey.](http://arxiv.org/abs/2305.01899) | 这篇论文探讨了人工智能技术在农业食品系统中的应用，重点关注了农业、畜牧业和渔业等领域。人工智能技术在农业食品分类、生长监测、产量预测和品质评估等方面表现出强大的能力，同时也提出了未来研究方向以及潜在的挑战和限制。 |
| [^48] | [VSRQ: Quantitative Assessment Method for Safety Risk of Vehicle Intelligent Connected System.](http://arxiv.org/abs/2305.01898) | 本文提出了一种新的车辆安全风险评估模型：VSRQ模型。通过结合I-FAHP和FCA聚类，挖掘车辆智能联接系统的易受攻击组件，并对其进行优先测试，以降低风险并确保车辆安全。 |
| [^49] | [Causality-aware Concept Extraction based on Knowledge-guided Prompting.](http://arxiv.org/abs/2305.01876) | 该论文提出了一种基于因果感知的知识引导提示方法，将其作为干预器装备到基于预训练语言模型的句子提取器中，以缓解概念偏差。在代表性的多语言KG数据集上进行广泛实验，获得了最先进的结果。 |
| [^50] | [GPTutor: a ChatGPT-powered programming tool for code explanation.](http://arxiv.org/abs/2305.01863) | 本文介绍了一种名为GPTutor的ChatGPT动力编程工具，它是一个使用ChatGPT API的Visual Studio Code扩展，通过设计提示词，可以对所选代码进行精简、准确的解释。 |
| [^51] | [Multimodal Data Augmentation for Image Captioning using Diffusion Models.](http://arxiv.org/abs/2305.01855) | 本文提出了一种基于扩增数据的扩散模型多模态图像描述方法，用于生成高质量的图像-描述对，并在 MS COCO 数据集上实验表明其优于几个基准方法，并且在训练数据较少的情况下表现出显著的提升。 |
| [^52] | [LineFormer: Rethinking Line Chart Data Extraction as Instance Segmentation.](http://arxiv.org/abs/2305.01837) | 本文提出了一种使用实例分割的稳健线数据提取方法LineFormer，旨在解决多线图中视觉和结构变化所带来的挑战，其在多个基准数据集上实现了最先进的性能。 |
| [^53] | [Autonomous search of real-life environments combining dynamical system-based path planning and unsupervised learning.](http://arxiv.org/abs/2305.01834) | 本文提出了一种自动生成基于动态系统路径规划器和无监督机器学习技术相结合的算法，以克服混沌覆盖路径规划器的立即问题，并在模拟和实际环境中进行了测试，展示其在有限环境中实现自主搜索和覆盖的能力。 |
| [^54] | [KEPLET: Knowledge-Enhanced Pretrained Language Model with Topic Entity Awareness.](http://arxiv.org/abs/2305.01810) | 本文提出了一种知识增强预训练语言模型，即KEPLET，在预训练语料中加入主题实体感知，从而改善了实体交互和词语语义表示。 |
| [^55] | [When Newer is Not Better: Does Deep Learning Really Benefit Recommendation From Implicit Feedback?.](http://arxiv.org/abs/2305.01801) | 本研究对多个神经推荐模型与传统模型进行比较，提出了一组评估策略来衡量其记忆性能、泛化性能和子群特定性能，揭示了在IMDB和Yelp数据集上，神经推荐模型与传统模型的差异性。 |
| [^56] | [Vision Meets Definitions: Unsupervised Visual Word Sense Disambiguation Incorporating Gloss Information.](http://arxiv.org/abs/2305.01788) | 本文提出了一种无监督的视觉词义消歧方法，通过引入外部词汇知识库的词义信息来解决原来图像-文本匹配模型中的多义词问题。采用贝叶斯推断来加入词义定义，并通过与上下文相关的 GPT-3 定义生成方法，成功解决了词典外问题。 |
| [^57] | [Cheap and Deterministic Inference for Deep State-Space Models of Interacting Dynamical Systems.](http://arxiv.org/abs/2305.01773) | 本文提出了一种利用图神经网络建模大规模动态系统的深度状态空间模型，在保持多峰预测分布的准确性的同时，通过确定性矩匹配规则实现了无样本推断，提高了预测的效率和稳定性。 |
| [^58] | [Psychologically-Inspired Causal Prompts.](http://arxiv.org/abs/2305.01764) | 本文提出了三个因果提示语，涵盖了情感分类任务中人类的心理过程。这些提示语可以用来产生更准确和可解释的模型预测。 |
| [^59] | [Spatial-Temporal Networks for Antibiogram Pattern Prediction.](http://arxiv.org/abs/2305.01761) | 本文提出了一个新颖的问题，即抗生素敏感性图案预测，旨在预测未来哪些图案将出现，并解决了这一问题遇到的挑战。 |
| [^60] | [Evaluation of Speaker Anonymization on Emotional Speech.](http://arxiv.org/abs/2305.01759) | 本文研究了VoicePrivacy 2020 Challenge中演讲者匿名化对情感语音的影响，并发现其未能有效地保护演讲者的隐私。 |
| [^61] | [Few-shot In-context Learning for Knowledge Base Question Answering.](http://arxiv.org/abs/2305.01750) | 该论文提出了KB-BINDER框架，通过少量的上下文演示实现了在多个知识库问答数据集上的背景学习，大大提高了KBQA问题的可解性。 |
| [^62] | [Expectation Maximization Pseudo Labelling for Segmentation with Limited Annotations.](http://arxiv.org/abs/2305.01747) | 本文提出了一种伪标签的泛化方法，称为贝叶斯伪标签，在半监督医学图像分割任务中应用效果良好。 |
| [^63] | [Leveraging Factored Action Spaces for Efficient Offline Reinforcement Learning in Healthcare.](http://arxiv.org/abs/2305.01738) | 本论文提出了一种利用因子化动作空间的线性Q函数分解形式的方法，用于解决离线强化学习中存在的动作组合问题，该方法在提高采样效率的同时并不牺牲策略最优性，通过模拟器和实际数据集的几个离线强化学习问题的实验表明，相较于标准方法，该方法具有更快的收敛速度、更好的性能和更高的采样效率。 |
| [^64] | [Construction of Decision Trees and Acyclic Decision Graphs from Decision Rule Systems.](http://arxiv.org/abs/2305.01721) | 该论文探讨了从决策规则系统构建决策树和无环决策图的复杂性，并讨论了不必构建完整决策树而只需描述给定输入的计算路径的可能性。 |
| [^65] | [Learning Disentangled Semantic Spaces of Explanations via Invertible Neural Networks.](http://arxiv.org/abs/2305.01713) | 本文介绍了一种使用可逆神经网络将BERT-GPT2自动编码器的隐藏空间转换为更可分离的语义空间的方法，实验结果表明此方法可以改进模型的可解释性和可控性，并取得了比最先进模型更好的性能表现。 |
| [^66] | [Fears about AI-mediated communication are grounded in different expectations for one's own versus others' use.](http://arxiv.org/abs/2305.01670) | 人们对AI调解沟通技术的秘密使用持消极态度，期望别人的使用率比实际情况高，很多人认为别人对AICTs使用不负责任，这些因素可能导致关于AI调解沟通技术的错误看法。 |
| [^67] | [Visual Reasoning: from State to Transformation.](http://arxiv.org/abs/2305.01668) | 提出了一个“以变换为驱动”的视觉推理（TVR）任务，旨在解决已有任务仅关注静态环境状态限制的问题。基于CLEVR构建了合成数据集和真实数据集进行验证。 |
| [^68] | [SIA-FTP: A Spoken Instruction Aware Flight Trajectory Prediction Framework.](http://arxiv.org/abs/2305.01661) | 提出一种语音指令感知的飞行轨迹预测框架，通过融合即时的语音指令和飞行轨迹表示，解决了语音指令和飞行轨迹的模态差距问题，在多个真实世界数据集上表现优异。 |
| [^69] | [Data valuation: The partial ordinal Shapley value for machine learning.](http://arxiv.org/abs/2305.01660) | 本文提出了偏序 Shapley 值的定义，并提出三种算法来近似计算结果，以解决数据合作中顺序作用的问题。 |
| [^70] | [FlightBERT++: A Non-autoregressive Multi-Horizon Flight Trajectory Prediction Framework.](http://arxiv.org/abs/2305.01658) | FlightBERT++提出了一种非自回归的多时域飞行轨迹预测框架，通过引入时域感知上下文生成器解决了误差累积和低效率的问题。 |
| [^71] | [Scalable Data Point Valuation in Decentralized Learning.](http://arxiv.org/abs/2305.01657) | 该文提出了一种名为DDVal的方法，用于在联邦和群智学习中的分散式数据估值，可以估算单个数据点的价值。DDVal基于共享深度特征，并通过k最近邻逼近方法来估算Shapley值，可用于同时向机构和个人奖励为分散式机器学习任务提供数据的贡献。同时，DDVal对机构的贡献进行了层次化的结论，并在实验证明其估算机构贡献的准确性较现有的联邦学习Shapley值逼近方法更高。 |
| [^72] | [From Words to Code: Harnessing Data for Program Synthesis from Natural Language.](http://arxiv.org/abs/2305.01598) | 该论文利用数据上下文对大型语言模型生成的代码进行语义重排，以生成更优质的程序。 |
| [^73] | [How to Unleash the Power of Large Language Models for Few-shot Relation Extraction?.](http://arxiv.org/abs/2305.01555) | 本文通过使用GPT-3.5模型在少样本关系抽取中，实现在四个不同数据集上的新的最优性能，并提出了与任务相关的指导说明和约束模式下的数据生成方法。 |
| [^74] | [Sample Efficient Model-free Reinforcement Learning from LTL Specifications with Optimality Guarantees.](http://arxiv.org/abs/2305.01381) | 本文提出了一种基于LTL规范的无模型强化学习方法，该方法结合乘积MDP、奖励结构和折扣机制有效地学习并优化未知随机系统最大化满足LTL规范的概率的最优策略。 |
| [^75] | [Prompt as Triggers for Backdoor Attack: Examining the Vulnerability in Language Models.](http://arxiv.org/abs/2305.01219) | 本研究提出一种新颖有效的“ProAttack”方法来执行干净标签的后门攻击，使用的是提示本身作为触发器。该方法不需要外部触发器，并确保毒瘤数据的标注正确，提高了后门攻击的隐蔽性，相比于现有的后门攻击方法有显著提升。 |
| [^76] | [CryCeleb: A Speaker Verification Dataset Based on Infant Cry Sounds.](http://arxiv.org/abs/2305.00969) | CryCeleb是一个基于婴儿哭声的说话人认证数据集，包括超过6小时的手动分割哭声，可用于研究婴儿哭声分析。 |
| [^77] | [Discrepancy-Guided Reconstruction Learning for Image Forgery Detection.](http://arxiv.org/abs/2304.13349) | 本论文提出了一种基于差异引导的图像篡改检测方法，能够提升模型对篡改敏感且具有紧凑视觉模式的学习能力，具有较广泛的推广性。 |
| [^78] | [Auditing and Generating Synthetic Data with Controllable Trust Trade-offs.](http://arxiv.org/abs/2304.10819) | 本论文提出了一个审计框架，能够以全面的方式评估合成数据和AI模型的具体效果，包括偏见和歧视预防、对真实数据的忠实程度、效用、鲁棒性和隐私保护。在多个用例中，审计框架平衡了信任和效用之间的权衡。 |
| [^79] | [GREAT Score: Global Robustness Evaluation of Adversarial Perturbation using Generative Models.](http://arxiv.org/abs/2304.09875) | 本文提出了一个新的框架——GREAT分数，用于使用生成模型对对抗性扰动进行全局鲁棒性评估。该分数捕捉了所有样本中的平均认证防攻击扰动水平，无需运行对抗性攻击。 |
| [^80] | [Optimizing Group Utility in Itinerary Planning: A Strategic and Crowd-Aware Approach.](http://arxiv.org/abs/2304.08495) | 本论文介绍了一种名为SCAIR的算法，可以优化群体效用，解决行程规划中的多个用户排队时间和人群水平优化的问题。 |
| [^81] | [ImpressionGPT: An Iterative Optimizing Framework for Radiology Report Summarization with ChatGPT.](http://arxiv.org/abs/2304.08448) | ImpressionGPT是一个利用LLMs构建动态上下文的迭代优化框架，用于放射学报告摘要生成。相对于其他方法，ImpressionGPT在具有较好泛化性能的同时，成功提高了放射学报告摘要的生成能力。 |
| [^82] | [Multimodal Image-Text Matching Improves Retrieval-based Chest X-Ray Report Generation.](http://arxiv.org/abs/2303.17579) | 本研究提出了一种基于检索的放射性医学报告生成模块 X-REM，它使用图像文本匹配分数来衡量胸部 X 光图像和放射学报告之间的相似度，以进行报告检索，其在多个先前的放射学报告生成模块中表现优异，可有效提高放射学报告的自动生成精度。 |
| [^83] | [A Categorical Framework of General Intelligence.](http://arxiv.org/abs/2303.04571) | 本文介绍了一个通用智能的范畴框架，涉及对象和场景的表示及模拟，并提出了相应的算法和不变性属性，可以用于解决AI的可解释性和安全问题。 |
| [^84] | [Unsupervised Task Graph Generation from Instructional Video Transcripts.](http://arxiv.org/abs/2302.09173) | 本文提出了一种无监督的任务图生成方法，通过结合支持指导的语言模型的推理能力和聚类、排序组件，从执行真实世界活动的教学视频文本记录中生成任务图。实验结果表明该方法在ProceL和CrossTask数据集上比监督学习方法生成的任务图更加准确。 |
| [^85] | [DocILE Benchmark for Document Information Localization and Extraction.](http://arxiv.org/abs/2302.05658) | 本文介绍了DocILE基准数据集，该数据集包含大量商务文件，可用于关键信息定位和提取以及行项目识别任务。该数据集具有55个类别的注释，超过以往发布的数据集，同时包括众多不同布局和未标记的文档，为该领域提供了有力的研究工具。 |
| [^86] | [APAM: Adaptive Pre-training and Adaptive Meta Learning in Language Model for Noisy Labels and Long-tailed Learning.](http://arxiv.org/abs/2302.03488) | 本文提出了APAM框架，通过整合自适应预训练和元学习的方法，成功解决了长尾和噪声标签带来的挑战，实验证明该方法的效果优于现有最新方法。 |
| [^87] | [Probabilistic Contrastive Learning Recovers the Correct Aleatoric Uncertainty of Ambiguous Inputs.](http://arxiv.org/abs/2302.02865) | 本文提出利用概率对比学习方法可以恢复具有不确定性输入的正确估计，通过扩展InfoNCE目标和编码器以预测潜变量分布来实现，在计算已知查询图像的可信区间方面具有应用价值。 |
| [^88] | [Deep Reinforcement Learning for Online Error Detection in Cyber-Physical Systems.](http://arxiv.org/abs/2302.01567) | 本文提出了一种基于深度强化学习（DRL）的新型在线错误检测方法。 |
| [^89] | [A novel framework for medium-term wind power prediction based on temporal attention mechanisms.](http://arxiv.org/abs/2302.01222) | 本文提出了一种基于树状Parzen估计器（TPE）和分解算法的新框架（TPE-VMD-TFT），用于24小时和48小时之前的风电功率预测。在法国电力公司Engie的风能数据集上，所提出的方法表现良好。 |
| [^90] | [Surgical Aggregation: A Collaborative Learning Framework for Harmonizing Distributed Medical Imaging Datasets with Diverse Tasks.](http://arxiv.org/abs/2301.06683) | 本论文提出了一种手术聚合的协同学习框架，该框架可用于协调和聚合分布式医学影像数据集的知识，并带有部分疾病注释，从而可训练具有完整胸部内可能出现的所有异常的临床实用、强大模型。 |
| [^91] | [Self-Adaptive In-Context Learning: An Information Compression Perspective for In-Context Example Selection and Ordering.](http://arxiv.org/abs/2212.10375) | 这篇论文提出了自适应上下文学习的原则，通过引入自适应机制帮助每个样本找到正确的上下文示例排列，从而最大化表现。通过广泛的评估，在8个不同的NLP数据集上，自适应ICL方法相对于常规设置提高了40%的相对改进。 |
| [^92] | [Don't Generate, Discriminate: A Proposal for Grounding Language Models to Real-World Environments.](http://arxiv.org/abs/2212.09736) | Pangu是一个泛用的框架，用于实现语言模型与现实环境的接轨，它利用语言模型的辨别能力而非生成能力，由一个符号代理和一个神经语言模型协同工作。这一方案已经在知识库问答问题中证明了它的有效性和灵活性。 |
| [^93] | [Monte Carlo Planning in Hybrid Belief POMDPs.](http://arxiv.org/abs/2211.07735) | 本文提出了HB-MCP算法，利用蒙特卡罗树搜索算法解决POMDP问题，并保持混合置信度。该算法优于不支持混合置信度的最先进在线求解器，并且在更大的计划范围内具有可扩展性和鲁棒性。 |
| [^94] | [Low-Resource Music Genre Classification with Cross-Modal Neural Model Reprogramming.](http://arxiv.org/abs/2211.01317) | 本文提出了一种基于神经模型重新编程的迁移学习方法，并针对复杂输入数据提出了输入依赖NMR范式，能够有效地进行音乐风格分类。 |
| [^95] | [Discovering Many Diverse Solutions with Bayesian Optimization.](http://arxiv.org/abs/2210.10953) | ROBOT是一种新的贝叶斯优化方法，可以找到一组高性能、多样化的解决方案，解决了传统单目标贝叶斯优化方法只能找到一个最佳解决方案的局限性。 |
| [^96] | [Training Efficient Controllers via Analytic Policy Gradient.](http://arxiv.org/abs/2209.13052) | 本文提出了一种名为“解析策略梯度（APG）”的离线学习控制器方法，在跟踪误差上使用梯度下降算法，通过可微分仿真器离线训练控制器。该方法可在算力有限的系统上实现高效，精确的控制。 |
| [^97] | [Learning a Single Near-hover Position Controller for Vastly Different Quadcopters.](http://arxiv.org/abs/2209.09232) | 本文介绍了一种适用于不同大小无人机的单一近悬停位置控制器，通过神经网络学习动态适应不同无人机参数和干扰，实现快速运行并成功适应外部干扰。 |
| [^98] | [ImGCL: Revisiting Graph Contrastive Learning on Imbalanced Node Classification.](http://arxiv.org/abs/2205.11332) | 本文提出了一种名为"ImGCL"的图形对比学习（GCL）算法框架，该框架能够自动自适应地平衡不平衡节点分类问题中从无标签节点（图）中学到的表示，通过整合在线聚类和逐步平衡采样方法，我们的算法可以有效地学习区分表示，实现与先进技术相当的性能。 |
| [^99] | [Gradient Aligned Attacks via a Few Queries.](http://arxiv.org/abs/2205.09518) | 该论文提出了一种梯度对齐攻击方法，通过设计梯度对齐损失在代理模型上估计准确梯度，提高在少量查询的情况下对深度学习模型的攻击效果。 |
| [^100] | [Contrastive Learning of Sociopragmatic Meaning in Social Media.](http://arxiv.org/abs/2203.07648) | 提出了一种社交媒体中社会语用意义的对比学习框架，该框架能够学习可迁移的任务不可知表示学习，并在各种对比学习框架中表现最佳。 |
| [^101] | [Generalization of graph network inferences in higher-order graphical models.](http://arxiv.org/abs/2107.05729) | 本论文提出了递归因子图神经网络(RF-GNN)，用于实现对涉及多变量相互作用的图形模型的快速近似推断。在多个图形模型家族的实验中展示了RF-GNN在表达性图形模型中快速且准确地执行推断的潜力。 |
| [^102] | [Uni-Encoder: A Fast and Accurate Response Selection Paradigm for Generation-Based Dialogue Systems.](http://arxiv.org/abs/2106.01263) | 论文提出一种新的响应选择范例Uni-Encoder，解决了Cross-Encoder多次编码相同上下文计算成本高和Poly-Encoder性能下降的问题。该范例在一次前向传递中对所有候选与上下文进行编码。 |

# 详细

[^1]: 自动摘要中的政治偏见特征分析：以特朗普和拜登为例的案例研究

    Characterizing Political Bias in Automatic Summaries: A Case Study of Trump and Biden. (arXiv:2305.02321v1 [cs.CL])

    [http://arxiv.org/abs/2305.02321](http://arxiv.org/abs/2305.02321)

    本文研究了自动生成新闻文章摘要中的政治偏见。研究发现，与特朗普相比，更多的美国政府集体机构（即政府）与拜登相关联。这些发现为未来的摘要偏见研究提供了一个框架。

    

    越来越多的文献表明，强大的NLP系统可能对社会偏见进行编码；然而，自动摘要模型的政治偏见仍相对未知。在这项工作中，我们使用实体替换方法研究了新闻文章自动生成摘要中的政治家描绘。我们基于政治实体和词汇资源开发了一个计算框架，并使用它来评估抽取式和抽象式摘要模型中有关唐纳德·特朗普和乔·拜登的偏见。我们发现了一些一致的差异，例如在与特朗普相比，更多的美国政府集体机构（即政府）与拜登相关联。当实体在源文章中重点出现时，这些摘要差异最为明显。我们的系统化特征分析提供了一个未来研究摘要偏见的框架。

    Growing literature has shown that powerful NLP systems may encode social biases; however, the political bias of summarization models remains relatively unknown. In this work, we use an entity replacement method to investigate the portrayal of politicians in automatically generated summaries of news articles. We develop a computational framework based on political entities and lexical resources, and use it to assess biases about Donald Trump and Joe Biden in both extractive and abstractive summarization models. We find consistent differences, such as stronger associations of a collective US government (i.e., administration) with Biden than with Trump. These summary dissimilarities are most prominent when the entity is heavily featured in the source article. Our systematic characterization provides a framework for future studies of bias in summarization.
    
[^2]: 适用于单张图像人像的实时辐射场合成

    Real-Time Radiance Fields for Single-Image Portrait View Synthesis. (arXiv:2305.02310v1 [cs.CV])

    [http://arxiv.org/abs/2305.02310](http://arxiv.org/abs/2305.02310)

    该论文提出了一种适用于单张图片的实时辐射场合成方法，能够从单张未经过姿势调整的图像中推断和渲染出逼真的3D表示，并产生高质量的3D感知人像合成结果。

    

    我们提出了一个单拍摄方法，可以从单张未经过姿势调整的图像（例如面部肖像）中推断和渲染出逼真的3D表示，并实时合成。 给定单个RGB输入，我们的图像编码器直接预测由神经辐射场的规范三面图表示，通过体渲染进行三维感知的新视图合成。我们的方法在消费级硬件上快速（24fps），且产生的质量高于需要测试时间优化的强GAN反演基线。为了训练三面图编码器管道，我们只使用合成数据，展示了如何从预训练的3D GAN中提取知识，并将其蒸馏成前馈编码器。技术贡献包括基于Vision Transformer的三面图编码器、相机数据增强策略以及针对合成数据训练的良好设计的损失函数。我们在最先进的方法上进行基准测试，在具有挑战性的现实世界场景中展示了显着的鲁棒性和图像质量改进。我们展示了我们的结果，表明它能够生成具有高质量的3D感知人像合成结果。

    We present a one-shot method to infer and render a photorealistic 3D representation from a single unposed image (e.g., face portrait) in real-time. Given a single RGB input, our image encoder directly predicts a canonical triplane representation of a neural radiance field for 3D-aware novel view synthesis via volume rendering. Our method is fast (24 fps) on consumer hardware, and produces higher quality results than strong GAN-inversion baselines that require test-time optimization. To train our triplane encoder pipeline, we use only synthetic data, showing how to distill the knowledge from a pretrained 3D GAN into a feedforward encoder. Technical contributions include a Vision Transformer-based triplane encoder, a camera data augmentation strategy, and a well-designed loss function for synthetic data training. We benchmark against the state-of-the-art methods, demonstrating significant improvements in robustness and image quality in challenging real-world settings. We showcase our res
    
[^3]: Fashionpedia-Taste：一个用于解释人类时尚品味的数据集

    Fashionpedia-Taste: A Dataset towards Explaining Human Fashion Taste. (arXiv:2305.02307v1 [cs.CV])

    [http://arxiv.org/abs/2305.02307](http://arxiv.org/abs/2305.02307)

    Fashionpedia-Taste是一个可解释性的时尚数据集，其中包含了局部属性，人类注意力和说明等多种因素，能够帮助研究人员从不同的人文视角和模态全面理解和解释人类的时尚品味。

    

    现有的时尚数据集并没有考虑导致消费者喜欢或不喜欢时尚图像的多种因素。即使有两个消费者喜欢相同的时尚图像，他们也可能因为完全不同的原因喜欢这个图像。本文研究了消费者为何喜欢某个时尚图像的原因。为达到这个目标，我们引入了一个可解释性数据集 Fashionpedia-taste，其中包含丰富的注释，以解释受试者从以下三个方面为什么会喜欢或不喜欢一张时尚图像：1）局部属性；2）人类注意力；3）说明。此外，受试者被要求提供他们的个人属性和时尚偏好，例如个性和喜欢的时尚品牌。我们的数据集使研究人员能够建立计算模型，从不同的人文视角和模态全面理解和解释人类的时尚品味。

    Existing fashion datasets do not consider the multi-facts that cause a consumer to like or dislike a fashion image. Even two consumers like a same fashion image, they could like this image for total different reasons. In this paper, we study the reason why a consumer like a certain fashion image. Towards this goal, we introduce an interpretability dataset, Fashionpedia-taste, consist of rich annotation to explain why a subject like or dislike a fashion image from the following 3 perspectives: 1) localized attributes; 2) human attention; 3) caption. Furthermore, subjects are asked to provide their personal attributes and preference on fashion, such as personality and preferred fashion brands. Our dataset makes it possible for researchers to build computational models to fully understand and interpret human fashion taste from different humanistic perspectives and modalities.
    
[^4]: 校准化解释：基于不确定性信息和反事实的解释模型

    Calibrated Explanations: with Uncertainty Information and Counterfactuals. (arXiv:2305.02305v1 [cs.AI])

    [http://arxiv.org/abs/2305.02305](http://arxiv.org/abs/2305.02305)

    该论文提出了一种新的特征重要性解释方法，Calibrated Explanations (CE)，它可以提供准确、稳定的解释，并且可以为概率估计和特征重要性权重提供不确定性量化信息，是一种快速、可靠且强健的解释方法。

    

    人工智能已经成为各种领域决策支持系统中不可或缺的一部分，但人工智能决策系统中预测模型缺乏透明度可能导致滥用或不使用。可解释人工智能旨在创建可以向人类用户解释其推理过程的人工智能系统。可解释人工智能中的局部解释可以提供关于特征重要性的个别预测原因的信息，但存在不稳定性等缺点。为了解决这些问题，我们提出了一种新的特征重要性解释方法，校准化解释(Calibrated Explanations，CE)，它基于 Venn-Abers，同时在生成特征重要性解释的同时校准底层模型。CE不仅提供快速、可靠、稳定和强健的解释，还提供概率估计和特征重要性权重的不确定性量化。此外，该方法是模型无关的，具有易于理解的条件规则，也可以生成反事实推理。

    Artificial Intelligence (AI) has become an integral part of decision support systems (DSSs) in various domains, but the lack of transparency in the predictive models used in AI-based DSSs can lead to misuse or disuse. Explainable Artificial Intelligence (XAI) aims to create AI systems that can explain their rationale to human users. Local explanations in XAI can provide information about the causes of individual predictions in terms of feature importance, but they suffer from drawbacks such as instability. To address these issues, we propose a new feature importance explanation method, Calibrated Explanations (CE), which is based on Venn-Abers and calibrates the underlying model while generating feature importance explanations. CE provides fast, reliable, stable, and robust explanations, along with uncertainty quantification of the probability estimates and feature importance weights. Furthermore, the method is model agnostic with easily understood conditional rules and can also genera
    
[^5]: Distilling Step-by-Step！使用更少的训练数据和更小的模型尺寸胜过更大的语言模型

    Distilling Step-by-Step! Outperforming Larger Language Models with Less Training Data and Smaller Model Sizes. (arXiv:2305.02301v1 [cs.CL])

    [http://arxiv.org/abs/2305.02301](http://arxiv.org/abs/2305.02301)

    本研究提出了Distilling Step-by-Step机制，通过提取LLM基础信息为小型模型提供额外的监督训练，从而使它们胜过更大的LLM模型，并需更少的训练数据。

    

    部署大型语言模型（LLM）面临内存效率低和计算密集度高的问题，研究人员通过微调或精炼使用LLM生成的标签来训练较小的任务特定模型。但是，要想达到LLM相当的性能，这需要大量的训练数据。我们引入了Distilling Step-by-Step，这是一种新的机制， (a)训练较小的模型比LLM表现更好，(b)并通过利用微调或精炼所需的更少的训练数据来实现。我们的方法在多任务训练框架中提取LLM基础，并作为额外的监督来训练小型模型。在四个NLP基准测试中，我们提出了三个发现：第一，与微调和精炼相比，我们的机制使用较少的标记/未标记训练示例取得更好的性能。第二，与LLM相比，即使使用更小的模型，我们也实现了更好的性能。

    Deploying large language models (LLMs) is challenging because they are memory inefficient and compute-intensive for practical applications. In reaction, researchers train smaller task-specific models by either finetuning with human labels or distilling using LLM-generated labels. However, finetuning and distillation require large amounts of training data to achieve comparable performance to LLMs. We introduce Distilling step-by-step, a new mechanism that (a) trains smaller models that outperform LLMs, and (b) achieves so by leveraging less training data needed by finetuning or distillation. Our method extracts LLM rationales as additional supervision for small models within a multi-task training framework. We present three findings across 4 NLP benchmarks: First, compared to both finetuning and distillation, our mechanism achieves better performance with much fewer labeled/unlabeled training examples. Second, compared to LLMs, we achieve better performance using substantially smaller m
    
[^6]: 评估长度可控机器翻译的有效性

    Evaluating the Efficacy of Length-Controllable Machine Translation. (arXiv:2305.02300v1 [cs.CL])

    [http://arxiv.org/abs/2305.02300](http://arxiv.org/abs/2305.02300)

    本文评估了长度可控机器翻译的自动评估指标，发现BLEURT和COMET是最适合作为其评估指标的。

    

    长度可控机器翻译是一种约束翻译，旨在在控制翻译长度的同时尽可能保留原始含义。我们可以使用自动摘要或机器翻译评估指标进行长度可控机器翻译，但这并不一定适用和准确。这项工作是第一次系统评估长度可控机器翻译任务的自动评估指标。我们在两个翻译方向上进行了严格的人工评估，并评估了18个摘要或翻译评估指标。我们发现BLEURT和COMET与人工评估的相关性最高，最适合作为长度可控机器翻译的评估指标。

    Length-controllable machine translation is a type of constrained translation. It aims to contain the original meaning as much as possible while controlling the length of the translation. We can use automatic summarization or machine translation evaluation metrics for length-controllable machine translation, but this is not necessarily suitable and accurate. This work is the first attempt to evaluate the automatic metrics for length-controllable machine translation tasks systematically. We conduct a rigorous human evaluation on two translation directions and evaluate 18 summarization or translation evaluation metrics. We find that BLEURT and COMET have the highest correlation with human evaluation and are most suitable as evaluation metrics for length-controllable machine translation.
    
[^7]: DynamicStereo：来自立体视频的一致动态深度

    DynamicStereo: Consistent Dynamic Depth from Stereo Videos. (arXiv:2305.02296v1 [cs.CV])

    [http://arxiv.org/abs/2305.02296](http://arxiv.org/abs/2305.02296)

    本文提出了一种新颖的 DynamicStereo 架构，用于从立体视频中估计视差，并从相邻帧中汇集信息，以改善其预测的时间一致性。同时，提出了一个新的 Dynamic Replica 数据集作为基准数据集，更接近真实应用场景，用于训练和评估动态立体的性能。

    

    本文考虑从立体摄像头观察的动态场景中重建深度的问题。大多数现有的立体深度方法独立地对待不同的立体帧，导致时间上不一致的深度预测。对于沉浸式 AR 或 VR 场景，时间一致性尤其重要，因为闪烁会大大降低用户体验。我们提出了 DynamicStereo，一种新颖的基于 transformer 的体系结构，用于估计立体视频的视差。网络学习从相邻帧中汇集信息，以改善其预测的时间一致性。我们的体系结构设计通过划分注意力层来高效处理立体视频。我们还介绍了 Dynamic Replica，这是一个新的基准数据集，其中包含扫描环境中的人和动物的合成视频，为动态立体更接近真实应用提供了补充的训练和评估数据。使用这个数据集的训练进一步提高了模型预测的性能。

    We consider the problem of reconstructing a dynamic scene observed from a stereo camera. Most existing methods for depth from stereo treat different stereo frames independently, leading to temporally inconsistent depth predictions. Temporal consistency is especially important for immersive AR or VR scenarios, where flickering greatly diminishes the user experience. We propose DynamicStereo, a novel transformer-based architecture to estimate disparity for stereo videos. The network learns to pool information from neighboring frames to improve the temporal consistency of its predictions. Our architecture is designed to process stereo videos efficiently through divided attention layers. We also introduce Dynamic Replica, a new benchmark dataset containing synthetic videos of people and animals in scanned environments, which provides complementary training and evaluation data for dynamic stereo closer to real applications than existing datasets. Training with this dataset further improves 
    
[^8]: 基于生物启发式神经动力学和自适应滑模创新滤波的移动机器人分布式领航者跟随者编队控制

    Distributed Leader Follower Formation Control of Mobile Robots based on Bioinspired Neural Dynamics and Adaptive Sliding Innovation Filter. (arXiv:2305.02288v1 [cs.RO])

    [http://arxiv.org/abs/2305.02288](http://arxiv.org/abs/2305.02288)

    本文提出了一种基于生物启发式神经动力学的编队控制方法，结合自适应滑模创新滤波器，能够解决传统设计中存在的速度跳跃问题和抖动问题，并提供额外的鲁棒性和平滑的控制输入。

    

    本文研究了多个差动驱动移动机器人的分布式领航者跟随者编队控制问题。首先引入了分布式估计器，它仅需要每个跟随者自身和其相邻机器人的状态信息。然后，我们提出了一种基于生物启发式神经动力学的反步和滑模控制混合编队控制方法，并证明了其稳定性。所提出的控制策略解决了传统反步设计中存在的不切实际的速度跳跃问题。此外，考虑到系统和测量噪声，所提出的控制策略不仅消除了传统滑模控制中存在的抖动问题，还提供了额外的鲁棒性和平滑的控制输入。然后，将自适应滑模创新滤波器与所提出的控制结合起来，以提供鲁棒的状态估计，能够克服建模不确定性。最后，我们进行了多次仿真来演示创新方法的有效性。

    This paper investigated the distributed leader follower formation control problem for multiple differentially driven mobile robots. A distributed estimator is first introduced and it only requires the state information from each follower itself and its neighbors. Then, we propose a bioinspired neural dynamic based backstepping and sliding mode control hybrid formation control method with proof of its stability. The proposed control strategy resolves the impractical speed jump issue that exists in the conventional backstepping design. Additionally, considering the system and measurement noises, the proposed control strategy not only removes the chattering issue existing in the conventional sliding mode control but also provides smooth control input with extra robustness. After that, an adaptive sliding innovation filter is integrated with the proposed control to provide accurate state estimates that are robust to modeling uncertainties. Finally, we performed multiple simulations to demo
    
[^9]: Learngene: 从祖先模型中继承压缩知识到后代模型

    Learngene: Inheriting Condensed Knowledge from the Ancestry Model to Descendant Models. (arXiv:2305.02279v1 [cs.LG])

    [http://arxiv.org/abs/2305.02279](http://arxiv.org/abs/2305.02279)

    本文提出了一种机器学习范式 Learngene，将积累的知识压缩成更为紧凑的信息片段并继承给后代模型，以便于适应新的环境

    

    在一个生物的连续进化过程中，它的基因积累了广泛的经验和知识，使新生后代能够快速适应其特定环境。受到这一观察的启发，我们提出了一种新的机器学习范 paradigm，即 Learngene，使学习模型能够融合基因的三个关键特征。 (i) 积累：知识在祖先模型的连续学习过程中积累。 (ii) 压缩：将积累的详尽知识压缩成更为紧凑的信息片段，即 Learngene。 (iii) 继承：将压缩的 Learngene 继承给后代模型，以便于适应新的环境。由于积累已在一些成熟的范式中得到研究，如大规模预训练和终身学习，因此我们专注于压缩和继承，这引发了三个关键问题，并为这些问题提供了初步的解决方案。

    During the continuous evolution of one organism's ancestry, its genes accumulate extensive experiences and knowledge, enabling newborn descendants to rapidly adapt to their specific environments. Motivated by this observation, we propose a novel machine learning paradigm \textit{Learngene} to enable learning models to incorporate three key characteristics of genes. (i) Accumulating: the knowledge is accumulated during the continuous learning of an \textbf{ancestry model}. (ii) Condensing: the exhaustive accumulated knowledge is condensed into a much more compact information piece, \ie \textbf{learngene}. (iii): Inheriting: the condensed \textbf{learngene} is inherited to make it easier for \textbf{descendant models} to adapt to new environments. Since accumulating has been studied in some well-developed paradigms like large-scale pre-training and lifelong learning, we focus on condensing and inheriting, which induces three key issues and we provide the preliminary solutions to these is
    
[^10]: 基于中转的级联翻译模型的端到端训练与解码方法

    End-to-end Training and Decoding for Pivot-based Cascaded Translation Model. (arXiv:2305.02261v1 [cs.CL])

    [http://arxiv.org/abs/2305.02261](http://arxiv.org/abs/2305.02261)

    本文提出了一种端到端训练方法，并配置了改进的解码算法，即基于中转的级联翻译模型，使用加权中转语言嵌入输入模型，利用波束搜索缓解标记和概率分布之间的不一致性。实验证明，该方法提高了翻译的质量。

    

    利用中转语言可以显著提高低资源机器翻译效果。通常，源语言到中转语言模型和中转语言到目标语言模型分别训练，没有利用有限的（源语言，目标语言）并行数据。本文提出了一种用于级联翻译模型的端到端训练方法，并配置了改进的解码算法。中转语言到目标语言模型的输入根据源语言到中转语言模型的概率分布修改为加权中转语言嵌入，从而可以进行端到端训练。此外，当使用中转语言解码中的波束搜索时，我们缓解了标记和概率分布之间的不一致性。实验结果表明，我们的方法提高了翻译的质量。

    Utilizing pivot language effectively can significantly improve low-resource machine translation. Usually, the two translation models, source-pivot and pivot-target, are trained individually and do not utilize the limited (source, target) parallel data. This work proposes an end-to-end training method for the cascaded translation model and configures an improved decoding algorithm. The input of the pivot-target model is modified to weighted pivot embedding based on the probability distribution output by the source-pivot model. This allows the model to be trained end-to-end. In addition, we mitigate the inconsistency between tokens and probability distributions while using beam search in pivot decoding. Experiments demonstrate that our method enhances the quality of translation.
    
[^11]: 场景生成的情境推理（技术报告）

    Contextual Reasoning for Scene Generation (Technical Report). (arXiv:2305.02255v1 [cs.AI])

    [http://arxiv.org/abs/2305.02255](http://arxiv.org/abs/2305.02255)

    本文展示了如何将MR-CKR框架应用于真实的自主车辆场景数据，以生成具有挑战性的场景问题。实验表明，我们的框架可以有效生成多样化和具有挑战性的场景，为提高自主车辆安全导航的培训提供了有希望的解决方案。

    

    本文是我们先前工作的延续，在该工作中，我们开发了MR-CKR框架，用于跨上下文组织的多关系层次中的知识覆盖推理。 推理通过具有代数度量的ASP实现，允许对偏好进行灵活的定义。在本文中，我们展示了如何将我们的理论工作应用于真实的自主车辆场景数据。该工作的目标是将MR-CKR应用于自主车辆学习中生成具有挑战性的场景问题。实际上，用于AV学习模型的大部分场景数据涵盖了常见情况，因此难以捕捉特定情况发生的情况（例如，行人横穿时的部分遮挡）。MR-CKR模型允许利用此类数据的多维性进行数据组织（例如，时间和空间）。在多个背景下进行推理，可以使用不同场景本体的组合验证和配置场景。我们描述了一个将MR-CKR模型集成到AV场景生成的数据处理管道中的框架。实验表明，我们的框架可以有效生成多样化和具有挑战性的场景，为提高自主车辆安全导航的培训提供了有希望的解决方案。

    We present a continuation to our previous work, in which we developed the MR-CKR framework to reason with knowledge overriding across contexts organized in multi-relational hierarchies. Reasoning is realized via ASP with algebraic measures, allowing for flexible definitions of preferences. In this paper, we show how to apply our theoretical work to real autonomous-vehicle scene data. Goal of this work is to apply MR-CKR to the problem of generating challenging scenes for autonomous vehicle learning. In practice, most of the scene data for AV learning models common situations, thus it might be difficult to capture cases where a particular situation occurs (e.g. partial occlusions of a crossing pedestrian). The MR-CKR model allows for data organization exploiting the multi-dimensionality of such data (e.g., temporal and spatial). Reasoning over multiple contexts enables the verification and configuration of scenes, using the combination of different scene ontologies. We describe a framew
    
[^12]: 自动化科学发现：从方程式探索到自主发现系统

    Automated Scientific Discovery: From Equation Discovery to Autonomous Discovery Systems. (arXiv:2305.02251v1 [cs.AI])

    [http://arxiv.org/abs/2305.02251](http://arxiv.org/abs/2305.02251)

    本文调研了自动化科学发现，介绍了各种方法和最近的话题，并概述了闭环科学发现系统和自主发现系统，其中最大级别不需要任何人类干预。该研究旨在发展能够产生诺贝尔级成果的AI科学家。

    

    本文调研了自动化科学发现，从方程式探索和符号回归到自主发现系统和代理。从“宏观”和上下文角度讨论了各种方法，但也讨论了开放问题和最近的话题，如深度神经网络在这个领域中的各种角色，帮助发现人类可解释的知识。此外，我们将介绍闭环科学发现系统，从Adam系统的开创性工作到当前在材料科学和天文学等领域的努力。最后，我们将从机器学习的角度详细阐述自主性，并以自动驾驶的自主级别为类比。最大级别，第五级，定义为在生产科学知识时不需要任何人类干预。实现这一点是迈向解决Nobel Turing Grand Challenge的一步：开发能够产生诺贝尔级科学成果的AI科学家 - 能力的一步。

    The paper surveys automated scientific discovery, from equation discovery and symbolic regression to autonomous discovery systems and agents. It discusses the individual approaches from a "big picture" perspective and in context, but also discusses open issues and recent topics like the various roles of deep neural networks in this area, aiding in the discovery of human-interpretable knowledge. Further, we will present closed-loop scientific discovery systems, starting with the pioneering work on the Adam system up to current efforts in fields from material science to astronomy. Finally, we will elaborate on autonomy from a machine learning perspective, but also in analogy to the autonomy levels in autonomous driving. The maximal level, level five, is defined to require no human intervention at all in the production of scientific knowledge. Achieving this is one step towards solving the Nobel Turing Grand Challenge to develop AI Scientists: AI systems capable of making Nobel-quality sc
    
[^13]: 标注描述训练在零样本文本分类中的好处

    The Benefits of Label-Description Training for Zero-Shot Text Classification. (arXiv:2305.02239v1 [cs.CL])

    [http://arxiv.org/abs/2305.02239](http://arxiv.org/abs/2305.02239)

    本文提出了标注描述训练的方法，在零样本分类中可以显著提高准确率，并能更鲁棒地处理分类任务。

    

    大型语言模型通过允许从训练数据中转移语义知识，提高了零样本文本分类的性能，本文提出了一种简单的方法，进一步提高零样本准确性。我们策划了一个小的微调数据集，旨在描述任务标签。与通常有文本标注标签的微调数据不同，我们的数据只是用语言描述标签，例如使用一些相关术语、词典/百科全书条目和短模板。我们的方法在各种主题和情感数据集上的准确性比零样本高15-17％绝对值。它还更具有零样本分类所需选择的鲁棒性，例如提示模型进行分类的模式以及从标签映射到模型词汇表中的令牌。此外，由于我们的数据仅描述标签但不使用输入文本，因此在其上微调的模型可以将分类的重点更专注于标签而不是文本。

    Large language models have improved zero-shot text classification by allowing the transfer of semantic knowledge from the training data in order to classify among specific label sets in downstream tasks. We propose a simple way to further improve zero-shot accuracies with minimal effort. We curate small finetuning datasets intended to describe the labels for a task. Unlike typical finetuning data, which has texts annotated with labels, our data simply describes the labels in language, e.g., using a few related terms, dictionary/encyclopedia entries, and short templates. Across a range of topic and sentiment datasets, our method is more accurate than zero-shot by 15-17% absolute. It is also more robust to choices required for zero-shot classification, such as patterns for prompting the model to classify and mappings from labels to tokens in the model's vocabulary. Furthermore, since our data merely describes the labels but does not use input texts, finetuning on it yields a model that p
    
[^14]: 构建可信人工智能：从人工智能原则、伦理和主要需求到负责任的人工智能系统和监管

    Connecting the Dots in Trustworthy Artificial Intelligence: From AI Principles, Ethics, and Key Requirements to Responsible AI Systems and Regulation. (arXiv:2305.02231v1 [cs.CY])

    [http://arxiv.org/abs/2305.02231](http://arxiv.org/abs/2305.02231)

    该论文旨在探讨可信人工智能的构建，包括从法律、伦理和技术、社会角度确保其健壮性。实现真正可信的人工智能涉及到更广阔的愿景，考虑到伦理方面、风险方面、以及对七个技术需求的支持度和大局整体之关系。

    

    可信人工智能基于七个技术需求，分别从法律、伦理和技术、社会角度确保其健壮性。然而，实现真正可信的人工智能涉及到更广阔的愿景，包括系统生命周期中所有参与流程和参与者可信性的考量。一个更全面的愿景将考虑到伦理方面、风险方面、以下要件的支持度以及大局整体之关系。评估七个需求之技术方面、伦理方面和监管挑战方面。

    Trustworthy Artificial Intelligence (AI) is based on seven technical requirements sustained over three main pillars that should be met throughout the system's entire life cycle: it should be (1) lawful, (2) ethical, and (3) robust, both from a technical and a social perspective. However, attaining truly trustworthy AI concerns a wider vision that comprises the trustworthiness of all processes and actors that are part of the system's life cycle, and considers previous aspects from different lenses. A more holistic vision contemplates four essential axes: the global principles for ethical use and development of AI-based systems, a philosophical take on AI ethics, a risk-based approach to AI regulation, and the mentioned pillars and requirements. The seven requirements (human agency and oversight; robustness and safety; privacy and data governance; transparency; diversity, non-discrimination and fairness; societal and environmental wellbeing; and accountability) are analyzed from a triple
    
[^15]: ChatGPT能通过入门级函数式语言编程课程吗？

    Can ChatGPT Pass An Introductory Level Functional Language Programming Course?. (arXiv:2305.02230v1 [cs.CY])

    [http://arxiv.org/abs/2305.02230](http://arxiv.org/abs/2305.02230)

    本研究测试了ChatGPT在入门级函数式语言编程课程中的表现，结果显示它可以获得B-的成绩并且能够给学生和讲师带来潜在好处。

    

    ChatGPT的引入引起了工业界和学术界的广泛关注，因为它在解决各种任务，包括语言翻译、文本摘要和计算机编程方面具有卓越的能力。它编写、修改甚至纠正代码的能力加上其易于使用和访问已经对计算机科学教育产生了巨大影响。本文旨在探讨ChatGPT在入门级函数式语言编程课程中的表现。在我们的系统评估中，我们把ChatGPT视为我们的一名学生，并证明它可以获得B-的成绩，排名在314名学生中的第155位。我们的综合评估从学生和讲师的角度提供了有价值的见解。此外，我们还确定了ChatGPT可以为这两个群体提供的几个潜在好处。总体而言，我们认为本研究明确了ChatGPT在计算机科学教育中的应用价值。

    The recent introduction of ChatGPT has drawn significant attention from both industry and academia due to its impressive capabilities in solving a diverse range of tasks, including language translation, text summarization, and computer programming. Its capability for writing, modifying, and even correcting code together with its ease of use and access is already dramatically impacting computer science education. This paper aims to explore how well ChatGPT can perform in an introductory-level functional language programming course. In our systematic evaluation, we treated ChatGPT as one of our students and demonstrated that it can achieve a grade B- and its rank in the class is 155 out of 314 students overall. Our comprehensive evaluation provides valuable insights into ChatGPT's impact from both student and instructor perspectives. Additionally, we identify several potential benefits that ChatGPT can offer to both groups. Overall, we believe that this study significantly clarifies and 
    
[^16]: 利用大型语言模型从医生-患者对话中生成临床笔记：来自MEDIQA-Chat的见解

    Clinical Note Generation from Doctor-Patient Conversations using Large Language Models: Insights from MEDIQA-Chat. (arXiv:2305.02220v1 [cs.CL])

    [http://arxiv.org/abs/2305.02220](http://arxiv.org/abs/2305.02220)

    本文介绍了使用大型语言模型从医生-患者对话中自动生成临床笔记的研究，采用少样本上下文学习法所生成笔记表现优秀，且可与人工编写的笔记媲美。

    

    本文描述了我们在MEDIQA-Chat 2023共享任务中提交的自动临床笔记生成方案。我们报告了两种方法的结果：第一种是在共享任务数据上微调预训练语言模型（PLM），第二种是使用大型语言模型（LLM）的少样本上下文学习（ICL）。两种方法都取得了高性能，如通过自动度量标准（例如ROUGE，BERTScore）测量，并分别在所有提交的方案中排名第二和第一。专家审核表明，通过基于ICL的方法使用GPT-4生成的笔记与人工编写的笔记一样受欢迎，这使得它成为从医生-患者对话中自动生成笔记的有前途的路径。

    This paper describes our submission to the MEDIQA-Chat 2023 shared task for automatic clinical note generation from doctor-patient conversations. We report results for two approaches: the first fine-tunes a pre-trained language model (PLM) on the shared task data, and the second uses few-shot in-context learning (ICL) with a large language model (LLM). Both achieve high performance as measured by automatic metrics (e.g. ROUGE, BERTScore) and ranked second and first, respectively, of all submissions to the shared task. Expert human scrutiny indicates that notes generated via the ICL-based approach with GPT-4 are preferred about as often as human-written notes, making it a promising path toward automated note generation from doctor-patient conversations.
    
[^17]: 用语言分类探究单语BERT的语言属性

    Exploring Linguistic Properties of Monolingual BERTs with Typological Classification among Languages. (arXiv:2305.02215v1 [cs.CL])

    [http://arxiv.org/abs/2305.02215](http://arxiv.org/abs/2305.02215)

    本文研究使用语言分类方法探究单语BERT的语言属性，核心发现为BERT正在复制传统的语言模型。

    

    Transformer模型的巨大成功使人们产生了一个问题：这些机器是在复制某些传统的语言模型，还是发现了根本性的新理论？在本文中，我们提出了一种新的研究观点，使用语言之间的类型相似性来对比不同语言的transformer模型，观察这些相似性是否出现在特定的层次。为了进行这项研究，我们提出了基于中心核对齐的权重矩阵相似度测量方法。我们发现，句法类型学相似性与中间层权重之间的相似性是一致的。这一发现确认了通过句法探针方法获得的BERT的结果，并因此重要地证明了BERT正在复制传统的语言模型。

    The overwhelming success of transformers is a real conundrum stimulating a compelling question: are these machines replicating some traditional linguistic models or discovering radically new theories? In this paper, we propose a novel standpoint to investigate this important question. Using typological similarities among languages, we aim to layer-wise compare transformers for different languages to observe whether these similarities emerge for particular layers. For this investigation, we propose to use Centered kernel alignment to measure similarity among weight matrices. We discovered that syntactic typological similarity is consistent with the similarity among weights in the middle layers. This finding confirms results obtained by syntactically probing BERT and, thus, gives an important confirmation that BERT is replicating traditional linguistic models.
    
[^18]: 大规模网上拼车：任务分配优化对系统性能的影响

    Large-scale Online Ridesharing: The Effect of Assignment Optimality on System Performance. (arXiv:2305.02209v1 [math.OC])

    [http://arxiv.org/abs/2305.02209](http://arxiv.org/abs/2305.02209)

    本文介绍了一种名为VGA方法的拼车系统方法，可以用于计算大规模MoD系统中的最优乘客-车辆分配和相应的车辆路径。研究者比较了使用最优分配的MoD系统与使用普通分配的MoD系统的性能。

    

    流动出行（MoD）系统由一群共享汽车组成，可用于单程点对点的乘坐。通过使用拼车，即将多名乘客分配到一辆车上，可以减少车辆和车队的行驶总里程。然而，在MoD系统中找到最优的乘客-车辆分配是一个困难的组合问题。本文介绍了一个名为VGA方法的最近提出的拼车系统方法，该方法可以用于计算大规模MoD系统中的最优乘客-车辆分配和相应的车辆路径。与现有的研究相比，我们解决了所有乘客-车辆分配问题，定期处理包含成千上万辆车和乘客的实例。此外，为了检查使用最优拼车分配的影响，我们比较了使用最优分配的MoD系统与使用普通分配的MoD系统的性能。

    Mobility-on-demand (MoD) systems consist of a fleet of shared vehicles that can be hailed for one-way point-to-point trips. The total distance driven by the vehicles and the fleet size can be reduced by employing ridesharing, i.e., by assigning multiple passengers to one vehicle. However, finding the optimal passenger-vehicle assignment in an MoD system is a hard combinatorial problem. In this work, we demonstrate how the VGA method, a recently proposed systematic method for ridesharing, can be used to compute the optimal passenger-vehicle assignments and corresponding vehicle routes in a massive-scale MoD system. In contrast to existing works, we solve all passenger-vehicle assignment problems to optimality, regularly dealing with instances containing thousands of vehicles and passengers. Moreover, to examine the impact of using optimal ridesharing assignments, we compare the performance of an MoD system that uses optimal assignments against an MoD system that uses assignments compute
    
[^19]: 条件对抗潜在模型用于可直接操控虚拟角色生成

    CALM: Conditional Adversarial Latent Models for Directable Virtual Characters. (arXiv:2305.02195v1 [cs.CV])

    [http://arxiv.org/abs/2305.02195](http://arxiv.org/abs/2305.02195)

    本文提出了CALM方法，通过模仿学习实现了对虚拟角色动作的直接控制，并可以进行样式条件训练，该方法学习了一种丰富复杂的语义运动表示。

    

    本文提出了条件对抗潜在模型（CALM），一种用于生成多样化可直接操控虚拟角色行为的方法。使用模仿学习，CALM学习了一种能够捕捉人类运动复杂性和多样性的运动表示方法，并且实现了对角色动作的直接控制。该方法联合学习控制策略和运动编码器，重建给定运动的关键特征，而不仅仅是复制它。结果表明，CALM学习了一种语义运动表示方法，可以通过直观的界面控制生成的运动，适合更高层次的任务训练。一旦训练完成，角色可以使用类似于视频游戏的直观界面进行控制。

    In this work, we present Conditional Adversarial Latent Models (CALM), an approach for generating diverse and directable behaviors for user-controlled interactive virtual characters. Using imitation learning, CALM learns a representation of movement that captures the complexity and diversity of human motion, and enables direct control over character movements. The approach jointly learns a control policy and a motion encoder that reconstructs key characteristics of a given motion without merely replicating it. The results show that CALM learns a semantic motion representation, enabling control over the generated motions and style-conditioning for higher-level task training. Once trained, the character can be controlled using intuitive interfaces, akin to those found in video games.
    
[^20]: 重新思考图彩票: 图的稀疏性很重要

    Rethinking Graph Lottery Tickets: Graph Sparsity Matters. (arXiv:2305.02190v1 [cs.LG])

    [http://arxiv.org/abs/2305.02190](http://arxiv.org/abs/2305.02190)

    本文探讨了图彩票问题中图的稀疏性问题，提出了保留节点输入输出特征的对称修剪技术和保留特征图空间位置的修剪技术，并在基准数据集上取得了比现有技术更优秀的结果。

    

    彩票猜想 (LTH) 声称存在一种获胜的彩票 (即，一个经过适当修剪的子网络以及原始权重初始化)，它可以实现与原始密集网络相当的性能。最近的一项工作称为 UGS，扩展了 LTH 以修剪图神经网络 (GNN)，以有效加速 GNN 推理。UGS 同时使用相同的屏蔽机制修剪图邻接矩阵和模型权重，但由于图邻接矩阵和权重矩阵的角色非常不同，我们发现他们的稀疏化导致不同的性能特征。具体而言，我们发现当图的稀疏程度超过一定程度时，稀疏 GNN 的性能会显着下降。因此，我们提出了两种技术，以改善当图的稀疏程度较高时的 GNN 性能。首先，UGS 使用丢失公式修剪邻接矩阵，然而，该技术并未适当涉及邻接矩阵的所有元素。为了缓解这个问题，我们提出了一个对称的修剪技术，它可以在修剪邻接矩阵的同时保证每个节点的输入和输出特征被保留。其次，我们提出了一种新颖的稀疏化技术，它避免了直接修剪图结构，而是在保留特征图的空间位置的同时修剪了 GNN 层的特征通道，类似于图像卷积网络采用的策略。实验结果验证了我们提出的技术的有效性，在基准数据集上，在准确度和计算效率上超过了最先进的基线，分别达到了 7.0% 和 5.0x。

    Lottery Ticket Hypothesis (LTH) claims the existence of a winning ticket (i.e., a properly pruned sub-network together with original weight initialization) that can achieve competitive performance to the original dense network. A recent work, called UGS, extended LTH to prune graph neural networks (GNNs) for effectively accelerating GNN inference. UGS simultaneously prunes the graph adjacency matrix and the model weights using the same masking mechanism, but since the roles of the graph adjacency matrix and the weight matrices are very different, we find that their sparsifications lead to different performance characteristics. Specifically, we find that the performance of a sparsified GNN degrades significantly when the graph sparsity goes beyond a certain extent. Therefore, we propose two techniques to improve GNN performance when the graph sparsity is high. First, UGS prunes the adjacency matrix using a loss formulation which, however, does not properly involve all elements of the ad
    
[^21]: 持续推理：在神经符号 AI 中使用持续学习进行非单调推理

    Continual Reasoning: Non-Monotonic Reasoning in Neurosymbolic AI using Continual Learning. (arXiv:2305.02171v1 [cs.AI])

    [http://arxiv.org/abs/2305.02171](http://arxiv.org/abs/2305.02171)

    本文提出了一种持续推理的新方法，通过将神经符号系统与持续学习相结合，可以在处理非单调推理任务时获得更高的准确性。

    

    尽管已经在相似性推理方面进行了广泛投资和令人瞩目的最近进展，但深度学习在更复杂的推理形式，如非单调和常识推理方面仍然存在困难。非单调是非经典推理的一个特性，通常在常识推理中看到，推理系统允许（与古典逻辑不同）作出可能稍后被撤回的结论，当有新信息可用时。神经符号系统（如逻辑张量网络）已被证明能够有效地使深度神经网络具有推理能力。在本文中，我们展示了通过将神经符号系统与持续学习方法相结合，LTN在处理非单调推理任务时可以获得更高水平的准确性。我们通过采用从知识和数据中学习和回忆的学习课程将持续学习加入到LTN中。我们称这个过程为“持续推理”，这是一种新的方法论。

    Despite the extensive investment and impressive recent progress at reasoning by similarity, deep learning continues to struggle with more complex forms of reasoning such as non-monotonic and commonsense reasoning. Non-monotonicity is a property of non-classical reasoning typically seen in commonsense reasoning, whereby a reasoning system is allowed (differently from classical logic) to jump to conclusions which may be retracted later, when new information becomes available. Neural-symbolic systems such as Logic Tensor Networks (LTN) have been shown to be effective at enabling deep neural networks to achieve reasoning capabilities. In this paper, we show that by combining a neural-symbolic system with methods from continual learning, LTN can obtain a higher level of accuracy when addressing non-monotonic reasoning tasks. Continual learning is added to LTNs by adopting a curriculum of learning from knowledge and data with recall. We call this process Continual Reasoning, a new methodolog
    
[^22]: 语言距离与多语言表示空间中的跨语言传递的相关性研究

    Identifying the Correlation Between Language Distance and Cross-Lingual Transfer in a Multilingual Representation Space. (arXiv:2305.02151v1 [cs.CL])

    [http://arxiv.org/abs/2305.02151](http://arxiv.org/abs/2305.02151)

    探索了语言特征对多语言表示空间中的跨语言传递性能的影响，初步提供了方法以增强对语言上相距较远的语言的传递能力。

    

    先前的研究已经探讨了不同语言特征对跨语言传递性能的影响。本研究探讨了这种效应如何映射到表示空间中。过去的研究集中在微调期间多语言语言模型的跨语言对齐上的影响，而本研究研究的是由MLLMs生成的相应语言表示空间的绝对演变。我们特别强调语言特征的作用，并调查其与表示空间和跨语言传递性能的影响之间的相互关系。此外，本文提供了初步证据，说明如何利用这些发现增强对语言上相距较远的语言的传递能力。

    Prior research has investigated the impact of various linguistic features on cross-lingual transfer performance. In this study, we investigate the manner in which this effect can be mapped onto the representation space. While past studies have focused on the impact on cross-lingual alignment in multilingual language models during fine-tuning, this study examines the absolute evolution of the respective language representation spaces produced by MLLMs. We place a specific emphasis on the role of linguistic characteristics and investigate their inter-correlation with the impact on representation spaces and cross-lingual transfer performance. Additionally, this paper provides preliminary evidence of how these findings can be leveraged to enhance transfer to linguistically distant languages.
    
[^23]: 为什么燕麦是便宜的？科尔莫戈洛夫复杂性与程序化生成。

    Why Oatmeal is Cheap: Kolmogorov Complexity and Procedural Generation. (arXiv:2305.02131v1 [cs.AI])

    [http://arxiv.org/abs/2305.02131](http://arxiv.org/abs/2305.02131)

    本文关注燕麦为什么便宜的问题，并将信息论的理论工作与游戏内容生成联系在一起。该论文证明了一种生成器能够产生的最复杂制品的 Kolomogorov 复杂度与该生成器可能空间的大小之间存在关系。

    

    尽管程序化生成在游戏开发者中很受欢迎，但学术研究主要集中在新应用上，一些研究则着重于实证分析。本文将信息论的理论工作与游戏内容生成联系在一起。我们证明了一种生成器能够产生的最复杂制品的 Kolomogorov 复杂度与该生成器可能空间的大小之间存在关系。在这样做的过程中，我们确定了一个知识编码在生成器中、输出空间的密度以及所产生的制品复杂性之间的限制关系。我们将结果与专家程序生成器设计者的经验联系起来，并用一些例子加以说明。

    Although procedural generation is popular among game developers, academic research on the topic has primarily focused on new applications, with some research into empirical analysis. In this paper we relate theoretical work in information theory to the generation of content for games. We prove that there is a relationship between the Kolomogorov complexity of the most complex artifact a generator can produce, and the size of that generator's possibility space. In doing so, we identify the limiting relationship between the knowledge encoded in a generator, the density of its output space, and the intricacy of the artifacts it produces. We relate our result to the experience of expert procedural generator designers, and illustrate it with some examples.
    
[^24]: 系统神经多样性：在多智能体学习中度量行为异质性

    System Neural Diversity: Measuring Behavioral Heterogeneity in Multi-Agent Learning. (arXiv:2305.02128v1 [cs.MA])

    [http://arxiv.org/abs/2305.02128](http://arxiv.org/abs/2305.02128)

    本文介绍了一种名为“系统神经多样性”的方法，用于度量具有随机策略的多智能体系统的行为异质性，探讨了多样性对集体弹性和性能的影响。

    

    进化科学提供了多样性具有韧性的证据。然而，传统的多智能体强化学习技术通常强制要求同质性以增加训练样本的效率。当学习代理系统不受同质策略的限制时，个体代理可能会发展出不同的行为，从而产生有利于系统的新兴互补性。尽管如此，缺乏衡量学习代理系统中行为多样性的工具意味着我们无法深入了解多样性对集体弹性和性能的影响。在本文中，我们介绍了系统神经多样性（SND）：一种用于具有随机策略的多智能体系统的行为异质性度量方法，探讨并证明了其理论性质，并将其与跨学科领域中使用的最新行为多样性指标进行了比较。

    Evolutionary science provides evidence that diversity confers resilience. Yet, traditional multi-agent reinforcement learning techniques commonly enforce homogeneity to increase training sample efficiency. When a system of learning agents is not constrained to homogeneous policies, individual agents may develop diverse behaviors, resulting in emergent complementarity that benefits the system. Despite this feat, there is a surprising lack of tools that measure behavioral diversity in systems of learning agents. Such techniques would pave the way towards understanding the impact of diversity in collective resilience and performance. In this paper, we introduce System Neural Diversity (SND): a measure of behavioral heterogeneity for multi-agent systems where agents have stochastic policies. %over a continuous state space. We discuss and prove its theoretical properties, and compare it with alternate, state-of-the-art behavioral diversity metrics used in cross-disciplinary domains. Through
    
[^25]: 非对称量子决策

    Asymmetric quantum decision-making. (arXiv:2305.02117v1 [quant-ph])

    [http://arxiv.org/abs/2305.02117](http://arxiv.org/abs/2305.02117)

    本研究以理论和实验的方法探讨了利用携带轨道角动量的光子或纠缠光子的量子干涉实现非对称集体决策，并实现更高的效用，同时保持决策的公平性。

    

    集体决策对于信息与通信系统至关重要。决策代理人之间的冲突阻碍了整个系统潜在效用的最大化。量子过程可以利用光子的纠缠或轨道角动量的量子干涉，实现两个代理人之间的无冲突联合决策。然而，以前 的研究一直呈现对称的联合决策结果。虽然这个属性有助于维护和保护平等，但它不能解决不平等问题。伦理和公平等全球性挑战在负责任的人工智能领域被认为是负责任的研究和创新范例。因此，决策系统不仅必须保持现有的平等，还必须解决不平等问题。本研究从理论和数值上探讨了利用携带轨道角动量的光子或纠缠光子的量子干涉实现非对称集体决策。虽然成功实现了不对称性，但所得的联合决策可以在保持决策公平性的同时实现更高的效用。该研究为设计量子决策协议提供了新的视角，并具有潜在的量子通讯和加密应用。

    Collective decision-making is crucial to information and communication systems. Decision conflicts among agents hinder the maximization of potential utilities of the entire system. Quantum processes can realize conflict-free joint decisions among two agents using the entanglement of photons or quantum interference of orbital angular momentum (OAM). However, previous studies have always presented symmetric resultant joint decisions. Although this property helps maintain and preserve equality, it cannot resolve disparities. Global challenges, such as ethics and equity, are recognized in the field of responsible artificial intelligence as responsible research and innovation paradigm. Thus, decision-making systems must not only preserve existing equality but also tackle disparities. This study theoretically and numerically investigates asymmetric collective decision-making using quantum interference of photons carrying OAM or entangled photons. Although asymmetry is successfully realized, 
    
[^26]: 联邦学习与O-RAN的协同：面向多个分布式机器学习服务的弹性虚拟化架构

    Synergies Between Federated Learning and O-RAN: Towards an Elastic Virtualized Architecture for Multiple Distributed Machine Learning Services. (arXiv:2305.02109v1 [cs.NI])

    [http://arxiv.org/abs/2305.02109](http://arxiv.org/abs/2305.02109)

    本文研究了联邦学习在现代无线网络下的挑战，提出了一种方法称为动态多服务联邦学习（DMS-FL）来解决这个问题。同时，还提出了一种名为弹性虚拟化联邦学习（EV-FL）的分布式机器学习架构，来支持DMS-FL中的设计要求。

    

    联邦学习是最流行的分布式机器学习技术，但是在现代无线网络中实现联邦学习面临着许多挑战，主要包括网络条件的动态性、系统中多个联邦学习服务/任务的并存以及联邦学习服务与其他网络服务的并行执行等。针对这些挑战，本文提出了一种名为动态多服务联邦学习（DMS-FL）的联邦学习泛型架构，并通过提出一种新的分布式机器学习架构——弹性虚拟化联邦学习（EV-FL）来解决DMS-FL中的三个未探索的设计问题。

    Federated learning (FL) is the most popular distributed machine learning technique. However, implementation of FL over modern wireless networks faces key challenges caused by (i) dynamics of the network conditions, (ii) coexistence of multiple FL services/tasks in the system, and (iii) concurrent execution of FL services with other network services, which are not jointly considered in prior works. Motivated by these challenges, we introduce a generic FL paradigm over next-generation (NextG) networks, called dynamic multi-service FL (DMS-FL). We identify three unexplored design considerations in DMS-FL: (i) FL service operator accumulation, (ii) wireless resource fragmentation, and (iii) signal strength fluctuations. We take the first steps towards addressing these design considerations through proposing a novel distributed ML architecture called elastic virtualized FL (EV-FL). EV-FL unleashes the full potential of Open RAN (O-RAN) systems and introduces an elastic resource provisioning
    
[^27]: 采用摄像陷阱图像和深度学习消除鸟类分类中的人为瓶颈

    Removing Human Bottlenecks in Bird Classification Using Camera Trap Images and Deep Learning. (arXiv:2305.02097v1 [cs.CV])

    [http://arxiv.org/abs/2305.02097](http://arxiv.org/abs/2305.02097)

    本文介绍了采用摄像陷阱和深度学习来消除鸟类监测中的瓶颈。通过该方法，减少了图像处理的工作量和虚警比例，提高了监测效率和准确性。

    

    鸟类是监测生物多样性和栖息地健康的重要指标；它们在生态系统管理中也发挥着关键作用。鸟类数量的下降可能导致生态系统服务的降低，包括种子传播、授粉和害虫控制。对于生态学家来说，准确和长期地监测鸟类并识别关注物种，同时衡量保护干预的成功，至关重要。然而，监测工作耗时、昂贵，并且在长时间持续和大规模空间尺度上管理起来往往很困难。摄像陷阱、声学监测器和无人机等技术提供了非侵入性监测的方法。使用摄像陷阱进行监测存在两个主要问题：a）摄像机生成大量图像，使得在适时处理和分析数据变得困难；b）虚警比例高，使处理和分析难以汇报。在本文中，我们提出了一种方法来克服这些问题。

    Birds are important indicators for monitoring both biodiversity and habitat health; they also play a crucial role in ecosystem management. Decline in bird populations can result in reduced eco-system services, including seed dispersal, pollination and pest control. Accurate and long-term monitoring of birds to identify species of concern while measuring the success of conservation interventions is essential for ecologists. However, monitoring is time consuming, costly and often difficult to manage over long durations and at meaningfully large spatial scales. Technology such as camera traps, acoustic monitors and drones provide methods for non-invasive monitoring. There are two main problems with using camera traps for monitoring: a) cameras generate many images, making it difficult to process and analyse the data in a timely manner; and b) the high proportion of false positives hinders the processing and analysis for reporting. In this paper, we outline an approach for overcoming these
    
[^28]: 毫米波移动雷达成像的高效卷积神经网络超分辨率算法

    Efficient CNN-based Super Resolution Algorithms for mmWave Mobile Radar Imaging. (arXiv:2305.02092v1 [cs.CV])

    [http://arxiv.org/abs/2305.02092](http://arxiv.org/abs/2305.02092)

    本文介绍了两种基于卷积神经网络的超分辨率算法，用于实现高效且准确的近场合成孔径雷达成像，具有卓越的性能。

    

    本文提出了一种创新的超分辨率方法来应对新型近场合成孔径雷达成像的需求，即将卷积神经网络扩展到电磁域，以实现对由雷达信号生成的图像进行超分辨率处理。具体来说，近场合成孔径雷达成像是通过在空间中扫描雷达来创建合成孔径来生成高分辨率图像的方法，其高保真度的空间感知能力、低成本设备和广泛的应用空间使其备受关注。由于SAR成像需要大的孔径尺寸才能实现高分辨率，因此超分辨率算法对于许多应用非常有价值。然而，基于自由手持智能手机SAR收集的不规则SAR孔径数据实现高效、高精度的SAR成像是有挑战的。为此，本文提出了两种基于卷积神经网络的超分辨率算法，用于实现高效且准确的近场SAR成像，与现有方法相比，这些算法在性能上具有卓越表现。第一种算法使用端到端网络直接将低分辨率SAR图像放大，而第二种算法则采用亚像素卷积层，在超分辨率过程中更好地保留图像细节。

    In this paper, we introduce an innovative super resolution approach to emerging modes of near-field synthetic aperture radar (SAR) imaging. Recent research extends convolutional neural network (CNN) architectures from the optical to the electromagnetic domain to achieve super resolution on images generated from radar signaling. Specifically, near-field synthetic aperture radar (SAR) imaging, a method for generating high-resolution images by scanning a radar across space to create a synthetic aperture, is of interest due to its high-fidelity spatial sensing capability, low cost devices, and large application space. Since SAR imaging requires large aperture sizes to achieve high resolution, super-resolution algorithms are valuable for many applications. Freehand smartphone SAR, an emerging sensing modality, requires irregular SAR apertures in the near-field and computation on mobile devices. Achieving efficient high-resolution SAR images from irregularly sampled data collected by freehan
    
[^29]: 毫米波雷达物体识别的系统研究

    A Systematic Study on Object Recognition Using Millimeter-wave Radar. (arXiv:2305.02085v1 [cs.CV])

    [http://arxiv.org/abs/2305.02085](http://arxiv.org/abs/2305.02085)

    本研究对商用毫米波雷达进行了全面研究，展示了毫米波雷达作为一种有前途的物体识别技术的潜力，能够以高准确性、鲁棒性和实时性识别物体，不受外观的影响，并解决了遮挡效果问题。

    

    由于毫米波雷达可以在光线和天气不确定的环境下进行感知，因此在智能环境中毫米波雷达至关重要。智能车辆系统和工业级毫米波雷达已经集成了这样的能力。但是，面向社区目的的智能环境应用程序很难获得工业级毫米波雷达，而商用毫米波雷达具有需要研究的潜在挑战，例如识别物体和活动、实时人员跟踪、对象定位等。图像和视频数据对于这样的工作来说很容易收集、理解和注释。图像和视频数据受光线和天气的影响，容易受遮挡效果的影响，并存在隐私问题。为了消除依赖性并确保隐私，商用毫米波雷达应该得到测试。在推进之前，必须解决毫米波雷达在不同操作设置下的实用性和性能问题。为了解决这些问题，我们使用Texas Instruments' IWR6843毫米波雷达收集了数据集，并构建了基于深度学习的物体识别系统。我们对数据集进行了全面的研究，并显示毫米波雷达是一种有前途的物体识别技术，即使在复杂环境中也是如此。我们的实验表明，毫米波雷达可以以极高的准确性、鲁棒性和实时性识别物体。此外，该系统在没有任何关于物体外观的先验知识的情况下工作，并且具有抗遮挡效果。我们的工作为未来基于毫米波雷达的物体识别研究奠定了基础。

    Due to its light and weather-independent sensing, millimeter-wave (MMW) radar is essential in smart environments. Intelligent vehicle systems and industry-grade MMW radars have integrated such capabilities. Industry-grade MMW radars are expensive and hard to get for community-purpose smart environment applications. However, commercially available MMW radars have hidden underpinning challenges that need to be investigated for tasks like recognizing objects and activities, real-time person tracking, object localization, etc. Image and video data are straightforward to gather, understand, and annotate for such jobs. Image and video data are light and weather-dependent, susceptible to the occlusion effect, and present privacy problems. To eliminate dependence and ensure privacy, commercial MMW radars should be tested. MMW radar's practicality and performance in varied operating settings must be addressed before promoting it. To address the problems, we collected a dataset using Texas Instr
    
[^30]: 一个基于角色依赖的名称本体设计模式

    An Ontology Design Pattern for Role-Dependent Names. (arXiv:2305.02077v1 [cs.AI])

    [http://arxiv.org/abs/2305.02077](http://arxiv.org/abs/2305.02077)

    本文提出了一个用于建模名称与角色相关联的设计模式，能够捕捉代理人在不同角色中使用不同名称的情况。

    

    我们提出了一个本体设计模式，用于对名称作为角色的一部分进行建模，以捕捉代理人使用与不同角色相关联的不同名称执行不同角色的情况。代理人使用不同名称执行角色的示例是相当广泛的，例如以不同笔名写作的作者，或者具有一个以上国家公民身份的不同法定名称。提出的模式是标准代理人角色和标准名称模式存根的修改合并。

    We present an ontology design pattern for modeling Names as part of Roles, to capture scenarios where an Agent performs different Roles using different Names associated with the different Roles. Examples of an Agent performing a Role using different Names are rather ubiquitous, e.g., authors who write under different pseudonyms, or different legal names for citizens of more than one country. The proposed pattern is a modified merger of a standard Agent Role and a standard Name pattern stub.
    
[^31]: 一种用于近场不规则SAR超分辨率的视觉Transformer方法

    A Vision Transformer Approach for Efficient Near-Field Irregular SAR Super-Resolution. (arXiv:2305.02074v1 [cs.CV])

    [http://arxiv.org/abs/2305.02074](http://arxiv.org/abs/2305.02074)

    本文提出了一种新的、用于近场不规则SAR超分辨率的算法，以应对高分辨率成像中遇到的独特挑战，为实现边缘和物联网(IoT)技术奠定技术基础。

    

    本文提出了一种新颖的、针对非规则扫描几何的近场合成孔径雷达(SAR)超分辨率算法。随着第五代(5G)毫米波(mmWave)设备变得越来越实惠和可用，高分辨率SAR成像对用户应用和非实验室环境变得可行。新兴应用如手持成像、无人机成像和汽车SAR面临着高分辨率成像的几个独特挑战。首先，恢复SAR图像需要在整个扫描期间了解阵列位置。虽然最近的工作引入了基于相机的定位系统，能够足够地估计位置，但实现高效的恢复算法是实现边缘和物联网(IoT)技术的必要条件。最近的工作探讨了非合作近场SAR采样的高效算法，但是这些算法很大程度上是试验性的，需要更好的鲁棒性和实用性。

    In this paper, we develop a novel super-resolution algorithm for near-field synthetic-aperture radar (SAR) under irregular scanning geometries. As fifth-generation (5G) millimeter-wave (mmWave) devices are becoming increasingly affordable and available, high-resolution SAR imaging is feasible for end-user applications and non-laboratory environments. Emerging applications such freehand imaging, wherein a handheld radar is scanned throughout space by a user, unmanned aerial vehicle (UAV) imaging, and automotive SAR face several unique challenges for high-resolution imaging. First, recovering a SAR image requires knowledge of the array positions throughout the scan. While recent work has introduced camera-based positioning systems capable of adequately estimating the position, recovering the algorithm efficiently is a requirement to enable edge and Internet of Things (IoT) technologies. Efficient algorithms for non-cooperative near-field SAR sampling have been explored in recent work, bu
    
[^32]: 多智能体协作感知的注意力特征融合

    Attention Based Feature Fusion For Multi-Agent Collaborative Perception. (arXiv:2305.02061v1 [cs.MA])

    [http://arxiv.org/abs/2305.02061](http://arxiv.org/abs/2305.02061)

    该论文提出了一种基于图注意力网络的多智能体协作感知方案，从而提高了多智能体感知的整体精度并缓解网络资源的限制。

    

    在智能交通系统领域，协作感知作为一种新的方法已经被提出。通过实现多智能体之间的信息交换，以提高整个系统的感知能力，从而克服个体感知的局限性。协作感知克服了个体感知器件的局限性，使连接代理人能够感知超出他们视线和视野之外的环境。然而，协作感知的可靠性在很大程度上取决于数据聚合策略和通信带宽，必须克服有限网络资源带来的挑战。为了提高物体检测的精度和缓解有限的网络资源，我们提出了一种基于图注意力网络（GAT）的中间协作感知方案。所提出的方法采用了一种基于注意力的聚合策略，用于融合多个连接代理人之间交换的中间表示。该方法提高了多智能体感知的整体精度，而不需要显著增加网络资源。

    In the domain of intelligent transportation systems (ITS), collaborative perception has emerged as a promising approach to overcome the limitations of individual perception by enabling multiple agents to exchange information, thus enhancing their situational awareness. Collaborative perception overcomes the limitations of individual sensors, allowing connected agents to perceive environments beyond their line-of-sight and field of view. However, the reliability of collaborative perception heavily depends on the data aggregation strategy and communication bandwidth, which must overcome the challenges posed by limited network resources. To improve the precision of object detection and alleviate limited network resources, we propose an intermediate collaborative perception solution in the form of a graph attention network (GAT). The proposed approach develops an attention-based aggregation strategy to fuse intermediate representations exchanged among multiple connected agents. This approa
    
[^33]: 通过合作马尔可夫决策过程系统实现人机协同适应界面

    Human Machine Co-adaption Interface via Cooperation Markov Decision Process System. (arXiv:2305.02058v1 [cs.AI])

    [http://arxiv.org/abs/2305.02058](http://arxiv.org/abs/2305.02058)

    本文提出了一种新的人机界面，将机器人辅助康复的整个过程视为协同适应或相互学习过程。提出了一种量化高抽象层系统学习速率的模型，并根据该模型设计了协作的策略迭代方法，通过该系统解决了非平稳问题。

    

    本文旨在通过引入基于模型的强化学习中的协同适应技术，开发一种新的人机界面，从用户（患者）和机器（机器人）双方的角度来改善康复表现。传统研究更侧重于机器人协助，即通过改善控制策略来实现按需协助的目标。本研究将机器人辅助康复的整个过程视为协同适应或相互学习过程，并强调用户对机器人的适应性。为此，我们提出了一种称为协同MDPs（CaMDPs）的模型，以基于协作多智能体强化学习（MARL）的学习速率来量化系统的高抽象层。我们提出了几种方法来协作地调整策略迭代框架中的两个代理之间的策略改进。根据我们提出的协同MDPs，仿真研究表明非平稳问题可以通过此系统解决。

    This paper aims to develop a new human-machine interface to improve rehabilitation performance from the perspective of both the user (patient) and the machine (robot) by introducing the co-adaption techniques via model-based reinforcement learning. Previous studies focus more on robot assistance, i.e., to improve the control strategy so as to fulfill the objective of Assist-As-Needed. In this study, we treat the full process of robot-assisted rehabilitation as a co-adaptive or mutual learning process and emphasize the adaptation of the user to the machine. To this end, we proposed a Co-adaptive MDPs (CaMDPs) model to quantify the learning rates based on cooperative multi-agent reinforcement learning (MARL) in the high abstraction layer of the systems. We proposed several approaches to cooperatively adjust the Policy Improvement among the two agents in the framework of Policy Iteration. Based on the proposed co-adaptive MDPs, the simulation study indicates the non-stationary problem can
    
[^34]: 基于地图的经验回放：强化学习中遗忘现象的内存节约解决方案

    Map-based Experience Replay: A Memory-Efficient Solution to Catastrophic Forgetting in Reinforcement Learning. (arXiv:2305.02054v1 [cs.LG])

    [http://arxiv.org/abs/2305.02054](http://arxiv.org/abs/2305.02054)

    本文提出了一种基于地图的经验回放方法，通过将存储的转换组织成一种简洁的环境模型网络，以在减少内存大小的同时增加每个样本的相关性，从而有效解决强化学习中的遗忘问题。

    

    深度强化学习代理在训练新数据时常常会遭受灾难性的遗忘，遗忘先前在输入空间中找到的解决方案。回放记忆是解决这个问题的常见方法，它会对旧和新的训练样本进行去关联和混洗。他们天真地按照状态过渡的顺序存储状态转变，而不考虑冗余性。我们介绍了一种基于Grow-When-Required（GWR）自组织网络的新型认知启发式回放内存方法，它类似于一种基于地图的世界认知模型。我们的方法将存储的转换组织成一个简洁的环境模型网络，将相似的样本合并以减少内存大小并增加样本之间的两两距离，从而增加每个样本的相关性。总体而言，我们的论文表明，基于地图的经验回放允许显着减少内存，只会产生轻微的性能下降。

    Deep Reinforcement Learning agents often suffer from catastrophic forgetting, forgetting previously found solutions in parts of the input space when training on new data. Replay Memories are a common solution to the problem, decorrelating and shuffling old and new training samples. They naively store state transitions as they come in, without regard for redundancy. We introduce a novel cognitive-inspired replay memory approach based on the Grow-When-Required (GWR) self-organizing network, which resembles a map-based mental model of the world. Our approach organizes stored transitions into a concise environment-model-like network of state-nodes and transition-edges, merging similar samples to reduce the memory size and increase pair-wise distance among samples, which increases the relevancy of each sample. Overall, our paper shows that map-based experience replay allows for significant memory reduction with only small performance decreases.
    
[^35]: 基于新型无菌训练技术，使用深度卷积神经网络提高静态手势分类准确率

    Improved Static Hand Gesture Classification on Deep Convolutional Neural Networks using Novel Sterile Training Technique. (arXiv:2305.02039v1 [cs.CV])

    [http://arxiv.org/abs/2305.02039](http://arxiv.org/abs/2305.02039)

    本文提出一种使用mmWave雷达和CNN的数据收集和训练新技术，同时提出了一种新颖的无菌训练技术，可以在非理想成像条件下提高静态手势分类准确性。

    

    本文探讨了一种使用卷积神经网络(CNN)和频率调制连续波（FMCW）毫米波（mmWave）雷达的静态手势分类的新型数据收集和训练技术，以提高分类准确性。使用mmWave雷达，可以在非理想成像条件下获取精确的空间信息，因此在人机交互(HCI)、增强/虚拟现实(AR/VR)等多种应用中具有广泛的应用前景。本文提出了一种新颖的无菌训练技术，可以从训练数据集中去除离群值和异常输入，从而提高分类准确性。实验结果表明，所提出的方法优于现有最先进的技术。

    In this paper, we investigate novel data collection and training techniques towards improving classification accuracy of non-moving (static) hand gestures using a convolutional neural network (CNN) and frequency-modulated-continuous-wave (FMCW) millimeter-wave (mmWave) radars. Recently, non-contact hand pose and static gesture recognition have received considerable attention in many applications ranging from human-computer interaction (HCI), augmented/virtual reality (AR/VR), and even therapeutic range of motion for medical applications. While most current solutions rely on optical or depth cameras, these methods require ideal lighting and temperature conditions. mmWave radar devices have recently emerged as a promising alternative offering low-cost system-on-chip sensors whose output signals contain precise spatial information even in non-ideal imaging conditions. Additionally, deep convolutional neural networks have been employed extensively in image recognition by learning both feat
    
[^36]: 系统研究基于伪目标训练的知识蒸馏用于自然语言生成

    A Systematic Study of Knowledge Distillation for Natural Language Generation with Pseudo-Target Training. (arXiv:2305.02031v1 [cs.CL])

    [http://arxiv.org/abs/2305.02031](http://arxiv.org/abs/2305.02031)

    本文研究如何压缩自然语言生成模型以适应实际应用需求，通过使用知识蒸馏和伪目标训练技术针对特定的自然语言生成任务和数据集进行优化，并取得了显著效果。

    

    现代自然语言生成模型需要大量的计算和存储资源。本文研究压缩这些模型的潜力，这对于服务数百万用户的实际应用至关重要。我们聚焦于知识蒸馏（KD）技术，其中小的学生模型学习模仿大的教师模型，使得可以从教师向学生传递知识。与之前的大部分工作不同，我们的目标是针对特定的自然语言生成任务和数据集优化模型。通常，在真实世界的应用中，除了有标记数据外，还有大量的未标记任务特定数据，这对于通过知识蒸馏获得高压缩率至关重要。在本文中，我们在现实的假设下，对各种自然语言生成任务进行了系统的任务特定知识蒸馏研究，并讨论了自然语言生成蒸馏的特殊特征，尤其是曝光偏差问题。接着，我们推导出一系列伪目标训练（PTT）技术，缓解了这个问题，并提高了学生模型的质量。通过广泛的实验评估，我们证明了我们提出的方法在不同的自然语言生成任务和数据集上的有效性。

    Modern Natural Language Generation (NLG) models come with massive computational and storage requirements. In this work, we study the potential of compressing them, which is crucial for real-world applications serving millions of users. We focus on Knowledge Distillation (KD) techniques, in which a small student model learns to imitate a large teacher model, allowing to transfer knowledge from the teacher to the student. In contrast to much of the previous work, our goal is to optimize the model for a specific NLG task and a specific dataset. Typically, in real-world applications, in addition to labeled data there is abundant unlabeled task-specific data, which is crucial for attaining high compression rates via KD. In this work, we conduct a systematic study of task-specific KD techniques for various NLG tasks under realistic assumptions. We discuss the special characteristics of NLG distillation and particularly the exposure bias problem. Following, we derive a family of Pseudo-Target
    
[^37]: 基于深度学习的多波段信号融合用于 3-D SAR 超分辨率

    Deep Learning-Based Multiband Signal Fusion for 3-D SAR Super-Resolution. (arXiv:2305.02017v1 [cs.CV])

    [http://arxiv.org/abs/2305.02017](http://arxiv.org/abs/2305.02017)

    本研究首次提出使用深度学习进行多波段信号融合，以应对实际场景中目标模型复杂的问题。

    

    三维合成孔径雷达（3-D SAR）被广泛应用于许多安全和工业应用，需要对隐蔽或遮挡对象进行高分辨率成像。能够分辨错综复杂的 3-D 目标对于这些应用的性能至关重要，并且直接取决于系统带宽。然而，由于高带宽系统面临几个禁止因素，因此另一种解决方案是在不同频段上操作多个雷达并融合多波段信号。当前的多波段信号融合方法假设一个简单的目标模型和少数点反射器，但这种方法对于实际的安全筛查和工业成像场景中的大量反射器构成的目标模型无效。据我们所知，本研究首次使用深度学习进行多波段信号融合。所提出的名为 kR-Net 的网络采用混合的双重域复值卷积神经网络。

    Three-dimensional (3-D) synthetic aperture radar (SAR) is widely used in many security and industrial applications requiring high-resolution imaging of concealed or occluded objects. The ability to resolve intricate 3-D targets is essential to the performance of such applications and depends directly on system bandwidth. However, because high-bandwidth systems face several prohibitive hurdles, an alternative solution is to operate multiple radars at distinct frequency bands and fuse the multiband signals. Current multiband signal fusion methods assume a simple target model and a small number of point reflectors, which is invalid for realistic security screening and industrial imaging scenarios wherein the target model effectively consists of a large number of reflectors. To the best of our knowledge, this study presents the first use of deep learning for multiband signal fusion. The proposed network, called kR-Net, employs a hybrid, dual-domain complex-valued convolutional neural netwo
    
[^38]: 可解释人工智能方法评述：SHAP 和 LIME

    Commentary on explainable artificial intelligence methods: SHAP and LIME. (arXiv:2305.02012v1 [stat.ML])

    [http://arxiv.org/abs/2305.02012](http://arxiv.org/abs/2305.02012)

    这篇评论对可解释人工智能方法 SHAP 和 LIME 进行了评述和比较，提出了一个框架且突出了它们的优缺点。

    

    可解释人工智能（XAI）方法已经发展出来，将机器学习模型的黑匣子转化为更易理解的形式。这些方法有助于传达模型的工作原理，旨在使机器学习模型更透明，并增加最终用户对其输出的信任。 SHapley Additive exPlanations（SHAP）和Local Interpretable Model Agnostic Explanation（LIME）是两种在表格数据中广泛使用的XAI方法。在这篇评论中，我们讨论了两种方法的可解释性度量是如何生成的，并提出了一个解释它们输出的框架，突出了它们的优缺点。

    eXplainable artificial intelligence (XAI) methods have emerged to convert the black box of machine learning models into a more digestible form. These methods help to communicate how the model works with the aim of making machine learning models more transparent and increasing the trust of end-users into their output. SHapley Additive exPlanations (SHAP) and Local Interpretable Model Agnostic Explanation (LIME) are two widely used XAI methods particularly with tabular data. In this commentary piece, we discuss the way the explainability metrics of these two methods are generated and propose a framework for interpretation of their outputs, highlighting their weaknesses and strengths.
    
[^39]: 超声心动图体积指数的提取：哪种深度学习方案可以应用于临床？

    Extraction of volumetric indices from echocardiography: which deep learning solution for clinical use?. (arXiv:2305.01997v1 [eess.IV])

    [http://arxiv.org/abs/2305.01997](http://arxiv.org/abs/2305.01997)

    本文对当前医学/超声心动图图像分割方法进行了全面比较，提出了3D nnU-Net模型，解决了时间一致性和跨数据集方面的问题，并通过引入一个新的私有数据集，CARDINAL，来证明其在应用于临床中的优越性。

    

    基于深度学习的方法已经成为超声心动图图像自动分析的主要手段，利用多个由专家注释的开放数据集（其中CAMUS是最大的公共数据库之一）。然而，由于存在一些问题，如预测的时间一致性和跨数据集的推广能力等问题，这些模型仍然被临床医生认为是不可靠的。因此，本文提出了对当前表现最佳的医学/超声心动图图像分割方法进行全面比较，并特别关注了时间一致性和跨数据集方面。我们介绍了一个名为CARDINAL的新的私有数据集，其包括心尖两腔和心尖四腔序列，并具有完整心脏周期的参考分割。我们展示了所提出的3D nnU-Net优于替代的2D和循环分割方法，同时也报告了在CARDINAL上训练的最佳模型在测试数据集上的良好表现。

    Deep learning-based methods have spearheaded the automatic analysis of echocardiographic images, taking advantage of the publication of multiple open access datasets annotated by experts (CAMUS being one of the largest public databases). However, these models are still considered unreliable by clinicians due to unresolved issues concerning i) the temporal consistency of their predictions, and ii) their ability to generalize across datasets. In this context, we propose a comprehensive comparison between the current best performing methods in medical/echocardiographic image segmentation, with a particular focus on temporal consistency and cross-dataset aspects. We introduce a new private dataset, named CARDINAL, of apical two-chamber and apical four-chamber sequences, with reference segmentation over the full cardiac cycle. We show that the proposed 3D nnU-Net outperforms alternative 2D and recurrent segmentation methods. We also report that the best models trained on CARDINAL, when test
    
[^40]: 证明AI模型中稀疏符号概念的出现

    Where We Have Arrived in Proving the Emergence of Sparse Symbolic Concepts in AI Models. (arXiv:2305.01939v1 [cs.LG])

    [http://arxiv.org/abs/2305.01939](http://arxiv.org/abs/2305.01939)

    证明了对于训练良好的AI模型，如果满足一定条件，将出现稀疏交互概念，这些概念能够描述输入变量之间的相互作用，并对模型推理分数产生影响。

    

    本文旨在证明训练良好的AI模型中出现符号概念的现象。我们证明，如果（1）模型输出相对于输入变量的高阶导数均为零，（2）AI模型可用于遮挡样本且输入样本较少遮挡时会产生更高的置信度，（3）AI模型在遮挡样本上的置信度并不会显著降低，则AI模型将编码稀疏交互概念。每个交互概念表示特定一组输入变量之间的相互作用，并对模型推理分数产生一定的数值影响。具体而言，我们证明了模型的推理分数总是可以表示为所有交互概念的交互效应之和。事实上，我们希望证明出现符号概念的条件非常普遍。这意味着对于大多数AI模型，我们通常可以使用少量的交互概念来模拟模型。

    This paper aims to prove the emergence of symbolic concepts in well-trained AI models. We prove that if (1) the high-order derivatives of the model output w.r.t. the input variables are all zero, (2) the AI model can be used on occluded samples and will yield higher confidence when the input sample is less occluded, and (3) the confidence of the AI model does not significantly degrade on occluded samples, then the AI model will encode sparse interactive concepts. Each interactive concept represents an interaction between a specific set of input variables, and has a certain numerical effect on the inference score of the model. Specifically, it is proved that the inference score of the model can always be represented as the sum of the interaction effects of all interactive concepts. In fact, we hope to prove that conditions for the emergence of symbolic concepts are quite common. It means that for most AI models, we can usually use a small number of interactive concepts to mimic the mode
    
[^41]: Doc2SoarGraph：基于语义导向分层图的富含视觉表格文档的离散推理

    Doc2SoarGraph: Discrete Reasoning over Visually-Rich Table-Text Documents with Semantic-Oriented Hierarchical Graphs. (arXiv:2305.01938v1 [cs.CL])

    [http://arxiv.org/abs/2305.01938](http://arxiv.org/abs/2305.01938)

    本文提出了 Doc2SoarGraph 框架，利用语义导向分层图结构中元素之间的差异和相关性，在富含视觉表格文本的TAT-DQA问题下实现了离散推理，表现出了最佳的实验结果。

    

    近两年来，对于表格文本文档（例如财务报告）的离散推理越来越受到关注。现有的工作大多通过手动选择和转换文档页面到结构化的表格和段落来简化这一挑战，从而阻碍其实际应用。在这项工作中，我们探究了一种更为现实的问题设置，即以 TAT-DQA 的形式回答富含视觉表格文本的问题。具体而言，我们提出了一种新颖的 Doc2SoarGraph 框架，通过利用语义导向分层图结构中不同元素之间的差异和相关性，提高了其离散推理能力。我们对 TAT-DQA 数据集进行了广泛的实验，结果显示，我们的提出的框架在测试集上的精确匹配（EM）和 F1 得分方面分别比最佳基线模型分别提高了 17.73% 和 16.91%，实现了新的最先进技术水平。

    Discrete reasoning over table-text documents (e.g., financial reports) gains increasing attention in recent two years. Existing works mostly simplify this challenge by manually selecting and transforming document pages to structured tables and paragraphs, hindering their practical application. In this work, we explore a more realistic problem setting in the form of TAT-DQA, i.e. to answer the question over a visually-rich table-text document. Specifically, we propose a novel Doc2SoarGraph framework with enhanced discrete reasoning capability by harnessing the differences and correlations among different elements (e.g., quantities, dates) of the given question and document with Semantic-oriented hierarchical Graph structures. We conduct extensive experiments on TAT-DQA dataset, and the results show that our proposed framework outperforms the best baseline model by 17.73% and 16.91% in terms of Exact Match (EM) and F1 score respectively on the test set, achieving the new state-of-the-art
    
[^42]: 图神经网络中的条件方法探究

    An Exploration of Conditioning Methods in Graph Neural Networks. (arXiv:2305.01933v1 [cs.LG])

    [http://arxiv.org/abs/2305.01933](http://arxiv.org/abs/2305.01933)

    本文探究图神经网络中的三种条件处理方式：弱条件处理、强条件处理和纯条件处理，对于不同类别的GNNs，有不同的表现，实证研究表明这些条件处理方式对于GNN的性能有影响。

    

    基于消息传递的图神经网络（GNN）的灵活性和有效性在图结构数据的深度学习中取得了相当的进步。在这种方法中，GNN基于其邻居递归地更新节点表示，并通过使用节点和边属性向量来获得表现力。例如，在物理和化学等计算任务中，使用边属性（如相对位置或距离）被证明是必要的。在本文中，我们关注的不是要使用什么类型的属性，而是如何在此信息的基础上进行条件处理，以提高模型性能。我们考虑了三种类型的条件处理：弱条件处理、强条件处理和纯条件处理，分别与基于连接的条件处理、门控和因果依赖于属性的变换相关。这种分类提供了一个统一的观点来看待不同类别的GNN，从可分离卷积到各种形式的消息传递网络。我们在三个常见的任务上进行了实证研究，表明GNNs的性能受到该条件方式的影响。

    The flexibility and effectiveness of message passing based graph neural networks (GNNs) induced considerable advances in deep learning on graph-structured data. In such approaches, GNNs recursively update node representations based on their neighbors and they gain expressivity through the use of node and edge attribute vectors. E.g., in computational tasks such as physics and chemistry usage of edge attributes such as relative position or distance proved to be essential. In this work, we address not what kind of attributes to use, but how to condition on this information to improve model performance. We consider three types of conditioning; weak, strong, and pure, which respectively relate to concatenation-based conditioning, gating, and transformations that are causally dependent on the attributes. This categorization provides a unifying viewpoint on different classes of GNNs, from separable convolutions to various forms of message passing networks. We provide an empirical study on th
    
[^43]: 改进句子嵌入的对比学习方法，利用人工智能反馈

    Improving Contrastive Learning of Sentence Embeddings from AI Feedback. (arXiv:2305.01918v1 [cs.CL])

    [http://arxiv.org/abs/2305.01918](http://arxiv.org/abs/2305.01918)

    本文提出了一种利用人工智能反馈改进句子嵌入对比学习方法的方式，可以提高对比学习样本对的质量，并结合人类反馈来提供更好的监督信号。

    

    对比学习已成为自然语言处理中句子嵌入学习中的流行方法。然而，自然语言的离散性使得通过数据增强方法生成的正负样本对的质量难以保证。虽然有监督的对比学习可以通过人类反馈标签生成更准确的样本对，但仍缺乏细粒度的训练信号。本文提出了一种基于AI反馈来改进句子嵌入对比学习的方法（CLAIF），利用大型预训练语言模型 (LLMs) 的AI反馈构建带有细粒度样本相似度分数的样本对，以改进对比学习。此外，我们结合人工反馈和AI反馈为对比学习中的句子嵌入提供更好的监督信号。实验结果表明，我们的方法达到了最先进的水平。

    Contrastive learning has become a popular approach in natural language processing, particularly for the learning of sentence embeddings. However, the discrete nature of natural language makes it difficult to ensure the quality of positive and negative sample pairs generated through data augmentation methods. Although supervised contrastive learning can produce more accurate sample pairs with human feedback labels, it still lacks fine-grained training signals. In this paper, we propose to improve \textbf{C}ontrastive \textbf{L}earning of sentence embeddings from \textbf{AI} \textbf{F}eedback \textbf{(CLAIF)}. Our method utilizes AI feedback from large pre-trained language models (LLMs) to construct sample pairs with fine-grained sample similarity scores to improve contrastive learning. Besides, we combine human feedback and AI feedback to provide better supervision signals for supervised contrastive learning of sentence embeddings. Experimental results show that our method achieves stat
    
[^44]: MolKD: 在分子属性预测中提取化学反应中的跨模态知识

    MolKD: Distilling Cross-Modal Knowledge in Chemical Reactions for Molecular Property Prediction. (arXiv:2305.01912v1 [cs.LG])

    [http://arxiv.org/abs/2305.01912](http://arxiv.org/abs/2305.01912)

    本文提出了一种名为MolKD的新颖方法，通过将化学反应与分子间的跨模态知识提取和转移，为分子表示学习提供辅助，从而提高分子属性预测的效果。

    

    如何有效地表示分子是分子属性预测和药物发现中长期存在的挑战。本文研究了这个问题，提出了将化学领域知识，特别是与化学反应相关的知识，纳入到学习有效分子表示中。 然而，化学反应和分子之间固有的跨模态特性提出了重大挑战。因此，我们介绍了一种新的方法，即MolKD，它在化学反应中提取跨模态知识，以辅助分子属性预测。

    How to effectively represent molecules is a long-standing challenge for molecular property prediction and drug discovery. This paper studies this problem and proposes to incorporate chemical domain knowledge, specifically related to chemical reactions, for learning effective molecular representations. However, the inherent cross-modality property between chemical reactions and molecules presents a significant challenge to address. To this end, we introduce a novel method, namely MolKD, which Distills cross-modal Knowledge in chemical reactions to assist Molecular property prediction. Specifically, the reaction-to-molecule distillation model within MolKD transfers cross-modal knowledge from a pre-trained teacher network learning with one modality (i.e., reactions) into a student network learning with another modality (i.e., molecules). Moreover, MolKD learns effective molecular representations by incorporating reaction yields to measure transformation efficiency of the reactant-product 
    
[^45]: 分布式实例分割：用隐变量控制不确定性和高置信度预测的Latent-MaskRCNN模型研究

    Distributional Instance Segmentation: Modeling Uncertainty and High Confidence Predictions with Latent-MaskRCNN. (arXiv:2305.01910v1 [cs.CV])

    [http://arxiv.org/abs/2305.01910](http://arxiv.org/abs/2305.01910)

    本文提出了一种分布式实例分割模型，使用隐变量对对象掩膜的不确定性进行建模，同时通过置信度掩膜方法提高高精度拾取机器人的表现，并证明该方法可以显著减少机器人系统中的关键错误。

    

    目标识别和实例分割是任何机器人或自主系统中的基本技能。现有的最先进方法通常无法捕捉具有挑战性或模糊的场景中的有意义的不确定性，因此可能会在高性能应用程序中导致关键错误。本文探讨了一类使用隐变量的分布式实例分割模型，可以对对象掩模的可行假设建模，从而模拟不确定性。对于机器人拾取应用程序，我们提出一种置信度掩模方法，以实现工业应用案例所需的高精度。我们展示了我们的方法可以显著减少机器人系统中的关键错误，包括我们新发布的模糊场景数据集。在现实世界的服装拾取机器人上，我们的方法显著减少了双重拾取错误，同时保持高性能。

    Object recognition and instance segmentation are fundamental skills in any robotic or autonomous system. Existing state-of-the-art methods are often unable to capture meaningful uncertainty in challenging or ambiguous scenes, and as such can cause critical errors in high-performance applications. In this paper, we explore a class of distributional instance segmentation models using latent codes that can model uncertainty over plausible hypotheses of object masks. For robotic picking applications, we propose a confidence mask method to achieve the high precision necessary in industrial use cases. We show that our method can significantly reduce critical errors in robotic systems, including our newly released dataset of ambiguous scenes in a robotic application. On a real-world apparel-picking robot, our method significantly reduces double pick errors while maintaining high performance.
    
[^46]: 小样本事件检测：经验研究和统一视角

    Few-shot Event Detection: An Empirical Study and a Unified View. (arXiv:2305.01901v1 [cs.CL])

    [http://arxiv.org/abs/2305.01901](http://arxiv.org/abs/2305.01901)

    本文从两个实用的设置出发，分析比较了十种代表性的小样本事件检测方法，归纳总结出了原型方法的性能优越性，并在此基础上提出了一种简单且有效的方法。

    

    小样本事件检测 (ED) 已经被广泛研究，然而这也带来了明显的差异，例如各种动机、任务和实验设置，这些差异妨碍了模型的理解和未来进展。本文提出了一项彻底的经验研究、一个ED模型的统一视角和一个更好的统一基准线。为了公平评估，我们选择了两个实用的设置：低资源设置来评估泛化能力和类转移设置来评估可转移性。我们比较了三个数据集上的十种代表性方法，这些方法大致被分为基于提示和基于原型的模型进行详细分析。为了调查基于原型方法的优越性能，我们分解了设计并建立了一个统一框架。基于此，我们不仅提出了一种简单而有效的方法（例如在低资源设置下获得2.7％F1收益），而且为未来的研究提供了许多有价值的研究见解。

    Few-shot event detection (ED) has been widely studied, while this brings noticeable discrepancies, e.g., various motivations, tasks, and experimental settings, that hinder the understanding of models for future progress. This paper presents a thorough empirical study, a unified view of ED models, and a better unified baseline. For fair evaluation, we choose two practical settings: low-resource setting to assess generalization ability and class-transfer setting for transferability. We compare ten representative methods on three datasets, which are roughly grouped into prompt-based and prototype-based models for detailed analysis. To investigate the superior performance of prototype-based methods, we break down the design and build a unified framework. Based on that, we not only propose a simple yet effective method (e.g., 2.7% F1 gains under low-resource setting) but also offer many valuable research insights for future research.
    
[^47]: 人工智能革命：农业食品系统的全面调查

    Revolutionizing Agrifood Systems with Artificial Intelligence: A Survey. (arXiv:2305.01899v1 [cs.AI])

    [http://arxiv.org/abs/2305.01899](http://arxiv.org/abs/2305.01899)

    这篇论文探讨了人工智能技术在农业食品系统中的应用，重点关注了农业、畜牧业和渔业等领域。人工智能技术在农业食品分类、生长监测、产量预测和品质评估等方面表现出强大的能力，同时也提出了未来研究方向以及潜在的挑战和限制。

    

    随着全球人口的迅速增长，转变农业食品系统，使其更具生产力、效率、安全和可持续性，是缓解潜在粮食短缺的关键。最近，深度学习等人工智能技术在语言、视觉、遥感和农业食品系统应用等各个领域均显示出了其强大的能力。然而，人工智能对农业食品系统的整体影响仍不清楚。本文全面回顾了人工智能技术如何改变农业食品系统，并为现代农业食品行业做出贡献。首先，我们总结了农业食品系统中的数据获取方法，包括获取、存储和处理技术。其次，我们详细介绍了人工智能技术在农业、畜牧业和渔业等领域中的进展情况，涵盖了农业食品分类、生长监测、产量预测和品质评估等主题。此外，我们还提出了未来研究方向，并讨论了在农业食品系统应用人工智能技术中潜在的挑战和限制。

    With the world population rapidly increasing, transforming our agrifood systems to be more productive, efficient, safe, and sustainable is crucial to mitigate potential food shortages. Recently, artificial intelligence (AI) techniques such as deep learning (DL) have demonstrated their strong abilities in various areas, including language, vision, remote sensing (RS), and agrifood systems applications. However, the overall impact of AI on agrifood systems remains unclear. In this paper, we thoroughly review how AI techniques can transform agrifood systems and contribute to the modern agrifood industry. Firstly, we summarize the data acquisition methods in agrifood systems, including acquisition, storage, and processing techniques. Secondly, we present a progress review of AI methods in agrifood systems, specifically in agriculture, animal husbandry, and fishery, covering topics such as agrifood classification, growth monitoring, yield prediction, and quality assessment. Furthermore, we 
    
[^48]: VSRQ: 车联网系统安全风险的量化评估方法

    VSRQ: Quantitative Assessment Method for Safety Risk of Vehicle Intelligent Connected System. (arXiv:2305.01898v1 [cs.AI])

    [http://arxiv.org/abs/2305.01898](http://arxiv.org/abs/2305.01898)

    本文提出了一种新的车辆安全风险评估模型：VSRQ模型。通过结合I-FAHP和FCA聚类，挖掘车辆智能联接系统的易受攻击组件，并对其进行优先测试，以降低风险并确保车辆安全。

    

    随着车联网在现代汽车中的应用不断扩大，车辆功能也随着时代的发展变得越来越复杂。这也导致了越来越多的车辆漏洞和安全问题。因此，特别重要的是要识别高风险的车联网系统，因为它可以告诉安全人员哪个系统最容易受到攻击，让他们进行更彻底的检查和测试。在本文中，我们结合I-FAHP和FCA聚类开发了一个新的车辆安全风险评估模型：VSRQ模型。我们提取与车辆安全相关的重要指标，使用模糊聚类分析（FCA）和模糊层次分析过程（FAHP）挖掘车辆智能联接系统的易受攻击组件，并对易受攻击的组件进行优先测试，以降低风险并确保车辆安全。我们在OpenPilot上评估了模型并进行实验。

    The field of intelligent connected in modern vehicles continues to expand, and the functions of vehicles become more and more complex with the development of the times. This has also led to an increasing number of vehicle vulnerabilities and many safety issues. Therefore, it is particularly important to identify high-risk vehicle intelligent connected systems, because it can inform security personnel which systems are most vulnerable to attacks, allowing them to conduct more thorough inspections and tests. In this paper, we develop a new model for vehicle risk assessment by combining I-FAHP with FCA clustering: VSRQ model. We extract important indicators related to vehicle safety, use fuzzy cluster analys (FCA) combined with fuzzy analytic hierarchy process (FAHP) to mine the vulnerable components of the vehicle intelligent connected system, and conduct priority testing on vulnerable components to reduce risks and ensure vehicle safety. We evaluate the model on OpenPilot and experiment
    
[^49]: 基于因果感知的知识引导句子提取

    Causality-aware Concept Extraction based on Knowledge-guided Prompting. (arXiv:2305.01876v1 [cs.CL])

    [http://arxiv.org/abs/2305.01876](http://arxiv.org/abs/2305.01876)

    该论文提出了一种基于因果感知的知识引导提示方法，将其作为干预器装备到基于预训练语言模型的句子提取器中，以缓解概念偏差。在代表性的多语言KG数据集上进行广泛实验，获得了最先进的结果。

    

    概念有助于自然语言理解，但现有的知识图谱（KG）中远未完善。最近，预训练语言模型（PLM）已被广泛用于基于文本的概念提取（CE）。然而，PLM往往从大量语料库的共现关联中进行预训练知识挖掘，而非Token之间的真实因果关系。因此，预训练知识混淆了PLM，导致提取基于虚假共现相关性的有偏概念，不可避免地导致低精度。本文通过结构因果模型（SCM）提出了一种知识引导提示方法，将其作为干预器装备到基于PLM的提取器中，以减轻概念偏差。提示采用现有KG中的给定实体主题来缓解实体和有偏概念之间的虚假共现相关性。我们在代表性的多语言KG数据集上进行了广泛的实验，证明了我们提出的提示显著改进了提取性能，并达到了最先进的结果。

    Concepts benefit natural language understanding but are far from complete in existing knowledge graphs (KGs). Recently, pre-trained language models (PLMs) have been widely used in text-based concept extraction (CE). However, PLMs tend to mine the co-occurrence associations from massive corpus as pre-trained knowledge rather than the real causal effect between tokens.As a result, the pre-trained knowledge confounds PLMs to extract biased concepts based on spurious co-occurrence correlations, inevitably resulting in low precision. In this paper, through the lens of a Structural Causal Model (SCM), we propose equipping the PLM-based extractor with a knowledge-guided prompt as an intervention to alleviate concept bias. The prompt adopts the topic of the given entity from the existing knowledge in KGs to mitigate the spurious co-occurrence correlations between entities and biased concepts. Our extensive experiments on representative multilingual KG datasets justify that our proposed prompt 
    
[^50]: GPTutor: 一种由ChatGPT驱动的编程工具，用于程序代码解释

    GPTutor: a ChatGPT-powered programming tool for code explanation. (arXiv:2305.01863v1 [cs.HC])

    [http://arxiv.org/abs/2305.01863](http://arxiv.org/abs/2305.01863)

    本文介绍了一种名为GPTutor的ChatGPT动力编程工具，它是一个使用ChatGPT API的Visual Studio Code扩展，通过设计提示词，可以对所选代码进行精简、准确的解释。

    

    学习新的编程技能需要个性化指导。随着ChatGPT API等高级自然语言生成模型的出现，现在有可能创建一个方便的、个性化的AI编程教育辅导系统。本文介绍了一种名为GPTutor的ChatGPT动力编程工具，它是一个使用ChatGPT API的Visual Studio Code扩展，用于提供编程代码解释。

    Learning new programming skills requires tailored guidance. With the emergence of advanced Natural Language Generation models like the ChatGPT API, there is now a possibility of creating a convenient and personalized tutoring system with AI for computer science education. This paper presents GPTutor, a ChatGPT-powered programming tool, which is a Visual Studio Code extension using the ChatGPT API to provide programming code explanations. By integrating Visual Studio Code API, GPTutor can comprehensively analyze the provided code by referencing the relevant source codes. As a result, GPTutor can use designed prompts to explain the selected code with a pop-up message. GPTutor is now published at the Visual Studio Code Extension Marketplace, and its source code is openly accessible on GitHub. Preliminary evaluation indicates that GPTutor delivers the most concise and accurate explanations compared to vanilla ChatGPT and GitHub Copilot. Moreover, the feedback from students and teachers ind
    
[^51]: 基于扩增数据的扩散模型多模态图像描述

    Multimodal Data Augmentation for Image Captioning using Diffusion Models. (arXiv:2305.01855v1 [cs.CV])

    [http://arxiv.org/abs/2305.01855](http://arxiv.org/abs/2305.01855)

    本文提出了一种基于扩增数据的扩散模型多模态图像描述方法，用于生成高质量的图像-描述对，并在 MS COCO 数据集上实验表明其优于几个基准方法，并且在训练数据较少的情况下表现出显著的提升。

    

    图像描述是一项重要的视觉-语言任务，常常需要大量精细标注的图像-描述对来学习图像和文本之间的对齐关系。本文提出了一种多模态数据扩增方法，利用最新的文本到图像模型 Stable Diffusion 来扩展训练集，高质量生成图像-描述对。在 MS COCO 数据集上的广泛实验表明，我们的方法优于几个基准方法，在训练数据较少的情况下尤其表现出显著的提升。此外，我们扩增数据集训练的模型在性能上也超过了先前的未配对图像描述方法。最后，通过质量评估有意地筛选生成的数据，可进一步提高训练效率和效果。

    Image captioning, an important vision-language task, often requires a tremendous number of finely labeled image-caption pairs for learning the underlying alignment between images and texts. In this paper, we proposed a multimodal data augmentation method, leveraging a recent text-to-image model called Stable Diffusion, to expand the training set via high-quality generation of image-caption pairs. Extensive experiments on the MS COCO dataset demonstrate the advantages of our approach over several benchmark methods, and particularly a significant boost when having fewer training instances. In addition, models trained on our augmented datasets also outperform prior unpaired image captioning methods by a large margin. Finally, further improvement regarding the training efficiency and effectiveness can be obtained after intentionally filtering the generated data based on quality assessment.
    
[^52]: LineFormer：将线图数据提取重新思考为实例分割

    LineFormer: Rethinking Line Chart Data Extraction as Instance Segmentation. (arXiv:2305.01837v1 [cs.CV])

    [http://arxiv.org/abs/2305.01837](http://arxiv.org/abs/2305.01837)

    本文提出了一种使用实例分割的稳健线数据提取方法LineFormer，旨在解决多线图中视觉和结构变化所带来的挑战，其在多个基准数据集上实现了最先进的性能。

    

    从线图图像中提取数据是自动文档理解过程的重要组成部分，因为线图是一种普遍存在的数据可视化格式。然而，多线图中的视觉和结构变化量使它们特别具有挑战性。现有的工作对于所有这些变化都不是非常健壮，或者采取了一个全部图表统一的方法，或者依赖于诸如图例之类的辅助信息来提取线数据。在这项工作中，我们提出了一种使用实例分割的稳健线数据提取方法LineFormer。我们在几个基准合成和真实图表数据集上实现了最先进的性能。我们的实现可在https://github.com/TheJaeLal/LineFormer获得。

    Data extraction from line-chart images is an essential component of the automated document understanding process, as line charts are a ubiquitous data visualization format. However, the amount of visual and structural variations in multi-line graphs makes them particularly challenging for automated parsing. Existing works, however, are not robust to all these variations, either taking an all-chart unified approach or relying on auxiliary information such as legends for line data extraction. In this work, we propose LineFormer, a robust approach to line data extraction using instance segmentation. We achieve state-of-the-art performance on several benchmark synthetic and real chart datasets. Our implementation is available at https://github.com/TheJaeLal/LineFormer .
    
[^53]: 基于动态系统路径规划和无监督学习的实时环境自主搜索

    Autonomous search of real-life environments combining dynamical system-based path planning and unsupervised learning. (arXiv:2305.01834v1 [cs.RO])

    [http://arxiv.org/abs/2305.01834](http://arxiv.org/abs/2305.01834)

    本文提出了一种自动生成基于动态系统路径规划器和无监督机器学习技术相结合的算法，以克服混沌覆盖路径规划器的立即问题，并在模拟和实际环境中进行了测试，展示其在有限环境中实现自主搜索和覆盖的能力。

    

    近年来取得了使用混沌覆盖路径规划器进行有限环境搜索和遍历的进展，但该领域的现状仍处于初级阶段，目前的实验工作尚未开发出可满足混沌覆盖路径规划器需要克服的立即问题的强大方法 。本文旨在提出一种自动生成基于动态系统路径规划器和无监督机器学习技术相结合的算法，以克服混沌覆盖路径规划器的立即问题，并在模拟和实际环境中进行测试，展示其在有限环境中实现自主搜索和覆盖的能力。

    In recent years, advancements have been made towards the goal of using chaotic coverage path planners for autonomous search and traversal of spaces with limited environmental cues. However, the state of this field is still in its infancy as there has been little experimental work done. Current experimental work has not developed robust methods to satisfactorily address the immediate set of problems a chaotic coverage path planner needs to overcome in order to scan realistic environments within reasonable coverage times. These immediate problems are as follows: (1) an obstacle avoidance technique which generally maintains the kinematic efficiency of the robot's motion, (2) a means to spread chaotic trajectories across the environment (especially crucial for large and/or complex-shaped environments) that need to be covered, and (3) a real-time coverage calculation technique that is accurate and independent of cell size. This paper aims to progress the field by proposing algorithms that a
    
[^54]: KEPLET: 一种带有主题实体感知的知识增强预训练语言模型

    KEPLET: Knowledge-Enhanced Pretrained Language Model with Topic Entity Awareness. (arXiv:2305.01810v1 [cs.CL])

    [http://arxiv.org/abs/2305.01810](http://arxiv.org/abs/2305.01810)

    本文提出了一种知识增强预训练语言模型，即KEPLET，在预训练语料中加入主题实体感知，从而改善了实体交互和词语语义表示。

    

    近年来，预训练语言模型（PLM）通过在未结构化文本语料上进行预训练，然后在下游任务上进行微调以显示其优越性。在实体丰富的文本资源（如维基百科）中，知识增强的PLM（KEPLMs）在预训练过程中将标记与所提及的实体之间的交互结合起来，因此在实体中心任务（如实体链接和关系分类）上更有效。虽然传统KEPLM在某种程度上利用了维基百科的丰富结构，但它们仍然忽略了每个维基百科页面围绕一个主题实体的独特布局（由页面URL标识并在页面标题中显示）。本文证明，如果不加入主题实体，KEPLM将导致实体交互不足和偏差（关系）词语语义。因此，我们提出了KEPLET，一种新颖的带有主题实体感知的知识增强预训练语言模型。通过一种端到端的方式，KEPLET确定预训练语料中的主题实体，并改进了KEPLM的实体交互和词语语义表示。

    In recent years, Pre-trained Language Models (PLMs) have shown their superiority by pre-training on unstructured text corpus and then fine-tuning on downstream tasks. On entity-rich textual resources like Wikipedia, Knowledge-Enhanced PLMs (KEPLMs) incorporate the interactions between tokens and mentioned entities in pre-training, and are thus more effective on entity-centric tasks such as entity linking and relation classification. Although exploiting Wikipedia's rich structures to some extent, conventional KEPLMs still neglect a unique layout of the corpus where each Wikipedia page is around a topic entity (identified by the page URL and shown in the page title). In this paper, we demonstrate that KEPLMs without incorporating the topic entities will lead to insufficient entity interaction and biased (relation) word semantics. We thus propose KEPLET, a novel Knowledge-Enhanced Pre-trained LanguagE model with Topic entity awareness. In an end-to-end manner, KEPLET identifies where to a
    
[^55]: 当新的不一定是更好的：深度学习是否真正受益于基于隐式反馈的推荐？

    When Newer is Not Better: Does Deep Learning Really Benefit Recommendation From Implicit Feedback?. (arXiv:2305.01801v1 [cs.IR])

    [http://arxiv.org/abs/2305.01801](http://arxiv.org/abs/2305.01801)

    本研究对多个神经推荐模型与传统模型进行比较，提出了一组评估策略来衡量其记忆性能、泛化性能和子群特定性能，揭示了在IMDB和Yelp数据集上，神经推荐模型与传统模型的差异性。

    

    最近几年，神经模型被多次宣传为推荐领域的最先进技术，但是多个研究表明，许多神经推荐模型的最新结果并不能可靠地复现。一个主要原因是现有的评估是在不一致的协议下进行的。因此，这些可重复性问题使人们难以了解实际上可以从这些神经模型中获得多少益处。因此，需要一个公平而全面的绩效比较来比较传统模型和神经模型。为此，我们进行了一项大规模、系统性的研究，比较了基于隐式数据的顶部推荐的最新神经推荐模型和传统模型。我们提出了一组评估策略，用于衡量推荐模型的记忆性能、泛化性能和子群特定性能。

    In recent years, neural models have been repeatedly touted to exhibit state-of-the-art performance in recommendation. Nevertheless, multiple recent studies have revealed that the reported state-of-the-art results of many neural recommendation models cannot be reliably replicated. A primary reason is that existing evaluations are performed under various inconsistent protocols. Correspondingly, these replicability issues make it difficult to understand how much benefit we can actually gain from these neural models. It then becomes clear that a fair and comprehensive performance comparison between traditional and neural models is needed.  Motivated by these issues, we perform a large-scale, systematic study to compare recent neural recommendation models against traditional ones in top-n recommendation from implicit data. We propose a set of evaluation strategies for measuring memorization performance, generalization performance, and subgroup-specific performance of recommendation models. 
    
[^56]: 视觉与定义相遇：融合词义信息的无监督视觉词义消歧

    Vision Meets Definitions: Unsupervised Visual Word Sense Disambiguation Incorporating Gloss Information. (arXiv:2305.01788v1 [cs.CL])

    [http://arxiv.org/abs/2305.01788](http://arxiv.org/abs/2305.01788)

    本文提出了一种无监督的视觉词义消歧方法，通过引入外部词汇知识库的词义信息来解决原来图像-文本匹配模型中的多义词问题。采用贝叶斯推断来加入词义定义，并通过与上下文相关的 GPT-3 定义生成方法，成功解决了词典外问题。

    

    视觉词义消歧是一项任务，旨在找到最准确地描述给定上下文中目标词正确意义的图像。以往的图像-文本匹配模型往往受到词义多义性的影响。本文介绍了一种无监督的视觉词义消歧方法，该方法使用了外部词汇知识库的词汇信息，特别是词义定义。具体而言，我们建议在没有提供答案的词义信息时，采用贝叶斯推断来加入词义定义。此外，为了改进词典外问题，我们提出了一种与上下文相关的GPT-3定义生成方法。实验结果表明，我们的基于贝叶斯推断的方法明显提高了视觉词义消歧的性能。此外，我们的上下文相关定义生成方法在词典外例子上取得了显著的性能提升，表现优于现有的定义生成方法。

    Visual Word Sense Disambiguation (VWSD) is a task to find the image that most accurately depicts the correct sense of the target word for the given context. Previously, image-text matching models often suffered from recognizing polysemous words. This paper introduces an unsupervised VWSD approach that uses gloss information of an external lexical knowledge-base, especially the sense definitions. Specifically, we suggest employing Bayesian inference to incorporate the sense definitions when sense information of the answer is not provided. In addition, to ameliorate the out-of-dictionary (OOD) issue, we propose a context-aware definition generation with GPT-3. Experimental results show that the VWSD performance significantly increased with our Bayesian inference-based approach. In addition, our context-aware definition generation achieved prominent performance improvement in OOD examples exhibiting better performance than the existing definition generation method. We will publish source 
    
[^57]: 大规模动态系统的深度状态空间模型的廉价和确定性推断

    Cheap and Deterministic Inference for Deep State-Space Models of Interacting Dynamical Systems. (arXiv:2305.01773v1 [cs.LG])

    [http://arxiv.org/abs/2305.01773](http://arxiv.org/abs/2305.01773)

    本文提出了一种利用图神经网络建模大规模动态系统的深度状态空间模型，在保持多峰预测分布的准确性的同时，通过确定性矩匹配规则实现了无样本推断，提高了预测的效率和稳定性。

    

    图神经网络通常被用于建模相互作用的动态系统，因为它们优雅地适应于具有变化和大量代理的系统。虽然在确定性相互作用系统方面取得了很多进展，但对于有兴趣获得未来轨迹的预测分布的随机系统，模型更具挑战性。现有方法要么计算速度慢，因为它们依赖于蒙特卡罗抽样，要么做出简化假设，使得预测分布是单峰的。在本文中，我们提出了一个深度状态空间模型，它采用图神经网络来建模底层的相互作用动态系统。预测分布是多峰的，并且具有高斯混合模型的形式，其中高斯分量的矩可以通过确定性矩匹配规则计算。我们的矩匹配方案可以用于无样本推断，从而实现更有效和稳定的预测。实验结果表明，我们的方法能够有效地建模和预测随机系统的轨迹，即使存在巨大的不确定性。

    Graph neural networks are often used to model interacting dynamical systems since they gracefully scale to systems with a varying and high number of agents. While there has been much progress made for deterministic interacting systems, modeling is much more challenging for stochastic systems in which one is interested in obtaining a predictive distribution over future trajectories. Existing methods are either computationally slow since they rely on Monte Carlo sampling or make simplifying assumptions such that the predictive distribution is unimodal. In this work, we present a deep state-space model which employs graph neural networks in order to model the underlying interacting dynamical system. The predictive distribution is multimodal and has the form of a Gaussian mixture model, where the moments of the Gaussian components can be computed via deterministic moment matching rules. Our moment matching scheme can be exploited for sample-free inference, leading to more efficient and sta
    
[^58]: 受心理学启发的因果提示语

    Psychologically-Inspired Causal Prompts. (arXiv:2305.01764v1 [cs.CL])

    [http://arxiv.org/abs/2305.01764](http://arxiv.org/abs/2305.01764)

    本文提出了三个因果提示语，涵盖了情感分类任务中人类的心理过程。这些提示语可以用来产生更准确和可解释的模型预测。

    

    NLP数据集不仅仅含有输入输出对，还包含输入和输出变量之间的因果关系。本文以情感分类为例，探讨评论（X）和情感（Y）之间的因果关系。心理学研究表明，语言可以影响情绪，当一个人首次进行评分并在评论中进行自我合理化时（情感引起评论，即Y->X），与首先描述自己的经历并权衡利弊以做出最后评分时（评论引起情感，即X->Y），会引发不同的心理过程。此外，如果评注者通过心智理论（ToM）推断用户的原始评分，则这也是完全不同的心理过程（评论引起评分，即X-ToM-> Y）。本文将这三种情感分类的人类心理过程的因果机制转化为三个提示语，并在情感分类任务中应用这些提示语，以产生更准确和可解释的模型预测。

    NLP datasets are richer than just input-output pairs; rather, they carry causal relations between the input and output variables. In this work, we take sentiment classification as an example and look into the causal relations between the review (X) and sentiment (Y). As psychology studies show that language can affect emotion, different psychological processes are evoked when a person first makes a rating and then self-rationalizes their feeling in a review (where the sentiment causes the review, i.e., Y -> X), versus first describes their experience, and weighs the pros and cons to give a final rating (where the review causes the sentiment, i.e., X -> Y ). Furthermore, it is also a completely different psychological process if an annotator infers the original rating of the user by theory of mind (ToM) (where the review causes the rating, i.e., X -ToM-> Y ). In this paper, we verbalize these three causal mechanisms of human psychological processes of sentiment classification into three
    
[^59]: 空间-时间网络用于抗生素敏感性图案预测

    Spatial-Temporal Networks for Antibiogram Pattern Prediction. (arXiv:2305.01761v1 [cs.LG])

    [http://arxiv.org/abs/2305.01761](http://arxiv.org/abs/2305.01761)

    本文提出了一个新颖的问题，即抗生素敏感性图案预测，旨在预测未来哪些图案将出现，并解决了这一问题遇到的挑战。

    

    抗生素敏感性图案是对感染患者的抗生素耐药性检测结果进行周期性总结。抗生素敏感性图案有助于医生了解地区耐药性率并选择适当的处方抗生素。本文提出了一个新颖的问题，即抗生素敏感性图案预测，旨在预测未来哪些图案将出现。尽管该问题的重要性，但处理该问题会遇到一系列挑战，并且在文献中尚未得到探索。首先，抗生素敏感性图案不是独立同分布的，因为它们可能由于基因相似性而彼此紧密相关。

    An antibiogram is a periodic summary of antibiotic resistance results of organisms from infected patients to selected antimicrobial drugs. Antibiograms help clinicians to understand regional resistance rates and select appropriate antibiotics in prescriptions. In practice, significant combinations of antibiotic resistance may appear in different antibiograms, forming antibiogram patterns. Such patterns may imply the prevalence of some infectious diseases in certain regions. Thus it is of crucial importance to monitor antibiotic resistance trends and track the spread of multi-drug resistant organisms. In this paper, we propose a novel problem of antibiogram pattern prediction that aims to predict which patterns will appear in the future. Despite its importance, tackling this problem encounters a series of challenges and has not yet been explored in the literature. First of all, antibiogram patterns are not i.i.d as they may have strong relations with each other due to genomic similariti
    
[^60]: 演讲者匿名化对情感语音的影响评估

    Evaluation of Speaker Anonymization on Emotional Speech. (arXiv:2305.01759v1 [eess.AS])

    [http://arxiv.org/abs/2305.01759](http://arxiv.org/abs/2305.01759)

    本文研究了VoicePrivacy 2020 Challenge中演讲者匿名化对情感语音的影响，并发现其未能有效地保护演讲者的隐私。

    

    语音数据携带着个人的信息，如演讲者的身份和情感状态。这些属性可能被用于恶意目的。随着虚拟助手的发展，出现了新一代的隐私威胁。当前的研究已经解决了保护语音隐私的话题，其中之一是VoicePrivacy倡议，旨在促进为语音技术开发隐私保护工具。VoicePrivacy 2020挑战赛（VPC）选定的任务是演讲者匿名化。目标是隐藏源演讲者的身份，同时保留语言信息。VPC的基准线使用了语音转换。本文研究了VPC基准线系统对语音话语中情感信息的影响。按照攻击者对匿名化系统的了解，执行了评估。我们的研究结果表明，VPC基准线系统未能有效地匿名化语音中的情感信息，这可能会对演讲者的隐私造成潜在威胁。

    Speech data carries a range of personal information, such as the speaker's identity and emotional state. These attributes can be used for malicious purposes. With the development of virtual assistants, a new generation of privacy threats has emerged. Current studies have addressed the topic of preserving speech privacy. One of them, the VoicePrivacy initiative aims to promote the development of privacy preservation tools for speech technology. The task selected for the VoicePrivacy 2020 Challenge (VPC) is about speaker anonymization. The goal is to hide the source speaker's identity while preserving the linguistic information. The baseline of the VPC makes use of a voice conversion. This paper studies the impact of the speaker anonymization baseline system of the VPC on emotional information present in speech utterances. Evaluation is performed following the VPC rules regarding the attackers' knowledge about the anonymization system. Our results show that the VPC baseline system does n
    
[^61]: 基于少样本背景学习的知识库问答

    Few-shot In-context Learning for Knowledge Base Question Answering. (arXiv:2305.01750v1 [cs.CL])

    [http://arxiv.org/abs/2305.01750](http://arxiv.org/abs/2305.01750)

    该论文提出了KB-BINDER框架，通过少量的上下文演示实现了在多个知识库问答数据集上的背景学习，大大提高了KBQA问题的可解性。

    

    知识库问答被认为是一个难以解决的问题，因为需要应对各种可能的自然语言问题。此外，不同知识库架构项之间的异构性通常需要针对不同的知识库问答（KBQA）数据集进行专门的训练。为了处理多种KBQA数据集上的问题，我们提出了KB-BINDER，该框架可以进行少量样本的背景学习，并将不同的KBQA数据集统一。首先，KB-BINDER利用像Codex这样的大型语言模型通过模仿少量演示来生成特定问题的逻辑形式作为草稿。其次，KB-BINDER基于知识库来绑定生成的草稿至可执行形式，通过BM25分数匹配。在四个公开的异构KBQA数据集上的实验结果表明，KB-BINDER可以在少量上下文演示的情况下取得强大的性能，在某些情况下超过了最先进的方法。

    Question answering over knowledge bases is considered a difficult problem due to the challenge of generalizing to a wide variety of possible natural language questions. Additionally, the heterogeneity of knowledge base schema items between different knowledge bases often necessitates specialized training for different knowledge base question-answering (KBQA) datasets. To handle questions over diverse KBQA datasets with a unified training-free framework, we propose KB-BINDER, which for the first time enables few-shot in-context learning over KBQA tasks. Firstly, KB-BINDER leverages large language models like Codex to generate logical forms as the draft for a specific question by imitating a few demonstrations. Secondly, KB-BINDER grounds on the knowledge base to bind the generated draft to an executable one with BM25 score matching. The experimental results on four public heterogeneous KBQA datasets show that KB-BINDER can achieve a strong performance with only a few in-context demonstr
    
[^62]: 带有有限注释的分割任务中的期望最大化伪标签方法研究

    Expectation Maximization Pseudo Labelling for Segmentation with Limited Annotations. (arXiv:2305.01747v1 [cs.CV])

    [http://arxiv.org/abs/2305.01747](http://arxiv.org/abs/2305.01747)

    本文提出了一种伪标签的泛化方法，称为贝叶斯伪标签，在半监督医学图像分割任务中应用效果良好。

    

    本文研究了半监督医学图像分割中的伪标签及其推广，伪标签通过利用未标记数据的原始推断作为自训练的伪标签，在半监督学习中取得了巨大的实证成功。我们建立了伪标签和期望最大化算法之间的联系，部分解释了其实证成功。在此基础上，我们展示了贝叶斯原理下伪标签的完全泛化，称为贝叶斯伪标签。然后，我们提供了一种变分方法来学习逼近贝叶斯伪标签，通过学习选择高质量伪标签的阈值。接下来，我们在医学图像分割的半监督学习中展示了伪标签和其推广贝叶斯伪标签的应用。

    We study pseudo labelling and its generalisation for semi-supervised segmentation of medical images. Pseudo labelling has achieved great empirical successes in semi-supervised learning, by utilising raw inferences on unlabelled data as pseudo labels for self-training. In our paper, we build a connection between pseudo labelling and the Expectation Maximization algorithm which partially explains its empirical successes. We thereby realise that the original pseudo labelling is an empirical estimation of its underlying full formulation. Following this insight, we demonstrate the full generalisation of pseudo labels under Bayes' principle, called Bayesian Pseudo Labels. We then provide a variational approach to learn to approximate Bayesian Pseudo Labels, by learning a threshold to select good quality pseudo labels. In the rest of the paper, we demonstrate the applications of Pseudo Labelling and its generalisation Bayesian Psuedo Labelling in semi-supervised segmentation of medical images
    
[^63]: 利用因子化动作空间在医疗保健中进行高效的离线强化学习

    Leveraging Factored Action Spaces for Efficient Offline Reinforcement Learning in Healthcare. (arXiv:2305.01738v1 [cs.LG])

    [http://arxiv.org/abs/2305.01738](http://arxiv.org/abs/2305.01738)

    本论文提出了一种利用因子化动作空间的线性Q函数分解形式的方法，用于解决离线强化学习中存在的动作组合问题，该方法在提高采样效率的同时并不牺牲策略最优性，通过模拟器和实际数据集的几个离线强化学习问题的实验表明，相较于标准方法，该方法具有更快的收敛速度、更好的性能和更高的采样效率。

    

    许多强化学习应用程序具有组合动作空间，其中每个动作是子动作的组合。标准强化学习方法忽略了这种固有的分解结构，导致可能对少见的子动作组合做出的推理没有意义；这在离线设置下尤其问题突出，因为数据可能受限。在这项工作中，我们提出了一种由因子化动作空间引起的线性Q函数分解的形式。我们研究了我们的方法的理论性质，确定了当用于近似Q函数时保证产生零偏差的情况。在具有理论保证的范围之外的情况下，我们表明我们的方法仍然是有用的，因为它提高了采样效率而不一定牺牲策略最优性，允许我们实现更好的偏差-方差权衡。在使用由医疗保健启示的模拟器和实际数据集进行的几个离线强化学习问题中，我们证明了我们的方法比标准方法具有更快的收敛速度、更好的性能和更高的采样效率。

    Many reinforcement learning (RL) applications have combinatorial action spaces, where each action is a composition of sub-actions. A standard RL approach ignores this inherent factorization structure, resulting in a potential failure to make meaningful inferences about rarely observed sub-action combinations; this is particularly problematic for offline settings, where data may be limited. In this work, we propose a form of linear Q-function decomposition induced by factored action spaces. We study the theoretical properties of our approach, identifying scenarios where it is guaranteed to lead to zero bias when used to approximate the Q-function. Outside the regimes with theoretical guarantees, we show that our approach can still be useful because it leads to better sample efficiency without necessarily sacrificing policy optimality, allowing us to achieve a better bias-variance trade-off. Across several offline RL problems using simulators and real-world datasets motivated by healthca
    
[^64]: 从决策规则系统构建决策树和无环决策图

    Construction of Decision Trees and Acyclic Decision Graphs from Decision Rule Systems. (arXiv:2305.01721v1 [cs.AI])

    [http://arxiv.org/abs/2305.01721](http://arxiv.org/abs/2305.01721)

    该论文探讨了从决策规则系统构建决策树和无环决策图的复杂性，并讨论了不必构建完整决策树而只需描述给定输入的计算路径的可能性。

    

    决策树和决策规则系统被广泛用作分类器、知识表示和运算法。它们是最易于解释的数据分析模型之一。研究这两种模型之间的关系可以看作是计算机科学的一个重要任务。该文研究了从决策规则系统构建决策树和无环决策图的复杂性，并讨论了在给定输入时不构建整个决策树，而是描述在该树中的计算路径的可能性。

    Decision trees and systems of decision rules are widely used as classifiers, as a means for knowledge representation, and as algorithms. They are among the most interpretable models for data analysis. The study of the relationships between these two models can be seen as an important task of computer science. Methods for transforming decision trees into systems of decision rules are simple and well-known. In this paper, we consider the inverse transformation problem, which is not trivial. We study the complexity of constructing decision trees and acyclic decision graphs representing decision trees from decision rule systems, and we discuss the possibility of not building the entire decision tree, but describing the computation path in this tree for the given input.
    
[^65]: 通过可逆神经网络学习解释的非交互语义空间

    Learning Disentangled Semantic Spaces of Explanations via Invertible Neural Networks. (arXiv:2305.01713v1 [cs.CL])

    [http://arxiv.org/abs/2305.01713](http://arxiv.org/abs/2305.01713)

    本文介绍了一种使用可逆神经网络将BERT-GPT2自动编码器的隐藏空间转换为更可分离的语义空间的方法，实验结果表明此方法可以改进模型的可解释性和可控性，并取得了比最先进模型更好的性能表现。

    

    在细化连续空间的句子表征上进行解耦可以在定位明确发生的生成因素的同时，改进可解释性和语义控制，这为基于神经的语言模型赋予了一些符号模型的优势，同时保持其灵活性。 本文提出了一种方法，通过使用可逆神经网络（INN）将BERT-GPT2自动编码器的隐藏空间转换为更可分离的语义空间来解除编码的隐藏空间。实验结果表明，与最新的最先进模型相比，INN能够将分布式隐藏空间转换为更好的语义上解耦的潜在空间，从而产生更好的可解释性和可控性。

    Disentangling sentence representations over continuous spaces can be a critical process in improving interpretability and semantic control by localising explicit generative factors. Such process confers to neural-based language models some of the advantages that are characteristic of symbolic models, while keeping their flexibility. This work presents a methodology for disentangling the hidden space of a BERT-GPT2 autoencoder by transforming it into a more separable semantic space with the support of a flow-based invertible neural network (INN). Experimental results indicate that the INN can transform the distributed hidden space into a better semantically disentangled latent space, resulting in better interpretability and controllability, when compared to recent state-of-the-art models.
    
[^66]: 基于期望角度看待AI调解沟通的担忧和不同态度

    Fears about AI-mediated communication are grounded in different expectations for one's own versus others' use. (arXiv:2305.01670v1 [cs.HC])

    [http://arxiv.org/abs/2305.01670](http://arxiv.org/abs/2305.01670)

    人们对AI调解沟通技术的秘密使用持消极态度，期望别人的使用率比实际情况高，很多人认为别人对AICTs使用不负责任，这些因素可能导致关于AI调解沟通技术的错误看法。

    

    AI媒介交流技术(AICTs)的迅速发展，即使用人工智能来增强人与人之间的消息沟通已经引发了人们对人际关系的未来以及披露和采用行为的担忧。本文通过评估人们对公开和隐秘的AICTs的可接受性和使用情况的看法，进一步探讨了这个问题。在两项代表性样本研究（英国：N=477，美国：N=765）中，我们发现，与公开AICTs相比，秘密AICTs使用被认为不太可接受，人们往往高估别人的AICTs使用率，而且人们也期望他人不负责任地使用AICTs。因此，我们担心这种畸形期望和不同的期望角度会引起一种自我实现的悲观看法，从而影响到AI调解沟通的发展。

    The rapid development of AI-mediated communication technologies (AICTs), which are digital tools that use AI to augment interpersonal messages, has raised concerns about the future of interpersonal trust and prompted discussions about disclosure and uptake. This paper contributes to this discussion by assessing perceptions about the acceptability and use of open and secret AICTs for oneself and others. In two studies with representative samples (UK: N=477, US: N=765), we found that secret AICT use is deemed less acceptable than open AICT use, people tend to overestimate others' AICT use, and people expect others to use AICTs irresponsibly. Thus, we raise concerns about the potential for misperceptions and different expectations for others to drive self-fulfilling pessimistic outlooks about AI-mediated communication.
    
[^67]: 视觉推理：从状态到变换

    Visual Reasoning: from State to Transformation. (arXiv:2305.01668v1 [cs.CV])

    [http://arxiv.org/abs/2305.01668](http://arxiv.org/abs/2305.01668)

    提出了一个“以变换为驱动”的视觉推理（TVR）任务，旨在解决已有任务仅关注静态环境状态限制的问题。基于CLEVR构建了合成数据集和真实数据集进行验证。

    

    大部分已有的视觉推理任务，例如VQA中的CLEVR，忽略了一个重要因素：变换。它们仅用于测试机器在静态环境（例如单个图像）中理解概念和关系的能力。这种仅关注状态的视觉推理存在限制，不能很好地反映不同状态之间动态推断的能力，而在Piaget的理论中，这种推断能力同样重要。为了解决这个问题，我们提出了一种新的“以变换为驱动”的视觉推理（TVR）任务。给定初始和最终状态，目标是推断相应的中间变换。基于CLEVR，我们首先构建了一个名为TRANCE的新的合成数据集，其包括三个级别的设置：基本（单步变换）、事件（多步变换）和视图（多步变换与变形视图）。接下来，我们基于真实数据集构建了另一个名为TRANCO的数据集。

    Most existing visual reasoning tasks, such as CLEVR in VQA, ignore an important factor, i.e.~transformation. They are solely defined to test how well machines understand concepts and relations within static settings, like one image. Such \textbf{state driven} visual reasoning has limitations in reflecting the ability to infer the dynamics between different states, which has shown to be equally important for human cognition in Piaget's theory. To tackle this problem, we propose a novel \textbf{transformation driven} visual reasoning (TVR) task. Given both the initial and final states, the target becomes to infer the corresponding intermediate transformation. Following this definition, a new synthetic dataset namely TRANCE is first constructed on the basis of CLEVR, including three levels of settings, i.e.~Basic (single-step transformation), Event (multi-step transformation), and View (multi-step transformation with variant views). Next, we build another real dataset called TRANCO based 
    
[^68]: SIA-FTP: 一种语音指令感知的飞行轨迹预测框架

    SIA-FTP: A Spoken Instruction Aware Flight Trajectory Prediction Framework. (arXiv:2305.01661v1 [cs.SD])

    [http://arxiv.org/abs/2305.01661](http://arxiv.org/abs/2305.01661)

    提出一种语音指令感知的飞行轨迹预测框架，通过融合即时的语音指令和飞行轨迹表示，解决了语音指令和飞行轨迹的模态差距问题，在多个真实世界数据集上表现优异。

    

    通过语音通讯进行地空协商是确保空中交通管制（ATC）操作安全和效率的重要前提。但是，随着交通流量的增加，由于人为因素导致的错误指令给ATC安全带来了巨大威胁。现有的飞行轨迹预测（FTP）方法主要依赖于历史轨迹的飞行状态，在实时机动指令的预测上会出现显著的延迟，这不利于冲突检测。本文提出了一种名为SIA-FTP的语音指令感知FTP框架，通过包含即时的语音指令来支持高机动FTP任务。为了解决模态差距并最小化数据需求，我们提出了一种联合注意机制来融合语音指令嵌入和飞行轨迹表示。在多个真实世界数据集上评估了所提出的SIA-FTP，与现有的FTP方法相比取得了显著的改进。

    Ground-air negotiation via speech communication is a vital prerequisite for ensuring safety and efficiency in air traffic control (ATC) operations. However, with the increase in traffic flow, incorrect instructions caused by human factors bring a great threat to ATC safety. Existing flight trajectory prediction (FTP) approaches primarily rely on the flight status of historical trajectory, leading to significant delays in the prediction of real-time maneuvering instruction, which is not conducive to conflict detection. A major reason is that spoken instructions and flight trajectories are presented in different modalities in the current air traffic control (ATC) system, bringing great challenges to considering the maneuvering instruction in the FTP tasks. In this paper, a spoken instruction-aware FTP framework, called SIA-FTP, is innovatively proposed to support high-maneuvering FTP tasks by incorporating instant spoken instruction. To address the modality gap and minimize the data requ
    
[^69]: 数据估值：机器学习中的偏序 Shapley 值

    Data valuation: The partial ordinal Shapley value for machine learning. (arXiv:2305.01660v1 [cs.LG])

    [http://arxiv.org/abs/2305.01660](http://arxiv.org/abs/2305.01660)

    本文提出了偏序 Shapley 值的定义，并提出三种算法来近似计算结果，以解决数据合作中顺序作用的问题。

    

    在机器学习应用中，使用 Shapley 值进行数据估值已经成为一个流行的研究领域。然而，由于大多数研究缺乏关于数据合作中顺序作用的讨论，因此解决数据顺序的作用是一个挑战。为了解决这个问题，本文通过群论中的抽象代数研究了偏序 Shapley 值的定义。此外，由于偏序 Shapley 值的计算需要指数级别的时间，本文还提出了三个算法来近似计算结果，分别为截断蒙特卡洛算法、分类蒙特卡洛算法和分类截断蒙特卡洛算法。这三个算法的实现不同，但都可以通过一定程度的近似来加快计算速度。

    Data valuation using Shapley value has emerged as a prevalent research domain in machine learning applications. However, it is a challenge to address the role of order in data cooperation as most research lacks such discussion. To tackle this problem, this paper studies the definition of the partial ordinal Shapley value by group theory in abstract algebra. Besides, since the calculation of the partial ordinal Shapley value requires exponential time, this paper also gives three algorithms for approximating the results. The Truncated Monte Carlo algorithm is derived from the classic Shapley value approximation algorithm. The Classification Monte Carlo algorithm and the Classification Truncated Monte Carlo algorithm are based on the fact that the data points in the same class provide similar information, then we can accelerate the calculation by leaving out some data points in each class.
    
[^70]: FlightBERT++：一种非自回归多时域飞行轨迹预测框架

    FlightBERT++: A Non-autoregressive Multi-Horizon Flight Trajectory Prediction Framework. (arXiv:2305.01658v1 [cs.LG])

    [http://arxiv.org/abs/2305.01658](http://arxiv.org/abs/2305.01658)

    FlightBERT++提出了一种非自回归的多时域飞行轨迹预测框架，通过引入时域感知上下文生成器解决了误差累积和低效率的问题。

    

    飞行轨迹预测是空中交通管制中的重要任务，可以帮助空管员更安全高效地管理空域。现有方法通常采用自回归方式执行多时域飞行轨迹预测任务，容易出现误差累积和低效率问题。本文提出了一种新的框架，称为FlightBERT++，以i）直接以非自回归方式预测多时域飞行轨迹，和ii）改善FlightBERT框架中二进制编码（BE）表示的限制。具体而言，所提出的框架通过通用的编码器-解码器架构实现，其中编码器从历史观测中学习时空模式，而解码器预测未来时间步的飞行状态。与传统架构相比，额外的时域感知上下文生成器（HACG）专门设计考虑先前的时域。

    Flight Trajectory Prediction (FTP) is an essential task in Air Traffic Control (ATC), which can assist air traffic controllers to manage airspace more safely and efficiently. Existing approaches generally perform multi-horizon FTP tasks in an autoregressive manner, which is prone to suffer from error accumulation and low-efficiency problems. In this paper, a novel framework, called FlightBERT++, is proposed to i) forecast multi-horizon flight trajectories directly in a non-autoregressive way, and ii) improved the limitation of the binary encoding (BE) representation in the FlightBERT framework. Specifically, the proposed framework is implemented by a generalized Encoder-Decoder architecture, in which the encoder learns the temporal-spatial patterns from historical observations and the decoder predicts the flight status for the future time steps. Compared to conventional architecture, an extra horizon-aware contexts generator (HACG) is dedicatedly designed to consider the prior horizon 
    
[^71]: 基于DDVal的分散式学习中可伸缩的数据点估值方法

    Scalable Data Point Valuation in Decentralized Learning. (arXiv:2305.01657v1 [cs.LG])

    [http://arxiv.org/abs/2305.01657](http://arxiv.org/abs/2305.01657)

    该文提出了一种名为DDVal的方法，用于在联邦和群智学习中的分散式数据估值，可以估算单个数据点的价值。DDVal基于共享深度特征，并通过k最近邻逼近方法来估算Shapley值，可用于同时向机构和个人奖励为分散式机器学习任务提供数据的贡献。同时，DDVal对机构的贡献进行了层次化的结论，并在实验证明其估算机构贡献的准确性较现有的联邦学习Shapley值逼近方法更高。

    

    对于联邦和群智学习中的数据估值研究，现有文献集中在估算客户端贡献上，并且在数据在客户端之间是独立同分布(IID)时表现最佳。然而，在实际的应用中，数据很少是IID分布的。我们提出了一种名为DDVal的方法，用于在联邦和群智学习中的分散式数据估值，可以估算单个数据点的价值。DDVal基于共享深度特征，并通过k最近邻逼近方法来估算Shapley值。这允许新的应用，例如同时向机构和个人奖励为分散式机器学习任务提供数据的贡献。通过DDVal对数据点进行估值，还能对机构的贡献进行层次化的结论，我们通过实验证明DDVal在估算机构贡献时的准确性比现有的联邦学习Shapley值逼近方法高。具体而言，它达到了...

    Existing research on data valuation in federated and swarm learning focuses on valuing client contributions and works best when data across clients is independent and identically distributed (IID). In practice, data is rarely distributed IID. We develop an approach called DDVal for decentralized data valuation, capable of valuing individual data points in federated and swarm learning. DDVal is based on sharing deep features and approximating Shapley values through a k-nearest neighbor approximation method. This allows for novel applications, for example, to simultaneously reward institutions and individuals for providing data to a decentralized machine learning task. The valuation of data points through DDVal allows to also draw hierarchical conclusions on the contribution of institutions, and we empirically show that the accuracy of DDVal in estimating institutional contributions is higher than existing Shapley value approximation methods for federated learning. Specifically, it reach
    
[^72]: 从自然语言到代码：利用数据进行程序综合。

    From Words to Code: Harnessing Data for Program Synthesis from Natural Language. (arXiv:2305.01598v1 [cs.DB])

    [http://arxiv.org/abs/2305.01598](http://arxiv.org/abs/2305.01598)

    该论文利用数据上下文对大型语言模型生成的代码进行语义重排，以生成更优质的程序。

    

    创建正确操作数据的程序是一项艰巨的任务，因为底层的编程语言和 API 对于许多不熟练的程序员来说学习起来很具有挑战性。大型语言模型展示了从自然语言生成代码的巨大潜力，但在数据操作领域，除了所需任务的自然语言描述外，我们还有数据集作为该任务的上下文。现有的方法仅通过将输入数据中的相关信息添加到发送给 LLM 的提示中的方式有限地利用数据上下文。在这项工作中，我们利用可用的输入数据来执行 LLM 生成的候选程序并收集它们的输出。我们引入了语义重排技术，该技术基于程序输出的三个信号（a）语义过滤和良好格式得分调整：程序是否符合语义和格式， (b) 输入-输出示例得分: 程序是否为输入数据提供了输出。, (c) 结构与规范得分：程序是否遵循API的结构和规范，以重排 LLM 生成的程序。

    Creating programs to correctly manipulate data is a difficult task, as the underlying programming languages and APIs can be challenging to learn for many users who are not skilled programmers. Large language models (LLMs) demonstrate remarkable potential for generating code from natural language, but in the data manipulation domain, apart from the natural language (NL) description of the intended task, we also have the dataset on which the task is to be performed, or the "data context". Existing approaches have utilized data context in a limited way by simply adding relevant information from the input data into the prompts sent to the LLM.  In this work, we utilize the available input data to execute the candidate programs generated by the LLMs and gather their outputs. We introduce semantic reranking, a technique to rerank the programs generated by LLMs based on three signals coming the program outputs: (a) semantic filtering and well-formedness based score tuning: do programs even ge
    
[^73]: 如何发挥大语言模型在少样本关系抽取中的能力？

    How to Unleash the Power of Large Language Models for Few-shot Relation Extraction?. (arXiv:2305.01555v1 [cs.CL])

    [http://arxiv.org/abs/2305.01555](http://arxiv.org/abs/2305.01555)

    本文通过使用GPT-3.5模型在少样本关系抽取中，实现在四个不同数据集上的新的最优性能，并提出了与任务相关的指导说明和约束模式下的数据生成方法。

    

    语言模型的扩展已经彻底改变了广泛的自然语言处理任务，但是使用大型语言模型进行少样本关系抽取还没有得到全面探索。本文通过详细实验，研究了使用GPT-3.5进行少样本关系抽取的基本方法——上下文学习和数据生成。为了增强少样本性能，我们进一步提出了与任务相关的指导说明和约束模式下的数据生成。我们观察到，在上下文学习的情况下，可以实现与以前的提示学习方法相当的性能，而使用大型语言模型的数据生成可以推动以前的解决方案以在四个广泛研究的关系抽取数据集上获得新的最先进的少样本结果。我们希望我们的工作可以激发未来对大型语言模型在少样本关系抽取中的能力的研究。代码可以在 \url{https://github.com/zjunlp/DeepKE/tree/main/example/llm} 中找到。

    Scaling language models have revolutionized widespread NLP tasks, yet little comprehensively explored few-shot relation extraction with large language models. In this paper, we investigate principal methodologies, in-context learning and data generation, for few-shot relation extraction via GPT-3.5 through exhaustive experiments. To enhance few-shot performance, we further propose task-related instructions and schema-constrained data generation. We observe that in-context learning can achieve performance on par with previous prompt learning approaches, and data generation with the large language model can boost previous solutions to obtain new state-of-the-art few-shot results on four widely-studied relation extraction datasets. We hope our work can inspire future research for the capabilities of large language models in few-shot relation extraction. Code is available in \url{https://github.com/zjunlp/DeepKE/tree/main/example/llm.
    
[^74]: 基于LTL规范的样本有效无模型强化学习与优化保证

    Sample Efficient Model-free Reinforcement Learning from LTL Specifications with Optimality Guarantees. (arXiv:2305.01381v1 [cs.LG])

    [http://arxiv.org/abs/2305.01381](http://arxiv.org/abs/2305.01381)

    本文提出了一种基于LTL规范的无模型强化学习方法，该方法结合乘积MDP、奖励结构和折扣机制有效地学习并优化未知随机系统最大化满足LTL规范的概率的最优策略。

    

    线性时间逻辑（LTL）广泛用于指定系统策略的高级目标，自主系统学习相对于这样的规范的最优策略是非常理想的。 但是，从LTL规范中学习最优策略并不轻松。我们提出了一种无模型强化学习（RL）方法，该方法可以有效地学习未知随机系统的最优策略，其中使用马尔可夫决策过程（MDP）进行建模。我们提出了一种新颖且更通用的乘积MDP、奖励结构和折扣机制，当与现成的无模型RL算法结合使用时，能够高效地学习最大化给定LTL规范满足概率的最优策略，并提供了更好的有关选择RL中关键参数以保证最优性的理论结果。为了直接评估学习策略，我们采用概率模型检查器PRISM来计算LTL规范的满足概率。

    Linear Temporal Logic (LTL) is widely used to specify high-level objectives for system policies, and it is highly desirable for autonomous systems to learn the optimal policy with respect to such specifications. However, learning the optimal policy from LTL specifications is not trivial. We present a model-free Reinforcement Learning (RL) approach that efficiently learns an optimal policy for an unknown stochastic system, modelled using Markov Decision Processes (MDPs). We propose a novel and more general product MDP, reward structure and discounting mechanism that, when applied in conjunction with off-the-shelf model-free RL algorithms, efficiently learn the optimal policy that maximizes the probability of satisfying a given LTL specification with optimality guarantees. We also provide improved theoretical results on choosing the key parameters in RL to ensure optimality. To directly evaluate the learned policy, we adopt probabilistic model checker PRISM to compute the probability of 
    
[^75]: 触发词作为后门攻击的触发器：检查语言模型的脆弱性

    Prompt as Triggers for Backdoor Attack: Examining the Vulnerability in Language Models. (arXiv:2305.01219v1 [cs.CL])

    [http://arxiv.org/abs/2305.01219](http://arxiv.org/abs/2305.01219)

    本研究提出一种新颖有效的“ProAttack”方法来执行干净标签的后门攻击，使用的是提示本身作为触发器。该方法不需要外部触发器，并确保毒瘤数据的标注正确，提高了后门攻击的隐蔽性，相比于现有的后门攻击方法有显著提升。

    

    基于提示的学习范例弥合了预训练和微调之间的差距，在几个NLP任务中取得了最先进的性能，尤其是在少样本情况下。尽管应用广泛，但基于提示的学习容易受到后门攻击。文本后门攻击旨在通过注入触发器并修改标签来在模型中引入有针对性的漏洞。然而，由于触发器的存在和毒瘤数据标注不正确等缺陷，这种攻击存在异常的自然语言表达。在本研究中，我们提出了一种新颖有效的“ProAttack”方法，基于提示来执行干净标签的后门攻击，使用的是提示本身作为触发器。我们的方法不需要外部触发器，并确保毒瘤数据的标注正确，提高了后门攻击的隐蔽性。通过在丰富的资源和少样本文本语料库上的广泛实验，我们证明了ProAttack方法在保持干净数据一致性的同时显著优于现有的后门攻击方式。

    The prompt-based learning paradigm, which bridges the gap between pre-training and fine-tuning, achieves state-of-the-art performance on several NLP tasks, particularly in few-shot settings. Despite being widely applied, prompt-based learning is vulnerable to backdoor attacks. Textual backdoor attacks are designed to introduce targeted vulnerabilities into models by poisoning a subset of training samples through trigger injection and label modification. However, they suffer from flaws such as abnormal natural language expressions resulting from the trigger and incorrect labeling of poisoned samples. In this study, we propose {\bf ProAttack}, a novel and efficient method for performing clean-label backdoor attacks based on the prompt, which uses the prompt itself as a trigger. Our method does not require external triggers and ensures correct labeling of poisoned samples, improving the stealthy nature of the backdoor attack. With extensive experiments on rich-resource and few-shot text c
    
[^76]: CryCeleb: 基于婴儿哭声的说话人认证数据集

    CryCeleb: A Speaker Verification Dataset Based on Infant Cry Sounds. (arXiv:2305.00969v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2305.00969](http://arxiv.org/abs/2305.00969)

    CryCeleb是一个基于婴儿哭声的说话人认证数据集，包括超过6小时的手动分割哭声，可用于研究婴儿哭声分析。

    

    本文描述了Ubenwa CryCeleb数据集——一个标记的婴儿哭声收集，以及附带的CryCeleb 2023任务——一个基于婴儿哭声的公共说话人验证挑战。我们释放出786名新生儿超过6小时的手动分割哭声，以鼓励婴儿哭声分析方面的研究。

    This paper describes the Ubenwa CryCeleb dataset - a labeled collection of infant cries, and the accompanying CryCeleb 2023 task - a public speaker verification challenge based on infant cry sounds. We release for academic usage more than 6 hours of manually segmented cry sounds from 786 newborns to encourage research in infant cry analysis.
    
[^77]: 基于差异引导重建学习的图像篡改检测方法

    Discrepancy-Guided Reconstruction Learning for Image Forgery Detection. (arXiv:2304.13349v1 [cs.CV])

    [http://arxiv.org/abs/2304.13349](http://arxiv.org/abs/2304.13349)

    本论文提出了一种基于差异引导的图像篡改检测方法，能够提升模型对篡改敏感且具有紧凑视觉模式的学习能力，具有较广泛的推广性。

    

    本论文提出了一种新的图像篡改检测范式，旨在提高模型对于既敏感于篡改又具有紧凑视觉模式的学习能力。相对于现有方法仅关注篡改特定模式（例如噪声、纹理和频率）的问题，我们的方法更具有广泛的推广性。具体而言，我们首先提出了一个差异引导编码器（DisGE）来提取敏感于篡改的视觉模式。DisGE由两个分支组成，其中主流的骨干分支用于提取一般语义特征，而辅助的差异性外部注意力分支用于提取明确的篡改提示。此外，还提出了一个双头重建（DouHR）模块，用于增强不同颗粒空间中的真实紧凑视觉模式。在DouHR下，我们进一步引入了一种差异聚合检测器（DisAD）来聚合这些真实紧凑的视觉模式，从而提高对未知模式的篡改检测能力。

    In this paper, we propose a novel image forgery detection paradigm for boosting the model learning capacity on both forgery-sensitive and genuine compact visual patterns. Compared to the existing methods that only focus on the discrepant-specific patterns (\eg, noises, textures, and frequencies), our method has a greater generalization. Specifically, we first propose a Discrepancy-Guided Encoder (DisGE) to extract forgery-sensitive visual patterns. DisGE consists of two branches, where the mainstream backbone branch is used to extract general semantic features, and the accessorial discrepant external attention branch is used to extract explicit forgery cues. Besides, a Double-Head Reconstruction (DouHR) module is proposed to enhance genuine compact visual patterns in different granular spaces. Under DouHR, we further introduce a Discrepancy-Aggregation Detector (DisAD) to aggregate these genuine compact visual patterns, such that the forgery detection capability on unknown patterns can
    
[^78]: 可控的信任权衡下的合成数据审计与生成

    Auditing and Generating Synthetic Data with Controllable Trust Trade-offs. (arXiv:2304.10819v1 [cs.LG])

    [http://arxiv.org/abs/2304.10819](http://arxiv.org/abs/2304.10819)

    本论文提出了一个审计框架，能够以全面的方式评估合成数据和AI模型的具体效果，包括偏见和歧视预防、对真实数据的忠实程度、效用、鲁棒性和隐私保护。在多个用例中，审计框架平衡了信任和效用之间的权衡。

    

    现实中收集的数据往往存在偏差、不平衡，并且有泄露敏感和隐私信息的风险。这一事实引发了创建合成数据集的想法，以减轻真实数据中固有的风险、偏见、伤害和隐私问题。这个概念依赖于生成AI模型，以产生不偏执、保护隐私的合成数据，同时忠实于真实数据。在这种新范式中，我们如何知道这种方法是否兑现了其承诺？我们提出了一个审计框架，提供了对合成数据集和基于它们训练的AI模型的全面评估，围绕偏见和歧视的预防、对真实数据的忠实程度、效用、鲁棒性和隐私保护。我们通过审计多个生成模型在不同用例中展示了我们的框架，包括教育、医疗保健、银行、人力资源，以及从表格，时间序列到自然语言的不同模态。我们的用例展示了在合成数据生成中平衡信任和效用的权衡的重要性。

    Data collected from the real world tends to be biased, unbalanced, and at risk of exposing sensitive and private information. This reality has given rise to the idea of creating synthetic datasets to alleviate risk, bias, harm, and privacy concerns inherent in the real data. This concept relies on Generative AI models to produce unbiased, privacy-preserving synthetic data while being true to the real data. In this new paradigm, how can we tell if this approach delivers on its promises? We present an auditing framework that offers a holistic assessment of synthetic datasets and AI models trained on them, centered around bias and discrimination prevention, fidelity to the real data, utility, robustness, and privacy preservation. We showcase our framework by auditing multiple generative models on diverse use cases, including education, healthcare, banking, human resources, and across different modalities, from tabular, to time-series, to natural language. Our use cases demonstrate the imp
    
[^79]: GREAT分数：使用生成模型对对抗性扰动进行全局鲁棒性评估

    GREAT Score: Global Robustness Evaluation of Adversarial Perturbation using Generative Models. (arXiv:2304.09875v1 [cs.LG])

    [http://arxiv.org/abs/2304.09875](http://arxiv.org/abs/2304.09875)

    本文提出了一个新的框架——GREAT分数，用于使用生成模型对对抗性扰动进行全局鲁棒性评估。该分数捕捉了所有样本中的平均认证防攻击扰动水平，无需运行对抗性攻击。

    

    目前对于对抗性鲁棒性的研究主要集中在聚合一组数据样本的局部鲁棒性结果上，以评估和排名不同的模型。然而，局部统计量可能无法很好地代表基础未知数据分布的真正全局鲁棒性。为了解决这一挑战，本文首次尝试提出了一个新的框架——GREAT分数，用于使用生成模型对对抗性扰动进行全局鲁棒性评估。GREAT分数正式具有一个全局统计量的物理意义，捕捉来自生成模型的所有样本中的平均认证防攻击扰动水平。对于有限样本评估，我们还推导出样本复杂度和样本均值与真实均值之间的概率保证。GREAT分数有几个优点：（1）使用GREAT分数进行鲁棒性评估高效而且规模可扩展，无需运行对抗性攻击。

    Current studies on adversarial robustness mainly focus on aggregating local robustness results from a set of data samples to evaluate and rank different models. However, the local statistics may not well represent the true global robustness of the underlying unknown data distribution. To address this challenge, this paper makes the first attempt to present a new framework, called GREAT Score , for global robustness evaluation of adversarial perturbation using generative models. Formally, GREAT Score carries the physical meaning of a global statistic capturing a mean certified attack-proof perturbation level over all samples drawn from a generative model. For finite-sample evaluation, we also derive a probabilistic guarantee on the sample complexity and the difference between the sample mean and the true mean. GREAT Score has several advantages: (1) Robustness evaluations using GREAT Score are efficient and scalable to large models, by sparing the need of running adversarial attacks. In
    
[^80]: 行程规划中的群体效用优化：一种策略性和众包意识方法

    Optimizing Group Utility in Itinerary Planning: A Strategic and Crowd-Aware Approach. (arXiv:2304.08495v1 [cs.AI])

    [http://arxiv.org/abs/2304.08495](http://arxiv.org/abs/2304.08495)

    本论文介绍了一种名为SCAIR的算法，可以优化群体效用，解决行程规划中的多个用户排队时间和人群水平优化的问题。

    

    行程推荐是一个具有许多实际应用的复杂的序列预测问题。当考虑到优化多个用户排队时间和人群水平时，这项任务变得更具挑战性，因为涉及到诸多参数，如景点受欢迎程度、排队时间、步行时间和营业时间等。现有的解决方案通常集中在单人视角上，未能解决自然人群行为引起的现实问题，如贪婪路由问题。本文介绍了一种名为“战略和众包意识行程推荐（SCAIR）”算法，该算法在现实环境中优化群体效用。我们将路线推荐策略建模为马尔可夫决策过程，并提出了一种状态编码机制，使得可以在线性时间内实现实时规划和分配。我们使用主题公园数据集对我们的算法进行各种竞争性和现实的基线测试，证明SCAIR优于其他算法。

    Itinerary recommendation is a complex sequence prediction problem with numerous real-world applications. This task becomes even more challenging when considering the optimization of multiple user queuing times and crowd levels, as well as numerous involved parameters, such as attraction popularity, queuing time, walking time, and operating hours. Existing solutions typically focus on single-person perspectives and fail to address real-world issues resulting from natural crowd behavior, like the Selfish Routing problem. In this paper, we introduce the Strategic and Crowd-Aware Itinerary Recommendation (SCAIR) algorithm, which optimizes group utility in real-world settings. We model the route recommendation strategy as a Markov Decision Process and propose a State Encoding mechanism that enables real-time planning and allocation in linear time. We evaluate our algorithm against various competitive and realistic baselines using a theme park dataset, demonstrating that SCAIR outperforms th
    
[^81]: 基于ChatGPT的放射学报告摘要生成的迭代优化框架：ImpressionGPT

    ImpressionGPT: An Iterative Optimizing Framework for Radiology Report Summarization with ChatGPT. (arXiv:2304.08448v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2304.08448](http://arxiv.org/abs/2304.08448)

    ImpressionGPT是一个利用LLMs构建动态上下文的迭代优化框架，用于放射学报告摘要生成。相对于其他方法，ImpressionGPT在具有较好泛化性能的同时，成功提高了放射学报告摘要的生成能力。

    

    放射学报告中的"Impression"部分是放射科医师和其他医生交流的重要基础，通常是基于"Findings"部分编写的。然而，对于放射科医师来说，编写大量的印象描述可能是费时费力且容易出错的。尽管最近的研究使用大规模医学文本数据进行预训练和微调预训练语言模型，实现了自动印象生成的有希望的结果。但这些模型通常需要大量的医学文本数据，并且具有较差的泛化性能。虽然像ChatGPT这样的大型语言模型表现出强大的泛化能力和性能，但它们在特定领域（如放射学）中的表现仍然未经调查，可能受到限制。为了解决这个问题，我们提出了ImpressionGPT，利用LLM的上下文学习能力，通过使用领域特定的个性化数据构建动态上下文，提高了放射学报告摘要的生成能力。

    The 'Impression' section of a radiology report is a critical basis for communication between radiologists and other physicians, and it is typically written by radiologists based on the 'Findings' section. However, writing numerous impressions can be laborious and error-prone for radiologists. Although recent studies have achieved promising results in automatic impression generation using large-scale medical text data for pre-training and fine-tuning pre-trained language models, such models often require substantial amounts of medical text data and have poor generalization performance. While large language models (LLMs) like ChatGPT have shown strong generalization capabilities and performance, their performance in specific domains, such as radiology, remains under-investigated and potentially limited. To address this limitation, we propose ImpressionGPT, which leverages the in-context learning capability of LLMs by constructing dynamic contexts using domain-specific, individualized dat
    
[^82]: 多模态图像文本匹配优化基于检索的胸部 X 射线报告生成

    Multimodal Image-Text Matching Improves Retrieval-based Chest X-Ray Report Generation. (arXiv:2303.17579v1 [cs.CL])

    [http://arxiv.org/abs/2303.17579](http://arxiv.org/abs/2303.17579)

    本研究提出了一种基于检索的放射性医学报告生成模块 X-REM，它使用图像文本匹配分数来衡量胸部 X 光图像和放射学报告之间的相似度，以进行报告检索，其在多个先前的放射学报告生成模块中表现优异，可有效提高放射学报告的自动生成精度。

    

    自动化生成临床准确的放射学报告可以改善患者护理。以前依赖图像字幕模型的报告生成方法由于缺乏相关领域知识而经常生成不连贯和不正确的文本，而基于检索的尝试经常检索到与输入图像不相关的报告。在这项工作中，我们提出了一种名为 Contrastive X-Ray REport Match（X-REM）的新型基于检索的放射性医学报告生成模块，该模块使用图像文本匹配分数来衡量胸部 X 光图像和放射学报告之间的相似度以进行报告检索。我们观察到，使用语言图像模型计算图像文本匹配分数可以有效地捕捉到在使用余弦相似性时经常丢失的图像和文本之间的细粒度交互。在自然语言和临床度量方面，X-REM在多个先前的放射学报告生成模块中表现优异。通过对生成的报告进行人类评估，表明 X-R...

    Automated generation of clinically accurate radiology reports can improve patient care. Previous report generation methods that rely on image captioning models often generate incoherent and incorrect text due to their lack of relevant domain knowledge, while retrieval-based attempts frequently retrieve reports that are irrelevant to the input image. In this work, we propose Contrastive X-Ray REport Match (X-REM), a novel retrieval-based radiology report generation module that uses an image-text matching score to measure the similarity of a chest X-ray image and radiology report for report retrieval. We observe that computing the image-text matching score with a language-image model can effectively capture the fine-grained interaction between image and text that is often lost when using cosine similarity. X-REM outperforms multiple prior radiology report generation modules in terms of both natural language and clinical metrics. Human evaluation of the generated reports suggests that X-R
    
[^83]: 一种通用智能的范畴框架

    A Categorical Framework of General Intelligence. (arXiv:2303.04571v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2303.04571](http://arxiv.org/abs/2303.04571)

    本文介绍了一个通用智能的范畴框架，涉及对象和场景的表示及模拟，并提出了相应的算法和不变性属性，可以用于解决AI的可解释性和安全问题。

    

    自从Alan Turing在1950年提出“机器是否可以思考”的问题以来，由于缺少扎实的通用智能数学基础，至今难以给出直接答案。本文介绍了一个通往这一目标的范畴框架，得到了两个主要结果。首先，我们通过预层次研究对象表示，引入了自我状态感知的概念作为类别对应自我意识的模拟，并提出了相应的强制执行和评估算法。其次，我们将对象表示扩展到场景表示，使用图表和界限，这些成为了数学建模、可解释性和AI安全的构建块。作为一个附带的结果，我们的框架引入了各种范畴不变性属性，可以用作模型训练的对准信号。

    Can machines think? Since Alan Turing asked this question in 1950, nobody is able to give a direct answer, due to the lack of solid mathematical foundations for general intelligence. In this paper, we introduce a categorical framework towards this goal, with two main results. First, we investigate object representation through presheaves, introducing the notion of self-state awareness as a categorical analogue to self-consciousness, along with corresponding algorithms for its enforcement and evaluation. Secondly, we extend object representation to scenario representation using diagrams and limits, which then become building blocks for mathematical modeling, interpretability and AI safety. As an ancillary result, our framework introduces various categorical invariance properties that can serve as the alignment signals for model training.
    
[^84]: 从教学视频文本转录中无监督生成任务图

    Unsupervised Task Graph Generation from Instructional Video Transcripts. (arXiv:2302.09173v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2302.09173](http://arxiv.org/abs/2302.09173)

    本文提出了一种无监督的任务图生成方法，通过结合支持指导的语言模型的推理能力和聚类、排序组件，从执行真实世界活动的教学视频文本记录中生成任务图。实验结果表明该方法在ProceL和CrossTask数据集上比监督学习方法生成的任务图更加准确。

    

    本研究探讨了生成真实世界活动任务图的问题。与以往的方法不同，我们考虑提供执行真实世界活动（如制作咖啡）的教学视频文本记录，并旨在确定与任务相关的关键步骤及其依赖关系。我们提出了一种新颖的任务图生成方法，该方法结合了面向指导的语言模型的推理能力以及聚类和排序组件，在完全无监督的情况下生成准确的任务图。我们展示了该方法在ProceL和CrossTask数据集上生成的任务图比监督学习方法更加准确。

    This work explores the problem of generating task graphs of real-world activities. Different from prior formulations, we consider a setting where text transcripts of instructional videos performing a real-world activity (e.g., making coffee) are provided and the goal is to identify the key steps relevant to the task as well as the dependency relationship between these key steps. We propose a novel task graph generation approach that combines the reasoning capabilities of instruction-tuned language models along with clustering and ranking components to generate accurate task graphs in a completely unsupervised manner. We show that the proposed approach generates more accurate task graphs compared to a supervised learning approach on tasks from the ProceL and CrossTask datasets.
    
[^85]: DocILE基准数据集用于文件信息定位和提取

    DocILE Benchmark for Document Information Localization and Extraction. (arXiv:2302.05658v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.05658](http://arxiv.org/abs/2302.05658)

    本文介绍了DocILE基准数据集，该数据集包含大量商务文件，可用于关键信息定位和提取以及行项目识别任务。该数据集具有55个类别的注释，超过以往发布的数据集，同时包括众多不同布局和未标记的文档，为该领域提供了有力的研究工具。

    

    本文介绍了DocILE基准数据集，用于关键信息定位和提取以及行项目识别任务的商务文件的最大数据集。 它包含6.7k个带注释的商务文件，100k个合成生成的文档以及近1M个未标记的文档，用于无监督的预训练。 该数据集具有特定于领域和任务的知识，具有以下关键特征：（i）在55个类别中注释，其粒度远远超过以前发布的关键信息提取数据集; （ii）行项目识别表示一项极具实用性的信息提取任务，在表格中必须将关键信息分配给项目; （iii）文档来自众多布局，测试集包括零-shot和少-shot案例以及训练集中常见的布局。基准数据集配有多个基线，包括RoBERTa、 LayoutLMv3和基于DETR的表格Transformer；

    This paper introduces the DocILE benchmark with the largest dataset of business documents for the tasks of Key Information Localization and Extraction and Line Item Recognition. It contains 6.7k annotated business documents, 100k synthetically generated documents, and nearly~1M unlabeled documents for unsupervised pre-training. The dataset has been built with knowledge of domainand task-specific aspects, resulting in the following key features: (i) annotations in 55 classes, which surpasses the granularity of previously published key information extraction datasets by a large margin; (ii) Line Item Recognition represents a highly practical information extraction task, where key information has to be assigned to items in a table; (iii) documents come from numerous layouts and the test set includes zero- and few-shot cases as well as layouts commonly seen in the training set. The benchmark comes with several baselines, including RoBERTa, LayoutLMv3 and DETR-based Table Transformer; app
    
[^86]: APAM：自适应预训练和自适应元学习在语言模型中用于处理噪声标签和长尾学习

    APAM: Adaptive Pre-training and Adaptive Meta Learning in Language Model for Noisy Labels and Long-tailed Learning. (arXiv:2302.03488v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.03488](http://arxiv.org/abs/2302.03488)

    本文提出了APAM框架，通过整合自适应预训练和元学习的方法，成功解决了长尾和噪声标签带来的挑战，实验证明该方法的效果优于现有最新方法。

    

    实际的自然语言处理 (NLP) 任务通常具有噪声标签和长尾分布的特点，这些问题会挑战复杂模型（如深度神经网络）的泛化和鲁棒性。常用的重抽样技术（如过采样或欠采样）容易导致过拟合。借助少量元数据学习数据权重正变得越来越流行。此外，最近的研究表明，自监督预训练对于弱表示数据的优点愈发明显。本文提出了一个通用的框架来处理长尾和噪声标签问题。该模型采用对比学习的方式适应问题域，并采用一种前馈神经网络的重新加权模块，该模块可以学习显式加权函数并根据元数据进行适应。我们在损失函数的项权重上进一步采用了交叉熵损失的多项式扩展和重点正则化的组合。此外，我们还将自适应元学习方法整合到预训练阶段中，以从弱表示类中学习更具可传递性的表示。实验表明，我们的方法在各种长尾和噪音标签分类任务中优于现有的最新方法。

    Practical natural language processing (NLP) tasks are commonly long-tailed with noisy labels. Those problems challenge the generalization and robustness of complex models such as Deep Neural Networks (DNNs). Some commonly used resampling techniques, such as oversampling or undersampling, could easily lead to overfitting. It is growing popular to learn the data weights leveraging a small amount of metadata. Besides, recent studies have shown the advantages of self-supervised pre-training, particularly to the under-represented data. In this work, we propose a general framework to handle the problem of both long-tail and noisy labels. The model is adapted to the domain of problems in a contrastive learning manner. The re-weighting module is a feed-forward network that learns explicit weighting functions and adapts weights according to metadata. The framework further adapts weights of terms in the loss function through a combination of the polynomial expansion of cross-entropy loss and foc
    
[^87]: 概率对比学习恢复了不确定性输入的正确估计

    Probabilistic Contrastive Learning Recovers the Correct Aleatoric Uncertainty of Ambiguous Inputs. (arXiv:2302.02865v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.02865](http://arxiv.org/abs/2302.02865)

    本文提出利用概率对比学习方法可以恢复具有不确定性输入的正确估计，通过扩展InfoNCE目标和编码器以预测潜变量分布来实现，在计算已知查询图像的可信区间方面具有应用价值。

    

    最近，对比学习编码器被证明可以翻转数据生成过程：它们可以将每个输入（如图像）编码成生成该图像的真实潜变量（Zimmermann等人，2021）。然而，现实世界的观察结果通常存在内在的模糊性。例如，图像可能模糊或只显示3D物体的2D视图，因此可能有多个潜变量生成它们。这使得潜变量的真实后验概率具有异方差不确定性。在这种设置下，我们扩展了常见的InfoNCE目标和编码器，以预测潜变量分布而不是点。我们证明这些分布恢复了数据生成过程的正确后验分布，包括其不确定性水平的估计，该估计存在潜变量空间的旋转。除了提供校准的不确定性估计之外，这些后验分布还允许在图像检索中计算可信区间。它们包括具有与给定查询相同的潜变量的图像。

    Contrastively trained encoders have recently been proven to invert the data-generating process: they encode each input, e.g., an image, into the true latent vector that generated the image (Zimmermann et al., 2021). However, real-world observations often have inherent ambiguities. For instance, images may be blurred or only show a 2D view of a 3D object, so multiple latents could have generated them. This makes the true posterior for the latent vector probabilistic with heteroscedastic uncertainty. In this setup, we extend the common InfoNCE objective and encoders to predict latent distributions instead of points. We prove that these distributions recover the correct posteriors of the data-generating process, including its level of aleatoric uncertainty, up to a rotation of the latent space. In addition to providing calibrated uncertainty estimates, these posteriors allow the computation of credible intervals in image retrieval. They comprise images with the same latent as a given quer
    
[^88]: 基于深度强化学习的网络物理系统在线错误检测

    Deep Reinforcement Learning for Online Error Detection in Cyber-Physical Systems. (arXiv:2302.01567v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.01567](http://arxiv.org/abs/2302.01567)

    本文提出了一种基于深度强化学习（DRL）的新型在线错误检测方法。

    

    可靠性是网络物理系统中主要的设计标准之一。这是由于CPS中存在一些关键应用程序，它们的失效是灾难性的。因此，在CPS中使用强大的错误检测和纠正机制是不可避免的。传统的容错方法包括冗余时间、硬件、信息和/或软件。然而，这些方法除了低错误覆盖率外，还会带来极大的开销，限制了它们的适用性。本文提出了一种基于深度强化学习（DRL）的新型错误检测方法。

    Reliability is one of the major design criteria in Cyber-Physical Systems (CPSs). This is because of the existence of some critical applications in CPSs and their failure is catastrophic. Therefore, employing strong error detection and correction mechanisms in CPSs is inevitable. CPSs are composed of a variety of units, including sensors, networks, and microcontrollers. Each of these units is probable to be in a faulty state at any time and the occurred fault can result in erroneous output. The fault may cause the units of CPS to malfunction and eventually crash. Traditional fault-tolerant approaches include redundancy time, hardware, information, and/or software. However, these approaches impose significant overheads besides their low error coverage, which limits their applicability. In addition, the interval between error occurrence and detection is too long in these approaches. In this paper, based on Deep Reinforcement Learning (DRL), a new error detection approach is proposed that
    
[^89]: 基于时间注意机制的中期风电功率预测新框架

    A novel framework for medium-term wind power prediction based on temporal attention mechanisms. (arXiv:2302.01222v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.01222](http://arxiv.org/abs/2302.01222)

    本文提出了一种基于树状Parzen估计器（TPE）和分解算法的新框架（TPE-VMD-TFT），用于24小时和48小时之前的风电功率预测。在法国电力公司Engie的风能数据集上，所提出的方法表现良好。

    

    风能是一种广泛分布、可再生和环保的能源，对缓解全球变暖和能源短缺具有重要作用。然而，由于其不确定性和波动性，大规模风电系统的网格集成具有挑战性。中期风电功率预测可以为能量调度提供基本依据，因此精确的风电功率预测至关重要。本文提出了一种基于树状Parzen估计器（TPE）和分解算法的新框架。该框架基于变分模式分解（VMD）和时间融合变压器（TFT）定义了24小时和48小时之前的风电功率预测的TPE-VMD-TFT方法。在法国电力公司Engie的风能数据集上，结果表明所提出的方法优于其他方法。

    Wind energy is a widely distributed, recyclable and environmentally friendly energy source that plays an important role in mitigating global warming and energy shortages. Wind energy's uncertainty and fluctuating nature makes grid integration of large-scale wind energy systems challenging. Medium-term wind power forecasts can provide an essential basis for energy dispatch, so accurate wind power forecasts are essential. Much research has yielded excellent results in recent years. However, many of them require additional experimentation and analysis when applied to other data. In this paper, we propose a novel short-term forecasting framework by tree-structured parzen estimator (TPE) and decomposition algorithms. This framework defines the TPE-VMD-TFT method for 24-h and 48-h ahead wind power forecasting based on variational mode decomposition (VMD) and time fusion transformer (TFT). In the Engie wind dataset from the electricity company in France, the results show that the proposed met
    
[^90]: 手术聚合：一种用于协同学习的分布式医学影像数据和多样任务协调框架

    Surgical Aggregation: A Collaborative Learning Framework for Harmonizing Distributed Medical Imaging Datasets with Diverse Tasks. (arXiv:2301.06683v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2301.06683](http://arxiv.org/abs/2301.06683)

    本论文提出了一种手术聚合的协同学习框架，该框架可用于协调和聚合分布式医学影像数据集的知识，并带有部分疾病注释，从而可训练具有完整胸部内可能出现的所有异常的临床实用、强大模型。

    

    大规模的胸部X光数据集已经通过深度学习进行异常检测，并有潜力为许多临床应用提供巨大的益处。然而，每个数据集仅专注于检测患者可能同时出现的一部分发现，从而限制了其临床效用。因此，数据协调对于聚合这些数据集来训练具有完整胸部内可能出现的所有异常的临床实用、强大模型至关重要。为此，我们提出了手术聚合，一种协同学习框架，用于协调和聚合分布式异构数据集的知识，并带有部分疾病注释。我们在合成的iid数据集和具有部分注释的真实大规模非iid数据集上评估了手术聚合。我们的结果表明，手术聚合显著优于当前的策略，具有更好的通用性。

    Large-scale chest x-ray datasets have been curated for the detection of abnormalities using deep learning, with the potential to provide substantial benefits across many clinical applications. However, each dataset focuses only on detecting a subset of findings that can be simultaneously present in a patient, thereby limiting its clinical utility. Therefore, data harmonization is crucial to leverage these datasets in aggregate to train clinically-useful, robust models with a complete representation of all abnormalities that may occur within the thorax. To that end, we propose surgical aggregation, a collaborative learning framework for harmonizing and aggregating knowledge from distributed heterogeneous datasets with partial disease annotations. We evaluate surgical aggregation across synthetic iid datasets and real-world large-scale non-iid datasets with partial annotations. Our results indicate that surgical aggregation significantly outperforms current strategies, has better general
    
[^91]: 自适应上下文学习：基于信息压缩视角的上下文示例选取和排序方法

    Self-Adaptive In-Context Learning: An Information Compression Perspective for In-Context Example Selection and Ordering. (arXiv:2212.10375v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10375](http://arxiv.org/abs/2212.10375)

    这篇论文提出了自适应上下文学习的原则，通过引入自适应机制帮助每个样本找到正确的上下文示例排列，从而最大化表现。通过广泛的评估，在8个不同的NLP数据集上，自适应ICL方法相对于常规设置提高了40%的相对改进。

    

    尽管在上下文学习 (ICL) 中具有惊人的少样本表现，但仍然普遍采用随机选取样本作为上下文的做法。本文提出了一种新的ICL原则：自适应上下文学习。引入自适应机制来帮助每个样本找到一个能够得到正确预测的上下文示例排列（即选取和排序），从而最大化表现。为了验证自适应ICL的有效性，我们提出了一个通用的选择-排序框架，并将其用新的选择和排序算法实例化。在八个不同的NLP数据集上进行了广泛的评估，我们的自适应ICL方法相对于常规设置提高了40%的相对改进。进一步分析揭示了自适应ICL的巨大潜力，即可能通过更先进的算法来缩小ICL和微调之间的差距。我们发布代码，以促进未来在该领域的研究：https://github.com/jxlr/SAICL_iclr22。

    Despite the surprising few-shot performance of in-context learning (ICL), it is still a common practice to randomly sample examples to serve as context. This paper advocates a new principle for ICL: self-adaptive in-context learning. The self-adaption mechanism is introduced to help each sample find an in-context example permutation (i.e., selection and ordering) that can derive the correct prediction, thus maximizing performance. To validate the effectiveness of self-adaptive ICL, we propose a general select-then-rank framework and instantiate it with new selection and ranking algorithms. Upon extensive evaluation on eight different NLP datasets, our self-adaptive ICL method achieves a 40% relative improvement over the common practice setting. Further analysis reveals the enormous potential of self-adaptive ICL that it might be able to close the gap between ICL and finetuning given more advanced algorithms. Our code is released to facilitate future research in this area: https://githu
    
[^92]: 不生成，辨别：一种将语言模型与现实世界环境接轨的方案

    Don't Generate, Discriminate: A Proposal for Grounding Language Models to Real-World Environments. (arXiv:2212.09736v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09736](http://arxiv.org/abs/2212.09736)

    Pangu是一个泛用的框架，用于实现语言模型与现实环境的接轨，它利用语言模型的辨别能力而非生成能力，由一个符号代理和一个神经语言模型协同工作。这一方案已经在知识库问答问题中证明了它的有效性和灵活性。

    

    目前语言模型最缺失的就是现实世界环境的接轨性。已有的相关工作将语言模型用于直接生成计划，以便在环境中执行以达到预期的效果，这使得语言模型负担了确保语法正确性、忠实性和可控性的重担。本文提出了一个泛用的框架Pangu，用于实现语言模型与现实环境的接轨，该框架利用语言模型的辨别能力而非生成能力，由一个符号代理和一个神经语言模型协同工作：代理在环境中探索以逐步构建有效的计划，而语言模型评估备选计划的合理性以引导搜索过程。针对知识库问答（KBQA）这一具有挑战性的问题进行了案例研究，该问题具有庞大的环境，结果表明了Pangu的显著有效性和灵活性：BERT基语言模型已足够应对。

    A key missing capacity of current language models (LMs) is grounding to real-world environments. Most existing work for grounded language understanding uses LMs to directly generate plans that can be executed in the environment to achieve the desired effects. It thereby casts the burden of ensuring grammaticality, faithfulness, and controllability all on the LMs. We propose Pangu, a generic framework for grounded language understanding that capitalizes on the discriminative ability of LMs instead of their generative ability. Pangu consists of a symbolic agent and a neural LM working in a concerted fashion: The agent explores the environment to incrementally construct valid plans, and the LM evaluates the plausibility of the candidate plans to guide the search process. A case study on the challenging problem of knowledge base question answering (KBQA), which features a massive environment, demonstrates the remarkable effectiveness and flexibility of Pangu: A BERT-base LM is sufficient f
    
[^93]: 混合置信度POMDP中的蒙特卡罗规划

    Monte Carlo Planning in Hybrid Belief POMDPs. (arXiv:2211.07735v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2211.07735](http://arxiv.org/abs/2211.07735)

    本文提出了HB-MCP算法，利用蒙特卡罗树搜索算法解决POMDP问题，并保持混合置信度。该算法优于不支持混合置信度的最先进在线求解器，并且在更大的计划范围内具有可扩展性和鲁棒性。

    

    现实问题需要同时对离散和连续随机变量进行混合信念的推理，但在规划的背景下，这种情况几乎没有被研究。此外，现有的在线部分可观察马尔可夫决策过程（POMDP）求解器不直接支持混合信念。作为本项工作的一部分，我们提出了一种新的算法，混合置信度蒙特卡罗规划（HB-MCP），该算法利用蒙特卡罗树搜索（MCTS）算法来解决POMDP，并保持混合置信度。我们演示了如何利用上置信度（UCB）探索奖励来指导假设树和信念树的增长。然后，在未解决数据关联导致多模态信念假设的高度模糊的模拟环境中评估了我们的方法。我们的结果显示，HB-MCP优于不支持混合信念的最先进的在线求解器。此外，我们证明了我们的算法可扩展到更大的计划范围，并且对不同的初始置信度配置具有鲁棒性。

    Real-world problems often require reasoning about hybrid beliefs, over both discrete and continuous random variables. Yet, such a setting has hardly been investigated in the context of planning. Moreover, existing online Partially Observable Markov Decision Processes (POMDPs) solvers do not support hybrid beliefs directly. In particular, these solvers do not address the added computational burden due to an increasing number of hypotheses with the planning horizon, which can grow exponentially. As part of this work, we present a novel algorithm, Hybrid Belief Monte Carlo Planning (HB-MCP) that utilizes the Monte Carlo Tree Search (MCTS) algorithm to solve a POMDP while maintaining a hybrid belief. We illustrate how the upper confidence bound (UCB) exploration bonus can be leveraged to guide the growth of hypotheses trees alongside the belief trees. We then evaluate our approach in highly aliased simulated environments where unresolved data association leads to multi-modal belief hypothe
    
[^94]: 基于跨模态神经模型重新编程的低资源音乐风格分类

    Low-Resource Music Genre Classification with Cross-Modal Neural Model Reprogramming. (arXiv:2211.01317v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2211.01317](http://arxiv.org/abs/2211.01317)

    本文提出了一种基于神经模型重新编程的迁移学习方法，并针对复杂输入数据提出了输入依赖NMR范式，能够有效地进行音乐风格分类。

    

    迁移学习方法在处理训练数据有限的任务时展现出了很好的效果。然而，微调预训练的神经网络来处理目标领域数据通常需要大量的内存和计算资源。本文提出了一种基于神经模型重新编程 (NMR) 的新方法，用于利用预训练模型进行低资源音乐分类。NMR旨在通过修改冻结的预训练模型的输入，将预训练模型从源域重新调整用于目标域。除了已知的与输入无关的重新编程方法外，我们还提出了一种先进的重新编程范式：输入依赖NMR，以增加对复杂输入数据（如音频）的适应性。实验结果表明，使用这种重新编程方法，基于大规模数据集预训练的神经模型成功地进行音乐风格分类。所提出的两种输入相关的NMR迁移学习方法表现优于传统的迁移学习方法。

    Transfer learning (TL) approaches have shown promising results when handling tasks with limited training data. However, considerable memory and computational resources are often required for fine-tuning pre-trained neural networks with target domain data. In this work, we introduce a novel method for leveraging pre-trained models for low-resource (music) classification based on the concept of Neural Model Reprogramming (NMR). NMR aims at re-purposing a pre-trained model from a source domain to a target domain by modifying the input of a frozen pre-trained model. In addition to the known, input-independent, reprogramming method, we propose an advanced reprogramming paradigm: Input-dependent NMR, to increase adaptability to complex input data such as musical audio. Experimental results suggest that a neural model pre-trained on large-scale datasets can successfully perform music genre classification by using this reprogramming method. The two proposed Input-dependent NMR TL methods outpe
    
[^95]: 用贝叶斯优化发现多样的解决方案

    Discovering Many Diverse Solutions with Bayesian Optimization. (arXiv:2210.10953v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.10953](http://arxiv.org/abs/2210.10953)

    ROBOT是一种新的贝叶斯优化方法，可以找到一组高性能、多样化的解决方案，解决了传统单目标贝叶斯优化方法只能找到一个最佳解决方案的局限性。

    ROBOT is a new Bayesian optimization method that can find a portfolio of high-performing diverse solutions, addressing the limitation of traditional single-objective Bayesian optimization methods that only seek to find a single best solution.

    贝叶斯优化是一种用于黑盒目标函数的高效优化的流行方法。传统的单目标贝叶斯优化方法只寻求找到一个最佳解决方案，这在解决方案后期可能变得棘手的情况下会有很大的局限性。为了解决这个问题，我们提出了一种名为ROBOT的排序贝叶斯优化方法，旨在找到一组高性能、多样化的解决方案，这些解决方案根据用户指定的多样性度量进行排序。我们在几个真实世界的应用中评估了ROBOT，并展示了它可以发现大量高性能的多样化解决方案，同时与寻找单个最佳解决方案相比，需要很少的额外函数评估。

    Bayesian optimization (BO) is a popular approach for sample-efficient optimization of black-box objective functions. While BO has been successfully applied to a wide range of scientific applications, traditional approaches to single-objective BO only seek to find a single best solution. This can be a significant limitation in situations where solutions may later turn out to be intractable. For example, a designed molecule may turn out to violate constraints that can only be reasonably evaluated after the optimization process has concluded. To address this issue, we propose Rank-Ordered Bayesian Optimization with Trust-regions (ROBOT) which aims to find a portfolio of high-performing solutions that are diverse according to a user-specified diversity metric. We evaluate ROBOT on several real-world applications and show that it can discover large sets of high-performing diverse solutions while requiring few additional function evaluations compared to finding a single best solution.
    
[^96]: 通过解析策略梯度训练高效控制器

    Training Efficient Controllers via Analytic Policy Gradient. (arXiv:2209.13052v3 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2209.13052](http://arxiv.org/abs/2209.13052)

    本文提出了一种名为“解析策略梯度（APG）”的离线学习控制器方法，在跟踪误差上使用梯度下降算法，通过可微分仿真器离线训练控制器。该方法可在算力有限的系统上实现高效，精确的控制。

    

    机器人系统的控制设计很复杂，通常需要解决一个优化问题以准确地跟踪轨迹。虽然在线优化方法如模型预测控制（MPC）已经证明可以实现很好的跟踪性能，但需要高算力。相反，基于学习的离线优化方法，如强化学习（RL），允许机器人快速，高效地执行，但在轨迹跟踪任务中很难与MPC的准确性相匹配。对于算力有限的系统（如空中飞行器），高效的控制器的准确性至关重要。我们提出了一种解析策略梯度（APG）方法来解决这个问题。APG利用可微分仿真器的可用性，通过在跟踪误差上使用梯度下降算法离线训练控制器。我们通过课程学习来解决APG经常出现的训练不稳定性，并在广泛使用的控制基准测试CartPole上进行了实验。

    Control design for robotic systems is complex and often requires solving an optimization to follow a trajectory accurately. Online optimization approaches like Model Predictive Control (MPC) have been shown to achieve great tracking performance, but require high computing power. Conversely, learning-based offline optimization approaches, such as Reinforcement Learning (RL), allow fast and efficient execution on the robot but hardly match the accuracy of MPC in trajectory tracking tasks. In systems with limited compute, such as aerial vehicles, an accurate controller that is efficient at execution time is imperative. We propose an Analytic Policy Gradient (APG) method to tackle this problem. APG exploits the availability of differentiable simulators by training a controller offline with gradient descent on the tracking error. We address training instabilities that frequently occur with APG through curriculum learning and experiment on a widely used controls benchmark, the CartPole, and 
    
[^97]: 学习适用于不同大小无人机的单一近悬停位置控制器

    Learning a Single Near-hover Position Controller for Vastly Different Quadcopters. (arXiv:2209.09232v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2209.09232](http://arxiv.org/abs/2209.09232)

    本文介绍了一种适用于不同大小无人机的单一近悬停位置控制器，通过神经网络学习动态适应不同无人机参数和干扰，实现快速运行并成功适应外部干扰。

    

    本文提出了一种适应性近悬停位置控制器，可部署到质量、大小和电机常数非常不同的四轴飞行器上，而且在运行时也能快速适应未知干扰。其核心算法思想是学习一个单一策略，能够在测试时在线适应不仅应用于无人机的干扰，还能适应相同框架中的机器人动态和硬件。我们通过训练神经网络来估计机器人和环境参数的潜在表示，这将用于控制器的行为调节，同时也表示为神经网络。我们在模拟环境中仅对这两个网络进行培训，以飞行四轴飞行器到目标位置并避免撞到地面为目标。我们直接在现实世界中使用相同的控制器，在两个具有不同质量、大小、电机和螺旋桨推力比的四轴飞行器上进行了测试，结果表明我们的方法能够实现成功的近悬停性能并快速适应运动变化以及外部干扰。

    This paper proposes an adaptive near-hover position controller for quadcopters, which can be deployed to quadcopters of very different mass, size and motor constants, and also shows rapid adaptation to unknown disturbances during runtime. The core algorithmic idea is to learn a single policy that can adapt online at test time not only to the disturbances applied to the drone, but also to the robot dynamics and hardware in the same framework. We achieve this by training a neural network to estimate a latent representation of the robot and environment parameters, which is used to condition the behaviour of the controller, also represented as a neural network. We train both networks exclusively in simulation with the goal of flying the quadcopters to goal positions and avoiding crashes to the ground. We directly deploy the same controller trained in the simulation without any modifications on two quadcopters in the real world with differences in mass, size, motors, and propellers with mas
    
[^98]: ImGCL：重访图形对比学习在不平衡节点分类中的应用

    ImGCL: Revisiting Graph Contrastive Learning on Imbalanced Node Classification. (arXiv:2205.11332v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.11332](http://arxiv.org/abs/2205.11332)

    本文提出了一种名为"ImGCL"的图形对比学习（GCL）算法框架，该框架能够自动自适应地平衡不平衡节点分类问题中从无标签节点（图）中学到的表示，通过整合在线聚类和逐步平衡采样方法，我们的算法可以有效地学习区分表示，实现与先进技术相当的性能。

    

    图形对比学习（GCL）由于其在无标签节点/图形表示学习方面的超凡性能而受到了极大关注。 然而，在实践中，给定图形的未标记节点的潜在类别分布通常是不平衡的。这种高度不平衡的分类分布不可避免地降低了GCL中学习到的节点表示的质量。 实际上，我们在实验中发现，大多数最先进的GCL方法无法获得有区别的表示，并在不平衡节点分类中表现出差劲的性能。受此观察的启发，我们提出了一种基于不平衡节点分类的正式GCL框架（ImGCL），该框架可以自动和自适应地平衡从GCL中学到的表示，即使在高度不平衡的情况下也能够有效地学习区分表示，并实现与先进技术相当的性能。

    Graph contrastive learning (GCL) has attracted a surge of attention due to its superior performance for learning node/graph representations without labels. However, in practice, the underlying class distribution of unlabeled nodes for the given graph is usually imbalanced. This highly imbalanced class distribution inevitably deteriorates the quality of learned node representations in GCL. Indeed, we empirically find that most state-of-the-art GCL methods cannot obtain discriminative representations and exhibit poor performance on imbalanced node classification. Motivated by this observation, we propose a principled GCL framework on Imbalanced node classification (ImGCL), which automatically and adaptively balances the representations learned from GCL without labels. Specifically, we first introduce the online clustering based progressively balanced sampling (PBS) method with theoretical rationale, which balances the training sets based on pseudo-labels obtained from learned representat
    
[^99]: 通过少量查询实现梯度对齐攻击

    Gradient Aligned Attacks via a Few Queries. (arXiv:2205.09518v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2205.09518](http://arxiv.org/abs/2205.09518)

    该论文提出了一种梯度对齐攻击方法，通过设计梯度对齐损失在代理模型上估计准确梯度，提高在少量查询的情况下对深度学习模型的攻击效果。

    

    黑盒查询攻击已被证明在攻击深度学习模型方面很有效。然而，在只允许少量查询的新颖情况下，现有的黑盒查询攻击展现出很低的性能。为了解决这个问题，我们提出了梯度对齐攻击（GAA），使用梯度对齐损失（GAL）在代理模型上估计准确梯度，从而提高对受害模型的攻击效果。

    Black-box query attacks, which rely only on the output of the victim model, have proven to be effective in attacking deep learning models. However, existing black-box query attacks show low performance in a novel scenario where only a few queries are allowed. To address this issue, we propose gradient aligned attacks (GAA), which use the gradient aligned losses (GAL) we designed on the surrogate model to estimate the accurate gradient to improve the attack performance on the victim model. Specifically, we propose a gradient aligned mechanism to ensure that the derivatives of the loss function with respect to the logit vector have the same weight coefficients between the surrogate and victim models. Using this mechanism, we transform the cross-entropy (CE) loss and margin loss into gradient aligned forms, i.e. the gradient aligned CE or margin losses. These losses not only improve the attack performance of our gradient aligned attacks in the novel scenario but also increase the query ef
    
[^100]: 社交媒体中社会语用意义的对比学习

    Contrastive Learning of Sociopragmatic Meaning in Social Media. (arXiv:2203.07648v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2203.07648](http://arxiv.org/abs/2203.07648)

    提出了一种社交媒体中社会语用意义的对比学习框架，该框架能够学习可迁移的任务不可知表示学习，并在各种对比学习框架中表现最佳。

    

    最近自然语言处理中的表示学习和对比学习等研究进展尚未广泛考虑社会语用意义这一类别（即不同语言社区内的交流意义）。为了弥补这一空白，我们提出了一种新的框架，用于学习可迁移至各种社会语用任务（如情感、仇恨言论、幽默、讽刺）的任务不可知表示学习。我们的框架在领域内和领域外数据以及一般和少样本情况下的各种对比学习框架中表现最佳。例如，与两个流行的预训练语言模型相比，我们的方法在每个数据集仅用20个训练样本微调时，平均F1值在16个数据集上提高了11.66个百分点。

    Recent progress in representation and contrastive learning in NLP has not widely considered the class of \textit{sociopragmatic meaning} (i.e., meaning in interaction within different language communities). To bridge this gap, we propose a novel framework for learning task-agnostic representations transferable to a wide range of sociopragmatic tasks (e.g., emotion, hate speech, humor, sarcasm). Our framework outperforms other contrastive learning frameworks for both in-domain and out-of-domain data, across both the general and few-shot settings. For example, compared to two popular pre-trained language models, our method obtains an improvement of $11.66$ average $F_1$ on $16$ datasets when fine-tuned on only $20$ training samples per dataset.
    
[^101]: 高阶图形模型中图网络推断的一般化

    Generalization of graph network inferences in higher-order graphical models. (arXiv:2107.05729v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2107.05729](http://arxiv.org/abs/2107.05729)

    本论文提出了递归因子图神经网络(RF-GNN)，用于实现对涉及多变量相互作用的图形模型的快速近似推断。在多个图形模型家族的实验中展示了RF-GNN在表达性图形模型中快速且准确地执行推断的潜力。

    

    概率图模型提供了一种描述复杂统计结构的强大工具，具有从控制机器人手臂到理解神经计算等许多科学和工程实际应用。这些图形模型的主要挑战是，在一般图形条件下，如边际化等推断是不可行的。这些推断通常由分布式消息传递算法（例如信任传播）近似，但是它不总能在具有循环的图形上表现良好，并且不总能轻松指定复杂的连续概率分布。在具有不可计算高阶交互作用的表达性图形模型中，这些困难经常出现。在本文中，我们定义了递归因子图神经网络（RF-GNN），以实现对涉及多变量相互作用的图形模型的快速近似推断。在几个图形模型家族的实验结果证明了RF-GNN在训练数据集之外的分布下的一般化，展示了RF-GNN在表达性图形模型中快速且准确地执行推断的潜力。

    Probabilistic graphical models provide a powerful tool to describe complex statistical structure, with many real-world applications in science and engineering from controlling robotic arms to understanding neuronal computations. A major challenge for these graphical models is that inferences such as marginalization are intractable for general graphs. These inferences are often approximated by a distributed message-passing algorithm such as Belief Propagation, which does not always perform well on graphs with cycles, nor can it always be easily specified for complex continuous probability distributions. Such difficulties arise frequently in expressive graphical models that include intractable higher-order interactions. In this paper we define the Recurrent Factor Graph Neural Network (RF-GNN) to achieve fast approximate inference on graphical models that involve many-variable interactions. Experimental results on several families of graphical models demonstrate the out-of-distribution g
    
[^102]: Uni-Encoder: 一种用于生成型对话系统的快速准确响应选择范例

    Uni-Encoder: A Fast and Accurate Response Selection Paradigm for Generation-Based Dialogue Systems. (arXiv:2106.01263v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2106.01263](http://arxiv.org/abs/2106.01263)

    论文提出一种新的响应选择范例Uni-Encoder，解决了Cross-Encoder多次编码相同上下文计算成本高和Poly-Encoder性能下降的问题。该范例在一次前向传递中对所有候选与上下文进行编码。

    

    样本与排序是现代生成型对话系统的关键解码策略，通过从生成的少量候选答案中选择一个答案来实现多样化和高质量的响应。当前最先进的排序方法主要使用称为交叉编码器的编码范例，该编码器分别对每个上下文-候选对进行编码，并根据其适应度得分对候选进行排序。然而，交叉编码器为每个候选重复编码相同的冗长上下文，导致计算成本高。Poly-Encoder通过减少上下文和候选之间的交互来解决上述问题，但代价是性能下降。在这项工作中，我们开发了一种新的范例，称为Uni-Encoder，它像交叉编码器一样完全关注每个候选对，同时像Poly-编码器一样只编码一次上下文。Uni-Encoder在一次前向传递中对所有候选与上下文进行编码。我们针对所有候选使用相同的位置嵌入。

    Sample-and-rank is a key decoding strategy for modern generation-based dialogue systems. It helps achieve diverse and high-quality responses by selecting an answer from a small pool of generated candidates. The current state-of-the-art ranking methods mainly use an encoding paradigm called Cross-Encoder, which separately encodes each context-candidate pair and ranks the candidates according to their fitness scores. However, Cross-Encoder repeatedly encodes the same lengthy context for each candidate, resulting in high computational costs. Poly-Encoder addresses the above problems by reducing the interaction between context and candidates, but with a price of performance drop. In this work, we develop a new paradigm called Uni-Encoder, that keeps the full attention over each pair as in Cross-Encoder while only encoding the context once, as in Poly-Encoder. Uni-Encoder encodes all the candidates with the context in one forward pass. We use the same positional embedding for all candidates
    

