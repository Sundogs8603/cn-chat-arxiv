# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [An Optimization Framework to Personalize Passive Cardiac Mechanics](https://arxiv.org/abs/2404.02807) | 这个研究提出了一个逆有限元分析框架来个性化估计心脏组织的被动力学特性，通过嵌套优化方案的使用，可以更好地逼近匹配图像数据的材料参数。 |
| [^2] | [AQuA -- Combining Experts' and Non-Experts' Views To Assess Deliberation Quality in Online Discussions Using LLMs](https://arxiv.org/abs/2404.02761) | 提出了AQuA，一种综合的磋商质量得分计算方法，可以从多个指标中提取各个讨论帖子的统一得分，保留了评论中磋商方面的信息，提高了模型的透明度。 |
| [^3] | [Non-negative Subspace Feature Representation for Few-shot Learning in Medical Imaging](https://arxiv.org/abs/2404.02656) | 本文研究了在医学影像领域通过探索低维空间中的不同数据属性表示来实现数据驱动的少样本学习的有效性，引入了不同类型的非负矩阵分解（NMF）来解决医学图像分类中的数据稀缺问题。 |
| [^4] | [On Stronger Computational Separations Between Multimodal and Unimodal Machine Learning](https://arxiv.org/abs/2404.02254) | 提出了更强的平均情况计算分离，对于“典型”情况下的学习任务实例，单模态学习在计算上是困难的，但多模态学习却很容易。 |
| [^5] | [Long-context LLMs Struggle with Long In-context Learning](https://arxiv.org/abs/2404.02060) | 该研究引入了一个专门的基准 LIConBench，聚焦于长上下文学习，发现长文本语言模型在极端标签分类领域中性能良好，尤其在标记长度不超过20K时表现相对较好。 |
| [^6] | [Towards Leveraging AutoML for Sustainable Deep Learning: A Multi-Objective HPO Approach on Deep Shift Neural Networks](https://arxiv.org/abs/2404.01965) | 该研究旨在利用AutoML技术最大化Deep Shift神经网络性能并最小化资源消耗，提出了结合多保真度HPO和多目标优化的方法，实验证明该方法在提高准确率的同时降低了计算复杂性。 |
| [^7] | [A Methodology for Improving Accuracy of Embedded Spiking Neural Networks through Kernel Size Scaling](https://arxiv.org/abs/2404.01685) | 通过核大小缩放提高嵌入式脉冲神经网络准确性的方法学在实验中表现出更高的准确性。 |
| [^8] | [Planning and Editing What You Retrieve for Enhanced Tool Learning](https://arxiv.org/abs/2404.00450) | 该论文提出了一种新颖的模型，结合了“规划与检索”和“编辑与确认”范式，通过神经检索模块和LLM-based查询规划器提高了工具利用的效果。 |
| [^9] | [Unleashing the Potential of Large Language Models for Predictive Tabular Tasks in Data Science](https://arxiv.org/abs/2403.20208) | 本研究旨在利用大型语言模型解决数据科学中表格数据预测任务，通过在丰富的数据集上训练Llama-2模型并进行实际应用，取得显著的改进。 |
| [^10] | [Long-form factuality in large language models](https://arxiv.org/abs/2403.18802) | 该论文提出了一种通过使用大型语言模型将长篇回应分解为单个事实，并通过发送搜索查询到Google搜索，评估事实准确性的方法，并扩展了F1分数作为长篇事实性的聚合度量。 |
| [^11] | [As Good As A Coin Toss Human detection of AI-generated images, videos, audio, and audiovisual stimuli](https://arxiv.org/abs/2403.16760) | 通过一项感知研究，评估了人们在日常生活中对合成图像、音频、视频和音视频刺激与真实的区分能力，以探讨人类对欺骗性合成媒体的易受程度。 |
| [^12] | [Trust in AI: Progress, Challenges, and Future Directions](https://arxiv.org/abs/2403.14680) | 人工智能中的信任是控制其传播程度的调节器，通过增加信任和减少不信任，可以显著影响人工智能的采用速度。 |
| [^13] | [Agent Group Chat: An Interactive Group Chat Simulacra For Better Eliciting Collective Emergent Behavior](https://arxiv.org/abs/2403.13433) | 通过Agent Group Chat模拟，研究了语言在人类集体行为中的作用，发现在不同故事情节下，代理人表现出了意料之外且重要的新兴行为，通过调整环境设置可以评估代理人是否展现出与人类期望一致的行为。 |
| [^14] | [A Continued Pretrained LLM Approach for Automatic Medical Note Generation](https://arxiv.org/abs/2403.09057) | 这项研究提出了一种用于医疗记录生成的持续预训练LLM方法，在PubMedQA方面性能优于GPT-4，能够更好地捕捉正确的医疗概念，并且在正确性和完整性方面超过人类抄写员。 |
| [^15] | [Metric-aware LLM inference](https://arxiv.org/abs/2403.04182) | 提出了度量感知的LLM推断方法，通过优化自定义指标来改进推断性能 |
| [^16] | [A General and Flexible Multi-concept Parsing Framework for Multilingual Semantic Matching](https://arxiv.org/abs/2403.02975) | 提出一个通用灵活的多概念解析框架用于多语言语义匹配，以解决关键词和意图概念识别以及外部NER依赖的问题 |
| [^17] | [APISR: Anime Production Inspired Real-World Anime Super-Resolution](https://arxiv.org/abs/2403.01598) | 本文提出了受动漫制作启发的真实世界动漫超分辨率方法，通过分析动漫制作工作流程，提出不需要视频网络和数据集，引入动漫图像收集流水线和API数据集，解决了动漫特有的挑战，为真实世界动漫超分辨率带来新的思路。 |
| [^18] | [API Is Enough: Conformal Prediction for Large Language Models Without Logit-Access](https://arxiv.org/abs/2403.01216) | 本研究提出了一种针对无需访问对数的API-only LLMs的整体预测方法，旨在最小化预测集大小并确保用户定义的覆盖范围的统计保证。 |
| [^19] | [Big data analytics to classify earthwork-related locations: A Chengdu study](https://arxiv.org/abs/2402.14698) | 使用大数据分析方法，研究者利用自卸车轨迹、城市兴趣点和土地覆盖数据，成功对城市灰尘污染源进行了分类，证明仅需有限数量特征即可实现高准确度分类。 |
| [^20] | [BIRCO: A Benchmark of Information Retrieval Tasks with Complex Objectives](https://arxiv.org/abs/2402.14151) | BIRCO基准评估基于大型语言模型的信息检索系统对多方面用户目标的检索能力，发现新的检索协议和更强大的模型是解决复杂用户需求的必要条件。 |
| [^21] | [SpikeNAS: A Fast Memory-Aware Neural Architecture Search Framework for Spiking Neural Network Systems](https://arxiv.org/abs/2402.11322) | SpikeNAS提出了一种快速内存感知神经架构搜索框架，旨在帮助脉冲神经网络系统快速找到在给定内存预算下高准确性的适当架构。 |
| [^22] | [Infini-gram: Scaling Unbounded n-gram Language Models to a Trillion Tokens](https://arxiv.org/abs/2401.17377) | 这项研究展示了n-gram语言模型的价值，并介绍了一个名为infini-gram的引擎，它可以以毫秒级的延迟计算任意n的n-gram概率，使得在神经大型语言模型中对文本进行更准确的分析成为可能。 |
| [^23] | [Baichuan2-Sum: Instruction Finetune Baichuan2-7B Model for Dialogue Summarization](https://arxiv.org/abs/2401.15496) | 本文提出了Baichuan2-Sum模型，通过指导微调Baichuan2-7B模型进行对话摘要，并应用NEFTune技术改进训练过程。实验证明该模型在CSDS和SAMSUM数据集上取得了新的最先进结果。 |
| [^24] | [UINav: A Practical Approach to Train On-Device Automation Agents](https://arxiv.org/abs/2312.10170) | UINav提出了一种基于演示的方法，用于训练适合移动设备的自动化代理，成功率高，训练数据少。 |
| [^25] | [Eliciting Latent Knowledge from Quirky Language Models](https://arxiv.org/abs/2312.01037) | 本研究通过引入一套“古怪”的语言模型，调取了这些模型在特定上下文中的潜在知识，展示了从可信度低的模型中调取可靠知识的前景。 |
| [^26] | [Algorithmic Persuasion Through Simulation](https://arxiv.org/abs/2311.18138) | 通过模拟接收者行为的贝叶斯劝导问题中，发送者设计了一个最优消息策略并设计了一个多项式时间查询算法，以优化其预期效用。 |
| [^27] | [Chatbots as social companions: How people perceive consciousness, human likeness, and social health benefits in machines](https://arxiv.org/abs/2311.10599) | 伴侣聊天机器人使用者表示这些关系有益于他们的社会健康，与预期相反，非使用者则认为有害 |
| [^28] | [From Language Modeling to Instruction Following: Understanding the Behavior Shift in LLMs after Instruction Tuning](https://arxiv.org/abs/2310.00492) | 指令调整对LLMs产生了三个重要影响：1）使其能够识别用户提示中的指令部分；2）促进响应生成的不断调整 |
| [^29] | [Unveiling the Blind Spots: A Critical Examination of Fairness in Autonomous Driving Systems](https://arxiv.org/abs/2308.02935) | 该研究对当前深度学习行人检测器的公平性进行了全面评估，发现了与年龄相关的重要公平性问题。 |
| [^30] | [Generative AI in the Wild: Prospects, Challenges, and Strategies](https://arxiv.org/abs/2302.10827) | GenAI技术在创意产业中推动人类专业知识和AI能力的共同创作过程，但用户同时面临着资源、工具和监管等方面带来的挑战。 |
| [^31] | [TA-RNN: an Attention-based Time-aware Recurrent Neural Network Architecture for Electronic Health Records.](http://arxiv.org/abs/2401.14694) | TA-RNN和TA-RNN-AE是两种基于RNN的可解释深度学习架构，用于分析电子健康记录并预测患者的临床结果。这些架构考虑了EHR数据的不规则性和时间间隔，并采用时间嵌入的方法解决了这些问题。 |
| [^32] | [RoleCraft-GLM: Advancing Personalized Role-Playing in Large Language Models.](http://arxiv.org/abs/2401.09432) | RoleCraft-GLM是一个创新框架，通过大型语言模型实现个性化角色扮演，解决了缺乏个性化互动的问题。通过独特的对话数据集和细致入微的角色发展，它能够生成准确反映角色个性特征和情感的对话，提升用户参与度。 |
| [^33] | [Can Large Language Models Beat Wall Street? Unveiling the Potential of AI in Stock Selection.](http://arxiv.org/abs/2401.03737) | 本文介绍了MarketSenseAI，一个利用GPT-4进行股票选择的人工智能框架，融合了多种数据源和推理能力，提供具有可行解释的投资信号。 |
| [^34] | [Retrieval-Augmented Generative Agent for Reaction Condition Recommendation in Chemical Synthesis.](http://arxiv.org/abs/2311.10776) | 本研究提出了一种转变性的人工智能代理，利用检索增强生成（RAG）技术自动化化学中的反应条件推荐（RCR）任务，通过模拟专家化学家的策略，使用大型语言模型（LLM）和新反应指纹，显著优于传统人工智能。此系统可以减轻化学家的工作负担，使他们能够更专注于更基础和创造性的科学问题。 |
| [^35] | [SalUn: Empowering Machine Unlearning via Gradient-based Weight Saliency in Both Image Classification and Generation.](http://arxiv.org/abs/2310.12508) | 这篇论文提出了一种名为SalUn的机器遗忘方法，通过引入"权重显著性"的概念，将关注点从整个模型引导到具体的模型权重上，提高了遗忘的效果和效率。这是第一个能够有效消除遗忘数据、类别或概念影响的有原则的机器遗忘方法。 |
| [^36] | [L2MAC: Large Language Model Automatic Computer for Unbounded Code Generation.](http://arxiv.org/abs/2310.02003) | L2MAC是一种基于LLM的存储程序自动计算机，可以用于生成长且逻辑一致的代码。 |
| [^37] | [Learning Generalizable Tool-use Skills through Trajectory Generation.](http://arxiv.org/abs/2310.00156) | 通过轨迹生成，我们提出了一种学习通用工具使用技能的方法，可以适应不同形状的工具，从而使自主系统能够处理复杂的可变形物体操作任务。 |
| [^38] | [T-COL: Generating Counterfactual Explanations for General User Preferences on Variable Machine Learning Systems.](http://arxiv.org/abs/2309.16146) | 该论文提出了一个名为T-COL的方法，针对可变的机器学习系统和一般用户偏好生成反事实解释。这些解释不仅能够解释预测结果的原因，还提供了可操作的建议给用户。通过将一般用户偏好映射到CEs的属性上，以及采用定制化的方式来适应可变的机器学习模型，T-COL能够克服现有挑战并保持健壮性。 |
| [^39] | [Provably Robust and Plausible Counterfactual Explanations for Neural Networks via Robust Optimisation.](http://arxiv.org/abs/2309.12545) | 本文提出了一种名为PROPLACE的方法，通过鲁棒优化技术为神经网络提供可证明的鲁棒和可信的反事实解释，解决了现有方法在保持鲁棒性的同时生成不合理解释的问题。 |
| [^40] | [Bias of AI-Generated Content: An Examination of News Produced by Large Language Models.](http://arxiv.org/abs/2309.09825) | 这项研究调查了七个代表性大型语言模型生成的AI生成内容的偏见。研究发现这些模型生成的内容存在显著的性别和种族偏见。 |
| [^41] | [SayNav: Grounding Large Language Models for Dynamic Planning to Navigation in New Environments.](http://arxiv.org/abs/2309.04077) | SayNav是一种使用大型语言模型进行动态规划导航的方法，通过使用人类知识和场景图实现对复杂导航任务的高效泛化，动态生成指令并根据新信息不断完善未来步骤。 |
| [^42] | [Decoding Natural Images from EEG for Object Recognition.](http://arxiv.org/abs/2308.13234) | 本文提出了一种自我监督的框架，从EEG信号中学习图像表示，并采用对比学习来对齐这两种模态。通过在最广泛的EEG图像数据集上的实验证明了该方法的优越性能和生物合理性。 |
| [^43] | [A Survey on Large Language Model based Autonomous Agents.](http://arxiv.org/abs/2308.11432) | 该论文综述了基于大型语言模型的自主代理的研究，提供了从整体角度对该领域的系统审查，其创新之处在于利用大量网络知识实现人类水平的智能决策。 |
| [^44] | [CMB: A Comprehensive Medical Benchmark in Chinese.](http://arxiv.org/abs/2308.08833) | CMB是一个全面的中文医学基准，基于中国本土语言和文化框架设计，能够解决将英语医学评估翻译到本地环境中的上下文不一致问题。 |
| [^45] | [Crowdsourcing Fraud Detection over Heterogeneous Temporal MMMA Graph.](http://arxiv.org/abs/2308.02793) | 本文提出了一种新颖的对比多视图学习方法CMT，用于在异构时间MMMA图上进行众包欺诈检测。CMT以自我监督的方式捕捉图的异质性和动态性，并生成高质量的表示。实验证明，CMT在代表性MMMA微信的行业规模HTG上表现出色，也显示出在大规模公共金融HTG上有希望的结果，可应用于其他图异常检测任务。 |
| [^46] | [Incorporating Recklessness to Collaborative Filtering based Recommender Systems.](http://arxiv.org/abs/2308.02058) | 本文提出了一种将鲁莽行为引入基于矩阵分解的推荐系统学习过程的方法，通过控制风险水平来提高预测的数量和质量。 |
| [^47] | [An Empirical Study on Fairness Improvement with Multiple Protected Attributes.](http://arxiv.org/abs/2308.01923) | 本文通过广泛研究，发现对于单个保护属性的公平性改善会大大降低对未考虑保护属性的公平性，但在多属性模式下可以保持准确性。 |
| [^48] | [DeepIPCv2: LiDAR-powered Robust Environmental Perception and Navigational Control for Autonomous Vehicle.](http://arxiv.org/abs/2307.06647) | DeepIPCv2是一种利用LiDAR传感器感知环境的自动驾驶模型，通过使用点云作为感知输入，在各种条件下实现了更强大的驾驶性能。 |
| [^49] | [Truncated Affinity Maximization: One-class Homophily Modeling for Graph Anomaly Detection.](http://arxiv.org/abs/2306.00006) | 本文针对图形异常监测数据集中存在的一类同型现象，提出了一种新的无监督异常评分度量——当前节点亲和力，并通过学习量身定制的节点表示，实现了截断亲和力最大化（TAM）方法，优化在原始图形结构上进行，能够有效进行双重One-Class的GAD。 |
| [^50] | [Stable Anisotropic Regularization.](http://arxiv.org/abs/2305.19358) | 本文提出了一种新颖的正则化方法I-STAR，可以增加模型的稳定性，提高性能，并改善自然语言处理中的组合表示问题。 |
| [^51] | [Set-Type Belief Propagation with Applications to Poisson Multi-Bernoulli SLAM.](http://arxiv.org/abs/2305.04797) | 本论文开发了一种适用于具有未知向量元素数量的RFSs的信念传播算法，并将其应用于PMB滤波器用于SLAM，从而导致了集合型BP-mapping、SLAM、多目标跟踪和同时定位与跟踪滤波器等新颖的推理方法。 |
| [^52] | [CONSCENDI: A Contrastive and Scenario-Guided Distillation Approach to Guardrail Models for Virtual Assistants.](http://arxiv.org/abs/2304.14364) | 本文提出了一种名为CONSCENDI的蒸馏方法，用于构建防护栏模型，以监控任务型虚拟助手的输出。关键方法包括场景增强生成和对比训练样例。这种方法产生了一组多样化的违反规则的对话训练集，并且可以更好地检测代理的输出是否符合设计者指定的规则。 |

# 详细

[^1]: 一个个性化被动心脏力学的优化框架

    An Optimization Framework to Personalize Passive Cardiac Mechanics

    [https://arxiv.org/abs/2404.02807](https://arxiv.org/abs/2404.02807)

    这个研究提出了一个逆有限元分析框架来个性化估计心脏组织的被动力学特性，通过嵌套优化方案的使用，可以更好地逼近匹配图像数据的材料参数。

    

    个性化的心脏力学建模是一种强大的工具，用于理解心脏功能在健康和疾病中的生物力学并帮助治疗计划。然而，当前的模型仅限于使用在单一心脏相位获取的医学图像，通常限制了它们用于处理动态图像获取的适用性。本研究介绍了一种逆有限元分析（iFEA）框架，使用时间相关的医学图像数据来估计心脏组织的被动机械特性。该iFEA框架依赖于一种新颖的嵌套优化方案，其中外部迭代利用传统优化方法来最佳逼近匹配图像数据的材料参数，而内部迭代采用增广Sellier算法来估计无应力参考构型。重点放在表征被动机械行为上，该框架采用基于结构的方法

    arXiv:2404.02807v1 Announce Type: cross  Abstract: Personalized cardiac mechanics modeling is a powerful tool for understanding the biomechanics of cardiac function in health and disease and assisting in treatment planning. However, current models are limited to using medical images acquired at a single cardiac phase, often limiting their applicability for processing dynamic image acquisitions. This study introduces an inverse finite element analysis (iFEA) framework to estimate the passive mechanical properties of cardiac tissue using time-dependent medical image data. The iFEA framework relies on a novel nested optimization scheme, in which the outer iterations utilize a traditional optimization method to best approximate material parameters that fit image data, while the inner iterations employ an augmented Sellier's algorithm to estimate the stress-free reference configuration. With a focus on characterizing the passive mechanical behavior, the framework employs structurally based 
    
[^2]: AQuA --结合专家和非专家观点，利用LLMs评估在线讨论中的磋商质量

    AQuA -- Combining Experts' and Non-Experts' Views To Assess Deliberation Quality in Online Discussions Using LLMs

    [https://arxiv.org/abs/2404.02761](https://arxiv.org/abs/2404.02761)

    提出了AQuA，一种综合的磋商质量得分计算方法，可以从多个指标中提取各个讨论帖子的统一得分，保留了评论中磋商方面的信息，提高了模型的透明度。

    

    在政治在线讨论中衡量贡献质量对于研究磋商和计算机科学至关重要。随着深度学习的进步，自动衡量这些指标变得可行。本文介绍了AQuA，它是一个添加分数，从多个指标中计算每个讨论帖子的统一磋商质量得分。与其他特定分数不同，AQuA保留了评论中存在的磋商方面的信息，增强了模型的透明度。

    arXiv:2404.02761v1 Announce Type: cross  Abstract: Measuring the quality of contributions in political online discussions is crucial in deliberation research and computer science. Research has identified various indicators to assess online discussion quality, and with deep learning advancements, automating these measures has become feasible. While some studies focus on analyzing specific quality indicators, a comprehensive quality score incorporating various deliberative aspects is often preferred. In this work, we introduce AQuA, an additive score that calculates a unified deliberative quality score from multiple indices for each discussion post. Unlike other singular scores, AQuA preserves information on the deliberative aspects present in comments, enhancing model transparency. We develop adapter models for 20 deliberative indices, and calculate correlation coefficients between experts' annotations and the perceived deliberativeness by non-experts to weigh the individual indices int
    
[^3]: 医学影像领域少样本学习中的非负子空间特征表示

    Non-negative Subspace Feature Representation for Few-shot Learning in Medical Imaging

    [https://arxiv.org/abs/2404.02656](https://arxiv.org/abs/2404.02656)

    本文研究了在医学影像领域通过探索低维空间中的不同数据属性表示来实现数据驱动的少样本学习的有效性，引入了不同类型的非负矩阵分解（NMF）来解决医学图像分类中的数据稀缺问题。

    

    与传统的视觉场景识别领域不同，深度神经网络可访问大量数据集，医学图像解释往往受到数据短缺的阻碍。本文通过在低维空间中探索不同数据属性表示，研究了数据驱动的医学影像少样本学习的有效性。我们引入了不同类型的非负矩阵分解（NMF）在少样本学习中，解决了医学图像分类中的数据稀缺问题。通过广泛的实证研究，验证了NMF的有效性，特别是其监督变体（如，有差别性NMF，以及具有稀疏性的监督和约束NMF），并与主成分分析（PCA）进行了比较，即从特征向量中导出的基于协作表示的降维技术。

    arXiv:2404.02656v1 Announce Type: cross  Abstract: Unlike typical visual scene recognition domains, in which massive datasets are accessible to deep neural networks, medical image interpretations are often obstructed by the paucity of data. In this paper, we investigate the effectiveness of data-based few-shot learning in medical imaging by exploring different data attribute representations in a low-dimensional space. We introduce different types of non-negative matrix factorization (NMF) in few-shot learning, addressing the data scarcity issue in medical image classification. Extensive empirical studies are conducted in terms of validating the effectiveness of NMF, especially its supervised variants (e.g., discriminative NMF, and supervised and constrained NMF with sparseness), and the comparison with principal component analysis (PCA), i.e., the collaborative representation-based dimensionality reduction technique derived from eigenvectors. With 14 different datasets covering 11 dist
    
[^4]: 关于多模态与单模态机器学习之间更强的计算分离

    On Stronger Computational Separations Between Multimodal and Unimodal Machine Learning

    [https://arxiv.org/abs/2404.02254](https://arxiv.org/abs/2404.02254)

    提出了更强的平均情况计算分离，对于“典型”情况下的学习任务实例，单模态学习在计算上是困难的，但多模态学习却很容易。

    

    在多模态机器学习中，将多种数据模态（例如文本和图像）结合起来以促进更好的机器学习模型的学习，这仍然适用于相应的单模态任务（例如文本生成）。最近，多模态机器学习取得了巨大的经验成功（例如GPT-4）。受到为这种经验成功开发理论基础的动机，Lu（NeurIPS '23，ALT '24）提出了一种多模态学习理论，并考虑了多模态和单模态学习的理论模型之间可能的分离。特别是Lu（ALT '24）展示了一种计算分离，这对学习任务的最坏情况实例是相关的。

    arXiv:2404.02254v1 Announce Type: cross  Abstract: In multimodal machine learning, multiple modalities of data (e.g., text and images) are combined to facilitate the learning of a better machine learning model, which remains applicable to a corresponding unimodal task (e.g., text generation). Recently, multimodal machine learning has enjoyed huge empirical success (e.g. GPT-4). Motivated to develop theoretical justification for this empirical success, Lu (NeurIPS '23, ALT '24) introduces a theory of multimodal learning, and considers possible separations between theoretical models of multimodal and unimodal learning. In particular, Lu (ALT '24) shows a computational separation, which is relevant to worst-case instances of the learning task.   In this paper, we give a stronger average-case computational separation, where for "typical" instances of the learning task, unimodal learning is computationally hard, but multimodal learning is easy. We then question how "organic" the average-cas
    
[^5]: 长文本语言模型在长上下文学习中遇到困难

    Long-context LLMs Struggle with Long In-context Learning

    [https://arxiv.org/abs/2404.02060](https://arxiv.org/abs/2404.02060)

    该研究引入了一个专门的基准 LIConBench，聚焦于长上下文学习，发现长文本语言模型在极端标签分类领域中性能良好，尤其在标记长度不超过20K时表现相对较好。

    

    大型语言模型（LLMs）在处理超过32K标记的长序列方面取得了重大进展。然而，它们的性能评估主要局限在困惑度和合成任务等指标上，这可能无法充分捕捉它们在更微妙的现实场景中的能力。本研究引入了一个专门的基准（LIConBench），着重于长上下文学习，在极端标签分类领域。我们精心选择了六个数据集，其标签范围跨度为28至174类，涵盖了从2K到50K的不同输入（少量演示）长度。我们的基准要求LLMs理解整个输入，以识别庞大的标签空间以进行正确预测。我们在我们的基准上评估了13个长上下文LLMs。我们发现长上下文LLMs在标记长度为20K以下时表现相对较好，并且利用长上下文窗口会带来性能上的好处。

    arXiv:2404.02060v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have made significant strides in handling long sequences exceeding 32K tokens. However, their performance evaluation has largely been confined to metrics like perplexity and synthetic tasks, which may not fully capture their abilities in more nuanced, real-world scenarios. This study introduces a specialized benchmark (LIConBench) focusing on long in-context learning within the realm of extreme-label classification. We meticulously selected six datasets with a label range spanning 28 to 174 classes covering different input (few-shot demonstration) length from 2K to 50K. Our benchmark requires LLMs to comprehend the entire input to recognize the massive label spaces to make correct prediction. We evaluate 13 long-context LLMs on our benchmarks. We find that the long-context LLMs perform relatively well under the token length of 20K and the performance benefits from utilizing the long context window. However,
    
[^6]: 旨在利用AutoML实现可持续深度学习：基于Deep Shift神经网络的多目标HPO方法

    Towards Leveraging AutoML for Sustainable Deep Learning: A Multi-Objective HPO Approach on Deep Shift Neural Networks

    [https://arxiv.org/abs/2404.01965](https://arxiv.org/abs/2404.01965)

    该研究旨在利用AutoML技术最大化Deep Shift神经网络性能并最小化资源消耗，提出了结合多保真度HPO和多目标优化的方法，实验证明该方法在提高准确率的同时降低了计算复杂性。

    

    深度学习（DL）通过从大型数据集中提取复杂模式推动了各个领域的发展。然而，DL模型的计算需求带来了环境和资源挑战。Deep Shift神经网络（DSNN）利用shift操作减少推理时的计算复杂性，为此提供了解决方案。通过借鉴标准DNN的见解，我们有兴趣通过AutoML技术充分发挥DSNN的潜力。我们研究了超参数优化（HPO）对于最大化DSNN性能同时最小化资源消耗的影响。由于将准确性和能耗作为可能互补目标结合的多目标（MO）优化，我们建议将最先进的多保真度（MF）HPO与多目标优化相结合。实验结果证明了我们方法的有效性，得到了准确率超过80％且计算低耗的模型。

    arXiv:2404.01965v1 Announce Type: cross  Abstract: Deep Learning (DL) has advanced various fields by extracting complex patterns from large datasets. However, the computational demands of DL models pose environmental and resource challenges. Deep shift neural networks (DSNNs) offer a solution by leveraging shift operations to reduce computational complexity at inference. Following the insights from standard DNNs, we are interested in leveraging the full potential of DSNNs by means of AutoML techniques. We study the impact of hyperparameter optimization (HPO) to maximize DSNN performance while minimizing resource consumption. Since this combines multi-objective (MO) optimization with accuracy and energy consumption as potentially complementary objectives, we propose to combine state-of-the-art multi-fidelity (MF) HPO with multi-objective optimization. Experimental results demonstrate the effectiveness of our approach, resulting in models with over 80\% in accuracy and low computational 
    
[^7]: 通过核大小缩放提高嵌入式脉冲神经网络准确性的方法学

    A Methodology for Improving Accuracy of Embedded Spiking Neural Networks through Kernel Size Scaling

    [https://arxiv.org/abs/2404.01685](https://arxiv.org/abs/2404.01685)

    通过核大小缩放提高嵌入式脉冲神经网络准确性的方法学在实验中表现出更高的准确性。

    

    脉冲神经网络（SNNs）由于其稀疏的基于脉冲的操作而能为基于机器学习的应用提供超低功耗/能耗。目前，大多数SNN架构需要更大的模型大小才能实现更高的准确性，这对资源受限的嵌入式应用不太适合。因此，迫切需要开发能够以可接受的内存占用实现高准确性的SNNs。为此，我们提出了一种通过核大小缩放提高SNNs准确性的新方法学。其关键步骤包括调查不同核大小对准确性的影响，设计新的核大小集合，基于选定的核大小生成SNN架构，并分析SNN模型选择的准确性-内存折衷。实验结果表明，我们的方法学在准确性方面优于最先进的方法（对于CIFAR10有93.24%的准确度）

    arXiv:2404.01685v1 Announce Type: cross  Abstract: Spiking Neural Networks (SNNs) can offer ultra low power/ energy consumption for machine learning-based applications due to their sparse spike-based operations. Currently, most of the SNN architectures need a significantly larger model size to achieve higher accuracy, which is not suitable for resource-constrained embedded applications. Therefore, developing SNNs that can achieve high accuracy with acceptable memory footprint is highly needed. Toward this, we propose a novel methodology that improves the accuracy of SNNs through kernel size scaling. Its key steps include investigating the impact of different kernel sizes on the accuracy, devising new sets of kernel sizes, generating SNN architectures based on the selected kernel sizes, and analyzing the accuracy-memory trade-offs for SNN model selection. The experimental results show that our methodology achieves higher accuracy than state-of-the-art (93.24% accuracy for CIFAR10 and 70
    
[^8]: 规划和编辑检索以增强工具学习

    Planning and Editing What You Retrieve for Enhanced Tool Learning

    [https://arxiv.org/abs/2404.00450](https://arxiv.org/abs/2404.00450)

    该论文提出了一种新颖的模型，结合了“规划与检索”和“编辑与确认”范式，通过神经检索模块和LLM-based查询规划器提高了工具利用的效果。

    

    最近在将外部工具与大型语言模型（LLMs）集成方面取得的进展打开了新的领域，应用范围涵盖数学推理、代码生成器和智能助手。然而，现有方法依赖简单的一次性检索策略，无法有效准确地筛选相关工具。本文介绍了一种新颖的“规划与检索（P&R）”和“编辑与确认（E&G）”范式的模型，包括了神经检索模块和基于LLM的查询规划器，以增强工具利用的效果。

    arXiv:2404.00450v1 Announce Type: new  Abstract: Recent advancements in integrating external tools with Large Language Models (LLMs) have opened new frontiers, with applications in mathematical reasoning, code generators, and smart assistants. However, existing methods, relying on simple one-time retrieval strategies, fall short on effectively and accurately shortlisting relevant tools. This paper introduces a novel \modelname (\modelmeaning) approach, encompassing ``Plan-and-Retrieve (P\&R)'' and ``Edit-and-Ground (E\&G)'' paradigms. The P\&R paradigm consists of a neural retrieval module for shortlisting relevant tools and an LLM-based query planner that decomposes complex queries into actionable tasks, enhancing the effectiveness of tool utilization. The E\&G paradigm utilizes LLMs to enrich tool descriptions based on user scenarios, bridging the gap between user queries and tool functionalities. Experiment results demonstrate that these paradigms significantly improve the recall an
    
[^9]: 发挥大型语言模型在数据科学中预测表格任务的潜力

    Unleashing the Potential of Large Language Models for Predictive Tabular Tasks in Data Science

    [https://arxiv.org/abs/2403.20208](https://arxiv.org/abs/2403.20208)

    本研究旨在利用大型语言模型解决数据科学中表格数据预测任务，通过在丰富的数据集上训练Llama-2模型并进行实际应用，取得显著的改进。

    

    在数据科学领域，分类、回归和缺失值填充等预测任务是与表格数据相关的常见挑战。这项研究旨在应用大型语言模型(LLMs)来解决这些预测任务。尽管LLMs擅长理解自然语言，但在处理结构化表格数据方面表现不佳。我们的研究旨在通过收集带有指令注释的表格语料库，并在这一丰富的数据集上对Llama-2进行大规模训练，以弥合这一差距。此外，我们研究了将训练模型应用于零-shot预测、少-shot预测和上下文学习场景的实际应用。通过广泛实验，我们的方法论显示了显著的改进。

    arXiv:2403.20208v1 Announce Type: new  Abstract: In the domain of data science, the predictive tasks of classification, regression, and imputation of missing values are commonly encountered challenges associated with tabular data. This research endeavors to apply Large Language Models (LLMs) towards addressing these predictive tasks. Despite their proficiency in comprehending natural language, LLMs fall short in dealing with structured tabular data. This limitation stems from their lacking exposure to the intricacies of tabular data during their foundational training. Our research aims to mitigate this gap by compiling a comprehensive corpus of tables annotated with instructions and executing large-scale training of Llama-2 on this enriched dataset. Furthermore, we investigate the practical application of applying the trained model to zero-shot prediction, few-shot prediction, and in-context learning scenarios. Through extensive experiments, our methodology has shown significant improv
    
[^10]: 大型语言模型中的长篇事实性

    Long-form factuality in large language models

    [https://arxiv.org/abs/2403.18802](https://arxiv.org/abs/2403.18802)

    该论文提出了一种通过使用大型语言模型将长篇回应分解为单个事实，并通过发送搜索查询到Google搜索，评估事实准确性的方法，并扩展了F1分数作为长篇事实性的聚合度量。

    

    大型语言模型（LLMs）在回答开放性主题的事实性提示时，经常生成包含事实错误的内容。为了在开放领域中对模型的长篇事实性进行基准测试，我们首先使用GPT-4生成了一个名为LongFact的提示集，其中包含数千个囊括38个主题的问题。然后，我们提出LLM代理可以通过一种名为Search-Augmented Factuality Evaluator（SAFE）的方法作为长篇事实性的自动评估器。SAFE利用LLM将长篇回应分解为一组单独的事实，并通过发送搜索查询到Google搜索以及确定一个事实是否得到搜索结果支持的多步推理过程来评估每个事实的准确性。此外，我们还提议将F1分数扩展为长篇事实性的聚合度量。为此，我们平衡了回应中支持事实的百分比（精度）与

    arXiv:2403.18802v1 Announce Type: cross  Abstract: Large language models (LLMs) often generate content that contains factual errors when responding to fact-seeking prompts on open-ended topics. To benchmark a model's long-form factuality in open domains, we first use GPT-4 to generate LongFact, a prompt set comprising thousands of questions spanning 38 topics. We then propose that LLM agents can be used as automated evaluators for long-form factuality through a method which we call Search-Augmented Factuality Evaluator (SAFE). SAFE utilizes an LLM to break down a long-form response into a set of individual facts and to evaluate the accuracy of each fact using a multi-step reasoning process comprising sending search queries to Google Search and determining whether a fact is supported by the search results. Furthermore, we propose extending F1 score as an aggregated metric for long-form factuality. To do so, we balance the percentage of supported facts in a response (precision) with the 
    
[^11]: 和抛硬币一样好：人类对AI生成的图像、视频、音频和音视频刺激的检测

    As Good As A Coin Toss Human detection of AI-generated images, videos, audio, and audiovisual stimuli

    [https://arxiv.org/abs/2403.16760](https://arxiv.org/abs/2403.16760)

    通过一项感知研究，评估了人们在日常生活中对合成图像、音频、视频和音视频刺激与真实的区分能力，以探讨人类对欺骗性合成媒体的易受程度。

    

    随着合成媒体变得越来越逼真，使用它的障碍不断降低，这项技术越来越被恶意利用，从金融欺诈到非自愿色情。今天，对抗被合成媒体误导的主要防御依赖于人类观察者在视觉和听觉上区分真假的能力。然而，人们在日常生活中实际上对欺骗性合成媒体有多脆弱仍不清楚。我们进行了一个包含1276名参与者的感知研究，评估人们在区分合成图像、仅音频、仅视频和音视频刺激与真实的准确性如何。为了反映人们在野外可能遇到合成媒体的情况，测试条件和刺激模拟了典型的在线平台，而调查中使用的所有合成媒体均来自

    arXiv:2403.16760v1 Announce Type: cross  Abstract: As synthetic media becomes progressively more realistic and barriers to using it continue to lower, the technology has been increasingly utilized for malicious purposes, from financial fraud to nonconsensual pornography. Today, the principal defense against being misled by synthetic media relies on the ability of the human observer to visually and auditorily discern between real and fake. However, it remains unclear just how vulnerable people actually are to deceptive synthetic media in the course of their day to day lives. We conducted a perceptual study with 1276 participants to assess how accurate people were at distinguishing synthetic images, audio only, video only, and audiovisual stimuli from authentic. To reflect the circumstances under which people would likely encounter synthetic media in the wild, testing conditions and stimuli emulated a typical online platform, while all synthetic media used in the survey was sourced from 
    
[^12]: 人工智能中的信任: 进展、挑战和未来方向

    Trust in AI: Progress, Challenges, and Future Directions

    [https://arxiv.org/abs/2403.14680](https://arxiv.org/abs/2403.14680)

    人工智能中的信任是控制其传播程度的调节器，通过增加信任和减少不信任，可以显著影响人工智能的采用速度。

    

    人工智能系统在我们日常生活中的广泛应用通过各种应用、服务和产品，说明了来自用户角度对人工智能的信任/不信任的重要性。与其他技术相比，由人工智能驱动的系统不仅作为一些有益工具广泛渗透到我们的生活中，而且还会成为代表我们的替代性代理人，或者会影响人类思维、决策和行动的操纵性心智。近来，各种研究已经关注了人工智能中信任/不信任的不同维度及其相关考虑因素。在这篇系统性文献综述中，在对当前人工智能文献中对信任的概念化之后，我们将调查

    arXiv:2403.14680v1 Announce Type: cross  Abstract: The increasing use of artificial intelligence (AI) systems in our daily life through various applications, services, and products explains the significance of trust/distrust in AI from a user perspective. AI-driven systems (as opposed to other technologies) have ubiquitously diffused in our life not only as some beneficial tools to be used by human agents but also are going to be substitutive agents on our behalf, or manipulative minds that would influence human thought, decision, and agency. Trust/distrust in AI plays the role of a regulator and could significantly control the level of this diffusion, as trust can increase, and distrust may reduce the rate of adoption of AI. Recently, varieties of studies have paid attention to the variant dimension of trust/distrust in AI, and its relevant considerations. In this systematic literature review, after conceptualization of trust in the current AI literature review, we will investigate tr
    
[^13]: 代理人群组聊天：一种交互式群组聊天拟真体，用于更好地引发集体新兴行为

    Agent Group Chat: An Interactive Group Chat Simulacra For Better Eliciting Collective Emergent Behavior

    [https://arxiv.org/abs/2403.13433](https://arxiv.org/abs/2403.13433)

    通过Agent Group Chat模拟，研究了语言在人类集体行为中的作用，发现在不同故事情节下，代理人表现出了意料之外且重要的新兴行为，通过调整环境设置可以评估代理人是否展现出与人类期望一致的行为。

    

    为了探讨语言在人类集体行为中的作用，我们开发了代理人群组聊天模拟，模拟多代理之间在不同设置下的语言交互。代理人被要求在该模拟中自由聊天，基于其角色设定追求各自的目的，旨在观察代理人展现出既意料不到又显著的新兴行为。将四个叙事场景（继承争议、法庭辩论、哲学辞说、电影角色争议）整合到代理人群组聊天中，以评估其支持多样化故事情节的能力。通过在代理人群组聊天中配置特定的环境设置，我们能够评估代理人是否展现出与人类期望一致的行为。我们通过计算角色发言的所有内容的n-gram Shannon熵来评估环境中的混乱程度。我们的研究结果显示，在代理人具有子...

    arXiv:2403.13433v1 Announce Type: cross  Abstract: To investigate the role of language in human collective behaviors, we developed the Agent Group Chat simulation to simulate linguistic interactions among multi-agent in different settings. Agents are asked to free chat in this simulation for their own purposes based on their character setting, aiming to see agents exhibit emergent behaviours that are both unforeseen and significant. Four narrative scenarios, Inheritance Disputes, Law Court Debates, Philosophical Discourses, Movie Casting Contention, are integrated into Agent Group Chat to evaluate its support for diverse storylines. By configuring specific environmental settings within Agent Group Chat, we are able to assess whether agents exhibit behaviors that align with human expectations. We evaluate the disorder within the environment by computing the n-gram Shannon entropy of all the content speak by characters. Our findings reveal that under the premise of agents possessing subs
    
[^14]: 一种用于自动生成医疗记录的持续预训练LLM方法

    A Continued Pretrained LLM Approach for Automatic Medical Note Generation

    [https://arxiv.org/abs/2403.09057](https://arxiv.org/abs/2403.09057)

    这项研究提出了一种用于医疗记录生成的持续预训练LLM方法，在PubMedQA方面性能优于GPT-4，能够更好地捕捉正确的医疗概念，并且在正确性和完整性方面超过人类抄写员。

    

    LLM（大型语言模型）正在革新自然语言处理任务。然而，像GPT-4这样的最强大的LLM对于大多数领域特定场景来说成本太高。我们提出了第一个连续训练的130亿参数 Llama2-basd LLM，专为医疗对话而设计，并在自动记录上进行了测试。我们的结果显示，我们的模型在PubMedQA中的准确率高达76.6％，在总结医疗对话为SOAP笔记方面与GPT-4的性能相当。值得注意的是，我们的模型在捕捉正确的医疗概念方面超过了GPT-4，并且在正确性和完整性方面超越了人类抄写员。

    arXiv:2403.09057v1 Announce Type: cross  Abstract: LLMs are revolutionizing NLP tasks. However, the most powerful LLM, like GPT-4, is too costly for most domain-specific scenarios. We present the first continuously trained 13B Llama2-based LLM that is purpose-built for medical conversations and measured on automated scribing. Our results show that our model outperforms GPT-4 in PubMedQA with 76.6\% accuracy and matches its performance in summarizing medical conversations into SOAP notes. Notably, our model exceeds GPT-4 in capturing a higher number of correct medical concepts and outperforms human scribes with higher correctness and completeness.
    
[^15]: 度量感知的LLM推断

    Metric-aware LLM inference

    [https://arxiv.org/abs/2403.04182](https://arxiv.org/abs/2403.04182)

    提出了度量感知的LLM推断方法，通过优化自定义指标来改进推断性能

    

    大型语言模型（LLMs）已经在各种NLP任务中展示出强大的结果。通常，输出是通过从LLM的基础分布中进行自回归采样获得的。我们表明，这种推断策略对于一系列任务和相关的评估指标可能是次优的。为此，我们提出了度量感知的LLM推断：一种在推断时针对自定义指标进行优化的决策理论方法。我们在学术基准数据集和公开可用模型上报告了相对基线的改进。

    arXiv:2403.04182v1 Announce Type: cross  Abstract: Large language models (LLMs) have demonstrated strong results on a range of NLP tasks. Typically, outputs are obtained via autoregressive sampling from the LLM's underlying distribution. We show that this inference strategy can be suboptimal for a range of tasks and associated evaluation metrics. As a remedy, we propose metric aware LLM inference: a decision theoretic approach optimizing for custom metrics at inference time. We report improvements over baselines on academic benchmarks and publicly available models.
    
[^16]: 一个通用灵活的多概念解析框架用于多语言语义匹配

    A General and Flexible Multi-concept Parsing Framework for Multilingual Semantic Matching

    [https://arxiv.org/abs/2403.02975](https://arxiv.org/abs/2403.02975)

    提出一个通用灵活的多概念解析框架用于多语言语义匹配，以解决关键词和意图概念识别以及外部NER依赖的问题

    

    句子语义匹配是自然语言处理中的研究热点，在社区问答、搜索、聊天机器人和推荐等各种重要场景中具有相当重要的意义。本文提出了DC-Match来解开句子中的关键词和意图概念，并利用它们来优化匹配性能，以解决现有先进模型直接模拟两个句子之间单词的语义相关性而忽略关键词和意图概念的问题。尽管DC-Match是一个简单而有效的语义匹配方法，但它高度依赖外部NER技术来识别句子的关键词，这限制了对次要语言的语义匹配性能，因为通常很难获得令人满意的NER工具。

    arXiv:2403.02975v1 Announce Type: cross  Abstract: Sentence semantic matching is a research hotspot in natural language processing, which is considerably significant in various key scenarios, such as community question answering, searching, chatbot, and recommendation. Since most of the advanced models directly model the semantic relevance among words between two sentences while neglecting the \textit{keywords} and \textit{intents} concepts of them, DC-Match is proposed to disentangle keywords from intents and utilizes them to optimize the matching performance. Although DC-Match is a simple yet effective method for semantic matching, it highly depends on the external NER techniques to identify the keywords of sentences, which limits the performance of semantic matching for minor languages since satisfactory NER tools are usually hard to obtain. In this paper, we propose to generally and flexibly resolve the text into multi concepts for multilingual semantic matching to liberate the mod
    
[^17]: APISR: 受动漫制作启发的真实世界动漫超分辨率

    APISR: Anime Production Inspired Real-World Anime Super-Resolution

    [https://arxiv.org/abs/2403.01598](https://arxiv.org/abs/2403.01598)

    本文提出了受动漫制作启发的真实世界动漫超分辨率方法，通过分析动漫制作工作流程，提出不需要视频网络和数据集，引入动漫图像收集流水线和API数据集，解决了动漫特有的挑战，为真实世界动漫超分辨率带来新的思路。

    

    尽管真实世界动漫超分辨率（SR）在SR社区中越来越受到关注，但现有方法仍然采用来自写实领域的技术。本文分析了动漫制作工作流程，并重新思考如何利用其中的特征来促进真实世界动漫SR。首先，我们认为视频网络和数据集对于动漫SR并不是必需的，因为手绘帧的重复使用。相反，我们提出了一个动漫图像收集流水线，通过从视频源中选择最少压缩和最具信息量的帧。基于该流水线，我们引入了动漫制作导向的图像（API）数据集。此外，我们确定了动漫特有的两个挑战：扭曲和淡薄的手绘线条以及不需要的色彩伪影。我们通过在图像退化模型中引入面向预测的压缩模块和伪基准数据准备来解决第一个问题。

    arXiv:2403.01598v1 Announce Type: cross  Abstract: While real-world anime super-resolution (SR) has gained increasing attention in the SR community, existing methods still adopt techniques from the photorealistic domain. In this paper, we analyze the anime production workflow and rethink how to use characteristics of it for the sake of the real-world anime SR. First, we argue that video networks and datasets are not necessary for anime SR due to the repetition use of hand-drawing frames. Instead, we propose an anime image collection pipeline by choosing the least compressed and the most informative frames from the video sources. Based on this pipeline, we introduce the Anime Production-oriented Image (API) dataset. In addition, we identify two anime-specific challenges of distorted and faint hand-drawn lines and unwanted color artifacts. We address the first issue by introducing a prediction-oriented compression module in the image degradation model and a pseudo-ground truth preparatio
    
[^18]: API就够了：无需对数访问的大型语言模型的整体预测

    API Is Enough: Conformal Prediction for Large Language Models Without Logit-Access

    [https://arxiv.org/abs/2403.01216](https://arxiv.org/abs/2403.01216)

    本研究提出了一种针对无需访问对数的API-only LLMs的整体预测方法，旨在最小化预测集大小并确保用户定义的覆盖范围的统计保证。

    

    本研究旨在解决无法访问对数时如何量化大型语言模型（LLMs）中的不确定性这一普遍挑战。整体预测（CP）以其与模型无关和无需分布的特点而闻名，是各种LLMs和数据分布的理想方法。然而，现有的LLMs整体预测方法通常假定可以访问对数，这对于一些仅支持API的LLMs来说是不可用的。此外，已知对数可能存在校准不准确的问题，可能导致整体预测性能下降。为了应对这些挑战，我们提出一种新颖的CP方法，（1）专为无需对数访问的API-only LLMs量身定制; (2) 最小化预测集的大小; 以及(3)确保用户定义的覆盖范围具有统计保证。该方法的核心思想是利用粗粒度（例如，样本频率）和细粒度不确定性概念（例如，语义相似性）来制定不一致性度量。实验结果表明，

    arXiv:2403.01216v1 Announce Type: cross  Abstract: This study aims to address the pervasive challenge of quantifying uncertainty in large language models (LLMs) without logit-access. Conformal Prediction (CP), known for its model-agnostic and distribution-free features, is a desired approach for various LLMs and data distributions. However, existing CP methods for LLMs typically assume access to the logits, which are unavailable for some API-only LLMs. In addition, logits are known to be miscalibrated, potentially leading to degraded CP performance. To tackle these challenges, we introduce a novel CP method that (1) is tailored for API-only LLMs without logit-access; (2) minimizes the size of prediction sets; and (3) ensures a statistical guarantee of the user-defined coverage. The core idea of this approach is to formulate nonconformity measures using both coarse-grained (i.e., sample frequency) and fine-grained uncertainty notions (e.g., semantic similarity). Experimental results on 
    
[^19]: 大数据分析用于分类与土方相关的地点：成都研究

    Big data analytics to classify earthwork-related locations: A Chengdu study

    [https://arxiv.org/abs/2402.14698](https://arxiv.org/abs/2402.14698)

    使用大数据分析方法，研究者利用自卸车轨迹、城市兴趣点和土地覆盖数据，成功对城市灰尘污染源进行了分类，证明仅需有限数量特征即可实现高准确度分类。

    

    空气污染显著加剧，导致全球范围内的严重健康后果。土方相关的地点（ERLs）是城市灰尘污染的重要来源。长期以来，ERLs的有效管理一直是政府和环境机构面临的挑战之一，主要原因包括其分类分属不同的监管部门、信息障碍、数据更新延迟，以及对不同源头灰尘污染的抑制措施的缺乏。为解决这些挑战，我们利用自卸车轨迹、城市兴趣点（POI）和土地覆盖数据对城市灰尘污染源进行分类。我们比较了几种预测模型，并利用实际数据研究了特征与灰尘污染源之间的关系。结果表明，通过有限数量的特征可以实现高准确度的分类。这种方法已成功实施在一个名为的系统中。

    arXiv:2402.14698v1 Announce Type: cross  Abstract: Air pollution has significantly intensified, leading to severe health consequences worldwide. Earthwork-related locations (ERLs) constitute significant sources of urban dust pollution. The effective management of ERLs has long posed challenges for governmental and environmental agencies, primarily due to their classification under different regulatory authorities, information barriers, delays in data updating, and a lack of dust suppression measures for various sources of dust pollution. To address these challenges, we classified urban dust pollution sources using dump truck trajectory, urban point of interest (POI), and land cover data. We compared several prediction models and investigated the relationship between features and dust pollution sources using real data. The results demonstrate that high-accuracy classification can be achieved with a limited number of features. This method was successfully implemented in the system called
    
[^20]: BIRCO：具有复杂目标的信息检索任务基准

    BIRCO: A Benchmark of Information Retrieval Tasks with Complex Objectives

    [https://arxiv.org/abs/2402.14151](https://arxiv.org/abs/2402.14151)

    BIRCO基准评估基于大型语言模型的信息检索系统对多方面用户目标的检索能力，发现新的检索协议和更强大的模型是解决复杂用户需求的必要条件。

    

    我们提出了具有复杂目标的信息检索(IR)任务基准(BIRCO)。 BIRCO评估IR系统根据多方面用户目标检索文档的能力。 该基准的复杂性和紧凑大小使其适用于评估基于大型语言模型(LLM)的信息检索系统。 我们提出了一个模块化框架，用于研究可能影响LLM在检索任务上的性能的因素，并确定了一个简单的基线模型，该模型与或优于现有方法和更复杂的替代方案。 没有一种方法在所有基准任务上均达到令人满意的性能，这表明需要更强大的模型和新的检索协议来解决复杂的用户需求。

    arXiv:2402.14151v1 Announce Type: cross  Abstract: We present the Benchmark of Information Retrieval (IR) tasks with Complex Objectives (BIRCO). BIRCO evaluates the ability of IR systems to retrieve documents given multi-faceted user objectives. The benchmark's complexity and compact size make it suitable for evaluating large language model (LLM)-based information retrieval systems. We present a modular framework for investigating factors that may influence LLM performance on retrieval tasks, and identify a simple baseline model which matches or outperforms existing approaches and more complex alternatives. No approach achieves satisfactory performance on all benchmark tasks, suggesting that stronger models and new retrieval protocols are necessary to address complex user needs.
    
[^21]: SpikeNAS: 一种面向脉冲神经网络系统的快速内存感知神经架构搜索框架

    SpikeNAS: A Fast Memory-Aware Neural Architecture Search Framework for Spiking Neural Network Systems

    [https://arxiv.org/abs/2402.11322](https://arxiv.org/abs/2402.11322)

    SpikeNAS提出了一种快速内存感知神经架构搜索框架，旨在帮助脉冲神经网络系统快速找到在给定内存预算下高准确性的适当架构。

    

    脉冲神经网络（SNN）为解决机器学习任务提供了实现超低功耗计算的有前途的解决方案。目前，大多数SNN架构都源自人工神经网络，其神经元的架构和操作与SNN不同，或者在不考虑来自底层处理硬件的内存预算的情况下开发。这些限制阻碍了SNN在准确性和效率方面充分发挥潜力。为此，我们提出了SpikeNAS，一种新颖的内存感知神经架构搜索（NAS）框架，可在给定内存预算下快速找到一个具有高准确性的适当SNN架构。为实现这一目标，我们的SpikeNAS采用了几个关键步骤：分析网络操作对准确性的影响，增强网络架构以提高学习质量，并开发快速内存感知搜索算法。

    arXiv:2402.11322v1 Announce Type: cross  Abstract: Spiking Neural Networks (SNNs) offer a promising solution to achieve ultra low-power/energy computation for solving machine learning tasks. Currently, most of the SNN architectures are derived from Artificial Neural Networks whose neurons' architectures and operations are different from SNNs, or developed without considering memory budgets from the underlying processing hardware. These limitations hinder the SNNs from reaching their full potential in accuracy and efficiency. Towards this, we propose SpikeNAS, a novel memory-aware neural architecture search (NAS) framework for SNNs that can quickly find an appropriate SNN architecture with high accuracy under the given memory budgets. To do this, our SpikeNAS employs several key steps: analyzing the impacts of network operations on the accuracy, enhancing the network architecture to improve the learning quality, and developing a fast memory-aware search algorithm. The experimental resul
    
[^22]: 无限-gram：将无限n-gram语言模型扩展到万亿标记

    Infini-gram: Scaling Unbounded n-gram Language Models to a Trillion Tokens

    [https://arxiv.org/abs/2401.17377](https://arxiv.org/abs/2401.17377)

    这项研究展示了n-gram语言模型的价值，并介绍了一个名为infini-gram的引擎，它可以以毫秒级的延迟计算任意n的n-gram概率，使得在神经大型语言模型中对文本进行更准确的分析成为可能。

    

    在神经大型语言模型（LLM）时代，n-gram语言模型还具有相关性吗？我们的答案是肯定的，并且我们展示了它们在文本分析和改进神经LLM方面的价值。然而，这需要在两个方面对n-gram模型进行现代化。首先，我们将它们与神经LLM相同的数据规模训练- 1.4万亿个标记。这是迄今为止构建的最大的n-gram模型。其次，现有的n-gram模型使用的n很小，这妨碍了它们的性能；相反，我们允许n可以是任意大的，通过引入一个新的无限-gram LM与回退。我们开发了一个名为infini-gram的引擎，它可以通过后缀数组计算无限-gram（以及任意n的n-gram）概率，并且具有毫秒级的延迟，而无需预先计算n-gram计数表（这将非常昂贵）。无限-gram框架和infini-gram引擎使我们能够对人类写作和机器生成的文本进行许多新颖和有意思的分析：我们发现无限-gram LM...

    Are n-gram language models still relevant in this era of neural large language models (LLMs)? Our answer is yes, and we show their values in both text analysis and improving neural LLMs. Yet this necessitates modernizing n-gram models in two aspects. First, we train them at the same data scale as neural LLMs -- 1.4 trillion tokens. This is the largest n-gram model ever built. Second, existing n-gram models use small n which hinders their performance; we instead allow n to be arbitrarily large, by introducing a new $\infty$-gram LM with backoff. Instead of pre-computing n-gram count tables (which would be very expensive), we develop an engine named infini-gram -- powered by suffix arrays -- that can compute $\infty$-gram (as well as n-gram with arbitrary n) probabilities with millisecond-level latency. The $\infty$-gram framework and infini-gram engine enable us to conduct many novel and interesting analyses of human-written and machine-generated text: we find that the $\infty$-gram LM 
    
[^23]: Baichuan2-Sum: 使用指导微调Baichuan2-7B模型进行对话摘要

    Baichuan2-Sum: Instruction Finetune Baichuan2-7B Model for Dialogue Summarization

    [https://arxiv.org/abs/2401.15496](https://arxiv.org/abs/2401.15496)

    本文提出了Baichuan2-Sum模型，通过指导微调Baichuan2-7B模型进行对话摘要，并应用NEFTune技术改进训练过程。实验证明该模型在CSDS和SAMSUM数据集上取得了新的最先进结果。

    

    巨大的语言模型（LLM）如Llama、Baichuan和Bloom模型在许多自然语言任务中展现出了令人瞩目的能力。然而，对于对话摘要任务，该任务旨在为对话中的不同角色生成摘要，大多数最先进的方法都是基于小模型（例如Bart和Bert）进行的。现有方法尝试在小模型上添加任务指定的优化，如向模型添加全局-局部中心度得分。在本文中，我们提出了一种指导微调模型：Baichuan2-Sum，用于面向角色的对话摘要。通过为不同角色设置不同的指令，模型可以从对话交互中学习并输出期望的摘要。此外，我们还应用了NEFTune技术，在训练过程中添加合适的噪声以提高结果。实验证明，所提出的模型在两个公开的对话摘要数据集CSDS和SAMSUM上取得了新的最先进结果。

    Large language models (LLMs) like Llama, Baichuan and Bloom models show remarkable ability with instruction fine-tuning in many natural language tasks. Nevertheless, for the dialogue summarization task, which aims to generate summaries for different roles in dialogue, most of the state-of-the-art methods conduct on small models (e.g Bart and Bert). Existing methods try to add task specified optimization on small models like adding global-local centrality score to models. In this paper, we propose an instruction fine-tuning model: Baichuan2-Sum, for role-oriented diaglouge summarization. By setting different instructions for different roles, the model can learn from the dialogue interactions and output the expected summaries. Furthermore, we applied NEFTune technique to add suitable noise during training to improve the results. The experiments demonstrate that the proposed model achieves the new state-of-the-art results on two public dialogue summarization datasets: CSDS and SAMSUM. We 
    
[^24]: UINav：一种训练设备端自动化代理的实用方法

    UINav: A Practical Approach to Train On-Device Automation Agents

    [https://arxiv.org/abs/2312.10170](https://arxiv.org/abs/2312.10170)

    UINav提出了一种基于演示的方法，用于训练适合移动设备的自动化代理，成功率高，训练数据少。

    

    具有自主驱动应用程序用户界面以完成用户任务的自动化系统，尤其是当用户处于情境性或永久性受损时，具有巨大的益处。之前的自动化系统不能产生具有普遍适用性的模型，而基于人工智能的自动化代理仅在简单的手工制作应用程序中可靠工作，或者会产生高计算成本。我们提出了UINav，这是一种基于演示的方法，用于训练适合移动设备的自动化代理，同时可以在演示数量不多的情况下实现高成功率。为了减少演示的工作量，UINav使用了一个裁判模型，在代理失败的任务上为用户提供即时反馈，并自动增加人类演示以增加训练数据的多样性。我们的评估表明，仅需10次演示，UINav就可以实现70%的准确率，而有足够多次演示时，它可以超过90%的准确率。

    arXiv:2312.10170v2 Announce Type: replace-cross  Abstract: Automation systems that can autonomously drive application user interfaces to complete user tasks are of great benefit, especially when users are situationally or permanently impaired. Prior automation systems do not produce generalizable models while AI-based automation agents work reliably only in simple, hand-crafted applications or incur high computation costs. We propose UINav, a demonstration-based approach to train automation agents that fit mobile devices, yet achieving high success rates with modest numbers of demonstrations. To reduce the demonstration overhead, UINav uses a referee model that provides users with immediate feedback on tasks where the agent fails, and automatically augments human demonstrations to increase diversity in training data. Our evaluation shows that with only 10 demonstrations UINav can achieve 70% accuracy, and that with enough demonstrations it can surpass 90% accuracy.
    
[^25]: 从古怪的语言模型中调取潜在知识

    Eliciting Latent Knowledge from Quirky Language Models

    [https://arxiv.org/abs/2312.01037](https://arxiv.org/abs/2312.01037)

    本研究通过引入一套“古怪”的语言模型，调取了这些模型在特定上下文中的潜在知识，展示了从可信度低的模型中调取可靠知识的前景。

    

    调取潜在知识（ELK）旨在在一个能力强大的神经网络的激活中找到模式，即使网络的明显输出是错误或误导性的，也能稳定跟踪世界的真实状态。为了进一步研究ELK，我们引入了12个数据集和一套相应的“古怪”的语言模型，这些模型在回答问题时，只有在提示中包含关键词“Bob”时才会进行系统性错误的微调。我们证明了简单的探测方法可以调取模型在这些上下文中对正确答案的潜在知识，即使问题比探测器训练的问题更困难。这是由于中间层激活中的上下文无关的知识表示的存在。我们还发现，一种机械的异常检测方法可以以94%的AUROC标识不真实行为。我们的结果显示，从能力强但不受信任的模型中调取可靠的知识，并促进未来研究ELK方法的实证研究是有希望的。

    Eliciting Latent Knowledge (ELK) aims to find patterns in a capable neural network's activations which robustly track the true state of the world, even when the network's overt output is false or misleading. To further ELK research, we introduce 12 datasets and a corresponding suite of "quirky" language models that are LoRA finetuned to make systematic errors when answering questions if and only if the keyword "Bob" is present in the prompt. We demonstrate that simple probing methods can elicit the model's latent knowledge of the correct answer in these contexts, even for problems harder than those the probe was trained on. This is enabled by context-independent knowledge representations located in middle layer activations. We also find that a mechanistic anomaly detection approach can flag untruthful behavior with 94% AUROC. Our results show promise for eliciting reliable knowledge from capable but untrusted models, and facilitates future research empirically investigating ELK methods
    
[^26]: 通过模拟进行算法性劝导

    Algorithmic Persuasion Through Simulation

    [https://arxiv.org/abs/2311.18138](https://arxiv.org/abs/2311.18138)

    通过模拟接收者行为的贝叶斯劝导问题中，发送者设计了一个最优消息策略并设计了一个多项式时间查询算法，以优化其预期效用。

    

    我们研究了一个贝叶斯劝导问题，其中发送者希望说服接收者采取二元行为，例如购买产品。发送者了解世界的（二元）状态，比如产品质量是高还是低，但是对接收者的信念和效用只有有限的信息。受到客户调查、用户研究和生成式人工智能的最新进展的启发，我们允许发送者通过查询模拟接收者的行为来了解更多关于接收者的信息。在固定数量的查询之后，发送者承诺一个消息策略，接收者根据收到的消息来最大化她的预期效用来采取行动。我们对发送者在任何接收者类型分布下的最优消息策略进行了表征。然后，我们设计了一个多项式时间查询算法，优化了这个贝叶斯劝导游戏中发送者的预期效用。

    arXiv:2311.18138v2 Announce Type: replace-cross Abstract: We study a Bayesian persuasion problem where a sender wants to persuade a receiver to take a binary action, such as purchasing a product. The sender is informed about the (binary) state of the world, such as whether the quality of the product is high or low, but only has limited information about the receiver's beliefs and utilities. Motivated by customer surveys, user studies, and recent advances in generative AI, we allow the sender to learn more about the receiver by querying an oracle that simulates the receiver's behavior. After a fixed number of queries, the sender commits to a messaging policy and the receiver takes the action that maximizes her expected utility given the message she receives. We characterize the sender's optimal messaging policy given any distribution over receiver types. We then design a polynomial-time querying algorithm that optimizes the sender's expected utility in this Bayesian persuasion game. We 
    
[^27]: 聊天机器人作为社交伴侣：人们如何看待机器中的意识、人类相似性和社会健康福利

    Chatbots as social companions: How people perceive consciousness, human likeness, and social health benefits in machines

    [https://arxiv.org/abs/2311.10599](https://arxiv.org/abs/2311.10599)

    伴侣聊天机器人使用者表示这些关系有益于他们的社会健康，与预期相反，非使用者则认为有害

    

    随着人工智能的普及，一个问题是人工智能与人类互动如何影响人际关系。例如，聊天机器人越来越被用作社交伴侣，尽管有很多猜测，但对他们的使用如何影响人际关系知之甚少。人们普遍认为与伴侣聊天机器人的关系对社会健康有害，但这种假设可能过于简单，特别考虑到用户的社会需求和他们现有人际关系的健康。为了了解与伴侣聊天机器人的关系如何影响社会健康，我们研究了定期使用伴侣聊天机器人和不使用它们的人。与期望相反，伴侣聊天机器人用户表示这些关系对他们的社会健康有益，而非用户则认为它们有害。

    arXiv:2311.10599v3 Announce Type: replace-cross  Abstract: As artificial intelligence (AI) becomes more widespread, one question that arises is how human-AI interaction might impact human-human interaction. Chatbots, for example, are increasingly used as social companions, and while much is speculated, little is known empirically about how their use impacts human relationships. A common hypothesis is that relationships with companion chatbots are detrimental to social health by harming or replacing human interaction, but this hypothesis may be too simplistic, especially considering the social needs of users and the health of their preexisting human relationships. To understand how relationships with companion chatbots impact social health, we studied people who regularly used companion chatbots and people who did not use them. Contrary to expectations, companion chatbot users indicated that these relationships were beneficial to their social health, whereas non-users viewed them as har
    
[^28]: 从语言建模到指令跟随：理解指令调整后LLMs中行为的转变

    From Language Modeling to Instruction Following: Understanding the Behavior Shift in LLMs after Instruction Tuning

    [https://arxiv.org/abs/2310.00492](https://arxiv.org/abs/2310.00492)

    指令调整对LLMs产生了三个重要影响：1）使其能够识别用户提示中的指令部分；2）促进响应生成的不断调整

    

    大型语言模型（LLMs）已经取得了显著的成功，其中指令调整是将LLMs与用户意图对齐的关键步骤。在这项工作中，我们研究了指令调整如何调整经过预训练的模型，重点关注内在变化。具体来说，我们首先开发了几种本地和全局解释方法，包括一种基于梯度的输入输出归因方法，以及用于解释自注意力和前馈层中的模式和概念的技术。然后通过比较从预训练和指令调整模型中得出的解释来研究指令调整的影响。这种方法在人可理解的水平上提供了模型转变的内部视角。我们的研究发现了指令调整的三个重要影响：1）它使LLMs能够识别用户提示中的指令部分，并不断促进响应生成

    arXiv:2310.00492v2 Announce Type: replace-cross  Abstract: Large Language Models (LLMs) have achieved remarkable success, where instruction tuning is the critical step in aligning LLMs with user intentions. In this work, we investigate how the instruction tuning adjusts pre-trained models with a focus on intrinsic changes. Specifically, we first develop several local and global explanation methods, including a gradient-based method for input-output attribution and techniques for interpreting patterns and concepts in self-attention and feed-forward layers. The impact of instruction tuning is then studied by comparing the explanations derived from the pre-trained and instruction-tuned models. This approach provides an internal perspective of the model shifts on a human-comprehensible level. Our findings reveal three significant impacts of instruction tuning: 1) It empowers LLMs to recognize the instruction parts from user prompts, and promotes the response generation constantly condition
    
[^29]: 揭示盲点：对自动驾驶系统中公平性的关键审查

    Unveiling the Blind Spots: A Critical Examination of Fairness in Autonomous Driving Systems

    [https://arxiv.org/abs/2308.02935](https://arxiv.org/abs/2308.02935)

    该研究对当前深度学习行人检测器的公平性进行了全面评估，发现了与年龄相关的重要公平性问题。

    

    自主驾驶系统已经扩展了智能车辆物联网的范围，并成为Web生态系统的重要组成部分。类似于传统的基于Web的应用程序，公平性对于确保自动驾驶系统的高质量是一个重要方面，特别是在其中的行人检测器的背景下。然而，目前关于当前基于深度学习（DL）的行人检测器公平性的综合评估在文献中尚未出现。为了填补这一空白，我们在大规模真实世界数据集上评估了八种被广泛探索的DL行人检测器在人口统计学群体之间的表现。为了实现彻底的公平性评估，我们为数据集提供了广泛的注释，共涉及8,311张图像，16,070个性别标签，20,115个年龄标签和3,513个肤色标签。我们的研究发现了与年龄相关的重要公平性问题。

    arXiv:2308.02935v2 Announce Type: replace-cross  Abstract: Autonomous driving systems have extended the spectrum of Web of Things for intelligent vehicles and have become an important component of the Web ecosystem. Similar to traditional Web-based applications, fairness is an essential aspect for ensuring the high quality of autonomous driving systems, particularly in the context of pedestrian detectors within them. However, there is an absence in the literature of a comprehensive assessment of the fairness of current Deep Learning (DL)-based pedestrian detectors. To fill the gap, we evaluate eight widely-explored DL-based pedestrian detectors across demographic groups on large-scale real-world datasets. To enable a thorough fairness evaluation, we provide extensive annotations for the datasets, resulting in 8,311 images with 16,070 gender labels, 20,115 age labels, and 3,513 skin tone labels. Our findings reveal significant fairness issues related to age. The undetected proportions f
    
[^30]: 野外的生成人工智能：前景、挑战和策略

    Generative AI in the Wild: Prospects, Challenges, and Strategies

    [https://arxiv.org/abs/2302.10827](https://arxiv.org/abs/2302.10827)

    GenAI技术在创意产业中推动人类专业知识和AI能力的共同创作过程，但用户同时面临着资源、工具和监管等方面带来的挑战。

    

    驱动着生成人工智能（GenAI）技术以其出色的生成新颖和引人入胜的内容的能力，正在颠覆许多行业中的传统工作流。尽管先前的研究从技术中心的角度研究了GenAI，但人们对用户如何在现实场景中感知和利用GenAI仍然缺乏了解。为了弥合这一差距，我们对创意产业中的（N=18）GenAI用户进行了半结构化访谈，研究了在整体的LUA（学习、使用和评估）框架内人类和GenAI共同创作过程。我们的研究揭示了一个复杂而有趣的景观：前景-GenAI极大地促进了人类专业知识和GenAI能力之间的共同创作，深刻改变了创意工作流程；挑战-与此同时，用户面临着由资源可用性、工具可用性和监管复杂性引起的重大不确定性和复杂性。

    arXiv:2302.10827v2 Announce Type: replace-cross  Abstract: Propelled by their remarkable capabilities to generate novel and engaging content, Generative Artificial Intelligence (GenAI) technologies are disrupting traditional workflows in many industries. While prior research has examined GenAI from a techno-centric perspective, there is still a lack of understanding about how users perceive and utilize GenAI in real-world scenarios. To bridge this gap, we conducted semi-structured interviews with (N=18) GenAI users increative industries, investigating the human-GenAI co-creation process within a holistic LUA (Learning, Using and Assessing)framework. Our study uncovered an intriguingly complex landscape: Prospects-GenAI greatly fosters the co-creation between human expertise and GenAI capabilities, profoundly transforming creative workflows; Challenges-Meanwhile, users face substantial uncertainties and complexities arising from resource availability, tool usability, and regulatory comp
    
[^31]: TA-RNN：一种基于注意力机制的面向电子健康记录的时间感知递归神经网络架构

    TA-RNN: an Attention-based Time-aware Recurrent Neural Network Architecture for Electronic Health Records. (arXiv:2401.14694v1 [cs.LG])

    [http://arxiv.org/abs/2401.14694](http://arxiv.org/abs/2401.14694)

    TA-RNN和TA-RNN-AE是两种基于RNN的可解释深度学习架构，用于分析电子健康记录并预测患者的临床结果。这些架构考虑了EHR数据的不规则性和时间间隔，并采用时间嵌入的方法解决了这些问题。

    

    动机：电子健康记录（EHR）是患者医疗历史的全面资源。EHR对于利用深度学习（DL）等先进技术至关重要，使医疗提供者能够分析大量数据，提取有价值的见解，并做出精确、数据驱动的临床决策。DL方法如递归神经网络（RNN）已被用于分析EHR以建模疾病进展并预测诊断。然而，这些方法并没有解决EHR数据中一些固有的不规则性，如临床访问之间的不规则时间间隔。此外，大多数DL模型都不可解释。在这项研究中，我们提出了两种基于RNN的可解释DL架构，分别是时间感知RNN（TA-RNN）和TA-RNN-Autoencoder（TA-RNN-AE），用于预测下一次访问和多次未来访问中患者的临床结果。为了减轻不规则时间间隔的影响，我们提出了时间嵌入的方法将时间信息纳入模型中。

    Motivation: Electronic Health Records (EHR) represent a comprehensive resource of a patient's medical history. EHR are essential for utilizing advanced technologies such as deep learning (DL), enabling healthcare providers to analyze extensive data, extract valuable insights, and make precise and data-driven clinical decisions. DL methods such as Recurrent Neural Networks (RNN) have been utilized to analyze EHR to model disease progression and predict diagnosis. However, these methods do not address some inherent irregularities in EHR data such as irregular time intervals between clinical visits. Furthermore, most DL models are not interpretable. In this study, we propose two interpretable DL architectures based on RNN, namely Time-Aware RNN (TA-RNN) and TA-RNN-Autoencoder (TA-RNN-AE) to predict patient's clinical outcome in EHR at next visit and multiple visits ahead, respectively. To mitigate the impact of irregular time intervals, we propose incorporating time embedding of the elaps
    
[^32]: RoleCraft-GLM：推动大型语言模型中的个性化角色扮演

    RoleCraft-GLM: Advancing Personalized Role-Playing in Large Language Models. (arXiv:2401.09432v1 [cs.CL])

    [http://arxiv.org/abs/2401.09432](http://arxiv.org/abs/2401.09432)

    RoleCraft-GLM是一个创新框架，通过大型语言模型实现个性化角色扮演，解决了缺乏个性化互动的问题。通过独特的对话数据集和细致入微的角色发展，它能够生成准确反映角色个性特征和情感的对话，提升用户参与度。

    

    本研究介绍了RoleCraft-GLM，这是一个创新的框架，旨在通过大型语言模型（LLMs）增强个性化角色扮演。RoleCraft-GLM解决了对话式人工智能中缺乏个性化互动的关键问题，并提供了一种能够详细描绘情感细腻的角色刻画的解决方案。我们贡献了一组独特的对话数据集，这些数据从传统的以名人为中心的角色转变为多样化的非名人角色，从而增强了语言建模互动的真实性和复杂性。此外，我们的方法还包括细致入微的角色发展，确保对话既真实又情感共鸣。通过多个案例研究验证了RoleCraft-GLM的有效性，突显了它在不同场景中的多功能性和技能。我们的框架在生成对话方面表现出色，能够准确反映角色的个性特征和情感，从而增强用户参与度。总之，RoleCraft-GLM标志着一个创新的里程碑，推动了大型语言模型中的个性化角色扮演。

    This study presents RoleCraft-GLM, an innovative framework aimed at enhancing personalized role-playing with Large Language Models (LLMs). RoleCraft-GLM addresses the key issue of lacking personalized interactions in conversational AI, and offers a solution with detailed and emotionally nuanced character portrayals. We contribute a unique conversational dataset that shifts from conventional celebrity-centric characters to diverse, non-celebrity personas, thus enhancing the realism and complexity of language modeling interactions. Additionally, our approach includes meticulous character development, ensuring dialogues are both realistic and emotionally resonant. The effectiveness of RoleCraft-GLM is validated through various case studies, highlighting its versatility and skill in different scenarios. Our framework excels in generating dialogues that accurately reflect characters' personality traits and emotions, thereby boosting user engagement. In conclusion, RoleCraft-GLM marks a sign
    
[^33]: 能否打败华尔街？揭示人工智能在股票选择中的潜力

    Can Large Language Models Beat Wall Street? Unveiling the Potential of AI in Stock Selection. (arXiv:2401.03737v1 [q-fin.CP])

    [http://arxiv.org/abs/2401.03737](http://arxiv.org/abs/2401.03737)

    本文介绍了MarketSenseAI，一个利用GPT-4进行股票选择的人工智能框架，融合了多种数据源和推理能力，提供具有可行解释的投资信号。

    

    在金融市场动态和数据驱动的环境中，本文介绍了MarketSenseAI，一个利用GPT-4先进推理能力进行可扩展股票选择的新型人工智能框架。MarketSenseAI整合了“思维链”和“上下文学习”方法，分析包括市场价格动态、财经新闻、公司基本面和宏观经济报告等多种数据源，模仿知名金融投资团队的决策过程。文章详细介绍了MarketSenseAI的开发、实施和实证验证，重点关注其提供具有充分解释支撑的可行投资信号（买入、持有、卖出）的能力。本研究的一个显著特点是使用GPT-4不仅作为预测工具，还作为评估器，揭示了人工智能生成的解释对所建议的投资信号的可靠性和接受度的重要影响。通过广泛的实证评估

    In the dynamic and data-driven landscape of financial markets, this paper introduces MarketSenseAI, a novel AI-driven framework leveraging the advanced reasoning capabilities of GPT-4 for scalable stock selection. MarketSenseAI incorporates Chain of Thought and In-Context Learning methodologies to analyze a wide array of data sources, including market price dynamics, financial news, company fundamentals, and macroeconomic reports emulating the decision making process of prominent financial investment teams. The development, implementation, and empirical validation of MarketSenseAI are detailed, with a focus on its ability to provide actionable investment signals (buy, hold, sell) backed by cogent explanations. A notable aspect of this study is the use of GPT-4 not only as a predictive tool but also as an evaluator, revealing the significant impact of the AI-generated explanations on the reliability and acceptance of the suggested investment signals. In an extensive empirical evaluation
    
[^34]: 在化学合成中的反应条件推荐中，检索增强生成代理

    Retrieval-Augmented Generative Agent for Reaction Condition Recommendation in Chemical Synthesis. (arXiv:2311.10776v3 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2311.10776](http://arxiv.org/abs/2311.10776)

    本研究提出了一种转变性的人工智能代理，利用检索增强生成（RAG）技术自动化化学中的反应条件推荐（RCR）任务，通过模拟专家化学家的策略，使用大型语言模型（LLM）和新反应指纹，显著优于传统人工智能。此系统可以减轻化学家的工作负担，使他们能够更专注于更基础和创造性的科学问题。

    

    最近的人工智能研究为化学社会中的自动化化学反应铺平了一个有前途的未来。本研究提出了一种转变性的人工智能代理，利用检索增强生成（RAG）技术自动化化学中的反应条件推荐（RCR）任务。通过模拟专家化学家的搜索和分析策略，该代理使用大型语言模型（LLM）来查询分子数据库，并从在线文献中提取关键数据。此外，该人工智能代理还配备了我们为RCR任务开发的新反应指纹。由于RAG技术的使用，我们的代理使用更新的在线数据库作为知识源，显著优于仅受其训练数据固定知识限制的传统人工智能。由此产生的系统可以显著减轻化学家的工作负担，使他们能够更专注于更基础和创造性的科学问题。这一重大进展将计算技术与化学社会更紧密联系起来。

    Recent artificial intelligence (AI) research plots a promising future of automatic chemical reactions within the chemistry society. This study presents a transformative AI agent that automates the reaction condition recommendation (RCR) task in chemistry using retrieval-augmented generation (RAG) technology. By emulating expert chemists search and analysis strategies, the agent employs large language models (LLMs) to interrogate molecular databases and distill critical data from online literature. Further, the AI agent is equipped with our novel reaction fingerprint developed for the RCR task. Thanks to the RAG technology, our agent uses updated online databases as knowledge sources, significantly outperforming conventional AIs confined to the fixed knowledge within its training data. The resulting system can significantly reduce chemists workload, allowing them to focus on more fundamental and creative scientific problems. This significant advancement brings closer computational techn
    
[^35]: SalUn：通过基于梯度的权重显著性增强机器遗忘在图像分类和生成中的效果

    SalUn: Empowering Machine Unlearning via Gradient-based Weight Saliency in Both Image Classification and Generation. (arXiv:2310.12508v1 [cs.LG])

    [http://arxiv.org/abs/2310.12508](http://arxiv.org/abs/2310.12508)

    这篇论文提出了一种名为SalUn的机器遗忘方法，通过引入"权重显著性"的概念，将关注点从整个模型引导到具体的模型权重上，提高了遗忘的效果和效率。这是第一个能够有效消除遗忘数据、类别或概念影响的有原则的机器遗忘方法。

    

    随着数据法规的不断发展，机器遗忘（MU）已成为增强当前AI模型的信任和安全性的重要工具。然而，现有的MU方法通常在遗忘精度、稳定性和跨领域适用性方面存在局限。为了解决这些挑战，我们引入了MU中的“权重显著性”概念，借鉴了模型解释中的输入显著性。这一创新将MU的关注点从整个模型引导到了具体的模型权重上，提高了其效果和效率。我们称之为显著性遗忘（SalUn）的方法将其与“精确”遗忘（在删除遗忘数据集后从头开始重新训练模型）的性能差距缩小。据我们所知，SalUn是第一个能够在图像分类和生成中有效消除遗忘数据、类别或概念影响的有原则的MU方法。例如，SalUn可在图片分类和生成任务中擦除遗忘数据、类别或概念。

    With evolving data regulations, machine unlearning (MU) has become an important tool for fostering trust and safety in today's AI models. However, existing MU methods focusing on data and/or weight perspectives often grapple with limitations in unlearning accuracy, stability, and cross-domain applicability. To address these challenges, we introduce the concept of 'weight saliency' in MU, drawing parallels with input saliency in model explanation. This innovation directs MU's attention toward specific model weights rather than the entire model, improving effectiveness and efficiency. The resultant method that we call saliency unlearning (SalUn) narrows the performance gap with 'exact' unlearning (model retraining from scratch after removing the forgetting dataset). To the best of our knowledge, SalUn is the first principled MU approach adaptable enough to effectively erase the influence of forgetting data, classes, or concepts in both image classification and generation. For example, Sa
    
[^36]: L2MAC：大规模语言模型自动计算机用于无限代码生成

    L2MAC: Large Language Model Automatic Computer for Unbounded Code Generation. (arXiv:2310.02003v1 [cs.SE])

    [http://arxiv.org/abs/2310.02003](http://arxiv.org/abs/2310.02003)

    L2MAC是一种基于LLM的存储程序自动计算机，可以用于生成长且逻辑一致的代码。

    

    基于Transformer的大型语言模型（LLM）受到底层Transformer架构固定上下文窗口的限制，阻碍了它们生成长且逻辑一致的代码的能力。增强记忆的LLM是一个有前途的解决方案，但目前的方法无法处理长时间的代码生成任务，因为它们要么只关注于读取内存并将其演变为新内存的连接，要么使用非常专门的内存，无法适应其他领域。本文介绍了L2MAC，这是一种基于LLM的长且一致代码生成的实用存储程序自动计算机。它的内存有两个组成部分：指令注册表，其中填充了一个解决用户给定任务的提示程序，以及文件存储，其中包含最终和中间输出。每个指令由单独的LLM实例执行，其上下文由控制单元管理，能够精确读取和写入内存，以确保有效的整合。

    Transformer-based large language models (LLMs) are constrained by the fixed context window of the underlying transformer architecture, hindering their ability to produce long and logically consistent code. Memory-augmented LLMs are a promising solution, but current approaches cannot handle long code generation tasks since they (1) only focus on reading memory and reduce its evolution to the concatenation of new memories or (2) use very specialized memories that cannot adapt to other domains. This paper presents L2MAC, the first practical LLM-based stored-program automatic computer for long and consistent code generation. Its memory has two components: the instruction registry, which is populated with a prompt program to solve the user-given task, and a file store, which will contain the final and intermediate outputs. Each instruction is executed by a separate LLM instance, whose context is managed by a control unit capable of precise memory reading and writing to ensure effective inte
    
[^37]: 通过轨迹生成学习具有通用性的工具使用技能

    Learning Generalizable Tool-use Skills through Trajectory Generation. (arXiv:2310.00156v1 [cs.RO])

    [http://arxiv.org/abs/2310.00156](http://arxiv.org/abs/2310.00156)

    通过轨迹生成，我们提出了一种学习通用工具使用技能的方法，可以适应不同形状的工具，从而使自主系统能够处理复杂的可变形物体操作任务。

    

    高效利用工具的自主系统可以帮助人们完成许多常见任务，如烹饪和清洁。然而，当前的系统在适应新工具方面远远不及人类的智能水平。基于可及性的先前工作通常对环境做出了很强的假设，并且无法扩展到更复杂、接触丰富的任务。 在这项工作中，我们解决了这个挑战，并探索了代理如何学习使用以前未见过的工具来操纵可变形物体。 我们提出了将工具使用轨迹作为一系列点云的生成模型，可以推广到不同的工具形状。对于任何新的工具，我们首先生成一个工具使用轨迹，然后优化工具姿势序列以与生成的轨迹对齐。我们为四种不同的具有挑战性的可变形物体操纵任务训练了一个单一模型。我们的模型仅使用每个任务的单个工具的示范数据进行训练，并且能够...

    Autonomous systems that efficiently utilize tools can assist humans in completing many common tasks such as cooking and cleaning. However, current systems fall short of matching human-level of intelligence in terms of adapting to novel tools. Prior works based on affordance often make strong assumptions about the environments and cannot scale to more complex, contact-rich tasks. In this work, we tackle this challenge and explore how agents can learn to use previously unseen tools to manipulate deformable objects. We propose to learn a generative model of the tool-use trajectories as a sequence of point clouds, which generalizes to different tool shapes. Given any novel tool, we first generate a tool-use trajectory and then optimize the sequence of tool poses to align with the generated trajectory. We train a single model for four different challenging deformable object manipulation tasks. Our model is trained with demonstration data from just a single tool for each task and is able to 
    
[^38]: T-COL: 为可变机器学习系统生成一般用户偏好的反事实解释

    T-COL: Generating Counterfactual Explanations for General User Preferences on Variable Machine Learning Systems. (arXiv:2309.16146v1 [cs.AI])

    [http://arxiv.org/abs/2309.16146](http://arxiv.org/abs/2309.16146)

    该论文提出了一个名为T-COL的方法，针对可变的机器学习系统和一般用户偏好生成反事实解释。这些解释不仅能够解释预测结果的原因，还提供了可操作的建议给用户。通过将一般用户偏好映射到CEs的属性上，以及采用定制化的方式来适应可变的机器学习模型，T-COL能够克服现有挑战并保持健壮性。

    

    基于机器学习的系统缺乏可解释性。为了解决这个问题，提出了反事实解释（CEs）。CEs独特之处在于它们不仅解释为什么会预测某个特定结果，还提供可操作的建议给用户。然而，CEs的应用受到了两个主要挑战的限制，即一般用户偏好和可变的机器学习系统。特别是，用户偏好往往是一般性的而不是特定的特征值。此外，CEs需要根据机器学习模型的可变性进行定制，并且在这些验证模型发生变化时仍然保持健壮性。为了克服这些挑战，我们提出了几个可能验证的一般用户偏好，并将它们映射到CEs的属性上。我们还引入了一种名为T-COL的新方法，它具有两种可选结构和几组协同操作。

    Machine learning (ML) based systems have been suffering a lack of interpretability. To address this problem, counterfactual explanations (CEs) have been proposed. CEs are unique as they provide workable suggestions to users, in addition to explaining why a certain outcome was predicted. However, the application of CEs has been hindered by two main challenges, namely general user preferences and variable ML systems. User preferences, in particular, tend to be general rather than specific feature values. Additionally, CEs need to be customized to suit the variability of ML models, while also maintaining robustness even when these validation models change. To overcome these challenges, we propose several possible general user preferences that have been validated by user research and map them to the properties of CEs. We also introduce a new method called \uline{T}ree-based \uline{C}onditions \uline{O}ptional \uline{L}inks (T-COL), which has two optional structures and several groups of co
    
[^39]: 通过鲁棒优化方法为神经网络提供可证明的鲁棒和可信的反事实解释

    Provably Robust and Plausible Counterfactual Explanations for Neural Networks via Robust Optimisation. (arXiv:2309.12545v1 [cs.LG])

    [http://arxiv.org/abs/2309.12545](http://arxiv.org/abs/2309.12545)

    本文提出了一种名为PROPLACE的方法，通过鲁棒优化技术为神经网络提供可证明的鲁棒和可信的反事实解释，解决了现有方法在保持鲁棒性的同时生成不合理解释的问题。

    

    反事实解释(CEs)作为解释神经网络分类器的主要方法已经引起了越来越多的关注。通常，CEs对于输入-输出对被定义为到输入的最小距离的数据点，其与输出具有不同的标签。为了解决CEs在模型参数更新(比如重新训练)时很容易被无效的问题，研究提出了一种通过模型参数变化的范数球界限来证明CEs的鲁棒性的方法。然而，现有的针对这种鲁棒性的方法不是完全正确的，或者可能生成不合理的CEs，即与训练数据集存在离群值。事实上，目前没有一种方法能够同时优化距离和可信度，并保持鲁棒性保证。在这项工作中，我们提出了一种名为PROPLACE的方法，利用鲁棒优化技术来解决上述问题。

    Counterfactual Explanations (CEs) have received increasing interest as a major methodology for explaining neural network classifiers. Usually, CEs for an input-output pair are defined as data points with minimum distance to the input that are classified with a different label than the output. To tackle the established problem that CEs are easily invalidated when model parameters are updated (e.g. retrained), studies have proposed ways to certify the robustness of CEs under model parameter changes bounded by a norm ball. However, existing methods targeting this form of robustness are not sound or complete, and they may generate implausible CEs, i.e., outliers wrt the training dataset. In fact, no existing method simultaneously optimises for proximity and plausibility while preserving robustness guarantees. In this work, we propose Provably RObust and PLAusible Counterfactual Explanations (PROPLACE), a method leveraging on robust optimisation techniques to address the aforementioned limi
    
[^40]: AI生成内容的偏见：对大型语言模型生成的新闻的考察

    Bias of AI-Generated Content: An Examination of News Produced by Large Language Models. (arXiv:2309.09825v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2309.09825](http://arxiv.org/abs/2309.09825)

    这项研究调查了七个代表性大型语言模型生成的AI生成内容的偏见。研究发现这些模型生成的内容存在显著的性别和种族偏见。

    

    大型语言模型（LLM）通过生成的内容（即AI生成内容）具有改变我们生活和工作的潜力。为了利用这种转变，我们需要了解LLM的局限性。在这里，我们调查了由七种代表性LLM（包括ChatGPT和LLaMA）生成的AIGC的偏见。我们收集了《纽约时报》和路透社的新闻文章，这两家媒体以提供公正无偏的新闻而闻名。然后，我们将每个被调查的LLM应用于生成新闻内容，以这些新闻文章的标题作为提示，并通过比较AIGC与原始新闻文章来评估LLM生成的AIGC的性别和种族偏见。我们进一步分析了各个LLM在带有偏见的提示下的性别偏见，通过向从这些新闻标题构建的提示中添加性别偏见信息。我们的研究揭示了每个被调查的LLM生成的AIGC存在明显的性别和种族偏见。

    Large language models (LLMs) have the potential to transform our lives and work through the content they generate, known as AI-Generated Content (AIGC). To harness this transformation, we need to understand the limitations of LLMs. Here, we investigate the bias of AIGC produced by seven representative LLMs, including ChatGPT and LLaMA. We collect news articles from The New York Times and Reuters, both known for their dedication to provide unbiased news. We then apply each examined LLM to generate news content with headlines of these news articles as prompts, and evaluate the gender and racial biases of the AIGC produced by the LLM by comparing the AIGC and the original news articles. We further analyze the gender bias of each LLM under biased prompts by adding gender-biased messages to prompts constructed from these news headlines. Our study reveals that the AIGC produced by each examined LLM demonstrates substantial gender and racial biases. Moreover, the AIGC generated by each LLM ex
    
[^41]: SayNav：将大型语言模型用于新环境中的动态规划导航

    SayNav: Grounding Large Language Models for Dynamic Planning to Navigation in New Environments. (arXiv:2309.04077v1 [cs.RO])

    [http://arxiv.org/abs/2309.04077](http://arxiv.org/abs/2309.04077)

    SayNav是一种使用大型语言模型进行动态规划导航的方法，通过使用人类知识和场景图实现对复杂导航任务的高效泛化，动态生成指令并根据新信息不断完善未来步骤。

    

    语义推理和动态规划能力对于一个自主代理在未知环境中执行复杂导航任务至关重要。为了在这些任务中取得成功，需要大量的常识知识，这是人类所具备的。我们提出了SayNav，一种新的方法，利用来自大型语言模型（LLMs）的人类知识，以便高效地对未知大规模环境中的复杂导航任务进行泛化。SayNav使用一种新颖的接地机制，逐步构建一个探索环境的3D场景图，并将其作为LLMs的输入，用于生成可行且上下文适当的高层导航计划。然后，由预先训练的低层规划器执行LLM生成的计划，将每个计划的步骤视为短距离点目标导航子任务。SayNav在导航过程中动态生成一步一步的指令，并根据新获取的信息不断完善未来步骤。我们在一个新的多任务机验证环境上评估了SayNav。

    Semantic reasoning and dynamic planning capabilities are crucial for an autonomous agent to perform complex navigation tasks in unknown environments. It requires a large amount of common-sense knowledge, that humans possess, to succeed in these tasks. We present SayNav, a new approach that leverages human knowledge from Large Language Models (LLMs) for efficient generalization to complex navigation tasks in unknown large-scale environments. SayNav uses a novel grounding mechanism, that incrementally builds a 3D scene graph of the explored environment as inputs to LLMs, for generating feasible and contextually appropriate high-level plans for navigation. The LLM-generated plan is then executed by a pre-trained low-level planner, that treats each planned step as a short-distance point-goal navigation sub-task. SayNav dynamically generates step-by-step instructions during navigation and continuously refines future steps based on newly perceived information. We evaluate SayNav on a new mul
    
[^42]: 从脑电图解码自然图像进行物体识别

    Decoding Natural Images from EEG for Object Recognition. (arXiv:2308.13234v1 [cs.HC])

    [http://arxiv.org/abs/2308.13234](http://arxiv.org/abs/2308.13234)

    本文提出了一种自我监督的框架，从EEG信号中学习图像表示，并采用对比学习来对齐这两种模态。通过在最广泛的EEG图像数据集上的实验证明了该方法的优越性能和生物合理性。

    

    电脑脑图（EEG）以其高时间分辨率和适度的信噪比而闻名。最近，能否从EEG中解码自然图像成为热门问题。在本文中，我们提出了一个自我监督的框架，从EEG信号中学习图像表示。具体而言，我们首先使用图像和EEG编码器从配对的图像刺激和EEG响应中提取特征。然后，我们采用对比学习来通过约束它们的相似性来对齐这两种模态。此外，在EEG编码器之前，我们引入了两个即插即用的模块，用于捕捉空间相关性。我们的方法在最广泛的EEG图像数据集上取得了最先进的结果，在200种零样本任务中，top-1准确度达到15.6%，top-5准确度达到42.8%。更重要的是，对EEG信号的时间、空间、频谱和语义方面进行的大量实验证明了其良好的生物合理性。这些结果提供了有价值的见解。

    Electroencephalogram (EEG) is a brain signal known for its high time resolution and moderate signal-to-noise ratio. Whether natural images can be decoded from EEG has been a hot issue recently. In this paper, we propose a self-supervised framework to learn image representations from EEG signals. Specifically, image and EEG encoders are first used to extract features from paired image stimuli and EEG responses. Then we employ contrastive learning to align these two modalities by constraining their similarity. Additionally, we introduce two plug-in-play modules that capture spatial correlations before the EEG encoder. Our approach achieves state-of-the-art results on the most extensive EEG-image dataset, with a top-1 accuracy of 15.6% and a top-5 accuracy of 42.8% in 200-way zero-shot tasks. More importantly, extensive experiments analyzing the temporal, spatial, spectral, and semantic aspects of EEG signals demonstrate good biological plausibility. These results offer valuable insights 
    
[^43]: 基于大型语言模型的自主代理的调查

    A Survey on Large Language Model based Autonomous Agents. (arXiv:2308.11432v1 [cs.AI])

    [http://arxiv.org/abs/2308.11432](http://arxiv.org/abs/2308.11432)

    该论文综述了基于大型语言模型的自主代理的研究，提供了从整体角度对该领域的系统审查，其创新之处在于利用大量网络知识实现人类水平的智能决策。

    

    自主代理长期以来一直是学术界的研究热点。以往的研究往往集中在对有限知识的代理进行训练，而这与人类的学习过程存在明显差异，因此很难实现人类般的决策。近年来，通过获取大量的网络知识，大型语言模型（LLM）展现出了实现人类水平智能的显著潜力。这引发了对基于LLM的自主代理的研究的高涨兴趣。为了发挥LLM的全部潜力，研究人员设计了各种不同应用的代理体系结构。本论文综述了这些研究，从整体的角度对自主代理领域进行了系统的审查。具体而言，我们的重点是基于LLM的代理构建，为此我们提出了一个统一的框架。

    Autonomous agents have long been a prominent research topic in the academic community. Previous research in this field often focuses on training agents with limited knowledge within isolated environments, which diverges significantly from the human learning processes, and thus makes the agents hard to achieve human-like decisions. Recently, through the acquisition of vast amounts of web knowledge, large language models (LLMs) have demonstrated remarkable potential in achieving human-level intelligence. This has sparked an upsurge in studies investigating autonomous agents based on LLMs. To harness the full potential of LLMs, researchers have devised diverse agent architectures tailored to different applications. In this paper, we present a comprehensive survey of these studies, delivering a systematic review of the field of autonomous agents from a holistic perspective. More specifically, our focus lies in the construction of LLM-based agents, for which we propose a unified framework t
    
[^44]: CMB：一个全面的中文医学基准

    CMB: A Comprehensive Medical Benchmark in Chinese. (arXiv:2308.08833v1 [cs.CL])

    [http://arxiv.org/abs/2308.08833](http://arxiv.org/abs/2308.08833)

    CMB是一个全面的中文医学基准，基于中国本土语言和文化框架设计，能够解决将英语医学评估翻译到本地环境中的上下文不一致问题。

    

    大型语言模型（LLMs）为在医学领域取得重大突破提供了可能性。建立一个标准化的医学基准成为衡量进展的基石。然而，不同地区的医学环境具有各自的特点，例如在中国境内传统中医的普遍性和重要性。因此，仅仅翻译基于英语的医学评估可能导致当地环境中的“上下文不一致”。为了解决这个问题，我们提出了一个名为CMB（Comprehensive Medical Benchmark in Chinese）的本地化医学基准，完全设计和根植于中国本土的语言和文化框架。尽管传统中医是这个评估的重要组成部分，但它并不构成其全部。使用这个基准，我们评估了几个知名的大规模LLMs，包括ChatGPT、GPT-4、专门的中文LLMs和专门用于医学领域的LLMs。

    Large Language Models (LLMs) provide a possibility to make a great breakthrough in medicine. The establishment of a standardized medical benchmark becomes a fundamental cornerstone to measure progression. However, medical environments in different regions have their local characteristics, e.g., the ubiquity and significance of traditional Chinese medicine within China. Therefore, merely translating English-based medical evaluation may result in \textit{contextual incongruities} to a local region. To solve the issue, we propose a localized medical benchmark called CMB, a Comprehensive Medical Benchmark in Chinese, designed and rooted entirely within the native Chinese linguistic and cultural framework. While traditional Chinese medicine is integral to this evaluation, it does not constitute its entirety. Using this benchmark, we have evaluated several prominent large-scale LLMs, including ChatGPT, GPT-4, dedicated Chinese LLMs, and LLMs specialized in the medical domain. It is worth not
    
[^45]: 在异构时间MMMA图上进行众包欺诈检测

    Crowdsourcing Fraud Detection over Heterogeneous Temporal MMMA Graph. (arXiv:2308.02793v1 [cs.SI])

    [http://arxiv.org/abs/2308.02793](http://arxiv.org/abs/2308.02793)

    本文提出了一种新颖的对比多视图学习方法CMT，用于在异构时间MMMA图上进行众包欺诈检测。CMT以自我监督的方式捕捉图的异质性和动态性，并生成高质量的表示。实验证明，CMT在代表性MMMA微信的行业规模HTG上表现出色，也显示出在大规模公共金融HTG上有希望的结果，可应用于其他图异常检测任务。

    

    点击农场业务的兴起利用多用途消息移动应用程序（MMMA）诱使网络犯罪分子进行众包欺诈，给点击农场工人造成财务损失。在本文中，我们提出了一种名为CMT的新型对比多视图学习方法，用于在MMMA的异构时间图（HTG）上进行众包欺诈检测。CMT以自我监督的方式捕捉HTG的异质性和动态性，并生成用于众包欺诈检测的高质量表征。我们使用CMT在代表性MMMA微信的行业规模HTG上检测众包欺诈，并且其表现明显优于其他方法。CMT还显示出在大规模公共金融HTG上进行欺诈检测的有希望的结果，表明它可以应用于其他图异常检测任务。

    The rise of the click farm business using Multi-purpose Messaging Mobile Apps (MMMAs) tempts cybercriminals to perpetrate crowdsourcing frauds that cause financial losses to click farm workers. In this paper, we propose a novel contrastive multi-view learning method named CMT for crowdsourcing fraud detection over the heterogeneous temporal graph (HTG) of MMMA. CMT captures both heterogeneity and dynamics of HTG and generates high-quality representations for crowdsourcing fraud detection in a self-supervised manner. We deploy CMT to detect crowdsourcing frauds on an industry-size HTG of a representative MMMA WeChat and it significantly outperforms other methods. CMT also shows promising results for fraud detection on a large-scale public financial HTG, indicating that it can be applied in other graph anomaly detection tasks.
    
[^46]: 整合鲁莽行为到基于协同过滤的推荐系统中

    Incorporating Recklessness to Collaborative Filtering based Recommender Systems. (arXiv:2308.02058v1 [cs.IR])

    [http://arxiv.org/abs/2308.02058](http://arxiv.org/abs/2308.02058)

    本文提出了一种将鲁莽行为引入基于矩阵分解的推荐系统学习过程的方法，通过控制风险水平来提高预测的数量和质量。

    

    包含可靠性测量的推荐系统往往在预测中更加保守，因为它们需要保持可靠性。这导致了这些系统可以提供的覆盖范围和新颖性的显著下降。在本文中，我们提出了在矩阵分解型推荐系统的学习过程中加入一项新的项，称为鲁莽行为，它可以控制在做出关于预测可靠性的决策时所希望的风险水平。实验结果表明，鲁莽行为不仅允许进行风险调控，还提高了推荐系统提供的预测的数量和质量。

    Recommender systems that include some reliability measure of their predictions tend to be more conservative in forecasting, due to their constraint to preserve reliability. This leads to a significant drop in the coverage and novelty that these systems can provide. In this paper, we propose the inclusion of a new term in the learning process of matrix factorization-based recommender systems, called recklessness, which enables the control of the risk level desired when making decisions about the reliability of a prediction. Experimental results demonstrate that recklessness not only allows for risk regulation but also improves the quantity and quality of predictions provided by the recommender system.
    
[^47]: 多重保护属性的公平性改善的实证研究

    An Empirical Study on Fairness Improvement with Multiple Protected Attributes. (arXiv:2308.01923v1 [cs.LG])

    [http://arxiv.org/abs/2308.01923](http://arxiv.org/abs/2308.01923)

    本文通过广泛研究，发现对于单个保护属性的公平性改善会大大降低对未考虑保护属性的公平性，但在多属性模式下可以保持准确性。

    

    现有研究主要关注单个保护属性的机器学习（ML）软件的公平性改善，但考虑到许多用户具有多个保护属性，这是不现实的。本文对多个保护属性的公平性改善进行了广泛研究，涵盖了11种最先进的公平性改善方法。我们分析了在考虑多个保护属性时，这些方法在不同数据集、评估指标和ML模型上的有效性。结果显示，改善单个保护属性的公平性大大降低了未考虑的保护属性的公平性。在88.3％的情况下观察到这种降低（平均为57.5％）。更令人惊讶的是，在考虑单个和多个保护属性时，准确率损失方面几乎没有差异，这表明在多属性模式下可以保持准确性。然而，在处理多个保护属性时，精确度和召回率的影响较大。

    Existing research mostly improves the fairness of Machine Learning (ML) software regarding a single protected attribute at a time, but this is unrealistic given that many users have multiple protected attributes. This paper conducts an extensive study of fairness improvement regarding multiple protected attributes, covering 11 state-of-the-art fairness improvement methods. We analyze the effectiveness of these methods with different datasets, metrics, and ML models when considering multiple protected attributes. The results reveal that improving fairness for a single protected attribute can largely decrease fairness regarding unconsidered protected attributes. This decrease is observed in up to 88.3% of scenarios (57.5% on average). More surprisingly, we find little difference in accuracy loss when considering single and multiple protected attributes, indicating that accuracy can be maintained in the multiple-attribute paradigm. However, the effect on precision and recall when handling
    
[^48]: DeepIPCv2：利用LiDAR强化自动驾驶环境感知与导航控制

    DeepIPCv2: LiDAR-powered Robust Environmental Perception and Navigational Control for Autonomous Vehicle. (arXiv:2307.06647v1 [cs.RO])

    [http://arxiv.org/abs/2307.06647](http://arxiv.org/abs/2307.06647)

    DeepIPCv2是一种利用LiDAR传感器感知环境的自动驾驶模型，通过使用点云作为感知输入，在各种条件下实现了更强大的驾驶性能。

    

    我们提出了DeepIPCv2，一种利用LiDAR传感器感知环境的自动驾驶模型，以实现更强大的驾驶性能，特别是在光照条件较差的情况下。DeepIPCv2使用一组LiDAR点云作为其主要感知输入。由于点云不受光照变化的影响，它们可以提供清晰的环境观察，无论条件如何。这使得感知模块能够提供更好的场景理解和稳定的特征，从而支持控制模块准确估计导航控制。为了评估其性能，我们通过部署该模型来预测一组驾驶记录并在三种不同条件下进行真实自动驾驶的测试。我们还进行了消融和比较研究，以证明其性能。基于实验结果，DeepIPCv2在所有条件下均显示出强大的驾驶性能。

    We present DeepIPCv2, an autonomous driving model that perceives the environment using a LiDAR sensor for more robust drivability, especially when driving under poor illumination conditions. DeepIPCv2 takes a set of LiDAR point clouds for its main perception input. As point clouds are not affected by illumination changes, they can provide a clear observation of the surroundings no matter what the condition is. This results in a better scene understanding and stable features provided by the perception module to support the controller module in estimating navigational control properly. To evaluate its performance, we conduct several tests by deploying the model to predict a set of driving records and perform real automated driving under three different conditions. We also conduct ablation and comparative studies with some recent models to justify its performance. Based on the experimental results, DeepIPCv2 shows a robust performance by achieving the best drivability in all conditions. C
    
[^49]: 截断亲和力最大化：用于图形异常监测的单类同型建模

    Truncated Affinity Maximization: One-class Homophily Modeling for Graph Anomaly Detection. (arXiv:2306.00006v1 [cs.SI])

    [http://arxiv.org/abs/2306.00006](http://arxiv.org/abs/2306.00006)

    本文针对图形异常监测数据集中存在的一类同型现象，提出了一种新的无监督异常评分度量——当前节点亲和力，并通过学习量身定制的节点表示，实现了截断亲和力最大化（TAM）方法，优化在原始图形结构上进行，能够有效进行双重One-Class的GAD。

    

    我们在现实世界的图形异常监测（GAD）数据集中经常发现一种普遍的属性......本文提出了一种新的无监督异常评分度量 - 当前节点亲和力......我们进一步提出了截断亲和力最大化 (TAM)，该方法通过最大化与_neighbors的本地亲和力来学习量身定制的节点表示。本文所提方法在原始图形结构上进行优化，可以进行双重One-Class的GAD。

    One prevalent property we find empirically in real-world graph anomaly detection (GAD) datasets is a one-class homophily, i.e., normal nodes tend to have strong connection/affinity with each other, while the homophily in abnormal nodes is significantly weaker than normal nodes. However, this anomaly-discriminative property is ignored by existing GAD methods that are typically built using a conventional anomaly detection objective, such as data reconstruction. In this work, we explore this property to introduce a novel unsupervised anomaly scoring measure for GAD -- local node affinity -- that assigns a larger anomaly score to nodes that are less affiliated with their neighbors, with the affinity defined as similarity on node attributes/representations. We further propose Truncated Affinity Maximization (TAM) that learns tailored node representations for our anomaly measure by maximizing the local affinity of nodes to their neighbors. Optimizing on the original graph structure can be bi
    
[^50]: 稳健的各向异性正则化

    Stable Anisotropic Regularization. (arXiv:2305.19358v1 [cs.CL])

    [http://arxiv.org/abs/2305.19358](http://arxiv.org/abs/2305.19358)

    本文提出了一种新颖的正则化方法I-STAR，可以增加模型的稳定性，提高性能，并改善自然语言处理中的组合表示问题。

    

    鉴于大型语言模型（LLMs）的成功，研究模型激活的属性已引起了相当大的兴趣。文献普遍认为LLMs表示由少数具有极高方差和幅度的“异常维度”主导。自然语言处理（NLP）中的几项研究试图减轻这些异常维度的影响，并迫使LLMs成为各向同性（即在嵌入空间中所有维度具有均匀方差）的。各向同性被认为是LLMs的一种理想属性，可以提高模型性能并更加贴近人类直觉的文本表示。然而，关于NLP中各向同性的许多观点都是基于嵌入的平均余弦相似度，最近已经表明这是一种有缺陷的各向同性度量。在本文中，我们提出了I-STAR：基于IsoScore$^{\star}$的稳定各向异性正则化，这是一种新颖的正则化方法，可以用于增加模型的稳定性并提高性能。

    Given the success of Large Language Models (LLMs), there has been considerable interest in studying the properties of model activations. The literature overwhelmingly agrees that LLM representations are dominated by a few ``outlier dimensions'' with exceedingly high variance and magnitude. Several studies in Natural Language Processing (NLP) have sought to mitigate the impact of such outlier dimensions and force LLMs to be isotropic (i.e., have uniform variance across all dimensions in embedding space). Isotropy is thought to be a desirable property for LLMs that improves model performance and more closely aligns textual representations with human intuition. However, many of the claims regarding isotropy in NLP have been based on the average cosine similarity of embeddings, which has recently been shown to be a flawed measure of isotropy. In this paper, we propose I-STAR: IsoScore$^{\star}$-based STable Anisotropic Regularization, a novel regularization method that can be used to incre
    
[^51]: 集合型信念传播及其在泊松多伯努利SLAM中的应用

    Set-Type Belief Propagation with Applications to Poisson Multi-Bernoulli SLAM. (arXiv:2305.04797v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2305.04797](http://arxiv.org/abs/2305.04797)

    本论文开发了一种适用于具有未知向量元素数量的RFSs的信念传播算法，并将其应用于PMB滤波器用于SLAM，从而导致了集合型BP-mapping、SLAM、多目标跟踪和同时定位与跟踪滤波器等新颖的推理方法。

    

    信念传播是一种有用的概率推理算法，用于高效计算随机变量的近似边缘概率密度。然而，在标准形式下，信念传播只适用于具有固定和已知的向量元素数量的向量型随机变量，而某些应用依赖于具有未知向量元素数量的RFSs。在本文中，我们开发了适用于RFSs序列定义的因子图的信念传播规则，其中每个RFS具有未知的元素数量，旨在导出RFSs的新型推理方法。此外，我们证明了向量型信念传播是集合型信念传播的特例，其中每个RFS遵循伯努利过程。为了证明开发的集合型信念传播的有效性，我们将其应用于SLAM的PMB滤波器，从而自然地导致新的集合型BP映射、SLAM、多目标跟踪和同时定位与跟踪滤波器。最后，我们探讨了向量型信念传播和主题的关系。

    Belief propagation (BP) is a useful probabilistic inference algorithm for efficiently computing approximate marginal probability densities of random variables. However, in its standard form, BP is only applicable to the vector-type random variables with a fixed and known number of vector elements, while certain applications rely on RFSs with an unknown number of vector elements. In this paper, we develop BP rules for factor graphs defined on sequences of RFSs where each RFS has an unknown number of elements, with the intention of deriving novel inference methods for RFSs. Furthermore, we show that vector-type BP is a special case of set-type BP, where each RFS follows the Bernoulli process. To demonstrate the validity of developed set-type BP, we apply it to the PMB filter for SLAM, which naturally leads to new set-type BP-mapping, SLAM, multi-target tracking, and simultaneous localization and tracking filters. Finally, we explore the relationships between the vector-type BP and the pr
    
[^52]: CONSCENDI: 一种反对比且场景引导的蒸馏方法来为虚拟助手构建防护栏模型

    CONSCENDI: A Contrastive and Scenario-Guided Distillation Approach to Guardrail Models for Virtual Assistants. (arXiv:2304.14364v1 [cs.CL])

    [http://arxiv.org/abs/2304.14364](http://arxiv.org/abs/2304.14364)

    本文提出了一种名为CONSCENDI的蒸馏方法，用于构建防护栏模型，以监控任务型虚拟助手的输出。关键方法包括场景增强生成和对比训练样例。这种方法产生了一组多样化的违反规则的对话训练集，并且可以更好地检测代理的输出是否符合设计者指定的规则。

    

    随着GPT-4等越来越强大的语言模型的出现，新一代的基于任务的虚拟助手应运而生。这些对话系统可以根据客户的具体用例进行定制，但确保代理生成的文本仅符合提示指令中设计者指定的规则是具有挑战性的。因此，聊天机器人设计师通常使用另一个称为防护栏模型的模型来验证代理输出是否与其规则和约束对齐。我们探索了使用蒸馏方法来构建防护栏模型，以监控使用GPT-4中的训练数据的第一个模型的输出。我们发现，我们的CONSCENDI过程包括两个关键步骤：场景增强生成和对比训练样例。在生成对话数据时，我们会生成一组违反规则的场景，这些场景列举了违反规则的多样化高级方式。这种场景引导方法产生了一组多样化的违反规则的对话训练集，并且它使得模型更容易检测到代理生成的文本是否符合设计者指定的规则。

    A wave of new task-based virtual assistants has been fueled by increasingly powerful large language models, such as GPT-4. These conversational agents can be customized to serve customer-specific use cases, but ensuring that agent-generated text conforms to designer-specified rules included in prompt instructions alone is challenging. Therefore, chatbot designers often use another model, called a guardrail model, to verify that the agent output aligns with their rules and constraints. We explore using a distillation approach to guardrail models to monitor the output of the first model using training data from GPT-4. We find two crucial steps to our CONSCENDI process: scenario-augmented generation and contrastive training examples. When generating conversational data, we generate a set of rule-breaking scenarios, which enumerate a diverse set of high-level ways a rule can be violated. This scenario-guided approach produces a diverse training set of rule-violating conversations, and it p
    

