# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Interpreting Key Mechanisms of Factual Recall in Transformer-Based Language Models](https://arxiv.org/abs/2403.19521) | 通过深入研究Transformer-based语言模型在事实回忆任务中的机制，我们发现了零/少次样本情况下的特定任务头、MLP层和残差流的功能，以及抗过度自信机制。 |
| [^2] | [FSL Model can Score Higher as It Is](https://arxiv.org/abs/2402.18292) | 为了增加测试期间正确预测的机会，研究旨在通过图像到图像的转换纠正FSL模型的测试输入，生成被测试类别的新样本。 |
| [^3] | [Generalization or Memorization: Data Contamination and Trustworthy Evaluation for Large Language Models](https://arxiv.org/abs/2402.15938) | 本文提出了一种通过LLMs输出分布进行污染检测的方法CDD，以及一种基于LLMs输出修正的可信评估方法TED，以应对大语言模型在数据污染和可信评估方面面临的挑战。 |
| [^4] | [GenTranslate: Large Language Models are Generative Multilingual Speech and Machine Translators](https://arxiv.org/abs/2402.06894) | GenTranslate是一个新的翻译任务生成模型，通过利用大型语言模型的丰富语言知识和强大推理能力，可以从N-best列表中生成更高质量的翻译结果。 |
| [^5] | [Training-Free Consistent Text-to-Image Generation](https://arxiv.org/abs/2402.03286) | 本文提出了一种无需训练的方法ConsiStory，通过共享预训练模型的内部激活，实现了一致的文本到图像生成。引入了主题驱动的共享注意力块和基于对应的特征注入，促进了图像之间的主题一致性，并采用了策略来保持布局多样性。 |
| [^6] | [Lookbehind-SAM: k steps back, 1 step forward](https://arxiv.org/abs/2307.16704) | 本研究提出了一种名为Lookbehind-SAM的方法，通过多次上升步骤和线性插值来增强最大化和最小化过程，以实现更好的损失锐度折衷。实验证明，该方法在各种任务中都有多种优点，包括提高的泛化性能、更高的鲁棒性和改进的学习过程。 |
| [^7] | [A blind spot for large language models: Supradiegetic linguistic information](https://arxiv.org/abs/2306.06794) | 大型语言模型的盲点在于其对超叙事语言信息的忽视，研究提出考虑模型如何感知语言信息有助于深入了解其能力。 |
| [^8] | [Neurosymbolic AI for Reasoning over Knowledge Graphs: A Survey](https://arxiv.org/abs/2302.07200) | 这项综述介绍了神经符号人工智能在知识图谱推理方面的研究。研究表明，最近的方法试图将符号推理和深度学习相结合，以生成具有解释性、竞争性能力并集成专家知识的模型。 |
| [^9] | [HyperSense: Accelerating Hyper-Dimensional Computing for Intelligent Sensor Data Processing.](http://arxiv.org/abs/2401.10267) | HyperSense是一个协同设计的硬件和软件系统，能够根据传感器数据中的物体存在预测有效地控制数据生成速率，通过使用低精度ADC减少冗余数据降低机器学习系统的成本，利用超维度计算的特点分析实时的低精度传感器数据，在处理噪声、以内存为中心和实时学习方面具有优势。该系统结合了高性能的物体检测软件和实时的硬件预测，引入了智能传感器控制的新概念。在软件和硬件评估中表现出卓越的性能。 |
| [^10] | [Querying Easily Flip-flopped Samples for Deep Active Learning.](http://arxiv.org/abs/2401.09787) | 本文提出了一种基于模型的预测不确定性度量，即最小不一致度量（LDM），用于解决复杂决策边界情况下的主动学习问题。通过查询具有最小LDM的未标记数据，可以提高深度学习模型的性能。 |
| [^11] | [What makes for a 'good' social actor? Using respect as a lens to evaluate interactions with language agents.](http://arxiv.org/abs/2401.09082) | 本文研究以尊重为视角评估与语言代理的交互，提出了一种更加关注关系和情境因素的伦理方法，旨在帮助LLM技术表现得“好” |
| [^12] | [NID-SLAM: Neural Implicit Representation-based RGB-D SLAM in dynamic environments.](http://arxiv.org/abs/2401.01189) | NID-SLAM是一种基于神经隐式表示的RGB-D SLAM算法，它通过提升语义掩膜中的不准确区域和引入关键帧选择策略，显著改善了在动态环境下的性能，提高了跟踪精度和建图质量。 |
| [^13] | [Testing learning-enabled cyber-physical systems with Large-Language Models: A Formal Approach.](http://arxiv.org/abs/2311.07377) | 本研究对学习增强型物联网系统的测试进行了形式化方法的探索，以应对当前测试方法的局限性。 |
| [^14] | [GOPlan: Goal-conditioned Offline Reinforcement Learning by Planning with Learned Models.](http://arxiv.org/abs/2310.20025) | GOPlan是一个使用学习模型进行计划的目标条件下的离线强化学习方法，通过预训练先验策略和使用重新分析方法生成虚构轨迹，用以提高性能和处理有限数据预算和未见目标泛化的能力。 |
| [^15] | [Incremental Learning of Humanoid Robot Behavior from Natural Interaction and Large Language Models.](http://arxiv.org/abs/2309.04316) | 本文提出了一个从自然互动中实现复杂行为增量学习的系统，并演示了在一个人形机器人上的应用。该系统利用大型语言模型对机器人的行为进行高级协调，通过交互式控制台生成Python语句来调用机器人的感知和动作，并通过将人类指令、环境观测和执行结果反馈给语言模型来实现循环交互。 |
| [^16] | [MIMIC: Masked Image Modeling with Image Correspondences.](http://arxiv.org/abs/2306.15128) | MIMIC是一种基于图像对应关系的遮蔽图像建模方法，通过挖掘不需要任何注释的数据集，使用多个自监督模型进行训练，达到了在多个下游任务上优于使用注释挖掘的表示的效果。 |
| [^17] | [MagicBrush: A Manually Annotated Dataset for Instruction-Guided Image Editing.](http://arxiv.org/abs/2306.10012) | MagicBrush是第一个大规模的手动标注的数据集，用于指导真实图像的编辑。它包括超过10K个手动标注的三元组，支持大规模的文本指导图像编辑模型训练。在此数据集上微调InstructPix2Pix可以根据人类评估提供更好的图像。 |

# 详细

[^1]: 解释基于Transformer模型的语言模型在事实回忆中的关键机制

    Interpreting Key Mechanisms of Factual Recall in Transformer-Based Language Models

    [https://arxiv.org/abs/2403.19521](https://arxiv.org/abs/2403.19521)

    通过深入研究Transformer-based语言模型在事实回忆任务中的机制，我们发现了零/少次样本情况下的特定任务头、MLP层和残差流的功能，以及抗过度自信机制。

    

    本文深入探讨了Transformer-based语言模型在事实回忆任务中所采用的机制。在零次样本情况下，给定类似“法国的首都是”的提示，特定任务的注意力头会从上下文中提取主题实体，如“法国”，并将其传递给后续的MLP以回忆所需的答案，如“巴黎”。我们引入了一种新颖的分析方法，旨在将MLP的输出分解为人类可理解的组件。通过这种方法，我们量化了跟随这些特定任务头的MLP层的功能。在残差流中，它会擦除或放大来自各个头的信息。此外，它会生成一个组件，将残差流重新定向到预期答案的方向。这些零次机制也适用于少次样本情况。此外，我们观察到一种广泛存在的抗过度自信机制。

    arXiv:2403.19521v1 Announce Type: cross  Abstract: In this paper, we deeply explore the mechanisms employed by Transformer-based language models in factual recall tasks. In zero-shot scenarios, given a prompt like "The capital of France is," task-specific attention heads extract the topic entity, such as "France," from the context and pass it to subsequent MLPs to recall the required answer such as "Paris." We introduce a novel analysis method aimed at decomposing the outputs of the MLP into components understandable by humans. Through this method, we quantify the function of the MLP layer following these task-specific heads. In the residual stream, it either erases or amplifies the information originating from individual heads. Moreover, it generates a component that redirects the residual stream towards the direction of its expected answer. These zero-shot mechanisms are also employed in few-shot scenarios. Additionally, we observed a widely existent anti-overconfidence mechanism in 
    
[^2]: FSL模型可以因为其优越性得分更高

    FSL Model can Score Higher as It Is

    [https://arxiv.org/abs/2402.18292](https://arxiv.org/abs/2402.18292)

    为了增加测试期间正确预测的机会，研究旨在通过图像到图像的转换纠正FSL模型的测试输入，生成被测试类别的新样本。

    

    在日常生活中，为了增加被正确识别的机会，我们倾向于面对面地直视面部识别机，而不是侧着面对。少样本学习（FSL）分类本身就具有挑战性，因为模型必须识别属于训练时未见的类别的图像。因此，在测试期间对扭曲和非典型的查询或支持图像会让模型更难正确预测。在我们的研究中，为了增加测试期间正确预测的机会，我们旨在通过图像到图像的转换纠正训练过的FSL模型的测试输入，生成被测试类别的新样本。FSL模型通常是在具有足够样本的类别上进行训练，然后在具有少样本样本的类别上进行测试。我们提出的方法首先捕捉测试图像的风格或形状，然后识别一个适当的训

    arXiv:2402.18292v1 Announce Type: cross  Abstract: In daily life, we tend to present the front of our faces by staring squarely at a facial recognition machine, instead of facing it sideways, in order to increase the chance of being correctly recognised. Few-shot-learning (FSL) classification is challenging in itself because a model has to identify images that belong to classes previously unseen during training. Therefore, a warped and non-typical query or support image during testing can make it even more challenging for a model to predict correctly. In our work, to increase the chance of correct prediction during testing, we aim to rectify the test input of a trained FSL model by generating new samples of the tested classes through image-to-image translation. An FSL model is usually trained on classes with sufficient samples, and then tested on classes with few-shot samples. Our proposed method first captures the style or shape of the test image, and then identifies a suitable traine
    
[^3]: 大语言模型的泛化或记忆：数据污染与可信评估

    Generalization or Memorization: Data Contamination and Trustworthy Evaluation for Large Language Models

    [https://arxiv.org/abs/2402.15938](https://arxiv.org/abs/2402.15938)

    本文提出了一种通过LLMs输出分布进行污染检测的方法CDD，以及一种基于LLMs输出修正的可信评估方法TED，以应对大语言模型在数据污染和可信评估方面面临的挑战。

    

    最近关于大语言模型（LLMs）令人印象深刻能力的说法通常是通过在开放获取的基准上进行评估来支持的。考虑到LLMs的训练数据的庞大规模和广泛来源，它可能明确或隐含地包含测试数据，导致LLMs更容易受到数据污染的影响。然而，由于训练数据的不透明性、模型的黑盒访问以及合成训练数据的快速增长，对于LLMs来说检测和减轻数据污染面临着重大挑战。在本文中，我们提出了CDD，即通过LLMs输出分布进行污染检测的CDD。CDD仅需要采样文本来检测数据污染，通过识别LLMs输出分布的峰值来进行检测。为了减轻评估中数据污染的影响，我们还提出了TED：基于LLMs输出修正的可信评估。

    arXiv:2402.15938v1 Announce Type: cross  Abstract: Recent statements about the impressive capabilities of large language models (LLMs) are usually supported by evaluating on open-access benchmarks. Considering the vast size and wide-ranging sources of LLMs' training data, it could explicitly or implicitly include test data, leading to LLMs being more susceptible to data contamination. However, due to the opacity of training data, the black-box access of models, and the rapid growth of synthetic training data, detecting and mitigating data contamination for LLMs faces significant challenges. In this paper, we propose CDD, which stands for Contamination Detection via output Distribution for LLMs. CDD necessitates only the sampled texts to detect data contamination, by identifying the peakedness of LLM's output distribution. To mitigate the impact of data contamination in evaluation, we also present TED: Trustworthy Evaluation via output Distribution, based on the correction of LLM's outp
    
[^4]: GenTranslate: 大型语言模型是生成的多语言语音和机器翻译工具

    GenTranslate: Large Language Models are Generative Multilingual Speech and Machine Translators

    [https://arxiv.org/abs/2402.06894](https://arxiv.org/abs/2402.06894)

    GenTranslate是一个新的翻译任务生成模型，通过利用大型语言模型的丰富语言知识和强大推理能力，可以从N-best列表中生成更高质量的翻译结果。

    

    大型语言模型（LLMs）的最新进展通过减少表示误差和引入外部知识，推动了多语言语音和机器翻译的发展。然而，翻译任务通常使用束搜索解码和前k个假设选择进行推理。这些技术往往不能充分利用多样化的N-best假设中的丰富信息，使得它们在需要单个高质量输出序列的翻译任务中效果不佳。在本文中，我们提出了一个新的翻译任务生成模型，即“GenTranslate”，它基于LLMs来从N-best列表中生成更好的结果。利用LLMs丰富的语言知识和强大的推理能力，我们的新模型可以将N-best候选人中的丰富信息整合起来，生成更高质量的翻译结果。此外，为了支持LLM的微调，我们构建并发布了一个HypoTransla模型。

    Recent advances in large language models (LLMs) have stepped forward the development of multilingual speech and machine translation by its reduced representation errors and incorporated external knowledge. However, both translation tasks typically utilize beam search decoding and top-1 hypothesis selection for inference. These techniques struggle to fully exploit the rich information in the diverse N-best hypotheses, making them less optimal for translation tasks that require a single, high-quality output sequence. In this paper, we propose a new generative paradigm for translation tasks, namely "GenTranslate", which builds upon LLMs to generate better results from the diverse translation versions in N-best list. Leveraging the rich linguistic knowledge and strong reasoning abilities of LLMs, our new paradigm can integrate the rich information in N-best candidates to generate a higher-quality translation result. Furthermore, to support LLM finetuning, we build and release a HypoTransla
    
[^5]: 无需训练的一致性文本到图像生成

    Training-Free Consistent Text-to-Image Generation

    [https://arxiv.org/abs/2402.03286](https://arxiv.org/abs/2402.03286)

    本文提出了一种无需训练的方法ConsiStory，通过共享预训练模型的内部激活，实现了一致的文本到图像生成。引入了主题驱动的共享注意力块和基于对应的特征注入，促进了图像之间的主题一致性，并采用了策略来保持布局多样性。

    

    文本到图像模型通过自然语言引导图像生成过程，提供了一种新的创造性灵活性。然而，使用这些模型在多样化的提示下一致地描绘相同的主题仍然具有挑战性。现有方法通过优化模型来教授它描述特定用户提供主题的新词汇或者为模型添加图像条件。这些方法要求针对每个主题进行漫长的优化或进行大规模预训练。此外，它们在将生成的图像与文本提示对齐和描绘多个主题方面遇到困难。在这里，我们介绍了一种无训练方法ConsiStory，通过共享预训练模型的内部激活来实现一致的主题生成。我们引入了一个主题驱动共享注意力块和基于对应的特征注入，以促进图像之间的主题一致性。此外，我们开发了策略以鼓励布局多样性，同时保持主题一致性。

    Text-to-image models offer a new level of creative flexibility by allowing users to guide the image generation process through natural language. However, using these models to consistently portray the same subject across diverse prompts remains challenging. Existing approaches fine-tune the model to teach it new words that describe specific user-provided subjects or add image conditioning to the model. These methods require lengthy per-subject optimization or large-scale pre-training. Moreover, they struggle to align generated images with text prompts and face difficulties in portraying multiple subjects. Here, we present ConsiStory, a training-free approach that enables consistent subject generation by sharing the internal activations of the pretrained model. We introduce a subject-driven shared attention block and correspondence-based feature injection to promote subject consistency between images. Additionally, we develop strategies to encourage layout diversity while maintaining su
    
[^6]: Lookbehind-SAM: k步回望，1步前进

    Lookbehind-SAM: k steps back, 1 step forward

    [https://arxiv.org/abs/2307.16704](https://arxiv.org/abs/2307.16704)

    本研究提出了一种名为Lookbehind-SAM的方法，通过多次上升步骤和线性插值来增强最大化和最小化过程，以实现更好的损失锐度折衷。实验证明，该方法在各种任务中都有多种优点，包括提高的泛化性能、更高的鲁棒性和改进的学习过程。

    

    锐度感知优化（SAM）方法通过将最小化损失值和损失锐度问题表述为极小极大型目标，得到了越来越多的关注。在本研究中，我们增加了SAM目标中最大化和最小化部分的效率，以实现更好的损失锐度折衷。受Lookahead优化器的启发，该优化器使用多个向前的下降步骤，我们提出了Lookbehind，它在后面执行多个上升步骤，增强了SAM的最大化步骤，并找到了一个具有更高损失的最坏情况扰动。然后，为了减小由于收集到的多个上升步骤的梯度所引起的下降步骤的方差，我们采用线性插值来改进最小化过程。Lookbehind在各种任务中带来了许多好处。特别是，我们展示了提高的泛化性能，对噪声权重的更高鲁棒性，以及在学习过程中改进的效果和较少的灾难性遗忘。

    Sharpness-aware minimization (SAM) methods have gained increasing popularity by formulating the problem of minimizing both loss value and loss sharpness as a minimax objective. In this work, we increase the efficiency of the maximization and minimization parts of SAM's objective to achieve a better loss-sharpness trade-off. By taking inspiration from the Lookahead optimizer, which uses multiple descent steps ahead, we propose Lookbehind, which performs multiple ascent steps behind to enhance the maximization step of SAM and find a worst-case perturbation with higher loss. Then, to mitigate the variance in the descent step arising from the gathered gradients across the multiple ascent steps, we employ linear interpolation to refine the minimization step. Lookbehind leads to a myriad of benefits across a variety of tasks. Particularly, we show increased generalization performance, greater robustness against noisy weights, as well as improved learning and less catastrophic forgetting in l
    
[^7]: 大型语言模型的盲点：超叙事语言信息

    A blind spot for large language models: Supradiegetic linguistic information

    [https://arxiv.org/abs/2306.06794](https://arxiv.org/abs/2306.06794)

    大型语言模型的盲点在于其对超叙事语言信息的忽视，研究提出考虑模型如何感知语言信息有助于深入了解其能力。

    

    像ChatGPT这样的大型语言模型(LLMs)反映了人工智能领域的深刻变革，实现了令人印象深刻甚至令人震惊的类人语言流利度。它们目前和潜在的能力范围是一个积极探讨的领域，绝非仅限于科研人员。人们通常将LLMs的训练数据框定为“文本”甚至“语言”。我们使用来自语言学、体现认知、认知科学、数学和历史等领域的思想，仔细审视这一框架的细节。我们提出，考虑像ChatGPT这样的LLM是什么感觉，正如纳格尔可能会说的那样，可以帮助我们深入了解其整体能力，特别是，其接受的语言训练数据可以被有益地重新构思为对语言中编码的叙事信息的接触，其缺陷可以被重新构思为对这些信息的无知。

    arXiv:2306.06794v2 Announce Type: replace-cross  Abstract: Large Language Models (LLMs) like ChatGPT reflect profound changes in the field of Artificial Intelligence, achieving a linguistic fluency that is impressively, even shockingly, human-like. The extent of their current and potential capabilities is an active area of investigation by no means limited to scientific researchers. It is common for people to frame the training data for LLMs as "text" or even "language". We examine the details of this framing using ideas from several areas, including linguistics, embodied cognition, cognitive science, mathematics, and history. We propose that considering what it is like to be an LLM like ChatGPT, as Nagel might have put it, can help us gain insight into its capabilities in general, and in particular, that its exposure to linguistic training data can be productively reframed as exposure to the diegetic information encoded in language, and its deficits can be reframed as ignorance of ext
    
[^8]: 知识图谱推理的神经符号人工智能：一项综述

    Neurosymbolic AI for Reasoning over Knowledge Graphs: A Survey

    [https://arxiv.org/abs/2302.07200](https://arxiv.org/abs/2302.07200)

    这项综述介绍了神经符号人工智能在知识图谱推理方面的研究。研究表明，最近的方法试图将符号推理和深度学习相结合，以生成具有解释性、竞争性能力并集成专家知识的模型。

    

    神经符号人工智能是一个日益活跃的研究领域，它将符号推理方法与深度学习相结合，以利用它们的互补优势。随着知识图谱成为表示异构和多关系数据的一种流行方式，对图结构进行推理的方法开始遵循这种神经符号范式。传统上，这些方法要么利用基于规则的推理，要么生成代表性的数值嵌入，从中可以提取出模式。然而，最近的一些研究尝试弥合这种二元对立，提出了能够促进可解释性、保持竞争性能力并集成专家知识的模型。因此，我们调查了在知识图谱上执行神经符号推理任务的方法，并提出了一种新的分类法。具体而言，我们提出了三个主要类别：（1）逻辑信息嵌入方法，（2）基于嵌入的方法与逻辑一致的方法

    Neurosymbolic AI is an increasingly active area of research that combines symbolic reasoning methods with deep learning to leverage their complementary benefits. As knowledge graphs are becoming a popular way to represent heterogeneous and multi-relational data, methods for reasoning on graph structures have attempted to follow this neurosymbolic paradigm. Traditionally, such approaches have utilized either rule-based inference or generated representative numerical embeddings from which patterns could be extracted. However, several recent studies have attempted to bridge this dichotomy to generate models that facilitate interpretability, maintain competitive performance, and integrate expert knowledge. Therefore, we survey methods that perform neurosymbolic reasoning tasks on knowledge graphs and propose a novel taxonomy by which we can classify them. Specifically, we propose three major categories: (1) logically-informed embedding approaches, (2) embedding approaches with logical cons
    
[^9]: HyperSense: 加速超维度计算以用于智能传感器数据处理

    HyperSense: Accelerating Hyper-Dimensional Computing for Intelligent Sensor Data Processing. (arXiv:2401.10267v1 [cs.AR])

    [http://arxiv.org/abs/2401.10267](http://arxiv.org/abs/2401.10267)

    HyperSense是一个协同设计的硬件和软件系统，能够根据传感器数据中的物体存在预测有效地控制数据生成速率，通过使用低精度ADC减少冗余数据降低机器学习系统的成本，利用超维度计算的特点分析实时的低精度传感器数据，在处理噪声、以内存为中心和实时学习方面具有优势。该系统结合了高性能的物体检测软件和实时的硬件预测，引入了智能传感器控制的新概念。在软件和硬件评估中表现出卓越的性能。

    

    引入HyperSense，我们协同设计的硬件和软件系统根据传感器数据中的物体存在预测有效地控制模拟到数字转换器（ADC）模块的数据生成速率。针对不断增加的传感器数量和数据速率所带来的挑战，HyperSense使用高效的低精度ADC减少冗余的数字数据，降低了机器学习系统的成本。利用神经启发的超维度计算（HDC），HyperSense分析实时的原始低精度传感器数据，在处理噪声、以内存为中心和实时学习方面具有优势。我们提出的HyperSense模型将高性能的物体检测软件与实时的硬件预测结合起来，引入了智能传感器控制的新概念。全面的软件和硬件评估展示了我们解决方案的卓越性能，通过最高的曲线下面积（AUC）和最陡的接收器操作特性（ROC）曲线证明了这一点。

    Introducing HyperSense, our co-designed hardware and software system efficiently controls Analog-to-Digital Converter (ADC) modules' data generation rate based on object presence predictions in sensor data. Addressing challenges posed by escalating sensor quantities and data rates, HyperSense reduces redundant digital data using energy-efficient low-precision ADC, diminishing machine learning system costs. Leveraging neurally-inspired HyperDimensional Computing (HDC), HyperSense analyzes real-time raw low-precision sensor data, offering advantages in handling noise, memory-centricity, and real-time learning.  Our proposed HyperSense model combines high-performance software for object detection with real-time hardware prediction, introducing the novel concept of Intelligent Sensor Control. Comprehensive software and hardware evaluations demonstrate our solution's superior performance, evidenced by the highest Area Under the Curve (AUC) and sharpest Receiver Operating Characteristic (ROC
    
[^10]: 查询易于翻转样本的深度主动学习

    Querying Easily Flip-flopped Samples for Deep Active Learning. (arXiv:2401.09787v1 [cs.LG])

    [http://arxiv.org/abs/2401.09787](http://arxiv.org/abs/2401.09787)

    本文提出了一种基于模型的预测不确定性度量，即最小不一致度量（LDM），用于解决复杂决策边界情况下的主动学习问题。通过查询具有最小LDM的未标记数据，可以提高深度学习模型的性能。

    

    主动学习是一种机器学习范式，旨在通过选择和查询未标记数据来提高模型的性能。一种有效的选择策略是基于模型的预测不确定性，这可以解释为样本的信息量度量。样本到决策边界的距离是一种自然的预测不确定性度量，但通常难以计算，特别是对于多类分类任务中形成的复杂决策边界。为了解决这个问题，本文提出了“最小不一致度量”（LDM），定义为预测标签不一致的最小概率，并且证明了LDM的估计器在温和假设下是渐近一致的。该估计器计算效率高，并且可以通过参数扰动轻松实现在深度学习模型中使用。基于LDM的主动学习通过查询具有最小LDM的未标记数据来执行。

    Active learning is a machine learning paradigm that aims to improve the performance of a model by strategically selecting and querying unlabeled data. One effective selection strategy is to base it on the model's predictive uncertainty, which can be interpreted as a measure of how informative a sample is. The sample's distance to the decision boundary is a natural measure of predictive uncertainty, but it is often intractable to compute, especially for complex decision boundaries formed in multiclass classification tasks. To address this issue, this paper proposes the {\it least disagree metric} (LDM), defined as the smallest probability of disagreement of the predicted label, and an estimator for LDM proven to be asymptotically consistent under mild assumptions. The estimator is computationally efficient and can be easily implemented for deep learning models using parameter perturbation. The LDM-based active learning is performed by querying unlabeled data with the smallest LDM. Exper
    
[^11]: 什么是“好”的社交行为者？以尊重为视角评估与语言代理的交互

    What makes for a 'good' social actor? Using respect as a lens to evaluate interactions with language agents. (arXiv:2401.09082v1 [cs.CL])

    [http://arxiv.org/abs/2401.09082](http://arxiv.org/abs/2401.09082)

    本文研究以尊重为视角评估与语言代理的交互，提出了一种更加关注关系和情境因素的伦理方法，旨在帮助LLM技术表现得“好”

    

    随着基于大型语言模型（LLM）的对话代理越来越受欢迎，如何确保它们的行为道德和适当性已经引起了紧急关注。从“HHH”标准的角度来看，这主要体现在让输出更有帮助和诚实，并避免有害（有偏见、有毒或不准确）的陈述。虽然这种语义焦点对于将LLM代理视为纯粹的信息媒介是有用的，但它未能考虑到在不同社交情境中，同样的话语可能会显得更或者更少冒犯或不得体的实际因素。我们提出了一种更加关注关系和情境因素的伦理方法，探讨作为社交行为者的系统如何在交互中以尊重的方式对待个体。我们的工作预见了在情境交互层面上一系列尚未被探索的风险，并提供了实用建议，以帮助LLM技术表现得“好”

    With the growing popularity of dialogue agents based on large language models (LLMs), urgent attention has been drawn to finding ways to ensure their behaviour is ethical and appropriate. These are largely interpreted in terms of the 'HHH' criteria: making outputs more helpful and honest, and avoiding harmful (biased, toxic, or inaccurate) statements. Whilst this semantic focus is useful from the perspective of viewing LLM agents as mere mediums for information, it fails to account for pragmatic factors that can make the same utterance seem more or less offensive or tactless in different social situations. We propose an approach to ethics that is more centred on relational and situational factors, exploring what it means for a system, as a social actor, to treat an individual respectfully in a (series of) interaction(s). Our work anticipates a set of largely unexplored risks at the level of situated interaction, and offers practical suggestions to help LLM technologies behave as 'good'
    
[^12]: NID-SLAM: 基于神经隐式表示的动态环境RGB-D SLAM

    NID-SLAM: Neural Implicit Representation-based RGB-D SLAM in dynamic environments. (arXiv:2401.01189v1 [cs.RO])

    [http://arxiv.org/abs/2401.01189](http://arxiv.org/abs/2401.01189)

    NID-SLAM是一种基于神经隐式表示的RGB-D SLAM算法，它通过提升语义掩膜中的不准确区域和引入关键帧选择策略，显著改善了在动态环境下的性能，提高了跟踪精度和建图质量。

    

    神经隐式表示已被用于增强视觉SLAM算法，特别是提供高保真密集地图方面。现有的方法在静态场景下运作良好，但在移动物体造成的干扰下困难重重。在本文中，我们提出了NID-SLAM，在动态环境中显著改善了神经SLAM的性能。我们提出了一种新的方法，以增强语义掩膜中的不准确区域，特别是边缘区域。利用深度图像中的几何信息，这种方法能够精确地去除动态物体，从而降低相机漂移的概率。此外，我们引入了一种适用于动态场景的关键帧选择策略，增强了相机跟踪对大尺度物体的鲁棒性，并提高了建图的效率。在公开可用的RGB-D数据集上的实验证明，我们的方法在跟踪精度和建图质量上优于竞争性的神经SLAM方法。

    Neural implicit representations have been explored to enhance visual SLAM algorithms, especially in providing high-fidelity dense map. Existing methods operate robustly in static scenes but struggle with the disruption caused by moving objects. In this paper we present NID-SLAM, which significantly improves the performance of neural SLAM in dynamic environments. We propose a new approach to enhance inaccurate regions in semantic masks, particularly in marginal areas. Utilizing the geometric information present in depth images, this method enables accurate removal of dynamic objects, thereby reducing the probability of camera drift. Additionally, we introduce a keyframe selection strategy for dynamic scenes, which enhances camera tracking robustness against large-scale objects and improves the efficiency of mapping. Experiments on publicly available RGB-D datasets demonstrate that our method outperforms competitive neural SLAM approaches in tracking accuracy and mapping quality in dynam
    
[^13]: 使用大型语言模型对学习增强型的物联网系统进行测试：一种形式化方法

    Testing learning-enabled cyber-physical systems with Large-Language Models: A Formal Approach. (arXiv:2311.07377v2 [cs.SE] UPDATED)

    [http://arxiv.org/abs/2311.07377](http://arxiv.org/abs/2311.07377)

    本研究对学习增强型物联网系统的测试进行了形式化方法的探索，以应对当前测试方法的局限性。

    

    将机器学习（ML）整合到物联网系统（CPS）中，可以带来显著的好处，包括增强效率、预测能力、实时响应和实现自主运行。这种融合加速了一系列真实世界应用的开发和部署，例如自动驾驶车辆、送货无人机、服务机器人和远程医疗程序。然而，人工智能增强的CPS的软件开发生命周期（SDLC）与传统方法存在明显的差异，具有数据和学习作为两个关键组成部分。现有的验证和验证技术常常不足以应对这些新的范式。本研究旨在确定确保学习增强型CPS形式化安全性的主要挑战。我们首先考察了作为验证和验证最实用方法的测试，总结了当前最先进的方法论。认识到当前测试方法的局限性

    The integration of machine learning (ML) into cyber-physical systems (CPS) offers significant benefits, including enhanced efficiency, predictive capabilities, real-time responsiveness, and the enabling of autonomous operations. This convergence has accelerated the development and deployment of a range of real-world applications, such as autonomous vehicles, delivery drones, service robots, and telemedicine procedures. However, the software development life cycle (SDLC) for AI-infused CPS diverges significantly from traditional approaches, featuring data and learning as two critical components. Existing verification and validation techniques are often inadequate for these new paradigms. In this study, we pinpoint the main challenges in ensuring formal safety for learningenabled CPS.We begin by examining testing as the most pragmatic method for verification and validation, summarizing the current state-of-the-art methodologies. Recognizing the limitations in current testing approaches t
    
[^14]: GOPlan:通过学习模型进行计划的目标条件下的离线强化学习

    GOPlan: Goal-conditioned Offline Reinforcement Learning by Planning with Learned Models. (arXiv:2310.20025v1 [cs.LG])

    [http://arxiv.org/abs/2310.20025](http://arxiv.org/abs/2310.20025)

    GOPlan是一个使用学习模型进行计划的目标条件下的离线强化学习方法，通过预训练先验策略和使用重新分析方法生成虚构轨迹，用以提高性能和处理有限数据预算和未见目标泛化的能力。

    

    离线目标条件下的强化学习（GCRL）为从多样化和多任务的离线数据集中学习通用策略提供了可行的范例。尽管近期取得了显著进展，但主导的离线GCRL方法仍然受限于无模型方法，限制了它们应对有限数据预算和未见目标泛化的能力。在这项工作中，我们提出了一种新的两阶段模型为基础的框架，Goal-conditioned Offline Planning（GOPlan），包括（1）预训练一个能够捕捉多目标数据集中多模态动作分布的先验策略；（2）利用规划的重新分析方法为微调策略生成虚构轨迹。具体而言，先验策略基于一个具有明显模式分离的带优势权重的条件生成对抗网络，以克服超出分布（OOD）动作的缺点。为进一步优化策略，重新分析方法通过规划生成高质量的虚构数据。

    Offline goal-conditioned RL (GCRL) offers a feasible paradigm to learn general-purpose policies from diverse and multi-task offline datasets. Despite notable recent progress, the predominant offline GCRL methods have been restricted to model-free approaches, constraining their capacity to tackle limited data budgets and unseen goal generalization. In this work, we propose a novel two-stage model-based framework, Goal-conditioned Offline Planning (GOPlan), including (1) pretraining a prior policy capable of capturing multi-modal action distribution within the multi-goal dataset; (2) employing the reanalysis method with planning to generate imagined trajectories for funetuning policies. Specifically, the prior policy is based on an advantage-weighted Conditioned Generative Adversarial Networks that exhibits distinct mode separation to overcome the pitfalls of out-of-distribution (OOD) actions. For further policy optimization, the reanalysis method generates high-quality imaginary data by
    
[^15]: 从自然互动和大型语言模型中增量学习人形机器人行为

    Incremental Learning of Humanoid Robot Behavior from Natural Interaction and Large Language Models. (arXiv:2309.04316v1 [cs.RO])

    [http://arxiv.org/abs/2309.04316](http://arxiv.org/abs/2309.04316)

    本文提出了一个从自然互动中实现复杂行为增量学习的系统，并演示了在一个人形机器人上的应用。该系统利用大型语言模型对机器人的行为进行高级协调，通过交互式控制台生成Python语句来调用机器人的感知和动作，并通过将人类指令、环境观测和执行结果反馈给语言模型来实现循环交互。

    

    自然语言对话对于直观的人机交互至关重要。它不仅可以用来表达人类的意图，而且还可以用来传达指令以改进机器人对命令的理解。非常重要的是要赋予机器人从这种交互经验中增量学习的能力，以使它们能够改进自己的行为或避免未来的错误。本文提出了一个从自然互动中实现复杂行为增量学习的系统，并在一个人形机器人上演示其实现。基于最新的进展，我们提出了一个使用大型语言模型（Large Language Models，LLMs）进行机器人行为的高层协调的系统，这个系统的思想是让LLM在交互式控制台中生成Python语句来调用机器人的感知和动作。通过将人类指令、环境观测和执行结果反馈给LLM来关闭交互循环。

    Natural-language dialog is key for intuitive human-robot interaction. It can be used not only to express humans' intents, but also to communicate instructions for improvement if a robot does not understand a command correctly. Of great importance is to endow robots with the ability to learn from such interaction experience in an incremental way to allow them to improve their behaviors or avoid mistakes in the future. In this paper, we propose a system to achieve incremental learning of complex behavior from natural interaction, and demonstrate its implementation on a humanoid robot. Building on recent advances, we present a system that deploys Large Language Models (LLMs) for high-level orchestration of the robot's behavior, based on the idea of enabling the LLM to generate Python statements in an interactive console to invoke both robot perception and action. The interaction loop is closed by feeding back human instructions, environment observations, and execution results to the LLM, 
    
[^16]: MIMIC: 基于图像对应关系的遮蔽图像建模

    MIMIC: Masked Image Modeling with Image Correspondences. (arXiv:2306.15128v1 [cs.CV])

    [http://arxiv.org/abs/2306.15128](http://arxiv.org/abs/2306.15128)

    MIMIC是一种基于图像对应关系的遮蔽图像建模方法，通过挖掘不需要任何注释的数据集，使用多个自监督模型进行训练，达到了在多个下游任务上优于使用注释挖掘的表示的效果。

    

    许多像素级的密集预测任务——如计算机视觉中的深度估计和语义分割——如今依赖于预训练的图像表示。因此，筛选有效的预训练数据集至关重要。不幸的是，有效的预训练数据集仅通过模拟环境中的带有注释的3D网格、点云和相机参数筛选而来，并不具备多视角场景。我们提出了一种不需要任何注释的数据集筛选机制。我们从开源视频数据集和合成的3D环境中挖掘了两个数据集：MIMIC-1M(包含1.3M个多视角图像对)和MIMIC-3M(包含3.1M个多视角图像对)。我们使用多个自监督模型进行训练，采用不同的遮蔽图像建模目标，展示了以下发现：在多个下游任务中，基于MIMIC-3M训练的表示优于使用注释挖掘的表示，包括深度估计、语义分割、表面法线和姿态估计等。

    Many pixelwise dense prediction tasks-depth estimation and semantic segmentation in computer vision today rely on pretrained image representations. Therefore, curating effective pretraining datasets is vital. Unfortunately, the effective pretraining datasets are those with multi-view scenes and have only been curated using annotated 3D meshes, point clouds, and camera parameters from simulated environments. We propose a dataset-curation mechanism that does not require any annotations. We mine two datasets: MIMIC-1M with 1.3M and MIMIC-3M with 3.1M multi-view image pairs from open-sourced video datasets and from synthetic 3D environments. We train multiple self-supervised models with different masked image modeling objectives to showcase the following findings: Representations trained on MIMIC-3M outperform those mined using annotations on multiple downstream tasks, including depth estimation, semantic segmentation, surface normals, and pose estimation. They also outperform representati
    
[^17]: MagicBrush: 人工标注的用于指导图像编辑的数据集

    MagicBrush: A Manually Annotated Dataset for Instruction-Guided Image Editing. (arXiv:2306.10012v1 [cs.CV])

    [http://arxiv.org/abs/2306.10012](http://arxiv.org/abs/2306.10012)

    MagicBrush是第一个大规模的手动标注的数据集，用于指导真实图像的编辑。它包括超过10K个手动标注的三元组，支持大规模的文本指导图像编辑模型训练。在此数据集上微调InstructPix2Pix可以根据人类评估提供更好的图像。

    

    文本指导的图像编辑从个人使用到专业应用（如Photoshop）广泛需要。然而，现有的方法要么是零样本，要么是在自动合成的数据集上进行训练，其中含有大量的噪声。因此，它们在实践中仍需要大量的手动调整才能产生理想的结果。为了解决这个问题，我们介绍了MagicBrush，第一个大规模的手动标注的数据集，用于指导真实图像的编辑，包括单个操作、多个操作、提供掩码和不提供掩码等不同场景。MagicBrush包括超过10K个手动标注的三元组（源图像，指令，目标图像），支持大规模的文本指导图像编辑模型训练。我们在MagicBrush上微调InstructPix2Pix，并展示了新模型可以根据人类评估提供更好的图像。我们还进行了广泛的实验评估，以评估模型的泛化能力和使用效果。

    Text-guided image editing is widely needed in daily life, ranging from personal use to professional applications such as Photoshop. However, existing methods are either zero-shot or trained on an automatically synthesized dataset, which contains a high volume of noise. Thus, they still require lots of manual tuning to produce desirable outcomes in practice. To address this issue, we introduce MagicBrush (https://osu-nlp-group.github.io/MagicBrush/), the first large-scale, manually annotated dataset for instruction-guided real image editing that covers diverse scenarios: single-turn, multi-turn, mask-provided, and mask-free editing. MagicBrush comprises over 10K manually annotated triples (source image, instruction, target image), which supports trainining large-scale text-guided image editing models. We fine-tune InstructPix2Pix on MagicBrush and show that the new model can produce much better images according to human evaluation. We further conduct extensive experiments to evaluate cu
    

