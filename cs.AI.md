# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Open-source Frame Semantic Parsing.](http://arxiv.org/abs/2303.12788) | 本文介绍了一个开源Python库Frame Semantic Transformer，该库用于框架语义解析，并在易用性和性能方面实现接近最新水平，可通过在推理时使用FrameNet词汇单元来提高性能，并通过在训练期间使用文本数据增强来提高对真实世界数据的稳健性。 |
| [^2] | [Matryoshka Policy Gradient for Entropy-Regularized RL: Convergence and Global Optimality.](http://arxiv.org/abs/2303.12785) | 本文介绍了一种新的策略梯度算法——莫特里卡多策略梯度(MPG)，该算法尤其在最大熵强化学习中表现突出，能够实现一系列策略的训练和学习以达到任务的最优化，具有极高的收敛性和全局最优性。 |
| [^3] | [Conformal Prediction for Time Series with Modern Hopfield Networks.](http://arxiv.org/abs/2303.12783) | 该论文提出了一种名为 HopCPT 的新一致性时间序列预测方法，不仅能够处理时间结构，而且能够利用其优势，已在多种真实世界的时间序列数据集上证明了优于现有方法的性能。 |
| [^4] | [The Complexity of Why-Provenance for Datalog Queries.](http://arxiv.org/abs/2303.12773) | 为了向可解释人工智能目标迈进，我们研究了Datalog查询及其子类的why-provenance的数据复杂性，这有助于解释查询结果并提供证据。我们的结果表明，即使递归被限制，在递归查询中实现why-provenance的计算复杂性也非常困难。 |
| [^5] | [Interpretable Bangla Sarcasm Detection using BERT and Explainable AI.](http://arxiv.org/abs/2303.12772) | 该论文提出了一种基于BERT的冷嘲热讽检测系统，可以有效地检测孟加拉语中的冷嘲热讽，对社交媒体分析等任务具有重要意义。 |
| [^6] | [Can we trust the evaluation on ChatGPT?.](http://arxiv.org/abs/2303.12767) | 本文讨论了ChatGPT评估中面临的数据污染挑战，通过倾向性检测任务阐述了这一问题，并探讨了如何在闭合且持续训练模型的时代确保模型评估的公平性。 |
| [^7] | [Spherical Transformer for LiDAR-based 3D Recognition.](http://arxiv.org/abs/2303.12766) | 本文提出了一种名为SphereFormer的新方法，它考虑了LiDAR点云数据的不同稀疏度，通过设计径向窗口自注意力机制和指数分裂等手段，可以聚合和处理稀疏的远距离点，具有更好的性能表现。 |
| [^8] | [Text Semantics to Image Generation: A method of building facades design base on Stable Diffusion model.](http://arxiv.org/abs/2303.12755) | 本文提出了一种多网络结合的文本到建筑立面图像生成方法，通过 LoRA 训练方法微调稳定扩散模型和 ControlNet 模型的添加，大大提高了文本到建筑立面图像生成的可控性和稳定性，为后续建筑图像生成研究提供了基础。 |
| [^9] | [Audio-Visual Deception Detection: DOLOS Dataset and Parameter-Efficient Crossmodal Learning.](http://arxiv.org/abs/2303.12745) | 该论文介绍了DOLOS数据集，这是最大的游戏节目欺骗检测数据集，包含1,675个视频片段和丰富的欺骗对话。同时，该论文提出了一种参数高效的跨模态学习方法（PECL），可以有效地学习多模态特征。 |
| [^10] | [DR.CPO: Diversified and Realistic 3D Augmentation via Iterative Construction, Random Placement, and HPR Occlusion.](http://arxiv.org/abs/2303.12743) | 该论文提出了一种多样化和逼真的增强方法，可以创建整体对象并灵活地定位和旋转对象，并相应地应用自遮挡和外遮挡。通过迭代构建多个对象来提高整体对象构造的多样性，构造的对象可以在训练帧中随机放置和旋转。 |
| [^11] | [Optimizing CAD Models with Latent Space Manipulation.](http://arxiv.org/abs/2303.12739) | 本文介绍了一种利用潜空间操作优化CAD模型的方法，扩展了StyleCLIP来适用于体素模型形式的CAD模型，能够优化实际CAD模型的自动化能力。 |
| [^12] | [Comparing Trajectory and Vision Modalities for Verb Representation.](http://arxiv.org/abs/2303.12737) | 本文测试了使用2D图像和3D轨迹对动词语义表示的影响，发现2D视觉模态的表现与3D轨迹类似，挑战了传统的智慧。 |
| [^13] | [On the De-duplication of LAION-2B.](http://arxiv.org/abs/2303.12733) | 本文提出了一种算法链，使用适度计算量的CLIP特征进行压缩，实现高效的重复检测，即使是巨大的图像数据集。该方法在LAION-2B中发现30\%的图像可能是重复的，并提供了该数据集上的重复图像直方图，可用于检测模型的版权问题。 |
| [^14] | [Unfinished Architectures: A Perspective from Artificial Intelligence.](http://arxiv.org/abs/2303.12732) | 本文探讨了如何运用AI工具，如DALL-E，来完成未完成的历史建筑，特别是未完成的寺庙正面，并分析了该领域仍处于萌芽状态的建筑图形组成，为建筑设计任务提供可能性。 |
| [^15] | [Visualizing Semiotics in Generative Adversarial Networks.](http://arxiv.org/abs/2303.12731) | 该论文演示了如何利用生成对抗网络和符号学对图像进行修改，以展现非物理、抽象属性的变化，并揭示了与符号学属性相关的潜在视觉象征，有助于新的视觉概念产生。 |
| [^16] | [Toward Data-Driven Glare Classification and Prediction for Marine Megafauna Survey.](http://arxiv.org/abs/2303.12730) | 本文针对数据驱动的耀斑建模系统进行了基础建设，允许调查员预先最小化耀斑并最大限度地利用有用的图像来收集数据。 |
| [^17] | [Pedestrain detection for low-light vision proposal.](http://arxiv.org/abs/2303.12725) | 低光环境下的行人检测方案提案，使用图像融合技术预处理数据集，采用 Vision Transformer 模型检测行人，比较 ViT 模型和 YOLOv5 模型性能。 |
| [^18] | [Diffusion-based Target Sampler for Unsupervised Domain Adaptation.](http://arxiv.org/abs/2303.12724) | 该论文提出了一种基于扩散的目标采样器，可以生成高保真度和多样性伪目标样本，它可以帮助现有的无监督领域自适应方法更容易地从源域转移至目标域并且在提高转移性能。 |
| [^19] | [Evaluation of Sketch-Based and Semantic-Based Modalities for Mockup Generation.](http://arxiv.org/abs/2303.12709) | 本文评估了基于手绘和语义的方法来生成设计模型，结果表明基于手绘的方法更加直观和富有表现力，而基于语义的生成AI在质量和逼真度方面获得更好的结果。 |
| [^20] | [Comparison of Probabilistic Deep Learning Methods for Autism Detection.](http://arxiv.org/abs/2303.12707) | 该文章研究了最先进的概率深度学习方法，用于自闭症的检测和诊断，旨在量化方法依赖于机器学习解决客观的自闭症谱系障碍行为特征的挑战。 |
| [^21] | [Open Set Action Recognition via Multi-Label Evidential Learning.](http://arxiv.org/abs/2303.12698) | 本研究提出了一种使用多标签证据学习的新方法，解决了开放集动作识别的新颖性检测问题和同一场景中单个或多个演员以及任何演员的同时动作的更一般问题。 |
| [^22] | [Dense Network Expansion for Class Incremental Learning.](http://arxiv.org/abs/2303.12696) | 本文提出了一种新的网络扩展方法，称为密集网络扩展（DNE），通过跨任务注意机制和密集连接来实现从旧任务到新任务的知识传递。在精度和模型复杂度之间实现更好的平衡，达到了最先进的性能。 |
| [^23] | [Resilient Output Containment Control of Heterogeneous Multiagent Systems Against Composite Attacks: A Digital Twin Approach.](http://arxiv.org/abs/2303.12693) | 本文提出了一种基于数字孪生方法的多智能体系统抗合成攻击的弹性输出约束控制方案，并通过分布式观察器、估计器和自适应控制保证了跟随者的输出被抗FDI和伪装攻击所约束。 |
| [^24] | [An Extended Study of Human-like Behavior under Adversarial Training.](http://arxiv.org/abs/2303.12669) | 对抗训练可以使模型更倾向于人类形状识别，而非仅仅利用纹理线索。在数据集中包含素描的情况下，这种变换效果仍然有效，并且在语言处理领域也适用。 |
| [^25] | [Posthoc Interpretation via Quantization.](http://arxiv.org/abs/2303.12659) | 本文提出了一种新的方法 PIQ，通过对分类器进行向量量化，将其表示转换为离散类特定的潜空间，从而解释分类器所做出的决策，并且通过研究发现该方法相比其他方法更容易让人理解。 |
| [^26] | [Reliable and Efficient Evaluation of Adversarial Robustness for Deep Hashing-Based Retrieval.](http://arxiv.org/abs/2303.12658) | 本文提出了一种名为 Pharos-guided Attack (PgA) 的攻击方法，通过设计代表良性图像语义的 Pharos 代码实现快速且可靠地进行对抗攻击，能够更全面地评估深度哈希检索模型的对抗鲁棒性。 |
| [^27] | [Democratising AI: Multiple Meanings, Goals, and Methods.](http://arxiv.org/abs/2303.12642) | 这篇论文探讨了AI的民主化，包括四种类型的民主化：AI使用的民主化，AI开发的民主化，AI利润的民主化，和AI治理的民主化。要想实现有效的政策和权衡讨论，需要认识到AI治理的民主化在决策中扮演着重要的角色。 |
| [^28] | [Reveal to Revise: An Explainable AI Life Cycle for Iterative Bias Correction of Deep Models.](http://arxiv.org/abs/2303.12641) | 本文提出一个可解释的AI生命周期框架（R2R），允许从业者逐步识别、减少和重新评估深度学习模型数据偏差，包括寻找异常值、检测负责的文物、空间定位和修改模型的行为。 |
| [^29] | [Semi-supervised counterfactual explanations.](http://arxiv.org/abs/2303.12634) | 本论文介绍了一种半监督对抗性解释的方法，通过在对抗性搜索过程中结合自编码器重构损失和将分类器的输出行为与自编码器的潜在空间连接，提高了对抗性搜索过程的速度和生成结果的解释性。 |
| [^30] | [Neuro-Symbolic Reasoning Shortcuts: Mitigation Strategies and their Limitations.](http://arxiv.org/abs/2303.12578) | 本文讨论了神经符号推理的快捷方式带来的问题，并讨论了传统的缓解策略的局限性。 |
| [^31] | [RepoCoder: Repository-Level Code Completion Through Iterative Retrieval and Generation.](http://arxiv.org/abs/2303.12570) | RepoCoder是一个简单、通用和有效的框架，结合了一个基于相似性的检索器和预训练的代码语言模型，在库级别代码完成流程中实现了有效利用库级别信息进行代码完成和生成。 |
| [^32] | [Wasserstein Auto-encoded MDPs: Formal Verification of Efficiently Distilled RL Policies with Many-sided Guarantees.](http://arxiv.org/abs/2303.12558) | 该论文提出了一种名为WAE-MDP的潜在空间模型，可以从任何RL策略中提取形式可验证控制器，并且具有平衡控制性能和安全之间的效果和解决一些学习缺陷的多方保证。 |
| [^33] | [Q-HyViT: Post-Training Quantization for Hybrid Vision Transformer with Bridge Block Reconstruction.](http://arxiv.org/abs/2303.12557) | 本文针对视觉Transformer在移动设备上计算要求高的问题，提出了一种带桥块重构的混合视觉Transformer的后训练量化方法，提高其在移动设备上的加速效果。 |
| [^34] | [DevelSet: Deep Neural Level Set for Instant Mask Optimization.](http://arxiv.org/abs/2303.12529) | DevelSet是一种GPU和深度神经网络(DNN)加速的水平集金属光刻掩模综合框架，通过引入曲率项减少掩模复杂度，并应用GPU加速来克服计算瓶颈，进一步提高可打印性和快速迭代收敛。 |
| [^35] | [Few-shot Multimodal Multitask Multilingual Learning.](http://arxiv.org/abs/2303.12489) | 提出了一种多阶段微调框架，针对少样本多模态多任务多语言学习，可以有效地利用迁移学习和少样本学习的优势，它采用一种通用的编码器-解码器骨架，并使用注意机制处理多模态信息和每个任务的语言特定的微调，在多个基准数据集上表现优异。 |
| [^36] | [Label-Efficient Deep Learning in Medical Image Analysis: Challenges and Future Directions.](http://arxiv.org/abs/2303.12484) | 近年来深度学习在医学图像分析中取得了最先进的性能，但这种方法的标记代价大，标记不足。因此发展了高效标记深度学习方法，充分利用未标记的和弱标记的数据。该综述总结了这方面的最新进展。 |
| [^37] | [Externalities in Chore Division.](http://arxiv.org/abs/2303.12446) | 该论文研究了劳务分工中的外部性问题，扩展了经典模型考虑到其他代理的影响。 |
| [^38] | [MEDIMP: Medical Images and Prompts for renal transplant representation learning.](http://arxiv.org/abs/2303.12445) | MEDIMP是一种用于多模式学习肾移植DCE MRI的医学图像和提示模型，利用联合文本-图像嵌入的对比学习来学习有意义的表示。 |
| [^39] | [$P^{3}O$: Transferring Visual Representations for Reinforcement Learning via Prompting.](http://arxiv.org/abs/2303.12371) | 本论文提出一种名为$P^{3}O$的三阶段DRL算法，通过提问来转移视觉表示，显著优于现有的视觉传输方案。 |
| [^40] | [ExBEHRT: Extended Transformer for Electronic Health Records to Predict Disease Subtypes & Progressions.](http://arxiv.org/abs/2303.12364) | ExBEHRT是一种扩展Transformer模型，应用于电子病历数据，将多种类型的记录包括在特征空间中，可以预测不同疾病下游任务的性能更好，并使用预期梯度对结果进行更细粒度的解释。 |
| [^41] | [Wasserstein Adversarial Examples on Univariant Time Series Data.](http://arxiv.org/abs/2303.12357) | 该论文为时间序列数据提出了一种新的对抗性攻击方法WPGD，利用Wasserstein距离限制正常样本和对抗性例子之间的扰动。实验结果表明该方法能够成功地对单变量时间序列数据进行对抗性攻击，并显著提高成功率。 |
| [^42] | [Artificial Intelligence and Dual Contract.](http://arxiv.org/abs/2303.12350) | 本文通过实验研究了人工智能算法在双重合同问题中能够自主设计激励相容的合同，无需外部引导或通信，并且不同AI算法支持的委托人可以采用混合和零和博弈行为，更具智能的委托人往往会变得合作。 |
| [^43] | [NUWA-XL: Diffusion over Diffusion for eXtremely Long Video Generation.](http://arxiv.org/abs/2303.12346) | NUWA-XL采用扩散过程，在极长视频的生成中实现了由粗到细的过程，减小了训练-推断之间的差距，并且使得所有的段落都可以并行生成。 |
| [^44] | [A multi-functional simulation platform for on-demand ride service operations.](http://arxiv.org/abs/2303.12336) | 本文介绍了一种用于按需乘车服务操作的多功能模拟平台，该平台具有高度的模块化，可扩展性和灵活性，在操作效率和公平性评估，优化算法调整以及实时动态操作控制等方面均能发挥作用，并为研究人员和实践者提供了一个公共的平台。 |
| [^45] | [Frozen Language Model Helps ECG Zero-Shot Learning.](http://arxiv.org/abs/2303.12311) | 该论文提出了一种名为METS的心电图分类方法，使用可训练的心电编码器和冻结的语言模型分别嵌入配对的心电图和自动生成的机器临床报告，以实现心电图零样本学习，并在两个基准心电图数据集上获得了比其他最先进的方法更好的性能。 |
| [^46] | [Curvature-Balanced Feature Manifold Learning for Long-Tailed Classification.](http://arxiv.org/abs/2303.12307) | 本文提出了一种曲率平衡特征流形学习的方法，探究了感知流形的几何特性对分类难度的影响，发现曲率不平衡会导致模型不公平。 |
| [^47] | [Logical Expressiveness of Graph Neural Network for Knowledge Graph Reasoning.](http://arxiv.org/abs/2303.12306) | 本文提出了一种理论分析图神经网络在知识图谱推理方面的逻辑表达能力的方法，并发现图神经网络可以从分级模态逻辑中捕获逻辑规则，从而设计出更好的知识图谱推理方法。 |
| [^48] | [SiamTHN: Siamese Target Highlight Network for Visual Tracking.](http://arxiv.org/abs/2303.12304) | 本文提出了SiamTHN跟踪器，使用目标突出模块帮助相似性响应图集中在目标区域，使用校正损失进一步提高模型的精度，取得了在多个基准测试上的最新性能。 |
| [^49] | [Prototype Helps Federated Learning: Towards Faster Convergence.](http://arxiv.org/abs/2303.12296) | 本文提出一种基于原型的联邦学习框架，可以在只对联邦学习进行少量更改的情况下，提高模型推断的性能和精度，并实现高效的通信。 |
| [^50] | [Adaptive Road Configurations for Improved Autonomous Vehicle-Pedestrian Interactions using Reinforcement Learning.](http://arxiv.org/abs/2303.12289) | 该论文使用强化学习方法探讨如何动态生成行人和自动驾驶汽车 ROW 计划，优化交通流的效率，为行人分配更多空间。 |
| [^51] | [Hardness of Independent Learning and Sparse Equilibrium Computation in Markov Games.](http://arxiv.org/abs/2303.12287) | 本文研究了分散式多智能体强化学习的问题，证明了在标准马尔可夫博弈框架下不存在可获得纳什均衡且可独立学习的算法。 |
| [^52] | [Reducing Air Pollution through Machine Learning.](http://arxiv.org/abs/2303.12285) | 本文介绍了一种基于机器学习的方法来将工业生产对周边城市的空气污染影响降至最低，同时保持生产活动。该方法结合了预测和指导式机器学习模型，并将环境影响减少和生产维持之间达成了多种权衡方案。 |
| [^53] | [Generate labeled training data using Prompt Programming and GPT-3. An example of Big Five Personality Classification.](http://arxiv.org/abs/2303.12279) | 本研究使用Prompt Programming和GPT-3技术生成了大量带有特征标记的对话数据，有效用于训练大五人格分类模型。 |
| [^54] | [Autonomous Robotic Drilling System for Mice Cranial Window Creation: An Evaluation with an Egg Model.](http://arxiv.org/abs/2303.12265) | 本文提出了一种针对小鼠颅骨不均匀问题的自主式机器人操作系统。 |
| [^55] | [Brain-inspired bodily self-perception model that replicates the rubber hand illusion.](http://arxiv.org/abs/2303.12259) | 该论文提出了一个基于大脑启发的身体自我感知模型，模拟橡胶手幻觉，为认识人类身体自我意识的计算机制提供了新的洞见。 |
| [^56] | [Preventing Dimensional Collapse of Incomplete Multi-View Clustering via Direct Contrastive Learning.](http://arxiv.org/abs/2303.12241) | 该论文提出了一种新的不完整多视图对比聚类框架，直接优化特征子空间，并利用重构学习和一致性学习的方式，有效避免了维度崩塌和不一致私有信息的影响，经实验证明其有效性。 |
| [^57] | [Automated deep learning segmentation of high-resolution 7 T ex vivo MRI for quantitative analysis of structure-pathology correlations in neurodegenerative diseases.](http://arxiv.org/abs/2303.12237) | 本文提出了一个深度学习分割管道，用于离体MRI图像的自动化分割。基于37个标本的高分辨率7 T MRI图像，该方法可准确分割整个脑半球，包括皮层、皮质下结构、白质高信号以及正常出现的白质。该方法可为神经病理学研究提供帮助。 |
| [^58] | [Infrastructure-based End-to-End Learning and Prevention of Driver Failure.](http://arxiv.org/abs/2303.12224) | 本论文介绍了一种基于循环神经网络的端到端训练方法来预测自动驾驶车辆中可能存在的故障和危险驾驶员，并在缩小的微型城市中进行了测试。 |
| [^59] | [Policy Optimization for Personalized Interventions in Behavioral Health.](http://arxiv.org/abs/2303.12206) | 研究如何通过数字平台传递的行为健康介入最大化健康结果和治疗成本，提出了一个名为DecompPI的新算法，从离线数据进行预测任务，减轻了在线实验的需要，并在理论上证明了该算法的可扩展性和渐近收敛性。 |
| [^60] | [Practice of the conformer enhanced AUDIO-VISUAL HUBERT on Mandarin and English.](http://arxiv.org/abs/2303.12187) | 本文介绍了一种混合方法，conformer enhanced AV-HuBERT，可以在中英文的音视频识别任务中提高系统性能，该方法在英语AVSR数据集上相对于基线AV-HuBERT分别实现了7%和16%的相对WER降低，并建立了一个新的中文AVSR数据集CSTS，将WeNet ASR系统相应性能超越了14%和18%。 |
| [^61] | [Black-box Backdoor Defense via Zero-shot Image Purification.](http://arxiv.org/abs/2303.12175) | 本文提出了一种黑盒后门防御框架，利用零样本图像净化有效地防御各种攻击，无需任何内部信息或先前知识，通过对受污染的图像进行线性变换和预训练的扩散模型恢复缺失语义信息实现。 |
| [^62] | [Physics Informed Neural Networks for Phase Locked Loop Transient Stability Assessment.](http://arxiv.org/abs/2303.12116) | 本文提出了一种物理知识神经网络（PINN）架构，结合了EMT仿真的精度和ML模型的计算效率，用于准确预测PLL控制器在故障情况下的非线性瞬态动力学并确定其稳定边界。 |
| [^63] | [Positive-Augmented Constrastive Learning for Image and Video Captioning Evaluation.](http://arxiv.org/abs/2303.12112) | 本论文提出一种新的图像标题评估指标PAC-S，可以更准确地评估图像和视频的标题，相比于现有的指标有更好的表现；源代码和训练模型已经公开。 |
| [^64] | [CLSA: Contrastive Learning-based Survival Analysis for Popularity Prediction in MEC Networks.](http://arxiv.org/abs/2303.12097) | 本论文提出了一种基于对比学习的移动边缘缓存网络流行度预测框架，用于解决深度神经网络在处理多内容顺序请求模式时面临的问题。 |
| [^65] | [Reply to: Inability of a graph neural network heuristic to outperform greedy algorithms in solving combinatorial optimization problems.](http://arxiv.org/abs/2303.12096) | 回复评论，认为评论聚焦于一种非典型问题且过于简化，强调了原始工作背后更广泛的算法开发以及实验数据的改进，并且指出图神经网络的内部解剖与贪心算法的本质大不相同，因此具有优势。 |
| [^66] | [Adaptive Negative Evidential Deep Learning for Open-set Semi-supervised Learning.](http://arxiv.org/abs/2303.12091) | 本文提出了ANEDL框架，应用证据深度学习量化不同类型的不确定性，并设计了新颖的适应性负优化策略，有效应对在未标记数据集中包含内部值和异常值的开放式半监督学习。 |
| [^67] | [Thrill-K Architecture: Towards a Solution to the Problem of Knowledge Based Understanding.](http://arxiv.org/abs/2303.12084) | Thrill-K架构将神经学习与不同类型的知识相结合，为解决部署端到端学习系统所需要的计算需求增加、以及缺乏灵活性、适应性、可解释性、推理和验证能力等问题提供了一种解决方案。 |
| [^68] | [Multi-agent Reinforcement Learning for Regional Signal control in Large-scale Grid Traffic network.](http://arxiv.org/abs/2303.11899) | 本文提出了一种新的训练框架 RegionLight，基于交叉口之间的邻接关系将智能体分配到每个区域中。同时，研究人员扩展了BDQ方法为DBDQ，以限制联合动作空间大小的增长并缓解智能体训练问题。 |
| [^69] | [Legs as Manipulator: Pushing Quadrupedal Agility Beyond Locomotion.](http://arxiv.org/abs/2303.11330) | 该论文展示了如何训练四足机器人使用前肢执行操纵任务，如攀爬、按下按钮和与物体交互，并使用课程学习将这些技能从模拟环境转移到真实环境中，并获得了成功的实验结果。 |
| [^70] | [Rotating without Seeing: Towards In-hand Dexterity through Touch.](http://arxiv.org/abs/2303.10880) | 本研究提出了一种新系统Touch Dexterity，通过密集二进制力传感器实现了多指机器人手不看就能旋转物体，同时大大降低了成本和与实际应用的差距。 |
| [^71] | [GPTs are GPTs: An Early Look at the Labor Market Impact Potential of Large Language Models.](http://arxiv.org/abs/2303.10130) | 该研究调查了GPT（大语言模型）和相关技术对美国劳动力市场的潜在影响，发现大约80%的美国劳动力可能会受到10%的工作任务的影响，涵盖了所有工资水平和各行各业，预示着这些模型可能具有显著的经济、社会和政策影响。 |
| [^72] | [SemDeDup: Data-efficient learning at web-scale through semantic deduplication.](http://arxiv.org/abs/2303.09540) | SemDeDup是一种利用预训练模型的嵌入来识别和删除语义重复项的方法。通过对LAION的子集进行分析，SemDeDup可以最小化性能损失的同时删除50%的数据，实际上将训练时间减半。此外，SemDeDup在提供效率收益的同时改进了先前的方法。 |
| [^73] | [WDiscOOD: Out-of-Distribution Detection via Whitened Linear Discriminative Analysis.](http://arxiv.org/abs/2303.07543) | 本论文提出了一种名为WDiscOOD的新型OOD检测方法，其中使用白化线性判别分析将特征投影到判别子空间和残留子空间中，确定OOD分数。在大规模ImageNet-1k基准测试和六个OOD数据集中，WDiscOOD表现出了优越的性能。 |
| [^74] | [Text-Visual Prompting for Efficient 2D Temporal Video Grounding.](http://arxiv.org/abs/2303.04995) | 本文提出了一种新颖的文本-视觉提示（TVP）框架来解决时间视频定位问题，该框架有效地共同训练视觉编码器和语言编码器，且使用只有低复杂度稀疏二维视觉特征来提高跨模态特征融合的性能，并提出了一种时态对话排名（TDR）训练策略用于监督TVP的学习，实验证明该框架有效且高效。 |
| [^75] | [Understanding the Diffusion Objective as a Weighted Integral of ELBOs.](http://arxiv.org/abs/2303.00848) | 本文深入理解了扩散目标，并揭示了加权损失和ELBO目标之间的直接关系。 |
| [^76] | [Side Adapter Network for Open-Vocabulary Semantic Segmentation.](http://arxiv.org/abs/2302.12242) | 本文提出的Side Adapter Network框架采用冻结的CLIP模型和辅助网络来实现开放词汇语义分割任务，具有快速、准确和轻量级优势。该网络可以重用CLIP特征，仅增加少量可训练参数，显著优于其他方法。 |
| [^77] | [Scalable Bayesian optimization with high-dimensional outputs using randomized prior networks.](http://arxiv.org/abs/2302.07260) | 本文提出了一个基于带随机先验的神经网络的深度学习框架用于高维输出的贝叶斯优化，可有效地处理全局优化问题，即使在高维度向量空间或无限维函数空间中也能近似功能关系。 |
| [^78] | [DeepAstroUDA: Semi-Supervised Universal Domain Adaptation for Cross-Survey Galaxy Morphology Classification and Anomaly Detection.](http://arxiv.org/abs/2302.02005) | DeepAstroUDA是一种通用域自适应方法，可用于跨调查银河形态分类和异常检测，可以应用于具有不同数据分布和类别重叠的数据集。其在分类准确性方面提供了显著的改善，特别是在标记数据稀缺或不可用的情况下。 |
| [^79] | [Guiding Online Reinforcement Learning with Action-Free Offline Pretraining.](http://arxiv.org/abs/2301.12876) | 本文研究了使用无动作离线数据集来提高在线强化学习的效率和性能的方法，提出了AF-Guide，实现变体的Upside-Down强化学习和指导在线学习的Guided SAC，实验结果表明该方法可以成功改善在离线数据集中不存在动作信息的情况下的性能。 |
| [^80] | [Task-Oriented Communications for NextG: End-to-End Deep Learning and AI Security Aspects.](http://arxiv.org/abs/2212.09668) | 本文探讨了在NextG无线接入网络中，通过端到端深度学习和AI安全保证信号分类任务，并在保证信号传输效率的情况下进行任务导向通信的方法。 |
| [^81] | [Shape-Guided Diffusion with Inside-Outside Attention.](http://arxiv.org/abs/2212.00210) | 该论文提出了一种无需训练的形状引导扩散方法，使用一种新颖的内外部注意机制将形状限制应用于跨注意力图和自注意力图上，从而在文本到图像扩散模型中考虑到对象形状，进而可以实现对象形状忠实度更高的图像生成。 |
| [^82] | [AIREPAIR: A Repair Platform for Neural Networks.](http://arxiv.org/abs/2211.15387) | AIREPAIR是一个神经网络修复平台，它能够集成现有网络修复工具并实现不同方法的公平比较，评估结果表明其实用性。 |
| [^83] | [Melting Pot 2.0.](http://arxiv.org/abs/2211.13746) | 研究工具Melting Pot 2.0为多智能体人工智能提供了评估协议，在一组典型测试场景中测量它们对新颖社交伙伴的泛化能力。 |
| [^84] | [Solving Bilevel Knapsack Problem using Graph Neural Networks.](http://arxiv.org/abs/2211.13436) | 本研究提出了一种使用图神经网络的深度学习方法来解决双层背包问题，该方法比精确算法快500倍，可找到可行性解决方案。 |
| [^85] | [VoP: Text-Video Co-operative Prompt Tuning for Cross-Modal Retrieval.](http://arxiv.org/abs/2211.12764) | 本论文提出了一种用于文本视频跨模态检索的协作提示调整（VoP）框架，与传统方法相比，VoP具有更少的可训练参数和更低的计算复杂度，同时实现了相似甚至更好的性能。 |
| [^86] | [EfficientTrain: Exploring Generalized Curriculum Learning for Training Visual Backbones.](http://arxiv.org/abs/2211.09703) | 本文提出了一种泛化课程学习方法，用于高效训练视觉主干网络，通过优先让模型学习“更容易学习”的模式，不断引入更难的模式，从而加速训练过程。 |
| [^87] | [Efficient Multi-view Clustering via Unified and Discrete Bipartite Graph Learning.](http://arxiv.org/abs/2209.04187) | 本文提出了一种高效的多视图聚类方法，通过基于锚点的子空间学习、双向图学习和离散优化实现了单视图和一致性图的联合学习，避免了高计算复杂度，并在多个数据集上取得了优异的性能表现。 |
| [^88] | [The Alberta Plan for AI Research.](http://arxiv.org/abs/2208.11173) | 阿尔伯塔计划是一项人工智能研究计划，在阿尔伯塔的研究团队及全球志同道合的人士中进行，旨在探索AI的研究方法和应用。 |
| [^89] | [Long-term Causal Effects Estimation via Latent Surrogates Representation Learning.](http://arxiv.org/abs/2208.04589) | Laser 是一种基于潜在代理表示学习的估计长期因果效应的灵活方法，能够在代理和其代理混合在一起的真实世界情景中应用。 |
| [^90] | [The Causal Structure of Semantic Ambiguities.](http://arxiv.org/abs/2206.06807) | 本文使用Gogioso和Pinzani在QPL 2021中提出的束理论模型，为语义歧义的两个特征（不同可能解释的联合可信度和某些词在过程中扮演更重要角色的因果结构）进行建模。通过对心理语言学文献中的歧义短语数据集进行分析，研究人员对人类对于这些歧义的判断进行了实证测量。 |
| [^91] | [New-Onset Diabetes Assessment Using Artificial Intelligence-Enhanced Electrocardiography.](http://arxiv.org/abs/2205.02900) | 本研究表明，使用人工智能增强的心电图可以有效地识别新发糖尿病成人患者，相较于传统的ADA风险检测方法，该方法具有更好的准确性和特异性。 |
| [^92] | [Real-time Cooperative Vehicle Coordination at Unsignalized Road Intersections.](http://arxiv.org/abs/2205.01278) | 该论文提出了一种实时车辆协同协调框架，涉及的车辆交出控制权限，并通过解决非凸顺序决策问题的方式，利用双延迟深度确定性网络（T3D）算法实现最大化交通通行能力，同时确保驾驶安全和协调系统的长期稳定性。广泛的仿真结果证明了该方法在交通通行能力、驾驶安全和协调稳定性方面的优越性。 |
| [^93] | [Visual Spatial Reasoning.](http://arxiv.org/abs/2205.00363) | 本文介绍了一种名为Visual Spatial Reasoning（VSR）的数据集，其中包含超过10k个自然文本-图像配对，用于推理包括66种空间关系，研究发现目前的视觉和语言模型（VLMs）难以捕捉关系信息和较少关注物体的方向关系。 |
| [^94] | [Fix the Noise: Disentangling Source Feature for Transfer Learning of StyleGAN.](http://arxiv.org/abs/2204.14079) | 本文提出了一种新的方法“FixNoise”，在StyleGAN的迁移学习中引入了简单的特征匹配损失来改善生成质量，并在目标特征空间的一部分中仅保留源特征以控制源特征的程度。实验证明其在领域翻译和属性编辑中的有效性。 |
| [^95] | [Causal Reasoning Meets Visual Representation Learning: A Prospective Study.](http://arxiv.org/abs/2204.12037) | 这项论文讨论了视觉表征学习中缺乏解释性，鲁棒性和泛化性的问题，并提出了因果推理范式来实现这些属性。 |
| [^96] | [CgAT: Center-Guided Adversarial Training for Deep Hashing-Based Retrieval.](http://arxiv.org/abs/2204.10779) | 本文提出了CgAT方法，基于中心引导的对抗性训练方法，可提升深度Hashing网络检索的鲁棒性，取得了领先于现有方法的效果。 |

# 详细

[^1]: 开源框架语义解析

    Open-source Frame Semantic Parsing. (arXiv:2303.12788v1 [cs.CL])

    [http://arxiv.org/abs/2303.12788](http://arxiv.org/abs/2303.12788)

    本文介绍了一个开源Python库Frame Semantic Transformer，该库用于框架语义解析，并在易用性和性能方面实现接近最新水平，可通过在推理时使用FrameNet词汇单元来提高性能，并通过在训练期间使用文本数据增强来提高对真实世界数据的稳健性。

    

    虽然最近几年来框架语义解析的最新技术取得了显著进展，但对于终端用户来说，将最新模型应用于实践仍然很困难。为了解决这个问题，我们提出了Frame Semantic Transformer，这是一个开源Python库，可以在关注易用性的同时，在FrameNet 1.7上实现接近最新水平的性能。我们使用一个在Propbank和FrameNet示例上微调的T5模型作为基础，并通过在推理时使用FrameNet词汇单元为T5提供提示来提高性能。我们通过在训练期间使用文本数据增强来提高对真实世界数据的稳健性。

    While the state-of-the-art for frame semantic parsing has progressed dramatically in recent years, it is still difficult for end-users to apply state-of-the-art models in practice. To address this, we present Frame Semantic Transformer, an open-source Python library which achieves near state-of-the-art performance on FrameNet 1.7, while focusing on ease-of-use. We use a T5 model fine-tuned on Propbank and FrameNet exemplars as a base, and improve performance by using FrameNet lexical units to provide hints to T5 at inference time. We enhance robustness to real-world data by using textual data augmentations during training.
    
[^2]: 熵正则化强化学习的莫特里卡多策略梯度：收敛性与全局最优性

    Matryoshka Policy Gradient for Entropy-Regularized RL: Convergence and Global Optimality. (arXiv:2303.12785v1 [cs.LG])

    [http://arxiv.org/abs/2303.12785](http://arxiv.org/abs/2303.12785)

    本文介绍了一种新的策略梯度算法——莫特里卡多策略梯度(MPG)，该算法尤其在最大熵强化学习中表现突出，能够实现一系列策略的训练和学习以达到任务的最优化，具有极高的收敛性和全局最优性。

    

    本文介绍并研究了一种新的策略梯度算法——莫特里卡多策略梯度(MPG)，在最大熵强化学习的背景下，代理目标是最大化除了累计奖励外的熵奖励。MPG与标准PG的不同之处在于它训练一系列策略同时学习有限的任务，而不是针对单一的标准目标训练一个单一的策略。对于softmax策略，我们证明了MPG的收敛性和极限的全局最优性，通过证明MPG目标的唯一临界点是最优策略；即使在连续紧致状态空间的情况下，这些结果仍然成立。MPG直观、理论上Sound，我们进一步展示了标准最大熵目标的最优策略可以通过MPG框架的最优策略进行任意精度的逼近。最后，我们证明了在策略用神经网络参数化的情况下，MPG非常适合。

    A novel Policy Gradient (PG) algorithm, called Matryoshka Policy Gradient (MPG), is introduced and studied, in the context of max-entropy reinforcement learning, where an agent aims at maximising entropy bonuses additional to its cumulative rewards. MPG differs from standard PG in that it trains a sequence of policies to learn finite horizon tasks simultaneously, instead of a single policy for the single standard objective. For softmax policies, we prove convergence of MPG and global optimality of the limit by showing that the only critical point of the MPG objective is the optimal policy; these results hold true even in the case of continuous compact state space. MPG is intuitive, theoretically sound and we furthermore show that the optimal policy of the standard max-entropy objective can be approximated arbitrarily well by the optimal policy of the MPG framework. Finally, we justify that MPG is well suited when the policies are parametrized with neural networks and we provide an simp
    
[^3]: 基于现代 Hopfield 网络的时间序列一致性预测方法

    Conformal Prediction for Time Series with Modern Hopfield Networks. (arXiv:2303.12783v1 [cs.LG])

    [http://arxiv.org/abs/2303.12783](http://arxiv.org/abs/2303.12783)

    该论文提出了一种名为 HopCPT 的新一致性时间序列预测方法，不仅能够处理时间结构，而且能够利用其优势，已在多种真实世界的时间序列数据集上证明了优于现有方法的性能。

    

    为了量化不确定性，一致性预测方法受到越来越多的关注，并已成功应用于各个领域。然而，它们难以应用于时间序列，因为时间序列的自相关结构违反了一致性预测所需的基本假设。我们提出了 HopCPT，一种新的基于 Hopfield 网络的时间序列一致性预测方法，不仅能够应对时间结构，而且能够利用它们。我们证明了我们的方法在存在时间依赖性的时间序列中在理论上是有很好的理论基础的。在实验中，我们证明了我们的新方法在四个不同领域的多个真实世界时间序列数据集上优于现有的最先进的一致性预测方法。

    To quantify uncertainty, conformal prediction methods are gaining continuously more interest and have already been successfully applied to various domains. However, they are difficult to apply to time series as the autocorrelative structure of time series violates basic assumptions required by conformal prediction. We propose HopCPT, a novel conformal prediction approach for time series that not only copes with temporal structures but leverages them. We show that our approach is theoretically well justified for time series where temporal dependencies are present. In experiments, we demonstrate that our new approach outperforms state-of-the-art conformal prediction methods on multiple real-world time series datasets from four different domains.
    
[^4]: Datalog查询的Why-Provenance的复杂性

    The Complexity of Why-Provenance for Datalog Queries. (arXiv:2303.12773v1 [cs.DB])

    [http://arxiv.org/abs/2303.12773](http://arxiv.org/abs/2303.12773)

    为了向可解释人工智能目标迈进，我们研究了Datalog查询及其子类的why-provenance的数据复杂性，这有助于解释查询结果并提供证据。我们的结果表明，即使递归被限制，在递归查询中实现why-provenance的计算复杂性也非常困难。

    

    解释数据库查询结果的原因是实现可解释人工智能的重要任务，尤其是在表达丰富的查询语言（如Datalog）在本体论应用程序的发展中发挥至关重要的作用的当下。解释查询结果的标准方法是所谓的why-provenance，它以足以推导该结果的输入数据库的子集的形式提供有关查询结果的证据。令人惊讶的是，尽管对于Datalog查询的why-provenance的概念已存在数十年并受到广泛研究，但其计算复杂性仍未被探索。本工作的目标是填补why-provenance文献中这个明显的空白。为此，我们确定了Datalog查询及其关键子类的why-provenance的数据复杂性。我们的研究结果表明，即使递归被限制为非常特殊的情况，对于递归查询的Why-Provenance的计算复杂性同样是困难的。

    Explaining why a database query result is obtained is an essential task towards the goal of Explainable AI, especially nowadays where expressive database query languages such as Datalog play a critical role in the development of ontology-based applications. A standard way of explaining a query result is the so-called why-provenance, which essentially provides information about the witnesses to a query result in the form of subsets of the input database that are sufficient to derive that result. To our surprise, despite the fact that the notion of why-provenance for Datalog queries has been around for decades and intensively studied, its computational complexity remains unexplored. The goal of this work is to fill this apparent gap in the why-provenance literature. Towards this end, we pinpoint the data complexity of why-provenance for Datalog queries and key subclasses thereof. The takeaway of our work is that why-provenance for recursive queries, even if the recursion is limited to be
    
[^5]: 使用BERT和可解释AI的可解释孟加拉冷嘲热讽检测

    Interpretable Bangla Sarcasm Detection using BERT and Explainable AI. (arXiv:2303.12772v1 [cs.CL])

    [http://arxiv.org/abs/2303.12772](http://arxiv.org/abs/2303.12772)

    该论文提出了一种基于BERT的冷嘲热讽检测系统，可以有效地检测孟加拉语中的冷嘲热讽，对社交媒体分析等任务具有重要意义。

    

    正面的话或伴随负向动机的语句通常被定义为冷嘲热讽，而在当今社交媒体平台如Facebook、Twitter、Reddit等上广泛使用。最近，社交媒体平台上的活跃用户数量呈现爆炸性增长，这增强了需要一种基于自然语言处理的自动化系统来完成多项任务，如确定市场需求、情感分析、威胁检测等的需求。然而，由于冷嘲热讽通常意味着相反的意思，其检测经常是一个具有挑战性的问题，因此通过NLP模型进行数据意义提取变得更加复杂。因此，在过去的几年中，针对英语中的冷嘲热讽检测已经有大量研究，并且取得了显著的进步，但孟加拉语中的冷嘲热讽检测始终没有改善。本文提出了一种基于BERT模型的系统，在使用传统机器学习算法时只能达到99.60\%的情况下，可以实现冷嘲热讽的检测。

    A positive phrase or a sentence with an underlying negative motive is usually defined as sarcasm that is widely used in today's social media platforms such as Facebook, Twitter, Reddit, etc. In recent times active users in social media platforms are increasing dramatically which raises the need for an automated NLP-based system that can be utilized in various tasks such as determining market demand, sentiment analysis, threat detection, etc. However, since sarcasm usually implies the opposite meaning and its detection is frequently a challenging issue, data meaning extraction through an NLP-based model becomes more complicated. As a result, there has been a lot of study on sarcasm detection in English over the past several years, and there's been a noticeable improvement and yet sarcasm detection in the Bangla language's state remains the same. In this article, we present a BERT-based system that can achieve 99.60\% while the utilized traditional machine learning algorithms are only ca
    
[^6]: 我们能相信ChatGPT的评估吗？

    Can we trust the evaluation on ChatGPT?. (arXiv:2303.12767v1 [cs.CL])

    [http://arxiv.org/abs/2303.12767](http://arxiv.org/abs/2303.12767)

    本文讨论了ChatGPT评估中面临的数据污染挑战，通过倾向性检测任务阐述了这一问题，并探讨了如何在闭合且持续训练模型的时代确保模型评估的公平性。

    

    ChatGPT是第一个被广泛采纳的大型语言模型，展示出在多项自然语言任务中卓越的表现。但是，由于模型的闭合性以及通过强化学习和人类反馈不断更新，评估ChatGPT在不同问题领域的表现仍然具有挑战性。本文重点讨论了在ChatGPT的评估中存在的数据污染问题，并使用倾向性检测任务作为案例进行了说明。我们还讨论了如何在闭合和持续训练模型的时代，避免数据污染和确保公平的模型评估的挑战。

    ChatGPT, the first large language model (LLM) with mass adoption, has demonstrated remarkable performance in numerous natural language tasks. Despite its evident usefulness, evaluating ChatGPT's performance in diverse problem domains remains challenging due to the closed nature of the model and its continuous updates via Reinforcement Learning from Human Feedback (RLHF). We highlight the issue of data contamination in ChatGPT evaluations, with a case study of the task of stance detection. We discuss the challenge of preventing data contamination and ensuring fair model evaluation in the age of closed and continuously trained models.
    
[^7]: 基于球面变换的LiDAR三维识别技术

    Spherical Transformer for LiDAR-based 3D Recognition. (arXiv:2303.12766v1 [cs.CV])

    [http://arxiv.org/abs/2303.12766](http://arxiv.org/abs/2303.12766)

    本文提出了一种名为SphereFormer的新方法，它考虑了LiDAR点云数据的不同稀疏度，通过设计径向窗口自注意力机制和指数分裂等手段，可以聚合和处理稀疏的远距离点，具有更好的性能表现。

    

    基于LiDAR点云的三维识别已经在各种应用中得到了广泛的应用。当前大多数方法并没有专门考虑LiDAR点分布的情况，因此对于稀疏的远距离点经常面临信息不连通和有限感受野的问题。本文研究了LiDAR点分布的不同稀疏性，并提出了SphereFormer，可直接从密集的近距离点聚合信息和稀疏的远距离点。我们设计了径向窗口自注意力机制，将空间划分为多个非重叠窄长窗口。它可以克服不连通问题，平滑且显着地扩大感受野，从而显著提高稀疏远距离点的性能。此外，为了适应窄长窗口，我们提出指数分裂方法以得到细粒度的位置编码和动态特征选择以提高模型表征能力。值得注意的是，我们的方法在nuScenes和SemanticKITTI语义分割数据集上均名列前茅。

    LiDAR-based 3D point cloud recognition has benefited various applications. Without specially considering the LiDAR point distribution, most current methods suffer from information disconnection and limited receptive field, especially for the sparse distant points. In this work, we study the varying-sparsity distribution of LiDAR points and present SphereFormer to directly aggregate information from dense close points to the sparse distant ones. We design radial window self-attention that partitions the space into multiple non-overlapping narrow and long windows. It overcomes the disconnection issue and enlarges the receptive field smoothly and dramatically, which significantly boosts the performance of sparse distant points. Moreover, to fit the narrow and long windows, we propose exponential splitting to yield fine-grained position encoding and dynamic feature selection to increase model representation ability. Notably, our method ranks 1st on both nuScenes and SemanticKITTI semantic 
    
[^8]: 从文本到图像生成: 基于稳定扩散模型构建建筑立面设计的方法

    Text Semantics to Image Generation: A method of building facades design base on Stable Diffusion model. (arXiv:2303.12755v1 [cs.CV])

    [http://arxiv.org/abs/2303.12755](http://arxiv.org/abs/2303.12755)

    本文提出了一种多网络结合的文本到建筑立面图像生成方法，通过 LoRA 训练方法微调稳定扩散模型和 ControlNet 模型的添加，大大提高了文本到建筑立面图像生成的可控性和稳定性，为后续建筑图像生成研究提供了基础。

    

    稳定扩散模型已广泛应用于建筑图像生成的研究中，但目前仍有提高生成图像内容可控性的机会。本文提出了一种多网络结合的文本到建筑立面图像生成方法。我们首先通过 LoRA（低秩自适应）方法在 CMP Fa-cades 数据集上对稳定扩散模型进行了微调，然后应用 ControlNet 模型进一步控制输出。最后，我们对不同建筑风格文本内容和控制策略下的立面生成结果进行了对比。结果表明，LoRA 训练方法显着降低了微调稳定扩散大模型的可能性，而 ControlNet 模型的添加增加了文本到建筑立面图像的可控性。这为后续关于建筑图像生成的研究提供了基础。

    Stable Diffusion model has been extensively employed in the study of archi-tectural image generation, but there is still an opportunity to enhance in terms of the controllability of the generated image content. A multi-network combined text-to-building facade image generating method is proposed in this work. We first fine-tuned the Stable Diffusion model on the CMP Fa-cades dataset using the LoRA (Low-Rank Adaptation) approach, then we ap-ply the ControlNet model to further control the output. Finally, we contrast-ed the facade generating outcomes under various architectural style text con-tents and control strategies. The results demonstrate that the LoRA training approach significantly decreases the possibility of fine-tuning the Stable Dif-fusion large model, and the addition of the ControlNet model increases the controllability of the creation of text to building facade images. This pro-vides a foundation for subsequent studies on the generation of architectural images.
    
[^9]: 音视频欺骗检测：DOLOS数据集和参数高效跨模态学习

    Audio-Visual Deception Detection: DOLOS Dataset and Parameter-Efficient Crossmodal Learning. (arXiv:2303.12745v1 [cs.CV])

    [http://arxiv.org/abs/2303.12745](http://arxiv.org/abs/2303.12745)

    该论文介绍了DOLOS数据集，这是最大的游戏节目欺骗检测数据集，包含1,675个视频片段和丰富的欺骗对话。同时，该论文提出了一种参数高效的跨模态学习方法（PECL），可以有效地学习多模态特征。

    

    对话中的欺诈检测是一项具有挑战性但非常重要的任务，在商业的可信度评估、多媒体防欺诈和定制安全等许多领域都有重要的应用。然而，由于缺乏高质量的欺诈数据集以及学习多模态特征的困难，欺诈检测研究受到了阻碍。为了解决这个问题，我们引入了DOLOS数据集，这是包含丰富的欺骗对话的最大游戏节目欺骗检测数据集。DOLOS包括1,675个视频片段，涉及213个被试者，并且已经用音视频特征注释进行了标注。我们提供了训练-测试、持续时间和性别协议来调查不同因素的影响。我们在先前提出的欺骗检测方法上对我们的数据集进行了基准测试。为了通过微调更少的参数进一步提高性能，我们提出了参数高效跨模态学习（PECL），其中统一时间适配器（UT-Adapter）探索时间

    Deception detection in conversations is a challenging yet important task, having pivotal applications in many fields such as credibility assessment in business, multimedia anti-frauds, and custom security. Despite this, deception detection research is hindered by the lack of high-quality deception datasets, as well as the difficulties of learning multimodal features effectively. To address this issue, we introduce DOLOS, the largest gameshow deception detection dataset with rich deceptive conversations. DOLOS includes 1,675 video clips featuring 213 subjects, and it has been labeled with audio-visual feature annotations. We provide train-test, duration, and gender protocols to investigate the impact of different factors. We benchmark our dataset on previously proposed deception detection approaches. To further improve the performance by fine-tuning fewer parameters, we propose Parameter-Efficient Crossmodal Learning (PECL), where a Uniform Temporal Adapter (UT-Adapter) explores tempora
    
[^10]: DR.CPO：通过迭代构建、随机放置和 HPR 遮蔽实现的多样化和逼真的三维增强

    DR.CPO: Diversified and Realistic 3D Augmentation via Iterative Construction, Random Placement, and HPR Occlusion. (arXiv:2303.12743v1 [cs.CV])

    [http://arxiv.org/abs/2303.12743](http://arxiv.org/abs/2303.12743)

    该论文提出了一种多样化和逼真的增强方法，可以创建整体对象并灵活地定位和旋转对象，并相应地应用自遮挡和外遮挡。通过迭代构建多个对象来提高整体对象构造的多样性，构造的对象可以在训练帧中随机放置和旋转。

    

    在自动驾驶中，数据增强常用于改进三维物体检测。最基本的方法包括插入复制对象和旋转和缩放整个训练帧。也已经开发了许多变体。然而，现有方法与现实世界的可能性相比相当有限。在这项工作中，我们开发了一种多样化和逼真增强方法，可以灵活地构造整体对象，自由地定位和旋转对象，并相应地应用自遮挡和外遮挡。为了提高整体对象构造的多样性，我们开发了一种迭代方法，将从现实世界观察到的多个对象随机组合成单个对象。与现有增强方法不同的是，构造的对象可以随机放置和旋转在训练帧中，因为适当的遮挡可以反映在最终整体对象中。最后，为了防止过度增强导致过拟合，我们介绍了一种分层遮挡概率设置，通过对象的位置和大小调整遮挡强度。

    In autonomous driving, data augmentation is commonly used for improving 3D object detection. The most basic methods include insertion of copied objects and rotation and scaling of the entire training frame. Numerous variants have been developed as well. The existing methods, however, are considerably limited when compared to the variety of the real world possibilities. In this work, we develop a diversified and realistic augmentation method that can flexibly construct a whole-body object, freely locate and rotate the object, and apply self-occlusion and external-occlusion accordingly. To improve the diversity of the whole-body object construction, we develop an iterative method that stochastically combines multiple objects observed from the real world into a single object. Unlike the existing augmentation methods, the constructed objects can be randomly located and rotated in the training frame because proper occlusions can be reflected to the whole-body objects in the final step. Fina
    
[^11]: 采用潜空间操作来优化CAD模型

    Optimizing CAD Models with Latent Space Manipulation. (arXiv:2303.12739v1 [cs.CV])

    [http://arxiv.org/abs/2303.12739](http://arxiv.org/abs/2303.12739)

    本文介绍了一种利用潜空间操作优化CAD模型的方法，扩展了StyleCLIP来适用于体素模型形式的CAD模型，能够优化实际CAD模型的自动化能力。

    

    当涉及到自动化领域中CAD模型的优化时，神经网络目前只起到了较小的作用。优化抽象特性如自动化能力是具有挑战性的，因为它们很难被模拟，对于基于规则的系统来说过于复杂，而且机器学习方法缺乏数据。另一方面，像StyleCLIP这样的可操纵图像中的抽象特征方法已经取得了很大的成功。它们依赖于预训练生成对抗性网络的潜空间，并且因此也可以利用大量未标记的CAD数据。在本文中，我们展示了这种方法也适用于优化CAD零件的抽象自动化相关特征。我们通过扩展StyleCLIP以适用于体素模型形式的CAD模型实现了这一点，其中包括使用3D StyleGAN和自定义分类器。最后，我们演示了我们的系统通过优化实际CAD模型的自动化能力而具备的能力。

    When it comes to the optimization of CAD models in the automation domain, neural networks currently play only a minor role. Optimizing abstract features such as automation capability is challenging, since they can be very difficult to simulate, are too complex for rule-based systems, and also have little to no data available for machine-learning methods. On the other hand, image manipulation methods that can manipulate abstract features in images such as StyleCLIP have seen much success. They rely on the latent space of pretrained generative adversarial networks, and could therefore also make use of the vast amount of unlabeled CAD data. In this paper, we show that such an approach is also suitable for optimizing abstract automation-related features of CAD parts. We achieved this by extending StyleCLIP to work with CAD models in the form of voxel models, which includes using a 3D StyleGAN and a custom classifier. Finally, we demonstrate the ability of our system for the optimiziation o
    
[^12]: 比较轨迹和视觉模态对动词表示的影响

    Comparing Trajectory and Vision Modalities for Verb Representation. (arXiv:2303.12737v1 [cs.CV])

    [http://arxiv.org/abs/2303.12737](http://arxiv.org/abs/2303.12737)

    本文测试了使用2D图像和3D轨迹对动词语义表示的影响，发现2D视觉模态的表现与3D轨迹类似，挑战了传统的智慧。

    

    三维轨迹，即物体随时间的3D位置和旋转，被证明可以编码动词语义的关键方面（例如，roll和slide的含义）。然而，大多数NLP中的多模态模型使用2D图像作为世界的表示。考虑到3D空间在动词语义的形式模型中的重要性，我们预期这些2D图像会导致贫瘠的表示，无法捕捉到微妙的差异。本文在受控实验中直接测试了这个假设。我们训练了自监督的图像和轨迹编码器，然后评估它们学习区分动词概念的程度。与我们最初的预期相反，我们发现2D视觉模态的表现与3D轨迹类似。虽然还需要进一步研究这个问题，但我们的初步发现挑战了传统的智慧：更丰富的环境表示必然会导致更好的表示学习。

    Three-dimensional trajectories, or the 3D position and rotation of objects over time, have been shown to encode key aspects of verb semantics (e.g., the meanings of roll vs. slide). However, most multimodal models in NLP use 2D images as representations of the world. Given the importance of 3D space in formal models of verb semantics, we expect that these 2D images would result in impoverished representations that fail to capture nuanced differences in meaning. This paper tests this hypothesis directly in controlled experiments. We train self-supervised image and trajectory encoders, and then evaluate them on the extent to which each learns to differentiate verb concepts. Contrary to our initial expectations, we find that 2D visual modalities perform similarly well to 3D trajectories. While further work should be conducted on this question, our initial findings challenge the conventional wisdom that richer environment representations necessarily translate into better representation lea
    
[^13]: LAION-2B的去重算法研究

    On the De-duplication of LAION-2B. (arXiv:2303.12733v1 [cs.CV])

    [http://arxiv.org/abs/2303.12733](http://arxiv.org/abs/2303.12733)

    本文提出了一种算法链，使用适度计算量的CLIP特征进行压缩，实现高效的重复检测，即使是巨大的图像数据集。该方法在LAION-2B中发现30\%的图像可能是重复的，并提供了该数据集上的重复图像直方图，可用于检测模型的版权问题。

    

    生成模型，如DALL-E、Midjourney和Stable Diffusion等，具有超越计算机科学领域的社会意义，这些模型需要像LAION-2B这样包含20亿张图片的大型图像数据库。在这个规模下，手动检查是困难的，自动分析也具有挑战性。此外，最近的研究表明，在LAION-2B上训练的模型中，重复的图像会导致版权问题，这影响了其可用性。本文提出了一种算法链，使用适度计算量的CLIP特征进行压缩，实现高效的重复检测，即使是巨大的图像数据集。我们的方法证明，LAION-2B中约700万张图像，约30\%的图像可能是重复的。我们的方法还提供了该数据集上的重复图像直方图，用于揭示Stable Diffusion的逐字复制示例，并进一步证明了我们的方法的可行性。当前版本的去重集将被分发。

    Generative models, such as DALL-E, Midjourney, and Stable Diffusion, have societal implications that extend beyond the field of computer science. These models require large image databases like LAION-2B, which contain two billion images. At this scale, manual inspection is difficult and automated analysis is challenging. In addition, recent studies show that duplicated images pose copyright problems for models trained on LAION2B, which hinders its usability. This paper proposes an algorithmic chain that runs with modest compute, that compresses CLIP features to enable efficient duplicate detection, even for vast image volumes. Our approach demonstrates that roughly 700 million images, or about 30\%, of LAION-2B's images are likely duplicated. Our method also provides the histograms of duplication on this dataset, which we use to reveal more examples of verbatim copies by Stable Diffusion and further justify the approach. The current version of the de-duplicated set will be distributed 
    
[^14]: 未完成的建筑：从人工智能的视角出发

    Unfinished Architectures: A Perspective from Artificial Intelligence. (arXiv:2303.12732v1 [cs.CV])

    [http://arxiv.org/abs/2303.12732](http://arxiv.org/abs/2303.12732)

    本文探讨了如何运用AI工具，如DALL-E，来完成未完成的历史建筑，特别是未完成的寺庙正面，并分析了该领域仍处于萌芽状态的建筑图形组成，为建筑设计任务提供可能性。

    

    未完工建筑在建筑历史上一直存在，并引发了关于是否完工的激烈辩论，为与已完成部分相协调的构思提供理论依据。人工智能的发展为未完成建筑的完成提出了新的可能性，尤其是随着DALL-E等工具的出现，这些工具可以根据文本描述完成图像，对于建筑设计任务来说，AI的帮助成为了可能。本文探讨了这些新的AI工具在历史寺庙未完成正面的完成中的应用，分析了建筑图形组成领域中的仍处于萌芽状态的足球场。

    Unfinished buildings are a constant throughout the history of architecture and have given rise to intense debates on the opportuneness of their completion, in addition to offering alibis for theorizing about the compositional possibilities in coherence with the finished parts. The development of Artificial Intelligence (AI) opens new avenues for the proposal of possibilities for the completion of unfinished architectures. Specifically, with the recent appearance of tools such as DALL-E, capable of completing images guided by a textual description, it is possible to count on the help of AI for architectural design tasks. In this article we explore the use of these new AI tools for the completion of unfinished facades of historical temples and analyse the still germinal stadium in the field of architectural graphic composition.
    
[^15]: 生成对抗网络中符号学的可视化

    Visualizing Semiotics in Generative Adversarial Networks. (arXiv:2303.12731v1 [cs.CV])

    [http://arxiv.org/abs/2303.12731](http://arxiv.org/abs/2303.12731)

    该论文演示了如何利用生成对抗网络和符号学对图像进行修改，以展现非物理、抽象属性的变化，并揭示了与符号学属性相关的潜在视觉象征，有助于新的视觉概念产生。

    

    我们进行了一系列的实验，证明了利用生成对抗网络生成的图像可以通过“符号学”进行修改。我们展示了类似于像素、色调之类的物理属性可以被修改一样，通过我们的方法，也可以修改非物理、抽象的属性。例如，机舱乘务员的制服设计可以被修改为更加“警觉”，不那么“严肃”，或者更加“实用”。一个房子的形式可以被修改为更加“未来感”，一辆车更加“友好”，一双球鞋则可以被更加“邪恶”。我们的方法揭示了与感兴趣的符号学属性相关的潜在视觉象征，使得这一过程可以使用抽象概念进行视觉形式发现。我们的方法是迭代式的，允许对属性存在程度进行控制，可以用于辅助设计过程，产生新的视觉概念。

    We perform a set of experiments to demonstrate that images generated using a Generative Adversarial Network can be modified using 'semiotics.' We show that just as physical attributes such as the hue and saturation of an image can be modified, so too can its non-physical, abstract properties using our method. For example, the design of a flight attendant's uniform may be modified to look more 'alert,' less 'austere,' or more 'practical.' The form of a house can be modified to appear more 'futuristic,' a car more 'friendly' a pair of sneakers, 'evil.' Our method uncovers latent visual iconography associated with the semiotic property of interest, enabling a process of visual form-finding using abstract concepts. Our approach is iterative and allows control over the degree of attribute presence and can be used to aid the design process to yield emergent visual concepts.
    
[^16]: 面向数据驱动的海洋大型动物调查中的耀斑分类和预测

    Toward Data-Driven Glare Classification and Prediction for Marine Megafauna Survey. (arXiv:2303.12730v1 [cs.CV])

    [http://arxiv.org/abs/2303.12730](http://arxiv.org/abs/2303.12730)

    本文针对数据驱动的耀斑建模系统进行了基础建设，允许调查员预先最小化耀斑并最大限度地利用有用的图像来收集数据。

    

    为了估计物种数量，加拿大北大西洋水域的濒危物种进行系统调查，并影响着政策。本文针对数据驱动的耀斑建模系统进行了基础建设，这将允许调查员预先最小化耀斑。调查员使用检测函数估计未明显看到的巨型动物种群。研究的一个目标是最大限度地利用有用的图像来收集数据，为此，我们将使用耀斑模型预测耀斑并优化无耀斑数据的收集。为构建此模型，我们利用小型标记数据集进行半监督学习。大型数据集使用自然伪标签方法使用级联随机森林模型进行标记。使用反射率模型，以确定感兴趣的特征，填充我们的数据集，从而可以进行上下文感知的机器学习模型。

    Critically endangered species in Canadian North Atlantic waters are systematically surveyed to estimate species populations which influence governing policies. Due to its impact on policy, population accuracy is important. This paper lays the foundation towards a data-driven glare modelling system, which will allow surveyors to preemptively minimize glare. Surveyors use a detection function to estimate megafauna populations which are not explicitly seen. A goal of the research is to maximize useful imagery collected, to that end we will use our glare model to predict glare and optimize for glare-free data collection. To build this model, we leverage a small labelled dataset to perform semi-supervised learning. The large dataset is labelled with a Cascading Random Forest Model using a na\"ive pseudo-labelling approach. A reflectance model is used, which pinpoints features of interest, to populate our datasets which allows for context-aware machine learning models. The pseudo-labelled da
    
[^17]: 低光环境下的行人检测方案提案

    Pedestrain detection for low-light vision proposal. (arXiv:2303.12725v1 [cs.CV])

    [http://arxiv.org/abs/2303.12725](http://arxiv.org/abs/2303.12725)

    低光环境下的行人检测方案提案，使用图像融合技术预处理数据集，采用 Vision Transformer 模型检测行人，比较 ViT 模型和 YOLOv5 模型性能。

    

    随着对行人检测的需求增加，针对各种视觉任务（如图像融合）的挑战性问题也日益突出。由于红外图像可以捕捉到热辐射信息，因此红外和可见光图像之间的图像融合可以在环境限制下显着提高目标检测效果。在我们的项目中，我们将使用图像融合技术对数据集进行预处理，然后使用 Vision Transformer 模型从融合图像中检测行人。在评估过程中，将在我们融合图像上比较 YOLOv5 和修订后的 ViT 模型的性能。

    The demand for pedestrian detection has created a challenging problem for various visual tasks such as image fusion. As infrared images can capture thermal radiation information, image fusion between infrared and visible images could significantly improve target detection under environmental limitations. In our project, we would approach by preprocessing our dataset with image fusion technique, then using Vision Transformer model to detect pedestrians from the fused images. During the evaluation procedure, a comparison would be made between YOLOv5 and the revised ViT model performance on our fused images
    
[^18]: 基于扩散的无监督领域自适应目标采样器

    Diffusion-based Target Sampler for Unsupervised Domain Adaptation. (arXiv:2303.12724v1 [cs.CV])

    [http://arxiv.org/abs/2303.12724](http://arxiv.org/abs/2303.12724)

    该论文提出了一种基于扩散的目标采样器，可以生成高保真度和多样性伪目标样本，它可以帮助现有的无监督领域自适应方法更容易地从源域转移至目标域并且在提高转移性能。

    

    当应用到新的应用场景时，深度学习模型的有限可转移性会限制其性能。最近，通过学习域不变特征，无监督领域自适应（UDA）已经在解决这个问题方面取得了显著进展。然而，目标域中的大域漂移和样本稀缺导致现有的UDA方法表现不佳。为了缓解这些问题，我们提出了一种即插即用的基于扩散的目标采样器（DTS），以生成高保真度和多样性伪目标样本。通过引入类条件信息，可以控制生成的目标样本的标签。生成的样本可以很好地模拟目标域的数据分布，并帮助现有的UDA方法更轻松地从源域转移至目标域，从而提高了转移性能。各种基准测试的大量实验表明，现有UDA方法的性能可以得到极大的改进。

    Limited transferability hinders the performance of deep learning models when applied to new application scenarios. Recently, unsupervised domain adaptation (UDA) has achieved significant progress in addressing this issue via learning domain-invariant features. However, large domain shifts and the sample scarcity in the target domain make existing UDA methods achieve suboptimal performance. To alleviate these issues, we propose a plug-and-play Diffusion-based Target Sampler (DTS) to generate high fidelity and diversity pseudo target samples. By introducing class-conditional information, the labels of the generated target samples can be controlled. The generated samples can well simulate the data distribution of the target domain and help existing UDA methods transfer from the source domain to the target domain more easily, thus improving the transfer performance. Extensive experiments on various benchmarks demonstrate that the performance of existing UDA methods can be greatly improved 
    
[^19]: 基于手绘和语义的模型生成方法的评估

    Evaluation of Sketch-Based and Semantic-Based Modalities for Mockup Generation. (arXiv:2303.12709v1 [cs.HC])

    [http://arxiv.org/abs/2303.12709](http://arxiv.org/abs/2303.12709)

    本文评估了基于手绘和语义的方法来生成设计模型，结果表明基于手绘的方法更加直观和富有表现力，而基于语义的生成AI在质量和逼真度方面获得更好的结果。

    

    设计模型是可视化和测试设计想法的重要工具。然而，生成模型的过程对设计师来说可能会耗费大量时间并具有挑战性。本文提出并评估了两种不同的模态，以支持设计师在其工作中生成模型想法：（1）基于手绘草图生成模型的方法，（2）基于一组预定义的设计元素生成界面的语义方法。为了评估这两种方法的有效性，我们进行了一系列实验，以13个参与者为受试对象，让他们使用每种模态生成模型。结果表明，基于手绘的生成方法更加直观和富有表现力，而基于语义的生成AI在质量和逼真度方面获得更好的结果。这两种方法都可以成为UI设计师提高创造力和效率的有价值工具。

    Design mockups are essential instruments for visualizing and testing design ideas. However, the process of generating mockups can be time-consuming and challenging for designers. In this article, we present and evaluate two different modalities for generating mockup ideas to support designers in their work: (1) a sketch-based approach to generate mockups based on hand-drawn sketches, and (2) a semantic-based approach to generate interfaces based on a set of predefined design elements. To evaluate the effectiveness of these two approaches, we conducted a series of experiments with 13 participants in which we asked them to generate mockups using each modality. Our results show that sketch-based generation was more intuitive and expressive, while semantic-based generative AI obtained better results in terms of quality and fidelity. Both methods can be valuable tools for UI designers looking to increase their creativity and efficiency.
    
[^20]: 比较概率深度学习在自闭症检测中的方法

    Comparison of Probabilistic Deep Learning Methods for Autism Detection. (arXiv:2303.12707v1 [cs.CV])

    [http://arxiv.org/abs/2303.12707](http://arxiv.org/abs/2303.12707)

    该文章研究了最先进的概率深度学习方法，用于自闭症的检测和诊断，旨在量化方法依赖于机器学习解决客观的自闭症谱系障碍行为特征的挑战。

    

    自闭症谱系障碍（ASD）是一种目前在世界范围内普遍存在的神经发育障碍。ASD 会在个体的整个生命期内存在，影响他们的行为和交流方式，导致明显的社交障碍、重复的行为特征以及兴趣受限。早期发现该疾病有助于启动治疗并帮助患者过上正常的生活。目前已经研究和开发了一些基于机器学习的定量方法，以克服临床方法存在的问题。这些量化方法依赖于机器学习，一些复杂的基于深度学习的方法已经被开发用于加速自闭症的检测和诊断。本文旨在探讨目前最先进的概率方法，以其所应用的数据集类型为特征进行描述。

    Autism Spectrum Disorder (ASD) is one neuro developmental disorder that is now widespread in the world. ASD persists throughout the life of an individual, impacting the way they behave and communicate, resulting to notable deficits consisting of social life retardation, repeated behavioural traits and a restriction in their interests. Early detection of the disorder helps in the onset treatment and helps one to lead a normal life. There are clinical approaches used in detection of autism, relying on behavioural data and in worst cases, neuroimaging. Quantitative methods involving machine learning have been studied and developed to overcome issues with clinical approaches. These quantitative methods rely on machine learning, with some complex methods based on deep learning developed to accelerate detection and diagnosis of ASD. These literature is aimed at exploring most state-of-the-art probabilistic methods in use today, characterizing them with the type of dataset they're most applie
    
[^21]: 多标签证据学习用于开放集动作识别

    Open Set Action Recognition via Multi-Label Evidential Learning. (arXiv:2303.12698v1 [cs.CV])

    [http://arxiv.org/abs/2303.12698](http://arxiv.org/abs/2303.12698)

    本研究提出了一种使用多标签证据学习的新方法，解决了开放集动作识别的新颖性检测问题和同一场景中单个或多个演员以及任何演员的同时动作的更一般问题。

    

    现有的开放集动作识别方法集中于新颖性检测，假设视频剪辑显示单个动作，这在现实世界中是不现实的。我们提出了一种通过多标签证据学习（MULE）进行开放集动作识别和新颖性检测的新方法，该方法超越了以前的新动作检测方法，通过解决同一场景中单个或多个演员以及任何演员的同时动作的更一般问题。我们的Beta证据神经网络基于演员-上下文-对象关系表示，使用Beta密度估计多动作不确定性。在优化过程中，添加证据去偏置约束到目标函数中，以减少视频表示的静态偏差，从而可以错误地关联预测和静态线索。我们开发了一个基于原始-对偶平均方案更新的学习算法，以优化所提出的问题。优化算法的理论分析证明了其收敛性和复杂性。

    Existing methods for open-set action recognition focus on novelty detection that assumes video clips show a single action, which is unrealistic in the real world. We propose a new method for open set action recognition and novelty detection via MUlti-Label Evidential learning (MULE), that goes beyond previous novel action detection methods by addressing the more general problems of single or multiple actors in the same scene, with simultaneous action(s) by any actor. Our Beta Evidential Neural Network estimates multi-action uncertainty with Beta densities based on actor-context-object relation representations. An evidence debiasing constraint is added to the objective function for optimization to reduce the static bias of video representations, which can incorrectly correlate predictions and static cues. We develop a learning algorithm based on a primal-dual average scheme update to optimize the proposed problem. Theoretical analysis of the optimization algorithm demonstrates the conve
    
[^22]: 密集网络扩展用于类别增量学习

    Dense Network Expansion for Class Incremental Learning. (arXiv:2303.12696v1 [cs.CV])

    [http://arxiv.org/abs/2303.12696](http://arxiv.org/abs/2303.12696)

    本文提出了一种新的网络扩展方法，称为密集网络扩展（DNE），通过跨任务注意机制和密集连接来实现从旧任务到新任务的知识传递。在精度和模型复杂度之间实现更好的平衡，达到了最先进的性能。

    

    本文研究了类别增量学习的问题。现有的方法采用基于网络扩展（NE）的动态架构，每个任务都需要增加一个专家。虽然这种方法在计算上很有效，但会导致模型随着任务数量的增加而快速增长。我们提出了一种新的网络扩展方法，即密集网络扩展（DNE），以在精度和模型复杂度之间实现更好的平衡。我们引入了任务专家网络中间层之间的密集连接，通过特征共享和复用，实现了从旧任务到新任务的知识传递。这种共享是通过跨任务注意机制来实现的，基于新任务注意块（TAB），它可以在任务之间融合信息。与传统注意机制不同，TAB 在特征混合的层次上操作，并且与空间注意力解耦。与联合空间和任务关注机制相比，这种方法在精度和计算效率方面都更有效。该方法在多个基准数据集上实现了最先进的性能。

    The problem of class incremental learning (CIL) is considered. State-of-the-art approaches use a dynamic architecture based on network expansion (NE), in which a task expert is added per task. While effective from a computational standpoint, these methods lead to models that grow quickly with the number of tasks. A new NE method, dense network expansion (DNE), is proposed to achieve a better trade-off between accuracy and model complexity. This is accomplished by the introduction of dense connections between the intermediate layers of the task expert networks, that enable the transfer of knowledge from old to new tasks via feature sharing and reusing. This sharing is implemented with a cross-task attention mechanism, based on a new task attention block (TAB), that fuses information across tasks. Unlike traditional attention mechanisms, TAB operates at the level of the feature mixing and is decoupled with spatial attentions. This is shown more effective than a joint spatial-and-task att
    
[^23]: 多智能体系统抗合成攻击的弹性输出约束控制: 数字孪生方法

    Resilient Output Containment Control of Heterogeneous Multiagent Systems Against Composite Attacks: A Digital Twin Approach. (arXiv:2303.12693v1 [eess.SY])

    [http://arxiv.org/abs/2303.12693](http://arxiv.org/abs/2303.12693)

    本文提出了一种基于数字孪生方法的多智能体系统抗合成攻击的弹性输出约束控制方案，并通过分布式观察器、估计器和自适应控制保证了跟随者的输出被抗FDI和伪装攻击所约束。

    

    本文研究了对抗合成攻击（包括拒绝服务攻击、虚假数据注入攻击、伪装攻击和执行攻击）的异构多智能体系统的分布式弹性输出约束控制。受数字孪生的启发，使用具有更高安全性和隐私性的孪生层（TL）将上述问题分解为两个任务：对TL上的DoS攻击的防御协议和对赛博物理层（CPL）上的执行攻击的防御协议。首先，考虑到领导动态的建模误差，我们引入分布式观察器，在TL上重新构造每个跟随者的领导动态。其次，使用分布式估计器根据在TL上重建的领导动态估计跟随者状态。第三，根据重建的领导动态，我们设计分散算法器在CPL上计算输出调节器方程。第四，提出分布式自适应抗攻击弹性控制方案，保证跟随者的输出被抗FDI和伪装攻击所约束。最后，提供了数值仿真，证明了所提出的弹性输出约束控制策略的有效性和优越性。

    This paper studies the distributed resilient output containment control of heterogeneous multiagent systems against composite attacks, including denial-of-services (DoS) attacks, false-data injection (FDI) attacks, camouflage attacks, and actuation attacks. Inspired by digital twins, a twin layer (TL) with higher security and privacy is used to decouple the above problem into two tasks: defense protocols against DoS attacks on TL and defense protocols against actuation attacks on cyber-physical layer (CPL). First, considering modeling errors of leader dynamics, we introduce distributed observers to reconstruct the leader dynamics for each follower on TL under DoS attacks. Second, distributed estimators are used to estimate follower states according to the reconstructed leader dynamics on the TL. Third, according to the reconstructed leader dynamics, we design decentralized solvers that calculate the output regulator equations on CPL. Fourth, decentralized adaptive attack-resilient cont
    
[^24]: 对抗训练下基于人类行为的研究扩展的实验

    An Extended Study of Human-like Behavior under Adversarial Training. (arXiv:2303.12669v1 [cs.CV])

    [http://arxiv.org/abs/2303.12669](http://arxiv.org/abs/2303.12669)

    对抗训练可以使模型更倾向于人类形状识别，而非仅仅利用纹理线索。在数据集中包含素描的情况下，这种变换效果仍然有效，并且在语言处理领域也适用。

    

    神经网络存在许多缺陷，其中最严重的之一是对分布偏差的敏感性，这允许模型轻易被小型扰动欺骗并做出错误预测，而这些扰动通常对人类来说不易察觉并不必须具有语义含义。 对抗性训练通过在最坏情况下对模型进行扰动来训练模型来解决这个问题。 然而，最近的工作也指出，神经网络的推理方式不同于人类。 人类通过形状识别对象，而神经网络主要利用纹理线索。 例如，受过照片训练的模型可能无法推广到包含素描的数据集。 有趣的是，还表明对抗性训练似乎有利于增加转向形状偏差的趋势。 本文重新审视了这一观察结果，并就各种架构，常见的$\ell_2$和$\ell_\infty$-training，以及基于Transformer的自然语言处理模型的效应进行了广泛分析。 我们在物体分类和自然语言推理上的实验表明，转向形状偏差的变换不仅限于视觉领域，而且也适用于语言处理。 具体而言，我们观察到对抗性训练导致模型更多地依赖组合结构来识别对象和进行预测，从而具有更接近人类的行为。

    Neural networks have a number of shortcomings. Amongst the severest ones is the sensitivity to distribution shifts which allows models to be easily fooled into wrong predictions by small perturbations to inputs that are often imperceivable to humans and do not have to carry semantic meaning. Adversarial training poses a partial solution to address this issue by training models on worst-case perturbations. Yet, recent work has also pointed out that the reasoning in neural networks is different from humans. Humans identify objects by shape, while neural nets mainly employ texture cues. Exemplarily, a model trained on photographs will likely fail to generalize to datasets containing sketches. Interestingly, it was also shown that adversarial training seems to favorably increase the shift toward shape bias. In this work, we revisit this observation and provide an extensive analysis of this effect on various architectures, the common $\ell_2$- and $\ell_\infty$-training, and Transformer-bas
    
[^25]: 通过量化进行的事后解释

    Posthoc Interpretation via Quantization. (arXiv:2303.12659v1 [cs.AI])

    [http://arxiv.org/abs/2303.12659](http://arxiv.org/abs/2303.12659)

    本文提出了一种新的方法 PIQ，通过对分类器进行向量量化，将其表示转换为离散类特定的潜空间，从而解释分类器所做出的决策，并且通过研究发现该方法相比其他方法更容易让人理解。

    

    本文提出了一种新的方法，称为“通过量化实现的事后解释（PIQ）”，用于解释训练分类器所做出的决策。我们的方法利用向量量化将分类器的表示转换为离散，类特定的潜空间。类特定的码本作为瓶颈，迫使解释者专注于分类器认为用于进行预测的输入数据的相关部分。我们通过定量和定性研究评估了我们的方法，并发现与文献中的几种其他解释方法相比，PIQ生成的解释更容易被参与我们用户研究的人所理解。

    In this paper, we introduce a new approach, called "Posthoc Interpretation via Quantization (PIQ)", for interpreting decisions made by trained classifiers. Our method utilizes vector quantization to transform the representations of a classifier into a discrete, class-specific latent space. The class-specific codebooks act as a bottleneck that forces the interpreter to focus on the parts of the input data deemed relevant by the classifier for making a prediction. We evaluated our method through quantitative and qualitative studies and found that PIQ generates interpretations that are more easily understood by participants to our user studies when compared to several other interpretation methods in the literature.
    
[^26]: 深度哈希检索方法的对抗鲁棒性的可靠高效评估

    Reliable and Efficient Evaluation of Adversarial Robustness for Deep Hashing-Based Retrieval. (arXiv:2303.12658v1 [cs.CV])

    [http://arxiv.org/abs/2303.12658](http://arxiv.org/abs/2303.12658)

    本文提出了一种名为 Pharos-guided Attack (PgA) 的攻击方法，通过设计代表良性图像语义的 Pharos 代码实现快速且可靠地进行对抗攻击，能够更全面地评估深度哈希检索模型的对抗鲁棒性。

    

    深度哈希技术在大规模图像检索领域具有高效性和有效性。然而，现有的攻击方法由于未充分利用原始样本之间的语义关系或需要用深度神经网络学习这些关系，在评估深度哈希模型对抗样本的鲁棒性时存在性能下降或效率低下的问题。本文提出了一种新颖的攻击方法 Pharos-guided Attack (PgA)，旨在通过设计代表良性图像语义的 Pharos 代码，可快速且可靠地进行对抗攻击。实验结果表明，与其他六种攻击方法相比，PgA 在成功率和效率方面均优于现有方法，并能够更全面地评估深度哈希检索模型的对抗鲁棒性。

    Deep hashing has been extensively applied to massive image retrieval due to its efficiency and effectiveness. Recently, several adversarial attacks have been presented to reveal the vulnerability of deep hashing models against adversarial examples. However, existing attack methods suffer from degraded performance or inefficiency because they underutilize the semantic relations between original samples or spend a lot of time learning these relations with a deep neural network. In this paper, we propose a novel Pharos-guided Attack, dubbed PgA, to evaluate the adversarial robustness of deep hashing networks reliably and efficiently. Specifically, we design pharos code to represent the semantics of the benign image, which preserves the similarity to semantically relevant samples and dissimilarity to irrelevant ones. It is proven that we can quickly calculate the pharos code via a simple math formula. Accordingly, PgA can directly conduct a reliable and efficient attack on deep hashing-bas
    
[^27]: 智能化的民主化：多种含义、目标和方法

    Democratising AI: Multiple Meanings, Goals, and Methods. (arXiv:2303.12642v1 [cs.AI])

    [http://arxiv.org/abs/2303.12642](http://arxiv.org/abs/2303.12642)

    这篇论文探讨了AI的民主化，包括四种类型的民主化：AI使用的民主化，AI开发的民主化，AI利润的民主化，和AI治理的民主化。要想实现有效的政策和权衡讨论，需要认识到AI治理的民主化在决策中扮演着重要的角色。

    

    许多人呼吁实现AI的民主化，但这个词语用来指代多种目标，有时会相互冲突。本文确定了通常讨论的四种AI民主化类型：(1) AI使用的民主化，(2) AI开发的民主化，(3) AI利润的民主化，和(4) AI治理的民主化。本文讨论了实现每种民主化形式的多个目标和方法。从本文中主要得出的结论是，AI的民主化是一个多元而有时会相互冲突的概念，不应混淆AI可访问性的改善。如果我们想要超越对智能化民主化的模糊承诺，进入具体政策和权衡的生产性讨论，我们需要认识到AI治理的民主化在跨越关于使用、开发和利润的决策中导航权衡和风险的主要作用。

    Numerous parties are calling for the democratisation of AI, but the phrase is used to refer to a variety of goals, the pursuit of which sometimes conflict. This paper identifies four kinds of AI democratisation that are commonly discussed: (1) the democratisation of AI use, (2) the democratisation of AI development, (3) the democratisation of AI profits, and (4) the democratisation of AI governance. Numerous goals and methods of achieving each form of democratisation are discussed. The main takeaway from this paper is that AI democratisation is a multifarious and sometimes conflicting concept that should not be conflated with improving AI accessibility. If we want to move beyond ambiguous commitments to democratising AI, to productive discussions of concrete policies and trade-offs, then we need to recognise the principal role of the democratisation of AI governance in navigating tradeoffs and risks across decisions around use, development, and profits.
    
[^28]: 揭示与修正：一种可解释的深度模型迭代偏差校正生命周期

    Reveal to Revise: An Explainable AI Life Cycle for Iterative Bias Correction of Deep Models. (arXiv:2303.12641v1 [cs.CV])

    [http://arxiv.org/abs/2303.12641](http://arxiv.org/abs/2303.12641)

    本文提出一个可解释的AI生命周期框架（R2R），允许从业者逐步识别、减少和重新评估深度学习模型数据偏差，包括寻找异常值、检测负责的文物、空间定位和修改模型的行为。

    

    最先进的机器学习模型通常会学习训练数据中嵌入的虚假相关性。当将这些模型用于高风险决策，如皮肤癌检测等医疗应用时，这会带来风险。为解决这个问题，本文提出了一种名为“揭示与修正”的框架，其中包括整个可解释人工智能(XAI)生命周期，使从业者能够逐步识别、减少和(重新)评估虚假模型行为，并最大程度地减少人类干预。

    State-of-the-art machine learning models often learn spurious correlations embedded in the training data. This poses risks when deploying these models for high-stake decision-making, such as in medical applications like skin cancer detection. To tackle this problem, we propose Reveal to Revise (R2R), a framework entailing the entire eXplainable Artificial Intelligence (XAI) life cycle, enabling practitioners to iteratively identify, mitigate, and (re-)evaluate spurious model behavior with a minimal amount of human interaction. In the first step (1), R2R reveals model weaknesses by finding outliers in attributions or through inspection of latent concepts learned by the model. Secondly (2), the responsible artifacts are detected and spatially localized in the input data, which is then leveraged to (3) revise the model behavior. Concretely, we apply the methods of RRR, CDEP and ClArC for model correction, and (4) (re-)evaluate the model's performance and remaining sensitivity towards the 
    
[^29]: 半监督对抗性解释

    Semi-supervised counterfactual explanations. (arXiv:2303.12634v1 [cs.LG])

    [http://arxiv.org/abs/2303.12634](http://arxiv.org/abs/2303.12634)

    本论文介绍了一种半监督对抗性解释的方法，通过在对抗性搜索过程中结合自编码器重构损失和将分类器的输出行为与自编码器的潜在空间连接，提高了对抗性搜索过程的速度和生成结果的解释性。

    

    机器学习模型的对抗性解释是用于查找最小干预特征值的方法，使得模型将预测更改为不同的输出或目标输出。有效的对抗性解释应具有可能的特征值。在本文中，我们解决了生成对抗性解释的挑战，使其处于与训练数据相同的数据分布中，并且更重要的是，它们属于目标类分布。通过在对抗性搜索过程中结合自编码器重构损失来解决这个要求。将分类器的输出行为与自编码器的潜在空间连接，进一步提高了对抗性搜索过程的速度和生成结果的解释性。在这一研究领域的持续努力下，我们展示了当自编码器在半监督状态下被训练时，对抗性解释的可解释性进一步提高。

    Counterfactual explanations for machine learning models are used to find minimal interventions to the feature values such that the model changes the prediction to a different output or a target output. A valid counterfactual explanation should have likely feature values. Here, we address the challenge of generating counterfactual explanations that lie in the same data distribution as that of the training data and more importantly, they belong to the target class distribution. This requirement has been addressed through the incorporation of auto-encoder reconstruction loss in the counterfactual search process. Connecting the output behavior of the classifier to the latent space of the auto-encoder has further improved the speed of the counterfactual search process and the interpretability of the resulting counterfactual explanations. Continuing this line of research, we show further improvement in the interpretability of counterfactual explanations when the auto-encoder is trained in a 
    
[^30]: 神经符号推理快捷方式：缓解策略及其限制

    Neuro-Symbolic Reasoning Shortcuts: Mitigation Strategies and their Limitations. (arXiv:2303.12578v1 [cs.AI])

    [http://arxiv.org/abs/2303.12578](http://arxiv.org/abs/2303.12578)

    本文讨论了神经符号推理的快捷方式带来的问题，并讨论了传统的缓解策略的局限性。

    

    神经符号预测器学习从子符号输入到更高层次概念的映射，然后在这个中间表示上执行（概率）逻辑推理。这种设置在符号先验知识的一致性方面具有明显的优势，通常被认为在遵守知识的前提下提供了解释性的好处，因为学习的概念可以更好地被人类利益相关者理解。然而，最近证明了这种设置受到推理快捷方式的影响，通过利用具有意外语义的概念实现高准确性的预测，导致了差的超出分布性能并损害了可解释性。在本文中，我们建立了推理快捷方式和损失函数的最优解之间的形式联系，并确定了推理快捷方式可能出现的情况。基于此，我们讨论了自然缓解策略（如重建和概念监督）的局限性。

    Neuro-symbolic predictors learn a mapping from sub-symbolic inputs to higher-level concepts and then carry out (probabilistic) logical inference on this intermediate representation. This setup offers clear advantages in terms of consistency to symbolic prior knowledge, and is often believed to provide interpretability benefits in that - by virtue of complying with the knowledge the learned concepts can be better understood by human stakeholders. However, it was recently shown that this setup is affected by reasoning shortcuts whereby predictions attain high accuracy by leveraging concepts with unintended semantics, yielding poor out-of-distribution performance and compromising interpretability. In this short paper, we establish a formal link between reasoning shortcuts and the optima of the loss function, and identify situations in which reasoning shortcuts can arise. Based on this, we discuss limitations of natural mitigation strategies such as reconstruction and concept supervision
    
[^31]: RepoCoder：通过迭代检索和生成实现的代码存储库级别完成

    RepoCoder: Repository-Level Code Completion Through Iterative Retrieval and Generation. (arXiv:2303.12570v1 [cs.CL])

    [http://arxiv.org/abs/2303.12570](http://arxiv.org/abs/2303.12570)

    RepoCoder是一个简单、通用和有效的框架，结合了一个基于相似性的检索器和预训练的代码语言模型，在库级别代码完成流程中实现了有效利用库级别信息进行代码完成和生成。

    

    库级别代码完成任务是基于代码库更广阔上下文中继续编写未完成代码的过程。但是对于自动完成工具而言，很难利用散布在不同文件中的有用信息。我们提出了RepoCoder，这是一个简单、通用和有效的框架，可以应对这一挑战。它通过整合基于相似性的检索器和预训练的代码语言模型简化了库级别代码完成流程，从而允许有效利用库级别信息进行代码完成，并具有不同粒度层面的代码生成能力。此外，RepoCoder 还使用了一种新的迭代检索-生成模型，弥合了检索上下文和预期完成目标之间的差距。我们还提出了一个新的RepoEval基准测试，其中包含了最新和高质量真实世界的代码库，涵盖了行、API 调用和函数体完成场景。

    The task of repository-level code completion is to continue writing the unfinished code based on a broader context of the repository. While for automated code completion tools, it is difficult to utilize the useful information scattered in different files. We propose RepoCoder, a simple, generic, and effective framework to address the challenge. It streamlines the repository-level code completion process by incorporating a similarity-based retriever and a pre-trained code language model, which allows for the effective utilization of repository-level information for code completion and grants the ability to generate code at various levels of granularity. Furthermore, RepoCoder utilizes a novel iterative retrieval-generation paradigm that bridges the gap between retrieval context and the intended completion target. We also propose a new benchmark RepoEval, which consists of the latest and high-quality real-world repositories covering line, API invocation, and function body completion sce
    
[^32]: Wasserstein自编码MDPs：具有多方保证的高效RL策略正式验证

    Wasserstein Auto-encoded MDPs: Formal Verification of Efficiently Distilled RL Policies with Many-sided Guarantees. (arXiv:2303.12558v1 [cs.LG])

    [http://arxiv.org/abs/2303.12558](http://arxiv.org/abs/2303.12558)

    该论文提出了一种名为WAE-MDP的潜在空间模型，可以从任何RL策略中提取形式可验证控制器，并且具有平衡控制性能和安全之间的效果和解决一些学习缺陷的多方保证。

    

    尽管深度强化学习（DRL）有许多成功案例，但通过这些先进技术学习的决策者在安全关键场景中的大规模部署受到正式保证不足的阻碍。变分马尔可夫决策过程（VAE-MDPs）是离散潜在空间模型，提供了从任何RL策略中提取形式可验证控制器的可靠框架。虽然相关保证涵盖了实际问题的满足性和安全性等方面，但VAE方法因缺乏抽象和表示保证以支持潜在最优化而遭受多种学习缺陷（后验崩塌，学习速度慢，动力学估计不良）。我们引入了Wasserstein自编码MDP（WAE-MDP），这是一种潜在空间模型，通过最小化执行原始策略的智能体行为和提取出的策略之间的最优转运的惩罚形式来解决这些问题。我们证明了所提出的方法可以有利于控制性能和安全之间的平衡，同时减轻了上述的学习问题。我们推导了关于性能和安全的理论保证，并在不同的RL基准上验证了该方法。

    Although deep reinforcement learning (DRL) has many success stories, the large-scale deployment of policies learned through these advanced techniques in safety-critical scenarios is hindered by their lack of formal guarantees. Variational Markov Decision Processes (VAE-MDPs) are discrete latent space models that provide a reliable framework for distilling formally verifiable controllers from any RL policy. While the related guarantees address relevant practical aspects such as the satisfaction of performance and safety properties, the VAE approach suffers from several learning flaws (posterior collapse, slow learning speed, poor dynamics estimates), primarily due to the absence of abstraction and representation guarantees to support latent optimization. We introduce the Wasserstein auto-encoded MDP (WAE-MDP), a latent space model that fixes those issues by minimizing a penalized form of the optimal transport between the behaviors of the agent executing the original policy and the disti
    
[^33]: Q-HyViT: 带桥块重构的混合视觉Transformer的后训练量化

    Q-HyViT: Post-Training Quantization for Hybrid Vision Transformer with Bridge Block Reconstruction. (arXiv:2303.12557v1 [cs.CV])

    [http://arxiv.org/abs/2303.12557](http://arxiv.org/abs/2303.12557)

    本文针对视觉Transformer在移动设备上计算要求高的问题，提出了一种带桥块重构的混合视觉Transformer的后训练量化方法，提高其在移动设备上的加速效果。

    

    最近，视觉Transformer （ViT）在许多任务中取代了卷积神经网络模型，包括分类、检测和分割。然而， ViT 的高计算要求阻碍了它们的广泛应用。为解决这个问题，研究人员提出了高效的混合变压器架构，结合卷积和变压器层，并优化注意力计算，使线性复杂度达到最大。此外，后训练量化被提出作为缓解计算要求的一种手段。将量化技术和高效的混合变压器结构相结合，对于在移动设备上加速视觉transformer至关重要。然而，以前没有研究将量化应用于高效的混合变压器。 在本文中，首先我们发现将现有的ViT PTQ方法直接应用于高效的混合transformer架构会导致严重的精度下降，由此我们提出了Q-HyViT。

    Recently, vision transformers (ViT) have replaced convolutional neural network models in numerous tasks, including classification, detection, and segmentation. However, the high computational requirements of ViTs hinder their widespread implementation. To address this issue, researchers have proposed efficient hybrid transformer architectures that combine convolutional and transformer layers and optimize attention computation for linear complexity. Additionally, post-training quantization has been proposed as a means of mitigating computational demands. Combining quantization techniques and efficient hybrid transformer structures is crucial to maximize the acceleration of vision transformers on mobile devices. However, no prior investigation has applied quantization to efficient hybrid transformers. In this paper, at first, we discover that the straightforward manner to apply the existing PTQ methods for ViT to efficient hybrid transformers results in a drastic accuracy drop due to the
    
[^34]: DevelSet: 深度神经水平集优化方法用于光刻掩模制作

    DevelSet: Deep Neural Level Set for Instant Mask Optimization. (arXiv:2303.12529v1 [cs.CV])

    [http://arxiv.org/abs/2303.12529](http://arxiv.org/abs/2303.12529)

    DevelSet是一种GPU和深度神经网络(DNN)加速的水平集金属光刻掩模综合框架，通过引入曲率项减少掩模复杂度，并应用GPU加速来克服计算瓶颈，进一步提高可打印性和快速迭代收敛。

    

    随着先进工艺节点中特征尺寸的不断缩小，掩模优化在传统设计流程中变得越来越重要，并伴随着光刻近似校正(OPC)方法中计算开销的爆炸式增长。最近, 反向光刻技术(ILT)已经引起了重视, 并在新兴的 OPC 解决方案中变得流行。然而，ILT方法要么耗时，要么掩模印刷性能和可制造性不足。本文提出了DevelSet，一种GPU和深度神经网络(DNN)加速的水平集金属光刻掩模综合框架。我们首先通过引入曲率项来降低掩模复杂度并应用GPU加速来克服计算瓶颈，改进了传统的基于水平集的ILT算法。为了进一步提高可打印性和快速迭代收敛，我们提出了一种新颖的深度神经网络，利用水平集固有原理巧妙地设计。

    With the feature size continuously shrinking in advanced technology nodes, mask optimization is increasingly crucial in the conventional design flow, accompanied by an explosive growth in prohibitive computational overhead in optical proximity correction (OPC) methods. Recently, inverse lithography technique (ILT) has drawn significant attention and is becoming prevalent in emerging OPC solutions. However, ILT methods are either time-consuming or in weak performance of mask printability and manufacturability. In this paper, we present DevelSet, a GPU and deep neural network (DNN) accelerated level set OPC framework for metal layer. We first improve the conventional level set-based ILT algorithm by introducing the curvature term to reduce mask complexity and applying GPU acceleration to overcome computational bottlenecks. To further enhance printability and fast iterative convergence, we propose a novel deep neural network delicately designed with level set intrinsic principles to facil
    
[^35]: 少样本、多模态、多任务、多语言学习

    Few-shot Multimodal Multitask Multilingual Learning. (arXiv:2303.12489v1 [cs.LG])

    [http://arxiv.org/abs/2303.12489](http://arxiv.org/abs/2303.12489)

    提出了一种多阶段微调框架，针对少样本多模态多任务多语言学习，可以有效地利用迁移学习和少样本学习的优势，它采用一种通用的编码器-解码器骨架，并使用注意机制处理多模态信息和每个任务的语言特定的微调，在多个基准数据集上表现优异。

    

    少样本学习作为一种迁移学习范式，在数据受限的情况下已经得到了广泛的应用。然而，过去主要是在构建单模态单语言模型的背景下探讨了少样本学习。现有的少样本多任务学习领域的大部分文献都是在上下文学习的情况下进行的，需要手动生成提示作为输入，这导致了结果的差异，取决于手动提示工程的水平。此外，上下文学习会带来相当大的计算、内存、存储成本，最终导致高推理延迟，因为它涉及每次进行预测时都要通过模型运行所有提示的示例。相比之下，通过微调范式的迁移学习方法避免了上述问题，在任务的基础上以一次性的代价微调权重。然而，这种方法缺乏少样本多模态多任务学习的经验。在本文中，我们提出了一种多阶段微调框架，针对少样本多模态多任务多语言学习，可以有效地利用迁移学习和少样本学习的优势。我们的方法采用一种通用的编码器-解码器骨架，并使用注意机制处理多模态信息和每个任务的语言特定的微调。所提出的框架表现出了优秀的性能，在几个基准数据集上优于现有模型。

    While few-shot learning as a transfer learning paradigm has gained significant traction for scenarios with limited data, it has primarily been explored in the context of building unimodal and unilingual models. Furthermore, a significant part of the existing literature in the domain of few-shot multitask learning perform in-context learning which requires manually generated prompts as the input, yielding varying outcomes depending on the level of manual prompt-engineering. In addition, in-context learning suffers from substantial computational, memory, and storage costs which eventually leads to high inference latency because it involves running all of the prompt's examples through the model every time a prediction is made. In contrast, methods based on the transfer learning via the fine-tuning paradigm avoid the aforementioned issues at a one-time cost of fine-tuning weights on a per-task basis. However, such methods lack exposure to few-shot multimodal multitask learning. In this pap
    
[^36]: 医学图像分析中高效标记深度学习的挑战与未来方向

    Label-Efficient Deep Learning in Medical Image Analysis: Challenges and Future Directions. (arXiv:2303.12484v1 [cs.CV])

    [http://arxiv.org/abs/2303.12484](http://arxiv.org/abs/2303.12484)

    近年来深度学习在医学图像分析中取得了最先进的性能，但这种方法的标记代价大，标记不足。因此发展了高效标记深度学习方法，充分利用未标记的和弱标记的数据。该综述总结了这方面的最新进展。

    

    深度学习近年来得到了迅速发展，并在广泛应用中取得了最先进的性能。但是，训练模型通常需要收集大量标记数据，这需要昂贵耗时。特别是在医学图像分析（MIA）领域，数据有限，标签很难获得。因此，人们开发了高效标记深度学习方法，充分利用标记数据以及非标记和弱标记数据的丰富性。在本调查中，我们对近300篇论文进行了广泛调查，以全面概述最新进展的高效标记学习策略在MIA中的研究现状。我们首先介绍高效标记学习的背景，并将不同方案的方法归类。接下来，我们通过每种方案详细研究了目前最先进的方法。具体而言，我们进行了深入调查，覆盖了不仅是标准策略，还包括使用后处理和集合方法等方法。

    Deep learning has seen rapid growth in recent years and achieved state-of-the-art performance in a wide range of applications. However, training models typically requires expensive and time-consuming collection of large quantities of labeled data. This is particularly true within the scope of medical imaging analysis (MIA), where data are limited and labels are expensive to be acquired. Thus, label-efficient deep learning methods are developed to make comprehensive use of the labeled data as well as the abundance of unlabeled and weak-labeled data. In this survey, we extensively investigated over 300 recent papers to provide a comprehensive overview of recent progress on label-efficient learning strategies in MIA. We first present the background of label-efficient learning and categorize the approaches into different schemes. Next, we examine the current state-of-the-art methods in detail through each scheme. Specifically, we provide an in-depth investigation, covering not only canonic
    
[^37]: 劳务分工中的外部性。

    Externalities in Chore Division. (arXiv:2303.12446v1 [cs.GT])

    [http://arxiv.org/abs/2303.12446](http://arxiv.org/abs/2303.12446)

    该论文研究了劳务分工中的外部性问题，扩展了经典模型考虑到其他代理的影响。

    

    劳务分工问题模拟了不同的资源在多个代理之间的公平分配。在公平分配问题中，每个代理只从自己的资源中获得价值。然而，代理也可能关注分配给其他代理的资源，这些外部性自然地出现在公平分配的情况中。Branzei等人通过扩展经典模型以考虑外部性，推广了比例和无嫉妒性的经典思想。（Branzei et al。，IJCAI 2013）

    The chore division problem simulates the fair division of a heterogeneous undesirable resource among several agents. In the fair division problem, each agent only gains value from its own piece. Agents may, however, also be concerned with the pieces given to other agents; these externalities naturally appear in fair division situations. Branzei et ai. (Branzei et al., IJCAI 2013) generalize the classical ideas of proportionality and envy-freeness while extending the classical model to account for externalities.
    
[^38]: MEDIMP: 用于肾移植表示学习的医学图像和提示

    MEDIMP: Medical Images and Prompts for renal transplant representation learning. (arXiv:2303.12445v1 [cs.CV])

    [http://arxiv.org/abs/2303.12445](http://arxiv.org/abs/2303.12445)

    MEDIMP是一种用于多模式学习肾移植DCE MRI的医学图像和提示模型，利用联合文本-图像嵌入的对比学习来学习有意义的表示。

    

    肾移植已成为终末期肾脏疾病的最有效解决方案。由于复杂原因，移植慢性功能障碍的重大风险仍然存在，可能导致移植失败。医学影像在肾移植监测中发挥着重要作用。然而，移植监督具有多学科特点，尤其是结合了肾脏学、泌尿学和放射学，在这种高维度和复杂数据中识别强大的生物标志物用于预后是具有挑战性的。本文受到大型语言模型（LLMs）的最近成功启发，提出了MEDIMP——医学影像和提示——一种用于多模式学习肾移植动态对比增强磁共振成像（DCE MRI）有意义的表示模型，通过将结构性临床生物数据翻译成文本提示来完成。MEDIMP基于联合文本-图像嵌入的对比学习，以执行这项具有挑战性的任务。

    Renal transplantation emerges as the most effective solution for end-stage renal disease. Occurring from complex causes, a substantial risk of transplant chronic dysfunction persists and may lead to graft loss. Medical imaging plays a substantial role in renal transplant monitoring in clinical practice. However, graft supervision is multi-disciplinary, notably joining nephrology, urology, and radiology, while identifying robust biomarkers from such high-dimensional and complex data for prognosis is challenging. In this work, taking inspiration from the recent success of Large Language Models (LLMs), we propose MEDIMP -- Medical Images and Prompts -- a model to learn meaningful multi-modal representations of renal transplant Dynamic Contrast-Enhanced Magnetic Resonance Imaging (DCE MRI) by incorporating structural clinicobiological data after translating them into text prompts. MEDIMP is based on contrastive learning from joint text-image paired embeddings to perform this challenging ta
    
[^39]: $P^{3}O$: Prompting方法中用于强化学习的视觉表示迁移

    $P^{3}O$: Transferring Visual Representations for Reinforcement Learning via Prompting. (arXiv:2303.12371v1 [cs.CV])

    [http://arxiv.org/abs/2303.12371](http://arxiv.org/abs/2303.12371)

    本论文提出一种名为$P^{3}O$的三阶段DRL算法，通过提问来转移视觉表示，显著优于现有的视觉传输方案。

    

    在深度强化学习算法中，将学到的策略转移至视觉输入不同的新环境是非常重要的。本文提出了一种基于Prompt的近端策略优化($P^{3}O$)的三阶段DRL算法，通过应用Prompt使得视觉表示从目标环境传递到源环境。$P^{3}O$的过程包括三个阶段:预训练、Prompting和预测。我们提出了一个Prompt-Transformer用于表示转换，并针对目标环境提出了一个两步训练过程，训练Prompt-Transformer，而DRL管道的其余部分保持不变。我们在OpenAI CarRacing视频游戏上实施$P^{3}O$并进行评估。实验结果表明，$P^{3}O$优于最先进的视觉转移方案，而且能让学到的策略在视觉输入不同的环境中表现良好，这是非常重要的。

    It is important for deep reinforcement learning (DRL) algorithms to transfer their learned policies to new environments that have different visual inputs. In this paper, we introduce Prompt based Proximal Policy Optimization ($P^{3}O$), a three-stage DRL algorithm that transfers visual representations from a target to a source environment by applying prompting. The process of $P^{3}O$ consists of three stages: pre-training, prompting, and predicting. In particular, we specify a prompt-transformer for representation conversion and propose a two-step training process to train the prompt-transformer for the target environment, while the rest of the DRL pipeline remains unchanged. We implement $P^{3}O$ and evaluate it on the OpenAI CarRacing video game. The experimental results show that $P^{3}O$ outperforms the state-of-the-art visual transferring schemes. In particular, $P^{3}O$ allows the learned policies to perform well in environments with different visual inputs, which is much more e
    
[^40]: ExBEHRT：基于电子病历的扩展Transformer预测疾病亚型和进展

    ExBEHRT: Extended Transformer for Electronic Health Records to Predict Disease Subtypes & Progressions. (arXiv:2303.12364v1 [cs.LG])

    [http://arxiv.org/abs/2303.12364](http://arxiv.org/abs/2303.12364)

    ExBEHRT是一种扩展Transformer模型，应用于电子病历数据，将多种类型的记录包括在特征空间中，可以预测不同疾病下游任务的性能更好，并使用预期梯度对结果进行更细粒度的解释。

    

    本研究引入了ExBEHRT，它是BEHRT（应用于电子病历的BERT）的扩展版本，并应用不同的算法来解释其结果。我们将特征空间从仅考虑诊断和患者年龄扩展到包括多种类型的记录，包括人口统计学、临床特征、生命体征、吸烟状态、诊断、手术、药物和实验室检查，并采用一种新方法来统一不同特征的频率和时间维度。我们展示了附加特征可以显著改善不同疾病下游任务的模型性能。为了保证模型的稳健性，我们使用了预期梯度的改进方法对模型预测结果进行解释，该方法以前未应用于将EHR数据与Transformer相结合，提供了比以前方法更细粒度的解释，如特征和令牌重要性。此外，通过对肿瘤学患者的模型表示进行聚类，我们展示了ExBEHRT可以用于预测疾病亚型和进展。

    In this study, we introduce ExBEHRT, an extended version of BEHRT (BERT applied to electronic health records), and apply different algorithms to interpret its results. While BEHRT considers only diagnoses and patient age, we extend the feature space to several multimodal records, namely demographics, clinical characteristics, vital signs, smoking status, diagnoses, procedures, medications, and laboratory tests, by applying a novel method to unify the frequencies and temporal dimensions of the different features. We show that additional features significantly improve model performance for various downstream tasks in different diseases. To ensure robustness, we interpret model predictions using an adaptation of expected gradients, which has not been previously applied to transformers with EHR data and provides more granular interpretations than previous approaches such as feature and token importances. Furthermore, by clustering the model representations of oncology patients, we show tha
    
[^41]: Wasserstein空间的对抗性例子用于单变量时间序列数据

    Wasserstein Adversarial Examples on Univariant Time Series Data. (arXiv:2303.12357v1 [cs.LG])

    [http://arxiv.org/abs/2303.12357](http://arxiv.org/abs/2303.12357)

    该论文为时间序列数据提出了一种新的对抗性攻击方法WPGD，利用Wasserstein距离限制正常样本和对抗性例子之间的扰动。实验结果表明该方法能够成功地对单变量时间序列数据进行对抗性攻击，并显著提高成功率。

    

    对抗性例子是通过向正常样本添加无法区分的扰动来欺骗良好训练的深度学习模型，使其错误地分类。在计算机视觉的背景下，区分度的概念通常由$L_{\infty}$或其他规范来限定，但是这些规范不适用于时间序列数据的区分度衡量。在本研究中，我们首次针对时间序列数据提出了Wasserstein空间中的对抗性例子，并利用Wasserstein距离来限定正常样本和对抗性例子之间的扰动。我们引入了Wasserstein投影梯度下降（WPGD），一种扰动单变量时间序列数据的对抗性攻击方法。我们利用1D空间中Wasserstein距离的封闭形式解来计算WPGD的投影步骤，以最小化扰动。我们进一步提出了两步投影方法，以有效进行在Wasserstein空间中的对抗性例子搜索。我们的实验结果表明，与其他最先进的方法相比，WPGD能够成功地对单变量时间序列数据进行对抗性攻击，并显著提高攻击的成功率。

    Adversarial examples are crafted by adding indistinguishable perturbations to normal examples in order to fool a well-trained deep learning model to misclassify. In the context of computer vision, this notion of indistinguishability is typically bounded by $L_{\infty}$ or other norms. However, these norms are not appropriate for measuring indistinguishiability for time series data. In this work, we propose adversarial examples in the Wasserstein space for time series data for the first time and utilize Wasserstein distance to bound the perturbation between normal examples and adversarial examples. We introduce Wasserstein projected gradient descent (WPGD), an adversarial attack method for perturbing univariant time series data. We leverage the closed-form solution of Wasserstein distance in the 1D space to calculate the projection step of WPGD efficiently with the gradient descent method. We further propose a two-step projection so that the search of adversarial examples in the Wassers
    
[^42]: 人工智能与双重合同

    Artificial Intelligence and Dual Contract. (arXiv:2303.12350v1 [cs.AI])

    [http://arxiv.org/abs/2303.12350](http://arxiv.org/abs/2303.12350)

    本文通过实验研究了人工智能算法在双重合同问题中能够自主设计激励相容的合同，无需外部引导或通信，并且不同AI算法支持的委托人可以采用混合和零和博弈行为，更具智能的委托人往往会变得合作。

    

    随着人工智能算法的快速进步，人们希望算法很快就能在各个领域取代人类决策者，例如合同设计。我们通过实验研究了由人工智能（多智能体Q学习）驱动的算法在双重委托-代理问题的经典“双重合同”模型中的行为。我们发现，这些AI算法可以自主学习设计合适的激励相容合同，而无需外部引导或者它们之间的通信。我们强调，由不同AI算法支持的委托人可以采用混合和零和博弈行为。我们还发现，更具智能的委托人往往会变得合作，而智能较低的委托人则会出现内生性近视并倾向于竞争。在最优合同下，代理的较低合同激励由委托人之间的勾结策略维持。

    With the dramatic progress of artificial intelligence algorithms in recent times, it is hoped that algorithms will soon supplant human decision-makers in various fields, such as contract design. We analyze the possible consequences by experimentally studying the behavior of algorithms powered by Artificial Intelligence (Multi-agent Q-learning) in a workhorse \emph{dual contract} model for dual-principal-agent problems. We find that the AI algorithms autonomously learn to design incentive-compatible contracts without external guidance or communication among themselves. We emphasize that the principal, powered by distinct AI algorithms, can play mixed-sum behavior such as collusion and competition. We find that the more intelligent principals tend to become cooperative, and the less intelligent principals are endogenizing myopia and tend to become competitive. Under the optimal contract, the lower contract incentive to the agent is sustained by collusive strategies between the principals
    
[^43]: NUWA-XL: 扩散过程在极长视频生成中的应用

    NUWA-XL: Diffusion over Diffusion for eXtremely Long Video Generation. (arXiv:2303.12346v1 [cs.CV])

    [http://arxiv.org/abs/2303.12346](http://arxiv.org/abs/2303.12346)

    NUWA-XL采用扩散过程，在极长视频的生成中实现了由粗到细的过程，减小了训练-推断之间的差距，并且使得所有的段落都可以并行生成。

    

    本文提出了一种新颖的NUWA-XL扩散过程架构，用于极长视频的生成。我们提出了一个“由粗到细”的过程，应用全局扩散模型在整个时间范围内生成关键帧，并且递归地应用本地扩散模型填充相邻帧之间的内容。这种简单而有效的策略使我们能够直接在长视频（3376帧）上进行训练，从而减小了训练-推断之间的差距，并且使得所有的段落都可以并行生成。

    In this paper, we propose NUWA-XL, a novel Diffusion over Diffusion architecture for eXtremely Long video generation. Most current work generates long videos segment by segment sequentially, which normally leads to the gap between training on short videos and inferring long videos, and the sequential generation is inefficient. Instead, our approach adopts a ``coarse-to-fine'' process, in which the video can be generated in parallel at the same granularity. A global diffusion model is applied to generate the keyframes across the entire time range, and then local diffusion models recursively fill in the content between nearby frames. This simple yet effective strategy allows us to directly train on long videos (3376 frames) to reduce the training-inference gap, and makes it possible to generate all segments in parallel. To evaluate our model, we build FlintstonesHD dataset, a new benchmark for long video generation. Experiments show that our model not only generates high-quality long vid
    
[^44]: 一种用于按需乘车服务运营的多功能模拟平台

    A multi-functional simulation platform for on-demand ride service operations. (arXiv:2303.12336v1 [cs.AI])

    [http://arxiv.org/abs/2303.12336](http://arxiv.org/abs/2303.12336)

    本文介绍了一种用于按需乘车服务操作的多功能模拟平台，该平台具有高度的模块化，可扩展性和灵活性，在操作效率和公平性评估，优化算法调整以及实时动态操作控制等方面均能发挥作用，并为研究人员和实践者提供了一个公共的平台。

    

    过去十年中，按需乘车服务或乘车共享服务飞速发展。已经开发了各种数学模型和优化算法，帮助乘车共享平台设计更高效的运营策略。然而，由于成本和可靠性问题（对于真实操作实现不成熟的算法可能导致系统波动），在实际世界乘车共享平台内验证这些模型并训练/测试这些优化算法通常是不可行的。作为一个有用的测试平台，乘车共享系统的模拟平台将非常重要，以通过试验和误差进行算法训练/测试或模型验证。尽管先前的研究已经为他们自己的任务建立了各种模拟器，但缺少一个公正和公开的平台来比较不同研究人员提出的模型或算法。此外，现有的模拟器面临许多挑战，从灵活性、可扩展性到真实度都有。在本文中，我们介绍了一种用于按需乘车服务操作的多功能模拟平台，其具有高度的模块化、可扩展性和灵活性，能够实现各种用户场景和系统配置。我们通过几个案例研究展示了我们平台的有用性，包括操作效率和公平性评估，优化算法调整以及实时动态操作控制。我们的平台不仅为研究人员提供了一个比较各种算法和模型的公共平台，而且还可以由实践者直接使用，以提高他们的操作效率和用户体验。

    On-demand ride services or ride-sourcing services have been experiencing fast development in the past decade. Various mathematical models and optimization algorithms have been developed to help ride-sourcing platforms design operational strategies with higher efficiency. However, due to cost and reliability issues (implementing an immature algorithm for real operations may result in system turbulence), it is commonly infeasible to validate these models and train/test these optimization algorithms within real-world ride sourcing platforms. Acting as a useful test bed, a simulation platform for ride-sourcing systems will be very important to conduct algorithm training/testing or model validation through trails and errors. While previous studies have established a variety of simulators for their own tasks, it lacks a fair and public platform for comparing the models or algorithms proposed by different researchers. In addition, the existing simulators still face many challenges, ranging fr
    
[^45]: 冻结语言模型助力心电信号零样本学习

    Frozen Language Model Helps ECG Zero-Shot Learning. (arXiv:2303.12311v1 [cs.LG])

    [http://arxiv.org/abs/2303.12311](http://arxiv.org/abs/2303.12311)

    该论文提出了一种名为METS的心电图分类方法，使用可训练的心电编码器和冻结的语言模型分别嵌入配对的心电图和自动生成的机器临床报告，以实现心电图零样本学习，并在两个基准心电图数据集上获得了比其他最先进的方法更好的性能。

    

    心电图是一种常用的非侵入式、方便的医疗监测工具，可辅助临床诊断心脏疾病。最近，深度学习（DL）技术，特别是自监督学习（SSL），在心电图分类方面展示出了巨大的潜力。在微调之后，SSL的预训练仅依靠少量的注释数据就取得了有竞争力的性能。然而，当前的SSL方法依赖于注释数据的可用性，无法预测微调数据集中不存在的标签。为了解决这一挑战，我们提出了多模态心电图文本自监督预训练（METS），这是第一篇利用自动生成的临床报告来指导心电图SSL预训练的工作。我们使用可训练的心电编码器和冻结的语言模型分别嵌入配对的心电图和自动生成的机器临床报告。SSL旨在最大化心电图和自动生成的报告之间的相似性，同时确保心电和文本模态的嵌入对齐良好。在两个基准心电图数据集上的实验结果表明，METS在零样本学习和少样本学习设置中显著改善了心电图分类性能，优于各种最先进的方法。

    The electrocardiogram (ECG) is one of the most commonly used non-invasive, convenient medical monitoring tools that assist in the clinical diagnosis of heart diseases. Recently, deep learning (DL) techniques, particularly self-supervised learning (SSL), have demonstrated great potential in the classification of ECG. SSL pre-training has achieved competitive performance with only a small amount of annotated data after fine-tuning. However, current SSL methods rely on the availability of annotated data and are unable to predict labels not existing in fine-tuning datasets. To address this challenge, we propose Multimodal ECG-Text Self-supervised pre-training (METS), the first work to utilize the auto-generated clinical reports to guide ECG SSL pre-training. We use a trainable ECG encoder and a frozen language model to embed paired ECG and automatically machine-generated clinical reports separately. The SSL aims to maximize the similarity between paired ECG and auto-generated report while 
    
[^46]: 长尾分类的曲率平衡特征流形学习

    Curvature-Balanced Feature Manifold Learning for Long-Tailed Classification. (arXiv:2303.12307v1 [cs.CV])

    [http://arxiv.org/abs/2303.12307](http://arxiv.org/abs/2303.12307)

    本文提出了一种曲率平衡特征流形学习的方法，探究了感知流形的几何特性对分类难度的影响，发现曲率不平衡会导致模型不公平。

    

    为了应对长尾分类的挑战，研究人员已经提出了几种方法来减少模型偏差，其中大多数假设样本较少的类是弱类。然而，最近的研究表明，尾部类别并不总是难以学习的，而在样本平衡的数据集上观察到了模型偏差，这表明存在其他影响模型偏差的因素。在本文中，我们系统地提出了一系列用于深度神经网络中感知流形的几何度量，并探讨了感知流形的几何特性对分类难度和学习如何塑造感知流形的几何特性的影响。一个意外的发现是：类别准确度和感知流形的分离程度之间的相关性在训练过程中逐渐减小，而与曲率的负相关性逐渐增加，这表明曲率不平衡导致模型不公平。

    To address the challenges of long-tailed classification, researchers have proposed several approaches to reduce model bias, most of which assume that classes with few samples are weak classes. However, recent studies have shown that tail classes are not always hard to learn, and model bias has been observed on sample-balanced datasets, suggesting the existence of other factors that affect model bias. In this work, we systematically propose a series of geometric measurements for perceptual manifolds in deep neural networks, and then explore the effect of the geometric characteristics of perceptual manifolds on classification difficulty and how learning shapes the geometric characteristics of perceptual manifolds. An unanticipated finding is that the correlation between the class accuracy and the separation degree of perceptual manifolds gradually decreases during training, while the negative correlation with the curvature gradually increases, implying that curvature imbalance leads to m
    
[^47]: 知识图谱推理的图神经网络的逻辑表达能力

    Logical Expressiveness of Graph Neural Network for Knowledge Graph Reasoning. (arXiv:2303.12306v1 [cs.LG])

    [http://arxiv.org/abs/2303.12306](http://arxiv.org/abs/2303.12306)

    本文提出了一种理论分析图神经网络在知识图谱推理方面的逻辑表达能力的方法，并发现图神经网络可以从分级模态逻辑中捕获逻辑规则，从而设计出更好的知识图谱推理方法。

    

    近年来，图神经网络被引入用于学习知识图谱，并在知识图谱推理方面取得了最先进的性能。然而，对于它们良好的经验性能缺乏理论证明。此外，虽然知识图谱中的逻辑对于归纳和可解释的推理非常重要，但现有的基于图神经网络的方法只是为了适应数据分布，并且对它们的逻辑表达能力知之甚少。本文旨在填补上述空白。具体而言，我们从逻辑的表达能力对GNN进行理论分析，并找出知识图谱中可以捕获哪些逻辑规则。我们的结果首先表明，GNN可以从分级模态逻辑中捕获逻辑规则，为分析GNN在知识图谱推理方面的表达能力提供了新的理论工具；而一个查询标记技巧使得GNN更容易捕获逻辑规则，解释了为什么最先进的方法主要基于标记技巧。最后，我们理论上的见解促进了一个新的基于GNN的知识图谱推理方法的设计，它可以充分利用逻辑表达能力并实现更好的性能。

    Graph Neural Networks (GNNs) have been recently introduced to learn from knowledge graph (KG) and achieved state-of-the-art performance in KG reasoning. However, a theoretical certification for their good empirical performance is still absent. Besides, while logic in KG is important for inductive and interpretable inference, existing GNN-based methods are just designed to fit data distributions with limited knowledge of their logical expressiveness. We propose to fill the above gap in this paper. Specifically, we theoretically analyze GNN from logical expressiveness and find out what kind of logical rules can be captured from KG. Our results first show that GNN can capture logical rules from graded modal logic, providing a new theoretical tool for analyzing the expressiveness of GNN for KG reasoning; and a query labeling trick makes it easier for GNN to capture logical rules, explaining why SOTA methods are mainly based on labeling trick. Finally, insights from our theory motivate the 
    
[^48]: SiamTHN：Siamese目标突出网络用于视觉跟踪

    SiamTHN: Siamese Target Highlight Network for Visual Tracking. (arXiv:2303.12304v1 [cs.CV])

    [http://arxiv.org/abs/2303.12304](http://arxiv.org/abs/2303.12304)

    本文提出了SiamTHN跟踪器，使用目标突出模块帮助相似性响应图集中在目标区域，使用校正损失进一步提高模型的精度，取得了在多个基准测试上的最新性能。

    

    最近，基于孪生网络的跟踪器在视觉目标跟踪领域迅速发展。现在大多数使用的孪生网络跟踪器将由主干网络生成的特征图中的每个通道平等处理，这使得相似性响应图对背景影响敏感，因此难以集中在目标区域。此外，这些跟踪器的分类和回归分支之间没有结构链接，两个分支在训练期间独立优化。因此，分类和回归分支之间存在不对齐，导致跟踪结果不够精确。为了帮助生成的相似性响应图更加集中在目标区域，本文提出了一个目标突出模块。为了减少不对齐并产生更精确的跟踪结果，我们提出了一种校正损失来训练模型。使用这个校正损失，我们共同调整了模型的两个分支，使它们的结构更好地匹配。实验结果表明，所提出的SiamTHN跟踪器在多个跟踪基准测试，如VOT2018、VOT2019和LaSOT上均取得了最新的性能。

    Siamese network based trackers develop rapidly in the field of visual object tracking in recent years. The majority of siamese network based trackers now in use treat each channel in the feature maps generated by the backbone network equally, making the similarity response map sensitive to background influence and hence challenging to focus on the target region. Additionally, there are no structural links between the classification and regression branches in these trackers, and the two branches are optimized separately during training. Therefore, there is a misalignment between the classification and regression branches, which results in less accurate tracking results. In this paper, a Target Highlight Module is proposed to help the generated similarity response maps to be more focused on the target region. To reduce the misalignment and produce more precise tracking results, we propose a corrective loss to train the model. The two branches of the model are jointly tuned with the use o
    
[^49]: 原型有助于联邦学习：实现更快的收敛

    Prototype Helps Federated Learning: Towards Faster Convergence. (arXiv:2303.12296v1 [cs.LG])

    [http://arxiv.org/abs/2303.12296](http://arxiv.org/abs/2303.12296)

    本文提出一种基于原型的联邦学习框架，可以在只对联邦学习进行少量更改的情况下，提高模型推断的性能和精度，并实现高效的通信。

    

    联邦学习（FL）是一种分布式机器学习技术，多个客户端合作训练共享模型而不交换原始数据。然而，不同客户端数据分布的异质性通常导致模型推断能力不佳。本文提出一种基于原型的联邦学习框架，而只需对典型的联邦学习过程的最后一个全局迭代进行少量更改，即可实现更好的推断性能。在最后一次迭代中，服务器聚合从分布式客户端传输的原型，然后将其发送回本地客户端，以用于各自的模型推断。在两个基准数据集上的实验表明，我们的提议在不同的异质性设置下，可以实现比两个流行基准更高的准确性（至少1％）和相对高效的通信。

    Federated learning (FL) is a distributed machine learning technique in which multiple clients cooperate to train a shared model without exchanging their raw data. However, heterogeneity of data distribution among clients usually leads to poor model inference. In this paper, a prototype-based federated learning framework is proposed, which can achieve better inference performance with only a few changes to the last global iteration of the typical federated learning process. In the last iteration, the server aggregates the prototypes transmitted from distributed clients and then sends them back to local clients for their respective model inferences. Experiments on two baseline datasets show that our proposal can achieve higher accuracy (at least 1%) and relatively efficient communication than two popular baselines under different heterogeneous settings.
    
[^50]: 使用强化学习改善自动驾驶汽车与行人交互的自适应道路配置

    Adaptive Road Configurations for Improved Autonomous Vehicle-Pedestrian Interactions using Reinforcement Learning. (arXiv:2303.12289v1 [cs.LG])

    [http://arxiv.org/abs/2303.12289](http://arxiv.org/abs/2303.12289)

    该论文使用强化学习方法探讨如何动态生成行人和自动驾驶汽车 ROW 计划，优化交通流的效率，为行人分配更多空间。

    

    自动驾驶汽车的部署为未来城市道路基础设施的设计和管理提供了重大挑战和独特的机遇。为了重新定义道路空间的 ROW 构成，已经提出了多种设计方法和智能控制模型，但缺乏一个可以根据实时需求动态生成行人和自动驾驶汽车 ROW 计划的操作框架。本研究基于微观交通仿真，探讨了使用强化学习方法来改进 ROW 构成的方法。我们分别实现了集中式范式和分布式学习范式，以分别对多个路网配置进行动态控制。实验结果表明，这些算法有潜力提高交通流的效率并分配更多的空间给行人。此外，分布式学习算法优于集中式算法并实现了更好的训练效率。

    The deployment of Autonomous Vehicles (AVs) poses considerable challenges and unique opportunities for the design and management of future urban road infrastructure. In light of this disruptive transformation, the Right-Of-Way (ROW) composition of road space has the potential to be renewed. Design approaches and intelligent control models have been proposed to address this problem, but we lack an operational framework that can dynamically generate ROW plans for AVs and pedestrians in response to real-time demand. Based on microscopic traffic simulation, this study explores Reinforcement Learning (RL) methods for evolving ROW compositions. We implement a centralised paradigm and a distributive learning paradigm to separately perform the dynamic control on several road network configurations. Experimental results indicate that the algorithms have the potential to improve traffic flow efficiency and allocate more space for pedestrians. Furthermore, the distributive learning algorithm outp
    
[^51]: 独立学习和稀疏均衡计算在马尔可夫博弈中的难度

    Hardness of Independent Learning and Sparse Equilibrium Computation in Markov Games. (arXiv:2303.12287v1 [cs.LG])

    [http://arxiv.org/abs/2303.12287](http://arxiv.org/abs/2303.12287)

    本文研究了分散式多智能体强化学习的问题，证明了在标准马尔可夫博弈框架下不存在可获得纳什均衡且可独立学习的算法。

    

    本文研究了马尔可夫博弈中分散式多智能体强化学习的问题。一个基本问题是，是否存在算法，当所有代理采用并在分散方式下独立运行时，每个玩家都可以不后悔地进展，类似于正常形式游戏中的著名收敛结果。虽然最近的研究表明，在受限制的情况下（特别是当后悔与马尔可夫策略的偏离有关时），这种算法存在，但是独立的不后悔学习是否能在标准的马尔可夫博弈框架下实现是值得探讨的问题。我们从计算和统计角度相应地提出了一个明确的否定解决这个问题。

    We consider the problem of decentralized multi-agent reinforcement learning in Markov games. A fundamental question is whether there exist algorithms that, when adopted by all agents and run independently in a decentralized fashion, lead to no-regret for each player, analogous to celebrated convergence results in normal-form games. While recent work has shown that such algorithms exist for restricted settings (notably, when regret is defined with respect to deviations to Markovian policies), the question of whether independent no-regret learning can be achieved in the standard Markov game framework was open. We provide a decisive negative resolution this problem, both from a computational and statistical perspective. We show that:  - Under the widely-believed assumption that PPAD-hard problems cannot be solved in polynomial time, there is no polynomial-time algorithm that attains no-regret in general-sum Markov games when executed independently by all players, even when the game is kno
    
[^52]: 基于机器学习的空气污染降低方法

    Reducing Air Pollution through Machine Learning. (arXiv:2303.12285v1 [cs.LG])

    [http://arxiv.org/abs/2303.12285](http://arxiv.org/abs/2303.12285)

    本文介绍了一种基于机器学习的方法来将工业生产对周边城市的空气污染影响降至最低，同时保持生产活动。该方法结合了预测和指导式机器学习模型，并将环境影响减少和生产维持之间达成了多种权衡方案。

    

    本文提出了一种基于数据驱动的方法来减少工业生产对周边城市的空气污染效应，该方法将运营决策与天气条件相结合。我们的方法结合了预测和指导式机器学习模型来预测短期风速和方向，并推荐运营决策以减少或暂停工业生产。我们展示了减少环境影响和维持生产活动之间的几种权衡。我们框架的预测组件采用各种机器学习模型，如梯度提升树模型和集成方法，进行时间序列预测。指导性组件利用可解释的最优策略树提出多个权衡方案，例如将危险排放物减少33-47%和将不必要的成本降低40-63%。我们部署的模型显著降低了预测误差，对于小于12小时的预测，降低了38-52%的误差范围，对于12到48小时的预测，降低了14-46%的误差范围。

    This paper presents a data-driven approach to mitigate the effects of air pollution from industrial plants on nearby cities by linking operational decisions with weather conditions. Our method combines predictive and prescriptive machine learning models to forecast short-term wind speed and direction and recommend operational decisions to reduce or pause the industrial plant's production. We exhibit several trade-offs between reducing environmental impact and maintaining production activities. The predictive component of our framework employs various machine learning models, such as gradient-boosted tree-based models and ensemble methods, for time series forecasting. The prescriptive component utilizes interpretable optimal policy trees to propose multiple trade-offs, such as reducing dangerous emissions by 33-47% and unnecessary costs by 40-63%. Our deployed models significantly reduced forecasting errors, with a range of 38-52% for less than 12-hour lead time and 14-46% for 12 to 48-
    
[^53]: 使用Prompt Programming和GPT-3生成标记训练数据——以大五人格分类为例

    Generate labeled training data using Prompt Programming and GPT-3. An example of Big Five Personality Classification. (arXiv:2303.12279v1 [cs.HC])

    [http://arxiv.org/abs/2303.12279](http://arxiv.org/abs/2303.12279)

    本研究使用Prompt Programming和GPT-3技术生成了大量带有特征标记的对话数据，有效用于训练大五人格分类模型。

    

    我们使用Prompt Programming和GPT-3生成了25000个带有大五人格特征标记的对话，并使用这些数据训练了大五分类模型。随后，我们使用2500条来自生成对话和真实对话数据集的人类注释的大五标记数据对这些模型进行了评估。结果表明，这种方法有望创建有效的训练数据。我们进一步比较了不同的训练方法和模型的性能。我们的结果表明，使用Adapter-Transformers和来自预训练RoBERTa情感分析模型的迁移学习将在生成的数据中表现最佳。我们的最佳模型在生成的数据中获得了0.71的准确率，在真实数据集中获得了0.65的准确率。最后，我们讨论了这种方法的潜在限制和置信度度量。

    We generated 25000 conversations labeled with Big Five Personality traits using prompt programming at GPT-3. Then we train Big Five classification models with these data and evaluate them with 2500 data from generated dialogues and real conversational datasets labeled in Big Five by human annotators. The results indicated that this approach is promising for creating effective training data. We then compare the performance by different training approaches and models. Our results suggest that using Adapter-Transformers and transfer learning from pre-trained RoBERTa sentiment analysis model will perform best with the generated data. Our best model obtained an accuracy of 0.71 in generated data and 0.65 in real datasets. Finally, we discuss this approach's potential limitations and confidence metric.
    
[^54]: 自主式小鼠颅窗骨抽样机器人钻孔系统：一个基于蛋模型的评估。

    Autonomous Robotic Drilling System for Mice Cranial Window Creation: An Evaluation with an Egg Model. (arXiv:2303.12265v1 [cs.RO])

    [http://arxiv.org/abs/2303.12265](http://arxiv.org/abs/2303.12265)

    本文提出了一种针对小鼠颅骨不均匀问题的自主式机器人操作系统。

    

    在生命科学实验中，机器人技术的应用可以使得对实验样本进行精确操作，不受科学家技能的限制。本研究以小鼠颅窗的骨抽样操作为例，考虑小鼠颅骨的不均匀情况，提出了一种自主式操作机器人系统。

    Robotic assistance for experimental manipulation in the life sciences is expected to enable precise manipulation of valuable samples, regardless of the skill of the scientist. Experimental specimens in the life sciences are subject to individual variability and deformation, and therefore require autonomous robotic control. As an example, we are studying the installation of a cranial window in a mouse. This operation requires the removal of the skull, which is approximately 300 um thick, to cut it into a circular shape 8 mm in diameter, but the shape of the mouse skull varies depending on the strain of mouse, sex and week of age. The thickness of the skull is not uniform, with some areas being thin and others thicker. It is also difficult to ensure that the skulls of the mice are kept in the same position for each operation. It is not realistically possible to measure all these features and pre-program a robotic trajectory for individual mice. The paper therefore proposes an autonomous 
    
[^55]: 模拟橡胶手幻觉的基于大脑启发的身体自我感知模型

    Brain-inspired bodily self-perception model that replicates the rubber hand illusion. (arXiv:2303.12259v1 [q-bio.NC])

    [http://arxiv.org/abs/2303.12259](http://arxiv.org/abs/2303.12259)

    该论文提出了一个基于大脑启发的身体自我感知模型，模拟橡胶手幻觉，为认识人类身体自我意识的计算机制提供了新的洞见。

    

    身体自我意识的核心是对自己身体拥有权的感知。最近，为了更深入地了解大脑对自身身体编码的机制，人们做出了各种尝试，发展出一个统一的理论框架来解释相关的行为和神经生理现象。一个核心问题是如何解释橡胶手幻觉这样的身体错觉实际发生的机制。尽管已经有了有关身体自我意识机制和可能相关的脑区的概念性描述，但现有的理论模型仍然缺乏解释大脑如何编码对自己身体的感知和如何使用神经网络生成我们主观感知的身体错觉的计算机制。在这里，我们整合身体自我意识的生物学发现，提出一个基于大脑启发的身体自我感知模型，使身体自我感知可以在没有外部刺激的情况下自主构建。基于该模型的模拟复制了橡胶手幻觉，并提供了对潜在神经机制的见解。

    At the core of bodily self-consciousness is the perception of the ownership of one's body. Recent efforts to gain a deeper understanding of the mechanisms behind the brain's encoding of the self-body have led to various attempts to develop a unified theoretical framework to explain related behavioral and neurophysiological phenomena. A central question to be explained is how body illusions such as the rubber hand illusion actually occur. Despite the conceptual descriptions of the mechanisms of bodily self-consciousness and the possible relevant brain areas, the existing theoretical models still lack an explanation of the computational mechanisms by which the brain encodes the perception of one's body and how our subjectively perceived body illusions can be generated by neural networks. Here we integrate the biological findings of bodily self-consciousness to propose a Brain-inspired bodily self-perception model, by which perceptions of bodily self can be autonomously constructed withou
    
[^56]: 通过直接对比学习预防不完整多视图聚类的维度崩塌

    Preventing Dimensional Collapse of Incomplete Multi-View Clustering via Direct Contrastive Learning. (arXiv:2303.12241v1 [cs.CV])

    [http://arxiv.org/abs/2303.12241](http://arxiv.org/abs/2303.12241)

    该论文提出了一种新的不完整多视图对比聚类框架，直接优化特征子空间，并利用重构学习和一致性学习的方式，有效避免了维度崩塌和不一致私有信息的影响，经实验证明其有效性。

    

    不完整多视图聚类（Incomplete multi-view clustering，IMVC）是一种无监督的方法，其中通过对比学习的IMVC由于其出色的性能而受到关注。现有的方法存在以下问题：1）在解决聚类期间潜在特征只在低维子空间有效的维度崩塌问题时过度依赖额外的投影头；但是，投影头中的许多参数是不必要的。2）恢复的视图包含不一致的私有信息，并且由于在同一特征上执行一致性学习和重构学习，无用的私有信息将误导常见语义的学习。为解决以上问题，我们提出了一种新的不完整多视图对比聚类框架。该框架直接优化潜在特征子空间，利用学习到的特征向量及其子向量进行重构学习和一致性学习，从而有效避免了维度崩塌，并降低了不一致私有信息的影响。在四个真实世界的数据集上的实验验证了我们模型的有效性。

    Incomplete multi-view clustering (IMVC) is an unsupervised approach, among which IMVC via contrastive learning has received attention due to its excellent performance. The previous methods have the following problems: 1) Over-reliance on additional projection heads when solving the dimensional collapse problem in which latent features are only valid in lower-dimensional subspaces during clustering. However, many parameters in the projection heads are unnecessary. 2) The recovered view contain inconsistent private information and useless private information will mislead the learning of common semantics due to consistent learning and reconstruction learning on the same feature. To address the above issues, we propose a novel incomplete multi-view contrastive clustering framework. This framework directly optimizes the latent feature subspace, utilizes the learned feature vectors and their sub-vectors for reconstruction learning and consistency learning, thereby effectively avoiding dimens
    
[^57]: 用于神经退行性疾病结构病理相关性定量分析的高分辨率7T离体MRI的自动化深度学习分割

    Automated deep learning segmentation of high-resolution 7 T ex vivo MRI for quantitative analysis of structure-pathology correlations in neurodegenerative diseases. (arXiv:2303.12237v1 [cs.CV])

    [http://arxiv.org/abs/2303.12237](http://arxiv.org/abs/2303.12237)

    本文提出了一个深度学习分割管道，用于离体MRI图像的自动化分割。基于37个标本的高分辨率7 T MRI图像，该方法可准确分割整个脑半球，包括皮层、皮质下结构、白质高信号以及正常出现的白质。该方法可为神经病理学研究提供帮助。

    

    相较于在 vivo MRI，大脑离体 MRI 提供了明显的优势，可用于可视化和表征详细的神经解剖，协助将微观组织学研究与形态测量相联系。然而，由于受限于标记数据集的有限可用性和扫描器硬件和采集协议的异质性，离体 MRI 的脑区域分割自动化方法并不发达。在本研究中，我们提出了一个高分辨率数据集，包含在7T全身MRI扫描器上扫描的37个离体人脑组织标本。我们开发了一个深度学习管道来分割皮层，通过对九种深度神经体系结构的性能进行基准测试。然后，我们对四个皮质下结构（尾状核，脑豆核，苍白球和丘脑）、白质高信号以及正常出现的白质进行分割。我们展示了不同标本的全脑半球之间的出色的泛化能力，也展示了在看不见的硬件上的泛化能力。我们的方法有潜力提高神经病理学和神经退行性疾病结构病理相关性的定量分析的效率和准确性。

    Ex vivo MRI of the brain provides remarkable advantages over in vivo MRI for visualizing and characterizing detailed neuroanatomy, and helps to link microscale histology studies with morphometric measurements. However, automated segmentation methods for brain mapping in ex vivo MRI are not well developed, primarily due to limited availability of labeled datasets, and heterogeneity in scanner hardware and acquisition protocols. In this work, we present a high resolution dataset of 37 ex vivo post-mortem human brain tissue specimens scanned on a 7T whole-body MRI scanner. We developed a deep learning pipeline to segment the cortical mantle by benchmarking the performance of nine deep neural architectures. We then segment the four subcortical structures: caudate, putamen, globus pallidus, and thalamus; white matter hyperintensities, and the normal appearing white matter. We show excellent generalizing capabilities across whole brain hemispheres in different specimens, and also on unseen i
    
[^58]: 基于基础设施的端到端学习和驾驶员失误预防

    Infrastructure-based End-to-End Learning and Prevention of Driver Failure. (arXiv:2303.12224v1 [cs.RO])

    [http://arxiv.org/abs/2303.12224](http://arxiv.org/abs/2303.12224)

    本论文介绍了一种基于循环神经网络的端到端训练方法来预测自动驾驶车辆中可能存在的故障和危险驾驶员，并在缩小的微型城市中进行了测试。

    

    智能交叉路口管理器可以通过检测自动驾驶车辆中的危险驾驶员或故障模式，警告接近交叉路口的来车，从而提高安全性。在这项工作中，我们介绍了FailureNet，这是一个在缩小的微型城市中基于轨迹对正常和不安全驾驶员进行端到端训练的循环神经网络。FailureNet观察车辆接近交叉口时的姿态，检测自主堆栈中是否存在故障，并警告交叉流量有潜在危险的驾驶员。FailureNet能够准确地识别控制故障、上游感知错误和超速驾驶员，与正常驾驶加以区别。该网络在MiniCity中进行训练和部署，与基于速度或频率的预测器相比，FailureNet的循环神经网络结构提供了更高的预测能力，当部署在硬件上时，其准确性高达84%以上。

    Intelligent intersection managers can improve safety by detecting dangerous drivers or failure modes in autonomous vehicles, warning oncoming vehicles as they approach an intersection. In this work, we present FailureNet, a recurrent neural network trained end-to-end on trajectories of both nominal and reckless drivers in a scaled miniature city. FailureNet observes the poses of vehicles as they approach an intersection and detects whether a failure is present in the autonomy stack, warning cross-traffic of potentially dangerous drivers. FailureNet can accurately identify control failures, upstream perception errors, and speeding drivers, distinguishing them from nominal driving. The network is trained and deployed with autonomous vehicles in the MiniCity. Compared to speed or frequency-based predictors, FailureNet's recurrent neural network structure provides improved predictive power, yielding upwards of 84% accuracy when deployed on hardware.
    
[^59]: 行为健康个性化介入的政策优化

    Policy Optimization for Personalized Interventions in Behavioral Health. (arXiv:2303.12206v1 [cs.LG])

    [http://arxiv.org/abs/2303.12206](http://arxiv.org/abs/2303.12206)

    研究如何通过数字平台传递的行为健康介入最大化健康结果和治疗成本，提出了一个名为DecompPI的新算法，从离线数据进行预测任务，减轻了在线实验的需要，并在理论上证明了该算法的可扩展性和渐近收敛性。

    

    问题定义：通过数字平台传递的行为健康介入，通过教育，激励，提醒和外展，有望显着改善健康结果。我们研究了在介入具有成本和能力限制的情况下，优化患者个性化介入以最大化某种长期结果的问题。方法/结果：本文提供了一种无模型方法来解决这个问题。我们发现，来自增强学习文献的通用无模型方法对于医疗应用来说过于数据密集，而更简单的赌臂问题方法取得了进展，但忽略了长期患者动态。我们提出了一种新算法，称为DecompPI，它近似于一步政策迭代。实现DecompPI只需从离线数据进行预测任务，减轻了在线实验的需要。在理论上，我们展示了在一种自然的结构假设下，DecompPI可以获得算法复杂度的渐近收敛性，同时保持一个可扩展的模型.

    Problem definition: Behavioral health interventions, delivered through digital platforms, have the potential to significantly improve health outcomes, through education, motivation, reminders, and outreach. We study the problem of optimizing personalized interventions for patients to maximize some long-term outcome, in a setting where interventions are costly and capacity-constrained.  Methodology/results: This paper provides a model-free approach to solving this problem. We find that generic model-free approaches from the reinforcement learning literature are too data intensive for healthcare applications, while simpler bandit approaches make progress at the expense of ignoring long-term patient dynamics. We present a new algorithm we dub DecompPI that approximates one step of policy iteration. Implementing DecompPI simply consists of a prediction task from offline data, alleviating the need for online experimentation. Theoretically, we show that under a natural set of structural assu
    
[^60]: 基于变压器的音视频HuBERT在中英文领域的应用实践

    Practice of the conformer enhanced AUDIO-VISUAL HUBERT on Mandarin and English. (arXiv:2303.12187v1 [eess.AS])

    [http://arxiv.org/abs/2303.12187](http://arxiv.org/abs/2303.12187)

    本文介绍了一种混合方法，conformer enhanced AV-HuBERT，可以在中英文的音视频识别任务中提高系统性能，该方法在英语AVSR数据集上相对于基线AV-HuBERT分别实现了7%和16%的相对WER降低，并建立了一个新的中文AVSR数据集CSTS，将WeNet ASR系统相应性能超越了14%和18%。

    

    考虑到人类语音感知的双模性质，嘴唇和牙齿的运动在自动语音识别中起着至关重要的作用。通过利用相关和噪声不变的视觉信息，音视频识别系统可以在多种情境下提高鲁棒性。本文提出了一种混合方法，命名为conformer enhanced AV-HuBERT，进一步提高了AV-HuBERT系统的性能。与基线AV-HuBERT相比，我们的方法在干净和嘈杂条件下的单阶段评估中，在英语AVSR基准数据集LRS3上分别实现了7%和16%的相对WER降低。此外，我们建立了一个新的1000小时的中文AVSR数据集CSTS。在基线AV-HuBERT的基础上，我们通过利用这个数据集的预训练，在MISP和CMLR上将WeNet ASR系统超越了14%和18%。我们提出的conformer enhanced AV-HuBERT在MISP上带来了7%的性能提升和6%的CER。

    Considering the bimodal nature of human speech perception, lips, and teeth movement has a pivotal role in automatic speech recognition. Benefiting from the correlated and noise-invariant visual information, audio-visual recognition systems enhance robustness in multiple scenarios. In previous work, audio-visual HuBERT appears to be the finest practice incorporating modality knowledge. This paper outlines a mixed methodology, named conformer enhanced AV-HuBERT, boosting the AV-HuBERT system's performance a step further. Compared with baseline AV-HuBERT, our method in the one-phase evaluation of clean and noisy conditions achieves 7% and 16% relative WER reduction on the English AVSR benchmark dataset LRS3. Furthermore, we establish a novel 1000h Mandarin AVSR dataset CSTS. On top of the baseline AV-HuBERT, we exceed the WeNet ASR system by 14% and 18% relatively on MISP and CMLR by pre-training with this dataset. The conformer-enhanced AV-HuBERT we proposed brings 7% on MISP and 6% CER 
    
[^61]: 零样本图像净化的黑盒后门防御方法

    Black-box Backdoor Defense via Zero-shot Image Purification. (arXiv:2303.12175v1 [cs.CV])

    [http://arxiv.org/abs/2303.12175](http://arxiv.org/abs/2303.12175)

    本文提出了一种黑盒后门防御框架，利用零样本图像净化有效地防御各种攻击，无需任何内部信息或先前知识，通过对受污染的图像进行线性变换和预训练的扩散模型恢复缺失语义信息实现。

    

    后门攻击会将毒数据注入训练集，导致模型推理时样本错误分类。在仅有模型预测可用的实际黑盒环境中，防御此类攻击是具有挑战性的。本文提出了一种新颖的后门防御框架，可以通过零样本图像净化（ZIP）有效地抵御各种攻击。我们的防御框架可以应用于黑盒模型，不需要任何关于受污染模型的内部信息或任何关于干净/受污染样本的先前知识。我们的防御框架包括两个步骤。首先，我们对受污染的图像应用线性变换以破坏触发模式。然后，我们使用预训练的扩散模型来恢复由变换去除的缺失语义信息。特别地，我们设计了一个新的反向过程，使用变换后的图像来引导高保真度净化图像的生成。

    Backdoor attacks inject poisoned data into the training set, resulting in misclassification of the poisoned samples during model inference. Defending against such attacks is challenging, especially in real-world black-box settings where only model predictions are available. In this paper, we propose a novel backdoor defense framework that can effectively defend against various attacks through zero-shot image purification (ZIP). Our proposed framework can be applied to black-box models without requiring any internal information about the poisoned model or any prior knowledge of the clean/poisoned samples. Our defense framework involves a two-step process. First, we apply a linear transformation on the poisoned image to destroy the trigger pattern. Then, we use a pre-trained diffusion model to recover the missing semantic information removed by the transformation. In particular, we design a new reverse process using the transformed image to guide the generation of high-fidelity purified 
    
[^62]: 物理知识网络用于锁相环瞬态稳定性评估

    Physics Informed Neural Networks for Phase Locked Loop Transient Stability Assessment. (arXiv:2303.12116v1 [eess.SY])

    [http://arxiv.org/abs/2303.12116](http://arxiv.org/abs/2303.12116)

    本文提出了一种物理知识神经网络（PINN）架构，结合了EMT仿真的精度和ML模型的计算效率，用于准确预测PLL控制器在故障情况下的非线性瞬态动力学并确定其稳定边界。

    

    实现联合国2050年零净排放目标需要大量的可再生能源，利用电力电子控制器，例如锁相环（PLL），来保持并网的可再生资源与网络同步可能导致在网络故障期间快速瞬态行为，进而导致不稳定。然而，评估所有可能的场景是不切实际的，因此有必要确定稳定的边界或吸引区域（ROA）。然而，使用EMT仿真或简化模型（ROM）来准确确定ROA是计算昂贵的。相反，机器学习（ML）模型已被提出作为一种有效的方法来预测稳定性。然而，传统的ML算法需要大量标记数据进行训练，这是计算昂贵的。本文提出了一种物理知识神经网络（PINN）架构，利用有限的标记数据准确预测PLL控制器在故障情况下的非线性瞬态动力学。所提出的模型结合了EMT仿真的精度和ML模型的计算效率，以准确确定PLL控制器的ROA。

    A significant increase in renewable energy production is necessary to achieve the UN's net-zero emission targets for 2050. Using power-electronic controllers, such as Phase Locked Loops (PLLs), to keep grid-tied renewable resources in synchronism with the grid can cause fast transient behavior during grid faults leading to instability. However, assessing all the probable scenarios is impractical, so determining the stability boundary or region of attraction (ROA) is necessary. However, using EMT simulations or Reduced-order models (ROMs) to accurately determine the ROA is computationally expensive. Alternatively, Machine Learning (ML) models have been proposed as an efficient method to predict stability. However, traditional ML algorithms require large amounts of labeled data for training, which is computationally expensive. This paper proposes a Physics-Informed Neural Network (PINN) architecture that accurately predicts the nonlinear transient dynamics of a PLL controller under fault
    
[^63]: 基于正样本增强对比学习的图像视频标题评估

    Positive-Augmented Constrastive Learning for Image and Video Captioning Evaluation. (arXiv:2303.12112v1 [cs.CV])

    [http://arxiv.org/abs/2303.12112](http://arxiv.org/abs/2303.12112)

    本论文提出一种新的图像标题评估指标PAC-S，可以更准确地评估图像和视频的标题，相比于现有的指标有更好的表现；源代码和训练模型已经公开。

    

    最近CLIP模型在很多跨模态任务上都非常有效，包括从视觉和语言结构中生成的标题评估。本文提出了一种新的基于对比度的图像标题评估指标配方，即正样本增强的对比度学习分数（PAC-S），以一种新颖的方式统一了对比度视觉-语义空间的学习和策展数据上生成的图像和文本的添加。跨越多个数据集的实验表明，我们的新指标在图像和视频上与人类判断的相关性最高，优于现有参考指标（如CIDEr和SPICE）和无参考指标（如CLIP-Score）。最后，我们考虑了流行的图像标题方法，并评估了采用不同跨模态特征的影响。我们的源代码和训练模型是公开的。

    The CLIP model has been recently proven to be very effective for a variety of cross-modal tasks, including the evaluation of captions generated from vision-and-language architectures. In this paper, we propose a new recipe for a contrastive-based evaluation metric for image captioning, namely Positive-Augmented Contrastive learning Score (PAC-S), that in a novel way unifies the learning of a contrastive visual-semantic space with the addition of generated images and text on curated data. Experiments spanning several datasets demonstrate that our new metric achieves the highest correlation with human judgments on both images and videos, outperforming existing reference-based metrics like CIDEr and SPICE and reference-free metrics like CLIP-Score. Finally, we test the system-level correlation of the proposed metric when considering popular image captioning approaches, and assess the impact of employing different cross-modal features. Our source code and trained models are publicly availa
    
[^64]: 基于对比学习的MEC网络流行度预测

    CLSA: Contrastive Learning-based Survival Analysis for Popularity Prediction in MEC Networks. (arXiv:2303.12097v1 [cs.LG])

    [http://arxiv.org/abs/2303.12097](http://arxiv.org/abs/2303.12097)

    本论文提出了一种基于对比学习的移动边缘缓存网络流行度预测框架，用于解决深度神经网络在处理多内容顺序请求模式时面临的问题。

    

    移动边缘缓存（MEC）与深度神经网络（DNNs）集成的创新技术具有极大的潜力，可以显著降低用户的延迟。然而，MEC网络的有效性严重依赖于其能力来预测和动态更新缓存节点存储最受欢迎的内容。现有的最先进的时间序列DNN模型通过同时将多个内容的顺序请求模式输入到网络中来捕捉后者，从而大大增加了输入样本的大小。这促使我们提出了一种基于对比学习的DNN流行度预测框架，旨在解决这一挑战。

    Mobile Edge Caching (MEC) integrated with Deep Neural Networks (DNNs) is an innovative technology with significant potential for the future generation of wireless networks, resulting in a considerable reduction in users' latency. The MEC network's effectiveness, however, heavily relies on its capacity to predict and dynamically update the storage of caching nodes with the most popular contents. To be effective, a DNN-based popularity prediction model needs to have the ability to understand the historical request patterns of content, including their temporal and spatial correlations. Existing state-of-the-art time-series DNN models capture the latter by simultaneously inputting the sequential request patterns of multiple contents to the network, considerably increasing the size of the input sample. This motivates us to address this challenge by proposing a DNN-based popularity prediction framework based on the idea of contrasting input samples against each other, designed for the Unmann
    
[^65]: 关于《无法通过图神经网络启发式算法在组合优化问题中胜过贪心算法》的回复(arXiv:2303.12096v1 [cs.LG])

    Reply to: Inability of a graph neural network heuristic to outperform greedy algorithms in solving combinatorial optimization problems. (arXiv:2303.12096v1 [cs.LG])

    [http://arxiv.org/abs/2303.12096](http://arxiv.org/abs/2303.12096)

    回复评论，认为评论聚焦于一种非典型问题且过于简化，强调了原始工作背后更广泛的算法开发以及实验数据的改进，并且指出图神经网络的内部解剖与贪心算法的本质大不相同，因此具有优势。

    

    我们对Stefan Boettcher [arXiv:2210.00623]的评论做了全面回复，并认为这个评论仅针对一种非典型的问题，仅关注稀疏图上的最大割问题(MaxCut)，而贪心算法在这种问题上表现良好。相反，我们强调了我们原始工作背后更广泛的算法开发，并在我们原始框架内提供了额外的数值结果，表明我们的算法在原始数据上有显着改进，因此推翻了评论的原始性能陈述。此外，已经证明物理启发的图神经网络(PI-GNN)能够胜过贪心算法，特别是在困难的、密集的实例上。我们还指出，图神经网络的内部(并行)解剖与贪心算法的(顺序)本质有很大不同，基于它们在实际社交网络规模的使用情况，指出了图神经网络的优势。

    We provide a comprehensive reply to the comment written by Stefan Boettcher [arXiv:2210.00623] and argue that the comment singles out one particular non-representative example problem, entirely focusing on the maximum cut problem (MaxCut) on sparse graphs, for which greedy algorithms are expected to perform well. Conversely, we highlight the broader algorithmic development underlying our original work, and (within our original framework) provide additional numerical results showing sizable improvements over our original data, thereby refuting the comment's original performance statements. Furthermore, it has already been shown that physics-inspired graph neural networks (PI-GNNs) can outperform greedy algorithms, in particular on hard, dense instances. We also argue that the internal (parallel) anatomy of graph neural networks is very different from the (sequential) nature of greedy algorithms, and (based on their usage at the scale of real-world social networks) point out that graph n
    
[^66]: 适应性负证据深度学习用于开放式半监督学习

    Adaptive Negative Evidential Deep Learning for Open-set Semi-supervised Learning. (arXiv:2303.12091v1 [cs.LG])

    [http://arxiv.org/abs/2303.12091](http://arxiv.org/abs/2303.12091)

    本文提出了ANEDL框架，应用证据深度学习量化不同类型的不确定性，并设计了新颖的适应性负优化策略，有效应对在未标记数据集中包含内部值和异常值的开放式半监督学习。

    

    半监督学习方法假设标记数据、未标记数据和测试数据来自同一分布。开放式半监督学习考虑到一个更实际的情况，即未标记数据和测试数据包含标记数据中未观察到的新类别（异常值）。本文提出了一种新颖的框架——适应性负证据深度学习（ANEDL），以应对二元分类器的不足之处，如缺乏可扩展性和无法区分不同类型的不确定性。具体而言，我们首先介绍证据深度学习（EDL）作为一种异常检测器来量化不同类型的不确定性，并设计不同的不确定性度量方法进行自我训练和推理。此外，我们提出了一种新颖的适应性负优化策略，使EDL更加适合包含内部值和异常值的未标记数据集。通过在基准数据集上的实验验证，我们的ANEDL显著优于现有的开放式半监督学习方法。

    Semi-supervised learning (SSL) methods assume that labeled data, unlabeled data and test data are from the same distribution. Open-set semi-supervised learning (Open-set SSL) considers a more practical scenario, where unlabeled data and test data contain new categories (outliers) not observed in labeled data (inliers). Most previous works focused on outlier detection via binary classifiers, which suffer from insufficient scalability and inability to distinguish different types of uncertainty. In this paper, we propose a novel framework, Adaptive Negative Evidential Deep Learning (ANEDL) to tackle these limitations. Concretely, we first introduce evidential deep learning (EDL) as an outlier detector to quantify different types of uncertainty, and design different uncertainty metrics for self-training and inference. Furthermore, we propose a novel adaptive negative optimization strategy, making EDL more tailored to the unlabeled dataset containing both inliers and outliers. As demonstrat
    
[^67]: Thrill-K架构：迈向基于知识的理解问题的解决方案

    Thrill-K Architecture: Towards a Solution to the Problem of Knowledge Based Understanding. (arXiv:2303.12084v1 [cs.LG])

    [http://arxiv.org/abs/2303.12084](http://arxiv.org/abs/2303.12084)

    Thrill-K架构将神经学习与不同类型的知识相结合，为解决部署端到端学习系统所需要的计算需求增加、以及缺乏灵活性、适应性、可解释性、推理和验证能力等问题提供了一种解决方案。

    

    虽然端到端学习系统正迅速获得能力和流行度，但部署这种系统所需的计算需求不断增加，加之灵活性、适应性、可解释性、推理和验证能力的缺乏，需要新类型的架构。在这里，我们介绍了一种混合系统的分类，该分类基于对人类知识和智能的分析，将神经学习与各种类型的知识和知识来源相结合。我们提出了Thrill-K架构作为将瞬时知识、备用知识和外部知识源集成到一个具有推理、学习和智能控制能力的框架中的原型解决方案。

    While end-to-end learning systems are rapidly gaining capabilities and popularity, the increasing computational demands for deploying such systems, along with a lack of flexibility, adaptability, explainability, reasoning and verification capabilities, require new types of architectures. Here we introduce a classification of hybrid systems which, based on an analysis of human knowledge and intelligence, combines neural learning with various types of knowledge and knowledge sources. We present the Thrill-K architecture as a prototypical solution for integrating instantaneous knowledge, standby knowledge and external knowledge sources in a framework capable of inference, learning and intelligent control.
    
[^68]: 多智能体强化学习用于大规模格网交通网络区域信号控制

    Multi-agent Reinforcement Learning for Regional Signal control in Large-scale Grid Traffic network. (arXiv:2303.11899v1 [cs.AI])

    [http://arxiv.org/abs/2303.11899](http://arxiv.org/abs/2303.11899)

    本文提出了一种新的训练框架 RegionLight，基于交叉口之间的邻接关系将智能体分配到每个区域中。同时，研究人员扩展了BDQ方法为DBDQ，以限制联合动作空间大小的增长并缓解智能体训练问题。

    

    多智能体强化学习（MARL）的自适应交通信号控制是当前非常流行的研究领域。大多数现有方法中，一个智能体控制单个路口，这些方法侧重于路口之间的协作。然而，MARL的非稳态性质随着交通网络规模的增长，仍然限制着上述方法的性能。一种妥协的策略是将一名智能体分配到一组路口中，以减少智能体数量。这种策略存在两个挑战，一个是如何将交通网络划分成小区域，另一个是如何搜索区域内的最优联合动作。本文提出了一种新的训练框架RegionLight，其中我们的区域划分规则基于交叉口之间的邻接关系，并扩展了Branching Dueling Q-Network(BDQ)。该方法将BDQ进一步优化为Dynamic Branching Dueling Q-Network(DBDQ)，以限制联合动作空间大小的增长并缓解智能体训练问题。

    Adaptive traffic signal control with Multi-agent Reinforcement Learning(MARL) is a very popular topic nowadays. In most existing novel methods, one agent controls single intersections and these methods focus on the cooperation between intersections. However, the non-stationary property of MARL still limits the performance of the above methods as the size of traffic networks grows. One compromised strategy is to assign one agent with a region of intersections to reduce the number of agents. There are two challenges in this strategy, one is how to partition a traffic network into small regions and the other is how to search for the optimal joint actions for a region of intersections. In this paper, we propose a novel training framework RegionLight where our region partition rule is based on the adjacency between the intersection and extended Branching Dueling Q-Network(BDQ) to Dynamic Branching Dueling Q-Network(DBDQ) to bound the growth of the size of joint action space and alleviate th
    
[^69]: 腿部作为机械手臂：将四足机器人敏捷性推向超出运动的领域

    Legs as Manipulator: Pushing Quadrupedal Agility Beyond Locomotion. (arXiv:2303.11330v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2303.11330](http://arxiv.org/abs/2303.11330)

    该论文展示了如何训练四足机器人使用前肢执行操纵任务，如攀爬、按下按钮和与物体交互，并使用课程学习将这些技能从模拟环境转移到真实环境中，并获得了成功的实验结果。

    

    目前，行走或奔跑在各种复杂地形上已经取得了显著的进步。然而，与狗等生物相比，机器人四足动物仍然远远落后，狗能够展示多种敏捷技能，并能使用腿部超出运动的范围，执行几个基本的操纵任务，如与物体进行交互和攀爬。在这篇论文中，我们通过训练四足机器人不仅行走，还使用前肢攀爬墙壁、按下按钮、在现实世界中执行物体交互等任务，来缩小这一差距。为了处理这一具有挑战性的优化问题，我们将技能广泛分为两类：运动，包括任何涉及运动的事物，无论是通过行走还是攀爬墙壁；操纵，涉及使用一条腿进行交互，同时保持其他三条腿的平衡。利用课程学习在模拟环境中训练这些技能，并使用我们提出的 sim2real 方法将其转移到真实环境中。我们的实验表明，我们的方法使得四足机器人能够在保持稳定的同时执行多种操纵任务，如打开门、按下按钮和提起物品。

    Locomotion has seen dramatic progress for walking or running across challenging terrains. However, robotic quadrupeds are still far behind their biological counterparts, such as dogs, which display a variety of agile skills and can use the legs beyond locomotion to perform several basic manipulation tasks like interacting with objects and climbing. In this paper, we take a step towards bridging this gap by training quadruped robots not only to walk but also to use the front legs to climb walls, press buttons, and perform object interaction in the real world. To handle this challenging optimization, we decouple the skill learning broadly into locomotion, which involves anything that involves movement whether via walking or climbing a wall, and manipulation, which involves using one leg to interact while balancing on the other three legs. These skills are trained in simulation using curriculum and transferred to the real world using our proposed sim2real variant that builds upon recent l
    
[^70]: 不看就能旋转: 通过触觉实现手部灵活性

    Rotating without Seeing: Towards In-hand Dexterity through Touch. (arXiv:2303.10880v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2303.10880](http://arxiv.org/abs/2303.10880)

    本研究提出了一种新系统Touch Dexterity，通过密集二进制力传感器实现了多指机器人手不看就能旋转物体，同时大大降低了成本和与实际应用的差距。

    

    触感信息在人类灵巧性中扮演着至关重要的角色，它可以提供有用的接触信息，直接从视觉中无法推断。这篇论文探讨了是否能够使多指机器人手具备与人类类似的不看就能旋转物体的能力。作者们提出了一个新的系统Touch Dexterity，通过使用覆盖整个机器人手的密集二进制力传感器（触摸或未触摸）代替仅仅在小区域内进行精准的触觉传感，使系统具有低成本、覆盖范围广等优点，并通过强化学习在多样的物体模拟中训练出了一种触感旋转策略，能够在真实的机器人手上直接实施不看就能旋转新型物体。

    Tactile information plays a critical role in human dexterity. It reveals useful contact information that may not be inferred directly from vision. In fact, humans can even perform in-hand dexterous manipulation without using vision. Can we enable the same ability for the multi-finger robot hand? In this paper, we present Touch Dexterity, a new system that can perform in-hand object rotation using only touching without seeing the object. Instead of relying on precise tactile sensing in a small region, we introduce a new system design using dense binary force sensors (touch or no touch) overlaying one side of the whole robot hand (palm, finger links, fingertips). Such a design is low-cost, giving a larger coverage of the object, and minimizing the Sim2Real gap at the same time. We train an in-hand rotation policy using Reinforcement Learning on diverse objects in simulation. Relying on touch-only sensing, we can directly deploy the policy in a real robot hand and rotate novel objects tha
    
[^71]: GPT是GPT：大语言模型对劳动力市场影响的早期研究

    GPTs are GPTs: An Early Look at the Labor Market Impact Potential of Large Language Models. (arXiv:2303.10130v1 [econ.GN])

    [http://arxiv.org/abs/2303.10130](http://arxiv.org/abs/2303.10130)

    该研究调查了GPT（大语言模型）和相关技术对美国劳动力市场的潜在影响，发现大约80%的美国劳动力可能会受到10%的工作任务的影响，涵盖了所有工资水平和各行各业，预示着这些模型可能具有显著的经济、社会和政策影响。

    

    我们研究了生成预训练变压器（GPT）模型和相关技术对美国劳动力市场的潜在影响。使用新的标准，我们评估职业与GPT能力的对应关系，结合人类专业知识和GPT-4的分类。我们的研究结果表明，约80%的美国劳动力可能会至少有10%的工作任务受到GPT引入的影响，而约19%的工人可能会看到至少50%的任务受到影响。影响范围涵盖了所有工资水平，高收入工作可能面临更大的风险。值得注意的是，影响并不局限于最近生产率增长较高的行业。我们得出结论，生成预训练变压器具有通用技术（GPT）的特性，表明这些模型可能具有显著的经济、社会和政策影响。

    We investigate the potential implications of Generative Pre-trained Transformer (GPT) models and related technologies on the U.S. labor market. Using a new rubric, we assess occupations based on their correspondence with GPT capabilities, incorporating both human expertise and classifications from GPT-4. Our findings indicate that approximately 80% of the U.S. workforce could have at least 10% of their work tasks affected by the introduction of GPTs, while around 19% of workers may see at least 50% of their tasks impacted. The influence spans all wage levels, with higher-income jobs potentially facing greater exposure. Notably, the impact is not limited to industries with higher recent productivity growth. We conclude that Generative Pre-trained Transformers exhibit characteristics of general-purpose technologies (GPTs), suggesting that as these models could have notable economic, social, and policy implications.
    
[^72]: SemDeDup:通过语义去重实现网络规模数据的高效学习（arXiv:2303.09540v1 [cs.LG]）

    SemDeDup: Data-efficient learning at web-scale through semantic deduplication. (arXiv:2303.09540v1 [cs.LG])

    [http://arxiv.org/abs/2303.09540](http://arxiv.org/abs/2303.09540)

    SemDeDup是一种利用预训练模型的嵌入来识别和删除语义重复项的方法。通过对LAION的子集进行分析，SemDeDup可以最小化性能损失的同时删除50%的数据，实际上将训练时间减半。此外，SemDeDup在提供效率收益的同时改进了先前的方法。

    

    机器学习领域的进展很大程度上是由海量数据的增加推动的。然而，像LAION这样的大型网络规模数据集在除查找精确重复项外，大部分未经精心筛选，可能存在很多冗余。在这里，我们介绍SemDeDup，一种基于预训练模型的嵌入来识别和删除语义重复项的方法：即语义上相似但并非完全相同的数据对。去除语义重复项可以保持性能并加速学习。通过对LAION的子集进行分析，我们展示了SemDeDup可以最小化性能损失的同时删除50%的数据，实际上将训练时间减半。此外，性能在分布以外得到提高。同时，通过分析在部分筛选过的数据集C4上训练的语言模型，我们展示了SemDeDup在提供效率收益的同时改进了先前的方法。SemDeDup提供了一个利用质量嵌入简单方法来使模型更快地学习的示例。

    Progress in machine learning has been driven in large part by massive increases in data. However, large web-scale datasets such as LAION are largely uncurated beyond searches for exact duplicates, potentially leaving much redundancy. Here, we introduce SemDeDup, a method which leverages embeddings from pre-trained models to identify and remove semantic duplicates: data pairs which are semantically similar, but not exactly identical. Removing semantic duplicates preserves performance and speeds up learning. Analyzing a subset of LAION, we show that SemDeDup can remove 50% of the data with minimal performance loss, effectively halving training time. Moreover, performance increases out of distribution. Also, analyzing language models trained on C4, a partially curated dataset, we show that SemDeDup improves over prior approaches while providing efficiency gains. SemDeDup provides an example of how simple ways of leveraging quality embeddings can be used to make models learn faster with le
    
[^73]: WDiscOOD：通过白化线性判别分析进行区分度优化的OOD检测

    WDiscOOD: Out-of-Distribution Detection via Whitened Linear Discriminative Analysis. (arXiv:2303.07543v1 [cs.CV])

    [http://arxiv.org/abs/2303.07543](http://arxiv.org/abs/2303.07543)

    本论文提出了一种名为WDiscOOD的新型OOD检测方法，其中使用白化线性判别分析将特征投影到判别子空间和残留子空间中，确定OOD分数。在大规模ImageNet-1k基准测试和六个OOD数据集中，WDiscOOD表现出了优越的性能。

    

    深度神经网络容易在遇到未知概念的情形下产生过度自信但错误的预测。这个挑战突显了在开放世界中检测OOD样本的重要性。本文提出了一种新颖的特征空间OOD检测分数，同时结合了类别特定和类别不可知的信息。具体地，我们的方法使用白化线性判别分析将特征投影到两个子空间中——判别子空间和残留子空间，其中ID类在判别子空间中被最大化地分离，并在残差子空间中被紧密地聚类。然后，在两个子空间中将来自输入数据与ID分布的偏差组合起来确定OOD分数。我们的方法名为WDiscOOD，在覆盖多种分布偏移的六个OOD数据集上验证了其高效性，包括大规模ImageNet-1k基准测试。WDiscOOD在深度分类器上表现出了优越的性能。

    Deep neural networks are susceptible to generating overconfident yet erroneous predictions when presented with data beyond known concepts. This challenge underscores the importance of detecting out-of-distribution (OOD) samples in the open world. In this work, we propose a novel feature-space OOD detection score that jointly reasons with both class-specific and class-agnostic information. Specifically, our approach utilizes Whitened Linear Discriminative Analysis to project features into two subspaces - the discriminative and residual subspaces - in which the ID classes are maximally separated and closely clustered, respectively. The OOD score is then determined by combining the deviation from the input data to the ID distribution in both subspaces. The efficacy of our method, named WDiscOOD, is verified on the large-scale ImageNet-1k benchmark, with six OOD datasets that covers a variety of distribution shifts. WDiscOOD demonstrates superior performance on deep classifiers with divers
    
[^74]: 文本-视觉提示用于高效的二维时间视频定位

    Text-Visual Prompting for Efficient 2D Temporal Video Grounding. (arXiv:2303.04995v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2303.04995](http://arxiv.org/abs/2303.04995)

    本文提出了一种新颖的文本-视觉提示（TVP）框架来解决时间视频定位问题，该框架有效地共同训练视觉编码器和语言编码器，且使用只有低复杂度稀疏二维视觉特征来提高跨模态特征融合的性能，并提出了一种时态对话排名（TDR）训练策略用于监督TVP的学习，实验证明该框架有效且高效。

    

    本文研究了时间视频定位（TVG）的问题，旨在预测文字描述的时刻在长时间未修剪的视频中的开始/结束时间点。受益于细粒度的三维视觉特征，TVG技术在近年来取得了显着进展。然而，三维卷积神经网络（CNNs）的高复杂性使得提取密集的三维视觉特征是耗时的，这需要大量的内存和计算资源。针对高效的TVG，作者提出了一种新颖的文本-视觉提示（TVP）框架，并将优化的扰动模式（称为“提示”）结合到TVG模型的视觉输入和文本特征中。与三维CNN形成鲜明对比，作者表明TVP允许我们在二维TVG模型中有效地共同训练视觉编码器和语言编码器，并使用只有低复杂度稀疏二维视觉特征来提高跨模态特征融合的性能。此外，作者提出了一种时态对话排名（TDR）训练策略，以监督TVP的学习并促进视频段与相应文本查询的对齐。在两个基准数据集上的实验结果验证了TVP模型的有效性和高效性。

    In this paper, we study the problem of temporal video grounding (TVG), which aims to predict the starting/ending time points of moments described by a text sentence within a long untrimmed video. Benefiting from fine-grained 3D visual features, the TVG techniques have achieved remarkable progress in recent years. However, the high complexity of 3D convolutional neural networks (CNNs) makes extracting dense 3D visual features time-consuming, which calls for intensive memory and computing resources. Towards efficient TVG, we propose a novel text-visual prompting (TVP) framework, which incorporates optimized perturbation patterns (that we call 'prompts') into both visual inputs and textual features of a TVG model. In sharp contrast to 3D CNNs, we show that TVP allows us to effectively co-train vision encoder and language encoder in a 2D TVG model and improves the performance of crossmodal feature fusion using only low-complexity sparse 2D visual features. Further, we propose a Temporal-Di
    
[^75]: 以ELBOs的加权积分理解扩散目标

    Understanding the Diffusion Objective as a Weighted Integral of ELBOs. (arXiv:2303.00848v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.00848](http://arxiv.org/abs/2303.00848)

    本文深入理解了扩散目标，并揭示了加权损失和ELBO目标之间的直接关系。

    

    文献中的扩散模型采用不同的目标进行优化，并且这些目标都是加权损失的特例，其中加权函数指定每个噪声级别的权重。均匀加权对应于最大似然的原则性近似ELBO的最大化。但是实际上，由于更好的样本质量，目前的扩散模型使用非均匀加权。本文揭示了加权损失（带有任何加权）和ELBO目标之间的直接关系。我们展示了加权损失可以被写成一种ELBOs的加权积分形式，其中每个噪声级别都有一个ELBO。如果权重函数是单调的，那么加权损失是一种基于似然的目标：它在简单的数据增强下（即高斯噪声扰动）下最大化ELBO。我们的主要贡献是更深入地理解了扩散目标，但我们还进行了一些比较单调和非单调权重的实验。

    Diffusion models in the literature are optimized with various objectives that are special cases of a weighted loss, where the weighting function specifies the weight per noise level. Uniform weighting corresponds to maximizing the ELBO, a principled approximation of maximum likelihood. In current practice diffusion models are optimized with non-uniform weighting due to better results in terms of sample quality. In this work we expose a direct relationship between the weighted loss (with any weighting) and the ELBO objective.  We show that the weighted loss can be written as a weighted integral of ELBOs, with one ELBO per noise level. If the weighting function is monotonic, then the weighted loss is a likelihood-based objective: it maximizes the ELBO under simple data augmentation, namely Gaussian noise perturbation. Our main contribution is a deeper theoretical understanding of the diffusion objective, but we also performed some experiments comparing monotonic with non-monotonic weight
    
[^76]: Side Adapter Network用于开放词汇语义分割

    Side Adapter Network for Open-Vocabulary Semantic Segmentation. (arXiv:2302.12242v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.12242](http://arxiv.org/abs/2302.12242)

    本文提出的Side Adapter Network框架采用冻结的CLIP模型和辅助网络来实现开放词汇语义分割任务，具有快速、准确和轻量级优势。该网络可以重用CLIP特征，仅增加少量可训练参数，显著优于其他方法。

    

    本文提出了一种新的开放词汇语义分割框架，利用预训练的视觉-语言模型命名为Side Adapter Network (SAN)。我们的方法将语义分割任务建模为区域识别问题，通过在冻结的CLIP模型上附加一个辅助网络来实现。该网络有两个分支：一个用于预测掩模提案，另一个用于预测注意偏差，该偏差应用于CLIP模型中来识别掩模的类别。这种分离的设计使得CLIP能够识别掩模提案的类别。由于辅助网络可以重用CLIP特征，因此它非常轻巧。此外，整个网络可以端到端地训练，使得辅助网络能够适应冻结的CLIP模型，从而使预测的掩模提案建立在CLIP的基础上。我们的方法快速、准确，仅增加了一些可训练参数。我们在多个语义分割基准测试上评估了我们的方法，结果表明我们的方法显着优于其他方法。

    This paper presents a new framework for open-vocabulary semantic segmentation with the pre-trained vision-language model, named Side Adapter Network (SAN). Our approach models the semantic segmentation task as a region recognition problem. A side network is attached to a frozen CLIP model with two branches: one for predicting mask proposals, and the other for predicting attention bias which is applied in the CLIP model to recognize the class of masks. This decoupled design has the benefit CLIP in recognizing the class of mask proposals. Since the attached side network can reuse CLIP features, it can be very light. In addition, the entire network can be trained end-to-end, allowing the side network to be adapted to the frozen CLIP model, which makes the predicted mask proposals CLIP-aware. Our approach is fast, accurate, and only adds a few additional trainable parameters. We evaluate our approach on multiple semantic segmentation benchmarks. Our method significantly outperforms other c
    
[^77]: 基于随机先验网络的高维输出可扩展贝叶斯优化

    Scalable Bayesian optimization with high-dimensional outputs using randomized prior networks. (arXiv:2302.07260v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.07260](http://arxiv.org/abs/2302.07260)

    本文提出了一个基于带随机先验的神经网络的深度学习框架用于高维输出的贝叶斯优化，可有效地处理全局优化问题，即使在高维度向量空间或无限维函数空间中也能近似功能关系。

    

    科学和工程中的一些基本问题涉及到未知的高维度映射一组可控变量到昂贵实验结果的黑盒函数的全局优化任务。贝叶斯优化（BO）技术已被证明在使用相对较少的目标函数评估时处理全局优化问题时非常有效，但当处理高维输出时，其性能受到影响。为克服维度主要挑战，本文提出了一个基于带随机先验的神经网络的自举集成的BO和序贯决策制定的深度学习框架。使用适当的体系结构选择，我们证明了所提出的框架可以近似设计变量和感兴趣量之间的功能关系，即使在后者取值于高维向量空间或甚至无限维函数空间的情况下。在贝叶斯优化的背景下，该方法允许高效和可扩展的处理高维度黑盒函数的全局优化。

    Several fundamental problems in science and engineering consist of global optimization tasks involving unknown high-dimensional (black-box) functions that map a set of controllable variables to the outcomes of an expensive experiment. Bayesian Optimization (BO) techniques are known to be effective in tackling global optimization problems using a relatively small number objective function evaluations, but their performance suffers when dealing with high-dimensional outputs. To overcome the major challenge of dimensionality, here we propose a deep learning framework for BO and sequential decision making based on bootstrapped ensembles of neural architectures with randomized priors. Using appropriate architecture choices, we show that the proposed framework can approximate functional relationships between design variables and quantities of interest, even in cases where the latter take values in high-dimensional vector spaces or even infinite-dimensional function spaces. In the context of 
    
[^78]: DeepAstroUDA: 面向跨调查银河形态分类和异常检测的半监督通用域自适应

    DeepAstroUDA: Semi-Supervised Universal Domain Adaptation for Cross-Survey Galaxy Morphology Classification and Anomaly Detection. (arXiv:2302.02005v2 [astro-ph.GA] UPDATED)

    [http://arxiv.org/abs/2302.02005](http://arxiv.org/abs/2302.02005)

    DeepAstroUDA是一种通用域自适应方法，可用于跨调查银河形态分类和异常检测，可以应用于具有不同数据分布和类别重叠的数据集。其在分类准确性方面提供了显著的改善，特别是在标记数据稀缺或不可用的情况下。

    

    人工智能方法在提高对大型天文数据集的处理质量和速度方面显示出极大的潜力，但这些方法的高复杂性导致提取数据集特定、不具鲁棒性的特征。因此，这些方法不能很好地推广到多个数据集。我们提出了一种通用域自适应方法，称为 DeepAstroUDA，作为克服这一挑战的途径。这个算法执行半监督域适应，并可以应用于具有不同数据分布和类别重叠的数据集。非重叠类可以存在于两个数据集中的任何一个（有标签的源域或无标签的目标域），而且即使存在未知类别，该方法也可以使用。我们将我们的方法应用于三个不同复杂度（$3$类和$10$类问题）的银河形态分类任务的例子，包括异常检测: 1）来自勘测望远镜不同观测年数的数据集，2）带有非标准滤镜的深度勘测，以及3）不同退化级别的模拟数据。我们的实验表明，DeepAstroUDA在分类精度方面提供了显著的改善，特别是在标记数据稀缺或不可用的情况下。我们的方法可以用于促进更灵活和高效的天文分类系统的创建，并可以提高天文图像中异常检测的质量。

    Artificial intelligence methods show great promise in increasing the quality and speed of work with large astronomical datasets, but the high complexity of these methods leads to the extraction of dataset-specific, non-robust features. Therefore, such methods do not generalize well across multiple datasets. We present a universal domain adaptation method, \textit{DeepAstroUDA}, as an approach to overcome this challenge. This algorithm performs semi-supervised domain adaptation and can be applied to datasets with different data distributions and class overlaps. Non-overlapping classes can be present in any of the two datasets (the labeled source domain, or the unlabeled target domain), and the method can even be used in the presence of unknown classes. We apply our method to three examples of galaxy morphology classification tasks of different complexities ($3$-class and $10$-class problems), with anomaly detection: 1) datasets created after different numbers of observing years from a s
    
[^79]: 使用无动作离线数据预训练指导在线强化学习

    Guiding Online Reinforcement Learning with Action-Free Offline Pretraining. (arXiv:2301.12876v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.12876](http://arxiv.org/abs/2301.12876)

    本文研究了使用无动作离线数据集来提高在线强化学习的效率和性能的方法，提出了AF-Guide，实现变体的Upside-Down强化学习和指导在线学习的Guided SAC，实验结果表明该方法可以成功改善在离线数据集中不存在动作信息的情况下的性能。

    

    离线RL方法通过训练代理使用离线收集的数据来减少环境交互的需求。然而，这些方法通常需要在数据收集期间记录动作信息，这在某些实际情况下可能是困难甚至不可能的。在本文中，我们研究了使用无动作离线数据集来改善在线强化学习的潜力，并将此问题命名为具有无动作离线预训练的强化学习（AFP-RL）。我们介绍了AF-Guide，一种通过从无动作离线数据集中提取知识来指导在线训练的方法。AF-Guide包括实施Upside-Down强化学习变体的无动作决策Transformer（AFDT），它学习从离线数据集中规划下一个状态，以及一个通过AFDT指导在线学习的Guided Soft Actor-Critic（Guided SAC）。实验结果表明，在离线数据集中不存在动作信息的环境中，AF-Guide可以提高在线RL的样本效率和性能。

    Offline RL methods have been shown to reduce the need for environment interaction by training agents using offline collected episodes. However, these methods typically require action information to be logged during data collection, which can be difficult or even impossible in some practical cases. In this paper, we investigate the potential of using action-free offline datasets to improve online reinforcement learning, name this problem Reinforcement Learning with Action-Free Offline Pretraining (AFP-RL). We introduce Action-Free Guide (AF-Guide), a method that guides online training by extracting knowledge from action-free offline datasets. AF-Guide consists of an Action-Free Decision Transformer (AFDT) implementing a variant of Upside-Down Reinforcement Learning. It learns to plan the next states from the offline dataset, and a Guided Soft Actor-Critic (Guided SAC) that learns online with guidance from AFDT. Experimental results show that AF-Guide can improve sample efficiency and pe
    
[^80]: 面向任务的通信系统：基于端到端深度学习和AI安全的NextG研究

    Task-Oriented Communications for NextG: End-to-End Deep Learning and AI Security Aspects. (arXiv:2212.09668v2 [cs.NI] UPDATED)

    [http://arxiv.org/abs/2212.09668](http://arxiv.org/abs/2212.09668)

    本文探讨了在NextG无线接入网络中，通过端到端深度学习和AI安全保证信号分类任务，并在保证信号传输效率的情况下进行任务导向通信的方法。

    

    传统通信系统主要设计用于可靠地传输数字数据流（比特流），而新一代通信系统（NextG）开始探索把设计范式转向可靠地执行特定任务，例如任务导向的通信。本文探讨了无线信号分类作为NextG无线接入网络（RAN）的任务，在该任务中，边缘设备收集无线信号以获取频谱感知，然后与需要识别信号标签的NextG基站（gNodeB）进行通信。然而边缘设备可能无法足够处理信号分类任务，并且由于严格的延迟、速率和能量限制，将信号传输到gNodeB可能不可行。为此，本研究考虑了通过联合训练发射机、接收机和分类器的功能作为编码器-解码器对，为边缘设备和gNodeB实现任务导向通信。

    Communications systems to date are primarily designed with the goal of reliable transfer of digital sequences (bits). Next generation (NextG) communication systems are beginning to explore shifting this design paradigm to reliably executing a given task such as in task-oriented communications. In this paper, wireless signal classification is considered as the task for the NextG Radio Access Network (RAN), where edge devices collect wireless signals for spectrum awareness and communicate with the NextG base station (gNodeB) that needs to identify the signal label. Edge devices may not have sufficient processing power and may not be trusted to perform the signal classification task, whereas the transfer of signals to the gNodeB may not be feasible due to stringent delay, rate, and energy restrictions. Task-oriented communications is considered by jointly training the transmitter, receiver and classifier functionalities as an encoder-decoder pair for the edge device and the gNodeB. This a
    
[^81]: 带有内外部注意力的形状引导扩散

    Shape-Guided Diffusion with Inside-Outside Attention. (arXiv:2212.00210v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.00210](http://arxiv.org/abs/2212.00210)

    该论文提出了一种无需训练的形状引导扩散方法，使用一种新颖的内外部注意机制将形状限制应用于跨注意力图和自注意力图上，从而在文本到图像扩散模型中考虑到对象形状，进而可以实现对象形状忠实度更高的图像生成。

    

    在操作对象时，现有的文本到图像扩散模型通常忽略对象的形状并生成错误比例、被截断或被背景内容替换的图像。我们提出了一种无需训练的方法 Shape-Guided Diffusion，该方法修改了预训练扩散模型，使之对用户指定的形状输入或从文本中自动推断的形状敏感。我们使用一种新颖的内外部注意机制，在反演和生成过程中将此形状限制应用于跨注意力图和自注意力图上。我们的机制指定空间区域是对象（内部）还是背景（外部），然后将文本提示指定的编辑与正确的区域相关联。我们在形状引导编辑任务上展示了我们方法的有效性，其中模型必须根据文本提示和对象掩码替换对象。我们创建了一个新的从 MS-COCO 衍生的 ShapePrompts 基准，并在形状忠实度方面实现了 SOTA 的结果，而不需要降级。

    When manipulating an object, existing text-to-image diffusion models often ignore the shape of the object and generate content that is incorrectly scaled, cut off, or replaced with background content. We propose a training-free method, Shape-Guided Diffusion, that modifies pretrained diffusion models to be sensitive to shape input specified by a user or automatically inferred from text. We use a novel Inside-Outside Attention mechanism during the inversion and generation process to apply this shape constraint to the cross- and self-attention maps. Our mechanism designates which spatial region is the object (inside) vs. background (outside) then associates edits specified by text prompts to the correct region. We demonstrate the efficacy of our method on the shape-guided editing task, where the model must replace an object according to a text prompt and object mask. We curate a new ShapePrompts benchmark derived from MS-COCO and achieve SOTA results in shape faithfulness without a degra
    
[^82]: AIREPAIR——一种神经网络修复平台

    AIREPAIR: A Repair Platform for Neural Networks. (arXiv:2211.15387v2 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2211.15387](http://arxiv.org/abs/2211.15387)

    AIREPAIR是一个神经网络修复平台，它能够集成现有网络修复工具并实现不同方法的公平比较，评估结果表明其实用性。

    

    我们介绍了一种名为AIREPAIR的神经网络修复平台。它包括了现有网络修复工具的集成，使得用户可以在同一个模型上运行不同的网络修复方法并进行公平的比较。我们使用三个最先进的修复工具在流行的深度学习数据集和模型上评估了AIREPAIR。评估结果表明AIREPAIR的实用性，通过比较和分析不同修复技术的结果进行了验证。演示视频可在 https://youtu.be/UkKw5neeWhw 查看。

    We present AIREPAIR, a platform for repairing neural networks. It features the integration of existing network repair tools. Based on AIREPAIR, one can run different repair methods on the same model, thus enabling the fair comparison of different repair techniques. We evaluate AIREPAIR with three state-of-the-art repair tools on popular deep-learning datasets and models. Our evaluation confirms the utility of AIREPAIR, by comparing and analyzing the results from different repair techniques. A demonstration is available at https://youtu.be/UkKw5neeWhw.
    
[^83]: 熔炉2.0

    Melting Pot 2.0. (arXiv:2211.13746v4 [cs.MA] UPDATED)

    [http://arxiv.org/abs/2211.13746](http://arxiv.org/abs/2211.13746)

    研究工具Melting Pot 2.0为多智能体人工智能提供了评估协议，在一组典型测试场景中测量它们对新颖社交伙伴的泛化能力。

    

    多智能体人工智能研究承诺开发比“自我中心”方法更具人类特点和更易于与人类兼容的智能技术。 Melting Pot是为促进多智能体人工智能工作而开发的研究工具，并提供一个评估协议，该协议在一组典型的测试场景中测量对新颖社交伙伴的泛化能力。每种情景将一个物理环境（“基板”）与一组参考合作者（“背景人群”）配对，以创建一个具有个体间相互依存性的社交情境。例如，一些情形受到了基于制度经济学的自然资源管理和公共物品供给困境的考虑的启发，而其他情形则受到了进化生物学、博弈论和人工生命等方面的考虑所启发。Melting Pot旨在涵盖一组最大多样化的情形。

    Multi-agent artificial intelligence research promises a path to develop intelligent technologies that are more human-like and more human-compatible than those produced by "solipsistic" approaches, which do not consider interactions between agents. Melting Pot is a research tool developed to facilitate work on multi-agent artificial intelligence, and provides an evaluation protocol that measures generalization to novel social partners in a set of canonical test scenarios. Each scenario pairs a physical environment (a "substrate") with a reference set of co-players (a "background population"), to create a social situation with substantial interdependence between the individuals involved. For instance, some scenarios were inspired by institutional-economics-based accounts of natural resource management and public-good-provision dilemmas. Others were inspired by considerations from evolutionary biology, game theory, and artificial life. Melting Pot aims to cover a maximally diverse set of 
    
[^84]: 使用图神经网络求解双层背包问题

    Solving Bilevel Knapsack Problem using Graph Neural Networks. (arXiv:2211.13436v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2211.13436](http://arxiv.org/abs/2211.13436)

    本研究提出了一种使用图神经网络的深度学习方法来解决双层背包问题，该方法比精确算法快500倍，可找到可行性解决方案。

    

    双层优化问题是一种具有两个代理人（领导者和追随者）的层次优化问题。领导者首先做出自己的决策，追随者随后做出最佳选择。领导者了解追随者的信息，问题的目标是从领导者的角度考虑追随者的反应，找到最优解。对于双层优化问题来说，没有通用的高效算法或商用求解器可以得到最优解，即使是简单的问题也很难得到良好的解。本文提出了一种使用图神经网络的深度学习方法来解决双层背包问题。我们训练模型来预测领导者的解决方案，并将其用于将层次优化问题转化为单层优化问题以获取解决方案。我们的模型发现了可行的解决方案，速度比精确算法快500倍。

    The Bilevel Optimization Problem is a hierarchical optimization problem with two agents, a leader and a follower. The leader make their own decisions first, and the followers make the best choices accordingly. The leader knows the information of the followers, and the goal of the problem is to find the optimal solution by considering the reactions of the followers from the leader's point of view. For the Bilevel Optimization Problem, there are no general and efficient algorithms or commercial solvers to get an optimal solution, and it is very difficult to get a good solution even for a simple problem. In this paper, we propose a deep learning approach using Graph Neural Networks to solve the bilevel knapsack problem. We train the model to predict the leader's solution and use it to transform the hierarchical optimization problem into a single-level optimization problem to get the solution. Our model found the feasible solution that was about 500 times faster than the exact algorithm wi
    
[^85]: VoP：用于文本视频跨模态检索的协作提示调整

    VoP: Text-Video Co-operative Prompt Tuning for Cross-Modal Retrieval. (arXiv:2211.12764v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.12764](http://arxiv.org/abs/2211.12764)

    本论文提出了一种用于文本视频跨模态检索的协作提示调整（VoP）框架，与传统方法相比，VoP具有更少的可训练参数和更低的计算复杂度，同时实现了相似甚至更好的性能。

    

    许多最近的研究利用预训练的CLIP来通过使用额外的重模块来调整backbone从而实现文本视频跨模态检索，这不仅带来了大量的计算负担和更多的参数，也导致了上游模型的知识遗忘。本文提出了VoP：文本视频协作提示调整，以实现对文本视频检索任务的高效调整。所提出的VoP是一个端到端框架，具有引入视频和文本提示的能力，可视为具有仅0.1％可训练参数的强大基线。此外，基于视频的时空特征，我们开发了三种新型视频提示机制，以提高不同可训练参数规模的性能。VoP增强的基本思想是分别利用特定的可训练提示来模拟帧位置，帧上下文和层函数。大量实验表明，与完全微调相比，增强的VoP实现了相似甚至更好的效果，并且具有更少的可训练参数和更低的计算复杂度。

    Many recent studies leverage the pre-trained CLIP for text-video cross-modal retrieval by tuning the backbone with additional heavy modules, which not only brings huge computational burdens with much more parameters, but also leads to the knowledge forgetting from upstream models. In this work, we propose the VoP: Text-Video Co-operative Prompt Tuning for efficient tuning on the text-video retrieval task. The proposed VoP is an end-to-end framework with both video & text prompts introducing, which can be regarded as a powerful baseline with only 0.1% trainable parameters. Further, based on the spatio-temporal characteristics of videos, we develop three novel video prompt mechanisms to improve the performance with different scales of trainable parameters. The basic idea of the VoP enhancement is to model the frame position, frame context, and layer function with specific trainable prompts, respectively. Extensive experiments show that compared to full fine-tuning, the enhanced VoP achie
    
[^86]: 高效训练：探索泛化课程学习来训练视觉主干网络

    EfficientTrain: Exploring Generalized Curriculum Learning for Training Visual Backbones. (arXiv:2211.09703v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.09703](http://arxiv.org/abs/2211.09703)

    本文提出了一种泛化课程学习方法，用于高效训练视觉主干网络，通过优先让模型学习“更容易学习”的模式，不断引入更难的模式，从而加速训练过程。

    

    现代深度网络的卓越性能通常伴随着昂贵的训练过程。本文提出了一种新的课程学习方法，用于高效训练视觉主干网络（例如视觉Transformer）。本文启发于深度网络的内在学习动力学：我们实验性地展示了在较早的训练阶段，模型主要学习在每个示例中识别一些“更容易学习”的判别模式，例如图像的低频成分和数据增广之前的原始信息。基于此现象，我们提出了一种课程，其中模型总是在每个时期利用所有训练数据，而课程始于仅暴露每个示例的“更容易学习”的模式，并逐渐引入更难的模式。为了实现这个想法，我们1）在输入的傅里叶谱中引入一个裁剪操作，使模型只能从低频组分中进行学习。

    The superior performance of modern deep networks usually comes with a costly training procedure. This paper presents a new curriculum learning approach for the efficient training of visual backbones (e.g., vision Transformers). Our work is inspired by the inherent learning dynamics of deep networks: we experimentally show that at an earlier training stage, the model mainly learns to recognize some 'easier-to-learn' discriminative patterns within each example, e.g., the lower-frequency components of images and the original information before data augmentation. Driven by this phenomenon, we propose a curriculum where the model always leverages all the training data at each epoch, while the curriculum starts with only exposing the 'easier-to-learn' patterns of each example, and introduces gradually more difficult patterns. To implement this idea, we 1) introduce a cropping operation in the Fourier spectrum of the inputs, which enables the model to learn from only the lower-frequency compo
    
[^87]: 一种通过统一离散的双向图学习实现高效多视图聚类的方法

    Efficient Multi-view Clustering via Unified and Discrete Bipartite Graph Learning. (arXiv:2209.04187v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.04187](http://arxiv.org/abs/2209.04187)

    本文提出了一种高效的多视图聚类方法，通过基于锚点的子空间学习、双向图学习和离散优化实现了单视图和一致性图的联合学习，避免了高计算复杂度，并在多个数据集上取得了优异的性能表现。

    

    尽管以往基于图的多视图聚类算法已经取得了重大进展，但它们大多仍然面临三个限制。首先，它们往往遭受高计算复杂度的困扰，限制了它们在大规模场景中的应用。其次，它们通常在单视图级别或视图一致性级别上执行图学习，但常常忽略了单视图和一致性图的联合学习可能性。第三，许多算法依赖于k-means对谱嵌入进行离散化，但缺乏直接学习带离散聚类结构的图的能力。因此，本文提出了一种通过统一离散的双向图学习实现高效多视图聚类的方法（UDBGL）。具体来说，该方法采用了基于锚点的子空间学习，从多个视图中学习了视图特定的双向图，然后利用双向图融合学习了视图一致性双向图。在此过程中，UDBGL通过采用低秩矩阵近似和加速交替方向乘数法避免了高计算复杂度。此外，通过最小化统一目标函数，它实现了单视图和一致性图的联合学习。最后，为了解决第三个限制，提出了一种离散优化方法，直接学习所学图的离散聚类结构。在各种数据集上的实验结果表明，UDBGL优于几种最新的多视图聚类算法。

    Although previous graph-based multi-view clustering algorithms have gained significant progress, most of them are still faced with three limitations. First, they often suffer from high computational complexity, which restricts their applications in large-scale scenarios. Second, they usually perform graph learning either at the single-view level or at the view-consensus level, but often neglect the possibility of the joint learning of single-view and consensus graphs. Third, many of them rely on the k-means for discretization of the spectral embeddings, which lack the ability to directly learn the graph with discrete cluster structure. In light of this, this paper presents an efficient multi-view clustering approach via unified and discrete bipartite graph learning (UDBGL). Specifically, the anchor-based subspace learning is incorporated to learn the view-specific bipartite graphs from multiple views, upon which the bipartite graph fusion is leveraged to learn a view-consensus bipartit
    
[^88]: 阿尔伯塔AI研究计划

    The Alberta Plan for AI Research. (arXiv:2208.11173v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2208.11173](http://arxiv.org/abs/2208.11173)

    阿尔伯塔计划是一项人工智能研究计划，在阿尔伯塔的研究团队及全球志同道合的人士中进行，旨在探索AI的研究方法和应用。

    

    本文介绍了我们的人工智能研究方法，我们称之为阿尔伯塔计划。阿尔伯塔计划在阿尔伯塔的研究团队以及世界各地志同道合的人士中开展。我们欢迎所有愿意加入我们这一追求的人。

    Herein we describe our approach to artificial intelligence research, which we call the Alberta Plan. The Alberta Plan is pursued within our research groups in Alberta and by others who are like minded throughout the world. We welcome all who would join us in this pursuit.
    
[^89]: 基于潜在代理表示学习的长期因果效应估计

    Long-term Causal Effects Estimation via Latent Surrogates Representation Learning. (arXiv:2208.04589v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2208.04589](http://arxiv.org/abs/2208.04589)

    Laser 是一种基于潜在代理表示学习的估计长期因果效应的灵活方法，能够在代理和其代理混合在一起的真实世界情景中应用。

    

    在许多实际应用，如营销和医学中，基于短期代理来估计长期因果效应是一个重要而具有挑战性的问题。尽管某些领域中已有所成功，但大多数现有方法以一种理想化和简化的方式估计因果效应，忽略了短期结果之间的因果结构，并将它们全部视为代理。然而，这种方法无法很好地应用于真实世界的情景，其中局部观察到的代理与它们在短期结果中的代理混合在一起。因此，我们开发了一种灵活的方法，称为Laser，以在更现实的情况下估计长期因果效应，其中观察到代理或具有观察代理。鉴于代理和代理之间的不可区分性，我们利用可识别变分自编码器（iVAE）在不需要区分观察到的代理或先验条件的情况下恢复所有有效代理候选者上的整个有效代理。

    Estimating long-term causal effects based on short-term surrogates is a significant but challenging problem in many real-world applications, e.g., marketing and medicine. Despite its success in certain domains, most existing methods estimate causal effects in an idealistic and simplistic way - ignoring the causal structure among short-term outcomes and treating all of them as surrogates. However, such methods cannot be well applied to real-world scenarios, in which the partially observed surrogates are mixed with their proxies among short-term outcomes. To this end, we develop our flexible method, Laser, to estimate long-term causal effects in the more realistic situation that the surrogates are observed or have observed proxies.Given the indistinguishability between the surrogates and proxies, we utilize identifiable variational auto-encoder (iVAE) to recover the whole valid surrogates on all the surrogates candidates without the need of distinguishing the observed surrogates or the p
    
[^90]: 语义歧义的因果结构

    The Causal Structure of Semantic Ambiguities. (arXiv:2206.06807v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2206.06807](http://arxiv.org/abs/2206.06807)

    本文使用Gogioso和Pinzani在QPL 2021中提出的束理论模型，为语义歧义的两个特征（不同可能解释的联合可信度和某些词在过程中扮演更重要角色的因果结构）进行建模。通过对心理语言学文献中的歧义短语数据集进行分析，研究人员对人类对于这些歧义的判断进行了实证测量。

    

    歧义是自然语言现象，在不同的语法、语义和语用层面上发生。它得到了广泛的研究；例如，在心理语言学领域，我们有多种竞争性的研究人类消歧过程的方法。这些研究是经验性的，基于眼动跟踪等测量方法。本文首次尝试为语义歧义形式化这些进程，其中我们确定了两个特征：(1)不同可能解释之间的联合可信度，(2)根据某些词在过程中扮演更重要角色的因果结构。Gogioso和Pinzani在QPL 2021中提出的新型束理论确定因果性模型并对这些特征进行推理提供了工具。我们将这个理论应用于从心理语言学文献中提取的歧义短语数据集和我们使用Amazon的机械土耳其引擎收集的人类可信度判断中。我们测量了其中的因果关系、歧义水平等。

    Ambiguity is a natural language phenomenon occurring at different levels of syntax, semantics, and pragmatics. It is widely studied; in Psycholinguistics, for instance, we have a variety of competing studies for the human disambiguation processes. These studies are empirical and based on eyetracking measurements. Here we take first steps towards formalizing these processes for semantic ambiguities where we identified the presence of two features: (1) joint plausibility degrees of different possible interpretations, (2) causal structures according to which certain words play a more substantial role in the processes. The novel sheaf-theoretic model of definite causality developed by Gogioso and Pinzani in QPL 2021 offers tools to model and reason about these features. We applied this theory to a dataset of ambiguous phrases extracted from Psycholinguistics literature and their human plausibility judgements collected by us using the Amazon Mechanical Turk engine. We measured the causal fr
    
[^91]: 使用人工智能增强的心电图进行新发糖尿病评估

    New-Onset Diabetes Assessment Using Artificial Intelligence-Enhanced Electrocardiography. (arXiv:2205.02900v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.02900](http://arxiv.org/abs/2205.02900)

    本研究表明，使用人工智能增强的心电图可以有效地识别新发糖尿病成人患者，相较于传统的ADA风险检测方法，该方法具有更好的准确性和特异性。

    

    未诊断的糖尿病在患者中占21.4％，由于筛查率的限制，糖尿病可能潜伏无症状而未被检测。本研究旨在通过使用人工智能（AI）增强的心电图（ECG）来确定新发糖尿病的成人患者。 我们训练了一个神经网络，使用12导联心电图和可用的人口统计学数据来估计HbA1c。 我们回顾性地收集了一组包含有配对的ECG和HbA1c数据的病人数据集。结果显示，相较于传统的ADA风险检测，基于ECG的评估效果更好。AI增强的ECG评估的准确性达到81％，灵敏度为80％，特异性为82％。研究结果表明，人工智能增强的ECG可以成为新发糖尿病成人患者的一个有前景的工具，特别是在传统筛查方法有限的人群中。

    Undiagnosed diabetes is present in 21.4% of adults with diabetes. Diabetes can remain asymptomatic and undetected due to limitations in screening rates. To address this issue, questionnaires, such as the American Diabetes Association (ADA) Risk test, have been recommended for use by physicians and the public. Based on evidence that blood glucose concentration can affect cardiac electrophysiology, we hypothesized that an artificial intelligence (AI)-enhanced electrocardiogram (ECG) could identify adults with new-onset diabetes. We trained a neural network to estimate HbA1c using a 12-lead ECG and readily available demographics. We retrospectively assembled a dataset comprised of patients with paired ECG and HbA1c data. The population of patients who receive both an ECG and HbA1c may a biased sample of the complete outpatient population, so we adjusted the importance placed on each patient to generate a more representative pseudo-population. We found ECG-based assessment outperforms the 
    
[^92]: 无信号道路交叉口的实时车辆协同协调

    Real-time Cooperative Vehicle Coordination at Unsignalized Road Intersections. (arXiv:2205.01278v2 [eess.SY] UPDATED)

    [http://arxiv.org/abs/2205.01278](http://arxiv.org/abs/2205.01278)

    该论文提出了一种实时车辆协同协调框架，涉及的车辆交出控制权限，并通过解决非凸顺序决策问题的方式，利用双延迟深度确定性网络（T3D）算法实现最大化交通通行能力，同时确保驾驶安全和协调系统的长期稳定性。广泛的仿真结果证明了该方法在交通通行能力、驾驶安全和协调稳定性方面的优越性。

    

    为了提高连接和自动化车辆的行驶安全和交通通行能力，无信号道路交叉口的协作协调近年来越来越受到关注。然而，大多数现有的研究要么存在计算复杂度问题，要么不能充分利用道路基础设施的潜力。为此，我们首先提出了一个专用的交叉口协调框架，其中涉及的车辆交出控制权限，并遵循来自集中协调器的指令。然后，将制定一个统一的协作轨迹优化问题，以最大化交通通行能力，同时确保驾驶安全和协调系统的长期稳定性。为了解决实际部署中的主要计算挑战，我们将这个非凸顺序决策问题重新制定为一个无模型马尔可夫决策过程（MDP），并通过设计具有两个并行神经网络的双延迟深度确定性网络（T3D）算法来解决它。我们提出的方法可以实现低计算复杂度和高可扩展性的实时车辆协同协调。广泛的仿真结果证明了我们的方法在交通通行能力、驾驶安全和协调稳定性方面的优越性。

    Cooperative coordination at unsignalized road intersections, which aims to improve the driving safety and traffic throughput for connected and automated vehicles, has attracted increasing interests in recent years. However, most existing investigations either suffer from computational complexity or cannot harness the full potential of the road infrastructure. To this end, we first present a dedicated intersection coordination framework, where the involved vehicles hand over their control authorities and follow instructions from a centralized coordinator. Then a unified cooperative trajectory optimization problem will be formulated to maximize the traffic throughput while ensuring the driving safety and long-term stability of the coordination system. To address the key computational challenges in the real-world deployment, we reformulate this non-convex sequential decision problem into a model-free Markov Decision Process (MDP) and tackle it by devising a Twin Delayed Deep Deterministic
    
[^93]: 视觉空间推理

    Visual Spatial Reasoning. (arXiv:2205.00363v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2205.00363](http://arxiv.org/abs/2205.00363)

    本文介绍了一种名为Visual Spatial Reasoning（VSR）的数据集，其中包含超过10k个自然文本-图像配对，用于推理包括66种空间关系，研究发现目前的视觉和语言模型（VLMs）难以捕捉关系信息和较少关注物体的方向关系。

    

    空间关系是人类认知的基本组成部分。然而，它们以各种方式用自然语言表达，先前的研究表明，目前的视觉和语言模型（VLMs）难以捕捉关系信息。在本文中，我们提出了一种名为Visual Spatial Reasoning（VSR）的数据集，其中包含超过10k个自然文本-图像配对，包括66种英语的空间关系（如：在下面，在前面和面对）。虽然使用了看似简单的注释格式，我们展示了数据集包括具有挑战性的语言现象，例如不同的参考框架。我们展示了人类和模型表现之间的巨大差距：人类准确率高达95%以上，而最先进的模型仅能达到70%左右。我们注意到VLM按关系表现的能力与训练示例数量几乎没有相关性，并且测试的模型通常无法识别涉及对象方向的关系。

    Spatial relations are a basic part of human cognition. However, they are expressed in natural language in a variety of ways, and previous work has suggested that current vision-and-language models (VLMs) struggle to capture relational information. In this paper, we present Visual Spatial Reasoning (VSR), a dataset containing more than 10k natural text-image pairs with 66 types of spatial relations in English (such as: under, in front of, and facing). While using a seemingly simple annotation format, we show how the dataset includes challenging linguistic phenomena, such as varying reference frames. We demonstrate a large gap between human and model performance: the human ceiling is above 95%, while state-of-the-art models only achieve around 70%. We observe that VLMs' by-relation performances have little correlation with the number of training examples and the tested models are in general incapable of recognising relations concerning the orientations of objects.
    
[^94]: 修正噪声：Disentangling Source Feature用于StyleGAN的迁移学习

    Fix the Noise: Disentangling Source Feature for Transfer Learning of StyleGAN. (arXiv:2204.14079v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2204.14079](http://arxiv.org/abs/2204.14079)

    本文提出了一种新的方法“FixNoise”，在StyleGAN的迁移学习中引入了简单的特征匹配损失来改善生成质量，并在目标特征空间的一部分中仅保留源特征以控制源特征的程度。实验证明其在领域翻译和属性编辑中的有效性。

    

    近来，StyleGAN的迁移学习在解决不同任务，特别是领域翻译上表现出了巨大潜力。然而，以往的方法通过交换或冻结权重来利用源模型进行迁移学习，但其在视觉质量和控制源特征方面存在限制。本文提出了一种新的方法，通过引入简单的特征匹配损失来改善生成质量，并通过所提出的策略“FixNoise”训练目标模型以仅在目标特征空间的一部分中保留源特征，从而控制源特征的程度。由于特征空间是分离的，我们的方法可以在单个模型中平滑地控制源特征的程度。大量实验证明了我们的方法在领域翻译和属性编辑中的有效性。

    Transfer learning of StyleGAN has recently shown great potential to solve diverse tasks, especially in domain translation. Previous methods utilized a source model by swapping or freezing weights during transfer learning, however, they have limitations on visual quality and controlling source features. In other words, they require additional models that are computationally demanding and have restricted control steps that prevent a smooth transition. In this paper, we propose a new approach to overcome these limitations. Instead of swapping or freezing, we introduce a simple feature matching loss to improve generation quality. In addition, to control the degree of source features, we train a target model with the proposed strategy, FixNoise, to preserve the source features only in a disentangled subspace of a target feature space. Owing to the disentangled feature space, our method can smoothly control the degree of the source features in a single model. Extensive experiments demonstrat
    
[^95]: 因果推理与视觉表征学习的交汇：一项前瞻性研究

    Causal Reasoning Meets Visual Representation Learning: A Prospective Study. (arXiv:2204.12037v8 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2204.12037](http://arxiv.org/abs/2204.12037)

    这项论文讨论了视觉表征学习中缺乏解释性，鲁棒性和泛化性的问题，并提出了因果推理范式来实现这些属性。

    

    视觉表征学习在各种实际应用中都是无处不在的，包括视觉理解、视频理解、多模态分析、人机交互和城市计算。由于大数据时代涌现的大量多模态异构的时空/时间/时空数据，现有视觉模型的解释性、鲁棒性和超出分布的泛化性缺乏挑战。现有方法中大多数倾向于适应原始数据/变量分布，忽略了多模态知识背后的基本因果关系，缺乏统一的指导和分析，无法解释为什么现代视觉表征学习方法容易陷入数据偏见，并且具有有限的泛化和认知能力。受到人类级别代理的强大推理能力的启发，近年来，人们付出了很大的努力开发因果推理范式，以实现强大的表征。

    Visual representation learning is ubiquitous in various real-world applications, including visual comprehension, video understanding, multi-modal analysis, human-computer interaction, and urban computing. Due to the emergence of huge amounts of multi-modal heterogeneous spatial/temporal/spatial-temporal data in big data era, the lack of interpretability, robustness, and out-of-distribution generalization are becoming the challenges of the existing visual models. The majority of the existing methods tend to fit the original data/variable distributions and ignore the essential causal relations behind the multi-modal knowledge, which lacks unified guidance and analysis about why modern visual representation learning methods easily collapse into data bias and have limited generalization and cognitive abilities. Inspired by the strong inference ability of human-level agents, recent years have therefore witnessed great effort in developing causal reasoning paradigms to realize robust represe
    
[^96]: CgAT：基于中心引导的对抗性训练提升Hashing检索鲁棒性

    CgAT: Center-Guided Adversarial Training for Deep Hashing-Based Retrieval. (arXiv:2204.10779v5 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2204.10779](http://arxiv.org/abs/2204.10779)

    本文提出了CgAT方法，基于中心引导的对抗性训练方法，可提升深度Hashing网络检索的鲁棒性，取得了领先于现有方法的效果。

    

    深度Hashing在图像检索领域被广泛应用，但往往容易受到对抗样本的攻击。为此，本文提出了基于min-max的中心引导的对抗性训练方法（CgAT），通过最坏的对抗性样本来提高深度Hashing网络的鲁棒性。实验表明，该方法在多个基准数据集上优于目前深度Hashing检索领域中的最新对抗性防御算法。

    Deep hashing has been extensively utilized in massive image retrieval because of its efficiency and effectiveness. However, deep hashing models are vulnerable to adversarial examples, making it essential to develop adversarial defense methods for image retrieval. Existing solutions achieved limited defense performance because of using weak adversarial samples for training and lacking discriminative optimization objectives to learn robust features. In this paper, we present a min-max based Center-guided Adversarial Training, namely CgAT, to improve the robustness of deep hashing networks through worst adversarial examples. Specifically, we first formulate the center code as a semantically-discriminative representative of the input image content, which preserves the semantic similarity with positive samples and dissimilarity with negative examples. We prove that a mathematical formula can calculate the center code immediately. After obtaining the center codes in each optimization iterati
    

