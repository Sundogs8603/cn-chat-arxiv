# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Tryage: Real-time, intelligent Routing of User Prompts to Large Language Model.](http://arxiv.org/abs/2308.11601) | Tryage是一个上下文感知的路由系统，能够根据对个体输入提示的分析，从模型库中选择最佳的专家模型，以消除模型选择和定制化的负担，释放庞大的新兴模型库的巨大威力给最终用户。 |
| [^2] | [UniDoc: A Universal Large Multimodal Model for Simultaneous Text Detection, Recognition, Spotting and Understanding.](http://arxiv.org/abs/2308.11592) | UniDoc是一种通用的大型多模态模型，具备文本检测和识别能力，并通过任务之间的有益交互提高每个任务的性能，达到了在多个基准测试中的最先进水平。 |
| [^3] | [Causal Intersectionality and Dual Form of Gradient Descent for Multimodal Analysis: a Case Study on Hateful Memes.](http://arxiv.org/abs/2308.11585) | 本篇论文探讨了因果交叉性和双重梯度下降在多模态分析中的应用，以仇恨迷因检测为例。通过结合因果分析和基于梯度的方法，研究发现模型的内部机制可以揭示其因果效应，并介绍了交叉性和模态的梯度注意力的摘要化方法。 |
| [^4] | [Building Emotional Support Chatbots in the Era of LLMs.](http://arxiv.org/abs/2308.11584) | 本研究利用大型语言模型（LLMs）的能力，通过合成人类见解与计算能力，构建了一个广泛的情感支持对话数据集。最终提出了一种名为ExTES的可扩展情感支持对话数据集，并部署了高级调优技术，以解决情感支持聊天机器人在实际应用中遇到的挑战。 |
| [^5] | [Refashioning Emotion Recognition Modelling: The Advent of Generalised Large Models.](http://arxiv.org/abs/2308.11578) | 本论文综合调查了大型语言模型（LLMs）在情绪识别中表现的各个方面，包括上下文学习、少样本学习和准确度等。LLMs的出现为情绪识别建模带来了新的潜力和机会。 |
| [^6] | [Large Language Model as a User Simulator.](http://arxiv.org/abs/2308.11534) | 本文创新性地将从真实人机对话中提取的人类问题作为学习目标，并且训练了一个用户模拟器UserGPT，并使用生成的高质量合成对话数据集RealChat来训练助手模型ReaLM。实验证明，ReaLM在多个基准测试中超过了基准模型。 |
| [^7] | [Furnishing Sound Event Detection with Language Model Abilities.](http://arxiv.org/abs/2308.11530) | 本文提出了一种增强声音事件检测的方法，通过对齐音频特征和文本特征来实现声音事件分类和时间定位。该方法利用语言模型的语义能力直接生成序列，相比传统方法更简洁全面，并通过实验证明了其在时间戳捕获和事件分类方面的有效性。 |
| [^8] | [BERT4CTR: An Efficient Framework to Combine Pre-trained Language Model with Non-textual Features for CTR Prediction.](http://arxiv.org/abs/2308.11527) | BERT4CTR是一种高效框架，将预训练语言模型与非文本特征相结合，用于点击率预测。它探索了两种整合多模态输入的方法，并解决了文本和非文本输入之间的交叉信息学习问题。 |
| [^9] | [Learning Representations on Logs for AIOps.](http://arxiv.org/abs/2308.11526) | 这篇论文介绍了一种针对AIOps的学习表示方法，通过训练大型语言模型（LLM）在公共和专有数据上，能够有效应对有限标记数据的日志分析任务。 |
| [^10] | [Self-Deception: Reverse Penetrating the Semantic Firewall of Large Language Models.](http://arxiv.org/abs/2308.11521) | 这篇论文研究了大型语言模型的越狱问题，并提出了一种自动越狱方法，介绍了语义防火墙的概念和三种技术实现方法。 |
| [^11] | [Exploring the Power of Topic Modeling Techniques in Analyzing Customer Reviews: A Comparative Analysis.](http://arxiv.org/abs/2308.11520) | 本研究对常用主题建模方法进行了综合研究和比较，特别应用于客户评论。我们展示了这些方法在检测重要主题方面的优势，并旨在突出它们的有效性。 |
| [^12] | [Optimizing Multi-Class Text Classification: A Diverse Stacking Ensemble Framework Utilizing Transformers.](http://arxiv.org/abs/2308.11519) | 本研究提出了一种利用转换器的多样堆叠集成框架，以优化多类文本分类。通过将多个单一转换器作为基层分类器，并引入基于RoBERTa的元层分类器，实现了最优的预测模型。 |
| [^13] | [TrackFlow: Multi-Object Tracking with Normalizing Flows.](http://arxiv.org/abs/2308.11513) | 本论文提出了一种带有标准化流的多目标跟踪方法，通过融合异构信息，并解决了成本贡献、超参数调整和独立性等问题。 |
| [^14] | [Large Language Models Sensitivity to The Order of Options in Multiple-Choice Questions.](http://arxiv.org/abs/2308.11483) | 本文研究了大型语言模型对多选题选项顺序的敏感性。实验证明，当对回答选项进行重新排序时，大型语言模型的性能差距可以达到13%至75%。这种敏感性主要在大型语言模型对前两个/三个选项的预测不确定时出现。 |
| [^15] | [Expecting The Unexpected: Towards Broad Out-Of-Distribution Detection.](http://arxiv.org/abs/2308.11480) | 这项研究对机器学习中分布外检测方法进行了评估，发现现有方法在检测未知类别方面表现出色，但在遇到其他类型的分布变化时性能不稳定。 |
| [^16] | [Revisiting column-generation-based matheuristic for learning classification trees.](http://arxiv.org/abs/2308.11477) | 该论文改进了基于列生成的启发式方法，以提高学习分类树的效果。通过减少子问题数量、使用数据依赖约束作为割平面以及生成违反约束的数据点，该方法提高了可伸缩性并适用于大型数据集。 |
| [^17] | [IT3D: Improved Text-to-3D Generation with Explicit View Synthesis.](http://arxiv.org/abs/2308.11473) | 这项研究提出了一种利用显式视角合成多视角图像来改进文本到3D生成技术的策略，该方法通过结合图像到图像流水线和大型扩散模型生成高质量的图像，并通过鉴别器和扩散生成对抗训练来解决视角一致性和内容变化的挑战。 |
| [^18] | [Dynamic Open Vocabulary Enhanced Safe-landing with Intelligence (DOVESEI).](http://arxiv.org/abs/2308.11471) | 本文提出了一种动态开放词汇增强的智能安全着陆系统，通过利用开放词汇图像分割的能力实现无人机的视觉伺服，适应不同场景且无需大量数据积累进行模型改进，可以处理100米高度的操作。 |
| [^19] | [Internal Cross-layer Gradients for Extending Homogeneity to Heterogeneity in Federated Learning.](http://arxiv.org/abs/2308.11464) | 提出了一种基于内部跨层梯度的联邦学习方法，通过混合浅层和深层的梯度，增强了深层的相似性，从而扩展了在处理系统异质性方面的能力。 |
| [^20] | [LegalBench: A Collaboratively Built Benchmark for Measuring Legal Reasoning in Large Language Models.](http://arxiv.org/abs/2308.11462) | LegalBench是一个协同构建的法律推理基准库，涵盖了162个任务，可用于衡量大型语言模型在法律推理方面的能力，为律师和LLM开发者提供了共同的词汇表。 |
| [^21] | [A Survey on Self-Supervised Representation Learning.](http://arxiv.org/abs/2308.11455) | 本综述论文全面回顾了无监督学习图像表示的方法，提出了一种分类法，并总结了最新的实验结果，为深入研究表示学习领域的人员提供了一个起点。 |
| [^22] | [Convergence guarantee for consistency models.](http://arxiv.org/abs/2308.11449) | 本文提供了一致性模型（CMs）的收敛保证，该模型可以在一步内从任何真实数据分布中有效地进行采样，且具有较小的$W_2$误差。这一结果对于$L^2$精确的分数和一致性假设成立，并且不需要强假设，同时在所有参数上呈多项式尺度增长，与基于分数的生成模型（SGMs）的最新收敛保证相匹配。另外，本文还提供了多步一致性采样过程可以进一步减小误差的结果。 |
| [^23] | [Exploration of Rashomon Set Assists Explanations for Medical Data.](http://arxiv.org/abs/2308.11446) | 本文提出了一种新的过程来探索和分析医疗数据中的拉舒蒙集合模型，从而超越传统单一模型选择的方法，并通过引入"拉舒蒙检测"算法识别出集合中最不同的模型。 |
| [^24] | [A Survey on Large Language Model based Autonomous Agents.](http://arxiv.org/abs/2308.11432) | 该论文综述了基于大型语言模型的自主代理的研究，提供了从整体角度对该领域的系统审查，其创新之处在于利用大量网络知识实现人类水平的智能决策。 |
| [^25] | [AIxArtist: A First-Person Tale of Interacting with Artificial Intelligence to Escape Creative Block.](http://arxiv.org/abs/2308.11424) | 这篇论文分享了一个HCI研究员与AI互动的第一人称故事，研究旨在尝试摆脱创造性阻碍。通过探索AI如何支持艺术家的创造力以及可解释性的含义，此研究为XAIxArts社区提供了进一步讨论和探索的思考。 |
| [^26] | [TurboViT: Generating Fast Vision Transformers via Generative Architecture Search.](http://arxiv.org/abs/2308.11421) | TurboViT是通过生成式架构搜索生成的快速视觉变压器架构设计，它在准确性和计算效率之间取得了良好的平衡。 |
| [^27] | [Tensor Regression.](http://arxiv.org/abs/2308.11419) | 本书系统研究了基于张量的回归模型及其应用，并覆盖了基本知识、核心思想和理论特性。读者可以学习如何使用这些方法解决多路径数据回归任务。 |
| [^28] | [Interpretable Distribution-Invariant Fairness Measures for Continuous Scores.](http://arxiv.org/abs/2308.11375) | 对于连续评分，我们提出了一种基于Wasserstein距离的分布不变公平性度量方法，能够解释度量结果并适用于比较不同模型、数据集或时间点之间的偏差。 |
| [^29] | [How Much Temporal Long-Term Context is Needed for Action Segmentation?.](http://arxiv.org/abs/2308.11358) | 本文提出了一种基于transformer的模型，利用稀疏注意力捕捉视频的完整上下文，以回答时间行动分割需要多少长期时间上下文。通过与当前最先进的方法进行比较，在三个时间行动分割数据集上取得了良好的性能。 |
| [^30] | [Semantic RGB-D Image Synthesis.](http://arxiv.org/abs/2308.11356) | 本文提出了语义RGB-D图像合成方法，用于解决RGB-D语义图像分割训练集缺乏多样性的问题。通过生成逼真的RGB-D图像来实现给定语义标签图的合成。本文的主要创新是提出了一种生成器，可以处理多模态数据，将与模态无关的信息与与模态相关的信息分离开来。 |
| [^31] | [ProAgent: Building Proactive Cooperative AI with Large Language Models.](http://arxiv.org/abs/2308.11339) | ProAgent是一个利用大型语言模型构建的主动合作的AI框架，能够预测队友的决策并为自己制定增强计划，具有高度的模块化和可解释性。 |
| [^32] | [On the Opportunities and Challenges of Offline Reinforcement Learning for Recommender Systems.](http://arxiv.org/abs/2308.11336) | 研究聚焦于解决强化学习推荐系统的数据效率问题，离线强化学习为从线下数据集中学习并在在线环境应用策略提供了新的解决方案。 |
| [^33] | [GrowCLIP: Data-aware Automatic Model Growing for Large-scale Contrastive Language-Image Pre-training.](http://arxiv.org/abs/2308.11331) | GrowCLIP是一种数据感知的自动模型增长算法，用于对比语言-图像预训练。它能够根据持续增长的图像-文本数据找到最佳架构，实现高效训练和更好的性能。 |
| [^34] | [From Mundane to Meaningful: AI's Influence on Work Dynamics -- evidence from ChatGPT and Stack Overflow.](http://arxiv.org/abs/2308.11302) | 本研究探讨了ChatGPT对编码问题解决方式的影响，发现它显著减少了问题数量，提高了问题文档质量，以及剩下的问题更加复杂，暗示着AI不仅提升了生产力，还改变了工作方式。 |
| [^35] | [Improving Knot Prediction in Wood Logs with Longitudinal Feature Propagation.](http://arxiv.org/abs/2308.11291) | 本文提出了一种通过木材外形预测内部缺陷位置的方法，利用卷积循环神经网络解决二分类分割任务，实现在廉价设备上进行推理，并在冷杉和云杉树种上验证了该方法的有效性。 |
| [^36] | [ShadowNet for Data-Centric Quantum System Learning.](http://arxiv.org/abs/2308.11290) | 本研究提出了一个数据为中心的量子系统学习范式，将神经网络和经典阴影相结合，以解决大型量子系统动力学的预测和泛化问题。 |
| [^37] | [CNN based Cuneiform Sign Detection Learned from Annotated 3D Renderings and Mapped Photographs with Illumination Augmentation.](http://arxiv.org/abs/2308.11277) | 该论文描述了一个基于CNN的楔形符号检测方法，通过学习注释的三维渲染和映射照片，结合光照增强。研究团队创建了HeiCuBeDa和MaiCuBeDa数据集，并提供了映射工具以传递注释。符号定位方法使用RepPoints检测器来预测字符的位置。该方法可以应用于处理楔形文字的数字工具开发和研究。 |
| [^38] | [Music Understanding LLaMA: Advancing Text-to-Music Generation with Question Answering and Captioning.](http://arxiv.org/abs/2308.11276) | 本研究提出了一个名为音乐理解LLaMA（MU-LLaMA）的模型，通过应用问答和字幕生成的方法，解决了文本到音乐生成面临的数据稀缺问题。我们设计了一个新的MusicQA数据集，用于训练MU-LLaMA模型，并在音乐问答方面取得了出色的性能。 |
| [^39] | [Robust Lagrangian and Adversarial Policy Gradient for Robust Constrained Markov Decision Processes.](http://arxiv.org/abs/2308.11267) | 本文介绍了两种算法，具有鲁棒拉格朗日的RCPG和对抗性RCPG，用于解决鲁棒约束马尔可夫决策过程中的问题。具有鲁棒拉格朗日的RCPG通过使用拉格朗日来计算最坏情况下的动态，而对抗性RCPG通过对抗策略的方式直接和增量学习最坏情况下的动态。 |
| [^40] | [Efficient Last-iterate Convergence Algorithms in Solving Games.](http://arxiv.org/abs/2308.11256) | 该论文研究了求解博弈中高效收敛算法的问题，通过分析乐观梯度下降上升（OGDA）和乐观乘法权重更新（OMWU）算法，以及基于奖励转化（RT）框架的算法，提出了解决这些问题的方法。 |
| [^41] | [A survey on bias in machine learning research.](http://arxiv.org/abs/2308.11254) | 本文调查了机器学习研究中的偏差问题，提供了偏差和错误的分类，并分析了机器学习流程中超过四十种潜在的偏差来源，为每种情况提供了清晰的示例。通过理解和减轻机器学习中的偏差，可以开发出更公平、更透明、更准确的ML模型。 |
| [^42] | [Multi-Source Domain Adaptation for Cross-Domain Fault Diagnosis of Chemical Processes.](http://arxiv.org/abs/2308.11247) | 本文在化学过程的交叉领域故障诊断中，对单源和多源无监督领域适应算法进行了广泛比较。研究结果表明，即使没有进行适应，使用多个领域进行训练也具有积极影响。 |
| [^43] | [Faster Optimization in S-Graphs Exploiting Hierarchy.](http://arxiv.org/abs/2308.11242) | 本文提出了一种在S-Graphs中利用层次性进行快速优化的方法，通过边缘化冗余的机器人姿态及其与相同结构实体的观测之间的连接来减小图的大小，并通过生成和优化局部图来实现压缩S-Graphs。 |
| [^44] | [ROSGPT_Vision: Commanding Robots Using Only Language Models' Prompts.](http://arxiv.org/abs/2308.11236) | 本文提出了一种新的机器人设计模式，名为Prompting Robotic Modalities（PRM），通过仅使用语言模型的提示来控制机器人。并且在构建了一个名为ROSGPT_Vision的机器人框架上应用了这种设计模式。这个框架能够通过视觉提示和LLM提示执行机器人任务。 |
| [^45] | [Adaptive White-Box Watermarking with Self-Mutual Check Parameters in Deep Neural Networks.](http://arxiv.org/abs/2308.11235) | 本文提出了一种自适应白盒水印技术，通过自我互助检查参数来检测篡改的深度神经网络模型，并且提出了最大化信息容量的自适应嵌入方法。实验证明，当修改率低于20%时，该方法具有出色的恢复性能。 |
| [^46] | [Traffic Flow Optimisation for Lifelong Multi-Agent Path Finding.](http://arxiv.org/abs/2308.11234) | 本文提出了一种新的终身多智能体路径规划方法，通过引导智能体避开拥堵路径来优化交通流量，显著提高解决方案质量和总体吞吐量。 |
| [^47] | [On-Premise AIOps Infrastructure for a Software Editor SME: An Experience Report.](http://arxiv.org/abs/2308.11225) | 本文研究了通过利用开源工具实施本地AIOps解决方案的可行性。我们成功部署了一种综合AIOps基础设施，并提供了构建其各个组件的不同选择的理由。 |
| [^48] | [Evaluating Large Language Models on Graphs: Performance Insights and Comparative Analysis.](http://arxiv.org/abs/2308.11224) | 本研究评估了四个大型语言模型在图数据上解决分析问题的能力，结果显示LLM在理解图数据、生成正确结果和进行结构推理方面表现出色，但在真实性和矫正能力方面存在一些挑战。 |
| [^49] | [Federated Learning on Patient Data for Privacy-Protecting Polycystic Ovary Syndrome Treatment.](http://arxiv.org/abs/2308.11220) | 本研究使用联邦学习方法，通过访问大量多样的患者数据并保护隐私，来预测多囊卵巢综合征患者的最佳治疗药物选项。 |
| [^50] | [Federated Learning in Big Model Era: Domain-Specific Multimodal Large Models.](http://arxiv.org/abs/2308.11217) | 本论文提出了一种多模态联邦学习框架，利用私有领域数据协同训练大型模型，以实现跨场景的智能服务。在大模型时代，该框架解决了异构数据、模型聚合、性能和成本权衡、数据隐私以及激励机制等方面的挑战。 |
| [^51] | [ConcatPlexer: Additional Dim1 Batching for Faster ViTs.](http://arxiv.org/abs/2308.11199) | 本文提出了一种名为ConcatPlexer的方法，通过在视觉识别中使用附加的Dim1批处理（即连接）来提高吞吐量，同时准确性受到的影响较小。 |
| [^52] | [ViLLA: Fine-Grained Vision-Language Representation Learning from Real-World Data.](http://arxiv.org/abs/2308.11194) | 本论文通过系统评估表明，当训练集的配对复杂性增加时，标准的视觉-语言模型在学习图像区域与文本属性之间的关系时表现较差，性能下降达到 |
| [^53] | [Diversity Measures: Domain-Independent Proxies for Failure in Language Model Queries.](http://arxiv.org/abs/2308.11189) | 本文提出了一种基于回应多样性的大型语言模型错误量化指标，这些指标独立于领域特定信息，并与失败概率强相关。实证结果展示了这些指标在少样本提示、思维链推理和错误检测方面的应用。 |
| [^54] | [MISSRec: Pre-training and Transferring Multi-modal Interest-aware Sequence Representation for Recommendation.](http://arxiv.org/abs/2308.11175) | 本文提出了一种名为MISSRec的多模态预训练和转移学习框架，通过探索多模态信息的潜力，解决了序列推荐中的稀疏ID和冷启动问题，并提升了推荐模型的可转移性和性能。 |
| [^55] | [Hierarchical Point-based Active Learning for Semi-supervised Point Cloud Semantic Segmentation.](http://arxiv.org/abs/2308.11166) | 本文提出了一种分层基于点的主动学习策略，通过测量每个点的不确定性来进行标注，解决了现有方法中冗余信息和区域划分的问题。 |
| [^56] | [xxMD: Benchmarking Neural Force Fields Using Extended Dynamics beyond Equilibrium.](http://arxiv.org/abs/2308.11155) | 在神经力场模型中，常用的MD17数据集对于表示经历化学反应的系统不足。为了解决这一问题，我们引入了xxMD数据集，该数据集采样自扩展激发态分子动力学，包含了能量和力的信息。 |
| [^57] | [Exploring Unsupervised Cell Recognition with Prior Self-activation Maps.](http://arxiv.org/abs/2308.11144) | 该论文提出了一种无监督细胞识别方法，通过先验自激活图生成伪掩膜作为训练目标。在多个数据集上的实验证明，该方法在细胞分割和多类别细胞检测任务中优于其他监督和弱监督方法。 |
| [^58] | [Is There Any Social Principle for LLM-Based Agents?.](http://arxiv.org/abs/2308.11136) | LLM基于智能体不仅应关注“以人为中心”的对齐或应用，还应关注智能体自身，并探讨社会科学在智能体中的潜力。 |
| [^59] | [ReLLa: Retrieval-enhanced Large Language Models for Lifelong Sequential Behavior Comprehension in Recommendation.](http://arxiv.org/abs/2308.11131) | 本论文提出了一种名为ReLLa的检索增强大型语言模型框架，用于零样本和小样本推荐任务。通过语义用户行为检索（SUBR）来提取上下文中的有用信息，以改善LLMs的推荐性能。 |
| [^60] | [Transformers for Capturing Multi-level Graph Structure using Hierarchical Distances.](http://arxiv.org/abs/2308.11129) | 本论文提出了一种层次距离结构编码（HDSE）方法，用于捕捉多层次图结构。经过在12个真实世界数据集上的实验，证明了该方法在10个基准数据集上实验效果达到了最先进水平。 |
| [^61] | [CAME: Contrastive Automated Model Evaluation.](http://arxiv.org/abs/2308.11111) | CAME是一个不依赖训练集的对比自动化模型评估框架，通过理论分析和实证验证，建立了模型性能与对比损失之间的可预测关系，并取得了新的SOTA结果。 |
| [^62] | [Anonymity at Risk? Assessing Re-Identification Capabilities of Large Language Models.](http://arxiv.org/abs/2308.11103) | 本研究评估了大型语言模型在重新识别匿名个人方面的能力，并发现模型大小、输入长度和指令调整是最重要的决定因素。 |
| [^63] | [Using Early Exits for Fast Inference in Automatic Modulation Classification.](http://arxiv.org/abs/2308.11100) | 本文提出了在自动调制分类中使用早期退出技术加速推理的方法。通过使用早期退出架构，针对信噪比适中至较高的信号，可以显著降低深度神经网络的推理速度，而不损失分类性能。 |
| [^64] | [Video OWL-ViT: Temporally-consistent open-world localization in video.](http://arxiv.org/abs/2308.11093) | 本论文提出了Video OWL-ViT模型，将预训练的开放世界图像模型应用于视频定位任务，通过添加变换器解码器实现时间上的连续传播，相比于传统的跟踪-by-detection方法具有更好的时间一致性。 |
| [^65] | [Collaborative Route Planning of UAVs, Workers and Cars for Crowdsensing in Disaster Response.](http://arxiv.org/abs/2308.11088) | 这篇论文研究了在灾难响应中，无人机、工人和汽车的协同路径规划问题，旨在最大化任务完成率。研究者提出了一种多智能体路径规划算法MANF-RL-RP，该算法包括了全局-局部双重信息处理和针对多智能体系统的定制模型结构。 |
| [^66] | [Neural Amortized Inference for Nested Multi-agent Reasoning.](http://arxiv.org/abs/2308.11071) | 本研究引入了一种新的方法，利用神经网络对高阶社会推理进行摊销，从而加快嵌套多智能体推理的计算速度，实验结果表明该方法在计算效率上表现出色，同时准确性降低最小化。 |
| [^67] | [Temporal-Distributed Backdoor Attack Against Video Based Action Recognition.](http://arxiv.org/abs/2308.11070) | 本文介绍了一种针对视频数据的简单而有效的背门攻击方法，通过在转换领域中添加难以察觉的、时间上分布的触发器来实现误分类。 |
| [^68] | [Topological Graph Signal Compression.](http://arxiv.org/abs/2308.11068) | 这项研究提出了一种基于拓扑结构的图信号压缩方法，通过处理高阶交互、聚类和消息传递等步骤，相比于传统方法在压缩信号时具有更好的重建误差，能够更好地捕捉和利用空间和时间特征。 |
| [^69] | [CSM-H-R: An Automatic Context Reasoning Framework for Interoperable Intelligent Systems and Privacy Protection.](http://arxiv.org/abs/2308.11066) | CSM-H-R是一个自动上下文推理框架，用于可互操作的智能系统和隐私保护。该框架结合了本体和状态，在运行时识别有意义的高级上下文，并可应用于不同的推理技术。在智能校园环境中进行了智能电梯系统的案例研究，并展示了使用先进的数学和概率模型的潜力。 |
| [^70] | [Beyond Discriminative Regions: Saliency Maps as Alternatives to CAMs for Weakly Supervised Semantic Segmentation.](http://arxiv.org/abs/2308.11052) | 本篇论文对弱监督语义分割中的显著性图和类激活图进行了全面比较，提出了新的评估指标，并证明了显著性图的有效性。 |
| [^71] | [Logistics Hub Location Optimization: A K-Means and P-Median Model Hybrid Approach Using Road Network Distances.](http://arxiv.org/abs/2308.11038) | 本研究基于K-Means和P-Median模型提出了一种混合方法，通过使用道路网络距离来优化在城市环境下物流集散地的位置布置，以减少配送距离和碳足迹。 |
| [^72] | [Digital Twin-Oriented Complex Networked Systems based on Heterogeneous node features and interaction rules.](http://arxiv.org/abs/2308.11034) | 本研究提出了一种面向数字孪生的复杂网络系统的可扩展建模框架，重点关注节点特征和交互规则。通过实验研究了网络增长和疫情传播的不同级别的复杂性对系统的影响，结果表明需要在DT-CNS中平衡这些复杂性水平。 |
| [^73] | [RBA-GCN: Relational Bilevel Aggregation Graph Convolutional Network for Emotion Recognition.](http://arxiv.org/abs/2308.11029) | 提出了RBA-GCN模型用于情感识别。该模型通过引入关系双层聚合和图生成模块，解决了GCN模型中的节点信息冗余和远距离上下文信息捕获问题。 |
| [^74] | [Personalized Event Prediction for Electronic Health Records.](http://arxiv.org/abs/2308.11013) | 该论文研究了个性化的电子健康记录事件预测，提出了多个新的预测模型和方法以更好地适应个体差异。 |
| [^75] | [Eigenvalue-based Incremental Spectral Clustering.](http://arxiv.org/abs/2308.10999) | 本文介绍了一种基于特征值的增量谱聚类方法，通过将数据集划分为子集并进行聚类和合并，可以获得与聚类整个数据集相近的结果。 |
| [^76] | [SPEGTI: Structured Prediction for Efficient Generative Text-to-Image Models.](http://arxiv.org/abs/2308.10997) | 本文提出了一种使用马尔可夫随机场（MRF）模型的轻量级方法，用于实现图像不同区域的相容性，以降低生成文本到图像模型的计算成本。 |
| [^77] | [ERA*: Enhanced Relaxed A* algorithm for Solving the Shortest Path Problem in Regular Grid Maps.](http://arxiv.org/abs/2308.10988) | 本文介绍了一种改进的放松A*算法，用于解决规则网格地图中的最短路径问题。相较于现有算法，该算法在时间和内存方面具有显著的优势，并通过实验证明其在各种类型和大小的地图上都表现出高效性能。 |
| [^78] | ["Guinea Pig Trials" Utilizing GPT: A Novel Smart Agent-Based Modeling Approach for Studying Firm Competition and Collusion.](http://arxiv.org/abs/2308.10974) | "引用GPT的“豚鼠试验”是一种创新的智能代理建模方法，利用智能代理代表企业进行竞争和勾结研究。它比使用人类主体进行实验更具成本效益和灵活性，并展现出超越传统代理建模方法的能力。" |
| [^79] | [DocPrompt: Large-scale continue pretrain for zero-shot and few-shot document question answering.](http://arxiv.org/abs/2308.10959) | 本文提出了一个名为DocPrompt的方法，用于处理文档问答任务，具有强大的零样本和少样本性能。实验结果表明，DocPrompt模型经过连续预训练后在文档问答任务中表现优异，大大提高了交付效率和模型性能，降低了注释成本和劳动成本。 |
| [^80] | [DataVinci: Learning Syntactic and Semantic String Repairs.](http://arxiv.org/abs/2308.10922) | DataVinci是一个全自动的无监督字符串数据错误检测和修复系统，可学习句法和语义模式，并自动推导出对数据错误的修复。 |
| [^81] | [Deep Semi-supervised Anomaly Detection with Metapath-based Context Knowledge.](http://arxiv.org/abs/2308.10918) | 本文介绍了一种利用基于Metapath的半监督学习的新颖方法，用于图异常检测。通过在编码器和解码器中使用GCN层来有效传播上下文信息，以及特别设计的异常社区，该方法在结构和属性差异的学习中表现出优越性能。通过实验证明了该方法的有效性，为未来的研究提供了重要的思路和方向。 |
| [^82] | [Diffusion Model as Representation Learner.](http://arxiv.org/abs/2308.10916) | 本文深入研究了扩散概率模型的表示能力，并提出了一种利用生成模型的知识进行识别任务的新的知识传递方法。通过引入RepFusion，我们从预先训练的DPMs中提取表示并将其作为学生网络的监督，通过强化学习来确定最佳的时间步骤。 |
| [^83] | [Explaining Emergence.](http://arxiv.org/abs/2308.10912) | 论文研究了出现现象，提出了计算不可简化性的概念，这是能够从客观角度理解出现现象的关键。 |
| [^84] | [Federated Pseudo Modality Generation for Incomplete Multi-Modal MRI Reconstruction.](http://arxiv.org/abs/2308.10910) | 本文提出了一种称为Fed-PMG的联合学习框架，通过伪模态生成机制解决了联合多模态MRI重建中的模态缺失问题，以提高通信效率。通过共享频率空间中幅度谱的分布信息恢复丢失的模态，避免了成对多模态数据的需求。 |
| [^85] | [Analyzing Quantization in TVM.](http://arxiv.org/abs/2308.10905) | 该论文研究了在TVM中8位量化的性能问题，并讨论了兼容性和优化机会。 |
| [^86] | [DynED: Dynamic Ensemble Diversification in Data Stream Classification.](http://arxiv.org/abs/2308.10807) | DynED是一种动态集成多样化方法，基于MRR结合了组件的多样性和预测准确性，在数据流环境中实现了更高的准确率。 |
| [^87] | [Stabilizing Unsupervised Environment Design with a Learned Adversary.](http://arxiv.org/abs/2308.10797) | 本论文研究了无监督环境设计（UED）中PAIRED方法存在的问题，并提出了解决方案，使其在实际性能上能够与或超过最先进的方法。 |
| [^88] | [Normative Conditional Reasoning as a Fragment of HOL.](http://arxiv.org/abs/2308.10686) | 本论文报告了关于正式化条件推理的研究结果，包括Aqvist的条件义务系统E的机械化和伦理论据评估的工具的开发。 |
| [^89] | [Performance Enhancement Leveraging Mask-RCNN on Bengali Document Layout Analysis.](http://arxiv.org/abs/2308.10511) | 本论文旨在通过使用基于掩膜区域卷积神经网络 (Mask-RCNN) 对孟加拉文档进行版面分析，提升性能。通过逐步的超参数调整，我们达到了0.889的良好dice分数。虽然在应用英文文档模型时遇到了一些挑战，但这表明每种语言都有其特定的问题需要解决。 |
| [^90] | [Taken by Surprise: Contrast effect for Similarity Scores.](http://arxiv.org/abs/2308.09765) | 提出了一种新的相似度度量方法，称为“惊喜分数”，该方法能够考虑对象的上下文信息并显著提高零样本和少样本文档分类任务的性能。 |
| [^91] | [MindMap: Knowledge Graph Prompting Sparks Graph of Thoughts in Large Language Models.](http://arxiv.org/abs/2308.09729) | 本论文通过使用知识图谱来激发大型语言模型，解决了整合新知识、产生幻觉和决策过程不透明等问题，并通过生成思维导图展示了模型的推理路径，实验证明这种方法可以取得显著的实证增益。 |
| [^92] | [PMET: Precise Model Editing in a Transformer.](http://arxiv.org/abs/2308.08742) | 该论文通过分析Transformer模型中的隐藏状态，发现多头自注意力编码了某些通用知识提取模式，因此在进行模型编辑时，不需要更新多头自注意力的权重。 |
| [^93] | [Consciousness in Artificial Intelligence: Insights from the Science of Consciousness.](http://arxiv.org/abs/2308.08708) | 本论文提出了一种严谨的方法，通过对当前的人工智能系统进行详细评估来探讨人工智能的意识问题。研究中对几种科学意识理论进行概述，并通过计算方法推导出意识的“指示性特征”。分析结果表明目前的人工智能系统尚不具备意识，但建立具有意识的人工智能系统并无明显的障碍。 |
| [^94] | [Context-Aware Planning and Environment-Aware Memory for Instruction Following Embodied Agents.](http://arxiv.org/abs/2308.07241) | 这项研究提出了一种称为CPEM的系统，它利用上下文信息和环境感知记忆来改进行为智能体的感知能力，从而提高视觉导航和物体交互的效果。 |
| [^95] | [Rethinking Noisy Label Learning in Real-world Annotation Scenarios from the Noise-type Perspective.](http://arxiv.org/abs/2307.16889) | 本文提出了一种基于样本选择的噪声标签学习方法，该方法可以在真实场景下区分不同类型的噪声，并利用噪声的语义信息进行学习。通过构建原型向量和计算样本与原型向量之间的距离，该方法可以改进标签的准确性。实证评估结果表明了该方法的鲁棒性和有效性。 |
| [^96] | [Multi-Source Domain Adaptation through Dataset Dictionary Learning in Wasserstein Space.](http://arxiv.org/abs/2307.14953) | 本文提出了一种基于字典学习和最优传输的MSDA框架，通过将每个域表示为字典原子的Wasserstein重心来缓解数据分布偏移。根据该字典，提出了两种新的MSDA方法，分别基于目标域标记样本的重构和在原子分布上学习的分类器的集成。在多个基准测试集上进行的实验证明，这些方法在分类任务上取得了显著的改进效果。 |
| [^97] | [Uncertainty Guided Adaptive Warping for Robust and Efficient Stereo Matching.](http://arxiv.org/abs/2307.14071) | 本文提出了一种不确定性引导的自适应变形方法，用于鲁棒和高效的立体匹配。通过引入不确定性估计和可学习参数，可以在不同场景下适应性地调整采样区域，并实现更鲁棒和有效的立体匹配。 |
| [^98] | [An open-source deep learning algorithm for efficient and fully-automatic analysis of the choroid in optical coherence tomography.](http://arxiv.org/abs/2307.00904) | 本研究开发了一个名为DeepGPET的开源全自动深度学习算法，用于光学相干断层扫描中脉络膜区域分割，并且在数据准确性和处理速度方面取得了显著的改进。 |
| [^99] | [Survey on Sociodemographic Bias in Natural Language Processing.](http://arxiv.org/abs/2306.08158) | 本文调查了209篇关于NLP模型偏见的论文，其中大部分涉及社会人口统计偏见。研究者提出了社会人口统计偏见的定义，并确定了NLP偏见研究的三个主要类别。当前去偏见技术只是隐藏了偏见而不是真正去除它，需要进一步改进。 |
| [^100] | [Double Pessimism is Provably Efficient for Distributionally Robust Offline Reinforcement Learning: Generic Algorithm and Robust Partial Coverage.](http://arxiv.org/abs/2305.09659) | 本论文提出了一个名为P2MPO的算法框架，用于解决基于鲁棒离线RL的问题。该框架结合了灵活的模型估计子例程和双重悲观的策略优化步骤，采用双重悲观性原则以克服模型偏移等问题。研究表明，在模型准确性的假设下，该框架在拥有良好的鲁棒部分覆盖数据的情况下是具备高效性的。 |
| [^101] | [Chronosymbolic Learning: Efficient CHC Solving with Symbolic Reasoning and Inductive Learning.](http://arxiv.org/abs/2305.01206) | Chronosymbolic Learning是一个简单而有效的框架，将符号推理和数据驱动方法相结合，用于高效地解决CHC系统。实验证明它在288个基准测试上表现出优异的结果，包括许多具有非线性整数算术的实例。 |
| [^102] | [CVRecon: Rethinking 3D Geometric Feature Learning For Neural Reconstruction.](http://arxiv.org/abs/2304.14633) | 研究团队提出了一种基于代价体的3D神经重建框架CVRecon，利用丰富的几何嵌入来促进3D几何特征学习。通过引入射线上下文补偿代价体（RCCV），有效提高了视角相关信息的完整性和鲁棒性，并在各种度量方面显着提高了重建质量。 |
| [^103] | [Better Aligning Text-to-Image Models with Human Preference.](http://arxiv.org/abs/2303.14420) | 研究者们收集了一个数据集，证明现有的生成模型评估指标与人类选择相关性不强。因此，他们使用这个数据集训练了一个人类偏好分类器，并通过HPS提出了一种方法以更好地将Stable Diffusion与人类审美偏好对齐。实验表明，该方法在预测人类选择方面优于CLIP，并具有良好的泛化能力。 |
| [^104] | [h-analysis and data-parallel physics-informed neural networks.](http://arxiv.org/abs/2302.08835) | 本论文提出了一种基于$h$-分析和数据并行加速的物理启发神经网络（PINNs）的新协议，可以实现具有规模鲁棒性和高吞吐量的PIML模型。实验证明该协议易于实现，不会影响训练，并且具有高效性和可控性，为实现通用的规模鲁棒PIML铺平了道路。 |
| [^105] | [Truveta Mapper: A Zero-shot Ontology Alignment Framework.](http://arxiv.org/abs/2301.09767) | 提出了一个将无监督本体匹配或本体对齐视为翻译任务的新视角的Truveta Mapper框架，在零样本、统一和端到端的方式下执行多本体对齐。该框架能够在运行时间延迟和对齐质量方面胜过现有解决方案，无需显式跨本体手动标注数据。 |
| [^106] | [Semantics-Empowered Communication: A Tutorial-cum-Survey.](http://arxiv.org/abs/2212.08487) | 本文提供了基于语义的沟通方面的教程兼综述，回顾了文献，介绍了SemCom生态系统，并将研究方向进行了分类。此外，还提供了启用技术的分类和未来应用场景的展望。 |
| [^107] | [LEAGUE: Guided Skill Learning and Abstraction for Long-Horizon Manipulation.](http://arxiv.org/abs/2210.12631) | 这项工作提出了一种名为LEAGUE的集成任务规划和技能学习框架，通过利用任务规划器的引导，结合符号接口和抽象化技巧，实现了长期操纵任务的学习和泛化。 |
| [^108] | [Sequence Learning Using Equilibrium Propagation.](http://arxiv.org/abs/2209.09626) | 本文提出了使用平衡传播（EP）进行序列学习的方法，EP是一种更符合生物可信性的学习框架，与传统的反向传播方法相比具有更广泛的应用性。文中利用现代Hopfield网络的进展，解决了基于EP的模型无法处理动态输入的问题，为复杂序列学习问题提供了解决方案。 |
| [^109] | [Probable Domain Generalization via Quantile Risk Minimization.](http://arxiv.org/abs/2207.09944) | 该论文提出了一种通过Quantile Risk Minimization（QRM）方法实现可能的领域泛化的概率性框架。通过最小化预测器风险分布在不同领域上的分位数，该方法可以实现在测试时以高概率表现良好的预测器。 |
| [^110] | [Active Exploration for Inverse Reinforcement Learning.](http://arxiv.org/abs/2207.08645) | AceIRL提出了一种新的逆强化学习算法，通过主动探索来学习奖励函数和策略，在不需要环境生成模型的情况下，能够确定可行奖励函数的置信区间，并找到侧重于环境中最有信息的区域的探索策略。 |
| [^111] | [FRAug: Tackling Federated Learning with Non-IID Features via Representation Augmentation.](http://arxiv.org/abs/2205.14900) | 本研究提出了一种名为FRAug的方法，用于解决联邦学习中具有非独立同分布特征的问题。该方法通过在嵌入空间中生成合成的客户端特定样本来增强客户端数据集。通过训练一个共享的生成模型，将来自不同特征分布的客户端的知识融合起来。 |
| [^112] | [Information Theory-Guided Heuristic Progressive Multi-View Coding.](http://arxiv.org/abs/2109.02344) | 该论文从信息论的视角重新思考了现有的多视角学习范式，并提出了一种新的信息论框架，用于广义的多视角学习。在此框架的指导下，作者提出了一种三层递进的多视角编码方法。 |
| [^113] | [Measuring Social Biases in Grounded Vision and Language Embeddings.](http://arxiv.org/abs/2002.08911) | 该论文推广了社会偏见的概念，从语言嵌入扩展到了基于图像和语言的嵌入。研究表明，基于图像和语言的嵌入中的偏见与未经培训的嵌入中的偏见同等重要甚至更重要。并通过引入新的度量方法来研究偏见、语言和视觉之间的交互作用。 |

# 详细

[^1]: Tryage: 实时智能路由用户提示到大型语言模型

    Tryage: Real-time, intelligent Routing of User Prompts to Large Language Model. (arXiv:2308.11601v1 [cs.LG])

    [http://arxiv.org/abs/2308.11601](http://arxiv.org/abs/2308.11601)

    Tryage是一个上下文感知的路由系统，能够根据对个体输入提示的分析，从模型库中选择最佳的专家模型，以消除模型选择和定制化的负担，释放庞大的新兴模型库的巨大威力给最终用户。

    

    变压器架构和自注意机制的引入导致了在特定下游任务和数据领域训练的语言模型的爆炸性增长。在Hugging Face生态系统中有超过200,000个模型，用户在选择和优化模型以适应多方面的工作流程和数据领域的同时，还要解决计算、安全和时效性等问题。迫切需要机器学习框架来消除模型选择和定制化的负担，并释放庞大的新兴模型库的巨大威力给最终用户。在这里，我们提出了一个上下文感知的路由系统Tryage，它利用语言模型路由器根据对个体输入提示的分析，从模型库中选择最佳的专家模型。受大脑中的丘脑路由器启发，Tryage采用感知路由器来预测下游模型在提示上的性能，并根据目标做出路由决策。

    The introduction of the transformer architecture and the self-attention mechanism has led to an explosive production of language models trained on specific downstream tasks and data domains. With over 200, 000 models in the Hugging Face ecosystem, users grapple with selecting and optimizing models to suit multifaceted workflows and data domains while addressing computational, security, and recency concerns. There is an urgent need for machine learning frameworks that can eliminate the burden of model selection and customization and unleash the incredible power of the vast emerging model library for end users. Here, we propose a context-aware routing system, Tryage, that leverages a language model router for optimal selection of expert models from a model library based on analysis of individual input prompts. Inspired by the thalamic router in the brain, Tryage employs a perceptive router to predict down-stream model performance on prompts and, then, makes a routing decision using an ob
    
[^2]: UniDoc: 一种通用的大型多模态模型，用于同时进行文本检测、识别、定位和理解

    UniDoc: A Universal Large Multimodal Model for Simultaneous Text Detection, Recognition, Spotting and Understanding. (arXiv:2308.11592v1 [cs.AI])

    [http://arxiv.org/abs/2308.11592](http://arxiv.org/abs/2308.11592)

    UniDoc是一种通用的大型多模态模型，具备文本检测和识别能力，并通过任务之间的有益交互提高每个任务的性能，达到了在多个基准测试中的最先进水平。

    

    在大语言模型（LLMs）时代，多模态理解领域取得了巨大的进展。然而，现有的高级算法受限于有效利用大型预训练模型所固有的巨大表示能力和丰富的世界知识，并且在文本丰富场景中任务之间的有益连接尚未充分探索。在这项工作中，我们介绍了UniDoc，一种新颖的多模态模型，具备现有方法所缺乏的文本检测和识别能力。此外，UniDoc利用任务之间的有益交互来提高每个单独任务的性能。为了实现UniDoc，我们对贡献的大规模指令跟随数据集进行了统一的多模态指导调优。定量和定性实验结果表明，UniDoc在多个具有挑战性的基准测试中取得了最先进的分数。

    In the era of Large Language Models (LLMs), tremendous strides have been made in the field of multimodal understanding. However, existing advanced algorithms are limited to effectively utilizing the immense representation capabilities and rich world knowledge inherent to these large pre-trained models, and the beneficial connections among tasks within the context of text-rich scenarios have not been sufficiently explored. In this work, we introduce UniDoc, a novel multimodal model equipped with text detection and recognition capabilities, which are deficient in existing approaches. Moreover, UniDoc capitalizes on the beneficial interactions among tasks to enhance the performance of each individual task. To implement UniDoc, we perform unified multimodal instruct tuning on the contributed large-scale instruction following datasets. Quantitative and qualitative experimental results show that UniDoc sets state-of-the-art scores across multiple challenging benchmarks. To the best of our kn
    
[^3]: 因果交叉性和双重梯度下降在多模态分析中的应用：以仇恨迷因为例（arXiv:2308.11585v1 [cs.AI]）

    Causal Intersectionality and Dual Form of Gradient Descent for Multimodal Analysis: a Case Study on Hateful Memes. (arXiv:2308.11585v1 [cs.AI])

    [http://arxiv.org/abs/2308.11585](http://arxiv.org/abs/2308.11585)

    本篇论文探讨了因果交叉性和双重梯度下降在多模态分析中的应用，以仇恨迷因检测为例。通过结合因果分析和基于梯度的方法，研究发现模型的内部机制可以揭示其因果效应，并介绍了交叉性和模态的梯度注意力的摘要化方法。

    

    随着机器学习（ML）的爆炸性增长，特别是在新兴的大语言模型（LLM）的背景下，理解其内部工作中的语义意义至关重要。虽然因果分析侧重于定义语义及其量化，基于梯度的方法是可解释的人工智能（XAI）的核心，用于解释黑盒子的解释。通过协同这些方法，探索模型的内部机制如何阐明其因果效应已成为基于证据的决策的必要条件。一系列并行的研究表明，交叉性--个体的多个人口统计学因素的组合影响--可以以平均处理效应（ATE）的形式进行结构化。最初，本研究阐述了仇恨迷因检测问题可以作为一个ATE来描述，借助交叉性原则，以及基于模态的梯度注意力的摘要化。

    In the wake of the explosive growth of machine learning (ML) usage, particularly within the context of emerging Large Language Models (LLMs), comprehending the semantic significance rooted in their internal workings is crucial. While causal analyses focus on defining semantics and its quantification, the gradient-based approach is central to explainable AI (XAI), tackling the interpretation of the black box. By synergizing these approaches, the exploration of how a model's internal mechanisms illuminate its causal effect has become integral for evidence-based decision-making. A parallel line of research has revealed that intersectionality - the combinatory impact of multiple demographics of an individual - can be structured in the form of an Averaged Treatment Effect (ATE). Initially, this study illustrates that the hateful memes detection problem can be formulated as an ATE, assisted by the principles of intersectionality, and that a modality-wise summarization of gradient-based atten
    
[^4]: 在LLMs时代构建情感支持聊天机器人

    Building Emotional Support Chatbots in the Era of LLMs. (arXiv:2308.11584v1 [cs.CL])

    [http://arxiv.org/abs/2308.11584](http://arxiv.org/abs/2308.11584)

    本研究利用大型语言模型（LLMs）的能力，通过合成人类见解与计算能力，构建了一个广泛的情感支持对话数据集。最终提出了一种名为ExTES的可扩展情感支持对话数据集，并部署了高级调优技术，以解决情感支持聊天机器人在实际应用中遇到的挑战。

    

    将情感支持集成到各种对话场景中具有深远的社会效益，如社交互动、心理健康咨询和客户服务。然而，在这一领域存在一些未解决的挑战，包括有限的数据可用性和缺乏被广泛接受的模型训练范例。本研究通过利用大型语言模型（LLMs）的能力，试图解决这些挑战。我们引入一种创新方法，将人类见解与LLMs的计算能力相结合，构建了一个广泛的情感支持对话数据集。我们的方法从精心设计的涵盖多种场景的对话集合作为生成种子开始。通过利用ChatGPT的上下文学习潜力，我们递归地生成了一个可扩展的情感支持对话数据集，命名为ExTES。在此基础上，我们对LLaMA模型进行了高级调优技术的部署，检验了其性能。

    The integration of emotional support into various conversational scenarios presents profound societal benefits, such as social interactions, mental health counseling, and customer service. However, there are unsolved challenges that hinder real-world applications in this field, including limited data availability and the absence of well-accepted model training paradigms. This work endeavors to navigate these challenges by harnessing the capabilities of Large Language Models (LLMs). We introduce an innovative methodology that synthesizes human insights with the computational prowess of LLMs to curate an extensive emotional support dialogue dataset. Our approach is initiated with a meticulously designed set of dialogues spanning diverse scenarios as generative seeds. By utilizing the in-context learning potential of ChatGPT, we recursively generate an ExTensible Emotional Support dialogue dataset, named ExTES. Following this, we deploy advanced tuning techniques on the LLaMA model, exami
    
[^5]: 改变情绪识别建模方式:通用大型模型的出现

    Refashioning Emotion Recognition Modelling: The Advent of Generalised Large Models. (arXiv:2308.11578v1 [cs.CL])

    [http://arxiv.org/abs/2308.11578](http://arxiv.org/abs/2308.11578)

    本论文综合调查了大型语言模型（LLMs）在情绪识别中表现的各个方面，包括上下文学习、少样本学习和准确度等。LLMs的出现为情绪识别建模带来了新的潜力和机会。

    

    在情绪识别或情感计算的诞生之后，由于其广泛应用，它已经成为一个越来越活跃的研究课题。在过去的几十年里，情绪识别模型逐渐从统计浅层模型迁移到基于神经网络的深度模型，可以显著提升情绪识别模型的性能，并在不同的基准测试中始终取得最佳结果。因此，近年来，深度模型一直被视为情绪识别的首选。然而，大型语言模型（LLMs）的出现，如ChatGPT，由于它们具备的零/少样本学习、上下文学习、连贯思维等能力，在情绪识别方面引起了巨大的惊讶，而这些能力在以前的深度模型中从未出现。在本文中，我们全面调查了LLMs在情绪识别方面的表现，包括上下文学习、少样本学习、准确度等各方面。

    After the inception of emotion recognition or affective computing, it has increasingly become an active research topic due to its broad applications. Over the past couple of decades, emotion recognition models have gradually migrated from statistically shallow models to neural network-based deep models, which can significantly boost the performance of emotion recognition models and consistently achieve the best results on different benchmarks. Therefore, in recent years, deep models have always been considered the first option for emotion recognition. However, the debut of large language models (LLMs), such as ChatGPT, has remarkably astonished the world due to their emerged capabilities of zero/few-shot learning, in-context learning, chain-of-thought, and others that are never shown in previous deep models. In the present paper, we comprehensively investigate how the LLMs perform in emotion recognition in terms of diverse aspects, including in-context learning, few-short learning, acc
    
[^6]: 作为用户模拟器的大型语言模型

    Large Language Model as a User Simulator. (arXiv:2308.11534v1 [cs.CL])

    [http://arxiv.org/abs/2308.11534](http://arxiv.org/abs/2308.11534)

    本文创新性地将从真实人机对话中提取的人类问题作为学习目标，并且训练了一个用户模拟器UserGPT，并使用生成的高质量合成对话数据集RealChat来训练助手模型ReaLM。实验证明，ReaLM在多个基准测试中超过了基准模型。

    

    闭源ChatGPT的卓越性能引发了对其民主化的努力，借助真实用户和ChatGPT对话的努力取得了显著进展，Vicuna是一个很好的例子。然而，目前的Baize和UltraChat等努力主要依靠ChatGPT根据指令模拟人类行为，而不是真实的人类学习，导致范围有限，多样性减弱，缺乏真正的多轮对话动态。为了解决上述问题，我们创新性地把从真实人机对话中提取的人类问题作为学习目标，并训练一个用户模拟器UserGPT来生成高质量的以人为中心的合成对话数据集RealChat。随后，该数据集训练我们的助手模型ReaLM。实验证明，ReaLM在Vicuna-Bench和MT-Bench中均超过了基准模型。

    The unparalleled performance of closed-sourced ChatGPT has sparked efforts towards its democratization, with notable strides made by leveraging real user and ChatGPT conversations, as evidenced by Vicuna. However, while current endeavors like Baize and UltraChat aim to auto-generate conversational data due to challenges in gathering human participation, they primarily rely on ChatGPT to simulate human behaviors based on directives rather than genuine human learning. This results in a limited scope, diminished diversity, and an absence of genuine multi-round conversational dynamics. To address the above issues, we innovatively target human questions extracted from genuine human-machine conversations as a learning goal and train a user simulator, UserGPT, to produce a high-quality human-centric synthetic conversation dataset, RealChat. Subsequently, this dataset trains our assistant model, ReaLM. Experimentally, ReaLM outpaces baseline models in both Vicuna-Bench and MT-Bench by pairwise
    
[^7]: 增强声音事件检测的语言模型能力

    Furnishing Sound Event Detection with Language Model Abilities. (arXiv:2308.11530v1 [cs.SD])

    [http://arxiv.org/abs/2308.11530](http://arxiv.org/abs/2308.11530)

    本文提出了一种增强声音事件检测的方法，通过对齐音频特征和文本特征来实现声音事件分类和时间定位。该方法利用语言模型的语义能力直接生成序列，相比传统方法更简洁全面，并通过实验证明了其在时间戳捕获和事件分类方面的有效性。

    

    最近，语言模型（LMs）在视觉跨模态中的能力引起了越来越多的关注。在本文中，我们进一步探索了LMs在声音事件检测（SED）中的生成能力，超越了视觉领域。具体而言，我们提出了一种优雅的方法，通过对齐音频特征和文本特征来完成声音事件分类和时间定位。该框架由一个声学编码器、一个对应的文本和音频表示对齐的对比模块，以及一个解耦的语言解码器组成，用于从音频特征中生成时间和事件序列。与需要复杂处理并几乎不使用有限音频特征的传统方法相比，我们的模型更简洁全面，因为语言模型直接利用其语义能力生成序列。我们研究了不同的解耦模块，以展示其对时间戳捕捉和事件分类的有效性。

    Recently, the ability of language models (LMs) has attracted increasing attention in visual cross-modality. In this paper, we further explore the generation capacity of LMs for sound event detection (SED), beyond the visual domain. Specifically, we propose an elegant method that aligns audio features and text features to accomplish sound event classification and temporal location. The framework consists of an acoustic encoder, a contrastive module that align the corresponding representations of the text and audio, and a decoupled language decoder that generates temporal and event sequences from the audio characteristic. Compared with conventional works that require complicated processing and barely utilize limited audio features, our model is more concise and comprehensive since language model directly leverage its semantic capabilities to generate the sequences. We investigate different decoupling modules to demonstrate the effectiveness for timestamps capture and event classification
    
[^8]: BERT4CTR:一种将预训练语言模型与非文本特征相结合用于点击率预测的高效框架

    BERT4CTR: An Efficient Framework to Combine Pre-trained Language Model with Non-textual Features for CTR Prediction. (arXiv:2308.11527v1 [cs.CL])

    [http://arxiv.org/abs/2308.11527](http://arxiv.org/abs/2308.11527)

    BERT4CTR是一种高效框架，将预训练语言模型与非文本特征相结合，用于点击率预测。它探索了两种整合多模态输入的方法，并解决了文本和非文本输入之间的交叉信息学习问题。

    

    虽然深度预训练语言模型在许多工业场景中显示出了很好的效益，包括点击率（CTR）预测，但如何将只处理文本信号的预训练语言模型与具有非文本特征的预测流程相结合是一个具有挑战性的问题。目前有两个方向来整合多模态输入并进行预训练语言模型的微调。一个方向是通过聚合层将语言模型和非文本特征的结果进行融合，形成集成框架，其中文本和非文本输入之间的交叉信息仅在聚合层中学习。另一个方向是将非文本特征分割成细粒度片段，并将这些片段转换为与文本片段相结合的新标记，以便可以直接输入到语言模型的Transformer层中。然而，这种方法增加了学习和推断的复杂性。

    Although deep pre-trained language models have shown promising benefit in a large set of industrial scenarios, including Click-Through-Rate (CTR) prediction, how to integrate pre-trained language models that handle only textual signals into a prediction pipeline with non-textual features is challenging.  Up to now two directions have been explored to integrate multi-modal inputs in fine-tuning of pre-trained language models. One consists of fusing the outcome of language models and non-textual features through an aggregation layer, resulting into ensemble framework, where the cross-information between textual and non-textual inputs are only learned in the aggregation layer. The second one consists of splitting non-textual features into fine-grained fragments and transforming the fragments to new tokens combined with textual ones, so that they can be fed directly to transformer layers in language models. However, this approach increases the complexity of the learning and inference becau
    
[^9]: 在AIOps上学习日志表示

    Learning Representations on Logs for AIOps. (arXiv:2308.11526v1 [cs.CL])

    [http://arxiv.org/abs/2308.11526](http://arxiv.org/abs/2308.11526)

    这篇论文介绍了一种针对AIOps的学习表示方法，通过训练大型语言模型（LLM）在公共和专有数据上，能够有效应对有限标记数据的日志分析任务。

    

    AI for IT Operations (AIOps)是一种功能强大的平台，Site Reliability Engineers (SREs)可以使用它来在最小的人工干预下自动化和优化操作工作流程。自动化日志分析是AIOps中的重要任务，因为它为SREs提供了关键洞察力，使其能够识别和解决持续的故障。日志格式检测、日志分类和日志解析等任务是自动化日志分析的关键组件。大部分这些任务需要有监督学习；然而，由于有限的带标签日志数据和日志数据的多样性，存在多个挑战。大型语言模型（LLMs）如BERT和GPT3使用自我监督训练了大量未标记数据。这些模型提供了广义表示，可以有效地用于利用有限标记数据的各种下游任务。在科学和生物学等特定领域的LLMs的成功的基础上，本文介绍了一种针对日志数据的LLM，它是在公共和专有数据上进行训练的。

    AI for IT Operations (AIOps) is a powerful platform that Site Reliability Engineers (SREs) use to automate and streamline operational workflows with minimal human intervention. Automated log analysis is a critical task in AIOps as it provides key insights for SREs to identify and address ongoing faults. Tasks such as log format detection, log classification, and log parsing are key components of automated log analysis. Most of these tasks require supervised learning; however, there are multiple challenges due to limited labelled log data and the diverse nature of log data. Large Language Models (LLMs) such as BERT and GPT3 are trained using self-supervision on a vast amount of unlabeled data. These models provide generalized representations that can be effectively used for various downstream tasks with limited labelled data. Motivated by the success of LLMs in specific domains like science and biology, this paper introduces a LLM for log data which is trained on public and proprietary 
    
[^10]: 自我欺骗：逆向破解大型语言模型的语义防火墙

    Self-Deception: Reverse Penetrating the Semantic Firewall of Large Language Models. (arXiv:2308.11521v1 [cs.CL])

    [http://arxiv.org/abs/2308.11521](http://arxiv.org/abs/2308.11521)

    这篇论文研究了大型语言模型的越狱问题，并提出了一种自动越狱方法，介绍了语义防火墙的概念和三种技术实现方法。

    

    大型语言模型（LLM），如ChatGPT，具有接近人工通用智能的惊人能力。虽然为各种社会需求提供了便利，但LLM也降低了生成有害内容的成本。因此，LLM开发人员已经部署了语义级的防御机制，用于识别和拒绝可能导致不适当内容的提示。不幸的是，这些防御机制并不完全可靠，一些攻击者已经设计出了“越狱”提示，临时使LLM忘记内容防御规则并回答任何不适当的问题。迄今为止，业界和学术界尚无关于这些语义级攻击和防御原则的明确解释。本文研究了LLM越狱问题，并首次提出了一种自动越狱方法。我们提出了语义防火墙的概念，并提供了三种技术实现方法。

    Large language models (LLMs), such as ChatGPT, have emerged with astonishing capabilities approaching artificial general intelligence. While providing convenience for various societal needs, LLMs have also lowered the cost of generating harmful content. Consequently, LLM developers have deployed semantic-level defenses to recognize and reject prompts that may lead to inappropriate content. Unfortunately, these defenses are not foolproof, and some attackers have crafted "jailbreak" prompts that temporarily hypnotize the LLM into forgetting content defense rules and answering any improper questions. To date, there is no clear explanation of the principles behind these semantic-level attacks and defenses in both industry and academia.  This paper investigates the LLM jailbreak problem and proposes an automatic jailbreak method for the first time. We propose the concept of a semantic firewall and provide three technical implementation approaches. Inspired by the attack that penetrates trad
    
[^11]: 探索主题建模技术在分析客户评论中的应用：一项比较分析

    Exploring the Power of Topic Modeling Techniques in Analyzing Customer Reviews: A Comparative Analysis. (arXiv:2308.11520v1 [cs.CL])

    [http://arxiv.org/abs/2308.11520](http://arxiv.org/abs/2308.11520)

    本研究对常用主题建模方法进行了综合研究和比较，特别应用于客户评论。我们展示了这些方法在检测重要主题方面的优势，并旨在突出它们的有效性。

    

    在线社交网络平台和应用的指数级增长导致了用户生成的文本内容（包括评论和评价）数量的激增。因此，用户通常在从这些内容中提取有价值的见解或相关信息时面临困难。为了解决这一挑战，机器学习和自然语言处理算法已被用于分析在线可获得的大量文本数据。近年来，主题建模技术在这个领域中取得了显著的流行度。在本研究中，我们全面地研究并比较了五种经常使用的主题建模方法，特别是应用于客户评论的方法。所研究的方法包括潜在语义分析（LSA）、潜在狄利克雷分配（LDA）、非负矩阵分解（NMF）、彩球推理模型（PAM）、Top2Vec和BERTopic。通过实际展示它们在检测重要主题方面的优势，我们旨在突出它们的有效性。

    The exponential growth of online social network platforms and applications has led to a staggering volume of user-generated textual content, including comments and reviews. Consequently, users often face difficulties in extracting valuable insights or relevant information from such content. To address this challenge, machine learning and natural language processing algorithms have been deployed to analyze the vast amount of textual data available online. In recent years, topic modeling techniques have gained significant popularity in this domain. In this study, we comprehensively examine and compare five frequently used topic modeling methods specifically applied to customer reviews. The methods under investigation are latent semantic analysis (LSA), latent Dirichlet allocation (LDA), non-negative matrix factorization (NMF), pachinko allocation model (PAM), Top2Vec, and BERTopic. By practically demonstrating their benefits in detecting important topics, we aim to highlight their effica
    
[^12]: 优化多类文本分类：利用转换器的多样堆叠集成框架

    Optimizing Multi-Class Text Classification: A Diverse Stacking Ensemble Framework Utilizing Transformers. (arXiv:2308.11519v1 [cs.CL])

    [http://arxiv.org/abs/2308.11519](http://arxiv.org/abs/2308.11519)

    本研究提出了一种利用转换器的多样堆叠集成框架，以优化多类文本分类。通过将多个单一转换器作为基层分类器，并引入基于RoBERTa的元层分类器，实现了最优的预测模型。

    

    客户评论在评估客户满意度、收集反馈和推动业务改进方面起着至关重要的作用。分析这些评论可以为客户情绪提供有价值的见解，包括赞美、评论和建议。文本分类技术使企业能够将客户评论分为不同的类别，为更好地了解客户反馈提供便利。然而，过拟合和偏见等挑战限制了单个分类器在确保最佳预测方面的有效性。本研究提出了一种新的方法来解决这些挑战，通过引入基于转换器模型的堆叠集成多文本分类方法。通过将多个单一转换器（包括BERT、ELECTRA和DistilBERT）作为基层分类器，以及基于RoBERTa的元层分类器，生成一个最优的预测模型。

    Customer reviews play a crucial role in assessing customer satisfaction, gathering feedback, and driving improvements for businesses. Analyzing these reviews provides valuable insights into customer sentiments, including compliments, comments, and suggestions. Text classification techniques enable businesses to categorize customer reviews into distinct categories, facilitating a better understanding of customer feedback. However, challenges such as overfitting and bias limit the effectiveness of a single classifier in ensuring optimal prediction. This study proposes a novel approach to address these challenges by introducing a stacking ensemble-based multi-text classification method that leverages transformer models. By combining multiple single transformers, including BERT, ELECTRA, and DistilBERT, as base-level classifiers, and a meta-level classifier based on RoBERTa, an optimal predictive model is generated. The proposed stacking ensemble-based multi-text classification method aims
    
[^13]: TrackFlow: 带有标准化流的多目标跟踪

    TrackFlow: Multi-Object Tracking with Normalizing Flows. (arXiv:2308.11513v1 [cs.CV])

    [http://arxiv.org/abs/2308.11513](http://arxiv.org/abs/2308.11513)

    本论文提出了一种带有标准化流的多目标跟踪方法，通过融合异构信息，并解决了成本贡献、超参数调整和独立性等问题。

    

    近年来，随着跟踪-检测方法的简洁性和强大先验条件使其摆脱了跟踪-注意力方法的复杂设计和麻烦，多目标跟踪领域对跟踪-检测方法重新产生了兴趣。在这种背景下，我们旨在将跟踪-检测方法扩展到多模态设置，其中需要从异构信息（例如2D运动线索、视觉外观和姿态估计）计算综合成本。具体而言，我们通过一个案例研究来融合具有粗略估计的三维信息和其他传统度量（例如IoU）。为了实现这一目标，最近的方法采用简单规则或复杂启发式方法来平衡每个成本的贡献。然而，它们需要在一个保留集上对定制超参数进行仔细调整，并且暗示这些成本是相互独立的，而这在现实中并不成立。我们通过建立一个优雅的概率模型来解决这些问题。

    The field of multi-object tracking has recently seen a renewed interest in the good old schema of tracking-by-detection, as its simplicity and strong priors spare it from the complex design and painful babysitting of tracking-by-attention approaches. In view of this, we aim at extending tracking-by-detection to multi-modal settings, where a comprehensive cost has to be computed from heterogeneous information e.g., 2D motion cues, visual appearance, and pose estimates. More precisely, we follow a case study where a rough estimate of 3D information is also available and must be merged with other traditional metrics (e.g., the IoU). To achieve that, recent approaches resort to either simple rules or complex heuristics to balance the contribution of each cost. However, i) they require careful tuning of tailored hyperparameters on a hold-out set, and ii) they imply these costs to be independent, which does not hold in reality. We address these issues by building upon an elegant probabilisti
    
[^14]: 大型语言模型对多选题选项顺序的敏感性

    Large Language Models Sensitivity to The Order of Options in Multiple-Choice Questions. (arXiv:2308.11483v1 [cs.CL])

    [http://arxiv.org/abs/2308.11483](http://arxiv.org/abs/2308.11483)

    本文研究了大型语言模型对多选题选项顺序的敏感性。实验证明，当对回答选项进行重新排序时，大型语言模型的性能差距可以达到13%至75%。这种敏感性主要在大型语言模型对前两个/三个选项的预测不确定时出现。

    

    大型语言模型在各种自然语言处理任务中展现了出色的能力。然而，先前的研究表明，这些模型对提示文字的敏感性以及少样本展示的顺序敏感性，给对这些模型的公正评估带来了挑战。随着这些模型变得更加强大，了解和解决这些局限性变得迫切。本文关注在多选题任务中，对大型语言模型对选项顺序的鲁棒性进行研究，这是研究大型语言模型推理和事实检索能力常用的任务。通过对大型语言模型在不同基准测试中在重新排序回答选项时的表现差距的调查，我们证明了在少样本情况下，大型语言模型的性能相差约13%至75%。通过详细分析，我们推测这种敏感性是在大型语言模型在前两个/三个选项之间的预测不确定时产生的。

    Large Language Models (LLMs) have demonstrated remarkable capabilities in various NLP tasks. However, previous works have shown these models are sensitive towards prompt wording, and few-shot demonstrations and their order, posing challenges to fair assessment of these models. As these models become more powerful, it becomes imperative to understand and address these limitations. In this paper, we focus on LLMs robustness on the task of multiple-choice questions -- commonly adopted task to study reasoning and fact-retrieving capability of LLMs. Investigating the sensitivity of LLMs towards the order of options in multiple-choice questions, we demonstrate a considerable performance gap of approximately 13% to 75% in LLMs on different benchmarks, when answer options are reordered, even when using demonstrations in a few-shot setting. Through a detailed analysis, we conjecture that this sensitivity arises when LLMs are uncertain about the prediction between the top-2/3 choices, and specif
    
[^15]: 对广泛的分布外检测的期望：期望之外的未知数据

    Expecting The Unexpected: Towards Broad Out-Of-Distribution Detection. (arXiv:2308.11480v1 [cs.LG])

    [http://arxiv.org/abs/2308.11480](http://arxiv.org/abs/2308.11480)

    这项研究对机器学习中分布外检测方法进行了评估，发现现有方法在检测未知类别方面表现出色，但在遇到其他类型的分布变化时性能不稳定。

    

    提高部署的机器学习系统的可靠性通常涉及开发方法来检测分布外（OOD）的输入。然而，现有研究常常狭窄地关注训练集中缺失的类别样本，忽略了其他类型的可能分布变化。这种限制降低了这些方法在现实场景中的适用性，因为系统会遇到各种各样的异常输入。在本研究中，我们将五种不同类型的分布变化进行分类，并对最近的OOD检测方法在每一种分布变化上进行了关键评估。我们以BROAD（Benchmarking Resilience Over Anomaly Diversity）的名义公开发布我们的基准。我们的研究发现这些方法在检测未知类别方面表现出色，但在遇到其他类型的分布变化时性能不一致。换句话说，它们只能可靠地检测到它们特别设计来预期的意外输入。

    Improving the reliability of deployed machine learning systems often involves developing methods to detect out-of-distribution (OOD) inputs. However, existing research often narrowly focuses on samples from classes that are absent from the training set, neglecting other types of plausible distribution shifts. This limitation reduces the applicability of these methods in real-world scenarios, where systems encounter a wide variety of anomalous inputs. In this study, we categorize five distinct types of distribution shifts and critically evaluate the performance of recent OOD detection methods on each of them. We publicly release our benchmark under the name BROAD (Benchmarking Resilience Over Anomaly Diversity). Our findings reveal that while these methods excel in detecting unknown classes, their performance is inconsistent when encountering other types of distribution shifts. In other words, they only reliably detect unexpected inputs that they have been specifically designed to expec
    
[^16]: 重新审视基于列生成的启发式方法用于学习分类树

    Revisiting column-generation-based matheuristic for learning classification trees. (arXiv:2308.11477v1 [cs.LG])

    [http://arxiv.org/abs/2308.11477](http://arxiv.org/abs/2308.11477)

    该论文改进了基于列生成的启发式方法，以提高学习分类树的效果。通过减少子问题数量、使用数据依赖约束作为割平面以及生成违反约束的数据点，该方法提高了可伸缩性并适用于大型数据集。

    

    决策树是机器学习中解决分类问题的高度可解释性模型。传统的机器学习算法训练决策树快速但生成的树在准确性上不够优化。文献中其他离散优化模型解决了最优性问题但只在较小的数据集上表现良好。firat2020column提出了一种基于列生成的启发式方法来学习决策树。该方法提高了可伸缩性，并可以处理大型数据集。在这篇论文中，我们描述了对该列生成方法的改进。首先，我们修改了子问题模型以显著减少多类分类实例中的子问题数量。接下来，我们证明了主问题中的数据依赖约束是蕴含的，并将其用作割平面。此外，我们描述了一个分离模型来生成线性规划松弛解违反其对应的数据点。

    Decision trees are highly interpretable models for solving classification problems in machine learning (ML). The standard ML algorithms for training decision trees are fast but generate suboptimal trees in terms of accuracy. Other discrete optimization models in the literature address the optimality problem but only work well on relatively small datasets. \cite{firat2020column} proposed a column-generation-based heuristic approach for learning decision trees. This approach improves scalability and can work with large datasets. In this paper, we describe improvements to this column generation approach. First, we modify the subproblem model to significantly reduce the number of subproblems in multiclass classification instances. Next, we show that the data-dependent constraints in the master problem are implied, and use them as cutting planes. Furthermore, we describe a separation model to generate data points for which the linear programming relaxation solution violates their correspond
    
[^17]: IT3D: 利用显式视角合成改进的文本到3D生成技术

    IT3D: Improved Text-to-3D Generation with Explicit View Synthesis. (arXiv:2308.11473v1 [cs.CV])

    [http://arxiv.org/abs/2308.11473](http://arxiv.org/abs/2308.11473)

    这项研究提出了一种利用显式视角合成多视角图像来改进文本到3D生成技术的策略，该方法通过结合图像到图像流水线和大型扩散模型生成高质量的图像，并通过鉴别器和扩散生成对抗训练来解决视角一致性和内容变化的挑战。

    

    近期的文本到3D技术的进展主要得益于从强大的大型文本到图像扩散模型（LDM）中提取知识。然而，现有的文本到3D方法常常面临过渡饱和、细节不足和不真实的输出等挑战。本研究提出了一种新的策略，利用显式合成的多视角图像来解决这些问题。我们的方法使用基于粗糙3D模型渲染的图像到图像流水线，借助LDM生成具有姿态和高质量的图像。尽管生成的图像大多数情况下缓解了前述问题，但由于大型扩散模型的生成性质，视角不一致和内容差异显著的挑战仍然存在，这在有效利用这些图像方面带来了巨大困难。为了克服这个障碍，我们提倡结合鉴别器和一种新颖的扩散生成对抗训练策略，来指导训练过程。

    Recent strides in Text-to-3D techniques have been propelled by distilling knowledge from powerful large text-to-image diffusion models (LDMs). Nonetheless, existing Text-to-3D approaches often grapple with challenges such as over-saturation, inadequate detailing, and unrealistic outputs. This study presents a novel strategy that leverages explicitly synthesized multi-view images to address these issues. Our approach involves the utilization of image-to-image pipelines, empowered by LDMs, to generate posed high-quality images based on the renderings of coarse 3D models. Although the generated images mostly alleviate the aforementioned issues, challenges such as view inconsistency and significant content variance persist due to the inherent generative nature of large diffusion models, posing extensive difficulties in leveraging these images effectively. To overcome this hurdle, we advocate integrating a discriminator alongside a novel Diffusion-GAN dual training strategy to guide the tra
    
[^18]: 动态开放词汇增强的智能安全着陆（DOVESEI）

    Dynamic Open Vocabulary Enhanced Safe-landing with Intelligence (DOVESEI). (arXiv:2308.11471v1 [cs.RO])

    [http://arxiv.org/abs/2308.11471](http://arxiv.org/abs/2308.11471)

    本文提出了一种动态开放词汇增强的智能安全着陆系统，通过利用开放词汇图像分割的能力实现无人机的视觉伺服，适应不同场景且无需大量数据积累进行模型改进，可以处理100米高度的操作。

    

    本研究针对城市空中机器人的基础步骤之一，即安全着陆。我们关注安全着陆感知堆栈中最关键的方面之一，即分割。我们提出了一种简化的反应式无人机系统，利用开放词汇图像分割的能力实现视觉伺服。这种方法可以适应各种场景，并通过其开放词汇方法，最小化调整需求，绕过对内部模型进行大量数据积累以进行改进的必要性。考虑到当地当局的限制，我们的主要关注点是从100米高度起飞的操作。这个选择是有意的，因为许多之前的工作处理的高度仅限于30米，与小型立体相机的能力相吻合。因此，我们采用传统的三维路径规划方法来导航剩下的20米。利用单目相机和图像

    This work targets what we consider to be the foundational step for urban airborne robots, a safe landing. Our attention is directed toward what we deem the most crucial aspect of the safe landing perception stack: segmentation. We present a streamlined reactive UAV system that employs visual servoing by harnessing the capabilities of open vocabulary image segmentation. This approach can adapt to various scenarios with minimal adjustments, bypassing the necessity for extensive data accumulation for refining internal models, thanks to its open vocabulary methodology. Given the limitations imposed by local authorities, our primary focus centers on operations originating from altitudes of 100 meters. This choice is deliberate, as numerous preceding works have dealt with altitudes up to 30 meters, aligning with the capabilities of small stereo cameras. Consequently, we leave the remaining 20m to be navigated using conventional 3D path planning methods. Utilizing monocular cameras and image 
    
[^19]: 基于内部跨层梯度的联邦学习中的同质性到异质性的扩展

    Internal Cross-layer Gradients for Extending Homogeneity to Heterogeneity in Federated Learning. (arXiv:2308.11464v1 [cs.LG])

    [http://arxiv.org/abs/2308.11464](http://arxiv.org/abs/2308.11464)

    提出了一种基于内部跨层梯度的联邦学习方法，通过混合浅层和深层的梯度，增强了深层的相似性，从而扩展了在处理系统异质性方面的能力。

    

    联邦学习（FL）在实际场景中不可避免地面临系统异质性的挑战。为了增强大多数模型同质性FL方法处理系统异质性的能力，我们提出了一种训练方案，可以扩展它们应对这一挑战的能力。我们在本文中从详细探索同质性和异质性FL设置开始，发现了三个关键观察结果：（1）客户端性能与层之间的相似性呈正相关，（2）浅层比深层具有更高的相似性，（3）较为平滑的梯度分布指示了更高的层相似性。基于这些观察结果，我们提出了InCo Aggregation方法，利用内部跨层梯度，即服务器模型中来自浅层和深层的梯度混合，以增强深层的相似性，而无需额外的客户端通信。

    Federated learning (FL) inevitably confronts the challenge of system heterogeneity in practical scenarios. To enhance the capabilities of most model-homogeneous FL methods in handling system heterogeneity, we propose a training scheme that can extend their capabilities to cope with this challenge. In this paper, we commence our study with a detailed exploration of homogeneous and heterogeneous FL settings and discover three key observations: (1) a positive correlation between client performance and layer similarities, (2) higher similarities in the shallow layers in contrast to the deep layers, and (3) the smoother gradients distributions indicate the higher layer similarities. Building upon these observations, we propose InCo Aggregation that leverags internal cross-layer gradients, a mixture of gradients from shallow and deep layers within a server model, to augment the similarity in the deep layers without requiring additional communication between clients. Furthermore, our methods 
    
[^20]: LegalBench：一个用于衡量大型语言模型的法律推理的协同构建基准库

    LegalBench: A Collaboratively Built Benchmark for Measuring Legal Reasoning in Large Language Models. (arXiv:2308.11462v1 [cs.CL])

    [http://arxiv.org/abs/2308.11462](http://arxiv.org/abs/2308.11462)

    LegalBench是一个协同构建的法律推理基准库，涵盖了162个任务，可用于衡量大型语言模型在法律推理方面的能力，为律师和LLM开发者提供了共同的词汇表。

    

    大型语言模型（LLMs）的出现和法律界对其的采用引发了一个问题：LLMs能够执行哪些类型的法律推理？为了更深入地研究这个问题，我们提出了LegalBench：一个协同构建的法律推理基准库，包含162个任务，涵盖了六种不同类型的法律推理。LegalBench是通过跨学科的过程构建的，我们收集了由法律专业人员设计和手工制作的任务。因为这些专业人员在构建过程中起了主导作用，所以任务要么衡量了实际有用的法律推理能力，要么衡量了律师们感兴趣的推理技能。为了促进跨学科关于法律界LLMs的对话，我们还展示了流行的法律框架如何描述法律推理，这些框架区分了许多形式，与LegalBench的任务对应起来，从而给律师和LLM开发者提供了共同的词汇表。

    The advent of large language models (LLMs) and their adoption by the legal community has given rise to the question: what types of legal reasoning can LLMs perform? To enable greater study of this question, we present LegalBench: a collaboratively constructed legal reasoning benchmark consisting of 162 tasks covering six different types of legal reasoning. LegalBench was built through an interdisciplinary process, in which we collected tasks designed and hand-crafted by legal professionals. Because these subject matter experts took a leading role in construction, tasks either measure legal reasoning capabilities that are practically useful, or measure reasoning skills that lawyers find interesting. To enable cross-disciplinary conversations about LLMs in the law, we additionally show how popular legal frameworks for describing legal reasoning -- which distinguish between its many forms -- correspond to LegalBench tasks, thus giving lawyers and LLM developers a common vocabulary. This p
    
[^21]: 《自监督表示学习综述》

    A Survey on Self-Supervised Representation Learning. (arXiv:2308.11455v1 [cs.LG])

    [http://arxiv.org/abs/2308.11455](http://arxiv.org/abs/2308.11455)

    本综述论文全面回顾了无监督学习图像表示的方法，提出了一种分类法，并总结了最新的实验结果，为深入研究表示学习领域的人员提供了一个起点。

    

    在现代机器学习领域中，学习有意义的表示是许多任务的核心。最近引入了许多允许无监督学习图像表示的方法。这些表示可以应用于分类或物体检测等下游任务中。这些表示的质量接近于有监督学习，而不需要标记的图像。本综述论文以统一的符号表示对这些方法进行了全面的回顾，指出了这些方法的相似性和差异，并提出了一种分类法，将这些方法联系起来。此外，我们的综述通过元分析总结了文献中最新的实验结果。我们的综述旨在为希望深入研究表示学习领域的研究人员和实践者提供一个起点。

    Learning meaningful representations is at the heart of many tasks in the field of modern machine learning. Recently, a lot of methods were introduced that allow learning of image representations without supervision. These representations can then be used in downstream tasks like classification or object detection. The quality of these representations is close to supervised learning, while no labeled images are needed. This survey paper provides a comprehensive review of these methods in a unified notation, points out similarities and differences of these methods, and proposes a taxonomy which sets these methods in relation to each other. Furthermore, our survey summarizes the most-recent experimental results reported in the literature in form of a meta-study. Our survey is intended as a starting point for researchers and practitioners who want to dive into the field of representation learning.
    
[^22]: 一致性模型的收敛保证

    Convergence guarantee for consistency models. (arXiv:2308.11449v1 [math.NA])

    [http://arxiv.org/abs/2308.11449](http://arxiv.org/abs/2308.11449)

    本文提供了一致性模型（CMs）的收敛保证，该模型可以在一步内从任何真实数据分布中有效地进行采样，且具有较小的$W_2$误差。这一结果对于$L^2$精确的分数和一致性假设成立，并且不需要强假设，同时在所有参数上呈多项式尺度增长，与基于分数的生成模型（SGMs）的最新收敛保证相匹配。另外，本文还提供了多步一致性采样过程可以进一步减小误差的结果。

    

    我们首次为一致性模型（CMs）提供了收敛保证，它是一种新兴的一步生成模型，能够生成与扩散模型生成的样本相媲美的样本。我们的主要结果是，在基本的分数匹配误差、一致性误差和数据分布的平滑性的假设下，CMs能够以小的$W_2$误差在一步内有效地从任何真实数据分布中进行采样。我们的结果：（1）适用于$L^2$精确的分数和一致性假设（而非$L^\infty$精确）；（2）不需要对数据分布做出如log-Sobelev不等式的强假设；（3）所有参数的尺度多项式地增长；（4）与基于分数的生成模型（SGMs）的最新收敛保证相匹配。我们还提供了多步一致性采样过程可以进一步减小误差的结果，支撑了原始论述中的"一致性模型"，杨松

    We provide the first convergence guarantees for the Consistency Models (CMs), a newly emerging type of one-step generative models that can generate comparable samples to those generated by Diffusion Models. Our main result is that, under the basic assumptions on score-matching errors, consistency errors and smoothness of the data distribution, CMs can efficiently sample from any realistic data distribution in one step with small $W_2$ error. Our results (1) hold for $L^2$-accurate score and consistency assumption (rather than $L^\infty$-accurate); (2) do note require strong assumptions on the data distribution such as log-Sobelev inequality; (3) scale polynomially in all parameters; and (4) match the state-of-the-art convergence guarantee for score-based generative models (SGMs). We also provide the result that the Multistep Consistency Sampling procedure can further reduce the error comparing to one step sampling, which support the original statement of "Consistency Models, Yang Song 
    
[^23]: 探索拉舒蒙集合有助于医疗数据的解释

    Exploration of Rashomon Set Assists Explanations for Medical Data. (arXiv:2308.11446v1 [cs.LG])

    [http://arxiv.org/abs/2308.11446](http://arxiv.org/abs/2308.11446)

    本文提出了一种新的过程来探索和分析医疗数据中的拉舒蒙集合模型，从而超越传统单一模型选择的方法，并通过引入"拉舒蒙检测"算法识别出集合中最不同的模型。

    

    机器学习建模过程通常以选择最大化某个性能指标的单一模型作为最终结果。然而，这种方法会导致对稍微差一些的模型进行更深入的分析被忽视。尤其在医疗和健康研究中，目标不仅仅是预测，还包括产生有价值的洞察，仅仅依赖性能指标可能会导致误导或不完整的结论。当处理一组性能接近最优的模型集合时，即所谓的"拉舒蒙集合"，这个问题尤为突出。这样的集合可能包含描述数据的不同方式的模型，需要进行全面的分析。本文引入了一种新的过程来探索拉舒蒙集合模型，扩展了传统建模方法。核心是通过引入的"拉舒蒙检测"算法来识别拉舒蒙集合中最不同的模型。

    The machine learning modeling process conventionally culminates in selecting a single model that maximizes a selected performance metric. However, this approach leads to abandoning a more profound analysis of slightly inferior models. Particularly in medical and healthcare studies, where the objective extends beyond predictions to valuable insight generation, relying solely on performance metrics can result in misleading or incomplete conclusions. This problem is particularly pertinent when dealing with a set of models with performance close to maximum one, known as $\textit{Rashomon set}$. Such a set can be numerous and may contain models describing the data in a different way, which calls for comprehensive analysis. This paper introduces a novel process to explore Rashomon set models, extending the conventional modeling approach. The cornerstone is the identification of the most different models within the Rashomon set, facilitated by the introduced $\texttt{Rashomon_DETECT}$ algorit
    
[^24]: 基于大型语言模型的自主代理的调查

    A Survey on Large Language Model based Autonomous Agents. (arXiv:2308.11432v1 [cs.AI])

    [http://arxiv.org/abs/2308.11432](http://arxiv.org/abs/2308.11432)

    该论文综述了基于大型语言模型的自主代理的研究，提供了从整体角度对该领域的系统审查，其创新之处在于利用大量网络知识实现人类水平的智能决策。

    

    自主代理长期以来一直是学术界的研究热点。以往的研究往往集中在对有限知识的代理进行训练，而这与人类的学习过程存在明显差异，因此很难实现人类般的决策。近年来，通过获取大量的网络知识，大型语言模型（LLM）展现出了实现人类水平智能的显著潜力。这引发了对基于LLM的自主代理的研究的高涨兴趣。为了发挥LLM的全部潜力，研究人员设计了各种不同应用的代理体系结构。本论文综述了这些研究，从整体的角度对自主代理领域进行了系统的审查。具体而言，我们的重点是基于LLM的代理构建，为此我们提出了一个统一的框架。

    Autonomous agents have long been a prominent research topic in the academic community. Previous research in this field often focuses on training agents with limited knowledge within isolated environments, which diverges significantly from the human learning processes, and thus makes the agents hard to achieve human-like decisions. Recently, through the acquisition of vast amounts of web knowledge, large language models (LLMs) have demonstrated remarkable potential in achieving human-level intelligence. This has sparked an upsurge in studies investigating autonomous agents based on LLMs. To harness the full potential of LLMs, researchers have devised diverse agent architectures tailored to different applications. In this paper, we present a comprehensive survey of these studies, delivering a systematic review of the field of autonomous agents from a holistic perspective. More specifically, our focus lies in the construction of LLM-based agents, for which we propose a unified framework t
    
[^25]: AIxArtist: 与人工智能互动以摆脱创造性阻碍的第一人称故事

    AIxArtist: A First-Person Tale of Interacting with Artificial Intelligence to Escape Creative Block. (arXiv:2308.11424v1 [cs.HC])

    [http://arxiv.org/abs/2308.11424](http://arxiv.org/abs/2308.11424)

    这篇论文分享了一个HCI研究员与AI互动的第一人称故事，研究旨在尝试摆脱创造性阻碍。通过探索AI如何支持艺术家的创造力以及可解释性的含义，此研究为XAIxArts社区提供了进一步讨论和探索的思考。

    

    随着技术的进步，艺术和人工智能（AI）的未来充满希望。随着AI在设计中的应用日益普及，艺术实践可能不再只是人类的艺术形式，而可能成为一种数字化整合的体验。通过增强创造力和合作，艺术和AI可以共同努力创造出视觉上吸引人并满足艺术家和观众需求的艺术作品。虽然人们不确定整合将会达到何种程度，但艺术和AI很可能会相互影响。本研讨会图文并茂地提出了一项第一人称研究，分享了一个人机交互研究员与AI互动的经历，试图摆脱创造性阻碍。这篇图文论文探讨了两个问题：AI如何支持艺术家的创造力，以及这种情境下的可解释性意味着什么？研究员与ChatGPT和Midjourney进行了互动，结果产生了一系列需要在XAIxArts社区进一步讨论和探索的思考。

    The future of the arts and artificial intelligence (AI) is promising as technology advances. As the use of AI in design becomes more widespread, art practice may not be a human-only art form and could instead become a digitally integrated experience. With enhanced creativity and collaboration, arts and AI could work together towards creating artistic outputs that are visually appealing and meet the needs of the artist and viewer. While it is uncertain how far the integration will go, arts and AI will likely influence one another. This workshop pictorial puts forward first-person research that shares interactions between an HCI researcher and AI as they try to escape the creative block. The pictorial paper explores two questions: How can AI support artists' creativity, and what does it mean to be explainable in this context? HIs, ChatGPT and Midjourney were engaged; the result was a series of reflections that require further discussion and explorations in the XAIxArts community: Transpa
    
[^26]: TurboViT: 通过生成式架构搜索生成快速视觉变压器

    TurboViT: Generating Fast Vision Transformers via Generative Architecture Search. (arXiv:2308.11421v1 [cs.CV])

    [http://arxiv.org/abs/2308.11421](http://arxiv.org/abs/2308.11421)

    TurboViT是通过生成式架构搜索生成的快速视觉变压器架构设计，它在准确性和计算效率之间取得了良好的平衡。

    

    近年来，视觉变压器在处理各种视觉感知任务方面展示出了前所未有的性能水平。然而，这种网络架构的结构和计算复杂性使得它们在具有高吞吐量和低内存要求的实际应用中难以部署。因此，最近在有效视觉变压器架构设计方面进行了重要的研究。在本研究中，我们通过生成式架构搜索（GAS）探索了快速视觉变压器架构设计的生成，以实现在准确性和架构计算效率之间的良好平衡。通过这个生成式架构搜索过程，我们创建了 TurboViT，这是一种基于掩码单元注意力和 Q-pooling 设计模式的高效分层视觉变压器架构设计。该结果表明，TurboViT 架构设计的架构计算复杂性显著降低（>2.47）

    Vision transformers have shown unprecedented levels of performance in tackling various visual perception tasks in recent years. However, the architectural and computational complexity of such network architectures have made them challenging to deploy in real-world applications with high-throughput, low-memory requirements. As such, there has been significant research recently on the design of efficient vision transformer architectures. In this study, we explore the generation of fast vision transformer architecture designs via generative architecture search (GAS) to achieve a strong balance between accuracy and architectural and computational efficiency. Through this generative architecture search process, we create TurboViT, a highly efficient hierarchical vision transformer architecture design that is generated around mask unit attention and Q-pooling design patterns. The resulting TurboViT architecture design achieves significantly lower architectural computational complexity (>2.47
    
[^27]: 张量回归

    Tensor Regression. (arXiv:2308.11419v1 [stat.ML])

    [http://arxiv.org/abs/2308.11419](http://arxiv.org/abs/2308.11419)

    本书系统研究了基于张量的回归模型及其应用，并覆盖了基本知识、核心思想和理论特性。读者可以学习如何使用这些方法解决多路径数据回归任务。

    

    回归分析是数据分析和机器学习领域的重要研究方向，旨在探索变量之间的依赖关系，通常使用向量表示。高维数据在神经影像学、计算机视觉、气候学和社交网络等技术中的出现给传统数据表示方法带来了挑战。作为向量的高维扩展，张量被视为高维数据的自然表示。本书系统地研究和分析了基于张量的回归模型及其在近年来的应用。它对现有的基于张量的回归方法进行了分组和说明，并涵盖了大多数基于张量的回归方法的基本知识、核心思想和理论特性。此外，读者还可以学习如何使用现有的基于张量的回归方法解决具体的多路径数据回归任务，应选择哪些数据集，以及使用哪些软件工具。

    Regression analysis is a key area of interest in the field of data analysis and machine learning which is devoted to exploring the dependencies between variables, often using vectors. The emergence of high dimensional data in technologies such as neuroimaging, computer vision, climatology and social networks, has brought challenges to traditional data representation methods. Tensors, as high dimensional extensions of vectors, are considered as natural representations of high dimensional data. In this book, the authors provide a systematic study and analysis of tensor-based regression models and their applications in recent years. It groups and illustrates the existing tensor-based regression methods and covers the basics, core ideas, and theoretical characteristics of most tensor-based regression methods. In addition, readers can learn how to use existing tensor-based regression methods to solve specific regression tasks with multiway data, what datasets can be selected, and what softw
    
[^28]: 可解释的分布不变公平性度量方法对于连续评分

    Interpretable Distribution-Invariant Fairness Measures for Continuous Scores. (arXiv:2308.11375v1 [stat.ML])

    [http://arxiv.org/abs/2308.11375](http://arxiv.org/abs/2308.11375)

    对于连续评分，我们提出了一种基于Wasserstein距离的分布不变公平性度量方法，能够解释度量结果并适用于比较不同模型、数据集或时间点之间的偏差。

    

    算法公平性度量通常在二元决策的背景下进行讨论。我们将这种方法扩展到连续评分。到目前为止，基于ROC的度量方法主要用于此目的。其他现有方法主要依赖于评分的分布，不适用于排名任务，或者它们的效果大小不可解释。在这里，我们提出了一种基于Wasserstein距离的连续评分的分布不变公平性度量方法，具有合理的解释。我们的度量方法易于计算，并适用于量化和解释群体差异的强度，以及比较不同模型、数据集或时间点之间的偏差。我们建立了现有评分公平性度量方法的不同族之间的联系，并表明所提出的分布不变公平性度量方法表现更好，因为它们更明确，并且可以量化显著的偏差，而ROC-based不能。

    Measures of algorithmic fairness are usually discussed in the context of binary decisions. We extend the approach to continuous scores. So far, ROC-based measures have mainly been suggested for this purpose. Other existing methods depend heavily on the distribution of scores, are unsuitable for ranking tasks, or their effect sizes are not interpretable. Here, we propose a distributionally invariant version of fairness measures for continuous scores with a reasonable interpretation based on the Wasserstein distance. Our measures are easily computable and well suited for quantifying and interpreting the strength of group disparities as well as for comparing biases across different models, datasets, or time points. We derive a link between the different families of existing fairness measures for scores and show that the proposed distributionally invariant fairness measures outperform ROC-based fairness measures because they are more explicit and can quantify significant biases that ROC-ba
    
[^29]: 行动分割需要多少长期时间上下文？

    How Much Temporal Long-Term Context is Needed for Action Segmentation?. (arXiv:2308.11358v1 [cs.CV])

    [http://arxiv.org/abs/2308.11358](http://arxiv.org/abs/2308.11358)

    本文提出了一种基于transformer的模型，利用稀疏注意力捕捉视频的完整上下文，以回答时间行动分割需要多少长期时间上下文。通过与当前最先进的方法进行比较，在三个时间行动分割数据集上取得了良好的性能。

    

    在视频中建模长期上下文对于许多细粒度任务包括时间行动分割至关重要。一个有趣的问题是，为了达到最佳性能，需要多少长期时间上下文仍然是一个未解之谜。虽然transformers可以对视频的长期上下文进行建模，但对于长视频，这在计算上是不可行的。因此，最近关于时间行动分割的研究结合了使用局部时间窗口计算出的自注意力的时间卷积网络。虽然这些方法显示出良好的结果，但它们的性能受到无法捕捉视频的完整上下文的限制。在这项工作中，我们通过引入基于transformer的模型并利用稀疏注意力来捕捉视频的完整上下文，试图回答需要多少长期时间上下文才能进行时间行动分割。我们将我们的模型与目前的三个数据集上的时间行动分割的最新技术水平进行比较，这三个数据集包括50Salads，Brea...

    Modeling long-term context in videos is crucial for many fine-grained tasks including temporal action segmentation. An interesting question that is still open is how much long-term temporal context is needed for optimal performance. While transformers can model the long-term context of a video, this becomes computationally prohibitive for long videos. Recent works on temporal action segmentation thus combine temporal convolutional networks with self-attentions that are computed only for a local temporal window. While these approaches show good results, their performance is limited by their inability to capture the full context of a video. In this work, we try to answer how much long-term temporal context is required for temporal action segmentation by introducing a transformer-based model that leverages sparse attention to capture the full context of a video. We compare our model with the current state of the art on three datasets for temporal action segmentation, namely 50Salads, Brea
    
[^30]: 语义RGB-D图像合成

    Semantic RGB-D Image Synthesis. (arXiv:2308.11356v1 [cs.CV])

    [http://arxiv.org/abs/2308.11356](http://arxiv.org/abs/2308.11356)

    本文提出了语义RGB-D图像合成方法，用于解决RGB-D语义图像分割训练集缺乏多样性的问题。通过生成逼真的RGB-D图像来实现给定语义标签图的合成。本文的主要创新是提出了一种生成器，可以处理多模态数据，将与模态无关的信息与与模态相关的信息分离开来。

    

    在RGB-D语义图像分割的训练集中收集各种各样的图像并不总是可能的。尤其是当机器人需要在隐私敏感区域如家庭中操作时，收集受限于一小部分地点。因此，标注图像在外观上缺乏多样性，RGB-D语义图像分割的方法往往对训练数据过度拟合。因此本文提出了语义RGB-D图像合成来解决这个问题。这需要为给定的语义标签图合成一个逼真的RGB-D图像。然而，目前的方法是单模态的，不能处理多模态数据。事实上，我们展示了将单模态方法扩展到多模态数据时效果不佳。因此，在本文中，我们提出了一个用于多模态数据的生成器，将语义布局中与模态无关的信息与生成RGB和深度图像所需的与模态相关的信息分离开来。

    Collecting diverse sets of training images for RGB-D semantic image segmentation is not always possible. In particular, when robots need to operate in privacy-sensitive areas like homes, the collection is often limited to a small set of locations. As a consequence, the annotated images lack diversity in appearance and approaches for RGB-D semantic image segmentation tend to overfit the training data. In this paper, we thus introduce semantic RGB-D image synthesis to address this problem. It requires synthesising a realistic-looking RGB-D image for a given semantic label map. Current approaches, however, are uni-modal and cannot cope with multi-modal data. Indeed, we show that extending uni-modal approaches to multi-modal data does not perform well. In this paper, we therefore propose a generator for multi-modal data that separates modal-independent information of the semantic layout from the modal-dependent information that is needed to generate an RGB and a depth image, respectively. 
    
[^31]: ProAgent：利用大型语言模型构建主动合作的人工智能

    ProAgent: Building Proactive Cooperative AI with Large Language Models. (arXiv:2308.11339v1 [cs.AI])

    [http://arxiv.org/abs/2308.11339](http://arxiv.org/abs/2308.11339)

    ProAgent是一个利用大型语言模型构建的主动合作的AI框架，能够预测队友的决策并为自己制定增强计划，具有高度的模块化和可解释性。

    

    在AGI研究中，构建具有自适应行为的人工智能以进行人工智能和人类的合作成为一个关键关注点。目前，开发合作代理人的方法主要依赖于基于学习的方法，其中政策泛化严重依赖于与特定队友的过去互动。这些方法限制了代理人在面对新的队友时重新校准策略的能力。我们提出了ProAgent，这是一个新颖的框架，利用大型语言模型（LLMs）来创建一个具有预测队友未来决策能力和为自身制定增强计划能力的主动代理。ProAgent在合作推理方面表现出色，能够动态调整行为以增强与队友的协作努力。此外，ProAgent框架具有高度的模块化和可解释性，便于无缝集成，以应对各种协调场景。

    Building AIs with adaptive behaviors in human-AI cooperation stands as a pivotal focus in AGI research. Current methods for developing cooperative agents predominantly rely on learning-based methods, where policy generalization heavily hinges on past interactions with specific teammates. These approaches constrain the agent's capacity to recalibrate its strategy when confronted with novel teammates. We propose \textbf{ProAgent}, a novel framework that harnesses large language models (LLMs) to fashion a \textit{pro}active \textit{agent} empowered with the ability to anticipate teammates' forthcoming decisions and formulate enhanced plans for itself. ProAgent excels at cooperative reasoning with the capacity to dynamically adapt its behavior to enhance collaborative efforts with teammates. Moreover, the ProAgent framework exhibits a high degree of modularity and interpretability, facilitating seamless integration to address a wide array of coordination scenarios. Experimental evaluations
    
[^32]: 关于线下强化学习在推荐系统中的机遇和挑战

    On the Opportunities and Challenges of Offline Reinforcement Learning for Recommender Systems. (arXiv:2308.11336v1 [cs.IR])

    [http://arxiv.org/abs/2308.11336](http://arxiv.org/abs/2308.11336)

    研究聚焦于解决强化学习推荐系统的数据效率问题，离线强化学习为从线下数据集中学习并在在线环境应用策略提供了新的解决方案。

    

    强化学习作为一种建模动态用户兴趣的强大工具，近年来在推荐系统中得到了越来越多的研究关注。然而，它存在一个重要缺点：因为其交互性，其数据效率较低。强化学习推荐系统的训练需要昂贵的在线交互来积累足够的轨迹，这对于代理能够学习用户偏好至关重要。这种低效性使得基于强化学习的推荐系统成为一项艰巨的任务，需要探索潜在的解决方案。近期离线强化学习的进展提供了一种新的视角。离线强化学习使得代理能够从离线数据集中获取见解，并在在线环境中部署学习到的策略。鉴于推荐系统拥有广泛的线下数据集，离线强化学习框架与之紧密相符。尽管离线强化学习是一个新兴领域，但在离线强化学习方面的研究成果逐渐增多。

    Reinforcement learning serves as a potent tool for modeling dynamic user interests within recommender systems, garnering increasing research attention of late. However, a significant drawback persists: its poor data efficiency, stemming from its interactive nature. The training of reinforcement learning-based recommender systems demands expensive online interactions to amass adequate trajectories, essential for agents to learn user preferences. This inefficiency renders reinforcement learning-based recommender systems a formidable undertaking, necessitating the exploration of potential solutions. Recent strides in offline reinforcement learning present a new perspective. Offline reinforcement learning empowers agents to glean insights from offline datasets and deploy learned policies in online settings. Given that recommender systems possess extensive offline datasets, the framework of offline reinforcement learning aligns seamlessly. Despite being a burgeoning field, works centered on
    
[^33]: GrowCLIP: 数据感知的自动模型增长方法用于大规模对比语言-图像预训练

    GrowCLIP: Data-aware Automatic Model Growing for Large-scale Contrastive Language-Image Pre-training. (arXiv:2308.11331v1 [cs.CV])

    [http://arxiv.org/abs/2308.11331](http://arxiv.org/abs/2308.11331)

    GrowCLIP是一种数据感知的自动模型增长算法，用于对比语言-图像预训练。它能够根据持续增长的图像-文本数据找到最佳架构，实现高效训练和更好的性能。

    

    跨模态预训练在各种下游任务中展现出令人印象深刻的性能，从互联网收集的大量图像-文本对受益匪浅。在实践中，在线数据不断增长，凸显了预训练模型能够从不断增长的数据中学习的重要性。现有的跨模态预训练工作主要集中在训练具有固定架构的网络上。然而，考虑到实际应用中预训练数据的不断增长的特性，限制模型容量是不切实际的。另一方面，利用当前模型中的知识来获得高效的训练和更好的性能是很重要的。为了解决上述问题，在本文中，我们提出了GrowCLIP，这是一种数据驱动的自动模型增长算法，用于基于连续图像-文本对的对比语言-图像预训练。特别地，我们采用了动态增长空间，并寻找最佳架构。

    Cross-modal pre-training has shown impressive performance on a wide range of downstream tasks, benefiting from massive image-text pairs collected from the Internet. In practice, online data are growing constantly, highlighting the importance of the ability of pre-trained model to learn from data that is continuously growing. Existing works on cross-modal pre-training mainly focus on training a network with fixed architecture. However, it is impractical to limit the model capacity when considering the continuously growing nature of pre-training data in real-world applications. On the other hand, it is important to utilize the knowledge in the current model to obtain efficient training and better performance. To address the above issues, in this paper, we propose GrowCLIP, a data-driven automatic model growing algorithm for contrastive language-image pre-training with continuous image-text pairs as input. Specially, we adopt a dynamic growth space and seek out the optimal architecture at
    
[^34]: 从日常到有意义：AI对工作动态的影响 - 来自ChatGPT和Stack Overflow的证据

    From Mundane to Meaningful: AI's Influence on Work Dynamics -- evidence from ChatGPT and Stack Overflow. (arXiv:2308.11302v1 [econ.GN])

    [http://arxiv.org/abs/2308.11302](http://arxiv.org/abs/2308.11302)

    本研究探讨了ChatGPT对编码问题解决方式的影响，发现它显著减少了问题数量，提高了问题文档质量，以及剩下的问题更加复杂，暗示着AI不仅提升了生产力，还改变了工作方式。

    

    本文阐述了生成式AI如何为巨大的生产力提升提供机会，同时也引发了关于这些新强大技术对我们工作和共享知识方式的影响的问题。具体而言，我们探讨了ChatGPT如何改变了编码的一个基本方面：问题解决。为此，我们利用了ChatGPT在2022年11月30日突然发布对最大的在线编码社区Stack Overflow使用的影响。使用准实验方法（差分准差法），我们发现问题数量显著下降。此外，在ChatGPT发布后，问题的文档更加完善。最后，我们发现剩下的问题更加复杂。这些发现不仅表明了生产力的提升，而且还表明了我们工作方式的根本变化，其中AI解决了常规查询，使人们能够专注于更复杂的任务。

    This paper illustrates how generative AI could give opportunities for big productivity gains but also opens up questions about the impact of these new powerful technologies on the way we work and share knowledge. More specifically, we explore how ChatGPT changed a fundamental aspect of coding: problem-solving. To do so, we exploit the effect of the sudden release of ChatGPT on the 30th of November 2022 on the usage of the largest online community for coders: Stack Overflow. Using quasi-experimental methods (Difference-in-Difference), we find a significant drop in the number of questions. In addition, the questions are better documented after the release of ChatGPT. Finally, we find evidence that the remaining questions are more complex. These findings suggest not only productivity gains but also a fundamental change in the way we work where routine inquiries are solved by AI allowing humans to focus on more complex tasks.
    
[^35]: 提高长径向特征传播中的木材原结预测

    Improving Knot Prediction in Wood Logs with Longitudinal Feature Propagation. (arXiv:2308.11291v1 [cs.CV])

    [http://arxiv.org/abs/2308.11291](http://arxiv.org/abs/2308.11291)

    本文提出了一种通过木材外形预测内部缺陷位置的方法，利用卷积循环神经网络解决二分类分割任务，实现在廉价设备上进行推理，并在冷杉和云杉树种上验证了该方法的有效性。

    

    木材行业中木材原结的质量主要取决于内外缺陷的存在，其中内部节疤是树枝生长的结果。目前，定位内部节疤需要使用昂贵的设备，如X射线扫描仪。本文解决了通过木材外形预测内部缺陷位置的任务。数据集通过利用X射线测量提取轮廓和节疤构建。我们提出了使用卷积循环神经网络解决这个二分类分割任务的方法。一旦神经网络训练完毕，可以使用廉价设备（如激光剖面仪）测量的外形进行推理。我们在冷杉和云杉树种上验证了我们方法的有效性，并对循环的重要性进行了消融实验证明。

    The quality of a wood log in the wood industry depends heavily on the presence of both outer and inner defects, including inner knots that are a result of the growth of tree branches. Today, locating the inner knots require the use of expensive equipment such as X-ray scanners. In this paper, we address the task of predicting the location of inner defects from the outer shape of the logs. The dataset is built by extracting both the contours and the knots with X-ray measurements. We propose to solve this binary segmentation task by leveraging convolutional recurrent neural networks. Once the neural network is trained, inference can be performed from the outer shape measured with cheap devices such as laser profilers. We demonstrate the effectiveness of our approach on fir and spruce tree species and perform ablation on the recurrence to demonstrate its importance.
    
[^36]: 数据为中心的量子系统学习的影子网络

    ShadowNet for Data-Centric Quantum System Learning. (arXiv:2308.11290v1 [quant-ph])

    [http://arxiv.org/abs/2308.11290](http://arxiv.org/abs/2308.11290)

    本研究提出了一个数据为中心的量子系统学习范式，将神经网络和经典阴影相结合，以解决大型量子系统动力学的预测和泛化问题。

    

    由于维度诅咒，理解大型量子系统的动力学变得困难。统计学习通过神经网络协议和经典阴影在这个领域提供了新的可能性，然而这两种方法都存在局限性：前者受到预测不确定性的困扰，后者缺乏泛化能力。在这里，我们提出了一个数据为中心的学习范式，结合了这两种方法的优势，以促进多样化的量子系统学习任务。特别地，我们的范式利用了经典阴影和其他易于获取的量子系统信息来创建训练数据集，然后通过神经网络来学习探索的量子系统学习问题的潜在映射规律。利用神经网络的泛化能力，这个范式可以在离线训练，并且在推理阶段能够优秀地预测之前未见过的系统，即使只有很少的状态副本。此外，它还继承了

    Understanding the dynamics of large quantum systems is hindered by the curse of dimensionality. Statistical learning offers new possibilities in this regime by neural-network protocols and classical shadows, while both methods have limitations: the former is plagued by the predictive uncertainty and the latter lacks the generalization ability. Here we propose a data-centric learning paradigm combining the strength of these two approaches to facilitate diverse quantum system learning (QSL) tasks. Particularly, our paradigm utilizes classical shadows along with other easily obtainable information of quantum systems to create the training dataset, which is then learnt by neural networks to unveil the underlying mapping rule of the explored QSL problem. Capitalizing on the generalization power of neural networks, this paradigm can be trained offline and excel at predicting previously unseen systems at the inference stage, even with few state copies. Besides, it inherits the characteristic 
    
[^37]: 基于CNN的基于注释的三维渲染和映射照片的楔形符号检测

    CNN based Cuneiform Sign Detection Learned from Annotated 3D Renderings and Mapped Photographs with Illumination Augmentation. (arXiv:2308.11277v1 [cs.CV])

    [http://arxiv.org/abs/2308.11277](http://arxiv.org/abs/2308.11277)

    该论文描述了一个基于CNN的楔形符号检测方法，通过学习注释的三维渲染和映射照片，结合光照增强。研究团队创建了HeiCuBeDa和MaiCuBeDa数据集，并提供了映射工具以传递注释。符号定位方法使用RepPoints检测器来预测字符的位置。该方法可以应用于处理楔形文字的数字工具开发和研究。

    

    在Digital Ancient Near Eastern Studies (DANES)社区面临的挑战的推动下，我们开发了用于处理楔形文字的数字工具，这是一种印在粘土板上的三维脚本，已有三千多年历史和至少八种主要语言。它由数千个随时间和空间变化的字符组成。照片是最常用的用于机器学习的表示方式，而墨水绘画则容易被解释。我们创建并使用了HeiCuBeDa和MaiCuBeDa数据集，这些数据集包含约500个带有注释的平板。对于我们的新型类似OCR的混合图像数据方法，我们提供了一种额外的映射工具，用于在3D渲染和照片之间传递注释。我们使用RepPoints检测器来预测字符的位置，以边界框的形式进行符号定位。我们使用来自GigaMesh的MSII（曲率）基于渲染的图像数据，以及Phong着色的3D数据。

    Motivated by the challenges of the Digital Ancient Near Eastern Studies (DANES) community, we develop digital tools for processing cuneiform script being a 3D script imprinted into clay tablets used for more than three millennia and at least eight major languages. It consists of thousands of characters that have changed over time and space. Photographs are the most common representations usable for machine learning, while ink drawings are prone to interpretation. Best suited 3D datasets that are becoming available. We created and used the HeiCuBeDa and MaiCuBeDa datasets, which consist of around 500 annotated tablets. For our novel OCR-like approach to mixed image data, we provide an additional mapping tool for transferring annotations between 3D renderings and photographs. Our sign localization uses a RepPoints detector to predict the locations of characters as bounding boxes. We use image data from GigaMesh's MSII (curvature, see https://gigamesh.eu) based rendering, Phong-shaded 3D 
    
[^38]: 音乐理解LLaMA：应用问答和字幕推进文本到音乐生成

    Music Understanding LLaMA: Advancing Text-to-Music Generation with Question Answering and Captioning. (arXiv:2308.11276v1 [cs.SD])

    [http://arxiv.org/abs/2308.11276](http://arxiv.org/abs/2308.11276)

    本研究提出了一个名为音乐理解LLaMA（MU-LLaMA）的模型，通过应用问答和字幕生成的方法，解决了文本到音乐生成面临的数据稀缺问题。我们设计了一个新的MusicQA数据集，用于训练MU-LLaMA模型，并在音乐问答方面取得了出色的性能。

    

    由于缺乏具有自然语言字幕的大规模公开音乐数据集，文本到音乐生成（T2M-Gen）面临重大障碍。为了解决这个问题，我们提出了音乐理解LLaMA（MU-LLaMA），能够回答与音乐相关的问题并为音乐文件生成字幕。我们的模型利用预训练的MERT模型从音频中提取音乐特征。然而，获取适用于训练MU-LLaMA模型的合适数据集仍然具有挑战性，因为现有的公开可访问的音频问答数据集缺乏开放式音乐问答所需的深度。为了填补这一空白，我们提出了一种从现有音频字幕数据集生成问答对的方法，并介绍了设计用于回答开放式音乐相关问题的MusicQA数据集。实验证明，经过我们设计的MusicQA数据集训练的MU-LLaMA模型在音乐问答方面取得了优秀的性能。

    Text-to-music generation (T2M-Gen) faces a major obstacle due to the scarcity of large-scale publicly available music datasets with natural language captions. To address this, we propose the Music Understanding LLaMA (MU-LLaMA), capable of answering music-related questions and generating captions for music files. Our model utilizes audio representations from a pretrained MERT model to extract music features. However, obtaining a suitable dataset for training the MU-LLaMA model remains challenging, as existing publicly accessible audio question answering datasets lack the necessary depth for open-ended music question answering. To fill this gap, we present a methodology for generating question-answer pairs from existing audio captioning datasets and introduce the MusicQA Dataset designed for answering open-ended music-related questions. The experiments demonstrate that the proposed MU-LLaMA model, trained on our designed MusicQA dataset, achieves outstanding performance in both music qu
    
[^39]: 鲁棒拉格朗日和对抗性策略梯度在鲁棒约束马尔可夫决策过程中的应用

    Robust Lagrangian and Adversarial Policy Gradient for Robust Constrained Markov Decision Processes. (arXiv:2308.11267v1 [cs.LG])

    [http://arxiv.org/abs/2308.11267](http://arxiv.org/abs/2308.11267)

    本文介绍了两种算法，具有鲁棒拉格朗日的RCPG和对抗性RCPG，用于解决鲁棒约束马尔可夫决策过程中的问题。具有鲁棒拉格朗日的RCPG通过使用拉格朗日来计算最坏情况下的动态，而对抗性RCPG通过对抗策略的方式直接和增量学习最坏情况下的动态。

    

    鲁棒约束马尔可夫决策过程（RCMDP）是一个最近应用于强化学习的任务建模框架，它通过使用不确定性集合在转移动态模型中提供了对错误的鲁棒性。模拟RCMDPs需要基于每个状态的值估计计算最坏情况下的动态，这种方法之前在鲁棒约束策略梯度（RCPG）中使用过。本文介绍了两种算法，分别称为具有鲁棒拉格朗日的RCPG和对抗性RCPG。具有鲁棒拉格朗日的RCPG通过使用拉格朗日而不是值或约束来计算最坏情况下的动态从而修改RCPG。对抗性RCPG也基于拉格朗日公式计算最坏情况下的动态，但是将其作为对抗策略直接和增量地学习。

    The robust constrained Markov decision process (RCMDP) is a recent task-modelling framework for reinforcement learning that incorporates behavioural constraints and that provides robustness to errors in the transition dynamics model through the use of an uncertainty set. Simulating RCMDPs requires computing the worst-case dynamics based on value estimates for each state, an approach which has previously been used in the Robust Constrained Policy Gradient (RCPG). Highlighting potential downsides of RCPG such as not robustifying the full constrained objective and the lack of incremental learning, this paper introduces two algorithms, called RCPG with Robust Lagrangian and Adversarial RCPG. RCPG with Robust Lagrangian modifies RCPG by taking the worst-case dynamics based on the Lagrangian rather than either the value or the constraint. Adversarial RCPG also formulates the worst-case dynamics based on the Lagrangian but learns this directly and incrementally as an adversarial policy throug
    
[^40]: 在求解博弈中的高效收敛算法

    Efficient Last-iterate Convergence Algorithms in Solving Games. (arXiv:2308.11256v1 [cs.GT])

    [http://arxiv.org/abs/2308.11256](http://arxiv.org/abs/2308.11256)

    该论文研究了求解博弈中高效收敛算法的问题，通过分析乐观梯度下降上升（OGDA）和乐观乘法权重更新（OMWU）算法，以及基于奖励转化（RT）框架的算法，提出了解决这些问题的方法。

    

    无悔算法在学习两人零和标准型游戏和扩展型游戏的纳什均衡中很受欢迎。最近的许多研究考虑了最后一次迭代收敛的无悔算法。其中，最有名的两个算法是乐观梯度下降上升（OGDA）和乐观乘法权重更新（OMWU）。然而，OGDA的每次迭代复杂度很高。OMWU具有较低的每次迭代复杂度，但实验性能较差，并且它的收敛仅在纳什均衡唯一时成立。最近的研究提出了一种基于奖励转化（RT）框架用于MWU，它消除了唯一性条件，并且在与OMWU相同迭代次数的情况下实现了有竞争力的性能。不幸的是，基于RT的算法在相同迭代次数下表现不如OGDA，并且它们的收敛保证基于连续时间反馈假设，这在大多数情况下不成立。为了解决这些问题，我们对RT框架进行了更详细的分析。

    No-regret algorithms are popular for learning Nash equilibrium (NE) in two-player zero-sum normal-form games (NFGs) and extensive-form games (EFGs). Many recent works consider the last-iterate convergence no-regret algorithms. Among them, the two most famous algorithms are Optimistic Gradient Descent Ascent (OGDA) and Optimistic Multiplicative Weight Update (OMWU). However, OGDA has high per-iteration complexity. OMWU exhibits a lower per-iteration complexity but poorer empirical performance, and its convergence holds only when NE is unique. Recent works propose a Reward Transformation (RT) framework for MWU, which removes the uniqueness condition and achieves competitive performance with OMWU. Unfortunately, RT-based algorithms perform worse than OGDA under the same number of iterations, and their convergence guarantee is based on the continuous-time feedback assumption, which does not hold in most scenarios. To address these issues, we provide a closer analysis of the RT framework, w
    
[^41]: 机器学习研究中偏差的调查

    A survey on bias in machine learning research. (arXiv:2308.11254v1 [cs.LG])

    [http://arxiv.org/abs/2308.11254](http://arxiv.org/abs/2308.11254)

    本文调查了机器学习研究中的偏差问题，提供了偏差和错误的分类，并分析了机器学习流程中超过四十种潜在的偏差来源，为每种情况提供了清晰的示例。通过理解和减轻机器学习中的偏差，可以开发出更公平、更透明、更准确的ML模型。

    

    当前对机器学习中偏差的研究通常关注公平性，却忽视了偏差的根源或原因。然而，偏差最初被定义为“系统性错误”，通常是由研究过程中不同阶段的人类引起的。本文旨在通过提供偏差和数据模型中潜在偏差和错误的分类，弥补过去关于偏差研究的差距。该文重点研究机器学习流程中的偏差。调查分析了机器学习（ML）流程中超过四十种潜在的偏差来源，并为每种情况提供了清晰的示例。通过理解机器学习中偏差的来源和后果，可以开发出更好的方法来检测和减轻偏差，从而实现更公平、更透明、更准确的ML模型。

    Current research on bias in machine learning often focuses on fairness, while overlooking the roots or causes of bias. However, bias was originally defined as a "systematic error," often caused by humans at different stages of the research process. This article aims to bridge the gap between past literature on bias in research by providing taxonomy for potential sources of bias and errors in data and models. The paper focus on bias in machine learning pipelines. Survey analyses over forty potential sources of bias in the machine learning (ML) pipeline, providing clear examples for each. By understanding the sources and consequences of bias in machine learning, better methods can be developed for its detecting and mitigating, leading to fairer, more transparent, and more accurate ML models.
    
[^42]: 多源领域适应用于化学过程交叉领域故障诊断

    Multi-Source Domain Adaptation for Cross-Domain Fault Diagnosis of Chemical Processes. (arXiv:2308.11247v1 [cs.LG])

    [http://arxiv.org/abs/2308.11247](http://arxiv.org/abs/2308.11247)

    本文在化学过程的交叉领域故障诊断中，对单源和多源无监督领域适应算法进行了广泛比较。研究结果表明，即使没有进行适应，使用多个领域进行训练也具有积极影响。

    

    故障诊断是过程监视中的重要组成部分。机器学习的故障诊断系统基于传感器数据预测故障类型。然而，这些模型对数据分布的变化敏感，这些变化可能由于监测过程中的变化，如操作模式的改变，导致跨领域故障诊断的情况。本文在化学工业中广泛使用的田纳西-伊斯曼过程的背景下，提供了单源和多源无监督领域适应算法在交叉领域故障诊断中的广泛比较。研究结果表明，即使没有进行适应，使用多个领域进行训练也具有积极影响。因此，多源无监督领域适应的基准模型相对于单源无监督领域适应的基准模型有所改进。

    Fault diagnosis is an essential component in process supervision. Indeed, it determines which kind of fault has occurred, given that it has been previously detected, allowing for appropriate intervention. Automatic fault diagnosis systems use machine learning for predicting the fault type from sensor readings. Nonetheless, these models are sensible to changes in the data distributions, which may be caused by changes in the monitored process, such as changes in the mode of operation. This scenario is known as Cross-Domain Fault Diagnosis (CDFD). We provide an extensive comparison of single and multi-source unsupervised domain adaptation (SSDA and MSDA respectively) algorithms for CDFD. We study these methods in the context of the Tennessee-Eastmann Process, a widely used benchmark in the chemical industry. We show that using multiple domains during training has a positive effect, even when no adaptation is employed. As such, the MSDA baseline improves over the SSDA baseline classificati
    
[^43]: 在S-Graphs中利用层次性进行快速优化

    Faster Optimization in S-Graphs Exploiting Hierarchy. (arXiv:2308.11242v1 [cs.RO])

    [http://arxiv.org/abs/2308.11242](http://arxiv.org/abs/2308.11242)

    本文提出了一种在S-Graphs中利用层次性进行快速优化的方法，通过边缘化冗余的机器人姿态及其与相同结构实体的观测之间的连接来减小图的大小，并通过生成和优化局部图来实现压缩S-Graphs。

    

    3D场景图以层次方式适当地组织不同的环境实体。我们之前的工作在SLAM中将3D场景图的概念扩展到了情境图，通过紧密地将机器人姿态与场景图实体相结合，实现了最先进的结果。然而，S-Graphs的一个限制是在真正大的环境中的可扩展性，由于随时间增长图的大小增加，计算复杂性增加。为了克服这个限制，在这项工作中，我们介绍了一个改进版本的S-Graphs的初步研究，利用层次性来减小图的大小，通过边缘化冗余的机器人姿态及其与相同结构实体的观测之间的连接。首先，我们提出了在类似房间的结构中包含所有图实体的局部图的生成和优化。这些局部图用于压缩S-Graphs，边缘化冗余的机器人关键帧及其与观测之间的连接。

    3D scene graphs hierarchically represent the environment appropriately organizing different environmental entities in various layers. Our previous work on situational graphs extends the concept of 3D scene graph to SLAM by tightly coupling the robot poses with the scene graph entities, achieving state-of-the-art results. Though, one of the limitations of S-Graphs is scalability in really large environments due to the increased graph size over time, increasing the computational complexity.  To overcome this limitation in this work we present an initial research of an improved version of S-Graphs exploiting the hierarchy to reduce the graph size by marginalizing redundant robot poses and their connections to the observations of the same structural entities. Firstly, we propose the generation and optimization of room-local graphs encompassing all graph entities within a room-like structure. These room-local graphs are used to compress the S-Graphs marginalizing the redundant robot keyfram
    
[^44]: ROSGPT_Vision: 仅使用语言模型提示来控制机器人

    ROSGPT_Vision: Commanding Robots Using Only Language Models' Prompts. (arXiv:2308.11236v1 [cs.RO])

    [http://arxiv.org/abs/2308.11236](http://arxiv.org/abs/2308.11236)

    本文提出了一种新的机器人设计模式，名为Prompting Robotic Modalities（PRM），通过仅使用语言模型的提示来控制机器人。并且在构建了一个名为ROSGPT_Vision的机器人框架上应用了这种设计模式。这个框架能够通过视觉提示和LLM提示执行机器人任务。

    

    本文认为，下一代机器人可以仅通过语言模型的提示来进行命令。每个提示通过其模态语言模型（MLM）单独查询特定的机器人模态。中央任务模态通过大型语言模型（LLM）调节整个通信以执行机器人任务。本文将这种新的机器人设计模式命名为：Prompting Robotic Modalities（PRM）。此外，本文将这个PRM设计模式应用于构建一个名为ROSGPT_Vision的新的机器人框架。ROSGPT_Vision只需要两个提示即可执行机器人任务：一个是视觉提示，一个是LLM提示。视觉提示以自然语言提取与所考虑任务相关的视觉语义特征（视觉机器人模态）。同时，LLM提示调节机器人对视觉描述的反应（任务模态）。该框架自动化了这两个提示背后的所有机制。该框架使机器人能够...

    In this paper, we argue that the next generation of robots can be commanded using only Language Models' prompts. Every prompt interrogates separately a specific Robotic Modality via its Modality Language Model (MLM). A central Task Modality mediates the whole communication to execute the robotic mission via a Large Language Model (LLM). This paper gives this new robotic design pattern the name of: Prompting Robotic Modalities (PRM). Moreover, this paper applies this PRM design pattern in building a new robotic framework named ROSGPT_Vision. ROSGPT_Vision allows the execution of a robotic task using only two prompts: a Visual and an LLM prompt. The Visual Prompt extracts, in natural language, the visual semantic features related to the task under consideration (Visual Robotic Modality). Meanwhile, the LLM Prompt regulates the robotic reaction to the visual description (Task Modality). The framework automates all the mechanisms behind these two prompts. The framework enables the robot to
    
[^45]: 自适应白盒水印在深度神经网络中的应用与自我互助检查参数

    Adaptive White-Box Watermarking with Self-Mutual Check Parameters in Deep Neural Networks. (arXiv:2308.11235v1 [cs.CR])

    [http://arxiv.org/abs/2308.11235](http://arxiv.org/abs/2308.11235)

    本文提出了一种自适应白盒水印技术，通过自我互助检查参数来检测篡改的深度神经网络模型，并且提出了最大化信息容量的自适应嵌入方法。实验证明，当修改率低于20%时，该方法具有出色的恢复性能。

    

    人工智能在各个领域得到了广泛应用，但在部署过程中也面临着意外或恶意篡改的风险。为了检测和防止这些风险，需要进行定期检查。脆弱水印技术可以用来识别人工智能模型中的篡改。然而，之前的方法存在着遗漏的风险、额外信息传输的问题以及无法精确定位篡改的问题。本文提出了一种检测篡改参数和位的方法，该方法可以用来检测、定位和恢复被篡改的参数。我们还提出了一种自适应嵌入方法，该方法在保持模型准确性的同时最大化信息容量。我们的方法在多个经受了修改权重参数攻击的神经网络上进行了测试，结果表明在修改率低于20%时，我们的方法具有出色的恢复性能。此外，对于使用水印的模型，这些水印的存在不会对模型的性能产生显著的影响。

    Artificial Intelligence (AI) has found wide application, but also poses risks due to unintentional or malicious tampering during deployment. Regular checks are therefore necessary to detect and prevent such risks. Fragile watermarking is a technique used to identify tampering in AI models. However, previous methods have faced challenges including risks of omission, additional information transmission, and inability to locate tampering precisely. In this paper, we propose a method for detecting tampered parameters and bits, which can be used to detect, locate, and restore parameters that have been tampered with. We also propose an adaptive embedding method that maximizes information capacity while maintaining model accuracy. Our approach was tested on multiple neural networks subjected to attacks that modified weight parameters, and our results demonstrate that our method achieved great recovery performance when the modification rate was below 20%. Furthermore, for models where watermar
    
[^46]: 交通流量优化的终身多智能体路径规划

    Traffic Flow Optimisation for Lifelong Multi-Agent Path Finding. (arXiv:2308.11234v1 [cs.AI])

    [http://arxiv.org/abs/2308.11234](http://arxiv.org/abs/2308.11234)

    本文提出了一种新的终身多智能体路径规划方法，通过引导智能体避开拥堵路径来优化交通流量，显著提高解决方案质量和总体吞吐量。

    

    多智能体路径规划(MAPF)是机器人领域的一个基本问题，要求为一个团队的智能体计算无碰撞路径，所有智能体都在共享地图上移动。尽管有许多相关研究，但当前的算法在智能体数量增加时都会遇到困难。主要原因是现有方法通常规划自由流动的最优路径，这会导致拥堵。为了解决这个问题，我们提出了一种新的MAPF方法，通过跟随避免拥堵的路径来引导智能体到达目的地。我们在两个大规模场景中评估了这个想法：一次性MAPF，每个智能体只有一个目的地，以及终身MAPF，智能体不断被分配新任务。对于一次性MAPF，我们展示了我们的方法大大提高了解决方案的质量。对于终身MAPF，我们报告了总体吞吐量的大幅提升。

    Multi-Agent Path Finding (MAPF) is a fundamental problem in robotics that asks us to compute collision-free paths for a team of agents, all moving across a shared map. Although many works appear on this topic, all current algorithms struggle as the number of agents grows. The principal reason is that existing approaches typically plan free-flow optimal paths, which creates congestion. To tackle this issue we propose a new approach for MAPF where agents are guided to their destination by following congestion-avoiding paths. We evaluate the idea in two large-scale settings: one-shot MAPF, where each agent has a single destination, and lifelong MAPF, where agents are continuously assigned new tasks. For one-shot MAPF we show that our approach substantially improves solution quality. For Lifelong MAPF we report large improvements in overall throughput.
    
[^47]: 中小型软件编辑公司的本地AIOps基础设施：一份经验报告

    On-Premise AIOps Infrastructure for a Software Editor SME: An Experience Report. (arXiv:2308.11225v1 [cs.SE])

    [http://arxiv.org/abs/2308.11225](http://arxiv.org/abs/2308.11225)

    本文研究了通过利用开源工具实施本地AIOps解决方案的可行性。我们成功部署了一种综合AIOps基础设施，并提供了构建其各个组件的不同选择的理由。

    

    信息技术已成为各行各业的关键组成部分，导致对软件维护和监控的关注增加。随着现代软件系统的复杂性，传统的维护方法已经不足够。AIOps的概念应运而生，通过使用大数据和机器学习能力来增强预测性维护。然而，利用AIOps需要解决与数据和事件管理复杂性相关的几个挑战。商业解决方案存在，但由于高昂的成本、数据治理问题和不覆盖私有软件的限制，它们可能不适合某些公司。本文通过利用开源工具来实施本地AIOps解决方案的可行性进行了研究。我们介绍了我们在公司成功部署的一种综合AIOps基础设施，并提供了构建其各个组件的不同选择的理由。

    Information Technology has become a critical component in various industries, leading to an increased focus on software maintenance and monitoring. With the complexities of modern software systems, traditional maintenance approaches have become insufficient. The concept of AIOps has emerged to enhance predictive maintenance using Big Data and Machine Learning capabilities. However, exploiting AIOps requires addressing several challenges related to the complexity of data and incident management. Commercial solutions exist, but they may not be suitable for certain companies due to high costs, data governance issues, and limitations in covering private software. This paper investigates the feasibility of implementing on-premise AIOps solutions by leveraging open-source tools. We introduce a comprehensive AIOps infrastructure that we have successfully deployed in our company, and we provide the rationale behind different choices that we made to build its various components. Particularly, w
    
[^48]: 在图上评估大型语言模型：性能洞察与比较分析

    Evaluating Large Language Models on Graphs: Performance Insights and Comparative Analysis. (arXiv:2308.11224v1 [cs.AI])

    [http://arxiv.org/abs/2308.11224](http://arxiv.org/abs/2308.11224)

    本研究评估了四个大型语言模型在图数据上解决分析问题的能力，结果显示LLM在理解图数据、生成正确结果和进行结构推理方面表现出色，但在真实性和矫正能力方面存在一些挑战。

    

    大型语言模型(LLM)引起了学术界和工业界的广泛关注，然而LLM在图数据上的应用仍然未被充分探索。在本研究中，我们评估了四个LLM在解决几个图数据分析问题时的能力。我们采用了四个不同的评估指标：理解能力、正确性、真实性和矫正能力。我们的结果表明：1) LLM能够有效地理解自然语言中的图数据，并推理图的拓扑结构。2) GPT模型能够生成逻辑和连贯的结果，在正确性方面优于其他替代方案。3) 所有被检测的LLM在结构推理方面都面临挑战，零样本思维链和少样本提示等技术显示出效果下降。4) GPT模型在多答案任务中经常产生错误答案，引发真实性方面的担忧。5) GPT模型对其输出表现出较高的信心，可能阻碍其矫正能力。值得注意的是，GPT-4显示出了不同水平的性能。

    Large Language Models (LLMs) have garnered considerable interest within both academic and industrial. Yet, the application of LLMs to graph data remains under-explored. In this study, we evaluate the capabilities of four LLMs in addressing several analytical problems with graph data. We employ four distinct evaluation metrics: Comprehension, Correctness, Fidelity, and Rectification. Our results show that: 1) LLMs effectively comprehend graph data in natural language and reason with graph topology. 2) GPT models can generate logical and coherent results, outperforming alternatives in correctness. 3) All examined LLMs face challenges in structural reasoning, with techniques like zero-shot chain-of-thought and few-shot prompting showing diminished efficacy. 4) GPT models often produce erroneous answers in multi-answer tasks, raising concerns in fidelity. 5) GPT models exhibit elevated confidence in their outputs, potentially hindering their rectification capacities. Notably, GPT-4 has dem
    
[^49]: 使用患者数据的联邦学习以保护多囊卵巢综合征的隐私

    Federated Learning on Patient Data for Privacy-Protecting Polycystic Ovary Syndrome Treatment. (arXiv:2308.11220v1 [cs.LG])

    [http://arxiv.org/abs/2308.11220](http://arxiv.org/abs/2308.11220)

    本研究使用联邦学习方法，通过访问大量多样的患者数据并保护隐私，来预测多囊卵巢综合征患者的最佳治疗药物选项。

    

    妇科内分泌学领域在数据驱动的医疗解决方案方面落后，主要是因为对患者数据隐私的担忧。有关荷尔蒙水平或月经周期的有价值的数据点可能会暴露出患有合并症或终止妊娠的患者，侵犯其隐私。我们探讨了在预测多囊卵巢综合征（PCOS）患者的最佳药物方面应用联邦学习（FL）的方法。PCOS是一种影响全球数百万女性的严重激素失调疾病，但其研究受限于患者数据的缺乏。我们展示了各种联邦学习方法在合成的PCOS患者数据集上的成功应用。我们提出的联邦学习模型是一种访问大量多样数据并识别最有效治疗选项的工具，同时提供PCOS患者的隐私保证。

    The field of women's endocrinology has trailed behind data-driven medical solutions, largely due to concerns over the privacy of patient data. Valuable datapoints about hormone levels or menstrual cycling could expose patients who suffer from comorbidities or terminate a pregnancy, violating their privacy. We explore the application of Federated Learning (FL) to predict the optimal drug for patients with polycystic ovary syndrome (PCOS). PCOS is a serious hormonal disorder impacting millions of women worldwide, yet it's poorly understood and its research is stunted by a lack of patient data. We demonstrate that a variety of FL approaches succeed on a synthetic PCOS patient dataset. Our proposed FL models are a tool to access massive quantities of diverse data and identify the most effective treatment option while providing PCOS patients with privacy guarantees.
    
[^50]: 大模型时代中的联邦学习：针对特定领域的多模态大模型

    Federated Learning in Big Model Era: Domain-Specific Multimodal Large Models. (arXiv:2308.11217v1 [cs.LG])

    [http://arxiv.org/abs/2308.11217](http://arxiv.org/abs/2308.11217)

    本论文提出了一种多模态联邦学习框架，利用私有领域数据协同训练大型模型，以实现跨场景的智能服务。在大模型时代，该框架解决了异构数据、模型聚合、性能和成本权衡、数据隐私以及激励机制等方面的挑战。

    

    多模态数据能够全面感知和识别物理世界，已成为通往通用人工智能的重要路径。然而，在公共数据集上训练的多模态大模型在特定工业领域的性能往往不理想。本文提出了一种多模态联邦学习框架，可以使多个企业利用私有领域数据协同训练大型模型，实现跨场景的智能服务。作者深入探讨了大模型时代联邦学习的智能基础和目标的战略转变，以及在异构数据、模型聚合、性能和成本权衡、数据隐私和激励机制方面面临的新挑战。本文详细介绍了领先企业在城市安全运营管理方面贡献多模态数据和专家知识的案例研究，包括分布式部署和高效性能的实现。

    Multimodal data, which can comprehensively perceive and recognize the physical world, has become an essential path towards general artificial intelligence. However, multimodal large models trained on public datasets often underperform in specific industrial domains. This paper proposes a multimodal federated learning framework that enables multiple enterprises to utilize private domain data to collaboratively train large models for vertical domains, achieving intelligent services across scenarios. The authors discuss in-depth the strategic transformation of federated learning in terms of intelligence foundation and objectives in the era of big model, as well as the new challenges faced in heterogeneous data, model aggregation, performance and cost trade-off, data privacy, and incentive mechanism. The paper elaborates a case study of leading enterprises contributing multimodal data and expert knowledge to city safety operation management , including distributed deployment and efficient 
    
[^51]: ConcatPlexer：通过附加Dim1批处理以加快ViTs速度

    ConcatPlexer: Additional Dim1 Batching for Faster ViTs. (arXiv:2308.11199v1 [cs.CV])

    [http://arxiv.org/abs/2308.11199](http://arxiv.org/abs/2308.11199)

    本文提出了一种名为ConcatPlexer的方法，通过在视觉识别中使用附加的Dim1批处理（即连接）来提高吞吐量，同时准确性受到的影响较小。

    

    Transformer不仅在自然语言处理领域，还在计算机视觉领域取得了巨大成功，引发了各种创新的方法和应用。然而，Transformer卓越的性能和建模灵活性带来了计算成本的严重增加，因此有几项工作提出了减少这种负担的方法。受语言模型的一种减少成本的方法Data Multiplexing (DataMUX)的启发，我们提出了一种用于高效视觉识别的新方法，它采用了附加的Dim1批处理（即连接），在保证准确性的基础上大大提高了吞吐量。我们首先为视觉模型引入了DataMux的一种天然适应方法，图像多路复用器（Image Multiplexer），并设计了新的组件来克服其缺点，进而形成了我们最终的模型ConcatPlexer，在推理速度和准确度之间找到了平衡点。ConcatPlexer在ImageNet1K和CIFAR100数据集上进行了训练。

    Transformers have demonstrated tremendous success not only in the natural language processing (NLP) domain but also the field of computer vision, igniting various creative approaches and applications. Yet, the superior performance and modeling flexibility of transformers came with a severe increase in computation costs, and hence several works have proposed methods to reduce this burden. Inspired by a cost-cutting method originally proposed for language models, Data Multiplexing (DataMUX), we propose a novel approach for efficient visual recognition that employs additional dim1 batching (i.e., concatenation) that greatly improves the throughput with little compromise in the accuracy. We first introduce a naive adaptation of DataMux for vision models, Image Multiplexer, and devise novel components to overcome its weaknesses, rendering our final model, ConcatPlexer, at the sweet spot between inference speed and accuracy. The ConcatPlexer was trained on ImageNet1K and CIFAR100 dataset and
    
[^52]: ViLLA:从真实世界数据中进行细粒度的视觉-语言表示学习

    ViLLA: Fine-Grained Vision-Language Representation Learning from Real-World Data. (arXiv:2308.11194v1 [cs.CV])

    [http://arxiv.org/abs/2308.11194](http://arxiv.org/abs/2308.11194)

    本论文通过系统评估表明，当训练集的配对复杂性增加时，标准的视觉-语言模型在学习图像区域与文本属性之间的关系时表现较差，性能下降达到

    

    视觉-语言模型（VLMs），如CLIP和ALIGN，通常是在从网络获取的图像-标题对的数据集上进行训练的。然而，真实世界的多模态数据集，如医疗数据，显著更加复杂：每个图像（如X光）通常与描述图像细粒度区域中发生的许多不同属性的文本（如医生报告）配对。我们将这些样本称为展示高配对复杂性，因为每个图像-文本对可以分解为大量的区域-属性配对。以往尚未评估VLMs在训练这种数据时能否捕捉到图像区域与文本属性之间的细粒度关系。此工作的第一个关键贡献是通过系统评估表明，随着训练数据集的配对复杂性增加，标准的VLMs在学习区域-属性关系方面面临困难，性能下降达到

    Vision-language models (VLMs), such as CLIP and ALIGN, are generally trained on datasets consisting of image-caption pairs obtained from the web. However, real-world multimodal datasets, such as healthcare data, are significantly more complex: each image (e.g. X-ray) is often paired with text (e.g. physician report) that describes many distinct attributes occurring in fine-grained regions of the image. We refer to these samples as exhibiting high pairwise complexity, since each image-text pair can be decomposed into a large number of region-attribute pairings. The extent to which VLMs can capture fine-grained relationships between image regions and textual attributes when trained on such data has not been previously evaluated. The first key contribution of this work is to demonstrate through systematic evaluations that as the pairwise complexity of the training dataset increases, standard VLMs struggle to learn region-attribute relationships, exhibiting performance degradations of up t
    
[^53]: 多样性指标：语言模型查询中失败的领域无关代理

    Diversity Measures: Domain-Independent Proxies for Failure in Language Model Queries. (arXiv:2308.11189v1 [cs.CL])

    [http://arxiv.org/abs/2308.11189](http://arxiv.org/abs/2308.11189)

    本文提出了一种基于回应多样性的大型语言模型错误量化指标，这些指标独立于领域特定信息，并与失败概率强相关。实证结果展示了这些指标在少样本提示、思维链推理和错误检测方面的应用。

    

    大型语言模型中的错误预测通常依赖于领域特定的信息。本文提出了一种基于回应多样性的大型语言模型错误量化指标，因此独立于底层应用。我们描述了如何使用基于熵、基尼不纯度和质心距离的三个指标。我们进行了一系列的实验，涉及多个数据集和温度设置，证明这些指标与失败概率强相关。此外，我们还提出了实证结果，展示了如何将这些指标应用于少样本提示、思维链推理和错误检测。

    Error prediction in large language models often relies on domain-specific information. In this paper, we present measures for quantification of error in the response of a large language model based on the diversity of responses to a given prompt - hence independent of the underlying application. We describe how three such measures - based on entropy, Gini impurity, and centroid distance can be employed. We perform a suite of experiments on multiple datasets and temperature settings to demonstrate that these measures strongly correlate with the probability of failure. Additionally, we present empirical results demonstrating how these measures can be applied to few-shot prompting, chain-of-thought reasoning, and error detection.
    
[^54]: MISSRec: 面向推荐的预训练和转移多模态兴趣感知序列表示

    MISSRec: Pre-training and Transferring Multi-modal Interest-aware Sequence Representation for Recommendation. (arXiv:2308.11175v1 [cs.IR])

    [http://arxiv.org/abs/2308.11175](http://arxiv.org/abs/2308.11175)

    本文提出了一种名为MISSRec的多模态预训练和转移学习框架，通过探索多模态信息的潜力，解决了序列推荐中的稀疏ID和冷启动问题，并提升了推荐模型的可转移性和性能。

    

    序列推荐的目标是基于用户的历史交互序列预测其可能感兴趣的物品。大部分现有的序列推荐器是基于ID特征开发的，然而在使用稀疏ID时往往表现不佳，并且在冷启动问题上遇到困难。此外，不一致的ID映射限制了模型的可转移性，使得相似的推荐领域无法进行共同优化。本文旨在通过探索多模态信息的潜力来解决这些问题，提出了MISSRec，一种面向SR的多模态预训练和转移学习框架。在用户端，我们设计了基于Transformer的编码-解码模型，其中上下文编码器学习捕捉序列级的多模态协同作用，而新颖的兴趣感知解码器则用于把握物品-模态-兴趣关系以获得更好的序列表示。

    The goal of sequential recommendation (SR) is to predict a user's potential interested items based on her/his historical interaction sequences. Most existing sequential recommenders are developed based on ID features, which, despite their widespread use, often underperform with sparse IDs and struggle with the cold-start problem. Besides, inconsistent ID mappings hinder the model's transferability, isolating similar recommendation domains that could have been co-optimized. This paper aims to address these issues by exploring the potential of multi-modal information in learning robust and generalizable sequence representations. We propose MISSRec, a multi-modal pre-training and transfer learning framework for SR. On the user side, we design a Transformer-based encoder-decoder model, where the contextual encoder learns to capture the sequence-level multi-modal synergy while a novel interest-aware decoder is developed to grasp item-modality-interest relations for better sequence represent
    
[^55]: 用于半监督点云语义分割的分层基于点的主动学习

    Hierarchical Point-based Active Learning for Semi-supervised Point Cloud Semantic Segmentation. (arXiv:2308.11166v1 [cs.CV])

    [http://arxiv.org/abs/2308.11166](http://arxiv.org/abs/2308.11166)

    本文提出了一种分层基于点的主动学习策略，通过测量每个点的不确定性来进行标注，解决了现有方法中冗余信息和区域划分的问题。

    

    用大量标注数据进行全监督的方法在点云语义分割方面取得了卓越的性能。然而，获取具有点级标签的大规模点云数据是一项费力的工作，因此许多尝试致力于探索仅使用有限注释进行学习三维点云分割的方法。主动学习是实现这一目标的有效策略之一，但目前仍未得到充分探索。最近的研究方法通过测量每个预分割区域的不确定性来进行手动标注，但这些方法存在冗余信息，并且需要额外的努力进行区域划分。本文旨在通过开发一种分层基于点的主动学习策略来解决这个问题。具体而言，我们通过一种考虑多个层次上的上下文信息的分层最小边缘不确定性模块来测量每个点的不确定性。然后，设计了一种特征距离抑制策略，选择重要的点进行标注。

    Impressive performance on point cloud semantic segmentation has been achieved by fully-supervised methods with large amounts of labelled data. As it is labour-intensive to acquire large-scale point cloud data with point-wise labels, many attempts have been made to explore learning 3D point cloud segmentation with limited annotations. Active learning is one of the effective strategies to achieve this purpose but is still under-explored. The most recent methods of this kind measure the uncertainty of each pre-divided region for manual labelling but they suffer from redundant information and require additional efforts for region division. This paper aims at addressing this issue by developing a hierarchical point-based active learning strategy. Specifically, we measure the uncertainty for each point by a hierarchical minimum margin uncertainty module which considers the contextual information at multiple levels. Then, a feature-distance suppression strategy is designed to select important
    
[^56]: 通过超出平衡状态的扩展动力学性能评估神经力场

    xxMD: Benchmarking Neural Force Fields Using Extended Dynamics beyond Equilibrium. (arXiv:2308.11155v1 [cs.LG])

    [http://arxiv.org/abs/2308.11155](http://arxiv.org/abs/2308.11155)

    在神经力场模型中，常用的MD17数据集对于表示经历化学反应的系统不足。为了解决这一问题，我们引入了xxMD数据集，该数据集采样自扩展激发态分子动力学，包含了能量和力的信息。

    

    神经力场已成为计算化学中的重要模型，取代了从头算的分子动力学中的量子化学计算。目前对神经力场的主要评估基准是MD17数据集及其后续扩展。这些数据集主要包含来自基态势能面平衡区域的几何结构，采样自直接绝热动力学。然而，许多化学反应涉及到较大的分子变形，特别是键断裂。我们展示了MD17数据集中内坐标和能量的约束分布，凸显了其在表示经历化学反应的系统方面的不足。为了解决这种采样限制，我们引入了xxMD（扩展激发态分子动力学）数据集，从非绝热动力学中派生。该数据集包含了从多参考波函数理论和密度泛函中确定的能量和力。

    Neural force fields (NFFs) have gained prominence in computational chemistry as surrogate models, superseding quantum-chemistry calculations in ab initio molecular dynamics. The prevalent benchmark for NFFs has been the MD17 dataset and its subsequent extension. These datasets predominantly comprise geometries from the equilibrium region of the ground electronic state potential energy surface, sampling from direct adiabatic dynamics. However, many chemical reactions entail significant molecular deformations, notably bond breaking. We demonstrate the constrained distribution of internal coordinates and energies in the MD17 datasets, underscoring their inadequacy for representing systems undergoing chemical reactions. Addressing this sampling limitation, we introduce the xxMD (Extended Excited-state Molecular Dynamics) dataset, derived from non-adiabatic dynamics. This dataset encompasses energies and forces ascertained from both multireference wave function theory and density functional
    
[^57]: 无监督细胞识别中的先验自激活图探索

    Exploring Unsupervised Cell Recognition with Prior Self-activation Maps. (arXiv:2308.11144v1 [cs.CV])

    [http://arxiv.org/abs/2308.11144](http://arxiv.org/abs/2308.11144)

    该论文提出了一种无监督细胞识别方法，通过先验自激活图生成伪掩膜作为训练目标。在多个数据集上的实验证明，该方法在细胞分割和多类别细胞检测任务中优于其他监督和弱监督方法。

    

    目前在细胞识别任务上，监督深度学习模型的成功依赖于详细的注释。许多先前的研究已经成功减少了对标签的依赖性。然而，考虑到一个补丁中包含的大量细胞，昂贵而低效的标注仍然不可避免。为此，我们探索了无标签方法来进行细胞识别。我们提出了先验自激活图（PSM）来生成伪掩膜作为训练目标。具体而言，我们使用自监督学习来训练一个激活网络。网络的浅层中的梯度信息被聚合以生成先验自激活图。然后，我们引入了一个语义聚类模块作为管道，将PSMs转换为像素级语义伪掩膜，以供下游任务使用。我们在两个组织学数据集MoNuSeg（细胞分割）和BCData（多类别细胞检测）上评估了我们的方法。与其他全监督和弱监督方法相比，我们的方法表现更好。

    The success of supervised deep learning models on cell recognition tasks relies on detailed annotations. Many previous works have managed to reduce the dependency on labels. However, considering the large number of cells contained in a patch, costly and inefficient labeling is still inevitable. To this end, we explored label-free methods for cell recognition. Prior self-activation maps (PSM) are proposed to generate pseudo masks as training targets. To be specific, an activation network is trained with self-supervised learning. The gradient information in the shallow layers of the network is aggregated to generate prior self-activation maps. Afterward, a semantic clustering module is then introduced as a pipeline to transform PSMs to pixel-level semantic pseudo masks for downstream tasks. We evaluated our method on two histological datasets: MoNuSeg (cell segmentation) and BCData (multi-class cell detection). Compared with other fully-supervised and weakly-supervised methods, our metho
    
[^58]: LLM基于智能体是否存在社会原则？

    Is There Any Social Principle for LLM-Based Agents?. (arXiv:2308.11136v1 [cs.CY])

    [http://arxiv.org/abs/2308.11136](http://arxiv.org/abs/2308.11136)

    LLM基于智能体不仅应关注“以人为中心”的对齐或应用，还应关注智能体自身，并探讨社会科学在智能体中的潜力。

    

    关注基于大型语言模型的智能体应该超越“以人为中心”的对齐或应用。我们认为应该更多关注智能体本身，并探讨社会科学在智能体中的潜力。

    Focus on Large Language Model based agents should involve more than "human-centered" alignment or application. We argue that more attention should be paid to the agent itself and discuss the potential of social sciences for agents.
    
[^59]: ReLLa: 基于检索增强的大型语言模型的推荐系统中的生命周期序列行为理解

    ReLLa: Retrieval-enhanced Large Language Models for Lifelong Sequential Behavior Comprehension in Recommendation. (arXiv:2308.11131v1 [cs.IR])

    [http://arxiv.org/abs/2308.11131](http://arxiv.org/abs/2308.11131)

    本论文提出了一种名为ReLLa的检索增强大型语言模型框架，用于零样本和小样本推荐任务。通过语义用户行为检索（SUBR）来提取上下文中的有用信息，以改善LLMs的推荐性能。

    

    随着大型语言模型（LLMs）在自然语言处理（NLP）领域取得了显著突破，基于LLM的推荐系统引起了广泛关注并被积极探索。本文专注于适应和增强纯大型语言模型以用于零样本和小样本推荐任务。首先，我们针对推荐领域中LLMs无法从长用户行为序列的文本上下文中提取有用信息的问题，提出并定义了生命周期序列行为理解问题。为了解决这个问题并提高LLMs的推荐性能，我们提出了一种新的框架，即检索增强的大型语言模型（ReLLa）。针对零样本推荐，我们执行语义用户行为检索（SUBR）来提高数据的利用率。

    With large language models (LLMs) achieving remarkable breakthroughs in natural language processing (NLP) domains, LLM-enhanced recommender systems have received much attention and have been actively explored currently. In this paper, we focus on adapting and empowering a pure large language model for zero-shot and few-shot recommendation tasks. First and foremost, we identify and formulate the lifelong sequential behavior incomprehension problem for LLMs in recommendation domains, i.e., LLMs fail to extract useful information from a textual context of long user behavior sequence, even if the length of context is far from reaching the context limitation of LLMs. To address such an issue and improve the recommendation performance of LLMs, we propose a novel framework, namely Retrieval-enhanced Large Language models (ReLLa) for recommendation tasks in both zero-shot and few-shot settings. For zero-shot recommendation, we perform semantic user behavior retrieval (SUBR) to improve the data
    
[^60]: 使用层次结构距离捕捉多层次图结构的变压器

    Transformers for Capturing Multi-level Graph Structure using Hierarchical Distances. (arXiv:2308.11129v1 [cs.LG])

    [http://arxiv.org/abs/2308.11129](http://arxiv.org/abs/2308.11129)

    本论文提出了一种层次距离结构编码（HDSE）方法，用于捕捉多层次图结构。经过在12个真实世界数据集上的实验，证明了该方法在10个基准数据集上实验效果达到了最先进水平。

    

    图变压器需要强大的归纳偏差来得出有意义的注意力分数。然而，当前的提议很少涉及捕捉更长距离、层次结构或社区结构的方法，而这些在分子、社交网络和引用网络等各种图形中都会出现。在本文中，我们提出了一种层次距离结构编码（HDSE）方法，用于建模图中节点之间的层次距离，重点关注其多层次、层次化的性质。特别是，这产生了一个可以灵活与现有图变压器集成的框架，可以与其他位置表示同时应用。通过在12个真实世界数据集上进行大量实验，我们证明了我们的HDSE方法成功提升了各种类型的基线变压器，在10个基准数据集上获得了最先进的实证性能。

    Graph transformers need strong inductive biases to derive meaningful attention scores. Yet, current proposals rarely address methods capturing longer ranges, hierarchical structures, or community structures, as they appear in various graphs such as molecules, social networks, and citation networks. In this paper, we propose a hierarchy-distance structural encoding (HDSE), which models a hierarchical distance between the nodes in a graph focusing on its multi-level, hierarchical nature. In particular, this yields a framework which can be flexibly integrated with existing graph transformers, allowing for simultaneous application with other positional representations. Through extensive experiments on 12 real-world datasets, we demonstrate that our HDSE method successfully enhances various types of baseline transformers, achieving state-of-the-art empirical performances on 10 benchmark datasets.
    
[^61]: CAME: 对比自动化模型评估

    CAME: Contrastive Automated Model Evaluation. (arXiv:2308.11111v1 [cs.CV])

    [http://arxiv.org/abs/2308.11111](http://arxiv.org/abs/2308.11111)

    CAME是一个不依赖训练集的对比自动化模型评估框架，通过理论分析和实证验证，建立了模型性能与对比损失之间的可预测关系，并取得了新的SOTA结果。

    

    自动化模型评估（AutoEval）框架探索了在没有标记的测试集的情况下评估训练好的机器学习模型的可能性。尽管有一些不错的结果和承诺，但现有的AutoEval方法主要依赖于计算未标记测试集与训练集之间的分布偏移。我们认为这种对训练集的依赖成为将这项技术应用于真实世界机器学习开发中的另一个障碍。在这项工作中，我们提出了对比自动模型评估（CAME）一个新的AutoEval框架，该框架不需要依赖训练集。CAME的核心思想基于理论分析，将模型性能与对比损失相联系。此外，通过大量的实证验证，我们成功建立了两者之间的可预测关系，只需在未标记/未见的测试集上进行推导。由此产生的框架CAME通过超越以前的工作建立了新的SOTA结果。

    The Automated Model Evaluation (AutoEval) framework entertains the possibility of evaluating a trained machine learning model without resorting to a labeled testing set. Despite the promise and some decent results, the existing AutoEval methods heavily rely on computing distribution shifts between the unlabelled testing set and the training set. We believe this reliance on the training set becomes another obstacle in shipping this technology to real-world ML development. In this work, we propose Contrastive Automatic Model Evaluation (CAME), a novel AutoEval framework that is rid of involving training set in the loop. The core idea of CAME bases on a theoretical analysis which bonds the model performance with a contrastive loss. Further, with extensive empirical validation, we manage to set up a predictable relationship between the two, simply by deducing on the unlabeled/unseen testing set. The resulting framework CAME establishes a new SOTA results for AutoEval by surpassing prior wo
    
[^62]: 大型语言模型的再识别能力：匿名面临风险吗？

    Anonymity at Risk? Assessing Re-Identification Capabilities of Large Language Models. (arXiv:2308.11103v1 [cs.CL])

    [http://arxiv.org/abs/2308.11103](http://arxiv.org/abs/2308.11103)

    本研究评估了大型语言模型在重新识别匿名个人方面的能力，并发现模型大小、输入长度和指令调整是最重要的决定因素。

    

    在欧盟和瑞士，法院裁决中自然人和法人的匿名性是隐私保护的关键方面。随着大型语言模型（LLMs）的出现，对于匿名人员的大规模再识别的担忧日益增长。根据瑞士联邦最高法院的要求，我们通过使用来自瑞士联邦最高法院的实际法律数据构建了一个概念验证，来探讨LLMs重新识别法院裁决中个人的潜力。在最初的实验之后，我们构建了一个经过匿名化处理的维基百科数据集，作为一个更严格的测试场地来进一步研究研究结果。通过引入并应用文本中再识别人员的新任务，我们还引入了新的性能衡量指标。我们系统地分析了影响成功再识别的因素，确定模型大小、输入长度和指令调整是最重要的决定因素之一。尽管在匿名化处理后，LLMs在重新识别上的成功率很高，但在某些情况下仍然存在风险。

    Anonymity of both natural and legal persons in court rulings is a critical aspect of privacy protection in the European Union and Switzerland. With the advent of LLMs, concerns about large-scale re-identification of anonymized persons are growing. In accordance with the Federal Supreme Court of Switzerland, we explore the potential of LLMs to re-identify individuals in court rulings by constructing a proof-of-concept using actual legal data from the Swiss federal supreme court. Following the initial experiment, we constructed an anonymized Wikipedia dataset as a more rigorous testing ground to further investigate the findings. With the introduction and application of the new task of re-identifying people in texts, we also introduce new metrics to measure performance. We systematically analyze the factors that influence successful re-identifications, identifying model size, input length, and instruction tuning among the most critical determinants. Despite high re-identification rates on
    
[^63]: 在自动调制分类中使用早期退出以实现快速推理

    Using Early Exits for Fast Inference in Automatic Modulation Classification. (arXiv:2308.11100v1 [cs.NI])

    [http://arxiv.org/abs/2308.11100](http://arxiv.org/abs/2308.11100)

    本文提出了在自动调制分类中使用早期退出技术加速推理的方法。通过使用早期退出架构，针对信噪比适中至较高的信号，可以显著降低深度神经网络的推理速度，而不损失分类性能。

    

    自动调制分类在无线通信中起着关键作用，通过自主地对无线频谱上传输的信号进行分类。由于深度学习技术能够提取复杂的无线信号特征，因此越来越多地将其用于自动调制分类。然而，深度学习模型计算密集且推理延迟较高。本文提出了在用于自动调制分类的深度学习模型中应用早期退出技术以加速推理。我们提出并分析了四种早期退出架构和针对该问题的定制多分支训练算法。通过大量实验，我们表明在信噪比（SNR）适中至较高的信号上更容易进行分类，不需要深度结构，因此可以利用所提出的早期退出架构。我们的实验结果表明，早期退出技术可以显著降低深度神经网络的推理速度，同时不损失分类性能。

    Automatic modulation classification (AMC) plays a critical role in wireless communications by autonomously classifying signals transmitted over the radio spectrum. Deep learning (DL) techniques are increasingly being used for AMC due to their ability to extract complex wireless signal features. However, DL models are computationally intensive and incur high inference latencies. This paper proposes the application of early exiting (EE) techniques for DL models used for AMC to accelerate inference. We present and analyze four early exiting architectures and a customized multi-branch training algorithm for this problem. Through extensive experimentation, we show that signals with moderate to high signal-to-noise ratios (SNRs) are easier to classify, do not require deep architectures, and can therefore leverage the proposed EE architectures. Our experimental results demonstrate that EE techniques can significantly reduce the inference speed of deep neural networks without sacrificing class
    
[^64]: Video OWL-ViT: 视频中具有时间一致性的开放世界定位

    Video OWL-ViT: Temporally-consistent open-world localization in video. (arXiv:2308.11093v1 [cs.CV])

    [http://arxiv.org/abs/2308.11093](http://arxiv.org/abs/2308.11093)

    本论文提出了Video OWL-ViT模型，将预训练的开放世界图像模型应用于视频定位任务，通过添加变换器解码器实现时间上的连续传播，相比于传统的跟踪-by-detection方法具有更好的时间一致性。

    

    我们提出了一种架构和训练方案，将预训练的开放世界图像模型应用于视频定位。理解开放的视觉世界（不受固定标签空间的限制）对于许多真实世界的视觉任务至关重要。在大型图像-文本数据集上进行对比预训练最近在图像级任务中取得了显著的改进。对于涉及对象定位的更结构化任务，应用预训练模型更具挑战性。对于视频任务来说尤其如此，因为任务特定的数据是有限的。我们通过在OWL-ViT开放词汇检测模型的基础上构建，并通过添加一个变换器解码器将其适应为视频，展示了开放世界模型的成功转移。解码器通过使用一个帧的输出标记作为下一帧的对象查询，以时间上的连续方式传播对象表示。我们的模型可以对视频数据进行端到端的训练，并且相比通过检测进行跟踪的方法，具有更好的时间一致性。

    We present an architecture and a training recipe that adapts pre-trained open-world image models to localization in videos. Understanding the open visual world (without being constrained by fixed label spaces) is crucial for many real-world vision tasks. Contrastive pre-training on large image-text datasets has recently led to significant improvements for image-level tasks. For more structured tasks involving object localization applying pre-trained models is more challenging. This is particularly true for video tasks, where task-specific data is limited. We show successful transfer of open-world models by building on the OWL-ViT open-vocabulary detection model and adapting it to video by adding a transformer decoder. The decoder propagates object representations recurrently through time by using the output tokens for one frame as the object queries for the next. Our model is end-to-end trainable on video data and enjoys improved temporal consistency compared to tracking-by-detection b
    
[^65]: UAV、工人和汽车的协同路径规划在灾难响应中的众包感知

    Collaborative Route Planning of UAVs, Workers and Cars for Crowdsensing in Disaster Response. (arXiv:2308.11088v1 [cs.AI])

    [http://arxiv.org/abs/2308.11088](http://arxiv.org/abs/2308.11088)

    这篇论文研究了在灾难响应中，无人机、工人和汽车的协同路径规划问题，旨在最大化任务完成率。研究者提出了一种多智能体路径规划算法MANF-RL-RP，该算法包括了全局-局部双重信息处理和针对多智能体系统的定制模型结构。

    

    高效地获取灾区最新信息是成功的灾难响应的关键。无人机、工人和汽车可以协同完成诸如数据收集等感知任务。本文针对包括无人机、工人和汽车在内的一组代理人的路径规划问题，旨在最大化任务完成率。我们提出了一种多智能体路径规划算法MANF-RL-RP，该算法包括了多种有效的设计，包括全局-局部双重信息处理和针对多智能体系统的定制模型结构。全局-局部双重信息处理涵盖了从全局信息中提取和传播空间特征，以及从个体代理人中分割和过滤本地信息。对于多智能体的模型结构构建，我们完成了以下工作：

    Efficiently obtaining the up-to-date information in the disaster-stricken area is the key to successful disaster response. Unmanned aerial vehicles (UAVs), workers and cars can collaborate to accomplish sensing tasks, such as data collection, in disaster-stricken areas. In this paper, we explicitly address the route planning for a group of agents, including UAVs, workers, and cars, with the goal of maximizing the task completion rate. We propose MANF-RL-RP, a heterogeneous multi-agent route planning algorithm that incorporates several efficient designs, including global-local dual information processing and a tailored model structure for heterogeneous multi-agent systems. Global-local dual information processing encompasses the extraction and dissemination of spatial features from global information, as well as the partitioning and filtering of local information from individual agents. Regarding the construction of the model structure for heterogeneous multi-agent, we perform the follo
    
[^66]: 嵌套的多智能体推理的神经摊销推断

    Neural Amortized Inference for Nested Multi-agent Reasoning. (arXiv:2308.11071v1 [cs.AI])

    [http://arxiv.org/abs/2308.11071](http://arxiv.org/abs/2308.11071)

    本研究引入了一种新的方法，利用神经网络对高阶社会推理进行摊销，从而加快嵌套多智能体推理的计算速度，实验结果表明该方法在计算效率上表现出色，同时准确性降低最小化。

    

    多智能体之间的相互作用，如沟通、教学和虚张声势，通常依赖于高阶的社会推理，即理解他人如何推断自己。这种复杂的推理可以通过嵌套式多智能体推理来有效建模。然而，随着每个推理级别的增加，计算复杂性呈指数级增长，提出了重大挑战。然而，人类在日常生活中轻松地执行复杂的社会推理。为了弥合人类推理能力和计算限制之间的差距，我们提出了一种新的方法：利用神经网络对高阶社会推理进行摊销，从而加快嵌套多智能体推理。我们在两个具有挑战性的多智能体交互领域对我们的方法进行评估。实验结果表明，我们的方法在计算效率上表现出色，同时准确性降低最小化。

    Multi-agent interactions, such as communication, teaching, and bluffing, often rely on higher-order social inference, i.e., understanding how others infer oneself. Such intricate reasoning can be effectively modeled through nested multi-agent reasoning. Nonetheless, the computational complexity escalates exponentially with each level of reasoning, posing a significant challenge. However, humans effortlessly perform complex social inferences as part of their daily lives. To bridge the gap between human-like inference capabilities and computational limitations, we propose a novel approach: leveraging neural networks to amortize high-order social inference, thereby expediting nested multi-agent reasoning. We evaluate our method in two challenging multi-agent interaction domains. The experimental results demonstrate that our method is computationally efficient while exhibiting minimal degradation in accuracy.
    
[^67]: 基于时间分布的视频行为识别背门攻击

    Temporal-Distributed Backdoor Attack Against Video Based Action Recognition. (arXiv:2308.11070v1 [cs.CV])

    [http://arxiv.org/abs/2308.11070](http://arxiv.org/abs/2308.11070)

    本文介绍了一种针对视频数据的简单而有效的背门攻击方法，通过在转换领域中添加难以察觉的、时间上分布的触发器来实现误分类。

    

    深度神经网络在包括视频行为识别在内的各种应用中取得了巨大成功，但仍然容易受到背门攻击（特洛伊）。当测试实例（来自非目标类）嵌入特定触发器时，被背门破坏的模型会误分类为攻击者选择的目标类，同时在无攻击实例上保持高准确率。尽管对于图像数据的背门攻击已经进行了广泛研究，但视频系统在背门攻击下的易受攻击性仍然很少被探索。当前的研究是对图像数据的方法的直接延伸，例如，触发器是\textbf{独立}嵌入帧中的，容易被现有防御机制检测到。在本文中，我们介绍了一种\textit{简单}但\textit{有效}的视频数据背门攻击。我们提出的攻击在一个转换的领域中添加扰动，以嵌入\textbf{难以察觉的，时间上分布的}触发器。

    Deep neural networks (DNNs) have achieved tremendous success in various applications including video action recognition, yet remain vulnerable to backdoor attacks (Trojans). The backdoor-compromised model will mis-classify to the target class chosen by the attacker when a test instance (from a non-target class) is embedded with a specific trigger, while maintaining high accuracy on attack-free instances. Although there are extensive studies on backdoor attacks against image data, the susceptibility of video-based systems under backdoor attacks remains largely unexplored. Current studies are direct extensions of approaches proposed for image data, e.g., the triggers are \textbf{independently} embedded within the frames, which tend to be detectable by existing defenses. In this paper, we introduce a \textit{simple} yet \textit{effective} backdoor attack against video data. Our proposed attack, adding perturbations in a transformed domain, plants an \textbf{imperceptible, temporally distr
    
[^68]: 基于拓扑结构的图信号压缩

    Topological Graph Signal Compression. (arXiv:2308.11068v1 [cs.LG])

    [http://arxiv.org/abs/2308.11068](http://arxiv.org/abs/2308.11068)

    这项研究提出了一种基于拓扑结构的图信号压缩方法，通过处理高阶交互、聚类和消息传递等步骤，相比于传统方法在压缩信号时具有更好的重建误差，能够更好地捕捉和利用空间和时间特征。

    

    最近出现的拓扑深度学习（TDL）方法旨在通过自然地处理高阶交互，超越由图表示定义的成对关系和局部邻域，从而扩展当前的图神经网络（GNN）。在本文中，我们提出了一种基于TDL的图信号压缩方法，包括两个主要步骤：首先，基于原始信号推断出不相交的高阶结构，通过将N个数据点聚类成K个集合；然后，基于拓扑启示的消息传递在这些多元素集合中获得信号的压缩表示。我们的结果表明，我们的框架在压缩来自两个真实的互联网服务提供商网络数据集的时间链路信号时，比标准的GNN和前馈架构具有更好的重建误差——在所有评估场景中，重建误差提高了从30%到90%。这表明它更好地捕捉和利用了空间和时间特征。

    Recently emerged Topological Deep Learning (TDL) methods aim to extend current Graph Neural Networks (GNN) by naturally processing higher-order interactions, going beyond the pairwise relations and local neighborhoods defined by graph representations. In this paper we propose a novel TDL-based method for compressing signals over graphs, consisting in two main steps: first, disjoint sets of higher-order structures are inferred based on the original signal --by clustering $N$ datapoints into $K\ll N$ collections; then, a topological-inspired message passing gets a compressed representation of the signal within those multi-element sets. Our results show that our framework improves both standard GNN and feed-forward architectures in compressing temporal link-based signals from two real-word Internet Service Provider Networks' datasets --from $30\%$ up to $90\%$ better reconstruction errors across all evaluation scenarios--, suggesting that it better captures and exploits spatial and tempor
    
[^69]: CSM-H-R: 一种用于可互操作智能系统和隐私保护的自动上下文推理框架

    CSM-H-R: An Automatic Context Reasoning Framework for Interoperable Intelligent Systems and Privacy Protection. (arXiv:2308.11066v1 [cs.AI])

    [http://arxiv.org/abs/2308.11066](http://arxiv.org/abs/2308.11066)

    CSM-H-R是一个自动上下文推理框架，用于可互操作的智能系统和隐私保护。该框架结合了本体和状态，在运行时识别有意义的高级上下文，并可应用于不同的推理技术。在智能校园环境中进行了智能电梯系统的案例研究，并展示了使用先进的数学和概率模型的潜力。

    

    在物联网时代，智能系统对高级上下文(HLC)推理的自动化变得至关重要，这是因为上下文数据的不断积累、多源数据融合的趋势以及基于上下文决策过程的固有复杂性和动态性。为了解决这个问题，我们提出了一种自动上下文推理框架CSM-H-R，该框架在运行时以编程方式组合本体和状态，并结合模型存储阶段，以实现识别有意义的HLC的能力，所得到的数据表示可应用于不同的推理技术。在智能校园环境中基于智能电梯系统开展了案例研究。框架的实现-CSM引擎以及将HLC推理转化为矢量和矩阵计算的实验，特别关注上下文的动态特性，并展示了使用先进的数学和概率模型的潜力。

    Automation of High-Level Context (HLC) reasoning for intelligent systems at scale is imperative due to the unceasing accumulation of contextual data in the IoT era, the trend of the fusion of data from multi-sources, and the intrinsic complexity and dynamism of the context-based decision-making process. To mitigate this issue, we propose an automatic context reasoning framework CSM-H-R, which programmatically combines ontologies and states at runtime and the model-storage phase for attaining the ability to recognize meaningful HLC, and the resulting data representation can be applied to different reasoning techniques. Case studies are developed based on an intelligent elevator system in a smart campus setting. An implementation of the framework - a CSM Engine, and the experiments of translating the HLC reasoning into vector and matrix computing especially take care of the dynamic aspects of context and present the potentiality of using advanced mathematical and probabilistic models to 
    
[^70]: 超越判别性区域：作为弱监督语义分割CAM的替代方法的显著性图

    Beyond Discriminative Regions: Saliency Maps as Alternatives to CAMs for Weakly Supervised Semantic Segmentation. (arXiv:2308.11052v1 [cs.CV])

    [http://arxiv.org/abs/2308.11052](http://arxiv.org/abs/2308.11052)

    本篇论文对弱监督语义分割中的显著性图和类激活图进行了全面比较，提出了新的评估指标，并证明了显著性图的有效性。

    

    近年来，提出了几种使用分类器生成的类激活图（CAM）来生成伪地面真相以训练分割模型的弱监督语义分割（WS3）方法。虽然CAM能够很好地突出图像的判别性区域（DR），但它们被知道忽视不对分类器预测做出贡献的物体区域，称为非判别性区域（NDR）。相比之下，显著性图等归因方法提供了一种基于每个像素对分类预测的贡献来分配得分的替代方法。本文对WS3中的显著性图和CAM进行了全面比较。我们的研究从多个角度理解它们的相似性和差异。此外，我们提供了新的评估指标，对比CAM的替代方法在WS3性能方面进行了全面评估。我们证明了显著性图的有效性。

    In recent years, several Weakly Supervised Semantic Segmentation (WS3) methods have been proposed that use class activation maps (CAMs) generated by a classifier to produce pseudo-ground truths for training segmentation models. While CAMs are good at highlighting discriminative regions (DR) of an image, they are known to disregard regions of the object that do not contribute to the classifier's prediction, termed non-discriminative regions (NDR). In contrast, attribution methods such as saliency maps provide an alternative approach for assigning a score to every pixel based on its contribution to the classification prediction. This paper provides a comprehensive comparison between saliencies and CAMs for WS3. Our study includes multiple perspectives on understanding their similarities and dissimilarities. Moreover, we provide new evaluation metrics that perform a comprehensive assessment of WS3 performance of alternative methods w.r.t. CAMs. We demonstrate the effectiveness of salienci
    
[^71]: 物流集散地位置优化：一种基于K-Means和P-Median模型的混合方法，利用道路网络距离

    Logistics Hub Location Optimization: A K-Means and P-Median Model Hybrid Approach Using Road Network Distances. (arXiv:2308.11038v1 [math.OC])

    [http://arxiv.org/abs/2308.11038](http://arxiv.org/abs/2308.11038)

    本研究基于K-Means和P-Median模型提出了一种混合方法，通过使用道路网络距离来优化在城市环境下物流集散地的位置布置，以减少配送距离和碳足迹。

    

    物流集散地在最后一公里配送距离中起着关键作用；即使距离微小增加也会对电子商务行业的业务产生负面影响，同时还会增加其碳足迹。特别是在Covid-19之后，该行业的增长进一步加剧了在城市环境中优化资源分配的需求。在这项研究中，我们使用了一种混合方法来优化物流集散地的布置。该方法依次采用不同的技术。首先，根据它们的空间位置，使用K-Means对交付点进行聚类。聚类方法使用道路网络距离，而不是欧几里德距离。避免使用非基于道路网络的方法，因为它们会导致错误和误导性结果。最后，使用P-Median方法确定集散地的位置。P-Median方法还将交付数量和人口作为权重考虑在内。使用Muller和Phipps（M＆P）的实际交付数据

    Logistic hubs play a pivotal role in the last-mile delivery distance; even a slight increment in distance negatively impacts the business of the e-commerce industry while also increasing its carbon footprint. The growth of this industry, particularly after Covid-19, has further intensified the need for optimized allocation of resources in an urban environment. In this study, we use a hybrid approach to optimize the placement of logistic hubs. The approach sequentially employs different techniques. Initially, delivery points are clustered using K-Means in relation to their spatial locations. The clustering method utilizes road network distances as opposed to Euclidean distances. Non-road network-based approaches have been avoided since they lead to erroneous and misleading results. Finally, hubs are located using the P-Median method. The P-Median method also incorporates the number of deliveries and population as weights. Real-world delivery data from Muller and Phipps (M&P) is used to 
    
[^72]: 基于异构节点特征和交互规则的面向数字孪生的复杂网络系统

    Digital Twin-Oriented Complex Networked Systems based on Heterogeneous node features and interaction rules. (arXiv:2308.11034v1 [cs.SI])

    [http://arxiv.org/abs/2308.11034](http://arxiv.org/abs/2308.11034)

    本研究提出了一种面向数字孪生的复杂网络系统的可扩展建模框架，重点关注节点特征和交互规则。通过实验研究了网络增长和疫情传播的不同级别的复杂性对系统的影响，结果表明需要在DT-CNS中平衡这些复杂性水平。

    

    本研究提出了一种可扩展的建模框架，用于数字孪生导向的复杂网络系统（DT-CNS），旨在生成能够真实表示实际系统的网络。建模过程关注节点的特征和基于个体节点偏好创建连接的交互规则。我们对基于模拟的DT-CNS进行了实验，其中包括各种特征和规则，以及与传染病在这些网络中的传播相关的不同传染能力。我们通过调查特定时间和社交距离内的感染情况，对社交网络的灾害韧性进行了案例研究。实验结果显示了结构复杂性和动态复杂性的不同级别对网络增长和疫情传播的影响，分别涉及特征多样性和交互规则的灵活性。分析表明，要实现最大的灾害韧性，需要在DT-CNS中平衡这些复杂性水平。

    This study proposes an extendable modelling framework for Digital Twin-Oriented Complex Networked Systems (DT-CNSs) with a goal of generating networks that faithfully represent real systems. Modelling process focuses on (i) features of nodes and (ii) interaction rules for creating connections that are built based on individual node's preferences. We conduct experiments on simulation-based DT-CNSs that incorporate various features and rules about network growth and different transmissibilities related to an epidemic spread on these networks. We present a case study on disaster resilience of social networks given an epidemic outbreak by investigating the infection occurrence within specific time and social distance. The experimental results show how different levels of the structural and dynamics complexities, concerned with feature diversity and flexibility of interaction rules respectively, influence network growth and epidemic spread. The analysis revealed that, to achieve maximum dis
    
[^73]: RBA-GCN: 关系双层聚合图卷积网络用于情感识别

    RBA-GCN: Relational Bilevel Aggregation Graph Convolutional Network for Emotion Recognition. (arXiv:2308.11029v1 [cs.AI])

    [http://arxiv.org/abs/2308.11029](http://arxiv.org/abs/2308.11029)

    提出了RBA-GCN模型用于情感识别。该模型通过引入关系双层聚合和图生成模块，解决了GCN模型中的节点信息冗余和远距离上下文信息捕获问题。

    

    情感识别在对话中的应用受到了研究人员的关注，由于它具有广泛的应用。由于对话具有自然的图结构，很多基于图卷积网络（GCNs）的ERC模型方法取得了显著的结果。然而，传统GCNs的聚合方法存在节点信息冗余问题，导致节点辨别信息的丢失。此外，单层GCNs缺乏从图中捕获远距离上下文信息的能力。此外，大多数方法都是基于文本模态或将不同模态拼接在一起，导致捕捉模态间交互能力弱。为了解决这些问题，我们提出了关系双层聚合图卷积网络（RBA-GCN），它由三个模块组成：图生成模块（GGM）、基于相似性的簇构建模块（SCBM）和双层聚合模块。

    Emotion recognition in conversation (ERC) has received increasing attention from researchers due to its wide range of applications. As conversation has a natural graph structure, numerous approaches used to model ERC based on graph convolutional networks (GCNs) have yielded significant results. However, the aggregation approach of traditional GCNs suffers from the node information redundancy problem, leading to node discriminant information loss. Additionally, single-layer GCNs lack the capacity to capture long-range contextual information from the graph. Furthermore, the majority of approaches are based on textual modality or stitching together different modalities, resulting in a weak ability to capture interactions between modalities. To address these problems, we present the relational bilevel aggregation graph convolutional network (RBA-GCN), which consists of three modules: the graph generation module (GGM), similarity-based cluster building module (SCBM) and bilevel aggregation 
    
[^74]: 个性化的电子健康记录事件预测

    Personalized Event Prediction for Electronic Health Records. (arXiv:2308.11013v1 [cs.LG])

    [http://arxiv.org/abs/2308.11013](http://arxiv.org/abs/2308.11013)

    该论文研究了个性化的电子健康记录事件预测，提出了多个新的预测模型和方法以更好地适应个体差异。

    

    临床事件序列包含数百个临床事件，代表了患者在不同时间接受照护的记录。开发准确的预测模型对于支持各种模型来解释/分类当前患者状况或预测不良临床事件和结果非常重要，所有这些都旨在提高患者护理水平。学习临床序列的预测模型的一个重要挑战是它们的个体差异性。根据潜在的临床条件，每个患者的序列可能包含不同的临床事件集（观察，实验室结果，药物，程序）。因此，仅基于许多不同患者的事件序列学习的简单群体范围模型可能无法准确预测患者特定的事件序列动态和差异。为了解决这个问题，我们提出并研究了多个新的事件序列预测模型和方法，可以更好地调整预测结果。

    Clinical event sequences consist of hundreds of clinical events that represent records of patient care in time. Developing accurate predictive models of such sequences is of a great importance for supporting a variety of models for interpreting/classifying the current patient condition, or predicting adverse clinical events and outcomes, all aimed to improve patient care. One important challenge of learning predictive models of clinical sequences is their patient-specific variability. Based on underlying clinical conditions, each patient's sequence may consist of different sets of clinical events (observations, lab results, medications, procedures). Hence, simple population-wide models learned from event sequences for many different patients may not accurately predict patient-specific dynamics of event sequences and their differences. To address the problem, we propose and investigate multiple new event sequence prediction models and methods that let us better adjust the prediction for
    
[^75]: 基于特征值的增量谱聚类

    Eigenvalue-based Incremental Spectral Clustering. (arXiv:2308.10999v1 [cs.LG])

    [http://arxiv.org/abs/2308.10999](http://arxiv.org/abs/2308.10999)

    本文介绍了一种基于特征值的增量谱聚类方法，通过将数据集划分为子集并进行聚类和合并，可以获得与聚类整个数据集相近的结果。

    

    我们之前的实验表明，（短）文档的子集合（包含几百个条目）在组合拉普拉斯特征值谱上有共同的归一化方式。基于这一洞察，我们提出了一种增量谱聚类的方法。该方法包括以下步骤：（1）将数据划分为可管理的子集，（2）对每个子集进行聚类，（3）基于特征值谱的相似性合并来自不同子集的聚类，形成整个数据集的聚类。这种方法可以特别适用于数据样本量大小发生强烈变化的聚类方法，例如典型的谱聚类。实验证明，实际上对子集进行聚类和合并可以得到与对整个数据集进行聚类相近的聚类结果。

    Our previous experiments demonstrated that subsets collections of (short) documents (with several hundred entries) share a common normalized in some way eigenvalue spectrum of combinatorial Laplacian. Based on this insight, we propose a method of incremental spectral clustering. The method consists of the following steps: (1) split the data into manageable subsets, (2) cluster each of the subsets, (3) merge clusters from different subsets based on the eigenvalue spectrum similarity to form clusters of the entire set. This method can be especially useful for clustering methods of complexity strongly increasing with the size of the data sample,like in case of typical spectral clustering. Experiments were performed showing that in fact the clustering and merging the subsets yields clusters close to clustering the entire dataset.
    
[^76]: SPEGTI: 结构预测用于高效生成文本到图像模型

    SPEGTI: Structured Prediction for Efficient Generative Text-to-Image Models. (arXiv:2308.10997v1 [cs.CV])

    [http://arxiv.org/abs/2308.10997](http://arxiv.org/abs/2308.10997)

    本文提出了一种使用马尔可夫随机场（MRF）模型的轻量级方法，用于实现图像不同区域的相容性，以降低生成文本到图像模型的计算成本。

    

    现代文本到图像生成模型能够生成高质量的图像，既逼真又与文本提示相符。然而，这种质量需要付出巨大的计算成本：几乎所有这些模型都是迭代式的，需要多次运行推断，并使用大模型。这种迭代过程是为了确保图像的不同区域不仅与文本提示对齐，还与其他区域相容。本文中，我们提出了一种轻量级的方法来实现图像不同区域的相容性，使用了马尔可夫随机场（MRF）模型。这种方法能够与最近提出的Muse模型配合使用。MRF编码了不同空间位置的图像标记之间的相容性，并且使我们能够显著减少所需的Muse预测步骤。使用MRF的推断成本大大降低，并且可以通过反向传播快速学习其参数，通过对MRF进行建模。

    Modern text-to-image generation models produce high-quality images that are both photorealistic and faithful to the text prompts. However, this quality comes at significant computational cost: nearly all of these models are iterative and require running inference multiple times with large models. This iterative process is needed to ensure that different regions of the image are not only aligned with the text prompt, but also compatible with each other. In this work, we propose a light-weight approach to achieving this compatibility between different regions of an image, using a Markov Random Field (MRF) model. This method is shown to work in conjunction with the recently proposed Muse model. The MRF encodes the compatibility among image tokens at different spatial locations and enables us to significantly reduce the required number of Muse prediction steps. Inference with the MRF is significantly cheaper, and its parameters can be quickly learned through back-propagation by modeling MR
    
[^77]: ERA*: 改进的放松A*算法用于解决规则网格地图中的最短路径问题

    ERA*: Enhanced Relaxed A* algorithm for Solving the Shortest Path Problem in Regular Grid Maps. (arXiv:2308.10988v1 [cs.AI])

    [http://arxiv.org/abs/2308.10988](http://arxiv.org/abs/2308.10988)

    本文介绍了一种改进的放松A*算法，用于解决规则网格地图中的最短路径问题。相较于现有算法，该算法在时间和内存方面具有显著的优势，并通过实验证明其在各种类型和大小的地图上都表现出高效性能。

    

    本文介绍了一种新的算法，用于解决静态规则8邻接连通（G8）网格中的点对点最短路径问题。这个算法可以视为将Hadlock算法推广到G8网格的结果，并且在所提供的解的路径长度方面在理论上等价于放松A* (RA*)算法，但由于完全不同的计算策略（基于定义一组查找矩阵），能够节省大量的时间和内存。通过对各种类型和大小的网格地图进行实验研究（在43个地图上进行了1290次运行），平均证明它比RA*快2.25倍，比原始A*快17倍。此外，它更节省内存，因为不需要存储G得分矩阵。

    This paper introduces a novel algorithm for solving the point-to-point shortest path problem in a static regular 8-neighbor connectivity (G8) grid. This algorithm can be seen as a generalization of Hadlock algorithm to G8 grids, and is shown to be theoretically equivalent to the relaxed $A^*$ ($RA^*$) algorithm in terms of the provided solution's path length, but with substantial time and memory savings, due to a completely different computation strategy, based on defining a set of lookup matrices. Through an experimental study on grid maps of various types and sizes (1290 runs on 43 maps), it is proven to be 2.25 times faster than $RA^*$ and 17 times faster than the original $A^*$, in average. Moreover, it is more memory-efficient, since it does not need to store a G score matrix.
    
[^78]: "引用GPT的“豚鼠试验”：一种研究企业竞争和勾结的创新智能代理建模方法"

    "Guinea Pig Trials" Utilizing GPT: A Novel Smart Agent-Based Modeling Approach for Studying Firm Competition and Collusion. (arXiv:2308.10974v1 [cs.AI])

    [http://arxiv.org/abs/2308.10974](http://arxiv.org/abs/2308.10974)

    "引用GPT的“豚鼠试验”是一种创新的智能代理建模方法，利用智能代理代表企业进行竞争和勾结研究。它比使用人类主体进行实验更具成本效益和灵活性，并展现出超越传统代理建模方法的能力。"

    

    企业竞争和勾结涉及复杂的动态，尤其是考虑到企业之间的沟通。这些问题可以被建模为复杂系统的问题，传统上通过涉及人类主体或基于代理的建模方法进行探究。我们提出了一种创新的框架，称为智能代理建模（SABM），其中由GPT-4技术支持的智能代理代表企业并相互交互。我们进行了一项控制实验，研究了不同条件下企业价格竞争和勾结行为。与使用人类主体进行实验相比，SABM更具成本效益和灵活性。智能代理拥有决策的广泛知识库，展现出类似人类的战略能力，超越了传统的基于代理的建模方法。此外，智能代理能够模拟人类对话并个性化，使其成为研究涉及沟通的复杂情况的理想选择。我们的结果表明...

    Firm competition and collusion involve complex dynamics, particularly when considering communication among firms. Such issues can be modeled as problems of complex systems, traditionally approached through experiments involving human subjects or agent-based modeling methods. We propose an innovative framework called Smart Agent-Based Modeling (SABM), wherein smart agents, supported by GPT-4 technologies, represent firms, and interact with one another. We conducted a controlled experiment to study firm price competition and collusion behaviors under various conditions. SABM is more cost-effective and flexible compared to conducting experiments with human subjects. Smart agents possess an extensive knowledge base for decision-making and exhibit human-like strategic abilities, surpassing traditional ABM agents. Furthermore, smart agents can simulate human conversation and be personalized, making them ideal for studying complex situations involving communication. Our results demonstrate th
    
[^79]: DocPrompt: 大规模连续预训练用于零样本和少样本文档问答

    DocPrompt: Large-scale continue pretrain for zero-shot and few-shot document question answering. (arXiv:2308.10959v1 [cs.CL])

    [http://arxiv.org/abs/2308.10959](http://arxiv.org/abs/2308.10959)

    本文提出了一个名为DocPrompt的方法，用于处理文档问答任务，具有强大的零样本和少样本性能。实验结果表明，DocPrompt模型经过连续预训练后在文档问答任务中表现优异，大大提高了交付效率和模型性能，降低了注释成本和劳动成本。

    

    本文提出了一个名为DocPrompt的方法，用于处理文档问答任务，具有强大的零样本和少样本性能。我们提出了一种新颖的弱监督数据生成方法、一种新颖的多阶段训练方法，以及一种新颖的理解模型和生成模型集成方法。实验结果表明，在文档问答任务中，经过连续预训练的DocPrompt模型明显优于现有的强基线模型。这种方法极大地提高了文档问答客户项目的交付效率和模型性能，降低了注释成本和劳动成本。我们的演示可以在https://huggingface.co/spaces/PaddlePaddle/ERNIE-Layout找到。

    In this paper, we propose Docprompt for document question answering tasks with powerful zero-shot and few-shot performance. We proposed a novel weakly supervised data generation method, a novel multl-stage training method and a novel understanding model & generation model ensemble method. Experiment results show that the Docprompt model after continue pretrain significantly outperforms the existing strong baseline models on document question answering tasks. This method greatly improves the delivery efficiency and model performance of document question answering customer projects, reducing annotation costs and labor costs. Our demo can be found at https://huggingface.co/spaces/PaddlePaddle/ERNIE-Layout.
    
[^80]: DataVinci: 学习句法和语义字符串修复

    DataVinci: Learning Syntactic and Semantic String Repairs. (arXiv:2308.10922v1 [cs.DB])

    [http://arxiv.org/abs/2308.10922](http://arxiv.org/abs/2308.10922)

    DataVinci是一个全自动的无监督字符串数据错误检测和修复系统，可学习句法和语义模式，并自动推导出对数据错误的修复。

    

    字符串数据在现实世界的数据集中很常见：从网络上采样的180万个真实Excel电子表格中，有67.6%的值表示为文本。成功清理这种字符串数据的系统对实际用户有重要影响。尽管以前的工作已经探索了字符串数据中的错误，但是所提出的方法通常局限于错误检测，或者需要用户提供注释、示例或约束来修复错误。此外，这些系统独立地关注于字符串中的句法错误或语义错误，而忽略了字符串通常同时包含句法和语义子字符串的情况。我们引入了DataVinci，一个完全无监督的字符串数据错误检测和修复系统。DataVinci学习基于正则表达式的模式，覆盖了列中大多数的值，并将不满足这些模式的值报告为数据错误。DataVinci可以根据主要模式和约束自动推导出对数据错误的修复。

    String data is common in real-world datasets: 67.6% of values in a sample of 1.8 million real Excel spreadsheets from the web were represented as text. Systems that successfully clean such string data can have a significant impact on real users. While prior work has explored errors in string data, proposed approaches have often been limited to error detection or require that the user provide annotations, examples, or constraints to fix the errors. Furthermore, these systems have focused independently on syntactic errors or semantic errors in strings, but ignore that strings often contain both syntactic and semantic substrings. We introduce DataVinci, a fully unsupervised string data error detection and repair system. DataVinci learns regular-expression-based patterns that cover a majority of values in a column and reports values that do not satisfy such patterns as data errors. DataVinci can automatically derive edits to the data error based on the majority patterns and constraints lea
    
[^81]: 基于Metapath的上下文知识的深度半监督异常检测

    Deep Semi-supervised Anomaly Detection with Metapath-based Context Knowledge. (arXiv:2308.10918v1 [cs.LG])

    [http://arxiv.org/abs/2308.10918](http://arxiv.org/abs/2308.10918)

    本文介绍了一种利用基于Metapath的半监督学习的新颖方法，用于图异常检测。通过在编码器和解码器中使用GCN层来有效传播上下文信息，以及特别设计的异常社区，该方法在结构和属性差异的学习中表现出优越性能。通过实验证明了该方法的有效性，为未来的研究提供了重要的思路和方向。

    

    图异常检测近年来引起了广泛的关注。本文介绍了一种新颖的方法，利用基于Metapath的半监督学习，解决了之前方法的局限性。我们提出了一种新的框架，基于Metapath的半监督异常检测（MSAD），在编码器和解码器中都使用GCN层来有效地传播异常和正常节点之间的上下文信息。基于Metapath的上下文信息的设计和特别精心设计的异常社区增强了全局和局部结构和属性差异的学习过程。通过在七个真实网络上进行的一系列综合实验，本文证明了MSAD方法相对于最先进技术的优越性。本研究的有希望的结果为未来的研究铺平了道路，重点是优化和分析Metapath模式以进一步提高方法的效果。

    Graph anomaly detection has attracted considerable attention in recent years. This paper introduces a novel approach that leverages metapath-based semi-supervised learning, addressing the limitations of previous methods. We present a new framework, Metapath-based Semi-supervised Anomaly Detection (MSAD), incorporating GCN layers in both the encoder and decoder to efficiently propagate context information between abnormal and normal nodes. The design of metapath-based context information and a specifically crafted anomaly community enhance the process of learning differences in structures and attributes, both globally and locally. Through a comprehensive set of experiments conducted on seven real-world networks, this paper demonstrates the superiority of the MSAD method compared to state-of-the-art techniques. The promising results of this study pave the way for future investigations, focusing on the optimization and analysis of metapath patterns to further enhance the effectiveness of 
    
[^82]: 据传统模型作为表示学习器

    Diffusion Model as Representation Learner. (arXiv:2308.10916v1 [cs.CV])

    [http://arxiv.org/abs/2308.10916](http://arxiv.org/abs/2308.10916)

    本文深入研究了扩散概率模型的表示能力，并提出了一种利用生成模型的知识进行识别任务的新的知识传递方法。通过引入RepFusion，我们从预先训练的DPMs中提取表示并将其作为学生网络的监督，通过强化学习来确定最佳的时间步骤。

    

    最近，扩散概率模型（DPMs）在各种生成任务中展示出了令人印象深刻的结果。然而，预先训练的DPMs的学习表示尚未完全理解。在本文中，我们对DPMs的表示力进行了深入研究，并提出了一种新的知识传递方法，利用生成性DPMs获得的知识进行识别任务。我们的研究从研究DPMs的特征空间开始，揭示了DPMs作为去噪自编码器对表示学习和模型容量进行平衡。为此，我们引入了一种名为RepFusion的新的知识传递范式。我们的模式从DPMs中提取不同时间步的表示，并将它们动态地用作学生网络的监督，并通过强化学习确定最佳时间。我们在几个图像分类、语义

    Diffusion Probabilistic Models (DPMs) have recently demonstrated impressive results on various generative tasks.Despite its promises, the learned representations of pre-trained DPMs, however, have not been fully understood. In this paper, we conduct an in-depth investigation of the representation power of DPMs, and propose a novel knowledge transfer method that leverages the knowledge acquired by generative DPMs for recognition tasks. Our study begins by examining the feature space of DPMs, revealing that DPMs are inherently denoising autoencoders that balance the representation learning with regularizing model capacity. To this end, we introduce a novel knowledge transfer paradigm named RepFusion. Our paradigm extracts representations at different time steps from off-the-shelf DPMs and dynamically employs them as supervision for student networks, in which the optimal time is determined through reinforcement learning. We evaluate our approach on several image classification, semantic s
    
[^83]: 解释出现.（arXiv:2308.10912v1 [cs.CC]）

    Explaining Emergence. (arXiv:2308.10912v1 [cs.CC])

    [http://arxiv.org/abs/2308.10912](http://arxiv.org/abs/2308.10912)

    论文研究了出现现象，提出了计算不可简化性的概念，这是能够从客观角度理解出现现象的关键。

    

    出现是各个领域中一个重要的性质。它是一个现象出现得令人惊讶，并且似乎不能预测其出现的事实。这也是为什么经常说出现是相对于观察者而言的主观属性。一些具有简单而确定性规则的数学系统却表现出出现行为。研究这些系统为这个主题带来了新的视角，并且定义了一个新概念，即计算不可简化性，它涉及到行为的完全确定性，但无法在不模拟的情况下预测。因此，计算不可简化性是从客观角度理解出现现象的关键，它不需要提及任何观察者。

    Emergence is a pregnant property in various fields. It is the fact for a phenomenon to appear surprisingly and to be such that it seems at first sight that it is not possible to predict its apparition. That is the reason why it has often been said that emergence is a subjective property relative to the observer. Some mathematical systems having very simple and deterministic rules nevertheless show emergent behavior. Studying these systems shed a new light on the subject and allows to define a new concept, computational irreducibility, which deals with behaviors that even though they are totally deterministic cannot be predicted without simulating them. Computational irreducibility is then a key for understanding emergent phenomena from an objective point of view that does not need the mention of any observer.
    
[^84]: 不完整多模态MRI重建的联合伪模态生成

    Federated Pseudo Modality Generation for Incomplete Multi-Modal MRI Reconstruction. (arXiv:2308.10910v1 [eess.IV])

    [http://arxiv.org/abs/2308.10910](http://arxiv.org/abs/2308.10910)

    本文提出了一种称为Fed-PMG的联合学习框架，通过伪模态生成机制解决了联合多模态MRI重建中的模态缺失问题，以提高通信效率。通过共享频率空间中幅度谱的分布信息恢复丢失的模态，避免了成对多模态数据的需求。

    

    尽管多模态学习在MRI重建中得到广泛应用，但它依赖于难以在实际临床场景中获取的成对多模态数据。特别是在联合学习的情况下，常见情况是几个医疗机构只有单模态数据，即称为模态缺失问题。因此，在这种条件下无法部署标准的联合学习框架。在本文中，我们提出了一种新颖的通信高效的联合学习框架，即Fed-PMG，以解决联合多模态MRI重建中的模态缺失挑战。具体来说，我们利用一种伪模态生成机制通过在频率空间中共享幅度谱的分布信息来恢复每个单模态客户端的丢失模态。然而，共享原始幅度谱的步骤会导致沉重的通信成本。为了降低通信成本，我们引入了聚类方案来进行投影。

    While multi-modal learning has been widely used for MRI reconstruction, it relies on paired multi-modal data which is difficult to acquire in real clinical scenarios. Especially in the federated setting, the common situation is that several medical institutions only have single-modal data, termed the modality missing issue. Therefore, it is infeasible to deploy a standard federated learning framework in such conditions. In this paper, we propose a novel communication-efficient federated learning framework, namely Fed-PMG, to address the missing modality challenge in federated multi-modal MRI reconstruction. Specifically, we utilize a pseudo modality generation mechanism to recover the missing modality for each single-modal client by sharing the distribution information of the amplitude spectrum in frequency space. However, the step of sharing the original amplitude spectrum leads to heavy communication costs. To reduce the communication cost, we introduce a clustering scheme to project
    
[^85]: 在TVM中分析量化

    Analyzing Quantization in TVM. (arXiv:2308.10905v1 [cs.LG])

    [http://arxiv.org/abs/2308.10905](http://arxiv.org/abs/2308.10905)

    该论文研究了在TVM中8位量化的性能问题，并讨论了兼容性和优化机会。

    

    在深度学习模型中对权重张量进行量化以减少推理延迟和内存占用的研究已经有很多。TVM也具备支持低比特计算和量化权重的能力。尽管通常期望通过量化来提高推理时间，在TVM中，8位量化的性能却不能满足期望。通常在将8位量化应用于深度学习模型时，通常期望达到全精度推理时间的50%左右。然而，在这种特殊情况下，量化版本不仅未能实现所期望的性能提升，而且实际上性能更差，导致推理时间约为非量化版本的两倍慢。在这个项目中，我们深入探讨了性能不佳的原因，评估了8位量化在TVM中的兼容性和优化机会。我们讨论了两种不同类型的优化方法

    There has been many papers in academic literature on quantizing weight tensors in deep learning models to reduce inference latency and memory footprint. TVM also has the ability to quantize weights and support low-bit computations. Although quantization is typically expected to improve inference time, in TVM, the performance of 8-bit quantization does not meet the expectations. Typically, when applying 8-bit quantization to a deep learning model, it is usually expected to achieve around 50% of the full-precision inference time. However, in this particular case, not only does the quantized version fail to achieve the desired performance boost, but it actually performs worse, resulting in an inference time that is about 2 times as slow as the non-quantized version. In this project, we thoroughly investigate the reasons behind the underperformance and assess the compatibility and optimization opportunities of 8-bit quantization in TVM. We discuss the optimization of two different types of
    
[^86]: DynED: 数据流分类中的动态集成多样化

    DynED: Dynamic Ensemble Diversification in Data Stream Classification. (arXiv:2308.10807v1 [cs.LG] CROSS LISTED)

    [http://arxiv.org/abs/2308.10807](http://arxiv.org/abs/2308.10807)

    DynED是一种动态集成多样化方法，基于MRR结合了组件的多样性和预测准确性，在数据流环境中实现了更高的准确率。

    

    鉴于数据分布的突变性变化，也称为概念漂移，在数据流环境中实现高准确度是一项具有挑战性的任务。在这种情况下，集合方法被广泛应用于分类，因为它们具有出色的性能。 在集合内部的更大多样性已被证明可以提高预测准确性。尽管集合内组件的多样性很高，但并不是所有组件都像预期的那样对整体性能有所贡献。这需要一种方法来选择展现出高性能和多样性的组件。我们提出了一种基于MMR（最大边际相关性）的新型集合构建和维护方法，在组合集合的过程中动态地结合了组件的多样性和预测准确性。在四个真实和11个合成数据集上的实验结果表明，所提出的方法（DynED）相比于五种最先进的基准方法提供了更高的平均准确率

    Ensemble methods are commonly used in classification due to their remarkable performance. Achieving high accuracy in a data stream environment is a challenging task considering disruptive changes in the data distribution, also known as concept drift. A greater diversity of ensemble components is known to enhance prediction accuracy in such settings. Despite the diversity of components within an ensemble, not all contribute as expected to its overall performance. This necessitates a method for selecting components that exhibit high performance and diversity. We present a novel ensemble construction and maintenance approach based on MMR (Maximal Marginal Relevance) that dynamically combines the diversity and prediction accuracy of components during the process of structuring an ensemble. The experimental results on both four real and 11 synthetic datasets demonstrate that the proposed approach (DynED) provides a higher average mean accuracy compared to the five state-of-the-art baselines
    
[^87]: 使用学习对手稳定无监督环境设计

    Stabilizing Unsupervised Environment Design with a Learned Adversary. (arXiv:2308.10797v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2308.10797](http://arxiv.org/abs/2308.10797)

    本论文研究了无监督环境设计（UED）中PAIRED方法存在的问题，并提出了解决方案，使其在实际性能上能够与或超过最先进的方法。

    

    训练具备普遍能力的智能体面临的主要挑战是设计训练任务，以促进广泛泛化和对环境变化的鲁棒性。这个挑战驱动了无监督环境设计（UED）的问题设置，其中学生智能体在由教师智能体提出的自适应任务分布上进行训练。UED的先驱方法是PAIRED，它使用强化学习（RL）训练教师策略从头开始设计任务，这样可以直接生成适应智能体当前能力的任务。尽管其有很强的理论支持，但PAIRED存在一些挑战，妨碍了其实际性能。因此，目前的最先进方法依赖于策划和变异，而不是生成新任务。在这项工作中，我们研究了PAIRED的几个关键不足之处，并提出了解决方案。因此，我们使PAIRED能够与或超过最先进的方法。

    A key challenge in training generally-capable agents is the design of training tasks that facilitate broad generalization and robustness to environment variations. This challenge motivates the problem setting of Unsupervised Environment Design (UED), whereby a student agent trains on an adaptive distribution of tasks proposed by a teacher agent. A pioneering approach for UED is PAIRED, which uses reinforcement learning (RL) to train a teacher policy to design tasks from scratch, making it possible to directly generate tasks that are adapted to the agent's current capabilities. Despite its strong theoretical backing, PAIRED suffers from a variety of challenges that hinder its practical performance. Thus, state-of-the-art methods currently rely on curation and mutation rather than generation of new tasks. In this work, we investigate several key shortcomings of PAIRED and propose solutions for each shortcoming. As a result, we make it possible for PAIRED to match or exceed state-of-the-a
    
[^88]: 总括荷尔蒙体系作为HOL的一个片段

    Normative Conditional Reasoning as a Fragment of HOL. (arXiv:2308.10686v2 [cs.LO] UPDATED)

    [http://arxiv.org/abs/2308.10686](http://arxiv.org/abs/2308.10686)

    本论文报告了关于正式化条件推理的研究结果，包括Aqvist的条件义务系统E的机械化和伦理论据评估的工具的开发。

    

    我们报告了关于正式化（基于偏好的）条件推理的一些结果。我们关注的是Aqvist的条件义务系统E（及其扩展）。我们通过Isabelle/HOL中的浅表语义嵌入来实现我们的正式化。我们考虑了该框架的两种可能用途。第一种是作为对所考虑逻辑进行元推理的工具。我们将其用于自动验证权利义务对应关系（广义上理解）及相关事项，类似于之前对模态逻辑立方体所取得的成果。第二种用途是作为伦理论据评估的工具。我们提供了人口伦理学中一个众所周知的悖论Parfit的令人厌恶的结论的计算机编码。如何通过这个编码增加或减少令人厌恶的结论的吸引力和说服力是一个我们希望向哲学和伦理学提出的问题。

    We report some results regarding the mechanization of normative (preference-based) conditional reasoning. Our focus is on Aqvist's system E for conditional obligation (and its extensions). Our mechanization is achieved via a shallow semantical embedding in Isabelle/HOL. We consider two possible uses of the framework. The first one is as a tool for meta-reasoning about the considered logic. We employ it for the automated verification of deontic correspondences (broadly conceived) and related matters, analogous to what has been previously achieved for the modal logic cube. The second use is as a tool for assessing ethical arguments. We provide a computer encoding of a well-known paradox in population ethics, Parfit's repugnant conclusion. Whether the presented encoding increases or decreases the attractiveness and persuasiveness of the repugnant conclusion is a question we would like to pass on to philosophy and ethics.
    
[^89]: 基于掩膜区域卷积神经网络 (Mask-RCNN) 的孟加拉文档版面分析性能增强

    Performance Enhancement Leveraging Mask-RCNN on Bengali Document Layout Analysis. (arXiv:2308.10511v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2308.10511](http://arxiv.org/abs/2308.10511)

    本论文旨在通过使用基于掩膜区域卷积神经网络 (Mask-RCNN) 对孟加拉文档进行版面分析，提升性能。通过逐步的超参数调整，我们达到了0.889的良好dice分数。虽然在应用英文文档模型时遇到了一些挑战，但这表明每种语言都有其特定的问题需要解决。

    

    理解数字文档就像解决一个谜题，尤其是历史文档。文档版面分析(DLA)通过将文档划分为段落、图片和表格等部分，帮助解决这个谜题。这对于机器来阅读和理解这些文档非常重要。在DL Sprint 2.0竞赛中，我们致力于理解孟加拉文档。我们使用了一个名为BaDLAD的数据集，其中包含很多例子。我们训练了一个特殊的模型，称为Mask R-CNN，来帮助理解。通过逐步的超参数调整，我们改进了这个模型，并取得了0.889的好的dice分数。然而，并不是一切都进行得非常完美。我们尝试使用训练好的英文文档模型，但它与孟加拉文不太匹配。这向我们展示了每种语言都有自己的挑战。我们对DL Sprint 2.0的解决方案可以在https://www.kaggle.com/competitions/dlsprint2/discussion/432201公开获得，其中包括notebooks、权重和推理笔记本。

    Understanding digital documents is like solving a puzzle, especially historical ones. Document Layout Analysis (DLA) helps with this puzzle by dividing documents into sections like paragraphs, images, and tables. This is crucial for machines to read and understand these documents. In the DL Sprint 2.0 competition, we worked on understanding Bangla documents. We used a dataset called BaDLAD with lots of examples. We trained a special model called Mask R-CNN to help with this understanding. We made this model better by step-by-step hyperparameter tuning, and we achieved a good dice score of 0.889. However, not everything went perfectly. We tried using a model trained for English documents, but it didn't fit well with Bangla. This showed us that each language has its own challenges. Our solution for the DL Sprint 2.0 is publicly available at https://www.kaggle.com/competitions/dlsprint2/discussion/432201 along with notebooks, weights, and inference notebook.
    
[^90]: 受冷落: 相似度分数的反差效应

    Taken by Surprise: Contrast effect for Similarity Scores. (arXiv:2308.09765v1 [cs.CL])

    [http://arxiv.org/abs/2308.09765](http://arxiv.org/abs/2308.09765)

    提出了一种新的相似度度量方法，称为“惊喜分数”，该方法能够考虑对象的上下文信息并显著提高零样本和少样本文档分类任务的性能。

    

    准确评估物体向量嵌入的相似度对于自然语言处理、信息检索和分类任务至关重要。流行的相似度分数（如余弦相似度）基于嵌入向量对，并忽略了从中提取对象的分布。人类对物体相似度的感知显著取决于对象出现的上下文。在这项工作中，我们提出了“惊喜分数”，这是一个对整体进行归一化的相似度度量，包括了人类感知的反差效应，并显著提高了零样本和少样本文档分类任务的性能。此分数量化了在两个元素之间找到给定相似度的惊喜，相对于成对的整体相似度。我们在零样本/少样本分类和聚类任务上评估了这个度量，通常发现与原始余弦相似度相比，性能提高了10-15\%。我们的代码...

    Accurately evaluating the similarity of object vector embeddings is of critical importance for natural language processing, information retrieval and classification tasks. Popular similarity scores (e.g cosine similarity) are based on pairs of embedding vectors and disregard the distribution of the ensemble from which objects are drawn. Human perception of object similarity significantly depends on the context in which the objects appear. In this work we propose the \emph{surprise score}, an ensemble-normalized similarity metric that encapsulates the contrast effect of human perception and significantly improves the classification performance on zero- and few-shot document classification tasks. This score quantifies the surprise to find a given similarity between two elements relative to the pairwise ensemble similarities. We evaluate this metric on zero/few shot classification and clustering tasks and typically find 10-15\% better performance compared to raw cosine similarity. Our cod
    
[^91]: MindMap：知识图谱激发大型语言模型的思维图思考方法

    MindMap: Knowledge Graph Prompting Sparks Graph of Thoughts in Large Language Models. (arXiv:2308.09729v1 [cs.AI])

    [http://arxiv.org/abs/2308.09729](http://arxiv.org/abs/2308.09729)

    本论文通过使用知识图谱来激发大型语言模型，解决了整合新知识、产生幻觉和决策过程不透明等问题，并通过生成思维导图展示了模型的推理路径，实验证明这种方法可以取得显著的实证增益。

    

    通常，大型语言模型存在无法整合新知识、产生幻觉和决策过程不透明等限制。本文探讨了如何利用知识图谱（KG）来激发大型语言模型，以解决整合最新知识和引发模型思维路径的问题。具体来说，我们构建了一个提示管道，使大型语言模型能够理解KG输入并利用隐含知识和检索到的外部知识进行推理。此外，我们研究了引发大型语言模型执行推理和生成答案的思维导图。研究发现，生成的思维导图基于知识的本体论，展示了大型语言模型的推理路径，从而为生产环境中的推理提供了探索和评估的可能性。对三个问答数据集的实验证明，MindMap提示方法带来了显著的实证增益。

    LLMs usually exhibit limitations in their ability to incorporate new knowledge, the generation of hallucinations, and the transparency of their decision-making process. In this paper, we explore how to prompt LLMs with knowledge graphs (KG), working as a remedy to engage LLMs with up-to-date knowledge and elicit the reasoning pathways from LLMs. Specifically, we build a prompting pipeline that endows LLMs with the capability of comprehending KG inputs and inferring with a combined implicit knowledge and the retrieved external knowledge. In addition, we investigate eliciting the mind map on which LLMs perform the reasoning and generate the answers. It is identified that the produced mind map exhibits the reasoning pathways of LLMs grounded on the ontology of knowledge, hence bringing the prospects of probing and gauging LLM inference in production. The experiments on three question & answering datasets also show that MindMap prompting leads to a striking empirical gain. For instance, pr
    
[^92]: PMET: 在Transformer中的精确模型编辑

    PMET: Precise Model Editing in a Transformer. (arXiv:2308.08742v1 [cs.CL])

    [http://arxiv.org/abs/2308.08742](http://arxiv.org/abs/2308.08742)

    该论文通过分析Transformer模型中的隐藏状态，发现多头自注意力编码了某些通用知识提取模式，因此在进行模型编辑时，不需要更新多头自注意力的权重。

    

    模型编辑技术可以以较低的成本修改大型语言模型中的少量知识，并且已经取得了显著的成功。现有方法假设Transformer层隐藏状态是前馈网络的键值内存的值。它们通常优化Transformer层隐藏状态来记忆目标知识，并将其用于更新大型语言模型中前馈网络的权重。然而，Transformer层隐藏状态的信息流来自三个部分：多头自注意力、前馈网络和残差连接。现有方法忽视了Transformer层隐藏状态包含了前馈网络特别需要的信息这一事实。因此，模型编辑的性能下降。为了实现更精确的模型编辑，我们分析了多头自注意力和前馈网络的隐藏状态，发现多头自注意力编码了某些通用知识提取模式。这意味着当引入新知识时，多头自注意力的权重不需要更新。

    Model editing techniques modify a minor proportion of knowledge in Large Language Models (LLMs) at a relatively low cost, which have demonstrated notable success. Existing methods assume Transformer Layer (TL) hidden states are values of key-value memories of the Feed-Forward Network (FFN). They usually optimize the TL hidden states to memorize target knowledge and use it to update the weights of the FFN in LLMs. However, the information flow of TL hidden states comes from three parts: Multi-Head Self-Attention (MHSA), FFN, and residual connections. Existing methods neglect the fact that the TL hidden states contains information not specifically required for FFN. Consequently, the performance of model editing decreases. To achieve more precise model editing, we analyze hidden states of MHSA and FFN, finding that MHSA encodes certain general knowledge extraction patterns. This implies that MHSA weights do not require updating when new knowledge is introduced. Based on above findings, we
    
[^93]: 人工智能中的意识：来自意识科学的洞见

    Consciousness in Artificial Intelligence: Insights from the Science of Consciousness. (arXiv:2308.08708v1 [cs.AI])

    [http://arxiv.org/abs/2308.08708](http://arxiv.org/abs/2308.08708)

    本论文提出了一种严谨的方法，通过对当前的人工智能系统进行详细评估来探讨人工智能的意识问题。研究中对几种科学意识理论进行概述，并通过计算方法推导出意识的“指示性特征”。分析结果表明目前的人工智能系统尚不具备意识，但建立具有意识的人工智能系统并无明显的障碍。

    

    当前或近期的人工智能系统是否能具有意识成为科学界关注的话题，也引起了公众的担忧。本报告提出并举例了一种严谨且经验基础的人工智能意识方法：根据我们目前最可信的神经科学理论对现有的人工智能系统进行详细评估。我们概述了几种广泛认可的科学意识理论，包括循环处理理论、全局工作空间理论、高阶理论、预测处理理论和注意模式理论。从这些理论中，我们推导出一些意识的“指示性特征”，并通过计算方法来评估人工智能系统是否具备这些特征。我们利用这些指示性特征来评估了几个近期的人工智能系统，并讨论了未来系统如何实现这些特征。我们的分析表明，目前没有现有的人工智能系统具有意识，但同时也显示出没有明显的建立具有意识的人工智能系统的障碍。

    Whether current or near-term AI systems could be conscious is a topic of scientific interest and increasing public concern. This report argues for, and exemplifies, a rigorous and empirically grounded approach to AI consciousness: assessing existing AI systems in detail, in light of our best-supported neuroscientific theories of consciousness. We survey several prominent scientific theories of consciousness, including recurrent processing theory, global workspace theory, higher-order theories, predictive processing, and attention schema theory. From these theories we derive "indicator properties" of consciousness, elucidated in computational terms that allow us to assess AI systems for these properties. We use these indicator properties to assess several recent AI systems, and we discuss how future systems might implement them. Our analysis suggests that no current AI systems are conscious, but also shows that there are no obvious barriers to building conscious AI systems.
    
[^94]: 具有环境感知记忆的上下文感知规划用于指导行为智能体

    Context-Aware Planning and Environment-Aware Memory for Instruction Following Embodied Agents. (arXiv:2308.07241v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2308.07241](http://arxiv.org/abs/2308.07241)

    这项研究提出了一种称为CPEM的系统，它利用上下文信息和环境感知记忆来改进行为智能体的感知能力，从而提高视觉导航和物体交互的效果。

    

    完成家务任务（例如“拿一杯水”）需要通过保持对空间对象的空间布局和先前行动的结果的知识来进行逐步的规划。然而，当前的行为智能体在感知模型方面经常出错，因为缺乏这种知识，而依赖于不完美的学习的模仿智能体或者没有关于先前行动对环境变化的知识的算法规划器。为了解决这个问题，我们提出了CPEM（上下文感知规划器和环境感知记忆），将先前行动的上下文信息与环境中物体的空间布局和状态（例如物体是否被移动）结合到感知模型中，以改进视觉导航和物体交互。我们观察到，CPEM在各种度量指标上实现了最先进的任务成功性能。

    Accomplishing household tasks such as 'bringing a cup of water' requires planning step-by-step actions by maintaining knowledge about the spatial arrangement of objects and the consequences of previous actions. Perception models of the current embodied AI agents, however, often make mistakes due to a lack of such knowledge but rely on imperfect learning of imitating agents or an algorithmic planner without knowledge about the changed environment by the previous actions. To address the issue, we propose CPEM (Context-aware Planner and Environment-aware Memory) to incorporate the contextual information of previous actions for planning and maintaining spatial arrangement of objects with their states (e.g., if an object has been moved or not) in an environment to the perception model for improving both visual navigation and object interaction. We observe that CPEM achieves state-of-the-art task success performance in various metrics using a challenging interactive instruction following ben
    
[^95]: 从噪声类型角度重新思考真实场景下的有噪标注学习问题

    Rethinking Noisy Label Learning in Real-world Annotation Scenarios from the Noise-type Perspective. (arXiv:2307.16889v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2307.16889](http://arxiv.org/abs/2307.16889)

    本文提出了一种基于样本选择的噪声标签学习方法，该方法可以在真实场景下区分不同类型的噪声，并利用噪声的语义信息进行学习。通过构建原型向量和计算样本与原型向量之间的距离，该方法可以改进标签的准确性。实证评估结果表明了该方法的鲁棒性和有效性。

    

    本文研究了在真实场景下学习具有噪声标签的问题，其中噪声可以分为两种类型：事实性噪声和模糊性噪声。为了更好地区分这些噪声类型并利用其语义，我们提出了一种基于样本选择的噪声标签学习方法，称为Proto-semi。Proto-semi通过预热将所有样本划分为自信和不自信的数据集。通过利用自信数据集，构建原型向量以捕捉类别特征。然后，计算不自信样本与原型向量之间的距离以促进噪声分类。根据这些距离，对标签进行修正或保留，从而改进自信和不自信数据集。最后，我们引入了一种半监督学习方法来增强训练。对一个真实标注数据集进行的实证评估证实了Proto-semi的鲁棒性。

    In this paper, we investigate the problem of learning with noisy labels in real-world annotation scenarios, where noise can be categorized into two types: factual noise and ambiguity noise. To better distinguish these noise types and utilize their semantics, we propose a novel sample selection-based approach for noisy label learning, called Proto-semi. Proto-semi initially divides all samples into the confident and unconfident datasets via warm-up. By leveraging the confident dataset, prototype vectors are constructed to capture class characteristics. Subsequently, the distances between the unconfident samples and the prototype vectors are calculated to facilitate noise classification. Based on these distances, the labels are either corrected or retained, resulting in the refinement of the confident and unconfident datasets. Finally, we introduce a semi-supervised learning method to enhance training. Empirical evaluations on a real-world annotated dataset substantiate the robustness of
    
[^96]: 在Wasserstein空间中通过数据集字典学习进行多源域自适应

    Multi-Source Domain Adaptation through Dataset Dictionary Learning in Wasserstein Space. (arXiv:2307.14953v1 [cs.LG])

    [http://arxiv.org/abs/2307.14953](http://arxiv.org/abs/2307.14953)

    本文提出了一种基于字典学习和最优传输的MSDA框架，通过将每个域表示为字典原子的Wasserstein重心来缓解数据分布偏移。根据该字典，提出了两种新的MSDA方法，分别基于目标域标记样本的重构和在原子分布上学习的分类器的集成。在多个基准测试集上进行的实验证明，这些方法在分类任务上取得了显著的改进效果。

    

    本文旨在解决多源域自适应（MSDA）问题，该问题旨在在从多个标记的源域转移知识到未标记的目标域时缓解数据分布偏移。我们提出了一种基于字典学习和最优传输的新型MSDA框架。我们将MSDA中的每个域解释为经验分布。因此，我们将每个域表达为字典原子的Wasserstein重心，这些原子是经验分布。我们提出了一种新的通过小批量学习的算法DaDiL：（i）原子分布；（ii）重心坐标矩阵。根据我们的字典，我们提出了两种新的MSDA方法：DaDiL-R，基于目标域标记样本的重构；DaDiL-E，基于在原子分布上学习的分类器的集成。我们在3个基准测试集中评估了我们的方法：Caltech-Office、Office 31和CRWU，在分类上改进了以前的最先进技术3.15％、2.29％和7.71％。

    This paper seeks to solve Multi-Source Domain Adaptation (MSDA), which aims to mitigate data distribution shifts when transferring knowledge from multiple labeled source domains to an unlabeled target domain. We propose a novel MSDA framework based on dictionary learning and optimal transport. We interpret each domain in MSDA as an empirical distribution. As such, we express each domain as a Wasserstein barycenter of dictionary atoms, which are empirical distributions. We propose a novel algorithm, DaDiL, for learning via mini-batches: (i) atom distributions; (ii) a matrix of barycentric coordinates. Based on our dictionary, we propose two novel methods for MSDA: DaDil-R, based on the reconstruction of labeled samples in the target domain, and DaDiL-E, based on the ensembling of classifiers learned on atom distributions. We evaluate our methods in 3 benchmarks: Caltech-Office, Office 31, and CRWU, where we improved previous state-of-the-art by 3.15%, 2.29%, and 7.71% in classification 
    
[^97]: 用于鲁棒和高效的立体匹配的不确定性引导自适应变形

    Uncertainty Guided Adaptive Warping for Robust and Efficient Stereo Matching. (arXiv:2307.14071v1 [cs.CV] CROSS LISTED)

    [http://arxiv.org/abs/2307.14071](http://arxiv.org/abs/2307.14071)

    本文提出了一种不确定性引导的自适应变形方法，用于鲁棒和高效的立体匹配。通过引入不确定性估计和可学习参数，可以在不同场景下适应性地调整采样区域，并实现更鲁棒和有效的立体匹配。

    

    基于相关的立体匹配取得了出色的性能，这是通过在两个特征图之间构建代价体来实现的。然而，当前的方法由于固定模型，在各种数据集上的表现并不一致，从而极大地限制了它们在实际应用中的适用性。为了解决这个问题，本文提出了一种动态计算相关性以用于鲁棒立体匹配的新视角。引入了一种新颖的不确定性引导自适应相关（UGAC）模块，以适应不同的场景。具体地，采用了基于方差的不确定性估计方法，在变形操作过程中自适应地调整采样区域。此外，我们改进了传统的非参数变形方法，引入可学习参数，从而可以学习位置特定的权重。实验证明，通过在循环网络中引入UGAC模块，可以更鲁棒和有效地利用立体匹配。广泛的实验证明了我们方法的性能。

    Correlation based stereo matching has achieved outstanding performance, which pursues cost volume between two feature maps. Unfortunately, current methods with a fixed model do not work uniformly well across various datasets, greatly limiting their real-world applicability. To tackle this issue, this paper proposes a new perspective to dynamically calculate correlation for robust stereo matching. A novel Uncertainty Guided Adaptive Correlation (UGAC) module is introduced to robustly adapt the same model for different scenarios. Specifically, a variance-based uncertainty estimation is employed to adaptively adjust the sampling area during warping operation. Additionally, we improve the traditional non-parametric warping with learnable parameters, such that the position-specific weights can be learned. We show that by empowering the recurrent network with the UGAC module, stereo matching can be exploited more robustly and effectively. Extensive experiments demonstrate that our method ach
    
[^98]: 一个用于光学相干断层扫描中脉络膜的高效全自动分析的开源深度学习算法

    An open-source deep learning algorithm for efficient and fully-automatic analysis of the choroid in optical coherence tomography. (arXiv:2307.00904v2 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2307.00904](http://arxiv.org/abs/2307.00904)

    本研究开发了一个名为DeepGPET的开源全自动深度学习算法，用于光学相干断层扫描中脉络膜区域分割，并且在数据准确性和处理速度方面取得了显著的改进。

    

    目的：开发一个开源全自动深度学习算法DeepGPET，用于光学相干断层扫描（OCT）数据中脉络膜区域分割。方法：我们使用了来自3个与系统性疾病相关的临床研究的715个OCT B-扫描（82名受试者，115只眼睛）的数据集。使用临床验证的半自动脉络膜分割方法高斯过程边缘追踪（GPET）生成了地面真实分割。我们对在ImageNet上预训练了MobileNetV3骨干的UNet进行了微调。标准分割一致性指标以及脉络膜厚度和面积的衍生度量被用于评估DeepGPET，同时还进行了临床眼科医生的定性评估。结果：DeepGPET在来自3个临床研究的数据上与GPET达到了很好的一致性（AUC = 0.9994，Dice = 0.9664；脉络膜厚度的皮尔逊相关系数为0.8908，脉络膜面积的皮尔逊相关系数为0.9082），同时将在标准笔记本电脑CPU上每张图像的平均处理时间缩短至34.49秒

    Purpose: To develop an open-source, fully-automatic deep learning algorithm, DeepGPET, for choroid region segmentation in optical coherence tomography (OCT) data. Methods: We used a dataset of 715 OCT B-scans (82 subjects, 115 eyes) from 3 clinical studies related to systemic disease. Ground truth segmentations were generated using a clinically validated, semi-automatic choroid segmentation method, Gaussian Process Edge Tracing (GPET). We finetuned a UNet with MobileNetV3 backbone pre-trained on ImageNet. Standard segmentation agreement metrics, as well as derived measures of choroidal thickness and area, were used to evaluate DeepGPET, alongside qualitative evaluation from a clinical ophthalmologist. Results: DeepGPET achieves excellent agreement with GPET on data from 3 clinical studies (AUC=0.9994, Dice=0.9664; Pearson correlation of 0.8908 for choroidal thickness and 0.9082 for choroidal area), while reducing the mean processing time per image on a standard laptop CPU from 34.49s (
    
[^99]: 自然语言处理中社会人口统计偏见的调查

    Survey on Sociodemographic Bias in Natural Language Processing. (arXiv:2306.08158v1 [cs.CL])

    [http://arxiv.org/abs/2306.08158](http://arxiv.org/abs/2306.08158)

    本文调查了209篇关于NLP模型偏见的论文，其中大部分涉及社会人口统计偏见。研究者提出了社会人口统计偏见的定义，并确定了NLP偏见研究的三个主要类别。当前去偏见技术只是隐藏了偏见而不是真正去除它，需要进一步改进。

    

    深度神经网络在训练过程中往往会学习到非预期的偏见，这在实际应用中可能会产生有害的影响。本文对209篇关于NLP模型中偏见的论文进行了调查，其中大部分论文涉及社会人口统计偏见。为了更好地理解偏见与真实世界的危害之间的区别，我们借鉴心理学和行为经济学的思想，提出了社会人口统计偏见的定义。我们确定了NLP偏见研究的三个主要类别：偏见类型、量化偏见和去偏见。我们认为当前对于量化偏见的方法存在可靠性问题，许多偏见度量并不涉及真实世界中的偏见，当前的去偏见技术是表面的，只是隐藏了偏见，而不是真正去除它。最后，我们提供了未来工作的建议。

    Deep neural networks often learn unintended biases during training, which might have harmful effects when deployed in real-world settings. This paper surveys 209 papers on bias in NLP models, most of which address sociodemographic bias. To better understand the distinction between bias and real-world harm, we turn to ideas from psychology and behavioral economics to propose a definition for sociodemographic bias. We identify three main categories of NLP bias research: types of bias, quantifying bias, and debiasing. We conclude that current approaches on quantifying bias face reliability issues, that many of the bias metrics do not relate to real-world biases, and that current debiasing techniques are superficial and hide bias rather than removing it. Finally, we provide recommendations for future work.
    
[^100]: 分布式鲁棒的离线强化学习：基于双重悲观性的通用算法和强健部分覆盖

    Double Pessimism is Provably Efficient for Distributionally Robust Offline Reinforcement Learning: Generic Algorithm and Robust Partial Coverage. (arXiv:2305.09659v1 [cs.LG])

    [http://arxiv.org/abs/2305.09659](http://arxiv.org/abs/2305.09659)

    本论文提出了一个名为P2MPO的算法框架，用于解决基于鲁棒离线RL的问题。该框架结合了灵活的模型估计子例程和双重悲观的策略优化步骤，采用双重悲观性原则以克服模型偏移等问题。研究表明，在模型准确性的假设下，该框架在拥有良好的鲁棒部分覆盖数据的情况下是具备高效性的。

    

    本文研究了分布式鲁棒的离线强化学习（鲁棒离线RL），其旨在从离线数据集中纯粹地找到一个能够在扰动环境中表现良好的最优强鲁棒策略。我们提出了一个名为P2MPO的算法框架，其中包含了灵活的模型估计子例程和双重悲观的策略优化步骤。双重悲观性原则对于克服由行为策略和目标策略家族之间的不匹配以及名义模型的扰动所引起的分布偏移至关重要。在对模型估计子例程进行一定准确性假设的情况下，我们证明了P2MPO算法在拥有良好的鲁棒部分覆盖数据的情况下是可证明有效的。

    We study distributionally robust offline reinforcement learning (robust offline RL), which seeks to find an optimal robust policy purely from an offline dataset that can perform well in perturbed environments. We propose a generic algorithm framework \underline{D}oubly \underline{P}essimistic \underline{M}odel-based \underline{P}olicy \underline{O}ptimization ($\texttt{P}^2\texttt{MPO}$) for robust offline RL, which features a novel combination of a flexible model estimation subroutine and a doubly pessimistic policy optimization step. The \emph{double pessimism} principle is crucial to overcome the distributional shift incurred by i) the mismatch between behavior policy and the family of target policies; and ii) the perturbation of the nominal model. Under certain accuracy assumptions on the model estimation subroutine, we show that $\texttt{P}^2\texttt{MPO}$ is provably efficient with \emph{robust partial coverage data}, which means that the offline dataset has good coverage of the d
    
[^101]: Chronosymbolic Learning: 结合符号推理与归纳学习的有效CHC求解方法

    Chronosymbolic Learning: Efficient CHC Solving with Symbolic Reasoning and Inductive Learning. (arXiv:2305.01206v1 [cs.LO])

    [http://arxiv.org/abs/2305.01206](http://arxiv.org/abs/2305.01206)

    Chronosymbolic Learning是一个简单而有效的框架，将符号推理和数据驱动方法相结合，用于高效地解决CHC系统。实验证明它在288个基准测试上表现出优异的结果，包括许多具有非线性整数算术的实例。

    

    CHC (Constrained Horn Clauses)的求解是许多验证和分析任务的基本挑战。数据驱动法在提高CHC求解效率方面显示出巨大的潜力，同时避免了手动创建和调整各种启发式方法的繁琐工作。但数据驱动的CHC求解器与基于符号推理的求解器之间存在巨大的性能差距。在这项工作中，我们开发了一个简单而有效的框架，"Chronosymbolic Learning"，它将符号信息和数值数据点统一起来，将CHC系统高效地求解。我们还展示了Chronosymbolic Learning的一个简单实例，其中包括一个数据驱动学习器和一个BMC样式的推理器。尽管该工具非常简单，但实验结果表明其效力和健壮性。它在由288个基准测试组成的数据集上胜过了最先进的CHC求解器，其中包括许多包含非线性整数算术的实例。

    Solving Constrained Horn Clauses (CHCs) is a fundamental challenge behind a wide range of verification and analysis tasks. Data-driven approaches show great promise in improving CHC solving without the painstaking manual effort of creating and tuning various heuristics. However, a large performance gap exists between data-driven CHC solvers and symbolic reasoning-based solvers. In this work, we develop a simple but effective framework, "Chronosymbolic Learning", which unifies symbolic information and numerical data points to solve a CHC system efficiently. We also present a simple instance of Chronosymbolic Learning with a data-driven learner and a BMC-styled reasoner. Despite its great simplicity, experimental results show the efficacy and robustness of our tool. It outperforms state-of-the-art CHC solvers on a dataset consisting of 288 benchmarks, including many instances with non-linear integer arithmetics.
    
[^102]: CVRecon: 重新思考神经重建的3D几何特征学习

    CVRecon: Rethinking 3D Geometric Feature Learning For Neural Reconstruction. (arXiv:2304.14633v1 [cs.CV])

    [http://arxiv.org/abs/2304.14633](http://arxiv.org/abs/2304.14633)

    研究团队提出了一种基于代价体的3D神经重建框架CVRecon，利用丰富的几何嵌入来促进3D几何特征学习。通过引入射线上下文补偿代价体（RCCV），有效提高了视角相关信息的完整性和鲁棒性，并在各种度量方面显着提高了重建质量。

    

    最近使用图像序列进行神经重建的进展取得了显着进展。但是，由于缺乏深度信息，现有的基于体积的技术仅沿整个相机光线复制对象表面的2D图像特征。我们认为这种复制会在空洞和遮挡空间中引入噪声，从而产生高质量的3D几何体成形方面产生挑战。受传统多视角立体方法的启发，我们提出了一种端到端的3D神经重建框架CVRecon，旨在利用代价体中丰富的几何嵌入来促进3D几何特征学习。此外，我们提出了一种新颖的3D几何特征表示法——射线上下文补偿代价体（RCCV），它具有更好的完整性和鲁棒性，可以编码视角相关信息。通过全面的实验，我们证明了我们的方法在各种度量方面显着提高了重建质量，并恢复了清晰的

    Recent advances in neural reconstruction using posed image sequences have made remarkable progress. However, due to the lack of depth information, existing volumetric-based techniques simply duplicate 2D image features of the object surface along the entire camera ray. We contend this duplication introduces noise in empty and occluded spaces, posing challenges for producing high-quality 3D geometry. Drawing inspiration from traditional multi-view stereo methods, we propose an end-to-end 3D neural reconstruction framework CVRecon, designed to exploit the rich geometric embedding in the cost volumes to facilitate 3D geometric feature learning. Furthermore, we present Ray-contextual Compensated Cost Volume (RCCV), a novel 3D geometric feature representation that encodes view-dependent information with improved integrity and robustness. Through comprehensive experiments, we demonstrate that our approach significantly improves the reconstruction quality in various metrics and recovers clear
    
[^103]: 更好地将文本到图像模型与人类偏好对齐

    Better Aligning Text-to-Image Models with Human Preference. (arXiv:2303.14420v1 [cs.CV])

    [http://arxiv.org/abs/2303.14420](http://arxiv.org/abs/2303.14420)

    研究者们收集了一个数据集，证明现有的生成模型评估指标与人类选择相关性不强。因此，他们使用这个数据集训练了一个人类偏好分类器，并通过HPS提出了一种方法以更好地将Stable Diffusion与人类审美偏好对齐。实验表明，该方法在预测人类选择方面优于CLIP，并具有良好的泛化能力。

    

    近年来，深度生成模型蓬勃发展，其中文本到图像模型备受关注。然而，现有模型通常生成的图像与人类审美偏好不符，例如肢体和面部表情的组合不自然。为解决这一问题，我们收集了来自Stable Foundation Discord频道的人类选择生成图像的数据集。我们的实验证明，当前的生成模型评估指标与人类选择相关性不强。因此，我们使用收集的数据集训练了一个人类偏好分类器，并基于该分类器得出了一个基于人类偏好的分数（HPS）。通过HPS，我们提出了一种简单而有效的方法，以更好地将Stable Diffusion与人类审美偏好对齐。我们的实验表明，HPS在预测人类选择方面优于CLIP，并且具有对来自其他模型生成的图像的良好泛化能力。通过使用HPS调整Stable Diffusion的噪声水平，我们实现了更好的人类偏好对齐，同时保持了生成图像的多样性和质量。

    Recent years have witnessed a rapid growth of deep generative models, with text-to-image models gaining significant attention from the public. However, existing models often generate images that do not align well with human aesthetic preferences, such as awkward combinations of limbs and facial expressions. To address this issue, we collect a dataset of human choices on generated images from the Stable Foundation Discord channel. Our experiments demonstrate that current evaluation metrics for generative models do not correlate well with human choices. Thus, we train a human preference classifier with the collected dataset and derive a Human Preference Score (HPS) based on the classifier. Using the HPS, we propose a simple yet effective method to adapt Stable Diffusion to better align with human aesthetic preferences. Our experiments show that the HPS outperforms CLIP in predicting human choices and has good generalization capability towards images generated from other models. By tuning
    
[^104]: h分析和数据并行的物理启发神经网络

    h-analysis and data-parallel physics-informed neural networks. (arXiv:2302.08835v2 [cs.CE] UPDATED)

    [http://arxiv.org/abs/2302.08835](http://arxiv.org/abs/2302.08835)

    本论文提出了一种基于$h$-分析和数据并行加速的物理启发神经网络（PINNs）的新协议，可以实现具有规模鲁棒性和高吞吐量的PIML模型。实验证明该协议易于实现，不会影响训练，并且具有高效性和可控性，为实现通用的规模鲁棒PIML铺平了道路。

    

    我们探索了物理启发机器学习（PIML）方案的数据并行加速，在多个图形处理单元（GPUs）体系结构下关注物理启发神经网络（PINNs）。为了开发适用于复杂应用的规模鲁棒和高吞吐量的PIML模型（例如，涉及复杂和高维领域、非线性操作符或多物理学），我们详细介绍了一种基于$h$-分析和通过Horovod训练框架进行数据并行加速的新协议。该协议基于对泛化误差和训练-测试差距的新收敛界限。我们表明加速实现简单，不会损害训练，并且证明是高效和可控的，为通用的规模鲁棒PIML铺平了道路。通过增加复杂性的大量数值实验证明了其稳健性和一致性，提供了广泛的

    We explore the data-parallel acceleration of physics-informed machine learning (PIML) schemes, with a focus on physics-informed neural networks (PINNs) for multiple graphics processing units (GPUs) architectures. In order to develop scale-robust and high-throughput PIML models for sophisticated applications which may require a large number of training points (e.g., involving complex and high-dimensional domains, non-linear operators or multi-physics), we detail a novel protocol based on $h$-analysis and data-parallel acceleration through the Horovod training framework. The protocol is backed by new convergence bounds for the generalization error and the train-test gap. We show that the acceleration is straightforward to implement, does not compromise training, and proves to be highly efficient and controllable, paving the way towards generic scale-robust PIML. Extensive numerical experiments with increasing complexity illustrate its robustness and consistency, offering a wide range of 
    
[^105]: Truveta Mapper：一个零样本本体映射框架

    Truveta Mapper: A Zero-shot Ontology Alignment Framework. (arXiv:2301.09767v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.09767](http://arxiv.org/abs/2301.09767)

    提出了一个将无监督本体匹配或本体对齐视为翻译任务的新视角的Truveta Mapper框架，在零样本、统一和端到端的方式下执行多本体对齐。该框架能够在运行时间延迟和对齐质量方面胜过现有解决方案，无需显式跨本体手动标注数据。

    

    本文提出了一种将无监督本体匹配(Ontology Matching, OM)或本体对齐(Ontology Alignment, OA)视为翻译任务的新视角。将本体表示为图形，在源本体图中的节点到目标本体图中的路径之间进行翻译。所提出的Truveta Mapper (TM)框架利用多任务序列到序列转换器模型，在零样本、统一和端到端的方式下执行多本体对齐。多任务使模型能够通过迁移学习来隐含地学习不同本体之间的关系，无需任何显式的跨本体手动标注数据。这也使得该框架能够在运行时间延迟和对齐质量方面胜过现有解决方案。模型仅在公开可用的文本语料库和内部本体数据上进行预训练和微调。该方案优于现有标准基准解决方案，如Edit-Similarity和MINTE+。

    In this paper, a new perspective is suggested for unsupervised Ontology Matching (OM) or Ontology Alignment (OA) by treating it as a translation task. Ontologies are represented as graphs, and the translation is performed from a node in the source ontology graph to a path in the target ontology graph. The proposed framework, Truveta Mapper (TM), leverages a multi-task sequence-to-sequence transformer model to perform alignment across multiple ontologies in a zero-shot, unified and end-to-end manner. Multi-tasking enables the model to implicitly learn the relationship between different ontologies via transfer-learning without requiring any explicit cross-ontology manually labeled data. This also enables the formulated framework to outperform existing solutions for both runtime latency and alignment quality. The model is pre-trained and fine-tuned only on publicly available text corpus and inner-ontologies data. The proposed solution outperforms state-of-the-art approaches, Edit-Similari
    
[^106]: 基于语义的沟通：一篇教程兼综述

    Semantics-Empowered Communication: A Tutorial-cum-Survey. (arXiv:2212.08487v3 [cs.HC] UPDATED)

    [http://arxiv.org/abs/2212.08487](http://arxiv.org/abs/2212.08487)

    本文提供了基于语义的沟通方面的教程兼综述，回顾了文献，介绍了SemCom生态系统，并将研究方向进行了分类。此外，还提供了启用技术的分类和未来应用场景的展望。

    

    随着基于语义的沟通（SemCom）研究的兴起，学术界和工业界对其各个方面（如理论、应用、度量和实现）的兴趣不断增长。本文的目的是提供一个综合性的调查，涵盖了背景和研究分类，以及详细的技术教程。具体而言，我们首先回顾文献并回答关于语义传输的“什么”和“为什么”问题。然后，我们展示了SemCom生态系统，包括历史、理论、度量、数据集和工具包，并介绍了研究方向的分类方式。此外，我们提议通过显式和隐式基于推理的方法对关键的启用技术进行分类，并详细阐述它们如何演变并为现代内容和通道语义驱动的通信做出贡献。除了回顾和总结最新的e技术，我们还提供了未来的展望和应用场景。

    Along with the springing up of the semantics-empowered communication (SemCom) research, it is now witnessing an unprecedentedly growing interest towards a wide range of aspects (e.g., theories, applications, metrics and implementations) in both academia and industry. In this work, we primarily aim to provide a comprehensive survey on both the background and research taxonomy, as well as a detailed technical tutorial. Specifically, we start by reviewing the literature and answering the "what" and "why" questions in semantic transmissions. Afterwards, we present the ecosystems of SemCom, including history, theories, metrics, datasets and toolkits, on top of which the taxonomy for research directions is presented. Furthermore, we propose to categorize the critical enabling techniques by explicit and implicit reasoning-based methods, and elaborate on how they evolve and contribute to modern content & channel semantics-empowered communications. Besides reviewing and summarizing the latest e
    
[^107]: LEAGUE: 长期操纵的引导式技能学习与抽象化

    LEAGUE: Guided Skill Learning and Abstraction for Long-Horizon Manipulation. (arXiv:2210.12631v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2210.12631](http://arxiv.org/abs/2210.12631)

    这项工作提出了一种名为LEAGUE的集成任务规划和技能学习框架，通过利用任务规划器的引导，结合符号接口和抽象化技巧，实现了长期操纵任务的学习和泛化。

    

    为了辅助日常的人类活动，机器人必须解决复杂的长期操纵任务，并且能够泛化到新环境中。近期的深度强化学习方法在完全自主学习方面显示出了希望，但是它们在大型环境中难以达到长期目标。另一方面，任务与动作规划（TAMP）方法在解决和泛化长期操纵任务方面表现出色，这要归功于它们强大的状态和动作抽象化。但是它们假设预先定义的技能集，这限制了它们在现实世界中的应用。在这项工作中，我们结合了这两种范式的优点，提出了一个集成任务规划和技能学习框架，名为LEAGUE（带引导的学习和抽象化）。LEAGUE利用任务规划器的符号接口来引导基于RL的技能学习，并创建抽象的状态空间以实现技能复用。更重要的是，LEAGUE在任务规划系统的场景中学习操纵技能，不断增强其能力。

    To assist with everyday human activities, robots must solve complex long-horizon tasks and generalize to new settings. Recent deep reinforcement learning (RL) methods show promise in fully autonomous learning, but they struggle to reach long-term goals in large environments. On the other hand, Task and Motion Planning (TAMP) approaches excel at solving and generalizing across long-horizon tasks, thanks to their powerful state and action abstractions. But they assume predefined skill sets, which limits their real-world applications. In this work, we combine the benefits of these two paradigms and propose an integrated task planning and skill learning framework named LEAGUE (Learning and Abstraction with Guidance). LEAGUE leverages the symbolic interface of a task planner to guide RL-based skill learning and creates abstract state space to enable skill reuse. More importantly, LEAGUE learns manipulation skills in-situ of the task planning system, continuously growing its capability and t
    
[^108]: 使用平衡传播的序列学习

    Sequence Learning Using Equilibrium Propagation. (arXiv:2209.09626v4 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2209.09626](http://arxiv.org/abs/2209.09626)

    本文提出了使用平衡传播（EP）进行序列学习的方法，EP是一种更符合生物可信性的学习框架，与传统的反向传播方法相比具有更广泛的应用性。文中利用现代Hopfield网络的进展，解决了基于EP的模型无法处理动态输入的问题，为复杂序列学习问题提供了解决方案。

    

    平衡传播（EP）是一种强大且更符合生物可信性的学习框架，可替代传统的反向传播方法。EP的有效性源于它仅依赖于局部计算，并且在训练的两个阶段中只需要一种计算单元，因此在生物启发的神经形态计算等领域具有更广泛的应用性。EP模型的动力学受能量函数控制，模型的内部状态随之收敛到稳定状态，遵循由同一函数定义的状态转换规则。然而，根据定义，EP要求模型的输入（收敛的循环神经网络）在训练的两个阶段中都是静态的。因此，不可能使用类似LSTM或GRU的架构设计基于EP的序列分类模型。本文利用现代Hopfield网络的最新进展，进一步理解基于能量的模型，并为复杂序列学习问题提供解决方案。

    Equilibrium Propagation (EP) is a powerful and more bio-plausible alternative to conventional learning frameworks such as backpropagation. The effectiveness of EP stems from the fact that it relies only on local computations and requires solely one kind of computational unit during both of its training phases, thereby enabling greater applicability in domains such as bio-inspired neuromorphic computing. The dynamics of the model in EP is governed by an energy function and the internal states of the model consequently converge to a steady state following the state transition rules defined by the same. However, by definition, EP requires the input to the model (a convergent RNN) to be static in both the phases of training. Thus it is not possible to design a model for sequence classification using EP with an LSTM or GRU like architecture. In this paper, we leverage recent developments in modern hopfield networks to further understand energy based models and develop solutions for complex 
    
[^109]: 通过分位数风险最小化实现可能的领域泛化

    Probable Domain Generalization via Quantile Risk Minimization. (arXiv:2207.09944v4 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2207.09944](http://arxiv.org/abs/2207.09944)

    该论文提出了一种通过Quantile Risk Minimization（QRM）方法实现可能的领域泛化的概率性框架。通过最小化预测器风险分布在不同领域上的分位数，该方法可以实现在测试时以高概率表现良好的预测器。

    

    领域泛化（DG）通过利用来自多个相关训练领域的数据，寻找在未见测试分布上表现良好的预测器。为了实现这一目标，DG通常被描述为对可能的领域集合进行平均或最坏情况下的问题。然而，平均情况下表现良好的预测器缺乏鲁棒性，而在最坏情况下表现良好的预测器往往过于保守。为解决这个问题，我们提出了一个新的概率性框架来进行DG，目标是学习以高概率表现良好的预测器。我们的关键思想是在训练过程中观察到的分布变化应该能够告诉我们测试时可能的分布变化，我们通过将训练和测试领域明确地视为从同一基础元分布中抽取的实现这一目标。为了实现可能的DG，我们提出了一个称为Quantile Risk Minimization（QRM）的新优化问题。通过最小化预测器风险分布在领域上的α-分位数，QRM可以实现概率上的DG。

    Domain generalization (DG) seeks predictors which perform well on unseen test distributions by leveraging data drawn from multiple related training distributions or domains. To achieve this, DG is commonly formulated as an average- or worst-case problem over the set of possible domains. However, predictors that perform well on average lack robustness while predictors that perform well in the worst case tend to be overly-conservative. To address this, we propose a new probabilistic framework for DG where the goal is to learn predictors that perform well with high probability. Our key idea is that distribution shifts seen during training should inform us of probable shifts at test time, which we realize by explicitly relating training and test domains as draws from the same underlying meta-distribution. To achieve probable DG, we propose a new optimization problem called Quantile Risk Minimization (QRM). By minimizing the $\alpha$-quantile of predictor's risk distribution over domains, Q
    
[^110]: 逆强化学习的主动探索方法

    Active Exploration for Inverse Reinforcement Learning. (arXiv:2207.08645v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2207.08645](http://arxiv.org/abs/2207.08645)

    AceIRL提出了一种新的逆强化学习算法，通过主动探索来学习奖励函数和策略，在不需要环境生成模型的情况下，能够确定可行奖励函数的置信区间，并找到侧重于环境中最有信息的区域的探索策略。

    

    逆强化学习（IRL）是从专家演示中推断奖励函数的强大范式。许多IRL算法需要已知的转移模型，有时甚至需要已知的专家策略，或者至少需要访问生成模型。但是，这些假设对于许多实际应用来说太强了，因为只能通过顺序交互来访问环境。我们提出了一种新的IRL算法：主动探索逆强化学习（AceIRL），它主动探索未知环境和专家策略，快速学习专家的奖励函数并识别出一个好的策略。AceIRL使用先前的观察结果构建置信区间来捕捉可行的奖励函数，并找到侧重于环境中最有信息的区域的探索策略。AceIRL是第一种具有样本复杂度界限且不需要环境生成模型的主动IRL方法。

    Inverse Reinforcement Learning (IRL) is a powerful paradigm for inferring a reward function from expert demonstrations. Many IRL algorithms require a known transition model and sometimes even a known expert policy, or they at least require access to a generative model. However, these assumptions are too strong for many real-world applications, where the environment can be accessed only through sequential interaction. We propose a novel IRL algorithm: Active exploration for Inverse Reinforcement Learning (AceIRL), which actively explores an unknown environment and expert policy to quickly learn the expert's reward function and identify a good policy. AceIRL uses previous observations to construct confidence intervals that capture plausible reward functions and find exploration policies that focus on the most informative regions of the environment. AceIRL is the first approach to active IRL with sample-complexity bounds that does not require a generative model of the environment. AceIRL 
    
[^111]: FRAug: 通过表示增强解决非独立同分布特征的联邦学习问题

    FRAug: Tackling Federated Learning with Non-IID Features via Representation Augmentation. (arXiv:2205.14900v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.14900](http://arxiv.org/abs/2205.14900)

    本研究提出了一种名为FRAug的方法，用于解决联邦学习中具有非独立同分布特征的问题。该方法通过在嵌入空间中生成合成的客户端特定样本来增强客户端数据集。通过训练一个共享的生成模型，将来自不同特征分布的客户端的知识融合起来。

    

    联邦学习是一种去中心化的学习范式，在其中多个客户端协同训练深度学习模型，而不集中其本地数据，从而保护数据隐私。实际应用通常涉及不同客户端数据集之间的分布偏移，这会损害客户端对来自各自数据分布的未见样本的泛化能力。本研究解决了最近提出的特征偏移问题，其中客户端具有不同的特征分布，而标签分布相同。我们提出了Federated Representation Augmentation (FRAug)来解决这个实际且具有挑战性的问题。我们的方法在嵌入空间中生成合成的客户端特定样本，以增强通常较小的客户端数据集。为此，我们训练一个共享的生成模型，来融合客户端从不同特征分布中学到的知识。这个生成器合成客户无关的嵌入向量。

    Federated Learning (FL) is a decentralized learning paradigm, in which multiple clients collaboratively train deep learning models without centralizing their local data, and hence preserve data privacy. Real-world applications usually involve a distribution shift across the datasets of the different clients, which hurts the generalization ability of the clients to unseen samples from their respective data distributions. In this work, we address the recently proposed feature shift problem where the clients have different feature distributions, while the label distribution is the same. We propose Federated Representation Augmentation (FRAug) to tackle this practical and challenging problem. Our approach generates synthetic client-specific samples in the embedding space to augment the usually small client datasets. For that, we train a shared generative model to fuse the clients knowledge learned from their different feature distributions. This generator synthesizes client-agnostic embedd
    
[^112]: 信息论引导的启发式渐进式多视角编码

    Information Theory-Guided Heuristic Progressive Multi-View Coding. (arXiv:2109.02344v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2109.02344](http://arxiv.org/abs/2109.02344)

    该论文从信息论的视角重新思考了现有的多视角学习范式，并提出了一种新的信息论框架，用于广义的多视角学习。在此框架的指导下，作者提出了一种三层递进的多视角编码方法。

    

    多视角表示学习从共享上下文的多个视角中捕捉综合信息。最近的研究直观地将对比学习（CL）应用于表示学习，被认为是一种成对方式，但仍然可扩展：在学习视角共享表示时，不会过滤特定于视角的噪声；虚假的负对，其中负项实际上与正项属于同一类，以及真实的负对被等同对待；均匀地测量术语之间的相似性可能干扰优化。重要的是，很少有研究针对广义自监督多视角学习的理论框架，尤其是针对超过两个视角的情况。为此，我们从信息理论的角度重新思考现有的多视角学习范式，然后提出了一种新颖的信息理论框架，用于广义多视角学习。在其指导下，我们构建了一种具有三层递进的多视角编码方法。

    Multi-view representation learning captures comprehensive information from multiple views of a shared context. Recent works intuitively apply contrastive learning (CL) to learn representations, regarded as a pairwise manner, which is still scalable: view-specific noise is not filtered in learning view-shared representations; the fake negative pairs, where the negative terms are actually within the same class as the positive, and the real negative pairs are coequally treated; and evenly measuring the similarities between terms might interfere with optimization. Importantly, few works research the theoretical framework of generalized self-supervised multi-view learning, especially for more than two views. To this end, we rethink the existing multi-view learning paradigm from the information theoretical perspective and then propose a novel information theoretical framework for generalized multi-view learning. Guided by it, we build a multi-view coding method with a three-tier progressive 
    
[^113]: 在基于图像和语言嵌入中测量社会偏见

    Measuring Social Biases in Grounded Vision and Language Embeddings. (arXiv:2002.08911v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2002.08911](http://arxiv.org/abs/2002.08911)

    该论文推广了社会偏见的概念，从语言嵌入扩展到了基于图像和语言的嵌入。研究表明，基于图像和语言的嵌入中的偏见与未经培训的嵌入中的偏见同等重要甚至更重要。并通过引入新的度量方法来研究偏见、语言和视觉之间的交互作用。

    

    我们将社会偏见的概念从语言嵌入推广到了基于图像和语言的嵌入中。存在于基于图像和语言嵌入中的偏见似乎与未经培训的嵌入中的偏见同等甚至更为重要。尽管视觉和语言可能受到不同的偏见，人们可能希望这些偏见可以相互衰减，但实际情况并非如此。我们提出了多种泛化度量嵌入中的偏见的方法，并引入了泛化空间（Grounded-WEAT和Grounded-SEAT），并展示了三种不同的泛化方法对于偏见、语言和视觉交互作用的重要问题具有不同的回答。我们使用这些度量方法在一个新的数据集上进行实验，这是第一个用于基于图像的偏见的数据集，通过在COCO、概念字幕和谷歌图像等标准语言偏见基准上增加10,228张图像来构建。数据集的构建具有挑战性，因为视觉数据集本身就存在很大的偏见。

    We generalize the notion of social biases from language embeddings to grounded vision and language embeddings. Biases are present in grounded embeddings, and indeed seem to be equally or more significant than for ungrounded embeddings. This is despite the fact that vision and language can suffer from different biases, which one might hope could attenuate the biases in both. Multiple ways exist to generalize metrics measuring bias in word embeddings to this new setting. We introduce the space of generalizations (Grounded-WEAT and Grounded-SEAT) and demonstrate that three generalizations answer different yet important questions about how biases, language, and vision interact. These metrics are used on a new dataset, the first for grounded bias, created by augmenting extending standard linguistic bias benchmarks with 10,228 images from COCO, Conceptual Captions, and Google Images. Dataset construction is challenging because vision datasets are themselves very biased. The presence of these
    

